tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 459, val: 25, test: 0	
vocab size: 168	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 306344	
cloning rnn	
cloning criterion	
1/22950 (epoch 0.002), train_loss = 5.13137259, grad/param norm = 5.6210e-01, time/batch = 0.7333s	
2/22950 (epoch 0.004), train_loss = 4.89638978, grad/param norm = 1.3856e+00, time/batch = 0.6769s	
3/22950 (epoch 0.007), train_loss = 4.06068990, grad/param norm = 1.7335e+00, time/batch = 0.6808s	
4/22950 (epoch 0.009), train_loss = 3.72874528, grad/param norm = 1.1836e+00, time/batch = 0.6770s	
5/22950 (epoch 0.011), train_loss = 3.76368650, grad/param norm = 8.6793e-01, time/batch = 0.6729s	
6/22950 (epoch 0.013), train_loss = 3.77646816, grad/param norm = 9.1137e-01, time/batch = 0.6762s	
7/22950 (epoch 0.015), train_loss = 3.53133739, grad/param norm = 5.8429e-01, time/batch = 0.6763s	
8/22950 (epoch 0.017), train_loss = 3.46294543, grad/param norm = 6.4712e-01, time/batch = 0.6764s	
9/22950 (epoch 0.020), train_loss = 3.39129124, grad/param norm = 5.8556e-01, time/batch = 0.6873s	
10/22950 (epoch 0.022), train_loss = 3.37684639, grad/param norm = 4.7083e-01, time/batch = 0.6996s	
11/22950 (epoch 0.024), train_loss = 3.30731809, grad/param norm = 5.4463e-01, time/batch = 0.6848s	
12/22950 (epoch 0.026), train_loss = 3.24389160, grad/param norm = 7.3404e-01, time/batch = 0.6741s	
13/22950 (epoch 0.028), train_loss = 3.48297784, grad/param norm = 8.0369e-01, time/batch = 0.6781s	
14/22950 (epoch 0.031), train_loss = 3.62217019, grad/param norm = 6.1453e-01, time/batch = 0.6746s	
15/22950 (epoch 0.033), train_loss = 3.75887671, grad/param norm = 7.9334e-01, time/batch = 0.7098s	
16/22950 (epoch 0.035), train_loss = 3.66270136, grad/param norm = 7.2457e-01, time/batch = 0.6975s	
17/22950 (epoch 0.037), train_loss = 3.54333025, grad/param norm = 4.8592e-01, time/batch = 0.6907s	
18/22950 (epoch 0.039), train_loss = 3.58272625, grad/param norm = 5.1745e-01, time/batch = 0.6844s	
19/22950 (epoch 0.041), train_loss = 3.55674903, grad/param norm = 6.0212e-01, time/batch = 0.6803s	
20/22950 (epoch 0.044), train_loss = 3.36310472, grad/param norm = 6.0715e-01, time/batch = 0.6749s	
21/22950 (epoch 0.046), train_loss = 3.45399920, grad/param norm = 4.1227e-01, time/batch = 0.6791s	
22/22950 (epoch 0.048), train_loss = 3.35400190, grad/param norm = 6.8496e-01, time/batch = 0.6755s	
23/22950 (epoch 0.050), train_loss = 3.36042483, grad/param norm = 5.7634e-01, time/batch = 0.6725s	
24/22950 (epoch 0.052), train_loss = 3.33996420, grad/param norm = 6.0201e-01, time/batch = 0.6722s	
25/22950 (epoch 0.054), train_loss = 3.46470243, grad/param norm = 6.6938e-01, time/batch = 0.6848s	
26/22950 (epoch 0.057), train_loss = 3.39171643, grad/param norm = 6.4667e-01, time/batch = 0.6844s	
27/22950 (epoch 0.059), train_loss = 3.36827812, grad/param norm = 7.5244e-01, time/batch = 0.7098s	
28/22950 (epoch 0.061), train_loss = 3.30708288, grad/param norm = 6.1134e-01, time/batch = 0.6763s	
29/22950 (epoch 0.063), train_loss = 3.40226967, grad/param norm = 5.0359e-01, time/batch = 0.6915s	
30/22950 (epoch 0.065), train_loss = 3.22459101, grad/param norm = 6.7194e-01, time/batch = 0.7003s	
31/22950 (epoch 0.068), train_loss = 3.51124164, grad/param norm = 7.0968e-01, time/batch = 0.6980s	
32/22950 (epoch 0.070), train_loss = 3.43454981, grad/param norm = 7.9927e-01, time/batch = 0.6957s	
33/22950 (epoch 0.072), train_loss = 3.36145232, grad/param norm = 9.9200e-01, time/batch = 0.6782s	
34/22950 (epoch 0.074), train_loss = 3.38878718, grad/param norm = 9.1364e-01, time/batch = 0.6730s	
35/22950 (epoch 0.076), train_loss = 3.27395596, grad/param norm = 5.9093e-01, time/batch = 0.6829s	
36/22950 (epoch 0.078), train_loss = 3.39738054, grad/param norm = 5.2304e-01, time/batch = 0.6869s	
37/22950 (epoch 0.081), train_loss = 3.36649135, grad/param norm = 5.0952e-01, time/batch = 0.7111s	
38/22950 (epoch 0.083), train_loss = 3.34807807, grad/param norm = 7.6732e-01, time/batch = 0.6813s	
39/22950 (epoch 0.085), train_loss = 3.27463008, grad/param norm = 5.7255e-01, time/batch = 0.6763s	
40/22950 (epoch 0.087), train_loss = 3.40998116, grad/param norm = 6.9485e-01, time/batch = 0.6715s	
41/22950 (epoch 0.089), train_loss = 3.43930768, grad/param norm = 6.4228e-01, time/batch = 0.6741s	
42/22950 (epoch 0.092), train_loss = 3.39063748, grad/param norm = 6.7903e-01, time/batch = 0.6705s	
43/22950 (epoch 0.094), train_loss = 3.45183933, grad/param norm = 5.2455e-01, time/batch = 0.6751s	
44/22950 (epoch 0.096), train_loss = 3.34580597, grad/param norm = 5.5885e-01, time/batch = 0.6738s	
45/22950 (epoch 0.098), train_loss = 3.39295693, grad/param norm = 6.2054e-01, time/batch = 0.6721s	
46/22950 (epoch 0.100), train_loss = 3.46868742, grad/param norm = 5.8373e-01, time/batch = 0.6730s	
47/22950 (epoch 0.102), train_loss = 3.36268282, grad/param norm = 5.6847e-01, time/batch = 0.7071s	
48/22950 (epoch 0.105), train_loss = 3.28073121, grad/param norm = 5.8564e-01, time/batch = 0.6890s	
49/22950 (epoch 0.107), train_loss = 3.35874754, grad/param norm = 6.7456e-01, time/batch = 0.6721s	
50/22950 (epoch 0.109), train_loss = 3.30569458, grad/param norm = 6.8556e-01, time/batch = 0.6696s	
51/22950 (epoch 0.111), train_loss = 3.25307892, grad/param norm = 4.5719e-01, time/batch = 0.6710s	
52/22950 (epoch 0.113), train_loss = 3.33598834, grad/param norm = 6.1489e-01, time/batch = 0.6827s	
53/22950 (epoch 0.115), train_loss = 3.37131306, grad/param norm = 6.5142e-01, time/batch = 0.6773s	
54/22950 (epoch 0.118), train_loss = 3.49638425, grad/param norm = 6.0989e-01, time/batch = 0.6758s	
55/22950 (epoch 0.120), train_loss = 3.26929378, grad/param norm = 5.5156e-01, time/batch = 0.6779s	
56/22950 (epoch 0.122), train_loss = 3.35616074, grad/param norm = 5.2246e-01, time/batch = 0.6794s	
57/22950 (epoch 0.124), train_loss = 3.30002266, grad/param norm = 5.2165e-01, time/batch = 0.7040s	
58/22950 (epoch 0.126), train_loss = 3.25105006, grad/param norm = 5.8220e-01, time/batch = 0.7048s	
59/22950 (epoch 0.129), train_loss = 3.27115852, grad/param norm = 4.5305e-01, time/batch = 0.6920s	
60/22950 (epoch 0.131), train_loss = 3.28615282, grad/param norm = 6.6525e-01, time/batch = 0.6941s	
61/22950 (epoch 0.133), train_loss = 3.46801674, grad/param norm = 6.6388e-01, time/batch = 0.7042s	
62/22950 (epoch 0.135), train_loss = 3.29325690, grad/param norm = 5.8617e-01, time/batch = 0.6944s	
63/22950 (epoch 0.137), train_loss = 3.41010013, grad/param norm = 5.4203e-01, time/batch = 0.6941s	
64/22950 (epoch 0.139), train_loss = 3.22657056, grad/param norm = 7.5323e-01, time/batch = 0.6782s	
65/22950 (epoch 0.142), train_loss = 3.25761230, grad/param norm = 8.0296e-01, time/batch = 0.6760s	
66/22950 (epoch 0.144), train_loss = 3.34274944, grad/param norm = 7.3493e-01, time/batch = 0.6740s	
67/22950 (epoch 0.146), train_loss = 3.34513961, grad/param norm = 6.7534e-01, time/batch = 0.6724s	
68/22950 (epoch 0.148), train_loss = 3.28263263, grad/param norm = 7.5545e-01, time/batch = 0.6750s	
69/22950 (epoch 0.150), train_loss = 3.39059883, grad/param norm = 4.6905e-01, time/batch = 0.6736s	
70/22950 (epoch 0.153), train_loss = 3.31785445, grad/param norm = 4.9597e-01, time/batch = 0.6735s	
71/22950 (epoch 0.155), train_loss = 3.32151986, grad/param norm = 4.0627e-01, time/batch = 0.6735s	
72/22950 (epoch 0.157), train_loss = 3.25993865, grad/param norm = 5.1563e-01, time/batch = 0.6833s	
73/22950 (epoch 0.159), train_loss = 3.31130582, grad/param norm = 7.2745e-01, time/batch = 0.6740s	
74/22950 (epoch 0.161), train_loss = 3.51070822, grad/param norm = 5.5346e-01, time/batch = 0.6959s	
75/22950 (epoch 0.163), train_loss = 3.75578883, grad/param norm = 5.7095e-01, time/batch = 0.7096s	
76/22950 (epoch 0.166), train_loss = 3.77318936, grad/param norm = 5.8518e-01, time/batch = 0.7034s	
77/22950 (epoch 0.168), train_loss = 3.54093910, grad/param norm = 5.7830e-01, time/batch = 0.6950s	
78/22950 (epoch 0.170), train_loss = 3.30726874, grad/param norm = 6.5607e-01, time/batch = 0.7098s	
79/22950 (epoch 0.172), train_loss = 3.32900489, grad/param norm = 7.4533e-01, time/batch = 0.7048s	
80/22950 (epoch 0.174), train_loss = 3.32511302, grad/param norm = 5.3318e-01, time/batch = 0.6879s	
81/22950 (epoch 0.176), train_loss = 3.34853533, grad/param norm = 5.0174e-01, time/batch = 0.6825s	
82/22950 (epoch 0.179), train_loss = 3.35971583, grad/param norm = 4.0392e-01, time/batch = 0.6847s	
83/22950 (epoch 0.181), train_loss = 3.42665805, grad/param norm = 3.7380e-01, time/batch = 0.6765s	
84/22950 (epoch 0.183), train_loss = 3.23640855, grad/param norm = 5.8981e-01, time/batch = 0.6775s	
85/22950 (epoch 0.185), train_loss = 3.39887952, grad/param norm = 5.2899e-01, time/batch = 0.6738s	
86/22950 (epoch 0.187), train_loss = 3.28272688, grad/param norm = 5.3296e-01, time/batch = 0.6775s	
87/22950 (epoch 0.190), train_loss = 3.34522597, grad/param norm = 5.5351e-01, time/batch = 0.6749s	
88/22950 (epoch 0.192), train_loss = 3.39450093, grad/param norm = 6.0161e-01, time/batch = 0.6747s	
89/22950 (epoch 0.194), train_loss = 3.35501092, grad/param norm = 6.0121e-01, time/batch = 0.6717s	
90/22950 (epoch 0.196), train_loss = 3.24417990, grad/param norm = 3.6927e-01, time/batch = 0.6745s	
91/22950 (epoch 0.198), train_loss = 3.38736013, grad/param norm = 4.6175e-01, time/batch = 0.6760s	
92/22950 (epoch 0.200), train_loss = 3.29004964, grad/param norm = 5.9873e-01, time/batch = 0.6726s	
93/22950 (epoch 0.203), train_loss = 3.23557341, grad/param norm = 5.8534e-01, time/batch = 0.6725s	
94/22950 (epoch 0.205), train_loss = 3.36390102, grad/param norm = 7.0353e-01, time/batch = 0.6743s	
95/22950 (epoch 0.207), train_loss = 3.36717576, grad/param norm = 6.2354e-01, time/batch = 0.6761s	
96/22950 (epoch 0.209), train_loss = 3.68048699, grad/param norm = 5.9777e-01, time/batch = 0.6718s	
97/22950 (epoch 0.211), train_loss = 3.36660724, grad/param norm = 6.0249e-01, time/batch = 0.6721s	
98/22950 (epoch 0.214), train_loss = 3.33399125, grad/param norm = 5.9778e-01, time/batch = 0.6730s	
99/22950 (epoch 0.216), train_loss = 3.35288135, grad/param norm = 6.1589e-01, time/batch = 0.6770s	
100/22950 (epoch 0.218), train_loss = 3.27010099, grad/param norm = 4.2829e-01, time/batch = 0.6722s	
101/22950 (epoch 0.220), train_loss = 3.52145346, grad/param norm = 4.8591e-01, time/batch = 0.6756s	
102/22950 (epoch 0.222), train_loss = 3.42287402, grad/param norm = 4.2789e-01, time/batch = 0.6741s	
103/22950 (epoch 0.224), train_loss = 3.27447912, grad/param norm = 4.0231e-01, time/batch = 0.6766s	
104/22950 (epoch 0.227), train_loss = 3.31049355, grad/param norm = 4.4344e-01, time/batch = 0.6736s	
105/22950 (epoch 0.229), train_loss = 3.31382339, grad/param norm = 6.1668e-01, time/batch = 0.6777s	
106/22950 (epoch 0.231), train_loss = 3.25166265, grad/param norm = 6.8698e-01, time/batch = 0.6710s	
107/22950 (epoch 0.233), train_loss = 3.29954462, grad/param norm = 5.7228e-01, time/batch = 0.6726s	
108/22950 (epoch 0.235), train_loss = 3.29331932, grad/param norm = 6.5720e-01, time/batch = 0.6717s	
109/22950 (epoch 0.237), train_loss = 3.25989622, grad/param norm = 4.5394e-01, time/batch = 0.6742s	
110/22950 (epoch 0.240), train_loss = 3.20047620, grad/param norm = 3.7443e-01, time/batch = 0.6733s	
111/22950 (epoch 0.242), train_loss = 3.32041265, grad/param norm = 6.1993e-01, time/batch = 0.6714s	
112/22950 (epoch 0.244), train_loss = 3.32334568, grad/param norm = 5.0911e-01, time/batch = 0.6719s	
113/22950 (epoch 0.246), train_loss = 3.37884579, grad/param norm = 4.8374e-01, time/batch = 0.6734s	
114/22950 (epoch 0.248), train_loss = 3.24741040, grad/param norm = 5.9583e-01, time/batch = 0.6744s	
115/22950 (epoch 0.251), train_loss = 3.27858006, grad/param norm = 6.5393e-01, time/batch = 0.6744s	
116/22950 (epoch 0.253), train_loss = 3.29383025, grad/param norm = 6.4211e-01, time/batch = 0.6768s	
117/22950 (epoch 0.255), train_loss = 3.22312979, grad/param norm = 4.6631e-01, time/batch = 0.6708s	
118/22950 (epoch 0.257), train_loss = 3.35429959, grad/param norm = 5.2552e-01, time/batch = 0.6746s	
119/22950 (epoch 0.259), train_loss = 3.38849454, grad/param norm = 4.8756e-01, time/batch = 0.6754s	
120/22950 (epoch 0.261), train_loss = 3.82201903, grad/param norm = 6.1958e-01, time/batch = 0.6824s	
121/22950 (epoch 0.264), train_loss = 3.75685744, grad/param norm = 6.5876e-01, time/batch = 0.6766s	
122/22950 (epoch 0.266), train_loss = 3.78889009, grad/param norm = 6.5895e-01, time/batch = 0.6755s	
123/22950 (epoch 0.268), train_loss = 3.82696480, grad/param norm = 7.0813e-01, time/batch = 0.6730s	
124/22950 (epoch 0.270), train_loss = 3.57405157, grad/param norm = 3.9051e-01, time/batch = 0.6718s	
125/22950 (epoch 0.272), train_loss = 3.67905779, grad/param norm = 4.7013e-01, time/batch = 0.6751s	
126/22950 (epoch 0.275), train_loss = 3.38895143, grad/param norm = 8.0602e-01, time/batch = 0.6809s	
127/22950 (epoch 0.277), train_loss = 3.32690608, grad/param norm = 9.7736e-01, time/batch = 0.6778s	
128/22950 (epoch 0.279), train_loss = 3.36139244, grad/param norm = 4.3829e-01, time/batch = 0.6995s	
129/22950 (epoch 0.281), train_loss = 3.37202341, grad/param norm = 4.7674e-01, time/batch = 0.7097s	
130/22950 (epoch 0.283), train_loss = 3.27136591, grad/param norm = 5.2907e-01, time/batch = 0.7010s	
131/22950 (epoch 0.285), train_loss = 3.16041450, grad/param norm = 4.2251e-01, time/batch = 0.6912s	
132/22950 (epoch 0.288), train_loss = 3.24121503, grad/param norm = 5.3194e-01, time/batch = 0.6874s	
133/22950 (epoch 0.290), train_loss = 3.34143460, grad/param norm = 4.0865e-01, time/batch = 0.6873s	
134/22950 (epoch 0.292), train_loss = 3.19706756, grad/param norm = 4.5690e-01, time/batch = 0.6775s	
135/22950 (epoch 0.294), train_loss = 3.28775573, grad/param norm = 3.5831e-01, time/batch = 0.6745s	
136/22950 (epoch 0.296), train_loss = 3.18964578, grad/param norm = 3.2890e-01, time/batch = 0.6722s	
137/22950 (epoch 0.298), train_loss = 3.35623546, grad/param norm = 4.3862e-01, time/batch = 0.6727s	
138/22950 (epoch 0.301), train_loss = 3.25435748, grad/param norm = 4.1296e-01, time/batch = 0.6717s	
139/22950 (epoch 0.303), train_loss = 3.39703107, grad/param norm = 4.7106e-01, time/batch = 0.6779s	
140/22950 (epoch 0.305), train_loss = 3.71192645, grad/param norm = 4.9534e-01, time/batch = 0.6729s	
141/22950 (epoch 0.307), train_loss = 3.54751482, grad/param norm = 5.5701e-01, time/batch = 0.6714s	
142/22950 (epoch 0.309), train_loss = 3.57389253, grad/param norm = 8.1087e-01, time/batch = 0.6766s	
143/22950 (epoch 0.312), train_loss = 3.43875356, grad/param norm = 1.4866e+00, time/batch = 0.6775s	
144/22950 (epoch 0.314), train_loss = 3.23017853, grad/param norm = 6.7054e-01, time/batch = 0.6777s	
145/22950 (epoch 0.316), train_loss = 3.19016326, grad/param norm = 5.1865e-01, time/batch = 0.6846s	
146/22950 (epoch 0.318), train_loss = 3.22237694, grad/param norm = 4.6674e-01, time/batch = 0.6745s	
147/22950 (epoch 0.320), train_loss = 3.29616910, grad/param norm = 4.4794e-01, time/batch = 0.6782s	
148/22950 (epoch 0.322), train_loss = 3.17979566, grad/param norm = 5.5140e-01, time/batch = 0.6751s	
149/22950 (epoch 0.325), train_loss = 3.14135525, grad/param norm = 4.5249e-01, time/batch = 0.6764s	
150/22950 (epoch 0.327), train_loss = 3.10014753, grad/param norm = 4.3695e-01, time/batch = 0.6725s	
151/22950 (epoch 0.329), train_loss = 3.07185107, grad/param norm = 4.8657e-01, time/batch = 0.6785s	
152/22950 (epoch 0.331), train_loss = 3.14710054, grad/param norm = 4.5171e-01, time/batch = 0.6786s	
153/22950 (epoch 0.333), train_loss = 3.12215616, grad/param norm = 6.7275e-01, time/batch = 0.6733s	
154/22950 (epoch 0.336), train_loss = 3.21276685, grad/param norm = 1.0594e+00, time/batch = 0.6767s	
155/22950 (epoch 0.338), train_loss = 3.18597995, grad/param norm = 9.9689e-01, time/batch = 0.6744s	
156/22950 (epoch 0.340), train_loss = 3.05444486, grad/param norm = 6.9874e-01, time/batch = 0.6735s	
157/22950 (epoch 0.342), train_loss = 3.14920251, grad/param norm = 4.4920e-01, time/batch = 0.6742s	
158/22950 (epoch 0.344), train_loss = 3.14871194, grad/param norm = 4.0731e-01, time/batch = 0.6858s	
159/22950 (epoch 0.346), train_loss = 3.22065320, grad/param norm = 3.7925e-01, time/batch = 0.6799s	
160/22950 (epoch 0.349), train_loss = 3.30238475, grad/param norm = 5.3484e-01, time/batch = 0.6768s	
161/22950 (epoch 0.351), train_loss = 3.19115621, grad/param norm = 6.8873e-01, time/batch = 0.6760s	
162/22950 (epoch 0.353), train_loss = 3.18509677, grad/param norm = 6.8702e-01, time/batch = 0.6984s	
163/22950 (epoch 0.355), train_loss = 3.40335104, grad/param norm = 4.7824e-01, time/batch = 0.7027s	
164/22950 (epoch 0.357), train_loss = 3.43885568, grad/param norm = 4.1996e-01, time/batch = 0.7093s	
165/22950 (epoch 0.359), train_loss = 3.35531123, grad/param norm = 3.9409e-01, time/batch = 0.6853s	
166/22950 (epoch 0.362), train_loss = 3.28705947, grad/param norm = 1.1420e+00, time/batch = 0.6768s	
167/22950 (epoch 0.364), train_loss = 3.20376322, grad/param norm = 1.6330e+00, time/batch = 0.6879s	
168/22950 (epoch 0.366), train_loss = 3.02023175, grad/param norm = 7.8463e-01, time/batch = 0.6752s	
169/22950 (epoch 0.368), train_loss = 3.00830109, grad/param norm = 3.5878e-01, time/batch = 0.6784s	
170/22950 (epoch 0.370), train_loss = 3.00745815, grad/param norm = 3.5552e-01, time/batch = 0.6774s	
171/22950 (epoch 0.373), train_loss = 2.99883945, grad/param norm = 3.7423e-01, time/batch = 0.6746s	
172/22950 (epoch 0.375), train_loss = 3.35604615, grad/param norm = 4.5999e-01, time/batch = 0.6744s	
173/22950 (epoch 0.377), train_loss = 3.31194600, grad/param norm = 6.7301e-01, time/batch = 0.7087s	
174/22950 (epoch 0.379), train_loss = 3.66643444, grad/param norm = 3.3502e+00, time/batch = 0.6877s	
175/22950 (epoch 0.381), train_loss = 3.05002073, grad/param norm = 1.1513e+00, time/batch = 0.6812s	
176/22950 (epoch 0.383), train_loss = 3.08295261, grad/param norm = 3.8658e-01, time/batch = 0.6746s	
177/22950 (epoch 0.386), train_loss = 3.16760531, grad/param norm = 5.0885e-01, time/batch = 0.6747s	
178/22950 (epoch 0.388), train_loss = 3.19947877, grad/param norm = 4.1704e-01, time/batch = 0.6751s	
179/22950 (epoch 0.390), train_loss = 2.98873588, grad/param norm = 4.3865e-01, time/batch = 0.6764s	
180/22950 (epoch 0.392), train_loss = 3.07970463, grad/param norm = 4.7766e-01, time/batch = 0.6775s	
181/22950 (epoch 0.394), train_loss = 3.11141800, grad/param norm = 3.9570e-01, time/batch = 0.6724s	
182/22950 (epoch 0.397), train_loss = 3.02668082, grad/param norm = 5.7685e-01, time/batch = 0.6711s	
183/22950 (epoch 0.399), train_loss = 3.11283257, grad/param norm = 5.6934e-01, time/batch = 0.6730s	
184/22950 (epoch 0.401), train_loss = 3.17967269, grad/param norm = 8.1242e-01, time/batch = 0.6823s	
185/22950 (epoch 0.403), train_loss = 3.10071656, grad/param norm = 1.1696e+00, time/batch = 0.7105s	
186/22950 (epoch 0.405), train_loss = 2.95978735, grad/param norm = 7.9482e-01, time/batch = 0.6752s	
187/22950 (epoch 0.407), train_loss = 3.16754811, grad/param norm = 5.4193e-01, time/batch = 0.6717s	
188/22950 (epoch 0.410), train_loss = 2.89738189, grad/param norm = 4.4928e-01, time/batch = 0.6699s	
189/22950 (epoch 0.412), train_loss = 3.07701131, grad/param norm = 3.4075e-01, time/batch = 0.6742s	
190/22950 (epoch 0.414), train_loss = 3.05872367, grad/param norm = 4.4323e-01, time/batch = 0.6806s	
191/22950 (epoch 0.416), train_loss = 3.05315892, grad/param norm = 6.3435e-01, time/batch = 0.6858s	
192/22950 (epoch 0.418), train_loss = 3.14257415, grad/param norm = 6.4282e-01, time/batch = 0.6871s	
193/22950 (epoch 0.420), train_loss = 2.99362259, grad/param norm = 3.4154e-01, time/batch = 0.6768s	
194/22950 (epoch 0.423), train_loss = 3.04939229, grad/param norm = 3.0669e-01, time/batch = 0.6761s	
195/22950 (epoch 0.425), train_loss = 3.01521140, grad/param norm = 3.6032e-01, time/batch = 0.6747s	
196/22950 (epoch 0.427), train_loss = 2.91512897, grad/param norm = 6.3100e-01, time/batch = 0.6695s	
197/22950 (epoch 0.429), train_loss = 2.89446766, grad/param norm = 7.2541e-01, time/batch = 0.6742s	
198/22950 (epoch 0.431), train_loss = 2.96554950, grad/param norm = 8.8658e-01, time/batch = 0.6696s	
199/22950 (epoch 0.434), train_loss = 3.01167727, grad/param norm = 1.2743e+00, time/batch = 0.6686s	
200/22950 (epoch 0.436), train_loss = 3.25931507, grad/param norm = 1.2133e+00, time/batch = 0.6715s	
201/22950 (epoch 0.438), train_loss = 2.99933208, grad/param norm = 5.9226e-01, time/batch = 0.6711s	
202/22950 (epoch 0.440), train_loss = 2.95696690, grad/param norm = 4.6038e-01, time/batch = 0.6729s	
203/22950 (epoch 0.442), train_loss = 3.01587508, grad/param norm = 4.2288e-01, time/batch = 0.6717s	
204/22950 (epoch 0.444), train_loss = 3.29903863, grad/param norm = 5.6635e-01, time/batch = 0.6739s	
205/22950 (epoch 0.447), train_loss = 3.08654655, grad/param norm = 6.9590e-01, time/batch = 0.6719s	
206/22950 (epoch 0.449), train_loss = 2.98322165, grad/param norm = 6.2500e-01, time/batch = 0.6755s	
207/22950 (epoch 0.451), train_loss = 3.05694185, grad/param norm = 7.9365e-01, time/batch = 0.6729s	
208/22950 (epoch 0.453), train_loss = 3.13494859, grad/param norm = 9.2247e-01, time/batch = 0.6744s	
209/22950 (epoch 0.455), train_loss = 2.97399934, grad/param norm = 7.2173e-01, time/batch = 0.6771s	
210/22950 (epoch 0.458), train_loss = 2.94238118, grad/param norm = 4.2564e-01, time/batch = 0.6744s	
211/22950 (epoch 0.460), train_loss = 2.96840896, grad/param norm = 4.7557e-01, time/batch = 0.6743s	
212/22950 (epoch 0.462), train_loss = 2.98752452, grad/param norm = 5.4106e-01, time/batch = 0.6703s	
213/22950 (epoch 0.464), train_loss = 3.03011003, grad/param norm = 6.4976e-01, time/batch = 0.6729s	
214/22950 (epoch 0.466), train_loss = 2.88111708, grad/param norm = 9.4217e-01, time/batch = 0.6877s	
215/22950 (epoch 0.468), train_loss = 3.02304027, grad/param norm = 7.5794e-01, time/batch = 0.6827s	
216/22950 (epoch 0.471), train_loss = 2.91305319, grad/param norm = 5.4042e-01, time/batch = 0.6712s	
217/22950 (epoch 0.473), train_loss = 2.85995428, grad/param norm = 7.1869e-01, time/batch = 0.6699s	
218/22950 (epoch 0.475), train_loss = 3.03580021, grad/param norm = 1.0768e+00, time/batch = 0.6708s	
219/22950 (epoch 0.477), train_loss = 2.97515686, grad/param norm = 8.2487e-01, time/batch = 0.6708s	
220/22950 (epoch 0.479), train_loss = 3.02831116, grad/param norm = 6.3240e-01, time/batch = 0.6704s	
221/22950 (epoch 0.481), train_loss = 2.96832744, grad/param norm = 7.0755e-01, time/batch = 0.6739s	
222/22950 (epoch 0.484), train_loss = 3.08715815, grad/param norm = 7.5222e-01, time/batch = 0.6762s	
223/22950 (epoch 0.486), train_loss = 2.84933689, grad/param norm = 7.0259e-01, time/batch = 0.6760s	
224/22950 (epoch 0.488), train_loss = 2.84079283, grad/param norm = 5.0546e-01, time/batch = 0.6724s	
225/22950 (epoch 0.490), train_loss = 2.90641783, grad/param norm = 3.4563e-01, time/batch = 0.6719s	
226/22950 (epoch 0.492), train_loss = 2.95647145, grad/param norm = 2.5872e-01, time/batch = 0.6717s	
227/22950 (epoch 0.495), train_loss = 2.96417961, grad/param norm = 3.9701e-01, time/batch = 0.6749s	
228/22950 (epoch 0.497), train_loss = 2.97696995, grad/param norm = 4.6537e-01, time/batch = 0.6758s	
229/22950 (epoch 0.499), train_loss = 2.97173244, grad/param norm = 8.4329e-01, time/batch = 0.6727s	
230/22950 (epoch 0.501), train_loss = 2.96957684, grad/param norm = 1.0735e+00, time/batch = 0.6741s	
231/22950 (epoch 0.503), train_loss = 2.92960772, grad/param norm = 1.0808e+00, time/batch = 0.6881s	
232/22950 (epoch 0.505), train_loss = 2.85168169, grad/param norm = 6.6731e-01, time/batch = 0.6725s	
233/22950 (epoch 0.508), train_loss = 2.96426300, grad/param norm = 5.3361e-01, time/batch = 0.6755s	
234/22950 (epoch 0.510), train_loss = 2.87272736, grad/param norm = 3.7342e-01, time/batch = 0.6736s	
235/22950 (epoch 0.512), train_loss = 2.78350376, grad/param norm = 4.7835e-01, time/batch = 0.6776s	
236/22950 (epoch 0.514), train_loss = 2.76206617, grad/param norm = 6.3411e-01, time/batch = 0.6755s	
237/22950 (epoch 0.516), train_loss = 2.79278971, grad/param norm = 8.8643e-01, time/batch = 0.6777s	
238/22950 (epoch 0.519), train_loss = 2.88696964, grad/param norm = 8.9586e-01, time/batch = 0.6766s	
239/22950 (epoch 0.521), train_loss = 2.84466168, grad/param norm = 8.2506e-01, time/batch = 0.6747s	
240/22950 (epoch 0.523), train_loss = 2.90969805, grad/param norm = 6.0708e-01, time/batch = 0.6875s	
241/22950 (epoch 0.525), train_loss = 3.01303224, grad/param norm = 4.6002e-01, time/batch = 0.7123s	
242/22950 (epoch 0.527), train_loss = 2.75130964, grad/param norm = 3.9137e-01, time/batch = 0.6769s	
243/22950 (epoch 0.529), train_loss = 2.99271014, grad/param norm = 6.1008e-01, time/batch = 0.6750s	
244/22950 (epoch 0.532), train_loss = 2.94860993, grad/param norm = 7.5240e-01, time/batch = 0.6747s	
245/22950 (epoch 0.534), train_loss = 2.96748319, grad/param norm = 7.6037e-01, time/batch = 0.6755s	
246/22950 (epoch 0.536), train_loss = 2.82818749, grad/param norm = 6.3539e-01, time/batch = 0.6786s	
247/22950 (epoch 0.538), train_loss = 2.89370515, grad/param norm = 7.7498e-01, time/batch = 0.6757s	
248/22950 (epoch 0.540), train_loss = 2.92410053, grad/param norm = 9.8611e-01, time/batch = 0.6756s	
249/22950 (epoch 0.542), train_loss = 2.90638118, grad/param norm = 9.3188e-01, time/batch = 0.6784s	
250/22950 (epoch 0.545), train_loss = 2.83759046, grad/param norm = 8.5066e-01, time/batch = 0.6993s	
251/22950 (epoch 0.547), train_loss = 2.85058163, grad/param norm = 7.0071e-01, time/batch = 0.7086s	
252/22950 (epoch 0.549), train_loss = 2.88013444, grad/param norm = 7.8720e-01, time/batch = 0.7119s	
253/22950 (epoch 0.551), train_loss = 2.79905939, grad/param norm = 8.1214e-01, time/batch = 0.6855s	
254/22950 (epoch 0.553), train_loss = 2.86151330, grad/param norm = 5.7927e-01, time/batch = 0.6853s	
255/22950 (epoch 0.556), train_loss = 2.91547900, grad/param norm = 4.7592e-01, time/batch = 0.6809s	
256/22950 (epoch 0.558), train_loss = 2.79811621, grad/param norm = 3.8971e-01, time/batch = 0.6824s	
257/22950 (epoch 0.560), train_loss = 2.79570263, grad/param norm = 3.1967e-01, time/batch = 0.6762s	
258/22950 (epoch 0.562), train_loss = 2.80419109, grad/param norm = 3.6165e-01, time/batch = 0.6744s	
259/22950 (epoch 0.564), train_loss = 3.00437212, grad/param norm = 5.7918e-01, time/batch = 0.6747s	
260/22950 (epoch 0.566), train_loss = 2.91862794, grad/param norm = 8.5086e-01, time/batch = 0.6724s	
261/22950 (epoch 0.569), train_loss = 2.98458639, grad/param norm = 8.4040e-01, time/batch = 0.6798s	
262/22950 (epoch 0.571), train_loss = 2.73476355, grad/param norm = 5.5610e-01, time/batch = 0.6939s	
263/22950 (epoch 0.573), train_loss = 2.91355208, grad/param norm = 4.3700e-01, time/batch = 0.7262s	
264/22950 (epoch 0.575), train_loss = 3.33829462, grad/param norm = 9.0273e-01, time/batch = 0.7131s	
265/22950 (epoch 0.577), train_loss = 3.10440285, grad/param norm = 1.8803e+00, time/batch = 0.7070s	
266/22950 (epoch 0.580), train_loss = 3.03576027, grad/param norm = 1.1941e+00, time/batch = 0.7018s	
267/22950 (epoch 0.582), train_loss = 2.93890772, grad/param norm = 9.6308e-01, time/batch = 0.6953s	
268/22950 (epoch 0.584), train_loss = 2.93547918, grad/param norm = 4.6053e-01, time/batch = 0.6786s	
269/22950 (epoch 0.586), train_loss = 2.83414508, grad/param norm = 4.8476e-01, time/batch = 0.6749s	
270/22950 (epoch 0.588), train_loss = 2.89928810, grad/param norm = 4.7228e-01, time/batch = 0.6728s	
271/22950 (epoch 0.590), train_loss = 2.78865083, grad/param norm = 5.3142e-01, time/batch = 0.7117s	
272/22950 (epoch 0.593), train_loss = 2.71725883, grad/param norm = 5.2832e-01, time/batch = 0.6757s	
273/22950 (epoch 0.595), train_loss = 2.86034331, grad/param norm = 5.4726e-01, time/batch = 0.6742s	
274/22950 (epoch 0.597), train_loss = 2.85214978, grad/param norm = 4.8793e-01, time/batch = 0.6729s	
275/22950 (epoch 0.599), train_loss = 2.86180573, grad/param norm = 5.1186e-01, time/batch = 0.6755s	
276/22950 (epoch 0.601), train_loss = 2.80184867, grad/param norm = 2.7685e-01, time/batch = 0.6858s	
277/22950 (epoch 0.603), train_loss = 2.88170251, grad/param norm = 3.6226e-01, time/batch = 0.6771s	
278/22950 (epoch 0.606), train_loss = 2.78100122, grad/param norm = 3.6580e-01, time/batch = 0.6751s	
279/22950 (epoch 0.608), train_loss = 2.76436378, grad/param norm = 6.9426e-01, time/batch = 0.6838s	
280/22950 (epoch 0.610), train_loss = 2.86466567, grad/param norm = 1.1861e+00, time/batch = 0.6730s	
281/22950 (epoch 0.612), train_loss = 2.88240229, grad/param norm = 1.3711e+00, time/batch = 0.6736s	
282/22950 (epoch 0.614), train_loss = 2.92893755, grad/param norm = 8.3092e-01, time/batch = 0.6740s	
283/22950 (epoch 0.617), train_loss = 2.80511924, grad/param norm = 3.2150e-01, time/batch = 0.6772s	
284/22950 (epoch 0.619), train_loss = 2.76310970, grad/param norm = 3.6515e-01, time/batch = 0.6777s	
285/22950 (epoch 0.621), train_loss = 2.82472919, grad/param norm = 2.9951e-01, time/batch = 0.6815s	
286/22950 (epoch 0.623), train_loss = 2.77489296, grad/param norm = 3.2170e-01, time/batch = 0.6782s	
287/22950 (epoch 0.625), train_loss = 2.71030031, grad/param norm = 3.1548e-01, time/batch = 0.6738s	
288/22950 (epoch 0.627), train_loss = 2.67190902, grad/param norm = 3.5056e-01, time/batch = 0.6748s	
289/22950 (epoch 0.630), train_loss = 2.78914995, grad/param norm = 6.8605e-01, time/batch = 0.6747s	
290/22950 (epoch 0.632), train_loss = 2.87697833, grad/param norm = 6.5121e-01, time/batch = 0.6738s	
291/22950 (epoch 0.634), train_loss = 2.79489331, grad/param norm = 6.4317e-01, time/batch = 0.6795s	
292/22950 (epoch 0.636), train_loss = 2.74654202, grad/param norm = 7.5081e-01, time/batch = 0.7154s	
293/22950 (epoch 0.638), train_loss = 2.72833697, grad/param norm = 5.5579e-01, time/batch = 0.7064s	
294/22950 (epoch 0.641), train_loss = 2.77496199, grad/param norm = 4.8741e-01, time/batch = 0.7044s	
295/22950 (epoch 0.643), train_loss = 2.69766395, grad/param norm = 3.9510e-01, time/batch = 0.6980s	
296/22950 (epoch 0.645), train_loss = 2.68327446, grad/param norm = 5.0343e-01, time/batch = 0.6903s	
297/22950 (epoch 0.647), train_loss = 2.76807057, grad/param norm = 9.0157e-01, time/batch = 0.6914s	
298/22950 (epoch 0.649), train_loss = 2.88453727, grad/param norm = 9.3201e-01, time/batch = 0.6920s	
299/22950 (epoch 0.651), train_loss = 2.79665224, grad/param norm = 7.3172e-01, time/batch = 0.6893s	
300/22950 (epoch 0.654), train_loss = 2.68802553, grad/param norm = 7.1125e-01, time/batch = 0.6925s	
301/22950 (epoch 0.656), train_loss = 2.93138101, grad/param norm = 6.5982e-01, time/batch = 0.6915s	
302/22950 (epoch 0.658), train_loss = 2.79434429, grad/param norm = 4.8621e-01, time/batch = 0.6970s	
303/22950 (epoch 0.660), train_loss = 2.64142172, grad/param norm = 3.7077e-01, time/batch = 0.6897s	
304/22950 (epoch 0.662), train_loss = 2.74188174, grad/param norm = 3.4620e-01, time/batch = 0.6918s	
305/22950 (epoch 0.664), train_loss = 2.71229165, grad/param norm = 4.6899e-01, time/batch = 0.6926s	
306/22950 (epoch 0.667), train_loss = 2.71965224, grad/param norm = 5.1913e-01, time/batch = 0.6913s	
307/22950 (epoch 0.669), train_loss = 2.61871192, grad/param norm = 6.1092e-01, time/batch = 0.6939s	
308/22950 (epoch 0.671), train_loss = 2.79256291, grad/param norm = 6.4622e-01, time/batch = 0.6929s	
309/22950 (epoch 0.673), train_loss = 2.81474719, grad/param norm = 5.4811e-01, time/batch = 0.6989s	
310/22950 (epoch 0.675), train_loss = 2.78539117, grad/param norm = 4.2948e-01, time/batch = 0.6986s	
311/22950 (epoch 0.678), train_loss = 2.70399162, grad/param norm = 6.0013e-01, time/batch = 0.7098s	
312/22950 (epoch 0.680), train_loss = 2.82060135, grad/param norm = 8.5685e-01, time/batch = 0.7292s	
313/22950 (epoch 0.682), train_loss = 3.11572483, grad/param norm = 7.9912e-01, time/batch = 0.6911s	
314/22950 (epoch 0.684), train_loss = 2.89662666, grad/param norm = 7.4087e-01, time/batch = 0.6941s	
315/22950 (epoch 0.686), train_loss = 2.88874636, grad/param norm = 8.6447e-01, time/batch = 0.6915s	
316/22950 (epoch 0.688), train_loss = 2.79551837, grad/param norm = 5.9302e-01, time/batch = 0.6913s	
317/22950 (epoch 0.691), train_loss = 2.67660576, grad/param norm = 3.5594e-01, time/batch = 0.6922s	
318/22950 (epoch 0.693), train_loss = 2.66741665, grad/param norm = 5.0868e-01, time/batch = 0.7076s	
319/22950 (epoch 0.695), train_loss = 2.88599194, grad/param norm = 6.6803e-01, time/batch = 0.6918s	
320/22950 (epoch 0.697), train_loss = 2.80315200, grad/param norm = 9.4892e-01, time/batch = 0.6929s	
321/22950 (epoch 0.699), train_loss = 2.86656688, grad/param norm = 1.1988e+00, time/batch = 0.7076s	
322/22950 (epoch 0.702), train_loss = 2.68849790, grad/param norm = 8.0909e-01, time/batch = 0.7276s	
323/22950 (epoch 0.704), train_loss = 2.78962903, grad/param norm = 6.0433e-01, time/batch = 0.6934s	
324/22950 (epoch 0.706), train_loss = 2.75282524, grad/param norm = 4.2310e-01, time/batch = 0.6951s	
325/22950 (epoch 0.708), train_loss = 2.82546164, grad/param norm = 6.1877e-01, time/batch = 0.6941s	
326/22950 (epoch 0.710), train_loss = 2.94102853, grad/param norm = 8.1769e-01, time/batch = 0.7003s	
327/22950 (epoch 0.712), train_loss = 2.74593885, grad/param norm = 4.8879e-01, time/batch = 0.7163s	
328/22950 (epoch 0.715), train_loss = 2.71975665, grad/param norm = 3.1788e-01, time/batch = 0.6952s	
329/22950 (epoch 0.717), train_loss = 2.60305215, grad/param norm = 4.3160e-01, time/batch = 0.6923s	
330/22950 (epoch 0.719), train_loss = 2.73175530, grad/param norm = 3.9013e-01, time/batch = 0.6944s	
331/22950 (epoch 0.721), train_loss = 2.64682118, grad/param norm = 3.5304e-01, time/batch = 0.7092s	
332/22950 (epoch 0.723), train_loss = 2.75039129, grad/param norm = 5.9997e-01, time/batch = 0.7255s	
333/22950 (epoch 0.725), train_loss = 2.81451648, grad/param norm = 8.3715e-01, time/batch = 0.6902s	
334/22950 (epoch 0.728), train_loss = 2.72000653, grad/param norm = 1.0565e+00, time/batch = 0.6922s	
335/22950 (epoch 0.730), train_loss = 2.63960969, grad/param norm = 8.2997e-01, time/batch = 0.6905s	
336/22950 (epoch 0.732), train_loss = 2.68489894, grad/param norm = 6.4804e-01, time/batch = 0.6991s	
337/22950 (epoch 0.734), train_loss = 2.65825873, grad/param norm = 5.1860e-01, time/batch = 0.7204s	
338/22950 (epoch 0.736), train_loss = 2.62735855, grad/param norm = 5.0094e-01, time/batch = 0.7270s	
339/22950 (epoch 0.739), train_loss = 2.78783273, grad/param norm = 5.3501e-01, time/batch = 0.7185s	
340/22950 (epoch 0.741), train_loss = 2.70552818, grad/param norm = 5.9009e-01, time/batch = 0.7167s	
341/22950 (epoch 0.743), train_loss = 2.79083993, grad/param norm = 5.8692e-01, time/batch = 0.7491s	
342/22950 (epoch 0.745), train_loss = 2.76882364, grad/param norm = 3.9594e-01, time/batch = 0.7434s	
343/22950 (epoch 0.747), train_loss = 2.63367558, grad/param norm = 4.2928e-01, time/batch = 0.7191s	
344/22950 (epoch 0.749), train_loss = 2.65425736, grad/param norm = 4.4506e-01, time/batch = 0.6952s	
345/22950 (epoch 0.752), train_loss = 2.68708248, grad/param norm = 5.6637e-01, time/batch = 0.6951s	
346/22950 (epoch 0.754), train_loss = 2.70717481, grad/param norm = 7.3105e-01, time/batch = 0.6959s	
347/22950 (epoch 0.756), train_loss = 2.60511617, grad/param norm = 7.0645e-01, time/batch = 0.6962s	
348/22950 (epoch 0.758), train_loss = 2.66507480, grad/param norm = 6.6501e-01, time/batch = 0.6951s	
349/22950 (epoch 0.760), train_loss = 2.69377316, grad/param norm = 7.1139e-01, time/batch = 0.6900s	
350/22950 (epoch 0.763), train_loss = 2.65124446, grad/param norm = 5.0755e-01, time/batch = 0.6918s	
351/22950 (epoch 0.765), train_loss = 2.69572146, grad/param norm = 5.2800e-01, time/batch = 0.7229s	
352/22950 (epoch 0.767), train_loss = 2.61359744, grad/param norm = 6.9134e-01, time/batch = 0.7165s	
353/22950 (epoch 0.769), train_loss = 2.71605675, grad/param norm = 6.4630e-01, time/batch = 0.6896s	
354/22950 (epoch 0.771), train_loss = 2.56131610, grad/param norm = 5.5650e-01, time/batch = 0.6908s	
355/22950 (epoch 0.773), train_loss = 2.57100991, grad/param norm = 4.6115e-01, time/batch = 0.7005s	
356/22950 (epoch 0.776), train_loss = 2.64850457, grad/param norm = 4.6625e-01, time/batch = 0.6918s	
357/22950 (epoch 0.778), train_loss = 2.66907070, grad/param norm = 6.1261e-01, time/batch = 0.6930s	
358/22950 (epoch 0.780), train_loss = 2.53751328, grad/param norm = 8.9236e-01, time/batch = 0.6912s	
359/22950 (epoch 0.782), train_loss = 2.57729205, grad/param norm = 8.7508e-01, time/batch = 0.6998s	
360/22950 (epoch 0.784), train_loss = 2.78580678, grad/param norm = 6.5030e-01, time/batch = 0.6954s	
361/22950 (epoch 0.786), train_loss = 2.66095880, grad/param norm = 4.8895e-01, time/batch = 0.7230s	
362/22950 (epoch 0.789), train_loss = 2.50877937, grad/param norm = 3.6259e-01, time/batch = 0.7159s	
363/22950 (epoch 0.791), train_loss = 2.59479886, grad/param norm = 3.7060e-01, time/batch = 0.6978s	
364/22950 (epoch 0.793), train_loss = 2.80238165, grad/param norm = 3.5209e-01, time/batch = 0.6963s	
365/22950 (epoch 0.795), train_loss = 2.58875841, grad/param norm = 5.0767e-01, time/batch = 0.7032s	
366/22950 (epoch 0.797), train_loss = 2.72404138, grad/param norm = 7.6043e-01, time/batch = 0.7065s	
367/22950 (epoch 0.800), train_loss = 2.58273828, grad/param norm = 7.8349e-01, time/batch = 0.6978s	
368/22950 (epoch 0.802), train_loss = 2.60000123, grad/param norm = 6.7271e-01, time/batch = 0.6933s	
369/22950 (epoch 0.804), train_loss = 2.56420816, grad/param norm = 5.5734e-01, time/batch = 0.6971s	
370/22950 (epoch 0.806), train_loss = 2.52987915, grad/param norm = 5.6820e-01, time/batch = 0.6949s	
371/22950 (epoch 0.808), train_loss = 2.67427687, grad/param norm = 4.2821e-01, time/batch = 0.6941s	
372/22950 (epoch 0.810), train_loss = 2.58394460, grad/param norm = 3.8304e-01, time/batch = 0.6956s	
373/22950 (epoch 0.813), train_loss = 2.48666967, grad/param norm = 4.0589e-01, time/batch = 0.6945s	
374/22950 (epoch 0.815), train_loss = 2.70387307, grad/param norm = 5.5093e-01, time/batch = 0.6939s	
375/22950 (epoch 0.817), train_loss = 2.53245655, grad/param norm = 5.3161e-01, time/batch = 0.6956s	
376/22950 (epoch 0.819), train_loss = 2.67958155, grad/param norm = 4.4355e-01, time/batch = 0.7214s	
377/22950 (epoch 0.821), train_loss = 2.45220310, grad/param norm = 4.3995e-01, time/batch = 0.7032s	
378/22950 (epoch 0.824), train_loss = 2.45295629, grad/param norm = 5.2956e-01, time/batch = 0.6940s	
379/22950 (epoch 0.826), train_loss = 2.64552764, grad/param norm = 7.1553e-01, time/batch = 0.6986s	
380/22950 (epoch 0.828), train_loss = 2.65692339, grad/param norm = 6.7903e-01, time/batch = 0.6965s	
381/22950 (epoch 0.830), train_loss = 2.64838441, grad/param norm = 6.1794e-01, time/batch = 0.7009s	
382/22950 (epoch 0.832), train_loss = 2.64191128, grad/param norm = 5.7706e-01, time/batch = 0.6926s	
383/22950 (epoch 0.834), train_loss = 2.56673889, grad/param norm = 5.1654e-01, time/batch = 0.7127s	
384/22950 (epoch 0.837), train_loss = 2.69417336, grad/param norm = 6.2390e-01, time/batch = 0.7110s	
385/22950 (epoch 0.839), train_loss = 2.78039240, grad/param norm = 4.2838e-01, time/batch = 0.7036s	
386/22950 (epoch 0.841), train_loss = 2.52542698, grad/param norm = 3.0853e-01, time/batch = 0.6917s	
387/22950 (epoch 0.843), train_loss = 2.47813554, grad/param norm = 3.5575e-01, time/batch = 0.6999s	
388/22950 (epoch 0.845), train_loss = 2.78989586, grad/param norm = 6.6758e-01, time/batch = 0.6908s	
389/22950 (epoch 0.847), train_loss = 2.73988044, grad/param norm = 5.6179e-01, time/batch = 0.6894s	
390/22950 (epoch 0.850), train_loss = 2.59663143, grad/param norm = 4.9600e-01, time/batch = 0.6898s	
391/22950 (epoch 0.852), train_loss = 2.53490738, grad/param norm = 3.9835e-01, time/batch = 0.6930s	
392/22950 (epoch 0.854), train_loss = 2.52909652, grad/param norm = 2.5599e-01, time/batch = 0.6908s	
393/22950 (epoch 0.856), train_loss = 2.78924410, grad/param norm = 5.2407e-01, time/batch = 0.6971s	
394/22950 (epoch 0.858), train_loss = 2.62521787, grad/param norm = 8.2682e-01, time/batch = 0.6973s	
395/22950 (epoch 0.861), train_loss = 2.58314304, grad/param norm = 9.4016e-01, time/batch = 0.6988s	
396/22950 (epoch 0.863), train_loss = 2.73136991, grad/param norm = 1.0254e+00, time/batch = 0.6964s	
397/22950 (epoch 0.865), train_loss = 2.73264445, grad/param norm = 6.5733e-01, time/batch = 0.6925s	
398/22950 (epoch 0.867), train_loss = 2.59758809, grad/param norm = 4.4498e-01, time/batch = 0.6907s	
399/22950 (epoch 0.869), train_loss = 2.64499970, grad/param norm = 4.0368e-01, time/batch = 0.6914s	
400/22950 (epoch 0.871), train_loss = 2.50312297, grad/param norm = 3.0426e-01, time/batch = 0.6910s	
401/22950 (epoch 0.874), train_loss = 2.62406683, grad/param norm = 3.8618e-01, time/batch = 0.7012s	
402/22950 (epoch 0.876), train_loss = 2.57277500, grad/param norm = 4.0692e-01, time/batch = 0.6909s	
403/22950 (epoch 0.878), train_loss = 2.50669692, grad/param norm = 3.7870e-01, time/batch = 0.6934s	
404/22950 (epoch 0.880), train_loss = 2.64661483, grad/param norm = 4.2570e-01, time/batch = 0.6959s	
405/22950 (epoch 0.882), train_loss = 2.54706525, grad/param norm = 4.8978e-01, time/batch = 0.7130s	
406/22950 (epoch 0.885), train_loss = 2.61961954, grad/param norm = 6.8591e-01, time/batch = 0.7202s	
407/22950 (epoch 0.887), train_loss = 2.61841946, grad/param norm = 9.7112e-01, time/batch = 0.6964s	
408/22950 (epoch 0.889), train_loss = 2.77003549, grad/param norm = 7.3518e-01, time/batch = 0.6947s	
409/22950 (epoch 0.891), train_loss = 2.68011130, grad/param norm = 7.0832e-01, time/batch = 0.6949s	
410/22950 (epoch 0.893), train_loss = 2.59735077, grad/param norm = 5.3959e-01, time/batch = 0.6898s	
411/22950 (epoch 0.895), train_loss = 2.58105520, grad/param norm = 3.9167e-01, time/batch = 0.6910s	
412/22950 (epoch 0.898), train_loss = 2.59879034, grad/param norm = 4.8307e-01, time/batch = 0.6894s	
413/22950 (epoch 0.900), train_loss = 2.49212333, grad/param norm = 4.8849e-01, time/batch = 0.6910s	
414/22950 (epoch 0.902), train_loss = 2.52888622, grad/param norm = 5.1021e-01, time/batch = 0.6918s	
415/22950 (epoch 0.904), train_loss = 2.50463264, grad/param norm = 4.5097e-01, time/batch = 0.7087s	
416/22950 (epoch 0.906), train_loss = 2.62485172, grad/param norm = 4.6612e-01, time/batch = 0.7147s	
417/22950 (epoch 0.908), train_loss = 2.45992506, grad/param norm = 6.0879e-01, time/batch = 0.6957s	
418/22950 (epoch 0.911), train_loss = 2.48305846, grad/param norm = 5.0063e-01, time/batch = 0.6932s	
419/22950 (epoch 0.913), train_loss = 2.43828002, grad/param norm = 4.9851e-01, time/batch = 0.7017s	
420/22950 (epoch 0.915), train_loss = 2.79285646, grad/param norm = 8.4768e-01, time/batch = 0.6969s	
421/22950 (epoch 0.917), train_loss = 2.60016273, grad/param norm = 7.7361e-01, time/batch = 0.6980s	
422/22950 (epoch 0.919), train_loss = 2.60680545, grad/param norm = 6.0991e-01, time/batch = 0.7159s	
423/22950 (epoch 0.922), train_loss = 2.53937543, grad/param norm = 5.9358e-01, time/batch = 0.7305s	
424/22950 (epoch 0.924), train_loss = 2.61173524, grad/param norm = 5.7540e-01, time/batch = 0.7500s	
425/22950 (epoch 0.926), train_loss = 2.50054609, grad/param norm = 4.3324e-01, time/batch = 0.7227s	
426/22950 (epoch 0.928), train_loss = 2.47044413, grad/param norm = 4.3620e-01, time/batch = 0.7044s	
427/22950 (epoch 0.930), train_loss = 2.49903997, grad/param norm = 4.8674e-01, time/batch = 0.6846s	
428/22950 (epoch 0.932), train_loss = 2.54727890, grad/param norm = 4.8054e-01, time/batch = 0.6850s	
429/22950 (epoch 0.935), train_loss = 2.50234250, grad/param norm = 3.6710e-01, time/batch = 0.6898s	
430/22950 (epoch 0.937), train_loss = 2.55020248, grad/param norm = 3.7704e-01, time/batch = 0.6961s	
431/22950 (epoch 0.939), train_loss = 2.51489469, grad/param norm = 3.9660e-01, time/batch = 0.6736s	
432/22950 (epoch 0.941), train_loss = 2.49952439, grad/param norm = 4.0118e-01, time/batch = 0.6756s	
433/22950 (epoch 0.943), train_loss = 2.50030440, grad/param norm = 4.1399e-01, time/batch = 0.6723s	
434/22950 (epoch 0.946), train_loss = 2.35728663, grad/param norm = 6.1469e-01, time/batch = 0.6687s	
435/22950 (epoch 0.948), train_loss = 2.61073250, grad/param norm = 7.1656e-01, time/batch = 0.6734s	
436/22950 (epoch 0.950), train_loss = 2.61810778, grad/param norm = 6.5543e-01, time/batch = 0.6789s	
437/22950 (epoch 0.952), train_loss = 2.54928688, grad/param norm = 5.4937e-01, time/batch = 0.6727s	
438/22950 (epoch 0.954), train_loss = 2.51545076, grad/param norm = 4.8128e-01, time/batch = 0.6824s	
439/22950 (epoch 0.956), train_loss = 2.43627175, grad/param norm = 3.5120e-01, time/batch = 0.6907s	
440/22950 (epoch 0.959), train_loss = 2.39449617, grad/param norm = 3.0692e-01, time/batch = 0.6861s	
441/22950 (epoch 0.961), train_loss = 2.46335418, grad/param norm = 4.1809e-01, time/batch = 0.6725s	
442/22950 (epoch 0.963), train_loss = 2.60592406, grad/param norm = 4.1423e-01, time/batch = 0.6750s	
443/22950 (epoch 0.965), train_loss = 2.67964601, grad/param norm = 3.4050e-01, time/batch = 0.6754s	
444/22950 (epoch 0.967), train_loss = 2.43708365, grad/param norm = 4.5452e-01, time/batch = 0.6749s	
445/22950 (epoch 0.969), train_loss = 2.45315996, grad/param norm = 3.6351e-01, time/batch = 0.6903s	
446/22950 (epoch 0.972), train_loss = 2.50621803, grad/param norm = 4.7605e-01, time/batch = 0.7125s	
447/22950 (epoch 0.974), train_loss = 2.39099785, grad/param norm = 5.2858e-01, time/batch = 0.6793s	
448/22950 (epoch 0.976), train_loss = 2.36133137, grad/param norm = 5.6169e-01, time/batch = 0.6836s	
449/22950 (epoch 0.978), train_loss = 2.53894440, grad/param norm = 7.5310e-01, time/batch = 0.6759s	
450/22950 (epoch 0.980), train_loss = 2.57615818, grad/param norm = 7.3390e-01, time/batch = 0.6754s	
451/22950 (epoch 0.983), train_loss = 2.48339751, grad/param norm = 5.9527e-01, time/batch = 0.6772s	
452/22950 (epoch 0.985), train_loss = 2.53655114, grad/param norm = 6.7637e-01, time/batch = 0.6767s	
453/22950 (epoch 0.987), train_loss = 2.60293871, grad/param norm = 5.6046e-01, time/batch = 0.6733s	
454/22950 (epoch 0.989), train_loss = 2.61250573, grad/param norm = 4.8350e-01, time/batch = 0.6775s	
455/22950 (epoch 0.991), train_loss = 2.54211234, grad/param norm = 3.1685e-01, time/batch = 0.6913s	
456/22950 (epoch 0.993), train_loss = 2.47004235, grad/param norm = 4.3140e-01, time/batch = 0.7089s	
457/22950 (epoch 0.996), train_loss = 2.60792362, grad/param norm = 4.7543e-01, time/batch = 0.6840s	
458/22950 (epoch 0.998), train_loss = 2.42901790, grad/param norm = 3.3539e-01, time/batch = 0.6710s	
459/22950 (epoch 1.000), train_loss = 2.41049807, grad/param norm = 3.7833e-01, time/batch = 0.6707s	
460/22950 (epoch 1.002), train_loss = 2.69278713, grad/param norm = 5.1674e-01, time/batch = 0.6870s	
461/22950 (epoch 1.004), train_loss = 2.50077457, grad/param norm = 6.1466e-01, time/batch = 0.7005s	
462/22950 (epoch 1.007), train_loss = 2.48525008, grad/param norm = 6.4005e-01, time/batch = 0.6941s	
463/22950 (epoch 1.009), train_loss = 2.71361837, grad/param norm = 8.7451e-01, time/batch = 0.6929s	
464/22950 (epoch 1.011), train_loss = 2.80717444, grad/param norm = 1.0720e+00, time/batch = 0.6857s	
465/22950 (epoch 1.013), train_loss = 2.66598616, grad/param norm = 6.6382e-01, time/batch = 0.6919s	
466/22950 (epoch 1.015), train_loss = 2.65309940, grad/param norm = 5.5928e-01, time/batch = 0.7099s	
467/22950 (epoch 1.017), train_loss = 2.42706419, grad/param norm = 5.9397e-01, time/batch = 0.7064s	
468/22950 (epoch 1.020), train_loss = 2.48367723, grad/param norm = 5.2366e-01, time/batch = 0.6880s	
469/22950 (epoch 1.022), train_loss = 2.34240482, grad/param norm = 4.6857e-01, time/batch = 0.6837s	
470/22950 (epoch 1.024), train_loss = 2.42537231, grad/param norm = 4.9408e-01, time/batch = 0.6866s	
471/22950 (epoch 1.026), train_loss = 2.39862291, grad/param norm = 5.5812e-01, time/batch = 0.6862s	
472/22950 (epoch 1.028), train_loss = 2.52468668, grad/param norm = 5.2259e-01, time/batch = 0.6846s	
473/22950 (epoch 1.031), train_loss = 2.44800939, grad/param norm = 4.0569e-01, time/batch = 0.6889s	
474/22950 (epoch 1.033), train_loss = 2.63269602, grad/param norm = 3.1983e-01, time/batch = 0.6864s	
475/22950 (epoch 1.035), train_loss = 2.63983147, grad/param norm = 3.8907e-01, time/batch = 0.6754s	
476/22950 (epoch 1.037), train_loss = 2.51584665, grad/param norm = 2.8193e-01, time/batch = 0.6781s	
477/22950 (epoch 1.039), train_loss = 2.48288652, grad/param norm = 3.8826e-01, time/batch = 0.6825s	
478/22950 (epoch 1.041), train_loss = 2.62809921, grad/param norm = 5.1226e-01, time/batch = 0.6948s	
479/22950 (epoch 1.044), train_loss = 2.44065038, grad/param norm = 7.2986e-01, time/batch = 0.6881s	
480/22950 (epoch 1.046), train_loss = 2.44309745, grad/param norm = 6.6967e-01, time/batch = 0.6920s	
481/22950 (epoch 1.048), train_loss = 2.51453408, grad/param norm = 4.6300e-01, time/batch = 0.6947s	
482/22950 (epoch 1.050), train_loss = 2.53694087, grad/param norm = 3.6807e-01, time/batch = 0.6921s	
483/22950 (epoch 1.052), train_loss = 2.44843536, grad/param norm = 3.8272e-01, time/batch = 0.6729s	
484/22950 (epoch 1.054), train_loss = 2.53637879, grad/param norm = 3.8583e-01, time/batch = 0.6759s	
485/22950 (epoch 1.057), train_loss = 2.46927967, grad/param norm = 5.0478e-01, time/batch = 0.6705s	
486/22950 (epoch 1.059), train_loss = 2.39433200, grad/param norm = 4.9503e-01, time/batch = 0.6737s	
487/22950 (epoch 1.061), train_loss = 2.40929047, grad/param norm = 3.7547e-01, time/batch = 0.6713s	
488/22950 (epoch 1.063), train_loss = 2.53804186, grad/param norm = 3.5316e-01, time/batch = 0.6933s	
489/22950 (epoch 1.065), train_loss = 2.15950309, grad/param norm = 5.3237e-01, time/batch = 0.6929s	
490/22950 (epoch 1.068), train_loss = 2.67610184, grad/param norm = 5.4991e-01, time/batch = 0.6843s	
491/22950 (epoch 1.070), train_loss = 2.44142326, grad/param norm = 3.8364e-01, time/batch = 0.6738s	
492/22950 (epoch 1.072), train_loss = 2.35774948, grad/param norm = 6.0962e-01, time/batch = 0.6928s	
493/22950 (epoch 1.074), train_loss = 2.47214682, grad/param norm = 8.5270e-01, time/batch = 0.6900s	
494/22950 (epoch 1.076), train_loss = 2.47229292, grad/param norm = 7.5658e-01, time/batch = 0.6930s	
495/22950 (epoch 1.078), train_loss = 2.48881202, grad/param norm = 3.9172e-01, time/batch = 0.6954s	
496/22950 (epoch 1.081), train_loss = 2.50057333, grad/param norm = 3.0049e-01, time/batch = 0.7048s	
497/22950 (epoch 1.083), train_loss = 2.42637950, grad/param norm = 3.9648e-01, time/batch = 0.7073s	
498/22950 (epoch 1.085), train_loss = 2.34233270, grad/param norm = 3.3437e-01, time/batch = 0.6910s	
499/22950 (epoch 1.087), train_loss = 2.37649940, grad/param norm = 2.8245e-01, time/batch = 0.6795s	
500/22950 (epoch 1.089), train_loss = 2.44002951, grad/param norm = 3.3107e-01, time/batch = 0.6717s	
501/22950 (epoch 1.092), train_loss = 2.41726425, grad/param norm = 4.5001e-01, time/batch = 0.6752s	
502/22950 (epoch 1.094), train_loss = 2.45906189, grad/param norm = 4.7556e-01, time/batch = 0.6733s	
503/22950 (epoch 1.096), train_loss = 2.60396498, grad/param norm = 4.9182e-01, time/batch = 0.6714s	
504/22950 (epoch 1.098), train_loss = 2.49818154, grad/param norm = 4.6658e-01, time/batch = 0.6711s	
505/22950 (epoch 1.100), train_loss = 2.52142942, grad/param norm = 3.2416e-01, time/batch = 0.6723s	
506/22950 (epoch 1.102), train_loss = 2.38904459, grad/param norm = 4.2992e-01, time/batch = 0.6731s	
507/22950 (epoch 1.105), train_loss = 2.38282051, grad/param norm = 5.5391e-01, time/batch = 0.6733s	
508/22950 (epoch 1.107), train_loss = 2.50259499, grad/param norm = 5.3840e-01, time/batch = 0.6808s	
509/22950 (epoch 1.109), train_loss = 2.48631072, grad/param norm = 5.5549e-01, time/batch = 0.6976s	
510/22950 (epoch 1.111), train_loss = 2.33685231, grad/param norm = 5.2984e-01, time/batch = 0.7055s	
511/22950 (epoch 1.113), train_loss = 2.43912409, grad/param norm = 3.5941e-01, time/batch = 0.7002s	
512/22950 (epoch 1.115), train_loss = 2.43703949, grad/param norm = 4.9196e-01, time/batch = 0.6850s	
513/22950 (epoch 1.118), train_loss = 2.48117540, grad/param norm = 4.9095e-01, time/batch = 0.6799s	
514/22950 (epoch 1.120), train_loss = 2.34123237, grad/param norm = 3.6906e-01, time/batch = 0.6815s	
515/22950 (epoch 1.122), train_loss = 2.41913657, grad/param norm = 3.6592e-01, time/batch = 0.6782s	
516/22950 (epoch 1.124), train_loss = 2.26279414, grad/param norm = 3.8234e-01, time/batch = 0.6797s	
517/22950 (epoch 1.126), train_loss = 2.28245545, grad/param norm = 3.4081e-01, time/batch = 0.6739s	
518/22950 (epoch 1.129), train_loss = 2.23548686, grad/param norm = 6.1433e-01, time/batch = 0.6819s	
519/22950 (epoch 1.131), train_loss = 2.52536956, grad/param norm = 1.1296e+00, time/batch = 0.6808s	
520/22950 (epoch 1.133), train_loss = 2.63517724, grad/param norm = 7.4872e-01, time/batch = 0.6771s	
521/22950 (epoch 1.135), train_loss = 2.41651211, grad/param norm = 3.7496e-01, time/batch = 0.6768s	
522/22950 (epoch 1.137), train_loss = 2.51644206, grad/param norm = 3.5049e-01, time/batch = 0.6758s	
523/22950 (epoch 1.139), train_loss = 2.29224058, grad/param norm = 4.4397e-01, time/batch = 0.6754s	
524/22950 (epoch 1.142), train_loss = 2.31969640, grad/param norm = 5.8624e-01, time/batch = 0.6945s	
525/22950 (epoch 1.144), train_loss = 2.33983139, grad/param norm = 4.4341e-01, time/batch = 0.6969s	
526/22950 (epoch 1.146), train_loss = 2.48643813, grad/param norm = 3.6816e-01, time/batch = 0.6999s	
527/22950 (epoch 1.148), train_loss = 2.25704565, grad/param norm = 3.3460e-01, time/batch = 0.7098s	
528/22950 (epoch 1.150), train_loss = 2.44129715, grad/param norm = 3.2323e-01, time/batch = 0.6860s	
529/22950 (epoch 1.153), train_loss = 2.34305376, grad/param norm = 4.1241e-01, time/batch = 0.6733s	
530/22950 (epoch 1.155), train_loss = 2.39016791, grad/param norm = 5.4319e-01, time/batch = 0.6756s	
531/22950 (epoch 1.157), train_loss = 2.39249876, grad/param norm = 6.0272e-01, time/batch = 0.6739s	
532/22950 (epoch 1.159), train_loss = 2.37604822, grad/param norm = 6.7504e-01, time/batch = 0.6705s	
533/22950 (epoch 1.161), train_loss = 2.56836329, grad/param norm = 5.4600e-01, time/batch = 0.6726s	
534/22950 (epoch 1.163), train_loss = 2.56152378, grad/param norm = 3.1972e-01, time/batch = 0.6724s	
535/22950 (epoch 1.166), train_loss = 2.51818161, grad/param norm = 3.1590e-01, time/batch = 0.6835s	
536/22950 (epoch 1.168), train_loss = 2.47521292, grad/param norm = 4.1023e-01, time/batch = 0.6875s	
537/22950 (epoch 1.170), train_loss = 2.43494745, grad/param norm = 3.5029e-01, time/batch = 0.7058s	
538/22950 (epoch 1.172), train_loss = 2.43299050, grad/param norm = 4.6102e-01, time/batch = 0.6974s	
539/22950 (epoch 1.174), train_loss = 2.46716638, grad/param norm = 4.9397e-01, time/batch = 0.6776s	
540/22950 (epoch 1.176), train_loss = 2.45483059, grad/param norm = 3.2274e-01, time/batch = 0.6738s	
541/22950 (epoch 1.179), train_loss = 2.47012413, grad/param norm = 3.7204e-01, time/batch = 0.6718s	
542/22950 (epoch 1.181), train_loss = 2.47480185, grad/param norm = 4.0788e-01, time/batch = 0.6783s	
543/22950 (epoch 1.183), train_loss = 2.38501568, grad/param norm = 4.2539e-01, time/batch = 0.6777s	
544/22950 (epoch 1.185), train_loss = 2.47397883, grad/param norm = 4.9566e-01, time/batch = 0.6768s	
545/22950 (epoch 1.187), train_loss = 2.40903654, grad/param norm = 4.9200e-01, time/batch = 0.6740s	
546/22950 (epoch 1.190), train_loss = 2.51617269, grad/param norm = 4.0570e-01, time/batch = 0.6742s	
547/22950 (epoch 1.192), train_loss = 2.33968942, grad/param norm = 2.7139e-01, time/batch = 0.6716s	
548/22950 (epoch 1.194), train_loss = 2.31279128, grad/param norm = 3.8024e-01, time/batch = 0.6788s	
549/22950 (epoch 1.196), train_loss = 2.18991174, grad/param norm = 6.2104e-01, time/batch = 0.6753s	
550/22950 (epoch 1.198), train_loss = 2.59791820, grad/param norm = 8.0019e-01, time/batch = 0.6741s	
551/22950 (epoch 1.200), train_loss = 2.37516676, grad/param norm = 6.2262e-01, time/batch = 0.6790s	
552/22950 (epoch 1.203), train_loss = 2.27321290, grad/param norm = 3.7062e-01, time/batch = 0.6771s	
553/22950 (epoch 1.205), train_loss = 2.36050880, grad/param norm = 5.0461e-01, time/batch = 0.6812s	
554/22950 (epoch 1.207), train_loss = 2.43095653, grad/param norm = 4.4562e-01, time/batch = 0.6806s	
555/22950 (epoch 1.209), train_loss = 2.64856643, grad/param norm = 3.5292e-01, time/batch = 0.6764s	
556/22950 (epoch 1.211), train_loss = 2.38155462, grad/param norm = 4.0412e-01, time/batch = 0.6717s	
557/22950 (epoch 1.214), train_loss = 2.26754775, grad/param norm = 3.2578e-01, time/batch = 0.6727s	
558/22950 (epoch 1.216), train_loss = 2.40552181, grad/param norm = 3.5579e-01, time/batch = 0.6737s	
559/22950 (epoch 1.218), train_loss = 2.40597344, grad/param norm = 2.6580e-01, time/batch = 0.6738s	
560/22950 (epoch 1.220), train_loss = 2.44504559, grad/param norm = 3.1358e-01, time/batch = 0.6751s	
561/22950 (epoch 1.222), train_loss = 2.39291003, grad/param norm = 2.7569e-01, time/batch = 0.6751s	
562/22950 (epoch 1.224), train_loss = 2.25441149, grad/param norm = 3.1387e-01, time/batch = 0.6929s	
563/22950 (epoch 1.227), train_loss = 2.25235622, grad/param norm = 3.2614e-01, time/batch = 0.6853s	
564/22950 (epoch 1.229), train_loss = 2.36813878, grad/param norm = 4.6279e-01, time/batch = 0.6700s	
565/22950 (epoch 1.231), train_loss = 2.25974397, grad/param norm = 4.5256e-01, time/batch = 0.6702s	
566/22950 (epoch 1.233), train_loss = 2.39536873, grad/param norm = 4.5293e-01, time/batch = 0.6739s	
567/22950 (epoch 1.235), train_loss = 2.47780442, grad/param norm = 5.9447e-01, time/batch = 0.6709s	
568/22950 (epoch 1.237), train_loss = 2.20701840, grad/param norm = 6.0076e-01, time/batch = 0.6745s	
569/22950 (epoch 1.240), train_loss = 2.18816499, grad/param norm = 3.6832e-01, time/batch = 0.6768s	
570/22950 (epoch 1.242), train_loss = 2.27846652, grad/param norm = 3.4087e-01, time/batch = 0.6773s	
571/22950 (epoch 1.244), train_loss = 2.43976452, grad/param norm = 3.4013e-01, time/batch = 0.6731s	
572/22950 (epoch 1.246), train_loss = 2.38482300, grad/param norm = 4.7515e-01, time/batch = 0.6938s	
573/22950 (epoch 1.248), train_loss = 2.37344913, grad/param norm = 4.7964e-01, time/batch = 0.7050s	
574/22950 (epoch 1.251), train_loss = 2.36611237, grad/param norm = 4.4809e-01, time/batch = 0.6732s	
575/22950 (epoch 1.253), train_loss = 2.46363323, grad/param norm = 4.6200e-01, time/batch = 0.6711s	
576/22950 (epoch 1.255), train_loss = 2.26115687, grad/param norm = 4.1645e-01, time/batch = 0.6715s	
577/22950 (epoch 1.257), train_loss = 2.38208378, grad/param norm = 3.0021e-01, time/batch = 0.6722s	
578/22950 (epoch 1.259), train_loss = 2.17311309, grad/param norm = 2.9289e-01, time/batch = 0.6779s	
579/22950 (epoch 1.261), train_loss = 2.60182685, grad/param norm = 4.1881e-01, time/batch = 0.6758s	
580/22950 (epoch 1.264), train_loss = 2.45957629, grad/param norm = 5.8207e-01, time/batch = 0.6719s	
581/22950 (epoch 1.266), train_loss = 2.53744344, grad/param norm = 5.2351e-01, time/batch = 0.6763s	
582/22950 (epoch 1.268), train_loss = 2.52418813, grad/param norm = 3.0778e-01, time/batch = 0.6862s	
583/22950 (epoch 1.270), train_loss = 2.40928131, grad/param norm = 3.2546e-01, time/batch = 0.7093s	
584/22950 (epoch 1.272), train_loss = 2.56918855, grad/param norm = 3.3110e-01, time/batch = 0.6747s	
585/22950 (epoch 1.275), train_loss = 2.31617941, grad/param norm = 4.8744e-01, time/batch = 0.6875s	
586/22950 (epoch 1.277), train_loss = 2.37745322, grad/param norm = 5.0887e-01, time/batch = 0.7023s	
587/22950 (epoch 1.279), train_loss = 2.44124745, grad/param norm = 6.1977e-01, time/batch = 0.7057s	
588/22950 (epoch 1.281), train_loss = 2.42202990, grad/param norm = 6.4139e-01, time/batch = 0.7066s	
589/22950 (epoch 1.283), train_loss = 2.35790437, grad/param norm = 5.7896e-01, time/batch = 0.7082s	
590/22950 (epoch 1.285), train_loss = 2.35573883, grad/param norm = 5.1573e-01, time/batch = 0.7059s	
591/22950 (epoch 1.288), train_loss = 2.27051164, grad/param norm = 4.6759e-01, time/batch = 0.7023s	
592/22950 (epoch 1.290), train_loss = 2.28888452, grad/param norm = 3.0522e-01, time/batch = 0.6799s	
593/22950 (epoch 1.292), train_loss = 2.31255595, grad/param norm = 3.5281e-01, time/batch = 0.6787s	
594/22950 (epoch 1.294), train_loss = 2.38089579, grad/param norm = 3.9372e-01, time/batch = 0.6699s	
595/22950 (epoch 1.296), train_loss = 2.19717161, grad/param norm = 3.5728e-01, time/batch = 0.6765s	
596/22950 (epoch 1.298), train_loss = 2.40295259, grad/param norm = 3.9145e-01, time/batch = 0.6815s	
597/22950 (epoch 1.301), train_loss = 2.37465556, grad/param norm = 2.9316e-01, time/batch = 0.6976s	
598/22950 (epoch 1.303), train_loss = 2.41723795, grad/param norm = 2.7388e-01, time/batch = 0.7113s	
599/22950 (epoch 1.305), train_loss = 2.53565965, grad/param norm = 2.9212e-01, time/batch = 0.6807s	
600/22950 (epoch 1.307), train_loss = 2.50101171, grad/param norm = 4.7759e-01, time/batch = 0.6975s	
601/22950 (epoch 1.309), train_loss = 2.55784415, grad/param norm = 4.5624e-01, time/batch = 0.6924s	
602/22950 (epoch 1.312), train_loss = 2.45165697, grad/param norm = 3.3767e-01, time/batch = 0.6795s	
603/22950 (epoch 1.314), train_loss = 2.23306376, grad/param norm = 4.1958e-01, time/batch = 0.6823s	
604/22950 (epoch 1.316), train_loss = 2.34512258, grad/param norm = 4.2755e-01, time/batch = 0.6726s	
605/22950 (epoch 1.318), train_loss = 2.23945799, grad/param norm = 3.7883e-01, time/batch = 0.6713s	
606/22950 (epoch 1.320), train_loss = 2.31096082, grad/param norm = 3.4998e-01, time/batch = 0.6786s	
607/22950 (epoch 1.322), train_loss = 2.35595946, grad/param norm = 3.5102e-01, time/batch = 0.6783s	
608/22950 (epoch 1.325), train_loss = 2.18618270, grad/param norm = 3.5534e-01, time/batch = 0.6692s	
609/22950 (epoch 1.327), train_loss = 2.13769475, grad/param norm = 4.6424e-01, time/batch = 0.6732s	
610/22950 (epoch 1.329), train_loss = 2.23971010, grad/param norm = 4.6479e-01, time/batch = 0.6758s	
611/22950 (epoch 1.331), train_loss = 2.24426917, grad/param norm = 5.4269e-01, time/batch = 0.6751s	
612/22950 (epoch 1.333), train_loss = 2.24702554, grad/param norm = 4.0928e-01, time/batch = 0.6790s	
613/22950 (epoch 1.336), train_loss = 2.33078662, grad/param norm = 3.1525e-01, time/batch = 0.6978s	
614/22950 (epoch 1.338), train_loss = 2.27306172, grad/param norm = 4.7610e-01, time/batch = 0.6886s	
615/22950 (epoch 1.340), train_loss = 2.27427540, grad/param norm = 6.7241e-01, time/batch = 0.6762s	
616/22950 (epoch 1.342), train_loss = 2.33302359, grad/param norm = 5.4722e-01, time/batch = 0.6749s	
617/22950 (epoch 1.344), train_loss = 2.30324714, grad/param norm = 3.6583e-01, time/batch = 0.6753s	
618/22950 (epoch 1.346), train_loss = 2.40056699, grad/param norm = 3.5775e-01, time/batch = 0.6763s	
619/22950 (epoch 1.349), train_loss = 2.43661821, grad/param norm = 5.2063e-01, time/batch = 0.6751s	
620/22950 (epoch 1.351), train_loss = 2.36209494, grad/param norm = 4.6271e-01, time/batch = 0.6724s	
621/22950 (epoch 1.353), train_loss = 2.39231373, grad/param norm = 3.4839e-01, time/batch = 0.6765s	
622/22950 (epoch 1.355), train_loss = 2.52181110, grad/param norm = 3.7890e-01, time/batch = 0.6728s	
623/22950 (epoch 1.357), train_loss = 2.43412636, grad/param norm = 2.8683e-01, time/batch = 0.6976s	
624/22950 (epoch 1.359), train_loss = 2.49994401, grad/param norm = 2.9731e-01, time/batch = 0.7056s	
625/22950 (epoch 1.362), train_loss = 2.32533215, grad/param norm = 3.0009e-01, time/batch = 0.6775s	
626/22950 (epoch 1.364), train_loss = 2.37098845, grad/param norm = 2.6405e-01, time/batch = 0.6782s	
627/22950 (epoch 1.366), train_loss = 2.04856987, grad/param norm = 2.8774e-01, time/batch = 0.6770s	
628/22950 (epoch 1.368), train_loss = 2.23968496, grad/param norm = 3.0555e-01, time/batch = 0.6730s	
629/22950 (epoch 1.370), train_loss = 2.25670832, grad/param norm = 2.9349e-01, time/batch = 0.6751s	
630/22950 (epoch 1.373), train_loss = 2.13598872, grad/param norm = 2.7085e-01, time/batch = 0.6782s	
631/22950 (epoch 1.375), train_loss = 2.50026559, grad/param norm = 3.6037e-01, time/batch = 0.6773s	
632/22950 (epoch 1.377), train_loss = 2.39885290, grad/param norm = 5.2373e-01, time/batch = 0.6763s	
633/22950 (epoch 1.379), train_loss = 2.52005031, grad/param norm = 4.4507e-01, time/batch = 0.6745s	
634/22950 (epoch 1.381), train_loss = 2.11797171, grad/param norm = 3.8101e-01, time/batch = 0.6722s	
635/22950 (epoch 1.383), train_loss = 2.33195805, grad/param norm = 3.6651e-01, time/batch = 0.6717s	
636/22950 (epoch 1.386), train_loss = 2.38282558, grad/param norm = 3.4307e-01, time/batch = 0.6755s	
637/22950 (epoch 1.388), train_loss = 2.37998661, grad/param norm = 3.6495e-01, time/batch = 0.6809s	
638/22950 (epoch 1.390), train_loss = 2.19313840, grad/param norm = 4.4559e-01, time/batch = 0.6707s	
639/22950 (epoch 1.392), train_loss = 2.22476425, grad/param norm = 4.7063e-01, time/batch = 0.6724s	
640/22950 (epoch 1.394), train_loss = 2.23140119, grad/param norm = 4.4053e-01, time/batch = 0.6745s	
641/22950 (epoch 1.397), train_loss = 2.34641616, grad/param norm = 4.4745e-01, time/batch = 0.6756s	
642/22950 (epoch 1.399), train_loss = 2.35335306, grad/param norm = 3.5911e-01, time/batch = 0.6859s	
643/22950 (epoch 1.401), train_loss = 2.51767927, grad/param norm = 3.7135e-01, time/batch = 0.6918s	
644/22950 (epoch 1.403), train_loss = 2.33699252, grad/param norm = 4.2129e-01, time/batch = 0.6848s	
645/22950 (epoch 1.405), train_loss = 2.21327117, grad/param norm = 3.4381e-01, time/batch = 0.6850s	
646/22950 (epoch 1.407), train_loss = 2.41018228, grad/param norm = 4.5564e-01, time/batch = 0.6870s	
647/22950 (epoch 1.410), train_loss = 2.15631856, grad/param norm = 4.5874e-01, time/batch = 0.6738s	
648/22950 (epoch 1.412), train_loss = 2.37005262, grad/param norm = 4.2136e-01, time/batch = 0.6769s	
649/22950 (epoch 1.414), train_loss = 2.30367183, grad/param norm = 3.7797e-01, time/batch = 0.6756s	
650/22950 (epoch 1.416), train_loss = 2.35687034, grad/param norm = 4.2800e-01, time/batch = 0.6731s	
651/22950 (epoch 1.418), train_loss = 2.39568242, grad/param norm = 4.9826e-01, time/batch = 0.6749s	
652/22950 (epoch 1.420), train_loss = 2.31709278, grad/param norm = 3.6347e-01, time/batch = 0.6743s	
653/22950 (epoch 1.423), train_loss = 2.27145050, grad/param norm = 3.8284e-01, time/batch = 0.6752s	
654/22950 (epoch 1.425), train_loss = 2.32829808, grad/param norm = 4.7575e-01, time/batch = 0.6789s	
655/22950 (epoch 1.427), train_loss = 2.29230910, grad/param norm = 6.6642e-01, time/batch = 0.6739s	
656/22950 (epoch 1.429), train_loss = 2.18593023, grad/param norm = 5.3211e-01, time/batch = 0.6769s	
657/22950 (epoch 1.431), train_loss = 2.33228376, grad/param norm = 5.7689e-01, time/batch = 0.6761s	
658/22950 (epoch 1.434), train_loss = 2.25807941, grad/param norm = 4.8312e-01, time/batch = 0.6744s	
659/22950 (epoch 1.436), train_loss = 2.46803579, grad/param norm = 3.4680e-01, time/batch = 0.6716s	
660/22950 (epoch 1.438), train_loss = 2.37437926, grad/param norm = 3.3820e-01, time/batch = 0.6706s	
661/22950 (epoch 1.440), train_loss = 2.27032044, grad/param norm = 2.9345e-01, time/batch = 0.6748s	
662/22950 (epoch 1.442), train_loss = 2.42826055, grad/param norm = 2.7351e-01, time/batch = 0.6726s	
663/22950 (epoch 1.444), train_loss = 2.51199809, grad/param norm = 3.4610e-01, time/batch = 0.6710s	
664/22950 (epoch 1.447), train_loss = 2.41150645, grad/param norm = 4.3360e-01, time/batch = 0.6715s	
665/22950 (epoch 1.449), train_loss = 2.21364365, grad/param norm = 3.7750e-01, time/batch = 0.6745s	
666/22950 (epoch 1.451), train_loss = 2.34294322, grad/param norm = 3.7252e-01, time/batch = 0.6735s	
667/22950 (epoch 1.453), train_loss = 2.39124597, grad/param norm = 3.6237e-01, time/batch = 0.6684s	
668/22950 (epoch 1.455), train_loss = 2.22313511, grad/param norm = 2.8478e-01, time/batch = 0.6686s	
669/22950 (epoch 1.458), train_loss = 2.42302949, grad/param norm = 3.1079e-01, time/batch = 0.6735s	
670/22950 (epoch 1.460), train_loss = 2.33367462, grad/param norm = 3.4322e-01, time/batch = 0.6775s	
671/22950 (epoch 1.462), train_loss = 2.25929497, grad/param norm = 3.8125e-01, time/batch = 0.6844s	
672/22950 (epoch 1.464), train_loss = 2.34331060, grad/param norm = 4.0057e-01, time/batch = 0.6738s	
673/22950 (epoch 1.466), train_loss = 2.25133295, grad/param norm = 3.6312e-01, time/batch = 0.6710s	
674/22950 (epoch 1.468), train_loss = 2.38791767, grad/param norm = 3.2427e-01, time/batch = 0.6726s	
675/22950 (epoch 1.471), train_loss = 2.18983130, grad/param norm = 4.0675e-01, time/batch = 0.6717s	
676/22950 (epoch 1.473), train_loss = 2.23759205, grad/param norm = 4.9262e-01, time/batch = 0.6700s	
677/22950 (epoch 1.475), train_loss = 2.47785952, grad/param norm = 5.3319e-01, time/batch = 0.6732s	
678/22950 (epoch 1.477), train_loss = 2.35229359, grad/param norm = 4.3385e-01, time/batch = 0.6703s	
679/22950 (epoch 1.479), train_loss = 2.33452995, grad/param norm = 3.2763e-01, time/batch = 0.6931s	
680/22950 (epoch 1.481), train_loss = 2.38189060, grad/param norm = 3.0839e-01, time/batch = 0.7030s	
681/22950 (epoch 1.484), train_loss = 2.54512981, grad/param norm = 3.6689e-01, time/batch = 0.6739s	
682/22950 (epoch 1.486), train_loss = 2.19405470, grad/param norm = 4.3922e-01, time/batch = 0.6721s	
683/22950 (epoch 1.488), train_loss = 2.23397641, grad/param norm = 4.2815e-01, time/batch = 0.6731s	
684/22950 (epoch 1.490), train_loss = 2.31046457, grad/param norm = 4.0027e-01, time/batch = 0.6895s	
685/22950 (epoch 1.492), train_loss = 2.32156074, grad/param norm = 2.7765e-01, time/batch = 0.7071s	
686/22950 (epoch 1.495), train_loss = 2.35130569, grad/param norm = 3.5474e-01, time/batch = 0.7043s	
687/22950 (epoch 1.497), train_loss = 2.37617093, grad/param norm = 4.0150e-01, time/batch = 0.7097s	
688/22950 (epoch 1.499), train_loss = 2.32498227, grad/param norm = 4.6327e-01, time/batch = 0.6943s	
689/22950 (epoch 1.501), train_loss = 2.35659495, grad/param norm = 3.7700e-01, time/batch = 0.7071s	
690/22950 (epoch 1.503), train_loss = 2.28293855, grad/param norm = 3.6992e-01, time/batch = 0.7094s	
691/22950 (epoch 1.505), train_loss = 2.18442027, grad/param norm = 3.0145e-01, time/batch = 0.7020s	
692/22950 (epoch 1.508), train_loss = 2.31305814, grad/param norm = 2.8728e-01, time/batch = 0.6921s	
693/22950 (epoch 1.510), train_loss = 2.23365856, grad/param norm = 3.0485e-01, time/batch = 0.6879s	
694/22950 (epoch 1.512), train_loss = 2.28272097, grad/param norm = 3.8504e-01, time/batch = 0.6954s	
695/22950 (epoch 1.514), train_loss = 2.08827744, grad/param norm = 5.9458e-01, time/batch = 0.6968s	
696/22950 (epoch 1.516), train_loss = 2.21407951, grad/param norm = 5.7566e-01, time/batch = 0.6956s	
697/22950 (epoch 1.519), train_loss = 2.22010163, grad/param norm = 4.1970e-01, time/batch = 0.6880s	
698/22950 (epoch 1.521), train_loss = 2.20696263, grad/param norm = 3.9970e-01, time/batch = 0.6942s	
699/22950 (epoch 1.523), train_loss = 2.14001805, grad/param norm = 3.0496e-01, time/batch = 0.7000s	
700/22950 (epoch 1.525), train_loss = 2.26828330, grad/param norm = 2.8872e-01, time/batch = 0.7095s	
701/22950 (epoch 1.527), train_loss = 2.11426438, grad/param norm = 2.8157e-01, time/batch = 0.6929s	
702/22950 (epoch 1.529), train_loss = 2.32103070, grad/param norm = 2.9742e-01, time/batch = 0.6921s	
703/22950 (epoch 1.532), train_loss = 2.25580849, grad/param norm = 2.7650e-01, time/batch = 0.6943s	
704/22950 (epoch 1.534), train_loss = 2.31727906, grad/param norm = 3.4578e-01, time/batch = 0.6986s	
705/22950 (epoch 1.536), train_loss = 2.26290253, grad/param norm = 3.6895e-01, time/batch = 0.6841s	
706/22950 (epoch 1.538), train_loss = 2.26120752, grad/param norm = 4.3600e-01, time/batch = 0.6733s	
707/22950 (epoch 1.540), train_loss = 2.22798243, grad/param norm = 4.0768e-01, time/batch = 0.6729s	
708/22950 (epoch 1.542), train_loss = 2.33013074, grad/param norm = 3.5003e-01, time/batch = 0.6719s	
709/22950 (epoch 1.545), train_loss = 2.20748122, grad/param norm = 2.9867e-01, time/batch = 0.6740s	
710/22950 (epoch 1.547), train_loss = 2.21985519, grad/param norm = 2.7864e-01, time/batch = 0.6708s	
711/22950 (epoch 1.549), train_loss = 2.18512490, grad/param norm = 2.6780e-01, time/batch = 0.6749s	
712/22950 (epoch 1.551), train_loss = 2.28711736, grad/param norm = 4.0865e-01, time/batch = 0.6724s	
713/22950 (epoch 1.553), train_loss = 2.22107653, grad/param norm = 4.2778e-01, time/batch = 0.6783s	
714/22950 (epoch 1.556), train_loss = 2.28899169, grad/param norm = 2.8575e-01, time/batch = 0.6746s	
715/22950 (epoch 1.558), train_loss = 2.25316246, grad/param norm = 3.0282e-01, time/batch = 0.7013s	
716/22950 (epoch 1.560), train_loss = 2.21818053, grad/param norm = 3.4466e-01, time/batch = 0.6743s	
717/22950 (epoch 1.562), train_loss = 2.17283261, grad/param norm = 3.4871e-01, time/batch = 0.6919s	
718/22950 (epoch 1.564), train_loss = 2.46712085, grad/param norm = 4.7111e-01, time/batch = 0.6880s	
719/22950 (epoch 1.566), train_loss = 2.30335703, grad/param norm = 5.5184e-01, time/batch = 0.6850s	
720/22950 (epoch 1.569), train_loss = 2.49451915, grad/param norm = 4.8014e-01, time/batch = 0.7147s	
721/22950 (epoch 1.571), train_loss = 2.09076686, grad/param norm = 2.6957e-01, time/batch = 0.6811s	
722/22950 (epoch 1.573), train_loss = 2.25190993, grad/param norm = 3.0961e-01, time/batch = 0.6708s	
723/22950 (epoch 1.575), train_loss = 2.65491361, grad/param norm = 4.3687e-01, time/batch = 0.6721s	
724/22950 (epoch 1.577), train_loss = 2.33165384, grad/param norm = 5.0727e-01, time/batch = 0.6734s	
725/22950 (epoch 1.580), train_loss = 2.38799811, grad/param norm = 4.7031e-01, time/batch = 0.6722s	
726/22950 (epoch 1.582), train_loss = 2.38682513, grad/param norm = 3.3335e-01, time/batch = 0.6840s	
727/22950 (epoch 1.584), train_loss = 2.08605696, grad/param norm = 3.4559e-01, time/batch = 0.6831s	
728/22950 (epoch 1.586), train_loss = 2.25316229, grad/param norm = 4.1097e-01, time/batch = 0.6805s	
729/22950 (epoch 1.588), train_loss = 2.36794182, grad/param norm = 3.7590e-01, time/batch = 0.6790s	
730/22950 (epoch 1.590), train_loss = 2.17728770, grad/param norm = 3.4341e-01, time/batch = 0.6792s	
731/22950 (epoch 1.593), train_loss = 2.06296273, grad/param norm = 3.0523e-01, time/batch = 0.6808s	
732/22950 (epoch 1.595), train_loss = 2.19594521, grad/param norm = 3.4225e-01, time/batch = 0.6765s	
733/22950 (epoch 1.597), train_loss = 2.26202121, grad/param norm = 4.5454e-01, time/batch = 0.6797s	
734/22950 (epoch 1.599), train_loss = 2.31823006, grad/param norm = 4.0764e-01, time/batch = 0.6750s	
735/22950 (epoch 1.601), train_loss = 2.23596064, grad/param norm = 3.1632e-01, time/batch = 0.6750s	
736/22950 (epoch 1.603), train_loss = 2.34205240, grad/param norm = 2.8540e-01, time/batch = 0.6842s	
737/22950 (epoch 1.606), train_loss = 2.21739141, grad/param norm = 3.0482e-01, time/batch = 0.6732s	
738/22950 (epoch 1.608), train_loss = 2.16655647, grad/param norm = 3.5478e-01, time/batch = 0.6753s	
739/22950 (epoch 1.610), train_loss = 2.20144907, grad/param norm = 4.0429e-01, time/batch = 0.6727s	
740/22950 (epoch 1.612), train_loss = 2.32096272, grad/param norm = 4.3392e-01, time/batch = 0.7004s	
741/22950 (epoch 1.614), train_loss = 2.34867590, grad/param norm = 4.2193e-01, time/batch = 0.7008s	
742/22950 (epoch 1.617), train_loss = 2.29196483, grad/param norm = 2.6670e-01, time/batch = 0.6774s	
743/22950 (epoch 1.619), train_loss = 2.14663571, grad/param norm = 2.7217e-01, time/batch = 0.6764s	
744/22950 (epoch 1.621), train_loss = 2.30959799, grad/param norm = 2.7088e-01, time/batch = 0.6804s	
745/22950 (epoch 1.623), train_loss = 2.21768166, grad/param norm = 2.9176e-01, time/batch = 0.6769s	
746/22950 (epoch 1.625), train_loss = 2.18908308, grad/param norm = 2.6546e-01, time/batch = 0.6750s	
747/22950 (epoch 1.627), train_loss = 2.16725427, grad/param norm = 2.9544e-01, time/batch = 0.6744s	
748/22950 (epoch 1.630), train_loss = 2.13549702, grad/param norm = 3.5157e-01, time/batch = 0.6760s	
749/22950 (epoch 1.632), train_loss = 2.29733609, grad/param norm = 2.9764e-01, time/batch = 0.6743s	
750/22950 (epoch 1.634), train_loss = 2.17366451, grad/param norm = 2.8349e-01, time/batch = 0.6917s	
751/22950 (epoch 1.636), train_loss = 2.16125836, grad/param norm = 2.9192e-01, time/batch = 0.7108s	
752/22950 (epoch 1.638), train_loss = 2.15021659, grad/param norm = 3.6613e-01, time/batch = 0.6761s	
753/22950 (epoch 1.641), train_loss = 2.26489369, grad/param norm = 3.8984e-01, time/batch = 0.6840s	
754/22950 (epoch 1.643), train_loss = 2.21354372, grad/param norm = 4.0724e-01, time/batch = 0.6902s	
755/22950 (epoch 1.645), train_loss = 2.18992184, grad/param norm = 3.2015e-01, time/batch = 0.6839s	
756/22950 (epoch 1.647), train_loss = 2.22547669, grad/param norm = 3.1988e-01, time/batch = 0.6775s	
757/22950 (epoch 1.649), train_loss = 2.27290642, grad/param norm = 3.2009e-01, time/batch = 0.6794s	
758/22950 (epoch 1.651), train_loss = 2.27220838, grad/param norm = 3.1749e-01, time/batch = 0.6758s	
759/22950 (epoch 1.654), train_loss = 2.08085641, grad/param norm = 3.2600e-01, time/batch = 0.6777s	
760/22950 (epoch 1.656), train_loss = 2.30530677, grad/param norm = 3.3977e-01, time/batch = 0.6740s	
761/22950 (epoch 1.658), train_loss = 2.22249667, grad/param norm = 3.0963e-01, time/batch = 0.6767s	
762/22950 (epoch 1.660), train_loss = 2.01990929, grad/param norm = 3.0429e-01, time/batch = 0.6752s	
763/22950 (epoch 1.662), train_loss = 2.14139618, grad/param norm = 3.7092e-01, time/batch = 0.6744s	
764/22950 (epoch 1.664), train_loss = 2.21793244, grad/param norm = 3.7449e-01, time/batch = 0.6768s	
765/22950 (epoch 1.667), train_loss = 2.28779890, grad/param norm = 3.2970e-01, time/batch = 0.6737s	
766/22950 (epoch 1.669), train_loss = 2.09984983, grad/param norm = 4.1732e-01, time/batch = 0.6739s	
767/22950 (epoch 1.671), train_loss = 2.31691254, grad/param norm = 4.8477e-01, time/batch = 0.6741s	
768/22950 (epoch 1.673), train_loss = 2.30774833, grad/param norm = 4.8520e-01, time/batch = 0.6715s	
769/22950 (epoch 1.675), train_loss = 2.24613389, grad/param norm = 4.3973e-01, time/batch = 0.6702s	
770/22950 (epoch 1.678), train_loss = 2.22866338, grad/param norm = 4.4205e-01, time/batch = 0.6737s	
771/22950 (epoch 1.680), train_loss = 2.21492015, grad/param norm = 3.2588e-01, time/batch = 0.6802s	
772/22950 (epoch 1.682), train_loss = 2.32317654, grad/param norm = 2.9064e-01, time/batch = 0.7062s	
773/22950 (epoch 1.684), train_loss = 2.33134433, grad/param norm = 3.0320e-01, time/batch = 0.7146s	
774/22950 (epoch 1.686), train_loss = 2.27980685, grad/param norm = 3.1364e-01, time/batch = 0.6974s	
775/22950 (epoch 1.688), train_loss = 2.22659735, grad/param norm = 2.8505e-01, time/batch = 0.6817s	
776/22950 (epoch 1.691), train_loss = 2.11814083, grad/param norm = 3.7838e-01, time/batch = 0.6830s	
777/22950 (epoch 1.693), train_loss = 2.16384108, grad/param norm = 3.5600e-01, time/batch = 0.6800s	
778/22950 (epoch 1.695), train_loss = 2.37346839, grad/param norm = 2.9835e-01, time/batch = 0.6813s	
779/22950 (epoch 1.697), train_loss = 2.26899793, grad/param norm = 2.6784e-01, time/batch = 0.6951s	
780/22950 (epoch 1.699), train_loss = 2.25574641, grad/param norm = 2.4655e-01, time/batch = 0.6776s	
781/22950 (epoch 1.702), train_loss = 2.19952936, grad/param norm = 2.6199e-01, time/batch = 0.6808s	
782/22950 (epoch 1.704), train_loss = 2.30921430, grad/param norm = 3.5755e-01, time/batch = 0.6777s	
783/22950 (epoch 1.706), train_loss = 2.29920932, grad/param norm = 3.2511e-01, time/batch = 0.6755s	
784/22950 (epoch 1.708), train_loss = 2.29446638, grad/param norm = 4.1352e-01, time/batch = 0.6745s	
785/22950 (epoch 1.710), train_loss = 2.34384176, grad/param norm = 3.6154e-01, time/batch = 0.6914s	
786/22950 (epoch 1.712), train_loss = 2.27240570, grad/param norm = 2.7147e-01, time/batch = 0.7126s	
787/22950 (epoch 1.715), train_loss = 2.19894622, grad/param norm = 3.2296e-01, time/batch = 0.6817s	
788/22950 (epoch 1.717), train_loss = 1.99568574, grad/param norm = 3.6402e-01, time/batch = 0.6774s	
789/22950 (epoch 1.719), train_loss = 2.27291370, grad/param norm = 3.8191e-01, time/batch = 0.6799s	
790/22950 (epoch 1.721), train_loss = 2.21060367, grad/param norm = 3.2299e-01, time/batch = 0.6748s	
791/22950 (epoch 1.723), train_loss = 2.21257526, grad/param norm = 2.9869e-01, time/batch = 0.6787s	
792/22950 (epoch 1.725), train_loss = 2.39260827, grad/param norm = 3.8832e-01, time/batch = 0.6794s	
793/22950 (epoch 1.728), train_loss = 2.19014883, grad/param norm = 4.0504e-01, time/batch = 0.7022s	
794/22950 (epoch 1.730), train_loss = 2.14839589, grad/param norm = 4.2539e-01, time/batch = 0.6921s	
795/22950 (epoch 1.732), train_loss = 2.18092097, grad/param norm = 2.9573e-01, time/batch = 0.6977s	
796/22950 (epoch 1.734), train_loss = 2.23658988, grad/param norm = 2.5175e-01, time/batch = 0.7123s	
797/22950 (epoch 1.736), train_loss = 2.08404387, grad/param norm = 2.5415e-01, time/batch = 0.6777s	
798/22950 (epoch 1.739), train_loss = 2.24094856, grad/param norm = 2.9160e-01, time/batch = 0.6776s	
799/22950 (epoch 1.741), train_loss = 2.20060755, grad/param norm = 3.3774e-01, time/batch = 0.6754s	
800/22950 (epoch 1.743), train_loss = 2.34536016, grad/param norm = 2.9980e-01, time/batch = 0.6792s	
801/22950 (epoch 1.745), train_loss = 2.35593333, grad/param norm = 3.3946e-01, time/batch = 0.6913s	
802/22950 (epoch 1.747), train_loss = 2.13754631, grad/param norm = 3.8835e-01, time/batch = 0.6767s	
803/22950 (epoch 1.749), train_loss = 2.19266434, grad/param norm = 3.7826e-01, time/batch = 0.6754s	
804/22950 (epoch 1.752), train_loss = 2.29816236, grad/param norm = 2.9600e-01, time/batch = 0.6767s	
805/22950 (epoch 1.754), train_loss = 2.27860413, grad/param norm = 2.8751e-01, time/batch = 0.6805s	
806/22950 (epoch 1.756), train_loss = 2.08142548, grad/param norm = 3.0260e-01, time/batch = 0.7103s	
807/22950 (epoch 1.758), train_loss = 2.17140688, grad/param norm = 3.1534e-01, time/batch = 0.6867s	
808/22950 (epoch 1.760), train_loss = 2.14320899, grad/param norm = 2.9782e-01, time/batch = 0.6735s	
809/22950 (epoch 1.763), train_loss = 2.18781227, grad/param norm = 3.2601e-01, time/batch = 0.6717s	
810/22950 (epoch 1.765), train_loss = 2.21730350, grad/param norm = 3.9881e-01, time/batch = 0.6737s	
811/22950 (epoch 1.767), train_loss = 2.18329666, grad/param norm = 3.6276e-01, time/batch = 0.6759s	
812/22950 (epoch 1.769), train_loss = 2.21560255, grad/param norm = 3.9118e-01, time/batch = 0.6751s	
813/22950 (epoch 1.771), train_loss = 2.03662808, grad/param norm = 3.3876e-01, time/batch = 0.6723s	
814/22950 (epoch 1.773), train_loss = 2.07805347, grad/param norm = 4.3688e-01, time/batch = 0.6725s	
815/22950 (epoch 1.776), train_loss = 2.16480583, grad/param norm = 4.1726e-01, time/batch = 0.6754s	
816/22950 (epoch 1.778), train_loss = 2.13492189, grad/param norm = 3.1342e-01, time/batch = 0.6741s	
817/22950 (epoch 1.780), train_loss = 2.04024612, grad/param norm = 3.8264e-01, time/batch = 0.6753s	
818/22950 (epoch 1.782), train_loss = 2.12539670, grad/param norm = 3.7670e-01, time/batch = 0.6785s	
819/22950 (epoch 1.784), train_loss = 2.31170822, grad/param norm = 3.5164e-01, time/batch = 0.6753s	
820/22950 (epoch 1.786), train_loss = 2.18445311, grad/param norm = 2.9156e-01, time/batch = 0.6754s	
821/22950 (epoch 1.789), train_loss = 2.04539664, grad/param norm = 2.5645e-01, time/batch = 0.6779s	
822/22950 (epoch 1.791), train_loss = 2.05647503, grad/param norm = 2.8182e-01, time/batch = 0.6791s	
823/22950 (epoch 1.793), train_loss = 2.39725043, grad/param norm = 3.2315e-01, time/batch = 0.6856s	
824/22950 (epoch 1.795), train_loss = 2.09081375, grad/param norm = 3.4310e-01, time/batch = 0.6755s	
825/22950 (epoch 1.797), train_loss = 2.29395301, grad/param norm = 3.5206e-01, time/batch = 0.6742s	
826/22950 (epoch 1.800), train_loss = 2.09451836, grad/param norm = 3.6634e-01, time/batch = 0.6871s	
827/22950 (epoch 1.802), train_loss = 2.10731491, grad/param norm = 3.0291e-01, time/batch = 0.6756s	
828/22950 (epoch 1.804), train_loss = 2.07809140, grad/param norm = 2.8315e-01, time/batch = 0.6732s	
829/22950 (epoch 1.806), train_loss = 2.11881263, grad/param norm = 3.4454e-01, time/batch = 0.6741s	
830/22950 (epoch 1.808), train_loss = 2.21541639, grad/param norm = 3.6432e-01, time/batch = 0.6750s	
831/22950 (epoch 1.810), train_loss = 2.19954534, grad/param norm = 4.0535e-01, time/batch = 0.6807s	
832/22950 (epoch 1.813), train_loss = 1.99092235, grad/param norm = 3.1929e-01, time/batch = 0.6783s	
833/22950 (epoch 1.815), train_loss = 2.24400444, grad/param norm = 4.2109e-01, time/batch = 0.6741s	
834/22950 (epoch 1.817), train_loss = 2.10286984, grad/param norm = 4.5840e-01, time/batch = 0.6728s	
835/22950 (epoch 1.819), train_loss = 2.16162384, grad/param norm = 3.2623e-01, time/batch = 0.6755s	
836/22950 (epoch 1.821), train_loss = 2.06494653, grad/param norm = 2.9570e-01, time/batch = 0.6750s	
837/22950 (epoch 1.824), train_loss = 2.06791228, grad/param norm = 3.2073e-01, time/batch = 0.6751s	
838/22950 (epoch 1.826), train_loss = 2.20439350, grad/param norm = 3.1005e-01, time/batch = 0.6751s	
839/22950 (epoch 1.828), train_loss = 2.13251532, grad/param norm = 2.8583e-01, time/batch = 0.6716s	
840/22950 (epoch 1.830), train_loss = 2.17708723, grad/param norm = 2.4859e-01, time/batch = 0.6733s	
841/22950 (epoch 1.832), train_loss = 2.15305310, grad/param norm = 2.7198e-01, time/batch = 0.6756s	
842/22950 (epoch 1.834), train_loss = 2.02620649, grad/param norm = 2.6800e-01, time/batch = 0.6709s	
843/22950 (epoch 1.837), train_loss = 2.17355637, grad/param norm = 3.2995e-01, time/batch = 0.6730s	
844/22950 (epoch 1.839), train_loss = 2.24350159, grad/param norm = 3.2050e-01, time/batch = 0.6761s	
845/22950 (epoch 1.841), train_loss = 2.09353289, grad/param norm = 3.2451e-01, time/batch = 0.6739s	
846/22950 (epoch 1.843), train_loss = 2.06764616, grad/param norm = 3.1502e-01, time/batch = 0.6795s	
847/22950 (epoch 1.845), train_loss = 2.23965361, grad/param norm = 3.1626e-01, time/batch = 0.6801s	
848/22950 (epoch 1.847), train_loss = 2.25732482, grad/param norm = 2.6314e-01, time/batch = 0.6863s	
849/22950 (epoch 1.850), train_loss = 2.18226835, grad/param norm = 3.8301e-01, time/batch = 0.6716s	
850/22950 (epoch 1.852), train_loss = 2.19351250, grad/param norm = 3.2737e-01, time/batch = 0.6755s	
851/22950 (epoch 1.854), train_loss = 2.13040803, grad/param norm = 3.0156e-01, time/batch = 0.6752s	
852/22950 (epoch 1.856), train_loss = 2.39683059, grad/param norm = 2.9343e-01, time/batch = 0.6802s	
853/22950 (epoch 1.858), train_loss = 2.15873490, grad/param norm = 2.5705e-01, time/batch = 0.6823s	
854/22950 (epoch 1.861), train_loss = 2.17012636, grad/param norm = 3.2328e-01, time/batch = 0.6731s	
855/22950 (epoch 1.863), train_loss = 2.28094931, grad/param norm = 3.3681e-01, time/batch = 0.6731s	
856/22950 (epoch 1.865), train_loss = 2.26717957, grad/param norm = 3.1021e-01, time/batch = 0.6733s	
857/22950 (epoch 1.867), train_loss = 2.23055755, grad/param norm = 3.2857e-01, time/batch = 0.6744s	
858/22950 (epoch 1.869), train_loss = 2.30592546, grad/param norm = 2.9057e-01, time/batch = 0.6764s	
859/22950 (epoch 1.871), train_loss = 2.10565067, grad/param norm = 2.8763e-01, time/batch = 0.6862s	
860/22950 (epoch 1.874), train_loss = 2.17231614, grad/param norm = 3.5541e-01, time/batch = 0.6984s	
861/22950 (epoch 1.876), train_loss = 2.22119218, grad/param norm = 3.3224e-01, time/batch = 0.7190s	
862/22950 (epoch 1.878), train_loss = 2.07666617, grad/param norm = 3.3225e-01, time/batch = 0.7152s	
863/22950 (epoch 1.880), train_loss = 2.25825381, grad/param norm = 3.0158e-01, time/batch = 0.6862s	
864/22950 (epoch 1.882), train_loss = 2.02651868, grad/param norm = 2.8027e-01, time/batch = 0.6851s	
865/22950 (epoch 1.885), train_loss = 2.20000770, grad/param norm = 3.6295e-01, time/batch = 0.7002s	
866/22950 (epoch 1.887), train_loss = 2.17799704, grad/param norm = 4.3301e-01, time/batch = 0.6982s	
867/22950 (epoch 1.889), train_loss = 2.37834688, grad/param norm = 5.1522e-01, time/batch = 0.6889s	
868/22950 (epoch 1.891), train_loss = 2.29192490, grad/param norm = 3.5829e-01, time/batch = 0.6753s	
869/22950 (epoch 1.893), train_loss = 2.16414107, grad/param norm = 2.4230e-01, time/batch = 0.6767s	
870/22950 (epoch 1.895), train_loss = 2.22498961, grad/param norm = 2.8082e-01, time/batch = 0.6762s	
871/22950 (epoch 1.898), train_loss = 2.16673352, grad/param norm = 3.5254e-01, time/batch = 0.6853s	
872/22950 (epoch 1.900), train_loss = 2.06174195, grad/param norm = 3.6156e-01, time/batch = 0.6871s	
873/22950 (epoch 1.902), train_loss = 2.09988965, grad/param norm = 3.2878e-01, time/batch = 0.6809s	
874/22950 (epoch 1.904), train_loss = 2.14051040, grad/param norm = 2.4518e-01, time/batch = 0.6789s	
875/22950 (epoch 1.906), train_loss = 2.22305262, grad/param norm = 2.5569e-01, time/batch = 0.6849s	
876/22950 (epoch 1.908), train_loss = 2.02449115, grad/param norm = 2.9972e-01, time/batch = 0.6867s	
877/22950 (epoch 1.911), train_loss = 2.00765467, grad/param norm = 2.8857e-01, time/batch = 0.6880s	
878/22950 (epoch 1.913), train_loss = 2.01361405, grad/param norm = 2.3881e-01, time/batch = 0.6880s	
879/22950 (epoch 1.915), train_loss = 2.36861882, grad/param norm = 3.4255e-01, time/batch = 0.6890s	
880/22950 (epoch 1.917), train_loss = 2.17889212, grad/param norm = 4.2615e-01, time/batch = 0.6884s	
881/22950 (epoch 1.919), train_loss = 2.23862417, grad/param norm = 4.5388e-01, time/batch = 0.6907s	
882/22950 (epoch 1.922), train_loss = 2.11689194, grad/param norm = 3.9783e-01, time/batch = 0.7227s	
883/22950 (epoch 1.924), train_loss = 2.22996252, grad/param norm = 2.9043e-01, time/batch = 0.6959s	
884/22950 (epoch 1.926), train_loss = 2.07552412, grad/param norm = 2.8953e-01, time/batch = 0.6869s	
885/22950 (epoch 1.928), train_loss = 2.03714197, grad/param norm = 3.4723e-01, time/batch = 0.6853s	
886/22950 (epoch 1.930), train_loss = 2.03128346, grad/param norm = 3.6046e-01, time/batch = 0.6841s	
887/22950 (epoch 1.932), train_loss = 2.13816392, grad/param norm = 3.1112e-01, time/batch = 0.6859s	
888/22950 (epoch 1.935), train_loss = 2.10485975, grad/param norm = 2.3811e-01, time/batch = 0.6892s	
889/22950 (epoch 1.937), train_loss = 2.14266376, grad/param norm = 3.0527e-01, time/batch = 0.6884s	
890/22950 (epoch 1.939), train_loss = 2.11719518, grad/param norm = 3.3391e-01, time/batch = 0.6871s	
891/22950 (epoch 1.941), train_loss = 2.06463875, grad/param norm = 2.6904e-01, time/batch = 0.6854s	
892/22950 (epoch 1.943), train_loss = 2.14461405, grad/param norm = 2.5338e-01, time/batch = 0.6888s	
893/22950 (epoch 1.946), train_loss = 1.95828608, grad/param norm = 2.7297e-01, time/batch = 0.6874s	
894/22950 (epoch 1.948), train_loss = 2.19059991, grad/param norm = 3.0341e-01, time/batch = 0.6870s	
895/22950 (epoch 1.950), train_loss = 2.19910926, grad/param norm = 4.0046e-01, time/batch = 0.6866s	
896/22950 (epoch 1.952), train_loss = 2.16269211, grad/param norm = 3.0597e-01, time/batch = 0.6830s	
897/22950 (epoch 1.954), train_loss = 2.12810364, grad/param norm = 2.8764e-01, time/batch = 0.6843s	
898/22950 (epoch 1.956), train_loss = 2.04331232, grad/param norm = 2.3660e-01, time/batch = 0.6864s	
899/22950 (epoch 1.959), train_loss = 2.00394738, grad/param norm = 3.1712e-01, time/batch = 0.6874s	
900/22950 (epoch 1.961), train_loss = 2.06593226, grad/param norm = 2.9693e-01, time/batch = 0.6850s	
901/22950 (epoch 1.963), train_loss = 2.22836150, grad/param norm = 3.3464e-01, time/batch = 0.6880s	
902/22950 (epoch 1.965), train_loss = 2.31388792, grad/param norm = 3.5330e-01, time/batch = 0.7036s	
903/22950 (epoch 1.967), train_loss = 2.05355207, grad/param norm = 3.1453e-01, time/batch = 0.6999s	
904/22950 (epoch 1.969), train_loss = 2.06931050, grad/param norm = 2.6496e-01, time/batch = 0.6931s	
905/22950 (epoch 1.972), train_loss = 2.09738269, grad/param norm = 2.8880e-01, time/batch = 0.6885s	
906/22950 (epoch 1.974), train_loss = 1.98353828, grad/param norm = 2.5608e-01, time/batch = 0.6851s	
907/22950 (epoch 1.976), train_loss = 1.95418967, grad/param norm = 3.1940e-01, time/batch = 0.6853s	
908/22950 (epoch 1.978), train_loss = 2.18997894, grad/param norm = 3.5994e-01, time/batch = 0.6874s	
909/22950 (epoch 1.980), train_loss = 2.18507202, grad/param norm = 3.1791e-01, time/batch = 0.6890s	
910/22950 (epoch 1.983), train_loss = 2.02037807, grad/param norm = 2.9936e-01, time/batch = 0.6901s	
911/22950 (epoch 1.985), train_loss = 2.05937396, grad/param norm = 3.2739e-01, time/batch = 0.6945s	
912/22950 (epoch 1.987), train_loss = 2.13661242, grad/param norm = 2.9838e-01, time/batch = 0.6894s	
913/22950 (epoch 1.989), train_loss = 2.21896086, grad/param norm = 3.2083e-01, time/batch = 0.6866s	
914/22950 (epoch 1.991), train_loss = 2.11474194, grad/param norm = 2.9554e-01, time/batch = 0.7100s	
915/22950 (epoch 1.993), train_loss = 2.12106761, grad/param norm = 3.5071e-01, time/batch = 0.7255s	
916/22950 (epoch 1.996), train_loss = 2.26786939, grad/param norm = 4.4169e-01, time/batch = 0.7225s	
917/22950 (epoch 1.998), train_loss = 2.04040807, grad/param norm = 3.1704e-01, time/batch = 0.7107s	
918/22950 (epoch 2.000), train_loss = 1.98761235, grad/param norm = 2.9385e-01, time/batch = 0.6980s	
919/22950 (epoch 2.002), train_loss = 2.33000642, grad/param norm = 2.6253e-01, time/batch = 0.6873s	
920/22950 (epoch 2.004), train_loss = 2.17547593, grad/param norm = 2.9270e-01, time/batch = 0.6886s	
921/22950 (epoch 2.007), train_loss = 2.07545004, grad/param norm = 3.6360e-01, time/batch = 0.6873s	
922/22950 (epoch 2.009), train_loss = 2.29816206, grad/param norm = 4.1533e-01, time/batch = 0.6852s	
923/22950 (epoch 2.011), train_loss = 2.33317580, grad/param norm = 4.9990e-01, time/batch = 0.6847s	
924/22950 (epoch 2.013), train_loss = 2.31159745, grad/param norm = 3.3966e-01, time/batch = 0.6862s	
925/22950 (epoch 2.015), train_loss = 2.27542846, grad/param norm = 3.7398e-01, time/batch = 0.6842s	
926/22950 (epoch 2.017), train_loss = 2.04602310, grad/param norm = 4.4884e-01, time/batch = 0.6863s	
927/22950 (epoch 2.020), train_loss = 2.09255489, grad/param norm = 4.0021e-01, time/batch = 0.6897s	
928/22950 (epoch 2.022), train_loss = 1.95807857, grad/param norm = 3.4492e-01, time/batch = 0.6900s	
929/22950 (epoch 2.024), train_loss = 2.09861115, grad/param norm = 3.4693e-01, time/batch = 0.6949s	
930/22950 (epoch 2.026), train_loss = 2.02045992, grad/param norm = 2.8312e-01, time/batch = 0.7125s	
931/22950 (epoch 2.028), train_loss = 2.15626875, grad/param norm = 4.0733e-01, time/batch = 0.7044s	
932/22950 (epoch 2.031), train_loss = 2.10644011, grad/param norm = 2.9392e-01, time/batch = 0.6999s	
933/22950 (epoch 2.033), train_loss = 2.34498616, grad/param norm = 2.9370e-01, time/batch = 0.7052s	
934/22950 (epoch 2.035), train_loss = 2.19810789, grad/param norm = 3.0508e-01, time/batch = 0.6991s	
935/22950 (epoch 2.037), train_loss = 2.06589692, grad/param norm = 2.6321e-01, time/batch = 0.7057s	
936/22950 (epoch 2.039), train_loss = 2.12263973, grad/param norm = 2.9253e-01, time/batch = 0.7105s	
937/22950 (epoch 2.041), train_loss = 2.23629443, grad/param norm = 3.6928e-01, time/batch = 0.6892s	
938/22950 (epoch 2.044), train_loss = 2.01593196, grad/param norm = 3.3387e-01, time/batch = 0.6854s	
939/22950 (epoch 2.046), train_loss = 2.02783102, grad/param norm = 2.8241e-01, time/batch = 0.6865s	
940/22950 (epoch 2.048), train_loss = 2.10398540, grad/param norm = 2.6186e-01, time/batch = 0.6842s	
941/22950 (epoch 2.050), train_loss = 2.15917048, grad/param norm = 2.6547e-01, time/batch = 0.6863s	
942/22950 (epoch 2.052), train_loss = 2.09443113, grad/param norm = 2.4559e-01, time/batch = 0.6860s	
943/22950 (epoch 2.054), train_loss = 2.27656827, grad/param norm = 2.9946e-01, time/batch = 0.6850s	
944/22950 (epoch 2.057), train_loss = 2.09366588, grad/param norm = 3.5518e-01, time/batch = 0.6867s	
945/22950 (epoch 2.059), train_loss = 2.10420417, grad/param norm = 2.8504e-01, time/batch = 0.6931s	
946/22950 (epoch 2.061), train_loss = 2.03000794, grad/param norm = 2.5585e-01, time/batch = 0.7168s	
947/22950 (epoch 2.063), train_loss = 2.18315258, grad/param norm = 2.5150e-01, time/batch = 0.7200s	
948/22950 (epoch 2.065), train_loss = 1.75114243, grad/param norm = 3.1513e-01, time/batch = 0.7143s	
949/22950 (epoch 2.068), train_loss = 2.28017158, grad/param norm = 3.1310e-01, time/batch = 0.6922s	
950/22950 (epoch 2.070), train_loss = 2.04433901, grad/param norm = 2.8431e-01, time/batch = 0.6959s	
951/22950 (epoch 2.072), train_loss = 2.02722211, grad/param norm = 3.3814e-01, time/batch = 0.6978s	
952/22950 (epoch 2.074), train_loss = 2.06143770, grad/param norm = 3.7282e-01, time/batch = 0.6990s	
953/22950 (epoch 2.076), train_loss = 2.05600261, grad/param norm = 3.6460e-01, time/batch = 0.6928s	
954/22950 (epoch 2.078), train_loss = 2.08880888, grad/param norm = 2.3903e-01, time/batch = 0.6917s	
955/22950 (epoch 2.081), train_loss = 2.17665686, grad/param norm = 2.8948e-01, time/batch = 0.7022s	
956/22950 (epoch 2.083), train_loss = 2.09614202, grad/param norm = 3.3994e-01, time/batch = 0.6950s	
957/22950 (epoch 2.085), train_loss = 2.01412497, grad/param norm = 2.8353e-01, time/batch = 0.6965s	
958/22950 (epoch 2.087), train_loss = 2.03058496, grad/param norm = 2.6093e-01, time/batch = 0.7142s	
959/22950 (epoch 2.089), train_loss = 2.06666475, grad/param norm = 2.6558e-01, time/batch = 0.6960s	
960/22950 (epoch 2.092), train_loss = 2.09195427, grad/param norm = 2.8933e-01, time/batch = 0.7042s	
961/22950 (epoch 2.094), train_loss = 2.00417480, grad/param norm = 3.1073e-01, time/batch = 0.7126s	
962/22950 (epoch 2.096), train_loss = 2.26549369, grad/param norm = 3.1819e-01, time/batch = 0.7078s	
963/22950 (epoch 2.098), train_loss = 2.13337086, grad/param norm = 2.9866e-01, time/batch = 0.7312s	
964/22950 (epoch 2.100), train_loss = 2.08181273, grad/param norm = 2.8847e-01, time/batch = 0.7234s	
965/22950 (epoch 2.102), train_loss = 2.06300400, grad/param norm = 2.6417e-01, time/batch = 0.7126s	
966/22950 (epoch 2.105), train_loss = 1.99484695, grad/param norm = 2.2858e-01, time/batch = 0.7191s	
967/22950 (epoch 2.107), train_loss = 2.09470526, grad/param norm = 2.7978e-01, time/batch = 0.7015s	
968/22950 (epoch 2.109), train_loss = 2.09655631, grad/param norm = 3.0869e-01, time/batch = 0.7031s	
969/22950 (epoch 2.111), train_loss = 1.94702354, grad/param norm = 2.7837e-01, time/batch = 0.7057s	
970/22950 (epoch 2.113), train_loss = 2.09903793, grad/param norm = 2.9395e-01, time/batch = 0.7013s	
971/22950 (epoch 2.115), train_loss = 2.16067060, grad/param norm = 2.9944e-01, time/batch = 0.7107s	
972/22950 (epoch 2.118), train_loss = 2.17666954, grad/param norm = 3.4190e-01, time/batch = 0.7103s	
973/22950 (epoch 2.120), train_loss = 2.00272911, grad/param norm = 2.6319e-01, time/batch = 0.7027s	
974/22950 (epoch 2.122), train_loss = 2.10304096, grad/param norm = 3.0569e-01, time/batch = 0.6897s	
975/22950 (epoch 2.124), train_loss = 1.88626480, grad/param norm = 2.9838e-01, time/batch = 0.6882s	
976/22950 (epoch 2.126), train_loss = 1.98594302, grad/param norm = 2.6857e-01, time/batch = 0.6883s	
977/22950 (epoch 2.129), train_loss = 1.83892404, grad/param norm = 2.6035e-01, time/batch = 0.6845s	
978/22950 (epoch 2.131), train_loss = 2.09244931, grad/param norm = 2.9718e-01, time/batch = 0.6887s	
979/22950 (epoch 2.133), train_loss = 2.22891506, grad/param norm = 2.7825e-01, time/batch = 0.6879s	
980/22950 (epoch 2.135), train_loss = 2.05756751, grad/param norm = 2.7711e-01, time/batch = 0.6859s	
981/22950 (epoch 2.137), train_loss = 2.24731072, grad/param norm = 2.5066e-01, time/batch = 0.6873s	
982/22950 (epoch 2.139), train_loss = 1.99217850, grad/param norm = 3.2755e-01, time/batch = 0.6886s	
983/22950 (epoch 2.142), train_loss = 1.97391816, grad/param norm = 4.2675e-01, time/batch = 0.6882s	
984/22950 (epoch 2.144), train_loss = 1.96017623, grad/param norm = 3.1351e-01, time/batch = 0.6869s	
985/22950 (epoch 2.146), train_loss = 2.16570672, grad/param norm = 3.0934e-01, time/batch = 0.6878s	
986/22950 (epoch 2.148), train_loss = 1.97937860, grad/param norm = 2.8162e-01, time/batch = 0.6880s	
987/22950 (epoch 2.150), train_loss = 2.06427776, grad/param norm = 2.5639e-01, time/batch = 0.6881s	
988/22950 (epoch 2.153), train_loss = 2.00604560, grad/param norm = 3.0206e-01, time/batch = 0.6896s	
989/22950 (epoch 2.155), train_loss = 2.04161907, grad/param norm = 3.3576e-01, time/batch = 0.6917s	
990/22950 (epoch 2.157), train_loss = 2.01321842, grad/param norm = 3.7909e-01, time/batch = 0.6937s	
991/22950 (epoch 2.159), train_loss = 1.97407348, grad/param norm = 4.3491e-01, time/batch = 0.6929s	
992/22950 (epoch 2.161), train_loss = 2.21055913, grad/param norm = 3.7151e-01, time/batch = 0.6861s	
993/22950 (epoch 2.163), train_loss = 2.13834620, grad/param norm = 2.7462e-01, time/batch = 0.6859s	
994/22950 (epoch 2.166), train_loss = 2.17111659, grad/param norm = 2.2838e-01, time/batch = 0.6871s	
995/22950 (epoch 2.168), train_loss = 2.17045581, grad/param norm = 2.8508e-01, time/batch = 0.6865s	
996/22950 (epoch 2.170), train_loss = 2.12045952, grad/param norm = 3.1401e-01, time/batch = 0.6869s	
997/22950 (epoch 2.172), train_loss = 2.05439092, grad/param norm = 3.1664e-01, time/batch = 0.6974s	
998/22950 (epoch 2.174), train_loss = 2.11275031, grad/param norm = 3.2625e-01, time/batch = 0.6886s	
999/22950 (epoch 2.176), train_loss = 2.19570425, grad/param norm = 2.5266e-01, time/batch = 0.6913s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch2.18_2.1132.t7	
1000/22950 (epoch 2.179), train_loss = 2.15451363, grad/param norm = 3.4623e-01, time/batch = 0.6870s	
1001/22950 (epoch 2.181), train_loss = 2.22684778, grad/param norm = 3.3306e-01, time/batch = 0.6991s	
1002/22950 (epoch 2.183), train_loss = 2.13791915, grad/param norm = 3.1390e-01, time/batch = 0.6888s	
1003/22950 (epoch 2.185), train_loss = 2.10478295, grad/param norm = 2.7186e-01, time/batch = 0.6896s	
1004/22950 (epoch 2.187), train_loss = 2.03239357, grad/param norm = 3.1178e-01, time/batch = 0.6918s	
1005/22950 (epoch 2.190), train_loss = 2.17163391, grad/param norm = 3.8142e-01, time/batch = 0.6911s	
1006/22950 (epoch 2.192), train_loss = 2.01364623, grad/param norm = 2.6094e-01, time/batch = 0.7001s	
1007/22950 (epoch 2.194), train_loss = 2.03886769, grad/param norm = 2.9755e-01, time/batch = 0.6904s	
1008/22950 (epoch 2.196), train_loss = 1.86983294, grad/param norm = 3.1439e-01, time/batch = 0.6944s	
1009/22950 (epoch 2.198), train_loss = 2.21132894, grad/param norm = 3.2975e-01, time/batch = 0.6900s	
1010/22950 (epoch 2.200), train_loss = 1.94409723, grad/param norm = 3.2045e-01, time/batch = 0.6944s	
1011/22950 (epoch 2.203), train_loss = 1.91519558, grad/param norm = 3.1642e-01, time/batch = 0.6882s	
1012/22950 (epoch 2.205), train_loss = 2.01400875, grad/param norm = 3.9827e-01, time/batch = 0.6936s	
1013/22950 (epoch 2.207), train_loss = 2.06896435, grad/param norm = 3.6677e-01, time/batch = 0.6850s	
1014/22950 (epoch 2.209), train_loss = 2.35005499, grad/param norm = 2.9803e-01, time/batch = 0.6846s	
1015/22950 (epoch 2.211), train_loss = 2.02541518, grad/param norm = 2.8627e-01, time/batch = 0.6857s	
1016/22950 (epoch 2.214), train_loss = 1.96307388, grad/param norm = 2.5821e-01, time/batch = 0.6871s	
1017/22950 (epoch 2.216), train_loss = 2.07351887, grad/param norm = 2.7017e-01, time/batch = 0.6860s	
1018/22950 (epoch 2.218), train_loss = 2.09774426, grad/param norm = 2.7064e-01, time/batch = 0.6840s	
1019/22950 (epoch 2.220), train_loss = 2.15751996, grad/param norm = 3.1934e-01, time/batch = 0.6878s	
1020/22950 (epoch 2.222), train_loss = 2.11298405, grad/param norm = 2.4289e-01, time/batch = 0.6864s	
1021/22950 (epoch 2.224), train_loss = 1.96162681, grad/param norm = 2.7078e-01, time/batch = 0.6900s	
1022/22950 (epoch 2.227), train_loss = 1.94104793, grad/param norm = 2.5244e-01, time/batch = 0.6885s	
1023/22950 (epoch 2.229), train_loss = 2.05373123, grad/param norm = 3.3727e-01, time/batch = 0.6891s	
1024/22950 (epoch 2.231), train_loss = 1.92677924, grad/param norm = 3.4409e-01, time/batch = 0.6893s	
1025/22950 (epoch 2.233), train_loss = 2.04246336, grad/param norm = 3.0580e-01, time/batch = 0.7140s	
1026/22950 (epoch 2.235), train_loss = 2.14006667, grad/param norm = 3.2304e-01, time/batch = 0.7198s	
1027/22950 (epoch 2.237), train_loss = 1.85011758, grad/param norm = 3.8173e-01, time/batch = 0.7162s	
1028/22950 (epoch 2.240), train_loss = 1.91617379, grad/param norm = 2.2670e-01, time/batch = 0.6985s	
1029/22950 (epoch 2.242), train_loss = 1.97154230, grad/param norm = 3.0155e-01, time/batch = 0.6965s	
1030/22950 (epoch 2.244), train_loss = 2.16330607, grad/param norm = 2.9405e-01, time/batch = 0.6953s	
1031/22950 (epoch 2.246), train_loss = 2.09542300, grad/param norm = 2.8256e-01, time/batch = 0.7044s	
1032/22950 (epoch 2.248), train_loss = 2.05261877, grad/param norm = 2.9794e-01, time/batch = 0.7039s	
1033/22950 (epoch 2.251), train_loss = 2.07040244, grad/param norm = 2.9195e-01, time/batch = 0.7016s	
1034/22950 (epoch 2.253), train_loss = 2.12488235, grad/param norm = 3.2858e-01, time/batch = 0.6924s	
1035/22950 (epoch 2.255), train_loss = 1.94323998, grad/param norm = 2.6644e-01, time/batch = 0.6936s	
1036/22950 (epoch 2.257), train_loss = 2.15043340, grad/param norm = 2.6851e-01, time/batch = 0.6878s	
1037/22950 (epoch 2.259), train_loss = 1.86686155, grad/param norm = 3.0331e-01, time/batch = 0.7139s	
1038/22950 (epoch 2.261), train_loss = 2.24864021, grad/param norm = 2.9550e-01, time/batch = 0.7049s	
1039/22950 (epoch 2.264), train_loss = 2.05444300, grad/param norm = 2.6734e-01, time/batch = 0.7023s	
1040/22950 (epoch 2.266), train_loss = 2.25017686, grad/param norm = 3.1640e-01, time/batch = 0.6954s	
1041/22950 (epoch 2.268), train_loss = 2.23349639, grad/param norm = 2.4567e-01, time/batch = 0.7118s	
1042/22950 (epoch 2.270), train_loss = 2.17482667, grad/param norm = 3.1087e-01, time/batch = 0.6913s	
1043/22950 (epoch 2.272), train_loss = 2.25664900, grad/param norm = 2.6889e-01, time/batch = 0.6891s	
1044/22950 (epoch 2.275), train_loss = 1.96881248, grad/param norm = 3.2636e-01, time/batch = 0.6900s	
1045/22950 (epoch 2.277), train_loss = 2.05304454, grad/param norm = 3.5556e-01, time/batch = 0.6881s	
1046/22950 (epoch 2.279), train_loss = 2.12234800, grad/param norm = 3.6289e-01, time/batch = 0.6865s	
1047/22950 (epoch 2.281), train_loss = 2.08100897, grad/param norm = 3.9714e-01, time/batch = 0.6891s	
1048/22950 (epoch 2.283), train_loss = 2.01926554, grad/param norm = 3.8892e-01, time/batch = 0.6853s	
1049/22950 (epoch 2.285), train_loss = 2.06700158, grad/param norm = 3.5743e-01, time/batch = 0.6886s	
1050/22950 (epoch 2.288), train_loss = 1.98300933, grad/param norm = 3.1770e-01, time/batch = 0.6853s	
1051/22950 (epoch 2.290), train_loss = 1.97499693, grad/param norm = 2.4469e-01, time/batch = 0.6899s	
1052/22950 (epoch 2.292), train_loss = 2.04603810, grad/param norm = 2.4669e-01, time/batch = 0.6926s	
1053/22950 (epoch 2.294), train_loss = 2.11156074, grad/param norm = 2.7909e-01, time/batch = 0.6944s	
1054/22950 (epoch 2.296), train_loss = 1.84688556, grad/param norm = 2.3360e-01, time/batch = 0.6910s	
1055/22950 (epoch 2.298), train_loss = 2.01409166, grad/param norm = 2.9109e-01, time/batch = 0.6867s	
1056/22950 (epoch 2.301), train_loss = 2.09654981, grad/param norm = 3.2648e-01, time/batch = 0.6860s	
1057/22950 (epoch 2.303), train_loss = 2.11834446, grad/param norm = 3.3592e-01, time/batch = 0.6828s	
1058/22950 (epoch 2.305), train_loss = 2.23865640, grad/param norm = 2.3647e-01, time/batch = 0.6885s	
1059/22950 (epoch 2.307), train_loss = 2.17381416, grad/param norm = 3.3969e-01, time/batch = 0.6874s	
1060/22950 (epoch 2.309), train_loss = 2.21150677, grad/param norm = 2.9069e-01, time/batch = 0.6855s	
1061/22950 (epoch 2.312), train_loss = 2.17653506, grad/param norm = 2.2966e-01, time/batch = 0.6865s	
1062/22950 (epoch 2.314), train_loss = 1.88600424, grad/param norm = 2.7218e-01, time/batch = 0.6862s	
1063/22950 (epoch 2.316), train_loss = 2.04130951, grad/param norm = 2.4928e-01, time/batch = 0.6848s	
1064/22950 (epoch 2.318), train_loss = 1.88982805, grad/param norm = 2.2272e-01, time/batch = 0.6969s	
1065/22950 (epoch 2.320), train_loss = 1.99672081, grad/param norm = 2.3307e-01, time/batch = 0.7171s	
1066/22950 (epoch 2.322), train_loss = 2.00067287, grad/param norm = 2.6733e-01, time/batch = 0.7215s	
1067/22950 (epoch 2.325), train_loss = 1.79452669, grad/param norm = 2.4455e-01, time/batch = 0.7214s	
1068/22950 (epoch 2.327), train_loss = 1.80145678, grad/param norm = 2.8360e-01, time/batch = 0.7133s	
1069/22950 (epoch 2.329), train_loss = 1.89633069, grad/param norm = 2.7221e-01, time/batch = 0.7059s	
1070/22950 (epoch 2.331), train_loss = 1.86697801, grad/param norm = 3.1734e-01, time/batch = 0.7012s	
1071/22950 (epoch 2.333), train_loss = 1.94351570, grad/param norm = 2.7550e-01, time/batch = 0.6853s	
1072/22950 (epoch 2.336), train_loss = 2.03995603, grad/param norm = 3.0238e-01, time/batch = 0.6869s	
1073/22950 (epoch 2.338), train_loss = 1.99640599, grad/param norm = 4.0686e-01, time/batch = 0.6855s	
1074/22950 (epoch 2.340), train_loss = 1.95512396, grad/param norm = 4.0234e-01, time/batch = 0.6843s	
1075/22950 (epoch 2.342), train_loss = 2.00394537, grad/param norm = 2.6942e-01, time/batch = 0.6915s	
1076/22950 (epoch 2.344), train_loss = 1.99362208, grad/param norm = 2.5805e-01, time/batch = 0.6905s	
1077/22950 (epoch 2.346), train_loss = 2.15678987, grad/param norm = 2.6811e-01, time/batch = 0.6865s	
1078/22950 (epoch 2.349), train_loss = 2.12205586, grad/param norm = 3.3218e-01, time/batch = 0.6909s	
1079/22950 (epoch 2.351), train_loss = 2.02474427, grad/param norm = 2.9227e-01, time/batch = 0.6899s	
1080/22950 (epoch 2.353), train_loss = 2.06740928, grad/param norm = 2.6663e-01, time/batch = 0.7181s	
1081/22950 (epoch 2.355), train_loss = 2.19116273, grad/param norm = 2.6603e-01, time/batch = 0.7053s	
1082/22950 (epoch 2.357), train_loss = 2.09884969, grad/param norm = 2.5286e-01, time/batch = 0.6901s	
1083/22950 (epoch 2.359), train_loss = 2.18006824, grad/param norm = 2.6701e-01, time/batch = 0.6888s	
1084/22950 (epoch 2.362), train_loss = 1.99844038, grad/param norm = 2.9597e-01, time/batch = 0.6927s	
1085/22950 (epoch 2.364), train_loss = 2.08364402, grad/param norm = 2.3763e-01, time/batch = 0.6894s	
1086/22950 (epoch 2.366), train_loss = 1.77299684, grad/param norm = 2.7785e-01, time/batch = 0.6861s	
1087/22950 (epoch 2.368), train_loss = 1.97286250, grad/param norm = 2.6464e-01, time/batch = 0.6861s	
1088/22950 (epoch 2.370), train_loss = 1.97402037, grad/param norm = 2.5770e-01, time/batch = 0.6873s	
1089/22950 (epoch 2.373), train_loss = 1.85920881, grad/param norm = 2.2384e-01, time/batch = 0.6875s	
1090/22950 (epoch 2.375), train_loss = 2.20682480, grad/param norm = 2.4811e-01, time/batch = 0.6871s	
1091/22950 (epoch 2.377), train_loss = 2.00754876, grad/param norm = 3.1345e-01, time/batch = 0.6877s	
1092/22950 (epoch 2.379), train_loss = 2.17740838, grad/param norm = 3.1728e-01, time/batch = 0.6900s	
1093/22950 (epoch 2.381), train_loss = 1.83230089, grad/param norm = 2.7983e-01, time/batch = 0.6887s	
1094/22950 (epoch 2.383), train_loss = 2.06646012, grad/param norm = 2.7393e-01, time/batch = 0.6853s	
1095/22950 (epoch 2.386), train_loss = 2.10430433, grad/param norm = 2.8208e-01, time/batch = 0.6896s	
1096/22950 (epoch 2.388), train_loss = 2.07913664, grad/param norm = 2.7343e-01, time/batch = 0.6909s	
1097/22950 (epoch 2.390), train_loss = 1.89909138, grad/param norm = 3.0183e-01, time/batch = 0.6873s	
1098/22950 (epoch 2.392), train_loss = 1.90171722, grad/param norm = 3.0185e-01, time/batch = 0.6914s	
1099/22950 (epoch 2.394), train_loss = 1.95099661, grad/param norm = 2.6349e-01, time/batch = 0.6922s	
1100/22950 (epoch 2.397), train_loss = 2.04480534, grad/param norm = 2.7988e-01, time/batch = 0.6820s	
1101/22950 (epoch 2.399), train_loss = 2.09269598, grad/param norm = 2.7511e-01, time/batch = 0.6877s	
1102/22950 (epoch 2.401), train_loss = 2.28604818, grad/param norm = 3.1594e-01, time/batch = 0.6859s	
1103/22950 (epoch 2.403), train_loss = 2.01404885, grad/param norm = 2.9584e-01, time/batch = 0.6871s	
1104/22950 (epoch 2.405), train_loss = 1.96495800, grad/param norm = 2.9625e-01, time/batch = 0.6874s	
1105/22950 (epoch 2.407), train_loss = 2.11589278, grad/param norm = 3.4692e-01, time/batch = 0.6855s	
1106/22950 (epoch 2.410), train_loss = 1.84191012, grad/param norm = 3.0000e-01, time/batch = 0.6848s	
1107/22950 (epoch 2.412), train_loss = 2.05654184, grad/param norm = 3.0123e-01, time/batch = 0.6875s	
1108/22950 (epoch 2.414), train_loss = 2.03209700, grad/param norm = 2.7725e-01, time/batch = 0.6897s	
1109/22950 (epoch 2.416), train_loss = 2.11974156, grad/param norm = 2.9147e-01, time/batch = 0.6880s	
1110/22950 (epoch 2.418), train_loss = 2.09140355, grad/param norm = 3.0068e-01, time/batch = 0.6856s	
1111/22950 (epoch 2.420), train_loss = 2.05438022, grad/param norm = 2.4262e-01, time/batch = 0.7141s	
1112/22950 (epoch 2.423), train_loss = 1.92638968, grad/param norm = 2.8887e-01, time/batch = 0.7178s	
1113/22950 (epoch 2.425), train_loss = 2.02884919, grad/param norm = 2.8573e-01, time/batch = 0.7178s	
1114/22950 (epoch 2.427), train_loss = 1.95239949, grad/param norm = 3.3671e-01, time/batch = 0.6943s	
1115/22950 (epoch 2.429), train_loss = 1.87460281, grad/param norm = 2.7563e-01, time/batch = 0.6930s	
1116/22950 (epoch 2.431), train_loss = 2.02433992, grad/param norm = 3.4300e-01, time/batch = 0.6949s	
1117/22950 (epoch 2.434), train_loss = 1.99074284, grad/param norm = 3.3355e-01, time/batch = 0.7016s	
1118/22950 (epoch 2.436), train_loss = 2.23702938, grad/param norm = 2.7351e-01, time/batch = 0.7218s	
1119/22950 (epoch 2.438), train_loss = 2.04046323, grad/param norm = 3.0084e-01, time/batch = 0.7074s	
1120/22950 (epoch 2.440), train_loss = 2.04873228, grad/param norm = 2.4750e-01, time/batch = 0.6895s	
1121/22950 (epoch 2.442), train_loss = 2.19073254, grad/param norm = 2.7512e-01, time/batch = 0.6886s	
1122/22950 (epoch 2.444), train_loss = 2.21868531, grad/param norm = 3.1616e-01, time/batch = 0.7202s	
1123/22950 (epoch 2.447), train_loss = 2.13704182, grad/param norm = 3.9519e-01, time/batch = 0.6886s	
1124/22950 (epoch 2.449), train_loss = 1.89496911, grad/param norm = 3.1812e-01, time/batch = 0.6990s	
1125/22950 (epoch 2.451), train_loss = 2.04833047, grad/param norm = 2.9582e-01, time/batch = 0.6938s	
1126/22950 (epoch 2.453), train_loss = 2.09010544, grad/param norm = 2.7965e-01, time/batch = 0.6847s	
1127/22950 (epoch 2.455), train_loss = 1.91740906, grad/param norm = 2.7117e-01, time/batch = 0.6850s	
1128/22950 (epoch 2.458), train_loss = 2.19707165, grad/param norm = 2.9675e-01, time/batch = 0.6903s	
1129/22950 (epoch 2.460), train_loss = 2.09421160, grad/param norm = 2.8523e-01, time/batch = 0.6941s	
1130/22950 (epoch 2.462), train_loss = 2.00117588, grad/param norm = 2.8563e-01, time/batch = 0.6844s	
1131/22950 (epoch 2.464), train_loss = 2.03559281, grad/param norm = 3.0783e-01, time/batch = 0.6882s	
1132/22950 (epoch 2.466), train_loss = 1.96969928, grad/param norm = 2.9587e-01, time/batch = 0.6833s	
1133/22950 (epoch 2.468), train_loss = 2.11982532, grad/param norm = 2.3934e-01, time/batch = 0.6850s	
1134/22950 (epoch 2.471), train_loss = 1.91435474, grad/param norm = 2.7584e-01, time/batch = 0.6922s	
1135/22950 (epoch 2.473), train_loss = 2.00362010, grad/param norm = 3.0172e-01, time/batch = 0.7032s	
1136/22950 (epoch 2.475), train_loss = 2.20556365, grad/param norm = 3.9343e-01, time/batch = 0.6911s	
1137/22950 (epoch 2.477), train_loss = 2.09994994, grad/param norm = 3.5936e-01, time/batch = 0.6898s	
1138/22950 (epoch 2.479), train_loss = 2.11503615, grad/param norm = 3.1018e-01, time/batch = 0.6872s	
1139/22950 (epoch 2.481), train_loss = 2.20437300, grad/param norm = 3.5624e-01, time/batch = 0.6851s	
1140/22950 (epoch 2.484), train_loss = 2.29815048, grad/param norm = 3.5593e-01, time/batch = 0.6898s	
1141/22950 (epoch 2.486), train_loss = 1.89453086, grad/param norm = 3.0975e-01, time/batch = 0.6904s	
1142/22950 (epoch 2.488), train_loss = 1.94887646, grad/param norm = 3.0739e-01, time/batch = 0.6856s	
1143/22950 (epoch 2.490), train_loss = 2.02037822, grad/param norm = 2.7637e-01, time/batch = 0.6853s	
1144/22950 (epoch 2.492), train_loss = 2.02471628, grad/param norm = 2.2791e-01, time/batch = 0.6951s	
1145/22950 (epoch 2.495), train_loss = 2.07507396, grad/param norm = 3.0955e-01, time/batch = 0.7225s	
1146/22950 (epoch 2.497), train_loss = 2.05544804, grad/param norm = 2.2675e-01, time/batch = 0.6969s	
1147/22950 (epoch 2.499), train_loss = 2.05618402, grad/param norm = 2.7865e-01, time/batch = 0.6894s	
1148/22950 (epoch 2.501), train_loss = 2.13030716, grad/param norm = 2.5705e-01, time/batch = 0.6874s	
1149/22950 (epoch 2.503), train_loss = 2.07608562, grad/param norm = 2.7062e-01, time/batch = 0.6862s	
1150/22950 (epoch 2.505), train_loss = 1.91151707, grad/param norm = 2.4220e-01, time/batch = 0.6867s	
1151/22950 (epoch 2.508), train_loss = 2.02460125, grad/param norm = 2.6004e-01, time/batch = 0.6873s	
1152/22950 (epoch 2.510), train_loss = 1.96108249, grad/param norm = 2.4835e-01, time/batch = 0.6878s	
1153/22950 (epoch 2.512), train_loss = 2.03027768, grad/param norm = 3.1758e-01, time/batch = 0.6874s	
1154/22950 (epoch 2.514), train_loss = 1.80007951, grad/param norm = 4.2862e-01, time/batch = 0.6992s	
1155/22950 (epoch 2.516), train_loss = 1.88204467, grad/param norm = 3.3729e-01, time/batch = 0.7226s	
1156/22950 (epoch 2.519), train_loss = 1.95913804, grad/param norm = 2.5275e-01, time/batch = 0.6986s	
1157/22950 (epoch 2.521), train_loss = 1.93852589, grad/param norm = 2.2970e-01, time/batch = 0.6873s	
1158/22950 (epoch 2.523), train_loss = 1.82890981, grad/param norm = 2.5264e-01, time/batch = 0.6876s	
1159/22950 (epoch 2.525), train_loss = 1.98470299, grad/param norm = 3.1621e-01, time/batch = 0.6985s	
1160/22950 (epoch 2.527), train_loss = 1.83801668, grad/param norm = 3.1329e-01, time/batch = 0.6910s	
1161/22950 (epoch 2.529), train_loss = 2.04914503, grad/param norm = 2.6667e-01, time/batch = 0.6879s	
1162/22950 (epoch 2.532), train_loss = 1.99938694, grad/param norm = 2.4270e-01, time/batch = 0.6905s	
1163/22950 (epoch 2.534), train_loss = 2.06727745, grad/param norm = 2.6686e-01, time/batch = 0.6831s	
1164/22950 (epoch 2.536), train_loss = 2.00883096, grad/param norm = 2.9937e-01, time/batch = 0.6884s	
1165/22950 (epoch 2.538), train_loss = 2.01343944, grad/param norm = 3.1042e-01, time/batch = 0.7234s	
1166/22950 (epoch 2.540), train_loss = 1.91453661, grad/param norm = 2.6963e-01, time/batch = 0.6950s	
1167/22950 (epoch 2.542), train_loss = 2.15629349, grad/param norm = 2.6691e-01, time/batch = 0.6847s	
1168/22950 (epoch 2.545), train_loss = 1.93967093, grad/param norm = 2.5308e-01, time/batch = 0.6862s	
1169/22950 (epoch 2.547), train_loss = 1.94964152, grad/param norm = 2.7161e-01, time/batch = 0.6843s	
1170/22950 (epoch 2.549), train_loss = 1.91527158, grad/param norm = 2.6903e-01, time/batch = 0.6896s	
1171/22950 (epoch 2.551), train_loss = 2.07570226, grad/param norm = 3.8933e-01, time/batch = 0.7074s	
1172/22950 (epoch 2.553), train_loss = 1.97447159, grad/param norm = 3.4571e-01, time/batch = 0.6870s	
1173/22950 (epoch 2.556), train_loss = 2.03734544, grad/param norm = 2.3070e-01, time/batch = 0.6884s	
1174/22950 (epoch 2.558), train_loss = 1.98681408, grad/param norm = 2.5272e-01, time/batch = 0.6900s	
1175/22950 (epoch 2.560), train_loss = 1.97431608, grad/param norm = 2.3093e-01, time/batch = 0.7225s	
1176/22950 (epoch 2.562), train_loss = 1.86695121, grad/param norm = 2.8169e-01, time/batch = 0.6999s	
1177/22950 (epoch 2.564), train_loss = 2.20341016, grad/param norm = 2.9459e-01, time/batch = 0.6852s	
1178/22950 (epoch 2.566), train_loss = 2.00099809, grad/param norm = 2.5889e-01, time/batch = 0.6857s	
1179/22950 (epoch 2.569), train_loss = 2.17690958, grad/param norm = 3.3439e-01, time/batch = 0.6899s	
1180/22950 (epoch 2.571), train_loss = 1.86351003, grad/param norm = 2.5687e-01, time/batch = 0.6854s	
1181/22950 (epoch 2.573), train_loss = 1.99415202, grad/param norm = 2.7807e-01, time/batch = 0.6894s	
1182/22950 (epoch 2.575), train_loss = 2.39677858, grad/param norm = 3.1880e-01, time/batch = 0.6916s	
1183/22950 (epoch 2.577), train_loss = 2.04734821, grad/param norm = 3.1021e-01, time/batch = 0.6898s	
1184/22950 (epoch 2.580), train_loss = 2.09508722, grad/param norm = 2.9651e-01, time/batch = 0.6886s	
1185/22950 (epoch 2.582), train_loss = 2.18703101, grad/param norm = 2.6236e-01, time/batch = 0.6907s	
1186/22950 (epoch 2.584), train_loss = 1.80973785, grad/param norm = 2.9323e-01, time/batch = 0.6886s	
1187/22950 (epoch 2.586), train_loss = 1.94086277, grad/param norm = 3.1288e-01, time/batch = 0.6880s	
1188/22950 (epoch 2.588), train_loss = 2.13828672, grad/param norm = 3.3725e-01, time/batch = 0.6887s	
1189/22950 (epoch 2.590), train_loss = 1.91193843, grad/param norm = 2.8082e-01, time/batch = 0.6897s	
1190/22950 (epoch 2.593), train_loss = 1.79934601, grad/param norm = 2.5452e-01, time/batch = 0.6859s	
1191/22950 (epoch 2.595), train_loss = 1.91800424, grad/param norm = 2.6313e-01, time/batch = 0.6880s	
1192/22950 (epoch 2.597), train_loss = 2.05789029, grad/param norm = 2.7968e-01, time/batch = 0.6877s	
1193/22950 (epoch 2.599), train_loss = 2.03592922, grad/param norm = 2.9895e-01, time/batch = 0.6921s	
1194/22950 (epoch 2.601), train_loss = 2.00821095, grad/param norm = 2.7734e-01, time/batch = 0.6869s	
1195/22950 (epoch 2.603), train_loss = 2.11054116, grad/param norm = 2.9472e-01, time/batch = 0.6846s	
1196/22950 (epoch 2.606), train_loss = 1.94369751, grad/param norm = 2.6591e-01, time/batch = 0.6857s	
1197/22950 (epoch 2.608), train_loss = 1.89419710, grad/param norm = 2.4307e-01, time/batch = 0.7037s	
1198/22950 (epoch 2.610), train_loss = 1.95223299, grad/param norm = 2.9897e-01, time/batch = 0.7151s	
1199/22950 (epoch 2.612), train_loss = 2.03878362, grad/param norm = 2.6547e-01, time/batch = 0.7169s	
1200/22950 (epoch 2.614), train_loss = 2.13890895, grad/param norm = 2.6870e-01, time/batch = 0.6999s	
1201/22950 (epoch 2.617), train_loss = 2.02551505, grad/param norm = 2.3312e-01, time/batch = 0.7091s	
1202/22950 (epoch 2.619), train_loss = 1.87266465, grad/param norm = 2.4041e-01, time/batch = 0.7166s	
1203/22950 (epoch 2.621), train_loss = 2.07505034, grad/param norm = 2.3965e-01, time/batch = 0.6910s	
1204/22950 (epoch 2.623), train_loss = 1.94247474, grad/param norm = 2.7052e-01, time/batch = 0.7133s	
1205/22950 (epoch 2.625), train_loss = 1.97556740, grad/param norm = 2.4338e-01, time/batch = 0.7126s	
1206/22950 (epoch 2.627), train_loss = 1.96364228, grad/param norm = 2.6453e-01, time/batch = 0.7128s	
1207/22950 (epoch 2.630), train_loss = 1.83350237, grad/param norm = 2.6350e-01, time/batch = 0.6905s	
1208/22950 (epoch 2.632), train_loss = 2.03488790, grad/param norm = 2.3185e-01, time/batch = 0.7033s	
1209/22950 (epoch 2.634), train_loss = 1.92415778, grad/param norm = 2.3885e-01, time/batch = 0.7035s	
1210/22950 (epoch 2.636), train_loss = 1.93642038, grad/param norm = 2.2790e-01, time/batch = 0.6872s	
1211/22950 (epoch 2.638), train_loss = 1.88480593, grad/param norm = 2.8227e-01, time/batch = 0.6922s	
1212/22950 (epoch 2.641), train_loss = 1.95560473, grad/param norm = 2.4372e-01, time/batch = 0.6873s	
1213/22950 (epoch 2.643), train_loss = 1.97893032, grad/param norm = 2.7556e-01, time/batch = 0.6850s	
1214/22950 (epoch 2.645), train_loss = 1.93050013, grad/param norm = 3.8640e-01, time/batch = 0.6825s	
1215/22950 (epoch 2.647), train_loss = 2.00293337, grad/param norm = 3.6972e-01, time/batch = 0.6849s	
1216/22950 (epoch 2.649), train_loss = 2.01349055, grad/param norm = 2.4405e-01, time/batch = 0.6828s	
1217/22950 (epoch 2.651), train_loss = 2.04274011, grad/param norm = 2.4014e-01, time/batch = 0.6833s	
1218/22950 (epoch 2.654), train_loss = 1.78973657, grad/param norm = 2.3016e-01, time/batch = 0.6837s	
1219/22950 (epoch 2.656), train_loss = 2.04270469, grad/param norm = 2.5758e-01, time/batch = 0.6812s	
1220/22950 (epoch 2.658), train_loss = 1.92401068, grad/param norm = 2.4415e-01, time/batch = 0.6817s	
1221/22950 (epoch 2.660), train_loss = 1.77874670, grad/param norm = 2.8157e-01, time/batch = 0.6828s	
1222/22950 (epoch 2.662), train_loss = 1.86524853, grad/param norm = 2.5867e-01, time/batch = 0.6842s	
1223/22950 (epoch 2.664), train_loss = 2.01164947, grad/param norm = 2.6323e-01, time/batch = 0.6853s	
1224/22950 (epoch 2.667), train_loss = 2.01455610, grad/param norm = 2.5666e-01, time/batch = 0.6841s	
1225/22950 (epoch 2.669), train_loss = 1.84682855, grad/param norm = 2.4094e-01, time/batch = 0.6839s	
1226/22950 (epoch 2.671), train_loss = 2.04921463, grad/param norm = 2.5330e-01, time/batch = 0.6874s	
1227/22950 (epoch 2.673), train_loss = 2.03065670, grad/param norm = 2.3679e-01, time/batch = 0.6876s	
1228/22950 (epoch 2.675), train_loss = 1.94753591, grad/param norm = 2.6046e-01, time/batch = 0.6857s	
1229/22950 (epoch 2.678), train_loss = 2.00714481, grad/param norm = 2.7786e-01, time/batch = 0.6853s	
1230/22950 (epoch 2.680), train_loss = 1.98899972, grad/param norm = 2.4291e-01, time/batch = 0.6871s	
1231/22950 (epoch 2.682), train_loss = 2.07521311, grad/param norm = 2.3436e-01, time/batch = 0.6906s	
1232/22950 (epoch 2.684), train_loss = 2.01865675, grad/param norm = 2.0906e-01, time/batch = 0.6866s	
1233/22950 (epoch 2.686), train_loss = 1.99682515, grad/param norm = 2.2613e-01, time/batch = 0.6919s	
1234/22950 (epoch 2.688), train_loss = 1.96559206, grad/param norm = 2.7278e-01, time/batch = 0.6897s	
1235/22950 (epoch 2.691), train_loss = 1.88747866, grad/param norm = 3.2182e-01, time/batch = 0.6887s	
1236/22950 (epoch 2.693), train_loss = 1.93699391, grad/param norm = 2.9293e-01, time/batch = 0.6907s	
1237/22950 (epoch 2.695), train_loss = 2.16635313, grad/param norm = 3.4495e-01, time/batch = 0.6907s	
1238/22950 (epoch 2.697), train_loss = 2.08538278, grad/param norm = 2.7572e-01, time/batch = 0.6876s	
1239/22950 (epoch 2.699), train_loss = 2.00483823, grad/param norm = 2.2829e-01, time/batch = 0.6952s	
1240/22950 (epoch 2.702), train_loss = 1.98562141, grad/param norm = 2.2445e-01, time/batch = 0.6868s	
1241/22950 (epoch 2.704), train_loss = 2.07527398, grad/param norm = 2.7442e-01, time/batch = 0.6939s	
1242/22950 (epoch 2.706), train_loss = 2.10602040, grad/param norm = 2.9130e-01, time/batch = 0.6890s	
1243/22950 (epoch 2.708), train_loss = 2.02622153, grad/param norm = 3.6035e-01, time/batch = 0.6901s	
1244/22950 (epoch 2.710), train_loss = 2.02852031, grad/param norm = 2.5428e-01, time/batch = 0.6837s	
1245/22950 (epoch 2.712), train_loss = 2.04492961, grad/param norm = 2.2641e-01, time/batch = 0.6831s	
1246/22950 (epoch 2.715), train_loss = 1.99182276, grad/param norm = 2.3858e-01, time/batch = 0.6857s	
1247/22950 (epoch 2.717), train_loss = 1.75874504, grad/param norm = 2.2728e-01, time/batch = 0.6834s	
1248/22950 (epoch 2.719), train_loss = 2.04253520, grad/param norm = 2.5040e-01, time/batch = 0.6834s	
1249/22950 (epoch 2.721), train_loss = 2.01266959, grad/param norm = 2.7301e-01, time/batch = 0.6850s	
1250/22950 (epoch 2.723), train_loss = 1.91234932, grad/param norm = 2.2910e-01, time/batch = 0.6842s	
1251/22950 (epoch 2.725), train_loss = 2.16335459, grad/param norm = 3.0513e-01, time/batch = 0.6867s	
1252/22950 (epoch 2.728), train_loss = 1.95155723, grad/param norm = 3.0186e-01, time/batch = 0.6869s	
1253/22950 (epoch 2.730), train_loss = 1.92260232, grad/param norm = 2.8674e-01, time/batch = 0.6851s	
1254/22950 (epoch 2.732), train_loss = 1.95884425, grad/param norm = 2.2439e-01, time/batch = 0.6870s	
1255/22950 (epoch 2.734), train_loss = 1.98332020, grad/param norm = 2.2447e-01, time/batch = 0.6896s	
1256/22950 (epoch 2.736), train_loss = 1.83475460, grad/param norm = 2.2716e-01, time/batch = 0.6902s	
1257/22950 (epoch 2.739), train_loss = 2.00982586, grad/param norm = 2.6725e-01, time/batch = 0.6853s	
1258/22950 (epoch 2.741), train_loss = 1.97928202, grad/param norm = 2.6900e-01, time/batch = 0.6932s	
1259/22950 (epoch 2.743), train_loss = 2.14051783, grad/param norm = 2.8939e-01, time/batch = 0.6859s	
1260/22950 (epoch 2.745), train_loss = 2.15380594, grad/param norm = 2.7515e-01, time/batch = 0.6832s	
1261/22950 (epoch 2.747), train_loss = 1.93436506, grad/param norm = 2.9784e-01, time/batch = 0.6841s	
1262/22950 (epoch 2.749), train_loss = 1.93289265, grad/param norm = 3.0470e-01, time/batch = 0.6854s	
1263/22950 (epoch 2.752), train_loss = 2.09415082, grad/param norm = 2.4993e-01, time/batch = 0.6851s	
1264/22950 (epoch 2.754), train_loss = 2.06729137, grad/param norm = 2.7594e-01, time/batch = 0.6857s	
1265/22950 (epoch 2.756), train_loss = 1.82921408, grad/param norm = 2.5525e-01, time/batch = 0.6972s	
1266/22950 (epoch 2.758), train_loss = 1.91605492, grad/param norm = 2.4254e-01, time/batch = 0.6888s	
1267/22950 (epoch 2.760), train_loss = 1.92335957, grad/param norm = 2.4078e-01, time/batch = 0.6873s	
1268/22950 (epoch 2.763), train_loss = 1.95087356, grad/param norm = 2.8265e-01, time/batch = 0.6847s	
1269/22950 (epoch 2.765), train_loss = 2.01379303, grad/param norm = 2.6789e-01, time/batch = 0.6890s	
1270/22950 (epoch 2.767), train_loss = 1.99355584, grad/param norm = 2.3799e-01, time/batch = 0.6872s	
1271/22950 (epoch 2.769), train_loss = 1.96140136, grad/param norm = 2.5807e-01, time/batch = 0.6926s	
1272/22950 (epoch 2.771), train_loss = 1.77569425, grad/param norm = 2.2835e-01, time/batch = 0.6869s	
1273/22950 (epoch 2.773), train_loss = 1.76655445, grad/param norm = 2.6598e-01, time/batch = 0.6876s	
1274/22950 (epoch 2.776), train_loss = 1.90226912, grad/param norm = 2.4779e-01, time/batch = 0.7082s	
1275/22950 (epoch 2.778), train_loss = 1.81619765, grad/param norm = 2.4144e-01, time/batch = 0.7164s	
1276/22950 (epoch 2.780), train_loss = 1.79953191, grad/param norm = 3.0913e-01, time/batch = 0.6889s	
1277/22950 (epoch 2.782), train_loss = 1.90060780, grad/param norm = 2.9730e-01, time/batch = 0.6892s	
1278/22950 (epoch 2.784), train_loss = 2.02391595, grad/param norm = 2.9008e-01, time/batch = 0.6870s	
1279/22950 (epoch 2.786), train_loss = 1.97121445, grad/param norm = 2.3924e-01, time/batch = 0.6878s	
1280/22950 (epoch 2.789), train_loss = 1.81275794, grad/param norm = 2.1489e-01, time/batch = 0.6880s	
1281/22950 (epoch 2.791), train_loss = 1.83329104, grad/param norm = 2.2805e-01, time/batch = 0.6883s	
1282/22950 (epoch 2.793), train_loss = 2.18457909, grad/param norm = 2.3809e-01, time/batch = 0.6884s	
1283/22950 (epoch 2.795), train_loss = 1.84636819, grad/param norm = 2.3298e-01, time/batch = 0.6917s	
1284/22950 (epoch 2.797), train_loss = 2.11571310, grad/param norm = 2.7544e-01, time/batch = 0.7124s	
1285/22950 (epoch 2.800), train_loss = 1.88133976, grad/param norm = 3.4430e-01, time/batch = 0.7258s	
1286/22950 (epoch 2.802), train_loss = 1.88715215, grad/param norm = 2.7075e-01, time/batch = 0.7285s	
1287/22950 (epoch 2.804), train_loss = 1.87893116, grad/param norm = 2.5328e-01, time/batch = 0.7281s	
1288/22950 (epoch 2.806), train_loss = 1.88516672, grad/param norm = 2.9238e-01, time/batch = 0.7167s	
1289/22950 (epoch 2.808), train_loss = 1.96320222, grad/param norm = 3.0411e-01, time/batch = 0.7187s	
1290/22950 (epoch 2.810), train_loss = 1.96949353, grad/param norm = 3.2506e-01, time/batch = 0.7010s	
1291/22950 (epoch 2.813), train_loss = 1.72328890, grad/param norm = 2.5878e-01, time/batch = 0.6919s	
1292/22950 (epoch 2.815), train_loss = 1.98680844, grad/param norm = 2.6123e-01, time/batch = 0.6874s	
1293/22950 (epoch 2.817), train_loss = 1.84713537, grad/param norm = 2.7661e-01, time/batch = 0.6897s	
1294/22950 (epoch 2.819), train_loss = 1.90327357, grad/param norm = 2.5101e-01, time/batch = 0.7059s	
1295/22950 (epoch 2.821), train_loss = 1.88751929, grad/param norm = 2.7852e-01, time/batch = 0.7079s	
1296/22950 (epoch 2.824), train_loss = 1.85997190, grad/param norm = 2.6874e-01, time/batch = 0.6883s	
1297/22950 (epoch 2.826), train_loss = 2.01060459, grad/param norm = 2.4270e-01, time/batch = 0.6893s	
1298/22950 (epoch 2.828), train_loss = 1.89715809, grad/param norm = 2.4706e-01, time/batch = 0.6936s	
1299/22950 (epoch 2.830), train_loss = 1.97747953, grad/param norm = 2.3694e-01, time/batch = 0.6886s	
1300/22950 (epoch 2.832), train_loss = 1.92934541, grad/param norm = 2.3519e-01, time/batch = 0.6908s	
1301/22950 (epoch 2.834), train_loss = 1.79697656, grad/param norm = 2.3120e-01, time/batch = 0.7035s	
1302/22950 (epoch 2.837), train_loss = 1.89607354, grad/param norm = 2.4375e-01, time/batch = 0.7106s	
1303/22950 (epoch 2.839), train_loss = 1.94459099, grad/param norm = 2.5515e-01, time/batch = 0.6999s	
1304/22950 (epoch 2.841), train_loss = 1.84815899, grad/param norm = 2.4531e-01, time/batch = 0.6891s	
1305/22950 (epoch 2.843), train_loss = 1.84635971, grad/param norm = 2.4049e-01, time/batch = 0.6869s	
1306/22950 (epoch 2.845), train_loss = 1.96432667, grad/param norm = 2.4996e-01, time/batch = 0.6904s	
1307/22950 (epoch 2.847), train_loss = 2.02376009, grad/param norm = 2.2366e-01, time/batch = 0.6870s	
1308/22950 (epoch 2.850), train_loss = 1.97158776, grad/param norm = 2.7761e-01, time/batch = 0.6883s	
1309/22950 (epoch 2.852), train_loss = 2.01077567, grad/param norm = 2.8903e-01, time/batch = 0.6876s	
1310/22950 (epoch 2.854), train_loss = 1.91079056, grad/param norm = 2.6474e-01, time/batch = 0.6886s	
1311/22950 (epoch 2.856), train_loss = 2.17324310, grad/param norm = 2.6534e-01, time/batch = 0.6898s	
1312/22950 (epoch 2.858), train_loss = 1.92756954, grad/param norm = 2.4928e-01, time/batch = 0.6879s	
1313/22950 (epoch 2.861), train_loss = 2.01770770, grad/param norm = 2.9750e-01, time/batch = 0.6891s	
1314/22950 (epoch 2.863), train_loss = 2.08729713, grad/param norm = 2.7505e-01, time/batch = 0.7070s	
1315/22950 (epoch 2.865), train_loss = 2.05487449, grad/param norm = 2.5628e-01, time/batch = 0.7152s	
1316/22950 (epoch 2.867), train_loss = 1.99286716, grad/param norm = 2.5030e-01, time/batch = 0.6881s	
1317/22950 (epoch 2.869), train_loss = 2.11761118, grad/param norm = 2.4231e-01, time/batch = 0.6861s	
1318/22950 (epoch 2.871), train_loss = 1.90147891, grad/param norm = 2.5321e-01, time/batch = 0.6833s	
1319/22950 (epoch 2.874), train_loss = 1.91077649, grad/param norm = 2.6768e-01, time/batch = 0.6844s	
1320/22950 (epoch 2.876), train_loss = 2.01544490, grad/param norm = 2.6738e-01, time/batch = 0.6844s	
1321/22950 (epoch 2.878), train_loss = 1.84774539, grad/param norm = 2.8015e-01, time/batch = 0.6872s	
1322/22950 (epoch 2.880), train_loss = 2.06770617, grad/param norm = 2.8609e-01, time/batch = 0.6855s	
1323/22950 (epoch 2.882), train_loss = 1.75623566, grad/param norm = 2.1157e-01, time/batch = 0.6929s	
1324/22950 (epoch 2.885), train_loss = 1.96925887, grad/param norm = 2.5965e-01, time/batch = 0.7150s	
1325/22950 (epoch 2.887), train_loss = 1.95511838, grad/param norm = 2.7335e-01, time/batch = 0.7210s	
1326/22950 (epoch 2.889), train_loss = 2.11792837, grad/param norm = 3.2789e-01, time/batch = 0.6970s	
1327/22950 (epoch 2.891), train_loss = 2.01881645, grad/param norm = 2.5775e-01, time/batch = 0.6894s	
1328/22950 (epoch 2.893), train_loss = 1.96825084, grad/param norm = 2.4636e-01, time/batch = 0.6904s	
1329/22950 (epoch 2.895), train_loss = 2.06910577, grad/param norm = 2.5131e-01, time/batch = 0.6849s	
1330/22950 (epoch 2.898), train_loss = 1.92136446, grad/param norm = 2.4871e-01, time/batch = 0.6843s	
1331/22950 (epoch 2.900), train_loss = 1.80717801, grad/param norm = 2.4534e-01, time/batch = 0.6876s	
1332/22950 (epoch 2.902), train_loss = 1.87474722, grad/param norm = 2.2057e-01, time/batch = 0.6917s	
1333/22950 (epoch 2.904), train_loss = 1.91725472, grad/param norm = 2.1827e-01, time/batch = 0.6844s	
1334/22950 (epoch 2.906), train_loss = 2.01031551, grad/param norm = 2.2598e-01, time/batch = 0.6998s	
1335/22950 (epoch 2.908), train_loss = 1.79763683, grad/param norm = 2.4927e-01, time/batch = 0.7232s	
1336/22950 (epoch 2.911), train_loss = 1.76964798, grad/param norm = 2.4318e-01, time/batch = 0.6945s	
1337/22950 (epoch 2.913), train_loss = 1.79963046, grad/param norm = 2.1511e-01, time/batch = 0.6884s	
1338/22950 (epoch 2.915), train_loss = 2.14918827, grad/param norm = 2.9462e-01, time/batch = 0.6914s	
1339/22950 (epoch 2.917), train_loss = 1.93056625, grad/param norm = 2.9887e-01, time/batch = 0.7223s	
1340/22950 (epoch 2.919), train_loss = 1.96619689, grad/param norm = 3.1169e-01, time/batch = 0.7128s	
1341/22950 (epoch 2.922), train_loss = 1.88447400, grad/param norm = 3.0147e-01, time/batch = 0.6856s	
1342/22950 (epoch 2.924), train_loss = 2.00746028, grad/param norm = 2.5341e-01, time/batch = 0.6897s	
1343/22950 (epoch 2.926), train_loss = 1.80581352, grad/param norm = 3.0171e-01, time/batch = 0.6895s	
1344/22950 (epoch 2.928), train_loss = 1.80091438, grad/param norm = 3.4502e-01, time/batch = 0.6849s	
1345/22950 (epoch 2.930), train_loss = 1.80267372, grad/param norm = 2.7276e-01, time/batch = 0.6944s	
1346/22950 (epoch 2.932), train_loss = 1.89031053, grad/param norm = 2.8198e-01, time/batch = 0.6877s	
1347/22950 (epoch 2.935), train_loss = 1.90012549, grad/param norm = 2.5296e-01, time/batch = 0.6825s	
1348/22950 (epoch 2.937), train_loss = 1.93328543, grad/param norm = 2.5882e-01, time/batch = 0.6833s	
1349/22950 (epoch 2.939), train_loss = 1.90762006, grad/param norm = 2.6190e-01, time/batch = 0.6832s	
1350/22950 (epoch 2.941), train_loss = 1.81160164, grad/param norm = 2.2248e-01, time/batch = 0.6818s	
1351/22950 (epoch 2.943), train_loss = 1.96329070, grad/param norm = 2.7627e-01, time/batch = 0.6895s	
1352/22950 (epoch 2.946), train_loss = 1.74628509, grad/param norm = 2.5658e-01, time/batch = 0.6994s	
1353/22950 (epoch 2.948), train_loss = 1.98369673, grad/param norm = 2.8715e-01, time/batch = 0.7021s	
1354/22950 (epoch 2.950), train_loss = 1.96815184, grad/param norm = 3.0950e-01, time/batch = 0.7015s	
1355/22950 (epoch 2.952), train_loss = 1.97605652, grad/param norm = 2.5307e-01, time/batch = 0.7060s	
1356/22950 (epoch 2.954), train_loss = 1.85916440, grad/param norm = 2.3927e-01, time/batch = 0.7009s	
1357/22950 (epoch 2.956), train_loss = 1.83142344, grad/param norm = 2.1730e-01, time/batch = 0.7039s	
1358/22950 (epoch 2.959), train_loss = 1.79136581, grad/param norm = 2.7371e-01, time/batch = 0.6956s	
1359/22950 (epoch 2.961), train_loss = 1.88188557, grad/param norm = 2.5279e-01, time/batch = 0.7027s	
1360/22950 (epoch 2.963), train_loss = 2.02910891, grad/param norm = 2.8532e-01, time/batch = 0.6929s	
1361/22950 (epoch 2.965), train_loss = 2.10042400, grad/param norm = 2.3849e-01, time/batch = 0.6864s	
1362/22950 (epoch 2.967), train_loss = 1.86385519, grad/param norm = 2.5450e-01, time/batch = 0.6842s	
1363/22950 (epoch 2.969), train_loss = 1.82984576, grad/param norm = 2.2013e-01, time/batch = 0.6889s	
1364/22950 (epoch 2.972), train_loss = 1.86779952, grad/param norm = 2.6028e-01, time/batch = 0.6849s	
1365/22950 (epoch 2.974), train_loss = 1.76932994, grad/param norm = 2.3400e-01, time/batch = 0.6872s	
1366/22950 (epoch 2.976), train_loss = 1.75708036, grad/param norm = 2.9954e-01, time/batch = 0.6917s	
1367/22950 (epoch 2.978), train_loss = 1.96013683, grad/param norm = 2.6168e-01, time/batch = 0.6896s	
1368/22950 (epoch 2.980), train_loss = 1.92807424, grad/param norm = 2.5648e-01, time/batch = 0.6878s	
1369/22950 (epoch 2.983), train_loss = 1.77842868, grad/param norm = 2.5363e-01, time/batch = 0.6944s	
1370/22950 (epoch 2.985), train_loss = 1.78536201, grad/param norm = 2.7050e-01, time/batch = 0.7188s	
1371/22950 (epoch 2.987), train_loss = 1.87985156, grad/param norm = 2.6813e-01, time/batch = 0.7232s	
1372/22950 (epoch 2.989), train_loss = 1.99392609, grad/param norm = 2.9480e-01, time/batch = 0.7023s	
1373/22950 (epoch 2.991), train_loss = 1.87216644, grad/param norm = 2.4854e-01, time/batch = 0.6957s	
1374/22950 (epoch 2.993), train_loss = 1.92115375, grad/param norm = 2.7083e-01, time/batch = 0.6924s	
1375/22950 (epoch 2.996), train_loss = 2.03031894, grad/param norm = 2.7240e-01, time/batch = 0.6957s	
1376/22950 (epoch 2.998), train_loss = 1.79451547, grad/param norm = 2.1713e-01, time/batch = 0.6941s	
1377/22950 (epoch 3.000), train_loss = 1.75194669, grad/param norm = 2.3409e-01, time/batch = 0.6994s	
1378/22950 (epoch 3.002), train_loss = 2.11015607, grad/param norm = 2.5622e-01, time/batch = 0.6939s	
1379/22950 (epoch 3.004), train_loss = 1.97281994, grad/param norm = 2.5389e-01, time/batch = 0.6902s	
1380/22950 (epoch 3.007), train_loss = 1.86419461, grad/param norm = 2.4827e-01, time/batch = 0.6869s	
1381/22950 (epoch 3.009), train_loss = 2.02320933, grad/param norm = 2.2795e-01, time/batch = 0.6913s	
1382/22950 (epoch 3.011), train_loss = 2.00968821, grad/param norm = 2.9658e-01, time/batch = 0.6879s	
1383/22950 (epoch 3.013), train_loss = 2.06406420, grad/param norm = 2.8237e-01, time/batch = 0.6865s	
1384/22950 (epoch 3.015), train_loss = 2.01217338, grad/param norm = 2.9723e-01, time/batch = 0.6968s	
1385/22950 (epoch 3.017), train_loss = 1.85281236, grad/param norm = 3.1042e-01, time/batch = 0.6936s	
1386/22950 (epoch 3.020), train_loss = 1.90083527, grad/param norm = 2.6040e-01, time/batch = 0.6967s	
1387/22950 (epoch 3.022), train_loss = 1.71482036, grad/param norm = 2.2688e-01, time/batch = 0.6908s	
1388/22950 (epoch 3.024), train_loss = 1.88530118, grad/param norm = 2.4258e-01, time/batch = 0.6886s	
1389/22950 (epoch 3.026), train_loss = 1.84155643, grad/param norm = 2.3826e-01, time/batch = 0.6881s	
1390/22950 (epoch 3.028), train_loss = 1.95056813, grad/param norm = 3.3953e-01, time/batch = 0.7016s	
1391/22950 (epoch 3.031), train_loss = 1.88005501, grad/param norm = 2.5515e-01, time/batch = 0.6917s	
1392/22950 (epoch 3.033), train_loss = 2.14140011, grad/param norm = 2.5637e-01, time/batch = 0.6882s	
1393/22950 (epoch 3.035), train_loss = 1.91784769, grad/param norm = 2.5315e-01, time/batch = 0.6892s	
1394/22950 (epoch 3.037), train_loss = 1.80951680, grad/param norm = 2.0696e-01, time/batch = 0.6903s	
1395/22950 (epoch 3.039), train_loss = 1.88301574, grad/param norm = 2.3254e-01, time/batch = 0.6901s	
1396/22950 (epoch 3.041), train_loss = 1.98696890, grad/param norm = 2.9029e-01, time/batch = 0.6909s	
1397/22950 (epoch 3.044), train_loss = 1.79461499, grad/param norm = 2.6194e-01, time/batch = 0.6872s	
1398/22950 (epoch 3.046), train_loss = 1.84283327, grad/param norm = 2.6657e-01, time/batch = 0.6872s	
1399/22950 (epoch 3.048), train_loss = 1.91700677, grad/param norm = 2.3414e-01, time/batch = 0.6937s	
1400/22950 (epoch 3.050), train_loss = 1.95262460, grad/param norm = 2.3151e-01, time/batch = 0.7158s	
1401/22950 (epoch 3.052), train_loss = 1.89121672, grad/param norm = 2.4787e-01, time/batch = 0.7115s	
1402/22950 (epoch 3.054), train_loss = 2.12891056, grad/param norm = 2.8688e-01, time/batch = 0.7101s	
1403/22950 (epoch 3.057), train_loss = 1.89032372, grad/param norm = 2.6556e-01, time/batch = 0.6975s	
1404/22950 (epoch 3.059), train_loss = 1.94557428, grad/param norm = 2.2733e-01, time/batch = 0.6933s	
1405/22950 (epoch 3.061), train_loss = 1.79513940, grad/param norm = 2.2831e-01, time/batch = 0.7038s	
1406/22950 (epoch 3.063), train_loss = 1.94790923, grad/param norm = 2.3506e-01, time/batch = 0.6910s	
1407/22950 (epoch 3.065), train_loss = 1.54456991, grad/param norm = 2.6404e-01, time/batch = 0.6905s	
1408/22950 (epoch 3.068), train_loss = 2.05951079, grad/param norm = 2.4814e-01, time/batch = 0.6921s	
1409/22950 (epoch 3.070), train_loss = 1.82983116, grad/param norm = 2.8206e-01, time/batch = 0.6934s	
1410/22950 (epoch 3.072), train_loss = 1.86243780, grad/param norm = 2.9463e-01, time/batch = 0.6917s	
1411/22950 (epoch 3.074), train_loss = 1.84688959, grad/param norm = 2.5678e-01, time/batch = 0.6949s	
1412/22950 (epoch 3.076), train_loss = 1.82832362, grad/param norm = 2.4195e-01, time/batch = 0.6930s	
1413/22950 (epoch 3.078), train_loss = 1.90443708, grad/param norm = 2.4954e-01, time/batch = 0.6935s	
1414/22950 (epoch 3.081), train_loss = 1.96165127, grad/param norm = 2.5874e-01, time/batch = 0.6928s	
1415/22950 (epoch 3.083), train_loss = 1.88227812, grad/param norm = 2.9529e-01, time/batch = 0.6935s	
1416/22950 (epoch 3.085), train_loss = 1.78500112, grad/param norm = 2.5716e-01, time/batch = 0.6891s	
1417/22950 (epoch 3.087), train_loss = 1.83481112, grad/param norm = 2.4193e-01, time/batch = 0.6952s	
1418/22950 (epoch 3.089), train_loss = 1.85125864, grad/param norm = 2.2326e-01, time/batch = 0.6939s	
1419/22950 (epoch 3.092), train_loss = 1.90218241, grad/param norm = 2.5889e-01, time/batch = 0.6930s	
1420/22950 (epoch 3.094), train_loss = 1.80381562, grad/param norm = 2.5038e-01, time/batch = 0.6990s	
1421/22950 (epoch 3.096), train_loss = 2.03786724, grad/param norm = 2.4445e-01, time/batch = 0.6941s	
1422/22950 (epoch 3.098), train_loss = 1.91728562, grad/param norm = 2.4456e-01, time/batch = 0.6999s	
1423/22950 (epoch 3.100), train_loss = 1.83401062, grad/param norm = 2.2490e-01, time/batch = 0.6915s	
1424/22950 (epoch 3.102), train_loss = 1.88082830, grad/param norm = 2.1320e-01, time/batch = 0.7003s	
1425/22950 (epoch 3.105), train_loss = 1.80104422, grad/param norm = 2.2009e-01, time/batch = 0.7274s	
1426/22950 (epoch 3.107), train_loss = 1.89301513, grad/param norm = 2.7964e-01, time/batch = 0.6955s	
1427/22950 (epoch 3.109), train_loss = 1.85933771, grad/param norm = 2.9689e-01, time/batch = 0.6901s	
1428/22950 (epoch 3.111), train_loss = 1.72426478, grad/param norm = 2.1234e-01, time/batch = 0.6949s	
1429/22950 (epoch 3.113), train_loss = 1.88661754, grad/param norm = 2.4347e-01, time/batch = 0.6945s	
1430/22950 (epoch 3.115), train_loss = 1.99427387, grad/param norm = 2.6169e-01, time/batch = 0.6988s	
1431/22950 (epoch 3.118), train_loss = 1.97569632, grad/param norm = 2.5710e-01, time/batch = 0.6969s	
1432/22950 (epoch 3.120), train_loss = 1.82549280, grad/param norm = 2.4257e-01, time/batch = 0.6910s	
1433/22950 (epoch 3.122), train_loss = 1.94134561, grad/param norm = 2.7051e-01, time/batch = 0.6935s	
1434/22950 (epoch 3.124), train_loss = 1.67082471, grad/param norm = 2.3308e-01, time/batch = 0.7050s	
1435/22950 (epoch 3.126), train_loss = 1.80702171, grad/param norm = 2.2063e-01, time/batch = 0.7288s	
1436/22950 (epoch 3.129), train_loss = 1.65111254, grad/param norm = 2.3446e-01, time/batch = 0.6959s	
1437/22950 (epoch 3.131), train_loss = 1.91302511, grad/param norm = 3.0054e-01, time/batch = 0.6903s	
1438/22950 (epoch 3.133), train_loss = 2.00995485, grad/param norm = 2.4205e-01, time/batch = 0.6896s	
1439/22950 (epoch 3.135), train_loss = 1.85710417, grad/param norm = 2.4483e-01, time/batch = 0.6892s	
1440/22950 (epoch 3.137), train_loss = 2.10020689, grad/param norm = 2.3166e-01, time/batch = 0.6901s	
1441/22950 (epoch 3.139), train_loss = 1.81219869, grad/param norm = 2.7123e-01, time/batch = 0.6953s	
1442/22950 (epoch 3.142), train_loss = 1.75944942, grad/param norm = 2.9711e-01, time/batch = 0.6920s	
1443/22950 (epoch 3.144), train_loss = 1.74650503, grad/param norm = 2.4497e-01, time/batch = 0.6939s	
1444/22950 (epoch 3.146), train_loss = 1.93909535, grad/param norm = 2.6919e-01, time/batch = 0.6979s	
1445/22950 (epoch 3.148), train_loss = 1.79582276, grad/param norm = 2.3666e-01, time/batch = 0.7285s	
1446/22950 (epoch 3.150), train_loss = 1.84816240, grad/param norm = 2.3693e-01, time/batch = 0.6983s	
1447/22950 (epoch 3.153), train_loss = 1.83160056, grad/param norm = 2.6197e-01, time/batch = 0.6901s	
1448/22950 (epoch 3.155), train_loss = 1.80922773, grad/param norm = 2.4758e-01, time/batch = 0.6922s	
1449/22950 (epoch 3.157), train_loss = 1.79957534, grad/param norm = 2.8172e-01, time/batch = 0.6901s	
1450/22950 (epoch 3.159), train_loss = 1.71908572, grad/param norm = 2.6077e-01, time/batch = 0.6883s	
1451/22950 (epoch 3.161), train_loss = 1.95274410, grad/param norm = 2.4234e-01, time/batch = 0.6931s	
1452/22950 (epoch 3.163), train_loss = 1.88656518, grad/param norm = 2.1096e-01, time/batch = 0.6940s	
1453/22950 (epoch 3.166), train_loss = 1.99583545, grad/param norm = 2.3681e-01, time/batch = 0.6933s	
1454/22950 (epoch 3.168), train_loss = 2.02858113, grad/param norm = 4.0666e-01, time/batch = 0.6990s	
1455/22950 (epoch 3.170), train_loss = 1.94414348, grad/param norm = 2.6826e-01, time/batch = 0.7275s	
1456/22950 (epoch 3.172), train_loss = 1.85142205, grad/param norm = 2.3630e-01, time/batch = 0.7060s	
1457/22950 (epoch 3.174), train_loss = 1.89263138, grad/param norm = 2.7080e-01, time/batch = 0.7040s	
1458/22950 (epoch 3.176), train_loss = 2.01917848, grad/param norm = 2.2003e-01, time/batch = 0.7029s	
1459/22950 (epoch 3.179), train_loss = 1.95434421, grad/param norm = 2.8347e-01, time/batch = 0.7029s	
1460/22950 (epoch 3.181), train_loss = 2.03201664, grad/param norm = 2.8349e-01, time/batch = 0.7090s	
1461/22950 (epoch 3.183), train_loss = 1.95606252, grad/param norm = 2.6482e-01, time/batch = 0.7137s	
1462/22950 (epoch 3.185), train_loss = 1.92450337, grad/param norm = 2.4803e-01, time/batch = 0.7046s	
1463/22950 (epoch 3.187), train_loss = 1.80737079, grad/param norm = 2.8862e-01, time/batch = 0.7059s	
1464/22950 (epoch 3.190), train_loss = 1.95669959, grad/param norm = 3.6253e-01, time/batch = 0.7236s	
1465/22950 (epoch 3.192), train_loss = 1.80310625, grad/param norm = 2.4098e-01, time/batch = 0.7028s	
1466/22950 (epoch 3.194), train_loss = 1.88907907, grad/param norm = 2.5875e-01, time/batch = 0.6809s	
1467/22950 (epoch 3.196), train_loss = 1.68021882, grad/param norm = 2.5059e-01, time/batch = 0.6773s	
1468/22950 (epoch 3.198), train_loss = 2.02754876, grad/param norm = 2.3760e-01, time/batch = 0.6745s	
1469/22950 (epoch 3.200), train_loss = 1.70283129, grad/param norm = 2.4200e-01, time/batch = 0.6731s	
1470/22950 (epoch 3.203), train_loss = 1.68839286, grad/param norm = 2.5372e-01, time/batch = 0.6762s	
1471/22950 (epoch 3.205), train_loss = 1.78696574, grad/param norm = 3.0710e-01, time/batch = 0.6834s	
1472/22950 (epoch 3.207), train_loss = 1.87483841, grad/param norm = 2.5486e-01, time/batch = 0.6727s	
1473/22950 (epoch 3.209), train_loss = 2.13219287, grad/param norm = 2.9323e-01, time/batch = 0.6731s	
1474/22950 (epoch 3.211), train_loss = 1.83872965, grad/param norm = 2.7956e-01, time/batch = 0.6768s	
1475/22950 (epoch 3.214), train_loss = 1.80541114, grad/param norm = 2.6537e-01, time/batch = 0.7087s	
1476/22950 (epoch 3.216), train_loss = 1.87890438, grad/param norm = 2.4018e-01, time/batch = 0.6919s	
1477/22950 (epoch 3.218), train_loss = 1.89791872, grad/param norm = 2.4524e-01, time/batch = 0.6730s	
1478/22950 (epoch 3.220), train_loss = 1.99505826, grad/param norm = 2.6241e-01, time/batch = 0.6674s	
1479/22950 (epoch 3.222), train_loss = 1.95842057, grad/param norm = 2.2550e-01, time/batch = 0.6720s	
1480/22950 (epoch 3.224), train_loss = 1.79110905, grad/param norm = 2.3571e-01, time/batch = 0.7032s	
1481/22950 (epoch 3.227), train_loss = 1.77571232, grad/param norm = 2.5947e-01, time/batch = 0.7090s	
1482/22950 (epoch 3.229), train_loss = 1.85452322, grad/param norm = 3.2370e-01, time/batch = 0.6907s	
1483/22950 (epoch 3.231), train_loss = 1.73750696, grad/param norm = 2.6818e-01, time/batch = 0.6888s	
1484/22950 (epoch 3.233), train_loss = 1.82010104, grad/param norm = 2.3654e-01, time/batch = 0.6747s	
1485/22950 (epoch 3.235), train_loss = 1.97249405, grad/param norm = 2.3782e-01, time/batch = 0.6744s	
1486/22950 (epoch 3.237), train_loss = 1.66399059, grad/param norm = 2.5730e-01, time/batch = 0.6758s	
1487/22950 (epoch 3.240), train_loss = 1.75621196, grad/param norm = 2.2140e-01, time/batch = 0.6724s	
1488/22950 (epoch 3.242), train_loss = 1.84391494, grad/param norm = 2.7173e-01, time/batch = 0.6772s	
1489/22950 (epoch 3.244), train_loss = 2.00614517, grad/param norm = 2.9164e-01, time/batch = 0.6787s	
1490/22950 (epoch 3.246), train_loss = 1.92900640, grad/param norm = 2.3928e-01, time/batch = 0.6776s	
1491/22950 (epoch 3.248), train_loss = 1.86117145, grad/param norm = 2.4763e-01, time/batch = 0.6865s	
1492/22950 (epoch 3.251), train_loss = 1.89535642, grad/param norm = 2.6792e-01, time/batch = 0.6991s	
1493/22950 (epoch 3.253), train_loss = 1.91404901, grad/param norm = 2.8144e-01, time/batch = 0.6965s	
1494/22950 (epoch 3.255), train_loss = 1.76958968, grad/param norm = 2.2500e-01, time/batch = 0.7040s	
1495/22950 (epoch 3.257), train_loss = 1.99615427, grad/param norm = 2.4465e-01, time/batch = 0.6981s	
1496/22950 (epoch 3.259), train_loss = 1.67507024, grad/param norm = 2.5005e-01, time/batch = 0.7078s	
1497/22950 (epoch 3.261), train_loss = 1.99040149, grad/param norm = 2.5953e-01, time/batch = 0.7135s	
1498/22950 (epoch 3.264), train_loss = 1.77489475, grad/param norm = 2.1593e-01, time/batch = 0.7020s	
1499/22950 (epoch 3.266), train_loss = 2.01767890, grad/param norm = 2.6986e-01, time/batch = 0.7052s	
1500/22950 (epoch 3.268), train_loss = 1.98731056, grad/param norm = 2.3869e-01, time/batch = 0.6987s	
1501/22950 (epoch 3.270), train_loss = 1.97306281, grad/param norm = 2.6091e-01, time/batch = 0.7099s	
1502/22950 (epoch 3.272), train_loss = 2.04421978, grad/param norm = 2.3269e-01, time/batch = 0.6995s	
1503/22950 (epoch 3.275), train_loss = 1.72791404, grad/param norm = 2.4871e-01, time/batch = 0.7114s	
1504/22950 (epoch 3.277), train_loss = 1.79943731, grad/param norm = 2.9423e-01, time/batch = 0.7327s	
1505/22950 (epoch 3.279), train_loss = 1.96070735, grad/param norm = 2.7431e-01, time/batch = 0.7246s	
1506/22950 (epoch 3.281), train_loss = 1.86391792, grad/param norm = 3.1512e-01, time/batch = 0.7114s	
1507/22950 (epoch 3.283), train_loss = 1.79655147, grad/param norm = 3.0494e-01, time/batch = 0.7125s	
1508/22950 (epoch 3.285), train_loss = 1.87105192, grad/param norm = 2.6844e-01, time/batch = 0.7005s	
1509/22950 (epoch 3.288), train_loss = 1.81089796, grad/param norm = 2.7857e-01, time/batch = 0.6946s	
1510/22950 (epoch 3.290), train_loss = 1.78757935, grad/param norm = 2.2605e-01, time/batch = 0.7111s	
1511/22950 (epoch 3.292), train_loss = 1.88206023, grad/param norm = 2.2047e-01, time/batch = 0.7037s	
1512/22950 (epoch 3.294), train_loss = 1.93476554, grad/param norm = 2.6000e-01, time/batch = 0.6939s	
1513/22950 (epoch 3.296), train_loss = 1.62915081, grad/param norm = 2.3057e-01, time/batch = 0.6949s	
1514/22950 (epoch 3.298), train_loss = 1.80060905, grad/param norm = 2.4033e-01, time/batch = 0.7018s	
1515/22950 (epoch 3.301), train_loss = 1.90994294, grad/param norm = 2.8792e-01, time/batch = 0.7282s	
1516/22950 (epoch 3.303), train_loss = 1.93968136, grad/param norm = 2.6927e-01, time/batch = 0.7007s	
1517/22950 (epoch 3.305), train_loss = 2.01658022, grad/param norm = 2.4898e-01, time/batch = 0.6909s	
1518/22950 (epoch 3.307), train_loss = 1.96773788, grad/param norm = 2.8428e-01, time/batch = 0.6987s	
1519/22950 (epoch 3.309), train_loss = 1.95274367, grad/param norm = 2.2629e-01, time/batch = 0.6911s	
1520/22950 (epoch 3.312), train_loss = 1.96207393, grad/param norm = 2.1715e-01, time/batch = 0.6924s	
1521/22950 (epoch 3.314), train_loss = 1.68869040, grad/param norm = 2.5034e-01, time/batch = 0.6911s	
1522/22950 (epoch 3.316), train_loss = 1.89720016, grad/param norm = 2.5407e-01, time/batch = 0.6911s	
1523/22950 (epoch 3.318), train_loss = 1.69577973, grad/param norm = 2.4032e-01, time/batch = 0.6936s	
1524/22950 (epoch 3.320), train_loss = 1.81807451, grad/param norm = 2.2394e-01, time/batch = 0.6968s	
1525/22950 (epoch 3.322), train_loss = 1.79686078, grad/param norm = 2.2256e-01, time/batch = 0.7268s	
1526/22950 (epoch 3.325), train_loss = 1.55451079, grad/param norm = 2.1184e-01, time/batch = 0.7032s	
1527/22950 (epoch 3.327), train_loss = 1.59418618, grad/param norm = 2.2280e-01, time/batch = 0.6918s	
1528/22950 (epoch 3.329), train_loss = 1.72468219, grad/param norm = 2.5238e-01, time/batch = 0.6935s	
1529/22950 (epoch 3.331), train_loss = 1.68511413, grad/param norm = 2.4244e-01, time/batch = 0.6940s	
1530/22950 (epoch 3.333), train_loss = 1.76182079, grad/param norm = 2.4584e-01, time/batch = 0.6909s	
1531/22950 (epoch 3.336), train_loss = 1.86337335, grad/param norm = 2.8272e-01, time/batch = 0.7010s	
1532/22950 (epoch 3.338), train_loss = 1.80028638, grad/param norm = 3.4307e-01, time/batch = 0.7279s	
1533/22950 (epoch 3.340), train_loss = 1.74199264, grad/param norm = 2.9710e-01, time/batch = 0.7277s	
1534/22950 (epoch 3.342), train_loss = 1.84433875, grad/param norm = 2.2260e-01, time/batch = 0.7063s	
1535/22950 (epoch 3.344), train_loss = 1.83732165, grad/param norm = 2.4618e-01, time/batch = 0.7266s	
1536/22950 (epoch 3.346), train_loss = 2.02496142, grad/param norm = 2.4959e-01, time/batch = 0.6915s	
1537/22950 (epoch 3.349), train_loss = 1.90293746, grad/param norm = 2.7068e-01, time/batch = 0.6936s	
1538/22950 (epoch 3.351), train_loss = 1.83289154, grad/param norm = 2.3664e-01, time/batch = 0.6888s	
1539/22950 (epoch 3.353), train_loss = 1.88060052, grad/param norm = 2.4995e-01, time/batch = 0.6891s	
1540/22950 (epoch 3.355), train_loss = 2.00644297, grad/param norm = 2.7187e-01, time/batch = 0.6890s	
1541/22950 (epoch 3.357), train_loss = 1.89157601, grad/param norm = 2.2506e-01, time/batch = 0.7170s	
1542/22950 (epoch 3.359), train_loss = 1.94435622, grad/param norm = 2.2800e-01, time/batch = 0.7203s	
1543/22950 (epoch 3.362), train_loss = 1.77129256, grad/param norm = 2.4155e-01, time/batch = 0.7248s	
1544/22950 (epoch 3.364), train_loss = 1.88827946, grad/param norm = 2.4235e-01, time/batch = 0.7102s	
1545/22950 (epoch 3.366), train_loss = 1.60909853, grad/param norm = 2.5018e-01, time/batch = 0.7276s	
1546/22950 (epoch 3.368), train_loss = 1.82847438, grad/param norm = 2.3820e-01, time/batch = 0.6960s	
1547/22950 (epoch 3.370), train_loss = 1.79852940, grad/param norm = 2.4719e-01, time/batch = 0.6932s	
1548/22950 (epoch 3.373), train_loss = 1.67456978, grad/param norm = 2.0654e-01, time/batch = 0.6947s	
1549/22950 (epoch 3.375), train_loss = 2.01972101, grad/param norm = 2.4459e-01, time/batch = 0.6952s	
1550/22950 (epoch 3.377), train_loss = 1.77707873, grad/param norm = 2.4733e-01, time/batch = 0.6940s	
1551/22950 (epoch 3.379), train_loss = 1.97401268, grad/param norm = 2.4497e-01, time/batch = 0.7013s	
1552/22950 (epoch 3.381), train_loss = 1.67071213, grad/param norm = 2.2235e-01, time/batch = 0.6976s	
1553/22950 (epoch 3.383), train_loss = 1.90417897, grad/param norm = 2.5889e-01, time/batch = 0.7116s	
1554/22950 (epoch 3.386), train_loss = 1.89197275, grad/param norm = 2.6553e-01, time/batch = 0.7125s	
1555/22950 (epoch 3.388), train_loss = 1.89103763, grad/param norm = 2.5356e-01, time/batch = 0.7251s	
1556/22950 (epoch 3.390), train_loss = 1.70981012, grad/param norm = 2.7093e-01, time/batch = 0.6941s	
1557/22950 (epoch 3.392), train_loss = 1.69341200, grad/param norm = 2.4334e-01, time/batch = 0.6962s	
1558/22950 (epoch 3.394), train_loss = 1.75770342, grad/param norm = 2.2363e-01, time/batch = 0.6956s	
1559/22950 (epoch 3.397), train_loss = 1.86396046, grad/param norm = 2.3298e-01, time/batch = 0.6896s	
1560/22950 (epoch 3.399), train_loss = 1.91931808, grad/param norm = 2.2474e-01, time/batch = 0.6907s	
1561/22950 (epoch 3.401), train_loss = 2.11098733, grad/param norm = 2.5013e-01, time/batch = 0.6941s	
1562/22950 (epoch 3.403), train_loss = 1.81919912, grad/param norm = 2.6870e-01, time/batch = 0.6903s	
1563/22950 (epoch 3.405), train_loss = 1.82783805, grad/param norm = 2.4319e-01, time/batch = 0.6908s	
1564/22950 (epoch 3.407), train_loss = 1.95333434, grad/param norm = 2.2607e-01, time/batch = 0.7165s	
1565/22950 (epoch 3.410), train_loss = 1.64327031, grad/param norm = 2.2636e-01, time/batch = 0.7252s	
1566/22950 (epoch 3.412), train_loss = 1.84194353, grad/param norm = 2.2789e-01, time/batch = 0.6919s	
1567/22950 (epoch 3.414), train_loss = 1.88509217, grad/param norm = 2.6204e-01, time/batch = 0.6924s	
1568/22950 (epoch 3.416), train_loss = 1.96269066, grad/param norm = 2.6853e-01, time/batch = 0.6909s	
1569/22950 (epoch 3.418), train_loss = 1.92978239, grad/param norm = 2.5411e-01, time/batch = 0.6919s	
1570/22950 (epoch 3.420), train_loss = 1.89201102, grad/param norm = 2.2623e-01, time/batch = 0.6943s	
1571/22950 (epoch 3.423), train_loss = 1.71435742, grad/param norm = 2.6056e-01, time/batch = 0.6994s	
1572/22950 (epoch 3.425), train_loss = 1.84171358, grad/param norm = 2.4154e-01, time/batch = 0.6928s	
1573/22950 (epoch 3.427), train_loss = 1.77690794, grad/param norm = 2.5541e-01, time/batch = 0.6915s	
1574/22950 (epoch 3.429), train_loss = 1.69578478, grad/param norm = 2.1938e-01, time/batch = 0.7102s	
1575/22950 (epoch 3.431), train_loss = 1.83654123, grad/param norm = 2.6181e-01, time/batch = 0.7234s	
1576/22950 (epoch 3.434), train_loss = 1.82520873, grad/param norm = 2.8607e-01, time/batch = 0.6900s	
1577/22950 (epoch 3.436), train_loss = 2.08529333, grad/param norm = 2.6917e-01, time/batch = 0.6897s	
1578/22950 (epoch 3.438), train_loss = 1.84667090, grad/param norm = 2.8102e-01, time/batch = 0.6895s	
1579/22950 (epoch 3.440), train_loss = 1.86770600, grad/param norm = 2.1393e-01, time/batch = 0.6895s	
1580/22950 (epoch 3.442), train_loss = 2.01395398, grad/param norm = 2.6567e-01, time/batch = 0.6910s	
1581/22950 (epoch 3.444), train_loss = 2.01744499, grad/param norm = 2.6750e-01, time/batch = 0.6932s	
1582/22950 (epoch 3.447), train_loss = 1.98421833, grad/param norm = 3.2940e-01, time/batch = 0.6929s	
1583/22950 (epoch 3.449), train_loss = 1.70899060, grad/param norm = 2.6190e-01, time/batch = 0.6967s	
1584/22950 (epoch 3.451), train_loss = 1.88057185, grad/param norm = 2.5379e-01, time/batch = 0.7199s	
1585/22950 (epoch 3.453), train_loss = 1.92257853, grad/param norm = 2.2866e-01, time/batch = 0.7230s	
1586/22950 (epoch 3.455), train_loss = 1.74054964, grad/param norm = 2.4032e-01, time/batch = 0.6879s	
1587/22950 (epoch 3.458), train_loss = 2.02387963, grad/param norm = 2.5016e-01, time/batch = 0.6873s	
1588/22950 (epoch 3.460), train_loss = 1.93535924, grad/param norm = 2.6600e-01, time/batch = 0.6923s	
1589/22950 (epoch 3.462), train_loss = 1.81532841, grad/param norm = 2.5065e-01, time/batch = 0.6865s	
1590/22950 (epoch 3.464), train_loss = 1.85601697, grad/param norm = 2.7340e-01, time/batch = 0.6897s	
1591/22950 (epoch 3.466), train_loss = 1.79732694, grad/param norm = 2.6031e-01, time/batch = 0.6964s	
1592/22950 (epoch 3.468), train_loss = 1.94148381, grad/param norm = 2.1929e-01, time/batch = 0.6908s	
1593/22950 (epoch 3.471), train_loss = 1.76283120, grad/param norm = 2.2598e-01, time/batch = 0.6870s	
1594/22950 (epoch 3.473), train_loss = 1.88087384, grad/param norm = 2.6024e-01, time/batch = 0.6896s	
1595/22950 (epoch 3.475), train_loss = 2.04843256, grad/param norm = 3.2706e-01, time/batch = 0.6939s	
1596/22950 (epoch 3.477), train_loss = 1.90993974, grad/param norm = 2.9109e-01, time/batch = 0.7205s	
1597/22950 (epoch 3.479), train_loss = 1.92683824, grad/param norm = 2.5852e-01, time/batch = 0.7031s	
1598/22950 (epoch 3.481), train_loss = 2.04611966, grad/param norm = 2.9357e-01, time/batch = 0.6934s	
1599/22950 (epoch 3.484), train_loss = 2.09919466, grad/param norm = 2.9676e-01, time/batch = 0.6930s	
1600/22950 (epoch 3.486), train_loss = 1.71630280, grad/param norm = 2.7695e-01, time/batch = 0.6935s	
1601/22950 (epoch 3.488), train_loss = 1.79049711, grad/param norm = 2.7915e-01, time/batch = 0.7018s	
1602/22950 (epoch 3.490), train_loss = 1.80856710, grad/param norm = 2.3329e-01, time/batch = 0.7140s	
1603/22950 (epoch 3.492), train_loss = 1.85367271, grad/param norm = 2.1689e-01, time/batch = 0.6914s	
1604/22950 (epoch 3.495), train_loss = 1.87750448, grad/param norm = 2.4746e-01, time/batch = 0.7041s	
1605/22950 (epoch 3.497), train_loss = 1.90297669, grad/param norm = 2.0447e-01, time/batch = 0.7059s	
1606/22950 (epoch 3.499), train_loss = 1.90582689, grad/param norm = 2.6321e-01, time/batch = 0.6902s	
1607/22950 (epoch 3.501), train_loss = 1.97425865, grad/param norm = 2.3712e-01, time/batch = 0.6912s	
1608/22950 (epoch 3.503), train_loss = 1.93905688, grad/param norm = 2.6084e-01, time/batch = 0.7056s	
1609/22950 (epoch 3.505), train_loss = 1.73675018, grad/param norm = 2.2235e-01, time/batch = 0.6958s	
1610/22950 (epoch 3.508), train_loss = 1.84311915, grad/param norm = 2.4689e-01, time/batch = 0.6951s	
1611/22950 (epoch 3.510), train_loss = 1.79963113, grad/param norm = 2.2823e-01, time/batch = 0.6762s	
1612/22950 (epoch 3.512), train_loss = 1.82011423, grad/param norm = 2.4920e-01, time/batch = 0.6786s	
1613/22950 (epoch 3.514), train_loss = 1.62340864, grad/param norm = 2.9076e-01, time/batch = 0.6749s	
1614/22950 (epoch 3.516), train_loss = 1.68802957, grad/param norm = 2.5842e-01, time/batch = 0.6802s	
1615/22950 (epoch 3.519), train_loss = 1.78418880, grad/param norm = 2.2247e-01, time/batch = 0.6740s	
1616/22950 (epoch 3.521), train_loss = 1.78476242, grad/param norm = 2.2796e-01, time/batch = 0.6723s	
1617/22950 (epoch 3.523), train_loss = 1.61089946, grad/param norm = 2.4624e-01, time/batch = 0.6724s	
1618/22950 (epoch 3.525), train_loss = 1.79279766, grad/param norm = 2.9943e-01, time/batch = 0.6755s	
1619/22950 (epoch 3.527), train_loss = 1.62956542, grad/param norm = 2.6344e-01, time/batch = 0.6737s	
1620/22950 (epoch 3.529), train_loss = 1.88007751, grad/param norm = 2.2395e-01, time/batch = 0.6742s	
1621/22950 (epoch 3.532), train_loss = 1.83111660, grad/param norm = 2.3217e-01, time/batch = 0.6749s	
1622/22950 (epoch 3.534), train_loss = 1.91428106, grad/param norm = 2.5732e-01, time/batch = 0.6757s	
1623/22950 (epoch 3.536), train_loss = 1.84747086, grad/param norm = 2.7584e-01, time/batch = 0.6747s	
1624/22950 (epoch 3.538), train_loss = 1.84064991, grad/param norm = 2.6579e-01, time/batch = 0.6750s	
1625/22950 (epoch 3.540), train_loss = 1.75767364, grad/param norm = 2.4233e-01, time/batch = 0.6765s	
1626/22950 (epoch 3.542), train_loss = 2.04535507, grad/param norm = 2.3359e-01, time/batch = 0.6736s	
1627/22950 (epoch 3.545), train_loss = 1.75735454, grad/param norm = 2.3602e-01, time/batch = 0.7025s	
1628/22950 (epoch 3.547), train_loss = 1.77984065, grad/param norm = 2.4386e-01, time/batch = 0.7053s	
1629/22950 (epoch 3.549), train_loss = 1.77244337, grad/param norm = 2.6415e-01, time/batch = 0.7165s	
1630/22950 (epoch 3.551), train_loss = 1.89816333, grad/param norm = 3.3584e-01, time/batch = 0.7017s	
1631/22950 (epoch 3.553), train_loss = 1.79503390, grad/param norm = 2.6408e-01, time/batch = 0.6866s	
1632/22950 (epoch 3.556), train_loss = 1.90064748, grad/param norm = 2.3228e-01, time/batch = 0.6806s	
1633/22950 (epoch 3.558), train_loss = 1.80853919, grad/param norm = 2.1784e-01, time/batch = 0.6820s	
1634/22950 (epoch 3.560), train_loss = 1.83681803, grad/param norm = 2.0550e-01, time/batch = 0.6785s	
1635/22950 (epoch 3.562), train_loss = 1.69477012, grad/param norm = 2.3812e-01, time/batch = 0.6717s	
1636/22950 (epoch 3.564), train_loss = 2.07082647, grad/param norm = 3.4600e-01, time/batch = 0.6739s	
1637/22950 (epoch 3.566), train_loss = 1.85410932, grad/param norm = 2.5535e-01, time/batch = 0.6942s	
1638/22950 (epoch 3.569), train_loss = 1.96913016, grad/param norm = 2.5507e-01, time/batch = 0.6773s	
1639/22950 (epoch 3.571), train_loss = 1.68560900, grad/param norm = 2.1691e-01, time/batch = 0.6989s	
1640/22950 (epoch 3.573), train_loss = 1.80523743, grad/param norm = 2.1674e-01, time/batch = 0.7039s	
1641/22950 (epoch 3.575), train_loss = 2.21257357, grad/param norm = 3.0294e-01, time/batch = 0.6810s	
1642/22950 (epoch 3.577), train_loss = 1.88435155, grad/param norm = 2.8467e-01, time/batch = 0.6938s	
1643/22950 (epoch 3.580), train_loss = 1.90346812, grad/param norm = 2.5008e-01, time/batch = 0.6920s	
1644/22950 (epoch 3.582), train_loss = 2.03474811, grad/param norm = 2.3995e-01, time/batch = 0.6846s	
1645/22950 (epoch 3.584), train_loss = 1.62805777, grad/param norm = 2.5376e-01, time/batch = 0.6919s	
1646/22950 (epoch 3.586), train_loss = 1.72815944, grad/param norm = 2.4226e-01, time/batch = 0.6795s	
1647/22950 (epoch 3.588), train_loss = 1.95582714, grad/param norm = 2.5541e-01, time/batch = 0.6777s	
1648/22950 (epoch 3.590), train_loss = 1.75651975, grad/param norm = 2.3490e-01, time/batch = 0.6745s	
1649/22950 (epoch 3.593), train_loss = 1.62630980, grad/param norm = 2.4345e-01, time/batch = 0.6708s	
1650/22950 (epoch 3.595), train_loss = 1.73380439, grad/param norm = 2.4824e-01, time/batch = 0.6763s	
1651/22950 (epoch 3.597), train_loss = 1.91195159, grad/param norm = 2.4651e-01, time/batch = 0.6774s	
1652/22950 (epoch 3.599), train_loss = 1.86773142, grad/param norm = 2.7227e-01, time/batch = 0.6763s	
1653/22950 (epoch 3.601), train_loss = 1.85145341, grad/param norm = 2.5820e-01, time/batch = 0.6742s	
1654/22950 (epoch 3.603), train_loss = 1.95104867, grad/param norm = 2.5337e-01, time/batch = 0.6733s	
1655/22950 (epoch 3.606), train_loss = 1.77374095, grad/param norm = 2.5436e-01, time/batch = 0.6724s	
1656/22950 (epoch 3.608), train_loss = 1.74370232, grad/param norm = 2.3795e-01, time/batch = 0.6805s	
1657/22950 (epoch 3.610), train_loss = 1.79486891, grad/param norm = 2.6836e-01, time/batch = 0.6855s	
1658/22950 (epoch 3.612), train_loss = 1.84437417, grad/param norm = 2.3223e-01, time/batch = 0.6741s	
1659/22950 (epoch 3.614), train_loss = 1.97751136, grad/param norm = 2.4294e-01, time/batch = 0.6725s	
1660/22950 (epoch 3.617), train_loss = 1.85086917, grad/param norm = 2.2562e-01, time/batch = 0.6744s	
1661/22950 (epoch 3.619), train_loss = 1.68683827, grad/param norm = 2.1320e-01, time/batch = 0.6751s	
1662/22950 (epoch 3.621), train_loss = 1.91313579, grad/param norm = 2.2846e-01, time/batch = 0.6761s	
1663/22950 (epoch 3.623), train_loss = 1.77526561, grad/param norm = 2.3040e-01, time/batch = 0.6741s	
1664/22950 (epoch 3.625), train_loss = 1.80653929, grad/param norm = 2.1415e-01, time/batch = 0.6733s	
1665/22950 (epoch 3.627), train_loss = 1.81415906, grad/param norm = 2.4148e-01, time/batch = 0.6750s	
1666/22950 (epoch 3.630), train_loss = 1.63811247, grad/param norm = 2.2105e-01, time/batch = 0.6759s	
1667/22950 (epoch 3.632), train_loss = 1.87244559, grad/param norm = 2.1887e-01, time/batch = 0.6752s	
1668/22950 (epoch 3.634), train_loss = 1.75423879, grad/param norm = 2.1740e-01, time/batch = 0.6748s	
1669/22950 (epoch 3.636), train_loss = 1.78367519, grad/param norm = 2.0853e-01, time/batch = 0.6749s	
1670/22950 (epoch 3.638), train_loss = 1.72347166, grad/param norm = 2.3532e-01, time/batch = 0.6729s	
1671/22950 (epoch 3.641), train_loss = 1.76608924, grad/param norm = 2.2365e-01, time/batch = 0.6772s	
1672/22950 (epoch 3.643), train_loss = 1.81958676, grad/param norm = 2.5563e-01, time/batch = 0.6815s	
1673/22950 (epoch 3.645), train_loss = 1.73516691, grad/param norm = 3.2336e-01, time/batch = 0.6789s	
1674/22950 (epoch 3.647), train_loss = 1.84170406, grad/param norm = 2.7723e-01, time/batch = 0.6755s	
1675/22950 (epoch 3.649), train_loss = 1.81015142, grad/param norm = 2.0891e-01, time/batch = 0.6760s	
1676/22950 (epoch 3.651), train_loss = 1.90426965, grad/param norm = 2.4028e-01, time/batch = 0.6775s	
1677/22950 (epoch 3.654), train_loss = 1.58975235, grad/param norm = 2.0556e-01, time/batch = 0.6881s	
1678/22950 (epoch 3.656), train_loss = 1.89943143, grad/param norm = 2.4244e-01, time/batch = 0.6865s	
1679/22950 (epoch 3.658), train_loss = 1.72629552, grad/param norm = 2.0821e-01, time/batch = 0.6867s	
1680/22950 (epoch 3.660), train_loss = 1.61695244, grad/param norm = 2.3239e-01, time/batch = 0.6830s	
1681/22950 (epoch 3.662), train_loss = 1.68699217, grad/param norm = 2.2244e-01, time/batch = 0.6857s	
1682/22950 (epoch 3.664), train_loss = 1.87234632, grad/param norm = 2.3571e-01, time/batch = 0.6843s	
1683/22950 (epoch 3.667), train_loss = 1.85726350, grad/param norm = 2.4382e-01, time/batch = 0.6855s	
1684/22950 (epoch 3.669), train_loss = 1.69999977, grad/param norm = 2.4213e-01, time/batch = 0.6868s	
1685/22950 (epoch 3.671), train_loss = 1.89386286, grad/param norm = 2.5430e-01, time/batch = 0.6887s	
1686/22950 (epoch 3.673), train_loss = 1.84271672, grad/param norm = 2.0421e-01, time/batch = 0.6894s	
1687/22950 (epoch 3.675), train_loss = 1.76780497, grad/param norm = 2.2104e-01, time/batch = 0.6932s	
1688/22950 (epoch 3.678), train_loss = 1.83993792, grad/param norm = 2.2723e-01, time/batch = 0.6864s	
1689/22950 (epoch 3.680), train_loss = 1.84345972, grad/param norm = 2.1298e-01, time/batch = 0.6860s	
1690/22950 (epoch 3.682), train_loss = 1.89893255, grad/param norm = 2.1702e-01, time/batch = 0.6856s	
1691/22950 (epoch 3.684), train_loss = 1.85750185, grad/param norm = 1.9958e-01, time/batch = 0.6883s	
1692/22950 (epoch 3.686), train_loss = 1.83627149, grad/param norm = 2.0757e-01, time/batch = 0.6872s	
1693/22950 (epoch 3.688), train_loss = 1.79133023, grad/param norm = 2.2769e-01, time/batch = 0.6886s	
1694/22950 (epoch 3.691), train_loss = 1.73583332, grad/param norm = 2.4930e-01, time/batch = 0.6884s	
1695/22950 (epoch 3.693), train_loss = 1.75741809, grad/param norm = 2.3050e-01, time/batch = 0.7232s	
1696/22950 (epoch 3.695), train_loss = 1.99382606, grad/param norm = 2.7380e-01, time/batch = 0.6957s	
1697/22950 (epoch 3.697), train_loss = 1.94639504, grad/param norm = 2.2537e-01, time/batch = 0.6857s	
1698/22950 (epoch 3.699), train_loss = 1.84834189, grad/param norm = 2.1302e-01, time/batch = 0.6850s	
1699/22950 (epoch 3.702), train_loss = 1.83159277, grad/param norm = 2.0307e-01, time/batch = 0.6865s	
1700/22950 (epoch 3.704), train_loss = 1.90741488, grad/param norm = 2.3834e-01, time/batch = 0.6856s	
1701/22950 (epoch 3.706), train_loss = 1.95219241, grad/param norm = 2.4683e-01, time/batch = 0.6868s	
1702/22950 (epoch 3.708), train_loss = 1.84894268, grad/param norm = 2.7336e-01, time/batch = 0.6869s	
1703/22950 (epoch 3.710), train_loss = 1.85814351, grad/param norm = 2.2148e-01, time/batch = 0.6842s	
1704/22950 (epoch 3.712), train_loss = 1.92207606, grad/param norm = 2.1535e-01, time/batch = 0.6931s	
1705/22950 (epoch 3.715), train_loss = 1.84575418, grad/param norm = 2.1601e-01, time/batch = 0.7231s	
1706/22950 (epoch 3.717), train_loss = 1.62609756, grad/param norm = 2.0486e-01, time/batch = 0.6998s	
1707/22950 (epoch 3.719), train_loss = 1.87803353, grad/param norm = 2.2677e-01, time/batch = 0.6866s	
1708/22950 (epoch 3.721), train_loss = 1.89403878, grad/param norm = 2.4310e-01, time/batch = 0.6849s	
1709/22950 (epoch 3.723), train_loss = 1.72375040, grad/param norm = 2.1145e-01, time/batch = 0.6936s	
1710/22950 (epoch 3.725), train_loss = 2.00299874, grad/param norm = 2.6949e-01, time/batch = 0.6926s	
1711/22950 (epoch 3.728), train_loss = 1.80398713, grad/param norm = 2.6864e-01, time/batch = 0.6910s	
1712/22950 (epoch 3.730), train_loss = 1.80669933, grad/param norm = 2.5961e-01, time/batch = 0.6845s	
1713/22950 (epoch 3.732), train_loss = 1.78831088, grad/param norm = 2.0791e-01, time/batch = 0.6863s	
1714/22950 (epoch 3.734), train_loss = 1.82162127, grad/param norm = 2.2563e-01, time/batch = 0.7078s	
1715/22950 (epoch 3.736), train_loss = 1.69835190, grad/param norm = 2.5422e-01, time/batch = 0.7213s	
1716/22950 (epoch 3.739), train_loss = 1.85406822, grad/param norm = 2.6418e-01, time/batch = 0.7278s	
1717/22950 (epoch 3.741), train_loss = 1.84773942, grad/param norm = 2.5067e-01, time/batch = 0.7068s	
1718/22950 (epoch 3.743), train_loss = 1.99261751, grad/param norm = 2.4557e-01, time/batch = 0.7204s	
1719/22950 (epoch 3.745), train_loss = 2.01213360, grad/param norm = 2.4201e-01, time/batch = 0.7143s	
1720/22950 (epoch 3.747), train_loss = 1.80324892, grad/param norm = 2.6988e-01, time/batch = 0.6905s	
1721/22950 (epoch 3.749), train_loss = 1.75950910, grad/param norm = 2.5872e-01, time/batch = 0.6927s	
1722/22950 (epoch 3.752), train_loss = 1.95496585, grad/param norm = 2.3177e-01, time/batch = 0.6864s	
1723/22950 (epoch 3.754), train_loss = 1.90544841, grad/param norm = 2.5113e-01, time/batch = 0.6871s	
1724/22950 (epoch 3.756), train_loss = 1.66133129, grad/param norm = 2.3132e-01, time/batch = 0.6919s	
1725/22950 (epoch 3.758), train_loss = 1.76475672, grad/param norm = 2.2846e-01, time/batch = 0.7231s	
1726/22950 (epoch 3.760), train_loss = 1.78101590, grad/param norm = 2.3254e-01, time/batch = 0.7155s	
1727/22950 (epoch 3.763), train_loss = 1.78593842, grad/param norm = 2.6406e-01, time/batch = 0.6990s	
1728/22950 (epoch 3.765), train_loss = 1.85951864, grad/param norm = 2.3218e-01, time/batch = 0.6918s	
1729/22950 (epoch 3.767), train_loss = 1.89488810, grad/param norm = 2.2014e-01, time/batch = 0.6868s	
1730/22950 (epoch 3.769), train_loss = 1.80921712, grad/param norm = 2.3241e-01, time/batch = 0.6893s	
1731/22950 (epoch 3.771), train_loss = 1.64130330, grad/param norm = 2.1706e-01, time/batch = 0.6992s	
1732/22950 (epoch 3.773), train_loss = 1.54893067, grad/param norm = 2.1607e-01, time/batch = 0.6906s	
1733/22950 (epoch 3.776), train_loss = 1.72372791, grad/param norm = 2.0450e-01, time/batch = 0.7164s	
1734/22950 (epoch 3.778), train_loss = 1.63872756, grad/param norm = 2.1698e-01, time/batch = 0.7180s	
1735/22950 (epoch 3.780), train_loss = 1.63182949, grad/param norm = 2.2433e-01, time/batch = 0.6878s	
1736/22950 (epoch 3.782), train_loss = 1.73121515, grad/param norm = 2.4184e-01, time/batch = 0.6865s	
1737/22950 (epoch 3.784), train_loss = 1.84771782, grad/param norm = 2.7009e-01, time/batch = 0.6861s	
1738/22950 (epoch 3.786), train_loss = 1.83388568, grad/param norm = 2.3050e-01, time/batch = 0.6910s	
1739/22950 (epoch 3.789), train_loss = 1.65474384, grad/param norm = 2.1719e-01, time/batch = 0.6887s	
1740/22950 (epoch 3.791), train_loss = 1.69572590, grad/param norm = 2.2791e-01, time/batch = 0.6854s	
1741/22950 (epoch 3.793), train_loss = 2.05167863, grad/param norm = 2.2287e-01, time/batch = 0.6856s	
1742/22950 (epoch 3.795), train_loss = 1.69429843, grad/param norm = 2.2047e-01, time/batch = 0.6863s	
1743/22950 (epoch 3.797), train_loss = 1.98490728, grad/param norm = 2.5689e-01, time/batch = 0.6914s	
1744/22950 (epoch 3.800), train_loss = 1.71937542, grad/param norm = 3.1093e-01, time/batch = 0.6917s	
1745/22950 (epoch 3.802), train_loss = 1.73554688, grad/param norm = 2.4551e-01, time/batch = 0.6867s	
1746/22950 (epoch 3.804), train_loss = 1.74838702, grad/param norm = 2.2596e-01, time/batch = 0.6868s	
1747/22950 (epoch 3.806), train_loss = 1.70037621, grad/param norm = 2.3589e-01, time/batch = 0.6915s	
1748/22950 (epoch 3.808), train_loss = 1.76022233, grad/param norm = 2.3765e-01, time/batch = 0.6852s	
1749/22950 (epoch 3.810), train_loss = 1.77729602, grad/param norm = 2.5265e-01, time/batch = 0.6875s	
1750/22950 (epoch 3.813), train_loss = 1.54425268, grad/param norm = 2.2459e-01, time/batch = 0.6857s	
1751/22950 (epoch 3.815), train_loss = 1.79797363, grad/param norm = 2.2423e-01, time/batch = 0.6962s	
1752/22950 (epoch 3.817), train_loss = 1.67557558, grad/param norm = 2.3447e-01, time/batch = 0.6863s	
1753/22950 (epoch 3.819), train_loss = 1.75040899, grad/param norm = 2.3120e-01, time/batch = 0.6878s	
1754/22950 (epoch 3.821), train_loss = 1.75955306, grad/param norm = 2.6230e-01, time/batch = 0.6859s	
1755/22950 (epoch 3.824), train_loss = 1.71111406, grad/param norm = 2.4101e-01, time/batch = 0.6881s	
1756/22950 (epoch 3.826), train_loss = 1.86757367, grad/param norm = 2.2607e-01, time/batch = 0.6881s	
1757/22950 (epoch 3.828), train_loss = 1.75891668, grad/param norm = 2.3177e-01, time/batch = 0.6875s	
1758/22950 (epoch 3.830), train_loss = 1.83264263, grad/param norm = 2.3345e-01, time/batch = 0.6895s	
1759/22950 (epoch 3.832), train_loss = 1.78386314, grad/param norm = 2.3735e-01, time/batch = 0.7235s	
1760/22950 (epoch 3.834), train_loss = 1.64660292, grad/param norm = 2.2816e-01, time/batch = 0.7143s	
1761/22950 (epoch 3.837), train_loss = 1.74820157, grad/param norm = 2.2967e-01, time/batch = 0.6870s	
1762/22950 (epoch 3.839), train_loss = 1.73405512, grad/param norm = 2.1141e-01, time/batch = 0.6896s	
1763/22950 (epoch 3.841), train_loss = 1.69178905, grad/param norm = 2.0958e-01, time/batch = 0.6853s	
1764/22950 (epoch 3.843), train_loss = 1.69170700, grad/param norm = 2.2915e-01, time/batch = 0.6921s	
1765/22950 (epoch 3.845), train_loss = 1.77754921, grad/param norm = 2.3363e-01, time/batch = 0.6886s	
1766/22950 (epoch 3.847), train_loss = 1.86532020, grad/param norm = 2.1692e-01, time/batch = 0.6859s	
1767/22950 (epoch 3.850), train_loss = 1.83434626, grad/param norm = 2.3871e-01, time/batch = 0.6877s	
1768/22950 (epoch 3.852), train_loss = 1.86081642, grad/param norm = 2.7046e-01, time/batch = 0.6884s	
1769/22950 (epoch 3.854), train_loss = 1.76778580, grad/param norm = 2.3279e-01, time/batch = 0.7064s	
1770/22950 (epoch 3.856), train_loss = 2.01129333, grad/param norm = 2.3697e-01, time/batch = 0.7169s	
1771/22950 (epoch 3.858), train_loss = 1.77951236, grad/param norm = 2.2321e-01, time/batch = 0.6887s	
1772/22950 (epoch 3.861), train_loss = 1.87495225, grad/param norm = 2.5921e-01, time/batch = 0.6892s	
1773/22950 (epoch 3.863), train_loss = 1.94514299, grad/param norm = 2.4387e-01, time/batch = 0.6900s	
1774/22950 (epoch 3.865), train_loss = 1.94373536, grad/param norm = 2.5289e-01, time/batch = 0.6907s	
1775/22950 (epoch 3.867), train_loss = 1.83149813, grad/param norm = 2.2632e-01, time/batch = 0.7052s	
1776/22950 (epoch 3.869), train_loss = 1.98660400, grad/param norm = 2.3866e-01, time/batch = 0.7110s	
1777/22950 (epoch 3.871), train_loss = 1.74876908, grad/param norm = 2.2761e-01, time/batch = 0.7035s	
1778/22950 (epoch 3.874), train_loss = 1.75255475, grad/param norm = 2.3339e-01, time/batch = 0.6963s	
1779/22950 (epoch 3.876), train_loss = 1.87451494, grad/param norm = 2.4426e-01, time/batch = 0.7164s	
1780/22950 (epoch 3.878), train_loss = 1.68127510, grad/param norm = 2.4039e-01, time/batch = 0.7149s	
1781/22950 (epoch 3.880), train_loss = 1.93263126, grad/param norm = 2.3528e-01, time/batch = 0.6916s	
1782/22950 (epoch 3.882), train_loss = 1.60408833, grad/param norm = 2.0406e-01, time/batch = 0.6932s	
1783/22950 (epoch 3.885), train_loss = 1.80700942, grad/param norm = 2.3975e-01, time/batch = 0.7144s	
1784/22950 (epoch 3.887), train_loss = 1.79540123, grad/param norm = 2.4030e-01, time/batch = 0.7018s	
1785/22950 (epoch 3.889), train_loss = 1.92887285, grad/param norm = 2.7507e-01, time/batch = 0.7019s	
1786/22950 (epoch 3.891), train_loss = 1.83509966, grad/param norm = 2.1088e-01, time/batch = 0.6983s	
1787/22950 (epoch 3.893), train_loss = 1.81620788, grad/param norm = 2.3200e-01, time/batch = 0.7163s	
1788/22950 (epoch 3.895), train_loss = 1.93130376, grad/param norm = 2.3909e-01, time/batch = 0.7287s	
1789/22950 (epoch 3.898), train_loss = 1.76753255, grad/param norm = 2.1624e-01, time/batch = 0.7282s	
1790/22950 (epoch 3.900), train_loss = 1.64404213, grad/param norm = 2.1551e-01, time/batch = 0.7270s	
1791/22950 (epoch 3.902), train_loss = 1.74640149, grad/param norm = 2.0744e-01, time/batch = 0.7291s	
1792/22950 (epoch 3.904), train_loss = 1.77356318, grad/param norm = 2.1546e-01, time/batch = 0.7253s	
1793/22950 (epoch 3.906), train_loss = 1.85914168, grad/param norm = 2.2300e-01, time/batch = 0.7253s	
1794/22950 (epoch 3.908), train_loss = 1.65549467, grad/param norm = 2.3151e-01, time/batch = 0.7241s	
1795/22950 (epoch 3.911), train_loss = 1.60575161, grad/param norm = 2.2992e-01, time/batch = 0.7257s	
1796/22950 (epoch 3.913), train_loss = 1.65080859, grad/param norm = 1.9902e-01, time/batch = 0.7270s	
1797/22950 (epoch 3.915), train_loss = 1.98304980, grad/param norm = 2.3889e-01, time/batch = 0.7284s	
1798/22950 (epoch 3.917), train_loss = 1.70372207, grad/param norm = 2.3633e-01, time/batch = 0.7282s	
1799/22950 (epoch 3.919), train_loss = 1.76472732, grad/param norm = 2.3847e-01, time/batch = 0.7244s	
1800/22950 (epoch 3.922), train_loss = 1.72014876, grad/param norm = 2.2896e-01, time/batch = 0.7188s	
1801/22950 (epoch 3.924), train_loss = 1.85925939, grad/param norm = 2.2873e-01, time/batch = 0.7192s	
1802/22950 (epoch 3.926), train_loss = 1.62538036, grad/param norm = 2.4108e-01, time/batch = 0.7018s	
1803/22950 (epoch 3.928), train_loss = 1.63243243, grad/param norm = 2.4557e-01, time/batch = 0.6981s	
1804/22950 (epoch 3.930), train_loss = 1.62077778, grad/param norm = 2.2644e-01, time/batch = 0.6992s	
1805/22950 (epoch 3.932), train_loss = 1.70068509, grad/param norm = 2.5483e-01, time/batch = 0.7016s	
1806/22950 (epoch 3.935), train_loss = 1.77137936, grad/param norm = 2.3516e-01, time/batch = 0.7027s	
1807/22950 (epoch 3.937), train_loss = 1.80003423, grad/param norm = 2.4212e-01, time/batch = 0.6934s	
1808/22950 (epoch 3.939), train_loss = 1.75902140, grad/param norm = 2.3881e-01, time/batch = 0.6988s	
1809/22950 (epoch 3.941), train_loss = 1.66588561, grad/param norm = 2.0927e-01, time/batch = 0.7104s	
1810/22950 (epoch 3.943), train_loss = 1.81664022, grad/param norm = 2.7064e-01, time/batch = 0.7075s	
1811/22950 (epoch 3.946), train_loss = 1.60534823, grad/param norm = 2.4768e-01, time/batch = 0.7045s	
1812/22950 (epoch 3.948), train_loss = 1.81830839, grad/param norm = 2.5060e-01, time/batch = 0.6911s	
1813/22950 (epoch 3.950), train_loss = 1.81813258, grad/param norm = 2.4061e-01, time/batch = 0.6927s	
1814/22950 (epoch 3.952), train_loss = 1.83339503, grad/param norm = 2.3224e-01, time/batch = 0.6884s	
1815/22950 (epoch 3.954), train_loss = 1.71034925, grad/param norm = 2.3452e-01, time/batch = 0.6920s	
1816/22950 (epoch 3.956), train_loss = 1.70096221, grad/param norm = 2.1911e-01, time/batch = 0.6913s	
1817/22950 (epoch 3.959), train_loss = 1.64358383, grad/param norm = 2.4617e-01, time/batch = 0.6934s	
1818/22950 (epoch 3.961), train_loss = 1.76741494, grad/param norm = 2.3577e-01, time/batch = 0.6918s	
1819/22950 (epoch 3.963), train_loss = 1.87315697, grad/param norm = 2.5212e-01, time/batch = 0.6958s	
1820/22950 (epoch 3.965), train_loss = 1.96468121, grad/param norm = 2.1268e-01, time/batch = 0.6858s	
1821/22950 (epoch 3.967), train_loss = 1.73921043, grad/param norm = 2.3811e-01, time/batch = 0.6886s	
1822/22950 (epoch 3.969), train_loss = 1.67627363, grad/param norm = 2.1752e-01, time/batch = 0.6852s	
1823/22950 (epoch 3.972), train_loss = 1.73226252, grad/param norm = 2.4729e-01, time/batch = 0.6855s	
1824/22950 (epoch 3.974), train_loss = 1.63367276, grad/param norm = 2.3121e-01, time/batch = 0.6881s	
1825/22950 (epoch 3.976), train_loss = 1.61661429, grad/param norm = 2.7009e-01, time/batch = 0.6875s	
1826/22950 (epoch 3.978), train_loss = 1.78439263, grad/param norm = 2.3546e-01, time/batch = 0.6876s	
1827/22950 (epoch 3.980), train_loss = 1.75929149, grad/param norm = 2.4147e-01, time/batch = 0.6897s	
1828/22950 (epoch 3.983), train_loss = 1.61734894, grad/param norm = 2.1773e-01, time/batch = 0.6892s	
1829/22950 (epoch 3.985), train_loss = 1.61752080, grad/param norm = 2.6902e-01, time/batch = 0.6893s	
1830/22950 (epoch 3.987), train_loss = 1.73215824, grad/param norm = 2.4797e-01, time/batch = 0.6853s	
1831/22950 (epoch 3.989), train_loss = 1.81892655, grad/param norm = 2.3811e-01, time/batch = 0.6872s	
1832/22950 (epoch 3.991), train_loss = 1.70422168, grad/param norm = 2.1957e-01, time/batch = 0.6885s	
1833/22950 (epoch 3.993), train_loss = 1.78043927, grad/param norm = 2.4996e-01, time/batch = 0.6902s	
1834/22950 (epoch 3.996), train_loss = 1.87473157, grad/param norm = 2.4071e-01, time/batch = 0.6890s	
1835/22950 (epoch 3.998), train_loss = 1.64686664, grad/param norm = 2.1623e-01, time/batch = 0.6893s	
1836/22950 (epoch 4.000), train_loss = 1.60058139, grad/param norm = 2.2046e-01, time/batch = 0.6878s	
1837/22950 (epoch 4.002), train_loss = 1.95314195, grad/param norm = 2.4930e-01, time/batch = 0.6870s	
1838/22950 (epoch 4.004), train_loss = 1.81044966, grad/param norm = 2.2573e-01, time/batch = 0.6882s	
1839/22950 (epoch 4.007), train_loss = 1.73522389, grad/param norm = 2.2720e-01, time/batch = 0.6864s	
1840/22950 (epoch 4.009), train_loss = 1.85235532, grad/param norm = 2.1354e-01, time/batch = 0.6916s	
1841/22950 (epoch 4.011), train_loss = 1.82046464, grad/param norm = 2.2093e-01, time/batch = 0.6873s	
1842/22950 (epoch 4.013), train_loss = 1.89361345, grad/param norm = 2.3687e-01, time/batch = 0.6882s	
1843/22950 (epoch 4.015), train_loss = 1.83249229, grad/param norm = 2.3451e-01, time/batch = 0.6927s	
1844/22950 (epoch 4.017), train_loss = 1.71470758, grad/param norm = 2.5252e-01, time/batch = 0.6906s	
1845/22950 (epoch 4.020), train_loss = 1.74243634, grad/param norm = 2.2161e-01, time/batch = 0.6998s	
1846/22950 (epoch 4.022), train_loss = 1.55815235, grad/param norm = 2.0301e-01, time/batch = 0.7046s	
1847/22950 (epoch 4.024), train_loss = 1.72416884, grad/param norm = 2.2913e-01, time/batch = 0.6933s	
1848/22950 (epoch 4.026), train_loss = 1.73006883, grad/param norm = 2.4139e-01, time/batch = 0.6869s	
1849/22950 (epoch 4.028), train_loss = 1.78161748, grad/param norm = 2.9074e-01, time/batch = 0.6837s	
1850/22950 (epoch 4.031), train_loss = 1.72559472, grad/param norm = 2.1529e-01, time/batch = 0.6940s	
1851/22950 (epoch 4.033), train_loss = 1.98277083, grad/param norm = 2.3550e-01, time/batch = 0.6885s	
1852/22950 (epoch 4.035), train_loss = 1.76262945, grad/param norm = 2.1045e-01, time/batch = 0.6886s	
1853/22950 (epoch 4.037), train_loss = 1.66804688, grad/param norm = 2.0356e-01, time/batch = 0.7119s	
1854/22950 (epoch 4.039), train_loss = 1.75938730, grad/param norm = 2.4510e-01, time/batch = 0.7140s	
1855/22950 (epoch 4.041), train_loss = 1.80026942, grad/param norm = 2.5567e-01, time/batch = 0.6884s	
1856/22950 (epoch 4.044), train_loss = 1.65974720, grad/param norm = 2.3084e-01, time/batch = 0.6890s	
1857/22950 (epoch 4.046), train_loss = 1.70641269, grad/param norm = 2.5111e-01, time/batch = 0.6918s	
1858/22950 (epoch 4.048), train_loss = 1.77848964, grad/param norm = 2.0881e-01, time/batch = 0.7225s	
1859/22950 (epoch 4.050), train_loss = 1.81132642, grad/param norm = 2.2369e-01, time/batch = 0.6876s	
1860/22950 (epoch 4.052), train_loss = 1.73294725, grad/param norm = 2.3469e-01, time/batch = 0.6941s	
1861/22950 (epoch 4.054), train_loss = 2.00484778, grad/param norm = 2.5272e-01, time/batch = 0.6982s	
1862/22950 (epoch 4.057), train_loss = 1.78209080, grad/param norm = 2.3507e-01, time/batch = 0.6915s	
1863/22950 (epoch 4.059), train_loss = 1.81953989, grad/param norm = 2.2562e-01, time/batch = 0.6965s	
1864/22950 (epoch 4.061), train_loss = 1.63493385, grad/param norm = 2.2451e-01, time/batch = 0.6902s	
1865/22950 (epoch 4.063), train_loss = 1.78425454, grad/param norm = 2.1800e-01, time/batch = 0.6846s	
1866/22950 (epoch 4.065), train_loss = 1.41337529, grad/param norm = 2.5343e-01, time/batch = 0.6826s	
1867/22950 (epoch 4.068), train_loss = 1.90482039, grad/param norm = 2.2817e-01, time/batch = 0.6844s	
1868/22950 (epoch 4.070), train_loss = 1.66221579, grad/param norm = 2.4140e-01, time/batch = 0.6831s	
1869/22950 (epoch 4.072), train_loss = 1.74642650, grad/param norm = 2.5798e-01, time/batch = 0.6849s	
1870/22950 (epoch 4.074), train_loss = 1.71478609, grad/param norm = 2.5727e-01, time/batch = 0.6875s	
1871/22950 (epoch 4.076), train_loss = 1.70547280, grad/param norm = 2.5081e-01, time/batch = 0.6934s	
1872/22950 (epoch 4.078), train_loss = 1.80813469, grad/param norm = 2.5267e-01, time/batch = 0.6947s	
1873/22950 (epoch 4.081), train_loss = 1.82838907, grad/param norm = 2.2376e-01, time/batch = 0.6911s	
1874/22950 (epoch 4.083), train_loss = 1.71832088, grad/param norm = 2.6629e-01, time/batch = 0.6886s	
1875/22950 (epoch 4.085), train_loss = 1.62266973, grad/param norm = 2.2554e-01, time/batch = 0.6879s	
1876/22950 (epoch 4.087), train_loss = 1.68631874, grad/param norm = 2.2653e-01, time/batch = 0.6900s	
1877/22950 (epoch 4.089), train_loss = 1.72995113, grad/param norm = 2.0299e-01, time/batch = 0.6872s	
1878/22950 (epoch 4.092), train_loss = 1.76779414, grad/param norm = 2.3575e-01, time/batch = 0.6860s	
1879/22950 (epoch 4.094), train_loss = 1.66797301, grad/param norm = 2.1695e-01, time/batch = 0.6878s	
1880/22950 (epoch 4.096), train_loss = 1.88395009, grad/param norm = 2.1545e-01, time/batch = 0.6844s	
1881/22950 (epoch 4.098), train_loss = 1.76226664, grad/param norm = 2.2944e-01, time/batch = 0.6871s	
1882/22950 (epoch 4.100), train_loss = 1.67241691, grad/param norm = 2.1794e-01, time/batch = 0.6864s	
1883/22950 (epoch 4.102), train_loss = 1.73270838, grad/param norm = 1.9570e-01, time/batch = 0.6888s	
1884/22950 (epoch 4.105), train_loss = 1.64808118, grad/param norm = 2.0577e-01, time/batch = 0.6858s	
1885/22950 (epoch 4.107), train_loss = 1.72508025, grad/param norm = 2.5208e-01, time/batch = 0.6944s	
1886/22950 (epoch 4.109), train_loss = 1.69383019, grad/param norm = 2.3914e-01, time/batch = 0.7169s	
1887/22950 (epoch 4.111), train_loss = 1.59062975, grad/param norm = 2.0915e-01, time/batch = 0.7215s	
1888/22950 (epoch 4.113), train_loss = 1.76243891, grad/param norm = 2.2677e-01, time/batch = 0.7030s	
1889/22950 (epoch 4.115), train_loss = 1.86349097, grad/param norm = 2.6011e-01, time/batch = 0.6929s	
1890/22950 (epoch 4.118), train_loss = 1.84913800, grad/param norm = 2.2832e-01, time/batch = 0.6978s	
1891/22950 (epoch 4.120), train_loss = 1.68333941, grad/param norm = 2.1603e-01, time/batch = 0.6989s	
1892/22950 (epoch 4.122), train_loss = 1.82575098, grad/param norm = 2.4329e-01, time/batch = 0.6934s	
1893/22950 (epoch 4.124), train_loss = 1.53084064, grad/param norm = 2.1947e-01, time/batch = 0.6956s	
1894/22950 (epoch 4.126), train_loss = 1.67650271, grad/param norm = 2.1742e-01, time/batch = 0.6871s	
1895/22950 (epoch 4.129), train_loss = 1.53303505, grad/param norm = 2.2337e-01, time/batch = 0.6881s	
1896/22950 (epoch 4.131), train_loss = 1.77162179, grad/param norm = 2.5808e-01, time/batch = 0.6899s	
1897/22950 (epoch 4.133), train_loss = 1.84791714, grad/param norm = 2.1663e-01, time/batch = 0.6946s	
1898/22950 (epoch 4.135), train_loss = 1.70532271, grad/param norm = 2.3276e-01, time/batch = 0.7256s	
1899/22950 (epoch 4.137), train_loss = 1.96986318, grad/param norm = 2.3696e-01, time/batch = 0.6977s	
1900/22950 (epoch 4.139), train_loss = 1.68799728, grad/param norm = 2.4860e-01, time/batch = 0.6926s	
1901/22950 (epoch 4.142), train_loss = 1.61798790, grad/param norm = 2.5254e-01, time/batch = 0.6948s	
1902/22950 (epoch 4.144), train_loss = 1.61154949, grad/param norm = 2.2468e-01, time/batch = 0.6904s	
1903/22950 (epoch 4.146), train_loss = 1.78265305, grad/param norm = 2.4555e-01, time/batch = 0.6852s	
1904/22950 (epoch 4.148), train_loss = 1.66631648, grad/param norm = 2.1830e-01, time/batch = 0.6854s	
1905/22950 (epoch 4.150), train_loss = 1.69693596, grad/param norm = 2.2349e-01, time/batch = 0.6883s	
1906/22950 (epoch 4.153), train_loss = 1.70364694, grad/param norm = 2.2635e-01, time/batch = 0.6883s	
1907/22950 (epoch 4.155), train_loss = 1.65317923, grad/param norm = 2.2581e-01, time/batch = 0.6872s	
1908/22950 (epoch 4.157), train_loss = 1.66101748, grad/param norm = 2.5577e-01, time/batch = 0.7065s	
1909/22950 (epoch 4.159), train_loss = 1.57170064, grad/param norm = 2.0518e-01, time/batch = 0.6911s	
1910/22950 (epoch 4.161), train_loss = 1.77822698, grad/param norm = 2.1283e-01, time/batch = 0.6853s	
1911/22950 (epoch 4.163), train_loss = 1.70621529, grad/param norm = 1.9952e-01, time/batch = 0.6870s	
1912/22950 (epoch 4.166), train_loss = 1.85689909, grad/param norm = 2.1738e-01, time/batch = 0.6875s	
1913/22950 (epoch 4.168), train_loss = 1.87072130, grad/param norm = 2.8666e-01, time/batch = 0.6851s	
1914/22950 (epoch 4.170), train_loss = 1.81360773, grad/param norm = 2.6915e-01, time/batch = 0.6889s	
1915/22950 (epoch 4.172), train_loss = 1.71135735, grad/param norm = 2.1666e-01, time/batch = 0.6888s	
1916/22950 (epoch 4.174), train_loss = 1.76583759, grad/param norm = 2.5231e-01, time/batch = 0.6911s	
1917/22950 (epoch 4.176), train_loss = 1.86496699, grad/param norm = 2.2330e-01, time/batch = 0.6896s	
1918/22950 (epoch 4.179), train_loss = 1.82194771, grad/param norm = 2.7332e-01, time/batch = 0.6985s	
1919/22950 (epoch 4.181), train_loss = 1.90765391, grad/param norm = 2.6214e-01, time/batch = 0.7004s	
1920/22950 (epoch 4.183), train_loss = 1.82915460, grad/param norm = 2.3315e-01, time/batch = 0.6874s	
1921/22950 (epoch 4.185), train_loss = 1.80420461, grad/param norm = 2.2211e-01, time/batch = 0.6883s	
1922/22950 (epoch 4.187), train_loss = 1.62654992, grad/param norm = 2.4888e-01, time/batch = 0.6870s	
1923/22950 (epoch 4.190), train_loss = 1.78622925, grad/param norm = 2.7410e-01, time/batch = 0.7143s	
1924/22950 (epoch 4.192), train_loss = 1.64493654, grad/param norm = 2.0992e-01, time/batch = 0.7121s	
1925/22950 (epoch 4.194), train_loss = 1.75994452, grad/param norm = 2.5921e-01, time/batch = 0.6998s	
1926/22950 (epoch 4.196), train_loss = 1.53429784, grad/param norm = 2.3443e-01, time/batch = 0.7017s	
1927/22950 (epoch 4.198), train_loss = 1.88731512, grad/param norm = 2.2770e-01, time/batch = 0.6873s	
1928/22950 (epoch 4.200), train_loss = 1.55718194, grad/param norm = 2.3305e-01, time/batch = 0.6872s	
1929/22950 (epoch 4.203), train_loss = 1.54122846, grad/param norm = 2.2167e-01, time/batch = 0.6884s	
1930/22950 (epoch 4.205), train_loss = 1.63859894, grad/param norm = 2.6596e-01, time/batch = 0.6886s	
1931/22950 (epoch 4.207), train_loss = 1.72876193, grad/param norm = 2.2998e-01, time/batch = 0.6896s	
1932/22950 (epoch 4.209), train_loss = 1.96492845, grad/param norm = 2.5366e-01, time/batch = 0.6882s	
1933/22950 (epoch 4.211), train_loss = 1.66848600, grad/param norm = 2.6541e-01, time/batch = 0.6907s	
1934/22950 (epoch 4.214), train_loss = 1.68161508, grad/param norm = 2.4426e-01, time/batch = 0.6919s	
1935/22950 (epoch 4.216), train_loss = 1.74643627, grad/param norm = 2.1073e-01, time/batch = 0.6891s	
1936/22950 (epoch 4.218), train_loss = 1.76023992, grad/param norm = 2.2090e-01, time/batch = 0.7004s	
1937/22950 (epoch 4.220), train_loss = 1.86702434, grad/param norm = 2.3628e-01, time/batch = 0.6987s	
1938/22950 (epoch 4.222), train_loss = 1.84742304, grad/param norm = 2.2700e-01, time/batch = 0.6910s	
1939/22950 (epoch 4.224), train_loss = 1.66477211, grad/param norm = 2.2311e-01, time/batch = 0.6880s	
1940/22950 (epoch 4.227), train_loss = 1.67571758, grad/param norm = 2.4810e-01, time/batch = 0.6871s	
1941/22950 (epoch 4.229), train_loss = 1.69686281, grad/param norm = 2.5252e-01, time/batch = 0.6882s	
1942/22950 (epoch 4.231), train_loss = 1.59614952, grad/param norm = 2.1139e-01, time/batch = 0.6842s	
1943/22950 (epoch 4.233), train_loss = 1.67231920, grad/param norm = 2.1493e-01, time/batch = 0.6893s	
1944/22950 (epoch 4.235), train_loss = 1.83361740, grad/param norm = 2.4044e-01, time/batch = 0.6876s	
1945/22950 (epoch 4.237), train_loss = 1.55125997, grad/param norm = 2.4646e-01, time/batch = 0.6924s	
1946/22950 (epoch 4.240), train_loss = 1.64188473, grad/param norm = 2.0808e-01, time/batch = 0.6888s	
1947/22950 (epoch 4.242), train_loss = 1.75907746, grad/param norm = 2.6430e-01, time/batch = 0.6887s	
1948/22950 (epoch 4.244), train_loss = 1.89255600, grad/param norm = 2.5723e-01, time/batch = 0.6893s	
1949/22950 (epoch 4.246), train_loss = 1.80511985, grad/param norm = 2.3639e-01, time/batch = 0.6921s	
1950/22950 (epoch 4.248), train_loss = 1.75531169, grad/param norm = 2.4343e-01, time/batch = 0.6885s	
1951/22950 (epoch 4.251), train_loss = 1.75743179, grad/param norm = 2.4117e-01, time/batch = 0.6873s	
1952/22950 (epoch 4.253), train_loss = 1.73442910, grad/param norm = 2.2913e-01, time/batch = 0.6854s	
1953/22950 (epoch 4.255), train_loss = 1.64237689, grad/param norm = 2.1059e-01, time/batch = 0.6892s	
1954/22950 (epoch 4.257), train_loss = 1.86375658, grad/param norm = 2.2093e-01, time/batch = 0.6863s	
1955/22950 (epoch 4.259), train_loss = 1.54300831, grad/param norm = 2.2696e-01, time/batch = 0.6846s	
1956/22950 (epoch 4.261), train_loss = 1.81659100, grad/param norm = 2.3680e-01, time/batch = 0.6866s	
1957/22950 (epoch 4.264), train_loss = 1.59858204, grad/param norm = 1.8634e-01, time/batch = 0.6892s	
1958/22950 (epoch 4.266), train_loss = 1.85789071, grad/param norm = 2.3596e-01, time/batch = 0.6883s	
1959/22950 (epoch 4.268), train_loss = 1.81429558, grad/param norm = 2.2048e-01, time/batch = 0.6891s	
1960/22950 (epoch 4.270), train_loss = 1.83667530, grad/param norm = 2.3719e-01, time/batch = 0.6852s	
1961/22950 (epoch 4.272), train_loss = 1.91655105, grad/param norm = 2.2334e-01, time/batch = 0.6875s	
1962/22950 (epoch 4.275), train_loss = 1.61323264, grad/param norm = 2.6236e-01, time/batch = 0.6852s	
1963/22950 (epoch 4.277), train_loss = 1.60619865, grad/param norm = 2.5430e-01, time/batch = 0.6855s	
1964/22950 (epoch 4.279), train_loss = 1.82158024, grad/param norm = 2.5529e-01, time/batch = 0.6835s	
1965/22950 (epoch 4.281), train_loss = 1.69951619, grad/param norm = 2.8356e-01, time/batch = 0.6832s	
1966/22950 (epoch 4.283), train_loss = 1.60939487, grad/param norm = 2.6100e-01, time/batch = 0.6830s	
1967/22950 (epoch 4.285), train_loss = 1.72524561, grad/param norm = 2.3502e-01, time/batch = 0.6850s	
1968/22950 (epoch 4.288), train_loss = 1.68548017, grad/param norm = 2.6738e-01, time/batch = 0.7046s	
1969/22950 (epoch 4.290), train_loss = 1.65394069, grad/param norm = 2.2181e-01, time/batch = 0.7190s	
1970/22950 (epoch 4.292), train_loss = 1.76714172, grad/param norm = 2.1374e-01, time/batch = 0.6965s	
1971/22950 (epoch 4.294), train_loss = 1.79013697, grad/param norm = 2.3102e-01, time/batch = 0.6998s	
1972/22950 (epoch 4.296), train_loss = 1.46859156, grad/param norm = 2.0934e-01, time/batch = 0.7110s	
1973/22950 (epoch 4.298), train_loss = 1.66286904, grad/param norm = 2.2140e-01, time/batch = 0.7229s	
1974/22950 (epoch 4.301), train_loss = 1.76282986, grad/param norm = 2.4327e-01, time/batch = 0.7081s	
1975/22950 (epoch 4.303), train_loss = 1.79715471, grad/param norm = 2.2639e-01, time/batch = 0.6931s	
1976/22950 (epoch 4.305), train_loss = 1.85873442, grad/param norm = 2.2936e-01, time/batch = 0.6966s	
1977/22950 (epoch 4.307), train_loss = 1.81807933, grad/param norm = 2.2894e-01, time/batch = 0.6893s	
1978/22950 (epoch 4.309), train_loss = 1.78743090, grad/param norm = 2.0573e-01, time/batch = 0.6927s	
1979/22950 (epoch 4.312), train_loss = 1.79869086, grad/param norm = 2.1482e-01, time/batch = 0.6895s	
1980/22950 (epoch 4.314), train_loss = 1.57574884, grad/param norm = 2.2028e-01, time/batch = 0.6880s	
1981/22950 (epoch 4.316), train_loss = 1.76744321, grad/param norm = 2.4065e-01, time/batch = 0.6870s	
1982/22950 (epoch 4.318), train_loss = 1.54135413, grad/param norm = 2.1738e-01, time/batch = 0.6900s	
1983/22950 (epoch 4.320), train_loss = 1.68404048, grad/param norm = 1.8808e-01, time/batch = 0.6927s	
1984/22950 (epoch 4.322), train_loss = 1.68849017, grad/param norm = 2.1462e-01, time/batch = 0.6863s	
1985/22950 (epoch 4.325), train_loss = 1.39345022, grad/param norm = 2.0284e-01, time/batch = 0.7076s	
1986/22950 (epoch 4.327), train_loss = 1.46366243, grad/param norm = 2.0401e-01, time/batch = 0.7178s	
1987/22950 (epoch 4.329), train_loss = 1.60679207, grad/param norm = 2.2231e-01, time/batch = 0.7267s	
1988/22950 (epoch 4.331), train_loss = 1.55928785, grad/param norm = 2.1361e-01, time/batch = 0.7219s	
1989/22950 (epoch 4.333), train_loss = 1.63671904, grad/param norm = 2.2889e-01, time/batch = 0.7205s	
1990/22950 (epoch 4.336), train_loss = 1.72259448, grad/param norm = 2.5496e-01, time/batch = 0.7125s	
1991/22950 (epoch 4.338), train_loss = 1.65774877, grad/param norm = 3.0961e-01, time/batch = 0.7115s	
1992/22950 (epoch 4.340), train_loss = 1.59508214, grad/param norm = 2.5501e-01, time/batch = 0.6871s	
1993/22950 (epoch 4.342), train_loss = 1.74219391, grad/param norm = 2.1747e-01, time/batch = 0.6893s	
1994/22950 (epoch 4.344), train_loss = 1.70987930, grad/param norm = 2.3831e-01, time/batch = 0.6850s	
1995/22950 (epoch 4.346), train_loss = 1.92138262, grad/param norm = 2.4852e-01, time/batch = 0.6827s	
1996/22950 (epoch 4.349), train_loss = 1.77073709, grad/param norm = 2.6001e-01, time/batch = 0.6874s	
1997/22950 (epoch 4.351), train_loss = 1.70602139, grad/param norm = 2.2412e-01, time/batch = 0.6854s	
1998/22950 (epoch 4.353), train_loss = 1.78883297, grad/param norm = 2.5589e-01, time/batch = 0.6856s	
1999/22950 (epoch 4.355), train_loss = 1.86628857, grad/param norm = 2.6961e-01, time/batch = 0.6893s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch4.36_1.7793.t7	
2000/22950 (epoch 4.357), train_loss = 1.75052928, grad/param norm = 2.1532e-01, time/batch = 0.6884s	
2001/22950 (epoch 4.359), train_loss = 1.92782581, grad/param norm = 2.4276e-01, time/batch = 0.6910s	
2002/22950 (epoch 4.362), train_loss = 1.62659078, grad/param norm = 2.2667e-01, time/batch = 0.6908s	
2003/22950 (epoch 4.364), train_loss = 1.73677044, grad/param norm = 2.4110e-01, time/batch = 0.6886s	
2004/22950 (epoch 4.366), train_loss = 1.49721174, grad/param norm = 2.2131e-01, time/batch = 0.6877s	
2005/22950 (epoch 4.368), train_loss = 1.72258566, grad/param norm = 2.2886e-01, time/batch = 0.6892s	
2006/22950 (epoch 4.370), train_loss = 1.67084051, grad/param norm = 2.3011e-01, time/batch = 0.7008s	
2007/22950 (epoch 4.373), train_loss = 1.54112104, grad/param norm = 1.9197e-01, time/batch = 0.6882s	
2008/22950 (epoch 4.375), train_loss = 1.89340810, grad/param norm = 2.4414e-01, time/batch = 0.6876s	
2009/22950 (epoch 4.377), train_loss = 1.65310307, grad/param norm = 2.2813e-01, time/batch = 0.6977s	
2010/22950 (epoch 4.379), train_loss = 1.84266771, grad/param norm = 2.1142e-01, time/batch = 0.7240s	
2011/22950 (epoch 4.381), train_loss = 1.55618333, grad/param norm = 2.1765e-01, time/batch = 0.7089s	
2012/22950 (epoch 4.383), train_loss = 1.78064632, grad/param norm = 2.6110e-01, time/batch = 0.6958s	
2013/22950 (epoch 4.386), train_loss = 1.75358706, grad/param norm = 2.6841e-01, time/batch = 0.6938s	
2014/22950 (epoch 4.388), train_loss = 1.76120563, grad/param norm = 2.3578e-01, time/batch = 0.6887s	
2015/22950 (epoch 4.390), train_loss = 1.57862051, grad/param norm = 2.4226e-01, time/batch = 0.6932s	
2016/22950 (epoch 4.392), train_loss = 1.55930887, grad/param norm = 2.1911e-01, time/batch = 0.6841s	
2017/22950 (epoch 4.394), train_loss = 1.60865150, grad/param norm = 2.0382e-01, time/batch = 0.6792s	
2018/22950 (epoch 4.397), train_loss = 1.74495301, grad/param norm = 2.3178e-01, time/batch = 0.6804s	
2019/22950 (epoch 4.399), train_loss = 1.79046187, grad/param norm = 2.2051e-01, time/batch = 0.6954s	
2020/22950 (epoch 4.401), train_loss = 1.99426307, grad/param norm = 2.3873e-01, time/batch = 0.6883s	
2021/22950 (epoch 4.403), train_loss = 1.69489093, grad/param norm = 2.5409e-01, time/batch = 0.7013s	
2022/22950 (epoch 4.405), train_loss = 1.75064752, grad/param norm = 2.3211e-01, time/batch = 0.7188s	
2023/22950 (epoch 4.407), train_loss = 1.84360968, grad/param norm = 2.1473e-01, time/batch = 0.6974s	
2024/22950 (epoch 4.410), train_loss = 1.52449499, grad/param norm = 2.0832e-01, time/batch = 0.7002s	
2025/22950 (epoch 4.412), train_loss = 1.70752735, grad/param norm = 2.1604e-01, time/batch = 0.7060s	
2026/22950 (epoch 4.414), train_loss = 1.77678176, grad/param norm = 2.4073e-01, time/batch = 0.6996s	
2027/22950 (epoch 4.416), train_loss = 1.82179278, grad/param norm = 2.2413e-01, time/batch = 0.6954s	
2028/22950 (epoch 4.418), train_loss = 1.82001672, grad/param norm = 2.3148e-01, time/batch = 0.6999s	
2029/22950 (epoch 4.420), train_loss = 1.78161257, grad/param norm = 2.1765e-01, time/batch = 0.6952s	
2030/22950 (epoch 4.423), train_loss = 1.56351573, grad/param norm = 1.9784e-01, time/batch = 0.7242s	
2031/22950 (epoch 4.425), train_loss = 1.70674826, grad/param norm = 2.0383e-01, time/batch = 0.7168s	
2032/22950 (epoch 4.427), train_loss = 1.63892334, grad/param norm = 2.2275e-01, time/batch = 0.6998s	
2033/22950 (epoch 4.429), train_loss = 1.57065027, grad/param norm = 2.1116e-01, time/batch = 0.6873s	
2034/22950 (epoch 4.431), train_loss = 1.71429174, grad/param norm = 2.3533e-01, time/batch = 0.6815s	
2035/22950 (epoch 4.434), train_loss = 1.69921122, grad/param norm = 2.6478e-01, time/batch = 0.6798s	
2036/22950 (epoch 4.436), train_loss = 1.96323130, grad/param norm = 2.5757e-01, time/batch = 0.6977s	
2037/22950 (epoch 4.438), train_loss = 1.72614785, grad/param norm = 2.4880e-01, time/batch = 0.6812s	
2038/22950 (epoch 4.440), train_loss = 1.74079804, grad/param norm = 2.0967e-01, time/batch = 0.6776s	
2039/22950 (epoch 4.442), train_loss = 1.88857168, grad/param norm = 2.5769e-01, time/batch = 0.6766s	
2040/22950 (epoch 4.444), train_loss = 1.87719255, grad/param norm = 2.3923e-01, time/batch = 0.6744s	
2041/22950 (epoch 4.447), train_loss = 1.88167657, grad/param norm = 2.7159e-01, time/batch = 0.6845s	
2042/22950 (epoch 4.449), train_loss = 1.58095843, grad/param norm = 2.2030e-01, time/batch = 0.7127s	
2043/22950 (epoch 4.451), train_loss = 1.75349348, grad/param norm = 2.3634e-01, time/batch = 0.6829s	
2044/22950 (epoch 4.453), train_loss = 1.79769497, grad/param norm = 2.1459e-01, time/batch = 0.6740s	
2045/22950 (epoch 4.455), train_loss = 1.61947552, grad/param norm = 2.0980e-01, time/batch = 0.6779s	
2046/22950 (epoch 4.458), train_loss = 1.89009170, grad/param norm = 2.2963e-01, time/batch = 0.6755s	
2047/22950 (epoch 4.460), train_loss = 1.80366866, grad/param norm = 2.4064e-01, time/batch = 0.6767s	
2048/22950 (epoch 4.462), train_loss = 1.67507345, grad/param norm = 2.2407e-01, time/batch = 0.6736s	
2049/22950 (epoch 4.464), train_loss = 1.71162556, grad/param norm = 2.4053e-01, time/batch = 0.6893s	
2050/22950 (epoch 4.466), train_loss = 1.68840084, grad/param norm = 2.4604e-01, time/batch = 0.6943s	
2051/22950 (epoch 4.468), train_loss = 1.81730588, grad/param norm = 2.1383e-01, time/batch = 0.7221s	
2052/22950 (epoch 4.471), train_loss = 1.65108915, grad/param norm = 2.1266e-01, time/batch = 0.7325s	
2053/22950 (epoch 4.473), train_loss = 1.78124955, grad/param norm = 2.4550e-01, time/batch = 0.7175s	
2054/22950 (epoch 4.475), train_loss = 1.92716041, grad/param norm = 2.7951e-01, time/batch = 0.7184s	
2055/22950 (epoch 4.477), train_loss = 1.76190997, grad/param norm = 2.3504e-01, time/batch = 0.7138s	
2056/22950 (epoch 4.479), train_loss = 1.77030721, grad/param norm = 2.2954e-01, time/batch = 0.7036s	
2057/22950 (epoch 4.481), train_loss = 1.93732008, grad/param norm = 2.6647e-01, time/batch = 0.6973s	
2058/22950 (epoch 4.484), train_loss = 1.92099517, grad/param norm = 2.6973e-01, time/batch = 0.6981s	
2059/22950 (epoch 4.486), train_loss = 1.57819060, grad/param norm = 2.4942e-01, time/batch = 0.6941s	
2060/22950 (epoch 4.488), train_loss = 1.68798657, grad/param norm = 2.4040e-01, time/batch = 0.6920s	
2061/22950 (epoch 4.490), train_loss = 1.63929480, grad/param norm = 2.1597e-01, time/batch = 0.7020s	
2062/22950 (epoch 4.492), train_loss = 1.74241149, grad/param norm = 2.1275e-01, time/batch = 0.7278s	
2063/22950 (epoch 4.495), train_loss = 1.73412286, grad/param norm = 2.1762e-01, time/batch = 0.6983s	
2064/22950 (epoch 4.497), train_loss = 1.80371370, grad/param norm = 2.1972e-01, time/batch = 0.6946s	
2065/22950 (epoch 4.499), train_loss = 1.80351214, grad/param norm = 2.4198e-01, time/batch = 0.6938s	
2066/22950 (epoch 4.501), train_loss = 1.84587676, grad/param norm = 2.2577e-01, time/batch = 0.6958s	
2067/22950 (epoch 4.503), train_loss = 1.82429812, grad/param norm = 2.3132e-01, time/batch = 0.6918s	
2068/22950 (epoch 4.505), train_loss = 1.62218068, grad/param norm = 2.1253e-01, time/batch = 0.6968s	
2069/22950 (epoch 4.508), train_loss = 1.73083223, grad/param norm = 2.2939e-01, time/batch = 0.7011s	
2070/22950 (epoch 4.510), train_loss = 1.67513502, grad/param norm = 2.1802e-01, time/batch = 0.6974s	
2071/22950 (epoch 4.512), train_loss = 1.67245131, grad/param norm = 2.4222e-01, time/batch = 0.7008s	
2072/22950 (epoch 4.514), train_loss = 1.52181600, grad/param norm = 2.4227e-01, time/batch = 0.6917s	
2073/22950 (epoch 4.516), train_loss = 1.56621647, grad/param norm = 2.2829e-01, time/batch = 0.6938s	
2074/22950 (epoch 4.519), train_loss = 1.66079533, grad/param norm = 2.2013e-01, time/batch = 0.6931s	
2075/22950 (epoch 4.521), train_loss = 1.66948865, grad/param norm = 2.0955e-01, time/batch = 0.6902s	
2076/22950 (epoch 4.523), train_loss = 1.46831629, grad/param norm = 2.1821e-01, time/batch = 0.6936s	
2077/22950 (epoch 4.525), train_loss = 1.63807429, grad/param norm = 2.1941e-01, time/batch = 0.6935s	
2078/22950 (epoch 4.527), train_loss = 1.47876501, grad/param norm = 2.1016e-01, time/batch = 0.6903s	
2079/22950 (epoch 4.529), train_loss = 1.76057165, grad/param norm = 2.0986e-01, time/batch = 0.6911s	
2080/22950 (epoch 4.532), train_loss = 1.70141826, grad/param norm = 2.2607e-01, time/batch = 0.6905s	
2081/22950 (epoch 4.534), train_loss = 1.80131350, grad/param norm = 2.4202e-01, time/batch = 0.7035s	
2082/22950 (epoch 4.536), train_loss = 1.74133076, grad/param norm = 2.4943e-01, time/batch = 0.7279s	
2083/22950 (epoch 4.538), train_loss = 1.70200392, grad/param norm = 2.5685e-01, time/batch = 0.7014s	
2084/22950 (epoch 4.540), train_loss = 1.64941675, grad/param norm = 2.1850e-01, time/batch = 0.6915s	
2085/22950 (epoch 4.542), train_loss = 1.93127482, grad/param norm = 2.2489e-01, time/batch = 0.6920s	
2086/22950 (epoch 4.545), train_loss = 1.62426735, grad/param norm = 2.1430e-01, time/batch = 0.6896s	
2087/22950 (epoch 4.547), train_loss = 1.66974613, grad/param norm = 2.2387e-01, time/batch = 0.6890s	
2088/22950 (epoch 4.549), train_loss = 1.68039240, grad/param norm = 2.4962e-01, time/batch = 0.7000s	
2089/22950 (epoch 4.551), train_loss = 1.76164544, grad/param norm = 2.7527e-01, time/batch = 0.6972s	
2090/22950 (epoch 4.553), train_loss = 1.66993528, grad/param norm = 2.3981e-01, time/batch = 0.6938s	
2091/22950 (epoch 4.556), train_loss = 1.78570605, grad/param norm = 2.2330e-01, time/batch = 0.7009s	
2092/22950 (epoch 4.558), train_loss = 1.67789463, grad/param norm = 2.0044e-01, time/batch = 0.7282s	
2093/22950 (epoch 4.560), train_loss = 1.72808930, grad/param norm = 1.9896e-01, time/batch = 0.6974s	
2094/22950 (epoch 4.562), train_loss = 1.56968315, grad/param norm = 2.1665e-01, time/batch = 0.6927s	
2095/22950 (epoch 4.564), train_loss = 1.93691332, grad/param norm = 2.6280e-01, time/batch = 0.6919s	
2096/22950 (epoch 4.566), train_loss = 1.73466840, grad/param norm = 2.3350e-01, time/batch = 0.6947s	
2097/22950 (epoch 4.569), train_loss = 1.86966100, grad/param norm = 2.4520e-01, time/batch = 0.6908s	
2098/22950 (epoch 4.571), train_loss = 1.55095467, grad/param norm = 2.0685e-01, time/batch = 0.6900s	
2099/22950 (epoch 4.573), train_loss = 1.67281112, grad/param norm = 2.0822e-01, time/batch = 0.7045s	
2100/22950 (epoch 4.575), train_loss = 2.04576674, grad/param norm = 2.2713e-01, time/batch = 0.7046s	
2101/22950 (epoch 4.577), train_loss = 1.73400700, grad/param norm = 2.4045e-01, time/batch = 0.6999s	
2102/22950 (epoch 4.580), train_loss = 1.77257997, grad/param norm = 2.4023e-01, time/batch = 0.6937s	
2103/22950 (epoch 4.582), train_loss = 1.89381509, grad/param norm = 2.1577e-01, time/batch = 0.6901s	
2104/22950 (epoch 4.584), train_loss = 1.49730052, grad/param norm = 2.2187e-01, time/batch = 0.6907s	
2105/22950 (epoch 4.586), train_loss = 1.58767182, grad/param norm = 2.2095e-01, time/batch = 0.6914s	
2106/22950 (epoch 4.588), train_loss = 1.83880034, grad/param norm = 2.2483e-01, time/batch = 0.6936s	
2107/22950 (epoch 4.590), train_loss = 1.65265199, grad/param norm = 2.2615e-01, time/batch = 0.6920s	
2108/22950 (epoch 4.593), train_loss = 1.51953896, grad/param norm = 2.2683e-01, time/batch = 0.6920s	
2109/22950 (epoch 4.595), train_loss = 1.60156901, grad/param norm = 2.3826e-01, time/batch = 0.6944s	
2110/22950 (epoch 4.597), train_loss = 1.78999008, grad/param norm = 2.4595e-01, time/batch = 0.6931s	
2111/22950 (epoch 4.599), train_loss = 1.75307771, grad/param norm = 2.5914e-01, time/batch = 0.6942s	
2112/22950 (epoch 4.601), train_loss = 1.71798997, grad/param norm = 2.5046e-01, time/batch = 0.6901s	
2113/22950 (epoch 4.603), train_loss = 1.84721405, grad/param norm = 2.4886e-01, time/batch = 0.6901s	
2114/22950 (epoch 4.606), train_loss = 1.65530903, grad/param norm = 2.3373e-01, time/batch = 0.6899s	
2115/22950 (epoch 4.608), train_loss = 1.64884478, grad/param norm = 2.2441e-01, time/batch = 0.6934s	
2116/22950 (epoch 4.610), train_loss = 1.66250491, grad/param norm = 2.2047e-01, time/batch = 0.7004s	
2117/22950 (epoch 4.612), train_loss = 1.70451811, grad/param norm = 2.1324e-01, time/batch = 0.6861s	
2118/22950 (epoch 4.614), train_loss = 1.84418857, grad/param norm = 2.3391e-01, time/batch = 0.6887s	
2119/22950 (epoch 4.617), train_loss = 1.72552949, grad/param norm = 2.3187e-01, time/batch = 0.6883s	
2120/22950 (epoch 4.619), train_loss = 1.57228239, grad/param norm = 2.0681e-01, time/batch = 0.6870s	
2121/22950 (epoch 4.621), train_loss = 1.79046747, grad/param norm = 2.1389e-01, time/batch = 0.6893s	
2122/22950 (epoch 4.623), train_loss = 1.66801327, grad/param norm = 1.9968e-01, time/batch = 0.6906s	
2123/22950 (epoch 4.625), train_loss = 1.67994732, grad/param norm = 2.0579e-01, time/batch = 0.6855s	
2124/22950 (epoch 4.627), train_loss = 1.72235917, grad/param norm = 2.2996e-01, time/batch = 0.6892s	
2125/22950 (epoch 4.630), train_loss = 1.51373617, grad/param norm = 2.0193e-01, time/batch = 0.6902s	
2126/22950 (epoch 4.632), train_loss = 1.75759090, grad/param norm = 2.2674e-01, time/batch = 0.6890s	
2127/22950 (epoch 4.634), train_loss = 1.63675365, grad/param norm = 2.1812e-01, time/batch = 0.6900s	
2128/22950 (epoch 4.636), train_loss = 1.66596021, grad/param norm = 2.0632e-01, time/batch = 0.6930s	
2129/22950 (epoch 4.638), train_loss = 1.59555088, grad/param norm = 2.1799e-01, time/batch = 0.6923s	
2130/22950 (epoch 4.641), train_loss = 1.62868728, grad/param norm = 2.0220e-01, time/batch = 0.6914s	
2131/22950 (epoch 4.643), train_loss = 1.71069073, grad/param norm = 2.4539e-01, time/batch = 0.6951s	
2132/22950 (epoch 4.645), train_loss = 1.62316413, grad/param norm = 2.9665e-01, time/batch = 0.6941s	
2133/22950 (epoch 4.647), train_loss = 1.71570134, grad/param norm = 2.4240e-01, time/batch = 0.6902s	
2134/22950 (epoch 4.649), train_loss = 1.67366087, grad/param norm = 1.9678e-01, time/batch = 0.6892s	
2135/22950 (epoch 4.651), train_loss = 1.79416007, grad/param norm = 2.3785e-01, time/batch = 0.6925s	
2136/22950 (epoch 4.654), train_loss = 1.47025272, grad/param norm = 2.0075e-01, time/batch = 0.7164s	
2137/22950 (epoch 4.656), train_loss = 1.80933808, grad/param norm = 2.1978e-01, time/batch = 0.7251s	
2138/22950 (epoch 4.658), train_loss = 1.59026196, grad/param norm = 2.0360e-01, time/batch = 0.7378s	
2139/22950 (epoch 4.660), train_loss = 1.51108427, grad/param norm = 1.9889e-01, time/batch = 0.7211s	
2140/22950 (epoch 4.662), train_loss = 1.55603008, grad/param norm = 2.1390e-01, time/batch = 0.6991s	
2141/22950 (epoch 4.664), train_loss = 1.75590116, grad/param norm = 2.1939e-01, time/batch = 0.7037s	
2142/22950 (epoch 4.667), train_loss = 1.74252501, grad/param norm = 2.3124e-01, time/batch = 0.7140s	
2143/22950 (epoch 4.669), train_loss = 1.59282736, grad/param norm = 2.3682e-01, time/batch = 0.6969s	
2144/22950 (epoch 4.671), train_loss = 1.77110805, grad/param norm = 2.2978e-01, time/batch = 0.6948s	
2145/22950 (epoch 4.673), train_loss = 1.71717217, grad/param norm = 1.9223e-01, time/batch = 0.6997s	
2146/22950 (epoch 4.675), train_loss = 1.66419889, grad/param norm = 2.0778e-01, time/batch = 0.7121s	
2147/22950 (epoch 4.678), train_loss = 1.72287238, grad/param norm = 2.1456e-01, time/batch = 0.6778s	
2148/22950 (epoch 4.680), train_loss = 1.74025911, grad/param norm = 2.0368e-01, time/batch = 0.6775s	
2149/22950 (epoch 4.682), train_loss = 1.79371537, grad/param norm = 2.1485e-01, time/batch = 0.6739s	
2150/22950 (epoch 4.684), train_loss = 1.76529328, grad/param norm = 2.1856e-01, time/batch = 0.6742s	
2151/22950 (epoch 4.686), train_loss = 1.73774422, grad/param norm = 2.0999e-01, time/batch = 0.6774s	
2152/22950 (epoch 4.688), train_loss = 1.66269669, grad/param norm = 2.0816e-01, time/batch = 0.6728s	
2153/22950 (epoch 4.691), train_loss = 1.63155392, grad/param norm = 2.1320e-01, time/batch = 0.6723s	
2154/22950 (epoch 4.693), train_loss = 1.62668150, grad/param norm = 2.1225e-01, time/batch = 0.6719s	
2155/22950 (epoch 4.695), train_loss = 1.86895594, grad/param norm = 2.3654e-01, time/batch = 0.6715s	
2156/22950 (epoch 4.697), train_loss = 1.83648942, grad/param norm = 2.1398e-01, time/batch = 0.6699s	
2157/22950 (epoch 4.699), train_loss = 1.74424700, grad/param norm = 2.0786e-01, time/batch = 0.6741s	
2158/22950 (epoch 4.702), train_loss = 1.73174336, grad/param norm = 2.0814e-01, time/batch = 0.6724s	
2159/22950 (epoch 4.704), train_loss = 1.78830168, grad/param norm = 2.2505e-01, time/batch = 0.6707s	
2160/22950 (epoch 4.706), train_loss = 1.83381174, grad/param norm = 2.2134e-01, time/batch = 0.6704s	
2161/22950 (epoch 4.708), train_loss = 1.72865344, grad/param norm = 2.4988e-01, time/batch = 0.6765s	
2162/22950 (epoch 4.710), train_loss = 1.73937424, grad/param norm = 1.8795e-01, time/batch = 0.6759s	
2163/22950 (epoch 4.712), train_loss = 1.84117540, grad/param norm = 2.2097e-01, time/batch = 0.6759s	
2164/22950 (epoch 4.715), train_loss = 1.74366560, grad/param norm = 2.0564e-01, time/batch = 0.6751s	
2165/22950 (epoch 4.717), train_loss = 1.53594837, grad/param norm = 1.9386e-01, time/batch = 0.6747s	
2166/22950 (epoch 4.719), train_loss = 1.73327752, grad/param norm = 2.1533e-01, time/batch = 0.6900s	
2167/22950 (epoch 4.721), train_loss = 1.79107568, grad/param norm = 2.1975e-01, time/batch = 0.7076s	
2168/22950 (epoch 4.723), train_loss = 1.59358488, grad/param norm = 2.0481e-01, time/batch = 0.6776s	
2169/22950 (epoch 4.725), train_loss = 1.87385683, grad/param norm = 2.3876e-01, time/batch = 0.6739s	
2170/22950 (epoch 4.728), train_loss = 1.69537647, grad/param norm = 2.4071e-01, time/batch = 0.6779s	
2171/22950 (epoch 4.730), train_loss = 1.70686110, grad/param norm = 2.3340e-01, time/batch = 0.6778s	
2172/22950 (epoch 4.732), train_loss = 1.67260061, grad/param norm = 1.9399e-01, time/batch = 0.6755s	
2173/22950 (epoch 4.734), train_loss = 1.70983185, grad/param norm = 2.1615e-01, time/batch = 0.6725s	
2174/22950 (epoch 4.736), train_loss = 1.58883643, grad/param norm = 2.4623e-01, time/batch = 0.6721s	
2175/22950 (epoch 4.739), train_loss = 1.72726418, grad/param norm = 2.3266e-01, time/batch = 0.6712s	
2176/22950 (epoch 4.741), train_loss = 1.74456921, grad/param norm = 2.3980e-01, time/batch = 0.6728s	
2177/22950 (epoch 4.743), train_loss = 1.88596168, grad/param norm = 2.3146e-01, time/batch = 0.6744s	
2178/22950 (epoch 4.745), train_loss = 1.91122214, grad/param norm = 2.3240e-01, time/batch = 0.6739s	
2179/22950 (epoch 4.747), train_loss = 1.70072016, grad/param norm = 2.4350e-01, time/batch = 0.6861s	
2180/22950 (epoch 4.749), train_loss = 1.62385170, grad/param norm = 2.2337e-01, time/batch = 0.6781s	
2181/22950 (epoch 4.752), train_loss = 1.85470914, grad/param norm = 2.2952e-01, time/batch = 0.6969s	
2182/22950 (epoch 4.754), train_loss = 1.79090806, grad/param norm = 2.3209e-01, time/batch = 0.6946s	
2183/22950 (epoch 4.756), train_loss = 1.54992289, grad/param norm = 2.1269e-01, time/batch = 0.6795s	
2184/22950 (epoch 4.758), train_loss = 1.64150434, grad/param norm = 2.1022e-01, time/batch = 0.6871s	
2185/22950 (epoch 4.760), train_loss = 1.67696980, grad/param norm = 2.1609e-01, time/batch = 0.6840s	
2186/22950 (epoch 4.763), train_loss = 1.65078044, grad/param norm = 2.2277e-01, time/batch = 0.6772s	
2187/22950 (epoch 4.765), train_loss = 1.75954056, grad/param norm = 2.2176e-01, time/batch = 0.6765s	
2188/22950 (epoch 4.767), train_loss = 1.83144525, grad/param norm = 2.1266e-01, time/batch = 0.6808s	
2189/22950 (epoch 4.769), train_loss = 1.69511055, grad/param norm = 2.1719e-01, time/batch = 0.6733s	
2190/22950 (epoch 4.771), train_loss = 1.54095953, grad/param norm = 2.0458e-01, time/batch = 0.6747s	
2191/22950 (epoch 4.773), train_loss = 1.40995549, grad/param norm = 1.9318e-01, time/batch = 0.6763s	
2192/22950 (epoch 4.776), train_loss = 1.60303684, grad/param norm = 1.9855e-01, time/batch = 0.6743s	
2193/22950 (epoch 4.778), train_loss = 1.51436190, grad/param norm = 2.0462e-01, time/batch = 0.6820s	
2194/22950 (epoch 4.780), train_loss = 1.53304710, grad/param norm = 2.1352e-01, time/batch = 0.6900s	
2195/22950 (epoch 4.782), train_loss = 1.61721961, grad/param norm = 2.1419e-01, time/batch = 0.6899s	
2196/22950 (epoch 4.784), train_loss = 1.73103662, grad/param norm = 2.3712e-01, time/batch = 0.6946s	
2197/22950 (epoch 4.786), train_loss = 1.73001270, grad/param norm = 2.1460e-01, time/batch = 0.6910s	
2198/22950 (epoch 4.789), train_loss = 1.52339448, grad/param norm = 2.1193e-01, time/batch = 0.6902s	
2199/22950 (epoch 4.791), train_loss = 1.59583299, grad/param norm = 2.2918e-01, time/batch = 0.6864s	
2200/22950 (epoch 4.793), train_loss = 1.94573755, grad/param norm = 2.1125e-01, time/batch = 0.6894s	
2201/22950 (epoch 4.795), train_loss = 1.57379651, grad/param norm = 1.9761e-01, time/batch = 0.6885s	
2202/22950 (epoch 4.797), train_loss = 1.88294715, grad/param norm = 2.4228e-01, time/batch = 0.6859s	
2203/22950 (epoch 4.800), train_loss = 1.59922544, grad/param norm = 2.7572e-01, time/batch = 0.6895s	
2204/22950 (epoch 4.802), train_loss = 1.62788276, grad/param norm = 2.1916e-01, time/batch = 0.6862s	
2205/22950 (epoch 4.804), train_loss = 1.65248271, grad/param norm = 2.1587e-01, time/batch = 0.6849s	
2206/22950 (epoch 4.806), train_loss = 1.56378220, grad/param norm = 2.1102e-01, time/batch = 0.6868s	
2207/22950 (epoch 4.808), train_loss = 1.62622989, grad/param norm = 2.1785e-01, time/batch = 0.6980s	
2208/22950 (epoch 4.810), train_loss = 1.63879190, grad/param norm = 2.2168e-01, time/batch = 0.7064s	
2209/22950 (epoch 4.813), train_loss = 1.41940297, grad/param norm = 1.9499e-01, time/batch = 0.7122s	
2210/22950 (epoch 4.815), train_loss = 1.64619620, grad/param norm = 2.0965e-01, time/batch = 0.7020s	
2211/22950 (epoch 4.817), train_loss = 1.55340251, grad/param norm = 2.2531e-01, time/batch = 0.7066s	
2212/22950 (epoch 4.819), train_loss = 1.64544069, grad/param norm = 2.1563e-01, time/batch = 0.7025s	
2213/22950 (epoch 4.821), train_loss = 1.65194826, grad/param norm = 2.3315e-01, time/batch = 0.7022s	
2214/22950 (epoch 4.824), train_loss = 1.60809852, grad/param norm = 2.2204e-01, time/batch = 0.6970s	
2215/22950 (epoch 4.826), train_loss = 1.75577841, grad/param norm = 2.1674e-01, time/batch = 0.6883s	
2216/22950 (epoch 4.828), train_loss = 1.64440397, grad/param norm = 2.1921e-01, time/batch = 0.6894s	
2217/22950 (epoch 4.830), train_loss = 1.71906717, grad/param norm = 2.2582e-01, time/batch = 0.6892s	
2218/22950 (epoch 4.832), train_loss = 1.68879641, grad/param norm = 2.2405e-01, time/batch = 0.6865s	
2219/22950 (epoch 4.834), train_loss = 1.54433000, grad/param norm = 2.2218e-01, time/batch = 0.6876s	
2220/22950 (epoch 4.837), train_loss = 1.65776206, grad/param norm = 2.2002e-01, time/batch = 0.6865s	
2221/22950 (epoch 4.839), train_loss = 1.59205515, grad/param norm = 1.9014e-01, time/batch = 0.6853s	
2222/22950 (epoch 4.841), train_loss = 1.58285893, grad/param norm = 1.9395e-01, time/batch = 0.6897s	
2223/22950 (epoch 4.843), train_loss = 1.57784928, grad/param norm = 2.1216e-01, time/batch = 0.6948s	
2224/22950 (epoch 4.845), train_loss = 1.65087152, grad/param norm = 2.1240e-01, time/batch = 0.7156s	
2225/22950 (epoch 4.847), train_loss = 1.75546798, grad/param norm = 2.0759e-01, time/batch = 0.7250s	
2226/22950 (epoch 4.850), train_loss = 1.73044787, grad/param norm = 2.2882e-01, time/batch = 0.7134s	
2227/22950 (epoch 4.852), train_loss = 1.74698451, grad/param norm = 2.4371e-01, time/batch = 0.6908s	
2228/22950 (epoch 4.854), train_loss = 1.67296153, grad/param norm = 2.1150e-01, time/batch = 0.6903s	
2229/22950 (epoch 4.856), train_loss = 1.88994368, grad/param norm = 2.2512e-01, time/batch = 0.7348s	
2230/22950 (epoch 4.858), train_loss = 1.68669831, grad/param norm = 2.1482e-01, time/batch = 0.7143s	
2231/22950 (epoch 4.861), train_loss = 1.76793507, grad/param norm = 2.3883e-01, time/batch = 0.7120s	
2232/22950 (epoch 4.863), train_loss = 1.84368876, grad/param norm = 2.3151e-01, time/batch = 0.6914s	
2233/22950 (epoch 4.865), train_loss = 1.86111092, grad/param norm = 2.3443e-01, time/batch = 0.6937s	
2234/22950 (epoch 4.867), train_loss = 1.71837353, grad/param norm = 2.1340e-01, time/batch = 0.6931s	
2235/22950 (epoch 4.869), train_loss = 1.88703497, grad/param norm = 2.3521e-01, time/batch = 0.6978s	
2236/22950 (epoch 4.871), train_loss = 1.63484192, grad/param norm = 2.1769e-01, time/batch = 0.7144s	
2237/22950 (epoch 4.874), train_loss = 1.63679902, grad/param norm = 2.2192e-01, time/batch = 0.7212s	
2238/22950 (epoch 4.876), train_loss = 1.76779157, grad/param norm = 2.3309e-01, time/batch = 0.7143s	
2239/22950 (epoch 4.878), train_loss = 1.56259730, grad/param norm = 2.2763e-01, time/batch = 0.7109s	
2240/22950 (epoch 4.880), train_loss = 1.82894256, grad/param norm = 2.2000e-01, time/batch = 0.7020s	
2241/22950 (epoch 4.882), train_loss = 1.51033192, grad/param norm = 1.9822e-01, time/batch = 0.6953s	
2242/22950 (epoch 4.885), train_loss = 1.68568529, grad/param norm = 2.1843e-01, time/batch = 0.6886s	
2243/22950 (epoch 4.887), train_loss = 1.68454061, grad/param norm = 2.3767e-01, time/batch = 0.6913s	
2244/22950 (epoch 4.889), train_loss = 1.80170104, grad/param norm = 2.4198e-01, time/batch = 0.6916s	
2245/22950 (epoch 4.891), train_loss = 1.70587191, grad/param norm = 1.9898e-01, time/batch = 0.6885s	
2246/22950 (epoch 4.893), train_loss = 1.70850830, grad/param norm = 2.2657e-01, time/batch = 0.6864s	
2247/22950 (epoch 4.895), train_loss = 1.82404952, grad/param norm = 2.3607e-01, time/batch = 0.6913s	
2248/22950 (epoch 4.898), train_loss = 1.65868535, grad/param norm = 2.0164e-01, time/batch = 0.7013s	
2249/22950 (epoch 4.900), train_loss = 1.53340526, grad/param norm = 2.0288e-01, time/batch = 0.7058s	
2250/22950 (epoch 4.902), train_loss = 1.66558946, grad/param norm = 2.0983e-01, time/batch = 0.6914s	
2251/22950 (epoch 4.904), train_loss = 1.67527333, grad/param norm = 2.1227e-01, time/batch = 0.6905s	
2252/22950 (epoch 4.906), train_loss = 1.73274768, grad/param norm = 2.1736e-01, time/batch = 0.6912s	
2253/22950 (epoch 4.908), train_loss = 1.54998691, grad/param norm = 2.3223e-01, time/batch = 0.6863s	
2254/22950 (epoch 4.911), train_loss = 1.49734960, grad/param norm = 2.1269e-01, time/batch = 0.6910s	
2255/22950 (epoch 4.913), train_loss = 1.55142736, grad/param norm = 1.9206e-01, time/batch = 0.6920s	
2256/22950 (epoch 4.915), train_loss = 1.86921831, grad/param norm = 2.2527e-01, time/batch = 0.6882s	
2257/22950 (epoch 4.917), train_loss = 1.54393246, grad/param norm = 2.1810e-01, time/batch = 0.6902s	
2258/22950 (epoch 4.919), train_loss = 1.64039185, grad/param norm = 2.1111e-01, time/batch = 0.6922s	
2259/22950 (epoch 4.922), train_loss = 1.61589858, grad/param norm = 2.0920e-01, time/batch = 0.6859s	
2260/22950 (epoch 4.924), train_loss = 1.76110774, grad/param norm = 2.2174e-01, time/batch = 0.6859s	
2261/22950 (epoch 4.926), train_loss = 1.51699969, grad/param norm = 2.3662e-01, time/batch = 0.6875s	
2262/22950 (epoch 4.928), train_loss = 1.51225048, grad/param norm = 2.1635e-01, time/batch = 0.6842s	
2263/22950 (epoch 4.930), train_loss = 1.48846018, grad/param norm = 2.1473e-01, time/batch = 0.6882s	
2264/22950 (epoch 4.932), train_loss = 1.54826580, grad/param norm = 2.3766e-01, time/batch = 0.6868s	
2265/22950 (epoch 4.935), train_loss = 1.67824965, grad/param norm = 2.3223e-01, time/batch = 0.6871s	
2266/22950 (epoch 4.937), train_loss = 1.70207194, grad/param norm = 2.2686e-01, time/batch = 0.6882s	
2267/22950 (epoch 4.939), train_loss = 1.64653667, grad/param norm = 2.2665e-01, time/batch = 0.6861s	
2268/22950 (epoch 4.941), train_loss = 1.55823610, grad/param norm = 2.0541e-01, time/batch = 0.6856s	
2269/22950 (epoch 4.943), train_loss = 1.69727585, grad/param norm = 2.3907e-01, time/batch = 0.6907s	
2270/22950 (epoch 4.946), train_loss = 1.50185904, grad/param norm = 2.2527e-01, time/batch = 0.6906s	
2271/22950 (epoch 4.948), train_loss = 1.70591416, grad/param norm = 2.3470e-01, time/batch = 0.6870s	
2272/22950 (epoch 4.950), train_loss = 1.71230997, grad/param norm = 2.2737e-01, time/batch = 0.6880s	
2273/22950 (epoch 4.952), train_loss = 1.70948019, grad/param norm = 2.2944e-01, time/batch = 0.6890s	
2274/22950 (epoch 4.954), train_loss = 1.59895460, grad/param norm = 2.2115e-01, time/batch = 0.6883s	
2275/22950 (epoch 4.956), train_loss = 1.59790788, grad/param norm = 2.0938e-01, time/batch = 0.6858s	
2276/22950 (epoch 4.959), train_loss = 1.53091177, grad/param norm = 2.3757e-01, time/batch = 0.6831s	
2277/22950 (epoch 4.961), train_loss = 1.66753782, grad/param norm = 2.1650e-01, time/batch = 0.6842s	
2278/22950 (epoch 4.963), train_loss = 1.76588505, grad/param norm = 2.3303e-01, time/batch = 0.6864s	
2279/22950 (epoch 4.965), train_loss = 1.86594263, grad/param norm = 2.1602e-01, time/batch = 0.6869s	
2280/22950 (epoch 4.967), train_loss = 1.64301724, grad/param norm = 2.3476e-01, time/batch = 0.6868s	
2281/22950 (epoch 4.969), train_loss = 1.56000444, grad/param norm = 2.0560e-01, time/batch = 0.6891s	
2282/22950 (epoch 4.972), train_loss = 1.64353291, grad/param norm = 2.2379e-01, time/batch = 0.7246s	
2283/22950 (epoch 4.974), train_loss = 1.53296405, grad/param norm = 2.0450e-01, time/batch = 0.7045s	
2284/22950 (epoch 4.976), train_loss = 1.49662172, grad/param norm = 2.2872e-01, time/batch = 0.6852s	
2285/22950 (epoch 4.978), train_loss = 1.65489013, grad/param norm = 2.2446e-01, time/batch = 0.6871s	
2286/22950 (epoch 4.980), train_loss = 1.64449738, grad/param norm = 2.1817e-01, time/batch = 0.6885s	
2287/22950 (epoch 4.983), train_loss = 1.51543903, grad/param norm = 2.2062e-01, time/batch = 0.6906s	
2288/22950 (epoch 4.985), train_loss = 1.49744116, grad/param norm = 2.5773e-01, time/batch = 0.6880s	
2289/22950 (epoch 4.987), train_loss = 1.60717335, grad/param norm = 2.2810e-01, time/batch = 0.6829s	
2290/22950 (epoch 4.989), train_loss = 1.70715210, grad/param norm = 2.2245e-01, time/batch = 0.6830s	
2291/22950 (epoch 4.991), train_loss = 1.57367376, grad/param norm = 2.0915e-01, time/batch = 0.6887s	
2292/22950 (epoch 4.993), train_loss = 1.66533500, grad/param norm = 2.3280e-01, time/batch = 0.7221s	
2293/22950 (epoch 4.996), train_loss = 1.75780712, grad/param norm = 2.2348e-01, time/batch = 0.7146s	
2294/22950 (epoch 4.998), train_loss = 1.54617114, grad/param norm = 2.1020e-01, time/batch = 0.6841s	
2295/22950 (epoch 5.000), train_loss = 1.49364409, grad/param norm = 2.1012e-01, time/batch = 0.6898s	
2296/22950 (epoch 5.002), train_loss = 1.85514228, grad/param norm = 2.3707e-01, time/batch = 0.6883s	
2297/22950 (epoch 5.004), train_loss = 1.70754245, grad/param norm = 2.1859e-01, time/batch = 0.6879s	
2298/22950 (epoch 5.007), train_loss = 1.63835519, grad/param norm = 2.1447e-01, time/batch = 0.6828s	
2299/22950 (epoch 5.009), train_loss = 1.73494398, grad/param norm = 1.9979e-01, time/batch = 0.6839s	
2300/22950 (epoch 5.011), train_loss = 1.68438335, grad/param norm = 2.0196e-01, time/batch = 0.6860s	
2301/22950 (epoch 5.013), train_loss = 1.77005766, grad/param norm = 2.1569e-01, time/batch = 0.6916s	
2302/22950 (epoch 5.015), train_loss = 1.71702967, grad/param norm = 2.1679e-01, time/batch = 0.7195s	
2303/22950 (epoch 5.017), train_loss = 1.60590534, grad/param norm = 2.2180e-01, time/batch = 0.7172s	
2304/22950 (epoch 5.020), train_loss = 1.61450730, grad/param norm = 2.0561e-01, time/batch = 0.6885s	
2305/22950 (epoch 5.022), train_loss = 1.45229435, grad/param norm = 1.9120e-01, time/batch = 0.6860s	
2306/22950 (epoch 5.024), train_loss = 1.58791208, grad/param norm = 2.2768e-01, time/batch = 0.6857s	
2307/22950 (epoch 5.026), train_loss = 1.63682027, grad/param norm = 2.2477e-01, time/batch = 0.6838s	
2308/22950 (epoch 5.028), train_loss = 1.66859281, grad/param norm = 2.3673e-01, time/batch = 0.6876s	
2309/22950 (epoch 5.031), train_loss = 1.62237748, grad/param norm = 2.0415e-01, time/batch = 0.6895s	
2310/22950 (epoch 5.033), train_loss = 1.86169415, grad/param norm = 2.1511e-01, time/batch = 0.7140s	
2311/22950 (epoch 5.035), train_loss = 1.64271173, grad/param norm = 1.9413e-01, time/batch = 0.7261s	
2312/22950 (epoch 5.037), train_loss = 1.58566419, grad/param norm = 2.0971e-01, time/batch = 0.7319s	
2313/22950 (epoch 5.039), train_loss = 1.65731277, grad/param norm = 2.2638e-01, time/batch = 0.7219s	
2314/22950 (epoch 5.041), train_loss = 1.65334678, grad/param norm = 2.1785e-01, time/batch = 0.6956s	
2315/22950 (epoch 5.044), train_loss = 1.57620446, grad/param norm = 2.0606e-01, time/batch = 0.7351s	
2316/22950 (epoch 5.046), train_loss = 1.61658125, grad/param norm = 2.3153e-01, time/batch = 0.7217s	
2317/22950 (epoch 5.048), train_loss = 1.66707696, grad/param norm = 2.0000e-01, time/batch = 0.6912s	
2318/22950 (epoch 5.050), train_loss = 1.71010453, grad/param norm = 2.2116e-01, time/batch = 0.6911s	
2319/22950 (epoch 5.052), train_loss = 1.61836698, grad/param norm = 2.2022e-01, time/batch = 0.6894s	
2320/22950 (epoch 5.054), train_loss = 1.91499414, grad/param norm = 2.4144e-01, time/batch = 0.6894s	
2321/22950 (epoch 5.057), train_loss = 1.69948571, grad/param norm = 2.1425e-01, time/batch = 0.6923s	
2322/22950 (epoch 5.059), train_loss = 1.72495454, grad/param norm = 2.1328e-01, time/batch = 0.7245s	
2323/22950 (epoch 5.061), train_loss = 1.50947337, grad/param norm = 2.0960e-01, time/batch = 0.7006s	
2324/22950 (epoch 5.063), train_loss = 1.68142032, grad/param norm = 2.1586e-01, time/batch = 0.6905s	
2325/22950 (epoch 5.065), train_loss = 1.32308114, grad/param norm = 2.3159e-01, time/batch = 0.6930s	
2326/22950 (epoch 5.068), train_loss = 1.78915089, grad/param norm = 2.1541e-01, time/batch = 0.6918s	
2327/22950 (epoch 5.070), train_loss = 1.54944241, grad/param norm = 2.2167e-01, time/batch = 0.6871s	
2328/22950 (epoch 5.072), train_loss = 1.64990951, grad/param norm = 2.3517e-01, time/batch = 0.6892s	
2329/22950 (epoch 5.074), train_loss = 1.62644742, grad/param norm = 2.4317e-01, time/batch = 0.6855s	
2330/22950 (epoch 5.076), train_loss = 1.60764995, grad/param norm = 2.4337e-01, time/batch = 0.6874s	
2331/22950 (epoch 5.078), train_loss = 1.74773136, grad/param norm = 2.4386e-01, time/batch = 0.6874s	
2332/22950 (epoch 5.081), train_loss = 1.73081162, grad/param norm = 2.0693e-01, time/batch = 0.7245s	
2333/22950 (epoch 5.083), train_loss = 1.60954976, grad/param norm = 2.4339e-01, time/batch = 0.7039s	
2334/22950 (epoch 5.085), train_loss = 1.51328585, grad/param norm = 2.1620e-01, time/batch = 0.6927s	
2335/22950 (epoch 5.087), train_loss = 1.57087892, grad/param norm = 2.2426e-01, time/batch = 0.6886s	
2336/22950 (epoch 5.089), train_loss = 1.64946228, grad/param norm = 1.9928e-01, time/batch = 0.6874s	
2337/22950 (epoch 5.092), train_loss = 1.65530576, grad/param norm = 2.2372e-01, time/batch = 0.6889s	
2338/22950 (epoch 5.094), train_loss = 1.56850785, grad/param norm = 2.0556e-01, time/batch = 0.6908s	
2339/22950 (epoch 5.096), train_loss = 1.77943953, grad/param norm = 2.1409e-01, time/batch = 0.6863s	
2340/22950 (epoch 5.098), train_loss = 1.65336862, grad/param norm = 2.1481e-01, time/batch = 0.6898s	
2341/22950 (epoch 5.100), train_loss = 1.56113559, grad/param norm = 2.0601e-01, time/batch = 0.6893s	
2342/22950 (epoch 5.102), train_loss = 1.62205553, grad/param norm = 1.8851e-01, time/batch = 0.6897s	
2343/22950 (epoch 5.105), train_loss = 1.51634606, grad/param norm = 1.9542e-01, time/batch = 0.6775s	
2344/22950 (epoch 5.107), train_loss = 1.59682808, grad/param norm = 2.2816e-01, time/batch = 0.6755s	
2345/22950 (epoch 5.109), train_loss = 1.58477990, grad/param norm = 2.1316e-01, time/batch = 0.6765s	
2346/22950 (epoch 5.111), train_loss = 1.48225559, grad/param norm = 2.0492e-01, time/batch = 0.6734s	
2347/22950 (epoch 5.113), train_loss = 1.67536167, grad/param norm = 2.1002e-01, time/batch = 0.6730s	
2348/22950 (epoch 5.115), train_loss = 1.75551709, grad/param norm = 2.6150e-01, time/batch = 0.6747s	
2349/22950 (epoch 5.118), train_loss = 1.76819581, grad/param norm = 2.0960e-01, time/batch = 0.6776s	
2350/22950 (epoch 5.120), train_loss = 1.57429712, grad/param norm = 2.1420e-01, time/batch = 0.6732s	
2351/22950 (epoch 5.122), train_loss = 1.73682104, grad/param norm = 2.1939e-01, time/batch = 0.6778s	
2352/22950 (epoch 5.124), train_loss = 1.42518937, grad/param norm = 2.0126e-01, time/batch = 0.6743s	
2353/22950 (epoch 5.126), train_loss = 1.57308960, grad/param norm = 2.1209e-01, time/batch = 0.6756s	
2354/22950 (epoch 5.129), train_loss = 1.43627497, grad/param norm = 2.1028e-01, time/batch = 0.6726s	
2355/22950 (epoch 5.131), train_loss = 1.65344279, grad/param norm = 2.3751e-01, time/batch = 0.6762s	
2356/22950 (epoch 5.133), train_loss = 1.74090437, grad/param norm = 2.0859e-01, time/batch = 0.6754s	
2357/22950 (epoch 5.135), train_loss = 1.59604050, grad/param norm = 2.2092e-01, time/batch = 0.6896s	
2358/22950 (epoch 5.137), train_loss = 1.86676662, grad/param norm = 2.4189e-01, time/batch = 0.6801s	
2359/22950 (epoch 5.139), train_loss = 1.58647212, grad/param norm = 2.3092e-01, time/batch = 0.6967s	
2360/22950 (epoch 5.142), train_loss = 1.50958088, grad/param norm = 2.2150e-01, time/batch = 0.7034s	
2361/22950 (epoch 5.144), train_loss = 1.51171555, grad/param norm = 2.0515e-01, time/batch = 0.6873s	
2362/22950 (epoch 5.146), train_loss = 1.66591856, grad/param norm = 2.2111e-01, time/batch = 0.6818s	
2363/22950 (epoch 5.148), train_loss = 1.55969790, grad/param norm = 2.0647e-01, time/batch = 0.6850s	
2364/22950 (epoch 5.150), train_loss = 1.58549148, grad/param norm = 2.0930e-01, time/batch = 0.6856s	
2365/22950 (epoch 5.153), train_loss = 1.60006050, grad/param norm = 2.0977e-01, time/batch = 0.6851s	
2366/22950 (epoch 5.155), train_loss = 1.55279181, grad/param norm = 2.1889e-01, time/batch = 0.6873s	
2367/22950 (epoch 5.157), train_loss = 1.54954335, grad/param norm = 2.3130e-01, time/batch = 0.6798s	
2368/22950 (epoch 5.159), train_loss = 1.47540787, grad/param norm = 1.9149e-01, time/batch = 0.6786s	
2369/22950 (epoch 5.161), train_loss = 1.64954592, grad/param norm = 2.1046e-01, time/batch = 0.6838s	
2370/22950 (epoch 5.163), train_loss = 1.57164359, grad/param norm = 2.0189e-01, time/batch = 0.6928s	
2371/22950 (epoch 5.166), train_loss = 1.75852778, grad/param norm = 2.0926e-01, time/batch = 0.6887s	
2372/22950 (epoch 5.168), train_loss = 1.78025818, grad/param norm = 2.5802e-01, time/batch = 0.6857s	
2373/22950 (epoch 5.170), train_loss = 1.70151565, grad/param norm = 2.4078e-01, time/batch = 0.6988s	
2374/22950 (epoch 5.172), train_loss = 1.61045993, grad/param norm = 2.0992e-01, time/batch = 0.6964s	
2375/22950 (epoch 5.174), train_loss = 1.68320545, grad/param norm = 2.4884e-01, time/batch = 0.6943s	
2376/22950 (epoch 5.176), train_loss = 1.74255436, grad/param norm = 2.1328e-01, time/batch = 0.6883s	
2377/22950 (epoch 5.179), train_loss = 1.71042813, grad/param norm = 2.5099e-01, time/batch = 0.6879s	
2378/22950 (epoch 5.181), train_loss = 1.80078753, grad/param norm = 2.3468e-01, time/batch = 0.6915s	
2379/22950 (epoch 5.183), train_loss = 1.72082926, grad/param norm = 2.2073e-01, time/batch = 0.6874s	
2380/22950 (epoch 5.185), train_loss = 1.70061828, grad/param norm = 2.2270e-01, time/batch = 0.6865s	
2381/22950 (epoch 5.187), train_loss = 1.49489409, grad/param norm = 2.2848e-01, time/batch = 0.6937s	
2382/22950 (epoch 5.190), train_loss = 1.65223247, grad/param norm = 2.2500e-01, time/batch = 0.6997s	
2383/22950 (epoch 5.192), train_loss = 1.53159672, grad/param norm = 2.0459e-01, time/batch = 0.6927s	
2384/22950 (epoch 5.194), train_loss = 1.64574089, grad/param norm = 2.5334e-01, time/batch = 0.6862s	
2385/22950 (epoch 5.196), train_loss = 1.41838897, grad/param norm = 2.1691e-01, time/batch = 0.6834s	
2386/22950 (epoch 5.198), train_loss = 1.76228471, grad/param norm = 2.1897e-01, time/batch = 0.6822s	
2387/22950 (epoch 5.200), train_loss = 1.45727803, grad/param norm = 2.0702e-01, time/batch = 0.6827s	
2388/22950 (epoch 5.203), train_loss = 1.43239875, grad/param norm = 2.0299e-01, time/batch = 0.6868s	
2389/22950 (epoch 5.205), train_loss = 1.53464369, grad/param norm = 2.5982e-01, time/batch = 0.6852s	
2390/22950 (epoch 5.207), train_loss = 1.61388720, grad/param norm = 2.2857e-01, time/batch = 0.6829s	
2391/22950 (epoch 5.209), train_loss = 1.83796560, grad/param norm = 2.4606e-01, time/batch = 0.6891s	
2392/22950 (epoch 5.211), train_loss = 1.53146699, grad/param norm = 2.5372e-01, time/batch = 0.6870s	
2393/22950 (epoch 5.214), train_loss = 1.57033274, grad/param norm = 2.2119e-01, time/batch = 0.6874s	
2394/22950 (epoch 5.216), train_loss = 1.65388470, grad/param norm = 2.0116e-01, time/batch = 0.6851s	
2395/22950 (epoch 5.218), train_loss = 1.65329123, grad/param norm = 2.1585e-01, time/batch = 0.6898s	
2396/22950 (epoch 5.220), train_loss = 1.76959868, grad/param norm = 2.2599e-01, time/batch = 0.7040s	
2397/22950 (epoch 5.222), train_loss = 1.74344978, grad/param norm = 2.2545e-01, time/batch = 0.7190s	
2398/22950 (epoch 5.224), train_loss = 1.57369239, grad/param norm = 2.2595e-01, time/batch = 0.7190s	
2399/22950 (epoch 5.227), train_loss = 1.59324160, grad/param norm = 2.3092e-01, time/batch = 0.7050s	
2400/22950 (epoch 5.229), train_loss = 1.59845726, grad/param norm = 2.1107e-01, time/batch = 0.7110s	
2401/22950 (epoch 5.231), train_loss = 1.49173744, grad/param norm = 2.0444e-01, time/batch = 0.7164s	
2402/22950 (epoch 5.233), train_loss = 1.58409953, grad/param norm = 2.1151e-01, time/batch = 0.7154s	
2403/22950 (epoch 5.235), train_loss = 1.72834705, grad/param norm = 2.2773e-01, time/batch = 0.7227s	
2404/22950 (epoch 5.237), train_loss = 1.45977408, grad/param norm = 2.1759e-01, time/batch = 0.7139s	
2405/22950 (epoch 5.240), train_loss = 1.55816986, grad/param norm = 2.0248e-01, time/batch = 0.7112s	
2406/22950 (epoch 5.242), train_loss = 1.68539833, grad/param norm = 2.6550e-01, time/batch = 0.6899s	
2407/22950 (epoch 5.244), train_loss = 1.80009857, grad/param norm = 2.3617e-01, time/batch = 0.7221s	
2408/22950 (epoch 5.246), train_loss = 1.72258931, grad/param norm = 2.2881e-01, time/batch = 0.7024s	
2409/22950 (epoch 5.248), train_loss = 1.67152989, grad/param norm = 2.4210e-01, time/batch = 0.6865s	
2410/22950 (epoch 5.251), train_loss = 1.64493229, grad/param norm = 2.2381e-01, time/batch = 0.6894s	
2411/22950 (epoch 5.253), train_loss = 1.61968712, grad/param norm = 2.1493e-01, time/batch = 0.6865s	
2412/22950 (epoch 5.255), train_loss = 1.55335640, grad/param norm = 2.0565e-01, time/batch = 0.6879s	
2413/22950 (epoch 5.257), train_loss = 1.76312197, grad/param norm = 2.1499e-01, time/batch = 0.6871s	
2414/22950 (epoch 5.259), train_loss = 1.45259949, grad/param norm = 2.0459e-01, time/batch = 0.6916s	
2415/22950 (epoch 5.261), train_loss = 1.68169300, grad/param norm = 2.1396e-01, time/batch = 0.6898s	
2416/22950 (epoch 5.264), train_loss = 1.48321208, grad/param norm = 1.8273e-01, time/batch = 0.6891s	
2417/22950 (epoch 5.266), train_loss = 1.74362575, grad/param norm = 2.1985e-01, time/batch = 0.7199s	
2418/22950 (epoch 5.268), train_loss = 1.68351048, grad/param norm = 1.9829e-01, time/batch = 0.7039s	
2419/22950 (epoch 5.270), train_loss = 1.71542541, grad/param norm = 2.0301e-01, time/batch = 0.6838s	
2420/22950 (epoch 5.272), train_loss = 1.81298006, grad/param norm = 2.2451e-01, time/batch = 0.6816s	
2421/22950 (epoch 5.275), train_loss = 1.53184542, grad/param norm = 2.5261e-01, time/batch = 0.6895s	
2422/22950 (epoch 5.277), train_loss = 1.48271512, grad/param norm = 2.2025e-01, time/batch = 0.6896s	
2423/22950 (epoch 5.279), train_loss = 1.72082464, grad/param norm = 2.4311e-01, time/batch = 0.6895s	
2424/22950 (epoch 5.281), train_loss = 1.56359985, grad/param norm = 2.5579e-01, time/batch = 0.6878s	
2425/22950 (epoch 5.283), train_loss = 1.47191743, grad/param norm = 2.2648e-01, time/batch = 0.6907s	
2426/22950 (epoch 5.285), train_loss = 1.61129609, grad/param norm = 2.1646e-01, time/batch = 0.6889s	
2427/22950 (epoch 5.288), train_loss = 1.58703458, grad/param norm = 2.3959e-01, time/batch = 0.6900s	
2428/22950 (epoch 5.290), train_loss = 1.54602094, grad/param norm = 2.1172e-01, time/batch = 0.6879s	
2429/22950 (epoch 5.292), train_loss = 1.67132536, grad/param norm = 2.1430e-01, time/batch = 0.6898s	
2430/22950 (epoch 5.294), train_loss = 1.67695521, grad/param norm = 2.1974e-01, time/batch = 0.6891s	
2431/22950 (epoch 5.296), train_loss = 1.36705293, grad/param norm = 1.9623e-01, time/batch = 0.6923s	
2432/22950 (epoch 5.298), train_loss = 1.56808571, grad/param norm = 1.9388e-01, time/batch = 0.6874s	
2433/22950 (epoch 5.301), train_loss = 1.64949700, grad/param norm = 2.2868e-01, time/batch = 0.6865s	
2434/22950 (epoch 5.303), train_loss = 1.70475771, grad/param norm = 2.1505e-01, time/batch = 0.6847s	
2435/22950 (epoch 5.305), train_loss = 1.73932837, grad/param norm = 2.1916e-01, time/batch = 0.6845s	
2436/22950 (epoch 5.307), train_loss = 1.72234826, grad/param norm = 2.1634e-01, time/batch = 0.6846s	
2437/22950 (epoch 5.309), train_loss = 1.64665110, grad/param norm = 1.9170e-01, time/batch = 0.6865s	
2438/22950 (epoch 5.312), train_loss = 1.68257224, grad/param norm = 2.0846e-01, time/batch = 0.6893s	
2439/22950 (epoch 5.314), train_loss = 1.49694074, grad/param norm = 2.0997e-01, time/batch = 0.6945s	
2440/22950 (epoch 5.316), train_loss = 1.65261678, grad/param norm = 2.1506e-01, time/batch = 0.6971s	
2441/22950 (epoch 5.318), train_loss = 1.42741245, grad/param norm = 2.0157e-01, time/batch = 0.6956s	
2442/22950 (epoch 5.320), train_loss = 1.58862450, grad/param norm = 1.8766e-01, time/batch = 0.6908s	
2443/22950 (epoch 5.322), train_loss = 1.59908339, grad/param norm = 2.1565e-01, time/batch = 0.6862s	
2444/22950 (epoch 5.325), train_loss = 1.28973199, grad/param norm = 1.9709e-01, time/batch = 0.6872s	
2445/22950 (epoch 5.327), train_loss = 1.36577286, grad/param norm = 1.9223e-01, time/batch = 0.6876s	
2446/22950 (epoch 5.329), train_loss = 1.50839975, grad/param norm = 2.0584e-01, time/batch = 0.6930s	
2447/22950 (epoch 5.331), train_loss = 1.45951553, grad/param norm = 2.0305e-01, time/batch = 0.6917s	
2448/22950 (epoch 5.333), train_loss = 1.54787377, grad/param norm = 2.1417e-01, time/batch = 0.6825s	
2449/22950 (epoch 5.336), train_loss = 1.60880128, grad/param norm = 2.3699e-01, time/batch = 0.6839s	
2450/22950 (epoch 5.338), train_loss = 1.54698839, grad/param norm = 2.6375e-01, time/batch = 0.6872s	
2451/22950 (epoch 5.340), train_loss = 1.51011812, grad/param norm = 2.2549e-01, time/batch = 0.6874s	
2452/22950 (epoch 5.342), train_loss = 1.66641729, grad/param norm = 2.1915e-01, time/batch = 0.6867s	
2453/22950 (epoch 5.344), train_loss = 1.62183772, grad/param norm = 2.2868e-01, time/batch = 0.6894s	
2454/22950 (epoch 5.346), train_loss = 1.82932573, grad/param norm = 2.3576e-01, time/batch = 0.6884s	
2455/22950 (epoch 5.349), train_loss = 1.66969590, grad/param norm = 2.3571e-01, time/batch = 0.6942s	
2456/22950 (epoch 5.351), train_loss = 1.61243350, grad/param norm = 2.1938e-01, time/batch = 0.6908s	
2457/22950 (epoch 5.353), train_loss = 1.72762314, grad/param norm = 2.5314e-01, time/batch = 0.7058s	
2458/22950 (epoch 5.355), train_loss = 1.75999546, grad/param norm = 2.4357e-01, time/batch = 0.7182s	
2459/22950 (epoch 5.357), train_loss = 1.64508261, grad/param norm = 2.1218e-01, time/batch = 0.6905s	
2460/22950 (epoch 5.359), train_loss = 1.69197537, grad/param norm = 2.1307e-01, time/batch = 0.6885s	
2461/22950 (epoch 5.362), train_loss = 1.53977829, grad/param norm = 2.0643e-01, time/batch = 0.6844s	
2462/22950 (epoch 5.364), train_loss = 1.61828849, grad/param norm = 2.1765e-01, time/batch = 0.6867s	
2463/22950 (epoch 5.366), train_loss = 1.41481799, grad/param norm = 2.0198e-01, time/batch = 0.6850s	
2464/22950 (epoch 5.368), train_loss = 1.62859833, grad/param norm = 2.2483e-01, time/batch = 0.6872s	
2465/22950 (epoch 5.370), train_loss = 1.57070904, grad/param norm = 2.1963e-01, time/batch = 0.6876s	
2466/22950 (epoch 5.373), train_loss = 1.45396635, grad/param norm = 1.9662e-01, time/batch = 0.6845s	
2467/22950 (epoch 5.375), train_loss = 1.77686716, grad/param norm = 2.3922e-01, time/batch = 0.6868s	
2468/22950 (epoch 5.377), train_loss = 1.57303041, grad/param norm = 2.1815e-01, time/batch = 0.6899s	
2469/22950 (epoch 5.379), train_loss = 1.73368714, grad/param norm = 2.0013e-01, time/batch = 0.6896s	
2470/22950 (epoch 5.381), train_loss = 1.46201684, grad/param norm = 2.0745e-01, time/batch = 0.6854s	
2471/22950 (epoch 5.383), train_loss = 1.67820355, grad/param norm = 2.4713e-01, time/batch = 0.6862s	
2472/22950 (epoch 5.386), train_loss = 1.64833556, grad/param norm = 2.7047e-01, time/batch = 0.6849s	
2473/22950 (epoch 5.388), train_loss = 1.66508004, grad/param norm = 2.2912e-01, time/batch = 0.6852s	
2474/22950 (epoch 5.390), train_loss = 1.48418480, grad/param norm = 2.2346e-01, time/batch = 0.6853s	
2475/22950 (epoch 5.392), train_loss = 1.46716775, grad/param norm = 2.0336e-01, time/batch = 0.6945s	
2476/22950 (epoch 5.394), train_loss = 1.49830714, grad/param norm = 1.8751e-01, time/batch = 0.6917s	
2477/22950 (epoch 5.397), train_loss = 1.67402276, grad/param norm = 2.2952e-01, time/batch = 0.6830s	
2478/22950 (epoch 5.399), train_loss = 1.69744538, grad/param norm = 2.1578e-01, time/batch = 0.6864s	
2479/22950 (epoch 5.401), train_loss = 1.90995138, grad/param norm = 2.2656e-01, time/batch = 0.6848s	
2480/22950 (epoch 5.403), train_loss = 1.58161923, grad/param norm = 2.3086e-01, time/batch = 0.6856s	
2481/22950 (epoch 5.405), train_loss = 1.69183963, grad/param norm = 2.2267e-01, time/batch = 0.6885s	
2482/22950 (epoch 5.407), train_loss = 1.76505810, grad/param norm = 2.1699e-01, time/batch = 0.7004s	
2483/22950 (epoch 5.410), train_loss = 1.43622495, grad/param norm = 1.9745e-01, time/batch = 0.7115s	
2484/22950 (epoch 5.412), train_loss = 1.61384089, grad/param norm = 2.1956e-01, time/batch = 0.7259s	
2485/22950 (epoch 5.414), train_loss = 1.69121968, grad/param norm = 2.2252e-01, time/batch = 0.7087s	
2486/22950 (epoch 5.416), train_loss = 1.71102430, grad/param norm = 2.0694e-01, time/batch = 0.6910s	
2487/22950 (epoch 5.418), train_loss = 1.72436480, grad/param norm = 2.1986e-01, time/batch = 0.6912s	
2488/22950 (epoch 5.420), train_loss = 1.68578423, grad/param norm = 2.1073e-01, time/batch = 0.7078s	
2489/22950 (epoch 5.423), train_loss = 1.45591587, grad/param norm = 1.7619e-01, time/batch = 0.7119s	
2490/22950 (epoch 5.425), train_loss = 1.61558879, grad/param norm = 2.0218e-01, time/batch = 0.6860s	
2491/22950 (epoch 5.427), train_loss = 1.53653916, grad/param norm = 2.0978e-01, time/batch = 0.6944s	
2492/22950 (epoch 5.429), train_loss = 1.47982107, grad/param norm = 2.0630e-01, time/batch = 0.6900s	
2493/22950 (epoch 5.431), train_loss = 1.64001965, grad/param norm = 2.2873e-01, time/batch = 0.6889s	
2494/22950 (epoch 5.434), train_loss = 1.59997624, grad/param norm = 2.3450e-01, time/batch = 0.6910s	
2495/22950 (epoch 5.436), train_loss = 1.87114290, grad/param norm = 2.3280e-01, time/batch = 0.6860s	
2496/22950 (epoch 5.438), train_loss = 1.62044175, grad/param norm = 2.3308e-01, time/batch = 0.6874s	
2497/22950 (epoch 5.440), train_loss = 1.64111787, grad/param norm = 2.0818e-01, time/batch = 0.6905s	
2498/22950 (epoch 5.442), train_loss = 1.79680492, grad/param norm = 2.4716e-01, time/batch = 0.6910s	
2499/22950 (epoch 5.444), train_loss = 1.77331428, grad/param norm = 2.3629e-01, time/batch = 0.6890s	
2500/22950 (epoch 5.447), train_loss = 1.81507950, grad/param norm = 2.4638e-01, time/batch = 0.6914s	
2501/22950 (epoch 5.449), train_loss = 1.47750702, grad/param norm = 1.9074e-01, time/batch = 0.6981s	
2502/22950 (epoch 5.451), train_loss = 1.65228103, grad/param norm = 2.1780e-01, time/batch = 0.7200s	
2503/22950 (epoch 5.453), train_loss = 1.69439379, grad/param norm = 2.0856e-01, time/batch = 0.7082s	
2504/22950 (epoch 5.455), train_loss = 1.51899166, grad/param norm = 2.0308e-01, time/batch = 0.7003s	
2505/22950 (epoch 5.458), train_loss = 1.77044765, grad/param norm = 2.1940e-01, time/batch = 0.6909s	
2506/22950 (epoch 5.460), train_loss = 1.69534138, grad/param norm = 2.1820e-01, time/batch = 0.6860s	
2507/22950 (epoch 5.462), train_loss = 1.57688627, grad/param norm = 2.0938e-01, time/batch = 0.6894s	
2508/22950 (epoch 5.464), train_loss = 1.60597499, grad/param norm = 2.3602e-01, time/batch = 0.6875s	
2509/22950 (epoch 5.466), train_loss = 1.61292963, grad/param norm = 2.3699e-01, time/batch = 0.6868s	
2510/22950 (epoch 5.468), train_loss = 1.71819518, grad/param norm = 2.0232e-01, time/batch = 0.6876s	
2511/22950 (epoch 5.471), train_loss = 1.57450113, grad/param norm = 2.0696e-01, time/batch = 0.6970s	
2512/22950 (epoch 5.473), train_loss = 1.70855473, grad/param norm = 2.4056e-01, time/batch = 0.6864s	
2513/22950 (epoch 5.475), train_loss = 1.84087107, grad/param norm = 2.5259e-01, time/batch = 0.6872s	
2514/22950 (epoch 5.477), train_loss = 1.66134398, grad/param norm = 2.1468e-01, time/batch = 0.6886s	
2515/22950 (epoch 5.479), train_loss = 1.64692704, grad/param norm = 2.1965e-01, time/batch = 0.6885s	
2516/22950 (epoch 5.481), train_loss = 1.85385946, grad/param norm = 2.5420e-01, time/batch = 0.6873s	
2517/22950 (epoch 5.484), train_loss = 1.77537109, grad/param norm = 2.4639e-01, time/batch = 0.6876s	
2518/22950 (epoch 5.486), train_loss = 1.47112668, grad/param norm = 2.2420e-01, time/batch = 0.6880s	
2519/22950 (epoch 5.488), train_loss = 1.61202798, grad/param norm = 2.3056e-01, time/batch = 0.6871s	
2520/22950 (epoch 5.490), train_loss = 1.51283998, grad/param norm = 2.0875e-01, time/batch = 0.6878s	
2521/22950 (epoch 5.492), train_loss = 1.65227071, grad/param norm = 2.1198e-01, time/batch = 0.6864s	
2522/22950 (epoch 5.495), train_loss = 1.62849337, grad/param norm = 2.0885e-01, time/batch = 0.7176s	
2523/22950 (epoch 5.497), train_loss = 1.70759753, grad/param norm = 2.0077e-01, time/batch = 0.7083s	
2524/22950 (epoch 5.499), train_loss = 1.71714978, grad/param norm = 2.3403e-01, time/batch = 0.6905s	
2525/22950 (epoch 5.501), train_loss = 1.75002030, grad/param norm = 2.2109e-01, time/batch = 0.6867s	
2526/22950 (epoch 5.503), train_loss = 1.72637863, grad/param norm = 2.1351e-01, time/batch = 0.6875s	
2527/22950 (epoch 5.505), train_loss = 1.52577388, grad/param norm = 1.9888e-01, time/batch = 0.6884s	
2528/22950 (epoch 5.508), train_loss = 1.64590177, grad/param norm = 2.1606e-01, time/batch = 0.6847s	
2529/22950 (epoch 5.510), train_loss = 1.58555972, grad/param norm = 2.2014e-01, time/batch = 0.6861s	
2530/22950 (epoch 5.512), train_loss = 1.56348764, grad/param norm = 2.3280e-01, time/batch = 0.6857s	
2531/22950 (epoch 5.514), train_loss = 1.44736020, grad/param norm = 2.1654e-01, time/batch = 0.6884s	
2532/22950 (epoch 5.516), train_loss = 1.49285918, grad/param norm = 2.2002e-01, time/batch = 0.7146s	
2533/22950 (epoch 5.519), train_loss = 1.57735789, grad/param norm = 2.2087e-01, time/batch = 0.7089s	
2534/22950 (epoch 5.521), train_loss = 1.58372063, grad/param norm = 1.9710e-01, time/batch = 0.6841s	
2535/22950 (epoch 5.523), train_loss = 1.37562682, grad/param norm = 2.0906e-01, time/batch = 0.6948s	
2536/22950 (epoch 5.525), train_loss = 1.54215986, grad/param norm = 1.9912e-01, time/batch = 0.6870s	
2537/22950 (epoch 5.527), train_loss = 1.37292849, grad/param norm = 1.9440e-01, time/batch = 0.6858s	
2538/22950 (epoch 5.529), train_loss = 1.66827744, grad/param norm = 2.0667e-01, time/batch = 0.6929s	
2539/22950 (epoch 5.532), train_loss = 1.59619681, grad/param norm = 2.1127e-01, time/batch = 0.7014s	
2540/22950 (epoch 5.534), train_loss = 1.71462455, grad/param norm = 2.3136e-01, time/batch = 0.6900s	
2541/22950 (epoch 5.536), train_loss = 1.66220425, grad/param norm = 2.2781e-01, time/batch = 0.6906s	
2542/22950 (epoch 5.538), train_loss = 1.59481456, grad/param norm = 2.5079e-01, time/batch = 0.7158s	
2543/22950 (epoch 5.540), train_loss = 1.56828321, grad/param norm = 1.9640e-01, time/batch = 0.7104s	
2544/22950 (epoch 5.542), train_loss = 1.83614538, grad/param norm = 2.3280e-01, time/batch = 0.6867s	
2545/22950 (epoch 5.545), train_loss = 1.54040844, grad/param norm = 2.2087e-01, time/batch = 0.6876s	
2546/22950 (epoch 5.547), train_loss = 1.58728251, grad/param norm = 2.1369e-01, time/batch = 0.6865s	
2547/22950 (epoch 5.549), train_loss = 1.58731439, grad/param norm = 2.2652e-01, time/batch = 0.6860s	
2548/22950 (epoch 5.551), train_loss = 1.65371755, grad/param norm = 2.5137e-01, time/batch = 0.6889s	
2549/22950 (epoch 5.553), train_loss = 1.58191636, grad/param norm = 2.2213e-01, time/batch = 0.6974s	
2550/22950 (epoch 5.556), train_loss = 1.68273022, grad/param norm = 2.0171e-01, time/batch = 0.7101s	
2551/22950 (epoch 5.558), train_loss = 1.59100540, grad/param norm = 1.9775e-01, time/batch = 0.7188s	
2552/22950 (epoch 5.560), train_loss = 1.65060577, grad/param norm = 1.9577e-01, time/batch = 0.7168s	
2553/22950 (epoch 5.562), train_loss = 1.46534126, grad/param norm = 2.0319e-01, time/batch = 0.7135s	
2554/22950 (epoch 5.564), train_loss = 1.84542565, grad/param norm = 2.6601e-01, time/batch = 0.7058s	
2555/22950 (epoch 5.566), train_loss = 1.64220746, grad/param norm = 2.2727e-01, time/batch = 0.6971s	
2556/22950 (epoch 5.569), train_loss = 1.79201000, grad/param norm = 2.2611e-01, time/batch = 0.6999s	
2557/22950 (epoch 5.571), train_loss = 1.45021669, grad/param norm = 2.0185e-01, time/batch = 0.7064s	
2558/22950 (epoch 5.573), train_loss = 1.58646326, grad/param norm = 2.0417e-01, time/batch = 0.6872s	
2559/22950 (epoch 5.575), train_loss = 1.93064365, grad/param norm = 2.1638e-01, time/batch = 0.6871s	
2560/22950 (epoch 5.577), train_loss = 1.62953185, grad/param norm = 2.2162e-01, time/batch = 0.6897s	
2561/22950 (epoch 5.580), train_loss = 1.68335384, grad/param norm = 2.2298e-01, time/batch = 0.6882s	
2562/22950 (epoch 5.582), train_loss = 1.79740598, grad/param norm = 1.9703e-01, time/batch = 0.7167s	
2563/22950 (epoch 5.584), train_loss = 1.41226702, grad/param norm = 2.0566e-01, time/batch = 0.7101s	
2564/22950 (epoch 5.586), train_loss = 1.49990655, grad/param norm = 2.0727e-01, time/batch = 0.6887s	
2565/22950 (epoch 5.588), train_loss = 1.75436035, grad/param norm = 2.1577e-01, time/batch = 0.6860s	
2566/22950 (epoch 5.590), train_loss = 1.57970688, grad/param norm = 2.2411e-01, time/batch = 0.6950s	
2567/22950 (epoch 5.593), train_loss = 1.43245675, grad/param norm = 2.1123e-01, time/batch = 0.6846s	
2568/22950 (epoch 5.595), train_loss = 1.50185424, grad/param norm = 2.2062e-01, time/batch = 0.7026s	
2569/22950 (epoch 5.597), train_loss = 1.69890538, grad/param norm = 2.4165e-01, time/batch = 0.7185s	
2570/22950 (epoch 5.599), train_loss = 1.65919588, grad/param norm = 2.5012e-01, time/batch = 1.0527s	
2571/22950 (epoch 5.601), train_loss = 1.61679131, grad/param norm = 2.3368e-01, time/batch = 1.2351s	
2572/22950 (epoch 5.603), train_loss = 1.75662716, grad/param norm = 2.2630e-01, time/batch = 0.7174s	
2573/22950 (epoch 5.606), train_loss = 1.56143356, grad/param norm = 2.1724e-01, time/batch = 0.6947s	
2574/22950 (epoch 5.608), train_loss = 1.56824664, grad/param norm = 2.1437e-01, time/batch = 0.6935s	
2575/22950 (epoch 5.610), train_loss = 1.57249090, grad/param norm = 2.0439e-01, time/batch = 0.6949s	
2576/22950 (epoch 5.612), train_loss = 1.61545028, grad/param norm = 2.0309e-01, time/batch = 0.6934s	
2577/22950 (epoch 5.614), train_loss = 1.75689198, grad/param norm = 2.4012e-01, time/batch = 0.7338s	
2578/22950 (epoch 5.617), train_loss = 1.62621174, grad/param norm = 2.2614e-01, time/batch = 0.7101s	
2579/22950 (epoch 5.619), train_loss = 1.48121316, grad/param norm = 2.0406e-01, time/batch = 0.6894s	
2580/22950 (epoch 5.621), train_loss = 1.69437205, grad/param norm = 1.9885e-01, time/batch = 0.6921s	
2581/22950 (epoch 5.623), train_loss = 1.59829605, grad/param norm = 1.9210e-01, time/batch = 0.6955s	
2582/22950 (epoch 5.625), train_loss = 1.58700431, grad/param norm = 1.9266e-01, time/batch = 0.7055s	
2583/22950 (epoch 5.627), train_loss = 1.64423350, grad/param norm = 2.2282e-01, time/batch = 0.7044s	
2584/22950 (epoch 5.630), train_loss = 1.41561917, grad/param norm = 1.8799e-01, time/batch = 0.6935s	
2585/22950 (epoch 5.632), train_loss = 1.66595657, grad/param norm = 2.1996e-01, time/batch = 0.6952s	
2586/22950 (epoch 5.634), train_loss = 1.54734275, grad/param norm = 2.0641e-01, time/batch = 0.6915s	
2587/22950 (epoch 5.636), train_loss = 1.57552923, grad/param norm = 1.8808e-01, time/batch = 0.6918s	
2588/22950 (epoch 5.638), train_loss = 1.50055296, grad/param norm = 2.0383e-01, time/batch = 0.6956s	
2589/22950 (epoch 5.641), train_loss = 1.52872706, grad/param norm = 1.9614e-01, time/batch = 0.6959s	
2590/22950 (epoch 5.643), train_loss = 1.63768194, grad/param norm = 2.4446e-01, time/batch = 0.6919s	
2591/22950 (epoch 5.645), train_loss = 1.52439817, grad/param norm = 2.7457e-01, time/batch = 0.6921s	
2592/22950 (epoch 5.647), train_loss = 1.62100899, grad/param norm = 2.2366e-01, time/batch = 0.7007s	
2593/22950 (epoch 5.649), train_loss = 1.57178737, grad/param norm = 1.9211e-01, time/batch = 0.7048s	
2594/22950 (epoch 5.651), train_loss = 1.70732482, grad/param norm = 2.2877e-01, time/batch = 0.7082s	
2595/22950 (epoch 5.654), train_loss = 1.38095202, grad/param norm = 1.9432e-01, time/batch = 0.7220s	
2596/22950 (epoch 5.656), train_loss = 1.73255166, grad/param norm = 2.1922e-01, time/batch = 0.7107s	
2597/22950 (epoch 5.658), train_loss = 1.48422735, grad/param norm = 1.9947e-01, time/batch = 0.7069s	
2598/22950 (epoch 5.660), train_loss = 1.42699665, grad/param norm = 1.9082e-01, time/batch = 0.7016s	
2599/22950 (epoch 5.662), train_loss = 1.45007731, grad/param norm = 1.9883e-01, time/batch = 0.7048s	
2600/22950 (epoch 5.664), train_loss = 1.67025707, grad/param norm = 2.0678e-01, time/batch = 0.7090s	
2601/22950 (epoch 5.667), train_loss = 1.64420485, grad/param norm = 2.2414e-01, time/batch = 0.7038s	
2602/22950 (epoch 5.669), train_loss = 1.51706829, grad/param norm = 2.2875e-01, time/batch = 0.7114s	
2603/22950 (epoch 5.671), train_loss = 1.67262852, grad/param norm = 2.1986e-01, time/batch = 0.7052s	
2604/22950 (epoch 5.673), train_loss = 1.62604402, grad/param norm = 1.8917e-01, time/batch = 0.7042s	
2605/22950 (epoch 5.675), train_loss = 1.58340201, grad/param norm = 2.0364e-01, time/batch = 0.7035s	
2606/22950 (epoch 5.678), train_loss = 1.62856044, grad/param norm = 2.1040e-01, time/batch = 0.7118s	
2607/22950 (epoch 5.680), train_loss = 1.64043867, grad/param norm = 2.0176e-01, time/batch = 0.7066s	
2608/22950 (epoch 5.682), train_loss = 1.71558858, grad/param norm = 2.0705e-01, time/batch = 0.7175s	
2609/22950 (epoch 5.684), train_loss = 1.68698561, grad/param norm = 2.0350e-01, time/batch = 0.7171s	
2610/22950 (epoch 5.686), train_loss = 1.65635334, grad/param norm = 2.0945e-01, time/batch = 0.7063s	
2611/22950 (epoch 5.688), train_loss = 1.58046931, grad/param norm = 1.9918e-01, time/batch = 0.7000s	
2612/22950 (epoch 5.691), train_loss = 1.54325890, grad/param norm = 2.0428e-01, time/batch = 0.6996s	
2613/22950 (epoch 5.693), train_loss = 1.52513218, grad/param norm = 2.0881e-01, time/batch = 0.6983s	
2614/22950 (epoch 5.695), train_loss = 1.78571521, grad/param norm = 2.1986e-01, time/batch = 0.7049s	
2615/22950 (epoch 5.697), train_loss = 1.74598099, grad/param norm = 2.0986e-01, time/batch = 0.7340s	
2616/22950 (epoch 5.699), train_loss = 1.66300791, grad/param norm = 2.0190e-01, time/batch = 0.7177s	
2617/22950 (epoch 5.702), train_loss = 1.65242074, grad/param norm = 2.0407e-01, time/batch = 0.7239s	
2618/22950 (epoch 5.704), train_loss = 1.68456674, grad/param norm = 2.1315e-01, time/batch = 0.6952s	
2619/22950 (epoch 5.706), train_loss = 1.74631897, grad/param norm = 2.0864e-01, time/batch = 0.6984s	
2620/22950 (epoch 5.708), train_loss = 1.61494768, grad/param norm = 2.2771e-01, time/batch = 0.6928s	
2621/22950 (epoch 5.710), train_loss = 1.65862664, grad/param norm = 1.7741e-01, time/batch = 0.6930s	
2622/22950 (epoch 5.712), train_loss = 1.77183055, grad/param norm = 2.2051e-01, time/batch = 0.6961s	
2623/22950 (epoch 5.715), train_loss = 1.66020686, grad/param norm = 2.0053e-01, time/batch = 0.6956s	
2624/22950 (epoch 5.717), train_loss = 1.46064245, grad/param norm = 1.8781e-01, time/batch = 0.7033s	
2625/22950 (epoch 5.719), train_loss = 1.61278377, grad/param norm = 2.0558e-01, time/batch = 0.7167s	
2626/22950 (epoch 5.721), train_loss = 1.69455768, grad/param norm = 2.1134e-01, time/batch = 0.7126s	
2627/22950 (epoch 5.723), train_loss = 1.49451612, grad/param norm = 1.9542e-01, time/batch = 0.7216s	
2628/22950 (epoch 5.725), train_loss = 1.76788713, grad/param norm = 2.2250e-01, time/batch = 0.7004s	
2629/22950 (epoch 5.728), train_loss = 1.61100772, grad/param norm = 2.1425e-01, time/batch = 0.6994s	
2630/22950 (epoch 5.730), train_loss = 1.62342501, grad/param norm = 2.2152e-01, time/batch = 0.7008s	
2631/22950 (epoch 5.732), train_loss = 1.59638555, grad/param norm = 1.8955e-01, time/batch = 0.7200s	
2632/22950 (epoch 5.734), train_loss = 1.62611460, grad/param norm = 2.0777e-01, time/batch = 0.7070s	
2633/22950 (epoch 5.736), train_loss = 1.50894146, grad/param norm = 2.2591e-01, time/batch = 0.7038s	
2634/22950 (epoch 5.739), train_loss = 1.63880013, grad/param norm = 2.1363e-01, time/batch = 0.6896s	
2635/22950 (epoch 5.741), train_loss = 1.65315454, grad/param norm = 2.2355e-01, time/batch = 0.6890s	
2636/22950 (epoch 5.743), train_loss = 1.78445602, grad/param norm = 2.1522e-01, time/batch = 0.7099s	
2637/22950 (epoch 5.745), train_loss = 1.84325601, grad/param norm = 2.3356e-01, time/batch = 0.7069s	
2638/22950 (epoch 5.747), train_loss = 1.61949052, grad/param norm = 2.2383e-01, time/batch = 0.7025s	
2639/22950 (epoch 5.749), train_loss = 1.52455742, grad/param norm = 2.1669e-01, time/batch = 0.7062s	
2640/22950 (epoch 5.752), train_loss = 1.77325335, grad/param norm = 2.2050e-01, time/batch = 0.7060s	
2641/22950 (epoch 5.754), train_loss = 1.70916517, grad/param norm = 2.3097e-01, time/batch = 0.7062s	
2642/22950 (epoch 5.756), train_loss = 1.47198447, grad/param norm = 2.0870e-01, time/batch = 0.7038s	
2643/22950 (epoch 5.758), train_loss = 1.54520207, grad/param norm = 1.9987e-01, time/batch = 0.6981s	
2644/22950 (epoch 5.760), train_loss = 1.59878305, grad/param norm = 1.9914e-01, time/batch = 0.7061s	
2645/22950 (epoch 5.763), train_loss = 1.55729956, grad/param norm = 2.0223e-01, time/batch = 0.7071s	
2646/22950 (epoch 5.765), train_loss = 1.69029512, grad/param norm = 2.1667e-01, time/batch = 0.6887s	
2647/22950 (epoch 5.767), train_loss = 1.78863233, grad/param norm = 2.0484e-01, time/batch = 0.6909s	
2648/22950 (epoch 5.769), train_loss = 1.60166100, grad/param norm = 2.0556e-01, time/batch = 0.6949s	
2649/22950 (epoch 5.771), train_loss = 1.46209966, grad/param norm = 1.9643e-01, time/batch = 0.6911s	
2650/22950 (epoch 5.773), train_loss = 1.31939325, grad/param norm = 1.8657e-01, time/batch = 0.6921s	
2651/22950 (epoch 5.776), train_loss = 1.51988055, grad/param norm = 1.9497e-01, time/batch = 0.6968s	
2652/22950 (epoch 5.778), train_loss = 1.42435948, grad/param norm = 1.9083e-01, time/batch = 0.7144s	
2653/22950 (epoch 5.780), train_loss = 1.45803578, grad/param norm = 2.0292e-01, time/batch = 0.7221s	
2654/22950 (epoch 5.782), train_loss = 1.53223841, grad/param norm = 2.0558e-01, time/batch = 0.7324s	
2655/22950 (epoch 5.784), train_loss = 1.65034011, grad/param norm = 2.3106e-01, time/batch = 0.7222s	
2656/22950 (epoch 5.786), train_loss = 1.64989315, grad/param norm = 2.0642e-01, time/batch = 0.7084s	
2657/22950 (epoch 5.789), train_loss = 1.42539836, grad/param norm = 2.0409e-01, time/batch = 0.6998s	
2658/22950 (epoch 5.791), train_loss = 1.49165878, grad/param norm = 2.2004e-01, time/batch = 0.7000s	
2659/22950 (epoch 5.793), train_loss = 1.86105109, grad/param norm = 2.0692e-01, time/batch = 0.6988s	
2660/22950 (epoch 5.795), train_loss = 1.49742830, grad/param norm = 1.9567e-01, time/batch = 0.6959s	
2661/22950 (epoch 5.797), train_loss = 1.80725897, grad/param norm = 2.3257e-01, time/batch = 0.7070s	
2662/22950 (epoch 5.800), train_loss = 1.50469204, grad/param norm = 2.4811e-01, time/batch = 0.7210s	
2663/22950 (epoch 5.802), train_loss = 1.54187585, grad/param norm = 2.1202e-01, time/batch = 0.7164s	
2664/22950 (epoch 5.804), train_loss = 1.58071366, grad/param norm = 2.1128e-01, time/batch = 0.6990s	
2665/22950 (epoch 5.806), train_loss = 1.46768055, grad/param norm = 2.0273e-01, time/batch = 0.6943s	
2666/22950 (epoch 5.808), train_loss = 1.52956246, grad/param norm = 2.1277e-01, time/batch = 0.6942s	
2667/22950 (epoch 5.810), train_loss = 1.53737608, grad/param norm = 2.1411e-01, time/batch = 0.6968s	
2668/22950 (epoch 5.813), train_loss = 1.32799479, grad/param norm = 1.8308e-01, time/batch = 0.6958s	
2669/22950 (epoch 5.815), train_loss = 1.52578826, grad/param norm = 1.9478e-01, time/batch = 0.6930s	
2670/22950 (epoch 5.817), train_loss = 1.45893563, grad/param norm = 2.1345e-01, time/batch = 0.6912s	
2671/22950 (epoch 5.819), train_loss = 1.55562084, grad/param norm = 2.0860e-01, time/batch = 0.6928s	
2672/22950 (epoch 5.821), train_loss = 1.57752152, grad/param norm = 2.2221e-01, time/batch = 0.7032s	
2673/22950 (epoch 5.824), train_loss = 1.53566501, grad/param norm = 2.0767e-01, time/batch = 0.6978s	
2674/22950 (epoch 5.826), train_loss = 1.67886468, grad/param norm = 2.1440e-01, time/batch = 0.7238s	
2675/22950 (epoch 5.828), train_loss = 1.56242827, grad/param norm = 2.1728e-01, time/batch = 0.7117s	
2676/22950 (epoch 5.830), train_loss = 1.62738217, grad/param norm = 2.1113e-01, time/batch = 0.6968s	
2677/22950 (epoch 5.832), train_loss = 1.62180829, grad/param norm = 2.1106e-01, time/batch = 0.6961s	
2678/22950 (epoch 5.834), train_loss = 1.46738810, grad/param norm = 2.0792e-01, time/batch = 0.6982s	
2679/22950 (epoch 5.837), train_loss = 1.58325962, grad/param norm = 2.1882e-01, time/batch = 0.7044s	
2680/22950 (epoch 5.839), train_loss = 1.50140536, grad/param norm = 1.8548e-01, time/batch = 0.7065s	
2681/22950 (epoch 5.841), train_loss = 1.48751827, grad/param norm = 1.8343e-01, time/batch = 0.6989s	
2682/22950 (epoch 5.843), train_loss = 1.49634236, grad/param norm = 2.0422e-01, time/batch = 0.6977s	
2683/22950 (epoch 5.845), train_loss = 1.56748162, grad/param norm = 2.0338e-01, time/batch = 0.6999s	
2684/22950 (epoch 5.847), train_loss = 1.67048440, grad/param norm = 1.9953e-01, time/batch = 0.6965s	
2685/22950 (epoch 5.850), train_loss = 1.64961977, grad/param norm = 2.2479e-01, time/batch = 0.6931s	
2686/22950 (epoch 5.852), train_loss = 1.66234999, grad/param norm = 2.2594e-01, time/batch = 0.6968s	
2687/22950 (epoch 5.854), train_loss = 1.59548733, grad/param norm = 2.0251e-01, time/batch = 0.6961s	
2688/22950 (epoch 5.856), train_loss = 1.79282501, grad/param norm = 2.1446e-01, time/batch = 0.6931s	
2689/22950 (epoch 5.858), train_loss = 1.60947830, grad/param norm = 2.1280e-01, time/batch = 0.6898s	
2690/22950 (epoch 5.861), train_loss = 1.69594492, grad/param norm = 2.3971e-01, time/batch = 0.6941s	
2691/22950 (epoch 5.863), train_loss = 1.76238617, grad/param norm = 2.1677e-01, time/batch = 0.6971s	
2692/22950 (epoch 5.865), train_loss = 1.78534415, grad/param norm = 2.2076e-01, time/batch = 0.6936s	
2693/22950 (epoch 5.867), train_loss = 1.62751793, grad/param norm = 2.0472e-01, time/batch = 0.6950s	
2694/22950 (epoch 5.869), train_loss = 1.81596292, grad/param norm = 2.2012e-01, time/batch = 0.6973s	
2695/22950 (epoch 5.871), train_loss = 1.54738374, grad/param norm = 2.1306e-01, time/batch = 0.6936s	
2696/22950 (epoch 5.874), train_loss = 1.55411464, grad/param norm = 2.1623e-01, time/batch = 0.6942s	
2697/22950 (epoch 5.876), train_loss = 1.67832289, grad/param norm = 2.2501e-01, time/batch = 0.6986s	
2698/22950 (epoch 5.878), train_loss = 1.48319867, grad/param norm = 2.2157e-01, time/batch = 0.6957s	
2699/22950 (epoch 5.880), train_loss = 1.74380945, grad/param norm = 2.0685e-01, time/batch = 0.6966s	
2700/22950 (epoch 5.882), train_loss = 1.43692394, grad/param norm = 1.9203e-01, time/batch = 0.6981s	
2701/22950 (epoch 5.885), train_loss = 1.60185155, grad/param norm = 2.0927e-01, time/batch = 0.7014s	
2702/22950 (epoch 5.887), train_loss = 1.60044133, grad/param norm = 2.2924e-01, time/batch = 0.7211s	
2703/22950 (epoch 5.889), train_loss = 1.71216487, grad/param norm = 2.3221e-01, time/batch = 0.7233s	
2704/22950 (epoch 5.891), train_loss = 1.61267949, grad/param norm = 1.9670e-01, time/batch = 0.7188s	
2705/22950 (epoch 5.893), train_loss = 1.62319560, grad/param norm = 2.1719e-01, time/batch = 0.7264s	
2706/22950 (epoch 5.895), train_loss = 1.74463990, grad/param norm = 2.3236e-01, time/batch = 0.7253s	
2707/22950 (epoch 5.898), train_loss = 1.57751999, grad/param norm = 1.9792e-01, time/batch = 0.7254s	
2708/22950 (epoch 5.900), train_loss = 1.46025848, grad/param norm = 1.9779e-01, time/batch = 0.7263s	
2709/22950 (epoch 5.902), train_loss = 1.61218209, grad/param norm = 2.1332e-01, time/batch = 0.7242s	
2710/22950 (epoch 5.904), train_loss = 1.61608513, grad/param norm = 2.0806e-01, time/batch = 0.7193s	
2711/22950 (epoch 5.906), train_loss = 1.63346993, grad/param norm = 2.1405e-01, time/batch = 0.7179s	
2712/22950 (epoch 5.908), train_loss = 1.47064766, grad/param norm = 2.2475e-01, time/batch = 0.6964s	
2713/22950 (epoch 5.911), train_loss = 1.42418801, grad/param norm = 1.9816e-01, time/batch = 0.6933s	
2714/22950 (epoch 5.913), train_loss = 1.49156412, grad/param norm = 1.8996e-01, time/batch = 0.6933s	
2715/22950 (epoch 5.915), train_loss = 1.78091230, grad/param norm = 2.2236e-01, time/batch = 0.6954s	
2716/22950 (epoch 5.917), train_loss = 1.43071356, grad/param norm = 2.0638e-01, time/batch = 0.6946s	
2717/22950 (epoch 5.919), train_loss = 1.55307595, grad/param norm = 2.0336e-01, time/batch = 0.6938s	
2718/22950 (epoch 5.922), train_loss = 1.54613613, grad/param norm = 2.0224e-01, time/batch = 0.6980s	
2719/22950 (epoch 5.924), train_loss = 1.67395841, grad/param norm = 2.1900e-01, time/batch = 0.6911s	
2720/22950 (epoch 5.926), train_loss = 1.44077602, grad/param norm = 2.3643e-01, time/batch = 0.6894s	
2721/22950 (epoch 5.928), train_loss = 1.42903079, grad/param norm = 2.0482e-01, time/batch = 0.6931s	
2722/22950 (epoch 5.930), train_loss = 1.39493317, grad/param norm = 2.0425e-01, time/batch = 0.6985s	
2723/22950 (epoch 5.932), train_loss = 1.43045475, grad/param norm = 2.1647e-01, time/batch = 0.6931s	
2724/22950 (epoch 5.935), train_loss = 1.60839650, grad/param norm = 2.1986e-01, time/batch = 0.6936s	
2725/22950 (epoch 5.937), train_loss = 1.62531115, grad/param norm = 2.1823e-01, time/batch = 0.6947s	
2726/22950 (epoch 5.939), train_loss = 1.55029919, grad/param norm = 2.1611e-01, time/batch = 0.6938s	
2727/22950 (epoch 5.941), train_loss = 1.47029450, grad/param norm = 2.0020e-01, time/batch = 0.6939s	
2728/22950 (epoch 5.943), train_loss = 1.61489844, grad/param norm = 2.2726e-01, time/batch = 0.7108s	
2729/22950 (epoch 5.946), train_loss = 1.42675389, grad/param norm = 2.1624e-01, time/batch = 0.7050s	
2730/22950 (epoch 5.948), train_loss = 1.62118932, grad/param norm = 2.2120e-01, time/batch = 0.6955s	
2731/22950 (epoch 5.950), train_loss = 1.63051433, grad/param norm = 2.1533e-01, time/batch = 0.6905s	
2732/22950 (epoch 5.952), train_loss = 1.60499671, grad/param norm = 2.1479e-01, time/batch = 0.6918s	
2733/22950 (epoch 5.954), train_loss = 1.51528368, grad/param norm = 2.0436e-01, time/batch = 0.6905s	
2734/22950 (epoch 5.956), train_loss = 1.50723755, grad/param norm = 1.8904e-01, time/batch = 0.6900s	
2735/22950 (epoch 5.959), train_loss = 1.44447446, grad/param norm = 2.3048e-01, time/batch = 0.6970s	
2736/22950 (epoch 5.961), train_loss = 1.58764877, grad/param norm = 2.0812e-01, time/batch = 0.6967s	
2737/22950 (epoch 5.963), train_loss = 1.67813486, grad/param norm = 2.2308e-01, time/batch = 0.7245s	
2738/22950 (epoch 5.965), train_loss = 1.78589483, grad/param norm = 2.1196e-01, time/batch = 0.7300s	
2739/22950 (epoch 5.967), train_loss = 1.57254905, grad/param norm = 2.3258e-01, time/batch = 0.7210s	
2740/22950 (epoch 5.969), train_loss = 1.47407338, grad/param norm = 1.9868e-01, time/batch = 0.7062s	
2741/22950 (epoch 5.972), train_loss = 1.56335677, grad/param norm = 2.0225e-01, time/batch = 0.6987s	
2742/22950 (epoch 5.974), train_loss = 1.45732579, grad/param norm = 1.9328e-01, time/batch = 0.7373s	
2743/22950 (epoch 5.976), train_loss = 1.41482142, grad/param norm = 2.0786e-01, time/batch = 0.7179s	
2744/22950 (epoch 5.978), train_loss = 1.55996200, grad/param norm = 2.2154e-01, time/batch = 0.7104s	
2745/22950 (epoch 5.980), train_loss = 1.56094715, grad/param norm = 2.1071e-01, time/batch = 0.6993s	
2746/22950 (epoch 5.983), train_loss = 1.43415094, grad/param norm = 2.1950e-01, time/batch = 0.6980s	
2747/22950 (epoch 5.985), train_loss = 1.40600122, grad/param norm = 2.3254e-01, time/batch = 0.6983s	
2748/22950 (epoch 5.987), train_loss = 1.50882781, grad/param norm = 2.1515e-01, time/batch = 0.6955s	
2749/22950 (epoch 5.989), train_loss = 1.62082136, grad/param norm = 2.1637e-01, time/batch = 0.6955s	
2750/22950 (epoch 5.991), train_loss = 1.46777840, grad/param norm = 2.0451e-01, time/batch = 0.6988s	
2751/22950 (epoch 5.993), train_loss = 1.57634084, grad/param norm = 2.1676e-01, time/batch = 0.7020s	
2752/22950 (epoch 5.996), train_loss = 1.66174809, grad/param norm = 2.1631e-01, time/batch = 0.7075s	
2753/22950 (epoch 5.998), train_loss = 1.48219019, grad/param norm = 2.0059e-01, time/batch = 0.7061s	
2754/22950 (epoch 6.000), train_loss = 1.40693392, grad/param norm = 2.0428e-01, time/batch = 0.6937s	
2755/22950 (epoch 6.002), train_loss = 1.77466010, grad/param norm = 2.2931e-01, time/batch = 0.6938s	
2756/22950 (epoch 6.004), train_loss = 1.61744670, grad/param norm = 2.1130e-01, time/batch = 0.6952s	
2757/22950 (epoch 6.007), train_loss = 1.55358205, grad/param norm = 2.0708e-01, time/batch = 0.6963s	
2758/22950 (epoch 6.009), train_loss = 1.64621798, grad/param norm = 1.8766e-01, time/batch = 0.6945s	
2759/22950 (epoch 6.011), train_loss = 1.57780508, grad/param norm = 2.0449e-01, time/batch = 0.6957s	
2760/22950 (epoch 6.013), train_loss = 1.68104048, grad/param norm = 2.1043e-01, time/batch = 0.6944s	
2761/22950 (epoch 6.015), train_loss = 1.63860590, grad/param norm = 2.0316e-01, time/batch = 0.6963s	
2762/22950 (epoch 6.017), train_loss = 1.52050132, grad/param norm = 2.0641e-01, time/batch = 0.6963s	
2763/22950 (epoch 6.020), train_loss = 1.52276108, grad/param norm = 2.0058e-01, time/batch = 0.6978s	
2764/22950 (epoch 6.022), train_loss = 1.37050445, grad/param norm = 1.8622e-01, time/batch = 0.7047s	
2765/22950 (epoch 6.024), train_loss = 1.48609204, grad/param norm = 2.1796e-01, time/batch = 0.6941s	
2766/22950 (epoch 6.026), train_loss = 1.56781745, grad/param norm = 2.1041e-01, time/batch = 0.6914s	
2767/22950 (epoch 6.028), train_loss = 1.59690632, grad/param norm = 2.2053e-01, time/batch = 0.6949s	
2768/22950 (epoch 6.031), train_loss = 1.54877404, grad/param norm = 2.0071e-01, time/batch = 0.7122s	
2769/22950 (epoch 6.033), train_loss = 1.76946149, grad/param norm = 2.0484e-01, time/batch = 0.6988s	
2770/22950 (epoch 6.035), train_loss = 1.53497905, grad/param norm = 1.8192e-01, time/batch = 0.6917s	
2771/22950 (epoch 6.037), train_loss = 1.51335712, grad/param norm = 2.0304e-01, time/batch = 0.6995s	
2772/22950 (epoch 6.039), train_loss = 1.57335304, grad/param norm = 2.1150e-01, time/batch = 0.6959s	
2773/22950 (epoch 6.041), train_loss = 1.54854592, grad/param norm = 1.9276e-01, time/batch = 0.6941s	
2774/22950 (epoch 6.044), train_loss = 1.51375842, grad/param norm = 1.9887e-01, time/batch = 0.6914s	
2775/22950 (epoch 6.046), train_loss = 1.55249798, grad/param norm = 2.1934e-01, time/batch = 0.6898s	
2776/22950 (epoch 6.048), train_loss = 1.57244796, grad/param norm = 1.9377e-01, time/batch = 0.6939s	
2777/22950 (epoch 6.050), train_loss = 1.62100266, grad/param norm = 2.1462e-01, time/batch = 0.6910s	
2778/22950 (epoch 6.052), train_loss = 1.54544735, grad/param norm = 2.1165e-01, time/batch = 0.6924s	
2779/22950 (epoch 6.054), train_loss = 1.83525676, grad/param norm = 2.3374e-01, time/batch = 0.6953s	
2780/22950 (epoch 6.057), train_loss = 1.63176027, grad/param norm = 2.0458e-01, time/batch = 0.6942s	
2781/22950 (epoch 6.059), train_loss = 1.64557010, grad/param norm = 2.0536e-01, time/batch = 0.6941s	
2782/22950 (epoch 6.061), train_loss = 1.42542688, grad/param norm = 2.0220e-01, time/batch = 0.6930s	
2783/22950 (epoch 6.063), train_loss = 1.60681315, grad/param norm = 2.1477e-01, time/batch = 0.6939s	
2784/22950 (epoch 6.065), train_loss = 1.25931851, grad/param norm = 2.1105e-01, time/batch = 0.6947s	
2785/22950 (epoch 6.068), train_loss = 1.69150936, grad/param norm = 2.0716e-01, time/batch = 0.7304s	
2786/22950 (epoch 6.070), train_loss = 1.45133713, grad/param norm = 2.0858e-01, time/batch = 0.7122s	
2787/22950 (epoch 6.072), train_loss = 1.56711228, grad/param norm = 2.2447e-01, time/batch = 0.7101s	
2788/22950 (epoch 6.074), train_loss = 1.54702904, grad/param norm = 2.2975e-01, time/batch = 0.7010s	
2789/22950 (epoch 6.076), train_loss = 1.52939522, grad/param norm = 2.2667e-01, time/batch = 0.6914s	
2790/22950 (epoch 6.078), train_loss = 1.68578688, grad/param norm = 2.3747e-01, time/batch = 0.6913s	
2791/22950 (epoch 6.081), train_loss = 1.66390984, grad/param norm = 2.1339e-01, time/batch = 0.6923s	
2792/22950 (epoch 6.083), train_loss = 1.53002699, grad/param norm = 2.3733e-01, time/batch = 0.6915s	
2793/22950 (epoch 6.085), train_loss = 1.43346954, grad/param norm = 2.1171e-01, time/batch = 0.6907s	
2794/22950 (epoch 6.087), train_loss = 1.47540480, grad/param norm = 2.0758e-01, time/batch = 0.6932s	
2795/22950 (epoch 6.089), train_loss = 1.57613303, grad/param norm = 1.9727e-01, time/batch = 0.6947s	
2796/22950 (epoch 6.092), train_loss = 1.55938631, grad/param norm = 2.0824e-01, time/batch = 0.6906s	
2797/22950 (epoch 6.094), train_loss = 1.49329626, grad/param norm = 2.0535e-01, time/batch = 0.6887s	
2798/22950 (epoch 6.096), train_loss = 1.69546055, grad/param norm = 2.1290e-01, time/batch = 0.6904s	
2799/22950 (epoch 6.098), train_loss = 1.57760946, grad/param norm = 2.1402e-01, time/batch = 0.6930s	
2800/22950 (epoch 6.100), train_loss = 1.48584250, grad/param norm = 2.0507e-01, time/batch = 0.6900s	
2801/22950 (epoch 6.102), train_loss = 1.55220454, grad/param norm = 1.8794e-01, time/batch = 0.6909s	
2802/22950 (epoch 6.105), train_loss = 1.41170397, grad/param norm = 1.8792e-01, time/batch = 0.6891s	
2803/22950 (epoch 6.107), train_loss = 1.50101415, grad/param norm = 2.0956e-01, time/batch = 0.6996s	
2804/22950 (epoch 6.109), train_loss = 1.50700099, grad/param norm = 2.0442e-01, time/batch = 0.6909s	
2805/22950 (epoch 6.111), train_loss = 1.39498301, grad/param norm = 1.9122e-01, time/batch = 0.6915s	
2806/22950 (epoch 6.113), train_loss = 1.59405434, grad/param norm = 1.9459e-01, time/batch = 0.6891s	
2807/22950 (epoch 6.115), train_loss = 1.65640264, grad/param norm = 2.4981e-01, time/batch = 0.6900s	
2808/22950 (epoch 6.118), train_loss = 1.69409393, grad/param norm = 2.0074e-01, time/batch = 0.6960s	
2809/22950 (epoch 6.120), train_loss = 1.48525600, grad/param norm = 2.0897e-01, time/batch = 0.6925s	
2810/22950 (epoch 6.122), train_loss = 1.66795867, grad/param norm = 2.0648e-01, time/batch = 0.7051s	
2811/22950 (epoch 6.124), train_loss = 1.34324211, grad/param norm = 1.8751e-01, time/batch = 0.6924s	
2812/22950 (epoch 6.126), train_loss = 1.50087380, grad/param norm = 2.1018e-01, time/batch = 0.7126s	
2813/22950 (epoch 6.129), train_loss = 1.35685064, grad/param norm = 1.9866e-01, time/batch = 0.7063s	
2814/22950 (epoch 6.131), train_loss = 1.55244044, grad/param norm = 2.2926e-01, time/batch = 0.6940s	
2815/22950 (epoch 6.133), train_loss = 1.66125850, grad/param norm = 2.1069e-01, time/batch = 0.6946s	
2816/22950 (epoch 6.135), train_loss = 1.51572054, grad/param norm = 2.1228e-01, time/batch = 0.6903s	
2817/22950 (epoch 6.137), train_loss = 1.78332758, grad/param norm = 2.3308e-01, time/batch = 0.6913s	
2818/22950 (epoch 6.139), train_loss = 1.51275200, grad/param norm = 2.2371e-01, time/batch = 0.6923s	
2819/22950 (epoch 6.142), train_loss = 1.43881569, grad/param norm = 2.0964e-01, time/batch = 0.6996s	
2820/22950 (epoch 6.144), train_loss = 1.43194500, grad/param norm = 1.9900e-01, time/batch = 0.6942s	
2821/22950 (epoch 6.146), train_loss = 1.57784783, grad/param norm = 2.1181e-01, time/batch = 0.6933s	
2822/22950 (epoch 6.148), train_loss = 1.47748060, grad/param norm = 1.9577e-01, time/batch = 0.7258s	
2823/22950 (epoch 6.150), train_loss = 1.50800362, grad/param norm = 1.9730e-01, time/batch = 0.7272s	
2824/22950 (epoch 6.153), train_loss = 1.51521187, grad/param norm = 2.0037e-01, time/batch = 0.7261s	
2825/22950 (epoch 6.155), train_loss = 1.46988656, grad/param norm = 2.0974e-01, time/batch = 0.7169s	
2826/22950 (epoch 6.157), train_loss = 1.47177439, grad/param norm = 2.1338e-01, time/batch = 0.7004s	
2827/22950 (epoch 6.159), train_loss = 1.39857248, grad/param norm = 1.9204e-01, time/batch = 0.7007s	
2828/22950 (epoch 6.161), train_loss = 1.54373041, grad/param norm = 2.0435e-01, time/batch = 0.7331s	
2829/22950 (epoch 6.163), train_loss = 1.48228110, grad/param norm = 2.0695e-01, time/batch = 0.7065s	
2830/22950 (epoch 6.166), train_loss = 1.67984425, grad/param norm = 1.9451e-01, time/batch = 0.7064s	
2831/22950 (epoch 6.168), train_loss = 1.69783755, grad/param norm = 2.2867e-01, time/batch = 0.7080s	
2832/22950 (epoch 6.170), train_loss = 1.61483025, grad/param norm = 2.1818e-01, time/batch = 0.7072s	
2833/22950 (epoch 6.172), train_loss = 1.53050328, grad/param norm = 2.0472e-01, time/batch = 0.6938s	
2834/22950 (epoch 6.174), train_loss = 1.61653870, grad/param norm = 2.2893e-01, time/batch = 0.6957s	
2835/22950 (epoch 6.176), train_loss = 1.66693264, grad/param norm = 2.0762e-01, time/batch = 0.6916s	
2836/22950 (epoch 6.179), train_loss = 1.61650808, grad/param norm = 2.3232e-01, time/batch = 0.6959s	
2837/22950 (epoch 6.181), train_loss = 1.72500055, grad/param norm = 2.2014e-01, time/batch = 0.6963s	
2838/22950 (epoch 6.183), train_loss = 1.63672163, grad/param norm = 2.2324e-01, time/batch = 0.6967s	
2839/22950 (epoch 6.185), train_loss = 1.60553504, grad/param norm = 2.0627e-01, time/batch = 0.6932s	
2840/22950 (epoch 6.187), train_loss = 1.39403013, grad/param norm = 2.0260e-01, time/batch = 0.6936s	
2841/22950 (epoch 6.190), train_loss = 1.55384867, grad/param norm = 2.1585e-01, time/batch = 0.6932s	
2842/22950 (epoch 6.192), train_loss = 1.44094063, grad/param norm = 1.9155e-01, time/batch = 0.7145s	
2843/22950 (epoch 6.194), train_loss = 1.54952519, grad/param norm = 2.3287e-01, time/batch = 0.7008s	
2844/22950 (epoch 6.196), train_loss = 1.34306541, grad/param norm = 2.0768e-01, time/batch = 0.6907s	
2845/22950 (epoch 6.198), train_loss = 1.67270444, grad/param norm = 2.1750e-01, time/batch = 0.6942s	
2846/22950 (epoch 6.200), train_loss = 1.38436434, grad/param norm = 1.9318e-01, time/batch = 0.6917s	
2847/22950 (epoch 6.203), train_loss = 1.34552083, grad/param norm = 1.9022e-01, time/batch = 0.6963s	
2848/22950 (epoch 6.205), train_loss = 1.45313706, grad/param norm = 2.3930e-01, time/batch = 0.7071s	
2849/22950 (epoch 6.207), train_loss = 1.51352304, grad/param norm = 2.2021e-01, time/batch = 0.6991s	
2850/22950 (epoch 6.209), train_loss = 1.74275801, grad/param norm = 2.2327e-01, time/batch = 0.6942s	
2851/22950 (epoch 6.211), train_loss = 1.42686620, grad/param norm = 2.3016e-01, time/batch = 0.7061s	
2852/22950 (epoch 6.214), train_loss = 1.49260159, grad/param norm = 2.1402e-01, time/batch = 0.7283s	
2853/22950 (epoch 6.216), train_loss = 1.59077448, grad/param norm = 1.9881e-01, time/batch = 0.7041s	
2854/22950 (epoch 6.218), train_loss = 1.56424741, grad/param norm = 2.0807e-01, time/batch = 0.6937s	
2855/22950 (epoch 6.220), train_loss = 1.69222242, grad/param norm = 2.1775e-01, time/batch = 0.6944s	
2856/22950 (epoch 6.222), train_loss = 1.66782372, grad/param norm = 2.2071e-01, time/batch = 0.6994s	
2857/22950 (epoch 6.224), train_loss = 1.49202950, grad/param norm = 2.1485e-01, time/batch = 0.6913s	
2858/22950 (epoch 6.227), train_loss = 1.53060035, grad/param norm = 2.2687e-01, time/batch = 0.6879s	
2859/22950 (epoch 6.229), train_loss = 1.53773743, grad/param norm = 2.0037e-01, time/batch = 0.6861s	
2860/22950 (epoch 6.231), train_loss = 1.41056253, grad/param norm = 2.0468e-01, time/batch = 0.6858s	
2861/22950 (epoch 6.233), train_loss = 1.51537848, grad/param norm = 1.9872e-01, time/batch = 0.6899s	
2862/22950 (epoch 6.235), train_loss = 1.64902611, grad/param norm = 2.1616e-01, time/batch = 0.6869s	
2863/22950 (epoch 6.237), train_loss = 1.39887986, grad/param norm = 2.0336e-01, time/batch = 0.6883s	
2864/22950 (epoch 6.240), train_loss = 1.49260601, grad/param norm = 2.0162e-01, time/batch = 0.6883s	
2865/22950 (epoch 6.242), train_loss = 1.62420412, grad/param norm = 2.5647e-01, time/batch = 0.6917s	
2866/22950 (epoch 6.244), train_loss = 1.72826388, grad/param norm = 2.2626e-01, time/batch = 0.6877s	
2867/22950 (epoch 6.246), train_loss = 1.66331409, grad/param norm = 2.2427e-01, time/batch = 0.6902s	
2868/22950 (epoch 6.248), train_loss = 1.59547433, grad/param norm = 2.3184e-01, time/batch = 0.6850s	
2869/22950 (epoch 6.251), train_loss = 1.54608838, grad/param norm = 2.0892e-01, time/batch = 0.6859s	
2870/22950 (epoch 6.253), train_loss = 1.52984045, grad/param norm = 2.0278e-01, time/batch = 0.6868s	
2871/22950 (epoch 6.255), train_loss = 1.49044314, grad/param norm = 2.0498e-01, time/batch = 0.6900s	
2872/22950 (epoch 6.257), train_loss = 1.68235412, grad/param norm = 2.1836e-01, time/batch = 0.7044s	
2873/22950 (epoch 6.259), train_loss = 1.38081280, grad/param norm = 1.9627e-01, time/batch = 0.7080s	
2874/22950 (epoch 6.261), train_loss = 1.57733366, grad/param norm = 2.0819e-01, time/batch = 0.6896s	
2875/22950 (epoch 6.264), train_loss = 1.40777123, grad/param norm = 1.8086e-01, time/batch = 0.6969s	
2876/22950 (epoch 6.266), train_loss = 1.64559369, grad/param norm = 2.0654e-01, time/batch = 0.7137s	
2877/22950 (epoch 6.268), train_loss = 1.59202507, grad/param norm = 1.9048e-01, time/batch = 0.6885s	
2878/22950 (epoch 6.270), train_loss = 1.61617054, grad/param norm = 1.9029e-01, time/batch = 0.6841s	
2879/22950 (epoch 6.272), train_loss = 1.72046329, grad/param norm = 2.1260e-01, time/batch = 0.6890s	
2880/22950 (epoch 6.275), train_loss = 1.45836582, grad/param norm = 2.2496e-01, time/batch = 0.6914s	
2881/22950 (epoch 6.277), train_loss = 1.39986866, grad/param norm = 2.1044e-01, time/batch = 0.6917s	
2882/22950 (epoch 6.279), train_loss = 1.63609604, grad/param norm = 2.3322e-01, time/batch = 0.6875s	
2883/22950 (epoch 6.281), train_loss = 1.46707165, grad/param norm = 2.3678e-01, time/batch = 0.6882s	
2884/22950 (epoch 6.283), train_loss = 1.36960639, grad/param norm = 2.0467e-01, time/batch = 0.6868s	
2885/22950 (epoch 6.285), train_loss = 1.53021734, grad/param norm = 2.1083e-01, time/batch = 0.6956s	
2886/22950 (epoch 6.288), train_loss = 1.50886365, grad/param norm = 2.1450e-01, time/batch = 0.6874s	
2887/22950 (epoch 6.290), train_loss = 1.46362506, grad/param norm = 2.1343e-01, time/batch = 0.6803s	
2888/22950 (epoch 6.292), train_loss = 1.58483017, grad/param norm = 2.0562e-01, time/batch = 0.6835s	
2889/22950 (epoch 6.294), train_loss = 1.58768154, grad/param norm = 2.1206e-01, time/batch = 0.6819s	
2890/22950 (epoch 6.296), train_loss = 1.29928598, grad/param norm = 1.8746e-01, time/batch = 0.6808s	
2891/22950 (epoch 6.298), train_loss = 1.49429270, grad/param norm = 1.8131e-01, time/batch = 0.6852s	
2892/22950 (epoch 6.301), train_loss = 1.56915854, grad/param norm = 2.1278e-01, time/batch = 0.6879s	
2893/22950 (epoch 6.303), train_loss = 1.62626437, grad/param norm = 2.0785e-01, time/batch = 0.6977s	
2894/22950 (epoch 6.305), train_loss = 1.65688201, grad/param norm = 2.2100e-01, time/batch = 0.6917s	
2895/22950 (epoch 6.307), train_loss = 1.66007297, grad/param norm = 2.1571e-01, time/batch = 0.6914s	
2896/22950 (epoch 6.309), train_loss = 1.54134479, grad/param norm = 1.7921e-01, time/batch = 0.7094s	
2897/22950 (epoch 6.312), train_loss = 1.59022968, grad/param norm = 2.0540e-01, time/batch = 0.7216s	
2898/22950 (epoch 6.314), train_loss = 1.43400782, grad/param norm = 2.0408e-01, time/batch = 0.6902s	
2899/22950 (epoch 6.316), train_loss = 1.56056401, grad/param norm = 1.9629e-01, time/batch = 0.6926s	
2900/22950 (epoch 6.318), train_loss = 1.34577924, grad/param norm = 1.9276e-01, time/batch = 0.6890s	
2901/22950 (epoch 6.320), train_loss = 1.50891001, grad/param norm = 1.8669e-01, time/batch = 0.6898s	
2902/22950 (epoch 6.322), train_loss = 1.51841308, grad/param norm = 2.0977e-01, time/batch = 0.6894s	
2903/22950 (epoch 6.325), train_loss = 1.21852743, grad/param norm = 1.8865e-01, time/batch = 0.6951s	
2904/22950 (epoch 6.327), train_loss = 1.29078255, grad/param norm = 1.8536e-01, time/batch = 0.6877s	
2905/22950 (epoch 6.329), train_loss = 1.41812021, grad/param norm = 1.9571e-01, time/batch = 0.6876s	
2906/22950 (epoch 6.331), train_loss = 1.38120604, grad/param norm = 1.9360e-01, time/batch = 0.7038s	
2907/22950 (epoch 6.333), train_loss = 1.47904302, grad/param norm = 2.0405e-01, time/batch = 0.7256s	
2908/22950 (epoch 6.336), train_loss = 1.52636894, grad/param norm = 2.3838e-01, time/batch = 0.7060s	
2909/22950 (epoch 6.338), train_loss = 1.46923201, grad/param norm = 2.3561e-01, time/batch = 0.7145s	
2910/22950 (epoch 6.340), train_loss = 1.45802057, grad/param norm = 2.1503e-01, time/batch = 0.7267s	
2911/22950 (epoch 6.342), train_loss = 1.60314226, grad/param norm = 2.0618e-01, time/batch = 0.7202s	
2912/22950 (epoch 6.344), train_loss = 1.54849305, grad/param norm = 2.1613e-01, time/batch = 0.7251s	
2913/22950 (epoch 6.346), train_loss = 1.75266651, grad/param norm = 2.2690e-01, time/batch = 0.6975s	
2914/22950 (epoch 6.349), train_loss = 1.58572549, grad/param norm = 2.1787e-01, time/batch = 0.6960s	
2915/22950 (epoch 6.351), train_loss = 1.55222611, grad/param norm = 2.2167e-01, time/batch = 0.6959s	
2916/22950 (epoch 6.353), train_loss = 1.66393375, grad/param norm = 2.4075e-01, time/batch = 0.7151s	
2917/22950 (epoch 6.355), train_loss = 1.68619436, grad/param norm = 2.2914e-01, time/batch = 0.7148s	
2918/22950 (epoch 6.357), train_loss = 1.55095026, grad/param norm = 2.0368e-01, time/batch = 0.6917s	
2919/22950 (epoch 6.359), train_loss = 1.60368071, grad/param norm = 1.9959e-01, time/batch = 0.6942s	
2920/22950 (epoch 6.362), train_loss = 1.47305274, grad/param norm = 1.9696e-01, time/batch = 0.7059s	
2921/22950 (epoch 6.364), train_loss = 1.54217550, grad/param norm = 2.0334e-01, time/batch = 0.7020s	
2922/22950 (epoch 6.366), train_loss = 1.34371321, grad/param norm = 1.8656e-01, time/batch = 0.6954s	
2923/22950 (epoch 6.368), train_loss = 1.55356226, grad/param norm = 2.3042e-01, time/batch = 0.6966s	
2924/22950 (epoch 6.370), train_loss = 1.49468776, grad/param norm = 2.1711e-01, time/batch = 0.6906s	
2925/22950 (epoch 6.373), train_loss = 1.37691562, grad/param norm = 1.9325e-01, time/batch = 0.6938s	
2926/22950 (epoch 6.375), train_loss = 1.68449684, grad/param norm = 2.2712e-01, time/batch = 0.6906s	
2927/22950 (epoch 6.377), train_loss = 1.49674508, grad/param norm = 2.0520e-01, time/batch = 0.6891s	
2928/22950 (epoch 6.379), train_loss = 1.64698017, grad/param norm = 1.9522e-01, time/batch = 0.6904s	
2929/22950 (epoch 6.381), train_loss = 1.38288172, grad/param norm = 2.0237e-01, time/batch = 0.6896s	
2930/22950 (epoch 6.383), train_loss = 1.59699677, grad/param norm = 2.3463e-01, time/batch = 0.6927s	
2931/22950 (epoch 6.386), train_loss = 1.56092924, grad/param norm = 2.4831e-01, time/batch = 0.6900s	
2932/22950 (epoch 6.388), train_loss = 1.57416825, grad/param norm = 2.2608e-01, time/batch = 0.6959s	
2933/22950 (epoch 6.390), train_loss = 1.41584353, grad/param norm = 2.0992e-01, time/batch = 0.6996s	
2934/22950 (epoch 6.392), train_loss = 1.38801342, grad/param norm = 1.9169e-01, time/batch = 0.7027s	
2935/22950 (epoch 6.394), train_loss = 1.41899634, grad/param norm = 1.7811e-01, time/batch = 0.7087s	
2936/22950 (epoch 6.397), train_loss = 1.61843433, grad/param norm = 2.2513e-01, time/batch = 0.7010s	
2937/22950 (epoch 6.399), train_loss = 1.62240360, grad/param norm = 2.0510e-01, time/batch = 0.7034s	
2938/22950 (epoch 6.401), train_loss = 1.83137292, grad/param norm = 2.1919e-01, time/batch = 0.7017s	
2939/22950 (epoch 6.403), train_loss = 1.49395124, grad/param norm = 2.1852e-01, time/batch = 0.6983s	
2940/22950 (epoch 6.405), train_loss = 1.63724074, grad/param norm = 2.2129e-01, time/batch = 0.6929s	
2941/22950 (epoch 6.407), train_loss = 1.70391252, grad/param norm = 2.1686e-01, time/batch = 0.7053s	
2942/22950 (epoch 6.410), train_loss = 1.36736138, grad/param norm = 1.9672e-01, time/batch = 0.6970s	
2943/22950 (epoch 6.412), train_loss = 1.54555788, grad/param norm = 2.1386e-01, time/batch = 0.7095s	
2944/22950 (epoch 6.414), train_loss = 1.62755984, grad/param norm = 2.1308e-01, time/batch = 0.7043s	
2945/22950 (epoch 6.416), train_loss = 1.62841171, grad/param norm = 2.0435e-01, time/batch = 0.6931s	
2946/22950 (epoch 6.418), train_loss = 1.64625242, grad/param norm = 2.1675e-01, time/batch = 0.7008s	
2947/22950 (epoch 6.420), train_loss = 1.60964732, grad/param norm = 2.0588e-01, time/batch = 0.6992s	
2948/22950 (epoch 6.423), train_loss = 1.38573597, grad/param norm = 1.7030e-01, time/batch = 0.7067s	
2949/22950 (epoch 6.425), train_loss = 1.53869508, grad/param norm = 1.9699e-01, time/batch = 0.7128s	
2950/22950 (epoch 6.427), train_loss = 1.45862186, grad/param norm = 1.9743e-01, time/batch = 0.6969s	
2951/22950 (epoch 6.429), train_loss = 1.42261997, grad/param norm = 2.0148e-01, time/batch = 0.6981s	
2952/22950 (epoch 6.431), train_loss = 1.58259766, grad/param norm = 2.1974e-01, time/batch = 0.6927s	
2953/22950 (epoch 6.434), train_loss = 1.51799850, grad/param norm = 2.1725e-01, time/batch = 0.6945s	
2954/22950 (epoch 6.436), train_loss = 1.79938666, grad/param norm = 2.3113e-01, time/batch = 0.6919s	
2955/22950 (epoch 6.438), train_loss = 1.54292231, grad/param norm = 2.2826e-01, time/batch = 0.6889s	
2956/22950 (epoch 6.440), train_loss = 1.56287924, grad/param norm = 2.0682e-01, time/batch = 0.6899s	
2957/22950 (epoch 6.442), train_loss = 1.71301145, grad/param norm = 2.3316e-01, time/batch = 0.6939s	
2958/22950 (epoch 6.444), train_loss = 1.68512986, grad/param norm = 2.3057e-01, time/batch = 0.6961s	
2959/22950 (epoch 6.447), train_loss = 1.75972705, grad/param norm = 2.3427e-01, time/batch = 0.6891s	
2960/22950 (epoch 6.449), train_loss = 1.39623507, grad/param norm = 1.7966e-01, time/batch = 0.6901s	
2961/22950 (epoch 6.451), train_loss = 1.58135567, grad/param norm = 2.0578e-01, time/batch = 0.6974s	
2962/22950 (epoch 6.453), train_loss = 1.60941725, grad/param norm = 1.9635e-01, time/batch = 0.6912s	
2963/22950 (epoch 6.455), train_loss = 1.43904263, grad/param norm = 1.9441e-01, time/batch = 0.6871s	
2964/22950 (epoch 6.458), train_loss = 1.67519557, grad/param norm = 2.0993e-01, time/batch = 0.6878s	
2965/22950 (epoch 6.460), train_loss = 1.60074297, grad/param norm = 2.0961e-01, time/batch = 0.6913s	
2966/22950 (epoch 6.462), train_loss = 1.51322065, grad/param norm = 2.1059e-01, time/batch = 0.7161s	
2967/22950 (epoch 6.464), train_loss = 1.51807397, grad/param norm = 2.2538e-01, time/batch = 0.7259s	
2968/22950 (epoch 6.466), train_loss = 1.54521674, grad/param norm = 2.2869e-01, time/batch = 0.7059s	
2969/22950 (epoch 6.468), train_loss = 1.64401408, grad/param norm = 1.9584e-01, time/batch = 0.6938s	
2970/22950 (epoch 6.471), train_loss = 1.52238779, grad/param norm = 2.0705e-01, time/batch = 0.7057s	
2971/22950 (epoch 6.473), train_loss = 1.64939664, grad/param norm = 2.2339e-01, time/batch = 0.7049s	
2972/22950 (epoch 6.475), train_loss = 1.78715671, grad/param norm = 2.3861e-01, time/batch = 0.6934s	
2973/22950 (epoch 6.477), train_loss = 1.58621981, grad/param norm = 2.0662e-01, time/batch = 0.6955s	
2974/22950 (epoch 6.479), train_loss = 1.54803767, grad/param norm = 2.1556e-01, time/batch = 0.7018s	
2975/22950 (epoch 6.481), train_loss = 1.77819305, grad/param norm = 2.4328e-01, time/batch = 0.6874s	
2976/22950 (epoch 6.484), train_loss = 1.66245806, grad/param norm = 2.3067e-01, time/batch = 0.6881s	
2977/22950 (epoch 6.486), train_loss = 1.38844484, grad/param norm = 2.0865e-01, time/batch = 0.6896s	
2978/22950 (epoch 6.488), train_loss = 1.54960121, grad/param norm = 2.3020e-01, time/batch = 0.6896s	
2979/22950 (epoch 6.490), train_loss = 1.42640628, grad/param norm = 2.1973e-01, time/batch = 0.6931s	
2980/22950 (epoch 6.492), train_loss = 1.57678949, grad/param norm = 2.1101e-01, time/batch = 0.6905s	
2981/22950 (epoch 6.495), train_loss = 1.54620251, grad/param norm = 1.9900e-01, time/batch = 0.6883s	
2982/22950 (epoch 6.497), train_loss = 1.63039781, grad/param norm = 2.0089e-01, time/batch = 0.6897s	
2983/22950 (epoch 6.499), train_loss = 1.64066936, grad/param norm = 2.1817e-01, time/batch = 0.6867s	
2984/22950 (epoch 6.501), train_loss = 1.65938332, grad/param norm = 2.0565e-01, time/batch = 0.6897s	
2985/22950 (epoch 6.503), train_loss = 1.64924638, grad/param norm = 2.0504e-01, time/batch = 0.6936s	
2986/22950 (epoch 6.505), train_loss = 1.43883579, grad/param norm = 1.8617e-01, time/batch = 0.7120s	
2987/22950 (epoch 6.508), train_loss = 1.58114951, grad/param norm = 2.0364e-01, time/batch = 0.7233s	
2988/22950 (epoch 6.510), train_loss = 1.52480376, grad/param norm = 2.2080e-01, time/batch = 0.7131s	
2989/22950 (epoch 6.512), train_loss = 1.47869047, grad/param norm = 2.1606e-01, time/batch = 0.7116s	
2990/22950 (epoch 6.514), train_loss = 1.39021780, grad/param norm = 2.0577e-01, time/batch = 0.7097s	
2991/22950 (epoch 6.516), train_loss = 1.43767273, grad/param norm = 2.1493e-01, time/batch = 0.7083s	
2992/22950 (epoch 6.519), train_loss = 1.50329449, grad/param norm = 2.1064e-01, time/batch = 0.7103s	
2993/22950 (epoch 6.521), train_loss = 1.51497824, grad/param norm = 1.8999e-01, time/batch = 0.7147s	
2994/22950 (epoch 6.523), train_loss = 1.30469907, grad/param norm = 2.0982e-01, time/batch = 0.7223s	
2995/22950 (epoch 6.525), train_loss = 1.47719205, grad/param norm = 1.9582e-01, time/batch = 0.7341s	
2996/22950 (epoch 6.527), train_loss = 1.29263681, grad/param norm = 1.8974e-01, time/batch = 0.7341s	
2997/22950 (epoch 6.529), train_loss = 1.59377695, grad/param norm = 2.0340e-01, time/batch = 0.7219s	
2998/22950 (epoch 6.532), train_loss = 1.51502531, grad/param norm = 2.0701e-01, time/batch = 0.7124s	
2999/22950 (epoch 6.534), train_loss = 1.64653040, grad/param norm = 2.2408e-01, time/batch = 0.7032s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch6.54_1.6829.t7	
3000/22950 (epoch 6.536), train_loss = 1.58990925, grad/param norm = 2.1688e-01, time/batch = 0.7003s	
3001/22950 (epoch 6.538), train_loss = 1.64860809, grad/param norm = 2.4461e-01, time/batch = 0.6962s	
3002/22950 (epoch 6.540), train_loss = 1.50937088, grad/param norm = 1.8943e-01, time/batch = 0.6959s	
3003/22950 (epoch 6.542), train_loss = 1.74450282, grad/param norm = 2.2216e-01, time/batch = 0.6905s	
3004/22950 (epoch 6.545), train_loss = 1.48288167, grad/param norm = 2.2738e-01, time/batch = 0.6905s	
3005/22950 (epoch 6.547), train_loss = 1.51515465, grad/param norm = 2.0577e-01, time/batch = 0.6900s	
3006/22950 (epoch 6.549), train_loss = 1.51198152, grad/param norm = 2.0701e-01, time/batch = 0.6884s	
3007/22950 (epoch 6.551), train_loss = 1.57479983, grad/param norm = 2.3961e-01, time/batch = 0.6884s	
3008/22950 (epoch 6.553), train_loss = 1.50976841, grad/param norm = 2.1423e-01, time/batch = 0.6899s	
3009/22950 (epoch 6.556), train_loss = 1.61120009, grad/param norm = 1.9302e-01, time/batch = 0.7277s	
3010/22950 (epoch 6.558), train_loss = 1.50584272, grad/param norm = 1.9989e-01, time/batch = 0.7244s	
3011/22950 (epoch 6.560), train_loss = 1.58190123, grad/param norm = 1.9094e-01, time/batch = 0.7274s	
3012/22950 (epoch 6.562), train_loss = 1.38650056, grad/param norm = 1.9353e-01, time/batch = 0.7285s	
3013/22950 (epoch 6.564), train_loss = 1.76860194, grad/param norm = 2.5602e-01, time/batch = 0.7071s	
3014/22950 (epoch 6.566), train_loss = 1.55521282, grad/param norm = 2.1511e-01, time/batch = 0.6880s	
3015/22950 (epoch 6.569), train_loss = 1.72278003, grad/param norm = 2.1456e-01, time/batch = 0.6925s	
3016/22950 (epoch 6.571), train_loss = 1.38232281, grad/param norm = 1.9764e-01, time/batch = 0.6886s	
3017/22950 (epoch 6.573), train_loss = 1.51788823, grad/param norm = 2.0102e-01, time/batch = 0.6859s	
3018/22950 (epoch 6.575), train_loss = 1.83522598, grad/param norm = 2.1792e-01, time/batch = 0.6846s	
3019/22950 (epoch 6.577), train_loss = 1.54537014, grad/param norm = 2.1564e-01, time/batch = 0.6867s	
3020/22950 (epoch 6.580), train_loss = 1.60387887, grad/param norm = 2.1802e-01, time/batch = 0.6893s	
3021/22950 (epoch 6.582), train_loss = 1.72917637, grad/param norm = 1.9780e-01, time/batch = 0.6882s	
3022/22950 (epoch 6.584), train_loss = 1.34507125, grad/param norm = 1.9363e-01, time/batch = 0.6873s	
3023/22950 (epoch 6.586), train_loss = 1.43937531, grad/param norm = 2.0413e-01, time/batch = 0.6846s	
3024/22950 (epoch 6.588), train_loss = 1.68216179, grad/param norm = 2.1036e-01, time/batch = 0.6828s	
3025/22950 (epoch 6.590), train_loss = 1.51812923, grad/param norm = 2.1475e-01, time/batch = 0.6867s	
3026/22950 (epoch 6.593), train_loss = 1.36142167, grad/param norm = 1.9972e-01, time/batch = 0.6867s	
3027/22950 (epoch 6.595), train_loss = 1.41886022, grad/param norm = 2.0449e-01, time/batch = 0.6811s	
3028/22950 (epoch 6.597), train_loss = 1.62626104, grad/param norm = 2.3736e-01, time/batch = 0.6858s	
3029/22950 (epoch 6.599), train_loss = 1.58604417, grad/param norm = 2.4596e-01, time/batch = 0.6880s	
3030/22950 (epoch 6.601), train_loss = 1.53909813, grad/param norm = 2.2760e-01, time/batch = 0.6873s	
3031/22950 (epoch 6.603), train_loss = 1.67897352, grad/param norm = 2.1030e-01, time/batch = 0.6947s	
3032/22950 (epoch 6.606), train_loss = 1.48783333, grad/param norm = 2.0850e-01, time/batch = 0.6890s	
3033/22950 (epoch 6.608), train_loss = 1.50288757, grad/param norm = 2.1169e-01, time/batch = 0.6855s	
3034/22950 (epoch 6.610), train_loss = 1.49975896, grad/param norm = 1.9635e-01, time/batch = 0.6892s	
3035/22950 (epoch 6.612), train_loss = 1.55092129, grad/param norm = 1.9647e-01, time/batch = 0.6995s	
3036/22950 (epoch 6.614), train_loss = 1.68212162, grad/param norm = 2.3908e-01, time/batch = 0.6911s	
3037/22950 (epoch 6.617), train_loss = 1.54095432, grad/param norm = 2.1824e-01, time/batch = 0.7008s	
3038/22950 (epoch 6.619), train_loss = 1.40306129, grad/param norm = 2.0045e-01, time/batch = 0.6980s	
3039/22950 (epoch 6.621), train_loss = 1.62205801, grad/param norm = 1.9757e-01, time/batch = 0.7141s	
3040/22950 (epoch 6.623), train_loss = 1.54646464, grad/param norm = 1.8695e-01, time/batch = 0.7107s	
3041/22950 (epoch 6.625), train_loss = 1.50773854, grad/param norm = 1.8495e-01, time/batch = 0.6886s	
3042/22950 (epoch 6.627), train_loss = 1.57295423, grad/param norm = 2.2142e-01, time/batch = 0.6857s	
3043/22950 (epoch 6.630), train_loss = 1.34246311, grad/param norm = 1.7965e-01, time/batch = 0.6849s	
3044/22950 (epoch 6.632), train_loss = 1.58801719, grad/param norm = 2.1804e-01, time/batch = 0.6893s	
3045/22950 (epoch 6.634), train_loss = 1.47895563, grad/param norm = 1.9972e-01, time/batch = 0.6937s	
3046/22950 (epoch 6.636), train_loss = 1.51060915, grad/param norm = 1.8545e-01, time/batch = 0.6864s	
3047/22950 (epoch 6.638), train_loss = 1.42853946, grad/param norm = 2.0346e-01, time/batch = 0.6833s	
3048/22950 (epoch 6.641), train_loss = 1.45619786, grad/param norm = 1.9306e-01, time/batch = 0.6884s	
3049/22950 (epoch 6.643), train_loss = 1.57934985, grad/param norm = 2.3718e-01, time/batch = 0.7131s	
3050/22950 (epoch 6.645), train_loss = 1.46080285, grad/param norm = 2.5972e-01, time/batch = 0.7125s	
3051/22950 (epoch 6.647), train_loss = 1.53670499, grad/param norm = 2.0615e-01, time/batch = 0.6882s	
3052/22950 (epoch 6.649), train_loss = 1.49574109, grad/param norm = 1.8842e-01, time/batch = 0.6882s	
3053/22950 (epoch 6.651), train_loss = 1.63462743, grad/param norm = 2.1899e-01, time/batch = 0.6861s	
3054/22950 (epoch 6.654), train_loss = 1.31634445, grad/param norm = 1.9419e-01, time/batch = 0.6871s	
3055/22950 (epoch 6.656), train_loss = 1.65371392, grad/param norm = 2.1777e-01, time/batch = 0.6874s	
3056/22950 (epoch 6.658), train_loss = 1.40807507, grad/param norm = 1.9508e-01, time/batch = 0.6861s	
3057/22950 (epoch 6.660), train_loss = 1.35367332, grad/param norm = 1.8897e-01, time/batch = 0.7101s	
3058/22950 (epoch 6.662), train_loss = 1.37057639, grad/param norm = 1.9477e-01, time/batch = 0.7066s	
3059/22950 (epoch 6.664), train_loss = 1.59984598, grad/param norm = 2.0215e-01, time/batch = 0.7174s	
3060/22950 (epoch 6.667), train_loss = 1.56816464, grad/param norm = 2.1801e-01, time/batch = 0.7171s	
3061/22950 (epoch 6.669), train_loss = 1.45295956, grad/param norm = 2.1289e-01, time/batch = 0.6995s	
3062/22950 (epoch 6.671), train_loss = 1.58894264, grad/param norm = 2.1280e-01, time/batch = 0.6995s	
3063/22950 (epoch 6.673), train_loss = 1.54386566, grad/param norm = 1.9110e-01, time/batch = 0.6979s	
3064/22950 (epoch 6.675), train_loss = 1.50887547, grad/param norm = 1.9798e-01, time/batch = 0.6939s	
3065/22950 (epoch 6.678), train_loss = 1.54769301, grad/param norm = 2.1040e-01, time/batch = 0.6868s	
3066/22950 (epoch 6.680), train_loss = 1.55670898, grad/param norm = 1.9990e-01, time/batch = 0.6843s	
3067/22950 (epoch 6.682), train_loss = 1.63828067, grad/param norm = 1.9882e-01, time/batch = 0.6943s	
3068/22950 (epoch 6.684), train_loss = 1.62652099, grad/param norm = 1.9863e-01, time/batch = 0.6885s	
3069/22950 (epoch 6.686), train_loss = 1.58616088, grad/param norm = 2.0533e-01, time/batch = 0.7116s	
3070/22950 (epoch 6.688), train_loss = 1.51329654, grad/param norm = 1.9713e-01, time/batch = 0.7105s	
3071/22950 (epoch 6.691), train_loss = 1.47191616, grad/param norm = 1.9949e-01, time/batch = 0.6890s	
3072/22950 (epoch 6.693), train_loss = 1.44473725, grad/param norm = 2.0145e-01, time/batch = 0.6984s	
3073/22950 (epoch 6.695), train_loss = 1.70875082, grad/param norm = 2.1212e-01, time/batch = 0.7139s	
3074/22950 (epoch 6.697), train_loss = 1.67103061, grad/param norm = 2.0511e-01, time/batch = 0.7271s	
3075/22950 (epoch 6.699), train_loss = 1.59735801, grad/param norm = 1.9410e-01, time/batch = 0.6924s	
3076/22950 (epoch 6.702), train_loss = 1.58583452, grad/param norm = 1.9942e-01, time/batch = 0.6956s	
3077/22950 (epoch 6.704), train_loss = 1.60749793, grad/param norm = 2.0794e-01, time/batch = 0.6991s	
3078/22950 (epoch 6.706), train_loss = 1.67284253, grad/param norm = 2.0575e-01, time/batch = 0.7023s	
3079/22950 (epoch 6.708), train_loss = 1.52023346, grad/param norm = 2.1837e-01, time/batch = 0.7178s	
3080/22950 (epoch 6.710), train_loss = 1.59949511, grad/param norm = 1.8144e-01, time/batch = 0.7131s	
3081/22950 (epoch 6.712), train_loss = 1.70666720, grad/param norm = 2.0777e-01, time/batch = 0.7058s	
3082/22950 (epoch 6.715), train_loss = 1.60102371, grad/param norm = 2.0250e-01, time/batch = 0.6924s	
3083/22950 (epoch 6.717), train_loss = 1.39193800, grad/param norm = 1.8264e-01, time/batch = 0.6928s	
3084/22950 (epoch 6.719), train_loss = 1.52052918, grad/param norm = 2.0464e-01, time/batch = 0.6916s	
3085/22950 (epoch 6.721), train_loss = 1.60915599, grad/param norm = 2.0543e-01, time/batch = 0.6896s	
3086/22950 (epoch 6.723), train_loss = 1.42658418, grad/param norm = 1.9019e-01, time/batch = 0.6914s	
3087/22950 (epoch 6.725), train_loss = 1.68546894, grad/param norm = 2.0798e-01, time/batch = 0.6923s	
3088/22950 (epoch 6.728), train_loss = 1.53853479, grad/param norm = 2.0010e-01, time/batch = 0.6985s	
3089/22950 (epoch 6.730), train_loss = 1.54600381, grad/param norm = 2.1818e-01, time/batch = 0.7215s	
3090/22950 (epoch 6.732), train_loss = 1.53457271, grad/param norm = 1.8391e-01, time/batch = 0.7070s	
3091/22950 (epoch 6.734), train_loss = 1.55511193, grad/param norm = 2.0566e-01, time/batch = 0.6888s	
3092/22950 (epoch 6.736), train_loss = 1.45667222, grad/param norm = 2.1628e-01, time/batch = 0.6882s	
3093/22950 (epoch 6.739), train_loss = 1.57345629, grad/param norm = 1.9835e-01, time/batch = 0.6873s	
3094/22950 (epoch 6.741), train_loss = 1.56652118, grad/param norm = 2.0494e-01, time/batch = 0.6845s	
3095/22950 (epoch 6.743), train_loss = 1.71420685, grad/param norm = 2.1346e-01, time/batch = 0.6843s	
3096/22950 (epoch 6.745), train_loss = 1.78523199, grad/param norm = 2.2339e-01, time/batch = 0.6825s	
3097/22950 (epoch 6.747), train_loss = 1.55232598, grad/param norm = 2.0812e-01, time/batch = 0.6839s	
3098/22950 (epoch 6.749), train_loss = 1.44919445, grad/param norm = 2.1104e-01, time/batch = 0.6831s	
3099/22950 (epoch 6.752), train_loss = 1.71375876, grad/param norm = 2.1105e-01, time/batch = 0.7148s	
3100/22950 (epoch 6.754), train_loss = 1.63351432, grad/param norm = 2.2473e-01, time/batch = 0.7110s	
3101/22950 (epoch 6.756), train_loss = 1.41873570, grad/param norm = 2.1252e-01, time/batch = 0.6983s	
3102/22950 (epoch 6.758), train_loss = 1.48139658, grad/param norm = 2.0020e-01, time/batch = 0.7112s	
3103/22950 (epoch 6.760), train_loss = 1.54375968, grad/param norm = 1.9379e-01, time/batch = 0.7207s	
3104/22950 (epoch 6.763), train_loss = 1.49533519, grad/param norm = 1.9398e-01, time/batch = 0.7212s	
3105/22950 (epoch 6.765), train_loss = 1.63316195, grad/param norm = 2.1091e-01, time/batch = 0.7140s	
3106/22950 (epoch 6.767), train_loss = 1.74887409, grad/param norm = 2.0236e-01, time/batch = 0.7075s	
3107/22950 (epoch 6.769), train_loss = 1.53500216, grad/param norm = 2.0001e-01, time/batch = 0.7074s	
3108/22950 (epoch 6.771), train_loss = 1.40153162, grad/param norm = 1.9117e-01, time/batch = 0.7203s	
3109/22950 (epoch 6.773), train_loss = 1.24972379, grad/param norm = 1.8140e-01, time/batch = 0.7070s	
3110/22950 (epoch 6.776), train_loss = 1.45977720, grad/param norm = 1.9187e-01, time/batch = 0.6884s	
3111/22950 (epoch 6.778), train_loss = 1.35888239, grad/param norm = 1.8435e-01, time/batch = 0.6856s	
3112/22950 (epoch 6.780), train_loss = 1.39283793, grad/param norm = 1.9385e-01, time/batch = 0.6769s	
3113/22950 (epoch 6.782), train_loss = 1.46715050, grad/param norm = 2.0172e-01, time/batch = 0.6771s	
3114/22950 (epoch 6.784), train_loss = 1.58586194, grad/param norm = 2.2630e-01, time/batch = 0.6783s	
3115/22950 (epoch 6.786), train_loss = 1.58271532, grad/param norm = 1.9633e-01, time/batch = 0.6794s	
3116/22950 (epoch 6.789), train_loss = 1.35077233, grad/param norm = 1.9872e-01, time/batch = 0.6765s	
3117/22950 (epoch 6.791), train_loss = 1.40683491, grad/param norm = 2.0928e-01, time/batch = 0.6785s	
3118/22950 (epoch 6.793), train_loss = 1.79041707, grad/param norm = 2.0581e-01, time/batch = 0.6726s	
3119/22950 (epoch 6.795), train_loss = 1.44189388, grad/param norm = 1.9421e-01, time/batch = 0.7021s	
3120/22950 (epoch 6.797), train_loss = 1.73410279, grad/param norm = 2.2734e-01, time/batch = 0.6974s	
3121/22950 (epoch 6.800), train_loss = 1.43685442, grad/param norm = 2.2833e-01, time/batch = 0.6786s	
3122/22950 (epoch 6.802), train_loss = 1.46228704, grad/param norm = 2.0325e-01, time/batch = 0.6817s	
3123/22950 (epoch 6.804), train_loss = 1.51260654, grad/param norm = 2.0331e-01, time/batch = 0.6781s	
3124/22950 (epoch 6.806), train_loss = 1.39121163, grad/param norm = 1.9157e-01, time/batch = 0.6742s	
3125/22950 (epoch 6.808), train_loss = 1.45543221, grad/param norm = 2.0752e-01, time/batch = 0.6719s	
3126/22950 (epoch 6.810), train_loss = 1.46051472, grad/param norm = 2.1299e-01, time/batch = 0.6745s	
3127/22950 (epoch 6.813), train_loss = 1.26467076, grad/param norm = 1.7911e-01, time/batch = 0.6755s	
3128/22950 (epoch 6.815), train_loss = 1.43267476, grad/param norm = 1.8353e-01, time/batch = 0.6798s	
3129/22950 (epoch 6.817), train_loss = 1.37252669, grad/param norm = 1.9788e-01, time/batch = 0.6980s	
3130/22950 (epoch 6.819), train_loss = 1.47648727, grad/param norm = 2.0448e-01, time/batch = 0.6789s	
3131/22950 (epoch 6.821), train_loss = 1.51663247, grad/param norm = 2.1111e-01, time/batch = 0.6841s	
3132/22950 (epoch 6.824), train_loss = 1.47133309, grad/param norm = 2.0175e-01, time/batch = 0.6778s	
3133/22950 (epoch 6.826), train_loss = 1.61444116, grad/param norm = 2.1632e-01, time/batch = 0.6726s	
3134/22950 (epoch 6.828), train_loss = 1.50245220, grad/param norm = 2.1345e-01, time/batch = 0.6750s	
3135/22950 (epoch 6.830), train_loss = 1.54693399, grad/param norm = 1.9680e-01, time/batch = 0.6737s	
3136/22950 (epoch 6.832), train_loss = 1.56502945, grad/param norm = 2.0635e-01, time/batch = 0.6758s	
3137/22950 (epoch 6.834), train_loss = 1.40318630, grad/param norm = 1.9567e-01, time/batch = 0.6755s	
3138/22950 (epoch 6.837), train_loss = 1.51735404, grad/param norm = 2.2039e-01, time/batch = 0.6739s	
3139/22950 (epoch 6.839), train_loss = 1.42622449, grad/param norm = 1.8492e-01, time/batch = 0.6732s	
3140/22950 (epoch 6.841), train_loss = 1.40390819, grad/param norm = 1.8026e-01, time/batch = 0.6750s	
3141/22950 (epoch 6.843), train_loss = 1.43231250, grad/param norm = 2.0350e-01, time/batch = 0.6776s	
3142/22950 (epoch 6.845), train_loss = 1.51189719, grad/param norm = 2.0627e-01, time/batch = 0.6750s	
3143/22950 (epoch 6.847), train_loss = 1.60083451, grad/param norm = 1.9321e-01, time/batch = 0.6762s	
3144/22950 (epoch 6.850), train_loss = 1.58615247, grad/param norm = 2.2500e-01, time/batch = 0.6860s	
3145/22950 (epoch 6.852), train_loss = 1.59222760, grad/param norm = 2.1442e-01, time/batch = 0.6820s	
3146/22950 (epoch 6.854), train_loss = 1.52249956, grad/param norm = 1.9604e-01, time/batch = 0.6786s	
3147/22950 (epoch 6.856), train_loss = 1.72117335, grad/param norm = 2.0889e-01, time/batch = 0.6720s	
3148/22950 (epoch 6.858), train_loss = 1.54622748, grad/param norm = 2.0877e-01, time/batch = 0.6749s	
3149/22950 (epoch 6.861), train_loss = 1.62582363, grad/param norm = 2.2996e-01, time/batch = 0.6852s	
3150/22950 (epoch 6.863), train_loss = 1.68446049, grad/param norm = 2.0680e-01, time/batch = 0.6751s	
3151/22950 (epoch 6.865), train_loss = 1.73212185, grad/param norm = 2.2420e-01, time/batch = 0.6760s	
3152/22950 (epoch 6.867), train_loss = 1.55634201, grad/param norm = 2.0739e-01, time/batch = 0.6759s	
3153/22950 (epoch 6.869), train_loss = 1.75350058, grad/param norm = 2.0934e-01, time/batch = 0.6714s	
3154/22950 (epoch 6.871), train_loss = 1.48336870, grad/param norm = 2.0740e-01, time/batch = 0.6740s	
3155/22950 (epoch 6.874), train_loss = 1.48361955, grad/param norm = 2.0925e-01, time/batch = 0.6720s	
3156/22950 (epoch 6.876), train_loss = 1.60239829, grad/param norm = 2.1927e-01, time/batch = 0.6744s	
3157/22950 (epoch 6.878), train_loss = 1.41981802, grad/param norm = 2.1311e-01, time/batch = 0.6751s	
3158/22950 (epoch 6.880), train_loss = 1.67392803, grad/param norm = 1.9946e-01, time/batch = 0.6722s	
3159/22950 (epoch 6.882), train_loss = 1.37727217, grad/param norm = 1.9257e-01, time/batch = 0.6930s	
3160/22950 (epoch 6.885), train_loss = 1.53921019, grad/param norm = 2.0612e-01, time/batch = 0.7091s	
3161/22950 (epoch 6.887), train_loss = 1.52805089, grad/param norm = 2.1412e-01, time/batch = 0.7067s	
3162/22950 (epoch 6.889), train_loss = 1.64827076, grad/param norm = 2.2990e-01, time/batch = 0.6828s	
3163/22950 (epoch 6.891), train_loss = 1.54735975, grad/param norm = 1.9702e-01, time/batch = 0.6783s	
3164/22950 (epoch 6.893), train_loss = 1.54705039, grad/param norm = 2.1130e-01, time/batch = 0.6865s	
3165/22950 (epoch 6.895), train_loss = 1.67894831, grad/param norm = 2.2780e-01, time/batch = 0.7013s	
3166/22950 (epoch 6.898), train_loss = 1.51258075, grad/param norm = 1.9786e-01, time/batch = 0.7137s	
3167/22950 (epoch 6.900), train_loss = 1.40682862, grad/param norm = 1.9103e-01, time/batch = 0.6942s	
3168/22950 (epoch 6.902), train_loss = 1.56928251, grad/param norm = 2.0915e-01, time/batch = 0.6860s	
3169/22950 (epoch 6.904), train_loss = 1.56685261, grad/param norm = 2.0013e-01, time/batch = 0.6745s	
3170/22950 (epoch 6.906), train_loss = 1.56221934, grad/param norm = 2.1387e-01, time/batch = 0.6716s	
3171/22950 (epoch 6.908), train_loss = 1.39680458, grad/param norm = 2.0518e-01, time/batch = 0.6775s	
3172/22950 (epoch 6.911), train_loss = 1.35912305, grad/param norm = 1.8625e-01, time/batch = 0.6761s	
3173/22950 (epoch 6.913), train_loss = 1.44891736, grad/param norm = 1.9155e-01, time/batch = 0.6797s	
3174/22950 (epoch 6.915), train_loss = 1.70641558, grad/param norm = 2.1791e-01, time/batch = 0.6768s	
3175/22950 (epoch 6.917), train_loss = 1.34893662, grad/param norm = 1.9218e-01, time/batch = 0.6891s	
3176/22950 (epoch 6.919), train_loss = 1.48623951, grad/param norm = 2.0047e-01, time/batch = 0.6765s	
3177/22950 (epoch 6.922), train_loss = 1.49373916, grad/param norm = 2.0073e-01, time/batch = 0.6767s	
3178/22950 (epoch 6.924), train_loss = 1.59892175, grad/param norm = 2.0472e-01, time/batch = 0.6811s	
3179/22950 (epoch 6.926), train_loss = 1.37209391, grad/param norm = 2.1305e-01, time/batch = 0.6785s	
3180/22950 (epoch 6.928), train_loss = 1.36282133, grad/param norm = 1.9903e-01, time/batch = 0.6785s	
3181/22950 (epoch 6.930), train_loss = 1.32788908, grad/param norm = 2.0478e-01, time/batch = 0.6767s	
3182/22950 (epoch 6.932), train_loss = 1.34508736, grad/param norm = 2.0440e-01, time/batch = 0.6823s	
3183/22950 (epoch 6.935), train_loss = 1.54793849, grad/param norm = 2.1343e-01, time/batch = 0.6862s	
3184/22950 (epoch 6.937), train_loss = 1.55849864, grad/param norm = 2.1327e-01, time/batch = 0.6866s	
3185/22950 (epoch 6.939), train_loss = 1.46696360, grad/param norm = 2.0825e-01, time/batch = 0.6908s	
3186/22950 (epoch 6.941), train_loss = 1.40213870, grad/param norm = 1.9512e-01, time/batch = 0.6930s	
3187/22950 (epoch 6.943), train_loss = 1.54656398, grad/param norm = 2.1684e-01, time/batch = 0.6806s	
3188/22950 (epoch 6.946), train_loss = 1.36353712, grad/param norm = 2.0659e-01, time/batch = 0.6875s	
3189/22950 (epoch 6.948), train_loss = 1.54674555, grad/param norm = 1.9794e-01, time/batch = 0.6842s	
3190/22950 (epoch 6.950), train_loss = 1.57510002, grad/param norm = 2.1615e-01, time/batch = 0.6889s	
3191/22950 (epoch 6.952), train_loss = 1.52668512, grad/param norm = 2.0936e-01, time/batch = 0.6834s	
3192/22950 (epoch 6.954), train_loss = 1.46013856, grad/param norm = 1.9350e-01, time/batch = 0.6860s	
3193/22950 (epoch 6.956), train_loss = 1.43332316, grad/param norm = 1.8145e-01, time/batch = 0.6842s	
3194/22950 (epoch 6.959), train_loss = 1.37980532, grad/param norm = 2.2506e-01, time/batch = 0.6862s	
3195/22950 (epoch 6.961), train_loss = 1.52044778, grad/param norm = 1.9698e-01, time/batch = 0.6839s	
3196/22950 (epoch 6.963), train_loss = 1.60430128, grad/param norm = 2.1622e-01, time/batch = 0.6903s	
3197/22950 (epoch 6.965), train_loss = 1.72183639, grad/param norm = 2.0900e-01, time/batch = 0.6843s	
3198/22950 (epoch 6.967), train_loss = 1.51350918, grad/param norm = 2.2339e-01, time/batch = 0.6837s	
3199/22950 (epoch 6.969), train_loss = 1.41251163, grad/param norm = 1.9360e-01, time/batch = 0.6890s	
3200/22950 (epoch 6.972), train_loss = 1.50240032, grad/param norm = 1.9494e-01, time/batch = 0.6928s	
3201/22950 (epoch 6.974), train_loss = 1.39185230, grad/param norm = 1.8978e-01, time/batch = 0.6746s	
3202/22950 (epoch 6.976), train_loss = 1.34404141, grad/param norm = 1.9971e-01, time/batch = 0.6732s	
3203/22950 (epoch 6.978), train_loss = 1.47959081, grad/param norm = 2.1986e-01, time/batch = 0.6767s	
3204/22950 (epoch 6.980), train_loss = 1.49115320, grad/param norm = 2.0311e-01, time/batch = 0.6812s	
3205/22950 (epoch 6.983), train_loss = 1.37014309, grad/param norm = 2.0472e-01, time/batch = 0.6804s	
3206/22950 (epoch 6.985), train_loss = 1.33612822, grad/param norm = 2.0614e-01, time/batch = 0.6813s	
3207/22950 (epoch 6.987), train_loss = 1.42788236, grad/param norm = 2.0278e-01, time/batch = 0.6925s	
3208/22950 (epoch 6.989), train_loss = 1.54221391, grad/param norm = 2.0467e-01, time/batch = 0.6777s	
3209/22950 (epoch 6.991), train_loss = 1.38306388, grad/param norm = 1.9930e-01, time/batch = 0.6836s	
3210/22950 (epoch 6.993), train_loss = 1.51125719, grad/param norm = 2.1256e-01, time/batch = 0.6796s	
3211/22950 (epoch 6.996), train_loss = 1.59311103, grad/param norm = 2.0638e-01, time/batch = 0.6866s	
3212/22950 (epoch 6.998), train_loss = 1.43755807, grad/param norm = 2.0031e-01, time/batch = 0.6796s	
3213/22950 (epoch 7.000), train_loss = 1.34256446, grad/param norm = 2.0116e-01, time/batch = 0.6784s	
3214/22950 (epoch 7.002), train_loss = 1.70728035, grad/param norm = 2.2132e-01, time/batch = 0.6750s	
3215/22950 (epoch 7.004), train_loss = 1.53693776, grad/param norm = 2.0143e-01, time/batch = 0.6731s	
3216/22950 (epoch 7.007), train_loss = 1.47704959, grad/param norm = 2.0029e-01, time/batch = 0.6726s	
3217/22950 (epoch 7.009), train_loss = 1.58725460, grad/param norm = 1.8364e-01, time/batch = 0.6778s	
3218/22950 (epoch 7.011), train_loss = 1.48792694, grad/param norm = 2.0318e-01, time/batch = 0.7052s	
3219/22950 (epoch 7.013), train_loss = 1.62064577, grad/param norm = 2.1255e-01, time/batch = 0.6985s	
3220/22950 (epoch 7.015), train_loss = 1.58174482, grad/param norm = 1.9842e-01, time/batch = 0.6850s	
3221/22950 (epoch 7.017), train_loss = 1.45525646, grad/param norm = 1.9835e-01, time/batch = 0.6856s	
3222/22950 (epoch 7.020), train_loss = 1.45013428, grad/param norm = 1.9721e-01, time/batch = 0.6837s	
3223/22950 (epoch 7.022), train_loss = 1.30350537, grad/param norm = 1.8034e-01, time/batch = 0.6798s	
3224/22950 (epoch 7.024), train_loss = 1.40920265, grad/param norm = 2.1478e-01, time/batch = 0.6749s	
3225/22950 (epoch 7.026), train_loss = 1.51004279, grad/param norm = 2.0279e-01, time/batch = 0.6803s	
3226/22950 (epoch 7.028), train_loss = 1.54832662, grad/param norm = 2.1732e-01, time/batch = 0.6771s	
3227/22950 (epoch 7.031), train_loss = 1.49205822, grad/param norm = 1.9394e-01, time/batch = 0.6745s	
3228/22950 (epoch 7.033), train_loss = 1.69280857, grad/param norm = 2.1070e-01, time/batch = 0.6784s	
3229/22950 (epoch 7.035), train_loss = 1.46797012, grad/param norm = 1.7581e-01, time/batch = 0.6778s	
3230/22950 (epoch 7.037), train_loss = 1.45164272, grad/param norm = 2.0471e-01, time/batch = 0.6746s	
3231/22950 (epoch 7.039), train_loss = 1.49428647, grad/param norm = 1.9900e-01, time/batch = 0.6778s	
3232/22950 (epoch 7.041), train_loss = 1.46857274, grad/param norm = 1.8400e-01, time/batch = 0.6803s	
3233/22950 (epoch 7.044), train_loss = 1.45967911, grad/param norm = 2.0322e-01, time/batch = 0.6749s	
3234/22950 (epoch 7.046), train_loss = 1.49908921, grad/param norm = 2.0987e-01, time/batch = 0.6807s	
3235/22950 (epoch 7.048), train_loss = 1.50332039, grad/param norm = 1.9642e-01, time/batch = 0.6728s	
3236/22950 (epoch 7.050), train_loss = 1.54447036, grad/param norm = 2.0810e-01, time/batch = 0.6744s	
3237/22950 (epoch 7.052), train_loss = 1.49103564, grad/param norm = 2.0490e-01, time/batch = 0.6747s	
3238/22950 (epoch 7.054), train_loss = 1.76190407, grad/param norm = 2.2238e-01, time/batch = 0.6744s	
3239/22950 (epoch 7.057), train_loss = 1.57416115, grad/param norm = 1.9756e-01, time/batch = 0.6717s	
3240/22950 (epoch 7.059), train_loss = 1.58090436, grad/param norm = 2.0417e-01, time/batch = 0.6724s	
3241/22950 (epoch 7.061), train_loss = 1.36272058, grad/param norm = 1.9299e-01, time/batch = 0.6740s	
3242/22950 (epoch 7.063), train_loss = 1.53818887, grad/param norm = 1.9940e-01, time/batch = 0.6726s	
3243/22950 (epoch 7.065), train_loss = 1.20328537, grad/param norm = 1.9885e-01, time/batch = 0.6713s	
3244/22950 (epoch 7.068), train_loss = 1.61160877, grad/param norm = 2.0468e-01, time/batch = 0.6704s	
3245/22950 (epoch 7.070), train_loss = 1.37469365, grad/param norm = 2.0332e-01, time/batch = 0.6689s	
3246/22950 (epoch 7.072), train_loss = 1.49912726, grad/param norm = 2.1565e-01, time/batch = 0.6744s	
3247/22950 (epoch 7.074), train_loss = 1.48139902, grad/param norm = 2.3097e-01, time/batch = 0.7008s	
3248/22950 (epoch 7.076), train_loss = 1.47515551, grad/param norm = 2.1602e-01, time/batch = 0.7112s	
3249/22950 (epoch 7.078), train_loss = 1.62401668, grad/param norm = 2.3039e-01, time/batch = 0.6935s	
3250/22950 (epoch 7.081), train_loss = 1.61192001, grad/param norm = 2.1792e-01, time/batch = 0.6816s	
3251/22950 (epoch 7.083), train_loss = 1.45711503, grad/param norm = 2.3251e-01, time/batch = 0.6820s	
3252/22950 (epoch 7.085), train_loss = 1.37203442, grad/param norm = 2.0743e-01, time/batch = 0.6877s	
3253/22950 (epoch 7.087), train_loss = 1.40271185, grad/param norm = 2.0135e-01, time/batch = 0.6918s	
3254/22950 (epoch 7.089), train_loss = 1.51059306, grad/param norm = 1.9850e-01, time/batch = 0.7056s	
3255/22950 (epoch 7.092), train_loss = 1.48539797, grad/param norm = 2.0574e-01, time/batch = 0.7084s	
3256/22950 (epoch 7.094), train_loss = 1.43310438, grad/param norm = 2.0169e-01, time/batch = 0.6863s	
3257/22950 (epoch 7.096), train_loss = 1.63180035, grad/param norm = 2.0891e-01, time/batch = 0.6892s	
3258/22950 (epoch 7.098), train_loss = 1.51601966, grad/param norm = 2.0799e-01, time/batch = 0.6882s	
3259/22950 (epoch 7.100), train_loss = 1.41792695, grad/param norm = 2.0172e-01, time/batch = 0.6886s	
3260/22950 (epoch 7.102), train_loss = 1.49388787, grad/param norm = 1.8963e-01, time/batch = 0.6862s	
3261/22950 (epoch 7.105), train_loss = 1.34111115, grad/param norm = 1.8575e-01, time/batch = 0.6909s	
3262/22950 (epoch 7.107), train_loss = 1.42455266, grad/param norm = 2.0182e-01, time/batch = 0.6893s	
3263/22950 (epoch 7.109), train_loss = 1.44864021, grad/param norm = 2.0294e-01, time/batch = 0.6899s	
3264/22950 (epoch 7.111), train_loss = 1.33088427, grad/param norm = 1.8270e-01, time/batch = 0.6905s	
3265/22950 (epoch 7.113), train_loss = 1.53360688, grad/param norm = 1.9427e-01, time/batch = 0.6895s	
3266/22950 (epoch 7.115), train_loss = 1.57326280, grad/param norm = 2.3890e-01, time/batch = 0.6889s	
3267/22950 (epoch 7.118), train_loss = 1.63501548, grad/param norm = 2.0234e-01, time/batch = 0.6958s	
3268/22950 (epoch 7.120), train_loss = 1.40999978, grad/param norm = 1.9594e-01, time/batch = 0.6962s	
3269/22950 (epoch 7.122), train_loss = 1.61584845, grad/param norm = 2.0620e-01, time/batch = 0.6969s	
3270/22950 (epoch 7.124), train_loss = 1.26765118, grad/param norm = 1.7202e-01, time/batch = 0.6978s	
3271/22950 (epoch 7.126), train_loss = 1.44476724, grad/param norm = 2.0684e-01, time/batch = 0.6958s	
3272/22950 (epoch 7.129), train_loss = 1.29492715, grad/param norm = 1.9012e-01, time/batch = 0.7089s	
3273/22950 (epoch 7.131), train_loss = 1.47303532, grad/param norm = 2.2196e-01, time/batch = 0.6936s	
3274/22950 (epoch 7.133), train_loss = 1.59073498, grad/param norm = 2.0981e-01, time/batch = 0.6887s	
3275/22950 (epoch 7.135), train_loss = 1.45334462, grad/param norm = 2.0963e-01, time/batch = 0.6934s	
3276/22950 (epoch 7.137), train_loss = 1.71075255, grad/param norm = 2.2329e-01, time/batch = 0.6987s	
3277/22950 (epoch 7.139), train_loss = 1.43972998, grad/param norm = 2.1561e-01, time/batch = 0.6891s	
3278/22950 (epoch 7.142), train_loss = 1.37239316, grad/param norm = 1.9827e-01, time/batch = 0.6901s	
3279/22950 (epoch 7.144), train_loss = 1.36449296, grad/param norm = 1.9290e-01, time/batch = 0.6881s	
3280/22950 (epoch 7.146), train_loss = 1.50699639, grad/param norm = 2.0608e-01, time/batch = 0.6890s	
3281/22950 (epoch 7.148), train_loss = 1.41087841, grad/param norm = 1.9001e-01, time/batch = 0.6898s	
3282/22950 (epoch 7.150), train_loss = 1.44759929, grad/param norm = 1.9203e-01, time/batch = 0.6882s	
3283/22950 (epoch 7.153), train_loss = 1.45346178, grad/param norm = 1.9659e-01, time/batch = 0.6848s	
3284/22950 (epoch 7.155), train_loss = 1.40466819, grad/param norm = 1.9980e-01, time/batch = 0.6861s	
3285/22950 (epoch 7.157), train_loss = 1.41249447, grad/param norm = 2.0633e-01, time/batch = 0.6837s	
3286/22950 (epoch 7.159), train_loss = 1.34067249, grad/param norm = 1.8869e-01, time/batch = 0.6845s	
3287/22950 (epoch 7.161), train_loss = 1.46453083, grad/param norm = 1.8676e-01, time/batch = 0.6837s	
3288/22950 (epoch 7.163), train_loss = 1.40430296, grad/param norm = 1.8485e-01, time/batch = 0.6845s	
3289/22950 (epoch 7.166), train_loss = 1.62244499, grad/param norm = 2.3588e-01, time/batch = 0.6860s	
3290/22950 (epoch 7.168), train_loss = 1.64524818, grad/param norm = 2.4280e-01, time/batch = 0.6905s	
3291/22950 (epoch 7.170), train_loss = 1.54121076, grad/param norm = 2.0646e-01, time/batch = 0.6901s	
3292/22950 (epoch 7.172), train_loss = 1.46430686, grad/param norm = 2.0246e-01, time/batch = 0.7013s	
3293/22950 (epoch 7.174), train_loss = 1.56678951, grad/param norm = 2.2124e-01, time/batch = 0.6874s	
3294/22950 (epoch 7.176), train_loss = 1.61554157, grad/param norm = 1.9882e-01, time/batch = 0.6815s	
3295/22950 (epoch 7.179), train_loss = 1.53912587, grad/param norm = 2.2680e-01, time/batch = 0.6836s	
3296/22950 (epoch 7.181), train_loss = 1.67168352, grad/param norm = 2.0927e-01, time/batch = 0.6868s	
3297/22950 (epoch 7.183), train_loss = 1.57160372, grad/param norm = 2.2029e-01, time/batch = 0.6877s	
3298/22950 (epoch 7.185), train_loss = 1.53852141, grad/param norm = 1.9789e-01, time/batch = 0.6905s	
3299/22950 (epoch 7.187), train_loss = 1.31880318, grad/param norm = 2.0177e-01, time/batch = 0.6847s	
3300/22950 (epoch 7.190), train_loss = 1.45711467, grad/param norm = 2.0961e-01, time/batch = 0.6859s	
3301/22950 (epoch 7.192), train_loss = 1.37390398, grad/param norm = 1.8606e-01, time/batch = 0.6877s	
3302/22950 (epoch 7.194), train_loss = 1.47072549, grad/param norm = 2.2332e-01, time/batch = 0.6856s	
3303/22950 (epoch 7.196), train_loss = 1.28259426, grad/param norm = 1.9809e-01, time/batch = 0.6859s	
3304/22950 (epoch 7.198), train_loss = 1.59974216, grad/param norm = 2.1440e-01, time/batch = 0.6898s	
3305/22950 (epoch 7.200), train_loss = 1.32839533, grad/param norm = 1.8703e-01, time/batch = 0.6921s	
3306/22950 (epoch 7.203), train_loss = 1.27523337, grad/param norm = 1.8094e-01, time/batch = 0.6929s	
3307/22950 (epoch 7.205), train_loss = 1.38925240, grad/param norm = 2.1832e-01, time/batch = 0.6978s	
3308/22950 (epoch 7.207), train_loss = 1.44045996, grad/param norm = 2.0415e-01, time/batch = 0.7014s	
3309/22950 (epoch 7.209), train_loss = 1.65483240, grad/param norm = 2.1122e-01, time/batch = 0.6913s	
3310/22950 (epoch 7.211), train_loss = 1.35103411, grad/param norm = 2.2674e-01, time/batch = 0.6895s	
3311/22950 (epoch 7.214), train_loss = 1.43789464, grad/param norm = 2.0352e-01, time/batch = 0.6916s	
3312/22950 (epoch 7.216), train_loss = 1.53695870, grad/param norm = 1.9236e-01, time/batch = 0.6888s	
3313/22950 (epoch 7.218), train_loss = 1.48634689, grad/param norm = 1.9644e-01, time/batch = 0.6894s	
3314/22950 (epoch 7.220), train_loss = 1.62749313, grad/param norm = 2.1745e-01, time/batch = 0.6857s	
3315/22950 (epoch 7.222), train_loss = 1.60649496, grad/param norm = 2.1654e-01, time/batch = 0.6860s	
3316/22950 (epoch 7.224), train_loss = 1.42773578, grad/param norm = 2.0381e-01, time/batch = 0.6884s	
3317/22950 (epoch 7.227), train_loss = 1.47141830, grad/param norm = 2.1149e-01, time/batch = 0.6877s	
3318/22950 (epoch 7.229), train_loss = 1.48835133, grad/param norm = 1.9970e-01, time/batch = 0.6879s	
3319/22950 (epoch 7.231), train_loss = 1.33773848, grad/param norm = 1.9489e-01, time/batch = 0.6888s	
3320/22950 (epoch 7.233), train_loss = 1.45247821, grad/param norm = 1.9535e-01, time/batch = 0.6865s	
3321/22950 (epoch 7.235), train_loss = 1.58916546, grad/param norm = 2.0752e-01, time/batch = 0.6897s	
3322/22950 (epoch 7.237), train_loss = 1.34713211, grad/param norm = 1.9390e-01, time/batch = 0.6852s	
3323/22950 (epoch 7.240), train_loss = 1.44427133, grad/param norm = 2.0882e-01, time/batch = 0.6861s	
3324/22950 (epoch 7.242), train_loss = 1.57155930, grad/param norm = 2.4323e-01, time/batch = 0.6857s	
3325/22950 (epoch 7.244), train_loss = 1.67093323, grad/param norm = 2.2911e-01, time/batch = 0.6867s	
3326/22950 (epoch 7.246), train_loss = 1.61507339, grad/param norm = 2.2504e-01, time/batch = 0.6867s	
3327/22950 (epoch 7.248), train_loss = 1.53120961, grad/param norm = 2.2208e-01, time/batch = 0.6845s	
3328/22950 (epoch 7.251), train_loss = 1.46520114, grad/param norm = 2.0218e-01, time/batch = 0.6852s	
3329/22950 (epoch 7.253), train_loss = 1.45114869, grad/param norm = 2.0080e-01, time/batch = 0.6843s	
3330/22950 (epoch 7.255), train_loss = 1.44702231, grad/param norm = 2.0899e-01, time/batch = 0.6865s	
3331/22950 (epoch 7.257), train_loss = 1.60630791, grad/param norm = 2.0561e-01, time/batch = 0.7061s	
3332/22950 (epoch 7.259), train_loss = 1.32135987, grad/param norm = 1.9433e-01, time/batch = 0.7141s	
3333/22950 (epoch 7.261), train_loss = 1.49441639, grad/param norm = 2.0808e-01, time/batch = 0.7256s	
3334/22950 (epoch 7.264), train_loss = 1.35641853, grad/param norm = 1.7942e-01, time/batch = 0.7224s	
3335/22950 (epoch 7.266), train_loss = 1.56353408, grad/param norm = 1.9710e-01, time/batch = 0.7426s	
3336/22950 (epoch 7.268), train_loss = 1.52874302, grad/param norm = 1.9145e-01, time/batch = 0.7164s	
3337/22950 (epoch 7.270), train_loss = 1.54412942, grad/param norm = 2.0414e-01, time/batch = 0.7123s	
3338/22950 (epoch 7.272), train_loss = 1.64898268, grad/param norm = 2.0984e-01, time/batch = 0.6916s	
3339/22950 (epoch 7.275), train_loss = 1.41235444, grad/param norm = 2.2346e-01, time/batch = 0.6959s	
3340/22950 (epoch 7.277), train_loss = 1.33473868, grad/param norm = 1.9817e-01, time/batch = 0.6912s	
3341/22950 (epoch 7.279), train_loss = 1.56013768, grad/param norm = 2.1996e-01, time/batch = 0.6891s	
3342/22950 (epoch 7.281), train_loss = 1.39749186, grad/param norm = 2.2411e-01, time/batch = 0.6861s	
3343/22950 (epoch 7.283), train_loss = 1.29045887, grad/param norm = 1.9053e-01, time/batch = 0.6847s	
3344/22950 (epoch 7.285), train_loss = 1.46373681, grad/param norm = 2.0307e-01, time/batch = 0.6858s	
3345/22950 (epoch 7.288), train_loss = 1.45295620, grad/param norm = 1.9604e-01, time/batch = 0.6848s	
3346/22950 (epoch 7.290), train_loss = 1.39934390, grad/param norm = 2.0144e-01, time/batch = 0.6855s	
3347/22950 (epoch 7.292), train_loss = 1.51736874, grad/param norm = 1.9758e-01, time/batch = 0.6890s	
3348/22950 (epoch 7.294), train_loss = 1.51457997, grad/param norm = 2.0722e-01, time/batch = 0.6901s	
3349/22950 (epoch 7.296), train_loss = 1.24560977, grad/param norm = 1.8250e-01, time/batch = 0.6935s	
3350/22950 (epoch 7.298), train_loss = 1.43389911, grad/param norm = 1.7835e-01, time/batch = 0.6872s	
3351/22950 (epoch 7.301), train_loss = 1.50622729, grad/param norm = 2.0197e-01, time/batch = 0.6880s	
3352/22950 (epoch 7.303), train_loss = 1.55211990, grad/param norm = 2.0474e-01, time/batch = 0.6884s	
3353/22950 (epoch 7.305), train_loss = 1.58115817, grad/param norm = 2.0933e-01, time/batch = 0.6884s	
3354/22950 (epoch 7.307), train_loss = 1.59467445, grad/param norm = 2.0648e-01, time/batch = 0.6895s	
3355/22950 (epoch 7.309), train_loss = 1.46716842, grad/param norm = 1.7815e-01, time/batch = 0.6874s	
3356/22950 (epoch 7.312), train_loss = 1.51869837, grad/param norm = 2.0426e-01, time/batch = 0.6866s	
3357/22950 (epoch 7.314), train_loss = 1.38190562, grad/param norm = 1.9760e-01, time/batch = 0.6946s	
3358/22950 (epoch 7.316), train_loss = 1.49149867, grad/param norm = 1.9260e-01, time/batch = 0.6843s	
3359/22950 (epoch 7.318), train_loss = 1.27991654, grad/param norm = 1.8890e-01, time/batch = 0.6883s	
3360/22950 (epoch 7.320), train_loss = 1.44571556, grad/param norm = 1.7966e-01, time/batch = 0.6890s	
3361/22950 (epoch 7.322), train_loss = 1.45378494, grad/param norm = 2.0555e-01, time/batch = 0.6882s	
3362/22950 (epoch 7.325), train_loss = 1.16798971, grad/param norm = 1.8315e-01, time/batch = 0.6995s	
3363/22950 (epoch 7.327), train_loss = 1.22692840, grad/param norm = 1.7607e-01, time/batch = 0.6972s	
3364/22950 (epoch 7.329), train_loss = 1.34583350, grad/param norm = 1.9006e-01, time/batch = 0.6886s	
3365/22950 (epoch 7.331), train_loss = 1.31668577, grad/param norm = 1.8619e-01, time/batch = 0.6878s	
3366/22950 (epoch 7.333), train_loss = 1.41762009, grad/param norm = 2.0124e-01, time/batch = 0.6863s	
3367/22950 (epoch 7.336), train_loss = 1.45731965, grad/param norm = 2.3843e-01, time/batch = 0.7052s	
3368/22950 (epoch 7.338), train_loss = 1.41101380, grad/param norm = 2.2009e-01, time/batch = 0.7068s	
3369/22950 (epoch 7.340), train_loss = 1.41489044, grad/param norm = 2.1077e-01, time/batch = 0.6878s	
3370/22950 (epoch 7.342), train_loss = 1.54233647, grad/param norm = 1.9809e-01, time/batch = 0.6859s	
3371/22950 (epoch 7.344), train_loss = 1.47793069, grad/param norm = 2.0795e-01, time/batch = 0.6959s	
3372/22950 (epoch 7.346), train_loss = 1.68681676, grad/param norm = 2.1867e-01, time/batch = 0.6926s	
3373/22950 (epoch 7.349), train_loss = 1.51398185, grad/param norm = 2.0783e-01, time/batch = 0.6892s	
3374/22950 (epoch 7.351), train_loss = 1.50417138, grad/param norm = 2.2090e-01, time/batch = 0.6867s	
3375/22950 (epoch 7.353), train_loss = 1.60527107, grad/param norm = 2.3598e-01, time/batch = 0.6892s	
3376/22950 (epoch 7.355), train_loss = 1.62573744, grad/param norm = 2.1945e-01, time/batch = 0.6889s	
3377/22950 (epoch 7.357), train_loss = 1.47638267, grad/param norm = 1.8942e-01, time/batch = 0.6889s	
3378/22950 (epoch 7.359), train_loss = 1.52595312, grad/param norm = 1.9485e-01, time/batch = 0.7135s	
3379/22950 (epoch 7.362), train_loss = 1.42124119, grad/param norm = 1.9199e-01, time/batch = 0.6852s	
3380/22950 (epoch 7.364), train_loss = 1.47917267, grad/param norm = 1.9241e-01, time/batch = 0.6852s	
3381/22950 (epoch 7.366), train_loss = 1.28003205, grad/param norm = 1.7874e-01, time/batch = 0.7070s	
3382/22950 (epoch 7.368), train_loss = 1.49522786, grad/param norm = 2.3493e-01, time/batch = 0.6942s	
3383/22950 (epoch 7.370), train_loss = 1.43514164, grad/param norm = 2.1199e-01, time/batch = 0.6947s	
3384/22950 (epoch 7.373), train_loss = 1.30590072, grad/param norm = 1.8771e-01, time/batch = 0.6911s	
3385/22950 (epoch 7.375), train_loss = 1.61230652, grad/param norm = 2.2205e-01, time/batch = 0.6891s	
3386/22950 (epoch 7.377), train_loss = 1.43181242, grad/param norm = 2.0466e-01, time/batch = 0.6866s	
3387/22950 (epoch 7.379), train_loss = 1.57832461, grad/param norm = 1.9449e-01, time/batch = 0.7055s	
3388/22950 (epoch 7.381), train_loss = 1.30684918, grad/param norm = 1.9505e-01, time/batch = 0.7204s	
3389/22950 (epoch 7.383), train_loss = 1.53753447, grad/param norm = 2.2944e-01, time/batch = 0.6917s	
3390/22950 (epoch 7.386), train_loss = 1.48516213, grad/param norm = 2.2475e-01, time/batch = 0.6892s	
3391/22950 (epoch 7.388), train_loss = 1.50398792, grad/param norm = 2.2762e-01, time/batch = 0.6924s	
3392/22950 (epoch 7.390), train_loss = 1.35775250, grad/param norm = 1.9943e-01, time/batch = 0.6965s	
3393/22950 (epoch 7.392), train_loss = 1.32584985, grad/param norm = 1.8616e-01, time/batch = 0.6827s	
3394/22950 (epoch 7.394), train_loss = 1.35771529, grad/param norm = 1.7238e-01, time/batch = 0.6846s	
3395/22950 (epoch 7.397), train_loss = 1.56570883, grad/param norm = 2.1964e-01, time/batch = 0.6887s	
3396/22950 (epoch 7.399), train_loss = 1.56731958, grad/param norm = 1.9915e-01, time/batch = 0.6837s	
3397/22950 (epoch 7.401), train_loss = 1.76408904, grad/param norm = 2.1841e-01, time/batch = 0.7046s	
3398/22950 (epoch 7.403), train_loss = 1.41762962, grad/param norm = 2.0495e-01, time/batch = 0.7201s	
3399/22950 (epoch 7.405), train_loss = 1.58053010, grad/param norm = 2.2657e-01, time/batch = 0.6858s	
3400/22950 (epoch 7.407), train_loss = 1.63803027, grad/param norm = 2.1828e-01, time/batch = 0.6833s	
3401/22950 (epoch 7.410), train_loss = 1.31644132, grad/param norm = 1.9903e-01, time/batch = 0.6883s	
3402/22950 (epoch 7.412), train_loss = 1.49277781, grad/param norm = 2.1015e-01, time/batch = 0.6832s	
3403/22950 (epoch 7.414), train_loss = 1.58353771, grad/param norm = 2.1563e-01, time/batch = 0.6844s	
3404/22950 (epoch 7.416), train_loss = 1.55739276, grad/param norm = 2.0232e-01, time/batch = 0.6883s	
3405/22950 (epoch 7.418), train_loss = 1.57562365, grad/param norm = 2.0802e-01, time/batch = 0.6896s	
3406/22950 (epoch 7.420), train_loss = 1.55185174, grad/param norm = 2.0414e-01, time/batch = 0.6886s	
3407/22950 (epoch 7.423), train_loss = 1.33690608, grad/param norm = 1.6851e-01, time/batch = 0.7035s	
3408/22950 (epoch 7.425), train_loss = 1.47571938, grad/param norm = 1.9474e-01, time/batch = 0.7240s	
3409/22950 (epoch 7.427), train_loss = 1.40242166, grad/param norm = 1.8403e-01, time/batch = 0.6910s	
3410/22950 (epoch 7.429), train_loss = 1.38992981, grad/param norm = 1.9681e-01, time/batch = 0.6890s	
3411/22950 (epoch 7.431), train_loss = 1.52720934, grad/param norm = 2.1144e-01, time/batch = 0.6877s	
3412/22950 (epoch 7.434), train_loss = 1.45382752, grad/param norm = 2.1168e-01, time/batch = 0.6868s	
3413/22950 (epoch 7.436), train_loss = 1.73793911, grad/param norm = 2.3361e-01, time/batch = 0.6887s	
3414/22950 (epoch 7.438), train_loss = 1.47631045, grad/param norm = 2.1469e-01, time/batch = 0.6850s	
3415/22950 (epoch 7.440), train_loss = 1.50875753, grad/param norm = 2.1243e-01, time/batch = 0.6885s	
3416/22950 (epoch 7.442), train_loss = 1.64451784, grad/param norm = 2.2041e-01, time/batch = 0.6850s	
3417/22950 (epoch 7.444), train_loss = 1.60933623, grad/param norm = 2.1659e-01, time/batch = 0.6976s	
3418/22950 (epoch 7.447), train_loss = 1.70589968, grad/param norm = 2.2453e-01, time/batch = 0.7215s	
3419/22950 (epoch 7.449), train_loss = 1.33037702, grad/param norm = 1.7485e-01, time/batch = 0.7053s	
3420/22950 (epoch 7.451), train_loss = 1.52370562, grad/param norm = 2.0204e-01, time/batch = 0.7192s	
3421/22950 (epoch 7.453), train_loss = 1.53449743, grad/param norm = 1.9053e-01, time/batch = 0.7340s	
3422/22950 (epoch 7.455), train_loss = 1.37994539, grad/param norm = 1.9220e-01, time/batch = 0.7272s	
3423/22950 (epoch 7.458), train_loss = 1.60493378, grad/param norm = 2.0234e-01, time/batch = 0.7109s	
3424/22950 (epoch 7.460), train_loss = 1.51669299, grad/param norm = 2.0207e-01, time/batch = 0.7088s	
3425/22950 (epoch 7.462), train_loss = 1.46691992, grad/param norm = 2.0994e-01, time/batch = 0.6918s	
3426/22950 (epoch 7.464), train_loss = 1.44399265, grad/param norm = 2.1342e-01, time/batch = 0.6934s	
3427/22950 (epoch 7.466), train_loss = 1.48773686, grad/param norm = 2.1527e-01, time/batch = 0.7101s	
3428/22950 (epoch 7.468), train_loss = 1.58206678, grad/param norm = 1.9254e-01, time/batch = 0.7157s	
3429/22950 (epoch 7.471), train_loss = 1.47484918, grad/param norm = 2.0544e-01, time/batch = 0.6844s	
3430/22950 (epoch 7.473), train_loss = 1.59694144, grad/param norm = 2.1670e-01, time/batch = 0.6837s	
3431/22950 (epoch 7.475), train_loss = 1.73748437, grad/param norm = 2.3866e-01, time/batch = 0.6863s	
3432/22950 (epoch 7.477), train_loss = 1.52007523, grad/param norm = 2.0513e-01, time/batch = 0.6868s	
3433/22950 (epoch 7.479), train_loss = 1.46256545, grad/param norm = 2.1762e-01, time/batch = 0.7203s	
3434/22950 (epoch 7.481), train_loss = 1.71215349, grad/param norm = 2.4230e-01, time/batch = 0.7059s	
3435/22950 (epoch 7.484), train_loss = 1.57620385, grad/param norm = 2.1283e-01, time/batch = 0.7003s	
3436/22950 (epoch 7.486), train_loss = 1.31929132, grad/param norm = 1.9899e-01, time/batch = 0.6865s	
3437/22950 (epoch 7.488), train_loss = 1.49306137, grad/param norm = 2.2371e-01, time/batch = 0.7089s	
3438/22950 (epoch 7.490), train_loss = 1.34220432, grad/param norm = 2.0736e-01, time/batch = 0.7206s	
3439/22950 (epoch 7.492), train_loss = 1.50404757, grad/param norm = 2.0468e-01, time/batch = 0.6958s	
3440/22950 (epoch 7.495), train_loss = 1.48154326, grad/param norm = 1.9423e-01, time/batch = 0.7037s	
3441/22950 (epoch 7.497), train_loss = 1.55869505, grad/param norm = 1.9107e-01, time/batch = 0.6929s	
3442/22950 (epoch 7.499), train_loss = 1.58039021, grad/param norm = 2.0950e-01, time/batch = 0.6894s	
3443/22950 (epoch 7.501), train_loss = 1.57878006, grad/param norm = 1.9683e-01, time/batch = 0.6880s	
3444/22950 (epoch 7.503), train_loss = 1.59303521, grad/param norm = 2.0539e-01, time/batch = 0.6881s	
3445/22950 (epoch 7.505), train_loss = 1.36781452, grad/param norm = 1.7976e-01, time/batch = 0.6874s	
3446/22950 (epoch 7.508), train_loss = 1.52791652, grad/param norm = 1.9385e-01, time/batch = 0.6883s	
3447/22950 (epoch 7.510), train_loss = 1.47762180, grad/param norm = 2.1653e-01, time/batch = 0.7133s	
3448/22950 (epoch 7.512), train_loss = 1.40473718, grad/param norm = 1.8842e-01, time/batch = 0.7202s	
3449/22950 (epoch 7.514), train_loss = 1.33448818, grad/param norm = 1.9637e-01, time/batch = 0.6857s	
3450/22950 (epoch 7.516), train_loss = 1.39174188, grad/param norm = 2.1129e-01, time/batch = 0.6823s	
3451/22950 (epoch 7.519), train_loss = 1.43938331, grad/param norm = 2.0095e-01, time/batch = 0.6861s	
3452/22950 (epoch 7.521), train_loss = 1.45517410, grad/param norm = 1.8790e-01, time/batch = 0.6912s	
3453/22950 (epoch 7.523), train_loss = 1.24170246, grad/param norm = 2.0599e-01, time/batch = 0.6846s	
3454/22950 (epoch 7.525), train_loss = 1.42450477, grad/param norm = 1.9858e-01, time/batch = 0.6851s	
3455/22950 (epoch 7.527), train_loss = 1.23305229, grad/param norm = 1.8702e-01, time/batch = 0.6904s	
3456/22950 (epoch 7.529), train_loss = 1.53201186, grad/param norm = 2.0212e-01, time/batch = 0.6865s	
3457/22950 (epoch 7.532), train_loss = 1.44771728, grad/param norm = 2.0413e-01, time/batch = 0.6858s	
3458/22950 (epoch 7.534), train_loss = 1.58917011, grad/param norm = 2.1791e-01, time/batch = 0.6831s	
3459/22950 (epoch 7.536), train_loss = 1.53093355, grad/param norm = 2.1402e-01, time/batch = 0.6859s	
3460/22950 (epoch 7.538), train_loss = 1.44546269, grad/param norm = 2.1894e-01, time/batch = 0.6907s	
3461/22950 (epoch 7.540), train_loss = 1.46090389, grad/param norm = 1.8836e-01, time/batch = 0.7029s	
3462/22950 (epoch 7.542), train_loss = 1.66893819, grad/param norm = 2.1381e-01, time/batch = 0.7033s	
3463/22950 (epoch 7.545), train_loss = 1.43562493, grad/param norm = 2.3453e-01, time/batch = 0.7083s	
3464/22950 (epoch 7.547), train_loss = 1.44618960, grad/param norm = 1.9936e-01, time/batch = 0.7136s	
3465/22950 (epoch 7.549), train_loss = 1.45592499, grad/param norm = 2.0447e-01, time/batch = 0.6951s	
3466/22950 (epoch 7.551), train_loss = 1.50855224, grad/param norm = 2.2786e-01, time/batch = 0.7019s	
3467/22950 (epoch 7.553), train_loss = 1.45293381, grad/param norm = 2.1586e-01, time/batch = 0.6979s	
3468/22950 (epoch 7.556), train_loss = 1.56170485, grad/param norm = 1.9192e-01, time/batch = 0.6969s	
3469/22950 (epoch 7.558), train_loss = 1.43322366, grad/param norm = 2.0247e-01, time/batch = 0.7003s	
3470/22950 (epoch 7.560), train_loss = 1.51878690, grad/param norm = 1.8503e-01, time/batch = 0.7094s	
3471/22950 (epoch 7.562), train_loss = 1.32794867, grad/param norm = 1.8752e-01, time/batch = 0.6993s	
3472/22950 (epoch 7.564), train_loss = 1.69737741, grad/param norm = 2.4198e-01, time/batch = 0.6966s	
3473/22950 (epoch 7.566), train_loss = 1.48500274, grad/param norm = 2.0484e-01, time/batch = 0.7033s	
3474/22950 (epoch 7.569), train_loss = 1.65983491, grad/param norm = 2.0480e-01, time/batch = 0.7050s	
3475/22950 (epoch 7.571), train_loss = 1.33068405, grad/param norm = 1.9814e-01, time/batch = 0.7036s	
3476/22950 (epoch 7.573), train_loss = 1.46582872, grad/param norm = 2.0278e-01, time/batch = 0.7232s	
3477/22950 (epoch 7.575), train_loss = 1.75086235, grad/param norm = 2.1810e-01, time/batch = 0.7186s	
3478/22950 (epoch 7.577), train_loss = 1.47971219, grad/param norm = 2.1254e-01, time/batch = 0.7182s	
3479/22950 (epoch 7.580), train_loss = 1.53584843, grad/param norm = 2.1323e-01, time/batch = 0.7102s	
3480/22950 (epoch 7.582), train_loss = 1.66777211, grad/param norm = 1.9856e-01, time/batch = 0.6944s	
3481/22950 (epoch 7.584), train_loss = 1.28024945, grad/param norm = 1.8249e-01, time/batch = 0.6923s	
3482/22950 (epoch 7.586), train_loss = 1.39784513, grad/param norm = 2.0498e-01, time/batch = 0.6895s	
3483/22950 (epoch 7.588), train_loss = 1.61856349, grad/param norm = 2.0156e-01, time/batch = 0.6889s	
3484/22950 (epoch 7.590), train_loss = 1.45470027, grad/param norm = 2.0379e-01, time/batch = 0.6875s	
3485/22950 (epoch 7.593), train_loss = 1.29676956, grad/param norm = 1.9078e-01, time/batch = 0.6868s	
3486/22950 (epoch 7.595), train_loss = 1.35452025, grad/param norm = 1.9856e-01, time/batch = 0.6850s	
3487/22950 (epoch 7.597), train_loss = 1.55804609, grad/param norm = 2.2955e-01, time/batch = 0.6858s	
3488/22950 (epoch 7.599), train_loss = 1.52170555, grad/param norm = 2.3312e-01, time/batch = 0.6849s	
3489/22950 (epoch 7.601), train_loss = 1.47202010, grad/param norm = 2.2171e-01, time/batch = 0.6887s	
3490/22950 (epoch 7.603), train_loss = 1.61303455, grad/param norm = 2.0566e-01, time/batch = 0.6927s	
3491/22950 (epoch 7.606), train_loss = 1.42400342, grad/param norm = 2.0823e-01, time/batch = 0.7069s	
3492/22950 (epoch 7.608), train_loss = 1.45729139, grad/param norm = 2.0777e-01, time/batch = 0.7085s	
3493/22950 (epoch 7.610), train_loss = 1.43932856, grad/param norm = 1.9525e-01, time/batch = 0.7063s	
3494/22950 (epoch 7.612), train_loss = 1.49194471, grad/param norm = 1.9488e-01, time/batch = 0.7089s	
3495/22950 (epoch 7.614), train_loss = 1.61541138, grad/param norm = 2.2805e-01, time/batch = 0.7094s	
3496/22950 (epoch 7.617), train_loss = 1.46568566, grad/param norm = 2.1242e-01, time/batch = 0.7063s	
3497/22950 (epoch 7.619), train_loss = 1.34164812, grad/param norm = 1.8674e-01, time/batch = 0.6964s	
3498/22950 (epoch 7.621), train_loss = 1.56516227, grad/param norm = 1.9690e-01, time/batch = 0.6901s	
3499/22950 (epoch 7.623), train_loss = 1.50029742, grad/param norm = 1.7965e-01, time/batch = 0.6890s	
3500/22950 (epoch 7.625), train_loss = 1.43914725, grad/param norm = 1.8041e-01, time/batch = 0.6899s	
3501/22950 (epoch 7.627), train_loss = 1.50842682, grad/param norm = 2.2020e-01, time/batch = 0.6904s	
3502/22950 (epoch 7.630), train_loss = 1.28991736, grad/param norm = 1.7928e-01, time/batch = 0.6991s	
3503/22950 (epoch 7.632), train_loss = 1.52506727, grad/param norm = 2.1664e-01, time/batch = 0.6878s	
3504/22950 (epoch 7.634), train_loss = 1.42211326, grad/param norm = 1.9511e-01, time/batch = 0.6926s	
3505/22950 (epoch 7.636), train_loss = 1.45540091, grad/param norm = 1.8242e-01, time/batch = 0.7154s	
3506/22950 (epoch 7.638), train_loss = 1.37387418, grad/param norm = 2.0576e-01, time/batch = 0.7195s	
3507/22950 (epoch 7.641), train_loss = 1.39645870, grad/param norm = 1.9296e-01, time/batch = 0.7148s	
3508/22950 (epoch 7.643), train_loss = 1.52192121, grad/param norm = 2.3556e-01, time/batch = 0.6943s	
3509/22950 (epoch 7.645), train_loss = 1.39830065, grad/param norm = 2.3149e-01, time/batch = 0.6943s	
3510/22950 (epoch 7.647), train_loss = 1.46702857, grad/param norm = 1.9853e-01, time/batch = 0.6938s	
3511/22950 (epoch 7.649), train_loss = 1.44632496, grad/param norm = 1.9202e-01, time/batch = 0.6957s	
3512/22950 (epoch 7.651), train_loss = 1.56592571, grad/param norm = 2.1139e-01, time/batch = 0.6916s	
3513/22950 (epoch 7.654), train_loss = 1.26918959, grad/param norm = 1.9173e-01, time/batch = 0.6915s	
3514/22950 (epoch 7.656), train_loss = 1.58692302, grad/param norm = 2.1082e-01, time/batch = 0.6897s	
3515/22950 (epoch 7.658), train_loss = 1.34491388, grad/param norm = 1.8730e-01, time/batch = 0.6925s	
3516/22950 (epoch 7.660), train_loss = 1.29270639, grad/param norm = 1.8500e-01, time/batch = 0.6893s	
3517/22950 (epoch 7.662), train_loss = 1.30616396, grad/param norm = 1.9397e-01, time/batch = 0.6914s	
3518/22950 (epoch 7.664), train_loss = 1.52661749, grad/param norm = 1.9514e-01, time/batch = 0.6868s	
3519/22950 (epoch 7.667), train_loss = 1.51457670, grad/param norm = 2.1243e-01, time/batch = 0.6894s	
3520/22950 (epoch 7.669), train_loss = 1.39492659, grad/param norm = 2.0386e-01, time/batch = 0.7066s	
3521/22950 (epoch 7.671), train_loss = 1.51779532, grad/param norm = 2.0119e-01, time/batch = 0.6945s	
3522/22950 (epoch 7.673), train_loss = 1.47498110, grad/param norm = 1.9296e-01, time/batch = 0.6835s	
3523/22950 (epoch 7.675), train_loss = 1.44689331, grad/param norm = 1.9340e-01, time/batch = 0.6838s	
3524/22950 (epoch 7.678), train_loss = 1.47714993, grad/param norm = 2.0785e-01, time/batch = 0.6871s	
3525/22950 (epoch 7.680), train_loss = 1.49518437, grad/param norm = 1.9457e-01, time/batch = 0.6854s	
3526/22950 (epoch 7.682), train_loss = 1.56487656, grad/param norm = 1.9351e-01, time/batch = 0.6850s	
3527/22950 (epoch 7.684), train_loss = 1.57628560, grad/param norm = 2.0196e-01, time/batch = 0.6854s	
3528/22950 (epoch 7.686), train_loss = 1.52419415, grad/param norm = 1.9882e-01, time/batch = 0.6841s	
3529/22950 (epoch 7.688), train_loss = 1.46295081, grad/param norm = 2.0122e-01, time/batch = 0.6849s	
3530/22950 (epoch 7.691), train_loss = 1.41509053, grad/param norm = 1.9556e-01, time/batch = 0.6816s	
3531/22950 (epoch 7.693), train_loss = 1.38036813, grad/param norm = 1.9601e-01, time/batch = 0.6847s	
3532/22950 (epoch 7.695), train_loss = 1.64521155, grad/param norm = 2.0681e-01, time/batch = 0.6831s	
3533/22950 (epoch 7.697), train_loss = 1.60704158, grad/param norm = 2.0044e-01, time/batch = 0.6836s	
3534/22950 (epoch 7.699), train_loss = 1.53964538, grad/param norm = 1.8963e-01, time/batch = 0.6870s	
3535/22950 (epoch 7.702), train_loss = 1.53388862, grad/param norm = 1.9630e-01, time/batch = 0.6855s	
3536/22950 (epoch 7.704), train_loss = 1.54956399, grad/param norm = 2.0890e-01, time/batch = 0.6821s	
3537/22950 (epoch 7.706), train_loss = 1.61486270, grad/param norm = 2.0366e-01, time/batch = 0.6824s	
3538/22950 (epoch 7.708), train_loss = 1.45394179, grad/param norm = 2.1239e-01, time/batch = 0.6870s	
3539/22950 (epoch 7.710), train_loss = 1.53874084, grad/param norm = 1.7828e-01, time/batch = 0.6836s	
3540/22950 (epoch 7.712), train_loss = 1.64417893, grad/param norm = 1.9570e-01, time/batch = 0.6851s	
3541/22950 (epoch 7.715), train_loss = 1.54983998, grad/param norm = 2.0885e-01, time/batch = 0.6852s	
3542/22950 (epoch 7.717), train_loss = 1.34379343, grad/param norm = 1.8068e-01, time/batch = 0.7224s	
3543/22950 (epoch 7.719), train_loss = 1.44772413, grad/param norm = 2.0155e-01, time/batch = 0.6980s	
3544/22950 (epoch 7.721), train_loss = 1.53607707, grad/param norm = 1.9764e-01, time/batch = 0.6840s	
3545/22950 (epoch 7.723), train_loss = 1.37250825, grad/param norm = 1.9081e-01, time/batch = 0.6849s	
3546/22950 (epoch 7.725), train_loss = 1.61858481, grad/param norm = 2.0302e-01, time/batch = 0.6854s	
3547/22950 (epoch 7.728), train_loss = 1.48102759, grad/param norm = 1.9624e-01, time/batch = 0.6831s	
3548/22950 (epoch 7.730), train_loss = 1.48443472, grad/param norm = 2.1814e-01, time/batch = 0.7140s	
3549/22950 (epoch 7.732), train_loss = 1.48259767, grad/param norm = 1.8097e-01, time/batch = 0.6873s	
3550/22950 (epoch 7.734), train_loss = 1.48983252, grad/param norm = 2.0252e-01, time/batch = 0.7001s	
3551/22950 (epoch 7.736), train_loss = 1.41462821, grad/param norm = 2.1128e-01, time/batch = 0.6916s	
3552/22950 (epoch 7.739), train_loss = 1.52006228, grad/param norm = 1.8697e-01, time/batch = 0.7210s	
3553/22950 (epoch 7.741), train_loss = 1.49385518, grad/param norm = 1.9383e-01, time/batch = 0.6998s	
3554/22950 (epoch 7.743), train_loss = 1.65736246, grad/param norm = 2.0774e-01, time/batch = 0.6839s	
3555/22950 (epoch 7.745), train_loss = 1.73544320, grad/param norm = 2.2383e-01, time/batch = 0.6828s	
3556/22950 (epoch 7.747), train_loss = 1.49423394, grad/param norm = 2.0186e-01, time/batch = 0.6887s	
3557/22950 (epoch 7.749), train_loss = 1.38835413, grad/param norm = 2.0612e-01, time/batch = 0.6839s	
3558/22950 (epoch 7.752), train_loss = 1.66342100, grad/param norm = 2.0914e-01, time/batch = 0.6792s	
3559/22950 (epoch 7.754), train_loss = 1.56438740, grad/param norm = 2.1422e-01, time/batch = 0.6826s	
3560/22950 (epoch 7.756), train_loss = 1.37399148, grad/param norm = 2.0931e-01, time/batch = 0.6878s	
3561/22950 (epoch 7.758), train_loss = 1.42680482, grad/param norm = 1.9871e-01, time/batch = 0.6823s	
3562/22950 (epoch 7.760), train_loss = 1.50506337, grad/param norm = 1.9463e-01, time/batch = 0.7186s	
3563/22950 (epoch 7.763), train_loss = 1.45534438, grad/param norm = 1.9108e-01, time/batch = 0.7071s	
3564/22950 (epoch 7.765), train_loss = 1.57535079, grad/param norm = 2.1055e-01, time/batch = 0.7007s	
3565/22950 (epoch 7.767), train_loss = 1.70349380, grad/param norm = 2.0729e-01, time/batch = 0.7201s	
3566/22950 (epoch 7.769), train_loss = 1.48286491, grad/param norm = 1.9897e-01, time/batch = 0.7201s	
3567/22950 (epoch 7.771), train_loss = 1.36102992, grad/param norm = 2.1976e-01, time/batch = 0.7195s	
3568/22950 (epoch 7.773), train_loss = 1.19071590, grad/param norm = 1.8373e-01, time/batch = 0.7070s	
3569/22950 (epoch 7.776), train_loss = 1.40632568, grad/param norm = 1.9512e-01, time/batch = 0.7052s	
3570/22950 (epoch 7.778), train_loss = 1.30516557, grad/param norm = 1.8456e-01, time/batch = 0.6865s	
3571/22950 (epoch 7.780), train_loss = 1.33585575, grad/param norm = 1.8421e-01, time/batch = 0.6912s	
3572/22950 (epoch 7.782), train_loss = 1.40453051, grad/param norm = 1.9677e-01, time/batch = 0.6870s	
3573/22950 (epoch 7.784), train_loss = 1.52148569, grad/param norm = 2.2064e-01, time/batch = 0.6840s	
3574/22950 (epoch 7.786), train_loss = 1.53186818, grad/param norm = 1.8877e-01, time/batch = 0.6855s	
3575/22950 (epoch 7.789), train_loss = 1.29024129, grad/param norm = 1.9244e-01, time/batch = 0.6882s	
3576/22950 (epoch 7.791), train_loss = 1.34632481, grad/param norm = 2.0462e-01, time/batch = 0.6998s	
3577/22950 (epoch 7.793), train_loss = 1.73151367, grad/param norm = 2.0664e-01, time/batch = 0.7023s	
3578/22950 (epoch 7.795), train_loss = 1.38845281, grad/param norm = 1.8577e-01, time/batch = 0.6885s	
3579/22950 (epoch 7.797), train_loss = 1.67181444, grad/param norm = 2.2026e-01, time/batch = 0.6928s	
3580/22950 (epoch 7.800), train_loss = 1.37508822, grad/param norm = 2.1345e-01, time/batch = 0.6845s	
3581/22950 (epoch 7.802), train_loss = 1.40132155, grad/param norm = 2.0053e-01, time/batch = 0.6900s	
3582/22950 (epoch 7.804), train_loss = 1.44920880, grad/param norm = 1.9355e-01, time/batch = 0.6887s	
3583/22950 (epoch 7.806), train_loss = 1.33302789, grad/param norm = 1.8738e-01, time/batch = 0.6893s	
3584/22950 (epoch 7.808), train_loss = 1.40364460, grad/param norm = 2.0620e-01, time/batch = 0.6904s	
3585/22950 (epoch 7.810), train_loss = 1.39816939, grad/param norm = 2.1147e-01, time/batch = 0.6866s	
3586/22950 (epoch 7.813), train_loss = 1.21751698, grad/param norm = 1.7958e-01, time/batch = 0.6856s	
3587/22950 (epoch 7.815), train_loss = 1.35943387, grad/param norm = 1.7970e-01, time/batch = 0.6862s	
3588/22950 (epoch 7.817), train_loss = 1.30306177, grad/param norm = 1.8787e-01, time/batch = 0.6874s	
3589/22950 (epoch 7.819), train_loss = 1.40957584, grad/param norm = 1.9830e-01, time/batch = 0.7027s	
3590/22950 (epoch 7.821), train_loss = 1.47069527, grad/param norm = 2.0709e-01, time/batch = 0.6874s	
3591/22950 (epoch 7.824), train_loss = 1.42105337, grad/param norm = 2.0114e-01, time/batch = 0.7111s	
3592/22950 (epoch 7.826), train_loss = 1.56254088, grad/param norm = 2.2065e-01, time/batch = 0.7216s	
3593/22950 (epoch 7.828), train_loss = 1.44334929, grad/param norm = 2.0541e-01, time/batch = 0.7244s	
3594/22950 (epoch 7.830), train_loss = 1.47746862, grad/param norm = 1.9167e-01, time/batch = 0.6974s	
3595/22950 (epoch 7.832), train_loss = 1.50718466, grad/param norm = 2.0344e-01, time/batch = 0.7082s	
3596/22950 (epoch 7.834), train_loss = 1.34698851, grad/param norm = 1.9104e-01, time/batch = 0.7099s	
3597/22950 (epoch 7.837), train_loss = 1.45937737, grad/param norm = 2.0914e-01, time/batch = 0.7056s	
3598/22950 (epoch 7.839), train_loss = 1.35260271, grad/param norm = 1.8765e-01, time/batch = 0.6926s	
3599/22950 (epoch 7.841), train_loss = 1.33837355, grad/param norm = 1.7700e-01, time/batch = 0.6906s	
3600/22950 (epoch 7.843), train_loss = 1.38242130, grad/param norm = 2.0264e-01, time/batch = 0.6912s	
3601/22950 (epoch 7.845), train_loss = 1.46121675, grad/param norm = 2.0800e-01, time/batch = 0.6917s	
3602/22950 (epoch 7.847), train_loss = 1.54353791, grad/param norm = 1.9173e-01, time/batch = 0.6862s	
3603/22950 (epoch 7.850), train_loss = 1.52708701, grad/param norm = 2.2676e-01, time/batch = 0.6882s	
3604/22950 (epoch 7.852), train_loss = 1.53545941, grad/param norm = 2.0671e-01, time/batch = 0.7049s	
3605/22950 (epoch 7.854), train_loss = 1.45665815, grad/param norm = 1.9381e-01, time/batch = 0.6984s	
3606/22950 (epoch 7.856), train_loss = 1.66942392, grad/param norm = 2.1343e-01, time/batch = 0.6897s	
3607/22950 (epoch 7.858), train_loss = 1.48826664, grad/param norm = 2.0301e-01, time/batch = 0.6887s	
3608/22950 (epoch 7.861), train_loss = 1.56703904, grad/param norm = 2.1919e-01, time/batch = 0.6867s	
3609/22950 (epoch 7.863), train_loss = 1.62245844, grad/param norm = 2.0634e-01, time/batch = 0.6866s	
3610/22950 (epoch 7.865), train_loss = 1.68702168, grad/param norm = 2.2602e-01, time/batch = 0.6894s	
3611/22950 (epoch 7.867), train_loss = 1.50173808, grad/param norm = 2.0110e-01, time/batch = 0.6898s	
3612/22950 (epoch 7.869), train_loss = 1.69470339, grad/param norm = 2.0878e-01, time/batch = 0.6859s	
3613/22950 (epoch 7.871), train_loss = 1.43294669, grad/param norm = 2.0554e-01, time/batch = 0.6856s	
3614/22950 (epoch 7.874), train_loss = 1.42782057, grad/param norm = 2.0782e-01, time/batch = 0.6875s	
3615/22950 (epoch 7.876), train_loss = 1.53459511, grad/param norm = 2.0620e-01, time/batch = 0.6874s	
3616/22950 (epoch 7.878), train_loss = 1.36706812, grad/param norm = 2.0666e-01, time/batch = 0.6876s	
3617/22950 (epoch 7.880), train_loss = 1.62473754, grad/param norm = 1.9901e-01, time/batch = 0.6886s	
3618/22950 (epoch 7.882), train_loss = 1.33175346, grad/param norm = 1.9572e-01, time/batch = 0.6862s	
3619/22950 (epoch 7.885), train_loss = 1.48836160, grad/param norm = 2.0342e-01, time/batch = 0.6861s	
3620/22950 (epoch 7.887), train_loss = 1.46709706, grad/param norm = 2.0451e-01, time/batch = 0.6905s	
3621/22950 (epoch 7.889), train_loss = 1.58891909, grad/param norm = 2.3140e-01, time/batch = 0.6888s	
3622/22950 (epoch 7.891), train_loss = 1.49490369, grad/param norm = 2.0033e-01, time/batch = 0.6848s	
3623/22950 (epoch 7.893), train_loss = 1.47992586, grad/param norm = 2.0666e-01, time/batch = 0.6884s	
3624/22950 (epoch 7.895), train_loss = 1.62011318, grad/param norm = 2.1332e-01, time/batch = 0.6902s	
3625/22950 (epoch 7.898), train_loss = 1.46279027, grad/param norm = 1.9879e-01, time/batch = 0.6890s	
3626/22950 (epoch 7.900), train_loss = 1.35383080, grad/param norm = 1.8434e-01, time/batch = 0.6934s	
3627/22950 (epoch 7.902), train_loss = 1.52573089, grad/param norm = 2.0093e-01, time/batch = 0.6857s	
3628/22950 (epoch 7.904), train_loss = 1.52438129, grad/param norm = 1.9904e-01, time/batch = 0.6839s	
3629/22950 (epoch 7.906), train_loss = 1.50940822, grad/param norm = 2.1232e-01, time/batch = 0.6846s	
3630/22950 (epoch 7.908), train_loss = 1.33707748, grad/param norm = 1.9119e-01, time/batch = 0.6995s	
3631/22950 (epoch 7.911), train_loss = 1.30190780, grad/param norm = 1.7989e-01, time/batch = 0.6848s	
3632/22950 (epoch 7.913), train_loss = 1.40502854, grad/param norm = 1.8939e-01, time/batch = 0.6832s	
3633/22950 (epoch 7.915), train_loss = 1.64015520, grad/param norm = 2.1388e-01, time/batch = 0.6837s	
3634/22950 (epoch 7.917), train_loss = 1.28853361, grad/param norm = 1.8696e-01, time/batch = 0.6852s	
3635/22950 (epoch 7.919), train_loss = 1.43844859, grad/param norm = 1.9974e-01, time/batch = 0.6915s	
3636/22950 (epoch 7.922), train_loss = 1.44959175, grad/param norm = 2.0026e-01, time/batch = 0.6851s	
3637/22950 (epoch 7.924), train_loss = 1.53503346, grad/param norm = 1.9530e-01, time/batch = 0.6803s	
3638/22950 (epoch 7.926), train_loss = 1.31421131, grad/param norm = 1.9825e-01, time/batch = 0.6818s	
3639/22950 (epoch 7.928), train_loss = 1.31109629, grad/param norm = 1.9365e-01, time/batch = 0.6839s	
3640/22950 (epoch 7.930), train_loss = 1.27357721, grad/param norm = 2.0361e-01, time/batch = 0.6862s	
3641/22950 (epoch 7.932), train_loss = 1.28193677, grad/param norm = 1.9327e-01, time/batch = 0.6955s	
3642/22950 (epoch 7.935), train_loss = 1.49145183, grad/param norm = 2.1337e-01, time/batch = 0.6930s	
3643/22950 (epoch 7.937), train_loss = 1.50267894, grad/param norm = 2.1320e-01, time/batch = 0.6882s	
3644/22950 (epoch 7.939), train_loss = 1.39966959, grad/param norm = 2.0642e-01, time/batch = 0.6865s	
3645/22950 (epoch 7.941), train_loss = 1.35142626, grad/param norm = 1.9103e-01, time/batch = 0.6866s	
3646/22950 (epoch 7.943), train_loss = 1.48193921, grad/param norm = 2.1063e-01, time/batch = 0.6882s	
3647/22950 (epoch 7.946), train_loss = 1.31449989, grad/param norm = 1.9642e-01, time/batch = 0.7108s	
3648/22950 (epoch 7.948), train_loss = 1.49276544, grad/param norm = 1.9086e-01, time/batch = 0.6940s	
3649/22950 (epoch 7.950), train_loss = 1.52381915, grad/param norm = 2.1571e-01, time/batch = 0.6852s	
3650/22950 (epoch 7.952), train_loss = 1.46967853, grad/param norm = 2.0624e-01, time/batch = 0.6863s	
3651/22950 (epoch 7.954), train_loss = 1.41792304, grad/param norm = 1.8793e-01, time/batch = 0.6875s	
3652/22950 (epoch 7.956), train_loss = 1.37386678, grad/param norm = 1.8177e-01, time/batch = 0.6841s	
3653/22950 (epoch 7.959), train_loss = 1.32938538, grad/param norm = 2.2135e-01, time/batch = 0.6857s	
3654/22950 (epoch 7.961), train_loss = 1.46667318, grad/param norm = 1.9250e-01, time/batch = 0.6861s	
3655/22950 (epoch 7.963), train_loss = 1.54154841, grad/param norm = 2.1125e-01, time/batch = 0.6871s	
3656/22950 (epoch 7.965), train_loss = 1.66265425, grad/param norm = 2.0839e-01, time/batch = 0.6837s	
3657/22950 (epoch 7.967), train_loss = 1.45940641, grad/param norm = 2.1870e-01, time/batch = 0.6858s	
3658/22950 (epoch 7.969), train_loss = 1.35587485, grad/param norm = 1.9060e-01, time/batch = 0.6847s	
3659/22950 (epoch 7.972), train_loss = 1.44910259, grad/param norm = 1.9378e-01, time/batch = 0.6828s	
3660/22950 (epoch 7.974), train_loss = 1.33702968, grad/param norm = 1.9009e-01, time/batch = 0.6843s	
3661/22950 (epoch 7.976), train_loss = 1.27907922, grad/param norm = 1.9251e-01, time/batch = 0.6851s	
3662/22950 (epoch 7.978), train_loss = 1.41611153, grad/param norm = 2.1930e-01, time/batch = 0.6852s	
3663/22950 (epoch 7.980), train_loss = 1.43591059, grad/param norm = 2.0012e-01, time/batch = 0.6925s	
3664/22950 (epoch 7.983), train_loss = 1.31876498, grad/param norm = 1.9062e-01, time/batch = 0.6889s	
3665/22950 (epoch 7.985), train_loss = 1.28066283, grad/param norm = 1.9623e-01, time/batch = 0.6857s	
3666/22950 (epoch 7.987), train_loss = 1.35967398, grad/param norm = 1.9310e-01, time/batch = 0.6803s	
3667/22950 (epoch 7.989), train_loss = 1.48307040, grad/param norm = 1.9227e-01, time/batch = 0.6851s	
3668/22950 (epoch 7.991), train_loss = 1.31792716, grad/param norm = 1.9798e-01, time/batch = 0.6863s	
3669/22950 (epoch 7.993), train_loss = 1.46048555, grad/param norm = 2.1246e-01, time/batch = 0.6849s	
3670/22950 (epoch 7.996), train_loss = 1.53707266, grad/param norm = 2.0066e-01, time/batch = 0.6872s	
3671/22950 (epoch 7.998), train_loss = 1.39228635, grad/param norm = 1.9844e-01, time/batch = 0.6931s	
3672/22950 (epoch 8.000), train_loss = 1.28868769, grad/param norm = 1.9468e-01, time/batch = 0.6852s	
3673/22950 (epoch 8.002), train_loss = 1.65412609, grad/param norm = 2.1682e-01, time/batch = 0.6850s	
3674/22950 (epoch 8.004), train_loss = 1.47346229, grad/param norm = 1.9366e-01, time/batch = 0.6852s	
3675/22950 (epoch 8.007), train_loss = 1.41760017, grad/param norm = 1.9522e-01, time/batch = 0.6826s	
3676/22950 (epoch 8.009), train_loss = 1.53948903, grad/param norm = 1.8698e-01, time/batch = 0.6855s	
3677/22950 (epoch 8.011), train_loss = 1.41165185, grad/param norm = 1.9603e-01, time/batch = 0.6914s	
3678/22950 (epoch 8.013), train_loss = 1.57205474, grad/param norm = 2.1417e-01, time/batch = 0.7189s	
3679/22950 (epoch 8.015), train_loss = 1.53293402, grad/param norm = 1.9278e-01, time/batch = 0.7275s	
3680/22950 (epoch 8.017), train_loss = 1.39760248, grad/param norm = 1.9207e-01, time/batch = 0.6986s	
3681/22950 (epoch 8.020), train_loss = 1.39531836, grad/param norm = 1.9434e-01, time/batch = 0.6952s	
3682/22950 (epoch 8.022), train_loss = 1.24831363, grad/param norm = 1.7639e-01, time/batch = 0.6967s	
3683/22950 (epoch 8.024), train_loss = 1.34414180, grad/param norm = 2.0323e-01, time/batch = 0.7135s	
3684/22950 (epoch 8.026), train_loss = 1.45906203, grad/param norm = 2.0437e-01, time/batch = 0.6939s	
3685/22950 (epoch 8.028), train_loss = 1.50517670, grad/param norm = 2.1196e-01, time/batch = 0.6869s	
3686/22950 (epoch 8.031), train_loss = 1.43553048, grad/param norm = 1.8782e-01, time/batch = 0.6903s	
3687/22950 (epoch 8.033), train_loss = 1.63653273, grad/param norm = 2.1871e-01, time/batch = 0.6871s	
3688/22950 (epoch 8.035), train_loss = 1.41261494, grad/param norm = 1.7538e-01, time/batch = 0.6958s	
3689/22950 (epoch 8.037), train_loss = 1.40074226, grad/param norm = 2.0663e-01, time/batch = 0.6950s	
3690/22950 (epoch 8.039), train_loss = 1.43308370, grad/param norm = 2.0055e-01, time/batch = 0.6906s	
3691/22950 (epoch 8.041), train_loss = 1.39883299, grad/param norm = 1.8115e-01, time/batch = 0.6894s	
3692/22950 (epoch 8.044), train_loss = 1.41516224, grad/param norm = 2.0918e-01, time/batch = 0.6917s	
3693/22950 (epoch 8.046), train_loss = 1.45423791, grad/param norm = 2.0586e-01, time/batch = 0.6891s	
3694/22950 (epoch 8.048), train_loss = 1.45148191, grad/param norm = 1.9882e-01, time/batch = 0.6858s	
3695/22950 (epoch 8.050), train_loss = 1.48745405, grad/param norm = 2.0505e-01, time/batch = 0.6836s	
3696/22950 (epoch 8.052), train_loss = 1.44265390, grad/param norm = 2.0001e-01, time/batch = 0.6876s	
3697/22950 (epoch 8.054), train_loss = 1.70324425, grad/param norm = 2.1511e-01, time/batch = 0.6874s	
3698/22950 (epoch 8.057), train_loss = 1.52819451, grad/param norm = 1.9567e-01, time/batch = 0.6890s	
3699/22950 (epoch 8.059), train_loss = 1.52315945, grad/param norm = 2.0709e-01, time/batch = 0.6908s	
3700/22950 (epoch 8.061), train_loss = 1.31740764, grad/param norm = 1.9264e-01, time/batch = 0.6879s	
3701/22950 (epoch 8.063), train_loss = 1.48074210, grad/param norm = 1.8511e-01, time/batch = 0.6892s	
3702/22950 (epoch 8.065), train_loss = 1.15797602, grad/param norm = 1.9567e-01, time/batch = 0.6852s	
3703/22950 (epoch 8.068), train_loss = 1.53979248, grad/param norm = 2.0238e-01, time/batch = 0.6861s	
3704/22950 (epoch 8.070), train_loss = 1.31123882, grad/param norm = 1.9579e-01, time/batch = 0.6887s	
3705/22950 (epoch 8.072), train_loss = 1.45169230, grad/param norm = 2.1101e-01, time/batch = 0.6864s	
3706/22950 (epoch 8.074), train_loss = 1.43169105, grad/param norm = 2.3225e-01, time/batch = 0.6866s	
3707/22950 (epoch 8.076), train_loss = 1.43148791, grad/param norm = 2.1295e-01, time/batch = 0.6895s	
3708/22950 (epoch 8.078), train_loss = 1.56375217, grad/param norm = 2.1980e-01, time/batch = 0.6885s	
3709/22950 (epoch 8.081), train_loss = 1.56151479, grad/param norm = 2.1005e-01, time/batch = 0.6842s	
3710/22950 (epoch 8.083), train_loss = 1.39441832, grad/param norm = 2.1967e-01, time/batch = 0.6867s	
3711/22950 (epoch 8.085), train_loss = 1.32526720, grad/param norm = 2.0229e-01, time/batch = 0.6883s	
3712/22950 (epoch 8.087), train_loss = 1.35440800, grad/param norm = 2.0282e-01, time/batch = 0.6889s	
3713/22950 (epoch 8.089), train_loss = 1.45916172, grad/param norm = 1.9909e-01, time/batch = 0.6855s	
3714/22950 (epoch 8.092), train_loss = 1.43314943, grad/param norm = 2.0720e-01, time/batch = 0.6886s	
3715/22950 (epoch 8.094), train_loss = 1.37758914, grad/param norm = 1.9883e-01, time/batch = 0.6891s	
3716/22950 (epoch 8.096), train_loss = 1.58424300, grad/param norm = 2.0963e-01, time/batch = 0.6859s	
3717/22950 (epoch 8.098), train_loss = 1.46068030, grad/param norm = 2.0164e-01, time/batch = 0.6852s	
3718/22950 (epoch 8.100), train_loss = 1.35369974, grad/param norm = 1.9472e-01, time/batch = 0.6853s	
3719/22950 (epoch 8.102), train_loss = 1.43764864, grad/param norm = 1.8587e-01, time/batch = 0.6852s	
3720/22950 (epoch 8.105), train_loss = 1.28314978, grad/param norm = 1.7746e-01, time/batch = 0.6855s	
3721/22950 (epoch 8.107), train_loss = 1.36492367, grad/param norm = 1.9530e-01, time/batch = 0.6905s	
3722/22950 (epoch 8.109), train_loss = 1.39766564, grad/param norm = 2.0092e-01, time/batch = 0.6888s	
3723/22950 (epoch 8.111), train_loss = 1.28191639, grad/param norm = 1.7742e-01, time/batch = 0.6868s	
3724/22950 (epoch 8.113), train_loss = 1.47970280, grad/param norm = 2.0117e-01, time/batch = 0.6845s	
3725/22950 (epoch 8.115), train_loss = 1.50699140, grad/param norm = 2.3392e-01, time/batch = 0.6861s	
3726/22950 (epoch 8.118), train_loss = 1.58503576, grad/param norm = 2.0172e-01, time/batch = 0.6904s	
3727/22950 (epoch 8.120), train_loss = 1.34966101, grad/param norm = 1.8779e-01, time/batch = 0.6901s	
3728/22950 (epoch 8.122), train_loss = 1.57316528, grad/param norm = 2.0942e-01, time/batch = 0.6946s	
3729/22950 (epoch 8.124), train_loss = 1.20557986, grad/param norm = 1.6281e-01, time/batch = 0.6898s	
3730/22950 (epoch 8.126), train_loss = 1.39202233, grad/param norm = 2.0068e-01, time/batch = 0.6862s	
3731/22950 (epoch 8.129), train_loss = 1.24974697, grad/param norm = 1.8202e-01, time/batch = 0.7036s	
3732/22950 (epoch 8.131), train_loss = 1.40993559, grad/param norm = 2.1913e-01, time/batch = 0.7040s	
3733/22950 (epoch 8.133), train_loss = 1.53406393, grad/param norm = 2.1278e-01, time/batch = 0.6876s	
3734/22950 (epoch 8.135), train_loss = 1.40519088, grad/param norm = 2.0285e-01, time/batch = 0.7028s	
3735/22950 (epoch 8.137), train_loss = 1.64275955, grad/param norm = 2.1152e-01, time/batch = 0.7169s	
3736/22950 (epoch 8.139), train_loss = 1.37771209, grad/param norm = 2.1612e-01, time/batch = 0.7153s	
3737/22950 (epoch 8.142), train_loss = 1.32037033, grad/param norm = 1.8921e-01, time/batch = 0.7203s	
3738/22950 (epoch 8.144), train_loss = 1.31119689, grad/param norm = 1.8735e-01, time/batch = 0.7064s	
3739/22950 (epoch 8.146), train_loss = 1.44194020, grad/param norm = 2.0215e-01, time/batch = 0.7078s	
3740/22950 (epoch 8.148), train_loss = 1.36258862, grad/param norm = 1.8656e-01, time/batch = 0.7102s	
3741/22950 (epoch 8.150), train_loss = 1.39378112, grad/param norm = 1.9051e-01, time/batch = 0.7071s	
3742/22950 (epoch 8.153), train_loss = 1.39705355, grad/param norm = 1.9449e-01, time/batch = 0.7052s	
3743/22950 (epoch 8.155), train_loss = 1.35458913, grad/param norm = 1.9183e-01, time/batch = 0.7033s	
3744/22950 (epoch 8.157), train_loss = 1.36238594, grad/param norm = 2.0175e-01, time/batch = 0.6883s	
3745/22950 (epoch 8.159), train_loss = 1.29437383, grad/param norm = 1.8160e-01, time/batch = 0.6980s	
3746/22950 (epoch 8.161), train_loss = 1.40197058, grad/param norm = 1.8181e-01, time/batch = 0.6867s	
3747/22950 (epoch 8.163), train_loss = 1.34372837, grad/param norm = 1.8523e-01, time/batch = 0.7051s	
3748/22950 (epoch 8.166), train_loss = 1.62561156, grad/param norm = 4.3665e-01, time/batch = 0.7153s	
3749/22950 (epoch 8.168), train_loss = 1.58882825, grad/param norm = 2.6473e-01, time/batch = 0.7051s	
3750/22950 (epoch 8.170), train_loss = 1.50817763, grad/param norm = 2.1042e-01, time/batch = 0.7206s	
3751/22950 (epoch 8.172), train_loss = 1.41031899, grad/param norm = 1.9834e-01, time/batch = 0.7134s	
3752/22950 (epoch 8.174), train_loss = 1.52917431, grad/param norm = 2.1400e-01, time/batch = 0.6921s	
3753/22950 (epoch 8.176), train_loss = 1.56844170, grad/param norm = 1.9330e-01, time/batch = 0.6911s	
3754/22950 (epoch 8.179), train_loss = 1.47996780, grad/param norm = 2.0882e-01, time/batch = 0.6925s	
3755/22950 (epoch 8.181), train_loss = 1.62397481, grad/param norm = 2.0207e-01, time/batch = 0.6944s	
3756/22950 (epoch 8.183), train_loss = 1.52205140, grad/param norm = 2.1189e-01, time/batch = 0.6928s	
3757/22950 (epoch 8.185), train_loss = 1.49017140, grad/param norm = 1.9572e-01, time/batch = 0.6910s	
3758/22950 (epoch 8.187), train_loss = 1.26691632, grad/param norm = 2.0107e-01, time/batch = 0.6930s	
3759/22950 (epoch 8.190), train_loss = 1.37033918, grad/param norm = 2.0495e-01, time/batch = 0.6908s	
3760/22950 (epoch 8.192), train_loss = 1.31951127, grad/param norm = 1.8988e-01, time/batch = 0.6925s	
3761/22950 (epoch 8.194), train_loss = 1.40341567, grad/param norm = 2.2059e-01, time/batch = 0.6923s	
3762/22950 (epoch 8.196), train_loss = 1.23495481, grad/param norm = 1.9021e-01, time/batch = 0.6942s	
3763/22950 (epoch 8.198), train_loss = 1.53628043, grad/param norm = 2.0747e-01, time/batch = 0.7029s	
3764/22950 (epoch 8.200), train_loss = 1.27766844, grad/param norm = 1.8025e-01, time/batch = 0.7225s	
3765/22950 (epoch 8.203), train_loss = 1.22111943, grad/param norm = 1.7636e-01, time/batch = 0.7271s	
3766/22950 (epoch 8.205), train_loss = 1.34124117, grad/param norm = 2.0731e-01, time/batch = 0.7145s	
3767/22950 (epoch 8.207), train_loss = 1.38330005, grad/param norm = 1.9459e-01, time/batch = 0.7022s	
3768/22950 (epoch 8.209), train_loss = 1.57555886, grad/param norm = 2.0144e-01, time/batch = 0.7044s	
3769/22950 (epoch 8.211), train_loss = 1.28160164, grad/param norm = 2.1070e-01, time/batch = 0.7153s	
3770/22950 (epoch 8.214), train_loss = 1.38737766, grad/param norm = 1.9290e-01, time/batch = 0.7020s	
3771/22950 (epoch 8.216), train_loss = 1.49750174, grad/param norm = 1.9362e-01, time/batch = 0.7038s	
3772/22950 (epoch 8.218), train_loss = 1.42079462, grad/param norm = 1.8871e-01, time/batch = 0.7054s	
3773/22950 (epoch 8.220), train_loss = 1.57520369, grad/param norm = 2.1564e-01, time/batch = 0.6957s	
3774/22950 (epoch 8.222), train_loss = 1.54798094, grad/param norm = 2.1063e-01, time/batch = 0.7126s	
3775/22950 (epoch 8.224), train_loss = 1.37693289, grad/param norm = 1.9803e-01, time/batch = 0.7117s	
3776/22950 (epoch 8.227), train_loss = 1.42085598, grad/param norm = 1.9120e-01, time/batch = 0.6996s	
3777/22950 (epoch 8.229), train_loss = 1.44942601, grad/param norm = 2.0855e-01, time/batch = 0.7016s	
3778/22950 (epoch 8.231), train_loss = 1.27136618, grad/param norm = 1.7977e-01, time/batch = 0.7017s	
3779/22950 (epoch 8.233), train_loss = 1.39078989, grad/param norm = 1.9450e-01, time/batch = 0.6953s	
3780/22950 (epoch 8.235), train_loss = 1.54259556, grad/param norm = 1.9731e-01, time/batch = 0.6967s	
3781/22950 (epoch 8.237), train_loss = 1.30512349, grad/param norm = 1.8993e-01, time/batch = 0.6993s	
3782/22950 (epoch 8.240), train_loss = 1.40216014, grad/param norm = 2.1428e-01, time/batch = 0.6932s	
3783/22950 (epoch 8.242), train_loss = 1.52820929, grad/param norm = 2.3219e-01, time/batch = 0.6940s	
3784/22950 (epoch 8.244), train_loss = 1.62314679, grad/param norm = 2.3419e-01, time/batch = 0.6954s	
3785/22950 (epoch 8.246), train_loss = 1.56404442, grad/param norm = 2.1710e-01, time/batch = 0.6934s	
3786/22950 (epoch 8.248), train_loss = 1.47933974, grad/param norm = 2.1810e-01, time/batch = 0.6932s	
3787/22950 (epoch 8.251), train_loss = 1.40154201, grad/param norm = 2.0222e-01, time/batch = 0.6922s	
3788/22950 (epoch 8.253), train_loss = 1.39114054, grad/param norm = 2.0414e-01, time/batch = 0.6899s	
3789/22950 (epoch 8.255), train_loss = 1.40703074, grad/param norm = 2.0744e-01, time/batch = 0.6941s	
3790/22950 (epoch 8.257), train_loss = 1.54321121, grad/param norm = 2.0353e-01, time/batch = 0.6977s	
3791/22950 (epoch 8.259), train_loss = 1.26833105, grad/param norm = 1.9579e-01, time/batch = 0.6894s	
3792/22950 (epoch 8.261), train_loss = 1.43171831, grad/param norm = 2.0360e-01, time/batch = 0.6958s	
3793/22950 (epoch 8.264), train_loss = 1.32063123, grad/param norm = 1.7364e-01, time/batch = 0.6891s	
3794/22950 (epoch 8.266), train_loss = 1.49862042, grad/param norm = 1.9587e-01, time/batch = 0.6884s	
3795/22950 (epoch 8.268), train_loss = 1.48263466, grad/param norm = 1.9983e-01, time/batch = 0.6878s	
3796/22950 (epoch 8.270), train_loss = 1.47132616, grad/param norm = 1.8893e-01, time/batch = 0.6866s	
3797/22950 (epoch 8.272), train_loss = 1.58240323, grad/param norm = 1.9650e-01, time/batch = 0.6939s	
3798/22950 (epoch 8.275), train_loss = 1.35922849, grad/param norm = 2.0468e-01, time/batch = 0.6933s	
3799/22950 (epoch 8.277), train_loss = 1.28180251, grad/param norm = 1.8863e-01, time/batch = 0.6931s	
3800/22950 (epoch 8.279), train_loss = 1.49244440, grad/param norm = 2.1794e-01, time/batch = 0.6904s	
3801/22950 (epoch 8.281), train_loss = 1.34372963, grad/param norm = 2.1061e-01, time/batch = 0.6936s	
3802/22950 (epoch 8.283), train_loss = 1.23552534, grad/param norm = 1.8643e-01, time/batch = 0.6949s	
3803/22950 (epoch 8.285), train_loss = 1.40861922, grad/param norm = 1.9438e-01, time/batch = 0.6928s	
3804/22950 (epoch 8.288), train_loss = 1.40618599, grad/param norm = 1.8752e-01, time/batch = 0.6905s	
3805/22950 (epoch 8.290), train_loss = 1.34668325, grad/param norm = 1.9222e-01, time/batch = 0.6918s	
3806/22950 (epoch 8.292), train_loss = 1.45994073, grad/param norm = 1.9124e-01, time/batch = 0.6921s	
3807/22950 (epoch 8.294), train_loss = 1.45026292, grad/param norm = 2.0787e-01, time/batch = 0.6931s	
3808/22950 (epoch 8.296), train_loss = 1.19909010, grad/param norm = 1.7926e-01, time/batch = 0.6979s	
3809/22950 (epoch 8.298), train_loss = 1.38939088, grad/param norm = 1.8128e-01, time/batch = 0.6941s	
3810/22950 (epoch 8.301), train_loss = 1.45871353, grad/param norm = 1.9897e-01, time/batch = 0.6865s	
3811/22950 (epoch 8.303), train_loss = 1.48582885, grad/param norm = 2.0308e-01, time/batch = 0.6909s	
3812/22950 (epoch 8.305), train_loss = 1.51838550, grad/param norm = 2.0766e-01, time/batch = 0.6912s	
3813/22950 (epoch 8.307), train_loss = 1.55145663, grad/param norm = 2.1652e-01, time/batch = 0.6934s	
3814/22950 (epoch 8.309), train_loss = 1.41154542, grad/param norm = 1.7706e-01, time/batch = 0.6965s	
3815/22950 (epoch 8.312), train_loss = 1.45017629, grad/param norm = 2.0156e-01, time/batch = 0.6974s	
3816/22950 (epoch 8.314), train_loss = 1.33283313, grad/param norm = 1.9352e-01, time/batch = 0.7072s	
3817/22950 (epoch 8.316), train_loss = 1.43825825, grad/param norm = 1.9355e-01, time/batch = 0.7069s	
3818/22950 (epoch 8.318), train_loss = 1.22670601, grad/param norm = 1.8277e-01, time/batch = 0.7105s	
3819/22950 (epoch 8.320), train_loss = 1.38443071, grad/param norm = 1.7516e-01, time/batch = 0.7025s	
3820/22950 (epoch 8.322), train_loss = 1.40141346, grad/param norm = 2.0145e-01, time/batch = 0.7035s	
3821/22950 (epoch 8.325), train_loss = 1.12589755, grad/param norm = 1.7668e-01, time/batch = 0.7217s	
3822/22950 (epoch 8.327), train_loss = 1.17112034, grad/param norm = 1.7151e-01, time/batch = 0.7100s	
3823/22950 (epoch 8.329), train_loss = 1.29492620, grad/param norm = 1.8865e-01, time/batch = 0.7140s	
3824/22950 (epoch 8.331), train_loss = 1.25863958, grad/param norm = 1.8263e-01, time/batch = 0.7041s	
3825/22950 (epoch 8.333), train_loss = 1.36494063, grad/param norm = 1.9769e-01, time/batch = 0.7026s	
3826/22950 (epoch 8.336), train_loss = 1.40454175, grad/param norm = 2.3033e-01, time/batch = 0.7069s	
3827/22950 (epoch 8.338), train_loss = 1.35050489, grad/param norm = 2.0395e-01, time/batch = 0.7056s	
3828/22950 (epoch 8.340), train_loss = 1.36617716, grad/param norm = 2.0887e-01, time/batch = 0.7005s	
3829/22950 (epoch 8.342), train_loss = 1.48658390, grad/param norm = 2.0046e-01, time/batch = 0.7025s	
3830/22950 (epoch 8.344), train_loss = 1.41984565, grad/param norm = 2.0348e-01, time/batch = 0.6984s	
3831/22950 (epoch 8.346), train_loss = 1.63079981, grad/param norm = 2.1530e-01, time/batch = 0.7068s	
3832/22950 (epoch 8.349), train_loss = 1.44752782, grad/param norm = 2.0296e-01, time/batch = 0.7036s	
3833/22950 (epoch 8.351), train_loss = 1.44726793, grad/param norm = 2.1124e-01, time/batch = 0.7015s	
3834/22950 (epoch 8.353), train_loss = 1.54699863, grad/param norm = 2.3083e-01, time/batch = 0.7138s	
3835/22950 (epoch 8.355), train_loss = 1.55984808, grad/param norm = 2.1433e-01, time/batch = 0.7149s	
3836/22950 (epoch 8.357), train_loss = 1.42105180, grad/param norm = 1.9087e-01, time/batch = 0.7055s	
3837/22950 (epoch 8.359), train_loss = 1.47513810, grad/param norm = 1.9767e-01, time/batch = 0.6996s	
3838/22950 (epoch 8.362), train_loss = 1.37132043, grad/param norm = 1.8719e-01, time/batch = 0.6938s	
3839/22950 (epoch 8.364), train_loss = 1.43141806, grad/param norm = 1.9545e-01, time/batch = 0.6951s	
3840/22950 (epoch 8.366), train_loss = 1.22458691, grad/param norm = 1.7842e-01, time/batch = 0.6941s	
3841/22950 (epoch 8.368), train_loss = 1.44377135, grad/param norm = 2.3261e-01, time/batch = 0.7015s	
3842/22950 (epoch 8.370), train_loss = 1.38689026, grad/param norm = 2.0501e-01, time/batch = 0.6912s	
3843/22950 (epoch 8.373), train_loss = 1.25409112, grad/param norm = 1.8869e-01, time/batch = 0.6888s	
3844/22950 (epoch 8.375), train_loss = 1.55588369, grad/param norm = 2.1912e-01, time/batch = 0.6905s	
3845/22950 (epoch 8.377), train_loss = 1.37662460, grad/param norm = 2.0513e-01, time/batch = 0.6896s	
3846/22950 (epoch 8.379), train_loss = 1.51391265, grad/param norm = 1.9626e-01, time/batch = 0.6891s	
3847/22950 (epoch 8.381), train_loss = 1.24217856, grad/param norm = 1.8439e-01, time/batch = 0.7002s	
3848/22950 (epoch 8.383), train_loss = 1.47650888, grad/param norm = 2.1919e-01, time/batch = 0.6933s	
3849/22950 (epoch 8.386), train_loss = 1.41357518, grad/param norm = 2.0945e-01, time/batch = 0.7214s	
3850/22950 (epoch 8.388), train_loss = 1.45697386, grad/param norm = 2.3755e-01, time/batch = 0.7316s	
3851/22950 (epoch 8.390), train_loss = 1.30653336, grad/param norm = 1.9433e-01, time/batch = 0.7328s	
3852/22950 (epoch 8.392), train_loss = 1.27363013, grad/param norm = 1.8516e-01, time/batch = 0.7241s	
3853/22950 (epoch 8.394), train_loss = 1.30996778, grad/param norm = 1.7272e-01, time/batch = 0.7284s	
3854/22950 (epoch 8.397), train_loss = 1.52333369, grad/param norm = 2.1860e-01, time/batch = 0.7131s	
3855/22950 (epoch 8.399), train_loss = 1.52145338, grad/param norm = 2.0299e-01, time/batch = 0.7030s	
3856/22950 (epoch 8.401), train_loss = 1.71586928, grad/param norm = 2.2065e-01, time/batch = 0.7045s	
3857/22950 (epoch 8.403), train_loss = 1.35947920, grad/param norm = 2.0033e-01, time/batch = 0.6982s	
3858/22950 (epoch 8.405), train_loss = 1.52542100, grad/param norm = 2.2704e-01, time/batch = 0.6968s	
3859/22950 (epoch 8.407), train_loss = 1.57681760, grad/param norm = 2.1696e-01, time/batch = 0.6987s	
3860/22950 (epoch 8.410), train_loss = 1.26825026, grad/param norm = 1.9147e-01, time/batch = 0.6914s	
3861/22950 (epoch 8.412), train_loss = 1.44414479, grad/param norm = 2.0825e-01, time/batch = 0.6949s	
3862/22950 (epoch 8.414), train_loss = 1.54517566, grad/param norm = 2.2152e-01, time/batch = 0.6914s	
3863/22950 (epoch 8.416), train_loss = 1.50194192, grad/param norm = 1.9957e-01, time/batch = 0.6919s	
3864/22950 (epoch 8.418), train_loss = 1.50728273, grad/param norm = 1.9992e-01, time/batch = 0.6930s	
3865/22950 (epoch 8.420), train_loss = 1.50037020, grad/param norm = 2.0494e-01, time/batch = 0.6967s	
3866/22950 (epoch 8.423), train_loss = 1.29468698, grad/param norm = 1.6769e-01, time/batch = 0.6885s	
3867/22950 (epoch 8.425), train_loss = 1.42500332, grad/param norm = 1.9588e-01, time/batch = 0.6893s	
3868/22950 (epoch 8.427), train_loss = 1.35894622, grad/param norm = 1.8163e-01, time/batch = 0.6915s	
3869/22950 (epoch 8.429), train_loss = 1.36002905, grad/param norm = 1.9912e-01, time/batch = 0.7073s	
3870/22950 (epoch 8.431), train_loss = 1.47578976, grad/param norm = 2.0632e-01, time/batch = 0.7118s	
3871/22950 (epoch 8.434), train_loss = 1.40002755, grad/param norm = 2.0258e-01, time/batch = 0.7018s	
3872/22950 (epoch 8.436), train_loss = 1.68097512, grad/param norm = 2.3010e-01, time/batch = 0.6921s	
3873/22950 (epoch 8.438), train_loss = 1.42371224, grad/param norm = 2.0652e-01, time/batch = 0.7151s	
3874/22950 (epoch 8.440), train_loss = 1.46812461, grad/param norm = 2.1565e-01, time/batch = 0.7117s	
3875/22950 (epoch 8.442), train_loss = 1.58867991, grad/param norm = 2.1838e-01, time/batch = 0.7059s	
3876/22950 (epoch 8.444), train_loss = 1.54558106, grad/param norm = 2.0756e-01, time/batch = 0.6967s	
3877/22950 (epoch 8.447), train_loss = 1.64780239, grad/param norm = 2.1527e-01, time/batch = 0.6974s	
3878/22950 (epoch 8.449), train_loss = 1.28235615, grad/param norm = 1.7387e-01, time/batch = 0.6901s	
3879/22950 (epoch 8.451), train_loss = 1.47703466, grad/param norm = 2.0365e-01, time/batch = 0.6941s	
3880/22950 (epoch 8.453), train_loss = 1.47708607, grad/param norm = 1.9052e-01, time/batch = 0.6925s	
3881/22950 (epoch 8.455), train_loss = 1.32439342, grad/param norm = 1.8308e-01, time/batch = 0.6967s	
3882/22950 (epoch 8.458), train_loss = 1.54968447, grad/param norm = 1.9573e-01, time/batch = 0.6912s	
3883/22950 (epoch 8.460), train_loss = 1.45203073, grad/param norm = 1.9479e-01, time/batch = 0.6913s	
3884/22950 (epoch 8.462), train_loss = 1.42170675, grad/param norm = 2.0147e-01, time/batch = 0.6929s	
3885/22950 (epoch 8.464), train_loss = 1.38577452, grad/param norm = 2.0816e-01, time/batch = 0.7013s	
3886/22950 (epoch 8.466), train_loss = 1.44337848, grad/param norm = 2.0387e-01, time/batch = 0.6949s	
3887/22950 (epoch 8.468), train_loss = 1.53078020, grad/param norm = 1.9239e-01, time/batch = 0.7007s	
3888/22950 (epoch 8.471), train_loss = 1.43243767, grad/param norm = 2.0247e-01, time/batch = 0.7254s	
3889/22950 (epoch 8.473), train_loss = 1.54507081, grad/param norm = 2.1621e-01, time/batch = 0.7063s	
3890/22950 (epoch 8.475), train_loss = 1.69074634, grad/param norm = 2.4098e-01, time/batch = 0.6939s	
3891/22950 (epoch 8.477), train_loss = 1.45881474, grad/param norm = 2.0800e-01, time/batch = 0.6928s	
3892/22950 (epoch 8.479), train_loss = 1.38605336, grad/param norm = 2.0718e-01, time/batch = 0.6899s	
3893/22950 (epoch 8.481), train_loss = 1.64850330, grad/param norm = 2.3182e-01, time/batch = 0.6952s	
3894/22950 (epoch 8.484), train_loss = 1.51526087, grad/param norm = 2.1009e-01, time/batch = 0.6969s	
3895/22950 (epoch 8.486), train_loss = 1.26870859, grad/param norm = 1.9082e-01, time/batch = 0.6907s	
3896/22950 (epoch 8.488), train_loss = 1.44340468, grad/param norm = 2.1864e-01, time/batch = 0.6885s	
3897/22950 (epoch 8.490), train_loss = 1.27379357, grad/param norm = 1.9971e-01, time/batch = 0.6929s	
3898/22950 (epoch 8.492), train_loss = 1.44185942, grad/param norm = 2.0082e-01, time/batch = 0.6985s	
3899/22950 (epoch 8.495), train_loss = 1.42527177, grad/param norm = 1.9083e-01, time/batch = 0.6988s	
3900/22950 (epoch 8.497), train_loss = 1.50195044, grad/param norm = 1.8732e-01, time/batch = 0.6973s	
3901/22950 (epoch 8.499), train_loss = 1.53555261, grad/param norm = 2.0788e-01, time/batch = 0.6934s	
3902/22950 (epoch 8.501), train_loss = 1.51124658, grad/param norm = 1.9254e-01, time/batch = 0.6898s	
3903/22950 (epoch 8.503), train_loss = 1.54164587, grad/param norm = 2.0667e-01, time/batch = 0.6903s	
3904/22950 (epoch 8.505), train_loss = 1.30738057, grad/param norm = 1.8039e-01, time/batch = 0.6899s	
3905/22950 (epoch 8.508), train_loss = 1.48218007, grad/param norm = 1.9013e-01, time/batch = 0.6894s	
3906/22950 (epoch 8.510), train_loss = 1.43394557, grad/param norm = 2.0703e-01, time/batch = 0.6912s	
3907/22950 (epoch 8.512), train_loss = 1.34337480, grad/param norm = 1.7642e-01, time/batch = 0.6917s	
3908/22950 (epoch 8.514), train_loss = 1.29172136, grad/param norm = 1.8922e-01, time/batch = 0.6962s	
3909/22950 (epoch 8.516), train_loss = 1.35122545, grad/param norm = 2.0958e-01, time/batch = 0.6895s	
3910/22950 (epoch 8.519), train_loss = 1.38917028, grad/param norm = 1.9728e-01, time/batch = 0.6896s	
3911/22950 (epoch 8.521), train_loss = 1.40333322, grad/param norm = 1.8421e-01, time/batch = 0.6956s	
3912/22950 (epoch 8.523), train_loss = 1.18311211, grad/param norm = 1.9738e-01, time/batch = 0.6940s	
3913/22950 (epoch 8.525), train_loss = 1.36648421, grad/param norm = 1.9249e-01, time/batch = 0.6958s	
3914/22950 (epoch 8.527), train_loss = 1.18633225, grad/param norm = 1.8287e-01, time/batch = 0.6929s	
3915/22950 (epoch 8.529), train_loss = 1.47750705, grad/param norm = 1.9874e-01, time/batch = 0.6931s	
3916/22950 (epoch 8.532), train_loss = 1.38503316, grad/param norm = 1.9438e-01, time/batch = 0.6933s	
3917/22950 (epoch 8.534), train_loss = 1.53615297, grad/param norm = 2.1185e-01, time/batch = 0.6910s	
3918/22950 (epoch 8.536), train_loss = 1.48428364, grad/param norm = 2.1293e-01, time/batch = 0.7129s	
3919/22950 (epoch 8.538), train_loss = 1.39114975, grad/param norm = 2.1711e-01, time/batch = 0.7145s	
3920/22950 (epoch 8.540), train_loss = 1.42080462, grad/param norm = 1.8781e-01, time/batch = 0.7282s	
3921/22950 (epoch 8.542), train_loss = 1.60892821, grad/param norm = 2.0691e-01, time/batch = 0.7172s	
3922/22950 (epoch 8.545), train_loss = 1.38590900, grad/param norm = 2.2029e-01, time/batch = 0.7248s	
3923/22950 (epoch 8.547), train_loss = 1.38951112, grad/param norm = 1.9347e-01, time/batch = 0.7314s	
3924/22950 (epoch 8.549), train_loss = 1.40447093, grad/param norm = 1.9474e-01, time/batch = 0.7105s	
3925/22950 (epoch 8.551), train_loss = 1.44076089, grad/param norm = 2.1514e-01, time/batch = 0.7069s	
3926/22950 (epoch 8.553), train_loss = 1.40878840, grad/param norm = 2.2115e-01, time/batch = 0.7091s	
3927/22950 (epoch 8.556), train_loss = 1.51125789, grad/param norm = 1.9024e-01, time/batch = 0.6975s	
3928/22950 (epoch 8.558), train_loss = 1.36599441, grad/param norm = 2.0212e-01, time/batch = 0.6894s	
3929/22950 (epoch 8.560), train_loss = 1.45986322, grad/param norm = 1.8472e-01, time/batch = 0.6898s	
3930/22950 (epoch 8.562), train_loss = 1.28445635, grad/param norm = 1.8629e-01, time/batch = 0.6907s	
3931/22950 (epoch 8.564), train_loss = 1.63787555, grad/param norm = 2.3754e-01, time/batch = 0.6916s	
3932/22950 (epoch 8.566), train_loss = 1.43107753, grad/param norm = 2.0295e-01, time/batch = 0.6904s	
3933/22950 (epoch 8.569), train_loss = 1.59212926, grad/param norm = 1.9987e-01, time/batch = 0.6929s	
3934/22950 (epoch 8.571), train_loss = 1.28117696, grad/param norm = 1.9594e-01, time/batch = 0.7088s	
3935/22950 (epoch 8.573), train_loss = 1.42363050, grad/param norm = 2.0466e-01, time/batch = 0.7219s	
3936/22950 (epoch 8.575), train_loss = 1.67975620, grad/param norm = 2.1454e-01, time/batch = 0.7318s	
3937/22950 (epoch 8.577), train_loss = 1.43583121, grad/param norm = 2.1938e-01, time/batch = 0.6987s	
3938/22950 (epoch 8.580), train_loss = 1.48401246, grad/param norm = 2.1402e-01, time/batch = 0.6973s	
3939/22950 (epoch 8.582), train_loss = 1.62208358, grad/param norm = 1.9580e-01, time/batch = 0.6959s	
3940/22950 (epoch 8.584), train_loss = 1.23674094, grad/param norm = 1.7749e-01, time/batch = 0.6989s	
3941/22950 (epoch 8.586), train_loss = 1.36507845, grad/param norm = 2.0829e-01, time/batch = 0.7062s	
3942/22950 (epoch 8.588), train_loss = 1.56526869, grad/param norm = 1.9589e-01, time/batch = 0.7332s	
3943/22950 (epoch 8.590), train_loss = 1.40076178, grad/param norm = 1.9812e-01, time/batch = 0.6978s	
3944/22950 (epoch 8.593), train_loss = 1.25126385, grad/param norm = 1.9107e-01, time/batch = 0.6939s	
3945/22950 (epoch 8.595), train_loss = 1.30122802, grad/param norm = 1.9649e-01, time/batch = 0.6915s	
3946/22950 (epoch 8.597), train_loss = 1.50096611, grad/param norm = 2.2421e-01, time/batch = 0.6926s	
3947/22950 (epoch 8.599), train_loss = 1.46687933, grad/param norm = 2.2530e-01, time/batch = 0.6912s	
3948/22950 (epoch 8.601), train_loss = 1.41639963, grad/param norm = 2.1516e-01, time/batch = 0.6907s	
3949/22950 (epoch 8.603), train_loss = 1.56223997, grad/param norm = 2.0019e-01, time/batch = 0.6922s	
3950/22950 (epoch 8.606), train_loss = 1.37077834, grad/param norm = 2.0382e-01, time/batch = 0.6974s	
3951/22950 (epoch 8.608), train_loss = 1.41586093, grad/param norm = 2.0058e-01, time/batch = 0.6947s	
3952/22950 (epoch 8.610), train_loss = 1.39235402, grad/param norm = 1.9914e-01, time/batch = 0.6906s	
3953/22950 (epoch 8.612), train_loss = 1.44011388, grad/param norm = 1.9289e-01, time/batch = 0.6916s	
3954/22950 (epoch 8.614), train_loss = 1.56327456, grad/param norm = 2.2384e-01, time/batch = 0.6907s	
3955/22950 (epoch 8.617), train_loss = 1.40315923, grad/param norm = 2.0644e-01, time/batch = 0.6895s	
3956/22950 (epoch 8.619), train_loss = 1.28885328, grad/param norm = 1.7772e-01, time/batch = 0.6922s	
3957/22950 (epoch 8.621), train_loss = 1.51679137, grad/param norm = 1.9739e-01, time/batch = 0.6919s	
3958/22950 (epoch 8.623), train_loss = 1.46157734, grad/param norm = 1.7826e-01, time/batch = 0.6917s	
3959/22950 (epoch 8.625), train_loss = 1.38407494, grad/param norm = 1.7949e-01, time/batch = 0.6926s	
3960/22950 (epoch 8.627), train_loss = 1.44951102, grad/param norm = 2.1586e-01, time/batch = 0.6919s	
3961/22950 (epoch 8.630), train_loss = 1.24663574, grad/param norm = 1.7795e-01, time/batch = 0.6946s	
3962/22950 (epoch 8.632), train_loss = 1.47515391, grad/param norm = 2.1406e-01, time/batch = 0.6919s	
3963/22950 (epoch 8.634), train_loss = 1.37597176, grad/param norm = 1.9409e-01, time/batch = 0.7026s	
3964/22950 (epoch 8.636), train_loss = 1.41021660, grad/param norm = 1.8423e-01, time/batch = 0.6950s	
3965/22950 (epoch 8.638), train_loss = 1.32366166, grad/param norm = 2.0578e-01, time/batch = 0.6938s	
3966/22950 (epoch 8.641), train_loss = 1.34506850, grad/param norm = 1.9052e-01, time/batch = 0.7034s	
3967/22950 (epoch 8.643), train_loss = 1.46602392, grad/param norm = 2.3181e-01, time/batch = 0.6934s	
3968/22950 (epoch 8.645), train_loss = 1.33980852, grad/param norm = 2.0956e-01, time/batch = 0.6911s	
3969/22950 (epoch 8.647), train_loss = 1.41942700, grad/param norm = 2.0506e-01, time/batch = 0.6971s	
3970/22950 (epoch 8.649), train_loss = 1.40654540, grad/param norm = 1.9855e-01, time/batch = 0.6946s	
3971/22950 (epoch 8.651), train_loss = 1.51477361, grad/param norm = 2.1182e-01, time/batch = 0.6940s	
3972/22950 (epoch 8.654), train_loss = 1.22807046, grad/param norm = 1.8430e-01, time/batch = 0.6948s	
3973/22950 (epoch 8.656), train_loss = 1.53830316, grad/param norm = 2.0898e-01, time/batch = 0.6924s	
3974/22950 (epoch 8.658), train_loss = 1.29047298, grad/param norm = 1.8412e-01, time/batch = 0.6904s	
3975/22950 (epoch 8.660), train_loss = 1.23722511, grad/param norm = 1.7964e-01, time/batch = 0.6900s	
3976/22950 (epoch 8.662), train_loss = 1.25017695, grad/param norm = 1.9249e-01, time/batch = 0.6884s	
3977/22950 (epoch 8.664), train_loss = 1.46237760, grad/param norm = 1.8794e-01, time/batch = 0.6893s	
3978/22950 (epoch 8.667), train_loss = 1.46939050, grad/param norm = 2.0528e-01, time/batch = 0.6931s	
3979/22950 (epoch 8.669), train_loss = 1.34975463, grad/param norm = 2.0061e-01, time/batch = 0.6943s	
3980/22950 (epoch 8.671), train_loss = 1.46588424, grad/param norm = 1.9288e-01, time/batch = 0.6922s	
3981/22950 (epoch 8.673), train_loss = 1.41550142, grad/param norm = 1.9268e-01, time/batch = 0.6928s	
3982/22950 (epoch 8.675), train_loss = 1.39558922, grad/param norm = 1.9345e-01, time/batch = 0.6915s	
3983/22950 (epoch 8.678), train_loss = 1.41416213, grad/param norm = 2.0406e-01, time/batch = 0.6931s	
3984/22950 (epoch 8.680), train_loss = 1.44548119, grad/param norm = 1.9079e-01, time/batch = 0.6975s	
3985/22950 (epoch 8.682), train_loss = 1.49901273, grad/param norm = 1.9439e-01, time/batch = 0.6948s	
3986/22950 (epoch 8.684), train_loss = 1.53127832, grad/param norm = 1.9998e-01, time/batch = 0.6938s	
3987/22950 (epoch 8.686), train_loss = 1.48183858, grad/param norm = 2.0054e-01, time/batch = 0.6938s	
3988/22950 (epoch 8.688), train_loss = 1.42308222, grad/param norm = 2.0349e-01, time/batch = 0.6931s	
3989/22950 (epoch 8.691), train_loss = 1.37216332, grad/param norm = 1.9341e-01, time/batch = 0.6900s	
3990/22950 (epoch 8.693), train_loss = 1.32787339, grad/param norm = 1.9540e-01, time/batch = 0.7001s	
3991/22950 (epoch 8.695), train_loss = 1.59538794, grad/param norm = 2.0375e-01, time/batch = 0.6979s	
3992/22950 (epoch 8.697), train_loss = 1.55014750, grad/param norm = 1.9911e-01, time/batch = 0.6965s	
3993/22950 (epoch 8.699), train_loss = 1.49648044, grad/param norm = 1.9216e-01, time/batch = 0.6940s	
3994/22950 (epoch 8.702), train_loss = 1.48980394, grad/param norm = 1.9388e-01, time/batch = 0.7002s	
3995/22950 (epoch 8.704), train_loss = 1.49570974, grad/param norm = 2.1208e-01, time/batch = 0.7044s	
3996/22950 (epoch 8.706), train_loss = 1.56268191, grad/param norm = 2.0636e-01, time/batch = 0.6976s	
3997/22950 (epoch 8.708), train_loss = 1.39494492, grad/param norm = 2.0735e-01, time/batch = 0.6990s	
3998/22950 (epoch 8.710), train_loss = 1.48192494, grad/param norm = 1.7889e-01, time/batch = 0.6921s	
3999/22950 (epoch 8.712), train_loss = 1.58797141, grad/param norm = 1.9113e-01, time/batch = 0.6930s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch8.71_1.6299.t7	
4000/22950 (epoch 8.715), train_loss = 1.50546228, grad/param norm = 2.1245e-01, time/batch = 0.6922s	
4001/22950 (epoch 8.717), train_loss = 1.44084002, grad/param norm = 1.8423e-01, time/batch = 0.6980s	
4002/22950 (epoch 8.719), train_loss = 1.39002717, grad/param norm = 1.9736e-01, time/batch = 0.6897s	
4003/22950 (epoch 8.721), train_loss = 1.48185922, grad/param norm = 1.9159e-01, time/batch = 0.6940s	
4004/22950 (epoch 8.723), train_loss = 1.31510867, grad/param norm = 1.8291e-01, time/batch = 0.6941s	
4005/22950 (epoch 8.725), train_loss = 1.55836714, grad/param norm = 2.0434e-01, time/batch = 0.6963s	
4006/22950 (epoch 8.728), train_loss = 1.43504018, grad/param norm = 1.9467e-01, time/batch = 0.6983s	
4007/22950 (epoch 8.730), train_loss = 1.43072148, grad/param norm = 2.0780e-01, time/batch = 0.6920s	
4008/22950 (epoch 8.732), train_loss = 1.43283691, grad/param norm = 1.7590e-01, time/batch = 0.6893s	
4009/22950 (epoch 8.734), train_loss = 1.43029617, grad/param norm = 1.9863e-01, time/batch = 0.6982s	
4010/22950 (epoch 8.736), train_loss = 1.37062264, grad/param norm = 2.0347e-01, time/batch = 0.6962s	
4011/22950 (epoch 8.739), train_loss = 1.48113139, grad/param norm = 1.8788e-01, time/batch = 0.6958s	
4012/22950 (epoch 8.741), train_loss = 1.44383200, grad/param norm = 1.8971e-01, time/batch = 0.6950s	
4013/22950 (epoch 8.743), train_loss = 1.61592777, grad/param norm = 2.0813e-01, time/batch = 0.7060s	
4014/22950 (epoch 8.745), train_loss = 1.68498047, grad/param norm = 2.1936e-01, time/batch = 0.7234s	
4015/22950 (epoch 8.747), train_loss = 1.44450796, grad/param norm = 1.9762e-01, time/batch = 0.7457s	
4016/22950 (epoch 8.749), train_loss = 1.33101123, grad/param norm = 1.9823e-01, time/batch = 0.7270s	
4017/22950 (epoch 8.752), train_loss = 1.61727924, grad/param norm = 2.0736e-01, time/batch = 0.7000s	
4018/22950 (epoch 8.754), train_loss = 1.49952093, grad/param norm = 2.0409e-01, time/batch = 0.6977s	
4019/22950 (epoch 8.756), train_loss = 1.33232857, grad/param norm = 2.0905e-01, time/batch = 0.7040s	
4020/22950 (epoch 8.758), train_loss = 1.37783821, grad/param norm = 1.9876e-01, time/batch = 0.7282s	
4021/22950 (epoch 8.760), train_loss = 1.46071487, grad/param norm = 1.9382e-01, time/batch = 0.7157s	
4022/22950 (epoch 8.763), train_loss = 1.42502170, grad/param norm = 1.9390e-01, time/batch = 0.7056s	
4023/22950 (epoch 8.765), train_loss = 1.51551692, grad/param norm = 2.0674e-01, time/batch = 0.7008s	
4024/22950 (epoch 8.767), train_loss = 1.65261039, grad/param norm = 2.1033e-01, time/batch = 0.6918s	
4025/22950 (epoch 8.769), train_loss = 1.43602138, grad/param norm = 1.9514e-01, time/batch = 0.6881s	
4026/22950 (epoch 8.771), train_loss = 1.32257322, grad/param norm = 2.3041e-01, time/batch = 0.6906s	
4027/22950 (epoch 8.773), train_loss = 1.13508185, grad/param norm = 1.8229e-01, time/batch = 0.6945s	
4028/22950 (epoch 8.776), train_loss = 1.35103570, grad/param norm = 1.9275e-01, time/batch = 0.6933s	
4029/22950 (epoch 8.778), train_loss = 1.25874628, grad/param norm = 1.8232e-01, time/batch = 0.6974s	
4030/22950 (epoch 8.780), train_loss = 1.29704509, grad/param norm = 1.7788e-01, time/batch = 0.6853s	
4031/22950 (epoch 8.782), train_loss = 1.35239093, grad/param norm = 1.9351e-01, time/batch = 0.6906s	
4032/22950 (epoch 8.784), train_loss = 1.46119711, grad/param norm = 2.1289e-01, time/batch = 0.6918s	
4033/22950 (epoch 8.786), train_loss = 1.48381833, grad/param norm = 1.8503e-01, time/batch = 0.6945s	
4034/22950 (epoch 8.789), train_loss = 1.24053605, grad/param norm = 1.8971e-01, time/batch = 0.6926s	
4035/22950 (epoch 8.791), train_loss = 1.29374848, grad/param norm = 2.0071e-01, time/batch = 0.6894s	
4036/22950 (epoch 8.793), train_loss = 1.67510180, grad/param norm = 2.0527e-01, time/batch = 0.6916s	
4037/22950 (epoch 8.795), train_loss = 1.34056272, grad/param norm = 1.8127e-01, time/batch = 0.6931s	
4038/22950 (epoch 8.797), train_loss = 1.62459412, grad/param norm = 2.1838e-01, time/batch = 0.6895s	
4039/22950 (epoch 8.800), train_loss = 1.32747835, grad/param norm = 2.0453e-01, time/batch = 0.6918s	
4040/22950 (epoch 8.802), train_loss = 1.34837817, grad/param norm = 1.9642e-01, time/batch = 0.6882s	
4041/22950 (epoch 8.804), train_loss = 1.39474495, grad/param norm = 1.9215e-01, time/batch = 0.6892s	
4042/22950 (epoch 8.806), train_loss = 1.28895421, grad/param norm = 1.8596e-01, time/batch = 0.6927s	
4043/22950 (epoch 8.808), train_loss = 1.35698757, grad/param norm = 2.0061e-01, time/batch = 0.6926s	
4044/22950 (epoch 8.810), train_loss = 1.34624565, grad/param norm = 2.0128e-01, time/batch = 0.6879s	
4045/22950 (epoch 8.813), train_loss = 1.17890891, grad/param norm = 1.8145e-01, time/batch = 0.6864s	
4046/22950 (epoch 8.815), train_loss = 1.29406375, grad/param norm = 1.7577e-01, time/batch = 0.6875s	
4047/22950 (epoch 8.817), train_loss = 1.24995489, grad/param norm = 1.8000e-01, time/batch = 0.6843s	
4048/22950 (epoch 8.819), train_loss = 1.36083894, grad/param norm = 1.9589e-01, time/batch = 0.6875s	
4049/22950 (epoch 8.821), train_loss = 1.42946911, grad/param norm = 2.0771e-01, time/batch = 0.6866s	
4050/22950 (epoch 8.824), train_loss = 1.38089531, grad/param norm = 2.0446e-01, time/batch = 0.6954s	
4051/22950 (epoch 8.826), train_loss = 1.50741713, grad/param norm = 2.2169e-01, time/batch = 0.6876s	
4052/22950 (epoch 8.828), train_loss = 1.38416338, grad/param norm = 1.9922e-01, time/batch = 0.7035s	
4053/22950 (epoch 8.830), train_loss = 1.41989976, grad/param norm = 1.8807e-01, time/batch = 0.6946s	
4054/22950 (epoch 8.832), train_loss = 1.45441558, grad/param norm = 2.0380e-01, time/batch = 0.6870s	
4055/22950 (epoch 8.834), train_loss = 1.29358861, grad/param norm = 1.9214e-01, time/batch = 0.6862s	
4056/22950 (epoch 8.837), train_loss = 1.40858018, grad/param norm = 2.0407e-01, time/batch = 0.6867s	
4057/22950 (epoch 8.839), train_loss = 1.29199110, grad/param norm = 1.8873e-01, time/batch = 0.6861s	
4058/22950 (epoch 8.841), train_loss = 1.28649501, grad/param norm = 1.7118e-01, time/batch = 0.6917s	
4059/22950 (epoch 8.843), train_loss = 1.34066459, grad/param norm = 2.0310e-01, time/batch = 0.6935s	
4060/22950 (epoch 8.845), train_loss = 1.41318136, grad/param norm = 2.0444e-01, time/batch = 0.6975s	
4061/22950 (epoch 8.847), train_loss = 1.49754223, grad/param norm = 1.9026e-01, time/batch = 0.7029s	
4062/22950 (epoch 8.850), train_loss = 1.46664453, grad/param norm = 2.2839e-01, time/batch = 0.7167s	
4063/22950 (epoch 8.852), train_loss = 1.48816564, grad/param norm = 2.0382e-01, time/batch = 0.7081s	
4064/22950 (epoch 8.854), train_loss = 1.40084900, grad/param norm = 1.9477e-01, time/batch = 0.6994s	
4065/22950 (epoch 8.856), train_loss = 1.62412577, grad/param norm = 2.1554e-01, time/batch = 0.7046s	
4066/22950 (epoch 8.858), train_loss = 1.43638182, grad/param norm = 1.9828e-01, time/batch = 0.7007s	
4067/22950 (epoch 8.861), train_loss = 1.52268411, grad/param norm = 2.1282e-01, time/batch = 0.6951s	
4068/22950 (epoch 8.863), train_loss = 1.57285606, grad/param norm = 2.1112e-01, time/batch = 0.6916s	
4069/22950 (epoch 8.865), train_loss = 1.64386027, grad/param norm = 2.2087e-01, time/batch = 0.6987s	
4070/22950 (epoch 8.867), train_loss = 1.46237084, grad/param norm = 1.9922e-01, time/batch = 0.6952s	
4071/22950 (epoch 8.869), train_loss = 1.64811586, grad/param norm = 2.1243e-01, time/batch = 0.6969s	
4072/22950 (epoch 8.871), train_loss = 1.40208742, grad/param norm = 2.0971e-01, time/batch = 0.7014s	
4073/22950 (epoch 8.874), train_loss = 1.39221284, grad/param norm = 2.1094e-01, time/batch = 0.7012s	
4074/22950 (epoch 8.876), train_loss = 1.47923302, grad/param norm = 1.9724e-01, time/batch = 0.6918s	
4075/22950 (epoch 8.878), train_loss = 1.33602665, grad/param norm = 2.0172e-01, time/batch = 0.6878s	
4076/22950 (epoch 8.880), train_loss = 1.58153061, grad/param norm = 1.9349e-01, time/batch = 0.7012s	
4077/22950 (epoch 8.882), train_loss = 1.28428524, grad/param norm = 1.9358e-01, time/batch = 0.7033s	
4078/22950 (epoch 8.885), train_loss = 1.44473295, grad/param norm = 2.0452e-01, time/batch = 0.6876s	
4079/22950 (epoch 8.887), train_loss = 1.42206464, grad/param norm = 1.9866e-01, time/batch = 0.6909s	
4080/22950 (epoch 8.889), train_loss = 1.53717688, grad/param norm = 2.2967e-01, time/batch = 0.6884s	
4081/22950 (epoch 8.891), train_loss = 1.44234737, grad/param norm = 2.0040e-01, time/batch = 0.6921s	
4082/22950 (epoch 8.893), train_loss = 1.43499015, grad/param norm = 2.0250e-01, time/batch = 0.6866s	
4083/22950 (epoch 8.895), train_loss = 1.57551638, grad/param norm = 2.0328e-01, time/batch = 0.6874s	
4084/22950 (epoch 8.898), train_loss = 1.41859130, grad/param norm = 1.9514e-01, time/batch = 0.6898s	
4085/22950 (epoch 8.900), train_loss = 1.29508161, grad/param norm = 1.7717e-01, time/batch = 0.6904s	
4086/22950 (epoch 8.902), train_loss = 1.48300546, grad/param norm = 1.9765e-01, time/batch = 0.6898s	
4087/22950 (epoch 8.904), train_loss = 1.48475870, grad/param norm = 2.0073e-01, time/batch = 0.7062s	
4088/22950 (epoch 8.906), train_loss = 1.45070847, grad/param norm = 1.9973e-01, time/batch = 0.7105s	
4089/22950 (epoch 8.908), train_loss = 1.28812392, grad/param norm = 1.9028e-01, time/batch = 0.6876s	
4090/22950 (epoch 8.911), train_loss = 1.25033017, grad/param norm = 1.7570e-01, time/batch = 0.6875s	
4091/22950 (epoch 8.913), train_loss = 1.36441360, grad/param norm = 1.8477e-01, time/batch = 0.6921s	
4092/22950 (epoch 8.915), train_loss = 1.57743140, grad/param norm = 2.1556e-01, time/batch = 0.6912s	
4093/22950 (epoch 8.917), train_loss = 1.24253866, grad/param norm = 1.9030e-01, time/batch = 0.6886s	
4094/22950 (epoch 8.919), train_loss = 1.39466963, grad/param norm = 1.9764e-01, time/batch = 0.6888s	
4095/22950 (epoch 8.922), train_loss = 1.40315161, grad/param norm = 1.9916e-01, time/batch = 0.6856s	
4096/22950 (epoch 8.924), train_loss = 1.48345453, grad/param norm = 1.9048e-01, time/batch = 0.6845s	
4097/22950 (epoch 8.926), train_loss = 1.26696390, grad/param norm = 1.9145e-01, time/batch = 0.6877s	
4098/22950 (epoch 8.928), train_loss = 1.26598849, grad/param norm = 1.9466e-01, time/batch = 0.6915s	
4099/22950 (epoch 8.930), train_loss = 1.22794573, grad/param norm = 2.0318e-01, time/batch = 0.7117s	
4100/22950 (epoch 8.932), train_loss = 1.23291970, grad/param norm = 1.8952e-01, time/batch = 0.7203s	
4101/22950 (epoch 8.935), train_loss = 1.44144165, grad/param norm = 2.1189e-01, time/batch = 0.7279s	
4102/22950 (epoch 8.937), train_loss = 1.45212074, grad/param norm = 2.1361e-01, time/batch = 0.7025s	
4103/22950 (epoch 8.939), train_loss = 1.34117705, grad/param norm = 2.0523e-01, time/batch = 0.6967s	
4104/22950 (epoch 8.941), train_loss = 1.31114425, grad/param norm = 1.9329e-01, time/batch = 0.6942s	
4105/22950 (epoch 8.943), train_loss = 1.42856058, grad/param norm = 2.0152e-01, time/batch = 0.6940s	
4106/22950 (epoch 8.946), train_loss = 1.27323351, grad/param norm = 1.9730e-01, time/batch = 0.6941s	
4107/22950 (epoch 8.948), train_loss = 1.44416094, grad/param norm = 1.8755e-01, time/batch = 0.7069s	
4108/22950 (epoch 8.950), train_loss = 1.47488848, grad/param norm = 2.1373e-01, time/batch = 0.6944s	
4109/22950 (epoch 8.952), train_loss = 1.43437631, grad/param norm = 2.0491e-01, time/batch = 0.7025s	
4110/22950 (epoch 8.954), train_loss = 1.38430515, grad/param norm = 1.8826e-01, time/batch = 0.6956s	
4111/22950 (epoch 8.956), train_loss = 1.32522583, grad/param norm = 1.8103e-01, time/batch = 0.6910s	
4112/22950 (epoch 8.959), train_loss = 1.28531607, grad/param norm = 2.1045e-01, time/batch = 0.6849s	
4113/22950 (epoch 8.961), train_loss = 1.42479851, grad/param norm = 1.9708e-01, time/batch = 0.7029s	
4114/22950 (epoch 8.963), train_loss = 1.48030091, grad/param norm = 2.0815e-01, time/batch = 0.7037s	
4115/22950 (epoch 8.965), train_loss = 1.61297680, grad/param norm = 2.0991e-01, time/batch = 0.7116s	
4116/22950 (epoch 8.967), train_loss = 1.40656156, grad/param norm = 2.1255e-01, time/batch = 0.7218s	
4117/22950 (epoch 8.969), train_loss = 1.31093112, grad/param norm = 1.8907e-01, time/batch = 0.7244s	
4118/22950 (epoch 8.972), train_loss = 1.39702056, grad/param norm = 1.9340e-01, time/batch = 0.7256s	
4119/22950 (epoch 8.974), train_loss = 1.29819098, grad/param norm = 1.9253e-01, time/batch = 0.7163s	
4120/22950 (epoch 8.976), train_loss = 1.22341763, grad/param norm = 1.8726e-01, time/batch = 0.7099s	
4121/22950 (epoch 8.978), train_loss = 1.37121139, grad/param norm = 2.1718e-01, time/batch = 0.6952s	
4122/22950 (epoch 8.980), train_loss = 1.39173769, grad/param norm = 2.0401e-01, time/batch = 0.6922s	
4123/22950 (epoch 8.983), train_loss = 1.27944131, grad/param norm = 1.8368e-01, time/batch = 0.6911s	
4124/22950 (epoch 8.985), train_loss = 1.23537175, grad/param norm = 1.9218e-01, time/batch = 0.6888s	
4125/22950 (epoch 8.987), train_loss = 1.30356161, grad/param norm = 1.8777e-01, time/batch = 0.6918s	
4126/22950 (epoch 8.989), train_loss = 1.43674379, grad/param norm = 1.8954e-01, time/batch = 0.6941s	
4127/22950 (epoch 8.991), train_loss = 1.25869413, grad/param norm = 1.9586e-01, time/batch = 0.7056s	
4128/22950 (epoch 8.993), train_loss = 1.42068154, grad/param norm = 2.1002e-01, time/batch = 0.7089s	
4129/22950 (epoch 8.996), train_loss = 1.48604415, grad/param norm = 1.9744e-01, time/batch = 0.6890s	
4130/22950 (epoch 8.998), train_loss = 1.34812321, grad/param norm = 1.9500e-01, time/batch = 0.6879s	
4131/22950 (epoch 9.000), train_loss = 1.23963983, grad/param norm = 1.9209e-01, time/batch = 0.6933s	
4132/22950 (epoch 9.002), train_loss = 1.60221240, grad/param norm = 2.1241e-01, time/batch = 0.6982s	
4133/22950 (epoch 9.004), train_loss = 1.42354347, grad/param norm = 1.9462e-01, time/batch = 0.7066s	
4134/22950 (epoch 9.007), train_loss = 1.37249210, grad/param norm = 1.8958e-01, time/batch = 0.6989s	
4135/22950 (epoch 9.009), train_loss = 1.49580909, grad/param norm = 1.9093e-01, time/batch = 0.6881s	
4136/22950 (epoch 9.011), train_loss = 1.34452885, grad/param norm = 1.8888e-01, time/batch = 0.6902s	
4137/22950 (epoch 9.013), train_loss = 1.52466535, grad/param norm = 2.2213e-01, time/batch = 0.7126s	
4138/22950 (epoch 9.015), train_loss = 1.49646046, grad/param norm = 2.0231e-01, time/batch = 0.7150s	
4139/22950 (epoch 9.017), train_loss = 1.35503210, grad/param norm = 1.8855e-01, time/batch = 0.6861s	
4140/22950 (epoch 9.020), train_loss = 1.34982965, grad/param norm = 1.8767e-01, time/batch = 0.6878s	
4141/22950 (epoch 9.022), train_loss = 1.20334247, grad/param norm = 1.7570e-01, time/batch = 0.6948s	
4142/22950 (epoch 9.024), train_loss = 1.28623345, grad/param norm = 1.9366e-01, time/batch = 0.6925s	
4143/22950 (epoch 9.026), train_loss = 1.40937672, grad/param norm = 2.0424e-01, time/batch = 0.6976s	
4144/22950 (epoch 9.028), train_loss = 1.45815009, grad/param norm = 2.0506e-01, time/batch = 0.7038s	
4145/22950 (epoch 9.031), train_loss = 1.39558560, grad/param norm = 1.8951e-01, time/batch = 0.7072s	
4146/22950 (epoch 9.033), train_loss = 1.58297391, grad/param norm = 2.1739e-01, time/batch = 0.6918s	
4147/22950 (epoch 9.035), train_loss = 1.36185576, grad/param norm = 1.7477e-01, time/batch = 0.6927s	
4148/22950 (epoch 9.037), train_loss = 1.35144184, grad/param norm = 2.0019e-01, time/batch = 0.6973s	
4149/22950 (epoch 9.039), train_loss = 1.37862817, grad/param norm = 2.0143e-01, time/batch = 0.6935s	
4150/22950 (epoch 9.041), train_loss = 1.33900236, grad/param norm = 1.7940e-01, time/batch = 0.6968s	
4151/22950 (epoch 9.044), train_loss = 1.37177177, grad/param norm = 2.0290e-01, time/batch = 0.6987s	
4152/22950 (epoch 9.046), train_loss = 1.41737131, grad/param norm = 1.9467e-01, time/batch = 0.6915s	
4153/22950 (epoch 9.048), train_loss = 1.41060955, grad/param norm = 1.9947e-01, time/batch = 0.6901s	
4154/22950 (epoch 9.050), train_loss = 1.44323580, grad/param norm = 2.0384e-01, time/batch = 0.6882s	
4155/22950 (epoch 9.052), train_loss = 1.40213852, grad/param norm = 1.9945e-01, time/batch = 0.6878s	
4156/22950 (epoch 9.054), train_loss = 1.65138672, grad/param norm = 2.1163e-01, time/batch = 0.6900s	
4157/22950 (epoch 9.057), train_loss = 1.49051631, grad/param norm = 2.0249e-01, time/batch = 0.7132s	
4158/22950 (epoch 9.059), train_loss = 1.47342357, grad/param norm = 2.0962e-01, time/batch = 0.7211s	
4159/22950 (epoch 9.061), train_loss = 1.28245961, grad/param norm = 2.0024e-01, time/batch = 0.6854s	
4160/22950 (epoch 9.063), train_loss = 1.44338343, grad/param norm = 1.8366e-01, time/batch = 0.6855s	
4161/22950 (epoch 9.065), train_loss = 1.12230957, grad/param norm = 1.9396e-01, time/batch = 0.6933s	
4162/22950 (epoch 9.068), train_loss = 1.48547964, grad/param norm = 2.0939e-01, time/batch = 0.6944s	
4163/22950 (epoch 9.070), train_loss = 1.25386043, grad/param norm = 1.8859e-01, time/batch = 0.6934s	
4164/22950 (epoch 9.072), train_loss = 1.41735241, grad/param norm = 2.1416e-01, time/batch = 0.6925s	
4165/22950 (epoch 9.074), train_loss = 1.38360275, grad/param norm = 2.3069e-01, time/batch = 0.6917s	
4166/22950 (epoch 9.076), train_loss = 1.38246634, grad/param norm = 2.0448e-01, time/batch = 0.6886s	
4167/22950 (epoch 9.078), train_loss = 1.51484528, grad/param norm = 2.1564e-01, time/batch = 0.6883s	
4168/22950 (epoch 9.081), train_loss = 1.50580799, grad/param norm = 2.0113e-01, time/batch = 0.6862s	
4169/22950 (epoch 9.083), train_loss = 1.34044298, grad/param norm = 2.0993e-01, time/batch = 0.6874s	
4170/22950 (epoch 9.085), train_loss = 1.28504921, grad/param norm = 1.9727e-01, time/batch = 0.6908s	
4171/22950 (epoch 9.087), train_loss = 1.31365113, grad/param norm = 2.0390e-01, time/batch = 0.6925s	
4172/22950 (epoch 9.089), train_loss = 1.41674191, grad/param norm = 1.9971e-01, time/batch = 0.6908s	
4173/22950 (epoch 9.092), train_loss = 1.38035743, grad/param norm = 1.9852e-01, time/batch = 0.6913s	
4174/22950 (epoch 9.094), train_loss = 1.32843451, grad/param norm = 1.9933e-01, time/batch = 0.6906s	
4175/22950 (epoch 9.096), train_loss = 1.54352231, grad/param norm = 2.0747e-01, time/batch = 0.6913s	
4176/22950 (epoch 9.098), train_loss = 1.41190569, grad/param norm = 1.9852e-01, time/batch = 0.6905s	
4177/22950 (epoch 9.100), train_loss = 1.30427491, grad/param norm = 1.9247e-01, time/batch = 0.7072s	
4178/22950 (epoch 9.102), train_loss = 1.38917724, grad/param norm = 1.8284e-01, time/batch = 0.7190s	
4179/22950 (epoch 9.105), train_loss = 1.23555798, grad/param norm = 1.7003e-01, time/batch = 0.6876s	
4180/22950 (epoch 9.107), train_loss = 1.32079371, grad/param norm = 1.9069e-01, time/batch = 0.6873s	
4181/22950 (epoch 9.109), train_loss = 1.34492172, grad/param norm = 1.9495e-01, time/batch = 0.6856s	
4182/22950 (epoch 9.111), train_loss = 1.24183376, grad/param norm = 1.7833e-01, time/batch = 0.6877s	
4183/22950 (epoch 9.113), train_loss = 1.42446154, grad/param norm = 2.0187e-01, time/batch = 0.6862s	
4184/22950 (epoch 9.115), train_loss = 1.44460777, grad/param norm = 2.2398e-01, time/batch = 0.6944s	
4185/22950 (epoch 9.118), train_loss = 1.53922670, grad/param norm = 1.9875e-01, time/batch = 0.7141s	
4186/22950 (epoch 9.120), train_loss = 1.29687638, grad/param norm = 1.8787e-01, time/batch = 0.7267s	
4187/22950 (epoch 9.122), train_loss = 1.53373076, grad/param norm = 2.1182e-01, time/batch = 0.7259s	
4188/22950 (epoch 9.124), train_loss = 1.15721456, grad/param norm = 1.5484e-01, time/batch = 0.7131s	
4189/22950 (epoch 9.126), train_loss = 1.34617923, grad/param norm = 1.9457e-01, time/batch = 0.6911s	
4190/22950 (epoch 9.129), train_loss = 1.21034979, grad/param norm = 1.7648e-01, time/batch = 0.6884s	
4191/22950 (epoch 9.131), train_loss = 1.35064861, grad/param norm = 2.1482e-01, time/batch = 0.6998s	
4192/22950 (epoch 9.133), train_loss = 1.48691561, grad/param norm = 2.1504e-01, time/batch = 0.6912s	
4193/22950 (epoch 9.135), train_loss = 1.36360906, grad/param norm = 1.9600e-01, time/batch = 0.6877s	
4194/22950 (epoch 9.137), train_loss = 1.58546942, grad/param norm = 2.0399e-01, time/batch = 0.6927s	
4195/22950 (epoch 9.139), train_loss = 1.33082128, grad/param norm = 2.2198e-01, time/batch = 0.6898s	
4196/22950 (epoch 9.142), train_loss = 1.28338140, grad/param norm = 1.8320e-01, time/batch = 0.7003s	
4197/22950 (epoch 9.144), train_loss = 1.26967103, grad/param norm = 1.8671e-01, time/batch = 0.7160s	
4198/22950 (epoch 9.146), train_loss = 1.39077266, grad/param norm = 2.0283e-01, time/batch = 0.7001s	
4199/22950 (epoch 9.148), train_loss = 1.32402144, grad/param norm = 1.8167e-01, time/batch = 0.6902s	
4200/22950 (epoch 9.150), train_loss = 1.35430911, grad/param norm = 1.8888e-01, time/batch = 0.6969s	
4201/22950 (epoch 9.153), train_loss = 1.34381795, grad/param norm = 1.9386e-01, time/batch = 0.6951s	
4202/22950 (epoch 9.155), train_loss = 1.30564566, grad/param norm = 1.8190e-01, time/batch = 0.6947s	
4203/22950 (epoch 9.157), train_loss = 1.31632596, grad/param norm = 2.0007e-01, time/batch = 0.6902s	
4204/22950 (epoch 9.159), train_loss = 1.25529065, grad/param norm = 1.7654e-01, time/batch = 0.6893s	
4205/22950 (epoch 9.161), train_loss = 1.34895905, grad/param norm = 1.8090e-01, time/batch = 0.6884s	
4206/22950 (epoch 9.163), train_loss = 1.28433831, grad/param norm = 1.8602e-01, time/batch = 0.6944s	
4207/22950 (epoch 9.166), train_loss = 1.56027581, grad/param norm = 2.2397e-01, time/batch = 0.7093s	
4208/22950 (epoch 9.168), train_loss = 1.53018991, grad/param norm = 2.1570e-01, time/batch = 0.7132s	
4209/22950 (epoch 9.170), train_loss = 1.45091878, grad/param norm = 2.0918e-01, time/batch = 0.6851s	
4210/22950 (epoch 9.172), train_loss = 1.36995601, grad/param norm = 1.9400e-01, time/batch = 0.6871s	
4211/22950 (epoch 9.174), train_loss = 1.48488501, grad/param norm = 2.1182e-01, time/batch = 0.6882s	
4212/22950 (epoch 9.176), train_loss = 1.53059640, grad/param norm = 1.9133e-01, time/batch = 0.6883s	
4213/22950 (epoch 9.179), train_loss = 1.43242491, grad/param norm = 2.1497e-01, time/batch = 0.6897s	
4214/22950 (epoch 9.181), train_loss = 1.57244532, grad/param norm = 1.9666e-01, time/batch = 0.6925s	
4215/22950 (epoch 9.183), train_loss = 1.47348927, grad/param norm = 2.0635e-01, time/batch = 0.6917s	
4216/22950 (epoch 9.185), train_loss = 1.44130070, grad/param norm = 1.8887e-01, time/batch = 0.6895s	
4217/22950 (epoch 9.187), train_loss = 1.23044021, grad/param norm = 1.9622e-01, time/batch = 0.6887s	
4218/22950 (epoch 9.190), train_loss = 1.30526585, grad/param norm = 2.0436e-01, time/batch = 0.6908s	
4219/22950 (epoch 9.192), train_loss = 1.27832909, grad/param norm = 1.8617e-01, time/batch = 0.6882s	
4220/22950 (epoch 9.194), train_loss = 1.34589743, grad/param norm = 2.1381e-01, time/batch = 0.6881s	
4221/22950 (epoch 9.196), train_loss = 1.19096301, grad/param norm = 1.9100e-01, time/batch = 0.6877s	
4222/22950 (epoch 9.198), train_loss = 1.48387165, grad/param norm = 1.9840e-01, time/batch = 0.6853s	
4223/22950 (epoch 9.200), train_loss = 1.23875986, grad/param norm = 1.8424e-01, time/batch = 0.6870s	
4224/22950 (epoch 9.203), train_loss = 1.17991611, grad/param norm = 1.7606e-01, time/batch = 0.6858s	
4225/22950 (epoch 9.205), train_loss = 1.30444844, grad/param norm = 2.0254e-01, time/batch = 0.6844s	
4226/22950 (epoch 9.207), train_loss = 1.33885578, grad/param norm = 1.9291e-01, time/batch = 0.6864s	
4227/22950 (epoch 9.209), train_loss = 1.51444129, grad/param norm = 2.2394e-01, time/batch = 0.6871s	
4228/22950 (epoch 9.211), train_loss = 1.22396813, grad/param norm = 2.0901e-01, time/batch = 0.6891s	
4229/22950 (epoch 9.214), train_loss = 1.34991009, grad/param norm = 1.8805e-01, time/batch = 0.6905s	
4230/22950 (epoch 9.216), train_loss = 1.46101367, grad/param norm = 1.9978e-01, time/batch = 0.6940s	
4231/22950 (epoch 9.218), train_loss = 1.37343430, grad/param norm = 1.8423e-01, time/batch = 0.6879s	
4232/22950 (epoch 9.220), train_loss = 1.52324884, grad/param norm = 1.9800e-01, time/batch = 0.6902s	
4233/22950 (epoch 9.222), train_loss = 1.49603995, grad/param norm = 2.0857e-01, time/batch = 0.6881s	
4234/22950 (epoch 9.224), train_loss = 1.33780987, grad/param norm = 2.0108e-01, time/batch = 0.6907s	
4235/22950 (epoch 9.227), train_loss = 1.38516770, grad/param norm = 1.8296e-01, time/batch = 0.6981s	
4236/22950 (epoch 9.229), train_loss = 1.41548158, grad/param norm = 2.1200e-01, time/batch = 0.6890s	
4237/22950 (epoch 9.231), train_loss = 1.23138037, grad/param norm = 1.7763e-01, time/batch = 0.6883s	
4238/22950 (epoch 9.233), train_loss = 1.33231498, grad/param norm = 1.9150e-01, time/batch = 0.6914s	
4239/22950 (epoch 9.235), train_loss = 1.50846416, grad/param norm = 1.9650e-01, time/batch = 0.6834s	
4240/22950 (epoch 9.237), train_loss = 1.26388602, grad/param norm = 1.8769e-01, time/batch = 0.6808s	
4241/22950 (epoch 9.240), train_loss = 1.35818859, grad/param norm = 2.1559e-01, time/batch = 0.6881s	
4242/22950 (epoch 9.242), train_loss = 1.49003734, grad/param norm = 2.1824e-01, time/batch = 0.7008s	
4243/22950 (epoch 9.244), train_loss = 1.58718228, grad/param norm = 2.3962e-01, time/batch = 0.7043s	
4244/22950 (epoch 9.246), train_loss = 1.52206547, grad/param norm = 2.1293e-01, time/batch = 0.7058s	
4245/22950 (epoch 9.248), train_loss = 1.44068322, grad/param norm = 2.2074e-01, time/batch = 0.6921s	
4246/22950 (epoch 9.251), train_loss = 1.35469843, grad/param norm = 2.0645e-01, time/batch = 0.6845s	
4247/22950 (epoch 9.253), train_loss = 1.34405796, grad/param norm = 2.1177e-01, time/batch = 0.6859s	
4248/22950 (epoch 9.255), train_loss = 1.36772005, grad/param norm = 2.0453e-01, time/batch = 0.6867s	
4249/22950 (epoch 9.257), train_loss = 1.49077855, grad/param norm = 2.0359e-01, time/batch = 0.6871s	
4250/22950 (epoch 9.259), train_loss = 1.22920858, grad/param norm = 1.9594e-01, time/batch = 0.6827s	
4251/22950 (epoch 9.261), train_loss = 1.37129768, grad/param norm = 1.9570e-01, time/batch = 0.6887s	
4252/22950 (epoch 9.264), train_loss = 1.28601674, grad/param norm = 1.7283e-01, time/batch = 0.6864s	
4253/22950 (epoch 9.266), train_loss = 1.43932130, grad/param norm = 1.8874e-01, time/batch = 0.6916s	
4254/22950 (epoch 9.268), train_loss = 1.43156415, grad/param norm = 1.8189e-01, time/batch = 0.7139s	
4255/22950 (epoch 9.270), train_loss = 1.41397906, grad/param norm = 1.9499e-01, time/batch = 0.6962s	
4256/22950 (epoch 9.272), train_loss = 1.52727596, grad/param norm = 1.9518e-01, time/batch = 0.6860s	
4257/22950 (epoch 9.275), train_loss = 1.31089199, grad/param norm = 1.9468e-01, time/batch = 0.6898s	
4258/22950 (epoch 9.277), train_loss = 1.23422391, grad/param norm = 1.8240e-01, time/batch = 0.6888s	
4259/22950 (epoch 9.279), train_loss = 1.42444879, grad/param norm = 2.1430e-01, time/batch = 0.6849s	
4260/22950 (epoch 9.281), train_loss = 1.29448530, grad/param norm = 1.9828e-01, time/batch = 0.6835s	
4261/22950 (epoch 9.283), train_loss = 1.18739570, grad/param norm = 1.8645e-01, time/batch = 0.6864s	
4262/22950 (epoch 9.285), train_loss = 1.36082626, grad/param norm = 1.8415e-01, time/batch = 0.6834s	
4263/22950 (epoch 9.288), train_loss = 1.36465700, grad/param norm = 1.8094e-01, time/batch = 0.6858s	
4264/22950 (epoch 9.290), train_loss = 1.28802644, grad/param norm = 1.8208e-01, time/batch = 0.6881s	
4265/22950 (epoch 9.292), train_loss = 1.41538951, grad/param norm = 1.8788e-01, time/batch = 0.6888s	
4266/22950 (epoch 9.294), train_loss = 1.38429875, grad/param norm = 1.9992e-01, time/batch = 0.6880s	
4267/22950 (epoch 9.296), train_loss = 1.15635423, grad/param norm = 1.7437e-01, time/batch = 0.6859s	
4268/22950 (epoch 9.298), train_loss = 1.35426235, grad/param norm = 1.8261e-01, time/batch = 0.6862s	
4269/22950 (epoch 9.301), train_loss = 1.41514482, grad/param norm = 1.9650e-01, time/batch = 0.6883s	
4270/22950 (epoch 9.303), train_loss = 1.43580619, grad/param norm = 2.0243e-01, time/batch = 0.6880s	
4271/22950 (epoch 9.305), train_loss = 1.46219433, grad/param norm = 2.0565e-01, time/batch = 0.7164s	
4272/22950 (epoch 9.307), train_loss = 1.50972304, grad/param norm = 2.1696e-01, time/batch = 0.7193s	
4273/22950 (epoch 9.309), train_loss = 1.36299567, grad/param norm = 1.8049e-01, time/batch = 0.7380s	
4274/22950 (epoch 9.312), train_loss = 1.39845582, grad/param norm = 2.0094e-01, time/batch = 0.7185s	
4275/22950 (epoch 9.314), train_loss = 1.28630374, grad/param norm = 1.8468e-01, time/batch = 0.6979s	
4276/22950 (epoch 9.316), train_loss = 1.39121079, grad/param norm = 1.9408e-01, time/batch = 0.6978s	
4277/22950 (epoch 9.318), train_loss = 1.18213336, grad/param norm = 1.8463e-01, time/batch = 0.6973s	
4278/22950 (epoch 9.320), train_loss = 1.33067845, grad/param norm = 1.7397e-01, time/batch = 0.7264s	
4279/22950 (epoch 9.322), train_loss = 1.35957430, grad/param norm = 1.9587e-01, time/batch = 0.7155s	
4280/22950 (epoch 9.325), train_loss = 1.08960603, grad/param norm = 1.7329e-01, time/batch = 0.7049s	
4281/22950 (epoch 9.327), train_loss = 1.12657467, grad/param norm = 1.6982e-01, time/batch = 0.7032s	
4282/22950 (epoch 9.329), train_loss = 1.25268178, grad/param norm = 1.8606e-01, time/batch = 0.7203s	
4283/22950 (epoch 9.331), train_loss = 1.20884863, grad/param norm = 1.8372e-01, time/batch = 0.7059s	
4284/22950 (epoch 9.333), train_loss = 1.31815879, grad/param norm = 1.9219e-01, time/batch = 0.7033s	
4285/22950 (epoch 9.336), train_loss = 1.36449406, grad/param norm = 2.3412e-01, time/batch = 0.6891s	
4286/22950 (epoch 9.338), train_loss = 1.29726266, grad/param norm = 1.9552e-01, time/batch = 0.6914s	
4287/22950 (epoch 9.340), train_loss = 1.32555180, grad/param norm = 2.0300e-01, time/batch = 0.6933s	
4288/22950 (epoch 9.342), train_loss = 1.43939740, grad/param norm = 1.9640e-01, time/batch = 0.6861s	
4289/22950 (epoch 9.344), train_loss = 1.36237717, grad/param norm = 2.0020e-01, time/batch = 0.6848s	
4290/22950 (epoch 9.346), train_loss = 1.57651010, grad/param norm = 2.1385e-01, time/batch = 0.6889s	
4291/22950 (epoch 9.349), train_loss = 1.39698969, grad/param norm = 2.0364e-01, time/batch = 0.6925s	
4292/22950 (epoch 9.351), train_loss = 1.39953456, grad/param norm = 2.0053e-01, time/batch = 0.6916s	
4293/22950 (epoch 9.353), train_loss = 1.49032538, grad/param norm = 2.1832e-01, time/batch = 0.6901s	
4294/22950 (epoch 9.355), train_loss = 1.50374451, grad/param norm = 2.0031e-01, time/batch = 0.6879s	
4295/22950 (epoch 9.357), train_loss = 1.37505069, grad/param norm = 1.8534e-01, time/batch = 0.6890s	
4296/22950 (epoch 9.359), train_loss = 1.42905380, grad/param norm = 1.9535e-01, time/batch = 0.6856s	
4297/22950 (epoch 9.362), train_loss = 1.32784565, grad/param norm = 1.8282e-01, time/batch = 0.6901s	
4298/22950 (epoch 9.364), train_loss = 1.38216149, grad/param norm = 1.9243e-01, time/batch = 0.7241s	
4299/22950 (epoch 9.366), train_loss = 1.18538752, grad/param norm = 1.7812e-01, time/batch = 0.6998s	
4300/22950 (epoch 9.368), train_loss = 1.39251666, grad/param norm = 2.2773e-01, time/batch = 0.6862s	
4301/22950 (epoch 9.370), train_loss = 1.34377169, grad/param norm = 1.9838e-01, time/batch = 0.6883s	
4302/22950 (epoch 9.373), train_loss = 1.21532761, grad/param norm = 1.9144e-01, time/batch = 0.6969s	
4303/22950 (epoch 9.375), train_loss = 1.50027543, grad/param norm = 2.1403e-01, time/batch = 0.6978s	
4304/22950 (epoch 9.377), train_loss = 1.33164449, grad/param norm = 2.0092e-01, time/batch = 0.6895s	
4305/22950 (epoch 9.379), train_loss = 1.46504651, grad/param norm = 1.9596e-01, time/batch = 0.7178s	
4306/22950 (epoch 9.381), train_loss = 1.19324879, grad/param norm = 1.8531e-01, time/batch = 0.7059s	
4307/22950 (epoch 9.383), train_loss = 1.42565879, grad/param norm = 2.1373e-01, time/batch = 0.6851s	
4308/22950 (epoch 9.386), train_loss = 1.35158301, grad/param norm = 2.0583e-01, time/batch = 0.6855s	
4309/22950 (epoch 9.388), train_loss = 1.40741494, grad/param norm = 2.2330e-01, time/batch = 0.6870s	
4310/22950 (epoch 9.390), train_loss = 1.26313215, grad/param norm = 1.8917e-01, time/batch = 0.6879s	
4311/22950 (epoch 9.392), train_loss = 1.22845028, grad/param norm = 1.8172e-01, time/batch = 0.6870s	
4312/22950 (epoch 9.394), train_loss = 1.26827202, grad/param norm = 1.7413e-01, time/batch = 0.6878s	
4313/22950 (epoch 9.397), train_loss = 1.47859938, grad/param norm = 2.1643e-01, time/batch = 0.7017s	
4314/22950 (epoch 9.399), train_loss = 1.48474438, grad/param norm = 2.0768e-01, time/batch = 0.7161s	
4315/22950 (epoch 9.401), train_loss = 1.67082138, grad/param norm = 2.1645e-01, time/batch = 0.7148s	
4316/22950 (epoch 9.403), train_loss = 1.31609155, grad/param norm = 1.9694e-01, time/batch = 0.7090s	
4317/22950 (epoch 9.405), train_loss = 1.47515758, grad/param norm = 2.2056e-01, time/batch = 0.6959s	
4318/22950 (epoch 9.407), train_loss = 1.53422751, grad/param norm = 2.2049e-01, time/batch = 0.6848s	
4319/22950 (epoch 9.410), train_loss = 1.23140966, grad/param norm = 1.8719e-01, time/batch = 0.6862s	
4320/22950 (epoch 9.412), train_loss = 1.40617750, grad/param norm = 2.0951e-01, time/batch = 0.6865s	
4321/22950 (epoch 9.414), train_loss = 1.49953599, grad/param norm = 2.2018e-01, time/batch = 0.6945s	
4322/22950 (epoch 9.416), train_loss = 1.45840463, grad/param norm = 2.0307e-01, time/batch = 0.7075s	
4323/22950 (epoch 9.418), train_loss = 1.45345768, grad/param norm = 1.9984e-01, time/batch = 0.6937s	
4324/22950 (epoch 9.420), train_loss = 1.45851895, grad/param norm = 2.0081e-01, time/batch = 0.6983s	
4325/22950 (epoch 9.423), train_loss = 1.25705157, grad/param norm = 1.6886e-01, time/batch = 0.7061s	
4326/22950 (epoch 9.425), train_loss = 1.37942199, grad/param norm = 1.9219e-01, time/batch = 0.6888s	
4327/22950 (epoch 9.427), train_loss = 1.31630835, grad/param norm = 1.8230e-01, time/batch = 0.6879s	
4328/22950 (epoch 9.429), train_loss = 1.32551385, grad/param norm = 2.0061e-01, time/batch = 0.6900s	
4329/22950 (epoch 9.431), train_loss = 1.43147903, grad/param norm = 2.0570e-01, time/batch = 0.6892s	
4330/22950 (epoch 9.434), train_loss = 1.35982874, grad/param norm = 1.9575e-01, time/batch = 0.6982s	
4331/22950 (epoch 9.436), train_loss = 1.63640308, grad/param norm = 2.2895e-01, time/batch = 0.6862s	
4332/22950 (epoch 9.438), train_loss = 1.38053417, grad/param norm = 2.0016e-01, time/batch = 0.6852s	
4333/22950 (epoch 9.440), train_loss = 1.43212696, grad/param norm = 2.1314e-01, time/batch = 0.6925s	
4334/22950 (epoch 9.442), train_loss = 1.54122019, grad/param norm = 2.2010e-01, time/batch = 0.6892s	
4335/22950 (epoch 9.444), train_loss = 1.49307302, grad/param norm = 2.0452e-01, time/batch = 0.6883s	
4336/22950 (epoch 9.447), train_loss = 1.59322006, grad/param norm = 2.1168e-01, time/batch = 0.6852s	
4337/22950 (epoch 9.449), train_loss = 1.24635430, grad/param norm = 1.7563e-01, time/batch = 0.6853s	
4338/22950 (epoch 9.451), train_loss = 1.42625930, grad/param norm = 2.0514e-01, time/batch = 0.7229s	
4339/22950 (epoch 9.453), train_loss = 1.43084473, grad/param norm = 1.9876e-01, time/batch = 0.7025s	
4340/22950 (epoch 9.455), train_loss = 1.26710615, grad/param norm = 1.7836e-01, time/batch = 0.6868s	
4341/22950 (epoch 9.458), train_loss = 1.51147336, grad/param norm = 1.9253e-01, time/batch = 0.6882s	
4342/22950 (epoch 9.460), train_loss = 1.40156679, grad/param norm = 1.9720e-01, time/batch = 0.6873s	
4343/22950 (epoch 9.462), train_loss = 1.37319693, grad/param norm = 1.9639e-01, time/batch = 0.7195s	
4344/22950 (epoch 9.464), train_loss = 1.33257206, grad/param norm = 2.0012e-01, time/batch = 0.7193s	
4345/22950 (epoch 9.466), train_loss = 1.40119135, grad/param norm = 1.9533e-01, time/batch = 0.7291s	
4346/22950 (epoch 9.468), train_loss = 1.49861071, grad/param norm = 1.9535e-01, time/batch = 0.7307s	
4347/22950 (epoch 9.471), train_loss = 1.39551187, grad/param norm = 1.9702e-01, time/batch = 0.7296s	
4348/22950 (epoch 9.473), train_loss = 1.49093411, grad/param norm = 2.1694e-01, time/batch = 0.7240s	
4349/22950 (epoch 9.475), train_loss = 1.64734550, grad/param norm = 2.3977e-01, time/batch = 0.7323s	
4350/22950 (epoch 9.477), train_loss = 1.39925373, grad/param norm = 2.0974e-01, time/batch = 0.7319s	
4351/22950 (epoch 9.479), train_loss = 1.32532836, grad/param norm = 2.0328e-01, time/batch = 0.7356s	
4352/22950 (epoch 9.481), train_loss = 1.58895481, grad/param norm = 2.2341e-01, time/batch = 0.7353s	
4353/22950 (epoch 9.484), train_loss = 1.46534810, grad/param norm = 2.0400e-01, time/batch = 0.7332s	
4354/22950 (epoch 9.486), train_loss = 1.23420657, grad/param norm = 1.9715e-01, time/batch = 0.7324s	
4355/22950 (epoch 9.488), train_loss = 1.38768624, grad/param norm = 2.1451e-01, time/batch = 0.7335s	
4356/22950 (epoch 9.490), train_loss = 1.21324609, grad/param norm = 1.9097e-01, time/batch = 0.7249s	
4357/22950 (epoch 9.492), train_loss = 1.38621695, grad/param norm = 1.9997e-01, time/batch = 0.7228s	
4358/22950 (epoch 9.495), train_loss = 1.37007329, grad/param norm = 1.9172e-01, time/batch = 0.7298s	
4359/22950 (epoch 9.497), train_loss = 1.45943360, grad/param norm = 1.8869e-01, time/batch = 0.7005s	
4360/22950 (epoch 9.499), train_loss = 1.49075136, grad/param norm = 2.0934e-01, time/batch = 0.7001s	
4361/22950 (epoch 9.501), train_loss = 1.45969303, grad/param norm = 1.9382e-01, time/batch = 0.7022s	
4362/22950 (epoch 9.503), train_loss = 1.49344840, grad/param norm = 2.0311e-01, time/batch = 0.7056s	
4363/22950 (epoch 9.505), train_loss = 1.24868865, grad/param norm = 1.7593e-01, time/batch = 0.7343s	
4364/22950 (epoch 9.508), train_loss = 1.44185782, grad/param norm = 1.9086e-01, time/batch = 0.7156s	
4365/22950 (epoch 9.510), train_loss = 1.39047993, grad/param norm = 2.0277e-01, time/batch = 0.7067s	
4366/22950 (epoch 9.512), train_loss = 1.28878798, grad/param norm = 1.7172e-01, time/batch = 0.7029s	
4367/22950 (epoch 9.514), train_loss = 1.26025652, grad/param norm = 1.8576e-01, time/batch = 0.6997s	
4368/22950 (epoch 9.516), train_loss = 1.32612116, grad/param norm = 2.1207e-01, time/batch = 0.6953s	
4369/22950 (epoch 9.519), train_loss = 1.33892855, grad/param norm = 1.9251e-01, time/batch = 0.6959s	
4370/22950 (epoch 9.521), train_loss = 1.36419898, grad/param norm = 1.7982e-01, time/batch = 0.6983s	
4371/22950 (epoch 9.523), train_loss = 1.13094071, grad/param norm = 1.8881e-01, time/batch = 0.6986s	
4372/22950 (epoch 9.525), train_loss = 1.30953330, grad/param norm = 1.8965e-01, time/batch = 0.7012s	
4373/22950 (epoch 9.527), train_loss = 1.15095709, grad/param norm = 1.8163e-01, time/batch = 0.6954s	
4374/22950 (epoch 9.529), train_loss = 1.43042819, grad/param norm = 1.9930e-01, time/batch = 0.6970s	
4375/22950 (epoch 9.532), train_loss = 1.33147207, grad/param norm = 1.8559e-01, time/batch = 0.6951s	
4376/22950 (epoch 9.534), train_loss = 1.49193144, grad/param norm = 2.1450e-01, time/batch = 0.7044s	
4377/22950 (epoch 9.536), train_loss = 1.44354004, grad/param norm = 2.1175e-01, time/batch = 0.6953s	
4378/22950 (epoch 9.538), train_loss = 1.33852408, grad/param norm = 2.1642e-01, time/batch = 0.6913s	
4379/22950 (epoch 9.540), train_loss = 1.38772497, grad/param norm = 1.8718e-01, time/batch = 0.6923s	
4380/22950 (epoch 9.542), train_loss = 1.56594719, grad/param norm = 2.1603e-01, time/batch = 0.7028s	
4381/22950 (epoch 9.545), train_loss = 1.34921165, grad/param norm = 2.1401e-01, time/batch = 0.6980s	
4382/22950 (epoch 9.547), train_loss = 1.34065329, grad/param norm = 1.8789e-01, time/batch = 0.7047s	
4383/22950 (epoch 9.549), train_loss = 1.35895822, grad/param norm = 1.8565e-01, time/batch = 0.7057s	
4384/22950 (epoch 9.551), train_loss = 1.38309290, grad/param norm = 2.0057e-01, time/batch = 0.6928s	
4385/22950 (epoch 9.553), train_loss = 1.36035776, grad/param norm = 2.2258e-01, time/batch = 0.6961s	
4386/22950 (epoch 9.556), train_loss = 1.45642868, grad/param norm = 1.8432e-01, time/batch = 0.7074s	
4387/22950 (epoch 9.558), train_loss = 1.30729432, grad/param norm = 1.9822e-01, time/batch = 0.7128s	
4388/22950 (epoch 9.560), train_loss = 1.40837311, grad/param norm = 1.8914e-01, time/batch = 0.7061s	
4389/22950 (epoch 9.562), train_loss = 1.24610971, grad/param norm = 1.8684e-01, time/batch = 0.6924s	
4390/22950 (epoch 9.564), train_loss = 1.58604120, grad/param norm = 2.3962e-01, time/batch = 0.6921s	
4391/22950 (epoch 9.566), train_loss = 1.38231631, grad/param norm = 1.9569e-01, time/batch = 0.6951s	
4392/22950 (epoch 9.569), train_loss = 1.53820722, grad/param norm = 2.0016e-01, time/batch = 0.6924s	
4393/22950 (epoch 9.571), train_loss = 1.23835240, grad/param norm = 1.9310e-01, time/batch = 0.6948s	
4394/22950 (epoch 9.573), train_loss = 1.38247727, grad/param norm = 2.0706e-01, time/batch = 0.6934s	
4395/22950 (epoch 9.575), train_loss = 1.62281902, grad/param norm = 2.1142e-01, time/batch = 0.6949s	
4396/22950 (epoch 9.577), train_loss = 1.38990024, grad/param norm = 2.2590e-01, time/batch = 0.6918s	
4397/22950 (epoch 9.580), train_loss = 1.43931236, grad/param norm = 2.0982e-01, time/batch = 0.7223s	
4398/22950 (epoch 9.582), train_loss = 1.58261882, grad/param norm = 1.9056e-01, time/batch = 0.7117s	
4399/22950 (epoch 9.584), train_loss = 1.20259899, grad/param norm = 1.7738e-01, time/batch = 0.6937s	
4400/22950 (epoch 9.586), train_loss = 1.32615089, grad/param norm = 2.0465e-01, time/batch = 0.6932s	
4401/22950 (epoch 9.588), train_loss = 1.51775181, grad/param norm = 1.9292e-01, time/batch = 0.6942s	
4402/22950 (epoch 9.590), train_loss = 1.35871120, grad/param norm = 1.9882e-01, time/batch = 0.6887s	
4403/22950 (epoch 9.593), train_loss = 1.22081934, grad/param norm = 1.9097e-01, time/batch = 0.6921s	
4404/22950 (epoch 9.595), train_loss = 1.25751055, grad/param norm = 2.0043e-01, time/batch = 0.6905s	
4405/22950 (epoch 9.597), train_loss = 1.46050446, grad/param norm = 2.2245e-01, time/batch = 0.6930s	
4406/22950 (epoch 9.599), train_loss = 1.41778330, grad/param norm = 2.1992e-01, time/batch = 0.6983s	
4407/22950 (epoch 9.601), train_loss = 1.37220535, grad/param norm = 2.0542e-01, time/batch = 0.6936s	
4408/22950 (epoch 9.603), train_loss = 1.51717127, grad/param norm = 1.9285e-01, time/batch = 0.6917s	
4409/22950 (epoch 9.606), train_loss = 1.32624574, grad/param norm = 1.9900e-01, time/batch = 0.6903s	
4410/22950 (epoch 9.608), train_loss = 1.37638238, grad/param norm = 1.9472e-01, time/batch = 0.6910s	
4411/22950 (epoch 9.610), train_loss = 1.34765830, grad/param norm = 2.0311e-01, time/batch = 0.6914s	
4412/22950 (epoch 9.612), train_loss = 1.39255247, grad/param norm = 1.9216e-01, time/batch = 0.6917s	
4413/22950 (epoch 9.614), train_loss = 1.51585816, grad/param norm = 2.1950e-01, time/batch = 0.6933s	
4414/22950 (epoch 9.617), train_loss = 1.35029297, grad/param norm = 1.9435e-01, time/batch = 0.6952s	
4415/22950 (epoch 9.619), train_loss = 1.24976223, grad/param norm = 1.7260e-01, time/batch = 0.6970s	
4416/22950 (epoch 9.621), train_loss = 1.47066716, grad/param norm = 1.9037e-01, time/batch = 0.6901s	
4417/22950 (epoch 9.623), train_loss = 1.42697010, grad/param norm = 1.7933e-01, time/batch = 0.7208s	
4418/22950 (epoch 9.625), train_loss = 1.34120284, grad/param norm = 1.7707e-01, time/batch = 0.7111s	
4419/22950 (epoch 9.627), train_loss = 1.39470739, grad/param norm = 2.0940e-01, time/batch = 0.6922s	
4420/22950 (epoch 9.630), train_loss = 1.21309693, grad/param norm = 1.7763e-01, time/batch = 0.6910s	
4421/22950 (epoch 9.632), train_loss = 1.42556730, grad/param norm = 2.0593e-01, time/batch = 0.6949s	
4422/22950 (epoch 9.634), train_loss = 1.34111339, grad/param norm = 1.9318e-01, time/batch = 0.7049s	
4423/22950 (epoch 9.636), train_loss = 1.37352738, grad/param norm = 1.9209e-01, time/batch = 0.6988s	
4424/22950 (epoch 9.638), train_loss = 1.27452927, grad/param norm = 2.0199e-01, time/batch = 0.6920s	
4425/22950 (epoch 9.641), train_loss = 1.29733187, grad/param norm = 1.8604e-01, time/batch = 0.6895s	
4426/22950 (epoch 9.643), train_loss = 1.41226745, grad/param norm = 2.2382e-01, time/batch = 0.6909s	
4427/22950 (epoch 9.645), train_loss = 1.29182852, grad/param norm = 2.0085e-01, time/batch = 0.6921s	
4428/22950 (epoch 9.647), train_loss = 1.37726736, grad/param norm = 2.0545e-01, time/batch = 0.6950s	
4429/22950 (epoch 9.649), train_loss = 1.36720218, grad/param norm = 2.0117e-01, time/batch = 0.6983s	
4430/22950 (epoch 9.651), train_loss = 1.47382713, grad/param norm = 2.1586e-01, time/batch = 0.6946s	
4431/22950 (epoch 9.654), train_loss = 1.18569754, grad/param norm = 1.8202e-01, time/batch = 0.6933s	
4432/22950 (epoch 9.656), train_loss = 1.50261056, grad/param norm = 2.1274e-01, time/batch = 0.6946s	
4433/22950 (epoch 9.658), train_loss = 1.24206352, grad/param norm = 1.8269e-01, time/batch = 0.6941s	
4434/22950 (epoch 9.660), train_loss = 1.19230469, grad/param norm = 1.7656e-01, time/batch = 0.7006s	
4435/22950 (epoch 9.662), train_loss = 1.20062383, grad/param norm = 1.8615e-01, time/batch = 0.6909s	
4436/22950 (epoch 9.664), train_loss = 1.40359439, grad/param norm = 1.8325e-01, time/batch = 0.6957s	
4437/22950 (epoch 9.667), train_loss = 1.42088426, grad/param norm = 1.9684e-01, time/batch = 0.6983s	
4438/22950 (epoch 9.669), train_loss = 1.31132259, grad/param norm = 1.9692e-01, time/batch = 0.6923s	
4439/22950 (epoch 9.671), train_loss = 1.41703269, grad/param norm = 1.9050e-01, time/batch = 0.6930s	
4440/22950 (epoch 9.673), train_loss = 1.35684321, grad/param norm = 1.8994e-01, time/batch = 0.6914s	
4441/22950 (epoch 9.675), train_loss = 1.34650042, grad/param norm = 1.9026e-01, time/batch = 0.7041s	
4442/22950 (epoch 9.678), train_loss = 1.35774928, grad/param norm = 2.0382e-01, time/batch = 0.7168s	
4443/22950 (epoch 9.680), train_loss = 1.39671940, grad/param norm = 1.8834e-01, time/batch = 0.7316s	
4444/22950 (epoch 9.682), train_loss = 1.45413111, grad/param norm = 2.0417e-01, time/batch = 0.7113s	
4445/22950 (epoch 9.684), train_loss = 1.48495485, grad/param norm = 1.9634e-01, time/batch = 0.6985s	
4446/22950 (epoch 9.686), train_loss = 1.44996872, grad/param norm = 1.9177e-01, time/batch = 0.7014s	
4447/22950 (epoch 9.688), train_loss = 1.37334546, grad/param norm = 2.0285e-01, time/batch = 0.7054s	
4448/22950 (epoch 9.691), train_loss = 1.33960447, grad/param norm = 1.9464e-01, time/batch = 0.7025s	
4449/22950 (epoch 9.693), train_loss = 1.28477765, grad/param norm = 1.9527e-01, time/batch = 0.7052s	
4450/22950 (epoch 9.695), train_loss = 1.55498708, grad/param norm = 2.0326e-01, time/batch = 0.6983s	
4451/22950 (epoch 9.697), train_loss = 1.49917859, grad/param norm = 1.9578e-01, time/batch = 0.6982s	
4452/22950 (epoch 9.699), train_loss = 1.45574532, grad/param norm = 1.9046e-01, time/batch = 0.7013s	
4453/22950 (epoch 9.702), train_loss = 1.44941307, grad/param norm = 1.9203e-01, time/batch = 0.7145s	
4454/22950 (epoch 9.704), train_loss = 1.45480063, grad/param norm = 2.1503e-01, time/batch = 0.7181s	
4455/22950 (epoch 9.706), train_loss = 1.51621158, grad/param norm = 2.1170e-01, time/batch = 0.7130s	
4456/22950 (epoch 9.708), train_loss = 1.34716899, grad/param norm = 2.1109e-01, time/batch = 0.6957s	
4457/22950 (epoch 9.710), train_loss = 1.43858171, grad/param norm = 1.8240e-01, time/batch = 0.7019s	
4458/22950 (epoch 9.712), train_loss = 1.53421794, grad/param norm = 1.9077e-01, time/batch = 0.6972s	
4459/22950 (epoch 9.715), train_loss = 1.45995546, grad/param norm = 2.0397e-01, time/batch = 0.6931s	
4460/22950 (epoch 9.717), train_loss = 1.27320745, grad/param norm = 1.7735e-01, time/batch = 0.6918s	
4461/22950 (epoch 9.719), train_loss = 1.33608618, grad/param norm = 2.0232e-01, time/batch = 0.6916s	
4462/22950 (epoch 9.721), train_loss = 1.43439265, grad/param norm = 1.8993e-01, time/batch = 0.6944s	
4463/22950 (epoch 9.723), train_loss = 1.27711357, grad/param norm = 1.8554e-01, time/batch = 0.6917s	
4464/22950 (epoch 9.725), train_loss = 1.49290013, grad/param norm = 1.9874e-01, time/batch = 0.6920s	
4465/22950 (epoch 9.728), train_loss = 1.39298091, grad/param norm = 1.9547e-01, time/batch = 0.6958s	
4466/22950 (epoch 9.730), train_loss = 1.38402917, grad/param norm = 1.9676e-01, time/batch = 0.6924s	
4467/22950 (epoch 9.732), train_loss = 1.39677473, grad/param norm = 1.7857e-01, time/batch = 0.6937s	
4468/22950 (epoch 9.734), train_loss = 1.38862278, grad/param norm = 1.9668e-01, time/batch = 0.6943s	
4469/22950 (epoch 9.736), train_loss = 1.31784538, grad/param norm = 1.9475e-01, time/batch = 0.6924s	
4470/22950 (epoch 9.739), train_loss = 1.44961283, grad/param norm = 1.9593e-01, time/batch = 0.6956s	
4471/22950 (epoch 9.741), train_loss = 1.40386687, grad/param norm = 1.9437e-01, time/batch = 0.6941s	
4472/22950 (epoch 9.743), train_loss = 1.57137198, grad/param norm = 2.0788e-01, time/batch = 0.6953s	
4473/22950 (epoch 9.745), train_loss = 1.63370253, grad/param norm = 2.1311e-01, time/batch = 0.6944s	
4474/22950 (epoch 9.747), train_loss = 1.40138014, grad/param norm = 1.9373e-01, time/batch = 0.7013s	
4475/22950 (epoch 9.749), train_loss = 1.28370323, grad/param norm = 1.9932e-01, time/batch = 0.6961s	
4476/22950 (epoch 9.752), train_loss = 1.57922043, grad/param norm = 2.1242e-01, time/batch = 0.6967s	
4477/22950 (epoch 9.754), train_loss = 1.45475140, grad/param norm = 2.0325e-01, time/batch = 0.6952s	
4478/22950 (epoch 9.756), train_loss = 1.29450622, grad/param norm = 2.0609e-01, time/batch = 0.6948s	
4479/22950 (epoch 9.758), train_loss = 1.32923265, grad/param norm = 1.9584e-01, time/batch = 0.6945s	
4480/22950 (epoch 9.760), train_loss = 1.41858471, grad/param norm = 1.9456e-01, time/batch = 0.6914s	
4481/22950 (epoch 9.763), train_loss = 1.39962024, grad/param norm = 2.0134e-01, time/batch = 0.7177s	
4482/22950 (epoch 9.765), train_loss = 1.46068799, grad/param norm = 1.9652e-01, time/batch = 0.7165s	
4483/22950 (epoch 9.767), train_loss = 1.60992695, grad/param norm = 2.1025e-01, time/batch = 0.6965s	
4484/22950 (epoch 9.769), train_loss = 1.40284423, grad/param norm = 1.9532e-01, time/batch = 0.7053s	
4485/22950 (epoch 9.771), train_loss = 1.27627303, grad/param norm = 2.1119e-01, time/batch = 0.7007s	
4486/22950 (epoch 9.773), train_loss = 1.08938082, grad/param norm = 1.7696e-01, time/batch = 0.7140s	
4487/22950 (epoch 9.776), train_loss = 1.30182751, grad/param norm = 1.8732e-01, time/batch = 0.7071s	
4488/22950 (epoch 9.778), train_loss = 1.21922321, grad/param norm = 1.7967e-01, time/batch = 0.7055s	
4489/22950 (epoch 9.780), train_loss = 1.26971502, grad/param norm = 1.7227e-01, time/batch = 0.6995s	
4490/22950 (epoch 9.782), train_loss = 1.30763656, grad/param norm = 1.9056e-01, time/batch = 0.7038s	
4491/22950 (epoch 9.784), train_loss = 1.41134223, grad/param norm = 2.0813e-01, time/batch = 0.7170s	
4492/22950 (epoch 9.786), train_loss = 1.44126475, grad/param norm = 1.8271e-01, time/batch = 0.6919s	
4493/22950 (epoch 9.789), train_loss = 1.20186943, grad/param norm = 1.8908e-01, time/batch = 0.6962s	
4494/22950 (epoch 9.791), train_loss = 1.25266394, grad/param norm = 1.9607e-01, time/batch = 0.6961s	
4495/22950 (epoch 9.793), train_loss = 1.62858854, grad/param norm = 2.0525e-01, time/batch = 0.6954s	
4496/22950 (epoch 9.795), train_loss = 1.29641973, grad/param norm = 1.8048e-01, time/batch = 0.6943s	
4497/22950 (epoch 9.797), train_loss = 1.57551628, grad/param norm = 2.1600e-01, time/batch = 0.7035s	
4498/22950 (epoch 9.800), train_loss = 1.28874684, grad/param norm = 1.9864e-01, time/batch = 0.6863s	
4499/22950 (epoch 9.802), train_loss = 1.30555385, grad/param norm = 1.9050e-01, time/batch = 0.6902s	
4500/22950 (epoch 9.804), train_loss = 1.34512830, grad/param norm = 1.9519e-01, time/batch = 0.6966s	
4501/22950 (epoch 9.806), train_loss = 1.24309355, grad/param norm = 1.8621e-01, time/batch = 0.7112s	
4502/22950 (epoch 9.808), train_loss = 1.31967822, grad/param norm = 1.9731e-01, time/batch = 0.6917s	
4503/22950 (epoch 9.810), train_loss = 1.30655449, grad/param norm = 1.9582e-01, time/batch = 0.6727s	
4504/22950 (epoch 9.813), train_loss = 1.14409545, grad/param norm = 1.8207e-01, time/batch = 0.6727s	
4505/22950 (epoch 9.815), train_loss = 1.24123361, grad/param norm = 1.7314e-01, time/batch = 0.6740s	
4506/22950 (epoch 9.817), train_loss = 1.20976625, grad/param norm = 1.7539e-01, time/batch = 0.6736s	
4507/22950 (epoch 9.819), train_loss = 1.31923718, grad/param norm = 1.9820e-01, time/batch = 0.6733s	
4508/22950 (epoch 9.821), train_loss = 1.38865972, grad/param norm = 2.0879e-01, time/batch = 0.6723s	
4509/22950 (epoch 9.824), train_loss = 1.33864264, grad/param norm = 2.0848e-01, time/batch = 0.6721s	
4510/22950 (epoch 9.826), train_loss = 1.46074123, grad/param norm = 2.1848e-01, time/batch = 0.6727s	
4511/22950 (epoch 9.828), train_loss = 1.33686307, grad/param norm = 1.9951e-01, time/batch = 0.6708s	
4512/22950 (epoch 9.830), train_loss = 1.37067867, grad/param norm = 1.9028e-01, time/batch = 0.6730s	
4513/22950 (epoch 9.832), train_loss = 1.40457766, grad/param norm = 2.0551e-01, time/batch = 0.6749s	
4514/22950 (epoch 9.834), train_loss = 1.24301979, grad/param norm = 1.9187e-01, time/batch = 0.6736s	
4515/22950 (epoch 9.837), train_loss = 1.36732191, grad/param norm = 2.0067e-01, time/batch = 0.6867s	
4516/22950 (epoch 9.839), train_loss = 1.24334440, grad/param norm = 1.9005e-01, time/batch = 0.6846s	
4517/22950 (epoch 9.841), train_loss = 1.24203699, grad/param norm = 1.6809e-01, time/batch = 0.6719s	
4518/22950 (epoch 9.843), train_loss = 1.30471428, grad/param norm = 2.0417e-01, time/batch = 0.6705s	
4519/22950 (epoch 9.845), train_loss = 1.36641123, grad/param norm = 2.0415e-01, time/batch = 0.6712s	
4520/22950 (epoch 9.847), train_loss = 1.45969520, grad/param norm = 1.8777e-01, time/batch = 0.6735s	
4521/22950 (epoch 9.850), train_loss = 1.41444103, grad/param norm = 2.3042e-01, time/batch = 0.6719s	
4522/22950 (epoch 9.852), train_loss = 1.44251214, grad/param norm = 2.0108e-01, time/batch = 0.6712s	
4523/22950 (epoch 9.854), train_loss = 1.35740842, grad/param norm = 2.0191e-01, time/batch = 0.6725s	
4524/22950 (epoch 9.856), train_loss = 1.57295803, grad/param norm = 2.1197e-01, time/batch = 0.6738s	
4525/22950 (epoch 9.858), train_loss = 1.40086648, grad/param norm = 1.9975e-01, time/batch = 0.6736s	
4526/22950 (epoch 9.861), train_loss = 1.48753510, grad/param norm = 2.1531e-01, time/batch = 0.6723s	
4527/22950 (epoch 9.863), train_loss = 1.53456161, grad/param norm = 2.1069e-01, time/batch = 0.6755s	
4528/22950 (epoch 9.865), train_loss = 1.59760289, grad/param norm = 2.1264e-01, time/batch = 0.7051s	
4529/22950 (epoch 9.867), train_loss = 1.42040738, grad/param norm = 1.9984e-01, time/batch = 0.7090s	
4530/22950 (epoch 9.869), train_loss = 1.60417808, grad/param norm = 2.1199e-01, time/batch = 0.6937s	
4531/22950 (epoch 9.871), train_loss = 1.38229689, grad/param norm = 2.1449e-01, time/batch = 0.6837s	
4532/22950 (epoch 9.874), train_loss = 1.35903045, grad/param norm = 2.0985e-01, time/batch = 0.6765s	
4533/22950 (epoch 9.876), train_loss = 1.42864595, grad/param norm = 1.9208e-01, time/batch = 0.6741s	
4534/22950 (epoch 9.878), train_loss = 1.30940348, grad/param norm = 2.0311e-01, time/batch = 0.6768s	
4535/22950 (epoch 9.880), train_loss = 1.53928762, grad/param norm = 1.9405e-01, time/batch = 0.6864s	
4536/22950 (epoch 9.882), train_loss = 1.24255516, grad/param norm = 1.9044e-01, time/batch = 0.6831s	
4537/22950 (epoch 9.885), train_loss = 1.40436373, grad/param norm = 2.0416e-01, time/batch = 0.6789s	
4538/22950 (epoch 9.887), train_loss = 1.38540297, grad/param norm = 2.0066e-01, time/batch = 0.6824s	
4539/22950 (epoch 9.889), train_loss = 1.49131640, grad/param norm = 2.3492e-01, time/batch = 0.7228s	
4540/22950 (epoch 9.891), train_loss = 1.39219406, grad/param norm = 2.0223e-01, time/batch = 0.7120s	
4541/22950 (epoch 9.893), train_loss = 1.39090626, grad/param norm = 1.9707e-01, time/batch = 0.6985s	
4542/22950 (epoch 9.895), train_loss = 1.54105935, grad/param norm = 2.0092e-01, time/batch = 0.6936s	
4543/22950 (epoch 9.898), train_loss = 1.37821093, grad/param norm = 1.9441e-01, time/batch = 0.6957s	
4544/22950 (epoch 9.900), train_loss = 1.24646876, grad/param norm = 1.7443e-01, time/batch = 0.6943s	
4545/22950 (epoch 9.902), train_loss = 1.44180342, grad/param norm = 1.9657e-01, time/batch = 0.6920s	
4546/22950 (epoch 9.904), train_loss = 1.43831717, grad/param norm = 1.9988e-01, time/batch = 0.6911s	
4547/22950 (epoch 9.906), train_loss = 1.39258963, grad/param norm = 1.8705e-01, time/batch = 0.6879s	
4548/22950 (epoch 9.908), train_loss = 1.25873267, grad/param norm = 1.9654e-01, time/batch = 0.6944s	
4549/22950 (epoch 9.911), train_loss = 1.20507959, grad/param norm = 1.6978e-01, time/batch = 0.6946s	
4550/22950 (epoch 9.913), train_loss = 1.32989237, grad/param norm = 1.8809e-01, time/batch = 0.6916s	
4551/22950 (epoch 9.915), train_loss = 1.52151834, grad/param norm = 2.2032e-01, time/batch = 0.6910s	
4552/22950 (epoch 9.917), train_loss = 1.20522828, grad/param norm = 1.9036e-01, time/batch = 0.6939s	
4553/22950 (epoch 9.919), train_loss = 1.34452943, grad/param norm = 1.9416e-01, time/batch = 0.6904s	
4554/22950 (epoch 9.922), train_loss = 1.36563408, grad/param norm = 2.0130e-01, time/batch = 0.6948s	
4555/22950 (epoch 9.924), train_loss = 1.43595138, grad/param norm = 1.8869e-01, time/batch = 0.6944s	
4556/22950 (epoch 9.926), train_loss = 1.22723308, grad/param norm = 1.8915e-01, time/batch = 0.6923s	
4557/22950 (epoch 9.928), train_loss = 1.22280237, grad/param norm = 1.9634e-01, time/batch = 0.6907s	
4558/22950 (epoch 9.930), train_loss = 1.19088541, grad/param norm = 2.0638e-01, time/batch = 0.6924s	
4559/22950 (epoch 9.932), train_loss = 1.18494178, grad/param norm = 1.8428e-01, time/batch = 0.6916s	
4560/22950 (epoch 9.935), train_loss = 1.40090882, grad/param norm = 2.0969e-01, time/batch = 0.6877s	
4561/22950 (epoch 9.937), train_loss = 1.41019523, grad/param norm = 2.1652e-01, time/batch = 0.6971s	
4562/22950 (epoch 9.939), train_loss = 1.29688521, grad/param norm = 2.0454e-01, time/batch = 0.7047s	
4563/22950 (epoch 9.941), train_loss = 1.26919617, grad/param norm = 1.9516e-01, time/batch = 0.6951s	
4564/22950 (epoch 9.943), train_loss = 1.37988549, grad/param norm = 1.9611e-01, time/batch = 0.6938s	
4565/22950 (epoch 9.946), train_loss = 1.23529395, grad/param norm = 1.9872e-01, time/batch = 0.6930s	
4566/22950 (epoch 9.948), train_loss = 1.40320089, grad/param norm = 1.8745e-01, time/batch = 0.6915s	
4567/22950 (epoch 9.950), train_loss = 1.42603989, grad/param norm = 2.0854e-01, time/batch = 0.6918s	
4568/22950 (epoch 9.952), train_loss = 1.40674458, grad/param norm = 2.0550e-01, time/batch = 0.6936s	
4569/22950 (epoch 9.954), train_loss = 1.35347558, grad/param norm = 1.8769e-01, time/batch = 0.6920s	
4570/22950 (epoch 9.956), train_loss = 1.28415596, grad/param norm = 1.8308e-01, time/batch = 0.6902s	
4571/22950 (epoch 9.959), train_loss = 1.24627790, grad/param norm = 1.9883e-01, time/batch = 0.6939s	
4572/22950 (epoch 9.961), train_loss = 1.38459427, grad/param norm = 1.9662e-01, time/batch = 0.6917s	
4573/22950 (epoch 9.963), train_loss = 1.42953174, grad/param norm = 2.0382e-01, time/batch = 0.6891s	
4574/22950 (epoch 9.965), train_loss = 1.56500816, grad/param norm = 2.0633e-01, time/batch = 0.6912s	
4575/22950 (epoch 9.967), train_loss = 1.36048811, grad/param norm = 2.1421e-01, time/batch = 0.6902s	
4576/22950 (epoch 9.969), train_loss = 1.27086994, grad/param norm = 1.8866e-01, time/batch = 0.6866s	
4577/22950 (epoch 9.972), train_loss = 1.35030943, grad/param norm = 1.9503e-01, time/batch = 0.6907s	
4578/22950 (epoch 9.974), train_loss = 1.26286670, grad/param norm = 1.9195e-01, time/batch = 0.7034s	
4579/22950 (epoch 9.976), train_loss = 1.18166934, grad/param norm = 1.9108e-01, time/batch = 0.6992s	
4580/22950 (epoch 9.978), train_loss = 1.33094292, grad/param norm = 2.1179e-01, time/batch = 0.7038s	
4581/22950 (epoch 9.980), train_loss = 1.35008406, grad/param norm = 2.0378e-01, time/batch = 0.7082s	
4582/22950 (epoch 9.983), train_loss = 1.24871807, grad/param norm = 1.8211e-01, time/batch = 0.7123s	
4583/22950 (epoch 9.985), train_loss = 1.19830161, grad/param norm = 1.8539e-01, time/batch = 0.6928s	
4584/22950 (epoch 9.987), train_loss = 1.25323361, grad/param norm = 1.8424e-01, time/batch = 0.6898s	
4585/22950 (epoch 9.989), train_loss = 1.39122371, grad/param norm = 1.8617e-01, time/batch = 0.6941s	
4586/22950 (epoch 9.991), train_loss = 1.20319151, grad/param norm = 1.9402e-01, time/batch = 0.7225s	
4587/22950 (epoch 9.993), train_loss = 1.38281355, grad/param norm = 2.0956e-01, time/batch = 0.7108s	
4588/22950 (epoch 9.996), train_loss = 1.44780083, grad/param norm = 1.9870e-01, time/batch = 0.6887s	
4589/22950 (epoch 9.998), train_loss = 1.30257913, grad/param norm = 1.9268e-01, time/batch = 0.6855s	
decayed learning rate by a factor 0.97 to 0.00194	
4590/22950 (epoch 10.000), train_loss = 1.19532712, grad/param norm = 1.9008e-01, time/batch = 0.6874s	
4591/22950 (epoch 10.002), train_loss = 1.55697220, grad/param norm = 2.1098e-01, time/batch = 0.6891s	
4592/22950 (epoch 10.004), train_loss = 1.38795583, grad/param norm = 2.0080e-01, time/batch = 0.6903s	
4593/22950 (epoch 10.007), train_loss = 1.34169216, grad/param norm = 1.9009e-01, time/batch = 0.6917s	
4594/22950 (epoch 10.009), train_loss = 1.46249391, grad/param norm = 1.8910e-01, time/batch = 0.6915s	
4595/22950 (epoch 10.011), train_loss = 1.29609599, grad/param norm = 1.9248e-01, time/batch = 0.6924s	
4596/22950 (epoch 10.013), train_loss = 1.47631419, grad/param norm = 2.2148e-01, time/batch = 0.6878s	
4597/22950 (epoch 10.015), train_loss = 1.44841142, grad/param norm = 2.0148e-01, time/batch = 0.6875s	
4598/22950 (epoch 10.017), train_loss = 1.31535421, grad/param norm = 1.7999e-01, time/batch = 0.6884s	
4599/22950 (epoch 10.020), train_loss = 1.30770615, grad/param norm = 1.7948e-01, time/batch = 0.6898s	
4600/22950 (epoch 10.022), train_loss = 1.16261761, grad/param norm = 1.7850e-01, time/batch = 0.6908s	
4601/22950 (epoch 10.024), train_loss = 1.23589282, grad/param norm = 1.8633e-01, time/batch = 0.6965s	
4602/22950 (epoch 10.026), train_loss = 1.35919548, grad/param norm = 1.9759e-01, time/batch = 0.6892s	
4603/22950 (epoch 10.028), train_loss = 1.41510764, grad/param norm = 1.9522e-01, time/batch = 0.6901s	
4604/22950 (epoch 10.031), train_loss = 1.34867065, grad/param norm = 1.8453e-01, time/batch = 0.6896s	
4605/22950 (epoch 10.033), train_loss = 1.53796848, grad/param norm = 2.2069e-01, time/batch = 0.6911s	
4606/22950 (epoch 10.035), train_loss = 1.31816772, grad/param norm = 1.7054e-01, time/batch = 0.7028s	
4607/22950 (epoch 10.037), train_loss = 1.30835873, grad/param norm = 1.9644e-01, time/batch = 0.6984s	
4608/22950 (epoch 10.039), train_loss = 1.32634949, grad/param norm = 2.0413e-01, time/batch = 0.6996s	
4609/22950 (epoch 10.041), train_loss = 1.29305691, grad/param norm = 1.7798e-01, time/batch = 0.6976s	
4610/22950 (epoch 10.044), train_loss = 1.33190456, grad/param norm = 1.9435e-01, time/batch = 0.6990s	
4611/22950 (epoch 10.046), train_loss = 1.37772392, grad/param norm = 1.9189e-01, time/batch = 0.6912s	
4612/22950 (epoch 10.048), train_loss = 1.37505380, grad/param norm = 1.9806e-01, time/batch = 0.6878s	
4613/22950 (epoch 10.050), train_loss = 1.41078720, grad/param norm = 2.0648e-01, time/batch = 0.6904s	
4614/22950 (epoch 10.052), train_loss = 1.36287319, grad/param norm = 1.9194e-01, time/batch = 0.7183s	
4615/22950 (epoch 10.054), train_loss = 1.60100653, grad/param norm = 2.0906e-01, time/batch = 0.7249s	
4616/22950 (epoch 10.057), train_loss = 1.44896477, grad/param norm = 2.0240e-01, time/batch = 0.7313s	
4617/22950 (epoch 10.059), train_loss = 1.41735488, grad/param norm = 1.9893e-01, time/batch = 0.7280s	
4618/22950 (epoch 10.061), train_loss = 1.23953406, grad/param norm = 1.9166e-01, time/batch = 0.7039s	
4619/22950 (epoch 10.063), train_loss = 1.40723751, grad/param norm = 1.8373e-01, time/batch = 0.7200s	
4620/22950 (epoch 10.065), train_loss = 1.08553116, grad/param norm = 1.8888e-01, time/batch = 0.7206s	
4621/22950 (epoch 10.068), train_loss = 1.44148575, grad/param norm = 2.1051e-01, time/batch = 0.7159s	
4622/22950 (epoch 10.070), train_loss = 1.20586708, grad/param norm = 1.8143e-01, time/batch = 0.6920s	
4623/22950 (epoch 10.072), train_loss = 1.38278356, grad/param norm = 2.1368e-01, time/batch = 0.6941s	
4624/22950 (epoch 10.074), train_loss = 1.33719357, grad/param norm = 2.1568e-01, time/batch = 0.6927s	
4625/22950 (epoch 10.076), train_loss = 1.33637780, grad/param norm = 1.9626e-01, time/batch = 0.6948s	
4626/22950 (epoch 10.078), train_loss = 1.47281763, grad/param norm = 2.1246e-01, time/batch = 0.7122s	
4627/22950 (epoch 10.081), train_loss = 1.45532507, grad/param norm = 1.9849e-01, time/batch = 0.7199s	
4628/22950 (epoch 10.083), train_loss = 1.29879532, grad/param norm = 2.1310e-01, time/batch = 0.6940s	
4629/22950 (epoch 10.085), train_loss = 1.24934829, grad/param norm = 1.9903e-01, time/batch = 0.6971s	
4630/22950 (epoch 10.087), train_loss = 1.27290074, grad/param norm = 1.9831e-01, time/batch = 0.6991s	
4631/22950 (epoch 10.089), train_loss = 1.37652828, grad/param norm = 1.9630e-01, time/batch = 0.6909s	
4632/22950 (epoch 10.092), train_loss = 1.32873022, grad/param norm = 1.9822e-01, time/batch = 0.6895s	
4633/22950 (epoch 10.094), train_loss = 1.28261204, grad/param norm = 2.0078e-01, time/batch = 0.6946s	
4634/22950 (epoch 10.096), train_loss = 1.50203825, grad/param norm = 2.0294e-01, time/batch = 0.6935s	
4635/22950 (epoch 10.098), train_loss = 1.37157984, grad/param norm = 1.9919e-01, time/batch = 0.6904s	
4636/22950 (epoch 10.100), train_loss = 1.26954116, grad/param norm = 1.8744e-01, time/batch = 0.7081s	
4637/22950 (epoch 10.102), train_loss = 1.34909878, grad/param norm = 1.8384e-01, time/batch = 0.7169s	
4638/22950 (epoch 10.105), train_loss = 1.19408485, grad/param norm = 1.6667e-01, time/batch = 0.6868s	
4639/22950 (epoch 10.107), train_loss = 1.28600859, grad/param norm = 1.8763e-01, time/batch = 0.6876s	
4640/22950 (epoch 10.109), train_loss = 1.29669435, grad/param norm = 1.9572e-01, time/batch = 0.6896s	
4641/22950 (epoch 10.111), train_loss = 1.21139443, grad/param norm = 1.8531e-01, time/batch = 0.6891s	
4642/22950 (epoch 10.113), train_loss = 1.36951296, grad/param norm = 1.9686e-01, time/batch = 0.6903s	
4643/22950 (epoch 10.115), train_loss = 1.39193654, grad/param norm = 2.1414e-01, time/batch = 0.6907s	
4644/22950 (epoch 10.118), train_loss = 1.49415605, grad/param norm = 1.9470e-01, time/batch = 0.6915s	
4645/22950 (epoch 10.120), train_loss = 1.25354515, grad/param norm = 1.8724e-01, time/batch = 0.6886s	
4646/22950 (epoch 10.122), train_loss = 1.49030192, grad/param norm = 2.0782e-01, time/batch = 0.6873s	
4647/22950 (epoch 10.124), train_loss = 1.11716892, grad/param norm = 1.5096e-01, time/batch = 0.6922s	
4648/22950 (epoch 10.126), train_loss = 1.30776380, grad/param norm = 1.9281e-01, time/batch = 0.6933s	
4649/22950 (epoch 10.129), train_loss = 1.17332770, grad/param norm = 1.7705e-01, time/batch = 0.6883s	
4650/22950 (epoch 10.131), train_loss = 1.30117733, grad/param norm = 2.0667e-01, time/batch = 0.6870s	
4651/22950 (epoch 10.133), train_loss = 1.43729764, grad/param norm = 2.1457e-01, time/batch = 0.6873s	
4652/22950 (epoch 10.135), train_loss = 1.32020969, grad/param norm = 1.9175e-01, time/batch = 0.6898s	
4653/22950 (epoch 10.137), train_loss = 1.53288728, grad/param norm = 2.1034e-01, time/batch = 0.6907s	
4654/22950 (epoch 10.139), train_loss = 1.28647569, grad/param norm = 2.2184e-01, time/batch = 0.6903s	
4655/22950 (epoch 10.142), train_loss = 1.25170421, grad/param norm = 1.8566e-01, time/batch = 0.6972s	
4656/22950 (epoch 10.144), train_loss = 1.23770495, grad/param norm = 1.8949e-01, time/batch = 0.7025s	
4657/22950 (epoch 10.146), train_loss = 1.34410888, grad/param norm = 2.0400e-01, time/batch = 0.7209s	
4658/22950 (epoch 10.148), train_loss = 1.28589938, grad/param norm = 1.7890e-01, time/batch = 0.6907s	
4659/22950 (epoch 10.150), train_loss = 1.32467430, grad/param norm = 1.9085e-01, time/batch = 0.6905s	
4660/22950 (epoch 10.153), train_loss = 1.29860341, grad/param norm = 1.9223e-01, time/batch = 0.6898s	
4661/22950 (epoch 10.155), train_loss = 1.26027390, grad/param norm = 1.7353e-01, time/batch = 0.6905s	
4662/22950 (epoch 10.157), train_loss = 1.26797322, grad/param norm = 2.0149e-01, time/batch = 0.7037s	
4663/22950 (epoch 10.159), train_loss = 1.21967454, grad/param norm = 1.7515e-01, time/batch = 0.7071s	
4664/22950 (epoch 10.161), train_loss = 1.30456160, grad/param norm = 1.7992e-01, time/batch = 0.7072s	
4665/22950 (epoch 10.163), train_loss = 1.23617834, grad/param norm = 1.8711e-01, time/batch = 0.7146s	
4666/22950 (epoch 10.166), train_loss = 1.50149593, grad/param norm = 2.0307e-01, time/batch = 0.7154s	
4667/22950 (epoch 10.168), train_loss = 1.48585378, grad/param norm = 2.2469e-01, time/batch = 0.7147s	
4668/22950 (epoch 10.170), train_loss = 1.40131855, grad/param norm = 2.0744e-01, time/batch = 0.6871s	
4669/22950 (epoch 10.172), train_loss = 1.33279896, grad/param norm = 1.9289e-01, time/batch = 0.6896s	
4670/22950 (epoch 10.174), train_loss = 1.43322273, grad/param norm = 2.0737e-01, time/batch = 0.6884s	
4671/22950 (epoch 10.176), train_loss = 1.49554661, grad/param norm = 1.9302e-01, time/batch = 0.6920s	
4672/22950 (epoch 10.179), train_loss = 1.38622576, grad/param norm = 1.9606e-01, time/batch = 0.6906s	
4673/22950 (epoch 10.181), train_loss = 1.52475351, grad/param norm = 1.9302e-01, time/batch = 0.6934s	
4674/22950 (epoch 10.183), train_loss = 1.43683142, grad/param norm = 2.0431e-01, time/batch = 0.6859s	
4675/22950 (epoch 10.185), train_loss = 1.40033814, grad/param norm = 1.9004e-01, time/batch = 0.6856s	
4676/22950 (epoch 10.187), train_loss = 1.19270116, grad/param norm = 1.9161e-01, time/batch = 0.7040s	
4677/22950 (epoch 10.190), train_loss = 1.25063706, grad/param norm = 2.0067e-01, time/batch = 0.7201s	
4678/22950 (epoch 10.192), train_loss = 1.23062068, grad/param norm = 1.8345e-01, time/batch = 0.6883s	
4679/22950 (epoch 10.194), train_loss = 1.29630183, grad/param norm = 2.1569e-01, time/batch = 0.6878s	
4680/22950 (epoch 10.196), train_loss = 1.15783126, grad/param norm = 1.9031e-01, time/batch = 0.6865s	
4681/22950 (epoch 10.198), train_loss = 1.42563486, grad/param norm = 1.9228e-01, time/batch = 0.6878s	
4682/22950 (epoch 10.200), train_loss = 1.20346917, grad/param norm = 1.8088e-01, time/batch = 0.6882s	
4683/22950 (epoch 10.203), train_loss = 1.14653756, grad/param norm = 1.7789e-01, time/batch = 0.6882s	
4684/22950 (epoch 10.205), train_loss = 1.26846412, grad/param norm = 1.9735e-01, time/batch = 0.6869s	
4685/22950 (epoch 10.207), train_loss = 1.29364287, grad/param norm = 1.8647e-01, time/batch = 0.6892s	
4686/22950 (epoch 10.209), train_loss = 1.45336630, grad/param norm = 2.0217e-01, time/batch = 0.7022s	
4687/22950 (epoch 10.211), train_loss = 1.17105441, grad/param norm = 2.0664e-01, time/batch = 0.7226s	
4688/22950 (epoch 10.214), train_loss = 1.31195222, grad/param norm = 1.8859e-01, time/batch = 0.6891s	
4689/22950 (epoch 10.216), train_loss = 1.43178823, grad/param norm = 2.0381e-01, time/batch = 0.6894s	
4690/22950 (epoch 10.218), train_loss = 1.32634632, grad/param norm = 1.8651e-01, time/batch = 0.6890s	
4691/22950 (epoch 10.220), train_loss = 1.47966315, grad/param norm = 2.1306e-01, time/batch = 0.6916s	
4692/22950 (epoch 10.222), train_loss = 1.44077043, grad/param norm = 1.9686e-01, time/batch = 0.6933s	
4693/22950 (epoch 10.224), train_loss = 1.30035960, grad/param norm = 1.9388e-01, time/batch = 0.6894s	
4694/22950 (epoch 10.227), train_loss = 1.35956373, grad/param norm = 1.8287e-01, time/batch = 0.6876s	
4695/22950 (epoch 10.229), train_loss = 1.38417245, grad/param norm = 2.1774e-01, time/batch = 0.6910s	
4696/22950 (epoch 10.231), train_loss = 1.19403998, grad/param norm = 1.8145e-01, time/batch = 0.7021s	
4697/22950 (epoch 10.233), train_loss = 1.28438072, grad/param norm = 1.8963e-01, time/batch = 0.7228s	
4698/22950 (epoch 10.235), train_loss = 1.46900533, grad/param norm = 1.9925e-01, time/batch = 0.6902s	
4699/22950 (epoch 10.237), train_loss = 1.22105192, grad/param norm = 1.8234e-01, time/batch = 0.6987s	
4700/22950 (epoch 10.240), train_loss = 1.32063276, grad/param norm = 2.1722e-01, time/batch = 0.7122s	
4701/22950 (epoch 10.242), train_loss = 1.44862377, grad/param norm = 2.0749e-01, time/batch = 0.7322s	
4702/22950 (epoch 10.244), train_loss = 1.54634788, grad/param norm = 2.3421e-01, time/batch = 0.7334s	
4703/22950 (epoch 10.246), train_loss = 1.47254999, grad/param norm = 2.0144e-01, time/batch = 0.7304s	
4704/22950 (epoch 10.248), train_loss = 1.39205521, grad/param norm = 2.2085e-01, time/batch = 0.7283s	
4705/22950 (epoch 10.251), train_loss = 1.30119947, grad/param norm = 1.9994e-01, time/batch = 0.7263s	
4706/22950 (epoch 10.253), train_loss = 1.29884673, grad/param norm = 2.1139e-01, time/batch = 0.7322s	
4707/22950 (epoch 10.255), train_loss = 1.32521883, grad/param norm = 2.0446e-01, time/batch = 0.7251s	
4708/22950 (epoch 10.257), train_loss = 1.44831687, grad/param norm = 2.0676e-01, time/batch = 0.6964s	
4709/22950 (epoch 10.259), train_loss = 1.19341981, grad/param norm = 1.9837e-01, time/batch = 0.6907s	
4710/22950 (epoch 10.261), train_loss = 1.32372172, grad/param norm = 1.9945e-01, time/batch = 0.6854s	
4711/22950 (epoch 10.264), train_loss = 1.23896321, grad/param norm = 1.7120e-01, time/batch = 0.6867s	
4712/22950 (epoch 10.266), train_loss = 1.39892565, grad/param norm = 1.9226e-01, time/batch = 0.6881s	
4713/22950 (epoch 10.268), train_loss = 1.38943390, grad/param norm = 1.8426e-01, time/batch = 0.6894s	
4714/22950 (epoch 10.270), train_loss = 1.35825980, grad/param norm = 1.8747e-01, time/batch = 0.6835s	
4715/22950 (epoch 10.272), train_loss = 1.47537330, grad/param norm = 1.9703e-01, time/batch = 0.6905s	
4716/22950 (epoch 10.275), train_loss = 1.27064722, grad/param norm = 1.9850e-01, time/batch = 0.7129s	
4717/22950 (epoch 10.277), train_loss = 1.18024751, grad/param norm = 1.7104e-01, time/batch = 0.7138s	
4718/22950 (epoch 10.279), train_loss = 1.36168631, grad/param norm = 2.1041e-01, time/batch = 0.6855s	
4719/22950 (epoch 10.281), train_loss = 1.24685745, grad/param norm = 1.9398e-01, time/batch = 0.6924s	
4720/22950 (epoch 10.283), train_loss = 1.13876241, grad/param norm = 1.8035e-01, time/batch = 0.6915s	
4721/22950 (epoch 10.285), train_loss = 1.31693276, grad/param norm = 1.7610e-01, time/batch = 0.6881s	
4722/22950 (epoch 10.288), train_loss = 1.32623060, grad/param norm = 1.7352e-01, time/batch = 0.6863s	
4723/22950 (epoch 10.290), train_loss = 1.23362559, grad/param norm = 1.7345e-01, time/batch = 0.6864s	
4724/22950 (epoch 10.292), train_loss = 1.37523187, grad/param norm = 1.8837e-01, time/batch = 0.6845s	
4725/22950 (epoch 10.294), train_loss = 1.33196718, grad/param norm = 1.9040e-01, time/batch = 0.6893s	
4726/22950 (epoch 10.296), train_loss = 1.11291019, grad/param norm = 1.6759e-01, time/batch = 0.6876s	
4727/22950 (epoch 10.298), train_loss = 1.31834410, grad/param norm = 1.8229e-01, time/batch = 0.6833s	
4728/22950 (epoch 10.301), train_loss = 1.36946631, grad/param norm = 1.9110e-01, time/batch = 0.6921s	
4729/22950 (epoch 10.303), train_loss = 1.38766493, grad/param norm = 2.0283e-01, time/batch = 0.6891s	
4730/22950 (epoch 10.305), train_loss = 1.41599715, grad/param norm = 2.0629e-01, time/batch = 0.6852s	
4731/22950 (epoch 10.307), train_loss = 1.47095384, grad/param norm = 2.1149e-01, time/batch = 0.6862s	
4732/22950 (epoch 10.309), train_loss = 1.30888572, grad/param norm = 1.7409e-01, time/batch = 0.6881s	
4733/22950 (epoch 10.312), train_loss = 1.35009501, grad/param norm = 2.0006e-01, time/batch = 0.6883s	
4734/22950 (epoch 10.314), train_loss = 1.24758062, grad/param norm = 1.8079e-01, time/batch = 0.6889s	
4735/22950 (epoch 10.316), train_loss = 1.35049129, grad/param norm = 1.9776e-01, time/batch = 0.6884s	
4736/22950 (epoch 10.318), train_loss = 1.13690338, grad/param norm = 1.8408e-01, time/batch = 0.6972s	
4737/22950 (epoch 10.320), train_loss = 1.27916524, grad/param norm = 1.6766e-01, time/batch = 0.7077s	
4738/22950 (epoch 10.322), train_loss = 1.31710592, grad/param norm = 1.9303e-01, time/batch = 0.6888s	
4739/22950 (epoch 10.325), train_loss = 1.05640241, grad/param norm = 1.7328e-01, time/batch = 0.6902s	
4740/22950 (epoch 10.327), train_loss = 1.08857671, grad/param norm = 1.6884e-01, time/batch = 0.6864s	
4741/22950 (epoch 10.329), train_loss = 1.21843508, grad/param norm = 1.8705e-01, time/batch = 0.6920s	
4742/22950 (epoch 10.331), train_loss = 1.16515524, grad/param norm = 1.8492e-01, time/batch = 0.6959s	
4743/22950 (epoch 10.333), train_loss = 1.27895052, grad/param norm = 1.9194e-01, time/batch = 0.6888s	
4744/22950 (epoch 10.336), train_loss = 1.31719320, grad/param norm = 2.2311e-01, time/batch = 0.7178s	
4745/22950 (epoch 10.338), train_loss = 1.24796764, grad/param norm = 1.8494e-01, time/batch = 0.6915s	
4746/22950 (epoch 10.340), train_loss = 1.28981518, grad/param norm = 1.9988e-01, time/batch = 0.7038s	
4747/22950 (epoch 10.342), train_loss = 1.39669627, grad/param norm = 1.9495e-01, time/batch = 0.7222s	
4748/22950 (epoch 10.344), train_loss = 1.31928779, grad/param norm = 2.0015e-01, time/batch = 0.6886s	
4749/22950 (epoch 10.346), train_loss = 1.52051649, grad/param norm = 2.1616e-01, time/batch = 0.6874s	
4750/22950 (epoch 10.349), train_loss = 1.34557902, grad/param norm = 2.0527e-01, time/batch = 0.6895s	
4751/22950 (epoch 10.351), train_loss = 1.35766413, grad/param norm = 1.9709e-01, time/batch = 0.6905s	
4752/22950 (epoch 10.353), train_loss = 1.43370470, grad/param norm = 2.1432e-01, time/batch = 0.6850s	
4753/22950 (epoch 10.355), train_loss = 1.45343690, grad/param norm = 2.0522e-01, time/batch = 0.6858s	
4754/22950 (epoch 10.357), train_loss = 1.33174098, grad/param norm = 1.8454e-01, time/batch = 0.6870s	
4755/22950 (epoch 10.359), train_loss = 1.38776882, grad/param norm = 2.0147e-01, time/batch = 0.7034s	
4756/22950 (epoch 10.362), train_loss = 1.29638878, grad/param norm = 1.8331e-01, time/batch = 0.7041s	
4757/22950 (epoch 10.364), train_loss = 1.33971986, grad/param norm = 1.9567e-01, time/batch = 0.7209s	
4758/22950 (epoch 10.366), train_loss = 1.15194667, grad/param norm = 1.7847e-01, time/batch = 0.6876s	
4759/22950 (epoch 10.368), train_loss = 1.34974052, grad/param norm = 2.2503e-01, time/batch = 0.6907s	
4760/22950 (epoch 10.370), train_loss = 1.30525112, grad/param norm = 1.9609e-01, time/batch = 0.6853s	
4761/22950 (epoch 10.373), train_loss = 1.17980556, grad/param norm = 1.9574e-01, time/batch = 0.6903s	
4762/22950 (epoch 10.375), train_loss = 1.45942494, grad/param norm = 2.1812e-01, time/batch = 0.6905s	
4763/22950 (epoch 10.377), train_loss = 1.28495317, grad/param norm = 1.9617e-01, time/batch = 0.6908s	
4764/22950 (epoch 10.379), train_loss = 1.41761572, grad/param norm = 2.0169e-01, time/batch = 0.6881s	
4765/22950 (epoch 10.381), train_loss = 1.14454196, grad/param norm = 1.7814e-01, time/batch = 0.6927s	
4766/22950 (epoch 10.383), train_loss = 1.37485226, grad/param norm = 2.0242e-01, time/batch = 0.7164s	
4767/22950 (epoch 10.386), train_loss = 1.29585866, grad/param norm = 2.0356e-01, time/batch = 0.7094s	
4768/22950 (epoch 10.388), train_loss = 1.35999522, grad/param norm = 2.1460e-01, time/batch = 0.6955s	
4769/22950 (epoch 10.390), train_loss = 1.22382957, grad/param norm = 1.9195e-01, time/batch = 0.6861s	
4770/22950 (epoch 10.392), train_loss = 1.18549864, grad/param norm = 1.7745e-01, time/batch = 0.6854s	
4771/22950 (epoch 10.394), train_loss = 1.23078171, grad/param norm = 1.7276e-01, time/batch = 0.6945s	
4772/22950 (epoch 10.397), train_loss = 1.42809860, grad/param norm = 2.1382e-01, time/batch = 0.7126s	
4773/22950 (epoch 10.399), train_loss = 1.44095923, grad/param norm = 2.0708e-01, time/batch = 0.7072s	
4774/22950 (epoch 10.401), train_loss = 1.62144362, grad/param norm = 2.1456e-01, time/batch = 0.6997s	
4775/22950 (epoch 10.403), train_loss = 1.27608351, grad/param norm = 1.9207e-01, time/batch = 0.7058s	
4776/22950 (epoch 10.405), train_loss = 1.42734632, grad/param norm = 2.1323e-01, time/batch = 0.7009s	
4777/22950 (epoch 10.407), train_loss = 1.49585418, grad/param norm = 2.1531e-01, time/batch = 0.6984s	
4778/22950 (epoch 10.410), train_loss = 1.19942222, grad/param norm = 1.8343e-01, time/batch = 0.7011s	
4779/22950 (epoch 10.412), train_loss = 1.37145583, grad/param norm = 2.1638e-01, time/batch = 0.6975s	
4780/22950 (epoch 10.414), train_loss = 1.44997975, grad/param norm = 2.2161e-01, time/batch = 0.6881s	
4781/22950 (epoch 10.416), train_loss = 1.41724691, grad/param norm = 2.1156e-01, time/batch = 0.6905s	
4782/22950 (epoch 10.418), train_loss = 1.39963540, grad/param norm = 2.0212e-01, time/batch = 0.6877s	
4783/22950 (epoch 10.420), train_loss = 1.41194318, grad/param norm = 1.9841e-01, time/batch = 0.6863s	
4784/22950 (epoch 10.423), train_loss = 1.21959191, grad/param norm = 1.6730e-01, time/batch = 0.6861s	
4785/22950 (epoch 10.425), train_loss = 1.33201568, grad/param norm = 1.8787e-01, time/batch = 0.7079s	
4786/22950 (epoch 10.427), train_loss = 1.28173844, grad/param norm = 1.8626e-01, time/batch = 0.7199s	
4787/22950 (epoch 10.429), train_loss = 1.29216543, grad/param norm = 2.0131e-01, time/batch = 0.7157s	
4788/22950 (epoch 10.431), train_loss = 1.38998257, grad/param norm = 2.0760e-01, time/batch = 0.7087s	
4789/22950 (epoch 10.434), train_loss = 1.32045596, grad/param norm = 1.9322e-01, time/batch = 0.6980s	
4790/22950 (epoch 10.436), train_loss = 1.58031837, grad/param norm = 2.2303e-01, time/batch = 0.6978s	
4791/22950 (epoch 10.438), train_loss = 1.33848926, grad/param norm = 1.9502e-01, time/batch = 0.7127s	
4792/22950 (epoch 10.440), train_loss = 1.39850439, grad/param norm = 2.0805e-01, time/batch = 0.7218s	
4793/22950 (epoch 10.442), train_loss = 1.49747446, grad/param norm = 2.1599e-01, time/batch = 0.7126s	
4794/22950 (epoch 10.444), train_loss = 1.44023637, grad/param norm = 1.9711e-01, time/batch = 0.6928s	
4795/22950 (epoch 10.447), train_loss = 1.55468564, grad/param norm = 2.1152e-01, time/batch = 0.6893s	
4796/22950 (epoch 10.449), train_loss = 1.20793340, grad/param norm = 1.7284e-01, time/batch = 0.7099s	
4797/22950 (epoch 10.451), train_loss = 1.36961742, grad/param norm = 1.9433e-01, time/batch = 0.7165s	
4798/22950 (epoch 10.453), train_loss = 1.38818232, grad/param norm = 1.9139e-01, time/batch = 0.6868s	
4799/22950 (epoch 10.455), train_loss = 1.22181090, grad/param norm = 1.7650e-01, time/batch = 0.6839s	
4800/22950 (epoch 10.458), train_loss = 1.47096938, grad/param norm = 1.9115e-01, time/batch = 0.6888s	
4801/22950 (epoch 10.460), train_loss = 1.35589587, grad/param norm = 1.9713e-01, time/batch = 0.6898s	
4802/22950 (epoch 10.462), train_loss = 1.32468020, grad/param norm = 1.8949e-01, time/batch = 0.6936s	
4803/22950 (epoch 10.464), train_loss = 1.29136654, grad/param norm = 1.9787e-01, time/batch = 0.6851s	
4804/22950 (epoch 10.466), train_loss = 1.35822645, grad/param norm = 1.9134e-01, time/batch = 0.6862s	
4805/22950 (epoch 10.468), train_loss = 1.46709984, grad/param norm = 1.9612e-01, time/batch = 0.6868s	
4806/22950 (epoch 10.471), train_loss = 1.35788367, grad/param norm = 1.8977e-01, time/batch = 0.6849s	
4807/22950 (epoch 10.473), train_loss = 1.43399800, grad/param norm = 2.1589e-01, time/batch = 0.6870s	
4808/22950 (epoch 10.475), train_loss = 1.60019697, grad/param norm = 2.3123e-01, time/batch = 0.6880s	
4809/22950 (epoch 10.477), train_loss = 1.34240614, grad/param norm = 2.0383e-01, time/batch = 0.6876s	
4810/22950 (epoch 10.479), train_loss = 1.27128015, grad/param norm = 1.9178e-01, time/batch = 0.6880s	
4811/22950 (epoch 10.481), train_loss = 1.53003420, grad/param norm = 2.1439e-01, time/batch = 0.6882s	
4812/22950 (epoch 10.484), train_loss = 1.41110090, grad/param norm = 2.0369e-01, time/batch = 0.6887s	
4813/22950 (epoch 10.486), train_loss = 1.19799419, grad/param norm = 1.9785e-01, time/batch = 0.6892s	
4814/22950 (epoch 10.488), train_loss = 1.33645125, grad/param norm = 2.0921e-01, time/batch = 0.6924s	
4815/22950 (epoch 10.490), train_loss = 1.17381056, grad/param norm = 1.9822e-01, time/batch = 0.6970s	
4816/22950 (epoch 10.492), train_loss = 1.34071514, grad/param norm = 2.0022e-01, time/batch = 0.6966s	
4817/22950 (epoch 10.495), train_loss = 1.32805971, grad/param norm = 1.8952e-01, time/batch = 0.6947s	
4818/22950 (epoch 10.497), train_loss = 1.42319528, grad/param norm = 1.8912e-01, time/batch = 0.6967s	
4819/22950 (epoch 10.499), train_loss = 1.44820882, grad/param norm = 2.0711e-01, time/batch = 0.6947s	
4820/22950 (epoch 10.501), train_loss = 1.41328507, grad/param norm = 1.9582e-01, time/batch = 0.7004s	
4821/22950 (epoch 10.503), train_loss = 1.44035041, grad/param norm = 1.9906e-01, time/batch = 0.6953s	
4822/22950 (epoch 10.505), train_loss = 1.20346951, grad/param norm = 1.7669e-01, time/batch = 0.6935s	
4823/22950 (epoch 10.508), train_loss = 1.39651115, grad/param norm = 1.9095e-01, time/batch = 0.6915s	
4824/22950 (epoch 10.510), train_loss = 1.35221417, grad/param norm = 1.9864e-01, time/batch = 0.6968s	
4825/22950 (epoch 10.512), train_loss = 1.24655003, grad/param norm = 1.7216e-01, time/batch = 0.6974s	
4826/22950 (epoch 10.514), train_loss = 1.22076052, grad/param norm = 1.8068e-01, time/batch = 0.7068s	
4827/22950 (epoch 10.516), train_loss = 1.29681399, grad/param norm = 2.1185e-01, time/batch = 0.7269s	
4828/22950 (epoch 10.519), train_loss = 1.29272161, grad/param norm = 1.8796e-01, time/batch = 0.6944s	
4829/22950 (epoch 10.521), train_loss = 1.32602618, grad/param norm = 1.7884e-01, time/batch = 0.6954s	
4830/22950 (epoch 10.523), train_loss = 1.08944760, grad/param norm = 1.8514e-01, time/batch = 0.6963s	
4831/22950 (epoch 10.525), train_loss = 1.24905847, grad/param norm = 1.8344e-01, time/batch = 0.6951s	
4832/22950 (epoch 10.527), train_loss = 1.12962863, grad/param norm = 1.8670e-01, time/batch = 0.6907s	
4833/22950 (epoch 10.529), train_loss = 1.38776693, grad/param norm = 2.0339e-01, time/batch = 0.6888s	
4834/22950 (epoch 10.532), train_loss = 1.27797970, grad/param norm = 1.8266e-01, time/batch = 0.6895s	
4835/22950 (epoch 10.534), train_loss = 1.44206441, grad/param norm = 2.1399e-01, time/batch = 0.7007s	
4836/22950 (epoch 10.536), train_loss = 1.40540393, grad/param norm = 2.1091e-01, time/batch = 0.7077s	
4837/22950 (epoch 10.538), train_loss = 1.29139544, grad/param norm = 2.1142e-01, time/batch = 0.7271s	
4838/22950 (epoch 10.540), train_loss = 1.34992574, grad/param norm = 1.8304e-01, time/batch = 0.6924s	
4839/22950 (epoch 10.542), train_loss = 1.52633841, grad/param norm = 2.2058e-01, time/batch = 0.6931s	
4840/22950 (epoch 10.545), train_loss = 1.31686549, grad/param norm = 2.0786e-01, time/batch = 0.6936s	
4841/22950 (epoch 10.547), train_loss = 1.31013179, grad/param norm = 1.9982e-01, time/batch = 0.6918s	
4842/22950 (epoch 10.549), train_loss = 1.31561254, grad/param norm = 1.8295e-01, time/batch = 0.6954s	
4843/22950 (epoch 10.551), train_loss = 1.33536831, grad/param norm = 1.9468e-01, time/batch = 0.6976s	
4844/22950 (epoch 10.553), train_loss = 1.30963715, grad/param norm = 2.2304e-01, time/batch = 0.7076s	
4845/22950 (epoch 10.556), train_loss = 1.40680817, grad/param norm = 1.8061e-01, time/batch = 0.7137s	
4846/22950 (epoch 10.558), train_loss = 1.25478505, grad/param norm = 1.9402e-01, time/batch = 0.7012s	
4847/22950 (epoch 10.560), train_loss = 1.36601891, grad/param norm = 1.9228e-01, time/batch = 0.7079s	
4848/22950 (epoch 10.562), train_loss = 1.20530617, grad/param norm = 1.8434e-01, time/batch = 0.6954s	
4849/22950 (epoch 10.564), train_loss = 1.54230439, grad/param norm = 2.4198e-01, time/batch = 0.6960s	
4850/22950 (epoch 10.566), train_loss = 1.34204274, grad/param norm = 1.9251e-01, time/batch = 0.6945s	
4851/22950 (epoch 10.569), train_loss = 1.48181742, grad/param norm = 1.9950e-01, time/batch = 0.6920s	
4852/22950 (epoch 10.571), train_loss = 1.20480080, grad/param norm = 1.9559e-01, time/batch = 0.6956s	
4853/22950 (epoch 10.573), train_loss = 1.34047554, grad/param norm = 2.0535e-01, time/batch = 0.6930s	
4854/22950 (epoch 10.575), train_loss = 1.57402391, grad/param norm = 2.1551e-01, time/batch = 0.6918s	
4855/22950 (epoch 10.577), train_loss = 1.34377128, grad/param norm = 2.2282e-01, time/batch = 0.6931s	
4856/22950 (epoch 10.580), train_loss = 1.39514449, grad/param norm = 2.0411e-01, time/batch = 0.6949s	
4857/22950 (epoch 10.582), train_loss = 1.54684086, grad/param norm = 1.9386e-01, time/batch = 0.6944s	
4858/22950 (epoch 10.584), train_loss = 1.17890869, grad/param norm = 1.8201e-01, time/batch = 0.6931s	
4859/22950 (epoch 10.586), train_loss = 1.28643609, grad/param norm = 1.9735e-01, time/batch = 0.7011s	
4860/22950 (epoch 10.588), train_loss = 1.47150620, grad/param norm = 1.9605e-01, time/batch = 0.6953s	
4861/22950 (epoch 10.590), train_loss = 1.31485471, grad/param norm = 1.9466e-01, time/batch = 0.7034s	
4862/22950 (epoch 10.593), train_loss = 1.19173135, grad/param norm = 1.8951e-01, time/batch = 0.6952s	
4863/22950 (epoch 10.595), train_loss = 1.21772283, grad/param norm = 2.0067e-01, time/batch = 0.6938s	
4864/22950 (epoch 10.597), train_loss = 1.42070868, grad/param norm = 2.1801e-01, time/batch = 0.6948s	
4865/22950 (epoch 10.599), train_loss = 1.37402348, grad/param norm = 2.1805e-01, time/batch = 0.6924s	
4866/22950 (epoch 10.601), train_loss = 1.33100988, grad/param norm = 1.9971e-01, time/batch = 0.6913s	
4867/22950 (epoch 10.603), train_loss = 1.47422557, grad/param norm = 1.9197e-01, time/batch = 0.6888s	
4868/22950 (epoch 10.606), train_loss = 1.28877570, grad/param norm = 1.9654e-01, time/batch = 0.6925s	
4869/22950 (epoch 10.608), train_loss = 1.33853808, grad/param norm = 1.8806e-01, time/batch = 0.6910s	
4870/22950 (epoch 10.610), train_loss = 1.30652893, grad/param norm = 1.9951e-01, time/batch = 0.6938s	
4871/22950 (epoch 10.612), train_loss = 1.34649380, grad/param norm = 1.9074e-01, time/batch = 0.7181s	
4872/22950 (epoch 10.614), train_loss = 1.47221428, grad/param norm = 2.1743e-01, time/batch = 0.7237s	
4873/22950 (epoch 10.617), train_loss = 1.30586136, grad/param norm = 1.8932e-01, time/batch = 0.7221s	
4874/22950 (epoch 10.619), train_loss = 1.21360438, grad/param norm = 1.6766e-01, time/batch = 0.7047s	
4875/22950 (epoch 10.621), train_loss = 1.42308259, grad/param norm = 1.8549e-01, time/batch = 0.7000s	
4876/22950 (epoch 10.623), train_loss = 1.39030892, grad/param norm = 1.8131e-01, time/batch = 0.7038s	
4877/22950 (epoch 10.625), train_loss = 1.30860686, grad/param norm = 1.7583e-01, time/batch = 0.7062s	
4878/22950 (epoch 10.627), train_loss = 1.34730764, grad/param norm = 2.0335e-01, time/batch = 0.7055s	
4879/22950 (epoch 10.630), train_loss = 1.18258739, grad/param norm = 1.7912e-01, time/batch = 0.6971s	
4880/22950 (epoch 10.632), train_loss = 1.37392204, grad/param norm = 2.0015e-01, time/batch = 0.6946s	
4881/22950 (epoch 10.634), train_loss = 1.30988679, grad/param norm = 1.9635e-01, time/batch = 0.6985s	
4882/22950 (epoch 10.636), train_loss = 1.33455224, grad/param norm = 1.9594e-01, time/batch = 0.6991s	
4883/22950 (epoch 10.638), train_loss = 1.22839248, grad/param norm = 1.9688e-01, time/batch = 0.6769s	
4884/22950 (epoch 10.641), train_loss = 1.25668106, grad/param norm = 1.8575e-01, time/batch = 0.6769s	
4885/22950 (epoch 10.643), train_loss = 1.35722923, grad/param norm = 2.1528e-01, time/batch = 0.6808s	
4886/22950 (epoch 10.645), train_loss = 1.24377605, grad/param norm = 1.9349e-01, time/batch = 0.6865s	
4887/22950 (epoch 10.647), train_loss = 1.33193302, grad/param norm = 2.0240e-01, time/batch = 0.6816s	
4888/22950 (epoch 10.649), train_loss = 1.32885135, grad/param norm = 1.9439e-01, time/batch = 0.6780s	
4889/22950 (epoch 10.651), train_loss = 1.43092297, grad/param norm = 2.1414e-01, time/batch = 0.6759s	
4890/22950 (epoch 10.654), train_loss = 1.13807675, grad/param norm = 1.8168e-01, time/batch = 0.6823s	
4891/22950 (epoch 10.656), train_loss = 1.47389536, grad/param norm = 2.3071e-01, time/batch = 0.6792s	
4892/22950 (epoch 10.658), train_loss = 1.20033064, grad/param norm = 1.7935e-01, time/batch = 0.6776s	
4893/22950 (epoch 10.660), train_loss = 1.15345149, grad/param norm = 1.8370e-01, time/batch = 0.6770s	
4894/22950 (epoch 10.662), train_loss = 1.15607897, grad/param norm = 1.8091e-01, time/batch = 0.6768s	
4895/22950 (epoch 10.664), train_loss = 1.34390585, grad/param norm = 1.8125e-01, time/batch = 0.6758s	
4896/22950 (epoch 10.667), train_loss = 1.36901261, grad/param norm = 1.9211e-01, time/batch = 0.6836s	
4897/22950 (epoch 10.669), train_loss = 1.26753594, grad/param norm = 1.9408e-01, time/batch = 0.7111s	
4898/22950 (epoch 10.671), train_loss = 1.36744535, grad/param norm = 1.9038e-01, time/batch = 0.6793s	
4899/22950 (epoch 10.673), train_loss = 1.29951098, grad/param norm = 1.8865e-01, time/batch = 0.6714s	
4900/22950 (epoch 10.675), train_loss = 1.30841664, grad/param norm = 1.8636e-01, time/batch = 0.6752s	
4901/22950 (epoch 10.678), train_loss = 1.30563303, grad/param norm = 2.0162e-01, time/batch = 0.6778s	
4902/22950 (epoch 10.680), train_loss = 1.34432526, grad/param norm = 1.8829e-01, time/batch = 0.6734s	
4903/22950 (epoch 10.682), train_loss = 1.40049247, grad/param norm = 2.0243e-01, time/batch = 0.6766s	
4904/22950 (epoch 10.684), train_loss = 1.44370185, grad/param norm = 1.9131e-01, time/batch = 0.6738s	
4905/22950 (epoch 10.686), train_loss = 1.41404594, grad/param norm = 1.9614e-01, time/batch = 0.6753s	
4906/22950 (epoch 10.688), train_loss = 1.32087408, grad/param norm = 1.9673e-01, time/batch = 0.6749s	
4907/22950 (epoch 10.691), train_loss = 1.30518566, grad/param norm = 1.9040e-01, time/batch = 0.6734s	
4908/22950 (epoch 10.693), train_loss = 1.24248017, grad/param norm = 1.9245e-01, time/batch = 0.6702s	
4909/22950 (epoch 10.695), train_loss = 1.50342462, grad/param norm = 1.9957e-01, time/batch = 0.6713s	
4910/22950 (epoch 10.697), train_loss = 1.44902598, grad/param norm = 1.9271e-01, time/batch = 0.6725s	
4911/22950 (epoch 10.699), train_loss = 1.41556834, grad/param norm = 1.9221e-01, time/batch = 0.6748s	
4912/22950 (epoch 10.702), train_loss = 1.41047126, grad/param norm = 1.9619e-01, time/batch = 0.6734s	
4913/22950 (epoch 10.704), train_loss = 1.41607841, grad/param norm = 2.1627e-01, time/batch = 0.6760s	
4914/22950 (epoch 10.706), train_loss = 1.46148336, grad/param norm = 2.1006e-01, time/batch = 0.6757s	
4915/22950 (epoch 10.708), train_loss = 1.29152152, grad/param norm = 2.0539e-01, time/batch = 0.6768s	
4916/22950 (epoch 10.710), train_loss = 1.39336393, grad/param norm = 1.8058e-01, time/batch = 0.6806s	
4917/22950 (epoch 10.712), train_loss = 1.48600444, grad/param norm = 1.9439e-01, time/batch = 0.6768s	
4918/22950 (epoch 10.715), train_loss = 1.41791343, grad/param norm = 1.9955e-01, time/batch = 0.6765s	
4919/22950 (epoch 10.717), train_loss = 1.24699569, grad/param norm = 1.8295e-01, time/batch = 0.6755s	
4920/22950 (epoch 10.719), train_loss = 1.29254291, grad/param norm = 2.0005e-01, time/batch = 0.6777s	
4921/22950 (epoch 10.721), train_loss = 1.38566174, grad/param norm = 1.8909e-01, time/batch = 0.7024s	
4922/22950 (epoch 10.723), train_loss = 1.24370103, grad/param norm = 1.8620e-01, time/batch = 0.7071s	
4923/22950 (epoch 10.725), train_loss = 1.44051616, grad/param norm = 1.9918e-01, time/batch = 0.6966s	
4924/22950 (epoch 10.728), train_loss = 1.34934497, grad/param norm = 2.0173e-01, time/batch = 0.6914s	
4925/22950 (epoch 10.730), train_loss = 1.33925966, grad/param norm = 1.9635e-01, time/batch = 0.6915s	
4926/22950 (epoch 10.732), train_loss = 1.36412396, grad/param norm = 1.7661e-01, time/batch = 0.6779s	
4927/22950 (epoch 10.734), train_loss = 1.35204111, grad/param norm = 1.9883e-01, time/batch = 0.6926s	
4928/22950 (epoch 10.736), train_loss = 1.27369265, grad/param norm = 1.9180e-01, time/batch = 0.6755s	
4929/22950 (epoch 10.739), train_loss = 1.40827945, grad/param norm = 2.0267e-01, time/batch = 0.6816s	
4930/22950 (epoch 10.741), train_loss = 1.36686229, grad/param norm = 2.0200e-01, time/batch = 0.6769s	
4931/22950 (epoch 10.743), train_loss = 1.52647533, grad/param norm = 2.0214e-01, time/batch = 0.6822s	
4932/22950 (epoch 10.745), train_loss = 1.58365494, grad/param norm = 2.0851e-01, time/batch = 0.6764s	
4933/22950 (epoch 10.747), train_loss = 1.36288690, grad/param norm = 1.9314e-01, time/batch = 0.6770s	
4934/22950 (epoch 10.749), train_loss = 1.23652362, grad/param norm = 1.9514e-01, time/batch = 0.6763s	
4935/22950 (epoch 10.752), train_loss = 1.54388538, grad/param norm = 2.1545e-01, time/batch = 0.6755s	
4936/22950 (epoch 10.754), train_loss = 1.41708951, grad/param norm = 1.9786e-01, time/batch = 0.6750s	
4937/22950 (epoch 10.756), train_loss = 1.25650554, grad/param norm = 2.0213e-01, time/batch = 0.6757s	
4938/22950 (epoch 10.758), train_loss = 1.28147610, grad/param norm = 1.9554e-01, time/batch = 0.6746s	
4939/22950 (epoch 10.760), train_loss = 1.37913812, grad/param norm = 1.9293e-01, time/batch = 0.6795s	
4940/22950 (epoch 10.763), train_loss = 1.37606302, grad/param norm = 2.0780e-01, time/batch = 0.6812s	
4941/22950 (epoch 10.765), train_loss = 1.41219763, grad/param norm = 1.9559e-01, time/batch = 0.6809s	
4942/22950 (epoch 10.767), train_loss = 1.56391232, grad/param norm = 2.0952e-01, time/batch = 0.6760s	
4943/22950 (epoch 10.769), train_loss = 1.37166732, grad/param norm = 1.9514e-01, time/batch = 0.6762s	
4944/22950 (epoch 10.771), train_loss = 1.23678505, grad/param norm = 2.0433e-01, time/batch = 0.6780s	
4945/22950 (epoch 10.773), train_loss = 1.04303601, grad/param norm = 1.7089e-01, time/batch = 0.6790s	
4946/22950 (epoch 10.776), train_loss = 1.26022817, grad/param norm = 1.8714e-01, time/batch = 0.6773s	
4947/22950 (epoch 10.778), train_loss = 1.17680880, grad/param norm = 1.7540e-01, time/batch = 0.6766s	
4948/22950 (epoch 10.780), train_loss = 1.24878728, grad/param norm = 1.7219e-01, time/batch = 0.6765s	
4949/22950 (epoch 10.782), train_loss = 1.26886255, grad/param norm = 1.8558e-01, time/batch = 0.6744s	
4950/22950 (epoch 10.784), train_loss = 1.36590603, grad/param norm = 2.0438e-01, time/batch = 0.6751s	
4951/22950 (epoch 10.786), train_loss = 1.39705090, grad/param norm = 1.8072e-01, time/batch = 0.6825s	
4952/22950 (epoch 10.789), train_loss = 1.16132160, grad/param norm = 1.8243e-01, time/batch = 0.6770s	
4953/22950 (epoch 10.791), train_loss = 1.21106294, grad/param norm = 1.9932e-01, time/batch = 0.6736s	
4954/22950 (epoch 10.793), train_loss = 1.58248184, grad/param norm = 2.0672e-01, time/batch = 0.6747s	
4955/22950 (epoch 10.795), train_loss = 1.25245003, grad/param norm = 1.7935e-01, time/batch = 0.6728s	
4956/22950 (epoch 10.797), train_loss = 1.52539087, grad/param norm = 2.1741e-01, time/batch = 0.6751s	
4957/22950 (epoch 10.800), train_loss = 1.24957181, grad/param norm = 1.9400e-01, time/batch = 0.6765s	
4958/22950 (epoch 10.802), train_loss = 1.26441604, grad/param norm = 1.8987e-01, time/batch = 0.6960s	
4959/22950 (epoch 10.804), train_loss = 1.29198840, grad/param norm = 1.9429e-01, time/batch = 0.7067s	
4960/22950 (epoch 10.806), train_loss = 1.19579623, grad/param norm = 1.8074e-01, time/batch = 0.7059s	
4961/22950 (epoch 10.808), train_loss = 1.28782257, grad/param norm = 1.9730e-01, time/batch = 0.7175s	
4962/22950 (epoch 10.810), train_loss = 1.27246255, grad/param norm = 1.9434e-01, time/batch = 0.6953s	
4963/22950 (epoch 10.813), train_loss = 1.10236108, grad/param norm = 1.8209e-01, time/batch = 0.6894s	
4964/22950 (epoch 10.815), train_loss = 1.20050416, grad/param norm = 1.7607e-01, time/batch = 0.6855s	
4965/22950 (epoch 10.817), train_loss = 1.17383993, grad/param norm = 1.7320e-01, time/batch = 0.6893s	
4966/22950 (epoch 10.819), train_loss = 1.28313722, grad/param norm = 1.9911e-01, time/batch = 0.6786s	
4967/22950 (epoch 10.821), train_loss = 1.33953566, grad/param norm = 2.0719e-01, time/batch = 0.6795s	
4968/22950 (epoch 10.824), train_loss = 1.29024292, grad/param norm = 2.0578e-01, time/batch = 0.6782s	
4969/22950 (epoch 10.826), train_loss = 1.42331468, grad/param norm = 2.1734e-01, time/batch = 0.6780s	
4970/22950 (epoch 10.828), train_loss = 1.29578407, grad/param norm = 1.9970e-01, time/batch = 0.6736s	
4971/22950 (epoch 10.830), train_loss = 1.32421775, grad/param norm = 1.9030e-01, time/batch = 0.6779s	
4972/22950 (epoch 10.832), train_loss = 1.36095562, grad/param norm = 2.0794e-01, time/batch = 0.6771s	
4973/22950 (epoch 10.834), train_loss = 1.19461613, grad/param norm = 1.9034e-01, time/batch = 0.6787s	
4974/22950 (epoch 10.837), train_loss = 1.33281434, grad/param norm = 2.0394e-01, time/batch = 0.6764s	
4975/22950 (epoch 10.839), train_loss = 1.20272981, grad/param norm = 1.9136e-01, time/batch = 0.6808s	
4976/22950 (epoch 10.841), train_loss = 1.20532357, grad/param norm = 1.6871e-01, time/batch = 0.6749s	
4977/22950 (epoch 10.843), train_loss = 1.26431634, grad/param norm = 2.0134e-01, time/batch = 0.6744s	
4978/22950 (epoch 10.845), train_loss = 1.31832328, grad/param norm = 1.9994e-01, time/batch = 0.6749s	
4979/22950 (epoch 10.847), train_loss = 1.42249549, grad/param norm = 1.9061e-01, time/batch = 0.6757s	
4980/22950 (epoch 10.850), train_loss = 1.36664941, grad/param norm = 2.2544e-01, time/batch = 0.6751s	
4981/22950 (epoch 10.852), train_loss = 1.39914352, grad/param norm = 2.0071e-01, time/batch = 0.6836s	
4982/22950 (epoch 10.854), train_loss = 1.31649276, grad/param norm = 2.0069e-01, time/batch = 0.6738s	
4983/22950 (epoch 10.856), train_loss = 1.52109669, grad/param norm = 2.0840e-01, time/batch = 0.7137s	
4984/22950 (epoch 10.858), train_loss = 1.37075149, grad/param norm = 1.9587e-01, time/batch = 0.6945s	
4985/22950 (epoch 10.861), train_loss = 1.44336841, grad/param norm = 2.1258e-01, time/batch = 0.6771s	
4986/22950 (epoch 10.863), train_loss = 1.48853984, grad/param norm = 2.0808e-01, time/batch = 0.6772s	
4987/22950 (epoch 10.865), train_loss = 1.54563417, grad/param norm = 2.1138e-01, time/batch = 0.6769s	
4988/22950 (epoch 10.867), train_loss = 1.37846183, grad/param norm = 1.9991e-01, time/batch = 0.6740s	
4989/22950 (epoch 10.869), train_loss = 1.55928898, grad/param norm = 2.1264e-01, time/batch = 0.6743s	
4990/22950 (epoch 10.871), train_loss = 1.35541550, grad/param norm = 2.1569e-01, time/batch = 0.6758s	
4991/22950 (epoch 10.874), train_loss = 1.31712966, grad/param norm = 2.0067e-01, time/batch = 0.6769s	
4992/22950 (epoch 10.876), train_loss = 1.38403499, grad/param norm = 1.9055e-01, time/batch = 0.6769s	
4993/22950 (epoch 10.878), train_loss = 1.28239860, grad/param norm = 2.1058e-01, time/batch = 0.7002s	
4994/22950 (epoch 10.880), train_loss = 1.49942696, grad/param norm = 1.9517e-01, time/batch = 0.6991s	
4995/22950 (epoch 10.882), train_loss = 1.20428934, grad/param norm = 1.8391e-01, time/batch = 0.6711s	
4996/22950 (epoch 10.885), train_loss = 1.36404289, grad/param norm = 2.0187e-01, time/batch = 0.6716s	
4997/22950 (epoch 10.887), train_loss = 1.35074089, grad/param norm = 2.0604e-01, time/batch = 0.6706s	
4998/22950 (epoch 10.889), train_loss = 1.44138067, grad/param norm = 2.3144e-01, time/batch = 0.6718s	
4999/22950 (epoch 10.891), train_loss = 1.34092187, grad/param norm = 1.9964e-01, time/batch = 0.6737s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch10.89_1.6347.t7	
5000/22950 (epoch 10.893), train_loss = 1.35233097, grad/param norm = 1.9698e-01, time/batch = 0.6735s	
5001/22950 (epoch 10.895), train_loss = 1.75335734, grad/param norm = 2.2895e-01, time/batch = 0.6898s	
5002/22950 (epoch 10.898), train_loss = 1.34597484, grad/param norm = 2.0591e-01, time/batch = 0.6877s	
5003/22950 (epoch 10.900), train_loss = 1.21670178, grad/param norm = 1.7670e-01, time/batch = 0.6973s	
5004/22950 (epoch 10.902), train_loss = 1.40161316, grad/param norm = 1.9085e-01, time/batch = 0.6976s	
5005/22950 (epoch 10.904), train_loss = 1.37879207, grad/param norm = 1.9130e-01, time/batch = 0.7061s	
5006/22950 (epoch 10.906), train_loss = 1.34884354, grad/param norm = 1.8669e-01, time/batch = 0.7084s	
5007/22950 (epoch 10.908), train_loss = 1.23486860, grad/param norm = 2.0224e-01, time/batch = 0.7124s	
5008/22950 (epoch 10.911), train_loss = 1.16957704, grad/param norm = 1.6938e-01, time/batch = 0.7071s	
5009/22950 (epoch 10.913), train_loss = 1.29430947, grad/param norm = 1.9391e-01, time/batch = 0.7223s	
5010/22950 (epoch 10.915), train_loss = 1.46942972, grad/param norm = 2.2511e-01, time/batch = 0.7133s	
5011/22950 (epoch 10.917), train_loss = 1.18030967, grad/param norm = 1.8879e-01, time/batch = 0.6943s	
5012/22950 (epoch 10.919), train_loss = 1.29376955, grad/param norm = 1.9466e-01, time/batch = 0.6788s	
5013/22950 (epoch 10.922), train_loss = 1.32474829, grad/param norm = 1.9826e-01, time/batch = 0.6949s	
5014/22950 (epoch 10.924), train_loss = 1.39128530, grad/param norm = 1.8941e-01, time/batch = 0.7102s	
5015/22950 (epoch 10.926), train_loss = 1.18914240, grad/param norm = 1.8796e-01, time/batch = 0.6780s	
5016/22950 (epoch 10.928), train_loss = 1.18684163, grad/param norm = 2.0267e-01, time/batch = 0.6932s	
5017/22950 (epoch 10.930), train_loss = 1.15639221, grad/param norm = 2.0692e-01, time/batch = 0.7082s	
5018/22950 (epoch 10.932), train_loss = 1.13878362, grad/param norm = 1.8003e-01, time/batch = 0.6759s	
5019/22950 (epoch 10.935), train_loss = 1.36165672, grad/param norm = 2.0129e-01, time/batch = 0.6764s	
5020/22950 (epoch 10.937), train_loss = 1.36141312, grad/param norm = 2.1588e-01, time/batch = 0.6783s	
5021/22950 (epoch 10.939), train_loss = 1.26468333, grad/param norm = 2.0138e-01, time/batch = 0.6866s	
5022/22950 (epoch 10.941), train_loss = 1.22134348, grad/param norm = 1.8909e-01, time/batch = 0.6729s	
5023/22950 (epoch 10.943), train_loss = 1.33750277, grad/param norm = 1.9530e-01, time/batch = 0.6742s	
5024/22950 (epoch 10.946), train_loss = 1.18405105, grad/param norm = 1.9805e-01, time/batch = 0.6778s	
5025/22950 (epoch 10.948), train_loss = 1.35830227, grad/param norm = 1.8188e-01, time/batch = 0.6767s	
5026/22950 (epoch 10.950), train_loss = 1.37343355, grad/param norm = 2.0235e-01, time/batch = 0.6847s	
5027/22950 (epoch 10.952), train_loss = 1.36897354, grad/param norm = 2.0467e-01, time/batch = 0.7106s	
5028/22950 (epoch 10.954), train_loss = 1.32031622, grad/param norm = 1.8132e-01, time/batch = 0.6794s	
5029/22950 (epoch 10.956), train_loss = 1.24098008, grad/param norm = 1.8419e-01, time/batch = 0.6726s	
5030/22950 (epoch 10.959), train_loss = 1.21279963, grad/param norm = 2.0237e-01, time/batch = 0.6733s	
5031/22950 (epoch 10.961), train_loss = 1.34224055, grad/param norm = 1.9629e-01, time/batch = 0.6793s	
5032/22950 (epoch 10.963), train_loss = 1.38417738, grad/param norm = 2.0135e-01, time/batch = 0.6782s	
5033/22950 (epoch 10.965), train_loss = 1.51545366, grad/param norm = 2.0774e-01, time/batch = 0.6754s	
5034/22950 (epoch 10.967), train_loss = 1.32952448, grad/param norm = 2.2026e-01, time/batch = 0.6774s	
5035/22950 (epoch 10.969), train_loss = 1.23778258, grad/param norm = 1.9146e-01, time/batch = 0.6763s	
5036/22950 (epoch 10.972), train_loss = 1.30858012, grad/param norm = 1.9533e-01, time/batch = 0.6738s	
5037/22950 (epoch 10.974), train_loss = 1.23089485, grad/param norm = 1.8974e-01, time/batch = 0.6766s	
5038/22950 (epoch 10.976), train_loss = 1.15226829, grad/param norm = 1.9772e-01, time/batch = 0.6823s	
5039/22950 (epoch 10.978), train_loss = 1.28985805, grad/param norm = 2.0510e-01, time/batch = 0.7056s	
5040/22950 (epoch 10.980), train_loss = 1.30856740, grad/param norm = 2.0048e-01, time/batch = 0.7168s	
5041/22950 (epoch 10.983), train_loss = 1.22098303, grad/param norm = 1.7886e-01, time/batch = 0.7022s	
5042/22950 (epoch 10.985), train_loss = 1.16282893, grad/param norm = 1.7875e-01, time/batch = 0.7158s	
5043/22950 (epoch 10.987), train_loss = 1.20326333, grad/param norm = 1.8490e-01, time/batch = 0.7005s	
5044/22950 (epoch 10.989), train_loss = 1.35263998, grad/param norm = 1.8765e-01, time/batch = 0.6886s	
5045/22950 (epoch 10.991), train_loss = 1.15862132, grad/param norm = 1.9546e-01, time/batch = 0.6833s	
5046/22950 (epoch 10.993), train_loss = 1.34153170, grad/param norm = 2.0872e-01, time/batch = 0.6811s	
5047/22950 (epoch 10.996), train_loss = 1.40925853, grad/param norm = 2.0227e-01, time/batch = 0.6802s	
5048/22950 (epoch 10.998), train_loss = 1.25800786, grad/param norm = 1.8844e-01, time/batch = 0.6789s	
decayed learning rate by a factor 0.97 to 0.0018818	
5049/22950 (epoch 11.000), train_loss = 1.15067348, grad/param norm = 1.8432e-01, time/batch = 0.6777s	
5050/22950 (epoch 11.002), train_loss = 1.51112161, grad/param norm = 2.1040e-01, time/batch = 0.6743s	
5051/22950 (epoch 11.004), train_loss = 1.34674991, grad/param norm = 2.0433e-01, time/batch = 0.6739s	
5052/22950 (epoch 11.007), train_loss = 1.31299018, grad/param norm = 2.0063e-01, time/batch = 0.6726s	
5053/22950 (epoch 11.009), train_loss = 1.42970485, grad/param norm = 1.8899e-01, time/batch = 0.6753s	
5054/22950 (epoch 11.011), train_loss = 1.24748513, grad/param norm = 1.8852e-01, time/batch = 0.6739s	
5055/22950 (epoch 11.013), train_loss = 1.41746487, grad/param norm = 2.1808e-01, time/batch = 0.6766s	
5056/22950 (epoch 11.015), train_loss = 1.40486034, grad/param norm = 2.0182e-01, time/batch = 0.6721s	
5057/22950 (epoch 11.017), train_loss = 1.27853304, grad/param norm = 1.7273e-01, time/batch = 0.6762s	
5058/22950 (epoch 11.020), train_loss = 1.28121026, grad/param norm = 1.7387e-01, time/batch = 0.6753s	
5059/22950 (epoch 11.022), train_loss = 1.13033642, grad/param norm = 1.8026e-01, time/batch = 0.6782s	
5060/22950 (epoch 11.024), train_loss = 1.19974642, grad/param norm = 1.8427e-01, time/batch = 0.6737s	
5061/22950 (epoch 11.026), train_loss = 1.31874564, grad/param norm = 1.9604e-01, time/batch = 0.6805s	
5062/22950 (epoch 11.028), train_loss = 1.38256623, grad/param norm = 1.9371e-01, time/batch = 0.6747s	
5063/22950 (epoch 11.031), train_loss = 1.31365531, grad/param norm = 1.9047e-01, time/batch = 0.6730s	
5064/22950 (epoch 11.033), train_loss = 1.49010928, grad/param norm = 2.1850e-01, time/batch = 0.6738s	
5065/22950 (epoch 11.035), train_loss = 1.27563856, grad/param norm = 1.7948e-01, time/batch = 0.6825s	
5066/22950 (epoch 11.037), train_loss = 1.28742411, grad/param norm = 2.1174e-01, time/batch = 0.6714s	
5067/22950 (epoch 11.039), train_loss = 1.28316890, grad/param norm = 2.0880e-01, time/batch = 0.6714s	
5068/22950 (epoch 11.041), train_loss = 1.25306545, grad/param norm = 1.8074e-01, time/batch = 0.6842s	
5069/22950 (epoch 11.044), train_loss = 1.30073228, grad/param norm = 1.8837e-01, time/batch = 0.6765s	
5070/22950 (epoch 11.046), train_loss = 1.33275396, grad/param norm = 1.8657e-01, time/batch = 0.6739s	
5071/22950 (epoch 11.048), train_loss = 1.33555588, grad/param norm = 1.9528e-01, time/batch = 0.6743s	
5072/22950 (epoch 11.050), train_loss = 1.37713927, grad/param norm = 2.1383e-01, time/batch = 0.6758s	
5073/22950 (epoch 11.052), train_loss = 1.32680503, grad/param norm = 1.8948e-01, time/batch = 0.6836s	
5074/22950 (epoch 11.054), train_loss = 1.56291889, grad/param norm = 2.1256e-01, time/batch = 0.6840s	
5075/22950 (epoch 11.057), train_loss = 1.40633029, grad/param norm = 2.0106e-01, time/batch = 0.6804s	
5076/22950 (epoch 11.059), train_loss = 1.37309160, grad/param norm = 1.8966e-01, time/batch = 0.6745s	
5077/22950 (epoch 11.061), train_loss = 1.19964491, grad/param norm = 1.8041e-01, time/batch = 0.6733s	
5078/22950 (epoch 11.063), train_loss = 1.37065458, grad/param norm = 1.8743e-01, time/batch = 0.6731s	
5079/22950 (epoch 11.065), train_loss = 1.06037331, grad/param norm = 1.8708e-01, time/batch = 0.6785s	
5080/22950 (epoch 11.068), train_loss = 1.40213977, grad/param norm = 2.0965e-01, time/batch = 0.6755s	
5081/22950 (epoch 11.070), train_loss = 1.17615432, grad/param norm = 1.8523e-01, time/batch = 0.6745s	
5082/22950 (epoch 11.072), train_loss = 1.34751119, grad/param norm = 1.9898e-01, time/batch = 0.6765s	
5083/22950 (epoch 11.074), train_loss = 1.29698851, grad/param norm = 2.0241e-01, time/batch = 0.6779s	
5084/22950 (epoch 11.076), train_loss = 1.29900578, grad/param norm = 1.9451e-01, time/batch = 0.6784s	
5085/22950 (epoch 11.078), train_loss = 1.42763980, grad/param norm = 2.0603e-01, time/batch = 0.6801s	
5086/22950 (epoch 11.081), train_loss = 1.40404166, grad/param norm = 1.9522e-01, time/batch = 0.6763s	
5087/22950 (epoch 11.083), train_loss = 1.25919200, grad/param norm = 2.1184e-01, time/batch = 0.6722s	
5088/22950 (epoch 11.085), train_loss = 1.21370009, grad/param norm = 1.9876e-01, time/batch = 0.6736s	
5089/22950 (epoch 11.087), train_loss = 1.23043968, grad/param norm = 1.9393e-01, time/batch = 0.6759s	
5090/22950 (epoch 11.089), train_loss = 1.34447015, grad/param norm = 1.9725e-01, time/batch = 0.6838s	
5091/22950 (epoch 11.092), train_loss = 1.27900471, grad/param norm = 2.0145e-01, time/batch = 0.6770s	
5092/22950 (epoch 11.094), train_loss = 1.24287961, grad/param norm = 1.9495e-01, time/batch = 0.6757s	
5093/22950 (epoch 11.096), train_loss = 1.45873134, grad/param norm = 1.9693e-01, time/batch = 0.6760s	
5094/22950 (epoch 11.098), train_loss = 1.33810987, grad/param norm = 1.9733e-01, time/batch = 0.6752s	
5095/22950 (epoch 11.100), train_loss = 1.24101525, grad/param norm = 1.8779e-01, time/batch = 0.6742s	
5096/22950 (epoch 11.102), train_loss = 1.31501327, grad/param norm = 1.8530e-01, time/batch = 0.6740s	
5097/22950 (epoch 11.105), train_loss = 1.15437898, grad/param norm = 1.6284e-01, time/batch = 0.6744s	
5098/22950 (epoch 11.107), train_loss = 1.25897232, grad/param norm = 1.8852e-01, time/batch = 0.6801s	
5099/22950 (epoch 11.109), train_loss = 1.25764605, grad/param norm = 2.0056e-01, time/batch = 0.6787s	
5100/22950 (epoch 11.111), train_loss = 1.17378501, grad/param norm = 1.8860e-01, time/batch = 0.6782s	
5101/22950 (epoch 11.113), train_loss = 1.32333333, grad/param norm = 1.9438e-01, time/batch = 0.6759s	
5102/22950 (epoch 11.115), train_loss = 1.35055520, grad/param norm = 2.1390e-01, time/batch = 0.6769s	
5103/22950 (epoch 11.118), train_loss = 1.45014781, grad/param norm = 1.9350e-01, time/batch = 0.6764s	
5104/22950 (epoch 11.120), train_loss = 1.21607505, grad/param norm = 1.8507e-01, time/batch = 0.6803s	
5105/22950 (epoch 11.122), train_loss = 1.44336305, grad/param norm = 2.0254e-01, time/batch = 0.6944s	
5106/22950 (epoch 11.124), train_loss = 1.08156842, grad/param norm = 1.5252e-01, time/batch = 0.6885s	
5107/22950 (epoch 11.126), train_loss = 1.27198720, grad/param norm = 1.9335e-01, time/batch = 0.6782s	
5108/22950 (epoch 11.129), train_loss = 1.13300963, grad/param norm = 1.7781e-01, time/batch = 0.6790s	
5109/22950 (epoch 11.131), train_loss = 1.26142724, grad/param norm = 2.0252e-01, time/batch = 0.6741s	
5110/22950 (epoch 11.133), train_loss = 1.38299165, grad/param norm = 2.0978e-01, time/batch = 0.6718s	
5111/22950 (epoch 11.135), train_loss = 1.27650200, grad/param norm = 1.8378e-01, time/batch = 0.6771s	
5112/22950 (epoch 11.137), train_loss = 1.48123063, grad/param norm = 2.1169e-01, time/batch = 0.6758s	
5113/22950 (epoch 11.139), train_loss = 1.24490814, grad/param norm = 2.1390e-01, time/batch = 0.6774s	
5114/22950 (epoch 11.142), train_loss = 1.22071172, grad/param norm = 1.8922e-01, time/batch = 0.6797s	
5115/22950 (epoch 11.144), train_loss = 1.20293871, grad/param norm = 1.8727e-01, time/batch = 0.6729s	
5116/22950 (epoch 11.146), train_loss = 1.29951574, grad/param norm = 2.0519e-01, time/batch = 0.6870s	
5117/22950 (epoch 11.148), train_loss = 1.24553837, grad/param norm = 1.8235e-01, time/batch = 0.6715s	
5118/22950 (epoch 11.150), train_loss = 1.29324573, grad/param norm = 1.9215e-01, time/batch = 0.6739s	
5119/22950 (epoch 11.153), train_loss = 1.25945849, grad/param norm = 1.9093e-01, time/batch = 0.7086s	
5120/22950 (epoch 11.155), train_loss = 1.21809800, grad/param norm = 1.6797e-01, time/batch = 0.6995s	
5121/22950 (epoch 11.157), train_loss = 1.22373031, grad/param norm = 2.0169e-01, time/batch = 0.6731s	
5122/22950 (epoch 11.159), train_loss = 1.18805861, grad/param norm = 1.7345e-01, time/batch = 0.6737s	
5123/22950 (epoch 11.161), train_loss = 1.25902757, grad/param norm = 1.7619e-01, time/batch = 0.6754s	
5124/22950 (epoch 11.163), train_loss = 1.19486551, grad/param norm = 1.8367e-01, time/batch = 0.6743s	
5125/22950 (epoch 11.166), train_loss = 1.47100087, grad/param norm = 2.5170e-01, time/batch = 0.6773s	
5126/22950 (epoch 11.168), train_loss = 1.43377501, grad/param norm = 2.1256e-01, time/batch = 0.6899s	
5127/22950 (epoch 11.170), train_loss = 1.36787777, grad/param norm = 2.1600e-01, time/batch = 0.6978s	
5128/22950 (epoch 11.172), train_loss = 1.29862978, grad/param norm = 1.9175e-01, time/batch = 0.7241s	
5129/22950 (epoch 11.174), train_loss = 1.38924599, grad/param norm = 2.1373e-01, time/batch = 0.7155s	
5130/22950 (epoch 11.176), train_loss = 1.46088006, grad/param norm = 1.9992e-01, time/batch = 0.7009s	
5131/22950 (epoch 11.179), train_loss = 1.34861173, grad/param norm = 1.9011e-01, time/batch = 0.7037s	
5132/22950 (epoch 11.181), train_loss = 1.49972320, grad/param norm = 1.9811e-01, time/batch = 0.6851s	
5133/22950 (epoch 11.183), train_loss = 1.39797756, grad/param norm = 2.0400e-01, time/batch = 0.6843s	
5134/22950 (epoch 11.185), train_loss = 1.36706090, grad/param norm = 1.9595e-01, time/batch = 0.6950s	
5135/22950 (epoch 11.187), train_loss = 1.15863204, grad/param norm = 1.8718e-01, time/batch = 0.7007s	
5136/22950 (epoch 11.190), train_loss = 1.19802862, grad/param norm = 1.9981e-01, time/batch = 0.6976s	
5137/22950 (epoch 11.192), train_loss = 1.18483345, grad/param norm = 1.8109e-01, time/batch = 0.6853s	
5138/22950 (epoch 11.194), train_loss = 1.24746400, grad/param norm = 2.0787e-01, time/batch = 0.6903s	
5139/22950 (epoch 11.196), train_loss = 1.12469485, grad/param norm = 1.8920e-01, time/batch = 0.7086s	
5140/22950 (epoch 11.198), train_loss = 1.37918110, grad/param norm = 1.8892e-01, time/batch = 0.6943s	
5141/22950 (epoch 11.200), train_loss = 1.17197111, grad/param norm = 1.7868e-01, time/batch = 0.6806s	
5142/22950 (epoch 11.203), train_loss = 1.12162163, grad/param norm = 1.7626e-01, time/batch = 0.6836s	
5143/22950 (epoch 11.205), train_loss = 1.22983731, grad/param norm = 1.8946e-01, time/batch = 0.6756s	
5144/22950 (epoch 11.207), train_loss = 1.26262750, grad/param norm = 1.8893e-01, time/batch = 0.6731s	
5145/22950 (epoch 11.209), train_loss = 1.39900902, grad/param norm = 2.0589e-01, time/batch = 0.6733s	
5146/22950 (epoch 11.211), train_loss = 1.12204733, grad/param norm = 1.9607e-01, time/batch = 0.6741s	
5147/22950 (epoch 11.214), train_loss = 1.27702039, grad/param norm = 1.8349e-01, time/batch = 0.6744s	
5148/22950 (epoch 11.216), train_loss = 1.39692538, grad/param norm = 2.0434e-01, time/batch = 0.6768s	
5149/22950 (epoch 11.218), train_loss = 1.28449572, grad/param norm = 1.8236e-01, time/batch = 0.6958s	
5150/22950 (epoch 11.220), train_loss = 1.43371817, grad/param norm = 2.3924e-01, time/batch = 0.7037s	
5151/22950 (epoch 11.222), train_loss = 1.41649413, grad/param norm = 2.3107e-01, time/batch = 0.6772s	
5152/22950 (epoch 11.224), train_loss = 1.26460798, grad/param norm = 1.9344e-01, time/batch = 0.6768s	
5153/22950 (epoch 11.227), train_loss = 1.33701823, grad/param norm = 1.8683e-01, time/batch = 0.6776s	
5154/22950 (epoch 11.229), train_loss = 1.34845161, grad/param norm = 2.0828e-01, time/batch = 0.6787s	
5155/22950 (epoch 11.231), train_loss = 1.15339581, grad/param norm = 1.7688e-01, time/batch = 0.6768s	
5156/22950 (epoch 11.233), train_loss = 1.24409947, grad/param norm = 1.8893e-01, time/batch = 0.6772s	
5157/22950 (epoch 11.235), train_loss = 1.42970470, grad/param norm = 2.0556e-01, time/batch = 0.6767s	
5158/22950 (epoch 11.237), train_loss = 1.18527425, grad/param norm = 1.7754e-01, time/batch = 0.6779s	
5159/22950 (epoch 11.240), train_loss = 1.28379828, grad/param norm = 2.1327e-01, time/batch = 0.6932s	
5160/22950 (epoch 11.242), train_loss = 1.40413455, grad/param norm = 1.9961e-01, time/batch = 0.7119s	
5161/22950 (epoch 11.244), train_loss = 1.50472928, grad/param norm = 2.2362e-01, time/batch = 0.6802s	
5162/22950 (epoch 11.246), train_loss = 1.43393884, grad/param norm = 1.9441e-01, time/batch = 0.6744s	
5163/22950 (epoch 11.248), train_loss = 1.34718374, grad/param norm = 2.1671e-01, time/batch = 0.6767s	
5164/22950 (epoch 11.251), train_loss = 1.25082176, grad/param norm = 1.9615e-01, time/batch = 0.6779s	
5165/22950 (epoch 11.253), train_loss = 1.25125707, grad/param norm = 2.0792e-01, time/batch = 0.6703s	
5166/22950 (epoch 11.255), train_loss = 1.28740066, grad/param norm = 2.0098e-01, time/batch = 0.6730s	
5167/22950 (epoch 11.257), train_loss = 1.40948956, grad/param norm = 2.0688e-01, time/batch = 0.6715s	
5168/22950 (epoch 11.259), train_loss = 1.15797963, grad/param norm = 2.0086e-01, time/batch = 0.6703s	
5169/22950 (epoch 11.261), train_loss = 1.27874684, grad/param norm = 1.9896e-01, time/batch = 0.6847s	
5170/22950 (epoch 11.264), train_loss = 1.19485874, grad/param norm = 1.7033e-01, time/batch = 0.6976s	
5171/22950 (epoch 11.266), train_loss = 1.36354034, grad/param norm = 1.9789e-01, time/batch = 0.6801s	
5172/22950 (epoch 11.268), train_loss = 1.34031983, grad/param norm = 1.8068e-01, time/batch = 0.6766s	
5173/22950 (epoch 11.270), train_loss = 1.31398987, grad/param norm = 1.8827e-01, time/batch = 0.6757s	
5174/22950 (epoch 11.272), train_loss = 1.42887587, grad/param norm = 1.9494e-01, time/batch = 0.6736s	
5175/22950 (epoch 11.275), train_loss = 1.22256608, grad/param norm = 1.8878e-01, time/batch = 0.6732s	
5176/22950 (epoch 11.277), train_loss = 1.13653643, grad/param norm = 1.6660e-01, time/batch = 0.6732s	
5177/22950 (epoch 11.279), train_loss = 1.31644414, grad/param norm = 2.1330e-01, time/batch = 0.6780s	
5178/22950 (epoch 11.281), train_loss = 1.20986327, grad/param norm = 1.9150e-01, time/batch = 0.6771s	
5179/22950 (epoch 11.283), train_loss = 1.09861690, grad/param norm = 1.7589e-01, time/batch = 0.6740s	
5180/22950 (epoch 11.285), train_loss = 1.27647035, grad/param norm = 1.7417e-01, time/batch = 0.6736s	
5181/22950 (epoch 11.288), train_loss = 1.29443313, grad/param norm = 1.7170e-01, time/batch = 0.6781s	
5182/22950 (epoch 11.290), train_loss = 1.19156681, grad/param norm = 1.7201e-01, time/batch = 0.6778s	
5183/22950 (epoch 11.292), train_loss = 1.34152391, grad/param norm = 1.9063e-01, time/batch = 0.6783s	
5184/22950 (epoch 11.294), train_loss = 1.28702506, grad/param norm = 1.8609e-01, time/batch = 0.6758s	
5185/22950 (epoch 11.296), train_loss = 1.06984019, grad/param norm = 1.6251e-01, time/batch = 0.6790s	
5186/22950 (epoch 11.298), train_loss = 1.28733973, grad/param norm = 1.7921e-01, time/batch = 0.6867s	
5187/22950 (epoch 11.301), train_loss = 1.32515445, grad/param norm = 1.9095e-01, time/batch = 0.6753s	
5188/22950 (epoch 11.303), train_loss = 1.34467863, grad/param norm = 2.0119e-01, time/batch = 0.6773s	
5189/22950 (epoch 11.305), train_loss = 1.35687158, grad/param norm = 1.9425e-01, time/batch = 0.6758s	
5190/22950 (epoch 11.307), train_loss = 1.43908986, grad/param norm = 2.1654e-01, time/batch = 0.6764s	
5191/22950 (epoch 11.309), train_loss = 1.25102839, grad/param norm = 1.7103e-01, time/batch = 0.6781s	
5192/22950 (epoch 11.312), train_loss = 1.30607653, grad/param norm = 1.9872e-01, time/batch = 0.6828s	
5193/22950 (epoch 11.314), train_loss = 1.22161815, grad/param norm = 1.8333e-01, time/batch = 0.6738s	
5194/22950 (epoch 11.316), train_loss = 1.31087550, grad/param norm = 1.9639e-01, time/batch = 0.6728s	
5195/22950 (epoch 11.318), train_loss = 1.09620171, grad/param norm = 1.8407e-01, time/batch = 0.6751s	
5196/22950 (epoch 11.320), train_loss = 1.23939156, grad/param norm = 1.6812e-01, time/batch = 0.6750s	
5197/22950 (epoch 11.322), train_loss = 1.27822602, grad/param norm = 1.9519e-01, time/batch = 0.6770s	
5198/22950 (epoch 11.325), train_loss = 1.02785392, grad/param norm = 1.7789e-01, time/batch = 0.6719s	
5199/22950 (epoch 11.327), train_loss = 1.06036496, grad/param norm = 1.7050e-01, time/batch = 0.6751s	
5200/22950 (epoch 11.329), train_loss = 1.19200044, grad/param norm = 1.8872e-01, time/batch = 0.6836s	
5201/22950 (epoch 11.331), train_loss = 1.12704564, grad/param norm = 1.8681e-01, time/batch = 0.7007s	
5202/22950 (epoch 11.333), train_loss = 1.24438990, grad/param norm = 1.8963e-01, time/batch = 0.6926s	
5203/22950 (epoch 11.336), train_loss = 1.26877245, grad/param norm = 2.0969e-01, time/batch = 0.6919s	
5204/22950 (epoch 11.338), train_loss = 1.20649073, grad/param norm = 1.8214e-01, time/batch = 0.6953s	
5205/22950 (epoch 11.340), train_loss = 1.26569291, grad/param norm = 2.0148e-01, time/batch = 0.6991s	
5206/22950 (epoch 11.342), train_loss = 1.36087933, grad/param norm = 1.9700e-01, time/batch = 0.6985s	
5207/22950 (epoch 11.344), train_loss = 1.28100330, grad/param norm = 1.9805e-01, time/batch = 0.6852s	
5208/22950 (epoch 11.346), train_loss = 1.47130880, grad/param norm = 2.3019e-01, time/batch = 0.6841s	
5209/22950 (epoch 11.349), train_loss = 1.30134625, grad/param norm = 2.0332e-01, time/batch = 0.6800s	
5210/22950 (epoch 11.351), train_loss = 1.32390191, grad/param norm = 1.9928e-01, time/batch = 0.6786s	
5211/22950 (epoch 11.353), train_loss = 1.39133079, grad/param norm = 2.1636e-01, time/batch = 0.6899s	
5212/22950 (epoch 11.355), train_loss = 1.40624014, grad/param norm = 1.9591e-01, time/batch = 0.6801s	
5213/22950 (epoch 11.357), train_loss = 1.29466402, grad/param norm = 1.9283e-01, time/batch = 0.6796s	
5214/22950 (epoch 11.359), train_loss = 1.34364556, grad/param norm = 2.1127e-01, time/batch = 0.7013s	
5215/22950 (epoch 11.362), train_loss = 1.26560083, grad/param norm = 1.9380e-01, time/batch = 0.7079s	
5216/22950 (epoch 11.364), train_loss = 1.28908668, grad/param norm = 1.9103e-01, time/batch = 0.6976s	
5217/22950 (epoch 11.366), train_loss = 1.12451700, grad/param norm = 1.7994e-01, time/batch = 0.6837s	
5218/22950 (epoch 11.368), train_loss = 1.31288957, grad/param norm = 2.1742e-01, time/batch = 0.6790s	
5219/22950 (epoch 11.370), train_loss = 1.26444615, grad/param norm = 1.9347e-01, time/batch = 0.6779s	
5220/22950 (epoch 11.373), train_loss = 1.14306860, grad/param norm = 1.8887e-01, time/batch = 0.6786s	
5221/22950 (epoch 11.375), train_loss = 1.41826092, grad/param norm = 2.1635e-01, time/batch = 0.6799s	
5222/22950 (epoch 11.377), train_loss = 1.24020570, grad/param norm = 1.9374e-01, time/batch = 0.6825s	
5223/22950 (epoch 11.379), train_loss = 1.36575313, grad/param norm = 2.0155e-01, time/batch = 0.6753s	
5224/22950 (epoch 11.381), train_loss = 1.10449567, grad/param norm = 1.8300e-01, time/batch = 0.6773s	
5225/22950 (epoch 11.383), train_loss = 1.33664788, grad/param norm = 2.0332e-01, time/batch = 0.6794s	
5226/22950 (epoch 11.386), train_loss = 1.24959445, grad/param norm = 2.0232e-01, time/batch = 0.6747s	
5227/22950 (epoch 11.388), train_loss = 1.30938514, grad/param norm = 2.0562e-01, time/batch = 0.6716s	
5228/22950 (epoch 11.390), train_loss = 1.18765877, grad/param norm = 1.9122e-01, time/batch = 0.6745s	
5229/22950 (epoch 11.392), train_loss = 1.15926986, grad/param norm = 1.7956e-01, time/batch = 0.6789s	
5230/22950 (epoch 11.394), train_loss = 1.20077441, grad/param norm = 1.7193e-01, time/batch = 0.6892s	
5231/22950 (epoch 11.397), train_loss = 1.39209799, grad/param norm = 2.1128e-01, time/batch = 0.6948s	
5232/22950 (epoch 11.399), train_loss = 1.39862923, grad/param norm = 2.0852e-01, time/batch = 0.6775s	
5233/22950 (epoch 11.401), train_loss = 1.57124183, grad/param norm = 2.0948e-01, time/batch = 0.6743s	
5234/22950 (epoch 11.403), train_loss = 1.23736829, grad/param norm = 1.9087e-01, time/batch = 0.6758s	
5235/22950 (epoch 11.405), train_loss = 1.38469464, grad/param norm = 2.1224e-01, time/batch = 0.6753s	
5236/22950 (epoch 11.407), train_loss = 1.46341891, grad/param norm = 2.1411e-01, time/batch = 0.6751s	
5237/22950 (epoch 11.410), train_loss = 1.17244167, grad/param norm = 1.8090e-01, time/batch = 0.7079s	
5238/22950 (epoch 11.412), train_loss = 1.33206374, grad/param norm = 2.1744e-01, time/batch = 0.6931s	
5239/22950 (epoch 11.414), train_loss = 1.40195062, grad/param norm = 2.2310e-01, time/batch = 0.6757s	
5240/22950 (epoch 11.416), train_loss = 1.36999647, grad/param norm = 2.1567e-01, time/batch = 0.6737s	
5241/22950 (epoch 11.418), train_loss = 1.34655798, grad/param norm = 1.9785e-01, time/batch = 0.7082s	
5242/22950 (epoch 11.420), train_loss = 1.36588551, grad/param norm = 1.9781e-01, time/batch = 0.6794s	
5243/22950 (epoch 11.423), train_loss = 1.19036249, grad/param norm = 1.7376e-01, time/batch = 0.6867s	
5244/22950 (epoch 11.425), train_loss = 1.29152666, grad/param norm = 1.8803e-01, time/batch = 0.6914s	
5245/22950 (epoch 11.427), train_loss = 1.25177477, grad/param norm = 1.9195e-01, time/batch = 0.6844s	
5246/22950 (epoch 11.429), train_loss = 1.26853733, grad/param norm = 2.0414e-01, time/batch = 0.6783s	
5247/22950 (epoch 11.431), train_loss = 1.34514718, grad/param norm = 2.0339e-01, time/batch = 0.6934s	
5248/22950 (epoch 11.434), train_loss = 1.28195888, grad/param norm = 1.9214e-01, time/batch = 0.6755s	
5249/22950 (epoch 11.436), train_loss = 1.52249969, grad/param norm = 2.1475e-01, time/batch = 0.6731s	
5250/22950 (epoch 11.438), train_loss = 1.30010225, grad/param norm = 1.9799e-01, time/batch = 0.6748s	
5251/22950 (epoch 11.440), train_loss = 1.37056263, grad/param norm = 2.0974e-01, time/batch = 0.6748s	
5252/22950 (epoch 11.442), train_loss = 1.46452890, grad/param norm = 2.1016e-01, time/batch = 0.6736s	
5253/22950 (epoch 11.444), train_loss = 1.39309923, grad/param norm = 1.9840e-01, time/batch = 0.6912s	
5254/22950 (epoch 11.447), train_loss = 1.51461545, grad/param norm = 2.1110e-01, time/batch = 0.6885s	
5255/22950 (epoch 11.449), train_loss = 1.16819956, grad/param norm = 1.6831e-01, time/batch = 0.6766s	
5256/22950 (epoch 11.451), train_loss = 1.32745207, grad/param norm = 1.8867e-01, time/batch = 0.6757s	
5257/22950 (epoch 11.453), train_loss = 1.34474592, grad/param norm = 1.8774e-01, time/batch = 0.6829s	
5258/22950 (epoch 11.455), train_loss = 1.18388035, grad/param norm = 1.7910e-01, time/batch = 0.6755s	
5259/22950 (epoch 11.458), train_loss = 1.43226853, grad/param norm = 1.9221e-01, time/batch = 0.6852s	
5260/22950 (epoch 11.460), train_loss = 1.31215690, grad/param norm = 1.9643e-01, time/batch = 0.6787s	
5261/22950 (epoch 11.462), train_loss = 1.28916828, grad/param norm = 1.8463e-01, time/batch = 0.6725s	
5262/22950 (epoch 11.464), train_loss = 1.25153677, grad/param norm = 1.9262e-01, time/batch = 0.6725s	
5263/22950 (epoch 11.466), train_loss = 1.32625629, grad/param norm = 1.9833e-01, time/batch = 0.6717s	
5264/22950 (epoch 11.468), train_loss = 1.42904928, grad/param norm = 1.9766e-01, time/batch = 0.6751s	
5265/22950 (epoch 11.471), train_loss = 1.32816931, grad/param norm = 1.9067e-01, time/batch = 0.6873s	
5266/22950 (epoch 11.473), train_loss = 1.38745867, grad/param norm = 2.1099e-01, time/batch = 0.6787s	
5267/22950 (epoch 11.475), train_loss = 1.55947213, grad/param norm = 2.2388e-01, time/batch = 0.6731s	
5268/22950 (epoch 11.477), train_loss = 1.28870916, grad/param norm = 2.0136e-01, time/batch = 0.6766s	
5269/22950 (epoch 11.479), train_loss = 1.22877951, grad/param norm = 1.9142e-01, time/batch = 0.6773s	
5270/22950 (epoch 11.481), train_loss = 1.47608755, grad/param norm = 2.1178e-01, time/batch = 0.6726s	
5271/22950 (epoch 11.484), train_loss = 1.37042003, grad/param norm = 1.9865e-01, time/batch = 0.6766s	
5272/22950 (epoch 11.486), train_loss = 1.16052976, grad/param norm = 1.8834e-01, time/batch = 0.6777s	
5273/22950 (epoch 11.488), train_loss = 1.29515971, grad/param norm = 2.0762e-01, time/batch = 0.6775s	
5274/22950 (epoch 11.490), train_loss = 1.13216859, grad/param norm = 1.9556e-01, time/batch = 0.6827s	
5275/22950 (epoch 11.492), train_loss = 1.29395618, grad/param norm = 1.9685e-01, time/batch = 0.6779s	
5276/22950 (epoch 11.495), train_loss = 1.27865876, grad/param norm = 1.8801e-01, time/batch = 0.6726s	
5277/22950 (epoch 11.497), train_loss = 1.38075909, grad/param norm = 1.9129e-01, time/batch = 0.6754s	
5278/22950 (epoch 11.499), train_loss = 1.41048746, grad/param norm = 2.0493e-01, time/batch = 0.7092s	
5279/22950 (epoch 11.501), train_loss = 1.36640344, grad/param norm = 1.9184e-01, time/batch = 0.6910s	
5280/22950 (epoch 11.503), train_loss = 1.40325421, grad/param norm = 1.9733e-01, time/batch = 0.6740s	
5281/22950 (epoch 11.505), train_loss = 1.16728337, grad/param norm = 1.7401e-01, time/batch = 0.6769s	
5282/22950 (epoch 11.508), train_loss = 1.36295294, grad/param norm = 1.9080e-01, time/batch = 0.6743s	
5283/22950 (epoch 11.510), train_loss = 1.31396530, grad/param norm = 1.9112e-01, time/batch = 0.6735s	
5284/22950 (epoch 11.512), train_loss = 1.20577104, grad/param norm = 1.7308e-01, time/batch = 0.6767s	
5285/22950 (epoch 11.514), train_loss = 1.17600355, grad/param norm = 1.7584e-01, time/batch = 0.6722s	
5286/22950 (epoch 11.516), train_loss = 1.27531783, grad/param norm = 2.1049e-01, time/batch = 0.6741s	
5287/22950 (epoch 11.519), train_loss = 1.25896942, grad/param norm = 1.8495e-01, time/batch = 0.6800s	
5288/22950 (epoch 11.521), train_loss = 1.29238471, grad/param norm = 1.8186e-01, time/batch = 0.7059s	
5289/22950 (epoch 11.523), train_loss = 1.05293805, grad/param norm = 1.7770e-01, time/batch = 0.7003s	
5290/22950 (epoch 11.525), train_loss = 1.19566762, grad/param norm = 1.8189e-01, time/batch = 0.6759s	
5291/22950 (epoch 11.527), train_loss = 1.10780429, grad/param norm = 1.9109e-01, time/batch = 0.6779s	
5292/22950 (epoch 11.529), train_loss = 1.34985088, grad/param norm = 2.0874e-01, time/batch = 0.6736s	
5293/22950 (epoch 11.532), train_loss = 1.22891834, grad/param norm = 1.8266e-01, time/batch = 0.6766s	
5294/22950 (epoch 11.534), train_loss = 1.39525221, grad/param norm = 2.1310e-01, time/batch = 0.6751s	
5295/22950 (epoch 11.536), train_loss = 1.36837804, grad/param norm = 2.1197e-01, time/batch = 0.6757s	
5296/22950 (epoch 11.538), train_loss = 1.25123552, grad/param norm = 2.1021e-01, time/batch = 0.6791s	
5297/22950 (epoch 11.540), train_loss = 1.31382646, grad/param norm = 1.8278e-01, time/batch = 0.6771s	
5298/22950 (epoch 11.542), train_loss = 1.48564235, grad/param norm = 2.2410e-01, time/batch = 0.6756s	
5299/22950 (epoch 11.545), train_loss = 1.28184276, grad/param norm = 2.0870e-01, time/batch = 0.6776s	
5300/22950 (epoch 11.547), train_loss = 1.27738581, grad/param norm = 1.9093e-01, time/batch = 0.6754s	
5301/22950 (epoch 11.549), train_loss = 1.27729803, grad/param norm = 1.8967e-01, time/batch = 0.6883s	
5302/22950 (epoch 11.551), train_loss = 1.29865054, grad/param norm = 1.9449e-01, time/batch = 0.6988s	
5303/22950 (epoch 11.553), train_loss = 1.26621806, grad/param norm = 2.1836e-01, time/batch = 0.7115s	
5304/22950 (epoch 11.556), train_loss = 1.36283837, grad/param norm = 1.7868e-01, time/batch = 0.6994s	
5305/22950 (epoch 11.558), train_loss = 1.21047460, grad/param norm = 1.9571e-01, time/batch = 0.6889s	
5306/22950 (epoch 11.560), train_loss = 1.33225008, grad/param norm = 1.9627e-01, time/batch = 0.6772s	
5307/22950 (epoch 11.562), train_loss = 1.17245627, grad/param norm = 1.8236e-01, time/batch = 0.6800s	
5308/22950 (epoch 11.564), train_loss = 1.48995330, grad/param norm = 2.3886e-01, time/batch = 0.6782s	
5309/22950 (epoch 11.566), train_loss = 1.30321213, grad/param norm = 1.8952e-01, time/batch = 0.6819s	
5310/22950 (epoch 11.569), train_loss = 1.42906615, grad/param norm = 1.9281e-01, time/batch = 0.6789s	
5311/22950 (epoch 11.571), train_loss = 1.17438649, grad/param norm = 2.0204e-01, time/batch = 0.6979s	
5312/22950 (epoch 11.573), train_loss = 1.30631734, grad/param norm = 2.0425e-01, time/batch = 0.7029s	
5313/22950 (epoch 11.575), train_loss = 1.51690426, grad/param norm = 2.1348e-01, time/batch = 0.6944s	
5314/22950 (epoch 11.577), train_loss = 1.29889714, grad/param norm = 2.1387e-01, time/batch = 0.6984s	
5315/22950 (epoch 11.580), train_loss = 1.35329509, grad/param norm = 2.0837e-01, time/batch = 0.7053s	
5316/22950 (epoch 11.582), train_loss = 1.50917963, grad/param norm = 1.9628e-01, time/batch = 0.7023s	
5317/22950 (epoch 11.584), train_loss = 1.15523054, grad/param norm = 1.8512e-01, time/batch = 0.6965s	
5318/22950 (epoch 11.586), train_loss = 1.25686508, grad/param norm = 1.9753e-01, time/batch = 0.6886s	
5319/22950 (epoch 11.588), train_loss = 1.42833751, grad/param norm = 1.9388e-01, time/batch = 0.6949s	
5320/22950 (epoch 11.590), train_loss = 1.27452880, grad/param norm = 1.9088e-01, time/batch = 0.6841s	
5321/22950 (epoch 11.593), train_loss = 1.16453304, grad/param norm = 1.9366e-01, time/batch = 0.6874s	
5322/22950 (epoch 11.595), train_loss = 1.18140413, grad/param norm = 2.0315e-01, time/batch = 0.6914s	
5323/22950 (epoch 11.597), train_loss = 1.37644898, grad/param norm = 2.0994e-01, time/batch = 0.6772s	
5324/22950 (epoch 11.599), train_loss = 1.33352942, grad/param norm = 2.1788e-01, time/batch = 0.6717s	
5325/22950 (epoch 11.601), train_loss = 1.29331136, grad/param norm = 1.9834e-01, time/batch = 0.6715s	
5326/22950 (epoch 11.603), train_loss = 1.43866376, grad/param norm = 1.9213e-01, time/batch = 0.6734s	
5327/22950 (epoch 11.606), train_loss = 1.25855241, grad/param norm = 1.9776e-01, time/batch = 0.6755s	
5328/22950 (epoch 11.608), train_loss = 1.30692686, grad/param norm = 1.8692e-01, time/batch = 0.6789s	
5329/22950 (epoch 11.610), train_loss = 1.26921769, grad/param norm = 1.9348e-01, time/batch = 0.6723s	
5330/22950 (epoch 11.612), train_loss = 1.30264772, grad/param norm = 1.9309e-01, time/batch = 0.6726s	
5331/22950 (epoch 11.614), train_loss = 1.42940110, grad/param norm = 2.1826e-01, time/batch = 0.6784s	
5332/22950 (epoch 11.617), train_loss = 1.26692817, grad/param norm = 1.8965e-01, time/batch = 0.6839s	
5333/22950 (epoch 11.619), train_loss = 1.18696825, grad/param norm = 1.6716e-01, time/batch = 0.6772s	
5334/22950 (epoch 11.621), train_loss = 1.38273556, grad/param norm = 1.8483e-01, time/batch = 0.6753s	
5335/22950 (epoch 11.623), train_loss = 1.35067869, grad/param norm = 1.7966e-01, time/batch = 0.6808s	
5336/22950 (epoch 11.625), train_loss = 1.27781484, grad/param norm = 1.8121e-01, time/batch = 0.6762s	
5337/22950 (epoch 11.627), train_loss = 1.30565943, grad/param norm = 1.9974e-01, time/batch = 0.6746s	
5338/22950 (epoch 11.630), train_loss = 1.14825579, grad/param norm = 1.8277e-01, time/batch = 0.6751s	
5339/22950 (epoch 11.632), train_loss = 1.32404224, grad/param norm = 2.0101e-01, time/batch = 0.6756s	
5340/22950 (epoch 11.634), train_loss = 1.27864355, grad/param norm = 1.9836e-01, time/batch = 0.6747s	
5341/22950 (epoch 11.636), train_loss = 1.30826149, grad/param norm = 2.0556e-01, time/batch = 0.6752s	
5342/22950 (epoch 11.638), train_loss = 1.19145014, grad/param norm = 1.9546e-01, time/batch = 0.6771s	
5343/22950 (epoch 11.641), train_loss = 1.22762610, grad/param norm = 1.8925e-01, time/batch = 0.6889s	
5344/22950 (epoch 11.643), train_loss = 1.32180021, grad/param norm = 2.1526e-01, time/batch = 0.7111s	
5345/22950 (epoch 11.645), train_loss = 1.20808257, grad/param norm = 1.8938e-01, time/batch = 0.6749s	
5346/22950 (epoch 11.647), train_loss = 1.29176109, grad/param norm = 2.0427e-01, time/batch = 0.6726s	
5347/22950 (epoch 11.649), train_loss = 1.29798183, grad/param norm = 1.9312e-01, time/batch = 0.6771s	
5348/22950 (epoch 11.651), train_loss = 1.39435274, grad/param norm = 2.1739e-01, time/batch = 0.6766s	
5349/22950 (epoch 11.654), train_loss = 1.09045587, grad/param norm = 1.7618e-01, time/batch = 0.6784s	
5350/22950 (epoch 11.656), train_loss = 1.44304282, grad/param norm = 2.3632e-01, time/batch = 0.6815s	
5351/22950 (epoch 11.658), train_loss = 1.17303965, grad/param norm = 1.7979e-01, time/batch = 0.6817s	
5352/22950 (epoch 11.660), train_loss = 1.11245983, grad/param norm = 1.8223e-01, time/batch = 0.6878s	
5353/22950 (epoch 11.662), train_loss = 1.11753190, grad/param norm = 1.7882e-01, time/batch = 0.6905s	
5354/22950 (epoch 11.664), train_loss = 1.29284762, grad/param norm = 1.8678e-01, time/batch = 0.6856s	
5355/22950 (epoch 11.667), train_loss = 1.32523821, grad/param norm = 1.9259e-01, time/batch = 0.6831s	
5356/22950 (epoch 11.669), train_loss = 1.23395875, grad/param norm = 1.9463e-01, time/batch = 0.6847s	
5357/22950 (epoch 11.671), train_loss = 1.32553087, grad/param norm = 1.9293e-01, time/batch = 0.6843s	
5358/22950 (epoch 11.673), train_loss = 1.24893698, grad/param norm = 1.9017e-01, time/batch = 0.6842s	
5359/22950 (epoch 11.675), train_loss = 1.27650949, grad/param norm = 1.9043e-01, time/batch = 0.6842s	
5360/22950 (epoch 11.678), train_loss = 1.27145625, grad/param norm = 2.0334e-01, time/batch = 0.6868s	
5361/22950 (epoch 11.680), train_loss = 1.30100493, grad/param norm = 1.9125e-01, time/batch = 0.6867s	
5362/22950 (epoch 11.682), train_loss = 1.35949219, grad/param norm = 2.0258e-01, time/batch = 0.6903s	
5363/22950 (epoch 11.684), train_loss = 1.40706830, grad/param norm = 1.9707e-01, time/batch = 0.6855s	
5364/22950 (epoch 11.686), train_loss = 1.38580781, grad/param norm = 2.1202e-01, time/batch = 0.6869s	
5365/22950 (epoch 11.688), train_loss = 1.28737558, grad/param norm = 2.0122e-01, time/batch = 0.6890s	
5366/22950 (epoch 11.691), train_loss = 1.27579713, grad/param norm = 1.8841e-01, time/batch = 0.6873s	
5367/22950 (epoch 11.693), train_loss = 1.20440117, grad/param norm = 1.9513e-01, time/batch = 0.6904s	
5368/22950 (epoch 11.695), train_loss = 1.44958789, grad/param norm = 1.9846e-01, time/batch = 0.6870s	
5369/22950 (epoch 11.697), train_loss = 1.40599046, grad/param norm = 1.9855e-01, time/batch = 0.6872s	
5370/22950 (epoch 11.699), train_loss = 1.37933977, grad/param norm = 1.9421e-01, time/batch = 0.6879s	
5371/22950 (epoch 11.702), train_loss = 1.36986919, grad/param norm = 1.9739e-01, time/batch = 0.6894s	
5372/22950 (epoch 11.704), train_loss = 1.37270798, grad/param norm = 2.0656e-01, time/batch = 0.6895s	
5373/22950 (epoch 11.706), train_loss = 1.40305867, grad/param norm = 2.0723e-01, time/batch = 0.6872s	
5374/22950 (epoch 11.708), train_loss = 1.23216199, grad/param norm = 1.9734e-01, time/batch = 0.6883s	
5375/22950 (epoch 11.710), train_loss = 1.36430360, grad/param norm = 1.8795e-01, time/batch = 0.6936s	
5376/22950 (epoch 11.712), train_loss = 1.44151772, grad/param norm = 2.0017e-01, time/batch = 0.7073s	
5377/22950 (epoch 11.715), train_loss = 1.38337978, grad/param norm = 2.0173e-01, time/batch = 0.7054s	
5378/22950 (epoch 11.717), train_loss = 1.22048697, grad/param norm = 1.8706e-01, time/batch = 0.7124s	
5379/22950 (epoch 11.719), train_loss = 1.25868959, grad/param norm = 2.0492e-01, time/batch = 0.7134s	
5380/22950 (epoch 11.721), train_loss = 1.33907625, grad/param norm = 1.8572e-01, time/batch = 0.7041s	
5381/22950 (epoch 11.723), train_loss = 1.21053817, grad/param norm = 1.8499e-01, time/batch = 0.7052s	
5382/22950 (epoch 11.725), train_loss = 1.39173768, grad/param norm = 1.9998e-01, time/batch = 0.7101s	
5383/22950 (epoch 11.728), train_loss = 1.30533631, grad/param norm = 2.0842e-01, time/batch = 0.7072s	
5384/22950 (epoch 11.730), train_loss = 1.29748516, grad/param norm = 1.9637e-01, time/batch = 0.7054s	
5385/22950 (epoch 11.732), train_loss = 1.33419969, grad/param norm = 1.7793e-01, time/batch = 0.7032s	
5386/22950 (epoch 11.734), train_loss = 1.32056216, grad/param norm = 2.0626e-01, time/batch = 0.7039s	
5387/22950 (epoch 11.736), train_loss = 1.24145012, grad/param norm = 1.8939e-01, time/batch = 0.7063s	
5388/22950 (epoch 11.739), train_loss = 1.36587526, grad/param norm = 2.0536e-01, time/batch = 0.7211s	
5389/22950 (epoch 11.741), train_loss = 1.33783513, grad/param norm = 2.0300e-01, time/batch = 0.7313s	
5390/22950 (epoch 11.743), train_loss = 1.48492357, grad/param norm = 2.0248e-01, time/batch = 0.7332s	
5391/22950 (epoch 11.745), train_loss = 1.54224398, grad/param norm = 2.0388e-01, time/batch = 0.7362s	
5392/22950 (epoch 11.747), train_loss = 1.33540963, grad/param norm = 1.9369e-01, time/batch = 0.7334s	
5393/22950 (epoch 11.749), train_loss = 1.18960878, grad/param norm = 1.8514e-01, time/batch = 0.7473s	
5394/22950 (epoch 11.752), train_loss = 1.50606862, grad/param norm = 2.1179e-01, time/batch = 0.7338s	
5395/22950 (epoch 11.754), train_loss = 1.39203958, grad/param norm = 2.0206e-01, time/batch = 0.7296s	
5396/22950 (epoch 11.756), train_loss = 1.21923667, grad/param norm = 2.0234e-01, time/batch = 0.6975s	
5397/22950 (epoch 11.758), train_loss = 1.23908617, grad/param norm = 1.8957e-01, time/batch = 0.7095s	
5398/22950 (epoch 11.760), train_loss = 1.33816000, grad/param norm = 1.9176e-01, time/batch = 0.7184s	
5399/22950 (epoch 11.763), train_loss = 1.35144443, grad/param norm = 2.0679e-01, time/batch = 0.6996s	
5400/22950 (epoch 11.765), train_loss = 1.36405683, grad/param norm = 1.9929e-01, time/batch = 0.6935s	
5401/22950 (epoch 11.767), train_loss = 1.51781475, grad/param norm = 2.0764e-01, time/batch = 0.6939s	
5402/22950 (epoch 11.769), train_loss = 1.33584137, grad/param norm = 2.0165e-01, time/batch = 0.6938s	
5403/22950 (epoch 11.771), train_loss = 1.20158842, grad/param norm = 2.0202e-01, time/batch = 0.7148s	
5404/22950 (epoch 11.773), train_loss = 1.00484289, grad/param norm = 1.6988e-01, time/batch = 0.7192s	
5405/22950 (epoch 11.776), train_loss = 1.22231331, grad/param norm = 1.8410e-01, time/batch = 0.6973s	
5406/22950 (epoch 11.778), train_loss = 1.13751444, grad/param norm = 1.7708e-01, time/batch = 0.6918s	
5407/22950 (epoch 11.780), train_loss = 1.22882336, grad/param norm = 1.7063e-01, time/batch = 0.6947s	
5408/22950 (epoch 11.782), train_loss = 1.23752269, grad/param norm = 1.8370e-01, time/batch = 0.6947s	
5409/22950 (epoch 11.784), train_loss = 1.32121492, grad/param norm = 2.0191e-01, time/batch = 0.6921s	
5410/22950 (epoch 11.786), train_loss = 1.35978228, grad/param norm = 1.8156e-01, time/batch = 0.6915s	
5411/22950 (epoch 11.789), train_loss = 1.12345908, grad/param norm = 1.7978e-01, time/batch = 0.6927s	
5412/22950 (epoch 11.791), train_loss = 1.17506821, grad/param norm = 1.9787e-01, time/batch = 0.6918s	
5413/22950 (epoch 11.793), train_loss = 1.53796658, grad/param norm = 2.0997e-01, time/batch = 0.7129s	
5414/22950 (epoch 11.795), train_loss = 1.21787032, grad/param norm = 1.7935e-01, time/batch = 0.7228s	
5415/22950 (epoch 11.797), train_loss = 1.48041113, grad/param norm = 2.1389e-01, time/batch = 0.6923s	
5416/22950 (epoch 11.800), train_loss = 1.20759639, grad/param norm = 1.9036e-01, time/batch = 0.6907s	
5417/22950 (epoch 11.802), train_loss = 1.22186742, grad/param norm = 1.9322e-01, time/batch = 0.6961s	
5418/22950 (epoch 11.804), train_loss = 1.25609396, grad/param norm = 1.9357e-01, time/batch = 0.6923s	
5419/22950 (epoch 11.806), train_loss = 1.15405821, grad/param norm = 1.8191e-01, time/batch = 0.6878s	
5420/22950 (epoch 11.808), train_loss = 1.25614526, grad/param norm = 1.9564e-01, time/batch = 0.6887s	
5421/22950 (epoch 11.810), train_loss = 1.23926262, grad/param norm = 1.9516e-01, time/batch = 0.6990s	
5422/22950 (epoch 11.813), train_loss = 1.06224995, grad/param norm = 1.8322e-01, time/batch = 0.6995s	
5423/22950 (epoch 11.815), train_loss = 1.16212780, grad/param norm = 1.7822e-01, time/batch = 0.7155s	
5424/22950 (epoch 11.817), train_loss = 1.13744186, grad/param norm = 1.7143e-01, time/batch = 0.7209s	
5425/22950 (epoch 11.819), train_loss = 1.25457402, grad/param norm = 2.0196e-01, time/batch = 0.6895s	
5426/22950 (epoch 11.821), train_loss = 1.29614440, grad/param norm = 2.0839e-01, time/batch = 0.6911s	
5427/22950 (epoch 11.824), train_loss = 1.25352042, grad/param norm = 1.9868e-01, time/batch = 0.6920s	
5428/22950 (epoch 11.826), train_loss = 1.39377347, grad/param norm = 2.1937e-01, time/batch = 0.6908s	
5429/22950 (epoch 11.828), train_loss = 1.26096690, grad/param norm = 2.0152e-01, time/batch = 0.7088s	
5430/22950 (epoch 11.830), train_loss = 1.28255053, grad/param norm = 1.9165e-01, time/batch = 0.7043s	
5431/22950 (epoch 11.832), train_loss = 1.31381975, grad/param norm = 2.0775e-01, time/batch = 0.7093s	
5432/22950 (epoch 11.834), train_loss = 1.14436845, grad/param norm = 1.8357e-01, time/batch = 0.7029s	
5433/22950 (epoch 11.837), train_loss = 1.30392148, grad/param norm = 2.0207e-01, time/batch = 0.7162s	
5434/22950 (epoch 11.839), train_loss = 1.15368867, grad/param norm = 1.8002e-01, time/batch = 0.7181s	
5435/22950 (epoch 11.841), train_loss = 1.17503765, grad/param norm = 1.7164e-01, time/batch = 0.6890s	
5436/22950 (epoch 11.843), train_loss = 1.23412336, grad/param norm = 2.0336e-01, time/batch = 0.6917s	
5437/22950 (epoch 11.845), train_loss = 1.28283152, grad/param norm = 2.0020e-01, time/batch = 0.6934s	
5438/22950 (epoch 11.847), train_loss = 1.38327177, grad/param norm = 1.9665e-01, time/batch = 0.6962s	
5439/22950 (epoch 11.850), train_loss = 1.32322721, grad/param norm = 2.2441e-01, time/batch = 0.7020s	
5440/22950 (epoch 11.852), train_loss = 1.35361202, grad/param norm = 1.9908e-01, time/batch = 0.6926s	
5441/22950 (epoch 11.854), train_loss = 1.28109131, grad/param norm = 2.0772e-01, time/batch = 0.6978s	
5442/22950 (epoch 11.856), train_loss = 1.48456184, grad/param norm = 2.0735e-01, time/batch = 0.6921s	
5443/22950 (epoch 11.858), train_loss = 1.34571820, grad/param norm = 1.9408e-01, time/batch = 0.6948s	
5444/22950 (epoch 11.861), train_loss = 1.40198994, grad/param norm = 2.0926e-01, time/batch = 0.6966s	
5445/22950 (epoch 11.863), train_loss = 1.44367802, grad/param norm = 2.1093e-01, time/batch = 0.7010s	
5446/22950 (epoch 11.865), train_loss = 1.48883719, grad/param norm = 2.0893e-01, time/batch = 0.6950s	
5447/22950 (epoch 11.867), train_loss = 1.34302306, grad/param norm = 2.0573e-01, time/batch = 0.6965s	
5448/22950 (epoch 11.869), train_loss = 1.51637593, grad/param norm = 2.1660e-01, time/batch = 0.6937s	
5449/22950 (epoch 11.871), train_loss = 1.32657099, grad/param norm = 2.1438e-01, time/batch = 0.6935s	
5450/22950 (epoch 11.874), train_loss = 1.28353723, grad/param norm = 1.9618e-01, time/batch = 0.6942s	
5451/22950 (epoch 11.876), train_loss = 1.34111102, grad/param norm = 1.9144e-01, time/batch = 0.7045s	
5452/22950 (epoch 11.878), train_loss = 1.25057622, grad/param norm = 2.1769e-01, time/batch = 0.7049s	
5453/22950 (epoch 11.880), train_loss = 1.46319733, grad/param norm = 1.9701e-01, time/batch = 0.7027s	
5454/22950 (epoch 11.882), train_loss = 1.16966667, grad/param norm = 1.8301e-01, time/batch = 0.7015s	
5455/22950 (epoch 11.885), train_loss = 1.32817294, grad/param norm = 2.0038e-01, time/batch = 0.6944s	
5456/22950 (epoch 11.887), train_loss = 1.32030834, grad/param norm = 2.1054e-01, time/batch = 0.6954s	
5457/22950 (epoch 11.889), train_loss = 1.39647366, grad/param norm = 2.2697e-01, time/batch = 0.6922s	
5458/22950 (epoch 11.891), train_loss = 1.28748246, grad/param norm = 2.0332e-01, time/batch = 0.6924s	
5459/22950 (epoch 11.893), train_loss = 1.32483692, grad/param norm = 2.0513e-01, time/batch = 0.6939s	
5460/22950 (epoch 11.895), train_loss = 1.48563131, grad/param norm = 2.0637e-01, time/batch = 0.7148s	
5461/22950 (epoch 11.898), train_loss = 1.30368678, grad/param norm = 1.9952e-01, time/batch = 0.6941s	
5462/22950 (epoch 11.900), train_loss = 1.18779262, grad/param norm = 1.7348e-01, time/batch = 0.6919s	
5463/22950 (epoch 11.902), train_loss = 1.36610006, grad/param norm = 1.9347e-01, time/batch = 0.7003s	
5464/22950 (epoch 11.904), train_loss = 1.33777452, grad/param norm = 1.9054e-01, time/batch = 0.6856s	
5465/22950 (epoch 11.906), train_loss = 1.30678863, grad/param norm = 1.8550e-01, time/batch = 0.6890s	
5466/22950 (epoch 11.908), train_loss = 1.20426020, grad/param norm = 2.0447e-01, time/batch = 0.6872s	
5467/22950 (epoch 11.911), train_loss = 1.13634045, grad/param norm = 1.6877e-01, time/batch = 0.6898s	
5468/22950 (epoch 11.913), train_loss = 1.26015895, grad/param norm = 1.9781e-01, time/batch = 0.6875s	
5469/22950 (epoch 11.915), train_loss = 1.42007719, grad/param norm = 2.2386e-01, time/batch = 0.6910s	
5470/22950 (epoch 11.917), train_loss = 1.14790855, grad/param norm = 1.8569e-01, time/batch = 0.6897s	
5471/22950 (epoch 11.919), train_loss = 1.25046277, grad/param norm = 1.9369e-01, time/batch = 0.6894s	
5472/22950 (epoch 11.922), train_loss = 1.28319193, grad/param norm = 1.9885e-01, time/batch = 0.6904s	
5473/22950 (epoch 11.924), train_loss = 1.35919039, grad/param norm = 1.9232e-01, time/batch = 0.7006s	
5474/22950 (epoch 11.926), train_loss = 1.15376809, grad/param norm = 1.8878e-01, time/batch = 0.7209s	
5475/22950 (epoch 11.928), train_loss = 1.15115078, grad/param norm = 2.0214e-01, time/batch = 0.7322s	
5476/22950 (epoch 11.930), train_loss = 1.13055900, grad/param norm = 2.0926e-01, time/batch = 0.7267s	
5477/22950 (epoch 11.932), train_loss = 1.10375642, grad/param norm = 1.7894e-01, time/batch = 0.7023s	
5478/22950 (epoch 11.935), train_loss = 1.32514091, grad/param norm = 1.9428e-01, time/batch = 0.6911s	
5479/22950 (epoch 11.937), train_loss = 1.32287527, grad/param norm = 2.1189e-01, time/batch = 0.6944s	
5480/22950 (epoch 11.939), train_loss = 1.23391220, grad/param norm = 2.0086e-01, time/batch = 0.6916s	
5481/22950 (epoch 11.941), train_loss = 1.18195890, grad/param norm = 1.9012e-01, time/batch = 0.6966s	
5482/22950 (epoch 11.943), train_loss = 1.29683174, grad/param norm = 2.0356e-01, time/batch = 0.6913s	
5483/22950 (epoch 11.946), train_loss = 1.14631133, grad/param norm = 2.0244e-01, time/batch = 0.6908s	
5484/22950 (epoch 11.948), train_loss = 1.32840454, grad/param norm = 1.8186e-01, time/batch = 0.6887s	
5485/22950 (epoch 11.950), train_loss = 1.33039272, grad/param norm = 2.0191e-01, time/batch = 0.6874s	
5486/22950 (epoch 11.952), train_loss = 1.32777799, grad/param norm = 2.0593e-01, time/batch = 0.6892s	
5487/22950 (epoch 11.954), train_loss = 1.29076866, grad/param norm = 1.8236e-01, time/batch = 0.6880s	
5488/22950 (epoch 11.956), train_loss = 1.20843566, grad/param norm = 1.8875e-01, time/batch = 0.7044s	
5489/22950 (epoch 11.959), train_loss = 1.17654766, grad/param norm = 1.9830e-01, time/batch = 0.6999s	
5490/22950 (epoch 11.961), train_loss = 1.30517401, grad/param norm = 1.9744e-01, time/batch = 0.6841s	
5491/22950 (epoch 11.963), train_loss = 1.33828410, grad/param norm = 2.0718e-01, time/batch = 0.6966s	
5492/22950 (epoch 11.965), train_loss = 1.47297763, grad/param norm = 2.0773e-01, time/batch = 0.6868s	
5493/22950 (epoch 11.967), train_loss = 1.30350744, grad/param norm = 2.2549e-01, time/batch = 0.6876s	
5494/22950 (epoch 11.969), train_loss = 1.20715233, grad/param norm = 1.9851e-01, time/batch = 0.6867s	
5495/22950 (epoch 11.972), train_loss = 1.27341400, grad/param norm = 1.9159e-01, time/batch = 0.6841s	
5496/22950 (epoch 11.974), train_loss = 1.20772499, grad/param norm = 1.9418e-01, time/batch = 0.6843s	
5497/22950 (epoch 11.976), train_loss = 1.12743072, grad/param norm = 1.9363e-01, time/batch = 0.6834s	
5498/22950 (epoch 11.978), train_loss = 1.25098560, grad/param norm = 1.9900e-01, time/batch = 0.6840s	
5499/22950 (epoch 11.980), train_loss = 1.27744898, grad/param norm = 1.9795e-01, time/batch = 0.6868s	
5500/22950 (epoch 11.983), train_loss = 1.20142040, grad/param norm = 1.7989e-01, time/batch = 0.6848s	
5501/22950 (epoch 11.985), train_loss = 1.13152361, grad/param norm = 1.7859e-01, time/batch = 0.6852s	
5502/22950 (epoch 11.987), train_loss = 1.16518861, grad/param norm = 1.8271e-01, time/batch = 0.6875s	
5503/22950 (epoch 11.989), train_loss = 1.30923880, grad/param norm = 1.9091e-01, time/batch = 0.6860s	
5504/22950 (epoch 11.991), train_loss = 1.11754663, grad/param norm = 1.8822e-01, time/batch = 0.6858s	
5505/22950 (epoch 11.993), train_loss = 1.30734643, grad/param norm = 2.0862e-01, time/batch = 0.6857s	
5506/22950 (epoch 11.996), train_loss = 1.37222519, grad/param norm = 2.0716e-01, time/batch = 0.6838s	
5507/22950 (epoch 11.998), train_loss = 1.21760939, grad/param norm = 1.8446e-01, time/batch = 0.6936s	
decayed learning rate by a factor 0.97 to 0.001825346	
5508/22950 (epoch 12.000), train_loss = 1.11615613, grad/param norm = 1.8398e-01, time/batch = 0.7025s	
5509/22950 (epoch 12.002), train_loss = 1.47314441, grad/param norm = 2.1047e-01, time/batch = 0.7089s	
5510/22950 (epoch 12.004), train_loss = 1.30475300, grad/param norm = 2.0085e-01, time/batch = 0.7036s	
5511/22950 (epoch 12.007), train_loss = 1.28151935, grad/param norm = 2.0316e-01, time/batch = 0.6992s	
5512/22950 (epoch 12.009), train_loss = 1.40429921, grad/param norm = 1.9334e-01, time/batch = 0.6868s	
5513/22950 (epoch 12.011), train_loss = 1.20089063, grad/param norm = 1.8499e-01, time/batch = 0.6885s	
5514/22950 (epoch 12.013), train_loss = 1.37103494, grad/param norm = 2.1080e-01, time/batch = 0.6872s	
5515/22950 (epoch 12.015), train_loss = 1.36725370, grad/param norm = 2.0693e-01, time/batch = 0.6851s	
5516/22950 (epoch 12.017), train_loss = 1.25690151, grad/param norm = 1.7447e-01, time/batch = 0.6869s	
5517/22950 (epoch 12.020), train_loss = 1.25796130, grad/param norm = 1.7503e-01, time/batch = 0.6894s	
5518/22950 (epoch 12.022), train_loss = 1.10676979, grad/param norm = 1.7929e-01, time/batch = 0.6925s	
5519/22950 (epoch 12.024), train_loss = 1.16540506, grad/param norm = 1.8143e-01, time/batch = 0.6885s	
5520/22950 (epoch 12.026), train_loss = 1.29006169, grad/param norm = 1.9608e-01, time/batch = 0.6877s	
5521/22950 (epoch 12.028), train_loss = 1.35411964, grad/param norm = 1.9424e-01, time/batch = 0.6880s	
5522/22950 (epoch 12.031), train_loss = 1.27577839, grad/param norm = 1.8738e-01, time/batch = 0.6867s	
5523/22950 (epoch 12.033), train_loss = 1.44553576, grad/param norm = 2.1401e-01, time/batch = 0.6889s	
5524/22950 (epoch 12.035), train_loss = 1.23921476, grad/param norm = 1.7091e-01, time/batch = 0.6926s	
5525/22950 (epoch 12.037), train_loss = 1.25144983, grad/param norm = 1.9796e-01, time/batch = 0.6892s	
5526/22950 (epoch 12.039), train_loss = 1.23568530, grad/param norm = 1.9503e-01, time/batch = 0.6844s	
5527/22950 (epoch 12.041), train_loss = 1.22920425, grad/param norm = 1.8950e-01, time/batch = 0.6831s	
5528/22950 (epoch 12.044), train_loss = 1.26706494, grad/param norm = 1.8331e-01, time/batch = 0.6841s	
5529/22950 (epoch 12.046), train_loss = 1.29436235, grad/param norm = 1.8872e-01, time/batch = 0.6857s	
5530/22950 (epoch 12.048), train_loss = 1.29613395, grad/param norm = 1.9466e-01, time/batch = 0.6840s	
5531/22950 (epoch 12.050), train_loss = 1.33366879, grad/param norm = 2.1139e-01, time/batch = 0.6905s	
5532/22950 (epoch 12.052), train_loss = 1.29750579, grad/param norm = 1.8557e-01, time/batch = 0.7085s	
5533/22950 (epoch 12.054), train_loss = 1.52740394, grad/param norm = 2.1595e-01, time/batch = 0.7137s	
5534/22950 (epoch 12.057), train_loss = 1.36878459, grad/param norm = 1.9945e-01, time/batch = 0.6819s	
5535/22950 (epoch 12.059), train_loss = 1.33450724, grad/param norm = 1.8591e-01, time/batch = 0.6888s	
5536/22950 (epoch 12.061), train_loss = 1.17436013, grad/param norm = 1.8218e-01, time/batch = 0.6960s	
5537/22950 (epoch 12.063), train_loss = 1.33533028, grad/param norm = 1.8886e-01, time/batch = 0.6933s	
5538/22950 (epoch 12.065), train_loss = 1.03847241, grad/param norm = 1.8763e-01, time/batch = 0.6950s	
5539/22950 (epoch 12.068), train_loss = 1.35926199, grad/param norm = 2.0192e-01, time/batch = 0.6858s	
5540/22950 (epoch 12.070), train_loss = 1.15611347, grad/param norm = 1.9003e-01, time/batch = 0.6852s	
5541/22950 (epoch 12.072), train_loss = 1.30881459, grad/param norm = 1.8860e-01, time/batch = 0.6878s	
5542/22950 (epoch 12.074), train_loss = 1.25878891, grad/param norm = 1.9703e-01, time/batch = 0.7078s	
5543/22950 (epoch 12.076), train_loss = 1.27121230, grad/param norm = 1.9778e-01, time/batch = 0.7153s	
5544/22950 (epoch 12.078), train_loss = 1.38216768, grad/param norm = 2.0248e-01, time/batch = 0.6853s	
5545/22950 (epoch 12.081), train_loss = 1.36184928, grad/param norm = 1.9305e-01, time/batch = 0.6881s	
5546/22950 (epoch 12.083), train_loss = 1.23300477, grad/param norm = 2.1578e-01, time/batch = 0.6874s	
5547/22950 (epoch 12.085), train_loss = 1.18424526, grad/param norm = 2.0540e-01, time/batch = 0.6930s	
5548/22950 (epoch 12.087), train_loss = 1.18887264, grad/param norm = 1.9407e-01, time/batch = 0.6873s	
5549/22950 (epoch 12.089), train_loss = 1.30272302, grad/param norm = 1.9471e-01, time/batch = 0.6885s	
5550/22950 (epoch 12.092), train_loss = 1.23447051, grad/param norm = 1.9755e-01, time/batch = 0.6866s	
5551/22950 (epoch 12.094), train_loss = 1.21171244, grad/param norm = 1.9285e-01, time/batch = 0.6882s	
5552/22950 (epoch 12.096), train_loss = 1.42431493, grad/param norm = 1.9848e-01, time/batch = 0.7062s	
5553/22950 (epoch 12.098), train_loss = 1.31105717, grad/param norm = 1.9785e-01, time/batch = 0.7178s	
5554/22950 (epoch 12.100), train_loss = 1.21155590, grad/param norm = 1.8797e-01, time/batch = 0.6826s	
5555/22950 (epoch 12.102), train_loss = 1.27848836, grad/param norm = 1.8522e-01, time/batch = 0.6881s	
5556/22950 (epoch 12.105), train_loss = 1.12028458, grad/param norm = 1.6334e-01, time/batch = 0.6872s	
5557/22950 (epoch 12.107), train_loss = 1.22830677, grad/param norm = 1.8969e-01, time/batch = 0.6867s	
5558/22950 (epoch 12.109), train_loss = 1.22151384, grad/param norm = 2.0392e-01, time/batch = 0.6882s	
5559/22950 (epoch 12.111), train_loss = 1.13518025, grad/param norm = 1.8841e-01, time/batch = 0.6964s	
5560/22950 (epoch 12.113), train_loss = 1.28991464, grad/param norm = 1.9318e-01, time/batch = 0.7203s	
5561/22950 (epoch 12.115), train_loss = 1.31229269, grad/param norm = 2.1609e-01, time/batch = 0.7267s	
5562/22950 (epoch 12.118), train_loss = 1.41413312, grad/param norm = 1.9749e-01, time/batch = 0.7364s	
5563/22950 (epoch 12.120), train_loss = 1.18033444, grad/param norm = 1.8133e-01, time/batch = 0.7305s	
5564/22950 (epoch 12.122), train_loss = 1.40698070, grad/param norm = 2.0189e-01, time/batch = 0.7131s	
5565/22950 (epoch 12.124), train_loss = 1.05582896, grad/param norm = 1.5534e-01, time/batch = 0.7103s	
5566/22950 (epoch 12.126), train_loss = 1.23145654, grad/param norm = 1.8984e-01, time/batch = 0.6967s	
5567/22950 (epoch 12.129), train_loss = 1.09658136, grad/param norm = 1.7854e-01, time/batch = 0.6915s	
5568/22950 (epoch 12.131), train_loss = 1.22535206, grad/param norm = 2.0032e-01, time/batch = 0.6919s	
5569/22950 (epoch 12.133), train_loss = 1.33280334, grad/param norm = 2.0094e-01, time/batch = 0.6957s	
5570/22950 (epoch 12.135), train_loss = 1.24085730, grad/param norm = 1.7835e-01, time/batch = 0.6880s	
5571/22950 (epoch 12.137), train_loss = 1.43204992, grad/param norm = 2.0392e-01, time/batch = 0.6910s	
5572/22950 (epoch 12.139), train_loss = 1.19924823, grad/param norm = 2.0832e-01, time/batch = 0.7092s	
5573/22950 (epoch 12.142), train_loss = 1.18639178, grad/param norm = 1.8911e-01, time/batch = 0.7063s	
5574/22950 (epoch 12.144), train_loss = 1.16352232, grad/param norm = 1.8421e-01, time/batch = 0.7003s	
5575/22950 (epoch 12.146), train_loss = 1.26571704, grad/param norm = 2.1050e-01, time/batch = 0.6839s	
5576/22950 (epoch 12.148), train_loss = 1.20886831, grad/param norm = 1.8706e-01, time/batch = 0.6896s	
5577/22950 (epoch 12.150), train_loss = 1.26105613, grad/param norm = 1.9552e-01, time/batch = 0.6814s	
5578/22950 (epoch 12.153), train_loss = 1.22400395, grad/param norm = 1.9347e-01, time/batch = 0.6865s	
5579/22950 (epoch 12.155), train_loss = 1.18149370, grad/param norm = 1.6840e-01, time/batch = 0.6863s	
5580/22950 (epoch 12.157), train_loss = 1.18309783, grad/param norm = 2.0026e-01, time/batch = 0.6862s	
5581/22950 (epoch 12.159), train_loss = 1.15879662, grad/param norm = 1.7206e-01, time/batch = 0.6871s	
5582/22950 (epoch 12.161), train_loss = 1.21521669, grad/param norm = 1.6975e-01, time/batch = 0.7059s	
5583/22950 (epoch 12.163), train_loss = 1.15802004, grad/param norm = 1.7856e-01, time/batch = 0.7163s	
5584/22950 (epoch 12.166), train_loss = 1.43469868, grad/param norm = 2.0622e-01, time/batch = 0.6978s	
5585/22950 (epoch 12.168), train_loss = 1.40557646, grad/param norm = 2.3603e-01, time/batch = 0.6883s	
5586/22950 (epoch 12.170), train_loss = 1.32244944, grad/param norm = 2.0894e-01, time/batch = 0.6879s	
5587/22950 (epoch 12.172), train_loss = 1.27377721, grad/param norm = 1.9256e-01, time/batch = 0.6869s	
5588/22950 (epoch 12.174), train_loss = 1.35106922, grad/param norm = 2.1231e-01, time/batch = 0.6921s	
5589/22950 (epoch 12.176), train_loss = 1.41157262, grad/param norm = 1.9514e-01, time/batch = 0.6904s	
5590/22950 (epoch 12.179), train_loss = 1.31428180, grad/param norm = 1.9100e-01, time/batch = 0.6879s	
5591/22950 (epoch 12.181), train_loss = 1.47270657, grad/param norm = 2.0264e-01, time/batch = 0.6865s	
5592/22950 (epoch 12.183), train_loss = 1.36547258, grad/param norm = 2.0659e-01, time/batch = 0.7082s	
5593/22950 (epoch 12.185), train_loss = 1.34026843, grad/param norm = 2.0033e-01, time/batch = 0.7172s	
5594/22950 (epoch 12.187), train_loss = 1.14059323, grad/param norm = 1.9117e-01, time/batch = 0.6893s	
5595/22950 (epoch 12.190), train_loss = 1.15146985, grad/param norm = 2.0003e-01, time/batch = 0.6921s	
5596/22950 (epoch 12.192), train_loss = 1.14948877, grad/param norm = 1.7920e-01, time/batch = 0.6908s	
5597/22950 (epoch 12.194), train_loss = 1.21485853, grad/param norm = 2.2707e-01, time/batch = 0.6860s	
5598/22950 (epoch 12.196), train_loss = 1.09339500, grad/param norm = 1.8705e-01, time/batch = 0.6888s	
5599/22950 (epoch 12.198), train_loss = 1.34995654, grad/param norm = 1.9718e-01, time/batch = 0.6883s	
5600/22950 (epoch 12.200), train_loss = 1.14088875, grad/param norm = 1.8196e-01, time/batch = 0.6868s	
5601/22950 (epoch 12.203), train_loss = 1.09894942, grad/param norm = 1.7641e-01, time/batch = 0.6871s	
5602/22950 (epoch 12.205), train_loss = 1.19568686, grad/param norm = 1.8502e-01, time/batch = 0.6890s	
5603/22950 (epoch 12.207), train_loss = 1.23326617, grad/param norm = 1.9418e-01, time/batch = 0.6911s	
5604/22950 (epoch 12.209), train_loss = 1.34232510, grad/param norm = 1.9213e-01, time/batch = 0.6881s	
5605/22950 (epoch 12.211), train_loss = 1.08052767, grad/param norm = 1.9812e-01, time/batch = 0.6921s	
5606/22950 (epoch 12.214), train_loss = 1.24658855, grad/param norm = 1.8306e-01, time/batch = 0.6859s	
5607/22950 (epoch 12.216), train_loss = 1.36298416, grad/param norm = 2.0469e-01, time/batch = 0.6890s	
5608/22950 (epoch 12.218), train_loss = 1.24798527, grad/param norm = 1.7857e-01, time/batch = 0.6862s	
5609/22950 (epoch 12.220), train_loss = 1.39481754, grad/param norm = 2.0702e-01, time/batch = 0.6878s	
5610/22950 (epoch 12.222), train_loss = 1.36758756, grad/param norm = 2.0577e-01, time/batch = 0.6921s	
5611/22950 (epoch 12.224), train_loss = 1.22263590, grad/param norm = 1.9259e-01, time/batch = 0.6872s	
5612/22950 (epoch 12.227), train_loss = 1.30697917, grad/param norm = 1.8658e-01, time/batch = 0.7063s	
5613/22950 (epoch 12.229), train_loss = 1.31792597, grad/param norm = 2.0537e-01, time/batch = 0.6942s	
5614/22950 (epoch 12.231), train_loss = 1.12280143, grad/param norm = 1.8504e-01, time/batch = 0.7040s	
5615/22950 (epoch 12.233), train_loss = 1.20200213, grad/param norm = 1.8588e-01, time/batch = 0.7023s	
5616/22950 (epoch 12.235), train_loss = 1.39779266, grad/param norm = 2.0850e-01, time/batch = 0.6886s	
5617/22950 (epoch 12.237), train_loss = 1.15345747, grad/param norm = 1.7635e-01, time/batch = 0.6917s	
5618/22950 (epoch 12.240), train_loss = 1.25555248, grad/param norm = 2.1555e-01, time/batch = 0.6900s	
5619/22950 (epoch 12.242), train_loss = 1.36239606, grad/param norm = 1.9259e-01, time/batch = 0.6920s	
5620/22950 (epoch 12.244), train_loss = 1.46739052, grad/param norm = 2.2655e-01, time/batch = 0.6868s	
5621/22950 (epoch 12.246), train_loss = 1.40051644, grad/param norm = 1.9999e-01, time/batch = 0.6873s	
5622/22950 (epoch 12.248), train_loss = 1.31332706, grad/param norm = 2.2047e-01, time/batch = 0.6854s	
5623/22950 (epoch 12.251), train_loss = 1.20696705, grad/param norm = 1.9614e-01, time/batch = 0.6861s	
5624/22950 (epoch 12.253), train_loss = 1.21107341, grad/param norm = 2.1111e-01, time/batch = 0.6857s	
5625/22950 (epoch 12.255), train_loss = 1.25608668, grad/param norm = 2.0226e-01, time/batch = 0.6830s	
5626/22950 (epoch 12.257), train_loss = 1.37358152, grad/param norm = 2.0776e-01, time/batch = 0.6847s	
5627/22950 (epoch 12.259), train_loss = 1.12440654, grad/param norm = 2.0121e-01, time/batch = 0.6867s	
5628/22950 (epoch 12.261), train_loss = 1.24046356, grad/param norm = 2.0088e-01, time/batch = 0.6846s	
5629/22950 (epoch 12.264), train_loss = 1.17529539, grad/param norm = 1.8353e-01, time/batch = 0.6896s	
5630/22950 (epoch 12.266), train_loss = 1.31986422, grad/param norm = 1.9444e-01, time/batch = 0.6847s	
5631/22950 (epoch 12.268), train_loss = 1.30352536, grad/param norm = 1.9457e-01, time/batch = 0.7016s	
5632/22950 (epoch 12.270), train_loss = 1.28521879, grad/param norm = 2.0795e-01, time/batch = 0.6905s	
5633/22950 (epoch 12.272), train_loss = 1.39424695, grad/param norm = 2.0147e-01, time/batch = 0.7056s	
5634/22950 (epoch 12.275), train_loss = 1.19664535, grad/param norm = 1.9854e-01, time/batch = 0.7027s	
5635/22950 (epoch 12.277), train_loss = 1.09574624, grad/param norm = 1.6443e-01, time/batch = 0.7017s	
5636/22950 (epoch 12.279), train_loss = 1.28295136, grad/param norm = 2.2083e-01, time/batch = 0.7088s	
5637/22950 (epoch 12.281), train_loss = 1.17923829, grad/param norm = 1.8683e-01, time/batch = 0.7104s	
5638/22950 (epoch 12.283), train_loss = 1.06888014, grad/param norm = 1.7307e-01, time/batch = 0.7088s	
5639/22950 (epoch 12.285), train_loss = 1.24563421, grad/param norm = 1.7292e-01, time/batch = 0.7026s	
5640/22950 (epoch 12.288), train_loss = 1.26691651, grad/param norm = 1.7293e-01, time/batch = 0.6944s	
5641/22950 (epoch 12.290), train_loss = 1.15637440, grad/param norm = 1.7090e-01, time/batch = 0.6852s	
5642/22950 (epoch 12.292), train_loss = 1.31019784, grad/param norm = 1.9137e-01, time/batch = 0.6848s	
5643/22950 (epoch 12.294), train_loss = 1.24763007, grad/param norm = 1.8735e-01, time/batch = 0.6841s	
5644/22950 (epoch 12.296), train_loss = 1.02933461, grad/param norm = 1.5787e-01, time/batch = 0.6848s	
5645/22950 (epoch 12.298), train_loss = 1.25220902, grad/param norm = 1.7632e-01, time/batch = 0.6931s	
5646/22950 (epoch 12.301), train_loss = 1.28876542, grad/param norm = 1.9559e-01, time/batch = 0.7128s	
5647/22950 (epoch 12.303), train_loss = 1.31056077, grad/param norm = 2.0282e-01, time/batch = 0.7232s	
5648/22950 (epoch 12.305), train_loss = 1.31052922, grad/param norm = 1.9595e-01, time/batch = 0.7101s	
5649/22950 (epoch 12.307), train_loss = 1.40538451, grad/param norm = 2.2026e-01, time/batch = 0.6946s	
5650/22950 (epoch 12.309), train_loss = 1.20715785, grad/param norm = 1.7279e-01, time/batch = 0.6876s	
5651/22950 (epoch 12.312), train_loss = 1.26170102, grad/param norm = 1.9353e-01, time/batch = 0.6932s	
5652/22950 (epoch 12.314), train_loss = 1.19244647, grad/param norm = 1.8612e-01, time/batch = 0.6893s	
5653/22950 (epoch 12.316), train_loss = 1.26962628, grad/param norm = 1.9000e-01, time/batch = 0.6927s	
5654/22950 (epoch 12.318), train_loss = 1.06633567, grad/param norm = 1.8207e-01, time/batch = 0.6958s	
5655/22950 (epoch 12.320), train_loss = 1.20080672, grad/param norm = 1.6965e-01, time/batch = 0.6950s	
5656/22950 (epoch 12.322), train_loss = 1.24185837, grad/param norm = 1.9611e-01, time/batch = 0.6975s	
5657/22950 (epoch 12.325), train_loss = 0.99524076, grad/param norm = 1.7436e-01, time/batch = 0.7148s	
5658/22950 (epoch 12.327), train_loss = 1.03378856, grad/param norm = 1.7468e-01, time/batch = 0.6876s	
5659/22950 (epoch 12.329), train_loss = 1.16139129, grad/param norm = 1.8727e-01, time/batch = 0.6776s	
5660/22950 (epoch 12.331), train_loss = 1.09189796, grad/param norm = 1.9230e-01, time/batch = 0.6800s	
5661/22950 (epoch 12.333), train_loss = 1.21362884, grad/param norm = 1.8963e-01, time/batch = 0.6800s	
5662/22950 (epoch 12.336), train_loss = 1.21976395, grad/param norm = 2.0074e-01, time/batch = 0.6848s	
5663/22950 (epoch 12.338), train_loss = 1.17495960, grad/param norm = 1.8442e-01, time/batch = 0.6814s	
5664/22950 (epoch 12.340), train_loss = 1.23658550, grad/param norm = 2.0423e-01, time/batch = 0.6818s	
5665/22950 (epoch 12.342), train_loss = 1.33225175, grad/param norm = 1.9989e-01, time/batch = 0.6745s	
5666/22950 (epoch 12.344), train_loss = 1.24359939, grad/param norm = 1.9668e-01, time/batch = 0.6736s	
5667/22950 (epoch 12.346), train_loss = 1.42787420, grad/param norm = 2.2563e-01, time/batch = 0.6748s	
5668/22950 (epoch 12.349), train_loss = 1.25731114, grad/param norm = 2.0471e-01, time/batch = 0.6787s	
5669/22950 (epoch 12.351), train_loss = 1.28848019, grad/param norm = 1.9860e-01, time/batch = 0.6820s	
5670/22950 (epoch 12.353), train_loss = 1.35728124, grad/param norm = 2.2263e-01, time/batch = 0.6792s	
5671/22950 (epoch 12.355), train_loss = 1.37155032, grad/param norm = 2.0982e-01, time/batch = 0.6760s	
5672/22950 (epoch 12.357), train_loss = 1.26522033, grad/param norm = 2.0326e-01, time/batch = 0.6763s	
5673/22950 (epoch 12.359), train_loss = 1.30251914, grad/param norm = 2.1987e-01, time/batch = 0.6717s	
5674/22950 (epoch 12.362), train_loss = 1.23494020, grad/param norm = 1.8575e-01, time/batch = 0.6713s	
5675/22950 (epoch 12.364), train_loss = 1.24831108, grad/param norm = 1.9295e-01, time/batch = 0.6779s	
5676/22950 (epoch 12.366), train_loss = 1.10231136, grad/param norm = 1.8228e-01, time/batch = 0.6764s	
5677/22950 (epoch 12.368), train_loss = 1.27542913, grad/param norm = 2.1095e-01, time/batch = 0.6770s	
5678/22950 (epoch 12.370), train_loss = 1.22888457, grad/param norm = 1.9323e-01, time/batch = 0.6839s	
5679/22950 (epoch 12.373), train_loss = 1.10626501, grad/param norm = 1.8694e-01, time/batch = 0.6793s	
5680/22950 (epoch 12.375), train_loss = 1.37358493, grad/param norm = 2.1443e-01, time/batch = 0.6771s	
5681/22950 (epoch 12.377), train_loss = 1.19039652, grad/param norm = 2.0035e-01, time/batch = 0.6727s	
5682/22950 (epoch 12.379), train_loss = 1.32469896, grad/param norm = 2.1664e-01, time/batch = 0.6732s	
5683/22950 (epoch 12.381), train_loss = 1.07016820, grad/param norm = 1.7765e-01, time/batch = 0.6740s	
5684/22950 (epoch 12.383), train_loss = 1.29461406, grad/param norm = 2.0531e-01, time/batch = 0.6831s	
5685/22950 (epoch 12.386), train_loss = 1.21255372, grad/param norm = 2.0636e-01, time/batch = 0.6791s	
5686/22950 (epoch 12.388), train_loss = 1.26835475, grad/param norm = 2.1089e-01, time/batch = 0.6794s	
5687/22950 (epoch 12.390), train_loss = 1.15338419, grad/param norm = 1.9072e-01, time/batch = 0.6818s	
5688/22950 (epoch 12.392), train_loss = 1.13446333, grad/param norm = 1.8585e-01, time/batch = 0.7094s	
5689/22950 (epoch 12.394), train_loss = 1.17052943, grad/param norm = 1.7135e-01, time/batch = 0.6872s	
5690/22950 (epoch 12.397), train_loss = 1.36434040, grad/param norm = 2.1388e-01, time/batch = 0.6817s	
5691/22950 (epoch 12.399), train_loss = 1.35756751, grad/param norm = 2.0646e-01, time/batch = 0.6765s	
5692/22950 (epoch 12.401), train_loss = 1.53171492, grad/param norm = 2.1315e-01, time/batch = 0.6800s	
5693/22950 (epoch 12.403), train_loss = 1.20807890, grad/param norm = 1.9222e-01, time/batch = 0.6787s	
5694/22950 (epoch 12.405), train_loss = 1.35507752, grad/param norm = 2.1526e-01, time/batch = 0.6734s	
5695/22950 (epoch 12.407), train_loss = 1.42800725, grad/param norm = 2.1381e-01, time/batch = 0.6746s	
5696/22950 (epoch 12.410), train_loss = 1.14446200, grad/param norm = 1.8450e-01, time/batch = 0.6732s	
5697/22950 (epoch 12.412), train_loss = 1.28535507, grad/param norm = 2.1770e-01, time/batch = 0.6751s	
5698/22950 (epoch 12.414), train_loss = 1.35677669, grad/param norm = 2.1763e-01, time/batch = 0.6735s	
5699/22950 (epoch 12.416), train_loss = 1.31929887, grad/param norm = 2.2402e-01, time/batch = 0.6707s	
5700/22950 (epoch 12.418), train_loss = 1.30534179, grad/param norm = 2.0954e-01, time/batch = 0.6697s	
5701/22950 (epoch 12.420), train_loss = 1.33096411, grad/param norm = 2.1170e-01, time/batch = 0.6725s	
5702/22950 (epoch 12.423), train_loss = 1.16088883, grad/param norm = 1.7261e-01, time/batch = 0.6704s	
5703/22950 (epoch 12.425), train_loss = 1.26188747, grad/param norm = 1.9533e-01, time/batch = 0.6691s	
5704/22950 (epoch 12.427), train_loss = 1.22548944, grad/param norm = 1.9769e-01, time/batch = 0.6741s	
5705/22950 (epoch 12.429), train_loss = 1.23877222, grad/param norm = 2.0276e-01, time/batch = 0.6755s	
5706/22950 (epoch 12.431), train_loss = 1.30503208, grad/param norm = 2.0103e-01, time/batch = 0.6750s	
5707/22950 (epoch 12.434), train_loss = 1.25213238, grad/param norm = 1.9717e-01, time/batch = 0.6734s	
5708/22950 (epoch 12.436), train_loss = 1.47487955, grad/param norm = 2.1197e-01, time/batch = 0.6727s	
5709/22950 (epoch 12.438), train_loss = 1.26506813, grad/param norm = 2.0278e-01, time/batch = 0.6696s	
5710/22950 (epoch 12.440), train_loss = 1.34868547, grad/param norm = 2.0823e-01, time/batch = 0.6760s	
5711/22950 (epoch 12.442), train_loss = 1.42827999, grad/param norm = 2.0531e-01, time/batch = 0.6759s	
5712/22950 (epoch 12.444), train_loss = 1.35202244, grad/param norm = 1.9693e-01, time/batch = 0.6739s	
5713/22950 (epoch 12.447), train_loss = 1.47922909, grad/param norm = 2.1882e-01, time/batch = 0.6746s	
5714/22950 (epoch 12.449), train_loss = 1.13328406, grad/param norm = 1.6978e-01, time/batch = 0.6759s	
5715/22950 (epoch 12.451), train_loss = 1.29307069, grad/param norm = 1.8937e-01, time/batch = 0.6796s	
5716/22950 (epoch 12.453), train_loss = 1.30396002, grad/param norm = 1.8777e-01, time/batch = 0.6768s	
5717/22950 (epoch 12.455), train_loss = 1.15130873, grad/param norm = 1.8255e-01, time/batch = 0.6752s	
5718/22950 (epoch 12.458), train_loss = 1.40118089, grad/param norm = 1.9573e-01, time/batch = 0.6770s	
5719/22950 (epoch 12.460), train_loss = 1.27893155, grad/param norm = 1.9866e-01, time/batch = 0.6745s	
5720/22950 (epoch 12.462), train_loss = 1.25713496, grad/param norm = 1.8249e-01, time/batch = 0.6735s	
5721/22950 (epoch 12.464), train_loss = 1.21798696, grad/param norm = 1.8861e-01, time/batch = 0.6770s	
5722/22950 (epoch 12.466), train_loss = 1.29918366, grad/param norm = 2.0412e-01, time/batch = 0.6712s	
5723/22950 (epoch 12.468), train_loss = 1.38584407, grad/param norm = 1.9891e-01, time/batch = 0.6735s	
5724/22950 (epoch 12.471), train_loss = 1.29035608, grad/param norm = 1.9147e-01, time/batch = 0.6901s	
5725/22950 (epoch 12.473), train_loss = 1.34504709, grad/param norm = 2.0987e-01, time/batch = 0.7082s	
5726/22950 (epoch 12.475), train_loss = 1.51367719, grad/param norm = 2.1892e-01, time/batch = 0.7061s	
5727/22950 (epoch 12.477), train_loss = 1.25516927, grad/param norm = 1.9904e-01, time/batch = 0.6996s	
5728/22950 (epoch 12.479), train_loss = 1.19680404, grad/param norm = 1.9650e-01, time/batch = 0.6913s	
5729/22950 (epoch 12.481), train_loss = 1.42430264, grad/param norm = 2.1580e-01, time/batch = 0.7108s	
5730/22950 (epoch 12.484), train_loss = 1.32171493, grad/param norm = 1.9982e-01, time/batch = 0.6834s	
5731/22950 (epoch 12.486), train_loss = 1.12639402, grad/param norm = 1.8208e-01, time/batch = 0.6789s	
5732/22950 (epoch 12.488), train_loss = 1.25786598, grad/param norm = 2.0979e-01, time/batch = 0.6772s	
5733/22950 (epoch 12.490), train_loss = 1.09608873, grad/param norm = 2.0005e-01, time/batch = 0.6948s	
5734/22950 (epoch 12.492), train_loss = 1.24916335, grad/param norm = 1.9338e-01, time/batch = 0.7016s	
5735/22950 (epoch 12.495), train_loss = 1.23878285, grad/param norm = 1.8860e-01, time/batch = 0.7232s	
5736/22950 (epoch 12.497), train_loss = 1.34827160, grad/param norm = 1.9867e-01, time/batch = 0.7194s	
5737/22950 (epoch 12.499), train_loss = 1.38116045, grad/param norm = 2.0669e-01, time/batch = 0.7086s	
5738/22950 (epoch 12.501), train_loss = 1.32739458, grad/param norm = 1.9511e-01, time/batch = 0.7070s	
5739/22950 (epoch 12.503), train_loss = 1.37161628, grad/param norm = 2.0564e-01, time/batch = 0.6931s	
5740/22950 (epoch 12.505), train_loss = 1.13575682, grad/param norm = 1.7276e-01, time/batch = 0.6903s	
5741/22950 (epoch 12.508), train_loss = 1.32776112, grad/param norm = 1.9412e-01, time/batch = 0.6890s	
5742/22950 (epoch 12.510), train_loss = 1.27608056, grad/param norm = 1.9103e-01, time/batch = 0.6879s	
5743/22950 (epoch 12.512), train_loss = 1.16791575, grad/param norm = 1.7192e-01, time/batch = 0.6865s	
5744/22950 (epoch 12.514), train_loss = 1.13968153, grad/param norm = 1.7286e-01, time/batch = 0.6869s	
5745/22950 (epoch 12.516), train_loss = 1.24579646, grad/param norm = 2.0995e-01, time/batch = 0.6867s	
5746/22950 (epoch 12.519), train_loss = 1.22281250, grad/param norm = 1.8232e-01, time/batch = 0.6864s	
5747/22950 (epoch 12.521), train_loss = 1.26264636, grad/param norm = 1.7963e-01, time/batch = 0.6885s	
5748/22950 (epoch 12.523), train_loss = 1.02447591, grad/param norm = 1.7613e-01, time/batch = 0.6921s	
5749/22950 (epoch 12.525), train_loss = 1.15346766, grad/param norm = 1.9051e-01, time/batch = 0.7106s	
5750/22950 (epoch 12.527), train_loss = 1.08552314, grad/param norm = 1.9529e-01, time/batch = 0.6933s	
5751/22950 (epoch 12.529), train_loss = 1.30819828, grad/param norm = 2.0375e-01, time/batch = 0.6899s	
5752/22950 (epoch 12.532), train_loss = 1.19109396, grad/param norm = 1.8295e-01, time/batch = 0.6859s	
5753/22950 (epoch 12.534), train_loss = 1.35147692, grad/param norm = 2.1232e-01, time/batch = 0.6892s	
5754/22950 (epoch 12.536), train_loss = 1.32979476, grad/param norm = 2.1831e-01, time/batch = 0.6863s	
5755/22950 (epoch 12.538), train_loss = 1.22240169, grad/param norm = 2.1024e-01, time/batch = 0.6876s	
5756/22950 (epoch 12.540), train_loss = 1.27868868, grad/param norm = 1.8263e-01, time/batch = 0.6903s	
5757/22950 (epoch 12.542), train_loss = 1.44336569, grad/param norm = 2.1470e-01, time/batch = 0.6920s	
5758/22950 (epoch 12.545), train_loss = 1.24121744, grad/param norm = 2.0713e-01, time/batch = 0.6889s	
5759/22950 (epoch 12.547), train_loss = 1.24104175, grad/param norm = 1.9146e-01, time/batch = 0.7245s	
5760/22950 (epoch 12.549), train_loss = 1.23874675, grad/param norm = 1.9246e-01, time/batch = 0.7029s	
5761/22950 (epoch 12.551), train_loss = 1.26394577, grad/param norm = 1.9640e-01, time/batch = 0.6898s	
5762/22950 (epoch 12.553), train_loss = 1.22953024, grad/param norm = 2.1658e-01, time/batch = 0.6886s	
5763/22950 (epoch 12.556), train_loss = 1.32171309, grad/param norm = 1.8111e-01, time/batch = 0.6889s	
5764/22950 (epoch 12.558), train_loss = 1.17425491, grad/param norm = 1.9579e-01, time/batch = 0.6902s	
5765/22950 (epoch 12.560), train_loss = 1.29790266, grad/param norm = 1.9753e-01, time/batch = 0.6880s	
5766/22950 (epoch 12.562), train_loss = 1.14418628, grad/param norm = 1.8090e-01, time/batch = 0.6913s	
5767/22950 (epoch 12.564), train_loss = 1.44300817, grad/param norm = 2.4150e-01, time/batch = 0.6888s	
5768/22950 (epoch 12.566), train_loss = 1.27291316, grad/param norm = 1.9249e-01, time/batch = 0.6901s	
5769/22950 (epoch 12.569), train_loss = 1.38636166, grad/param norm = 1.9455e-01, time/batch = 0.6876s	
5770/22950 (epoch 12.571), train_loss = 1.14840570, grad/param norm = 2.0390e-01, time/batch = 0.6874s	
5771/22950 (epoch 12.573), train_loss = 1.27242131, grad/param norm = 2.0304e-01, time/batch = 0.6910s	
5772/22950 (epoch 12.575), train_loss = 1.46376524, grad/param norm = 2.1872e-01, time/batch = 0.6905s	
5773/22950 (epoch 12.577), train_loss = 1.26244296, grad/param norm = 2.2090e-01, time/batch = 0.6870s	
5774/22950 (epoch 12.580), train_loss = 1.31471899, grad/param norm = 2.0968e-01, time/batch = 0.6843s	
5775/22950 (epoch 12.582), train_loss = 1.47828355, grad/param norm = 2.0578e-01, time/batch = 0.6838s	
5776/22950 (epoch 12.584), train_loss = 1.13080972, grad/param norm = 1.8318e-01, time/batch = 0.6871s	
5777/22950 (epoch 12.586), train_loss = 1.23119082, grad/param norm = 2.0437e-01, time/batch = 0.6875s	
5778/22950 (epoch 12.588), train_loss = 1.38733463, grad/param norm = 1.9369e-01, time/batch = 0.6907s	
5779/22950 (epoch 12.590), train_loss = 1.24204669, grad/param norm = 1.9371e-01, time/batch = 0.6878s	
5780/22950 (epoch 12.593), train_loss = 1.14162819, grad/param norm = 1.9117e-01, time/batch = 0.6855s	
5781/22950 (epoch 12.595), train_loss = 1.14475758, grad/param norm = 1.9835e-01, time/batch = 0.6868s	
5782/22950 (epoch 12.597), train_loss = 1.33245091, grad/param norm = 2.0380e-01, time/batch = 0.6995s	
5783/22950 (epoch 12.599), train_loss = 1.28983505, grad/param norm = 2.1815e-01, time/batch = 0.6869s	
5784/22950 (epoch 12.601), train_loss = 1.26350361, grad/param norm = 1.9862e-01, time/batch = 0.6870s	
5785/22950 (epoch 12.603), train_loss = 1.40479575, grad/param norm = 1.9160e-01, time/batch = 0.6934s	
5786/22950 (epoch 12.606), train_loss = 1.22726785, grad/param norm = 1.9765e-01, time/batch = 0.6879s	
5787/22950 (epoch 12.608), train_loss = 1.27756226, grad/param norm = 1.8905e-01, time/batch = 0.6859s	
5788/22950 (epoch 12.610), train_loss = 1.23170429, grad/param norm = 1.8769e-01, time/batch = 0.6873s	
5789/22950 (epoch 12.612), train_loss = 1.26013477, grad/param norm = 1.9896e-01, time/batch = 0.6869s	
5790/22950 (epoch 12.614), train_loss = 1.39350244, grad/param norm = 2.2019e-01, time/batch = 0.6880s	
5791/22950 (epoch 12.617), train_loss = 1.23493393, grad/param norm = 1.8973e-01, time/batch = 0.6936s	
5792/22950 (epoch 12.619), train_loss = 1.16041484, grad/param norm = 1.6588e-01, time/batch = 0.6958s	
5793/22950 (epoch 12.621), train_loss = 1.34895441, grad/param norm = 1.8366e-01, time/batch = 0.7126s	
5794/22950 (epoch 12.623), train_loss = 1.31345152, grad/param norm = 1.7730e-01, time/batch = 0.7252s	
5795/22950 (epoch 12.625), train_loss = 1.25185271, grad/param norm = 1.9042e-01, time/batch = 0.7181s	
5796/22950 (epoch 12.627), train_loss = 1.26355424, grad/param norm = 1.9645e-01, time/batch = 0.7210s	
5797/22950 (epoch 12.630), train_loss = 1.11783463, grad/param norm = 1.8865e-01, time/batch = 0.7188s	
5798/22950 (epoch 12.632), train_loss = 1.28032447, grad/param norm = 2.0109e-01, time/batch = 0.7162s	
5799/22950 (epoch 12.634), train_loss = 1.24201124, grad/param norm = 1.9213e-01, time/batch = 0.7250s	
5800/22950 (epoch 12.636), train_loss = 1.28949291, grad/param norm = 2.1530e-01, time/batch = 0.7331s	
5801/22950 (epoch 12.638), train_loss = 1.15865301, grad/param norm = 1.9739e-01, time/batch = 0.7273s	
5802/22950 (epoch 12.641), train_loss = 1.20058250, grad/param norm = 1.8643e-01, time/batch = 0.7240s	
5803/22950 (epoch 12.643), train_loss = 1.29094318, grad/param norm = 2.1842e-01, time/batch = 0.7264s	
5804/22950 (epoch 12.645), train_loss = 1.17854615, grad/param norm = 1.9061e-01, time/batch = 0.7257s	
5805/22950 (epoch 12.647), train_loss = 1.25373858, grad/param norm = 2.0512e-01, time/batch = 0.7044s	
5806/22950 (epoch 12.649), train_loss = 1.27255307, grad/param norm = 1.9882e-01, time/batch = 0.7027s	
5807/22950 (epoch 12.651), train_loss = 1.35214284, grad/param norm = 2.1102e-01, time/batch = 0.7058s	
5808/22950 (epoch 12.654), train_loss = 1.05535065, grad/param norm = 1.7662e-01, time/batch = 0.6979s	
5809/22950 (epoch 12.656), train_loss = 1.40536529, grad/param norm = 2.3102e-01, time/batch = 0.6916s	
5810/22950 (epoch 12.658), train_loss = 1.15169111, grad/param norm = 1.8567e-01, time/batch = 0.7099s	
5811/22950 (epoch 12.660), train_loss = 1.08184248, grad/param norm = 1.9359e-01, time/batch = 0.6981s	
5812/22950 (epoch 12.662), train_loss = 1.08247378, grad/param norm = 1.7410e-01, time/batch = 0.6879s	
5813/22950 (epoch 12.664), train_loss = 1.25491315, grad/param norm = 1.8800e-01, time/batch = 0.6933s	
5814/22950 (epoch 12.667), train_loss = 1.28574492, grad/param norm = 1.9127e-01, time/batch = 0.6850s	
5815/22950 (epoch 12.669), train_loss = 1.21206189, grad/param norm = 1.9754e-01, time/batch = 0.6877s	
5816/22950 (epoch 12.671), train_loss = 1.28539232, grad/param norm = 1.9995e-01, time/batch = 0.6983s	
5817/22950 (epoch 12.673), train_loss = 1.20338356, grad/param norm = 1.8501e-01, time/batch = 0.6886s	
5818/22950 (epoch 12.675), train_loss = 1.24849253, grad/param norm = 1.9633e-01, time/batch = 0.6966s	
5819/22950 (epoch 12.678), train_loss = 1.24768785, grad/param norm = 2.0223e-01, time/batch = 0.7151s	
5820/22950 (epoch 12.680), train_loss = 1.26271933, grad/param norm = 1.9110e-01, time/batch = 0.7232s	
5821/22950 (epoch 12.682), train_loss = 1.33430189, grad/param norm = 2.0670e-01, time/batch = 0.7129s	
5822/22950 (epoch 12.684), train_loss = 1.36873341, grad/param norm = 1.9245e-01, time/batch = 0.7018s	
5823/22950 (epoch 12.686), train_loss = 1.35038227, grad/param norm = 2.0997e-01, time/batch = 0.7021s	
5824/22950 (epoch 12.688), train_loss = 1.25335379, grad/param norm = 2.0666e-01, time/batch = 0.6938s	
5825/22950 (epoch 12.691), train_loss = 1.24620948, grad/param norm = 1.8786e-01, time/batch = 0.6917s	
5826/22950 (epoch 12.693), train_loss = 1.16850933, grad/param norm = 1.9676e-01, time/batch = 0.6928s	
5827/22950 (epoch 12.695), train_loss = 1.40055768, grad/param norm = 1.9794e-01, time/batch = 0.7037s	
5828/22950 (epoch 12.697), train_loss = 1.36864742, grad/param norm = 1.9984e-01, time/batch = 0.7160s	
5829/22950 (epoch 12.699), train_loss = 1.34255372, grad/param norm = 1.9780e-01, time/batch = 0.6964s	
5830/22950 (epoch 12.702), train_loss = 1.33677058, grad/param norm = 1.9864e-01, time/batch = 0.6950s	
5831/22950 (epoch 12.704), train_loss = 1.33692190, grad/param norm = 2.1229e-01, time/batch = 0.6882s	
5832/22950 (epoch 12.706), train_loss = 1.34881405, grad/param norm = 2.0393e-01, time/batch = 0.6894s	
5833/22950 (epoch 12.708), train_loss = 1.18013086, grad/param norm = 1.8500e-01, time/batch = 0.7219s	
5834/22950 (epoch 12.710), train_loss = 1.32174899, grad/param norm = 1.8377e-01, time/batch = 0.7062s	
5835/22950 (epoch 12.712), train_loss = 1.40300739, grad/param norm = 2.0496e-01, time/batch = 0.6926s	
5836/22950 (epoch 12.715), train_loss = 1.34559483, grad/param norm = 2.0483e-01, time/batch = 0.6880s	
5837/22950 (epoch 12.717), train_loss = 1.19738165, grad/param norm = 1.8747e-01, time/batch = 0.6878s	
5838/22950 (epoch 12.719), train_loss = 1.22251628, grad/param norm = 2.0796e-01, time/batch = 0.6885s	
5839/22950 (epoch 12.721), train_loss = 1.30139570, grad/param norm = 1.8567e-01, time/batch = 0.6948s	
5840/22950 (epoch 12.723), train_loss = 1.17745900, grad/param norm = 1.8102e-01, time/batch = 0.6897s	
5841/22950 (epoch 12.725), train_loss = 1.34258140, grad/param norm = 2.0256e-01, time/batch = 0.6918s	
5842/22950 (epoch 12.728), train_loss = 1.26239567, grad/param norm = 2.1619e-01, time/batch = 0.6924s	
5843/22950 (epoch 12.730), train_loss = 1.26073960, grad/param norm = 2.0102e-01, time/batch = 0.7208s	
5844/22950 (epoch 12.732), train_loss = 1.30114434, grad/param norm = 1.8154e-01, time/batch = 0.7054s	
5845/22950 (epoch 12.734), train_loss = 1.28916259, grad/param norm = 2.1330e-01, time/batch = 0.6899s	
5846/22950 (epoch 12.736), train_loss = 1.21312722, grad/param norm = 1.8716e-01, time/batch = 0.6906s	
5847/22950 (epoch 12.739), train_loss = 1.32891798, grad/param norm = 2.0819e-01, time/batch = 0.6889s	
5848/22950 (epoch 12.741), train_loss = 1.31346250, grad/param norm = 2.0507e-01, time/batch = 0.6888s	
5849/22950 (epoch 12.743), train_loss = 1.44383102, grad/param norm = 2.0380e-01, time/batch = 0.6892s	
5850/22950 (epoch 12.745), train_loss = 1.50938922, grad/param norm = 2.0235e-01, time/batch = 0.6848s	
5851/22950 (epoch 12.747), train_loss = 1.30805850, grad/param norm = 1.9800e-01, time/batch = 0.6919s	
5852/22950 (epoch 12.749), train_loss = 1.15725348, grad/param norm = 1.8875e-01, time/batch = 0.6909s	
5853/22950 (epoch 12.752), train_loss = 1.46839181, grad/param norm = 2.1288e-01, time/batch = 0.6915s	
5854/22950 (epoch 12.754), train_loss = 1.36625509, grad/param norm = 1.9980e-01, time/batch = 0.6862s	
5855/22950 (epoch 12.756), train_loss = 1.18382938, grad/param norm = 2.0302e-01, time/batch = 0.6871s	
5856/22950 (epoch 12.758), train_loss = 1.20367306, grad/param norm = 1.8607e-01, time/batch = 0.6865s	
5857/22950 (epoch 12.760), train_loss = 1.30098603, grad/param norm = 1.9345e-01, time/batch = 0.6856s	
5858/22950 (epoch 12.763), train_loss = 1.32435200, grad/param norm = 2.0894e-01, time/batch = 0.6890s	
5859/22950 (epoch 12.765), train_loss = 1.32320015, grad/param norm = 2.0875e-01, time/batch = 0.6888s	
5860/22950 (epoch 12.767), train_loss = 1.47733129, grad/param norm = 2.0780e-01, time/batch = 0.6870s	
5861/22950 (epoch 12.769), train_loss = 1.30012999, grad/param norm = 2.0368e-01, time/batch = 0.6879s	
5862/22950 (epoch 12.771), train_loss = 1.17052581, grad/param norm = 2.1415e-01, time/batch = 0.6949s	
5863/22950 (epoch 12.773), train_loss = 0.96829257, grad/param norm = 1.6843e-01, time/batch = 0.6901s	
5864/22950 (epoch 12.776), train_loss = 1.19238905, grad/param norm = 1.8790e-01, time/batch = 0.7033s	
5865/22950 (epoch 12.778), train_loss = 1.10800515, grad/param norm = 1.7710e-01, time/batch = 0.6959s	
5866/22950 (epoch 12.780), train_loss = 1.20398024, grad/param norm = 1.7225e-01, time/batch = 0.6920s	
5867/22950 (epoch 12.782), train_loss = 1.21278704, grad/param norm = 1.8333e-01, time/batch = 0.6897s	
5868/22950 (epoch 12.784), train_loss = 1.27871349, grad/param norm = 2.0118e-01, time/batch = 0.6919s	
5869/22950 (epoch 12.786), train_loss = 1.32732301, grad/param norm = 1.8496e-01, time/batch = 0.6932s	
5870/22950 (epoch 12.789), train_loss = 1.09304233, grad/param norm = 1.7951e-01, time/batch = 0.6893s	
5871/22950 (epoch 12.791), train_loss = 1.14248791, grad/param norm = 1.9858e-01, time/batch = 0.6880s	
5872/22950 (epoch 12.793), train_loss = 1.49926433, grad/param norm = 2.1925e-01, time/batch = 0.6859s	
5873/22950 (epoch 12.795), train_loss = 1.19317625, grad/param norm = 1.8108e-01, time/batch = 0.6855s	
5874/22950 (epoch 12.797), train_loss = 1.43974883, grad/param norm = 2.1513e-01, time/batch = 0.6855s	
5875/22950 (epoch 12.800), train_loss = 1.16881623, grad/param norm = 1.9364e-01, time/batch = 0.6857s	
5876/22950 (epoch 12.802), train_loss = 1.18266390, grad/param norm = 1.9535e-01, time/batch = 0.7052s	
5877/22950 (epoch 12.804), train_loss = 1.22088012, grad/param norm = 1.8958e-01, time/batch = 0.7088s	
5878/22950 (epoch 12.806), train_loss = 1.12100838, grad/param norm = 1.8883e-01, time/batch = 0.6932s	
5879/22950 (epoch 12.808), train_loss = 1.22446554, grad/param norm = 1.8872e-01, time/batch = 0.6817s	
5880/22950 (epoch 12.810), train_loss = 1.20959530, grad/param norm = 1.9777e-01, time/batch = 0.6865s	
5881/22950 (epoch 12.813), train_loss = 1.02367507, grad/param norm = 1.7897e-01, time/batch = 0.6874s	
5882/22950 (epoch 12.815), train_loss = 1.12758863, grad/param norm = 1.8297e-01, time/batch = 0.6880s	
5883/22950 (epoch 12.817), train_loss = 1.10598515, grad/param norm = 1.7302e-01, time/batch = 0.6890s	
5884/22950 (epoch 12.819), train_loss = 1.23092425, grad/param norm = 2.0500e-01, time/batch = 0.6885s	
5885/22950 (epoch 12.821), train_loss = 1.25629923, grad/param norm = 2.1283e-01, time/batch = 0.6877s	
5886/22950 (epoch 12.824), train_loss = 1.22822647, grad/param norm = 2.0124e-01, time/batch = 0.6890s	
5887/22950 (epoch 12.826), train_loss = 1.36728308, grad/param norm = 2.2459e-01, time/batch = 0.6915s	
5888/22950 (epoch 12.828), train_loss = 1.22819274, grad/param norm = 2.0315e-01, time/batch = 0.6893s	
5889/22950 (epoch 12.830), train_loss = 1.25195396, grad/param norm = 1.9155e-01, time/batch = 0.6863s	
5890/22950 (epoch 12.832), train_loss = 1.26589147, grad/param norm = 2.0211e-01, time/batch = 0.6894s	
5891/22950 (epoch 12.834), train_loss = 1.10463539, grad/param norm = 1.8506e-01, time/batch = 0.6900s	
5892/22950 (epoch 12.837), train_loss = 1.26840059, grad/param norm = 1.9918e-01, time/batch = 0.6913s	
5893/22950 (epoch 12.839), train_loss = 1.11846635, grad/param norm = 1.8136e-01, time/batch = 0.6901s	
5894/22950 (epoch 12.841), train_loss = 1.15014997, grad/param norm = 1.7737e-01, time/batch = 0.6896s	
5895/22950 (epoch 12.843), train_loss = 1.20358938, grad/param norm = 2.0153e-01, time/batch = 0.6849s	
5896/22950 (epoch 12.845), train_loss = 1.24787145, grad/param norm = 2.0371e-01, time/batch = 0.6887s	
5897/22950 (epoch 12.847), train_loss = 1.33989576, grad/param norm = 2.0115e-01, time/batch = 0.6879s	
5898/22950 (epoch 12.850), train_loss = 1.27997354, grad/param norm = 2.1795e-01, time/batch = 0.6849s	
5899/22950 (epoch 12.852), train_loss = 1.30005605, grad/param norm = 1.9265e-01, time/batch = 0.6858s	
5900/22950 (epoch 12.854), train_loss = 1.24759530, grad/param norm = 2.0913e-01, time/batch = 0.6862s	
5901/22950 (epoch 12.856), train_loss = 1.45172411, grad/param norm = 2.1362e-01, time/batch = 0.6890s	
5902/22950 (epoch 12.858), train_loss = 1.32006120, grad/param norm = 1.9316e-01, time/batch = 0.6906s	
5903/22950 (epoch 12.861), train_loss = 1.36215518, grad/param norm = 2.0496e-01, time/batch = 0.6896s	
5904/22950 (epoch 12.863), train_loss = 1.39932935, grad/param norm = 2.1658e-01, time/batch = 0.6838s	
5905/22950 (epoch 12.865), train_loss = 1.44046884, grad/param norm = 2.0869e-01, time/batch = 0.7090s	
5906/22950 (epoch 12.867), train_loss = 1.30323685, grad/param norm = 2.0077e-01, time/batch = 0.7216s	
5907/22950 (epoch 12.869), train_loss = 1.47827976, grad/param norm = 2.1982e-01, time/batch = 0.7279s	
5908/22950 (epoch 12.871), train_loss = 1.28484452, grad/param norm = 2.1062e-01, time/batch = 0.7107s	
5909/22950 (epoch 12.874), train_loss = 1.25222256, grad/param norm = 1.9551e-01, time/batch = 0.7137s	
5910/22950 (epoch 12.876), train_loss = 1.30490104, grad/param norm = 1.8978e-01, time/batch = 0.7171s	
5911/22950 (epoch 12.878), train_loss = 1.21420798, grad/param norm = 2.2321e-01, time/batch = 0.7324s	
5912/22950 (epoch 12.880), train_loss = 1.43634868, grad/param norm = 2.0573e-01, time/batch = 0.7259s	
5913/22950 (epoch 12.882), train_loss = 1.13785552, grad/param norm = 1.8369e-01, time/batch = 0.7269s	
5914/22950 (epoch 12.885), train_loss = 1.29843150, grad/param norm = 2.0636e-01, time/batch = 0.7208s	
5915/22950 (epoch 12.887), train_loss = 1.29312151, grad/param norm = 2.0670e-01, time/batch = 0.6931s	
5916/22950 (epoch 12.889), train_loss = 1.35487112, grad/param norm = 2.2079e-01, time/batch = 0.6966s	
5917/22950 (epoch 12.891), train_loss = 1.24301020, grad/param norm = 2.0705e-01, time/batch = 0.7004s	
5918/22950 (epoch 12.893), train_loss = 1.29546233, grad/param norm = 2.0891e-01, time/batch = 0.7262s	
5919/22950 (epoch 12.895), train_loss = 1.45348090, grad/param norm = 2.0694e-01, time/batch = 0.6870s	
5920/22950 (epoch 12.898), train_loss = 1.27316809, grad/param norm = 2.0219e-01, time/batch = 0.6935s	
5921/22950 (epoch 12.900), train_loss = 1.16506708, grad/param norm = 1.7383e-01, time/batch = 0.6938s	
5922/22950 (epoch 12.902), train_loss = 1.33649665, grad/param norm = 1.9506e-01, time/batch = 0.6882s	
5923/22950 (epoch 12.904), train_loss = 1.30039835, grad/param norm = 1.8865e-01, time/batch = 0.6912s	
5924/22950 (epoch 12.906), train_loss = 1.27128483, grad/param norm = 1.8451e-01, time/batch = 0.6897s	
5925/22950 (epoch 12.908), train_loss = 1.17135429, grad/param norm = 2.0225e-01, time/batch = 0.6954s	
5926/22950 (epoch 12.911), train_loss = 1.10946375, grad/param norm = 1.7340e-01, time/batch = 0.6928s	
5927/22950 (epoch 12.913), train_loss = 1.21295642, grad/param norm = 1.9558e-01, time/batch = 0.6888s	
5928/22950 (epoch 12.915), train_loss = 1.37187169, grad/param norm = 2.1900e-01, time/batch = 0.6910s	
5929/22950 (epoch 12.917), train_loss = 1.12090120, grad/param norm = 1.8664e-01, time/batch = 0.6918s	
5930/22950 (epoch 12.919), train_loss = 1.20788432, grad/param norm = 1.9371e-01, time/batch = 0.6906s	
5931/22950 (epoch 12.922), train_loss = 1.24882439, grad/param norm = 2.0135e-01, time/batch = 0.6985s	
5932/22950 (epoch 12.924), train_loss = 1.32967398, grad/param norm = 1.9254e-01, time/batch = 0.6925s	
5933/22950 (epoch 12.926), train_loss = 1.11623721, grad/param norm = 1.9548e-01, time/batch = 0.6910s	
5934/22950 (epoch 12.928), train_loss = 1.11432282, grad/param norm = 1.9717e-01, time/batch = 0.6916s	
5935/22950 (epoch 12.930), train_loss = 1.10261008, grad/param norm = 2.0222e-01, time/batch = 0.6916s	
5936/22950 (epoch 12.932), train_loss = 1.07252344, grad/param norm = 1.7662e-01, time/batch = 0.6891s	
5937/22950 (epoch 12.935), train_loss = 1.29037571, grad/param norm = 1.9170e-01, time/batch = 0.6879s	
5938/22950 (epoch 12.937), train_loss = 1.28622203, grad/param norm = 2.1174e-01, time/batch = 0.6924s	
5939/22950 (epoch 12.939), train_loss = 1.20629106, grad/param norm = 2.0738e-01, time/batch = 0.6914s	
5940/22950 (epoch 12.941), train_loss = 1.15280195, grad/param norm = 1.9020e-01, time/batch = 0.6936s	
5941/22950 (epoch 12.943), train_loss = 1.25571042, grad/param norm = 2.0325e-01, time/batch = 0.6941s	
5942/22950 (epoch 12.946), train_loss = 1.11691987, grad/param norm = 2.0620e-01, time/batch = 0.6917s	
5943/22950 (epoch 12.948), train_loss = 1.30056117, grad/param norm = 1.8524e-01, time/batch = 0.6879s	
5944/22950 (epoch 12.950), train_loss = 1.28674712, grad/param norm = 2.0277e-01, time/batch = 0.6893s	
5945/22950 (epoch 12.952), train_loss = 1.29334412, grad/param norm = 2.1137e-01, time/batch = 0.6874s	
5946/22950 (epoch 12.954), train_loss = 1.26451358, grad/param norm = 1.8518e-01, time/batch = 0.6859s	
5947/22950 (epoch 12.956), train_loss = 1.17920330, grad/param norm = 1.9223e-01, time/batch = 0.6875s	
5948/22950 (epoch 12.959), train_loss = 1.14289965, grad/param norm = 1.9436e-01, time/batch = 0.6872s	
5949/22950 (epoch 12.961), train_loss = 1.26422358, grad/param norm = 1.9469e-01, time/batch = 0.6894s	
5950/22950 (epoch 12.963), train_loss = 1.29595022, grad/param norm = 2.0217e-01, time/batch = 0.6883s	
5951/22950 (epoch 12.965), train_loss = 1.43773424, grad/param norm = 2.1642e-01, time/batch = 0.6867s	
5952/22950 (epoch 12.967), train_loss = 1.26271345, grad/param norm = 2.2145e-01, time/batch = 0.6855s	
5953/22950 (epoch 12.969), train_loss = 1.17149521, grad/param norm = 1.9554e-01, time/batch = 0.6844s	
5954/22950 (epoch 12.972), train_loss = 1.24211656, grad/param norm = 1.9090e-01, time/batch = 0.6867s	
5955/22950 (epoch 12.974), train_loss = 1.18682524, grad/param norm = 1.9532e-01, time/batch = 0.6962s	
5956/22950 (epoch 12.976), train_loss = 1.10664473, grad/param norm = 1.9119e-01, time/batch = 0.6876s	
5957/22950 (epoch 12.978), train_loss = 1.21640318, grad/param norm = 1.9776e-01, time/batch = 0.6933s	
5958/22950 (epoch 12.980), train_loss = 1.24648168, grad/param norm = 2.0030e-01, time/batch = 0.6874s	
5959/22950 (epoch 12.983), train_loss = 1.18325878, grad/param norm = 1.8297e-01, time/batch = 0.6905s	
5960/22950 (epoch 12.985), train_loss = 1.10048609, grad/param norm = 1.8153e-01, time/batch = 0.6872s	
5961/22950 (epoch 12.987), train_loss = 1.13301005, grad/param norm = 1.8546e-01, time/batch = 0.6901s	
5962/22950 (epoch 12.989), train_loss = 1.26636824, grad/param norm = 1.9246e-01, time/batch = 0.6989s	
5963/22950 (epoch 12.991), train_loss = 1.08323036, grad/param norm = 1.8177e-01, time/batch = 0.6908s	
5964/22950 (epoch 12.993), train_loss = 1.27302138, grad/param norm = 2.1215e-01, time/batch = 0.6931s	
5965/22950 (epoch 12.996), train_loss = 1.33437673, grad/param norm = 2.0780e-01, time/batch = 0.6879s	
5966/22950 (epoch 12.998), train_loss = 1.18638452, grad/param norm = 1.8758e-01, time/batch = 0.6908s	
decayed learning rate by a factor 0.97 to 0.00177058562	
5967/22950 (epoch 13.000), train_loss = 1.08238407, grad/param norm = 1.8328e-01, time/batch = 0.6877s	
5968/22950 (epoch 13.002), train_loss = 1.43070256, grad/param norm = 2.0830e-01, time/batch = 0.7212s	
5969/22950 (epoch 13.004), train_loss = 1.27271878, grad/param norm = 1.9940e-01, time/batch = 0.7088s	
5970/22950 (epoch 13.007), train_loss = 1.25280762, grad/param norm = 2.0993e-01, time/batch = 0.6978s	
5971/22950 (epoch 13.009), train_loss = 1.37759589, grad/param norm = 1.9812e-01, time/batch = 0.6962s	
5972/22950 (epoch 13.011), train_loss = 1.15929454, grad/param norm = 2.0198e-01, time/batch = 0.7026s	
5973/22950 (epoch 13.013), train_loss = 1.32786716, grad/param norm = 2.1063e-01, time/batch = 0.6982s	
5974/22950 (epoch 13.015), train_loss = 1.33639907, grad/param norm = 2.0895e-01, time/batch = 0.6877s	
5975/22950 (epoch 13.017), train_loss = 1.24197161, grad/param norm = 1.8121e-01, time/batch = 0.6937s	
5976/22950 (epoch 13.020), train_loss = 1.22765566, grad/param norm = 1.7377e-01, time/batch = 0.6873s	
5977/22950 (epoch 13.022), train_loss = 1.08068787, grad/param norm = 1.8496e-01, time/batch = 0.6878s	
5978/22950 (epoch 13.024), train_loss = 1.13764275, grad/param norm = 1.8157e-01, time/batch = 0.7216s	
5979/22950 (epoch 13.026), train_loss = 1.26074171, grad/param norm = 1.9579e-01, time/batch = 0.7029s	
5980/22950 (epoch 13.028), train_loss = 1.32350799, grad/param norm = 1.9133e-01, time/batch = 0.6862s	
5981/22950 (epoch 13.031), train_loss = 1.23919994, grad/param norm = 1.8400e-01, time/batch = 0.6889s	
5982/22950 (epoch 13.033), train_loss = 1.39731700, grad/param norm = 2.1006e-01, time/batch = 0.6868s	
5983/22950 (epoch 13.035), train_loss = 1.21113344, grad/param norm = 1.8403e-01, time/batch = 0.6884s	
5984/22950 (epoch 13.037), train_loss = 1.24251476, grad/param norm = 2.6031e-01, time/batch = 0.6841s	
5985/22950 (epoch 13.039), train_loss = 1.20324563, grad/param norm = 1.9680e-01, time/batch = 0.6861s	
5986/22950 (epoch 13.041), train_loss = 1.20788231, grad/param norm = 1.9696e-01, time/batch = 0.6886s	
5987/22950 (epoch 13.044), train_loss = 1.23990892, grad/param norm = 1.8521e-01, time/batch = 0.6902s	
5988/22950 (epoch 13.046), train_loss = 1.25682844, grad/param norm = 1.9275e-01, time/batch = 0.6890s	
5989/22950 (epoch 13.048), train_loss = 1.25869493, grad/param norm = 1.8998e-01, time/batch = 0.6905s	
5990/22950 (epoch 13.050), train_loss = 1.28911447, grad/param norm = 2.1168e-01, time/batch = 0.6893s	
5991/22950 (epoch 13.052), train_loss = 1.27155327, grad/param norm = 1.8768e-01, time/batch = 0.7220s	
5992/22950 (epoch 13.054), train_loss = 1.48895628, grad/param norm = 2.0872e-01, time/batch = 0.7214s	
5993/22950 (epoch 13.057), train_loss = 1.33206097, grad/param norm = 1.9810e-01, time/batch = 0.7312s	
5994/22950 (epoch 13.059), train_loss = 1.30691949, grad/param norm = 1.9811e-01, time/batch = 0.7313s	
5995/22950 (epoch 13.061), train_loss = 1.15241814, grad/param norm = 1.9005e-01, time/batch = 0.7154s	
5996/22950 (epoch 13.063), train_loss = 1.30209093, grad/param norm = 1.8952e-01, time/batch = 0.7228s	
5997/22950 (epoch 13.065), train_loss = 1.01513449, grad/param norm = 1.8754e-01, time/batch = 0.7084s	
5998/22950 (epoch 13.068), train_loss = 1.32671017, grad/param norm = 1.9943e-01, time/batch = 0.7242s	
5999/22950 (epoch 13.070), train_loss = 1.13357585, grad/param norm = 1.9164e-01, time/batch = 0.7050s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch13.07_1.6431.t7	
6000/22950 (epoch 13.072), train_loss = 1.28312842, grad/param norm = 1.8254e-01, time/batch = 0.6915s	
6001/22950 (epoch 13.074), train_loss = 1.49472414, grad/param norm = 2.2585e-01, time/batch = 0.6946s	
6002/22950 (epoch 13.076), train_loss = 1.24913065, grad/param norm = 1.9926e-01, time/batch = 0.6900s	
6003/22950 (epoch 13.078), train_loss = 1.34734464, grad/param norm = 2.0651e-01, time/batch = 0.6864s	
6004/22950 (epoch 13.081), train_loss = 1.32216555, grad/param norm = 1.9395e-01, time/batch = 0.6884s	
6005/22950 (epoch 13.083), train_loss = 1.20178047, grad/param norm = 2.0473e-01, time/batch = 0.6914s	
6006/22950 (epoch 13.085), train_loss = 1.15144905, grad/param norm = 2.0661e-01, time/batch = 0.6882s	
6007/22950 (epoch 13.087), train_loss = 1.15172460, grad/param norm = 1.8708e-01, time/batch = 0.6907s	
6008/22950 (epoch 13.089), train_loss = 1.25829534, grad/param norm = 1.8368e-01, time/batch = 0.6912s	
6009/22950 (epoch 13.092), train_loss = 1.18923506, grad/param norm = 1.9440e-01, time/batch = 0.6982s	
6010/22950 (epoch 13.094), train_loss = 1.18148166, grad/param norm = 1.8921e-01, time/batch = 0.6969s	
6011/22950 (epoch 13.096), train_loss = 1.39447759, grad/param norm = 1.9739e-01, time/batch = 0.6922s	
6012/22950 (epoch 13.098), train_loss = 1.28577843, grad/param norm = 1.9713e-01, time/batch = 0.6900s	
6013/22950 (epoch 13.100), train_loss = 1.18569075, grad/param norm = 1.8989e-01, time/batch = 0.6909s	
6014/22950 (epoch 13.102), train_loss = 1.24596846, grad/param norm = 1.8879e-01, time/batch = 0.6882s	
6015/22950 (epoch 13.105), train_loss = 1.09684554, grad/param norm = 1.6682e-01, time/batch = 0.6870s	
6016/22950 (epoch 13.107), train_loss = 1.19484418, grad/param norm = 1.8911e-01, time/batch = 0.6865s	
6017/22950 (epoch 13.109), train_loss = 1.18644618, grad/param norm = 2.0236e-01, time/batch = 0.6916s	
6018/22950 (epoch 13.111), train_loss = 1.10299137, grad/param norm = 1.9292e-01, time/batch = 0.6898s	
6019/22950 (epoch 13.113), train_loss = 1.25447392, grad/param norm = 1.8860e-01, time/batch = 0.6866s	
6020/22950 (epoch 13.115), train_loss = 1.28269879, grad/param norm = 2.1871e-01, time/batch = 0.6879s	
6021/22950 (epoch 13.118), train_loss = 1.37599549, grad/param norm = 1.9346e-01, time/batch = 0.6890s	
6022/22950 (epoch 13.120), train_loss = 1.15009307, grad/param norm = 1.7815e-01, time/batch = 0.6860s	
6023/22950 (epoch 13.122), train_loss = 1.37960394, grad/param norm = 2.0485e-01, time/batch = 0.6866s	
6024/22950 (epoch 13.124), train_loss = 1.03345749, grad/param norm = 1.5484e-01, time/batch = 0.6865s	
6025/22950 (epoch 13.126), train_loss = 1.19550545, grad/param norm = 1.8899e-01, time/batch = 0.6867s	
6026/22950 (epoch 13.129), train_loss = 1.07084768, grad/param norm = 1.7853e-01, time/batch = 0.6818s	
6027/22950 (epoch 13.131), train_loss = 1.19365856, grad/param norm = 1.9868e-01, time/batch = 0.6876s	
6028/22950 (epoch 13.133), train_loss = 1.29056606, grad/param norm = 2.0120e-01, time/batch = 0.6882s	
6029/22950 (epoch 13.135), train_loss = 1.21059108, grad/param norm = 1.7643e-01, time/batch = 0.6977s	
6030/22950 (epoch 13.137), train_loss = 1.38956606, grad/param norm = 2.0455e-01, time/batch = 0.7111s	
6031/22950 (epoch 13.139), train_loss = 1.15192085, grad/param norm = 2.0234e-01, time/batch = 0.7244s	
6032/22950 (epoch 13.142), train_loss = 1.15259004, grad/param norm = 1.8985e-01, time/batch = 0.7197s	
6033/22950 (epoch 13.144), train_loss = 1.12414796, grad/param norm = 1.7931e-01, time/batch = 0.7057s	
6034/22950 (epoch 13.146), train_loss = 1.22606286, grad/param norm = 2.0944e-01, time/batch = 0.6965s	
6035/22950 (epoch 13.148), train_loss = 1.17634866, grad/param norm = 1.8523e-01, time/batch = 0.7248s	
6036/22950 (epoch 13.150), train_loss = 1.23859082, grad/param norm = 2.0068e-01, time/batch = 0.7201s	
6037/22950 (epoch 13.153), train_loss = 1.18855677, grad/param norm = 1.9601e-01, time/batch = 0.7044s	
6038/22950 (epoch 13.155), train_loss = 1.15525090, grad/param norm = 1.7674e-01, time/batch = 0.6870s	
6039/22950 (epoch 13.157), train_loss = 1.14906478, grad/param norm = 1.9639e-01, time/batch = 0.6875s	
6040/22950 (epoch 13.159), train_loss = 1.12748010, grad/param norm = 1.7312e-01, time/batch = 0.6887s	
6041/22950 (epoch 13.161), train_loss = 1.17926261, grad/param norm = 1.6957e-01, time/batch = 0.6908s	
6042/22950 (epoch 13.163), train_loss = 1.12054320, grad/param norm = 1.8429e-01, time/batch = 0.6975s	
6043/22950 (epoch 13.166), train_loss = 1.41223602, grad/param norm = 2.4976e-01, time/batch = 0.6944s	
6044/22950 (epoch 13.168), train_loss = 1.35953077, grad/param norm = 2.3016e-01, time/batch = 0.6883s	
6045/22950 (epoch 13.170), train_loss = 1.27568961, grad/param norm = 2.0878e-01, time/batch = 0.6952s	
6046/22950 (epoch 13.172), train_loss = 1.24266290, grad/param norm = 1.9127e-01, time/batch = 0.6900s	
6047/22950 (epoch 13.174), train_loss = 1.32673696, grad/param norm = 2.2831e-01, time/batch = 0.6883s	
6048/22950 (epoch 13.176), train_loss = 1.36829119, grad/param norm = 1.9458e-01, time/batch = 0.6859s	
6049/22950 (epoch 13.179), train_loss = 1.27715164, grad/param norm = 1.9023e-01, time/batch = 0.6888s	
6050/22950 (epoch 13.181), train_loss = 1.44917726, grad/param norm = 2.0564e-01, time/batch = 0.6867s	
6051/22950 (epoch 13.183), train_loss = 1.33818297, grad/param norm = 2.0909e-01, time/batch = 0.6926s	
6052/22950 (epoch 13.185), train_loss = 1.30300124, grad/param norm = 2.0255e-01, time/batch = 0.6910s	
6053/22950 (epoch 13.187), train_loss = 1.12192450, grad/param norm = 1.9574e-01, time/batch = 0.6856s	
6054/22950 (epoch 13.190), train_loss = 1.10882356, grad/param norm = 2.0390e-01, time/batch = 0.6848s	
6055/22950 (epoch 13.192), train_loss = 1.11262794, grad/param norm = 1.7767e-01, time/batch = 0.7004s	
6056/22950 (epoch 13.194), train_loss = 1.17217616, grad/param norm = 2.1366e-01, time/batch = 0.7136s	
6057/22950 (epoch 13.196), train_loss = 1.06167693, grad/param norm = 1.8575e-01, time/batch = 0.7038s	
6058/22950 (epoch 13.198), train_loss = 1.32342713, grad/param norm = 2.0471e-01, time/batch = 0.7048s	
6059/22950 (epoch 13.200), train_loss = 1.11114111, grad/param norm = 1.8655e-01, time/batch = 0.7024s	
6060/22950 (epoch 13.203), train_loss = 1.07439742, grad/param norm = 1.7948e-01, time/batch = 0.7016s	
6061/22950 (epoch 13.205), train_loss = 1.15747080, grad/param norm = 1.7678e-01, time/batch = 0.7017s	
6062/22950 (epoch 13.207), train_loss = 1.20087226, grad/param norm = 1.9722e-01, time/batch = 0.7048s	
6063/22950 (epoch 13.209), train_loss = 1.28674003, grad/param norm = 1.9876e-01, time/batch = 0.7066s	
6064/22950 (epoch 13.211), train_loss = 1.03956839, grad/param norm = 1.9328e-01, time/batch = 0.6997s	
6065/22950 (epoch 13.214), train_loss = 1.21814601, grad/param norm = 1.8177e-01, time/batch = 0.7051s	
6066/22950 (epoch 13.216), train_loss = 1.32078985, grad/param norm = 2.0228e-01, time/batch = 0.7123s	
6067/22950 (epoch 13.218), train_loss = 1.22144552, grad/param norm = 1.8348e-01, time/batch = 0.7012s	
6068/22950 (epoch 13.220), train_loss = 1.35661980, grad/param norm = 2.0287e-01, time/batch = 0.6921s	
6069/22950 (epoch 13.222), train_loss = 1.34734170, grad/param norm = 2.1771e-01, time/batch = 0.7025s	
6070/22950 (epoch 13.224), train_loss = 1.18942901, grad/param norm = 1.9387e-01, time/batch = 0.7196s	
6071/22950 (epoch 13.227), train_loss = 1.28291099, grad/param norm = 1.9443e-01, time/batch = 0.7259s	
6072/22950 (epoch 13.229), train_loss = 1.28251235, grad/param norm = 2.0186e-01, time/batch = 0.7190s	
6073/22950 (epoch 13.231), train_loss = 1.09013799, grad/param norm = 1.8755e-01, time/batch = 0.7145s	
6074/22950 (epoch 13.233), train_loss = 1.17026015, grad/param norm = 1.9039e-01, time/batch = 0.7160s	
6075/22950 (epoch 13.235), train_loss = 1.36948681, grad/param norm = 2.1673e-01, time/batch = 0.7194s	
6076/22950 (epoch 13.237), train_loss = 1.12656132, grad/param norm = 1.7952e-01, time/batch = 0.7198s	
6077/22950 (epoch 13.240), train_loss = 1.22088346, grad/param norm = 2.1445e-01, time/batch = 0.7131s	
6078/22950 (epoch 13.242), train_loss = 1.31599804, grad/param norm = 1.8668e-01, time/batch = 0.7070s	
6079/22950 (epoch 13.244), train_loss = 1.42290204, grad/param norm = 2.2704e-01, time/batch = 0.7217s	
6080/22950 (epoch 13.246), train_loss = 1.36512274, grad/param norm = 2.0194e-01, time/batch = 0.7138s	
6081/22950 (epoch 13.248), train_loss = 1.27678756, grad/param norm = 2.2180e-01, time/batch = 0.7146s	
6082/22950 (epoch 13.251), train_loss = 1.16257176, grad/param norm = 1.9072e-01, time/batch = 0.6986s	
6083/22950 (epoch 13.253), train_loss = 1.17797570, grad/param norm = 2.1151e-01, time/batch = 0.7097s	
6084/22950 (epoch 13.255), train_loss = 1.22354899, grad/param norm = 2.0132e-01, time/batch = 0.7156s	
6085/22950 (epoch 13.257), train_loss = 1.34038390, grad/param norm = 1.9805e-01, time/batch = 0.7162s	
6086/22950 (epoch 13.259), train_loss = 1.08578647, grad/param norm = 2.0106e-01, time/batch = 0.6891s	
6087/22950 (epoch 13.261), train_loss = 1.20431318, grad/param norm = 2.0736e-01, time/batch = 0.6897s	
6088/22950 (epoch 13.264), train_loss = 1.13451993, grad/param norm = 1.7655e-01, time/batch = 0.6925s	
6089/22950 (epoch 13.266), train_loss = 1.27891650, grad/param norm = 1.9267e-01, time/batch = 0.7021s	
6090/22950 (epoch 13.268), train_loss = 1.26817145, grad/param norm = 1.9334e-01, time/batch = 0.6939s	
6091/22950 (epoch 13.270), train_loss = 1.24743489, grad/param norm = 1.9818e-01, time/batch = 0.6931s	
6092/22950 (epoch 13.272), train_loss = 1.35284213, grad/param norm = 1.9838e-01, time/batch = 0.6891s	
6093/22950 (epoch 13.275), train_loss = 1.16841931, grad/param norm = 2.1200e-01, time/batch = 0.6915s	
6094/22950 (epoch 13.277), train_loss = 1.05709391, grad/param norm = 1.6456e-01, time/batch = 0.6876s	
6095/22950 (epoch 13.279), train_loss = 1.23345126, grad/param norm = 2.2367e-01, time/batch = 0.6969s	
6096/22950 (epoch 13.281), train_loss = 1.14862567, grad/param norm = 1.8739e-01, time/batch = 0.6899s	
6097/22950 (epoch 13.283), train_loss = 1.04178080, grad/param norm = 1.7358e-01, time/batch = 0.6848s	
6098/22950 (epoch 13.285), train_loss = 1.21771838, grad/param norm = 1.7741e-01, time/batch = 0.6888s	
6099/22950 (epoch 13.288), train_loss = 1.24084744, grad/param norm = 1.7709e-01, time/batch = 0.6859s	
6100/22950 (epoch 13.290), train_loss = 1.13175593, grad/param norm = 1.7698e-01, time/batch = 0.6860s	
6101/22950 (epoch 13.292), train_loss = 1.28611749, grad/param norm = 1.9332e-01, time/batch = 0.6851s	
6102/22950 (epoch 13.294), train_loss = 1.21168066, grad/param norm = 1.8665e-01, time/batch = 0.6883s	
6103/22950 (epoch 13.296), train_loss = 0.99472186, grad/param norm = 1.5775e-01, time/batch = 0.6878s	
6104/22950 (epoch 13.298), train_loss = 1.22243921, grad/param norm = 1.7838e-01, time/batch = 0.6881s	
6105/22950 (epoch 13.301), train_loss = 1.25802600, grad/param norm = 2.0080e-01, time/batch = 0.7192s	
6106/22950 (epoch 13.303), train_loss = 1.27625188, grad/param norm = 2.0268e-01, time/batch = 0.7078s	
6107/22950 (epoch 13.305), train_loss = 1.27752917, grad/param norm = 1.9627e-01, time/batch = 0.6865s	
6108/22950 (epoch 13.307), train_loss = 1.37081925, grad/param norm = 2.1900e-01, time/batch = 0.6841s	
6109/22950 (epoch 13.309), train_loss = 1.17897015, grad/param norm = 1.7474e-01, time/batch = 0.6878s	
6110/22950 (epoch 13.312), train_loss = 1.21740558, grad/param norm = 1.8764e-01, time/batch = 0.6846s	
6111/22950 (epoch 13.314), train_loss = 1.16587585, grad/param norm = 1.8557e-01, time/batch = 0.6868s	
6112/22950 (epoch 13.316), train_loss = 1.23146219, grad/param norm = 1.9176e-01, time/batch = 0.6850s	
6113/22950 (epoch 13.318), train_loss = 1.03478974, grad/param norm = 1.7788e-01, time/batch = 0.6869s	
6114/22950 (epoch 13.320), train_loss = 1.16343021, grad/param norm = 1.6912e-01, time/batch = 0.6883s	
6115/22950 (epoch 13.322), train_loss = 1.20683143, grad/param norm = 1.9751e-01, time/batch = 0.7153s	
6116/22950 (epoch 13.325), train_loss = 0.96826843, grad/param norm = 1.7364e-01, time/batch = 0.7104s	
6117/22950 (epoch 13.327), train_loss = 1.00547354, grad/param norm = 1.7909e-01, time/batch = 0.6859s	
6118/22950 (epoch 13.329), train_loss = 1.13536841, grad/param norm = 1.8981e-01, time/batch = 0.6849s	
6119/22950 (epoch 13.331), train_loss = 1.06690247, grad/param norm = 1.9762e-01, time/batch = 0.6867s	
6120/22950 (epoch 13.333), train_loss = 1.18837096, grad/param norm = 1.9564e-01, time/batch = 0.6944s	
6121/22950 (epoch 13.336), train_loss = 1.17927546, grad/param norm = 1.9390e-01, time/batch = 0.6889s	
6122/22950 (epoch 13.338), train_loss = 1.14846442, grad/param norm = 1.8584e-01, time/batch = 0.6865s	
6123/22950 (epoch 13.340), train_loss = 1.20552504, grad/param norm = 2.1203e-01, time/batch = 0.6908s	
6124/22950 (epoch 13.342), train_loss = 1.31321293, grad/param norm = 1.9674e-01, time/batch = 0.6877s	
6125/22950 (epoch 13.344), train_loss = 1.21422839, grad/param norm = 1.9753e-01, time/batch = 0.7146s	
6126/22950 (epoch 13.346), train_loss = 1.38298778, grad/param norm = 2.1861e-01, time/batch = 0.7164s	
6127/22950 (epoch 13.349), train_loss = 1.22144288, grad/param norm = 2.0548e-01, time/batch = 0.6916s	
6128/22950 (epoch 13.351), train_loss = 1.25837294, grad/param norm = 1.9610e-01, time/batch = 0.6944s	
6129/22950 (epoch 13.353), train_loss = 1.32503268, grad/param norm = 2.2456e-01, time/batch = 0.6878s	
6130/22950 (epoch 13.355), train_loss = 1.33418829, grad/param norm = 1.9652e-01, time/batch = 0.6858s	
6131/22950 (epoch 13.357), train_loss = 1.22614465, grad/param norm = 1.9911e-01, time/batch = 0.6893s	
6132/22950 (epoch 13.359), train_loss = 1.25747191, grad/param norm = 2.1857e-01, time/batch = 0.6873s	
6133/22950 (epoch 13.362), train_loss = 1.20684632, grad/param norm = 1.8955e-01, time/batch = 0.6889s	
6134/22950 (epoch 13.364), train_loss = 1.21320818, grad/param norm = 1.9541e-01, time/batch = 0.6871s	
6135/22950 (epoch 13.366), train_loss = 1.07847403, grad/param norm = 1.7950e-01, time/batch = 0.7148s	
6136/22950 (epoch 13.368), train_loss = 1.24306215, grad/param norm = 2.0259e-01, time/batch = 0.7134s	
6137/22950 (epoch 13.370), train_loss = 1.19895343, grad/param norm = 1.9657e-01, time/batch = 0.6887s	
6138/22950 (epoch 13.373), train_loss = 1.07742858, grad/param norm = 1.8690e-01, time/batch = 0.6894s	
6139/22950 (epoch 13.375), train_loss = 1.33519591, grad/param norm = 2.1261e-01, time/batch = 0.6882s	
6140/22950 (epoch 13.377), train_loss = 1.15066511, grad/param norm = 2.1008e-01, time/batch = 0.6894s	
6141/22950 (epoch 13.379), train_loss = 1.27588267, grad/param norm = 2.1314e-01, time/batch = 0.6909s	
6142/22950 (epoch 13.381), train_loss = 1.04282327, grad/param norm = 1.8158e-01, time/batch = 0.6896s	
6143/22950 (epoch 13.383), train_loss = 1.25754949, grad/param norm = 2.0281e-01, time/batch = 0.6934s	
6144/22950 (epoch 13.386), train_loss = 1.17124650, grad/param norm = 2.0980e-01, time/batch = 0.6890s	
6145/22950 (epoch 13.388), train_loss = 1.23547402, grad/param norm = 2.1884e-01, time/batch = 0.6880s	
6146/22950 (epoch 13.390), train_loss = 1.11575038, grad/param norm = 1.8158e-01, time/batch = 0.6852s	
6147/22950 (epoch 13.392), train_loss = 1.10833374, grad/param norm = 1.8772e-01, time/batch = 0.6889s	
6148/22950 (epoch 13.394), train_loss = 1.13451286, grad/param norm = 1.6641e-01, time/batch = 0.6861s	
6149/22950 (epoch 13.397), train_loss = 1.34461842, grad/param norm = 2.1852e-01, time/batch = 0.6851s	
6150/22950 (epoch 13.399), train_loss = 1.32497622, grad/param norm = 2.1017e-01, time/batch = 0.6843s	
6151/22950 (epoch 13.401), train_loss = 1.48841994, grad/param norm = 2.1463e-01, time/batch = 0.6921s	
6152/22950 (epoch 13.403), train_loss = 1.18620611, grad/param norm = 1.9685e-01, time/batch = 0.6921s	
6153/22950 (epoch 13.405), train_loss = 1.33034460, grad/param norm = 2.1896e-01, time/batch = 0.6920s	
6154/22950 (epoch 13.407), train_loss = 1.39283098, grad/param norm = 2.0764e-01, time/batch = 0.6893s	
6155/22950 (epoch 13.410), train_loss = 1.12182867, grad/param norm = 1.8785e-01, time/batch = 0.7044s	
6156/22950 (epoch 13.412), train_loss = 1.24451100, grad/param norm = 2.1310e-01, time/batch = 0.7147s	
6157/22950 (epoch 13.414), train_loss = 1.32387011, grad/param norm = 2.1599e-01, time/batch = 0.7250s	
6158/22950 (epoch 13.416), train_loss = 1.27039446, grad/param norm = 2.2075e-01, time/batch = 0.7019s	
6159/22950 (epoch 13.418), train_loss = 1.26434126, grad/param norm = 1.9749e-01, time/batch = 0.6974s	
6160/22950 (epoch 13.420), train_loss = 1.28793248, grad/param norm = 2.1069e-01, time/batch = 0.7050s	
6161/22950 (epoch 13.423), train_loss = 1.13845910, grad/param norm = 1.8567e-01, time/batch = 0.7149s	
6162/22950 (epoch 13.425), train_loss = 1.23649261, grad/param norm = 2.0044e-01, time/batch = 0.6924s	
6163/22950 (epoch 13.427), train_loss = 1.20223744, grad/param norm = 2.0852e-01, time/batch = 0.6917s	
6164/22950 (epoch 13.429), train_loss = 1.20457434, grad/param norm = 2.0250e-01, time/batch = 0.6889s	
6165/22950 (epoch 13.431), train_loss = 1.26734483, grad/param norm = 2.0574e-01, time/batch = 0.6895s	
6166/22950 (epoch 13.434), train_loss = 1.22891024, grad/param norm = 2.0406e-01, time/batch = 0.6920s	
6167/22950 (epoch 13.436), train_loss = 1.43859446, grad/param norm = 2.1980e-01, time/batch = 0.6867s	
6168/22950 (epoch 13.438), train_loss = 1.23194200, grad/param norm = 1.9832e-01, time/batch = 0.6849s	
6169/22950 (epoch 13.440), train_loss = 1.32660583, grad/param norm = 2.0416e-01, time/batch = 0.6874s	
6170/22950 (epoch 13.442), train_loss = 1.39210929, grad/param norm = 2.0532e-01, time/batch = 0.6887s	
6171/22950 (epoch 13.444), train_loss = 1.31828708, grad/param norm = 2.0295e-01, time/batch = 0.6888s	
6172/22950 (epoch 13.447), train_loss = 1.43726529, grad/param norm = 2.2234e-01, time/batch = 0.6881s	
6173/22950 (epoch 13.449), train_loss = 1.10710794, grad/param norm = 1.7563e-01, time/batch = 0.6851s	
6174/22950 (epoch 13.451), train_loss = 1.25955795, grad/param norm = 1.9044e-01, time/batch = 0.6902s	
6175/22950 (epoch 13.453), train_loss = 1.26759365, grad/param norm = 1.9031e-01, time/batch = 0.7136s	
6176/22950 (epoch 13.455), train_loss = 1.11540502, grad/param norm = 1.7920e-01, time/batch = 0.6979s	
6177/22950 (epoch 13.458), train_loss = 1.36787982, grad/param norm = 1.9725e-01, time/batch = 0.6993s	
6178/22950 (epoch 13.460), train_loss = 1.25050249, grad/param norm = 2.0299e-01, time/batch = 0.6870s	
6179/22950 (epoch 13.462), train_loss = 1.22387530, grad/param norm = 1.8228e-01, time/batch = 0.6881s	
6180/22950 (epoch 13.464), train_loss = 1.19383411, grad/param norm = 1.9095e-01, time/batch = 0.6972s	
6181/22950 (epoch 13.466), train_loss = 1.26646921, grad/param norm = 2.0887e-01, time/batch = 0.6883s	
6182/22950 (epoch 13.468), train_loss = 1.35414118, grad/param norm = 1.9698e-01, time/batch = 0.6943s	
6183/22950 (epoch 13.471), train_loss = 1.26217040, grad/param norm = 1.9374e-01, time/batch = 0.6921s	
6184/22950 (epoch 13.473), train_loss = 1.30477121, grad/param norm = 2.0752e-01, time/batch = 0.6874s	
6185/22950 (epoch 13.475), train_loss = 1.47107070, grad/param norm = 2.1414e-01, time/batch = 0.6905s	
6186/22950 (epoch 13.477), train_loss = 1.21891702, grad/param norm = 1.9708e-01, time/batch = 0.6886s	
6187/22950 (epoch 13.479), train_loss = 1.16322656, grad/param norm = 2.0204e-01, time/batch = 0.6844s	
6188/22950 (epoch 13.481), train_loss = 1.37517118, grad/param norm = 2.1603e-01, time/batch = 0.6990s	
6189/22950 (epoch 13.484), train_loss = 1.27108950, grad/param norm = 1.9635e-01, time/batch = 0.6930s	
6190/22950 (epoch 13.486), train_loss = 1.09270059, grad/param norm = 1.8121e-01, time/batch = 0.6950s	
6191/22950 (epoch 13.488), train_loss = 1.21710977, grad/param norm = 2.0836e-01, time/batch = 0.6906s	
6192/22950 (epoch 13.490), train_loss = 1.06203273, grad/param norm = 2.0293e-01, time/batch = 0.6951s	
6193/22950 (epoch 13.492), train_loss = 1.20938478, grad/param norm = 1.9258e-01, time/batch = 0.6879s	
6194/22950 (epoch 13.495), train_loss = 1.20666947, grad/param norm = 1.9487e-01, time/batch = 0.6865s	
6195/22950 (epoch 13.497), train_loss = 1.31307044, grad/param norm = 2.0010e-01, time/batch = 0.6904s	
6196/22950 (epoch 13.499), train_loss = 1.35009485, grad/param norm = 2.0333e-01, time/batch = 0.6920s	
6197/22950 (epoch 13.501), train_loss = 1.29593564, grad/param norm = 2.0967e-01, time/batch = 0.6863s	
6198/22950 (epoch 13.503), train_loss = 1.33395061, grad/param norm = 2.0071e-01, time/batch = 0.6876s	
6199/22950 (epoch 13.505), train_loss = 1.10159398, grad/param norm = 1.7282e-01, time/batch = 0.6882s	
6200/22950 (epoch 13.508), train_loss = 1.29091063, grad/param norm = 1.9261e-01, time/batch = 0.6869s	
6201/22950 (epoch 13.510), train_loss = 1.24792549, grad/param norm = 1.9547e-01, time/batch = 0.6917s	
6202/22950 (epoch 13.512), train_loss = 1.13853427, grad/param norm = 1.7622e-01, time/batch = 0.6878s	
6203/22950 (epoch 13.514), train_loss = 1.11226094, grad/param norm = 1.7407e-01, time/batch = 0.6890s	
6204/22950 (epoch 13.516), train_loss = 1.21043058, grad/param norm = 2.0533e-01, time/batch = 0.6872s	
6205/22950 (epoch 13.519), train_loss = 1.18722613, grad/param norm = 1.7957e-01, time/batch = 0.6870s	
6206/22950 (epoch 13.521), train_loss = 1.23569097, grad/param norm = 1.8356e-01, time/batch = 0.6889s	
6207/22950 (epoch 13.523), train_loss = 1.00212507, grad/param norm = 1.8104e-01, time/batch = 0.6898s	
6208/22950 (epoch 13.525), train_loss = 1.11479169, grad/param norm = 1.8896e-01, time/batch = 0.6879s	
6209/22950 (epoch 13.527), train_loss = 1.05894864, grad/param norm = 1.9584e-01, time/batch = 0.6858s	
6210/22950 (epoch 13.529), train_loss = 1.26827707, grad/param norm = 2.0821e-01, time/batch = 0.6889s	
6211/22950 (epoch 13.532), train_loss = 1.16438564, grad/param norm = 1.8427e-01, time/batch = 0.6906s	
6212/22950 (epoch 13.534), train_loss = 1.31294002, grad/param norm = 2.1461e-01, time/batch = 0.6899s	
6213/22950 (epoch 13.536), train_loss = 1.29275233, grad/param norm = 2.2096e-01, time/batch = 0.6876s	
6214/22950 (epoch 13.538), train_loss = 1.19635952, grad/param norm = 2.1545e-01, time/batch = 0.6887s	
6215/22950 (epoch 13.540), train_loss = 1.24928230, grad/param norm = 1.8220e-01, time/batch = 0.6954s	
6216/22950 (epoch 13.542), train_loss = 1.40267678, grad/param norm = 2.1161e-01, time/batch = 0.6861s	
6217/22950 (epoch 13.545), train_loss = 1.20370840, grad/param norm = 2.0481e-01, time/batch = 0.6880s	
6218/22950 (epoch 13.547), train_loss = 1.20959524, grad/param norm = 1.9199e-01, time/batch = 0.6840s	
6219/22950 (epoch 13.549), train_loss = 1.20065957, grad/param norm = 1.9522e-01, time/batch = 0.6865s	
6220/22950 (epoch 13.551), train_loss = 1.23178615, grad/param norm = 2.0148e-01, time/batch = 0.6866s	
6221/22950 (epoch 13.553), train_loss = 1.19470667, grad/param norm = 2.1464e-01, time/batch = 0.6884s	
6222/22950 (epoch 13.556), train_loss = 1.28618352, grad/param norm = 1.8611e-01, time/batch = 0.6857s	
6223/22950 (epoch 13.558), train_loss = 1.14224803, grad/param norm = 1.9490e-01, time/batch = 0.6881s	
6224/22950 (epoch 13.560), train_loss = 1.25832099, grad/param norm = 2.0201e-01, time/batch = 0.6880s	
6225/22950 (epoch 13.562), train_loss = 1.11326756, grad/param norm = 1.8126e-01, time/batch = 0.6865s	
6226/22950 (epoch 13.564), train_loss = 1.39499981, grad/param norm = 2.4011e-01, time/batch = 0.6865s	
6227/22950 (epoch 13.566), train_loss = 1.24528738, grad/param norm = 1.9034e-01, time/batch = 0.6882s	
6228/22950 (epoch 13.569), train_loss = 1.34490612, grad/param norm = 1.9549e-01, time/batch = 0.6854s	
6229/22950 (epoch 13.571), train_loss = 1.12603823, grad/param norm = 1.9961e-01, time/batch = 0.6978s	
6230/22950 (epoch 13.573), train_loss = 1.23968047, grad/param norm = 1.9867e-01, time/batch = 0.7150s	
6231/22950 (epoch 13.575), train_loss = 1.41354669, grad/param norm = 2.1436e-01, time/batch = 0.7135s	
6232/22950 (epoch 13.577), train_loss = 1.23395436, grad/param norm = 2.2811e-01, time/batch = 0.6859s	
6233/22950 (epoch 13.580), train_loss = 1.28587886, grad/param norm = 2.0827e-01, time/batch = 0.6852s	
6234/22950 (epoch 13.582), train_loss = 1.44142245, grad/param norm = 2.1058e-01, time/batch = 0.6899s	
6235/22950 (epoch 13.584), train_loss = 1.11081376, grad/param norm = 1.8989e-01, time/batch = 0.6856s	
6236/22950 (epoch 13.586), train_loss = 1.20544065, grad/param norm = 2.1585e-01, time/batch = 0.6878s	
6237/22950 (epoch 13.588), train_loss = 1.34662439, grad/param norm = 1.9584e-01, time/batch = 0.6975s	
6238/22950 (epoch 13.590), train_loss = 1.21009193, grad/param norm = 1.9158e-01, time/batch = 0.6919s	
6239/22950 (epoch 13.593), train_loss = 1.12590491, grad/param norm = 1.9733e-01, time/batch = 0.6884s	
6240/22950 (epoch 13.595), train_loss = 1.10599906, grad/param norm = 1.9555e-01, time/batch = 0.6896s	
6241/22950 (epoch 13.597), train_loss = 1.29720161, grad/param norm = 2.0730e-01, time/batch = 0.6942s	
6242/22950 (epoch 13.599), train_loss = 1.26004779, grad/param norm = 2.2220e-01, time/batch = 0.7209s	
6243/22950 (epoch 13.601), train_loss = 1.23852493, grad/param norm = 2.0364e-01, time/batch = 0.7224s	
6244/22950 (epoch 13.603), train_loss = 1.37156514, grad/param norm = 1.9226e-01, time/batch = 0.7101s	
6245/22950 (epoch 13.606), train_loss = 1.19883893, grad/param norm = 1.9741e-01, time/batch = 0.6994s	
6246/22950 (epoch 13.608), train_loss = 1.25506078, grad/param norm = 1.9724e-01, time/batch = 0.6999s	
6247/22950 (epoch 13.610), train_loss = 1.19892360, grad/param norm = 1.8884e-01, time/batch = 0.7186s	
6248/22950 (epoch 13.612), train_loss = 1.22714639, grad/param norm = 2.0286e-01, time/batch = 0.7154s	
6249/22950 (epoch 13.614), train_loss = 1.36277677, grad/param norm = 2.2208e-01, time/batch = 0.7086s	
6250/22950 (epoch 13.617), train_loss = 1.20731443, grad/param norm = 1.8909e-01, time/batch = 0.6904s	
6251/22950 (epoch 13.619), train_loss = 1.13426783, grad/param norm = 1.6932e-01, time/batch = 0.6857s	
6252/22950 (epoch 13.621), train_loss = 1.31839451, grad/param norm = 1.8229e-01, time/batch = 0.6888s	
6253/22950 (epoch 13.623), train_loss = 1.28639670, grad/param norm = 1.7812e-01, time/batch = 0.6912s	
6254/22950 (epoch 13.625), train_loss = 1.22071455, grad/param norm = 1.9333e-01, time/batch = 0.6874s	
6255/22950 (epoch 13.627), train_loss = 1.22350954, grad/param norm = 1.9335e-01, time/batch = 0.6875s	
6256/22950 (epoch 13.630), train_loss = 1.09105521, grad/param norm = 1.9520e-01, time/batch = 0.6897s	
6257/22950 (epoch 13.632), train_loss = 1.24401400, grad/param norm = 2.0573e-01, time/batch = 0.6908s	
6258/22950 (epoch 13.634), train_loss = 1.21107990, grad/param norm = 1.9457e-01, time/batch = 0.6897s	
6259/22950 (epoch 13.636), train_loss = 1.27167817, grad/param norm = 2.1568e-01, time/batch = 0.7183s	
6260/22950 (epoch 13.638), train_loss = 1.13091986, grad/param norm = 1.9506e-01, time/batch = 0.7131s	
6261/22950 (epoch 13.641), train_loss = 1.17516883, grad/param norm = 1.8398e-01, time/batch = 0.7000s	
6262/22950 (epoch 13.643), train_loss = 1.26614326, grad/param norm = 2.2091e-01, time/batch = 0.6950s	
6263/22950 (epoch 13.645), train_loss = 1.15276956, grad/param norm = 1.9337e-01, time/batch = 0.6855s	
6264/22950 (epoch 13.647), train_loss = 1.22248423, grad/param norm = 2.0521e-01, time/batch = 0.6867s	
6265/22950 (epoch 13.649), train_loss = 1.23657156, grad/param norm = 1.9700e-01, time/batch = 0.6968s	
6266/22950 (epoch 13.651), train_loss = 1.32108985, grad/param norm = 2.1806e-01, time/batch = 0.6952s	
6267/22950 (epoch 13.654), train_loss = 1.03137733, grad/param norm = 1.8014e-01, time/batch = 0.6908s	
6268/22950 (epoch 13.656), train_loss = 1.36927244, grad/param norm = 2.2977e-01, time/batch = 0.6924s	
6269/22950 (epoch 13.658), train_loss = 1.13345392, grad/param norm = 1.9622e-01, time/batch = 0.6941s	
6270/22950 (epoch 13.660), train_loss = 1.05701488, grad/param norm = 2.0258e-01, time/batch = 0.6901s	
6271/22950 (epoch 13.662), train_loss = 1.05931420, grad/param norm = 1.7345e-01, time/batch = 0.6931s	
6272/22950 (epoch 13.664), train_loss = 1.23059529, grad/param norm = 1.9930e-01, time/batch = 0.6910s	
6273/22950 (epoch 13.667), train_loss = 1.25171868, grad/param norm = 2.0070e-01, time/batch = 0.6892s	
6274/22950 (epoch 13.669), train_loss = 1.18157003, grad/param norm = 1.9549e-01, time/batch = 0.6910s	
6275/22950 (epoch 13.671), train_loss = 1.24786839, grad/param norm = 2.0523e-01, time/batch = 0.6949s	
6276/22950 (epoch 13.673), train_loss = 1.17050214, grad/param norm = 1.8547e-01, time/batch = 0.7013s	
6277/22950 (epoch 13.675), train_loss = 1.21354009, grad/param norm = 2.0171e-01, time/batch = 0.6881s	
6278/22950 (epoch 13.678), train_loss = 1.22674132, grad/param norm = 2.0484e-01, time/batch = 0.6875s	
6279/22950 (epoch 13.680), train_loss = 1.23244513, grad/param norm = 1.8956e-01, time/batch = 0.6885s	
6280/22950 (epoch 13.682), train_loss = 1.30423835, grad/param norm = 2.1139e-01, time/batch = 0.7120s	
6281/22950 (epoch 13.684), train_loss = 1.33168568, grad/param norm = 1.9759e-01, time/batch = 0.7164s	
6282/22950 (epoch 13.686), train_loss = 1.31584623, grad/param norm = 2.1404e-01, time/batch = 0.6895s	
6283/22950 (epoch 13.688), train_loss = 1.23378037, grad/param norm = 2.0938e-01, time/batch = 0.6891s	
6284/22950 (epoch 13.691), train_loss = 1.21975493, grad/param norm = 1.9269e-01, time/batch = 0.6926s	
6285/22950 (epoch 13.693), train_loss = 1.13560101, grad/param norm = 1.9557e-01, time/batch = 0.6897s	
6286/22950 (epoch 13.695), train_loss = 1.36207091, grad/param norm = 1.9993e-01, time/batch = 0.6915s	
6287/22950 (epoch 13.697), train_loss = 1.32709461, grad/param norm = 2.0163e-01, time/batch = 0.6876s	
6288/22950 (epoch 13.699), train_loss = 1.30617975, grad/param norm = 1.9761e-01, time/batch = 0.6894s	
6289/22950 (epoch 13.702), train_loss = 1.29325335, grad/param norm = 1.9577e-01, time/batch = 0.6910s	
6290/22950 (epoch 13.704), train_loss = 1.30070687, grad/param norm = 1.9679e-01, time/batch = 0.6986s	
6291/22950 (epoch 13.706), train_loss = 1.31007440, grad/param norm = 2.2049e-01, time/batch = 0.7004s	
6292/22950 (epoch 13.708), train_loss = 1.13801570, grad/param norm = 1.9604e-01, time/batch = 0.6926s	
6293/22950 (epoch 13.710), train_loss = 1.29145029, grad/param norm = 1.9390e-01, time/batch = 0.6965s	
6294/22950 (epoch 13.712), train_loss = 1.36357547, grad/param norm = 2.0965e-01, time/batch = 0.6883s	
6295/22950 (epoch 13.715), train_loss = 1.30466649, grad/param norm = 2.0704e-01, time/batch = 0.6892s	
6296/22950 (epoch 13.717), train_loss = 1.17367659, grad/param norm = 1.8625e-01, time/batch = 0.6875s	
6297/22950 (epoch 13.719), train_loss = 1.20020965, grad/param norm = 2.1934e-01, time/batch = 0.6880s	
6298/22950 (epoch 13.721), train_loss = 1.27058311, grad/param norm = 1.9004e-01, time/batch = 0.6863s	
6299/22950 (epoch 13.723), train_loss = 1.14794230, grad/param norm = 1.8452e-01, time/batch = 0.6876s	
6300/22950 (epoch 13.725), train_loss = 1.30094438, grad/param norm = 1.9845e-01, time/batch = 0.7090s	
6301/22950 (epoch 13.728), train_loss = 1.22641783, grad/param norm = 2.2991e-01, time/batch = 0.7189s	
6302/22950 (epoch 13.730), train_loss = 1.23099207, grad/param norm = 2.0106e-01, time/batch = 0.6849s	
6303/22950 (epoch 13.732), train_loss = 1.27841396, grad/param norm = 1.8725e-01, time/batch = 0.6857s	
6304/22950 (epoch 13.734), train_loss = 1.25921113, grad/param norm = 2.1367e-01, time/batch = 0.6866s	
6305/22950 (epoch 13.736), train_loss = 1.19573378, grad/param norm = 1.9226e-01, time/batch = 0.6902s	
6306/22950 (epoch 13.739), train_loss = 1.29619724, grad/param norm = 2.0699e-01, time/batch = 0.6874s	
6307/22950 (epoch 13.741), train_loss = 1.28650956, grad/param norm = 2.0912e-01, time/batch = 0.6879s	
6308/22950 (epoch 13.743), train_loss = 1.40968247, grad/param norm = 2.0179e-01, time/batch = 0.6897s	
6309/22950 (epoch 13.745), train_loss = 1.47906504, grad/param norm = 2.0564e-01, time/batch = 0.6849s	
6310/22950 (epoch 13.747), train_loss = 1.26887056, grad/param norm = 1.9759e-01, time/batch = 0.6884s	
6311/22950 (epoch 13.749), train_loss = 1.12824000, grad/param norm = 1.8895e-01, time/batch = 0.6871s	
6312/22950 (epoch 13.752), train_loss = 1.44084981, grad/param norm = 2.1595e-01, time/batch = 0.6879s	
6313/22950 (epoch 13.754), train_loss = 1.34551043, grad/param norm = 2.0681e-01, time/batch = 0.6902s	
6314/22950 (epoch 13.756), train_loss = 1.15774130, grad/param norm = 2.0280e-01, time/batch = 0.6888s	
6315/22950 (epoch 13.758), train_loss = 1.16629557, grad/param norm = 1.8117e-01, time/batch = 0.6914s	
6316/22950 (epoch 13.760), train_loss = 1.26693849, grad/param norm = 1.9458e-01, time/batch = 0.6878s	
6317/22950 (epoch 13.763), train_loss = 1.29661467, grad/param norm = 2.1532e-01, time/batch = 0.6871s	
6318/22950 (epoch 13.765), train_loss = 1.28319086, grad/param norm = 2.1024e-01, time/batch = 0.6906s	
6319/22950 (epoch 13.767), train_loss = 1.44070570, grad/param norm = 2.0801e-01, time/batch = 0.6904s	
6320/22950 (epoch 13.769), train_loss = 1.26382131, grad/param norm = 1.9662e-01, time/batch = 0.6853s	
6321/22950 (epoch 13.771), train_loss = 1.13943546, grad/param norm = 2.0908e-01, time/batch = 0.6865s	
6322/22950 (epoch 13.773), train_loss = 0.94429694, grad/param norm = 1.7231e-01, time/batch = 0.6902s	
6323/22950 (epoch 13.776), train_loss = 1.15488514, grad/param norm = 1.8908e-01, time/batch = 0.6886s	
6324/22950 (epoch 13.778), train_loss = 1.08237752, grad/param norm = 1.8193e-01, time/batch = 0.6893s	
6325/22950 (epoch 13.780), train_loss = 1.18286543, grad/param norm = 1.7689e-01, time/batch = 0.6867s	
6326/22950 (epoch 13.782), train_loss = 1.19289211, grad/param norm = 1.8316e-01, time/batch = 0.6882s	
6327/22950 (epoch 13.784), train_loss = 1.23200041, grad/param norm = 1.9853e-01, time/batch = 0.6922s	
6328/22950 (epoch 13.786), train_loss = 1.30059428, grad/param norm = 1.8936e-01, time/batch = 0.7174s	
6329/22950 (epoch 13.789), train_loss = 1.07544485, grad/param norm = 1.8898e-01, time/batch = 0.7251s	
6330/22950 (epoch 13.791), train_loss = 1.11091044, grad/param norm = 1.9658e-01, time/batch = 0.7108s	
6331/22950 (epoch 13.793), train_loss = 1.47292130, grad/param norm = 2.3362e-01, time/batch = 0.7153s	
6332/22950 (epoch 13.795), train_loss = 1.16525119, grad/param norm = 1.7521e-01, time/batch = 0.7050s	
6333/22950 (epoch 13.797), train_loss = 1.39797940, grad/param norm = 2.1553e-01, time/batch = 0.7075s	
6334/22950 (epoch 13.800), train_loss = 1.13809782, grad/param norm = 1.9828e-01, time/batch = 0.6958s	
6335/22950 (epoch 13.802), train_loss = 1.14453954, grad/param norm = 1.9760e-01, time/batch = 0.7106s	
6336/22950 (epoch 13.804), train_loss = 1.18944533, grad/param norm = 1.8748e-01, time/batch = 0.7002s	
6337/22950 (epoch 13.806), train_loss = 1.09370219, grad/param norm = 1.9655e-01, time/batch = 0.6932s	
6338/22950 (epoch 13.808), train_loss = 1.20073399, grad/param norm = 1.9293e-01, time/batch = 0.6917s	
6339/22950 (epoch 13.810), train_loss = 1.17602626, grad/param norm = 2.0008e-01, time/batch = 0.6876s	
6340/22950 (epoch 13.813), train_loss = 0.98982076, grad/param norm = 1.7853e-01, time/batch = 0.6866s	
6341/22950 (epoch 13.815), train_loss = 1.09630701, grad/param norm = 1.8577e-01, time/batch = 0.6893s	
6342/22950 (epoch 13.817), train_loss = 1.08431582, grad/param norm = 1.7605e-01, time/batch = 0.6862s	
6343/22950 (epoch 13.819), train_loss = 1.20456698, grad/param norm = 2.0472e-01, time/batch = 0.6888s	
6344/22950 (epoch 13.821), train_loss = 1.21499046, grad/param norm = 2.1254e-01, time/batch = 0.6904s	
6345/22950 (epoch 13.824), train_loss = 1.20555177, grad/param norm = 2.0614e-01, time/batch = 0.7217s	
6346/22950 (epoch 13.826), train_loss = 1.33386950, grad/param norm = 2.2002e-01, time/batch = 0.6986s	
6347/22950 (epoch 13.828), train_loss = 1.19716366, grad/param norm = 2.0304e-01, time/batch = 0.6878s	
6348/22950 (epoch 13.830), train_loss = 1.23004436, grad/param norm = 1.9254e-01, time/batch = 0.6879s	
6349/22950 (epoch 13.832), train_loss = 1.22296559, grad/param norm = 1.8876e-01, time/batch = 0.6857s	
6350/22950 (epoch 13.834), train_loss = 1.06676217, grad/param norm = 1.8425e-01, time/batch = 0.6886s	
6351/22950 (epoch 13.837), train_loss = 1.23754358, grad/param norm = 2.0393e-01, time/batch = 0.6882s	
6352/22950 (epoch 13.839), train_loss = 1.08300557, grad/param norm = 1.8695e-01, time/batch = 0.6889s	
6353/22950 (epoch 13.841), train_loss = 1.12751872, grad/param norm = 1.8134e-01, time/batch = 0.6847s	
6354/22950 (epoch 13.843), train_loss = 1.17682178, grad/param norm = 2.0093e-01, time/batch = 0.6861s	
6355/22950 (epoch 13.845), train_loss = 1.22107976, grad/param norm = 2.0412e-01, time/batch = 0.7237s	
6356/22950 (epoch 13.847), train_loss = 1.29999655, grad/param norm = 2.0589e-01, time/batch = 0.7021s	
6357/22950 (epoch 13.850), train_loss = 1.24176850, grad/param norm = 2.0920e-01, time/batch = 0.6888s	
6358/22950 (epoch 13.852), train_loss = 1.25362685, grad/param norm = 1.8934e-01, time/batch = 0.6882s	
6359/22950 (epoch 13.854), train_loss = 1.20982914, grad/param norm = 2.0362e-01, time/batch = 0.6876s	
6360/22950 (epoch 13.856), train_loss = 1.41729719, grad/param norm = 2.1805e-01, time/batch = 0.6878s	
6361/22950 (epoch 13.858), train_loss = 1.29344354, grad/param norm = 1.9016e-01, time/batch = 0.6871s	
6362/22950 (epoch 13.861), train_loss = 1.32347522, grad/param norm = 2.0077e-01, time/batch = 0.6892s	
6363/22950 (epoch 13.863), train_loss = 1.36943350, grad/param norm = 2.2185e-01, time/batch = 0.6920s	
6364/22950 (epoch 13.865), train_loss = 1.39763587, grad/param norm = 2.0823e-01, time/batch = 0.6909s	
6365/22950 (epoch 13.867), train_loss = 1.27237975, grad/param norm = 2.0150e-01, time/batch = 0.7222s	
6366/22950 (epoch 13.869), train_loss = 1.44749777, grad/param norm = 2.2802e-01, time/batch = 0.7053s	
6367/22950 (epoch 13.871), train_loss = 1.23964689, grad/param norm = 2.0646e-01, time/batch = 0.6881s	
6368/22950 (epoch 13.874), train_loss = 1.22223616, grad/param norm = 2.0067e-01, time/batch = 0.6879s	
6369/22950 (epoch 13.876), train_loss = 1.28124869, grad/param norm = 1.9918e-01, time/batch = 0.6906s	
6370/22950 (epoch 13.878), train_loss = 1.17947597, grad/param norm = 2.1960e-01, time/batch = 0.6845s	
6371/22950 (epoch 13.880), train_loss = 1.40696470, grad/param norm = 2.0494e-01, time/batch = 0.6881s	
6372/22950 (epoch 13.882), train_loss = 1.10914494, grad/param norm = 1.8511e-01, time/batch = 0.6921s	
6373/22950 (epoch 13.885), train_loss = 1.26881301, grad/param norm = 2.1469e-01, time/batch = 0.6932s	
6374/22950 (epoch 13.887), train_loss = 1.26317873, grad/param norm = 2.0466e-01, time/batch = 0.6882s	
6375/22950 (epoch 13.889), train_loss = 1.32051391, grad/param norm = 2.2316e-01, time/batch = 0.7223s	
6376/22950 (epoch 13.891), train_loss = 1.20904563, grad/param norm = 2.0402e-01, time/batch = 0.7042s	
6377/22950 (epoch 13.893), train_loss = 1.26949012, grad/param norm = 2.0075e-01, time/batch = 0.6888s	
6378/22950 (epoch 13.895), train_loss = 1.42590820, grad/param norm = 2.1632e-01, time/batch = 0.6941s	
6379/22950 (epoch 13.898), train_loss = 1.24457941, grad/param norm = 2.0306e-01, time/batch = 0.6896s	
6380/22950 (epoch 13.900), train_loss = 1.13806419, grad/param norm = 1.7544e-01, time/batch = 0.6889s	
6381/22950 (epoch 13.902), train_loss = 1.30956455, grad/param norm = 1.9956e-01, time/batch = 0.6883s	
6382/22950 (epoch 13.904), train_loss = 1.26613430, grad/param norm = 1.9028e-01, time/batch = 0.6906s	
6383/22950 (epoch 13.906), train_loss = 1.24053135, grad/param norm = 1.8573e-01, time/batch = 0.6895s	
6384/22950 (epoch 13.908), train_loss = 1.13818075, grad/param norm = 1.9405e-01, time/batch = 0.6955s	
6385/22950 (epoch 13.911), train_loss = 1.08596436, grad/param norm = 1.8523e-01, time/batch = 0.7195s	
6386/22950 (epoch 13.913), train_loss = 1.16445889, grad/param norm = 1.9777e-01, time/batch = 0.7149s	
6387/22950 (epoch 13.915), train_loss = 1.33718832, grad/param norm = 2.1880e-01, time/batch = 0.6950s	
6388/22950 (epoch 13.917), train_loss = 1.09254338, grad/param norm = 1.8610e-01, time/batch = 0.6871s	
6389/22950 (epoch 13.919), train_loss = 1.16848215, grad/param norm = 1.8967e-01, time/batch = 0.6880s	
6390/22950 (epoch 13.922), train_loss = 1.22105536, grad/param norm = 2.0557e-01, time/batch = 0.6869s	
6391/22950 (epoch 13.924), train_loss = 1.30277030, grad/param norm = 2.0026e-01, time/batch = 0.7035s	
6392/22950 (epoch 13.926), train_loss = 1.07832467, grad/param norm = 1.9392e-01, time/batch = 0.6952s	
6393/22950 (epoch 13.928), train_loss = 1.08487310, grad/param norm = 1.9878e-01, time/batch = 0.6896s	
6394/22950 (epoch 13.930), train_loss = 1.07455990, grad/param norm = 1.9658e-01, time/batch = 0.6926s	
6395/22950 (epoch 13.932), train_loss = 1.04095921, grad/param norm = 1.8001e-01, time/batch = 0.6898s	
6396/22950 (epoch 13.935), train_loss = 1.24798963, grad/param norm = 1.9108e-01, time/batch = 0.6860s	
6397/22950 (epoch 13.937), train_loss = 1.25464943, grad/param norm = 2.1210e-01, time/batch = 0.6903s	
6398/22950 (epoch 13.939), train_loss = 1.17430258, grad/param norm = 2.1013e-01, time/batch = 0.6893s	
6399/22950 (epoch 13.941), train_loss = 1.12816031, grad/param norm = 1.8959e-01, time/batch = 0.6889s	
6400/22950 (epoch 13.943), train_loss = 1.22511910, grad/param norm = 2.0881e-01, time/batch = 0.6882s	
6401/22950 (epoch 13.946), train_loss = 1.09005686, grad/param norm = 2.0761e-01, time/batch = 0.6951s	
6402/22950 (epoch 13.948), train_loss = 1.26769239, grad/param norm = 1.8811e-01, time/batch = 0.6894s	
6403/22950 (epoch 13.950), train_loss = 1.24260866, grad/param norm = 2.1438e-01, time/batch = 0.6844s	
6404/22950 (epoch 13.952), train_loss = 1.26793753, grad/param norm = 2.1948e-01, time/batch = 0.6899s	
6405/22950 (epoch 13.954), train_loss = 1.23832276, grad/param norm = 1.9295e-01, time/batch = 0.6900s	
6406/22950 (epoch 13.956), train_loss = 1.14664858, grad/param norm = 1.9094e-01, time/batch = 0.6918s	
6407/22950 (epoch 13.959), train_loss = 1.11278573, grad/param norm = 1.9252e-01, time/batch = 0.6883s	
6408/22950 (epoch 13.961), train_loss = 1.23368214, grad/param norm = 2.0107e-01, time/batch = 0.6879s	
6409/22950 (epoch 13.963), train_loss = 1.26781077, grad/param norm = 2.0822e-01, time/batch = 0.6888s	
6410/22950 (epoch 13.965), train_loss = 1.39151764, grad/param norm = 2.1196e-01, time/batch = 0.6865s	
6411/22950 (epoch 13.967), train_loss = 1.22252303, grad/param norm = 2.1676e-01, time/batch = 0.6891s	
6412/22950 (epoch 13.969), train_loss = 1.13477714, grad/param norm = 1.9423e-01, time/batch = 0.6893s	
6413/22950 (epoch 13.972), train_loss = 1.20938640, grad/param norm = 1.8768e-01, time/batch = 0.6909s	
6414/22950 (epoch 13.974), train_loss = 1.16524936, grad/param norm = 2.0105e-01, time/batch = 0.7132s	
6415/22950 (epoch 13.976), train_loss = 1.08954543, grad/param norm = 1.9445e-01, time/batch = 0.7271s	
6416/22950 (epoch 13.978), train_loss = 1.19127055, grad/param norm = 2.0619e-01, time/batch = 0.7438s	
6417/22950 (epoch 13.980), train_loss = 1.21735989, grad/param norm = 2.0213e-01, time/batch = 0.7241s	
6418/22950 (epoch 13.983), train_loss = 1.16376567, grad/param norm = 1.8739e-01, time/batch = 0.6959s	
6419/22950 (epoch 13.985), train_loss = 1.07562097, grad/param norm = 1.8865e-01, time/batch = 0.6988s	
6420/22950 (epoch 13.987), train_loss = 1.10488772, grad/param norm = 1.8868e-01, time/batch = 0.6919s	
6421/22950 (epoch 13.989), train_loss = 1.23304497, grad/param norm = 1.9575e-01, time/batch = 0.6930s	
6422/22950 (epoch 13.991), train_loss = 1.05114736, grad/param norm = 1.8649e-01, time/batch = 0.6905s	
6423/22950 (epoch 13.993), train_loss = 1.24193849, grad/param norm = 2.1315e-01, time/batch = 0.7095s	
6424/22950 (epoch 13.996), train_loss = 1.30523369, grad/param norm = 2.1530e-01, time/batch = 0.7121s	
6425/22950 (epoch 13.998), train_loss = 1.16160496, grad/param norm = 1.9526e-01, time/batch = 0.7061s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
6426/22950 (epoch 14.000), train_loss = 1.04997745, grad/param norm = 1.8159e-01, time/batch = 0.7071s	
6427/22950 (epoch 14.002), train_loss = 1.39618856, grad/param norm = 2.1030e-01, time/batch = 0.7113s	
6428/22950 (epoch 14.004), train_loss = 1.24036331, grad/param norm = 1.9559e-01, time/batch = 0.7071s	
6429/22950 (epoch 14.007), train_loss = 1.22245141, grad/param norm = 2.0979e-01, time/batch = 0.7018s	
6430/22950 (epoch 14.009), train_loss = 1.34765294, grad/param norm = 2.0934e-01, time/batch = 0.7005s	
6431/22950 (epoch 14.011), train_loss = 1.11863348, grad/param norm = 1.9697e-01, time/batch = 0.6917s	
6432/22950 (epoch 14.013), train_loss = 1.29942631, grad/param norm = 2.3269e-01, time/batch = 0.6928s	
6433/22950 (epoch 14.015), train_loss = 1.30824161, grad/param norm = 2.1925e-01, time/batch = 0.6902s	
6434/22950 (epoch 14.017), train_loss = 1.22311388, grad/param norm = 1.8662e-01, time/batch = 0.6913s	
6435/22950 (epoch 14.020), train_loss = 1.19877423, grad/param norm = 1.7279e-01, time/batch = 0.6908s	
6436/22950 (epoch 14.022), train_loss = 1.05509560, grad/param norm = 1.8667e-01, time/batch = 0.6929s	
6437/22950 (epoch 14.024), train_loss = 1.12588836, grad/param norm = 1.8856e-01, time/batch = 0.6939s	
6438/22950 (epoch 14.026), train_loss = 1.23578376, grad/param norm = 1.9460e-01, time/batch = 0.6917s	
6439/22950 (epoch 14.028), train_loss = 1.29112605, grad/param norm = 1.9462e-01, time/batch = 0.6918s	
6440/22950 (epoch 14.031), train_loss = 1.20705457, grad/param norm = 1.8727e-01, time/batch = 0.6920s	
6441/22950 (epoch 14.033), train_loss = 1.35528214, grad/param norm = 2.0742e-01, time/batch = 0.6914s	
6442/22950 (epoch 14.035), train_loss = 1.19021920, grad/param norm = 1.8294e-01, time/batch = 0.6899s	
6443/22950 (epoch 14.037), train_loss = 1.19881073, grad/param norm = 2.0729e-01, time/batch = 0.6919s	
6444/22950 (epoch 14.039), train_loss = 1.16328617, grad/param norm = 1.9339e-01, time/batch = 0.6949s	
6445/22950 (epoch 14.041), train_loss = 1.17641746, grad/param norm = 1.8613e-01, time/batch = 0.6953s	
6446/22950 (epoch 14.044), train_loss = 1.21530525, grad/param norm = 1.8501e-01, time/batch = 0.6921s	
6447/22950 (epoch 14.046), train_loss = 1.22689521, grad/param norm = 1.9278e-01, time/batch = 0.6937s	
6448/22950 (epoch 14.048), train_loss = 1.22481270, grad/param norm = 1.9117e-01, time/batch = 0.6883s	
6449/22950 (epoch 14.050), train_loss = 1.24828801, grad/param norm = 2.0615e-01, time/batch = 0.6917s	
6450/22950 (epoch 14.052), train_loss = 1.24705769, grad/param norm = 1.9184e-01, time/batch = 0.6904s	
6451/22950 (epoch 14.054), train_loss = 1.45375929, grad/param norm = 2.1548e-01, time/batch = 0.6898s	
6452/22950 (epoch 14.057), train_loss = 1.30715554, grad/param norm = 2.0261e-01, time/batch = 0.6900s	
6453/22950 (epoch 14.059), train_loss = 1.27947563, grad/param norm = 1.9559e-01, time/batch = 0.6914s	
6454/22950 (epoch 14.061), train_loss = 1.12818189, grad/param norm = 1.9363e-01, time/batch = 0.6891s	
6455/22950 (epoch 14.063), train_loss = 1.26840566, grad/param norm = 1.9304e-01, time/batch = 0.6893s	
6456/22950 (epoch 14.065), train_loss = 0.98479685, grad/param norm = 1.8612e-01, time/batch = 0.6914s	
6457/22950 (epoch 14.068), train_loss = 1.29383303, grad/param norm = 1.9625e-01, time/batch = 0.6913s	
6458/22950 (epoch 14.070), train_loss = 1.10181109, grad/param norm = 1.9189e-01, time/batch = 0.6878s	
6459/22950 (epoch 14.072), train_loss = 1.25683986, grad/param norm = 1.8747e-01, time/batch = 0.7082s	
6460/22950 (epoch 14.074), train_loss = 1.21231562, grad/param norm = 2.0211e-01, time/batch = 0.7203s	
6461/22950 (epoch 14.076), train_loss = 1.21826592, grad/param norm = 2.0981e-01, time/batch = 0.6938s	
6462/22950 (epoch 14.078), train_loss = 1.30485484, grad/param norm = 2.0148e-01, time/batch = 0.6923s	
6463/22950 (epoch 14.081), train_loss = 1.28974303, grad/param norm = 1.9737e-01, time/batch = 0.6935s	
6464/22950 (epoch 14.083), train_loss = 1.17489343, grad/param norm = 2.0600e-01, time/batch = 0.6905s	
6465/22950 (epoch 14.085), train_loss = 1.12009248, grad/param norm = 2.0478e-01, time/batch = 0.6952s	
6466/22950 (epoch 14.087), train_loss = 1.12258432, grad/param norm = 1.9985e-01, time/batch = 0.6919s	
6467/22950 (epoch 14.089), train_loss = 1.22421005, grad/param norm = 1.8950e-01, time/batch = 0.6889s	
6468/22950 (epoch 14.092), train_loss = 1.15311608, grad/param norm = 1.9702e-01, time/batch = 0.6979s	
6469/22950 (epoch 14.094), train_loss = 1.14939057, grad/param norm = 1.9082e-01, time/batch = 0.7164s	
6470/22950 (epoch 14.096), train_loss = 1.35926740, grad/param norm = 2.0148e-01, time/batch = 0.7131s	
6471/22950 (epoch 14.098), train_loss = 1.26767873, grad/param norm = 2.0186e-01, time/batch = 1.0203s	
6472/22950 (epoch 14.100), train_loss = 1.16088523, grad/param norm = 1.9478e-01, time/batch = 1.0192s	
6473/22950 (epoch 14.102), train_loss = 1.21343873, grad/param norm = 1.9056e-01, time/batch = 1.0016s	
6474/22950 (epoch 14.105), train_loss = 1.07417780, grad/param norm = 1.6643e-01, time/batch = 1.0146s	
6475/22950 (epoch 14.107), train_loss = 1.15636312, grad/param norm = 1.8319e-01, time/batch = 1.0980s	
6476/22950 (epoch 14.109), train_loss = 1.16147134, grad/param norm = 2.1104e-01, time/batch = 1.8906s	
6477/22950 (epoch 14.111), train_loss = 1.06699795, grad/param norm = 1.9213e-01, time/batch = 1.8887s	
6478/22950 (epoch 14.113), train_loss = 1.22692719, grad/param norm = 1.9110e-01, time/batch = 9.1990s	
6479/22950 (epoch 14.115), train_loss = 1.25274107, grad/param norm = 2.1499e-01, time/batch = 18.4451s	
6480/22950 (epoch 14.118), train_loss = 1.34244742, grad/param norm = 1.9463e-01, time/batch = 16.5290s	
6481/22950 (epoch 14.120), train_loss = 1.12425375, grad/param norm = 1.7924e-01, time/batch = 18.8564s	
6482/22950 (epoch 14.122), train_loss = 1.34305615, grad/param norm = 2.0656e-01, time/batch = 18.2987s	
6483/22950 (epoch 14.124), train_loss = 1.01116101, grad/param norm = 1.6022e-01, time/batch = 18.5478s	
6484/22950 (epoch 14.126), train_loss = 1.15975250, grad/param norm = 1.8713e-01, time/batch = 19.8686s	
6485/22950 (epoch 14.129), train_loss = 1.04053040, grad/param norm = 1.7552e-01, time/batch = 17.8062s	
6486/22950 (epoch 14.131), train_loss = 1.16458902, grad/param norm = 2.0050e-01, time/batch = 18.7092s	
6487/22950 (epoch 14.133), train_loss = 1.24876254, grad/param norm = 2.0073e-01, time/batch = 19.7894s	
6488/22950 (epoch 14.135), train_loss = 1.18089064, grad/param norm = 1.7753e-01, time/batch = 18.7652s	
6489/22950 (epoch 14.137), train_loss = 1.35404157, grad/param norm = 2.1623e-01, time/batch = 19.4567s	
6490/22950 (epoch 14.139), train_loss = 1.12015629, grad/param norm = 1.9828e-01, time/batch = 16.4317s	
6491/22950 (epoch 14.142), train_loss = 1.11833790, grad/param norm = 1.8840e-01, time/batch = 19.4555s	
6492/22950 (epoch 14.144), train_loss = 1.09244751, grad/param norm = 1.7909e-01, time/batch = 18.2734s	
6493/22950 (epoch 14.146), train_loss = 1.18482610, grad/param norm = 2.0476e-01, time/batch = 19.6168s	
6494/22950 (epoch 14.148), train_loss = 1.15315690, grad/param norm = 1.9491e-01, time/batch = 17.1905s	
6495/22950 (epoch 14.150), train_loss = 1.21704272, grad/param norm = 2.0332e-01, time/batch = 17.4035s	
6496/22950 (epoch 14.153), train_loss = 1.15593886, grad/param norm = 1.9633e-01, time/batch = 19.5481s	
6497/22950 (epoch 14.155), train_loss = 1.13017446, grad/param norm = 1.7966e-01, time/batch = 18.8762s	
6498/22950 (epoch 14.157), train_loss = 1.12971516, grad/param norm = 2.0009e-01, time/batch = 18.4482s	
6499/22950 (epoch 14.159), train_loss = 1.09619175, grad/param norm = 1.7286e-01, time/batch = 19.2633s	
6500/22950 (epoch 14.161), train_loss = 1.15063970, grad/param norm = 1.7636e-01, time/batch = 18.4686s	
6501/22950 (epoch 14.163), train_loss = 1.08141169, grad/param norm = 1.7365e-01, time/batch = 18.1178s	
6502/22950 (epoch 14.166), train_loss = 1.37395189, grad/param norm = 2.3713e-01, time/batch = 17.9695s	
6503/22950 (epoch 14.168), train_loss = 1.31916603, grad/param norm = 2.0764e-01, time/batch = 18.8976s	
6504/22950 (epoch 14.170), train_loss = 1.22686128, grad/param norm = 2.0620e-01, time/batch = 18.6354s	
6505/22950 (epoch 14.172), train_loss = 1.20957400, grad/param norm = 1.8669e-01, time/batch = 19.3007s	
6506/22950 (epoch 14.174), train_loss = 1.29688058, grad/param norm = 2.2763e-01, time/batch = 18.7139s	
6507/22950 (epoch 14.176), train_loss = 1.33082841, grad/param norm = 1.9704e-01, time/batch = 17.5352s	
6508/22950 (epoch 14.179), train_loss = 1.26003328, grad/param norm = 1.9910e-01, time/batch = 18.7639s	
6509/22950 (epoch 14.181), train_loss = 1.43471156, grad/param norm = 2.1632e-01, time/batch = 15.6994s	
6510/22950 (epoch 14.183), train_loss = 1.30609101, grad/param norm = 2.1023e-01, time/batch = 17.8582s	
6511/22950 (epoch 14.185), train_loss = 1.27040037, grad/param norm = 2.0126e-01, time/batch = 18.5952s	
6512/22950 (epoch 14.187), train_loss = 1.10115062, grad/param norm = 1.9978e-01, time/batch = 19.6354s	
6513/22950 (epoch 14.190), train_loss = 1.07726126, grad/param norm = 2.1827e-01, time/batch = 18.4649s	
6514/22950 (epoch 14.192), train_loss = 1.07867061, grad/param norm = 1.8287e-01, time/batch = 17.7985s	
6515/22950 (epoch 14.194), train_loss = 1.14223052, grad/param norm = 2.1287e-01, time/batch = 19.8634s	
6516/22950 (epoch 14.196), train_loss = 1.02714502, grad/param norm = 1.8750e-01, time/batch = 18.4619s	
6517/22950 (epoch 14.198), train_loss = 1.29612845, grad/param norm = 2.1079e-01, time/batch = 18.5509s	
6518/22950 (epoch 14.200), train_loss = 1.08888222, grad/param norm = 1.8821e-01, time/batch = 20.5302s	
6519/22950 (epoch 14.203), train_loss = 1.06374367, grad/param norm = 1.8574e-01, time/batch = 18.4557s	
6520/22950 (epoch 14.205), train_loss = 1.12210430, grad/param norm = 1.7037e-01, time/batch = 18.5459s	
6521/22950 (epoch 14.207), train_loss = 1.17811539, grad/param norm = 1.9563e-01, time/batch = 18.1957s	
6522/22950 (epoch 14.209), train_loss = 1.25545841, grad/param norm = 2.7545e-01, time/batch = 19.9436s	
6523/22950 (epoch 14.211), train_loss = 1.02640182, grad/param norm = 2.1753e-01, time/batch = 20.0392s	
6524/22950 (epoch 14.214), train_loss = 1.18867212, grad/param norm = 1.8618e-01, time/batch = 34.4079s	
6525/22950 (epoch 14.216), train_loss = 1.28710139, grad/param norm = 2.0082e-01, time/batch = 18.1883s	
6526/22950 (epoch 14.218), train_loss = 1.20122727, grad/param norm = 1.9752e-01, time/batch = 15.9954s	
6527/22950 (epoch 14.220), train_loss = 1.33387772, grad/param norm = 2.3424e-01, time/batch = 19.6283s	
6528/22950 (epoch 14.222), train_loss = 1.32793987, grad/param norm = 2.2787e-01, time/batch = 19.2053s	
6529/22950 (epoch 14.224), train_loss = 1.17309028, grad/param norm = 1.9841e-01, time/batch = 18.6895s	
6530/22950 (epoch 14.227), train_loss = 1.25974967, grad/param norm = 1.9373e-01, time/batch = 18.4676s	
6531/22950 (epoch 14.229), train_loss = 1.26896830, grad/param norm = 2.0451e-01, time/batch = 20.3672s	
6532/22950 (epoch 14.231), train_loss = 1.06172786, grad/param norm = 1.8587e-01, time/batch = 19.0401s	
6533/22950 (epoch 14.233), train_loss = 1.13736375, grad/param norm = 1.8901e-01, time/batch = 17.4418s	
6534/22950 (epoch 14.235), train_loss = 1.34034294, grad/param norm = 2.1814e-01, time/batch = 19.8704s	
6535/22950 (epoch 14.237), train_loss = 1.09620497, grad/param norm = 1.8207e-01, time/batch = 17.1995s	
6536/22950 (epoch 14.240), train_loss = 1.17608814, grad/param norm = 2.0527e-01, time/batch = 17.4519s	
6537/22950 (epoch 14.242), train_loss = 1.28968468, grad/param norm = 1.8620e-01, time/batch = 18.5479s	
6538/22950 (epoch 14.244), train_loss = 1.39044614, grad/param norm = 2.2564e-01, time/batch = 20.0367s	
6539/22950 (epoch 14.246), train_loss = 1.33107943, grad/param norm = 1.9944e-01, time/batch = 17.2854s	
6540/22950 (epoch 14.248), train_loss = 1.24262049, grad/param norm = 2.2090e-01, time/batch = 18.9602s	
6541/22950 (epoch 14.251), train_loss = 1.12949812, grad/param norm = 1.9147e-01, time/batch = 19.2163s	
6542/22950 (epoch 14.253), train_loss = 1.14785353, grad/param norm = 2.1387e-01, time/batch = 17.7674s	
6543/22950 (epoch 14.255), train_loss = 1.20189671, grad/param norm = 2.0481e-01, time/batch = 19.3735s	
6544/22950 (epoch 14.257), train_loss = 1.32450359, grad/param norm = 2.0658e-01, time/batch = 19.1454s	
6545/22950 (epoch 14.259), train_loss = 1.06398607, grad/param norm = 2.0369e-01, time/batch = 18.8722s	
6546/22950 (epoch 14.261), train_loss = 1.16604194, grad/param norm = 2.1158e-01, time/batch = 17.6755s	
6547/22950 (epoch 14.264), train_loss = 1.09800274, grad/param norm = 1.8430e-01, time/batch = 18.8755s	
6548/22950 (epoch 14.266), train_loss = 1.24639469, grad/param norm = 2.1410e-01, time/batch = 19.2037s	
6549/22950 (epoch 14.268), train_loss = 1.24598223, grad/param norm = 2.1229e-01, time/batch = 16.5277s	
6550/22950 (epoch 14.270), train_loss = 1.23568645, grad/param norm = 2.0265e-01, time/batch = 18.2864s	
6551/22950 (epoch 14.272), train_loss = 1.32751326, grad/param norm = 2.1063e-01, time/batch = 18.2146s	
6552/22950 (epoch 14.275), train_loss = 1.13761404, grad/param norm = 1.8684e-01, time/batch = 17.9602s	
6553/22950 (epoch 14.277), train_loss = 1.02972408, grad/param norm = 1.6528e-01, time/batch = 18.7977s	
6554/22950 (epoch 14.279), train_loss = 1.18324110, grad/param norm = 2.1555e-01, time/batch = 18.0704s	
6555/22950 (epoch 14.281), train_loss = 1.12547793, grad/param norm = 1.8945e-01, time/batch = 18.0299s	
6556/22950 (epoch 14.283), train_loss = 1.01410511, grad/param norm = 1.6901e-01, time/batch = 18.4613s	
6557/22950 (epoch 14.285), train_loss = 1.19260528, grad/param norm = 1.7978e-01, time/batch = 18.8764s	
6558/22950 (epoch 14.288), train_loss = 1.21577718, grad/param norm = 1.7550e-01, time/batch = 17.1132s	
6559/22950 (epoch 14.290), train_loss = 1.11811407, grad/param norm = 1.8095e-01, time/batch = 18.2823s	
6560/22950 (epoch 14.292), train_loss = 1.26777005, grad/param norm = 1.9197e-01, time/batch = 16.9848s	
6561/22950 (epoch 14.294), train_loss = 1.17906171, grad/param norm = 1.8444e-01, time/batch = 19.4617s	
6562/22950 (epoch 14.296), train_loss = 0.96511682, grad/param norm = 1.5604e-01, time/batch = 18.7958s	
6563/22950 (epoch 14.298), train_loss = 1.19355038, grad/param norm = 1.8219e-01, time/batch = 18.3645s	
6564/22950 (epoch 14.301), train_loss = 1.21867673, grad/param norm = 1.9915e-01, time/batch = 19.3001s	
6565/22950 (epoch 14.303), train_loss = 1.24279020, grad/param norm = 1.9882e-01, time/batch = 17.0530s	
6566/22950 (epoch 14.305), train_loss = 1.23499297, grad/param norm = 1.9678e-01, time/batch = 19.3655s	
6567/22950 (epoch 14.307), train_loss = 1.32564847, grad/param norm = 2.1189e-01, time/batch = 16.1391s	
6568/22950 (epoch 14.309), train_loss = 1.13928821, grad/param norm = 1.7097e-01, time/batch = 17.1225s	
6569/22950 (epoch 14.312), train_loss = 1.18818826, grad/param norm = 1.9744e-01, time/batch = 17.2020s	
6570/22950 (epoch 14.314), train_loss = 1.14355143, grad/param norm = 1.8522e-01, time/batch = 16.1880s	
6571/22950 (epoch 14.316), train_loss = 1.19647781, grad/param norm = 1.9996e-01, time/batch = 18.5379s	
6572/22950 (epoch 14.318), train_loss = 0.99835588, grad/param norm = 1.7459e-01, time/batch = 17.6203s	
6573/22950 (epoch 14.320), train_loss = 1.14046754, grad/param norm = 1.7014e-01, time/batch = 19.1329s	
6574/22950 (epoch 14.322), train_loss = 1.16925002, grad/param norm = 1.9788e-01, time/batch = 18.0379s	
6575/22950 (epoch 14.325), train_loss = 0.93352963, grad/param norm = 1.6844e-01, time/batch = 17.2005s	
6576/22950 (epoch 14.327), train_loss = 0.97929654, grad/param norm = 1.8145e-01, time/batch = 18.2023s	
6577/22950 (epoch 14.329), train_loss = 1.11679730, grad/param norm = 1.8967e-01, time/batch = 18.1315s	
6578/22950 (epoch 14.331), train_loss = 1.04026435, grad/param norm = 1.9154e-01, time/batch = 18.2928s	
6579/22950 (epoch 14.333), train_loss = 1.15789020, grad/param norm = 1.9501e-01, time/batch = 19.0359s	
6580/22950 (epoch 14.336), train_loss = 1.14898527, grad/param norm = 1.9617e-01, time/batch = 19.4695s	
6581/22950 (epoch 14.338), train_loss = 1.12120611, grad/param norm = 1.8401e-01, time/batch = 18.8808s	
6582/22950 (epoch 14.340), train_loss = 1.17891251, grad/param norm = 2.1020e-01, time/batch = 16.1018s	
6583/22950 (epoch 14.342), train_loss = 1.29021866, grad/param norm = 1.9912e-01, time/batch = 17.8891s	
6584/22950 (epoch 14.344), train_loss = 1.17960930, grad/param norm = 2.0129e-01, time/batch = 19.2173s	
6585/22950 (epoch 14.346), train_loss = 1.33997621, grad/param norm = 2.1623e-01, time/batch = 18.1899s	
6586/22950 (epoch 14.349), train_loss = 1.19423925, grad/param norm = 2.1901e-01, time/batch = 19.9611s	
6587/22950 (epoch 14.351), train_loss = 1.22683533, grad/param norm = 1.9076e-01, time/batch = 18.9677s	
6588/22950 (epoch 14.353), train_loss = 1.29436628, grad/param norm = 2.2619e-01, time/batch = 17.4505s	
6589/22950 (epoch 14.355), train_loss = 1.30331139, grad/param norm = 1.9879e-01, time/batch = 18.4640s	
6590/22950 (epoch 14.357), train_loss = 1.19102501, grad/param norm = 1.9897e-01, time/batch = 17.5590s	
6591/22950 (epoch 14.359), train_loss = 1.22076482, grad/param norm = 2.1929e-01, time/batch = 15.9867s	
6592/22950 (epoch 14.362), train_loss = 1.18832785, grad/param norm = 2.1416e-01, time/batch = 16.7330s	
6593/22950 (epoch 14.364), train_loss = 1.17973657, grad/param norm = 1.9436e-01, time/batch = 18.6299s	
6594/22950 (epoch 14.366), train_loss = 1.05954386, grad/param norm = 1.7785e-01, time/batch = 18.5310s	
6595/22950 (epoch 14.368), train_loss = 1.22466264, grad/param norm = 2.0602e-01, time/batch = 16.3459s	
6596/22950 (epoch 14.370), train_loss = 1.16822958, grad/param norm = 2.0574e-01, time/batch = 18.2967s	
6597/22950 (epoch 14.373), train_loss = 1.05838985, grad/param norm = 2.0151e-01, time/batch = 17.4513s	
6598/22950 (epoch 14.375), train_loss = 1.30467536, grad/param norm = 2.1074e-01, time/batch = 18.4495s	
6599/22950 (epoch 14.377), train_loss = 1.10895437, grad/param norm = 1.9199e-01, time/batch = 17.5294s	
6600/22950 (epoch 14.379), train_loss = 1.22889950, grad/param norm = 2.0819e-01, time/batch = 18.7123s	
6601/22950 (epoch 14.381), train_loss = 1.01984276, grad/param norm = 1.8419e-01, time/batch = 18.6273s	
6602/22950 (epoch 14.383), train_loss = 1.22550527, grad/param norm = 2.0945e-01, time/batch = 19.2046s	
6603/22950 (epoch 14.386), train_loss = 1.13139055, grad/param norm = 2.2318e-01, time/batch = 19.9535s	
6604/22950 (epoch 14.388), train_loss = 1.19883297, grad/param norm = 2.1826e-01, time/batch = 18.9488s	
6605/22950 (epoch 14.390), train_loss = 1.09144627, grad/param norm = 1.8477e-01, time/batch = 18.0321s	
6606/22950 (epoch 14.392), train_loss = 1.09368620, grad/param norm = 1.9254e-01, time/batch = 19.1360s	
6607/22950 (epoch 14.394), train_loss = 1.11005217, grad/param norm = 1.7454e-01, time/batch = 17.3610s	
6608/22950 (epoch 14.397), train_loss = 1.32173848, grad/param norm = 2.1087e-01, time/batch = 16.8570s	
6609/22950 (epoch 14.399), train_loss = 1.29719133, grad/param norm = 2.2145e-01, time/batch = 17.1938s	
6610/22950 (epoch 14.401), train_loss = 1.43918453, grad/param norm = 2.1275e-01, time/batch = 19.9490s	
6611/22950 (epoch 14.403), train_loss = 1.16135791, grad/param norm = 2.0470e-01, time/batch = 17.7904s	
6612/22950 (epoch 14.405), train_loss = 1.29967411, grad/param norm = 2.1934e-01, time/batch = 19.7123s	
6613/22950 (epoch 14.407), train_loss = 1.36302950, grad/param norm = 2.0430e-01, time/batch = 19.6987s	
6614/22950 (epoch 14.410), train_loss = 1.09273999, grad/param norm = 1.8161e-01, time/batch = 19.1932s	
6615/22950 (epoch 14.412), train_loss = 1.21067696, grad/param norm = 2.2592e-01, time/batch = 19.2073s	
6616/22950 (epoch 14.414), train_loss = 1.29870803, grad/param norm = 2.3172e-01, time/batch = 19.1220s	
6617/22950 (epoch 14.416), train_loss = 1.24094401, grad/param norm = 2.2812e-01, time/batch = 18.7907s	
6618/22950 (epoch 14.418), train_loss = 1.23907697, grad/param norm = 2.0224e-01, time/batch = 18.7978s	
6619/22950 (epoch 14.420), train_loss = 1.25146959, grad/param norm = 2.1231e-01, time/batch = 19.1146s	
6620/22950 (epoch 14.423), train_loss = 1.10916641, grad/param norm = 1.8341e-01, time/batch = 19.1062s	
6621/22950 (epoch 14.425), train_loss = 1.20210852, grad/param norm = 2.0276e-01, time/batch = 18.2937s	
6622/22950 (epoch 14.427), train_loss = 1.17946637, grad/param norm = 2.0579e-01, time/batch = 19.0390s	
6623/22950 (epoch 14.429), train_loss = 1.17828383, grad/param norm = 2.0590e-01, time/batch = 17.9607s	
6624/22950 (epoch 14.431), train_loss = 1.24105904, grad/param norm = 2.1234e-01, time/batch = 19.1096s	
6625/22950 (epoch 14.434), train_loss = 1.20144613, grad/param norm = 2.0413e-01, time/batch = 18.0417s	
6626/22950 (epoch 14.436), train_loss = 1.39083568, grad/param norm = 2.3056e-01, time/batch = 18.4704s	
6627/22950 (epoch 14.438), train_loss = 1.20244357, grad/param norm = 1.9546e-01, time/batch = 16.5599s	
6628/22950 (epoch 14.440), train_loss = 1.29787961, grad/param norm = 2.0130e-01, time/batch = 17.2899s	
6629/22950 (epoch 14.442), train_loss = 1.34839633, grad/param norm = 2.0578e-01, time/batch = 18.8673s	
6630/22950 (epoch 14.444), train_loss = 1.27928888, grad/param norm = 1.9880e-01, time/batch = 17.9643s	
6631/22950 (epoch 14.447), train_loss = 1.40230488, grad/param norm = 2.2011e-01, time/batch = 19.9509s	
6632/22950 (epoch 14.449), train_loss = 1.08386304, grad/param norm = 1.7749e-01, time/batch = 18.5111s	
6633/22950 (epoch 14.451), train_loss = 1.22619375, grad/param norm = 1.8913e-01, time/batch = 18.2088s	
6634/22950 (epoch 14.453), train_loss = 1.24590790, grad/param norm = 1.9238e-01, time/batch = 19.5476s	
6635/22950 (epoch 14.455), train_loss = 1.08798899, grad/param norm = 1.7811e-01, time/batch = 17.3922s	
6636/22950 (epoch 14.458), train_loss = 1.33757444, grad/param norm = 2.0328e-01, time/batch = 19.8739s	
6637/22950 (epoch 14.460), train_loss = 1.22967311, grad/param norm = 2.1098e-01, time/batch = 19.5225s	
6638/22950 (epoch 14.462), train_loss = 1.19412692, grad/param norm = 1.7899e-01, time/batch = 19.4678s	
6639/22950 (epoch 14.464), train_loss = 1.17139794, grad/param norm = 1.9159e-01, time/batch = 16.7850s	
6640/22950 (epoch 14.466), train_loss = 1.22939205, grad/param norm = 2.0256e-01, time/batch = 16.9469s	
6641/22950 (epoch 14.468), train_loss = 1.33284063, grad/param norm = 2.0553e-01, time/batch = 18.8753s	
6642/22950 (epoch 14.471), train_loss = 1.22398309, grad/param norm = 1.9914e-01, time/batch = 19.6222s	
6643/22950 (epoch 14.473), train_loss = 1.26841105, grad/param norm = 2.1093e-01, time/batch = 16.0078s	
6644/22950 (epoch 14.475), train_loss = 1.42931998, grad/param norm = 2.1259e-01, time/batch = 20.2076s	
6645/22950 (epoch 14.477), train_loss = 1.19034244, grad/param norm = 1.9520e-01, time/batch = 18.9836s	
6646/22950 (epoch 14.479), train_loss = 1.12625280, grad/param norm = 2.0039e-01, time/batch = 18.4471s	
6647/22950 (epoch 14.481), train_loss = 1.33019096, grad/param norm = 2.1565e-01, time/batch = 20.3744s	
6648/22950 (epoch 14.484), train_loss = 1.23784339, grad/param norm = 1.9782e-01, time/batch = 17.6207s	
6649/22950 (epoch 14.486), train_loss = 1.06472248, grad/param norm = 1.8362e-01, time/batch = 19.0409s	
6650/22950 (epoch 14.488), train_loss = 1.18077158, grad/param norm = 2.0860e-01, time/batch = 19.3745s	
6651/22950 (epoch 14.490), train_loss = 1.03364149, grad/param norm = 2.1198e-01, time/batch = 19.3749s	
6652/22950 (epoch 14.492), train_loss = 1.17309697, grad/param norm = 1.9038e-01, time/batch = 17.4669s	
6653/22950 (epoch 14.495), train_loss = 1.18333267, grad/param norm = 1.9917e-01, time/batch = 16.3395s	
6654/22950 (epoch 14.497), train_loss = 1.28054411, grad/param norm = 1.9996e-01, time/batch = 19.4616s	
6655/22950 (epoch 14.499), train_loss = 1.32592883, grad/param norm = 2.0646e-01, time/batch = 18.9481s	
6656/22950 (epoch 14.501), train_loss = 1.25981389, grad/param norm = 2.0463e-01, time/batch = 17.2529s	
6657/22950 (epoch 14.503), train_loss = 1.29909619, grad/param norm = 1.9861e-01, time/batch = 19.7121s	
6658/22950 (epoch 14.505), train_loss = 1.06669256, grad/param norm = 1.7177e-01, time/batch = 20.1122s	
6659/22950 (epoch 14.508), train_loss = 1.26165917, grad/param norm = 1.9613e-01, time/batch = 18.7068s	
6660/22950 (epoch 14.510), train_loss = 1.22009912, grad/param norm = 2.0132e-01, time/batch = 18.1287s	
6661/22950 (epoch 14.512), train_loss = 1.11633657, grad/param norm = 1.8142e-01, time/batch = 15.5436s	
6662/22950 (epoch 14.514), train_loss = 1.08715110, grad/param norm = 1.7352e-01, time/batch = 18.7816s	
6663/22950 (epoch 14.516), train_loss = 1.17369742, grad/param norm = 2.0022e-01, time/batch = 19.2999s	
6664/22950 (epoch 14.519), train_loss = 1.16127771, grad/param norm = 1.8388e-01, time/batch = 19.5389s	
6665/22950 (epoch 14.521), train_loss = 1.20687747, grad/param norm = 1.8533e-01, time/batch = 19.1289s	
6666/22950 (epoch 14.523), train_loss = 0.97810856, grad/param norm = 1.8159e-01, time/batch = 19.3047s	
6667/22950 (epoch 14.525), train_loss = 1.08469228, grad/param norm = 1.9279e-01, time/batch = 18.8698s	
6668/22950 (epoch 14.527), train_loss = 1.03456668, grad/param norm = 1.9384e-01, time/batch = 19.9658s	
6669/22950 (epoch 14.529), train_loss = 1.23411519, grad/param norm = 2.1490e-01, time/batch = 18.6630s	
6670/22950 (epoch 14.532), train_loss = 1.13290954, grad/param norm = 1.8512e-01, time/batch = 18.0609s	
6671/22950 (epoch 14.534), train_loss = 1.28260205, grad/param norm = 2.1649e-01, time/batch = 18.1996s	
6672/22950 (epoch 14.536), train_loss = 1.26567655, grad/param norm = 2.2174e-01, time/batch = 16.8597s	
6673/22950 (epoch 14.538), train_loss = 1.17513676, grad/param norm = 2.1972e-01, time/batch = 16.3617s	
6674/22950 (epoch 14.540), train_loss = 1.22106264, grad/param norm = 1.8289e-01, time/batch = 18.3720s	
6675/22950 (epoch 14.542), train_loss = 1.36958246, grad/param norm = 1.9945e-01, time/batch = 19.1228s	
6676/22950 (epoch 14.545), train_loss = 1.16999888, grad/param norm = 1.9594e-01, time/batch = 19.3766s	
6677/22950 (epoch 14.547), train_loss = 1.18276023, grad/param norm = 1.9197e-01, time/batch = 18.0021s	
6678/22950 (epoch 14.549), train_loss = 1.16764452, grad/param norm = 1.9884e-01, time/batch = 19.2874s	
6679/22950 (epoch 14.551), train_loss = 1.20137943, grad/param norm = 2.0906e-01, time/batch = 18.5403s	
6680/22950 (epoch 14.553), train_loss = 1.17044964, grad/param norm = 2.2265e-01, time/batch = 18.4734s	
6681/22950 (epoch 14.556), train_loss = 1.24832874, grad/param norm = 1.8798e-01, time/batch = 16.8051s	
6682/22950 (epoch 14.558), train_loss = 1.10594792, grad/param norm = 1.8841e-01, time/batch = 19.0203s	
6683/22950 (epoch 14.560), train_loss = 1.21593582, grad/param norm = 1.9646e-01, time/batch = 20.1205s	
6684/22950 (epoch 14.562), train_loss = 1.08484502, grad/param norm = 1.8330e-01, time/batch = 19.6270s	
6685/22950 (epoch 14.564), train_loss = 1.34524649, grad/param norm = 2.3796e-01, time/batch = 17.1368s	
6686/22950 (epoch 14.566), train_loss = 1.23772669, grad/param norm = 2.0731e-01, time/batch = 17.9623s	
6687/22950 (epoch 14.569), train_loss = 1.30918726, grad/param norm = 2.0892e-01, time/batch = 16.2631s	
6688/22950 (epoch 14.571), train_loss = 1.10649927, grad/param norm = 2.0402e-01, time/batch = 15.9828s	
6689/22950 (epoch 14.573), train_loss = 1.21375417, grad/param norm = 2.0480e-01, time/batch = 19.3681s	
6690/22950 (epoch 14.575), train_loss = 1.37174805, grad/param norm = 2.2233e-01, time/batch = 17.7887s	
6691/22950 (epoch 14.577), train_loss = 1.19556075, grad/param norm = 2.1173e-01, time/batch = 19.5423s	
6692/22950 (epoch 14.580), train_loss = 1.24379811, grad/param norm = 2.0565e-01, time/batch = 19.1104s	
6693/22950 (epoch 14.582), train_loss = 1.40356867, grad/param norm = 2.1120e-01, time/batch = 19.5354s	
6694/22950 (epoch 14.584), train_loss = 1.09399653, grad/param norm = 1.9677e-01, time/batch = 19.6301s	
6695/22950 (epoch 14.586), train_loss = 1.17084525, grad/param norm = 2.1870e-01, time/batch = 16.3519s	
6696/22950 (epoch 14.588), train_loss = 1.31684926, grad/param norm = 2.0401e-01, time/batch = 18.4369s	
6697/22950 (epoch 14.590), train_loss = 1.18844660, grad/param norm = 1.9678e-01, time/batch = 20.3569s	
6698/22950 (epoch 14.593), train_loss = 1.10325084, grad/param norm = 2.0046e-01, time/batch = 17.1323s	
6699/22950 (epoch 14.595), train_loss = 1.07202681, grad/param norm = 1.9581e-01, time/batch = 19.4626s	
6700/22950 (epoch 14.597), train_loss = 1.26482625, grad/param norm = 2.0786e-01, time/batch = 19.8746s	
6701/22950 (epoch 14.599), train_loss = 1.23534188, grad/param norm = 2.2130e-01, time/batch = 17.6138s	
6702/22950 (epoch 14.601), train_loss = 1.21190323, grad/param norm = 2.1146e-01, time/batch = 18.6289s	
6703/22950 (epoch 14.603), train_loss = 1.33959027, grad/param norm = 2.0074e-01, time/batch = 18.7915s	
6704/22950 (epoch 14.606), train_loss = 1.17851310, grad/param norm = 2.0345e-01, time/batch = 17.5297s	
6705/22950 (epoch 14.608), train_loss = 1.23246078, grad/param norm = 2.0243e-01, time/batch = 19.8558s	
6706/22950 (epoch 14.610), train_loss = 1.16680647, grad/param norm = 1.9192e-01, time/batch = 18.2036s	
6707/22950 (epoch 14.612), train_loss = 1.19446956, grad/param norm = 2.0325e-01, time/batch = 18.7836s	
6708/22950 (epoch 14.614), train_loss = 1.33445058, grad/param norm = 2.1785e-01, time/batch = 19.6071s	
6709/22950 (epoch 14.617), train_loss = 1.18568623, grad/param norm = 1.9509e-01, time/batch = 18.5499s	
6710/22950 (epoch 14.619), train_loss = 1.11391726, grad/param norm = 1.7453e-01, time/batch = 20.1212s	
6711/22950 (epoch 14.621), train_loss = 1.28781437, grad/param norm = 1.7848e-01, time/batch = 18.8007s	
6712/22950 (epoch 14.623), train_loss = 1.26380585, grad/param norm = 1.8235e-01, time/batch = 18.0400s	
6713/22950 (epoch 14.625), train_loss = 1.18803644, grad/param norm = 1.8964e-01, time/batch = 17.9496s	
6714/22950 (epoch 14.627), train_loss = 1.19184721, grad/param norm = 1.9474e-01, time/batch = 17.5257s	
6715/22950 (epoch 14.630), train_loss = 1.05943223, grad/param norm = 1.9760e-01, time/batch = 20.3839s	
6716/22950 (epoch 14.632), train_loss = 1.20944541, grad/param norm = 2.0721e-01, time/batch = 17.2708s	
6717/22950 (epoch 14.634), train_loss = 1.18215066, grad/param norm = 1.8965e-01, time/batch = 26.7687s	
6718/22950 (epoch 14.636), train_loss = 1.24546233, grad/param norm = 2.1328e-01, time/batch = 23.6524s	
6719/22950 (epoch 14.638), train_loss = 1.11582614, grad/param norm = 2.0233e-01, time/batch = 16.8785s	
6720/22950 (epoch 14.641), train_loss = 1.15369725, grad/param norm = 1.8722e-01, time/batch = 16.7993s	
6721/22950 (epoch 14.643), train_loss = 1.23958360, grad/param norm = 2.2473e-01, time/batch = 18.2768s	
6722/22950 (epoch 14.645), train_loss = 1.12737523, grad/param norm = 1.9320e-01, time/batch = 19.1342s	
6723/22950 (epoch 14.647), train_loss = 1.19056789, grad/param norm = 2.0339e-01, time/batch = 18.1170s	
6724/22950 (epoch 14.649), train_loss = 1.19618710, grad/param norm = 1.9090e-01, time/batch = 19.7255s	
6725/22950 (epoch 14.651), train_loss = 1.29294999, grad/param norm = 2.2541e-01, time/batch = 18.3967s	
6726/22950 (epoch 14.654), train_loss = 1.01589487, grad/param norm = 1.8531e-01, time/batch = 18.2136s	
6727/22950 (epoch 14.656), train_loss = 1.34294590, grad/param norm = 2.3290e-01, time/batch = 18.9516s	
6728/22950 (epoch 14.658), train_loss = 1.11370510, grad/param norm = 2.0062e-01, time/batch = 19.4646s	
6729/22950 (epoch 14.660), train_loss = 1.02771753, grad/param norm = 1.9118e-01, time/batch = 15.7591s	
6730/22950 (epoch 14.662), train_loss = 1.02495126, grad/param norm = 1.6921e-01, time/batch = 15.2249s	
6731/22950 (epoch 14.664), train_loss = 1.19883616, grad/param norm = 1.9804e-01, time/batch = 15.0012s	
6732/22950 (epoch 14.667), train_loss = 1.21406552, grad/param norm = 1.9616e-01, time/batch = 16.8842s	
6733/22950 (epoch 14.669), train_loss = 1.16037759, grad/param norm = 1.9421e-01, time/batch = 17.6148s	
6734/22950 (epoch 14.671), train_loss = 1.21365195, grad/param norm = 2.0610e-01, time/batch = 19.3773s	
6735/22950 (epoch 14.673), train_loss = 1.14378396, grad/param norm = 1.9007e-01, time/batch = 17.5552s	
6736/22950 (epoch 14.675), train_loss = 1.18046532, grad/param norm = 2.0823e-01, time/batch = 17.1995s	
6737/22950 (epoch 14.678), train_loss = 1.19628253, grad/param norm = 2.0701e-01, time/batch = 17.3692s	
6738/22950 (epoch 14.680), train_loss = 1.20095828, grad/param norm = 1.8556e-01, time/batch = 19.2986s	
6739/22950 (epoch 14.682), train_loss = 1.26060091, grad/param norm = 2.1736e-01, time/batch = 19.2046s	
6740/22950 (epoch 14.684), train_loss = 1.31429339, grad/param norm = 2.4176e-01, time/batch = 17.7844s	
6741/22950 (epoch 14.686), train_loss = 1.28724273, grad/param norm = 2.1956e-01, time/batch = 18.3643s	
6742/22950 (epoch 14.688), train_loss = 1.19844850, grad/param norm = 2.0876e-01, time/batch = 19.4667s	
6743/22950 (epoch 14.691), train_loss = 1.19744165, grad/param norm = 1.9762e-01, time/batch = 17.6376s	
6744/22950 (epoch 14.693), train_loss = 1.10666324, grad/param norm = 1.9226e-01, time/batch = 18.7025s	
6745/22950 (epoch 14.695), train_loss = 1.33309766, grad/param norm = 2.0410e-01, time/batch = 18.4740s	
6746/22950 (epoch 14.697), train_loss = 1.29572307, grad/param norm = 2.1115e-01, time/batch = 17.7001s	
6747/22950 (epoch 14.699), train_loss = 1.27643544, grad/param norm = 2.0249e-01, time/batch = 17.2839s	
6748/22950 (epoch 14.702), train_loss = 1.26554894, grad/param norm = 2.0013e-01, time/batch = 17.8615s	
6749/22950 (epoch 14.704), train_loss = 1.27077459, grad/param norm = 1.9298e-01, time/batch = 19.2998s	
6750/22950 (epoch 14.706), train_loss = 1.27982365, grad/param norm = 2.1692e-01, time/batch = 18.1227s	
6751/22950 (epoch 14.708), train_loss = 1.09953462, grad/param norm = 1.8673e-01, time/batch = 17.5591s	
6752/22950 (epoch 14.710), train_loss = 1.24988262, grad/param norm = 1.9225e-01, time/batch = 17.3795s	
6753/22950 (epoch 14.712), train_loss = 1.32065220, grad/param norm = 2.0381e-01, time/batch = 17.5427s	
6754/22950 (epoch 14.715), train_loss = 1.27423587, grad/param norm = 2.2258e-01, time/batch = 18.8002s	
6755/22950 (epoch 14.717), train_loss = 1.14889600, grad/param norm = 1.8358e-01, time/batch = 19.4575s	
6756/22950 (epoch 14.719), train_loss = 1.17348588, grad/param norm = 2.2099e-01, time/batch = 17.7828s	
6757/22950 (epoch 14.721), train_loss = 1.24533044, grad/param norm = 1.9149e-01, time/batch = 15.5292s	
6758/22950 (epoch 14.723), train_loss = 1.12509996, grad/param norm = 1.8476e-01, time/batch = 19.0602s	
6759/22950 (epoch 14.725), train_loss = 1.26447111, grad/param norm = 2.0479e-01, time/batch = 18.1226s	
6760/22950 (epoch 14.728), train_loss = 1.19160105, grad/param norm = 2.3090e-01, time/batch = 18.8784s	
6761/22950 (epoch 14.730), train_loss = 1.20235925, grad/param norm = 1.9759e-01, time/batch = 18.2232s	
6762/22950 (epoch 14.732), train_loss = 1.24892678, grad/param norm = 1.9132e-01, time/batch = 16.1186s	
6763/22950 (epoch 14.734), train_loss = 1.23101204, grad/param norm = 2.1416e-01, time/batch = 17.8795s	
6764/22950 (epoch 14.736), train_loss = 1.17543671, grad/param norm = 1.9426e-01, time/batch = 19.8831s	
6765/22950 (epoch 14.739), train_loss = 1.26421100, grad/param norm = 2.1097e-01, time/batch = 18.7039s	
6766/22950 (epoch 14.741), train_loss = 1.25819304, grad/param norm = 2.0894e-01, time/batch = 15.7915s	
6767/22950 (epoch 14.743), train_loss = 1.37268565, grad/param norm = 2.0402e-01, time/batch = 18.2051s	
6768/22950 (epoch 14.745), train_loss = 1.44699303, grad/param norm = 2.0811e-01, time/batch = 19.3751s	
6769/22950 (epoch 14.747), train_loss = 1.23594446, grad/param norm = 2.0933e-01, time/batch = 16.9499s	
6770/22950 (epoch 14.749), train_loss = 1.11648620, grad/param norm = 1.9824e-01, time/batch = 20.1960s	
6771/22950 (epoch 14.752), train_loss = 1.41283230, grad/param norm = 2.1921e-01, time/batch = 17.3789s	
6772/22950 (epoch 14.754), train_loss = 1.32096237, grad/param norm = 2.0714e-01, time/batch = 16.6506s	
6773/22950 (epoch 14.756), train_loss = 1.12636456, grad/param norm = 1.9428e-01, time/batch = 17.1184s	
6774/22950 (epoch 14.758), train_loss = 1.14251775, grad/param norm = 1.8476e-01, time/batch = 18.4669s	
6775/22950 (epoch 14.760), train_loss = 1.24904809, grad/param norm = 2.0716e-01, time/batch = 18.6295s	
6776/22950 (epoch 14.763), train_loss = 1.26773675, grad/param norm = 2.1626e-01, time/batch = 18.4539s	
6777/22950 (epoch 14.765), train_loss = 1.25725894, grad/param norm = 2.1323e-01, time/batch = 19.0487s	
6778/22950 (epoch 14.767), train_loss = 1.40937080, grad/param norm = 2.1035e-01, time/batch = 19.6177s	
6779/22950 (epoch 14.769), train_loss = 1.23525358, grad/param norm = 1.9561e-01, time/batch = 18.2780s	
6780/22950 (epoch 14.771), train_loss = 1.09912966, grad/param norm = 1.9995e-01, time/batch = 19.0408s	
6781/22950 (epoch 14.773), train_loss = 0.92593203, grad/param norm = 1.7678e-01, time/batch = 15.9481s	
6782/22950 (epoch 14.776), train_loss = 1.12162974, grad/param norm = 1.9180e-01, time/batch = 19.4483s	
6783/22950 (epoch 14.778), train_loss = 1.06096626, grad/param norm = 1.8269e-01, time/batch = 3.1591s	
6784/22950 (epoch 14.780), train_loss = 1.15773889, grad/param norm = 1.7515e-01, time/batch = 0.6947s	
6785/22950 (epoch 14.782), train_loss = 1.18130014, grad/param norm = 1.8417e-01, time/batch = 0.7023s	
6786/22950 (epoch 14.784), train_loss = 1.19128043, grad/param norm = 1.9917e-01, time/batch = 0.7041s	
6787/22950 (epoch 14.786), train_loss = 1.27117354, grad/param norm = 1.9026e-01, time/batch = 0.6891s	
6788/22950 (epoch 14.789), train_loss = 1.05326593, grad/param norm = 1.9527e-01, time/batch = 0.6904s	
6789/22950 (epoch 14.791), train_loss = 1.08146992, grad/param norm = 1.9595e-01, time/batch = 0.6872s	
6790/22950 (epoch 14.793), train_loss = 1.43405805, grad/param norm = 2.2501e-01, time/batch = 0.9195s	
6791/22950 (epoch 14.795), train_loss = 1.14512305, grad/param norm = 1.7870e-01, time/batch = 1.0099s	
6792/22950 (epoch 14.797), train_loss = 1.36199519, grad/param norm = 2.1549e-01, time/batch = 1.0132s	
6793/22950 (epoch 14.800), train_loss = 1.10246480, grad/param norm = 1.9158e-01, time/batch = 1.0026s	
6794/22950 (epoch 14.802), train_loss = 1.11379855, grad/param norm = 2.0085e-01, time/batch = 1.0138s	
6795/22950 (epoch 14.804), train_loss = 1.16548623, grad/param norm = 1.9036e-01, time/batch = 1.6767s	
6796/22950 (epoch 14.806), train_loss = 1.06802935, grad/param norm = 2.0184e-01, time/batch = 1.8948s	
6797/22950 (epoch 14.808), train_loss = 1.17939839, grad/param norm = 1.9038e-01, time/batch = 3.9791s	
6798/22950 (epoch 14.810), train_loss = 1.14676456, grad/param norm = 1.9918e-01, time/batch = 17.5488s	
6799/22950 (epoch 14.813), train_loss = 0.97036046, grad/param norm = 1.8450e-01, time/batch = 17.8287s	
6800/22950 (epoch 14.815), train_loss = 1.06307691, grad/param norm = 1.8699e-01, time/batch = 17.2702s	
6801/22950 (epoch 14.817), train_loss = 1.06240739, grad/param norm = 1.7961e-01, time/batch = 19.6935s	
6802/22950 (epoch 14.819), train_loss = 1.17526416, grad/param norm = 2.0268e-01, time/batch = 17.2220s	
6803/22950 (epoch 14.821), train_loss = 1.16827840, grad/param norm = 2.1067e-01, time/batch = 17.7822s	
6804/22950 (epoch 14.824), train_loss = 1.18586138, grad/param norm = 2.1935e-01, time/batch = 18.3112s	
6805/22950 (epoch 14.826), train_loss = 1.31235991, grad/param norm = 2.1801e-01, time/batch = 18.9663s	
6806/22950 (epoch 14.828), train_loss = 1.16844749, grad/param norm = 1.9798e-01, time/batch = 18.7837s	
6807/22950 (epoch 14.830), train_loss = 1.19766446, grad/param norm = 1.9176e-01, time/batch = 18.3660s	
6808/22950 (epoch 14.832), train_loss = 1.19375037, grad/param norm = 1.8870e-01, time/batch = 17.6905s	
6809/22950 (epoch 14.834), train_loss = 1.03052822, grad/param norm = 1.8757e-01, time/batch = 18.7933s	
6810/22950 (epoch 14.837), train_loss = 1.21024480, grad/param norm = 2.0408e-01, time/batch = 20.1239s	
6811/22950 (epoch 14.839), train_loss = 1.04505319, grad/param norm = 1.7198e-01, time/batch = 18.8704s	
6812/22950 (epoch 14.841), train_loss = 1.10060740, grad/param norm = 1.8092e-01, time/batch = 19.2113s	
6813/22950 (epoch 14.843), train_loss = 1.14639725, grad/param norm = 2.0092e-01, time/batch = 17.7594s	
6814/22950 (epoch 14.845), train_loss = 1.20335295, grad/param norm = 2.0743e-01, time/batch = 18.6373s	
6815/22950 (epoch 14.847), train_loss = 1.26144655, grad/param norm = 2.0916e-01, time/batch = 17.6384s	
6816/22950 (epoch 14.850), train_loss = 1.21718311, grad/param norm = 2.0504e-01, time/batch = 16.1250s	
6817/22950 (epoch 14.852), train_loss = 1.22639239, grad/param norm = 1.9514e-01, time/batch = 19.9582s	
6818/22950 (epoch 14.854), train_loss = 1.16795169, grad/param norm = 1.9358e-01, time/batch = 19.3830s	
6819/22950 (epoch 14.856), train_loss = 1.38981179, grad/param norm = 2.2939e-01, time/batch = 18.6175s	
6820/22950 (epoch 14.858), train_loss = 1.26419403, grad/param norm = 1.8942e-01, time/batch = 18.9399s	
6821/22950 (epoch 14.861), train_loss = 1.29665192, grad/param norm = 2.0070e-01, time/batch = 19.2934s	
6822/22950 (epoch 14.863), train_loss = 1.34390885, grad/param norm = 2.2062e-01, time/batch = 18.7071s	
6823/22950 (epoch 14.865), train_loss = 1.35595126, grad/param norm = 2.0834e-01, time/batch = 18.9509s	
6824/22950 (epoch 14.867), train_loss = 1.23777540, grad/param norm = 2.0330e-01, time/batch = 16.8762s	
6825/22950 (epoch 14.869), train_loss = 1.40722464, grad/param norm = 2.3217e-01, time/batch = 18.0341s	
6826/22950 (epoch 14.871), train_loss = 1.20292124, grad/param norm = 2.0477e-01, time/batch = 17.2722s	
6827/22950 (epoch 14.874), train_loss = 1.19446427, grad/param norm = 2.0481e-01, time/batch = 17.8131s	
6828/22950 (epoch 14.876), train_loss = 1.26622666, grad/param norm = 2.1288e-01, time/batch = 17.9772s	
6829/22950 (epoch 14.878), train_loss = 1.14972322, grad/param norm = 2.2399e-01, time/batch = 17.2830s	
6830/22950 (epoch 14.880), train_loss = 1.37070199, grad/param norm = 2.0091e-01, time/batch = 18.9608s	
6831/22950 (epoch 14.882), train_loss = 1.08258537, grad/param norm = 1.8958e-01, time/batch = 17.1922s	
6832/22950 (epoch 14.885), train_loss = 1.24329410, grad/param norm = 2.1836e-01, time/batch = 16.4349s	
6833/22950 (epoch 14.887), train_loss = 1.23659562, grad/param norm = 2.0649e-01, time/batch = 17.5456s	
6834/22950 (epoch 14.889), train_loss = 1.28345592, grad/param norm = 2.1783e-01, time/batch = 19.3785s	
6835/22950 (epoch 14.891), train_loss = 1.18316581, grad/param norm = 2.0635e-01, time/batch = 18.7037s	
6836/22950 (epoch 14.893), train_loss = 1.24732216, grad/param norm = 1.9772e-01, time/batch = 19.1108s	
6837/22950 (epoch 14.895), train_loss = 1.39706033, grad/param norm = 2.2117e-01, time/batch = 19.2913s	
6838/22950 (epoch 14.898), train_loss = 1.20777049, grad/param norm = 2.0370e-01, time/batch = 18.8611s	
6839/22950 (epoch 14.900), train_loss = 1.11649708, grad/param norm = 1.7158e-01, time/batch = 17.7852s	
6840/22950 (epoch 14.902), train_loss = 1.27033508, grad/param norm = 1.9814e-01, time/batch = 19.7044s	
6841/22950 (epoch 14.904), train_loss = 1.24629273, grad/param norm = 1.9835e-01, time/batch = 19.2166s	
6842/22950 (epoch 14.906), train_loss = 1.20861572, grad/param norm = 1.8717e-01, time/batch = 17.9325s	
6843/22950 (epoch 14.908), train_loss = 1.10515205, grad/param norm = 1.9514e-01, time/batch = 18.3880s	
6844/22950 (epoch 14.911), train_loss = 1.05531433, grad/param norm = 1.9226e-01, time/batch = 16.6175s	
6845/22950 (epoch 14.913), train_loss = 1.13124152, grad/param norm = 2.0028e-01, time/batch = 18.0212s	
6846/22950 (epoch 14.915), train_loss = 1.30302238, grad/param norm = 2.1226e-01, time/batch = 19.0301s	
6847/22950 (epoch 14.917), train_loss = 1.06810289, grad/param norm = 1.8450e-01, time/batch = 17.6957s	
6848/22950 (epoch 14.919), train_loss = 1.14239809, grad/param norm = 1.9630e-01, time/batch = 17.6299s	
6849/22950 (epoch 14.922), train_loss = 1.20045618, grad/param norm = 2.1164e-01, time/batch = 17.4472s	
6850/22950 (epoch 14.924), train_loss = 1.26098839, grad/param norm = 1.9559e-01, time/batch = 20.0393s	
6851/22950 (epoch 14.926), train_loss = 1.04191313, grad/param norm = 1.9573e-01, time/batch = 19.6379s	
6852/22950 (epoch 14.928), train_loss = 1.05208824, grad/param norm = 1.9508e-01, time/batch = 19.6029s	
6853/22950 (epoch 14.930), train_loss = 1.05310227, grad/param norm = 1.9857e-01, time/batch = 18.8123s	
6854/22950 (epoch 14.932), train_loss = 1.00961654, grad/param norm = 1.8474e-01, time/batch = 19.2096s	
6855/22950 (epoch 14.935), train_loss = 1.20740388, grad/param norm = 1.9259e-01, time/batch = 16.1252s	
6856/22950 (epoch 14.937), train_loss = 1.22368229, grad/param norm = 2.1566e-01, time/batch = 19.3678s	
6857/22950 (epoch 14.939), train_loss = 1.13651118, grad/param norm = 2.1202e-01, time/batch = 19.5391s	
6858/22950 (epoch 14.941), train_loss = 1.10486729, grad/param norm = 1.8902e-01, time/batch = 17.7056s	
6859/22950 (epoch 14.943), train_loss = 1.20065209, grad/param norm = 2.0710e-01, time/batch = 20.2992s	
6860/22950 (epoch 14.946), train_loss = 1.06523732, grad/param norm = 2.0722e-01, time/batch = 18.6299s	
6861/22950 (epoch 14.948), train_loss = 1.24716770, grad/param norm = 1.9669e-01, time/batch = 18.0251s	
6862/22950 (epoch 14.950), train_loss = 1.20198157, grad/param norm = 2.0959e-01, time/batch = 19.6240s	
6863/22950 (epoch 14.952), train_loss = 1.23721925, grad/param norm = 2.1532e-01, time/batch = 18.0533s	
6864/22950 (epoch 14.954), train_loss = 1.21578999, grad/param norm = 2.0374e-01, time/batch = 17.4434s	
6865/22950 (epoch 14.956), train_loss = 1.11984809, grad/param norm = 1.9468e-01, time/batch = 19.1259s	
6866/22950 (epoch 14.959), train_loss = 1.08769268, grad/param norm = 1.9104e-01, time/batch = 16.5931s	
6867/22950 (epoch 14.961), train_loss = 1.19891438, grad/param norm = 2.0204e-01, time/batch = 20.2739s	
6868/22950 (epoch 14.963), train_loss = 1.23559363, grad/param norm = 2.1357e-01, time/batch = 17.7042s	
6869/22950 (epoch 14.965), train_loss = 1.35450019, grad/param norm = 2.1469e-01, time/batch = 19.7055s	
6870/22950 (epoch 14.967), train_loss = 1.18190587, grad/param norm = 2.1513e-01, time/batch = 18.8793s	
6871/22950 (epoch 14.969), train_loss = 1.10048731, grad/param norm = 1.9595e-01, time/batch = 18.7048s	
6872/22950 (epoch 14.972), train_loss = 1.18287094, grad/param norm = 1.9162e-01, time/batch = 19.8799s	
6873/22950 (epoch 14.974), train_loss = 1.14202767, grad/param norm = 2.0638e-01, time/batch = 18.9486s	
6874/22950 (epoch 14.976), train_loss = 1.06877145, grad/param norm = 1.9758e-01, time/batch = 17.8716s	
6875/22950 (epoch 14.978), train_loss = 1.15906860, grad/param norm = 2.0051e-01, time/batch = 17.9697s	
6876/22950 (epoch 14.980), train_loss = 1.19356851, grad/param norm = 1.9847e-01, time/batch = 19.6259s	
6877/22950 (epoch 14.983), train_loss = 1.14744680, grad/param norm = 1.9238e-01, time/batch = 17.6244s	
6878/22950 (epoch 14.985), train_loss = 1.04840427, grad/param norm = 1.8457e-01, time/batch = 20.0366s	
6879/22950 (epoch 14.987), train_loss = 1.07910807, grad/param norm = 1.8870e-01, time/batch = 17.5415s	
6880/22950 (epoch 14.989), train_loss = 1.20200965, grad/param norm = 1.9930e-01, time/batch = 15.5587s	
6881/22950 (epoch 14.991), train_loss = 1.02321571, grad/param norm = 1.9108e-01, time/batch = 19.7541s	
6882/22950 (epoch 14.993), train_loss = 1.20185392, grad/param norm = 2.0773e-01, time/batch = 18.7210s	
6883/22950 (epoch 14.996), train_loss = 1.26787862, grad/param norm = 2.1758e-01, time/batch = 17.7096s	
6884/22950 (epoch 14.998), train_loss = 1.13225429, grad/param norm = 1.9826e-01, time/batch = 17.2911s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
6885/22950 (epoch 15.000), train_loss = 1.02110425, grad/param norm = 1.8411e-01, time/batch = 18.6216s	
6886/22950 (epoch 15.002), train_loss = 1.36376914, grad/param norm = 2.1237e-01, time/batch = 18.5337s	
6887/22950 (epoch 15.004), train_loss = 1.20919252, grad/param norm = 1.9416e-01, time/batch = 17.8703s	
6888/22950 (epoch 15.007), train_loss = 1.18940285, grad/param norm = 2.0833e-01, time/batch = 17.2820s	
6889/22950 (epoch 15.009), train_loss = 1.32893234, grad/param norm = 2.1922e-01, time/batch = 16.2869s	
6890/22950 (epoch 15.011), train_loss = 1.08163300, grad/param norm = 1.9184e-01, time/batch = 18.9630s	
6891/22950 (epoch 15.013), train_loss = 1.25377783, grad/param norm = 2.1397e-01, time/batch = 18.1966s	
6892/22950 (epoch 15.015), train_loss = 1.27387630, grad/param norm = 2.1449e-01, time/batch = 19.5494s	
6893/22950 (epoch 15.017), train_loss = 1.20086028, grad/param norm = 1.8718e-01, time/batch = 18.5531s	
6894/22950 (epoch 15.020), train_loss = 1.17514810, grad/param norm = 1.7644e-01, time/batch = 15.7724s	
6895/22950 (epoch 15.022), train_loss = 1.03101804, grad/param norm = 1.8608e-01, time/batch = 17.7177s	
6896/22950 (epoch 15.024), train_loss = 1.10163307, grad/param norm = 1.8601e-01, time/batch = 18.1399s	
6897/22950 (epoch 15.026), train_loss = 1.21170896, grad/param norm = 1.9636e-01, time/batch = 15.7304s	
6898/22950 (epoch 15.028), train_loss = 1.26559887, grad/param norm = 1.9271e-01, time/batch = 18.5559s	
6899/22950 (epoch 15.031), train_loss = 1.18607629, grad/param norm = 2.0658e-01, time/batch = 18.7151s	
6900/22950 (epoch 15.033), train_loss = 1.32950448, grad/param norm = 2.3017e-01, time/batch = 17.7711s	
6901/22950 (epoch 15.035), train_loss = 1.16653396, grad/param norm = 1.7914e-01, time/batch = 18.9689s	
6902/22950 (epoch 15.037), train_loss = 1.16831758, grad/param norm = 2.0053e-01, time/batch = 19.5400s	
6903/22950 (epoch 15.039), train_loss = 1.14192149, grad/param norm = 1.9592e-01, time/batch = 18.8815s	
6904/22950 (epoch 15.041), train_loss = 1.16063152, grad/param norm = 2.0754e-01, time/batch = 18.5152s	
6905/22950 (epoch 15.044), train_loss = 1.19757586, grad/param norm = 2.0388e-01, time/batch = 20.2039s	
6906/22950 (epoch 15.046), train_loss = 1.20158933, grad/param norm = 2.0821e-01, time/batch = 18.9739s	
6907/22950 (epoch 15.048), train_loss = 1.19448219, grad/param norm = 1.9125e-01, time/batch = 17.7021s	
6908/22950 (epoch 15.050), train_loss = 1.20895042, grad/param norm = 2.0806e-01, time/batch = 19.9650s	
6909/22950 (epoch 15.052), train_loss = 1.21515989, grad/param norm = 1.8758e-01, time/batch = 16.8783s	
6910/22950 (epoch 15.054), train_loss = 1.40867557, grad/param norm = 2.1072e-01, time/batch = 17.2826s	
6911/22950 (epoch 15.057), train_loss = 1.29031139, grad/param norm = 2.0984e-01, time/batch = 17.7046s	
6912/22950 (epoch 15.059), train_loss = 1.25207550, grad/param norm = 1.9626e-01, time/batch = 18.6393s	
6913/22950 (epoch 15.061), train_loss = 1.10005534, grad/param norm = 1.9486e-01, time/batch = 16.7082s	
6914/22950 (epoch 15.063), train_loss = 1.24575687, grad/param norm = 1.9272e-01, time/batch = 19.2026s	
6915/22950 (epoch 15.065), train_loss = 0.96186743, grad/param norm = 1.8499e-01, time/batch = 18.9574s	
6916/22950 (epoch 15.068), train_loss = 1.26201737, grad/param norm = 1.9584e-01, time/batch = 19.2978s	
6917/22950 (epoch 15.070), train_loss = 1.07738797, grad/param norm = 1.9453e-01, time/batch = 19.8680s	
6918/22950 (epoch 15.072), train_loss = 1.23855134, grad/param norm = 1.9273e-01, time/batch = 18.0946s	
6919/22950 (epoch 15.074), train_loss = 1.17898314, grad/param norm = 2.0899e-01, time/batch = 20.0461s	
6920/22950 (epoch 15.076), train_loss = 1.18860741, grad/param norm = 1.9509e-01, time/batch = 19.1993s	
6921/22950 (epoch 15.078), train_loss = 1.27160587, grad/param norm = 2.0186e-01, time/batch = 17.7227s	
6922/22950 (epoch 15.081), train_loss = 1.26814864, grad/param norm = 2.0163e-01, time/batch = 18.6272s	
6923/22950 (epoch 15.083), train_loss = 1.14862756, grad/param norm = 1.9815e-01, time/batch = 17.9620s	
6924/22950 (epoch 15.085), train_loss = 1.09232772, grad/param norm = 2.0928e-01, time/batch = 18.8019s	
6925/22950 (epoch 15.087), train_loss = 1.09146755, grad/param norm = 1.9615e-01, time/batch = 17.7943s	
6926/22950 (epoch 15.089), train_loss = 1.18980339, grad/param norm = 1.8222e-01, time/batch = 26.3449s	
6927/22950 (epoch 15.092), train_loss = 1.12915445, grad/param norm = 2.1292e-01, time/batch = 24.3186s	
6928/22950 (epoch 15.094), train_loss = 1.11437060, grad/param norm = 1.8811e-01, time/batch = 17.8036s	
6929/22950 (epoch 15.096), train_loss = 1.32539595, grad/param norm = 2.0391e-01, time/batch = 18.8571s	
6930/22950 (epoch 15.098), train_loss = 1.23727611, grad/param norm = 1.9862e-01, time/batch = 16.9728s	
6931/22950 (epoch 15.100), train_loss = 1.14400852, grad/param norm = 2.1061e-01, time/batch = 18.1040s	
6932/22950 (epoch 15.102), train_loss = 1.18686888, grad/param norm = 1.9210e-01, time/batch = 17.5170s	
6933/22950 (epoch 15.105), train_loss = 1.05583743, grad/param norm = 1.7151e-01, time/batch = 20.3762s	
6934/22950 (epoch 15.107), train_loss = 1.12926890, grad/param norm = 1.8950e-01, time/batch = 18.3850s	
6935/22950 (epoch 15.109), train_loss = 1.13388800, grad/param norm = 2.2018e-01, time/batch = 18.2171s	
6936/22950 (epoch 15.111), train_loss = 1.03452046, grad/param norm = 1.8720e-01, time/batch = 19.7932s	
6937/22950 (epoch 15.113), train_loss = 1.20302631, grad/param norm = 1.9493e-01, time/batch = 17.7610s	
6938/22950 (epoch 15.115), train_loss = 1.22861554, grad/param norm = 2.0751e-01, time/batch = 18.2005s	
6939/22950 (epoch 15.118), train_loss = 1.30794058, grad/param norm = 1.9571e-01, time/batch = 19.1238s	
6940/22950 (epoch 15.120), train_loss = 1.10514105, grad/param norm = 1.8903e-01, time/batch = 19.8749s	
6941/22950 (epoch 15.122), train_loss = 1.31203675, grad/param norm = 2.0709e-01, time/batch = 17.8612s	
6942/22950 (epoch 15.124), train_loss = 0.99554970, grad/param norm = 1.6240e-01, time/batch = 16.3426s	
6943/22950 (epoch 15.126), train_loss = 1.13585930, grad/param norm = 1.8976e-01, time/batch = 19.6871s	
6944/22950 (epoch 15.129), train_loss = 1.01714266, grad/param norm = 1.7396e-01, time/batch = 17.9583s	
6945/22950 (epoch 15.131), train_loss = 1.13503198, grad/param norm = 1.9550e-01, time/batch = 16.9491s	
6946/22950 (epoch 15.133), train_loss = 1.21531539, grad/param norm = 2.0300e-01, time/batch = 19.0291s	
6947/22950 (epoch 15.135), train_loss = 1.14994190, grad/param norm = 1.7633e-01, time/batch = 19.0591s	
6948/22950 (epoch 15.137), train_loss = 1.31315609, grad/param norm = 2.1359e-01, time/batch = 18.2988s	
6949/22950 (epoch 15.139), train_loss = 1.09700313, grad/param norm = 1.9467e-01, time/batch = 19.6068s	
6950/22950 (epoch 15.142), train_loss = 1.09060219, grad/param norm = 1.9034e-01, time/batch = 18.6396s	
6951/22950 (epoch 15.144), train_loss = 1.06395925, grad/param norm = 1.7780e-01, time/batch = 16.8619s	
6952/22950 (epoch 15.146), train_loss = 1.14692243, grad/param norm = 2.0403e-01, time/batch = 17.6178s	
6953/22950 (epoch 15.148), train_loss = 1.12533868, grad/param norm = 1.9572e-01, time/batch = 19.2201s	
6954/22950 (epoch 15.150), train_loss = 1.18993960, grad/param norm = 2.0599e-01, time/batch = 19.7077s	
6955/22950 (epoch 15.153), train_loss = 1.12541609, grad/param norm = 1.9762e-01, time/batch = 18.1225s	
6956/22950 (epoch 15.155), train_loss = 1.10646868, grad/param norm = 1.8016e-01, time/batch = 19.9472s	
6957/22950 (epoch 15.157), train_loss = 1.11785241, grad/param norm = 2.0594e-01, time/batch = 19.9658s	
6958/22950 (epoch 15.159), train_loss = 1.06822458, grad/param norm = 1.7587e-01, time/batch = 17.7657s	
6959/22950 (epoch 15.161), train_loss = 1.11746368, grad/param norm = 1.7994e-01, time/batch = 18.7235s	
6960/22950 (epoch 15.163), train_loss = 1.06096832, grad/param norm = 1.8344e-01, time/batch = 19.1243s	
6961/22950 (epoch 15.166), train_loss = 1.31872747, grad/param norm = 2.0947e-01, time/batch = 18.3542s	
6962/22950 (epoch 15.168), train_loss = 1.27853771, grad/param norm = 2.1592e-01, time/batch = 18.2969s	
6963/22950 (epoch 15.170), train_loss = 1.19585121, grad/param norm = 2.1878e-01, time/batch = 19.7054s	
6964/22950 (epoch 15.172), train_loss = 1.18014715, grad/param norm = 1.8160e-01, time/batch = 18.8757s	
6965/22950 (epoch 15.174), train_loss = 1.25856458, grad/param norm = 2.1568e-01, time/batch = 18.9650s	
6966/22950 (epoch 15.176), train_loss = 1.29848393, grad/param norm = 1.9955e-01, time/batch = 20.2938s	
6967/22950 (epoch 15.179), train_loss = 1.23557098, grad/param norm = 2.0307e-01, time/batch = 18.3535s	
6968/22950 (epoch 15.181), train_loss = 1.41664171, grad/param norm = 2.1531e-01, time/batch = 19.6968s	
6969/22950 (epoch 15.183), train_loss = 1.27550018, grad/param norm = 2.0752e-01, time/batch = 16.8687s	
6970/22950 (epoch 15.185), train_loss = 1.23640768, grad/param norm = 2.0159e-01, time/batch = 17.1296s	
6971/22950 (epoch 15.187), train_loss = 1.08879478, grad/param norm = 2.0958e-01, time/batch = 17.6374s	
6972/22950 (epoch 15.190), train_loss = 1.04125902, grad/param norm = 2.2013e-01, time/batch = 19.1318s	
6973/22950 (epoch 15.192), train_loss = 1.04154221, grad/param norm = 1.8591e-01, time/batch = 18.5590s	
6974/22950 (epoch 15.194), train_loss = 1.10840956, grad/param norm = 2.0881e-01, time/batch = 16.5831s	
6975/22950 (epoch 15.196), train_loss = 0.99564069, grad/param norm = 1.8856e-01, time/batch = 17.3850s	
6976/22950 (epoch 15.198), train_loss = 1.26421794, grad/param norm = 2.1314e-01, time/batch = 18.3834s	
6977/22950 (epoch 15.200), train_loss = 1.07426751, grad/param norm = 1.8904e-01, time/batch = 17.0415s	
6978/22950 (epoch 15.203), train_loss = 1.04306271, grad/param norm = 1.8916e-01, time/batch = 17.9645s	
6979/22950 (epoch 15.205), train_loss = 1.09328126, grad/param norm = 1.6616e-01, time/batch = 19.2304s	
6980/22950 (epoch 15.207), train_loss = 1.15652122, grad/param norm = 1.9952e-01, time/batch = 18.0279s	
6981/22950 (epoch 15.209), train_loss = 1.21757269, grad/param norm = 2.0730e-01, time/batch = 19.8740s	
6982/22950 (epoch 15.211), train_loss = 1.00073428, grad/param norm = 2.1766e-01, time/batch = 18.4666s	
6983/22950 (epoch 15.214), train_loss = 1.16001876, grad/param norm = 1.9498e-01, time/batch = 19.4533s	
6984/22950 (epoch 15.216), train_loss = 1.26000800, grad/param norm = 2.0436e-01, time/batch = 18.5433s	
6985/22950 (epoch 15.218), train_loss = 1.17612497, grad/param norm = 2.0626e-01, time/batch = 19.2231s	
6986/22950 (epoch 15.220), train_loss = 1.29922976, grad/param norm = 2.3679e-01, time/batch = 19.3610s	
6987/22950 (epoch 15.222), train_loss = 1.29775103, grad/param norm = 2.1402e-01, time/batch = 18.0116s	
6988/22950 (epoch 15.224), train_loss = 1.14731245, grad/param norm = 1.9333e-01, time/batch = 19.0409s	
6989/22950 (epoch 15.227), train_loss = 1.23373058, grad/param norm = 1.8380e-01, time/batch = 19.8864s	
6990/22950 (epoch 15.229), train_loss = 1.24671894, grad/param norm = 2.0848e-01, time/batch = 16.2211s	
6991/22950 (epoch 15.231), train_loss = 1.02953970, grad/param norm = 1.8433e-01, time/batch = 18.1374s	
6992/22950 (epoch 15.233), train_loss = 1.10665422, grad/param norm = 1.9006e-01, time/batch = 18.8726s	
6993/22950 (epoch 15.235), train_loss = 1.30724955, grad/param norm = 2.1415e-01, time/batch = 16.3095s	
6994/22950 (epoch 15.237), train_loss = 1.07594071, grad/param norm = 1.8904e-01, time/batch = 18.2575s	
6995/22950 (epoch 15.240), train_loss = 1.14765618, grad/param norm = 2.0325e-01, time/batch = 19.7058s	
6996/22950 (epoch 15.242), train_loss = 1.27245310, grad/param norm = 1.9176e-01, time/batch = 19.4636s	
6997/22950 (epoch 15.244), train_loss = 1.36062868, grad/param norm = 2.2770e-01, time/batch = 18.7965s	
6998/22950 (epoch 15.246), train_loss = 1.29698987, grad/param norm = 2.0217e-01, time/batch = 19.6327s	
6999/22950 (epoch 15.248), train_loss = 1.20741269, grad/param norm = 2.1677e-01, time/batch = 18.6905s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch15.25_1.6717.t7	
7000/22950 (epoch 15.251), train_loss = 1.10011026, grad/param norm = 1.9461e-01, time/batch = 19.2060s	
7001/22950 (epoch 15.253), train_loss = 1.42648468, grad/param norm = 2.5732e-01, time/batch = 19.2128s	
7002/22950 (epoch 15.255), train_loss = 1.19627815, grad/param norm = 2.1837e-01, time/batch = 19.2005s	
7003/22950 (epoch 15.257), train_loss = 1.30481782, grad/param norm = 2.0550e-01, time/batch = 17.4474s	
7004/22950 (epoch 15.259), train_loss = 1.03302816, grad/param norm = 1.9741e-01, time/batch = 18.7177s	
7005/22950 (epoch 15.261), train_loss = 1.14316612, grad/param norm = 2.0327e-01, time/batch = 19.2896s	
7006/22950 (epoch 15.264), train_loss = 1.07979355, grad/param norm = 1.8857e-01, time/batch = 18.4773s	
7007/22950 (epoch 15.266), train_loss = 1.21580878, grad/param norm = 2.0855e-01, time/batch = 17.7004s	
7008/22950 (epoch 15.268), train_loss = 1.19733674, grad/param norm = 2.0598e-01, time/batch = 18.2206s	
7009/22950 (epoch 15.270), train_loss = 1.19365203, grad/param norm = 2.0532e-01, time/batch = 20.3580s	
7010/22950 (epoch 15.272), train_loss = 1.30068754, grad/param norm = 2.1164e-01, time/batch = 17.3605s	
7011/22950 (epoch 15.275), train_loss = 1.10612828, grad/param norm = 1.8855e-01, time/batch = 18.7756s	
7012/22950 (epoch 15.277), train_loss = 1.00423787, grad/param norm = 1.6557e-01, time/batch = 19.1270s	
7013/22950 (epoch 15.279), train_loss = 1.14442924, grad/param norm = 2.1270e-01, time/batch = 17.2823s	
7014/22950 (epoch 15.281), train_loss = 1.10758241, grad/param norm = 1.9392e-01, time/batch = 18.6299s	
7015/22950 (epoch 15.283), train_loss = 0.98634099, grad/param norm = 1.6585e-01, time/batch = 20.2143s	
7016/22950 (epoch 15.285), train_loss = 1.16551589, grad/param norm = 1.8025e-01, time/batch = 18.1102s	
7017/22950 (epoch 15.288), train_loss = 1.19513618, grad/param norm = 1.7539e-01, time/batch = 17.5358s	
7018/22950 (epoch 15.290), train_loss = 1.09761682, grad/param norm = 1.8150e-01, time/batch = 17.0281s	
7019/22950 (epoch 15.292), train_loss = 1.25415648, grad/param norm = 1.9497e-01, time/batch = 17.6297s	
7020/22950 (epoch 15.294), train_loss = 1.14824037, grad/param norm = 1.8433e-01, time/batch = 17.2002s	
7021/22950 (epoch 15.296), train_loss = 0.94106491, grad/param norm = 1.5855e-01, time/batch = 18.1506s	
7022/22950 (epoch 15.298), train_loss = 1.16894770, grad/param norm = 1.8037e-01, time/batch = 19.3798s	
7023/22950 (epoch 15.301), train_loss = 1.18586225, grad/param norm = 1.9901e-01, time/batch = 16.7929s	
7024/22950 (epoch 15.303), train_loss = 1.21412015, grad/param norm = 1.9994e-01, time/batch = 16.7133s	
7025/22950 (epoch 15.305), train_loss = 1.20671390, grad/param norm = 1.9060e-01, time/batch = 20.3658s	
7026/22950 (epoch 15.307), train_loss = 1.29100500, grad/param norm = 2.1046e-01, time/batch = 18.2950s	
7027/22950 (epoch 15.309), train_loss = 1.11719740, grad/param norm = 1.7616e-01, time/batch = 18.2969s	
7028/22950 (epoch 15.312), train_loss = 1.16127493, grad/param norm = 2.0466e-01, time/batch = 15.8702s	
7029/22950 (epoch 15.314), train_loss = 1.12396671, grad/param norm = 1.8775e-01, time/batch = 19.9528s	
7030/22950 (epoch 15.316), train_loss = 1.16550199, grad/param norm = 2.0132e-01, time/batch = 18.5240s	
7031/22950 (epoch 15.318), train_loss = 0.96866800, grad/param norm = 1.7199e-01, time/batch = 17.6305s	
7032/22950 (epoch 15.320), train_loss = 1.10977403, grad/param norm = 1.7699e-01, time/batch = 20.2907s	
7033/22950 (epoch 15.322), train_loss = 1.14474374, grad/param norm = 1.9782e-01, time/batch = 16.8376s	
7034/22950 (epoch 15.325), train_loss = 0.91010415, grad/param norm = 1.6732e-01, time/batch = 18.8021s	
7035/22950 (epoch 15.327), train_loss = 0.95670234, grad/param norm = 1.8488e-01, time/batch = 17.4813s	
7036/22950 (epoch 15.329), train_loss = 1.08990883, grad/param norm = 1.9020e-01, time/batch = 16.2898s	
7037/22950 (epoch 15.331), train_loss = 1.02169790, grad/param norm = 1.9370e-01, time/batch = 20.1020s	
7038/22950 (epoch 15.333), train_loss = 1.13591650, grad/param norm = 1.9207e-01, time/batch = 16.1011s	
7039/22950 (epoch 15.336), train_loss = 1.12207387, grad/param norm = 1.9601e-01, time/batch = 18.9399s	
7040/22950 (epoch 15.338), train_loss = 1.09707911, grad/param norm = 1.8123e-01, time/batch = 19.1198s	
7041/22950 (epoch 15.340), train_loss = 1.15743714, grad/param norm = 2.1471e-01, time/batch = 19.3888s	
7042/22950 (epoch 15.342), train_loss = 1.26651487, grad/param norm = 2.0189e-01, time/batch = 19.2947s	
7043/22950 (epoch 15.344), train_loss = 1.14869406, grad/param norm = 2.0529e-01, time/batch = 17.4214s	
7044/22950 (epoch 15.346), train_loss = 1.29781259, grad/param norm = 2.1104e-01, time/batch = 18.7149s	
7045/22950 (epoch 15.349), train_loss = 1.15771233, grad/param norm = 2.1700e-01, time/batch = 19.1383s	
7046/22950 (epoch 15.351), train_loss = 1.19534293, grad/param norm = 1.8843e-01, time/batch = 17.6292s	
7047/22950 (epoch 15.353), train_loss = 1.25666061, grad/param norm = 2.3586e-01, time/batch = 19.3866s	
7048/22950 (epoch 15.355), train_loss = 1.27461070, grad/param norm = 2.0053e-01, time/batch = 20.2814s	
7049/22950 (epoch 15.357), train_loss = 1.15973642, grad/param norm = 1.9794e-01, time/batch = 18.6926s	
7050/22950 (epoch 15.359), train_loss = 1.18634597, grad/param norm = 2.1871e-01, time/batch = 18.2163s	
7051/22950 (epoch 15.362), train_loss = 1.16221701, grad/param norm = 2.1982e-01, time/batch = 19.2930s	
7052/22950 (epoch 15.364), train_loss = 1.15644068, grad/param norm = 1.9684e-01, time/batch = 16.2102s	
7053/22950 (epoch 15.366), train_loss = 1.04408785, grad/param norm = 1.7670e-01, time/batch = 18.3702s	
7054/22950 (epoch 15.368), train_loss = 1.20127119, grad/param norm = 2.1026e-01, time/batch = 17.3545s	
7055/22950 (epoch 15.370), train_loss = 1.13316874, grad/param norm = 2.0832e-01, time/batch = 19.7053s	
7056/22950 (epoch 15.373), train_loss = 1.03525484, grad/param norm = 1.9330e-01, time/batch = 19.0516s	
7057/22950 (epoch 15.375), train_loss = 1.28276837, grad/param norm = 2.1561e-01, time/batch = 18.3136s	
7058/22950 (epoch 15.377), train_loss = 1.08743905, grad/param norm = 2.1187e-01, time/batch = 20.2931s	
7059/22950 (epoch 15.379), train_loss = 1.18373054, grad/param norm = 2.0633e-01, time/batch = 18.6139s	
7060/22950 (epoch 15.381), train_loss = 1.00164003, grad/param norm = 1.8704e-01, time/batch = 18.4482s	
7061/22950 (epoch 15.383), train_loss = 1.19289411, grad/param norm = 2.1398e-01, time/batch = 19.5310s	
7062/22950 (epoch 15.386), train_loss = 1.08857473, grad/param norm = 2.0022e-01, time/batch = 18.1855s	
7063/22950 (epoch 15.388), train_loss = 1.15823982, grad/param norm = 2.1010e-01, time/batch = 18.2955s	
7064/22950 (epoch 15.390), train_loss = 1.05911803, grad/param norm = 1.8053e-01, time/batch = 19.6213s	
7065/22950 (epoch 15.392), train_loss = 1.07038267, grad/param norm = 1.9332e-01, time/batch = 16.7608s	
7066/22950 (epoch 15.394), train_loss = 1.08319251, grad/param norm = 1.7119e-01, time/batch = 17.9724s	
7067/22950 (epoch 15.397), train_loss = 1.28909917, grad/param norm = 2.0184e-01, time/batch = 18.5588s	
7068/22950 (epoch 15.399), train_loss = 1.28268143, grad/param norm = 2.2875e-01, time/batch = 16.6099s	
7069/22950 (epoch 15.401), train_loss = 1.40363296, grad/param norm = 2.1180e-01, time/batch = 19.5294s	
7070/22950 (epoch 15.403), train_loss = 1.13946807, grad/param norm = 2.0907e-01, time/batch = 19.5340s	
7071/22950 (epoch 15.405), train_loss = 1.27355555, grad/param norm = 2.3560e-01, time/batch = 19.4333s	
7072/22950 (epoch 15.407), train_loss = 1.33497207, grad/param norm = 2.0397e-01, time/batch = 16.4207s	
7073/22950 (epoch 15.410), train_loss = 1.07017621, grad/param norm = 1.8649e-01, time/batch = 19.2209s	
7074/22950 (epoch 15.412), train_loss = 1.17418389, grad/param norm = 2.1162e-01, time/batch = 20.2127s	
7075/22950 (epoch 15.414), train_loss = 1.26088330, grad/param norm = 2.1656e-01, time/batch = 18.4477s	
7076/22950 (epoch 15.416), train_loss = 1.20136608, grad/param norm = 2.2013e-01, time/batch = 19.7098s	
7077/22950 (epoch 15.418), train_loss = 1.20762903, grad/param norm = 2.1264e-01, time/batch = 18.9705s	
7078/22950 (epoch 15.420), train_loss = 1.23138751, grad/param norm = 2.3620e-01, time/batch = 18.0270s	
7079/22950 (epoch 15.423), train_loss = 1.08667655, grad/param norm = 1.7949e-01, time/batch = 18.5555s	
7080/22950 (epoch 15.425), train_loss = 1.17886060, grad/param norm = 2.1209e-01, time/batch = 18.7201s	
7081/22950 (epoch 15.427), train_loss = 1.14826620, grad/param norm = 1.9924e-01, time/batch = 18.3588s	
7082/22950 (epoch 15.429), train_loss = 1.13935521, grad/param norm = 1.9683e-01, time/batch = 17.9680s	
7083/22950 (epoch 15.431), train_loss = 1.21027274, grad/param norm = 2.0332e-01, time/batch = 19.2138s	
7084/22950 (epoch 15.434), train_loss = 1.17639883, grad/param norm = 2.1089e-01, time/batch = 16.6316s	
7085/22950 (epoch 15.436), train_loss = 1.35509093, grad/param norm = 2.3166e-01, time/batch = 19.6165s	
7086/22950 (epoch 15.438), train_loss = 1.18229689, grad/param norm = 1.9724e-01, time/batch = 16.1913s	
7087/22950 (epoch 15.440), train_loss = 1.27566649, grad/param norm = 2.0702e-01, time/batch = 19.0624s	
7088/22950 (epoch 15.442), train_loss = 1.31778598, grad/param norm = 2.0996e-01, time/batch = 19.1964s	
7089/22950 (epoch 15.444), train_loss = 1.24745866, grad/param norm = 2.0310e-01, time/batch = 15.5680s	
7090/22950 (epoch 15.447), train_loss = 1.37087319, grad/param norm = 2.2396e-01, time/batch = 18.9582s	
7091/22950 (epoch 15.449), train_loss = 1.05206562, grad/param norm = 1.7615e-01, time/batch = 17.0485s	
7092/22950 (epoch 15.451), train_loss = 1.18934509, grad/param norm = 1.8521e-01, time/batch = 19.8801s	
7093/22950 (epoch 15.453), train_loss = 1.21649187, grad/param norm = 1.9201e-01, time/batch = 19.9532s	
7094/22950 (epoch 15.455), train_loss = 1.06224027, grad/param norm = 1.7396e-01, time/batch = 18.1252s	
7095/22950 (epoch 15.458), train_loss = 1.31549291, grad/param norm = 2.0680e-01, time/batch = 19.8750s	
7096/22950 (epoch 15.460), train_loss = 1.19945988, grad/param norm = 2.0567e-01, time/batch = 18.1296s	
7097/22950 (epoch 15.462), train_loss = 1.17340558, grad/param norm = 1.8277e-01, time/batch = 18.1258s	
7098/22950 (epoch 15.464), train_loss = 1.14516573, grad/param norm = 1.9285e-01, time/batch = 16.9490s	
7099/22950 (epoch 15.466), train_loss = 1.19309557, grad/param norm = 2.0077e-01, time/batch = 18.7215s	
7100/22950 (epoch 15.468), train_loss = 1.31376215, grad/param norm = 2.0743e-01, time/batch = 15.2323s	
7101/22950 (epoch 15.471), train_loss = 1.19723678, grad/param norm = 2.0516e-01, time/batch = 18.1084s	
7102/22950 (epoch 15.473), train_loss = 1.23427909, grad/param norm = 2.0764e-01, time/batch = 19.0320s	
7103/22950 (epoch 15.475), train_loss = 1.39871442, grad/param norm = 2.1361e-01, time/batch = 20.2146s	
7104/22950 (epoch 15.477), train_loss = 1.17059331, grad/param norm = 2.0673e-01, time/batch = 18.2949s	
7105/22950 (epoch 15.479), train_loss = 1.09793673, grad/param norm = 1.9697e-01, time/batch = 19.4508s	
7106/22950 (epoch 15.481), train_loss = 1.28980249, grad/param norm = 2.1116e-01, time/batch = 16.0990s	
7107/22950 (epoch 15.484), train_loss = 1.20579222, grad/param norm = 1.9729e-01, time/batch = 18.7029s	
7108/22950 (epoch 15.486), train_loss = 1.04786390, grad/param norm = 1.8821e-01, time/batch = 19.9494s	
7109/22950 (epoch 15.488), train_loss = 1.14488286, grad/param norm = 2.1131e-01, time/batch = 17.9649s	
7110/22950 (epoch 15.490), train_loss = 1.00359243, grad/param norm = 2.0060e-01, time/batch = 18.0489s	
7111/22950 (epoch 15.492), train_loss = 1.13712782, grad/param norm = 1.9405e-01, time/batch = 20.8773s	
7112/22950 (epoch 15.495), train_loss = 1.15639877, grad/param norm = 2.0288e-01, time/batch = 18.1280s	
7113/22950 (epoch 15.497), train_loss = 1.25363864, grad/param norm = 2.0005e-01, time/batch = 19.2146s	
7114/22950 (epoch 15.499), train_loss = 1.28688902, grad/param norm = 1.9673e-01, time/batch = 32.5348s	
7115/22950 (epoch 15.501), train_loss = 1.22742116, grad/param norm = 2.1333e-01, time/batch = 19.5361s	
7116/22950 (epoch 15.503), train_loss = 1.27239959, grad/param norm = 1.9361e-01, time/batch = 17.0057s	
7117/22950 (epoch 15.505), train_loss = 1.03269040, grad/param norm = 1.6759e-01, time/batch = 19.5541s	
7118/22950 (epoch 15.508), train_loss = 1.22212767, grad/param norm = 1.9270e-01, time/batch = 17.7305s	
7119/22950 (epoch 15.510), train_loss = 1.18740864, grad/param norm = 2.0359e-01, time/batch = 18.7841s	
7120/22950 (epoch 15.512), train_loss = 1.09974737, grad/param norm = 1.9301e-01, time/batch = 16.9532s	
7121/22950 (epoch 15.514), train_loss = 1.06481737, grad/param norm = 1.7093e-01, time/batch = 19.7084s	
7122/22950 (epoch 15.516), train_loss = 1.14388669, grad/param norm = 2.0297e-01, time/batch = 19.2772s	
7123/22950 (epoch 15.519), train_loss = 1.13493103, grad/param norm = 1.8260e-01, time/batch = 20.1121s	
7124/22950 (epoch 15.521), train_loss = 1.18206748, grad/param norm = 1.9299e-01, time/batch = 19.1308s	
7125/22950 (epoch 15.523), train_loss = 0.95695145, grad/param norm = 1.7726e-01, time/batch = 18.8043s	
7126/22950 (epoch 15.525), train_loss = 1.06601461, grad/param norm = 1.9528e-01, time/batch = 19.4405s	
7127/22950 (epoch 15.527), train_loss = 1.01345117, grad/param norm = 1.9962e-01, time/batch = 19.3737s	
7128/22950 (epoch 15.529), train_loss = 1.19570741, grad/param norm = 2.0673e-01, time/batch = 15.9422s	
7129/22950 (epoch 15.532), train_loss = 1.09897311, grad/param norm = 1.8081e-01, time/batch = 17.6959s	
7130/22950 (epoch 15.534), train_loss = 1.24348305, grad/param norm = 2.1652e-01, time/batch = 18.8818s	
7131/22950 (epoch 15.536), train_loss = 1.24154847, grad/param norm = 2.2551e-01, time/batch = 19.4526s	
7132/22950 (epoch 15.538), train_loss = 1.15232223, grad/param norm = 2.1814e-01, time/batch = 17.8599s	
7133/22950 (epoch 15.540), train_loss = 1.19255664, grad/param norm = 1.8708e-01, time/batch = 20.3642s	
7134/22950 (epoch 15.542), train_loss = 1.34093472, grad/param norm = 2.0334e-01, time/batch = 17.5553s	
7135/22950 (epoch 15.545), train_loss = 1.13835715, grad/param norm = 1.9107e-01, time/batch = 18.2910s	
7136/22950 (epoch 15.547), train_loss = 1.15624928, grad/param norm = 1.9389e-01, time/batch = 20.0375s	
7137/22950 (epoch 15.549), train_loss = 1.14195140, grad/param norm = 2.0709e-01, time/batch = 19.5422s	
7138/22950 (epoch 15.551), train_loss = 1.15505015, grad/param norm = 2.0824e-01, time/batch = 17.4367s	
7139/22950 (epoch 15.553), train_loss = 1.13749886, grad/param norm = 2.1596e-01, time/batch = 18.3502s	
7140/22950 (epoch 15.556), train_loss = 1.21147074, grad/param norm = 1.9760e-01, time/batch = 19.6982s	
7141/22950 (epoch 15.558), train_loss = 1.07070410, grad/param norm = 1.8822e-01, time/batch = 19.1215s	
7142/22950 (epoch 15.560), train_loss = 1.18563963, grad/param norm = 1.9866e-01, time/batch = 18.1198s	
7143/22950 (epoch 15.562), train_loss = 1.05837420, grad/param norm = 1.8115e-01, time/batch = 20.2989s	
7144/22950 (epoch 15.564), train_loss = 1.29524844, grad/param norm = 2.3005e-01, time/batch = 19.0454s	
7145/22950 (epoch 15.566), train_loss = 1.20494158, grad/param norm = 2.1402e-01, time/batch = 18.0301s	
7146/22950 (epoch 15.569), train_loss = 1.26503320, grad/param norm = 2.0895e-01, time/batch = 17.5650s	
7147/22950 (epoch 15.571), train_loss = 1.09137530, grad/param norm = 2.0588e-01, time/batch = 18.9643s	
7148/22950 (epoch 15.573), train_loss = 1.18966818, grad/param norm = 2.0658e-01, time/batch = 17.4452s	
7149/22950 (epoch 15.575), train_loss = 1.32991221, grad/param norm = 2.2376e-01, time/batch = 15.4444s	
7150/22950 (epoch 15.577), train_loss = 1.16416338, grad/param norm = 2.1990e-01, time/batch = 17.7246s	
7151/22950 (epoch 15.580), train_loss = 1.21575307, grad/param norm = 2.1426e-01, time/batch = 18.6987s	
7152/22950 (epoch 15.582), train_loss = 1.37363480, grad/param norm = 2.0985e-01, time/batch = 17.9780s	
7153/22950 (epoch 15.584), train_loss = 1.07240032, grad/param norm = 1.9442e-01, time/batch = 17.0708s	
7154/22950 (epoch 15.586), train_loss = 1.13987226, grad/param norm = 2.2620e-01, time/batch = 19.3815s	
7155/22950 (epoch 15.588), train_loss = 1.28738223, grad/param norm = 2.0338e-01, time/batch = 18.6189s	
7156/22950 (epoch 15.590), train_loss = 1.16764387, grad/param norm = 1.9746e-01, time/batch = 17.9453s	
7157/22950 (epoch 15.593), train_loss = 1.07812229, grad/param norm = 1.9657e-01, time/batch = 15.4466s	
7158/22950 (epoch 15.595), train_loss = 1.04747116, grad/param norm = 1.9949e-01, time/batch = 17.3754s	
7159/22950 (epoch 15.597), train_loss = 1.23560262, grad/param norm = 2.0777e-01, time/batch = 18.5577s	
7160/22950 (epoch 15.599), train_loss = 1.21443360, grad/param norm = 2.1990e-01, time/batch = 17.8902s	
7161/22950 (epoch 15.601), train_loss = 1.18568821, grad/param norm = 2.1720e-01, time/batch = 18.7858s	
7162/22950 (epoch 15.603), train_loss = 1.31163630, grad/param norm = 2.0346e-01, time/batch = 17.9268s	
7163/22950 (epoch 15.606), train_loss = 1.14962056, grad/param norm = 1.9828e-01, time/batch = 19.3027s	
7164/22950 (epoch 15.608), train_loss = 1.20554725, grad/param norm = 2.0503e-01, time/batch = 17.3716s	
7165/22950 (epoch 15.610), train_loss = 1.13851189, grad/param norm = 1.9292e-01, time/batch = 20.1126s	
7166/22950 (epoch 15.612), train_loss = 1.15893543, grad/param norm = 2.0661e-01, time/batch = 17.6983s	
7167/22950 (epoch 15.614), train_loss = 1.30907037, grad/param norm = 2.2554e-01, time/batch = 18.1231s	
7168/22950 (epoch 15.617), train_loss = 1.16051986, grad/param norm = 2.0423e-01, time/batch = 18.3742s	
7169/22950 (epoch 15.619), train_loss = 1.08831035, grad/param norm = 1.7250e-01, time/batch = 17.5679s	
7170/22950 (epoch 15.621), train_loss = 1.27013681, grad/param norm = 1.8128e-01, time/batch = 18.6302s	
7171/22950 (epoch 15.623), train_loss = 1.23882947, grad/param norm = 1.7981e-01, time/batch = 17.2044s	
7172/22950 (epoch 15.625), train_loss = 1.16205257, grad/param norm = 1.9335e-01, time/batch = 20.2021s	
7173/22950 (epoch 15.627), train_loss = 1.16256618, grad/param norm = 1.9956e-01, time/batch = 19.5393s	
7174/22950 (epoch 15.630), train_loss = 1.03339349, grad/param norm = 1.9644e-01, time/batch = 17.9539s	
7175/22950 (epoch 15.632), train_loss = 1.17525134, grad/param norm = 2.1161e-01, time/batch = 16.0241s	
7176/22950 (epoch 15.634), train_loss = 1.16294562, grad/param norm = 1.9661e-01, time/batch = 18.4659s	
7177/22950 (epoch 15.636), train_loss = 1.22005449, grad/param norm = 2.1026e-01, time/batch = 20.5429s	
7178/22950 (epoch 15.638), train_loss = 1.08499316, grad/param norm = 1.9667e-01, time/batch = 17.5166s	
7179/22950 (epoch 15.641), train_loss = 1.12609376, grad/param norm = 1.8615e-01, time/batch = 18.7158s	
7180/22950 (epoch 15.643), train_loss = 1.21148846, grad/param norm = 2.2837e-01, time/batch = 19.1776s	
7181/22950 (epoch 15.645), train_loss = 1.10778763, grad/param norm = 1.9891e-01, time/batch = 18.4166s	
7182/22950 (epoch 15.647), train_loss = 1.15931250, grad/param norm = 2.0951e-01, time/batch = 19.8797s	
7183/22950 (epoch 15.649), train_loss = 1.16579674, grad/param norm = 1.9523e-01, time/batch = 17.1317s	
7184/22950 (epoch 15.651), train_loss = 1.25032342, grad/param norm = 2.2184e-01, time/batch = 18.1142s	
7185/22950 (epoch 15.654), train_loss = 0.99590613, grad/param norm = 1.9138e-01, time/batch = 19.3780s	
7186/22950 (epoch 15.656), train_loss = 1.30023037, grad/param norm = 2.3021e-01, time/batch = 20.2974s	
7187/22950 (epoch 15.658), train_loss = 1.08356713, grad/param norm = 2.0364e-01, time/batch = 18.2175s	
7188/22950 (epoch 15.660), train_loss = 0.99740418, grad/param norm = 1.8833e-01, time/batch = 19.3784s	
7189/22950 (epoch 15.662), train_loss = 0.99775917, grad/param norm = 1.6962e-01, time/batch = 19.4736s	
7190/22950 (epoch 15.664), train_loss = 1.16808918, grad/param norm = 2.0216e-01, time/batch = 18.2880s	
7191/22950 (epoch 15.667), train_loss = 1.18294260, grad/param norm = 1.9275e-01, time/batch = 16.0498s	
7192/22950 (epoch 15.669), train_loss = 1.13800491, grad/param norm = 1.9452e-01, time/batch = 19.2966s	
7193/22950 (epoch 15.671), train_loss = 1.18319112, grad/param norm = 2.0905e-01, time/batch = 19.3734s	
7194/22950 (epoch 15.673), train_loss = 1.12023796, grad/param norm = 1.9307e-01, time/batch = 18.4411s	
7195/22950 (epoch 15.675), train_loss = 1.15704810, grad/param norm = 2.1078e-01, time/batch = 18.5562s	
7196/22950 (epoch 15.678), train_loss = 1.17416406, grad/param norm = 2.1050e-01, time/batch = 16.6487s	
7197/22950 (epoch 15.680), train_loss = 1.17746156, grad/param norm = 1.8592e-01, time/batch = 17.3467s	
7198/22950 (epoch 15.682), train_loss = 1.22087470, grad/param norm = 2.0973e-01, time/batch = 19.6300s	
7199/22950 (epoch 15.684), train_loss = 1.28483652, grad/param norm = 2.4331e-01, time/batch = 19.6358s	
7200/22950 (epoch 15.686), train_loss = 1.26269090, grad/param norm = 2.1559e-01, time/batch = 18.2049s	
7201/22950 (epoch 15.688), train_loss = 1.17806292, grad/param norm = 2.0750e-01, time/batch = 19.2915s	
7202/22950 (epoch 15.691), train_loss = 1.17183228, grad/param norm = 1.9961e-01, time/batch = 17.1332s	
7203/22950 (epoch 15.693), train_loss = 1.08213738, grad/param norm = 1.9345e-01, time/batch = 18.6269s	
7204/22950 (epoch 15.695), train_loss = 1.29173416, grad/param norm = 2.1651e-01, time/batch = 18.7849s	
7205/22950 (epoch 15.697), train_loss = 1.26658646, grad/param norm = 2.3229e-01, time/batch = 19.6253s	
7206/22950 (epoch 15.699), train_loss = 1.24595630, grad/param norm = 2.1001e-01, time/batch = 18.3732s	
7207/22950 (epoch 15.702), train_loss = 1.24189501, grad/param norm = 1.9988e-01, time/batch = 15.0697s	
7208/22950 (epoch 15.704), train_loss = 1.25097669, grad/param norm = 2.0930e-01, time/batch = 18.8654s	
7209/22950 (epoch 15.706), train_loss = 1.25654558, grad/param norm = 2.3742e-01, time/batch = 19.3067s	
7210/22950 (epoch 15.708), train_loss = 1.08094063, grad/param norm = 1.9988e-01, time/batch = 17.3526s	
7211/22950 (epoch 15.710), train_loss = 1.21138539, grad/param norm = 1.9412e-01, time/batch = 18.2156s	
7212/22950 (epoch 15.712), train_loss = 1.29525713, grad/param norm = 2.0730e-01, time/batch = 18.6283s	
7213/22950 (epoch 15.715), train_loss = 1.23227910, grad/param norm = 2.1924e-01, time/batch = 16.6160s	
7214/22950 (epoch 15.717), train_loss = 1.12912079, grad/param norm = 1.8593e-01, time/batch = 17.6350s	
7215/22950 (epoch 15.719), train_loss = 1.15306311, grad/param norm = 2.2185e-01, time/batch = 15.6925s	
7216/22950 (epoch 15.721), train_loss = 1.22713077, grad/param norm = 2.0430e-01, time/batch = 19.3781s	
7217/22950 (epoch 15.723), train_loss = 1.11065338, grad/param norm = 1.8761e-01, time/batch = 18.2738s	
7218/22950 (epoch 15.725), train_loss = 1.23051115, grad/param norm = 2.0396e-01, time/batch = 17.3018s	
7219/22950 (epoch 15.728), train_loss = 1.16165447, grad/param norm = 2.3081e-01, time/batch = 19.8822s	
7220/22950 (epoch 15.730), train_loss = 1.17966900, grad/param norm = 2.0888e-01, time/batch = 16.6243s	
7221/22950 (epoch 15.732), train_loss = 1.22895453, grad/param norm = 2.0305e-01, time/batch = 17.4671s	
7222/22950 (epoch 15.734), train_loss = 1.20582306, grad/param norm = 2.1720e-01, time/batch = 19.8062s	
7223/22950 (epoch 15.736), train_loss = 1.15192940, grad/param norm = 1.9657e-01, time/batch = 17.2114s	
7224/22950 (epoch 15.739), train_loss = 1.23688412, grad/param norm = 2.1094e-01, time/batch = 18.5468s	
7225/22950 (epoch 15.741), train_loss = 1.23583449, grad/param norm = 1.9989e-01, time/batch = 19.2111s	
7226/22950 (epoch 15.743), train_loss = 1.33582757, grad/param norm = 2.0902e-01, time/batch = 16.7820s	
7227/22950 (epoch 15.745), train_loss = 1.41925921, grad/param norm = 2.1100e-01, time/batch = 18.7705s	
7228/22950 (epoch 15.747), train_loss = 1.20659794, grad/param norm = 2.0578e-01, time/batch = 18.3131s	
7229/22950 (epoch 15.749), train_loss = 1.09784850, grad/param norm = 2.0316e-01, time/batch = 17.1360s	
7230/22950 (epoch 15.752), train_loss = 1.38102191, grad/param norm = 2.1680e-01, time/batch = 17.9419s	
7231/22950 (epoch 15.754), train_loss = 1.28496426, grad/param norm = 2.1002e-01, time/batch = 17.8025s	
7232/22950 (epoch 15.756), train_loss = 1.11009317, grad/param norm = 2.1738e-01, time/batch = 19.5513s	
7233/22950 (epoch 15.758), train_loss = 1.12553739, grad/param norm = 1.8698e-01, time/batch = 16.8845s	
7234/22950 (epoch 15.760), train_loss = 1.23262526, grad/param norm = 2.0802e-01, time/batch = 19.3865s	
7235/22950 (epoch 15.763), train_loss = 1.24547112, grad/param norm = 2.2077e-01, time/batch = 19.4706s	
7236/22950 (epoch 15.765), train_loss = 1.22270920, grad/param norm = 2.0848e-01, time/batch = 18.2866s	
7237/22950 (epoch 15.767), train_loss = 1.36704062, grad/param norm = 2.0647e-01, time/batch = 18.9658s	
7238/22950 (epoch 15.769), train_loss = 1.21183471, grad/param norm = 2.0200e-01, time/batch = 18.8189s	
7239/22950 (epoch 15.771), train_loss = 1.06855082, grad/param norm = 1.9802e-01, time/batch = 18.4224s	
7240/22950 (epoch 15.773), train_loss = 0.90535990, grad/param norm = 1.7900e-01, time/batch = 18.9508s	
7241/22950 (epoch 15.776), train_loss = 1.09316034, grad/param norm = 1.9169e-01, time/batch = 18.5455s	
7242/22950 (epoch 15.778), train_loss = 1.03684982, grad/param norm = 1.8567e-01, time/batch = 19.2157s	
7243/22950 (epoch 15.780), train_loss = 1.13880050, grad/param norm = 1.7972e-01, time/batch = 16.5357s	
7244/22950 (epoch 15.782), train_loss = 1.16251705, grad/param norm = 1.8721e-01, time/batch = 18.2118s	
7245/22950 (epoch 15.784), train_loss = 1.15588911, grad/param norm = 1.9950e-01, time/batch = 18.4704s	
7246/22950 (epoch 15.786), train_loss = 1.23509088, grad/param norm = 1.9231e-01, time/batch = 16.9412s	
7247/22950 (epoch 15.789), train_loss = 1.03342773, grad/param norm = 1.8844e-01, time/batch = 16.7203s	
7248/22950 (epoch 15.791), train_loss = 1.05641470, grad/param norm = 2.0074e-01, time/batch = 17.6123s	
7249/22950 (epoch 15.793), train_loss = 1.38931278, grad/param norm = 2.1042e-01, time/batch = 18.4576s	
7250/22950 (epoch 15.795), train_loss = 1.12437796, grad/param norm = 1.8675e-01, time/batch = 19.5522s	
7251/22950 (epoch 15.797), train_loss = 1.32584305, grad/param norm = 2.1236e-01, time/batch = 18.7953s	
7252/22950 (epoch 15.800), train_loss = 1.07535874, grad/param norm = 1.8853e-01, time/batch = 19.6085s	
7253/22950 (epoch 15.802), train_loss = 1.08461646, grad/param norm = 2.0672e-01, time/batch = 19.9694s	
7254/22950 (epoch 15.804), train_loss = 1.14221859, grad/param norm = 1.9220e-01, time/batch = 19.2212s	
7255/22950 (epoch 15.806), train_loss = 1.04442747, grad/param norm = 1.9960e-01, time/batch = 19.1129s	
7256/22950 (epoch 15.808), train_loss = 1.14954326, grad/param norm = 1.9018e-01, time/batch = 19.3706s	
7257/22950 (epoch 15.810), train_loss = 1.12627253, grad/param norm = 2.0164e-01, time/batch = 19.7055s	
7258/22950 (epoch 15.813), train_loss = 0.95202112, grad/param norm = 1.8544e-01, time/batch = 19.4648s	
7259/22950 (epoch 15.815), train_loss = 1.03237430, grad/param norm = 1.8861e-01, time/batch = 18.0309s	
7260/22950 (epoch 15.817), train_loss = 1.03688432, grad/param norm = 1.8235e-01, time/batch = 16.5377s	
7261/22950 (epoch 15.819), train_loss = 1.14944757, grad/param norm = 2.0093e-01, time/batch = 19.7821s	
7262/22950 (epoch 15.821), train_loss = 1.13354523, grad/param norm = 2.1082e-01, time/batch = 17.4411s	
7263/22950 (epoch 15.824), train_loss = 1.15965112, grad/param norm = 2.2051e-01, time/batch = 19.1407s	
7264/22950 (epoch 15.826), train_loss = 1.29035781, grad/param norm = 2.2251e-01, time/batch = 18.0585s	
7265/22950 (epoch 15.828), train_loss = 1.14379619, grad/param norm = 2.0053e-01, time/batch = 18.6347s	
7266/22950 (epoch 15.830), train_loss = 1.17662853, grad/param norm = 1.9569e-01, time/batch = 18.3651s	
7267/22950 (epoch 15.832), train_loss = 1.17478099, grad/param norm = 1.9002e-01, time/batch = 17.2681s	
7268/22950 (epoch 15.834), train_loss = 1.00216033, grad/param norm = 1.9584e-01, time/batch = 19.0379s	
7269/22950 (epoch 15.837), train_loss = 1.19102705, grad/param norm = 2.0585e-01, time/batch = 19.4575s	
7270/22950 (epoch 15.839), train_loss = 1.01459418, grad/param norm = 1.8199e-01, time/batch = 18.6372s	
7271/22950 (epoch 15.841), train_loss = 1.08146126, grad/param norm = 1.8341e-01, time/batch = 19.8626s	
7272/22950 (epoch 15.843), train_loss = 1.11381002, grad/param norm = 2.0006e-01, time/batch = 18.4438s	
7273/22950 (epoch 15.845), train_loss = 1.17361372, grad/param norm = 2.0505e-01, time/batch = 19.6404s	
7274/22950 (epoch 15.847), train_loss = 1.23364792, grad/param norm = 2.0702e-01, time/batch = 20.4632s	
7275/22950 (epoch 15.850), train_loss = 1.20268182, grad/param norm = 2.0909e-01, time/batch = 18.6032s	
7276/22950 (epoch 15.852), train_loss = 1.19794787, grad/param norm = 1.9750e-01, time/batch = 17.7801s	
7277/22950 (epoch 15.854), train_loss = 1.14092036, grad/param norm = 1.9713e-01, time/batch = 16.1878s	
7278/22950 (epoch 15.856), train_loss = 1.36339672, grad/param norm = 2.3616e-01, time/batch = 17.8910s	
7279/22950 (epoch 15.858), train_loss = 1.22511168, grad/param norm = 1.8883e-01, time/batch = 20.0415s	
7280/22950 (epoch 15.861), train_loss = 1.26180310, grad/param norm = 2.0269e-01, time/batch = 18.2154s	
7281/22950 (epoch 15.863), train_loss = 1.31893623, grad/param norm = 2.2309e-01, time/batch = 19.0243s	
7282/22950 (epoch 15.865), train_loss = 1.32185390, grad/param norm = 2.1111e-01, time/batch = 18.7227s	
7283/22950 (epoch 15.867), train_loss = 1.21558956, grad/param norm = 2.2178e-01, time/batch = 19.9653s	
7284/22950 (epoch 15.869), train_loss = 1.36820104, grad/param norm = 2.2529e-01, time/batch = 18.2939s	
7285/22950 (epoch 15.871), train_loss = 1.18039702, grad/param norm = 2.1496e-01, time/batch = 19.9539s	
7286/22950 (epoch 15.874), train_loss = 1.17569425, grad/param norm = 2.0981e-01, time/batch = 18.7879s	
7287/22950 (epoch 15.876), train_loss = 1.23866898, grad/param norm = 2.1075e-01, time/batch = 18.3651s	
7288/22950 (epoch 15.878), train_loss = 1.12387921, grad/param norm = 2.2330e-01, time/batch = 19.0442s	
7289/22950 (epoch 15.880), train_loss = 1.34155940, grad/param norm = 2.1717e-01, time/batch = 18.8878s	
7290/22950 (epoch 15.882), train_loss = 1.06046915, grad/param norm = 1.9304e-01, time/batch = 19.5597s	
7291/22950 (epoch 15.885), train_loss = 1.21615935, grad/param norm = 2.1328e-01, time/batch = 16.8283s	
7292/22950 (epoch 15.887), train_loss = 1.20538921, grad/param norm = 2.0480e-01, time/batch = 18.9503s	
7293/22950 (epoch 15.889), train_loss = 1.25152667, grad/param norm = 2.2535e-01, time/batch = 18.9715s	
7294/22950 (epoch 15.891), train_loss = 1.15328644, grad/param norm = 2.1276e-01, time/batch = 16.3599s	
7295/22950 (epoch 15.893), train_loss = 1.23580254, grad/param norm = 2.0773e-01, time/batch = 19.7269s	
7296/22950 (epoch 15.895), train_loss = 1.36837358, grad/param norm = 2.1651e-01, time/batch = 20.2902s	
7297/22950 (epoch 15.898), train_loss = 1.16520544, grad/param norm = 2.0031e-01, time/batch = 18.6976s	
7298/22950 (epoch 15.900), train_loss = 1.09973922, grad/param norm = 1.7844e-01, time/batch = 17.9580s	
7299/22950 (epoch 15.902), train_loss = 1.24038116, grad/param norm = 2.0045e-01, time/batch = 19.3011s	
7300/22950 (epoch 15.904), train_loss = 1.22110945, grad/param norm = 2.0192e-01, time/batch = 16.9406s	
7301/22950 (epoch 15.906), train_loss = 1.18317524, grad/param norm = 1.9202e-01, time/batch = 18.7135s	
7302/22950 (epoch 15.908), train_loss = 1.07341912, grad/param norm = 1.9042e-01, time/batch = 16.8974s	
7303/22950 (epoch 15.911), train_loss = 1.02658030, grad/param norm = 1.9486e-01, time/batch = 16.1528s	
7304/22950 (epoch 15.913), train_loss = 1.09108248, grad/param norm = 2.0347e-01, time/batch = 18.1275s	
7305/22950 (epoch 15.915), train_loss = 1.27599114, grad/param norm = 2.1458e-01, time/batch = 17.9859s	
7306/22950 (epoch 15.917), train_loss = 1.04132002, grad/param norm = 1.8476e-01, time/batch = 18.0633s	
7307/22950 (epoch 15.919), train_loss = 1.11793264, grad/param norm = 1.9897e-01, time/batch = 24.6898s	
7308/22950 (epoch 15.922), train_loss = 1.18315006, grad/param norm = 2.1801e-01, time/batch = 22.4073s	
7309/22950 (epoch 15.924), train_loss = 1.22659069, grad/param norm = 1.9808e-01, time/batch = 16.1013s	
7310/22950 (epoch 15.926), train_loss = 1.01459221, grad/param norm = 1.9982e-01, time/batch = 16.9491s	
7311/22950 (epoch 15.928), train_loss = 1.03108176, grad/param norm = 1.9541e-01, time/batch = 18.8909s	
7312/22950 (epoch 15.930), train_loss = 1.02672174, grad/param norm = 1.9569e-01, time/batch = 20.2191s	
7313/22950 (epoch 15.932), train_loss = 0.98051234, grad/param norm = 1.7992e-01, time/batch = 18.4634s	
7314/22950 (epoch 15.935), train_loss = 1.17720846, grad/param norm = 1.9052e-01, time/batch = 19.6323s	
7315/22950 (epoch 15.937), train_loss = 1.19070239, grad/param norm = 2.1380e-01, time/batch = 17.2188s	
7316/22950 (epoch 15.939), train_loss = 1.10507574, grad/param norm = 2.0567e-01, time/batch = 18.7894s	
7317/22950 (epoch 15.941), train_loss = 1.07746194, grad/param norm = 1.8859e-01, time/batch = 18.8594s	
7318/22950 (epoch 15.943), train_loss = 1.17773738, grad/param norm = 2.1179e-01, time/batch = 16.7949s	
7319/22950 (epoch 15.946), train_loss = 1.04101791, grad/param norm = 2.1132e-01, time/batch = 19.2810s	
7320/22950 (epoch 15.948), train_loss = 1.22163103, grad/param norm = 1.9639e-01, time/batch = 19.3783s	
7321/22950 (epoch 15.950), train_loss = 1.17816656, grad/param norm = 2.2313e-01, time/batch = 18.7989s	
7322/22950 (epoch 15.952), train_loss = 1.20255918, grad/param norm = 2.0974e-01, time/batch = 19.6393s	
7323/22950 (epoch 15.954), train_loss = 1.19300450, grad/param norm = 2.0769e-01, time/batch = 16.2072s	
7324/22950 (epoch 15.956), train_loss = 1.08802650, grad/param norm = 1.8995e-01, time/batch = 19.1380s	
7325/22950 (epoch 15.959), train_loss = 1.06137407, grad/param norm = 1.9360e-01, time/batch = 19.1342s	
7326/22950 (epoch 15.961), train_loss = 1.17964904, grad/param norm = 2.0817e-01, time/batch = 17.3468s	
7327/22950 (epoch 15.963), train_loss = 1.20796109, grad/param norm = 2.1390e-01, time/batch = 18.4645s	
7328/22950 (epoch 15.965), train_loss = 1.32837344, grad/param norm = 2.1492e-01, time/batch = 20.0392s	
7329/22950 (epoch 15.967), train_loss = 1.14723032, grad/param norm = 2.1657e-01, time/batch = 17.7957s	
7330/22950 (epoch 15.969), train_loss = 1.07073328, grad/param norm = 1.9836e-01, time/batch = 20.8715s	
7331/22950 (epoch 15.972), train_loss = 1.15984400, grad/param norm = 1.9304e-01, time/batch = 16.1592s	
7332/22950 (epoch 15.974), train_loss = 1.11868709, grad/param norm = 2.0565e-01, time/batch = 19.3598s	
7333/22950 (epoch 15.976), train_loss = 1.05373967, grad/param norm = 1.9833e-01, time/batch = 20.2092s	
7334/22950 (epoch 15.978), train_loss = 1.13030423, grad/param norm = 1.9422e-01, time/batch = 17.7202s	
7335/22950 (epoch 15.980), train_loss = 1.16272448, grad/param norm = 1.9705e-01, time/batch = 18.9453s	
7336/22950 (epoch 15.983), train_loss = 1.13102606, grad/param norm = 1.9257e-01, time/batch = 19.2241s	
7337/22950 (epoch 15.985), train_loss = 1.02970019, grad/param norm = 1.8913e-01, time/batch = 18.1424s	
7338/22950 (epoch 15.987), train_loss = 1.05319240, grad/param norm = 1.9126e-01, time/batch = 18.9756s	
7339/22950 (epoch 15.989), train_loss = 1.16975143, grad/param norm = 2.0423e-01, time/batch = 16.8705s	
7340/22950 (epoch 15.991), train_loss = 1.00063225, grad/param norm = 1.9172e-01, time/batch = 17.3171s	
7341/22950 (epoch 15.993), train_loss = 1.17140144, grad/param norm = 2.0638e-01, time/batch = 17.8054s	
7342/22950 (epoch 15.996), train_loss = 1.22800097, grad/param norm = 2.2386e-01, time/batch = 17.2899s	
7343/22950 (epoch 15.998), train_loss = 1.10361583, grad/param norm = 2.0454e-01, time/batch = 17.5450s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
7344/22950 (epoch 16.000), train_loss = 1.00085854, grad/param norm = 1.8630e-01, time/batch = 19.9691s	
7345/22950 (epoch 16.002), train_loss = 1.33643853, grad/param norm = 2.1214e-01, time/batch = 19.6193s	
7346/22950 (epoch 16.004), train_loss = 1.18604913, grad/param norm = 1.9519e-01, time/batch = 19.1209s	
7347/22950 (epoch 16.007), train_loss = 1.16081988, grad/param norm = 2.1103e-01, time/batch = 17.5146s	
7348/22950 (epoch 16.009), train_loss = 1.30542473, grad/param norm = 2.2187e-01, time/batch = 17.8588s	
7349/22950 (epoch 16.011), train_loss = 1.04974788, grad/param norm = 1.9752e-01, time/batch = 18.3611s	
7350/22950 (epoch 16.013), train_loss = 1.21455823, grad/param norm = 2.0997e-01, time/batch = 19.3761s	
7351/22950 (epoch 16.015), train_loss = 1.24455473, grad/param norm = 2.1711e-01, time/batch = 17.7550s	
7352/22950 (epoch 16.017), train_loss = 1.18308417, grad/param norm = 1.9097e-01, time/batch = 18.8687s	
7353/22950 (epoch 16.020), train_loss = 1.15023003, grad/param norm = 1.7572e-01, time/batch = 19.1423s	
7354/22950 (epoch 16.022), train_loss = 1.00887165, grad/param norm = 1.8792e-01, time/batch = 18.0426s	
7355/22950 (epoch 16.024), train_loss = 1.09137864, grad/param norm = 1.9290e-01, time/batch = 17.6147s	
7356/22950 (epoch 16.026), train_loss = 1.19154158, grad/param norm = 2.0019e-01, time/batch = 17.6302s	
7357/22950 (epoch 16.028), train_loss = 1.24161689, grad/param norm = 1.8856e-01, time/batch = 18.3803s	
7358/22950 (epoch 16.031), train_loss = 1.13912927, grad/param norm = 1.9828e-01, time/batch = 17.4411s	
7359/22950 (epoch 16.033), train_loss = 1.29519220, grad/param norm = 2.1222e-01, time/batch = 18.5462s	
7360/22950 (epoch 16.035), train_loss = 1.14614713, grad/param norm = 1.8258e-01, time/batch = 19.7856s	
7361/22950 (epoch 16.037), train_loss = 1.13310724, grad/param norm = 1.9429e-01, time/batch = 19.0407s	
7362/22950 (epoch 16.039), train_loss = 1.11030809, grad/param norm = 1.8904e-01, time/batch = 17.3053s	
7363/22950 (epoch 16.041), train_loss = 1.13550624, grad/param norm = 1.9976e-01, time/batch = 17.2677s	
7364/22950 (epoch 16.044), train_loss = 1.17697685, grad/param norm = 2.0579e-01, time/batch = 17.3217s	
7365/22950 (epoch 16.046), train_loss = 1.17066897, grad/param norm = 1.9329e-01, time/batch = 18.3772s	
7366/22950 (epoch 16.048), train_loss = 1.17021861, grad/param norm = 2.0117e-01, time/batch = 18.6823s	
7367/22950 (epoch 16.050), train_loss = 1.16805839, grad/param norm = 2.1012e-01, time/batch = 18.0553s	
7368/22950 (epoch 16.052), train_loss = 1.19019489, grad/param norm = 1.8787e-01, time/batch = 16.7900s	
7369/22950 (epoch 16.054), train_loss = 1.36644985, grad/param norm = 2.1966e-01, time/batch = 19.8807s	
7370/22950 (epoch 16.057), train_loss = 1.27539033, grad/param norm = 2.0519e-01, time/batch = 18.8792s	
7371/22950 (epoch 16.059), train_loss = 1.22986098, grad/param norm = 2.0452e-01, time/batch = 17.9364s	
7372/22950 (epoch 16.061), train_loss = 1.07138712, grad/param norm = 1.9055e-01, time/batch = 19.3723s	
7373/22950 (epoch 16.063), train_loss = 1.22247972, grad/param norm = 1.9365e-01, time/batch = 17.3899s	
7374/22950 (epoch 16.065), train_loss = 0.94415183, grad/param norm = 1.8263e-01, time/batch = 17.4137s	
7375/22950 (epoch 16.068), train_loss = 1.23347033, grad/param norm = 1.9790e-01, time/batch = 18.3390s	
7376/22950 (epoch 16.070), train_loss = 1.05179764, grad/param norm = 1.9482e-01, time/batch = 18.7994s	
7377/22950 (epoch 16.072), train_loss = 1.21132396, grad/param norm = 1.9649e-01, time/batch = 19.7214s	
7378/22950 (epoch 16.074), train_loss = 1.14745387, grad/param norm = 2.0936e-01, time/batch = 17.9593s	
7379/22950 (epoch 16.076), train_loss = 1.16940859, grad/param norm = 1.9652e-01, time/batch = 19.6389s	
7380/22950 (epoch 16.078), train_loss = 1.23567152, grad/param norm = 2.0111e-01, time/batch = 19.1072s	
7381/22950 (epoch 16.081), train_loss = 1.24644058, grad/param norm = 2.0435e-01, time/batch = 19.1003s	
7382/22950 (epoch 16.083), train_loss = 1.11927024, grad/param norm = 1.9395e-01, time/batch = 18.2946s	
7383/22950 (epoch 16.085), train_loss = 1.05587450, grad/param norm = 2.0736e-01, time/batch = 20.2035s	
7384/22950 (epoch 16.087), train_loss = 1.06188062, grad/param norm = 1.9725e-01, time/batch = 17.3761s	
7385/22950 (epoch 16.089), train_loss = 1.16215480, grad/param norm = 1.8043e-01, time/batch = 15.7861s	
7386/22950 (epoch 16.092), train_loss = 1.10103855, grad/param norm = 2.1164e-01, time/batch = 19.2116s	
7387/22950 (epoch 16.094), train_loss = 1.08867008, grad/param norm = 1.8629e-01, time/batch = 19.3694s	
7388/22950 (epoch 16.096), train_loss = 1.29985083, grad/param norm = 2.0713e-01, time/batch = 18.9652s	
7389/22950 (epoch 16.098), train_loss = 1.20394730, grad/param norm = 1.9322e-01, time/batch = 17.7194s	
7390/22950 (epoch 16.100), train_loss = 1.12103452, grad/param norm = 2.1126e-01, time/batch = 18.4528s	
7391/22950 (epoch 16.102), train_loss = 1.16310577, grad/param norm = 1.9482e-01, time/batch = 18.8627s	
7392/22950 (epoch 16.105), train_loss = 1.03685588, grad/param norm = 1.7961e-01, time/batch = 18.6233s	
7393/22950 (epoch 16.107), train_loss = 1.10381494, grad/param norm = 1.8859e-01, time/batch = 19.7943s	
7394/22950 (epoch 16.109), train_loss = 1.10955826, grad/param norm = 2.2777e-01, time/batch = 18.0169s	
7395/22950 (epoch 16.111), train_loss = 1.00627738, grad/param norm = 1.8854e-01, time/batch = 19.1224s	
7396/22950 (epoch 16.113), train_loss = 1.17855654, grad/param norm = 1.9735e-01, time/batch = 15.9533s	
7397/22950 (epoch 16.115), train_loss = 1.20242057, grad/param norm = 1.9938e-01, time/batch = 18.1980s	
7398/22950 (epoch 16.118), train_loss = 1.27876519, grad/param norm = 1.9703e-01, time/batch = 20.6236s	
7399/22950 (epoch 16.120), train_loss = 1.08054663, grad/param norm = 1.9379e-01, time/batch = 18.1243s	
7400/22950 (epoch 16.122), train_loss = 1.26761357, grad/param norm = 2.0896e-01, time/batch = 18.6208s	
7401/22950 (epoch 16.124), train_loss = 0.98121657, grad/param norm = 1.6409e-01, time/batch = 19.9471s	
7402/22950 (epoch 16.126), train_loss = 1.11361786, grad/param norm = 1.9153e-01, time/batch = 19.4647s	
7403/22950 (epoch 16.129), train_loss = 0.99707726, grad/param norm = 1.7622e-01, time/batch = 18.9462s	
7404/22950 (epoch 16.131), train_loss = 1.11413514, grad/param norm = 1.9473e-01, time/batch = 2.9594s	
7405/22950 (epoch 16.133), train_loss = 1.19490374, grad/param norm = 2.0164e-01, time/batch = 0.6874s	
7406/22950 (epoch 16.135), train_loss = 1.12805582, grad/param norm = 1.8083e-01, time/batch = 0.7018s	
7407/22950 (epoch 16.137), train_loss = 1.28393132, grad/param norm = 2.1682e-01, time/batch = 0.7007s	
7408/22950 (epoch 16.139), train_loss = 1.07099232, grad/param norm = 2.0106e-01, time/batch = 0.6862s	
7409/22950 (epoch 16.142), train_loss = 1.06678957, grad/param norm = 1.8910e-01, time/batch = 0.6877s	
7410/22950 (epoch 16.144), train_loss = 1.04412839, grad/param norm = 1.7785e-01, time/batch = 0.6886s	
7411/22950 (epoch 16.146), train_loss = 1.11855268, grad/param norm = 2.0603e-01, time/batch = 0.9268s	
7412/22950 (epoch 16.148), train_loss = 1.09718136, grad/param norm = 1.8749e-01, time/batch = 1.0082s	
7413/22950 (epoch 16.150), train_loss = 1.17114730, grad/param norm = 2.2205e-01, time/batch = 1.0149s	
7414/22950 (epoch 16.153), train_loss = 1.09368083, grad/param norm = 1.9738e-01, time/batch = 1.0133s	
7415/22950 (epoch 16.155), train_loss = 1.08378726, grad/param norm = 1.7862e-01, time/batch = 1.0084s	
7416/22950 (epoch 16.157), train_loss = 1.09602413, grad/param norm = 2.0291e-01, time/batch = 1.6907s	
7417/22950 (epoch 16.159), train_loss = 1.04493648, grad/param norm = 1.7961e-01, time/batch = 1.8933s	
7418/22950 (epoch 16.161), train_loss = 1.09175305, grad/param norm = 1.8309e-01, time/batch = 4.7090s	
7419/22950 (epoch 16.163), train_loss = 1.02225352, grad/param norm = 1.8917e-01, time/batch = 19.4479s	
7420/22950 (epoch 16.166), train_loss = 1.30363224, grad/param norm = 2.5804e-01, time/batch = 17.4586s	
7421/22950 (epoch 16.168), train_loss = 1.24703799, grad/param norm = 2.2340e-01, time/batch = 18.9690s	
7422/22950 (epoch 16.170), train_loss = 1.17178079, grad/param norm = 2.1943e-01, time/batch = 19.3760s	
7423/22950 (epoch 16.172), train_loss = 1.15472796, grad/param norm = 1.7845e-01, time/batch = 16.4478s	
7424/22950 (epoch 16.174), train_loss = 1.23740393, grad/param norm = 2.2785e-01, time/batch = 18.2762s	
7425/22950 (epoch 16.176), train_loss = 1.26884461, grad/param norm = 2.0431e-01, time/batch = 16.9848s	
7426/22950 (epoch 16.179), train_loss = 1.21770841, grad/param norm = 2.1263e-01, time/batch = 17.8100s	
7427/22950 (epoch 16.181), train_loss = 1.40110593, grad/param norm = 2.1596e-01, time/batch = 16.2105s	
7428/22950 (epoch 16.183), train_loss = 1.24880732, grad/param norm = 2.1462e-01, time/batch = 19.9607s	
7429/22950 (epoch 16.185), train_loss = 1.20350928, grad/param norm = 2.0816e-01, time/batch = 18.5409s	
7430/22950 (epoch 16.187), train_loss = 1.07483606, grad/param norm = 2.1106e-01, time/batch = 16.5942s	
7431/22950 (epoch 16.190), train_loss = 1.00149192, grad/param norm = 2.0112e-01, time/batch = 18.9503s	
7432/22950 (epoch 16.192), train_loss = 1.00865055, grad/param norm = 1.8241e-01, time/batch = 19.3698s	
7433/22950 (epoch 16.194), train_loss = 1.08720237, grad/param norm = 2.0877e-01, time/batch = 19.4731s	
7434/22950 (epoch 16.196), train_loss = 0.96559538, grad/param norm = 1.9080e-01, time/batch = 15.7567s	
7435/22950 (epoch 16.198), train_loss = 1.23875768, grad/param norm = 2.1619e-01, time/batch = 15.8921s	
7436/22950 (epoch 16.200), train_loss = 1.06016648, grad/param norm = 1.9025e-01, time/batch = 16.8572s	
7437/22950 (epoch 16.203), train_loss = 1.01440645, grad/param norm = 1.7949e-01, time/batch = 17.0479s	
7438/22950 (epoch 16.205), train_loss = 1.07001769, grad/param norm = 1.6971e-01, time/batch = 19.1341s	
7439/22950 (epoch 16.207), train_loss = 1.13255318, grad/param norm = 2.0649e-01, time/batch = 19.2837s	
7440/22950 (epoch 16.209), train_loss = 1.18713101, grad/param norm = 2.1130e-01, time/batch = 19.1131s	
7441/22950 (epoch 16.211), train_loss = 0.97944080, grad/param norm = 2.0828e-01, time/batch = 19.6207s	
7442/22950 (epoch 16.214), train_loss = 1.12345980, grad/param norm = 1.8209e-01, time/batch = 17.7995s	
7443/22950 (epoch 16.216), train_loss = 1.23167898, grad/param norm = 2.0720e-01, time/batch = 19.5523s	
7444/22950 (epoch 16.218), train_loss = 1.15180648, grad/param norm = 2.0796e-01, time/batch = 18.1888s	
7445/22950 (epoch 16.220), train_loss = 1.26594561, grad/param norm = 1.9785e-01, time/batch = 18.9609s	
7446/22950 (epoch 16.222), train_loss = 1.24700833, grad/param norm = 2.0255e-01, time/batch = 18.8759s	
7447/22950 (epoch 16.224), train_loss = 1.12909171, grad/param norm = 1.9870e-01, time/batch = 18.7883s	
7448/22950 (epoch 16.227), train_loss = 1.21908500, grad/param norm = 1.8671e-01, time/batch = 18.0503s	
7449/22950 (epoch 16.229), train_loss = 1.22065684, grad/param norm = 2.0541e-01, time/batch = 20.3597s	
7450/22950 (epoch 16.231), train_loss = 1.00733113, grad/param norm = 1.8044e-01, time/batch = 17.0323s	
7451/22950 (epoch 16.233), train_loss = 1.08304738, grad/param norm = 1.9826e-01, time/batch = 19.7928s	
7452/22950 (epoch 16.235), train_loss = 1.27633192, grad/param norm = 2.1266e-01, time/batch = 18.3092s	
7453/22950 (epoch 16.237), train_loss = 1.05016615, grad/param norm = 1.8418e-01, time/batch = 17.1299s	
7454/22950 (epoch 16.240), train_loss = 1.12699739, grad/param norm = 2.0390e-01, time/batch = 20.0319s	
7455/22950 (epoch 16.242), train_loss = 1.24296873, grad/param norm = 1.8790e-01, time/batch = 16.7096s	
7456/22950 (epoch 16.244), train_loss = 1.32783133, grad/param norm = 2.2761e-01, time/batch = 18.0151s	
7457/22950 (epoch 16.246), train_loss = 1.26498062, grad/param norm = 1.9401e-01, time/batch = 17.9560s	
7458/22950 (epoch 16.248), train_loss = 1.17879700, grad/param norm = 2.0899e-01, time/batch = 20.3005s	
7459/22950 (epoch 16.251), train_loss = 1.07653858, grad/param norm = 1.9687e-01, time/batch = 20.1156s	
7460/22950 (epoch 16.253), train_loss = 1.09520804, grad/param norm = 2.1561e-01, time/batch = 17.5117s	
7461/22950 (epoch 16.255), train_loss = 1.18545787, grad/param norm = 2.4384e-01, time/batch = 19.0496s	
7462/22950 (epoch 16.257), train_loss = 1.28386117, grad/param norm = 2.0762e-01, time/batch = 20.0485s	
7463/22950 (epoch 16.259), train_loss = 1.01311691, grad/param norm = 2.0128e-01, time/batch = 18.9488s	
7464/22950 (epoch 16.261), train_loss = 1.11563763, grad/param norm = 2.2346e-01, time/batch = 18.5518s	
7465/22950 (epoch 16.264), train_loss = 1.06411115, grad/param norm = 2.0720e-01, time/batch = 20.6236s	
7466/22950 (epoch 16.266), train_loss = 1.17663642, grad/param norm = 2.0354e-01, time/batch = 16.8678s	
7467/22950 (epoch 16.268), train_loss = 1.15328810, grad/param norm = 1.9198e-01, time/batch = 19.1275s	
7468/22950 (epoch 16.270), train_loss = 1.17450986, grad/param norm = 2.1849e-01, time/batch = 18.8034s	
7469/22950 (epoch 16.272), train_loss = 1.25457281, grad/param norm = 2.0381e-01, time/batch = 17.0429s	
7470/22950 (epoch 16.275), train_loss = 1.08705701, grad/param norm = 1.9433e-01, time/batch = 19.7981s	
7471/22950 (epoch 16.277), train_loss = 0.97952329, grad/param norm = 1.6930e-01, time/batch = 18.7139s	
7472/22950 (epoch 16.279), train_loss = 1.09890177, grad/param norm = 2.0379e-01, time/batch = 18.3672s	
7473/22950 (epoch 16.281), train_loss = 1.08967597, grad/param norm = 2.0082e-01, time/batch = 18.2142s	
7474/22950 (epoch 16.283), train_loss = 0.96156695, grad/param norm = 1.6311e-01, time/batch = 17.6047s	
7475/22950 (epoch 16.285), train_loss = 1.15020867, grad/param norm = 1.8676e-01, time/batch = 17.5212s	
7476/22950 (epoch 16.288), train_loss = 1.17294507, grad/param norm = 1.7800e-01, time/batch = 17.8248s	
7477/22950 (epoch 16.290), train_loss = 1.08511333, grad/param norm = 1.8200e-01, time/batch = 19.4700s	
7478/22950 (epoch 16.292), train_loss = 1.23303896, grad/param norm = 1.9680e-01, time/batch = 16.6264s	
7479/22950 (epoch 16.294), train_loss = 1.11787377, grad/param norm = 1.8379e-01, time/batch = 15.9277s	
7480/22950 (epoch 16.296), train_loss = 0.91458449, grad/param norm = 1.5669e-01, time/batch = 15.3797s	
7481/22950 (epoch 16.298), train_loss = 1.14613705, grad/param norm = 1.9157e-01, time/batch = 16.6051s	
7482/22950 (epoch 16.301), train_loss = 1.14862963, grad/param norm = 2.0052e-01, time/batch = 15.7787s	
7483/22950 (epoch 16.303), train_loss = 1.19129891, grad/param norm = 2.0729e-01, time/batch = 15.4004s	
7484/22950 (epoch 16.305), train_loss = 1.18392575, grad/param norm = 2.0232e-01, time/batch = 16.1855s	
7485/22950 (epoch 16.307), train_loss = 1.26061077, grad/param norm = 2.0634e-01, time/batch = 18.5277s	
7486/22950 (epoch 16.309), train_loss = 1.08387879, grad/param norm = 1.7678e-01, time/batch = 16.3215s	
7487/22950 (epoch 16.312), train_loss = 1.13408291, grad/param norm = 2.0635e-01, time/batch = 18.0562s	
7488/22950 (epoch 16.314), train_loss = 1.10442973, grad/param norm = 1.8684e-01, time/batch = 18.7157s	
7489/22950 (epoch 16.316), train_loss = 1.14373143, grad/param norm = 2.0532e-01, time/batch = 18.0527s	
7490/22950 (epoch 16.318), train_loss = 0.94549510, grad/param norm = 1.7821e-01, time/batch = 19.3516s	
7491/22950 (epoch 16.320), train_loss = 1.07965147, grad/param norm = 1.7729e-01, time/batch = 20.0410s	
7492/22950 (epoch 16.322), train_loss = 1.11664033, grad/param norm = 2.0676e-01, time/batch = 18.6198s	
7493/22950 (epoch 16.325), train_loss = 0.89856103, grad/param norm = 1.7389e-01, time/batch = 18.2028s	
7494/22950 (epoch 16.327), train_loss = 0.93496482, grad/param norm = 1.8739e-01, time/batch = 17.5275s	
7495/22950 (epoch 16.329), train_loss = 1.06338895, grad/param norm = 1.8445e-01, time/batch = 19.3770s	
7496/22950 (epoch 16.331), train_loss = 0.99613602, grad/param norm = 1.8849e-01, time/batch = 18.1254s	
7497/22950 (epoch 16.333), train_loss = 1.11236729, grad/param norm = 1.9424e-01, time/batch = 18.6251s	
7498/22950 (epoch 16.336), train_loss = 1.09948159, grad/param norm = 2.0238e-01, time/batch = 19.5357s	
7499/22950 (epoch 16.338), train_loss = 1.06859485, grad/param norm = 1.7771e-01, time/batch = 18.2941s	
7500/22950 (epoch 16.340), train_loss = 1.13356574, grad/param norm = 2.1429e-01, time/batch = 18.2032s	
7501/22950 (epoch 16.342), train_loss = 1.22932322, grad/param norm = 1.9505e-01, time/batch = 16.2679s	
7502/22950 (epoch 16.344), train_loss = 1.11633358, grad/param norm = 2.0953e-01, time/batch = 17.9479s	
7503/22950 (epoch 16.346), train_loss = 1.25223897, grad/param norm = 2.1109e-01, time/batch = 18.0113s	
7504/22950 (epoch 16.349), train_loss = 1.12751697, grad/param norm = 2.1655e-01, time/batch = 20.1202s	
7505/22950 (epoch 16.351), train_loss = 1.17332388, grad/param norm = 1.9578e-01, time/batch = 20.0488s	
7506/22950 (epoch 16.353), train_loss = 1.22973101, grad/param norm = 2.3394e-01, time/batch = 17.2904s	
7507/22950 (epoch 16.355), train_loss = 1.26901093, grad/param norm = 2.3037e-01, time/batch = 19.2248s	
7508/22950 (epoch 16.357), train_loss = 1.13706836, grad/param norm = 2.1697e-01, time/batch = 19.2220s	
7509/22950 (epoch 16.359), train_loss = 1.16272694, grad/param norm = 2.1930e-01, time/batch = 16.1015s	
7510/22950 (epoch 16.362), train_loss = 1.13935725, grad/param norm = 2.0874e-01, time/batch = 18.6133s	
7511/22950 (epoch 16.364), train_loss = 1.13446848, grad/param norm = 2.0636e-01, time/batch = 18.9607s	
7512/22950 (epoch 16.366), train_loss = 1.03298200, grad/param norm = 1.8110e-01, time/batch = 17.5613s	
7513/22950 (epoch 16.368), train_loss = 1.18213960, grad/param norm = 2.1635e-01, time/batch = 18.7999s	
7514/22950 (epoch 16.370), train_loss = 1.10425167, grad/param norm = 2.1420e-01, time/batch = 17.5606s	
7515/22950 (epoch 16.373), train_loss = 1.00792156, grad/param norm = 1.9111e-01, time/batch = 17.7879s	
7516/22950 (epoch 16.375), train_loss = 1.25356974, grad/param norm = 2.2433e-01, time/batch = 31.2858s	
7517/22950 (epoch 16.377), train_loss = 1.05037545, grad/param norm = 2.1173e-01, time/batch = 18.7974s	
7518/22950 (epoch 16.379), train_loss = 1.14946936, grad/param norm = 2.0296e-01, time/batch = 16.6335s	
7519/22950 (epoch 16.381), train_loss = 0.97908167, grad/param norm = 1.9502e-01, time/batch = 17.1195s	
7520/22950 (epoch 16.383), train_loss = 1.15370788, grad/param norm = 2.0671e-01, time/batch = 18.8812s	
7521/22950 (epoch 16.386), train_loss = 1.05942851, grad/param norm = 2.0097e-01, time/batch = 19.4509s	
7522/22950 (epoch 16.388), train_loss = 1.14185124, grad/param norm = 2.1877e-01, time/batch = 17.4635s	
7523/22950 (epoch 16.390), train_loss = 1.03338067, grad/param norm = 1.8232e-01, time/batch = 19.2159s	
7524/22950 (epoch 16.392), train_loss = 1.05786886, grad/param norm = 2.0125e-01, time/batch = 19.7900s	
7525/22950 (epoch 16.394), train_loss = 1.05700278, grad/param norm = 1.7886e-01, time/batch = 16.0045s	
7526/22950 (epoch 16.397), train_loss = 1.26509541, grad/param norm = 2.0409e-01, time/batch = 18.5379s	
7527/22950 (epoch 16.399), train_loss = 1.26011064, grad/param norm = 2.3472e-01, time/batch = 19.8019s	
7528/22950 (epoch 16.401), train_loss = 1.36414251, grad/param norm = 2.0567e-01, time/batch = 18.1120s	
7529/22950 (epoch 16.403), train_loss = 1.11710784, grad/param norm = 2.1497e-01, time/batch = 19.0390s	
7530/22950 (epoch 16.405), train_loss = 1.24565082, grad/param norm = 2.3006e-01, time/batch = 19.0490s	
7531/22950 (epoch 16.407), train_loss = 1.29998571, grad/param norm = 1.9446e-01, time/batch = 17.0218s	
7532/22950 (epoch 16.410), train_loss = 1.04510982, grad/param norm = 1.8693e-01, time/batch = 18.6893s	
7533/22950 (epoch 16.412), train_loss = 1.14677662, grad/param norm = 2.0937e-01, time/batch = 17.9675s	
7534/22950 (epoch 16.414), train_loss = 1.22969185, grad/param norm = 2.1188e-01, time/batch = 17.9243s	
7535/22950 (epoch 16.416), train_loss = 1.16765592, grad/param norm = 2.2040e-01, time/batch = 19.1711s	
7536/22950 (epoch 16.418), train_loss = 1.18418825, grad/param norm = 2.1728e-01, time/batch = 19.7000s	
7537/22950 (epoch 16.420), train_loss = 1.18626145, grad/param norm = 2.1367e-01, time/batch = 19.1270s	
7538/22950 (epoch 16.423), train_loss = 1.06543075, grad/param norm = 1.8446e-01, time/batch = 16.2326s	
7539/22950 (epoch 16.425), train_loss = 1.14758420, grad/param norm = 2.0550e-01, time/batch = 18.3830s	
7540/22950 (epoch 16.427), train_loss = 1.12970986, grad/param norm = 2.0533e-01, time/batch = 19.7950s	
7541/22950 (epoch 16.429), train_loss = 1.11033955, grad/param norm = 1.9679e-01, time/batch = 18.7031s	
7542/22950 (epoch 16.431), train_loss = 1.18621539, grad/param norm = 2.0096e-01, time/batch = 15.8530s	
7543/22950 (epoch 16.434), train_loss = 1.14231359, grad/param norm = 2.1029e-01, time/batch = 17.8742s	
7544/22950 (epoch 16.436), train_loss = 1.31808356, grad/param norm = 2.2203e-01, time/batch = 18.1063s	
7545/22950 (epoch 16.438), train_loss = 1.16626456, grad/param norm = 2.0343e-01, time/batch = 20.3876s	
7546/22950 (epoch 16.440), train_loss = 1.24538513, grad/param norm = 2.0696e-01, time/batch = 19.7041s	
7547/22950 (epoch 16.442), train_loss = 1.28463649, grad/param norm = 2.0703e-01, time/batch = 18.0348s	
7548/22950 (epoch 16.444), train_loss = 1.21847324, grad/param norm = 2.1241e-01, time/batch = 17.9403s	
7549/22950 (epoch 16.447), train_loss = 1.35158633, grad/param norm = 2.3858e-01, time/batch = 19.3826s	
7550/22950 (epoch 16.449), train_loss = 1.03084971, grad/param norm = 1.8315e-01, time/batch = 17.7874s	
7551/22950 (epoch 16.451), train_loss = 1.16500415, grad/param norm = 1.8751e-01, time/batch = 18.8565s	
7552/22950 (epoch 16.453), train_loss = 1.18662719, grad/param norm = 1.9076e-01, time/batch = 17.8800s	
7553/22950 (epoch 16.455), train_loss = 1.04081248, grad/param norm = 1.7822e-01, time/batch = 19.8000s	
7554/22950 (epoch 16.458), train_loss = 1.28573047, grad/param norm = 2.0666e-01, time/batch = 18.1037s	
7555/22950 (epoch 16.460), train_loss = 1.17217898, grad/param norm = 2.1041e-01, time/batch = 17.9454s	
7556/22950 (epoch 16.462), train_loss = 1.14609695, grad/param norm = 2.1291e-01, time/batch = 19.4399s	
7557/22950 (epoch 16.464), train_loss = 1.11686906, grad/param norm = 1.9830e-01, time/batch = 17.5255s	
7558/22950 (epoch 16.466), train_loss = 1.17111898, grad/param norm = 2.0316e-01, time/batch = 19.5503s	
7559/22950 (epoch 16.468), train_loss = 1.28891422, grad/param norm = 2.0953e-01, time/batch = 15.7400s	
7560/22950 (epoch 16.471), train_loss = 1.17766373, grad/param norm = 2.1013e-01, time/batch = 18.1233s	
7561/22950 (epoch 16.473), train_loss = 1.20933044, grad/param norm = 2.0851e-01, time/batch = 19.9602s	
7562/22950 (epoch 16.475), train_loss = 1.36847648, grad/param norm = 2.1670e-01, time/batch = 18.8684s	
7563/22950 (epoch 16.477), train_loss = 1.13978478, grad/param norm = 1.9704e-01, time/batch = 18.7860s	
7564/22950 (epoch 16.479), train_loss = 1.07090197, grad/param norm = 1.9640e-01, time/batch = 17.4418s	
7565/22950 (epoch 16.481), train_loss = 1.26610565, grad/param norm = 2.1627e-01, time/batch = 17.4599s	
7566/22950 (epoch 16.484), train_loss = 1.16973547, grad/param norm = 1.9779e-01, time/batch = 18.9562s	
7567/22950 (epoch 16.486), train_loss = 1.02267060, grad/param norm = 1.9524e-01, time/batch = 18.0270s	
7568/22950 (epoch 16.488), train_loss = 1.10437380, grad/param norm = 2.1037e-01, time/batch = 15.7074s	
7569/22950 (epoch 16.490), train_loss = 0.97767362, grad/param norm = 2.0093e-01, time/batch = 17.1264s	
7570/22950 (epoch 16.492), train_loss = 1.10704753, grad/param norm = 1.9954e-01, time/batch = 18.6196s	
7571/22950 (epoch 16.495), train_loss = 1.12245603, grad/param norm = 1.9659e-01, time/batch = 20.1249s	
7572/22950 (epoch 16.497), train_loss = 1.21953119, grad/param norm = 1.9901e-01, time/batch = 17.0393s	
7573/22950 (epoch 16.499), train_loss = 1.25742347, grad/param norm = 1.9749e-01, time/batch = 18.6252s	
7574/22950 (epoch 16.501), train_loss = 1.20378036, grad/param norm = 2.1079e-01, time/batch = 17.3068s	
7575/22950 (epoch 16.503), train_loss = 1.25607302, grad/param norm = 2.0475e-01, time/batch = 18.7092s	
7576/22950 (epoch 16.505), train_loss = 1.00634948, grad/param norm = 1.7195e-01, time/batch = 16.9599s	
7577/22950 (epoch 16.508), train_loss = 1.19345963, grad/param norm = 2.0407e-01, time/batch = 18.0196s	
7578/22950 (epoch 16.510), train_loss = 1.16919217, grad/param norm = 2.0798e-01, time/batch = 19.1215s	
7579/22950 (epoch 16.512), train_loss = 1.07614776, grad/param norm = 1.9505e-01, time/batch = 20.0545s	
7580/22950 (epoch 16.514), train_loss = 1.04417077, grad/param norm = 1.7119e-01, time/batch = 17.5341s	
7581/22950 (epoch 16.516), train_loss = 1.11161744, grad/param norm = 1.9948e-01, time/batch = 18.8824s	
7582/22950 (epoch 16.519), train_loss = 1.11884789, grad/param norm = 1.9154e-01, time/batch = 18.4649s	
7583/22950 (epoch 16.521), train_loss = 1.15805786, grad/param norm = 2.0050e-01, time/batch = 16.7299s	
7584/22950 (epoch 16.523), train_loss = 0.94126301, grad/param norm = 1.7941e-01, time/batch = 20.2788s	
7585/22950 (epoch 16.525), train_loss = 1.04333041, grad/param norm = 1.9034e-01, time/batch = 19.7043s	
7586/22950 (epoch 16.527), train_loss = 0.99779468, grad/param norm = 2.0520e-01, time/batch = 18.7011s	
7587/22950 (epoch 16.529), train_loss = 1.17807631, grad/param norm = 2.1139e-01, time/batch = 19.9619s	
7588/22950 (epoch 16.532), train_loss = 1.08146298, grad/param norm = 1.9438e-01, time/batch = 18.7922s	
7589/22950 (epoch 16.534), train_loss = 1.21193298, grad/param norm = 2.1903e-01, time/batch = 18.3878s	
7590/22950 (epoch 16.536), train_loss = 1.21222452, grad/param norm = 2.3310e-01, time/batch = 17.1834s	
7591/22950 (epoch 16.538), train_loss = 1.13297312, grad/param norm = 2.1876e-01, time/batch = 19.6422s	
7592/22950 (epoch 16.540), train_loss = 1.17503246, grad/param norm = 2.0059e-01, time/batch = 19.1324s	
7593/22950 (epoch 16.542), train_loss = 1.31816084, grad/param norm = 2.1459e-01, time/batch = 18.6135s	
7594/22950 (epoch 16.545), train_loss = 1.11175568, grad/param norm = 1.9023e-01, time/batch = 18.4595s	
7595/22950 (epoch 16.547), train_loss = 1.12742218, grad/param norm = 1.9603e-01, time/batch = 19.7857s	
7596/22950 (epoch 16.549), train_loss = 1.10979623, grad/param norm = 2.1174e-01, time/batch = 17.1257s	
7597/22950 (epoch 16.551), train_loss = 1.12536188, grad/param norm = 2.1476e-01, time/batch = 18.1237s	
7598/22950 (epoch 16.553), train_loss = 1.11239175, grad/param norm = 2.0906e-01, time/batch = 16.2954s	
7599/22950 (epoch 16.556), train_loss = 1.18609412, grad/param norm = 2.1870e-01, time/batch = 16.9373s	
7600/22950 (epoch 16.558), train_loss = 1.04251002, grad/param norm = 1.9175e-01, time/batch = 18.9712s	
7601/22950 (epoch 16.560), train_loss = 1.14541293, grad/param norm = 1.9154e-01, time/batch = 19.2969s	
7602/22950 (epoch 16.562), train_loss = 1.03946242, grad/param norm = 1.8637e-01, time/batch = 19.6222s	
7603/22950 (epoch 16.564), train_loss = 1.26303013, grad/param norm = 2.4175e-01, time/batch = 20.7869s	
7604/22950 (epoch 16.566), train_loss = 1.17822453, grad/param norm = 2.1020e-01, time/batch = 18.7205s	
7605/22950 (epoch 16.569), train_loss = 1.22412439, grad/param norm = 2.1157e-01, time/batch = 17.4454s	
7606/22950 (epoch 16.571), train_loss = 1.06833005, grad/param norm = 1.9391e-01, time/batch = 18.4551s	
7607/22950 (epoch 16.573), train_loss = 1.15715239, grad/param norm = 2.0066e-01, time/batch = 19.0547s	
7608/22950 (epoch 16.575), train_loss = 1.29667572, grad/param norm = 2.3228e-01, time/batch = 18.7110s	
7609/22950 (epoch 16.577), train_loss = 1.12890662, grad/param norm = 2.1133e-01, time/batch = 18.6157s	
7610/22950 (epoch 16.580), train_loss = 1.18019803, grad/param norm = 2.0760e-01, time/batch = 19.7086s	
7611/22950 (epoch 16.582), train_loss = 1.34416715, grad/param norm = 2.0732e-01, time/batch = 20.0389s	
7612/22950 (epoch 16.584), train_loss = 1.04480801, grad/param norm = 1.9173e-01, time/batch = 17.1214s	
7613/22950 (epoch 16.586), train_loss = 1.11569838, grad/param norm = 2.2779e-01, time/batch = 18.1278s	
7614/22950 (epoch 16.588), train_loss = 1.25793236, grad/param norm = 1.9906e-01, time/batch = 18.3106s	
7615/22950 (epoch 16.590), train_loss = 1.14501999, grad/param norm = 2.0020e-01, time/batch = 17.0401s	
7616/22950 (epoch 16.593), train_loss = 1.05253824, grad/param norm = 1.9597e-01, time/batch = 19.7909s	
7617/22950 (epoch 16.595), train_loss = 1.02604752, grad/param norm = 1.9924e-01, time/batch = 17.5424s	
7618/22950 (epoch 16.597), train_loss = 1.20479368, grad/param norm = 2.0866e-01, time/batch = 18.2015s	
7619/22950 (epoch 16.599), train_loss = 1.18533413, grad/param norm = 2.2711e-01, time/batch = 19.2016s	
7620/22950 (epoch 16.601), train_loss = 1.16693335, grad/param norm = 2.2508e-01, time/batch = 19.6167s	
7621/22950 (epoch 16.603), train_loss = 1.28153878, grad/param norm = 2.0423e-01, time/batch = 16.1008s	
7622/22950 (epoch 16.606), train_loss = 1.11586221, grad/param norm = 1.9810e-01, time/batch = 18.0956s	
7623/22950 (epoch 16.608), train_loss = 1.17363250, grad/param norm = 2.0565e-01, time/batch = 18.1169s	
7624/22950 (epoch 16.610), train_loss = 1.12222056, grad/param norm = 1.9547e-01, time/batch = 19.5499s	
7625/22950 (epoch 16.612), train_loss = 1.12201347, grad/param norm = 2.0607e-01, time/batch = 17.6969s	
7626/22950 (epoch 16.614), train_loss = 1.27848411, grad/param norm = 2.2633e-01, time/batch = 19.7927s	
7627/22950 (epoch 16.617), train_loss = 1.13852067, grad/param norm = 2.1075e-01, time/batch = 19.9313s	
7628/22950 (epoch 16.619), train_loss = 1.07503634, grad/param norm = 1.8289e-01, time/batch = 17.2921s	
7629/22950 (epoch 16.621), train_loss = 1.24955108, grad/param norm = 1.8274e-01, time/batch = 18.6393s	
7630/22950 (epoch 16.623), train_loss = 1.21531376, grad/param norm = 1.7962e-01, time/batch = 18.2916s	
7631/22950 (epoch 16.625), train_loss = 1.13687252, grad/param norm = 1.9784e-01, time/batch = 17.4468s	
7632/22950 (epoch 16.627), train_loss = 1.13294506, grad/param norm = 2.0382e-01, time/batch = 19.5413s	
7633/22950 (epoch 16.630), train_loss = 1.00885164, grad/param norm = 1.9018e-01, time/batch = 19.2897s	
7634/22950 (epoch 16.632), train_loss = 1.15017953, grad/param norm = 2.1548e-01, time/batch = 16.6978s	
7635/22950 (epoch 16.634), train_loss = 1.14545197, grad/param norm = 2.0054e-01, time/batch = 17.5170s	
7636/22950 (epoch 16.636), train_loss = 1.19027865, grad/param norm = 1.9984e-01, time/batch = 19.6323s	
7637/22950 (epoch 16.638), train_loss = 1.06823792, grad/param norm = 2.0144e-01, time/batch = 19.5481s	
7638/22950 (epoch 16.641), train_loss = 1.10550541, grad/param norm = 1.8667e-01, time/batch = 18.3684s	
7639/22950 (epoch 16.643), train_loss = 1.18713588, grad/param norm = 2.2902e-01, time/batch = 18.9390s	
7640/22950 (epoch 16.645), train_loss = 1.08795301, grad/param norm = 1.9577e-01, time/batch = 17.6377s	
7641/22950 (epoch 16.647), train_loss = 1.13146335, grad/param norm = 2.0972e-01, time/batch = 18.3669s	
7642/22950 (epoch 16.649), train_loss = 1.14580276, grad/param norm = 2.0297e-01, time/batch = 18.1405s	
7643/22950 (epoch 16.651), train_loss = 1.21738443, grad/param norm = 2.1894e-01, time/batch = 17.2139s	
7644/22950 (epoch 16.654), train_loss = 0.97531106, grad/param norm = 1.9399e-01, time/batch = 18.6932s	
7645/22950 (epoch 16.656), train_loss = 1.25923695, grad/param norm = 2.2790e-01, time/batch = 16.5217s	
7646/22950 (epoch 16.658), train_loss = 1.05171051, grad/param norm = 2.0154e-01, time/batch = 18.3935s	
7647/22950 (epoch 16.660), train_loss = 0.96859779, grad/param norm = 1.9825e-01, time/batch = 18.9564s	
7648/22950 (epoch 16.662), train_loss = 0.97346095, grad/param norm = 1.7483e-01, time/batch = 18.0268s	
7649/22950 (epoch 16.664), train_loss = 1.13327072, grad/param norm = 1.9403e-01, time/batch = 20.3578s	
7650/22950 (epoch 16.667), train_loss = 1.16189304, grad/param norm = 1.9435e-01, time/batch = 19.1129s	
7651/22950 (epoch 16.669), train_loss = 1.12446313, grad/param norm = 1.9816e-01, time/batch = 19.1126s	
7652/22950 (epoch 16.671), train_loss = 1.15231342, grad/param norm = 2.0496e-01, time/batch = 20.0500s	
7653/22950 (epoch 16.673), train_loss = 1.10638600, grad/param norm = 1.9631e-01, time/batch = 19.0228s	
7654/22950 (epoch 16.675), train_loss = 1.13777196, grad/param norm = 2.2014e-01, time/batch = 16.5269s	
7655/22950 (epoch 16.678), train_loss = 1.15141063, grad/param norm = 1.9974e-01, time/batch = 16.2887s	
7656/22950 (epoch 16.680), train_loss = 1.14342382, grad/param norm = 1.8814e-01, time/batch = 17.6318s	
7657/22950 (epoch 16.682), train_loss = 1.19490040, grad/param norm = 2.1452e-01, time/batch = 17.2097s	
7658/22950 (epoch 16.684), train_loss = 1.25630354, grad/param norm = 2.2114e-01, time/batch = 16.2269s	
7659/22950 (epoch 16.686), train_loss = 1.21629222, grad/param norm = 2.0708e-01, time/batch = 17.9608s	
7660/22950 (epoch 16.688), train_loss = 1.14922153, grad/param norm = 2.0517e-01, time/batch = 19.4645s	
7661/22950 (epoch 16.691), train_loss = 1.15935517, grad/param norm = 2.0906e-01, time/batch = 18.2712s	
7662/22950 (epoch 16.693), train_loss = 1.05845177, grad/param norm = 1.9665e-01, time/batch = 18.1334s	
7663/22950 (epoch 16.695), train_loss = 1.25726685, grad/param norm = 2.1305e-01, time/batch = 17.7158s	
7664/22950 (epoch 16.697), train_loss = 1.22350686, grad/param norm = 2.1423e-01, time/batch = 17.9179s	
7665/22950 (epoch 16.699), train_loss = 1.20954500, grad/param norm = 2.0438e-01, time/batch = 19.7000s	
7666/22950 (epoch 16.702), train_loss = 1.20659205, grad/param norm = 2.0025e-01, time/batch = 18.7064s	
7667/22950 (epoch 16.704), train_loss = 1.21872813, grad/param norm = 2.0002e-01, time/batch = 18.0417s	
7668/22950 (epoch 16.706), train_loss = 1.22710456, grad/param norm = 2.1941e-01, time/batch = 19.1170s	
7669/22950 (epoch 16.708), train_loss = 1.06394368, grad/param norm = 2.3156e-01, time/batch = 16.6164s	
7670/22950 (epoch 16.710), train_loss = 1.18933456, grad/param norm = 2.0340e-01, time/batch = 19.5311s	
7671/22950 (epoch 16.712), train_loss = 1.26800010, grad/param norm = 2.0926e-01, time/batch = 19.5388s	
7672/22950 (epoch 16.715), train_loss = 1.19480290, grad/param norm = 2.1341e-01, time/batch = 18.3723s	
7673/22950 (epoch 16.717), train_loss = 1.11615646, grad/param norm = 1.8994e-01, time/batch = 17.8039s	
7674/22950 (epoch 16.719), train_loss = 1.13285697, grad/param norm = 2.1386e-01, time/batch = 17.8595s	
7675/22950 (epoch 16.721), train_loss = 1.21472444, grad/param norm = 2.1224e-01, time/batch = 19.1300s	
7676/22950 (epoch 16.723), train_loss = 1.09877965, grad/param norm = 1.8945e-01, time/batch = 18.6271s	
7677/22950 (epoch 16.725), train_loss = 1.20586208, grad/param norm = 2.1805e-01, time/batch = 17.4559s	
7678/22950 (epoch 16.728), train_loss = 1.13449320, grad/param norm = 2.4293e-01, time/batch = 18.4666s	
7679/22950 (epoch 16.730), train_loss = 1.15293205, grad/param norm = 2.1806e-01, time/batch = 18.5394s	
7680/22950 (epoch 16.732), train_loss = 1.19606468, grad/param norm = 2.0108e-01, time/batch = 16.4076s	
7681/22950 (epoch 16.734), train_loss = 1.17043635, grad/param norm = 2.1212e-01, time/batch = 18.4357s	
7682/22950 (epoch 16.736), train_loss = 1.12939922, grad/param norm = 1.9968e-01, time/batch = 17.4781s	
7683/22950 (epoch 16.739), train_loss = 1.21086465, grad/param norm = 2.0842e-01, time/batch = 19.5547s	
7684/22950 (epoch 16.741), train_loss = 1.21655122, grad/param norm = 2.0043e-01, time/batch = 20.4387s	
7685/22950 (epoch 16.743), train_loss = 1.30017248, grad/param norm = 2.1120e-01, time/batch = 18.0549s	
7686/22950 (epoch 16.745), train_loss = 1.41383581, grad/param norm = 2.4120e-01, time/batch = 17.6896s	
7687/22950 (epoch 16.747), train_loss = 1.18779782, grad/param norm = 2.1096e-01, time/batch = 18.1091s	
7688/22950 (epoch 16.749), train_loss = 1.07526329, grad/param norm = 1.9780e-01, time/batch = 19.7029s	
7689/22950 (epoch 16.752), train_loss = 1.34877280, grad/param norm = 2.2253e-01, time/batch = 18.6200s	
7690/22950 (epoch 16.754), train_loss = 1.25335139, grad/param norm = 2.1711e-01, time/batch = 17.7946s	
7691/22950 (epoch 16.756), train_loss = 1.08575477, grad/param norm = 1.9986e-01, time/batch = 19.0494s	
7692/22950 (epoch 16.758), train_loss = 1.10166381, grad/param norm = 1.8657e-01, time/batch = 19.3745s	
7693/22950 (epoch 16.760), train_loss = 1.21004304, grad/param norm = 2.2046e-01, time/batch = 17.8636s	
7694/22950 (epoch 16.763), train_loss = 1.22751500, grad/param norm = 2.2746e-01, time/batch = 18.9645s	
7695/22950 (epoch 16.765), train_loss = 1.19594911, grad/param norm = 2.1216e-01, time/batch = 18.8034s	
7696/22950 (epoch 16.767), train_loss = 1.33775646, grad/param norm = 2.1410e-01, time/batch = 17.2068s	
7697/22950 (epoch 16.769), train_loss = 1.18333742, grad/param norm = 2.0261e-01, time/batch = 20.1038s	
7698/22950 (epoch 16.771), train_loss = 1.03609903, grad/param norm = 2.0219e-01, time/batch = 17.4818s	
7699/22950 (epoch 16.773), train_loss = 0.88264755, grad/param norm = 1.8064e-01, time/batch = 19.5471s	
7700/22950 (epoch 16.776), train_loss = 1.07383724, grad/param norm = 1.9180e-01, time/batch = 19.5190s	
7701/22950 (epoch 16.778), train_loss = 1.01770852, grad/param norm = 1.8852e-01, time/batch = 19.6283s	
7702/22950 (epoch 16.780), train_loss = 1.12434278, grad/param norm = 1.8238e-01, time/batch = 19.0440s	
7703/22950 (epoch 16.782), train_loss = 1.14326898, grad/param norm = 1.9388e-01, time/batch = 19.1109s	
7704/22950 (epoch 16.784), train_loss = 1.12569213, grad/param norm = 2.0974e-01, time/batch = 16.9445s	
7705/22950 (epoch 16.786), train_loss = 1.20595353, grad/param norm = 1.9366e-01, time/batch = 17.4408s	
7706/22950 (epoch 16.789), train_loss = 1.00809101, grad/param norm = 1.8290e-01, time/batch = 18.1136s	
7707/22950 (epoch 16.791), train_loss = 1.04089427, grad/param norm = 2.0930e-01, time/batch = 18.9603s	
7708/22950 (epoch 16.793), train_loss = 1.35973982, grad/param norm = 2.1541e-01, time/batch = 19.7240s	
7709/22950 (epoch 16.795), train_loss = 1.10520254, grad/param norm = 1.8914e-01, time/batch = 26.4280s	
7710/22950 (epoch 16.797), train_loss = 1.29179184, grad/param norm = 2.1230e-01, time/batch = 24.8291s	
7711/22950 (epoch 16.800), train_loss = 1.05163831, grad/param norm = 1.8815e-01, time/batch = 18.2005s	
7712/22950 (epoch 16.802), train_loss = 1.07097051, grad/param norm = 2.1188e-01, time/batch = 17.9443s	
7713/22950 (epoch 16.804), train_loss = 1.12794755, grad/param norm = 1.9933e-01, time/batch = 18.4792s	
7714/22950 (epoch 16.806), train_loss = 1.02729468, grad/param norm = 1.9676e-01, time/batch = 18.8974s	
7715/22950 (epoch 16.808), train_loss = 1.12894994, grad/param norm = 1.9421e-01, time/batch = 17.2938s	
7716/22950 (epoch 16.810), train_loss = 1.11370832, grad/param norm = 2.0546e-01, time/batch = 18.2213s	
7717/22950 (epoch 16.813), train_loss = 0.93183721, grad/param norm = 1.8798e-01, time/batch = 18.6290s	
7718/22950 (epoch 16.815), train_loss = 1.00392406, grad/param norm = 1.8743e-01, time/batch = 16.3674s	
7719/22950 (epoch 16.817), train_loss = 1.01337708, grad/param norm = 1.8414e-01, time/batch = 18.6107s	
7720/22950 (epoch 16.819), train_loss = 1.12132264, grad/param norm = 1.9688e-01, time/batch = 18.7823s	
7721/22950 (epoch 16.821), train_loss = 1.09245861, grad/param norm = 2.0700e-01, time/batch = 18.1206s	
7722/22950 (epoch 16.824), train_loss = 1.13260990, grad/param norm = 2.2578e-01, time/batch = 20.2804s	
7723/22950 (epoch 16.826), train_loss = 1.26406725, grad/param norm = 2.2479e-01, time/batch = 18.7903s	
7724/22950 (epoch 16.828), train_loss = 1.12130155, grad/param norm = 2.0821e-01, time/batch = 19.1005s	
7725/22950 (epoch 16.830), train_loss = 1.15209349, grad/param norm = 2.0105e-01, time/batch = 19.9417s	
7726/22950 (epoch 16.832), train_loss = 1.15944757, grad/param norm = 1.9950e-01, time/batch = 17.8015s	
7727/22950 (epoch 16.834), train_loss = 0.98270927, grad/param norm = 1.9499e-01, time/batch = 18.7967s	
7728/22950 (epoch 16.837), train_loss = 1.16054012, grad/param norm = 2.1756e-01, time/batch = 16.8262s	
7729/22950 (epoch 16.839), train_loss = 1.01028198, grad/param norm = 2.0744e-01, time/batch = 18.8127s	
7730/22950 (epoch 16.841), train_loss = 1.06661247, grad/param norm = 1.8152e-01, time/batch = 18.2988s	
7731/22950 (epoch 16.843), train_loss = 1.08407598, grad/param norm = 2.0051e-01, time/batch = 17.7081s	
7732/22950 (epoch 16.845), train_loss = 1.15034788, grad/param norm = 2.0889e-01, time/batch = 18.8773s	
7733/22950 (epoch 16.847), train_loss = 1.20998717, grad/param norm = 2.1342e-01, time/batch = 17.9530s	
7734/22950 (epoch 16.850), train_loss = 1.19388750, grad/param norm = 2.1476e-01, time/batch = 17.5378s	
7735/22950 (epoch 16.852), train_loss = 1.18952644, grad/param norm = 2.0663e-01, time/batch = 20.3666s	
7736/22950 (epoch 16.854), train_loss = 1.11107760, grad/param norm = 1.9653e-01, time/batch = 18.7118s	
7737/22950 (epoch 16.856), train_loss = 1.34449093, grad/param norm = 2.4442e-01, time/batch = 17.5513s	
7738/22950 (epoch 16.858), train_loss = 1.20257002, grad/param norm = 1.9514e-01, time/batch = 19.7151s	
7739/22950 (epoch 16.861), train_loss = 1.24035436, grad/param norm = 2.0489e-01, time/batch = 19.3918s	
7740/22950 (epoch 16.863), train_loss = 1.28898815, grad/param norm = 2.1896e-01, time/batch = 18.2887s	
7741/22950 (epoch 16.865), train_loss = 1.30462545, grad/param norm = 2.2553e-01, time/batch = 18.0900s	
7742/22950 (epoch 16.867), train_loss = 1.18848554, grad/param norm = 2.0423e-01, time/batch = 19.3723s	
7743/22950 (epoch 16.869), train_loss = 1.32823919, grad/param norm = 2.1515e-01, time/batch = 19.6352s	
7744/22950 (epoch 16.871), train_loss = 1.16918959, grad/param norm = 2.3712e-01, time/batch = 18.1778s	
7745/22950 (epoch 16.874), train_loss = 1.15992767, grad/param norm = 2.0866e-01, time/batch = 20.1229s	
7746/22950 (epoch 16.876), train_loss = 1.20944143, grad/param norm = 2.1114e-01, time/batch = 18.6279s	
7747/22950 (epoch 16.878), train_loss = 1.10434933, grad/param norm = 2.2364e-01, time/batch = 17.8805s	
7748/22950 (epoch 16.880), train_loss = 1.31002735, grad/param norm = 2.1019e-01, time/batch = 20.1233s	
7749/22950 (epoch 16.882), train_loss = 1.03845716, grad/param norm = 1.9400e-01, time/batch = 18.0512s	
7750/22950 (epoch 16.885), train_loss = 1.18731904, grad/param norm = 2.0870e-01, time/batch = 18.7111s	
7751/22950 (epoch 16.887), train_loss = 1.17870181, grad/param norm = 2.0628e-01, time/batch = 18.6175s	
7752/22950 (epoch 16.889), train_loss = 1.20363429, grad/param norm = 2.1641e-01, time/batch = 15.9286s	
7753/22950 (epoch 16.891), train_loss = 1.11200842, grad/param norm = 2.0605e-01, time/batch = 15.7811s	
7754/22950 (epoch 16.893), train_loss = 1.21470694, grad/param norm = 2.0492e-01, time/batch = 17.9664s	
7755/22950 (epoch 16.895), train_loss = 1.34530350, grad/param norm = 2.2202e-01, time/batch = 18.4556s	
7756/22950 (epoch 16.898), train_loss = 1.13146597, grad/param norm = 1.9443e-01, time/batch = 20.2816s	
7757/22950 (epoch 16.900), train_loss = 1.07683056, grad/param norm = 1.7780e-01, time/batch = 16.7891s	
7758/22950 (epoch 16.902), train_loss = 1.20523665, grad/param norm = 2.0780e-01, time/batch = 19.2970s	
7759/22950 (epoch 16.904), train_loss = 1.20805318, grad/param norm = 2.1130e-01, time/batch = 19.1973s	
7760/22950 (epoch 16.906), train_loss = 1.17006970, grad/param norm = 2.0004e-01, time/batch = 16.9455s	
7761/22950 (epoch 16.908), train_loss = 1.04614032, grad/param norm = 1.8959e-01, time/batch = 20.1921s	
7762/22950 (epoch 16.911), train_loss = 0.99800804, grad/param norm = 1.9329e-01, time/batch = 19.0457s	
7763/22950 (epoch 16.913), train_loss = 1.06417634, grad/param norm = 2.0442e-01, time/batch = 18.2000s	
7764/22950 (epoch 16.915), train_loss = 1.25645410, grad/param norm = 2.2952e-01, time/batch = 20.2846s	
7765/22950 (epoch 16.917), train_loss = 1.01904234, grad/param norm = 1.8878e-01, time/batch = 19.2153s	
7766/22950 (epoch 16.919), train_loss = 1.09441809, grad/param norm = 1.9983e-01, time/batch = 19.4635s	
7767/22950 (epoch 16.922), train_loss = 1.15878989, grad/param norm = 2.1937e-01, time/batch = 17.8898s	
7768/22950 (epoch 16.924), train_loss = 1.19666251, grad/param norm = 2.0554e-01, time/batch = 16.2177s	
7769/22950 (epoch 16.926), train_loss = 0.98978905, grad/param norm = 2.0219e-01, time/batch = 19.1246s	
7770/22950 (epoch 16.928), train_loss = 1.00600859, grad/param norm = 2.0319e-01, time/batch = 19.6076s	
7771/22950 (epoch 16.930), train_loss = 1.00384049, grad/param norm = 2.0028e-01, time/batch = 18.0569s	
7772/22950 (epoch 16.932), train_loss = 0.95271942, grad/param norm = 1.7674e-01, time/batch = 19.8693s	
7773/22950 (epoch 16.935), train_loss = 1.14115258, grad/param norm = 1.9289e-01, time/batch = 17.7658s	
7774/22950 (epoch 16.937), train_loss = 1.16387643, grad/param norm = 2.2723e-01, time/batch = 18.9572s	
7775/22950 (epoch 16.939), train_loss = 1.07864985, grad/param norm = 2.1668e-01, time/batch = 18.1177s	
7776/22950 (epoch 16.941), train_loss = 1.05873000, grad/param norm = 1.9523e-01, time/batch = 17.3077s	
7777/22950 (epoch 16.943), train_loss = 1.15233395, grad/param norm = 2.0634e-01, time/batch = 20.3686s	
7778/22950 (epoch 16.946), train_loss = 1.02225292, grad/param norm = 2.1687e-01, time/batch = 19.7169s	
7779/22950 (epoch 16.948), train_loss = 1.19736767, grad/param norm = 1.9201e-01, time/batch = 18.0520s	
7780/22950 (epoch 16.950), train_loss = 1.15499441, grad/param norm = 2.1325e-01, time/batch = 18.2940s	
7781/22950 (epoch 16.952), train_loss = 1.17102920, grad/param norm = 2.0917e-01, time/batch = 18.5475s	
7782/22950 (epoch 16.954), train_loss = 1.17143239, grad/param norm = 2.1057e-01, time/batch = 19.3623s	
7783/22950 (epoch 16.956), train_loss = 1.07134318, grad/param norm = 2.0019e-01, time/batch = 19.1273s	
7784/22950 (epoch 16.959), train_loss = 1.03708889, grad/param norm = 1.8759e-01, time/batch = 18.6292s	
7785/22950 (epoch 16.961), train_loss = 1.15006484, grad/param norm = 2.0605e-01, time/batch = 18.8672s	
7786/22950 (epoch 16.963), train_loss = 1.18552917, grad/param norm = 2.2142e-01, time/batch = 19.1255s	
7787/22950 (epoch 16.965), train_loss = 1.30059462, grad/param norm = 2.1666e-01, time/batch = 18.8870s	
7788/22950 (epoch 16.967), train_loss = 1.12014360, grad/param norm = 2.1799e-01, time/batch = 19.5412s	
7789/22950 (epoch 16.969), train_loss = 1.04738205, grad/param norm = 1.9765e-01, time/batch = 17.5883s	
7790/22950 (epoch 16.972), train_loss = 1.13679694, grad/param norm = 1.9893e-01, time/batch = 19.3856s	
7791/22950 (epoch 16.974), train_loss = 1.09211387, grad/param norm = 1.9820e-01, time/batch = 18.4609s	
7792/22950 (epoch 16.976), train_loss = 1.04007421, grad/param norm = 1.9524e-01, time/batch = 18.1090s	
7793/22950 (epoch 16.978), train_loss = 1.10618609, grad/param norm = 1.9908e-01, time/batch = 19.8693s	
7794/22950 (epoch 16.980), train_loss = 1.13242223, grad/param norm = 2.0044e-01, time/batch = 18.5480s	
7795/22950 (epoch 16.983), train_loss = 1.12017012, grad/param norm = 1.9947e-01, time/batch = 18.2100s	
7796/22950 (epoch 16.985), train_loss = 1.00856808, grad/param norm = 1.9272e-01, time/batch = 17.9089s	
7797/22950 (epoch 16.987), train_loss = 1.03667300, grad/param norm = 1.9174e-01, time/batch = 19.8828s	
7798/22950 (epoch 16.989), train_loss = 1.13563006, grad/param norm = 2.0700e-01, time/batch = 15.7713s	
7799/22950 (epoch 16.991), train_loss = 0.96842397, grad/param norm = 1.8641e-01, time/batch = 20.0419s	
7800/22950 (epoch 16.993), train_loss = 1.15343443, grad/param norm = 2.1650e-01, time/batch = 19.8078s	
7801/22950 (epoch 16.996), train_loss = 1.19457973, grad/param norm = 2.2365e-01, time/batch = 17.7932s	
7802/22950 (epoch 16.998), train_loss = 1.06184225, grad/param norm = 1.9447e-01, time/batch = 19.9644s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
7803/22950 (epoch 17.000), train_loss = 0.97467381, grad/param norm = 1.8723e-01, time/batch = 17.2998s	
7804/22950 (epoch 17.002), train_loss = 1.30778592, grad/param norm = 2.1331e-01, time/batch = 19.5478s	
7805/22950 (epoch 17.004), train_loss = 1.16669293, grad/param norm = 1.9857e-01, time/batch = 19.1153s	
7806/22950 (epoch 17.007), train_loss = 1.13478327, grad/param norm = 2.1017e-01, time/batch = 18.6463s	
7807/22950 (epoch 17.009), train_loss = 1.28776881, grad/param norm = 2.2606e-01, time/batch = 18.4356s	
7808/22950 (epoch 17.011), train_loss = 1.02388405, grad/param norm = 2.0754e-01, time/batch = 18.6039s	
7809/22950 (epoch 17.013), train_loss = 1.18706370, grad/param norm = 2.1303e-01, time/batch = 19.8847s	
7810/22950 (epoch 17.015), train_loss = 1.21407402, grad/param norm = 2.1925e-01, time/batch = 18.0431s	
7811/22950 (epoch 17.017), train_loss = 1.16868948, grad/param norm = 1.9713e-01, time/batch = 16.9631s	
7812/22950 (epoch 17.020), train_loss = 1.12990754, grad/param norm = 1.7854e-01, time/batch = 19.8708s	
7813/22950 (epoch 17.022), train_loss = 0.98811225, grad/param norm = 1.8881e-01, time/batch = 19.5459s	
7814/22950 (epoch 17.024), train_loss = 1.08417062, grad/param norm = 1.9728e-01, time/batch = 18.0422s	
7815/22950 (epoch 17.026), train_loss = 1.17971663, grad/param norm = 2.0861e-01, time/batch = 19.8659s	
7816/22950 (epoch 17.028), train_loss = 1.22515502, grad/param norm = 1.9152e-01, time/batch = 17.9546s	
7817/22950 (epoch 17.031), train_loss = 1.11574932, grad/param norm = 2.0972e-01, time/batch = 18.1138s	
7818/22950 (epoch 17.033), train_loss = 1.26837533, grad/param norm = 2.1570e-01, time/batch = 18.7766s	
7819/22950 (epoch 17.035), train_loss = 1.12701995, grad/param norm = 2.0091e-01, time/batch = 16.2070s	
7820/22950 (epoch 17.037), train_loss = 1.12394305, grad/param norm = 1.9739e-01, time/batch = 20.5282s	
7821/22950 (epoch 17.039), train_loss = 1.08881659, grad/param norm = 1.9149e-01, time/batch = 20.9215s	
7822/22950 (epoch 17.041), train_loss = 1.10579356, grad/param norm = 2.0526e-01, time/batch = 17.8025s	
7823/22950 (epoch 17.044), train_loss = 1.15663738, grad/param norm = 2.0459e-01, time/batch = 19.0347s	
7824/22950 (epoch 17.046), train_loss = 1.14585001, grad/param norm = 1.9716e-01, time/batch = 18.0159s	
7825/22950 (epoch 17.048), train_loss = 1.14603857, grad/param norm = 2.0392e-01, time/batch = 18.7068s	
7826/22950 (epoch 17.050), train_loss = 1.13402692, grad/param norm = 2.0352e-01, time/batch = 18.5431s	
7827/22950 (epoch 17.052), train_loss = 1.16333931, grad/param norm = 1.9222e-01, time/batch = 17.9346s	
7828/22950 (epoch 17.054), train_loss = 1.33483329, grad/param norm = 2.3148e-01, time/batch = 19.2130s	
7829/22950 (epoch 17.057), train_loss = 1.25779667, grad/param norm = 2.0489e-01, time/batch = 18.8945s	
7830/22950 (epoch 17.059), train_loss = 1.19892404, grad/param norm = 2.0728e-01, time/batch = 18.7010s	
7831/22950 (epoch 17.061), train_loss = 1.03663224, grad/param norm = 1.9092e-01, time/batch = 18.5476s	
7832/22950 (epoch 17.063), train_loss = 1.20543652, grad/param norm = 1.9768e-01, time/batch = 18.1972s	
7833/22950 (epoch 17.065), train_loss = 0.93180910, grad/param norm = 1.8298e-01, time/batch = 17.6249s	
7834/22950 (epoch 17.068), train_loss = 1.20954870, grad/param norm = 2.0722e-01, time/batch = 19.4585s	
7835/22950 (epoch 17.070), train_loss = 1.02713605, grad/param norm = 1.9490e-01, time/batch = 19.8768s	
7836/22950 (epoch 17.072), train_loss = 1.18593985, grad/param norm = 1.9895e-01, time/batch = 18.5222s	
7837/22950 (epoch 17.074), train_loss = 1.11563767, grad/param norm = 2.0306e-01, time/batch = 18.5248s	
7838/22950 (epoch 17.076), train_loss = 1.15235762, grad/param norm = 2.0301e-01, time/batch = 18.0423s	
7839/22950 (epoch 17.078), train_loss = 1.21091201, grad/param norm = 2.0307e-01, time/batch = 18.2971s	
7840/22950 (epoch 17.081), train_loss = 1.23353654, grad/param norm = 2.1585e-01, time/batch = 17.8535s	
7841/22950 (epoch 17.083), train_loss = 1.09749148, grad/param norm = 1.9811e-01, time/batch = 18.8007s	
7842/22950 (epoch 17.085), train_loss = 1.02762030, grad/param norm = 2.0971e-01, time/batch = 15.6160s	
7843/22950 (epoch 17.087), train_loss = 1.03583851, grad/param norm = 2.0269e-01, time/batch = 16.7647s	
7844/22950 (epoch 17.089), train_loss = 1.12949668, grad/param norm = 1.7959e-01, time/batch = 18.4757s	
7845/22950 (epoch 17.092), train_loss = 1.08946976, grad/param norm = 2.4335e-01, time/batch = 17.5538s	
7846/22950 (epoch 17.094), train_loss = 1.06467366, grad/param norm = 1.9773e-01, time/batch = 18.8717s	
7847/22950 (epoch 17.096), train_loss = 1.27528778, grad/param norm = 2.0944e-01, time/batch = 17.7974s	
7848/22950 (epoch 17.098), train_loss = 1.18169148, grad/param norm = 2.0083e-01, time/batch = 19.4562s	
7849/22950 (epoch 17.100), train_loss = 1.09747916, grad/param norm = 2.1828e-01, time/batch = 18.7266s	
7850/22950 (epoch 17.102), train_loss = 1.13598649, grad/param norm = 1.9558e-01, time/batch = 18.1110s	
7851/22950 (epoch 17.105), train_loss = 1.01418284, grad/param norm = 1.8716e-01, time/batch = 19.0469s	
7852/22950 (epoch 17.107), train_loss = 1.08150964, grad/param norm = 1.9104e-01, time/batch = 16.0656s	
7853/22950 (epoch 17.109), train_loss = 1.08269146, grad/param norm = 2.3024e-01, time/batch = 17.2859s	
7854/22950 (epoch 17.111), train_loss = 0.97718929, grad/param norm = 1.9452e-01, time/batch = 17.6984s	
7855/22950 (epoch 17.113), train_loss = 1.15606004, grad/param norm = 2.0283e-01, time/batch = 18.6289s	
7856/22950 (epoch 17.115), train_loss = 1.17335686, grad/param norm = 1.9840e-01, time/batch = 17.1094s	
7857/22950 (epoch 17.118), train_loss = 1.25904513, grad/param norm = 2.0431e-01, time/batch = 18.3825s	
7858/22950 (epoch 17.120), train_loss = 1.06059125, grad/param norm = 2.0313e-01, time/batch = 19.1366s	
7859/22950 (epoch 17.122), train_loss = 1.23923375, grad/param norm = 2.1442e-01, time/batch = 18.7142s	
7860/22950 (epoch 17.124), train_loss = 0.96917391, grad/param norm = 1.6380e-01, time/batch = 18.4431s	
7861/22950 (epoch 17.126), train_loss = 1.09729287, grad/param norm = 1.8797e-01, time/batch = 18.7035s	
7862/22950 (epoch 17.129), train_loss = 0.98172366, grad/param norm = 1.7747e-01, time/batch = 18.9690s	
7863/22950 (epoch 17.131), train_loss = 1.09239240, grad/param norm = 1.9474e-01, time/batch = 16.2032s	
7864/22950 (epoch 17.133), train_loss = 1.17245059, grad/param norm = 1.9897e-01, time/batch = 16.2767s	
7865/22950 (epoch 17.135), train_loss = 1.10695663, grad/param norm = 1.8243e-01, time/batch = 17.0622s	
7866/22950 (epoch 17.137), train_loss = 1.25902147, grad/param norm = 2.2571e-01, time/batch = 17.6179s	
7867/22950 (epoch 17.139), train_loss = 1.04081776, grad/param norm = 2.0836e-01, time/batch = 19.1086s	
7868/22950 (epoch 17.142), train_loss = 1.04100521, grad/param norm = 1.8845e-01, time/batch = 18.5301s	
7869/22950 (epoch 17.144), train_loss = 1.02635065, grad/param norm = 1.8330e-01, time/batch = 20.0459s	
7870/22950 (epoch 17.146), train_loss = 1.09631270, grad/param norm = 2.1163e-01, time/batch = 17.9398s	
7871/22950 (epoch 17.148), train_loss = 1.07584349, grad/param norm = 1.9602e-01, time/batch = 19.8669s	
7872/22950 (epoch 17.150), train_loss = 1.14145913, grad/param norm = 2.1201e-01, time/batch = 18.1095s	
7873/22950 (epoch 17.153), train_loss = 1.06141747, grad/param norm = 1.9547e-01, time/batch = 16.4872s	
7874/22950 (epoch 17.155), train_loss = 1.06700830, grad/param norm = 1.8166e-01, time/batch = 18.9735s	
7875/22950 (epoch 17.157), train_loss = 1.07516393, grad/param norm = 1.9901e-01, time/batch = 20.0442s	
7876/22950 (epoch 17.159), train_loss = 1.01903927, grad/param norm = 1.7991e-01, time/batch = 18.3608s	
7877/22950 (epoch 17.161), train_loss = 1.07190061, grad/param norm = 1.8432e-01, time/batch = 18.5466s	
7878/22950 (epoch 17.163), train_loss = 1.00282692, grad/param norm = 1.9512e-01, time/batch = 16.8175s	
7879/22950 (epoch 17.166), train_loss = 1.26665596, grad/param norm = 2.6399e-01, time/batch = 18.4329s	
7880/22950 (epoch 17.168), train_loss = 1.21594048, grad/param norm = 2.2926e-01, time/batch = 17.8575s	
7881/22950 (epoch 17.170), train_loss = 1.14321588, grad/param norm = 2.1787e-01, time/batch = 18.1387s	
7882/22950 (epoch 17.172), train_loss = 1.13466790, grad/param norm = 1.7971e-01, time/batch = 18.9576s	
7883/22950 (epoch 17.174), train_loss = 1.21570722, grad/param norm = 2.2784e-01, time/batch = 17.8773s	
7884/22950 (epoch 17.176), train_loss = 1.23581870, grad/param norm = 2.0589e-01, time/batch = 19.8747s	
7885/22950 (epoch 17.179), train_loss = 1.19487948, grad/param norm = 2.1592e-01, time/batch = 20.8750s	
7886/22950 (epoch 17.181), train_loss = 1.37957010, grad/param norm = 2.1362e-01, time/batch = 18.9274s	
7887/22950 (epoch 17.183), train_loss = 1.22251910, grad/param norm = 2.1453e-01, time/batch = 18.4496s	
7888/22950 (epoch 17.185), train_loss = 1.18941281, grad/param norm = 2.1419e-01, time/batch = 16.8738s	
7889/22950 (epoch 17.187), train_loss = 1.05822842, grad/param norm = 2.2427e-01, time/batch = 17.6215s	
7890/22950 (epoch 17.190), train_loss = 0.97815396, grad/param norm = 2.1275e-01, time/batch = 19.5398s	
7891/22950 (epoch 17.192), train_loss = 0.98374823, grad/param norm = 1.8530e-01, time/batch = 19.8801s	
7892/22950 (epoch 17.194), train_loss = 1.07357262, grad/param norm = 2.1373e-01, time/batch = 18.7111s	
7893/22950 (epoch 17.196), train_loss = 0.94756677, grad/param norm = 2.0499e-01, time/batch = 19.3791s	
7894/22950 (epoch 17.198), train_loss = 1.20909639, grad/param norm = 2.1094e-01, time/batch = 19.2066s	
7895/22950 (epoch 17.200), train_loss = 1.04445253, grad/param norm = 1.8736e-01, time/batch = 18.7059s	
7896/22950 (epoch 17.203), train_loss = 0.99868290, grad/param norm = 1.8384e-01, time/batch = 19.8687s	
7897/22950 (epoch 17.205), train_loss = 1.05282969, grad/param norm = 1.7949e-01, time/batch = 19.1199s	
7898/22950 (epoch 17.207), train_loss = 1.11488819, grad/param norm = 2.0623e-01, time/batch = 16.2937s	
7899/22950 (epoch 17.209), train_loss = 1.15597248, grad/param norm = 2.1484e-01, time/batch = 19.0343s	
7900/22950 (epoch 17.211), train_loss = 0.95003526, grad/param norm = 2.0605e-01, time/batch = 19.3753s	
7901/22950 (epoch 17.214), train_loss = 1.09404807, grad/param norm = 1.8596e-01, time/batch = 16.7930s	
7902/22950 (epoch 17.216), train_loss = 1.19220901, grad/param norm = 2.0279e-01, time/batch = 32.6988s	
7903/22950 (epoch 17.218), train_loss = 1.12153274, grad/param norm = 1.9542e-01, time/batch = 19.0321s	
7904/22950 (epoch 17.220), train_loss = 1.24404489, grad/param norm = 2.1360e-01, time/batch = 16.1064s	
7905/22950 (epoch 17.222), train_loss = 1.22613253, grad/param norm = 2.0603e-01, time/batch = 18.6271s	
7906/22950 (epoch 17.224), train_loss = 1.10814760, grad/param norm = 2.0332e-01, time/batch = 19.1316s	
7907/22950 (epoch 17.227), train_loss = 1.19306338, grad/param norm = 1.8401e-01, time/batch = 19.3711s	
7908/22950 (epoch 17.229), train_loss = 1.19042231, grad/param norm = 1.9835e-01, time/batch = 17.2022s	
7909/22950 (epoch 17.231), train_loss = 0.98756831, grad/param norm = 1.8128e-01, time/batch = 19.7919s	
7910/22950 (epoch 17.233), train_loss = 1.06196320, grad/param norm = 1.9506e-01, time/batch = 19.9552s	
7911/22950 (epoch 17.235), train_loss = 1.26159394, grad/param norm = 2.2235e-01, time/batch = 19.0487s	
7912/22950 (epoch 17.237), train_loss = 1.02686050, grad/param norm = 1.9049e-01, time/batch = 18.1122s	
7913/22950 (epoch 17.240), train_loss = 1.10813768, grad/param norm = 2.0582e-01, time/batch = 15.4587s	
7914/22950 (epoch 17.242), train_loss = 1.21965965, grad/param norm = 1.8643e-01, time/batch = 16.4676s	
7915/22950 (epoch 17.244), train_loss = 1.28946164, grad/param norm = 2.2195e-01, time/batch = 20.1240s	
7916/22950 (epoch 17.246), train_loss = 1.23603438, grad/param norm = 1.9442e-01, time/batch = 18.6182s	
7917/22950 (epoch 17.248), train_loss = 1.16172140, grad/param norm = 2.0661e-01, time/batch = 17.6950s	
7918/22950 (epoch 17.251), train_loss = 1.05347571, grad/param norm = 1.9107e-01, time/batch = 17.8845s	
7919/22950 (epoch 17.253), train_loss = 1.06543216, grad/param norm = 2.1087e-01, time/batch = 19.0391s	
7920/22950 (epoch 17.255), train_loss = 1.15325192, grad/param norm = 2.2896e-01, time/batch = 17.5429s	
7921/22950 (epoch 17.257), train_loss = 1.24687987, grad/param norm = 2.0792e-01, time/batch = 18.2794s	
7922/22950 (epoch 17.259), train_loss = 0.98482271, grad/param norm = 2.0476e-01, time/batch = 19.8577s	
7923/22950 (epoch 17.261), train_loss = 1.09977116, grad/param norm = 2.1520e-01, time/batch = 19.7952s	
7924/22950 (epoch 17.264), train_loss = 1.02667992, grad/param norm = 2.0080e-01, time/batch = 16.8541s	
7925/22950 (epoch 17.266), train_loss = 1.15544694, grad/param norm = 2.0700e-01, time/batch = 20.3710s	
7926/22950 (epoch 17.268), train_loss = 1.12135797, grad/param norm = 1.8531e-01, time/batch = 19.8773s	
7927/22950 (epoch 17.270), train_loss = 1.13215955, grad/param norm = 2.0085e-01, time/batch = 18.3556s	
7928/22950 (epoch 17.272), train_loss = 1.23180939, grad/param norm = 2.0588e-01, time/batch = 19.8004s	
7929/22950 (epoch 17.275), train_loss = 1.06810591, grad/param norm = 2.1369e-01, time/batch = 18.6142s	
7930/22950 (epoch 17.277), train_loss = 0.95480585, grad/param norm = 1.7167e-01, time/batch = 18.2102s	
7931/22950 (epoch 17.279), train_loss = 1.07294401, grad/param norm = 2.1151e-01, time/batch = 18.5421s	
7932/22950 (epoch 17.281), train_loss = 1.06985971, grad/param norm = 2.0339e-01, time/batch = 19.4578s	
7933/22950 (epoch 17.283), train_loss = 0.94031495, grad/param norm = 1.6749e-01, time/batch = 17.8491s	
7934/22950 (epoch 17.285), train_loss = 1.12935931, grad/param norm = 1.8828e-01, time/batch = 18.2099s	
7935/22950 (epoch 17.288), train_loss = 1.15972863, grad/param norm = 1.8825e-01, time/batch = 16.2767s	
7936/22950 (epoch 17.290), train_loss = 1.06127240, grad/param norm = 1.7967e-01, time/batch = 17.6145s	
7937/22950 (epoch 17.292), train_loss = 1.21503816, grad/param norm = 1.9401e-01, time/batch = 18.2876s	
7938/22950 (epoch 17.294), train_loss = 1.09515820, grad/param norm = 1.8597e-01, time/batch = 17.1121s	
7939/22950 (epoch 17.296), train_loss = 0.89481015, grad/param norm = 1.5927e-01, time/batch = 19.0512s	
7940/22950 (epoch 17.298), train_loss = 1.12466505, grad/param norm = 1.9958e-01, time/batch = 17.4310s	
7941/22950 (epoch 17.301), train_loss = 1.12592725, grad/param norm = 2.0565e-01, time/batch = 17.7917s	
7942/22950 (epoch 17.303), train_loss = 1.17002569, grad/param norm = 2.0515e-01, time/batch = 20.2922s	
7943/22950 (epoch 17.305), train_loss = 1.15293496, grad/param norm = 2.1060e-01, time/batch = 17.8737s	
7944/22950 (epoch 17.307), train_loss = 1.23666914, grad/param norm = 2.1303e-01, time/batch = 18.3872s	
7945/22950 (epoch 17.309), train_loss = 1.05849841, grad/param norm = 1.7397e-01, time/batch = 16.7297s	
7946/22950 (epoch 17.312), train_loss = 1.11566374, grad/param norm = 2.1055e-01, time/batch = 17.7013s	
7947/22950 (epoch 17.314), train_loss = 1.08943884, grad/param norm = 1.8846e-01, time/batch = 18.1140s	
7948/22950 (epoch 17.316), train_loss = 1.13608435, grad/param norm = 2.1785e-01, time/batch = 19.9513s	
7949/22950 (epoch 17.318), train_loss = 0.93409870, grad/param norm = 1.8021e-01, time/batch = 16.3753s	
7950/22950 (epoch 17.320), train_loss = 1.05539555, grad/param norm = 1.8275e-01, time/batch = 18.1778s	
7951/22950 (epoch 17.322), train_loss = 1.08866463, grad/param norm = 2.0455e-01, time/batch = 19.0454s	
7952/22950 (epoch 17.325), train_loss = 0.88537654, grad/param norm = 1.7516e-01, time/batch = 18.7206s	
7953/22950 (epoch 17.327), train_loss = 0.92079158, grad/param norm = 1.8922e-01, time/batch = 17.0273s	
7954/22950 (epoch 17.329), train_loss = 1.04157564, grad/param norm = 1.8159e-01, time/batch = 19.2992s	
7955/22950 (epoch 17.331), train_loss = 0.97978769, grad/param norm = 1.9275e-01, time/batch = 18.5519s	
7956/22950 (epoch 17.333), train_loss = 1.08947939, grad/param norm = 1.9936e-01, time/batch = 18.2071s	
7957/22950 (epoch 17.336), train_loss = 1.07275484, grad/param norm = 2.0009e-01, time/batch = 17.9663s	
7958/22950 (epoch 17.338), train_loss = 1.05469621, grad/param norm = 1.7887e-01, time/batch = 17.3712s	
7959/22950 (epoch 17.340), train_loss = 1.10955457, grad/param norm = 2.1089e-01, time/batch = 18.6138s	
7960/22950 (epoch 17.342), train_loss = 1.20607129, grad/param norm = 2.0437e-01, time/batch = 18.9644s	
7961/22950 (epoch 17.344), train_loss = 1.08823144, grad/param norm = 2.0824e-01, time/batch = 18.3117s	
7962/22950 (epoch 17.346), train_loss = 1.21770623, grad/param norm = 2.1870e-01, time/batch = 18.2907s	
7963/22950 (epoch 17.349), train_loss = 1.11092577, grad/param norm = 2.2239e-01, time/batch = 18.7582s	
7964/22950 (epoch 17.351), train_loss = 1.14325662, grad/param norm = 1.9557e-01, time/batch = 17.3062s	
7965/22950 (epoch 17.353), train_loss = 1.21666752, grad/param norm = 2.4866e-01, time/batch = 19.4653s	
7966/22950 (epoch 17.355), train_loss = 1.22895203, grad/param norm = 2.1836e-01, time/batch = 16.7924s	
7967/22950 (epoch 17.357), train_loss = 1.11096929, grad/param norm = 2.2504e-01, time/batch = 18.1352s	
7968/22950 (epoch 17.359), train_loss = 1.13974540, grad/param norm = 2.1868e-01, time/batch = 17.8106s	
7969/22950 (epoch 17.362), train_loss = 1.11518331, grad/param norm = 1.9357e-01, time/batch = 16.9063s	
7970/22950 (epoch 17.364), train_loss = 1.10667599, grad/param norm = 2.0681e-01, time/batch = 18.5413s	
7971/22950 (epoch 17.366), train_loss = 1.01898156, grad/param norm = 1.7778e-01, time/batch = 17.0368s	
7972/22950 (epoch 17.368), train_loss = 1.16284691, grad/param norm = 2.2315e-01, time/batch = 18.5456s	
7973/22950 (epoch 17.370), train_loss = 1.08463700, grad/param norm = 2.2189e-01, time/batch = 16.5017s	
7974/22950 (epoch 17.373), train_loss = 0.98345199, grad/param norm = 1.9185e-01, time/batch = 19.4677s	
7975/22950 (epoch 17.375), train_loss = 1.21791413, grad/param norm = 2.1819e-01, time/batch = 19.7097s	
7976/22950 (epoch 17.377), train_loss = 1.03244199, grad/param norm = 2.0693e-01, time/batch = 17.2176s	
7977/22950 (epoch 17.379), train_loss = 1.12118332, grad/param norm = 2.0976e-01, time/batch = 19.8062s	
7978/22950 (epoch 17.381), train_loss = 0.95943856, grad/param norm = 1.9418e-01, time/batch = 18.0213s	
7979/22950 (epoch 17.383), train_loss = 1.11738026, grad/param norm = 2.1480e-01, time/batch = 17.2994s	
7980/22950 (epoch 17.386), train_loss = 1.02908060, grad/param norm = 1.9990e-01, time/batch = 19.3036s	
7981/22950 (epoch 17.388), train_loss = 1.11303938, grad/param norm = 2.1639e-01, time/batch = 18.7041s	
7982/22950 (epoch 17.390), train_loss = 1.01267959, grad/param norm = 1.8935e-01, time/batch = 18.4487s	
7983/22950 (epoch 17.392), train_loss = 1.03359993, grad/param norm = 1.9882e-01, time/batch = 18.4433s	
7984/22950 (epoch 17.394), train_loss = 1.03002446, grad/param norm = 1.8385e-01, time/batch = 18.1293s	
7985/22950 (epoch 17.397), train_loss = 1.23747152, grad/param norm = 2.0301e-01, time/batch = 18.3058s	
7986/22950 (epoch 17.399), train_loss = 1.25003340, grad/param norm = 2.6786e-01, time/batch = 15.5490s	
7987/22950 (epoch 17.401), train_loss = 1.33215128, grad/param norm = 2.2959e-01, time/batch = 18.0310s	
7988/22950 (epoch 17.403), train_loss = 1.08832218, grad/param norm = 2.0761e-01, time/batch = 20.1125s	
7989/22950 (epoch 17.405), train_loss = 1.23491533, grad/param norm = 2.8079e-01, time/batch = 18.7800s	
7990/22950 (epoch 17.407), train_loss = 1.26983404, grad/param norm = 2.0644e-01, time/batch = 18.6267s	
7991/22950 (epoch 17.410), train_loss = 1.02594291, grad/param norm = 1.8968e-01, time/batch = 20.0447s	
7992/22950 (epoch 17.412), train_loss = 1.11639883, grad/param norm = 2.1669e-01, time/batch = 18.9498s	
7993/22950 (epoch 17.414), train_loss = 1.21909784, grad/param norm = 2.1892e-01, time/batch = 17.5418s	
7994/22950 (epoch 17.416), train_loss = 1.15554577, grad/param norm = 2.4572e-01, time/batch = 18.8588s	
7995/22950 (epoch 17.418), train_loss = 1.15069769, grad/param norm = 2.0918e-01, time/batch = 17.5542s	
7996/22950 (epoch 17.420), train_loss = 1.16113448, grad/param norm = 2.2767e-01, time/batch = 19.7841s	
7997/22950 (epoch 17.423), train_loss = 1.03737067, grad/param norm = 1.8530e-01, time/batch = 19.6243s	
7998/22950 (epoch 17.425), train_loss = 1.11902451, grad/param norm = 2.0738e-01, time/batch = 19.2023s	
7999/22950 (epoch 17.427), train_loss = 1.10535027, grad/param norm = 2.0718e-01, time/batch = 17.5527s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch17.43_1.7240.t7	
8000/22950 (epoch 17.429), train_loss = 1.07497445, grad/param norm = 1.9635e-01, time/batch = 18.8841s	
8001/22950 (epoch 17.431), train_loss = 1.47232178, grad/param norm = 2.3100e-01, time/batch = 20.0483s	
8002/22950 (epoch 17.434), train_loss = 1.11287557, grad/param norm = 2.1939e-01, time/batch = 18.7055s	
8003/22950 (epoch 17.436), train_loss = 1.28355337, grad/param norm = 2.3925e-01, time/batch = 18.6193s	
8004/22950 (epoch 17.438), train_loss = 1.14900422, grad/param norm = 2.0343e-01, time/batch = 19.8750s	
8005/22950 (epoch 17.440), train_loss = 1.22507094, grad/param norm = 2.0817e-01, time/batch = 18.3125s	
8006/22950 (epoch 17.442), train_loss = 1.26822957, grad/param norm = 2.1406e-01, time/batch = 18.0859s	
8007/22950 (epoch 17.444), train_loss = 1.19028246, grad/param norm = 2.1312e-01, time/batch = 18.6456s	
8008/22950 (epoch 17.447), train_loss = 1.31365429, grad/param norm = 2.2913e-01, time/batch = 20.1926s	
8009/22950 (epoch 17.449), train_loss = 1.01315603, grad/param norm = 1.8259e-01, time/batch = 18.1170s	
8010/22950 (epoch 17.451), train_loss = 1.13580862, grad/param norm = 2.0091e-01, time/batch = 17.8095s	
8011/22950 (epoch 17.453), train_loss = 1.16422514, grad/param norm = 1.9756e-01, time/batch = 19.4562s	
8012/22950 (epoch 17.455), train_loss = 1.03420331, grad/param norm = 1.8470e-01, time/batch = 16.8549s	
8013/22950 (epoch 17.458), train_loss = 1.25973007, grad/param norm = 2.0759e-01, time/batch = 17.3754s	
8014/22950 (epoch 17.460), train_loss = 1.13998717, grad/param norm = 2.0552e-01, time/batch = 17.5303s	
8015/22950 (epoch 17.462), train_loss = 1.11533380, grad/param norm = 1.9042e-01, time/batch = 18.9626s	
8016/22950 (epoch 17.464), train_loss = 1.09257422, grad/param norm = 1.9894e-01, time/batch = 19.8703s	
8017/22950 (epoch 17.466), train_loss = 1.14961499, grad/param norm = 1.9462e-01, time/batch = 18.0486s	
8018/22950 (epoch 17.468), train_loss = 1.27126650, grad/param norm = 2.1207e-01, time/batch = 18.6931s	
8019/22950 (epoch 17.471), train_loss = 1.16381286, grad/param norm = 2.2180e-01, time/batch = 19.3599s	
8020/22950 (epoch 17.473), train_loss = 1.20367109, grad/param norm = 2.2282e-01, time/batch = 19.4592s	
8021/22950 (epoch 17.475), train_loss = 1.33254904, grad/param norm = 2.1619e-01, time/batch = 18.8064s	
8022/22950 (epoch 17.477), train_loss = 1.12086187, grad/param norm = 2.0461e-01, time/batch = 17.2026s	
8023/22950 (epoch 17.479), train_loss = 1.03959678, grad/param norm = 1.9345e-01, time/batch = 19.5442s	
8024/22950 (epoch 17.481), train_loss = 1.23453270, grad/param norm = 2.2350e-01, time/batch = 20.3740s	
8025/22950 (epoch 17.484), train_loss = 1.14613069, grad/param norm = 2.0815e-01, time/batch = 9.4709s	
8026/22950 (epoch 17.486), train_loss = 0.99755135, grad/param norm = 2.0320e-01, time/batch = 0.6926s	
8027/22950 (epoch 17.488), train_loss = 1.08482090, grad/param norm = 2.1799e-01, time/batch = 0.6952s	
8028/22950 (epoch 17.490), train_loss = 0.95846039, grad/param norm = 2.0095e-01, time/batch = 0.6931s	
8029/22950 (epoch 17.492), train_loss = 1.09409973, grad/param norm = 2.1701e-01, time/batch = 0.6891s	
8030/22950 (epoch 17.495), train_loss = 1.09826364, grad/param norm = 1.9891e-01, time/batch = 0.6924s	
8031/22950 (epoch 17.497), train_loss = 1.18889451, grad/param norm = 2.0344e-01, time/batch = 0.6969s	
8032/22950 (epoch 17.499), train_loss = 1.24275304, grad/param norm = 2.0380e-01, time/batch = 0.7817s	
8033/22950 (epoch 17.501), train_loss = 1.17612705, grad/param norm = 2.1491e-01, time/batch = 1.0148s	
8034/22950 (epoch 17.503), train_loss = 1.23298098, grad/param norm = 2.0573e-01, time/batch = 1.0079s	
8035/22950 (epoch 17.505), train_loss = 0.98780855, grad/param norm = 1.8105e-01, time/batch = 1.0095s	
8036/22950 (epoch 17.508), train_loss = 1.16830491, grad/param norm = 2.0137e-01, time/batch = 1.0156s	
8037/22950 (epoch 17.510), train_loss = 1.14589961, grad/param norm = 2.0845e-01, time/batch = 1.3009s	
8038/22950 (epoch 17.512), train_loss = 1.05081406, grad/param norm = 1.9904e-01, time/batch = 1.8891s	
8039/22950 (epoch 17.514), train_loss = 1.02187967, grad/param norm = 1.6807e-01, time/batch = 1.8976s	
8040/22950 (epoch 17.516), train_loss = 1.08522407, grad/param norm = 1.9550e-01, time/batch = 13.2922s	
8041/22950 (epoch 17.519), train_loss = 1.08247818, grad/param norm = 1.9380e-01, time/batch = 16.7823s	
8042/22950 (epoch 17.521), train_loss = 1.14331430, grad/param norm = 2.0888e-01, time/batch = 17.1135s	
8043/22950 (epoch 17.523), train_loss = 0.91625252, grad/param norm = 1.7959e-01, time/batch = 20.2138s	
8044/22950 (epoch 17.525), train_loss = 1.01594941, grad/param norm = 1.8059e-01, time/batch = 17.8040s	
8045/22950 (epoch 17.527), train_loss = 0.97463641, grad/param norm = 2.0334e-01, time/batch = 18.3641s	
8046/22950 (epoch 17.529), train_loss = 1.15241767, grad/param norm = 2.0693e-01, time/batch = 18.7932s	
8047/22950 (epoch 17.532), train_loss = 1.05702089, grad/param norm = 1.9464e-01, time/batch = 18.6382s	
8048/22950 (epoch 17.534), train_loss = 1.19230374, grad/param norm = 2.3692e-01, time/batch = 19.6161s	
8049/22950 (epoch 17.536), train_loss = 1.18264331, grad/param norm = 2.3235e-01, time/batch = 19.2753s	
8050/22950 (epoch 17.538), train_loss = 1.11844452, grad/param norm = 2.2063e-01, time/batch = 19.8556s	
8051/22950 (epoch 17.540), train_loss = 1.15343797, grad/param norm = 2.0021e-01, time/batch = 19.6191s	
8052/22950 (epoch 17.542), train_loss = 1.29360770, grad/param norm = 2.0742e-01, time/batch = 19.8701s	
8053/22950 (epoch 17.545), train_loss = 1.08053865, grad/param norm = 1.9374e-01, time/batch = 19.7132s	
8054/22950 (epoch 17.547), train_loss = 1.10478889, grad/param norm = 2.0019e-01, time/batch = 19.1238s	
8055/22950 (epoch 17.549), train_loss = 1.07176352, grad/param norm = 2.1492e-01, time/batch = 18.2736s	
8056/22950 (epoch 17.551), train_loss = 1.10257989, grad/param norm = 2.1548e-01, time/batch = 18.4555s	
8057/22950 (epoch 17.553), train_loss = 1.08639754, grad/param norm = 2.1625e-01, time/batch = 16.3781s	
8058/22950 (epoch 17.556), train_loss = 1.15138786, grad/param norm = 2.1086e-01, time/batch = 17.0900s	
8059/22950 (epoch 17.558), train_loss = 1.01903528, grad/param norm = 1.9925e-01, time/batch = 19.1899s	
8060/22950 (epoch 17.560), train_loss = 1.11696595, grad/param norm = 1.9892e-01, time/batch = 19.1005s	
8061/22950 (epoch 17.562), train_loss = 1.02542774, grad/param norm = 1.9368e-01, time/batch = 19.1037s	
8062/22950 (epoch 17.564), train_loss = 1.23094044, grad/param norm = 2.1640e-01, time/batch = 20.1236s	
8063/22950 (epoch 17.566), train_loss = 1.16616579, grad/param norm = 2.2314e-01, time/batch = 18.8769s	
8064/22950 (epoch 17.569), train_loss = 1.18542863, grad/param norm = 2.0979e-01, time/batch = 19.3710s	
8065/22950 (epoch 17.571), train_loss = 1.06978558, grad/param norm = 2.0845e-01, time/batch = 20.2871s	
8066/22950 (epoch 17.573), train_loss = 1.13810842, grad/param norm = 2.0471e-01, time/batch = 19.0336s	
8067/22950 (epoch 17.575), train_loss = 1.26409632, grad/param norm = 2.3653e-01, time/batch = 18.1126s	
8068/22950 (epoch 17.577), train_loss = 1.11423713, grad/param norm = 2.2043e-01, time/batch = 18.3826s	
8069/22950 (epoch 17.580), train_loss = 1.15012618, grad/param norm = 2.0819e-01, time/batch = 19.2796s	
8070/22950 (epoch 17.582), train_loss = 1.31295621, grad/param norm = 2.0788e-01, time/batch = 19.2817s	
8071/22950 (epoch 17.584), train_loss = 1.02784476, grad/param norm = 2.1244e-01, time/batch = 18.5140s	
8072/22950 (epoch 17.586), train_loss = 1.09397327, grad/param norm = 2.2274e-01, time/batch = 15.3121s	
8073/22950 (epoch 17.588), train_loss = 1.24368468, grad/param norm = 2.2390e-01, time/batch = 17.3686s	
8074/22950 (epoch 17.590), train_loss = 1.11616960, grad/param norm = 2.1008e-01, time/batch = 17.5479s	
8075/22950 (epoch 17.593), train_loss = 1.04325035, grad/param norm = 2.0221e-01, time/batch = 18.3027s	
8076/22950 (epoch 17.595), train_loss = 1.00782459, grad/param norm = 2.0656e-01, time/batch = 20.2182s	
8077/22950 (epoch 17.597), train_loss = 1.18216828, grad/param norm = 2.1301e-01, time/batch = 17.0324s	
8078/22950 (epoch 17.599), train_loss = 1.15090234, grad/param norm = 2.2594e-01, time/batch = 18.4683s	
8079/22950 (epoch 17.601), train_loss = 1.14847274, grad/param norm = 2.1890e-01, time/batch = 18.6961s	
8080/22950 (epoch 17.603), train_loss = 1.26029797, grad/param norm = 2.0796e-01, time/batch = 18.3763s	
8081/22950 (epoch 17.606), train_loss = 1.09788172, grad/param norm = 2.0469e-01, time/batch = 19.2076s	
8082/22950 (epoch 17.608), train_loss = 1.15331172, grad/param norm = 2.0698e-01, time/batch = 20.7003s	
8083/22950 (epoch 17.610), train_loss = 1.09930345, grad/param norm = 1.9374e-01, time/batch = 18.8003s	
8084/22950 (epoch 17.612), train_loss = 1.09537527, grad/param norm = 2.1373e-01, time/batch = 17.9601s	
8085/22950 (epoch 17.614), train_loss = 1.24301306, grad/param norm = 2.2270e-01, time/batch = 19.0450s	
8086/22950 (epoch 17.617), train_loss = 1.11369430, grad/param norm = 2.1736e-01, time/batch = 19.6254s	
8087/22950 (epoch 17.619), train_loss = 1.05514191, grad/param norm = 1.8031e-01, time/batch = 18.5914s	
8088/22950 (epoch 17.621), train_loss = 1.22809275, grad/param norm = 1.8848e-01, time/batch = 17.9584s	
8089/22950 (epoch 17.623), train_loss = 1.18325813, grad/param norm = 1.8587e-01, time/batch = 20.0410s	
8090/22950 (epoch 17.625), train_loss = 1.10739981, grad/param norm = 1.9593e-01, time/batch = 16.8641s	
8091/22950 (epoch 17.627), train_loss = 1.11217336, grad/param norm = 2.1350e-01, time/batch = 18.3479s	
8092/22950 (epoch 17.630), train_loss = 0.98436082, grad/param norm = 1.8858e-01, time/batch = 20.2140s	
8093/22950 (epoch 17.632), train_loss = 1.12217029, grad/param norm = 2.2061e-01, time/batch = 18.5479s	
8094/22950 (epoch 17.634), train_loss = 1.12290743, grad/param norm = 2.0146e-01, time/batch = 18.4017s	
8095/22950 (epoch 17.636), train_loss = 1.16009675, grad/param norm = 2.0451e-01, time/batch = 16.4452s	
8096/22950 (epoch 17.638), train_loss = 1.04776899, grad/param norm = 2.0009e-01, time/batch = 18.2085s	
8097/22950 (epoch 17.641), train_loss = 1.09112795, grad/param norm = 1.9528e-01, time/batch = 15.5593s	
8098/22950 (epoch 17.643), train_loss = 1.15760738, grad/param norm = 2.3505e-01, time/batch = 17.5579s	
8099/22950 (epoch 17.645), train_loss = 1.07175660, grad/param norm = 2.0828e-01, time/batch = 19.0633s	
8100/22950 (epoch 17.647), train_loss = 1.11209305, grad/param norm = 2.1520e-01, time/batch = 18.1221s	
8101/22950 (epoch 17.649), train_loss = 1.13093245, grad/param norm = 2.0771e-01, time/batch = 17.8813s	
8102/22950 (epoch 17.651), train_loss = 1.19345590, grad/param norm = 2.2519e-01, time/batch = 19.5601s	
8103/22950 (epoch 17.654), train_loss = 0.94928349, grad/param norm = 1.9524e-01, time/batch = 26.6641s	
8104/22950 (epoch 17.656), train_loss = 1.22854862, grad/param norm = 2.4136e-01, time/batch = 21.7561s	
8105/22950 (epoch 17.658), train_loss = 1.01851416, grad/param norm = 2.0725e-01, time/batch = 18.3053s	
8106/22950 (epoch 17.660), train_loss = 0.94204190, grad/param norm = 2.0423e-01, time/batch = 18.2639s	
8107/22950 (epoch 17.662), train_loss = 0.94416116, grad/param norm = 1.7717e-01, time/batch = 19.1298s	
8108/22950 (epoch 17.664), train_loss = 1.10098846, grad/param norm = 2.0232e-01, time/batch = 19.8930s	
8109/22950 (epoch 17.667), train_loss = 1.14522770, grad/param norm = 2.0166e-01, time/batch = 17.4426s	
8110/22950 (epoch 17.669), train_loss = 1.10213498, grad/param norm = 1.9829e-01, time/batch = 20.3770s	
8111/22950 (epoch 17.671), train_loss = 1.13886993, grad/param norm = 2.0250e-01, time/batch = 20.9392s	
8112/22950 (epoch 17.673), train_loss = 1.07850207, grad/param norm = 2.0576e-01, time/batch = 18.0368s	
8113/22950 (epoch 17.675), train_loss = 1.11599305, grad/param norm = 2.2071e-01, time/batch = 19.1308s	
8114/22950 (epoch 17.678), train_loss = 1.12924572, grad/param norm = 2.0379e-01, time/batch = 19.2988s	
8115/22950 (epoch 17.680), train_loss = 1.10939648, grad/param norm = 1.8714e-01, time/batch = 16.8473s	
8116/22950 (epoch 17.682), train_loss = 1.16183620, grad/param norm = 2.1266e-01, time/batch = 18.7647s	
8117/22950 (epoch 17.684), train_loss = 1.24143066, grad/param norm = 2.3236e-01, time/batch = 19.3028s	
8118/22950 (epoch 17.686), train_loss = 1.19736008, grad/param norm = 2.0967e-01, time/batch = 18.2922s	
8119/22950 (epoch 17.688), train_loss = 1.13495053, grad/param norm = 2.0663e-01, time/batch = 18.1274s	
8120/22950 (epoch 17.691), train_loss = 1.13283267, grad/param norm = 2.0395e-01, time/batch = 20.2189s	
8121/22950 (epoch 17.693), train_loss = 1.04342795, grad/param norm = 2.0303e-01, time/batch = 17.7855s	
8122/22950 (epoch 17.695), train_loss = 1.23191972, grad/param norm = 2.2558e-01, time/batch = 17.6127s	
8123/22950 (epoch 17.697), train_loss = 1.19691862, grad/param norm = 2.1345e-01, time/batch = 19.5450s	
8124/22950 (epoch 17.699), train_loss = 1.18803734, grad/param norm = 2.0463e-01, time/batch = 19.0425s	
8125/22950 (epoch 17.702), train_loss = 1.18870032, grad/param norm = 2.0232e-01, time/batch = 17.9542s	
8126/22950 (epoch 17.704), train_loss = 1.20238973, grad/param norm = 2.1542e-01, time/batch = 18.7768s	
8127/22950 (epoch 17.706), train_loss = 1.20751435, grad/param norm = 2.3245e-01, time/batch = 18.9855s	
8128/22950 (epoch 17.708), train_loss = 1.05544199, grad/param norm = 2.4139e-01, time/batch = 17.2965s	
8129/22950 (epoch 17.710), train_loss = 1.16982883, grad/param norm = 2.2250e-01, time/batch = 15.9649s	
8130/22950 (epoch 17.712), train_loss = 1.25655696, grad/param norm = 2.2306e-01, time/batch = 17.8710s	
8131/22950 (epoch 17.715), train_loss = 1.16525060, grad/param norm = 2.2282e-01, time/batch = 17.6175s	
8132/22950 (epoch 17.717), train_loss = 1.09987797, grad/param norm = 1.9737e-01, time/batch = 18.0523s	
8133/22950 (epoch 17.719), train_loss = 1.10309475, grad/param norm = 2.1236e-01, time/batch = 19.2806s	
8134/22950 (epoch 17.721), train_loss = 1.17788499, grad/param norm = 2.1663e-01, time/batch = 18.8866s	
8135/22950 (epoch 17.723), train_loss = 1.07589581, grad/param norm = 1.8630e-01, time/batch = 16.8534s	
8136/22950 (epoch 17.725), train_loss = 1.18933205, grad/param norm = 2.3782e-01, time/batch = 19.7090s	
8137/22950 (epoch 17.728), train_loss = 1.11247349, grad/param norm = 2.4963e-01, time/batch = 18.9627s	
8138/22950 (epoch 17.730), train_loss = 1.12014586, grad/param norm = 1.9808e-01, time/batch = 18.2776s	
8139/22950 (epoch 17.732), train_loss = 1.18161437, grad/param norm = 2.1704e-01, time/batch = 17.8838s	
8140/22950 (epoch 17.734), train_loss = 1.14515958, grad/param norm = 2.1396e-01, time/batch = 16.0520s	
8141/22950 (epoch 17.736), train_loss = 1.11103600, grad/param norm = 1.9953e-01, time/batch = 18.5337s	
8142/22950 (epoch 17.739), train_loss = 1.18020278, grad/param norm = 2.0036e-01, time/batch = 18.4636s	
8143/22950 (epoch 17.741), train_loss = 1.20535785, grad/param norm = 2.0466e-01, time/batch = 20.4611s	
8144/22950 (epoch 17.743), train_loss = 1.26484220, grad/param norm = 2.0099e-01, time/batch = 18.0346s	
8145/22950 (epoch 17.745), train_loss = 1.37725592, grad/param norm = 2.2644e-01, time/batch = 18.5431s	
8146/22950 (epoch 17.747), train_loss = 1.16055607, grad/param norm = 2.1413e-01, time/batch = 18.2959s	
8147/22950 (epoch 17.749), train_loss = 1.04646586, grad/param norm = 2.1589e-01, time/batch = 17.1856s	
8148/22950 (epoch 17.752), train_loss = 1.31080009, grad/param norm = 2.3233e-01, time/batch = 18.5145s	
8149/22950 (epoch 17.754), train_loss = 1.21652076, grad/param norm = 2.1666e-01, time/batch = 18.3111s	
8150/22950 (epoch 17.756), train_loss = 1.05710097, grad/param norm = 2.0147e-01, time/batch = 19.7145s	
8151/22950 (epoch 17.758), train_loss = 1.07955920, grad/param norm = 1.8632e-01, time/batch = 17.5323s	
8152/22950 (epoch 17.760), train_loss = 1.17721071, grad/param norm = 2.1415e-01, time/batch = 19.3888s	
8153/22950 (epoch 17.763), train_loss = 1.21268815, grad/param norm = 2.2298e-01, time/batch = 19.1281s	
8154/22950 (epoch 17.765), train_loss = 1.17301923, grad/param norm = 2.1577e-01, time/batch = 17.4573s	
8155/22950 (epoch 17.767), train_loss = 1.30906589, grad/param norm = 2.1111e-01, time/batch = 19.0376s	
8156/22950 (epoch 17.769), train_loss = 1.15871451, grad/param norm = 2.0296e-01, time/batch = 19.3012s	
8157/22950 (epoch 17.771), train_loss = 1.00818465, grad/param norm = 1.8981e-01, time/batch = 18.1093s	
8158/22950 (epoch 17.773), train_loss = 0.86504100, grad/param norm = 1.8801e-01, time/batch = 19.4482s	
8159/22950 (epoch 17.776), train_loss = 1.05731228, grad/param norm = 1.9548e-01, time/batch = 18.1267s	
8160/22950 (epoch 17.778), train_loss = 1.00774381, grad/param norm = 1.9720e-01, time/batch = 18.2913s	
8161/22950 (epoch 17.780), train_loss = 1.11103021, grad/param norm = 1.8237e-01, time/batch = 17.2922s	
8162/22950 (epoch 17.782), train_loss = 1.11976948, grad/param norm = 1.9628e-01, time/batch = 17.2891s	
8163/22950 (epoch 17.784), train_loss = 1.09389344, grad/param norm = 2.1512e-01, time/batch = 19.7931s	
8164/22950 (epoch 17.786), train_loss = 1.17212564, grad/param norm = 1.9694e-01, time/batch = 18.7678s	
8165/22950 (epoch 17.789), train_loss = 0.98945883, grad/param norm = 1.8520e-01, time/batch = 17.3690s	
8166/22950 (epoch 17.791), train_loss = 1.01790490, grad/param norm = 2.1252e-01, time/batch = 20.1238s	
8167/22950 (epoch 17.793), train_loss = 1.31157993, grad/param norm = 2.1164e-01, time/batch = 17.2877s	
8168/22950 (epoch 17.795), train_loss = 1.08576562, grad/param norm = 1.9454e-01, time/batch = 19.9344s	
8169/22950 (epoch 17.797), train_loss = 1.27042846, grad/param norm = 2.1774e-01, time/batch = 18.2109s	
8170/22950 (epoch 17.800), train_loss = 1.03352580, grad/param norm = 1.9051e-01, time/batch = 16.4750s	
8171/22950 (epoch 17.802), train_loss = 1.05261956, grad/param norm = 2.0692e-01, time/batch = 19.3664s	
8172/22950 (epoch 17.804), train_loss = 1.11742156, grad/param norm = 1.9926e-01, time/batch = 19.7120s	
8173/22950 (epoch 17.806), train_loss = 1.01145761, grad/param norm = 1.9938e-01, time/batch = 19.0378s	
8174/22950 (epoch 17.808), train_loss = 1.11005806, grad/param norm = 2.0437e-01, time/batch = 17.7238s	
8175/22950 (epoch 17.810), train_loss = 1.08982187, grad/param norm = 2.0692e-01, time/batch = 19.8828s	
8176/22950 (epoch 17.813), train_loss = 0.90994145, grad/param norm = 1.9188e-01, time/batch = 19.6298s	
8177/22950 (epoch 17.815), train_loss = 0.98551399, grad/param norm = 1.9452e-01, time/batch = 19.5298s	
8178/22950 (epoch 17.817), train_loss = 0.99810144, grad/param norm = 1.8782e-01, time/batch = 19.3810s	
8179/22950 (epoch 17.819), train_loss = 1.11066854, grad/param norm = 2.0406e-01, time/batch = 19.0486s	
8180/22950 (epoch 17.821), train_loss = 1.07016865, grad/param norm = 2.2455e-01, time/batch = 15.1479s	
8181/22950 (epoch 17.824), train_loss = 1.11420213, grad/param norm = 2.3412e-01, time/batch = 20.0293s	
8182/22950 (epoch 17.826), train_loss = 1.24104180, grad/param norm = 2.1944e-01, time/batch = 19.2262s	
8183/22950 (epoch 17.828), train_loss = 1.10512213, grad/param norm = 2.1283e-01, time/batch = 17.1900s	
8184/22950 (epoch 17.830), train_loss = 1.12220277, grad/param norm = 2.0992e-01, time/batch = 16.4339s	
8185/22950 (epoch 17.832), train_loss = 1.13251232, grad/param norm = 2.0001e-01, time/batch = 18.8898s	
8186/22950 (epoch 17.834), train_loss = 0.95187974, grad/param norm = 1.9630e-01, time/batch = 17.5318s	
8187/22950 (epoch 17.837), train_loss = 1.14807805, grad/param norm = 2.1454e-01, time/batch = 19.7022s	
8188/22950 (epoch 17.839), train_loss = 0.97768110, grad/param norm = 1.9051e-01, time/batch = 18.7165s	
8189/22950 (epoch 17.841), train_loss = 1.04566729, grad/param norm = 1.8543e-01, time/batch = 19.0304s	
8190/22950 (epoch 17.843), train_loss = 1.06342500, grad/param norm = 2.0210e-01, time/batch = 18.0229s	
8191/22950 (epoch 17.845), train_loss = 1.12903341, grad/param norm = 2.0219e-01, time/batch = 18.3864s	
8192/22950 (epoch 17.847), train_loss = 1.17785230, grad/param norm = 2.1076e-01, time/batch = 19.6309s	
8193/22950 (epoch 17.850), train_loss = 1.17471708, grad/param norm = 2.2335e-01, time/batch = 17.2733s	
8194/22950 (epoch 17.852), train_loss = 1.16867587, grad/param norm = 2.1530e-01, time/batch = 16.2439s	
8195/22950 (epoch 17.854), train_loss = 1.08743935, grad/param norm = 1.9940e-01, time/batch = 19.6943s	
8196/22950 (epoch 17.856), train_loss = 1.31139836, grad/param norm = 2.3872e-01, time/batch = 16.7132s	
8197/22950 (epoch 17.858), train_loss = 1.17376410, grad/param norm = 2.0054e-01, time/batch = 19.2156s	
8198/22950 (epoch 17.861), train_loss = 1.22151128, grad/param norm = 2.1679e-01, time/batch = 17.6198s	
8199/22950 (epoch 17.863), train_loss = 1.25985442, grad/param norm = 2.2623e-01, time/batch = 17.7681s	
8200/22950 (epoch 17.865), train_loss = 1.28307262, grad/param norm = 2.2837e-01, time/batch = 18.5324s	
8201/22950 (epoch 17.867), train_loss = 1.16711545, grad/param norm = 2.0590e-01, time/batch = 18.4497s	
8202/22950 (epoch 17.869), train_loss = 1.29540600, grad/param norm = 2.1868e-01, time/batch = 18.2019s	
8203/22950 (epoch 17.871), train_loss = 1.14228336, grad/param norm = 2.1111e-01, time/batch = 19.3547s	
8204/22950 (epoch 17.874), train_loss = 1.13422498, grad/param norm = 2.0735e-01, time/batch = 16.2749s	
8205/22950 (epoch 17.876), train_loss = 1.19278898, grad/param norm = 2.2295e-01, time/batch = 19.3144s	
8206/22950 (epoch 17.878), train_loss = 1.07664786, grad/param norm = 2.2145e-01, time/batch = 18.7160s	
8207/22950 (epoch 17.880), train_loss = 1.29311206, grad/param norm = 2.1291e-01, time/batch = 19.3892s	
8208/22950 (epoch 17.882), train_loss = 1.01884523, grad/param norm = 1.9911e-01, time/batch = 18.4718s	
8209/22950 (epoch 17.885), train_loss = 1.15253721, grad/param norm = 2.0284e-01, time/batch = 18.8689s	
8210/22950 (epoch 17.887), train_loss = 1.15574219, grad/param norm = 2.0626e-01, time/batch = 18.0519s	
8211/22950 (epoch 17.889), train_loss = 1.18013424, grad/param norm = 2.1572e-01, time/batch = 19.7104s	
8212/22950 (epoch 17.891), train_loss = 1.08266464, grad/param norm = 2.1209e-01, time/batch = 17.5382s	
8213/22950 (epoch 17.893), train_loss = 1.18747900, grad/param norm = 2.0461e-01, time/batch = 18.5272s	
8214/22950 (epoch 17.895), train_loss = 1.33048261, grad/param norm = 2.3439e-01, time/batch = 19.7849s	
8215/22950 (epoch 17.898), train_loss = 1.11248461, grad/param norm = 2.0652e-01, time/batch = 18.8706s	
8216/22950 (epoch 17.900), train_loss = 1.05543499, grad/param norm = 1.7782e-01, time/batch = 19.1960s	
8217/22950 (epoch 17.902), train_loss = 1.17429512, grad/param norm = 2.1082e-01, time/batch = 16.9396s	
8218/22950 (epoch 17.904), train_loss = 1.18440595, grad/param norm = 2.1782e-01, time/batch = 18.3608s	
8219/22950 (epoch 17.906), train_loss = 1.15171132, grad/param norm = 2.1147e-01, time/batch = 18.4383s	
8220/22950 (epoch 17.908), train_loss = 1.01063989, grad/param norm = 1.8620e-01, time/batch = 18.8001s	
8221/22950 (epoch 17.911), train_loss = 0.97657859, grad/param norm = 1.8940e-01, time/batch = 20.4618s	
8222/22950 (epoch 17.913), train_loss = 1.04286362, grad/param norm = 2.1285e-01, time/batch = 18.9475s	
8223/22950 (epoch 17.915), train_loss = 1.23077400, grad/param norm = 2.2688e-01, time/batch = 19.9612s	
8224/22950 (epoch 17.917), train_loss = 0.99605950, grad/param norm = 2.0296e-01, time/batch = 19.7043s	
8225/22950 (epoch 17.919), train_loss = 1.07265693, grad/param norm = 2.0093e-01, time/batch = 17.7935s	
8226/22950 (epoch 17.922), train_loss = 1.14029703, grad/param norm = 2.1606e-01, time/batch = 19.6346s	
8227/22950 (epoch 17.924), train_loss = 1.17262799, grad/param norm = 1.9744e-01, time/batch = 20.4532s	
8228/22950 (epoch 17.926), train_loss = 0.96258091, grad/param norm = 2.0031e-01, time/batch = 17.6054s	
8229/22950 (epoch 17.928), train_loss = 1.00138547, grad/param norm = 2.0941e-01, time/batch = 20.1214s	
8230/22950 (epoch 17.930), train_loss = 0.97775814, grad/param norm = 1.9870e-01, time/batch = 20.2112s	
8231/22950 (epoch 17.932), train_loss = 0.93383584, grad/param norm = 1.7998e-01, time/batch = 17.5337s	
8232/22950 (epoch 17.935), train_loss = 1.11056651, grad/param norm = 1.9257e-01, time/batch = 19.8666s	
8233/22950 (epoch 17.937), train_loss = 1.13007571, grad/param norm = 2.2396e-01, time/batch = 17.6384s	
8234/22950 (epoch 17.939), train_loss = 1.05174435, grad/param norm = 2.1359e-01, time/batch = 17.7906s	
8235/22950 (epoch 17.941), train_loss = 1.02941109, grad/param norm = 1.9245e-01, time/batch = 18.1155s	
8236/22950 (epoch 17.943), train_loss = 1.13504669, grad/param norm = 2.1423e-01, time/batch = 19.7919s	
8237/22950 (epoch 17.946), train_loss = 0.98634707, grad/param norm = 2.0653e-01, time/batch = 19.0397s	
8238/22950 (epoch 17.948), train_loss = 1.18702368, grad/param norm = 2.0273e-01, time/batch = 19.9519s	
8239/22950 (epoch 17.950), train_loss = 1.13526386, grad/param norm = 2.1939e-01, time/batch = 18.4758s	
8240/22950 (epoch 17.952), train_loss = 1.15477323, grad/param norm = 2.1606e-01, time/batch = 17.2059s	
8241/22950 (epoch 17.954), train_loss = 1.15409810, grad/param norm = 2.1177e-01, time/batch = 19.0253s	
8242/22950 (epoch 17.956), train_loss = 1.04471501, grad/param norm = 1.9054e-01, time/batch = 18.3884s	
8243/22950 (epoch 17.959), train_loss = 1.01681018, grad/param norm = 1.8751e-01, time/batch = 20.2109s	
8244/22950 (epoch 17.961), train_loss = 1.12953167, grad/param norm = 2.1585e-01, time/batch = 18.7044s	
8245/22950 (epoch 17.963), train_loss = 1.15664493, grad/param norm = 2.0897e-01, time/batch = 18.2117s	
8246/22950 (epoch 17.965), train_loss = 1.26633942, grad/param norm = 2.1060e-01, time/batch = 18.3833s	
8247/22950 (epoch 17.967), train_loss = 1.09575999, grad/param norm = 2.2379e-01, time/batch = 17.4365s	
8248/22950 (epoch 17.969), train_loss = 1.02659742, grad/param norm = 2.0580e-01, time/batch = 17.8765s	
8249/22950 (epoch 17.972), train_loss = 1.11014284, grad/param norm = 1.9432e-01, time/batch = 16.8690s	
8250/22950 (epoch 17.974), train_loss = 1.06888780, grad/param norm = 2.0114e-01, time/batch = 17.6769s	
8251/22950 (epoch 17.976), train_loss = 1.02256536, grad/param norm = 1.9296e-01, time/batch = 18.8642s	
8252/22950 (epoch 17.978), train_loss = 1.08024213, grad/param norm = 1.9311e-01, time/batch = 19.1022s	
8253/22950 (epoch 17.980), train_loss = 1.10712175, grad/param norm = 2.0302e-01, time/batch = 19.1144s	
8254/22950 (epoch 17.983), train_loss = 1.10709384, grad/param norm = 2.0124e-01, time/batch = 18.0320s	
8255/22950 (epoch 17.985), train_loss = 0.98241497, grad/param norm = 1.9271e-01, time/batch = 19.9607s	
8256/22950 (epoch 17.987), train_loss = 1.02188685, grad/param norm = 1.9487e-01, time/batch = 19.0331s	
8257/22950 (epoch 17.989), train_loss = 1.10899927, grad/param norm = 2.1302e-01, time/batch = 18.0230s	
8258/22950 (epoch 17.991), train_loss = 0.94053008, grad/param norm = 1.8230e-01, time/batch = 20.1223s	
8259/22950 (epoch 17.993), train_loss = 1.13316171, grad/param norm = 2.1224e-01, time/batch = 18.9704s	
8260/22950 (epoch 17.996), train_loss = 1.16091491, grad/param norm = 2.1145e-01, time/batch = 17.7021s	
8261/22950 (epoch 17.998), train_loss = 1.03375646, grad/param norm = 1.9878e-01, time/batch = 19.2045s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
8262/22950 (epoch 18.000), train_loss = 0.95565696, grad/param norm = 1.8703e-01, time/batch = 19.9405s	
8263/22950 (epoch 18.002), train_loss = 1.28962425, grad/param norm = 2.1443e-01, time/batch = 16.7045s	
8264/22950 (epoch 18.004), train_loss = 1.14207470, grad/param norm = 2.0150e-01, time/batch = 18.8706s	
8265/22950 (epoch 18.007), train_loss = 1.11984301, grad/param norm = 2.1477e-01, time/batch = 18.7098s	
8266/22950 (epoch 18.009), train_loss = 1.26686822, grad/param norm = 2.2727e-01, time/batch = 17.2413s	
8267/22950 (epoch 18.011), train_loss = 0.99411443, grad/param norm = 2.0129e-01, time/batch = 18.7001s	
8268/22950 (epoch 18.013), train_loss = 1.14821876, grad/param norm = 2.0040e-01, time/batch = 19.6216s	
8269/22950 (epoch 18.015), train_loss = 1.18275786, grad/param norm = 2.1451e-01, time/batch = 16.7075s	
8270/22950 (epoch 18.017), train_loss = 1.14908280, grad/param norm = 2.0001e-01, time/batch = 18.3523s	
8271/22950 (epoch 18.020), train_loss = 1.10299901, grad/param norm = 1.7844e-01, time/batch = 18.3709s	
8272/22950 (epoch 18.022), train_loss = 0.97089701, grad/param norm = 1.9528e-01, time/batch = 19.2952s	
8273/22950 (epoch 18.024), train_loss = 1.06834685, grad/param norm = 1.9618e-01, time/batch = 18.3872s	
8274/22950 (epoch 18.026), train_loss = 1.16495246, grad/param norm = 2.1223e-01, time/batch = 19.5473s	
8275/22950 (epoch 18.028), train_loss = 1.20197239, grad/param norm = 1.9299e-01, time/batch = 18.4631s	
8276/22950 (epoch 18.031), train_loss = 1.08804467, grad/param norm = 2.0405e-01, time/batch = 18.2991s	
8277/22950 (epoch 18.033), train_loss = 1.24827708, grad/param norm = 2.4495e-01, time/batch = 19.0514s	
8278/22950 (epoch 18.035), train_loss = 1.11500297, grad/param norm = 1.9164e-01, time/batch = 15.2446s	
8279/22950 (epoch 18.037), train_loss = 1.10904621, grad/param norm = 2.2072e-01, time/batch = 18.2861s	
8280/22950 (epoch 18.039), train_loss = 1.06820582, grad/param norm = 1.9546e-01, time/batch = 17.7150s	
8281/22950 (epoch 18.041), train_loss = 1.09321656, grad/param norm = 2.1269e-01, time/batch = 18.5656s	
8282/22950 (epoch 18.044), train_loss = 1.13785961, grad/param norm = 1.9977e-01, time/batch = 18.7858s	
8283/22950 (epoch 18.046), train_loss = 1.11373914, grad/param norm = 1.9884e-01, time/batch = 18.6885s	
8284/22950 (epoch 18.048), train_loss = 1.12210557, grad/param norm = 1.9993e-01, time/batch = 18.5696s	
8285/22950 (epoch 18.050), train_loss = 1.10829926, grad/param norm = 2.1677e-01, time/batch = 20.6158s	
8286/22950 (epoch 18.052), train_loss = 1.14231939, grad/param norm = 1.9921e-01, time/batch = 18.7079s	
8287/22950 (epoch 18.054), train_loss = 1.30641723, grad/param norm = 2.3296e-01, time/batch = 19.4670s	
8288/22950 (epoch 18.057), train_loss = 1.23687390, grad/param norm = 2.1749e-01, time/batch = 16.0343s	
8289/22950 (epoch 18.059), train_loss = 1.17006819, grad/param norm = 1.9921e-01, time/batch = 18.1279s	
8290/22950 (epoch 18.061), train_loss = 1.01157754, grad/param norm = 1.9028e-01, time/batch = 19.3868s	
8291/22950 (epoch 18.063), train_loss = 1.17487592, grad/param norm = 1.9834e-01, time/batch = 18.6871s	
8292/22950 (epoch 18.065), train_loss = 0.91831217, grad/param norm = 1.8119e-01, time/batch = 18.3612s	
8293/22950 (epoch 18.068), train_loss = 1.18656035, grad/param norm = 2.1333e-01, time/batch = 19.7036s	
8294/22950 (epoch 18.070), train_loss = 1.00774201, grad/param norm = 1.8777e-01, time/batch = 19.7985s	
8295/22950 (epoch 18.072), train_loss = 1.16035534, grad/param norm = 2.0639e-01, time/batch = 21.5710s	
8296/22950 (epoch 18.074), train_loss = 1.09972168, grad/param norm = 2.0486e-01, time/batch = 29.5855s	
8297/22950 (epoch 18.076), train_loss = 1.13641322, grad/param norm = 2.0207e-01, time/batch = 18.9715s	
8298/22950 (epoch 18.078), train_loss = 1.19966234, grad/param norm = 2.0950e-01, time/batch = 18.5992s	
8299/22950 (epoch 18.081), train_loss = 1.21049423, grad/param norm = 2.2752e-01, time/batch = 19.8609s	
8300/22950 (epoch 18.083), train_loss = 1.07887321, grad/param norm = 1.9959e-01, time/batch = 15.6305s	
8301/22950 (epoch 18.085), train_loss = 0.99632042, grad/param norm = 2.0712e-01, time/batch = 17.6129s	
8302/22950 (epoch 18.087), train_loss = 1.01466214, grad/param norm = 2.0055e-01, time/batch = 20.4633s	
8303/22950 (epoch 18.089), train_loss = 1.10859884, grad/param norm = 1.8327e-01, time/batch = 18.9636s	
8304/22950 (epoch 18.092), train_loss = 1.06673465, grad/param norm = 2.2645e-01, time/batch = 17.7817s	
8305/22950 (epoch 18.094), train_loss = 1.03644368, grad/param norm = 1.9648e-01, time/batch = 16.1913s	
8306/22950 (epoch 18.096), train_loss = 1.25387999, grad/param norm = 2.1644e-01, time/batch = 18.7053s	
8307/22950 (epoch 18.098), train_loss = 1.15495170, grad/param norm = 1.9894e-01, time/batch = 19.7852s	
8308/22950 (epoch 18.100), train_loss = 1.06501256, grad/param norm = 2.0780e-01, time/batch = 16.8807s	
8309/22950 (epoch 18.102), train_loss = 1.10438762, grad/param norm = 1.9415e-01, time/batch = 19.6199s	
8310/22950 (epoch 18.105), train_loss = 0.99676382, grad/param norm = 1.8714e-01, time/batch = 20.2766s	
8311/22950 (epoch 18.107), train_loss = 1.06371926, grad/param norm = 1.9284e-01, time/batch = 17.6931s	
8312/22950 (epoch 18.109), train_loss = 1.05758498, grad/param norm = 2.1611e-01, time/batch = 19.5312s	
8313/22950 (epoch 18.111), train_loss = 0.95904241, grad/param norm = 2.1194e-01, time/batch = 19.4523s	
8314/22950 (epoch 18.113), train_loss = 1.12735575, grad/param norm = 2.0833e-01, time/batch = 16.9480s	
8315/22950 (epoch 18.115), train_loss = 1.14075854, grad/param norm = 1.9684e-01, time/batch = 17.9675s	
8316/22950 (epoch 18.118), train_loss = 1.24600725, grad/param norm = 2.1182e-01, time/batch = 19.9541s	
8317/22950 (epoch 18.120), train_loss = 1.03669605, grad/param norm = 2.0948e-01, time/batch = 18.4499s	
8318/22950 (epoch 18.122), train_loss = 1.20183645, grad/param norm = 2.0688e-01, time/batch = 19.1353s	
8319/22950 (epoch 18.124), train_loss = 0.95216841, grad/param norm = 1.7135e-01, time/batch = 18.0618s	
8320/22950 (epoch 18.126), train_loss = 1.08383408, grad/param norm = 1.9270e-01, time/batch = 17.6124s	
8321/22950 (epoch 18.129), train_loss = 0.96246950, grad/param norm = 1.7728e-01, time/batch = 19.7896s	
8322/22950 (epoch 18.131), train_loss = 1.06708765, grad/param norm = 1.9601e-01, time/batch = 18.2070s	
8323/22950 (epoch 18.133), train_loss = 1.16173251, grad/param norm = 2.0924e-01, time/batch = 16.0303s	
8324/22950 (epoch 18.135), train_loss = 1.09141079, grad/param norm = 1.8315e-01, time/batch = 19.1027s	
8325/22950 (epoch 18.137), train_loss = 1.22737200, grad/param norm = 2.2421e-01, time/batch = 19.3662s	
8326/22950 (epoch 18.139), train_loss = 1.01632572, grad/param norm = 2.0330e-01, time/batch = 20.0520s	
8327/22950 (epoch 18.142), train_loss = 1.02181027, grad/param norm = 2.0080e-01, time/batch = 16.8701s	
8328/22950 (epoch 18.144), train_loss = 1.01738086, grad/param norm = 1.8921e-01, time/batch = 17.9800s	
8329/22950 (epoch 18.146), train_loss = 1.06864079, grad/param norm = 2.1280e-01, time/batch = 17.5378s	
8330/22950 (epoch 18.148), train_loss = 1.05092649, grad/param norm = 1.9091e-01, time/batch = 17.9501s	
8331/22950 (epoch 18.150), train_loss = 1.12051804, grad/param norm = 2.2475e-01, time/batch = 17.3077s	
8332/22950 (epoch 18.153), train_loss = 1.04535027, grad/param norm = 2.0203e-01, time/batch = 19.0478s	
8333/22950 (epoch 18.155), train_loss = 1.04910308, grad/param norm = 1.8862e-01, time/batch = 17.9647s	
8334/22950 (epoch 18.157), train_loss = 1.06221181, grad/param norm = 2.0405e-01, time/batch = 18.8010s	
8335/22950 (epoch 18.159), train_loss = 0.99962651, grad/param norm = 1.7911e-01, time/batch = 18.6001s	
8336/22950 (epoch 18.161), train_loss = 1.04421094, grad/param norm = 1.8479e-01, time/batch = 19.2868s	
8337/22950 (epoch 18.163), train_loss = 0.97902212, grad/param norm = 1.9348e-01, time/batch = 18.2825s	
8338/22950 (epoch 18.166), train_loss = 1.22335986, grad/param norm = 2.1402e-01, time/batch = 19.1224s	
8339/22950 (epoch 18.168), train_loss = 1.20379776, grad/param norm = 2.3940e-01, time/batch = 16.2091s	
8340/22950 (epoch 18.170), train_loss = 1.12141916, grad/param norm = 2.2837e-01, time/batch = 18.1999s	
8341/22950 (epoch 18.172), train_loss = 1.12567375, grad/param norm = 1.9003e-01, time/batch = 19.6201s	
8342/22950 (epoch 18.174), train_loss = 1.18431550, grad/param norm = 2.3079e-01, time/batch = 20.5389s	
8343/22950 (epoch 18.176), train_loss = 1.20550590, grad/param norm = 2.1330e-01, time/batch = 17.3690s	
8344/22950 (epoch 18.179), train_loss = 1.17570993, grad/param norm = 2.2058e-01, time/batch = 19.2927s	
8345/22950 (epoch 18.181), train_loss = 1.35081272, grad/param norm = 2.2010e-01, time/batch = 18.6360s	
8346/22950 (epoch 18.183), train_loss = 1.20382598, grad/param norm = 2.1571e-01, time/batch = 16.4292s	
8347/22950 (epoch 18.185), train_loss = 1.16033132, grad/param norm = 2.1267e-01, time/batch = 18.3649s	
8348/22950 (epoch 18.187), train_loss = 1.02827693, grad/param norm = 2.1437e-01, time/batch = 19.6266s	
8349/22950 (epoch 18.190), train_loss = 0.94735172, grad/param norm = 2.0029e-01, time/batch = 18.9622s	
8350/22950 (epoch 18.192), train_loss = 0.95236642, grad/param norm = 1.8486e-01, time/batch = 17.3785s	
8351/22950 (epoch 18.194), train_loss = 1.06959507, grad/param norm = 2.3968e-01, time/batch = 19.4683s	
8352/22950 (epoch 18.196), train_loss = 0.92055137, grad/param norm = 2.0649e-01, time/batch = 20.7057s	
8353/22950 (epoch 18.198), train_loss = 1.18353986, grad/param norm = 2.1376e-01, time/batch = 18.9426s	
8354/22950 (epoch 18.200), train_loss = 1.02081060, grad/param norm = 1.8849e-01, time/batch = 18.2796s	
8355/22950 (epoch 18.203), train_loss = 0.97947063, grad/param norm = 1.8724e-01, time/batch = 18.4455s	
8356/22950 (epoch 18.205), train_loss = 1.04239979, grad/param norm = 1.9031e-01, time/batch = 16.5964s	
8357/22950 (epoch 18.207), train_loss = 1.08946433, grad/param norm = 2.0638e-01, time/batch = 19.0607s	
8358/22950 (epoch 18.209), train_loss = 1.11927970, grad/param norm = 1.9850e-01, time/batch = 17.7997s	
8359/22950 (epoch 18.211), train_loss = 0.92909745, grad/param norm = 2.1705e-01, time/batch = 18.1311s	
8360/22950 (epoch 18.214), train_loss = 1.06349457, grad/param norm = 1.9106e-01, time/batch = 18.7560s	
8361/22950 (epoch 18.216), train_loss = 1.16910985, grad/param norm = 2.0606e-01, time/batch = 18.9625s	
8362/22950 (epoch 18.218), train_loss = 1.10836671, grad/param norm = 1.9516e-01, time/batch = 17.4051s	
8363/22950 (epoch 18.220), train_loss = 1.21463885, grad/param norm = 2.2128e-01, time/batch = 18.5295s	
8364/22950 (epoch 18.222), train_loss = 1.20178650, grad/param norm = 2.1035e-01, time/batch = 18.9725s	
8365/22950 (epoch 18.224), train_loss = 1.08786598, grad/param norm = 2.0441e-01, time/batch = 19.7878s	
8366/22950 (epoch 18.227), train_loss = 1.17557371, grad/param norm = 1.8153e-01, time/batch = 18.8624s	
8367/22950 (epoch 18.229), train_loss = 1.17334846, grad/param norm = 2.0377e-01, time/batch = 16.1053s	
8368/22950 (epoch 18.231), train_loss = 0.96714596, grad/param norm = 1.8341e-01, time/batch = 19.7958s	
8369/22950 (epoch 18.233), train_loss = 1.04432848, grad/param norm = 1.9654e-01, time/batch = 17.0482s	
8370/22950 (epoch 18.235), train_loss = 1.23489682, grad/param norm = 2.1186e-01, time/batch = 19.6479s	
8371/22950 (epoch 18.237), train_loss = 1.00470077, grad/param norm = 1.9160e-01, time/batch = 19.0478s	
8372/22950 (epoch 18.240), train_loss = 1.08725743, grad/param norm = 2.1112e-01, time/batch = 18.1937s	
8373/22950 (epoch 18.242), train_loss = 1.20248421, grad/param norm = 1.9125e-01, time/batch = 19.1402s	
8374/22950 (epoch 18.244), train_loss = 1.26733564, grad/param norm = 2.3172e-01, time/batch = 19.7909s	
8375/22950 (epoch 18.246), train_loss = 1.21169958, grad/param norm = 1.9891e-01, time/batch = 17.6772s	
8376/22950 (epoch 18.248), train_loss = 1.13964792, grad/param norm = 2.0770e-01, time/batch = 18.8658s	
8377/22950 (epoch 18.251), train_loss = 1.03120826, grad/param norm = 1.9189e-01, time/batch = 18.6426s	
8378/22950 (epoch 18.253), train_loss = 1.05135434, grad/param norm = 2.2049e-01, time/batch = 18.2667s	
8379/22950 (epoch 18.255), train_loss = 1.12625309, grad/param norm = 2.2599e-01, time/batch = 16.7225s	
8380/22950 (epoch 18.257), train_loss = 1.22112217, grad/param norm = 2.0766e-01, time/batch = 17.9748s	
8381/22950 (epoch 18.259), train_loss = 0.95956492, grad/param norm = 2.0651e-01, time/batch = 19.4624s	
8382/22950 (epoch 18.261), train_loss = 1.06768885, grad/param norm = 2.0266e-01, time/batch = 19.1137s	
8383/22950 (epoch 18.264), train_loss = 0.99771367, grad/param norm = 1.9189e-01, time/batch = 19.6321s	
8384/22950 (epoch 18.266), train_loss = 1.11841047, grad/param norm = 2.0835e-01, time/batch = 17.4167s	
8385/22950 (epoch 18.268), train_loss = 1.09087966, grad/param norm = 1.8380e-01, time/batch = 17.6947s	
8386/22950 (epoch 18.270), train_loss = 1.10658935, grad/param norm = 2.0490e-01, time/batch = 19.8712s	
8387/22950 (epoch 18.272), train_loss = 1.20557082, grad/param norm = 2.0467e-01, time/batch = 18.6387s	
8388/22950 (epoch 18.275), train_loss = 1.02742786, grad/param norm = 1.9350e-01, time/batch = 18.7032s	
8389/22950 (epoch 18.277), train_loss = 0.92867834, grad/param norm = 1.7168e-01, time/batch = 19.6275s	
8390/22950 (epoch 18.279), train_loss = 1.05169883, grad/param norm = 2.2443e-01, time/batch = 20.1959s	
8391/22950 (epoch 18.281), train_loss = 1.05051160, grad/param norm = 1.9771e-01, time/batch = 18.2896s	
8392/22950 (epoch 18.283), train_loss = 0.92361402, grad/param norm = 1.6721e-01, time/batch = 18.0629s	
8393/22950 (epoch 18.285), train_loss = 1.11272384, grad/param norm = 1.9608e-01, time/batch = 15.8013s	
8394/22950 (epoch 18.288), train_loss = 1.13896780, grad/param norm = 1.9146e-01, time/batch = 18.6410s	
8395/22950 (epoch 18.290), train_loss = 1.04463246, grad/param norm = 1.8486e-01, time/batch = 18.3723s	
8396/22950 (epoch 18.292), train_loss = 1.19023335, grad/param norm = 2.0147e-01, time/batch = 19.3834s	
8397/22950 (epoch 18.294), train_loss = 1.07865355, grad/param norm = 1.8655e-01, time/batch = 19.2088s	
8398/22950 (epoch 18.296), train_loss = 0.86866181, grad/param norm = 1.5645e-01, time/batch = 18.3633s	
8399/22950 (epoch 18.298), train_loss = 1.10629236, grad/param norm = 1.9761e-01, time/batch = 18.8824s	
8400/22950 (epoch 18.301), train_loss = 1.10816029, grad/param norm = 2.0796e-01, time/batch = 18.7855s	
8401/22950 (epoch 18.303), train_loss = 1.13434830, grad/param norm = 2.0913e-01, time/batch = 19.1151s	
8402/22950 (epoch 18.305), train_loss = 1.12016552, grad/param norm = 2.1660e-01, time/batch = 19.4561s	
8403/22950 (epoch 18.307), train_loss = 1.21043489, grad/param norm = 2.2283e-01, time/batch = 16.6135s	
8404/22950 (epoch 18.309), train_loss = 1.02198320, grad/param norm = 1.7886e-01, time/batch = 15.8764s	
8405/22950 (epoch 18.312), train_loss = 1.09564847, grad/param norm = 2.1035e-01, time/batch = 19.4576s	
8406/22950 (epoch 18.314), train_loss = 1.07097246, grad/param norm = 1.8500e-01, time/batch = 19.2990s	
8407/22950 (epoch 18.316), train_loss = 1.10657127, grad/param norm = 2.1862e-01, time/batch = 17.8644s	
8408/22950 (epoch 18.318), train_loss = 0.92325672, grad/param norm = 1.7690e-01, time/batch = 18.1747s	
8409/22950 (epoch 18.320), train_loss = 1.02697521, grad/param norm = 1.7855e-01, time/batch = 18.9003s	
8410/22950 (epoch 18.322), train_loss = 1.06191509, grad/param norm = 2.0000e-01, time/batch = 20.2064s	
8411/22950 (epoch 18.325), train_loss = 0.86193495, grad/param norm = 1.7420e-01, time/batch = 18.1063s	
8412/22950 (epoch 18.327), train_loss = 0.90387951, grad/param norm = 1.8507e-01, time/batch = 19.2139s	
8413/22950 (epoch 18.329), train_loss = 1.02173355, grad/param norm = 1.8537e-01, time/batch = 20.2113s	
8414/22950 (epoch 18.331), train_loss = 0.95787300, grad/param norm = 1.8531e-01, time/batch = 17.3656s	
8415/22950 (epoch 18.333), train_loss = 1.06786373, grad/param norm = 2.0223e-01, time/batch = 19.9755s	
8416/22950 (epoch 18.336), train_loss = 1.04965707, grad/param norm = 1.9340e-01, time/batch = 19.4680s	
8417/22950 (epoch 18.338), train_loss = 1.03747582, grad/param norm = 1.8773e-01, time/batch = 18.2208s	
8418/22950 (epoch 18.340), train_loss = 1.08792090, grad/param norm = 2.1518e-01, time/batch = 20.5350s	
8419/22950 (epoch 18.342), train_loss = 1.18736454, grad/param norm = 2.0731e-01, time/batch = 18.9594s	
8420/22950 (epoch 18.344), train_loss = 1.06285786, grad/param norm = 2.1412e-01, time/batch = 17.6236s	
8421/22950 (epoch 18.346), train_loss = 1.19176521, grad/param norm = 2.2131e-01, time/batch = 19.2109s	
8422/22950 (epoch 18.349), train_loss = 1.09118011, grad/param norm = 2.2226e-01, time/batch = 19.5445s	
8423/22950 (epoch 18.351), train_loss = 1.11888573, grad/param norm = 1.9709e-01, time/batch = 17.7901s	
8424/22950 (epoch 18.353), train_loss = 1.18115666, grad/param norm = 2.4318e-01, time/batch = 18.7052s	
8425/22950 (epoch 18.355), train_loss = 1.21326848, grad/param norm = 2.7837e-01, time/batch = 16.7808s	
8426/22950 (epoch 18.357), train_loss = 1.09870115, grad/param norm = 2.2821e-01, time/batch = 18.7734s	
8427/22950 (epoch 18.359), train_loss = 1.10978774, grad/param norm = 2.3295e-01, time/batch = 18.3735s	
8428/22950 (epoch 18.362), train_loss = 1.09011584, grad/param norm = 2.0219e-01, time/batch = 19.9548s	
8429/22950 (epoch 18.364), train_loss = 1.07848975, grad/param norm = 2.0854e-01, time/batch = 18.1106s	
8430/22950 (epoch 18.366), train_loss = 1.00828281, grad/param norm = 1.8497e-01, time/batch = 18.1102s	
8431/22950 (epoch 18.368), train_loss = 1.13799035, grad/param norm = 2.2084e-01, time/batch = 17.8106s	
8432/22950 (epoch 18.370), train_loss = 1.05946189, grad/param norm = 2.2248e-01, time/batch = 19.3897s	
8433/22950 (epoch 18.373), train_loss = 0.96602683, grad/param norm = 1.9690e-01, time/batch = 17.0486s	
8434/22950 (epoch 18.375), train_loss = 1.19508455, grad/param norm = 2.3577e-01, time/batch = 19.3020s	
8435/22950 (epoch 18.377), train_loss = 1.00793980, grad/param norm = 2.1374e-01, time/batch = 18.1493s	
8436/22950 (epoch 18.379), train_loss = 1.09200879, grad/param norm = 2.1461e-01, time/batch = 17.7057s	
8437/22950 (epoch 18.381), train_loss = 0.94637076, grad/param norm = 2.0131e-01, time/batch = 18.8679s	
8438/22950 (epoch 18.383), train_loss = 1.10248686, grad/param norm = 2.2194e-01, time/batch = 16.1955s	
8439/22950 (epoch 18.386), train_loss = 0.99627214, grad/param norm = 1.9901e-01, time/batch = 19.9388s	
8440/22950 (epoch 18.388), train_loss = 1.08764901, grad/param norm = 2.1202e-01, time/batch = 18.4269s	
8441/22950 (epoch 18.390), train_loss = 0.97826078, grad/param norm = 1.8532e-01, time/batch = 18.3825s	
8442/22950 (epoch 18.392), train_loss = 1.01501642, grad/param norm = 2.0083e-01, time/batch = 18.3043s	
8443/22950 (epoch 18.394), train_loss = 1.00775392, grad/param norm = 1.7954e-01, time/batch = 18.1088s	
8444/22950 (epoch 18.397), train_loss = 1.22479800, grad/param norm = 2.1041e-01, time/batch = 19.9567s	
8445/22950 (epoch 18.399), train_loss = 1.22341824, grad/param norm = 2.3685e-01, time/batch = 18.4617s	
8446/22950 (epoch 18.401), train_loss = 1.31135803, grad/param norm = 2.2462e-01, time/batch = 18.6934s	
8447/22950 (epoch 18.403), train_loss = 1.07663842, grad/param norm = 2.3465e-01, time/batch = 19.3798s	
8448/22950 (epoch 18.405), train_loss = 1.20603368, grad/param norm = 2.2805e-01, time/batch = 19.2871s	
8449/22950 (epoch 18.407), train_loss = 1.24779383, grad/param norm = 2.0193e-01, time/batch = 18.0516s	
8450/22950 (epoch 18.410), train_loss = 1.01029097, grad/param norm = 1.9595e-01, time/batch = 18.7051s	
8451/22950 (epoch 18.412), train_loss = 1.08907962, grad/param norm = 2.1826e-01, time/batch = 20.1998s	
8452/22950 (epoch 18.414), train_loss = 1.19118926, grad/param norm = 2.1749e-01, time/batch = 17.7010s	
8453/22950 (epoch 18.416), train_loss = 1.12468536, grad/param norm = 2.2884e-01, time/batch = 19.5369s	
8454/22950 (epoch 18.418), train_loss = 1.11773234, grad/param norm = 2.1832e-01, time/batch = 20.2897s	
8455/22950 (epoch 18.420), train_loss = 1.13933043, grad/param norm = 2.1852e-01, time/batch = 16.9534s	
8456/22950 (epoch 18.423), train_loss = 1.02077392, grad/param norm = 1.8923e-01, time/batch = 19.5287s	
8457/22950 (epoch 18.425), train_loss = 1.09731109, grad/param norm = 2.1118e-01, time/batch = 18.3037s	
8458/22950 (epoch 18.427), train_loss = 1.07043091, grad/param norm = 1.9982e-01, time/batch = 15.9212s	
8459/22950 (epoch 18.429), train_loss = 1.04953815, grad/param norm = 1.8692e-01, time/batch = 16.5316s	
8460/22950 (epoch 18.431), train_loss = 1.14981144, grad/param norm = 2.1256e-01, time/batch = 16.5778s	
8461/22950 (epoch 18.434), train_loss = 1.08771239, grad/param norm = 2.0157e-01, time/batch = 20.3049s	
8462/22950 (epoch 18.436), train_loss = 1.24854804, grad/param norm = 2.2439e-01, time/batch = 18.3824s	
8463/22950 (epoch 18.438), train_loss = 1.12856660, grad/param norm = 2.0938e-01, time/batch = 17.9016s	
8464/22950 (epoch 18.440), train_loss = 1.20833598, grad/param norm = 2.0987e-01, time/batch = 19.7067s	
8465/22950 (epoch 18.442), train_loss = 1.24891005, grad/param norm = 2.2559e-01, time/batch = 18.9541s	
8466/22950 (epoch 18.444), train_loss = 1.15557203, grad/param norm = 2.0731e-01, time/batch = 19.8801s	
8467/22950 (epoch 18.447), train_loss = 1.28420046, grad/param norm = 2.3170e-01, time/batch = 18.6209s	
8468/22950 (epoch 18.449), train_loss = 0.99717736, grad/param norm = 1.8701e-01, time/batch = 18.4578s	
8469/22950 (epoch 18.451), train_loss = 1.12031703, grad/param norm = 1.9844e-01, time/batch = 16.0244s	
8470/22950 (epoch 18.453), train_loss = 1.13804361, grad/param norm = 1.9318e-01, time/batch = 19.3662s	
8471/22950 (epoch 18.455), train_loss = 1.01913945, grad/param norm = 1.8572e-01, time/batch = 18.8033s	
8472/22950 (epoch 18.458), train_loss = 1.22736097, grad/param norm = 2.0831e-01, time/batch = 17.3442s	
8473/22950 (epoch 18.460), train_loss = 1.12638251, grad/param norm = 2.1229e-01, time/batch = 18.9712s	
8474/22950 (epoch 18.462), train_loss = 1.10103790, grad/param norm = 1.9846e-01, time/batch = 19.3044s	
8475/22950 (epoch 18.464), train_loss = 1.06915847, grad/param norm = 1.9709e-01, time/batch = 17.4492s	
8476/22950 (epoch 18.466), train_loss = 1.13568286, grad/param norm = 1.9668e-01, time/batch = 19.4466s	
8477/22950 (epoch 18.468), train_loss = 1.24158554, grad/param norm = 2.1378e-01, time/batch = 19.9578s	
8478/22950 (epoch 18.471), train_loss = 1.14950295, grad/param norm = 2.3696e-01, time/batch = 18.6246s	
8479/22950 (epoch 18.473), train_loss = 1.18888781, grad/param norm = 2.2288e-01, time/batch = 19.3817s	
8480/22950 (epoch 18.475), train_loss = 1.30218572, grad/param norm = 2.1796e-01, time/batch = 18.3816s	
8481/22950 (epoch 18.477), train_loss = 1.09929183, grad/param norm = 1.9894e-01, time/batch = 18.6237s	
8482/22950 (epoch 18.479), train_loss = 1.01677880, grad/param norm = 1.9334e-01, time/batch = 20.2155s	
8483/22950 (epoch 18.481), train_loss = 1.20549478, grad/param norm = 2.2417e-01, time/batch = 19.5371s	
8484/22950 (epoch 18.484), train_loss = 1.11349020, grad/param norm = 1.9994e-01, time/batch = 17.9473s	
8485/22950 (epoch 18.486), train_loss = 0.97715871, grad/param norm = 1.8782e-01, time/batch = 16.9935s	
8486/22950 (epoch 18.488), train_loss = 1.06883300, grad/param norm = 2.5181e-01, time/batch = 18.5507s	
8487/22950 (epoch 18.490), train_loss = 0.95304251, grad/param norm = 2.2414e-01, time/batch = 19.8752s	
8488/22950 (epoch 18.492), train_loss = 1.07401140, grad/param norm = 2.1096e-01, time/batch = 30.2777s	
8489/22950 (epoch 18.495), train_loss = 1.07619896, grad/param norm = 1.9774e-01, time/batch = 18.7189s	
8490/22950 (epoch 18.497), train_loss = 1.17417078, grad/param norm = 2.1615e-01, time/batch = 17.6097s	
8491/22950 (epoch 18.499), train_loss = 1.21420072, grad/param norm = 2.0105e-01, time/batch = 18.5461s	
8492/22950 (epoch 18.501), train_loss = 1.15636477, grad/param norm = 2.1199e-01, time/batch = 17.7150s	
8493/22950 (epoch 18.503), train_loss = 1.21190488, grad/param norm = 2.0876e-01, time/batch = 18.3832s	
8494/22950 (epoch 18.505), train_loss = 0.97801483, grad/param norm = 1.8741e-01, time/batch = 19.1310s	
8495/22950 (epoch 18.508), train_loss = 1.13808672, grad/param norm = 2.0147e-01, time/batch = 17.6492s	
8496/22950 (epoch 18.510), train_loss = 1.13076595, grad/param norm = 2.1761e-01, time/batch = 19.7932s	
8497/22950 (epoch 18.512), train_loss = 1.02482344, grad/param norm = 1.9800e-01, time/batch = 19.6832s	
8498/22950 (epoch 18.514), train_loss = 1.00257987, grad/param norm = 1.7185e-01, time/batch = 19.3790s	
8499/22950 (epoch 18.516), train_loss = 1.06148713, grad/param norm = 1.9933e-01, time/batch = 19.2971s	
8500/22950 (epoch 18.519), train_loss = 1.06475561, grad/param norm = 1.8739e-01, time/batch = 18.2794s	
8501/22950 (epoch 18.521), train_loss = 1.10843434, grad/param norm = 2.1165e-01, time/batch = 19.7891s	
8502/22950 (epoch 18.523), train_loss = 0.90032160, grad/param norm = 1.8708e-01, time/batch = 18.6296s	
8503/22950 (epoch 18.525), train_loss = 0.99309783, grad/param norm = 1.8091e-01, time/batch = 16.6984s	
8504/22950 (epoch 18.527), train_loss = 0.95328326, grad/param norm = 2.0460e-01, time/batch = 19.1351s	
8505/22950 (epoch 18.529), train_loss = 1.13518040, grad/param norm = 2.1693e-01, time/batch = 17.2224s	
8506/22950 (epoch 18.532), train_loss = 1.03958740, grad/param norm = 2.0563e-01, time/batch = 17.6738s	
8507/22950 (epoch 18.534), train_loss = 1.15922757, grad/param norm = 2.2786e-01, time/batch = 17.6115s	
8508/22950 (epoch 18.536), train_loss = 1.15973413, grad/param norm = 2.3337e-01, time/batch = 17.5463s	
8509/22950 (epoch 18.538), train_loss = 1.10405482, grad/param norm = 2.2752e-01, time/batch = 19.6433s	
8510/22950 (epoch 18.540), train_loss = 1.12943360, grad/param norm = 2.1199e-01, time/batch = 15.3852s	
8511/22950 (epoch 18.542), train_loss = 1.25909971, grad/param norm = 2.1663e-01, time/batch = 17.1138s	
8512/22950 (epoch 18.545), train_loss = 1.05708919, grad/param norm = 1.9522e-01, time/batch = 20.4408s	
8513/22950 (epoch 18.547), train_loss = 1.07843869, grad/param norm = 2.0248e-01, time/batch = 18.1271s	
8514/22950 (epoch 18.549), train_loss = 1.05002792, grad/param norm = 2.1854e-01, time/batch = 19.1242s	
8515/22950 (epoch 18.551), train_loss = 1.07940673, grad/param norm = 2.1225e-01, time/batch = 20.1315s	
8516/22950 (epoch 18.553), train_loss = 1.07293263, grad/param norm = 2.2691e-01, time/batch = 18.1952s	
8517/22950 (epoch 18.556), train_loss = 1.12788635, grad/param norm = 2.1999e-01, time/batch = 20.1344s	
8518/22950 (epoch 18.558), train_loss = 0.98512628, grad/param norm = 1.8807e-01, time/batch = 18.7934s	
8519/22950 (epoch 18.560), train_loss = 1.09267200, grad/param norm = 2.0138e-01, time/batch = 18.0281s	
8520/22950 (epoch 18.562), train_loss = 1.00755165, grad/param norm = 1.9423e-01, time/batch = 19.8868s	
8521/22950 (epoch 18.564), train_loss = 1.21267996, grad/param norm = 2.3622e-01, time/batch = 18.3731s	
8522/22950 (epoch 18.566), train_loss = 1.12997658, grad/param norm = 2.1538e-01, time/batch = 18.4541s	
8523/22950 (epoch 18.569), train_loss = 1.14940732, grad/param norm = 2.0400e-01, time/batch = 19.1158s	
8524/22950 (epoch 18.571), train_loss = 1.05795339, grad/param norm = 2.0509e-01, time/batch = 19.7935s	
8525/22950 (epoch 18.573), train_loss = 1.10730770, grad/param norm = 2.0641e-01, time/batch = 19.2094s	
8526/22950 (epoch 18.575), train_loss = 1.23517808, grad/param norm = 2.5204e-01, time/batch = 18.1000s	
8527/22950 (epoch 18.577), train_loss = 1.09956991, grad/param norm = 2.1480e-01, time/batch = 15.9506s	
8528/22950 (epoch 18.580), train_loss = 1.12962768, grad/param norm = 2.1367e-01, time/batch = 19.1909s	
8529/22950 (epoch 18.582), train_loss = 1.29849048, grad/param norm = 2.2691e-01, time/batch = 17.3658s	
8530/22950 (epoch 18.584), train_loss = 0.99515619, grad/param norm = 1.9670e-01, time/batch = 19.8870s	
8531/22950 (epoch 18.586), train_loss = 1.06838712, grad/param norm = 2.1963e-01, time/batch = 16.0386s	
8532/22950 (epoch 18.588), train_loss = 1.21854926, grad/param norm = 2.0724e-01, time/batch = 18.4509s	
8533/22950 (epoch 18.590), train_loss = 1.10279650, grad/param norm = 2.1337e-01, time/batch = 19.2252s	
8534/22950 (epoch 18.593), train_loss = 1.03671589, grad/param norm = 2.1928e-01, time/batch = 18.3946s	
8535/22950 (epoch 18.595), train_loss = 0.97710612, grad/param norm = 2.0155e-01, time/batch = 17.9496s	
8536/22950 (epoch 18.597), train_loss = 1.16804560, grad/param norm = 2.1444e-01, time/batch = 17.4582s	
8537/22950 (epoch 18.599), train_loss = 1.12433282, grad/param norm = 2.3618e-01, time/batch = 18.9580s	
8538/22950 (epoch 18.601), train_loss = 1.12649341, grad/param norm = 2.1723e-01, time/batch = 18.5601s	
8539/22950 (epoch 18.603), train_loss = 1.22823473, grad/param norm = 2.0961e-01, time/batch = 16.1645s	
8540/22950 (epoch 18.606), train_loss = 1.08321004, grad/param norm = 2.0263e-01, time/batch = 18.3696s	
8541/22950 (epoch 18.608), train_loss = 1.12594092, grad/param norm = 2.1252e-01, time/batch = 19.8707s	
8542/22950 (epoch 18.610), train_loss = 1.07718644, grad/param norm = 1.9410e-01, time/batch = 17.8727s	
8543/22950 (epoch 18.612), train_loss = 1.07869663, grad/param norm = 2.0730e-01, time/batch = 18.0580s	
8544/22950 (epoch 18.614), train_loss = 1.22154876, grad/param norm = 2.2783e-01, time/batch = 19.8061s	
8545/22950 (epoch 18.617), train_loss = 1.09317021, grad/param norm = 2.1544e-01, time/batch = 17.4659s	
8546/22950 (epoch 18.619), train_loss = 1.04633437, grad/param norm = 1.8386e-01, time/batch = 18.8131s	
8547/22950 (epoch 18.621), train_loss = 1.20214539, grad/param norm = 1.9017e-01, time/batch = 19.0405s	
8548/22950 (epoch 18.623), train_loss = 1.17339927, grad/param norm = 1.9547e-01, time/batch = 17.7941s	
8549/22950 (epoch 18.625), train_loss = 1.08444239, grad/param norm = 2.0055e-01, time/batch = 16.6848s	
8550/22950 (epoch 18.627), train_loss = 1.07650789, grad/param norm = 2.1947e-01, time/batch = 18.5541s	
8551/22950 (epoch 18.630), train_loss = 0.96454991, grad/param norm = 1.8739e-01, time/batch = 18.6415s	
8552/22950 (epoch 18.632), train_loss = 1.10065742, grad/param norm = 2.3976e-01, time/batch = 17.4467s	
8553/22950 (epoch 18.634), train_loss = 1.11073544, grad/param norm = 2.1522e-01, time/batch = 16.8062s	
8554/22950 (epoch 18.636), train_loss = 1.14602513, grad/param norm = 2.1284e-01, time/batch = 18.5758s	
8555/22950 (epoch 18.638), train_loss = 1.02635249, grad/param norm = 2.0905e-01, time/batch = 15.6581s	
8556/22950 (epoch 18.641), train_loss = 1.07784705, grad/param norm = 1.9821e-01, time/batch = 18.6279s	
8557/22950 (epoch 18.643), train_loss = 1.13447080, grad/param norm = 2.3339e-01, time/batch = 16.5524s	
8558/22950 (epoch 18.645), train_loss = 1.04649713, grad/param norm = 1.9199e-01, time/batch = 17.6243s	
8559/22950 (epoch 18.647), train_loss = 1.08916737, grad/param norm = 2.0790e-01, time/batch = 17.8663s	
8560/22950 (epoch 18.649), train_loss = 1.11010333, grad/param norm = 2.2019e-01, time/batch = 17.9749s	
8561/22950 (epoch 18.651), train_loss = 1.16281053, grad/param norm = 2.2782e-01, time/batch = 19.9725s	
8562/22950 (epoch 18.654), train_loss = 0.92785856, grad/param norm = 1.9083e-01, time/batch = 18.2922s	
8563/22950 (epoch 18.656), train_loss = 1.19282516, grad/param norm = 2.3669e-01, time/batch = 17.8776s	
8564/22950 (epoch 18.658), train_loss = 0.99970636, grad/param norm = 2.1863e-01, time/batch = 18.3717s	
8565/22950 (epoch 18.660), train_loss = 0.92398680, grad/param norm = 2.2636e-01, time/batch = 16.9747s	
8566/22950 (epoch 18.662), train_loss = 0.91538832, grad/param norm = 1.7923e-01, time/batch = 19.2211s	
8567/22950 (epoch 18.664), train_loss = 1.06732854, grad/param norm = 2.0308e-01, time/batch = 17.9693s	
8568/22950 (epoch 18.667), train_loss = 1.12086244, grad/param norm = 1.9353e-01, time/batch = 18.3760s	
8569/22950 (epoch 18.669), train_loss = 1.08650200, grad/param norm = 2.0246e-01, time/batch = 17.7075s	
8570/22950 (epoch 18.671), train_loss = 1.10978319, grad/param norm = 2.0308e-01, time/batch = 19.0501s	
8571/22950 (epoch 18.673), train_loss = 1.05637356, grad/param norm = 2.1456e-01, time/batch = 19.8773s	
8572/22950 (epoch 18.675), train_loss = 1.09173053, grad/param norm = 2.1534e-01, time/batch = 18.3542s	
8573/22950 (epoch 18.678), train_loss = 1.11919828, grad/param norm = 2.1130e-01, time/batch = 20.3042s	
8574/22950 (epoch 18.680), train_loss = 1.09097538, grad/param norm = 1.9378e-01, time/batch = 19.1343s	
8575/22950 (epoch 18.682), train_loss = 1.12159450, grad/param norm = 2.1952e-01, time/batch = 18.0145s	
8576/22950 (epoch 18.684), train_loss = 1.21918966, grad/param norm = 2.3943e-01, time/batch = 19.3019s	
8577/22950 (epoch 18.686), train_loss = 1.17435643, grad/param norm = 2.0581e-01, time/batch = 15.7993s	
8578/22950 (epoch 18.688), train_loss = 1.12626674, grad/param norm = 2.1214e-01, time/batch = 17.4291s	
8579/22950 (epoch 18.691), train_loss = 1.11084185, grad/param norm = 2.1245e-01, time/batch = 20.0248s	
8580/22950 (epoch 18.693), train_loss = 1.02239119, grad/param norm = 2.1027e-01, time/batch = 19.3136s	
8581/22950 (epoch 18.695), train_loss = 1.20734606, grad/param norm = 2.2350e-01, time/batch = 17.4525s	
8582/22950 (epoch 18.697), train_loss = 1.16446507, grad/param norm = 2.0945e-01, time/batch = 19.0214s	
8583/22950 (epoch 18.699), train_loss = 1.16427068, grad/param norm = 2.1649e-01, time/batch = 18.5463s	
8584/22950 (epoch 18.702), train_loss = 1.16226395, grad/param norm = 2.1039e-01, time/batch = 17.9475s	
8585/22950 (epoch 18.704), train_loss = 1.17612412, grad/param norm = 1.9591e-01, time/batch = 17.6938s	
8586/22950 (epoch 18.706), train_loss = 1.17826190, grad/param norm = 2.1842e-01, time/batch = 18.0519s	
8587/22950 (epoch 18.708), train_loss = 1.00575124, grad/param norm = 2.0352e-01, time/batch = 17.5410s	
8588/22950 (epoch 18.710), train_loss = 1.13319493, grad/param norm = 2.1155e-01, time/batch = 16.3267s	
8589/22950 (epoch 18.712), train_loss = 1.22123267, grad/param norm = 2.2445e-01, time/batch = 19.6904s	
8590/22950 (epoch 18.715), train_loss = 1.13649599, grad/param norm = 2.2376e-01, time/batch = 19.4621s	
8591/22950 (epoch 18.717), train_loss = 1.09017419, grad/param norm = 1.9383e-01, time/batch = 18.2873s	
8592/22950 (epoch 18.719), train_loss = 1.07112331, grad/param norm = 2.0828e-01, time/batch = 19.6280s	
8593/22950 (epoch 18.721), train_loss = 1.15889210, grad/param norm = 2.2484e-01, time/batch = 19.3807s	
8594/22950 (epoch 18.723), train_loss = 1.05834524, grad/param norm = 1.9618e-01, time/batch = 19.0239s	
8595/22950 (epoch 18.725), train_loss = 1.16548548, grad/param norm = 2.3014e-01, time/batch = 16.9532s	
8596/22950 (epoch 18.728), train_loss = 1.09213596, grad/param norm = 2.6255e-01, time/batch = 17.2832s	
8597/22950 (epoch 18.730), train_loss = 1.09783692, grad/param norm = 2.1931e-01, time/batch = 17.4467s	
8598/22950 (epoch 18.732), train_loss = 1.15141954, grad/param norm = 2.1310e-01, time/batch = 18.2717s	
8599/22950 (epoch 18.734), train_loss = 1.11578839, grad/param norm = 2.1784e-01, time/batch = 18.9743s	
8600/22950 (epoch 18.736), train_loss = 1.08770419, grad/param norm = 1.9612e-01, time/batch = 19.7206s	
8601/22950 (epoch 18.739), train_loss = 1.16831151, grad/param norm = 2.0977e-01, time/batch = 17.1174s	
8602/22950 (epoch 18.741), train_loss = 1.19843694, grad/param norm = 2.3835e-01, time/batch = 17.9699s	
8603/22950 (epoch 18.743), train_loss = 1.23801289, grad/param norm = 2.1269e-01, time/batch = 16.9577s	
8604/22950 (epoch 18.745), train_loss = 1.36480752, grad/param norm = 2.3958e-01, time/batch = 16.1542s	
8605/22950 (epoch 18.747), train_loss = 1.13496114, grad/param norm = 2.0974e-01, time/batch = 16.2760s	
8606/22950 (epoch 18.749), train_loss = 1.03312952, grad/param norm = 2.2509e-01, time/batch = 15.6781s	
8607/22950 (epoch 18.752), train_loss = 1.30129319, grad/param norm = 2.3553e-01, time/batch = 15.2050s	
8608/22950 (epoch 18.754), train_loss = 1.20951599, grad/param norm = 2.4054e-01, time/batch = 15.5468s	
8609/22950 (epoch 18.756), train_loss = 1.03568330, grad/param norm = 2.0535e-01, time/batch = 15.7803s	
8610/22950 (epoch 18.758), train_loss = 1.06308864, grad/param norm = 1.9086e-01, time/batch = 17.9590s	
8611/22950 (epoch 18.760), train_loss = 1.16495435, grad/param norm = 2.2526e-01, time/batch = 18.8590s	
8612/22950 (epoch 18.763), train_loss = 1.18089429, grad/param norm = 2.1991e-01, time/batch = 19.4575s	
8613/22950 (epoch 18.765), train_loss = 1.15209120, grad/param norm = 2.1924e-01, time/batch = 17.8924s	
8614/22950 (epoch 18.767), train_loss = 1.29405469, grad/param norm = 2.1758e-01, time/batch = 15.6395s	
8615/22950 (epoch 18.769), train_loss = 1.13999971, grad/param norm = 2.0506e-01, time/batch = 17.7840s	
8616/22950 (epoch 18.771), train_loss = 0.98984760, grad/param norm = 2.1806e-01, time/batch = 19.3029s	
8617/22950 (epoch 18.773), train_loss = 0.84023544, grad/param norm = 1.8482e-01, time/batch = 18.7197s	
8618/22950 (epoch 18.776), train_loss = 1.03600636, grad/param norm = 1.9964e-01, time/batch = 16.7787s	
8619/22950 (epoch 18.778), train_loss = 0.98940359, grad/param norm = 2.0291e-01, time/batch = 18.2266s	
8620/22950 (epoch 18.780), train_loss = 1.08974674, grad/param norm = 1.8264e-01, time/batch = 19.0487s	
8621/22950 (epoch 18.782), train_loss = 1.11005204, grad/param norm = 2.0610e-01, time/batch = 18.1838s	
8622/22950 (epoch 18.784), train_loss = 1.06079955, grad/param norm = 2.0942e-01, time/batch = 18.7821s	
8623/22950 (epoch 18.786), train_loss = 1.15738582, grad/param norm = 2.0296e-01, time/batch = 20.0518s	
8624/22950 (epoch 18.789), train_loss = 0.96985089, grad/param norm = 1.8910e-01, time/batch = 18.7951s	
8625/22950 (epoch 18.791), train_loss = 0.99287706, grad/param norm = 2.1725e-01, time/batch = 19.6074s	
8626/22950 (epoch 18.793), train_loss = 1.27601843, grad/param norm = 2.1357e-01, time/batch = 17.6703s	
8627/22950 (epoch 18.795), train_loss = 1.05552238, grad/param norm = 1.9057e-01, time/batch = 20.1207s	
8628/22950 (epoch 18.797), train_loss = 1.24409603, grad/param norm = 2.2221e-01, time/batch = 19.4549s	
8629/22950 (epoch 18.800), train_loss = 1.02184109, grad/param norm = 1.9555e-01, time/batch = 18.2198s	
8630/22950 (epoch 18.802), train_loss = 1.03631931, grad/param norm = 2.0964e-01, time/batch = 20.0486s	
8631/22950 (epoch 18.804), train_loss = 1.10377015, grad/param norm = 2.0759e-01, time/batch = 19.2797s	
8632/22950 (epoch 18.806), train_loss = 0.99856693, grad/param norm = 2.0840e-01, time/batch = 18.8713s	
8633/22950 (epoch 18.808), train_loss = 1.08645391, grad/param norm = 2.0349e-01, time/batch = 20.6231s	
8634/22950 (epoch 18.810), train_loss = 1.06946858, grad/param norm = 2.1710e-01, time/batch = 17.9173s	
8635/22950 (epoch 18.813), train_loss = 0.91125440, grad/param norm = 2.0272e-01, time/batch = 18.8009s	
8636/22950 (epoch 18.815), train_loss = 0.96142795, grad/param norm = 1.8807e-01, time/batch = 16.7993s	
8637/22950 (epoch 18.817), train_loss = 0.98370300, grad/param norm = 1.9361e-01, time/batch = 18.4401s	
8638/22950 (epoch 18.819), train_loss = 1.08857268, grad/param norm = 2.0740e-01, time/batch = 16.1953s	
8639/22950 (epoch 18.821), train_loss = 1.03989166, grad/param norm = 2.0410e-01, time/batch = 19.3691s	
8640/22950 (epoch 18.824), train_loss = 1.09625745, grad/param norm = 2.4064e-01, time/batch = 18.2884s	
8641/22950 (epoch 18.826), train_loss = 1.21331997, grad/param norm = 2.2868e-01, time/batch = 19.8719s	
8642/22950 (epoch 18.828), train_loss = 1.07719897, grad/param norm = 2.1339e-01, time/batch = 18.1293s	
8643/22950 (epoch 18.830), train_loss = 1.09224715, grad/param norm = 2.1175e-01, time/batch = 19.3755s	
8644/22950 (epoch 18.832), train_loss = 1.10635867, grad/param norm = 2.0104e-01, time/batch = 20.1035s	
8645/22950 (epoch 18.834), train_loss = 0.93895101, grad/param norm = 1.9094e-01, time/batch = 18.9768s	
8646/22950 (epoch 18.837), train_loss = 1.10812795, grad/param norm = 2.1578e-01, time/batch = 18.7903s	
8647/22950 (epoch 18.839), train_loss = 0.94389930, grad/param norm = 1.8826e-01, time/batch = 19.0919s	
8648/22950 (epoch 18.841), train_loss = 1.01697007, grad/param norm = 1.8254e-01, time/batch = 19.2979s	
8649/22950 (epoch 18.843), train_loss = 1.04158210, grad/param norm = 2.0859e-01, time/batch = 19.9563s	
8650/22950 (epoch 18.845), train_loss = 1.11560317, grad/param norm = 2.1724e-01, time/batch = 8.4080s	
8651/22950 (epoch 18.847), train_loss = 1.15959793, grad/param norm = 2.1590e-01, time/batch = 0.6903s	
8652/22950 (epoch 18.850), train_loss = 1.14903321, grad/param norm = 2.2514e-01, time/batch = 0.6906s	
8653/22950 (epoch 18.852), train_loss = 1.15489659, grad/param norm = 2.2452e-01, time/batch = 0.6864s	
8654/22950 (epoch 18.854), train_loss = 1.05813831, grad/param norm = 2.0065e-01, time/batch = 0.6865s	
8655/22950 (epoch 18.856), train_loss = 1.26669922, grad/param norm = 2.2120e-01, time/batch = 0.7076s	
8656/22950 (epoch 18.858), train_loss = 1.14953670, grad/param norm = 2.0431e-01, time/batch = 0.7155s	
8657/22950 (epoch 18.861), train_loss = 1.18969521, grad/param norm = 2.1519e-01, time/batch = 0.8142s	
8658/22950 (epoch 18.863), train_loss = 1.22882155, grad/param norm = 2.2108e-01, time/batch = 1.0018s	
8659/22950 (epoch 18.865), train_loss = 1.26672440, grad/param norm = 2.2361e-01, time/batch = 1.0146s	
8660/22950 (epoch 18.867), train_loss = 1.13663079, grad/param norm = 2.0681e-01, time/batch = 1.0044s	
8661/22950 (epoch 18.869), train_loss = 1.27187653, grad/param norm = 2.3426e-01, time/batch = 1.0472s	
8662/22950 (epoch 18.871), train_loss = 1.11600265, grad/param norm = 2.1160e-01, time/batch = 1.4732s	
8663/22950 (epoch 18.874), train_loss = 1.10521787, grad/param norm = 2.1324e-01, time/batch = 1.9706s	
8664/22950 (epoch 18.876), train_loss = 1.16570813, grad/param norm = 2.1889e-01, time/batch = 1.8878s	
8665/22950 (epoch 18.878), train_loss = 1.05334021, grad/param norm = 2.1767e-01, time/batch = 18.4201s	
8666/22950 (epoch 18.880), train_loss = 1.26129645, grad/param norm = 2.1829e-01, time/batch = 17.1179s	
8667/22950 (epoch 18.882), train_loss = 0.99738959, grad/param norm = 2.0496e-01, time/batch = 17.4874s	
8668/22950 (epoch 18.885), train_loss = 1.13800277, grad/param norm = 2.0633e-01, time/batch = 19.3680s	
8669/22950 (epoch 18.887), train_loss = 1.12859550, grad/param norm = 2.1650e-01, time/batch = 17.5446s	
8670/22950 (epoch 18.889), train_loss = 1.16448489, grad/param norm = 2.2002e-01, time/batch = 17.2714s	
8671/22950 (epoch 18.891), train_loss = 1.05228889, grad/param norm = 2.0985e-01, time/batch = 19.1320s	
8672/22950 (epoch 18.893), train_loss = 1.16267438, grad/param norm = 2.0329e-01, time/batch = 19.7885s	
8673/22950 (epoch 18.895), train_loss = 1.29606705, grad/param norm = 2.3666e-01, time/batch = 18.2085s	
8674/22950 (epoch 18.898), train_loss = 1.08460139, grad/param norm = 2.0390e-01, time/batch = 18.7720s	
8675/22950 (epoch 18.900), train_loss = 1.04786882, grad/param norm = 1.8541e-01, time/batch = 19.2075s	
8676/22950 (epoch 18.902), train_loss = 1.15397127, grad/param norm = 2.1310e-01, time/batch = 18.1311s	
8677/22950 (epoch 18.904), train_loss = 1.16179069, grad/param norm = 2.3350e-01, time/batch = 17.7107s	
8678/22950 (epoch 18.906), train_loss = 1.14619480, grad/param norm = 2.1620e-01, time/batch = 20.1265s	
8679/22950 (epoch 18.908), train_loss = 0.98957532, grad/param norm = 1.8933e-01, time/batch = 19.3058s	
8680/22950 (epoch 18.911), train_loss = 0.95643300, grad/param norm = 1.8879e-01, time/batch = 16.2749s	
8681/22950 (epoch 18.913), train_loss = 1.02836509, grad/param norm = 2.0671e-01, time/batch = 18.6101s	
8682/22950 (epoch 18.915), train_loss = 1.21012899, grad/param norm = 2.2507e-01, time/batch = 18.8859s	
8683/22950 (epoch 18.917), train_loss = 0.97961278, grad/param norm = 1.9632e-01, time/batch = 16.4571s	
8684/22950 (epoch 18.919), train_loss = 1.05686610, grad/param norm = 2.0335e-01, time/batch = 18.5378s	
8685/22950 (epoch 18.922), train_loss = 1.10875479, grad/param norm = 2.1128e-01, time/batch = 19.6280s	
8686/22950 (epoch 18.924), train_loss = 1.15265488, grad/param norm = 2.1025e-01, time/batch = 17.4625s	
8687/22950 (epoch 18.926), train_loss = 0.94034564, grad/param norm = 1.9845e-01, time/batch = 16.5237s	
8688/22950 (epoch 18.928), train_loss = 0.97869708, grad/param norm = 2.0552e-01, time/batch = 18.2940s	
8689/22950 (epoch 18.930), train_loss = 0.95976179, grad/param norm = 2.0251e-01, time/batch = 18.9683s	
8690/22950 (epoch 18.932), train_loss = 0.91762035, grad/param norm = 1.8880e-01, time/batch = 20.2657s	
8691/22950 (epoch 18.935), train_loss = 1.08454692, grad/param norm = 1.9725e-01, time/batch = 18.9596s	
8692/22950 (epoch 18.937), train_loss = 1.09887655, grad/param norm = 2.1832e-01, time/batch = 19.3918s	
8693/22950 (epoch 18.939), train_loss = 1.02383342, grad/param norm = 2.0843e-01, time/batch = 19.1986s	
8694/22950 (epoch 18.941), train_loss = 1.01714982, grad/param norm = 1.9926e-01, time/batch = 17.4830s	
8695/22950 (epoch 18.943), train_loss = 1.12019133, grad/param norm = 2.1626e-01, time/batch = 15.6157s	
8696/22950 (epoch 18.946), train_loss = 0.95849885, grad/param norm = 2.0032e-01, time/batch = 29.0466s	
8697/22950 (epoch 18.948), train_loss = 1.16186818, grad/param norm = 2.0817e-01, time/batch = 20.2729s	
8698/22950 (epoch 18.950), train_loss = 1.11929147, grad/param norm = 2.1638e-01, time/batch = 18.8014s	
8699/22950 (epoch 18.952), train_loss = 1.13302465, grad/param norm = 2.1566e-01, time/batch = 18.4527s	
8700/22950 (epoch 18.954), train_loss = 1.13293170, grad/param norm = 2.1896e-01, time/batch = 18.8831s	
8701/22950 (epoch 18.956), train_loss = 1.02732005, grad/param norm = 2.1159e-01, time/batch = 18.1222s	
8702/22950 (epoch 18.959), train_loss = 0.99729574, grad/param norm = 1.8907e-01, time/batch = 16.9741s	
8703/22950 (epoch 18.961), train_loss = 1.10859056, grad/param norm = 2.0549e-01, time/batch = 18.4700s	
8704/22950 (epoch 18.963), train_loss = 1.14226731, grad/param norm = 2.2463e-01, time/batch = 19.0525s	
8705/22950 (epoch 18.965), train_loss = 1.25092717, grad/param norm = 2.2445e-01, time/batch = 17.5441s	
8706/22950 (epoch 18.967), train_loss = 1.07626833, grad/param norm = 2.2663e-01, time/batch = 18.6393s	
8707/22950 (epoch 18.969), train_loss = 0.99646205, grad/param norm = 2.0495e-01, time/batch = 18.0666s	
8708/22950 (epoch 18.972), train_loss = 1.08535302, grad/param norm = 2.0679e-01, time/batch = 17.6138s	
8709/22950 (epoch 18.974), train_loss = 1.04688826, grad/param norm = 2.0408e-01, time/batch = 17.6300s	
8710/22950 (epoch 18.976), train_loss = 1.02365717, grad/param norm = 2.0575e-01, time/batch = 19.2247s	
8711/22950 (epoch 18.978), train_loss = 1.05923816, grad/param norm = 2.0600e-01, time/batch = 20.2735s	
8712/22950 (epoch 18.980), train_loss = 1.07814461, grad/param norm = 2.0105e-01, time/batch = 16.3385s	
8713/22950 (epoch 18.983), train_loss = 1.09627119, grad/param norm = 2.0110e-01, time/batch = 19.0290s	
8714/22950 (epoch 18.985), train_loss = 0.96277517, grad/param norm = 2.0223e-01, time/batch = 15.4876s	
8715/22950 (epoch 18.987), train_loss = 1.01163653, grad/param norm = 1.9177e-01, time/batch = 17.4308s	
8716/22950 (epoch 18.989), train_loss = 1.08180738, grad/param norm = 2.0955e-01, time/batch = 18.9532s	
8717/22950 (epoch 18.991), train_loss = 0.91357553, grad/param norm = 1.8658e-01, time/batch = 18.7702s	
8718/22950 (epoch 18.993), train_loss = 1.11306686, grad/param norm = 2.1448e-01, time/batch = 19.5435s	
8719/22950 (epoch 18.996), train_loss = 1.13546729, grad/param norm = 2.1554e-01, time/batch = 18.9534s	
8720/22950 (epoch 18.998), train_loss = 1.00497091, grad/param norm = 2.0396e-01, time/batch = 19.9470s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
8721/22950 (epoch 19.000), train_loss = 0.92738722, grad/param norm = 1.8934e-01, time/batch = 18.9653s	
8722/22950 (epoch 19.002), train_loss = 1.25944925, grad/param norm = 2.1540e-01, time/batch = 18.2993s	
8723/22950 (epoch 19.004), train_loss = 1.11219379, grad/param norm = 2.0304e-01, time/batch = 20.0519s	
8724/22950 (epoch 19.007), train_loss = 1.10313151, grad/param norm = 2.0611e-01, time/batch = 18.4506s	
8725/22950 (epoch 19.009), train_loss = 1.24844461, grad/param norm = 2.3959e-01, time/batch = 19.1016s	
8726/22950 (epoch 19.011), train_loss = 0.96801932, grad/param norm = 2.1506e-01, time/batch = 20.3745s	
8727/22950 (epoch 19.013), train_loss = 1.13345702, grad/param norm = 2.6213e-01, time/batch = 19.2051s	
8728/22950 (epoch 19.015), train_loss = 1.15027343, grad/param norm = 2.1964e-01, time/batch = 18.2766s	
8729/22950 (epoch 19.017), train_loss = 1.12751981, grad/param norm = 2.0215e-01, time/batch = 18.9691s	
8730/22950 (epoch 19.020), train_loss = 1.09043880, grad/param norm = 1.8457e-01, time/batch = 19.8145s	
8731/22950 (epoch 19.022), train_loss = 0.94796545, grad/param norm = 1.8993e-01, time/batch = 18.0276s	
8732/22950 (epoch 19.024), train_loss = 1.05672640, grad/param norm = 2.0206e-01, time/batch = 19.4681s	
8733/22950 (epoch 19.026), train_loss = 1.14992777, grad/param norm = 2.1819e-01, time/batch = 19.2967s	
8734/22950 (epoch 19.028), train_loss = 1.18579281, grad/param norm = 1.9417e-01, time/batch = 16.0995s	
8735/22950 (epoch 19.031), train_loss = 1.06824791, grad/param norm = 2.1219e-01, time/batch = 20.2034s	
8736/22950 (epoch 19.033), train_loss = 1.21333904, grad/param norm = 2.0834e-01, time/batch = 19.6252s	
8737/22950 (epoch 19.035), train_loss = 1.08727069, grad/param norm = 1.8482e-01, time/batch = 18.9438s	
8738/22950 (epoch 19.037), train_loss = 1.08697123, grad/param norm = 2.1517e-01, time/batch = 17.7194s	
8739/22950 (epoch 19.039), train_loss = 1.05117362, grad/param norm = 2.0389e-01, time/batch = 16.0874s	
8740/22950 (epoch 19.041), train_loss = 1.05809353, grad/param norm = 2.0571e-01, time/batch = 17.3649s	
8741/22950 (epoch 19.044), train_loss = 1.11736242, grad/param norm = 2.1519e-01, time/batch = 20.1121s	
8742/22950 (epoch 19.046), train_loss = 1.08610815, grad/param norm = 2.0314e-01, time/batch = 17.7970s	
8743/22950 (epoch 19.048), train_loss = 1.10228469, grad/param norm = 1.9849e-01, time/batch = 19.2140s	
8744/22950 (epoch 19.050), train_loss = 1.07997701, grad/param norm = 2.0996e-01, time/batch = 18.5124s	
8745/22950 (epoch 19.052), train_loss = 1.12628158, grad/param norm = 2.1345e-01, time/batch = 18.7068s	
8746/22950 (epoch 19.054), train_loss = 1.27632619, grad/param norm = 2.4324e-01, time/batch = 17.2303s	
8747/22950 (epoch 19.057), train_loss = 1.21974056, grad/param norm = 2.2407e-01, time/batch = 16.9461s	
8748/22950 (epoch 19.059), train_loss = 1.14687646, grad/param norm = 2.0714e-01, time/batch = 19.0481s	
8749/22950 (epoch 19.061), train_loss = 1.00503479, grad/param norm = 2.0573e-01, time/batch = 18.3866s	
8750/22950 (epoch 19.063), train_loss = 1.15574863, grad/param norm = 2.0788e-01, time/batch = 17.3912s	
8751/22950 (epoch 19.065), train_loss = 0.90911485, grad/param norm = 1.9059e-01, time/batch = 19.4715s	
8752/22950 (epoch 19.068), train_loss = 1.16631080, grad/param norm = 2.2481e-01, time/batch = 18.0488s	
8753/22950 (epoch 19.070), train_loss = 0.98738393, grad/param norm = 1.9150e-01, time/batch = 17.8905s	
8754/22950 (epoch 19.072), train_loss = 1.14246359, grad/param norm = 2.0281e-01, time/batch = 18.9542s	
8755/22950 (epoch 19.074), train_loss = 1.09388753, grad/param norm = 2.1036e-01, time/batch = 17.3946s	
8756/22950 (epoch 19.076), train_loss = 1.11996120, grad/param norm = 2.0519e-01, time/batch = 18.9738s	
8757/22950 (epoch 19.078), train_loss = 1.16808174, grad/param norm = 1.9892e-01, time/batch = 15.6072s	
8758/22950 (epoch 19.081), train_loss = 1.18827878, grad/param norm = 2.1972e-01, time/batch = 17.8769s	
8759/22950 (epoch 19.083), train_loss = 1.07890601, grad/param norm = 2.3145e-01, time/batch = 19.0653s	
8760/22950 (epoch 19.085), train_loss = 0.97360188, grad/param norm = 2.0522e-01, time/batch = 17.9490s	
8761/22950 (epoch 19.087), train_loss = 0.98949533, grad/param norm = 2.0305e-01, time/batch = 19.1272s	
8762/22950 (epoch 19.089), train_loss = 1.09799913, grad/param norm = 1.9116e-01, time/batch = 18.2970s	
8763/22950 (epoch 19.092), train_loss = 1.05320524, grad/param norm = 2.4290e-01, time/batch = 16.8082s	
8764/22950 (epoch 19.094), train_loss = 1.01740451, grad/param norm = 1.9616e-01, time/batch = 18.1007s	
8765/22950 (epoch 19.096), train_loss = 1.23573867, grad/param norm = 2.3408e-01, time/batch = 19.8094s	
8766/22950 (epoch 19.098), train_loss = 1.13607283, grad/param norm = 1.9652e-01, time/batch = 18.8787s	
8767/22950 (epoch 19.100), train_loss = 1.04728630, grad/param norm = 2.0927e-01, time/batch = 18.1201s	
8768/22950 (epoch 19.102), train_loss = 1.08309221, grad/param norm = 1.9957e-01, time/batch = 19.2152s	
8769/22950 (epoch 19.105), train_loss = 0.96268951, grad/param norm = 1.8295e-01, time/batch = 18.7190s	
8770/22950 (epoch 19.107), train_loss = 1.04425073, grad/param norm = 2.0187e-01, time/batch = 18.0187s	
8771/22950 (epoch 19.109), train_loss = 1.03127046, grad/param norm = 2.1235e-01, time/batch = 19.7064s	
8772/22950 (epoch 19.111), train_loss = 0.93612492, grad/param norm = 2.0960e-01, time/batch = 17.9348s	
8773/22950 (epoch 19.113), train_loss = 1.10844464, grad/param norm = 2.1326e-01, time/batch = 17.7739s	
8774/22950 (epoch 19.115), train_loss = 1.11084495, grad/param norm = 2.0486e-01, time/batch = 20.2116s	
8775/22950 (epoch 19.118), train_loss = 1.22721486, grad/param norm = 2.1802e-01, time/batch = 19.8658s	
8776/22950 (epoch 19.120), train_loss = 1.01369598, grad/param norm = 2.1149e-01, time/batch = 17.3764s	
8777/22950 (epoch 19.122), train_loss = 1.18931978, grad/param norm = 2.1323e-01, time/batch = 17.5545s	
8778/22950 (epoch 19.124), train_loss = 0.94232577, grad/param norm = 1.7292e-01, time/batch = 18.8852s	
8779/22950 (epoch 19.126), train_loss = 1.06217866, grad/param norm = 1.9474e-01, time/batch = 18.8568s	
8780/22950 (epoch 19.129), train_loss = 0.94919561, grad/param norm = 1.8109e-01, time/batch = 18.3617s	
8781/22950 (epoch 19.131), train_loss = 1.04719708, grad/param norm = 1.9725e-01, time/batch = 18.1931s	
8782/22950 (epoch 19.133), train_loss = 1.13638387, grad/param norm = 2.0514e-01, time/batch = 19.1187s	
8783/22950 (epoch 19.135), train_loss = 1.08019352, grad/param norm = 1.8891e-01, time/batch = 18.3788s	
8784/22950 (epoch 19.137), train_loss = 1.21604122, grad/param norm = 2.4601e-01, time/batch = 20.3731s	
8785/22950 (epoch 19.139), train_loss = 0.99390809, grad/param norm = 2.2477e-01, time/batch = 19.6247s	
8786/22950 (epoch 19.142), train_loss = 1.00469808, grad/param norm = 1.9343e-01, time/batch = 19.1101s	
8787/22950 (epoch 19.144), train_loss = 1.00290468, grad/param norm = 1.9387e-01, time/batch = 19.0999s	
8788/22950 (epoch 19.146), train_loss = 1.05335325, grad/param norm = 2.2196e-01, time/batch = 17.3772s	
8789/22950 (epoch 19.148), train_loss = 1.03548946, grad/param norm = 2.0117e-01, time/batch = 17.3768s	
8790/22950 (epoch 19.150), train_loss = 1.10192458, grad/param norm = 2.1278e-01, time/batch = 17.8975s	
8791/22950 (epoch 19.153), train_loss = 1.02860222, grad/param norm = 1.9795e-01, time/batch = 19.3019s	
8792/22950 (epoch 19.155), train_loss = 1.02943701, grad/param norm = 1.9219e-01, time/batch = 16.0977s	
8793/22950 (epoch 19.157), train_loss = 1.04548578, grad/param norm = 2.0133e-01, time/batch = 17.5685s	
8794/22950 (epoch 19.159), train_loss = 0.98557985, grad/param norm = 1.8887e-01, time/batch = 17.9915s	
8795/22950 (epoch 19.161), train_loss = 1.01731028, grad/param norm = 1.7821e-01, time/batch = 18.7912s	
8796/22950 (epoch 19.163), train_loss = 0.95311189, grad/param norm = 1.8449e-01, time/batch = 18.7625s	
8797/22950 (epoch 19.166), train_loss = 1.20732309, grad/param norm = 2.5523e-01, time/batch = 20.2986s	
8798/22950 (epoch 19.168), train_loss = 1.17993087, grad/param norm = 2.5313e-01, time/batch = 19.3009s	
8799/22950 (epoch 19.170), train_loss = 1.09466308, grad/param norm = 2.2338e-01, time/batch = 16.7883s	
8800/22950 (epoch 19.172), train_loss = 1.09647933, grad/param norm = 1.9034e-01, time/batch = 19.3647s	
8801/22950 (epoch 19.174), train_loss = 1.15983181, grad/param norm = 2.2378e-01, time/batch = 16.3489s	
8802/22950 (epoch 19.176), train_loss = 1.18322798, grad/param norm = 2.1500e-01, time/batch = 18.7718s	
8803/22950 (epoch 19.179), train_loss = 1.15229302, grad/param norm = 2.2579e-01, time/batch = 18.5490s	
8804/22950 (epoch 19.181), train_loss = 1.32900240, grad/param norm = 2.0823e-01, time/batch = 20.0430s	
8805/22950 (epoch 19.183), train_loss = 1.18410302, grad/param norm = 2.1704e-01, time/batch = 18.5434s	
8806/22950 (epoch 19.185), train_loss = 1.13567628, grad/param norm = 2.1708e-01, time/batch = 18.3837s	
8807/22950 (epoch 19.187), train_loss = 1.01833645, grad/param norm = 2.3067e-01, time/batch = 20.2985s	
8808/22950 (epoch 19.190), train_loss = 0.92569703, grad/param norm = 1.9944e-01, time/batch = 17.6273s	
8809/22950 (epoch 19.192), train_loss = 0.92853204, grad/param norm = 1.8128e-01, time/batch = 19.5417s	
8810/22950 (epoch 19.194), train_loss = 1.05681256, grad/param norm = 2.3484e-01, time/batch = 15.8296s	
8811/22950 (epoch 19.196), train_loss = 0.89136078, grad/param norm = 2.2750e-01, time/batch = 18.5454s	
8812/22950 (epoch 19.198), train_loss = 1.15821281, grad/param norm = 2.1710e-01, time/batch = 18.6654s	
8813/22950 (epoch 19.200), train_loss = 1.00325117, grad/param norm = 1.8737e-01, time/batch = 19.2071s	
8814/22950 (epoch 19.203), train_loss = 0.95028311, grad/param norm = 1.8788e-01, time/batch = 20.3705s	
8815/22950 (epoch 19.205), train_loss = 1.01683686, grad/param norm = 1.9264e-01, time/batch = 18.9521s	
8816/22950 (epoch 19.207), train_loss = 1.06294482, grad/param norm = 2.0698e-01, time/batch = 15.0829s	
8817/22950 (epoch 19.209), train_loss = 1.08510135, grad/param norm = 2.2013e-01, time/batch = 19.3731s	
8818/22950 (epoch 19.211), train_loss = 0.89922100, grad/param norm = 1.9920e-01, time/batch = 18.1241s	
8819/22950 (epoch 19.214), train_loss = 1.04752847, grad/param norm = 1.9475e-01, time/batch = 18.8686s	
8820/22950 (epoch 19.216), train_loss = 1.15895367, grad/param norm = 2.1912e-01, time/batch = 19.1297s	
8821/22950 (epoch 19.218), train_loss = 1.08173088, grad/param norm = 1.9402e-01, time/batch = 18.7861s	
8822/22950 (epoch 19.220), train_loss = 1.17873376, grad/param norm = 2.1523e-01, time/batch = 19.8670s	
8823/22950 (epoch 19.222), train_loss = 1.19474182, grad/param norm = 2.1644e-01, time/batch = 18.7953s	
8824/22950 (epoch 19.224), train_loss = 1.06449672, grad/param norm = 2.0555e-01, time/batch = 18.2668s	
8825/22950 (epoch 19.227), train_loss = 1.15861556, grad/param norm = 1.8928e-01, time/batch = 19.4344s	
8826/22950 (epoch 19.229), train_loss = 1.14674988, grad/param norm = 2.0545e-01, time/batch = 18.8750s	
8827/22950 (epoch 19.231), train_loss = 0.94697326, grad/param norm = 1.8989e-01, time/batch = 18.8698s	
8828/22950 (epoch 19.233), train_loss = 1.02521300, grad/param norm = 2.0920e-01, time/batch = 16.2546s	
8829/22950 (epoch 19.235), train_loss = 1.22477312, grad/param norm = 2.2003e-01, time/batch = 19.5406s	
8830/22950 (epoch 19.237), train_loss = 0.97996203, grad/param norm = 1.8228e-01, time/batch = 20.0508s	
8831/22950 (epoch 19.240), train_loss = 1.06426680, grad/param norm = 2.0889e-01, time/batch = 19.2752s	
8832/22950 (epoch 19.242), train_loss = 1.17612494, grad/param norm = 1.9457e-01, time/batch = 19.0407s	
8833/22950 (epoch 19.244), train_loss = 1.22770109, grad/param norm = 2.2422e-01, time/batch = 20.3867s	
8834/22950 (epoch 19.246), train_loss = 1.18680129, grad/param norm = 1.9927e-01, time/batch = 17.7873s	
8835/22950 (epoch 19.248), train_loss = 1.12138209, grad/param norm = 2.1243e-01, time/batch = 20.2941s	
8836/22950 (epoch 19.251), train_loss = 1.00814762, grad/param norm = 1.9852e-01, time/batch = 19.1364s	
8837/22950 (epoch 19.253), train_loss = 1.02238401, grad/param norm = 2.1983e-01, time/batch = 16.7934s	
8838/22950 (epoch 19.255), train_loss = 1.09665764, grad/param norm = 2.2023e-01, time/batch = 18.1498s	
8839/22950 (epoch 19.257), train_loss = 1.18681764, grad/param norm = 2.0049e-01, time/batch = 18.5552s	
8840/22950 (epoch 19.259), train_loss = 0.93154534, grad/param norm = 2.0564e-01, time/batch = 16.0981s	
8841/22950 (epoch 19.261), train_loss = 1.03094154, grad/param norm = 1.9688e-01, time/batch = 18.3736s	
8842/22950 (epoch 19.264), train_loss = 0.98325769, grad/param norm = 2.3966e-01, time/batch = 18.2211s	
8843/22950 (epoch 19.266), train_loss = 1.10177888, grad/param norm = 2.3305e-01, time/batch = 18.8133s	
8844/22950 (epoch 19.268), train_loss = 1.06354813, grad/param norm = 1.9250e-01, time/batch = 17.2793s	
8845/22950 (epoch 19.270), train_loss = 1.07240398, grad/param norm = 1.9984e-01, time/batch = 18.6273s	
8846/22950 (epoch 19.272), train_loss = 1.17494324, grad/param norm = 2.2345e-01, time/batch = 18.7064s	
8847/22950 (epoch 19.275), train_loss = 1.01566071, grad/param norm = 1.9832e-01, time/batch = 19.1876s	
8848/22950 (epoch 19.277), train_loss = 0.91284816, grad/param norm = 1.7864e-01, time/batch = 17.8789s	
8849/22950 (epoch 19.279), train_loss = 1.02072701, grad/param norm = 2.2692e-01, time/batch = 19.9562s	
8850/22950 (epoch 19.281), train_loss = 1.03483639, grad/param norm = 2.0733e-01, time/batch = 18.3765s	
8851/22950 (epoch 19.283), train_loss = 0.90546219, grad/param norm = 1.6780e-01, time/batch = 15.6335s	
8852/22950 (epoch 19.285), train_loss = 1.09277651, grad/param norm = 1.9869e-01, time/batch = 16.5145s	
8853/22950 (epoch 19.288), train_loss = 1.12666167, grad/param norm = 1.9668e-01, time/batch = 18.7068s	
8854/22950 (epoch 19.290), train_loss = 1.02557262, grad/param norm = 1.8740e-01, time/batch = 17.7804s	
8855/22950 (epoch 19.292), train_loss = 1.17324701, grad/param norm = 1.9941e-01, time/batch = 19.1325s	
8856/22950 (epoch 19.294), train_loss = 1.06423376, grad/param norm = 1.9894e-01, time/batch = 19.4580s	
8857/22950 (epoch 19.296), train_loss = 0.85057856, grad/param norm = 1.6199e-01, time/batch = 17.5010s	
8858/22950 (epoch 19.298), train_loss = 1.09721945, grad/param norm = 2.0582e-01, time/batch = 17.9742s	
8859/22950 (epoch 19.301), train_loss = 1.09734535, grad/param norm = 2.2038e-01, time/batch = 15.8074s	
8860/22950 (epoch 19.303), train_loss = 1.10887835, grad/param norm = 2.1187e-01, time/batch = 17.0624s	
8861/22950 (epoch 19.305), train_loss = 1.10289089, grad/param norm = 2.1498e-01, time/batch = 18.2023s	
8862/22950 (epoch 19.307), train_loss = 1.18795029, grad/param norm = 2.1771e-01, time/batch = 17.6972s	
8863/22950 (epoch 19.309), train_loss = 1.00295949, grad/param norm = 1.7672e-01, time/batch = 18.2103s	
8864/22950 (epoch 19.312), train_loss = 1.07342979, grad/param norm = 2.0806e-01, time/batch = 19.4606s	
8865/22950 (epoch 19.314), train_loss = 1.05398378, grad/param norm = 1.8915e-01, time/batch = 17.6919s	
8866/22950 (epoch 19.316), train_loss = 1.08200958, grad/param norm = 2.2569e-01, time/batch = 19.9709s	
8867/22950 (epoch 19.318), train_loss = 0.90699489, grad/param norm = 1.7773e-01, time/batch = 20.2698s	
8868/22950 (epoch 19.320), train_loss = 1.00405840, grad/param norm = 1.8176e-01, time/batch = 18.8889s	
8869/22950 (epoch 19.322), train_loss = 1.04071455, grad/param norm = 2.1445e-01, time/batch = 19.4603s	
8870/22950 (epoch 19.325), train_loss = 0.84764385, grad/param norm = 1.7680e-01, time/batch = 18.2771s	
8871/22950 (epoch 19.327), train_loss = 0.88220288, grad/param norm = 1.7514e-01, time/batch = 17.5385s	
8872/22950 (epoch 19.329), train_loss = 1.00360795, grad/param norm = 1.9130e-01, time/batch = 19.3551s	
8873/22950 (epoch 19.331), train_loss = 0.94083297, grad/param norm = 1.8872e-01, time/batch = 18.1090s	
8874/22950 (epoch 19.333), train_loss = 1.04410700, grad/param norm = 2.0629e-01, time/batch = 17.7826s	
8875/22950 (epoch 19.336), train_loss = 1.03558148, grad/param norm = 2.0651e-01, time/batch = 19.2893s	
8876/22950 (epoch 19.338), train_loss = 1.03125359, grad/param norm = 1.8928e-01, time/batch = 17.5351s	
8877/22950 (epoch 19.340), train_loss = 1.06939445, grad/param norm = 2.1665e-01, time/batch = 19.9631s	
8878/22950 (epoch 19.342), train_loss = 1.16690707, grad/param norm = 3.0880e-01, time/batch = 19.4631s	
8879/22950 (epoch 19.344), train_loss = 1.05988999, grad/param norm = 2.4353e-01, time/batch = 18.4630s	
8880/22950 (epoch 19.346), train_loss = 1.17123449, grad/param norm = 2.4061e-01, time/batch = 19.8075s	
8881/22950 (epoch 19.349), train_loss = 1.07694664, grad/param norm = 2.2705e-01, time/batch = 19.3843s	
8882/22950 (epoch 19.351), train_loss = 1.09638796, grad/param norm = 2.0350e-01, time/batch = 18.9690s	
8883/22950 (epoch 19.353), train_loss = 1.16770884, grad/param norm = 2.4018e-01, time/batch = 18.0446s	
8884/22950 (epoch 19.355), train_loss = 1.16929795, grad/param norm = 2.2415e-01, time/batch = 19.7971s	
8885/22950 (epoch 19.357), train_loss = 1.06669083, grad/param norm = 2.3202e-01, time/batch = 19.8003s	
8886/22950 (epoch 19.359), train_loss = 1.08209482, grad/param norm = 2.0872e-01, time/batch = 18.7045s	
8887/22950 (epoch 19.362), train_loss = 1.06457076, grad/param norm = 2.1220e-01, time/batch = 16.5305s	
8888/22950 (epoch 19.364), train_loss = 1.07035171, grad/param norm = 2.5842e-01, time/batch = 19.1999s	
8889/22950 (epoch 19.366), train_loss = 0.99730714, grad/param norm = 1.8324e-01, time/batch = 32.1309s	
8890/22950 (epoch 19.368), train_loss = 1.12898444, grad/param norm = 2.3640e-01, time/batch = 17.8123s	
8891/22950 (epoch 19.370), train_loss = 1.03713379, grad/param norm = 2.0875e-01, time/batch = 16.7465s	
8892/22950 (epoch 19.373), train_loss = 0.94461056, grad/param norm = 2.0631e-01, time/batch = 19.6922s	
8893/22950 (epoch 19.375), train_loss = 1.17131472, grad/param norm = 2.4065e-01, time/batch = 18.6895s	
8894/22950 (epoch 19.377), train_loss = 0.97290618, grad/param norm = 2.0113e-01, time/batch = 19.5419s	
8895/22950 (epoch 19.379), train_loss = 1.07436141, grad/param norm = 2.2145e-01, time/batch = 18.2951s	
8896/22950 (epoch 19.381), train_loss = 0.93657259, grad/param norm = 2.0086e-01, time/batch = 16.8473s	
8897/22950 (epoch 19.383), train_loss = 1.06191122, grad/param norm = 2.2485e-01, time/batch = 20.7046s	
8898/22950 (epoch 19.386), train_loss = 0.98202628, grad/param norm = 2.1671e-01, time/batch = 18.3817s	
8899/22950 (epoch 19.388), train_loss = 1.06371708, grad/param norm = 2.1224e-01, time/batch = 19.2171s	
8900/22950 (epoch 19.390), train_loss = 0.96602506, grad/param norm = 2.0247e-01, time/batch = 18.1169s	
8901/22950 (epoch 19.392), train_loss = 0.99419214, grad/param norm = 1.9377e-01, time/batch = 18.4511s	
8902/22950 (epoch 19.394), train_loss = 0.99156400, grad/param norm = 1.8885e-01, time/batch = 20.2216s	
8903/22950 (epoch 19.397), train_loss = 1.18920384, grad/param norm = 1.9719e-01, time/batch = 19.2199s	
8904/22950 (epoch 19.399), train_loss = 1.20082176, grad/param norm = 2.3406e-01, time/batch = 17.7879s	
8905/22950 (epoch 19.401), train_loss = 1.26678739, grad/param norm = 2.4151e-01, time/batch = 18.5499s	
8906/22950 (epoch 19.403), train_loss = 1.04739252, grad/param norm = 2.3005e-01, time/batch = 18.3024s	
8907/22950 (epoch 19.405), train_loss = 1.18570839, grad/param norm = 2.3003e-01, time/batch = 17.6822s	
8908/22950 (epoch 19.407), train_loss = 1.22823347, grad/param norm = 2.0362e-01, time/batch = 17.4546s	
8909/22950 (epoch 19.410), train_loss = 0.99253656, grad/param norm = 1.9785e-01, time/batch = 18.3059s	
8910/22950 (epoch 19.412), train_loss = 1.06160757, grad/param norm = 2.1372e-01, time/batch = 19.2981s	
8911/22950 (epoch 19.414), train_loss = 1.17205416, grad/param norm = 2.1605e-01, time/batch = 19.2107s	
8912/22950 (epoch 19.416), train_loss = 1.10478593, grad/param norm = 2.4288e-01, time/batch = 18.0585s	
8913/22950 (epoch 19.418), train_loss = 1.08816790, grad/param norm = 2.3144e-01, time/batch = 18.0337s	
8914/22950 (epoch 19.420), train_loss = 1.12315996, grad/param norm = 2.2749e-01, time/batch = 17.7033s	
8915/22950 (epoch 19.423), train_loss = 1.00024189, grad/param norm = 1.9532e-01, time/batch = 17.9665s	
8916/22950 (epoch 19.425), train_loss = 1.06524899, grad/param norm = 2.1241e-01, time/batch = 19.1975s	
8917/22950 (epoch 19.427), train_loss = 1.06355335, grad/param norm = 2.0383e-01, time/batch = 17.2156s	
8918/22950 (epoch 19.429), train_loss = 1.03634451, grad/param norm = 1.9080e-01, time/batch = 17.7994s	
8919/22950 (epoch 19.431), train_loss = 1.11660571, grad/param norm = 2.1587e-01, time/batch = 16.9409s	
8920/22950 (epoch 19.434), train_loss = 1.07172187, grad/param norm = 2.0687e-01, time/batch = 18.6333s	
8921/22950 (epoch 19.436), train_loss = 1.20288830, grad/param norm = 2.2394e-01, time/batch = 17.6163s	
8922/22950 (epoch 19.438), train_loss = 1.11459886, grad/param norm = 2.1360e-01, time/batch = 17.8841s	
8923/22950 (epoch 19.440), train_loss = 1.17996389, grad/param norm = 2.0620e-01, time/batch = 19.0498s	
8924/22950 (epoch 19.442), train_loss = 1.23243899, grad/param norm = 2.3023e-01, time/batch = 17.5916s	
8925/22950 (epoch 19.444), train_loss = 1.13591932, grad/param norm = 2.2062e-01, time/batch = 16.4756s	
8926/22950 (epoch 19.447), train_loss = 1.25492577, grad/param norm = 2.2875e-01, time/batch = 18.4518s	
8927/22950 (epoch 19.449), train_loss = 0.97702498, grad/param norm = 1.9220e-01, time/batch = 18.7703s	
8928/22950 (epoch 19.451), train_loss = 1.11332804, grad/param norm = 2.1115e-01, time/batch = 19.2833s	
8929/22950 (epoch 19.453), train_loss = 1.11595061, grad/param norm = 2.0166e-01, time/batch = 20.0403s	
8930/22950 (epoch 19.455), train_loss = 1.01080273, grad/param norm = 1.8992e-01, time/batch = 19.4575s	
8931/22950 (epoch 19.458), train_loss = 1.18140561, grad/param norm = 2.0672e-01, time/batch = 19.0210s	
8932/22950 (epoch 19.460), train_loss = 1.11109388, grad/param norm = 2.0664e-01, time/batch = 17.3886s	
8933/22950 (epoch 19.462), train_loss = 1.07407304, grad/param norm = 1.9519e-01, time/batch = 17.6065s	
8934/22950 (epoch 19.464), train_loss = 1.04381248, grad/param norm = 2.0342e-01, time/batch = 19.4500s	
8935/22950 (epoch 19.466), train_loss = 1.12765754, grad/param norm = 2.0489e-01, time/batch = 19.6273s	
8936/22950 (epoch 19.468), train_loss = 1.21348030, grad/param norm = 2.2093e-01, time/batch = 19.4595s	
8937/22950 (epoch 19.471), train_loss = 1.12828113, grad/param norm = 2.3715e-01, time/batch = 19.0123s	
8938/22950 (epoch 19.473), train_loss = 1.16763110, grad/param norm = 2.3008e-01, time/batch = 18.1175s	
8939/22950 (epoch 19.475), train_loss = 1.27928559, grad/param norm = 2.2465e-01, time/batch = 18.4568s	
8940/22950 (epoch 19.477), train_loss = 1.07225991, grad/param norm = 1.9802e-01, time/batch = 16.4306s	
8941/22950 (epoch 19.479), train_loss = 0.98661521, grad/param norm = 1.9572e-01, time/batch = 19.2926s	
8942/22950 (epoch 19.481), train_loss = 1.17400447, grad/param norm = 2.1920e-01, time/batch = 15.7100s	
8943/22950 (epoch 19.484), train_loss = 1.10594475, grad/param norm = 2.1385e-01, time/batch = 17.1058s	
8944/22950 (epoch 19.486), train_loss = 0.95733642, grad/param norm = 1.9617e-01, time/batch = 20.4511s	
8945/22950 (epoch 19.488), train_loss = 1.03061963, grad/param norm = 2.2843e-01, time/batch = 18.2911s	
8946/22950 (epoch 19.490), train_loss = 0.93215954, grad/param norm = 2.0361e-01, time/batch = 17.0296s	
8947/22950 (epoch 19.492), train_loss = 1.05739754, grad/param norm = 2.2721e-01, time/batch = 18.4704s	
8948/22950 (epoch 19.495), train_loss = 1.04606706, grad/param norm = 2.0383e-01, time/batch = 19.7910s	
8949/22950 (epoch 19.497), train_loss = 1.14615540, grad/param norm = 2.1062e-01, time/batch = 19.3598s	
8950/22950 (epoch 19.499), train_loss = 1.19839057, grad/param norm = 2.0734e-01, time/batch = 17.9386s	
8951/22950 (epoch 19.501), train_loss = 1.14001663, grad/param norm = 2.1611e-01, time/batch = 18.7052s	
8952/22950 (epoch 19.503), train_loss = 1.18384704, grad/param norm = 2.1127e-01, time/batch = 17.5587s	
8953/22950 (epoch 19.505), train_loss = 0.95950425, grad/param norm = 1.8412e-01, time/batch = 16.1549s	
8954/22950 (epoch 19.508), train_loss = 1.11906275, grad/param norm = 2.0419e-01, time/batch = 17.1232s	
8955/22950 (epoch 19.510), train_loss = 1.10550851, grad/param norm = 2.2359e-01, time/batch = 15.3807s	
8956/22950 (epoch 19.512), train_loss = 0.99681475, grad/param norm = 2.0353e-01, time/batch = 15.2981s	
8957/22950 (epoch 19.514), train_loss = 0.99371762, grad/param norm = 1.7451e-01, time/batch = 17.3295s	
8958/22950 (epoch 19.516), train_loss = 1.05581013, grad/param norm = 2.0798e-01, time/batch = 19.3848s	
8959/22950 (epoch 19.519), train_loss = 1.04547324, grad/param norm = 1.8652e-01, time/batch = 19.1856s	
8960/22950 (epoch 19.521), train_loss = 1.08562475, grad/param norm = 2.1432e-01, time/batch = 18.2853s	
8961/22950 (epoch 19.523), train_loss = 0.88127213, grad/param norm = 1.8896e-01, time/batch = 19.3568s	
8962/22950 (epoch 19.525), train_loss = 0.96676174, grad/param norm = 1.7965e-01, time/batch = 20.1332s	
8963/22950 (epoch 19.527), train_loss = 0.93520492, grad/param norm = 2.0627e-01, time/batch = 18.1107s	
8964/22950 (epoch 19.529), train_loss = 1.10727930, grad/param norm = 2.0926e-01, time/batch = 19.8109s	
8965/22950 (epoch 19.532), train_loss = 1.02336596, grad/param norm = 2.0498e-01, time/batch = 18.6272s	
8966/22950 (epoch 19.534), train_loss = 1.12523561, grad/param norm = 2.2636e-01, time/batch = 17.9629s	
8967/22950 (epoch 19.536), train_loss = 1.14135850, grad/param norm = 2.3448e-01, time/batch = 19.2974s	
8968/22950 (epoch 19.538), train_loss = 1.09455412, grad/param norm = 2.2737e-01, time/batch = 19.1282s	
8969/22950 (epoch 19.540), train_loss = 1.11771438, grad/param norm = 2.1784e-01, time/batch = 18.6810s	
8970/22950 (epoch 19.542), train_loss = 1.23708273, grad/param norm = 2.0734e-01, time/batch = 16.9768s	
8971/22950 (epoch 19.545), train_loss = 1.03564933, grad/param norm = 2.0704e-01, time/batch = 16.6806s	
8972/22950 (epoch 19.547), train_loss = 1.05720887, grad/param norm = 2.0530e-01, time/batch = 19.0297s	
8973/22950 (epoch 19.549), train_loss = 1.02080842, grad/param norm = 2.0325e-01, time/batch = 17.0401s	
8974/22950 (epoch 19.551), train_loss = 1.07470183, grad/param norm = 2.2127e-01, time/batch = 20.2978s	
8975/22950 (epoch 19.553), train_loss = 1.04771775, grad/param norm = 2.3125e-01, time/batch = 17.8944s	
8976/22950 (epoch 19.556), train_loss = 1.11112780, grad/param norm = 2.1269e-01, time/batch = 19.1829s	
8977/22950 (epoch 19.558), train_loss = 0.97250303, grad/param norm = 2.0297e-01, time/batch = 19.1115s	
8978/22950 (epoch 19.560), train_loss = 1.06675238, grad/param norm = 2.0340e-01, time/batch = 19.3546s	
8979/22950 (epoch 19.562), train_loss = 0.99688043, grad/param norm = 1.9867e-01, time/batch = 17.9559s	
8980/22950 (epoch 19.564), train_loss = 1.17064797, grad/param norm = 2.2150e-01, time/batch = 19.3844s	
8981/22950 (epoch 19.566), train_loss = 1.10927205, grad/param norm = 2.2105e-01, time/batch = 20.2176s	
8982/22950 (epoch 19.569), train_loss = 1.11475268, grad/param norm = 2.0795e-01, time/batch = 18.6212s	
8983/22950 (epoch 19.571), train_loss = 1.04989965, grad/param norm = 2.2318e-01, time/batch = 19.9485s	
8984/22950 (epoch 19.573), train_loss = 1.08373270, grad/param norm = 2.1991e-01, time/batch = 19.3573s	
8985/22950 (epoch 19.575), train_loss = 1.21353401, grad/param norm = 2.6070e-01, time/batch = 18.2014s	
8986/22950 (epoch 19.577), train_loss = 1.08958071, grad/param norm = 2.3926e-01, time/batch = 16.0915s	
8987/22950 (epoch 19.580), train_loss = 1.10789754, grad/param norm = 2.3202e-01, time/batch = 18.2839s	
8988/22950 (epoch 19.582), train_loss = 1.26111133, grad/param norm = 2.3205e-01, time/batch = 19.2215s	
8989/22950 (epoch 19.584), train_loss = 0.98384850, grad/param norm = 2.0184e-01, time/batch = 18.1983s	
8990/22950 (epoch 19.586), train_loss = 1.04998522, grad/param norm = 2.3159e-01, time/batch = 18.7847s	
8991/22950 (epoch 19.588), train_loss = 1.19420238, grad/param norm = 2.1072e-01, time/batch = 20.1880s	
8992/22950 (epoch 19.590), train_loss = 1.07584319, grad/param norm = 2.1048e-01, time/batch = 16.9282s	
8993/22950 (epoch 19.593), train_loss = 1.02461769, grad/param norm = 2.1591e-01, time/batch = 19.6995s	
8994/22950 (epoch 19.595), train_loss = 0.95843818, grad/param norm = 2.1121e-01, time/batch = 20.2099s	
8995/22950 (epoch 19.597), train_loss = 1.14595048, grad/param norm = 2.1855e-01, time/batch = 17.7916s	
8996/22950 (epoch 19.599), train_loss = 1.09765774, grad/param norm = 2.2846e-01, time/batch = 19.3765s	
8997/22950 (epoch 19.601), train_loss = 1.10927970, grad/param norm = 2.2590e-01, time/batch = 19.4614s	
8998/22950 (epoch 19.603), train_loss = 1.20744855, grad/param norm = 2.1074e-01, time/batch = 17.7040s	
8999/22950 (epoch 19.606), train_loss = 1.07557470, grad/param norm = 2.4578e-01, time/batch = 19.4652s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch19.61_1.7520.t7	
9000/22950 (epoch 19.608), train_loss = 1.11025195, grad/param norm = 2.1382e-01, time/batch = 18.3628s	
9001/22950 (epoch 19.610), train_loss = 1.34078752, grad/param norm = 2.2699e-01, time/batch = 19.6963s	
9002/22950 (epoch 19.612), train_loss = 1.05713333, grad/param norm = 2.0688e-01, time/batch = 18.0441s	
9003/22950 (epoch 19.614), train_loss = 1.20089317, grad/param norm = 2.4968e-01, time/batch = 18.7090s	
9004/22950 (epoch 19.617), train_loss = 1.07283262, grad/param norm = 2.2411e-01, time/batch = 18.2942s	
9005/22950 (epoch 19.619), train_loss = 1.04018812, grad/param norm = 1.9571e-01, time/batch = 18.2127s	
9006/22950 (epoch 19.621), train_loss = 1.18281779, grad/param norm = 1.9760e-01, time/batch = 19.2860s	
9007/22950 (epoch 19.623), train_loss = 1.15877175, grad/param norm = 2.0225e-01, time/batch = 19.0491s	
9008/22950 (epoch 19.625), train_loss = 1.05910464, grad/param norm = 2.0613e-01, time/batch = 18.5432s	
9009/22950 (epoch 19.627), train_loss = 1.05584906, grad/param norm = 2.2447e-01, time/batch = 16.0121s	
9010/22950 (epoch 19.630), train_loss = 0.95361203, grad/param norm = 1.9567e-01, time/batch = 19.6964s	
9011/22950 (epoch 19.632), train_loss = 1.07191317, grad/param norm = 2.2892e-01, time/batch = 18.7064s	
9012/22950 (epoch 19.634), train_loss = 1.08639246, grad/param norm = 2.1065e-01, time/batch = 15.7795s	
9013/22950 (epoch 19.636), train_loss = 1.12982437, grad/param norm = 2.1250e-01, time/batch = 17.7237s	
9014/22950 (epoch 19.638), train_loss = 1.00215015, grad/param norm = 1.9957e-01, time/batch = 17.3869s	
9015/22950 (epoch 19.641), train_loss = 1.05817622, grad/param norm = 2.0664e-01, time/batch = 17.5224s	
9016/22950 (epoch 19.643), train_loss = 1.10826293, grad/param norm = 2.4202e-01, time/batch = 17.9482s	
9017/22950 (epoch 19.645), train_loss = 1.03477930, grad/param norm = 2.0310e-01, time/batch = 19.4644s	
9018/22950 (epoch 19.647), train_loss = 1.07308267, grad/param norm = 2.1366e-01, time/batch = 18.3026s	
9019/22950 (epoch 19.649), train_loss = 1.08560278, grad/param norm = 2.2845e-01, time/batch = 19.4542s	
9020/22950 (epoch 19.651), train_loss = 1.13431986, grad/param norm = 2.2397e-01, time/batch = 17.8850s	
9021/22950 (epoch 19.654), train_loss = 0.90267768, grad/param norm = 1.9393e-01, time/batch = 18.9681s	
9022/22950 (epoch 19.656), train_loss = 1.17877747, grad/param norm = 2.4456e-01, time/batch = 18.8624s	
9023/22950 (epoch 19.658), train_loss = 0.98134668, grad/param norm = 2.1300e-01, time/batch = 16.7483s	
9024/22950 (epoch 19.660), train_loss = 0.90489079, grad/param norm = 2.2685e-01, time/batch = 18.4830s	
9025/22950 (epoch 19.662), train_loss = 0.90221804, grad/param norm = 1.9724e-01, time/batch = 16.6322s	
9026/22950 (epoch 19.664), train_loss = 1.04388713, grad/param norm = 1.9347e-01, time/batch = 14.7421s	
9027/22950 (epoch 19.667), train_loss = 1.09573339, grad/param norm = 2.0247e-01, time/batch = 18.9619s	
9028/22950 (epoch 19.669), train_loss = 1.07316020, grad/param norm = 2.0378e-01, time/batch = 18.6185s	
9029/22950 (epoch 19.671), train_loss = 1.09389641, grad/param norm = 2.0127e-01, time/batch = 18.1355s	
9030/22950 (epoch 19.673), train_loss = 1.03614853, grad/param norm = 2.1964e-01, time/batch = 18.5523s	
9031/22950 (epoch 19.675), train_loss = 1.07279583, grad/param norm = 2.1834e-01, time/batch = 19.0556s	
9032/22950 (epoch 19.678), train_loss = 1.09954189, grad/param norm = 2.1740e-01, time/batch = 16.6833s	
9033/22950 (epoch 19.680), train_loss = 1.06732502, grad/param norm = 1.9256e-01, time/batch = 16.1182s	
9034/22950 (epoch 19.682), train_loss = 1.09807694, grad/param norm = 2.2130e-01, time/batch = 19.3910s	
9035/22950 (epoch 19.684), train_loss = 1.18482687, grad/param norm = 2.2554e-01, time/batch = 18.7004s	
9036/22950 (epoch 19.686), train_loss = 1.15429274, grad/param norm = 1.9100e-01, time/batch = 18.4617s	
9037/22950 (epoch 19.688), train_loss = 1.10070363, grad/param norm = 2.1193e-01, time/batch = 18.8786s	
9038/22950 (epoch 19.691), train_loss = 1.07631836, grad/param norm = 2.0649e-01, time/batch = 18.9464s	
9039/22950 (epoch 19.693), train_loss = 1.00783805, grad/param norm = 2.0890e-01, time/batch = 19.4359s	
9040/22950 (epoch 19.695), train_loss = 1.17559430, grad/param norm = 2.2671e-01, time/batch = 19.2030s	
9041/22950 (epoch 19.697), train_loss = 1.13845882, grad/param norm = 2.2564e-01, time/batch = 18.5452s	
9042/22950 (epoch 19.699), train_loss = 1.14841816, grad/param norm = 2.1366e-01, time/batch = 18.4667s	
9043/22950 (epoch 19.702), train_loss = 1.15331700, grad/param norm = 2.1545e-01, time/batch = 17.7775s	
9044/22950 (epoch 19.704), train_loss = 1.15438712, grad/param norm = 2.0656e-01, time/batch = 20.1120s	
9045/22950 (epoch 19.706), train_loss = 1.16074105, grad/param norm = 2.2182e-01, time/batch = 18.1918s	
9046/22950 (epoch 19.708), train_loss = 0.97914339, grad/param norm = 1.9760e-01, time/batch = 19.1184s	
9047/22950 (epoch 19.710), train_loss = 1.10865589, grad/param norm = 2.1681e-01, time/batch = 19.4443s	
9048/22950 (epoch 19.712), train_loss = 1.20669038, grad/param norm = 2.2404e-01, time/batch = 16.9113s	
9049/22950 (epoch 19.715), train_loss = 1.10842198, grad/param norm = 2.1375e-01, time/batch = 19.9485s	
9050/22950 (epoch 19.717), train_loss = 1.06559584, grad/param norm = 1.9207e-01, time/batch = 19.1999s	
9051/22950 (epoch 19.719), train_loss = 1.04744514, grad/param norm = 2.1586e-01, time/batch = 17.6229s	
9052/22950 (epoch 19.721), train_loss = 1.12672002, grad/param norm = 2.2210e-01, time/batch = 19.1958s	
9053/22950 (epoch 19.723), train_loss = 1.03923090, grad/param norm = 1.9927e-01, time/batch = 19.7946s	
9054/22950 (epoch 19.725), train_loss = 1.15112004, grad/param norm = 2.5807e-01, time/batch = 18.1286s	
9055/22950 (epoch 19.728), train_loss = 1.05967087, grad/param norm = 2.4826e-01, time/batch = 17.4623s	
9056/22950 (epoch 19.730), train_loss = 1.07104722, grad/param norm = 2.0454e-01, time/batch = 15.4636s	
9057/22950 (epoch 19.732), train_loss = 1.13579596, grad/param norm = 2.3003e-01, time/batch = 16.5593s	
9058/22950 (epoch 19.734), train_loss = 1.08808604, grad/param norm = 2.1941e-01, time/batch = 18.3639s	
9059/22950 (epoch 19.736), train_loss = 1.07603859, grad/param norm = 2.0801e-01, time/batch = 18.7024s	
9060/22950 (epoch 19.739), train_loss = 1.16468496, grad/param norm = 2.3060e-01, time/batch = 19.2059s	
9061/22950 (epoch 19.741), train_loss = 1.18570393, grad/param norm = 2.2734e-01, time/batch = 17.2633s	
9062/22950 (epoch 19.743), train_loss = 1.23257963, grad/param norm = 2.2111e-01, time/batch = 19.1397s	
9063/22950 (epoch 19.745), train_loss = 1.34206776, grad/param norm = 2.4639e-01, time/batch = 17.9552s	
9064/22950 (epoch 19.747), train_loss = 1.10695543, grad/param norm = 2.1286e-01, time/batch = 17.0428s	
9065/22950 (epoch 19.749), train_loss = 1.01121821, grad/param norm = 2.1245e-01, time/batch = 19.3628s	
9066/22950 (epoch 19.752), train_loss = 1.27721157, grad/param norm = 2.3606e-01, time/batch = 18.1940s	
9067/22950 (epoch 19.754), train_loss = 1.17195813, grad/param norm = 2.2543e-01, time/batch = 19.1083s	
9068/22950 (epoch 19.756), train_loss = 1.01336817, grad/param norm = 2.1623e-01, time/batch = 19.8654s	
9069/22950 (epoch 19.758), train_loss = 1.05085902, grad/param norm = 1.9371e-01, time/batch = 19.2040s	
9070/22950 (epoch 19.760), train_loss = 1.14884743, grad/param norm = 2.4334e-01, time/batch = 18.7139s	
9071/22950 (epoch 19.763), train_loss = 1.15353626, grad/param norm = 2.0607e-01, time/batch = 17.6942s	
9072/22950 (epoch 19.765), train_loss = 1.13810921, grad/param norm = 2.3335e-01, time/batch = 18.1433s	
9073/22950 (epoch 19.767), train_loss = 1.27804374, grad/param norm = 2.4031e-01, time/batch = 18.7252s	
9074/22950 (epoch 19.769), train_loss = 1.11009448, grad/param norm = 2.0128e-01, time/batch = 16.6020s	
9075/22950 (epoch 19.771), train_loss = 0.95544123, grad/param norm = 1.8967e-01, time/batch = 16.7716s	
9076/22950 (epoch 19.773), train_loss = 0.83659548, grad/param norm = 1.9662e-01, time/batch = 19.4587s	
9077/22950 (epoch 19.776), train_loss = 1.00868854, grad/param norm = 1.9138e-01, time/batch = 26.2638s	
9078/22950 (epoch 19.778), train_loss = 0.97843176, grad/param norm = 1.9006e-01, time/batch = 24.7346s	
9079/22950 (epoch 19.780), train_loss = 1.07286577, grad/param norm = 1.8734e-01, time/batch = 19.0386s	
9080/22950 (epoch 19.782), train_loss = 1.09336566, grad/param norm = 2.1126e-01, time/batch = 17.9425s	
9081/22950 (epoch 19.784), train_loss = 1.04593812, grad/param norm = 2.1799e-01, time/batch = 19.2223s	
9082/22950 (epoch 19.786), train_loss = 1.13123822, grad/param norm = 2.0688e-01, time/batch = 18.9687s	
9083/22950 (epoch 19.789), train_loss = 0.94793941, grad/param norm = 2.0551e-01, time/batch = 18.6873s	
9084/22950 (epoch 19.791), train_loss = 0.98881460, grad/param norm = 2.2035e-01, time/batch = 17.9600s	
9085/22950 (epoch 19.793), train_loss = 1.25809803, grad/param norm = 2.2827e-01, time/batch = 19.7777s	
9086/22950 (epoch 19.795), train_loss = 1.03392164, grad/param norm = 1.9273e-01, time/batch = 17.2804s	
9087/22950 (epoch 19.797), train_loss = 1.22924175, grad/param norm = 2.2269e-01, time/batch = 19.4678s	
9088/22950 (epoch 19.800), train_loss = 1.01051556, grad/param norm = 2.0196e-01, time/batch = 18.7179s	
9089/22950 (epoch 19.802), train_loss = 1.01774100, grad/param norm = 2.1143e-01, time/batch = 17.3676s	
9090/22950 (epoch 19.804), train_loss = 1.07814663, grad/param norm = 2.0433e-01, time/batch = 16.2726s	
9091/22950 (epoch 19.806), train_loss = 0.98167291, grad/param norm = 2.1385e-01, time/batch = 18.7149s	
9092/22950 (epoch 19.808), train_loss = 1.07512697, grad/param norm = 2.1055e-01, time/batch = 17.2784s	
9093/22950 (epoch 19.810), train_loss = 1.04231145, grad/param norm = 2.0972e-01, time/batch = 18.5174s	
9094/22950 (epoch 19.813), train_loss = 0.89527039, grad/param norm = 2.0805e-01, time/batch = 16.3752s	
9095/22950 (epoch 19.815), train_loss = 0.94151177, grad/param norm = 1.9218e-01, time/batch = 18.6882s	
9096/22950 (epoch 19.817), train_loss = 0.95987639, grad/param norm = 1.9107e-01, time/batch = 16.5879s	
9097/22950 (epoch 19.819), train_loss = 1.07461822, grad/param norm = 2.1129e-01, time/batch = 18.9476s	
9098/22950 (epoch 19.821), train_loss = 1.02028132, grad/param norm = 2.1337e-01, time/batch = 19.9526s	
9099/22950 (epoch 19.824), train_loss = 1.07974947, grad/param norm = 2.4166e-01, time/batch = 18.3697s	
9100/22950 (epoch 19.826), train_loss = 1.19386132, grad/param norm = 2.2619e-01, time/batch = 18.4739s	
9101/22950 (epoch 19.828), train_loss = 1.06274491, grad/param norm = 2.2192e-01, time/batch = 20.3693s	
9102/22950 (epoch 19.830), train_loss = 1.06571747, grad/param norm = 2.0740e-01, time/batch = 17.7774s	
9103/22950 (epoch 19.832), train_loss = 1.08639289, grad/param norm = 2.0426e-01, time/batch = 20.1226s	
9104/22950 (epoch 19.834), train_loss = 0.91367942, grad/param norm = 1.9451e-01, time/batch = 19.1094s	
9105/22950 (epoch 19.837), train_loss = 1.09607366, grad/param norm = 2.2088e-01, time/batch = 18.6226s	
9106/22950 (epoch 19.839), train_loss = 0.91616798, grad/param norm = 1.8677e-01, time/batch = 18.0376s	
9107/22950 (epoch 19.841), train_loss = 0.99283587, grad/param norm = 1.7961e-01, time/batch = 19.5370s	
9108/22950 (epoch 19.843), train_loss = 1.02296930, grad/param norm = 2.0675e-01, time/batch = 20.2772s	
9109/22950 (epoch 19.845), train_loss = 1.09894667, grad/param norm = 2.1936e-01, time/batch = 17.3577s	
9110/22950 (epoch 19.847), train_loss = 1.14044782, grad/param norm = 2.2148e-01, time/batch = 17.8425s	
9111/22950 (epoch 19.850), train_loss = 1.12233227, grad/param norm = 2.3018e-01, time/batch = 16.9206s	
9112/22950 (epoch 19.852), train_loss = 1.12749306, grad/param norm = 2.1702e-01, time/batch = 16.4279s	
9113/22950 (epoch 19.854), train_loss = 1.04115453, grad/param norm = 2.0320e-01, time/batch = 17.9442s	
9114/22950 (epoch 19.856), train_loss = 1.23599393, grad/param norm = 2.2427e-01, time/batch = 17.6306s	
9115/22950 (epoch 19.858), train_loss = 1.12455601, grad/param norm = 2.0799e-01, time/batch = 18.6210s	
9116/22950 (epoch 19.861), train_loss = 1.16705813, grad/param norm = 2.1902e-01, time/batch = 18.1312s	
9117/22950 (epoch 19.863), train_loss = 1.19354412, grad/param norm = 2.1929e-01, time/batch = 19.1289s	
9118/22950 (epoch 19.865), train_loss = 1.24306883, grad/param norm = 2.2885e-01, time/batch = 19.5478s	
9119/22950 (epoch 19.867), train_loss = 1.11110275, grad/param norm = 2.0768e-01, time/batch = 18.1339s	
9120/22950 (epoch 19.869), train_loss = 1.25852866, grad/param norm = 2.4137e-01, time/batch = 19.1920s	
9121/22950 (epoch 19.871), train_loss = 1.11123122, grad/param norm = 2.2217e-01, time/batch = 17.6042s	
9122/22950 (epoch 19.874), train_loss = 1.08100206, grad/param norm = 2.0363e-01, time/batch = 18.2967s	
9123/22950 (epoch 19.876), train_loss = 1.15016499, grad/param norm = 2.1880e-01, time/batch = 15.7095s	
9124/22950 (epoch 19.878), train_loss = 1.02633489, grad/param norm = 2.1619e-01, time/batch = 19.2098s	
9125/22950 (epoch 19.880), train_loss = 1.24198320, grad/param norm = 2.2519e-01, time/batch = 17.9536s	
9126/22950 (epoch 19.882), train_loss = 0.98283686, grad/param norm = 2.0210e-01, time/batch = 18.2628s	
9127/22950 (epoch 19.885), train_loss = 1.11415112, grad/param norm = 2.1278e-01, time/batch = 18.1292s	
9128/22950 (epoch 19.887), train_loss = 1.10225007, grad/param norm = 2.1314e-01, time/batch = 18.1069s	
9129/22950 (epoch 19.889), train_loss = 1.13876463, grad/param norm = 2.2426e-01, time/batch = 15.9799s	
9130/22950 (epoch 19.891), train_loss = 1.03588879, grad/param norm = 2.1818e-01, time/batch = 17.1757s	
9131/22950 (epoch 19.893), train_loss = 1.14355240, grad/param norm = 2.0596e-01, time/batch = 16.8553s	
9132/22950 (epoch 19.895), train_loss = 1.27135508, grad/param norm = 2.5149e-01, time/batch = 17.9412s	
9133/22950 (epoch 19.898), train_loss = 1.05741626, grad/param norm = 2.0184e-01, time/batch = 18.8747s	
9134/22950 (epoch 19.900), train_loss = 1.03359377, grad/param norm = 1.8839e-01, time/batch = 19.2957s	
9135/22950 (epoch 19.902), train_loss = 1.12527522, grad/param norm = 2.1070e-01, time/batch = 18.9576s	
9136/22950 (epoch 19.904), train_loss = 1.12522389, grad/param norm = 2.2399e-01, time/batch = 20.2136s	
9137/22950 (epoch 19.906), train_loss = 1.13100248, grad/param norm = 2.2251e-01, time/batch = 17.8806s	
9138/22950 (epoch 19.908), train_loss = 0.96598809, grad/param norm = 1.8536e-01, time/batch = 17.8864s	
9139/22950 (epoch 19.911), train_loss = 0.93824840, grad/param norm = 1.8512e-01, time/batch = 15.6623s	
9140/22950 (epoch 19.913), train_loss = 1.02505434, grad/param norm = 2.0880e-01, time/batch = 18.8919s	
9141/22950 (epoch 19.915), train_loss = 1.19009946, grad/param norm = 2.2312e-01, time/batch = 19.7742s	
9142/22950 (epoch 19.917), train_loss = 0.96349619, grad/param norm = 1.9614e-01, time/batch = 17.2688s	
9143/22950 (epoch 19.919), train_loss = 1.04469361, grad/param norm = 2.0680e-01, time/batch = 16.1853s	
9144/22950 (epoch 19.922), train_loss = 1.08676348, grad/param norm = 2.0870e-01, time/batch = 16.3653s	
9145/22950 (epoch 19.924), train_loss = 1.12993191, grad/param norm = 2.1789e-01, time/batch = 16.6387s	
9146/22950 (epoch 19.926), train_loss = 0.92037948, grad/param norm = 2.1958e-01, time/batch = 18.7572s	
9147/22950 (epoch 19.928), train_loss = 0.95448292, grad/param norm = 2.0623e-01, time/batch = 18.2092s	
9148/22950 (epoch 19.930), train_loss = 0.95355649, grad/param norm = 2.1640e-01, time/batch = 17.2161s	
9149/22950 (epoch 19.932), train_loss = 0.90121460, grad/param norm = 1.9051e-01, time/batch = 16.2693s	
9150/22950 (epoch 19.935), train_loss = 1.05714934, grad/param norm = 2.0498e-01, time/batch = 19.7139s	
9151/22950 (epoch 19.937), train_loss = 1.08331668, grad/param norm = 2.2704e-01, time/batch = 17.7916s	
9152/22950 (epoch 19.939), train_loss = 0.99869859, grad/param norm = 2.0627e-01, time/batch = 16.9622s	
9153/22950 (epoch 19.941), train_loss = 0.99482427, grad/param norm = 1.9722e-01, time/batch = 19.9686s	
9154/22950 (epoch 19.943), train_loss = 1.10367503, grad/param norm = 2.3405e-01, time/batch = 18.2714s	
9155/22950 (epoch 19.946), train_loss = 0.93697151, grad/param norm = 2.0030e-01, time/batch = 18.2883s	
9156/22950 (epoch 19.948), train_loss = 1.16124326, grad/param norm = 2.2274e-01, time/batch = 17.8872s	
9157/22950 (epoch 19.950), train_loss = 1.09542039, grad/param norm = 2.1973e-01, time/batch = 20.0376s	
9158/22950 (epoch 19.952), train_loss = 1.09875264, grad/param norm = 2.0946e-01, time/batch = 16.9308s	
9159/22950 (epoch 19.954), train_loss = 1.10350913, grad/param norm = 2.1286e-01, time/batch = 18.2161s	
9160/22950 (epoch 19.956), train_loss = 1.01052200, grad/param norm = 2.0715e-01, time/batch = 17.7179s	
9161/22950 (epoch 19.959), train_loss = 0.97623016, grad/param norm = 1.9414e-01, time/batch = 19.4523s	
9162/22950 (epoch 19.961), train_loss = 1.08965290, grad/param norm = 2.0478e-01, time/batch = 16.2376s	
9163/22950 (epoch 19.963), train_loss = 1.11724858, grad/param norm = 2.2744e-01, time/batch = 16.7490s	
9164/22950 (epoch 19.965), train_loss = 1.21731252, grad/param norm = 2.1140e-01, time/batch = 19.1988s	
9165/22950 (epoch 19.967), train_loss = 1.05679240, grad/param norm = 2.2717e-01, time/batch = 18.1154s	
9166/22950 (epoch 19.969), train_loss = 0.98063180, grad/param norm = 2.1035e-01, time/batch = 15.9425s	
9167/22950 (epoch 19.972), train_loss = 1.06188739, grad/param norm = 2.0036e-01, time/batch = 16.4721s	
9168/22950 (epoch 19.974), train_loss = 1.02758694, grad/param norm = 2.0957e-01, time/batch = 17.9316s	
9169/22950 (epoch 19.976), train_loss = 1.00154313, grad/param norm = 1.9255e-01, time/batch = 15.6560s	
9170/22950 (epoch 19.978), train_loss = 1.03260539, grad/param norm = 2.1114e-01, time/batch = 14.9860s	
9171/22950 (epoch 19.980), train_loss = 1.05205615, grad/param norm = 2.0316e-01, time/batch = 14.9143s	
9172/22950 (epoch 19.983), train_loss = 1.09292015, grad/param norm = 2.1080e-01, time/batch = 15.0609s	
9173/22950 (epoch 19.985), train_loss = 0.94299406, grad/param norm = 2.0756e-01, time/batch = 15.0609s	
9174/22950 (epoch 19.987), train_loss = 1.00051620, grad/param norm = 1.9275e-01, time/batch = 14.8396s	
9175/22950 (epoch 19.989), train_loss = 1.07024702, grad/param norm = 2.0487e-01, time/batch = 14.6750s	
9176/22950 (epoch 19.991), train_loss = 0.89823502, grad/param norm = 1.8983e-01, time/batch = 15.0716s	
9177/22950 (epoch 19.993), train_loss = 1.09632149, grad/param norm = 2.2553e-01, time/batch = 15.1496s	
9178/22950 (epoch 19.996), train_loss = 1.10388431, grad/param norm = 2.1068e-01, time/batch = 14.8977s	
9179/22950 (epoch 19.998), train_loss = 0.98261712, grad/param norm = 2.0589e-01, time/batch = 14.9930s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
9180/22950 (epoch 20.000), train_loss = 0.90835058, grad/param norm = 1.9381e-01, time/batch = 15.0704s	
9181/22950 (epoch 20.002), train_loss = 1.23677895, grad/param norm = 2.2093e-01, time/batch = 15.4710s	
9182/22950 (epoch 20.004), train_loss = 1.08340348, grad/param norm = 1.9913e-01, time/batch = 15.4580s	
9183/22950 (epoch 20.007), train_loss = 1.07799106, grad/param norm = 2.0198e-01, time/batch = 15.2412s	
9184/22950 (epoch 20.009), train_loss = 1.22740398, grad/param norm = 2.3258e-01, time/batch = 15.6917s	
9185/22950 (epoch 20.011), train_loss = 0.94324621, grad/param norm = 1.9577e-01, time/batch = 16.4626s	
9186/22950 (epoch 20.013), train_loss = 1.10824175, grad/param norm = 2.2499e-01, time/batch = 15.3119s	
9187/22950 (epoch 20.015), train_loss = 1.13124637, grad/param norm = 2.3830e-01, time/batch = 15.5480s	
9188/22950 (epoch 20.017), train_loss = 1.10639589, grad/param norm = 2.0041e-01, time/batch = 15.3975s	
9189/22950 (epoch 20.020), train_loss = 1.07723467, grad/param norm = 1.9533e-01, time/batch = 15.1741s	
9190/22950 (epoch 20.022), train_loss = 0.93464727, grad/param norm = 2.0232e-01, time/batch = 14.9940s	
9191/22950 (epoch 20.024), train_loss = 1.04647346, grad/param norm = 2.2009e-01, time/batch = 15.4554s	
9192/22950 (epoch 20.026), train_loss = 1.13106666, grad/param norm = 2.2170e-01, time/batch = 15.8690s	
9193/22950 (epoch 20.028), train_loss = 1.16898795, grad/param norm = 1.9478e-01, time/batch = 15.0789s	
9194/22950 (epoch 20.031), train_loss = 1.05683007, grad/param norm = 2.1137e-01, time/batch = 15.0582s	
9195/22950 (epoch 20.033), train_loss = 1.21125259, grad/param norm = 2.5049e-01, time/batch = 14.9932s	
9196/22950 (epoch 20.035), train_loss = 1.07228923, grad/param norm = 1.9787e-01, time/batch = 16.8944s	
9197/22950 (epoch 20.037), train_loss = 1.07621151, grad/param norm = 2.2337e-01, time/batch = 15.2482s	
9198/22950 (epoch 20.039), train_loss = 1.02217937, grad/param norm = 1.9619e-01, time/batch = 15.1646s	
9199/22950 (epoch 20.041), train_loss = 1.03916269, grad/param norm = 2.1368e-01, time/batch = 14.9941s	
9200/22950 (epoch 20.044), train_loss = 1.09810854, grad/param norm = 2.1307e-01, time/batch = 15.8670s	
9201/22950 (epoch 20.046), train_loss = 1.05676220, grad/param norm = 2.0603e-01, time/batch = 15.4826s	
9202/22950 (epoch 20.048), train_loss = 1.09764368, grad/param norm = 2.1492e-01, time/batch = 15.4049s	
9203/22950 (epoch 20.050), train_loss = 1.05176668, grad/param norm = 2.1263e-01, time/batch = 15.1732s	
9204/22950 (epoch 20.052), train_loss = 1.09735621, grad/param norm = 2.0136e-01, time/batch = 16.5433s	
9205/22950 (epoch 20.054), train_loss = 1.25237369, grad/param norm = 2.3201e-01, time/batch = 16.2717s	
9206/22950 (epoch 20.057), train_loss = 1.20369479, grad/param norm = 2.2597e-01, time/batch = 15.7816s	
9207/22950 (epoch 20.059), train_loss = 1.11098764, grad/param norm = 1.9892e-01, time/batch = 15.7156s	
9208/22950 (epoch 20.061), train_loss = 0.98061919, grad/param norm = 2.0203e-01, time/batch = 16.6243s	
9209/22950 (epoch 20.063), train_loss = 1.13599419, grad/param norm = 2.1655e-01, time/batch = 16.5312s	
9210/22950 (epoch 20.065), train_loss = 0.90311669, grad/param norm = 1.8550e-01, time/batch = 16.2029s	
9211/22950 (epoch 20.068), train_loss = 1.13327784, grad/param norm = 2.1294e-01, time/batch = 16.3759s	
9212/22950 (epoch 20.070), train_loss = 0.97242066, grad/param norm = 1.9672e-01, time/batch = 16.2944s	
9213/22950 (epoch 20.072), train_loss = 1.12004006, grad/param norm = 2.1664e-01, time/batch = 15.9871s	
9214/22950 (epoch 20.074), train_loss = 1.08462610, grad/param norm = 2.1845e-01, time/batch = 15.9715s	
9215/22950 (epoch 20.076), train_loss = 1.10026940, grad/param norm = 2.0132e-01, time/batch = 16.7695s	
9216/22950 (epoch 20.078), train_loss = 1.14318290, grad/param norm = 2.0949e-01, time/batch = 16.4510s	
9217/22950 (epoch 20.081), train_loss = 1.17232492, grad/param norm = 2.2139e-01, time/batch = 16.2201s	
9218/22950 (epoch 20.083), train_loss = 1.04460555, grad/param norm = 2.0683e-01, time/batch = 15.8793s	
9219/22950 (epoch 20.085), train_loss = 0.96051327, grad/param norm = 2.1621e-01, time/batch = 15.4825s	
9220/22950 (epoch 20.087), train_loss = 0.96862484, grad/param norm = 2.1435e-01, time/batch = 15.8140s	
9221/22950 (epoch 20.089), train_loss = 1.08784577, grad/param norm = 1.8688e-01, time/batch = 15.9540s	
9222/22950 (epoch 20.092), train_loss = 1.03501662, grad/param norm = 2.6111e-01, time/batch = 15.6446s	
9223/22950 (epoch 20.094), train_loss = 1.00272372, grad/param norm = 2.1593e-01, time/batch = 16.3451s	
9224/22950 (epoch 20.096), train_loss = 1.21152810, grad/param norm = 2.2019e-01, time/batch = 16.3787s	
9225/22950 (epoch 20.098), train_loss = 1.12789763, grad/param norm = 2.1642e-01, time/batch = 15.7482s	
9226/22950 (epoch 20.100), train_loss = 1.02833862, grad/param norm = 2.0863e-01, time/batch = 16.7757s	
9227/22950 (epoch 20.102), train_loss = 1.06470249, grad/param norm = 1.9722e-01, time/batch = 16.2624s	
9228/22950 (epoch 20.105), train_loss = 0.93502968, grad/param norm = 1.8072e-01, time/batch = 15.6827s	
9229/22950 (epoch 20.107), train_loss = 1.02894902, grad/param norm = 2.1057e-01, time/batch = 15.2960s	
9230/22950 (epoch 20.109), train_loss = 1.01490060, grad/param norm = 2.1608e-01, time/batch = 15.3922s	
9231/22950 (epoch 20.111), train_loss = 0.92128666, grad/param norm = 2.0847e-01, time/batch = 15.2454s	
9232/22950 (epoch 20.113), train_loss = 1.07997157, grad/param norm = 2.0992e-01, time/batch = 15.4044s	
9233/22950 (epoch 20.115), train_loss = 1.09106846, grad/param norm = 2.0826e-01, time/batch = 15.5469s	
9234/22950 (epoch 20.118), train_loss = 1.21678072, grad/param norm = 2.1461e-01, time/batch = 15.7242s	
9235/22950 (epoch 20.120), train_loss = 0.99434370, grad/param norm = 2.1933e-01, time/batch = 15.8660s	
9236/22950 (epoch 20.122), train_loss = 1.16632283, grad/param norm = 2.2125e-01, time/batch = 15.3927s	
9237/22950 (epoch 20.124), train_loss = 0.92998386, grad/param norm = 1.8440e-01, time/batch = 15.7704s	
9238/22950 (epoch 20.126), train_loss = 1.04258511, grad/param norm = 1.9274e-01, time/batch = 15.2276s	
9239/22950 (epoch 20.129), train_loss = 0.93450752, grad/param norm = 1.8318e-01, time/batch = 15.5593s	
9240/22950 (epoch 20.131), train_loss = 1.03440882, grad/param norm = 2.0917e-01, time/batch = 15.3197s	
9241/22950 (epoch 20.133), train_loss = 1.11499793, grad/param norm = 2.0652e-01, time/batch = 15.8058s	
9242/22950 (epoch 20.135), train_loss = 1.05855083, grad/param norm = 1.9104e-01, time/batch = 15.8784s	
9243/22950 (epoch 20.137), train_loss = 1.19032064, grad/param norm = 2.3228e-01, time/batch = 15.6375s	
9244/22950 (epoch 20.139), train_loss = 0.95825218, grad/param norm = 2.0785e-01, time/batch = 16.2308s	
9245/22950 (epoch 20.142), train_loss = 0.97979200, grad/param norm = 2.0204e-01, time/batch = 15.9391s	
9246/22950 (epoch 20.144), train_loss = 1.01342846, grad/param norm = 2.1052e-01, time/batch = 16.4065s	
9247/22950 (epoch 20.146), train_loss = 1.02018688, grad/param norm = 2.1472e-01, time/batch = 16.4456s	
9248/22950 (epoch 20.148), train_loss = 1.01463102, grad/param norm = 2.0789e-01, time/batch = 16.2340s	
9249/22950 (epoch 20.150), train_loss = 1.08276494, grad/param norm = 2.1959e-01, time/batch = 16.0810s	
9250/22950 (epoch 20.153), train_loss = 1.01083103, grad/param norm = 1.9802e-01, time/batch = 15.9878s	
9251/22950 (epoch 20.155), train_loss = 1.01880227, grad/param norm = 2.1058e-01, time/batch = 15.3614s	
9252/22950 (epoch 20.157), train_loss = 1.03467603, grad/param norm = 1.9907e-01, time/batch = 15.8451s	
9253/22950 (epoch 20.159), train_loss = 0.96848247, grad/param norm = 1.9038e-01, time/batch = 15.8800s	
9254/22950 (epoch 20.161), train_loss = 1.00619040, grad/param norm = 1.9170e-01, time/batch = 15.7920s	
9255/22950 (epoch 20.163), train_loss = 0.93391658, grad/param norm = 1.9659e-01, time/batch = 15.4891s	
9256/22950 (epoch 20.166), train_loss = 1.18765745, grad/param norm = 2.3218e-01, time/batch = 16.3779s	
9257/22950 (epoch 20.168), train_loss = 1.13237042, grad/param norm = 2.1742e-01, time/batch = 16.0988s	
9258/22950 (epoch 20.170), train_loss = 1.06375406, grad/param norm = 2.1786e-01, time/batch = 15.4927s	
9259/22950 (epoch 20.172), train_loss = 1.08279240, grad/param norm = 1.9461e-01, time/batch = 15.3264s	
9260/22950 (epoch 20.174), train_loss = 1.13691043, grad/param norm = 2.1882e-01, time/batch = 15.7084s	
9261/22950 (epoch 20.176), train_loss = 1.14489289, grad/param norm = 2.1106e-01, time/batch = 15.5678s	
9262/22950 (epoch 20.179), train_loss = 1.12551182, grad/param norm = 2.1362e-01, time/batch = 15.3293s	
9263/22950 (epoch 20.181), train_loss = 1.30210707, grad/param norm = 2.2174e-01, time/batch = 15.5559s	
9264/22950 (epoch 20.183), train_loss = 1.16031325, grad/param norm = 2.2254e-01, time/batch = 16.5435s	
9265/22950 (epoch 20.185), train_loss = 1.10744348, grad/param norm = 2.1192e-01, time/batch = 15.5998s	
9266/22950 (epoch 20.187), train_loss = 0.99785974, grad/param norm = 2.3800e-01, time/batch = 16.0073s	
9267/22950 (epoch 20.190), train_loss = 0.90886608, grad/param norm = 2.2153e-01, time/batch = 15.8832s	
9268/22950 (epoch 20.192), train_loss = 0.91150901, grad/param norm = 1.8896e-01, time/batch = 16.3818s	
9269/22950 (epoch 20.194), train_loss = 1.03161549, grad/param norm = 2.3827e-01, time/batch = 15.6118s	
9270/22950 (epoch 20.196), train_loss = 0.86406783, grad/param norm = 2.0809e-01, time/batch = 15.4660s	
9271/22950 (epoch 20.198), train_loss = 1.14673158, grad/param norm = 2.1908e-01, time/batch = 15.9671s	
9272/22950 (epoch 20.200), train_loss = 0.97920140, grad/param norm = 1.8965e-01, time/batch = 15.3855s	
9273/22950 (epoch 20.203), train_loss = 0.93005025, grad/param norm = 1.9060e-01, time/batch = 15.5294s	
9274/22950 (epoch 20.205), train_loss = 1.00690216, grad/param norm = 1.8775e-01, time/batch = 15.2112s	
9275/22950 (epoch 20.207), train_loss = 1.04399468, grad/param norm = 2.0860e-01, time/batch = 15.7123s	
9276/22950 (epoch 20.209), train_loss = 1.06678746, grad/param norm = 2.0163e-01, time/batch = 15.0712s	
9277/22950 (epoch 20.211), train_loss = 0.87320027, grad/param norm = 2.0270e-01, time/batch = 15.3294s	
9278/22950 (epoch 20.214), train_loss = 1.02168411, grad/param norm = 2.0531e-01, time/batch = 14.9745s	
9279/22950 (epoch 20.216), train_loss = 1.12897052, grad/param norm = 2.1299e-01, time/batch = 16.1393s	
9280/22950 (epoch 20.218), train_loss = 1.06484514, grad/param norm = 2.0106e-01, time/batch = 15.4716s	
9281/22950 (epoch 20.220), train_loss = 1.14839324, grad/param norm = 2.3113e-01, time/batch = 16.1542s	
9282/22950 (epoch 20.222), train_loss = 1.17959524, grad/param norm = 2.3278e-01, time/batch = 16.3635s	
9283/22950 (epoch 20.224), train_loss = 1.05861918, grad/param norm = 2.1675e-01, time/batch = 16.1089s	
9284/22950 (epoch 20.227), train_loss = 1.12759495, grad/param norm = 1.8894e-01, time/batch = 15.4068s	
9285/22950 (epoch 20.229), train_loss = 1.13365831, grad/param norm = 2.1491e-01, time/batch = 16.2513s	
9286/22950 (epoch 20.231), train_loss = 0.92575080, grad/param norm = 1.8019e-01, time/batch = 16.0922s	
9287/22950 (epoch 20.233), train_loss = 0.99979364, grad/param norm = 2.0834e-01, time/batch = 15.5451s	
9288/22950 (epoch 20.235), train_loss = 1.19515362, grad/param norm = 2.1440e-01, time/batch = 15.1549s	
9289/22950 (epoch 20.237), train_loss = 0.96854481, grad/param norm = 1.9469e-01, time/batch = 14.8086s	
9290/22950 (epoch 20.240), train_loss = 1.04770548, grad/param norm = 2.0920e-01, time/batch = 17.8960s	
9291/22950 (epoch 20.242), train_loss = 1.16003443, grad/param norm = 2.0173e-01, time/batch = 1.0028s	
9292/22950 (epoch 20.244), train_loss = 1.20833439, grad/param norm = 2.2909e-01, time/batch = 0.6850s	
9293/22950 (epoch 20.246), train_loss = 1.17317096, grad/param norm = 2.0467e-01, time/batch = 0.6924s	
9294/22950 (epoch 20.248), train_loss = 1.10139941, grad/param norm = 2.2054e-01, time/batch = 0.7000s	
9295/22950 (epoch 20.251), train_loss = 0.98638713, grad/param norm = 1.9110e-01, time/batch = 0.7219s	
9296/22950 (epoch 20.253), train_loss = 1.00873807, grad/param norm = 2.2168e-01, time/batch = 0.7103s	
9297/22950 (epoch 20.255), train_loss = 1.07976693, grad/param norm = 2.2594e-01, time/batch = 0.8818s	
9298/22950 (epoch 20.257), train_loss = 1.16814915, grad/param norm = 2.0812e-01, time/batch = 1.0111s	
9299/22950 (epoch 20.259), train_loss = 0.91775558, grad/param norm = 2.0093e-01, time/batch = 1.0031s	
9300/22950 (epoch 20.261), train_loss = 1.00891642, grad/param norm = 1.9951e-01, time/batch = 1.0218s	
9301/22950 (epoch 20.264), train_loss = 0.95929777, grad/param norm = 1.9868e-01, time/batch = 1.0388s	
9302/22950 (epoch 20.266), train_loss = 1.08788646, grad/param norm = 2.0958e-01, time/batch = 1.5897s	
9303/22950 (epoch 20.268), train_loss = 1.04198010, grad/param norm = 2.0846e-01, time/batch = 1.9431s	
9304/22950 (epoch 20.270), train_loss = 1.05397563, grad/param norm = 1.9458e-01, time/batch = 2.4722s	
9305/22950 (epoch 20.272), train_loss = 1.14365281, grad/param norm = 2.1322e-01, time/batch = 15.0677s	
9306/22950 (epoch 20.275), train_loss = 1.00092822, grad/param norm = 2.0131e-01, time/batch = 14.9992s	
9307/22950 (epoch 20.277), train_loss = 0.89385825, grad/param norm = 1.7547e-01, time/batch = 16.1566s	
9308/22950 (epoch 20.279), train_loss = 0.99338564, grad/param norm = 2.2357e-01, time/batch = 15.6120s	
9309/22950 (epoch 20.281), train_loss = 1.03090156, grad/param norm = 2.2423e-01, time/batch = 15.6227s	
9310/22950 (epoch 20.283), train_loss = 0.89938147, grad/param norm = 1.7326e-01, time/batch = 15.7870s	
9311/22950 (epoch 20.285), train_loss = 1.06887595, grad/param norm = 1.9884e-01, time/batch = 15.9595s	
9312/22950 (epoch 20.288), train_loss = 1.11228778, grad/param norm = 1.9458e-01, time/batch = 15.4803s	
9313/22950 (epoch 20.290), train_loss = 1.01115323, grad/param norm = 2.0496e-01, time/batch = 15.8047s	
9314/22950 (epoch 20.292), train_loss = 1.14892720, grad/param norm = 1.9627e-01, time/batch = 15.6294s	
9315/22950 (epoch 20.294), train_loss = 1.04020923, grad/param norm = 1.9246e-01, time/batch = 16.0089s	
9316/22950 (epoch 20.296), train_loss = 0.83127906, grad/param norm = 1.6627e-01, time/batch = 16.4045s	
9317/22950 (epoch 20.298), train_loss = 1.06778572, grad/param norm = 2.0521e-01, time/batch = 16.5637s	
9318/22950 (epoch 20.301), train_loss = 1.07601849, grad/param norm = 2.1838e-01, time/batch = 16.8100s	
9319/22950 (epoch 20.303), train_loss = 1.07411719, grad/param norm = 1.9769e-01, time/batch = 16.1905s	
9320/22950 (epoch 20.305), train_loss = 1.08167197, grad/param norm = 2.2753e-01, time/batch = 16.4222s	
9321/22950 (epoch 20.307), train_loss = 1.17006758, grad/param norm = 2.2888e-01, time/batch = 15.7972s	
9322/22950 (epoch 20.309), train_loss = 0.98540416, grad/param norm = 1.7715e-01, time/batch = 15.7844s	
9323/22950 (epoch 20.312), train_loss = 1.06253117, grad/param norm = 2.0975e-01, time/batch = 15.3195s	
9324/22950 (epoch 20.314), train_loss = 1.03851169, grad/param norm = 1.9551e-01, time/batch = 15.7844s	
9325/22950 (epoch 20.316), train_loss = 1.05081344, grad/param norm = 2.2143e-01, time/batch = 14.9062s	
9326/22950 (epoch 20.318), train_loss = 0.89259952, grad/param norm = 1.7860e-01, time/batch = 15.7769s	
9327/22950 (epoch 20.320), train_loss = 0.98066065, grad/param norm = 1.8692e-01, time/batch = 15.3949s	
9328/22950 (epoch 20.322), train_loss = 1.02280278, grad/param norm = 2.0718e-01, time/batch = 15.1525s	
9329/22950 (epoch 20.325), train_loss = 0.84119674, grad/param norm = 1.8632e-01, time/batch = 15.0708s	
9330/22950 (epoch 20.327), train_loss = 0.86971515, grad/param norm = 1.8371e-01, time/batch = 15.6114s	
9331/22950 (epoch 20.329), train_loss = 0.98636049, grad/param norm = 2.0080e-01, time/batch = 15.3166s	
9332/22950 (epoch 20.331), train_loss = 0.91795544, grad/param norm = 1.9781e-01, time/batch = 15.3968s	
9333/22950 (epoch 20.333), train_loss = 1.02312819, grad/param norm = 2.0435e-01, time/batch = 15.3173s	
9334/22950 (epoch 20.336), train_loss = 1.02333013, grad/param norm = 2.1333e-01, time/batch = 15.6981s	
9335/22950 (epoch 20.338), train_loss = 1.01576412, grad/param norm = 1.9351e-01, time/batch = 15.1602s	
9336/22950 (epoch 20.340), train_loss = 1.04482501, grad/param norm = 2.1591e-01, time/batch = 15.3887s	
9337/22950 (epoch 20.342), train_loss = 1.15411118, grad/param norm = 2.4540e-01, time/batch = 16.0040s	
9338/22950 (epoch 20.344), train_loss = 1.02435087, grad/param norm = 2.1556e-01, time/batch = 16.4846s	
9339/22950 (epoch 20.346), train_loss = 1.14494183, grad/param norm = 2.5324e-01, time/batch = 16.4152s	
9340/22950 (epoch 20.349), train_loss = 1.05748712, grad/param norm = 2.2045e-01, time/batch = 15.0721s	
9341/22950 (epoch 20.351), train_loss = 1.07930168, grad/param norm = 2.1827e-01, time/batch = 15.7868s	
9342/22950 (epoch 20.353), train_loss = 1.13834793, grad/param norm = 2.6777e-01, time/batch = 15.8681s	
9343/22950 (epoch 20.355), train_loss = 1.16285873, grad/param norm = 2.3602e-01, time/batch = 15.4609s	
9344/22950 (epoch 20.357), train_loss = 1.04612389, grad/param norm = 2.1669e-01, time/batch = 14.9828s	
9345/22950 (epoch 20.359), train_loss = 1.07372861, grad/param norm = 2.2383e-01, time/batch = 15.6784s	
9346/22950 (epoch 20.362), train_loss = 1.05720787, grad/param norm = 2.1152e-01, time/batch = 14.8070s	
9347/22950 (epoch 20.364), train_loss = 1.04123873, grad/param norm = 2.1880e-01, time/batch = 14.9051s	
9348/22950 (epoch 20.366), train_loss = 0.98823113, grad/param norm = 1.9052e-01, time/batch = 15.0069s	
9349/22950 (epoch 20.368), train_loss = 1.10292566, grad/param norm = 2.3180e-01, time/batch = 15.4822s	
9350/22950 (epoch 20.370), train_loss = 1.01690653, grad/param norm = 2.0838e-01, time/batch = 15.1547s	
9351/22950 (epoch 20.373), train_loss = 0.92625643, grad/param norm = 1.9560e-01, time/batch = 15.1538s	
9352/22950 (epoch 20.375), train_loss = 1.15821363, grad/param norm = 2.3543e-01, time/batch = 15.2388s	
9353/22950 (epoch 20.377), train_loss = 0.95552905, grad/param norm = 2.2986e-01, time/batch = 15.5513s	
9354/22950 (epoch 20.379), train_loss = 1.07380660, grad/param norm = 2.5315e-01, time/batch = 16.4044s	
9355/22950 (epoch 20.381), train_loss = 0.92046110, grad/param norm = 2.0951e-01, time/batch = 16.3472s	
9356/22950 (epoch 20.383), train_loss = 1.04411747, grad/param norm = 2.4050e-01, time/batch = 15.8616s	
9357/22950 (epoch 20.386), train_loss = 0.96968950, grad/param norm = 2.0967e-01, time/batch = 15.9467s	
9358/22950 (epoch 20.388), train_loss = 1.05396427, grad/param norm = 2.3682e-01, time/batch = 16.0899s	
9359/22950 (epoch 20.390), train_loss = 0.93570200, grad/param norm = 2.0223e-01, time/batch = 15.7242s	
9360/22950 (epoch 20.392), train_loss = 0.97625992, grad/param norm = 2.0412e-01, time/batch = 16.3155s	
9361/22950 (epoch 20.394), train_loss = 0.97495586, grad/param norm = 2.0512e-01, time/batch = 16.9068s	
9362/22950 (epoch 20.397), train_loss = 1.18437176, grad/param norm = 2.1274e-01, time/batch = 16.1099s	
9363/22950 (epoch 20.399), train_loss = 1.18860568, grad/param norm = 2.5624e-01, time/batch = 15.4944s	
9364/22950 (epoch 20.401), train_loss = 1.24356090, grad/param norm = 2.3039e-01, time/batch = 15.9450s	
9365/22950 (epoch 20.403), train_loss = 1.02014011, grad/param norm = 2.2499e-01, time/batch = 15.1679s	
9366/22950 (epoch 20.405), train_loss = 1.17536458, grad/param norm = 2.7225e-01, time/batch = 15.6282s	
9367/22950 (epoch 20.407), train_loss = 1.21858274, grad/param norm = 2.2423e-01, time/batch = 14.9081s	
9368/22950 (epoch 20.410), train_loss = 0.98048445, grad/param norm = 2.0319e-01, time/batch = 15.6345s	
9369/22950 (epoch 20.412), train_loss = 1.03259656, grad/param norm = 2.1902e-01, time/batch = 16.7378s	
9370/22950 (epoch 20.414), train_loss = 1.15886799, grad/param norm = 2.2523e-01, time/batch = 15.2313s	
9371/22950 (epoch 20.416), train_loss = 1.09338312, grad/param norm = 2.5390e-01, time/batch = 15.2478s	
9372/22950 (epoch 20.418), train_loss = 1.06445411, grad/param norm = 2.2130e-01, time/batch = 15.9563s	
9373/22950 (epoch 20.420), train_loss = 1.10781370, grad/param norm = 2.3309e-01, time/batch = 15.3307s	
9374/22950 (epoch 20.423), train_loss = 0.98169120, grad/param norm = 1.9134e-01, time/batch = 15.1572s	
9375/22950 (epoch 20.425), train_loss = 1.03321679, grad/param norm = 2.0022e-01, time/batch = 15.8529s	
9376/22950 (epoch 20.427), train_loss = 1.02785557, grad/param norm = 1.9202e-01, time/batch = 16.7460s	
9377/22950 (epoch 20.429), train_loss = 1.02336644, grad/param norm = 1.9226e-01, time/batch = 15.9817s	
9378/22950 (epoch 20.431), train_loss = 1.10286572, grad/param norm = 2.1863e-01, time/batch = 16.6091s	
9379/22950 (epoch 20.434), train_loss = 1.05848090, grad/param norm = 2.0839e-01, time/batch = 16.3497s	
9380/22950 (epoch 20.436), train_loss = 1.16804261, grad/param norm = 2.4626e-01, time/batch = 16.2972s	
9381/22950 (epoch 20.438), train_loss = 1.08895149, grad/param norm = 2.1378e-01, time/batch = 16.6746s	
9382/22950 (epoch 20.440), train_loss = 1.15665616, grad/param norm = 2.1268e-01, time/batch = 16.8688s	
9383/22950 (epoch 20.442), train_loss = 1.21654786, grad/param norm = 2.2870e-01, time/batch = 17.0472s	
9384/22950 (epoch 20.444), train_loss = 1.12464905, grad/param norm = 2.2855e-01, time/batch = 16.3590s	
9385/22950 (epoch 20.447), train_loss = 1.23520322, grad/param norm = 2.3026e-01, time/batch = 15.7303s	
9386/22950 (epoch 20.449), train_loss = 0.95046604, grad/param norm = 1.9750e-01, time/batch = 16.1852s	
9387/22950 (epoch 20.451), train_loss = 1.09259839, grad/param norm = 2.1642e-01, time/batch = 16.0533s	
9388/22950 (epoch 20.453), train_loss = 1.10736223, grad/param norm = 2.1082e-01, time/batch = 15.8867s	
9389/22950 (epoch 20.455), train_loss = 1.01482565, grad/param norm = 1.9713e-01, time/batch = 16.0360s	
9390/22950 (epoch 20.458), train_loss = 1.14811751, grad/param norm = 2.0716e-01, time/batch = 15.9592s	
9391/22950 (epoch 20.460), train_loss = 1.09937535, grad/param norm = 2.1553e-01, time/batch = 16.0504s	
9392/22950 (epoch 20.462), train_loss = 1.05572299, grad/param norm = 2.3596e-01, time/batch = 15.8085s	
9393/22950 (epoch 20.464), train_loss = 1.02601909, grad/param norm = 2.1177e-01, time/batch = 15.8091s	
9394/22950 (epoch 20.466), train_loss = 1.11955154, grad/param norm = 2.1119e-01, time/batch = 16.4834s	
9395/22950 (epoch 20.468), train_loss = 1.18046543, grad/param norm = 2.2583e-01, time/batch = 16.6524s	
9396/22950 (epoch 20.471), train_loss = 1.12053164, grad/param norm = 2.4757e-01, time/batch = 16.9113s	
9397/22950 (epoch 20.473), train_loss = 1.14682454, grad/param norm = 2.2396e-01, time/batch = 16.2719s	
9398/22950 (epoch 20.475), train_loss = 1.25504628, grad/param norm = 2.1819e-01, time/batch = 16.6742s	
9399/22950 (epoch 20.477), train_loss = 1.05131627, grad/param norm = 2.0453e-01, time/batch = 16.3689s	
9400/22950 (epoch 20.479), train_loss = 0.96914051, grad/param norm = 1.9733e-01, time/batch = 16.2006s	
9401/22950 (epoch 20.481), train_loss = 1.15521148, grad/param norm = 2.4050e-01, time/batch = 16.4526s	
9402/22950 (epoch 20.484), train_loss = 1.08830840, grad/param norm = 2.2473e-01, time/batch = 15.8134s	
9403/22950 (epoch 20.486), train_loss = 0.93161184, grad/param norm = 1.8794e-01, time/batch = 16.1913s	
9404/22950 (epoch 20.488), train_loss = 1.01609582, grad/param norm = 2.2982e-01, time/batch = 15.8959s	
9405/22950 (epoch 20.490), train_loss = 0.91670420, grad/param norm = 2.0095e-01, time/batch = 16.1897s	
9406/22950 (epoch 20.492), train_loss = 1.02749692, grad/param norm = 2.1995e-01, time/batch = 16.1413s	
9407/22950 (epoch 20.495), train_loss = 1.00846944, grad/param norm = 2.0473e-01, time/batch = 16.0541s	
9408/22950 (epoch 20.497), train_loss = 1.13462819, grad/param norm = 2.3463e-01, time/batch = 16.3787s	
9409/22950 (epoch 20.499), train_loss = 1.18435475, grad/param norm = 2.1448e-01, time/batch = 16.5441s	
9410/22950 (epoch 20.501), train_loss = 1.12224067, grad/param norm = 2.2480e-01, time/batch = 16.1855s	
9411/22950 (epoch 20.503), train_loss = 1.15787851, grad/param norm = 2.0682e-01, time/batch = 16.3464s	
9412/22950 (epoch 20.505), train_loss = 0.94864432, grad/param norm = 1.9131e-01, time/batch = 16.2547s	
9413/22950 (epoch 20.508), train_loss = 1.10266640, grad/param norm = 2.0933e-01, time/batch = 16.2851s	
9414/22950 (epoch 20.510), train_loss = 1.07650377, grad/param norm = 2.2352e-01, time/batch = 16.5148s	
9415/22950 (epoch 20.512), train_loss = 0.96986599, grad/param norm = 2.0895e-01, time/batch = 16.0368s	
9416/22950 (epoch 20.514), train_loss = 0.97461847, grad/param norm = 1.7928e-01, time/batch = 16.9662s	
9417/22950 (epoch 20.516), train_loss = 1.03780197, grad/param norm = 2.1042e-01, time/batch = 16.6562s	
9418/22950 (epoch 20.519), train_loss = 1.02671315, grad/param norm = 1.9018e-01, time/batch = 16.2948s	
9419/22950 (epoch 20.521), train_loss = 1.05783192, grad/param norm = 2.1811e-01, time/batch = 15.6386s	
9420/22950 (epoch 20.523), train_loss = 0.86682864, grad/param norm = 2.0416e-01, time/batch = 16.5948s	
9421/22950 (epoch 20.525), train_loss = 0.95323552, grad/param norm = 1.8065e-01, time/batch = 16.3023s	
9422/22950 (epoch 20.527), train_loss = 0.91375761, grad/param norm = 2.0094e-01, time/batch = 16.4126s	
9423/22950 (epoch 20.529), train_loss = 1.09030003, grad/param norm = 2.1705e-01, time/batch = 16.4063s	
9424/22950 (epoch 20.532), train_loss = 1.00860412, grad/param norm = 2.1223e-01, time/batch = 15.8050s	
9425/22950 (epoch 20.534), train_loss = 1.09468691, grad/param norm = 2.2546e-01, time/batch = 15.8015s	
9426/22950 (epoch 20.536), train_loss = 1.12487922, grad/param norm = 2.4966e-01, time/batch = 16.7750s	
9427/22950 (epoch 20.538), train_loss = 1.07963293, grad/param norm = 2.4033e-01, time/batch = 16.9208s	
9428/22950 (epoch 20.540), train_loss = 1.09511368, grad/param norm = 2.3859e-01, time/batch = 16.7748s	
9429/22950 (epoch 20.542), train_loss = 1.21213634, grad/param norm = 2.0600e-01, time/batch = 16.7258s	
9430/22950 (epoch 20.545), train_loss = 1.01871349, grad/param norm = 2.0008e-01, time/batch = 16.3829s	
9431/22950 (epoch 20.547), train_loss = 1.03134224, grad/param norm = 2.0746e-01, time/batch = 16.6393s	
9432/22950 (epoch 20.549), train_loss = 1.00305940, grad/param norm = 2.1363e-01, time/batch = 16.5190s	
9433/22950 (epoch 20.551), train_loss = 1.04751235, grad/param norm = 2.2402e-01, time/batch = 16.6229s	
9434/22950 (epoch 20.553), train_loss = 1.01978436, grad/param norm = 2.2793e-01, time/batch = 16.6510s	
9435/22950 (epoch 20.556), train_loss = 1.08866312, grad/param norm = 2.0899e-01, time/batch = 16.8784s	
9436/22950 (epoch 20.558), train_loss = 0.94976524, grad/param norm = 2.0328e-01, time/batch = 16.7729s	
9437/22950 (epoch 20.560), train_loss = 1.04927860, grad/param norm = 2.0793e-01, time/batch = 16.3476s	
9438/22950 (epoch 20.562), train_loss = 0.98602836, grad/param norm = 2.0263e-01, time/batch = 16.8621s	
9439/22950 (epoch 20.564), train_loss = 1.14488288, grad/param norm = 2.2438e-01, time/batch = 16.5125s	
9440/22950 (epoch 20.566), train_loss = 1.08893857, grad/param norm = 2.1357e-01, time/batch = 16.1382s	
9441/22950 (epoch 20.569), train_loss = 1.08070605, grad/param norm = 2.0701e-01, time/batch = 16.5148s	
9442/22950 (epoch 20.571), train_loss = 1.02849739, grad/param norm = 2.2389e-01, time/batch = 16.6724s	
9443/22950 (epoch 20.573), train_loss = 1.05935439, grad/param norm = 2.1525e-01, time/batch = 16.3860s	
9444/22950 (epoch 20.575), train_loss = 1.18611456, grad/param norm = 2.2746e-01, time/batch = 16.5405s	
9445/22950 (epoch 20.577), train_loss = 1.06656385, grad/param norm = 2.3112e-01, time/batch = 16.6109s	
9446/22950 (epoch 20.580), train_loss = 1.08744216, grad/param norm = 2.2667e-01, time/batch = 16.3026s	
9447/22950 (epoch 20.582), train_loss = 1.24872548, grad/param norm = 2.4104e-01, time/batch = 16.7036s	
9448/22950 (epoch 20.584), train_loss = 0.95310591, grad/param norm = 2.3386e-01, time/batch = 16.7009s	
9449/22950 (epoch 20.586), train_loss = 1.00796011, grad/param norm = 2.1559e-01, time/batch = 16.8812s	
9450/22950 (epoch 20.588), train_loss = 1.19600041, grad/param norm = 2.3394e-01, time/batch = 16.6312s	
9451/22950 (epoch 20.590), train_loss = 1.06170334, grad/param norm = 2.2032e-01, time/batch = 16.7271s	
9452/22950 (epoch 20.593), train_loss = 1.00928632, grad/param norm = 2.2030e-01, time/batch = 16.7032s	
9453/22950 (epoch 20.595), train_loss = 0.94317954, grad/param norm = 2.3186e-01, time/batch = 16.3740s	
9454/22950 (epoch 20.597), train_loss = 1.13083350, grad/param norm = 2.2144e-01, time/batch = 16.4681s	
9455/22950 (epoch 20.599), train_loss = 1.07744830, grad/param norm = 2.3047e-01, time/batch = 16.6698s	
9456/22950 (epoch 20.601), train_loss = 1.09547395, grad/param norm = 2.1538e-01, time/batch = 16.8613s	
9457/22950 (epoch 20.603), train_loss = 1.20011608, grad/param norm = 2.1522e-01, time/batch = 16.9392s	
9458/22950 (epoch 20.606), train_loss = 1.05421922, grad/param norm = 2.1194e-01, time/batch = 16.8498s	
9459/22950 (epoch 20.608), train_loss = 1.08920810, grad/param norm = 2.2337e-01, time/batch = 17.1615s	
9460/22950 (epoch 20.610), train_loss = 1.04763013, grad/param norm = 1.9267e-01, time/batch = 16.8728s	
9461/22950 (epoch 20.612), train_loss = 1.03711754, grad/param norm = 2.1403e-01, time/batch = 17.2940s	
9462/22950 (epoch 20.614), train_loss = 1.17317885, grad/param norm = 2.3183e-01, time/batch = 16.8018s	
9463/22950 (epoch 20.617), train_loss = 1.05115698, grad/param norm = 2.1433e-01, time/batch = 16.9423s	
9464/22950 (epoch 20.619), train_loss = 1.02579698, grad/param norm = 1.8503e-01, time/batch = 16.5854s	
9465/22950 (epoch 20.621), train_loss = 1.15838580, grad/param norm = 1.9469e-01, time/batch = 16.5152s	
9466/22950 (epoch 20.623), train_loss = 1.14553477, grad/param norm = 2.1444e-01, time/batch = 16.6324s	
9467/22950 (epoch 20.625), train_loss = 1.04045497, grad/param norm = 2.1812e-01, time/batch = 16.8855s	
9468/22950 (epoch 20.627), train_loss = 1.04091950, grad/param norm = 2.3327e-01, time/batch = 16.7157s	
9469/22950 (epoch 20.630), train_loss = 0.93165667, grad/param norm = 1.8799e-01, time/batch = 16.8532s	
9470/22950 (epoch 20.632), train_loss = 1.04019056, grad/param norm = 2.3983e-01, time/batch = 17.1814s	
9471/22950 (epoch 20.634), train_loss = 1.07321685, grad/param norm = 2.0995e-01, time/batch = 16.8846s	
9472/22950 (epoch 20.636), train_loss = 1.10635560, grad/param norm = 2.1578e-01, time/batch = 16.9370s	
9473/22950 (epoch 20.638), train_loss = 0.99208949, grad/param norm = 2.1700e-01, time/batch = 16.9304s	
9474/22950 (epoch 20.641), train_loss = 1.03105035, grad/param norm = 1.9700e-01, time/batch = 16.9498s	
9475/22950 (epoch 20.643), train_loss = 1.09027531, grad/param norm = 2.3940e-01, time/batch = 16.5628s	
9476/22950 (epoch 20.645), train_loss = 1.01791379, grad/param norm = 2.0273e-01, time/batch = 16.7242s	
9477/22950 (epoch 20.647), train_loss = 1.05035210, grad/param norm = 2.1772e-01, time/batch = 16.7972s	
9478/22950 (epoch 20.649), train_loss = 1.05216457, grad/param norm = 2.2526e-01, time/batch = 16.4841s	
9479/22950 (epoch 20.651), train_loss = 1.10865547, grad/param norm = 2.3497e-01, time/batch = 16.5677s	
9480/22950 (epoch 20.654), train_loss = 0.89045813, grad/param norm = 1.9379e-01, time/batch = 16.6394s	
9481/22950 (epoch 20.656), train_loss = 1.15412464, grad/param norm = 2.6825e-01, time/batch = 16.9278s	
9482/22950 (epoch 20.658), train_loss = 0.96663022, grad/param norm = 2.2186e-01, time/batch = 16.8544s	
9483/22950 (epoch 20.660), train_loss = 0.87248343, grad/param norm = 1.9853e-01, time/batch = 16.7759s	
9484/22950 (epoch 20.662), train_loss = 0.88142424, grad/param norm = 1.9038e-01, time/batch = 16.8198s	
9485/22950 (epoch 20.664), train_loss = 1.03524191, grad/param norm = 2.1627e-01, time/batch = 16.4890s	
9486/22950 (epoch 20.667), train_loss = 1.07629036, grad/param norm = 2.0445e-01, time/batch = 15.6371s	
9487/22950 (epoch 20.669), train_loss = 1.04994022, grad/param norm = 2.0894e-01, time/batch = 15.5582s	
9488/22950 (epoch 20.671), train_loss = 1.07067836, grad/param norm = 2.0501e-01, time/batch = 15.9545s	
9489/22950 (epoch 20.673), train_loss = 1.00613383, grad/param norm = 2.0094e-01, time/batch = 16.2809s	
9490/22950 (epoch 20.675), train_loss = 1.04716981, grad/param norm = 2.2446e-01, time/batch = 15.7170s	
9491/22950 (epoch 20.678), train_loss = 1.06858691, grad/param norm = 2.0841e-01, time/batch = 16.9642s	
9492/22950 (epoch 20.680), train_loss = 1.05195625, grad/param norm = 1.9846e-01, time/batch = 16.6572s	
9493/22950 (epoch 20.682), train_loss = 1.06334613, grad/param norm = 2.2831e-01, time/batch = 15.8113s	
9494/22950 (epoch 20.684), train_loss = 1.18792972, grad/param norm = 2.5972e-01, time/batch = 15.6414s	
9495/22950 (epoch 20.686), train_loss = 1.13229396, grad/param norm = 2.0856e-01, time/batch = 16.0428s	
9496/22950 (epoch 20.688), train_loss = 1.09589804, grad/param norm = 2.1879e-01, time/batch = 16.1215s	
9497/22950 (epoch 20.691), train_loss = 1.04374555, grad/param norm = 2.0297e-01, time/batch = 16.2775s	
9498/22950 (epoch 20.693), train_loss = 0.98671551, grad/param norm = 2.2195e-01, time/batch = 16.5267s	
9499/22950 (epoch 20.695), train_loss = 1.16207781, grad/param norm = 2.2995e-01, time/batch = 16.6942s	
9500/22950 (epoch 20.697), train_loss = 1.10876058, grad/param norm = 2.1850e-01, time/batch = 16.3442s	
9501/22950 (epoch 20.699), train_loss = 1.12082218, grad/param norm = 2.1605e-01, time/batch = 15.8864s	
9502/22950 (epoch 20.702), train_loss = 1.13004465, grad/param norm = 2.2396e-01, time/batch = 16.2836s	
9503/22950 (epoch 20.704), train_loss = 1.14172256, grad/param norm = 2.1405e-01, time/batch = 16.7034s	
9504/22950 (epoch 20.706), train_loss = 1.14614318, grad/param norm = 2.3434e-01, time/batch = 16.2918s	
9505/22950 (epoch 20.708), train_loss = 0.95218233, grad/param norm = 2.0144e-01, time/batch = 16.2205s	
9506/22950 (epoch 20.710), train_loss = 1.08984315, grad/param norm = 2.1619e-01, time/batch = 16.6853s	
9507/22950 (epoch 20.712), train_loss = 1.18356295, grad/param norm = 2.2311e-01, time/batch = 16.2155s	
9508/22950 (epoch 20.715), train_loss = 1.08485817, grad/param norm = 2.2510e-01, time/batch = 16.1218s	
9509/22950 (epoch 20.717), train_loss = 1.06706369, grad/param norm = 2.0699e-01, time/batch = 16.1355s	
9510/22950 (epoch 20.719), train_loss = 1.02880014, grad/param norm = 2.2594e-01, time/batch = 16.5139s	
9511/22950 (epoch 20.721), train_loss = 1.10745575, grad/param norm = 2.1485e-01, time/batch = 16.3731s	
9512/22950 (epoch 20.723), train_loss = 1.01879155, grad/param norm = 2.0334e-01, time/batch = 16.1355s	
9513/22950 (epoch 20.725), train_loss = 1.12980733, grad/param norm = 2.5141e-01, time/batch = 16.2139s	
9514/22950 (epoch 20.728), train_loss = 1.05287282, grad/param norm = 2.6040e-01, time/batch = 15.7830s	
9515/22950 (epoch 20.730), train_loss = 1.03599453, grad/param norm = 2.1071e-01, time/batch = 16.3309s	
9516/22950 (epoch 20.732), train_loss = 1.11795680, grad/param norm = 2.2327e-01, time/batch = 15.7291s	
9517/22950 (epoch 20.734), train_loss = 1.06629751, grad/param norm = 2.1693e-01, time/batch = 16.2786s	
9518/22950 (epoch 20.736), train_loss = 1.05788217, grad/param norm = 2.0000e-01, time/batch = 15.8901s	
9519/22950 (epoch 20.739), train_loss = 1.14764945, grad/param norm = 2.3059e-01, time/batch = 15.8903s	
9520/22950 (epoch 20.741), train_loss = 1.15528968, grad/param norm = 2.1959e-01, time/batch = 15.9709s	
9521/22950 (epoch 20.743), train_loss = 1.21210576, grad/param norm = 2.2143e-01, time/batch = 17.0403s	
9522/22950 (epoch 20.745), train_loss = 1.32754739, grad/param norm = 2.5345e-01, time/batch = 16.4270s	
9523/22950 (epoch 20.747), train_loss = 1.08137964, grad/param norm = 2.1015e-01, time/batch = 16.1936s	
9524/22950 (epoch 20.749), train_loss = 1.00013781, grad/param norm = 2.4393e-01, time/batch = 21.3424s	
9525/22950 (epoch 20.752), train_loss = 1.25985600, grad/param norm = 2.3824e-01, time/batch = 25.3223s	
9526/22950 (epoch 20.754), train_loss = 1.14906207, grad/param norm = 2.3831e-01, time/batch = 16.4363s	
9527/22950 (epoch 20.756), train_loss = 0.98845285, grad/param norm = 2.0765e-01, time/batch = 16.5737s	
9528/22950 (epoch 20.758), train_loss = 1.04397021, grad/param norm = 2.0847e-01, time/batch = 16.2771s	
9529/22950 (epoch 20.760), train_loss = 1.12037892, grad/param norm = 2.2482e-01, time/batch = 16.2044s	
9530/22950 (epoch 20.763), train_loss = 1.14193193, grad/param norm = 2.2168e-01, time/batch = 16.1235s	
9531/22950 (epoch 20.765), train_loss = 1.11183039, grad/param norm = 2.2960e-01, time/batch = 16.6914s	
9532/22950 (epoch 20.767), train_loss = 1.25854248, grad/param norm = 2.3103e-01, time/batch = 15.9601s	
9533/22950 (epoch 20.769), train_loss = 1.08997138, grad/param norm = 2.1029e-01, time/batch = 15.4664s	
9534/22950 (epoch 20.771), train_loss = 0.94403008, grad/param norm = 2.0617e-01, time/batch = 15.7901s	
9535/22950 (epoch 20.773), train_loss = 0.81804927, grad/param norm = 1.9003e-01, time/batch = 16.3636s	
9536/22950 (epoch 20.776), train_loss = 0.99109269, grad/param norm = 1.9416e-01, time/batch = 16.2251s	
9537/22950 (epoch 20.778), train_loss = 0.96804526, grad/param norm = 1.9391e-01, time/batch = 16.4584s	
9538/22950 (epoch 20.780), train_loss = 1.06237244, grad/param norm = 1.9345e-01, time/batch = 16.4130s	
9539/22950 (epoch 20.782), train_loss = 1.07579326, grad/param norm = 2.1317e-01, time/batch = 15.8677s	
9540/22950 (epoch 20.784), train_loss = 1.03082227, grad/param norm = 2.2913e-01, time/batch = 16.3187s	
9541/22950 (epoch 20.786), train_loss = 1.11333436, grad/param norm = 2.1116e-01, time/batch = 15.8869s	
9542/22950 (epoch 20.789), train_loss = 0.92616263, grad/param norm = 2.0198e-01, time/batch = 16.9576s	
9543/22950 (epoch 20.791), train_loss = 0.96758327, grad/param norm = 2.3202e-01, time/batch = 16.0203s	
9544/22950 (epoch 20.793), train_loss = 1.22322110, grad/param norm = 2.2770e-01, time/batch = 16.0436s	
9545/22950 (epoch 20.795), train_loss = 1.01603829, grad/param norm = 1.9104e-01, time/batch = 16.2047s	
9546/22950 (epoch 20.797), train_loss = 1.21241008, grad/param norm = 2.2850e-01, time/batch = 17.8591s	
9547/22950 (epoch 20.800), train_loss = 0.98970321, grad/param norm = 1.9891e-01, time/batch = 19.7063s	
9548/22950 (epoch 20.802), train_loss = 0.99454872, grad/param norm = 2.1463e-01, time/batch = 18.1195s	
9549/22950 (epoch 20.804), train_loss = 1.06662721, grad/param norm = 2.1364e-01, time/batch = 19.4449s	
9550/22950 (epoch 20.806), train_loss = 0.96648608, grad/param norm = 2.1425e-01, time/batch = 16.1521s	
9551/22950 (epoch 20.808), train_loss = 1.04931981, grad/param norm = 2.0895e-01, time/batch = 17.2712s	
9552/22950 (epoch 20.810), train_loss = 1.02289747, grad/param norm = 2.1629e-01, time/batch = 17.2625s	
9553/22950 (epoch 20.813), train_loss = 0.88437317, grad/param norm = 2.0957e-01, time/batch = 20.0448s	
9554/22950 (epoch 20.815), train_loss = 0.92411450, grad/param norm = 2.0440e-01, time/batch = 17.3642s	
9555/22950 (epoch 20.817), train_loss = 0.93158190, grad/param norm = 1.8624e-01, time/batch = 17.5813s	
9556/22950 (epoch 20.819), train_loss = 1.04988172, grad/param norm = 2.1168e-01, time/batch = 15.9339s	
9557/22950 (epoch 20.821), train_loss = 1.00304710, grad/param norm = 2.1831e-01, time/batch = 18.1204s	
9558/22950 (epoch 20.824), train_loss = 1.05900365, grad/param norm = 2.3449e-01, time/batch = 19.1328s	
9559/22950 (epoch 20.826), train_loss = 1.17917846, grad/param norm = 2.4051e-01, time/batch = 16.4253s	
9560/22950 (epoch 20.828), train_loss = 1.04867944, grad/param norm = 2.3008e-01, time/batch = 16.6908s	
9561/22950 (epoch 20.830), train_loss = 1.02625834, grad/param norm = 1.9658e-01, time/batch = 16.3340s	
9562/22950 (epoch 20.832), train_loss = 1.06687135, grad/param norm = 2.1056e-01, time/batch = 15.9054s	
9563/22950 (epoch 20.834), train_loss = 0.89618788, grad/param norm = 2.0536e-01, time/batch = 16.3557s	
9564/22950 (epoch 20.837), train_loss = 1.05469011, grad/param norm = 2.0809e-01, time/batch = 17.6866s	
9565/22950 (epoch 20.839), train_loss = 0.90334648, grad/param norm = 1.9520e-01, time/batch = 18.6995s	
9566/22950 (epoch 20.841), train_loss = 0.98232278, grad/param norm = 1.8476e-01, time/batch = 16.4765s	
9567/22950 (epoch 20.843), train_loss = 1.00016161, grad/param norm = 2.1346e-01, time/batch = 20.2080s	
9568/22950 (epoch 20.845), train_loss = 1.08143246, grad/param norm = 2.2682e-01, time/batch = 19.4697s	
9569/22950 (epoch 20.847), train_loss = 1.11330463, grad/param norm = 2.1523e-01, time/batch = 16.8631s	
9570/22950 (epoch 20.850), train_loss = 1.09978662, grad/param norm = 2.2288e-01, time/batch = 20.1253s	
9571/22950 (epoch 20.852), train_loss = 1.10158546, grad/param norm = 2.1767e-01, time/batch = 16.1273s	
9572/22950 (epoch 20.854), train_loss = 1.02226474, grad/param norm = 2.0828e-01, time/batch = 17.0948s	
9573/22950 (epoch 20.856), train_loss = 1.19765121, grad/param norm = 2.2131e-01, time/batch = 15.9084s	
9574/22950 (epoch 20.858), train_loss = 1.10266523, grad/param norm = 2.0319e-01, time/batch = 19.1292s	
9575/22950 (epoch 20.861), train_loss = 1.14004446, grad/param norm = 2.2872e-01, time/batch = 19.7107s	
9576/22950 (epoch 20.863), train_loss = 1.17905068, grad/param norm = 2.3187e-01, time/batch = 17.6865s	
9577/22950 (epoch 20.865), train_loss = 1.22241370, grad/param norm = 2.3880e-01, time/batch = 18.6229s	
9578/22950 (epoch 20.867), train_loss = 1.09271174, grad/param norm = 2.2225e-01, time/batch = 17.7967s	
9579/22950 (epoch 20.869), train_loss = 1.22423615, grad/param norm = 2.3728e-01, time/batch = 16.1623s	
9580/22950 (epoch 20.871), train_loss = 1.09408446, grad/param norm = 2.1459e-01, time/batch = 16.8135s	
9581/22950 (epoch 20.874), train_loss = 1.06671045, grad/param norm = 1.9810e-01, time/batch = 16.5548s	
9582/22950 (epoch 20.876), train_loss = 1.12790614, grad/param norm = 2.3185e-01, time/batch = 15.6578s	
9583/22950 (epoch 20.878), train_loss = 1.01291523, grad/param norm = 2.2816e-01, time/batch = 16.4174s	
9584/22950 (epoch 20.880), train_loss = 1.22798552, grad/param norm = 2.3756e-01, time/batch = 19.1223s	
9585/22950 (epoch 20.882), train_loss = 0.95849889, grad/param norm = 1.9958e-01, time/batch = 18.8631s	
9586/22950 (epoch 20.885), train_loss = 1.10513507, grad/param norm = 2.2441e-01, time/batch = 18.7069s	
9587/22950 (epoch 20.887), train_loss = 1.08071580, grad/param norm = 2.1119e-01, time/batch = 18.9601s	
9588/22950 (epoch 20.889), train_loss = 1.10688750, grad/param norm = 2.2367e-01, time/batch = 17.1263s	
9589/22950 (epoch 20.891), train_loss = 1.00345838, grad/param norm = 2.2199e-01, time/batch = 18.5159s	
9590/22950 (epoch 20.893), train_loss = 1.11530101, grad/param norm = 2.0305e-01, time/batch = 16.5125s	
9591/22950 (epoch 20.895), train_loss = 1.24404878, grad/param norm = 2.5987e-01, time/batch = 19.2631s	
9592/22950 (epoch 20.898), train_loss = 1.04649291, grad/param norm = 2.0674e-01, time/batch = 19.0868s	
9593/22950 (epoch 20.900), train_loss = 1.02885816, grad/param norm = 2.0025e-01, time/batch = 17.4257s	
9594/22950 (epoch 20.902), train_loss = 1.10599899, grad/param norm = 2.1307e-01, time/batch = 16.1303s	
9595/22950 (epoch 20.904), train_loss = 1.09454045, grad/param norm = 2.2590e-01, time/batch = 16.7277s	
9596/22950 (epoch 20.906), train_loss = 1.11780106, grad/param norm = 2.2881e-01, time/batch = 16.6400s	
9597/22950 (epoch 20.908), train_loss = 0.95011588, grad/param norm = 1.8945e-01, time/batch = 17.2686s	
9598/22950 (epoch 20.911), train_loss = 0.92561782, grad/param norm = 1.8746e-01, time/batch = 18.1280s	
9599/22950 (epoch 20.913), train_loss = 1.00829272, grad/param norm = 2.0771e-01, time/batch = 17.2092s	
9600/22950 (epoch 20.915), train_loss = 1.17380472, grad/param norm = 2.1744e-01, time/batch = 16.6047s	
9601/22950 (epoch 20.917), train_loss = 0.94139591, grad/param norm = 1.9678e-01, time/batch = 17.6978s	
9602/22950 (epoch 20.919), train_loss = 1.04337222, grad/param norm = 2.2194e-01, time/batch = 19.3750s	
9603/22950 (epoch 20.922), train_loss = 1.07533616, grad/param norm = 2.1679e-01, time/batch = 17.7125s	
9604/22950 (epoch 20.924), train_loss = 1.10752038, grad/param norm = 2.1974e-01, time/batch = 18.4680s	
9605/22950 (epoch 20.926), train_loss = 0.91400045, grad/param norm = 2.0740e-01, time/batch = 20.2040s	
9606/22950 (epoch 20.928), train_loss = 0.93362415, grad/param norm = 2.0582e-01, time/batch = 18.6190s	
9607/22950 (epoch 20.930), train_loss = 0.93359130, grad/param norm = 2.1580e-01, time/batch = 17.2528s	
9608/22950 (epoch 20.932), train_loss = 0.89147867, grad/param norm = 1.9550e-01, time/batch = 16.3428s	
9609/22950 (epoch 20.935), train_loss = 1.03976724, grad/param norm = 2.0341e-01, time/batch = 17.6128s	
9610/22950 (epoch 20.937), train_loss = 1.06769431, grad/param norm = 2.2684e-01, time/batch = 17.7648s	
9611/22950 (epoch 20.939), train_loss = 0.97916669, grad/param norm = 2.1075e-01, time/batch = 19.4560s	
9612/22950 (epoch 20.941), train_loss = 0.97323764, grad/param norm = 2.0359e-01, time/batch = 20.1087s	
9613/22950 (epoch 20.943), train_loss = 1.08945250, grad/param norm = 2.3839e-01, time/batch = 16.8232s	
9614/22950 (epoch 20.946), train_loss = 0.90916707, grad/param norm = 2.0341e-01, time/batch = 18.1845s	
9615/22950 (epoch 20.948), train_loss = 1.12532853, grad/param norm = 2.1004e-01, time/batch = 20.2848s	
9616/22950 (epoch 20.950), train_loss = 1.08182842, grad/param norm = 2.3924e-01, time/batch = 16.8557s	
9617/22950 (epoch 20.952), train_loss = 1.09486152, grad/param norm = 2.1827e-01, time/batch = 20.2615s	
9618/22950 (epoch 20.954), train_loss = 1.07178929, grad/param norm = 1.9743e-01, time/batch = 20.9532s	
9619/22950 (epoch 20.956), train_loss = 0.97637867, grad/param norm = 2.0708e-01, time/batch = 19.1035s	
9620/22950 (epoch 20.959), train_loss = 0.95127202, grad/param norm = 1.9164e-01, time/batch = 19.2899s	
9621/22950 (epoch 20.961), train_loss = 1.06898449, grad/param norm = 2.2709e-01, time/batch = 20.5342s	
9622/22950 (epoch 20.963), train_loss = 1.10036734, grad/param norm = 2.4278e-01, time/batch = 16.1032s	
9623/22950 (epoch 20.965), train_loss = 1.19887515, grad/param norm = 2.2098e-01, time/batch = 15.9540s	
9624/22950 (epoch 20.967), train_loss = 1.05290692, grad/param norm = 2.3605e-01, time/batch = 16.4374s	
9625/22950 (epoch 20.969), train_loss = 0.96143508, grad/param norm = 2.1937e-01, time/batch = 16.0513s	
9626/22950 (epoch 20.972), train_loss = 1.03546951, grad/param norm = 2.0603e-01, time/batch = 16.8237s	
9627/22950 (epoch 20.974), train_loss = 1.01218263, grad/param norm = 2.1519e-01, time/batch = 16.2895s	
9628/22950 (epoch 20.976), train_loss = 0.98915543, grad/param norm = 1.9784e-01, time/batch = 16.3496s	
9629/22950 (epoch 20.978), train_loss = 1.02622950, grad/param norm = 2.3566e-01, time/batch = 16.5050s	
9630/22950 (epoch 20.980), train_loss = 1.03081489, grad/param norm = 2.0502e-01, time/batch = 16.2106s	
9631/22950 (epoch 20.983), train_loss = 1.07915332, grad/param norm = 2.0849e-01, time/batch = 15.8912s	
9632/22950 (epoch 20.985), train_loss = 0.92915652, grad/param norm = 2.0416e-01, time/batch = 16.0412s	
9633/22950 (epoch 20.987), train_loss = 0.97551970, grad/param norm = 1.8674e-01, time/batch = 16.2641s	
9634/22950 (epoch 20.989), train_loss = 1.05220850, grad/param norm = 2.1048e-01, time/batch = 15.8014s	
9635/22950 (epoch 20.991), train_loss = 0.88732047, grad/param norm = 1.9368e-01, time/batch = 16.0281s	
9636/22950 (epoch 20.993), train_loss = 1.08007978, grad/param norm = 2.1701e-01, time/batch = 15.5706s	
9637/22950 (epoch 20.996), train_loss = 1.08159922, grad/param norm = 2.1088e-01, time/batch = 16.2075s	
9638/22950 (epoch 20.998), train_loss = 0.95306593, grad/param norm = 1.9666e-01, time/batch = 16.1161s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
9639/22950 (epoch 21.000), train_loss = 0.88670357, grad/param norm = 1.8885e-01, time/batch = 16.3321s	
9640/22950 (epoch 21.002), train_loss = 1.21153746, grad/param norm = 2.1887e-01, time/batch = 16.0048s	
9641/22950 (epoch 21.004), train_loss = 1.06754261, grad/param norm = 2.0348e-01, time/batch = 16.2616s	
9642/22950 (epoch 21.007), train_loss = 1.05730394, grad/param norm = 2.0449e-01, time/batch = 16.2539s	
9643/22950 (epoch 21.009), train_loss = 1.20445911, grad/param norm = 2.4367e-01, time/batch = 16.5674s	
9644/22950 (epoch 21.011), train_loss = 0.92043348, grad/param norm = 2.0326e-01, time/batch = 16.3458s	
9645/22950 (epoch 21.013), train_loss = 1.07267916, grad/param norm = 2.2938e-01, time/batch = 15.8827s	
9646/22950 (epoch 21.015), train_loss = 1.10135232, grad/param norm = 2.2475e-01, time/batch = 16.1040s	
9647/22950 (epoch 21.017), train_loss = 1.09192594, grad/param norm = 2.1131e-01, time/batch = 15.9602s	
9648/22950 (epoch 21.020), train_loss = 1.05977430, grad/param norm = 1.9881e-01, time/batch = 16.3387s	
9649/22950 (epoch 21.022), train_loss = 0.91530292, grad/param norm = 1.9793e-01, time/batch = 15.8830s	
9650/22950 (epoch 21.024), train_loss = 1.02596631, grad/param norm = 2.3090e-01, time/batch = 15.8826s	
9651/22950 (epoch 21.026), train_loss = 1.11649243, grad/param norm = 2.4757e-01, time/batch = 16.1255s	
9652/22950 (epoch 21.028), train_loss = 1.16122779, grad/param norm = 2.0509e-01, time/batch = 16.7523s	
9653/22950 (epoch 21.031), train_loss = 1.02919860, grad/param norm = 2.0685e-01, time/batch = 16.2807s	
9654/22950 (epoch 21.033), train_loss = 1.18539418, grad/param norm = 2.3517e-01, time/batch = 15.9741s	
9655/22950 (epoch 21.035), train_loss = 1.05257338, grad/param norm = 2.0541e-01, time/batch = 16.1189s	
9656/22950 (epoch 21.037), train_loss = 1.06993079, grad/param norm = 2.3675e-01, time/batch = 16.1298s	
9657/22950 (epoch 21.039), train_loss = 1.02525143, grad/param norm = 2.2509e-01, time/batch = 15.9732s	
9658/22950 (epoch 21.041), train_loss = 1.01049881, grad/param norm = 2.1436e-01, time/batch = 15.9673s	
9659/22950 (epoch 21.044), train_loss = 1.10062791, grad/param norm = 2.4407e-01, time/batch = 16.0494s	
9660/22950 (epoch 21.046), train_loss = 1.03508942, grad/param norm = 1.9936e-01, time/batch = 16.2128s	
9661/22950 (epoch 21.048), train_loss = 1.06835450, grad/param norm = 2.0262e-01, time/batch = 16.1350s	
9662/22950 (epoch 21.050), train_loss = 1.03624366, grad/param norm = 2.3544e-01, time/batch = 15.8924s	
9663/22950 (epoch 21.052), train_loss = 1.07926938, grad/param norm = 2.1460e-01, time/batch = 16.7200s	
9664/22950 (epoch 21.054), train_loss = 1.23241118, grad/param norm = 2.3139e-01, time/batch = 16.4501s	
9665/22950 (epoch 21.057), train_loss = 1.18705211, grad/param norm = 2.3517e-01, time/batch = 16.0565s	
9666/22950 (epoch 21.059), train_loss = 1.08614499, grad/param norm = 2.0462e-01, time/batch = 16.0463s	
9667/22950 (epoch 21.061), train_loss = 0.97901198, grad/param norm = 2.1018e-01, time/batch = 16.2020s	
9668/22950 (epoch 21.063), train_loss = 1.12499647, grad/param norm = 2.2722e-01, time/batch = 16.6644s	
9669/22950 (epoch 21.065), train_loss = 0.89741209, grad/param norm = 1.9047e-01, time/batch = 16.0474s	
9670/22950 (epoch 21.068), train_loss = 1.10876268, grad/param norm = 2.2846e-01, time/batch = 16.1878s	
9671/22950 (epoch 21.070), train_loss = 0.94002045, grad/param norm = 1.9075e-01, time/batch = 15.9800s	
9672/22950 (epoch 21.072), train_loss = 1.10777423, grad/param norm = 2.1333e-01, time/batch = 15.9039s	
9673/22950 (epoch 21.074), train_loss = 1.07386748, grad/param norm = 2.2147e-01, time/batch = 15.8891s	
9674/22950 (epoch 21.076), train_loss = 1.08273697, grad/param norm = 2.0698e-01, time/batch = 16.3624s	
9675/22950 (epoch 21.078), train_loss = 1.12403370, grad/param norm = 2.0795e-01, time/batch = 15.9012s	
9676/22950 (epoch 21.081), train_loss = 1.15986198, grad/param norm = 2.3034e-01, time/batch = 15.9692s	
9677/22950 (epoch 21.083), train_loss = 1.04201195, grad/param norm = 2.3020e-01, time/batch = 15.9634s	
9678/22950 (epoch 21.085), train_loss = 0.93767357, grad/param norm = 2.2194e-01, time/batch = 15.7253s	
9679/22950 (epoch 21.087), train_loss = 0.95222880, grad/param norm = 2.0565e-01, time/batch = 15.8045s	
9680/22950 (epoch 21.089), train_loss = 1.07016105, grad/param norm = 2.0007e-01, time/batch = 15.8858s	
9681/22950 (epoch 21.092), train_loss = 1.01826123, grad/param norm = 2.6840e-01, time/batch = 16.5834s	
9682/22950 (epoch 21.094), train_loss = 0.97983918, grad/param norm = 2.1861e-01, time/batch = 16.7424s	
9683/22950 (epoch 21.096), train_loss = 1.19260156, grad/param norm = 2.3757e-01, time/batch = 16.4887s	
9684/22950 (epoch 21.098), train_loss = 1.10051325, grad/param norm = 2.0426e-01, time/batch = 16.1320s	
9685/22950 (epoch 21.100), train_loss = 1.02286944, grad/param norm = 2.1282e-01, time/batch = 16.6636s	
9686/22950 (epoch 21.102), train_loss = 1.04414151, grad/param norm = 2.1637e-01, time/batch = 16.0566s	
9687/22950 (epoch 21.105), train_loss = 0.91396821, grad/param norm = 1.8193e-01, time/batch = 16.4383s	
9688/22950 (epoch 21.107), train_loss = 0.99652377, grad/param norm = 2.1298e-01, time/batch = 16.1397s	
9689/22950 (epoch 21.109), train_loss = 0.99436084, grad/param norm = 2.2979e-01, time/batch = 15.9604s	
9690/22950 (epoch 21.111), train_loss = 0.90463523, grad/param norm = 2.2449e-01, time/batch = 16.0496s	
9691/22950 (epoch 21.113), train_loss = 1.06675115, grad/param norm = 2.2794e-01, time/batch = 16.7784s	
9692/22950 (epoch 21.115), train_loss = 1.06007690, grad/param norm = 2.0496e-01, time/batch = 16.0462s	
9693/22950 (epoch 21.118), train_loss = 1.19616992, grad/param norm = 2.2548e-01, time/batch = 15.6412s	
9694/22950 (epoch 21.120), train_loss = 0.96747287, grad/param norm = 2.1996e-01, time/batch = 15.8923s	
9695/22950 (epoch 21.122), train_loss = 1.14914745, grad/param norm = 2.2744e-01, time/batch = 16.0491s	
9696/22950 (epoch 21.124), train_loss = 0.91866432, grad/param norm = 1.8432e-01, time/batch = 16.4390s	
9697/22950 (epoch 21.126), train_loss = 1.03146108, grad/param norm = 2.0065e-01, time/batch = 16.2148s	
9698/22950 (epoch 21.129), train_loss = 0.92140155, grad/param norm = 1.8158e-01, time/batch = 15.8086s	
9699/22950 (epoch 21.131), train_loss = 1.00931753, grad/param norm = 2.0282e-01, time/batch = 15.7269s	
9700/22950 (epoch 21.133), train_loss = 1.09575872, grad/param norm = 2.1968e-01, time/batch = 16.2634s	
9701/22950 (epoch 21.135), train_loss = 1.05033641, grad/param norm = 2.0675e-01, time/batch = 16.0356s	
9702/22950 (epoch 21.137), train_loss = 1.17204326, grad/param norm = 2.4326e-01, time/batch = 15.7293s	
9703/22950 (epoch 21.139), train_loss = 0.94762531, grad/param norm = 2.2696e-01, time/batch = 16.1487s	
9704/22950 (epoch 21.142), train_loss = 0.96453345, grad/param norm = 2.0461e-01, time/batch = 16.7369s	
9705/22950 (epoch 21.144), train_loss = 1.00168117, grad/param norm = 2.0318e-01, time/batch = 15.9687s	
9706/22950 (epoch 21.146), train_loss = 0.99550263, grad/param norm = 2.1804e-01, time/batch = 16.2843s	
9707/22950 (epoch 21.148), train_loss = 0.98910258, grad/param norm = 1.9486e-01, time/batch = 16.2845s	
9708/22950 (epoch 21.150), train_loss = 1.07129859, grad/param norm = 2.2290e-01, time/batch = 15.9644s	
9709/22950 (epoch 21.153), train_loss = 0.99107808, grad/param norm = 2.1088e-01, time/batch = 15.7172s	
9710/22950 (epoch 21.155), train_loss = 0.99510424, grad/param norm = 1.9714e-01, time/batch = 15.9711s	
9711/22950 (epoch 21.157), train_loss = 1.02169809, grad/param norm = 2.0303e-01, time/batch = 16.8297s	
9712/22950 (epoch 21.159), train_loss = 0.95812658, grad/param norm = 2.0233e-01, time/batch = 16.0604s	
9713/22950 (epoch 21.161), train_loss = 0.98861752, grad/param norm = 1.9139e-01, time/batch = 16.0397s	
9714/22950 (epoch 21.163), train_loss = 0.91549260, grad/param norm = 2.1452e-01, time/batch = 16.4067s	
9715/22950 (epoch 21.166), train_loss = 1.17546344, grad/param norm = 3.2166e-01, time/batch = 16.4072s	
9716/22950 (epoch 21.168), train_loss = 1.12706036, grad/param norm = 2.6726e-01, time/batch = 15.7963s	
9717/22950 (epoch 21.170), train_loss = 1.04586028, grad/param norm = 2.3184e-01, time/batch = 15.6537s	
9718/22950 (epoch 21.172), train_loss = 1.07288322, grad/param norm = 2.0589e-01, time/batch = 16.1207s	
9719/22950 (epoch 21.174), train_loss = 1.11217150, grad/param norm = 2.2718e-01, time/batch = 15.8928s	
9720/22950 (epoch 21.176), train_loss = 1.13044095, grad/param norm = 2.1133e-01, time/batch = 16.2240s	
9721/22950 (epoch 21.179), train_loss = 1.10281756, grad/param norm = 2.3225e-01, time/batch = 16.2044s	
9722/22950 (epoch 21.181), train_loss = 1.29160926, grad/param norm = 2.2224e-01, time/batch = 16.5020s	
9723/22950 (epoch 21.183), train_loss = 1.13338215, grad/param norm = 2.2203e-01, time/batch = 16.2678s	
9724/22950 (epoch 21.185), train_loss = 1.08420868, grad/param norm = 2.1725e-01, time/batch = 16.2784s	
9725/22950 (epoch 21.187), train_loss = 0.97708314, grad/param norm = 2.3375e-01, time/batch = 15.9603s	
9726/22950 (epoch 21.190), train_loss = 0.88030609, grad/param norm = 1.9624e-01, time/batch = 15.7999s	
9727/22950 (epoch 21.192), train_loss = 0.87902486, grad/param norm = 1.8551e-01, time/batch = 15.5632s	
9728/22950 (epoch 21.194), train_loss = 1.01463775, grad/param norm = 2.2795e-01, time/batch = 15.5567s	
9729/22950 (epoch 21.196), train_loss = 0.85259884, grad/param norm = 2.1208e-01, time/batch = 15.6420s	
9730/22950 (epoch 21.198), train_loss = 1.11978256, grad/param norm = 2.2211e-01, time/batch = 15.8866s	
9731/22950 (epoch 21.200), train_loss = 0.96114278, grad/param norm = 1.8774e-01, time/batch = 15.6494s	
9732/22950 (epoch 21.203), train_loss = 0.90145215, grad/param norm = 1.8746e-01, time/batch = 15.7865s	
9733/22950 (epoch 21.205), train_loss = 0.99608079, grad/param norm = 1.9745e-01, time/batch = 16.0279s	
9734/22950 (epoch 21.207), train_loss = 1.01909288, grad/param norm = 2.0308e-01, time/batch = 16.0156s	
9735/22950 (epoch 21.209), train_loss = 1.04904633, grad/param norm = 2.2850e-01, time/batch = 16.8739s	
9736/22950 (epoch 21.211), train_loss = 0.85533098, grad/param norm = 1.9697e-01, time/batch = 16.1594s	
9737/22950 (epoch 21.214), train_loss = 0.99764148, grad/param norm = 2.0245e-01, time/batch = 29.7230s	
9738/22950 (epoch 21.216), train_loss = 1.12618116, grad/param norm = 2.2531e-01, time/batch = 15.9115s	
9739/22950 (epoch 21.218), train_loss = 1.03321815, grad/param norm = 2.0913e-01, time/batch = 15.8442s	
9740/22950 (epoch 21.220), train_loss = 1.12409914, grad/param norm = 2.0858e-01, time/batch = 16.0893s	
9741/22950 (epoch 21.222), train_loss = 1.15217292, grad/param norm = 2.3188e-01, time/batch = 16.1688s	
9742/22950 (epoch 21.224), train_loss = 1.02542886, grad/param norm = 2.1487e-01, time/batch = 15.6058s	
9743/22950 (epoch 21.227), train_loss = 1.11612850, grad/param norm = 1.9217e-01, time/batch = 15.5244s	
9744/22950 (epoch 21.229), train_loss = 1.11985524, grad/param norm = 2.1866e-01, time/batch = 16.0920s	
9745/22950 (epoch 21.231), train_loss = 0.91629562, grad/param norm = 2.0444e-01, time/batch = 15.5638s	
9746/22950 (epoch 21.233), train_loss = 0.98516759, grad/param norm = 2.1300e-01, time/batch = 14.9201s	
9747/22950 (epoch 21.235), train_loss = 1.17916707, grad/param norm = 2.1760e-01, time/batch = 15.7503s	
9748/22950 (epoch 21.237), train_loss = 0.94672945, grad/param norm = 1.9369e-01, time/batch = 14.9224s	
9749/22950 (epoch 21.240), train_loss = 1.03908621, grad/param norm = 2.2449e-01, time/batch = 14.7575s	
9750/22950 (epoch 21.242), train_loss = 1.14808302, grad/param norm = 2.0253e-01, time/batch = 14.9971s	
9751/22950 (epoch 21.244), train_loss = 1.17171824, grad/param norm = 2.1720e-01, time/batch = 15.3128s	
9752/22950 (epoch 21.246), train_loss = 1.15164543, grad/param norm = 2.0842e-01, time/batch = 15.0018s	
9753/22950 (epoch 21.248), train_loss = 1.09160936, grad/param norm = 2.3120e-01, time/batch = 15.1523s	
9754/22950 (epoch 21.251), train_loss = 0.97703942, grad/param norm = 2.0682e-01, time/batch = 15.3251s	
9755/22950 (epoch 21.253), train_loss = 0.99596264, grad/param norm = 2.2268e-01, time/batch = 16.0160s	
9756/22950 (epoch 21.255), train_loss = 1.07130463, grad/param norm = 2.3914e-01, time/batch = 15.4697s	
9757/22950 (epoch 21.257), train_loss = 1.14647895, grad/param norm = 2.0872e-01, time/batch = 15.4716s	
9758/22950 (epoch 21.259), train_loss = 0.90066424, grad/param norm = 1.9319e-01, time/batch = 16.1495s	
9759/22950 (epoch 21.261), train_loss = 0.98429280, grad/param norm = 2.1209e-01, time/batch = 16.4653s	
9760/22950 (epoch 21.264), train_loss = 0.93600480, grad/param norm = 1.9509e-01, time/batch = 15.6269s	
9761/22950 (epoch 21.266), train_loss = 1.07842838, grad/param norm = 2.1831e-01, time/batch = 16.3931s	
9762/22950 (epoch 21.268), train_loss = 1.02201595, grad/param norm = 2.0014e-01, time/batch = 15.7051s	
9763/22950 (epoch 21.270), train_loss = 1.02636297, grad/param norm = 1.9997e-01, time/batch = 15.3217s	
9764/22950 (epoch 21.272), train_loss = 1.10127549, grad/param norm = 2.1305e-01, time/batch = 16.8560s	
9765/22950 (epoch 21.275), train_loss = 0.97169063, grad/param norm = 2.0708e-01, time/batch = 19.7890s	
9766/22950 (epoch 21.277), train_loss = 0.88256841, grad/param norm = 1.8204e-01, time/batch = 17.7084s	
9767/22950 (epoch 21.279), train_loss = 0.95816017, grad/param norm = 2.2681e-01, time/batch = 17.2231s	
9768/22950 (epoch 21.281), train_loss = 0.99629435, grad/param norm = 2.1262e-01, time/batch = 17.4667s	
9769/22950 (epoch 21.283), train_loss = 0.88837413, grad/param norm = 1.7847e-01, time/batch = 19.0206s	
9770/22950 (epoch 21.285), train_loss = 1.04989672, grad/param norm = 2.0534e-01, time/batch = 17.2800s	
9771/22950 (epoch 21.288), train_loss = 1.10620404, grad/param norm = 2.1159e-01, time/batch = 17.4389s	
9772/22950 (epoch 21.290), train_loss = 0.99465508, grad/param norm = 2.0056e-01, time/batch = 20.0405s	
9773/22950 (epoch 21.292), train_loss = 1.12514163, grad/param norm = 2.0281e-01, time/batch = 16.4391s	
9774/22950 (epoch 21.294), train_loss = 1.01999173, grad/param norm = 1.9558e-01, time/batch = 17.5549s	
9775/22950 (epoch 21.296), train_loss = 0.82052666, grad/param norm = 1.7503e-01, time/batch = 16.5323s	
9776/22950 (epoch 21.298), train_loss = 1.05571277, grad/param norm = 2.1258e-01, time/batch = 17.2308s	
9777/22950 (epoch 21.301), train_loss = 1.05756422, grad/param norm = 2.1576e-01, time/batch = 17.8489s	
9778/22950 (epoch 21.303), train_loss = 1.05790791, grad/param norm = 2.0011e-01, time/batch = 18.8009s	
9779/22950 (epoch 21.305), train_loss = 1.05638642, grad/param norm = 2.3198e-01, time/batch = 16.7811s	
9780/22950 (epoch 21.307), train_loss = 1.13548044, grad/param norm = 2.1603e-01, time/batch = 17.1338s	
9781/22950 (epoch 21.309), train_loss = 0.96925402, grad/param norm = 1.8222e-01, time/batch = 16.5077s	
9782/22950 (epoch 21.312), train_loss = 1.03609132, grad/param norm = 2.0328e-01, time/batch = 19.2745s	
9783/22950 (epoch 21.314), train_loss = 1.03303482, grad/param norm = 1.9398e-01, time/batch = 19.5350s	
9784/22950 (epoch 21.316), train_loss = 1.03391131, grad/param norm = 2.2389e-01, time/batch = 19.3835s	
9785/22950 (epoch 21.318), train_loss = 0.87778755, grad/param norm = 1.8743e-01, time/batch = 16.4061s	
9786/22950 (epoch 21.320), train_loss = 0.96794855, grad/param norm = 1.9194e-01, time/batch = 16.2263s	
9787/22950 (epoch 21.322), train_loss = 0.99911156, grad/param norm = 2.0418e-01, time/batch = 16.0478s	
9788/22950 (epoch 21.325), train_loss = 0.81820694, grad/param norm = 1.8258e-01, time/batch = 16.7757s	
9789/22950 (epoch 21.327), train_loss = 0.85887033, grad/param norm = 1.9298e-01, time/batch = 18.7003s	
9790/22950 (epoch 21.329), train_loss = 0.97250161, grad/param norm = 2.0045e-01, time/batch = 16.6096s	
9791/22950 (epoch 21.331), train_loss = 0.89048288, grad/param norm = 1.9184e-01, time/batch = 18.1888s	
9792/22950 (epoch 21.333), train_loss = 1.00627151, grad/param norm = 2.0056e-01, time/batch = 18.6973s	
9793/22950 (epoch 21.336), train_loss = 1.00220857, grad/param norm = 2.0801e-01, time/batch = 17.1763s	
9794/22950 (epoch 21.338), train_loss = 1.00433001, grad/param norm = 1.9913e-01, time/batch = 17.6927s	
9795/22950 (epoch 21.340), train_loss = 1.02376213, grad/param norm = 2.1264e-01, time/batch = 17.7584s	
9796/22950 (epoch 21.342), train_loss = 1.12403484, grad/param norm = 2.1790e-01, time/batch = 16.0864s	
9797/22950 (epoch 21.344), train_loss = 0.99803704, grad/param norm = 2.0697e-01, time/batch = 18.7855s	
9798/22950 (epoch 21.346), train_loss = 1.10360752, grad/param norm = 2.4890e-01, time/batch = 19.7036s	
9799/22950 (epoch 21.349), train_loss = 1.03629685, grad/param norm = 2.3400e-01, time/batch = 20.1098s	
9800/22950 (epoch 21.351), train_loss = 1.04232457, grad/param norm = 2.0204e-01, time/batch = 19.5411s	
9801/22950 (epoch 21.353), train_loss = 1.11693456, grad/param norm = 2.5695e-01, time/batch = 20.3732s	
9802/22950 (epoch 21.355), train_loss = 1.15842256, grad/param norm = 2.5118e-01, time/batch = 18.7043s	
9803/22950 (epoch 21.357), train_loss = 1.03795792, grad/param norm = 2.3637e-01, time/batch = 18.1032s	
9804/22950 (epoch 21.359), train_loss = 1.06356292, grad/param norm = 2.3585e-01, time/batch = 16.6824s	
9805/22950 (epoch 21.362), train_loss = 1.05285879, grad/param norm = 2.2478e-01, time/batch = 18.1156s	
9806/22950 (epoch 21.364), train_loss = 1.02706979, grad/param norm = 2.3558e-01, time/batch = 18.7659s	
9807/22950 (epoch 21.366), train_loss = 0.98883929, grad/param norm = 2.0419e-01, time/batch = 20.6097s	
9808/22950 (epoch 21.368), train_loss = 1.10460131, grad/param norm = 2.5360e-01, time/batch = 16.7539s	
9809/22950 (epoch 21.370), train_loss = 1.00330930, grad/param norm = 2.1909e-01, time/batch = 16.4477s	
9810/22950 (epoch 21.373), train_loss = 0.90975615, grad/param norm = 2.0570e-01, time/batch = 16.5004s	
9811/22950 (epoch 21.375), train_loss = 1.12885204, grad/param norm = 2.2918e-01, time/batch = 19.4353s	
9812/22950 (epoch 21.377), train_loss = 0.93407978, grad/param norm = 2.0688e-01, time/batch = 19.9559s	
9813/22950 (epoch 21.379), train_loss = 1.06300750, grad/param norm = 2.4156e-01, time/batch = 20.2116s	
9814/22950 (epoch 21.381), train_loss = 0.90703326, grad/param norm = 2.0507e-01, time/batch = 17.3689s	
9815/22950 (epoch 21.383), train_loss = 1.00226861, grad/param norm = 2.1624e-01, time/batch = 18.5267s	
9816/22950 (epoch 21.386), train_loss = 0.96140283, grad/param norm = 2.1984e-01, time/batch = 20.1030s	
9817/22950 (epoch 21.388), train_loss = 1.03491466, grad/param norm = 2.2626e-01, time/batch = 18.9660s	
9818/22950 (epoch 21.390), train_loss = 0.92110795, grad/param norm = 2.1894e-01, time/batch = 20.7112s	
9819/22950 (epoch 21.392), train_loss = 0.97355579, grad/param norm = 2.0574e-01, time/batch = 20.0223s	
9820/22950 (epoch 21.394), train_loss = 0.95720522, grad/param norm = 1.9268e-01, time/batch = 18.6374s	
9821/22950 (epoch 21.397), train_loss = 1.16546162, grad/param norm = 2.0994e-01, time/batch = 21.0309s	
9822/22950 (epoch 21.399), train_loss = 1.16899403, grad/param norm = 2.3183e-01, time/batch = 19.8289s	
9823/22950 (epoch 21.401), train_loss = 1.21685034, grad/param norm = 2.4542e-01, time/batch = 19.0352s	
9824/22950 (epoch 21.403), train_loss = 0.99640715, grad/param norm = 2.3186e-01, time/batch = 17.6271s	
9825/22950 (epoch 21.405), train_loss = 1.15906455, grad/param norm = 2.5659e-01, time/batch = 17.1197s	
9826/22950 (epoch 21.407), train_loss = 1.20509285, grad/param norm = 2.1788e-01, time/batch = 18.9424s	
9827/22950 (epoch 21.410), train_loss = 0.96688815, grad/param norm = 1.9501e-01, time/batch = 16.0599s	
9828/22950 (epoch 21.412), train_loss = 1.02137753, grad/param norm = 2.2021e-01, time/batch = 16.5796s	
9829/22950 (epoch 21.414), train_loss = 1.13723157, grad/param norm = 2.2724e-01, time/batch = 15.8337s	
9830/22950 (epoch 21.416), train_loss = 1.07285039, grad/param norm = 2.6391e-01, time/batch = 17.9371s	
9831/22950 (epoch 21.418), train_loss = 1.04442137, grad/param norm = 2.2433e-01, time/batch = 17.0453s	
9832/22950 (epoch 21.420), train_loss = 1.10379062, grad/param norm = 2.4556e-01, time/batch = 17.2952s	
9833/22950 (epoch 21.423), train_loss = 0.96501645, grad/param norm = 1.9885e-01, time/batch = 20.1139s	
9834/22950 (epoch 21.425), train_loss = 1.02460770, grad/param norm = 2.0261e-01, time/batch = 19.6336s	
9835/22950 (epoch 21.427), train_loss = 1.02108542, grad/param norm = 2.1148e-01, time/batch = 16.8745s	
9836/22950 (epoch 21.429), train_loss = 1.00186124, grad/param norm = 1.9078e-01, time/batch = 17.6147s	
9837/22950 (epoch 21.431), train_loss = 1.07771551, grad/param norm = 2.2420e-01, time/batch = 18.5366s	
9838/22950 (epoch 21.434), train_loss = 1.03553518, grad/param norm = 2.1343e-01, time/batch = 18.9365s	
9839/22950 (epoch 21.436), train_loss = 1.14241504, grad/param norm = 2.2515e-01, time/batch = 17.0351s	
9840/22950 (epoch 21.438), train_loss = 1.07596352, grad/param norm = 2.1469e-01, time/batch = 18.5129s	
9841/22950 (epoch 21.440), train_loss = 1.14823265, grad/param norm = 2.2117e-01, time/batch = 19.4351s	
9842/22950 (epoch 21.442), train_loss = 1.20217036, grad/param norm = 2.3893e-01, time/batch = 17.2654s	
9843/22950 (epoch 21.444), train_loss = 1.10416622, grad/param norm = 2.3093e-01, time/batch = 18.6155s	
9844/22950 (epoch 21.447), train_loss = 1.21804726, grad/param norm = 2.3890e-01, time/batch = 19.5952s	
9845/22950 (epoch 21.449), train_loss = 0.94341327, grad/param norm = 1.9544e-01, time/batch = 16.7570s	
9846/22950 (epoch 21.451), train_loss = 1.06874058, grad/param norm = 2.1920e-01, time/batch = 16.7014s	
9847/22950 (epoch 21.453), train_loss = 1.07697777, grad/param norm = 2.0050e-01, time/batch = 16.7732s	
9848/22950 (epoch 21.455), train_loss = 0.99937720, grad/param norm = 2.0152e-01, time/batch = 18.1958s	
9849/22950 (epoch 21.458), train_loss = 1.12035631, grad/param norm = 2.1786e-01, time/batch = 16.4718s	
9850/22950 (epoch 21.460), train_loss = 1.09496005, grad/param norm = 2.1122e-01, time/batch = 16.0979s	
9851/22950 (epoch 21.462), train_loss = 1.05134970, grad/param norm = 2.3902e-01, time/batch = 17.7702s	
9852/22950 (epoch 21.464), train_loss = 0.99899153, grad/param norm = 2.0767e-01, time/batch = 18.0337s	
9853/22950 (epoch 21.466), train_loss = 1.10096372, grad/param norm = 2.3214e-01, time/batch = 16.9716s	
9854/22950 (epoch 21.468), train_loss = 1.17214074, grad/param norm = 2.4279e-01, time/batch = 18.9602s	
9855/22950 (epoch 21.471), train_loss = 1.10843039, grad/param norm = 2.5138e-01, time/batch = 18.3361s	
9856/22950 (epoch 21.473), train_loss = 1.15897279, grad/param norm = 2.6443e-01, time/batch = 19.2090s	
9857/22950 (epoch 21.475), train_loss = 1.24310452, grad/param norm = 2.3299e-01, time/batch = 18.0452s	
9858/22950 (epoch 21.477), train_loss = 1.02859860, grad/param norm = 1.9763e-01, time/batch = 18.3549s	
9859/22950 (epoch 21.479), train_loss = 0.95460052, grad/param norm = 2.0308e-01, time/batch = 18.1112s	
9860/22950 (epoch 21.481), train_loss = 1.13551690, grad/param norm = 2.4506e-01, time/batch = 19.7043s	
9861/22950 (epoch 21.484), train_loss = 1.07198199, grad/param norm = 2.2639e-01, time/batch = 18.6955s	
9862/22950 (epoch 21.486), train_loss = 0.91583078, grad/param norm = 2.2384e-01, time/batch = 17.5946s	
9863/22950 (epoch 21.488), train_loss = 1.00260329, grad/param norm = 2.4498e-01, time/batch = 18.6989s	
9864/22950 (epoch 21.490), train_loss = 0.89930478, grad/param norm = 2.1347e-01, time/batch = 16.6534s	
9865/22950 (epoch 21.492), train_loss = 1.01641625, grad/param norm = 2.3472e-01, time/batch = 18.3262s	
9866/22950 (epoch 21.495), train_loss = 0.99181459, grad/param norm = 2.0660e-01, time/batch = 18.2969s	
9867/22950 (epoch 21.497), train_loss = 1.10888552, grad/param norm = 2.2085e-01, time/batch = 16.4900s	
9868/22950 (epoch 21.499), train_loss = 1.16650592, grad/param norm = 2.0541e-01, time/batch = 18.7598s	
9869/22950 (epoch 21.501), train_loss = 1.12251224, grad/param norm = 2.3141e-01, time/batch = 19.4461s	
9870/22950 (epoch 21.503), train_loss = 1.12934461, grad/param norm = 2.0369e-01, time/batch = 21.1154s	
9871/22950 (epoch 21.505), train_loss = 0.93133596, grad/param norm = 1.9013e-01, time/batch = 18.3566s	
9872/22950 (epoch 21.508), train_loss = 1.09215956, grad/param norm = 2.0387e-01, time/batch = 17.1047s	
9873/22950 (epoch 21.510), train_loss = 1.05548353, grad/param norm = 2.3767e-01, time/batch = 17.4263s	
9874/22950 (epoch 21.512), train_loss = 0.93304832, grad/param norm = 2.0869e-01, time/batch = 19.6992s	
9875/22950 (epoch 21.514), train_loss = 0.96435730, grad/param norm = 1.7924e-01, time/batch = 17.4364s	
9876/22950 (epoch 21.516), train_loss = 1.03271176, grad/param norm = 2.1905e-01, time/batch = 17.7081s	
9877/22950 (epoch 21.519), train_loss = 1.01467925, grad/param norm = 1.9698e-01, time/batch = 20.2911s	
9878/22950 (epoch 21.521), train_loss = 1.03642881, grad/param norm = 2.2981e-01, time/batch = 16.6167s	
9879/22950 (epoch 21.523), train_loss = 0.84822659, grad/param norm = 1.9244e-01, time/batch = 17.7171s	
9880/22950 (epoch 21.525), train_loss = 0.93350596, grad/param norm = 1.7702e-01, time/batch = 20.6114s	
9881/22950 (epoch 21.527), train_loss = 0.89597361, grad/param norm = 2.0101e-01, time/batch = 18.4297s	
9882/22950 (epoch 21.529), train_loss = 1.06058909, grad/param norm = 2.0709e-01, time/batch = 20.2017s	
9883/22950 (epoch 21.532), train_loss = 0.99573434, grad/param norm = 2.1669e-01, time/batch = 16.2728s	
9884/22950 (epoch 21.534), train_loss = 1.07378439, grad/param norm = 2.2499e-01, time/batch = 17.5293s	
9885/22950 (epoch 21.536), train_loss = 1.10204134, grad/param norm = 2.2855e-01, time/batch = 18.6877s	
9886/22950 (epoch 21.538), train_loss = 1.07326618, grad/param norm = 2.2753e-01, time/batch = 19.3630s	
9887/22950 (epoch 21.540), train_loss = 1.08057375, grad/param norm = 2.2550e-01, time/batch = 19.2649s	
9888/22950 (epoch 21.542), train_loss = 1.20029262, grad/param norm = 2.3460e-01, time/batch = 18.2660s	
9889/22950 (epoch 21.545), train_loss = 0.99603410, grad/param norm = 1.9293e-01, time/batch = 17.3952s	
9890/22950 (epoch 21.547), train_loss = 1.02302115, grad/param norm = 2.0645e-01, time/batch = 16.6953s	
9891/22950 (epoch 21.549), train_loss = 0.97867575, grad/param norm = 2.1234e-01, time/batch = 16.8266s	
9892/22950 (epoch 21.551), train_loss = 1.03567359, grad/param norm = 2.3225e-01, time/batch = 19.2818s	
9893/22950 (epoch 21.553), train_loss = 1.00838227, grad/param norm = 2.3273e-01, time/batch = 16.4274s	
9894/22950 (epoch 21.556), train_loss = 1.06720865, grad/param norm = 2.0023e-01, time/batch = 18.3738s	
9895/22950 (epoch 21.558), train_loss = 0.93823418, grad/param norm = 2.1022e-01, time/batch = 18.1065s	
9896/22950 (epoch 21.560), train_loss = 1.01976155, grad/param norm = 2.0498e-01, time/batch = 18.2162s	
9897/22950 (epoch 21.562), train_loss = 0.96449210, grad/param norm = 1.9907e-01, time/batch = 19.2853s	
9898/22950 (epoch 21.564), train_loss = 1.11376944, grad/param norm = 2.2785e-01, time/batch = 19.9593s	
9899/22950 (epoch 21.566), train_loss = 1.06268544, grad/param norm = 2.1412e-01, time/batch = 19.4519s	
9900/22950 (epoch 21.569), train_loss = 1.06412014, grad/param norm = 2.2339e-01, time/batch = 18.3807s	
9901/22950 (epoch 21.571), train_loss = 1.02384959, grad/param norm = 2.2687e-01, time/batch = 16.0161s	
9902/22950 (epoch 21.573), train_loss = 1.04602553, grad/param norm = 2.2579e-01, time/batch = 19.1410s	
9903/22950 (epoch 21.575), train_loss = 1.17618497, grad/param norm = 2.6435e-01, time/batch = 18.3747s	
9904/22950 (epoch 21.577), train_loss = 1.06356555, grad/param norm = 2.5840e-01, time/batch = 16.8015s	
9905/22950 (epoch 21.580), train_loss = 1.07126156, grad/param norm = 2.3772e-01, time/batch = 17.5865s	
9906/22950 (epoch 21.582), train_loss = 1.22806087, grad/param norm = 2.3990e-01, time/batch = 16.2386s	
9907/22950 (epoch 21.584), train_loss = 0.93094429, grad/param norm = 1.9943e-01, time/batch = 16.8617s	
9908/22950 (epoch 21.586), train_loss = 0.98280559, grad/param norm = 2.2441e-01, time/batch = 17.1796s	
9909/22950 (epoch 21.588), train_loss = 1.17110010, grad/param norm = 2.2947e-01, time/batch = 19.1270s	
9910/22950 (epoch 21.590), train_loss = 1.04664710, grad/param norm = 2.1224e-01, time/batch = 18.0940s	
9911/22950 (epoch 21.593), train_loss = 0.99544407, grad/param norm = 2.1943e-01, time/batch = 18.9241s	
9912/22950 (epoch 21.595), train_loss = 0.92401886, grad/param norm = 2.0645e-01, time/batch = 18.0436s	
9913/22950 (epoch 21.597), train_loss = 1.12359836, grad/param norm = 2.4297e-01, time/batch = 18.8048s	
9914/22950 (epoch 21.599), train_loss = 1.07097133, grad/param norm = 2.3858e-01, time/batch = 16.1944s	
9915/22950 (epoch 21.601), train_loss = 1.06901033, grad/param norm = 2.1371e-01, time/batch = 18.4517s	
9916/22950 (epoch 21.603), train_loss = 1.17816487, grad/param norm = 2.2679e-01, time/batch = 17.2865s	
9917/22950 (epoch 21.606), train_loss = 1.03947634, grad/param norm = 2.2447e-01, time/batch = 18.1948s	
9918/22950 (epoch 21.608), train_loss = 1.08584495, grad/param norm = 2.3260e-01, time/batch = 18.3715s	
9919/22950 (epoch 21.610), train_loss = 1.03522882, grad/param norm = 2.0389e-01, time/batch = 20.1134s	
9920/22950 (epoch 21.612), train_loss = 1.02097220, grad/param norm = 2.0822e-01, time/batch = 19.3540s	
9921/22950 (epoch 21.614), train_loss = 1.17006055, grad/param norm = 2.5086e-01, time/batch = 18.9433s	
9922/22950 (epoch 21.617), train_loss = 1.02877771, grad/param norm = 2.2778e-01, time/batch = 17.4485s	
9923/22950 (epoch 21.619), train_loss = 1.01409077, grad/param norm = 2.0394e-01, time/batch = 18.2835s	
9924/22950 (epoch 21.621), train_loss = 1.14028748, grad/param norm = 1.9897e-01, time/batch = 16.6770s	
9925/22950 (epoch 21.623), train_loss = 1.12459829, grad/param norm = 2.1160e-01, time/batch = 17.0128s	
9926/22950 (epoch 21.625), train_loss = 1.01446238, grad/param norm = 2.1633e-01, time/batch = 16.2733s	
9927/22950 (epoch 21.627), train_loss = 1.02484366, grad/param norm = 2.3909e-01, time/batch = 16.5640s	
9928/22950 (epoch 21.630), train_loss = 0.91029179, grad/param norm = 1.8917e-01, time/batch = 16.8717s	
9929/22950 (epoch 21.632), train_loss = 1.01396470, grad/param norm = 2.2251e-01, time/batch = 19.7514s	
9930/22950 (epoch 21.634), train_loss = 1.05382105, grad/param norm = 2.0016e-01, time/batch = 19.2062s	
9931/22950 (epoch 21.636), train_loss = 1.09188773, grad/param norm = 2.1555e-01, time/batch = 19.2860s	
9932/22950 (epoch 21.638), train_loss = 0.96914730, grad/param norm = 2.0226e-01, time/batch = 20.2888s	
9933/22950 (epoch 21.641), train_loss = 1.02544902, grad/param norm = 2.0396e-01, time/batch = 19.1286s	
9934/22950 (epoch 21.643), train_loss = 1.06758157, grad/param norm = 2.4002e-01, time/batch = 19.5196s	
9935/22950 (epoch 21.645), train_loss = 1.00433475, grad/param norm = 2.0575e-01, time/batch = 18.6273s	
9936/22950 (epoch 21.647), train_loss = 1.03194781, grad/param norm = 2.1877e-01, time/batch = 19.2009s	
9937/22950 (epoch 21.649), train_loss = 1.02829017, grad/param norm = 2.2538e-01, time/batch = 32.0860s	
9938/22950 (epoch 21.651), train_loss = 1.09508136, grad/param norm = 2.1736e-01, time/batch = 18.2850s	
9939/22950 (epoch 21.654), train_loss = 0.88434246, grad/param norm = 1.9573e-01, time/batch = 16.8699s	
9940/22950 (epoch 21.656), train_loss = 1.12926051, grad/param norm = 2.4592e-01, time/batch = 17.5159s	
9941/22950 (epoch 21.658), train_loss = 0.95260435, grad/param norm = 2.3734e-01, time/batch = 18.0440s	
9942/22950 (epoch 21.660), train_loss = 0.85729372, grad/param norm = 2.3681e-01, time/batch = 17.9690s	
9943/22950 (epoch 21.662), train_loss = 0.88184001, grad/param norm = 2.1779e-01, time/batch = 16.2522s	
9944/22950 (epoch 21.664), train_loss = 1.01775770, grad/param norm = 2.1643e-01, time/batch = 16.5068s	
9945/22950 (epoch 21.667), train_loss = 1.04565921, grad/param norm = 2.1419e-01, time/batch = 17.7618s	
9946/22950 (epoch 21.669), train_loss = 1.02935904, grad/param norm = 2.0961e-01, time/batch = 16.4665s	
9947/22950 (epoch 21.671), train_loss = 1.03266703, grad/param norm = 2.0120e-01, time/batch = 17.0373s	
9948/22950 (epoch 21.673), train_loss = 0.98682578, grad/param norm = 2.1480e-01, time/batch = 18.6119s	
9949/22950 (epoch 21.675), train_loss = 1.02465021, grad/param norm = 2.1432e-01, time/batch = 19.7727s	
9950/22950 (epoch 21.678), train_loss = 1.05223029, grad/param norm = 2.1527e-01, time/batch = 18.2950s	
9951/22950 (epoch 21.680), train_loss = 1.02815350, grad/param norm = 2.0146e-01, time/batch = 20.0290s	
9952/22950 (epoch 21.682), train_loss = 1.04019631, grad/param norm = 2.1993e-01, time/batch = 19.8621s	
9953/22950 (epoch 21.684), train_loss = 1.15412818, grad/param norm = 2.6014e-01, time/batch = 19.0944s	
9954/22950 (epoch 21.686), train_loss = 1.11756335, grad/param norm = 2.1286e-01, time/batch = 19.6142s	
9955/22950 (epoch 21.688), train_loss = 1.06777961, grad/param norm = 2.1234e-01, time/batch = 17.7154s	
9956/22950 (epoch 21.691), train_loss = 1.02874060, grad/param norm = 2.0447e-01, time/batch = 16.9252s	
9957/22950 (epoch 21.693), train_loss = 0.95934137, grad/param norm = 2.1798e-01, time/batch = 20.4578s	
9958/22950 (epoch 21.695), train_loss = 1.14664558, grad/param norm = 2.3836e-01, time/batch = 18.9580s	
9959/22950 (epoch 21.697), train_loss = 1.08346451, grad/param norm = 2.3044e-01, time/batch = 17.9427s	
9960/22950 (epoch 21.699), train_loss = 1.10640037, grad/param norm = 2.2011e-01, time/batch = 17.3591s	
9961/22950 (epoch 21.702), train_loss = 1.10295934, grad/param norm = 2.1924e-01, time/batch = 19.9474s	
9962/22950 (epoch 21.704), train_loss = 1.12093030, grad/param norm = 2.1350e-01, time/batch = 18.6869s	
9963/22950 (epoch 21.706), train_loss = 1.13848394, grad/param norm = 2.4932e-01, time/batch = 16.7505s	
9964/22950 (epoch 21.708), train_loss = 0.93408404, grad/param norm = 2.0878e-01, time/batch = 17.6869s	
9965/22950 (epoch 21.710), train_loss = 1.06795957, grad/param norm = 2.2706e-01, time/batch = 16.3259s	
9966/22950 (epoch 21.712), train_loss = 1.16953708, grad/param norm = 2.2256e-01, time/batch = 16.2043s	
9967/22950 (epoch 21.715), train_loss = 1.07684618, grad/param norm = 2.3732e-01, time/batch = 15.7716s	
9968/22950 (epoch 21.717), train_loss = 1.05870780, grad/param norm = 2.1021e-01, time/batch = 15.7728s	
9969/22950 (epoch 21.719), train_loss = 1.00709094, grad/param norm = 2.2305e-01, time/batch = 18.4493s	
9970/22950 (epoch 21.721), train_loss = 1.10007821, grad/param norm = 2.2158e-01, time/batch = 19.0330s	
9971/22950 (epoch 21.723), train_loss = 1.00159210, grad/param norm = 2.0532e-01, time/batch = 18.3616s	
9972/22950 (epoch 21.725), train_loss = 1.10646976, grad/param norm = 2.5043e-01, time/batch = 19.0360s	
9973/22950 (epoch 21.728), train_loss = 1.02981505, grad/param norm = 2.6123e-01, time/batch = 17.5218s	
9974/22950 (epoch 21.730), train_loss = 1.00475441, grad/param norm = 2.0241e-01, time/batch = 19.9571s	
9975/22950 (epoch 21.732), train_loss = 1.09692948, grad/param norm = 2.1186e-01, time/batch = 18.9591s	
9976/22950 (epoch 21.734), train_loss = 1.03480113, grad/param norm = 2.2169e-01, time/batch = 19.1958s	
9977/22950 (epoch 21.736), train_loss = 1.04296538, grad/param norm = 2.0204e-01, time/batch = 17.8749s	
9978/22950 (epoch 21.739), train_loss = 1.11659918, grad/param norm = 2.3060e-01, time/batch = 18.9789s	
9979/22950 (epoch 21.741), train_loss = 1.13468722, grad/param norm = 2.2490e-01, time/batch = 16.8652s	
9980/22950 (epoch 21.743), train_loss = 1.18348460, grad/param norm = 2.2180e-01, time/batch = 19.2802s	
9981/22950 (epoch 21.745), train_loss = 1.29448121, grad/param norm = 2.4735e-01, time/batch = 16.8652s	
9982/22950 (epoch 21.747), train_loss = 1.05450182, grad/param norm = 2.0608e-01, time/batch = 16.9304s	
9983/22950 (epoch 21.749), train_loss = 0.98094455, grad/param norm = 2.2201e-01, time/batch = 16.4437s	
9984/22950 (epoch 21.752), train_loss = 1.24178334, grad/param norm = 2.3987e-01, time/batch = 16.5739s	
9985/22950 (epoch 21.754), train_loss = 1.14929547, grad/param norm = 2.4118e-01, time/batch = 17.5070s	
9986/22950 (epoch 21.756), train_loss = 0.97231659, grad/param norm = 2.0822e-01, time/batch = 16.4895s	
9987/22950 (epoch 21.758), train_loss = 1.02779610, grad/param norm = 2.0795e-01, time/batch = 16.6890s	
9988/22950 (epoch 21.760), train_loss = 1.09846710, grad/param norm = 2.3935e-01, time/batch = 17.6922s	
9989/22950 (epoch 21.763), train_loss = 1.12355168, grad/param norm = 2.2610e-01, time/batch = 17.5990s	
9990/22950 (epoch 21.765), train_loss = 1.10119151, grad/param norm = 2.5694e-01, time/batch = 18.1797s	
9991/22950 (epoch 21.767), train_loss = 1.24066255, grad/param norm = 2.3291e-01, time/batch = 16.6722s	
9992/22950 (epoch 21.769), train_loss = 1.06654078, grad/param norm = 2.0355e-01, time/batch = 19.1734s	
9993/22950 (epoch 21.771), train_loss = 0.92055996, grad/param norm = 2.4479e-01, time/batch = 16.4271s	
9994/22950 (epoch 21.773), train_loss = 0.81184235, grad/param norm = 1.9392e-01, time/batch = 16.4460s	
9995/22950 (epoch 21.776), train_loss = 0.97496184, grad/param norm = 1.9774e-01, time/batch = 17.2997s	
9996/22950 (epoch 21.778), train_loss = 0.95832720, grad/param norm = 2.1278e-01, time/batch = 17.1074s	
9997/22950 (epoch 21.780), train_loss = 1.04549430, grad/param norm = 1.9727e-01, time/batch = 17.0380s	
9998/22950 (epoch 21.782), train_loss = 1.07278663, grad/param norm = 2.1578e-01, time/batch = 18.6889s	
9999/22950 (epoch 21.784), train_loss = 1.01738879, grad/param norm = 2.2652e-01, time/batch = 19.0856s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch21.79_1.7946.t7	
10000/22950 (epoch 21.786), train_loss = 1.08149360, grad/param norm = 2.1178e-01, time/batch = 19.9244s	
10001/22950 (epoch 21.789), train_loss = 1.21428155, grad/param norm = 2.4884e-01, time/batch = 0.7263s	
10002/22950 (epoch 21.791), train_loss = 0.96303906, grad/param norm = 2.4344e-01, time/batch = 0.7230s	
10003/22950 (epoch 21.793), train_loss = 1.22169581, grad/param norm = 2.2701e-01, time/batch = 0.7625s	
10004/22950 (epoch 21.795), train_loss = 1.00625508, grad/param norm = 1.9814e-01, time/batch = 1.0503s	
10005/22950 (epoch 21.797), train_loss = 1.19313772, grad/param norm = 2.2801e-01, time/batch = 1.0531s	
10006/22950 (epoch 21.800), train_loss = 0.97232959, grad/param norm = 2.1108e-01, time/batch = 1.0528s	
10007/22950 (epoch 21.802), train_loss = 0.97506050, grad/param norm = 2.2377e-01, time/batch = 1.0593s	
10008/22950 (epoch 21.804), train_loss = 1.04126338, grad/param norm = 2.1966e-01, time/batch = 1.3894s	
10009/22950 (epoch 21.806), train_loss = 0.94487969, grad/param norm = 2.1545e-01, time/batch = 1.9501s	
10010/22950 (epoch 21.808), train_loss = 1.03465830, grad/param norm = 2.0998e-01, time/batch = 2.0504s	
10011/22950 (epoch 21.810), train_loss = 0.99964447, grad/param norm = 2.1180e-01, time/batch = 16.3794s	
10012/22950 (epoch 21.813), train_loss = 0.86794936, grad/param norm = 2.0848e-01, time/batch = 17.5372s	
10013/22950 (epoch 21.815), train_loss = 0.89987719, grad/param norm = 2.1204e-01, time/batch = 16.7099s	
10014/22950 (epoch 21.817), train_loss = 0.91981501, grad/param norm = 1.8506e-01, time/batch = 18.5169s	
10015/22950 (epoch 21.819), train_loss = 1.03999780, grad/param norm = 2.2368e-01, time/batch = 16.4738s	
10016/22950 (epoch 21.821), train_loss = 0.98454881, grad/param norm = 2.3185e-01, time/batch = 18.5277s	
10017/22950 (epoch 21.824), train_loss = 1.03035594, grad/param norm = 2.2271e-01, time/batch = 16.5607s	
10018/22950 (epoch 21.826), train_loss = 1.15834014, grad/param norm = 2.4811e-01, time/batch = 16.5848s	
10019/22950 (epoch 21.828), train_loss = 1.03056528, grad/param norm = 2.3343e-01, time/batch = 15.8935s	
10020/22950 (epoch 21.830), train_loss = 1.01574769, grad/param norm = 2.1136e-01, time/batch = 16.0500s	
10021/22950 (epoch 21.832), train_loss = 1.04554005, grad/param norm = 2.2753e-01, time/batch = 15.8162s	
10022/22950 (epoch 21.834), train_loss = 0.88063530, grad/param norm = 2.0965e-01, time/batch = 15.8097s	
10023/22950 (epoch 21.837), train_loss = 1.04300440, grad/param norm = 2.1410e-01, time/batch = 16.6990s	
10024/22950 (epoch 21.839), train_loss = 0.88978542, grad/param norm = 1.9933e-01, time/batch = 16.7116s	
10025/22950 (epoch 21.841), train_loss = 0.96831042, grad/param norm = 1.8813e-01, time/batch = 16.3852s	
10026/22950 (epoch 21.843), train_loss = 0.98404426, grad/param norm = 2.2361e-01, time/batch = 16.2889s	
10027/22950 (epoch 21.845), train_loss = 1.04979398, grad/param norm = 2.1900e-01, time/batch = 21.4341s	
10028/22950 (epoch 21.847), train_loss = 1.09316435, grad/param norm = 2.3028e-01, time/batch = 20.3292s	
10029/22950 (epoch 21.850), train_loss = 1.07262994, grad/param norm = 2.2437e-01, time/batch = 23.7183s	
10030/22950 (epoch 21.852), train_loss = 1.08408136, grad/param norm = 2.1271e-01, time/batch = 27.0868s	
10031/22950 (epoch 21.854), train_loss = 1.00664059, grad/param norm = 2.0510e-01, time/batch = 26.2737s	
10032/22950 (epoch 21.856), train_loss = 1.18328775, grad/param norm = 2.3352e-01, time/batch = 24.9413s	
10033/22950 (epoch 21.858), train_loss = 1.07973213, grad/param norm = 2.0336e-01, time/batch = 29.9239s	
10034/22950 (epoch 21.861), train_loss = 1.12437489, grad/param norm = 2.3683e-01, time/batch = 27.6637s	
10035/22950 (epoch 21.863), train_loss = 1.15256555, grad/param norm = 2.3965e-01, time/batch = 23.0079s	
10036/22950 (epoch 21.865), train_loss = 1.20562452, grad/param norm = 2.3625e-01, time/batch = 23.8151s	
10037/22950 (epoch 21.867), train_loss = 1.06124772, grad/param norm = 2.1450e-01, time/batch = 24.4507s	
10038/22950 (epoch 21.869), train_loss = 1.20547706, grad/param norm = 2.4193e-01, time/batch = 28.9174s	
10039/22950 (epoch 21.871), train_loss = 1.07116582, grad/param norm = 2.3020e-01, time/batch = 26.0124s	
10040/22950 (epoch 21.874), train_loss = 1.05881323, grad/param norm = 2.2059e-01, time/batch = 24.2032s	
10041/22950 (epoch 21.876), train_loss = 1.10792966, grad/param norm = 2.1444e-01, time/batch = 24.8491s	
10042/22950 (epoch 21.878), train_loss = 0.98890128, grad/param norm = 2.1681e-01, time/batch = 24.3789s	
10043/22950 (epoch 21.880), train_loss = 1.19595587, grad/param norm = 2.2884e-01, time/batch = 25.5060s	
10044/22950 (epoch 21.882), train_loss = 0.94991943, grad/param norm = 2.0699e-01, time/batch = 25.4414s	
10045/22950 (epoch 21.885), train_loss = 1.08531887, grad/param norm = 2.1033e-01, time/batch = 26.4302s	
10046/22950 (epoch 21.887), train_loss = 1.05360053, grad/param norm = 2.0957e-01, time/batch = 29.1272s	
10047/22950 (epoch 21.889), train_loss = 1.09569913, grad/param norm = 2.3519e-01, time/batch = 22.8894s	
10048/22950 (epoch 21.891), train_loss = 0.98136181, grad/param norm = 2.1747e-01, time/batch = 16.4404s	
10049/22950 (epoch 21.893), train_loss = 1.10886555, grad/param norm = 2.1887e-01, time/batch = 16.5496s	
10050/22950 (epoch 21.895), train_loss = 1.22618566, grad/param norm = 2.6591e-01, time/batch = 15.6985s	
10051/22950 (epoch 21.898), train_loss = 1.02933114, grad/param norm = 2.0541e-01, time/batch = 16.5838s	
10052/22950 (epoch 21.900), train_loss = 1.01592677, grad/param norm = 2.0489e-01, time/batch = 17.9436s	
10053/22950 (epoch 21.902), train_loss = 1.08353737, grad/param norm = 2.3041e-01, time/batch = 17.7731s	
10054/22950 (epoch 21.904), train_loss = 1.07354309, grad/param norm = 2.1995e-01, time/batch = 17.7853s	
10055/22950 (epoch 21.906), train_loss = 1.09331822, grad/param norm = 2.3170e-01, time/batch = 18.8472s	
10056/22950 (epoch 21.908), train_loss = 0.93447937, grad/param norm = 1.9541e-01, time/batch = 17.4474s	
10057/22950 (epoch 21.911), train_loss = 0.91625863, grad/param norm = 1.9652e-01, time/batch = 18.5373s	
10058/22950 (epoch 21.913), train_loss = 0.98664733, grad/param norm = 2.0753e-01, time/batch = 19.1217s	
10059/22950 (epoch 21.915), train_loss = 1.17125562, grad/param norm = 2.3263e-01, time/batch = 16.4192s	
10060/22950 (epoch 21.917), train_loss = 0.93044025, grad/param norm = 2.0105e-01, time/batch = 19.5999s	
10061/22950 (epoch 21.919), train_loss = 1.02798600, grad/param norm = 2.1376e-01, time/batch = 19.0312s	
10062/22950 (epoch 21.922), train_loss = 1.05598148, grad/param norm = 2.1809e-01, time/batch = 19.2721s	
10063/22950 (epoch 21.924), train_loss = 1.08268323, grad/param norm = 2.2718e-01, time/batch = 20.5318s	
10064/22950 (epoch 21.926), train_loss = 0.90317099, grad/param norm = 2.1318e-01, time/batch = 18.4493s	
10065/22950 (epoch 21.928), train_loss = 0.92778363, grad/param norm = 2.0614e-01, time/batch = 17.7646s	
10066/22950 (epoch 21.930), train_loss = 0.92475686, grad/param norm = 2.1116e-01, time/batch = 19.7761s	
10067/22950 (epoch 21.932), train_loss = 0.88478236, grad/param norm = 1.9832e-01, time/batch = 18.0387s	
10068/22950 (epoch 21.935), train_loss = 1.01831446, grad/param norm = 2.0868e-01, time/batch = 18.0107s	
10069/22950 (epoch 21.937), train_loss = 1.05369414, grad/param norm = 2.2507e-01, time/batch = 16.3090s	
10070/22950 (epoch 21.939), train_loss = 0.95961147, grad/param norm = 2.1442e-01, time/batch = 16.0978s	
10071/22950 (epoch 21.941), train_loss = 0.97736363, grad/param norm = 2.0939e-01, time/batch = 16.0362s	
10072/22950 (epoch 21.943), train_loss = 1.07438980, grad/param norm = 2.3729e-01, time/batch = 17.0966s	
10073/22950 (epoch 21.946), train_loss = 0.90195661, grad/param norm = 2.0772e-01, time/batch = 15.8045s	
10074/22950 (epoch 21.948), train_loss = 1.10633393, grad/param norm = 2.1029e-01, time/batch = 19.3630s	
10075/22950 (epoch 21.950), train_loss = 1.04922561, grad/param norm = 2.3275e-01, time/batch = 16.8360s	
10076/22950 (epoch 21.952), train_loss = 1.07214831, grad/param norm = 2.1760e-01, time/batch = 18.2616s	
10077/22950 (epoch 21.954), train_loss = 1.06408916, grad/param norm = 2.2964e-01, time/batch = 18.5435s	
10078/22950 (epoch 21.956), train_loss = 0.95245288, grad/param norm = 2.1154e-01, time/batch = 20.1980s	
10079/22950 (epoch 21.959), train_loss = 0.94289086, grad/param norm = 2.1228e-01, time/batch = 19.3701s	
10080/22950 (epoch 21.961), train_loss = 1.06195039, grad/param norm = 2.3423e-01, time/batch = 18.3052s	
10081/22950 (epoch 21.963), train_loss = 1.08516435, grad/param norm = 2.3812e-01, time/batch = 19.5280s	
10082/22950 (epoch 21.965), train_loss = 1.17832758, grad/param norm = 2.3682e-01, time/batch = 19.3567s	
10083/22950 (epoch 21.967), train_loss = 1.03211917, grad/param norm = 2.2126e-01, time/batch = 19.0265s	
10084/22950 (epoch 21.969), train_loss = 0.94129007, grad/param norm = 2.1450e-01, time/batch = 20.1852s	
10085/22950 (epoch 21.972), train_loss = 1.01728661, grad/param norm = 1.9780e-01, time/batch = 17.3383s	
10086/22950 (epoch 21.974), train_loss = 0.98357679, grad/param norm = 2.1433e-01, time/batch = 16.0158s	
10087/22950 (epoch 21.976), train_loss = 0.96838373, grad/param norm = 1.9182e-01, time/batch = 15.9812s	
10088/22950 (epoch 21.978), train_loss = 0.99573518, grad/param norm = 2.2765e-01, time/batch = 15.8239s	
10089/22950 (epoch 21.980), train_loss = 1.01493583, grad/param norm = 2.0943e-01, time/batch = 16.4047s	
10090/22950 (epoch 21.983), train_loss = 1.06465817, grad/param norm = 2.0376e-01, time/batch = 15.3089s	
10091/22950 (epoch 21.985), train_loss = 0.92151531, grad/param norm = 2.2236e-01, time/batch = 16.8181s	
10092/22950 (epoch 21.987), train_loss = 0.96938099, grad/param norm = 2.0295e-01, time/batch = 16.7485s	
10093/22950 (epoch 21.989), train_loss = 1.02966442, grad/param norm = 2.1992e-01, time/batch = 15.4665s	
10094/22950 (epoch 21.991), train_loss = 0.86570359, grad/param norm = 1.9723e-01, time/batch = 15.8822s	
10095/22950 (epoch 21.993), train_loss = 1.06615143, grad/param norm = 2.1533e-01, time/batch = 15.0573s	
10096/22950 (epoch 21.996), train_loss = 1.05308766, grad/param norm = 2.1352e-01, time/batch = 15.5428s	
10097/22950 (epoch 21.998), train_loss = 0.95152328, grad/param norm = 2.2280e-01, time/batch = 17.5420s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
10098/22950 (epoch 22.000), train_loss = 0.86600628, grad/param norm = 1.9053e-01, time/batch = 19.1290s	
10099/22950 (epoch 22.002), train_loss = 1.19458144, grad/param norm = 2.2661e-01, time/batch = 16.5130s	
10100/22950 (epoch 22.004), train_loss = 1.05836584, grad/param norm = 2.0863e-01, time/batch = 18.2679s	
10101/22950 (epoch 22.007), train_loss = 1.02618678, grad/param norm = 2.1147e-01, time/batch = 19.5361s	
10102/22950 (epoch 22.009), train_loss = 1.17852425, grad/param norm = 2.5419e-01, time/batch = 18.6219s	
10103/22950 (epoch 22.011), train_loss = 0.89856000, grad/param norm = 2.0775e-01, time/batch = 20.4158s	
10104/22950 (epoch 22.013), train_loss = 1.05780391, grad/param norm = 2.2947e-01, time/batch = 16.4794s	
10105/22950 (epoch 22.015), train_loss = 1.08148706, grad/param norm = 2.4205e-01, time/batch = 16.9119s	
10106/22950 (epoch 22.017), train_loss = 1.06445603, grad/param norm = 2.0664e-01, time/batch = 16.5085s	
10107/22950 (epoch 22.020), train_loss = 1.04275161, grad/param norm = 2.0946e-01, time/batch = 19.4214s	
10108/22950 (epoch 22.022), train_loss = 0.89295078, grad/param norm = 2.0010e-01, time/batch = 18.4312s	
10109/22950 (epoch 22.024), train_loss = 1.00495740, grad/param norm = 2.0837e-01, time/batch = 17.6140s	
10110/22950 (epoch 22.026), train_loss = 1.09533111, grad/param norm = 2.2712e-01, time/batch = 17.4534s	
10111/22950 (epoch 22.028), train_loss = 1.14499901, grad/param norm = 2.0390e-01, time/batch = 20.7864s	
10112/22950 (epoch 22.031), train_loss = 1.00958089, grad/param norm = 1.9743e-01, time/batch = 17.8654s	
10113/22950 (epoch 22.033), train_loss = 1.16420163, grad/param norm = 2.3921e-01, time/batch = 18.8563s	
10114/22950 (epoch 22.035), train_loss = 1.02972565, grad/param norm = 2.0186e-01, time/batch = 18.9510s	
10115/22950 (epoch 22.037), train_loss = 1.03153176, grad/param norm = 2.0665e-01, time/batch = 18.7138s	
10116/22950 (epoch 22.039), train_loss = 1.00479088, grad/param norm = 2.1883e-01, time/batch = 19.6282s	
10117/22950 (epoch 22.041), train_loss = 0.98880098, grad/param norm = 2.2152e-01, time/batch = 19.5410s	
10118/22950 (epoch 22.044), train_loss = 1.07120812, grad/param norm = 2.3860e-01, time/batch = 19.6935s	
10119/22950 (epoch 22.046), train_loss = 1.03060822, grad/param norm = 2.2998e-01, time/batch = 18.5915s	
10120/22950 (epoch 22.048), train_loss = 1.05302679, grad/param norm = 2.2090e-01, time/batch = 16.7858s	
10121/22950 (epoch 22.050), train_loss = 1.00673277, grad/param norm = 2.4635e-01, time/batch = 16.4176s	
10122/22950 (epoch 22.052), train_loss = 1.07357689, grad/param norm = 2.4211e-01, time/batch = 17.0993s	
10123/22950 (epoch 22.054), train_loss = 1.20829677, grad/param norm = 2.3966e-01, time/batch = 18.4186s	
10124/22950 (epoch 22.057), train_loss = 1.15785348, grad/param norm = 2.2737e-01, time/batch = 20.0314s	
10125/22950 (epoch 22.059), train_loss = 1.07866616, grad/param norm = 2.0425e-01, time/batch = 19.6102s	
10126/22950 (epoch 22.061), train_loss = 0.95497096, grad/param norm = 2.1015e-01, time/batch = 20.6076s	
10127/22950 (epoch 22.063), train_loss = 1.09029053, grad/param norm = 2.2293e-01, time/batch = 19.2635s	
10128/22950 (epoch 22.065), train_loss = 0.89867868, grad/param norm = 1.9209e-01, time/batch = 18.8494s	
10129/22950 (epoch 22.068), train_loss = 1.09148708, grad/param norm = 2.2791e-01, time/batch = 19.3736s	
10130/22950 (epoch 22.070), train_loss = 0.92179027, grad/param norm = 1.9093e-01, time/batch = 19.4743s	
10131/22950 (epoch 22.072), train_loss = 1.08735017, grad/param norm = 2.1893e-01, time/batch = 16.6637s	
10132/22950 (epoch 22.074), train_loss = 1.05599701, grad/param norm = 2.2140e-01, time/batch = 16.4572s	
10133/22950 (epoch 22.076), train_loss = 1.06583828, grad/param norm = 2.1370e-01, time/batch = 17.6037s	
10134/22950 (epoch 22.078), train_loss = 1.12278783, grad/param norm = 2.1088e-01, time/batch = 17.8657s	
10135/22950 (epoch 22.081), train_loss = 1.13759468, grad/param norm = 2.2537e-01, time/batch = 24.2046s	
10136/22950 (epoch 22.083), train_loss = 1.01010832, grad/param norm = 2.1345e-01, time/batch = 28.5735s	
10137/22950 (epoch 22.085), train_loss = 0.92465305, grad/param norm = 2.1888e-01, time/batch = 15.8403s	
10138/22950 (epoch 22.087), train_loss = 0.94124727, grad/param norm = 2.1706e-01, time/batch = 16.8448s	
10139/22950 (epoch 22.089), train_loss = 1.06163032, grad/param norm = 1.9516e-01, time/batch = 15.4512s	
10140/22950 (epoch 22.092), train_loss = 0.99733940, grad/param norm = 2.6194e-01, time/batch = 15.6950s	
10141/22950 (epoch 22.094), train_loss = 0.95187228, grad/param norm = 2.0960e-01, time/batch = 15.3703s	
10142/22950 (epoch 22.096), train_loss = 1.16352664, grad/param norm = 2.3604e-01, time/batch = 15.0872s	
10143/22950 (epoch 22.098), train_loss = 1.09711938, grad/param norm = 2.1715e-01, time/batch = 14.9132s	
10144/22950 (epoch 22.100), train_loss = 0.99847617, grad/param norm = 2.0482e-01, time/batch = 14.7416s	
10145/22950 (epoch 22.102), train_loss = 1.02318602, grad/param norm = 2.0462e-01, time/batch = 14.9841s	
10146/22950 (epoch 22.105), train_loss = 0.89837515, grad/param norm = 1.8991e-01, time/batch = 15.0831s	
10147/22950 (epoch 22.107), train_loss = 0.98373494, grad/param norm = 2.1384e-01, time/batch = 14.9938s	
10148/22950 (epoch 22.109), train_loss = 0.97527684, grad/param norm = 2.1714e-01, time/batch = 15.1638s	
10149/22950 (epoch 22.111), train_loss = 0.88381139, grad/param norm = 2.0122e-01, time/batch = 15.7073s	
10150/22950 (epoch 22.113), train_loss = 1.03180476, grad/param norm = 2.1125e-01, time/batch = 15.7967s	
10151/22950 (epoch 22.115), train_loss = 1.05064252, grad/param norm = 2.1725e-01, time/batch = 16.1531s	
10152/22950 (epoch 22.118), train_loss = 1.18117040, grad/param norm = 2.2675e-01, time/batch = 15.2831s	
10153/22950 (epoch 22.120), train_loss = 0.96861052, grad/param norm = 2.4873e-01, time/batch = 15.7551s	
10154/22950 (epoch 22.122), train_loss = 1.13974454, grad/param norm = 2.3474e-01, time/batch = 16.4790s	
10155/22950 (epoch 22.124), train_loss = 0.89558819, grad/param norm = 1.9170e-01, time/batch = 16.1870s	
10156/22950 (epoch 22.126), train_loss = 1.01738173, grad/param norm = 2.1361e-01, time/batch = 16.2527s	
10157/22950 (epoch 22.129), train_loss = 0.90925297, grad/param norm = 1.8815e-01, time/batch = 15.7895s	
10158/22950 (epoch 22.131), train_loss = 1.00085685, grad/param norm = 2.0634e-01, time/batch = 15.4013s	
10159/22950 (epoch 22.133), train_loss = 1.08191563, grad/param norm = 2.1705e-01, time/batch = 14.5170s	
10160/22950 (epoch 22.135), train_loss = 1.03553083, grad/param norm = 2.0844e-01, time/batch = 15.3864s	
10161/22950 (epoch 22.137), train_loss = 1.15153303, grad/param norm = 2.3379e-01, time/batch = 15.9603s	
10162/22950 (epoch 22.139), train_loss = 0.92210361, grad/param norm = 2.2351e-01, time/batch = 15.2438s	
10163/22950 (epoch 22.142), train_loss = 0.94170154, grad/param norm = 2.0393e-01, time/batch = 16.0662s	
10164/22950 (epoch 22.144), train_loss = 0.99474486, grad/param norm = 2.2754e-01, time/batch = 15.6192s	
10165/22950 (epoch 22.146), train_loss = 0.97612651, grad/param norm = 2.1531e-01, time/batch = 15.2384s	
10166/22950 (epoch 22.148), train_loss = 0.96751664, grad/param norm = 1.9657e-01, time/batch = 15.0795s	
10167/22950 (epoch 22.150), train_loss = 1.04397137, grad/param norm = 2.1685e-01, time/batch = 15.4937s	
10168/22950 (epoch 22.153), train_loss = 0.98283319, grad/param norm = 2.2049e-01, time/batch = 15.5683s	
10169/22950 (epoch 22.155), train_loss = 0.97716678, grad/param norm = 2.0075e-01, time/batch = 15.7030s	
10170/22950 (epoch 22.157), train_loss = 1.01629158, grad/param norm = 2.0938e-01, time/batch = 15.0654s	
10171/22950 (epoch 22.159), train_loss = 0.94127590, grad/param norm = 2.0272e-01, time/batch = 15.0081s	
10172/22950 (epoch 22.161), train_loss = 0.98380550, grad/param norm = 2.1166e-01, time/batch = 15.6258s	
10173/22950 (epoch 22.163), train_loss = 0.89326326, grad/param norm = 1.9166e-01, time/batch = 14.9239s	
10174/22950 (epoch 22.166), train_loss = 1.15082162, grad/param norm = 2.5638e-01, time/batch = 14.8406s	
10175/22950 (epoch 22.168), train_loss = 1.08950097, grad/param norm = 2.3294e-01, time/batch = 15.0702s	
10176/22950 (epoch 22.170), train_loss = 1.00863913, grad/param norm = 2.3927e-01, time/batch = 15.6211s	
10177/22950 (epoch 22.172), train_loss = 1.04781853, grad/param norm = 1.9226e-01, time/batch = 15.0709s	
10178/22950 (epoch 22.174), train_loss = 1.09456410, grad/param norm = 2.2463e-01, time/batch = 15.1687s	
10179/22950 (epoch 22.176), train_loss = 1.11095039, grad/param norm = 2.1565e-01, time/batch = 15.2440s	
10180/22950 (epoch 22.179), train_loss = 1.08602157, grad/param norm = 2.2854e-01, time/batch = 16.1009s	
10181/22950 (epoch 22.181), train_loss = 1.27047695, grad/param norm = 2.2799e-01, time/batch = 16.1440s	
10182/22950 (epoch 22.183), train_loss = 1.11115318, grad/param norm = 2.2190e-01, time/batch = 16.1470s	
10183/22950 (epoch 22.185), train_loss = 1.05813662, grad/param norm = 2.1041e-01, time/batch = 15.6077s	
10184/22950 (epoch 22.187), train_loss = 0.95277317, grad/param norm = 2.3594e-01, time/batch = 15.6317s	
10185/22950 (epoch 22.190), train_loss = 0.86692995, grad/param norm = 2.1903e-01, time/batch = 16.2267s	
10186/22950 (epoch 22.192), train_loss = 0.87466959, grad/param norm = 1.9542e-01, time/batch = 16.5604s	
10187/22950 (epoch 22.194), train_loss = 1.00273896, grad/param norm = 2.6529e-01, time/batch = 16.4742s	
10188/22950 (epoch 22.196), train_loss = 0.82099637, grad/param norm = 2.0823e-01, time/batch = 16.2579s	
10189/22950 (epoch 22.198), train_loss = 1.11546550, grad/param norm = 2.3684e-01, time/batch = 15.9383s	
10190/22950 (epoch 22.200), train_loss = 0.93841004, grad/param norm = 1.8984e-01, time/batch = 15.5488s	
10191/22950 (epoch 22.203), train_loss = 0.88448282, grad/param norm = 1.9169e-01, time/batch = 15.9583s	
10192/22950 (epoch 22.205), train_loss = 0.98973699, grad/param norm = 2.1812e-01, time/batch = 15.4018s	
10193/22950 (epoch 22.207), train_loss = 1.01501659, grad/param norm = 2.1732e-01, time/batch = 16.0080s	
10194/22950 (epoch 22.209), train_loss = 1.04080514, grad/param norm = 2.3844e-01, time/batch = 15.1557s	
10195/22950 (epoch 22.211), train_loss = 0.84909155, grad/param norm = 2.1158e-01, time/batch = 15.7850s	
10196/22950 (epoch 22.214), train_loss = 0.97544119, grad/param norm = 2.2360e-01, time/batch = 15.1521s	
10197/22950 (epoch 22.216), train_loss = 1.10200526, grad/param norm = 2.2668e-01, time/batch = 15.2311s	
10198/22950 (epoch 22.218), train_loss = 1.02662986, grad/param norm = 2.0396e-01, time/batch = 15.0645s	
10199/22950 (epoch 22.220), train_loss = 1.10081349, grad/param norm = 2.5857e-01, time/batch = 15.6378s	
10200/22950 (epoch 22.222), train_loss = 1.12945979, grad/param norm = 2.3781e-01, time/batch = 14.9217s	
10201/22950 (epoch 22.224), train_loss = 1.02153826, grad/param norm = 2.2142e-01, time/batch = 15.2413s	
10202/22950 (epoch 22.227), train_loss = 1.10178849, grad/param norm = 2.0845e-01, time/batch = 15.2312s	
10203/22950 (epoch 22.229), train_loss = 1.09981167, grad/param norm = 2.1824e-01, time/batch = 16.1691s	
10204/22950 (epoch 22.231), train_loss = 0.89376851, grad/param norm = 2.1037e-01, time/batch = 16.5732s	
10205/22950 (epoch 22.233), train_loss = 0.96780436, grad/param norm = 2.2512e-01, time/batch = 16.1224s	
10206/22950 (epoch 22.235), train_loss = 1.16620263, grad/param norm = 2.3414e-01, time/batch = 16.1975s	
10207/22950 (epoch 22.237), train_loss = 0.95254182, grad/param norm = 2.1250e-01, time/batch = 16.4923s	
10208/22950 (epoch 22.240), train_loss = 1.01393888, grad/param norm = 2.0496e-01, time/batch = 16.5277s	
10209/22950 (epoch 22.242), train_loss = 1.13118672, grad/param norm = 2.0851e-01, time/batch = 16.1372s	
10210/22950 (epoch 22.244), train_loss = 1.15241923, grad/param norm = 2.3257e-01, time/batch = 16.5122s	
10211/22950 (epoch 22.246), train_loss = 1.14087434, grad/param norm = 2.1776e-01, time/batch = 17.0437s	
10212/22950 (epoch 22.248), train_loss = 1.06067190, grad/param norm = 2.1595e-01, time/batch = 16.6246s	
10213/22950 (epoch 22.251), train_loss = 0.96730676, grad/param norm = 2.1117e-01, time/batch = 16.5349s	
10214/22950 (epoch 22.253), train_loss = 0.97867117, grad/param norm = 2.2588e-01, time/batch = 16.4185s	
10215/22950 (epoch 22.255), train_loss = 1.06669769, grad/param norm = 2.4754e-01, time/batch = 16.0381s	
10216/22950 (epoch 22.257), train_loss = 1.12910877, grad/param norm = 2.1170e-01, time/batch = 16.3699s	
10217/22950 (epoch 22.259), train_loss = 0.89290667, grad/param norm = 2.0455e-01, time/batch = 16.1341s	
10218/22950 (epoch 22.261), train_loss = 0.98068114, grad/param norm = 2.1741e-01, time/batch = 16.1138s	
10219/22950 (epoch 22.264), train_loss = 0.92216552, grad/param norm = 2.2724e-01, time/batch = 16.2219s	
10220/22950 (epoch 22.266), train_loss = 1.03744342, grad/param norm = 2.1366e-01, time/batch = 15.7801s	
10221/22950 (epoch 22.268), train_loss = 1.00927709, grad/param norm = 2.0866e-01, time/batch = 16.4969s	
10222/22950 (epoch 22.270), train_loss = 1.01383925, grad/param norm = 2.0861e-01, time/batch = 15.7022s	
10223/22950 (epoch 22.272), train_loss = 1.07881500, grad/param norm = 2.1650e-01, time/batch = 15.0756s	
10224/22950 (epoch 22.275), train_loss = 0.97661800, grad/param norm = 2.2447e-01, time/batch = 16.2217s	
10225/22950 (epoch 22.277), train_loss = 0.85168348, grad/param norm = 1.7527e-01, time/batch = 15.5656s	
10226/22950 (epoch 22.279), train_loss = 0.93165672, grad/param norm = 2.3422e-01, time/batch = 15.2449s	
10227/22950 (epoch 22.281), train_loss = 0.97416055, grad/param norm = 2.1497e-01, time/batch = 15.0830s	
10228/22950 (epoch 22.283), train_loss = 0.86475475, grad/param norm = 1.6860e-01, time/batch = 15.2143s	
10229/22950 (epoch 22.285), train_loss = 1.03407756, grad/param norm = 2.2011e-01, time/batch = 15.7955s	
10230/22950 (epoch 22.288), train_loss = 1.09034916, grad/param norm = 2.2920e-01, time/batch = 15.3375s	
10231/22950 (epoch 22.290), train_loss = 0.96738393, grad/param norm = 1.9917e-01, time/batch = 15.6411s	
10232/22950 (epoch 22.292), train_loss = 1.10045065, grad/param norm = 2.0324e-01, time/batch = 15.6354s	
10233/22950 (epoch 22.294), train_loss = 1.00095939, grad/param norm = 2.0056e-01, time/batch = 15.7189s	
10234/22950 (epoch 22.296), train_loss = 0.79642967, grad/param norm = 1.7243e-01, time/batch = 15.4126s	
10235/22950 (epoch 22.298), train_loss = 1.03308376, grad/param norm = 2.2664e-01, time/batch = 15.6389s	
10236/22950 (epoch 22.301), train_loss = 1.03648484, grad/param norm = 2.1956e-01, time/batch = 15.7061s	
10237/22950 (epoch 22.303), train_loss = 1.03511446, grad/param norm = 2.0791e-01, time/batch = 15.9494s	
10238/22950 (epoch 22.305), train_loss = 1.03547575, grad/param norm = 2.3243e-01, time/batch = 16.1796s	
10239/22950 (epoch 22.307), train_loss = 1.14073618, grad/param norm = 2.3421e-01, time/batch = 16.5191s	
10240/22950 (epoch 22.309), train_loss = 0.95262063, grad/param norm = 1.9454e-01, time/batch = 16.4080s	
10241/22950 (epoch 22.312), train_loss = 1.03587556, grad/param norm = 2.1440e-01, time/batch = 16.1690s	
10242/22950 (epoch 22.314), train_loss = 1.01745853, grad/param norm = 1.9546e-01, time/batch = 15.6850s	
10243/22950 (epoch 22.316), train_loss = 1.02189341, grad/param norm = 2.3171e-01, time/batch = 15.2416s	
10244/22950 (epoch 22.318), train_loss = 0.86286660, grad/param norm = 1.8211e-01, time/batch = 18.1205s	
10245/22950 (epoch 22.320), train_loss = 0.94823301, grad/param norm = 1.9764e-01, time/batch = 18.1311s	
10246/22950 (epoch 22.322), train_loss = 0.98369901, grad/param norm = 2.0908e-01, time/batch = 16.8587s	
10247/22950 (epoch 22.325), train_loss = 0.81046928, grad/param norm = 1.8474e-01, time/batch = 17.2923s	
10248/22950 (epoch 22.327), train_loss = 0.83913043, grad/param norm = 1.8705e-01, time/batch = 15.7995s	
10249/22950 (epoch 22.329), train_loss = 0.95245764, grad/param norm = 2.1245e-01, time/batch = 18.2115s	
10250/22950 (epoch 22.331), train_loss = 0.86583090, grad/param norm = 1.8433e-01, time/batch = 19.3668s	
10251/22950 (epoch 22.333), train_loss = 0.98712114, grad/param norm = 2.0539e-01, time/batch = 17.3695s	
10252/22950 (epoch 22.336), train_loss = 0.98091925, grad/param norm = 2.1501e-01, time/batch = 18.0495s	
10253/22950 (epoch 22.338), train_loss = 0.98741290, grad/param norm = 2.0011e-01, time/batch = 16.1166s	
10254/22950 (epoch 22.340), train_loss = 1.00908648, grad/param norm = 2.2008e-01, time/batch = 16.5103s	
10255/22950 (epoch 22.342), train_loss = 1.10558873, grad/param norm = 2.1234e-01, time/batch = 17.8431s	
10256/22950 (epoch 22.344), train_loss = 0.98031106, grad/param norm = 2.1009e-01, time/batch = 17.8717s	
10257/22950 (epoch 22.346), train_loss = 1.09484058, grad/param norm = 2.3782e-01, time/batch = 16.3609s	
10258/22950 (epoch 22.349), train_loss = 1.01396822, grad/param norm = 2.2454e-01, time/batch = 18.4301s	
10259/22950 (epoch 22.351), train_loss = 1.01904166, grad/param norm = 2.0032e-01, time/batch = 18.7941s	
10260/22950 (epoch 22.353), train_loss = 1.09012590, grad/param norm = 2.8248e-01, time/batch = 17.1094s	
10261/22950 (epoch 22.355), train_loss = 1.14257208, grad/param norm = 3.3735e-01, time/batch = 16.8595s	
10262/22950 (epoch 22.357), train_loss = 1.01597534, grad/param norm = 2.3394e-01, time/batch = 17.2695s	
10263/22950 (epoch 22.359), train_loss = 1.04267823, grad/param norm = 2.3052e-01, time/batch = 17.7893s	
10264/22950 (epoch 22.362), train_loss = 1.02682760, grad/param norm = 2.3644e-01, time/batch = 17.0732s	
10265/22950 (epoch 22.364), train_loss = 1.02173754, grad/param norm = 2.3665e-01, time/batch = 18.9457s	
10266/22950 (epoch 22.366), train_loss = 0.97221070, grad/param norm = 2.0002e-01, time/batch = 17.0324s	
10267/22950 (epoch 22.368), train_loss = 1.08051252, grad/param norm = 2.3844e-01, time/batch = 19.4379s	
10268/22950 (epoch 22.370), train_loss = 0.98621498, grad/param norm = 2.1857e-01, time/batch = 17.6960s	
10269/22950 (epoch 22.373), train_loss = 0.88470756, grad/param norm = 1.9708e-01, time/batch = 19.1859s	
10270/22950 (epoch 22.375), train_loss = 1.12105527, grad/param norm = 2.2616e-01, time/batch = 19.6966s	
10271/22950 (epoch 22.377), train_loss = 0.93141479, grad/param norm = 2.3609e-01, time/batch = 18.1219s	
10272/22950 (epoch 22.379), train_loss = 1.05867980, grad/param norm = 2.5758e-01, time/batch = 20.2763s	
10273/22950 (epoch 22.381), train_loss = 0.89003851, grad/param norm = 2.0744e-01, time/batch = 18.0399s	
10274/22950 (epoch 22.383), train_loss = 0.99763256, grad/param norm = 2.2523e-01, time/batch = 17.0936s	
10275/22950 (epoch 22.386), train_loss = 0.94018587, grad/param norm = 2.2390e-01, time/batch = 19.0273s	
10276/22950 (epoch 22.388), train_loss = 1.02235188, grad/param norm = 2.2687e-01, time/batch = 16.7645s	
10277/22950 (epoch 22.390), train_loss = 0.89746223, grad/param norm = 2.0875e-01, time/batch = 18.0324s	
10278/22950 (epoch 22.392), train_loss = 0.95287561, grad/param norm = 2.0834e-01, time/batch = 18.0376s	
10279/22950 (epoch 22.394), train_loss = 0.93413886, grad/param norm = 2.1293e-01, time/batch = 20.6152s	
10280/22950 (epoch 22.397), train_loss = 1.14213786, grad/param norm = 2.0530e-01, time/batch = 17.1904s	
10281/22950 (epoch 22.399), train_loss = 1.15657579, grad/param norm = 2.3355e-01, time/batch = 18.0862s	
10282/22950 (epoch 22.401), train_loss = 1.19563445, grad/param norm = 2.5629e-01, time/batch = 16.2290s	
10283/22950 (epoch 22.403), train_loss = 0.98313111, grad/param norm = 2.4215e-01, time/batch = 18.4715s	
10284/22950 (epoch 22.405), train_loss = 1.12702419, grad/param norm = 2.4260e-01, time/batch = 16.9380s	
10285/22950 (epoch 22.407), train_loss = 1.16913577, grad/param norm = 2.0936e-01, time/batch = 19.1974s	
10286/22950 (epoch 22.410), train_loss = 0.95863293, grad/param norm = 1.9799e-01, time/batch = 17.0310s	
10287/22950 (epoch 22.412), train_loss = 0.99240297, grad/param norm = 1.9662e-01, time/batch = 17.5411s	
10288/22950 (epoch 22.414), train_loss = 1.12932819, grad/param norm = 2.2865e-01, time/batch = 18.2022s	
10289/22950 (epoch 22.416), train_loss = 1.05419713, grad/param norm = 2.3970e-01, time/batch = 18.4598s	
10290/22950 (epoch 22.418), train_loss = 1.03202634, grad/param norm = 2.5441e-01, time/batch = 18.4517s	
10291/22950 (epoch 22.420), train_loss = 1.09152718, grad/param norm = 2.5222e-01, time/batch = 19.5396s	
10292/22950 (epoch 22.423), train_loss = 0.96298605, grad/param norm = 2.0853e-01, time/batch = 18.3731s	
10293/22950 (epoch 22.425), train_loss = 0.98402745, grad/param norm = 1.9189e-01, time/batch = 19.1101s	
10294/22950 (epoch 22.427), train_loss = 0.99557856, grad/param norm = 2.0359e-01, time/batch = 18.6153s	
10295/22950 (epoch 22.429), train_loss = 0.99559243, grad/param norm = 1.9413e-01, time/batch = 19.3768s	
10296/22950 (epoch 22.431), train_loss = 1.07308349, grad/param norm = 2.2194e-01, time/batch = 19.5443s	
10297/22950 (epoch 22.434), train_loss = 1.02326957, grad/param norm = 2.0965e-01, time/batch = 19.1499s	
10298/22950 (epoch 22.436), train_loss = 1.10305528, grad/param norm = 2.1655e-01, time/batch = 18.7123s	
10299/22950 (epoch 22.438), train_loss = 1.06627471, grad/param norm = 2.3628e-01, time/batch = 15.9264s	
10300/22950 (epoch 22.440), train_loss = 1.12773590, grad/param norm = 2.2266e-01, time/batch = 16.0112s	
10301/22950 (epoch 22.442), train_loss = 1.18908248, grad/param norm = 2.4561e-01, time/batch = 17.4916s	
10302/22950 (epoch 22.444), train_loss = 1.08721366, grad/param norm = 2.3541e-01, time/batch = 16.4438s	
10303/22950 (epoch 22.447), train_loss = 1.19706401, grad/param norm = 2.3638e-01, time/batch = 16.1436s	
10304/22950 (epoch 22.449), train_loss = 0.91776664, grad/param norm = 2.0247e-01, time/batch = 15.1397s	
10305/22950 (epoch 22.451), train_loss = 1.04081877, grad/param norm = 2.1051e-01, time/batch = 15.6150s	
10306/22950 (epoch 22.453), train_loss = 1.06394006, grad/param norm = 2.0324e-01, time/batch = 18.9485s	
10307/22950 (epoch 22.455), train_loss = 0.98094847, grad/param norm = 1.9474e-01, time/batch = 18.7714s	
10308/22950 (epoch 22.458), train_loss = 1.09918159, grad/param norm = 2.1572e-01, time/batch = 17.8788s	
10309/22950 (epoch 22.460), train_loss = 1.07137512, grad/param norm = 2.1662e-01, time/batch = 18.0405s	
10310/22950 (epoch 22.462), train_loss = 1.03056716, grad/param norm = 2.1360e-01, time/batch = 18.4489s	
10311/22950 (epoch 22.464), train_loss = 0.99019086, grad/param norm = 2.1472e-01, time/batch = 18.2984s	
10312/22950 (epoch 22.466), train_loss = 1.07550781, grad/param norm = 2.1504e-01, time/batch = 18.7130s	
10313/22950 (epoch 22.468), train_loss = 1.14438528, grad/param norm = 2.3970e-01, time/batch = 19.5971s	
10314/22950 (epoch 22.471), train_loss = 1.08788576, grad/param norm = 2.4654e-01, time/batch = 17.4231s	
10315/22950 (epoch 22.473), train_loss = 1.10882151, grad/param norm = 2.2732e-01, time/batch = 18.8079s	
10316/22950 (epoch 22.475), train_loss = 1.22160240, grad/param norm = 2.2761e-01, time/batch = 17.6315s	
10317/22950 (epoch 22.477), train_loss = 1.02400409, grad/param norm = 2.0931e-01, time/batch = 16.4651s	
10318/22950 (epoch 22.479), train_loss = 0.92912449, grad/param norm = 1.9316e-01, time/batch = 19.5233s	
10319/22950 (epoch 22.481), train_loss = 1.12271965, grad/param norm = 2.4342e-01, time/batch = 18.6290s	
10320/22950 (epoch 22.484), train_loss = 1.05895332, grad/param norm = 2.7458e-01, time/batch = 16.4896s	
10321/22950 (epoch 22.486), train_loss = 0.90652120, grad/param norm = 2.0971e-01, time/batch = 17.0550s	
10322/22950 (epoch 22.488), train_loss = 0.97917703, grad/param norm = 2.3621e-01, time/batch = 16.6011s	
10323/22950 (epoch 22.490), train_loss = 0.89218351, grad/param norm = 2.2173e-01, time/batch = 16.4850s	
10324/22950 (epoch 22.492), train_loss = 0.98968707, grad/param norm = 2.3175e-01, time/batch = 16.4132s	
10325/22950 (epoch 22.495), train_loss = 0.98341622, grad/param norm = 2.2321e-01, time/batch = 19.2862s	
10326/22950 (epoch 22.497), train_loss = 1.09762737, grad/param norm = 2.3860e-01, time/batch = 17.7696s	
10327/22950 (epoch 22.499), train_loss = 1.14583681, grad/param norm = 2.1930e-01, time/batch = 16.4501s	
10328/22950 (epoch 22.501), train_loss = 1.10196149, grad/param norm = 2.3507e-01, time/batch = 17.7131s	
10329/22950 (epoch 22.503), train_loss = 1.11679757, grad/param norm = 2.0668e-01, time/batch = 18.2046s	
10330/22950 (epoch 22.505), train_loss = 0.91672477, grad/param norm = 1.9246e-01, time/batch = 15.7966s	
10331/22950 (epoch 22.508), train_loss = 1.07918619, grad/param norm = 2.1860e-01, time/batch = 16.7383s	
10332/22950 (epoch 22.510), train_loss = 1.02907176, grad/param norm = 2.2076e-01, time/batch = 18.2981s	
10333/22950 (epoch 22.512), train_loss = 0.91708754, grad/param norm = 2.1490e-01, time/batch = 16.6315s	
10334/22950 (epoch 22.514), train_loss = 0.94956556, grad/param norm = 1.8208e-01, time/batch = 17.7065s	
10335/22950 (epoch 22.516), train_loss = 1.00517524, grad/param norm = 2.2686e-01, time/batch = 17.4439s	
10336/22950 (epoch 22.519), train_loss = 1.00396112, grad/param norm = 2.0264e-01, time/batch = 18.2099s	
10337/22950 (epoch 22.521), train_loss = 1.01301852, grad/param norm = 2.1837e-01, time/batch = 16.0838s	
10338/22950 (epoch 22.523), train_loss = 0.83805349, grad/param norm = 2.0488e-01, time/batch = 16.9525s	
10339/22950 (epoch 22.525), train_loss = 0.91973218, grad/param norm = 1.8469e-01, time/batch = 18.6217s	
10340/22950 (epoch 22.527), train_loss = 0.88051506, grad/param norm = 2.0403e-01, time/batch = 17.2039s	
10341/22950 (epoch 22.529), train_loss = 1.04988372, grad/param norm = 2.4192e-01, time/batch = 17.6125s	
10342/22950 (epoch 22.532), train_loss = 0.97937182, grad/param norm = 2.1076e-01, time/batch = 17.1671s	
10343/22950 (epoch 22.534), train_loss = 1.06036651, grad/param norm = 2.3738e-01, time/batch = 17.7071s	
10344/22950 (epoch 22.536), train_loss = 1.08771951, grad/param norm = 2.4327e-01, time/batch = 17.3721s	
10345/22950 (epoch 22.538), train_loss = 1.05358403, grad/param norm = 2.3075e-01, time/batch = 19.8712s	
10346/22950 (epoch 22.540), train_loss = 1.06135504, grad/param norm = 2.2166e-01, time/batch = 19.6114s	
10347/22950 (epoch 22.542), train_loss = 1.19039026, grad/param norm = 2.6920e-01, time/batch = 16.1005s	
10348/22950 (epoch 22.545), train_loss = 0.98374056, grad/param norm = 2.0691e-01, time/batch = 34.0278s	
10349/22950 (epoch 22.547), train_loss = 1.00731643, grad/param norm = 2.1392e-01, time/batch = 17.9537s	
10350/22950 (epoch 22.549), train_loss = 0.97360940, grad/param norm = 2.1952e-01, time/batch = 17.9588s	
10351/22950 (epoch 22.551), train_loss = 1.00108119, grad/param norm = 2.2400e-01, time/batch = 18.1209s	
10352/22950 (epoch 22.553), train_loss = 0.98137965, grad/param norm = 2.2284e-01, time/batch = 19.4545s	
10353/22950 (epoch 22.556), train_loss = 1.05889148, grad/param norm = 2.0822e-01, time/batch = 16.5439s	
10354/22950 (epoch 22.558), train_loss = 0.90676739, grad/param norm = 2.1357e-01, time/batch = 16.9898s	
10355/22950 (epoch 22.560), train_loss = 1.00443880, grad/param norm = 2.1030e-01, time/batch = 16.8139s	
10356/22950 (epoch 22.562), train_loss = 0.95550639, grad/param norm = 2.0307e-01, time/batch = 16.9177s	
10357/22950 (epoch 22.564), train_loss = 1.07932422, grad/param norm = 2.2465e-01, time/batch = 16.1868s	
10358/22950 (epoch 22.566), train_loss = 1.04518784, grad/param norm = 2.1268e-01, time/batch = 17.7612s	
10359/22950 (epoch 22.569), train_loss = 1.02814463, grad/param norm = 2.2557e-01, time/batch = 18.2672s	
10360/22950 (epoch 22.571), train_loss = 0.99994572, grad/param norm = 2.5733e-01, time/batch = 17.7833s	
10361/22950 (epoch 22.573), train_loss = 1.00684189, grad/param norm = 2.3302e-01, time/batch = 20.2111s	
10362/22950 (epoch 22.575), train_loss = 1.15428691, grad/param norm = 2.5669e-01, time/batch = 19.4339s	
10363/22950 (epoch 22.577), train_loss = 1.04680291, grad/param norm = 2.4816e-01, time/batch = 18.3293s	
10364/22950 (epoch 22.580), train_loss = 1.06909271, grad/param norm = 2.5320e-01, time/batch = 18.2786s	
10365/22950 (epoch 22.582), train_loss = 1.21499190, grad/param norm = 2.4454e-01, time/batch = 18.1121s	
10366/22950 (epoch 22.584), train_loss = 0.90492725, grad/param norm = 2.0789e-01, time/batch = 18.9710s	
10367/22950 (epoch 22.586), train_loss = 0.95163123, grad/param norm = 2.0881e-01, time/batch = 16.9325s	
10368/22950 (epoch 22.588), train_loss = 1.15300578, grad/param norm = 2.2054e-01, time/batch = 18.5178s	
10369/22950 (epoch 22.590), train_loss = 1.04262057, grad/param norm = 2.0628e-01, time/batch = 18.1296s	
10370/22950 (epoch 22.593), train_loss = 0.98858404, grad/param norm = 2.2540e-01, time/batch = 16.5637s	
10371/22950 (epoch 22.595), train_loss = 0.91533218, grad/param norm = 2.3652e-01, time/batch = 16.8791s	
10372/22950 (epoch 22.597), train_loss = 1.10836588, grad/param norm = 2.4316e-01, time/batch = 16.7142s	
10373/22950 (epoch 22.599), train_loss = 1.05264363, grad/param norm = 2.5477e-01, time/batch = 18.6925s	
10374/22950 (epoch 22.601), train_loss = 1.07329992, grad/param norm = 2.5691e-01, time/batch = 18.3720s	
10375/22950 (epoch 22.603), train_loss = 1.16290426, grad/param norm = 2.2699e-01, time/batch = 16.7629s	
10376/22950 (epoch 22.606), train_loss = 1.01541470, grad/param norm = 2.0942e-01, time/batch = 16.7087s	
10377/22950 (epoch 22.608), train_loss = 1.05338360, grad/param norm = 2.2346e-01, time/batch = 17.6920s	
10378/22950 (epoch 22.610), train_loss = 1.00983740, grad/param norm = 2.0775e-01, time/batch = 18.3825s	
10379/22950 (epoch 22.612), train_loss = 1.01575671, grad/param norm = 2.2109e-01, time/batch = 16.3782s	
10380/22950 (epoch 22.614), train_loss = 1.14788520, grad/param norm = 2.7571e-01, time/batch = 17.4931s	
10381/22950 (epoch 22.617), train_loss = 1.00446598, grad/param norm = 2.2244e-01, time/batch = 19.0982s	
10382/22950 (epoch 22.619), train_loss = 0.98719379, grad/param norm = 1.9730e-01, time/batch = 17.8850s	
10383/22950 (epoch 22.621), train_loss = 1.12985002, grad/param norm = 2.0579e-01, time/batch = 19.6071s	
10384/22950 (epoch 22.623), train_loss = 1.10860039, grad/param norm = 2.1898e-01, time/batch = 17.2824s	
10385/22950 (epoch 22.625), train_loss = 0.99885775, grad/param norm = 2.0803e-01, time/batch = 17.9469s	
10386/22950 (epoch 22.627), train_loss = 0.99522298, grad/param norm = 2.2680e-01, time/batch = 19.8587s	
10387/22950 (epoch 22.630), train_loss = 0.89314677, grad/param norm = 1.9398e-01, time/batch = 18.9163s	
10388/22950 (epoch 22.632), train_loss = 0.98245951, grad/param norm = 2.3396e-01, time/batch = 17.7106s	
10389/22950 (epoch 22.634), train_loss = 1.04519296, grad/param norm = 2.0812e-01, time/batch = 16.6749s	
10390/22950 (epoch 22.636), train_loss = 1.07580549, grad/param norm = 2.2367e-01, time/batch = 17.9612s	
10391/22950 (epoch 22.638), train_loss = 0.95589011, grad/param norm = 2.0826e-01, time/batch = 16.1652s	
10392/22950 (epoch 22.641), train_loss = 0.99927084, grad/param norm = 2.0680e-01, time/batch = 16.8235s	
10393/22950 (epoch 22.643), train_loss = 1.06137972, grad/param norm = 2.5237e-01, time/batch = 17.8501s	
10394/22950 (epoch 22.645), train_loss = 0.97497906, grad/param norm = 2.0136e-01, time/batch = 20.2714s	
10395/22950 (epoch 22.647), train_loss = 1.02116594, grad/param norm = 2.1809e-01, time/batch = 19.4588s	
10396/22950 (epoch 22.649), train_loss = 1.00225431, grad/param norm = 2.3195e-01, time/batch = 17.8477s	
10397/22950 (epoch 22.651), train_loss = 1.06786659, grad/param norm = 2.1777e-01, time/batch = 17.9128s	
10398/22950 (epoch 22.654), train_loss = 0.86167155, grad/param norm = 1.9641e-01, time/batch = 18.1334s	
10399/22950 (epoch 22.656), train_loss = 1.10495399, grad/param norm = 2.4192e-01, time/batch = 18.3829s	
10400/22950 (epoch 22.658), train_loss = 0.92212249, grad/param norm = 2.1293e-01, time/batch = 16.7840s	
10401/22950 (epoch 22.660), train_loss = 0.82452344, grad/param norm = 2.0141e-01, time/batch = 17.6637s	
10402/22950 (epoch 22.662), train_loss = 0.85668682, grad/param norm = 1.9641e-01, time/batch = 17.8741s	
10403/22950 (epoch 22.664), train_loss = 1.00178119, grad/param norm = 2.1570e-01, time/batch = 17.7622s	
10404/22950 (epoch 22.667), train_loss = 1.02555306, grad/param norm = 2.2360e-01, time/batch = 16.2559s	
10405/22950 (epoch 22.669), train_loss = 1.01747141, grad/param norm = 2.1893e-01, time/batch = 20.6926s	
10406/22950 (epoch 22.671), train_loss = 1.02129357, grad/param norm = 2.1936e-01, time/batch = 19.1099s	
10407/22950 (epoch 22.673), train_loss = 0.97653298, grad/param norm = 2.2959e-01, time/batch = 19.9199s	
10408/22950 (epoch 22.675), train_loss = 1.00943719, grad/param norm = 2.1179e-01, time/batch = 19.7907s	
10409/22950 (epoch 22.678), train_loss = 1.04135642, grad/param norm = 2.3981e-01, time/batch = 16.5976s	
10410/22950 (epoch 22.680), train_loss = 1.00702191, grad/param norm = 2.0358e-01, time/batch = 18.0677s	
10411/22950 (epoch 22.682), train_loss = 1.00470234, grad/param norm = 2.2189e-01, time/batch = 19.2927s	
10412/22950 (epoch 22.684), train_loss = 1.12762760, grad/param norm = 2.4015e-01, time/batch = 15.5683s	
10413/22950 (epoch 22.686), train_loss = 1.09680169, grad/param norm = 2.1669e-01, time/batch = 16.7819s	
10414/22950 (epoch 22.688), train_loss = 1.06506204, grad/param norm = 2.3167e-01, time/batch = 17.0012s	
10415/22950 (epoch 22.691), train_loss = 1.01751876, grad/param norm = 2.1611e-01, time/batch = 17.1691s	
10416/22950 (epoch 22.693), train_loss = 0.94258001, grad/param norm = 2.1888e-01, time/batch = 16.4974s	
10417/22950 (epoch 22.695), train_loss = 1.12859875, grad/param norm = 2.4138e-01, time/batch = 16.7613s	
10418/22950 (epoch 22.697), train_loss = 1.06763879, grad/param norm = 2.2431e-01, time/batch = 17.4505s	
10419/22950 (epoch 22.699), train_loss = 1.07415259, grad/param norm = 2.1123e-01, time/batch = 20.3581s	
10420/22950 (epoch 22.702), train_loss = 1.08728527, grad/param norm = 2.4589e-01, time/batch = 16.3983s	
10421/22950 (epoch 22.704), train_loss = 1.11087814, grad/param norm = 2.1547e-01, time/batch = 16.8648s	
10422/22950 (epoch 22.706), train_loss = 1.11989919, grad/param norm = 2.5251e-01, time/batch = 16.2082s	
10423/22950 (epoch 22.708), train_loss = 0.90939230, grad/param norm = 2.1857e-01, time/batch = 15.6136s	
10424/22950 (epoch 22.710), train_loss = 1.05005462, grad/param norm = 2.2345e-01, time/batch = 16.7055s	
10425/22950 (epoch 22.712), train_loss = 1.14907638, grad/param norm = 2.3842e-01, time/batch = 16.6131s	
10426/22950 (epoch 22.715), train_loss = 1.03673075, grad/param norm = 2.2236e-01, time/batch = 16.3863s	
10427/22950 (epoch 22.717), train_loss = 1.05009597, grad/param norm = 2.1149e-01, time/batch = 17.2020s	
10428/22950 (epoch 22.719), train_loss = 0.98695826, grad/param norm = 2.2206e-01, time/batch = 18.2136s	
10429/22950 (epoch 22.721), train_loss = 1.09008693, grad/param norm = 2.2573e-01, time/batch = 18.3680s	
10430/22950 (epoch 22.723), train_loss = 0.98791166, grad/param norm = 2.3074e-01, time/batch = 17.0475s	
10431/22950 (epoch 22.725), train_loss = 1.08843852, grad/param norm = 2.5032e-01, time/batch = 16.7768s	
10432/22950 (epoch 22.728), train_loss = 1.00978077, grad/param norm = 2.4647e-01, time/batch = 16.2255s	
10433/22950 (epoch 22.730), train_loss = 0.99927719, grad/param norm = 2.2385e-01, time/batch = 17.1887s	
10434/22950 (epoch 22.732), train_loss = 1.09305246, grad/param norm = 2.3647e-01, time/batch = 16.6157s	
10435/22950 (epoch 22.734), train_loss = 1.02742116, grad/param norm = 2.3145e-01, time/batch = 16.5407s	
10436/22950 (epoch 22.736), train_loss = 1.01413249, grad/param norm = 1.9956e-01, time/batch = 16.7867s	
10437/22950 (epoch 22.739), train_loss = 1.10161866, grad/param norm = 2.3052e-01, time/batch = 15.9110s	
10438/22950 (epoch 22.741), train_loss = 1.11305857, grad/param norm = 2.3203e-01, time/batch = 16.5284s	
10439/22950 (epoch 22.743), train_loss = 1.17803222, grad/param norm = 2.6392e-01, time/batch = 20.2840s	
10440/22950 (epoch 22.745), train_loss = 1.28977936, grad/param norm = 2.6488e-01, time/batch = 16.6317s	
10441/22950 (epoch 22.747), train_loss = 1.04812405, grad/param norm = 2.3873e-01, time/batch = 17.7666s	
10442/22950 (epoch 22.749), train_loss = 0.97479635, grad/param norm = 2.3229e-01, time/batch = 20.0478s	
10443/22950 (epoch 22.752), train_loss = 1.20681356, grad/param norm = 2.4501e-01, time/batch = 17.1964s	
10444/22950 (epoch 22.754), train_loss = 1.12493128, grad/param norm = 2.5629e-01, time/batch = 16.3425s	
10445/22950 (epoch 22.756), train_loss = 0.97199753, grad/param norm = 2.2561e-01, time/batch = 16.7014s	
10446/22950 (epoch 22.758), train_loss = 1.02092049, grad/param norm = 2.1159e-01, time/batch = 15.8597s	
10447/22950 (epoch 22.760), train_loss = 1.07738991, grad/param norm = 2.2718e-01, time/batch = 14.9922s	
10448/22950 (epoch 22.763), train_loss = 1.10594969, grad/param norm = 2.2145e-01, time/batch = 15.4612s	
10449/22950 (epoch 22.765), train_loss = 1.09174002, grad/param norm = 2.3270e-01, time/batch = 15.9177s	
10450/22950 (epoch 22.767), train_loss = 1.23842348, grad/param norm = 2.5004e-01, time/batch = 14.9114s	
10451/22950 (epoch 22.769), train_loss = 1.06171104, grad/param norm = 2.1459e-01, time/batch = 15.5529s	
10452/22950 (epoch 22.771), train_loss = 0.89554723, grad/param norm = 2.1070e-01, time/batch = 15.1459s	
10453/22950 (epoch 22.773), train_loss = 0.80544142, grad/param norm = 2.1199e-01, time/batch = 15.6287s	
10454/22950 (epoch 22.776), train_loss = 0.94151710, grad/param norm = 1.9473e-01, time/batch = 14.7397s	
10455/22950 (epoch 22.778), train_loss = 0.93880061, grad/param norm = 2.0095e-01, time/batch = 15.6304s	
10456/22950 (epoch 22.780), train_loss = 1.03146593, grad/param norm = 2.1418e-01, time/batch = 16.3198s	
10457/22950 (epoch 22.782), train_loss = 1.04736689, grad/param norm = 2.0882e-01, time/batch = 16.3804s	
10458/22950 (epoch 22.784), train_loss = 0.98627178, grad/param norm = 2.1718e-01, time/batch = 15.2914s	
10459/22950 (epoch 22.786), train_loss = 1.06493557, grad/param norm = 2.1582e-01, time/batch = 15.0659s	
10460/22950 (epoch 22.789), train_loss = 0.90306506, grad/param norm = 2.1891e-01, time/batch = 15.4551s	
10461/22950 (epoch 22.791), train_loss = 0.94331253, grad/param norm = 2.4030e-01, time/batch = 15.0831s	
10462/22950 (epoch 22.793), train_loss = 1.18705705, grad/param norm = 2.4211e-01, time/batch = 15.0754s	
10463/22950 (epoch 22.795), train_loss = 0.99471065, grad/param norm = 2.0562e-01, time/batch = 15.0558s	
10464/22950 (epoch 22.797), train_loss = 1.17293778, grad/param norm = 2.2681e-01, time/batch = 15.8541s	
10465/22950 (epoch 22.800), train_loss = 0.94590454, grad/param norm = 2.0849e-01, time/batch = 15.2950s	
10466/22950 (epoch 22.802), train_loss = 0.96340387, grad/param norm = 2.1307e-01, time/batch = 15.3720s	
10467/22950 (epoch 22.804), train_loss = 1.02189073, grad/param norm = 2.1566e-01, time/batch = 15.2290s	
10468/22950 (epoch 22.806), train_loss = 0.92447486, grad/param norm = 2.0876e-01, time/batch = 15.7021s	
10469/22950 (epoch 22.808), train_loss = 1.02182828, grad/param norm = 2.2563e-01, time/batch = 14.9918s	
10470/22950 (epoch 22.810), train_loss = 0.98541617, grad/param norm = 2.2237e-01, time/batch = 15.2303s	
10471/22950 (epoch 22.813), train_loss = 0.84606298, grad/param norm = 2.0633e-01, time/batch = 15.6957s	
10472/22950 (epoch 22.815), train_loss = 0.87658674, grad/param norm = 2.0622e-01, time/batch = 16.9800s	
10473/22950 (epoch 22.817), train_loss = 0.90901360, grad/param norm = 1.9284e-01, time/batch = 15.6868s	
10474/22950 (epoch 22.819), train_loss = 1.01538240, grad/param norm = 2.2153e-01, time/batch = 16.0842s	
10475/22950 (epoch 22.821), train_loss = 0.95839911, grad/param norm = 2.0591e-01, time/batch = 15.8392s	
10476/22950 (epoch 22.824), train_loss = 1.00791902, grad/param norm = 2.1514e-01, time/batch = 15.3775s	
10477/22950 (epoch 22.826), train_loss = 1.12788928, grad/param norm = 2.4778e-01, time/batch = 14.8219s	
10478/22950 (epoch 22.828), train_loss = 1.00750361, grad/param norm = 2.1888e-01, time/batch = 14.7264s	
10479/22950 (epoch 22.830), train_loss = 0.98948675, grad/param norm = 2.0899e-01, time/batch = 15.1330s	
10480/22950 (epoch 22.832), train_loss = 1.03306412, grad/param norm = 2.1503e-01, time/batch = 14.6639s	
10481/22950 (epoch 22.834), train_loss = 0.85606765, grad/param norm = 1.9765e-01, time/batch = 14.6627s	
10482/22950 (epoch 22.837), train_loss = 1.02235591, grad/param norm = 2.0649e-01, time/batch = 14.9879s	
10483/22950 (epoch 22.839), train_loss = 0.88614412, grad/param norm = 2.1256e-01, time/batch = 15.1381s	
10484/22950 (epoch 22.841), train_loss = 0.95223433, grad/param norm = 1.9689e-01, time/batch = 15.3955s	
10485/22950 (epoch 22.843), train_loss = 0.97615484, grad/param norm = 2.2299e-01, time/batch = 15.2233s	
10486/22950 (epoch 22.845), train_loss = 1.03717659, grad/param norm = 2.3640e-01, time/batch = 15.1536s	
10487/22950 (epoch 22.847), train_loss = 1.06828781, grad/param norm = 2.2494e-01, time/batch = 15.8574s	
10488/22950 (epoch 22.850), train_loss = 1.06016096, grad/param norm = 2.3286e-01, time/batch = 16.1534s	
10489/22950 (epoch 22.852), train_loss = 1.06491720, grad/param norm = 2.1858e-01, time/batch = 15.4695s	
10490/22950 (epoch 22.854), train_loss = 0.98352275, grad/param norm = 2.0938e-01, time/batch = 14.9158s	
10491/22950 (epoch 22.856), train_loss = 1.15511253, grad/param norm = 2.5699e-01, time/batch = 15.7777s	
10492/22950 (epoch 22.858), train_loss = 1.08102521, grad/param norm = 2.1956e-01, time/batch = 15.6080s	
10493/22950 (epoch 22.861), train_loss = 1.09536732, grad/param norm = 2.3147e-01, time/batch = 15.1544s	
10494/22950 (epoch 22.863), train_loss = 1.14552308, grad/param norm = 2.5024e-01, time/batch = 15.7728s	
10495/22950 (epoch 22.865), train_loss = 1.17242607, grad/param norm = 2.5030e-01, time/batch = 16.3322s	
10496/22950 (epoch 22.867), train_loss = 1.04507697, grad/param norm = 2.1586e-01, time/batch = 16.1628s	
10497/22950 (epoch 22.869), train_loss = 1.18604097, grad/param norm = 2.5244e-01, time/batch = 16.4958s	
10498/22950 (epoch 22.871), train_loss = 1.06657225, grad/param norm = 2.3481e-01, time/batch = 15.7896s	
10499/22950 (epoch 22.874), train_loss = 1.03787290, grad/param norm = 2.0260e-01, time/batch = 15.6329s	
10500/22950 (epoch 22.876), train_loss = 1.08096404, grad/param norm = 2.3413e-01, time/batch = 15.3132s	
10501/22950 (epoch 22.878), train_loss = 0.97236529, grad/param norm = 2.3185e-01, time/batch = 14.7529s	
10502/22950 (epoch 22.880), train_loss = 1.19663262, grad/param norm = 2.5116e-01, time/batch = 15.1503s	
10503/22950 (epoch 22.882), train_loss = 0.92541162, grad/param norm = 2.0105e-01, time/batch = 15.3152s	
10504/22950 (epoch 22.885), train_loss = 1.07289764, grad/param norm = 2.2633e-01, time/batch = 15.3061s	
10505/22950 (epoch 22.887), train_loss = 1.03130270, grad/param norm = 2.0613e-01, time/batch = 15.3873s	
10506/22950 (epoch 22.889), train_loss = 1.06207541, grad/param norm = 2.2291e-01, time/batch = 15.7663s	
10507/22950 (epoch 22.891), train_loss = 0.97131128, grad/param norm = 2.2121e-01, time/batch = 15.7204s	
10508/22950 (epoch 22.893), train_loss = 1.08526592, grad/param norm = 2.3790e-01, time/batch = 15.7673s	
10509/22950 (epoch 22.895), train_loss = 1.20066037, grad/param norm = 2.6637e-01, time/batch = 15.6186s	
10510/22950 (epoch 22.898), train_loss = 1.02008844, grad/param norm = 2.1173e-01, time/batch = 15.6334s	
10511/22950 (epoch 22.900), train_loss = 1.00771495, grad/param norm = 2.0264e-01, time/batch = 15.6207s	
10512/22950 (epoch 22.902), train_loss = 1.06528880, grad/param norm = 2.2718e-01, time/batch = 15.9404s	
10513/22950 (epoch 22.904), train_loss = 1.04829907, grad/param norm = 2.3112e-01, time/batch = 15.4655s	
10514/22950 (epoch 22.906), train_loss = 1.08250017, grad/param norm = 2.2968e-01, time/batch = 15.8021s	
10515/22950 (epoch 22.908), train_loss = 0.91525581, grad/param norm = 1.8881e-01, time/batch = 16.3971s	
10516/22950 (epoch 22.911), train_loss = 0.89805073, grad/param norm = 1.9570e-01, time/batch = 16.4924s	
10517/22950 (epoch 22.913), train_loss = 0.97381247, grad/param norm = 2.0547e-01, time/batch = 16.3846s	
10518/22950 (epoch 22.915), train_loss = 1.15953768, grad/param norm = 2.3487e-01, time/batch = 15.9414s	
10519/22950 (epoch 22.917), train_loss = 0.91703392, grad/param norm = 1.9912e-01, time/batch = 16.2438s	
10520/22950 (epoch 22.919), train_loss = 1.02113214, grad/param norm = 2.2277e-01, time/batch = 16.9432s	
10521/22950 (epoch 22.922), train_loss = 1.04700634, grad/param norm = 2.3819e-01, time/batch = 16.6389s	
10522/22950 (epoch 22.924), train_loss = 1.06662838, grad/param norm = 2.2970e-01, time/batch = 15.6412s	
10523/22950 (epoch 22.926), train_loss = 0.89111396, grad/param norm = 2.3754e-01, time/batch = 15.6422s	
10524/22950 (epoch 22.928), train_loss = 0.89615116, grad/param norm = 1.9511e-01, time/batch = 15.4790s	
10525/22950 (epoch 22.930), train_loss = 0.91507271, grad/param norm = 2.2273e-01, time/batch = 16.3740s	
10526/22950 (epoch 22.932), train_loss = 0.86354960, grad/param norm = 1.8863e-01, time/batch = 15.9709s	
10527/22950 (epoch 22.935), train_loss = 1.00531791, grad/param norm = 2.0914e-01, time/batch = 15.3925s	
10528/22950 (epoch 22.937), train_loss = 1.03768746, grad/param norm = 2.4888e-01, time/batch = 15.3148s	
10529/22950 (epoch 22.939), train_loss = 0.94297656, grad/param norm = 2.0598e-01, time/batch = 16.4686s	
10530/22950 (epoch 22.941), train_loss = 0.96142229, grad/param norm = 2.1499e-01, time/batch = 16.2693s	
10531/22950 (epoch 22.943), train_loss = 1.05431536, grad/param norm = 2.3658e-01, time/batch = 15.3927s	
10532/22950 (epoch 22.946), train_loss = 0.87232342, grad/param norm = 2.0641e-01, time/batch = 15.0624s	
10533/22950 (epoch 22.948), train_loss = 1.09447202, grad/param norm = 2.2056e-01, time/batch = 15.3887s	
10534/22950 (epoch 22.950), train_loss = 1.02761728, grad/param norm = 2.3482e-01, time/batch = 15.2323s	
10535/22950 (epoch 22.952), train_loss = 1.06324436, grad/param norm = 2.1635e-01, time/batch = 15.5409s	
10536/22950 (epoch 22.954), train_loss = 1.03586645, grad/param norm = 2.0893e-01, time/batch = 16.1657s	
10537/22950 (epoch 22.956), train_loss = 0.94407287, grad/param norm = 2.2722e-01, time/batch = 15.4652s	
10538/22950 (epoch 22.959), train_loss = 0.93095826, grad/param norm = 2.1630e-01, time/batch = 15.0662s	
10539/22950 (epoch 22.961), train_loss = 1.03893052, grad/param norm = 2.2389e-01, time/batch = 15.4431s	
10540/22950 (epoch 22.963), train_loss = 1.05389143, grad/param norm = 2.1998e-01, time/batch = 15.6167s	
10541/22950 (epoch 22.965), train_loss = 1.15467271, grad/param norm = 2.3278e-01, time/batch = 15.6134s	
10542/22950 (epoch 22.967), train_loss = 1.00893800, grad/param norm = 2.3053e-01, time/batch = 14.8319s	
10543/22950 (epoch 22.969), train_loss = 0.92844383, grad/param norm = 2.1377e-01, time/batch = 14.9018s	
10544/22950 (epoch 22.972), train_loss = 1.00306758, grad/param norm = 2.0631e-01, time/batch = 15.9910s	
10545/22950 (epoch 22.974), train_loss = 0.97453196, grad/param norm = 2.0992e-01, time/batch = 14.5677s	
10546/22950 (epoch 22.976), train_loss = 0.95316564, grad/param norm = 1.9159e-01, time/batch = 14.8881s	
10547/22950 (epoch 22.978), train_loss = 0.96629881, grad/param norm = 2.3291e-01, time/batch = 14.6724s	
10548/22950 (epoch 22.980), train_loss = 0.98996383, grad/param norm = 2.0963e-01, time/batch = 15.3008s	
10549/22950 (epoch 22.983), train_loss = 1.04955207, grad/param norm = 2.0836e-01, time/batch = 15.4581s	
10550/22950 (epoch 22.985), train_loss = 0.89567439, grad/param norm = 2.2173e-01, time/batch = 15.3049s	
10551/22950 (epoch 22.987), train_loss = 0.94983385, grad/param norm = 1.9563e-01, time/batch = 15.0757s	
10552/22950 (epoch 22.989), train_loss = 1.01546122, grad/param norm = 2.1475e-01, time/batch = 16.2541s	
10553/22950 (epoch 22.991), train_loss = 0.85755432, grad/param norm = 2.0098e-01, time/batch = 15.0676s	
10554/22950 (epoch 22.993), train_loss = 1.04556708, grad/param norm = 2.2319e-01, time/batch = 14.9222s	
10555/22950 (epoch 22.996), train_loss = 1.03032506, grad/param norm = 2.1689e-01, time/batch = 14.8244s	
10556/22950 (epoch 22.998), train_loss = 0.93277239, grad/param norm = 2.0812e-01, time/batch = 15.3732s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
10557/22950 (epoch 23.000), train_loss = 0.83714791, grad/param norm = 1.8445e-01, time/batch = 16.1669s	
10558/22950 (epoch 23.002), train_loss = 1.16846179, grad/param norm = 2.2035e-01, time/batch = 16.4969s	
10559/22950 (epoch 23.004), train_loss = 1.02939172, grad/param norm = 1.9797e-01, time/batch = 15.8890s	
10560/22950 (epoch 23.007), train_loss = 1.01170882, grad/param norm = 2.0093e-01, time/batch = 16.2766s	
10561/22950 (epoch 23.009), train_loss = 1.16169782, grad/param norm = 2.7163e-01, time/batch = 16.1443s	
10562/22950 (epoch 23.011), train_loss = 0.88371959, grad/param norm = 2.1767e-01, time/batch = 16.0548s	
10563/22950 (epoch 23.013), train_loss = 1.04007817, grad/param norm = 2.5219e-01, time/batch = 22.2415s	
10564/22950 (epoch 23.015), train_loss = 1.04844599, grad/param norm = 2.2211e-01, time/batch = 24.6401s	
10565/22950 (epoch 23.017), train_loss = 1.05265787, grad/param norm = 2.1325e-01, time/batch = 17.3514s	
10566/22950 (epoch 23.020), train_loss = 1.03361925, grad/param norm = 2.0906e-01, time/batch = 18.1819s	
10567/22950 (epoch 23.022), train_loss = 0.88075356, grad/param norm = 1.8902e-01, time/batch = 17.1265s	
10568/22950 (epoch 23.024), train_loss = 0.99014114, grad/param norm = 2.1552e-01, time/batch = 16.4287s	
10569/22950 (epoch 23.026), train_loss = 1.08071373, grad/param norm = 2.3932e-01, time/batch = 18.5102s	
10570/22950 (epoch 23.028), train_loss = 1.12644273, grad/param norm = 2.0362e-01, time/batch = 17.2624s	
10571/22950 (epoch 23.031), train_loss = 0.99055844, grad/param norm = 2.0325e-01, time/batch = 16.6512s	
10572/22950 (epoch 23.033), train_loss = 1.13409286, grad/param norm = 2.4829e-01, time/batch = 19.1810s	
10573/22950 (epoch 23.035), train_loss = 1.00838114, grad/param norm = 1.9404e-01, time/batch = 17.8429s	
10574/22950 (epoch 23.037), train_loss = 1.02174380, grad/param norm = 2.2201e-01, time/batch = 19.5947s	
10575/22950 (epoch 23.039), train_loss = 0.99355290, grad/param norm = 2.2802e-01, time/batch = 17.3629s	
10576/22950 (epoch 23.041), train_loss = 0.96863439, grad/param norm = 2.3467e-01, time/batch = 16.9303s	
10577/22950 (epoch 23.044), train_loss = 1.06275347, grad/param norm = 2.3379e-01, time/batch = 16.8411s	
10578/22950 (epoch 23.046), train_loss = 1.00606773, grad/param norm = 2.1548e-01, time/batch = 19.0180s	
10579/22950 (epoch 23.048), train_loss = 1.02662077, grad/param norm = 2.0472e-01, time/batch = 18.1931s	
10580/22950 (epoch 23.050), train_loss = 0.98616682, grad/param norm = 2.3097e-01, time/batch = 19.0973s	
10581/22950 (epoch 23.052), train_loss = 1.04884307, grad/param norm = 2.3246e-01, time/batch = 19.8689s	
10582/22950 (epoch 23.054), train_loss = 1.19732501, grad/param norm = 2.4583e-01, time/batch = 19.1915s	
10583/22950 (epoch 23.057), train_loss = 1.13754066, grad/param norm = 2.2925e-01, time/batch = 16.6890s	
10584/22950 (epoch 23.059), train_loss = 1.05433861, grad/param norm = 1.9926e-01, time/batch = 19.6115s	
10585/22950 (epoch 23.061), train_loss = 0.95429741, grad/param norm = 2.2850e-01, time/batch = 20.1078s	
10586/22950 (epoch 23.063), train_loss = 1.06249975, grad/param norm = 2.2007e-01, time/batch = 18.0115s	
10587/22950 (epoch 23.065), train_loss = 0.89096679, grad/param norm = 2.0236e-01, time/batch = 18.1813s	
10588/22950 (epoch 23.068), train_loss = 1.06615459, grad/param norm = 2.2628e-01, time/batch = 16.0759s	
10589/22950 (epoch 23.070), train_loss = 0.91637196, grad/param norm = 2.0304e-01, time/batch = 16.6559s	
10590/22950 (epoch 23.072), train_loss = 1.08423463, grad/param norm = 2.2397e-01, time/batch = 16.8666s	
10591/22950 (epoch 23.074), train_loss = 1.03810231, grad/param norm = 2.1596e-01, time/batch = 20.0282s	
10592/22950 (epoch 23.076), train_loss = 1.05284257, grad/param norm = 2.2174e-01, time/batch = 18.7889s	
10593/22950 (epoch 23.078), train_loss = 1.09468413, grad/param norm = 2.0834e-01, time/batch = 18.8735s	
10594/22950 (epoch 23.081), train_loss = 1.11754174, grad/param norm = 2.2450e-01, time/batch = 18.7117s	
10595/22950 (epoch 23.083), train_loss = 1.00443124, grad/param norm = 2.1992e-01, time/batch = 19.0130s	
10596/22950 (epoch 23.085), train_loss = 0.89759386, grad/param norm = 2.2218e-01, time/batch = 18.7769s	
10597/22950 (epoch 23.087), train_loss = 0.93094233, grad/param norm = 2.1322e-01, time/batch = 18.5201s	
10598/22950 (epoch 23.089), train_loss = 1.03935070, grad/param norm = 2.1084e-01, time/batch = 17.8724s	
10599/22950 (epoch 23.092), train_loss = 0.98579923, grad/param norm = 2.4926e-01, time/batch = 18.6805s	
10600/22950 (epoch 23.094), train_loss = 0.93769249, grad/param norm = 2.0565e-01, time/batch = 19.0947s	
10601/22950 (epoch 23.096), train_loss = 1.14150507, grad/param norm = 2.2565e-01, time/batch = 19.8775s	
10602/22950 (epoch 23.098), train_loss = 1.07768030, grad/param norm = 2.1846e-01, time/batch = 16.0373s	
10603/22950 (epoch 23.100), train_loss = 0.98247270, grad/param norm = 2.1365e-01, time/batch = 16.7074s	
10604/22950 (epoch 23.102), train_loss = 1.00271771, grad/param norm = 2.0086e-01, time/batch = 16.6501s	
10605/22950 (epoch 23.105), train_loss = 0.87324690, grad/param norm = 1.8630e-01, time/batch = 16.5044s	
10606/22950 (epoch 23.107), train_loss = 0.96548021, grad/param norm = 2.1311e-01, time/batch = 16.0456s	
10607/22950 (epoch 23.109), train_loss = 0.95211014, grad/param norm = 2.1682e-01, time/batch = 15.7871s	
10608/22950 (epoch 23.111), train_loss = 0.87263829, grad/param norm = 2.1622e-01, time/batch = 16.8829s	
10609/22950 (epoch 23.113), train_loss = 1.02016011, grad/param norm = 2.2127e-01, time/batch = 17.4794s	
10610/22950 (epoch 23.115), train_loss = 1.01994318, grad/param norm = 2.1940e-01, time/batch = 20.2783s	
10611/22950 (epoch 23.118), train_loss = 1.14330637, grad/param norm = 2.1277e-01, time/batch = 17.2046s	
10612/22950 (epoch 23.120), train_loss = 0.93119717, grad/param norm = 2.3641e-01, time/batch = 19.0970s	
10613/22950 (epoch 23.122), train_loss = 1.12182705, grad/param norm = 2.3911e-01, time/batch = 17.5411s	
10614/22950 (epoch 23.124), train_loss = 0.88287050, grad/param norm = 1.9377e-01, time/batch = 17.0250s	
10615/22950 (epoch 23.126), train_loss = 1.00408495, grad/param norm = 2.0807e-01, time/batch = 19.8713s	
10616/22950 (epoch 23.129), train_loss = 0.90237561, grad/param norm = 1.9223e-01, time/batch = 17.4423s	
10617/22950 (epoch 23.131), train_loss = 0.98525499, grad/param norm = 2.0043e-01, time/batch = 18.9468s	
10618/22950 (epoch 23.133), train_loss = 1.04902081, grad/param norm = 2.1360e-01, time/batch = 18.2732s	
10619/22950 (epoch 23.135), train_loss = 1.01656746, grad/param norm = 2.0658e-01, time/batch = 16.7265s	
10620/22950 (epoch 23.137), train_loss = 1.13535311, grad/param norm = 2.5602e-01, time/batch = 18.2956s	
10621/22950 (epoch 23.139), train_loss = 0.90179706, grad/param norm = 1.9961e-01, time/batch = 17.8354s	
10622/22950 (epoch 23.142), train_loss = 0.91606423, grad/param norm = 2.0099e-01, time/batch = 17.6912s	
10623/22950 (epoch 23.144), train_loss = 0.98854801, grad/param norm = 2.2419e-01, time/batch = 18.6128s	
10624/22950 (epoch 23.146), train_loss = 0.95126263, grad/param norm = 2.1018e-01, time/batch = 19.1205s	
10625/22950 (epoch 23.148), train_loss = 0.94855148, grad/param norm = 2.0059e-01, time/batch = 17.8357s	
10626/22950 (epoch 23.150), train_loss = 1.03529893, grad/param norm = 2.4748e-01, time/batch = 18.1166s	
10627/22950 (epoch 23.153), train_loss = 0.96226555, grad/param norm = 2.1136e-01, time/batch = 18.6271s	
10628/22950 (epoch 23.155), train_loss = 0.94938616, grad/param norm = 1.9481e-01, time/batch = 20.5309s	
10629/22950 (epoch 23.157), train_loss = 0.99402404, grad/param norm = 2.0335e-01, time/batch = 17.7668s	
10630/22950 (epoch 23.159), train_loss = 0.92999507, grad/param norm = 1.9920e-01, time/batch = 16.5108s	
10631/22950 (epoch 23.161), train_loss = 0.95950559, grad/param norm = 2.0063e-01, time/batch = 18.5430s	
10632/22950 (epoch 23.163), train_loss = 0.87702167, grad/param norm = 1.9937e-01, time/batch = 17.1978s	
10633/22950 (epoch 23.166), train_loss = 1.11115489, grad/param norm = 2.9128e-01, time/batch = 18.5280s	
10634/22950 (epoch 23.168), train_loss = 1.07063670, grad/param norm = 2.5755e-01, time/batch = 19.2223s	
10635/22950 (epoch 23.170), train_loss = 0.99979770, grad/param norm = 2.1188e-01, time/batch = 18.8002s	
10636/22950 (epoch 23.172), train_loss = 1.04214109, grad/param norm = 2.0710e-01, time/batch = 16.5659s	
10637/22950 (epoch 23.174), train_loss = 1.08747832, grad/param norm = 2.2783e-01, time/batch = 16.2663s	
10638/22950 (epoch 23.176), train_loss = 1.09940689, grad/param norm = 2.3383e-01, time/batch = 16.0167s	
10639/22950 (epoch 23.179), train_loss = 1.05896423, grad/param norm = 2.3703e-01, time/batch = 15.9523s	
10640/22950 (epoch 23.181), train_loss = 1.24852153, grad/param norm = 2.3853e-01, time/batch = 16.1036s	
10641/22950 (epoch 23.183), train_loss = 1.09269975, grad/param norm = 2.2958e-01, time/batch = 15.9465s	
10642/22950 (epoch 23.185), train_loss = 1.04098722, grad/param norm = 2.1842e-01, time/batch = 16.0478s	
10643/22950 (epoch 23.187), train_loss = 0.92384891, grad/param norm = 2.3373e-01, time/batch = 16.5353s	
10644/22950 (epoch 23.190), train_loss = 0.85581804, grad/param norm = 2.0398e-01, time/batch = 16.3640s	
10645/22950 (epoch 23.192), train_loss = 0.85141002, grad/param norm = 1.9531e-01, time/batch = 16.5374s	
10646/22950 (epoch 23.194), train_loss = 0.97799294, grad/param norm = 2.4737e-01, time/batch = 15.4699s	
10647/22950 (epoch 23.196), train_loss = 0.81575683, grad/param norm = 2.2040e-01, time/batch = 17.8865s	
10648/22950 (epoch 23.198), train_loss = 1.08694119, grad/param norm = 2.3210e-01, time/batch = 16.2756s	
10649/22950 (epoch 23.200), train_loss = 0.92131744, grad/param norm = 1.8506e-01, time/batch = 17.9610s	
10650/22950 (epoch 23.203), train_loss = 0.88907463, grad/param norm = 2.3855e-01, time/batch = 18.1929s	
10651/22950 (epoch 23.205), train_loss = 0.96115701, grad/param norm = 2.0570e-01, time/batch = 18.0870s	
10652/22950 (epoch 23.207), train_loss = 0.99361862, grad/param norm = 2.1338e-01, time/batch = 16.0996s	
10653/22950 (epoch 23.209), train_loss = 1.02019599, grad/param norm = 2.4293e-01, time/batch = 16.6106s	
10654/22950 (epoch 23.211), train_loss = 0.82621163, grad/param norm = 2.1149e-01, time/batch = 17.2802s	
10655/22950 (epoch 23.214), train_loss = 0.96661459, grad/param norm = 2.2356e-01, time/batch = 16.8541s	
10656/22950 (epoch 23.216), train_loss = 1.08515156, grad/param norm = 2.1964e-01, time/batch = 19.1731s	
10657/22950 (epoch 23.218), train_loss = 0.99295347, grad/param norm = 2.0152e-01, time/batch = 19.1157s	
10658/22950 (epoch 23.220), train_loss = 1.09028709, grad/param norm = 2.2910e-01, time/batch = 16.5044s	
10659/22950 (epoch 23.222), train_loss = 1.12543949, grad/param norm = 2.4442e-01, time/batch = 16.3637s	
10660/22950 (epoch 23.224), train_loss = 0.98653349, grad/param norm = 2.2285e-01, time/batch = 16.2047s	
10661/22950 (epoch 23.227), train_loss = 1.07495407, grad/param norm = 2.0240e-01, time/batch = 16.4351s	
10662/22950 (epoch 23.229), train_loss = 1.09546943, grad/param norm = 2.2289e-01, time/batch = 16.2354s	
10663/22950 (epoch 23.231), train_loss = 0.87470796, grad/param norm = 2.1755e-01, time/batch = 15.8020s	
10664/22950 (epoch 23.233), train_loss = 0.95677389, grad/param norm = 2.0333e-01, time/batch = 16.3374s	
10665/22950 (epoch 23.235), train_loss = 1.15701479, grad/param norm = 2.2456e-01, time/batch = 15.8843s	
10666/22950 (epoch 23.237), train_loss = 0.93605479, grad/param norm = 2.1779e-01, time/batch = 15.6402s	
10667/22950 (epoch 23.240), train_loss = 1.01088157, grad/param norm = 2.2273e-01, time/batch = 15.9282s	
10668/22950 (epoch 23.242), train_loss = 1.11719516, grad/param norm = 2.0736e-01, time/batch = 16.0292s	
10669/22950 (epoch 23.244), train_loss = 1.13453974, grad/param norm = 2.2913e-01, time/batch = 15.7217s	
10670/22950 (epoch 23.246), train_loss = 1.11504441, grad/param norm = 2.1721e-01, time/batch = 16.2124s	
10671/22950 (epoch 23.248), train_loss = 1.05130770, grad/param norm = 2.1973e-01, time/batch = 16.5788s	
10672/22950 (epoch 23.251), train_loss = 0.94414927, grad/param norm = 2.1340e-01, time/batch = 15.7358s	
10673/22950 (epoch 23.253), train_loss = 0.95787080, grad/param norm = 2.1645e-01, time/batch = 16.1143s	
10674/22950 (epoch 23.255), train_loss = 1.05225594, grad/param norm = 2.6011e-01, time/batch = 15.7296s	
10675/22950 (epoch 23.257), train_loss = 1.11411542, grad/param norm = 2.2039e-01, time/batch = 16.1312s	
10676/22950 (epoch 23.259), train_loss = 0.88144850, grad/param norm = 2.0227e-01, time/batch = 15.7429s	
10677/22950 (epoch 23.261), train_loss = 0.96363460, grad/param norm = 2.3188e-01, time/batch = 16.1209s	
10678/22950 (epoch 23.264), train_loss = 0.91330797, grad/param norm = 2.0904e-01, time/batch = 16.1145s	
10679/22950 (epoch 23.266), train_loss = 1.03212668, grad/param norm = 2.2924e-01, time/batch = 16.6566s	
10680/22950 (epoch 23.268), train_loss = 1.00842510, grad/param norm = 2.4796e-01, time/batch = 16.5169s	
10681/22950 (epoch 23.270), train_loss = 1.00863553, grad/param norm = 2.1456e-01, time/batch = 16.5013s	
10682/22950 (epoch 23.272), train_loss = 1.06689284, grad/param norm = 2.5652e-01, time/batch = 16.0327s	
10683/22950 (epoch 23.275), train_loss = 0.95006323, grad/param norm = 2.2010e-01, time/batch = 15.6581s	
10684/22950 (epoch 23.277), train_loss = 0.84698047, grad/param norm = 1.9066e-01, time/batch = 15.6400s	
10685/22950 (epoch 23.279), train_loss = 0.91471064, grad/param norm = 2.3127e-01, time/batch = 15.7960s	
10686/22950 (epoch 23.281), train_loss = 0.95742361, grad/param norm = 2.2166e-01, time/batch = 16.0478s	
10687/22950 (epoch 23.283), train_loss = 0.86142450, grad/param norm = 1.8129e-01, time/batch = 16.2805s	
10688/22950 (epoch 23.285), train_loss = 1.00956403, grad/param norm = 2.0554e-01, time/batch = 15.7129s	
10689/22950 (epoch 23.288), train_loss = 1.08180137, grad/param norm = 2.1458e-01, time/batch = 15.4903s	
10690/22950 (epoch 23.290), train_loss = 0.95191819, grad/param norm = 2.0597e-01, time/batch = 16.2683s	
10691/22950 (epoch 23.292), train_loss = 1.09705154, grad/param norm = 2.0979e-01, time/batch = 16.0148s	
10692/22950 (epoch 23.294), train_loss = 0.99123238, grad/param norm = 2.1050e-01, time/batch = 16.2522s	
10693/22950 (epoch 23.296), train_loss = 0.78795674, grad/param norm = 1.7814e-01, time/batch = 15.5444s	
10694/22950 (epoch 23.298), train_loss = 1.00347227, grad/param norm = 1.9841e-01, time/batch = 15.7185s	
10695/22950 (epoch 23.301), train_loss = 1.02562190, grad/param norm = 2.2642e-01, time/batch = 15.7783s	
10696/22950 (epoch 23.303), train_loss = 1.01937615, grad/param norm = 2.1864e-01, time/batch = 16.0939s	
10697/22950 (epoch 23.305), train_loss = 1.00990367, grad/param norm = 2.4237e-01, time/batch = 15.7948s	
10698/22950 (epoch 23.307), train_loss = 1.11681614, grad/param norm = 2.4161e-01, time/batch = 15.7165s	
10699/22950 (epoch 23.309), train_loss = 0.93462327, grad/param norm = 1.7974e-01, time/batch = 15.6328s	
10700/22950 (epoch 23.312), train_loss = 1.00642436, grad/param norm = 2.1498e-01, time/batch = 15.6378s	
10701/22950 (epoch 23.314), train_loss = 1.01824613, grad/param norm = 2.0648e-01, time/batch = 15.3708s	
10702/22950 (epoch 23.316), train_loss = 1.00627761, grad/param norm = 2.4213e-01, time/batch = 0.7175s	
10703/22950 (epoch 23.318), train_loss = 0.85091701, grad/param norm = 1.8174e-01, time/batch = 0.7706s	
10704/22950 (epoch 23.320), train_loss = 0.93094165, grad/param norm = 1.9936e-01, time/batch = 0.7348s	
10705/22950 (epoch 23.322), train_loss = 0.96595798, grad/param norm = 2.1060e-01, time/batch = 0.7244s	
10706/22950 (epoch 23.325), train_loss = 0.80235733, grad/param norm = 1.8709e-01, time/batch = 0.7256s	
10707/22950 (epoch 23.327), train_loss = 0.82091539, grad/param norm = 1.8876e-01, time/batch = 0.7244s	
10708/22950 (epoch 23.329), train_loss = 0.93533333, grad/param norm = 2.0950e-01, time/batch = 0.7841s	
10709/22950 (epoch 23.331), train_loss = 0.85593195, grad/param norm = 1.9032e-01, time/batch = 1.0509s	
10710/22950 (epoch 23.333), train_loss = 0.96750344, grad/param norm = 2.1148e-01, time/batch = 1.0611s	
10711/22950 (epoch 23.336), train_loss = 0.96803437, grad/param norm = 2.1741e-01, time/batch = 1.0681s	
10712/22950 (epoch 23.338), train_loss = 0.98993126, grad/param norm = 2.1235e-01, time/batch = 1.0690s	
10713/22950 (epoch 23.340), train_loss = 0.98301058, grad/param norm = 2.3532e-01, time/batch = 1.5585s	
10714/22950 (epoch 23.342), train_loss = 1.08858343, grad/param norm = 2.1060e-01, time/batch = 1.9645s	
10715/22950 (epoch 23.344), train_loss = 0.96288835, grad/param norm = 2.0864e-01, time/batch = 1.9612s	
10716/22950 (epoch 23.346), train_loss = 1.06980765, grad/param norm = 2.2878e-01, time/batch = 16.5918s	
10717/22950 (epoch 23.349), train_loss = 0.99632059, grad/param norm = 2.2239e-01, time/batch = 16.3773s	
10718/22950 (epoch 23.351), train_loss = 0.99786883, grad/param norm = 2.0672e-01, time/batch = 16.5291s	
10719/22950 (epoch 23.353), train_loss = 1.06401805, grad/param norm = 2.5414e-01, time/batch = 16.4446s	
10720/22950 (epoch 23.355), train_loss = 1.14707714, grad/param norm = 2.7699e-01, time/batch = 15.5559s	
10721/22950 (epoch 23.357), train_loss = 1.01586321, grad/param norm = 2.5447e-01, time/batch = 15.5446s	
10722/22950 (epoch 23.359), train_loss = 1.00102514, grad/param norm = 2.1213e-01, time/batch = 15.7087s	
10723/22950 (epoch 23.362), train_loss = 1.02175334, grad/param norm = 2.3314e-01, time/batch = 15.4897s	
10724/22950 (epoch 23.364), train_loss = 0.99832425, grad/param norm = 2.3484e-01, time/batch = 16.0965s	
10725/22950 (epoch 23.366), train_loss = 0.96912738, grad/param norm = 2.1090e-01, time/batch = 15.5349s	
10726/22950 (epoch 23.368), train_loss = 1.06529312, grad/param norm = 2.3593e-01, time/batch = 16.7291s	
10727/22950 (epoch 23.370), train_loss = 0.96741080, grad/param norm = 2.2262e-01, time/batch = 16.0590s	
10728/22950 (epoch 23.373), train_loss = 0.88403720, grad/param norm = 1.9815e-01, time/batch = 16.0450s	
10729/22950 (epoch 23.375), train_loss = 1.10723058, grad/param norm = 2.3620e-01, time/batch = 16.9147s	
10730/22950 (epoch 23.377), train_loss = 0.90084257, grad/param norm = 2.2407e-01, time/batch = 16.2759s	
10731/22950 (epoch 23.379), train_loss = 1.03095661, grad/param norm = 2.3691e-01, time/batch = 16.9207s	
10732/22950 (epoch 23.381), train_loss = 0.87315659, grad/param norm = 2.1259e-01, time/batch = 16.9551s	
10733/22950 (epoch 23.383), train_loss = 0.97226106, grad/param norm = 2.1780e-01, time/batch = 16.8284s	
10734/22950 (epoch 23.386), train_loss = 0.92586500, grad/param norm = 2.2618e-01, time/batch = 15.9334s	
10735/22950 (epoch 23.388), train_loss = 1.00487318, grad/param norm = 2.3237e-01, time/batch = 16.0258s	
10736/22950 (epoch 23.390), train_loss = 0.87888028, grad/param norm = 2.0602e-01, time/batch = 15.8002s	
10737/22950 (epoch 23.392), train_loss = 0.93730999, grad/param norm = 2.1003e-01, time/batch = 16.2665s	
10738/22950 (epoch 23.394), train_loss = 0.92572175, grad/param norm = 2.1345e-01, time/batch = 16.8764s	
10739/22950 (epoch 23.397), train_loss = 1.13055079, grad/param norm = 2.1855e-01, time/batch = 15.5656s	
10740/22950 (epoch 23.399), train_loss = 1.14379447, grad/param norm = 2.3363e-01, time/batch = 16.3608s	
10741/22950 (epoch 23.401), train_loss = 1.17560027, grad/param norm = 2.5655e-01, time/batch = 16.5278s	
10742/22950 (epoch 23.403), train_loss = 0.96520981, grad/param norm = 2.3666e-01, time/batch = 16.3391s	
10743/22950 (epoch 23.405), train_loss = 1.10541183, grad/param norm = 2.3307e-01, time/batch = 16.1320s	
10744/22950 (epoch 23.407), train_loss = 1.16226648, grad/param norm = 2.2245e-01, time/batch = 16.3634s	
10745/22950 (epoch 23.410), train_loss = 0.95577434, grad/param norm = 2.0285e-01, time/batch = 15.9619s	
10746/22950 (epoch 23.412), train_loss = 0.98205674, grad/param norm = 2.1807e-01, time/batch = 15.7886s	
10747/22950 (epoch 23.414), train_loss = 1.10011827, grad/param norm = 2.2273e-01, time/batch = 16.0951s	
10748/22950 (epoch 23.416), train_loss = 1.03942890, grad/param norm = 2.4966e-01, time/batch = 15.7116s	
10749/22950 (epoch 23.418), train_loss = 1.02981778, grad/param norm = 2.7001e-01, time/batch = 15.8734s	
10750/22950 (epoch 23.420), train_loss = 1.08107724, grad/param norm = 2.6253e-01, time/batch = 15.6408s	
10751/22950 (epoch 23.423), train_loss = 0.93828623, grad/param norm = 2.0062e-01, time/batch = 16.1780s	
10752/22950 (epoch 23.425), train_loss = 0.97508645, grad/param norm = 2.1372e-01, time/batch = 15.3978s	
10753/22950 (epoch 23.427), train_loss = 0.98128585, grad/param norm = 2.2165e-01, time/batch = 15.6319s	
10754/22950 (epoch 23.429), train_loss = 0.97898647, grad/param norm = 2.0739e-01, time/batch = 15.4739s	
10755/22950 (epoch 23.431), train_loss = 1.06673129, grad/param norm = 2.4803e-01, time/batch = 16.5557s	
10756/22950 (epoch 23.434), train_loss = 1.00056013, grad/param norm = 2.2407e-01, time/batch = 17.1604s	
10757/22950 (epoch 23.436), train_loss = 1.08836297, grad/param norm = 2.4271e-01, time/batch = 16.4691s	
10758/22950 (epoch 23.438), train_loss = 1.05416830, grad/param norm = 2.3074e-01, time/batch = 16.5395s	
10759/22950 (epoch 23.440), train_loss = 1.11617112, grad/param norm = 2.3079e-01, time/batch = 16.8297s	
10760/22950 (epoch 23.442), train_loss = 1.19260514, grad/param norm = 2.5430e-01, time/batch = 16.8163s	
10761/22950 (epoch 23.444), train_loss = 1.08069432, grad/param norm = 2.3417e-01, time/batch = 17.5321s	
10762/22950 (epoch 23.447), train_loss = 1.19313616, grad/param norm = 2.4807e-01, time/batch = 17.6190s	
10763/22950 (epoch 23.449), train_loss = 0.90718706, grad/param norm = 2.0437e-01, time/batch = 17.3089s	
10764/22950 (epoch 23.451), train_loss = 1.02769983, grad/param norm = 2.2173e-01, time/batch = 17.3653s	
10765/22950 (epoch 23.453), train_loss = 1.04695061, grad/param norm = 2.0269e-01, time/batch = 17.3530s	
10766/22950 (epoch 23.455), train_loss = 0.96251232, grad/param norm = 1.9182e-01, time/batch = 16.9316s	
10767/22950 (epoch 23.458), train_loss = 1.05822824, grad/param norm = 2.2284e-01, time/batch = 16.8418s	
10768/22950 (epoch 23.460), train_loss = 1.06062849, grad/param norm = 2.0389e-01, time/batch = 16.3924s	
10769/22950 (epoch 23.462), train_loss = 1.02536791, grad/param norm = 2.2338e-01, time/batch = 16.8531s	
10770/22950 (epoch 23.464), train_loss = 0.97289626, grad/param norm = 2.0932e-01, time/batch = 16.6278s	
10771/22950 (epoch 23.466), train_loss = 1.07055278, grad/param norm = 2.1825e-01, time/batch = 16.6989s	
10772/22950 (epoch 23.468), train_loss = 1.10461495, grad/param norm = 2.2442e-01, time/batch = 16.6256s	
10773/22950 (epoch 23.471), train_loss = 1.06644617, grad/param norm = 2.5755e-01, time/batch = 16.9771s	
10774/22950 (epoch 23.473), train_loss = 1.07558653, grad/param norm = 2.2788e-01, time/batch = 16.8446s	
10775/22950 (epoch 23.475), train_loss = 1.20598598, grad/param norm = 2.3934e-01, time/batch = 16.4679s	
10776/22950 (epoch 23.477), train_loss = 1.01416861, grad/param norm = 2.1038e-01, time/batch = 16.5416s	
10777/22950 (epoch 23.479), train_loss = 0.92166489, grad/param norm = 1.9805e-01, time/batch = 16.4739s	
10778/22950 (epoch 23.481), train_loss = 1.09466649, grad/param norm = 2.5371e-01, time/batch = 16.6203s	
10779/22950 (epoch 23.484), train_loss = 1.04637507, grad/param norm = 2.5138e-01, time/batch = 16.4485s	
10780/22950 (epoch 23.486), train_loss = 0.88255877, grad/param norm = 2.5668e-01, time/batch = 16.6808s	
10781/22950 (epoch 23.488), train_loss = 0.96819337, grad/param norm = 2.6097e-01, time/batch = 16.6082s	
10782/22950 (epoch 23.490), train_loss = 0.89040584, grad/param norm = 2.2547e-01, time/batch = 16.3011s	
10783/22950 (epoch 23.492), train_loss = 0.98546981, grad/param norm = 2.4295e-01, time/batch = 16.0808s	
10784/22950 (epoch 23.495), train_loss = 0.96626232, grad/param norm = 2.2271e-01, time/batch = 16.1100s	
10785/22950 (epoch 23.497), train_loss = 1.07045992, grad/param norm = 2.2873e-01, time/batch = 15.6376s	
10786/22950 (epoch 23.499), train_loss = 1.13985499, grad/param norm = 2.1017e-01, time/batch = 15.3077s	
10787/22950 (epoch 23.501), train_loss = 1.08490571, grad/param norm = 2.4014e-01, time/batch = 23.7496s	
10788/22950 (epoch 23.503), train_loss = 1.10559562, grad/param norm = 2.0889e-01, time/batch = 21.9765s	
10789/22950 (epoch 23.505), train_loss = 0.90402959, grad/param norm = 1.9056e-01, time/batch = 16.7968s	
10790/22950 (epoch 23.508), train_loss = 1.05659950, grad/param norm = 2.1976e-01, time/batch = 16.7329s	
10791/22950 (epoch 23.510), train_loss = 1.00349951, grad/param norm = 2.1641e-01, time/batch = 16.2608s	
10792/22950 (epoch 23.512), train_loss = 0.89608541, grad/param norm = 2.1273e-01, time/batch = 16.7798s	
10793/22950 (epoch 23.514), train_loss = 0.94370382, grad/param norm = 1.8458e-01, time/batch = 16.7096s	
10794/22950 (epoch 23.516), train_loss = 0.98639233, grad/param norm = 2.2091e-01, time/batch = 16.8895s	
10795/22950 (epoch 23.519), train_loss = 0.98527038, grad/param norm = 2.0008e-01, time/batch = 16.5379s	
10796/22950 (epoch 23.521), train_loss = 0.99573037, grad/param norm = 2.1920e-01, time/batch = 16.8038s	
10797/22950 (epoch 23.523), train_loss = 0.81656576, grad/param norm = 2.0513e-01, time/batch = 16.9516s	
10798/22950 (epoch 23.525), train_loss = 0.90696609, grad/param norm = 1.8845e-01, time/batch = 17.3082s	
10799/22950 (epoch 23.527), train_loss = 0.85949673, grad/param norm = 2.0834e-01, time/batch = 17.2908s	
10800/22950 (epoch 23.529), train_loss = 1.02472594, grad/param norm = 2.2323e-01, time/batch = 17.2670s	
10801/22950 (epoch 23.532), train_loss = 0.96756794, grad/param norm = 2.1044e-01, time/batch = 17.3806s	
10802/22950 (epoch 23.534), train_loss = 1.05478428, grad/param norm = 2.3616e-01, time/batch = 16.8127s	
10803/22950 (epoch 23.536), train_loss = 1.05001725, grad/param norm = 2.2515e-01, time/batch = 16.5458s	
10804/22950 (epoch 23.538), train_loss = 1.04570700, grad/param norm = 2.3860e-01, time/batch = 16.8433s	
10805/22950 (epoch 23.540), train_loss = 1.06392849, grad/param norm = 2.6390e-01, time/batch = 16.7542s	
10806/22950 (epoch 23.542), train_loss = 1.15907257, grad/param norm = 2.2932e-01, time/batch = 16.4557s	
10807/22950 (epoch 23.545), train_loss = 0.96934690, grad/param norm = 1.9877e-01, time/batch = 16.7915s	
10808/22950 (epoch 23.547), train_loss = 0.98440458, grad/param norm = 2.1292e-01, time/batch = 17.0867s	
10809/22950 (epoch 23.549), train_loss = 0.93520920, grad/param norm = 2.0467e-01, time/batch = 16.8263s	
10810/22950 (epoch 23.551), train_loss = 0.99079012, grad/param norm = 2.3072e-01, time/batch = 16.6045s	
10811/22950 (epoch 23.553), train_loss = 0.96967904, grad/param norm = 2.4135e-01, time/batch = 17.2432s	
10812/22950 (epoch 23.556), train_loss = 1.04144874, grad/param norm = 2.1162e-01, time/batch = 17.2378s	
10813/22950 (epoch 23.558), train_loss = 0.88888902, grad/param norm = 2.1535e-01, time/batch = 17.2724s	
10814/22950 (epoch 23.560), train_loss = 0.99158294, grad/param norm = 2.1021e-01, time/batch = 17.0150s	
10815/22950 (epoch 23.562), train_loss = 0.93747480, grad/param norm = 2.1428e-01, time/batch = 17.2984s	
10816/22950 (epoch 23.564), train_loss = 1.06934282, grad/param norm = 2.5189e-01, time/batch = 16.9581s	
10817/22950 (epoch 23.566), train_loss = 1.02553167, grad/param norm = 2.1598e-01, time/batch = 17.1339s	
10818/22950 (epoch 23.569), train_loss = 1.01016611, grad/param norm = 2.1053e-01, time/batch = 17.1234s	
10819/22950 (epoch 23.571), train_loss = 0.99056058, grad/param norm = 2.3318e-01, time/batch = 17.0558s	
10820/22950 (epoch 23.573), train_loss = 1.00323459, grad/param norm = 2.2732e-01, time/batch = 17.1218s	
10821/22950 (epoch 23.575), train_loss = 1.12768766, grad/param norm = 2.6164e-01, time/batch = 17.3028s	
10822/22950 (epoch 23.577), train_loss = 1.02929765, grad/param norm = 2.6029e-01, time/batch = 17.1940s	
10823/22950 (epoch 23.580), train_loss = 1.04784695, grad/param norm = 2.3157e-01, time/batch = 16.8968s	
10824/22950 (epoch 23.582), train_loss = 1.18700962, grad/param norm = 2.3415e-01, time/batch = 16.9723s	
10825/22950 (epoch 23.584), train_loss = 0.87120941, grad/param norm = 2.0037e-01, time/batch = 17.1294s	
10826/22950 (epoch 23.586), train_loss = 0.94527846, grad/param norm = 2.2399e-01, time/batch = 17.4477s	
10827/22950 (epoch 23.588), train_loss = 1.13757665, grad/param norm = 2.2507e-01, time/batch = 17.1526s	
10828/22950 (epoch 23.590), train_loss = 1.01621962, grad/param norm = 2.0683e-01, time/batch = 17.2923s	
10829/22950 (epoch 23.593), train_loss = 0.97568229, grad/param norm = 2.3169e-01, time/batch = 17.2697s	
10830/22950 (epoch 23.595), train_loss = 0.89399549, grad/param norm = 2.0872e-01, time/batch = 17.2538s	
10831/22950 (epoch 23.597), train_loss = 1.08321473, grad/param norm = 2.3554e-01, time/batch = 17.3110s	
10832/22950 (epoch 23.599), train_loss = 1.02677094, grad/param norm = 2.3401e-01, time/batch = 17.2563s	
10833/22950 (epoch 23.601), train_loss = 1.05501462, grad/param norm = 2.3000e-01, time/batch = 17.0993s	
10834/22950 (epoch 23.603), train_loss = 1.14357260, grad/param norm = 2.3234e-01, time/batch = 17.1794s	
10835/22950 (epoch 23.606), train_loss = 1.01654702, grad/param norm = 2.4049e-01, time/batch = 16.9894s	
10836/22950 (epoch 23.608), train_loss = 1.05380926, grad/param norm = 2.3043e-01, time/batch = 16.4642s	
10837/22950 (epoch 23.610), train_loss = 1.00503043, grad/param norm = 2.1837e-01, time/batch = 17.2174s	
10838/22950 (epoch 23.612), train_loss = 0.98597241, grad/param norm = 2.0709e-01, time/batch = 16.9603s	
10839/22950 (epoch 23.614), train_loss = 1.12440860, grad/param norm = 2.3570e-01, time/batch = 17.0351s	
10840/22950 (epoch 23.617), train_loss = 0.99413204, grad/param norm = 2.2935e-01, time/batch = 17.0334s	
10841/22950 (epoch 23.619), train_loss = 0.97088840, grad/param norm = 1.9703e-01, time/batch = 17.1409s	
10842/22950 (epoch 23.621), train_loss = 1.10163643, grad/param norm = 2.0664e-01, time/batch = 17.3335s	
10843/22950 (epoch 23.623), train_loss = 1.09611283, grad/param norm = 2.2373e-01, time/batch = 17.1133s	
10844/22950 (epoch 23.625), train_loss = 0.97429938, grad/param norm = 2.0834e-01, time/batch = 16.9870s	
10845/22950 (epoch 23.627), train_loss = 0.97964349, grad/param norm = 2.3273e-01, time/batch = 17.1302s	
10846/22950 (epoch 23.630), train_loss = 0.87865837, grad/param norm = 1.9687e-01, time/batch = 17.1993s	
10847/22950 (epoch 23.632), train_loss = 0.96404963, grad/param norm = 2.3449e-01, time/batch = 16.8901s	
10848/22950 (epoch 23.634), train_loss = 1.02929663, grad/param norm = 2.3056e-01, time/batch = 16.9971s	
10849/22950 (epoch 23.636), train_loss = 1.05182276, grad/param norm = 2.3197e-01, time/batch = 17.3378s	
10850/22950 (epoch 23.638), train_loss = 0.93653659, grad/param norm = 2.0807e-01, time/batch = 17.2143s	
10851/22950 (epoch 23.641), train_loss = 0.99219719, grad/param norm = 2.1618e-01, time/batch = 17.3735s	
10852/22950 (epoch 23.643), train_loss = 1.05273043, grad/param norm = 2.5038e-01, time/batch = 17.2706s	
10853/22950 (epoch 23.645), train_loss = 0.96306885, grad/param norm = 2.0709e-01, time/batch = 17.4738s	
10854/22950 (epoch 23.647), train_loss = 0.99691284, grad/param norm = 2.3693e-01, time/batch = 17.3327s	
10855/22950 (epoch 23.649), train_loss = 0.98188610, grad/param norm = 2.2770e-01, time/batch = 17.2043s	
10856/22950 (epoch 23.651), train_loss = 1.06623486, grad/param norm = 2.3943e-01, time/batch = 17.3316s	
10857/22950 (epoch 23.654), train_loss = 0.84465363, grad/param norm = 2.0257e-01, time/batch = 17.5415s	
10858/22950 (epoch 23.656), train_loss = 1.08993706, grad/param norm = 2.6367e-01, time/batch = 17.3874s	
10859/22950 (epoch 23.658), train_loss = 0.91977238, grad/param norm = 2.1839e-01, time/batch = 17.3032s	
10860/22950 (epoch 23.660), train_loss = 0.83692148, grad/param norm = 2.3740e-01, time/batch = 17.3195s	
10861/22950 (epoch 23.662), train_loss = 0.84653014, grad/param norm = 2.1840e-01, time/batch = 17.2933s	
10862/22950 (epoch 23.664), train_loss = 0.98319197, grad/param norm = 2.1759e-01, time/batch = 17.3548s	
10863/22950 (epoch 23.667), train_loss = 0.99990946, grad/param norm = 2.1518e-01, time/batch = 17.0258s	
10864/22950 (epoch 23.669), train_loss = 1.00857742, grad/param norm = 2.3013e-01, time/batch = 16.9522s	
10865/22950 (epoch 23.671), train_loss = 1.00243033, grad/param norm = 2.1558e-01, time/batch = 16.9065s	
10866/22950 (epoch 23.673), train_loss = 0.94163406, grad/param norm = 2.1279e-01, time/batch = 17.1038s	
10867/22950 (epoch 23.675), train_loss = 1.00718686, grad/param norm = 2.2480e-01, time/batch = 17.2291s	
10868/22950 (epoch 23.678), train_loss = 1.01254087, grad/param norm = 2.1858e-01, time/batch = 17.3800s	
10869/22950 (epoch 23.680), train_loss = 0.99407790, grad/param norm = 2.0045e-01, time/batch = 17.3933s	
10870/22950 (epoch 23.682), train_loss = 0.99427814, grad/param norm = 2.2454e-01, time/batch = 17.2478s	
10871/22950 (epoch 23.684), train_loss = 1.09916586, grad/param norm = 2.4145e-01, time/batch = 17.3037s	
10872/22950 (epoch 23.686), train_loss = 1.08681756, grad/param norm = 2.1987e-01, time/batch = 17.2230s	
10873/22950 (epoch 23.688), train_loss = 1.04872875, grad/param norm = 2.2545e-01, time/batch = 17.2222s	
10874/22950 (epoch 23.691), train_loss = 1.00945253, grad/param norm = 2.3177e-01, time/batch = 17.6817s	
10875/22950 (epoch 23.693), train_loss = 0.92716522, grad/param norm = 2.1867e-01, time/batch = 17.2599s	
10876/22950 (epoch 23.695), train_loss = 1.10990749, grad/param norm = 2.2827e-01, time/batch = 17.2142s	
10877/22950 (epoch 23.697), train_loss = 1.05628377, grad/param norm = 2.2955e-01, time/batch = 17.1961s	
10878/22950 (epoch 23.699), train_loss = 1.06344064, grad/param norm = 2.1510e-01, time/batch = 16.9314s	
10879/22950 (epoch 23.702), train_loss = 1.06252584, grad/param norm = 2.3352e-01, time/batch = 17.0484s	
10880/22950 (epoch 23.704), train_loss = 1.10550329, grad/param norm = 2.2539e-01, time/batch = 17.1311s	
10881/22950 (epoch 23.706), train_loss = 1.10699577, grad/param norm = 2.4622e-01, time/batch = 17.2205s	
10882/22950 (epoch 23.708), train_loss = 0.89129496, grad/param norm = 2.1232e-01, time/batch = 17.1860s	
10883/22950 (epoch 23.710), train_loss = 1.02924285, grad/param norm = 2.2436e-01, time/batch = 17.3200s	
10884/22950 (epoch 23.712), train_loss = 1.13538472, grad/param norm = 2.3757e-01, time/batch = 17.2711s	
10885/22950 (epoch 23.715), train_loss = 1.02961629, grad/param norm = 2.4486e-01, time/batch = 17.3040s	
10886/22950 (epoch 23.717), train_loss = 1.02423316, grad/param norm = 2.0613e-01, time/batch = 17.2078s	
10887/22950 (epoch 23.719), train_loss = 0.97453662, grad/param norm = 2.2565e-01, time/batch = 17.3319s	
10888/22950 (epoch 23.721), train_loss = 1.05603478, grad/param norm = 2.1402e-01, time/batch = 16.9210s	
10889/22950 (epoch 23.723), train_loss = 0.98474177, grad/param norm = 2.0937e-01, time/batch = 17.0350s	
10890/22950 (epoch 23.725), train_loss = 1.06830730, grad/param norm = 2.5460e-01, time/batch = 17.2163s	
10891/22950 (epoch 23.728), train_loss = 0.99683193, grad/param norm = 2.6295e-01, time/batch = 17.5806s	
10892/22950 (epoch 23.730), train_loss = 0.96400389, grad/param norm = 2.0658e-01, time/batch = 17.4431s	
10893/22950 (epoch 23.732), train_loss = 1.07013996, grad/param norm = 2.2802e-01, time/batch = 17.3350s	
10894/22950 (epoch 23.734), train_loss = 1.00142884, grad/param norm = 2.3920e-01, time/batch = 17.2938s	
10895/22950 (epoch 23.736), train_loss = 1.01268296, grad/param norm = 2.0782e-01, time/batch = 17.4345s	
10896/22950 (epoch 23.739), train_loss = 1.07710456, grad/param norm = 2.3901e-01, time/batch = 17.3185s	
10897/22950 (epoch 23.741), train_loss = 1.10373250, grad/param norm = 2.6976e-01, time/batch = 17.2102s	
10898/22950 (epoch 23.743), train_loss = 1.17378421, grad/param norm = 2.6938e-01, time/batch = 17.2385s	
10899/22950 (epoch 23.745), train_loss = 1.25548330, grad/param norm = 2.5287e-01, time/batch = 17.0682s	
10900/22950 (epoch 23.747), train_loss = 1.02071947, grad/param norm = 2.0755e-01, time/batch = 17.1354s	
10901/22950 (epoch 23.749), train_loss = 0.94217321, grad/param norm = 2.1189e-01, time/batch = 17.2076s	
10902/22950 (epoch 23.752), train_loss = 1.20374864, grad/param norm = 2.6202e-01, time/batch = 17.2943s	
10903/22950 (epoch 23.754), train_loss = 1.09288398, grad/param norm = 2.3817e-01, time/batch = 17.0862s	
10904/22950 (epoch 23.756), train_loss = 0.95236835, grad/param norm = 2.2292e-01, time/batch = 17.3568s	
10905/22950 (epoch 23.758), train_loss = 0.99987884, grad/param norm = 1.9591e-01, time/batch = 17.2275s	
10906/22950 (epoch 23.760), train_loss = 1.07366180, grad/param norm = 2.2612e-01, time/batch = 17.2962s	
10907/22950 (epoch 23.763), train_loss = 1.09694352, grad/param norm = 2.2614e-01, time/batch = 17.3005s	
10908/22950 (epoch 23.765), train_loss = 1.06705631, grad/param norm = 2.3180e-01, time/batch = 17.3383s	
10909/22950 (epoch 23.767), train_loss = 1.23669463, grad/param norm = 2.6116e-01, time/batch = 17.1205s	
10910/22950 (epoch 23.769), train_loss = 1.05329202, grad/param norm = 2.2162e-01, time/batch = 16.7352s	
10911/22950 (epoch 23.771), train_loss = 0.88384465, grad/param norm = 2.3224e-01, time/batch = 16.8799s	
10912/22950 (epoch 23.773), train_loss = 0.78807304, grad/param norm = 1.9059e-01, time/batch = 16.8573s	
10913/22950 (epoch 23.776), train_loss = 0.92938414, grad/param norm = 2.0102e-01, time/batch = 16.7846s	
10914/22950 (epoch 23.778), train_loss = 0.93723682, grad/param norm = 2.1274e-01, time/batch = 16.8800s	
10915/22950 (epoch 23.780), train_loss = 1.02228225, grad/param norm = 2.0406e-01, time/batch = 16.7878s	
10916/22950 (epoch 23.782), train_loss = 1.04254383, grad/param norm = 2.1549e-01, time/batch = 16.7747s	
10917/22950 (epoch 23.784), train_loss = 0.97073634, grad/param norm = 2.1788e-01, time/batch = 16.8541s	
10918/22950 (epoch 23.786), train_loss = 1.04910141, grad/param norm = 2.1847e-01, time/batch = 16.6443s	
10919/22950 (epoch 23.789), train_loss = 0.88789435, grad/param norm = 2.1792e-01, time/batch = 16.6107s	
10920/22950 (epoch 23.791), train_loss = 0.92833543, grad/param norm = 2.2602e-01, time/batch = 16.4667s	
10921/22950 (epoch 23.793), train_loss = 1.16618237, grad/param norm = 2.3438e-01, time/batch = 16.8703s	
10922/22950 (epoch 23.795), train_loss = 0.97969058, grad/param norm = 1.9607e-01, time/batch = 17.0425s	
10923/22950 (epoch 23.797), train_loss = 1.16445476, grad/param norm = 2.4940e-01, time/batch = 16.5515s	
10924/22950 (epoch 23.800), train_loss = 0.93648189, grad/param norm = 2.1723e-01, time/batch = 16.9991s	
10925/22950 (epoch 23.802), train_loss = 0.94794689, grad/param norm = 2.2340e-01, time/batch = 17.1419s	
10926/22950 (epoch 23.804), train_loss = 0.98466313, grad/param norm = 2.1218e-01, time/batch = 17.0795s	
10927/22950 (epoch 23.806), train_loss = 0.90285026, grad/param norm = 2.0833e-01, time/batch = 16.7932s	
10928/22950 (epoch 23.808), train_loss = 1.00302891, grad/param norm = 2.1761e-01, time/batch = 16.7029s	
10929/22950 (epoch 23.810), train_loss = 0.96074066, grad/param norm = 2.1431e-01, time/batch = 16.6373s	
10930/22950 (epoch 23.813), train_loss = 0.83072119, grad/param norm = 2.0491e-01, time/batch = 16.9250s	
10931/22950 (epoch 23.815), train_loss = 0.85444087, grad/param norm = 2.2365e-01, time/batch = 16.9162s	
10932/22950 (epoch 23.817), train_loss = 0.90030482, grad/param norm = 2.0238e-01, time/batch = 16.3957s	
10933/22950 (epoch 23.819), train_loss = 0.99463896, grad/param norm = 2.1484e-01, time/batch = 16.4404s	
10934/22950 (epoch 23.821), train_loss = 0.94490832, grad/param norm = 2.2002e-01, time/batch = 16.3785s	
10935/22950 (epoch 23.824), train_loss = 1.01048829, grad/param norm = 2.3788e-01, time/batch = 16.6381s	
10936/22950 (epoch 23.826), train_loss = 1.11806987, grad/param norm = 2.4699e-01, time/batch = 16.6344s	
10937/22950 (epoch 23.828), train_loss = 0.98457260, grad/param norm = 2.1494e-01, time/batch = 16.8703s	
10938/22950 (epoch 23.830), train_loss = 0.97375313, grad/param norm = 2.0904e-01, time/batch = 16.7359s	
10939/22950 (epoch 23.832), train_loss = 1.01398054, grad/param norm = 2.2304e-01, time/batch = 16.7273s	
10940/22950 (epoch 23.834), train_loss = 0.85086587, grad/param norm = 2.0567e-01, time/batch = 16.5387s	
10941/22950 (epoch 23.837), train_loss = 1.01653066, grad/param norm = 2.4770e-01, time/batch = 16.6352s	
10942/22950 (epoch 23.839), train_loss = 0.87455992, grad/param norm = 2.2280e-01, time/batch = 16.4741s	
10943/22950 (epoch 23.841), train_loss = 0.93537345, grad/param norm = 1.9450e-01, time/batch = 16.4795s	
10944/22950 (epoch 23.843), train_loss = 0.95671071, grad/param norm = 2.2633e-01, time/batch = 17.0779s	
10945/22950 (epoch 23.845), train_loss = 1.01433703, grad/param norm = 2.3301e-01, time/batch = 16.9160s	
10946/22950 (epoch 23.847), train_loss = 1.06509279, grad/param norm = 2.4707e-01, time/batch = 16.6414s	
10947/22950 (epoch 23.850), train_loss = 1.04638565, grad/param norm = 2.3488e-01, time/batch = 16.6212s	
10948/22950 (epoch 23.852), train_loss = 1.06724161, grad/param norm = 2.2897e-01, time/batch = 16.7399s	
10949/22950 (epoch 23.854), train_loss = 0.97532729, grad/param norm = 2.1629e-01, time/batch = 16.9930s	
10950/22950 (epoch 23.856), train_loss = 1.14464873, grad/param norm = 2.8926e-01, time/batch = 16.9636s	
10951/22950 (epoch 23.858), train_loss = 1.05307653, grad/param norm = 2.1928e-01, time/batch = 17.2887s	
10952/22950 (epoch 23.861), train_loss = 1.10091316, grad/param norm = 2.4812e-01, time/batch = 16.6471s	
10953/22950 (epoch 23.863), train_loss = 1.12166130, grad/param norm = 2.5779e-01, time/batch = 16.9658s	
10954/22950 (epoch 23.865), train_loss = 1.15983998, grad/param norm = 2.4498e-01, time/batch = 16.9458s	
10955/22950 (epoch 23.867), train_loss = 1.02913615, grad/param norm = 2.2392e-01, time/batch = 17.1389s	
10956/22950 (epoch 23.869), train_loss = 1.16569559, grad/param norm = 2.4716e-01, time/batch = 16.9650s	
10957/22950 (epoch 23.871), train_loss = 1.03792867, grad/param norm = 2.2930e-01, time/batch = 16.9686s	
10958/22950 (epoch 23.874), train_loss = 1.02630371, grad/param norm = 2.2019e-01, time/batch = 16.8419s	
10959/22950 (epoch 23.876), train_loss = 1.06457410, grad/param norm = 2.1789e-01, time/batch = 16.4843s	
10960/22950 (epoch 23.878), train_loss = 0.97030703, grad/param norm = 2.5638e-01, time/batch = 16.7318s	
10961/22950 (epoch 23.880), train_loss = 1.18627349, grad/param norm = 2.6687e-01, time/batch = 16.3767s	
10962/22950 (epoch 23.882), train_loss = 0.92053823, grad/param norm = 2.1835e-01, time/batch = 16.2064s	
10963/22950 (epoch 23.885), train_loss = 1.04970159, grad/param norm = 2.1207e-01, time/batch = 15.7322s	
10964/22950 (epoch 23.887), train_loss = 1.01636096, grad/param norm = 2.3060e-01, time/batch = 15.8145s	
10965/22950 (epoch 23.889), train_loss = 1.05041265, grad/param norm = 2.2634e-01, time/batch = 16.3520s	
10966/22950 (epoch 23.891), train_loss = 0.96177982, grad/param norm = 2.1869e-01, time/batch = 16.8034s	
10967/22950 (epoch 23.893), train_loss = 1.08611920, grad/param norm = 2.2385e-01, time/batch = 16.4174s	
10968/22950 (epoch 23.895), train_loss = 1.17820400, grad/param norm = 2.8332e-01, time/batch = 15.5649s	
10969/22950 (epoch 23.898), train_loss = 1.01592386, grad/param norm = 2.1693e-01, time/batch = 16.2869s	
10970/22950 (epoch 23.900), train_loss = 1.00293304, grad/param norm = 2.1951e-01, time/batch = 16.1137s	
10971/22950 (epoch 23.902), train_loss = 1.03708042, grad/param norm = 2.1930e-01, time/batch = 16.4438s	
10972/22950 (epoch 23.904), train_loss = 1.03065650, grad/param norm = 2.2198e-01, time/batch = 15.9720s	
10973/22950 (epoch 23.906), train_loss = 1.06794959, grad/param norm = 2.3998e-01, time/batch = 15.8868s	
10974/22950 (epoch 23.908), train_loss = 0.90684237, grad/param norm = 1.9222e-01, time/batch = 15.7256s	
10975/22950 (epoch 23.911), train_loss = 0.89231927, grad/param norm = 2.0054e-01, time/batch = 15.5578s	
10976/22950 (epoch 23.913), train_loss = 0.97032275, grad/param norm = 2.2860e-01, time/batch = 15.7803s	
10977/22950 (epoch 23.915), train_loss = 1.14704571, grad/param norm = 2.3985e-01, time/batch = 15.7262s	
10978/22950 (epoch 23.917), train_loss = 0.90500293, grad/param norm = 2.0535e-01, time/batch = 15.6414s	
10979/22950 (epoch 23.919), train_loss = 1.00616505, grad/param norm = 2.1853e-01, time/batch = 15.4941s	
10980/22950 (epoch 23.922), train_loss = 1.02379294, grad/param norm = 2.1767e-01, time/batch = 16.3407s	
10981/22950 (epoch 23.924), train_loss = 1.05791555, grad/param norm = 2.3791e-01, time/batch = 15.7176s	
10982/22950 (epoch 23.926), train_loss = 0.87270145, grad/param norm = 2.1583e-01, time/batch = 15.8019s	
10983/22950 (epoch 23.928), train_loss = 0.89425337, grad/param norm = 2.0698e-01, time/batch = 15.4815s	
10984/22950 (epoch 23.930), train_loss = 0.89016488, grad/param norm = 2.1777e-01, time/batch = 15.9500s	
10985/22950 (epoch 23.932), train_loss = 0.86237073, grad/param norm = 1.9428e-01, time/batch = 15.9506s	
10986/22950 (epoch 23.935), train_loss = 0.99580959, grad/param norm = 2.1684e-01, time/batch = 16.1167s	
10987/22950 (epoch 23.937), train_loss = 1.01920536, grad/param norm = 2.2825e-01, time/batch = 16.1125s	
10988/22950 (epoch 23.939), train_loss = 0.93247233, grad/param norm = 2.2050e-01, time/batch = 16.6698s	
10989/22950 (epoch 23.941), train_loss = 0.94637912, grad/param norm = 2.0593e-01, time/batch = 15.8099s	
10990/22950 (epoch 23.943), train_loss = 1.03791725, grad/param norm = 2.4016e-01, time/batch = 15.7306s	
10991/22950 (epoch 23.946), train_loss = 0.85815745, grad/param norm = 2.0629e-01, time/batch = 16.2726s	
10992/22950 (epoch 23.948), train_loss = 1.07895728, grad/param norm = 2.2455e-01, time/batch = 16.1360s	
10993/22950 (epoch 23.950), train_loss = 1.00877253, grad/param norm = 2.2103e-01, time/batch = 15.8812s	
10994/22950 (epoch 23.952), train_loss = 1.05375092, grad/param norm = 2.3498e-01, time/batch = 15.8746s	
10995/22950 (epoch 23.954), train_loss = 1.03015404, grad/param norm = 2.1823e-01, time/batch = 16.3603s	
10996/22950 (epoch 23.956), train_loss = 0.92929636, grad/param norm = 2.3447e-01, time/batch = 15.8088s	
10997/22950 (epoch 23.959), train_loss = 0.91370591, grad/param norm = 2.0955e-01, time/batch = 15.6463s	
10998/22950 (epoch 23.961), train_loss = 1.02045580, grad/param norm = 2.2032e-01, time/batch = 15.8965s	
10999/22950 (epoch 23.963), train_loss = 1.03587935, grad/param norm = 2.3005e-01, time/batch = 30.6585s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch23.97_1.8377.t7	
11000/22950 (epoch 23.965), train_loss = 1.12735302, grad/param norm = 2.3459e-01, time/batch = 18.2047s	
11001/22950 (epoch 23.967), train_loss = 1.36947641, grad/param norm = 2.8898e-01, time/batch = 18.0542s	
11002/22950 (epoch 23.969), train_loss = 0.91170942, grad/param norm = 2.2423e-01, time/batch = 19.0346s	
11003/22950 (epoch 23.972), train_loss = 0.99943139, grad/param norm = 2.0207e-01, time/batch = 20.1097s	
11004/22950 (epoch 23.974), train_loss = 0.95616433, grad/param norm = 2.1582e-01, time/batch = 19.6296s	
11005/22950 (epoch 23.976), train_loss = 0.94433366, grad/param norm = 1.9121e-01, time/batch = 18.4486s	
11006/22950 (epoch 23.978), train_loss = 0.95987830, grad/param norm = 2.3121e-01, time/batch = 19.7062s	
11007/22950 (epoch 23.980), train_loss = 0.97782787, grad/param norm = 2.1320e-01, time/batch = 18.4519s	
11008/22950 (epoch 23.983), train_loss = 1.04621651, grad/param norm = 2.1302e-01, time/batch = 18.5953s	
11009/22950 (epoch 23.985), train_loss = 0.87042884, grad/param norm = 2.0916e-01, time/batch = 20.1112s	
11010/22950 (epoch 23.987), train_loss = 0.93901758, grad/param norm = 2.0394e-01, time/batch = 18.2197s	
11011/22950 (epoch 23.989), train_loss = 0.99701822, grad/param norm = 2.1873e-01, time/batch = 17.3450s	
11012/22950 (epoch 23.991), train_loss = 0.84789439, grad/param norm = 2.1134e-01, time/batch = 17.7767s	
11013/22950 (epoch 23.993), train_loss = 1.03279894, grad/param norm = 2.1797e-01, time/batch = 19.6180s	
11014/22950 (epoch 23.996), train_loss = 1.01600168, grad/param norm = 2.4839e-01, time/batch = 16.6508s	
11015/22950 (epoch 23.998), train_loss = 0.91823503, grad/param norm = 2.2521e-01, time/batch = 18.6963s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
11016/22950 (epoch 24.000), train_loss = 0.83476865, grad/param norm = 1.9881e-01, time/batch = 19.8815s	
11017/22950 (epoch 24.002), train_loss = 1.15743081, grad/param norm = 2.2416e-01, time/batch = 17.8634s	
11018/22950 (epoch 24.004), train_loss = 1.02850199, grad/param norm = 2.1712e-01, time/batch = 16.4450s	
11019/22950 (epoch 24.007), train_loss = 0.99194550, grad/param norm = 2.0652e-01, time/batch = 18.9634s	
11020/22950 (epoch 24.009), train_loss = 1.15779761, grad/param norm = 2.7305e-01, time/batch = 20.1346s	
11021/22950 (epoch 24.011), train_loss = 0.87982634, grad/param norm = 2.6924e-01, time/batch = 17.4499s	
11022/22950 (epoch 24.013), train_loss = 1.01751108, grad/param norm = 2.4676e-01, time/batch = 18.5636s	
11023/22950 (epoch 24.015), train_loss = 1.03569076, grad/param norm = 2.5807e-01, time/batch = 19.1171s	
11024/22950 (epoch 24.017), train_loss = 1.04026233, grad/param norm = 2.2604e-01, time/batch = 18.4511s	
11025/22950 (epoch 24.020), train_loss = 1.01861081, grad/param norm = 2.1967e-01, time/batch = 20.2782s	
11026/22950 (epoch 24.022), train_loss = 0.86733254, grad/param norm = 2.0216e-01, time/batch = 18.1249s	
11027/22950 (epoch 24.024), train_loss = 0.97376226, grad/param norm = 2.1796e-01, time/batch = 18.9675s	
11028/22950 (epoch 24.026), train_loss = 1.06090648, grad/param norm = 2.2949e-01, time/batch = 17.9538s	
11029/22950 (epoch 24.028), train_loss = 1.10692914, grad/param norm = 1.9946e-01, time/batch = 18.3807s	
11030/22950 (epoch 24.031), train_loss = 0.96362438, grad/param norm = 1.9761e-01, time/batch = 16.8221s	
11031/22950 (epoch 24.033), train_loss = 1.12279326, grad/param norm = 2.4473e-01, time/batch = 17.2598s	
11032/22950 (epoch 24.035), train_loss = 0.99312589, grad/param norm = 1.9730e-01, time/batch = 18.3537s	
11033/22950 (epoch 24.037), train_loss = 0.99769283, grad/param norm = 2.0991e-01, time/batch = 20.2941s	
11034/22950 (epoch 24.039), train_loss = 0.96898848, grad/param norm = 2.2613e-01, time/batch = 17.7784s	
11035/22950 (epoch 24.041), train_loss = 0.94192925, grad/param norm = 2.1267e-01, time/batch = 18.5596s	
11036/22950 (epoch 24.044), train_loss = 1.04272983, grad/param norm = 2.2665e-01, time/batch = 16.5337s	
11037/22950 (epoch 24.046), train_loss = 0.99351138, grad/param norm = 2.2508e-01, time/batch = 16.4606s	
11038/22950 (epoch 24.048), train_loss = 1.00135304, grad/param norm = 1.9197e-01, time/batch = 18.6946s	
11039/22950 (epoch 24.050), train_loss = 0.97224607, grad/param norm = 2.4821e-01, time/batch = 19.7812s	
11040/22950 (epoch 24.052), train_loss = 1.03640522, grad/param norm = 2.3758e-01, time/batch = 17.6162s	
11041/22950 (epoch 24.054), train_loss = 1.17354006, grad/param norm = 2.4888e-01, time/batch = 16.7647s	
11042/22950 (epoch 24.057), train_loss = 1.10159335, grad/param norm = 2.3522e-01, time/batch = 19.2991s	
11043/22950 (epoch 24.059), train_loss = 1.04482439, grad/param norm = 2.0071e-01, time/batch = 17.3484s	
11044/22950 (epoch 24.061), train_loss = 0.93459744, grad/param norm = 2.2880e-01, time/batch = 18.0255s	
11045/22950 (epoch 24.063), train_loss = 1.04682577, grad/param norm = 2.3717e-01, time/batch = 17.2140s	
11046/22950 (epoch 24.065), train_loss = 0.88112963, grad/param norm = 2.1108e-01, time/batch = 18.3124s	
11047/22950 (epoch 24.068), train_loss = 1.06771095, grad/param norm = 2.4802e-01, time/batch = 18.2901s	
11048/22950 (epoch 24.070), train_loss = 0.89391897, grad/param norm = 1.9826e-01, time/batch = 16.5465s	
11049/22950 (epoch 24.072), train_loss = 1.07632514, grad/param norm = 2.4585e-01, time/batch = 17.6936s	
11050/22950 (epoch 24.074), train_loss = 1.02267014, grad/param norm = 2.3355e-01, time/batch = 19.1346s	
11051/22950 (epoch 24.076), train_loss = 1.03456434, grad/param norm = 2.3140e-01, time/batch = 18.1203s	
11052/22950 (epoch 24.078), train_loss = 1.07891217, grad/param norm = 2.1063e-01, time/batch = 19.2036s	
11053/22950 (epoch 24.081), train_loss = 1.10846310, grad/param norm = 2.3452e-01, time/batch = 18.9734s	
11054/22950 (epoch 24.083), train_loss = 0.99474709, grad/param norm = 2.2303e-01, time/batch = 17.0361s	
11055/22950 (epoch 24.085), train_loss = 0.88730177, grad/param norm = 2.2807e-01, time/batch = 17.8879s	
11056/22950 (epoch 24.087), train_loss = 0.91978400, grad/param norm = 2.2952e-01, time/batch = 18.2978s	
11057/22950 (epoch 24.089), train_loss = 1.02842407, grad/param norm = 2.0722e-01, time/batch = 18.2085s	
11058/22950 (epoch 24.092), train_loss = 0.97276561, grad/param norm = 2.4489e-01, time/batch = 18.5495s	
11059/22950 (epoch 24.094), train_loss = 0.91213346, grad/param norm = 2.0729e-01, time/batch = 17.4558s	
11060/22950 (epoch 24.096), train_loss = 1.11835128, grad/param norm = 2.3423e-01, time/batch = 18.7235s	
11061/22950 (epoch 24.098), train_loss = 1.05181308, grad/param norm = 2.0876e-01, time/batch = 17.1003s	
11062/22950 (epoch 24.100), train_loss = 0.95458761, grad/param norm = 2.1995e-01, time/batch = 20.5215s	
11063/22950 (epoch 24.102), train_loss = 0.99209565, grad/param norm = 2.2014e-01, time/batch = 19.2934s	
11064/22950 (epoch 24.105), train_loss = 0.84913020, grad/param norm = 1.8850e-01, time/batch = 17.4391s	
11065/22950 (epoch 24.107), train_loss = 0.94512159, grad/param norm = 2.0774e-01, time/batch = 19.9402s	
11066/22950 (epoch 24.109), train_loss = 0.93949601, grad/param norm = 2.2027e-01, time/batch = 17.1845s	
11067/22950 (epoch 24.111), train_loss = 0.85168743, grad/param norm = 2.1133e-01, time/batch = 18.1974s	
11068/22950 (epoch 24.113), train_loss = 1.00100974, grad/param norm = 2.1855e-01, time/batch = 18.3753s	
11069/22950 (epoch 24.115), train_loss = 0.99856021, grad/param norm = 2.0595e-01, time/batch = 19.8667s	
11070/22950 (epoch 24.118), train_loss = 1.12771375, grad/param norm = 2.1876e-01, time/batch = 18.0449s	
11071/22950 (epoch 24.120), train_loss = 0.90754014, grad/param norm = 2.1786e-01, time/batch = 19.0228s	
11072/22950 (epoch 24.122), train_loss = 1.10071066, grad/param norm = 2.4905e-01, time/batch = 17.8680s	
11073/22950 (epoch 24.124), train_loss = 0.86956091, grad/param norm = 1.9688e-01, time/batch = 17.9341s	
11074/22950 (epoch 24.126), train_loss = 0.99240908, grad/param norm = 2.2367e-01, time/batch = 17.0421s	
11075/22950 (epoch 24.129), train_loss = 0.89521657, grad/param norm = 2.0062e-01, time/batch = 18.5492s	
11076/22950 (epoch 24.131), train_loss = 0.96735486, grad/param norm = 2.0302e-01, time/batch = 17.3563s	
11077/22950 (epoch 24.133), train_loss = 1.04553369, grad/param norm = 2.1910e-01, time/batch = 17.9668s	
11078/22950 (epoch 24.135), train_loss = 1.00789543, grad/param norm = 2.1600e-01, time/batch = 18.6135s	
11079/22950 (epoch 24.137), train_loss = 1.11976975, grad/param norm = 2.5555e-01, time/batch = 19.0220s	
11080/22950 (epoch 24.139), train_loss = 0.88203815, grad/param norm = 2.1454e-01, time/batch = 19.1937s	
11081/22950 (epoch 24.142), train_loss = 0.89268168, grad/param norm = 2.0715e-01, time/batch = 19.3659s	
11082/22950 (epoch 24.144), train_loss = 0.96830201, grad/param norm = 2.2255e-01, time/batch = 19.3042s	
11083/22950 (epoch 24.146), train_loss = 0.94606334, grad/param norm = 2.2236e-01, time/batch = 18.2007s	
11084/22950 (epoch 24.148), train_loss = 0.92922458, grad/param norm = 2.2401e-01, time/batch = 15.7766s	
11085/22950 (epoch 24.150), train_loss = 1.01656929, grad/param norm = 2.3422e-01, time/batch = 15.6887s	
11086/22950 (epoch 24.153), train_loss = 0.94101818, grad/param norm = 2.0629e-01, time/batch = 16.4586s	
11087/22950 (epoch 24.155), train_loss = 0.93360769, grad/param norm = 2.1219e-01, time/batch = 15.9890s	
11088/22950 (epoch 24.157), train_loss = 0.98806806, grad/param norm = 2.1351e-01, time/batch = 14.9562s	
11089/22950 (epoch 24.159), train_loss = 0.91689929, grad/param norm = 2.0243e-01, time/batch = 15.6140s	
11090/22950 (epoch 24.161), train_loss = 0.95323326, grad/param norm = 1.9989e-01, time/batch = 18.1930s	
11091/22950 (epoch 24.163), train_loss = 0.86029540, grad/param norm = 1.9151e-01, time/batch = 18.7698s	
11092/22950 (epoch 24.166), train_loss = 1.10020085, grad/param norm = 3.0665e-01, time/batch = 19.1353s	
11093/22950 (epoch 24.168), train_loss = 1.04449405, grad/param norm = 2.6795e-01, time/batch = 17.2152s	
11094/22950 (epoch 24.170), train_loss = 0.97611055, grad/param norm = 2.3341e-01, time/batch = 17.4581s	
11095/22950 (epoch 24.172), train_loss = 1.02040598, grad/param norm = 2.0358e-01, time/batch = 17.4450s	
11096/22950 (epoch 24.174), train_loss = 1.06523616, grad/param norm = 2.4614e-01, time/batch = 20.1301s	
11097/22950 (epoch 24.176), train_loss = 1.08142217, grad/param norm = 2.3322e-01, time/batch = 17.9438s	
11098/22950 (epoch 24.179), train_loss = 1.05087221, grad/param norm = 2.3549e-01, time/batch = 18.9647s	
11099/22950 (epoch 24.181), train_loss = 1.22808009, grad/param norm = 2.3547e-01, time/batch = 20.0269s	
11100/22950 (epoch 24.183), train_loss = 1.07703358, grad/param norm = 2.2924e-01, time/batch = 17.5959s	
11101/22950 (epoch 24.185), train_loss = 1.02335943, grad/param norm = 2.0129e-01, time/batch = 19.3616s	
11102/22950 (epoch 24.187), train_loss = 0.91590005, grad/param norm = 2.2065e-01, time/batch = 19.8612s	
11103/22950 (epoch 24.190), train_loss = 0.83690863, grad/param norm = 2.2937e-01, time/batch = 18.0399s	
11104/22950 (epoch 24.192), train_loss = 0.83278080, grad/param norm = 1.9350e-01, time/batch = 17.9632s	
11105/22950 (epoch 24.194), train_loss = 0.96901936, grad/param norm = 2.4232e-01, time/batch = 19.7930s	
11106/22950 (epoch 24.196), train_loss = 0.78573890, grad/param norm = 2.2654e-01, time/batch = 19.4489s	
11107/22950 (epoch 24.198), train_loss = 1.06864987, grad/param norm = 2.5248e-01, time/batch = 15.9122s	
11108/22950 (epoch 24.200), train_loss = 0.91312507, grad/param norm = 1.9510e-01, time/batch = 18.2865s	
11109/22950 (epoch 24.203), train_loss = 0.87091895, grad/param norm = 2.0596e-01, time/batch = 19.0525s	
11110/22950 (epoch 24.205), train_loss = 0.94471959, grad/param norm = 2.1115e-01, time/batch = 16.7923s	
11111/22950 (epoch 24.207), train_loss = 0.99160797, grad/param norm = 2.1944e-01, time/batch = 17.5412s	
11112/22950 (epoch 24.209), train_loss = 0.99482994, grad/param norm = 2.2032e-01, time/batch = 17.6282s	
11113/22950 (epoch 24.211), train_loss = 0.81240556, grad/param norm = 2.1775e-01, time/batch = 18.2019s	
11114/22950 (epoch 24.214), train_loss = 0.94477984, grad/param norm = 2.2329e-01, time/batch = 18.8929s	
11115/22950 (epoch 24.216), train_loss = 1.05761016, grad/param norm = 2.1575e-01, time/batch = 18.2071s	
11116/22950 (epoch 24.218), train_loss = 0.98954595, grad/param norm = 2.0789e-01, time/batch = 18.5515s	
11117/22950 (epoch 24.220), train_loss = 1.06347844, grad/param norm = 2.3162e-01, time/batch = 19.6981s	
11118/22950 (epoch 24.222), train_loss = 1.10215858, grad/param norm = 2.4801e-01, time/batch = 17.1247s	
11119/22950 (epoch 24.224), train_loss = 0.97647118, grad/param norm = 2.1771e-01, time/batch = 19.5099s	
11120/22950 (epoch 24.227), train_loss = 1.06178447, grad/param norm = 2.2350e-01, time/batch = 17.3735s	
11121/22950 (epoch 24.229), train_loss = 1.08081622, grad/param norm = 2.2425e-01, time/batch = 17.5582s	
11122/22950 (epoch 24.231), train_loss = 0.86369779, grad/param norm = 2.1392e-01, time/batch = 18.8704s	
11123/22950 (epoch 24.233), train_loss = 0.93921853, grad/param norm = 2.1332e-01, time/batch = 16.7911s	
11124/22950 (epoch 24.235), train_loss = 1.14698798, grad/param norm = 2.7455e-01, time/batch = 19.1314s	
11125/22950 (epoch 24.237), train_loss = 0.92087000, grad/param norm = 2.1620e-01, time/batch = 17.7177s	
11126/22950 (epoch 24.240), train_loss = 0.99198238, grad/param norm = 2.1770e-01, time/batch = 18.8727s	
11127/22950 (epoch 24.242), train_loss = 1.11432465, grad/param norm = 2.0793e-01, time/batch = 17.7865s	
11128/22950 (epoch 24.244), train_loss = 1.11037782, grad/param norm = 2.3833e-01, time/batch = 18.1223s	
11129/22950 (epoch 24.246), train_loss = 1.10173700, grad/param norm = 2.2417e-01, time/batch = 17.0345s	
11130/22950 (epoch 24.248), train_loss = 1.03155365, grad/param norm = 2.3198e-01, time/batch = 17.3458s	
11131/22950 (epoch 24.251), train_loss = 0.93769559, grad/param norm = 2.2100e-01, time/batch = 15.1404s	
11132/22950 (epoch 24.253), train_loss = 0.95135456, grad/param norm = 2.4866e-01, time/batch = 18.5395s	
11133/22950 (epoch 24.255), train_loss = 1.02010502, grad/param norm = 2.1750e-01, time/batch = 18.5461s	
11134/22950 (epoch 24.257), train_loss = 1.08869640, grad/param norm = 2.3076e-01, time/batch = 18.8758s	
11135/22950 (epoch 24.259), train_loss = 0.86371830, grad/param norm = 1.9486e-01, time/batch = 18.2220s	
11136/22950 (epoch 24.261), train_loss = 0.94897192, grad/param norm = 2.2054e-01, time/batch = 17.8020s	
11137/22950 (epoch 24.264), train_loss = 0.90590352, grad/param norm = 2.3090e-01, time/batch = 16.1239s	
11138/22950 (epoch 24.266), train_loss = 0.98904003, grad/param norm = 2.0848e-01, time/batch = 18.0592s	
11139/22950 (epoch 24.268), train_loss = 0.99244625, grad/param norm = 2.2900e-01, time/batch = 19.2928s	
11140/22950 (epoch 24.270), train_loss = 0.97921226, grad/param norm = 2.1331e-01, time/batch = 16.7021s	
11141/22950 (epoch 24.272), train_loss = 1.03722724, grad/param norm = 2.3060e-01, time/batch = 19.2191s	
11142/22950 (epoch 24.275), train_loss = 0.93120952, grad/param norm = 2.2181e-01, time/batch = 17.8891s	
11143/22950 (epoch 24.277), train_loss = 0.83338453, grad/param norm = 1.9412e-01, time/batch = 17.6330s	
11144/22950 (epoch 24.279), train_loss = 0.89680355, grad/param norm = 2.2987e-01, time/batch = 16.7150s	
11145/22950 (epoch 24.281), train_loss = 0.93855958, grad/param norm = 2.0878e-01, time/batch = 15.8536s	
11146/22950 (epoch 24.283), train_loss = 0.84864929, grad/param norm = 1.8196e-01, time/batch = 19.4540s	
11147/22950 (epoch 24.285), train_loss = 1.00638558, grad/param norm = 2.2173e-01, time/batch = 18.6817s	
11148/22950 (epoch 24.288), train_loss = 1.05817539, grad/param norm = 2.1528e-01, time/batch = 19.9639s	
11149/22950 (epoch 24.290), train_loss = 0.93507913, grad/param norm = 2.0524e-01, time/batch = 19.2831s	
11150/22950 (epoch 24.292), train_loss = 1.07174567, grad/param norm = 2.2611e-01, time/batch = 17.7898s	
11151/22950 (epoch 24.294), train_loss = 0.97890296, grad/param norm = 2.1938e-01, time/batch = 19.4481s	
11152/22950 (epoch 24.296), train_loss = 0.76942181, grad/param norm = 1.7300e-01, time/batch = 19.6976s	
11153/22950 (epoch 24.298), train_loss = 0.98265724, grad/param norm = 2.0534e-01, time/batch = 17.6988s	
11154/22950 (epoch 24.301), train_loss = 1.00184342, grad/param norm = 2.2959e-01, time/batch = 18.7179s	
11155/22950 (epoch 24.303), train_loss = 0.99117700, grad/param norm = 2.0700e-01, time/batch = 18.0526s	
11156/22950 (epoch 24.305), train_loss = 0.98308951, grad/param norm = 2.2730e-01, time/batch = 17.2666s	
11157/22950 (epoch 24.307), train_loss = 1.10543595, grad/param norm = 2.4907e-01, time/batch = 19.1251s	
11158/22950 (epoch 24.309), train_loss = 0.93239977, grad/param norm = 2.0953e-01, time/batch = 19.1940s	
11159/22950 (epoch 24.312), train_loss = 0.99801865, grad/param norm = 2.2260e-01, time/batch = 15.9335s	
11160/22950 (epoch 24.314), train_loss = 0.99863169, grad/param norm = 2.1001e-01, time/batch = 17.1172s	
11161/22950 (epoch 24.316), train_loss = 0.97962985, grad/param norm = 2.3075e-01, time/batch = 17.8602s	
11162/22950 (epoch 24.318), train_loss = 0.83389637, grad/param norm = 1.8035e-01, time/batch = 19.7061s	
11163/22950 (epoch 24.320), train_loss = 0.91657775, grad/param norm = 2.0319e-01, time/batch = 18.6993s	
11164/22950 (epoch 24.322), train_loss = 0.93289434, grad/param norm = 2.1605e-01, time/batch = 18.2165s	
11165/22950 (epoch 24.325), train_loss = 0.79775029, grad/param norm = 1.9451e-01, time/batch = 19.4329s	
11166/22950 (epoch 24.327), train_loss = 0.81031595, grad/param norm = 1.9972e-01, time/batch = 18.3735s	
11167/22950 (epoch 24.329), train_loss = 0.91557098, grad/param norm = 2.1446e-01, time/batch = 19.7891s	
11168/22950 (epoch 24.331), train_loss = 0.84363221, grad/param norm = 1.9693e-01, time/batch = 19.4508s	
11169/22950 (epoch 24.333), train_loss = 0.94933632, grad/param norm = 2.1158e-01, time/batch = 18.6198s	
11170/22950 (epoch 24.336), train_loss = 0.94163695, grad/param norm = 2.3008e-01, time/batch = 17.4578s	
11171/22950 (epoch 24.338), train_loss = 0.96030667, grad/param norm = 2.0119e-01, time/batch = 18.2793s	
11172/22950 (epoch 24.340), train_loss = 0.96694042, grad/param norm = 2.2655e-01, time/batch = 18.2728s	
11173/22950 (epoch 24.342), train_loss = 1.08627874, grad/param norm = 2.2511e-01, time/batch = 17.0926s	
11174/22950 (epoch 24.344), train_loss = 0.94661736, grad/param norm = 2.0831e-01, time/batch = 19.2128s	
11175/22950 (epoch 24.346), train_loss = 1.06209133, grad/param norm = 2.6866e-01, time/batch = 19.6265s	
11176/22950 (epoch 24.349), train_loss = 0.98252022, grad/param norm = 2.2205e-01, time/batch = 19.1892s	
11177/22950 (epoch 24.351), train_loss = 1.00318090, grad/param norm = 2.3029e-01, time/batch = 18.7720s	
11178/22950 (epoch 24.353), train_loss = 1.05129726, grad/param norm = 2.5612e-01, time/batch = 20.5386s	
11179/22950 (epoch 24.355), train_loss = 1.09363267, grad/param norm = 2.3337e-01, time/batch = 18.2076s	
11180/22950 (epoch 24.357), train_loss = 0.97747375, grad/param norm = 2.3482e-01, time/batch = 19.3774s	
11181/22950 (epoch 24.359), train_loss = 0.98069364, grad/param norm = 2.0784e-01, time/batch = 19.8767s	
11182/22950 (epoch 24.362), train_loss = 1.00990723, grad/param norm = 2.1447e-01, time/batch = 17.4573s	
11183/22950 (epoch 24.364), train_loss = 0.97684656, grad/param norm = 2.3346e-01, time/batch = 19.2223s	
11184/22950 (epoch 24.366), train_loss = 0.95055215, grad/param norm = 2.0763e-01, time/batch = 18.1232s	
11185/22950 (epoch 24.368), train_loss = 1.05222915, grad/param norm = 2.3619e-01, time/batch = 15.6772s	
11186/22950 (epoch 24.370), train_loss = 0.95866480, grad/param norm = 2.2139e-01, time/batch = 17.0375s	
11187/22950 (epoch 24.373), train_loss = 0.86336063, grad/param norm = 1.9375e-01, time/batch = 18.3839s	
11188/22950 (epoch 24.375), train_loss = 1.09110010, grad/param norm = 2.2872e-01, time/batch = 21.9945s	
11189/22950 (epoch 24.377), train_loss = 0.89173426, grad/param norm = 2.5814e-01, time/batch = 31.0011s	
11190/22950 (epoch 24.379), train_loss = 1.01996472, grad/param norm = 2.4924e-01, time/batch = 20.0221s	
11191/22950 (epoch 24.381), train_loss = 0.85800805, grad/param norm = 2.0963e-01, time/batch = 18.8554s	
11192/22950 (epoch 24.383), train_loss = 0.97282602, grad/param norm = 2.2484e-01, time/batch = 18.4268s	
11193/22950 (epoch 24.386), train_loss = 0.91565089, grad/param norm = 2.3980e-01, time/batch = 18.0452s	
11194/22950 (epoch 24.388), train_loss = 1.00270368, grad/param norm = 2.3900e-01, time/batch = 17.4542s	
11195/22950 (epoch 24.390), train_loss = 0.85549371, grad/param norm = 2.0714e-01, time/batch = 20.7789s	
11196/22950 (epoch 24.392), train_loss = 0.91098620, grad/param norm = 2.0283e-01, time/batch = 20.1109s	
11197/22950 (epoch 24.394), train_loss = 0.90123214, grad/param norm = 1.9365e-01, time/batch = 19.1794s	
11198/22950 (epoch 24.397), train_loss = 1.11169801, grad/param norm = 2.0722e-01, time/batch = 19.2046s	
11199/22950 (epoch 24.399), train_loss = 1.12030414, grad/param norm = 2.6826e-01, time/batch = 19.0333s	
11200/22950 (epoch 24.401), train_loss = 1.16630769, grad/param norm = 2.7377e-01, time/batch = 17.6142s	
11201/22950 (epoch 24.403), train_loss = 0.94610391, grad/param norm = 2.4848e-01, time/batch = 16.2871s	
11202/22950 (epoch 24.405), train_loss = 1.07263783, grad/param norm = 2.2811e-01, time/batch = 20.0231s	
11203/22950 (epoch 24.407), train_loss = 1.13223022, grad/param norm = 2.0896e-01, time/batch = 19.4397s	
11204/22950 (epoch 24.410), train_loss = 0.95430656, grad/param norm = 2.1851e-01, time/batch = 17.7829s	
11205/22950 (epoch 24.412), train_loss = 0.94808593, grad/param norm = 2.0085e-01, time/batch = 17.7042s	
11206/22950 (epoch 24.414), train_loss = 1.10278656, grad/param norm = 2.3809e-01, time/batch = 18.2822s	
11207/22950 (epoch 24.416), train_loss = 1.02949195, grad/param norm = 2.5115e-01, time/batch = 17.9584s	
11208/22950 (epoch 24.418), train_loss = 0.99766815, grad/param norm = 2.6407e-01, time/batch = 18.7021s	
11209/22950 (epoch 24.420), train_loss = 1.07131815, grad/param norm = 2.6201e-01, time/batch = 18.8602s	
11210/22950 (epoch 24.423), train_loss = 0.92039603, grad/param norm = 2.2416e-01, time/batch = 18.3674s	
11211/22950 (epoch 24.425), train_loss = 0.94691834, grad/param norm = 1.9811e-01, time/batch = 20.7804s	
11212/22950 (epoch 24.427), train_loss = 0.98207197, grad/param norm = 2.3187e-01, time/batch = 20.1112s	
11213/22950 (epoch 24.429), train_loss = 0.96799247, grad/param norm = 2.0671e-01, time/batch = 18.1171s	
11214/22950 (epoch 24.431), train_loss = 1.04560901, grad/param norm = 2.2786e-01, time/batch = 18.6672s	
11215/22950 (epoch 24.434), train_loss = 0.98290110, grad/param norm = 2.1126e-01, time/batch = 19.7020s	
11216/22950 (epoch 24.436), train_loss = 1.07540800, grad/param norm = 2.5241e-01, time/batch = 18.3642s	
11217/22950 (epoch 24.438), train_loss = 1.03364212, grad/param norm = 2.4071e-01, time/batch = 18.8686s	
11218/22950 (epoch 24.440), train_loss = 1.08604083, grad/param norm = 2.1611e-01, time/batch = 19.5380s	
11219/22950 (epoch 24.442), train_loss = 1.16167238, grad/param norm = 2.4558e-01, time/batch = 18.7520s	
11220/22950 (epoch 24.444), train_loss = 1.05406286, grad/param norm = 2.3864e-01, time/batch = 16.0435s	
11221/22950 (epoch 24.447), train_loss = 1.16233412, grad/param norm = 2.5113e-01, time/batch = 16.6869s	
11222/22950 (epoch 24.449), train_loss = 0.88688677, grad/param norm = 1.9857e-01, time/batch = 19.6187s	
11223/22950 (epoch 24.451), train_loss = 1.02074715, grad/param norm = 2.4448e-01, time/batch = 19.5221s	
11224/22950 (epoch 24.453), train_loss = 1.03765404, grad/param norm = 2.2551e-01, time/batch = 18.7699s	
11225/22950 (epoch 24.455), train_loss = 0.95860575, grad/param norm = 2.0621e-01, time/batch = 19.2915s	
11226/22950 (epoch 24.458), train_loss = 1.05167966, grad/param norm = 2.2919e-01, time/batch = 18.4664s	
11227/22950 (epoch 24.460), train_loss = 1.04500420, grad/param norm = 2.1428e-01, time/batch = 19.2911s	
11228/22950 (epoch 24.462), train_loss = 1.00127596, grad/param norm = 2.1821e-01, time/batch = 18.7968s	
11229/22950 (epoch 24.464), train_loss = 0.95485492, grad/param norm = 2.0895e-01, time/batch = 18.7101s	
11230/22950 (epoch 24.466), train_loss = 1.05827097, grad/param norm = 2.2870e-01, time/batch = 17.8645s	
11231/22950 (epoch 24.468), train_loss = 1.10539465, grad/param norm = 2.3818e-01, time/batch = 16.4829s	
11232/22950 (epoch 24.471), train_loss = 1.04382622, grad/param norm = 2.4374e-01, time/batch = 17.4389s	
11233/22950 (epoch 24.473), train_loss = 1.05831082, grad/param norm = 2.3170e-01, time/batch = 19.4532s	
11234/22950 (epoch 24.475), train_loss = 1.19471953, grad/param norm = 2.4871e-01, time/batch = 15.6782s	
11235/22950 (epoch 24.477), train_loss = 1.01165128, grad/param norm = 2.5001e-01, time/batch = 18.5514s	
11236/22950 (epoch 24.479), train_loss = 0.89881134, grad/param norm = 2.0009e-01, time/batch = 16.7869s	
11237/22950 (epoch 24.481), train_loss = 1.07183334, grad/param norm = 2.4299e-01, time/batch = 19.1378s	
11238/22950 (epoch 24.484), train_loss = 1.04228584, grad/param norm = 2.5944e-01, time/batch = 17.3130s	
11239/22950 (epoch 24.486), train_loss = 0.87075587, grad/param norm = 2.0357e-01, time/batch = 16.4654s	
11240/22950 (epoch 24.488), train_loss = 0.95223628, grad/param norm = 2.5728e-01, time/batch = 16.8739s	
11241/22950 (epoch 24.490), train_loss = 0.87624148, grad/param norm = 2.1681e-01, time/batch = 18.2102s	
11242/22950 (epoch 24.492), train_loss = 0.95818329, grad/param norm = 2.3267e-01, time/batch = 17.6361s	
11243/22950 (epoch 24.495), train_loss = 0.94577671, grad/param norm = 2.2635e-01, time/batch = 17.3745s	
11244/22950 (epoch 24.497), train_loss = 1.04710070, grad/param norm = 2.3196e-01, time/batch = 19.6160s	
11245/22950 (epoch 24.499), train_loss = 1.12628816, grad/param norm = 2.3692e-01, time/batch = 19.8774s	
11246/22950 (epoch 24.501), train_loss = 1.07860189, grad/param norm = 2.4878e-01, time/batch = 18.2124s	
11247/22950 (epoch 24.503), train_loss = 1.09526610, grad/param norm = 2.1502e-01, time/batch = 17.7009s	
11248/22950 (epoch 24.505), train_loss = 0.88231675, grad/param norm = 1.8885e-01, time/batch = 18.6348s	
11249/22950 (epoch 24.508), train_loss = 1.05025536, grad/param norm = 2.2408e-01, time/batch = 17.0323s	
11250/22950 (epoch 24.510), train_loss = 0.98713168, grad/param norm = 2.2381e-01, time/batch = 15.9322s	
11251/22950 (epoch 24.512), train_loss = 0.87477981, grad/param norm = 2.0812e-01, time/batch = 18.4551s	
11252/22950 (epoch 24.514), train_loss = 0.92855910, grad/param norm = 1.8559e-01, time/batch = 18.9521s	
11253/22950 (epoch 24.516), train_loss = 0.96379148, grad/param norm = 2.2311e-01, time/batch = 18.5464s	
11254/22950 (epoch 24.519), train_loss = 0.97227331, grad/param norm = 2.1910e-01, time/batch = 18.2182s	
11255/22950 (epoch 24.521), train_loss = 0.99191705, grad/param norm = 2.4018e-01, time/batch = 18.7198s	
11256/22950 (epoch 24.523), train_loss = 0.80728684, grad/param norm = 2.1264e-01, time/batch = 17.8400s	
11257/22950 (epoch 24.525), train_loss = 0.90319270, grad/param norm = 1.8699e-01, time/batch = 18.8429s	
11258/22950 (epoch 24.527), train_loss = 0.85649037, grad/param norm = 2.1548e-01, time/batch = 18.6160s	
11259/22950 (epoch 24.529), train_loss = 1.01367985, grad/param norm = 2.2096e-01, time/batch = 17.5429s	
11260/22950 (epoch 24.532), train_loss = 0.95405738, grad/param norm = 2.2382e-01, time/batch = 19.8646s	
11261/22950 (epoch 24.534), train_loss = 1.03239030, grad/param norm = 2.3055e-01, time/batch = 19.7045s	
11262/22950 (epoch 24.536), train_loss = 1.03445047, grad/param norm = 2.3550e-01, time/batch = 18.0320s	
11263/22950 (epoch 24.538), train_loss = 1.03723192, grad/param norm = 2.2981e-01, time/batch = 18.3050s	
11264/22950 (epoch 24.540), train_loss = 1.03139055, grad/param norm = 2.3240e-01, time/batch = 19.2099s	
11265/22950 (epoch 24.542), train_loss = 1.14725319, grad/param norm = 2.4246e-01, time/batch = 18.0463s	
11266/22950 (epoch 24.545), train_loss = 0.95351505, grad/param norm = 2.0963e-01, time/batch = 15.7791s	
11267/22950 (epoch 24.547), train_loss = 0.96991714, grad/param norm = 2.1531e-01, time/batch = 16.9767s	
11268/22950 (epoch 24.549), train_loss = 0.92358986, grad/param norm = 2.1528e-01, time/batch = 19.2140s	
11269/22950 (epoch 24.551), train_loss = 0.97942091, grad/param norm = 2.3692e-01, time/batch = 17.1174s	
11270/22950 (epoch 24.553), train_loss = 0.96181078, grad/param norm = 2.5523e-01, time/batch = 17.6364s	
11271/22950 (epoch 24.556), train_loss = 1.02593317, grad/param norm = 2.2419e-01, time/batch = 18.1892s	
11272/22950 (epoch 24.558), train_loss = 0.86320379, grad/param norm = 2.1918e-01, time/batch = 18.2014s	
11273/22950 (epoch 24.560), train_loss = 0.96679310, grad/param norm = 2.1464e-01, time/batch = 16.1225s	
11274/22950 (epoch 24.562), train_loss = 0.92024090, grad/param norm = 2.0108e-01, time/batch = 17.2900s	
11275/22950 (epoch 24.564), train_loss = 1.03998090, grad/param norm = 2.4426e-01, time/batch = 18.8671s	
11276/22950 (epoch 24.566), train_loss = 1.01756455, grad/param norm = 2.2082e-01, time/batch = 15.6850s	
11277/22950 (epoch 24.569), train_loss = 0.98848313, grad/param norm = 2.5256e-01, time/batch = 19.1325s	
11278/22950 (epoch 24.571), train_loss = 0.97311444, grad/param norm = 2.3260e-01, time/batch = 18.4782s	
11279/22950 (epoch 24.573), train_loss = 0.97921024, grad/param norm = 2.2629e-01, time/batch = 18.9317s	
11280/22950 (epoch 24.575), train_loss = 1.11824515, grad/param norm = 2.8426e-01, time/batch = 20.1224s	
11281/22950 (epoch 24.577), train_loss = 1.01185609, grad/param norm = 2.4490e-01, time/batch = 17.6304s	
11282/22950 (epoch 24.580), train_loss = 1.04942801, grad/param norm = 2.4953e-01, time/batch = 18.5320s	
11283/22950 (epoch 24.582), train_loss = 1.16391044, grad/param norm = 2.5353e-01, time/batch = 19.7048s	
11284/22950 (epoch 24.584), train_loss = 0.85790911, grad/param norm = 2.1261e-01, time/batch = 19.1094s	
11285/22950 (epoch 24.586), train_loss = 0.91895656, grad/param norm = 2.1942e-01, time/batch = 17.5306s	
11286/22950 (epoch 24.588), train_loss = 1.11945028, grad/param norm = 2.2931e-01, time/batch = 18.2236s	
11287/22950 (epoch 24.590), train_loss = 1.01240395, grad/param norm = 2.1649e-01, time/batch = 19.4648s	
11288/22950 (epoch 24.593), train_loss = 0.96980429, grad/param norm = 2.3830e-01, time/batch = 18.9405s	
11289/22950 (epoch 24.595), train_loss = 0.87872182, grad/param norm = 2.1606e-01, time/batch = 17.1222s	
11290/22950 (epoch 24.597), train_loss = 1.06304285, grad/param norm = 2.3559e-01, time/batch = 18.6776s	
11291/22950 (epoch 24.599), train_loss = 1.00449340, grad/param norm = 2.4185e-01, time/batch = 16.9350s	
11292/22950 (epoch 24.601), train_loss = 1.04205952, grad/param norm = 2.7384e-01, time/batch = 17.1820s	
11293/22950 (epoch 24.603), train_loss = 1.12797731, grad/param norm = 2.3007e-01, time/batch = 19.3812s	
11294/22950 (epoch 24.606), train_loss = 0.98755411, grad/param norm = 2.1721e-01, time/batch = 20.0327s	
11295/22950 (epoch 24.608), train_loss = 1.02591414, grad/param norm = 2.3244e-01, time/batch = 17.7939s	
11296/22950 (epoch 24.610), train_loss = 0.98685869, grad/param norm = 2.1934e-01, time/batch = 19.5484s	
11297/22950 (epoch 24.612), train_loss = 0.97811322, grad/param norm = 2.2211e-01, time/batch = 19.7998s	
11298/22950 (epoch 24.614), train_loss = 1.11027186, grad/param norm = 2.3114e-01, time/batch = 17.1260s	
11299/22950 (epoch 24.617), train_loss = 0.98526653, grad/param norm = 2.2450e-01, time/batch = 18.7807s	
11300/22950 (epoch 24.619), train_loss = 0.95999066, grad/param norm = 2.0102e-01, time/batch = 18.6276s	
11301/22950 (epoch 24.621), train_loss = 1.09003456, grad/param norm = 2.0610e-01, time/batch = 15.6360s	
11302/22950 (epoch 24.623), train_loss = 1.05974739, grad/param norm = 2.1262e-01, time/batch = 19.1129s	
11303/22950 (epoch 24.625), train_loss = 0.96332440, grad/param norm = 2.0175e-01, time/batch = 18.0299s	
11304/22950 (epoch 24.627), train_loss = 0.96965302, grad/param norm = 2.4702e-01, time/batch = 18.7942s	
11305/22950 (epoch 24.630), train_loss = 0.86268611, grad/param norm = 1.9800e-01, time/batch = 17.9338s	
11306/22950 (epoch 24.632), train_loss = 0.94274174, grad/param norm = 2.2785e-01, time/batch = 18.4480s	
11307/22950 (epoch 24.634), train_loss = 1.00978645, grad/param norm = 2.1777e-01, time/batch = 20.2942s	
11308/22950 (epoch 24.636), train_loss = 1.03845661, grad/param norm = 2.3598e-01, time/batch = 18.5244s	
11309/22950 (epoch 24.638), train_loss = 0.92692305, grad/param norm = 2.0925e-01, time/batch = 19.6191s	
11310/22950 (epoch 24.641), train_loss = 0.97112788, grad/param norm = 2.1140e-01, time/batch = 17.2884s	
11311/22950 (epoch 24.643), train_loss = 1.03424653, grad/param norm = 2.5225e-01, time/batch = 18.0855s	
11312/22950 (epoch 24.645), train_loss = 0.95144598, grad/param norm = 2.3232e-01, time/batch = 19.5389s	
11313/22950 (epoch 24.647), train_loss = 0.97024927, grad/param norm = 2.3128e-01, time/batch = 18.0459s	
11314/22950 (epoch 24.649), train_loss = 0.97170115, grad/param norm = 2.3869e-01, time/batch = 18.7895s	
11315/22950 (epoch 24.651), train_loss = 1.05442217, grad/param norm = 2.4355e-01, time/batch = 19.8688s	
11316/22950 (epoch 24.654), train_loss = 0.84571645, grad/param norm = 2.0207e-01, time/batch = 16.9696s	
11317/22950 (epoch 24.656), train_loss = 1.07541114, grad/param norm = 2.6369e-01, time/batch = 18.5337s	
11318/22950 (epoch 24.658), train_loss = 0.89228554, grad/param norm = 2.2212e-01, time/batch = 18.3646s	
11319/22950 (epoch 24.660), train_loss = 0.80953070, grad/param norm = 2.2911e-01, time/batch = 17.6476s	
11320/22950 (epoch 24.662), train_loss = 0.83299932, grad/param norm = 2.2655e-01, time/batch = 19.3744s	
11321/22950 (epoch 24.664), train_loss = 0.97371312, grad/param norm = 2.2170e-01, time/batch = 19.6897s	
11322/22950 (epoch 24.667), train_loss = 0.99873276, grad/param norm = 2.3355e-01, time/batch = 19.0960s	
11323/22950 (epoch 24.669), train_loss = 0.97887047, grad/param norm = 2.2692e-01, time/batch = 20.1288s	
11324/22950 (epoch 24.671), train_loss = 0.98189309, grad/param norm = 2.0905e-01, time/batch = 17.6051s	
11325/22950 (epoch 24.673), train_loss = 0.92642264, grad/param norm = 2.1515e-01, time/batch = 19.3044s	
11326/22950 (epoch 24.675), train_loss = 0.99275707, grad/param norm = 2.1991e-01, time/batch = 19.3874s	
11327/22950 (epoch 24.678), train_loss = 1.00293265, grad/param norm = 2.3768e-01, time/batch = 17.0501s	
11328/22950 (epoch 24.680), train_loss = 0.98890603, grad/param norm = 2.0404e-01, time/batch = 16.6246s	
11329/22950 (epoch 24.682), train_loss = 0.97631406, grad/param norm = 2.4623e-01, time/batch = 19.2764s	
11330/22950 (epoch 24.684), train_loss = 1.09077786, grad/param norm = 2.5231e-01, time/batch = 18.3716s	
11331/22950 (epoch 24.686), train_loss = 1.07570763, grad/param norm = 2.2347e-01, time/batch = 18.9602s	
11332/22950 (epoch 24.688), train_loss = 1.02667226, grad/param norm = 2.2663e-01, time/batch = 17.4369s	
11333/22950 (epoch 24.691), train_loss = 0.98770466, grad/param norm = 2.2097e-01, time/batch = 18.8681s	
11334/22950 (epoch 24.693), train_loss = 0.91244249, grad/param norm = 2.2642e-01, time/batch = 16.2270s	
11335/22950 (epoch 24.695), train_loss = 1.09592146, grad/param norm = 2.4625e-01, time/batch = 18.6360s	
11336/22950 (epoch 24.697), train_loss = 1.05137947, grad/param norm = 2.7916e-01, time/batch = 19.0367s	
11337/22950 (epoch 24.699), train_loss = 1.05414265, grad/param norm = 2.3508e-01, time/batch = 17.7874s	
11338/22950 (epoch 24.702), train_loss = 1.04316575, grad/param norm = 2.3029e-01, time/batch = 17.4802s	
11339/22950 (epoch 24.704), train_loss = 1.09298056, grad/param norm = 2.2690e-01, time/batch = 18.9505s	
11340/22950 (epoch 24.706), train_loss = 1.08411327, grad/param norm = 2.4446e-01, time/batch = 17.2993s	
11341/22950 (epoch 24.708), train_loss = 0.86992430, grad/param norm = 2.2840e-01, time/batch = 19.6302s	
11342/22950 (epoch 24.710), train_loss = 1.01854249, grad/param norm = 2.2334e-01, time/batch = 19.0457s	
11343/22950 (epoch 24.712), train_loss = 1.11965052, grad/param norm = 2.4221e-01, time/batch = 17.8872s	
11344/22950 (epoch 24.715), train_loss = 0.98882280, grad/param norm = 2.2495e-01, time/batch = 16.5970s	
11345/22950 (epoch 24.717), train_loss = 1.02322726, grad/param norm = 2.1505e-01, time/batch = 19.1314s	
11346/22950 (epoch 24.719), train_loss = 0.96925220, grad/param norm = 2.3123e-01, time/batch = 19.4650s	
11347/22950 (epoch 24.721), train_loss = 1.05288996, grad/param norm = 2.3120e-01, time/batch = 17.5987s	
11348/22950 (epoch 24.723), train_loss = 0.98412591, grad/param norm = 2.3497e-01, time/batch = 16.1032s	
11349/22950 (epoch 24.725), train_loss = 1.06426483, grad/param norm = 2.7381e-01, time/batch = 18.6323s	
11350/22950 (epoch 24.728), train_loss = 0.98244227, grad/param norm = 2.9151e-01, time/batch = 17.8706s	
11351/22950 (epoch 24.730), train_loss = 0.96195540, grad/param norm = 2.1771e-01, time/batch = 19.4454s	
11352/22950 (epoch 24.732), train_loss = 1.05669243, grad/param norm = 2.4227e-01, time/batch = 18.7904s	
11353/22950 (epoch 24.734), train_loss = 0.98010954, grad/param norm = 2.3307e-01, time/batch = 17.9562s	
11354/22950 (epoch 24.736), train_loss = 0.99838339, grad/param norm = 2.1644e-01, time/batch = 16.8643s	
11355/22950 (epoch 24.739), train_loss = 1.05899544, grad/param norm = 2.4199e-01, time/batch = 20.3040s	
11356/22950 (epoch 24.741), train_loss = 1.07929818, grad/param norm = 2.7097e-01, time/batch = 18.3828s	
11357/22950 (epoch 24.743), train_loss = 1.15391986, grad/param norm = 2.7340e-01, time/batch = 19.9397s	
11358/22950 (epoch 24.745), train_loss = 1.23979093, grad/param norm = 2.6879e-01, time/batch = 20.2904s	
11359/22950 (epoch 24.747), train_loss = 1.02911762, grad/param norm = 2.4477e-01, time/batch = 18.5404s	
11360/22950 (epoch 24.749), train_loss = 0.94407327, grad/param norm = 2.6533e-01, time/batch = 18.0814s	
11361/22950 (epoch 24.752), train_loss = 1.19484486, grad/param norm = 2.8679e-01, time/batch = 20.2002s	
11362/22950 (epoch 24.754), train_loss = 1.09471056, grad/param norm = 2.4638e-01, time/batch = 18.5526s	
11363/22950 (epoch 24.756), train_loss = 0.94975731, grad/param norm = 2.3820e-01, time/batch = 19.0975s	
11364/22950 (epoch 24.758), train_loss = 1.00368657, grad/param norm = 2.0993e-01, time/batch = 18.7861s	
11365/22950 (epoch 24.760), train_loss = 1.04729339, grad/param norm = 2.3689e-01, time/batch = 19.8836s	
11366/22950 (epoch 24.763), train_loss = 1.08000347, grad/param norm = 2.2588e-01, time/batch = 16.9373s	
11367/22950 (epoch 24.765), train_loss = 1.03883131, grad/param norm = 2.2831e-01, time/batch = 15.7706s	
11368/22950 (epoch 24.767), train_loss = 1.21405055, grad/param norm = 2.3736e-01, time/batch = 19.2873s	
11369/22950 (epoch 24.769), train_loss = 1.04489959, grad/param norm = 2.2745e-01, time/batch = 19.0186s	
11370/22950 (epoch 24.771), train_loss = 0.85816430, grad/param norm = 2.2618e-01, time/batch = 17.6882s	
11371/22950 (epoch 24.773), train_loss = 0.78179824, grad/param norm = 2.0074e-01, time/batch = 18.7881s	
11372/22950 (epoch 24.776), train_loss = 0.91965445, grad/param norm = 2.0542e-01, time/batch = 18.5357s	
11373/22950 (epoch 24.778), train_loss = 0.90251278, grad/param norm = 1.9713e-01, time/batch = 18.0415s	
11374/22950 (epoch 24.780), train_loss = 1.00459519, grad/param norm = 2.1198e-01, time/batch = 20.2780s	
11375/22950 (epoch 24.782), train_loss = 1.02281807, grad/param norm = 2.1138e-01, time/batch = 19.0316s	
11376/22950 (epoch 24.784), train_loss = 0.94917990, grad/param norm = 2.2321e-01, time/batch = 19.2060s	
11377/22950 (epoch 24.786), train_loss = 1.02894762, grad/param norm = 2.2925e-01, time/batch = 18.9650s	
11378/22950 (epoch 24.789), train_loss = 0.85958908, grad/param norm = 2.0623e-01, time/batch = 19.3693s	
11379/22950 (epoch 24.791), train_loss = 0.91089180, grad/param norm = 2.2784e-01, time/batch = 18.5255s	
11380/22950 (epoch 24.793), train_loss = 1.13973414, grad/param norm = 2.3109e-01, time/batch = 18.0576s	
11381/22950 (epoch 24.795), train_loss = 0.96121145, grad/param norm = 2.0410e-01, time/batch = 18.2016s	
11382/22950 (epoch 24.797), train_loss = 1.13891946, grad/param norm = 2.2154e-01, time/batch = 14.6228s	
11383/22950 (epoch 24.800), train_loss = 0.92074114, grad/param norm = 2.1638e-01, time/batch = 0.8555s	
11384/22950 (epoch 24.802), train_loss = 0.93617131, grad/param norm = 2.2681e-01, time/batch = 0.7285s	
11385/22950 (epoch 24.804), train_loss = 0.97748360, grad/param norm = 2.1918e-01, time/batch = 0.7237s	
11386/22950 (epoch 24.806), train_loss = 0.89327514, grad/param norm = 2.2483e-01, time/batch = 0.7213s	
11387/22950 (epoch 24.808), train_loss = 0.98000624, grad/param norm = 2.1028e-01, time/batch = 0.7018s	
11388/22950 (epoch 24.810), train_loss = 0.94645788, grad/param norm = 2.1479e-01, time/batch = 0.6956s	
11389/22950 (epoch 24.813), train_loss = 0.81893409, grad/param norm = 2.0181e-01, time/batch = 1.0156s	
11390/22950 (epoch 24.815), train_loss = 0.84052269, grad/param norm = 2.2483e-01, time/batch = 1.0316s	
11391/22950 (epoch 24.817), train_loss = 0.88521833, grad/param norm = 2.0243e-01, time/batch = 1.0452s	
11392/22950 (epoch 24.819), train_loss = 0.98010260, grad/param norm = 2.3400e-01, time/batch = 1.0354s	
11393/22950 (epoch 24.821), train_loss = 0.92275343, grad/param norm = 2.2185e-01, time/batch = 1.1068s	
11394/22950 (epoch 24.824), train_loss = 0.99416886, grad/param norm = 2.2191e-01, time/batch = 1.8712s	
11395/22950 (epoch 24.826), train_loss = 1.07466859, grad/param norm = 2.4055e-01, time/batch = 1.8789s	
11396/22950 (epoch 24.828), train_loss = 0.96850443, grad/param norm = 2.2714e-01, time/batch = 9.7540s	
11397/22950 (epoch 24.830), train_loss = 0.94544597, grad/param norm = 2.1525e-01, time/batch = 17.1948s	
11398/22950 (epoch 24.832), train_loss = 0.99784547, grad/param norm = 2.2803e-01, time/batch = 17.6322s	
11399/22950 (epoch 24.834), train_loss = 0.83129148, grad/param norm = 2.2052e-01, time/batch = 17.9618s	
11400/22950 (epoch 24.837), train_loss = 1.00568836, grad/param norm = 2.4030e-01, time/batch = 18.6133s	
11401/22950 (epoch 24.839), train_loss = 0.86471358, grad/param norm = 2.2935e-01, time/batch = 18.2056s	
11402/22950 (epoch 24.841), train_loss = 0.91900087, grad/param norm = 1.9935e-01, time/batch = 19.5216s	
11403/22950 (epoch 24.843), train_loss = 0.94375837, grad/param norm = 2.2874e-01, time/batch = 19.5309s	
11404/22950 (epoch 24.845), train_loss = 1.00022035, grad/param norm = 2.2833e-01, time/batch = 19.4433s	
11405/22950 (epoch 24.847), train_loss = 1.04001867, grad/param norm = 2.2766e-01, time/batch = 18.5370s	
11406/22950 (epoch 24.850), train_loss = 1.02494846, grad/param norm = 2.3865e-01, time/batch = 20.0279s	
11407/22950 (epoch 24.852), train_loss = 1.04233642, grad/param norm = 2.2726e-01, time/batch = 19.3016s	
11408/22950 (epoch 24.854), train_loss = 0.95958084, grad/param norm = 2.1514e-01, time/batch = 18.0998s	
11409/22950 (epoch 24.856), train_loss = 1.13798840, grad/param norm = 2.5246e-01, time/batch = 19.6266s	
11410/22950 (epoch 24.858), train_loss = 1.05086826, grad/param norm = 2.3050e-01, time/batch = 20.1276s	
11411/22950 (epoch 24.861), train_loss = 1.05589620, grad/param norm = 2.4120e-01, time/batch = 16.5337s	
11412/22950 (epoch 24.863), train_loss = 1.12231765, grad/param norm = 2.6081e-01, time/batch = 18.9315s	
11413/22950 (epoch 24.865), train_loss = 1.13333281, grad/param norm = 2.4275e-01, time/batch = 18.3033s	
11414/22950 (epoch 24.867), train_loss = 1.02188775, grad/param norm = 2.5597e-01, time/batch = 17.6101s	
11415/22950 (epoch 24.869), train_loss = 1.14517395, grad/param norm = 2.4826e-01, time/batch = 16.5434s	
11416/22950 (epoch 24.871), train_loss = 1.01940606, grad/param norm = 2.3194e-01, time/batch = 19.7967s	
11417/22950 (epoch 24.874), train_loss = 1.01651730, grad/param norm = 2.1178e-01, time/batch = 15.6796s	
11418/22950 (epoch 24.876), train_loss = 1.06333812, grad/param norm = 2.5093e-01, time/batch = 19.3717s	
11419/22950 (epoch 24.878), train_loss = 0.95715600, grad/param norm = 2.5590e-01, time/batch = 19.2988s	
11420/22950 (epoch 24.880), train_loss = 1.17036260, grad/param norm = 2.6523e-01, time/batch = 19.9583s	
11421/22950 (epoch 24.882), train_loss = 0.91160703, grad/param norm = 2.1825e-01, time/batch = 18.5403s	
11422/22950 (epoch 24.885), train_loss = 1.03383368, grad/param norm = 2.1554e-01, time/batch = 19.0401s	
11423/22950 (epoch 24.887), train_loss = 0.99552060, grad/param norm = 2.4030e-01, time/batch = 20.4605s	
11424/22950 (epoch 24.889), train_loss = 1.03131186, grad/param norm = 2.2897e-01, time/batch = 17.9504s	
11425/22950 (epoch 24.891), train_loss = 0.94362548, grad/param norm = 2.1704e-01, time/batch = 17.0023s	
11426/22950 (epoch 24.893), train_loss = 1.06600047, grad/param norm = 2.2531e-01, time/batch = 19.2929s	
11427/22950 (epoch 24.895), train_loss = 1.15706880, grad/param norm = 2.8565e-01, time/batch = 17.2113s	
11428/22950 (epoch 24.898), train_loss = 1.00046532, grad/param norm = 2.4079e-01, time/batch = 17.0406s	
11429/22950 (epoch 24.900), train_loss = 0.98324396, grad/param norm = 2.1244e-01, time/batch = 18.9420s	
11430/22950 (epoch 24.902), train_loss = 1.02743987, grad/param norm = 2.3731e-01, time/batch = 18.7016s	
11431/22950 (epoch 24.904), train_loss = 1.00717815, grad/param norm = 2.2441e-01, time/batch = 17.7022s	
11432/22950 (epoch 24.906), train_loss = 1.05659199, grad/param norm = 2.4979e-01, time/batch = 19.1047s	
11433/22950 (epoch 24.908), train_loss = 0.89631468, grad/param norm = 2.0410e-01, time/batch = 19.1227s	
11434/22950 (epoch 24.911), train_loss = 0.86742611, grad/param norm = 1.9934e-01, time/batch = 18.2933s	
11435/22950 (epoch 24.913), train_loss = 0.95456419, grad/param norm = 2.1928e-01, time/batch = 19.2102s	
11436/22950 (epoch 24.915), train_loss = 1.13103871, grad/param norm = 2.3736e-01, time/batch = 19.8745s	
11437/22950 (epoch 24.917), train_loss = 0.88753935, grad/param norm = 2.0915e-01, time/batch = 18.2001s	
11438/22950 (epoch 24.919), train_loss = 0.99362731, grad/param norm = 2.2447e-01, time/batch = 18.3736s	
11439/22950 (epoch 24.922), train_loss = 1.01354578, grad/param norm = 2.3046e-01, time/batch = 15.5226s	
11440/22950 (epoch 24.924), train_loss = 1.02769599, grad/param norm = 2.1778e-01, time/batch = 17.4596s	
11441/22950 (epoch 24.926), train_loss = 0.85952635, grad/param norm = 2.3757e-01, time/batch = 19.6880s	
11442/22950 (epoch 24.928), train_loss = 0.87575957, grad/param norm = 2.0445e-01, time/batch = 18.8671s	
11443/22950 (epoch 24.930), train_loss = 0.87497116, grad/param norm = 2.1718e-01, time/batch = 17.4995s	
11444/22950 (epoch 24.932), train_loss = 0.83373214, grad/param norm = 1.9092e-01, time/batch = 17.7703s	
11445/22950 (epoch 24.935), train_loss = 0.98676267, grad/param norm = 2.2665e-01, time/batch = 18.6283s	
11446/22950 (epoch 24.937), train_loss = 0.99735410, grad/param norm = 2.2792e-01, time/batch = 18.8669s	
11447/22950 (epoch 24.939), train_loss = 0.90250983, grad/param norm = 2.1829e-01, time/batch = 17.8738s	
11448/22950 (epoch 24.941), train_loss = 0.93494906, grad/param norm = 2.0716e-01, time/batch = 18.5403s	
11449/22950 (epoch 24.943), train_loss = 1.01651321, grad/param norm = 2.3161e-01, time/batch = 18.5581s	
11450/22950 (epoch 24.946), train_loss = 0.84811309, grad/param norm = 2.2712e-01, time/batch = 18.1156s	
11451/22950 (epoch 24.948), train_loss = 1.06763764, grad/param norm = 2.3374e-01, time/batch = 19.1410s	
11452/22950 (epoch 24.950), train_loss = 0.97867610, grad/param norm = 2.2254e-01, time/batch = 17.6099s	
11453/22950 (epoch 24.952), train_loss = 1.04069767, grad/param norm = 2.2569e-01, time/batch = 17.6164s	
11454/22950 (epoch 24.954), train_loss = 1.01631010, grad/param norm = 2.1929e-01, time/batch = 18.6497s	
11455/22950 (epoch 24.956), train_loss = 0.91600916, grad/param norm = 2.2215e-01, time/batch = 18.9609s	
11456/22950 (epoch 24.959), train_loss = 0.89696687, grad/param norm = 2.1722e-01, time/batch = 16.8926s	
11457/22950 (epoch 24.961), train_loss = 0.99151784, grad/param norm = 2.1056e-01, time/batch = 19.0487s	
11458/22950 (epoch 24.963), train_loss = 1.02851219, grad/param norm = 2.4084e-01, time/batch = 17.5373s	
11459/22950 (epoch 24.965), train_loss = 1.10862694, grad/param norm = 2.0972e-01, time/batch = 16.8547s	
11460/22950 (epoch 24.967), train_loss = 1.01519121, grad/param norm = 2.5047e-01, time/batch = 17.6805s	
11461/22950 (epoch 24.969), train_loss = 0.89412794, grad/param norm = 2.5393e-01, time/batch = 18.8040s	
11462/22950 (epoch 24.972), train_loss = 0.98722308, grad/param norm = 1.9959e-01, time/batch = 16.3646s	
11463/22950 (epoch 24.974), train_loss = 0.95620198, grad/param norm = 2.3085e-01, time/batch = 15.7273s	
11464/22950 (epoch 24.976), train_loss = 0.93231972, grad/param norm = 1.8883e-01, time/batch = 17.7061s	
11465/22950 (epoch 24.978), train_loss = 0.93030631, grad/param norm = 2.2825e-01, time/batch = 19.7822s	
11466/22950 (epoch 24.980), train_loss = 0.94907089, grad/param norm = 2.1441e-01, time/batch = 18.7057s	
11467/22950 (epoch 24.983), train_loss = 1.02379439, grad/param norm = 2.0480e-01, time/batch = 19.1299s	
11468/22950 (epoch 24.985), train_loss = 0.86969512, grad/param norm = 2.1721e-01, time/batch = 19.4590s	
11469/22950 (epoch 24.987), train_loss = 0.92926877, grad/param norm = 2.1113e-01, time/batch = 19.2837s	
11470/22950 (epoch 24.989), train_loss = 0.98412957, grad/param norm = 2.3092e-01, time/batch = 18.3804s	
11471/22950 (epoch 24.991), train_loss = 0.83615510, grad/param norm = 2.0956e-01, time/batch = 16.0587s	
11472/22950 (epoch 24.993), train_loss = 1.01900267, grad/param norm = 2.2071e-01, time/batch = 19.6190s	
11473/22950 (epoch 24.996), train_loss = 0.97631850, grad/param norm = 2.1171e-01, time/batch = 17.2966s	
11474/22950 (epoch 24.998), train_loss = 0.88951321, grad/param norm = 2.0973e-01, time/batch = 18.8758s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
11475/22950 (epoch 25.000), train_loss = 0.82269375, grad/param norm = 1.9891e-01, time/batch = 19.7052s	
11476/22950 (epoch 25.002), train_loss = 1.14070670, grad/param norm = 2.3155e-01, time/batch = 18.1175s	
11477/22950 (epoch 25.004), train_loss = 1.01166515, grad/param norm = 2.2033e-01, time/batch = 18.6191s	
11478/22950 (epoch 25.007), train_loss = 0.98111607, grad/param norm = 2.2495e-01, time/batch = 18.5423s	
11479/22950 (epoch 25.009), train_loss = 1.11203225, grad/param norm = 2.6224e-01, time/batch = 18.4551s	
11480/22950 (epoch 25.011), train_loss = 0.84601324, grad/param norm = 2.0967e-01, time/batch = 18.3758s	
11481/22950 (epoch 25.013), train_loss = 0.98648666, grad/param norm = 2.2858e-01, time/batch = 19.6791s	
11482/22950 (epoch 25.015), train_loss = 1.00083158, grad/param norm = 2.2810e-01, time/batch = 18.3648s	
11483/22950 (epoch 25.017), train_loss = 1.00127654, grad/param norm = 2.0714e-01, time/batch = 19.2472s	
11484/22950 (epoch 25.020), train_loss = 1.00687682, grad/param norm = 2.1431e-01, time/batch = 19.0317s	
11485/22950 (epoch 25.022), train_loss = 0.85271236, grad/param norm = 1.9846e-01, time/batch = 19.7674s	
11486/22950 (epoch 25.024), train_loss = 0.95006177, grad/param norm = 2.1403e-01, time/batch = 18.8669s	
11487/22950 (epoch 25.026), train_loss = 1.03981371, grad/param norm = 2.2902e-01, time/batch = 19.7100s	
11488/22950 (epoch 25.028), train_loss = 1.09201888, grad/param norm = 2.1058e-01, time/batch = 19.3680s	
11489/22950 (epoch 25.031), train_loss = 0.95320313, grad/param norm = 2.0350e-01, time/batch = 18.1150s	
11490/22950 (epoch 25.033), train_loss = 1.08719133, grad/param norm = 2.3878e-01, time/batch = 18.9542s	
11491/22950 (epoch 25.035), train_loss = 0.98216503, grad/param norm = 2.0616e-01, time/batch = 18.3414s	
11492/22950 (epoch 25.037), train_loss = 0.98266881, grad/param norm = 2.1870e-01, time/batch = 17.6040s	
11493/22950 (epoch 25.039), train_loss = 0.95603539, grad/param norm = 2.2174e-01, time/batch = 20.1949s	
11494/22950 (epoch 25.041), train_loss = 0.93461393, grad/param norm = 2.3369e-01, time/batch = 16.4560s	
11495/22950 (epoch 25.044), train_loss = 1.03505449, grad/param norm = 2.4333e-01, time/batch = 16.5218s	
11496/22950 (epoch 25.046), train_loss = 0.99650991, grad/param norm = 2.4084e-01, time/batch = 17.9561s	
11497/22950 (epoch 25.048), train_loss = 0.99585482, grad/param norm = 2.1759e-01, time/batch = 18.8839s	
11498/22950 (epoch 25.050), train_loss = 0.95137322, grad/param norm = 2.6214e-01, time/batch = 18.2820s	
11499/22950 (epoch 25.052), train_loss = 1.00779914, grad/param norm = 2.3088e-01, time/batch = 18.4343s	
11500/22950 (epoch 25.054), train_loss = 1.15370975, grad/param norm = 2.4126e-01, time/batch = 19.8654s	
11501/22950 (epoch 25.057), train_loss = 1.07845556, grad/param norm = 2.4215e-01, time/batch = 18.2678s	
11502/22950 (epoch 25.059), train_loss = 1.03776780, grad/param norm = 2.2011e-01, time/batch = 18.6907s	
11503/22950 (epoch 25.061), train_loss = 0.91957515, grad/param norm = 2.1865e-01, time/batch = 19.3027s	
11504/22950 (epoch 25.063), train_loss = 1.02235881, grad/param norm = 2.3493e-01, time/batch = 18.4515s	
11505/22950 (epoch 25.065), train_loss = 0.87561272, grad/param norm = 2.0581e-01, time/batch = 18.1991s	
11506/22950 (epoch 25.068), train_loss = 1.03327658, grad/param norm = 2.2439e-01, time/batch = 18.2881s	
11507/22950 (epoch 25.070), train_loss = 0.88785889, grad/param norm = 2.1699e-01, time/batch = 19.2916s	
11508/22950 (epoch 25.072), train_loss = 1.06644199, grad/param norm = 2.2816e-01, time/batch = 17.5223s	
11509/22950 (epoch 25.074), train_loss = 1.01108738, grad/param norm = 2.3395e-01, time/batch = 17.8832s	
11510/22950 (epoch 25.076), train_loss = 1.02684231, grad/param norm = 2.3824e-01, time/batch = 17.8614s	
11511/22950 (epoch 25.078), train_loss = 1.07195967, grad/param norm = 2.1985e-01, time/batch = 15.1424s	
11512/22950 (epoch 25.081), train_loss = 1.09598161, grad/param norm = 2.2967e-01, time/batch = 19.3462s	
11513/22950 (epoch 25.083), train_loss = 0.98964623, grad/param norm = 2.4289e-01, time/batch = 19.6952s	
11514/22950 (epoch 25.085), train_loss = 0.87935609, grad/param norm = 2.4782e-01, time/batch = 16.7092s	
11515/22950 (epoch 25.087), train_loss = 0.90551912, grad/param norm = 2.4254e-01, time/batch = 19.0400s	
11516/22950 (epoch 25.089), train_loss = 1.01819308, grad/param norm = 2.3798e-01, time/batch = 18.0424s	
11517/22950 (epoch 25.092), train_loss = 0.94424677, grad/param norm = 2.7377e-01, time/batch = 19.8004s	
11518/22950 (epoch 25.094), train_loss = 0.90167652, grad/param norm = 2.1862e-01, time/batch = 18.2119s	
11519/22950 (epoch 25.096), train_loss = 1.10111625, grad/param norm = 2.4116e-01, time/batch = 16.0996s	
11520/22950 (epoch 25.098), train_loss = 1.06145931, grad/param norm = 2.4888e-01, time/batch = 19.1327s	
11521/22950 (epoch 25.100), train_loss = 0.95352899, grad/param norm = 2.6318e-01, time/batch = 17.6955s	
11522/22950 (epoch 25.102), train_loss = 0.98497159, grad/param norm = 2.3150e-01, time/batch = 17.7214s	
11523/22950 (epoch 25.105), train_loss = 0.83632309, grad/param norm = 1.9692e-01, time/batch = 19.0429s	
11524/22950 (epoch 25.107), train_loss = 0.93786471, grad/param norm = 2.1644e-01, time/batch = 17.9520s	
11525/22950 (epoch 25.109), train_loss = 0.92082719, grad/param norm = 2.1730e-01, time/batch = 17.0309s	
11526/22950 (epoch 25.111), train_loss = 0.84041659, grad/param norm = 2.1724e-01, time/batch = 18.3033s	
11527/22950 (epoch 25.113), train_loss = 0.98433740, grad/param norm = 2.1514e-01, time/batch = 17.7244s	
11528/22950 (epoch 25.115), train_loss = 0.99249766, grad/param norm = 2.0790e-01, time/batch = 17.1297s	
11529/22950 (epoch 25.118), train_loss = 1.10715148, grad/param norm = 2.1621e-01, time/batch = 18.2019s	
11530/22950 (epoch 25.120), train_loss = 0.89192972, grad/param norm = 2.1937e-01, time/batch = 19.2026s	
11531/22950 (epoch 25.122), train_loss = 1.08097810, grad/param norm = 2.5421e-01, time/batch = 18.1160s	
11532/22950 (epoch 25.124), train_loss = 0.85117789, grad/param norm = 1.9837e-01, time/batch = 20.3639s	
11533/22950 (epoch 25.126), train_loss = 0.99240217, grad/param norm = 2.5554e-01, time/batch = 20.0389s	
11534/22950 (epoch 25.129), train_loss = 0.89147391, grad/param norm = 2.0442e-01, time/batch = 18.0295s	
11535/22950 (epoch 25.131), train_loss = 0.96568584, grad/param norm = 2.0671e-01, time/batch = 18.6347s	
11536/22950 (epoch 25.133), train_loss = 1.02945899, grad/param norm = 2.1578e-01, time/batch = 19.8765s	
11537/22950 (epoch 25.135), train_loss = 0.99443681, grad/param norm = 2.1896e-01, time/batch = 18.8552s	
11538/22950 (epoch 25.137), train_loss = 1.09933838, grad/param norm = 2.5146e-01, time/batch = 18.7706s	
11539/22950 (epoch 25.139), train_loss = 0.87621194, grad/param norm = 2.1566e-01, time/batch = 20.2879s	
11540/22950 (epoch 25.142), train_loss = 0.88479788, grad/param norm = 2.1488e-01, time/batch = 19.6094s	
11541/22950 (epoch 25.144), train_loss = 0.95121019, grad/param norm = 2.1001e-01, time/batch = 19.2031s	
11542/22950 (epoch 25.146), train_loss = 0.92767142, grad/param norm = 2.1639e-01, time/batch = 15.8502s	
11543/22950 (epoch 25.148), train_loss = 0.91584301, grad/param norm = 2.1080e-01, time/batch = 17.7995s	
11544/22950 (epoch 25.150), train_loss = 0.98771474, grad/param norm = 2.1288e-01, time/batch = 17.7631s	
11545/22950 (epoch 25.153), train_loss = 0.92268951, grad/param norm = 2.0992e-01, time/batch = 16.2874s	
11546/22950 (epoch 25.155), train_loss = 0.92299009, grad/param norm = 1.9840e-01, time/batch = 19.1205s	
11547/22950 (epoch 25.157), train_loss = 0.97239806, grad/param norm = 2.1026e-01, time/batch = 18.1234s	
11548/22950 (epoch 25.159), train_loss = 0.89883851, grad/param norm = 1.9765e-01, time/batch = 19.1244s	
11549/22950 (epoch 25.161), train_loss = 0.95440004, grad/param norm = 2.3024e-01, time/batch = 18.0440s	
11550/22950 (epoch 25.163), train_loss = 0.85523897, grad/param norm = 2.1106e-01, time/batch = 19.0433s	
11551/22950 (epoch 25.166), train_loss = 1.06467014, grad/param norm = 2.7420e-01, time/batch = 18.2032s	
11552/22950 (epoch 25.168), train_loss = 1.02732214, grad/param norm = 2.5430e-01, time/batch = 16.4332s	
11553/22950 (epoch 25.170), train_loss = 0.95389835, grad/param norm = 2.5052e-01, time/batch = 20.2811s	
11554/22950 (epoch 25.172), train_loss = 1.00578149, grad/param norm = 2.0667e-01, time/batch = 19.2615s	
11555/22950 (epoch 25.174), train_loss = 1.05743905, grad/param norm = 2.3705e-01, time/batch = 19.3850s	
11556/22950 (epoch 25.176), train_loss = 1.05534643, grad/param norm = 2.3955e-01, time/batch = 18.6208s	
11557/22950 (epoch 25.179), train_loss = 1.03394857, grad/param norm = 2.4379e-01, time/batch = 17.7525s	
11558/22950 (epoch 25.181), train_loss = 1.21986623, grad/param norm = 2.3676e-01, time/batch = 17.6166s	
11559/22950 (epoch 25.183), train_loss = 1.05311247, grad/param norm = 2.3289e-01, time/batch = 18.4713s	
11560/22950 (epoch 25.185), train_loss = 0.99923560, grad/param norm = 2.0171e-01, time/batch = 16.7790s	
11561/22950 (epoch 25.187), train_loss = 0.90209552, grad/param norm = 2.3799e-01, time/batch = 17.1129s	
11562/22950 (epoch 25.190), train_loss = 0.81623434, grad/param norm = 2.0280e-01, time/batch = 18.8812s	
11563/22950 (epoch 25.192), train_loss = 0.81932497, grad/param norm = 2.1425e-01, time/batch = 18.2001s	
11564/22950 (epoch 25.194), train_loss = 0.95887785, grad/param norm = 2.6909e-01, time/batch = 17.8847s	
11565/22950 (epoch 25.196), train_loss = 0.77783836, grad/param norm = 2.2544e-01, time/batch = 17.8583s	
11566/22950 (epoch 25.198), train_loss = 1.04213972, grad/param norm = 2.2874e-01, time/batch = 18.1050s	
11567/22950 (epoch 25.200), train_loss = 0.89951035, grad/param norm = 2.0617e-01, time/batch = 17.7954s	
11568/22950 (epoch 25.203), train_loss = 0.85878121, grad/param norm = 2.1275e-01, time/batch = 18.7815s	
11569/22950 (epoch 25.205), train_loss = 0.92765369, grad/param norm = 2.1136e-01, time/batch = 18.6745s	
11570/22950 (epoch 25.207), train_loss = 0.97643642, grad/param norm = 2.1072e-01, time/batch = 18.6197s	
11571/22950 (epoch 25.209), train_loss = 0.97179664, grad/param norm = 2.3623e-01, time/batch = 18.7070s	
11572/22950 (epoch 25.211), train_loss = 0.81041187, grad/param norm = 2.2331e-01, time/batch = 19.2128s	
11573/22950 (epoch 25.214), train_loss = 0.92881018, grad/param norm = 2.1261e-01, time/batch = 17.7040s	
11574/22950 (epoch 25.216), train_loss = 1.04928716, grad/param norm = 2.2385e-01, time/batch = 16.5743s	
11575/22950 (epoch 25.218), train_loss = 0.97091132, grad/param norm = 2.1332e-01, time/batch = 18.8633s	
11576/22950 (epoch 25.220), train_loss = 1.04220497, grad/param norm = 2.1416e-01, time/batch = 18.4672s	
11577/22950 (epoch 25.222), train_loss = 1.07823198, grad/param norm = 2.4433e-01, time/batch = 17.8665s	
11578/22950 (epoch 25.224), train_loss = 0.95109348, grad/param norm = 2.0498e-01, time/batch = 17.9548s	
11579/22950 (epoch 25.227), train_loss = 1.04238506, grad/param norm = 2.1355e-01, time/batch = 17.9753s	
11580/22950 (epoch 25.229), train_loss = 1.07242102, grad/param norm = 2.3338e-01, time/batch = 17.1230s	
11581/22950 (epoch 25.231), train_loss = 0.84553272, grad/param norm = 2.1751e-01, time/batch = 17.7929s	
11582/22950 (epoch 25.233), train_loss = 0.91859111, grad/param norm = 2.2923e-01, time/batch = 19.2144s	
11583/22950 (epoch 25.235), train_loss = 1.12874431, grad/param norm = 2.2660e-01, time/batch = 18.9567s	
11584/22950 (epoch 25.237), train_loss = 0.91372619, grad/param norm = 2.1597e-01, time/batch = 16.8851s	
11585/22950 (epoch 25.240), train_loss = 0.96346766, grad/param norm = 2.2675e-01, time/batch = 20.4430s	
11586/22950 (epoch 25.242), train_loss = 1.10570024, grad/param norm = 2.2580e-01, time/batch = 18.5365s	
11587/22950 (epoch 25.244), train_loss = 1.09560028, grad/param norm = 2.4375e-01, time/batch = 18.5393s	
11588/22950 (epoch 25.246), train_loss = 1.08128169, grad/param norm = 2.3180e-01, time/batch = 18.5376s	
11589/22950 (epoch 25.248), train_loss = 1.02113339, grad/param norm = 2.2960e-01, time/batch = 19.0430s	
11590/22950 (epoch 25.251), train_loss = 0.91488151, grad/param norm = 2.0757e-01, time/batch = 32.1746s	
11591/22950 (epoch 25.253), train_loss = 0.94911627, grad/param norm = 2.4449e-01, time/batch = 19.9588s	
11592/22950 (epoch 25.255), train_loss = 1.01975587, grad/param norm = 2.5404e-01, time/batch = 17.9559s	
11593/22950 (epoch 25.257), train_loss = 1.07117004, grad/param norm = 2.2749e-01, time/batch = 17.6153s	
11594/22950 (epoch 25.259), train_loss = 0.85039147, grad/param norm = 2.1181e-01, time/batch = 18.3025s	
11595/22950 (epoch 25.261), train_loss = 0.92669624, grad/param norm = 2.1354e-01, time/batch = 18.2105s	
11596/22950 (epoch 25.264), train_loss = 0.89596588, grad/param norm = 2.1553e-01, time/batch = 18.5433s	
11597/22950 (epoch 25.266), train_loss = 0.97179153, grad/param norm = 2.2848e-01, time/batch = 15.6086s	
11598/22950 (epoch 25.268), train_loss = 0.97237262, grad/param norm = 2.1373e-01, time/batch = 18.9551s	
11599/22950 (epoch 25.270), train_loss = 0.97202338, grad/param norm = 2.0617e-01, time/batch = 19.1104s	
11600/22950 (epoch 25.272), train_loss = 1.02482533, grad/param norm = 2.3463e-01, time/batch = 19.6974s	
11601/22950 (epoch 25.275), train_loss = 0.91684136, grad/param norm = 2.3007e-01, time/batch = 20.4414s	
11602/22950 (epoch 25.277), train_loss = 0.82009482, grad/param norm = 1.9797e-01, time/batch = 17.8286s	
11603/22950 (epoch 25.279), train_loss = 0.88861364, grad/param norm = 2.3409e-01, time/batch = 19.7738s	
11604/22950 (epoch 25.281), train_loss = 0.91971327, grad/param norm = 2.2409e-01, time/batch = 19.8869s	
11605/22950 (epoch 25.283), train_loss = 0.83389243, grad/param norm = 1.9075e-01, time/batch = 17.6838s	
11606/22950 (epoch 25.285), train_loss = 0.98742110, grad/param norm = 2.0826e-01, time/batch = 19.6221s	
11607/22950 (epoch 25.288), train_loss = 1.05998011, grad/param norm = 2.3345e-01, time/batch = 18.1217s	
11608/22950 (epoch 25.290), train_loss = 0.91298055, grad/param norm = 2.0565e-01, time/batch = 16.5494s	
11609/22950 (epoch 25.292), train_loss = 1.06247931, grad/param norm = 2.2997e-01, time/batch = 17.7852s	
11610/22950 (epoch 25.294), train_loss = 0.96083936, grad/param norm = 2.0828e-01, time/batch = 19.2212s	
11611/22950 (epoch 25.296), train_loss = 0.76837456, grad/param norm = 1.8593e-01, time/batch = 18.3597s	
11612/22950 (epoch 25.298), train_loss = 0.96516712, grad/param norm = 1.9582e-01, time/batch = 19.5418s	
11613/22950 (epoch 25.301), train_loss = 0.98441053, grad/param norm = 2.2838e-01, time/batch = 19.5380s	
11614/22950 (epoch 25.303), train_loss = 0.97824259, grad/param norm = 2.0992e-01, time/batch = 18.1117s	
11615/22950 (epoch 25.305), train_loss = 0.95393441, grad/param norm = 2.5184e-01, time/batch = 18.7114s	
11616/22950 (epoch 25.307), train_loss = 1.08216782, grad/param norm = 2.2756e-01, time/batch = 18.0521s	
11617/22950 (epoch 25.309), train_loss = 0.91300256, grad/param norm = 2.0519e-01, time/batch = 15.5375s	
11618/22950 (epoch 25.312), train_loss = 0.97984245, grad/param norm = 2.1822e-01, time/batch = 16.8003s	
11619/22950 (epoch 25.314), train_loss = 0.98158036, grad/param norm = 2.1465e-01, time/batch = 19.0412s	
11620/22950 (epoch 25.316), train_loss = 0.97411958, grad/param norm = 2.4380e-01, time/batch = 18.6981s	
11621/22950 (epoch 25.318), train_loss = 0.82141340, grad/param norm = 1.7864e-01, time/batch = 18.3707s	
11622/22950 (epoch 25.320), train_loss = 0.89533227, grad/param norm = 2.0435e-01, time/batch = 19.2069s	
11623/22950 (epoch 25.322), train_loss = 0.91227187, grad/param norm = 2.1550e-01, time/batch = 18.4562s	
11624/22950 (epoch 25.325), train_loss = 0.76899995, grad/param norm = 1.9189e-01, time/batch = 19.1903s	
11625/22950 (epoch 25.327), train_loss = 0.78609419, grad/param norm = 1.8685e-01, time/batch = 16.8779s	
11626/22950 (epoch 25.329), train_loss = 0.90481694, grad/param norm = 2.0171e-01, time/batch = 19.0353s	
11627/22950 (epoch 25.331), train_loss = 0.82633885, grad/param norm = 1.9466e-01, time/batch = 19.7796s	
11628/22950 (epoch 25.333), train_loss = 0.92734244, grad/param norm = 2.1603e-01, time/batch = 18.6155s	
11629/22950 (epoch 25.336), train_loss = 0.93434056, grad/param norm = 2.1742e-01, time/batch = 19.6264s	
11630/22950 (epoch 25.338), train_loss = 0.94980695, grad/param norm = 2.1473e-01, time/batch = 19.3880s	
11631/22950 (epoch 25.340), train_loss = 0.95353159, grad/param norm = 2.3124e-01, time/batch = 17.2470s	
11632/22950 (epoch 25.342), train_loss = 1.09064159, grad/param norm = 2.3715e-01, time/batch = 19.7945s	
11633/22950 (epoch 25.344), train_loss = 0.93037482, grad/param norm = 2.1581e-01, time/batch = 15.4453s	
11634/22950 (epoch 25.346), train_loss = 1.05729765, grad/param norm = 2.5272e-01, time/batch = 18.7820s	
11635/22950 (epoch 25.349), train_loss = 0.96072576, grad/param norm = 2.1618e-01, time/batch = 18.2884s	
11636/22950 (epoch 25.351), train_loss = 0.96433025, grad/param norm = 2.1886e-01, time/batch = 19.8598s	
11637/22950 (epoch 25.353), train_loss = 1.02766286, grad/param norm = 2.8010e-01, time/batch = 18.1700s	
11638/22950 (epoch 25.355), train_loss = 1.09474323, grad/param norm = 2.8278e-01, time/batch = 15.8307s	
11639/22950 (epoch 25.357), train_loss = 0.97959731, grad/param norm = 2.4996e-01, time/batch = 19.4555s	
11640/22950 (epoch 25.359), train_loss = 0.97248483, grad/param norm = 2.3492e-01, time/batch = 18.6898s	
11641/22950 (epoch 25.362), train_loss = 1.01037083, grad/param norm = 2.6853e-01, time/batch = 18.5359s	
11642/22950 (epoch 25.364), train_loss = 0.97714468, grad/param norm = 2.6598e-01, time/batch = 18.8645s	
11643/22950 (epoch 25.366), train_loss = 0.95445191, grad/param norm = 2.2062e-01, time/batch = 19.5400s	
11644/22950 (epoch 25.368), train_loss = 1.05340271, grad/param norm = 2.4682e-01, time/batch = 19.4478s	
11645/22950 (epoch 25.370), train_loss = 0.93974363, grad/param norm = 2.2404e-01, time/batch = 18.4604s	
11646/22950 (epoch 25.373), train_loss = 0.85726307, grad/param norm = 2.0761e-01, time/batch = 19.5198s	
11647/22950 (epoch 25.375), train_loss = 1.07290553, grad/param norm = 2.3091e-01, time/batch = 19.4435s	
11648/22950 (epoch 25.377), train_loss = 0.87882843, grad/param norm = 2.3661e-01, time/batch = 19.3853s	
11649/22950 (epoch 25.379), train_loss = 1.00469588, grad/param norm = 2.6272e-01, time/batch = 18.1267s	
11650/22950 (epoch 25.381), train_loss = 0.84204065, grad/param norm = 2.1585e-01, time/batch = 17.4527s	
11651/22950 (epoch 25.383), train_loss = 0.95329879, grad/param norm = 2.1960e-01, time/batch = 18.3755s	
11652/22950 (epoch 25.386), train_loss = 0.87845968, grad/param norm = 2.1977e-01, time/batch = 18.7163s	
11653/22950 (epoch 25.388), train_loss = 1.00732767, grad/param norm = 2.4070e-01, time/batch = 16.9595s	
11654/22950 (epoch 25.390), train_loss = 0.85207890, grad/param norm = 2.0702e-01, time/batch = 19.8685s	
11655/22950 (epoch 25.392), train_loss = 0.89371032, grad/param norm = 2.1588e-01, time/batch = 19.2694s	
11656/22950 (epoch 25.394), train_loss = 0.89481791, grad/param norm = 1.9543e-01, time/batch = 17.9579s	
11657/22950 (epoch 25.397), train_loss = 1.09766164, grad/param norm = 2.2450e-01, time/batch = 15.6959s	
11658/22950 (epoch 25.399), train_loss = 1.10205344, grad/param norm = 2.5050e-01, time/batch = 17.4438s	
11659/22950 (epoch 25.401), train_loss = 1.15933358, grad/param norm = 2.9155e-01, time/batch = 20.6350s	
11660/22950 (epoch 25.403), train_loss = 0.93112529, grad/param norm = 2.6989e-01, time/batch = 19.0080s	
11661/22950 (epoch 25.405), train_loss = 1.07394661, grad/param norm = 2.4219e-01, time/batch = 19.7894s	
11662/22950 (epoch 25.407), train_loss = 1.11632908, grad/param norm = 2.0840e-01, time/batch = 20.7874s	
11663/22950 (epoch 25.410), train_loss = 0.93857882, grad/param norm = 2.1541e-01, time/batch = 18.1048s	
11664/22950 (epoch 25.412), train_loss = 0.94929549, grad/param norm = 2.2438e-01, time/batch = 20.0206s	
11665/22950 (epoch 25.414), train_loss = 1.06103992, grad/param norm = 2.2065e-01, time/batch = 19.2952s	
11666/22950 (epoch 25.416), train_loss = 1.01283111, grad/param norm = 2.5460e-01, time/batch = 17.4377s	
11667/22950 (epoch 25.418), train_loss = 0.99388563, grad/param norm = 2.5460e-01, time/batch = 17.1272s	
11668/22950 (epoch 25.420), train_loss = 1.04998285, grad/param norm = 2.7201e-01, time/batch = 19.1048s	
11669/22950 (epoch 25.423), train_loss = 0.91525846, grad/param norm = 2.1766e-01, time/batch = 18.3318s	
11670/22950 (epoch 25.425), train_loss = 0.92341008, grad/param norm = 1.9934e-01, time/batch = 19.3760s	
11671/22950 (epoch 25.427), train_loss = 0.97092426, grad/param norm = 2.2719e-01, time/batch = 19.1171s	
11672/22950 (epoch 25.429), train_loss = 0.95023254, grad/param norm = 2.0307e-01, time/batch = 18.9461s	
11673/22950 (epoch 25.431), train_loss = 1.05094208, grad/param norm = 2.4864e-01, time/batch = 16.6053s	
11674/22950 (epoch 25.434), train_loss = 0.97000713, grad/param norm = 2.2428e-01, time/batch = 16.7194s	
11675/22950 (epoch 25.436), train_loss = 1.05065541, grad/param norm = 2.3819e-01, time/batch = 18.6222s	
11676/22950 (epoch 25.438), train_loss = 1.00616670, grad/param norm = 2.3974e-01, time/batch = 18.3577s	
11677/22950 (epoch 25.440), train_loss = 1.06818614, grad/param norm = 2.2618e-01, time/batch = 17.8820s	
11678/22950 (epoch 25.442), train_loss = 1.14604330, grad/param norm = 2.5865e-01, time/batch = 20.3633s	
11679/22950 (epoch 25.444), train_loss = 1.03315773, grad/param norm = 2.4458e-01, time/batch = 18.0240s	
11680/22950 (epoch 25.447), train_loss = 1.15371922, grad/param norm = 2.5674e-01, time/batch = 20.3785s	
11681/22950 (epoch 25.449), train_loss = 0.87110359, grad/param norm = 1.9661e-01, time/batch = 19.1135s	
11682/22950 (epoch 25.451), train_loss = 0.98466133, grad/param norm = 2.1629e-01, time/batch = 17.4657s	
11683/22950 (epoch 25.453), train_loss = 1.02880436, grad/param norm = 2.2447e-01, time/batch = 18.3769s	
11684/22950 (epoch 25.455), train_loss = 0.94301417, grad/param norm = 1.9397e-01, time/batch = 18.8743s	
11685/22950 (epoch 25.458), train_loss = 1.03622902, grad/param norm = 2.4743e-01, time/batch = 18.7709s	
11686/22950 (epoch 25.460), train_loss = 1.04256466, grad/param norm = 2.1231e-01, time/batch = 17.6239s	
11687/22950 (epoch 25.462), train_loss = 0.98776616, grad/param norm = 2.1720e-01, time/batch = 17.1305s	
11688/22950 (epoch 25.464), train_loss = 0.93247588, grad/param norm = 2.0022e-01, time/batch = 19.7922s	
11689/22950 (epoch 25.466), train_loss = 1.05168583, grad/param norm = 2.3788e-01, time/batch = 15.8548s	
11690/22950 (epoch 25.468), train_loss = 1.07421920, grad/param norm = 2.3475e-01, time/batch = 18.6072s	
11691/22950 (epoch 25.471), train_loss = 1.02778928, grad/param norm = 2.3870e-01, time/batch = 17.9592s	
11692/22950 (epoch 25.473), train_loss = 1.04675713, grad/param norm = 2.2878e-01, time/batch = 17.7116s	
11693/22950 (epoch 25.475), train_loss = 1.18689979, grad/param norm = 2.4195e-01, time/batch = 18.1311s	
11694/22950 (epoch 25.477), train_loss = 0.98080871, grad/param norm = 2.2902e-01, time/batch = 19.5402s	
11695/22950 (epoch 25.479), train_loss = 0.88976520, grad/param norm = 2.0965e-01, time/batch = 17.3084s	
11696/22950 (epoch 25.481), train_loss = 1.05822579, grad/param norm = 2.5092e-01, time/batch = 19.3095s	
11697/22950 (epoch 25.484), train_loss = 1.00925672, grad/param norm = 2.6157e-01, time/batch = 17.1293s	
11698/22950 (epoch 25.486), train_loss = 0.85726378, grad/param norm = 2.1910e-01, time/batch = 18.6998s	
11699/22950 (epoch 25.488), train_loss = 0.93607889, grad/param norm = 2.7132e-01, time/batch = 17.9613s	
11700/22950 (epoch 25.490), train_loss = 0.86802092, grad/param norm = 2.4694e-01, time/batch = 18.9628s	
11701/22950 (epoch 25.492), train_loss = 0.94393556, grad/param norm = 2.2848e-01, time/batch = 19.4734s	
11702/22950 (epoch 25.495), train_loss = 0.93456414, grad/param norm = 2.2225e-01, time/batch = 17.8646s	
11703/22950 (epoch 25.497), train_loss = 1.03466502, grad/param norm = 2.4101e-01, time/batch = 20.3675s	
11704/22950 (epoch 25.499), train_loss = 1.11730074, grad/param norm = 2.2104e-01, time/batch = 19.7052s	
11705/22950 (epoch 25.501), train_loss = 1.06436302, grad/param norm = 2.6349e-01, time/batch = 17.5267s	
11706/22950 (epoch 25.503), train_loss = 1.09054871, grad/param norm = 2.3980e-01, time/batch = 17.4644s	
11707/22950 (epoch 25.505), train_loss = 0.87281024, grad/param norm = 2.1362e-01, time/batch = 18.2808s	
11708/22950 (epoch 25.508), train_loss = 1.03688874, grad/param norm = 2.3066e-01, time/batch = 18.6133s	
11709/22950 (epoch 25.510), train_loss = 0.98072277, grad/param norm = 2.1837e-01, time/batch = 17.8648s	
11710/22950 (epoch 25.512), train_loss = 0.87034853, grad/param norm = 2.2472e-01, time/batch = 18.9605s	
11711/22950 (epoch 25.514), train_loss = 0.92772806, grad/param norm = 1.8690e-01, time/batch = 18.2142s	
11712/22950 (epoch 25.516), train_loss = 0.95567332, grad/param norm = 2.3170e-01, time/batch = 18.7921s	
11713/22950 (epoch 25.519), train_loss = 0.96625548, grad/param norm = 2.2287e-01, time/batch = 15.7765s	
11714/22950 (epoch 25.521), train_loss = 0.96915997, grad/param norm = 2.2563e-01, time/batch = 19.1152s	
11715/22950 (epoch 25.523), train_loss = 0.79487659, grad/param norm = 2.1585e-01, time/batch = 19.0312s	
11716/22950 (epoch 25.525), train_loss = 0.89931428, grad/param norm = 1.9506e-01, time/batch = 17.8829s	
11717/22950 (epoch 25.527), train_loss = 0.84321906, grad/param norm = 2.2080e-01, time/batch = 18.7147s	
11718/22950 (epoch 25.529), train_loss = 0.98680650, grad/param norm = 2.1031e-01, time/batch = 16.9446s	
11719/22950 (epoch 25.532), train_loss = 0.93493895, grad/param norm = 2.1019e-01, time/batch = 17.7782s	
11720/22950 (epoch 25.534), train_loss = 1.01636351, grad/param norm = 2.2207e-01, time/batch = 18.7962s	
11721/22950 (epoch 25.536), train_loss = 1.04237221, grad/param norm = 2.8038e-01, time/batch = 18.0277s	
11722/22950 (epoch 25.538), train_loss = 1.02488064, grad/param norm = 2.4941e-01, time/batch = 18.2046s	
11723/22950 (epoch 25.540), train_loss = 1.03911420, grad/param norm = 2.5295e-01, time/batch = 20.0374s	
11724/22950 (epoch 25.542), train_loss = 1.13260602, grad/param norm = 2.4862e-01, time/batch = 16.9470s	
11725/22950 (epoch 25.545), train_loss = 0.94585924, grad/param norm = 2.1288e-01, time/batch = 20.0299s	
11726/22950 (epoch 25.547), train_loss = 0.95761447, grad/param norm = 2.1358e-01, time/batch = 19.3811s	
11727/22950 (epoch 25.549), train_loss = 0.91550083, grad/param norm = 2.3935e-01, time/batch = 18.8651s	
11728/22950 (epoch 25.551), train_loss = 0.96478778, grad/param norm = 2.3674e-01, time/batch = 19.8598s	
11729/22950 (epoch 25.553), train_loss = 0.93527090, grad/param norm = 2.5136e-01, time/batch = 20.0471s	
11730/22950 (epoch 25.556), train_loss = 1.01213220, grad/param norm = 2.2724e-01, time/batch = 18.4678s	
11731/22950 (epoch 25.558), train_loss = 0.85079873, grad/param norm = 2.2498e-01, time/batch = 19.2705s	
11732/22950 (epoch 25.560), train_loss = 0.95336787, grad/param norm = 2.1312e-01, time/batch = 18.8781s	
11733/22950 (epoch 25.562), train_loss = 0.89850376, grad/param norm = 2.0022e-01, time/batch = 16.6091s	
11734/22950 (epoch 25.564), train_loss = 1.02261532, grad/param norm = 2.4744e-01, time/batch = 17.2622s	
11735/22950 (epoch 25.566), train_loss = 0.98689162, grad/param norm = 2.1587e-01, time/batch = 17.9661s	
11736/22950 (epoch 25.569), train_loss = 0.96769811, grad/param norm = 2.2250e-01, time/batch = 15.1409s	
11737/22950 (epoch 25.571), train_loss = 0.95513386, grad/param norm = 2.3624e-01, time/batch = 18.6917s	
11738/22950 (epoch 25.573), train_loss = 0.97912148, grad/param norm = 2.4500e-01, time/batch = 19.2115s	
11739/22950 (epoch 25.575), train_loss = 1.09219212, grad/param norm = 2.8825e-01, time/batch = 19.9410s	
11740/22950 (epoch 25.577), train_loss = 0.99264201, grad/param norm = 2.7786e-01, time/batch = 18.9569s	
11741/22950 (epoch 25.580), train_loss = 1.04036859, grad/param norm = 2.4725e-01, time/batch = 19.1194s	
11742/22950 (epoch 25.582), train_loss = 1.14798254, grad/param norm = 2.4724e-01, time/batch = 19.1336s	
11743/22950 (epoch 25.584), train_loss = 0.84036711, grad/param norm = 2.0079e-01, time/batch = 15.8551s	
11744/22950 (epoch 25.586), train_loss = 0.89957823, grad/param norm = 2.3257e-01, time/batch = 16.9589s	
11745/22950 (epoch 25.588), train_loss = 1.10796441, grad/param norm = 2.2089e-01, time/batch = 19.8842s	
11746/22950 (epoch 25.590), train_loss = 0.99734043, grad/param norm = 2.3263e-01, time/batch = 19.8468s	
11747/22950 (epoch 25.593), train_loss = 0.95537579, grad/param norm = 2.3103e-01, time/batch = 17.8637s	
11748/22950 (epoch 25.595), train_loss = 0.87731103, grad/param norm = 2.7874e-01, time/batch = 19.6359s	
11749/22950 (epoch 25.597), train_loss = 1.05654816, grad/param norm = 2.4256e-01, time/batch = 17.9566s	
11750/22950 (epoch 25.599), train_loss = 1.00552236, grad/param norm = 2.7410e-01, time/batch = 17.3599s	
11751/22950 (epoch 25.601), train_loss = 1.02136641, grad/param norm = 2.3815e-01, time/batch = 18.4438s	
11752/22950 (epoch 25.603), train_loss = 1.10588913, grad/param norm = 2.3177e-01, time/batch = 18.6908s	
11753/22950 (epoch 25.606), train_loss = 0.98111431, grad/param norm = 2.5031e-01, time/batch = 19.1911s	
11754/22950 (epoch 25.608), train_loss = 1.01762224, grad/param norm = 2.3901e-01, time/batch = 19.1745s	
11755/22950 (epoch 25.610), train_loss = 0.96650920, grad/param norm = 2.2201e-01, time/batch = 19.7033s	
11756/22950 (epoch 25.612), train_loss = 0.96946568, grad/param norm = 2.3196e-01, time/batch = 19.2818s	
11757/22950 (epoch 25.614), train_loss = 1.09365273, grad/param norm = 2.4244e-01, time/batch = 19.4477s	
11758/22950 (epoch 25.617), train_loss = 0.96893395, grad/param norm = 2.1729e-01, time/batch = 19.0512s	
11759/22950 (epoch 25.619), train_loss = 0.93607306, grad/param norm = 2.0027e-01, time/batch = 19.7890s	
11760/22950 (epoch 25.621), train_loss = 1.06648163, grad/param norm = 2.0409e-01, time/batch = 18.6066s	
11761/22950 (epoch 25.623), train_loss = 1.05546670, grad/param norm = 2.2282e-01, time/batch = 18.0889s	
11762/22950 (epoch 25.625), train_loss = 0.93775405, grad/param norm = 2.0155e-01, time/batch = 19.5470s	
11763/22950 (epoch 25.627), train_loss = 0.95616519, grad/param norm = 2.3675e-01, time/batch = 18.7769s	
11764/22950 (epoch 25.630), train_loss = 0.85155557, grad/param norm = 2.0991e-01, time/batch = 18.3790s	
11765/22950 (epoch 25.632), train_loss = 0.91919235, grad/param norm = 2.2850e-01, time/batch = 19.3733s	
11766/22950 (epoch 25.634), train_loss = 0.99618367, grad/param norm = 2.2778e-01, time/batch = 17.9410s	
11767/22950 (epoch 25.636), train_loss = 1.00388314, grad/param norm = 2.3130e-01, time/batch = 19.4476s	
11768/22950 (epoch 25.638), train_loss = 0.91222286, grad/param norm = 2.1438e-01, time/batch = 18.5520s	
11769/22950 (epoch 25.641), train_loss = 0.94928186, grad/param norm = 2.0836e-01, time/batch = 17.6900s	
11770/22950 (epoch 25.643), train_loss = 1.02888126, grad/param norm = 2.6612e-01, time/batch = 16.6832s	
11771/22950 (epoch 25.645), train_loss = 0.93228124, grad/param norm = 2.1867e-01, time/batch = 18.3141s	
11772/22950 (epoch 25.647), train_loss = 0.96843018, grad/param norm = 2.5046e-01, time/batch = 18.8796s	
11773/22950 (epoch 25.649), train_loss = 0.95857394, grad/param norm = 2.3256e-01, time/batch = 18.7844s	
11774/22950 (epoch 25.651), train_loss = 1.04230763, grad/param norm = 2.3303e-01, time/batch = 19.7902s	
11775/22950 (epoch 25.654), train_loss = 0.83231096, grad/param norm = 2.0530e-01, time/batch = 19.8686s	
11776/22950 (epoch 25.656), train_loss = 1.04062884, grad/param norm = 2.6416e-01, time/batch = 17.4529s	
11777/22950 (epoch 25.658), train_loss = 0.88395370, grad/param norm = 2.3361e-01, time/batch = 19.6240s	
11778/22950 (epoch 25.660), train_loss = 0.80379478, grad/param norm = 2.2718e-01, time/batch = 19.7955s	
11779/22950 (epoch 25.662), train_loss = 0.81299432, grad/param norm = 2.0413e-01, time/batch = 18.1063s	
11780/22950 (epoch 25.664), train_loss = 0.95521572, grad/param norm = 2.1443e-01, time/batch = 18.9727s	
11781/22950 (epoch 25.667), train_loss = 0.96282595, grad/param norm = 2.3937e-01, time/batch = 19.2073s	
11782/22950 (epoch 25.669), train_loss = 0.97654658, grad/param norm = 2.2925e-01, time/batch = 30.0535s	
11783/22950 (epoch 25.671), train_loss = 0.96699970, grad/param norm = 2.1013e-01, time/batch = 18.4881s	
11784/22950 (epoch 25.673), train_loss = 0.91152850, grad/param norm = 2.3117e-01, time/batch = 18.3492s	
11785/22950 (epoch 25.675), train_loss = 0.98300375, grad/param norm = 2.3051e-01, time/batch = 16.1228s	
11786/22950 (epoch 25.678), train_loss = 0.96973565, grad/param norm = 2.3017e-01, time/batch = 17.7790s	
11787/22950 (epoch 25.680), train_loss = 0.96848529, grad/param norm = 2.1044e-01, time/batch = 19.5429s	
11788/22950 (epoch 25.682), train_loss = 0.94996003, grad/param norm = 2.4438e-01, time/batch = 17.6108s	
11789/22950 (epoch 25.684), train_loss = 1.06622442, grad/param norm = 2.4695e-01, time/batch = 19.3769s	
11790/22950 (epoch 25.686), train_loss = 1.05751260, grad/param norm = 2.2453e-01, time/batch = 18.9610s	
11791/22950 (epoch 25.688), train_loss = 1.00967784, grad/param norm = 2.2547e-01, time/batch = 17.9538s	
11792/22950 (epoch 25.691), train_loss = 0.97740956, grad/param norm = 2.3318e-01, time/batch = 18.6745s	
11793/22950 (epoch 25.693), train_loss = 0.89523137, grad/param norm = 2.3805e-01, time/batch = 19.2910s	
11794/22950 (epoch 25.695), train_loss = 1.07316720, grad/param norm = 2.5602e-01, time/batch = 17.9442s	
11795/22950 (epoch 25.697), train_loss = 1.03218895, grad/param norm = 2.5268e-01, time/batch = 19.3620s	
11796/22950 (epoch 25.699), train_loss = 1.03379405, grad/param norm = 2.2210e-01, time/batch = 17.2003s	
11797/22950 (epoch 25.702), train_loss = 1.04482051, grad/param norm = 2.3979e-01, time/batch = 16.0815s	
11798/22950 (epoch 25.704), train_loss = 1.08916552, grad/param norm = 2.4710e-01, time/batch = 16.1734s	
11799/22950 (epoch 25.706), train_loss = 1.06903420, grad/param norm = 2.5647e-01, time/batch = 16.6200s	
11800/22950 (epoch 25.708), train_loss = 0.85782733, grad/param norm = 2.2071e-01, time/batch = 16.0764s	
11801/22950 (epoch 25.710), train_loss = 1.01038658, grad/param norm = 2.3580e-01, time/batch = 15.6875s	
11802/22950 (epoch 25.712), train_loss = 1.10975319, grad/param norm = 2.5666e-01, time/batch = 16.0071s	
11803/22950 (epoch 25.715), train_loss = 0.98818788, grad/param norm = 2.5361e-01, time/batch = 18.6844s	
11804/22950 (epoch 25.717), train_loss = 1.01802649, grad/param norm = 2.2012e-01, time/batch = 20.0466s	
11805/22950 (epoch 25.719), train_loss = 0.94218464, grad/param norm = 2.2016e-01, time/batch = 19.6894s	
11806/22950 (epoch 25.721), train_loss = 1.03209917, grad/param norm = 2.3490e-01, time/batch = 18.7919s	
11807/22950 (epoch 25.723), train_loss = 0.97407468, grad/param norm = 2.4288e-01, time/batch = 19.7824s	
11808/22950 (epoch 25.725), train_loss = 1.04309104, grad/param norm = 2.5818e-01, time/batch = 17.2890s	
11809/22950 (epoch 25.728), train_loss = 0.96866090, grad/param norm = 2.8497e-01, time/batch = 19.8860s	
11810/22950 (epoch 25.730), train_loss = 0.96046393, grad/param norm = 2.1485e-01, time/batch = 20.3547s	
11811/22950 (epoch 25.732), train_loss = 1.03915019, grad/param norm = 2.5434e-01, time/batch = 18.0357s	
11812/22950 (epoch 25.734), train_loss = 0.97917951, grad/param norm = 2.5314e-01, time/batch = 19.3786s	
11813/22950 (epoch 25.736), train_loss = 0.99573282, grad/param norm = 2.3716e-01, time/batch = 18.1991s	
11814/22950 (epoch 25.739), train_loss = 1.03961801, grad/param norm = 2.5458e-01, time/batch = 18.1256s	
11815/22950 (epoch 25.741), train_loss = 1.06148214, grad/param norm = 2.3566e-01, time/batch = 19.5208s	
11816/22950 (epoch 25.743), train_loss = 1.14425157, grad/param norm = 2.6788e-01, time/batch = 18.6678s	
11817/22950 (epoch 25.745), train_loss = 1.22140828, grad/param norm = 2.6289e-01, time/batch = 16.6879s	
11818/22950 (epoch 25.747), train_loss = 0.99789788, grad/param norm = 2.4566e-01, time/batch = 18.8448s	
11819/22950 (epoch 25.749), train_loss = 0.92744291, grad/param norm = 2.3015e-01, time/batch = 19.9379s	
11820/22950 (epoch 25.752), train_loss = 1.18310274, grad/param norm = 2.6448e-01, time/batch = 18.7725s	
11821/22950 (epoch 25.754), train_loss = 1.07027767, grad/param norm = 2.4944e-01, time/batch = 19.3707s	
11822/22950 (epoch 25.756), train_loss = 0.92277272, grad/param norm = 2.1939e-01, time/batch = 19.6203s	
11823/22950 (epoch 25.758), train_loss = 0.98824771, grad/param norm = 2.2608e-01, time/batch = 19.5368s	
11824/22950 (epoch 25.760), train_loss = 1.03375799, grad/param norm = 2.3748e-01, time/batch = 17.3680s	
11825/22950 (epoch 25.763), train_loss = 1.07497891, grad/param norm = 2.5569e-01, time/batch = 19.8867s	
11826/22950 (epoch 25.765), train_loss = 1.02835241, grad/param norm = 2.7616e-01, time/batch = 16.5089s	
11827/22950 (epoch 25.767), train_loss = 1.20627664, grad/param norm = 2.4986e-01, time/batch = 18.3644s	
11828/22950 (epoch 25.769), train_loss = 1.04409291, grad/param norm = 2.4227e-01, time/batch = 17.8779s	
11829/22950 (epoch 25.771), train_loss = 0.84420780, grad/param norm = 2.2589e-01, time/batch = 20.0438s	
11830/22950 (epoch 25.773), train_loss = 0.77005014, grad/param norm = 2.2335e-01, time/batch = 17.9492s	
11831/22950 (epoch 25.776), train_loss = 0.91296247, grad/param norm = 2.1053e-01, time/batch = 18.8636s	
11832/22950 (epoch 25.778), train_loss = 0.90678771, grad/param norm = 2.2363e-01, time/batch = 17.6351s	
11833/22950 (epoch 25.780), train_loss = 0.97913682, grad/param norm = 2.0833e-01, time/batch = 18.0999s	
11834/22950 (epoch 25.782), train_loss = 1.02160822, grad/param norm = 2.1490e-01, time/batch = 16.5490s	
11835/22950 (epoch 25.784), train_loss = 0.94404777, grad/param norm = 2.3716e-01, time/batch = 18.6101s	
11836/22950 (epoch 25.786), train_loss = 1.00547570, grad/param norm = 2.2648e-01, time/batch = 19.8674s	
11837/22950 (epoch 25.789), train_loss = 0.86332005, grad/param norm = 2.2851e-01, time/batch = 19.2030s	
11838/22950 (epoch 25.791), train_loss = 0.89805791, grad/param norm = 2.2565e-01, time/batch = 20.3766s	
11839/22950 (epoch 25.793), train_loss = 1.11828953, grad/param norm = 2.3256e-01, time/batch = 19.6978s	
11840/22950 (epoch 25.795), train_loss = 0.95853969, grad/param norm = 2.3187e-01, time/batch = 17.8692s	
11841/22950 (epoch 25.797), train_loss = 1.11834764, grad/param norm = 2.4279e-01, time/batch = 19.4501s	
11842/22950 (epoch 25.800), train_loss = 0.91399610, grad/param norm = 2.2550e-01, time/batch = 17.0350s	
11843/22950 (epoch 25.802), train_loss = 0.93062655, grad/param norm = 2.3080e-01, time/batch = 17.7698s	
11844/22950 (epoch 25.804), train_loss = 0.95123414, grad/param norm = 2.1299e-01, time/batch = 19.7055s	
11845/22950 (epoch 25.806), train_loss = 0.87379523, grad/param norm = 2.2091e-01, time/batch = 19.9472s	
11846/22950 (epoch 25.808), train_loss = 0.97070030, grad/param norm = 2.2118e-01, time/batch = 17.7711s	
11847/22950 (epoch 25.810), train_loss = 0.93716448, grad/param norm = 2.2316e-01, time/batch = 19.1017s	
11848/22950 (epoch 25.813), train_loss = 0.80553591, grad/param norm = 2.0434e-01, time/batch = 19.8716s	
11849/22950 (epoch 25.815), train_loss = 0.82441551, grad/param norm = 2.1822e-01, time/batch = 16.8627s	
11850/22950 (epoch 25.817), train_loss = 0.88753130, grad/param norm = 2.1215e-01, time/batch = 17.5222s	
11851/22950 (epoch 25.819), train_loss = 0.95503230, grad/param norm = 2.2151e-01, time/batch = 18.8721s	
11852/22950 (epoch 25.821), train_loss = 0.90797749, grad/param norm = 2.2494e-01, time/batch = 18.5213s	
11853/22950 (epoch 25.824), train_loss = 0.97781663, grad/param norm = 2.2483e-01, time/batch = 17.6076s	
11854/22950 (epoch 25.826), train_loss = 1.06801998, grad/param norm = 2.7912e-01, time/batch = 19.4551s	
11855/22950 (epoch 25.828), train_loss = 0.96584751, grad/param norm = 2.2792e-01, time/batch = 20.4496s	
11856/22950 (epoch 25.830), train_loss = 0.93378311, grad/param norm = 2.2269e-01, time/batch = 18.9543s	
11857/22950 (epoch 25.832), train_loss = 0.97722394, grad/param norm = 2.2795e-01, time/batch = 19.2946s	
11858/22950 (epoch 25.834), train_loss = 0.82395686, grad/param norm = 2.0969e-01, time/batch = 19.5398s	
11859/22950 (epoch 25.837), train_loss = 1.00683758, grad/param norm = 2.6992e-01, time/batch = 17.8683s	
11860/22950 (epoch 25.839), train_loss = 0.84614486, grad/param norm = 2.2632e-01, time/batch = 18.7944s	
11861/22950 (epoch 25.841), train_loss = 0.91039819, grad/param norm = 2.0529e-01, time/batch = 20.9523s	
11862/22950 (epoch 25.843), train_loss = 0.92929811, grad/param norm = 2.4417e-01, time/batch = 17.0480s	
11863/22950 (epoch 25.845), train_loss = 0.98358843, grad/param norm = 2.3899e-01, time/batch = 19.3789s	
11864/22950 (epoch 25.847), train_loss = 1.00895947, grad/param norm = 2.2000e-01, time/batch = 20.0318s	
11865/22950 (epoch 25.850), train_loss = 1.02015396, grad/param norm = 2.5711e-01, time/batch = 18.2798s	
11866/22950 (epoch 25.852), train_loss = 1.03291243, grad/param norm = 2.3006e-01, time/batch = 17.2696s	
11867/22950 (epoch 25.854), train_loss = 0.95956993, grad/param norm = 2.4118e-01, time/batch = 20.1185s	
11868/22950 (epoch 25.856), train_loss = 1.11219166, grad/param norm = 2.5240e-01, time/batch = 18.4438s	
11869/22950 (epoch 25.858), train_loss = 1.03152708, grad/param norm = 2.4456e-01, time/batch = 20.7771s	
11870/22950 (epoch 25.861), train_loss = 1.05112193, grad/param norm = 2.3815e-01, time/batch = 20.1884s	
11871/22950 (epoch 25.863), train_loss = 1.08589017, grad/param norm = 2.6387e-01, time/batch = 19.4608s	
11872/22950 (epoch 25.865), train_loss = 1.11371606, grad/param norm = 2.5983e-01, time/batch = 16.0177s	
11873/22950 (epoch 25.867), train_loss = 1.02565809, grad/param norm = 2.7711e-01, time/batch = 19.5405s	
11874/22950 (epoch 25.869), train_loss = 1.14602664, grad/param norm = 2.6898e-01, time/batch = 19.2827s	
11875/22950 (epoch 25.871), train_loss = 1.01850177, grad/param norm = 2.3317e-01, time/batch = 20.2819s	
11876/22950 (epoch 25.874), train_loss = 1.00071711, grad/param norm = 2.1746e-01, time/batch = 19.3573s	
11877/22950 (epoch 25.876), train_loss = 1.05089467, grad/param norm = 2.3531e-01, time/batch = 19.4480s	
11878/22950 (epoch 25.878), train_loss = 0.94330830, grad/param norm = 2.5714e-01, time/batch = 17.9294s	
11879/22950 (epoch 25.880), train_loss = 1.15932487, grad/param norm = 2.7098e-01, time/batch = 18.1994s	
11880/22950 (epoch 25.882), train_loss = 0.90461662, grad/param norm = 2.4144e-01, time/batch = 18.4611s	
11881/22950 (epoch 25.885), train_loss = 1.01888375, grad/param norm = 2.2378e-01, time/batch = 19.5235s	
11882/22950 (epoch 25.887), train_loss = 0.97452363, grad/param norm = 2.2139e-01, time/batch = 16.7100s	
11883/22950 (epoch 25.889), train_loss = 1.02514477, grad/param norm = 2.3737e-01, time/batch = 19.1169s	
11884/22950 (epoch 25.891), train_loss = 0.93772499, grad/param norm = 2.2713e-01, time/batch = 18.9410s	
11885/22950 (epoch 25.893), train_loss = 1.05475386, grad/param norm = 2.8980e-01, time/batch = 17.5278s	
11886/22950 (epoch 25.895), train_loss = 1.15143182, grad/param norm = 3.1193e-01, time/batch = 18.5222s	
11887/22950 (epoch 25.898), train_loss = 1.00428403, grad/param norm = 2.3689e-01, time/batch = 17.9522s	
11888/22950 (epoch 25.900), train_loss = 0.99283007, grad/param norm = 2.4357e-01, time/batch = 19.4621s	
11889/22950 (epoch 25.902), train_loss = 1.02588096, grad/param norm = 2.5965e-01, time/batch = 19.8042s	
11890/22950 (epoch 25.904), train_loss = 0.98951948, grad/param norm = 2.3436e-01, time/batch = 18.5277s	
11891/22950 (epoch 25.906), train_loss = 1.04699385, grad/param norm = 2.4788e-01, time/batch = 18.8625s	
11892/22950 (epoch 25.908), train_loss = 0.87567914, grad/param norm = 2.0068e-01, time/batch = 19.6180s	
11893/22950 (epoch 25.911), train_loss = 0.86370815, grad/param norm = 2.0136e-01, time/batch = 19.4501s	
11894/22950 (epoch 25.913), train_loss = 0.94771568, grad/param norm = 2.3504e-01, time/batch = 19.0259s	
11895/22950 (epoch 25.915), train_loss = 1.11660677, grad/param norm = 2.4277e-01, time/batch = 17.9458s	
11896/22950 (epoch 25.917), train_loss = 0.86697606, grad/param norm = 2.1342e-01, time/batch = 18.4516s	
11897/22950 (epoch 25.919), train_loss = 0.97269718, grad/param norm = 2.1173e-01, time/batch = 17.1867s	
11898/22950 (epoch 25.922), train_loss = 0.99235654, grad/param norm = 2.3848e-01, time/batch = 16.6996s	
11899/22950 (epoch 25.924), train_loss = 1.01771099, grad/param norm = 2.4203e-01, time/batch = 19.4742s	
11900/22950 (epoch 25.926), train_loss = 0.84548589, grad/param norm = 2.3342e-01, time/batch = 18.6089s	
11901/22950 (epoch 25.928), train_loss = 0.86130160, grad/param norm = 2.1237e-01, time/batch = 18.7196s	
11902/22950 (epoch 25.930), train_loss = 0.87630389, grad/param norm = 2.3994e-01, time/batch = 20.4540s	
11903/22950 (epoch 25.932), train_loss = 0.82836658, grad/param norm = 2.1185e-01, time/batch = 18.4433s	
11904/22950 (epoch 25.935), train_loss = 0.98150381, grad/param norm = 2.3305e-01, time/batch = 17.7816s	
11905/22950 (epoch 25.937), train_loss = 0.98385113, grad/param norm = 2.3981e-01, time/batch = 18.4363s	
11906/22950 (epoch 25.939), train_loss = 0.89455500, grad/param norm = 2.1575e-01, time/batch = 18.2863s	
11907/22950 (epoch 25.941), train_loss = 0.92751600, grad/param norm = 2.1285e-01, time/batch = 19.9553s	
11908/22950 (epoch 25.943), train_loss = 1.01061811, grad/param norm = 2.3629e-01, time/batch = 19.4651s	
11909/22950 (epoch 25.946), train_loss = 0.84077685, grad/param norm = 2.2189e-01, time/batch = 18.2860s	
11910/22950 (epoch 25.948), train_loss = 1.06239315, grad/param norm = 2.4279e-01, time/batch = 19.2595s	
11911/22950 (epoch 25.950), train_loss = 0.98493300, grad/param norm = 2.5650e-01, time/batch = 18.1226s	
11912/22950 (epoch 25.952), train_loss = 1.01997717, grad/param norm = 2.2192e-01, time/batch = 20.2215s	
11913/22950 (epoch 25.954), train_loss = 0.99177552, grad/param norm = 2.2536e-01, time/batch = 19.5297s	
11914/22950 (epoch 25.956), train_loss = 0.91649486, grad/param norm = 2.4122e-01, time/batch = 16.0247s	
11915/22950 (epoch 25.959), train_loss = 0.88219255, grad/param norm = 2.2197e-01, time/batch = 20.3708s	
11916/22950 (epoch 25.961), train_loss = 0.98098233, grad/param norm = 2.2494e-01, time/batch = 18.2085s	
11917/22950 (epoch 25.963), train_loss = 0.99997045, grad/param norm = 2.2997e-01, time/batch = 17.0952s	
11918/22950 (epoch 25.965), train_loss = 1.09495387, grad/param norm = 2.5342e-01, time/batch = 18.9476s	
11919/22950 (epoch 25.967), train_loss = 0.96724669, grad/param norm = 2.3418e-01, time/batch = 18.5298s	
11920/22950 (epoch 25.969), train_loss = 0.86554884, grad/param norm = 2.1880e-01, time/batch = 19.4445s	
11921/22950 (epoch 25.972), train_loss = 0.97360129, grad/param norm = 2.1082e-01, time/batch = 19.6262s	
11922/22950 (epoch 25.974), train_loss = 0.93934775, grad/param norm = 2.3162e-01, time/batch = 18.6154s	
11923/22950 (epoch 25.976), train_loss = 0.91891550, grad/param norm = 2.0044e-01, time/batch = 19.5371s	
11924/22950 (epoch 25.978), train_loss = 0.91349513, grad/param norm = 2.2033e-01, time/batch = 19.4607s	
11925/22950 (epoch 25.980), train_loss = 0.92037604, grad/param norm = 2.0462e-01, time/batch = 18.3470s	
11926/22950 (epoch 25.983), train_loss = 1.01026605, grad/param norm = 2.1389e-01, time/batch = 19.2479s	
11927/22950 (epoch 25.985), train_loss = 0.84001943, grad/param norm = 2.0979e-01, time/batch = 18.8801s	
11928/22950 (epoch 25.987), train_loss = 0.90948911, grad/param norm = 2.0279e-01, time/batch = 17.5485s	
11929/22950 (epoch 25.989), train_loss = 0.97783110, grad/param norm = 2.2936e-01, time/batch = 19.5118s	
11930/22950 (epoch 25.991), train_loss = 0.82151163, grad/param norm = 2.4977e-01, time/batch = 16.3533s	
11931/22950 (epoch 25.993), train_loss = 1.01317332, grad/param norm = 2.3389e-01, time/batch = 19.4288s	
11932/22950 (epoch 25.996), train_loss = 0.98230023, grad/param norm = 3.4073e-01, time/batch = 17.3602s	
11933/22950 (epoch 25.998), train_loss = 0.88566750, grad/param norm = 2.2794e-01, time/batch = 20.1991s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
11934/22950 (epoch 26.000), train_loss = 0.80060527, grad/param norm = 1.9882e-01, time/batch = 18.3675s	
11935/22950 (epoch 26.002), train_loss = 1.12923249, grad/param norm = 2.4503e-01, time/batch = 18.4554s	
11936/22950 (epoch 26.004), train_loss = 1.00247239, grad/param norm = 2.1749e-01, time/batch = 16.6361s	
11937/22950 (epoch 26.007), train_loss = 0.95122069, grad/param norm = 2.0818e-01, time/batch = 19.8765s	
11938/22950 (epoch 26.009), train_loss = 1.10542630, grad/param norm = 2.6897e-01, time/batch = 18.9559s	
11939/22950 (epoch 26.011), train_loss = 0.84724868, grad/param norm = 2.5056e-01, time/batch = 19.4549s	
11940/22950 (epoch 26.013), train_loss = 0.99116192, grad/param norm = 2.9793e-01, time/batch = 19.3803s	
11941/22950 (epoch 26.015), train_loss = 1.00229556, grad/param norm = 2.4788e-01, time/batch = 18.2943s	
11942/22950 (epoch 26.017), train_loss = 0.99025544, grad/param norm = 2.2387e-01, time/batch = 18.6982s	
11943/22950 (epoch 26.020), train_loss = 0.99521409, grad/param norm = 2.1727e-01, time/batch = 19.7896s	
11944/22950 (epoch 26.022), train_loss = 0.83195667, grad/param norm = 1.9297e-01, time/batch = 18.7827s	
11945/22950 (epoch 26.024), train_loss = 0.93801622, grad/param norm = 2.2459e-01, time/batch = 17.3534s	
11946/22950 (epoch 26.026), train_loss = 1.02018913, grad/param norm = 2.2978e-01, time/batch = 18.7890s	
11947/22950 (epoch 26.028), train_loss = 1.06969487, grad/param norm = 2.0205e-01, time/batch = 19.9565s	
11948/22950 (epoch 26.031), train_loss = 0.94793676, grad/param norm = 2.3879e-01, time/batch = 18.0229s	
11949/22950 (epoch 26.033), train_loss = 1.08046350, grad/param norm = 2.6086e-01, time/batch = 17.5332s	
11950/22950 (epoch 26.035), train_loss = 0.99165807, grad/param norm = 2.3897e-01, time/batch = 19.2753s	
11951/22950 (epoch 26.037), train_loss = 0.97602103, grad/param norm = 2.2953e-01, time/batch = 17.7845s	
11952/22950 (epoch 26.039), train_loss = 0.94013432, grad/param norm = 2.2229e-01, time/batch = 17.1783s	
11953/22950 (epoch 26.041), train_loss = 0.90500686, grad/param norm = 2.1741e-01, time/batch = 17.1108s	
11954/22950 (epoch 26.044), train_loss = 1.01742136, grad/param norm = 2.2481e-01, time/batch = 17.2054s	
11955/22950 (epoch 26.046), train_loss = 0.96918542, grad/param norm = 2.2110e-01, time/batch = 16.5363s	
11956/22950 (epoch 26.048), train_loss = 0.97792383, grad/param norm = 2.1459e-01, time/batch = 17.3645s	
11957/22950 (epoch 26.050), train_loss = 0.93552913, grad/param norm = 2.5742e-01, time/batch = 16.9481s	
11958/22950 (epoch 26.052), train_loss = 1.00356890, grad/param norm = 2.3654e-01, time/batch = 17.9370s	
11959/22950 (epoch 26.054), train_loss = 1.13580435, grad/param norm = 2.3898e-01, time/batch = 17.6750s	
11960/22950 (epoch 26.057), train_loss = 1.05831305, grad/param norm = 2.4368e-01, time/batch = 19.2819s	
11961/22950 (epoch 26.059), train_loss = 1.03273365, grad/param norm = 2.0812e-01, time/batch = 18.1233s	
11962/22950 (epoch 26.061), train_loss = 0.91793344, grad/param norm = 2.2687e-01, time/batch = 18.0430s	
11963/22950 (epoch 26.063), train_loss = 1.00919324, grad/param norm = 2.5219e-01, time/batch = 19.4491s	
11964/22950 (epoch 26.065), train_loss = 0.87621640, grad/param norm = 2.1195e-01, time/batch = 18.4750s	
11965/22950 (epoch 26.068), train_loss = 1.02511297, grad/param norm = 2.7491e-01, time/batch = 20.0319s	
11966/22950 (epoch 26.070), train_loss = 0.87503641, grad/param norm = 2.1864e-01, time/batch = 15.9451s	
11967/22950 (epoch 26.072), train_loss = 1.05076902, grad/param norm = 2.5058e-01, time/batch = 18.7764s	
11968/22950 (epoch 26.074), train_loss = 1.00549592, grad/param norm = 2.4188e-01, time/batch = 19.3665s	
11969/22950 (epoch 26.076), train_loss = 1.00106352, grad/param norm = 2.1996e-01, time/batch = 19.0306s	
11970/22950 (epoch 26.078), train_loss = 1.05784679, grad/param norm = 2.2740e-01, time/batch = 20.1367s	
11971/22950 (epoch 26.081), train_loss = 1.08390195, grad/param norm = 2.5115e-01, time/batch = 17.3643s	
11972/22950 (epoch 26.083), train_loss = 0.96463372, grad/param norm = 2.2652e-01, time/batch = 17.7820s	
11973/22950 (epoch 26.085), train_loss = 0.88289502, grad/param norm = 2.6790e-01, time/batch = 20.0224s	
11974/22950 (epoch 26.087), train_loss = 0.90167619, grad/param norm = 2.4592e-01, time/batch = 27.8392s	
11975/22950 (epoch 26.089), train_loss = 1.00153834, grad/param norm = 2.3400e-01, time/batch = 24.2228s	
11976/22950 (epoch 26.092), train_loss = 0.92821429, grad/param norm = 2.6121e-01, time/batch = 17.6712s	
11977/22950 (epoch 26.094), train_loss = 0.89089960, grad/param norm = 2.1542e-01, time/batch = 18.1211s	
11978/22950 (epoch 26.096), train_loss = 1.07820406, grad/param norm = 2.2992e-01, time/batch = 18.3429s	
11979/22950 (epoch 26.098), train_loss = 1.02453521, grad/param norm = 2.3851e-01, time/batch = 16.3593s	
11980/22950 (epoch 26.100), train_loss = 0.92495228, grad/param norm = 2.3401e-01, time/batch = 17.3601s	
11981/22950 (epoch 26.102), train_loss = 0.98016960, grad/param norm = 2.2076e-01, time/batch = 19.3815s	
11982/22950 (epoch 26.105), train_loss = 0.82234688, grad/param norm = 1.8911e-01, time/batch = 18.7089s	
11983/22950 (epoch 26.107), train_loss = 0.94202476, grad/param norm = 2.4203e-01, time/batch = 17.4613s	
11984/22950 (epoch 26.109), train_loss = 0.92486341, grad/param norm = 2.3884e-01, time/batch = 18.8892s	
11985/22950 (epoch 26.111), train_loss = 0.82869371, grad/param norm = 2.0981e-01, time/batch = 18.2902s	
11986/22950 (epoch 26.113), train_loss = 0.97658501, grad/param norm = 2.1927e-01, time/batch = 18.6166s	
11987/22950 (epoch 26.115), train_loss = 0.97487978, grad/param norm = 2.2056e-01, time/batch = 20.1948s	
11988/22950 (epoch 26.118), train_loss = 1.09641304, grad/param norm = 2.1799e-01, time/batch = 18.5468s	
11989/22950 (epoch 26.120), train_loss = 0.87870525, grad/param norm = 2.1843e-01, time/batch = 19.8576s	
11990/22950 (epoch 26.122), train_loss = 1.05330147, grad/param norm = 2.3789e-01, time/batch = 17.7669s	
11991/22950 (epoch 26.124), train_loss = 0.84062328, grad/param norm = 1.9607e-01, time/batch = 19.3766s	
11992/22950 (epoch 26.126), train_loss = 0.96900277, grad/param norm = 2.2380e-01, time/batch = 19.7053s	
11993/22950 (epoch 26.129), train_loss = 0.87903015, grad/param norm = 2.0353e-01, time/batch = 18.3479s	
11994/22950 (epoch 26.131), train_loss = 0.95239764, grad/param norm = 2.0699e-01, time/batch = 18.6240s	
11995/22950 (epoch 26.133), train_loss = 1.03116135, grad/param norm = 2.2394e-01, time/batch = 20.2040s	
11996/22950 (epoch 26.135), train_loss = 0.98062727, grad/param norm = 2.1021e-01, time/batch = 16.0084s	
11997/22950 (epoch 26.137), train_loss = 1.07221211, grad/param norm = 3.0818e-01, time/batch = 18.9596s	
11998/22950 (epoch 26.139), train_loss = 0.86775756, grad/param norm = 2.2409e-01, time/batch = 19.2839s	
11999/22950 (epoch 26.142), train_loss = 0.87206700, grad/param norm = 2.1898e-01, time/batch = 18.8669s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch26.14_1.8632.t7	
12000/22950 (epoch 26.144), train_loss = 0.94586326, grad/param norm = 2.2918e-01, time/batch = 20.4423s	
12001/22950 (epoch 26.146), train_loss = 1.37611364, grad/param norm = 2.9977e-01, time/batch = 0.6958s	
12002/22950 (epoch 26.148), train_loss = 0.91866296, grad/param norm = 2.4010e-01, time/batch = 0.6879s	
12003/22950 (epoch 26.150), train_loss = 0.99315224, grad/param norm = 2.5546e-01, time/batch = 0.6972s	
12004/22950 (epoch 26.153), train_loss = 0.92556913, grad/param norm = 2.1019e-01, time/batch = 0.6873s	
12005/22950 (epoch 26.155), train_loss = 0.91131113, grad/param norm = 2.0502e-01, time/batch = 0.6910s	
12006/22950 (epoch 26.157), train_loss = 0.95446044, grad/param norm = 2.0551e-01, time/batch = 0.6870s	
12007/22950 (epoch 26.159), train_loss = 0.88964902, grad/param norm = 2.0217e-01, time/batch = 0.7845s	
12008/22950 (epoch 26.161), train_loss = 0.93117731, grad/param norm = 2.1730e-01, time/batch = 1.0190s	
12009/22950 (epoch 26.163), train_loss = 0.84499828, grad/param norm = 2.0836e-01, time/batch = 1.0131s	
12010/22950 (epoch 26.166), train_loss = 1.04569072, grad/param norm = 3.0454e-01, time/batch = 1.0110s	
12011/22950 (epoch 26.168), train_loss = 1.01086693, grad/param norm = 2.4818e-01, time/batch = 1.0070s	
12012/22950 (epoch 26.170), train_loss = 0.92762292, grad/param norm = 2.2251e-01, time/batch = 1.3320s	
12013/22950 (epoch 26.172), train_loss = 0.98271049, grad/param norm = 2.0246e-01, time/batch = 1.9002s	
12014/22950 (epoch 26.174), train_loss = 1.05674340, grad/param norm = 2.6730e-01, time/batch = 1.8609s	
12015/22950 (epoch 26.176), train_loss = 1.05670058, grad/param norm = 2.3501e-01, time/batch = 14.6589s	
12016/22950 (epoch 26.179), train_loss = 1.02028465, grad/param norm = 2.4057e-01, time/batch = 19.0410s	
12017/22950 (epoch 26.181), train_loss = 1.21534679, grad/param norm = 2.6664e-01, time/batch = 18.3587s	
12018/22950 (epoch 26.183), train_loss = 1.03259792, grad/param norm = 2.3067e-01, time/batch = 17.8802s	
12019/22950 (epoch 26.185), train_loss = 1.00240914, grad/param norm = 2.3739e-01, time/batch = 18.7963s	
12020/22950 (epoch 26.187), train_loss = 0.90828156, grad/param norm = 2.5515e-01, time/batch = 17.5996s	
12021/22950 (epoch 26.190), train_loss = 0.80731273, grad/param norm = 2.1035e-01, time/batch = 18.2967s	
12022/22950 (epoch 26.192), train_loss = 0.78791927, grad/param norm = 1.8645e-01, time/batch = 19.2838s	
12023/22950 (epoch 26.194), train_loss = 0.92646765, grad/param norm = 2.4377e-01, time/batch = 18.1273s	
12024/22950 (epoch 26.196), train_loss = 0.75962806, grad/param norm = 2.2349e-01, time/batch = 19.4457s	
12025/22950 (epoch 26.198), train_loss = 1.03270596, grad/param norm = 2.4239e-01, time/batch = 16.4721s	
12026/22950 (epoch 26.200), train_loss = 0.88462155, grad/param norm = 2.0445e-01, time/batch = 17.6963s	
12027/22950 (epoch 26.203), train_loss = 0.86634747, grad/param norm = 2.2680e-01, time/batch = 17.9479s	
12028/22950 (epoch 26.205), train_loss = 0.92587678, grad/param norm = 2.1916e-01, time/batch = 17.0931s	
12029/22950 (epoch 26.207), train_loss = 0.99160485, grad/param norm = 2.3944e-01, time/batch = 18.7096s	
12030/22950 (epoch 26.209), train_loss = 0.93998944, grad/param norm = 2.3075e-01, time/batch = 16.5364s	
12031/22950 (epoch 26.211), train_loss = 0.79033194, grad/param norm = 2.0516e-01, time/batch = 18.4603s	
12032/22950 (epoch 26.214), train_loss = 0.90804073, grad/param norm = 2.1084e-01, time/batch = 18.1345s	
12033/22950 (epoch 26.216), train_loss = 1.03098632, grad/param norm = 2.1718e-01, time/batch = 17.6198s	
12034/22950 (epoch 26.218), train_loss = 0.94768935, grad/param norm = 2.1521e-01, time/batch = 19.7814s	
12035/22950 (epoch 26.220), train_loss = 1.04229126, grad/param norm = 2.5198e-01, time/batch = 18.8423s	
12036/22950 (epoch 26.222), train_loss = 1.06305618, grad/param norm = 2.4197e-01, time/batch = 18.6892s	
12037/22950 (epoch 26.224), train_loss = 0.95758418, grad/param norm = 2.3331e-01, time/batch = 20.0981s	
12038/22950 (epoch 26.227), train_loss = 1.03528770, grad/param norm = 2.3864e-01, time/batch = 19.6861s	
12039/22950 (epoch 26.229), train_loss = 1.05556603, grad/param norm = 2.3206e-01, time/batch = 18.9266s	
12040/22950 (epoch 26.231), train_loss = 0.82005976, grad/param norm = 2.0305e-01, time/batch = 19.7915s	
12041/22950 (epoch 26.233), train_loss = 0.91541617, grad/param norm = 2.1115e-01, time/batch = 18.7864s	
12042/22950 (epoch 26.235), train_loss = 1.10500267, grad/param norm = 2.2914e-01, time/batch = 18.7931s	
12043/22950 (epoch 26.237), train_loss = 0.90134575, grad/param norm = 2.3250e-01, time/batch = 16.2517s	
12044/22950 (epoch 26.240), train_loss = 0.95757223, grad/param norm = 2.2621e-01, time/batch = 19.2037s	
12045/22950 (epoch 26.242), train_loss = 1.08639761, grad/param norm = 2.1430e-01, time/batch = 18.2958s	
12046/22950 (epoch 26.244), train_loss = 1.06112668, grad/param norm = 2.3799e-01, time/batch = 16.8593s	
12047/22950 (epoch 26.246), train_loss = 1.07218779, grad/param norm = 2.3438e-01, time/batch = 18.4606s	
12048/22950 (epoch 26.248), train_loss = 0.98514051, grad/param norm = 2.1354e-01, time/batch = 19.2787s	
12049/22950 (epoch 26.251), train_loss = 0.89805665, grad/param norm = 2.1767e-01, time/batch = 17.2766s	
12050/22950 (epoch 26.253), train_loss = 0.93201385, grad/param norm = 2.3656e-01, time/batch = 19.1183s	
12051/22950 (epoch 26.255), train_loss = 0.99227335, grad/param norm = 2.3596e-01, time/batch = 18.6913s	
12052/22950 (epoch 26.257), train_loss = 1.03871673, grad/param norm = 2.2030e-01, time/batch = 15.9747s	
12053/22950 (epoch 26.259), train_loss = 0.83518510, grad/param norm = 2.0986e-01, time/batch = 17.6982s	
12054/22950 (epoch 26.261), train_loss = 0.90735650, grad/param norm = 2.0920e-01, time/batch = 19.8718s	
12055/22950 (epoch 26.264), train_loss = 0.88299143, grad/param norm = 2.2303e-01, time/batch = 20.4612s	
12056/22950 (epoch 26.266), train_loss = 0.94203041, grad/param norm = 2.2860e-01, time/batch = 18.8449s	
12057/22950 (epoch 26.268), train_loss = 0.96248235, grad/param norm = 2.5297e-01, time/batch = 19.9566s	
12058/22950 (epoch 26.270), train_loss = 0.95537754, grad/param norm = 2.2647e-01, time/batch = 18.9642s	
12059/22950 (epoch 26.272), train_loss = 1.00972983, grad/param norm = 2.6594e-01, time/batch = 16.9431s	
12060/22950 (epoch 26.275), train_loss = 0.90192199, grad/param norm = 2.3366e-01, time/batch = 19.3917s	
12061/22950 (epoch 26.277), train_loss = 0.79378362, grad/param norm = 1.8395e-01, time/batch = 19.8073s	
12062/22950 (epoch 26.279), train_loss = 0.86106509, grad/param norm = 2.2471e-01, time/batch = 17.0174s	
12063/22950 (epoch 26.281), train_loss = 0.91265840, grad/param norm = 2.3062e-01, time/batch = 16.3775s	
12064/22950 (epoch 26.283), train_loss = 0.81261304, grad/param norm = 1.8203e-01, time/batch = 18.1114s	
12065/22950 (epoch 26.285), train_loss = 0.97563522, grad/param norm = 2.1573e-01, time/batch = 19.1142s	
12066/22950 (epoch 26.288), train_loss = 1.05915219, grad/param norm = 2.4177e-01, time/batch = 18.2851s	
12067/22950 (epoch 26.290), train_loss = 0.90382121, grad/param norm = 2.1596e-01, time/batch = 19.4520s	
12068/22950 (epoch 26.292), train_loss = 1.05772245, grad/param norm = 2.2906e-01, time/batch = 19.4611s	
12069/22950 (epoch 26.294), train_loss = 0.94997677, grad/param norm = 2.0694e-01, time/batch = 19.3699s	
12070/22950 (epoch 26.296), train_loss = 0.74715758, grad/param norm = 1.7336e-01, time/batch = 18.7889s	
12071/22950 (epoch 26.298), train_loss = 0.94953677, grad/param norm = 2.1398e-01, time/batch = 20.1948s	
12072/22950 (epoch 26.301), train_loss = 0.98658404, grad/param norm = 2.3940e-01, time/batch = 20.0261s	
12073/22950 (epoch 26.303), train_loss = 0.96406409, grad/param norm = 2.1738e-01, time/batch = 17.7781s	
12074/22950 (epoch 26.305), train_loss = 0.94462960, grad/param norm = 2.4851e-01, time/batch = 20.0392s	
12075/22950 (epoch 26.307), train_loss = 1.07555011, grad/param norm = 2.6001e-01, time/batch = 18.6017s	
12076/22950 (epoch 26.309), train_loss = 0.89690271, grad/param norm = 2.1188e-01, time/batch = 19.6345s	
12077/22950 (epoch 26.312), train_loss = 0.97697949, grad/param norm = 2.2835e-01, time/batch = 19.0475s	
12078/22950 (epoch 26.314), train_loss = 0.96968131, grad/param norm = 2.0931e-01, time/batch = 16.6228s	
12079/22950 (epoch 26.316), train_loss = 0.95338594, grad/param norm = 2.3722e-01, time/batch = 18.8487s	
12080/22950 (epoch 26.318), train_loss = 0.81690017, grad/param norm = 1.8574e-01, time/batch = 16.3715s	
12081/22950 (epoch 26.320), train_loss = 0.89502827, grad/param norm = 2.0458e-01, time/batch = 18.6298s	
12082/22950 (epoch 26.322), train_loss = 0.90142057, grad/param norm = 2.1474e-01, time/batch = 16.8289s	
12083/22950 (epoch 26.325), train_loss = 0.75610216, grad/param norm = 1.9453e-01, time/batch = 17.9141s	
12084/22950 (epoch 26.327), train_loss = 0.78235609, grad/param norm = 2.0480e-01, time/batch = 18.8646s	
12085/22950 (epoch 26.329), train_loss = 0.89146408, grad/param norm = 2.1363e-01, time/batch = 18.4565s	
12086/22950 (epoch 26.331), train_loss = 0.81578884, grad/param norm = 1.9859e-01, time/batch = 20.2977s	
12087/22950 (epoch 26.333), train_loss = 0.90059362, grad/param norm = 2.0627e-01, time/batch = 17.9736s	
12088/22950 (epoch 26.336), train_loss = 0.92754107, grad/param norm = 2.3873e-01, time/batch = 18.9539s	
12089/22950 (epoch 26.338), train_loss = 0.93659712, grad/param norm = 2.1182e-01, time/batch = 19.8761s	
12090/22950 (epoch 26.340), train_loss = 0.94323083, grad/param norm = 2.5164e-01, time/batch = 17.6969s	
12091/22950 (epoch 26.342), train_loss = 1.06717065, grad/param norm = 2.1172e-01, time/batch = 18.1966s	
12092/22950 (epoch 26.344), train_loss = 0.91207094, grad/param norm = 2.1552e-01, time/batch = 18.5208s	
12093/22950 (epoch 26.346), train_loss = 1.04388803, grad/param norm = 3.0973e-01, time/batch = 20.5404s	
12094/22950 (epoch 26.349), train_loss = 0.94322775, grad/param norm = 2.1716e-01, time/batch = 17.0224s	
12095/22950 (epoch 26.351), train_loss = 0.96634267, grad/param norm = 2.3315e-01, time/batch = 19.7987s	
12096/22950 (epoch 26.353), train_loss = 1.03680214, grad/param norm = 3.1410e-01, time/batch = 19.0281s	
12097/22950 (epoch 26.355), train_loss = 1.07194554, grad/param norm = 2.4134e-01, time/batch = 17.9579s	
12098/22950 (epoch 26.357), train_loss = 0.96167578, grad/param norm = 2.4709e-01, time/batch = 18.6059s	
12099/22950 (epoch 26.359), train_loss = 0.93837996, grad/param norm = 2.3869e-01, time/batch = 19.3682s	
12100/22950 (epoch 26.362), train_loss = 1.00968020, grad/param norm = 3.0364e-01, time/batch = 16.0309s	
12101/22950 (epoch 26.364), train_loss = 0.95412280, grad/param norm = 2.6406e-01, time/batch = 20.1028s	
12102/22950 (epoch 26.366), train_loss = 0.94653861, grad/param norm = 2.1486e-01, time/batch = 19.0464s	
12103/22950 (epoch 26.368), train_loss = 1.03498908, grad/param norm = 2.4979e-01, time/batch = 20.1003s	
12104/22950 (epoch 26.370), train_loss = 0.93222002, grad/param norm = 2.3388e-01, time/batch = 17.5912s	
12105/22950 (epoch 26.373), train_loss = 0.84463706, grad/param norm = 1.9824e-01, time/batch = 19.7037s	
12106/22950 (epoch 26.375), train_loss = 1.05217272, grad/param norm = 2.2956e-01, time/batch = 20.2002s	
12107/22950 (epoch 26.377), train_loss = 0.84504002, grad/param norm = 2.1607e-01, time/batch = 18.5273s	
12108/22950 (epoch 26.379), train_loss = 0.97984882, grad/param norm = 2.6132e-01, time/batch = 18.8599s	
12109/22950 (epoch 26.381), train_loss = 0.84013752, grad/param norm = 2.3277e-01, time/batch = 16.5492s	
12110/22950 (epoch 26.383), train_loss = 0.94930719, grad/param norm = 2.2427e-01, time/batch = 17.4237s	
12111/22950 (epoch 26.386), train_loss = 0.89237814, grad/param norm = 2.5233e-01, time/batch = 17.0206s	
12112/22950 (epoch 26.388), train_loss = 1.00067351, grad/param norm = 2.4873e-01, time/batch = 18.2654s	
12113/22950 (epoch 26.390), train_loss = 0.84092820, grad/param norm = 2.2046e-01, time/batch = 18.1218s	
12114/22950 (epoch 26.392), train_loss = 0.87505340, grad/param norm = 2.0528e-01, time/batch = 19.2909s	
12115/22950 (epoch 26.394), train_loss = 0.89537356, grad/param norm = 2.1404e-01, time/batch = 17.6831s	
12116/22950 (epoch 26.397), train_loss = 1.07181312, grad/param norm = 2.2974e-01, time/batch = 19.8770s	
12117/22950 (epoch 26.399), train_loss = 1.08968649, grad/param norm = 2.5818e-01, time/batch = 20.3373s	
12118/22950 (epoch 26.401), train_loss = 1.11447650, grad/param norm = 2.5093e-01, time/batch = 18.8833s	
12119/22950 (epoch 26.403), train_loss = 0.91635628, grad/param norm = 2.4233e-01, time/batch = 18.3741s	
12120/22950 (epoch 26.405), train_loss = 1.05062755, grad/param norm = 2.3744e-01, time/batch = 17.1826s	
12121/22950 (epoch 26.407), train_loss = 1.10803196, grad/param norm = 2.1760e-01, time/batch = 18.7986s	
12122/22950 (epoch 26.410), train_loss = 0.93007314, grad/param norm = 2.2005e-01, time/batch = 16.4288s	
12123/22950 (epoch 26.412), train_loss = 0.94304027, grad/param norm = 2.5345e-01, time/batch = 18.4635s	
12124/22950 (epoch 26.414), train_loss = 1.06320936, grad/param norm = 2.3375e-01, time/batch = 19.7092s	
12125/22950 (epoch 26.416), train_loss = 0.99996042, grad/param norm = 2.6940e-01, time/batch = 18.1877s	
12126/22950 (epoch 26.418), train_loss = 0.98199645, grad/param norm = 3.0314e-01, time/batch = 15.7354s	
12127/22950 (epoch 26.420), train_loss = 1.06679847, grad/param norm = 3.1906e-01, time/batch = 15.9819s	
12128/22950 (epoch 26.423), train_loss = 0.90044660, grad/param norm = 2.3610e-01, time/batch = 16.6670s	
12129/22950 (epoch 26.425), train_loss = 0.92250740, grad/param norm = 2.1912e-01, time/batch = 19.0518s	
12130/22950 (epoch 26.427), train_loss = 0.95000745, grad/param norm = 2.2100e-01, time/batch = 17.4640s	
12131/22950 (epoch 26.429), train_loss = 0.94204196, grad/param norm = 2.1911e-01, time/batch = 16.2737s	
12132/22950 (epoch 26.431), train_loss = 1.02584952, grad/param norm = 2.3365e-01, time/batch = 19.6103s	
12133/22950 (epoch 26.434), train_loss = 0.96086124, grad/param norm = 2.1889e-01, time/batch = 16.3485s	
12134/22950 (epoch 26.436), train_loss = 1.04048354, grad/param norm = 2.4342e-01, time/batch = 19.6190s	
12135/22950 (epoch 26.438), train_loss = 0.98758575, grad/param norm = 2.3905e-01, time/batch = 18.9574s	
12136/22950 (epoch 26.440), train_loss = 1.05736073, grad/param norm = 2.3110e-01, time/batch = 19.0378s	
12137/22950 (epoch 26.442), train_loss = 1.11526732, grad/param norm = 2.5100e-01, time/batch = 18.9657s	
12138/22950 (epoch 26.444), train_loss = 1.02057218, grad/param norm = 2.5388e-01, time/batch = 18.1191s	
12139/22950 (epoch 26.447), train_loss = 1.13330344, grad/param norm = 2.5618e-01, time/batch = 19.4527s	
12140/22950 (epoch 26.449), train_loss = 0.86440237, grad/param norm = 2.0796e-01, time/batch = 16.5423s	
12141/22950 (epoch 26.451), train_loss = 0.98665171, grad/param norm = 2.2989e-01, time/batch = 20.0450s	
12142/22950 (epoch 26.453), train_loss = 1.01634134, grad/param norm = 2.2883e-01, time/batch = 18.2147s	
12143/22950 (epoch 26.455), train_loss = 0.92044051, grad/param norm = 1.9197e-01, time/batch = 16.4731s	
12144/22950 (epoch 26.458), train_loss = 1.00889714, grad/param norm = 2.3813e-01, time/batch = 17.0150s	
12145/22950 (epoch 26.460), train_loss = 1.02087265, grad/param norm = 2.1421e-01, time/batch = 16.2744s	
12146/22950 (epoch 26.462), train_loss = 0.99014577, grad/param norm = 2.5520e-01, time/batch = 16.3971s	
12147/22950 (epoch 26.464), train_loss = 0.92579047, grad/param norm = 2.1229e-01, time/batch = 15.8711s	
12148/22950 (epoch 26.466), train_loss = 1.03869697, grad/param norm = 2.2990e-01, time/batch = 16.1733s	
12149/22950 (epoch 26.468), train_loss = 1.07164870, grad/param norm = 2.5062e-01, time/batch = 15.8016s	
12150/22950 (epoch 26.471), train_loss = 1.01664971, grad/param norm = 2.4260e-01, time/batch = 15.7916s	
12151/22950 (epoch 26.473), train_loss = 1.01577451, grad/param norm = 2.2657e-01, time/batch = 15.8108s	
12152/22950 (epoch 26.475), train_loss = 1.17843653, grad/param norm = 2.5017e-01, time/batch = 15.6364s	
12153/22950 (epoch 26.477), train_loss = 0.95704661, grad/param norm = 2.3004e-01, time/batch = 16.1665s	
12154/22950 (epoch 26.479), train_loss = 0.87207888, grad/param norm = 2.1667e-01, time/batch = 15.6254s	
12155/22950 (epoch 26.481), train_loss = 1.04802788, grad/param norm = 2.4914e-01, time/batch = 15.8050s	
12156/22950 (epoch 26.484), train_loss = 1.01251826, grad/param norm = 2.8719e-01, time/batch = 16.0334s	
12157/22950 (epoch 26.486), train_loss = 0.82398320, grad/param norm = 2.1744e-01, time/batch = 15.6338s	
12158/22950 (epoch 26.488), train_loss = 0.92979169, grad/param norm = 2.5597e-01, time/batch = 15.8650s	
12159/22950 (epoch 26.490), train_loss = 0.84393904, grad/param norm = 2.1529e-01, time/batch = 15.6202s	
12160/22950 (epoch 26.492), train_loss = 0.93295587, grad/param norm = 2.4700e-01, time/batch = 15.5171s	
12161/22950 (epoch 26.495), train_loss = 0.91080272, grad/param norm = 2.4071e-01, time/batch = 15.6953s	
12162/22950 (epoch 26.497), train_loss = 1.02370167, grad/param norm = 2.3788e-01, time/batch = 16.3345s	
12163/22950 (epoch 26.499), train_loss = 1.10063532, grad/param norm = 2.7363e-01, time/batch = 15.9339s	
12164/22950 (epoch 26.501), train_loss = 1.02508922, grad/param norm = 2.4637e-01, time/batch = 15.7015s	
12165/22950 (epoch 26.503), train_loss = 1.07523226, grad/param norm = 2.4183e-01, time/batch = 16.3973s	
12166/22950 (epoch 26.505), train_loss = 0.84993780, grad/param norm = 1.9773e-01, time/batch = 17.1099s	
12167/22950 (epoch 26.508), train_loss = 1.01887761, grad/param norm = 2.2218e-01, time/batch = 16.9070s	
12168/22950 (epoch 26.510), train_loss = 0.96242077, grad/param norm = 2.1778e-01, time/batch = 16.6090s	
12169/22950 (epoch 26.512), train_loss = 0.85138081, grad/param norm = 2.2288e-01, time/batch = 16.5994s	
12170/22950 (epoch 26.514), train_loss = 0.91628789, grad/param norm = 1.8507e-01, time/batch = 16.1302s	
12171/22950 (epoch 26.516), train_loss = 0.94156154, grad/param norm = 2.2671e-01, time/batch = 16.4261s	
12172/22950 (epoch 26.519), train_loss = 0.94814937, grad/param norm = 2.1206e-01, time/batch = 16.0954s	
12173/22950 (epoch 26.521), train_loss = 0.96988918, grad/param norm = 2.4450e-01, time/batch = 16.7913s	
12174/22950 (epoch 26.523), train_loss = 0.77747770, grad/param norm = 2.1003e-01, time/batch = 16.7993s	
12175/22950 (epoch 26.525), train_loss = 0.87669103, grad/param norm = 1.9163e-01, time/batch = 16.5297s	
12176/22950 (epoch 26.527), train_loss = 0.82753909, grad/param norm = 2.1546e-01, time/batch = 16.3538s	
12177/22950 (epoch 26.529), train_loss = 0.97219943, grad/param norm = 2.1482e-01, time/batch = 16.0523s	
12178/22950 (epoch 26.532), train_loss = 0.92032172, grad/param norm = 2.0706e-01, time/batch = 16.4386s	
12179/22950 (epoch 26.534), train_loss = 1.01173571, grad/param norm = 2.2816e-01, time/batch = 16.5942s	
12180/22950 (epoch 26.536), train_loss = 1.01183957, grad/param norm = 2.5042e-01, time/batch = 29.5590s	
12181/22950 (epoch 26.538), train_loss = 0.98836814, grad/param norm = 2.5470e-01, time/batch = 16.2577s	
12182/22950 (epoch 26.540), train_loss = 1.01570555, grad/param norm = 2.3069e-01, time/batch = 16.4065s	
12183/22950 (epoch 26.542), train_loss = 1.11310996, grad/param norm = 2.4273e-01, time/batch = 16.9496s	
12184/22950 (epoch 26.545), train_loss = 0.92455206, grad/param norm = 1.9621e-01, time/batch = 16.6089s	
12185/22950 (epoch 26.547), train_loss = 0.94240196, grad/param norm = 2.1374e-01, time/batch = 16.1813s	
12186/22950 (epoch 26.549), train_loss = 0.87874584, grad/param norm = 2.0687e-01, time/batch = 15.8727s	
12187/22950 (epoch 26.551), train_loss = 0.93445781, grad/param norm = 2.4539e-01, time/batch = 16.0522s	
12188/22950 (epoch 26.553), train_loss = 0.91530082, grad/param norm = 2.4860e-01, time/batch = 15.8107s	
12189/22950 (epoch 26.556), train_loss = 0.99802212, grad/param norm = 2.2531e-01, time/batch = 15.7993s	
12190/22950 (epoch 26.558), train_loss = 0.82842750, grad/param norm = 2.1486e-01, time/batch = 15.9555s	
12191/22950 (epoch 26.560), train_loss = 0.93112187, grad/param norm = 2.1389e-01, time/batch = 15.6368s	
12192/22950 (epoch 26.562), train_loss = 0.88642099, grad/param norm = 2.1037e-01, time/batch = 15.9450s	
12193/22950 (epoch 26.564), train_loss = 0.99957919, grad/param norm = 2.4693e-01, time/batch = 15.8837s	
12194/22950 (epoch 26.566), train_loss = 0.98769351, grad/param norm = 2.4234e-01, time/batch = 16.0282s	
12195/22950 (epoch 26.569), train_loss = 0.94953619, grad/param norm = 2.2857e-01, time/batch = 15.6390s	
12196/22950 (epoch 26.571), train_loss = 0.93673461, grad/param norm = 2.3908e-01, time/batch = 15.8902s	
12197/22950 (epoch 26.573), train_loss = 0.95628927, grad/param norm = 2.3409e-01, time/batch = 15.8808s	
12198/22950 (epoch 26.575), train_loss = 1.07164247, grad/param norm = 2.7127e-01, time/batch = 16.5230s	
12199/22950 (epoch 26.577), train_loss = 0.98194251, grad/param norm = 2.6949e-01, time/batch = 16.5805s	
12200/22950 (epoch 26.580), train_loss = 1.02609459, grad/param norm = 2.3460e-01, time/batch = 15.8050s	
12201/22950 (epoch 26.582), train_loss = 1.12235232, grad/param norm = 2.4483e-01, time/batch = 16.4905s	
12202/22950 (epoch 26.584), train_loss = 0.83944558, grad/param norm = 2.1534e-01, time/batch = 16.7637s	
12203/22950 (epoch 26.586), train_loss = 0.87275929, grad/param norm = 2.1740e-01, time/batch = 16.8200s	
12204/22950 (epoch 26.588), train_loss = 1.09408963, grad/param norm = 2.1990e-01, time/batch = 15.6871s	
12205/22950 (epoch 26.590), train_loss = 0.99226364, grad/param norm = 2.2665e-01, time/batch = 16.2139s	
12206/22950 (epoch 26.593), train_loss = 0.93072479, grad/param norm = 2.2781e-01, time/batch = 15.9730s	
12207/22950 (epoch 26.595), train_loss = 0.86599598, grad/param norm = 2.4618e-01, time/batch = 16.5484s	
12208/22950 (epoch 26.597), train_loss = 1.04185999, grad/param norm = 2.4914e-01, time/batch = 16.1199s	
12209/22950 (epoch 26.599), train_loss = 0.97325377, grad/param norm = 2.2707e-01, time/batch = 16.0377s	
12210/22950 (epoch 26.601), train_loss = 1.01863440, grad/param norm = 2.4853e-01, time/batch = 16.1105s	
12211/22950 (epoch 26.603), train_loss = 1.08226348, grad/param norm = 2.3722e-01, time/batch = 16.0441s	
12212/22950 (epoch 26.606), train_loss = 0.96713821, grad/param norm = 2.4304e-01, time/batch = 16.5183s	
12213/22950 (epoch 26.608), train_loss = 0.99946273, grad/param norm = 2.4116e-01, time/batch = 15.7916s	
12214/22950 (epoch 26.610), train_loss = 0.96612814, grad/param norm = 2.3842e-01, time/batch = 15.6526s	
12215/22950 (epoch 26.612), train_loss = 0.96488492, grad/param norm = 2.4253e-01, time/batch = 15.4729s	
12216/22950 (epoch 26.614), train_loss = 1.09098184, grad/param norm = 2.6782e-01, time/batch = 16.2713s	
12217/22950 (epoch 26.617), train_loss = 0.96140870, grad/param norm = 2.2723e-01, time/batch = 16.1149s	
12218/22950 (epoch 26.619), train_loss = 0.93541508, grad/param norm = 2.0687e-01, time/batch = 16.4283s	
12219/22950 (epoch 26.621), train_loss = 1.05266720, grad/param norm = 2.1728e-01, time/batch = 16.3445s	
12220/22950 (epoch 26.623), train_loss = 1.04007000, grad/param norm = 2.4552e-01, time/batch = 16.3693s	
12221/22950 (epoch 26.625), train_loss = 0.94220248, grad/param norm = 2.4379e-01, time/batch = 16.3764s	
12222/22950 (epoch 26.627), train_loss = 0.94262313, grad/param norm = 2.4469e-01, time/batch = 16.6589s	
12223/22950 (epoch 26.630), train_loss = 0.83981089, grad/param norm = 2.0361e-01, time/batch = 15.9530s	
12224/22950 (epoch 26.632), train_loss = 0.91475704, grad/param norm = 2.6065e-01, time/batch = 15.9613s	
12225/22950 (epoch 26.634), train_loss = 0.96866034, grad/param norm = 2.1987e-01, time/batch = 16.2043s	
12226/22950 (epoch 26.636), train_loss = 0.99628073, grad/param norm = 2.3296e-01, time/batch = 15.8825s	
12227/22950 (epoch 26.638), train_loss = 0.89730986, grad/param norm = 2.1875e-01, time/batch = 16.1359s	
12228/22950 (epoch 26.641), train_loss = 0.94759076, grad/param norm = 2.2108e-01, time/batch = 15.8734s	
12229/22950 (epoch 26.643), train_loss = 1.03699328, grad/param norm = 2.7035e-01, time/batch = 16.3617s	
12230/22950 (epoch 26.645), train_loss = 0.92986473, grad/param norm = 2.4251e-01, time/batch = 16.3490s	
12231/22950 (epoch 26.647), train_loss = 0.93990287, grad/param norm = 2.2601e-01, time/batch = 16.3626s	
12232/22950 (epoch 26.649), train_loss = 0.92734304, grad/param norm = 2.1790e-01, time/batch = 16.2701s	
12233/22950 (epoch 26.651), train_loss = 1.01153519, grad/param norm = 2.2150e-01, time/batch = 16.0362s	
12234/22950 (epoch 26.654), train_loss = 0.82206828, grad/param norm = 2.1780e-01, time/batch = 16.1789s	
12235/22950 (epoch 26.656), train_loss = 1.03989239, grad/param norm = 2.9503e-01, time/batch = 16.2756s	
12236/22950 (epoch 26.658), train_loss = 0.87135088, grad/param norm = 2.3180e-01, time/batch = 16.4401s	
12237/22950 (epoch 26.660), train_loss = 0.78244897, grad/param norm = 2.1286e-01, time/batch = 15.7185s	
12238/22950 (epoch 26.662), train_loss = 0.79611420, grad/param norm = 2.0299e-01, time/batch = 16.0277s	
12239/22950 (epoch 26.664), train_loss = 0.93659413, grad/param norm = 2.2531e-01, time/batch = 16.2070s	
12240/22950 (epoch 26.667), train_loss = 0.97127486, grad/param norm = 2.5806e-01, time/batch = 15.9578s	
12241/22950 (epoch 26.669), train_loss = 0.96514253, grad/param norm = 2.3909e-01, time/batch = 16.4288s	
12242/22950 (epoch 26.671), train_loss = 0.95551939, grad/param norm = 2.1474e-01, time/batch = 16.5051s	
12243/22950 (epoch 26.673), train_loss = 0.89395832, grad/param norm = 2.3884e-01, time/batch = 15.6391s	
12244/22950 (epoch 26.675), train_loss = 0.97751134, grad/param norm = 2.3921e-01, time/batch = 15.7094s	
12245/22950 (epoch 26.678), train_loss = 0.94712855, grad/param norm = 2.3628e-01, time/batch = 15.7990s	
12246/22950 (epoch 26.680), train_loss = 0.96340027, grad/param norm = 1.9972e-01, time/batch = 15.7239s	
12247/22950 (epoch 26.682), train_loss = 0.93743003, grad/param norm = 2.5648e-01, time/batch = 15.5648s	
12248/22950 (epoch 26.684), train_loss = 1.04666766, grad/param norm = 2.4338e-01, time/batch = 15.6507s	
12249/22950 (epoch 26.686), train_loss = 1.05961569, grad/param norm = 2.5746e-01, time/batch = 15.7205s	
12250/22950 (epoch 26.688), train_loss = 0.99659231, grad/param norm = 2.3097e-01, time/batch = 15.8457s	
12251/22950 (epoch 26.691), train_loss = 0.95635214, grad/param norm = 2.2868e-01, time/batch = 15.6399s	
12252/22950 (epoch 26.693), train_loss = 0.87523860, grad/param norm = 2.3272e-01, time/batch = 15.4980s	
12253/22950 (epoch 26.695), train_loss = 1.06715662, grad/param norm = 2.5097e-01, time/batch = 16.1730s	
12254/22950 (epoch 26.697), train_loss = 1.00853970, grad/param norm = 2.5511e-01, time/batch = 16.1021s	
12255/22950 (epoch 26.699), train_loss = 1.02134541, grad/param norm = 2.3563e-01, time/batch = 15.3142s	
12256/22950 (epoch 26.702), train_loss = 1.03288409, grad/param norm = 2.4897e-01, time/batch = 15.7339s	
12257/22950 (epoch 26.704), train_loss = 1.08530939, grad/param norm = 2.9287e-01, time/batch = 16.3580s	
12258/22950 (epoch 26.706), train_loss = 1.06347356, grad/param norm = 2.4762e-01, time/batch = 15.9212s	
12259/22950 (epoch 26.708), train_loss = 0.85492492, grad/param norm = 2.4255e-01, time/batch = 15.2277s	
12260/22950 (epoch 26.710), train_loss = 0.98947750, grad/param norm = 2.3953e-01, time/batch = 14.6734s	
12261/22950 (epoch 26.712), train_loss = 1.11113750, grad/param norm = 2.8291e-01, time/batch = 15.8467s	
12262/22950 (epoch 26.715), train_loss = 0.95513615, grad/param norm = 2.4865e-01, time/batch = 15.3875s	
12263/22950 (epoch 26.717), train_loss = 0.99901289, grad/param norm = 2.1262e-01, time/batch = 14.8995s	
12264/22950 (epoch 26.719), train_loss = 0.92814460, grad/param norm = 2.3664e-01, time/batch = 14.8990s	
12265/22950 (epoch 26.721), train_loss = 1.01445581, grad/param norm = 2.3707e-01, time/batch = 15.2211s	
12266/22950 (epoch 26.723), train_loss = 0.97460050, grad/param norm = 2.3979e-01, time/batch = 14.6763s	
12267/22950 (epoch 26.725), train_loss = 1.02815717, grad/param norm = 2.6557e-01, time/batch = 14.9888s	
12268/22950 (epoch 26.728), train_loss = 0.93701463, grad/param norm = 2.4979e-01, time/batch = 14.9905s	
12269/22950 (epoch 26.730), train_loss = 0.94022983, grad/param norm = 2.7433e-01, time/batch = 15.8568s	
12270/22950 (epoch 26.732), train_loss = 1.01711836, grad/param norm = 2.3643e-01, time/batch = 14.8380s	
12271/22950 (epoch 26.734), train_loss = 0.96066292, grad/param norm = 2.4999e-01, time/batch = 14.9212s	
12272/22950 (epoch 26.736), train_loss = 0.97234664, grad/param norm = 2.2244e-01, time/batch = 15.8579s	
12273/22950 (epoch 26.739), train_loss = 1.02850571, grad/param norm = 2.3771e-01, time/batch = 15.2925s	
12274/22950 (epoch 26.741), train_loss = 1.04315577, grad/param norm = 2.4990e-01, time/batch = 14.7433s	
12275/22950 (epoch 26.743), train_loss = 1.11915175, grad/param norm = 2.7045e-01, time/batch = 14.9736s	
12276/22950 (epoch 26.745), train_loss = 1.20821693, grad/param norm = 2.7152e-01, time/batch = 14.7365s	
12277/22950 (epoch 26.747), train_loss = 0.97922205, grad/param norm = 2.3116e-01, time/batch = 14.8272s	
12278/22950 (epoch 26.749), train_loss = 0.91215019, grad/param norm = 2.2505e-01, time/batch = 15.2145s	
12279/22950 (epoch 26.752), train_loss = 1.15563264, grad/param norm = 2.5893e-01, time/batch = 14.9117s	
12280/22950 (epoch 26.754), train_loss = 1.04194815, grad/param norm = 2.3529e-01, time/batch = 14.9592s	
12281/22950 (epoch 26.756), train_loss = 0.91937967, grad/param norm = 2.3160e-01, time/batch = 14.8268s	
12282/22950 (epoch 26.758), train_loss = 0.96692788, grad/param norm = 2.2280e-01, time/batch = 14.9006s	
12283/22950 (epoch 26.760), train_loss = 1.01876473, grad/param norm = 2.6782e-01, time/batch = 14.5810s	
12284/22950 (epoch 26.763), train_loss = 1.05676675, grad/param norm = 2.6607e-01, time/batch = 15.5169s	
12285/22950 (epoch 26.765), train_loss = 1.00529847, grad/param norm = 2.4406e-01, time/batch = 15.0539s	
12286/22950 (epoch 26.767), train_loss = 1.18762357, grad/param norm = 2.4235e-01, time/batch = 14.5789s	
12287/22950 (epoch 26.769), train_loss = 1.02956191, grad/param norm = 2.4422e-01, time/batch = 15.1455s	
12288/22950 (epoch 26.771), train_loss = 0.83105520, grad/param norm = 2.3542e-01, time/batch = 15.0570s	
12289/22950 (epoch 26.773), train_loss = 0.76102727, grad/param norm = 2.0854e-01, time/batch = 15.0683s	
12290/22950 (epoch 26.776), train_loss = 0.88970921, grad/param norm = 2.0630e-01, time/batch = 14.9853s	
12291/22950 (epoch 26.778), train_loss = 0.89003975, grad/param norm = 2.1618e-01, time/batch = 15.2354s	
12292/22950 (epoch 26.780), train_loss = 0.97062279, grad/param norm = 2.0354e-01, time/batch = 15.4560s	
12293/22950 (epoch 26.782), train_loss = 1.02485154, grad/param norm = 2.4023e-01, time/batch = 15.2324s	
12294/22950 (epoch 26.784), train_loss = 0.92557984, grad/param norm = 2.1566e-01, time/batch = 14.6576s	
12295/22950 (epoch 26.786), train_loss = 0.99105292, grad/param norm = 2.3900e-01, time/batch = 15.0023s	
12296/22950 (epoch 26.789), train_loss = 0.83696348, grad/param norm = 2.1391e-01, time/batch = 15.3937s	
12297/22950 (epoch 26.791), train_loss = 0.88277203, grad/param norm = 2.2007e-01, time/batch = 15.2332s	
12298/22950 (epoch 26.793), train_loss = 1.09905649, grad/param norm = 2.4393e-01, time/batch = 15.7023s	
12299/22950 (epoch 26.795), train_loss = 0.94076882, grad/param norm = 1.9891e-01, time/batch = 15.0760s	
12300/22950 (epoch 26.797), train_loss = 1.10992798, grad/param norm = 2.3749e-01, time/batch = 15.7023s	
12301/22950 (epoch 26.800), train_loss = 0.89580046, grad/param norm = 2.3059e-01, time/batch = 16.6396s	
12302/22950 (epoch 26.802), train_loss = 0.91977221, grad/param norm = 2.3007e-01, time/batch = 14.9902s	
12303/22950 (epoch 26.804), train_loss = 0.91798113, grad/param norm = 2.1017e-01, time/batch = 15.2912s	
12304/22950 (epoch 26.806), train_loss = 0.85359255, grad/param norm = 2.1613e-01, time/batch = 15.2297s	
12305/22950 (epoch 26.808), train_loss = 0.95454276, grad/param norm = 2.1288e-01, time/batch = 15.0688s	
12306/22950 (epoch 26.810), train_loss = 0.91853829, grad/param norm = 2.2377e-01, time/batch = 14.9183s	
12307/22950 (epoch 26.813), train_loss = 0.78747329, grad/param norm = 2.0226e-01, time/batch = 14.8375s	
12308/22950 (epoch 26.815), train_loss = 0.80762772, grad/param norm = 2.1046e-01, time/batch = 16.0440s	
12309/22950 (epoch 26.817), train_loss = 0.86986495, grad/param norm = 2.1107e-01, time/batch = 14.8949s	
12310/22950 (epoch 26.819), train_loss = 0.94391454, grad/param norm = 2.1904e-01, time/batch = 14.9918s	
12311/22950 (epoch 26.821), train_loss = 0.89996623, grad/param norm = 2.3468e-01, time/batch = 14.8383s	
12312/22950 (epoch 26.824), train_loss = 0.96784012, grad/param norm = 2.4015e-01, time/batch = 15.5529s	
12313/22950 (epoch 26.826), train_loss = 1.03454725, grad/param norm = 2.6852e-01, time/batch = 14.9785s	
12314/22950 (epoch 26.828), train_loss = 0.93624653, grad/param norm = 2.4483e-01, time/batch = 15.1275s	
12315/22950 (epoch 26.830), train_loss = 0.92948401, grad/param norm = 2.3986e-01, time/batch = 14.8377s	
12316/22950 (epoch 26.832), train_loss = 0.95966968, grad/param norm = 2.4973e-01, time/batch = 15.6993s	
12317/22950 (epoch 26.834), train_loss = 0.80672827, grad/param norm = 2.3001e-01, time/batch = 15.2441s	
12318/22950 (epoch 26.837), train_loss = 0.96754988, grad/param norm = 2.4106e-01, time/batch = 15.6126s	
12319/22950 (epoch 26.839), train_loss = 0.83828621, grad/param norm = 2.5286e-01, time/batch = 15.5378s	
12320/22950 (epoch 26.841), train_loss = 0.89513666, grad/param norm = 2.1330e-01, time/batch = 16.7864s	
12321/22950 (epoch 26.843), train_loss = 0.90591231, grad/param norm = 2.3089e-01, time/batch = 19.5301s	
12322/22950 (epoch 26.845), train_loss = 0.97113696, grad/param norm = 2.3435e-01, time/batch = 16.8084s	
12323/22950 (epoch 26.847), train_loss = 1.00844657, grad/param norm = 2.4340e-01, time/batch = 16.3091s	
12324/22950 (epoch 26.850), train_loss = 1.02027808, grad/param norm = 2.5263e-01, time/batch = 16.4923s	
12325/22950 (epoch 26.852), train_loss = 1.02290720, grad/param norm = 2.4853e-01, time/batch = 17.8778s	
12326/22950 (epoch 26.854), train_loss = 0.95864681, grad/param norm = 2.3774e-01, time/batch = 18.0452s	
12327/22950 (epoch 26.856), train_loss = 1.11837831, grad/param norm = 3.1485e-01, time/batch = 17.2973s	
12328/22950 (epoch 26.858), train_loss = 1.02844702, grad/param norm = 2.2178e-01, time/batch = 17.7973s	
12329/22950 (epoch 26.861), train_loss = 1.04325889, grad/param norm = 2.5292e-01, time/batch = 19.7878s	
12330/22950 (epoch 26.863), train_loss = 1.07082946, grad/param norm = 2.4522e-01, time/batch = 16.4236s	
12331/22950 (epoch 26.865), train_loss = 1.09347106, grad/param norm = 2.5277e-01, time/batch = 17.3343s	
12332/22950 (epoch 26.867), train_loss = 0.99415161, grad/param norm = 2.4855e-01, time/batch = 18.9427s	
12333/22950 (epoch 26.869), train_loss = 1.12060580, grad/param norm = 2.6175e-01, time/batch = 18.2558s	
12334/22950 (epoch 26.871), train_loss = 1.00161814, grad/param norm = 2.4403e-01, time/batch = 17.6261s	
12335/22950 (epoch 26.874), train_loss = 0.98738211, grad/param norm = 2.1728e-01, time/batch = 19.7036s	
12336/22950 (epoch 26.876), train_loss = 1.03902218, grad/param norm = 2.4952e-01, time/batch = 18.4586s	
12337/22950 (epoch 26.878), train_loss = 0.93724776, grad/param norm = 2.5055e-01, time/batch = 18.8788s	
12338/22950 (epoch 26.880), train_loss = 1.15474023, grad/param norm = 2.7303e-01, time/batch = 19.5421s	
12339/22950 (epoch 26.882), train_loss = 0.87569763, grad/param norm = 2.2034e-01, time/batch = 16.3586s	
12340/22950 (epoch 26.885), train_loss = 0.99590360, grad/param norm = 2.1959e-01, time/batch = 19.5034s	
12341/22950 (epoch 26.887), train_loss = 0.96086384, grad/param norm = 2.2582e-01, time/batch = 18.7723s	
12342/22950 (epoch 26.889), train_loss = 1.00846527, grad/param norm = 2.2690e-01, time/batch = 19.4554s	
12343/22950 (epoch 26.891), train_loss = 0.91388566, grad/param norm = 2.1570e-01, time/batch = 18.1965s	
12344/22950 (epoch 26.893), train_loss = 1.04823621, grad/param norm = 2.2887e-01, time/batch = 18.7085s	
12345/22950 (epoch 26.895), train_loss = 1.12319648, grad/param norm = 2.9084e-01, time/batch = 17.6221s	
12346/22950 (epoch 26.898), train_loss = 0.98686302, grad/param norm = 2.4966e-01, time/batch = 17.1005s	
12347/22950 (epoch 26.900), train_loss = 0.95890799, grad/param norm = 2.2609e-01, time/batch = 19.1994s	
12348/22950 (epoch 26.902), train_loss = 0.99605485, grad/param norm = 2.3888e-01, time/batch = 18.4688s	
12349/22950 (epoch 26.904), train_loss = 1.00271416, grad/param norm = 2.4296e-01, time/batch = 18.0346s	
12350/22950 (epoch 26.906), train_loss = 1.02723326, grad/param norm = 2.7726e-01, time/batch = 16.4762s	
12351/22950 (epoch 26.908), train_loss = 0.87844117, grad/param norm = 2.2314e-01, time/batch = 17.2527s	
12352/22950 (epoch 26.911), train_loss = 0.84487594, grad/param norm = 1.8981e-01, time/batch = 19.0357s	
12353/22950 (epoch 26.913), train_loss = 0.93354299, grad/param norm = 2.2089e-01, time/batch = 16.7465s	
12354/22950 (epoch 26.915), train_loss = 1.10909831, grad/param norm = 2.5111e-01, time/batch = 18.5417s	
12355/22950 (epoch 26.917), train_loss = 0.84644234, grad/param norm = 2.1105e-01, time/batch = 19.7896s	
12356/22950 (epoch 26.919), train_loss = 0.96469804, grad/param norm = 2.2557e-01, time/batch = 17.7800s	
12357/22950 (epoch 26.922), train_loss = 0.99631381, grad/param norm = 2.3978e-01, time/batch = 18.1405s	
12358/22950 (epoch 26.924), train_loss = 1.00270749, grad/param norm = 2.2884e-01, time/batch = 18.7086s	
12359/22950 (epoch 26.926), train_loss = 0.83724683, grad/param norm = 2.6441e-01, time/batch = 17.2079s	
12360/22950 (epoch 26.928), train_loss = 0.84581984, grad/param norm = 2.0859e-01, time/batch = 20.3711s	
12361/22950 (epoch 26.930), train_loss = 0.85160003, grad/param norm = 2.2587e-01, time/batch = 18.7047s	
12362/22950 (epoch 26.932), train_loss = 0.80828629, grad/param norm = 2.0064e-01, time/batch = 17.2719s	
12363/22950 (epoch 26.935), train_loss = 0.95869248, grad/param norm = 2.2734e-01, time/batch = 18.2314s	
12364/22950 (epoch 26.937), train_loss = 0.96550272, grad/param norm = 2.4528e-01, time/batch = 18.5274s	
12365/22950 (epoch 26.939), train_loss = 0.87767115, grad/param norm = 2.1686e-01, time/batch = 17.4401s	
12366/22950 (epoch 26.941), train_loss = 0.92741886, grad/param norm = 2.5401e-01, time/batch = 16.2934s	
12367/22950 (epoch 26.943), train_loss = 0.98572554, grad/param norm = 2.3627e-01, time/batch = 17.6182s	
12368/22950 (epoch 26.946), train_loss = 0.83247086, grad/param norm = 2.2662e-01, time/batch = 18.1950s	
12369/22950 (epoch 26.948), train_loss = 1.03594322, grad/param norm = 2.4309e-01, time/batch = 17.6050s	
12370/22950 (epoch 26.950), train_loss = 0.95112964, grad/param norm = 2.2931e-01, time/batch = 19.4615s	
12371/22950 (epoch 26.952), train_loss = 1.00694769, grad/param norm = 2.2172e-01, time/batch = 19.9569s	
12372/22950 (epoch 26.954), train_loss = 0.99491146, grad/param norm = 2.3979e-01, time/batch = 17.9458s	
12373/22950 (epoch 26.956), train_loss = 0.89751925, grad/param norm = 2.2640e-01, time/batch = 19.7952s	
12374/22950 (epoch 26.959), train_loss = 0.86995683, grad/param norm = 2.3239e-01, time/batch = 19.2944s	
12375/22950 (epoch 26.961), train_loss = 0.97258808, grad/param norm = 2.3729e-01, time/batch = 17.7729s	
12376/22950 (epoch 26.963), train_loss = 0.98268105, grad/param norm = 2.3896e-01, time/batch = 19.6895s	
12377/22950 (epoch 26.965), train_loss = 1.07115209, grad/param norm = 2.3015e-01, time/batch = 18.3751s	
12378/22950 (epoch 26.967), train_loss = 0.95751930, grad/param norm = 2.4022e-01, time/batch = 20.1141s	
12379/22950 (epoch 26.969), train_loss = 0.85087290, grad/param norm = 2.2463e-01, time/batch = 19.4475s	
12380/22950 (epoch 26.972), train_loss = 0.95152827, grad/param norm = 2.0532e-01, time/batch = 18.4541s	
12381/22950 (epoch 26.974), train_loss = 0.92425013, grad/param norm = 2.3982e-01, time/batch = 19.5563s	
12382/22950 (epoch 26.976), train_loss = 0.90167453, grad/param norm = 2.1142e-01, time/batch = 18.9279s	
12383/22950 (epoch 26.978), train_loss = 0.89462365, grad/param norm = 2.5788e-01, time/batch = 17.2920s	
12384/22950 (epoch 26.980), train_loss = 0.90996663, grad/param norm = 2.2155e-01, time/batch = 19.7015s	
12385/22950 (epoch 26.983), train_loss = 1.00534554, grad/param norm = 2.1219e-01, time/batch = 17.7098s	
12386/22950 (epoch 26.985), train_loss = 0.84695440, grad/param norm = 2.3300e-01, time/batch = 17.0453s	
12387/22950 (epoch 26.987), train_loss = 0.89292947, grad/param norm = 2.2615e-01, time/batch = 19.2887s	
12388/22950 (epoch 26.989), train_loss = 0.94591984, grad/param norm = 2.2233e-01, time/batch = 17.9480s	
12389/22950 (epoch 26.991), train_loss = 0.81403696, grad/param norm = 2.1494e-01, time/batch = 19.9587s	
12390/22950 (epoch 26.993), train_loss = 0.98642782, grad/param norm = 2.1716e-01, time/batch = 17.0211s	
12391/22950 (epoch 26.996), train_loss = 0.94759636, grad/param norm = 2.2438e-01, time/batch = 17.6350s	
12392/22950 (epoch 26.998), train_loss = 0.86662136, grad/param norm = 2.0709e-01, time/batch = 16.0843s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
12393/22950 (epoch 27.000), train_loss = 0.80107578, grad/param norm = 2.0394e-01, time/batch = 18.1155s	
12394/22950 (epoch 27.002), train_loss = 1.10774552, grad/param norm = 2.3478e-01, time/batch = 19.3082s	
12395/22950 (epoch 27.004), train_loss = 0.98973879, grad/param norm = 2.3049e-01, time/batch = 31.7767s	
12396/22950 (epoch 27.007), train_loss = 0.94991211, grad/param norm = 2.3085e-01, time/batch = 16.7208s	
12397/22950 (epoch 27.009), train_loss = 1.08065424, grad/param norm = 2.5658e-01, time/batch = 17.7040s	
12398/22950 (epoch 27.011), train_loss = 0.82686285, grad/param norm = 2.4316e-01, time/batch = 18.4713s	
12399/22950 (epoch 27.013), train_loss = 0.96346840, grad/param norm = 2.8342e-01, time/batch = 16.4562s	
12400/22950 (epoch 27.015), train_loss = 0.97137260, grad/param norm = 2.3396e-01, time/batch = 19.5350s	
12401/22950 (epoch 27.017), train_loss = 0.96817928, grad/param norm = 2.1556e-01, time/batch = 16.2006s	
12402/22950 (epoch 27.020), train_loss = 0.99356664, grad/param norm = 2.2600e-01, time/batch = 18.9742s	
12403/22950 (epoch 27.022), train_loss = 0.82127168, grad/param norm = 2.0219e-01, time/batch = 19.8667s	
12404/22950 (epoch 27.024), train_loss = 0.91443831, grad/param norm = 2.5255e-01, time/batch = 17.4606s	
12405/22950 (epoch 27.026), train_loss = 1.00487813, grad/param norm = 2.4369e-01, time/batch = 18.6447s	
12406/22950 (epoch 27.028), train_loss = 1.04067196, grad/param norm = 2.0598e-01, time/batch = 17.9432s	
12407/22950 (epoch 27.031), train_loss = 0.91885067, grad/param norm = 2.1074e-01, time/batch = 16.6615s	
12408/22950 (epoch 27.033), train_loss = 1.06207799, grad/param norm = 2.4753e-01, time/batch = 19.1942s	
12409/22950 (epoch 27.035), train_loss = 0.96263402, grad/param norm = 2.1492e-01, time/batch = 18.3030s	
12410/22950 (epoch 27.037), train_loss = 0.95048374, grad/param norm = 2.2580e-01, time/batch = 19.5498s	
12411/22950 (epoch 27.039), train_loss = 0.91880964, grad/param norm = 2.2089e-01, time/batch = 18.5080s	
12412/22950 (epoch 27.041), train_loss = 0.89428748, grad/param norm = 2.2471e-01, time/batch = 18.0417s	
12413/22950 (epoch 27.044), train_loss = 1.00014784, grad/param norm = 2.4088e-01, time/batch = 20.0302s	
12414/22950 (epoch 27.046), train_loss = 0.96110218, grad/param norm = 2.3062e-01, time/batch = 17.6715s	
12415/22950 (epoch 27.048), train_loss = 0.95853299, grad/param norm = 2.1696e-01, time/batch = 17.7108s	
12416/22950 (epoch 27.050), train_loss = 0.91297299, grad/param norm = 2.5933e-01, time/batch = 19.4590s	
12417/22950 (epoch 27.052), train_loss = 0.98806716, grad/param norm = 2.4102e-01, time/batch = 17.9394s	
12418/22950 (epoch 27.054), train_loss = 1.12555360, grad/param norm = 2.4871e-01, time/batch = 19.5469s	
12419/22950 (epoch 27.057), train_loss = 1.03463747, grad/param norm = 2.3779e-01, time/batch = 18.1146s	
12420/22950 (epoch 27.059), train_loss = 1.01034431, grad/param norm = 2.1307e-01, time/batch = 18.7844s	
12421/22950 (epoch 27.061), train_loss = 0.89431692, grad/param norm = 2.2345e-01, time/batch = 17.9664s	
12422/22950 (epoch 27.063), train_loss = 0.98227176, grad/param norm = 2.3654e-01, time/batch = 17.1329s	
12423/22950 (epoch 27.065), train_loss = 0.85160240, grad/param norm = 2.1317e-01, time/batch = 19.1309s	
12424/22950 (epoch 27.068), train_loss = 0.99636368, grad/param norm = 2.2985e-01, time/batch = 17.9587s	
12425/22950 (epoch 27.070), train_loss = 0.85713694, grad/param norm = 2.0766e-01, time/batch = 18.9527s	
12426/22950 (epoch 27.072), train_loss = 1.02802426, grad/param norm = 2.3217e-01, time/batch = 18.8720s	
12427/22950 (epoch 27.074), train_loss = 1.00092321, grad/param norm = 2.4453e-01, time/batch = 18.1830s	
12428/22950 (epoch 27.076), train_loss = 0.99568977, grad/param norm = 2.2689e-01, time/batch = 19.0483s	
12429/22950 (epoch 27.078), train_loss = 1.04072603, grad/param norm = 2.3103e-01, time/batch = 18.3671s	
12430/22950 (epoch 27.081), train_loss = 1.06930730, grad/param norm = 2.3642e-01, time/batch = 18.6111s	
12431/22950 (epoch 27.083), train_loss = 0.97241096, grad/param norm = 2.4728e-01, time/batch = 16.0994s	
12432/22950 (epoch 27.085), train_loss = 0.85014465, grad/param norm = 2.3228e-01, time/batch = 18.5324s	
12433/22950 (epoch 27.087), train_loss = 0.89199740, grad/param norm = 2.7477e-01, time/batch = 18.1213s	
12434/22950 (epoch 27.089), train_loss = 0.99066901, grad/param norm = 2.3435e-01, time/batch = 17.6050s	
12435/22950 (epoch 27.092), train_loss = 0.90784161, grad/param norm = 2.4596e-01, time/batch = 19.7623s	
12436/22950 (epoch 27.094), train_loss = 0.87267970, grad/param norm = 2.2166e-01, time/batch = 18.6889s	
12437/22950 (epoch 27.096), train_loss = 1.06020572, grad/param norm = 2.3569e-01, time/batch = 18.8677s	
12438/22950 (epoch 27.098), train_loss = 1.01595956, grad/param norm = 2.2778e-01, time/batch = 19.1201s	
12439/22950 (epoch 27.100), train_loss = 0.92111870, grad/param norm = 2.3535e-01, time/batch = 17.1885s	
12440/22950 (epoch 27.102), train_loss = 0.96591787, grad/param norm = 2.4088e-01, time/batch = 16.7700s	
12441/22950 (epoch 27.105), train_loss = 0.80994113, grad/param norm = 2.0866e-01, time/batch = 16.3583s	
12442/22950 (epoch 27.107), train_loss = 0.90297139, grad/param norm = 2.1256e-01, time/batch = 17.7044s	
12443/22950 (epoch 27.109), train_loss = 0.91393129, grad/param norm = 2.3611e-01, time/batch = 17.1907s	
12444/22950 (epoch 27.111), train_loss = 0.81037531, grad/param norm = 2.1516e-01, time/batch = 17.8531s	
12445/22950 (epoch 27.113), train_loss = 0.96301002, grad/param norm = 2.3379e-01, time/batch = 16.9869s	
12446/22950 (epoch 27.115), train_loss = 0.96335201, grad/param norm = 2.1726e-01, time/batch = 18.8142s	
12447/22950 (epoch 27.118), train_loss = 1.07429835, grad/param norm = 2.2780e-01, time/batch = 17.4557s	
12448/22950 (epoch 27.120), train_loss = 0.85904306, grad/param norm = 2.1380e-01, time/batch = 16.1102s	
12449/22950 (epoch 27.122), train_loss = 1.03925308, grad/param norm = 2.3428e-01, time/batch = 19.2058s	
12450/22950 (epoch 27.124), train_loss = 0.82924947, grad/param norm = 1.9479e-01, time/batch = 15.1395s	
12451/22950 (epoch 27.126), train_loss = 0.97283883, grad/param norm = 2.7526e-01, time/batch = 18.4553s	
12452/22950 (epoch 27.129), train_loss = 0.86977740, grad/param norm = 1.9875e-01, time/batch = 18.2164s	
12453/22950 (epoch 27.131), train_loss = 0.94251561, grad/param norm = 2.1928e-01, time/batch = 18.9539s	
12454/22950 (epoch 27.133), train_loss = 1.00327092, grad/param norm = 2.1461e-01, time/batch = 18.0040s	
12455/22950 (epoch 27.135), train_loss = 0.96178705, grad/param norm = 2.1490e-01, time/batch = 16.5544s	
12456/22950 (epoch 27.137), train_loss = 1.05489097, grad/param norm = 2.7822e-01, time/batch = 16.7216s	
12457/22950 (epoch 27.139), train_loss = 0.86197490, grad/param norm = 2.3072e-01, time/batch = 16.6931s	
12458/22950 (epoch 27.142), train_loss = 0.84897957, grad/param norm = 2.1401e-01, time/batch = 16.6278s	
12459/22950 (epoch 27.144), train_loss = 0.92166436, grad/param norm = 2.1811e-01, time/batch = 16.0821s	
12460/22950 (epoch 27.146), train_loss = 0.91432623, grad/param norm = 2.4306e-01, time/batch = 16.1691s	
12461/22950 (epoch 27.148), train_loss = 0.90095923, grad/param norm = 2.2518e-01, time/batch = 16.3799s	
12462/22950 (epoch 27.150), train_loss = 0.97048190, grad/param norm = 2.3227e-01, time/batch = 16.3790s	
12463/22950 (epoch 27.153), train_loss = 0.89946613, grad/param norm = 2.0487e-01, time/batch = 16.5491s	
12464/22950 (epoch 27.155), train_loss = 0.89601699, grad/param norm = 2.0824e-01, time/batch = 15.9238s	
12465/22950 (epoch 27.157), train_loss = 0.94920403, grad/param norm = 2.1774e-01, time/batch = 16.2162s	
12466/22950 (epoch 27.159), train_loss = 0.87108083, grad/param norm = 2.0937e-01, time/batch = 16.1738s	
12467/22950 (epoch 27.161), train_loss = 0.92291977, grad/param norm = 2.1753e-01, time/batch = 19.2074s	
12468/22950 (epoch 27.163), train_loss = 0.84109919, grad/param norm = 2.2244e-01, time/batch = 17.7755s	
12469/22950 (epoch 27.166), train_loss = 1.01640837, grad/param norm = 3.0210e-01, time/batch = 16.6834s	
12470/22950 (epoch 27.168), train_loss = 0.98824781, grad/param norm = 2.9085e-01, time/batch = 16.0221s	
12471/22950 (epoch 27.170), train_loss = 0.92111561, grad/param norm = 2.4723e-01, time/batch = 16.6337s	
12472/22950 (epoch 27.172), train_loss = 0.98389449, grad/param norm = 2.0758e-01, time/batch = 16.9374s	
12473/22950 (epoch 27.174), train_loss = 1.03854879, grad/param norm = 2.5480e-01, time/batch = 19.4642s	
12474/22950 (epoch 27.176), train_loss = 1.04071946, grad/param norm = 2.5622e-01, time/batch = 18.7711s	
12475/22950 (epoch 27.179), train_loss = 0.99994978, grad/param norm = 2.5148e-01, time/batch = 16.4404s	
12476/22950 (epoch 27.181), train_loss = 1.18836173, grad/param norm = 2.4260e-01, time/batch = 16.3413s	
12477/22950 (epoch 27.183), train_loss = 1.02455525, grad/param norm = 2.4113e-01, time/batch = 19.0423s	
12478/22950 (epoch 27.185), train_loss = 0.98111968, grad/param norm = 2.1533e-01, time/batch = 17.1296s	
12479/22950 (epoch 27.187), train_loss = 0.87480872, grad/param norm = 2.3468e-01, time/batch = 16.6379s	
12480/22950 (epoch 27.190), train_loss = 0.79783979, grad/param norm = 2.1786e-01, time/batch = 16.1123s	
12481/22950 (epoch 27.192), train_loss = 0.78610938, grad/param norm = 2.1559e-01, time/batch = 17.7674s	
12482/22950 (epoch 27.194), train_loss = 0.92395458, grad/param norm = 2.5655e-01, time/batch = 17.0345s	
12483/22950 (epoch 27.196), train_loss = 0.73115659, grad/param norm = 2.4595e-01, time/batch = 16.1206s	
12484/22950 (epoch 27.198), train_loss = 1.00841007, grad/param norm = 2.5511e-01, time/batch = 16.4328s	
12485/22950 (epoch 27.200), train_loss = 0.87684426, grad/param norm = 2.2494e-01, time/batch = 16.9594s	
12486/22950 (epoch 27.203), train_loss = 0.84872060, grad/param norm = 2.2651e-01, time/batch = 20.1150s	
12487/22950 (epoch 27.205), train_loss = 0.89543739, grad/param norm = 2.0838e-01, time/batch = 17.9599s	
12488/22950 (epoch 27.207), train_loss = 0.96753045, grad/param norm = 2.3022e-01, time/batch = 17.7448s	
12489/22950 (epoch 27.209), train_loss = 0.94305366, grad/param norm = 3.0032e-01, time/batch = 16.6785s	
12490/22950 (epoch 27.211), train_loss = 0.80687140, grad/param norm = 2.3388e-01, time/batch = 16.3338s	
12491/22950 (epoch 27.214), train_loss = 0.89207865, grad/param norm = 2.4294e-01, time/batch = 16.3018s	
12492/22950 (epoch 27.216), train_loss = 1.01487512, grad/param norm = 2.3868e-01, time/batch = 16.4429s	
12493/22950 (epoch 27.218), train_loss = 0.94157870, grad/param norm = 2.1680e-01, time/batch = 16.4584s	
12494/22950 (epoch 27.220), train_loss = 1.02480115, grad/param norm = 2.6415e-01, time/batch = 16.2210s	
12495/22950 (epoch 27.222), train_loss = 1.04215603, grad/param norm = 2.4661e-01, time/batch = 16.3588s	
12496/22950 (epoch 27.224), train_loss = 0.94599761, grad/param norm = 2.2384e-01, time/batch = 16.3467s	
12497/22950 (epoch 27.227), train_loss = 1.01090189, grad/param norm = 2.2329e-01, time/batch = 15.9639s	
12498/22950 (epoch 27.229), train_loss = 1.04484038, grad/param norm = 2.5119e-01, time/batch = 16.1268s	
12499/22950 (epoch 27.231), train_loss = 0.80976763, grad/param norm = 2.0984e-01, time/batch = 16.1789s	
12500/22950 (epoch 27.233), train_loss = 0.89639539, grad/param norm = 2.0970e-01, time/batch = 16.8050s	
12501/22950 (epoch 27.235), train_loss = 1.07653782, grad/param norm = 2.3160e-01, time/batch = 16.6916s	
12502/22950 (epoch 27.237), train_loss = 0.89239645, grad/param norm = 2.2515e-01, time/batch = 16.6620s	
12503/22950 (epoch 27.240), train_loss = 0.93958329, grad/param norm = 2.1533e-01, time/batch = 16.7370s	
12504/22950 (epoch 27.242), train_loss = 1.08289773, grad/param norm = 2.2937e-01, time/batch = 16.7496s	
12505/22950 (epoch 27.244), train_loss = 1.05107662, grad/param norm = 2.4139e-01, time/batch = 16.3356s	
12506/22950 (epoch 27.246), train_loss = 1.05001227, grad/param norm = 2.2312e-01, time/batch = 16.7410s	
12507/22950 (epoch 27.248), train_loss = 0.98517628, grad/param norm = 2.4782e-01, time/batch = 17.0673s	
12508/22950 (epoch 27.251), train_loss = 0.87873866, grad/param norm = 2.1895e-01, time/batch = 16.6914s	
12509/22950 (epoch 27.253), train_loss = 0.89857106, grad/param norm = 2.4216e-01, time/batch = 16.2176s	
12510/22950 (epoch 27.255), train_loss = 0.97706713, grad/param norm = 2.4129e-01, time/batch = 16.5964s	
12511/22950 (epoch 27.257), train_loss = 1.03857546, grad/param norm = 2.5458e-01, time/batch = 16.7577s	
12512/22950 (epoch 27.259), train_loss = 0.81114982, grad/param norm = 2.0392e-01, time/batch = 15.9692s	
12513/22950 (epoch 27.261), train_loss = 0.90530015, grad/param norm = 2.2444e-01, time/batch = 16.1330s	
12514/22950 (epoch 27.264), train_loss = 0.86030334, grad/param norm = 2.1859e-01, time/batch = 16.6804s	
12515/22950 (epoch 27.266), train_loss = 0.93745533, grad/param norm = 2.2680e-01, time/batch = 16.3008s	
12516/22950 (epoch 27.268), train_loss = 0.95435298, grad/param norm = 2.3982e-01, time/batch = 16.1287s	
12517/22950 (epoch 27.270), train_loss = 0.95029854, grad/param norm = 2.3599e-01, time/batch = 15.7086s	
12518/22950 (epoch 27.272), train_loss = 0.98503763, grad/param norm = 2.4394e-01, time/batch = 16.3546s	
12519/22950 (epoch 27.275), train_loss = 0.88609929, grad/param norm = 2.3866e-01, time/batch = 16.0401s	
12520/22950 (epoch 27.277), train_loss = 0.80237825, grad/param norm = 2.1391e-01, time/batch = 16.0412s	
12521/22950 (epoch 27.279), train_loss = 0.85595715, grad/param norm = 2.6181e-01, time/batch = 16.7785s	
12522/22950 (epoch 27.281), train_loss = 0.88778849, grad/param norm = 2.2158e-01, time/batch = 16.3112s	
12523/22950 (epoch 27.283), train_loss = 0.80839525, grad/param norm = 1.9088e-01, time/batch = 16.3080s	
12524/22950 (epoch 27.285), train_loss = 0.96029649, grad/param norm = 2.1448e-01, time/batch = 16.3807s	
12525/22950 (epoch 27.288), train_loss = 1.04097891, grad/param norm = 2.1681e-01, time/batch = 16.8893s	
12526/22950 (epoch 27.290), train_loss = 0.90273715, grad/param norm = 2.2545e-01, time/batch = 16.8706s	
12527/22950 (epoch 27.292), train_loss = 1.03427321, grad/param norm = 2.3472e-01, time/batch = 16.5969s	
12528/22950 (epoch 27.294), train_loss = 0.95395758, grad/param norm = 2.2411e-01, time/batch = 16.5980s	
12529/22950 (epoch 27.296), train_loss = 0.74081917, grad/param norm = 1.7722e-01, time/batch = 16.8787s	
12530/22950 (epoch 27.298), train_loss = 0.93707581, grad/param norm = 2.2667e-01, time/batch = 16.5871s	
12531/22950 (epoch 27.301), train_loss = 0.96428024, grad/param norm = 2.3411e-01, time/batch = 16.2267s	
12532/22950 (epoch 27.303), train_loss = 0.94239582, grad/param norm = 2.2229e-01, time/batch = 16.7387s	
12533/22950 (epoch 27.305), train_loss = 0.93584183, grad/param norm = 2.3306e-01, time/batch = 16.4259s	
12534/22950 (epoch 27.307), train_loss = 1.06566805, grad/param norm = 2.2900e-01, time/batch = 16.5649s	
12535/22950 (epoch 27.309), train_loss = 0.88887449, grad/param norm = 2.1400e-01, time/batch = 15.8662s	
12536/22950 (epoch 27.312), train_loss = 0.96136128, grad/param norm = 2.3361e-01, time/batch = 15.5687s	
12537/22950 (epoch 27.314), train_loss = 0.94653625, grad/param norm = 1.9905e-01, time/batch = 15.7867s	
12538/22950 (epoch 27.316), train_loss = 0.93109632, grad/param norm = 2.5365e-01, time/batch = 15.8644s	
12539/22950 (epoch 27.318), train_loss = 0.79307723, grad/param norm = 1.8211e-01, time/batch = 15.6361s	
12540/22950 (epoch 27.320), train_loss = 0.86528119, grad/param norm = 2.1137e-01, time/batch = 15.7997s	
12541/22950 (epoch 27.322), train_loss = 0.88300359, grad/param norm = 2.2244e-01, time/batch = 15.4850s	
12542/22950 (epoch 27.325), train_loss = 0.74875837, grad/param norm = 2.1214e-01, time/batch = 16.1348s	
12543/22950 (epoch 27.327), train_loss = 0.76019658, grad/param norm = 2.0273e-01, time/batch = 16.0295s	
12544/22950 (epoch 27.329), train_loss = 0.87017709, grad/param norm = 1.9723e-01, time/batch = 15.3144s	
12545/22950 (epoch 27.331), train_loss = 0.81415142, grad/param norm = 1.9555e-01, time/batch = 15.2264s	
12546/22950 (epoch 27.333), train_loss = 0.88727907, grad/param norm = 2.1728e-01, time/batch = 15.1476s	
12547/22950 (epoch 27.336), train_loss = 0.90736617, grad/param norm = 2.3998e-01, time/batch = 15.7120s	
12548/22950 (epoch 27.338), train_loss = 0.91755998, grad/param norm = 2.0326e-01, time/batch = 15.1574s	
12549/22950 (epoch 27.340), train_loss = 0.91920012, grad/param norm = 2.4968e-01, time/batch = 16.4745s	
12550/22950 (epoch 27.342), train_loss = 1.08045321, grad/param norm = 2.3838e-01, time/batch = 16.2075s	
12551/22950 (epoch 27.344), train_loss = 0.89989988, grad/param norm = 2.1323e-01, time/batch = 16.8049s	
12552/22950 (epoch 27.346), train_loss = 1.03324613, grad/param norm = 2.7466e-01, time/batch = 15.9468s	
12553/22950 (epoch 27.349), train_loss = 0.91737324, grad/param norm = 2.1769e-01, time/batch = 16.4070s	
12554/22950 (epoch 27.351), train_loss = 0.93834881, grad/param norm = 2.0929e-01, time/batch = 16.5657s	
12555/22950 (epoch 27.353), train_loss = 1.01994045, grad/param norm = 3.7686e-01, time/batch = 15.9390s	
12556/22950 (epoch 27.355), train_loss = 1.06323217, grad/param norm = 2.8416e-01, time/batch = 16.7147s	
12557/22950 (epoch 27.357), train_loss = 0.93730038, grad/param norm = 2.4303e-01, time/batch = 16.2568s	
12558/22950 (epoch 27.359), train_loss = 0.93900324, grad/param norm = 2.3375e-01, time/batch = 15.9987s	
12559/22950 (epoch 27.362), train_loss = 0.98594830, grad/param norm = 2.2154e-01, time/batch = 15.6223s	
12560/22950 (epoch 27.364), train_loss = 0.92678237, grad/param norm = 2.4819e-01, time/batch = 15.5661s	
12561/22950 (epoch 27.366), train_loss = 0.92758508, grad/param norm = 2.1066e-01, time/batch = 15.6197s	
12562/22950 (epoch 27.368), train_loss = 1.02934647, grad/param norm = 2.5755e-01, time/batch = 15.7141s	
12563/22950 (epoch 27.370), train_loss = 0.91697502, grad/param norm = 2.3030e-01, time/batch = 15.3893s	
12564/22950 (epoch 27.373), train_loss = 0.82818530, grad/param norm = 1.9044e-01, time/batch = 15.5431s	
12565/22950 (epoch 27.375), train_loss = 1.05772997, grad/param norm = 2.5632e-01, time/batch = 15.3768s	
12566/22950 (epoch 27.377), train_loss = 0.86545900, grad/param norm = 2.5669e-01, time/batch = 15.9417s	
12567/22950 (epoch 27.379), train_loss = 0.97039527, grad/param norm = 2.6814e-01, time/batch = 15.4715s	
12568/22950 (epoch 27.381), train_loss = 0.81217053, grad/param norm = 2.0450e-01, time/batch = 15.8518s	
12569/22950 (epoch 27.383), train_loss = 0.93271552, grad/param norm = 2.2965e-01, time/batch = 16.7844s	
12570/22950 (epoch 27.386), train_loss = 0.86910269, grad/param norm = 2.2182e-01, time/batch = 16.5807s	
12571/22950 (epoch 27.388), train_loss = 1.01360890, grad/param norm = 2.7120e-01, time/batch = 16.5818s	
12572/22950 (epoch 27.390), train_loss = 0.81811745, grad/param norm = 2.1225e-01, time/batch = 16.8038s	
12573/22950 (epoch 27.392), train_loss = 0.86985516, grad/param norm = 2.4027e-01, time/batch = 17.3373s	
12574/22950 (epoch 27.394), train_loss = 0.89756793, grad/param norm = 2.2607e-01, time/batch = 17.3476s	
12575/22950 (epoch 27.397), train_loss = 1.06540269, grad/param norm = 2.1731e-01, time/batch = 17.5402s	
12576/22950 (epoch 27.399), train_loss = 1.08218667, grad/param norm = 2.7512e-01, time/batch = 17.1211s	
12577/22950 (epoch 27.401), train_loss = 1.11629111, grad/param norm = 2.8776e-01, time/batch = 16.3900s	
12578/22950 (epoch 27.403), train_loss = 0.92807069, grad/param norm = 3.0014e-01, time/batch = 16.5869s	
12579/22950 (epoch 27.405), train_loss = 1.03830822, grad/param norm = 2.9155e-01, time/batch = 17.0610s	
12580/22950 (epoch 27.407), train_loss = 1.08259947, grad/param norm = 2.2563e-01, time/batch = 16.8542s	
12581/22950 (epoch 27.410), train_loss = 0.91061955, grad/param norm = 2.2080e-01, time/batch = 16.6375s	
12582/22950 (epoch 27.412), train_loss = 0.93495513, grad/param norm = 2.1761e-01, time/batch = 16.3934s	
12583/22950 (epoch 27.414), train_loss = 1.03442005, grad/param norm = 2.3466e-01, time/batch = 16.6772s	
12584/22950 (epoch 27.416), train_loss = 0.98525698, grad/param norm = 2.5512e-01, time/batch = 16.9938s	
12585/22950 (epoch 27.418), train_loss = 0.95762912, grad/param norm = 2.8462e-01, time/batch = 16.8513s	
12586/22950 (epoch 27.420), train_loss = 1.04470489, grad/param norm = 2.7709e-01, time/batch = 16.8696s	
12587/22950 (epoch 27.423), train_loss = 0.89228734, grad/param norm = 2.2480e-01, time/batch = 17.0232s	
12588/22950 (epoch 27.425), train_loss = 0.91762245, grad/param norm = 2.3434e-01, time/batch = 16.8543s	
12589/22950 (epoch 27.427), train_loss = 0.96332456, grad/param norm = 2.5772e-01, time/batch = 16.7819s	
12590/22950 (epoch 27.429), train_loss = 0.92468093, grad/param norm = 2.2146e-01, time/batch = 17.0263s	
12591/22950 (epoch 27.431), train_loss = 1.02363414, grad/param norm = 2.4835e-01, time/batch = 17.1158s	
12592/22950 (epoch 27.434), train_loss = 0.93961864, grad/param norm = 2.0992e-01, time/batch = 17.1042s	
12593/22950 (epoch 27.436), train_loss = 1.00754334, grad/param norm = 2.4207e-01, time/batch = 16.8628s	
12594/22950 (epoch 27.438), train_loss = 0.97583582, grad/param norm = 2.4004e-01, time/batch = 16.8707s	
12595/22950 (epoch 27.440), train_loss = 1.04450623, grad/param norm = 2.4491e-01, time/batch = 16.6425s	
12596/22950 (epoch 27.442), train_loss = 1.09665646, grad/param norm = 2.4609e-01, time/batch = 16.6319s	
12597/22950 (epoch 27.444), train_loss = 1.00633735, grad/param norm = 2.3440e-01, time/batch = 16.6366s	
12598/22950 (epoch 27.447), train_loss = 1.13099039, grad/param norm = 2.6174e-01, time/batch = 16.7545s	
12599/22950 (epoch 27.449), train_loss = 0.85440673, grad/param norm = 2.0173e-01, time/batch = 16.2344s	
12600/22950 (epoch 27.451), train_loss = 0.96473990, grad/param norm = 2.3002e-01, time/batch = 16.3426s	
12601/22950 (epoch 27.453), train_loss = 1.00236108, grad/param norm = 2.1924e-01, time/batch = 16.2703s	
12602/22950 (epoch 27.455), train_loss = 0.90847267, grad/param norm = 2.0799e-01, time/batch = 16.0158s	
12603/22950 (epoch 27.458), train_loss = 0.99393496, grad/param norm = 2.4165e-01, time/batch = 15.9296s	
12604/22950 (epoch 27.460), train_loss = 1.01174910, grad/param norm = 2.1392e-01, time/batch = 16.0223s	
12605/22950 (epoch 27.462), train_loss = 0.98200184, grad/param norm = 2.5515e-01, time/batch = 25.9766s	
12606/22950 (epoch 27.464), train_loss = 0.93155355, grad/param norm = 2.4851e-01, time/batch = 18.6739s	
12607/22950 (epoch 27.466), train_loss = 1.02719221, grad/param norm = 2.3315e-01, time/batch = 16.5429s	
12608/22950 (epoch 27.468), train_loss = 1.05775410, grad/param norm = 2.5813e-01, time/batch = 16.1614s	
12609/22950 (epoch 27.471), train_loss = 1.01579351, grad/param norm = 2.7099e-01, time/batch = 16.5691s	
12610/22950 (epoch 27.473), train_loss = 1.00326721, grad/param norm = 2.2543e-01, time/batch = 15.9489s	
12611/22950 (epoch 27.475), train_loss = 1.16622902, grad/param norm = 2.4473e-01, time/batch = 15.5481s	
12612/22950 (epoch 27.477), train_loss = 0.95818313, grad/param norm = 2.4481e-01, time/batch = 16.0287s	
12613/22950 (epoch 27.479), train_loss = 0.85568219, grad/param norm = 2.0696e-01, time/batch = 16.4054s	
12614/22950 (epoch 27.481), train_loss = 1.03757390, grad/param norm = 2.6347e-01, time/batch = 15.7117s	
12615/22950 (epoch 27.484), train_loss = 0.99102101, grad/param norm = 2.4942e-01, time/batch = 15.6279s	
12616/22950 (epoch 27.486), train_loss = 0.82856591, grad/param norm = 2.2270e-01, time/batch = 15.8745s	
12617/22950 (epoch 27.488), train_loss = 0.90085144, grad/param norm = 2.5239e-01, time/batch = 15.3026s	
12618/22950 (epoch 27.490), train_loss = 0.84728870, grad/param norm = 2.3757e-01, time/batch = 15.5573s	
12619/22950 (epoch 27.492), train_loss = 0.91199837, grad/param norm = 2.2553e-01, time/batch = 16.0242s	
12620/22950 (epoch 27.495), train_loss = 0.88960157, grad/param norm = 2.1816e-01, time/batch = 16.1007s	
12621/22950 (epoch 27.497), train_loss = 1.01144672, grad/param norm = 2.7207e-01, time/batch = 15.8796s	
12622/22950 (epoch 27.499), train_loss = 1.08963767, grad/param norm = 2.2406e-01, time/batch = 15.4826s	
12623/22950 (epoch 27.501), train_loss = 1.02201037, grad/param norm = 2.6446e-01, time/batch = 16.1121s	
12624/22950 (epoch 27.503), train_loss = 1.04570758, grad/param norm = 2.3532e-01, time/batch = 15.4741s	
12625/22950 (epoch 27.505), train_loss = 0.82403036, grad/param norm = 1.9548e-01, time/batch = 15.7964s	
12626/22950 (epoch 27.508), train_loss = 0.99658780, grad/param norm = 2.2150e-01, time/batch = 15.5641s	
12627/22950 (epoch 27.510), train_loss = 0.94659148, grad/param norm = 2.3998e-01, time/batch = 16.0223s	
12628/22950 (epoch 27.512), train_loss = 0.83510615, grad/param norm = 2.2150e-01, time/batch = 15.6956s	
12629/22950 (epoch 27.514), train_loss = 0.92586636, grad/param norm = 1.9586e-01, time/batch = 15.4600s	
12630/22950 (epoch 27.516), train_loss = 0.92295335, grad/param norm = 2.2544e-01, time/batch = 16.0172s	
12631/22950 (epoch 27.519), train_loss = 0.93849442, grad/param norm = 2.2754e-01, time/batch = 16.1145s	
12632/22950 (epoch 27.521), train_loss = 0.94350176, grad/param norm = 2.3043e-01, time/batch = 16.3291s	
12633/22950 (epoch 27.523), train_loss = 0.77568872, grad/param norm = 2.1409e-01, time/batch = 16.3865s	
12634/22950 (epoch 27.525), train_loss = 0.87237550, grad/param norm = 2.0566e-01, time/batch = 16.1078s	
12635/22950 (epoch 27.527), train_loss = 0.82972797, grad/param norm = 2.3528e-01, time/batch = 15.8042s	
12636/22950 (epoch 27.529), train_loss = 0.96551018, grad/param norm = 2.4307e-01, time/batch = 15.5700s	
12637/22950 (epoch 27.532), train_loss = 0.90845754, grad/param norm = 2.1074e-01, time/batch = 15.4803s	
12638/22950 (epoch 27.534), train_loss = 0.99116496, grad/param norm = 2.3781e-01, time/batch = 15.8571s	
12639/22950 (epoch 27.536), train_loss = 0.99326326, grad/param norm = 2.6172e-01, time/batch = 15.4845s	
12640/22950 (epoch 27.538), train_loss = 0.98669468, grad/param norm = 2.6032e-01, time/batch = 15.7104s	
12641/22950 (epoch 27.540), train_loss = 1.01359506, grad/param norm = 2.5841e-01, time/batch = 15.4864s	
12642/22950 (epoch 27.542), train_loss = 1.10024220, grad/param norm = 2.5069e-01, time/batch = 16.0379s	
12643/22950 (epoch 27.545), train_loss = 0.91767816, grad/param norm = 2.1657e-01, time/batch = 15.6409s	
12644/22950 (epoch 27.547), train_loss = 0.93989458, grad/param norm = 2.2411e-01, time/batch = 15.7776s	
12645/22950 (epoch 27.549), train_loss = 0.86951490, grad/param norm = 2.1381e-01, time/batch = 15.2233s	
12646/22950 (epoch 27.551), train_loss = 0.92253296, grad/param norm = 2.3885e-01, time/batch = 15.9501s	
12647/22950 (epoch 27.553), train_loss = 0.90243996, grad/param norm = 2.5486e-01, time/batch = 16.2739s	
12648/22950 (epoch 27.556), train_loss = 0.96561014, grad/param norm = 2.0341e-01, time/batch = 16.4522s	
12649/22950 (epoch 27.558), train_loss = 0.81170110, grad/param norm = 2.2687e-01, time/batch = 16.3713s	
12650/22950 (epoch 27.560), train_loss = 0.92314542, grad/param norm = 2.1429e-01, time/batch = 16.8884s	
12651/22950 (epoch 27.562), train_loss = 0.86865429, grad/param norm = 2.2815e-01, time/batch = 16.6324s	
12652/22950 (epoch 27.564), train_loss = 0.99955138, grad/param norm = 2.7369e-01, time/batch = 16.9190s	
12653/22950 (epoch 27.566), train_loss = 0.96875473, grad/param norm = 2.3231e-01, time/batch = 16.7473s	
12654/22950 (epoch 27.569), train_loss = 0.95513300, grad/param norm = 2.4564e-01, time/batch = 16.4119s	
12655/22950 (epoch 27.571), train_loss = 0.91252850, grad/param norm = 2.3548e-01, time/batch = 16.8129s	
12656/22950 (epoch 27.573), train_loss = 0.94503614, grad/param norm = 2.5493e-01, time/batch = 16.2789s	
12657/22950 (epoch 27.575), train_loss = 1.05783745, grad/param norm = 2.6905e-01, time/batch = 15.7173s	
12658/22950 (epoch 27.577), train_loss = 0.96038719, grad/param norm = 2.4084e-01, time/batch = 15.6325s	
12659/22950 (epoch 27.580), train_loss = 1.03371822, grad/param norm = 2.9504e-01, time/batch = 15.6296s	
12660/22950 (epoch 27.582), train_loss = 1.11229805, grad/param norm = 2.4500e-01, time/batch = 16.5721s	
12661/22950 (epoch 27.584), train_loss = 0.81491818, grad/param norm = 2.3340e-01, time/batch = 15.9603s	
12662/22950 (epoch 27.586), train_loss = 0.87252199, grad/param norm = 2.5051e-01, time/batch = 15.8049s	
12663/22950 (epoch 27.588), train_loss = 1.09045499, grad/param norm = 2.4640e-01, time/batch = 15.5668s	
12664/22950 (epoch 27.590), train_loss = 0.97467264, grad/param norm = 2.3726e-01, time/batch = 15.8808s	
12665/22950 (epoch 27.593), train_loss = 0.93070351, grad/param norm = 2.3502e-01, time/batch = 15.4052s	
12666/22950 (epoch 27.595), train_loss = 0.83418942, grad/param norm = 2.3456e-01, time/batch = 15.7821s	
12667/22950 (epoch 27.597), train_loss = 1.02623355, grad/param norm = 2.4206e-01, time/batch = 15.3899s	
12668/22950 (epoch 27.599), train_loss = 0.97316155, grad/param norm = 2.6381e-01, time/batch = 16.4122s	
12669/22950 (epoch 27.601), train_loss = 0.98508686, grad/param norm = 2.3187e-01, time/batch = 16.3415s	
12670/22950 (epoch 27.603), train_loss = 1.07883896, grad/param norm = 2.3988e-01, time/batch = 15.7271s	
12671/22950 (epoch 27.606), train_loss = 0.95340433, grad/param norm = 2.4020e-01, time/batch = 15.9534s	
12672/22950 (epoch 27.608), train_loss = 0.99472497, grad/param norm = 2.5900e-01, time/batch = 16.8210s	
12673/22950 (epoch 27.610), train_loss = 0.95234735, grad/param norm = 2.4277e-01, time/batch = 16.1028s	
12674/22950 (epoch 27.612), train_loss = 0.94498319, grad/param norm = 2.2848e-01, time/batch = 16.1850s	
12675/22950 (epoch 27.614), train_loss = 1.06828044, grad/param norm = 2.6904e-01, time/batch = 17.1627s	
12676/22950 (epoch 27.617), train_loss = 0.94354658, grad/param norm = 2.2082e-01, time/batch = 17.6369s	
12677/22950 (epoch 27.619), train_loss = 0.91128948, grad/param norm = 2.2012e-01, time/batch = 17.4611s	
12678/22950 (epoch 27.621), train_loss = 1.04336628, grad/param norm = 2.3280e-01, time/batch = 18.4503s	
12679/22950 (epoch 27.623), train_loss = 1.01839040, grad/param norm = 2.2880e-01, time/batch = 15.8810s	
12680/22950 (epoch 27.625), train_loss = 0.92996828, grad/param norm = 2.1318e-01, time/batch = 17.1117s	
12681/22950 (epoch 27.627), train_loss = 0.93184650, grad/param norm = 2.4420e-01, time/batch = 17.8012s	
12682/22950 (epoch 27.630), train_loss = 0.82924600, grad/param norm = 1.9780e-01, time/batch = 16.5703s	
12683/22950 (epoch 27.632), train_loss = 0.90316893, grad/param norm = 2.5046e-01, time/batch = 16.5129s	
12684/22950 (epoch 27.634), train_loss = 0.95868783, grad/param norm = 2.1290e-01, time/batch = 17.7674s	
12685/22950 (epoch 27.636), train_loss = 0.96344367, grad/param norm = 2.3209e-01, time/batch = 18.6192s	
12686/22950 (epoch 27.638), train_loss = 0.88994808, grad/param norm = 2.2908e-01, time/batch = 16.4480s	
12687/22950 (epoch 27.641), train_loss = 0.92439025, grad/param norm = 2.0954e-01, time/batch = 16.2518s	
12688/22950 (epoch 27.643), train_loss = 1.01798047, grad/param norm = 2.6811e-01, time/batch = 16.2214s	
12689/22950 (epoch 27.645), train_loss = 0.90319541, grad/param norm = 2.1440e-01, time/batch = 16.2046s	
12690/22950 (epoch 27.647), train_loss = 0.92209193, grad/param norm = 2.4033e-01, time/batch = 16.5153s	
12691/22950 (epoch 27.649), train_loss = 0.90795133, grad/param norm = 2.1247e-01, time/batch = 16.9918s	
12692/22950 (epoch 27.651), train_loss = 1.00754264, grad/param norm = 2.4397e-01, time/batch = 18.2793s	
12693/22950 (epoch 27.654), train_loss = 0.80293531, grad/param norm = 2.0221e-01, time/batch = 16.3073s	
12694/22950 (epoch 27.656), train_loss = 1.00371319, grad/param norm = 2.7144e-01, time/batch = 16.5548s	
12695/22950 (epoch 27.658), train_loss = 0.85224103, grad/param norm = 2.2641e-01, time/batch = 16.2228s	
12696/22950 (epoch 27.660), train_loss = 0.77055145, grad/param norm = 2.3127e-01, time/batch = 14.1740s	
12697/22950 (epoch 27.662), train_loss = 0.77500190, grad/param norm = 2.0320e-01, time/batch = 0.7486s	
12698/22950 (epoch 27.664), train_loss = 0.93204595, grad/param norm = 2.3199e-01, time/batch = 0.7309s	
12699/22950 (epoch 27.667), train_loss = 0.94522514, grad/param norm = 2.5737e-01, time/batch = 0.7388s	
12700/22950 (epoch 27.669), train_loss = 0.95675960, grad/param norm = 2.5580e-01, time/batch = 0.7317s	
12701/22950 (epoch 27.671), train_loss = 0.94401651, grad/param norm = 2.2152e-01, time/batch = 0.7316s	
12702/22950 (epoch 27.673), train_loss = 0.88453527, grad/param norm = 2.4881e-01, time/batch = 0.7201s	
12703/22950 (epoch 27.675), train_loss = 0.97310125, grad/param norm = 2.5690e-01, time/batch = 0.8856s	
12704/22950 (epoch 27.678), train_loss = 0.94992792, grad/param norm = 2.5059e-01, time/batch = 1.0474s	
12705/22950 (epoch 27.680), train_loss = 0.95327027, grad/param norm = 2.2859e-01, time/batch = 1.0351s	
12706/22950 (epoch 27.682), train_loss = 0.91537770, grad/param norm = 2.4450e-01, time/batch = 1.0378s	
12707/22950 (epoch 27.684), train_loss = 1.02673258, grad/param norm = 2.4949e-01, time/batch = 1.0254s	
12708/22950 (epoch 27.686), train_loss = 1.03514059, grad/param norm = 2.4110e-01, time/batch = 1.5538s	
12709/22950 (epoch 27.688), train_loss = 0.96706150, grad/param norm = 2.3792e-01, time/batch = 1.9036s	
12710/22950 (epoch 27.691), train_loss = 0.93401305, grad/param norm = 2.3166e-01, time/batch = 1.9194s	
12711/22950 (epoch 27.693), train_loss = 0.87198926, grad/param norm = 2.4686e-01, time/batch = 15.6985s	
12712/22950 (epoch 27.695), train_loss = 1.06966939, grad/param norm = 2.7268e-01, time/batch = 15.9339s	
12713/22950 (epoch 27.697), train_loss = 0.99724961, grad/param norm = 2.6106e-01, time/batch = 16.4254s	
12714/22950 (epoch 27.699), train_loss = 0.99142174, grad/param norm = 2.2115e-01, time/batch = 16.8378s	
12715/22950 (epoch 27.702), train_loss = 1.01776572, grad/param norm = 2.4507e-01, time/batch = 16.8544s	
12716/22950 (epoch 27.704), train_loss = 1.07064250, grad/param norm = 2.4511e-01, time/batch = 16.7163s	
12717/22950 (epoch 27.706), train_loss = 1.04477685, grad/param norm = 2.6443e-01, time/batch = 16.6061s	
12718/22950 (epoch 27.708), train_loss = 0.84328936, grad/param norm = 2.2652e-01, time/batch = 16.0594s	
12719/22950 (epoch 27.710), train_loss = 0.96481851, grad/param norm = 2.3107e-01, time/batch = 15.4005s	
12720/22950 (epoch 27.712), train_loss = 1.07670100, grad/param norm = 2.7168e-01, time/batch = 15.4005s	
12721/22950 (epoch 27.715), train_loss = 0.96564297, grad/param norm = 2.6018e-01, time/batch = 15.6570s	
12722/22950 (epoch 27.717), train_loss = 0.98806491, grad/param norm = 2.1169e-01, time/batch = 15.6432s	
12723/22950 (epoch 27.719), train_loss = 0.92302785, grad/param norm = 2.5724e-01, time/batch = 16.3376s	
12724/22950 (epoch 27.721), train_loss = 0.99333339, grad/param norm = 2.2365e-01, time/batch = 16.1002s	
12725/22950 (epoch 27.723), train_loss = 0.94823738, grad/param norm = 2.1894e-01, time/batch = 15.9484s	
12726/22950 (epoch 27.725), train_loss = 1.00483242, grad/param norm = 2.6060e-01, time/batch = 15.7787s	
12727/22950 (epoch 27.728), train_loss = 0.93170846, grad/param norm = 2.7356e-01, time/batch = 15.2357s	
12728/22950 (epoch 27.730), train_loss = 0.93303614, grad/param norm = 2.1615e-01, time/batch = 15.7057s	
12729/22950 (epoch 27.732), train_loss = 1.00432903, grad/param norm = 2.2374e-01, time/batch = 15.7168s	
12730/22950 (epoch 27.734), train_loss = 0.94631314, grad/param norm = 2.4806e-01, time/batch = 15.3039s	
12731/22950 (epoch 27.736), train_loss = 0.97098572, grad/param norm = 2.3391e-01, time/batch = 16.3929s	
12732/22950 (epoch 27.739), train_loss = 1.02403681, grad/param norm = 2.5568e-01, time/batch = 16.4280s	
12733/22950 (epoch 27.741), train_loss = 1.03361331, grad/param norm = 2.8918e-01, time/batch = 16.7591s	
12734/22950 (epoch 27.743), train_loss = 1.09258368, grad/param norm = 2.4855e-01, time/batch = 16.1345s	
12735/22950 (epoch 27.745), train_loss = 1.19890191, grad/param norm = 2.7452e-01, time/batch = 16.1056s	
12736/22950 (epoch 27.747), train_loss = 0.97486667, grad/param norm = 2.3382e-01, time/batch = 16.3928s	
12737/22950 (epoch 27.749), train_loss = 0.90013181, grad/param norm = 2.6926e-01, time/batch = 15.4503s	
12738/22950 (epoch 27.752), train_loss = 1.13639761, grad/param norm = 2.5631e-01, time/batch = 15.2352s	
12739/22950 (epoch 27.754), train_loss = 1.04112931, grad/param norm = 2.5242e-01, time/batch = 15.5281s	
12740/22950 (epoch 27.756), train_loss = 0.89886459, grad/param norm = 2.2420e-01, time/batch = 15.7071s	
12741/22950 (epoch 27.758), train_loss = 0.95490864, grad/param norm = 2.0883e-01, time/batch = 16.2927s	
12742/22950 (epoch 27.760), train_loss = 0.99458746, grad/param norm = 2.3797e-01, time/batch = 16.0425s	
12743/22950 (epoch 27.763), train_loss = 1.02694441, grad/param norm = 2.3259e-01, time/batch = 16.7381s	
12744/22950 (epoch 27.765), train_loss = 0.97065563, grad/param norm = 2.4667e-01, time/batch = 17.0586s	
12745/22950 (epoch 27.767), train_loss = 1.17601379, grad/param norm = 2.6564e-01, time/batch = 16.6921s	
12746/22950 (epoch 27.769), train_loss = 1.02684722, grad/param norm = 2.4179e-01, time/batch = 16.4586s	
12747/22950 (epoch 27.771), train_loss = 0.81783012, grad/param norm = 2.2084e-01, time/batch = 16.7924s	
12748/22950 (epoch 27.773), train_loss = 0.75127872, grad/param norm = 2.1086e-01, time/batch = 16.5494s	
12749/22950 (epoch 27.776), train_loss = 0.89270284, grad/param norm = 2.2518e-01, time/batch = 16.5483s	
12750/22950 (epoch 27.778), train_loss = 0.87291745, grad/param norm = 2.1160e-01, time/batch = 16.6655s	
12751/22950 (epoch 27.780), train_loss = 0.95705041, grad/param norm = 2.1019e-01, time/batch = 16.8906s	
12752/22950 (epoch 27.782), train_loss = 1.02025458, grad/param norm = 2.3314e-01, time/batch = 16.4474s	
12753/22950 (epoch 27.784), train_loss = 0.90706436, grad/param norm = 2.3320e-01, time/batch = 16.3464s	
12754/22950 (epoch 27.786), train_loss = 0.95976162, grad/param norm = 2.2828e-01, time/batch = 15.7221s	
12755/22950 (epoch 27.789), train_loss = 0.81674229, grad/param norm = 2.0438e-01, time/batch = 15.2408s	
12756/22950 (epoch 27.791), train_loss = 0.88348539, grad/param norm = 2.3555e-01, time/batch = 16.2723s	
12757/22950 (epoch 27.793), train_loss = 1.08255116, grad/param norm = 2.5417e-01, time/batch = 16.3615s	
12758/22950 (epoch 27.795), train_loss = 0.92672005, grad/param norm = 2.1082e-01, time/batch = 16.1222s	
12759/22950 (epoch 27.797), train_loss = 1.09033422, grad/param norm = 2.3956e-01, time/batch = 15.6501s	
12760/22950 (epoch 27.800), train_loss = 0.86243472, grad/param norm = 2.0667e-01, time/batch = 15.8037s	
12761/22950 (epoch 27.802), train_loss = 0.91142624, grad/param norm = 2.4423e-01, time/batch = 16.3728s	
12762/22950 (epoch 27.804), train_loss = 0.90742337, grad/param norm = 2.1225e-01, time/batch = 16.6315s	
12763/22950 (epoch 27.806), train_loss = 0.83898143, grad/param norm = 2.1849e-01, time/batch = 16.0544s	
12764/22950 (epoch 27.808), train_loss = 0.93843454, grad/param norm = 2.1598e-01, time/batch = 16.1940s	
12765/22950 (epoch 27.810), train_loss = 0.90928518, grad/param norm = 2.2432e-01, time/batch = 16.7983s	
12766/22950 (epoch 27.813), train_loss = 0.77280173, grad/param norm = 2.1013e-01, time/batch = 16.1946s	
12767/22950 (epoch 27.815), train_loss = 0.78323717, grad/param norm = 2.2011e-01, time/batch = 16.6445s	
12768/22950 (epoch 27.817), train_loss = 0.86921054, grad/param norm = 2.1182e-01, time/batch = 16.2479s	
12769/22950 (epoch 27.819), train_loss = 0.93128720, grad/param norm = 2.1392e-01, time/batch = 16.5087s	
12770/22950 (epoch 27.821), train_loss = 0.89070423, grad/param norm = 2.4244e-01, time/batch = 16.2735s	
12771/22950 (epoch 27.824), train_loss = 0.96421837, grad/param norm = 2.3030e-01, time/batch = 15.8086s	
12772/22950 (epoch 27.826), train_loss = 1.00375207, grad/param norm = 2.5075e-01, time/batch = 16.1124s	
12773/22950 (epoch 27.828), train_loss = 0.92024631, grad/param norm = 2.2636e-01, time/batch = 16.1246s	
12774/22950 (epoch 27.830), train_loss = 0.90719990, grad/param norm = 2.4227e-01, time/batch = 16.1945s	
12775/22950 (epoch 27.832), train_loss = 0.95866743, grad/param norm = 2.4710e-01, time/batch = 15.7299s	
12776/22950 (epoch 27.834), train_loss = 0.79327289, grad/param norm = 2.2495e-01, time/batch = 16.1233s	
12777/22950 (epoch 27.837), train_loss = 0.96845719, grad/param norm = 2.5133e-01, time/batch = 15.8046s	
12778/22950 (epoch 27.839), train_loss = 0.80795294, grad/param norm = 2.2566e-01, time/batch = 15.9661s	
12779/22950 (epoch 27.841), train_loss = 0.88456285, grad/param norm = 2.1123e-01, time/batch = 15.8850s	
12780/22950 (epoch 27.843), train_loss = 0.89365065, grad/param norm = 2.3769e-01, time/batch = 16.1983s	
12781/22950 (epoch 27.845), train_loss = 0.95268996, grad/param norm = 2.4724e-01, time/batch = 15.8789s	
12782/22950 (epoch 27.847), train_loss = 0.98242304, grad/param norm = 2.2347e-01, time/batch = 15.8933s	
12783/22950 (epoch 27.850), train_loss = 1.01510637, grad/param norm = 2.6374e-01, time/batch = 16.2828s	
12784/22950 (epoch 27.852), train_loss = 1.00254092, grad/param norm = 2.3497e-01, time/batch = 16.4392s	
12785/22950 (epoch 27.854), train_loss = 0.94058439, grad/param norm = 2.2743e-01, time/batch = 16.8324s	
12786/22950 (epoch 27.856), train_loss = 1.10733638, grad/param norm = 3.0134e-01, time/batch = 16.5622s	
12787/22950 (epoch 27.858), train_loss = 1.00794734, grad/param norm = 2.4127e-01, time/batch = 16.2606s	
12788/22950 (epoch 27.861), train_loss = 1.01193434, grad/param norm = 2.3543e-01, time/batch = 15.8793s	
12789/22950 (epoch 27.863), train_loss = 1.06267198, grad/param norm = 2.7253e-01, time/batch = 16.4885s	
12790/22950 (epoch 27.865), train_loss = 1.08322942, grad/param norm = 2.6160e-01, time/batch = 15.4767s	
12791/22950 (epoch 27.867), train_loss = 0.97309010, grad/param norm = 2.1524e-01, time/batch = 16.2778s	
12792/22950 (epoch 27.869), train_loss = 1.09443363, grad/param norm = 2.4876e-01, time/batch = 15.7290s	
12793/22950 (epoch 27.871), train_loss = 0.97610950, grad/param norm = 2.2750e-01, time/batch = 15.8043s	
12794/22950 (epoch 27.874), train_loss = 0.98142502, grad/param norm = 2.1905e-01, time/batch = 15.8808s	
12795/22950 (epoch 27.876), train_loss = 1.02982149, grad/param norm = 2.5399e-01, time/batch = 16.2835s	
12796/22950 (epoch 27.878), train_loss = 0.92655263, grad/param norm = 2.7287e-01, time/batch = 16.2123s	
12797/22950 (epoch 27.880), train_loss = 1.14901249, grad/param norm = 2.7679e-01, time/batch = 16.1744s	
12798/22950 (epoch 27.882), train_loss = 0.86509636, grad/param norm = 2.2313e-01, time/batch = 16.0265s	
12799/22950 (epoch 27.885), train_loss = 0.98664286, grad/param norm = 2.3816e-01, time/batch = 16.0592s	
12800/22950 (epoch 27.887), train_loss = 0.95894083, grad/param norm = 2.3548e-01, time/batch = 16.5370s	
12801/22950 (epoch 27.889), train_loss = 0.99548113, grad/param norm = 2.3629e-01, time/batch = 16.2911s	
12802/22950 (epoch 27.891), train_loss = 0.92235372, grad/param norm = 2.3775e-01, time/batch = 16.2693s	
12803/22950 (epoch 27.893), train_loss = 1.01932256, grad/param norm = 2.2138e-01, time/batch = 16.1325s	
12804/22950 (epoch 27.895), train_loss = 1.10590212, grad/param norm = 2.7328e-01, time/batch = 16.1148s	
12805/22950 (epoch 27.898), train_loss = 0.98557244, grad/param norm = 2.3853e-01, time/batch = 16.5723s	
12806/22950 (epoch 27.900), train_loss = 0.94366931, grad/param norm = 2.3162e-01, time/batch = 16.7367s	
12807/22950 (epoch 27.902), train_loss = 0.98667319, grad/param norm = 2.2157e-01, time/batch = 16.5493s	
12808/22950 (epoch 27.904), train_loss = 0.97145240, grad/param norm = 2.3893e-01, time/batch = 16.0337s	
12809/22950 (epoch 27.906), train_loss = 1.00189735, grad/param norm = 2.3976e-01, time/batch = 16.3452s	
12810/22950 (epoch 27.908), train_loss = 0.85463938, grad/param norm = 2.2272e-01, time/batch = 16.2797s	
12811/22950 (epoch 27.911), train_loss = 0.83422552, grad/param norm = 2.0278e-01, time/batch = 16.0475s	
12812/22950 (epoch 27.913), train_loss = 0.91104992, grad/param norm = 2.3054e-01, time/batch = 15.8948s	
12813/22950 (epoch 27.915), train_loss = 1.09072911, grad/param norm = 2.3989e-01, time/batch = 16.3721s	
12814/22950 (epoch 27.917), train_loss = 0.84390067, grad/param norm = 2.1417e-01, time/batch = 16.6345s	
12815/22950 (epoch 27.919), train_loss = 0.95434846, grad/param norm = 2.2566e-01, time/batch = 18.3027s	
12816/22950 (epoch 27.922), train_loss = 0.97055799, grad/param norm = 2.3907e-01, time/batch = 18.0276s	
12817/22950 (epoch 27.924), train_loss = 0.99445212, grad/param norm = 2.3802e-01, time/batch = 17.8086s	
12818/22950 (epoch 27.926), train_loss = 0.81019183, grad/param norm = 2.3522e-01, time/batch = 16.4439s	
12819/22950 (epoch 27.928), train_loss = 0.83360536, grad/param norm = 2.1638e-01, time/batch = 17.2671s	
12820/22950 (epoch 27.930), train_loss = 0.84151911, grad/param norm = 2.4837e-01, time/batch = 16.3299s	
12821/22950 (epoch 27.932), train_loss = 0.79083153, grad/param norm = 1.9071e-01, time/batch = 17.7970s	
12822/22950 (epoch 27.935), train_loss = 0.95475309, grad/param norm = 2.3533e-01, time/batch = 17.0371s	
12823/22950 (epoch 27.937), train_loss = 0.95280842, grad/param norm = 2.4819e-01, time/batch = 16.8601s	
12824/22950 (epoch 27.939), train_loss = 0.87605202, grad/param norm = 2.2205e-01, time/batch = 15.9386s	
12825/22950 (epoch 27.941), train_loss = 0.90397886, grad/param norm = 2.5523e-01, time/batch = 16.0009s	
12826/22950 (epoch 27.943), train_loss = 0.96628902, grad/param norm = 2.3670e-01, time/batch = 15.9705s	
12827/22950 (epoch 27.946), train_loss = 0.80422607, grad/param norm = 2.1708e-01, time/batch = 16.0775s	
12828/22950 (epoch 27.948), train_loss = 1.01975483, grad/param norm = 2.3062e-01, time/batch = 16.3444s	
12829/22950 (epoch 27.950), train_loss = 0.94693543, grad/param norm = 2.5728e-01, time/batch = 16.4278s	
12830/22950 (epoch 27.952), train_loss = 1.00377213, grad/param norm = 2.4687e-01, time/batch = 18.8590s	
12831/22950 (epoch 27.954), train_loss = 0.98684266, grad/param norm = 2.5729e-01, time/batch = 16.4185s	
12832/22950 (epoch 27.956), train_loss = 0.89390709, grad/param norm = 2.4944e-01, time/batch = 19.2728s	
12833/22950 (epoch 27.959), train_loss = 0.87909297, grad/param norm = 2.9167e-01, time/batch = 18.8097s	
12834/22950 (epoch 27.961), train_loss = 0.95359723, grad/param norm = 2.3472e-01, time/batch = 17.6083s	
12835/22950 (epoch 27.963), train_loss = 0.97229724, grad/param norm = 2.4343e-01, time/batch = 15.6867s	
12836/22950 (epoch 27.965), train_loss = 1.05198397, grad/param norm = 2.4057e-01, time/batch = 19.2926s	
12837/22950 (epoch 27.967), train_loss = 0.94433185, grad/param norm = 2.4262e-01, time/batch = 26.9934s	
12838/22950 (epoch 27.969), train_loss = 0.84206734, grad/param norm = 2.2284e-01, time/batch = 22.5749s	
12839/22950 (epoch 27.972), train_loss = 0.92875917, grad/param norm = 2.0651e-01, time/batch = 18.9551s	
12840/22950 (epoch 27.974), train_loss = 0.90729416, grad/param norm = 2.3568e-01, time/batch = 15.9501s	
12841/22950 (epoch 27.976), train_loss = 0.89368640, grad/param norm = 2.0385e-01, time/batch = 16.9645s	
12842/22950 (epoch 27.978), train_loss = 0.87548162, grad/param norm = 2.3412e-01, time/batch = 18.7083s	
12843/22950 (epoch 27.980), train_loss = 0.89674441, grad/param norm = 2.3716e-01, time/batch = 17.4541s	
12844/22950 (epoch 27.983), train_loss = 0.98826716, grad/param norm = 2.2057e-01, time/batch = 18.3684s	
12845/22950 (epoch 27.985), train_loss = 0.82027513, grad/param norm = 2.0582e-01, time/batch = 17.7151s	
12846/22950 (epoch 27.987), train_loss = 0.86988784, grad/param norm = 2.0886e-01, time/batch = 16.9314s	
12847/22950 (epoch 27.989), train_loss = 0.94616287, grad/param norm = 2.3019e-01, time/batch = 17.1543s	
12848/22950 (epoch 27.991), train_loss = 0.79954431, grad/param norm = 2.2268e-01, time/batch = 17.8495s	
12849/22950 (epoch 27.993), train_loss = 0.97289210, grad/param norm = 2.3254e-01, time/batch = 16.0041s	
12850/22950 (epoch 27.996), train_loss = 0.93438626, grad/param norm = 2.2933e-01, time/batch = 15.7813s	
12851/22950 (epoch 27.998), train_loss = 0.84366416, grad/param norm = 2.1405e-01, time/batch = 19.1015s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
12852/22950 (epoch 28.000), train_loss = 0.78288452, grad/param norm = 2.0495e-01, time/batch = 17.6968s	
12853/22950 (epoch 28.002), train_loss = 1.09360749, grad/param norm = 2.4290e-01, time/batch = 17.8740s	
12854/22950 (epoch 28.004), train_loss = 0.97565074, grad/param norm = 2.2821e-01, time/batch = 17.5343s	
12855/22950 (epoch 28.007), train_loss = 0.94221297, grad/param norm = 2.3632e-01, time/batch = 18.4556s	
12856/22950 (epoch 28.009), train_loss = 1.07217529, grad/param norm = 2.7746e-01, time/batch = 18.8024s	
12857/22950 (epoch 28.011), train_loss = 0.82040153, grad/param norm = 2.5302e-01, time/batch = 17.7041s	
12858/22950 (epoch 28.013), train_loss = 0.92461545, grad/param norm = 2.3615e-01, time/batch = 17.2731s	
12859/22950 (epoch 28.015), train_loss = 0.97476320, grad/param norm = 2.8922e-01, time/batch = 16.7845s	
12860/22950 (epoch 28.017), train_loss = 0.96547491, grad/param norm = 2.3818e-01, time/batch = 18.1870s	
12861/22950 (epoch 28.020), train_loss = 0.96895663, grad/param norm = 2.2325e-01, time/batch = 18.5175s	
12862/22950 (epoch 28.022), train_loss = 0.82482869, grad/param norm = 2.5910e-01, time/batch = 19.8566s	
12863/22950 (epoch 28.024), train_loss = 0.92172967, grad/param norm = 2.3685e-01, time/batch = 18.2789s	
12864/22950 (epoch 28.026), train_loss = 0.98323060, grad/param norm = 2.2121e-01, time/batch = 18.1188s	
12865/22950 (epoch 28.028), train_loss = 1.04475316, grad/param norm = 2.2505e-01, time/batch = 19.1338s	
12866/22950 (epoch 28.031), train_loss = 0.90467718, grad/param norm = 2.2114e-01, time/batch = 17.4709s	
12867/22950 (epoch 28.033), train_loss = 1.02806066, grad/param norm = 2.5469e-01, time/batch = 16.4209s	
12868/22950 (epoch 28.035), train_loss = 0.94118137, grad/param norm = 2.2499e-01, time/batch = 16.2977s	
12869/22950 (epoch 28.037), train_loss = 0.94656368, grad/param norm = 2.4051e-01, time/batch = 16.0549s	
12870/22950 (epoch 28.039), train_loss = 0.91802719, grad/param norm = 2.4016e-01, time/batch = 15.9456s	
12871/22950 (epoch 28.041), train_loss = 0.88850671, grad/param norm = 2.6363e-01, time/batch = 18.7154s	
12872/22950 (epoch 28.044), train_loss = 0.98709387, grad/param norm = 2.2431e-01, time/batch = 16.2904s	
12873/22950 (epoch 28.046), train_loss = 0.95743686, grad/param norm = 2.6628e-01, time/batch = 18.3708s	
12874/22950 (epoch 28.048), train_loss = 0.94339974, grad/param norm = 2.3134e-01, time/batch = 16.7287s	
12875/22950 (epoch 28.050), train_loss = 0.90773756, grad/param norm = 3.1037e-01, time/batch = 16.2517s	
12876/22950 (epoch 28.052), train_loss = 0.97998695, grad/param norm = 2.2441e-01, time/batch = 19.7889s	
12877/22950 (epoch 28.054), train_loss = 1.10020526, grad/param norm = 2.5256e-01, time/batch = 16.2246s	
12878/22950 (epoch 28.057), train_loss = 1.00735761, grad/param norm = 2.2775e-01, time/batch = 18.6229s	
12879/22950 (epoch 28.059), train_loss = 1.01772384, grad/param norm = 2.2752e-01, time/batch = 19.6286s	
12880/22950 (epoch 28.061), train_loss = 0.89982646, grad/param norm = 2.4963e-01, time/batch = 17.3816s	
12881/22950 (epoch 28.063), train_loss = 0.97663929, grad/param norm = 2.5807e-01, time/batch = 16.6252s	
12882/22950 (epoch 28.065), train_loss = 0.84371136, grad/param norm = 2.2528e-01, time/batch = 20.1078s	
12883/22950 (epoch 28.068), train_loss = 0.98974177, grad/param norm = 2.4512e-01, time/batch = 18.7770s	
12884/22950 (epoch 28.070), train_loss = 0.84624647, grad/param norm = 2.1578e-01, time/batch = 17.9601s	
12885/22950 (epoch 28.072), train_loss = 1.01738022, grad/param norm = 2.4139e-01, time/batch = 17.7961s	
12886/22950 (epoch 28.074), train_loss = 0.98298637, grad/param norm = 2.5496e-01, time/batch = 16.3893s	
12887/22950 (epoch 28.076), train_loss = 0.98298069, grad/param norm = 2.3827e-01, time/batch = 16.4169s	
12888/22950 (epoch 28.078), train_loss = 1.02759412, grad/param norm = 2.5265e-01, time/batch = 16.1665s	
12889/22950 (epoch 28.081), train_loss = 1.05346432, grad/param norm = 2.3972e-01, time/batch = 17.0967s	
12890/22950 (epoch 28.083), train_loss = 0.95345537, grad/param norm = 2.3872e-01, time/batch = 15.9763s	
12891/22950 (epoch 28.085), train_loss = 0.84121739, grad/param norm = 2.5399e-01, time/batch = 15.9664s	
12892/22950 (epoch 28.087), train_loss = 0.87585814, grad/param norm = 2.3194e-01, time/batch = 18.0339s	
12893/22950 (epoch 28.089), train_loss = 0.98151457, grad/param norm = 2.3967e-01, time/batch = 16.7860s	
12894/22950 (epoch 28.092), train_loss = 0.88958625, grad/param norm = 2.2972e-01, time/batch = 18.5221s	
12895/22950 (epoch 28.094), train_loss = 0.86939089, grad/param norm = 2.4642e-01, time/batch = 19.9581s	
12896/22950 (epoch 28.096), train_loss = 1.03928415, grad/param norm = 2.3503e-01, time/batch = 17.4465s	
12897/22950 (epoch 28.098), train_loss = 0.99707312, grad/param norm = 2.3836e-01, time/batch = 18.6111s	
12898/22950 (epoch 28.100), train_loss = 0.91494814, grad/param norm = 2.3084e-01, time/batch = 19.2666s	
12899/22950 (epoch 28.102), train_loss = 0.94631767, grad/param norm = 2.2254e-01, time/batch = 18.7554s	
12900/22950 (epoch 28.105), train_loss = 0.79107407, grad/param norm = 2.0455e-01, time/batch = 18.4426s	
12901/22950 (epoch 28.107), train_loss = 0.89673666, grad/param norm = 2.3651e-01, time/batch = 18.9483s	
12902/22950 (epoch 28.109), train_loss = 0.90552394, grad/param norm = 2.2820e-01, time/batch = 19.3670s	
12903/22950 (epoch 28.111), train_loss = 0.80585327, grad/param norm = 2.3170e-01, time/batch = 18.6871s	
12904/22950 (epoch 28.113), train_loss = 0.95971987, grad/param norm = 2.2577e-01, time/batch = 16.6132s	
12905/22950 (epoch 28.115), train_loss = 0.95304991, grad/param norm = 2.3616e-01, time/batch = 18.3808s	
12906/22950 (epoch 28.118), train_loss = 1.06859453, grad/param norm = 2.1686e-01, time/batch = 16.6806s	
12907/22950 (epoch 28.120), train_loss = 0.86874616, grad/param norm = 2.2760e-01, time/batch = 15.9067s	
12908/22950 (epoch 28.122), train_loss = 1.02641209, grad/param norm = 2.5184e-01, time/batch = 16.1530s	
12909/22950 (epoch 28.124), train_loss = 0.81553427, grad/param norm = 1.9690e-01, time/batch = 17.4065s	
12910/22950 (epoch 28.126), train_loss = 0.96018829, grad/param norm = 2.3773e-01, time/batch = 15.9041s	
12911/22950 (epoch 28.129), train_loss = 0.85516640, grad/param norm = 1.9886e-01, time/batch = 15.3722s	
12912/22950 (epoch 28.131), train_loss = 0.92864328, grad/param norm = 2.2729e-01, time/batch = 14.8294s	
12913/22950 (epoch 28.133), train_loss = 0.99190938, grad/param norm = 2.1698e-01, time/batch = 15.3829s	
12914/22950 (epoch 28.135), train_loss = 0.93978728, grad/param norm = 2.0931e-01, time/batch = 14.8356s	
12915/22950 (epoch 28.137), train_loss = 1.04420312, grad/param norm = 2.8531e-01, time/batch = 15.2947s	
12916/22950 (epoch 28.139), train_loss = 0.84835791, grad/param norm = 2.1475e-01, time/batch = 14.9660s	
12917/22950 (epoch 28.142), train_loss = 0.85209495, grad/param norm = 2.1185e-01, time/batch = 15.0762s	
12918/22950 (epoch 28.144), train_loss = 0.91680282, grad/param norm = 2.2531e-01, time/batch = 14.8340s	
12919/22950 (epoch 28.146), train_loss = 0.89442893, grad/param norm = 2.4451e-01, time/batch = 15.3158s	
12920/22950 (epoch 28.148), train_loss = 0.90296594, grad/param norm = 2.7288e-01, time/batch = 14.9849s	
12921/22950 (epoch 28.150), train_loss = 0.95463202, grad/param norm = 2.4207e-01, time/batch = 15.0755s	
12922/22950 (epoch 28.153), train_loss = 0.88294655, grad/param norm = 2.0129e-01, time/batch = 14.8258s	
12923/22950 (epoch 28.155), train_loss = 0.88903220, grad/param norm = 2.0863e-01, time/batch = 15.3933s	
12924/22950 (epoch 28.157), train_loss = 0.91447793, grad/param norm = 2.0178e-01, time/batch = 14.9809s	
12925/22950 (epoch 28.159), train_loss = 0.85445994, grad/param norm = 2.0575e-01, time/batch = 15.0583s	
12926/22950 (epoch 28.161), train_loss = 0.91511833, grad/param norm = 2.2782e-01, time/batch = 14.9771s	
12927/22950 (epoch 28.163), train_loss = 0.83382936, grad/param norm = 3.3581e-01, time/batch = 15.3034s	
12928/22950 (epoch 28.166), train_loss = 1.02520626, grad/param norm = 3.5667e-01, time/batch = 15.2169s	
12929/22950 (epoch 28.168), train_loss = 0.98650668, grad/param norm = 2.5851e-01, time/batch = 14.8332s	
12930/22950 (epoch 28.170), train_loss = 0.90661880, grad/param norm = 2.3613e-01, time/batch = 14.8922s	
12931/22950 (epoch 28.172), train_loss = 0.96371576, grad/param norm = 2.1920e-01, time/batch = 15.1527s	
12932/22950 (epoch 28.174), train_loss = 1.01827061, grad/param norm = 2.3960e-01, time/batch = 14.8317s	
12933/22950 (epoch 28.176), train_loss = 1.02049429, grad/param norm = 2.4951e-01, time/batch = 14.8219s	
12934/22950 (epoch 28.179), train_loss = 1.00415913, grad/param norm = 2.5814e-01, time/batch = 14.9813s	
12935/22950 (epoch 28.181), train_loss = 1.18507517, grad/param norm = 2.7406e-01, time/batch = 15.0695s	
12936/22950 (epoch 28.183), train_loss = 1.01453226, grad/param norm = 2.4228e-01, time/batch = 15.6143s	
12937/22950 (epoch 28.185), train_loss = 0.97579361, grad/param norm = 2.4074e-01, time/batch = 16.4650s	
12938/22950 (epoch 28.187), train_loss = 0.86422473, grad/param norm = 2.3639e-01, time/batch = 16.2372s	
12939/22950 (epoch 28.190), train_loss = 0.78744928, grad/param norm = 2.2729e-01, time/batch = 16.2657s	
12940/22950 (epoch 28.192), train_loss = 0.78104272, grad/param norm = 2.1958e-01, time/batch = 16.0314s	
12941/22950 (epoch 28.194), train_loss = 0.92158895, grad/param norm = 2.5897e-01, time/batch = 15.9741s	
12942/22950 (epoch 28.196), train_loss = 0.72432401, grad/param norm = 2.2663e-01, time/batch = 16.0334s	
12943/22950 (epoch 28.198), train_loss = 1.00599167, grad/param norm = 2.6645e-01, time/batch = 15.5769s	
12944/22950 (epoch 28.200), train_loss = 0.87205887, grad/param norm = 2.1039e-01, time/batch = 15.6151s	
12945/22950 (epoch 28.203), train_loss = 0.82673324, grad/param norm = 2.2653e-01, time/batch = 15.3177s	
12946/22950 (epoch 28.205), train_loss = 0.88902105, grad/param norm = 2.2953e-01, time/batch = 15.7034s	
12947/22950 (epoch 28.207), train_loss = 0.96117255, grad/param norm = 2.4764e-01, time/batch = 15.7839s	
12948/22950 (epoch 28.209), train_loss = 0.92687946, grad/param norm = 2.7146e-01, time/batch = 15.7057s	
12949/22950 (epoch 28.211), train_loss = 0.76759635, grad/param norm = 2.2075e-01, time/batch = 15.4767s	
12950/22950 (epoch 28.214), train_loss = 0.87125518, grad/param norm = 2.2891e-01, time/batch = 16.0227s	
12951/22950 (epoch 28.216), train_loss = 1.00809356, grad/param norm = 2.3650e-01, time/batch = 15.7851s	
12952/22950 (epoch 28.218), train_loss = 0.92238612, grad/param norm = 2.1129e-01, time/batch = 15.1494s	
12953/22950 (epoch 28.220), train_loss = 1.01088304, grad/param norm = 2.3567e-01, time/batch = 15.5352s	
12954/22950 (epoch 28.222), train_loss = 1.03661192, grad/param norm = 2.7676e-01, time/batch = 15.7155s	
12955/22950 (epoch 28.224), train_loss = 0.94133725, grad/param norm = 2.4416e-01, time/batch = 16.0914s	
12956/22950 (epoch 28.227), train_loss = 0.99480812, grad/param norm = 2.2533e-01, time/batch = 16.2426s	
12957/22950 (epoch 28.229), train_loss = 1.02553001, grad/param norm = 2.3391e-01, time/batch = 16.3426s	
12958/22950 (epoch 28.231), train_loss = 0.79872048, grad/param norm = 2.2867e-01, time/batch = 16.5223s	
12959/22950 (epoch 28.233), train_loss = 0.89653158, grad/param norm = 2.1832e-01, time/batch = 15.5597s	
12960/22950 (epoch 28.235), train_loss = 1.07881624, grad/param norm = 2.2882e-01, time/batch = 15.6483s	
12961/22950 (epoch 28.237), train_loss = 0.88699602, grad/param norm = 2.5162e-01, time/batch = 16.4389s	
12962/22950 (epoch 28.240), train_loss = 0.92875783, grad/param norm = 2.2593e-01, time/batch = 15.8066s	
12963/22950 (epoch 28.242), train_loss = 1.05026335, grad/param norm = 2.2165e-01, time/batch = 15.7112s	
12964/22950 (epoch 28.244), train_loss = 1.05157548, grad/param norm = 2.5175e-01, time/batch = 15.9505s	
12965/22950 (epoch 28.246), train_loss = 1.05048159, grad/param norm = 2.3653e-01, time/batch = 16.3628s	
12966/22950 (epoch 28.248), train_loss = 0.98258461, grad/param norm = 2.5209e-01, time/batch = 16.1236s	
12967/22950 (epoch 28.251), train_loss = 0.88543798, grad/param norm = 2.5425e-01, time/batch = 15.7172s	
12968/22950 (epoch 28.253), train_loss = 0.88431351, grad/param norm = 2.3918e-01, time/batch = 16.0455s	
12969/22950 (epoch 28.255), train_loss = 0.96098168, grad/param norm = 2.2480e-01, time/batch = 15.8869s	
12970/22950 (epoch 28.257), train_loss = 1.02864799, grad/param norm = 2.4164e-01, time/batch = 16.0361s	
12971/22950 (epoch 28.259), train_loss = 0.80916639, grad/param norm = 2.1321e-01, time/batch = 16.0442s	
12972/22950 (epoch 28.261), train_loss = 0.88923036, grad/param norm = 2.2226e-01, time/batch = 16.0439s	
12973/22950 (epoch 28.264), train_loss = 0.84294088, grad/param norm = 2.1596e-01, time/batch = 16.1214s	
12974/22950 (epoch 28.266), train_loss = 0.93203859, grad/param norm = 2.5574e-01, time/batch = 15.8033s	
12975/22950 (epoch 28.268), train_loss = 0.95324380, grad/param norm = 2.4480e-01, time/batch = 15.7273s	
12976/22950 (epoch 28.270), train_loss = 0.92816081, grad/param norm = 2.1796e-01, time/batch = 15.9585s	
12977/22950 (epoch 28.272), train_loss = 0.98796432, grad/param norm = 2.6433e-01, time/batch = 16.2084s	
12978/22950 (epoch 28.275), train_loss = 0.87592580, grad/param norm = 2.1643e-01, time/batch = 16.2673s	
12979/22950 (epoch 28.277), train_loss = 0.78705794, grad/param norm = 2.1805e-01, time/batch = 15.7241s	
12980/22950 (epoch 28.279), train_loss = 0.84349473, grad/param norm = 2.4702e-01, time/batch = 16.9560s	
12981/22950 (epoch 28.281), train_loss = 0.88513932, grad/param norm = 2.2815e-01, time/batch = 16.1941s	
12982/22950 (epoch 28.283), train_loss = 0.79792734, grad/param norm = 1.9353e-01, time/batch = 16.1834s	
12983/22950 (epoch 28.285), train_loss = 0.93202489, grad/param norm = 2.1355e-01, time/batch = 16.6195s	
12984/22950 (epoch 28.288), train_loss = 1.03474448, grad/param norm = 2.3465e-01, time/batch = 15.8833s	
12985/22950 (epoch 28.290), train_loss = 0.87402257, grad/param norm = 2.2049e-01, time/batch = 16.2722s	
12986/22950 (epoch 28.292), train_loss = 1.02661694, grad/param norm = 2.4408e-01, time/batch = 16.0538s	
12987/22950 (epoch 28.294), train_loss = 0.93014933, grad/param norm = 2.1946e-01, time/batch = 16.1168s	
12988/22950 (epoch 28.296), train_loss = 0.73403122, grad/param norm = 1.8043e-01, time/batch = 15.8012s	
12989/22950 (epoch 28.298), train_loss = 0.92578302, grad/param norm = 2.1400e-01, time/batch = 15.6484s	
12990/22950 (epoch 28.301), train_loss = 0.96881176, grad/param norm = 2.4275e-01, time/batch = 15.9276s	
12991/22950 (epoch 28.303), train_loss = 0.92985551, grad/param norm = 2.3367e-01, time/batch = 16.2005s	
12992/22950 (epoch 28.305), train_loss = 0.92113525, grad/param norm = 2.4200e-01, time/batch = 16.0179s	
12993/22950 (epoch 28.307), train_loss = 1.05276027, grad/param norm = 2.4022e-01, time/batch = 15.7823s	
12994/22950 (epoch 28.309), train_loss = 0.89070429, grad/param norm = 2.2792e-01, time/batch = 15.7140s	
12995/22950 (epoch 28.312), train_loss = 0.94276420, grad/param norm = 2.3097e-01, time/batch = 16.0548s	
12996/22950 (epoch 28.314), train_loss = 0.94186390, grad/param norm = 2.1593e-01, time/batch = 15.7231s	
12997/22950 (epoch 28.316), train_loss = 0.91194268, grad/param norm = 2.4475e-01, time/batch = 15.8106s	
12998/22950 (epoch 28.318), train_loss = 0.79453092, grad/param norm = 1.9169e-01, time/batch = 16.1819s	
12999/22950 (epoch 28.320), train_loss = 0.84607606, grad/param norm = 2.0518e-01, time/batch = 15.8916s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch28.32_1.9018.t7	
13000/22950 (epoch 28.322), train_loss = 0.87251839, grad/param norm = 2.2257e-01, time/batch = 16.5629s	
13001/22950 (epoch 28.325), train_loss = 1.31385877, grad/param norm = 2.7615e-01, time/batch = 16.2099s	
13002/22950 (epoch 28.327), train_loss = 0.76351099, grad/param norm = 2.1519e-01, time/batch = 16.0442s	
13003/22950 (epoch 28.329), train_loss = 0.87207450, grad/param norm = 2.1530e-01, time/batch = 16.2061s	
13004/22950 (epoch 28.331), train_loss = 0.80685827, grad/param norm = 2.0800e-01, time/batch = 15.8850s	
13005/22950 (epoch 28.333), train_loss = 0.87104651, grad/param norm = 2.2821e-01, time/batch = 15.8080s	
13006/22950 (epoch 28.336), train_loss = 0.91458891, grad/param norm = 2.8321e-01, time/batch = 15.9726s	
13007/22950 (epoch 28.338), train_loss = 0.91244013, grad/param norm = 1.9945e-01, time/batch = 15.9701s	
13008/22950 (epoch 28.340), train_loss = 0.91377984, grad/param norm = 2.5986e-01, time/batch = 15.7994s	
13009/22950 (epoch 28.342), train_loss = 1.07213604, grad/param norm = 2.3540e-01, time/batch = 15.8077s	
13010/22950 (epoch 28.344), train_loss = 0.89112836, grad/param norm = 2.3091e-01, time/batch = 16.4478s	
13011/22950 (epoch 28.346), train_loss = 1.01027555, grad/param norm = 2.4321e-01, time/batch = 16.1234s	
13012/22950 (epoch 28.349), train_loss = 0.90207949, grad/param norm = 2.1575e-01, time/batch = 15.9000s	
13013/22950 (epoch 28.351), train_loss = 0.93089578, grad/param norm = 2.2058e-01, time/batch = 15.7954s	
13014/22950 (epoch 28.353), train_loss = 0.98416729, grad/param norm = 2.7608e-01, time/batch = 16.8856s	
13015/22950 (epoch 28.355), train_loss = 1.03835033, grad/param norm = 2.6152e-01, time/batch = 16.5564s	
13016/22950 (epoch 28.357), train_loss = 0.94007556, grad/param norm = 2.6572e-01, time/batch = 16.2896s	
13017/22950 (epoch 28.359), train_loss = 0.92183164, grad/param norm = 2.2331e-01, time/batch = 16.0986s	
13018/22950 (epoch 28.362), train_loss = 0.96934803, grad/param norm = 2.2734e-01, time/batch = 15.8767s	
13019/22950 (epoch 28.364), train_loss = 0.91103466, grad/param norm = 2.2711e-01, time/batch = 16.5745s	
13020/22950 (epoch 28.366), train_loss = 0.91697504, grad/param norm = 2.1912e-01, time/batch = 16.5470s	
13021/22950 (epoch 28.368), train_loss = 1.02160913, grad/param norm = 2.6907e-01, time/batch = 16.0239s	
13022/22950 (epoch 28.370), train_loss = 0.91507850, grad/param norm = 2.5455e-01, time/batch = 15.8916s	
13023/22950 (epoch 28.373), train_loss = 0.82335767, grad/param norm = 2.0031e-01, time/batch = 15.8845s	
13024/22950 (epoch 28.375), train_loss = 1.03065891, grad/param norm = 2.5556e-01, time/batch = 15.7211s	
13025/22950 (epoch 28.377), train_loss = 0.84106528, grad/param norm = 2.8135e-01, time/batch = 16.3628s	
13026/22950 (epoch 28.379), train_loss = 0.94387893, grad/param norm = 2.5594e-01, time/batch = 15.8679s	
13027/22950 (epoch 28.381), train_loss = 0.82618911, grad/param norm = 2.3707e-01, time/batch = 15.6381s	
13028/22950 (epoch 28.383), train_loss = 0.92192296, grad/param norm = 2.4935e-01, time/batch = 15.3102s	
13029/22950 (epoch 28.386), train_loss = 0.87083996, grad/param norm = 2.5741e-01, time/batch = 16.0165s	
13030/22950 (epoch 28.388), train_loss = 0.98855003, grad/param norm = 2.6996e-01, time/batch = 15.2237s	
13031/22950 (epoch 28.390), train_loss = 0.81930296, grad/param norm = 2.0955e-01, time/batch = 15.5511s	
13032/22950 (epoch 28.392), train_loss = 0.86472955, grad/param norm = 2.3087e-01, time/batch = 15.6206s	
13033/22950 (epoch 28.394), train_loss = 0.87630315, grad/param norm = 2.1972e-01, time/batch = 16.0098s	
13034/22950 (epoch 28.397), train_loss = 1.03980304, grad/param norm = 2.2511e-01, time/batch = 16.1050s	
13035/22950 (epoch 28.399), train_loss = 1.03911030, grad/param norm = 2.4487e-01, time/batch = 16.4018s	
13036/22950 (epoch 28.401), train_loss = 1.08021387, grad/param norm = 2.6241e-01, time/batch = 16.4749s	
13037/22950 (epoch 28.403), train_loss = 0.90907920, grad/param norm = 2.4706e-01, time/batch = 16.0377s	
13038/22950 (epoch 28.405), train_loss = 1.02588954, grad/param norm = 2.6622e-01, time/batch = 15.9600s	
13039/22950 (epoch 28.407), train_loss = 1.08245059, grad/param norm = 2.2168e-01, time/batch = 16.6568s	
13040/22950 (epoch 28.410), train_loss = 0.92151323, grad/param norm = 2.2484e-01, time/batch = 16.4274s	
13041/22950 (epoch 28.412), train_loss = 0.91678504, grad/param norm = 2.3856e-01, time/batch = 16.2084s	
13042/22950 (epoch 28.414), train_loss = 1.02911280, grad/param norm = 2.5361e-01, time/batch = 15.4774s	
13043/22950 (epoch 28.416), train_loss = 0.96216397, grad/param norm = 2.6079e-01, time/batch = 15.5498s	
13044/22950 (epoch 28.418), train_loss = 0.94840073, grad/param norm = 2.7355e-01, time/batch = 15.8034s	
13045/22950 (epoch 28.420), train_loss = 1.02823012, grad/param norm = 3.0466e-01, time/batch = 15.8687s	
13046/22950 (epoch 28.423), train_loss = 0.88562270, grad/param norm = 2.2510e-01, time/batch = 17.6357s	
13047/22950 (epoch 28.425), train_loss = 0.90454779, grad/param norm = 2.2227e-01, time/batch = 24.2365s	
13048/22950 (epoch 28.427), train_loss = 0.93692020, grad/param norm = 2.4228e-01, time/batch = 23.5140s	
13049/22950 (epoch 28.429), train_loss = 0.91493945, grad/param norm = 2.3113e-01, time/batch = 17.6432s	
13050/22950 (epoch 28.431), train_loss = 1.01833042, grad/param norm = 2.5528e-01, time/batch = 17.6101s	
13051/22950 (epoch 28.434), train_loss = 0.94626057, grad/param norm = 2.6269e-01, time/batch = 17.7943s	
13052/22950 (epoch 28.436), train_loss = 1.02770662, grad/param norm = 2.8094e-01, time/batch = 17.5396s	
13053/22950 (epoch 28.438), train_loss = 0.95315487, grad/param norm = 2.3772e-01, time/batch = 17.7003s	
13054/22950 (epoch 28.440), train_loss = 1.03866983, grad/param norm = 2.5256e-01, time/batch = 17.7967s	
13055/22950 (epoch 28.442), train_loss = 1.07338478, grad/param norm = 2.4861e-01, time/batch = 17.6940s	
13056/22950 (epoch 28.444), train_loss = 0.99749969, grad/param norm = 2.4602e-01, time/batch = 17.8698s	
13057/22950 (epoch 28.447), train_loss = 1.11290999, grad/param norm = 2.5354e-01, time/batch = 16.4919s	
13058/22950 (epoch 28.449), train_loss = 0.85364095, grad/param norm = 2.2080e-01, time/batch = 16.7737s	
13059/22950 (epoch 28.451), train_loss = 0.96480325, grad/param norm = 2.4216e-01, time/batch = 16.6995s	
13060/22950 (epoch 28.453), train_loss = 0.99567040, grad/param norm = 2.2935e-01, time/batch = 16.4056s	
13061/22950 (epoch 28.455), train_loss = 0.89624535, grad/param norm = 1.9363e-01, time/batch = 16.4429s	
13062/22950 (epoch 28.458), train_loss = 0.98631087, grad/param norm = 2.4609e-01, time/batch = 19.5438s	
13063/22950 (epoch 28.460), train_loss = 1.00015526, grad/param norm = 2.3065e-01, time/batch = 18.1168s	
13064/22950 (epoch 28.462), train_loss = 0.96724273, grad/param norm = 2.2806e-01, time/batch = 17.3000s	
13065/22950 (epoch 28.464), train_loss = 0.90946556, grad/param norm = 2.3090e-01, time/batch = 19.3619s	
13066/22950 (epoch 28.466), train_loss = 1.02722531, grad/param norm = 2.4824e-01, time/batch = 19.6993s	
13067/22950 (epoch 28.468), train_loss = 1.03787259, grad/param norm = 2.7180e-01, time/batch = 18.1127s	
13068/22950 (epoch 28.471), train_loss = 0.99447808, grad/param norm = 2.5018e-01, time/batch = 17.6027s	
13069/22950 (epoch 28.473), train_loss = 0.98003471, grad/param norm = 2.2972e-01, time/batch = 16.8637s	
13070/22950 (epoch 28.475), train_loss = 1.15538735, grad/param norm = 2.5644e-01, time/batch = 17.3728s	
13071/22950 (epoch 28.477), train_loss = 0.93135467, grad/param norm = 2.3677e-01, time/batch = 19.5358s	
13072/22950 (epoch 28.479), train_loss = 0.82879006, grad/param norm = 2.0578e-01, time/batch = 17.2832s	
13073/22950 (epoch 28.481), train_loss = 1.02996888, grad/param norm = 2.6770e-01, time/batch = 18.6781s	
13074/22950 (epoch 28.484), train_loss = 0.99163907, grad/param norm = 3.6697e-01, time/batch = 17.2912s	
13075/22950 (epoch 28.486), train_loss = 0.82045447, grad/param norm = 2.2784e-01, time/batch = 18.8672s	
13076/22950 (epoch 28.488), train_loss = 0.89623453, grad/param norm = 2.6553e-01, time/batch = 17.1910s	
13077/22950 (epoch 28.490), train_loss = 0.83663485, grad/param norm = 2.7037e-01, time/batch = 16.3505s	
13078/22950 (epoch 28.492), train_loss = 0.89486195, grad/param norm = 2.1872e-01, time/batch = 19.6349s	
13079/22950 (epoch 28.495), train_loss = 0.88067031, grad/param norm = 2.2420e-01, time/batch = 15.7481s	
13080/22950 (epoch 28.497), train_loss = 0.98736058, grad/param norm = 2.3011e-01, time/batch = 15.9089s	
13081/22950 (epoch 28.499), train_loss = 1.07525214, grad/param norm = 2.3036e-01, time/batch = 16.0124s	
13082/22950 (epoch 28.501), train_loss = 0.98419165, grad/param norm = 2.5370e-01, time/batch = 18.2930s	
13083/22950 (epoch 28.503), train_loss = 1.03375444, grad/param norm = 2.3529e-01, time/batch = 18.5567s	
13084/22950 (epoch 28.505), train_loss = 0.81397697, grad/param norm = 1.9829e-01, time/batch = 18.5972s	
13085/22950 (epoch 28.508), train_loss = 0.99576048, grad/param norm = 2.5134e-01, time/batch = 16.5264s	
13086/22950 (epoch 28.510), train_loss = 0.92851156, grad/param norm = 2.3050e-01, time/batch = 20.4267s	
13087/22950 (epoch 28.512), train_loss = 0.84310304, grad/param norm = 2.2523e-01, time/batch = 17.2783s	
13088/22950 (epoch 28.514), train_loss = 0.91204594, grad/param norm = 2.0201e-01, time/batch = 19.5443s	
13089/22950 (epoch 28.516), train_loss = 0.91511061, grad/param norm = 2.1361e-01, time/batch = 18.9630s	
13090/22950 (epoch 28.519), train_loss = 0.92540806, grad/param norm = 2.2973e-01, time/batch = 18.3623s	
13091/22950 (epoch 28.521), train_loss = 0.94515256, grad/param norm = 2.4180e-01, time/batch = 16.3730s	
13092/22950 (epoch 28.523), train_loss = 0.75948188, grad/param norm = 2.0193e-01, time/batch = 18.2974s	
13093/22950 (epoch 28.525), train_loss = 0.85599903, grad/param norm = 2.0266e-01, time/batch = 18.2093s	
13094/22950 (epoch 28.527), train_loss = 0.80236053, grad/param norm = 2.1837e-01, time/batch = 16.0058s	
13095/22950 (epoch 28.529), train_loss = 0.94339678, grad/param norm = 2.2331e-01, time/batch = 16.9729s	
13096/22950 (epoch 28.532), train_loss = 0.89644746, grad/param norm = 2.1814e-01, time/batch = 16.3189s	
13097/22950 (epoch 28.534), train_loss = 0.97459149, grad/param norm = 2.3103e-01, time/batch = 15.6798s	
13098/22950 (epoch 28.536), train_loss = 0.97906038, grad/param norm = 2.4707e-01, time/batch = 15.9894s	
13099/22950 (epoch 28.538), train_loss = 0.95504447, grad/param norm = 2.4739e-01, time/batch = 17.8737s	
13100/22950 (epoch 28.540), train_loss = 1.00016272, grad/param norm = 2.7408e-01, time/batch = 16.7587s	
13101/22950 (epoch 28.542), train_loss = 1.09653316, grad/param norm = 2.4788e-01, time/batch = 15.9961s	
13102/22950 (epoch 28.545), train_loss = 0.90453854, grad/param norm = 2.0215e-01, time/batch = 16.8666s	
13103/22950 (epoch 28.547), train_loss = 0.93330890, grad/param norm = 2.2967e-01, time/batch = 19.5313s	
13104/22950 (epoch 28.549), train_loss = 0.84916281, grad/param norm = 2.1277e-01, time/batch = 17.2919s	
13105/22950 (epoch 28.551), train_loss = 0.89673559, grad/param norm = 2.1957e-01, time/batch = 20.1204s	
13106/22950 (epoch 28.553), train_loss = 0.89786300, grad/param norm = 2.5653e-01, time/batch = 18.7848s	
13107/22950 (epoch 28.556), train_loss = 0.97406112, grad/param norm = 2.2828e-01, time/batch = 17.0421s	
13108/22950 (epoch 28.558), train_loss = 0.80408417, grad/param norm = 2.2471e-01, time/batch = 19.8506s	
13109/22950 (epoch 28.560), train_loss = 0.90708557, grad/param norm = 2.3663e-01, time/batch = 17.0397s	
13110/22950 (epoch 28.562), train_loss = 0.86164617, grad/param norm = 2.2261e-01, time/batch = 17.8476s	
13111/22950 (epoch 28.564), train_loss = 0.97075797, grad/param norm = 2.3948e-01, time/batch = 17.2536s	
13112/22950 (epoch 28.566), train_loss = 0.93608236, grad/param norm = 2.2337e-01, time/batch = 17.9675s	
13113/22950 (epoch 28.569), train_loss = 0.92734421, grad/param norm = 2.4380e-01, time/batch = 19.9511s	
13114/22950 (epoch 28.571), train_loss = 0.90250954, grad/param norm = 2.4035e-01, time/batch = 16.4452s	
13115/22950 (epoch 28.573), train_loss = 0.93070640, grad/param norm = 2.2378e-01, time/batch = 17.6141s	
13116/22950 (epoch 28.575), train_loss = 1.03856799, grad/param norm = 2.9693e-01, time/batch = 18.2977s	
13117/22950 (epoch 28.577), train_loss = 0.95425302, grad/param norm = 2.7544e-01, time/batch = 17.4508s	
13118/22950 (epoch 28.580), train_loss = 1.02025015, grad/param norm = 2.7389e-01, time/batch = 17.9483s	
13119/22950 (epoch 28.582), train_loss = 1.08096877, grad/param norm = 2.4738e-01, time/batch = 18.3662s	
13120/22950 (epoch 28.584), train_loss = 0.81859992, grad/param norm = 2.3408e-01, time/batch = 19.3737s	
13121/22950 (epoch 28.586), train_loss = 0.85084804, grad/param norm = 2.2300e-01, time/batch = 18.9637s	
13122/22950 (epoch 28.588), train_loss = 1.07910708, grad/param norm = 2.5101e-01, time/batch = 17.3522s	
13123/22950 (epoch 28.590), train_loss = 0.97985044, grad/param norm = 2.5269e-01, time/batch = 16.4072s	
13124/22950 (epoch 28.593), train_loss = 0.90412813, grad/param norm = 2.2956e-01, time/batch = 16.6863s	
13125/22950 (epoch 28.595), train_loss = 0.85028364, grad/param norm = 2.9707e-01, time/batch = 16.6142s	
13126/22950 (epoch 28.597), train_loss = 1.00609783, grad/param norm = 2.5877e-01, time/batch = 19.7096s	
13127/22950 (epoch 28.599), train_loss = 0.95431857, grad/param norm = 2.4671e-01, time/batch = 18.9466s	
13128/22950 (epoch 28.601), train_loss = 0.97750036, grad/param norm = 2.4375e-01, time/batch = 18.4513s	
13129/22950 (epoch 28.603), train_loss = 1.06103486, grad/param norm = 2.4949e-01, time/batch = 18.8754s	
13130/22950 (epoch 28.606), train_loss = 0.95400919, grad/param norm = 2.4401e-01, time/batch = 17.6971s	
13131/22950 (epoch 28.608), train_loss = 0.96598853, grad/param norm = 2.3012e-01, time/batch = 15.4748s	
13132/22950 (epoch 28.610), train_loss = 0.95092561, grad/param norm = 2.4787e-01, time/batch = 17.6308s	
13133/22950 (epoch 28.612), train_loss = 0.93624662, grad/param norm = 2.4168e-01, time/batch = 18.6959s	
13134/22950 (epoch 28.614), train_loss = 1.03902874, grad/param norm = 2.6093e-01, time/batch = 18.1255s	
13135/22950 (epoch 28.617), train_loss = 0.93959775, grad/param norm = 2.3234e-01, time/batch = 16.0916s	
13136/22950 (epoch 28.619), train_loss = 0.89955479, grad/param norm = 1.9741e-01, time/batch = 19.8531s	
13137/22950 (epoch 28.621), train_loss = 1.02401600, grad/param norm = 2.3251e-01, time/batch = 17.1916s	
13138/22950 (epoch 28.623), train_loss = 1.00846055, grad/param norm = 2.3455e-01, time/batch = 16.8695s	
13139/22950 (epoch 28.625), train_loss = 0.91238440, grad/param norm = 2.1564e-01, time/batch = 18.5432s	
13140/22950 (epoch 28.627), train_loss = 0.91768070, grad/param norm = 2.5251e-01, time/batch = 17.6766s	
13141/22950 (epoch 28.630), train_loss = 0.81652228, grad/param norm = 2.1355e-01, time/batch = 19.6136s	
13142/22950 (epoch 28.632), train_loss = 0.89522242, grad/param norm = 2.8880e-01, time/batch = 19.3474s	
13143/22950 (epoch 28.634), train_loss = 0.96150335, grad/param norm = 2.4783e-01, time/batch = 16.8838s	
13144/22950 (epoch 28.636), train_loss = 0.95229496, grad/param norm = 2.3797e-01, time/batch = 16.8234s	
13145/22950 (epoch 28.638), train_loss = 0.87754086, grad/param norm = 2.2616e-01, time/batch = 18.0223s	
13146/22950 (epoch 28.641), train_loss = 0.91698924, grad/param norm = 2.1650e-01, time/batch = 20.0315s	
13147/22950 (epoch 28.643), train_loss = 1.00341275, grad/param norm = 2.7817e-01, time/batch = 17.0989s	
13148/22950 (epoch 28.645), train_loss = 0.90566761, grad/param norm = 2.4394e-01, time/batch = 19.1991s	
13149/22950 (epoch 28.647), train_loss = 0.93471743, grad/param norm = 2.8761e-01, time/batch = 19.4628s	
13150/22950 (epoch 28.649), train_loss = 0.88891237, grad/param norm = 2.2842e-01, time/batch = 17.3529s	
13151/22950 (epoch 28.651), train_loss = 0.99388643, grad/param norm = 2.3549e-01, time/batch = 20.1892s	
13152/22950 (epoch 28.654), train_loss = 0.80924706, grad/param norm = 2.1528e-01, time/batch = 18.2015s	
13153/22950 (epoch 28.656), train_loss = 0.97875534, grad/param norm = 2.6171e-01, time/batch = 17.8704s	
13154/22950 (epoch 28.658), train_loss = 0.83593748, grad/param norm = 2.1262e-01, time/batch = 19.1231s	
13155/22950 (epoch 28.660), train_loss = 0.76245991, grad/param norm = 2.2508e-01, time/batch = 17.6941s	
13156/22950 (epoch 28.662), train_loss = 0.77585445, grad/param norm = 2.2781e-01, time/batch = 18.0314s	
13157/22950 (epoch 28.664), train_loss = 0.90359778, grad/param norm = 2.2784e-01, time/batch = 18.5295s	
13158/22950 (epoch 28.667), train_loss = 0.94245126, grad/param norm = 2.8078e-01, time/batch = 18.4579s	
13159/22950 (epoch 28.669), train_loss = 0.95124916, grad/param norm = 2.4919e-01, time/batch = 19.3767s	
13160/22950 (epoch 28.671), train_loss = 0.94388247, grad/param norm = 2.3755e-01, time/batch = 16.2662s	
13161/22950 (epoch 28.673), train_loss = 0.87312035, grad/param norm = 2.4640e-01, time/batch = 16.5629s	
13162/22950 (epoch 28.675), train_loss = 0.95062762, grad/param norm = 2.2747e-01, time/batch = 16.3422s	
13163/22950 (epoch 28.678), train_loss = 0.92633905, grad/param norm = 2.3386e-01, time/batch = 17.5269s	
13164/22950 (epoch 28.680), train_loss = 0.94697460, grad/param norm = 2.1640e-01, time/batch = 18.2003s	
13165/22950 (epoch 28.682), train_loss = 0.91041411, grad/param norm = 2.5064e-01, time/batch = 18.6329s	
13166/22950 (epoch 28.684), train_loss = 1.02317906, grad/param norm = 2.5090e-01, time/batch = 19.4652s	
13167/22950 (epoch 28.686), train_loss = 1.03452925, grad/param norm = 2.3886e-01, time/batch = 18.0281s	
13168/22950 (epoch 28.688), train_loss = 0.95755411, grad/param norm = 2.3052e-01, time/batch = 16.4666s	
13169/22950 (epoch 28.691), train_loss = 0.93522225, grad/param norm = 2.3577e-01, time/batch = 18.3789s	
13170/22950 (epoch 28.693), train_loss = 0.85084534, grad/param norm = 2.5365e-01, time/batch = 18.0245s	
13171/22950 (epoch 28.695), train_loss = 1.04097214, grad/param norm = 2.8032e-01, time/batch = 19.1131s	
13172/22950 (epoch 28.697), train_loss = 0.97973276, grad/param norm = 2.5065e-01, time/batch = 18.7077s	
13173/22950 (epoch 28.699), train_loss = 0.98384167, grad/param norm = 2.2751e-01, time/batch = 18.9508s	
13174/22950 (epoch 28.702), train_loss = 0.99035330, grad/param norm = 2.4066e-01, time/batch = 18.1187s	
13175/22950 (epoch 28.704), train_loss = 1.06042833, grad/param norm = 2.6599e-01, time/batch = 18.9403s	
13176/22950 (epoch 28.706), train_loss = 1.03891353, grad/param norm = 2.5316e-01, time/batch = 18.3728s	
13177/22950 (epoch 28.708), train_loss = 0.84039135, grad/param norm = 2.4698e-01, time/batch = 17.5864s	
13178/22950 (epoch 28.710), train_loss = 0.95644587, grad/param norm = 2.2784e-01, time/batch = 18.7758s	
13179/22950 (epoch 28.712), train_loss = 1.07903506, grad/param norm = 2.7452e-01, time/batch = 17.2599s	
13180/22950 (epoch 28.715), train_loss = 0.95245473, grad/param norm = 2.4148e-01, time/batch = 16.2557s	
13181/22950 (epoch 28.717), train_loss = 0.98364889, grad/param norm = 2.2220e-01, time/batch = 17.1405s	
13182/22950 (epoch 28.719), train_loss = 0.91077744, grad/param norm = 2.5298e-01, time/batch = 16.7809s	
13183/22950 (epoch 28.721), train_loss = 1.00645554, grad/param norm = 2.5870e-01, time/batch = 18.5270s	
13184/22950 (epoch 28.723), train_loss = 0.95738041, grad/param norm = 2.4428e-01, time/batch = 19.7800s	
13185/22950 (epoch 28.725), train_loss = 0.99570470, grad/param norm = 2.5973e-01, time/batch = 18.2589s	
13186/22950 (epoch 28.728), train_loss = 0.92959174, grad/param norm = 3.0545e-01, time/batch = 19.1237s	
13187/22950 (epoch 28.730), train_loss = 0.92667347, grad/param norm = 2.5017e-01, time/batch = 18.5421s	
13188/22950 (epoch 28.732), train_loss = 0.99190409, grad/param norm = 2.4864e-01, time/batch = 17.3650s	
13189/22950 (epoch 28.734), train_loss = 0.93213325, grad/param norm = 2.5495e-01, time/batch = 18.8755s	
13190/22950 (epoch 28.736), train_loss = 0.96529056, grad/param norm = 2.4369e-01, time/batch = 18.3732s	
13191/22950 (epoch 28.739), train_loss = 1.00862813, grad/param norm = 2.6524e-01, time/batch = 19.1955s	
13192/22950 (epoch 28.741), train_loss = 1.01034313, grad/param norm = 2.7201e-01, time/batch = 15.8652s	
13193/22950 (epoch 28.743), train_loss = 1.09199614, grad/param norm = 2.9154e-01, time/batch = 18.2029s	
13194/22950 (epoch 28.745), train_loss = 1.19282771, grad/param norm = 2.7917e-01, time/batch = 19.4656s	
13195/22950 (epoch 28.747), train_loss = 0.95790530, grad/param norm = 2.4369e-01, time/batch = 18.7941s	
13196/22950 (epoch 28.749), train_loss = 0.89159465, grad/param norm = 2.3430e-01, time/batch = 17.3737s	
13197/22950 (epoch 28.752), train_loss = 1.13489989, grad/param norm = 2.9557e-01, time/batch = 17.6434s	
13198/22950 (epoch 28.754), train_loss = 1.01991487, grad/param norm = 2.6583e-01, time/batch = 17.1333s	
13199/22950 (epoch 28.756), train_loss = 0.88595427, grad/param norm = 2.2465e-01, time/batch = 17.1688s	
13200/22950 (epoch 28.758), train_loss = 0.94945205, grad/param norm = 2.2928e-01, time/batch = 16.4779s	
13201/22950 (epoch 28.760), train_loss = 0.99701289, grad/param norm = 2.4891e-01, time/batch = 16.5878s	
13202/22950 (epoch 28.763), train_loss = 1.01892797, grad/param norm = 2.5746e-01, time/batch = 19.6040s	
13203/22950 (epoch 28.765), train_loss = 0.96410991, grad/param norm = 2.7658e-01, time/batch = 18.7799s	
13204/22950 (epoch 28.767), train_loss = 1.17057143, grad/param norm = 2.7392e-01, time/batch = 16.6158s	
13205/22950 (epoch 28.769), train_loss = 1.00463459, grad/param norm = 2.4484e-01, time/batch = 20.2927s	
13206/22950 (epoch 28.771), train_loss = 0.81571501, grad/param norm = 2.1829e-01, time/batch = 17.9645s	
13207/22950 (epoch 28.773), train_loss = 0.73361660, grad/param norm = 2.0526e-01, time/batch = 18.8695s	
13208/22950 (epoch 28.776), train_loss = 0.87330718, grad/param norm = 2.0408e-01, time/batch = 19.8616s	
13209/22950 (epoch 28.778), train_loss = 0.86918157, grad/param norm = 2.3299e-01, time/batch = 16.6952s	
13210/22950 (epoch 28.780), train_loss = 0.95146863, grad/param norm = 2.0563e-01, time/batch = 18.3329s	
13211/22950 (epoch 28.782), train_loss = 1.02259011, grad/param norm = 2.4050e-01, time/batch = 18.0618s	
13212/22950 (epoch 28.784), train_loss = 0.89622553, grad/param norm = 2.2370e-01, time/batch = 20.1960s	
13213/22950 (epoch 28.786), train_loss = 0.96852941, grad/param norm = 2.4209e-01, time/batch = 17.5078s	
13214/22950 (epoch 28.789), train_loss = 0.80606542, grad/param norm = 2.2429e-01, time/batch = 18.7141s	
13215/22950 (epoch 28.791), train_loss = 0.87121991, grad/param norm = 3.4972e-01, time/batch = 18.6883s	
13216/22950 (epoch 28.793), train_loss = 1.05648880, grad/param norm = 2.6263e-01, time/batch = 17.1633s	
13217/22950 (epoch 28.795), train_loss = 0.92730724, grad/param norm = 2.2205e-01, time/batch = 17.2170s	
13218/22950 (epoch 28.797), train_loss = 1.07655161, grad/param norm = 2.3732e-01, time/batch = 17.1714s	
13219/22950 (epoch 28.800), train_loss = 0.86026640, grad/param norm = 2.2569e-01, time/batch = 17.7688s	
13220/22950 (epoch 28.802), train_loss = 0.89805822, grad/param norm = 2.3939e-01, time/batch = 20.6065s	
13221/22950 (epoch 28.804), train_loss = 0.90537607, grad/param norm = 2.1930e-01, time/batch = 16.6908s	
13222/22950 (epoch 28.806), train_loss = 0.82392998, grad/param norm = 2.2635e-01, time/batch = 16.2398s	
13223/22950 (epoch 28.808), train_loss = 0.92094881, grad/param norm = 2.1973e-01, time/batch = 16.8609s	
13224/22950 (epoch 28.810), train_loss = 0.90880681, grad/param norm = 2.5709e-01, time/batch = 17.2769s	
13225/22950 (epoch 28.813), train_loss = 0.77272788, grad/param norm = 2.0489e-01, time/batch = 19.2998s	
13226/22950 (epoch 28.815), train_loss = 0.77791481, grad/param norm = 2.3925e-01, time/batch = 17.3697s	
13227/22950 (epoch 28.817), train_loss = 0.86149465, grad/param norm = 2.2076e-01, time/batch = 19.2050s	
13228/22950 (epoch 28.819), train_loss = 0.91668562, grad/param norm = 2.2226e-01, time/batch = 17.7916s	
13229/22950 (epoch 28.821), train_loss = 0.87326904, grad/param norm = 2.5239e-01, time/batch = 19.0310s	
13230/22950 (epoch 28.824), train_loss = 0.94038283, grad/param norm = 2.3946e-01, time/batch = 18.1070s	
13231/22950 (epoch 28.826), train_loss = 0.99827592, grad/param norm = 2.6630e-01, time/batch = 17.3867s	
13232/22950 (epoch 28.828), train_loss = 0.90645173, grad/param norm = 2.3690e-01, time/batch = 19.8681s	
13233/22950 (epoch 28.830), train_loss = 0.89881123, grad/param norm = 2.4505e-01, time/batch = 16.0958s	
13234/22950 (epoch 28.832), train_loss = 0.94262563, grad/param norm = 2.4380e-01, time/batch = 16.6057s	
13235/22950 (epoch 28.834), train_loss = 0.78971135, grad/param norm = 2.3748e-01, time/batch = 17.1114s	
13236/22950 (epoch 28.837), train_loss = 0.93473465, grad/param norm = 2.4224e-01, time/batch = 18.0050s	
13237/22950 (epoch 28.839), train_loss = 0.79250363, grad/param norm = 2.1481e-01, time/batch = 19.0432s	
13238/22950 (epoch 28.841), train_loss = 0.87302293, grad/param norm = 2.0935e-01, time/batch = 18.2976s	
13239/22950 (epoch 28.843), train_loss = 0.88826245, grad/param norm = 2.3833e-01, time/batch = 17.5287s	
13240/22950 (epoch 28.845), train_loss = 0.93205177, grad/param norm = 2.3519e-01, time/batch = 16.6051s	
13241/22950 (epoch 28.847), train_loss = 0.97415899, grad/param norm = 2.5613e-01, time/batch = 18.4603s	
13242/22950 (epoch 28.850), train_loss = 1.00173309, grad/param norm = 2.7596e-01, time/batch = 19.1099s	
13243/22950 (epoch 28.852), train_loss = 0.99448035, grad/param norm = 2.4459e-01, time/batch = 18.1258s	
13244/22950 (epoch 28.854), train_loss = 0.91749652, grad/param norm = 2.1839e-01, time/batch = 17.9576s	
13245/22950 (epoch 28.856), train_loss = 1.09030824, grad/param norm = 2.7997e-01, time/batch = 16.8368s	
13246/22950 (epoch 28.858), train_loss = 0.97897409, grad/param norm = 2.2551e-01, time/batch = 21.5991s	
13247/22950 (epoch 28.861), train_loss = 1.00337232, grad/param norm = 2.5688e-01, time/batch = 27.0249s	
13248/22950 (epoch 28.863), train_loss = 1.04648361, grad/param norm = 2.7619e-01, time/batch = 17.2861s	
13249/22950 (epoch 28.865), train_loss = 1.06970165, grad/param norm = 2.6505e-01, time/batch = 16.6224s	
13250/22950 (epoch 28.867), train_loss = 0.97049713, grad/param norm = 2.4369e-01, time/batch = 18.5220s	
13251/22950 (epoch 28.869), train_loss = 1.08799873, grad/param norm = 2.6563e-01, time/batch = 19.0427s	
13252/22950 (epoch 28.871), train_loss = 0.97076224, grad/param norm = 2.3232e-01, time/batch = 17.2781s	
13253/22950 (epoch 28.874), train_loss = 0.98460329, grad/param norm = 2.4009e-01, time/batch = 18.9122s	
13254/22950 (epoch 28.876), train_loss = 1.01814452, grad/param norm = 2.4460e-01, time/batch = 18.2989s	
13255/22950 (epoch 28.878), train_loss = 0.92614225, grad/param norm = 2.5842e-01, time/batch = 19.1148s	
13256/22950 (epoch 28.880), train_loss = 1.12331425, grad/param norm = 2.5668e-01, time/batch = 18.3748s	
13257/22950 (epoch 28.882), train_loss = 0.84693650, grad/param norm = 2.2852e-01, time/batch = 18.3553s	
13258/22950 (epoch 28.885), train_loss = 0.97637968, grad/param norm = 2.4633e-01, time/batch = 19.5335s	
13259/22950 (epoch 28.887), train_loss = 0.92865051, grad/param norm = 2.1504e-01, time/batch = 16.6896s	
13260/22950 (epoch 28.889), train_loss = 0.99481353, grad/param norm = 2.4857e-01, time/batch = 19.0999s	
13261/22950 (epoch 28.891), train_loss = 0.89132614, grad/param norm = 2.2279e-01, time/batch = 18.1248s	
13262/22950 (epoch 28.893), train_loss = 1.01936500, grad/param norm = 2.4317e-01, time/batch = 16.6024s	
13263/22950 (epoch 28.895), train_loss = 1.08832662, grad/param norm = 2.6770e-01, time/batch = 16.5050s	
13264/22950 (epoch 28.898), train_loss = 0.97593727, grad/param norm = 2.4428e-01, time/batch = 16.1335s	
13265/22950 (epoch 28.900), train_loss = 0.92653859, grad/param norm = 2.1635e-01, time/batch = 15.4583s	
13266/22950 (epoch 28.902), train_loss = 0.96755534, grad/param norm = 2.3117e-01, time/batch = 16.7015s	
13267/22950 (epoch 28.904), train_loss = 0.95603931, grad/param norm = 2.4716e-01, time/batch = 17.2217s	
13268/22950 (epoch 28.906), train_loss = 0.99094713, grad/param norm = 2.3872e-01, time/batch = 20.1194s	
13269/22950 (epoch 28.908), train_loss = 0.83332712, grad/param norm = 2.1459e-01, time/batch = 16.6050s	
13270/22950 (epoch 28.911), train_loss = 0.80267106, grad/param norm = 1.9497e-01, time/batch = 17.5424s	
13271/22950 (epoch 28.913), train_loss = 0.91372517, grad/param norm = 2.1116e-01, time/batch = 19.2046s	
13272/22950 (epoch 28.915), train_loss = 1.09269935, grad/param norm = 2.5233e-01, time/batch = 18.3698s	
13273/22950 (epoch 28.917), train_loss = 0.82117479, grad/param norm = 2.1333e-01, time/batch = 18.7004s	
13274/22950 (epoch 28.919), train_loss = 0.94914079, grad/param norm = 2.2598e-01, time/batch = 19.4537s	
13275/22950 (epoch 28.922), train_loss = 0.96408484, grad/param norm = 2.4446e-01, time/batch = 18.2952s	
13276/22950 (epoch 28.924), train_loss = 0.99185829, grad/param norm = 2.6822e-01, time/batch = 18.7977s	
13277/22950 (epoch 28.926), train_loss = 0.80919195, grad/param norm = 2.5908e-01, time/batch = 19.7056s	
13278/22950 (epoch 28.928), train_loss = 0.82502167, grad/param norm = 2.1908e-01, time/batch = 19.4527s	
13279/22950 (epoch 28.930), train_loss = 0.82912162, grad/param norm = 2.3146e-01, time/batch = 18.3610s	
13280/22950 (epoch 28.932), train_loss = 0.77834947, grad/param norm = 1.9805e-01, time/batch = 17.1865s	
13281/22950 (epoch 28.935), train_loss = 0.93477027, grad/param norm = 2.2279e-01, time/batch = 17.0206s	
13282/22950 (epoch 28.937), train_loss = 0.94837851, grad/param norm = 2.6051e-01, time/batch = 17.0022s	
13283/22950 (epoch 28.939), train_loss = 0.85348195, grad/param norm = 2.2270e-01, time/batch = 18.2185s	
13284/22950 (epoch 28.941), train_loss = 0.89480732, grad/param norm = 2.3002e-01, time/batch = 16.4437s	
13285/22950 (epoch 28.943), train_loss = 0.95820495, grad/param norm = 2.5359e-01, time/batch = 18.5328s	
13286/22950 (epoch 28.946), train_loss = 0.78924087, grad/param norm = 2.1625e-01, time/batch = 19.4467s	
13287/22950 (epoch 28.948), train_loss = 1.01219715, grad/param norm = 2.4647e-01, time/batch = 17.8849s	
13288/22950 (epoch 28.950), train_loss = 0.93007392, grad/param norm = 2.5874e-01, time/batch = 19.6259s	
13289/22950 (epoch 28.952), train_loss = 0.97931287, grad/param norm = 2.3561e-01, time/batch = 17.8851s	
13290/22950 (epoch 28.954), train_loss = 0.97074558, grad/param norm = 2.6443e-01, time/batch = 15.7541s	
13291/22950 (epoch 28.956), train_loss = 0.88413088, grad/param norm = 2.6367e-01, time/batch = 16.0352s	
13292/22950 (epoch 28.959), train_loss = 0.86163770, grad/param norm = 2.2292e-01, time/batch = 15.3620s	
13293/22950 (epoch 28.961), train_loss = 0.94876173, grad/param norm = 2.3566e-01, time/batch = 18.7953s	
13294/22950 (epoch 28.963), train_loss = 0.95265590, grad/param norm = 2.3463e-01, time/batch = 18.1387s	
13295/22950 (epoch 28.965), train_loss = 1.03167152, grad/param norm = 2.4136e-01, time/batch = 16.7047s	
13296/22950 (epoch 28.967), train_loss = 0.92072532, grad/param norm = 2.4636e-01, time/batch = 16.6905s	
13297/22950 (epoch 28.969), train_loss = 0.83468938, grad/param norm = 2.4701e-01, time/batch = 19.5400s	
13298/22950 (epoch 28.972), train_loss = 0.92184918, grad/param norm = 2.1602e-01, time/batch = 19.3745s	
13299/22950 (epoch 28.974), train_loss = 0.89586875, grad/param norm = 2.4012e-01, time/batch = 17.0285s	
13300/22950 (epoch 28.976), train_loss = 0.87655115, grad/param norm = 2.1458e-01, time/batch = 18.3702s	
13301/22950 (epoch 28.978), train_loss = 0.87780050, grad/param norm = 2.6858e-01, time/batch = 18.2854s	
13302/22950 (epoch 28.980), train_loss = 0.87825543, grad/param norm = 2.1824e-01, time/batch = 18.1948s	
13303/22950 (epoch 28.983), train_loss = 0.98447522, grad/param norm = 2.3494e-01, time/batch = 20.6167s	
13304/22950 (epoch 28.985), train_loss = 0.81070847, grad/param norm = 2.1245e-01, time/batch = 17.7665s	
13305/22950 (epoch 28.987), train_loss = 0.87427700, grad/param norm = 2.2165e-01, time/batch = 18.1209s	
13306/22950 (epoch 28.989), train_loss = 0.93048099, grad/param norm = 2.3246e-01, time/batch = 17.2742s	
13307/22950 (epoch 28.991), train_loss = 0.79107386, grad/param norm = 2.1119e-01, time/batch = 17.6902s	
13308/22950 (epoch 28.993), train_loss = 0.95769616, grad/param norm = 2.2434e-01, time/batch = 16.6125s	
13309/22950 (epoch 28.996), train_loss = 0.91744347, grad/param norm = 2.1958e-01, time/batch = 18.5067s	
13310/22950 (epoch 28.998), train_loss = 0.83478998, grad/param norm = 2.0856e-01, time/batch = 20.4485s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
13311/22950 (epoch 29.000), train_loss = 0.77577705, grad/param norm = 2.0269e-01, time/batch = 18.6348s	
13312/22950 (epoch 29.002), train_loss = 1.06750993, grad/param norm = 2.2656e-01, time/batch = 17.2696s	
13313/22950 (epoch 29.004), train_loss = 0.94775008, grad/param norm = 2.1413e-01, time/batch = 17.5539s	
13314/22950 (epoch 29.007), train_loss = 0.92795109, grad/param norm = 2.2772e-01, time/batch = 18.3076s	
13315/22950 (epoch 29.009), train_loss = 1.05751113, grad/param norm = 2.8582e-01, time/batch = 17.6620s	
13316/22950 (epoch 29.011), train_loss = 0.81476545, grad/param norm = 2.5906e-01, time/batch = 17.2532s	
13317/22950 (epoch 29.013), train_loss = 0.92515737, grad/param norm = 2.4630e-01, time/batch = 15.7874s	
13318/22950 (epoch 29.015), train_loss = 0.96047113, grad/param norm = 2.4662e-01, time/batch = 19.6092s	
13319/22950 (epoch 29.017), train_loss = 0.93859146, grad/param norm = 2.2229e-01, time/batch = 18.7836s	
13320/22950 (epoch 29.020), train_loss = 0.96828351, grad/param norm = 2.2339e-01, time/batch = 17.6138s	
13321/22950 (epoch 29.022), train_loss = 0.80712186, grad/param norm = 2.0073e-01, time/batch = 16.0767s	
13322/22950 (epoch 29.024), train_loss = 0.89797784, grad/param norm = 2.4289e-01, time/batch = 16.1161s	
13323/22950 (epoch 29.026), train_loss = 0.96692938, grad/param norm = 2.3800e-01, time/batch = 17.4787s	
13324/22950 (epoch 29.028), train_loss = 1.01538312, grad/param norm = 2.0991e-01, time/batch = 17.1112s	
13325/22950 (epoch 29.031), train_loss = 0.87820948, grad/param norm = 2.1483e-01, time/batch = 18.4467s	
13326/22950 (epoch 29.033), train_loss = 1.02959348, grad/param norm = 2.4560e-01, time/batch = 18.9681s	
13327/22950 (epoch 29.035), train_loss = 0.91745181, grad/param norm = 2.2747e-01, time/batch = 18.6280s	
13328/22950 (epoch 29.037), train_loss = 0.91310322, grad/param norm = 2.0662e-01, time/batch = 19.6995s	
13329/22950 (epoch 29.039), train_loss = 0.90105220, grad/param norm = 2.2570e-01, time/batch = 16.2606s	
13330/22950 (epoch 29.041), train_loss = 0.87348106, grad/param norm = 2.3016e-01, time/batch = 18.1070s	
13331/22950 (epoch 29.044), train_loss = 0.97889560, grad/param norm = 2.4548e-01, time/batch = 19.6295s	
13332/22950 (epoch 29.046), train_loss = 0.94421196, grad/param norm = 2.4934e-01, time/batch = 18.4547s	
13333/22950 (epoch 29.048), train_loss = 0.91963977, grad/param norm = 2.1326e-01, time/batch = 18.6228s	
13334/22950 (epoch 29.050), train_loss = 0.88173244, grad/param norm = 2.6628e-01, time/batch = 17.6288s	
13335/22950 (epoch 29.052), train_loss = 0.97172075, grad/param norm = 2.3803e-01, time/batch = 17.9641s	
13336/22950 (epoch 29.054), train_loss = 1.09182361, grad/param norm = 2.4935e-01, time/batch = 19.4429s	
13337/22950 (epoch 29.057), train_loss = 1.01831181, grad/param norm = 2.7057e-01, time/batch = 16.6401s	
13338/22950 (epoch 29.059), train_loss = 1.00935599, grad/param norm = 2.5084e-01, time/batch = 19.2937s	
13339/22950 (epoch 29.061), train_loss = 0.87961421, grad/param norm = 2.3823e-01, time/batch = 16.9683s	
13340/22950 (epoch 29.063), train_loss = 0.95888245, grad/param norm = 2.6578e-01, time/batch = 16.1636s	
13341/22950 (epoch 29.065), train_loss = 0.84172866, grad/param norm = 2.3357e-01, time/batch = 17.4429s	
13342/22950 (epoch 29.068), train_loss = 0.95748869, grad/param norm = 2.3638e-01, time/batch = 16.1577s	
13343/22950 (epoch 29.070), train_loss = 0.84109473, grad/param norm = 2.3237e-01, time/batch = 16.7894s	
13344/22950 (epoch 29.072), train_loss = 1.00797702, grad/param norm = 2.4721e-01, time/batch = 14.7466s	
13345/22950 (epoch 29.074), train_loss = 0.96354469, grad/param norm = 2.2942e-01, time/batch = 14.7535s	
13346/22950 (epoch 29.076), train_loss = 0.96453345, grad/param norm = 2.3776e-01, time/batch = 15.6928s	
13347/22950 (epoch 29.078), train_loss = 1.01730105, grad/param norm = 2.4710e-01, time/batch = 15.1466s	
13348/22950 (epoch 29.081), train_loss = 1.05256839, grad/param norm = 2.3759e-01, time/batch = 14.9096s	
13349/22950 (epoch 29.083), train_loss = 0.94473237, grad/param norm = 2.3666e-01, time/batch = 14.7373s	
13350/22950 (epoch 29.085), train_loss = 0.81614857, grad/param norm = 2.2535e-01, time/batch = 15.9956s	
13351/22950 (epoch 29.087), train_loss = 0.85166240, grad/param norm = 2.2510e-01, time/batch = 15.0645s	
13352/22950 (epoch 29.089), train_loss = 0.97230268, grad/param norm = 2.6923e-01, time/batch = 14.8982s	
13353/22950 (epoch 29.092), train_loss = 0.87770265, grad/param norm = 2.3012e-01, time/batch = 14.7453s	
13354/22950 (epoch 29.094), train_loss = 0.85021497, grad/param norm = 2.2925e-01, time/batch = 15.5301s	
13355/22950 (epoch 29.096), train_loss = 1.02991728, grad/param norm = 2.4807e-01, time/batch = 14.8201s	
13356/22950 (epoch 29.098), train_loss = 0.97817014, grad/param norm = 2.3759e-01, time/batch = 15.1365s	
13357/22950 (epoch 29.100), train_loss = 0.90603168, grad/param norm = 2.3771e-01, time/batch = 14.7544s	
13358/22950 (epoch 29.102), train_loss = 0.93990255, grad/param norm = 2.3665e-01, time/batch = 15.1338s	
13359/22950 (epoch 29.105), train_loss = 0.78706968, grad/param norm = 2.0895e-01, time/batch = 14.7461s	
13360/22950 (epoch 29.107), train_loss = 0.87024720, grad/param norm = 2.1860e-01, time/batch = 14.9114s	
13361/22950 (epoch 29.109), train_loss = 0.88388870, grad/param norm = 2.3129e-01, time/batch = 14.8244s	
13362/22950 (epoch 29.111), train_loss = 0.79284346, grad/param norm = 2.3189e-01, time/batch = 15.3637s	
13363/22950 (epoch 29.113), train_loss = 0.93697648, grad/param norm = 2.2074e-01, time/batch = 14.6746s	
13364/22950 (epoch 29.115), train_loss = 0.94149235, grad/param norm = 2.2680e-01, time/batch = 15.1397s	
13365/22950 (epoch 29.118), train_loss = 1.04536198, grad/param norm = 2.1896e-01, time/batch = 14.5008s	
13366/22950 (epoch 29.120), train_loss = 0.83934815, grad/param norm = 2.1598e-01, time/batch = 16.3811s	
13367/22950 (epoch 29.122), train_loss = 1.00673568, grad/param norm = 2.4441e-01, time/batch = 16.0148s	
13368/22950 (epoch 29.124), train_loss = 0.82217801, grad/param norm = 2.1579e-01, time/batch = 15.9421s	
13369/22950 (epoch 29.126), train_loss = 0.92789829, grad/param norm = 2.2444e-01, time/batch = 15.2256s	
13370/22950 (epoch 29.129), train_loss = 0.84620011, grad/param norm = 2.0454e-01, time/batch = 15.1610s	
13371/22950 (epoch 29.131), train_loss = 0.91506109, grad/param norm = 2.2176e-01, time/batch = 15.3146s	
13372/22950 (epoch 29.133), train_loss = 0.96851778, grad/param norm = 2.2134e-01, time/batch = 15.0774s	
13373/22950 (epoch 29.135), train_loss = 0.92640539, grad/param norm = 2.0815e-01, time/batch = 15.2354s	
13374/22950 (epoch 29.137), train_loss = 1.03270418, grad/param norm = 2.8844e-01, time/batch = 15.2061s	
13375/22950 (epoch 29.139), train_loss = 0.84304275, grad/param norm = 2.3097e-01, time/batch = 14.7426s	
13376/22950 (epoch 29.142), train_loss = 0.83493592, grad/param norm = 2.1509e-01, time/batch = 14.7422s	
13377/22950 (epoch 29.144), train_loss = 0.89839241, grad/param norm = 2.2519e-01, time/batch = 14.9948s	
13378/22950 (epoch 29.146), train_loss = 0.88038277, grad/param norm = 2.5036e-01, time/batch = 14.8191s	
13379/22950 (epoch 29.148), train_loss = 0.88082775, grad/param norm = 2.3470e-01, time/batch = 14.8957s	
13380/22950 (epoch 29.150), train_loss = 0.93523709, grad/param norm = 2.3543e-01, time/batch = 14.5782s	
13381/22950 (epoch 29.153), train_loss = 0.86984790, grad/param norm = 2.1044e-01, time/batch = 14.7417s	
13382/22950 (epoch 29.155), train_loss = 0.86432161, grad/param norm = 2.0022e-01, time/batch = 14.7502s	
13383/22950 (epoch 29.157), train_loss = 0.91534692, grad/param norm = 2.0938e-01, time/batch = 14.5886s	
13384/22950 (epoch 29.159), train_loss = 0.84003394, grad/param norm = 2.0415e-01, time/batch = 14.5138s	
13385/22950 (epoch 29.161), train_loss = 0.90077872, grad/param norm = 2.3088e-01, time/batch = 14.6683s	
13386/22950 (epoch 29.163), train_loss = 0.83698102, grad/param norm = 3.4072e-01, time/batch = 15.0758s	
13387/22950 (epoch 29.166), train_loss = 1.00648126, grad/param norm = 3.0572e-01, time/batch = 15.3124s	
13388/22950 (epoch 29.168), train_loss = 0.97743945, grad/param norm = 3.0309e-01, time/batch = 16.2285s	
13389/22950 (epoch 29.170), train_loss = 0.90878023, grad/param norm = 2.3857e-01, time/batch = 15.6874s	
13390/22950 (epoch 29.172), train_loss = 0.94248255, grad/param norm = 2.1727e-01, time/batch = 14.9906s	
13391/22950 (epoch 29.174), train_loss = 1.00845323, grad/param norm = 2.5829e-01, time/batch = 15.3046s	
13392/22950 (epoch 29.176), train_loss = 1.01365608, grad/param norm = 2.6969e-01, time/batch = 15.0017s	
13393/22950 (epoch 29.179), train_loss = 0.97621874, grad/param norm = 2.7526e-01, time/batch = 15.1399s	
13394/22950 (epoch 29.181), train_loss = 1.16933527, grad/param norm = 2.7293e-01, time/batch = 14.8277s	
13395/22950 (epoch 29.183), train_loss = 0.98783817, grad/param norm = 2.3098e-01, time/batch = 14.7424s	
13396/22950 (epoch 29.185), train_loss = 0.96899903, grad/param norm = 2.3880e-01, time/batch = 15.1335s	
13397/22950 (epoch 29.187), train_loss = 0.85837857, grad/param norm = 2.3154e-01, time/batch = 14.9900s	
13398/22950 (epoch 29.190), train_loss = 0.77011694, grad/param norm = 2.0819e-01, time/batch = 15.8459s	
13399/22950 (epoch 29.192), train_loss = 0.74850944, grad/param norm = 2.0279e-01, time/batch = 15.9988s	
13400/22950 (epoch 29.194), train_loss = 0.90052018, grad/param norm = 2.3413e-01, time/batch = 15.6529s	
13401/22950 (epoch 29.196), train_loss = 0.70482191, grad/param norm = 2.2600e-01, time/batch = 15.1508s	
13402/22950 (epoch 29.198), train_loss = 0.96975240, grad/param norm = 2.4301e-01, time/batch = 15.4681s	
13403/22950 (epoch 29.200), train_loss = 0.85072603, grad/param norm = 2.0927e-01, time/batch = 14.9832s	
13404/22950 (epoch 29.203), train_loss = 0.81494030, grad/param norm = 2.2404e-01, time/batch = 14.8408s	
13405/22950 (epoch 29.205), train_loss = 0.86925431, grad/param norm = 2.1984e-01, time/batch = 14.5112s	
13406/22950 (epoch 29.207), train_loss = 0.94695821, grad/param norm = 2.6603e-01, time/batch = 0.6872s	
13407/22950 (epoch 29.209), train_loss = 0.90761500, grad/param norm = 2.4226e-01, time/batch = 0.6943s	
13408/22950 (epoch 29.211), train_loss = 0.77131358, grad/param norm = 2.1438e-01, time/batch = 0.6995s	
13409/22950 (epoch 29.214), train_loss = 0.84761747, grad/param norm = 2.1930e-01, time/batch = 0.6972s	
13410/22950 (epoch 29.216), train_loss = 1.00713842, grad/param norm = 2.3353e-01, time/batch = 0.7099s	
13411/22950 (epoch 29.218), train_loss = 0.91309646, grad/param norm = 2.2414e-01, time/batch = 0.7171s	
13412/22950 (epoch 29.220), train_loss = 1.00170461, grad/param norm = 3.0882e-01, time/batch = 0.6999s	
13413/22950 (epoch 29.222), train_loss = 1.01868735, grad/param norm = 2.4791e-01, time/batch = 1.0155s	
13414/22950 (epoch 29.224), train_loss = 0.92175019, grad/param norm = 2.2350e-01, time/batch = 1.0239s	
13415/22950 (epoch 29.227), train_loss = 0.97920301, grad/param norm = 2.3469e-01, time/batch = 1.0438s	
13416/22950 (epoch 29.229), train_loss = 1.02987818, grad/param norm = 2.4509e-01, time/batch = 1.0544s	
13417/22950 (epoch 29.231), train_loss = 0.78571105, grad/param norm = 2.2392e-01, time/batch = 1.1661s	
13418/22950 (epoch 29.233), train_loss = 0.87984701, grad/param norm = 2.3139e-01, time/batch = 1.9094s	
13419/22950 (epoch 29.235), train_loss = 1.05299677, grad/param norm = 2.2567e-01, time/batch = 1.9355s	
13420/22950 (epoch 29.237), train_loss = 0.87512010, grad/param norm = 2.4579e-01, time/batch = 9.4751s	
13421/22950 (epoch 29.240), train_loss = 0.92232242, grad/param norm = 2.5051e-01, time/batch = 15.2298s	
13422/22950 (epoch 29.242), train_loss = 1.05707915, grad/param norm = 2.4030e-01, time/batch = 15.1449s	
13423/22950 (epoch 29.244), train_loss = 1.02724069, grad/param norm = 2.6144e-01, time/batch = 14.9996s	
13424/22950 (epoch 29.246), train_loss = 1.03564602, grad/param norm = 2.3698e-01, time/batch = 15.2235s	
13425/22950 (epoch 29.248), train_loss = 0.93708502, grad/param norm = 2.2513e-01, time/batch = 15.1380s	
13426/22950 (epoch 29.251), train_loss = 0.86437399, grad/param norm = 2.2144e-01, time/batch = 15.0631s	
13427/22950 (epoch 29.253), train_loss = 0.88689453, grad/param norm = 2.6827e-01, time/batch = 15.0813s	
13428/22950 (epoch 29.255), train_loss = 0.95967339, grad/param norm = 2.3147e-01, time/batch = 15.0622s	
13429/22950 (epoch 29.257), train_loss = 1.00842011, grad/param norm = 2.5051e-01, time/batch = 14.8391s	
13430/22950 (epoch 29.259), train_loss = 0.79837921, grad/param norm = 2.2719e-01, time/batch = 15.1370s	
13431/22950 (epoch 29.261), train_loss = 0.88516536, grad/param norm = 2.2643e-01, time/batch = 15.2254s	
13432/22950 (epoch 29.264), train_loss = 0.82449920, grad/param norm = 2.0944e-01, time/batch = 14.8372s	
13433/22950 (epoch 29.266), train_loss = 0.92179162, grad/param norm = 2.5320e-01, time/batch = 15.2321s	
13434/22950 (epoch 29.268), train_loss = 0.92016822, grad/param norm = 2.4717e-01, time/batch = 15.8457s	
13435/22950 (epoch 29.270), train_loss = 0.91824236, grad/param norm = 2.5398e-01, time/batch = 15.1416s	
13436/22950 (epoch 29.272), train_loss = 0.94466707, grad/param norm = 2.3179e-01, time/batch = 16.0639s	
13437/22950 (epoch 29.275), train_loss = 0.86512790, grad/param norm = 2.4218e-01, time/batch = 15.9503s	
13438/22950 (epoch 29.277), train_loss = 0.77600752, grad/param norm = 1.9967e-01, time/batch = 15.1404s	
13439/22950 (epoch 29.279), train_loss = 0.82578726, grad/param norm = 2.4492e-01, time/batch = 16.1653s	
13440/22950 (epoch 29.281), train_loss = 0.87808672, grad/param norm = 2.2409e-01, time/batch = 14.9755s	
13441/22950 (epoch 29.283), train_loss = 0.80009843, grad/param norm = 1.9345e-01, time/batch = 15.4832s	
13442/22950 (epoch 29.285), train_loss = 0.92806522, grad/param norm = 2.0975e-01, time/batch = 16.4148s	
13443/22950 (epoch 29.288), train_loss = 1.02345058, grad/param norm = 2.3062e-01, time/batch = 14.9215s	
13444/22950 (epoch 29.290), train_loss = 0.87586476, grad/param norm = 2.4612e-01, time/batch = 15.7797s	
13445/22950 (epoch 29.292), train_loss = 1.01607375, grad/param norm = 2.6413e-01, time/batch = 15.3139s	
13446/22950 (epoch 29.294), train_loss = 0.93334953, grad/param norm = 2.2243e-01, time/batch = 15.3936s	
13447/22950 (epoch 29.296), train_loss = 0.72022239, grad/param norm = 1.8507e-01, time/batch = 15.0790s	
13448/22950 (epoch 29.298), train_loss = 0.91186272, grad/param norm = 2.1976e-01, time/batch = 14.5009s	
13449/22950 (epoch 29.301), train_loss = 0.95528220, grad/param norm = 2.5145e-01, time/batch = 14.4258s	
13450/22950 (epoch 29.303), train_loss = 0.91673664, grad/param norm = 2.2820e-01, time/batch = 14.9718s	
13451/22950 (epoch 29.305), train_loss = 0.90678853, grad/param norm = 2.5509e-01, time/batch = 14.7502s	
13452/22950 (epoch 29.307), train_loss = 1.03632960, grad/param norm = 2.6332e-01, time/batch = 15.2381s	
13453/22950 (epoch 29.309), train_loss = 0.86159390, grad/param norm = 2.0635e-01, time/batch = 15.0530s	
13454/22950 (epoch 29.312), train_loss = 0.91783767, grad/param norm = 2.0937e-01, time/batch = 15.3836s	
13455/22950 (epoch 29.314), train_loss = 0.92097866, grad/param norm = 2.0936e-01, time/batch = 15.0761s	
13456/22950 (epoch 29.316), train_loss = 0.90193584, grad/param norm = 2.5097e-01, time/batch = 14.8331s	
13457/22950 (epoch 29.318), train_loss = 0.78037629, grad/param norm = 1.7920e-01, time/batch = 15.3185s	
13458/22950 (epoch 29.320), train_loss = 0.83877653, grad/param norm = 1.9986e-01, time/batch = 15.7706s	
13459/22950 (epoch 29.322), train_loss = 0.86864602, grad/param norm = 2.5028e-01, time/batch = 15.1949s	
13460/22950 (epoch 29.325), train_loss = 0.74706518, grad/param norm = 2.1676e-01, time/batch = 14.4159s	
13461/22950 (epoch 29.327), train_loss = 0.74117123, grad/param norm = 2.1650e-01, time/batch = 14.3377s	
13462/22950 (epoch 29.329), train_loss = 0.84954233, grad/param norm = 2.1671e-01, time/batch = 14.7432s	
13463/22950 (epoch 29.331), train_loss = 0.80874733, grad/param norm = 2.1350e-01, time/batch = 15.0426s	
13464/22950 (epoch 29.333), train_loss = 0.84276079, grad/param norm = 2.1549e-01, time/batch = 14.7166s	
13465/22950 (epoch 29.336), train_loss = 0.90414440, grad/param norm = 2.5558e-01, time/batch = 14.9758s	
13466/22950 (epoch 29.338), train_loss = 0.91621901, grad/param norm = 2.2652e-01, time/batch = 16.4059s	
13467/22950 (epoch 29.340), train_loss = 0.89053833, grad/param norm = 2.4694e-01, time/batch = 15.9378s	
13468/22950 (epoch 29.342), train_loss = 1.04694152, grad/param norm = 2.3376e-01, time/batch = 15.5250s	
13469/22950 (epoch 29.344), train_loss = 0.87835978, grad/param norm = 2.2989e-01, time/batch = 15.5825s	
13470/22950 (epoch 29.346), train_loss = 0.99392698, grad/param norm = 2.4889e-01, time/batch = 15.4676s	
13471/22950 (epoch 29.349), train_loss = 0.89664639, grad/param norm = 2.1891e-01, time/batch = 15.1995s	
13472/22950 (epoch 29.351), train_loss = 0.91859021, grad/param norm = 2.2498e-01, time/batch = 14.8078s	
13473/22950 (epoch 29.353), train_loss = 0.96619869, grad/param norm = 2.6903e-01, time/batch = 15.3622s	
13474/22950 (epoch 29.355), train_loss = 1.02426631, grad/param norm = 2.6197e-01, time/batch = 15.2034s	
13475/22950 (epoch 29.357), train_loss = 0.91531389, grad/param norm = 2.5286e-01, time/batch = 14.5715s	
13476/22950 (epoch 29.359), train_loss = 0.91230035, grad/param norm = 2.5569e-01, time/batch = 14.5761s	
13477/22950 (epoch 29.362), train_loss = 0.95113496, grad/param norm = 2.3099e-01, time/batch = 21.4668s	
13478/22950 (epoch 29.364), train_loss = 0.89550149, grad/param norm = 2.2944e-01, time/batch = 25.4988s	
13479/22950 (epoch 29.366), train_loss = 0.90582080, grad/param norm = 2.2300e-01, time/batch = 19.3872s	
13480/22950 (epoch 29.368), train_loss = 0.99310782, grad/param norm = 2.6139e-01, time/batch = 16.1234s	
13481/22950 (epoch 29.370), train_loss = 0.88227629, grad/param norm = 2.3091e-01, time/batch = 18.4758s	
13482/22950 (epoch 29.373), train_loss = 0.82099484, grad/param norm = 2.1301e-01, time/batch = 17.8753s	
13483/22950 (epoch 29.375), train_loss = 1.02366943, grad/param norm = 2.4867e-01, time/batch = 16.4849s	
13484/22950 (epoch 29.377), train_loss = 0.83074884, grad/param norm = 2.4892e-01, time/batch = 16.6548s	
13485/22950 (epoch 29.379), train_loss = 0.92787505, grad/param norm = 2.5062e-01, time/batch = 16.9100s	
13486/22950 (epoch 29.381), train_loss = 0.80624006, grad/param norm = 2.2745e-01, time/batch = 16.2554s	
13487/22950 (epoch 29.383), train_loss = 0.90616471, grad/param norm = 2.3504e-01, time/batch = 16.7076s	
13488/22950 (epoch 29.386), train_loss = 0.85713896, grad/param norm = 2.3804e-01, time/batch = 16.6323s	
13489/22950 (epoch 29.388), train_loss = 0.96996386, grad/param norm = 2.3981e-01, time/batch = 19.1998s	
13490/22950 (epoch 29.390), train_loss = 0.80533621, grad/param norm = 2.3665e-01, time/batch = 18.0286s	
13491/22950 (epoch 29.392), train_loss = 0.85049758, grad/param norm = 2.5919e-01, time/batch = 19.0382s	
13492/22950 (epoch 29.394), train_loss = 0.87113399, grad/param norm = 2.1337e-01, time/batch = 19.3008s	
13493/22950 (epoch 29.397), train_loss = 1.02874721, grad/param norm = 2.2640e-01, time/batch = 18.6319s	
13494/22950 (epoch 29.399), train_loss = 1.01779797, grad/param norm = 2.4975e-01, time/batch = 17.2776s	
13495/22950 (epoch 29.401), train_loss = 1.07216376, grad/param norm = 2.7943e-01, time/batch = 18.8746s	
13496/22950 (epoch 29.403), train_loss = 0.89963136, grad/param norm = 2.6467e-01, time/batch = 19.5340s	
13497/22950 (epoch 29.405), train_loss = 1.01655356, grad/param norm = 2.9244e-01, time/batch = 17.1886s	
13498/22950 (epoch 29.407), train_loss = 1.06162775, grad/param norm = 2.2220e-01, time/batch = 16.6119s	
13499/22950 (epoch 29.410), train_loss = 0.89752800, grad/param norm = 2.3538e-01, time/batch = 16.7525s	
13500/22950 (epoch 29.412), train_loss = 0.91489583, grad/param norm = 2.5094e-01, time/batch = 18.2952s	
13501/22950 (epoch 29.414), train_loss = 1.01391773, grad/param norm = 2.5295e-01, time/batch = 20.6822s	
13502/22950 (epoch 29.416), train_loss = 0.95502614, grad/param norm = 2.8981e-01, time/batch = 17.5503s	
13503/22950 (epoch 29.418), train_loss = 0.92559321, grad/param norm = 2.6486e-01, time/batch = 16.8497s	
13504/22950 (epoch 29.420), train_loss = 1.02520521, grad/param norm = 2.6996e-01, time/batch = 17.0129s	
13505/22950 (epoch 29.423), train_loss = 0.86969090, grad/param norm = 2.5083e-01, time/batch = 19.3876s	
13506/22950 (epoch 29.425), train_loss = 0.90029019, grad/param norm = 2.2323e-01, time/batch = 17.8712s	
13507/22950 (epoch 29.427), train_loss = 0.93128724, grad/param norm = 2.4493e-01, time/batch = 16.7361s	
13508/22950 (epoch 29.429), train_loss = 0.90459744, grad/param norm = 2.2816e-01, time/batch = 15.4929s	
13509/22950 (epoch 29.431), train_loss = 1.00487942, grad/param norm = 2.4766e-01, time/batch = 18.5503s	
13510/22950 (epoch 29.434), train_loss = 0.91962163, grad/param norm = 2.2620e-01, time/batch = 17.6223s	
13511/22950 (epoch 29.436), train_loss = 0.99908719, grad/param norm = 2.6662e-01, time/batch = 15.9471s	
13512/22950 (epoch 29.438), train_loss = 0.93341967, grad/param norm = 2.2983e-01, time/batch = 18.6134s	
13513/22950 (epoch 29.440), train_loss = 1.00652847, grad/param norm = 2.3249e-01, time/batch = 18.7876s	
13514/22950 (epoch 29.442), train_loss = 1.06434776, grad/param norm = 2.5340e-01, time/batch = 18.9317s	
13515/22950 (epoch 29.444), train_loss = 0.98699018, grad/param norm = 2.4655e-01, time/batch = 17.3788s	
13516/22950 (epoch 29.447), train_loss = 1.08292364, grad/param norm = 2.4244e-01, time/batch = 16.4501s	
13517/22950 (epoch 29.449), train_loss = 0.84342853, grad/param norm = 2.2555e-01, time/batch = 18.1903s	
13518/22950 (epoch 29.451), train_loss = 0.94471407, grad/param norm = 2.4143e-01, time/batch = 17.9663s	
13519/22950 (epoch 29.453), train_loss = 0.97160024, grad/param norm = 2.2278e-01, time/batch = 20.1210s	
13520/22950 (epoch 29.455), train_loss = 0.88474789, grad/param norm = 1.9477e-01, time/batch = 18.6972s	
13521/22950 (epoch 29.458), train_loss = 0.96931285, grad/param norm = 2.5074e-01, time/batch = 18.4533s	
13522/22950 (epoch 29.460), train_loss = 0.99939137, grad/param norm = 2.4279e-01, time/batch = 18.5415s	
13523/22950 (epoch 29.462), train_loss = 0.94759271, grad/param norm = 2.2561e-01, time/batch = 16.7676s	
13524/22950 (epoch 29.464), train_loss = 0.90306916, grad/param norm = 2.3915e-01, time/batch = 18.6206s	
13525/22950 (epoch 29.466), train_loss = 1.01553983, grad/param norm = 2.4711e-01, time/batch = 16.8980s	
13526/22950 (epoch 29.468), train_loss = 1.00747444, grad/param norm = 2.4291e-01, time/batch = 15.8211s	
13527/22950 (epoch 29.471), train_loss = 0.97863140, grad/param norm = 2.5208e-01, time/batch = 17.1617s	
13528/22950 (epoch 29.473), train_loss = 0.97581306, grad/param norm = 2.2832e-01, time/batch = 16.1688s	
13529/22950 (epoch 29.475), train_loss = 1.12602114, grad/param norm = 2.4675e-01, time/batch = 16.3532s	
13530/22950 (epoch 29.477), train_loss = 0.92265480, grad/param norm = 2.4273e-01, time/batch = 17.1236s	
13531/22950 (epoch 29.479), train_loss = 0.83005776, grad/param norm = 2.0550e-01, time/batch = 18.6853s	
13532/22950 (epoch 29.481), train_loss = 1.01272866, grad/param norm = 2.8124e-01, time/batch = 17.3760s	
13533/22950 (epoch 29.484), train_loss = 0.97245769, grad/param norm = 2.5425e-01, time/batch = 18.7980s	
13534/22950 (epoch 29.486), train_loss = 0.80313160, grad/param norm = 2.2547e-01, time/batch = 18.6036s	
13535/22950 (epoch 29.488), train_loss = 0.87822097, grad/param norm = 2.7614e-01, time/batch = 18.2184s	
13536/22950 (epoch 29.490), train_loss = 0.81207169, grad/param norm = 2.3655e-01, time/batch = 18.7175s	
13537/22950 (epoch 29.492), train_loss = 0.89411257, grad/param norm = 2.2857e-01, time/batch = 18.4543s	
13538/22950 (epoch 29.495), train_loss = 0.87257682, grad/param norm = 2.3197e-01, time/batch = 19.4526s	
13539/22950 (epoch 29.497), train_loss = 0.99227007, grad/param norm = 2.6397e-01, time/batch = 16.0293s	
13540/22950 (epoch 29.499), train_loss = 1.06465175, grad/param norm = 2.2909e-01, time/batch = 16.9196s	
13541/22950 (epoch 29.501), train_loss = 0.96936301, grad/param norm = 2.5884e-01, time/batch = 19.3646s	
13542/22950 (epoch 29.503), train_loss = 1.02028016, grad/param norm = 2.4239e-01, time/batch = 17.8055s	
13543/22950 (epoch 29.505), train_loss = 0.79613907, grad/param norm = 1.9517e-01, time/batch = 18.2274s	
13544/22950 (epoch 29.508), train_loss = 0.97149296, grad/param norm = 2.2808e-01, time/batch = 17.1046s	
13545/22950 (epoch 29.510), train_loss = 0.91536455, grad/param norm = 2.4008e-01, time/batch = 17.2808s	
13546/22950 (epoch 29.512), train_loss = 0.82462237, grad/param norm = 2.4880e-01, time/batch = 16.9463s	
13547/22950 (epoch 29.514), train_loss = 0.88555485, grad/param norm = 1.9922e-01, time/batch = 16.7402s	
13548/22950 (epoch 29.516), train_loss = 0.90234462, grad/param norm = 2.1782e-01, time/batch = 17.1916s	
13549/22950 (epoch 29.519), train_loss = 0.91701740, grad/param norm = 2.4230e-01, time/batch = 17.6095s	
13550/22950 (epoch 29.521), train_loss = 0.93154158, grad/param norm = 2.3835e-01, time/batch = 19.2896s	
13551/22950 (epoch 29.523), train_loss = 0.75681658, grad/param norm = 2.2067e-01, time/batch = 17.9725s	
13552/22950 (epoch 29.525), train_loss = 0.84560998, grad/param norm = 2.2890e-01, time/batch = 19.3829s	
13553/22950 (epoch 29.527), train_loss = 0.79828366, grad/param norm = 2.1890e-01, time/batch = 20.0383s	
13554/22950 (epoch 29.529), train_loss = 0.92118247, grad/param norm = 2.1249e-01, time/batch = 16.2167s	
13555/22950 (epoch 29.532), train_loss = 0.88594799, grad/param norm = 2.2557e-01, time/batch = 15.1970s	
13556/22950 (epoch 29.534), train_loss = 0.96759556, grad/param norm = 2.3958e-01, time/batch = 15.7151s	
13557/22950 (epoch 29.536), train_loss = 0.97483359, grad/param norm = 2.5773e-01, time/batch = 18.1063s	
13558/22950 (epoch 29.538), train_loss = 0.93253154, grad/param norm = 2.4494e-01, time/batch = 17.9611s	
13559/22950 (epoch 29.540), train_loss = 0.98720566, grad/param norm = 3.1714e-01, time/batch = 18.8565s	
13560/22950 (epoch 29.542), train_loss = 1.07711816, grad/param norm = 2.7691e-01, time/batch = 18.7988s	
13561/22950 (epoch 29.545), train_loss = 0.88868604, grad/param norm = 2.1968e-01, time/batch = 18.2870s	
13562/22950 (epoch 29.547), train_loss = 0.92764889, grad/param norm = 2.3962e-01, time/batch = 17.5596s	
13563/22950 (epoch 29.549), train_loss = 0.84984646, grad/param norm = 2.5017e-01, time/batch = 19.4564s	
13564/22950 (epoch 29.551), train_loss = 0.89783411, grad/param norm = 2.3755e-01, time/batch = 17.6205s	
13565/22950 (epoch 29.553), train_loss = 0.87652720, grad/param norm = 2.7085e-01, time/batch = 17.2953s	
13566/22950 (epoch 29.556), train_loss = 0.94922286, grad/param norm = 2.2170e-01, time/batch = 19.3021s	
13567/22950 (epoch 29.558), train_loss = 0.78054664, grad/param norm = 2.2156e-01, time/batch = 18.1312s	
13568/22950 (epoch 29.560), train_loss = 0.89882128, grad/param norm = 2.6940e-01, time/batch = 19.2994s	
13569/22950 (epoch 29.562), train_loss = 0.84727075, grad/param norm = 2.0437e-01, time/batch = 16.0127s	
13570/22950 (epoch 29.564), train_loss = 0.95386108, grad/param norm = 2.4564e-01, time/batch = 17.1884s	
13571/22950 (epoch 29.566), train_loss = 0.94588559, grad/param norm = 2.2681e-01, time/batch = 16.9733s	
13572/22950 (epoch 29.569), train_loss = 0.93039333, grad/param norm = 2.4565e-01, time/batch = 16.1746s	
13573/22950 (epoch 29.571), train_loss = 0.89904836, grad/param norm = 2.6097e-01, time/batch = 16.0936s	
13574/22950 (epoch 29.573), train_loss = 0.92349590, grad/param norm = 2.3961e-01, time/batch = 16.6139s	
13575/22950 (epoch 29.575), train_loss = 1.02608432, grad/param norm = 2.7510e-01, time/batch = 15.5166s	
13576/22950 (epoch 29.577), train_loss = 0.93968797, grad/param norm = 2.7118e-01, time/batch = 14.7505s	
13577/22950 (epoch 29.580), train_loss = 0.99251054, grad/param norm = 2.4912e-01, time/batch = 14.7365s	
13578/22950 (epoch 29.582), train_loss = 1.07777694, grad/param norm = 2.6033e-01, time/batch = 15.4659s	
13579/22950 (epoch 29.584), train_loss = 0.80645130, grad/param norm = 2.3353e-01, time/batch = 14.9661s	
13580/22950 (epoch 29.586), train_loss = 0.84053515, grad/param norm = 2.2125e-01, time/batch = 14.5059s	
13581/22950 (epoch 29.588), train_loss = 1.06081652, grad/param norm = 2.5337e-01, time/batch = 15.0627s	
13582/22950 (epoch 29.590), train_loss = 0.97312270, grad/param norm = 2.5124e-01, time/batch = 14.9912s	
13583/22950 (epoch 29.593), train_loss = 0.91130077, grad/param norm = 2.3603e-01, time/batch = 15.0642s	
13584/22950 (epoch 29.595), train_loss = 0.83246327, grad/param norm = 2.4870e-01, time/batch = 15.6860s	
13585/22950 (epoch 29.597), train_loss = 1.01204090, grad/param norm = 2.5023e-01, time/batch = 14.6608s	
13586/22950 (epoch 29.599), train_loss = 0.94272263, grad/param norm = 2.7296e-01, time/batch = 14.7397s	
13587/22950 (epoch 29.601), train_loss = 0.95944696, grad/param norm = 2.4813e-01, time/batch = 14.7371s	
13588/22950 (epoch 29.603), train_loss = 1.03720271, grad/param norm = 2.2984e-01, time/batch = 14.4348s	
13589/22950 (epoch 29.606), train_loss = 0.93720363, grad/param norm = 2.4362e-01, time/batch = 14.5918s	
13590/22950 (epoch 29.608), train_loss = 0.95353431, grad/param norm = 2.4085e-01, time/batch = 14.9068s	
13591/22950 (epoch 29.610), train_loss = 0.94065322, grad/param norm = 2.4084e-01, time/batch = 14.5870s	
13592/22950 (epoch 29.612), train_loss = 0.92929610, grad/param norm = 2.3118e-01, time/batch = 14.7419s	
13593/22950 (epoch 29.614), train_loss = 1.04529945, grad/param norm = 2.7524e-01, time/batch = 14.8986s	
13594/22950 (epoch 29.617), train_loss = 0.91859768, grad/param norm = 2.2030e-01, time/batch = 15.8992s	
13595/22950 (epoch 29.619), train_loss = 0.88544792, grad/param norm = 2.1484e-01, time/batch = 15.3154s	
13596/22950 (epoch 29.621), train_loss = 0.99813148, grad/param norm = 2.2502e-01, time/batch = 14.9148s	
13597/22950 (epoch 29.623), train_loss = 0.99500941, grad/param norm = 2.4725e-01, time/batch = 14.8971s	
13598/22950 (epoch 29.625), train_loss = 0.91878759, grad/param norm = 2.5187e-01, time/batch = 15.3103s	
13599/22950 (epoch 29.627), train_loss = 0.91055614, grad/param norm = 2.5109e-01, time/batch = 15.1956s	
13600/22950 (epoch 29.630), train_loss = 0.80673530, grad/param norm = 1.9662e-01, time/batch = 14.9127s	
13601/22950 (epoch 29.632), train_loss = 0.87496392, grad/param norm = 2.6327e-01, time/batch = 14.9811s	
13602/22950 (epoch 29.634), train_loss = 0.95759955, grad/param norm = 2.4355e-01, time/batch = 15.3671s	
13603/22950 (epoch 29.636), train_loss = 0.95001141, grad/param norm = 2.5925e-01, time/batch = 14.6604s	
13604/22950 (epoch 29.638), train_loss = 0.88376108, grad/param norm = 2.4861e-01, time/batch = 14.8217s	
13605/22950 (epoch 29.641), train_loss = 0.90336210, grad/param norm = 2.2027e-01, time/batch = 14.5003s	
13606/22950 (epoch 29.643), train_loss = 0.98019463, grad/param norm = 2.7515e-01, time/batch = 14.8131s	
13607/22950 (epoch 29.645), train_loss = 0.88200325, grad/param norm = 2.2186e-01, time/batch = 14.8313s	
13608/22950 (epoch 29.647), train_loss = 0.90948808, grad/param norm = 2.8154e-01, time/batch = 14.9936s	
13609/22950 (epoch 29.649), train_loss = 0.88160999, grad/param norm = 2.1891e-01, time/batch = 14.6748s	
13610/22950 (epoch 29.651), train_loss = 1.01627961, grad/param norm = 2.7500e-01, time/batch = 15.5378s	
13611/22950 (epoch 29.654), train_loss = 0.78829385, grad/param norm = 2.0169e-01, time/batch = 15.2277s	
13612/22950 (epoch 29.656), train_loss = 0.98324670, grad/param norm = 4.4479e-01, time/batch = 14.8339s	
13613/22950 (epoch 29.658), train_loss = 0.86854556, grad/param norm = 2.6914e-01, time/batch = 14.7493s	
13614/22950 (epoch 29.660), train_loss = 0.74173094, grad/param norm = 2.2195e-01, time/batch = 15.3102s	
13615/22950 (epoch 29.662), train_loss = 0.76256578, grad/param norm = 2.2538e-01, time/batch = 14.9730s	
13616/22950 (epoch 29.664), train_loss = 0.90624950, grad/param norm = 2.7526e-01, time/batch = 15.7571s	
13617/22950 (epoch 29.667), train_loss = 0.94011640, grad/param norm = 2.5287e-01, time/batch = 14.8226s	
13618/22950 (epoch 29.669), train_loss = 0.92063638, grad/param norm = 2.3807e-01, time/batch = 15.2886s	
13619/22950 (epoch 29.671), train_loss = 0.93036049, grad/param norm = 2.4774e-01, time/batch = 14.7474s	
13620/22950 (epoch 29.673), train_loss = 0.86367467, grad/param norm = 2.6619e-01, time/batch = 14.9097s	
13621/22950 (epoch 29.675), train_loss = 0.93784532, grad/param norm = 2.6157e-01, time/batch = 14.9192s	
13622/22950 (epoch 29.678), train_loss = 0.91841107, grad/param norm = 2.4078e-01, time/batch = 16.0595s	
13623/22950 (epoch 29.680), train_loss = 0.93956324, grad/param norm = 2.0492e-01, time/batch = 14.9800s	
13624/22950 (epoch 29.682), train_loss = 0.90398233, grad/param norm = 2.5863e-01, time/batch = 15.2839s	
13625/22950 (epoch 29.684), train_loss = 1.00518744, grad/param norm = 2.6551e-01, time/batch = 14.6772s	
13626/22950 (epoch 29.686), train_loss = 1.01101399, grad/param norm = 2.3442e-01, time/batch = 15.1382s	
13627/22950 (epoch 29.688), train_loss = 0.94027525, grad/param norm = 2.3404e-01, time/batch = 15.4670s	
13628/22950 (epoch 29.691), train_loss = 0.90718764, grad/param norm = 2.4124e-01, time/batch = 15.1916s	
13629/22950 (epoch 29.693), train_loss = 0.84323440, grad/param norm = 2.3676e-01, time/batch = 14.8334s	
13630/22950 (epoch 29.695), train_loss = 1.01929577, grad/param norm = 2.6383e-01, time/batch = 15.2113s	
13631/22950 (epoch 29.697), train_loss = 0.98255349, grad/param norm = 3.2501e-01, time/batch = 14.8400s	
13632/22950 (epoch 29.699), train_loss = 0.98416396, grad/param norm = 2.6498e-01, time/batch = 14.7587s	
13633/22950 (epoch 29.702), train_loss = 0.99740838, grad/param norm = 2.7402e-01, time/batch = 14.5973s	
13634/22950 (epoch 29.704), train_loss = 1.05715979, grad/param norm = 2.5433e-01, time/batch = 15.3683s	
13635/22950 (epoch 29.706), train_loss = 1.01526058, grad/param norm = 2.6169e-01, time/batch = 14.6690s	
13636/22950 (epoch 29.708), train_loss = 0.84888111, grad/param norm = 2.9504e-01, time/batch = 14.9850s	
13637/22950 (epoch 29.710), train_loss = 0.93176313, grad/param norm = 2.5528e-01, time/batch = 14.7473s	
13638/22950 (epoch 29.712), train_loss = 1.06982058, grad/param norm = 3.1370e-01, time/batch = 15.2190s	
13639/22950 (epoch 29.715), train_loss = 0.94123435, grad/param norm = 2.6776e-01, time/batch = 14.8178s	
13640/22950 (epoch 29.717), train_loss = 0.97711836, grad/param norm = 2.1517e-01, time/batch = 14.7602s	
13641/22950 (epoch 29.719), train_loss = 0.88396080, grad/param norm = 2.6666e-01, time/batch = 14.7597s	
13642/22950 (epoch 29.721), train_loss = 0.98055115, grad/param norm = 2.5222e-01, time/batch = 15.3745s	
13643/22950 (epoch 29.723), train_loss = 0.93577094, grad/param norm = 2.4711e-01, time/batch = 15.3927s	
13644/22950 (epoch 29.725), train_loss = 0.99949155, grad/param norm = 2.7885e-01, time/batch = 15.8975s	
13645/22950 (epoch 29.728), train_loss = 0.90819469, grad/param norm = 3.0236e-01, time/batch = 15.3845s	
13646/22950 (epoch 29.730), train_loss = 0.91906849, grad/param norm = 2.3931e-01, time/batch = 15.9091s	
13647/22950 (epoch 29.732), train_loss = 1.00768898, grad/param norm = 2.8480e-01, time/batch = 15.4435s	
13648/22950 (epoch 29.734), train_loss = 0.91545880, grad/param norm = 2.5888e-01, time/batch = 15.0745s	
13649/22950 (epoch 29.736), train_loss = 0.95317499, grad/param norm = 2.3989e-01, time/batch = 15.0681s	
13650/22950 (epoch 29.739), train_loss = 0.98945240, grad/param norm = 2.6215e-01, time/batch = 15.0575s	
13651/22950 (epoch 29.741), train_loss = 1.00714464, grad/param norm = 2.9587e-01, time/batch = 14.8403s	
13652/22950 (epoch 29.743), train_loss = 1.07518799, grad/param norm = 3.2221e-01, time/batch = 15.3796s	
13653/22950 (epoch 29.745), train_loss = 1.18542055, grad/param norm = 3.2652e-01, time/batch = 15.6052s	
13654/22950 (epoch 29.747), train_loss = 0.95569271, grad/param norm = 2.6144e-01, time/batch = 15.0691s	
13655/22950 (epoch 29.749), train_loss = 0.88294732, grad/param norm = 2.5379e-01, time/batch = 14.9182s	
13656/22950 (epoch 29.752), train_loss = 1.12995649, grad/param norm = 2.9663e-01, time/batch = 14.9082s	
13657/22950 (epoch 29.754), train_loss = 0.99762240, grad/param norm = 2.5652e-01, time/batch = 15.3122s	
13658/22950 (epoch 29.756), train_loss = 0.88528811, grad/param norm = 2.3424e-01, time/batch = 15.1552s	
13659/22950 (epoch 29.758), train_loss = 0.94707160, grad/param norm = 2.1806e-01, time/batch = 14.9134s	
13660/22950 (epoch 29.760), train_loss = 0.97785183, grad/param norm = 2.6754e-01, time/batch = 14.7478s	
13661/22950 (epoch 29.763), train_loss = 1.00103745, grad/param norm = 2.7924e-01, time/batch = 15.4613s	
13662/22950 (epoch 29.765), train_loss = 0.93747638, grad/param norm = 2.4543e-01, time/batch = 15.2972s	
13663/22950 (epoch 29.767), train_loss = 1.15111941, grad/param norm = 2.8500e-01, time/batch = 15.3837s	
13664/22950 (epoch 29.769), train_loss = 0.98325307, grad/param norm = 2.4035e-01, time/batch = 14.7989s	
13665/22950 (epoch 29.771), train_loss = 0.81442111, grad/param norm = 2.4985e-01, time/batch = 15.1621s	
13666/22950 (epoch 29.773), train_loss = 0.73203461, grad/param norm = 2.0788e-01, time/batch = 15.0808s	
13667/22950 (epoch 29.776), train_loss = 0.87173343, grad/param norm = 2.2160e-01, time/batch = 15.4695s	
13668/22950 (epoch 29.778), train_loss = 0.86568061, grad/param norm = 2.2333e-01, time/batch = 16.3826s	
13669/22950 (epoch 29.780), train_loss = 0.94824139, grad/param norm = 2.1705e-01, time/batch = 16.0633s	
13670/22950 (epoch 29.782), train_loss = 0.99826187, grad/param norm = 2.3506e-01, time/batch = 15.3815s	
13671/22950 (epoch 29.784), train_loss = 0.88728354, grad/param norm = 2.3325e-01, time/batch = 14.9948s	
13672/22950 (epoch 29.786), train_loss = 0.93638446, grad/param norm = 2.3695e-01, time/batch = 14.7555s	
13673/22950 (epoch 29.789), train_loss = 0.79717065, grad/param norm = 2.2833e-01, time/batch = 15.2320s	
13674/22950 (epoch 29.791), train_loss = 0.85832502, grad/param norm = 2.4068e-01, time/batch = 15.1505s	
13675/22950 (epoch 29.793), train_loss = 1.04362290, grad/param norm = 2.6436e-01, time/batch = 14.9102s	
13676/22950 (epoch 29.795), train_loss = 0.90869371, grad/param norm = 2.2016e-01, time/batch = 14.5893s	
13677/22950 (epoch 29.797), train_loss = 1.06110078, grad/param norm = 2.5982e-01, time/batch = 15.5435s	
13678/22950 (epoch 29.800), train_loss = 0.85369469, grad/param norm = 2.2913e-01, time/batch = 14.8215s	
13679/22950 (epoch 29.802), train_loss = 0.88589394, grad/param norm = 2.4250e-01, time/batch = 15.1237s	
13680/22950 (epoch 29.804), train_loss = 0.89304948, grad/param norm = 2.2898e-01, time/batch = 14.7687s	
13681/22950 (epoch 29.806), train_loss = 0.80883605, grad/param norm = 2.1759e-01, time/batch = 15.0732s	
13682/22950 (epoch 29.808), train_loss = 0.92345597, grad/param norm = 2.4399e-01, time/batch = 14.9043s	
13683/22950 (epoch 29.810), train_loss = 0.89087950, grad/param norm = 2.3313e-01, time/batch = 15.2976s	
13684/22950 (epoch 29.813), train_loss = 0.76271424, grad/param norm = 2.0885e-01, time/batch = 14.8192s	
13685/22950 (epoch 29.815), train_loss = 0.74773403, grad/param norm = 2.3013e-01, time/batch = 15.1461s	
13686/22950 (epoch 29.817), train_loss = 0.84741282, grad/param norm = 2.2058e-01, time/batch = 14.8233s	
13687/22950 (epoch 29.819), train_loss = 0.90921760, grad/param norm = 2.2751e-01, time/batch = 15.1277s	
13688/22950 (epoch 29.821), train_loss = 0.89145899, grad/param norm = 2.5631e-01, time/batch = 15.4419s	
13689/22950 (epoch 29.824), train_loss = 0.93638595, grad/param norm = 2.3508e-01, time/batch = 15.2256s	
13690/22950 (epoch 29.826), train_loss = 0.97097120, grad/param norm = 2.6700e-01, time/batch = 15.2327s	
13691/22950 (epoch 29.828), train_loss = 0.90335735, grad/param norm = 2.4428e-01, time/batch = 15.8509s	
13692/22950 (epoch 29.830), train_loss = 0.88229081, grad/param norm = 2.4457e-01, time/batch = 14.6756s	
13693/22950 (epoch 29.832), train_loss = 0.92020156, grad/param norm = 2.4344e-01, time/batch = 15.6148s	
13694/22950 (epoch 29.834), train_loss = 0.78220729, grad/param norm = 2.3157e-01, time/batch = 14.7504s	
13695/22950 (epoch 29.837), train_loss = 0.92214110, grad/param norm = 2.5097e-01, time/batch = 16.7913s	
13696/22950 (epoch 29.839), train_loss = 0.78424851, grad/param norm = 2.3522e-01, time/batch = 20.2240s	
13697/22950 (epoch 29.841), train_loss = 0.85821312, grad/param norm = 2.0985e-01, time/batch = 29.2338s	
13698/22950 (epoch 29.843), train_loss = 0.86155358, grad/param norm = 2.3653e-01, time/batch = 15.9928s	
13699/22950 (epoch 29.845), train_loss = 0.91521673, grad/param norm = 2.6996e-01, time/batch = 16.4347s	
13700/22950 (epoch 29.847), train_loss = 0.95729578, grad/param norm = 2.4490e-01, time/batch = 15.7814s	
13701/22950 (epoch 29.850), train_loss = 1.00085524, grad/param norm = 2.7482e-01, time/batch = 15.2959s	
13702/22950 (epoch 29.852), train_loss = 0.98802859, grad/param norm = 2.6436e-01, time/batch = 14.6659s	
13703/22950 (epoch 29.854), train_loss = 0.92505715, grad/param norm = 2.3260e-01, time/batch = 15.1475s	
13704/22950 (epoch 29.856), train_loss = 1.06584041, grad/param norm = 2.8664e-01, time/batch = 15.0560s	
13705/22950 (epoch 29.858), train_loss = 0.97697829, grad/param norm = 2.3444e-01, time/batch = 15.6176s	
13706/22950 (epoch 29.861), train_loss = 0.98473365, grad/param norm = 2.4064e-01, time/batch = 14.8243s	
13707/22950 (epoch 29.863), train_loss = 1.01733508, grad/param norm = 2.4238e-01, time/batch = 15.0497s	
13708/22950 (epoch 29.865), train_loss = 1.05508492, grad/param norm = 2.5067e-01, time/batch = 14.9063s	
13709/22950 (epoch 29.867), train_loss = 0.94792792, grad/param norm = 2.2509e-01, time/batch = 15.0620s	
13710/22950 (epoch 29.869), train_loss = 1.08731161, grad/param norm = 2.7328e-01, time/batch = 14.8231s	
13711/22950 (epoch 29.871), train_loss = 0.95124595, grad/param norm = 2.3161e-01, time/batch = 16.0210s	
13712/22950 (epoch 29.874), train_loss = 0.96750362, grad/param norm = 2.3108e-01, time/batch = 15.7580s	
13713/22950 (epoch 29.876), train_loss = 1.02447566, grad/param norm = 2.7548e-01, time/batch = 14.6656s	
13714/22950 (epoch 29.878), train_loss = 0.91291260, grad/param norm = 2.6122e-01, time/batch = 14.5665s	
13715/22950 (epoch 29.880), train_loss = 1.12115078, grad/param norm = 2.6966e-01, time/batch = 15.5417s	
13716/22950 (epoch 29.882), train_loss = 0.83285690, grad/param norm = 2.3487e-01, time/batch = 14.8720s	
13717/22950 (epoch 29.885), train_loss = 0.97377577, grad/param norm = 2.5022e-01, time/batch = 14.7542s	
13718/22950 (epoch 29.887), train_loss = 0.92061077, grad/param norm = 2.0907e-01, time/batch = 14.8275s	
13719/22950 (epoch 29.889), train_loss = 0.98101445, grad/param norm = 2.4719e-01, time/batch = 15.1372s	
13720/22950 (epoch 29.891), train_loss = 0.88144988, grad/param norm = 2.5078e-01, time/batch = 14.4994s	
13721/22950 (epoch 29.893), train_loss = 1.00169565, grad/param norm = 2.3606e-01, time/batch = 14.7331s	
13722/22950 (epoch 29.895), train_loss = 1.08690449, grad/param norm = 2.8200e-01, time/batch = 15.4464s	
13723/22950 (epoch 29.898), train_loss = 0.97344567, grad/param norm = 2.4746e-01, time/batch = 15.2900s	
13724/22950 (epoch 29.900), train_loss = 0.90253110, grad/param norm = 2.1867e-01, time/batch = 14.6753s	
13725/22950 (epoch 29.902), train_loss = 0.96896523, grad/param norm = 2.5165e-01, time/batch = 15.2977s	
13726/22950 (epoch 29.904), train_loss = 0.94874112, grad/param norm = 2.4491e-01, time/batch = 16.4992s	
13727/22950 (epoch 29.906), train_loss = 0.97997434, grad/param norm = 2.5808e-01, time/batch = 14.9782s	
13728/22950 (epoch 29.908), train_loss = 0.82726054, grad/param norm = 2.1707e-01, time/batch = 15.2792s	
13729/22950 (epoch 29.911), train_loss = 0.80866735, grad/param norm = 2.1643e-01, time/batch = 14.8182s	
13730/22950 (epoch 29.913), train_loss = 0.90275552, grad/param norm = 2.5053e-01, time/batch = 14.5731s	
13731/22950 (epoch 29.915), train_loss = 1.06640334, grad/param norm = 2.3928e-01, time/batch = 15.3050s	
13732/22950 (epoch 29.917), train_loss = 0.81668833, grad/param norm = 2.4168e-01, time/batch = 14.5085s	
13733/22950 (epoch 29.919), train_loss = 0.93337907, grad/param norm = 2.3255e-01, time/batch = 14.8363s	
13734/22950 (epoch 29.922), train_loss = 0.95322032, grad/param norm = 2.5814e-01, time/batch = 14.8342s	
13735/22950 (epoch 29.924), train_loss = 0.97614439, grad/param norm = 2.4883e-01, time/batch = 15.3867s	
13736/22950 (epoch 29.926), train_loss = 0.79652556, grad/param norm = 2.5901e-01, time/batch = 15.2325s	
13737/22950 (epoch 29.928), train_loss = 0.79965211, grad/param norm = 2.1518e-01, time/batch = 14.8258s	
13738/22950 (epoch 29.930), train_loss = 0.81979968, grad/param norm = 2.4054e-01, time/batch = 14.8405s	
13739/22950 (epoch 29.932), train_loss = 0.77717965, grad/param norm = 2.0908e-01, time/batch = 15.2267s	
13740/22950 (epoch 29.935), train_loss = 0.92908477, grad/param norm = 2.5334e-01, time/batch = 14.9178s	
13741/22950 (epoch 29.937), train_loss = 0.92469424, grad/param norm = 2.5818e-01, time/batch = 15.2209s	
13742/22950 (epoch 29.939), train_loss = 0.85118800, grad/param norm = 2.2077e-01, time/batch = 15.0524s	
13743/22950 (epoch 29.941), train_loss = 0.87935870, grad/param norm = 2.1480e-01, time/batch = 15.0727s	
13744/22950 (epoch 29.943), train_loss = 0.93422630, grad/param norm = 2.3749e-01, time/batch = 14.8983s	
13745/22950 (epoch 29.946), train_loss = 0.77617882, grad/param norm = 2.2601e-01, time/batch = 14.9889s	
13746/22950 (epoch 29.948), train_loss = 0.99313916, grad/param norm = 2.2675e-01, time/batch = 14.8383s	
13747/22950 (epoch 29.950), train_loss = 0.90546398, grad/param norm = 2.5257e-01, time/batch = 15.5523s	
13748/22950 (epoch 29.952), train_loss = 0.97060360, grad/param norm = 2.2816e-01, time/batch = 15.2861s	
13749/22950 (epoch 29.954), train_loss = 0.96161980, grad/param norm = 2.6451e-01, time/batch = 14.5874s	
13750/22950 (epoch 29.956), train_loss = 0.86534321, grad/param norm = 2.2128e-01, time/batch = 14.7981s	
13751/22950 (epoch 29.959), train_loss = 0.84090103, grad/param norm = 2.3337e-01, time/batch = 14.9819s	
13752/22950 (epoch 29.961), train_loss = 0.93506979, grad/param norm = 2.3942e-01, time/batch = 14.4975s	
13753/22950 (epoch 29.963), train_loss = 0.93709524, grad/param norm = 2.4541e-01, time/batch = 14.6561s	
13754/22950 (epoch 29.965), train_loss = 1.01872302, grad/param norm = 2.4047e-01, time/batch = 15.4623s	
13755/22950 (epoch 29.967), train_loss = 0.90341711, grad/param norm = 2.5590e-01, time/batch = 15.7690s	
13756/22950 (epoch 29.969), train_loss = 0.84433108, grad/param norm = 2.4134e-01, time/batch = 14.9815s	
13757/22950 (epoch 29.972), train_loss = 0.90988586, grad/param norm = 2.1512e-01, time/batch = 15.5205s	
13758/22950 (epoch 29.974), train_loss = 0.88710910, grad/param norm = 2.4526e-01, time/batch = 15.2084s	
13759/22950 (epoch 29.976), train_loss = 0.87995845, grad/param norm = 2.3018e-01, time/batch = 15.6061s	
13760/22950 (epoch 29.978), train_loss = 0.83221305, grad/param norm = 2.0810e-01, time/batch = 16.0840s	
13761/22950 (epoch 29.980), train_loss = 0.87277768, grad/param norm = 2.5282e-01, time/batch = 15.9396s	
13762/22950 (epoch 29.983), train_loss = 0.97189856, grad/param norm = 2.3613e-01, time/batch = 15.3887s	
13763/22950 (epoch 29.985), train_loss = 0.79915049, grad/param norm = 2.0484e-01, time/batch = 15.0578s	
13764/22950 (epoch 29.987), train_loss = 0.85511814, grad/param norm = 2.2507e-01, time/batch = 14.9008s	
13765/22950 (epoch 29.989), train_loss = 0.91885118, grad/param norm = 2.3890e-01, time/batch = 15.0596s	
13766/22950 (epoch 29.991), train_loss = 0.77506619, grad/param norm = 2.2419e-01, time/batch = 15.3842s	
13767/22950 (epoch 29.993), train_loss = 0.94003019, grad/param norm = 2.2459e-01, time/batch = 15.3889s	
13768/22950 (epoch 29.996), train_loss = 0.89943707, grad/param norm = 2.2630e-01, time/batch = 15.2176s	
13769/22950 (epoch 29.998), train_loss = 0.82614918, grad/param norm = 2.1916e-01, time/batch = 14.7375s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
13770/22950 (epoch 30.000), train_loss = 0.75396967, grad/param norm = 1.9379e-01, time/batch = 15.0662s	
13771/22950 (epoch 30.002), train_loss = 1.06635435, grad/param norm = 2.4309e-01, time/batch = 14.8317s	
13772/22950 (epoch 30.004), train_loss = 0.94974145, grad/param norm = 2.3185e-01, time/batch = 14.8409s	
13773/22950 (epoch 30.007), train_loss = 0.91444022, grad/param norm = 2.4709e-01, time/batch = 14.9090s	
13774/22950 (epoch 30.009), train_loss = 1.03692978, grad/param norm = 2.5866e-01, time/batch = 15.3813s	
13775/22950 (epoch 30.011), train_loss = 0.79563880, grad/param norm = 2.1440e-01, time/batch = 15.0600s	
13776/22950 (epoch 30.013), train_loss = 0.90906630, grad/param norm = 2.7793e-01, time/batch = 15.2300s	
13777/22950 (epoch 30.015), train_loss = 0.94691244, grad/param norm = 2.3501e-01, time/batch = 15.1374s	
13778/22950 (epoch 30.017), train_loss = 0.93773625, grad/param norm = 2.4570e-01, time/batch = 15.5457s	
13779/22950 (epoch 30.020), train_loss = 0.95847939, grad/param norm = 2.4458e-01, time/batch = 15.0660s	
13780/22950 (epoch 30.022), train_loss = 0.80356055, grad/param norm = 2.2361e-01, time/batch = 15.4718s	
13781/22950 (epoch 30.024), train_loss = 0.88922785, grad/param norm = 2.1671e-01, time/batch = 15.8406s	
13782/22950 (epoch 30.026), train_loss = 0.95235038, grad/param norm = 2.3365e-01, time/batch = 14.9933s	
13783/22950 (epoch 30.028), train_loss = 1.00918096, grad/param norm = 2.2479e-01, time/batch = 15.6029s	
13784/22950 (epoch 30.031), train_loss = 0.87828569, grad/param norm = 2.2411e-01, time/batch = 15.9289s	
13785/22950 (epoch 30.033), train_loss = 0.99732492, grad/param norm = 2.5978e-01, time/batch = 15.8824s	
13786/22950 (epoch 30.035), train_loss = 0.90643261, grad/param norm = 2.4420e-01, time/batch = 15.2269s	
13787/22950 (epoch 30.037), train_loss = 0.90350729, grad/param norm = 2.4553e-01, time/batch = 14.9090s	
13788/22950 (epoch 30.039), train_loss = 0.88351427, grad/param norm = 2.2840e-01, time/batch = 14.9964s	
13789/22950 (epoch 30.041), train_loss = 0.85739650, grad/param norm = 2.3391e-01, time/batch = 14.9231s	
13790/22950 (epoch 30.044), train_loss = 0.98678027, grad/param norm = 2.6007e-01, time/batch = 15.2983s	
13791/22950 (epoch 30.046), train_loss = 0.91582317, grad/param norm = 2.4234e-01, time/batch = 15.3180s	
13792/22950 (epoch 30.048), train_loss = 0.91787353, grad/param norm = 2.1537e-01, time/batch = 14.9248s	
13793/22950 (epoch 30.050), train_loss = 0.88340351, grad/param norm = 2.9588e-01, time/batch = 14.8447s	
13794/22950 (epoch 30.052), train_loss = 0.95008992, grad/param norm = 2.3107e-01, time/batch = 15.2181s	
13795/22950 (epoch 30.054), train_loss = 1.06963963, grad/param norm = 2.7767e-01, time/batch = 15.3630s	
13796/22950 (epoch 30.057), train_loss = 0.99295558, grad/param norm = 2.5702e-01, time/batch = 14.6598s	
13797/22950 (epoch 30.059), train_loss = 1.00538997, grad/param norm = 2.4232e-01, time/batch = 14.5062s	
13798/22950 (epoch 30.061), train_loss = 0.86400650, grad/param norm = 2.3760e-01, time/batch = 14.8271s	
13799/22950 (epoch 30.063), train_loss = 0.93987419, grad/param norm = 2.5715e-01, time/batch = 14.6765s	
13800/22950 (epoch 30.065), train_loss = 0.82130880, grad/param norm = 2.1610e-01, time/batch = 15.2850s	
13801/22950 (epoch 30.068), train_loss = 0.95637345, grad/param norm = 2.5607e-01, time/batch = 14.5854s	
13802/22950 (epoch 30.070), train_loss = 0.82755325, grad/param norm = 2.0570e-01, time/batch = 15.0621s	
13803/22950 (epoch 30.072), train_loss = 0.98165021, grad/param norm = 2.3938e-01, time/batch = 14.8130s	
13804/22950 (epoch 30.074), train_loss = 0.93317878, grad/param norm = 2.2644e-01, time/batch = 15.1644s	
13805/22950 (epoch 30.076), train_loss = 0.96780866, grad/param norm = 2.3122e-01, time/batch = 15.8835s	
13806/22950 (epoch 30.078), train_loss = 1.02485117, grad/param norm = 2.6683e-01, time/batch = 16.2083s	
13807/22950 (epoch 30.081), train_loss = 1.06240044, grad/param norm = 2.5547e-01, time/batch = 15.3617s	
13808/22950 (epoch 30.083), train_loss = 0.93551296, grad/param norm = 2.2513e-01, time/batch = 18.2230s	
13809/22950 (epoch 30.085), train_loss = 0.80587033, grad/param norm = 2.3427e-01, time/batch = 17.4614s	
13810/22950 (epoch 30.087), train_loss = 0.83482138, grad/param norm = 2.3983e-01, time/batch = 18.9706s	
13811/22950 (epoch 30.089), train_loss = 0.96192452, grad/param norm = 2.3554e-01, time/batch = 18.0561s	
13812/22950 (epoch 30.092), train_loss = 0.86628765, grad/param norm = 2.3877e-01, time/batch = 16.4324s	
13813/22950 (epoch 30.094), train_loss = 0.84414938, grad/param norm = 2.3478e-01, time/batch = 16.6319s	
13814/22950 (epoch 30.096), train_loss = 1.01496335, grad/param norm = 2.6202e-01, time/batch = 16.8788s	
13815/22950 (epoch 30.098), train_loss = 0.97029643, grad/param norm = 2.7111e-01, time/batch = 17.2309s	
13816/22950 (epoch 30.100), train_loss = 0.90180882, grad/param norm = 2.4287e-01, time/batch = 15.5556s	
13817/22950 (epoch 30.102), train_loss = 0.92261211, grad/param norm = 2.5305e-01, time/batch = 16.9603s	
13818/22950 (epoch 30.105), train_loss = 0.76890736, grad/param norm = 2.3121e-01, time/batch = 16.2977s	
13819/22950 (epoch 30.107), train_loss = 0.86311746, grad/param norm = 2.2607e-01, time/batch = 15.6305s	
13820/22950 (epoch 30.109), train_loss = 0.88973780, grad/param norm = 2.4376e-01, time/batch = 16.9814s	
13821/22950 (epoch 30.111), train_loss = 0.78551524, grad/param norm = 2.4137e-01, time/batch = 16.4422s	
13822/22950 (epoch 30.113), train_loss = 0.93621277, grad/param norm = 2.2944e-01, time/batch = 18.6243s	
13823/22950 (epoch 30.115), train_loss = 0.91934346, grad/param norm = 2.1590e-01, time/batch = 18.1298s	
13824/22950 (epoch 30.118), train_loss = 1.02571112, grad/param norm = 2.1359e-01, time/batch = 19.4578s	
13825/22950 (epoch 30.120), train_loss = 0.84460054, grad/param norm = 2.3650e-01, time/batch = 18.7963s	
13826/22950 (epoch 30.122), train_loss = 0.99391393, grad/param norm = 2.4840e-01, time/batch = 15.8029s	
13827/22950 (epoch 30.124), train_loss = 0.80022008, grad/param norm = 2.0503e-01, time/batch = 16.4527s	
13828/22950 (epoch 30.126), train_loss = 0.93108630, grad/param norm = 2.2874e-01, time/batch = 15.7815s	
13829/22950 (epoch 30.129), train_loss = 0.84224791, grad/param norm = 2.0037e-01, time/batch = 18.1101s	
13830/22950 (epoch 30.131), train_loss = 0.88835444, grad/param norm = 2.2882e-01, time/batch = 17.0228s	
13831/22950 (epoch 30.133), train_loss = 0.98206822, grad/param norm = 2.3845e-01, time/batch = 19.2064s	
13832/22950 (epoch 30.135), train_loss = 0.91238599, grad/param norm = 2.0969e-01, time/batch = 18.0365s	
13833/22950 (epoch 30.137), train_loss = 1.01129535, grad/param norm = 2.7768e-01, time/batch = 18.3548s	
13834/22950 (epoch 30.139), train_loss = 0.82435562, grad/param norm = 2.1774e-01, time/batch = 18.3871s	
13835/22950 (epoch 30.142), train_loss = 0.81622213, grad/param norm = 2.0983e-01, time/batch = 18.2820s	
13836/22950 (epoch 30.144), train_loss = 0.89862940, grad/param norm = 2.3592e-01, time/batch = 18.8730s	
13837/22950 (epoch 30.146), train_loss = 0.86497945, grad/param norm = 2.5197e-01, time/batch = 19.5364s	
13838/22950 (epoch 30.148), train_loss = 0.87393306, grad/param norm = 2.5413e-01, time/batch = 18.1232s	
13839/22950 (epoch 30.150), train_loss = 0.94681861, grad/param norm = 2.6486e-01, time/batch = 19.7069s	
13840/22950 (epoch 30.153), train_loss = 0.85011777, grad/param norm = 2.0369e-01, time/batch = 18.5189s	
13841/22950 (epoch 30.155), train_loss = 0.86222338, grad/param norm = 1.9568e-01, time/batch = 18.0553s	
13842/22950 (epoch 30.157), train_loss = 0.90350941, grad/param norm = 2.1638e-01, time/batch = 19.8745s	
13843/22950 (epoch 30.159), train_loss = 0.82821039, grad/param norm = 1.9698e-01, time/batch = 16.0336s	
13844/22950 (epoch 30.161), train_loss = 0.88428387, grad/param norm = 2.1333e-01, time/batch = 16.4696s	
13845/22950 (epoch 30.163), train_loss = 0.81659882, grad/param norm = 2.4553e-01, time/batch = 18.7064s	
13846/22950 (epoch 30.166), train_loss = 0.96506526, grad/param norm = 2.6010e-01, time/batch = 18.3760s	
13847/22950 (epoch 30.168), train_loss = 0.94902692, grad/param norm = 2.5995e-01, time/batch = 17.9530s	
13848/22950 (epoch 30.170), train_loss = 0.89330298, grad/param norm = 2.3306e-01, time/batch = 15.9004s	
13849/22950 (epoch 30.172), train_loss = 0.94144955, grad/param norm = 2.3993e-01, time/batch = 16.8672s	
13850/22950 (epoch 30.174), train_loss = 0.99392494, grad/param norm = 2.3568e-01, time/batch = 17.7887s	
13851/22950 (epoch 30.176), train_loss = 1.00384365, grad/param norm = 2.6451e-01, time/batch = 16.6729s	
13852/22950 (epoch 30.179), train_loss = 0.95794515, grad/param norm = 2.3774e-01, time/batch = 19.7063s	
13853/22950 (epoch 30.181), train_loss = 1.16657899, grad/param norm = 2.6262e-01, time/batch = 18.2865s	
13854/22950 (epoch 30.183), train_loss = 0.97471312, grad/param norm = 2.4401e-01, time/batch = 20.2172s	
13855/22950 (epoch 30.185), train_loss = 0.95210289, grad/param norm = 2.3294e-01, time/batch = 18.1928s	
13856/22950 (epoch 30.187), train_loss = 0.83856045, grad/param norm = 2.2500e-01, time/batch = 18.4583s	
13857/22950 (epoch 30.190), train_loss = 0.76112663, grad/param norm = 2.2154e-01, time/batch = 16.6153s	
13858/22950 (epoch 30.192), train_loss = 0.74172246, grad/param norm = 2.3938e-01, time/batch = 18.8661s	
13859/22950 (epoch 30.194), train_loss = 0.89519587, grad/param norm = 2.5355e-01, time/batch = 18.8743s	
13860/22950 (epoch 30.196), train_loss = 0.70247762, grad/param norm = 2.6943e-01, time/batch = 19.3059s	
13861/22950 (epoch 30.198), train_loss = 0.96750086, grad/param norm = 2.8209e-01, time/batch = 18.7908s	
13862/22950 (epoch 30.200), train_loss = 0.84738831, grad/param norm = 2.1383e-01, time/batch = 18.7167s	
13863/22950 (epoch 30.203), train_loss = 0.80306915, grad/param norm = 2.2776e-01, time/batch = 18.3384s	
13864/22950 (epoch 30.205), train_loss = 0.85559782, grad/param norm = 2.1911e-01, time/batch = 17.8103s	
13865/22950 (epoch 30.207), train_loss = 0.93158781, grad/param norm = 2.5778e-01, time/batch = 17.6362s	
13866/22950 (epoch 30.209), train_loss = 0.89954229, grad/param norm = 2.8496e-01, time/batch = 16.7146s	
13867/22950 (epoch 30.211), train_loss = 0.76285818, grad/param norm = 2.1851e-01, time/batch = 18.3046s	
13868/22950 (epoch 30.214), train_loss = 0.83383268, grad/param norm = 2.1672e-01, time/batch = 15.4792s	
13869/22950 (epoch 30.216), train_loss = 0.99464397, grad/param norm = 2.4601e-01, time/batch = 15.1170s	
13870/22950 (epoch 30.218), train_loss = 0.89750849, grad/param norm = 2.2846e-01, time/batch = 16.4576s	
13871/22950 (epoch 30.220), train_loss = 0.99191645, grad/param norm = 2.6226e-01, time/batch = 17.8910s	
13872/22950 (epoch 30.222), train_loss = 1.00915944, grad/param norm = 2.4497e-01, time/batch = 19.2271s	
13873/22950 (epoch 30.224), train_loss = 0.90923173, grad/param norm = 2.4507e-01, time/batch = 17.3746s	
13874/22950 (epoch 30.227), train_loss = 0.95776617, grad/param norm = 2.2350e-01, time/batch = 19.8655s	
13875/22950 (epoch 30.229), train_loss = 1.00249048, grad/param norm = 2.2907e-01, time/batch = 17.8801s	
13876/22950 (epoch 30.231), train_loss = 0.77053719, grad/param norm = 2.3684e-01, time/batch = 17.8721s	
13877/22950 (epoch 30.233), train_loss = 0.86611279, grad/param norm = 2.2782e-01, time/batch = 19.0182s	
13878/22950 (epoch 30.235), train_loss = 1.03476642, grad/param norm = 2.2064e-01, time/batch = 16.4081s	
13879/22950 (epoch 30.237), train_loss = 0.86219113, grad/param norm = 2.3438e-01, time/batch = 18.9623s	
13880/22950 (epoch 30.240), train_loss = 0.90650448, grad/param norm = 2.2067e-01, time/batch = 17.6977s	
13881/22950 (epoch 30.242), train_loss = 1.03787652, grad/param norm = 2.2683e-01, time/batch = 18.1903s	
13882/22950 (epoch 30.244), train_loss = 1.02283655, grad/param norm = 2.8301e-01, time/batch = 17.8013s	
13883/22950 (epoch 30.246), train_loss = 1.01972153, grad/param norm = 2.4846e-01, time/batch = 16.1520s	
13884/22950 (epoch 30.248), train_loss = 0.93310430, grad/param norm = 2.4844e-01, time/batch = 17.5327s	
13885/22950 (epoch 30.251), train_loss = 0.85205749, grad/param norm = 2.1967e-01, time/batch = 18.6853s	
13886/22950 (epoch 30.253), train_loss = 0.86390998, grad/param norm = 2.5901e-01, time/batch = 16.3675s	
13887/22950 (epoch 30.255), train_loss = 0.94660311, grad/param norm = 2.2298e-01, time/batch = 17.0700s	
13888/22950 (epoch 30.257), train_loss = 0.99657650, grad/param norm = 2.3496e-01, time/batch = 16.8610s	
13889/22950 (epoch 30.259), train_loss = 0.79510808, grad/param norm = 2.2267e-01, time/batch = 18.8594s	
13890/22950 (epoch 30.261), train_loss = 0.85999330, grad/param norm = 2.3217e-01, time/batch = 17.3377s	
13891/22950 (epoch 30.264), train_loss = 0.81067246, grad/param norm = 2.2304e-01, time/batch = 17.2139s	
13892/22950 (epoch 30.266), train_loss = 0.89736478, grad/param norm = 2.3955e-01, time/batch = 16.0771s	
13893/22950 (epoch 30.268), train_loss = 0.91884931, grad/param norm = 2.5543e-01, time/batch = 16.2370s	
13894/22950 (epoch 30.270), train_loss = 0.89468412, grad/param norm = 2.1520e-01, time/batch = 18.1923s	
13895/22950 (epoch 30.272), train_loss = 0.92974692, grad/param norm = 2.3568e-01, time/batch = 16.6763s	
13896/22950 (epoch 30.275), train_loss = 0.85088484, grad/param norm = 2.6669e-01, time/batch = 17.1812s	
13897/22950 (epoch 30.277), train_loss = 0.77532251, grad/param norm = 2.2132e-01, time/batch = 16.5909s	
13898/22950 (epoch 30.279), train_loss = 0.80347242, grad/param norm = 2.5176e-01, time/batch = 15.3749s	
13899/22950 (epoch 30.281), train_loss = 0.84025542, grad/param norm = 2.2460e-01, time/batch = 16.0209s	
13900/22950 (epoch 30.283), train_loss = 0.78699268, grad/param norm = 1.9592e-01, time/batch = 14.5888s	
13901/22950 (epoch 30.285), train_loss = 0.91205324, grad/param norm = 2.1612e-01, time/batch = 15.2965s	
13902/22950 (epoch 30.288), train_loss = 1.01326832, grad/param norm = 2.3577e-01, time/batch = 16.3441s	
13903/22950 (epoch 30.290), train_loss = 0.86464391, grad/param norm = 2.2752e-01, time/batch = 16.6787s	
13904/22950 (epoch 30.292), train_loss = 1.00021608, grad/param norm = 2.5170e-01, time/batch = 17.9566s	
13905/22950 (epoch 30.294), train_loss = 0.92285676, grad/param norm = 2.1866e-01, time/batch = 19.6110s	
13906/22950 (epoch 30.296), train_loss = 0.71508767, grad/param norm = 1.9840e-01, time/batch = 19.5423s	
13907/22950 (epoch 30.298), train_loss = 0.88853952, grad/param norm = 2.1430e-01, time/batch = 18.6125s	
13908/22950 (epoch 30.301), train_loss = 0.94020072, grad/param norm = 2.4952e-01, time/batch = 17.2098s	
13909/22950 (epoch 30.303), train_loss = 0.90076276, grad/param norm = 2.4715e-01, time/batch = 18.7084s	
13910/22950 (epoch 30.305), train_loss = 0.90173311, grad/param norm = 2.5549e-01, time/batch = 18.5490s	
13911/22950 (epoch 30.307), train_loss = 1.02624621, grad/param norm = 2.7232e-01, time/batch = 18.2649s	
13912/22950 (epoch 30.309), train_loss = 0.86359511, grad/param norm = 2.2630e-01, time/batch = 17.9628s	
13913/22950 (epoch 30.312), train_loss = 0.91004441, grad/param norm = 2.3723e-01, time/batch = 18.3752s	
13914/22950 (epoch 30.314), train_loss = 0.92049373, grad/param norm = 2.1737e-01, time/batch = 29.0688s	
13915/22950 (epoch 30.316), train_loss = 0.88900209, grad/param norm = 2.5367e-01, time/batch = 19.0920s	
13916/22950 (epoch 30.318), train_loss = 0.78077325, grad/param norm = 2.0410e-01, time/batch = 16.3907s	
13917/22950 (epoch 30.320), train_loss = 0.82339209, grad/param norm = 2.1077e-01, time/batch = 16.6432s	
13918/22950 (epoch 30.322), train_loss = 0.86687636, grad/param norm = 2.3759e-01, time/batch = 16.1770s	
13919/22950 (epoch 30.325), train_loss = 0.72529107, grad/param norm = 2.3036e-01, time/batch = 16.1424s	
13920/22950 (epoch 30.327), train_loss = 0.73421382, grad/param norm = 2.1781e-01, time/batch = 16.0000s	
13921/22950 (epoch 30.329), train_loss = 0.84272635, grad/param norm = 2.2173e-01, time/batch = 15.7736s	
13922/22950 (epoch 30.331), train_loss = 0.78832037, grad/param norm = 2.1083e-01, time/batch = 15.3042s	
13923/22950 (epoch 30.333), train_loss = 0.82565539, grad/param norm = 2.2343e-01, time/batch = 15.6696s	
13924/22950 (epoch 30.336), train_loss = 0.88382689, grad/param norm = 2.7052e-01, time/batch = 15.4546s	
13925/22950 (epoch 30.338), train_loss = 0.89658197, grad/param norm = 2.1610e-01, time/batch = 15.5754s	
13926/22950 (epoch 30.340), train_loss = 0.88276906, grad/param norm = 2.6488e-01, time/batch = 14.8310s	
13927/22950 (epoch 30.342), train_loss = 1.04252505, grad/param norm = 2.4410e-01, time/batch = 16.1309s	
13928/22950 (epoch 30.344), train_loss = 0.86555160, grad/param norm = 2.4304e-01, time/batch = 17.9514s	
13929/22950 (epoch 30.346), train_loss = 0.99476135, grad/param norm = 2.8203e-01, time/batch = 18.0510s	
13930/22950 (epoch 30.349), train_loss = 0.88533930, grad/param norm = 2.2010e-01, time/batch = 19.8681s	
13931/22950 (epoch 30.351), train_loss = 0.91273672, grad/param norm = 2.4125e-01, time/batch = 17.2007s	
13932/22950 (epoch 30.353), train_loss = 0.95224478, grad/param norm = 2.8901e-01, time/batch = 18.0435s	
13933/22950 (epoch 30.355), train_loss = 1.00096650, grad/param norm = 2.5644e-01, time/batch = 17.3786s	
13934/22950 (epoch 30.357), train_loss = 0.89458330, grad/param norm = 2.6265e-01, time/batch = 19.4445s	
13935/22950 (epoch 30.359), train_loss = 0.90396737, grad/param norm = 2.6771e-01, time/batch = 16.4467s	
13936/22950 (epoch 30.362), train_loss = 0.95120882, grad/param norm = 2.5096e-01, time/batch = 15.9324s	
13937/22950 (epoch 30.364), train_loss = 0.87368039, grad/param norm = 2.8344e-01, time/batch = 19.2972s	
13938/22950 (epoch 30.366), train_loss = 0.90500272, grad/param norm = 2.2837e-01, time/batch = 17.5154s	
13939/22950 (epoch 30.368), train_loss = 0.98339165, grad/param norm = 2.5146e-01, time/batch = 19.2011s	
13940/22950 (epoch 30.370), train_loss = 0.87868794, grad/param norm = 2.3273e-01, time/batch = 18.8791s	
13941/22950 (epoch 30.373), train_loss = 0.80703080, grad/param norm = 2.0883e-01, time/batch = 19.4604s	
13942/22950 (epoch 30.375), train_loss = 1.00679280, grad/param norm = 2.4723e-01, time/batch = 19.5485s	
13943/22950 (epoch 30.377), train_loss = 0.82044859, grad/param norm = 2.7940e-01, time/batch = 17.0433s	
13944/22950 (epoch 30.379), train_loss = 0.91652755, grad/param norm = 2.3646e-01, time/batch = 18.2598s	
13945/22950 (epoch 30.381), train_loss = 0.78512577, grad/param norm = 2.2197e-01, time/batch = 16.2457s	
13946/22950 (epoch 30.383), train_loss = 0.88568453, grad/param norm = 2.3054e-01, time/batch = 16.2698s	
13947/22950 (epoch 30.386), train_loss = 0.83197494, grad/param norm = 2.4642e-01, time/batch = 19.0421s	
13948/22950 (epoch 30.388), train_loss = 0.96064959, grad/param norm = 2.2918e-01, time/batch = 18.1021s	
13949/22950 (epoch 30.390), train_loss = 0.79140673, grad/param norm = 2.1116e-01, time/batch = 17.5420s	
13950/22950 (epoch 30.392), train_loss = 0.83881300, grad/param norm = 2.1973e-01, time/batch = 17.0618s	
13951/22950 (epoch 30.394), train_loss = 0.85628700, grad/param norm = 2.2791e-01, time/batch = 17.6204s	
13952/22950 (epoch 30.397), train_loss = 1.01046604, grad/param norm = 2.2494e-01, time/batch = 19.5237s	
13953/22950 (epoch 30.399), train_loss = 1.00184122, grad/param norm = 2.5718e-01, time/batch = 19.1171s	
13954/22950 (epoch 30.401), train_loss = 1.05459591, grad/param norm = 3.0188e-01, time/batch = 18.2779s	
13955/22950 (epoch 30.403), train_loss = 0.88869268, grad/param norm = 2.6672e-01, time/batch = 20.1977s	
13956/22950 (epoch 30.405), train_loss = 0.99513646, grad/param norm = 2.6821e-01, time/batch = 20.0466s	
13957/22950 (epoch 30.407), train_loss = 1.05813491, grad/param norm = 2.2028e-01, time/batch = 17.2036s	
13958/22950 (epoch 30.410), train_loss = 0.90024409, grad/param norm = 2.2715e-01, time/batch = 19.3732s	
13959/22950 (epoch 30.412), train_loss = 0.89418388, grad/param norm = 2.4982e-01, time/batch = 17.6231s	
13960/22950 (epoch 30.414), train_loss = 1.01207353, grad/param norm = 2.6954e-01, time/batch = 20.7607s	
13961/22950 (epoch 30.416), train_loss = 0.92754085, grad/param norm = 2.8937e-01, time/batch = 19.1696s	
13962/22950 (epoch 30.418), train_loss = 0.90932515, grad/param norm = 2.9234e-01, time/batch = 18.4515s	
13963/22950 (epoch 30.420), train_loss = 0.99368667, grad/param norm = 2.6926e-01, time/batch = 17.9223s	
13964/22950 (epoch 30.423), train_loss = 0.86490617, grad/param norm = 2.3395e-01, time/batch = 16.8727s	
13965/22950 (epoch 30.425), train_loss = 0.88378966, grad/param norm = 2.1638e-01, time/batch = 16.4867s	
13966/22950 (epoch 30.427), train_loss = 0.91878646, grad/param norm = 2.5664e-01, time/batch = 16.7733s	
13967/22950 (epoch 30.429), train_loss = 0.88940806, grad/param norm = 2.1498e-01, time/batch = 18.3797s	
13968/22950 (epoch 30.431), train_loss = 1.00092524, grad/param norm = 2.6144e-01, time/batch = 17.1921s	
13969/22950 (epoch 30.434), train_loss = 0.91693571, grad/param norm = 2.3567e-01, time/batch = 17.2110s	
13970/22950 (epoch 30.436), train_loss = 0.99237575, grad/param norm = 2.5458e-01, time/batch = 17.3729s	
13971/22950 (epoch 30.438), train_loss = 0.92433919, grad/param norm = 2.3396e-01, time/batch = 18.1176s	
13972/22950 (epoch 30.440), train_loss = 0.99406759, grad/param norm = 2.2870e-01, time/batch = 16.6860s	
13973/22950 (epoch 30.442), train_loss = 1.04494484, grad/param norm = 2.5342e-01, time/batch = 19.5596s	
13974/22950 (epoch 30.444), train_loss = 0.95800837, grad/param norm = 2.4155e-01, time/batch = 17.8008s	
13975/22950 (epoch 30.447), train_loss = 1.06469838, grad/param norm = 2.5251e-01, time/batch = 19.2065s	
13976/22950 (epoch 30.449), train_loss = 0.82597060, grad/param norm = 2.2784e-01, time/batch = 18.9723s	
13977/22950 (epoch 30.451), train_loss = 0.92619864, grad/param norm = 2.4063e-01, time/batch = 17.8684s	
13978/22950 (epoch 30.453), train_loss = 0.96996895, grad/param norm = 2.1911e-01, time/batch = 20.2075s	
13979/22950 (epoch 30.455), train_loss = 0.86672682, grad/param norm = 1.8995e-01, time/batch = 18.2786s	
13980/22950 (epoch 30.458), train_loss = 0.94124734, grad/param norm = 2.2876e-01, time/batch = 16.6878s	
13981/22950 (epoch 30.460), train_loss = 0.97780132, grad/param norm = 2.2827e-01, time/batch = 17.5859s	
13982/22950 (epoch 30.462), train_loss = 0.94470815, grad/param norm = 2.3362e-01, time/batch = 17.0282s	
13983/22950 (epoch 30.464), train_loss = 0.88495943, grad/param norm = 2.4058e-01, time/batch = 16.6082s	
13984/22950 (epoch 30.466), train_loss = 1.00287286, grad/param norm = 2.6593e-01, time/batch = 16.8892s	
13985/22950 (epoch 30.468), train_loss = 1.00395484, grad/param norm = 2.5311e-01, time/batch = 16.0419s	
13986/22950 (epoch 30.471), train_loss = 0.95727917, grad/param norm = 2.5188e-01, time/batch = 17.2773s	
13987/22950 (epoch 30.473), train_loss = 0.95917219, grad/param norm = 2.4399e-01, time/batch = 18.0265s	
13988/22950 (epoch 30.475), train_loss = 1.10871581, grad/param norm = 2.5140e-01, time/batch = 17.9634s	
13989/22950 (epoch 30.477), train_loss = 0.88922404, grad/param norm = 2.3262e-01, time/batch = 18.1336s	
13990/22950 (epoch 30.479), train_loss = 0.80927219, grad/param norm = 2.2305e-01, time/batch = 18.9614s	
13991/22950 (epoch 30.481), train_loss = 1.01304957, grad/param norm = 2.8010e-01, time/batch = 18.7738s	
13992/22950 (epoch 30.484), train_loss = 0.94631394, grad/param norm = 2.3679e-01, time/batch = 18.2282s	
13993/22950 (epoch 30.486), train_loss = 0.78050495, grad/param norm = 2.1885e-01, time/batch = 17.3843s	
13994/22950 (epoch 30.488), train_loss = 0.86193426, grad/param norm = 2.5130e-01, time/batch = 18.3676s	
13995/22950 (epoch 30.490), train_loss = 0.79518389, grad/param norm = 2.3037e-01, time/batch = 18.7805s	
13996/22950 (epoch 30.492), train_loss = 0.87013024, grad/param norm = 2.2572e-01, time/batch = 20.1084s	
13997/22950 (epoch 30.495), train_loss = 0.84445253, grad/param norm = 2.1323e-01, time/batch = 17.6902s	
13998/22950 (epoch 30.497), train_loss = 0.95601979, grad/param norm = 2.6205e-01, time/batch = 19.0110s	
13999/22950 (epoch 30.499), train_loss = 1.05434117, grad/param norm = 2.4939e-01, time/batch = 19.6862s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch30.50_1.9335.t7	
14000/22950 (epoch 30.501), train_loss = 0.93168113, grad/param norm = 2.5235e-01, time/batch = 19.1089s	
14001/22950 (epoch 30.503), train_loss = 1.40988225, grad/param norm = 3.0280e-01, time/batch = 16.4599s	
14002/22950 (epoch 30.505), train_loss = 0.78882413, grad/param norm = 2.1155e-01, time/batch = 16.1268s	
14003/22950 (epoch 30.508), train_loss = 0.95428851, grad/param norm = 2.2334e-01, time/batch = 16.0588s	
14004/22950 (epoch 30.510), train_loss = 0.88946583, grad/param norm = 2.3121e-01, time/batch = 16.5530s	
14005/22950 (epoch 30.512), train_loss = 0.79234821, grad/param norm = 2.0999e-01, time/batch = 16.3791s	
14006/22950 (epoch 30.514), train_loss = 0.87724270, grad/param norm = 1.9787e-01, time/batch = 15.8985s	
14007/22950 (epoch 30.516), train_loss = 0.90392239, grad/param norm = 2.2815e-01, time/batch = 17.4658s	
14008/22950 (epoch 30.519), train_loss = 0.90373074, grad/param norm = 2.2944e-01, time/batch = 17.2068s	
14009/22950 (epoch 30.521), train_loss = 0.92009416, grad/param norm = 2.4437e-01, time/batch = 17.5580s	
14010/22950 (epoch 30.523), train_loss = 0.73170340, grad/param norm = 2.1380e-01, time/batch = 17.6280s	
14011/22950 (epoch 30.525), train_loss = 0.82520369, grad/param norm = 2.0198e-01, time/batch = 18.9581s	
14012/22950 (epoch 30.527), train_loss = 0.79730453, grad/param norm = 2.3891e-01, time/batch = 19.2792s	
14013/22950 (epoch 30.529), train_loss = 0.92824245, grad/param norm = 2.8678e-01, time/batch = 17.5370s	
14014/22950 (epoch 30.532), train_loss = 0.87385840, grad/param norm = 2.1241e-01, time/batch = 19.4419s	
14015/22950 (epoch 30.534), train_loss = 0.93686486, grad/param norm = 2.2118e-01, time/batch = 16.7524s	
14016/22950 (epoch 30.536), train_loss = 0.96554655, grad/param norm = 2.6438e-01, time/batch = 18.8073s	
14017/22950 (epoch 30.538), train_loss = 0.91986780, grad/param norm = 2.3925e-01, time/batch = 18.8730s	
14018/22950 (epoch 30.540), train_loss = 0.96986819, grad/param norm = 2.6565e-01, time/batch = 16.1210s	
14019/22950 (epoch 30.542), train_loss = 1.06247012, grad/param norm = 2.9626e-01, time/batch = 16.4100s	
14020/22950 (epoch 30.545), train_loss = 0.87383545, grad/param norm = 2.1094e-01, time/batch = 16.4274s	
14021/22950 (epoch 30.547), train_loss = 0.91491033, grad/param norm = 2.3061e-01, time/batch = 19.1912s	
14022/22950 (epoch 30.549), train_loss = 0.83624390, grad/param norm = 2.2442e-01, time/batch = 18.6167s	
14023/22950 (epoch 30.551), train_loss = 0.88646706, grad/param norm = 2.3683e-01, time/batch = 18.0469s	
14024/22950 (epoch 30.553), train_loss = 0.86781811, grad/param norm = 2.4819e-01, time/batch = 19.7150s	
14025/22950 (epoch 30.556), train_loss = 0.94474973, grad/param norm = 2.2853e-01, time/batch = 17.0927s	
14026/22950 (epoch 30.558), train_loss = 0.75888756, grad/param norm = 2.1932e-01, time/batch = 18.4785s	
14027/22950 (epoch 30.560), train_loss = 0.87329181, grad/param norm = 2.3796e-01, time/batch = 17.6464s	
14028/22950 (epoch 30.562), train_loss = 0.83833026, grad/param norm = 2.2192e-01, time/batch = 17.7947s	
14029/22950 (epoch 30.564), train_loss = 0.94904716, grad/param norm = 2.4390e-01, time/batch = 18.6179s	
14030/22950 (epoch 30.566), train_loss = 0.92704896, grad/param norm = 2.2540e-01, time/batch = 17.6800s	
14031/22950 (epoch 30.569), train_loss = 0.89961048, grad/param norm = 2.2940e-01, time/batch = 18.7865s	
14032/22950 (epoch 30.571), train_loss = 0.87367717, grad/param norm = 2.4303e-01, time/batch = 16.5148s	
14033/22950 (epoch 30.573), train_loss = 0.90990495, grad/param norm = 2.4804e-01, time/batch = 18.7838s	
14034/22950 (epoch 30.575), train_loss = 0.98090925, grad/param norm = 2.5773e-01, time/batch = 20.2174s	
14035/22950 (epoch 30.577), train_loss = 0.91225161, grad/param norm = 2.3905e-01, time/batch = 18.4245s	
14036/22950 (epoch 30.580), train_loss = 0.98159767, grad/param norm = 2.6225e-01, time/batch = 18.2146s	
14037/22950 (epoch 30.582), train_loss = 1.06373905, grad/param norm = 2.4937e-01, time/batch = 16.5150s	
14038/22950 (epoch 30.584), train_loss = 0.78570515, grad/param norm = 2.1417e-01, time/batch = 18.4790s	
14039/22950 (epoch 30.586), train_loss = 0.83227676, grad/param norm = 2.3860e-01, time/batch = 18.1907s	
14040/22950 (epoch 30.588), train_loss = 1.04458315, grad/param norm = 2.5828e-01, time/batch = 16.5918s	
14041/22950 (epoch 30.590), train_loss = 0.94927536, grad/param norm = 2.5111e-01, time/batch = 16.1683s	
14042/22950 (epoch 30.593), train_loss = 0.89257385, grad/param norm = 2.2598e-01, time/batch = 16.5721s	
14043/22950 (epoch 30.595), train_loss = 0.82456119, grad/param norm = 2.6335e-01, time/batch = 17.1999s	
14044/22950 (epoch 30.597), train_loss = 0.99911308, grad/param norm = 2.5419e-01, time/batch = 17.8677s	
14045/22950 (epoch 30.599), train_loss = 0.92872245, grad/param norm = 2.3999e-01, time/batch = 17.6276s	
14046/22950 (epoch 30.601), train_loss = 0.94716483, grad/param norm = 2.5457e-01, time/batch = 16.7290s	
14047/22950 (epoch 30.603), train_loss = 1.03454309, grad/param norm = 2.5111e-01, time/batch = 17.0266s	
14048/22950 (epoch 30.606), train_loss = 0.92811436, grad/param norm = 2.5538e-01, time/batch = 17.4549s	
14049/22950 (epoch 30.608), train_loss = 0.93969489, grad/param norm = 2.4314e-01, time/batch = 19.0335s	
14050/22950 (epoch 30.610), train_loss = 0.91378155, grad/param norm = 2.3094e-01, time/batch = 18.3002s	
14051/22950 (epoch 30.612), train_loss = 0.92396639, grad/param norm = 2.4422e-01, time/batch = 18.4645s	
14052/22950 (epoch 30.614), train_loss = 1.01602868, grad/param norm = 2.5608e-01, time/batch = 19.6942s	
14053/22950 (epoch 30.617), train_loss = 0.92317947, grad/param norm = 2.2913e-01, time/batch = 17.7025s	
14054/22950 (epoch 30.619), train_loss = 0.87562959, grad/param norm = 2.2631e-01, time/batch = 19.3006s	
14055/22950 (epoch 30.621), train_loss = 0.98889707, grad/param norm = 2.3007e-01, time/batch = 17.6982s	
14056/22950 (epoch 30.623), train_loss = 0.99821803, grad/param norm = 2.6236e-01, time/batch = 16.5039s	
14057/22950 (epoch 30.625), train_loss = 0.90924981, grad/param norm = 2.4313e-01, time/batch = 17.3842s	
14058/22950 (epoch 30.627), train_loss = 0.90265180, grad/param norm = 2.5382e-01, time/batch = 16.1468s	
14059/22950 (epoch 30.630), train_loss = 0.79113954, grad/param norm = 2.1206e-01, time/batch = 18.7131s	
14060/22950 (epoch 30.632), train_loss = 0.85930039, grad/param norm = 2.7741e-01, time/batch = 17.0593s	
14061/22950 (epoch 30.634), train_loss = 0.94237383, grad/param norm = 2.1902e-01, time/batch = 16.1225s	
14062/22950 (epoch 30.636), train_loss = 0.91846222, grad/param norm = 2.3190e-01, time/batch = 16.9356s	
14063/22950 (epoch 30.638), train_loss = 0.86939531, grad/param norm = 2.4523e-01, time/batch = 18.0239s	
14064/22950 (epoch 30.641), train_loss = 0.88421529, grad/param norm = 2.2262e-01, time/batch = 16.2054s	
14065/22950 (epoch 30.643), train_loss = 0.97281030, grad/param norm = 2.6427e-01, time/batch = 18.4606s	
14066/22950 (epoch 30.645), train_loss = 0.87532869, grad/param norm = 2.1418e-01, time/batch = 20.1907s	
14067/22950 (epoch 30.647), train_loss = 0.88456909, grad/param norm = 2.6036e-01, time/batch = 16.5219s	
14068/22950 (epoch 30.649), train_loss = 0.87050648, grad/param norm = 2.2941e-01, time/batch = 16.2691s	
14069/22950 (epoch 30.651), train_loss = 0.97335769, grad/param norm = 2.2822e-01, time/batch = 15.6098s	
14070/22950 (epoch 30.654), train_loss = 0.78042286, grad/param norm = 2.1724e-01, time/batch = 18.3733s	
14071/22950 (epoch 30.656), train_loss = 0.98021515, grad/param norm = 3.5666e-01, time/batch = 19.8803s	
14072/22950 (epoch 30.658), train_loss = 0.82337624, grad/param norm = 2.2582e-01, time/batch = 17.0333s	
14073/22950 (epoch 30.660), train_loss = 0.75582679, grad/param norm = 2.4372e-01, time/batch = 19.7844s	
14074/22950 (epoch 30.662), train_loss = 0.76068110, grad/param norm = 2.3418e-01, time/batch = 19.0396s	
14075/22950 (epoch 30.664), train_loss = 0.88118334, grad/param norm = 2.4520e-01, time/batch = 17.2637s	
14076/22950 (epoch 30.667), train_loss = 0.92885899, grad/param norm = 2.6215e-01, time/batch = 18.8718s	
14077/22950 (epoch 30.669), train_loss = 0.92324675, grad/param norm = 2.5939e-01, time/batch = 17.0242s	
14078/22950 (epoch 30.671), train_loss = 0.90185039, grad/param norm = 2.3457e-01, time/batch = 18.7675s	
14079/22950 (epoch 30.673), train_loss = 0.86312043, grad/param norm = 2.5661e-01, time/batch = 18.6598s	
14080/22950 (epoch 30.675), train_loss = 0.93923031, grad/param norm = 2.4657e-01, time/batch = 17.1107s	
14081/22950 (epoch 30.678), train_loss = 0.90288259, grad/param norm = 2.4484e-01, time/batch = 20.2883s	
14082/22950 (epoch 30.680), train_loss = 0.91641609, grad/param norm = 2.1868e-01, time/batch = 18.6077s	
14083/22950 (epoch 30.682), train_loss = 0.87048948, grad/param norm = 2.8046e-01, time/batch = 16.9444s	
14084/22950 (epoch 30.684), train_loss = 0.99844030, grad/param norm = 2.6931e-01, time/batch = 19.2980s	
14085/22950 (epoch 30.686), train_loss = 1.01907780, grad/param norm = 2.4635e-01, time/batch = 17.1310s	
14086/22950 (epoch 30.688), train_loss = 0.93311148, grad/param norm = 2.3306e-01, time/batch = 16.4243s	
14087/22950 (epoch 30.691), train_loss = 0.91388588, grad/param norm = 2.3896e-01, time/batch = 19.5522s	
14088/22950 (epoch 30.693), train_loss = 0.83357532, grad/param norm = 2.3103e-01, time/batch = 17.9632s	
14089/22950 (epoch 30.695), train_loss = 1.01789745, grad/param norm = 2.7626e-01, time/batch = 18.6231s	
14090/22950 (epoch 30.697), train_loss = 0.95264143, grad/param norm = 2.5489e-01, time/batch = 18.8539s	
14091/22950 (epoch 30.699), train_loss = 0.94871731, grad/param norm = 2.4379e-01, time/batch = 19.1071s	
14092/22950 (epoch 30.702), train_loss = 0.98830315, grad/param norm = 2.8227e-01, time/batch = 16.4858s	
14093/22950 (epoch 30.704), train_loss = 1.06642519, grad/param norm = 2.5963e-01, time/batch = 16.0217s	
14094/22950 (epoch 30.706), train_loss = 1.01242565, grad/param norm = 2.6178e-01, time/batch = 15.4466s	
14095/22950 (epoch 30.708), train_loss = 0.82803955, grad/param norm = 2.4335e-01, time/batch = 15.7987s	
14096/22950 (epoch 30.710), train_loss = 0.93031395, grad/param norm = 2.3778e-01, time/batch = 15.2211s	
14097/22950 (epoch 30.712), train_loss = 1.03417128, grad/param norm = 2.8463e-01, time/batch = 16.0973s	
14098/22950 (epoch 30.715), train_loss = 0.92102793, grad/param norm = 2.2980e-01, time/batch = 16.9600s	
14099/22950 (epoch 30.717), train_loss = 0.95825960, grad/param norm = 2.2241e-01, time/batch = 16.5274s	
14100/22950 (epoch 30.719), train_loss = 0.88431590, grad/param norm = 2.2115e-01, time/batch = 17.1431s	
14101/22950 (epoch 30.721), train_loss = 0.97367686, grad/param norm = 2.4626e-01, time/batch = 17.9480s	
14102/22950 (epoch 30.723), train_loss = 0.92193515, grad/param norm = 2.3861e-01, time/batch = 17.8753s	
14103/22950 (epoch 30.725), train_loss = 0.96290932, grad/param norm = 2.3541e-01, time/batch = 18.4676s	
14104/22950 (epoch 30.728), train_loss = 0.88570631, grad/param norm = 2.7751e-01, time/batch = 16.8053s	
14105/22950 (epoch 30.730), train_loss = 0.90529790, grad/param norm = 2.5425e-01, time/batch = 18.9600s	
14106/22950 (epoch 30.732), train_loss = 0.98309198, grad/param norm = 2.6097e-01, time/batch = 17.7093s	
14107/22950 (epoch 30.734), train_loss = 0.90434775, grad/param norm = 2.5627e-01, time/batch = 18.4832s	
14108/22950 (epoch 30.736), train_loss = 0.94400039, grad/param norm = 2.4497e-01, time/batch = 17.1243s	
14109/22950 (epoch 30.739), train_loss = 0.98907664, grad/param norm = 2.7783e-01, time/batch = 17.1814s	
14110/22950 (epoch 30.741), train_loss = 0.98381456, grad/param norm = 2.9008e-01, time/batch = 0.9674s	
14111/22950 (epoch 30.743), train_loss = 1.07133748, grad/param norm = 3.0692e-01, time/batch = 0.6918s	
14112/22950 (epoch 30.745), train_loss = 1.15643605, grad/param norm = 2.8960e-01, time/batch = 0.6968s	
14113/22950 (epoch 30.747), train_loss = 0.95529778, grad/param norm = 2.6675e-01, time/batch = 0.6894s	
14114/22950 (epoch 30.749), train_loss = 0.86616220, grad/param norm = 2.8813e-01, time/batch = 0.6877s	
14115/22950 (epoch 30.752), train_loss = 1.11012708, grad/param norm = 3.1772e-01, time/batch = 0.6932s	
14116/22950 (epoch 30.754), train_loss = 0.99424112, grad/param norm = 2.5975e-01, time/batch = 0.9053s	
14117/22950 (epoch 30.756), train_loss = 0.86456663, grad/param norm = 2.3872e-01, time/batch = 1.0174s	
14118/22950 (epoch 30.758), train_loss = 0.93664497, grad/param norm = 2.0849e-01, time/batch = 1.0028s	
14119/22950 (epoch 30.760), train_loss = 0.95179737, grad/param norm = 2.4022e-01, time/batch = 1.0009s	
14120/22950 (epoch 30.763), train_loss = 0.97563851, grad/param norm = 2.3517e-01, time/batch = 1.0134s	
14121/22950 (epoch 30.765), train_loss = 0.92786014, grad/param norm = 2.7354e-01, time/batch = 1.7024s	
14122/22950 (epoch 30.767), train_loss = 1.15796732, grad/param norm = 2.8617e-01, time/batch = 1.9061s	
14123/22950 (epoch 30.769), train_loss = 0.98099361, grad/param norm = 2.4964e-01, time/batch = 4.1089s	
14124/22950 (epoch 30.771), train_loss = 0.79584851, grad/param norm = 2.3336e-01, time/batch = 16.8023s	
14125/22950 (epoch 30.773), train_loss = 0.71625522, grad/param norm = 2.1048e-01, time/batch = 17.2065s	
14126/22950 (epoch 30.776), train_loss = 0.87057915, grad/param norm = 2.2265e-01, time/batch = 17.2911s	
14127/22950 (epoch 30.778), train_loss = 0.84443640, grad/param norm = 2.2511e-01, time/batch = 15.8580s	
14128/22950 (epoch 30.780), train_loss = 0.93505403, grad/param norm = 2.3114e-01, time/batch = 16.1106s	
14129/22950 (epoch 30.782), train_loss = 0.99568212, grad/param norm = 2.5060e-01, time/batch = 16.5961s	
14130/22950 (epoch 30.784), train_loss = 0.86410369, grad/param norm = 2.5372e-01, time/batch = 17.7906s	
14131/22950 (epoch 30.786), train_loss = 0.91383520, grad/param norm = 2.4841e-01, time/batch = 15.5066s	
14132/22950 (epoch 30.789), train_loss = 0.77202698, grad/param norm = 2.2246e-01, time/batch = 15.2740s	
14133/22950 (epoch 30.791), train_loss = 0.83994913, grad/param norm = 2.4035e-01, time/batch = 16.5319s	
14134/22950 (epoch 30.793), train_loss = 1.02623476, grad/param norm = 2.4462e-01, time/batch = 16.6139s	
14135/22950 (epoch 30.795), train_loss = 0.90445504, grad/param norm = 2.1647e-01, time/batch = 18.4455s	
14136/22950 (epoch 30.797), train_loss = 1.04169966, grad/param norm = 2.3457e-01, time/batch = 17.6099s	
14137/22950 (epoch 30.800), train_loss = 0.83164191, grad/param norm = 2.0746e-01, time/batch = 18.8636s	
14138/22950 (epoch 30.802), train_loss = 0.87842085, grad/param norm = 2.4256e-01, time/batch = 18.3834s	
14139/22950 (epoch 30.804), train_loss = 0.89116618, grad/param norm = 2.3717e-01, time/batch = 19.2960s	
14140/22950 (epoch 30.806), train_loss = 0.79176926, grad/param norm = 2.2345e-01, time/batch = 17.8649s	
14141/22950 (epoch 30.808), train_loss = 0.91490935, grad/param norm = 2.2541e-01, time/batch = 18.1390s	
14142/22950 (epoch 30.810), train_loss = 0.88725395, grad/param norm = 2.4136e-01, time/batch = 18.0504s	
14143/22950 (epoch 30.813), train_loss = 0.74961665, grad/param norm = 2.0959e-01, time/batch = 15.7063s	
14144/22950 (epoch 30.815), train_loss = 0.74360409, grad/param norm = 2.3699e-01, time/batch = 17.4714s	
14145/22950 (epoch 30.817), train_loss = 0.83392720, grad/param norm = 2.2309e-01, time/batch = 18.7033s	
14146/22950 (epoch 30.819), train_loss = 0.89605455, grad/param norm = 2.3159e-01, time/batch = 18.6923s	
14147/22950 (epoch 30.821), train_loss = 0.87536519, grad/param norm = 2.6546e-01, time/batch = 17.3474s	
14148/22950 (epoch 30.824), train_loss = 0.92862658, grad/param norm = 2.3121e-01, time/batch = 17.0564s	
14149/22950 (epoch 30.826), train_loss = 0.96897095, grad/param norm = 2.9832e-01, time/batch = 17.1843s	
14150/22950 (epoch 30.828), train_loss = 0.87716211, grad/param norm = 2.4457e-01, time/batch = 19.2738s	
14151/22950 (epoch 30.830), train_loss = 0.87092159, grad/param norm = 2.2255e-01, time/batch = 18.5015s	
14152/22950 (epoch 30.832), train_loss = 0.90953037, grad/param norm = 2.3205e-01, time/batch = 15.9918s	
14153/22950 (epoch 30.834), train_loss = 0.77653822, grad/param norm = 2.3812e-01, time/batch = 17.2739s	
14154/22950 (epoch 30.837), train_loss = 0.92229008, grad/param norm = 2.6016e-01, time/batch = 19.5265s	
14155/22950 (epoch 30.839), train_loss = 0.75853366, grad/param norm = 2.2762e-01, time/batch = 17.5508s	
14156/22950 (epoch 30.841), train_loss = 0.85249169, grad/param norm = 2.1797e-01, time/batch = 18.0401s	
14157/22950 (epoch 30.843), train_loss = 0.84806827, grad/param norm = 2.5684e-01, time/batch = 17.5223s	
14158/22950 (epoch 30.845), train_loss = 0.88307856, grad/param norm = 2.2262e-01, time/batch = 16.5425s	
14159/22950 (epoch 30.847), train_loss = 0.95011391, grad/param norm = 2.6761e-01, time/batch = 16.1209s	
14160/22950 (epoch 30.850), train_loss = 0.98202625, grad/param norm = 2.5664e-01, time/batch = 17.9379s	
14161/22950 (epoch 30.852), train_loss = 0.98569801, grad/param norm = 2.7616e-01, time/batch = 16.1240s	
14162/22950 (epoch 30.854), train_loss = 0.91618975, grad/param norm = 2.3125e-01, time/batch = 18.8665s	
14163/22950 (epoch 30.856), train_loss = 1.03180925, grad/param norm = 2.6961e-01, time/batch = 18.1204s	
14164/22950 (epoch 30.858), train_loss = 0.95504394, grad/param norm = 2.3402e-01, time/batch = 18.2122s	
14165/22950 (epoch 30.861), train_loss = 0.97084129, grad/param norm = 2.4569e-01, time/batch = 19.2921s	
14166/22950 (epoch 30.863), train_loss = 1.01763780, grad/param norm = 2.7001e-01, time/batch = 19.1167s	
14167/22950 (epoch 30.865), train_loss = 1.03401804, grad/param norm = 2.4380e-01, time/batch = 18.2641s	
14168/22950 (epoch 30.867), train_loss = 0.94818885, grad/param norm = 2.6150e-01, time/batch = 17.6315s	
14169/22950 (epoch 30.869), train_loss = 1.06213447, grad/param norm = 2.5474e-01, time/batch = 17.4734s	
14170/22950 (epoch 30.871), train_loss = 0.93492576, grad/param norm = 2.6703e-01, time/batch = 16.3390s	
14171/22950 (epoch 30.874), train_loss = 0.95546785, grad/param norm = 2.3501e-01, time/batch = 17.7988s	
14172/22950 (epoch 30.876), train_loss = 1.00244622, grad/param norm = 2.8767e-01, time/batch = 17.7507s	
14173/22950 (epoch 30.878), train_loss = 0.90672298, grad/param norm = 2.8078e-01, time/batch = 16.7097s	
14174/22950 (epoch 30.880), train_loss = 1.10276957, grad/param norm = 2.5231e-01, time/batch = 17.1302s	
14175/22950 (epoch 30.882), train_loss = 0.83179424, grad/param norm = 2.4725e-01, time/batch = 16.2060s	
14176/22950 (epoch 30.885), train_loss = 0.95817628, grad/param norm = 2.7949e-01, time/batch = 18.5298s	
14177/22950 (epoch 30.887), train_loss = 0.92277476, grad/param norm = 2.4430e-01, time/batch = 17.6961s	
14178/22950 (epoch 30.889), train_loss = 0.96309511, grad/param norm = 2.5315e-01, time/batch = 17.4598s	
14179/22950 (epoch 30.891), train_loss = 0.87050706, grad/param norm = 2.5845e-01, time/batch = 19.5442s	
14180/22950 (epoch 30.893), train_loss = 0.98265485, grad/param norm = 2.3045e-01, time/batch = 16.6519s	
14181/22950 (epoch 30.895), train_loss = 1.06655209, grad/param norm = 2.5964e-01, time/batch = 16.7398s	
14182/22950 (epoch 30.898), train_loss = 0.94790234, grad/param norm = 2.2967e-01, time/batch = 16.2420s	
14183/22950 (epoch 30.900), train_loss = 0.89145464, grad/param norm = 2.2306e-01, time/batch = 16.2299s	
14184/22950 (epoch 30.902), train_loss = 0.94444768, grad/param norm = 2.4977e-01, time/batch = 15.3851s	
14185/22950 (epoch 30.904), train_loss = 0.92831873, grad/param norm = 2.4883e-01, time/batch = 18.2610s	
14186/22950 (epoch 30.906), train_loss = 0.96261452, grad/param norm = 2.5134e-01, time/batch = 18.7116s	
14187/22950 (epoch 30.908), train_loss = 0.81226614, grad/param norm = 2.1961e-01, time/batch = 16.6696s	
14188/22950 (epoch 30.911), train_loss = 0.78428738, grad/param norm = 2.0118e-01, time/batch = 19.1135s	
14189/22950 (epoch 30.913), train_loss = 0.90285134, grad/param norm = 2.2546e-01, time/batch = 17.3683s	
14190/22950 (epoch 30.915), train_loss = 1.06518827, grad/param norm = 2.5853e-01, time/batch = 18.5131s	
14191/22950 (epoch 30.917), train_loss = 0.81373443, grad/param norm = 2.2060e-01, time/batch = 17.8659s	
14192/22950 (epoch 30.919), train_loss = 0.93052205, grad/param norm = 2.5230e-01, time/batch = 16.4499s	
14193/22950 (epoch 30.922), train_loss = 0.94694510, grad/param norm = 2.6392e-01, time/batch = 17.4691s	
14194/22950 (epoch 30.924), train_loss = 0.95559221, grad/param norm = 2.6858e-01, time/batch = 16.5609s	
14195/22950 (epoch 30.926), train_loss = 0.76938860, grad/param norm = 2.4111e-01, time/batch = 16.3769s	
14196/22950 (epoch 30.928), train_loss = 0.80308807, grad/param norm = 2.0986e-01, time/batch = 18.7846s	
14197/22950 (epoch 30.930), train_loss = 0.80416242, grad/param norm = 2.2883e-01, time/batch = 16.9387s	
14198/22950 (epoch 30.932), train_loss = 0.76561748, grad/param norm = 2.0473e-01, time/batch = 18.4380s	
14199/22950 (epoch 30.935), train_loss = 0.93565917, grad/param norm = 2.4772e-01, time/batch = 17.7113s	
14200/22950 (epoch 30.937), train_loss = 0.92132095, grad/param norm = 2.6763e-01, time/batch = 17.9429s	
14201/22950 (epoch 30.939), train_loss = 0.84440778, grad/param norm = 2.4647e-01, time/batch = 16.3689s	
14202/22950 (epoch 30.941), train_loss = 0.88590980, grad/param norm = 2.4991e-01, time/batch = 16.4454s	
14203/22950 (epoch 30.943), train_loss = 0.92173622, grad/param norm = 2.4006e-01, time/batch = 19.3800s	
14204/22950 (epoch 30.946), train_loss = 0.77902424, grad/param norm = 2.1521e-01, time/batch = 16.9264s	
14205/22950 (epoch 30.948), train_loss = 0.99629682, grad/param norm = 2.4299e-01, time/batch = 16.7323s	
14206/22950 (epoch 30.950), train_loss = 0.90055520, grad/param norm = 2.6640e-01, time/batch = 16.1852s	
14207/22950 (epoch 30.952), train_loss = 0.95002501, grad/param norm = 2.2577e-01, time/batch = 16.0999s	
14208/22950 (epoch 30.954), train_loss = 0.93573705, grad/param norm = 2.1764e-01, time/batch = 16.5056s	
14209/22950 (epoch 30.956), train_loss = 0.86688210, grad/param norm = 2.4507e-01, time/batch = 15.9530s	
14210/22950 (epoch 30.959), train_loss = 0.83589431, grad/param norm = 2.2595e-01, time/batch = 16.2563s	
14211/22950 (epoch 30.961), train_loss = 0.91368913, grad/param norm = 2.2481e-01, time/batch = 16.2391s	
14212/22950 (epoch 30.963), train_loss = 0.92047565, grad/param norm = 2.4384e-01, time/batch = 16.5710s	
14213/22950 (epoch 30.965), train_loss = 1.00568896, grad/param norm = 2.4708e-01, time/batch = 16.5977s	
14214/22950 (epoch 30.967), train_loss = 0.89970275, grad/param norm = 2.5369e-01, time/batch = 16.5389s	
14215/22950 (epoch 30.969), train_loss = 0.81619301, grad/param norm = 2.2920e-01, time/batch = 15.4737s	
14216/22950 (epoch 30.972), train_loss = 0.88281881, grad/param norm = 2.0345e-01, time/batch = 15.6996s	
14217/22950 (epoch 30.974), train_loss = 0.87686763, grad/param norm = 2.5177e-01, time/batch = 16.1020s	
14218/22950 (epoch 30.976), train_loss = 0.86612531, grad/param norm = 2.1703e-01, time/batch = 15.3143s	
14219/22950 (epoch 30.978), train_loss = 0.83214546, grad/param norm = 2.4157e-01, time/batch = 15.7712s	
14220/22950 (epoch 30.980), train_loss = 0.86277119, grad/param norm = 2.2657e-01, time/batch = 15.2283s	
14221/22950 (epoch 30.983), train_loss = 0.96554247, grad/param norm = 2.4176e-01, time/batch = 15.1501s	
14222/22950 (epoch 30.985), train_loss = 0.78919424, grad/param norm = 2.2609e-01, time/batch = 15.1483s	
14223/22950 (epoch 30.987), train_loss = 0.84429294, grad/param norm = 2.2286e-01, time/batch = 15.3064s	
14224/22950 (epoch 30.989), train_loss = 0.91144520, grad/param norm = 2.2189e-01, time/batch = 14.9772s	
14225/22950 (epoch 30.991), train_loss = 0.77115059, grad/param norm = 2.2408e-01, time/batch = 14.6577s	
14226/22950 (epoch 30.993), train_loss = 0.92663698, grad/param norm = 2.2451e-01, time/batch = 14.8228s	
14227/22950 (epoch 30.996), train_loss = 0.88770777, grad/param norm = 2.4378e-01, time/batch = 15.2953s	
14228/22950 (epoch 30.998), train_loss = 0.81986353, grad/param norm = 2.4391e-01, time/batch = 15.1413s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
14229/22950 (epoch 31.000), train_loss = 0.74912599, grad/param norm = 1.9536e-01, time/batch = 14.9036s	
14230/22950 (epoch 31.002), train_loss = 1.04638502, grad/param norm = 2.5106e-01, time/batch = 16.2085s	
14231/22950 (epoch 31.004), train_loss = 0.93387187, grad/param norm = 2.3815e-01, time/batch = 16.3708s	
14232/22950 (epoch 31.007), train_loss = 0.89272003, grad/param norm = 2.6674e-01, time/batch = 15.9362s	
14233/22950 (epoch 31.009), train_loss = 1.02970789, grad/param norm = 2.8734e-01, time/batch = 15.2955s	
14234/22950 (epoch 31.011), train_loss = 0.78574885, grad/param norm = 2.3706e-01, time/batch = 16.0071s	
14235/22950 (epoch 31.013), train_loss = 0.89601501, grad/param norm = 2.3882e-01, time/batch = 15.7044s	
14236/22950 (epoch 31.015), train_loss = 0.92531683, grad/param norm = 2.9080e-01, time/batch = 15.5944s	
14237/22950 (epoch 31.017), train_loss = 0.90432594, grad/param norm = 2.1905e-01, time/batch = 15.3056s	
14238/22950 (epoch 31.020), train_loss = 0.94171305, grad/param norm = 2.3134e-01, time/batch = 15.5655s	
14239/22950 (epoch 31.022), train_loss = 0.79153801, grad/param norm = 2.1915e-01, time/batch = 15.6298s	
14240/22950 (epoch 31.024), train_loss = 0.87706462, grad/param norm = 2.3205e-01, time/batch = 15.1611s	
14241/22950 (epoch 31.026), train_loss = 0.92528173, grad/param norm = 2.3708e-01, time/batch = 15.2506s	
14242/22950 (epoch 31.028), train_loss = 0.99268354, grad/param norm = 2.2755e-01, time/batch = 15.9628s	
14243/22950 (epoch 31.031), train_loss = 0.87126911, grad/param norm = 2.2142e-01, time/batch = 15.3072s	
14244/22950 (epoch 31.033), train_loss = 0.98839246, grad/param norm = 2.4389e-01, time/batch = 15.4775s	
14245/22950 (epoch 31.035), train_loss = 0.88672042, grad/param norm = 2.2840e-01, time/batch = 15.1588s	
14246/22950 (epoch 31.037), train_loss = 0.89697494, grad/param norm = 2.2162e-01, time/batch = 15.7891s	
14247/22950 (epoch 31.039), train_loss = 0.88213208, grad/param norm = 2.3434e-01, time/batch = 15.4718s	
14248/22950 (epoch 31.041), train_loss = 0.84107005, grad/param norm = 2.4476e-01, time/batch = 15.1551s	
14249/22950 (epoch 31.044), train_loss = 0.96019067, grad/param norm = 2.5692e-01, time/batch = 15.1496s	
14250/22950 (epoch 31.046), train_loss = 0.90396265, grad/param norm = 2.3784e-01, time/batch = 15.7674s	
14251/22950 (epoch 31.048), train_loss = 0.90985359, grad/param norm = 2.3147e-01, time/batch = 16.2415s	
14252/22950 (epoch 31.050), train_loss = 0.86836987, grad/param norm = 2.6913e-01, time/batch = 15.9192s	
14253/22950 (epoch 31.052), train_loss = 0.93100636, grad/param norm = 2.3035e-01, time/batch = 15.5475s	
14254/22950 (epoch 31.054), train_loss = 1.04128879, grad/param norm = 2.3660e-01, time/batch = 16.5277s	
14255/22950 (epoch 31.057), train_loss = 0.98988860, grad/param norm = 2.6196e-01, time/batch = 16.1662s	
14256/22950 (epoch 31.059), train_loss = 0.99285421, grad/param norm = 2.4409e-01, time/batch = 15.5461s	
14257/22950 (epoch 31.061), train_loss = 0.85904865, grad/param norm = 2.2745e-01, time/batch = 15.6759s	
14258/22950 (epoch 31.063), train_loss = 0.93902584, grad/param norm = 2.3084e-01, time/batch = 15.9169s	
14259/22950 (epoch 31.065), train_loss = 0.81014639, grad/param norm = 2.2603e-01, time/batch = 15.0503s	
14260/22950 (epoch 31.068), train_loss = 0.93224577, grad/param norm = 2.2730e-01, time/batch = 14.8230s	
14261/22950 (epoch 31.070), train_loss = 0.82380325, grad/param norm = 2.1236e-01, time/batch = 15.3763s	
14262/22950 (epoch 31.072), train_loss = 0.98068886, grad/param norm = 2.5620e-01, time/batch = 14.9872s	
14263/22950 (epoch 31.074), train_loss = 0.93003673, grad/param norm = 2.3035e-01, time/batch = 15.1360s	
14264/22950 (epoch 31.076), train_loss = 0.94854726, grad/param norm = 2.4209e-01, time/batch = 15.2226s	
14265/22950 (epoch 31.078), train_loss = 1.00881731, grad/param norm = 2.5659e-01, time/batch = 15.8627s	
14266/22950 (epoch 31.081), train_loss = 1.02726718, grad/param norm = 2.5368e-01, time/batch = 15.3922s	
14267/22950 (epoch 31.083), train_loss = 0.92511208, grad/param norm = 2.2918e-01, time/batch = 15.3904s	
14268/22950 (epoch 31.085), train_loss = 0.80444649, grad/param norm = 2.4220e-01, time/batch = 15.1408s	
14269/22950 (epoch 31.087), train_loss = 0.83105719, grad/param norm = 2.4151e-01, time/batch = 15.7693s	
14270/22950 (epoch 31.089), train_loss = 0.96109198, grad/param norm = 2.8985e-01, time/batch = 15.3070s	
14271/22950 (epoch 31.092), train_loss = 0.86571764, grad/param norm = 2.6782e-01, time/batch = 15.6986s	
14272/22950 (epoch 31.094), train_loss = 0.83657574, grad/param norm = 2.3167e-01, time/batch = 15.3059s	
14273/22950 (epoch 31.096), train_loss = 1.01174495, grad/param norm = 2.6121e-01, time/batch = 16.3207s	
14274/22950 (epoch 31.098), train_loss = 0.96605866, grad/param norm = 2.7696e-01, time/batch = 15.2264s	
14275/22950 (epoch 31.100), train_loss = 0.90247463, grad/param norm = 2.8072e-01, time/batch = 15.9312s	
14276/22950 (epoch 31.102), train_loss = 0.91451073, grad/param norm = 2.4314e-01, time/batch = 15.6661s	
14277/22950 (epoch 31.105), train_loss = 0.75561867, grad/param norm = 2.0246e-01, time/batch = 16.1325s	
14278/22950 (epoch 31.107), train_loss = 0.83808740, grad/param norm = 2.2614e-01, time/batch = 15.9352s	
14279/22950 (epoch 31.109), train_loss = 0.87753744, grad/param norm = 2.5234e-01, time/batch = 16.3925s	
14280/22950 (epoch 31.111), train_loss = 0.77824323, grad/param norm = 2.3064e-01, time/batch = 16.4081s	
14281/22950 (epoch 31.113), train_loss = 0.95064410, grad/param norm = 2.4600e-01, time/batch = 16.2026s	
14282/22950 (epoch 31.115), train_loss = 0.90763645, grad/param norm = 2.2409e-01, time/batch = 15.2363s	
14283/22950 (epoch 31.118), train_loss = 1.02395680, grad/param norm = 2.3608e-01, time/batch = 15.7818s	
14284/22950 (epoch 31.120), train_loss = 0.83094831, grad/param norm = 2.1724e-01, time/batch = 16.3195s	
14285/22950 (epoch 31.122), train_loss = 0.98001630, grad/param norm = 2.4677e-01, time/batch = 15.4551s	
14286/22950 (epoch 31.124), train_loss = 0.80007796, grad/param norm = 2.0864e-01, time/batch = 15.2217s	
14287/22950 (epoch 31.126), train_loss = 0.90287361, grad/param norm = 2.3994e-01, time/batch = 14.9138s	
14288/22950 (epoch 31.129), train_loss = 0.83617081, grad/param norm = 2.0160e-01, time/batch = 15.6015s	
14289/22950 (epoch 31.131), train_loss = 0.88138093, grad/param norm = 2.2402e-01, time/batch = 15.0602s	
14290/22950 (epoch 31.133), train_loss = 0.94400054, grad/param norm = 2.2531e-01, time/batch = 15.6106s	
14291/22950 (epoch 31.135), train_loss = 0.89452588, grad/param norm = 2.0665e-01, time/batch = 15.6404s	
14292/22950 (epoch 31.137), train_loss = 0.98226362, grad/param norm = 2.6242e-01, time/batch = 15.6896s	
14293/22950 (epoch 31.139), train_loss = 0.83472044, grad/param norm = 2.9523e-01, time/batch = 15.0009s	
14294/22950 (epoch 31.142), train_loss = 0.82137631, grad/param norm = 2.3109e-01, time/batch = 15.4636s	
14295/22950 (epoch 31.144), train_loss = 0.86607065, grad/param norm = 2.1809e-01, time/batch = 14.9959s	
14296/22950 (epoch 31.146), train_loss = 0.84156310, grad/param norm = 2.4295e-01, time/batch = 16.0799s	
14297/22950 (epoch 31.148), train_loss = 0.86201105, grad/param norm = 2.4849e-01, time/batch = 16.5817s	
14298/22950 (epoch 31.150), train_loss = 0.92375020, grad/param norm = 2.4078e-01, time/batch = 16.0309s	
14299/22950 (epoch 31.153), train_loss = 0.83468834, grad/param norm = 2.0951e-01, time/batch = 16.1093s	
14300/22950 (epoch 31.155), train_loss = 0.84565013, grad/param norm = 1.9442e-01, time/batch = 16.2740s	
14301/22950 (epoch 31.157), train_loss = 0.88413465, grad/param norm = 2.1416e-01, time/batch = 17.0282s	
14302/22950 (epoch 31.159), train_loss = 0.81275538, grad/param norm = 2.0268e-01, time/batch = 15.7613s	
14303/22950 (epoch 31.161), train_loss = 0.88319925, grad/param norm = 2.3369e-01, time/batch = 16.7688s	
14304/22950 (epoch 31.163), train_loss = 0.79475373, grad/param norm = 2.2220e-01, time/batch = 16.7942s	
14305/22950 (epoch 31.166), train_loss = 0.95757226, grad/param norm = 2.7335e-01, time/batch = 16.1869s	
14306/22950 (epoch 31.168), train_loss = 0.93532425, grad/param norm = 2.5716e-01, time/batch = 15.5450s	
14307/22950 (epoch 31.170), train_loss = 0.89457891, grad/param norm = 2.5225e-01, time/batch = 15.8380s	
14308/22950 (epoch 31.172), train_loss = 0.92298029, grad/param norm = 2.3597e-01, time/batch = 15.7207s	
14309/22950 (epoch 31.174), train_loss = 0.99065228, grad/param norm = 2.5369e-01, time/batch = 16.3501s	
14310/22950 (epoch 31.176), train_loss = 0.98145845, grad/param norm = 2.5948e-01, time/batch = 15.3772s	
14311/22950 (epoch 31.179), train_loss = 0.95423589, grad/param norm = 2.8290e-01, time/batch = 15.7062s	
14312/22950 (epoch 31.181), train_loss = 1.14178485, grad/param norm = 2.6126e-01, time/batch = 15.4504s	
14313/22950 (epoch 31.183), train_loss = 0.95023789, grad/param norm = 2.3998e-01, time/batch = 15.3080s	
14314/22950 (epoch 31.185), train_loss = 0.92810859, grad/param norm = 2.2921e-01, time/batch = 15.2267s	
14315/22950 (epoch 31.187), train_loss = 0.84288412, grad/param norm = 2.5308e-01, time/batch = 15.2279s	
14316/22950 (epoch 31.190), train_loss = 0.75065343, grad/param norm = 2.2383e-01, time/batch = 15.4322s	
14317/22950 (epoch 31.192), train_loss = 0.71790236, grad/param norm = 2.0440e-01, time/batch = 14.8341s	
14318/22950 (epoch 31.194), train_loss = 0.88028681, grad/param norm = 2.6308e-01, time/batch = 15.6229s	
14319/22950 (epoch 31.196), train_loss = 0.69500098, grad/param norm = 2.4059e-01, time/batch = 15.1496s	
14320/22950 (epoch 31.198), train_loss = 0.93806786, grad/param norm = 2.4837e-01, time/batch = 15.0523s	
14321/22950 (epoch 31.200), train_loss = 0.83221335, grad/param norm = 2.0721e-01, time/batch = 15.1486s	
14322/22950 (epoch 31.203), train_loss = 0.79551517, grad/param norm = 2.3526e-01, time/batch = 16.7163s	
14323/22950 (epoch 31.205), train_loss = 0.84442209, grad/param norm = 2.3773e-01, time/batch = 15.7787s	
14324/22950 (epoch 31.207), train_loss = 0.92896978, grad/param norm = 2.5985e-01, time/batch = 16.2504s	
14325/22950 (epoch 31.209), train_loss = 0.88075922, grad/param norm = 2.4514e-01, time/batch = 16.3237s	
14326/22950 (epoch 31.211), train_loss = 0.75153511, grad/param norm = 2.1456e-01, time/batch = 18.1943s	
14327/22950 (epoch 31.214), train_loss = 0.82504487, grad/param norm = 2.2054e-01, time/batch = 16.9511s	
14328/22950 (epoch 31.216), train_loss = 0.96707281, grad/param norm = 2.2513e-01, time/batch = 18.2630s	
14329/22950 (epoch 31.218), train_loss = 0.89160230, grad/param norm = 2.1213e-01, time/batch = 15.8679s	
14330/22950 (epoch 31.220), train_loss = 0.97436142, grad/param norm = 2.4764e-01, time/batch = 16.8561s	
14331/22950 (epoch 31.222), train_loss = 1.00933742, grad/param norm = 2.7006e-01, time/batch = 18.1854s	
14332/22950 (epoch 31.224), train_loss = 0.89828835, grad/param norm = 2.3736e-01, time/batch = 17.6711s	
14333/22950 (epoch 31.227), train_loss = 0.94996263, grad/param norm = 2.3082e-01, time/batch = 17.5149s	
14334/22950 (epoch 31.229), train_loss = 1.00887614, grad/param norm = 2.4504e-01, time/batch = 17.7683s	
14335/22950 (epoch 31.231), train_loss = 0.75189382, grad/param norm = 2.2943e-01, time/batch = 16.8142s	
14336/22950 (epoch 31.233), train_loss = 0.86105968, grad/param norm = 2.3057e-01, time/batch = 16.0579s	
14337/22950 (epoch 31.235), train_loss = 1.04116120, grad/param norm = 2.7481e-01, time/batch = 17.0209s	
14338/22950 (epoch 31.237), train_loss = 0.84785210, grad/param norm = 2.2434e-01, time/batch = 19.0994s	
14339/22950 (epoch 31.240), train_loss = 0.89594732, grad/param norm = 2.3305e-01, time/batch = 22.9983s	
14340/22950 (epoch 31.242), train_loss = 1.04363021, grad/param norm = 2.4538e-01, time/batch = 25.7062s	
14341/22950 (epoch 31.244), train_loss = 1.01146160, grad/param norm = 2.6901e-01, time/batch = 18.2678s	
14342/22950 (epoch 31.246), train_loss = 1.01683514, grad/param norm = 2.6510e-01, time/batch = 16.3154s	
14343/22950 (epoch 31.248), train_loss = 0.93432762, grad/param norm = 2.7053e-01, time/batch = 18.0734s	
14344/22950 (epoch 31.251), train_loss = 0.84390439, grad/param norm = 2.3160e-01, time/batch = 16.7425s	
14345/22950 (epoch 31.253), train_loss = 0.83702165, grad/param norm = 2.6738e-01, time/batch = 16.0363s	
14346/22950 (epoch 31.255), train_loss = 0.94900219, grad/param norm = 2.4231e-01, time/batch = 16.3484s	
14347/22950 (epoch 31.257), train_loss = 1.00218249, grad/param norm = 2.6115e-01, time/batch = 16.2955s	
14348/22950 (epoch 31.259), train_loss = 0.77560400, grad/param norm = 2.1702e-01, time/batch = 16.3459s	
14349/22950 (epoch 31.261), train_loss = 0.85341806, grad/param norm = 2.5365e-01, time/batch = 16.3569s	
14350/22950 (epoch 31.264), train_loss = 0.80718641, grad/param norm = 2.3449e-01, time/batch = 16.7505s	
14351/22950 (epoch 31.266), train_loss = 0.88903752, grad/param norm = 2.8790e-01, time/batch = 16.5941s	
14352/22950 (epoch 31.268), train_loss = 0.91422835, grad/param norm = 2.5426e-01, time/batch = 16.3585s	
14353/22950 (epoch 31.270), train_loss = 0.89026681, grad/param norm = 2.3454e-01, time/batch = 17.3376s	
14354/22950 (epoch 31.272), train_loss = 0.92203861, grad/param norm = 2.4239e-01, time/batch = 16.4345s	
14355/22950 (epoch 31.275), train_loss = 0.84646022, grad/param norm = 2.3399e-01, time/batch = 16.3456s	
14356/22950 (epoch 31.277), train_loss = 0.74889362, grad/param norm = 2.1288e-01, time/batch = 16.5893s	
14357/22950 (epoch 31.279), train_loss = 0.79732891, grad/param norm = 2.4340e-01, time/batch = 16.1929s	
14358/22950 (epoch 31.281), train_loss = 0.86069658, grad/param norm = 2.4465e-01, time/batch = 16.1215s	
14359/22950 (epoch 31.283), train_loss = 0.78307668, grad/param norm = 2.0253e-01, time/batch = 16.7102s	
14360/22950 (epoch 31.285), train_loss = 0.91517121, grad/param norm = 2.2610e-01, time/batch = 16.7159s	
14361/22950 (epoch 31.288), train_loss = 0.99828718, grad/param norm = 2.3157e-01, time/batch = 16.6055s	
14362/22950 (epoch 31.290), train_loss = 0.85099674, grad/param norm = 2.1154e-01, time/batch = 16.5101s	
14363/22950 (epoch 31.292), train_loss = 0.99039262, grad/param norm = 2.4449e-01, time/batch = 16.1140s	
14364/22950 (epoch 31.294), train_loss = 0.90923799, grad/param norm = 2.1263e-01, time/batch = 16.5083s	
14365/22950 (epoch 31.296), train_loss = 0.70822933, grad/param norm = 1.9267e-01, time/batch = 16.5157s	
14366/22950 (epoch 31.298), train_loss = 0.88122952, grad/param norm = 2.1742e-01, time/batch = 16.8070s	
14367/22950 (epoch 31.301), train_loss = 0.93314028, grad/param norm = 2.7326e-01, time/batch = 16.4951s	
14368/22950 (epoch 31.303), train_loss = 0.87018913, grad/param norm = 2.0194e-01, time/batch = 15.7951s	
14369/22950 (epoch 31.305), train_loss = 0.87871323, grad/param norm = 2.4781e-01, time/batch = 15.8783s	
14370/22950 (epoch 31.307), train_loss = 1.00689354, grad/param norm = 2.4931e-01, time/batch = 16.7363s	
14371/22950 (epoch 31.309), train_loss = 0.83462334, grad/param norm = 2.1047e-01, time/batch = 16.2013s	
14372/22950 (epoch 31.312), train_loss = 0.89774450, grad/param norm = 2.1512e-01, time/batch = 15.7156s	
14373/22950 (epoch 31.314), train_loss = 0.91366875, grad/param norm = 2.1411e-01, time/batch = 15.7831s	
14374/22950 (epoch 31.316), train_loss = 0.86759865, grad/param norm = 2.5023e-01, time/batch = 15.5383s	
14375/22950 (epoch 31.318), train_loss = 0.76220822, grad/param norm = 1.8758e-01, time/batch = 16.1909s	
14376/22950 (epoch 31.320), train_loss = 0.82015330, grad/param norm = 2.0431e-01, time/batch = 15.7971s	
14377/22950 (epoch 31.322), train_loss = 0.85812535, grad/param norm = 2.3981e-01, time/batch = 15.9572s	
14378/22950 (epoch 31.325), train_loss = 0.69782735, grad/param norm = 2.0283e-01, time/batch = 15.9538s	
14379/22950 (epoch 31.327), train_loss = 0.72049776, grad/param norm = 2.2630e-01, time/batch = 16.5651s	
14380/22950 (epoch 31.329), train_loss = 0.83161104, grad/param norm = 2.4407e-01, time/batch = 16.4670s	
14381/22950 (epoch 31.331), train_loss = 0.77601492, grad/param norm = 2.1106e-01, time/batch = 16.0440s	
14382/22950 (epoch 31.333), train_loss = 0.81212902, grad/param norm = 2.1754e-01, time/batch = 16.5736s	
14383/22950 (epoch 31.336), train_loss = 0.87519621, grad/param norm = 2.5835e-01, time/batch = 15.7078s	
14384/22950 (epoch 31.338), train_loss = 0.87953237, grad/param norm = 2.0209e-01, time/batch = 15.3974s	
14385/22950 (epoch 31.340), train_loss = 0.87083398, grad/param norm = 2.6423e-01, time/batch = 15.5540s	
14386/22950 (epoch 31.342), train_loss = 1.04459180, grad/param norm = 2.6286e-01, time/batch = 15.7893s	
14387/22950 (epoch 31.344), train_loss = 0.86775719, grad/param norm = 2.3464e-01, time/batch = 15.6864s	
14388/22950 (epoch 31.346), train_loss = 0.97355995, grad/param norm = 2.7574e-01, time/batch = 15.6388s	
14389/22950 (epoch 31.349), train_loss = 0.87070797, grad/param norm = 2.1265e-01, time/batch = 15.4576s	
14390/22950 (epoch 31.351), train_loss = 0.88493479, grad/param norm = 2.3178e-01, time/batch = 15.6335s	
14391/22950 (epoch 31.353), train_loss = 0.94270212, grad/param norm = 2.6426e-01, time/batch = 15.4671s	
14392/22950 (epoch 31.355), train_loss = 0.98488314, grad/param norm = 2.6124e-01, time/batch = 15.4750s	
14393/22950 (epoch 31.357), train_loss = 0.87981393, grad/param norm = 2.4184e-01, time/batch = 15.8631s	
14394/22950 (epoch 31.359), train_loss = 0.89747221, grad/param norm = 2.5745e-01, time/batch = 15.7048s	
14395/22950 (epoch 31.362), train_loss = 0.93687057, grad/param norm = 2.5767e-01, time/batch = 15.3995s	
14396/22950 (epoch 31.364), train_loss = 0.87858624, grad/param norm = 2.4777e-01, time/batch = 16.1748s	
14397/22950 (epoch 31.366), train_loss = 0.87159766, grad/param norm = 2.1416e-01, time/batch = 15.6280s	
14398/22950 (epoch 31.368), train_loss = 0.96787016, grad/param norm = 2.6614e-01, time/batch = 15.5447s	
14399/22950 (epoch 31.370), train_loss = 0.87013156, grad/param norm = 2.4416e-01, time/batch = 15.5473s	
14400/22950 (epoch 31.373), train_loss = 0.79361801, grad/param norm = 2.1108e-01, time/batch = 15.7052s	
14401/22950 (epoch 31.375), train_loss = 0.99428703, grad/param norm = 2.5117e-01, time/batch = 16.3493s	
14402/22950 (epoch 31.377), train_loss = 0.81488877, grad/param norm = 2.5606e-01, time/batch = 15.8649s	
14403/22950 (epoch 31.379), train_loss = 0.89319820, grad/param norm = 2.5346e-01, time/batch = 15.9287s	
14404/22950 (epoch 31.381), train_loss = 0.77794387, grad/param norm = 2.1995e-01, time/batch = 15.8219s	
14405/22950 (epoch 31.383), train_loss = 0.86432175, grad/param norm = 2.5922e-01, time/batch = 15.8562s	
14406/22950 (epoch 31.386), train_loss = 0.82672067, grad/param norm = 2.5196e-01, time/batch = 15.1503s	
14407/22950 (epoch 31.388), train_loss = 0.95730467, grad/param norm = 2.4082e-01, time/batch = 15.6179s	
14408/22950 (epoch 31.390), train_loss = 0.79170343, grad/param norm = 2.2647e-01, time/batch = 15.6944s	
14409/22950 (epoch 31.392), train_loss = 0.82197785, grad/param norm = 2.2115e-01, time/batch = 15.8772s	
14410/22950 (epoch 31.394), train_loss = 0.84951786, grad/param norm = 2.1959e-01, time/batch = 15.6335s	
14411/22950 (epoch 31.397), train_loss = 0.98132767, grad/param norm = 2.1742e-01, time/batch = 15.8068s	
14412/22950 (epoch 31.399), train_loss = 0.97667844, grad/param norm = 2.4698e-01, time/batch = 15.9559s	
14413/22950 (epoch 31.401), train_loss = 1.03384013, grad/param norm = 2.6000e-01, time/batch = 16.1966s	
14414/22950 (epoch 31.403), train_loss = 0.88368797, grad/param norm = 2.7312e-01, time/batch = 15.7174s	
14415/22950 (epoch 31.405), train_loss = 1.00346063, grad/param norm = 3.1178e-01, time/batch = 15.6449s	
14416/22950 (epoch 31.407), train_loss = 1.03544849, grad/param norm = 2.2497e-01, time/batch = 16.1622s	
14417/22950 (epoch 31.410), train_loss = 0.87566311, grad/param norm = 2.3918e-01, time/batch = 16.6546s	
14418/22950 (epoch 31.412), train_loss = 0.88367141, grad/param norm = 2.4110e-01, time/batch = 16.8499s	
14419/22950 (epoch 31.414), train_loss = 1.00579444, grad/param norm = 2.5144e-01, time/batch = 17.1344s	
14420/22950 (epoch 31.416), train_loss = 0.93340302, grad/param norm = 3.0682e-01, time/batch = 17.1132s	
14421/22950 (epoch 31.418), train_loss = 0.90928706, grad/param norm = 2.7226e-01, time/batch = 17.1588s	
14422/22950 (epoch 31.420), train_loss = 0.99074594, grad/param norm = 3.1390e-01, time/batch = 17.1233s	
14423/22950 (epoch 31.423), train_loss = 0.83923598, grad/param norm = 2.2781e-01, time/batch = 17.1120s	
14424/22950 (epoch 31.425), train_loss = 0.87338896, grad/param norm = 2.2900e-01, time/batch = 17.1539s	
14425/22950 (epoch 31.427), train_loss = 0.90024237, grad/param norm = 2.5057e-01, time/batch = 17.1012s	
14426/22950 (epoch 31.429), train_loss = 0.88675057, grad/param norm = 2.1367e-01, time/batch = 17.1005s	
14427/22950 (epoch 31.431), train_loss = 0.98512450, grad/param norm = 2.6455e-01, time/batch = 16.8434s	
14428/22950 (epoch 31.434), train_loss = 0.90219249, grad/param norm = 2.3123e-01, time/batch = 16.7774s	
14429/22950 (epoch 31.436), train_loss = 0.96967224, grad/param norm = 2.8246e-01, time/batch = 16.8449s	
14430/22950 (epoch 31.438), train_loss = 0.91336260, grad/param norm = 2.3321e-01, time/batch = 16.9860s	
14431/22950 (epoch 31.440), train_loss = 0.97214168, grad/param norm = 2.2389e-01, time/batch = 17.0026s	
14432/22950 (epoch 31.442), train_loss = 1.02238460, grad/param norm = 2.4024e-01, time/batch = 16.9303s	
14433/22950 (epoch 31.444), train_loss = 0.95366049, grad/param norm = 2.5571e-01, time/batch = 16.9315s	
14434/22950 (epoch 31.447), train_loss = 1.04474430, grad/param norm = 2.5202e-01, time/batch = 16.8287s	
14435/22950 (epoch 31.449), train_loss = 0.81413716, grad/param norm = 2.1629e-01, time/batch = 16.9220s	
14436/22950 (epoch 31.451), train_loss = 0.91580775, grad/param norm = 2.5166e-01, time/batch = 17.1056s	
14437/22950 (epoch 31.453), train_loss = 0.94397594, grad/param norm = 2.2585e-01, time/batch = 16.9961s	
14438/22950 (epoch 31.455), train_loss = 0.86355365, grad/param norm = 1.9879e-01, time/batch = 16.8643s	
14439/22950 (epoch 31.458), train_loss = 0.92325062, grad/param norm = 2.4462e-01, time/batch = 17.0263s	
14440/22950 (epoch 31.460), train_loss = 0.96666268, grad/param norm = 2.3621e-01, time/batch = 16.7169s	
14441/22950 (epoch 31.462), train_loss = 0.93302857, grad/param norm = 2.3920e-01, time/batch = 16.9460s	
14442/22950 (epoch 31.464), train_loss = 0.87949189, grad/param norm = 2.3246e-01, time/batch = 17.0395s	
14443/22950 (epoch 31.466), train_loss = 0.98691533, grad/param norm = 2.4960e-01, time/batch = 17.0395s	
14444/22950 (epoch 31.468), train_loss = 0.98167346, grad/param norm = 2.3865e-01, time/batch = 17.0176s	
14445/22950 (epoch 31.471), train_loss = 0.95075580, grad/param norm = 2.6422e-01, time/batch = 17.0006s	
14446/22950 (epoch 31.473), train_loss = 0.95975041, grad/param norm = 2.8377e-01, time/batch = 16.7693s	
14447/22950 (epoch 31.475), train_loss = 1.09907643, grad/param norm = 2.6671e-01, time/batch = 16.7160s	
14448/22950 (epoch 31.477), train_loss = 0.89451353, grad/param norm = 2.4354e-01, time/batch = 17.0735s	
14449/22950 (epoch 31.479), train_loss = 0.79421862, grad/param norm = 2.1976e-01, time/batch = 16.8676s	
14450/22950 (epoch 31.481), train_loss = 0.96824792, grad/param norm = 2.4477e-01, time/batch = 16.7005s	
14451/22950 (epoch 31.484), train_loss = 0.93722427, grad/param norm = 2.5048e-01, time/batch = 16.9290s	
14452/22950 (epoch 31.486), train_loss = 0.78075512, grad/param norm = 2.2182e-01, time/batch = 16.6846s	
14453/22950 (epoch 31.488), train_loss = 0.85928818, grad/param norm = 2.8218e-01, time/batch = 16.5259s	
14454/22950 (epoch 31.490), train_loss = 0.79979058, grad/param norm = 2.6813e-01, time/batch = 15.9816s	
14455/22950 (epoch 31.492), train_loss = 0.86052735, grad/param norm = 2.1316e-01, time/batch = 16.2505s	
14456/22950 (epoch 31.495), train_loss = 0.83139651, grad/param norm = 2.3865e-01, time/batch = 18.0296s	
14457/22950 (epoch 31.497), train_loss = 0.94089638, grad/param norm = 2.4809e-01, time/batch = 16.5583s	
14458/22950 (epoch 31.499), train_loss = 1.04152992, grad/param norm = 2.4500e-01, time/batch = 16.8032s	
14459/22950 (epoch 31.501), train_loss = 0.93568845, grad/param norm = 2.7629e-01, time/batch = 16.8575s	
14460/22950 (epoch 31.503), train_loss = 1.00339181, grad/param norm = 2.6153e-01, time/batch = 16.5072s	
14461/22950 (epoch 31.505), train_loss = 0.76521841, grad/param norm = 2.0403e-01, time/batch = 15.9573s	
14462/22950 (epoch 31.508), train_loss = 0.95426832, grad/param norm = 2.4330e-01, time/batch = 16.8076s	
14463/22950 (epoch 31.510), train_loss = 0.88057621, grad/param norm = 2.3604e-01, time/batch = 19.0984s	
14464/22950 (epoch 31.512), train_loss = 0.80212685, grad/param norm = 2.3063e-01, time/batch = 16.1771s	
14465/22950 (epoch 31.514), train_loss = 0.86763238, grad/param norm = 1.9722e-01, time/batch = 18.1028s	
14466/22950 (epoch 31.516), train_loss = 0.89188776, grad/param norm = 2.2246e-01, time/batch = 17.2349s	
14467/22950 (epoch 31.519), train_loss = 0.90026047, grad/param norm = 2.3624e-01, time/batch = 18.6216s	
14468/22950 (epoch 31.521), train_loss = 0.89705110, grad/param norm = 2.3099e-01, time/batch = 18.0467s	
14469/22950 (epoch 31.523), train_loss = 0.72768130, grad/param norm = 2.1847e-01, time/batch = 17.3629s	
14470/22950 (epoch 31.525), train_loss = 0.81292496, grad/param norm = 2.1255e-01, time/batch = 17.3312s	
14471/22950 (epoch 31.527), train_loss = 0.78165900, grad/param norm = 2.0825e-01, time/batch = 18.2911s	
14472/22950 (epoch 31.529), train_loss = 0.91327086, grad/param norm = 2.4470e-01, time/batch = 18.2100s	
14473/22950 (epoch 31.532), train_loss = 0.87214205, grad/param norm = 2.3956e-01, time/batch = 19.4573s	
14474/22950 (epoch 31.534), train_loss = 0.93566716, grad/param norm = 2.6970e-01, time/batch = 19.3590s	
14475/22950 (epoch 31.536), train_loss = 0.96064042, grad/param norm = 2.8915e-01, time/batch = 18.2908s	
14476/22950 (epoch 31.538), train_loss = 0.92567668, grad/param norm = 2.5951e-01, time/batch = 16.1487s	
14477/22950 (epoch 31.540), train_loss = 0.95024227, grad/param norm = 2.4983e-01, time/batch = 15.2183s	
14478/22950 (epoch 31.542), train_loss = 1.04504621, grad/param norm = 2.9600e-01, time/batch = 15.5279s	
14479/22950 (epoch 31.545), train_loss = 0.86842159, grad/param norm = 2.1629e-01, time/batch = 15.4698s	
14480/22950 (epoch 31.547), train_loss = 0.89563458, grad/param norm = 2.3525e-01, time/batch = 14.7618s	
14481/22950 (epoch 31.549), train_loss = 0.84411329, grad/param norm = 2.6654e-01, time/batch = 15.4659s	
14482/22950 (epoch 31.551), train_loss = 0.88182995, grad/param norm = 2.3661e-01, time/batch = 15.5248s	
14483/22950 (epoch 31.553), train_loss = 0.85734695, grad/param norm = 3.0761e-01, time/batch = 15.7201s	
14484/22950 (epoch 31.556), train_loss = 0.93006993, grad/param norm = 2.2861e-01, time/batch = 16.2768s	
14485/22950 (epoch 31.558), train_loss = 0.76193830, grad/param norm = 2.1984e-01, time/batch = 16.1196s	
14486/22950 (epoch 31.560), train_loss = 0.85571640, grad/param norm = 2.3383e-01, time/batch = 17.1859s	
14487/22950 (epoch 31.562), train_loss = 0.81292709, grad/param norm = 2.2270e-01, time/batch = 18.2057s	
14488/22950 (epoch 31.564), train_loss = 0.94441653, grad/param norm = 2.8090e-01, time/batch = 15.5599s	
14489/22950 (epoch 31.566), train_loss = 0.92617677, grad/param norm = 2.3783e-01, time/batch = 15.2202s	
14490/22950 (epoch 31.569), train_loss = 0.88371962, grad/param norm = 2.4220e-01, time/batch = 18.0331s	
14491/22950 (epoch 31.571), train_loss = 0.88122485, grad/param norm = 2.6923e-01, time/batch = 17.9470s	
14492/22950 (epoch 31.573), train_loss = 0.88708464, grad/param norm = 2.4333e-01, time/batch = 18.5521s	
14493/22950 (epoch 31.575), train_loss = 1.00363603, grad/param norm = 3.1618e-01, time/batch = 16.6928s	
14494/22950 (epoch 31.577), train_loss = 0.90860596, grad/param norm = 2.5092e-01, time/batch = 15.9833s	
14495/22950 (epoch 31.580), train_loss = 0.95205731, grad/param norm = 2.5589e-01, time/batch = 16.1141s	
14496/22950 (epoch 31.582), train_loss = 1.05116405, grad/param norm = 2.7112e-01, time/batch = 16.8740s	
14497/22950 (epoch 31.584), train_loss = 0.78483098, grad/param norm = 2.5409e-01, time/batch = 16.9979s	
14498/22950 (epoch 31.586), train_loss = 0.80810334, grad/param norm = 2.2462e-01, time/batch = 18.0531s	
14499/22950 (epoch 31.588), train_loss = 1.01500549, grad/param norm = 2.4665e-01, time/batch = 16.8590s	
14500/22950 (epoch 31.590), train_loss = 0.94011375, grad/param norm = 2.5130e-01, time/batch = 18.9372s	
14501/22950 (epoch 31.593), train_loss = 0.87950791, grad/param norm = 2.4887e-01, time/batch = 17.5280s	
14502/22950 (epoch 31.595), train_loss = 0.79946534, grad/param norm = 2.2712e-01, time/batch = 16.0745s	
14503/22950 (epoch 31.597), train_loss = 0.97755296, grad/param norm = 2.4930e-01, time/batch = 19.2807s	
14504/22950 (epoch 31.599), train_loss = 0.90336248, grad/param norm = 2.6665e-01, time/batch = 16.7962s	
14505/22950 (epoch 31.601), train_loss = 0.93142440, grad/param norm = 2.3895e-01, time/batch = 19.0422s	
14506/22950 (epoch 31.603), train_loss = 1.01406373, grad/param norm = 2.5865e-01, time/batch = 17.0900s	
14507/22950 (epoch 31.606), train_loss = 0.91579327, grad/param norm = 2.3365e-01, time/batch = 17.8410s	
14508/22950 (epoch 31.608), train_loss = 0.91564733, grad/param norm = 2.4273e-01, time/batch = 18.9187s	
14509/22950 (epoch 31.610), train_loss = 0.90831521, grad/param norm = 2.5319e-01, time/batch = 20.1841s	
14510/22950 (epoch 31.612), train_loss = 0.91767918, grad/param norm = 2.5863e-01, time/batch = 19.3757s	
14511/22950 (epoch 31.614), train_loss = 1.02649753, grad/param norm = 3.1083e-01, time/batch = 17.6926s	
14512/22950 (epoch 31.617), train_loss = 0.90729131, grad/param norm = 2.2253e-01, time/batch = 16.6285s	
14513/22950 (epoch 31.619), train_loss = 0.85737810, grad/param norm = 2.1241e-01, time/batch = 16.3281s	
14514/22950 (epoch 31.621), train_loss = 0.97483826, grad/param norm = 2.3519e-01, time/batch = 16.0816s	
14515/22950 (epoch 31.623), train_loss = 0.96710254, grad/param norm = 2.4945e-01, time/batch = 15.3129s	
14516/22950 (epoch 31.625), train_loss = 0.90546520, grad/param norm = 2.7846e-01, time/batch = 15.2387s	
14517/22950 (epoch 31.627), train_loss = 0.88156645, grad/param norm = 2.5690e-01, time/batch = 15.2208s	
14518/22950 (epoch 31.630), train_loss = 0.77434440, grad/param norm = 2.0430e-01, time/batch = 16.0321s	
14519/22950 (epoch 31.632), train_loss = 0.86037374, grad/param norm = 2.9723e-01, time/batch = 15.8863s	
14520/22950 (epoch 31.634), train_loss = 0.93441515, grad/param norm = 2.5772e-01, time/batch = 15.5523s	
14521/22950 (epoch 31.636), train_loss = 0.90093902, grad/param norm = 2.7598e-01, time/batch = 15.7121s	
14522/22950 (epoch 31.638), train_loss = 0.84866440, grad/param norm = 2.4255e-01, time/batch = 16.2886s	
14523/22950 (epoch 31.641), train_loss = 0.86854536, grad/param norm = 2.3759e-01, time/batch = 15.6311s	
14524/22950 (epoch 31.643), train_loss = 0.94925472, grad/param norm = 2.9165e-01, time/batch = 15.6349s	
14525/22950 (epoch 31.645), train_loss = 0.86596257, grad/param norm = 2.2778e-01, time/batch = 16.1755s	
14526/22950 (epoch 31.647), train_loss = 0.87886794, grad/param norm = 2.4936e-01, time/batch = 15.5554s	
14527/22950 (epoch 31.649), train_loss = 0.86129635, grad/param norm = 2.6080e-01, time/batch = 15.6340s	
14528/22950 (epoch 31.651), train_loss = 0.97249020, grad/param norm = 2.5980e-01, time/batch = 15.4767s	
14529/22950 (epoch 31.654), train_loss = 0.76382166, grad/param norm = 2.1410e-01, time/batch = 15.7901s	
14530/22950 (epoch 31.656), train_loss = 0.95531443, grad/param norm = 3.2484e-01, time/batch = 15.6368s	
14531/22950 (epoch 31.658), train_loss = 0.81963819, grad/param norm = 2.4950e-01, time/batch = 15.8844s	
14532/22950 (epoch 31.660), train_loss = 0.73621271, grad/param norm = 2.4548e-01, time/batch = 15.5442s	
14533/22950 (epoch 31.662), train_loss = 0.74768624, grad/param norm = 2.3549e-01, time/batch = 16.6347s	
14534/22950 (epoch 31.664), train_loss = 0.86862163, grad/param norm = 2.4729e-01, time/batch = 16.8376s	
14535/22950 (epoch 31.667), train_loss = 0.90878900, grad/param norm = 2.4899e-01, time/batch = 16.8361s	
14536/22950 (epoch 31.669), train_loss = 0.90169504, grad/param norm = 2.5254e-01, time/batch = 16.5347s	
14537/22950 (epoch 31.671), train_loss = 0.89380049, grad/param norm = 2.5473e-01, time/batch = 16.5943s	
14538/22950 (epoch 31.673), train_loss = 0.84762273, grad/param norm = 2.6122e-01, time/batch = 16.3682s	
14539/22950 (epoch 31.675), train_loss = 0.93097795, grad/param norm = 2.5447e-01, time/batch = 16.3061s	
14540/22950 (epoch 31.678), train_loss = 0.90108552, grad/param norm = 2.8532e-01, time/batch = 16.3778s	
14541/22950 (epoch 31.680), train_loss = 0.91493572, grad/param norm = 2.2564e-01, time/batch = 16.5509s	
14542/22950 (epoch 31.682), train_loss = 0.86348769, grad/param norm = 2.3984e-01, time/batch = 16.5326s	
14543/22950 (epoch 31.684), train_loss = 0.98791774, grad/param norm = 2.7143e-01, time/batch = 15.8936s	
14544/22950 (epoch 31.686), train_loss = 0.99606482, grad/param norm = 2.4427e-01, time/batch = 15.8843s	
14545/22950 (epoch 31.688), train_loss = 0.92330427, grad/param norm = 2.4322e-01, time/batch = 15.7293s	
14546/22950 (epoch 31.691), train_loss = 0.89940423, grad/param norm = 2.4399e-01, time/batch = 15.3959s	
14547/22950 (epoch 31.693), train_loss = 0.83247897, grad/param norm = 2.5302e-01, time/batch = 15.3073s	
14548/22950 (epoch 31.695), train_loss = 0.99287665, grad/param norm = 2.7377e-01, time/batch = 15.7838s	
14549/22950 (epoch 31.697), train_loss = 0.95798019, grad/param norm = 2.9848e-01, time/batch = 15.2258s	
14550/22950 (epoch 31.699), train_loss = 0.93845418, grad/param norm = 2.3861e-01, time/batch = 15.7838s	
14551/22950 (epoch 31.702), train_loss = 0.96869757, grad/param norm = 2.6582e-01, time/batch = 16.1021s	
14552/22950 (epoch 31.704), train_loss = 1.04408916, grad/param norm = 2.6555e-01, time/batch = 15.2209s	
14553/22950 (epoch 31.706), train_loss = 0.98443393, grad/param norm = 2.5587e-01, time/batch = 15.6364s	
14554/22950 (epoch 31.708), train_loss = 0.80077886, grad/param norm = 2.4677e-01, time/batch = 15.9293s	
14555/22950 (epoch 31.710), train_loss = 0.91175106, grad/param norm = 2.4058e-01, time/batch = 22.7540s	
14556/22950 (epoch 31.712), train_loss = 1.02290126, grad/param norm = 2.7065e-01, time/batch = 21.8258s	
14557/22950 (epoch 31.715), train_loss = 0.91729129, grad/param norm = 2.3774e-01, time/batch = 15.7593s	
14558/22950 (epoch 31.717), train_loss = 0.94289264, grad/param norm = 2.3692e-01, time/batch = 16.2577s	
14559/22950 (epoch 31.719), train_loss = 0.85402783, grad/param norm = 2.2144e-01, time/batch = 15.9422s	
14560/22950 (epoch 31.721), train_loss = 0.96138127, grad/param norm = 2.4868e-01, time/batch = 16.1728s	
14561/22950 (epoch 31.723), train_loss = 0.90841511, grad/param norm = 2.5296e-01, time/batch = 15.3100s	
14562/22950 (epoch 31.725), train_loss = 0.97528921, grad/param norm = 2.7825e-01, time/batch = 15.7093s	
14563/22950 (epoch 31.728), train_loss = 0.87640822, grad/param norm = 3.0709e-01, time/batch = 15.8520s	
14564/22950 (epoch 31.730), train_loss = 0.90649345, grad/param norm = 2.5511e-01, time/batch = 15.3118s	
14565/22950 (epoch 31.732), train_loss = 0.98701460, grad/param norm = 3.0808e-01, time/batch = 15.5337s	
14566/22950 (epoch 31.734), train_loss = 0.90705208, grad/param norm = 2.5879e-01, time/batch = 15.9386s	
14567/22950 (epoch 31.736), train_loss = 0.93348179, grad/param norm = 2.3343e-01, time/batch = 15.3877s	
14568/22950 (epoch 31.739), train_loss = 0.98017977, grad/param norm = 2.6144e-01, time/batch = 15.5602s	
14569/22950 (epoch 31.741), train_loss = 0.98240543, grad/param norm = 2.9174e-01, time/batch = 15.8588s	
14570/22950 (epoch 31.743), train_loss = 1.05852954, grad/param norm = 2.7183e-01, time/batch = 16.5558s	
14571/22950 (epoch 31.745), train_loss = 1.14533091, grad/param norm = 3.1925e-01, time/batch = 16.7859s	
14572/22950 (epoch 31.747), train_loss = 0.92897780, grad/param norm = 2.7009e-01, time/batch = 16.7487s	
14573/22950 (epoch 31.749), train_loss = 0.87610345, grad/param norm = 2.7221e-01, time/batch = 16.6216s	
14574/22950 (epoch 31.752), train_loss = 1.08986462, grad/param norm = 2.6983e-01, time/batch = 16.5400s	
14575/22950 (epoch 31.754), train_loss = 0.96858971, grad/param norm = 2.6451e-01, time/batch = 16.2890s	
14576/22950 (epoch 31.756), train_loss = 0.86215845, grad/param norm = 2.3621e-01, time/batch = 15.8933s	
14577/22950 (epoch 31.758), train_loss = 0.93587162, grad/param norm = 2.1936e-01, time/batch = 16.3553s	
14578/22950 (epoch 31.760), train_loss = 0.93565268, grad/param norm = 2.6263e-01, time/batch = 16.1269s	
14579/22950 (epoch 31.763), train_loss = 0.97022119, grad/param norm = 2.9633e-01, time/batch = 16.5764s	
14580/22950 (epoch 31.765), train_loss = 0.91908913, grad/param norm = 2.6037e-01, time/batch = 16.3613s	
14581/22950 (epoch 31.767), train_loss = 1.13874009, grad/param norm = 2.9571e-01, time/batch = 16.5363s	
14582/22950 (epoch 31.769), train_loss = 0.96341328, grad/param norm = 2.4712e-01, time/batch = 15.6876s	
14583/22950 (epoch 31.771), train_loss = 0.80053910, grad/param norm = 2.7328e-01, time/batch = 15.3833s	
14584/22950 (epoch 31.773), train_loss = 0.72355165, grad/param norm = 2.2236e-01, time/batch = 15.7070s	
14585/22950 (epoch 31.776), train_loss = 0.85049160, grad/param norm = 2.1239e-01, time/batch = 15.6400s	
14586/22950 (epoch 31.778), train_loss = 0.83944961, grad/param norm = 2.6021e-01, time/batch = 15.7826s	
14587/22950 (epoch 31.780), train_loss = 0.91705224, grad/param norm = 2.3123e-01, time/batch = 15.5498s	
14588/22950 (epoch 31.782), train_loss = 0.98900253, grad/param norm = 2.5765e-01, time/batch = 16.3423s	
14589/22950 (epoch 31.784), train_loss = 0.85449760, grad/param norm = 2.5305e-01, time/batch = 15.7941s	
14590/22950 (epoch 31.786), train_loss = 0.90198025, grad/param norm = 2.2589e-01, time/batch = 15.5474s	
14591/22950 (epoch 31.789), train_loss = 0.76503519, grad/param norm = 2.2410e-01, time/batch = 16.1729s	
14592/22950 (epoch 31.791), train_loss = 0.81827479, grad/param norm = 2.4066e-01, time/batch = 16.2665s	
14593/22950 (epoch 31.793), train_loss = 0.99848526, grad/param norm = 2.3885e-01, time/batch = 15.7928s	
14594/22950 (epoch 31.795), train_loss = 0.89498568, grad/param norm = 2.3545e-01, time/batch = 15.9550s	
14595/22950 (epoch 31.797), train_loss = 1.01647522, grad/param norm = 2.3147e-01, time/batch = 15.7075s	
14596/22950 (epoch 31.800), train_loss = 0.82827437, grad/param norm = 2.3085e-01, time/batch = 15.7924s	
14597/22950 (epoch 31.802), train_loss = 0.86742829, grad/param norm = 2.4841e-01, time/batch = 15.9563s	
14598/22950 (epoch 31.804), train_loss = 0.88244787, grad/param norm = 2.2429e-01, time/batch = 15.4721s	
14599/22950 (epoch 31.806), train_loss = 0.78023670, grad/param norm = 2.2504e-01, time/batch = 16.1848s	
14600/22950 (epoch 31.808), train_loss = 0.90597779, grad/param norm = 2.2895e-01, time/batch = 16.1575s	
14601/22950 (epoch 31.810), train_loss = 0.87537508, grad/param norm = 2.3658e-01, time/batch = 15.8840s	
14602/22950 (epoch 31.813), train_loss = 0.74194039, grad/param norm = 2.0934e-01, time/batch = 16.2580s	
14603/22950 (epoch 31.815), train_loss = 0.73312951, grad/param norm = 2.3118e-01, time/batch = 16.1148s	
14604/22950 (epoch 31.817), train_loss = 0.82783710, grad/param norm = 2.2106e-01, time/batch = 15.6417s	
14605/22950 (epoch 31.819), train_loss = 0.88340737, grad/param norm = 2.4513e-01, time/batch = 15.5585s	
14606/22950 (epoch 31.821), train_loss = 0.87630560, grad/param norm = 2.5175e-01, time/batch = 15.5445s	
14607/22950 (epoch 31.824), train_loss = 0.91316204, grad/param norm = 2.3617e-01, time/batch = 15.8038s	
14608/22950 (epoch 31.826), train_loss = 0.95803774, grad/param norm = 3.1018e-01, time/batch = 16.0256s	
14609/22950 (epoch 31.828), train_loss = 0.86186183, grad/param norm = 2.3378e-01, time/batch = 16.0458s	
14610/22950 (epoch 31.830), train_loss = 0.86040866, grad/param norm = 2.2831e-01, time/batch = 16.5872s	
14611/22950 (epoch 31.832), train_loss = 0.90418228, grad/param norm = 2.4028e-01, time/batch = 16.0388s	
14612/22950 (epoch 31.834), train_loss = 0.77043426, grad/param norm = 2.8209e-01, time/batch = 15.7164s	
14613/22950 (epoch 31.837), train_loss = 0.91650369, grad/param norm = 2.5702e-01, time/batch = 15.7307s	
14614/22950 (epoch 31.839), train_loss = 0.76942378, grad/param norm = 2.4199e-01, time/batch = 16.2058s	
14615/22950 (epoch 31.841), train_loss = 0.84666881, grad/param norm = 2.0944e-01, time/batch = 15.5564s	
14616/22950 (epoch 31.843), train_loss = 0.83346743, grad/param norm = 2.3054e-01, time/batch = 15.9528s	
14617/22950 (epoch 31.845), train_loss = 0.88336847, grad/param norm = 2.3360e-01, time/batch = 15.3191s	
14618/22950 (epoch 31.847), train_loss = 0.91701054, grad/param norm = 2.6372e-01, time/batch = 15.9547s	
14619/22950 (epoch 31.850), train_loss = 0.96291118, grad/param norm = 2.6098e-01, time/batch = 15.6337s	
14620/22950 (epoch 31.852), train_loss = 0.97098609, grad/param norm = 2.5994e-01, time/batch = 15.5474s	
14621/22950 (epoch 31.854), train_loss = 0.91031137, grad/param norm = 3.4714e-01, time/batch = 15.7910s	
14622/22950 (epoch 31.856), train_loss = 1.01497175, grad/param norm = 2.5668e-01, time/batch = 15.7855s	
14623/22950 (epoch 31.858), train_loss = 0.93740156, grad/param norm = 2.2573e-01, time/batch = 15.3959s	
14624/22950 (epoch 31.861), train_loss = 0.96661626, grad/param norm = 2.4863e-01, time/batch = 15.8487s	
14625/22950 (epoch 31.863), train_loss = 0.98311510, grad/param norm = 2.9595e-01, time/batch = 16.6547s	
14626/22950 (epoch 31.865), train_loss = 1.01899052, grad/param norm = 2.6099e-01, time/batch = 17.2644s	
14627/22950 (epoch 31.867), train_loss = 0.94280149, grad/param norm = 2.5956e-01, time/batch = 17.1987s	
14628/22950 (epoch 31.869), train_loss = 1.05316478, grad/param norm = 2.5944e-01, time/batch = 20.1201s	
14629/22950 (epoch 31.871), train_loss = 0.92504917, grad/param norm = 2.3529e-01, time/batch = 18.1163s	
14630/22950 (epoch 31.874), train_loss = 0.94821263, grad/param norm = 2.3475e-01, time/batch = 16.6729s	
14631/22950 (epoch 31.876), train_loss = 1.01895958, grad/param norm = 3.2078e-01, time/batch = 15.8461s	
14632/22950 (epoch 31.878), train_loss = 0.92741838, grad/param norm = 3.0172e-01, time/batch = 16.0506s	
14633/22950 (epoch 31.880), train_loss = 1.11141842, grad/param norm = 2.8358e-01, time/batch = 17.6128s	
14634/22950 (epoch 31.882), train_loss = 0.80687485, grad/param norm = 2.2851e-01, time/batch = 16.4919s	
14635/22950 (epoch 31.885), train_loss = 0.94637047, grad/param norm = 2.4130e-01, time/batch = 18.0175s	
14636/22950 (epoch 31.887), train_loss = 0.90672242, grad/param norm = 2.1571e-01, time/batch = 18.7107s	
14637/22950 (epoch 31.889), train_loss = 0.96093050, grad/param norm = 2.6781e-01, time/batch = 18.5424s	
14638/22950 (epoch 31.891), train_loss = 0.86604633, grad/param norm = 2.6687e-01, time/batch = 20.1158s	
14639/22950 (epoch 31.893), train_loss = 0.96982232, grad/param norm = 2.7656e-01, time/batch = 19.1093s	
14640/22950 (epoch 31.895), train_loss = 1.05653384, grad/param norm = 2.6969e-01, time/batch = 19.9448s	
14641/22950 (epoch 31.898), train_loss = 0.95448224, grad/param norm = 2.6648e-01, time/batch = 19.2900s	
14642/22950 (epoch 31.900), train_loss = 0.87507612, grad/param norm = 2.2084e-01, time/batch = 18.7625s	
14643/22950 (epoch 31.902), train_loss = 0.95076560, grad/param norm = 2.7972e-01, time/batch = 19.7839s	
14644/22950 (epoch 31.904), train_loss = 0.92073682, grad/param norm = 2.4245e-01, time/batch = 19.4509s	
14645/22950 (epoch 31.906), train_loss = 0.96102837, grad/param norm = 2.6226e-01, time/batch = 18.0158s	
14646/22950 (epoch 31.908), train_loss = 0.80412310, grad/param norm = 2.2393e-01, time/batch = 19.8589s	
14647/22950 (epoch 31.911), train_loss = 0.80076668, grad/param norm = 2.2202e-01, time/batch = 18.4637s	
14648/22950 (epoch 31.913), train_loss = 0.89758078, grad/param norm = 2.8568e-01, time/batch = 16.7159s	
14649/22950 (epoch 31.915), train_loss = 1.03239583, grad/param norm = 2.4115e-01, time/batch = 16.2468s	
14650/22950 (epoch 31.917), train_loss = 0.80585941, grad/param norm = 2.3608e-01, time/batch = 17.1712s	
14651/22950 (epoch 31.919), train_loss = 0.94138213, grad/param norm = 2.6976e-01, time/batch = 15.6302s	
14652/22950 (epoch 31.922), train_loss = 0.91367787, grad/param norm = 2.4460e-01, time/batch = 16.6312s	
14653/22950 (epoch 31.924), train_loss = 0.95777470, grad/param norm = 2.5657e-01, time/batch = 20.0412s	
14654/22950 (epoch 31.926), train_loss = 0.76018557, grad/param norm = 2.4056e-01, time/batch = 17.1989s	
14655/22950 (epoch 31.928), train_loss = 0.80998957, grad/param norm = 2.5048e-01, time/batch = 18.5329s	
14656/22950 (epoch 31.930), train_loss = 0.81709446, grad/param norm = 2.5537e-01, time/batch = 19.7147s	
14657/22950 (epoch 31.932), train_loss = 0.74770669, grad/param norm = 2.0584e-01, time/batch = 16.0816s	
14658/22950 (epoch 31.935), train_loss = 0.93726933, grad/param norm = 2.5616e-01, time/batch = 19.1147s	
14659/22950 (epoch 31.937), train_loss = 0.91639128, grad/param norm = 2.7534e-01, time/batch = 18.1343s	
14660/22950 (epoch 31.939), train_loss = 0.84183938, grad/param norm = 2.4309e-01, time/batch = 19.8120s	
14661/22950 (epoch 31.941), train_loss = 0.86235965, grad/param norm = 2.3565e-01, time/batch = 19.8704s	
14662/22950 (epoch 31.943), train_loss = 0.91379032, grad/param norm = 2.5823e-01, time/batch = 18.5180s	
14663/22950 (epoch 31.946), train_loss = 0.76544645, grad/param norm = 2.4562e-01, time/batch = 18.4663s	
14664/22950 (epoch 31.948), train_loss = 0.98525184, grad/param norm = 2.3770e-01, time/batch = 18.4512s	
14665/22950 (epoch 31.950), train_loss = 0.89426692, grad/param norm = 2.7572e-01, time/batch = 16.5993s	
14666/22950 (epoch 31.952), train_loss = 0.94528643, grad/param norm = 2.3504e-01, time/batch = 19.7867s	
14667/22950 (epoch 31.954), train_loss = 0.94155673, grad/param norm = 2.5759e-01, time/batch = 19.2771s	
14668/22950 (epoch 31.956), train_loss = 0.85562829, grad/param norm = 2.5896e-01, time/batch = 16.6060s	
14669/22950 (epoch 31.959), train_loss = 0.82222990, grad/param norm = 2.6498e-01, time/batch = 16.7843s	
14670/22950 (epoch 31.961), train_loss = 0.91261851, grad/param norm = 2.3644e-01, time/batch = 16.4353s	
14671/22950 (epoch 31.963), train_loss = 0.92817022, grad/param norm = 2.5339e-01, time/batch = 16.0356s	
14672/22950 (epoch 31.965), train_loss = 0.98042763, grad/param norm = 2.5392e-01, time/batch = 16.2603s	
14673/22950 (epoch 31.967), train_loss = 0.88070289, grad/param norm = 2.4702e-01, time/batch = 16.1107s	
14674/22950 (epoch 31.969), train_loss = 0.82652942, grad/param norm = 2.6767e-01, time/batch = 15.6305s	
14675/22950 (epoch 31.972), train_loss = 0.86041090, grad/param norm = 2.0586e-01, time/batch = 16.0474s	
14676/22950 (epoch 31.974), train_loss = 0.86035986, grad/param norm = 2.4684e-01, time/batch = 16.5060s	
14677/22950 (epoch 31.976), train_loss = 0.87684372, grad/param norm = 2.3590e-01, time/batch = 15.8777s	
14678/22950 (epoch 31.978), train_loss = 0.80287894, grad/param norm = 2.0657e-01, time/batch = 16.4620s	
14679/22950 (epoch 31.980), train_loss = 0.85982935, grad/param norm = 2.2283e-01, time/batch = 17.2853s	
14680/22950 (epoch 31.983), train_loss = 0.92873600, grad/param norm = 2.2479e-01, time/batch = 16.8879s	
14681/22950 (epoch 31.985), train_loss = 0.77879340, grad/param norm = 2.1017e-01, time/batch = 15.8133s	
14682/22950 (epoch 31.987), train_loss = 0.82202515, grad/param norm = 2.1202e-01, time/batch = 18.9638s	
14683/22950 (epoch 31.989), train_loss = 0.89967423, grad/param norm = 2.5482e-01, time/batch = 18.3620s	
14684/22950 (epoch 31.991), train_loss = 0.76713287, grad/param norm = 2.2519e-01, time/batch = 18.0414s	
14685/22950 (epoch 31.993), train_loss = 0.92261232, grad/param norm = 2.5516e-01, time/batch = 19.4531s	
14686/22950 (epoch 31.996), train_loss = 0.88150879, grad/param norm = 2.4862e-01, time/batch = 16.4346s	
14687/22950 (epoch 31.998), train_loss = 0.79986793, grad/param norm = 2.2446e-01, time/batch = 18.1699s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
14688/22950 (epoch 32.000), train_loss = 0.73970395, grad/param norm = 2.1533e-01, time/batch = 19.7944s	
14689/22950 (epoch 32.002), train_loss = 1.04397638, grad/param norm = 2.5206e-01, time/batch = 18.7058s	
14690/22950 (epoch 32.004), train_loss = 0.93796225, grad/param norm = 2.4700e-01, time/batch = 18.8422s	
14691/22950 (epoch 32.007), train_loss = 0.88792686, grad/param norm = 2.4326e-01, time/batch = 15.9215s	
14692/22950 (epoch 32.009), train_loss = 1.01348392, grad/param norm = 2.9748e-01, time/batch = 16.7053s	
14693/22950 (epoch 32.011), train_loss = 0.77257392, grad/param norm = 2.0969e-01, time/batch = 18.3843s	
14694/22950 (epoch 32.013), train_loss = 0.87298328, grad/param norm = 2.4836e-01, time/batch = 20.0417s	
14695/22950 (epoch 32.015), train_loss = 0.92642380, grad/param norm = 2.4907e-01, time/batch = 19.7005s	
14696/22950 (epoch 32.017), train_loss = 0.91211966, grad/param norm = 2.4351e-01, time/batch = 17.1873s	
14697/22950 (epoch 32.020), train_loss = 0.92503328, grad/param norm = 2.2786e-01, time/batch = 18.6229s	
14698/22950 (epoch 32.022), train_loss = 0.79707605, grad/param norm = 2.5429e-01, time/batch = 18.3879s	
14699/22950 (epoch 32.024), train_loss = 0.86756328, grad/param norm = 2.2365e-01, time/batch = 18.1183s	
14700/22950 (epoch 32.026), train_loss = 0.92276016, grad/param norm = 2.2978e-01, time/batch = 19.5418s	
14701/22950 (epoch 32.028), train_loss = 0.98592902, grad/param norm = 2.3238e-01, time/batch = 17.7950s	
14702/22950 (epoch 32.031), train_loss = 0.84087751, grad/param norm = 2.2848e-01, time/batch = 17.9566s	
14703/22950 (epoch 32.033), train_loss = 0.97463409, grad/param norm = 2.5655e-01, time/batch = 17.9702s	
14704/22950 (epoch 32.035), train_loss = 0.86607720, grad/param norm = 2.2412e-01, time/batch = 19.2004s	
14705/22950 (epoch 32.037), train_loss = 0.88799331, grad/param norm = 2.2524e-01, time/batch = 17.2558s	
14706/22950 (epoch 32.039), train_loss = 0.86729592, grad/param norm = 2.3859e-01, time/batch = 17.9407s	
14707/22950 (epoch 32.041), train_loss = 0.83339065, grad/param norm = 2.5945e-01, time/batch = 17.5333s	
14708/22950 (epoch 32.044), train_loss = 0.95292731, grad/param norm = 2.5947e-01, time/batch = 16.5508s	
14709/22950 (epoch 32.046), train_loss = 0.90328683, grad/param norm = 2.6241e-01, time/batch = 16.0132s	
14710/22950 (epoch 32.048), train_loss = 0.90131212, grad/param norm = 2.3160e-01, time/batch = 16.4221s	
14711/22950 (epoch 32.050), train_loss = 0.85626726, grad/param norm = 3.0636e-01, time/batch = 15.3608s	
14712/22950 (epoch 32.052), train_loss = 0.91538175, grad/param norm = 2.2388e-01, time/batch = 16.6270s	
14713/22950 (epoch 32.054), train_loss = 1.02401121, grad/param norm = 2.8535e-01, time/batch = 16.8603s	
14714/22950 (epoch 32.057), train_loss = 0.99249661, grad/param norm = 2.6801e-01, time/batch = 18.2106s	
14715/22950 (epoch 32.059), train_loss = 0.96581686, grad/param norm = 2.1969e-01, time/batch = 17.7840s	
14716/22950 (epoch 32.061), train_loss = 0.85749932, grad/param norm = 2.5924e-01, time/batch = 16.4338s	
14717/22950 (epoch 32.063), train_loss = 0.93151033, grad/param norm = 2.4006e-01, time/batch = 19.6980s	
14718/22950 (epoch 32.065), train_loss = 0.80461248, grad/param norm = 2.4471e-01, time/batch = 19.3319s	
14719/22950 (epoch 32.068), train_loss = 0.93824016, grad/param norm = 2.5097e-01, time/batch = 18.8614s	
14720/22950 (epoch 32.070), train_loss = 0.80129495, grad/param norm = 2.0630e-01, time/batch = 19.2685s	
14721/22950 (epoch 32.072), train_loss = 0.94547655, grad/param norm = 2.5181e-01, time/batch = 18.1235s	
14722/22950 (epoch 32.074), train_loss = 0.93733724, grad/param norm = 2.4699e-01, time/batch = 19.2826s	
14723/22950 (epoch 32.076), train_loss = 0.93570112, grad/param norm = 2.2782e-01, time/batch = 18.5334s	
14724/22950 (epoch 32.078), train_loss = 1.00060529, grad/param norm = 2.4183e-01, time/batch = 19.6185s	
14725/22950 (epoch 32.081), train_loss = 1.02409101, grad/param norm = 2.5025e-01, time/batch = 16.1729s	
14726/22950 (epoch 32.083), train_loss = 0.92012070, grad/param norm = 2.2729e-01, time/batch = 19.2614s	
14727/22950 (epoch 32.085), train_loss = 0.79806923, grad/param norm = 2.7006e-01, time/batch = 18.4578s	
14728/22950 (epoch 32.087), train_loss = 0.82799176, grad/param norm = 2.4269e-01, time/batch = 16.9727s	
14729/22950 (epoch 32.089), train_loss = 0.94590065, grad/param norm = 2.5784e-01, time/batch = 16.7943s	
14730/22950 (epoch 32.092), train_loss = 0.84255998, grad/param norm = 2.4458e-01, time/batch = 17.0498s	
14731/22950 (epoch 32.094), train_loss = 0.82240080, grad/param norm = 2.3413e-01, time/batch = 18.0150s	
14732/22950 (epoch 32.096), train_loss = 0.99035457, grad/param norm = 2.5942e-01, time/batch = 18.6327s	
14733/22950 (epoch 32.098), train_loss = 0.93306909, grad/param norm = 2.2014e-01, time/batch = 18.9070s	
14734/22950 (epoch 32.100), train_loss = 0.86939862, grad/param norm = 2.3835e-01, time/batch = 17.1891s	
14735/22950 (epoch 32.102), train_loss = 0.90492670, grad/param norm = 2.6983e-01, time/batch = 18.9404s	
14736/22950 (epoch 32.105), train_loss = 0.74513519, grad/param norm = 2.1565e-01, time/batch = 20.5300s	
14737/22950 (epoch 32.107), train_loss = 0.84120942, grad/param norm = 2.4579e-01, time/batch = 16.6298s	
14738/22950 (epoch 32.109), train_loss = 0.86573069, grad/param norm = 2.5064e-01, time/batch = 16.6218s	
14739/22950 (epoch 32.111), train_loss = 0.76355730, grad/param norm = 2.1940e-01, time/batch = 17.6138s	
14740/22950 (epoch 32.113), train_loss = 0.91079671, grad/param norm = 2.1641e-01, time/batch = 20.1962s	
14741/22950 (epoch 32.115), train_loss = 0.89457625, grad/param norm = 2.2488e-01, time/batch = 19.1186s	
14742/22950 (epoch 32.118), train_loss = 1.00342399, grad/param norm = 2.2748e-01, time/batch = 17.7655s	
14743/22950 (epoch 32.120), train_loss = 0.80029557, grad/param norm = 2.2591e-01, time/batch = 20.2672s	
14744/22950 (epoch 32.122), train_loss = 0.97720490, grad/param norm = 2.5041e-01, time/batch = 19.7952s	
14745/22950 (epoch 32.124), train_loss = 0.78254538, grad/param norm = 2.0067e-01, time/batch = 18.4351s	
14746/22950 (epoch 32.126), train_loss = 0.90167348, grad/param norm = 2.3414e-01, time/batch = 18.1996s	
14747/22950 (epoch 32.129), train_loss = 0.83146246, grad/param norm = 2.0329e-01, time/batch = 18.3504s	
14748/22950 (epoch 32.131), train_loss = 0.86226616, grad/param norm = 2.1895e-01, time/batch = 16.9151s	
14749/22950 (epoch 32.133), train_loss = 0.94235628, grad/param norm = 2.4749e-01, time/batch = 19.7137s	
14750/22950 (epoch 32.135), train_loss = 0.88578105, grad/param norm = 2.3134e-01, time/batch = 17.4304s	
14751/22950 (epoch 32.137), train_loss = 0.97539108, grad/param norm = 2.6253e-01, time/batch = 17.5071s	
14752/22950 (epoch 32.139), train_loss = 0.80371773, grad/param norm = 2.2434e-01, time/batch = 16.3891s	
14753/22950 (epoch 32.142), train_loss = 0.79909059, grad/param norm = 2.1178e-01, time/batch = 15.6011s	
14754/22950 (epoch 32.144), train_loss = 0.87572000, grad/param norm = 2.3226e-01, time/batch = 15.5028s	
14755/22950 (epoch 32.146), train_loss = 0.82947431, grad/param norm = 2.4157e-01, time/batch = 16.0746s	
14756/22950 (epoch 32.148), train_loss = 0.84471783, grad/param norm = 2.2801e-01, time/batch = 14.9940s	
14757/22950 (epoch 32.150), train_loss = 0.92396641, grad/param norm = 2.7013e-01, time/batch = 15.8693s	
14758/22950 (epoch 32.153), train_loss = 0.82595101, grad/param norm = 2.0981e-01, time/batch = 18.8588s	
14759/22950 (epoch 32.155), train_loss = 0.84269225, grad/param norm = 2.1123e-01, time/batch = 17.1986s	
14760/22950 (epoch 32.157), train_loss = 0.88715552, grad/param norm = 2.1860e-01, time/batch = 18.8732s	
14761/22950 (epoch 32.159), train_loss = 0.79916245, grad/param norm = 2.0664e-01, time/batch = 17.7970s	
14762/22950 (epoch 32.161), train_loss = 0.86037453, grad/param norm = 2.2773e-01, time/batch = 23.6168s	
14763/22950 (epoch 32.163), train_loss = 0.78360947, grad/param norm = 2.0484e-01, time/batch = 26.2715s	
14764/22950 (epoch 32.166), train_loss = 0.95383293, grad/param norm = 2.7017e-01, time/batch = 16.6167s	
14765/22950 (epoch 32.168), train_loss = 0.90761050, grad/param norm = 2.4840e-01, time/batch = 16.8603s	
14766/22950 (epoch 32.170), train_loss = 0.87632310, grad/param norm = 2.4835e-01, time/batch = 19.2900s	
14767/22950 (epoch 32.172), train_loss = 0.90074192, grad/param norm = 2.2453e-01, time/batch = 15.8637s	
14768/22950 (epoch 32.174), train_loss = 0.96881317, grad/param norm = 2.5269e-01, time/batch = 18.1862s	
14769/22950 (epoch 32.176), train_loss = 0.97480139, grad/param norm = 2.9044e-01, time/batch = 18.2120s	
14770/22950 (epoch 32.179), train_loss = 0.93998622, grad/param norm = 2.5732e-01, time/batch = 18.5439s	
14771/22950 (epoch 32.181), train_loss = 1.14163447, grad/param norm = 2.7383e-01, time/batch = 18.6390s	
14772/22950 (epoch 32.183), train_loss = 0.94170693, grad/param norm = 2.3699e-01, time/batch = 16.6858s	
14773/22950 (epoch 32.185), train_loss = 0.92942624, grad/param norm = 2.4704e-01, time/batch = 16.3586s	
14774/22950 (epoch 32.187), train_loss = 0.83335036, grad/param norm = 2.3924e-01, time/batch = 17.6738s	
14775/22950 (epoch 32.190), train_loss = 0.74336385, grad/param norm = 2.4035e-01, time/batch = 16.3125s	
14776/22950 (epoch 32.192), train_loss = 0.71689191, grad/param norm = 2.2749e-01, time/batch = 15.8812s	
14777/22950 (epoch 32.194), train_loss = 0.86851604, grad/param norm = 2.5376e-01, time/batch = 18.0274s	
14778/22950 (epoch 32.196), train_loss = 0.68508511, grad/param norm = 2.5385e-01, time/batch = 18.9354s	
14779/22950 (epoch 32.198), train_loss = 0.92086575, grad/param norm = 2.5572e-01, time/batch = 17.6028s	
14780/22950 (epoch 32.200), train_loss = 0.83071810, grad/param norm = 2.0697e-01, time/batch = 17.5203s	
14781/22950 (epoch 32.203), train_loss = 0.76852768, grad/param norm = 2.3357e-01, time/batch = 19.9637s	
14782/22950 (epoch 32.205), train_loss = 0.82068264, grad/param norm = 2.1814e-01, time/batch = 17.1995s	
14783/22950 (epoch 32.207), train_loss = 0.89646437, grad/param norm = 2.4258e-01, time/batch = 17.9499s	
14784/22950 (epoch 32.209), train_loss = 0.85317618, grad/param norm = 2.3292e-01, time/batch = 16.3297s	
14785/22950 (epoch 32.211), train_loss = 0.74288605, grad/param norm = 2.1678e-01, time/batch = 18.1944s	
14786/22950 (epoch 32.214), train_loss = 0.80531974, grad/param norm = 2.2479e-01, time/batch = 18.1315s	
14787/22950 (epoch 32.216), train_loss = 0.95840489, grad/param norm = 2.4506e-01, time/batch = 19.9619s	
14788/22950 (epoch 32.218), train_loss = 0.86329908, grad/param norm = 2.1817e-01, time/batch = 18.7845s	
14789/22950 (epoch 32.220), train_loss = 0.94765415, grad/param norm = 2.5270e-01, time/batch = 19.7898s	
14790/22950 (epoch 32.222), train_loss = 0.98128409, grad/param norm = 2.6502e-01, time/batch = 19.8813s	
14791/22950 (epoch 32.224), train_loss = 0.88626176, grad/param norm = 2.5867e-01, time/batch = 19.2007s	
14792/22950 (epoch 32.227), train_loss = 0.93292944, grad/param norm = 2.3336e-01, time/batch = 16.4379s	
14793/22950 (epoch 32.229), train_loss = 0.97982459, grad/param norm = 2.3877e-01, time/batch = 17.3471s	
14794/22950 (epoch 32.231), train_loss = 0.74316256, grad/param norm = 2.2376e-01, time/batch = 16.0690s	
14795/22950 (epoch 32.233), train_loss = 0.83522168, grad/param norm = 2.1925e-01, time/batch = 15.7739s	
14796/22950 (epoch 32.235), train_loss = 1.01830335, grad/param norm = 2.4607e-01, time/batch = 15.2370s	
14797/22950 (epoch 32.237), train_loss = 0.83224932, grad/param norm = 2.2468e-01, time/batch = 15.3074s	
14798/22950 (epoch 32.240), train_loss = 0.87870160, grad/param norm = 2.2988e-01, time/batch = 15.3807s	
14799/22950 (epoch 32.242), train_loss = 1.03108066, grad/param norm = 2.5314e-01, time/batch = 15.7788s	
14800/22950 (epoch 32.244), train_loss = 0.99574954, grad/param norm = 2.7128e-01, time/batch = 15.3772s	
14801/22950 (epoch 32.246), train_loss = 1.00295496, grad/param norm = 2.5744e-01, time/batch = 15.8737s	
14802/22950 (epoch 32.248), train_loss = 0.92693064, grad/param norm = 2.7711e-01, time/batch = 15.0699s	
14803/22950 (epoch 32.251), train_loss = 0.83064794, grad/param norm = 2.2238e-01, time/batch = 15.4823s	
14804/22950 (epoch 32.253), train_loss = 0.82879791, grad/param norm = 2.5956e-01, time/batch = 15.3246s	
14805/22950 (epoch 32.255), train_loss = 0.92271592, grad/param norm = 2.3284e-01, time/batch = 15.0714s	
14806/22950 (epoch 32.257), train_loss = 0.96887459, grad/param norm = 2.5384e-01, time/batch = 14.8292s	
14807/22950 (epoch 32.259), train_loss = 0.76071674, grad/param norm = 2.1866e-01, time/batch = 15.7151s	
14808/22950 (epoch 32.261), train_loss = 0.83934933, grad/param norm = 2.6943e-01, time/batch = 14.9863s	
14809/22950 (epoch 32.264), train_loss = 0.78530621, grad/param norm = 2.1967e-01, time/batch = 14.9200s	
14810/22950 (epoch 32.266), train_loss = 0.86732333, grad/param norm = 2.4645e-01, time/batch = 14.9180s	
14811/22950 (epoch 32.268), train_loss = 0.88259970, grad/param norm = 2.5254e-01, time/batch = 15.4710s	
14812/22950 (epoch 32.270), train_loss = 0.86787723, grad/param norm = 2.0543e-01, time/batch = 16.4662s	
14813/22950 (epoch 32.272), train_loss = 0.89830010, grad/param norm = 2.4202e-01, time/batch = 15.6328s	
14814/22950 (epoch 32.275), train_loss = 0.84137224, grad/param norm = 3.0932e-01, time/batch = 15.7652s	
14815/22950 (epoch 32.277), train_loss = 0.75319353, grad/param norm = 2.0576e-01, time/batch = 3.4111s	
14816/22950 (epoch 32.279), train_loss = 0.78782204, grad/param norm = 2.6700e-01, time/batch = 0.7066s	
14817/22950 (epoch 32.281), train_loss = 0.84009689, grad/param norm = 2.3801e-01, time/batch = 0.7057s	
14818/22950 (epoch 32.283), train_loss = 0.77947955, grad/param norm = 2.0897e-01, time/batch = 0.6981s	
14819/22950 (epoch 32.285), train_loss = 0.89564990, grad/param norm = 2.2934e-01, time/batch = 0.7108s	
14820/22950 (epoch 32.288), train_loss = 0.97910094, grad/param norm = 2.3604e-01, time/batch = 0.7156s	
14821/22950 (epoch 32.290), train_loss = 0.84339662, grad/param norm = 2.2597e-01, time/batch = 0.7026s	
14822/22950 (epoch 32.292), train_loss = 0.97542627, grad/param norm = 2.3940e-01, time/batch = 0.9562s	
14823/22950 (epoch 32.294), train_loss = 0.88159805, grad/param norm = 2.1739e-01, time/batch = 1.0255s	
14824/22950 (epoch 32.296), train_loss = 0.69908378, grad/param norm = 1.9199e-01, time/batch = 1.0291s	
14825/22950 (epoch 32.298), train_loss = 0.87275468, grad/param norm = 2.3111e-01, time/batch = 0.9948s	
14826/22950 (epoch 32.301), train_loss = 0.91140735, grad/param norm = 2.5876e-01, time/batch = 0.9989s	
14827/22950 (epoch 32.303), train_loss = 0.87096333, grad/param norm = 2.4950e-01, time/batch = 1.7568s	
14828/22950 (epoch 32.305), train_loss = 0.87485566, grad/param norm = 2.7439e-01, time/batch = 1.9029s	
14829/22950 (epoch 32.307), train_loss = 0.99303550, grad/param norm = 2.7913e-01, time/batch = 4.9563s	
14830/22950 (epoch 32.309), train_loss = 0.82903783, grad/param norm = 2.0313e-01, time/batch = 14.7601s	
14831/22950 (epoch 32.312), train_loss = 0.89215991, grad/param norm = 2.3360e-01, time/batch = 15.0871s	
14832/22950 (epoch 32.314), train_loss = 0.91157020, grad/param norm = 2.3203e-01, time/batch = 15.5569s	
14833/22950 (epoch 32.316), train_loss = 0.85732158, grad/param norm = 2.7973e-01, time/batch = 15.0720s	
14834/22950 (epoch 32.318), train_loss = 0.76939618, grad/param norm = 1.9921e-01, time/batch = 15.6289s	
14835/22950 (epoch 32.320), train_loss = 0.80742544, grad/param norm = 2.0878e-01, time/batch = 14.9136s	
14836/22950 (epoch 32.322), train_loss = 0.85109379, grad/param norm = 2.6188e-01, time/batch = 15.4717s	
14837/22950 (epoch 32.325), train_loss = 0.68673336, grad/param norm = 1.9147e-01, time/batch = 14.9223s	
14838/22950 (epoch 32.327), train_loss = 0.70586191, grad/param norm = 2.1607e-01, time/batch = 15.3864s	
14839/22950 (epoch 32.329), train_loss = 0.81801278, grad/param norm = 2.1839e-01, time/batch = 14.7431s	
14840/22950 (epoch 32.331), train_loss = 0.75191486, grad/param norm = 1.9490e-01, time/batch = 15.4778s	
14841/22950 (epoch 32.333), train_loss = 0.80280858, grad/param norm = 2.1628e-01, time/batch = 15.0808s	
14842/22950 (epoch 32.336), train_loss = 0.86028322, grad/param norm = 2.8099e-01, time/batch = 15.9373s	
14843/22950 (epoch 32.338), train_loss = 0.87124288, grad/param norm = 2.2336e-01, time/batch = 15.3211s	
14844/22950 (epoch 32.340), train_loss = 0.86762012, grad/param norm = 2.7919e-01, time/batch = 15.8545s	
14845/22950 (epoch 32.342), train_loss = 1.02676351, grad/param norm = 2.5842e-01, time/batch = 14.9263s	
14846/22950 (epoch 32.344), train_loss = 0.85123775, grad/param norm = 2.3066e-01, time/batch = 16.3082s	
14847/22950 (epoch 32.346), train_loss = 0.95853106, grad/param norm = 2.5164e-01, time/batch = 15.5296s	
14848/22950 (epoch 32.349), train_loss = 0.85833446, grad/param norm = 2.1980e-01, time/batch = 15.5226s	
14849/22950 (epoch 32.351), train_loss = 0.89875709, grad/param norm = 2.5298e-01, time/batch = 15.6375s	
14850/22950 (epoch 32.353), train_loss = 0.91721757, grad/param norm = 2.7439e-01, time/batch = 15.5462s	
14851/22950 (epoch 32.355), train_loss = 0.97774352, grad/param norm = 2.5974e-01, time/batch = 15.6287s	
14852/22950 (epoch 32.357), train_loss = 0.85920526, grad/param norm = 2.5329e-01, time/batch = 16.0085s	
14853/22950 (epoch 32.359), train_loss = 0.87580419, grad/param norm = 2.7009e-01, time/batch = 14.9034s	
14854/22950 (epoch 32.362), train_loss = 0.94720565, grad/param norm = 2.6525e-01, time/batch = 14.6714s	
14855/22950 (epoch 32.364), train_loss = 0.85044460, grad/param norm = 2.4533e-01, time/batch = 14.9830s	
14856/22950 (epoch 32.366), train_loss = 0.87138239, grad/param norm = 2.4696e-01, time/batch = 15.2347s	
14857/22950 (epoch 32.368), train_loss = 0.93503561, grad/param norm = 2.7194e-01, time/batch = 14.9999s	
14858/22950 (epoch 32.370), train_loss = 0.85979799, grad/param norm = 2.2715e-01, time/batch = 15.0844s	
14859/22950 (epoch 32.373), train_loss = 0.77745770, grad/param norm = 2.0004e-01, time/batch = 15.3169s	
14860/22950 (epoch 32.375), train_loss = 0.97738804, grad/param norm = 2.7904e-01, time/batch = 15.4664s	
14861/22950 (epoch 32.377), train_loss = 0.79388969, grad/param norm = 2.6749e-01, time/batch = 14.8420s	
14862/22950 (epoch 32.379), train_loss = 0.89857348, grad/param norm = 2.8399e-01, time/batch = 15.0790s	
14863/22950 (epoch 32.381), train_loss = 0.77427217, grad/param norm = 2.2751e-01, time/batch = 15.5433s	
14864/22950 (epoch 32.383), train_loss = 0.85597644, grad/param norm = 2.4282e-01, time/batch = 14.9969s	
14865/22950 (epoch 32.386), train_loss = 0.81461981, grad/param norm = 2.5248e-01, time/batch = 14.9133s	
14866/22950 (epoch 32.388), train_loss = 0.92977957, grad/param norm = 2.6409e-01, time/batch = 15.7820s	
14867/22950 (epoch 32.390), train_loss = 0.77309886, grad/param norm = 2.1828e-01, time/batch = 16.3310s	
14868/22950 (epoch 32.392), train_loss = 0.82561412, grad/param norm = 2.4255e-01, time/batch = 15.7962s	
14869/22950 (epoch 32.394), train_loss = 0.83367698, grad/param norm = 2.5534e-01, time/batch = 15.6904s	
14870/22950 (epoch 32.397), train_loss = 0.99441839, grad/param norm = 2.3841e-01, time/batch = 15.3694s	
14871/22950 (epoch 32.399), train_loss = 0.96687348, grad/param norm = 2.6654e-01, time/batch = 15.6395s	
14872/22950 (epoch 32.401), train_loss = 1.02104320, grad/param norm = 3.0961e-01, time/batch = 15.2352s	
14873/22950 (epoch 32.403), train_loss = 0.85166701, grad/param norm = 2.4962e-01, time/batch = 15.3949s	
14874/22950 (epoch 32.405), train_loss = 1.00020140, grad/param norm = 3.1805e-01, time/batch = 15.2297s	
14875/22950 (epoch 32.407), train_loss = 1.05473271, grad/param norm = 2.5212e-01, time/batch = 15.0668s	
14876/22950 (epoch 32.410), train_loss = 0.88657745, grad/param norm = 2.3666e-01, time/batch = 14.8440s	
14877/22950 (epoch 32.412), train_loss = 0.86408829, grad/param norm = 2.4736e-01, time/batch = 15.3075s	
14878/22950 (epoch 32.414), train_loss = 0.98509030, grad/param norm = 2.5692e-01, time/batch = 14.7469s	
14879/22950 (epoch 32.416), train_loss = 0.90469394, grad/param norm = 2.6143e-01, time/batch = 14.9070s	
14880/22950 (epoch 32.418), train_loss = 0.90873223, grad/param norm = 2.8371e-01, time/batch = 14.9086s	
14881/22950 (epoch 32.420), train_loss = 0.96787269, grad/param norm = 3.1706e-01, time/batch = 15.6091s	
14882/22950 (epoch 32.423), train_loss = 0.85313390, grad/param norm = 2.9028e-01, time/batch = 15.8034s	
14883/22950 (epoch 32.425), train_loss = 0.88040340, grad/param norm = 2.5035e-01, time/batch = 16.1211s	
14884/22950 (epoch 32.427), train_loss = 0.91039889, grad/param norm = 2.7542e-01, time/batch = 16.3746s	
14885/22950 (epoch 32.429), train_loss = 0.87544790, grad/param norm = 2.2089e-01, time/batch = 15.6423s	
14886/22950 (epoch 32.431), train_loss = 0.98639288, grad/param norm = 2.8865e-01, time/batch = 16.2877s	
14887/22950 (epoch 32.434), train_loss = 0.89433467, grad/param norm = 2.3782e-01, time/batch = 16.6665s	
14888/22950 (epoch 32.436), train_loss = 0.97909326, grad/param norm = 2.7958e-01, time/batch = 16.2704s	
14889/22950 (epoch 32.438), train_loss = 0.90424974, grad/param norm = 2.3994e-01, time/batch = 16.0492s	
14890/22950 (epoch 32.440), train_loss = 0.97884846, grad/param norm = 2.4699e-01, time/batch = 16.4878s	
14891/22950 (epoch 32.442), train_loss = 1.00298264, grad/param norm = 2.4466e-01, time/batch = 16.9983s	
14892/22950 (epoch 32.444), train_loss = 0.92649956, grad/param norm = 2.5817e-01, time/batch = 16.9112s	
14893/22950 (epoch 32.447), train_loss = 1.03895872, grad/param norm = 2.6993e-01, time/batch = 16.6380s	
14894/22950 (epoch 32.449), train_loss = 0.80983088, grad/param norm = 2.2818e-01, time/batch = 16.9869s	
14895/22950 (epoch 32.451), train_loss = 0.88399999, grad/param norm = 2.2483e-01, time/batch = 15.9701s	
14896/22950 (epoch 32.453), train_loss = 0.94001831, grad/param norm = 2.4288e-01, time/batch = 15.9681s	
14897/22950 (epoch 32.455), train_loss = 0.85564411, grad/param norm = 1.9616e-01, time/batch = 16.3769s	
14898/22950 (epoch 32.458), train_loss = 0.91932813, grad/param norm = 2.7107e-01, time/batch = 16.1313s	
14899/22950 (epoch 32.460), train_loss = 0.95726153, grad/param norm = 2.4886e-01, time/batch = 15.8099s	
14900/22950 (epoch 32.462), train_loss = 0.91908951, grad/param norm = 2.2887e-01, time/batch = 16.1858s	
14901/22950 (epoch 32.464), train_loss = 0.86412942, grad/param norm = 2.4330e-01, time/batch = 16.3581s	
14902/22950 (epoch 32.466), train_loss = 0.98526636, grad/param norm = 2.5813e-01, time/batch = 16.0424s	
14903/22950 (epoch 32.468), train_loss = 0.97446651, grad/param norm = 2.6594e-01, time/batch = 15.8117s	
14904/22950 (epoch 32.471), train_loss = 0.93324727, grad/param norm = 2.5665e-01, time/batch = 15.8064s	
14905/22950 (epoch 32.473), train_loss = 0.93574056, grad/param norm = 2.3036e-01, time/batch = 16.3613s	
14906/22950 (epoch 32.475), train_loss = 1.08253891, grad/param norm = 2.6376e-01, time/batch = 15.8760s	
14907/22950 (epoch 32.477), train_loss = 0.86953124, grad/param norm = 2.5535e-01, time/batch = 16.8082s	
14908/22950 (epoch 32.479), train_loss = 0.78771437, grad/param norm = 2.3417e-01, time/batch = 16.3377s	
14909/22950 (epoch 32.481), train_loss = 0.97804483, grad/param norm = 2.7665e-01, time/batch = 16.2663s	
14910/22950 (epoch 32.484), train_loss = 0.92622038, grad/param norm = 2.5400e-01, time/batch = 16.5291s	
14911/22950 (epoch 32.486), train_loss = 0.77317189, grad/param norm = 2.4862e-01, time/batch = 16.3576s	
14912/22950 (epoch 32.488), train_loss = 0.83419630, grad/param norm = 2.5141e-01, time/batch = 16.3566s	
14913/22950 (epoch 32.490), train_loss = 0.78226197, grad/param norm = 2.6984e-01, time/batch = 16.8843s	
14914/22950 (epoch 32.492), train_loss = 0.86686028, grad/param norm = 2.4311e-01, time/batch = 16.4846s	
14915/22950 (epoch 32.495), train_loss = 0.81154056, grad/param norm = 2.1585e-01, time/batch = 16.3761s	
14916/22950 (epoch 32.497), train_loss = 0.94052466, grad/param norm = 2.6856e-01, time/batch = 16.2963s	
14917/22950 (epoch 32.499), train_loss = 1.01811106, grad/param norm = 2.3276e-01, time/batch = 16.2771s	
14918/22950 (epoch 32.501), train_loss = 0.92631905, grad/param norm = 2.5786e-01, time/batch = 15.8033s	
14919/22950 (epoch 32.503), train_loss = 0.99645912, grad/param norm = 2.3786e-01, time/batch = 16.1243s	
14920/22950 (epoch 32.505), train_loss = 0.76011686, grad/param norm = 2.1832e-01, time/batch = 15.8914s	
14921/22950 (epoch 32.508), train_loss = 0.94361841, grad/param norm = 2.3473e-01, time/batch = 15.9787s	
14922/22950 (epoch 32.510), train_loss = 0.87337664, grad/param norm = 2.4387e-01, time/batch = 15.9769s	
14923/22950 (epoch 32.512), train_loss = 0.77540924, grad/param norm = 2.5777e-01, time/batch = 16.8090s	
14924/22950 (epoch 32.514), train_loss = 0.84462439, grad/param norm = 1.9505e-01, time/batch = 16.3437s	
14925/22950 (epoch 32.516), train_loss = 0.89865101, grad/param norm = 2.2987e-01, time/batch = 16.0522s	
14926/22950 (epoch 32.519), train_loss = 0.86896169, grad/param norm = 2.2826e-01, time/batch = 16.2038s	
14927/22950 (epoch 32.521), train_loss = 0.91395084, grad/param norm = 2.6766e-01, time/batch = 16.3679s	
14928/22950 (epoch 32.523), train_loss = 0.72321753, grad/param norm = 2.1152e-01, time/batch = 16.1276s	
14929/22950 (epoch 32.525), train_loss = 0.80416872, grad/param norm = 2.1706e-01, time/batch = 16.4264s	
14930/22950 (epoch 32.527), train_loss = 0.78155852, grad/param norm = 2.2110e-01, time/batch = 16.4247s	
14931/22950 (epoch 32.529), train_loss = 0.90594693, grad/param norm = 2.4833e-01, time/batch = 16.8139s	
14932/22950 (epoch 32.532), train_loss = 0.86450816, grad/param norm = 2.3913e-01, time/batch = 16.0413s	
14933/22950 (epoch 32.534), train_loss = 0.91108514, grad/param norm = 2.2850e-01, time/batch = 16.3730s	
14934/22950 (epoch 32.536), train_loss = 0.94227878, grad/param norm = 2.6947e-01, time/batch = 16.3613s	
14935/22950 (epoch 32.538), train_loss = 0.91100812, grad/param norm = 2.8718e-01, time/batch = 16.7231s	
14936/22950 (epoch 32.540), train_loss = 0.93674097, grad/param norm = 2.6001e-01, time/batch = 15.8820s	
14937/22950 (epoch 32.542), train_loss = 1.04607032, grad/param norm = 4.1290e-01, time/batch = 15.7216s	
14938/22950 (epoch 32.545), train_loss = 0.86474065, grad/param norm = 2.4046e-01, time/batch = 16.2943s	
14939/22950 (epoch 32.547), train_loss = 0.87268527, grad/param norm = 2.2653e-01, time/batch = 15.8825s	
14940/22950 (epoch 32.549), train_loss = 0.83182576, grad/param norm = 2.5980e-01, time/batch = 15.6503s	
14941/22950 (epoch 32.551), train_loss = 0.88170036, grad/param norm = 2.5346e-01, time/batch = 16.2132s	
14942/22950 (epoch 32.553), train_loss = 0.85319052, grad/param norm = 2.5517e-01, time/batch = 15.7247s	
14943/22950 (epoch 32.556), train_loss = 0.92979807, grad/param norm = 2.3231e-01, time/batch = 15.6376s	
14944/22950 (epoch 32.558), train_loss = 0.75794681, grad/param norm = 2.3863e-01, time/batch = 16.4829s	
14945/22950 (epoch 32.560), train_loss = 0.85504446, grad/param norm = 2.4607e-01, time/batch = 16.0233s	
14946/22950 (epoch 32.562), train_loss = 0.81079636, grad/param norm = 2.3933e-01, time/batch = 15.7972s	
14947/22950 (epoch 32.564), train_loss = 0.93071724, grad/param norm = 2.7383e-01, time/batch = 16.1898s	
14948/22950 (epoch 32.566), train_loss = 0.90814807, grad/param norm = 2.3410e-01, time/batch = 15.7099s	
14949/22950 (epoch 32.569), train_loss = 0.87101149, grad/param norm = 2.3058e-01, time/batch = 16.0458s	
14950/22950 (epoch 32.571), train_loss = 0.85093079, grad/param norm = 2.7126e-01, time/batch = 15.8024s	
14951/22950 (epoch 32.573), train_loss = 0.88303259, grad/param norm = 2.5504e-01, time/batch = 15.9641s	
14952/22950 (epoch 32.575), train_loss = 0.95303741, grad/param norm = 2.6079e-01, time/batch = 15.7965s	
14953/22950 (epoch 32.577), train_loss = 0.89974042, grad/param norm = 2.7938e-01, time/batch = 16.2721s	
14954/22950 (epoch 32.580), train_loss = 0.96381258, grad/param norm = 2.5559e-01, time/batch = 15.9632s	
14955/22950 (epoch 32.582), train_loss = 1.02470267, grad/param norm = 2.4653e-01, time/batch = 16.1111s	
14956/22950 (epoch 32.584), train_loss = 0.75573383, grad/param norm = 2.2524e-01, time/batch = 16.5957s	
14957/22950 (epoch 32.586), train_loss = 0.81951393, grad/param norm = 2.6117e-01, time/batch = 16.5299s	
14958/22950 (epoch 32.588), train_loss = 1.00464206, grad/param norm = 2.6614e-01, time/batch = 16.4982s	
14959/22950 (epoch 32.590), train_loss = 0.93144258, grad/param norm = 2.5715e-01, time/batch = 15.9691s	
14960/22950 (epoch 32.593), train_loss = 0.86601919, grad/param norm = 2.2817e-01, time/batch = 16.0356s	
14961/22950 (epoch 32.595), train_loss = 0.78845697, grad/param norm = 2.6307e-01, time/batch = 15.8793s	
14962/22950 (epoch 32.597), train_loss = 0.96220169, grad/param norm = 2.4882e-01, time/batch = 15.7225s	
14963/22950 (epoch 32.599), train_loss = 0.89855992, grad/param norm = 2.4770e-01, time/batch = 15.7916s	
14964/22950 (epoch 32.601), train_loss = 0.92431756, grad/param norm = 2.7231e-01, time/batch = 16.4495s	
14965/22950 (epoch 32.603), train_loss = 1.01872271, grad/param norm = 2.5996e-01, time/batch = 15.8969s	
14966/22950 (epoch 32.606), train_loss = 0.89781973, grad/param norm = 2.7405e-01, time/batch = 16.1317s	
14967/22950 (epoch 32.608), train_loss = 0.89046765, grad/param norm = 2.4036e-01, time/batch = 15.9505s	
14968/22950 (epoch 32.610), train_loss = 0.89645711, grad/param norm = 2.4711e-01, time/batch = 16.1399s	
14969/22950 (epoch 32.612), train_loss = 0.91115536, grad/param norm = 2.5560e-01, time/batch = 16.0467s	
14970/22950 (epoch 32.614), train_loss = 1.01176291, grad/param norm = 3.1819e-01, time/batch = 15.7296s	
14971/22950 (epoch 32.617), train_loss = 0.89875794, grad/param norm = 2.3851e-01, time/batch = 16.1436s	
14972/22950 (epoch 32.619), train_loss = 0.83801008, grad/param norm = 2.0930e-01, time/batch = 16.0507s	
14973/22950 (epoch 32.621), train_loss = 0.96108525, grad/param norm = 2.4495e-01, time/batch = 16.0376s	
14974/22950 (epoch 32.623), train_loss = 0.94828459, grad/param norm = 2.3220e-01, time/batch = 15.7249s	
14975/22950 (epoch 32.625), train_loss = 0.86843050, grad/param norm = 2.1834e-01, time/batch = 16.6651s	
14976/22950 (epoch 32.627), train_loss = 0.87599804, grad/param norm = 2.6109e-01, time/batch = 16.5434s	
14977/22950 (epoch 32.630), train_loss = 0.76828128, grad/param norm = 2.0085e-01, time/batch = 16.0450s	
14978/22950 (epoch 32.632), train_loss = 0.83370946, grad/param norm = 2.5399e-01, time/batch = 16.8299s	
14979/22950 (epoch 32.634), train_loss = 0.91017146, grad/param norm = 2.4930e-01, time/batch = 16.3563s	
14980/22950 (epoch 32.636), train_loss = 0.91027315, grad/param norm = 2.7306e-01, time/batch = 15.9774s	
14981/22950 (epoch 32.638), train_loss = 0.85594939, grad/param norm = 2.6283e-01, time/batch = 15.9770s	
14982/22950 (epoch 32.641), train_loss = 0.85804291, grad/param norm = 2.3669e-01, time/batch = 16.3521s	
14983/22950 (epoch 32.643), train_loss = 0.93532826, grad/param norm = 2.8139e-01, time/batch = 16.1677s	
14984/22950 (epoch 32.645), train_loss = 0.84991321, grad/param norm = 2.3540e-01, time/batch = 16.4857s	
14985/22950 (epoch 32.647), train_loss = 0.86509664, grad/param norm = 3.0254e-01, time/batch = 15.8611s	
14986/22950 (epoch 32.649), train_loss = 0.84011143, grad/param norm = 2.3351e-01, time/batch = 16.2790s	
14987/22950 (epoch 32.651), train_loss = 0.96519277, grad/param norm = 2.3718e-01, time/batch = 15.8798s	
14988/22950 (epoch 32.654), train_loss = 0.76633036, grad/param norm = 2.1616e-01, time/batch = 16.1105s	
14989/22950 (epoch 32.656), train_loss = 0.96190869, grad/param norm = 2.9985e-01, time/batch = 15.8860s	
14990/22950 (epoch 32.658), train_loss = 0.79883401, grad/param norm = 2.2149e-01, time/batch = 15.9612s	
14991/22950 (epoch 32.660), train_loss = 0.71768987, grad/param norm = 2.1103e-01, time/batch = 16.3631s	
14992/22950 (epoch 32.662), train_loss = 0.75099810, grad/param norm = 2.4956e-01, time/batch = 16.9093s	
14993/22950 (epoch 32.664), train_loss = 0.85803643, grad/param norm = 2.4155e-01, time/batch = 15.9639s	
14994/22950 (epoch 32.667), train_loss = 0.89531574, grad/param norm = 2.5383e-01, time/batch = 16.2640s	
14995/22950 (epoch 32.669), train_loss = 0.89877876, grad/param norm = 2.7073e-01, time/batch = 16.0499s	
14996/22950 (epoch 32.671), train_loss = 0.87828974, grad/param norm = 2.7201e-01, time/batch = 15.8131s	
14997/22950 (epoch 32.673), train_loss = 0.83591136, grad/param norm = 2.7360e-01, time/batch = 27.3202s	
14998/22950 (epoch 32.675), train_loss = 0.91393013, grad/param norm = 2.6879e-01, time/batch = 17.2793s	
14999/22950 (epoch 32.678), train_loss = 0.87893646, grad/param norm = 2.7187e-01, time/batch = 15.0788s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch32.68_1.9892.t7	
15000/22950 (epoch 32.680), train_loss = 0.92057055, grad/param norm = 2.3283e-01, time/batch = 16.3269s	
15001/22950 (epoch 32.682), train_loss = 1.51784431, grad/param norm = 3.4109e-01, time/batch = 16.4527s	
15002/22950 (epoch 32.684), train_loss = 1.00868849, grad/param norm = 3.4187e-01, time/batch = 16.0476s	
15003/22950 (epoch 32.686), train_loss = 1.00947549, grad/param norm = 2.6323e-01, time/batch = 15.9566s	
15004/22950 (epoch 32.688), train_loss = 0.92827078, grad/param norm = 2.6958e-01, time/batch = 16.3715s	
15005/22950 (epoch 32.691), train_loss = 0.88941199, grad/param norm = 2.5796e-01, time/batch = 16.8952s	
15006/22950 (epoch 32.693), train_loss = 0.82555596, grad/param norm = 2.5387e-01, time/batch = 15.9762s	
15007/22950 (epoch 32.695), train_loss = 1.01856175, grad/param norm = 3.2799e-01, time/batch = 16.2025s	
15008/22950 (epoch 32.697), train_loss = 0.93533645, grad/param norm = 2.6646e-01, time/batch = 16.3585s	
15009/22950 (epoch 32.699), train_loss = 0.92926831, grad/param norm = 2.6391e-01, time/batch = 16.2104s	
15010/22950 (epoch 32.702), train_loss = 0.95868296, grad/param norm = 2.7104e-01, time/batch = 16.1435s	
15011/22950 (epoch 32.704), train_loss = 1.04712522, grad/param norm = 2.8865e-01, time/batch = 16.0474s	
15012/22950 (epoch 32.706), train_loss = 0.97783325, grad/param norm = 2.7097e-01, time/batch = 16.3526s	
15013/22950 (epoch 32.708), train_loss = 0.79789730, grad/param norm = 2.6616e-01, time/batch = 15.6465s	
15014/22950 (epoch 32.710), train_loss = 0.92063181, grad/param norm = 2.3527e-01, time/batch = 15.8675s	
15015/22950 (epoch 32.712), train_loss = 0.99880038, grad/param norm = 2.8048e-01, time/batch = 16.4228s	
15016/22950 (epoch 32.715), train_loss = 0.91150122, grad/param norm = 2.5694e-01, time/batch = 15.9613s	
15017/22950 (epoch 32.717), train_loss = 0.92495253, grad/param norm = 2.2743e-01, time/batch = 16.3286s	
15018/22950 (epoch 32.719), train_loss = 0.86149920, grad/param norm = 2.6998e-01, time/batch = 16.6211s	
15019/22950 (epoch 32.721), train_loss = 0.94965514, grad/param norm = 2.7234e-01, time/batch = 16.6207s	
15020/22950 (epoch 32.723), train_loss = 0.91687604, grad/param norm = 2.7254e-01, time/batch = 16.3750s	
15021/22950 (epoch 32.725), train_loss = 0.95164979, grad/param norm = 2.4860e-01, time/batch = 16.2245s	
15022/22950 (epoch 32.728), train_loss = 0.86885822, grad/param norm = 2.7064e-01, time/batch = 16.2612s	
15023/22950 (epoch 32.730), train_loss = 0.90714430, grad/param norm = 2.7501e-01, time/batch = 16.2879s	
15024/22950 (epoch 32.732), train_loss = 0.96620992, grad/param norm = 2.9242e-01, time/batch = 16.1498s	
15025/22950 (epoch 32.734), train_loss = 0.87454081, grad/param norm = 2.4909e-01, time/batch = 16.0640s	
15026/22950 (epoch 32.736), train_loss = 0.92291865, grad/param norm = 2.4571e-01, time/batch = 15.8016s	
15027/22950 (epoch 32.739), train_loss = 0.96493504, grad/param norm = 2.6412e-01, time/batch = 16.1999s	
15028/22950 (epoch 32.741), train_loss = 0.96347412, grad/param norm = 2.7067e-01, time/batch = 15.9639s	
15029/22950 (epoch 32.743), train_loss = 1.02367616, grad/param norm = 2.6187e-01, time/batch = 15.7327s	
15030/22950 (epoch 32.745), train_loss = 1.11802894, grad/param norm = 2.8288e-01, time/batch = 16.1169s	
15031/22950 (epoch 32.747), train_loss = 0.92656453, grad/param norm = 2.3969e-01, time/batch = 16.4579s	
15032/22950 (epoch 32.749), train_loss = 0.83987914, grad/param norm = 2.4107e-01, time/batch = 16.0489s	
15033/22950 (epoch 32.752), train_loss = 1.07036676, grad/param norm = 2.5917e-01, time/batch = 16.0367s	
15034/22950 (epoch 32.754), train_loss = 0.95256671, grad/param norm = 2.4604e-01, time/batch = 16.1876s	
15035/22950 (epoch 32.756), train_loss = 0.83815251, grad/param norm = 2.3873e-01, time/batch = 15.6539s	
15036/22950 (epoch 32.758), train_loss = 0.92332198, grad/param norm = 2.2434e-01, time/batch = 16.0549s	
15037/22950 (epoch 32.760), train_loss = 0.91921751, grad/param norm = 2.3929e-01, time/batch = 16.7930s	
15038/22950 (epoch 32.763), train_loss = 0.94657705, grad/param norm = 2.6873e-01, time/batch = 16.1961s	
15039/22950 (epoch 32.765), train_loss = 0.89311956, grad/param norm = 2.5209e-01, time/batch = 15.7154s	
15040/22950 (epoch 32.767), train_loss = 1.12047574, grad/param norm = 3.0830e-01, time/batch = 15.8691s	
15041/22950 (epoch 32.769), train_loss = 0.95740873, grad/param norm = 2.5889e-01, time/batch = 16.6950s	
15042/22950 (epoch 32.771), train_loss = 0.78839235, grad/param norm = 2.4663e-01, time/batch = 15.7188s	
15043/22950 (epoch 32.773), train_loss = 0.69926117, grad/param norm = 2.0628e-01, time/batch = 15.5543s	
15044/22950 (epoch 32.776), train_loss = 0.82818866, grad/param norm = 2.1526e-01, time/batch = 16.5824s	
15045/22950 (epoch 32.778), train_loss = 0.82039053, grad/param norm = 2.2138e-01, time/batch = 17.0057s	
15046/22950 (epoch 32.780), train_loss = 0.90683209, grad/param norm = 2.2469e-01, time/batch = 16.4458s	
15047/22950 (epoch 32.782), train_loss = 0.97959192, grad/param norm = 2.4710e-01, time/batch = 15.7182s	
15048/22950 (epoch 32.784), train_loss = 0.84746607, grad/param norm = 2.4710e-01, time/batch = 15.5663s	
15049/22950 (epoch 32.786), train_loss = 0.88591315, grad/param norm = 2.4751e-01, time/batch = 16.4397s	
15050/22950 (epoch 32.789), train_loss = 0.75729471, grad/param norm = 2.2702e-01, time/batch = 15.8180s	
15051/22950 (epoch 32.791), train_loss = 0.80210837, grad/param norm = 2.4992e-01, time/batch = 16.3540s	
15052/22950 (epoch 32.793), train_loss = 0.98710055, grad/param norm = 2.5514e-01, time/batch = 16.1318s	
15053/22950 (epoch 32.795), train_loss = 0.87862038, grad/param norm = 2.2200e-01, time/batch = 15.8078s	
15054/22950 (epoch 32.797), train_loss = 1.00375821, grad/param norm = 2.4501e-01, time/batch = 15.9519s	
15055/22950 (epoch 32.800), train_loss = 0.81570200, grad/param norm = 2.1815e-01, time/batch = 15.8675s	
15056/22950 (epoch 32.802), train_loss = 0.85787723, grad/param norm = 2.5771e-01, time/batch = 16.0490s	
15057/22950 (epoch 32.804), train_loss = 0.87119166, grad/param norm = 2.3066e-01, time/batch = 16.2064s	
15058/22950 (epoch 32.806), train_loss = 0.78337522, grad/param norm = 2.5535e-01, time/batch = 16.7981s	
15059/22950 (epoch 32.808), train_loss = 0.90561075, grad/param norm = 2.3076e-01, time/batch = 15.8037s	
15060/22950 (epoch 32.810), train_loss = 0.86129360, grad/param norm = 2.3960e-01, time/batch = 16.5051s	
15061/22950 (epoch 32.813), train_loss = 0.74238242, grad/param norm = 2.1488e-01, time/batch = 15.8734s	
15062/22950 (epoch 32.815), train_loss = 0.72735153, grad/param norm = 2.5341e-01, time/batch = 16.1174s	
15063/22950 (epoch 32.817), train_loss = 0.80583949, grad/param norm = 2.2410e-01, time/batch = 15.5446s	
15064/22950 (epoch 32.819), train_loss = 0.85567945, grad/param norm = 2.4039e-01, time/batch = 15.8561s	
15065/22950 (epoch 32.821), train_loss = 0.87751369, grad/param norm = 2.8568e-01, time/batch = 15.6465s	
15066/22950 (epoch 32.824), train_loss = 0.89266766, grad/param norm = 2.3133e-01, time/batch = 15.7916s	
15067/22950 (epoch 32.826), train_loss = 0.93686225, grad/param norm = 2.8454e-01, time/batch = 15.9516s	
15068/22950 (epoch 32.828), train_loss = 0.85247652, grad/param norm = 2.4926e-01, time/batch = 16.0358s	
15069/22950 (epoch 32.830), train_loss = 0.84771911, grad/param norm = 2.3029e-01, time/batch = 15.5551s	
15070/22950 (epoch 32.832), train_loss = 0.88953502, grad/param norm = 2.5792e-01, time/batch = 16.2924s	
15071/22950 (epoch 32.834), train_loss = 0.75154206, grad/param norm = 2.2262e-01, time/batch = 16.0482s	
15072/22950 (epoch 32.837), train_loss = 0.88612705, grad/param norm = 2.4933e-01, time/batch = 15.8017s	
15073/22950 (epoch 32.839), train_loss = 0.75313290, grad/param norm = 2.2544e-01, time/batch = 16.2120s	
15074/22950 (epoch 32.841), train_loss = 0.84393170, grad/param norm = 2.2024e-01, time/batch = 15.8030s	
15075/22950 (epoch 32.843), train_loss = 0.82503452, grad/param norm = 2.5654e-01, time/batch = 16.1954s	
15076/22950 (epoch 32.845), train_loss = 0.86359780, grad/param norm = 2.3519e-01, time/batch = 15.9631s	
15077/22950 (epoch 32.847), train_loss = 0.91058504, grad/param norm = 2.4969e-01, time/batch = 15.8016s	
15078/22950 (epoch 32.850), train_loss = 0.96156902, grad/param norm = 2.8038e-01, time/batch = 16.6320s	
15079/22950 (epoch 32.852), train_loss = 0.94221158, grad/param norm = 2.7864e-01, time/batch = 16.6627s	
15080/22950 (epoch 32.854), train_loss = 0.89210156, grad/param norm = 2.5068e-01, time/batch = 15.9487s	
15081/22950 (epoch 32.856), train_loss = 1.00364487, grad/param norm = 2.9768e-01, time/batch = 16.4487s	
15082/22950 (epoch 32.858), train_loss = 0.93927669, grad/param norm = 2.4291e-01, time/batch = 20.9979s	
15083/22950 (epoch 32.861), train_loss = 0.94065003, grad/param norm = 2.6549e-01, time/batch = 19.9971s	
15084/22950 (epoch 32.863), train_loss = 0.98770184, grad/param norm = 2.7587e-01, time/batch = 21.5633s	
15085/22950 (epoch 32.865), train_loss = 1.00657974, grad/param norm = 2.3654e-01, time/batch = 22.9594s	
15086/22950 (epoch 32.867), train_loss = 0.91093553, grad/param norm = 2.6498e-01, time/batch = 21.9624s	
15087/22950 (epoch 32.869), train_loss = 1.05143329, grad/param norm = 2.8486e-01, time/batch = 21.6173s	
15088/22950 (epoch 32.871), train_loss = 0.90412470, grad/param norm = 2.3072e-01, time/batch = 23.1228s	
15089/22950 (epoch 32.874), train_loss = 0.93244991, grad/param norm = 2.3176e-01, time/batch = 21.8814s	
15090/22950 (epoch 32.876), train_loss = 0.97672283, grad/param norm = 2.7743e-01, time/batch = 22.2071s	
15091/22950 (epoch 32.878), train_loss = 0.90479218, grad/param norm = 2.8847e-01, time/batch = 22.3506s	
15092/22950 (epoch 32.880), train_loss = 1.08640525, grad/param norm = 2.8146e-01, time/batch = 20.1305s	
15093/22950 (epoch 32.882), train_loss = 0.79392557, grad/param norm = 2.3517e-01, time/batch = 22.8024s	
15094/22950 (epoch 32.885), train_loss = 0.93375245, grad/param norm = 2.5344e-01, time/batch = 23.4040s	
15095/22950 (epoch 32.887), train_loss = 0.88754865, grad/param norm = 2.1674e-01, time/batch = 22.9157s	
15096/22950 (epoch 32.889), train_loss = 0.92906580, grad/param norm = 2.4630e-01, time/batch = 22.9100s	
15097/22950 (epoch 32.891), train_loss = 0.85103846, grad/param norm = 2.4996e-01, time/batch = 22.6054s	
15098/22950 (epoch 32.893), train_loss = 0.95095121, grad/param norm = 2.4282e-01, time/batch = 22.5354s	
15099/22950 (epoch 32.895), train_loss = 1.05542650, grad/param norm = 2.8296e-01, time/batch = 22.6385s	
15100/22950 (epoch 32.898), train_loss = 0.95090056, grad/param norm = 2.8304e-01, time/batch = 23.3626s	
15101/22950 (epoch 32.900), train_loss = 0.85984630, grad/param norm = 2.3588e-01, time/batch = 23.1605s	
15102/22950 (epoch 32.902), train_loss = 0.93573030, grad/param norm = 2.6173e-01, time/batch = 26.0998s	
15103/22950 (epoch 32.904), train_loss = 0.92040616, grad/param norm = 2.4962e-01, time/batch = 21.5061s	
15104/22950 (epoch 32.906), train_loss = 0.93496737, grad/param norm = 2.6527e-01, time/batch = 15.8940s	
15105/22950 (epoch 32.908), train_loss = 0.78664752, grad/param norm = 2.1895e-01, time/batch = 16.4375s	
15106/22950 (epoch 32.911), train_loss = 0.76568655, grad/param norm = 2.0036e-01, time/batch = 16.2831s	
15107/22950 (epoch 32.913), train_loss = 0.88246620, grad/param norm = 2.2728e-01, time/batch = 16.1904s	
15108/22950 (epoch 32.915), train_loss = 1.03513664, grad/param norm = 2.6476e-01, time/batch = 15.8085s	
15109/22950 (epoch 32.917), train_loss = 0.80062332, grad/param norm = 2.4692e-01, time/batch = 16.0546s	
15110/22950 (epoch 32.919), train_loss = 0.92532608, grad/param norm = 2.5439e-01, time/batch = 15.8878s	
15111/22950 (epoch 32.922), train_loss = 0.92508130, grad/param norm = 2.8536e-01, time/batch = 16.6820s	
15112/22950 (epoch 32.924), train_loss = 0.93791959, grad/param norm = 2.9581e-01, time/batch = 16.2606s	
15113/22950 (epoch 32.926), train_loss = 0.76625064, grad/param norm = 3.1542e-01, time/batch = 16.4155s	
15114/22950 (epoch 32.928), train_loss = 0.79179020, grad/param norm = 2.2068e-01, time/batch = 16.5283s	
15115/22950 (epoch 32.930), train_loss = 0.78239113, grad/param norm = 2.3285e-01, time/batch = 15.6404s	
15116/22950 (epoch 32.932), train_loss = 0.74412665, grad/param norm = 2.0322e-01, time/batch = 16.3365s	
15117/22950 (epoch 32.935), train_loss = 0.92583049, grad/param norm = 2.4322e-01, time/batch = 15.7233s	
15118/22950 (epoch 32.937), train_loss = 0.89524495, grad/param norm = 2.6210e-01, time/batch = 16.0385s	
15119/22950 (epoch 32.939), train_loss = 0.82338809, grad/param norm = 2.3941e-01, time/batch = 15.9653s	
15120/22950 (epoch 32.941), train_loss = 0.88662208, grad/param norm = 2.6575e-01, time/batch = 16.1907s	
15121/22950 (epoch 32.943), train_loss = 0.88810939, grad/param norm = 2.3642e-01, time/batch = 15.5738s	
15122/22950 (epoch 32.946), train_loss = 0.76267583, grad/param norm = 2.2510e-01, time/batch = 15.8747s	
15123/22950 (epoch 32.948), train_loss = 0.97666292, grad/param norm = 2.3565e-01, time/batch = 15.4814s	
15124/22950 (epoch 32.950), train_loss = 0.86675435, grad/param norm = 2.6705e-01, time/batch = 15.7342s	
15125/22950 (epoch 32.952), train_loss = 0.92896213, grad/param norm = 2.3795e-01, time/batch = 16.0511s	
15126/22950 (epoch 32.954), train_loss = 0.92772531, grad/param norm = 2.3513e-01, time/batch = 16.4578s	
15127/22950 (epoch 32.956), train_loss = 0.84570843, grad/param norm = 2.4833e-01, time/batch = 16.5528s	
15128/22950 (epoch 32.959), train_loss = 0.81492852, grad/param norm = 2.3858e-01, time/batch = 16.0598s	
15129/22950 (epoch 32.961), train_loss = 0.90320694, grad/param norm = 2.4763e-01, time/batch = 15.9642s	
15130/22950 (epoch 32.963), train_loss = 0.91312613, grad/param norm = 2.4589e-01, time/batch = 15.8083s	
15131/22950 (epoch 32.965), train_loss = 0.96074566, grad/param norm = 2.5480e-01, time/batch = 16.3772s	
15132/22950 (epoch 32.967), train_loss = 0.88674764, grad/param norm = 2.6814e-01, time/batch = 15.8849s	
15133/22950 (epoch 32.969), train_loss = 0.79381133, grad/param norm = 2.5034e-01, time/batch = 16.5807s	
15134/22950 (epoch 32.972), train_loss = 0.85752133, grad/param norm = 2.1295e-01, time/batch = 16.3526s	
15135/22950 (epoch 32.974), train_loss = 0.83620627, grad/param norm = 2.3874e-01, time/batch = 16.7722s	
15136/22950 (epoch 32.976), train_loss = 0.87126872, grad/param norm = 2.3525e-01, time/batch = 16.1772s	
15137/22950 (epoch 32.978), train_loss = 0.81295200, grad/param norm = 2.5008e-01, time/batch = 15.7196s	
15138/22950 (epoch 32.980), train_loss = 0.84462038, grad/param norm = 2.2301e-01, time/batch = 15.8120s	
15139/22950 (epoch 32.983), train_loss = 0.92453256, grad/param norm = 2.2827e-01, time/batch = 16.3590s	
15140/22950 (epoch 32.985), train_loss = 0.77070755, grad/param norm = 2.4105e-01, time/batch = 16.0436s	
15141/22950 (epoch 32.987), train_loss = 0.81052764, grad/param norm = 2.2044e-01, time/batch = 16.4629s	
15142/22950 (epoch 32.989), train_loss = 0.88932149, grad/param norm = 2.3107e-01, time/batch = 16.4533s	
15143/22950 (epoch 32.991), train_loss = 0.75975474, grad/param norm = 2.4203e-01, time/batch = 16.0420s	
15144/22950 (epoch 32.993), train_loss = 0.90731662, grad/param norm = 2.3719e-01, time/batch = 16.7539s	
15145/22950 (epoch 32.996), train_loss = 0.88509361, grad/param norm = 3.9361e-01, time/batch = 16.5082s	
15146/22950 (epoch 32.998), train_loss = 0.79407147, grad/param norm = 2.3273e-01, time/batch = 16.4983s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
15147/22950 (epoch 33.000), train_loss = 0.74028592, grad/param norm = 2.1732e-01, time/batch = 16.3405s	
15148/22950 (epoch 33.002), train_loss = 1.03056089, grad/param norm = 2.7048e-01, time/batch = 15.9665s	
15149/22950 (epoch 33.004), train_loss = 0.91312250, grad/param norm = 2.4952e-01, time/batch = 16.1703s	
15150/22950 (epoch 33.007), train_loss = 0.85596590, grad/param norm = 2.2796e-01, time/batch = 15.6431s	
15151/22950 (epoch 33.009), train_loss = 1.00120676, grad/param norm = 2.5318e-01, time/batch = 16.5692s	
15152/22950 (epoch 33.011), train_loss = 0.75890371, grad/param norm = 2.3949e-01, time/batch = 16.3332s	
15153/22950 (epoch 33.013), train_loss = 0.86966726, grad/param norm = 2.5971e-01, time/batch = 15.9536s	
15154/22950 (epoch 33.015), train_loss = 0.90598709, grad/param norm = 2.5473e-01, time/batch = 16.1031s	
15155/22950 (epoch 33.017), train_loss = 0.88696162, grad/param norm = 2.1228e-01, time/batch = 16.1115s	
15156/22950 (epoch 33.020), train_loss = 0.90648689, grad/param norm = 2.2701e-01, time/batch = 15.8787s	
15157/22950 (epoch 33.022), train_loss = 0.78007928, grad/param norm = 2.3288e-01, time/batch = 16.0292s	
15158/22950 (epoch 33.024), train_loss = 0.86449381, grad/param norm = 2.8502e-01, time/batch = 15.9977s	
15159/22950 (epoch 33.026), train_loss = 0.91781190, grad/param norm = 2.6217e-01, time/batch = 16.3168s	
15160/22950 (epoch 33.028), train_loss = 0.96317729, grad/param norm = 2.3845e-01, time/batch = 16.0112s	
15161/22950 (epoch 33.031), train_loss = 0.83657329, grad/param norm = 2.3425e-01, time/batch = 16.8025s	
15162/22950 (epoch 33.033), train_loss = 0.97892385, grad/param norm = 2.6750e-01, time/batch = 16.7700s	
15163/22950 (epoch 33.035), train_loss = 0.88344266, grad/param norm = 2.4581e-01, time/batch = 16.2231s	
15164/22950 (epoch 33.037), train_loss = 0.87001977, grad/param norm = 2.2092e-01, time/batch = 16.5813s	
15165/22950 (epoch 33.039), train_loss = 0.85089808, grad/param norm = 2.4160e-01, time/batch = 16.2867s	
15166/22950 (epoch 33.041), train_loss = 0.80932709, grad/param norm = 2.5220e-01, time/batch = 16.4376s	
15167/22950 (epoch 33.044), train_loss = 0.93202698, grad/param norm = 2.6235e-01, time/batch = 16.0556s	
15168/22950 (epoch 33.046), train_loss = 0.89461741, grad/param norm = 2.5988e-01, time/batch = 16.0446s	
15169/22950 (epoch 33.048), train_loss = 0.87310497, grad/param norm = 2.4033e-01, time/batch = 16.2079s	
15170/22950 (epoch 33.050), train_loss = 0.85737385, grad/param norm = 3.2019e-01, time/batch = 16.3751s	
15171/22950 (epoch 33.052), train_loss = 0.90524547, grad/param norm = 2.3664e-01, time/batch = 15.8776s	
15172/22950 (epoch 33.054), train_loss = 1.02267683, grad/param norm = 2.6731e-01, time/batch = 15.8695s	
15173/22950 (epoch 33.057), train_loss = 0.98131063, grad/param norm = 2.4930e-01, time/batch = 15.9389s	
15174/22950 (epoch 33.059), train_loss = 0.97248073, grad/param norm = 2.4148e-01, time/batch = 15.9042s	
15175/22950 (epoch 33.061), train_loss = 0.83485676, grad/param norm = 2.4608e-01, time/batch = 15.8884s	
15176/22950 (epoch 33.063), train_loss = 0.90762581, grad/param norm = 2.3865e-01, time/batch = 15.6366s	
15177/22950 (epoch 33.065), train_loss = 0.78939620, grad/param norm = 2.4243e-01, time/batch = 16.0146s	
15178/22950 (epoch 33.068), train_loss = 0.92211386, grad/param norm = 2.7605e-01, time/batch = 16.0354s	
15179/22950 (epoch 33.070), train_loss = 0.78920156, grad/param norm = 2.0506e-01, time/batch = 15.9590s	
15180/22950 (epoch 33.072), train_loss = 0.94628589, grad/param norm = 2.7572e-01, time/batch = 16.2129s	
15181/22950 (epoch 33.074), train_loss = 0.92098336, grad/param norm = 2.2382e-01, time/batch = 16.6498s	
15182/22950 (epoch 33.076), train_loss = 0.91829661, grad/param norm = 2.3509e-01, time/batch = 16.4009s	
15183/22950 (epoch 33.078), train_loss = 0.98871606, grad/param norm = 2.6358e-01, time/batch = 16.1757s	
15184/22950 (epoch 33.081), train_loss = 1.01500516, grad/param norm = 2.4837e-01, time/batch = 16.2681s	
15185/22950 (epoch 33.083), train_loss = 0.90826386, grad/param norm = 2.4025e-01, time/batch = 16.5059s	
15186/22950 (epoch 33.085), train_loss = 0.77389253, grad/param norm = 2.4743e-01, time/batch = 16.3561s	
15187/22950 (epoch 33.087), train_loss = 0.79398052, grad/param norm = 2.2830e-01, time/batch = 16.0408s	
15188/22950 (epoch 33.089), train_loss = 0.94729192, grad/param norm = 2.6690e-01, time/batch = 16.4083s	
15189/22950 (epoch 33.092), train_loss = 0.84374553, grad/param norm = 2.7690e-01, time/batch = 16.4862s	
15190/22950 (epoch 33.094), train_loss = 0.83676800, grad/param norm = 2.5056e-01, time/batch = 16.5329s	
15191/22950 (epoch 33.096), train_loss = 0.98862322, grad/param norm = 2.5246e-01, time/batch = 16.1173s	
15192/22950 (epoch 33.098), train_loss = 0.92963002, grad/param norm = 2.2906e-01, time/batch = 16.1878s	
15193/22950 (epoch 33.100), train_loss = 0.86464060, grad/param norm = 2.4136e-01, time/batch = 16.1179s	
15194/22950 (epoch 33.102), train_loss = 0.87907520, grad/param norm = 2.5588e-01, time/batch = 16.1859s	
15195/22950 (epoch 33.105), train_loss = 0.72898230, grad/param norm = 2.1856e-01, time/batch = 16.2524s	
15196/22950 (epoch 33.107), train_loss = 0.82023109, grad/param norm = 2.5133e-01, time/batch = 15.9542s	
15197/22950 (epoch 33.109), train_loss = 0.84456181, grad/param norm = 2.3725e-01, time/batch = 16.0375s	
15198/22950 (epoch 33.111), train_loss = 0.74344397, grad/param norm = 2.2601e-01, time/batch = 15.8735s	
15199/22950 (epoch 33.113), train_loss = 0.90832876, grad/param norm = 2.3421e-01, time/batch = 16.1128s	
15200/22950 (epoch 33.115), train_loss = 0.88638645, grad/param norm = 2.3066e-01, time/batch = 16.1881s	
15201/22950 (epoch 33.118), train_loss = 0.98843213, grad/param norm = 2.2841e-01, time/batch = 16.0385s	
15202/22950 (epoch 33.120), train_loss = 0.79672331, grad/param norm = 2.2145e-01, time/batch = 16.1536s	
15203/22950 (epoch 33.122), train_loss = 0.97078864, grad/param norm = 2.5674e-01, time/batch = 22.4239s	
15204/22950 (epoch 33.124), train_loss = 0.77182748, grad/param norm = 1.8901e-01, time/batch = 24.5038s	
15205/22950 (epoch 33.126), train_loss = 0.88471085, grad/param norm = 2.2189e-01, time/batch = 15.2264s	
15206/22950 (epoch 33.129), train_loss = 0.81830408, grad/param norm = 2.0706e-01, time/batch = 16.2497s	
15207/22950 (epoch 33.131), train_loss = 0.86387569, grad/param norm = 2.3145e-01, time/batch = 15.5510s	
15208/22950 (epoch 33.133), train_loss = 0.91904642, grad/param norm = 2.5256e-01, time/batch = 16.4301s	
15209/22950 (epoch 33.135), train_loss = 0.88596897, grad/param norm = 2.2414e-01, time/batch = 15.9525s	
15210/22950 (epoch 33.137), train_loss = 0.95097755, grad/param norm = 2.7061e-01, time/batch = 16.1362s	
15211/22950 (epoch 33.139), train_loss = 0.80674428, grad/param norm = 2.3484e-01, time/batch = 15.6374s	
15212/22950 (epoch 33.142), train_loss = 0.78737567, grad/param norm = 2.1942e-01, time/batch = 15.5448s	
15213/22950 (epoch 33.144), train_loss = 0.85192279, grad/param norm = 2.3068e-01, time/batch = 16.1692s	
15214/22950 (epoch 33.146), train_loss = 0.80566459, grad/param norm = 2.2955e-01, time/batch = 15.6388s	
15215/22950 (epoch 33.148), train_loss = 0.81104310, grad/param norm = 2.1629e-01, time/batch = 15.8838s	
15216/22950 (epoch 33.150), train_loss = 0.91109540, grad/param norm = 2.4127e-01, time/batch = 15.8814s	
15217/22950 (epoch 33.153), train_loss = 0.81098227, grad/param norm = 2.1754e-01, time/batch = 16.3556s	
15218/22950 (epoch 33.155), train_loss = 0.83562551, grad/param norm = 2.0912e-01, time/batch = 15.9564s	
15219/22950 (epoch 33.157), train_loss = 0.87124445, grad/param norm = 2.4511e-01, time/batch = 15.9692s	
15220/22950 (epoch 33.159), train_loss = 0.79604120, grad/param norm = 2.1839e-01, time/batch = 15.7148s	
15221/22950 (epoch 33.161), train_loss = 0.84479498, grad/param norm = 2.1221e-01, time/batch = 16.2752s	
15222/22950 (epoch 33.163), train_loss = 0.77939019, grad/param norm = 2.2644e-01, time/batch = 16.4214s	
15223/22950 (epoch 33.166), train_loss = 0.95767025, grad/param norm = 4.7017e-01, time/batch = 16.2782s	
15224/22950 (epoch 33.168), train_loss = 0.93215467, grad/param norm = 2.6655e-01, time/batch = 16.4429s	
15225/22950 (epoch 33.170), train_loss = 0.90037497, grad/param norm = 2.5742e-01, time/batch = 16.6743s	
15226/22950 (epoch 33.172), train_loss = 0.90159655, grad/param norm = 2.4448e-01, time/batch = 16.4437s	
15227/22950 (epoch 33.174), train_loss = 0.95892000, grad/param norm = 2.4074e-01, time/batch = 16.2928s	
15228/22950 (epoch 33.176), train_loss = 0.97049924, grad/param norm = 2.7139e-01, time/batch = 16.5378s	
15229/22950 (epoch 33.179), train_loss = 0.93230414, grad/param norm = 2.5927e-01, time/batch = 16.3759s	
15230/22950 (epoch 33.181), train_loss = 1.13752086, grad/param norm = 2.9106e-01, time/batch = 16.4550s	
15231/22950 (epoch 33.183), train_loss = 0.93263048, grad/param norm = 2.5325e-01, time/batch = 16.6115s	
15232/22950 (epoch 33.185), train_loss = 0.92622554, grad/param norm = 2.3663e-01, time/batch = 16.5337s	
15233/22950 (epoch 33.187), train_loss = 0.81089274, grad/param norm = 2.2805e-01, time/batch = 16.0573s	
15234/22950 (epoch 33.190), train_loss = 0.73070500, grad/param norm = 2.2701e-01, time/batch = 16.2071s	
15235/22950 (epoch 33.192), train_loss = 0.69814153, grad/param norm = 2.1537e-01, time/batch = 16.3581s	
15236/22950 (epoch 33.194), train_loss = 0.87216670, grad/param norm = 2.6767e-01, time/batch = 16.3846s	
15237/22950 (epoch 33.196), train_loss = 0.66851599, grad/param norm = 2.4381e-01, time/batch = 16.7462s	
15238/22950 (epoch 33.198), train_loss = 0.90927139, grad/param norm = 2.3284e-01, time/batch = 16.5739s	
15239/22950 (epoch 33.200), train_loss = 0.80821667, grad/param norm = 2.0597e-01, time/batch = 16.5724s	
15240/22950 (epoch 33.203), train_loss = 0.77058954, grad/param norm = 2.3251e-01, time/batch = 16.1895s	
15241/22950 (epoch 33.205), train_loss = 0.82259949, grad/param norm = 2.3745e-01, time/batch = 16.0281s	
15242/22950 (epoch 33.207), train_loss = 0.89802130, grad/param norm = 2.7707e-01, time/batch = 15.9493s	
15243/22950 (epoch 33.209), train_loss = 0.84970800, grad/param norm = 2.7880e-01, time/batch = 16.8435s	
15244/22950 (epoch 33.211), train_loss = 0.74054727, grad/param norm = 2.3008e-01, time/batch = 15.8569s	
15245/22950 (epoch 33.214), train_loss = 0.81342128, grad/param norm = 2.3559e-01, time/batch = 15.7030s	
15246/22950 (epoch 33.216), train_loss = 0.94587455, grad/param norm = 2.2536e-01, time/batch = 15.7900s	
15247/22950 (epoch 33.218), train_loss = 0.86887547, grad/param norm = 2.2873e-01, time/batch = 16.5090s	
15248/22950 (epoch 33.220), train_loss = 0.93406887, grad/param norm = 2.3538e-01, time/batch = 16.7196s	
15249/22950 (epoch 33.222), train_loss = 0.96563071, grad/param norm = 2.7495e-01, time/batch = 16.5745s	
15250/22950 (epoch 33.224), train_loss = 0.88088327, grad/param norm = 2.6943e-01, time/batch = 16.5074s	
15251/22950 (epoch 33.227), train_loss = 0.91354552, grad/param norm = 2.3203e-01, time/batch = 16.4522s	
15252/22950 (epoch 33.229), train_loss = 0.98482467, grad/param norm = 2.4018e-01, time/batch = 16.1207s	
15253/22950 (epoch 33.231), train_loss = 0.73091413, grad/param norm = 2.2968e-01, time/batch = 16.1935s	
15254/22950 (epoch 33.233), train_loss = 0.83345334, grad/param norm = 2.3376e-01, time/batch = 16.4560s	
15255/22950 (epoch 33.235), train_loss = 1.00144840, grad/param norm = 2.3112e-01, time/batch = 16.3462s	
15256/22950 (epoch 33.237), train_loss = 0.81347146, grad/param norm = 2.2772e-01, time/batch = 16.5786s	
15257/22950 (epoch 33.240), train_loss = 0.87490206, grad/param norm = 2.3664e-01, time/batch = 16.9768s	
15258/22950 (epoch 33.242), train_loss = 1.00986878, grad/param norm = 2.3583e-01, time/batch = 16.4651s	
15259/22950 (epoch 33.244), train_loss = 0.98770846, grad/param norm = 2.8094e-01, time/batch = 16.4207s	
15260/22950 (epoch 33.246), train_loss = 0.99174890, grad/param norm = 2.6036e-01, time/batch = 16.4927s	
15261/22950 (epoch 33.248), train_loss = 0.89797702, grad/param norm = 2.5604e-01, time/batch = 16.5939s	
15262/22950 (epoch 33.251), train_loss = 0.82186910, grad/param norm = 2.4244e-01, time/batch = 16.5742s	
15263/22950 (epoch 33.253), train_loss = 0.81397816, grad/param norm = 2.5927e-01, time/batch = 15.8821s	
15264/22950 (epoch 33.255), train_loss = 0.91922092, grad/param norm = 2.4352e-01, time/batch = 15.9609s	
15265/22950 (epoch 33.257), train_loss = 0.95993209, grad/param norm = 2.5926e-01, time/batch = 15.9613s	
15266/22950 (epoch 33.259), train_loss = 0.75061665, grad/param norm = 2.3509e-01, time/batch = 15.8068s	
15267/22950 (epoch 33.261), train_loss = 0.81212403, grad/param norm = 2.3901e-01, time/batch = 15.5565s	
15268/22950 (epoch 33.264), train_loss = 0.78102057, grad/param norm = 2.2099e-01, time/batch = 16.1181s	
15269/22950 (epoch 33.266), train_loss = 0.85014099, grad/param norm = 2.2969e-01, time/batch = 16.8117s	
15270/22950 (epoch 33.268), train_loss = 0.86958391, grad/param norm = 2.4069e-01, time/batch = 16.3528s	
15271/22950 (epoch 33.270), train_loss = 0.85669120, grad/param norm = 2.2560e-01, time/batch = 16.1444s	
15272/22950 (epoch 33.272), train_loss = 0.88834662, grad/param norm = 2.4834e-01, time/batch = 16.5352s	
15273/22950 (epoch 33.275), train_loss = 0.81843858, grad/param norm = 2.3896e-01, time/batch = 15.6345s	
15274/22950 (epoch 33.277), train_loss = 0.74927105, grad/param norm = 2.3377e-01, time/batch = 15.5650s	
15275/22950 (epoch 33.279), train_loss = 0.76542429, grad/param norm = 2.6245e-01, time/batch = 15.9466s	
15276/22950 (epoch 33.281), train_loss = 0.82749369, grad/param norm = 2.5920e-01, time/batch = 15.8013s	
15277/22950 (epoch 33.283), train_loss = 0.76333846, grad/param norm = 2.0447e-01, time/batch = 15.7865s	
15278/22950 (epoch 33.285), train_loss = 0.88534968, grad/param norm = 2.1356e-01, time/batch = 16.0432s	
15279/22950 (epoch 33.288), train_loss = 0.96884043, grad/param norm = 2.3691e-01, time/batch = 16.1636s	
15280/22950 (epoch 33.290), train_loss = 0.82887247, grad/param norm = 2.3795e-01, time/batch = 16.1798s	
15281/22950 (epoch 33.292), train_loss = 0.96684928, grad/param norm = 2.5189e-01, time/batch = 16.8269s	
15282/22950 (epoch 33.294), train_loss = 0.87708724, grad/param norm = 2.2058e-01, time/batch = 16.0239s	
15283/22950 (epoch 33.296), train_loss = 0.68899154, grad/param norm = 1.9549e-01, time/batch = 16.1951s	
15284/22950 (epoch 33.298), train_loss = 0.85143083, grad/param norm = 2.1329e-01, time/batch = 16.8851s	
15285/22950 (epoch 33.301), train_loss = 0.90689450, grad/param norm = 2.6599e-01, time/batch = 17.0604s	
15286/22950 (epoch 33.303), train_loss = 0.86088454, grad/param norm = 2.2551e-01, time/batch = 16.6944s	
15287/22950 (epoch 33.305), train_loss = 0.84531897, grad/param norm = 2.3089e-01, time/batch = 16.9534s	
15288/22950 (epoch 33.307), train_loss = 0.99671069, grad/param norm = 3.3690e-01, time/batch = 16.7057s	
15289/22950 (epoch 33.309), train_loss = 0.81645025, grad/param norm = 2.0733e-01, time/batch = 16.6442s	
15290/22950 (epoch 33.312), train_loss = 0.87986126, grad/param norm = 2.3257e-01, time/batch = 16.6233s	
15291/22950 (epoch 33.314), train_loss = 0.89883295, grad/param norm = 2.1931e-01, time/batch = 16.7154s	
15292/22950 (epoch 33.316), train_loss = 0.84072186, grad/param norm = 2.4733e-01, time/batch = 16.5609s	
15293/22950 (epoch 33.318), train_loss = 0.75582121, grad/param norm = 1.9341e-01, time/batch = 16.7058s	
15294/22950 (epoch 33.320), train_loss = 0.81106784, grad/param norm = 2.2883e-01, time/batch = 16.8306s	
15295/22950 (epoch 33.322), train_loss = 0.84727488, grad/param norm = 2.5918e-01, time/batch = 16.5628s	
15296/22950 (epoch 33.325), train_loss = 0.66684892, grad/param norm = 1.9759e-01, time/batch = 16.8437s	
15297/22950 (epoch 33.327), train_loss = 0.69323710, grad/param norm = 2.2209e-01, time/batch = 16.8561s	
15298/22950 (epoch 33.329), train_loss = 0.80011255, grad/param norm = 2.0297e-01, time/batch = 16.7030s	
15299/22950 (epoch 33.331), train_loss = 0.75157613, grad/param norm = 2.1646e-01, time/batch = 16.6126s	
15300/22950 (epoch 33.333), train_loss = 0.77976318, grad/param norm = 2.2241e-01, time/batch = 16.6471s	
15301/22950 (epoch 33.336), train_loss = 0.84304588, grad/param norm = 2.5415e-01, time/batch = 16.8845s	
15302/22950 (epoch 33.338), train_loss = 0.85689946, grad/param norm = 2.0852e-01, time/batch = 16.7127s	
15303/22950 (epoch 33.340), train_loss = 0.83906281, grad/param norm = 2.6561e-01, time/batch = 16.6087s	
15304/22950 (epoch 33.342), train_loss = 1.00280286, grad/param norm = 2.3194e-01, time/batch = 16.5448s	
15305/22950 (epoch 33.344), train_loss = 0.84100856, grad/param norm = 2.3227e-01, time/batch = 16.4711s	
15306/22950 (epoch 33.346), train_loss = 0.94082605, grad/param norm = 2.5880e-01, time/batch = 16.5483s	
15307/22950 (epoch 33.349), train_loss = 0.85019057, grad/param norm = 2.2042e-01, time/batch = 16.9216s	
15308/22950 (epoch 33.351), train_loss = 0.87856337, grad/param norm = 2.4565e-01, time/batch = 16.9907s	
15309/22950 (epoch 33.353), train_loss = 0.92407724, grad/param norm = 4.7655e-01, time/batch = 16.7020s	
15310/22950 (epoch 33.355), train_loss = 0.96674075, grad/param norm = 2.9147e-01, time/batch = 16.5604s	
15311/22950 (epoch 33.357), train_loss = 0.86988127, grad/param norm = 2.9117e-01, time/batch = 16.6134s	
15312/22950 (epoch 33.359), train_loss = 0.88064233, grad/param norm = 2.7752e-01, time/batch = 16.8718s	
15313/22950 (epoch 33.362), train_loss = 0.90397556, grad/param norm = 2.3894e-01, time/batch = 16.7729s	
15314/22950 (epoch 33.364), train_loss = 0.88252988, grad/param norm = 3.1618e-01, time/batch = 16.5446s	
15315/22950 (epoch 33.366), train_loss = 0.86874749, grad/param norm = 2.2830e-01, time/batch = 16.3760s	
15316/22950 (epoch 33.368), train_loss = 0.95499212, grad/param norm = 2.7093e-01, time/batch = 16.2954s	
15317/22950 (epoch 33.370), train_loss = 0.84536270, grad/param norm = 2.3429e-01, time/batch = 16.5212s	
15318/22950 (epoch 33.373), train_loss = 0.78610487, grad/param norm = 2.2420e-01, time/batch = 16.2269s	
15319/22950 (epoch 33.375), train_loss = 0.97977133, grad/param norm = 2.5822e-01, time/batch = 16.2683s	
15320/22950 (epoch 33.377), train_loss = 0.79794678, grad/param norm = 2.9694e-01, time/batch = 15.9392s	
15321/22950 (epoch 33.379), train_loss = 0.89397035, grad/param norm = 2.7234e-01, time/batch = 16.2110s	
15322/22950 (epoch 33.381), train_loss = 0.77490701, grad/param norm = 2.3898e-01, time/batch = 16.5186s	
15323/22950 (epoch 33.383), train_loss = 0.84442820, grad/param norm = 2.5006e-01, time/batch = 16.4595s	
15324/22950 (epoch 33.386), train_loss = 0.79582181, grad/param norm = 2.4617e-01, time/batch = 16.4507s	
15325/22950 (epoch 33.388), train_loss = 0.93391150, grad/param norm = 2.5076e-01, time/batch = 16.2148s	
15326/22950 (epoch 33.390), train_loss = 0.77363898, grad/param norm = 2.5035e-01, time/batch = 16.7422s	
15327/22950 (epoch 33.392), train_loss = 0.81408137, grad/param norm = 2.4024e-01, time/batch = 16.8311s	
15328/22950 (epoch 33.394), train_loss = 0.83131927, grad/param norm = 2.1269e-01, time/batch = 17.0470s	
15329/22950 (epoch 33.397), train_loss = 0.96373703, grad/param norm = 2.3589e-01, time/batch = 17.0222s	
15330/22950 (epoch 33.399), train_loss = 0.94634608, grad/param norm = 2.7087e-01, time/batch = 17.0191s	
15331/22950 (epoch 33.401), train_loss = 1.01986843, grad/param norm = 3.0497e-01, time/batch = 17.1788s	
15332/22950 (epoch 33.403), train_loss = 0.85851922, grad/param norm = 2.6909e-01, time/batch = 16.8730s	
15333/22950 (epoch 33.405), train_loss = 0.98868981, grad/param norm = 3.0923e-01, time/batch = 17.0796s	
15334/22950 (epoch 33.407), train_loss = 1.02055869, grad/param norm = 2.3773e-01, time/batch = 16.8679s	
15335/22950 (epoch 33.410), train_loss = 0.85853676, grad/param norm = 2.2293e-01, time/batch = 16.9337s	
15336/22950 (epoch 33.412), train_loss = 0.85778959, grad/param norm = 2.5443e-01, time/batch = 16.6867s	
15337/22950 (epoch 33.414), train_loss = 0.97428009, grad/param norm = 2.5005e-01, time/batch = 16.2882s	
15338/22950 (epoch 33.416), train_loss = 0.89689157, grad/param norm = 2.7978e-01, time/batch = 16.0517s	
15339/22950 (epoch 33.418), train_loss = 0.89239517, grad/param norm = 3.0907e-01, time/batch = 16.7541s	
15340/22950 (epoch 33.420), train_loss = 0.96502358, grad/param norm = 3.3236e-01, time/batch = 16.3589s	
15341/22950 (epoch 33.423), train_loss = 0.82634522, grad/param norm = 2.3126e-01, time/batch = 16.6379s	
15342/22950 (epoch 33.425), train_loss = 0.85568173, grad/param norm = 2.3003e-01, time/batch = 16.6235s	
15343/22950 (epoch 33.427), train_loss = 0.89932244, grad/param norm = 2.7031e-01, time/batch = 16.6125s	
15344/22950 (epoch 33.429), train_loss = 0.86238063, grad/param norm = 2.1004e-01, time/batch = 16.5236s	
15345/22950 (epoch 33.431), train_loss = 0.96807185, grad/param norm = 2.7480e-01, time/batch = 15.6503s	
15346/22950 (epoch 33.434), train_loss = 0.90140850, grad/param norm = 2.6332e-01, time/batch = 16.3260s	
15347/22950 (epoch 33.436), train_loss = 0.97149055, grad/param norm = 3.0717e-01, time/batch = 16.6606s	
15348/22950 (epoch 33.438), train_loss = 0.89111815, grad/param norm = 2.5309e-01, time/batch = 16.3053s	
15349/22950 (epoch 33.440), train_loss = 0.96244494, grad/param norm = 2.3422e-01, time/batch = 15.8172s	
15350/22950 (epoch 33.442), train_loss = 1.01857056, grad/param norm = 2.7586e-01, time/batch = 15.8947s	
15351/22950 (epoch 33.444), train_loss = 0.93388044, grad/param norm = 3.7175e-01, time/batch = 16.3695s	
15352/22950 (epoch 33.447), train_loss = 1.04058365, grad/param norm = 2.6877e-01, time/batch = 16.3822s	
15353/22950 (epoch 33.449), train_loss = 0.80416174, grad/param norm = 2.4279e-01, time/batch = 16.1242s	
15354/22950 (epoch 33.451), train_loss = 0.89020156, grad/param norm = 2.4935e-01, time/batch = 16.1504s	
15355/22950 (epoch 33.453), train_loss = 0.92700403, grad/param norm = 2.2024e-01, time/batch = 16.5233s	
15356/22950 (epoch 33.455), train_loss = 0.83124652, grad/param norm = 1.9688e-01, time/batch = 16.2800s	
15357/22950 (epoch 33.458), train_loss = 0.91065006, grad/param norm = 2.5556e-01, time/batch = 16.5935s	
15358/22950 (epoch 33.460), train_loss = 0.94235206, grad/param norm = 2.3967e-01, time/batch = 16.8303s	
15359/22950 (epoch 33.462), train_loss = 0.92980114, grad/param norm = 2.5151e-01, time/batch = 16.7534s	
15360/22950 (epoch 33.464), train_loss = 0.84662648, grad/param norm = 2.3089e-01, time/batch = 16.6392s	
15361/22950 (epoch 33.466), train_loss = 0.98931733, grad/param norm = 3.0772e-01, time/batch = 16.1788s	
15362/22950 (epoch 33.468), train_loss = 0.96370296, grad/param norm = 2.6167e-01, time/batch = 16.6164s	
15363/22950 (epoch 33.471), train_loss = 0.92107061, grad/param norm = 2.7752e-01, time/batch = 16.4511s	
15364/22950 (epoch 33.473), train_loss = 0.93509855, grad/param norm = 2.8167e-01, time/batch = 16.1322s	
15365/22950 (epoch 33.475), train_loss = 1.06931234, grad/param norm = 2.6412e-01, time/batch = 16.1478s	
15366/22950 (epoch 33.477), train_loss = 0.85448617, grad/param norm = 2.5388e-01, time/batch = 16.5012s	
15367/22950 (epoch 33.479), train_loss = 0.78024159, grad/param norm = 2.4388e-01, time/batch = 16.1179s	
15368/22950 (epoch 33.481), train_loss = 0.96371379, grad/param norm = 2.5373e-01, time/batch = 16.5124s	
15369/22950 (epoch 33.484), train_loss = 0.91637344, grad/param norm = 2.6730e-01, time/batch = 16.0460s	
15370/22950 (epoch 33.486), train_loss = 0.77488201, grad/param norm = 2.4440e-01, time/batch = 16.2970s	
15371/22950 (epoch 33.488), train_loss = 0.82118283, grad/param norm = 2.8277e-01, time/batch = 16.4387s	
15372/22950 (epoch 33.490), train_loss = 0.77359281, grad/param norm = 2.4609e-01, time/batch = 16.1236s	
15373/22950 (epoch 33.492), train_loss = 0.84521266, grad/param norm = 2.2332e-01, time/batch = 16.6247s	
15374/22950 (epoch 33.495), train_loss = 0.81234592, grad/param norm = 2.3066e-01, time/batch = 16.7733s	
15375/22950 (epoch 33.497), train_loss = 0.92480408, grad/param norm = 2.4608e-01, time/batch = 16.7327s	
15376/22950 (epoch 33.499), train_loss = 1.01015157, grad/param norm = 2.6626e-01, time/batch = 17.0143s	
15377/22950 (epoch 33.501), train_loss = 0.89863412, grad/param norm = 2.3479e-01, time/batch = 16.4407s	
15378/22950 (epoch 33.503), train_loss = 0.98915917, grad/param norm = 2.3892e-01, time/batch = 15.9749s	
15379/22950 (epoch 33.505), train_loss = 0.74164805, grad/param norm = 2.1651e-01, time/batch = 15.8230s	
15380/22950 (epoch 33.508), train_loss = 0.93533258, grad/param norm = 2.4787e-01, time/batch = 16.0328s	
15381/22950 (epoch 33.510), train_loss = 0.85622742, grad/param norm = 2.3276e-01, time/batch = 16.2729s	
15382/22950 (epoch 33.512), train_loss = 0.77416447, grad/param norm = 2.5184e-01, time/batch = 15.7236s	
15383/22950 (epoch 33.514), train_loss = 0.84818690, grad/param norm = 2.0748e-01, time/batch = 15.8968s	
15384/22950 (epoch 33.516), train_loss = 0.89147944, grad/param norm = 2.3070e-01, time/batch = 16.4430s	
15385/22950 (epoch 33.519), train_loss = 0.87045445, grad/param norm = 2.2947e-01, time/batch = 16.6232s	
15386/22950 (epoch 33.521), train_loss = 0.87677521, grad/param norm = 2.4837e-01, time/batch = 16.5374s	
15387/22950 (epoch 33.523), train_loss = 0.71654240, grad/param norm = 2.1659e-01, time/batch = 16.1310s	
15388/22950 (epoch 33.525), train_loss = 0.79478950, grad/param norm = 2.2892e-01, time/batch = 16.3152s	
15389/22950 (epoch 33.527), train_loss = 0.76680037, grad/param norm = 2.0822e-01, time/batch = 16.0485s	
15390/22950 (epoch 33.529), train_loss = 0.88384914, grad/param norm = 2.3184e-01, time/batch = 16.0311s	
15391/22950 (epoch 33.532), train_loss = 0.85764078, grad/param norm = 2.3562e-01, time/batch = 16.4270s	
15392/22950 (epoch 33.534), train_loss = 0.89702748, grad/param norm = 2.2832e-01, time/batch = 16.3921s	
15393/22950 (epoch 33.536), train_loss = 0.94776241, grad/param norm = 2.9349e-01, time/batch = 16.1414s	
15394/22950 (epoch 33.538), train_loss = 0.89076895, grad/param norm = 2.4104e-01, time/batch = 16.2211s	
15395/22950 (epoch 33.540), train_loss = 0.91317344, grad/param norm = 2.4818e-01, time/batch = 16.5413s	
15396/22950 (epoch 33.542), train_loss = 1.02876414, grad/param norm = 2.8351e-01, time/batch = 15.3897s	
15397/22950 (epoch 33.545), train_loss = 0.85553789, grad/param norm = 2.2945e-01, time/batch = 15.2435s	
15398/22950 (epoch 33.547), train_loss = 0.86024787, grad/param norm = 2.1856e-01, time/batch = 15.0840s	
15399/22950 (epoch 33.549), train_loss = 0.82092143, grad/param norm = 2.5873e-01, time/batch = 15.3823s	
15400/22950 (epoch 33.551), train_loss = 0.85839453, grad/param norm = 2.6047e-01, time/batch = 15.6915s	
15401/22950 (epoch 33.553), train_loss = 0.84347256, grad/param norm = 3.0172e-01, time/batch = 16.0911s	
15402/22950 (epoch 33.556), train_loss = 0.90540947, grad/param norm = 2.2865e-01, time/batch = 15.3026s	
15403/22950 (epoch 33.558), train_loss = 0.73913176, grad/param norm = 2.2905e-01, time/batch = 15.7763s	
15404/22950 (epoch 33.560), train_loss = 0.84412895, grad/param norm = 2.6507e-01, time/batch = 14.9202s	
15405/22950 (epoch 33.562), train_loss = 0.80587433, grad/param norm = 2.2592e-01, time/batch = 14.8311s	
15406/22950 (epoch 33.564), train_loss = 0.92537453, grad/param norm = 3.7154e-01, time/batch = 14.9095s	
15407/22950 (epoch 33.566), train_loss = 0.93171353, grad/param norm = 2.7160e-01, time/batch = 15.4638s	
15408/22950 (epoch 33.569), train_loss = 0.85639687, grad/param norm = 2.3858e-01, time/batch = 14.9217s	
15409/22950 (epoch 33.571), train_loss = 0.84016817, grad/param norm = 2.5681e-01, time/batch = 16.4759s	
15410/22950 (epoch 33.573), train_loss = 0.86024856, grad/param norm = 2.3529e-01, time/batch = 16.1818s	
15411/22950 (epoch 33.575), train_loss = 0.95123463, grad/param norm = 2.7234e-01, time/batch = 16.1278s	
15412/22950 (epoch 33.577), train_loss = 0.89740315, grad/param norm = 2.7068e-01, time/batch = 15.0763s	
15413/22950 (epoch 33.580), train_loss = 0.93816653, grad/param norm = 2.5856e-01, time/batch = 14.9229s	
15414/22950 (epoch 33.582), train_loss = 1.02391065, grad/param norm = 2.8479e-01, time/batch = 15.3171s	
15415/22950 (epoch 33.584), train_loss = 0.75331206, grad/param norm = 2.6827e-01, time/batch = 15.3054s	
15416/22950 (epoch 33.586), train_loss = 0.80967477, grad/param norm = 2.4813e-01, time/batch = 15.7799s	
15417/22950 (epoch 33.588), train_loss = 0.98017983, grad/param norm = 2.5626e-01, time/batch = 15.3217s	
15418/22950 (epoch 33.590), train_loss = 0.93188724, grad/param norm = 2.6560e-01, time/batch = 15.3113s	
15419/22950 (epoch 33.593), train_loss = 0.84857803, grad/param norm = 2.2926e-01, time/batch = 15.1497s	
15420/22950 (epoch 33.595), train_loss = 0.78714305, grad/param norm = 2.3880e-01, time/batch = 15.0852s	
15421/22950 (epoch 33.597), train_loss = 0.95762716, grad/param norm = 2.5944e-01, time/batch = 15.5627s	
15422/22950 (epoch 33.599), train_loss = 0.89189781, grad/param norm = 2.9458e-01, time/batch = 22.9621s	
15423/22950 (epoch 33.601), train_loss = 0.91485539, grad/param norm = 2.4954e-01, time/batch = 27.3455s	
15424/22950 (epoch 33.603), train_loss = 1.00975259, grad/param norm = 2.6127e-01, time/batch = 17.8641s	
15425/22950 (epoch 33.606), train_loss = 0.89109820, grad/param norm = 2.5603e-01, time/batch = 19.9621s	
15426/22950 (epoch 33.608), train_loss = 0.87394842, grad/param norm = 2.4506e-01, time/batch = 17.0352s	
15427/22950 (epoch 33.610), train_loss = 0.87477725, grad/param norm = 2.3747e-01, time/batch = 17.1437s	
15428/22950 (epoch 33.612), train_loss = 0.89180925, grad/param norm = 2.5618e-01, time/batch = 16.4874s	
15429/22950 (epoch 33.614), train_loss = 0.98554366, grad/param norm = 2.7221e-01, time/batch = 17.0084s	
15430/22950 (epoch 33.617), train_loss = 0.88180204, grad/param norm = 2.3241e-01, time/batch = 16.1664s	
15431/22950 (epoch 33.619), train_loss = 0.82996698, grad/param norm = 2.1594e-01, time/batch = 17.0826s	
15432/22950 (epoch 33.621), train_loss = 0.95990393, grad/param norm = 2.4322e-01, time/batch = 20.1930s	
15433/22950 (epoch 33.623), train_loss = 0.93762068, grad/param norm = 2.5386e-01, time/batch = 19.2914s	
15434/22950 (epoch 33.625), train_loss = 0.85874848, grad/param norm = 2.4360e-01, time/batch = 16.5066s	
15435/22950 (epoch 33.627), train_loss = 0.85689951, grad/param norm = 2.6453e-01, time/batch = 19.5106s	
15436/22950 (epoch 33.630), train_loss = 0.76089622, grad/param norm = 2.0732e-01, time/batch = 18.2998s	
15437/22950 (epoch 33.632), train_loss = 0.83298343, grad/param norm = 2.6115e-01, time/batch = 20.3789s	
15438/22950 (epoch 33.634), train_loss = 0.92036174, grad/param norm = 2.5611e-01, time/batch = 18.0778s	
15439/22950 (epoch 33.636), train_loss = 0.87602975, grad/param norm = 2.8851e-01, time/batch = 19.7782s	
15440/22950 (epoch 33.638), train_loss = 0.84873763, grad/param norm = 2.4425e-01, time/batch = 18.5954s	
15441/22950 (epoch 33.641), train_loss = 0.84700683, grad/param norm = 2.3241e-01, time/batch = 19.4352s	
15442/22950 (epoch 33.643), train_loss = 0.91092065, grad/param norm = 2.7686e-01, time/batch = 18.9144s	
15443/22950 (epoch 33.645), train_loss = 0.83814001, grad/param norm = 2.3881e-01, time/batch = 19.1028s	
15444/22950 (epoch 33.647), train_loss = 0.85436155, grad/param norm = 2.6134e-01, time/batch = 19.6196s	
15445/22950 (epoch 33.649), train_loss = 0.83186246, grad/param norm = 2.4146e-01, time/batch = 18.5432s	
15446/22950 (epoch 33.651), train_loss = 0.95196811, grad/param norm = 2.3708e-01, time/batch = 18.9534s	
15447/22950 (epoch 33.654), train_loss = 0.74462634, grad/param norm = 2.2543e-01, time/batch = 17.2867s	
15448/22950 (epoch 33.656), train_loss = 0.92980564, grad/param norm = 3.0231e-01, time/batch = 16.6058s	
15449/22950 (epoch 33.658), train_loss = 0.79088164, grad/param norm = 2.5101e-01, time/batch = 16.1484s	
15450/22950 (epoch 33.660), train_loss = 0.71028890, grad/param norm = 2.3816e-01, time/batch = 15.0055s	
15451/22950 (epoch 33.662), train_loss = 0.72255102, grad/param norm = 2.2386e-01, time/batch = 16.1864s	
15452/22950 (epoch 33.664), train_loss = 0.83984885, grad/param norm = 2.5175e-01, time/batch = 15.3298s	
15453/22950 (epoch 33.667), train_loss = 0.87453122, grad/param norm = 2.3365e-01, time/batch = 15.3263s	
15454/22950 (epoch 33.669), train_loss = 0.87255439, grad/param norm = 2.4396e-01, time/batch = 15.8097s	
15455/22950 (epoch 33.671), train_loss = 0.86113085, grad/param norm = 2.5982e-01, time/batch = 15.7404s	
15456/22950 (epoch 33.673), train_loss = 0.81899149, grad/param norm = 2.5796e-01, time/batch = 15.4164s	
15457/22950 (epoch 33.675), train_loss = 0.91262529, grad/param norm = 2.8160e-01, time/batch = 15.5530s	
15458/22950 (epoch 33.678), train_loss = 0.85981852, grad/param norm = 2.3106e-01, time/batch = 16.8697s	
15459/22950 (epoch 33.680), train_loss = 0.89754393, grad/param norm = 2.1672e-01, time/batch = 19.4458s	
15460/22950 (epoch 33.682), train_loss = 0.87250910, grad/param norm = 2.6365e-01, time/batch = 15.4589s	
15461/22950 (epoch 33.684), train_loss = 0.97845720, grad/param norm = 2.7708e-01, time/batch = 15.8001s	
15462/22950 (epoch 33.686), train_loss = 0.98317589, grad/param norm = 2.5419e-01, time/batch = 17.5320s	
15463/22950 (epoch 33.688), train_loss = 0.90451660, grad/param norm = 2.5192e-01, time/batch = 20.1209s	
15464/22950 (epoch 33.691), train_loss = 0.87620470, grad/param norm = 2.2453e-01, time/batch = 18.4485s	
15465/22950 (epoch 33.693), train_loss = 0.81905410, grad/param norm = 2.6603e-01, time/batch = 18.3655s	
15466/22950 (epoch 33.695), train_loss = 0.98903850, grad/param norm = 3.1131e-01, time/batch = 17.5183s	
15467/22950 (epoch 33.697), train_loss = 0.93081798, grad/param norm = 2.8638e-01, time/batch = 20.7044s	
15468/22950 (epoch 33.699), train_loss = 0.92542400, grad/param norm = 2.4064e-01, time/batch = 17.9486s	
15469/22950 (epoch 33.702), train_loss = 0.94463974, grad/param norm = 2.7762e-01, time/batch = 19.7007s	
15470/22950 (epoch 33.704), train_loss = 1.04711817, grad/param norm = 3.2695e-01, time/batch = 16.0375s	
15471/22950 (epoch 33.706), train_loss = 0.97737391, grad/param norm = 2.9252e-01, time/batch = 18.0323s	
15472/22950 (epoch 33.708), train_loss = 0.78233572, grad/param norm = 2.6012e-01, time/batch = 17.9232s	
15473/22950 (epoch 33.710), train_loss = 0.88979126, grad/param norm = 2.4487e-01, time/batch = 17.6420s	
15474/22950 (epoch 33.712), train_loss = 0.99157975, grad/param norm = 2.6736e-01, time/batch = 16.4838s	
15475/22950 (epoch 33.715), train_loss = 0.90940441, grad/param norm = 2.8485e-01, time/batch = 16.5350s	
15476/22950 (epoch 33.717), train_loss = 0.92254589, grad/param norm = 2.3732e-01, time/batch = 17.0362s	
15477/22950 (epoch 33.719), train_loss = 0.84706035, grad/param norm = 2.8479e-01, time/batch = 15.8752s	
15478/22950 (epoch 33.721), train_loss = 0.95473454, grad/param norm = 2.8657e-01, time/batch = 18.8783s	
15479/22950 (epoch 33.723), train_loss = 0.89459074, grad/param norm = 2.6190e-01, time/batch = 17.9417s	
15480/22950 (epoch 33.725), train_loss = 0.93599837, grad/param norm = 2.7109e-01, time/batch = 19.3795s	
15481/22950 (epoch 33.728), train_loss = 0.85317070, grad/param norm = 2.6056e-01, time/batch = 19.1282s	
15482/22950 (epoch 33.730), train_loss = 0.87682119, grad/param norm = 2.5933e-01, time/batch = 17.7863s	
15483/22950 (epoch 33.732), train_loss = 0.95513089, grad/param norm = 2.8293e-01, time/batch = 17.8704s	
15484/22950 (epoch 33.734), train_loss = 0.86929487, grad/param norm = 2.9927e-01, time/batch = 18.3937s	
15485/22950 (epoch 33.736), train_loss = 0.92959580, grad/param norm = 2.4374e-01, time/batch = 17.2975s	
15486/22950 (epoch 33.739), train_loss = 0.97635830, grad/param norm = 2.8402e-01, time/batch = 17.7628s	
15487/22950 (epoch 33.741), train_loss = 0.96646205, grad/param norm = 2.8621e-01, time/batch = 17.3615s	
15488/22950 (epoch 33.743), train_loss = 1.03059229, grad/param norm = 3.1230e-01, time/batch = 18.8520s	
15489/22950 (epoch 33.745), train_loss = 1.11923165, grad/param norm = 3.0603e-01, time/batch = 19.0313s	
15490/22950 (epoch 33.747), train_loss = 0.92295418, grad/param norm = 2.4773e-01, time/batch = 18.2069s	
15491/22950 (epoch 33.749), train_loss = 0.83391548, grad/param norm = 2.9109e-01, time/batch = 18.3717s	
15492/22950 (epoch 33.752), train_loss = 1.06668347, grad/param norm = 2.9049e-01, time/batch = 16.2066s	
15493/22950 (epoch 33.754), train_loss = 0.94401206, grad/param norm = 2.5094e-01, time/batch = 18.9412s	
15494/22950 (epoch 33.756), train_loss = 0.84665761, grad/param norm = 2.3249e-01, time/batch = 16.2618s	
15495/22950 (epoch 33.758), train_loss = 0.91655774, grad/param norm = 2.3750e-01, time/batch = 17.1979s	
15496/22950 (epoch 33.760), train_loss = 0.90322316, grad/param norm = 2.3768e-01, time/batch = 16.4218s	
15497/22950 (epoch 33.763), train_loss = 0.93494091, grad/param norm = 2.6141e-01, time/batch = 17.1078s	
15498/22950 (epoch 33.765), train_loss = 0.88699440, grad/param norm = 2.6417e-01, time/batch = 19.0861s	
15499/22950 (epoch 33.767), train_loss = 1.10697255, grad/param norm = 3.0690e-01, time/batch = 16.3410s	
15500/22950 (epoch 33.769), train_loss = 0.93797713, grad/param norm = 2.4042e-01, time/batch = 17.0518s	
15501/22950 (epoch 33.771), train_loss = 0.79178787, grad/param norm = 2.5804e-01, time/batch = 18.1848s	
15502/22950 (epoch 33.773), train_loss = 0.69917386, grad/param norm = 2.1089e-01, time/batch = 17.5613s	
15503/22950 (epoch 33.776), train_loss = 0.81593665, grad/param norm = 2.0359e-01, time/batch = 19.8672s	
15504/22950 (epoch 33.778), train_loss = 0.80907769, grad/param norm = 2.2560e-01, time/batch = 17.6126s	
15505/22950 (epoch 33.780), train_loss = 0.89752098, grad/param norm = 2.3839e-01, time/batch = 18.6994s	
15506/22950 (epoch 33.782), train_loss = 0.93735559, grad/param norm = 2.2911e-01, time/batch = 17.6027s	
15507/22950 (epoch 33.784), train_loss = 0.82201496, grad/param norm = 2.3957e-01, time/batch = 18.1979s	
15508/22950 (epoch 33.786), train_loss = 0.89413095, grad/param norm = 2.6840e-01, time/batch = 19.0246s	
15509/22950 (epoch 33.789), train_loss = 0.75473425, grad/param norm = 2.3612e-01, time/batch = 17.1945s	
15510/22950 (epoch 33.791), train_loss = 0.78901463, grad/param norm = 2.2524e-01, time/batch = 18.0361s	
15511/22950 (epoch 33.793), train_loss = 0.97414266, grad/param norm = 2.6370e-01, time/batch = 19.0254s	
15512/22950 (epoch 33.795), train_loss = 0.86274725, grad/param norm = 2.2256e-01, time/batch = 18.6006s	
15513/22950 (epoch 33.797), train_loss = 0.97803249, grad/param norm = 2.3154e-01, time/batch = 16.4157s	
15514/22950 (epoch 33.800), train_loss = 0.81103269, grad/param norm = 2.3087e-01, time/batch = 17.1280s	
15515/22950 (epoch 33.802), train_loss = 0.85391981, grad/param norm = 2.5541e-01, time/batch = 16.8342s	
15516/22950 (epoch 33.804), train_loss = 0.85514254, grad/param norm = 2.3819e-01, time/batch = 18.8717s	
15517/22950 (epoch 33.806), train_loss = 0.76053211, grad/param norm = 2.2592e-01, time/batch = 16.2342s	
15518/22950 (epoch 33.808), train_loss = 0.87328493, grad/param norm = 2.2328e-01, time/batch = 16.9053s	
15519/22950 (epoch 33.810), train_loss = 0.84896972, grad/param norm = 2.3755e-01, time/batch = 18.1918s	
15520/22950 (epoch 33.813), train_loss = 0.73183676, grad/param norm = 2.1751e-01, time/batch = 18.8853s	
15521/22950 (epoch 33.815), train_loss = 0.70456192, grad/param norm = 2.1629e-01, time/batch = 19.7089s	
15522/22950 (epoch 33.817), train_loss = 0.80271350, grad/param norm = 2.2166e-01, time/batch = 16.0091s	
15523/22950 (epoch 33.819), train_loss = 0.85465789, grad/param norm = 2.5275e-01, time/batch = 19.0544s	
15524/22950 (epoch 33.821), train_loss = 0.87407843, grad/param norm = 2.6993e-01, time/batch = 17.2204s	
15525/22950 (epoch 33.824), train_loss = 0.88502659, grad/param norm = 2.2787e-01, time/batch = 18.7063s	
15526/22950 (epoch 33.826), train_loss = 0.91629877, grad/param norm = 2.5985e-01, time/batch = 18.5281s	
15527/22950 (epoch 33.828), train_loss = 0.84513618, grad/param norm = 2.4308e-01, time/batch = 16.5581s	
15528/22950 (epoch 33.830), train_loss = 0.82618249, grad/param norm = 2.2917e-01, time/batch = 18.8670s	
15529/22950 (epoch 33.832), train_loss = 0.87448020, grad/param norm = 2.2684e-01, time/batch = 18.6145s	
15530/22950 (epoch 33.834), train_loss = 0.74311983, grad/param norm = 2.4108e-01, time/batch = 16.1714s	
15531/22950 (epoch 33.837), train_loss = 0.88227589, grad/param norm = 2.4921e-01, time/batch = 17.0423s	
15532/22950 (epoch 33.839), train_loss = 0.74120716, grad/param norm = 2.1957e-01, time/batch = 18.6051s	
15533/22950 (epoch 33.841), train_loss = 0.82901599, grad/param norm = 2.2452e-01, time/batch = 17.3519s	
15534/22950 (epoch 33.843), train_loss = 0.79924077, grad/param norm = 2.3087e-01, time/batch = 19.1832s	
15535/22950 (epoch 33.845), train_loss = 0.86451277, grad/param norm = 2.3436e-01, time/batch = 17.5221s	
15536/22950 (epoch 33.847), train_loss = 0.89633867, grad/param norm = 2.3559e-01, time/batch = 18.0140s	
15537/22950 (epoch 33.850), train_loss = 0.94381858, grad/param norm = 2.5213e-01, time/batch = 18.2866s	
15538/22950 (epoch 33.852), train_loss = 0.94144256, grad/param norm = 2.8120e-01, time/batch = 20.1011s	
15539/22950 (epoch 33.854), train_loss = 0.87874456, grad/param norm = 2.6283e-01, time/batch = 19.8277s	
15540/22950 (epoch 33.856), train_loss = 0.99430923, grad/param norm = 3.8072e-01, time/batch = 18.8665s	
15541/22950 (epoch 33.858), train_loss = 0.94291676, grad/param norm = 2.6100e-01, time/batch = 18.4401s	
15542/22950 (epoch 33.861), train_loss = 0.93891845, grad/param norm = 2.6967e-01, time/batch = 17.4238s	
15543/22950 (epoch 33.863), train_loss = 0.96543608, grad/param norm = 2.6427e-01, time/batch = 18.8691s	
15544/22950 (epoch 33.865), train_loss = 1.00624223, grad/param norm = 2.7156e-01, time/batch = 19.8724s	
15545/22950 (epoch 33.867), train_loss = 0.89494042, grad/param norm = 2.4861e-01, time/batch = 16.8561s	
15546/22950 (epoch 33.869), train_loss = 1.05990795, grad/param norm = 3.1333e-01, time/batch = 18.1934s	
15547/22950 (epoch 33.871), train_loss = 0.91845220, grad/param norm = 2.7345e-01, time/batch = 19.5411s	
15548/22950 (epoch 33.874), train_loss = 0.91803280, grad/param norm = 2.2768e-01, time/batch = 16.7959s	
15549/22950 (epoch 33.876), train_loss = 0.98391664, grad/param norm = 2.9188e-01, time/batch = 16.6877s	
15550/22950 (epoch 33.878), train_loss = 0.90215222, grad/param norm = 2.9872e-01, time/batch = 16.6167s	
15551/22950 (epoch 33.880), train_loss = 1.07408889, grad/param norm = 2.7837e-01, time/batch = 19.6985s	
15552/22950 (epoch 33.882), train_loss = 0.78629983, grad/param norm = 2.3517e-01, time/batch = 18.3712s	
15553/22950 (epoch 33.885), train_loss = 0.92528319, grad/param norm = 2.6524e-01, time/batch = 20.2982s	
15554/22950 (epoch 33.887), train_loss = 0.88587264, grad/param norm = 2.3597e-01, time/batch = 19.8772s	
15555/22950 (epoch 33.889), train_loss = 0.91914083, grad/param norm = 2.5821e-01, time/batch = 5.4872s	
15556/22950 (epoch 33.891), train_loss = 0.83117579, grad/param norm = 2.3608e-01, time/batch = 0.6954s	
15557/22950 (epoch 33.893), train_loss = 0.94493478, grad/param norm = 2.5007e-01, time/batch = 0.6893s	
15558/22950 (epoch 33.895), train_loss = 1.02827326, grad/param norm = 2.4013e-01, time/batch = 0.6883s	
15559/22950 (epoch 33.898), train_loss = 0.94469782, grad/param norm = 2.8571e-01, time/batch = 0.6900s	
15560/22950 (epoch 33.900), train_loss = 0.84673855, grad/param norm = 2.1992e-01, time/batch = 0.6910s	
15561/22950 (epoch 33.902), train_loss = 0.92253391, grad/param norm = 2.6304e-01, time/batch = 0.7021s	
15562/22950 (epoch 33.904), train_loss = 0.89182356, grad/param norm = 2.4113e-01, time/batch = 0.8909s	
15563/22950 (epoch 33.906), train_loss = 0.94004461, grad/param norm = 2.7247e-01, time/batch = 1.0379s	
15564/22950 (epoch 33.908), train_loss = 0.79079724, grad/param norm = 2.4191e-01, time/batch = 1.0472s	
15565/22950 (epoch 33.911), train_loss = 0.75006226, grad/param norm = 2.1490e-01, time/batch = 1.0293s	
15566/22950 (epoch 33.913), train_loss = 0.88709877, grad/param norm = 2.4290e-01, time/batch = 1.0277s	
15567/22950 (epoch 33.915), train_loss = 1.00963350, grad/param norm = 2.7234e-01, time/batch = 1.6801s	
15568/22950 (epoch 33.917), train_loss = 0.80257344, grad/param norm = 2.3090e-01, time/batch = 1.9278s	
15569/22950 (epoch 33.919), train_loss = 0.90582620, grad/param norm = 2.4580e-01, time/batch = 3.8614s	
15570/22950 (epoch 33.922), train_loss = 0.89094204, grad/param norm = 2.6204e-01, time/batch = 16.3928s	
15571/22950 (epoch 33.924), train_loss = 0.92878499, grad/param norm = 2.9196e-01, time/batch = 17.5251s	
15572/22950 (epoch 33.926), train_loss = 0.74115153, grad/param norm = 2.5951e-01, time/batch = 19.1827s	
15573/22950 (epoch 33.928), train_loss = 0.79542723, grad/param norm = 2.4949e-01, time/batch = 17.4517s	
15574/22950 (epoch 33.930), train_loss = 0.79225686, grad/param norm = 2.5559e-01, time/batch = 16.8813s	
15575/22950 (epoch 33.932), train_loss = 0.74622889, grad/param norm = 2.2809e-01, time/batch = 17.7955s	
15576/22950 (epoch 33.935), train_loss = 0.90829921, grad/param norm = 2.5369e-01, time/batch = 19.9598s	
15577/22950 (epoch 33.937), train_loss = 0.89132850, grad/param norm = 2.7024e-01, time/batch = 15.9747s	
15578/22950 (epoch 33.939), train_loss = 0.84354562, grad/param norm = 2.6923e-01, time/batch = 19.3613s	
15579/22950 (epoch 33.941), train_loss = 0.86058001, grad/param norm = 2.5244e-01, time/batch = 17.9674s	
15580/22950 (epoch 33.943), train_loss = 0.89138091, grad/param norm = 2.7435e-01, time/batch = 19.4637s	
15581/22950 (epoch 33.946), train_loss = 0.74509425, grad/param norm = 2.2930e-01, time/batch = 19.5250s	
15582/22950 (epoch 33.948), train_loss = 0.97156805, grad/param norm = 2.5289e-01, time/batch = 19.0315s	
15583/22950 (epoch 33.950), train_loss = 0.88100181, grad/param norm = 3.1415e-01, time/batch = 18.6184s	
15584/22950 (epoch 33.952), train_loss = 0.91650503, grad/param norm = 2.2646e-01, time/batch = 18.9639s	
15585/22950 (epoch 33.954), train_loss = 0.91942477, grad/param norm = 2.3797e-01, time/batch = 19.6824s	
15586/22950 (epoch 33.956), train_loss = 0.83645594, grad/param norm = 2.5663e-01, time/batch = 17.7115s	
15587/22950 (epoch 33.959), train_loss = 0.79625429, grad/param norm = 2.2982e-01, time/batch = 17.5308s	
15588/22950 (epoch 33.961), train_loss = 0.88690841, grad/param norm = 2.4895e-01, time/batch = 17.0767s	
15589/22950 (epoch 33.963), train_loss = 0.89724534, grad/param norm = 2.4193e-01, time/batch = 18.7797s	
15590/22950 (epoch 33.965), train_loss = 0.96511252, grad/param norm = 2.6311e-01, time/batch = 17.3796s	
15591/22950 (epoch 33.967), train_loss = 0.86991888, grad/param norm = 2.4798e-01, time/batch = 18.7781s	
15592/22950 (epoch 33.969), train_loss = 0.77933943, grad/param norm = 2.4207e-01, time/batch = 16.3068s	
15593/22950 (epoch 33.972), train_loss = 0.85966843, grad/param norm = 2.3368e-01, time/batch = 16.2514s	
15594/22950 (epoch 33.974), train_loss = 0.83313420, grad/param norm = 2.5004e-01, time/batch = 19.0280s	
15595/22950 (epoch 33.976), train_loss = 0.85724295, grad/param norm = 2.4206e-01, time/batch = 17.6081s	
15596/22950 (epoch 33.978), train_loss = 0.79472336, grad/param norm = 2.2135e-01, time/batch = 19.0287s	
15597/22950 (epoch 33.980), train_loss = 0.83972505, grad/param norm = 2.2957e-01, time/batch = 21.1139s	
15598/22950 (epoch 33.983), train_loss = 0.90613868, grad/param norm = 2.3210e-01, time/batch = 17.6873s	
15599/22950 (epoch 33.985), train_loss = 0.76466765, grad/param norm = 2.1987e-01, time/batch = 18.1029s	
15600/22950 (epoch 33.987), train_loss = 0.80168669, grad/param norm = 2.1360e-01, time/batch = 19.3483s	
15601/22950 (epoch 33.989), train_loss = 0.88355799, grad/param norm = 2.4398e-01, time/batch = 16.5910s	
15602/22950 (epoch 33.991), train_loss = 0.74322965, grad/param norm = 2.0906e-01, time/batch = 18.2606s	
15603/22950 (epoch 33.993), train_loss = 0.90086166, grad/param norm = 2.4803e-01, time/batch = 17.8754s	
15604/22950 (epoch 33.996), train_loss = 0.88280140, grad/param norm = 2.7571e-01, time/batch = 18.6971s	
15605/22950 (epoch 33.998), train_loss = 0.78316284, grad/param norm = 2.5469e-01, time/batch = 17.3711s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
15606/22950 (epoch 34.000), train_loss = 0.72936872, grad/param norm = 2.1926e-01, time/batch = 16.7920s	
15607/22950 (epoch 34.002), train_loss = 1.04463134, grad/param norm = 2.9118e-01, time/batch = 20.1183s	
15608/22950 (epoch 34.004), train_loss = 0.91428056, grad/param norm = 2.4100e-01, time/batch = 17.0066s	
15609/22950 (epoch 34.007), train_loss = 0.85400090, grad/param norm = 2.7185e-01, time/batch = 19.0420s	
15610/22950 (epoch 34.009), train_loss = 1.00312872, grad/param norm = 3.0362e-01, time/batch = 17.6259s	
15611/22950 (epoch 34.011), train_loss = 0.75021488, grad/param norm = 2.4429e-01, time/batch = 16.3497s	
15612/22950 (epoch 34.013), train_loss = 0.84287988, grad/param norm = 2.3313e-01, time/batch = 17.1174s	
15613/22950 (epoch 34.015), train_loss = 0.89640908, grad/param norm = 2.4181e-01, time/batch = 19.3782s	
15614/22950 (epoch 34.017), train_loss = 0.90244118, grad/param norm = 2.3911e-01, time/batch = 17.8404s	
15615/22950 (epoch 34.020), train_loss = 0.90792554, grad/param norm = 2.4011e-01, time/batch = 17.5440s	
15616/22950 (epoch 34.022), train_loss = 0.76606697, grad/param norm = 2.1978e-01, time/batch = 18.0091s	
15617/22950 (epoch 34.024), train_loss = 0.85294102, grad/param norm = 2.4429e-01, time/batch = 16.4344s	
15618/22950 (epoch 34.026), train_loss = 0.88776969, grad/param norm = 2.2257e-01, time/batch = 17.7484s	
15619/22950 (epoch 34.028), train_loss = 0.96477317, grad/param norm = 2.3698e-01, time/batch = 17.2028s	
15620/22950 (epoch 34.031), train_loss = 0.83551847, grad/param norm = 2.6238e-01, time/batch = 17.9739s	
15621/22950 (epoch 34.033), train_loss = 0.95693451, grad/param norm = 2.7971e-01, time/batch = 17.5142s	
15622/22950 (epoch 34.035), train_loss = 0.84557416, grad/param norm = 2.1173e-01, time/batch = 18.8559s	
15623/22950 (epoch 34.037), train_loss = 0.85694628, grad/param norm = 2.2282e-01, time/batch = 16.1174s	
15624/22950 (epoch 34.039), train_loss = 0.85624016, grad/param norm = 2.7106e-01, time/batch = 19.8639s	
15625/22950 (epoch 34.041), train_loss = 0.80155759, grad/param norm = 2.6764e-01, time/batch = 19.7689s	
15626/22950 (epoch 34.044), train_loss = 0.91995426, grad/param norm = 2.6712e-01, time/batch = 19.4466s	
15627/22950 (epoch 34.046), train_loss = 0.86414937, grad/param norm = 2.3641e-01, time/batch = 19.0473s	
15628/22950 (epoch 34.048), train_loss = 0.88534090, grad/param norm = 2.3127e-01, time/batch = 18.2038s	
15629/22950 (epoch 34.050), train_loss = 0.84299102, grad/param norm = 2.8945e-01, time/batch = 17.0447s	
15630/22950 (epoch 34.052), train_loss = 0.89726373, grad/param norm = 2.4477e-01, time/batch = 19.4529s	
15631/22950 (epoch 34.054), train_loss = 1.00229553, grad/param norm = 2.6268e-01, time/batch = 17.8711s	
15632/22950 (epoch 34.057), train_loss = 0.96777530, grad/param norm = 2.7270e-01, time/batch = 20.7810s	
15633/22950 (epoch 34.059), train_loss = 0.96634371, grad/param norm = 2.4906e-01, time/batch = 17.3077s	
15634/22950 (epoch 34.061), train_loss = 0.82017944, grad/param norm = 2.3870e-01, time/batch = 26.2381s	
15635/22950 (epoch 34.063), train_loss = 0.92590941, grad/param norm = 3.1835e-01, time/batch = 21.3683s	
15636/22950 (epoch 34.065), train_loss = 0.78362868, grad/param norm = 2.3582e-01, time/batch = 15.8534s	
15637/22950 (epoch 34.068), train_loss = 0.92411993, grad/param norm = 2.5837e-01, time/batch = 17.3261s	
15638/22950 (epoch 34.070), train_loss = 0.78462248, grad/param norm = 1.9001e-01, time/batch = 16.0498s	
15639/22950 (epoch 34.072), train_loss = 0.93282784, grad/param norm = 2.6738e-01, time/batch = 16.3506s	
15640/22950 (epoch 34.074), train_loss = 0.91878358, grad/param norm = 2.5516e-01, time/batch = 16.2877s	
15641/22950 (epoch 34.076), train_loss = 0.91228333, grad/param norm = 2.5061e-01, time/batch = 16.5941s	
15642/22950 (epoch 34.078), train_loss = 0.97515435, grad/param norm = 2.4526e-01, time/batch = 16.0386s	
15643/22950 (epoch 34.081), train_loss = 0.98966949, grad/param norm = 2.5689e-01, time/batch = 15.8949s	
15644/22950 (epoch 34.083), train_loss = 0.90033744, grad/param norm = 2.2939e-01, time/batch = 16.1210s	
15645/22950 (epoch 34.085), train_loss = 0.77292196, grad/param norm = 2.5723e-01, time/batch = 16.3605s	
15646/22950 (epoch 34.087), train_loss = 0.80529053, grad/param norm = 2.5254e-01, time/batch = 15.8019s	
15647/22950 (epoch 34.089), train_loss = 0.93187848, grad/param norm = 2.6595e-01, time/batch = 15.9635s	
15648/22950 (epoch 34.092), train_loss = 0.82814029, grad/param norm = 2.9327e-01, time/batch = 16.3634s	
15649/22950 (epoch 34.094), train_loss = 0.82459351, grad/param norm = 2.4527e-01, time/batch = 15.8870s	
15650/22950 (epoch 34.096), train_loss = 0.99167693, grad/param norm = 2.8656e-01, time/batch = 15.8129s	
15651/22950 (epoch 34.098), train_loss = 0.93201813, grad/param norm = 2.6241e-01, time/batch = 15.9830s	
15652/22950 (epoch 34.100), train_loss = 0.85496889, grad/param norm = 2.5054e-01, time/batch = 16.4440s	
15653/22950 (epoch 34.102), train_loss = 0.90392230, grad/param norm = 3.3776e-01, time/batch = 15.8768s	
15654/22950 (epoch 34.105), train_loss = 0.72687148, grad/param norm = 2.1904e-01, time/batch = 15.9687s	
15655/22950 (epoch 34.107), train_loss = 0.81141268, grad/param norm = 2.4606e-01, time/batch = 16.1295s	
15656/22950 (epoch 34.109), train_loss = 0.84741273, grad/param norm = 2.4449e-01, time/batch = 16.6774s	
15657/22950 (epoch 34.111), train_loss = 0.75936279, grad/param norm = 2.6023e-01, time/batch = 16.4319s	
15658/22950 (epoch 34.113), train_loss = 0.91100426, grad/param norm = 2.7713e-01, time/batch = 16.4374s	
15659/22950 (epoch 34.115), train_loss = 0.87937068, grad/param norm = 2.3225e-01, time/batch = 16.3650s	
15660/22950 (epoch 34.118), train_loss = 0.98523405, grad/param norm = 2.3615e-01, time/batch = 16.1360s	
15661/22950 (epoch 34.120), train_loss = 0.78711461, grad/param norm = 2.4284e-01, time/batch = 15.8956s	
15662/22950 (epoch 34.122), train_loss = 0.94629413, grad/param norm = 2.3928e-01, time/batch = 15.8101s	
15663/22950 (epoch 34.124), train_loss = 0.77312228, grad/param norm = 2.0743e-01, time/batch = 16.4253s	
15664/22950 (epoch 34.126), train_loss = 0.88552820, grad/param norm = 2.3727e-01, time/batch = 16.4776s	
15665/22950 (epoch 34.129), train_loss = 0.81682638, grad/param norm = 2.0977e-01, time/batch = 16.1248s	
15666/22950 (epoch 34.131), train_loss = 0.83960958, grad/param norm = 2.1470e-01, time/batch = 16.5163s	
15667/22950 (epoch 34.133), train_loss = 0.92037361, grad/param norm = 2.4155e-01, time/batch = 16.4051s	
15668/22950 (epoch 34.135), train_loss = 0.87891060, grad/param norm = 2.1239e-01, time/batch = 15.8883s	
15669/22950 (epoch 34.137), train_loss = 0.95564306, grad/param norm = 3.3186e-01, time/batch = 16.0441s	
15670/22950 (epoch 34.139), train_loss = 0.80763411, grad/param norm = 2.7691e-01, time/batch = 16.1760s	
15671/22950 (epoch 34.142), train_loss = 0.77367928, grad/param norm = 2.0987e-01, time/batch = 16.2077s	
15672/22950 (epoch 34.144), train_loss = 0.84316647, grad/param norm = 2.2927e-01, time/batch = 16.0375s	
15673/22950 (epoch 34.146), train_loss = 0.80180143, grad/param norm = 2.6543e-01, time/batch = 15.7263s	
15674/22950 (epoch 34.148), train_loss = 0.80981245, grad/param norm = 2.6230e-01, time/batch = 16.7450s	
15675/22950 (epoch 34.150), train_loss = 0.88277677, grad/param norm = 2.1804e-01, time/batch = 15.7264s	
15676/22950 (epoch 34.153), train_loss = 0.79270326, grad/param norm = 2.0297e-01, time/batch = 16.3429s	
15677/22950 (epoch 34.155), train_loss = 0.81234778, grad/param norm = 2.2978e-01, time/batch = 15.9614s	
15678/22950 (epoch 34.157), train_loss = 0.86267177, grad/param norm = 2.4129e-01, time/batch = 15.7121s	
15679/22950 (epoch 34.159), train_loss = 0.78676347, grad/param norm = 2.1830e-01, time/batch = 15.8022s	
15680/22950 (epoch 34.161), train_loss = 0.82971726, grad/param norm = 2.1262e-01, time/batch = 15.9768s	
15681/22950 (epoch 34.163), train_loss = 0.78296079, grad/param norm = 2.6376e-01, time/batch = 16.1328s	
15682/22950 (epoch 34.166), train_loss = 0.93661276, grad/param norm = 3.2395e-01, time/batch = 16.3696s	
15683/22950 (epoch 34.168), train_loss = 0.89298188, grad/param norm = 2.4445e-01, time/batch = 16.0578s	
15684/22950 (epoch 34.170), train_loss = 0.86760339, grad/param norm = 2.4915e-01, time/batch = 15.8959s	
15685/22950 (epoch 34.172), train_loss = 0.88736462, grad/param norm = 2.4597e-01, time/batch = 16.3694s	
15686/22950 (epoch 34.174), train_loss = 0.94815995, grad/param norm = 2.7458e-01, time/batch = 16.1321s	
15687/22950 (epoch 34.176), train_loss = 0.95573801, grad/param norm = 2.8503e-01, time/batch = 16.5880s	
15688/22950 (epoch 34.179), train_loss = 0.93228550, grad/param norm = 2.8472e-01, time/batch = 16.9285s	
15689/22950 (epoch 34.181), train_loss = 1.11945976, grad/param norm = 2.8942e-01, time/batch = 16.5110s	
15690/22950 (epoch 34.183), train_loss = 0.92864111, grad/param norm = 2.5092e-01, time/batch = 16.1268s	
15691/22950 (epoch 34.185), train_loss = 0.92456867, grad/param norm = 2.3858e-01, time/batch = 16.7928s	
15692/22950 (epoch 34.187), train_loss = 0.80839422, grad/param norm = 2.3579e-01, time/batch = 16.3550s	
15693/22950 (epoch 34.190), train_loss = 0.72365677, grad/param norm = 2.5420e-01, time/batch = 16.2760s	
15694/22950 (epoch 34.192), train_loss = 0.69055959, grad/param norm = 2.1595e-01, time/batch = 16.2760s	
15695/22950 (epoch 34.194), train_loss = 0.84537096, grad/param norm = 2.4915e-01, time/batch = 15.9002s	
15696/22950 (epoch 34.196), train_loss = 0.65342131, grad/param norm = 2.1568e-01, time/batch = 16.5220s	
15697/22950 (epoch 34.198), train_loss = 0.89651672, grad/param norm = 2.5212e-01, time/batch = 15.7972s	
15698/22950 (epoch 34.200), train_loss = 0.80605375, grad/param norm = 2.2610e-01, time/batch = 15.7258s	
15699/22950 (epoch 34.203), train_loss = 0.74990963, grad/param norm = 2.3693e-01, time/batch = 15.6391s	
15700/22950 (epoch 34.205), train_loss = 0.81052746, grad/param norm = 2.4760e-01, time/batch = 16.5060s	
15701/22950 (epoch 34.207), train_loss = 0.89030509, grad/param norm = 2.5014e-01, time/batch = 16.4310s	
15702/22950 (epoch 34.209), train_loss = 0.84814343, grad/param norm = 2.7882e-01, time/batch = 16.3409s	
15703/22950 (epoch 34.211), train_loss = 0.73642399, grad/param norm = 2.2692e-01, time/batch = 16.1180s	
15704/22950 (epoch 34.214), train_loss = 0.79284843, grad/param norm = 2.5909e-01, time/batch = 16.2793s	
15705/22950 (epoch 34.216), train_loss = 0.94151769, grad/param norm = 2.3059e-01, time/batch = 15.9720s	
15706/22950 (epoch 34.218), train_loss = 0.84181904, grad/param norm = 2.1332e-01, time/batch = 15.9683s	
15707/22950 (epoch 34.220), train_loss = 0.92747760, grad/param norm = 3.0061e-01, time/batch = 16.3480s	
15708/22950 (epoch 34.222), train_loss = 0.95810410, grad/param norm = 2.6471e-01, time/batch = 15.8817s	
15709/22950 (epoch 34.224), train_loss = 0.86252916, grad/param norm = 2.4768e-01, time/batch = 16.0500s	
15710/22950 (epoch 34.227), train_loss = 0.91527154, grad/param norm = 2.5371e-01, time/batch = 16.1309s	
15711/22950 (epoch 34.229), train_loss = 0.96402324, grad/param norm = 2.3638e-01, time/batch = 16.9003s	
15712/22950 (epoch 34.231), train_loss = 0.72038189, grad/param norm = 2.3648e-01, time/batch = 16.7193s	
15713/22950 (epoch 34.233), train_loss = 0.81696399, grad/param norm = 2.4836e-01, time/batch = 16.7023s	
15714/22950 (epoch 34.235), train_loss = 0.98816364, grad/param norm = 2.4642e-01, time/batch = 16.7758s	
15715/22950 (epoch 34.237), train_loss = 0.81459959, grad/param norm = 2.2660e-01, time/batch = 16.5446s	
15716/22950 (epoch 34.240), train_loss = 0.84406754, grad/param norm = 2.2493e-01, time/batch = 16.4549s	
15717/22950 (epoch 34.242), train_loss = 1.01436305, grad/param norm = 2.6339e-01, time/batch = 15.7178s	
15718/22950 (epoch 34.244), train_loss = 0.98153877, grad/param norm = 2.7189e-01, time/batch = 16.1862s	
15719/22950 (epoch 34.246), train_loss = 0.97075523, grad/param norm = 2.5031e-01, time/batch = 15.8903s	
15720/22950 (epoch 34.248), train_loss = 0.88723757, grad/param norm = 2.5196e-01, time/batch = 16.0466s	
15721/22950 (epoch 34.251), train_loss = 0.81681778, grad/param norm = 2.4454e-01, time/batch = 16.7227s	
15722/22950 (epoch 34.253), train_loss = 0.80557143, grad/param norm = 2.4949e-01, time/batch = 16.4634s	
15723/22950 (epoch 34.255), train_loss = 0.91289094, grad/param norm = 2.6126e-01, time/batch = 16.2932s	
15724/22950 (epoch 34.257), train_loss = 0.95577325, grad/param norm = 2.7484e-01, time/batch = 16.0334s	
15725/22950 (epoch 34.259), train_loss = 0.75077732, grad/param norm = 2.3607e-01, time/batch = 16.4364s	
15726/22950 (epoch 34.261), train_loss = 0.80710277, grad/param norm = 2.5678e-01, time/batch = 16.5184s	
15727/22950 (epoch 34.264), train_loss = 0.76720993, grad/param norm = 2.3102e-01, time/batch = 16.1299s	
15728/22950 (epoch 34.266), train_loss = 0.84191918, grad/param norm = 2.6323e-01, time/batch = 16.2936s	
15729/22950 (epoch 34.268), train_loss = 0.85601588, grad/param norm = 2.6784e-01, time/batch = 16.4363s	
15730/22950 (epoch 34.270), train_loss = 0.84970491, grad/param norm = 2.3192e-01, time/batch = 16.5405s	
15731/22950 (epoch 34.272), train_loss = 0.88215477, grad/param norm = 2.5195e-01, time/batch = 16.6578s	
15732/22950 (epoch 34.275), train_loss = 0.80440927, grad/param norm = 2.4491e-01, time/batch = 16.2890s	
15733/22950 (epoch 34.277), train_loss = 0.73159310, grad/param norm = 2.2533e-01, time/batch = 16.8080s	
15734/22950 (epoch 34.279), train_loss = 0.76807558, grad/param norm = 2.7166e-01, time/batch = 16.5132s	
15735/22950 (epoch 34.281), train_loss = 0.83425864, grad/param norm = 2.4586e-01, time/batch = 15.8978s	
15736/22950 (epoch 34.283), train_loss = 0.75389070, grad/param norm = 2.0256e-01, time/batch = 16.1286s	
15737/22950 (epoch 34.285), train_loss = 0.86878691, grad/param norm = 2.3136e-01, time/batch = 15.8830s	
15738/22950 (epoch 34.288), train_loss = 0.95586450, grad/param norm = 2.4683e-01, time/batch = 19.7119s	
15739/22950 (epoch 34.290), train_loss = 0.82574303, grad/param norm = 2.3212e-01, time/batch = 19.2121s	
15740/22950 (epoch 34.292), train_loss = 0.94076471, grad/param norm = 2.4550e-01, time/batch = 18.9529s	
15741/22950 (epoch 34.294), train_loss = 0.88519061, grad/param norm = 2.2614e-01, time/batch = 18.9869s	
15742/22950 (epoch 34.296), train_loss = 0.68910165, grad/param norm = 2.0597e-01, time/batch = 18.8812s	
15743/22950 (epoch 34.298), train_loss = 0.84857961, grad/param norm = 2.2299e-01, time/batch = 16.1272s	
15744/22950 (epoch 34.301), train_loss = 0.89922608, grad/param norm = 2.5748e-01, time/batch = 19.0199s	
15745/22950 (epoch 34.303), train_loss = 0.84571243, grad/param norm = 2.3651e-01, time/batch = 18.5747s	
15746/22950 (epoch 34.305), train_loss = 0.82786504, grad/param norm = 2.2705e-01, time/batch = 18.5253s	
15747/22950 (epoch 34.307), train_loss = 0.98903868, grad/param norm = 2.6284e-01, time/batch = 16.2918s	
15748/22950 (epoch 34.309), train_loss = 0.80534858, grad/param norm = 2.0957e-01, time/batch = 16.7909s	
15749/22950 (epoch 34.312), train_loss = 0.87212450, grad/param norm = 2.5050e-01, time/batch = 16.3707s	
15750/22950 (epoch 34.314), train_loss = 0.87424568, grad/param norm = 2.1080e-01, time/batch = 16.3503s	
15751/22950 (epoch 34.316), train_loss = 0.82877086, grad/param norm = 2.5096e-01, time/batch = 16.0250s	
15752/22950 (epoch 34.318), train_loss = 0.74936518, grad/param norm = 2.0490e-01, time/batch = 15.6304s	
15753/22950 (epoch 34.320), train_loss = 0.79530191, grad/param norm = 1.9855e-01, time/batch = 15.7034s	
15754/22950 (epoch 34.322), train_loss = 0.82588757, grad/param norm = 2.4413e-01, time/batch = 15.7954s	
15755/22950 (epoch 34.325), train_loss = 0.65724549, grad/param norm = 1.9563e-01, time/batch = 15.4012s	
15756/22950 (epoch 34.327), train_loss = 0.68794332, grad/param norm = 2.2281e-01, time/batch = 15.8014s	
15757/22950 (epoch 34.329), train_loss = 0.79592838, grad/param norm = 2.2364e-01, time/batch = 16.7565s	
15758/22950 (epoch 34.331), train_loss = 0.74890387, grad/param norm = 2.2116e-01, time/batch = 16.3579s	
15759/22950 (epoch 34.333), train_loss = 0.77220532, grad/param norm = 2.2587e-01, time/batch = 15.7219s	
15760/22950 (epoch 34.336), train_loss = 0.84619713, grad/param norm = 2.7107e-01, time/batch = 15.5455s	
15761/22950 (epoch 34.338), train_loss = 0.84214124, grad/param norm = 2.1208e-01, time/batch = 16.6030s	
15762/22950 (epoch 34.340), train_loss = 0.82473395, grad/param norm = 2.6808e-01, time/batch = 15.5593s	
15763/22950 (epoch 34.342), train_loss = 0.99443874, grad/param norm = 2.4749e-01, time/batch = 15.6272s	
15764/22950 (epoch 34.344), train_loss = 0.82971882, grad/param norm = 2.3291e-01, time/batch = 15.8782s	
15765/22950 (epoch 34.346), train_loss = 0.92844823, grad/param norm = 3.1031e-01, time/batch = 16.6585s	
15766/22950 (epoch 34.349), train_loss = 0.84740012, grad/param norm = 2.3722e-01, time/batch = 16.6711s	
15767/22950 (epoch 34.351), train_loss = 0.86414664, grad/param norm = 2.4421e-01, time/batch = 16.6777s	
15768/22950 (epoch 34.353), train_loss = 0.92032827, grad/param norm = 3.4422e-01, time/batch = 15.8692s	
15769/22950 (epoch 34.355), train_loss = 0.95721040, grad/param norm = 2.8025e-01, time/batch = 16.1010s	
15770/22950 (epoch 34.357), train_loss = 0.83927498, grad/param norm = 2.5128e-01, time/batch = 16.5061s	
15771/22950 (epoch 34.359), train_loss = 0.85311740, grad/param norm = 2.5780e-01, time/batch = 15.8070s	
15772/22950 (epoch 34.362), train_loss = 0.91032593, grad/param norm = 2.6971e-01, time/batch = 16.5128s	
15773/22950 (epoch 34.364), train_loss = 0.84624751, grad/param norm = 2.4759e-01, time/batch = 15.4726s	
15774/22950 (epoch 34.366), train_loss = 0.85109667, grad/param norm = 2.2814e-01, time/batch = 15.6364s	
15775/22950 (epoch 34.368), train_loss = 0.93240144, grad/param norm = 3.2942e-01, time/batch = 15.6173s	
15776/22950 (epoch 34.370), train_loss = 0.83861554, grad/param norm = 2.7270e-01, time/batch = 15.8861s	
15777/22950 (epoch 34.373), train_loss = 0.77482083, grad/param norm = 2.1453e-01, time/batch = 15.7967s	
15778/22950 (epoch 34.375), train_loss = 0.96332957, grad/param norm = 2.7246e-01, time/batch = 15.6392s	
15779/22950 (epoch 34.377), train_loss = 0.77986363, grad/param norm = 2.6897e-01, time/batch = 15.9466s	
15780/22950 (epoch 34.379), train_loss = 0.86936676, grad/param norm = 2.5317e-01, time/batch = 16.3456s	
15781/22950 (epoch 34.381), train_loss = 0.76036200, grad/param norm = 2.5560e-01, time/batch = 15.8063s	
15782/22950 (epoch 34.383), train_loss = 0.83175505, grad/param norm = 2.7534e-01, time/batch = 15.9712s	
15783/22950 (epoch 34.386), train_loss = 0.79053746, grad/param norm = 2.4193e-01, time/batch = 16.1239s	
15784/22950 (epoch 34.388), train_loss = 0.91163609, grad/param norm = 2.4162e-01, time/batch = 16.0420s	
15785/22950 (epoch 34.390), train_loss = 0.78014440, grad/param norm = 2.5653e-01, time/batch = 16.1934s	
15786/22950 (epoch 34.392), train_loss = 0.80989093, grad/param norm = 2.5718e-01, time/batch = 15.7943s	
15787/22950 (epoch 34.394), train_loss = 0.81701913, grad/param norm = 2.1988e-01, time/batch = 16.3483s	
15788/22950 (epoch 34.397), train_loss = 0.96318688, grad/param norm = 2.3007e-01, time/batch = 16.4299s	
15789/22950 (epoch 34.399), train_loss = 0.95925229, grad/param norm = 2.6661e-01, time/batch = 15.7136s	
15790/22950 (epoch 34.401), train_loss = 1.00744798, grad/param norm = 2.9850e-01, time/batch = 16.6583s	
15791/22950 (epoch 34.403), train_loss = 0.83575012, grad/param norm = 2.4265e-01, time/batch = 16.2138s	
15792/22950 (epoch 34.405), train_loss = 0.98042498, grad/param norm = 3.1790e-01, time/batch = 15.6473s	
15793/22950 (epoch 34.407), train_loss = 1.03883434, grad/param norm = 2.6181e-01, time/batch = 15.6421s	
15794/22950 (epoch 34.410), train_loss = 0.83781476, grad/param norm = 2.2241e-01, time/batch = 16.3494s	
15795/22950 (epoch 34.412), train_loss = 0.85175321, grad/param norm = 2.8019e-01, time/batch = 16.4095s	
15796/22950 (epoch 34.414), train_loss = 0.97285582, grad/param norm = 2.6437e-01, time/batch = 16.5326s	
15797/22950 (epoch 34.416), train_loss = 0.89358983, grad/param norm = 3.9345e-01, time/batch = 15.7251s	
15798/22950 (epoch 34.418), train_loss = 0.87236862, grad/param norm = 2.8271e-01, time/batch = 16.5241s	
15799/22950 (epoch 34.420), train_loss = 0.93866326, grad/param norm = 3.5539e-01, time/batch = 16.1957s	
15800/22950 (epoch 34.423), train_loss = 0.85099078, grad/param norm = 2.6138e-01, time/batch = 15.6403s	
15801/22950 (epoch 34.425), train_loss = 0.87935704, grad/param norm = 2.8719e-01, time/batch = 16.2907s	
15802/22950 (epoch 34.427), train_loss = 0.88951971, grad/param norm = 2.7413e-01, time/batch = 16.0575s	
15803/22950 (epoch 34.429), train_loss = 0.86908768, grad/param norm = 2.3456e-01, time/batch = 15.8077s	
15804/22950 (epoch 34.431), train_loss = 0.95396463, grad/param norm = 2.7081e-01, time/batch = 16.1173s	
15805/22950 (epoch 34.434), train_loss = 0.88866661, grad/param norm = 2.5639e-01, time/batch = 16.0356s	
15806/22950 (epoch 34.436), train_loss = 0.96178298, grad/param norm = 2.7400e-01, time/batch = 16.2778s	
15807/22950 (epoch 34.438), train_loss = 0.88037206, grad/param norm = 2.4764e-01, time/batch = 15.7890s	
15808/22950 (epoch 34.440), train_loss = 0.95140819, grad/param norm = 2.4007e-01, time/batch = 15.6329s	
15809/22950 (epoch 34.442), train_loss = 0.99248797, grad/param norm = 2.5987e-01, time/batch = 15.9556s	
15810/22950 (epoch 34.444), train_loss = 0.94553723, grad/param norm = 2.8666e-01, time/batch = 15.4757s	
15811/22950 (epoch 34.447), train_loss = 1.01762494, grad/param norm = 2.7352e-01, time/batch = 16.0176s	
15812/22950 (epoch 34.449), train_loss = 0.79057649, grad/param norm = 2.3642e-01, time/batch = 15.4841s	
15813/22950 (epoch 34.451), train_loss = 0.87863794, grad/param norm = 2.5734e-01, time/batch = 16.1779s	
15814/22950 (epoch 34.453), train_loss = 0.91967124, grad/param norm = 2.3765e-01, time/batch = 16.0639s	
15815/22950 (epoch 34.455), train_loss = 0.83771698, grad/param norm = 2.1070e-01, time/batch = 16.0447s	
15816/22950 (epoch 34.458), train_loss = 0.88559611, grad/param norm = 2.4696e-01, time/batch = 16.3251s	
15817/22950 (epoch 34.460), train_loss = 0.93618186, grad/param norm = 2.6146e-01, time/batch = 16.1794s	
15818/22950 (epoch 34.462), train_loss = 0.90867047, grad/param norm = 2.6678e-01, time/batch = 15.3942s	
15819/22950 (epoch 34.464), train_loss = 0.85165422, grad/param norm = 2.5148e-01, time/batch = 16.2617s	
15820/22950 (epoch 34.466), train_loss = 0.95900629, grad/param norm = 2.5744e-01, time/batch = 16.5678s	
15821/22950 (epoch 34.468), train_loss = 0.94843317, grad/param norm = 2.6051e-01, time/batch = 16.8477s	
15822/22950 (epoch 34.471), train_loss = 0.91528929, grad/param norm = 2.6868e-01, time/batch = 16.3536s	
15823/22950 (epoch 34.473), train_loss = 0.91782741, grad/param norm = 2.4321e-01, time/batch = 15.4778s	
15824/22950 (epoch 34.475), train_loss = 1.05744765, grad/param norm = 2.6946e-01, time/batch = 15.9552s	
15825/22950 (epoch 34.477), train_loss = 0.84595069, grad/param norm = 2.6837e-01, time/batch = 15.6390s	
15826/22950 (epoch 34.479), train_loss = 0.77682418, grad/param norm = 2.6960e-01, time/batch = 15.7980s	
15827/22950 (epoch 34.481), train_loss = 0.95836043, grad/param norm = 2.7818e-01, time/batch = 15.7356s	
15828/22950 (epoch 34.484), train_loss = 0.91643855, grad/param norm = 3.2405e-01, time/batch = 16.1951s	
15829/22950 (epoch 34.486), train_loss = 0.77362196, grad/param norm = 2.4925e-01, time/batch = 15.6300s	
15830/22950 (epoch 34.488), train_loss = 0.82719149, grad/param norm = 2.9865e-01, time/batch = 15.8761s	
15831/22950 (epoch 34.490), train_loss = 0.76329859, grad/param norm = 2.4109e-01, time/batch = 16.1013s	
15832/22950 (epoch 34.492), train_loss = 0.83830774, grad/param norm = 2.5256e-01, time/batch = 16.5003s	
15833/22950 (epoch 34.495), train_loss = 0.79281071, grad/param norm = 2.2254e-01, time/batch = 15.7122s	
15834/22950 (epoch 34.497), train_loss = 0.91238576, grad/param norm = 2.5373e-01, time/batch = 16.4669s	
15835/22950 (epoch 34.499), train_loss = 1.00698485, grad/param norm = 2.5545e-01, time/batch = 16.6003s	
15836/22950 (epoch 34.501), train_loss = 0.88763025, grad/param norm = 2.5468e-01, time/batch = 16.2798s	
15837/22950 (epoch 34.503), train_loss = 0.98006743, grad/param norm = 2.6581e-01, time/batch = 16.7670s	
15838/22950 (epoch 34.505), train_loss = 0.74281906, grad/param norm = 2.1906e-01, time/batch = 16.0461s	
15839/22950 (epoch 34.508), train_loss = 0.92602368, grad/param norm = 2.4676e-01, time/batch = 16.5220s	
15840/22950 (epoch 34.510), train_loss = 0.84407566, grad/param norm = 2.5716e-01, time/batch = 16.6158s	
15841/22950 (epoch 34.512), train_loss = 0.75813653, grad/param norm = 2.4379e-01, time/batch = 16.9915s	
15842/22950 (epoch 34.514), train_loss = 0.82868260, grad/param norm = 2.1050e-01, time/batch = 16.5783s	
15843/22950 (epoch 34.516), train_loss = 0.88816110, grad/param norm = 2.5097e-01, time/batch = 16.7467s	
15844/22950 (epoch 34.519), train_loss = 0.86679299, grad/param norm = 2.3432e-01, time/batch = 16.1123s	
15845/22950 (epoch 34.521), train_loss = 0.87499233, grad/param norm = 2.3816e-01, time/batch = 16.2741s	
15846/22950 (epoch 34.523), train_loss = 0.70663947, grad/param norm = 2.2642e-01, time/batch = 16.8084s	
15847/22950 (epoch 34.525), train_loss = 0.79169722, grad/param norm = 2.5111e-01, time/batch = 16.3788s	
15848/22950 (epoch 34.527), train_loss = 0.76090189, grad/param norm = 2.1818e-01, time/batch = 16.0425s	
15849/22950 (epoch 34.529), train_loss = 0.87460984, grad/param norm = 2.2661e-01, time/batch = 15.7184s	
15850/22950 (epoch 34.532), train_loss = 0.83344162, grad/param norm = 2.1304e-01, time/batch = 16.5383s	
15851/22950 (epoch 34.534), train_loss = 0.87792415, grad/param norm = 2.2618e-01, time/batch = 15.8953s	
15852/22950 (epoch 34.536), train_loss = 0.92389973, grad/param norm = 3.2340e-01, time/batch = 16.8006s	
15853/22950 (epoch 34.538), train_loss = 0.89260963, grad/param norm = 2.5982e-01, time/batch = 24.5630s	
15854/22950 (epoch 34.540), train_loss = 0.91113775, grad/param norm = 2.6597e-01, time/batch = 24.0502s	
15855/22950 (epoch 34.542), train_loss = 1.01947411, grad/param norm = 2.8057e-01, time/batch = 18.5536s	
15856/22950 (epoch 34.545), train_loss = 0.84048809, grad/param norm = 2.1858e-01, time/batch = 19.3503s	
15857/22950 (epoch 34.547), train_loss = 0.84709929, grad/param norm = 2.2950e-01, time/batch = 18.7757s	
15858/22950 (epoch 34.549), train_loss = 0.80642004, grad/param norm = 2.4701e-01, time/batch = 17.3634s	
15859/22950 (epoch 34.551), train_loss = 0.86639251, grad/param norm = 2.6199e-01, time/batch = 16.2074s	
15860/22950 (epoch 34.553), train_loss = 0.82793164, grad/param norm = 2.7970e-01, time/batch = 17.9896s	
15861/22950 (epoch 34.556), train_loss = 0.90826861, grad/param norm = 2.3144e-01, time/batch = 19.8867s	
15862/22950 (epoch 34.558), train_loss = 0.72619988, grad/param norm = 2.1774e-01, time/batch = 18.5412s	
15863/22950 (epoch 34.560), train_loss = 0.83514910, grad/param norm = 3.0200e-01, time/batch = 18.5342s	
15864/22950 (epoch 34.562), train_loss = 0.79149146, grad/param norm = 2.1885e-01, time/batch = 16.8711s	
15865/22950 (epoch 34.564), train_loss = 0.91428123, grad/param norm = 2.7554e-01, time/batch = 16.1747s	
15866/22950 (epoch 34.566), train_loss = 0.89350824, grad/param norm = 2.3809e-01, time/batch = 16.7244s	
15867/22950 (epoch 34.569), train_loss = 0.85213004, grad/param norm = 2.3286e-01, time/batch = 16.6817s	
15868/22950 (epoch 34.571), train_loss = 0.83093702, grad/param norm = 2.7111e-01, time/batch = 16.3536s	
15869/22950 (epoch 34.573), train_loss = 0.84547211, grad/param norm = 2.6442e-01, time/batch = 16.3719s	
15870/22950 (epoch 34.575), train_loss = 0.93359146, grad/param norm = 2.7826e-01, time/batch = 16.4204s	
15871/22950 (epoch 34.577), train_loss = 0.86779925, grad/param norm = 2.7848e-01, time/batch = 15.9725s	
15872/22950 (epoch 34.580), train_loss = 0.93557033, grad/param norm = 3.0392e-01, time/batch = 15.7923s	
15873/22950 (epoch 34.582), train_loss = 1.01716675, grad/param norm = 2.5798e-01, time/batch = 16.6066s	
15874/22950 (epoch 34.584), train_loss = 0.73298482, grad/param norm = 2.3820e-01, time/batch = 16.6948s	
15875/22950 (epoch 34.586), train_loss = 0.81263668, grad/param norm = 2.5803e-01, time/batch = 16.4398s	
15876/22950 (epoch 34.588), train_loss = 0.97596133, grad/param norm = 2.6216e-01, time/batch = 19.1113s	
15877/22950 (epoch 34.590), train_loss = 0.90598108, grad/param norm = 2.5037e-01, time/batch = 19.0174s	
15878/22950 (epoch 34.593), train_loss = 0.83413789, grad/param norm = 2.2967e-01, time/batch = 16.2982s	
15879/22950 (epoch 34.595), train_loss = 0.78172513, grad/param norm = 2.5760e-01, time/batch = 19.1017s	
15880/22950 (epoch 34.597), train_loss = 0.93092978, grad/param norm = 2.6921e-01, time/batch = 18.7724s	
15881/22950 (epoch 34.599), train_loss = 0.87807598, grad/param norm = 2.8198e-01, time/batch = 19.9489s	
15882/22950 (epoch 34.601), train_loss = 0.90749603, grad/param norm = 2.5306e-01, time/batch = 20.2681s	
15883/22950 (epoch 34.603), train_loss = 0.98939605, grad/param norm = 2.5564e-01, time/batch = 18.8478s	
15884/22950 (epoch 34.606), train_loss = 0.85710519, grad/param norm = 2.3553e-01, time/batch = 18.8598s	
15885/22950 (epoch 34.608), train_loss = 0.85941610, grad/param norm = 2.5078e-01, time/batch = 19.6905s	
15886/22950 (epoch 34.610), train_loss = 0.86408226, grad/param norm = 2.3974e-01, time/batch = 18.6918s	
15887/22950 (epoch 34.612), train_loss = 0.87415239, grad/param norm = 2.5740e-01, time/batch = 17.8739s	
15888/22950 (epoch 34.614), train_loss = 0.97722579, grad/param norm = 2.9144e-01, time/batch = 18.3745s	
15889/22950 (epoch 34.617), train_loss = 0.86993944, grad/param norm = 2.3841e-01, time/batch = 16.2136s	
15890/22950 (epoch 34.619), train_loss = 0.81087256, grad/param norm = 2.1403e-01, time/batch = 16.3272s	
15891/22950 (epoch 34.621), train_loss = 0.93107385, grad/param norm = 2.1836e-01, time/batch = 18.5240s	
15892/22950 (epoch 34.623), train_loss = 0.92285853, grad/param norm = 2.3850e-01, time/batch = 18.3009s	
15893/22950 (epoch 34.625), train_loss = 0.84577374, grad/param norm = 2.3668e-01, time/batch = 18.7685s	
15894/22950 (epoch 34.627), train_loss = 0.84912919, grad/param norm = 2.6339e-01, time/batch = 19.8725s	
15895/22950 (epoch 34.630), train_loss = 0.75198981, grad/param norm = 2.0960e-01, time/batch = 18.8540s	
15896/22950 (epoch 34.632), train_loss = 0.82665063, grad/param norm = 3.2084e-01, time/batch = 19.2663s	
15897/22950 (epoch 34.634), train_loss = 0.88989859, grad/param norm = 2.3468e-01, time/batch = 18.0997s	
15898/22950 (epoch 34.636), train_loss = 0.86726146, grad/param norm = 2.3698e-01, time/batch = 19.4382s	
15899/22950 (epoch 34.638), train_loss = 0.85124895, grad/param norm = 3.2177e-01, time/batch = 17.5207s	
15900/22950 (epoch 34.641), train_loss = 0.83264950, grad/param norm = 2.3278e-01, time/batch = 18.1240s	
15901/22950 (epoch 34.643), train_loss = 0.89582278, grad/param norm = 2.7290e-01, time/batch = 21.1124s	
15902/22950 (epoch 34.645), train_loss = 0.84309283, grad/param norm = 2.7050e-01, time/batch = 16.1838s	
15903/22950 (epoch 34.647), train_loss = 0.84332621, grad/param norm = 2.6282e-01, time/batch = 17.9245s	
15904/22950 (epoch 34.649), train_loss = 0.80094183, grad/param norm = 2.3423e-01, time/batch = 19.5284s	
15905/22950 (epoch 34.651), train_loss = 0.95351723, grad/param norm = 2.6202e-01, time/batch = 17.3642s	
15906/22950 (epoch 34.654), train_loss = 0.73692278, grad/param norm = 2.1021e-01, time/batch = 19.1863s	
15907/22950 (epoch 34.656), train_loss = 0.93509939, grad/param norm = 2.9483e-01, time/batch = 16.5693s	
15908/22950 (epoch 34.658), train_loss = 0.78172778, grad/param norm = 2.3195e-01, time/batch = 16.4780s	
15909/22950 (epoch 34.660), train_loss = 0.69602281, grad/param norm = 2.2048e-01, time/batch = 16.6567s	
15910/22950 (epoch 34.662), train_loss = 0.73200228, grad/param norm = 2.5693e-01, time/batch = 15.9650s	
15911/22950 (epoch 34.664), train_loss = 0.82832827, grad/param norm = 2.4961e-01, time/batch = 15.7186s	
15912/22950 (epoch 34.667), train_loss = 0.85788718, grad/param norm = 2.3663e-01, time/batch = 16.5901s	
15913/22950 (epoch 34.669), train_loss = 0.86857003, grad/param norm = 2.5149e-01, time/batch = 16.8409s	
15914/22950 (epoch 34.671), train_loss = 0.84934581, grad/param norm = 2.5977e-01, time/batch = 18.7091s	
15915/22950 (epoch 34.673), train_loss = 0.81176529, grad/param norm = 2.5737e-01, time/batch = 20.3540s	
15916/22950 (epoch 34.675), train_loss = 0.88019000, grad/param norm = 2.5225e-01, time/batch = 17.2847s	
15917/22950 (epoch 34.678), train_loss = 0.85709135, grad/param norm = 2.3554e-01, time/batch = 16.9341s	
15918/22950 (epoch 34.680), train_loss = 0.89045840, grad/param norm = 2.0551e-01, time/batch = 18.7822s	
15919/22950 (epoch 34.682), train_loss = 0.84647653, grad/param norm = 2.4780e-01, time/batch = 17.9550s	
15920/22950 (epoch 34.684), train_loss = 0.95460847, grad/param norm = 2.9580e-01, time/batch = 17.9299s	
15921/22950 (epoch 34.686), train_loss = 0.97565022, grad/param norm = 2.6180e-01, time/batch = 18.6130s	
15922/22950 (epoch 34.688), train_loss = 0.90020142, grad/param norm = 2.7494e-01, time/batch = 18.4353s	
15923/22950 (epoch 34.691), train_loss = 0.86387201, grad/param norm = 2.3082e-01, time/batch = 18.5573s	
15924/22950 (epoch 34.693), train_loss = 0.81217348, grad/param norm = 2.8468e-01, time/batch = 16.7151s	
15925/22950 (epoch 34.695), train_loss = 0.98279706, grad/param norm = 3.4776e-01, time/batch = 19.4534s	
15926/22950 (epoch 34.697), train_loss = 0.93117287, grad/param norm = 3.3370e-01, time/batch = 16.3768s	
15927/22950 (epoch 34.699), train_loss = 0.91849385, grad/param norm = 2.7428e-01, time/batch = 17.3499s	
15928/22950 (epoch 34.702), train_loss = 0.95077424, grad/param norm = 2.9737e-01, time/batch = 16.8143s	
15929/22950 (epoch 34.704), train_loss = 1.02888955, grad/param norm = 2.8436e-01, time/batch = 16.3547s	
15930/22950 (epoch 34.706), train_loss = 0.96197611, grad/param norm = 2.6295e-01, time/batch = 16.1322s	
15931/22950 (epoch 34.708), train_loss = 0.76768299, grad/param norm = 2.5333e-01, time/batch = 16.5303s	
15932/22950 (epoch 34.710), train_loss = 0.89283356, grad/param norm = 2.6307e-01, time/batch = 16.8419s	
15933/22950 (epoch 34.712), train_loss = 0.99126064, grad/param norm = 3.1380e-01, time/batch = 18.4387s	
15934/22950 (epoch 34.715), train_loss = 0.89645760, grad/param norm = 2.9303e-01, time/batch = 20.1284s	
15935/22950 (epoch 34.717), train_loss = 0.92178177, grad/param norm = 2.4369e-01, time/batch = 16.0027s	
15936/22950 (epoch 34.719), train_loss = 0.83972457, grad/param norm = 2.5576e-01, time/batch = 17.2746s	
15937/22950 (epoch 34.721), train_loss = 0.93783672, grad/param norm = 2.8485e-01, time/batch = 18.7196s	
15938/22950 (epoch 34.723), train_loss = 0.87656960, grad/param norm = 2.4600e-01, time/batch = 17.7841s	
15939/22950 (epoch 34.725), train_loss = 0.92505715, grad/param norm = 2.7755e-01, time/batch = 18.4656s	
15940/22950 (epoch 34.728), train_loss = 0.85521453, grad/param norm = 2.7328e-01, time/batch = 17.8604s	
15941/22950 (epoch 34.730), train_loss = 0.88990748, grad/param norm = 2.9714e-01, time/batch = 19.0421s	
15942/22950 (epoch 34.732), train_loss = 0.96330018, grad/param norm = 3.0816e-01, time/batch = 16.5437s	
15943/22950 (epoch 34.734), train_loss = 0.87752743, grad/param norm = 2.8144e-01, time/batch = 16.8391s	
15944/22950 (epoch 34.736), train_loss = 0.91863851, grad/param norm = 2.4940e-01, time/batch = 20.5331s	
15945/22950 (epoch 34.739), train_loss = 0.94744930, grad/param norm = 2.8267e-01, time/batch = 19.7127s	
15946/22950 (epoch 34.741), train_loss = 0.94227493, grad/param norm = 2.6813e-01, time/batch = 18.3674s	
15947/22950 (epoch 34.743), train_loss = 1.02630608, grad/param norm = 3.1340e-01, time/batch = 17.0369s	
15948/22950 (epoch 34.745), train_loss = 1.10971816, grad/param norm = 3.1086e-01, time/batch = 18.0240s	
15949/22950 (epoch 34.747), train_loss = 0.92007443, grad/param norm = 2.8102e-01, time/batch = 17.7949s	
15950/22950 (epoch 34.749), train_loss = 0.82517490, grad/param norm = 2.3318e-01, time/batch = 20.0472s	
15951/22950 (epoch 34.752), train_loss = 1.06001043, grad/param norm = 2.9287e-01, time/batch = 19.7079s	
15952/22950 (epoch 34.754), train_loss = 0.92621607, grad/param norm = 2.5867e-01, time/batch = 18.6116s	
15953/22950 (epoch 34.756), train_loss = 0.84492519, grad/param norm = 2.6689e-01, time/batch = 18.2185s	
15954/22950 (epoch 34.758), train_loss = 0.90392362, grad/param norm = 2.4634e-01, time/batch = 19.2121s	
15955/22950 (epoch 34.760), train_loss = 0.88914778, grad/param norm = 2.4659e-01, time/batch = 17.9531s	
15956/22950 (epoch 34.763), train_loss = 0.91837473, grad/param norm = 2.5763e-01, time/batch = 17.0139s	
15957/22950 (epoch 34.765), train_loss = 0.87364440, grad/param norm = 2.6226e-01, time/batch = 18.5513s	
15958/22950 (epoch 34.767), train_loss = 1.09765494, grad/param norm = 3.2285e-01, time/batch = 16.0126s	
15959/22950 (epoch 34.769), train_loss = 0.93550166, grad/param norm = 2.7243e-01, time/batch = 17.3674s	
15960/22950 (epoch 34.771), train_loss = 0.78625664, grad/param norm = 2.5148e-01, time/batch = 16.8470s	
15961/22950 (epoch 34.773), train_loss = 0.69021442, grad/param norm = 2.2898e-01, time/batch = 16.4404s	
15962/22950 (epoch 34.776), train_loss = 0.80276076, grad/param norm = 2.1296e-01, time/batch = 18.8637s	
15963/22950 (epoch 34.778), train_loss = 0.80744563, grad/param norm = 2.5887e-01, time/batch = 18.3771s	
15964/22950 (epoch 34.780), train_loss = 0.89894941, grad/param norm = 2.3844e-01, time/batch = 18.3553s	
15965/22950 (epoch 34.782), train_loss = 0.95506131, grad/param norm = 2.6429e-01, time/batch = 16.0755s	
15966/22950 (epoch 34.784), train_loss = 0.82013660, grad/param norm = 2.4994e-01, time/batch = 16.4898s	
15967/22950 (epoch 34.786), train_loss = 0.88449673, grad/param norm = 2.7475e-01, time/batch = 15.7839s	
15968/22950 (epoch 34.789), train_loss = 0.72502802, grad/param norm = 2.1783e-01, time/batch = 17.6144s	
15969/22950 (epoch 34.791), train_loss = 0.77562142, grad/param norm = 2.4705e-01, time/batch = 17.9453s	
15970/22950 (epoch 34.793), train_loss = 0.95116550, grad/param norm = 2.3621e-01, time/batch = 19.9421s	
15971/22950 (epoch 34.795), train_loss = 0.85385691, grad/param norm = 2.3792e-01, time/batch = 18.2767s	
15972/22950 (epoch 34.797), train_loss = 0.98030259, grad/param norm = 2.4252e-01, time/batch = 19.1307s	
15973/22950 (epoch 34.800), train_loss = 0.80507524, grad/param norm = 2.1632e-01, time/batch = 19.3796s	
15974/22950 (epoch 34.802), train_loss = 0.84788633, grad/param norm = 2.7404e-01, time/batch = 18.5364s	
15975/22950 (epoch 34.804), train_loss = 0.83662912, grad/param norm = 2.2574e-01, time/batch = 20.0319s	
15976/22950 (epoch 34.806), train_loss = 0.74463740, grad/param norm = 2.3171e-01, time/batch = 19.4439s	
15977/22950 (epoch 34.808), train_loss = 0.87823998, grad/param norm = 2.3081e-01, time/batch = 16.6741s	
15978/22950 (epoch 34.810), train_loss = 0.85058834, grad/param norm = 2.4991e-01, time/batch = 19.2666s	
15979/22950 (epoch 34.813), train_loss = 0.72713989, grad/param norm = 2.2315e-01, time/batch = 18.2912s	
15980/22950 (epoch 34.815), train_loss = 0.69738838, grad/param norm = 2.3574e-01, time/batch = 20.3715s	
15981/22950 (epoch 34.817), train_loss = 0.77860873, grad/param norm = 1.9998e-01, time/batch = 19.1234s	
15982/22950 (epoch 34.819), train_loss = 0.84014358, grad/param norm = 2.3193e-01, time/batch = 16.4667s	
15983/22950 (epoch 34.821), train_loss = 0.86725548, grad/param norm = 3.0505e-01, time/batch = 19.8649s	
15984/22950 (epoch 34.824), train_loss = 0.87849793, grad/param norm = 2.3317e-01, time/batch = 17.9583s	
15985/22950 (epoch 34.826), train_loss = 0.91134796, grad/param norm = 2.8008e-01, time/batch = 18.1892s	
15986/22950 (epoch 34.828), train_loss = 0.84421148, grad/param norm = 2.5203e-01, time/batch = 19.1903s	
15987/22950 (epoch 34.830), train_loss = 0.81194515, grad/param norm = 2.2319e-01, time/batch = 16.5469s	
15988/22950 (epoch 34.832), train_loss = 0.87320719, grad/param norm = 2.5053e-01, time/batch = 18.6169s	
15989/22950 (epoch 34.834), train_loss = 0.73704436, grad/param norm = 2.5701e-01, time/batch = 19.0328s	
15990/22950 (epoch 34.837), train_loss = 0.86750762, grad/param norm = 2.4853e-01, time/batch = 17.9701s	
15991/22950 (epoch 34.839), train_loss = 0.72406354, grad/param norm = 2.1846e-01, time/batch = 19.9605s	
15992/22950 (epoch 34.841), train_loss = 0.82584642, grad/param norm = 2.2038e-01, time/batch = 17.0382s	
15993/22950 (epoch 34.843), train_loss = 0.81006955, grad/param norm = 2.4526e-01, time/batch = 19.0563s	
15994/22950 (epoch 34.845), train_loss = 0.86375129, grad/param norm = 2.7996e-01, time/batch = 18.7755s	
15995/22950 (epoch 34.847), train_loss = 0.89706406, grad/param norm = 2.7154e-01, time/batch = 18.7145s	
15996/22950 (epoch 34.850), train_loss = 0.92833697, grad/param norm = 2.4440e-01, time/batch = 18.5477s	
15997/22950 (epoch 34.852), train_loss = 0.91844225, grad/param norm = 2.6327e-01, time/batch = 16.9158s	
15998/22950 (epoch 34.854), train_loss = 0.87218748, grad/param norm = 2.5916e-01, time/batch = 18.5960s	
15999/22950 (epoch 34.856), train_loss = 0.97298000, grad/param norm = 2.9655e-01, time/batch = 18.3791s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch34.86_1.9980.t7	
16000/22950 (epoch 34.858), train_loss = 0.93499876, grad/param norm = 2.5434e-01, time/batch = 19.2124s	
16001/22950 (epoch 34.861), train_loss = 1.45014794, grad/param norm = 3.6778e-01, time/batch = 17.8712s	
16002/22950 (epoch 34.863), train_loss = 0.96575678, grad/param norm = 2.8373e-01, time/batch = 17.1281s	
16003/22950 (epoch 34.865), train_loss = 0.99070962, grad/param norm = 2.7974e-01, time/batch = 16.2077s	
16004/22950 (epoch 34.867), train_loss = 0.87910013, grad/param norm = 2.5206e-01, time/batch = 18.1206s	
16005/22950 (epoch 34.869), train_loss = 1.03974444, grad/param norm = 3.0195e-01, time/batch = 17.6684s	
16006/22950 (epoch 34.871), train_loss = 0.90347576, grad/param norm = 2.6609e-01, time/batch = 18.0960s	
16007/22950 (epoch 34.874), train_loss = 0.92339665, grad/param norm = 2.3427e-01, time/batch = 20.2877s	
16008/22950 (epoch 34.876), train_loss = 0.98089237, grad/param norm = 3.0744e-01, time/batch = 18.7898s	
16009/22950 (epoch 34.878), train_loss = 0.89555221, grad/param norm = 2.8329e-01, time/batch = 17.1901s	
16010/22950 (epoch 34.880), train_loss = 1.06296171, grad/param norm = 2.6051e-01, time/batch = 20.6141s	
16011/22950 (epoch 34.882), train_loss = 0.76911326, grad/param norm = 2.2544e-01, time/batch = 20.2116s	
16012/22950 (epoch 34.885), train_loss = 0.91960438, grad/param norm = 2.7917e-01, time/batch = 17.1039s	
16013/22950 (epoch 34.887), train_loss = 0.85963218, grad/param norm = 2.1862e-01, time/batch = 19.0386s	
16014/22950 (epoch 34.889), train_loss = 0.91179929, grad/param norm = 2.5892e-01, time/batch = 16.2387s	
16015/22950 (epoch 34.891), train_loss = 0.83007148, grad/param norm = 2.5383e-01, time/batch = 18.0008s	
16016/22950 (epoch 34.893), train_loss = 0.92466093, grad/param norm = 2.4240e-01, time/batch = 17.8216s	
16017/22950 (epoch 34.895), train_loss = 1.03065067, grad/param norm = 2.5690e-01, time/batch = 18.6238s	
16018/22950 (epoch 34.898), train_loss = 0.93695774, grad/param norm = 2.4902e-01, time/batch = 19.4437s	
16019/22950 (epoch 34.900), train_loss = 0.84229050, grad/param norm = 2.3610e-01, time/batch = 16.7921s	
16020/22950 (epoch 34.902), train_loss = 0.89862118, grad/param norm = 2.5276e-01, time/batch = 16.4717s	
16021/22950 (epoch 34.904), train_loss = 0.89186259, grad/param norm = 2.4353e-01, time/batch = 16.7580s	
16022/22950 (epoch 34.906), train_loss = 0.91690250, grad/param norm = 2.6979e-01, time/batch = 16.8902s	
16023/22950 (epoch 34.908), train_loss = 0.77716825, grad/param norm = 2.2809e-01, time/batch = 17.7190s	
16024/22950 (epoch 34.911), train_loss = 0.73692095, grad/param norm = 2.1173e-01, time/batch = 19.2793s	
16025/22950 (epoch 34.913), train_loss = 0.86641486, grad/param norm = 2.2555e-01, time/batch = 17.9653s	
16026/22950 (epoch 34.915), train_loss = 0.99705744, grad/param norm = 2.5606e-01, time/batch = 17.5369s	
16027/22950 (epoch 34.917), train_loss = 0.78685399, grad/param norm = 2.6134e-01, time/batch = 20.4694s	
16028/22950 (epoch 34.919), train_loss = 0.89197062, grad/param norm = 2.5216e-01, time/batch = 18.8014s	
16029/22950 (epoch 34.922), train_loss = 0.87743530, grad/param norm = 2.5475e-01, time/batch = 19.9200s	
16030/22950 (epoch 34.924), train_loss = 0.92206835, grad/param norm = 2.6809e-01, time/batch = 18.2919s	
16031/22950 (epoch 34.926), train_loss = 0.72563008, grad/param norm = 2.6567e-01, time/batch = 18.7865s	
16032/22950 (epoch 34.928), train_loss = 0.79181705, grad/param norm = 2.4121e-01, time/batch = 17.8535s	
16033/22950 (epoch 34.930), train_loss = 0.78440429, grad/param norm = 2.6009e-01, time/batch = 18.7253s	
16034/22950 (epoch 34.932), train_loss = 0.71987317, grad/param norm = 2.0659e-01, time/batch = 19.3593s	
16035/22950 (epoch 34.935), train_loss = 0.90839830, grad/param norm = 2.5673e-01, time/batch = 16.2005s	
16036/22950 (epoch 34.937), train_loss = 0.88309494, grad/param norm = 2.7838e-01, time/batch = 18.7751s	
16037/22950 (epoch 34.939), train_loss = 0.82368700, grad/param norm = 2.4704e-01, time/batch = 18.1932s	
16038/22950 (epoch 34.941), train_loss = 0.85756838, grad/param norm = 2.5795e-01, time/batch = 18.2079s	
16039/22950 (epoch 34.943), train_loss = 0.89024611, grad/param norm = 2.6845e-01, time/batch = 20.2084s	
16040/22950 (epoch 34.946), train_loss = 0.72390127, grad/param norm = 2.2517e-01, time/batch = 18.7964s	
16041/22950 (epoch 34.948), train_loss = 0.95138392, grad/param norm = 2.4644e-01, time/batch = 18.9396s	
16042/22950 (epoch 34.950), train_loss = 0.83984085, grad/param norm = 2.7399e-01, time/batch = 20.1165s	
16043/22950 (epoch 34.952), train_loss = 0.90469732, grad/param norm = 2.3250e-01, time/batch = 17.7234s	
16044/22950 (epoch 34.954), train_loss = 0.90779360, grad/param norm = 2.6519e-01, time/batch = 18.6294s	
16045/22950 (epoch 34.956), train_loss = 0.82848441, grad/param norm = 2.4442e-01, time/batch = 28.3830s	
16046/22950 (epoch 34.959), train_loss = 0.78965666, grad/param norm = 2.2187e-01, time/batch = 15.7524s	
16047/22950 (epoch 34.961), train_loss = 0.87658344, grad/param norm = 2.5107e-01, time/batch = 14.6448s	
16048/22950 (epoch 34.963), train_loss = 0.89281799, grad/param norm = 2.6807e-01, time/batch = 14.9757s	
16049/22950 (epoch 34.965), train_loss = 0.94731010, grad/param norm = 2.7854e-01, time/batch = 14.5856s	
16050/22950 (epoch 34.967), train_loss = 0.84663449, grad/param norm = 2.4521e-01, time/batch = 15.1331s	
16051/22950 (epoch 34.969), train_loss = 0.76976898, grad/param norm = 2.5209e-01, time/batch = 14.9957s	
16052/22950 (epoch 34.972), train_loss = 0.85013968, grad/param norm = 2.2248e-01, time/batch = 15.6189s	
16053/22950 (epoch 34.974), train_loss = 0.82092358, grad/param norm = 2.4493e-01, time/batch = 15.0096s	
16054/22950 (epoch 34.976), train_loss = 0.87770029, grad/param norm = 2.6313e-01, time/batch = 14.9209s	
16055/22950 (epoch 34.978), train_loss = 0.79820479, grad/param norm = 2.3551e-01, time/batch = 14.9170s	
16056/22950 (epoch 34.980), train_loss = 0.81396622, grad/param norm = 2.2830e-01, time/batch = 15.5372s	
16057/22950 (epoch 34.983), train_loss = 0.90011255, grad/param norm = 2.3646e-01, time/batch = 15.4621s	
16058/22950 (epoch 34.985), train_loss = 0.77107915, grad/param norm = 2.4414e-01, time/batch = 14.9946s	
16059/22950 (epoch 34.987), train_loss = 0.79206092, grad/param norm = 2.2756e-01, time/batch = 15.0624s	
16060/22950 (epoch 34.989), train_loss = 0.87829884, grad/param norm = 2.4809e-01, time/batch = 15.2994s	
16061/22950 (epoch 34.991), train_loss = 0.74683612, grad/param norm = 2.2176e-01, time/batch = 15.1481s	
16062/22950 (epoch 34.993), train_loss = 0.89613520, grad/param norm = 2.7205e-01, time/batch = 14.9156s	
16063/22950 (epoch 34.996), train_loss = 0.85240748, grad/param norm = 2.4421e-01, time/batch = 15.5462s	
16064/22950 (epoch 34.998), train_loss = 0.76309631, grad/param norm = 2.3384e-01, time/batch = 15.0686s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
16065/22950 (epoch 35.000), train_loss = 0.73291447, grad/param norm = 2.2366e-01, time/batch = 14.9925s	
16066/22950 (epoch 35.002), train_loss = 1.02896685, grad/param norm = 2.7002e-01, time/batch = 14.9765s	
16067/22950 (epoch 35.004), train_loss = 0.91245041, grad/param norm = 2.5105e-01, time/batch = 15.3754s	
16068/22950 (epoch 35.007), train_loss = 0.84315341, grad/param norm = 2.4867e-01, time/batch = 14.9994s	
16069/22950 (epoch 35.009), train_loss = 0.99662724, grad/param norm = 2.8787e-01, time/batch = 14.8316s	
16070/22950 (epoch 35.011), train_loss = 0.74931674, grad/param norm = 2.4853e-01, time/batch = 15.4573s	
16071/22950 (epoch 35.013), train_loss = 0.83667813, grad/param norm = 2.9897e-01, time/batch = 15.4521s	
16072/22950 (epoch 35.015), train_loss = 0.89121756, grad/param norm = 2.6204e-01, time/batch = 16.2250s	
16073/22950 (epoch 35.017), train_loss = 0.89413383, grad/param norm = 2.5835e-01, time/batch = 16.5682s	
16074/22950 (epoch 35.020), train_loss = 0.89763503, grad/param norm = 2.5837e-01, time/batch = 15.2332s	
16075/22950 (epoch 35.022), train_loss = 0.77173155, grad/param norm = 2.5037e-01, time/batch = 15.5432s	
16076/22950 (epoch 35.024), train_loss = 0.82499492, grad/param norm = 2.2212e-01, time/batch = 15.0773s	
16077/22950 (epoch 35.026), train_loss = 0.89615168, grad/param norm = 2.4460e-01, time/batch = 15.5447s	
16078/22950 (epoch 35.028), train_loss = 0.92706033, grad/param norm = 2.4215e-01, time/batch = 15.0768s	
16079/22950 (epoch 35.031), train_loss = 0.83460958, grad/param norm = 2.4186e-01, time/batch = 15.7091s	
16080/22950 (epoch 35.033), train_loss = 0.93976802, grad/param norm = 2.5079e-01, time/batch = 15.1576s	
16081/22950 (epoch 35.035), train_loss = 0.85214358, grad/param norm = 2.4200e-01, time/batch = 15.1534s	
16082/22950 (epoch 35.037), train_loss = 0.84630651, grad/param norm = 2.1569e-01, time/batch = 15.0049s	
16083/22950 (epoch 35.039), train_loss = 0.83405263, grad/param norm = 2.4704e-01, time/batch = 15.6129s	
16084/22950 (epoch 35.041), train_loss = 0.80363495, grad/param norm = 2.7390e-01, time/batch = 15.3031s	
16085/22950 (epoch 35.044), train_loss = 0.89744783, grad/param norm = 2.4823e-01, time/batch = 15.0671s	
16086/22950 (epoch 35.046), train_loss = 0.86939857, grad/param norm = 2.6992e-01, time/batch = 15.1596s	
16087/22950 (epoch 35.048), train_loss = 0.85338464, grad/param norm = 2.3935e-01, time/batch = 15.5410s	
16088/22950 (epoch 35.050), train_loss = 0.84644041, grad/param norm = 3.1596e-01, time/batch = 15.3042s	
16089/22950 (epoch 35.052), train_loss = 0.88139173, grad/param norm = 2.4322e-01, time/batch = 15.3922s	
16090/22950 (epoch 35.054), train_loss = 1.01876553, grad/param norm = 2.8488e-01, time/batch = 14.8378s	
16091/22950 (epoch 35.057), train_loss = 0.95551486, grad/param norm = 2.4165e-01, time/batch = 15.2174s	
16092/22950 (epoch 35.059), train_loss = 0.95536473, grad/param norm = 2.3794e-01, time/batch = 15.4060s	
16093/22950 (epoch 35.061), train_loss = 0.79559995, grad/param norm = 2.3588e-01, time/batch = 14.9807s	
16094/22950 (epoch 35.063), train_loss = 0.90516214, grad/param norm = 2.4376e-01, time/batch = 15.4292s	
16095/22950 (epoch 35.065), train_loss = 0.75632738, grad/param norm = 2.2760e-01, time/batch = 16.2250s	
16096/22950 (epoch 35.068), train_loss = 0.90598702, grad/param norm = 2.8359e-01, time/batch = 16.1054s	
16097/22950 (epoch 35.070), train_loss = 0.77755692, grad/param norm = 2.1425e-01, time/batch = 15.2969s	
16098/22950 (epoch 35.072), train_loss = 0.90607203, grad/param norm = 2.7769e-01, time/batch = 15.8597s	
16099/22950 (epoch 35.074), train_loss = 0.90546720, grad/param norm = 2.3985e-01, time/batch = 15.3224s	
16100/22950 (epoch 35.076), train_loss = 0.90422726, grad/param norm = 2.4241e-01, time/batch = 15.0026s	
16101/22950 (epoch 35.078), train_loss = 0.97593711, grad/param norm = 2.4996e-01, time/batch = 14.9977s	
16102/22950 (epoch 35.081), train_loss = 0.99601170, grad/param norm = 2.7954e-01, time/batch = 15.9505s	
16103/22950 (epoch 35.083), train_loss = 0.88985407, grad/param norm = 2.4905e-01, time/batch = 14.9891s	
16104/22950 (epoch 35.085), train_loss = 0.75724493, grad/param norm = 2.5935e-01, time/batch = 14.5922s	
16105/22950 (epoch 35.087), train_loss = 0.78543844, grad/param norm = 2.6924e-01, time/batch = 14.8972s	
16106/22950 (epoch 35.089), train_loss = 0.92683450, grad/param norm = 2.9029e-01, time/batch = 15.2273s	
16107/22950 (epoch 35.092), train_loss = 0.82664884, grad/param norm = 2.8997e-01, time/batch = 14.9118s	
16108/22950 (epoch 35.094), train_loss = 0.82045003, grad/param norm = 2.5016e-01, time/batch = 14.8158s	
16109/22950 (epoch 35.096), train_loss = 0.98381285, grad/param norm = 2.7501e-01, time/batch = 15.3684s	
16110/22950 (epoch 35.098), train_loss = 0.91951263, grad/param norm = 2.4982e-01, time/batch = 15.3109s	
16111/22950 (epoch 35.100), train_loss = 0.85961184, grad/param norm = 2.4229e-01, time/batch = 15.3162s	
16112/22950 (epoch 35.102), train_loss = 0.86947628, grad/param norm = 2.3966e-01, time/batch = 14.9213s	
16113/22950 (epoch 35.105), train_loss = 0.71535262, grad/param norm = 2.0495e-01, time/batch = 14.7602s	
16114/22950 (epoch 35.107), train_loss = 0.79016901, grad/param norm = 2.2473e-01, time/batch = 15.2296s	
16115/22950 (epoch 35.109), train_loss = 0.82808955, grad/param norm = 2.2658e-01, time/batch = 15.3206s	
16116/22950 (epoch 35.111), train_loss = 0.73150793, grad/param norm = 2.3031e-01, time/batch = 15.6883s	
16117/22950 (epoch 35.113), train_loss = 0.88508958, grad/param norm = 2.4600e-01, time/batch = 15.0700s	
16118/22950 (epoch 35.115), train_loss = 0.87820646, grad/param norm = 2.4781e-01, time/batch = 15.3125s	
16119/22950 (epoch 35.118), train_loss = 0.96133343, grad/param norm = 2.1512e-01, time/batch = 15.6210s	
16120/22950 (epoch 35.120), train_loss = 0.77113363, grad/param norm = 2.1697e-01, time/batch = 15.6058s	
16121/22950 (epoch 35.122), train_loss = 0.93619281, grad/param norm = 2.5742e-01, time/batch = 16.3262s	
16122/22950 (epoch 35.124), train_loss = 0.76631481, grad/param norm = 2.2762e-01, time/batch = 16.4112s	
16123/22950 (epoch 35.126), train_loss = 0.85872543, grad/param norm = 2.2595e-01, time/batch = 14.8276s	
16124/22950 (epoch 35.129), train_loss = 0.80168689, grad/param norm = 2.1588e-01, time/batch = 15.2191s	
16125/22950 (epoch 35.131), train_loss = 0.83920693, grad/param norm = 2.2729e-01, time/batch = 15.2362s	
16126/22950 (epoch 35.133), train_loss = 0.90386592, grad/param norm = 2.5883e-01, time/batch = 15.7940s	
16127/22950 (epoch 35.135), train_loss = 0.85816253, grad/param norm = 2.2006e-01, time/batch = 14.7537s	
16128/22950 (epoch 35.137), train_loss = 0.92957288, grad/param norm = 2.9000e-01, time/batch = 15.3020s	
16129/22950 (epoch 35.139), train_loss = 0.78621154, grad/param norm = 2.3324e-01, time/batch = 14.7506s	
16130/22950 (epoch 35.142), train_loss = 0.77051301, grad/param norm = 2.1875e-01, time/batch = 15.2266s	
16131/22950 (epoch 35.144), train_loss = 0.82037397, grad/param norm = 2.2142e-01, time/batch = 15.0851s	
16132/22950 (epoch 35.146), train_loss = 0.80260904, grad/param norm = 2.7891e-01, time/batch = 15.1454s	
16133/22950 (epoch 35.148), train_loss = 0.79513418, grad/param norm = 2.4303e-01, time/batch = 14.9234s	
16134/22950 (epoch 35.150), train_loss = 0.88803770, grad/param norm = 2.6532e-01, time/batch = 15.1348s	
16135/22950 (epoch 35.153), train_loss = 0.79166009, grad/param norm = 2.0621e-01, time/batch = 14.7502s	
16136/22950 (epoch 35.155), train_loss = 0.80369280, grad/param norm = 2.1245e-01, time/batch = 15.5190s	
16137/22950 (epoch 35.157), train_loss = 0.85289349, grad/param norm = 2.2863e-01, time/batch = 14.8316s	
16138/22950 (epoch 35.159), train_loss = 0.78090478, grad/param norm = 2.2570e-01, time/batch = 15.2338s	
16139/22950 (epoch 35.161), train_loss = 0.82466621, grad/param norm = 2.2683e-01, time/batch = 15.0547s	
16140/22950 (epoch 35.163), train_loss = 0.75869439, grad/param norm = 2.2007e-01, time/batch = 14.8360s	
16141/22950 (epoch 35.166), train_loss = 0.89156706, grad/param norm = 2.4608e-01, time/batch = 15.7888s	
16142/22950 (epoch 35.168), train_loss = 0.87757191, grad/param norm = 2.5265e-01, time/batch = 16.4073s	
16143/22950 (epoch 35.170), train_loss = 0.87654316, grad/param norm = 2.4938e-01, time/batch = 15.0685s	
16144/22950 (epoch 35.172), train_loss = 0.86196489, grad/param norm = 2.3798e-01, time/batch = 14.9965s	
16145/22950 (epoch 35.174), train_loss = 0.93175213, grad/param norm = 2.4119e-01, time/batch = 15.0730s	
16146/22950 (epoch 35.176), train_loss = 0.93393803, grad/param norm = 2.7172e-01, time/batch = 15.4697s	
16147/22950 (epoch 35.179), train_loss = 0.90070972, grad/param norm = 2.5793e-01, time/batch = 15.2406s	
16148/22950 (epoch 35.181), train_loss = 1.11312168, grad/param norm = 3.3388e-01, time/batch = 15.7526s	
16149/22950 (epoch 35.183), train_loss = 0.90098472, grad/param norm = 2.3715e-01, time/batch = 15.5304s	
16150/22950 (epoch 35.185), train_loss = 0.92171467, grad/param norm = 2.5962e-01, time/batch = 16.4930s	
16151/22950 (epoch 35.187), train_loss = 0.80384070, grad/param norm = 2.4882e-01, time/batch = 16.6178s	
16152/22950 (epoch 35.190), train_loss = 0.70982773, grad/param norm = 2.2442e-01, time/batch = 19.2852s	
16153/22950 (epoch 35.192), train_loss = 0.68635444, grad/param norm = 2.7169e-01, time/batch = 17.9391s	
16154/22950 (epoch 35.194), train_loss = 0.84811777, grad/param norm = 2.6211e-01, time/batch = 17.2286s	
16155/22950 (epoch 35.196), train_loss = 0.64472290, grad/param norm = 2.3987e-01, time/batch = 18.9671s	
16156/22950 (epoch 35.198), train_loss = 0.89569072, grad/param norm = 2.5316e-01, time/batch = 16.7702s	
16157/22950 (epoch 35.200), train_loss = 0.78635537, grad/param norm = 2.2780e-01, time/batch = 19.4631s	
16158/22950 (epoch 35.203), train_loss = 0.73916236, grad/param norm = 2.3163e-01, time/batch = 18.9766s	
16159/22950 (epoch 35.205), train_loss = 0.80386780, grad/param norm = 2.2894e-01, time/batch = 17.4421s	
16160/22950 (epoch 35.207), train_loss = 0.87732430, grad/param norm = 2.6902e-01, time/batch = 18.2142s	
16161/22950 (epoch 35.209), train_loss = 0.83890487, grad/param norm = 2.6869e-01, time/batch = 15.4035s	
16162/22950 (epoch 35.211), train_loss = 0.73468774, grad/param norm = 2.4155e-01, time/batch = 15.8502s	
16163/22950 (epoch 35.214), train_loss = 0.78528552, grad/param norm = 2.2203e-01, time/batch = 16.0906s	
16164/22950 (epoch 35.216), train_loss = 0.93831625, grad/param norm = 2.4983e-01, time/batch = 16.2964s	
16165/22950 (epoch 35.218), train_loss = 0.83484704, grad/param norm = 2.2354e-01, time/batch = 16.2769s	
16166/22950 (epoch 35.220), train_loss = 0.92122043, grad/param norm = 2.5682e-01, time/batch = 19.2188s	
16167/22950 (epoch 35.222), train_loss = 0.94282559, grad/param norm = 2.4017e-01, time/batch = 17.1159s	
16168/22950 (epoch 35.224), train_loss = 0.84691240, grad/param norm = 2.4222e-01, time/batch = 16.8723s	
16169/22950 (epoch 35.227), train_loss = 0.90652758, grad/param norm = 2.6581e-01, time/batch = 17.2418s	
16170/22950 (epoch 35.229), train_loss = 0.95499062, grad/param norm = 2.3436e-01, time/batch = 16.1363s	
16171/22950 (epoch 35.231), train_loss = 0.70095679, grad/param norm = 2.9124e-01, time/batch = 15.4566s	
16172/22950 (epoch 35.233), train_loss = 0.80824581, grad/param norm = 2.5877e-01, time/batch = 14.9149s	
16173/22950 (epoch 35.235), train_loss = 0.98728537, grad/param norm = 2.4092e-01, time/batch = 14.8347s	
16174/22950 (epoch 35.237), train_loss = 0.79993977, grad/param norm = 2.1452e-01, time/batch = 15.3796s	
16175/22950 (epoch 35.240), train_loss = 0.84512721, grad/param norm = 2.4306e-01, time/batch = 15.0771s	
16176/22950 (epoch 35.242), train_loss = 0.99173887, grad/param norm = 2.3819e-01, time/batch = 14.9998s	
16177/22950 (epoch 35.244), train_loss = 0.96994932, grad/param norm = 2.6320e-01, time/batch = 14.9948s	
16178/22950 (epoch 35.246), train_loss = 0.96645474, grad/param norm = 2.4424e-01, time/batch = 15.6319s	
16179/22950 (epoch 35.248), train_loss = 0.86910497, grad/param norm = 2.5398e-01, time/batch = 15.9282s	
16180/22950 (epoch 35.251), train_loss = 0.80320189, grad/param norm = 2.4681e-01, time/batch = 15.2098s	
16181/22950 (epoch 35.253), train_loss = 0.79148192, grad/param norm = 2.6328e-01, time/batch = 15.0681s	
16182/22950 (epoch 35.255), train_loss = 0.90049777, grad/param norm = 2.4044e-01, time/batch = 15.6337s	
16183/22950 (epoch 35.257), train_loss = 0.94902513, grad/param norm = 2.7527e-01, time/batch = 15.0809s	
16184/22950 (epoch 35.259), train_loss = 0.72334311, grad/param norm = 2.3407e-01, time/batch = 15.6285s	
16185/22950 (epoch 35.261), train_loss = 0.78500751, grad/param norm = 2.2076e-01, time/batch = 15.1555s	
16186/22950 (epoch 35.264), train_loss = 0.76081698, grad/param norm = 2.1290e-01, time/batch = 14.9914s	
16187/22950 (epoch 35.266), train_loss = 0.82334334, grad/param norm = 2.5178e-01, time/batch = 15.0615s	
16188/22950 (epoch 35.268), train_loss = 0.84098838, grad/param norm = 2.6270e-01, time/batch = 14.9177s	
16189/22950 (epoch 35.270), train_loss = 0.84510841, grad/param norm = 2.3525e-01, time/batch = 15.0623s	
16190/22950 (epoch 35.272), train_loss = 0.87255922, grad/param norm = 2.8126e-01, time/batch = 15.2410s	
16191/22950 (epoch 35.275), train_loss = 0.82124002, grad/param norm = 3.0812e-01, time/batch = 16.0794s	
16192/22950 (epoch 35.277), train_loss = 0.72707351, grad/param norm = 2.1732e-01, time/batch = 16.0998s	
16193/22950 (epoch 35.279), train_loss = 0.76170799, grad/param norm = 2.5587e-01, time/batch = 15.7881s	
16194/22950 (epoch 35.281), train_loss = 0.82676965, grad/param norm = 2.6555e-01, time/batch = 15.1591s	
16195/22950 (epoch 35.283), train_loss = 0.74576929, grad/param norm = 2.3418e-01, time/batch = 15.1462s	
16196/22950 (epoch 35.285), train_loss = 0.85943967, grad/param norm = 2.2397e-01, time/batch = 14.9174s	
16197/22950 (epoch 35.288), train_loss = 0.95266301, grad/param norm = 2.4464e-01, time/batch = 15.4544s	
16198/22950 (epoch 35.290), train_loss = 0.81707885, grad/param norm = 2.2990e-01, time/batch = 16.0811s	
16199/22950 (epoch 35.292), train_loss = 0.93345404, grad/param norm = 2.3955e-01, time/batch = 14.9017s	
16200/22950 (epoch 35.294), train_loss = 0.87015920, grad/param norm = 2.3107e-01, time/batch = 14.9904s	
16201/22950 (epoch 35.296), train_loss = 0.67382594, grad/param norm = 1.8896e-01, time/batch = 15.3091s	
16202/22950 (epoch 35.298), train_loss = 0.82355905, grad/param norm = 2.1042e-01, time/batch = 14.9098s	
16203/22950 (epoch 35.301), train_loss = 0.87925499, grad/param norm = 2.5209e-01, time/batch = 15.6800s	
16204/22950 (epoch 35.303), train_loss = 0.83380220, grad/param norm = 2.4507e-01, time/batch = 15.2929s	
16205/22950 (epoch 35.305), train_loss = 0.83147818, grad/param norm = 2.4803e-01, time/batch = 15.3133s	
16206/22950 (epoch 35.307), train_loss = 0.97478795, grad/param norm = 3.1310e-01, time/batch = 14.9194s	
16207/22950 (epoch 35.309), train_loss = 0.79700672, grad/param norm = 2.2434e-01, time/batch = 14.7568s	
16208/22950 (epoch 35.312), train_loss = 0.86175137, grad/param norm = 2.2656e-01, time/batch = 14.9906s	
16209/22950 (epoch 35.314), train_loss = 0.87399346, grad/param norm = 2.2329e-01, time/batch = 15.3098s	
16210/22950 (epoch 35.316), train_loss = 0.81442013, grad/param norm = 2.4014e-01, time/batch = 15.2497s	
16211/22950 (epoch 35.318), train_loss = 0.73492489, grad/param norm = 2.0428e-01, time/batch = 15.7898s	
16212/22950 (epoch 35.320), train_loss = 0.78093113, grad/param norm = 2.0881e-01, time/batch = 15.5321s	
16213/22950 (epoch 35.322), train_loss = 0.82291918, grad/param norm = 2.6653e-01, time/batch = 16.2289s	
16214/22950 (epoch 35.325), train_loss = 0.64505683, grad/param norm = 2.1360e-01, time/batch = 16.0420s	
16215/22950 (epoch 35.327), train_loss = 0.67607317, grad/param norm = 2.2289e-01, time/batch = 15.5396s	
16216/22950 (epoch 35.329), train_loss = 0.78140129, grad/param norm = 2.1470e-01, time/batch = 14.9992s	
16217/22950 (epoch 35.331), train_loss = 0.73369410, grad/param norm = 2.3494e-01, time/batch = 15.6332s	
16218/22950 (epoch 35.333), train_loss = 0.76685561, grad/param norm = 2.8291e-01, time/batch = 14.8939s	
16219/22950 (epoch 35.336), train_loss = 0.82949830, grad/param norm = 2.7258e-01, time/batch = 14.9102s	
16220/22950 (epoch 35.338), train_loss = 0.84787010, grad/param norm = 2.2831e-01, time/batch = 15.6972s	
16221/22950 (epoch 35.340), train_loss = 0.81310668, grad/param norm = 2.5837e-01, time/batch = 15.2343s	
16222/22950 (epoch 35.342), train_loss = 1.00059145, grad/param norm = 2.7675e-01, time/batch = 14.9098s	
16223/22950 (epoch 35.344), train_loss = 0.81994810, grad/param norm = 2.3688e-01, time/batch = 15.2204s	
16224/22950 (epoch 35.346), train_loss = 0.92592847, grad/param norm = 3.1899e-01, time/batch = 14.7318s	
16225/22950 (epoch 35.349), train_loss = 0.83578554, grad/param norm = 2.2642e-01, time/batch = 14.8329s	
16226/22950 (epoch 35.351), train_loss = 0.84579676, grad/param norm = 2.4145e-01, time/batch = 14.8143s	
16227/22950 (epoch 35.353), train_loss = 0.89347291, grad/param norm = 3.0213e-01, time/batch = 14.7534s	
16228/22950 (epoch 35.355), train_loss = 0.95085821, grad/param norm = 2.9416e-01, time/batch = 15.1545s	
16229/22950 (epoch 35.357), train_loss = 0.85860320, grad/param norm = 3.3804e-01, time/batch = 15.7015s	
16230/22950 (epoch 35.359), train_loss = 0.85150661, grad/param norm = 2.7690e-01, time/batch = 15.0735s	
16231/22950 (epoch 35.362), train_loss = 0.89056599, grad/param norm = 2.6042e-01, time/batch = 15.1501s	
16232/22950 (epoch 35.364), train_loss = 0.84111022, grad/param norm = 2.6021e-01, time/batch = 15.4707s	
16233/22950 (epoch 35.366), train_loss = 0.84008044, grad/param norm = 2.2956e-01, time/batch = 15.7827s	
16234/22950 (epoch 35.368), train_loss = 0.91097049, grad/param norm = 2.7608e-01, time/batch = 15.7081s	
16235/22950 (epoch 35.370), train_loss = 0.81879810, grad/param norm = 2.3750e-01, time/batch = 16.0635s	
16236/22950 (epoch 35.373), train_loss = 0.76372380, grad/param norm = 2.2521e-01, time/batch = 16.3909s	
16237/22950 (epoch 35.375), train_loss = 0.95626277, grad/param norm = 3.0490e-01, time/batch = 16.0441s	
16238/22950 (epoch 35.377), train_loss = 0.77673835, grad/param norm = 3.9934e-01, time/batch = 16.5871s	
16239/22950 (epoch 35.379), train_loss = 0.88997778, grad/param norm = 3.3336e-01, time/batch = 16.5937s	
16240/22950 (epoch 35.381), train_loss = 0.74704223, grad/param norm = 2.3151e-01, time/batch = 16.5925s	
16241/22950 (epoch 35.383), train_loss = 0.82244692, grad/param norm = 2.7060e-01, time/batch = 15.3126s	
16242/22950 (epoch 35.386), train_loss = 0.76996958, grad/param norm = 2.3194e-01, time/batch = 15.2833s	
16243/22950 (epoch 35.388), train_loss = 0.90589267, grad/param norm = 2.6075e-01, time/batch = 14.5840s	
16244/22950 (epoch 35.390), train_loss = 0.74959360, grad/param norm = 2.2641e-01, time/batch = 15.2129s	
16245/22950 (epoch 35.392), train_loss = 0.80866269, grad/param norm = 2.5882e-01, time/batch = 14.5121s	
16246/22950 (epoch 35.394), train_loss = 0.80971064, grad/param norm = 2.2976e-01, time/batch = 14.8985s	
16247/22950 (epoch 35.397), train_loss = 0.95698609, grad/param norm = 2.4295e-01, time/batch = 15.0515s	
16248/22950 (epoch 35.399), train_loss = 0.92483662, grad/param norm = 2.8401e-01, time/batch = 15.2837s	
16249/22950 (epoch 35.401), train_loss = 1.00867489, grad/param norm = 3.3920e-01, time/batch = 14.6656s	
16250/22950 (epoch 35.403), train_loss = 0.82838376, grad/param norm = 2.4953e-01, time/batch = 14.4155s	
16251/22950 (epoch 35.405), train_loss = 0.99049216, grad/param norm = 3.2341e-01, time/batch = 14.9043s	
16252/22950 (epoch 35.407), train_loss = 1.00761817, grad/param norm = 2.4568e-01, time/batch = 15.3043s	
16253/22950 (epoch 35.410), train_loss = 0.87398388, grad/param norm = 2.5012e-01, time/batch = 14.5092s	
16254/22950 (epoch 35.412), train_loss = 0.83363809, grad/param norm = 2.5553e-01, time/batch = 15.1231s	
16255/22950 (epoch 35.414), train_loss = 0.96003390, grad/param norm = 2.6576e-01, time/batch = 15.9863s	
16256/22950 (epoch 35.416), train_loss = 0.89733779, grad/param norm = 3.2119e-01, time/batch = 16.3510s	
16257/22950 (epoch 35.418), train_loss = 0.88182232, grad/param norm = 2.8695e-01, time/batch = 15.3031s	
16258/22950 (epoch 35.420), train_loss = 0.93972710, grad/param norm = 3.0655e-01, time/batch = 14.8923s	
16259/22950 (epoch 35.423), train_loss = 0.82071263, grad/param norm = 2.7381e-01, time/batch = 15.0709s	
16260/22950 (epoch 35.425), train_loss = 0.83625531, grad/param norm = 2.3422e-01, time/batch = 15.2080s	
16261/22950 (epoch 35.427), train_loss = 0.89010755, grad/param norm = 2.6785e-01, time/batch = 15.5235s	
16262/22950 (epoch 35.429), train_loss = 0.85356965, grad/param norm = 2.2637e-01, time/batch = 14.8916s	
16263/22950 (epoch 35.431), train_loss = 0.94430910, grad/param norm = 2.6648e-01, time/batch = 14.8104s	
16264/22950 (epoch 35.434), train_loss = 0.85659772, grad/param norm = 2.3714e-01, time/batch = 15.2980s	
16265/22950 (epoch 35.436), train_loss = 0.93923271, grad/param norm = 2.7315e-01, time/batch = 14.9678s	
16266/22950 (epoch 35.438), train_loss = 0.86311301, grad/param norm = 2.4134e-01, time/batch = 14.4987s	
16267/22950 (epoch 35.440), train_loss = 0.95502773, grad/param norm = 2.4574e-01, time/batch = 15.2033s	
16268/22950 (epoch 35.442), train_loss = 0.99776841, grad/param norm = 2.7102e-01, time/batch = 14.8983s	
16269/22950 (epoch 35.444), train_loss = 0.90184756, grad/param norm = 2.6290e-01, time/batch = 14.8933s	
16270/22950 (epoch 35.447), train_loss = 1.01467296, grad/param norm = 2.7675e-01, time/batch = 14.9139s	
16271/22950 (epoch 35.449), train_loss = 0.77903330, grad/param norm = 2.2937e-01, time/batch = 15.2246s	
16272/22950 (epoch 35.451), train_loss = 0.86166971, grad/param norm = 2.4783e-01, time/batch = 15.2372s	
16273/22950 (epoch 35.453), train_loss = 0.91085089, grad/param norm = 2.2315e-01, time/batch = 15.0653s	
16274/22950 (epoch 35.455), train_loss = 0.84884641, grad/param norm = 2.0551e-01, time/batch = 15.3772s	
16275/22950 (epoch 35.458), train_loss = 0.87324073, grad/param norm = 2.5665e-01, time/batch = 16.2938s	
16276/22950 (epoch 35.460), train_loss = 0.90708031, grad/param norm = 2.3623e-01, time/batch = 1.1160s	
16277/22950 (epoch 35.462), train_loss = 0.90874845, grad/param norm = 2.4773e-01, time/batch = 0.7519s	
16278/22950 (epoch 35.464), train_loss = 0.82724342, grad/param norm = 2.4001e-01, time/batch = 0.7456s	
16279/22950 (epoch 35.466), train_loss = 0.94965842, grad/param norm = 2.6595e-01, time/batch = 0.7149s	
16280/22950 (epoch 35.468), train_loss = 0.94248630, grad/param norm = 2.4782e-01, time/batch = 0.7309s	
16281/22950 (epoch 35.471), train_loss = 0.88851632, grad/param norm = 2.5703e-01, time/batch = 0.7365s	
16282/22950 (epoch 35.473), train_loss = 0.91279027, grad/param norm = 2.6267e-01, time/batch = 1.0537s	
16283/22950 (epoch 35.475), train_loss = 1.04552855, grad/param norm = 2.5135e-01, time/batch = 1.0200s	
16284/22950 (epoch 35.477), train_loss = 0.83717395, grad/param norm = 2.4047e-01, time/batch = 0.9983s	
16285/22950 (epoch 35.479), train_loss = 0.76503817, grad/param norm = 2.4984e-01, time/batch = 1.0032s	
16286/22950 (epoch 35.481), train_loss = 0.94349147, grad/param norm = 2.6275e-01, time/batch = 1.0862s	
16287/22950 (epoch 35.484), train_loss = 0.91323164, grad/param norm = 3.0289e-01, time/batch = 1.8501s	
16288/22950 (epoch 35.486), train_loss = 0.76141991, grad/param norm = 2.6020e-01, time/batch = 1.8619s	
16289/22950 (epoch 35.488), train_loss = 0.81841885, grad/param norm = 3.2046e-01, time/batch = 7.3210s	
16290/22950 (epoch 35.490), train_loss = 0.74764498, grad/param norm = 2.4835e-01, time/batch = 15.3801s	
16291/22950 (epoch 35.492), train_loss = 0.83155641, grad/param norm = 2.2870e-01, time/batch = 15.6119s	
16292/22950 (epoch 35.495), train_loss = 0.81284938, grad/param norm = 2.5188e-01, time/batch = 15.3803s	
16293/22950 (epoch 35.497), train_loss = 0.90387350, grad/param norm = 2.5919e-01, time/batch = 15.1444s	
16294/22950 (epoch 35.499), train_loss = 0.97812529, grad/param norm = 2.3116e-01, time/batch = 15.7738s	
16295/22950 (epoch 35.501), train_loss = 0.87341901, grad/param norm = 2.7198e-01, time/batch = 15.2367s	
16296/22950 (epoch 35.503), train_loss = 0.97199105, grad/param norm = 2.4830e-01, time/batch = 16.5034s	
16297/22950 (epoch 35.505), train_loss = 0.72567378, grad/param norm = 2.5746e-01, time/batch = 15.9528s	
16298/22950 (epoch 35.508), train_loss = 0.92714772, grad/param norm = 2.6662e-01, time/batch = 14.9061s	
16299/22950 (epoch 35.510), train_loss = 0.83217185, grad/param norm = 2.2564e-01, time/batch = 16.4555s	
16300/22950 (epoch 35.512), train_loss = 0.75684986, grad/param norm = 2.4826e-01, time/batch = 16.6408s	
16301/22950 (epoch 35.514), train_loss = 0.81980128, grad/param norm = 2.0341e-01, time/batch = 15.7591s	
16302/22950 (epoch 35.516), train_loss = 0.87160239, grad/param norm = 2.2800e-01, time/batch = 19.0174s	
16303/22950 (epoch 35.519), train_loss = 0.86550342, grad/param norm = 2.4125e-01, time/batch = 18.1088s	
16304/22950 (epoch 35.521), train_loss = 0.86544372, grad/param norm = 2.4696e-01, time/batch = 17.0329s	
16305/22950 (epoch 35.523), train_loss = 0.70607716, grad/param norm = 2.3087e-01, time/batch = 16.7614s	
16306/22950 (epoch 35.525), train_loss = 0.78025107, grad/param norm = 2.3785e-01, time/batch = 18.0235s	
16307/22950 (epoch 35.527), train_loss = 0.74502580, grad/param norm = 2.1686e-01, time/batch = 20.1144s	
16308/22950 (epoch 35.529), train_loss = 0.86040965, grad/param norm = 2.3347e-01, time/batch = 17.8417s	
16309/22950 (epoch 35.532), train_loss = 0.82981447, grad/param norm = 2.2889e-01, time/batch = 19.0067s	
16310/22950 (epoch 35.534), train_loss = 0.86882673, grad/param norm = 2.3970e-01, time/batch = 19.5185s	
16311/22950 (epoch 35.536), train_loss = 0.90726485, grad/param norm = 2.9182e-01, time/batch = 17.2844s	
16312/22950 (epoch 35.538), train_loss = 0.85925367, grad/param norm = 2.5362e-01, time/batch = 19.9515s	
16313/22950 (epoch 35.540), train_loss = 0.89280972, grad/param norm = 2.5016e-01, time/batch = 17.3703s	
16314/22950 (epoch 35.542), train_loss = 0.99953304, grad/param norm = 2.8487e-01, time/batch = 16.9285s	
16315/22950 (epoch 35.545), train_loss = 0.83451243, grad/param norm = 2.4100e-01, time/batch = 20.3464s	
16316/22950 (epoch 35.547), train_loss = 0.84626419, grad/param norm = 2.3336e-01, time/batch = 18.2045s	
16317/22950 (epoch 35.549), train_loss = 0.81540969, grad/param norm = 2.6477e-01, time/batch = 18.4438s	
16318/22950 (epoch 35.551), train_loss = 0.84031811, grad/param norm = 2.3910e-01, time/batch = 17.6138s	
16319/22950 (epoch 35.553), train_loss = 0.82106811, grad/param norm = 2.8688e-01, time/batch = 17.8447s	
16320/22950 (epoch 35.556), train_loss = 0.89466763, grad/param norm = 2.3941e-01, time/batch = 15.8144s	
16321/22950 (epoch 35.558), train_loss = 0.72553355, grad/param norm = 2.2996e-01, time/batch = 15.7759s	
16322/22950 (epoch 35.560), train_loss = 0.81908220, grad/param norm = 2.3971e-01, time/batch = 18.2048s	
16323/22950 (epoch 35.562), train_loss = 0.78691746, grad/param norm = 2.2184e-01, time/batch = 16.9313s	
16324/22950 (epoch 35.564), train_loss = 0.89847264, grad/param norm = 2.7290e-01, time/batch = 16.5460s	
16325/22950 (epoch 35.566), train_loss = 0.86871784, grad/param norm = 2.4520e-01, time/batch = 17.7143s	
16326/22950 (epoch 35.569), train_loss = 0.83730062, grad/param norm = 2.4247e-01, time/batch = 16.8363s	
16327/22950 (epoch 35.571), train_loss = 0.81206467, grad/param norm = 2.3796e-01, time/batch = 18.9589s	
16328/22950 (epoch 35.573), train_loss = 0.83451891, grad/param norm = 2.4460e-01, time/batch = 17.7159s	
16329/22950 (epoch 35.575), train_loss = 0.92285659, grad/param norm = 3.9633e-01, time/batch = 19.7809s	
16330/22950 (epoch 35.577), train_loss = 0.86438734, grad/param norm = 3.2071e-01, time/batch = 19.1329s	
16331/22950 (epoch 35.580), train_loss = 0.95983441, grad/param norm = 3.3804e-01, time/batch = 19.3767s	
16332/22950 (epoch 35.582), train_loss = 1.02620539, grad/param norm = 3.0916e-01, time/batch = 18.9539s	
16333/22950 (epoch 35.584), train_loss = 0.74310797, grad/param norm = 2.5168e-01, time/batch = 19.3678s	
16334/22950 (epoch 35.586), train_loss = 0.79940980, grad/param norm = 2.6236e-01, time/batch = 19.4506s	
16335/22950 (epoch 35.588), train_loss = 0.95808053, grad/param norm = 2.8460e-01, time/batch = 18.7977s	
16336/22950 (epoch 35.590), train_loss = 0.91250876, grad/param norm = 2.6447e-01, time/batch = 17.0868s	
16337/22950 (epoch 35.593), train_loss = 0.85217771, grad/param norm = 2.8316e-01, time/batch = 16.6481s	
16338/22950 (epoch 35.595), train_loss = 0.77370631, grad/param norm = 2.4823e-01, time/batch = 16.3435s	
16339/22950 (epoch 35.597), train_loss = 0.91179577, grad/param norm = 2.6102e-01, time/batch = 16.7280s	
16340/22950 (epoch 35.599), train_loss = 0.87347377, grad/param norm = 2.7737e-01, time/batch = 16.7993s	
16341/22950 (epoch 35.601), train_loss = 0.89758733, grad/param norm = 2.4348e-01, time/batch = 16.3323s	
16342/22950 (epoch 35.603), train_loss = 0.97964593, grad/param norm = 2.5099e-01, time/batch = 16.4600s	
16343/22950 (epoch 35.606), train_loss = 0.85005355, grad/param norm = 2.3175e-01, time/batch = 15.9544s	
16344/22950 (epoch 35.608), train_loss = 0.83133653, grad/param norm = 2.2711e-01, time/batch = 16.3785s	
16345/22950 (epoch 35.610), train_loss = 0.85328166, grad/param norm = 2.4739e-01, time/batch = 16.4349s	
16346/22950 (epoch 35.612), train_loss = 0.87960794, grad/param norm = 2.4640e-01, time/batch = 17.9219s	
16347/22950 (epoch 35.614), train_loss = 0.95191680, grad/param norm = 2.8550e-01, time/batch = 16.4966s	
16348/22950 (epoch 35.617), train_loss = 0.88834535, grad/param norm = 2.4730e-01, time/batch = 16.9498s	
16349/22950 (epoch 35.619), train_loss = 0.79067993, grad/param norm = 2.0269e-01, time/batch = 16.3893s	
16350/22950 (epoch 35.621), train_loss = 0.92424281, grad/param norm = 2.3812e-01, time/batch = 17.9497s	
16351/22950 (epoch 35.623), train_loss = 0.92695868, grad/param norm = 2.6268e-01, time/batch = 17.7724s	
16352/22950 (epoch 35.625), train_loss = 0.84532688, grad/param norm = 2.4382e-01, time/batch = 20.3688s	
16353/22950 (epoch 35.627), train_loss = 0.83157144, grad/param norm = 2.4943e-01, time/batch = 17.3690s	
16354/22950 (epoch 35.630), train_loss = 0.74132892, grad/param norm = 2.2232e-01, time/batch = 18.2855s	
16355/22950 (epoch 35.632), train_loss = 0.81016416, grad/param norm = 2.7107e-01, time/batch = 20.7007s	
16356/22950 (epoch 35.634), train_loss = 0.89351536, grad/param norm = 2.5631e-01, time/batch = 17.7826s	
16357/22950 (epoch 35.636), train_loss = 0.85396838, grad/param norm = 2.3616e-01, time/batch = 17.6744s	
16358/22950 (epoch 35.638), train_loss = 0.83332660, grad/param norm = 2.5364e-01, time/batch = 16.8325s	
16359/22950 (epoch 35.641), train_loss = 0.82467907, grad/param norm = 2.4853e-01, time/batch = 16.6931s	
16360/22950 (epoch 35.643), train_loss = 0.87559181, grad/param norm = 2.7269e-01, time/batch = 16.7251s	
16361/22950 (epoch 35.645), train_loss = 0.82984573, grad/param norm = 2.3175e-01, time/batch = 16.1086s	
16362/22950 (epoch 35.647), train_loss = 0.83142635, grad/param norm = 2.5507e-01, time/batch = 15.9259s	
16363/22950 (epoch 35.649), train_loss = 0.80202476, grad/param norm = 2.5120e-01, time/batch = 16.3999s	
16364/22950 (epoch 35.651), train_loss = 0.94336807, grad/param norm = 2.5163e-01, time/batch = 16.0921s	
16365/22950 (epoch 35.654), train_loss = 0.72907784, grad/param norm = 2.3442e-01, time/batch = 18.6107s	
16366/22950 (epoch 35.656), train_loss = 0.91423334, grad/param norm = 3.5570e-01, time/batch = 20.3620s	
16367/22950 (epoch 35.658), train_loss = 0.77636016, grad/param norm = 2.5294e-01, time/batch = 17.0471s	
16368/22950 (epoch 35.660), train_loss = 0.68909813, grad/param norm = 2.4923e-01, time/batch = 18.6281s	
16369/22950 (epoch 35.662), train_loss = 0.70838905, grad/param norm = 2.4194e-01, time/batch = 19.3706s	
16370/22950 (epoch 35.664), train_loss = 0.81693093, grad/param norm = 2.5508e-01, time/batch = 17.7976s	
16371/22950 (epoch 35.667), train_loss = 0.85515368, grad/param norm = 2.4807e-01, time/batch = 18.2913s	
16372/22950 (epoch 35.669), train_loss = 0.85465964, grad/param norm = 2.6184e-01, time/batch = 19.1285s	
16373/22950 (epoch 35.671), train_loss = 0.84519551, grad/param norm = 2.9255e-01, time/batch = 18.4437s	
16374/22950 (epoch 35.673), train_loss = 0.80435377, grad/param norm = 2.7388e-01, time/batch = 17.4487s	
16375/22950 (epoch 35.675), train_loss = 0.88771832, grad/param norm = 2.7655e-01, time/batch = 18.0551s	
16376/22950 (epoch 35.678), train_loss = 0.84941693, grad/param norm = 2.4662e-01, time/batch = 16.2610s	
16377/22950 (epoch 35.680), train_loss = 0.87539646, grad/param norm = 2.1751e-01, time/batch = 16.7782s	
16378/22950 (epoch 35.682), train_loss = 0.84162906, grad/param norm = 2.5037e-01, time/batch = 17.7172s	
16379/22950 (epoch 35.684), train_loss = 0.95405642, grad/param norm = 3.0003e-01, time/batch = 15.7982s	
16380/22950 (epoch 35.686), train_loss = 0.95859722, grad/param norm = 2.4855e-01, time/batch = 17.5125s	
16381/22950 (epoch 35.688), train_loss = 0.89011208, grad/param norm = 2.6365e-01, time/batch = 16.5753s	
16382/22950 (epoch 35.691), train_loss = 0.85882698, grad/param norm = 2.7086e-01, time/batch = 16.3368s	
16383/22950 (epoch 35.693), train_loss = 0.80758386, grad/param norm = 2.4858e-01, time/batch = 15.8768s	
16384/22950 (epoch 35.695), train_loss = 0.96246973, grad/param norm = 3.2315e-01, time/batch = 16.1120s	
16385/22950 (epoch 35.697), train_loss = 0.90742497, grad/param norm = 3.1290e-01, time/batch = 16.4006s	
16386/22950 (epoch 35.699), train_loss = 0.90504324, grad/param norm = 2.4964e-01, time/batch = 16.3920s	
16387/22950 (epoch 35.702), train_loss = 0.91825739, grad/param norm = 2.4859e-01, time/batch = 16.4078s	
16388/22950 (epoch 35.704), train_loss = 1.00820149, grad/param norm = 3.0417e-01, time/batch = 16.1877s	
16389/22950 (epoch 35.706), train_loss = 0.96888068, grad/param norm = 3.0968e-01, time/batch = 15.7138s	
16390/22950 (epoch 35.708), train_loss = 0.76342163, grad/param norm = 2.6201e-01, time/batch = 15.7882s	
16391/22950 (epoch 35.710), train_loss = 0.87998444, grad/param norm = 2.6126e-01, time/batch = 16.0987s	
16392/22950 (epoch 35.712), train_loss = 0.98432020, grad/param norm = 2.8079e-01, time/batch = 15.7057s	
16393/22950 (epoch 35.715), train_loss = 0.89719256, grad/param norm = 2.8958e-01, time/batch = 15.7099s	
16394/22950 (epoch 35.717), train_loss = 0.91111463, grad/param norm = 2.3758e-01, time/batch = 16.0446s	
16395/22950 (epoch 35.719), train_loss = 0.83551820, grad/param norm = 2.5602e-01, time/batch = 16.1900s	
16396/22950 (epoch 35.721), train_loss = 0.93920133, grad/param norm = 2.7198e-01, time/batch = 15.9726s	
16397/22950 (epoch 35.723), train_loss = 0.89210874, grad/param norm = 3.3487e-01, time/batch = 16.0314s	
16398/22950 (epoch 35.725), train_loss = 0.93558520, grad/param norm = 2.7386e-01, time/batch = 16.0237s	
16399/22950 (epoch 35.728), train_loss = 0.85050485, grad/param norm = 2.9612e-01, time/batch = 16.5931s	
16400/22950 (epoch 35.730), train_loss = 0.88089383, grad/param norm = 2.5465e-01, time/batch = 15.9348s	
16401/22950 (epoch 35.732), train_loss = 0.94744170, grad/param norm = 2.8803e-01, time/batch = 16.0473s	
16402/22950 (epoch 35.734), train_loss = 0.84200423, grad/param norm = 2.6735e-01, time/batch = 16.0353s	
16403/22950 (epoch 35.736), train_loss = 0.91418466, grad/param norm = 2.4775e-01, time/batch = 16.0454s	
16404/22950 (epoch 35.739), train_loss = 0.94523936, grad/param norm = 2.6758e-01, time/batch = 15.7874s	
16405/22950 (epoch 35.741), train_loss = 0.93592343, grad/param norm = 2.6736e-01, time/batch = 15.7980s	
16406/22950 (epoch 35.743), train_loss = 1.02830153, grad/param norm = 3.5868e-01, time/batch = 16.3405s	
16407/22950 (epoch 35.745), train_loss = 1.11734342, grad/param norm = 3.4058e-01, time/batch = 16.4318s	
16408/22950 (epoch 35.747), train_loss = 0.92438088, grad/param norm = 2.8196e-01, time/batch = 16.6970s	
16409/22950 (epoch 35.749), train_loss = 0.82333851, grad/param norm = 2.6827e-01, time/batch = 15.7853s	
16410/22950 (epoch 35.752), train_loss = 1.04824037, grad/param norm = 2.8794e-01, time/batch = 16.2595s	
16411/22950 (epoch 35.754), train_loss = 0.91594354, grad/param norm = 2.6987e-01, time/batch = 15.9496s	
16412/22950 (epoch 35.756), train_loss = 0.83130585, grad/param norm = 2.7194e-01, time/batch = 15.6166s	
16413/22950 (epoch 35.758), train_loss = 0.89633519, grad/param norm = 2.2520e-01, time/batch = 15.2226s	
16414/22950 (epoch 35.760), train_loss = 0.87469399, grad/param norm = 2.3702e-01, time/batch = 16.5930s	
16415/22950 (epoch 35.763), train_loss = 0.91297372, grad/param norm = 2.9835e-01, time/batch = 16.1289s	
16416/22950 (epoch 35.765), train_loss = 0.86953522, grad/param norm = 2.7055e-01, time/batch = 16.5737s	
16417/22950 (epoch 35.767), train_loss = 1.07184339, grad/param norm = 3.0181e-01, time/batch = 17.0387s	
16418/22950 (epoch 35.769), train_loss = 0.92093616, grad/param norm = 2.7117e-01, time/batch = 16.8736s	
16419/22950 (epoch 35.771), train_loss = 0.78851430, grad/param norm = 2.8583e-01, time/batch = 16.5881s	
16420/22950 (epoch 35.773), train_loss = 0.66890546, grad/param norm = 2.1470e-01, time/batch = 16.2198s	
16421/22950 (epoch 35.776), train_loss = 0.79446557, grad/param norm = 2.0616e-01, time/batch = 16.6083s	
16422/22950 (epoch 35.778), train_loss = 0.79141844, grad/param norm = 2.6269e-01, time/batch = 16.0498s	
16423/22950 (epoch 35.780), train_loss = 0.87016129, grad/param norm = 2.4593e-01, time/batch = 15.8826s	
16424/22950 (epoch 35.782), train_loss = 0.93124366, grad/param norm = 2.7475e-01, time/batch = 15.9626s	
16425/22950 (epoch 35.784), train_loss = 0.82126792, grad/param norm = 2.5347e-01, time/batch = 16.1955s	
16426/22950 (epoch 35.786), train_loss = 0.87574740, grad/param norm = 2.5887e-01, time/batch = 16.1958s	
16427/22950 (epoch 35.789), train_loss = 0.72314702, grad/param norm = 2.1977e-01, time/batch = 16.3515s	
16428/22950 (epoch 35.791), train_loss = 0.75866991, grad/param norm = 2.2839e-01, time/batch = 16.2028s	
16429/22950 (epoch 35.793), train_loss = 0.95333979, grad/param norm = 2.5638e-01, time/batch = 15.8932s	
16430/22950 (epoch 35.795), train_loss = 0.83341095, grad/param norm = 2.4583e-01, time/batch = 15.8690s	
16431/22950 (epoch 35.797), train_loss = 0.95862499, grad/param norm = 2.4215e-01, time/batch = 16.1330s	
16432/22950 (epoch 35.800), train_loss = 0.80138729, grad/param norm = 2.3113e-01, time/batch = 15.9574s	
16433/22950 (epoch 35.802), train_loss = 0.85144513, grad/param norm = 2.7057e-01, time/batch = 15.7273s	
16434/22950 (epoch 35.804), train_loss = 0.83095321, grad/param norm = 2.3036e-01, time/batch = 16.1134s	
16435/22950 (epoch 35.806), train_loss = 0.75361026, grad/param norm = 2.4149e-01, time/batch = 15.7108s	
16436/22950 (epoch 35.808), train_loss = 0.85754484, grad/param norm = 2.3619e-01, time/batch = 15.9556s	
16437/22950 (epoch 35.810), train_loss = 0.83982922, grad/param norm = 2.6571e-01, time/batch = 15.7303s	
16438/22950 (epoch 35.813), train_loss = 0.71462844, grad/param norm = 2.3580e-01, time/batch = 16.1106s	
16439/22950 (epoch 35.815), train_loss = 0.69851838, grad/param norm = 2.3366e-01, time/batch = 16.7015s	
16440/22950 (epoch 35.817), train_loss = 0.76190694, grad/param norm = 2.1865e-01, time/batch = 16.1148s	
16441/22950 (epoch 35.819), train_loss = 0.82662647, grad/param norm = 2.6921e-01, time/batch = 16.4888s	
16442/22950 (epoch 35.821), train_loss = 0.83014280, grad/param norm = 2.4632e-01, time/batch = 16.5118s	
16443/22950 (epoch 35.824), train_loss = 0.85813384, grad/param norm = 2.2657e-01, time/batch = 16.2123s	
16444/22950 (epoch 35.826), train_loss = 0.89139424, grad/param norm = 2.8050e-01, time/batch = 16.3061s	
16445/22950 (epoch 35.828), train_loss = 0.83957746, grad/param norm = 2.8506e-01, time/batch = 16.4505s	
16446/22950 (epoch 35.830), train_loss = 0.82231781, grad/param norm = 2.4254e-01, time/batch = 16.4592s	
16447/22950 (epoch 35.832), train_loss = 0.86423404, grad/param norm = 2.3026e-01, time/batch = 16.8396s	
16448/22950 (epoch 35.834), train_loss = 0.71444070, grad/param norm = 2.5709e-01, time/batch = 16.3805s	
16449/22950 (epoch 35.837), train_loss = 0.87037921, grad/param norm = 2.6663e-01, time/batch = 15.8086s	
16450/22950 (epoch 35.839), train_loss = 0.72987561, grad/param norm = 2.7970e-01, time/batch = 15.8789s	
16451/22950 (epoch 35.841), train_loss = 0.82998447, grad/param norm = 2.2743e-01, time/batch = 15.7182s	
16452/22950 (epoch 35.843), train_loss = 0.80814752, grad/param norm = 2.5854e-01, time/batch = 15.9497s	
16453/22950 (epoch 35.845), train_loss = 0.85153814, grad/param norm = 2.7783e-01, time/batch = 16.3417s	
16454/22950 (epoch 35.847), train_loss = 0.87708360, grad/param norm = 2.5356e-01, time/batch = 15.9537s	
16455/22950 (epoch 35.850), train_loss = 0.92842643, grad/param norm = 2.5492e-01, time/batch = 15.6327s	
16456/22950 (epoch 35.852), train_loss = 0.91732095, grad/param norm = 2.5276e-01, time/batch = 15.6319s	
16457/22950 (epoch 35.854), train_loss = 0.86056120, grad/param norm = 2.3983e-01, time/batch = 15.7883s	
16458/22950 (epoch 35.856), train_loss = 0.95640117, grad/param norm = 2.9054e-01, time/batch = 16.1101s	
16459/22950 (epoch 35.858), train_loss = 0.92522409, grad/param norm = 2.6317e-01, time/batch = 16.8124s	
16460/22950 (epoch 35.861), train_loss = 0.91624231, grad/param norm = 2.4566e-01, time/batch = 16.7044s	
16461/22950 (epoch 35.863), train_loss = 0.96286194, grad/param norm = 3.3645e-01, time/batch = 16.5357s	
16462/22950 (epoch 35.865), train_loss = 0.98550718, grad/param norm = 2.7510e-01, time/batch = 16.8546s	
16463/22950 (epoch 35.867), train_loss = 0.89352487, grad/param norm = 2.5501e-01, time/batch = 16.8373s	
16464/22950 (epoch 35.869), train_loss = 1.01094288, grad/param norm = 2.8603e-01, time/batch = 16.6102s	
16465/22950 (epoch 35.871), train_loss = 0.87712154, grad/param norm = 2.6993e-01, time/batch = 16.5665s	
16466/22950 (epoch 35.874), train_loss = 0.90249842, grad/param norm = 2.2424e-01, time/batch = 16.6561s	
16467/22950 (epoch 35.876), train_loss = 0.94230002, grad/param norm = 2.7449e-01, time/batch = 16.4386s	
16468/22950 (epoch 35.878), train_loss = 0.88398656, grad/param norm = 2.7775e-01, time/batch = 16.4177s	
16469/22950 (epoch 35.880), train_loss = 1.05444599, grad/param norm = 2.7848e-01, time/batch = 16.3915s	
16470/22950 (epoch 35.882), train_loss = 0.76117411, grad/param norm = 2.2687e-01, time/batch = 16.2656s	
16471/22950 (epoch 35.885), train_loss = 0.90396706, grad/param norm = 2.6485e-01, time/batch = 16.5755s	
16472/22950 (epoch 35.887), train_loss = 0.85110333, grad/param norm = 2.1645e-01, time/batch = 15.9542s	
16473/22950 (epoch 35.889), train_loss = 0.90249297, grad/param norm = 2.5110e-01, time/batch = 16.1277s	
16474/22950 (epoch 35.891), train_loss = 0.80618612, grad/param norm = 2.3680e-01, time/batch = 16.5707s	
16475/22950 (epoch 35.893), train_loss = 0.92109024, grad/param norm = 2.5849e-01, time/batch = 16.7979s	
16476/22950 (epoch 35.895), train_loss = 1.01884883, grad/param norm = 2.8120e-01, time/batch = 16.6811s	
16477/22950 (epoch 35.898), train_loss = 0.93008362, grad/param norm = 2.5154e-01, time/batch = 16.1152s	
16478/22950 (epoch 35.900), train_loss = 0.82395922, grad/param norm = 2.2234e-01, time/batch = 16.0339s	
16479/22950 (epoch 35.902), train_loss = 0.88138936, grad/param norm = 2.7266e-01, time/batch = 15.7128s	
16480/22950 (epoch 35.904), train_loss = 0.87388100, grad/param norm = 2.4916e-01, time/batch = 16.3402s	
16481/22950 (epoch 35.906), train_loss = 0.90494759, grad/param norm = 3.3443e-01, time/batch = 16.0371s	
16482/22950 (epoch 35.908), train_loss = 0.78215859, grad/param norm = 2.4651e-01, time/batch = 15.4755s	
16483/22950 (epoch 35.911), train_loss = 0.73843587, grad/param norm = 2.1865e-01, time/batch = 15.9425s	
16484/22950 (epoch 35.913), train_loss = 0.86848954, grad/param norm = 2.8125e-01, time/batch = 16.5822s	
16485/22950 (epoch 35.915), train_loss = 0.98549015, grad/param norm = 2.7067e-01, time/batch = 15.9427s	
16486/22950 (epoch 35.917), train_loss = 0.77872017, grad/param norm = 2.2709e-01, time/batch = 15.7229s	
16487/22950 (epoch 35.919), train_loss = 0.89895631, grad/param norm = 2.6680e-01, time/batch = 16.1952s	
16488/22950 (epoch 35.922), train_loss = 0.87571466, grad/param norm = 2.6805e-01, time/batch = 16.1141s	
16489/22950 (epoch 35.924), train_loss = 0.91456828, grad/param norm = 2.9112e-01, time/batch = 15.7960s	
16490/22950 (epoch 35.926), train_loss = 0.72777773, grad/param norm = 2.5878e-01, time/batch = 15.8091s	
16491/22950 (epoch 35.928), train_loss = 0.77726833, grad/param norm = 2.4323e-01, time/batch = 16.2753s	
16492/22950 (epoch 35.930), train_loss = 0.75035512, grad/param norm = 2.2368e-01, time/batch = 15.8949s	
16493/22950 (epoch 35.932), train_loss = 0.72595633, grad/param norm = 2.3223e-01, time/batch = 15.7213s	
16494/22950 (epoch 35.935), train_loss = 0.90343738, grad/param norm = 2.4737e-01, time/batch = 15.6026s	
16495/22950 (epoch 35.937), train_loss = 0.85838836, grad/param norm = 2.9256e-01, time/batch = 16.0811s	
16496/22950 (epoch 35.939), train_loss = 0.82678965, grad/param norm = 3.0229e-01, time/batch = 16.3840s	
16497/22950 (epoch 35.941), train_loss = 0.86179444, grad/param norm = 2.7326e-01, time/batch = 15.9317s	
16498/22950 (epoch 35.943), train_loss = 0.87051360, grad/param norm = 2.4192e-01, time/batch = 15.9280s	
16499/22950 (epoch 35.946), train_loss = 0.73005989, grad/param norm = 2.5505e-01, time/batch = 16.2552s	
16500/22950 (epoch 35.948), train_loss = 0.94502525, grad/param norm = 2.4733e-01, time/batch = 16.0903s	
16501/22950 (epoch 35.950), train_loss = 0.85037486, grad/param norm = 2.7639e-01, time/batch = 16.8023s	
16502/22950 (epoch 35.952), train_loss = 0.90817751, grad/param norm = 2.5483e-01, time/batch = 26.7268s	
16503/22950 (epoch 35.954), train_loss = 0.89957772, grad/param norm = 2.6176e-01, time/batch = 20.5456s	
16504/22950 (epoch 35.956), train_loss = 0.81785276, grad/param norm = 2.7911e-01, time/batch = 16.2045s	
16505/22950 (epoch 35.959), train_loss = 0.78333424, grad/param norm = 2.4792e-01, time/batch = 16.6817s	
16506/22950 (epoch 35.961), train_loss = 0.86365657, grad/param norm = 2.5254e-01, time/batch = 16.4532s	
16507/22950 (epoch 35.963), train_loss = 0.88445831, grad/param norm = 2.7649e-01, time/batch = 16.4234s	
16508/22950 (epoch 35.965), train_loss = 0.94352114, grad/param norm = 3.0288e-01, time/batch = 15.8623s	
16509/22950 (epoch 35.967), train_loss = 0.84016360, grad/param norm = 2.6073e-01, time/batch = 15.8626s	
16510/22950 (epoch 35.969), train_loss = 0.76298023, grad/param norm = 2.4668e-01, time/batch = 15.9448s	
16511/22950 (epoch 35.972), train_loss = 0.83987673, grad/param norm = 2.4711e-01, time/batch = 15.7989s	
16512/22950 (epoch 35.974), train_loss = 0.80576206, grad/param norm = 2.4223e-01, time/batch = 16.0301s	
16513/22950 (epoch 35.976), train_loss = 0.84303419, grad/param norm = 2.2251e-01, time/batch = 15.8605s	
16514/22950 (epoch 35.978), train_loss = 0.77383565, grad/param norm = 2.3724e-01, time/batch = 15.5505s	
16515/22950 (epoch 35.980), train_loss = 0.81745853, grad/param norm = 2.4005e-01, time/batch = 15.5520s	
16516/22950 (epoch 35.983), train_loss = 0.88156540, grad/param norm = 2.2657e-01, time/batch = 16.0930s	
16517/22950 (epoch 35.985), train_loss = 0.74765760, grad/param norm = 2.4137e-01, time/batch = 16.0290s	
16518/22950 (epoch 35.987), train_loss = 0.78459963, grad/param norm = 2.3714e-01, time/batch = 15.7996s	
16519/22950 (epoch 35.989), train_loss = 0.85415189, grad/param norm = 2.5168e-01, time/batch = 16.5042s	
16520/22950 (epoch 35.991), train_loss = 0.72571614, grad/param norm = 2.2742e-01, time/batch = 16.9697s	
16521/22950 (epoch 35.993), train_loss = 0.88579754, grad/param norm = 2.7044e-01, time/batch = 17.0093s	
16522/22950 (epoch 35.996), train_loss = 0.83702314, grad/param norm = 2.4006e-01, time/batch = 15.9239s	
16523/22950 (epoch 35.998), train_loss = 0.76598398, grad/param norm = 2.6807e-01, time/batch = 16.0478s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
16524/22950 (epoch 36.000), train_loss = 0.71946608, grad/param norm = 2.1275e-01, time/batch = 16.2366s	
16525/22950 (epoch 36.002), train_loss = 1.01472475, grad/param norm = 3.4667e-01, time/batch = 16.2524s	
16526/22950 (epoch 36.004), train_loss = 0.89474524, grad/param norm = 2.3000e-01, time/batch = 16.3087s	
16527/22950 (epoch 36.007), train_loss = 0.84795713, grad/param norm = 2.6493e-01, time/batch = 16.0159s	
16528/22950 (epoch 36.009), train_loss = 0.97068286, grad/param norm = 2.7264e-01, time/batch = 15.9474s	
16529/22950 (epoch 36.011), train_loss = 0.72592035, grad/param norm = 2.2955e-01, time/batch = 16.0345s	
16530/22950 (epoch 36.013), train_loss = 0.82746086, grad/param norm = 2.6424e-01, time/batch = 15.5429s	
16531/22950 (epoch 36.015), train_loss = 0.89376976, grad/param norm = 3.3957e-01, time/batch = 16.1268s	
16532/22950 (epoch 36.017), train_loss = 0.86712066, grad/param norm = 2.3923e-01, time/batch = 15.9505s	
16533/22950 (epoch 36.020), train_loss = 0.87726209, grad/param norm = 2.4537e-01, time/batch = 15.9480s	
16534/22950 (epoch 36.022), train_loss = 0.75677985, grad/param norm = 2.6779e-01, time/batch = 16.1795s	
16535/22950 (epoch 36.024), train_loss = 0.84210863, grad/param norm = 2.6468e-01, time/batch = 15.9614s	
16536/22950 (epoch 36.026), train_loss = 0.88908149, grad/param norm = 2.4127e-01, time/batch = 15.6504s	
16537/22950 (epoch 36.028), train_loss = 0.92179293, grad/param norm = 2.4014e-01, time/batch = 15.3155s	
16538/22950 (epoch 36.031), train_loss = 0.80974983, grad/param norm = 2.4327e-01, time/batch = 15.5345s	
16539/22950 (epoch 36.033), train_loss = 0.93985773, grad/param norm = 2.6292e-01, time/batch = 15.5432s	
16540/22950 (epoch 36.035), train_loss = 0.83494048, grad/param norm = 2.2999e-01, time/batch = 15.4629s	
16541/22950 (epoch 36.037), train_loss = 0.84707967, grad/param norm = 2.3861e-01, time/batch = 15.7235s	
16542/22950 (epoch 36.039), train_loss = 0.82806169, grad/param norm = 2.3128e-01, time/batch = 16.0353s	
16543/22950 (epoch 36.041), train_loss = 0.78709649, grad/param norm = 2.7415e-01, time/batch = 15.9581s	
16544/22950 (epoch 36.044), train_loss = 0.89030351, grad/param norm = 2.5145e-01, time/batch = 16.2486s	
16545/22950 (epoch 36.046), train_loss = 0.86129929, grad/param norm = 2.6341e-01, time/batch = 15.6361s	
16546/22950 (epoch 36.048), train_loss = 0.85829908, grad/param norm = 2.3575e-01, time/batch = 15.8619s	
16547/22950 (epoch 36.050), train_loss = 0.81121382, grad/param norm = 2.8729e-01, time/batch = 15.3030s	
16548/22950 (epoch 36.052), train_loss = 0.88587751, grad/param norm = 2.4757e-01, time/batch = 15.4549s	
16549/22950 (epoch 36.054), train_loss = 0.96747769, grad/param norm = 2.7349e-01, time/batch = 16.1566s	
16550/22950 (epoch 36.057), train_loss = 0.99046160, grad/param norm = 3.5661e-01, time/batch = 16.1735s	
16551/22950 (epoch 36.059), train_loss = 0.95121009, grad/param norm = 2.7725e-01, time/batch = 16.9051s	
16552/22950 (epoch 36.061), train_loss = 0.80322342, grad/param norm = 2.4523e-01, time/batch = 15.5482s	
16553/22950 (epoch 36.063), train_loss = 0.91317980, grad/param norm = 3.0368e-01, time/batch = 15.7111s	
16554/22950 (epoch 36.065), train_loss = 0.77484113, grad/param norm = 2.5007e-01, time/batch = 16.5316s	
16555/22950 (epoch 36.068), train_loss = 0.88958451, grad/param norm = 2.8070e-01, time/batch = 15.6342s	
16556/22950 (epoch 36.070), train_loss = 0.76978017, grad/param norm = 2.1181e-01, time/batch = 15.3852s	
16557/22950 (epoch 36.072), train_loss = 0.92215242, grad/param norm = 3.0472e-01, time/batch = 16.4121s	
16558/22950 (epoch 36.074), train_loss = 0.90547145, grad/param norm = 2.8204e-01, time/batch = 15.5470s	
16559/22950 (epoch 36.076), train_loss = 0.88492901, grad/param norm = 2.3247e-01, time/batch = 15.4751s	
16560/22950 (epoch 36.078), train_loss = 0.94502855, grad/param norm = 2.3740e-01, time/batch = 15.3984s	
16561/22950 (epoch 36.081), train_loss = 0.97641824, grad/param norm = 2.5946e-01, time/batch = 15.8709s	
16562/22950 (epoch 36.083), train_loss = 0.88826176, grad/param norm = 2.5233e-01, time/batch = 15.8002s	
16563/22950 (epoch 36.085), train_loss = 0.76182227, grad/param norm = 2.5738e-01, time/batch = 16.2578s	
16564/22950 (epoch 36.087), train_loss = 0.78654603, grad/param norm = 2.5835e-01, time/batch = 15.5519s	
16565/22950 (epoch 36.089), train_loss = 0.90792549, grad/param norm = 2.6618e-01, time/batch = 16.1166s	
16566/22950 (epoch 36.092), train_loss = 0.80913361, grad/param norm = 2.5977e-01, time/batch = 15.6381s	
16567/22950 (epoch 36.094), train_loss = 0.81444873, grad/param norm = 2.7096e-01, time/batch = 16.2086s	
16568/22950 (epoch 36.096), train_loss = 0.98048598, grad/param norm = 2.5170e-01, time/batch = 15.9416s	
16569/22950 (epoch 36.098), train_loss = 0.90859880, grad/param norm = 2.5069e-01, time/batch = 16.0428s	
16570/22950 (epoch 36.100), train_loss = 0.84596082, grad/param norm = 2.4648e-01, time/batch = 15.3983s	
16571/22950 (epoch 36.102), train_loss = 0.87129696, grad/param norm = 2.7125e-01, time/batch = 15.7984s	
16572/22950 (epoch 36.105), train_loss = 0.70175108, grad/param norm = 2.1212e-01, time/batch = 16.4168s	
16573/22950 (epoch 36.107), train_loss = 0.78875632, grad/param norm = 2.4125e-01, time/batch = 16.1142s	
16574/22950 (epoch 36.109), train_loss = 0.82537762, grad/param norm = 2.6696e-01, time/batch = 15.6290s	
16575/22950 (epoch 36.111), train_loss = 0.72323341, grad/param norm = 2.3429e-01, time/batch = 16.4724s	
16576/22950 (epoch 36.113), train_loss = 0.88194814, grad/param norm = 2.4429e-01, time/batch = 16.0889s	
16577/22950 (epoch 36.115), train_loss = 0.85705017, grad/param norm = 2.4704e-01, time/batch = 15.6961s	
16578/22950 (epoch 36.118), train_loss = 0.97082595, grad/param norm = 2.3593e-01, time/batch = 15.8618s	
16579/22950 (epoch 36.120), train_loss = 0.77970440, grad/param norm = 2.4625e-01, time/batch = 15.7092s	
16580/22950 (epoch 36.122), train_loss = 0.93233474, grad/param norm = 2.7807e-01, time/batch = 16.4323s	
16581/22950 (epoch 36.124), train_loss = 0.76181694, grad/param norm = 2.3998e-01, time/batch = 15.8572s	
16582/22950 (epoch 36.126), train_loss = 0.86214830, grad/param norm = 2.2826e-01, time/batch = 15.9532s	
16583/22950 (epoch 36.129), train_loss = 0.80167900, grad/param norm = 2.1660e-01, time/batch = 15.8733s	
16584/22950 (epoch 36.131), train_loss = 0.83820977, grad/param norm = 2.2668e-01, time/batch = 16.1864s	
16585/22950 (epoch 36.133), train_loss = 0.89570792, grad/param norm = 2.5181e-01, time/batch = 16.1869s	
16586/22950 (epoch 36.135), train_loss = 0.85225346, grad/param norm = 2.2928e-01, time/batch = 15.5525s	
16587/22950 (epoch 36.137), train_loss = 0.91710906, grad/param norm = 3.2023e-01, time/batch = 15.7205s	
16588/22950 (epoch 36.139), train_loss = 0.76957468, grad/param norm = 2.4237e-01, time/batch = 15.8741s	
16589/22950 (epoch 36.142), train_loss = 0.76158579, grad/param norm = 2.0053e-01, time/batch = 15.4758s	
16590/22950 (epoch 36.144), train_loss = 0.82105312, grad/param norm = 2.4165e-01, time/batch = 15.3097s	
16591/22950 (epoch 36.146), train_loss = 0.77836533, grad/param norm = 2.5008e-01, time/batch = 15.7896s	
16592/22950 (epoch 36.148), train_loss = 0.78700302, grad/param norm = 2.2128e-01, time/batch = 15.4007s	
16593/22950 (epoch 36.150), train_loss = 0.86902983, grad/param norm = 2.2778e-01, time/batch = 15.7067s	
16594/22950 (epoch 36.153), train_loss = 0.78301792, grad/param norm = 2.3954e-01, time/batch = 15.5556s	
16595/22950 (epoch 36.155), train_loss = 0.80133828, grad/param norm = 2.2214e-01, time/batch = 16.9479s	
16596/22950 (epoch 36.157), train_loss = 0.83629339, grad/param norm = 2.3978e-01, time/batch = 15.7070s	
16597/22950 (epoch 36.159), train_loss = 0.77088169, grad/param norm = 2.3643e-01, time/batch = 15.4728s	
16598/22950 (epoch 36.161), train_loss = 0.81563484, grad/param norm = 2.3951e-01, time/batch = 15.6359s	
16599/22950 (epoch 36.163), train_loss = 0.75716372, grad/param norm = 2.3572e-01, time/batch = 15.8791s	
16600/22950 (epoch 36.166), train_loss = 0.89525894, grad/param norm = 3.2599e-01, time/batch = 15.8681s	
16601/22950 (epoch 36.168), train_loss = 0.87776674, grad/param norm = 2.5779e-01, time/batch = 16.6844s	
16602/22950 (epoch 36.170), train_loss = 0.86416949, grad/param norm = 2.6426e-01, time/batch = 16.3648s	
16603/22950 (epoch 36.172), train_loss = 0.83885136, grad/param norm = 2.3242e-01, time/batch = 16.1717s	
16604/22950 (epoch 36.174), train_loss = 0.92309736, grad/param norm = 2.6801e-01, time/batch = 16.1505s	
16605/22950 (epoch 36.176), train_loss = 0.91608901, grad/param norm = 2.7618e-01, time/batch = 15.6953s	
16606/22950 (epoch 36.179), train_loss = 0.89129560, grad/param norm = 2.5639e-01, time/batch = 16.1991s	
16607/22950 (epoch 36.181), train_loss = 1.07387028, grad/param norm = 2.6230e-01, time/batch = 15.3876s	
16608/22950 (epoch 36.183), train_loss = 0.91541894, grad/param norm = 2.6839e-01, time/batch = 15.7166s	
16609/22950 (epoch 36.185), train_loss = 0.90548690, grad/param norm = 2.3566e-01, time/batch = 16.0301s	
16610/22950 (epoch 36.187), train_loss = 0.78162398, grad/param norm = 2.4421e-01, time/batch = 20.8563s	
16611/22950 (epoch 36.190), train_loss = 0.71690122, grad/param norm = 2.5169e-01, time/batch = 17.2798s	
16612/22950 (epoch 36.192), train_loss = 0.67599133, grad/param norm = 2.2735e-01, time/batch = 18.3605s	
16613/22950 (epoch 36.194), train_loss = 0.84083937, grad/param norm = 2.9707e-01, time/batch = 17.2722s	
16614/22950 (epoch 36.196), train_loss = 0.63562248, grad/param norm = 2.3365e-01, time/batch = 18.6319s	
16615/22950 (epoch 36.198), train_loss = 0.88893154, grad/param norm = 2.7760e-01, time/batch = 17.2749s	
16616/22950 (epoch 36.200), train_loss = 0.78858353, grad/param norm = 2.3045e-01, time/batch = 17.0949s	
16617/22950 (epoch 36.203), train_loss = 0.74232891, grad/param norm = 2.5017e-01, time/batch = 20.0222s	
16618/22950 (epoch 36.205), train_loss = 0.79109338, grad/param norm = 2.3110e-01, time/batch = 17.0301s	
16619/22950 (epoch 36.207), train_loss = 0.85277206, grad/param norm = 2.4752e-01, time/batch = 17.9543s	
16620/22950 (epoch 36.209), train_loss = 0.82256912, grad/param norm = 2.5119e-01, time/batch = 18.6937s	
16621/22950 (epoch 36.211), train_loss = 0.71744929, grad/param norm = 2.4072e-01, time/batch = 19.8795s	
16622/22950 (epoch 36.214), train_loss = 0.78402166, grad/param norm = 2.8247e-01, time/batch = 18.7044s	
16623/22950 (epoch 36.216), train_loss = 0.91851773, grad/param norm = 2.3559e-01, time/batch = 18.6179s	
16624/22950 (epoch 36.218), train_loss = 0.82901923, grad/param norm = 2.3095e-01, time/batch = 16.7613s	
16625/22950 (epoch 36.220), train_loss = 0.90104704, grad/param norm = 2.6235e-01, time/batch = 19.4477s	
16626/22950 (epoch 36.222), train_loss = 0.93845827, grad/param norm = 2.8774e-01, time/batch = 16.4047s	
16627/22950 (epoch 36.224), train_loss = 0.84653412, grad/param norm = 2.7828e-01, time/batch = 16.0424s	
16628/22950 (epoch 36.227), train_loss = 0.90452641, grad/param norm = 2.6340e-01, time/batch = 19.8666s	
16629/22950 (epoch 36.229), train_loss = 0.95944740, grad/param norm = 2.4713e-01, time/batch = 17.5253s	
16630/22950 (epoch 36.231), train_loss = 0.70053932, grad/param norm = 2.4922e-01, time/batch = 16.7784s	
16631/22950 (epoch 36.233), train_loss = 0.80000862, grad/param norm = 2.4618e-01, time/batch = 17.8897s	
16632/22950 (epoch 36.235), train_loss = 0.97125780, grad/param norm = 2.4948e-01, time/batch = 19.1267s	
16633/22950 (epoch 36.237), train_loss = 0.79793683, grad/param norm = 2.2982e-01, time/batch = 17.7831s	
16634/22950 (epoch 36.240), train_loss = 0.84474086, grad/param norm = 2.4495e-01, time/batch = 18.7029s	
16635/22950 (epoch 36.242), train_loss = 0.98610724, grad/param norm = 2.4984e-01, time/batch = 16.7749s	
16636/22950 (epoch 36.244), train_loss = 0.96333169, grad/param norm = 2.6608e-01, time/batch = 16.8501s	
16637/22950 (epoch 36.246), train_loss = 0.95779236, grad/param norm = 2.6187e-01, time/batch = 18.6291s	
16638/22950 (epoch 36.248), train_loss = 0.85916014, grad/param norm = 2.7731e-01, time/batch = 18.4589s	
16639/22950 (epoch 36.251), train_loss = 0.78821686, grad/param norm = 2.2143e-01, time/batch = 19.3640s	
16640/22950 (epoch 36.253), train_loss = 0.76835071, grad/param norm = 2.5753e-01, time/batch = 18.5178s	
16641/22950 (epoch 36.255), train_loss = 0.87895431, grad/param norm = 2.4024e-01, time/batch = 18.7842s	
16642/22950 (epoch 36.257), train_loss = 0.93633236, grad/param norm = 2.9117e-01, time/batch = 18.8524s	
16643/22950 (epoch 36.259), train_loss = 0.72623234, grad/param norm = 2.2479e-01, time/batch = 16.2324s	
16644/22950 (epoch 36.261), train_loss = 0.78675584, grad/param norm = 2.6206e-01, time/batch = 16.9351s	
16645/22950 (epoch 36.264), train_loss = 0.75970430, grad/param norm = 2.4107e-01, time/batch = 16.2154s	
16646/22950 (epoch 36.266), train_loss = 0.81822223, grad/param norm = 2.3673e-01, time/batch = 17.0252s	
16647/22950 (epoch 36.268), train_loss = 0.82948360, grad/param norm = 2.5079e-01, time/batch = 20.0432s	
16648/22950 (epoch 36.270), train_loss = 0.83276418, grad/param norm = 2.1663e-01, time/batch = 19.2104s	
16649/22950 (epoch 36.272), train_loss = 0.87121415, grad/param norm = 2.7608e-01, time/batch = 17.9556s	
16650/22950 (epoch 36.275), train_loss = 0.78892183, grad/param norm = 2.3611e-01, time/batch = 17.7820s	
16651/22950 (epoch 36.277), train_loss = 0.72131530, grad/param norm = 2.4675e-01, time/batch = 17.6813s	
16652/22950 (epoch 36.279), train_loss = 0.74829755, grad/param norm = 2.8315e-01, time/batch = 16.5188s	
16653/22950 (epoch 36.281), train_loss = 0.81624032, grad/param norm = 2.7061e-01, time/batch = 18.2817s	
16654/22950 (epoch 36.283), train_loss = 0.73117553, grad/param norm = 2.2449e-01, time/batch = 19.5408s	
16655/22950 (epoch 36.285), train_loss = 0.84839098, grad/param norm = 2.1936e-01, time/batch = 20.2935s	
16656/22950 (epoch 36.288), train_loss = 0.94087372, grad/param norm = 2.6695e-01, time/batch = 18.9252s	
16657/22950 (epoch 36.290), train_loss = 0.81048665, grad/param norm = 2.4323e-01, time/batch = 18.2032s	
16658/22950 (epoch 36.292), train_loss = 0.94268178, grad/param norm = 2.6064e-01, time/batch = 20.4653s	
16659/22950 (epoch 36.294), train_loss = 0.86304479, grad/param norm = 2.3496e-01, time/batch = 18.3728s	
16660/22950 (epoch 36.296), train_loss = 0.66440889, grad/param norm = 1.9783e-01, time/batch = 18.2957s	
16661/22950 (epoch 36.298), train_loss = 0.81224077, grad/param norm = 2.3088e-01, time/batch = 18.1075s	
16662/22950 (epoch 36.301), train_loss = 0.86460445, grad/param norm = 2.5107e-01, time/batch = 18.0669s	
16663/22950 (epoch 36.303), train_loss = 0.81318596, grad/param norm = 2.1962e-01, time/batch = 16.1582s	
16664/22950 (epoch 36.305), train_loss = 0.81330692, grad/param norm = 2.5346e-01, time/batch = 17.3647s	
16665/22950 (epoch 36.307), train_loss = 0.97186101, grad/param norm = 2.9936e-01, time/batch = 18.0373s	
16666/22950 (epoch 36.309), train_loss = 0.79451425, grad/param norm = 2.1453e-01, time/batch = 18.4505s	
16667/22950 (epoch 36.312), train_loss = 0.85066483, grad/param norm = 2.2229e-01, time/batch = 18.1221s	
16668/22950 (epoch 36.314), train_loss = 0.86477060, grad/param norm = 2.3283e-01, time/batch = 16.0011s	
16669/22950 (epoch 36.316), train_loss = 0.81487557, grad/param norm = 2.3815e-01, time/batch = 16.5932s	
16670/22950 (epoch 36.318), train_loss = 0.73525288, grad/param norm = 1.9575e-01, time/batch = 17.3010s	
16671/22950 (epoch 36.320), train_loss = 0.76610506, grad/param norm = 2.0840e-01, time/batch = 19.8738s	
16672/22950 (epoch 36.322), train_loss = 0.80042789, grad/param norm = 2.4958e-01, time/batch = 18.5282s	
16673/22950 (epoch 36.325), train_loss = 0.64299048, grad/param norm = 2.0259e-01, time/batch = 18.3042s	
16674/22950 (epoch 36.327), train_loss = 0.66796204, grad/param norm = 2.0735e-01, time/batch = 18.6945s	
16675/22950 (epoch 36.329), train_loss = 0.77900864, grad/param norm = 2.2391e-01, time/batch = 19.0176s	
16676/22950 (epoch 36.331), train_loss = 0.72769681, grad/param norm = 2.4185e-01, time/batch = 20.2723s	
16677/22950 (epoch 36.333), train_loss = 0.75772613, grad/param norm = 2.3223e-01, time/batch = 18.6123s	
16678/22950 (epoch 36.336), train_loss = 0.80574682, grad/param norm = 2.3638e-01, time/batch = 19.6807s	
16679/22950 (epoch 36.338), train_loss = 0.82226531, grad/param norm = 2.4217e-01, time/batch = 19.1857s	
16680/22950 (epoch 36.340), train_loss = 0.80570312, grad/param norm = 2.7232e-01, time/batch = 18.9613s	
16681/22950 (epoch 36.342), train_loss = 0.98407309, grad/param norm = 2.5418e-01, time/batch = 18.5425s	
16682/22950 (epoch 36.344), train_loss = 0.80565887, grad/param norm = 2.6689e-01, time/batch = 17.4225s	
16683/22950 (epoch 36.346), train_loss = 0.91469991, grad/param norm = 2.9161e-01, time/batch = 17.1744s	
16684/22950 (epoch 36.349), train_loss = 0.83344298, grad/param norm = 2.4846e-01, time/batch = 17.9463s	
16685/22950 (epoch 36.351), train_loss = 0.84297211, grad/param norm = 2.5366e-01, time/batch = 17.0404s	
16686/22950 (epoch 36.353), train_loss = 0.87438998, grad/param norm = 3.0315e-01, time/batch = 17.6172s	
16687/22950 (epoch 36.355), train_loss = 0.92329642, grad/param norm = 2.9816e-01, time/batch = 16.0863s	
16688/22950 (epoch 36.357), train_loss = 0.80702987, grad/param norm = 2.7809e-01, time/batch = 16.5194s	
16689/22950 (epoch 36.359), train_loss = 0.85270335, grad/param norm = 2.8947e-01, time/batch = 16.6701s	
16690/22950 (epoch 36.362), train_loss = 0.87839142, grad/param norm = 2.7119e-01, time/batch = 19.0340s	
16691/22950 (epoch 36.364), train_loss = 0.85285547, grad/param norm = 2.7888e-01, time/batch = 16.1027s	
16692/22950 (epoch 36.366), train_loss = 0.83180576, grad/param norm = 2.2691e-01, time/batch = 18.6875s	
16693/22950 (epoch 36.368), train_loss = 0.90095560, grad/param norm = 3.0767e-01, time/batch = 19.1282s	
16694/22950 (epoch 36.370), train_loss = 0.81854313, grad/param norm = 2.5377e-01, time/batch = 17.1260s	
16695/22950 (epoch 36.373), train_loss = 0.75947952, grad/param norm = 2.2522e-01, time/batch = 16.9394s	
16696/22950 (epoch 36.375), train_loss = 0.95075080, grad/param norm = 2.8849e-01, time/batch = 19.2101s	
16697/22950 (epoch 36.377), train_loss = 0.78034253, grad/param norm = 2.9744e-01, time/batch = 17.3000s	
16698/22950 (epoch 36.379), train_loss = 0.86383914, grad/param norm = 2.7276e-01, time/batch = 18.7138s	
16699/22950 (epoch 36.381), train_loss = 0.74477572, grad/param norm = 2.7782e-01, time/batch = 16.4898s	
16700/22950 (epoch 36.383), train_loss = 0.81460861, grad/param norm = 2.6897e-01, time/batch = 15.8908s	
16701/22950 (epoch 36.386), train_loss = 0.76766861, grad/param norm = 2.6201e-01, time/batch = 15.5138s	
16702/22950 (epoch 36.388), train_loss = 0.88891186, grad/param norm = 2.5083e-01, time/batch = 14.8125s	
16703/22950 (epoch 36.390), train_loss = 0.75054120, grad/param norm = 2.4283e-01, time/batch = 15.2247s	
16704/22950 (epoch 36.392), train_loss = 0.78641721, grad/param norm = 2.3725e-01, time/batch = 14.5953s	
16705/22950 (epoch 36.394), train_loss = 0.79717919, grad/param norm = 2.5007e-01, time/batch = 15.0744s	
16706/22950 (epoch 36.397), train_loss = 0.93618352, grad/param norm = 2.4888e-01, time/batch = 15.3859s	
16707/22950 (epoch 36.399), train_loss = 0.92758806, grad/param norm = 2.7508e-01, time/batch = 15.0626s	
16708/22950 (epoch 36.401), train_loss = 0.97213638, grad/param norm = 2.6936e-01, time/batch = 15.7153s	
16709/22950 (epoch 36.403), train_loss = 0.84389951, grad/param norm = 2.8985e-01, time/batch = 16.0187s	
16710/22950 (epoch 36.405), train_loss = 0.95789631, grad/param norm = 2.7491e-01, time/batch = 17.3048s	
16711/22950 (epoch 36.407), train_loss = 0.99887827, grad/param norm = 2.9174e-01, time/batch = 16.4373s	
16712/22950 (epoch 36.410), train_loss = 0.86213234, grad/param norm = 2.4748e-01, time/batch = 15.6404s	
16713/22950 (epoch 36.412), train_loss = 0.81814461, grad/param norm = 2.5100e-01, time/batch = 16.9766s	
16714/22950 (epoch 36.414), train_loss = 0.94728635, grad/param norm = 2.6380e-01, time/batch = 33.5839s	
16715/22950 (epoch 36.416), train_loss = 0.87031304, grad/param norm = 2.8565e-01, time/batch = 20.1048s	
16716/22950 (epoch 36.418), train_loss = 0.86637725, grad/param norm = 2.8073e-01, time/batch = 16.7586s	
16717/22950 (epoch 36.420), train_loss = 0.92401907, grad/param norm = 3.2239e-01, time/batch = 19.0354s	
16718/22950 (epoch 36.423), train_loss = 0.80851557, grad/param norm = 2.4456e-01, time/batch = 17.0311s	
16719/22950 (epoch 36.425), train_loss = 0.84192356, grad/param norm = 2.4225e-01, time/batch = 18.7069s	
16720/22950 (epoch 36.427), train_loss = 0.86699084, grad/param norm = 2.5097e-01, time/batch = 18.7116s	
16721/22950 (epoch 36.429), train_loss = 0.85582249, grad/param norm = 2.3854e-01, time/batch = 18.2831s	
16722/22950 (epoch 36.431), train_loss = 0.93069113, grad/param norm = 2.6723e-01, time/batch = 19.1129s	
16723/22950 (epoch 36.434), train_loss = 0.85063094, grad/param norm = 2.4187e-01, time/batch = 19.2951s	
16724/22950 (epoch 36.436), train_loss = 0.94386225, grad/param norm = 3.4504e-01, time/batch = 18.5345s	
16725/22950 (epoch 36.438), train_loss = 0.86765689, grad/param norm = 2.5677e-01, time/batch = 17.0910s	
16726/22950 (epoch 36.440), train_loss = 0.93552091, grad/param norm = 2.2711e-01, time/batch = 16.3021s	
16727/22950 (epoch 36.442), train_loss = 0.98079723, grad/param norm = 2.8815e-01, time/batch = 16.0488s	
16728/22950 (epoch 36.444), train_loss = 0.89575763, grad/param norm = 2.7682e-01, time/batch = 16.5196s	
16729/22950 (epoch 36.447), train_loss = 0.98812183, grad/param norm = 2.5894e-01, time/batch = 16.9870s	
16730/22950 (epoch 36.449), train_loss = 0.77023563, grad/param norm = 2.3201e-01, time/batch = 16.6049s	
16731/22950 (epoch 36.451), train_loss = 0.85906590, grad/param norm = 2.8224e-01, time/batch = 16.5478s	
16732/22950 (epoch 36.453), train_loss = 0.87030247, grad/param norm = 2.1729e-01, time/batch = 16.8525s	
16733/22950 (epoch 36.455), train_loss = 0.82301194, grad/param norm = 2.0917e-01, time/batch = 16.6069s	
16734/22950 (epoch 36.458), train_loss = 0.86247819, grad/param norm = 2.4401e-01, time/batch = 16.1160s	
16735/22950 (epoch 36.460), train_loss = 0.91446226, grad/param norm = 2.7063e-01, time/batch = 16.5055s	
16736/22950 (epoch 36.462), train_loss = 0.89745444, grad/param norm = 2.4071e-01, time/batch = 16.8249s	
16737/22950 (epoch 36.464), train_loss = 0.82409262, grad/param norm = 2.3672e-01, time/batch = 16.6127s	
16738/22950 (epoch 36.466), train_loss = 0.93072858, grad/param norm = 2.6325e-01, time/batch = 17.3619s	
16739/22950 (epoch 36.468), train_loss = 0.92797374, grad/param norm = 2.6863e-01, time/batch = 20.1170s	
16740/22950 (epoch 36.471), train_loss = 0.88345631, grad/param norm = 2.6822e-01, time/batch = 17.4412s	
16741/22950 (epoch 36.473), train_loss = 0.89485339, grad/param norm = 2.4711e-01, time/batch = 18.0468s	
16742/22950 (epoch 36.475), train_loss = 1.03667802, grad/param norm = 2.6712e-01, time/batch = 19.8689s	
16743/22950 (epoch 36.477), train_loss = 0.83036984, grad/param norm = 2.3888e-01, time/batch = 17.3563s	
16744/22950 (epoch 36.479), train_loss = 0.73697715, grad/param norm = 2.0108e-01, time/batch = 17.9511s	
16745/22950 (epoch 36.481), train_loss = 0.93129951, grad/param norm = 2.7438e-01, time/batch = 17.8001s	
16746/22950 (epoch 36.484), train_loss = 0.89433015, grad/param norm = 2.8240e-01, time/batch = 18.2108s	
16747/22950 (epoch 36.486), train_loss = 0.76027466, grad/param norm = 2.4412e-01, time/batch = 16.2072s	
16748/22950 (epoch 36.488), train_loss = 0.78936403, grad/param norm = 2.7345e-01, time/batch = 17.8719s	
16749/22950 (epoch 36.490), train_loss = 0.74963931, grad/param norm = 2.4780e-01, time/batch = 18.0369s	
16750/22950 (epoch 36.492), train_loss = 0.82035746, grad/param norm = 2.3006e-01, time/batch = 16.7104s	
16751/22950 (epoch 36.495), train_loss = 0.78264127, grad/param norm = 2.6154e-01, time/batch = 16.3954s	
16752/22950 (epoch 36.497), train_loss = 0.89372999, grad/param norm = 2.5794e-01, time/batch = 15.8754s	
16753/22950 (epoch 36.499), train_loss = 0.96842146, grad/param norm = 2.2688e-01, time/batch = 15.5564s	
16754/22950 (epoch 36.501), train_loss = 0.85512193, grad/param norm = 2.5614e-01, time/batch = 17.9364s	
16755/22950 (epoch 36.503), train_loss = 0.94808764, grad/param norm = 2.4250e-01, time/batch = 16.4866s	
16756/22950 (epoch 36.505), train_loss = 0.71219788, grad/param norm = 2.0629e-01, time/batch = 16.3135s	
16757/22950 (epoch 36.508), train_loss = 0.92254872, grad/param norm = 2.6683e-01, time/batch = 16.8181s	
16758/22950 (epoch 36.510), train_loss = 0.81990666, grad/param norm = 2.1960e-01, time/batch = 16.6175s	
16759/22950 (epoch 36.512), train_loss = 0.74642194, grad/param norm = 2.2646e-01, time/batch = 16.3611s	
16760/22950 (epoch 36.514), train_loss = 0.81973968, grad/param norm = 2.2814e-01, time/batch = 15.4773s	
16761/22950 (epoch 36.516), train_loss = 0.86207719, grad/param norm = 2.4645e-01, time/batch = 16.1142s	
16762/22950 (epoch 36.519), train_loss = 0.84767526, grad/param norm = 2.2541e-01, time/batch = 15.8005s	
16763/22950 (epoch 36.521), train_loss = 0.85071795, grad/param norm = 2.4464e-01, time/batch = 15.9476s	
16764/22950 (epoch 36.523), train_loss = 0.70241223, grad/param norm = 2.3462e-01, time/batch = 16.1905s	
16765/22950 (epoch 36.525), train_loss = 0.77115316, grad/param norm = 2.2409e-01, time/batch = 16.8218s	
16766/22950 (epoch 36.527), train_loss = 0.75079697, grad/param norm = 2.2820e-01, time/batch = 15.6483s	
16767/22950 (epoch 36.529), train_loss = 0.86386333, grad/param norm = 2.5720e-01, time/batch = 15.7872s	
16768/22950 (epoch 36.532), train_loss = 0.81510536, grad/param norm = 2.2381e-01, time/batch = 15.6279s	
16769/22950 (epoch 36.534), train_loss = 0.85462111, grad/param norm = 2.2649e-01, time/batch = 16.1695s	
16770/22950 (epoch 36.536), train_loss = 0.88894893, grad/param norm = 2.8665e-01, time/batch = 16.5460s	
16771/22950 (epoch 36.538), train_loss = 0.85635995, grad/param norm = 2.4573e-01, time/batch = 16.7014s	
16772/22950 (epoch 36.540), train_loss = 0.88433332, grad/param norm = 2.5574e-01, time/batch = 16.2020s	
16773/22950 (epoch 36.542), train_loss = 0.99607803, grad/param norm = 2.7091e-01, time/batch = 15.7907s	
16774/22950 (epoch 36.545), train_loss = 0.82420183, grad/param norm = 2.3531e-01, time/batch = 15.4730s	
16775/22950 (epoch 36.547), train_loss = 0.83097290, grad/param norm = 2.3754e-01, time/batch = 15.4719s	
16776/22950 (epoch 36.549), train_loss = 0.79317596, grad/param norm = 2.8338e-01, time/batch = 16.1222s	
16777/22950 (epoch 36.551), train_loss = 0.84064140, grad/param norm = 2.5698e-01, time/batch = 15.9649s	
16778/22950 (epoch 36.553), train_loss = 0.79468606, grad/param norm = 2.6122e-01, time/batch = 15.6416s	
16779/22950 (epoch 36.556), train_loss = 0.88288850, grad/param norm = 2.2623e-01, time/batch = 15.6484s	
16780/22950 (epoch 36.558), train_loss = 0.70961293, grad/param norm = 2.3547e-01, time/batch = 16.0380s	
16781/22950 (epoch 36.560), train_loss = 0.80554376, grad/param norm = 2.8116e-01, time/batch = 15.9538s	
16782/22950 (epoch 36.562), train_loss = 0.76976886, grad/param norm = 2.0944e-01, time/batch = 15.5721s	
16783/22950 (epoch 36.564), train_loss = 0.89249293, grad/param norm = 2.6949e-01, time/batch = 15.8642s	
16784/22950 (epoch 36.566), train_loss = 0.87349476, grad/param norm = 2.3220e-01, time/batch = 16.5493s	
16785/22950 (epoch 36.569), train_loss = 0.83418664, grad/param norm = 2.3106e-01, time/batch = 16.5605s	
16786/22950 (epoch 36.571), train_loss = 0.78778389, grad/param norm = 2.4479e-01, time/batch = 16.1001s	
16787/22950 (epoch 36.573), train_loss = 0.82436584, grad/param norm = 2.4911e-01, time/batch = 16.4343s	
16788/22950 (epoch 36.575), train_loss = 0.91286151, grad/param norm = 3.1838e-01, time/batch = 15.8130s	
16789/22950 (epoch 36.577), train_loss = 0.85150947, grad/param norm = 2.6936e-01, time/batch = 15.7903s	
16790/22950 (epoch 36.580), train_loss = 0.92126376, grad/param norm = 3.0388e-01, time/batch = 16.4177s	
16791/22950 (epoch 36.582), train_loss = 0.99005637, grad/param norm = 2.8163e-01, time/batch = 16.2630s	
16792/22950 (epoch 36.584), train_loss = 0.73634088, grad/param norm = 3.6214e-01, time/batch = 16.3993s	
16793/22950 (epoch 36.586), train_loss = 0.80108372, grad/param norm = 2.8691e-01, time/batch = 16.0877s	
16794/22950 (epoch 36.588), train_loss = 0.94432070, grad/param norm = 2.8289e-01, time/batch = 15.6407s	
16795/22950 (epoch 36.590), train_loss = 0.91096110, grad/param norm = 2.5265e-01, time/batch = 16.1116s	
16796/22950 (epoch 36.593), train_loss = 0.81898228, grad/param norm = 2.4778e-01, time/batch = 15.6414s	
16797/22950 (epoch 36.595), train_loss = 0.75786665, grad/param norm = 2.2433e-01, time/batch = 15.9374s	
16798/22950 (epoch 36.597), train_loss = 0.91329784, grad/param norm = 2.6122e-01, time/batch = 15.9639s	
16799/22950 (epoch 36.599), train_loss = 0.86036700, grad/param norm = 2.7359e-01, time/batch = 15.8763s	
16800/22950 (epoch 36.601), train_loss = 0.90301093, grad/param norm = 2.4407e-01, time/batch = 15.9651s	
16801/22950 (epoch 36.603), train_loss = 0.96137323, grad/param norm = 2.5269e-01, time/batch = 16.5987s	
16802/22950 (epoch 36.606), train_loss = 0.83386719, grad/param norm = 2.5535e-01, time/batch = 16.5055s	
16803/22950 (epoch 36.608), train_loss = 0.82242242, grad/param norm = 2.4157e-01, time/batch = 15.7259s	
16804/22950 (epoch 36.610), train_loss = 0.83622410, grad/param norm = 2.1766e-01, time/batch = 15.9529s	
16805/22950 (epoch 36.612), train_loss = 0.85202112, grad/param norm = 2.5000e-01, time/batch = 15.7987s	
16806/22950 (epoch 36.614), train_loss = 0.93326946, grad/param norm = 2.6894e-01, time/batch = 16.0150s	
16807/22950 (epoch 36.617), train_loss = 0.83948072, grad/param norm = 2.2503e-01, time/batch = 16.3026s	
16808/22950 (epoch 36.619), train_loss = 0.77818611, grad/param norm = 2.3593e-01, time/batch = 16.5227s	
16809/22950 (epoch 36.621), train_loss = 0.91426637, grad/param norm = 2.4473e-01, time/batch = 16.8845s	
16810/22950 (epoch 36.623), train_loss = 0.91171102, grad/param norm = 2.6744e-01, time/batch = 16.8345s	
16811/22950 (epoch 36.625), train_loss = 0.82079454, grad/param norm = 2.3657e-01, time/batch = 16.2083s	
16812/22950 (epoch 36.627), train_loss = 0.81728228, grad/param norm = 2.5243e-01, time/batch = 16.9597s	
16813/22950 (epoch 36.630), train_loss = 0.74647775, grad/param norm = 2.1847e-01, time/batch = 16.8897s	
16814/22950 (epoch 36.632), train_loss = 0.82053800, grad/param norm = 3.0257e-01, time/batch = 16.5945s	
16815/22950 (epoch 36.634), train_loss = 0.89032243, grad/param norm = 2.7306e-01, time/batch = 16.1830s	
16816/22950 (epoch 36.636), train_loss = 0.84910176, grad/param norm = 2.6289e-01, time/batch = 15.6345s	
16817/22950 (epoch 36.638), train_loss = 0.83750820, grad/param norm = 2.6860e-01, time/batch = 15.8891s	
16818/22950 (epoch 36.641), train_loss = 0.82110570, grad/param norm = 2.4985e-01, time/batch = 15.8781s	
16819/22950 (epoch 36.643), train_loss = 0.87065782, grad/param norm = 2.9112e-01, time/batch = 15.5636s	
16820/22950 (epoch 36.645), train_loss = 0.81017523, grad/param norm = 2.2919e-01, time/batch = 16.0175s	
16821/22950 (epoch 36.647), train_loss = 0.82449779, grad/param norm = 2.6806e-01, time/batch = 15.9590s	
16822/22950 (epoch 36.649), train_loss = 0.78107187, grad/param norm = 2.4049e-01, time/batch = 15.6572s	
16823/22950 (epoch 36.651), train_loss = 0.92454099, grad/param norm = 2.6475e-01, time/batch = 15.5703s	
16824/22950 (epoch 36.654), train_loss = 0.71587692, grad/param norm = 2.0473e-01, time/batch = 15.9709s	
16825/22950 (epoch 36.656), train_loss = 0.88617979, grad/param norm = 2.5516e-01, time/batch = 15.9645s	
16826/22950 (epoch 36.658), train_loss = 0.77306154, grad/param norm = 2.9730e-01, time/batch = 16.0378s	
16827/22950 (epoch 36.660), train_loss = 0.68411652, grad/param norm = 2.4145e-01, time/batch = 16.3536s	
16828/22950 (epoch 36.662), train_loss = 0.70947506, grad/param norm = 2.6934e-01, time/batch = 16.6274s	
16829/22950 (epoch 36.664), train_loss = 0.80898946, grad/param norm = 2.6611e-01, time/batch = 16.6342s	
16830/22950 (epoch 36.667), train_loss = 0.85452464, grad/param norm = 2.7020e-01, time/batch = 15.7244s	
16831/22950 (epoch 36.669), train_loss = 0.85488652, grad/param norm = 2.5830e-01, time/batch = 16.2700s	
16832/22950 (epoch 36.671), train_loss = 0.82143232, grad/param norm = 2.4864e-01, time/batch = 15.8572s	
16833/22950 (epoch 36.673), train_loss = 0.78624433, grad/param norm = 2.5635e-01, time/batch = 15.2326s	
16834/22950 (epoch 36.675), train_loss = 0.85795719, grad/param norm = 2.6938e-01, time/batch = 15.7895s	
16835/22950 (epoch 36.678), train_loss = 0.82880713, grad/param norm = 2.5702e-01, time/batch = 15.4743s	
16836/22950 (epoch 36.680), train_loss = 0.87333621, grad/param norm = 2.2408e-01, time/batch = 15.5358s	
16837/22950 (epoch 36.682), train_loss = 0.83433912, grad/param norm = 2.4490e-01, time/batch = 15.4593s	
16838/22950 (epoch 36.684), train_loss = 0.93274672, grad/param norm = 2.5658e-01, time/batch = 15.2296s	
16839/22950 (epoch 36.686), train_loss = 0.94784144, grad/param norm = 2.5950e-01, time/batch = 15.9339s	
16840/22950 (epoch 36.688), train_loss = 0.87530292, grad/param norm = 2.5786e-01, time/batch = 15.6307s	
16841/22950 (epoch 36.691), train_loss = 0.83565437, grad/param norm = 2.3051e-01, time/batch = 15.5556s	
16842/22950 (epoch 36.693), train_loss = 0.78401133, grad/param norm = 2.6759e-01, time/batch = 15.5504s	
16843/22950 (epoch 36.695), train_loss = 0.96207355, grad/param norm = 3.2792e-01, time/batch = 16.3641s	
16844/22950 (epoch 36.697), train_loss = 0.89910392, grad/param norm = 2.8855e-01, time/batch = 15.7262s	
16845/22950 (epoch 36.699), train_loss = 0.88753191, grad/param norm = 2.7319e-01, time/batch = 16.0302s	
16846/22950 (epoch 36.702), train_loss = 0.92562508, grad/param norm = 3.1894e-01, time/batch = 16.2946s	
16847/22950 (epoch 36.704), train_loss = 0.99920630, grad/param norm = 3.1192e-01, time/batch = 16.5242s	
16848/22950 (epoch 36.706), train_loss = 0.93347846, grad/param norm = 2.6170e-01, time/batch = 16.0216s	
16849/22950 (epoch 36.708), train_loss = 0.74987500, grad/param norm = 2.3760e-01, time/batch = 16.5752s	
16850/22950 (epoch 36.710), train_loss = 0.85900190, grad/param norm = 2.3957e-01, time/batch = 16.3501s	
16851/22950 (epoch 36.712), train_loss = 0.94898438, grad/param norm = 2.7346e-01, time/batch = 15.8635s	
16852/22950 (epoch 36.715), train_loss = 0.89253505, grad/param norm = 3.3380e-01, time/batch = 15.7248s	
16853/22950 (epoch 36.717), train_loss = 0.89999537, grad/param norm = 2.5127e-01, time/batch = 15.6216s	
16854/22950 (epoch 36.719), train_loss = 0.82936542, grad/param norm = 2.6739e-01, time/batch = 16.0263s	
16855/22950 (epoch 36.721), train_loss = 0.92400274, grad/param norm = 3.1025e-01, time/batch = 15.4797s	
16856/22950 (epoch 36.723), train_loss = 0.86678118, grad/param norm = 2.7570e-01, time/batch = 15.2333s	
16857/22950 (epoch 36.725), train_loss = 0.91629276, grad/param norm = 2.8139e-01, time/batch = 15.3074s	
16858/22950 (epoch 36.728), train_loss = 0.83395102, grad/param norm = 2.7541e-01, time/batch = 16.8099s	
16859/22950 (epoch 36.730), train_loss = 0.89162861, grad/param norm = 3.3723e-01, time/batch = 16.5317s	
16860/22950 (epoch 36.732), train_loss = 0.95152619, grad/param norm = 3.0171e-01, time/batch = 16.8352s	
16861/22950 (epoch 36.734), train_loss = 0.82287653, grad/param norm = 2.5254e-01, time/batch = 16.9479s	
16862/22950 (epoch 36.736), train_loss = 0.91037087, grad/param norm = 2.6169e-01, time/batch = 16.7746s	
16863/22950 (epoch 36.739), train_loss = 0.91940558, grad/param norm = 2.8120e-01, time/batch = 16.4039s	
16864/22950 (epoch 36.741), train_loss = 0.92469076, grad/param norm = 2.6950e-01, time/batch = 16.5333s	
16865/22950 (epoch 36.743), train_loss = 1.01820633, grad/param norm = 3.2583e-01, time/batch = 16.6192s	
16866/22950 (epoch 36.745), train_loss = 1.09093458, grad/param norm = 3.2844e-01, time/batch = 16.8016s	
16867/22950 (epoch 36.747), train_loss = 0.93317477, grad/param norm = 2.6741e-01, time/batch = 16.7997s	
16868/22950 (epoch 36.749), train_loss = 0.80634671, grad/param norm = 2.5311e-01, time/batch = 16.7548s	
16869/22950 (epoch 36.752), train_loss = 1.02895191, grad/param norm = 2.6394e-01, time/batch = 17.1720s	
16870/22950 (epoch 36.754), train_loss = 0.89773506, grad/param norm = 2.9525e-01, time/batch = 17.1199s	
16871/22950 (epoch 36.756), train_loss = 0.82880006, grad/param norm = 2.6586e-01, time/batch = 17.0185s	
16872/22950 (epoch 36.758), train_loss = 0.90075974, grad/param norm = 2.5637e-01, time/batch = 16.6010s	
16873/22950 (epoch 36.760), train_loss = 0.88227090, grad/param norm = 2.8038e-01, time/batch = 16.2654s	
16874/22950 (epoch 36.763), train_loss = 0.89391061, grad/param norm = 2.6960e-01, time/batch = 15.6264s	
16875/22950 (epoch 36.765), train_loss = 0.85870348, grad/param norm = 2.6695e-01, time/batch = 15.4709s	
16876/22950 (epoch 36.767), train_loss = 1.06818373, grad/param norm = 3.0991e-01, time/batch = 16.7461s	
16877/22950 (epoch 36.769), train_loss = 0.91253622, grad/param norm = 2.6595e-01, time/batch = 15.8562s	
16878/22950 (epoch 36.771), train_loss = 0.76294638, grad/param norm = 2.3945e-01, time/batch = 15.7219s	
16879/22950 (epoch 36.773), train_loss = 0.67024315, grad/param norm = 2.1392e-01, time/batch = 15.7064s	
16880/22950 (epoch 36.776), train_loss = 0.78315007, grad/param norm = 2.0240e-01, time/batch = 15.7225s	
16881/22950 (epoch 36.778), train_loss = 0.77327211, grad/param norm = 2.2543e-01, time/batch = 16.0128s	
16882/22950 (epoch 36.780), train_loss = 0.88018103, grad/param norm = 2.4987e-01, time/batch = 16.1944s	
16883/22950 (epoch 36.782), train_loss = 0.91841855, grad/param norm = 2.6566e-01, time/batch = 15.7916s	
16884/22950 (epoch 36.784), train_loss = 0.80114511, grad/param norm = 2.4120e-01, time/batch = 15.8838s	
16885/22950 (epoch 36.786), train_loss = 0.86242951, grad/param norm = 2.5337e-01, time/batch = 15.7196s	
16886/22950 (epoch 36.789), train_loss = 0.72795019, grad/param norm = 2.4916e-01, time/batch = 15.5579s	
16887/22950 (epoch 36.791), train_loss = 0.74598321, grad/param norm = 2.2089e-01, time/batch = 15.8632s	
16888/22950 (epoch 36.793), train_loss = 0.94316225, grad/param norm = 2.5023e-01, time/batch = 16.7876s	
16889/22950 (epoch 36.795), train_loss = 0.84139793, grad/param norm = 2.5439e-01, time/batch = 16.1813s	
16890/22950 (epoch 36.797), train_loss = 0.95532532, grad/param norm = 2.4446e-01, time/batch = 15.7920s	
16891/22950 (epoch 36.800), train_loss = 0.78439561, grad/param norm = 2.2302e-01, time/batch = 16.5632s	
16892/22950 (epoch 36.802), train_loss = 0.83992882, grad/param norm = 2.5188e-01, time/batch = 16.7136s	
16893/22950 (epoch 36.804), train_loss = 0.83286604, grad/param norm = 2.3820e-01, time/batch = 16.3685s	
16894/22950 (epoch 36.806), train_loss = 0.72371276, grad/param norm = 2.1901e-01, time/batch = 16.6483s	
16895/22950 (epoch 36.808), train_loss = 0.85448069, grad/param norm = 2.4506e-01, time/batch = 16.8866s	
16896/22950 (epoch 36.810), train_loss = 0.81929485, grad/param norm = 2.4593e-01, time/batch = 16.6209s	
16897/22950 (epoch 36.813), train_loss = 0.69377871, grad/param norm = 2.2693e-01, time/batch = 16.6311s	
16898/22950 (epoch 36.815), train_loss = 0.68586828, grad/param norm = 2.5689e-01, time/batch = 16.9033s	
16899/22950 (epoch 36.817), train_loss = 0.76736039, grad/param norm = 2.1571e-01, time/batch = 16.1028s	
16900/22950 (epoch 36.819), train_loss = 0.81067188, grad/param norm = 2.4112e-01, time/batch = 16.0250s	
16901/22950 (epoch 36.821), train_loss = 0.82577990, grad/param norm = 2.4968e-01, time/batch = 15.7854s	
16902/22950 (epoch 36.824), train_loss = 0.84703593, grad/param norm = 2.1818e-01, time/batch = 16.1961s	
16903/22950 (epoch 36.826), train_loss = 0.89384483, grad/param norm = 2.6672e-01, time/batch = 15.7923s	
16904/22950 (epoch 36.828), train_loss = 0.80740497, grad/param norm = 2.5026e-01, time/batch = 15.6297s	
16905/22950 (epoch 36.830), train_loss = 0.79709493, grad/param norm = 2.3758e-01, time/batch = 15.9472s	
16906/22950 (epoch 36.832), train_loss = 0.85390945, grad/param norm = 2.3887e-01, time/batch = 16.1892s	
16907/22950 (epoch 36.834), train_loss = 0.70683104, grad/param norm = 2.9138e-01, time/batch = 16.0930s	
16908/22950 (epoch 36.837), train_loss = 0.84823588, grad/param norm = 2.4894e-01, time/batch = 15.7179s	
16909/22950 (epoch 36.839), train_loss = 0.72094680, grad/param norm = 2.7171e-01, time/batch = 16.3670s	
16910/22950 (epoch 36.841), train_loss = 0.81219124, grad/param norm = 2.1864e-01, time/batch = 16.5226s	
16911/22950 (epoch 36.843), train_loss = 0.79318129, grad/param norm = 2.6555e-01, time/batch = 16.6748s	
16912/22950 (epoch 36.845), train_loss = 0.83369829, grad/param norm = 2.4258e-01, time/batch = 16.1118s	
16913/22950 (epoch 36.847), train_loss = 0.87054932, grad/param norm = 2.8843e-01, time/batch = 16.7230s	
16914/22950 (epoch 36.850), train_loss = 0.90440036, grad/param norm = 2.4203e-01, time/batch = 16.7983s	
16915/22950 (epoch 36.852), train_loss = 0.90711591, grad/param norm = 2.8249e-01, time/batch = 16.7304s	
16916/22950 (epoch 36.854), train_loss = 0.84918640, grad/param norm = 2.5060e-01, time/batch = 16.8155s	
16917/22950 (epoch 36.856), train_loss = 0.95920622, grad/param norm = 3.0958e-01, time/batch = 15.8876s	
16918/22950 (epoch 36.858), train_loss = 0.91822595, grad/param norm = 2.7355e-01, time/batch = 16.0311s	
16919/22950 (epoch 36.861), train_loss = 0.89743928, grad/param norm = 2.7160e-01, time/batch = 16.0283s	
16920/22950 (epoch 36.863), train_loss = 0.93893237, grad/param norm = 2.7265e-01, time/batch = 15.9654s	
16921/22950 (epoch 36.865), train_loss = 0.97704786, grad/param norm = 2.8042e-01, time/batch = 15.8775s	
16922/22950 (epoch 36.867), train_loss = 0.87519195, grad/param norm = 3.0470e-01, time/batch = 15.8100s	
16923/22950 (epoch 36.869), train_loss = 1.02126649, grad/param norm = 3.0638e-01, time/batch = 15.4029s	
16924/22950 (epoch 36.871), train_loss = 0.89337836, grad/param norm = 3.3119e-01, time/batch = 15.9436s	
16925/22950 (epoch 36.874), train_loss = 0.91044321, grad/param norm = 2.3239e-01, time/batch = 16.2341s	
16926/22950 (epoch 36.876), train_loss = 0.96474392, grad/param norm = 3.1630e-01, time/batch = 16.6471s	
16927/22950 (epoch 36.878), train_loss = 0.88961929, grad/param norm = 3.0402e-01, time/batch = 16.5770s	
16928/22950 (epoch 36.880), train_loss = 1.03478310, grad/param norm = 2.5210e-01, time/batch = 16.4339s	
16929/22950 (epoch 36.882), train_loss = 0.75630939, grad/param norm = 2.2919e-01, time/batch = 16.8822s	
16930/22950 (epoch 36.885), train_loss = 0.89277352, grad/param norm = 2.8605e-01, time/batch = 16.8897s	
16931/22950 (epoch 36.887), train_loss = 0.85050737, grad/param norm = 2.3064e-01, time/batch = 27.1391s	
16932/22950 (epoch 36.889), train_loss = 0.89305681, grad/param norm = 2.5649e-01, time/batch = 19.3128s	
16933/22950 (epoch 36.891), train_loss = 0.80568823, grad/param norm = 2.3322e-01, time/batch = 16.2798s	
16934/22950 (epoch 36.893), train_loss = 0.90105126, grad/param norm = 2.4057e-01, time/batch = 16.7080s	
16935/22950 (epoch 36.895), train_loss = 1.00709789, grad/param norm = 2.7075e-01, time/batch = 15.7959s	
16936/22950 (epoch 36.898), train_loss = 0.91697182, grad/param norm = 2.5242e-01, time/batch = 16.1137s	
16937/22950 (epoch 36.900), train_loss = 0.80596263, grad/param norm = 2.1982e-01, time/batch = 15.7919s	
16938/22950 (epoch 36.902), train_loss = 0.88187194, grad/param norm = 2.4342e-01, time/batch = 16.1947s	
16939/22950 (epoch 36.904), train_loss = 0.88153578, grad/param norm = 2.7138e-01, time/batch = 15.7920s	
16940/22950 (epoch 36.906), train_loss = 0.88945057, grad/param norm = 2.5616e-01, time/batch = 15.7052s	
16941/22950 (epoch 36.908), train_loss = 0.77491080, grad/param norm = 2.3940e-01, time/batch = 16.1127s	
16942/22950 (epoch 36.911), train_loss = 0.71719483, grad/param norm = 2.1878e-01, time/batch = 16.1285s	
16943/22950 (epoch 36.913), train_loss = 0.85278449, grad/param norm = 2.3543e-01, time/batch = 15.6393s	
16944/22950 (epoch 36.915), train_loss = 0.97631159, grad/param norm = 2.6088e-01, time/batch = 15.9364s	
16945/22950 (epoch 36.917), train_loss = 0.76811179, grad/param norm = 2.4313e-01, time/batch = 16.7103s	
16946/22950 (epoch 36.919), train_loss = 0.87540873, grad/param norm = 2.4087e-01, time/batch = 16.5688s	
16947/22950 (epoch 36.922), train_loss = 0.86067592, grad/param norm = 2.4648e-01, time/batch = 16.2513s	
16948/22950 (epoch 36.924), train_loss = 0.90060525, grad/param norm = 2.7673e-01, time/batch = 15.6303s	
16949/22950 (epoch 36.926), train_loss = 0.71511080, grad/param norm = 2.6228e-01, time/batch = 16.4910s	
16950/22950 (epoch 36.928), train_loss = 0.76566780, grad/param norm = 2.2592e-01, time/batch = 16.0231s	
16951/22950 (epoch 36.930), train_loss = 0.77098851, grad/param norm = 2.4316e-01, time/batch = 16.1087s	
16952/22950 (epoch 36.932), train_loss = 0.69664223, grad/param norm = 2.1932e-01, time/batch = 16.0280s	
16953/22950 (epoch 36.935), train_loss = 0.88700382, grad/param norm = 2.4603e-01, time/batch = 16.1207s	
16954/22950 (epoch 36.937), train_loss = 0.85556933, grad/param norm = 2.9242e-01, time/batch = 15.8586s	
16955/22950 (epoch 36.939), train_loss = 0.79987588, grad/param norm = 2.5197e-01, time/batch = 16.5655s	
16956/22950 (epoch 36.941), train_loss = 0.83276751, grad/param norm = 2.6593e-01, time/batch = 15.9402s	
16957/22950 (epoch 36.943), train_loss = 0.85771038, grad/param norm = 2.6762e-01, time/batch = 15.7965s	
16958/22950 (epoch 36.946), train_loss = 0.72176287, grad/param norm = 2.6232e-01, time/batch = 15.5388s	
16959/22950 (epoch 36.948), train_loss = 0.94840166, grad/param norm = 2.7675e-01, time/batch = 15.3855s	
16960/22950 (epoch 36.950), train_loss = 0.82888932, grad/param norm = 2.4447e-01, time/batch = 16.3365s	
16961/22950 (epoch 36.952), train_loss = 0.88654767, grad/param norm = 2.3695e-01, time/batch = 15.5556s	
16962/22950 (epoch 36.954), train_loss = 0.88650562, grad/param norm = 2.5534e-01, time/batch = 15.7926s	
16963/22950 (epoch 36.956), train_loss = 0.79454681, grad/param norm = 2.5212e-01, time/batch = 16.3474s	
16964/22950 (epoch 36.959), train_loss = 0.76455243, grad/param norm = 2.3124e-01, time/batch = 16.2121s	
16965/22950 (epoch 36.961), train_loss = 0.86025624, grad/param norm = 2.7147e-01, time/batch = 15.5641s	
16966/22950 (epoch 36.963), train_loss = 0.86070420, grad/param norm = 2.6007e-01, time/batch = 16.6543s	
16967/22950 (epoch 36.965), train_loss = 0.93374015, grad/param norm = 2.7436e-01, time/batch = 16.9464s	
16968/22950 (epoch 36.967), train_loss = 0.83779382, grad/param norm = 2.5718e-01, time/batch = 16.5849s	
16969/22950 (epoch 36.969), train_loss = 0.74056490, grad/param norm = 2.4602e-01, time/batch = 15.9975s	
16970/22950 (epoch 36.972), train_loss = 0.83566439, grad/param norm = 2.3880e-01, time/batch = 14.5936s	
16971/22950 (epoch 36.974), train_loss = 0.79130390, grad/param norm = 2.3565e-01, time/batch = 15.7967s	
16972/22950 (epoch 36.976), train_loss = 0.85264387, grad/param norm = 2.3975e-01, time/batch = 14.9068s	
16973/22950 (epoch 36.978), train_loss = 0.77748346, grad/param norm = 2.4452e-01, time/batch = 15.2421s	
16974/22950 (epoch 36.980), train_loss = 0.81260754, grad/param norm = 2.5918e-01, time/batch = 15.3179s	
16975/22950 (epoch 36.983), train_loss = 0.87271557, grad/param norm = 2.2782e-01, time/batch = 15.4731s	
16976/22950 (epoch 36.985), train_loss = 0.76064386, grad/param norm = 2.4887e-01, time/batch = 15.0664s	
16977/22950 (epoch 36.987), train_loss = 0.76595116, grad/param norm = 2.1609e-01, time/batch = 15.1595s	
16978/22950 (epoch 36.989), train_loss = 0.85221900, grad/param norm = 2.4181e-01, time/batch = 15.0792s	
16979/22950 (epoch 36.991), train_loss = 0.71908137, grad/param norm = 2.2876e-01, time/batch = 15.5256s	
16980/22950 (epoch 36.993), train_loss = 0.85733520, grad/param norm = 2.4189e-01, time/batch = 15.5282s	
16981/22950 (epoch 36.996), train_loss = 0.82018339, grad/param norm = 2.4261e-01, time/batch = 15.2260s	
16982/22950 (epoch 36.998), train_loss = 0.74681781, grad/param norm = 2.3666e-01, time/batch = 14.9995s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
16983/22950 (epoch 37.000), train_loss = 0.70925354, grad/param norm = 2.2305e-01, time/batch = 15.3991s	
16984/22950 (epoch 37.002), train_loss = 1.00862689, grad/param norm = 2.7072e-01, time/batch = 14.9168s	
16985/22950 (epoch 37.004), train_loss = 0.89191472, grad/param norm = 2.6179e-01, time/batch = 14.7558s	
16986/22950 (epoch 37.007), train_loss = 0.82571817, grad/param norm = 2.5530e-01, time/batch = 15.8787s	
16987/22950 (epoch 37.009), train_loss = 0.96376013, grad/param norm = 2.8338e-01, time/batch = 16.4791s	
16988/22950 (epoch 37.011), train_loss = 0.73127847, grad/param norm = 2.2845e-01, time/batch = 15.6121s	
16989/22950 (epoch 37.013), train_loss = 0.81704088, grad/param norm = 2.9050e-01, time/batch = 15.6908s	
16990/22950 (epoch 37.015), train_loss = 0.87180564, grad/param norm = 2.5404e-01, time/batch = 16.3155s	
16991/22950 (epoch 37.017), train_loss = 0.87496854, grad/param norm = 2.6835e-01, time/batch = 15.9487s	
16992/22950 (epoch 37.020), train_loss = 0.88396688, grad/param norm = 2.4132e-01, time/batch = 14.9091s	
16993/22950 (epoch 37.022), train_loss = 0.75147532, grad/param norm = 2.1377e-01, time/batch = 15.3851s	
16994/22950 (epoch 37.024), train_loss = 0.81129295, grad/param norm = 2.3439e-01, time/batch = 15.4664s	
16995/22950 (epoch 37.026), train_loss = 0.86273342, grad/param norm = 2.2990e-01, time/batch = 15.1556s	
16996/22950 (epoch 37.028), train_loss = 0.90525582, grad/param norm = 2.3973e-01, time/batch = 14.9780s	
16997/22950 (epoch 37.031), train_loss = 0.81701398, grad/param norm = 2.6974e-01, time/batch = 14.8132s	
16998/22950 (epoch 37.033), train_loss = 0.93080279, grad/param norm = 2.8706e-01, time/batch = 15.3042s	
16999/22950 (epoch 37.035), train_loss = 0.84297687, grad/param norm = 2.4773e-01, time/batch = 15.2135s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch37.04_2.0128.t7	
17000/22950 (epoch 37.037), train_loss = 0.83994026, grad/param norm = 2.5338e-01, time/batch = 15.1473s	
17001/22950 (epoch 37.039), train_loss = 1.47414929, grad/param norm = 3.8141e-01, time/batch = 0.7105s	
17002/22950 (epoch 37.041), train_loss = 0.77881916, grad/param norm = 2.6854e-01, time/batch = 0.7310s	
17003/22950 (epoch 37.044), train_loss = 0.89202593, grad/param norm = 3.0282e-01, time/batch = 0.7217s	
17004/22950 (epoch 37.046), train_loss = 0.82947322, grad/param norm = 2.4749e-01, time/batch = 0.7316s	
17005/22950 (epoch 37.048), train_loss = 0.86263905, grad/param norm = 2.6628e-01, time/batch = 0.7413s	
17006/22950 (epoch 37.050), train_loss = 0.80794439, grad/param norm = 3.5742e-01, time/batch = 0.7466s	
17007/22950 (epoch 37.052), train_loss = 0.87363302, grad/param norm = 2.4746e-01, time/batch = 1.0490s	
17008/22950 (epoch 37.054), train_loss = 0.97980126, grad/param norm = 2.9712e-01, time/batch = 1.0456s	
17009/22950 (epoch 37.057), train_loss = 0.95333599, grad/param norm = 2.8722e-01, time/batch = 1.0512s	
17010/22950 (epoch 37.059), train_loss = 0.96221282, grad/param norm = 2.5962e-01, time/batch = 1.0528s	
17011/22950 (epoch 37.061), train_loss = 0.78583090, grad/param norm = 2.2663e-01, time/batch = 1.3256s	
17012/22950 (epoch 37.063), train_loss = 0.90099584, grad/param norm = 2.6837e-01, time/batch = 1.9955s	
17013/22950 (epoch 37.065), train_loss = 0.75938798, grad/param norm = 2.4204e-01, time/batch = 1.9109s	
17014/22950 (epoch 37.068), train_loss = 0.88437767, grad/param norm = 2.5138e-01, time/batch = 11.8882s	
17015/22950 (epoch 37.070), train_loss = 0.75938382, grad/param norm = 2.1902e-01, time/batch = 15.4589s	
17016/22950 (epoch 37.072), train_loss = 0.90517134, grad/param norm = 2.7871e-01, time/batch = 16.0963s	
17017/22950 (epoch 37.074), train_loss = 0.88933923, grad/param norm = 2.5593e-01, time/batch = 16.1378s	
17018/22950 (epoch 37.076), train_loss = 0.88833486, grad/param norm = 2.7419e-01, time/batch = 15.2914s	
17019/22950 (epoch 37.078), train_loss = 0.94969922, grad/param norm = 2.7187e-01, time/batch = 15.0639s	
17020/22950 (epoch 37.081), train_loss = 0.97603920, grad/param norm = 2.6707e-01, time/batch = 15.2887s	
17021/22950 (epoch 37.083), train_loss = 0.87530866, grad/param norm = 2.3705e-01, time/batch = 15.2693s	
17022/22950 (epoch 37.085), train_loss = 0.72850000, grad/param norm = 2.6543e-01, time/batch = 15.6458s	
17023/22950 (epoch 37.087), train_loss = 0.78510226, grad/param norm = 2.7479e-01, time/batch = 15.4076s	
17024/22950 (epoch 37.089), train_loss = 0.90625717, grad/param norm = 2.9233e-01, time/batch = 15.3798s	
17025/22950 (epoch 37.092), train_loss = 0.79341045, grad/param norm = 2.7344e-01, time/batch = 14.8984s	
17026/22950 (epoch 37.094), train_loss = 0.81624542, grad/param norm = 2.7979e-01, time/batch = 15.4582s	
17027/22950 (epoch 37.096), train_loss = 0.96901424, grad/param norm = 2.9382e-01, time/batch = 15.0462s	
17028/22950 (epoch 37.098), train_loss = 0.90218401, grad/param norm = 2.7742e-01, time/batch = 15.1378s	
17029/22950 (epoch 37.100), train_loss = 0.82715669, grad/param norm = 2.4866e-01, time/batch = 15.2231s	
17030/22950 (epoch 37.102), train_loss = 0.86122866, grad/param norm = 2.7647e-01, time/batch = 14.8253s	
17031/22950 (epoch 37.105), train_loss = 0.70543130, grad/param norm = 2.3016e-01, time/batch = 15.0731s	
17032/22950 (epoch 37.107), train_loss = 0.78332186, grad/param norm = 2.3395e-01, time/batch = 15.9153s	
17033/22950 (epoch 37.109), train_loss = 0.81914901, grad/param norm = 2.6627e-01, time/batch = 15.0663s	
17034/22950 (epoch 37.111), train_loss = 0.72814180, grad/param norm = 2.4552e-01, time/batch = 16.0748s	
17035/22950 (epoch 37.113), train_loss = 0.87942094, grad/param norm = 2.4149e-01, time/batch = 16.1955s	
17036/22950 (epoch 37.115), train_loss = 0.85730235, grad/param norm = 2.7608e-01, time/batch = 15.8756s	
17037/22950 (epoch 37.118), train_loss = 0.96264327, grad/param norm = 2.5507e-01, time/batch = 15.7777s	
17038/22950 (epoch 37.120), train_loss = 0.74993593, grad/param norm = 2.2391e-01, time/batch = 15.6910s	
17039/22950 (epoch 37.122), train_loss = 0.89960504, grad/param norm = 2.2652e-01, time/batch = 15.0683s	
17040/22950 (epoch 37.124), train_loss = 0.74636201, grad/param norm = 2.1689e-01, time/batch = 15.3921s	
17041/22950 (epoch 37.126), train_loss = 0.84044270, grad/param norm = 2.3029e-01, time/batch = 15.6144s	
17042/22950 (epoch 37.129), train_loss = 0.78754409, grad/param norm = 2.0978e-01, time/batch = 14.9182s	
17043/22950 (epoch 37.131), train_loss = 0.82021606, grad/param norm = 2.3386e-01, time/batch = 14.8207s	
17044/22950 (epoch 37.133), train_loss = 0.88504001, grad/param norm = 2.4838e-01, time/batch = 14.9765s	
17045/22950 (epoch 37.135), train_loss = 0.84447223, grad/param norm = 2.2684e-01, time/batch = 14.8289s	
17046/22950 (epoch 37.137), train_loss = 0.90870806, grad/param norm = 3.7905e-01, time/batch = 15.9677s	
17047/22950 (epoch 37.139), train_loss = 0.78486412, grad/param norm = 2.3713e-01, time/batch = 17.3153s	
17048/22950 (epoch 37.142), train_loss = 0.75479488, grad/param norm = 2.0455e-01, time/batch = 17.7829s	
17049/22950 (epoch 37.144), train_loss = 0.80954665, grad/param norm = 2.2704e-01, time/batch = 19.7085s	
17050/22950 (epoch 37.146), train_loss = 0.78059651, grad/param norm = 2.6012e-01, time/batch = 19.1267s	
17051/22950 (epoch 37.148), train_loss = 0.77333896, grad/param norm = 2.2724e-01, time/batch = 18.0382s	
17052/22950 (epoch 37.150), train_loss = 0.87113854, grad/param norm = 2.7790e-01, time/batch = 18.6271s	
17053/22950 (epoch 37.153), train_loss = 0.77113244, grad/param norm = 2.3126e-01, time/batch = 17.9460s	
17054/22950 (epoch 37.155), train_loss = 0.79336573, grad/param norm = 2.3041e-01, time/batch = 16.3326s	
17055/22950 (epoch 37.157), train_loss = 0.82729818, grad/param norm = 2.4110e-01, time/batch = 16.5384s	
17056/22950 (epoch 37.159), train_loss = 0.75562298, grad/param norm = 2.4017e-01, time/batch = 15.7518s	
17057/22950 (epoch 37.161), train_loss = 0.79500001, grad/param norm = 2.2043e-01, time/batch = 16.1876s	
17058/22950 (epoch 37.163), train_loss = 0.74248721, grad/param norm = 2.3029e-01, time/batch = 16.4454s	
17059/22950 (epoch 37.166), train_loss = 0.91218879, grad/param norm = 4.4540e-01, time/batch = 19.7794s	
17060/22950 (epoch 37.168), train_loss = 0.86709711, grad/param norm = 3.2164e-01, time/batch = 20.1107s	
17061/22950 (epoch 37.170), train_loss = 0.87871972, grad/param norm = 2.6656e-01, time/batch = 19.0040s	
17062/22950 (epoch 37.172), train_loss = 0.83428770, grad/param norm = 2.7207e-01, time/batch = 19.4729s	
17063/22950 (epoch 37.174), train_loss = 0.91575212, grad/param norm = 2.6497e-01, time/batch = 19.7119s	
17064/22950 (epoch 37.176), train_loss = 0.91133714, grad/param norm = 2.8068e-01, time/batch = 17.8684s	
17065/22950 (epoch 37.179), train_loss = 0.89503831, grad/param norm = 2.7093e-01, time/batch = 18.1434s	
17066/22950 (epoch 37.181), train_loss = 1.08616353, grad/param norm = 2.9493e-01, time/batch = 19.9527s	
17067/22950 (epoch 37.183), train_loss = 0.88817969, grad/param norm = 2.5548e-01, time/batch = 18.8533s	
17068/22950 (epoch 37.185), train_loss = 0.89772371, grad/param norm = 2.5520e-01, time/batch = 18.3670s	
17069/22950 (epoch 37.187), train_loss = 0.77276241, grad/param norm = 2.3467e-01, time/batch = 19.2080s	
17070/22950 (epoch 37.190), train_loss = 0.69370806, grad/param norm = 2.4282e-01, time/batch = 17.7852s	
17071/22950 (epoch 37.192), train_loss = 0.67036070, grad/param norm = 2.1413e-01, time/batch = 18.1222s	
17072/22950 (epoch 37.194), train_loss = 0.82174875, grad/param norm = 2.6633e-01, time/batch = 17.6279s	
17073/22950 (epoch 37.196), train_loss = 0.62971520, grad/param norm = 2.5977e-01, time/batch = 16.7924s	
17074/22950 (epoch 37.198), train_loss = 0.89025613, grad/param norm = 2.9597e-01, time/batch = 16.4308s	
17075/22950 (epoch 37.200), train_loss = 0.77836984, grad/param norm = 2.3673e-01, time/batch = 15.5760s	
17076/22950 (epoch 37.203), train_loss = 0.72473793, grad/param norm = 2.3856e-01, time/batch = 15.5160s	
17077/22950 (epoch 37.205), train_loss = 0.77578333, grad/param norm = 2.4627e-01, time/batch = 16.3728s	
17078/22950 (epoch 37.207), train_loss = 0.86020418, grad/param norm = 2.5393e-01, time/batch = 17.9676s	
17079/22950 (epoch 37.209), train_loss = 0.82730826, grad/param norm = 3.0612e-01, time/batch = 17.3508s	
17080/22950 (epoch 37.211), train_loss = 0.70886979, grad/param norm = 2.3797e-01, time/batch = 17.6959s	
17081/22950 (epoch 37.214), train_loss = 0.75841043, grad/param norm = 2.2576e-01, time/batch = 19.1796s	
17082/22950 (epoch 37.216), train_loss = 0.92369497, grad/param norm = 2.3148e-01, time/batch = 17.1214s	
17083/22950 (epoch 37.218), train_loss = 0.82076493, grad/param norm = 2.3398e-01, time/batch = 20.0179s	
17084/22950 (epoch 37.220), train_loss = 0.88774043, grad/param norm = 2.4835e-01, time/batch = 17.2904s	
17085/22950 (epoch 37.222), train_loss = 0.92297109, grad/param norm = 2.6606e-01, time/batch = 18.6292s	
17086/22950 (epoch 37.224), train_loss = 0.83096315, grad/param norm = 2.5148e-01, time/batch = 16.4199s	
17087/22950 (epoch 37.227), train_loss = 0.88278446, grad/param norm = 2.4741e-01, time/batch = 18.0224s	
17088/22950 (epoch 37.229), train_loss = 0.94523706, grad/param norm = 2.6636e-01, time/batch = 20.2765s	
17089/22950 (epoch 37.231), train_loss = 0.68007720, grad/param norm = 2.2216e-01, time/batch = 18.3722s	
17090/22950 (epoch 37.233), train_loss = 0.78573609, grad/param norm = 2.4085e-01, time/batch = 16.1631s	
17091/22950 (epoch 37.235), train_loss = 0.95738869, grad/param norm = 2.3423e-01, time/batch = 18.9429s	
17092/22950 (epoch 37.237), train_loss = 0.77921870, grad/param norm = 2.3766e-01, time/batch = 17.2590s	
17093/22950 (epoch 37.240), train_loss = 0.83666804, grad/param norm = 2.6921e-01, time/batch = 16.1875s	
17094/22950 (epoch 37.242), train_loss = 0.97408405, grad/param norm = 2.4547e-01, time/batch = 16.5697s	
17095/22950 (epoch 37.244), train_loss = 0.94941266, grad/param norm = 2.9198e-01, time/batch = 15.7245s	
17096/22950 (epoch 37.246), train_loss = 0.95513248, grad/param norm = 2.9198e-01, time/batch = 16.1742s	
17097/22950 (epoch 37.248), train_loss = 0.86870052, grad/param norm = 2.9573e-01, time/batch = 15.7157s	
17098/22950 (epoch 37.251), train_loss = 0.78401673, grad/param norm = 2.6041e-01, time/batch = 15.8822s	
17099/22950 (epoch 37.253), train_loss = 0.76003383, grad/param norm = 2.8024e-01, time/batch = 15.5589s	
17100/22950 (epoch 37.255), train_loss = 0.89357262, grad/param norm = 2.7723e-01, time/batch = 15.8600s	
17101/22950 (epoch 37.257), train_loss = 0.92226705, grad/param norm = 2.6814e-01, time/batch = 15.8741s	
17102/22950 (epoch 37.259), train_loss = 0.70346042, grad/param norm = 2.3455e-01, time/batch = 15.7940s	
17103/22950 (epoch 37.261), train_loss = 0.77727039, grad/param norm = 2.6041e-01, time/batch = 16.0456s	
17104/22950 (epoch 37.264), train_loss = 0.73916414, grad/param norm = 2.0696e-01, time/batch = 16.1337s	
17105/22950 (epoch 37.266), train_loss = 0.78806320, grad/param norm = 2.3276e-01, time/batch = 15.7922s	
17106/22950 (epoch 37.268), train_loss = 0.81381744, grad/param norm = 2.6124e-01, time/batch = 15.4663s	
17107/22950 (epoch 37.270), train_loss = 0.81692610, grad/param norm = 2.5752e-01, time/batch = 15.6398s	
17108/22950 (epoch 37.272), train_loss = 0.84910576, grad/param norm = 2.5746e-01, time/batch = 16.5068s	
17109/22950 (epoch 37.275), train_loss = 0.79302681, grad/param norm = 2.7804e-01, time/batch = 16.0234s	
17110/22950 (epoch 37.277), train_loss = 0.70908684, grad/param norm = 2.3505e-01, time/batch = 15.7234s	
17111/22950 (epoch 37.279), train_loss = 0.72905187, grad/param norm = 2.6918e-01, time/batch = 16.1096s	
17112/22950 (epoch 37.281), train_loss = 0.80705122, grad/param norm = 2.4362e-01, time/batch = 15.8361s	
17113/22950 (epoch 37.283), train_loss = 0.73145607, grad/param norm = 2.2678e-01, time/batch = 16.8192s	
17114/22950 (epoch 37.285), train_loss = 0.84126281, grad/param norm = 2.2503e-01, time/batch = 16.5750s	
17115/22950 (epoch 37.288), train_loss = 0.93482831, grad/param norm = 2.5477e-01, time/batch = 15.9583s	
17116/22950 (epoch 37.290), train_loss = 0.79864544, grad/param norm = 2.4510e-01, time/batch = 15.8819s	
17117/22950 (epoch 37.292), train_loss = 0.93095576, grad/param norm = 2.6174e-01, time/batch = 16.2784s	
17118/22950 (epoch 37.294), train_loss = 0.86139477, grad/param norm = 2.3284e-01, time/batch = 15.8844s	
17119/22950 (epoch 37.296), train_loss = 0.66713962, grad/param norm = 2.0569e-01, time/batch = 15.4703s	
17120/22950 (epoch 37.298), train_loss = 0.81402705, grad/param norm = 2.2170e-01, time/batch = 15.5437s	
17121/22950 (epoch 37.301), train_loss = 0.85304298, grad/param norm = 2.7031e-01, time/batch = 16.0453s	
17122/22950 (epoch 37.303), train_loss = 0.80765042, grad/param norm = 2.3564e-01, time/batch = 15.7240s	
17123/22950 (epoch 37.305), train_loss = 0.82023094, grad/param norm = 2.7091e-01, time/batch = 15.8938s	
17124/22950 (epoch 37.307), train_loss = 0.95004104, grad/param norm = 2.8336e-01, time/batch = 16.3938s	
17125/22950 (epoch 37.309), train_loss = 0.78869196, grad/param norm = 2.4256e-01, time/batch = 15.8751s	
17126/22950 (epoch 37.312), train_loss = 0.83890770, grad/param norm = 2.2369e-01, time/batch = 15.6998s	
17127/22950 (epoch 37.314), train_loss = 0.84794722, grad/param norm = 2.3494e-01, time/batch = 15.5529s	
17128/22950 (epoch 37.316), train_loss = 0.80714091, grad/param norm = 2.5886e-01, time/batch = 16.5582s	
17129/22950 (epoch 37.318), train_loss = 0.72949256, grad/param norm = 2.0670e-01, time/batch = 16.5648s	
17130/22950 (epoch 37.320), train_loss = 0.76858552, grad/param norm = 2.1752e-01, time/batch = 16.4292s	
17131/22950 (epoch 37.322), train_loss = 0.79022963, grad/param norm = 2.4205e-01, time/batch = 15.9644s	
17132/22950 (epoch 37.325), train_loss = 0.63306431, grad/param norm = 2.0879e-01, time/batch = 15.5616s	
17133/22950 (epoch 37.327), train_loss = 0.64542161, grad/param norm = 2.0143e-01, time/batch = 15.6230s	
17134/22950 (epoch 37.329), train_loss = 0.76345093, grad/param norm = 2.4055e-01, time/batch = 15.2217s	
17135/22950 (epoch 37.331), train_loss = 0.72495798, grad/param norm = 2.5885e-01, time/batch = 15.7899s	
17136/22950 (epoch 37.333), train_loss = 0.75584211, grad/param norm = 2.4331e-01, time/batch = 16.1363s	
17137/22950 (epoch 37.336), train_loss = 0.79880443, grad/param norm = 2.6544e-01, time/batch = 16.8210s	
17138/22950 (epoch 37.338), train_loss = 0.82424386, grad/param norm = 2.2862e-01, time/batch = 15.8175s	
17139/22950 (epoch 37.340), train_loss = 0.78437918, grad/param norm = 2.5729e-01, time/batch = 16.8189s	
17140/22950 (epoch 37.342), train_loss = 0.98803225, grad/param norm = 2.5484e-01, time/batch = 15.8168s	
17141/22950 (epoch 37.344), train_loss = 0.79408569, grad/param norm = 2.5005e-01, time/batch = 16.5981s	
17142/22950 (epoch 37.346), train_loss = 0.91094878, grad/param norm = 2.8299e-01, time/batch = 16.9007s	
17143/22950 (epoch 37.349), train_loss = 0.81848700, grad/param norm = 2.3284e-01, time/batch = 16.3825s	
17144/22950 (epoch 37.351), train_loss = 0.84140094, grad/param norm = 2.9712e-01, time/batch = 16.4556s	
17145/22950 (epoch 37.353), train_loss = 0.86519842, grad/param norm = 3.1305e-01, time/batch = 16.2903s	
17146/22950 (epoch 37.355), train_loss = 0.90830917, grad/param norm = 2.8702e-01, time/batch = 16.6342s	
17147/22950 (epoch 37.357), train_loss = 0.79542450, grad/param norm = 2.6558e-01, time/batch = 16.8911s	
17148/22950 (epoch 37.359), train_loss = 0.83276171, grad/param norm = 2.6634e-01, time/batch = 16.2972s	
17149/22950 (epoch 37.362), train_loss = 0.86544571, grad/param norm = 2.8979e-01, time/batch = 16.2095s	
17150/22950 (epoch 37.364), train_loss = 0.83084481, grad/param norm = 2.8109e-01, time/batch = 16.6153s	
17151/22950 (epoch 37.366), train_loss = 0.85134700, grad/param norm = 2.4906e-01, time/batch = 16.6027s	
17152/22950 (epoch 37.368), train_loss = 0.87931002, grad/param norm = 2.8578e-01, time/batch = 16.6030s	
17153/22950 (epoch 37.370), train_loss = 0.80307800, grad/param norm = 2.5853e-01, time/batch = 16.0370s	
17154/22950 (epoch 37.373), train_loss = 0.75864308, grad/param norm = 2.3339e-01, time/batch = 15.9696s	
17155/22950 (epoch 37.375), train_loss = 0.93177977, grad/param norm = 2.7219e-01, time/batch = 15.7131s	
17156/22950 (epoch 37.377), train_loss = 0.76007464, grad/param norm = 2.4929e-01, time/batch = 15.4765s	
17157/22950 (epoch 37.379), train_loss = 0.83894022, grad/param norm = 2.5069e-01, time/batch = 23.9136s	
17158/22950 (epoch 37.381), train_loss = 0.73058972, grad/param norm = 2.3345e-01, time/batch = 22.3012s	
17159/22950 (epoch 37.383), train_loss = 0.80230675, grad/param norm = 2.5631e-01, time/batch = 15.4761s	
17160/22950 (epoch 37.386), train_loss = 0.75842344, grad/param norm = 2.6136e-01, time/batch = 16.2565s	
17161/22950 (epoch 37.388), train_loss = 0.86574136, grad/param norm = 2.4618e-01, time/batch = 15.4768s	
17162/22950 (epoch 37.390), train_loss = 0.74664436, grad/param norm = 2.5840e-01, time/batch = 15.7053s	
17163/22950 (epoch 37.392), train_loss = 0.78620176, grad/param norm = 2.5633e-01, time/batch = 16.5432s	
17164/22950 (epoch 37.394), train_loss = 0.79789630, grad/param norm = 2.3297e-01, time/batch = 16.1742s	
17165/22950 (epoch 37.397), train_loss = 0.93064727, grad/param norm = 2.5162e-01, time/batch = 16.0835s	
17166/22950 (epoch 37.399), train_loss = 0.91130418, grad/param norm = 2.9596e-01, time/batch = 16.0113s	
17167/22950 (epoch 37.401), train_loss = 0.97886462, grad/param norm = 3.6056e-01, time/batch = 16.7792s	
17168/22950 (epoch 37.403), train_loss = 0.81691711, grad/param norm = 2.3963e-01, time/batch = 16.3518s	
17169/22950 (epoch 37.405), train_loss = 0.95840920, grad/param norm = 4.1013e-01, time/batch = 15.7999s	
17170/22950 (epoch 37.407), train_loss = 1.01653834, grad/param norm = 2.6678e-01, time/batch = 15.9548s	
17171/22950 (epoch 37.410), train_loss = 0.85439520, grad/param norm = 2.4804e-01, time/batch = 16.0976s	
17172/22950 (epoch 37.412), train_loss = 0.83024078, grad/param norm = 3.1812e-01, time/batch = 15.7163s	
17173/22950 (epoch 37.414), train_loss = 0.94280331, grad/param norm = 3.4302e-01, time/batch = 15.7104s	
17174/22950 (epoch 37.416), train_loss = 0.88388880, grad/param norm = 3.0416e-01, time/batch = 15.7973s	
17175/22950 (epoch 37.418), train_loss = 0.85202937, grad/param norm = 2.9150e-01, time/batch = 16.2770s	
17176/22950 (epoch 37.420), train_loss = 0.90429766, grad/param norm = 2.7833e-01, time/batch = 15.8693s	
17177/22950 (epoch 37.423), train_loss = 0.79211757, grad/param norm = 2.4797e-01, time/batch = 15.3129s	
17178/22950 (epoch 37.425), train_loss = 0.82467663, grad/param norm = 2.5690e-01, time/batch = 15.3917s	
17179/22950 (epoch 37.427), train_loss = 0.86266943, grad/param norm = 2.5407e-01, time/batch = 16.3373s	
17180/22950 (epoch 37.429), train_loss = 0.83889979, grad/param norm = 2.3679e-01, time/batch = 15.7162s	
17181/22950 (epoch 37.431), train_loss = 0.92405252, grad/param norm = 2.7295e-01, time/batch = 16.4166s	
17182/22950 (epoch 37.434), train_loss = 0.85193176, grad/param norm = 2.4938e-01, time/batch = 15.7224s	
17183/22950 (epoch 37.436), train_loss = 0.92991574, grad/param norm = 3.4410e-01, time/batch = 16.1100s	
17184/22950 (epoch 37.438), train_loss = 0.83785212, grad/param norm = 2.4514e-01, time/batch = 16.2504s	
17185/22950 (epoch 37.440), train_loss = 0.93438603, grad/param norm = 2.5343e-01, time/batch = 15.7026s	
17186/22950 (epoch 37.442), train_loss = 0.97647638, grad/param norm = 3.0370e-01, time/batch = 15.4704s	
17187/22950 (epoch 37.444), train_loss = 0.89626274, grad/param norm = 2.6947e-01, time/batch = 15.3796s	
17188/22950 (epoch 37.447), train_loss = 1.01591152, grad/param norm = 2.9794e-01, time/batch = 15.4653s	
17189/22950 (epoch 37.449), train_loss = 0.77372792, grad/param norm = 2.3181e-01, time/batch = 16.4836s	
17190/22950 (epoch 37.451), train_loss = 0.85002567, grad/param norm = 2.6491e-01, time/batch = 16.3991s	
17191/22950 (epoch 37.453), train_loss = 0.87581513, grad/param norm = 2.4890e-01, time/batch = 16.2529s	
17192/22950 (epoch 37.455), train_loss = 0.82626942, grad/param norm = 2.1506e-01, time/batch = 16.1892s	
17193/22950 (epoch 37.458), train_loss = 0.86031881, grad/param norm = 2.7671e-01, time/batch = 15.6174s	
17194/22950 (epoch 37.460), train_loss = 0.89577275, grad/param norm = 2.9179e-01, time/batch = 16.1018s	
17195/22950 (epoch 37.462), train_loss = 0.89241117, grad/param norm = 2.5088e-01, time/batch = 15.8699s	
17196/22950 (epoch 37.464), train_loss = 0.81035680, grad/param norm = 2.4083e-01, time/batch = 15.4638s	
17197/22950 (epoch 37.466), train_loss = 0.93872992, grad/param norm = 2.9208e-01, time/batch = 15.4484s	
17198/22950 (epoch 37.468), train_loss = 0.91816168, grad/param norm = 2.6355e-01, time/batch = 15.7908s	
17199/22950 (epoch 37.471), train_loss = 0.87938648, grad/param norm = 2.8958e-01, time/batch = 15.1550s	
17200/22950 (epoch 37.473), train_loss = 0.90378081, grad/param norm = 2.9181e-01, time/batch = 15.9379s	
17201/22950 (epoch 37.475), train_loss = 1.03421852, grad/param norm = 2.7714e-01, time/batch = 15.7739s	
17202/22950 (epoch 37.477), train_loss = 0.84394992, grad/param norm = 3.3802e-01, time/batch = 18.6581s	
17203/22950 (epoch 37.479), train_loss = 0.73871466, grad/param norm = 2.2776e-01, time/batch = 18.2082s	
17204/22950 (epoch 37.481), train_loss = 0.92929255, grad/param norm = 3.0569e-01, time/batch = 16.2466s	
17205/22950 (epoch 37.484), train_loss = 0.88847770, grad/param norm = 2.6032e-01, time/batch = 17.0052s	
17206/22950 (epoch 37.486), train_loss = 0.75358476, grad/param norm = 2.8148e-01, time/batch = 17.7701s	
17207/22950 (epoch 37.488), train_loss = 0.77692224, grad/param norm = 2.8544e-01, time/batch = 16.0475s	
17208/22950 (epoch 37.490), train_loss = 0.71639355, grad/param norm = 2.4203e-01, time/batch = 16.3909s	
17209/22950 (epoch 37.492), train_loss = 0.81272297, grad/param norm = 2.3628e-01, time/batch = 17.2710s	
17210/22950 (epoch 37.495), train_loss = 0.77012478, grad/param norm = 2.2929e-01, time/batch = 19.1960s	
17211/22950 (epoch 37.497), train_loss = 0.86830951, grad/param norm = 2.8680e-01, time/batch = 15.5546s	
17212/22950 (epoch 37.499), train_loss = 0.95964933, grad/param norm = 2.4265e-01, time/batch = 18.6630s	
17213/22950 (epoch 37.501), train_loss = 0.85408673, grad/param norm = 2.4089e-01, time/batch = 17.6275s	
17214/22950 (epoch 37.503), train_loss = 0.94769580, grad/param norm = 2.6380e-01, time/batch = 20.5247s	
17215/22950 (epoch 37.505), train_loss = 0.71225752, grad/param norm = 2.5311e-01, time/batch = 17.3429s	
17216/22950 (epoch 37.508), train_loss = 0.91922523, grad/param norm = 2.7835e-01, time/batch = 19.6293s	
17217/22950 (epoch 37.510), train_loss = 0.80711910, grad/param norm = 2.3805e-01, time/batch = 17.5256s	
17218/22950 (epoch 37.512), train_loss = 0.73810105, grad/param norm = 2.5994e-01, time/batch = 18.5368s	
17219/22950 (epoch 37.514), train_loss = 0.80709186, grad/param norm = 2.1083e-01, time/batch = 18.6142s	
17220/22950 (epoch 37.516), train_loss = 0.84531686, grad/param norm = 2.3392e-01, time/batch = 19.0562s	
17221/22950 (epoch 37.519), train_loss = 0.84621025, grad/param norm = 2.5706e-01, time/batch = 18.6114s	
17222/22950 (epoch 37.521), train_loss = 0.85311884, grad/param norm = 2.7225e-01, time/batch = 18.7793s	
17223/22950 (epoch 37.523), train_loss = 0.68311147, grad/param norm = 2.2497e-01, time/batch = 18.7182s	
17224/22950 (epoch 37.525), train_loss = 0.75576766, grad/param norm = 2.2402e-01, time/batch = 18.7689s	
17225/22950 (epoch 37.527), train_loss = 0.73809353, grad/param norm = 2.1878e-01, time/batch = 16.7371s	
17226/22950 (epoch 37.529), train_loss = 0.84924959, grad/param norm = 2.8025e-01, time/batch = 16.5624s	
17227/22950 (epoch 37.532), train_loss = 0.82189249, grad/param norm = 2.6298e-01, time/batch = 16.5092s	
17228/22950 (epoch 37.534), train_loss = 0.85151177, grad/param norm = 2.3451e-01, time/batch = 16.3505s	
17229/22950 (epoch 37.536), train_loss = 0.89011433, grad/param norm = 2.9493e-01, time/batch = 16.5530s	
17230/22950 (epoch 37.538), train_loss = 0.83753520, grad/param norm = 2.5144e-01, time/batch = 16.4568s	
17231/22950 (epoch 37.540), train_loss = 0.87285518, grad/param norm = 2.5668e-01, time/batch = 17.2033s	
17232/22950 (epoch 37.542), train_loss = 1.01088586, grad/param norm = 3.1264e-01, time/batch = 15.6491s	
17233/22950 (epoch 37.545), train_loss = 0.82369652, grad/param norm = 2.2323e-01, time/batch = 17.6201s	
17234/22950 (epoch 37.547), train_loss = 0.81515918, grad/param norm = 2.3680e-01, time/batch = 17.1099s	
17235/22950 (epoch 37.549), train_loss = 0.78459262, grad/param norm = 2.6924e-01, time/batch = 17.3574s	
17236/22950 (epoch 37.551), train_loss = 0.80982269, grad/param norm = 2.5688e-01, time/batch = 19.2672s	
17237/22950 (epoch 37.553), train_loss = 0.79312630, grad/param norm = 2.8018e-01, time/batch = 19.8814s	
17238/22950 (epoch 37.556), train_loss = 0.87011768, grad/param norm = 2.2623e-01, time/batch = 19.0300s	
17239/22950 (epoch 37.558), train_loss = 0.69097966, grad/param norm = 2.2620e-01, time/batch = 20.3719s	
17240/22950 (epoch 37.560), train_loss = 0.81243378, grad/param norm = 2.6199e-01, time/batch = 17.8937s	
17241/22950 (epoch 37.562), train_loss = 0.77660787, grad/param norm = 2.3620e-01, time/batch = 16.8487s	
17242/22950 (epoch 37.564), train_loss = 0.87495932, grad/param norm = 3.3499e-01, time/batch = 17.9562s	
17243/22950 (epoch 37.566), train_loss = 0.86777540, grad/param norm = 2.6499e-01, time/batch = 16.7540s	
17244/22950 (epoch 37.569), train_loss = 0.82568479, grad/param norm = 2.6773e-01, time/batch = 15.8398s	
17245/22950 (epoch 37.571), train_loss = 0.79318543, grad/param norm = 2.4184e-01, time/batch = 18.3558s	
17246/22950 (epoch 37.573), train_loss = 0.82326852, grad/param norm = 2.7795e-01, time/batch = 19.0170s	
17247/22950 (epoch 37.575), train_loss = 0.89974045, grad/param norm = 3.0456e-01, time/batch = 17.5491s	
17248/22950 (epoch 37.577), train_loss = 0.83833108, grad/param norm = 2.9184e-01, time/batch = 17.4431s	
17249/22950 (epoch 37.580), train_loss = 0.90943679, grad/param norm = 3.0345e-01, time/batch = 17.6133s	
17250/22950 (epoch 37.582), train_loss = 0.99442310, grad/param norm = 2.9203e-01, time/batch = 18.8776s	
17251/22950 (epoch 37.584), train_loss = 0.73411674, grad/param norm = 2.6319e-01, time/batch = 15.6012s	
17252/22950 (epoch 37.586), train_loss = 0.76920192, grad/param norm = 2.4684e-01, time/batch = 19.1049s	
17253/22950 (epoch 37.588), train_loss = 0.93992717, grad/param norm = 2.8760e-01, time/batch = 19.5444s	
17254/22950 (epoch 37.590), train_loss = 0.89656310, grad/param norm = 2.6806e-01, time/batch = 19.8807s	
17255/22950 (epoch 37.593), train_loss = 0.81968342, grad/param norm = 2.6186e-01, time/batch = 17.2861s	
17256/22950 (epoch 37.595), train_loss = 0.76075032, grad/param norm = 2.7838e-01, time/batch = 19.5467s	
17257/22950 (epoch 37.597), train_loss = 0.90839176, grad/param norm = 2.8680e-01, time/batch = 19.1973s	
17258/22950 (epoch 37.599), train_loss = 0.84483855, grad/param norm = 2.6517e-01, time/batch = 17.5114s	
17259/22950 (epoch 37.601), train_loss = 0.88432341, grad/param norm = 2.6365e-01, time/batch = 15.9211s	
17260/22950 (epoch 37.603), train_loss = 0.94956676, grad/param norm = 2.5795e-01, time/batch = 16.4559s	
17261/22950 (epoch 37.606), train_loss = 0.81181962, grad/param norm = 2.3255e-01, time/batch = 15.7218s	
17262/22950 (epoch 37.608), train_loss = 0.80249997, grad/param norm = 2.3003e-01, time/batch = 16.5037s	
17263/22950 (epoch 37.610), train_loss = 0.82647378, grad/param norm = 2.1902e-01, time/batch = 16.4909s	
17264/22950 (epoch 37.612), train_loss = 0.83955334, grad/param norm = 2.5988e-01, time/batch = 15.5663s	
17265/22950 (epoch 37.614), train_loss = 0.93795634, grad/param norm = 3.2041e-01, time/batch = 15.8680s	
17266/22950 (epoch 37.617), train_loss = 0.84632843, grad/param norm = 2.5503e-01, time/batch = 16.4195s	
17267/22950 (epoch 37.619), train_loss = 0.77332996, grad/param norm = 2.3757e-01, time/batch = 15.6364s	
17268/22950 (epoch 37.621), train_loss = 0.88877627, grad/param norm = 2.3097e-01, time/batch = 15.9505s	
17269/22950 (epoch 37.623), train_loss = 0.89461362, grad/param norm = 2.5277e-01, time/batch = 15.8714s	
17270/22950 (epoch 37.625), train_loss = 0.83345360, grad/param norm = 2.6174e-01, time/batch = 15.8766s	
17271/22950 (epoch 37.627), train_loss = 0.79913489, grad/param norm = 2.4845e-01, time/batch = 16.0289s	
17272/22950 (epoch 37.630), train_loss = 0.73598877, grad/param norm = 2.1798e-01, time/batch = 15.5591s	
17273/22950 (epoch 37.632), train_loss = 0.78023894, grad/param norm = 2.3462e-01, time/batch = 16.1120s	
17274/22950 (epoch 37.634), train_loss = 0.86957187, grad/param norm = 2.4803e-01, time/batch = 15.6414s	
17275/22950 (epoch 37.636), train_loss = 0.83979808, grad/param norm = 2.4231e-01, time/batch = 15.7179s	
17276/22950 (epoch 37.638), train_loss = 0.81912306, grad/param norm = 2.4451e-01, time/batch = 16.4875s	
17277/22950 (epoch 37.641), train_loss = 0.79951794, grad/param norm = 2.6217e-01, time/batch = 16.0412s	
17278/22950 (epoch 37.643), train_loss = 0.86398119, grad/param norm = 3.0942e-01, time/batch = 15.9627s	
17279/22950 (epoch 37.645), train_loss = 0.80701496, grad/param norm = 2.4401e-01, time/batch = 15.6469s	
17280/22950 (epoch 37.647), train_loss = 0.81799578, grad/param norm = 2.8602e-01, time/batch = 16.1194s	
17281/22950 (epoch 37.649), train_loss = 0.77089831, grad/param norm = 2.4572e-01, time/batch = 16.2104s	
17282/22950 (epoch 37.651), train_loss = 0.92495891, grad/param norm = 2.7434e-01, time/batch = 16.5586s	
17283/22950 (epoch 37.654), train_loss = 0.71565521, grad/param norm = 2.2909e-01, time/batch = 15.7117s	
17284/22950 (epoch 37.656), train_loss = 0.87931587, grad/param norm = 3.0092e-01, time/batch = 16.0339s	
17285/22950 (epoch 37.658), train_loss = 0.75997017, grad/param norm = 2.5973e-01, time/batch = 16.3507s	
17286/22950 (epoch 37.660), train_loss = 0.67069658, grad/param norm = 2.4869e-01, time/batch = 15.7161s	
17287/22950 (epoch 37.662), train_loss = 0.69731937, grad/param norm = 2.1650e-01, time/batch = 15.7938s	
17288/22950 (epoch 37.664), train_loss = 0.78972468, grad/param norm = 2.4456e-01, time/batch = 16.1128s	
17289/22950 (epoch 37.667), train_loss = 0.83315256, grad/param norm = 2.5652e-01, time/batch = 15.5631s	
17290/22950 (epoch 37.669), train_loss = 0.84379413, grad/param norm = 2.6317e-01, time/batch = 15.6334s	
17291/22950 (epoch 37.671), train_loss = 0.83043555, grad/param norm = 3.0605e-01, time/batch = 15.7163s	
17292/22950 (epoch 37.673), train_loss = 0.77802447, grad/param norm = 2.9160e-01, time/batch = 16.1167s	
17293/22950 (epoch 37.675), train_loss = 0.86098802, grad/param norm = 2.8468e-01, time/batch = 16.3400s	
17294/22950 (epoch 37.678), train_loss = 0.83648522, grad/param norm = 2.5271e-01, time/batch = 15.6375s	
17295/22950 (epoch 37.680), train_loss = 0.86104873, grad/param norm = 2.2376e-01, time/batch = 16.0277s	
17296/22950 (epoch 37.682), train_loss = 0.81108255, grad/param norm = 2.4900e-01, time/batch = 15.9656s	
17297/22950 (epoch 37.684), train_loss = 0.93334265, grad/param norm = 2.7174e-01, time/batch = 15.5649s	
17298/22950 (epoch 37.686), train_loss = 0.93380372, grad/param norm = 2.3521e-01, time/batch = 15.4818s	
17299/22950 (epoch 37.688), train_loss = 0.87001652, grad/param norm = 2.5736e-01, time/batch = 16.1291s	
17300/22950 (epoch 37.691), train_loss = 0.84239342, grad/param norm = 2.7177e-01, time/batch = 15.7744s	
17301/22950 (epoch 37.693), train_loss = 0.77895802, grad/param norm = 2.9356e-01, time/batch = 16.2417s	
17302/22950 (epoch 37.695), train_loss = 0.95564952, grad/param norm = 3.4395e-01, time/batch = 16.1756s	
17303/22950 (epoch 37.697), train_loss = 0.88804987, grad/param norm = 3.1989e-01, time/batch = 16.7885s	
17304/22950 (epoch 37.699), train_loss = 0.88072660, grad/param norm = 2.6931e-01, time/batch = 15.8741s	
17305/22950 (epoch 37.702), train_loss = 0.94634213, grad/param norm = 3.1337e-01, time/batch = 16.3423s	
17306/22950 (epoch 37.704), train_loss = 0.99442151, grad/param norm = 3.1633e-01, time/batch = 15.8743s	
17307/22950 (epoch 37.706), train_loss = 0.93710188, grad/param norm = 2.9386e-01, time/batch = 15.7261s	
17308/22950 (epoch 37.708), train_loss = 0.74238686, grad/param norm = 2.7397e-01, time/batch = 15.5636s	
17309/22950 (epoch 37.710), train_loss = 0.86733219, grad/param norm = 3.1886e-01, time/batch = 15.3128s	
17310/22950 (epoch 37.712), train_loss = 0.96853589, grad/param norm = 2.9138e-01, time/batch = 15.6275s	
17311/22950 (epoch 37.715), train_loss = 0.85634296, grad/param norm = 2.5163e-01, time/batch = 15.5521s	
17312/22950 (epoch 37.717), train_loss = 0.88312360, grad/param norm = 2.3248e-01, time/batch = 15.5513s	
17313/22950 (epoch 37.719), train_loss = 0.82727044, grad/param norm = 2.8438e-01, time/batch = 15.3240s	
17314/22950 (epoch 37.721), train_loss = 0.91534315, grad/param norm = 2.7933e-01, time/batch = 15.6306s	
17315/22950 (epoch 37.723), train_loss = 0.84661426, grad/param norm = 2.5029e-01, time/batch = 15.4007s	
17316/22950 (epoch 37.725), train_loss = 0.89891192, grad/param norm = 2.7658e-01, time/batch = 15.5419s	
17317/22950 (epoch 37.728), train_loss = 0.83205483, grad/param norm = 3.0095e-01, time/batch = 15.5549s	
17318/22950 (epoch 37.730), train_loss = 0.87508593, grad/param norm = 2.9959e-01, time/batch = 15.8672s	
17319/22950 (epoch 37.732), train_loss = 0.93189611, grad/param norm = 2.9695e-01, time/batch = 16.2481s	
17320/22950 (epoch 37.734), train_loss = 0.80980235, grad/param norm = 2.6656e-01, time/batch = 15.3078s	
17321/22950 (epoch 37.736), train_loss = 0.90214417, grad/param norm = 2.5604e-01, time/batch = 15.5587s	
17322/22950 (epoch 37.739), train_loss = 0.92052602, grad/param norm = 3.0220e-01, time/batch = 16.0817s	
17323/22950 (epoch 37.741), train_loss = 0.92845570, grad/param norm = 2.7374e-01, time/batch = 16.3908s	
17324/22950 (epoch 37.743), train_loss = 1.00013811, grad/param norm = 3.1270e-01, time/batch = 15.8677s	
17325/22950 (epoch 37.745), train_loss = 1.07730730, grad/param norm = 3.4654e-01, time/batch = 15.5626s	
17326/22950 (epoch 37.747), train_loss = 0.89472521, grad/param norm = 2.5481e-01, time/batch = 15.5700s	
17327/22950 (epoch 37.749), train_loss = 0.79758966, grad/param norm = 3.0423e-01, time/batch = 15.3826s	
17328/22950 (epoch 37.752), train_loss = 1.03105721, grad/param norm = 2.9492e-01, time/batch = 15.3135s	
17329/22950 (epoch 37.754), train_loss = 0.89482838, grad/param norm = 2.6744e-01, time/batch = 15.5974s	
17330/22950 (epoch 37.756), train_loss = 0.81872672, grad/param norm = 2.5925e-01, time/batch = 15.9131s	
17331/22950 (epoch 37.758), train_loss = 0.88923685, grad/param norm = 2.5673e-01, time/batch = 15.6972s	
17332/22950 (epoch 37.760), train_loss = 0.85051800, grad/param norm = 2.5863e-01, time/batch = 15.8292s	
17333/22950 (epoch 37.763), train_loss = 0.87971020, grad/param norm = 2.6219e-01, time/batch = 15.7779s	
17334/22950 (epoch 37.765), train_loss = 0.85757019, grad/param norm = 3.1354e-01, time/batch = 15.4650s	
17335/22950 (epoch 37.767), train_loss = 1.04289202, grad/param norm = 3.0211e-01, time/batch = 15.6095s	
17336/22950 (epoch 37.769), train_loss = 0.88379064, grad/param norm = 2.4018e-01, time/batch = 16.2677s	
17337/22950 (epoch 37.771), train_loss = 0.78725140, grad/param norm = 2.7100e-01, time/batch = 16.5884s	
17338/22950 (epoch 37.773), train_loss = 0.65194598, grad/param norm = 2.1865e-01, time/batch = 15.7952s	
17339/22950 (epoch 37.776), train_loss = 0.77124870, grad/param norm = 2.0125e-01, time/batch = 15.7246s	
17340/22950 (epoch 37.778), train_loss = 0.77972401, grad/param norm = 2.7669e-01, time/batch = 15.9466s	
17341/22950 (epoch 37.780), train_loss = 0.86004264, grad/param norm = 2.5851e-01, time/batch = 16.3774s	
17342/22950 (epoch 37.782), train_loss = 0.89603227, grad/param norm = 2.4189e-01, time/batch = 15.7333s	
17343/22950 (epoch 37.784), train_loss = 0.79875469, grad/param norm = 2.5760e-01, time/batch = 16.1998s	
17344/22950 (epoch 37.786), train_loss = 0.85502122, grad/param norm = 2.8122e-01, time/batch = 16.7817s	
17345/22950 (epoch 37.789), train_loss = 0.71175735, grad/param norm = 2.2860e-01, time/batch = 16.1849s	
17346/22950 (epoch 37.791), train_loss = 0.74594804, grad/param norm = 2.9016e-01, time/batch = 16.7294s	
17347/22950 (epoch 37.793), train_loss = 0.94424954, grad/param norm = 2.8759e-01, time/batch = 15.7092s	
17348/22950 (epoch 37.795), train_loss = 0.81532458, grad/param norm = 2.2920e-01, time/batch = 15.9591s	
17349/22950 (epoch 37.797), train_loss = 0.96670381, grad/param norm = 2.7689e-01, time/batch = 15.8924s	
17350/22950 (epoch 37.800), train_loss = 0.79376143, grad/param norm = 2.4366e-01, time/batch = 15.5542s	
17351/22950 (epoch 37.802), train_loss = 0.83357164, grad/param norm = 2.6243e-01, time/batch = 15.8056s	
17352/22950 (epoch 37.804), train_loss = 0.82621104, grad/param norm = 2.4219e-01, time/batch = 16.2747s	
17353/22950 (epoch 37.806), train_loss = 0.72706364, grad/param norm = 2.4188e-01, time/batch = 15.9477s	
17354/22950 (epoch 37.808), train_loss = 0.84825929, grad/param norm = 2.2802e-01, time/batch = 15.7214s	
17355/22950 (epoch 37.810), train_loss = 0.81851674, grad/param norm = 2.9349e-01, time/batch = 15.9460s	
17356/22950 (epoch 37.813), train_loss = 0.69427747, grad/param norm = 2.3603e-01, time/batch = 16.2732s	
17357/22950 (epoch 37.815), train_loss = 0.69450322, grad/param norm = 2.8353e-01, time/batch = 15.7215s	
17358/22950 (epoch 37.817), train_loss = 0.76679969, grad/param norm = 2.3125e-01, time/batch = 15.7053s	
17359/22950 (epoch 37.819), train_loss = 0.79151245, grad/param norm = 2.5432e-01, time/batch = 15.8773s	
17360/22950 (epoch 37.821), train_loss = 0.81535862, grad/param norm = 3.0923e-01, time/batch = 15.8690s	
17361/22950 (epoch 37.824), train_loss = 0.84112607, grad/param norm = 2.3754e-01, time/batch = 15.7922s	
17362/22950 (epoch 37.826), train_loss = 0.89735679, grad/param norm = 2.8803e-01, time/batch = 15.8731s	
17363/22950 (epoch 37.828), train_loss = 0.81714982, grad/param norm = 2.6403e-01, time/batch = 16.3424s	
17364/22950 (epoch 37.830), train_loss = 0.79725570, grad/param norm = 2.5427e-01, time/batch = 16.6727s	
17365/22950 (epoch 37.832), train_loss = 0.85206788, grad/param norm = 2.4886e-01, time/batch = 16.7140s	
17366/22950 (epoch 37.834), train_loss = 0.69523700, grad/param norm = 2.5666e-01, time/batch = 15.6375s	
17367/22950 (epoch 37.837), train_loss = 0.84811326, grad/param norm = 2.6766e-01, time/batch = 16.0977s	
17368/22950 (epoch 37.839), train_loss = 0.70059238, grad/param norm = 2.3360e-01, time/batch = 15.3924s	
17369/22950 (epoch 37.841), train_loss = 0.81514540, grad/param norm = 2.1913e-01, time/batch = 16.0952s	
17370/22950 (epoch 37.843), train_loss = 0.81010179, grad/param norm = 2.6505e-01, time/batch = 16.0192s	
17371/22950 (epoch 37.845), train_loss = 0.83112353, grad/param norm = 2.6387e-01, time/batch = 15.7948s	
17372/22950 (epoch 37.847), train_loss = 0.86392408, grad/param norm = 2.6550e-01, time/batch = 15.7151s	
17373/22950 (epoch 37.850), train_loss = 0.90071463, grad/param norm = 2.5101e-01, time/batch = 15.9597s	
17374/22950 (epoch 37.852), train_loss = 0.89531367, grad/param norm = 2.9028e-01, time/batch = 24.0478s	
17375/22950 (epoch 37.854), train_loss = 0.85039161, grad/param norm = 2.9116e-01, time/batch = 22.2772s	
17376/22950 (epoch 37.856), train_loss = 0.93654630, grad/param norm = 3.2003e-01, time/batch = 18.9551s	
17377/22950 (epoch 37.858), train_loss = 0.90561556, grad/param norm = 2.7364e-01, time/batch = 17.1821s	
17378/22950 (epoch 37.861), train_loss = 0.88963137, grad/param norm = 2.6470e-01, time/batch = 19.1992s	
17379/22950 (epoch 37.863), train_loss = 0.94316021, grad/param norm = 3.0465e-01, time/batch = 16.8610s	
17380/22950 (epoch 37.865), train_loss = 0.98028766, grad/param norm = 2.9260e-01, time/batch = 16.3804s	
17381/22950 (epoch 37.867), train_loss = 0.87009795, grad/param norm = 2.8620e-01, time/batch = 16.2412s	
17382/22950 (epoch 37.869), train_loss = 1.01033020, grad/param norm = 2.7985e-01, time/batch = 16.3018s	
17383/22950 (epoch 37.871), train_loss = 0.87374975, grad/param norm = 2.9284e-01, time/batch = 18.4526s	
17384/22950 (epoch 37.874), train_loss = 0.88172571, grad/param norm = 2.3311e-01, time/batch = 18.2790s	
17385/22950 (epoch 37.876), train_loss = 0.96664568, grad/param norm = 3.6675e-01, time/batch = 15.8344s	
17386/22950 (epoch 37.878), train_loss = 0.89004238, grad/param norm = 3.1615e-01, time/batch = 16.0311s	
17387/22950 (epoch 37.880), train_loss = 1.04416111, grad/param norm = 3.0386e-01, time/batch = 17.5205s	
17388/22950 (epoch 37.882), train_loss = 0.74754024, grad/param norm = 2.6139e-01, time/batch = 17.0303s	
17389/22950 (epoch 37.885), train_loss = 0.87719210, grad/param norm = 2.5954e-01, time/batch = 20.3443s	
17390/22950 (epoch 37.887), train_loss = 0.84173406, grad/param norm = 2.3152e-01, time/batch = 18.8269s	
17391/22950 (epoch 37.889), train_loss = 0.87266034, grad/param norm = 2.4847e-01, time/batch = 17.7667s	
17392/22950 (epoch 37.891), train_loss = 0.79803090, grad/param norm = 2.5560e-01, time/batch = 17.9640s	
17393/22950 (epoch 37.893), train_loss = 0.88266322, grad/param norm = 2.6119e-01, time/batch = 18.7906s	
17394/22950 (epoch 37.895), train_loss = 0.99218528, grad/param norm = 2.8025e-01, time/batch = 18.1892s	
17395/22950 (epoch 37.898), train_loss = 0.90841731, grad/param norm = 2.4756e-01, time/batch = 17.1220s	
17396/22950 (epoch 37.900), train_loss = 0.82065550, grad/param norm = 2.3680e-01, time/batch = 16.7541s	
17397/22950 (epoch 37.902), train_loss = 0.85971320, grad/param norm = 2.5052e-01, time/batch = 18.1883s	
17398/22950 (epoch 37.904), train_loss = 0.85649854, grad/param norm = 2.5499e-01, time/batch = 17.8005s	
17399/22950 (epoch 37.906), train_loss = 0.86441058, grad/param norm = 2.6614e-01, time/batch = 16.3542s	
17400/22950 (epoch 37.908), train_loss = 0.76646792, grad/param norm = 2.5362e-01, time/batch = 17.5929s	
17401/22950 (epoch 37.911), train_loss = 0.71227962, grad/param norm = 2.1447e-01, time/batch = 16.1395s	
17402/22950 (epoch 37.913), train_loss = 0.84350749, grad/param norm = 2.4430e-01, time/batch = 16.0987s	
17403/22950 (epoch 37.915), train_loss = 0.96863482, grad/param norm = 2.7511e-01, time/batch = 19.4612s	
17404/22950 (epoch 37.917), train_loss = 0.76225788, grad/param norm = 2.4577e-01, time/batch = 17.8646s	
17405/22950 (epoch 37.919), train_loss = 0.87460046, grad/param norm = 2.4752e-01, time/batch = 18.4647s	
17406/22950 (epoch 37.922), train_loss = 0.83364763, grad/param norm = 2.5369e-01, time/batch = 18.8568s	
17407/22950 (epoch 37.924), train_loss = 0.89341020, grad/param norm = 2.7186e-01, time/batch = 17.4524s	
17408/22950 (epoch 37.926), train_loss = 0.71612886, grad/param norm = 2.8469e-01, time/batch = 18.7714s	
17409/22950 (epoch 37.928), train_loss = 0.75691106, grad/param norm = 2.2370e-01, time/batch = 18.3797s	
17410/22950 (epoch 37.930), train_loss = 0.75711451, grad/param norm = 2.2152e-01, time/batch = 16.0949s	
17411/22950 (epoch 37.932), train_loss = 0.69619575, grad/param norm = 2.0814e-01, time/batch = 17.2695s	
17412/22950 (epoch 37.935), train_loss = 0.87933457, grad/param norm = 2.7368e-01, time/batch = 16.4962s	
17413/22950 (epoch 37.937), train_loss = 0.83829992, grad/param norm = 2.7179e-01, time/batch = 16.8700s	
17414/22950 (epoch 37.939), train_loss = 0.78960092, grad/param norm = 2.5013e-01, time/batch = 18.2613s	
17415/22950 (epoch 37.941), train_loss = 0.82474576, grad/param norm = 2.4450e-01, time/batch = 19.4608s	
17416/22950 (epoch 37.943), train_loss = 0.85676806, grad/param norm = 2.7297e-01, time/batch = 18.4653s	
17417/22950 (epoch 37.946), train_loss = 0.70182781, grad/param norm = 2.4848e-01, time/batch = 17.8717s	
17418/22950 (epoch 37.948), train_loss = 0.93639362, grad/param norm = 2.5581e-01, time/batch = 17.6782s	
17419/22950 (epoch 37.950), train_loss = 0.82265979, grad/param norm = 2.6622e-01, time/batch = 16.8450s	
17420/22950 (epoch 37.952), train_loss = 0.88644921, grad/param norm = 2.3771e-01, time/batch = 17.1962s	
17421/22950 (epoch 37.954), train_loss = 0.88064338, grad/param norm = 2.6419e-01, time/batch = 17.2713s	
17422/22950 (epoch 37.956), train_loss = 0.80173527, grad/param norm = 2.7049e-01, time/batch = 16.3830s	
17423/22950 (epoch 37.959), train_loss = 0.76613371, grad/param norm = 2.3842e-01, time/batch = 18.8575s	
17424/22950 (epoch 37.961), train_loss = 0.83351217, grad/param norm = 2.4354e-01, time/batch = 16.3789s	
17425/22950 (epoch 37.963), train_loss = 0.85681781, grad/param norm = 2.9965e-01, time/batch = 16.0837s	
17426/22950 (epoch 37.965), train_loss = 0.91872049, grad/param norm = 2.8213e-01, time/batch = 16.0050s	
17427/22950 (epoch 37.967), train_loss = 0.81355496, grad/param norm = 2.5927e-01, time/batch = 18.6371s	
17428/22950 (epoch 37.969), train_loss = 0.73931706, grad/param norm = 2.6380e-01, time/batch = 16.0462s	
17429/22950 (epoch 37.972), train_loss = 0.82041750, grad/param norm = 2.3634e-01, time/batch = 17.3465s	
17430/22950 (epoch 37.974), train_loss = 0.79254851, grad/param norm = 2.4891e-01, time/batch = 17.9450s	
17431/22950 (epoch 37.976), train_loss = 0.84806331, grad/param norm = 2.5829e-01, time/batch = 18.6134s	
17432/22950 (epoch 37.978), train_loss = 0.77293604, grad/param norm = 2.5805e-01, time/batch = 19.4401s	
17433/22950 (epoch 37.980), train_loss = 0.78692069, grad/param norm = 2.3691e-01, time/batch = 19.1969s	
17434/22950 (epoch 37.983), train_loss = 0.87824539, grad/param norm = 2.5197e-01, time/batch = 17.8703s	
17435/22950 (epoch 37.985), train_loss = 0.74423882, grad/param norm = 2.2516e-01, time/batch = 18.7027s	
17436/22950 (epoch 37.987), train_loss = 0.75270243, grad/param norm = 2.1714e-01, time/batch = 18.0566s	
17437/22950 (epoch 37.989), train_loss = 0.85213539, grad/param norm = 2.6792e-01, time/batch = 18.9641s	
17438/22950 (epoch 37.991), train_loss = 0.73063024, grad/param norm = 2.5257e-01, time/batch = 16.0907s	
17439/22950 (epoch 37.993), train_loss = 0.85903305, grad/param norm = 2.6218e-01, time/batch = 19.0620s	
17440/22950 (epoch 37.996), train_loss = 0.82292676, grad/param norm = 2.5951e-01, time/batch = 18.2896s	
17441/22950 (epoch 37.998), train_loss = 0.73295966, grad/param norm = 2.3110e-01, time/batch = 17.7736s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
17442/22950 (epoch 38.000), train_loss = 0.72350296, grad/param norm = 2.5031e-01, time/batch = 17.8770s	
17443/22950 (epoch 38.002), train_loss = 1.00446714, grad/param norm = 2.7130e-01, time/batch = 17.4412s	
17444/22950 (epoch 38.004), train_loss = 0.87075868, grad/param norm = 2.4496e-01, time/batch = 18.6829s	
17445/22950 (epoch 38.007), train_loss = 0.80922247, grad/param norm = 2.5463e-01, time/batch = 16.7320s	
17446/22950 (epoch 38.009), train_loss = 0.95588331, grad/param norm = 2.8049e-01, time/batch = 18.8386s	
17447/22950 (epoch 38.011), train_loss = 0.71517922, grad/param norm = 2.3303e-01, time/batch = 18.6011s	
17448/22950 (epoch 38.013), train_loss = 0.80238047, grad/param norm = 2.6972e-01, time/batch = 20.4371s	
17449/22950 (epoch 38.015), train_loss = 0.85295731, grad/param norm = 2.7505e-01, time/batch = 18.7201s	
17450/22950 (epoch 38.017), train_loss = 0.84629873, grad/param norm = 2.3635e-01, time/batch = 19.3828s	
17451/22950 (epoch 38.020), train_loss = 0.86076968, grad/param norm = 2.5165e-01, time/batch = 19.5190s	
17452/22950 (epoch 38.022), train_loss = 0.74735654, grad/param norm = 2.6982e-01, time/batch = 17.6420s	
17453/22950 (epoch 38.024), train_loss = 0.80934593, grad/param norm = 2.4845e-01, time/batch = 20.2915s	
17454/22950 (epoch 38.026), train_loss = 0.85727201, grad/param norm = 2.3186e-01, time/batch = 17.1253s	
17455/22950 (epoch 38.028), train_loss = 0.89443462, grad/param norm = 2.5209e-01, time/batch = 18.2032s	
17456/22950 (epoch 38.031), train_loss = 0.79654266, grad/param norm = 2.5014e-01, time/batch = 16.4380s	
17457/22950 (epoch 38.033), train_loss = 0.90915960, grad/param norm = 2.9693e-01, time/batch = 18.3654s	
17458/22950 (epoch 38.035), train_loss = 0.82870482, grad/param norm = 2.2080e-01, time/batch = 18.0184s	
17459/22950 (epoch 38.037), train_loss = 0.83420839, grad/param norm = 2.3702e-01, time/batch = 18.4687s	
17460/22950 (epoch 38.039), train_loss = 0.84270597, grad/param norm = 2.5775e-01, time/batch = 18.7793s	
17461/22950 (epoch 38.041), train_loss = 0.77593221, grad/param norm = 2.8049e-01, time/batch = 17.9333s	
17462/22950 (epoch 38.044), train_loss = 0.87074010, grad/param norm = 2.8461e-01, time/batch = 17.0184s	
17463/22950 (epoch 38.046), train_loss = 0.83812805, grad/param norm = 2.6869e-01, time/batch = 18.2611s	
17464/22950 (epoch 38.048), train_loss = 0.83956259, grad/param norm = 2.4284e-01, time/batch = 16.4832s	
17465/22950 (epoch 38.050), train_loss = 0.80548962, grad/param norm = 3.2934e-01, time/batch = 16.5954s	
17466/22950 (epoch 38.052), train_loss = 0.85511784, grad/param norm = 2.2910e-01, time/batch = 17.8968s	
17467/22950 (epoch 38.054), train_loss = 0.97022190, grad/param norm = 2.7627e-01, time/batch = 15.3149s	
17468/22950 (epoch 38.057), train_loss = 0.96627089, grad/param norm = 3.1636e-01, time/batch = 15.9696s	
17469/22950 (epoch 38.059), train_loss = 0.93660163, grad/param norm = 2.8299e-01, time/batch = 16.4381s	
17470/22950 (epoch 38.061), train_loss = 0.78142985, grad/param norm = 2.5191e-01, time/batch = 16.5816s	
17471/22950 (epoch 38.063), train_loss = 0.89832483, grad/param norm = 2.6398e-01, time/batch = 16.3436s	
17472/22950 (epoch 38.065), train_loss = 0.75722762, grad/param norm = 2.5373e-01, time/batch = 17.3874s	
17473/22950 (epoch 38.068), train_loss = 0.87556498, grad/param norm = 2.6444e-01, time/batch = 17.3946s	
17474/22950 (epoch 38.070), train_loss = 0.75338793, grad/param norm = 2.2024e-01, time/batch = 17.6133s	
17475/22950 (epoch 38.072), train_loss = 0.90145926, grad/param norm = 2.8807e-01, time/batch = 17.6099s	
17476/22950 (epoch 38.074), train_loss = 0.89100672, grad/param norm = 2.6413e-01, time/batch = 17.8137s	
17477/22950 (epoch 38.076), train_loss = 0.87477181, grad/param norm = 2.4570e-01, time/batch = 16.5295s	
17478/22950 (epoch 38.078), train_loss = 0.93522616, grad/param norm = 2.9022e-01, time/batch = 16.5471s	
17479/22950 (epoch 38.081), train_loss = 0.97397481, grad/param norm = 2.5750e-01, time/batch = 16.7135s	
17480/22950 (epoch 38.083), train_loss = 0.85469445, grad/param norm = 2.5424e-01, time/batch = 16.2095s	
17481/22950 (epoch 38.085), train_loss = 0.73285419, grad/param norm = 2.4252e-01, time/batch = 18.8548s	
17482/22950 (epoch 38.087), train_loss = 0.79787628, grad/param norm = 3.0546e-01, time/batch = 18.6310s	
17483/22950 (epoch 38.089), train_loss = 0.88615365, grad/param norm = 2.8722e-01, time/batch = 18.2094s	
17484/22950 (epoch 38.092), train_loss = 0.80949565, grad/param norm = 2.9021e-01, time/batch = 18.3634s	
17485/22950 (epoch 38.094), train_loss = 0.79330575, grad/param norm = 2.8001e-01, time/batch = 19.0225s	
17486/22950 (epoch 38.096), train_loss = 0.96334914, grad/param norm = 3.0056e-01, time/batch = 19.0407s	
17487/22950 (epoch 38.098), train_loss = 0.90388215, grad/param norm = 2.8040e-01, time/batch = 18.7075s	
17488/22950 (epoch 38.100), train_loss = 0.81563136, grad/param norm = 2.4938e-01, time/batch = 17.2047s	
17489/22950 (epoch 38.102), train_loss = 0.86024070, grad/param norm = 2.9520e-01, time/batch = 17.0477s	
17490/22950 (epoch 38.105), train_loss = 0.70194214, grad/param norm = 2.4582e-01, time/batch = 17.9961s	
17491/22950 (epoch 38.107), train_loss = 0.79695653, grad/param norm = 2.3229e-01, time/batch = 17.5384s	
17492/22950 (epoch 38.109), train_loss = 0.80611249, grad/param norm = 2.5151e-01, time/batch = 17.3116s	
17493/22950 (epoch 38.111), train_loss = 0.70008820, grad/param norm = 2.2569e-01, time/batch = 18.4614s	
17494/22950 (epoch 38.113), train_loss = 0.86091946, grad/param norm = 2.6137e-01, time/batch = 17.6413s	
17495/22950 (epoch 38.115), train_loss = 0.85016058, grad/param norm = 2.5113e-01, time/batch = 17.6128s	
17496/22950 (epoch 38.118), train_loss = 0.94078423, grad/param norm = 2.2683e-01, time/batch = 15.6059s	
17497/22950 (epoch 38.120), train_loss = 0.76161424, grad/param norm = 2.8028e-01, time/batch = 17.4540s	
17498/22950 (epoch 38.122), train_loss = 0.91273465, grad/param norm = 2.7055e-01, time/batch = 17.7972s	
17499/22950 (epoch 38.124), train_loss = 0.73640874, grad/param norm = 2.1623e-01, time/batch = 17.8887s	
17500/22950 (epoch 38.126), train_loss = 0.84061432, grad/param norm = 2.3690e-01, time/batch = 19.3805s	
17501/22950 (epoch 38.129), train_loss = 0.77445848, grad/param norm = 2.1362e-01, time/batch = 16.7280s	
17502/22950 (epoch 38.131), train_loss = 0.82176461, grad/param norm = 2.3386e-01, time/batch = 17.1100s	
17503/22950 (epoch 38.133), train_loss = 0.87612336, grad/param norm = 2.4263e-01, time/batch = 18.9687s	
17504/22950 (epoch 38.135), train_loss = 0.84470948, grad/param norm = 2.2529e-01, time/batch = 19.5193s	
17505/22950 (epoch 38.137), train_loss = 0.90146729, grad/param norm = 3.3627e-01, time/batch = 17.8556s	
17506/22950 (epoch 38.139), train_loss = 0.77760608, grad/param norm = 2.4639e-01, time/batch = 18.9589s	
17507/22950 (epoch 38.142), train_loss = 0.75281703, grad/param norm = 2.1084e-01, time/batch = 19.7896s	
17508/22950 (epoch 38.144), train_loss = 0.80784864, grad/param norm = 2.3620e-01, time/batch = 17.6060s	
17509/22950 (epoch 38.146), train_loss = 0.76020342, grad/param norm = 2.5600e-01, time/batch = 18.5878s	
17510/22950 (epoch 38.148), train_loss = 0.77696418, grad/param norm = 2.5568e-01, time/batch = 19.0388s	
17511/22950 (epoch 38.150), train_loss = 0.85158585, grad/param norm = 2.3168e-01, time/batch = 18.6938s	
17512/22950 (epoch 38.153), train_loss = 0.74890162, grad/param norm = 2.1490e-01, time/batch = 18.4592s	
17513/22950 (epoch 38.155), train_loss = 0.78625241, grad/param norm = 2.2823e-01, time/batch = 18.0301s	
17514/22950 (epoch 38.157), train_loss = 0.81212812, grad/param norm = 2.2643e-01, time/batch = 18.9487s	
17515/22950 (epoch 38.159), train_loss = 0.74070959, grad/param norm = 2.2360e-01, time/batch = 16.6641s	
17516/22950 (epoch 38.161), train_loss = 0.79688990, grad/param norm = 2.5975e-01, time/batch = 17.9438s	
17517/22950 (epoch 38.163), train_loss = 0.74045088, grad/param norm = 2.4971e-01, time/batch = 15.9995s	
17518/22950 (epoch 38.166), train_loss = 0.87159810, grad/param norm = 2.8619e-01, time/batch = 16.3807s	
17519/22950 (epoch 38.168), train_loss = 0.88418950, grad/param norm = 3.1360e-01, time/batch = 18.0449s	
17520/22950 (epoch 38.170), train_loss = 0.84154300, grad/param norm = 2.3789e-01, time/batch = 17.9578s	
17521/22950 (epoch 38.172), train_loss = 0.82648961, grad/param norm = 2.6112e-01, time/batch = 18.2947s	
17522/22950 (epoch 38.174), train_loss = 0.90681553, grad/param norm = 2.5421e-01, time/batch = 16.9799s	
17523/22950 (epoch 38.176), train_loss = 0.90243625, grad/param norm = 3.1501e-01, time/batch = 18.2005s	
17524/22950 (epoch 38.179), train_loss = 0.88813139, grad/param norm = 2.6857e-01, time/batch = 17.0360s	
17525/22950 (epoch 38.181), train_loss = 1.08338441, grad/param norm = 3.0323e-01, time/batch = 17.6702s	
17526/22950 (epoch 38.183), train_loss = 0.88335948, grad/param norm = 2.6071e-01, time/batch = 17.4097s	
17527/22950 (epoch 38.185), train_loss = 0.90279487, grad/param norm = 2.7406e-01, time/batch = 17.5546s	
17528/22950 (epoch 38.187), train_loss = 0.76590993, grad/param norm = 2.4744e-01, time/batch = 18.0434s	
17529/22950 (epoch 38.190), train_loss = 0.68832475, grad/param norm = 2.3605e-01, time/batch = 18.0671s	
17530/22950 (epoch 38.192), train_loss = 0.65641700, grad/param norm = 2.2546e-01, time/batch = 17.0248s	
17531/22950 (epoch 38.194), train_loss = 0.80040949, grad/param norm = 2.5758e-01, time/batch = 17.9588s	
17532/22950 (epoch 38.196), train_loss = 0.61281401, grad/param norm = 2.3958e-01, time/batch = 16.4663s	
17533/22950 (epoch 38.198), train_loss = 0.86789293, grad/param norm = 2.5930e-01, time/batch = 19.3790s	
17534/22950 (epoch 38.200), train_loss = 0.76032122, grad/param norm = 2.3992e-01, time/batch = 16.4726s	
17535/22950 (epoch 38.203), train_loss = 0.71521263, grad/param norm = 2.2286e-01, time/batch = 16.4843s	
17536/22950 (epoch 38.205), train_loss = 0.79590529, grad/param norm = 2.7116e-01, time/batch = 16.5085s	
17537/22950 (epoch 38.207), train_loss = 0.85096668, grad/param norm = 2.6581e-01, time/batch = 16.5951s	
17538/22950 (epoch 38.209), train_loss = 0.81213423, grad/param norm = 3.3417e-01, time/batch = 17.1985s	
17539/22950 (epoch 38.211), train_loss = 0.70426427, grad/param norm = 2.7272e-01, time/batch = 16.2522s	
17540/22950 (epoch 38.214), train_loss = 0.76263077, grad/param norm = 2.3457e-01, time/batch = 16.4040s	
17541/22950 (epoch 38.216), train_loss = 0.91700307, grad/param norm = 2.6283e-01, time/batch = 15.6170s	
17542/22950 (epoch 38.218), train_loss = 0.80395192, grad/param norm = 2.2982e-01, time/batch = 17.4422s	
17543/22950 (epoch 38.220), train_loss = 0.89603855, grad/param norm = 2.7863e-01, time/batch = 17.8685s	
17544/22950 (epoch 38.222), train_loss = 0.92054867, grad/param norm = 3.1501e-01, time/batch = 17.8840s	
17545/22950 (epoch 38.224), train_loss = 0.82284133, grad/param norm = 2.5014e-01, time/batch = 17.9446s	
17546/22950 (epoch 38.227), train_loss = 0.89110821, grad/param norm = 2.5622e-01, time/batch = 17.0390s	
17547/22950 (epoch 38.229), train_loss = 0.95755942, grad/param norm = 2.7751e-01, time/batch = 18.6300s	
17548/22950 (epoch 38.231), train_loss = 0.66832814, grad/param norm = 2.2433e-01, time/batch = 16.6243s	
17549/22950 (epoch 38.233), train_loss = 0.76950309, grad/param norm = 2.5074e-01, time/batch = 18.6051s	
17550/22950 (epoch 38.235), train_loss = 0.95611171, grad/param norm = 2.4988e-01, time/batch = 18.0472s	
17551/22950 (epoch 38.237), train_loss = 0.77793649, grad/param norm = 2.2191e-01, time/batch = 17.5383s	
17552/22950 (epoch 38.240), train_loss = 0.81785798, grad/param norm = 2.4241e-01, time/batch = 16.9186s	
17553/22950 (epoch 38.242), train_loss = 0.97213699, grad/param norm = 2.4560e-01, time/batch = 17.2079s	
17554/22950 (epoch 38.244), train_loss = 0.94584606, grad/param norm = 2.8334e-01, time/batch = 19.2919s	
17555/22950 (epoch 38.246), train_loss = 0.93672771, grad/param norm = 2.4668e-01, time/batch = 18.6119s	
17556/22950 (epoch 38.248), train_loss = 0.85478221, grad/param norm = 2.9422e-01, time/batch = 18.3878s	
17557/22950 (epoch 38.251), train_loss = 0.77329601, grad/param norm = 2.5063e-01, time/batch = 16.8799s	
17558/22950 (epoch 38.253), train_loss = 0.77214158, grad/param norm = 2.6561e-01, time/batch = 17.9257s	
17559/22950 (epoch 38.255), train_loss = 0.86562453, grad/param norm = 2.5131e-01, time/batch = 17.2188s	
17560/22950 (epoch 38.257), train_loss = 0.91413002, grad/param norm = 2.8272e-01, time/batch = 15.7819s	
17561/22950 (epoch 38.259), train_loss = 0.69777125, grad/param norm = 2.3314e-01, time/batch = 15.9503s	
17562/22950 (epoch 38.261), train_loss = 0.75172898, grad/param norm = 2.3881e-01, time/batch = 16.2990s	
17563/22950 (epoch 38.264), train_loss = 0.74302636, grad/param norm = 2.2765e-01, time/batch = 19.2563s	
17564/22950 (epoch 38.266), train_loss = 0.79016940, grad/param norm = 2.4089e-01, time/batch = 16.6083s	
17565/22950 (epoch 38.268), train_loss = 0.79772554, grad/param norm = 2.6570e-01, time/batch = 16.2888s	
17566/22950 (epoch 38.270), train_loss = 0.82108822, grad/param norm = 2.3621e-01, time/batch = 15.5484s	
17567/22950 (epoch 38.272), train_loss = 0.84505406, grad/param norm = 2.6927e-01, time/batch = 15.2481s	
17568/22950 (epoch 38.275), train_loss = 0.77630854, grad/param norm = 3.5417e-01, time/batch = 14.9940s	
17569/22950 (epoch 38.277), train_loss = 0.69494191, grad/param norm = 2.2673e-01, time/batch = 15.0785s	
17570/22950 (epoch 38.279), train_loss = 0.71901594, grad/param norm = 2.6001e-01, time/batch = 15.7119s	
17571/22950 (epoch 38.281), train_loss = 0.82177858, grad/param norm = 2.4575e-01, time/batch = 15.2326s	
17572/22950 (epoch 38.283), train_loss = 0.71192609, grad/param norm = 2.2857e-01, time/batch = 15.9360s	
17573/22950 (epoch 38.285), train_loss = 0.81932484, grad/param norm = 2.2278e-01, time/batch = 16.3239s	
17574/22950 (epoch 38.288), train_loss = 0.91973003, grad/param norm = 2.3470e-01, time/batch = 16.4151s	
17575/22950 (epoch 38.290), train_loss = 0.78660657, grad/param norm = 2.3709e-01, time/batch = 15.7227s	
17576/22950 (epoch 38.292), train_loss = 0.92578335, grad/param norm = 2.5862e-01, time/batch = 15.3251s	
17577/22950 (epoch 38.294), train_loss = 0.85437936, grad/param norm = 2.4137e-01, time/batch = 16.4264s	
17578/22950 (epoch 38.296), train_loss = 0.63784359, grad/param norm = 2.0154e-01, time/batch = 27.0626s	
17579/22950 (epoch 38.298), train_loss = 0.80916627, grad/param norm = 2.3882e-01, time/batch = 15.1504s	
17580/22950 (epoch 38.301), train_loss = 0.82964036, grad/param norm = 2.5130e-01, time/batch = 15.2345s	
17581/22950 (epoch 38.303), train_loss = 0.80668299, grad/param norm = 2.4794e-01, time/batch = 16.0970s	
17582/22950 (epoch 38.305), train_loss = 0.79660965, grad/param norm = 2.5585e-01, time/batch = 15.5391s	
17583/22950 (epoch 38.307), train_loss = 0.93126751, grad/param norm = 2.4814e-01, time/batch = 15.2953s	
17584/22950 (epoch 38.309), train_loss = 0.76132402, grad/param norm = 2.1958e-01, time/batch = 15.1464s	
17585/22950 (epoch 38.312), train_loss = 0.83741630, grad/param norm = 2.3252e-01, time/batch = 15.4632s	
17586/22950 (epoch 38.314), train_loss = 0.85381174, grad/param norm = 2.4091e-01, time/batch = 15.0012s	
17587/22950 (epoch 38.316), train_loss = 0.79571265, grad/param norm = 2.5706e-01, time/batch = 14.9999s	
17588/22950 (epoch 38.318), train_loss = 0.71217051, grad/param norm = 1.9937e-01, time/batch = 15.0547s	
17589/22950 (epoch 38.320), train_loss = 0.77080284, grad/param norm = 2.3321e-01, time/batch = 15.7721s	
17590/22950 (epoch 38.322), train_loss = 0.78352908, grad/param norm = 2.4634e-01, time/batch = 15.5347s	
17591/22950 (epoch 38.325), train_loss = 0.62547862, grad/param norm = 2.1231e-01, time/batch = 16.7182s	
17592/22950 (epoch 38.327), train_loss = 0.64519253, grad/param norm = 2.0810e-01, time/batch = 16.6982s	
17593/22950 (epoch 38.329), train_loss = 0.75142870, grad/param norm = 2.2362e-01, time/batch = 16.3788s	
17594/22950 (epoch 38.331), train_loss = 0.70743902, grad/param norm = 2.0965e-01, time/batch = 16.6082s	
17595/22950 (epoch 38.333), train_loss = 0.73550248, grad/param norm = 2.2686e-01, time/batch = 16.5413s	
17596/22950 (epoch 38.336), train_loss = 0.80010389, grad/param norm = 3.1738e-01, time/batch = 16.9871s	
17597/22950 (epoch 38.338), train_loss = 0.81897190, grad/param norm = 2.5649e-01, time/batch = 16.4663s	
17598/22950 (epoch 38.340), train_loss = 0.76458470, grad/param norm = 2.4903e-01, time/batch = 16.2973s	
17599/22950 (epoch 38.342), train_loss = 0.96700855, grad/param norm = 2.9462e-01, time/batch = 16.1256s	
17600/22950 (epoch 38.344), train_loss = 0.79182585, grad/param norm = 2.6532e-01, time/batch = 16.2064s	
17601/22950 (epoch 38.346), train_loss = 0.91340297, grad/param norm = 2.9701e-01, time/batch = 16.6557s	
17602/22950 (epoch 38.349), train_loss = 0.81247161, grad/param norm = 2.2731e-01, time/batch = 16.9034s	
17603/22950 (epoch 38.351), train_loss = 0.84394076, grad/param norm = 3.1716e-01, time/batch = 16.4427s	
17604/22950 (epoch 38.353), train_loss = 0.84941355, grad/param norm = 3.1046e-01, time/batch = 15.8808s	
17605/22950 (epoch 38.355), train_loss = 0.90449488, grad/param norm = 3.0875e-01, time/batch = 15.8069s	
17606/22950 (epoch 38.357), train_loss = 0.79121275, grad/param norm = 2.7565e-01, time/batch = 15.7976s	
17607/22950 (epoch 38.359), train_loss = 0.83530315, grad/param norm = 2.7274e-01, time/batch = 16.1948s	
17608/22950 (epoch 38.362), train_loss = 0.87562974, grad/param norm = 2.6360e-01, time/batch = 15.8084s	
17609/22950 (epoch 38.364), train_loss = 0.84807287, grad/param norm = 2.7777e-01, time/batch = 16.0303s	
17610/22950 (epoch 38.366), train_loss = 0.82135229, grad/param norm = 2.2237e-01, time/batch = 15.8661s	
17611/22950 (epoch 38.368), train_loss = 0.85766686, grad/param norm = 2.7786e-01, time/batch = 16.2015s	
17612/22950 (epoch 38.370), train_loss = 0.79218101, grad/param norm = 2.5267e-01, time/batch = 15.7131s	
17613/22950 (epoch 38.373), train_loss = 0.76271579, grad/param norm = 2.4257e-01, time/batch = 16.1212s	
17614/22950 (epoch 38.375), train_loss = 0.91608997, grad/param norm = 2.6345e-01, time/batch = 16.3303s	
17615/22950 (epoch 38.377), train_loss = 0.74340724, grad/param norm = 2.3490e-01, time/batch = 16.0445s	
17616/22950 (epoch 38.379), train_loss = 0.82917710, grad/param norm = 2.4358e-01, time/batch = 16.1287s	
17617/22950 (epoch 38.381), train_loss = 0.72628562, grad/param norm = 2.2675e-01, time/batch = 15.7996s	
17618/22950 (epoch 38.383), train_loss = 0.79863167, grad/param norm = 2.7750e-01, time/batch = 15.9641s	
17619/22950 (epoch 38.386), train_loss = 0.75964563, grad/param norm = 2.7611e-01, time/batch = 15.4823s	
17620/22950 (epoch 38.388), train_loss = 0.85297438, grad/param norm = 2.3315e-01, time/batch = 16.2867s	
17621/22950 (epoch 38.390), train_loss = 0.72278402, grad/param norm = 2.3812e-01, time/batch = 16.6753s	
17622/22950 (epoch 38.392), train_loss = 0.77319433, grad/param norm = 2.5947e-01, time/batch = 17.1896s	
17623/22950 (epoch 38.394), train_loss = 0.78537980, grad/param norm = 2.3024e-01, time/batch = 16.8957s	
17624/22950 (epoch 38.397), train_loss = 0.92194422, grad/param norm = 2.4133e-01, time/batch = 17.0136s	
17625/22950 (epoch 38.399), train_loss = 0.89408350, grad/param norm = 2.9829e-01, time/batch = 17.2627s	
17626/22950 (epoch 38.401), train_loss = 0.95411572, grad/param norm = 3.0754e-01, time/batch = 16.7724s	
17627/22950 (epoch 38.403), train_loss = 0.80233722, grad/param norm = 2.6013e-01, time/batch = 16.6196s	
17628/22950 (epoch 38.405), train_loss = 0.95655710, grad/param norm = 3.1691e-01, time/batch = 16.7001s	
17629/22950 (epoch 38.407), train_loss = 0.98000168, grad/param norm = 2.4004e-01, time/batch = 16.9425s	
17630/22950 (epoch 38.410), train_loss = 0.83951896, grad/param norm = 2.2833e-01, time/batch = 16.9757s	
17631/22950 (epoch 38.412), train_loss = 0.81114954, grad/param norm = 2.8886e-01, time/batch = 17.2932s	
17632/22950 (epoch 38.414), train_loss = 0.93877256, grad/param norm = 2.6571e-01, time/batch = 17.4753s	
17633/22950 (epoch 38.416), train_loss = 0.85306334, grad/param norm = 2.8070e-01, time/batch = 17.3396s	
17634/22950 (epoch 38.418), train_loss = 0.84484503, grad/param norm = 2.6943e-01, time/batch = 17.0714s	
17635/22950 (epoch 38.420), train_loss = 0.88232479, grad/param norm = 3.0653e-01, time/batch = 16.4629s	
17636/22950 (epoch 38.423), train_loss = 0.77856159, grad/param norm = 2.4727e-01, time/batch = 16.7750s	
17637/22950 (epoch 38.425), train_loss = 0.81160847, grad/param norm = 2.5393e-01, time/batch = 16.4794s	
17638/22950 (epoch 38.427), train_loss = 0.84607943, grad/param norm = 2.5865e-01, time/batch = 16.6088s	
17639/22950 (epoch 38.429), train_loss = 0.83315507, grad/param norm = 2.3181e-01, time/batch = 16.4667s	
17640/22950 (epoch 38.431), train_loss = 0.91347477, grad/param norm = 2.8303e-01, time/batch = 17.0422s	
17641/22950 (epoch 38.434), train_loss = 0.84340292, grad/param norm = 2.6243e-01, time/batch = 17.0393s	
17642/22950 (epoch 38.436), train_loss = 0.91767359, grad/param norm = 2.9689e-01, time/batch = 16.7584s	
17643/22950 (epoch 38.438), train_loss = 0.82741091, grad/param norm = 2.4038e-01, time/batch = 16.9866s	
17644/22950 (epoch 38.440), train_loss = 0.92047385, grad/param norm = 2.5038e-01, time/batch = 16.4525s	
17645/22950 (epoch 38.442), train_loss = 0.97134306, grad/param norm = 2.8034e-01, time/batch = 16.2213s	
17646/22950 (epoch 38.444), train_loss = 0.87393581, grad/param norm = 2.8025e-01, time/batch = 16.3749s	
17647/22950 (epoch 38.447), train_loss = 0.98077843, grad/param norm = 2.6712e-01, time/batch = 16.5611s	
17648/22950 (epoch 38.449), train_loss = 0.75340927, grad/param norm = 2.4280e-01, time/batch = 16.5197s	
17649/22950 (epoch 38.451), train_loss = 0.83909284, grad/param norm = 2.7774e-01, time/batch = 16.1468s	
17650/22950 (epoch 38.453), train_loss = 0.85859661, grad/param norm = 2.1487e-01, time/batch = 16.4507s	
17651/22950 (epoch 38.455), train_loss = 0.82622224, grad/param norm = 2.2622e-01, time/batch = 16.8279s	
17652/22950 (epoch 38.458), train_loss = 0.83519182, grad/param norm = 2.4765e-01, time/batch = 16.3876s	
17653/22950 (epoch 38.460), train_loss = 0.88361483, grad/param norm = 2.7542e-01, time/batch = 16.2991s	
17654/22950 (epoch 38.462), train_loss = 0.89010613, grad/param norm = 3.1174e-01, time/batch = 16.9416s	
17655/22950 (epoch 38.464), train_loss = 0.80382322, grad/param norm = 2.4407e-01, time/batch = 16.6245s	
17656/22950 (epoch 38.466), train_loss = 0.92715027, grad/param norm = 2.6959e-01, time/batch = 16.6060s	
17657/22950 (epoch 38.468), train_loss = 0.90664158, grad/param norm = 2.6049e-01, time/batch = 16.6316s	
17658/22950 (epoch 38.471), train_loss = 0.86313555, grad/param norm = 2.7887e-01, time/batch = 16.5376s	
17659/22950 (epoch 38.473), train_loss = 0.88202576, grad/param norm = 3.1241e-01, time/batch = 16.6553s	
17660/22950 (epoch 38.475), train_loss = 0.99792413, grad/param norm = 2.6763e-01, time/batch = 16.2936s	
17661/22950 (epoch 38.477), train_loss = 0.81782572, grad/param norm = 2.5011e-01, time/batch = 16.8175s	
17662/22950 (epoch 38.479), train_loss = 0.72966438, grad/param norm = 2.2335e-01, time/batch = 16.9683s	
17663/22950 (epoch 38.481), train_loss = 0.91562380, grad/param norm = 2.8064e-01, time/batch = 16.6438s	
17664/22950 (epoch 38.484), train_loss = 0.87711191, grad/param norm = 2.8405e-01, time/batch = 16.6812s	
17665/22950 (epoch 38.486), train_loss = 0.74068609, grad/param norm = 2.8986e-01, time/batch = 16.6228s	
17666/22950 (epoch 38.488), train_loss = 0.75920597, grad/param norm = 2.7010e-01, time/batch = 16.3150s	
17667/22950 (epoch 38.490), train_loss = 0.71282357, grad/param norm = 3.3456e-01, time/batch = 16.1502s	
17668/22950 (epoch 38.492), train_loss = 0.79870579, grad/param norm = 2.2327e-01, time/batch = 16.9335s	
17669/22950 (epoch 38.495), train_loss = 0.76638581, grad/param norm = 2.4632e-01, time/batch = 16.7873s	
17670/22950 (epoch 38.497), train_loss = 0.87576766, grad/param norm = 2.6772e-01, time/batch = 16.8402s	
17671/22950 (epoch 38.499), train_loss = 0.94436316, grad/param norm = 2.5090e-01, time/batch = 16.7907s	
17672/22950 (epoch 38.501), train_loss = 0.84829173, grad/param norm = 2.6339e-01, time/batch = 16.6980s	
17673/22950 (epoch 38.503), train_loss = 0.94230301, grad/param norm = 2.7278e-01, time/batch = 16.5387s	
17674/22950 (epoch 38.505), train_loss = 0.70513444, grad/param norm = 2.2978e-01, time/batch = 17.2709s	
17675/22950 (epoch 38.508), train_loss = 0.89572529, grad/param norm = 2.5461e-01, time/batch = 16.7009s	
17676/22950 (epoch 38.510), train_loss = 0.80160521, grad/param norm = 2.3140e-01, time/batch = 16.9047s	
17677/22950 (epoch 38.512), train_loss = 0.72409266, grad/param norm = 2.3006e-01, time/batch = 17.1234s	
17678/22950 (epoch 38.514), train_loss = 0.80004979, grad/param norm = 2.2265e-01, time/batch = 17.4538s	
17679/22950 (epoch 38.516), train_loss = 0.85122616, grad/param norm = 2.5002e-01, time/batch = 17.0388s	
17680/22950 (epoch 38.519), train_loss = 0.83666358, grad/param norm = 2.3997e-01, time/batch = 16.3115s	
17681/22950 (epoch 38.521), train_loss = 0.85197960, grad/param norm = 2.5734e-01, time/batch = 17.1423s	
17682/22950 (epoch 38.523), train_loss = 0.66611883, grad/param norm = 2.2644e-01, time/batch = 16.8284s	
17683/22950 (epoch 38.525), train_loss = 0.75582497, grad/param norm = 2.4157e-01, time/batch = 16.7404s	
17684/22950 (epoch 38.527), train_loss = 0.72454540, grad/param norm = 2.1803e-01, time/batch = 16.6606s	
17685/22950 (epoch 38.529), train_loss = 0.82506884, grad/param norm = 2.6920e-01, time/batch = 16.7467s	
17686/22950 (epoch 38.532), train_loss = 0.82122828, grad/param norm = 2.4593e-01, time/batch = 16.6960s	
17687/22950 (epoch 38.534), train_loss = 0.83046308, grad/param norm = 2.1385e-01, time/batch = 16.3912s	
17688/22950 (epoch 38.536), train_loss = 0.87256644, grad/param norm = 3.5125e-01, time/batch = 16.6859s	
17689/22950 (epoch 38.538), train_loss = 0.83023882, grad/param norm = 2.5120e-01, time/batch = 16.3742s	
17690/22950 (epoch 38.540), train_loss = 0.86700413, grad/param norm = 2.7363e-01, time/batch = 16.3922s	
17691/22950 (epoch 38.542), train_loss = 0.99426365, grad/param norm = 3.5271e-01, time/batch = 16.3054s	
17692/22950 (epoch 38.545), train_loss = 0.82485083, grad/param norm = 2.4005e-01, time/batch = 16.4420s	
17693/22950 (epoch 38.547), train_loss = 0.81883362, grad/param norm = 2.3894e-01, time/batch = 16.3891s	
17694/22950 (epoch 38.549), train_loss = 0.77057834, grad/param norm = 2.5767e-01, time/batch = 16.3877s	
17695/22950 (epoch 38.551), train_loss = 0.82227419, grad/param norm = 2.9413e-01, time/batch = 16.2355s	
17696/22950 (epoch 38.553), train_loss = 0.78226382, grad/param norm = 2.9189e-01, time/batch = 16.2844s	
17697/22950 (epoch 38.556), train_loss = 0.86977311, grad/param norm = 2.3284e-01, time/batch = 16.5351s	
17698/22950 (epoch 38.558), train_loss = 0.70352316, grad/param norm = 2.3907e-01, time/batch = 16.4660s	
17699/22950 (epoch 38.560), train_loss = 0.80446094, grad/param norm = 3.1272e-01, time/batch = 16.3898s	
17700/22950 (epoch 38.562), train_loss = 0.77006839, grad/param norm = 2.4603e-01, time/batch = 16.9582s	
17701/22950 (epoch 38.564), train_loss = 0.86337364, grad/param norm = 2.7570e-01, time/batch = 16.7836s	
17702/22950 (epoch 38.566), train_loss = 0.87351090, grad/param norm = 2.7660e-01, time/batch = 15.8950s	
17703/22950 (epoch 38.569), train_loss = 0.82142634, grad/param norm = 2.5423e-01, time/batch = 15.5782s	
17704/22950 (epoch 38.571), train_loss = 0.77122221, grad/param norm = 2.4526e-01, time/batch = 16.4126s	
17705/22950 (epoch 38.573), train_loss = 0.80013835, grad/param norm = 2.4667e-01, time/batch = 15.5513s	
17706/22950 (epoch 38.575), train_loss = 0.89284230, grad/param norm = 3.2155e-01, time/batch = 15.8476s	
17707/22950 (epoch 38.577), train_loss = 0.84506565, grad/param norm = 4.4062e-01, time/batch = 15.5454s	
17708/22950 (epoch 38.580), train_loss = 0.89829202, grad/param norm = 2.8177e-01, time/batch = 16.1231s	
17709/22950 (epoch 38.582), train_loss = 0.95799440, grad/param norm = 2.4842e-01, time/batch = 15.6331s	
17710/22950 (epoch 38.584), train_loss = 0.71828051, grad/param norm = 2.5004e-01, time/batch = 15.9514s	
17711/22950 (epoch 38.586), train_loss = 0.76784019, grad/param norm = 2.5231e-01, time/batch = 16.2009s	
17712/22950 (epoch 38.588), train_loss = 0.92224185, grad/param norm = 2.8080e-01, time/batch = 16.4180s	
17713/22950 (epoch 38.590), train_loss = 0.92646752, grad/param norm = 3.0410e-01, time/batch = 15.6348s	
17714/22950 (epoch 38.593), train_loss = 0.79432670, grad/param norm = 2.4415e-01, time/batch = 15.3116s	
17715/22950 (epoch 38.595), train_loss = 0.74900600, grad/param norm = 3.2827e-01, time/batch = 15.5422s	
17716/22950 (epoch 38.597), train_loss = 0.89556058, grad/param norm = 2.7826e-01, time/batch = 15.4777s	
17717/22950 (epoch 38.599), train_loss = 0.83753563, grad/param norm = 2.9597e-01, time/batch = 15.5556s	
17718/22950 (epoch 38.601), train_loss = 0.89686020, grad/param norm = 2.5904e-01, time/batch = 15.1539s	
17719/22950 (epoch 38.603), train_loss = 0.93648273, grad/param norm = 2.7813e-01, time/batch = 15.7047s	
17720/22950 (epoch 38.606), train_loss = 0.79755021, grad/param norm = 2.3251e-01, time/batch = 15.6286s	
17721/22950 (epoch 38.608), train_loss = 0.79010357, grad/param norm = 2.4817e-01, time/batch = 15.3963s	
17722/22950 (epoch 38.610), train_loss = 0.82628577, grad/param norm = 2.4273e-01, time/batch = 16.4830s	
17723/22950 (epoch 38.612), train_loss = 0.84769462, grad/param norm = 3.0405e-01, time/batch = 16.7696s	
17724/22950 (epoch 38.614), train_loss = 0.93339200, grad/param norm = 3.1339e-01, time/batch = 16.4521s	
17725/22950 (epoch 38.617), train_loss = 0.83338764, grad/param norm = 2.5696e-01, time/batch = 16.2843s	
17726/22950 (epoch 38.619), train_loss = 0.75986570, grad/param norm = 2.3095e-01, time/batch = 16.6583s	
17727/22950 (epoch 38.621), train_loss = 0.90045041, grad/param norm = 2.5430e-01, time/batch = 16.8150s	
17728/22950 (epoch 38.623), train_loss = 0.87708774, grad/param norm = 2.4251e-01, time/batch = 15.7192s	
17729/22950 (epoch 38.625), train_loss = 0.82397649, grad/param norm = 2.5464e-01, time/batch = 16.0386s	
17730/22950 (epoch 38.627), train_loss = 0.81103850, grad/param norm = 2.8234e-01, time/batch = 16.0269s	
17731/22950 (epoch 38.630), train_loss = 0.72367630, grad/param norm = 2.1019e-01, time/batch = 16.3393s	
17732/22950 (epoch 38.632), train_loss = 0.79557966, grad/param norm = 2.6942e-01, time/batch = 15.7944s	
17733/22950 (epoch 38.634), train_loss = 0.85999740, grad/param norm = 2.6875e-01, time/batch = 15.8115s	
17734/22950 (epoch 38.636), train_loss = 0.82423943, grad/param norm = 2.5424e-01, time/batch = 15.9424s	
17735/22950 (epoch 38.638), train_loss = 0.81454439, grad/param norm = 2.6334e-01, time/batch = 15.6164s	
17736/22950 (epoch 38.641), train_loss = 0.80912833, grad/param norm = 2.4751e-01, time/batch = 14.9202s	
17737/22950 (epoch 38.643), train_loss = 0.84105920, grad/param norm = 3.1590e-01, time/batch = 15.0670s	
17738/22950 (epoch 38.645), train_loss = 0.79813881, grad/param norm = 2.3300e-01, time/batch = 15.1442s	
17739/22950 (epoch 38.647), train_loss = 0.78885733, grad/param norm = 2.7162e-01, time/batch = 14.9141s	
17740/22950 (epoch 38.649), train_loss = 0.77497465, grad/param norm = 2.7437e-01, time/batch = 15.1409s	
17741/22950 (epoch 38.651), train_loss = 0.91490721, grad/param norm = 2.5632e-01, time/batch = 15.6211s	
17742/22950 (epoch 38.654), train_loss = 0.71303812, grad/param norm = 2.3157e-01, time/batch = 4.6204s	
17743/22950 (epoch 38.656), train_loss = 0.88426958, grad/param norm = 2.9529e-01, time/batch = 0.7274s	
17744/22950 (epoch 38.658), train_loss = 0.73906411, grad/param norm = 3.1301e-01, time/batch = 0.7000s	
17745/22950 (epoch 38.660), train_loss = 0.66114374, grad/param norm = 2.4566e-01, time/batch = 0.6912s	
17746/22950 (epoch 38.662), train_loss = 0.69771810, grad/param norm = 2.8150e-01, time/batch = 0.6884s	
17747/22950 (epoch 38.664), train_loss = 0.78923084, grad/param norm = 2.5612e-01, time/batch = 0.6960s	
17748/22950 (epoch 38.667), train_loss = 0.81896329, grad/param norm = 2.6204e-01, time/batch = 0.7099s	
17749/22950 (epoch 38.669), train_loss = 0.82332573, grad/param norm = 2.5559e-01, time/batch = 0.9119s	
17750/22950 (epoch 38.671), train_loss = 0.81200501, grad/param norm = 2.4594e-01, time/batch = 1.0170s	
17751/22950 (epoch 38.673), train_loss = 0.77586211, grad/param norm = 2.7692e-01, time/batch = 1.0603s	
17752/22950 (epoch 38.675), train_loss = 0.83909085, grad/param norm = 2.7778e-01, time/batch = 1.0688s	
17753/22950 (epoch 38.678), train_loss = 0.82130091, grad/param norm = 2.8079e-01, time/batch = 1.0711s	
17754/22950 (epoch 38.680), train_loss = 0.85308650, grad/param norm = 2.5027e-01, time/batch = 1.9071s	
17755/22950 (epoch 38.682), train_loss = 0.79614392, grad/param norm = 2.5774e-01, time/batch = 1.9080s	
17756/22950 (epoch 38.684), train_loss = 0.92078587, grad/param norm = 2.6911e-01, time/batch = 7.0871s	
17757/22950 (epoch 38.686), train_loss = 0.93722253, grad/param norm = 2.8378e-01, time/batch = 15.2984s	
17758/22950 (epoch 38.688), train_loss = 0.84024577, grad/param norm = 2.5325e-01, time/batch = 15.3024s	
17759/22950 (epoch 38.691), train_loss = 0.83087462, grad/param norm = 2.7415e-01, time/batch = 16.5364s	
17760/22950 (epoch 38.693), train_loss = 0.77476146, grad/param norm = 2.7700e-01, time/batch = 16.1423s	
17761/22950 (epoch 38.695), train_loss = 0.93055211, grad/param norm = 3.0152e-01, time/batch = 15.3010s	
17762/22950 (epoch 38.697), train_loss = 0.87340086, grad/param norm = 3.2097e-01, time/batch = 14.8177s	
17763/22950 (epoch 38.699), train_loss = 0.87269002, grad/param norm = 2.7925e-01, time/batch = 15.2941s	
17764/22950 (epoch 38.702), train_loss = 0.90011541, grad/param norm = 3.0058e-01, time/batch = 14.6530s	
17765/22950 (epoch 38.704), train_loss = 0.98298230, grad/param norm = 3.2293e-01, time/batch = 14.5805s	
17766/22950 (epoch 38.706), train_loss = 0.91305841, grad/param norm = 2.9024e-01, time/batch = 14.6607s	
17767/22950 (epoch 38.708), train_loss = 0.73542412, grad/param norm = 2.6455e-01, time/batch = 15.1545s	
17768/22950 (epoch 38.710), train_loss = 0.84366843, grad/param norm = 2.9151e-01, time/batch = 14.9207s	
17769/22950 (epoch 38.712), train_loss = 0.97243186, grad/param norm = 3.6825e-01, time/batch = 14.8252s	
17770/22950 (epoch 38.715), train_loss = 0.86823695, grad/param norm = 2.7383e-01, time/batch = 14.9102s	
17771/22950 (epoch 38.717), train_loss = 0.87562449, grad/param norm = 2.3661e-01, time/batch = 15.3050s	
17772/22950 (epoch 38.719), train_loss = 0.82346441, grad/param norm = 2.6144e-01, time/batch = 14.9153s	
17773/22950 (epoch 38.721), train_loss = 0.91799419, grad/param norm = 2.8389e-01, time/batch = 14.8361s	
17774/22950 (epoch 38.723), train_loss = 0.83853298, grad/param norm = 2.4755e-01, time/batch = 14.9880s	
17775/22950 (epoch 38.725), train_loss = 0.89158483, grad/param norm = 2.8864e-01, time/batch = 15.4577s	
17776/22950 (epoch 38.728), train_loss = 0.82583478, grad/param norm = 3.0403e-01, time/batch = 14.9207s	
17777/22950 (epoch 38.730), train_loss = 0.86177559, grad/param norm = 3.1584e-01, time/batch = 15.2184s	
17778/22950 (epoch 38.732), train_loss = 0.91678906, grad/param norm = 3.0404e-01, time/batch = 14.9873s	
17779/22950 (epoch 38.734), train_loss = 0.81738109, grad/param norm = 2.9935e-01, time/batch = 15.5496s	
17780/22950 (epoch 38.736), train_loss = 0.89296202, grad/param norm = 2.7287e-01, time/batch = 14.9840s	
17781/22950 (epoch 38.739), train_loss = 0.92401994, grad/param norm = 3.2176e-01, time/batch = 16.5419s	
17782/22950 (epoch 38.741), train_loss = 0.91929222, grad/param norm = 2.9696e-01, time/batch = 15.2977s	
17783/22950 (epoch 38.743), train_loss = 0.98120290, grad/param norm = 3.3912e-01, time/batch = 15.9676s	
17784/22950 (epoch 38.745), train_loss = 1.05815899, grad/param norm = 3.0135e-01, time/batch = 15.5185s	
17785/22950 (epoch 38.747), train_loss = 0.88788531, grad/param norm = 2.6507e-01, time/batch = 14.8256s	
17786/22950 (epoch 38.749), train_loss = 0.81135454, grad/param norm = 2.9084e-01, time/batch = 15.2059s	
17787/22950 (epoch 38.752), train_loss = 1.03380110, grad/param norm = 3.8695e-01, time/batch = 14.9955s	
17788/22950 (epoch 38.754), train_loss = 0.88543479, grad/param norm = 2.6787e-01, time/batch = 14.9772s	
17789/22950 (epoch 38.756), train_loss = 0.82291690, grad/param norm = 2.6998e-01, time/batch = 14.9124s	
17790/22950 (epoch 38.758), train_loss = 0.87726722, grad/param norm = 2.4457e-01, time/batch = 15.2884s	
17791/22950 (epoch 38.760), train_loss = 0.85289869, grad/param norm = 2.7151e-01, time/batch = 15.2798s	
17792/22950 (epoch 38.763), train_loss = 0.87439911, grad/param norm = 2.8659e-01, time/batch = 15.8057s	
17793/22950 (epoch 38.765), train_loss = 0.85780657, grad/param norm = 3.0614e-01, time/batch = 14.9543s	
17794/22950 (epoch 38.767), train_loss = 1.04525502, grad/param norm = 3.1773e-01, time/batch = 15.3793s	
17795/22950 (epoch 38.769), train_loss = 0.89200165, grad/param norm = 2.6974e-01, time/batch = 15.1400s	
17796/22950 (epoch 38.771), train_loss = 0.76203551, grad/param norm = 2.9004e-01, time/batch = 15.0609s	
17797/22950 (epoch 38.773), train_loss = 0.64846323, grad/param norm = 2.2369e-01, time/batch = 14.8951s	
17798/22950 (epoch 38.776), train_loss = 0.77165494, grad/param norm = 2.1955e-01, time/batch = 15.2274s	
17799/22950 (epoch 38.778), train_loss = 0.76610260, grad/param norm = 2.9201e-01, time/batch = 14.9068s	
17800/22950 (epoch 38.780), train_loss = 0.86362649, grad/param norm = 2.4792e-01, time/batch = 15.1904s	
17801/22950 (epoch 38.782), train_loss = 0.90968080, grad/param norm = 2.7971e-01, time/batch = 14.8968s	
17802/22950 (epoch 38.784), train_loss = 0.79644523, grad/param norm = 2.6287e-01, time/batch = 15.0527s	
17803/22950 (epoch 38.786), train_loss = 0.86368416, grad/param norm = 4.0025e-01, time/batch = 15.5244s	
17804/22950 (epoch 38.789), train_loss = 0.70673196, grad/param norm = 2.5433e-01, time/batch = 14.7260s	
17805/22950 (epoch 38.791), train_loss = 0.74896607, grad/param norm = 3.0345e-01, time/batch = 14.8154s	
17806/22950 (epoch 38.793), train_loss = 0.98524394, grad/param norm = 5.3871e-01, time/batch = 15.3045s	
17807/22950 (epoch 38.795), train_loss = 0.80593716, grad/param norm = 2.3421e-01, time/batch = 15.0754s	
17808/22950 (epoch 38.797), train_loss = 0.95258686, grad/param norm = 2.7748e-01, time/batch = 15.1572s	
17809/22950 (epoch 38.800), train_loss = 0.78452389, grad/param norm = 2.3634e-01, time/batch = 14.9988s	
17810/22950 (epoch 38.802), train_loss = 0.83146212, grad/param norm = 2.6215e-01, time/batch = 15.2271s	
17811/22950 (epoch 38.804), train_loss = 0.82445370, grad/param norm = 2.5444e-01, time/batch = 15.3053s	
17812/22950 (epoch 38.806), train_loss = 0.73636354, grad/param norm = 2.3611e-01, time/batch = 14.9141s	
17813/22950 (epoch 38.808), train_loss = 0.85592263, grad/param norm = 2.5379e-01, time/batch = 15.8922s	
17814/22950 (epoch 38.810), train_loss = 0.80347219, grad/param norm = 2.6900e-01, time/batch = 31.0438s	
17815/22950 (epoch 38.813), train_loss = 0.71294209, grad/param norm = 2.3941e-01, time/batch = 17.6212s	
17816/22950 (epoch 38.815), train_loss = 0.66155709, grad/param norm = 2.4226e-01, time/batch = 16.1663s	
17817/22950 (epoch 38.817), train_loss = 0.74850261, grad/param norm = 2.2370e-01, time/batch = 16.4793s	
17818/22950 (epoch 38.819), train_loss = 0.79093889, grad/param norm = 2.5716e-01, time/batch = 17.3729s	
17819/22950 (epoch 38.821), train_loss = 0.80283107, grad/param norm = 2.5027e-01, time/batch = 17.1155s	
17820/22950 (epoch 38.824), train_loss = 0.84665267, grad/param norm = 2.5788e-01, time/batch = 17.0301s	
17821/22950 (epoch 38.826), train_loss = 0.87129484, grad/param norm = 2.7066e-01, time/batch = 17.9393s	
17822/22950 (epoch 38.828), train_loss = 0.79300206, grad/param norm = 2.7135e-01, time/batch = 16.5284s	
17823/22950 (epoch 38.830), train_loss = 0.80577058, grad/param norm = 2.5605e-01, time/batch = 17.9434s	
17824/22950 (epoch 38.832), train_loss = 0.84647379, grad/param norm = 2.5418e-01, time/batch = 19.3616s	
17825/22950 (epoch 38.834), train_loss = 0.68759448, grad/param norm = 3.7771e-01, time/batch = 17.7921s	
17826/22950 (epoch 38.837), train_loss = 0.84438890, grad/param norm = 2.8996e-01, time/batch = 19.6101s	
17827/22950 (epoch 38.839), train_loss = 0.70053913, grad/param norm = 2.8070e-01, time/batch = 18.8749s	
17828/22950 (epoch 38.841), train_loss = 0.80812500, grad/param norm = 2.3651e-01, time/batch = 20.1971s	
17829/22950 (epoch 38.843), train_loss = 0.78782144, grad/param norm = 2.5003e-01, time/batch = 17.4656s	
17830/22950 (epoch 38.845), train_loss = 0.83123860, grad/param norm = 2.8697e-01, time/batch = 16.9345s	
17831/22950 (epoch 38.847), train_loss = 0.86752987, grad/param norm = 2.6513e-01, time/batch = 19.5402s	
17832/22950 (epoch 38.850), train_loss = 0.90187060, grad/param norm = 2.9276e-01, time/batch = 18.3842s	
17833/22950 (epoch 38.852), train_loss = 0.90248424, grad/param norm = 3.2766e-01, time/batch = 16.4533s	
17834/22950 (epoch 38.854), train_loss = 0.83768981, grad/param norm = 2.4516e-01, time/batch = 16.6271s	
17835/22950 (epoch 38.856), train_loss = 0.94404354, grad/param norm = 3.1402e-01, time/batch = 15.8388s	
17836/22950 (epoch 38.858), train_loss = 0.90057788, grad/param norm = 2.7125e-01, time/batch = 15.9716s	
17837/22950 (epoch 38.861), train_loss = 0.89246971, grad/param norm = 2.7616e-01, time/batch = 16.6037s	
17838/22950 (epoch 38.863), train_loss = 0.93693360, grad/param norm = 3.0968e-01, time/batch = 17.5235s	
17839/22950 (epoch 38.865), train_loss = 0.94888922, grad/param norm = 2.8235e-01, time/batch = 16.6085s	
17840/22950 (epoch 38.867), train_loss = 0.86700188, grad/param norm = 3.0566e-01, time/batch = 17.7820s	
17841/22950 (epoch 38.869), train_loss = 1.00020717, grad/param norm = 2.7678e-01, time/batch = 18.1185s	
17842/22950 (epoch 38.871), train_loss = 0.87692274, grad/param norm = 2.9004e-01, time/batch = 18.2144s	
17843/22950 (epoch 38.874), train_loss = 0.87645689, grad/param norm = 2.3458e-01, time/batch = 17.3449s	
17844/22950 (epoch 38.876), train_loss = 0.95174405, grad/param norm = 3.3157e-01, time/batch = 18.9561s	
17845/22950 (epoch 38.878), train_loss = 0.87401787, grad/param norm = 3.2448e-01, time/batch = 18.4571s	
17846/22950 (epoch 38.880), train_loss = 1.02511804, grad/param norm = 2.8426e-01, time/batch = 19.9528s	
17847/22950 (epoch 38.882), train_loss = 0.75664420, grad/param norm = 2.5874e-01, time/batch = 17.0962s	
17848/22950 (epoch 38.885), train_loss = 0.87514767, grad/param norm = 3.1544e-01, time/batch = 19.1235s	
17849/22950 (epoch 38.887), train_loss = 0.83499622, grad/param norm = 2.4902e-01, time/batch = 18.4563s	
17850/22950 (epoch 38.889), train_loss = 0.88282764, grad/param norm = 2.6877e-01, time/batch = 17.5338s	
17851/22950 (epoch 38.891), train_loss = 0.78477911, grad/param norm = 2.3284e-01, time/batch = 20.0450s	
17852/22950 (epoch 38.893), train_loss = 0.87283055, grad/param norm = 2.7906e-01, time/batch = 16.2993s	
17853/22950 (epoch 38.895), train_loss = 0.99255959, grad/param norm = 2.9489e-01, time/batch = 17.1182s	
17854/22950 (epoch 38.898), train_loss = 0.91379495, grad/param norm = 2.7405e-01, time/batch = 17.5427s	
17855/22950 (epoch 38.900), train_loss = 0.80040763, grad/param norm = 2.2726e-01, time/batch = 16.0076s	
17856/22950 (epoch 38.902), train_loss = 0.86042374, grad/param norm = 2.6674e-01, time/batch = 16.7589s	
17857/22950 (epoch 38.904), train_loss = 0.85138291, grad/param norm = 2.7841e-01, time/batch = 16.2237s	
17858/22950 (epoch 38.906), train_loss = 0.86326743, grad/param norm = 2.9220e-01, time/batch = 15.9171s	
17859/22950 (epoch 38.908), train_loss = 0.75874694, grad/param norm = 2.4992e-01, time/batch = 18.2537s	
17860/22950 (epoch 38.911), train_loss = 0.70073183, grad/param norm = 2.2210e-01, time/batch = 16.4418s	
17861/22950 (epoch 38.913), train_loss = 0.82603062, grad/param norm = 2.5827e-01, time/batch = 20.2756s	
17862/22950 (epoch 38.915), train_loss = 0.95908867, grad/param norm = 3.1267e-01, time/batch = 18.2243s	
17863/22950 (epoch 38.917), train_loss = 0.75883255, grad/param norm = 2.5394e-01, time/batch = 17.6124s	
17864/22950 (epoch 38.919), train_loss = 0.87190906, grad/param norm = 2.6601e-01, time/batch = 17.1167s	
17865/22950 (epoch 38.922), train_loss = 0.83359382, grad/param norm = 2.5252e-01, time/batch = 17.5399s	
17866/22950 (epoch 38.924), train_loss = 0.88131130, grad/param norm = 2.9193e-01, time/batch = 18.4668s	
17867/22950 (epoch 38.926), train_loss = 0.72244135, grad/param norm = 2.8451e-01, time/batch = 17.0462s	
17868/22950 (epoch 38.928), train_loss = 0.76206664, grad/param norm = 2.4313e-01, time/batch = 18.7840s	
17869/22950 (epoch 38.930), train_loss = 0.74786644, grad/param norm = 2.1977e-01, time/batch = 17.5366s	
17870/22950 (epoch 38.932), train_loss = 0.70721331, grad/param norm = 2.5941e-01, time/batch = 18.7755s	
17871/22950 (epoch 38.935), train_loss = 0.87931558, grad/param norm = 2.5944e-01, time/batch = 18.7108s	
17872/22950 (epoch 38.937), train_loss = 0.82247559, grad/param norm = 2.7796e-01, time/batch = 17.5678s	
17873/22950 (epoch 38.939), train_loss = 0.78881290, grad/param norm = 2.8062e-01, time/batch = 19.1075s	
17874/22950 (epoch 38.941), train_loss = 0.82045546, grad/param norm = 2.5366e-01, time/batch = 16.0261s	
17875/22950 (epoch 38.943), train_loss = 0.84437882, grad/param norm = 3.2857e-01, time/batch = 17.6200s	
17876/22950 (epoch 38.946), train_loss = 0.70781444, grad/param norm = 2.5540e-01, time/batch = 16.5416s	
17877/22950 (epoch 38.948), train_loss = 0.93010275, grad/param norm = 3.2196e-01, time/batch = 16.1624s	
17878/22950 (epoch 38.950), train_loss = 0.81743200, grad/param norm = 2.6753e-01, time/batch = 16.1416s	
17879/22950 (epoch 38.952), train_loss = 0.87117000, grad/param norm = 2.3691e-01, time/batch = 18.5319s	
17880/22950 (epoch 38.954), train_loss = 0.88285942, grad/param norm = 2.5716e-01, time/batch = 19.6953s	
17881/22950 (epoch 38.956), train_loss = 0.79191139, grad/param norm = 2.9909e-01, time/batch = 19.0267s	
17882/22950 (epoch 38.959), train_loss = 0.75783720, grad/param norm = 2.7907e-01, time/batch = 17.8021s	
17883/22950 (epoch 38.961), train_loss = 0.82726447, grad/param norm = 2.4850e-01, time/batch = 19.2900s	
17884/22950 (epoch 38.963), train_loss = 0.82977468, grad/param norm = 2.4276e-01, time/batch = 17.0862s	
17885/22950 (epoch 38.965), train_loss = 0.92426612, grad/param norm = 2.8786e-01, time/batch = 19.1168s	
17886/22950 (epoch 38.967), train_loss = 0.79243628, grad/param norm = 2.3574e-01, time/batch = 16.7570s	
17887/22950 (epoch 38.969), train_loss = 0.74023697, grad/param norm = 2.8194e-01, time/batch = 18.1215s	
17888/22950 (epoch 38.972), train_loss = 0.80192100, grad/param norm = 2.2846e-01, time/batch = 20.1098s	
17889/22950 (epoch 38.974), train_loss = 0.77541830, grad/param norm = 2.6946e-01, time/batch = 18.4583s	
17890/22950 (epoch 38.976), train_loss = 0.83393000, grad/param norm = 2.4556e-01, time/batch = 16.4416s	
17891/22950 (epoch 38.978), train_loss = 0.76334052, grad/param norm = 2.4891e-01, time/batch = 19.6923s	
17892/22950 (epoch 38.980), train_loss = 0.78512771, grad/param norm = 2.9911e-01, time/batch = 19.3720s	
17893/22950 (epoch 38.983), train_loss = 0.86678335, grad/param norm = 2.3663e-01, time/batch = 16.9585s	
17894/22950 (epoch 38.985), train_loss = 0.75517550, grad/param norm = 2.4063e-01, time/batch = 16.9024s	
17895/22950 (epoch 38.987), train_loss = 0.75445766, grad/param norm = 2.2283e-01, time/batch = 16.8107s	
17896/22950 (epoch 38.989), train_loss = 0.83529859, grad/param norm = 2.5362e-01, time/batch = 16.1079s	
17897/22950 (epoch 38.991), train_loss = 0.71513219, grad/param norm = 2.4355e-01, time/batch = 16.2424s	
17898/22950 (epoch 38.993), train_loss = 0.84715933, grad/param norm = 2.6442e-01, time/batch = 15.7691s	
17899/22950 (epoch 38.996), train_loss = 0.81039658, grad/param norm = 3.1194e-01, time/batch = 17.0560s	
17900/22950 (epoch 38.998), train_loss = 0.73610923, grad/param norm = 3.0565e-01, time/batch = 18.1041s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
17901/22950 (epoch 39.000), train_loss = 0.69104483, grad/param norm = 2.2493e-01, time/batch = 19.2849s	
17902/22950 (epoch 39.002), train_loss = 0.98834681, grad/param norm = 2.8705e-01, time/batch = 18.3884s	
17903/22950 (epoch 39.004), train_loss = 0.87419731, grad/param norm = 2.6713e-01, time/batch = 17.0358s	
17904/22950 (epoch 39.007), train_loss = 0.81743996, grad/param norm = 2.6608e-01, time/batch = 16.7842s	
17905/22950 (epoch 39.009), train_loss = 0.94996476, grad/param norm = 3.1874e-01, time/batch = 17.6797s	
17906/22950 (epoch 39.011), train_loss = 0.72835590, grad/param norm = 2.6915e-01, time/batch = 19.1199s	
17907/22950 (epoch 39.013), train_loss = 0.79195541, grad/param norm = 2.7351e-01, time/batch = 18.3589s	
17908/22950 (epoch 39.015), train_loss = 0.84818073, grad/param norm = 2.7350e-01, time/batch = 19.6166s	
17909/22950 (epoch 39.017), train_loss = 0.85052148, grad/param norm = 2.6649e-01, time/batch = 19.2012s	
17910/22950 (epoch 39.020), train_loss = 0.84882059, grad/param norm = 2.3475e-01, time/batch = 16.6810s	
17911/22950 (epoch 39.022), train_loss = 0.72473388, grad/param norm = 2.1661e-01, time/batch = 16.7133s	
17912/22950 (epoch 39.024), train_loss = 0.79722216, grad/param norm = 2.3517e-01, time/batch = 17.7777s	
17913/22950 (epoch 39.026), train_loss = 0.86461594, grad/param norm = 2.5902e-01, time/batch = 17.7079s	
17914/22950 (epoch 39.028), train_loss = 0.88701409, grad/param norm = 2.6168e-01, time/batch = 16.1996s	
17915/22950 (epoch 39.031), train_loss = 0.80729925, grad/param norm = 2.9009e-01, time/batch = 16.0698s	
17916/22950 (epoch 39.033), train_loss = 0.91093799, grad/param norm = 2.6485e-01, time/batch = 16.5130s	
17917/22950 (epoch 39.035), train_loss = 0.82512668, grad/param norm = 2.2552e-01, time/batch = 17.6198s	
17918/22950 (epoch 39.037), train_loss = 0.83360991, grad/param norm = 2.7219e-01, time/batch = 15.8585s	
17919/22950 (epoch 39.039), train_loss = 0.82095042, grad/param norm = 2.9958e-01, time/batch = 18.3710s	
17920/22950 (epoch 39.041), train_loss = 0.77216173, grad/param norm = 2.9233e-01, time/batch = 17.7679s	
17921/22950 (epoch 39.044), train_loss = 0.86052392, grad/param norm = 2.5749e-01, time/batch = 16.1304s	
17922/22950 (epoch 39.046), train_loss = 0.81174539, grad/param norm = 2.5025e-01, time/batch = 15.6018s	
17923/22950 (epoch 39.048), train_loss = 0.84574193, grad/param norm = 2.6258e-01, time/batch = 16.1089s	
17924/22950 (epoch 39.050), train_loss = 0.78898725, grad/param norm = 2.9243e-01, time/batch = 19.1175s	
17925/22950 (epoch 39.052), train_loss = 0.84575571, grad/param norm = 2.4308e-01, time/batch = 18.8805s	
17926/22950 (epoch 39.054), train_loss = 0.96345321, grad/param norm = 2.8036e-01, time/batch = 18.8729s	
17927/22950 (epoch 39.057), train_loss = 0.92960997, grad/param norm = 2.4823e-01, time/batch = 18.6246s	
17928/22950 (epoch 39.059), train_loss = 0.94741348, grad/param norm = 2.7299e-01, time/batch = 17.4402s	
17929/22950 (epoch 39.061), train_loss = 0.76391385, grad/param norm = 2.3886e-01, time/batch = 19.7140s	
17930/22950 (epoch 39.063), train_loss = 0.87264494, grad/param norm = 2.5307e-01, time/batch = 19.7839s	
17931/22950 (epoch 39.065), train_loss = 0.75056433, grad/param norm = 2.6331e-01, time/batch = 16.9414s	
17932/22950 (epoch 39.068), train_loss = 0.86281414, grad/param norm = 2.7101e-01, time/batch = 17.3153s	
17933/22950 (epoch 39.070), train_loss = 0.73277193, grad/param norm = 1.9777e-01, time/batch = 17.8751s	
17934/22950 (epoch 39.072), train_loss = 0.88384671, grad/param norm = 2.8760e-01, time/batch = 18.5157s	
17935/22950 (epoch 39.074), train_loss = 0.87462932, grad/param norm = 2.6568e-01, time/batch = 18.4594s	
17936/22950 (epoch 39.076), train_loss = 0.87119900, grad/param norm = 2.7471e-01, time/batch = 19.9402s	
17937/22950 (epoch 39.078), train_loss = 0.92338563, grad/param norm = 2.7173e-01, time/batch = 17.7500s	
17938/22950 (epoch 39.081), train_loss = 0.96095619, grad/param norm = 2.6369e-01, time/batch = 16.4331s	
17939/22950 (epoch 39.083), train_loss = 0.86279327, grad/param norm = 2.6305e-01, time/batch = 16.2290s	
17940/22950 (epoch 39.085), train_loss = 0.71466029, grad/param norm = 2.4462e-01, time/batch = 17.6938s	
17941/22950 (epoch 39.087), train_loss = 0.76208586, grad/param norm = 2.5304e-01, time/batch = 17.8751s	
17942/22950 (epoch 39.089), train_loss = 0.86623569, grad/param norm = 2.6373e-01, time/batch = 17.8892s	
17943/22950 (epoch 39.092), train_loss = 0.78076517, grad/param norm = 2.4944e-01, time/batch = 18.8033s	
17944/22950 (epoch 39.094), train_loss = 0.80016370, grad/param norm = 2.6583e-01, time/batch = 16.5571s	
17945/22950 (epoch 39.096), train_loss = 0.95029831, grad/param norm = 2.7832e-01, time/batch = 16.1767s	
17946/22950 (epoch 39.098), train_loss = 0.88208237, grad/param norm = 2.5863e-01, time/batch = 19.7973s	
17947/22950 (epoch 39.100), train_loss = 0.81270307, grad/param norm = 2.2339e-01, time/batch = 18.5486s	
17948/22950 (epoch 39.102), train_loss = 0.83930733, grad/param norm = 2.6051e-01, time/batch = 17.1852s	
17949/22950 (epoch 39.105), train_loss = 0.69158713, grad/param norm = 2.2272e-01, time/batch = 18.8143s	
17950/22950 (epoch 39.107), train_loss = 0.78186000, grad/param norm = 2.5961e-01, time/batch = 19.8654s	
17951/22950 (epoch 39.109), train_loss = 0.79409934, grad/param norm = 2.4133e-01, time/batch = 17.5471s	
17952/22950 (epoch 39.111), train_loss = 0.69582375, grad/param norm = 2.4299e-01, time/batch = 18.2239s	
17953/22950 (epoch 39.113), train_loss = 0.86079743, grad/param norm = 2.5087e-01, time/batch = 17.8809s	
17954/22950 (epoch 39.115), train_loss = 0.85443539, grad/param norm = 3.0207e-01, time/batch = 17.6942s	
17955/22950 (epoch 39.118), train_loss = 0.93767599, grad/param norm = 2.4512e-01, time/batch = 17.8715s	
17956/22950 (epoch 39.120), train_loss = 0.74207831, grad/param norm = 2.4846e-01, time/batch = 20.1219s	
17957/22950 (epoch 39.122), train_loss = 0.88624063, grad/param norm = 2.5489e-01, time/batch = 17.5184s	
17958/22950 (epoch 39.124), train_loss = 0.74066122, grad/param norm = 2.3282e-01, time/batch = 16.5959s	
17959/22950 (epoch 39.126), train_loss = 0.82564017, grad/param norm = 2.3390e-01, time/batch = 16.5631s	
17960/22950 (epoch 39.129), train_loss = 0.75431930, grad/param norm = 2.0550e-01, time/batch = 19.5310s	
17961/22950 (epoch 39.131), train_loss = 0.81392177, grad/param norm = 2.2985e-01, time/batch = 16.9599s	
17962/22950 (epoch 39.133), train_loss = 0.86602269, grad/param norm = 2.4422e-01, time/batch = 15.9726s	
17963/22950 (epoch 39.135), train_loss = 0.82273236, grad/param norm = 2.0796e-01, time/batch = 17.9717s	
17964/22950 (epoch 39.137), train_loss = 0.88405121, grad/param norm = 3.0604e-01, time/batch = 16.0415s	
17965/22950 (epoch 39.139), train_loss = 0.74929482, grad/param norm = 2.5122e-01, time/batch = 16.1248s	
17966/22950 (epoch 39.142), train_loss = 0.74658257, grad/param norm = 2.0837e-01, time/batch = 15.2283s	
17967/22950 (epoch 39.144), train_loss = 0.80307199, grad/param norm = 2.4949e-01, time/batch = 15.9695s	
17968/22950 (epoch 39.146), train_loss = 0.76722558, grad/param norm = 2.6575e-01, time/batch = 16.5517s	
17969/22950 (epoch 39.148), train_loss = 0.76142779, grad/param norm = 2.4410e-01, time/batch = 15.5467s	
17970/22950 (epoch 39.150), train_loss = 0.84746341, grad/param norm = 2.8430e-01, time/batch = 15.7080s	
17971/22950 (epoch 39.153), train_loss = 0.73882627, grad/param norm = 2.2790e-01, time/batch = 15.5342s	
17972/22950 (epoch 39.155), train_loss = 0.77203718, grad/param norm = 2.2143e-01, time/batch = 16.1269s	
17973/22950 (epoch 39.157), train_loss = 0.79741042, grad/param norm = 2.2486e-01, time/batch = 19.4636s	
17974/22950 (epoch 39.159), train_loss = 0.73349245, grad/param norm = 2.2774e-01, time/batch = 19.5428s	
17975/22950 (epoch 39.161), train_loss = 0.78116234, grad/param norm = 2.2841e-01, time/batch = 17.4614s	
17976/22950 (epoch 39.163), train_loss = 0.74424289, grad/param norm = 2.7385e-01, time/batch = 18.3837s	
17977/22950 (epoch 39.166), train_loss = 0.86515623, grad/param norm = 3.5172e-01, time/batch = 17.9752s	
17978/22950 (epoch 39.168), train_loss = 0.86048097, grad/param norm = 2.8347e-01, time/batch = 18.1067s	
17979/22950 (epoch 39.170), train_loss = 0.86136490, grad/param norm = 2.8375e-01, time/batch = 18.8732s	
17980/22950 (epoch 39.172), train_loss = 0.80943970, grad/param norm = 2.5552e-01, time/batch = 19.0462s	
17981/22950 (epoch 39.174), train_loss = 0.88473771, grad/param norm = 2.4814e-01, time/batch = 17.3523s	
17982/22950 (epoch 39.176), train_loss = 0.88814822, grad/param norm = 2.7275e-01, time/batch = 16.9006s	
17983/22950 (epoch 39.179), train_loss = 0.86319714, grad/param norm = 2.7260e-01, time/batch = 16.9591s	
17984/22950 (epoch 39.181), train_loss = 1.06310896, grad/param norm = 3.6810e-01, time/batch = 16.3852s	
17985/22950 (epoch 39.183), train_loss = 0.87123194, grad/param norm = 2.4433e-01, time/batch = 17.8745s	
17986/22950 (epoch 39.185), train_loss = 0.89178240, grad/param norm = 2.6346e-01, time/batch = 19.4417s	
17987/22950 (epoch 39.187), train_loss = 0.76525411, grad/param norm = 2.4752e-01, time/batch = 18.2955s	
17988/22950 (epoch 39.190), train_loss = 0.67653467, grad/param norm = 2.4699e-01, time/batch = 16.8790s	
17989/22950 (epoch 39.192), train_loss = 0.64762025, grad/param norm = 2.2748e-01, time/batch = 18.6260s	
17990/22950 (epoch 39.194), train_loss = 0.80193528, grad/param norm = 2.7547e-01, time/batch = 18.1052s	
17991/22950 (epoch 39.196), train_loss = 0.60701343, grad/param norm = 2.3647e-01, time/batch = 20.1181s	
17992/22950 (epoch 39.198), train_loss = 0.84871485, grad/param norm = 2.5866e-01, time/batch = 16.7547s	
17993/22950 (epoch 39.200), train_loss = 0.75065510, grad/param norm = 2.2495e-01, time/batch = 18.4516s	
17994/22950 (epoch 39.203), train_loss = 0.68554448, grad/param norm = 2.1733e-01, time/batch = 20.4379s	
17995/22950 (epoch 39.205), train_loss = 0.75565682, grad/param norm = 2.3360e-01, time/batch = 18.5238s	
17996/22950 (epoch 39.207), train_loss = 0.84826192, grad/param norm = 2.7022e-01, time/batch = 18.7842s	
17997/22950 (epoch 39.209), train_loss = 0.78889177, grad/param norm = 2.8269e-01, time/batch = 19.8629s	
17998/22950 (epoch 39.211), train_loss = 0.68823326, grad/param norm = 2.2607e-01, time/batch = 17.0957s	
17999/22950 (epoch 39.214), train_loss = 0.74335580, grad/param norm = 2.3061e-01, time/batch = 18.2020s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch39.22_2.0514.t7	
18000/22950 (epoch 39.216), train_loss = 0.89959129, grad/param norm = 2.3340e-01, time/batch = 17.6502s	
18001/22950 (epoch 39.218), train_loss = 1.29946830, grad/param norm = 2.9598e-01, time/batch = 20.2822s	
18002/22950 (epoch 39.220), train_loss = 0.87953210, grad/param norm = 2.8567e-01, time/batch = 18.1112s	
18003/22950 (epoch 39.222), train_loss = 0.92343697, grad/param norm = 3.3322e-01, time/batch = 18.3806s	
18004/22950 (epoch 39.224), train_loss = 0.82053731, grad/param norm = 2.9268e-01, time/batch = 18.4668s	
18005/22950 (epoch 39.227), train_loss = 0.86903419, grad/param norm = 2.4266e-01, time/batch = 18.4477s	
18006/22950 (epoch 39.229), train_loss = 0.93956635, grad/param norm = 2.5320e-01, time/batch = 19.0485s	
18007/22950 (epoch 39.231), train_loss = 0.66805843, grad/param norm = 2.4382e-01, time/batch = 19.0512s	
18008/22950 (epoch 39.233), train_loss = 0.77106320, grad/param norm = 2.3761e-01, time/batch = 20.0747s	
18009/22950 (epoch 39.235), train_loss = 0.93658309, grad/param norm = 2.3268e-01, time/batch = 32.0330s	
18010/22950 (epoch 39.237), train_loss = 0.76422152, grad/param norm = 2.2168e-01, time/batch = 16.8501s	
18011/22950 (epoch 39.240), train_loss = 0.82772134, grad/param norm = 2.5585e-01, time/batch = 16.5908s	
18012/22950 (epoch 39.242), train_loss = 0.96134556, grad/param norm = 2.6374e-01, time/batch = 16.3218s	
18013/22950 (epoch 39.244), train_loss = 0.93129976, grad/param norm = 2.6787e-01, time/batch = 16.0368s	
18014/22950 (epoch 39.246), train_loss = 0.93703805, grad/param norm = 2.6405e-01, time/batch = 16.1850s	
18015/22950 (epoch 39.248), train_loss = 0.83397023, grad/param norm = 2.6485e-01, time/batch = 16.0496s	
18016/22950 (epoch 39.251), train_loss = 0.76313833, grad/param norm = 2.5564e-01, time/batch = 15.6333s	
18017/22950 (epoch 39.253), train_loss = 0.74640925, grad/param norm = 2.5135e-01, time/batch = 15.9474s	
18018/22950 (epoch 39.255), train_loss = 0.85929432, grad/param norm = 2.5322e-01, time/batch = 15.9545s	
18019/22950 (epoch 39.257), train_loss = 0.91843510, grad/param norm = 2.9666e-01, time/batch = 15.8907s	
18020/22950 (epoch 39.259), train_loss = 0.69590031, grad/param norm = 2.5432e-01, time/batch = 15.7106s	
18021/22950 (epoch 39.261), train_loss = 0.75734751, grad/param norm = 2.6139e-01, time/batch = 15.9639s	
18022/22950 (epoch 39.264), train_loss = 0.72686669, grad/param norm = 2.2011e-01, time/batch = 16.3456s	
18023/22950 (epoch 39.266), train_loss = 0.78110306, grad/param norm = 2.3092e-01, time/batch = 16.4242s	
18024/22950 (epoch 39.268), train_loss = 0.80881460, grad/param norm = 2.9101e-01, time/batch = 15.7168s	
18025/22950 (epoch 39.270), train_loss = 0.78701305, grad/param norm = 2.2564e-01, time/batch = 15.8066s	
18026/22950 (epoch 39.272), train_loss = 0.83718883, grad/param norm = 2.8608e-01, time/batch = 16.4289s	
18027/22950 (epoch 39.275), train_loss = 0.77764925, grad/param norm = 2.6667e-01, time/batch = 15.7235s	
18028/22950 (epoch 39.277), train_loss = 0.68499514, grad/param norm = 2.1039e-01, time/batch = 15.6400s	
18029/22950 (epoch 39.279), train_loss = 0.72521634, grad/param norm = 2.9377e-01, time/batch = 15.6390s	
18030/22950 (epoch 39.281), train_loss = 0.79441492, grad/param norm = 2.6480e-01, time/batch = 16.5745s	
18031/22950 (epoch 39.283), train_loss = 0.71085039, grad/param norm = 2.1539e-01, time/batch = 16.4139s	
18032/22950 (epoch 39.285), train_loss = 0.81891437, grad/param norm = 2.2909e-01, time/batch = 16.5779s	
18033/22950 (epoch 39.288), train_loss = 0.90998611, grad/param norm = 2.4294e-01, time/batch = 15.7118s	
18034/22950 (epoch 39.290), train_loss = 0.78512605, grad/param norm = 2.4771e-01, time/batch = 15.5573s	
18035/22950 (epoch 39.292), train_loss = 0.91039350, grad/param norm = 2.5207e-01, time/batch = 16.0367s	
18036/22950 (epoch 39.294), train_loss = 0.85005506, grad/param norm = 2.3209e-01, time/batch = 15.6302s	
18037/22950 (epoch 39.296), train_loss = 0.64845553, grad/param norm = 2.1421e-01, time/batch = 16.8622s	
18038/22950 (epoch 39.298), train_loss = 0.79848530, grad/param norm = 2.5059e-01, time/batch = 16.3314s	
18039/22950 (epoch 39.301), train_loss = 0.82644508, grad/param norm = 2.2894e-01, time/batch = 16.4591s	
18040/22950 (epoch 39.303), train_loss = 0.80650201, grad/param norm = 2.7391e-01, time/batch = 15.8623s	
18041/22950 (epoch 39.305), train_loss = 0.80151173, grad/param norm = 2.3963e-01, time/batch = 16.3659s	
18042/22950 (epoch 39.307), train_loss = 0.92246620, grad/param norm = 2.6650e-01, time/batch = 16.0260s	
18043/22950 (epoch 39.309), train_loss = 0.76547828, grad/param norm = 2.2948e-01, time/batch = 15.7940s	
18044/22950 (epoch 39.312), train_loss = 0.82551258, grad/param norm = 2.5258e-01, time/batch = 16.1889s	
18045/22950 (epoch 39.314), train_loss = 0.82466794, grad/param norm = 2.5110e-01, time/batch = 16.1244s	
18046/22950 (epoch 39.316), train_loss = 0.77774117, grad/param norm = 2.4882e-01, time/batch = 16.1170s	
18047/22950 (epoch 39.318), train_loss = 0.70964075, grad/param norm = 1.9588e-01, time/batch = 15.7106s	
18048/22950 (epoch 39.320), train_loss = 0.74781022, grad/param norm = 2.1597e-01, time/batch = 15.5605s	
18049/22950 (epoch 39.322), train_loss = 0.75904896, grad/param norm = 2.3551e-01, time/batch = 15.7074s	
18050/22950 (epoch 39.325), train_loss = 0.63549918, grad/param norm = 2.2385e-01, time/batch = 15.3811s	
18051/22950 (epoch 39.327), train_loss = 0.63000564, grad/param norm = 2.0648e-01, time/batch = 15.9327s	
18052/22950 (epoch 39.329), train_loss = 0.74120799, grad/param norm = 2.2624e-01, time/batch = 16.6301s	
18053/22950 (epoch 39.331), train_loss = 0.71333829, grad/param norm = 2.3798e-01, time/batch = 16.0970s	
18054/22950 (epoch 39.333), train_loss = 0.71980396, grad/param norm = 2.1965e-01, time/batch = 16.1042s	
18055/22950 (epoch 39.336), train_loss = 0.78450442, grad/param norm = 2.5790e-01, time/batch = 15.6371s	
18056/22950 (epoch 39.338), train_loss = 0.80958019, grad/param norm = 2.4295e-01, time/batch = 16.3524s	
18057/22950 (epoch 39.340), train_loss = 0.77457014, grad/param norm = 2.6637e-01, time/batch = 15.7939s	
18058/22950 (epoch 39.342), train_loss = 0.96979855, grad/param norm = 3.2897e-01, time/batch = 15.8802s	
18059/22950 (epoch 39.344), train_loss = 0.78970733, grad/param norm = 2.8116e-01, time/batch = 15.8643s	
18060/22950 (epoch 39.346), train_loss = 0.88003312, grad/param norm = 2.6625e-01, time/batch = 16.6308s	
18061/22950 (epoch 39.349), train_loss = 0.80424673, grad/param norm = 2.3445e-01, time/batch = 16.2705s	
18062/22950 (epoch 39.351), train_loss = 0.83535714, grad/param norm = 2.5174e-01, time/batch = 15.6487s	
18063/22950 (epoch 39.353), train_loss = 0.83784738, grad/param norm = 3.1079e-01, time/batch = 16.6823s	
18064/22950 (epoch 39.355), train_loss = 0.88359068, grad/param norm = 2.5944e-01, time/batch = 15.8899s	
18065/22950 (epoch 39.357), train_loss = 0.77796796, grad/param norm = 2.7296e-01, time/batch = 15.9500s	
18066/22950 (epoch 39.359), train_loss = 0.79819901, grad/param norm = 2.8679e-01, time/batch = 15.6331s	
18067/22950 (epoch 39.362), train_loss = 0.84731637, grad/param norm = 2.8096e-01, time/batch = 16.2736s	
18068/22950 (epoch 39.364), train_loss = 0.82751679, grad/param norm = 2.9273e-01, time/batch = 15.7178s	
18069/22950 (epoch 39.366), train_loss = 0.81555455, grad/param norm = 2.2555e-01, time/batch = 15.8818s	
18070/22950 (epoch 39.368), train_loss = 0.84354301, grad/param norm = 2.5650e-01, time/batch = 16.1053s	
18071/22950 (epoch 39.370), train_loss = 0.77769343, grad/param norm = 2.3188e-01, time/batch = 16.2816s	
18072/22950 (epoch 39.373), train_loss = 0.74663212, grad/param norm = 2.5814e-01, time/batch = 15.5607s	
18073/22950 (epoch 39.375), train_loss = 0.91053921, grad/param norm = 2.9600e-01, time/batch = 15.7210s	
18074/22950 (epoch 39.377), train_loss = 0.74750293, grad/param norm = 2.6830e-01, time/batch = 15.8702s	
18075/22950 (epoch 39.379), train_loss = 0.80840678, grad/param norm = 2.5949e-01, time/batch = 16.2639s	
18076/22950 (epoch 39.381), train_loss = 0.70439013, grad/param norm = 2.2373e-01, time/batch = 15.6538s	
18077/22950 (epoch 39.383), train_loss = 0.78806135, grad/param norm = 2.5394e-01, time/batch = 16.1070s	
18078/22950 (epoch 39.386), train_loss = 0.75084884, grad/param norm = 2.4741e-01, time/batch = 16.3426s	
18079/22950 (epoch 39.388), train_loss = 0.86896205, grad/param norm = 2.5857e-01, time/batch = 16.0376s	
18080/22950 (epoch 39.390), train_loss = 0.71648545, grad/param norm = 2.5690e-01, time/batch = 15.9583s	
18081/22950 (epoch 39.392), train_loss = 0.74966510, grad/param norm = 2.4017e-01, time/batch = 16.2714s	
18082/22950 (epoch 39.394), train_loss = 0.75694710, grad/param norm = 2.1753e-01, time/batch = 17.0846s	
18083/22950 (epoch 39.397), train_loss = 0.90404456, grad/param norm = 2.3494e-01, time/batch = 15.7776s	
18084/22950 (epoch 39.399), train_loss = 0.87269353, grad/param norm = 2.5066e-01, time/batch = 15.8018s	
18085/22950 (epoch 39.401), train_loss = 0.95573736, grad/param norm = 3.7357e-01, time/batch = 15.8662s	
18086/22950 (epoch 39.403), train_loss = 0.80209628, grad/param norm = 2.8000e-01, time/batch = 16.5173s	
18087/22950 (epoch 39.405), train_loss = 0.92989178, grad/param norm = 3.2823e-01, time/batch = 15.7129s	
18088/22950 (epoch 39.407), train_loss = 0.97776600, grad/param norm = 2.8671e-01, time/batch = 15.9535s	
18089/22950 (epoch 39.410), train_loss = 0.83819082, grad/param norm = 2.5623e-01, time/batch = 15.8731s	
18090/22950 (epoch 39.412), train_loss = 0.79807675, grad/param norm = 2.8788e-01, time/batch = 16.0388s	
18091/22950 (epoch 39.414), train_loss = 0.91259082, grad/param norm = 2.5557e-01, time/batch = 15.6360s	
18092/22950 (epoch 39.416), train_loss = 0.83879665, grad/param norm = 2.6572e-01, time/batch = 15.5489s	
18093/22950 (epoch 39.418), train_loss = 0.85140203, grad/param norm = 3.0872e-01, time/batch = 16.0445s	
18094/22950 (epoch 39.420), train_loss = 0.88520747, grad/param norm = 2.7359e-01, time/batch = 15.9446s	
18095/22950 (epoch 39.423), train_loss = 0.79098720, grad/param norm = 4.2117e-01, time/batch = 15.8571s	
18096/22950 (epoch 39.425), train_loss = 0.82076633, grad/param norm = 2.7738e-01, time/batch = 16.3209s	
18097/22950 (epoch 39.427), train_loss = 0.84175548, grad/param norm = 2.9405e-01, time/batch = 15.7145s	
18098/22950 (epoch 39.429), train_loss = 0.83765325, grad/param norm = 2.3727e-01, time/batch = 15.4049s	
18099/22950 (epoch 39.431), train_loss = 0.89741412, grad/param norm = 2.7679e-01, time/batch = 15.5582s	
18100/22950 (epoch 39.434), train_loss = 0.81903516, grad/param norm = 2.8222e-01, time/batch = 15.6898s	
18101/22950 (epoch 39.436), train_loss = 0.90135857, grad/param norm = 3.0395e-01, time/batch = 15.9649s	
18102/22950 (epoch 39.438), train_loss = 0.83076262, grad/param norm = 2.6438e-01, time/batch = 16.0274s	
18103/22950 (epoch 39.440), train_loss = 0.90954412, grad/param norm = 2.3740e-01, time/batch = 16.2625s	
18104/22950 (epoch 39.442), train_loss = 0.97085137, grad/param norm = 3.3180e-01, time/batch = 16.1855s	
18105/22950 (epoch 39.444), train_loss = 0.87397630, grad/param norm = 3.3077e-01, time/batch = 15.7159s	
18106/22950 (epoch 39.447), train_loss = 0.97895126, grad/param norm = 2.8830e-01, time/batch = 16.2685s	
18107/22950 (epoch 39.449), train_loss = 0.75048265, grad/param norm = 2.3466e-01, time/batch = 16.3469s	
18108/22950 (epoch 39.451), train_loss = 0.83094285, grad/param norm = 2.9665e-01, time/batch = 16.0334s	
18109/22950 (epoch 39.453), train_loss = 0.86508375, grad/param norm = 2.6056e-01, time/batch = 16.0479s	
18110/22950 (epoch 39.455), train_loss = 0.79127480, grad/param norm = 2.1708e-01, time/batch = 16.2544s	
18111/22950 (epoch 39.458), train_loss = 0.83740937, grad/param norm = 2.8026e-01, time/batch = 16.3262s	
18112/22950 (epoch 39.460), train_loss = 0.88583232, grad/param norm = 2.6792e-01, time/batch = 16.4499s	
18113/22950 (epoch 39.462), train_loss = 0.87227793, grad/param norm = 2.4521e-01, time/batch = 16.6551s	
18114/22950 (epoch 39.464), train_loss = 0.79405185, grad/param norm = 2.8269e-01, time/batch = 16.2678s	
18115/22950 (epoch 39.466), train_loss = 0.90869544, grad/param norm = 2.8149e-01, time/batch = 16.3546s	
18116/22950 (epoch 39.468), train_loss = 0.88451356, grad/param norm = 2.5092e-01, time/batch = 16.4120s	
18117/22950 (epoch 39.471), train_loss = 0.85173807, grad/param norm = 2.7203e-01, time/batch = 15.9594s	
18118/22950 (epoch 39.473), train_loss = 0.88287637, grad/param norm = 2.7163e-01, time/batch = 15.7237s	
18119/22950 (epoch 39.475), train_loss = 1.00469518, grad/param norm = 2.9350e-01, time/batch = 16.3226s	
18120/22950 (epoch 39.477), train_loss = 0.81263392, grad/param norm = 2.7996e-01, time/batch = 18.1851s	
18121/22950 (epoch 39.479), train_loss = 0.73842684, grad/param norm = 2.1502e-01, time/batch = 19.7841s	
18122/22950 (epoch 39.481), train_loss = 0.89983671, grad/param norm = 2.9241e-01, time/batch = 18.9504s	
18123/22950 (epoch 39.484), train_loss = 0.86771840, grad/param norm = 2.8839e-01, time/batch = 17.0207s	
18124/22950 (epoch 39.486), train_loss = 0.74041805, grad/param norm = 2.7121e-01, time/batch = 18.2716s	
18125/22950 (epoch 39.488), train_loss = 0.75358133, grad/param norm = 2.8764e-01, time/batch = 15.6301s	
18126/22950 (epoch 39.490), train_loss = 0.69559903, grad/param norm = 2.9817e-01, time/batch = 17.7650s	
18127/22950 (epoch 39.492), train_loss = 0.79650439, grad/param norm = 2.3404e-01, time/batch = 18.4632s	
18128/22950 (epoch 39.495), train_loss = 0.76380308, grad/param norm = 2.6823e-01, time/batch = 16.0025s	
18129/22950 (epoch 39.497), train_loss = 0.85129644, grad/param norm = 2.6947e-01, time/batch = 15.8849s	
18130/22950 (epoch 39.499), train_loss = 0.92214213, grad/param norm = 2.5638e-01, time/batch = 16.1709s	
18131/22950 (epoch 39.501), train_loss = 0.81560440, grad/param norm = 2.4099e-01, time/batch = 18.3683s	
18132/22950 (epoch 39.503), train_loss = 0.93197415, grad/param norm = 2.6888e-01, time/batch = 15.6878s	
18133/22950 (epoch 39.505), train_loss = 0.69783531, grad/param norm = 2.1834e-01, time/batch = 16.0874s	
18134/22950 (epoch 39.508), train_loss = 0.90011224, grad/param norm = 2.5879e-01, time/batch = 18.1124s	
18135/22950 (epoch 39.510), train_loss = 0.79331281, grad/param norm = 2.6607e-01, time/batch = 18.6155s	
18136/22950 (epoch 39.512), train_loss = 0.71936225, grad/param norm = 2.6516e-01, time/batch = 17.5148s	
18137/22950 (epoch 39.514), train_loss = 0.79870123, grad/param norm = 2.3116e-01, time/batch = 18.3994s	
18138/22950 (epoch 39.516), train_loss = 0.82924633, grad/param norm = 2.3968e-01, time/batch = 17.6199s	
18139/22950 (epoch 39.519), train_loss = 0.82277443, grad/param norm = 2.6953e-01, time/batch = 18.3531s	
18140/22950 (epoch 39.521), train_loss = 0.82076009, grad/param norm = 2.5004e-01, time/batch = 18.5408s	
18141/22950 (epoch 39.523), train_loss = 0.67338283, grad/param norm = 2.3978e-01, time/batch = 16.4479s	
18142/22950 (epoch 39.525), train_loss = 0.73408953, grad/param norm = 2.1428e-01, time/batch = 17.6645s	
18143/22950 (epoch 39.527), train_loss = 0.71711832, grad/param norm = 2.1298e-01, time/batch = 18.0780s	
18144/22950 (epoch 39.529), train_loss = 0.81738207, grad/param norm = 2.3740e-01, time/batch = 19.2008s	
18145/22950 (epoch 39.532), train_loss = 0.80463025, grad/param norm = 2.3241e-01, time/batch = 19.7985s	
18146/22950 (epoch 39.534), train_loss = 0.82904892, grad/param norm = 2.3753e-01, time/batch = 19.2666s	
18147/22950 (epoch 39.536), train_loss = 0.87051188, grad/param norm = 3.2947e-01, time/batch = 16.3715s	
18148/22950 (epoch 39.538), train_loss = 0.82008091, grad/param norm = 2.5478e-01, time/batch = 15.4911s	
18149/22950 (epoch 39.540), train_loss = 0.84774452, grad/param norm = 2.3600e-01, time/batch = 17.9578s	
18150/22950 (epoch 39.542), train_loss = 0.96974383, grad/param norm = 2.7651e-01, time/batch = 17.7381s	
18151/22950 (epoch 39.545), train_loss = 0.81322411, grad/param norm = 2.3327e-01, time/batch = 18.7335s	
18152/22950 (epoch 39.547), train_loss = 0.79680453, grad/param norm = 2.3323e-01, time/batch = 18.4525s	
18153/22950 (epoch 39.549), train_loss = 0.77750958, grad/param norm = 3.2243e-01, time/batch = 17.4573s	
18154/22950 (epoch 39.551), train_loss = 0.80852186, grad/param norm = 2.6190e-01, time/batch = 15.7521s	
18155/22950 (epoch 39.553), train_loss = 0.78669654, grad/param norm = 3.0916e-01, time/batch = 18.5269s	
18156/22950 (epoch 39.556), train_loss = 0.85245117, grad/param norm = 2.2879e-01, time/batch = 17.1135s	
18157/22950 (epoch 39.558), train_loss = 0.69420047, grad/param norm = 2.4985e-01, time/batch = 16.8963s	
18158/22950 (epoch 39.560), train_loss = 0.79175929, grad/param norm = 2.6657e-01, time/batch = 19.6199s	
18159/22950 (epoch 39.562), train_loss = 0.77018267, grad/param norm = 2.2665e-01, time/batch = 17.6958s	
18160/22950 (epoch 39.564), train_loss = 0.86284043, grad/param norm = 2.8789e-01, time/batch = 19.6269s	
18161/22950 (epoch 39.566), train_loss = 0.84749824, grad/param norm = 2.5318e-01, time/batch = 18.4471s	
18162/22950 (epoch 39.569), train_loss = 0.79850116, grad/param norm = 2.4992e-01, time/batch = 18.4641s	
18163/22950 (epoch 39.571), train_loss = 0.76494346, grad/param norm = 2.3933e-01, time/batch = 17.1249s	
18164/22950 (epoch 39.573), train_loss = 0.79818801, grad/param norm = 2.5663e-01, time/batch = 16.9643s	
18165/22950 (epoch 39.575), train_loss = 0.88404628, grad/param norm = 3.6254e-01, time/batch = 16.6074s	
18166/22950 (epoch 39.577), train_loss = 0.84052739, grad/param norm = 3.5293e-01, time/batch = 16.2556s	
18167/22950 (epoch 39.580), train_loss = 0.87703352, grad/param norm = 3.0689e-01, time/batch = 15.5128s	
18168/22950 (epoch 39.582), train_loss = 0.95009817, grad/param norm = 2.9609e-01, time/batch = 16.3924s	
18169/22950 (epoch 39.584), train_loss = 0.72980487, grad/param norm = 3.0964e-01, time/batch = 18.8824s	
18170/22950 (epoch 39.586), train_loss = 0.75791540, grad/param norm = 2.6520e-01, time/batch = 18.5142s	
18171/22950 (epoch 39.588), train_loss = 0.92780476, grad/param norm = 3.2841e-01, time/batch = 17.3042s	
18172/22950 (epoch 39.590), train_loss = 0.89891616, grad/param norm = 2.6376e-01, time/batch = 19.9323s	
18173/22950 (epoch 39.593), train_loss = 0.78637642, grad/param norm = 2.3956e-01, time/batch = 16.4375s	
18174/22950 (epoch 39.595), train_loss = 0.75800658, grad/param norm = 2.7618e-01, time/batch = 17.8562s	
18175/22950 (epoch 39.597), train_loss = 0.87236982, grad/param norm = 2.6446e-01, time/batch = 17.2931s	
18176/22950 (epoch 39.599), train_loss = 0.83879660, grad/param norm = 3.1481e-01, time/batch = 18.0268s	
18177/22950 (epoch 39.601), train_loss = 0.87599525, grad/param norm = 2.3432e-01, time/batch = 19.8807s	
18178/22950 (epoch 39.603), train_loss = 0.93058878, grad/param norm = 2.4933e-01, time/batch = 18.3867s	
18179/22950 (epoch 39.606), train_loss = 0.80558299, grad/param norm = 2.5394e-01, time/batch = 18.3679s	
18180/22950 (epoch 39.608), train_loss = 0.77412161, grad/param norm = 2.4225e-01, time/batch = 19.0544s	
18181/22950 (epoch 39.610), train_loss = 0.81488130, grad/param norm = 2.3315e-01, time/batch = 18.9515s	
18182/22950 (epoch 39.612), train_loss = 0.83565690, grad/param norm = 2.7552e-01, time/batch = 19.3640s	
18183/22950 (epoch 39.614), train_loss = 0.93394547, grad/param norm = 3.0665e-01, time/batch = 18.0342s	
18184/22950 (epoch 39.617), train_loss = 0.83038807, grad/param norm = 2.4425e-01, time/batch = 16.9798s	
18185/22950 (epoch 39.619), train_loss = 0.75616802, grad/param norm = 2.3430e-01, time/batch = 17.9221s	
18186/22950 (epoch 39.621), train_loss = 0.88908726, grad/param norm = 2.5666e-01, time/batch = 16.2974s	
18187/22950 (epoch 39.623), train_loss = 0.86757584, grad/param norm = 2.4661e-01, time/batch = 15.6973s	
18188/22950 (epoch 39.625), train_loss = 0.80037083, grad/param norm = 2.2219e-01, time/batch = 19.3687s	
18189/22950 (epoch 39.627), train_loss = 0.78499066, grad/param norm = 2.4902e-01, time/batch = 18.4525s	
18190/22950 (epoch 39.630), train_loss = 0.72005562, grad/param norm = 2.2706e-01, time/batch = 16.3010s	
18191/22950 (epoch 39.632), train_loss = 0.78491586, grad/param norm = 2.7700e-01, time/batch = 20.4427s	
18192/22950 (epoch 39.634), train_loss = 0.85799863, grad/param norm = 2.5471e-01, time/batch = 17.3012s	
18193/22950 (epoch 39.636), train_loss = 0.82299566, grad/param norm = 2.5868e-01, time/batch = 18.1053s	
18194/22950 (epoch 39.638), train_loss = 0.79913589, grad/param norm = 2.6390e-01, time/batch = 17.7186s	
18195/22950 (epoch 39.641), train_loss = 0.79578364, grad/param norm = 2.3363e-01, time/batch = 18.7322s	
18196/22950 (epoch 39.643), train_loss = 0.85543185, grad/param norm = 3.1623e-01, time/batch = 17.5423s	
18197/22950 (epoch 39.645), train_loss = 0.78422310, grad/param norm = 2.5745e-01, time/batch = 17.2246s	
18198/22950 (epoch 39.647), train_loss = 0.79167584, grad/param norm = 2.7188e-01, time/batch = 19.2020s	
18199/22950 (epoch 39.649), train_loss = 0.74895515, grad/param norm = 2.4646e-01, time/batch = 17.8603s	
18200/22950 (epoch 39.651), train_loss = 0.91943676, grad/param norm = 3.0155e-01, time/batch = 17.7299s	
18201/22950 (epoch 39.654), train_loss = 0.71039728, grad/param norm = 2.4172e-01, time/batch = 18.7025s	
18202/22950 (epoch 39.656), train_loss = 0.87561861, grad/param norm = 3.8039e-01, time/batch = 17.7942s	
18203/22950 (epoch 39.658), train_loss = 0.74163647, grad/param norm = 2.6985e-01, time/batch = 16.6661s	
18204/22950 (epoch 39.660), train_loss = 0.64963402, grad/param norm = 2.3179e-01, time/batch = 16.6176s	
18205/22950 (epoch 39.662), train_loss = 0.68085016, grad/param norm = 2.3313e-01, time/batch = 17.9592s	
18206/22950 (epoch 39.664), train_loss = 0.77306086, grad/param norm = 2.7457e-01, time/batch = 19.1278s	
18207/22950 (epoch 39.667), train_loss = 0.81601136, grad/param norm = 2.4945e-01, time/batch = 18.7717s	
18208/22950 (epoch 39.669), train_loss = 0.81559374, grad/param norm = 2.6594e-01, time/batch = 16.2951s	
18209/22950 (epoch 39.671), train_loss = 0.80533064, grad/param norm = 2.8275e-01, time/batch = 18.2695s	
18210/22950 (epoch 39.673), train_loss = 0.76067087, grad/param norm = 2.6996e-01, time/batch = 19.2103s	
18211/22950 (epoch 39.675), train_loss = 0.82538000, grad/param norm = 2.6374e-01, time/batch = 18.6969s	
18212/22950 (epoch 39.678), train_loss = 0.80994560, grad/param norm = 3.0186e-01, time/batch = 18.9685s	
18213/22950 (epoch 39.680), train_loss = 0.86015501, grad/param norm = 2.5006e-01, time/batch = 17.9662s	
18214/22950 (epoch 39.682), train_loss = 0.79770386, grad/param norm = 2.5639e-01, time/batch = 16.0208s	
18215/22950 (epoch 39.684), train_loss = 0.91875248, grad/param norm = 2.7649e-01, time/batch = 15.5892s	
18216/22950 (epoch 39.686), train_loss = 0.91232199, grad/param norm = 2.5695e-01, time/batch = 17.4588s	
18217/22950 (epoch 39.688), train_loss = 0.83396580, grad/param norm = 2.7334e-01, time/batch = 20.0300s	
18218/22950 (epoch 39.691), train_loss = 0.79782172, grad/param norm = 2.4269e-01, time/batch = 17.9566s	
18219/22950 (epoch 39.693), train_loss = 0.74755814, grad/param norm = 2.5342e-01, time/batch = 23.1246s	
18220/22950 (epoch 39.695), train_loss = 0.92218307, grad/param norm = 3.4674e-01, time/batch = 26.7599s	
18221/22950 (epoch 39.697), train_loss = 0.85686889, grad/param norm = 3.5838e-01, time/batch = 17.2615s	
18222/22950 (epoch 39.699), train_loss = 0.86329446, grad/param norm = 3.0227e-01, time/batch = 16.4699s	
18223/22950 (epoch 39.702), train_loss = 0.89512297, grad/param norm = 2.7103e-01, time/batch = 18.3905s	
18224/22950 (epoch 39.704), train_loss = 0.99091420, grad/param norm = 3.1329e-01, time/batch = 18.0420s	
18225/22950 (epoch 39.706), train_loss = 0.91339679, grad/param norm = 2.6437e-01, time/batch = 17.2915s	
18226/22950 (epoch 39.708), train_loss = 0.71439700, grad/param norm = 2.5192e-01, time/batch = 18.4679s	
18227/22950 (epoch 39.710), train_loss = 0.83495741, grad/param norm = 2.7198e-01, time/batch = 18.7184s	
18228/22950 (epoch 39.712), train_loss = 0.95296252, grad/param norm = 3.3315e-01, time/batch = 19.1885s	
18229/22950 (epoch 39.715), train_loss = 0.86910567, grad/param norm = 2.9157e-01, time/batch = 18.3873s	
18230/22950 (epoch 39.717), train_loss = 0.87726421, grad/param norm = 2.7435e-01, time/batch = 17.1377s	
18231/22950 (epoch 39.719), train_loss = 0.84400697, grad/param norm = 2.8374e-01, time/batch = 17.5508s	
18232/22950 (epoch 39.721), train_loss = 0.90886595, grad/param norm = 3.0064e-01, time/batch = 16.5859s	
18233/22950 (epoch 39.723), train_loss = 0.83582326, grad/param norm = 2.5393e-01, time/batch = 19.1225s	
18234/22950 (epoch 39.725), train_loss = 0.89114411, grad/param norm = 3.1645e-01, time/batch = 16.3025s	
18235/22950 (epoch 39.728), train_loss = 0.82035589, grad/param norm = 3.5362e-01, time/batch = 15.9412s	
18236/22950 (epoch 39.730), train_loss = 0.85711184, grad/param norm = 2.6883e-01, time/batch = 16.1946s	
18237/22950 (epoch 39.732), train_loss = 0.92049608, grad/param norm = 3.0629e-01, time/batch = 18.4560s	
18238/22950 (epoch 39.734), train_loss = 0.80985304, grad/param norm = 2.7272e-01, time/batch = 18.6456s	
18239/22950 (epoch 39.736), train_loss = 0.87219716, grad/param norm = 2.5864e-01, time/batch = 16.4527s	
18240/22950 (epoch 39.739), train_loss = 0.90152843, grad/param norm = 3.0132e-01, time/batch = 17.6316s	
18241/22950 (epoch 39.741), train_loss = 0.92390939, grad/param norm = 3.0298e-01, time/batch = 17.9625s	
18242/22950 (epoch 39.743), train_loss = 0.98665926, grad/param norm = 4.6708e-01, time/batch = 18.2089s	
18243/22950 (epoch 39.745), train_loss = 1.06436563, grad/param norm = 3.8092e-01, time/batch = 16.0860s	
18244/22950 (epoch 39.747), train_loss = 0.91039675, grad/param norm = 3.2743e-01, time/batch = 16.2536s	
18245/22950 (epoch 39.749), train_loss = 0.79385976, grad/param norm = 3.8249e-01, time/batch = 20.0910s	
18246/22950 (epoch 39.752), train_loss = 1.03729179, grad/param norm = 3.1885e-01, time/batch = 18.6175s	
18247/22950 (epoch 39.754), train_loss = 0.87883697, grad/param norm = 3.3620e-01, time/batch = 20.7811s	
18248/22950 (epoch 39.756), train_loss = 0.80792087, grad/param norm = 2.7875e-01, time/batch = 19.4534s	
18249/22950 (epoch 39.758), train_loss = 0.86310990, grad/param norm = 2.5400e-01, time/batch = 18.7650s	
18250/22950 (epoch 39.760), train_loss = 0.84340382, grad/param norm = 2.7705e-01, time/batch = 18.0634s	
18251/22950 (epoch 39.763), train_loss = 0.87485156, grad/param norm = 2.8877e-01, time/batch = 18.2947s	
18252/22950 (epoch 39.765), train_loss = 0.84325353, grad/param norm = 2.9677e-01, time/batch = 17.1576s	
18253/22950 (epoch 39.767), train_loss = 1.00450904, grad/param norm = 3.1533e-01, time/batch = 18.1598s	
18254/22950 (epoch 39.769), train_loss = 0.88245015, grad/param norm = 2.8349e-01, time/batch = 16.1379s	
18255/22950 (epoch 39.771), train_loss = 0.75564028, grad/param norm = 2.5776e-01, time/batch = 16.2663s	
18256/22950 (epoch 39.773), train_loss = 0.65323398, grad/param norm = 2.3087e-01, time/batch = 17.6884s	
18257/22950 (epoch 39.776), train_loss = 0.76591835, grad/param norm = 2.1827e-01, time/batch = 19.4352s	
18258/22950 (epoch 39.778), train_loss = 0.77524725, grad/param norm = 2.6901e-01, time/batch = 17.8762s	
18259/22950 (epoch 39.780), train_loss = 0.84251275, grad/param norm = 2.5538e-01, time/batch = 20.3503s	
18260/22950 (epoch 39.782), train_loss = 0.89234934, grad/param norm = 2.6109e-01, time/batch = 20.6232s	
18261/22950 (epoch 39.784), train_loss = 0.77859557, grad/param norm = 2.6203e-01, time/batch = 18.8606s	
18262/22950 (epoch 39.786), train_loss = 0.86012250, grad/param norm = 2.8381e-01, time/batch = 17.9352s	
18263/22950 (epoch 39.789), train_loss = 0.71250172, grad/param norm = 2.8240e-01, time/batch = 19.3818s	
18264/22950 (epoch 39.791), train_loss = 0.72214323, grad/param norm = 2.3750e-01, time/batch = 19.2070s	
18265/22950 (epoch 39.793), train_loss = 0.94762660, grad/param norm = 3.0794e-01, time/batch = 17.7850s	
18266/22950 (epoch 39.795), train_loss = 0.81263921, grad/param norm = 2.7470e-01, time/batch = 17.8781s	
18267/22950 (epoch 39.797), train_loss = 0.94543293, grad/param norm = 3.1336e-01, time/batch = 15.6099s	
18268/22950 (epoch 39.800), train_loss = 0.76942290, grad/param norm = 2.2880e-01, time/batch = 16.5870s	
18269/22950 (epoch 39.802), train_loss = 0.83007127, grad/param norm = 2.7780e-01, time/batch = 17.1129s	
18270/22950 (epoch 39.804), train_loss = 0.81454390, grad/param norm = 2.5154e-01, time/batch = 17.0528s	
18271/22950 (epoch 39.806), train_loss = 0.72338354, grad/param norm = 2.4454e-01, time/batch = 18.7119s	
18272/22950 (epoch 39.808), train_loss = 0.83958477, grad/param norm = 2.2597e-01, time/batch = 16.1997s	
18273/22950 (epoch 39.810), train_loss = 0.79343362, grad/param norm = 2.5388e-01, time/batch = 16.9967s	
18274/22950 (epoch 39.813), train_loss = 0.69149840, grad/param norm = 2.5220e-01, time/batch = 18.2023s	
18275/22950 (epoch 39.815), train_loss = 0.66504587, grad/param norm = 2.7476e-01, time/batch = 16.1520s	
18276/22950 (epoch 39.817), train_loss = 0.74652851, grad/param norm = 2.2227e-01, time/batch = 15.7872s	
18277/22950 (epoch 39.819), train_loss = 0.78703934, grad/param norm = 2.9565e-01, time/batch = 18.4734s	
18278/22950 (epoch 39.821), train_loss = 0.78434573, grad/param norm = 3.1590e-01, time/batch = 19.1436s	
18279/22950 (epoch 39.824), train_loss = 0.84983255, grad/param norm = 2.7075e-01, time/batch = 18.1903s	
18280/22950 (epoch 39.826), train_loss = 0.86078980, grad/param norm = 2.7921e-01, time/batch = 18.4619s	
18281/22950 (epoch 39.828), train_loss = 0.77999040, grad/param norm = 2.7856e-01, time/batch = 19.8818s	
18282/22950 (epoch 39.830), train_loss = 0.79953928, grad/param norm = 2.8608e-01, time/batch = 19.2659s	
18283/22950 (epoch 39.832), train_loss = 0.83118332, grad/param norm = 2.3796e-01, time/batch = 18.6219s	
18284/22950 (epoch 39.834), train_loss = 0.66754568, grad/param norm = 2.4572e-01, time/batch = 20.1286s	
18285/22950 (epoch 39.837), train_loss = 0.84135502, grad/param norm = 2.8342e-01, time/batch = 18.7519s	
18286/22950 (epoch 39.839), train_loss = 0.69093819, grad/param norm = 2.5064e-01, time/batch = 19.9424s	
18287/22950 (epoch 39.841), train_loss = 0.80097488, grad/param norm = 2.3604e-01, time/batch = 16.0062s	
18288/22950 (epoch 39.843), train_loss = 0.80942948, grad/param norm = 2.6777e-01, time/batch = 17.9429s	
18289/22950 (epoch 39.845), train_loss = 0.80616360, grad/param norm = 2.7357e-01, time/batch = 17.5798s	
18290/22950 (epoch 39.847), train_loss = 0.84764835, grad/param norm = 2.6708e-01, time/batch = 18.2932s	
18291/22950 (epoch 39.850), train_loss = 0.88170434, grad/param norm = 2.4687e-01, time/batch = 16.3039s	
18292/22950 (epoch 39.852), train_loss = 0.87717367, grad/param norm = 2.8835e-01, time/batch = 16.3539s	
18293/22950 (epoch 39.854), train_loss = 0.83109073, grad/param norm = 2.4553e-01, time/batch = 18.5732s	
18294/22950 (epoch 39.856), train_loss = 0.90907786, grad/param norm = 2.7733e-01, time/batch = 16.4330s	
18295/22950 (epoch 39.858), train_loss = 0.89987177, grad/param norm = 2.5857e-01, time/batch = 15.7013s	
18296/22950 (epoch 39.861), train_loss = 0.87112419, grad/param norm = 2.7699e-01, time/batch = 17.6370s	
18297/22950 (epoch 39.863), train_loss = 0.93653598, grad/param norm = 3.2715e-01, time/batch = 19.0179s	
18298/22950 (epoch 39.865), train_loss = 0.95339567, grad/param norm = 2.7439e-01, time/batch = 17.6179s	
18299/22950 (epoch 39.867), train_loss = 0.85926535, grad/param norm = 2.9290e-01, time/batch = 18.4478s	
18300/22950 (epoch 39.869), train_loss = 1.00034934, grad/param norm = 2.8126e-01, time/batch = 19.1299s	
18301/22950 (epoch 39.871), train_loss = 0.85566992, grad/param norm = 2.9207e-01, time/batch = 19.7033s	
18302/22950 (epoch 39.874), train_loss = 0.87031950, grad/param norm = 2.3454e-01, time/batch = 17.8579s	
18303/22950 (epoch 39.876), train_loss = 0.92511530, grad/param norm = 2.6829e-01, time/batch = 18.1327s	
18304/22950 (epoch 39.878), train_loss = 0.86125882, grad/param norm = 2.6796e-01, time/batch = 19.4684s	
18305/22950 (epoch 39.880), train_loss = 1.00769274, grad/param norm = 2.7456e-01, time/batch = 17.7972s	
18306/22950 (epoch 39.882), train_loss = 0.74000324, grad/param norm = 2.4040e-01, time/batch = 16.5122s	
18307/22950 (epoch 39.885), train_loss = 0.84827952, grad/param norm = 2.6525e-01, time/batch = 16.8479s	
18308/22950 (epoch 39.887), train_loss = 0.82136587, grad/param norm = 2.3472e-01, time/batch = 18.0366s	
18309/22950 (epoch 39.889), train_loss = 0.86461988, grad/param norm = 2.6727e-01, time/batch = 17.7164s	
18310/22950 (epoch 39.891), train_loss = 0.78943097, grad/param norm = 2.6370e-01, time/batch = 20.1145s	
18311/22950 (epoch 39.893), train_loss = 0.85968969, grad/param norm = 2.6446e-01, time/batch = 19.3791s	
18312/22950 (epoch 39.895), train_loss = 0.98006142, grad/param norm = 2.5452e-01, time/batch = 15.6328s	
18313/22950 (epoch 39.898), train_loss = 0.89107930, grad/param norm = 2.7026e-01, time/batch = 16.5122s	
18314/22950 (epoch 39.900), train_loss = 0.79978397, grad/param norm = 2.3570e-01, time/batch = 19.4604s	
18315/22950 (epoch 39.902), train_loss = 0.85469846, grad/param norm = 3.3524e-01, time/batch = 16.3403s	
18316/22950 (epoch 39.904), train_loss = 0.84513320, grad/param norm = 2.7634e-01, time/batch = 16.7814s	
18317/22950 (epoch 39.906), train_loss = 0.85296990, grad/param norm = 2.5054e-01, time/batch = 15.7176s	
18318/22950 (epoch 39.908), train_loss = 0.74806830, grad/param norm = 2.7332e-01, time/batch = 14.7464s	
18319/22950 (epoch 39.911), train_loss = 0.69169182, grad/param norm = 2.2252e-01, time/batch = 15.4471s	
18320/22950 (epoch 39.913), train_loss = 0.84300695, grad/param norm = 2.8598e-01, time/batch = 15.0614s	
18321/22950 (epoch 39.915), train_loss = 0.95640152, grad/param norm = 2.9070e-01, time/batch = 15.5412s	
18322/22950 (epoch 39.917), train_loss = 0.74198260, grad/param norm = 2.3831e-01, time/batch = 15.1232s	
18323/22950 (epoch 39.919), train_loss = 0.86686160, grad/param norm = 2.6488e-01, time/batch = 15.2244s	
18324/22950 (epoch 39.922), train_loss = 0.83878563, grad/param norm = 2.7842e-01, time/batch = 14.8462s	
18325/22950 (epoch 39.924), train_loss = 0.88454544, grad/param norm = 2.8191e-01, time/batch = 14.9965s	
18326/22950 (epoch 39.926), train_loss = 0.70677874, grad/param norm = 3.3103e-01, time/batch = 15.1330s	
18327/22950 (epoch 39.928), train_loss = 0.76386798, grad/param norm = 2.7645e-01, time/batch = 15.0563s	
18328/22950 (epoch 39.930), train_loss = 0.74521099, grad/param norm = 2.4113e-01, time/batch = 14.8324s	
18329/22950 (epoch 39.932), train_loss = 0.68213460, grad/param norm = 2.2516e-01, time/batch = 14.7515s	
18330/22950 (epoch 39.935), train_loss = 0.87588394, grad/param norm = 2.6249e-01, time/batch = 14.5855s	
18331/22950 (epoch 39.937), train_loss = 0.81718534, grad/param norm = 2.8116e-01, time/batch = 14.9937s	
18332/22950 (epoch 39.939), train_loss = 0.78285744, grad/param norm = 2.4806e-01, time/batch = 14.6594s	
18333/22950 (epoch 39.941), train_loss = 0.81727327, grad/param norm = 2.7086e-01, time/batch = 14.6576s	
18334/22950 (epoch 39.943), train_loss = 0.85098413, grad/param norm = 2.7251e-01, time/batch = 14.4252s	
18335/22950 (epoch 39.946), train_loss = 0.69175618, grad/param norm = 2.6457e-01, time/batch = 15.1238s	
18336/22950 (epoch 39.948), train_loss = 0.91368900, grad/param norm = 2.6407e-01, time/batch = 14.5950s	
18337/22950 (epoch 39.950), train_loss = 0.82325625, grad/param norm = 2.9097e-01, time/batch = 14.7537s	
18338/22950 (epoch 39.952), train_loss = 0.87352367, grad/param norm = 2.5121e-01, time/batch = 14.7505s	
18339/22950 (epoch 39.954), train_loss = 0.86768348, grad/param norm = 2.6333e-01, time/batch = 15.4600s	
18340/22950 (epoch 39.956), train_loss = 0.78228355, grad/param norm = 2.6463e-01, time/batch = 14.8131s	
18341/22950 (epoch 39.959), train_loss = 0.74238735, grad/param norm = 2.2088e-01, time/batch = 14.9913s	
18342/22950 (epoch 39.961), train_loss = 0.82460968, grad/param norm = 2.4910e-01, time/batch = 14.7301s	
18343/22950 (epoch 39.963), train_loss = 0.81645944, grad/param norm = 2.7869e-01, time/batch = 15.2958s	
18344/22950 (epoch 39.965), train_loss = 0.90719047, grad/param norm = 2.8640e-01, time/batch = 14.8318s	
18345/22950 (epoch 39.967), train_loss = 0.79277391, grad/param norm = 2.6041e-01, time/batch = 15.8412s	
18346/22950 (epoch 39.969), train_loss = 0.72753478, grad/param norm = 2.6845e-01, time/batch = 15.0491s	
18347/22950 (epoch 39.972), train_loss = 0.79878672, grad/param norm = 2.2931e-01, time/batch = 15.2202s	
18348/22950 (epoch 39.974), train_loss = 0.77461129, grad/param norm = 2.3718e-01, time/batch = 14.9022s	
18349/22950 (epoch 39.976), train_loss = 0.83723620, grad/param norm = 2.8033e-01, time/batch = 14.7558s	
18350/22950 (epoch 39.978), train_loss = 0.76105972, grad/param norm = 2.5817e-01, time/batch = 14.7609s	
18351/22950 (epoch 39.980), train_loss = 0.76911019, grad/param norm = 2.4349e-01, time/batch = 15.3189s	
18352/22950 (epoch 39.983), train_loss = 0.85959666, grad/param norm = 2.2886e-01, time/batch = 15.4564s	
18353/22950 (epoch 39.985), train_loss = 0.74652983, grad/param norm = 2.4992e-01, time/batch = 14.8342s	
18354/22950 (epoch 39.987), train_loss = 0.74467934, grad/param norm = 2.2061e-01, time/batch = 14.8291s	
18355/22950 (epoch 39.989), train_loss = 0.84467632, grad/param norm = 2.5956e-01, time/batch = 15.1470s	
18356/22950 (epoch 39.991), train_loss = 0.70903478, grad/param norm = 2.2814e-01, time/batch = 14.8365s	
18357/22950 (epoch 39.993), train_loss = 0.83222598, grad/param norm = 2.5835e-01, time/batch = 14.8324s	
18358/22950 (epoch 39.996), train_loss = 0.81105513, grad/param norm = 3.0622e-01, time/batch = 14.9176s	
18359/22950 (epoch 39.998), train_loss = 0.72367977, grad/param norm = 2.4851e-01, time/batch = 16.2206s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
18360/22950 (epoch 40.000), train_loss = 0.71033680, grad/param norm = 2.6027e-01, time/batch = 14.9111s	
18361/22950 (epoch 40.002), train_loss = 0.97908461, grad/param norm = 3.2450e-01, time/batch = 15.4682s	
18362/22950 (epoch 40.004), train_loss = 0.87160061, grad/param norm = 2.8390e-01, time/batch = 15.2165s	
18363/22950 (epoch 40.007), train_loss = 0.79683023, grad/param norm = 2.7547e-01, time/batch = 15.3240s	
18364/22950 (epoch 40.009), train_loss = 0.93680605, grad/param norm = 2.7289e-01, time/batch = 15.0619s	
18365/22950 (epoch 40.011), train_loss = 0.69341264, grad/param norm = 2.2156e-01, time/batch = 15.5390s	
18366/22950 (epoch 40.013), train_loss = 0.77847496, grad/param norm = 2.4130e-01, time/batch = 15.0652s	
18367/22950 (epoch 40.015), train_loss = 0.84479988, grad/param norm = 3.0383e-01, time/batch = 15.4590s	
18368/22950 (epoch 40.017), train_loss = 0.81681649, grad/param norm = 2.3895e-01, time/batch = 15.3050s	
18369/22950 (epoch 40.020), train_loss = 0.85186114, grad/param norm = 2.5403e-01, time/batch = 15.0015s	
18370/22950 (epoch 40.022), train_loss = 0.73028923, grad/param norm = 2.3315e-01, time/batch = 15.1467s	
18371/22950 (epoch 40.024), train_loss = 0.80354456, grad/param norm = 2.8756e-01, time/batch = 14.9073s	
18372/22950 (epoch 40.026), train_loss = 0.84949243, grad/param norm = 2.4608e-01, time/batch = 14.6704s	
18373/22950 (epoch 40.028), train_loss = 0.86534621, grad/param norm = 2.4230e-01, time/batch = 14.4298s	
18374/22950 (epoch 40.031), train_loss = 0.77071259, grad/param norm = 2.4443e-01, time/batch = 14.9046s	
18375/22950 (epoch 40.033), train_loss = 0.88946744, grad/param norm = 2.5107e-01, time/batch = 14.5778s	
18376/22950 (epoch 40.035), train_loss = 0.80277446, grad/param norm = 2.1401e-01, time/batch = 14.4970s	
18377/22950 (epoch 40.037), train_loss = 0.81505471, grad/param norm = 2.5034e-01, time/batch = 14.5111s	
18378/22950 (epoch 40.039), train_loss = 0.80805667, grad/param norm = 2.3428e-01, time/batch = 15.3051s	
18379/22950 (epoch 40.041), train_loss = 0.76839956, grad/param norm = 3.0335e-01, time/batch = 15.0009s	
18380/22950 (epoch 40.044), train_loss = 0.86622945, grad/param norm = 3.2956e-01, time/batch = 14.9090s	
18381/22950 (epoch 40.046), train_loss = 0.82313180, grad/param norm = 2.7491e-01, time/batch = 15.0502s	
18382/22950 (epoch 40.048), train_loss = 0.84887388, grad/param norm = 2.7130e-01, time/batch = 15.1472s	
18383/22950 (epoch 40.050), train_loss = 0.79298242, grad/param norm = 3.8032e-01, time/batch = 15.5339s	
18384/22950 (epoch 40.052), train_loss = 0.85163521, grad/param norm = 2.8615e-01, time/batch = 14.8312s	
18385/22950 (epoch 40.054), train_loss = 0.96440511, grad/param norm = 3.2365e-01, time/batch = 15.3052s	
18386/22950 (epoch 40.057), train_loss = 0.93489168, grad/param norm = 2.6124e-01, time/batch = 15.1362s	
18387/22950 (epoch 40.059), train_loss = 0.93401960, grad/param norm = 2.4268e-01, time/batch = 14.9955s	
18388/22950 (epoch 40.061), train_loss = 0.76686721, grad/param norm = 2.5637e-01, time/batch = 15.1400s	
18389/22950 (epoch 40.063), train_loss = 0.86716236, grad/param norm = 2.7628e-01, time/batch = 15.2133s	
18390/22950 (epoch 40.065), train_loss = 0.73447341, grad/param norm = 2.4439e-01, time/batch = 15.5271s	
18391/22950 (epoch 40.068), train_loss = 0.84940280, grad/param norm = 2.7276e-01, time/batch = 16.5812s	
18392/22950 (epoch 40.070), train_loss = 0.73269421, grad/param norm = 2.1911e-01, time/batch = 15.5659s	
18393/22950 (epoch 40.072), train_loss = 0.87464706, grad/param norm = 2.9577e-01, time/batch = 15.5801s	
18394/22950 (epoch 40.074), train_loss = 0.88754003, grad/param norm = 2.7355e-01, time/batch = 16.0412s	
18395/22950 (epoch 40.076), train_loss = 0.86202831, grad/param norm = 2.7296e-01, time/batch = 15.7358s	
18396/22950 (epoch 40.078), train_loss = 0.90429997, grad/param norm = 2.7062e-01, time/batch = 15.7182s	
18397/22950 (epoch 40.081), train_loss = 0.95233224, grad/param norm = 2.8486e-01, time/batch = 15.8177s	
18398/22950 (epoch 40.083), train_loss = 0.85209813, grad/param norm = 2.7013e-01, time/batch = 16.1896s	
18399/22950 (epoch 40.085), train_loss = 0.71570707, grad/param norm = 2.5342e-01, time/batch = 16.4283s	
18400/22950 (epoch 40.087), train_loss = 0.74668180, grad/param norm = 2.4048e-01, time/batch = 15.8086s	
18401/22950 (epoch 40.089), train_loss = 0.86151084, grad/param norm = 2.7386e-01, time/batch = 16.1256s	
18402/22950 (epoch 40.092), train_loss = 0.77927199, grad/param norm = 2.7614e-01, time/batch = 16.8274s	
18403/22950 (epoch 40.094), train_loss = 0.77330285, grad/param norm = 2.5645e-01, time/batch = 15.7942s	
18404/22950 (epoch 40.096), train_loss = 0.93799844, grad/param norm = 2.7881e-01, time/batch = 15.8657s	
18405/22950 (epoch 40.098), train_loss = 0.87920758, grad/param norm = 2.6302e-01, time/batch = 15.7121s	
18406/22950 (epoch 40.100), train_loss = 0.81997012, grad/param norm = 2.6060e-01, time/batch = 15.9539s	
18407/22950 (epoch 40.102), train_loss = 0.83643014, grad/param norm = 2.4628e-01, time/batch = 15.7941s	
18408/22950 (epoch 40.105), train_loss = 0.69995152, grad/param norm = 2.2954e-01, time/batch = 15.5597s	
18409/22950 (epoch 40.107), train_loss = 0.75821672, grad/param norm = 2.4021e-01, time/batch = 15.9564s	
18410/22950 (epoch 40.109), train_loss = 0.78208739, grad/param norm = 2.3988e-01, time/batch = 15.6347s	
18411/22950 (epoch 40.111), train_loss = 0.69121045, grad/param norm = 2.3703e-01, time/batch = 15.7363s	
18412/22950 (epoch 40.113), train_loss = 0.84370089, grad/param norm = 2.5105e-01, time/batch = 15.3964s	
18413/22950 (epoch 40.115), train_loss = 0.82776799, grad/param norm = 2.4058e-01, time/batch = 16.4414s	
18414/22950 (epoch 40.118), train_loss = 0.90967057, grad/param norm = 2.3296e-01, time/batch = 15.8096s	
18415/22950 (epoch 40.120), train_loss = 0.72322496, grad/param norm = 2.2115e-01, time/batch = 16.8063s	
18416/22950 (epoch 40.122), train_loss = 0.88549070, grad/param norm = 2.4042e-01, time/batch = 16.9215s	
18417/22950 (epoch 40.124), train_loss = 0.71639116, grad/param norm = 2.0819e-01, time/batch = 17.0637s	
18418/22950 (epoch 40.126), train_loss = 0.80100104, grad/param norm = 2.2682e-01, time/batch = 16.5391s	
18419/22950 (epoch 40.129), train_loss = 0.75546268, grad/param norm = 2.0445e-01, time/batch = 16.3043s	
18420/22950 (epoch 40.131), train_loss = 0.79451497, grad/param norm = 2.3810e-01, time/batch = 16.4559s	
18421/22950 (epoch 40.133), train_loss = 0.85949751, grad/param norm = 2.5466e-01, time/batch = 15.7960s	
18422/22950 (epoch 40.135), train_loss = 0.82488203, grad/param norm = 2.1885e-01, time/batch = 15.7061s	
18423/22950 (epoch 40.137), train_loss = 0.87298695, grad/param norm = 2.9841e-01, time/batch = 15.8611s	
18424/22950 (epoch 40.139), train_loss = 0.76483452, grad/param norm = 3.0256e-01, time/batch = 15.9658s	
18425/22950 (epoch 40.142), train_loss = 0.73608293, grad/param norm = 2.0782e-01, time/batch = 16.1035s	
18426/22950 (epoch 40.144), train_loss = 0.80161081, grad/param norm = 2.4162e-01, time/batch = 15.5539s	
18427/22950 (epoch 40.146), train_loss = 0.72646106, grad/param norm = 2.4787e-01, time/batch = 15.3833s	
18428/22950 (epoch 40.148), train_loss = 0.74545433, grad/param norm = 2.4364e-01, time/batch = 15.4800s	
18429/22950 (epoch 40.150), train_loss = 0.82481154, grad/param norm = 2.2350e-01, time/batch = 15.3152s	
18430/22950 (epoch 40.153), train_loss = 0.72413365, grad/param norm = 2.1551e-01, time/batch = 15.4652s	
18431/22950 (epoch 40.155), train_loss = 0.76332205, grad/param norm = 2.3145e-01, time/batch = 16.1045s	
18432/22950 (epoch 40.157), train_loss = 0.78643178, grad/param norm = 2.2640e-01, time/batch = 16.2729s	
18433/22950 (epoch 40.159), train_loss = 0.72100569, grad/param norm = 2.2233e-01, time/batch = 15.7239s	
18434/22950 (epoch 40.161), train_loss = 0.77253915, grad/param norm = 2.3759e-01, time/batch = 16.1262s	
18435/22950 (epoch 40.163), train_loss = 0.70996447, grad/param norm = 2.1338e-01, time/batch = 13.6857s	
18436/22950 (epoch 40.166), train_loss = 0.83979328, grad/param norm = 3.0920e-01, time/batch = 0.9184s	
18437/22950 (epoch 40.168), train_loss = 0.84813775, grad/param norm = 2.5097e-01, time/batch = 0.7564s	
18438/22950 (epoch 40.170), train_loss = 0.84585309, grad/param norm = 2.7148e-01, time/batch = 0.7437s	
18439/22950 (epoch 40.172), train_loss = 0.80607966, grad/param norm = 2.5996e-01, time/batch = 0.7455s	
18440/22950 (epoch 40.174), train_loss = 0.88574023, grad/param norm = 2.4662e-01, time/batch = 0.7630s	
18441/22950 (epoch 40.176), train_loss = 0.87819217, grad/param norm = 2.8852e-01, time/batch = 0.9557s	
18442/22950 (epoch 40.179), train_loss = 0.85190263, grad/param norm = 2.6198e-01, time/batch = 1.0861s	
18443/22950 (epoch 40.181), train_loss = 1.05345905, grad/param norm = 2.7743e-01, time/batch = 1.0976s	
18444/22950 (epoch 40.183), train_loss = 0.85699346, grad/param norm = 2.6933e-01, time/batch = 1.0937s	
18445/22950 (epoch 40.185), train_loss = 0.88983828, grad/param norm = 2.5704e-01, time/batch = 1.0847s	
18446/22950 (epoch 40.187), train_loss = 0.75696869, grad/param norm = 2.4594e-01, time/batch = 1.9210s	
18447/22950 (epoch 40.190), train_loss = 0.67297448, grad/param norm = 2.4301e-01, time/batch = 1.9329s	
18448/22950 (epoch 40.192), train_loss = 0.64257368, grad/param norm = 2.3373e-01, time/batch = 7.0598s	
18449/22950 (epoch 40.194), train_loss = 0.78581529, grad/param norm = 2.8306e-01, time/batch = 16.0205s	
18450/22950 (epoch 40.196), train_loss = 0.58972235, grad/param norm = 2.2968e-01, time/batch = 16.7925s	
18451/22950 (epoch 40.198), train_loss = 0.84881496, grad/param norm = 2.9908e-01, time/batch = 16.6141s	
18452/22950 (epoch 40.200), train_loss = 0.75393636, grad/param norm = 2.5783e-01, time/batch = 15.7127s	
18453/22950 (epoch 40.203), train_loss = 0.69330526, grad/param norm = 2.2378e-01, time/batch = 16.1859s	
18454/22950 (epoch 40.205), train_loss = 0.77168821, grad/param norm = 2.6102e-01, time/batch = 15.9495s	
18455/22950 (epoch 40.207), train_loss = 0.82660468, grad/param norm = 2.5552e-01, time/batch = 16.0360s	
18456/22950 (epoch 40.209), train_loss = 0.77993208, grad/param norm = 2.6536e-01, time/batch = 15.7157s	
18457/22950 (epoch 40.211), train_loss = 0.67987485, grad/param norm = 2.5799e-01, time/batch = 15.5561s	
18458/22950 (epoch 40.214), train_loss = 0.74380369, grad/param norm = 2.5167e-01, time/batch = 15.8822s	
18459/22950 (epoch 40.216), train_loss = 0.88151892, grad/param norm = 2.4183e-01, time/batch = 16.0620s	
18460/22950 (epoch 40.218), train_loss = 0.79781756, grad/param norm = 2.2929e-01, time/batch = 15.8806s	
18461/22950 (epoch 40.220), train_loss = 0.87184126, grad/param norm = 2.7427e-01, time/batch = 16.1154s	
18462/22950 (epoch 40.222), train_loss = 0.88680203, grad/param norm = 2.5249e-01, time/batch = 16.2750s	
18463/22950 (epoch 40.224), train_loss = 0.80153370, grad/param norm = 2.6325e-01, time/batch = 15.8819s	
18464/22950 (epoch 40.227), train_loss = 0.86603639, grad/param norm = 2.6410e-01, time/batch = 15.6567s	
18465/22950 (epoch 40.229), train_loss = 0.93838877, grad/param norm = 2.6808e-01, time/batch = 16.0362s	
18466/22950 (epoch 40.231), train_loss = 0.65983384, grad/param norm = 2.6793e-01, time/batch = 16.2626s	
18467/22950 (epoch 40.233), train_loss = 0.76216196, grad/param norm = 2.6199e-01, time/batch = 15.9660s	
18468/22950 (epoch 40.235), train_loss = 0.95105358, grad/param norm = 2.7266e-01, time/batch = 16.0501s	
18469/22950 (epoch 40.237), train_loss = 0.76274381, grad/param norm = 2.2248e-01, time/batch = 15.7888s	
18470/22950 (epoch 40.240), train_loss = 0.80136430, grad/param norm = 2.3013e-01, time/batch = 15.5568s	
18471/22950 (epoch 40.242), train_loss = 0.95044022, grad/param norm = 2.5711e-01, time/batch = 15.9079s	
18472/22950 (epoch 40.244), train_loss = 0.91969093, grad/param norm = 2.5573e-01, time/batch = 15.8646s	
18473/22950 (epoch 40.246), train_loss = 0.91532831, grad/param norm = 2.5362e-01, time/batch = 15.8686s	
18474/22950 (epoch 40.248), train_loss = 0.82829483, grad/param norm = 2.6609e-01, time/batch = 15.4043s	
18475/22950 (epoch 40.251), train_loss = 0.75851187, grad/param norm = 2.4985e-01, time/batch = 16.0148s	
18476/22950 (epoch 40.253), train_loss = 0.73642984, grad/param norm = 2.8032e-01, time/batch = 16.5700s	
18477/22950 (epoch 40.255), train_loss = 0.84627887, grad/param norm = 2.4529e-01, time/batch = 16.2767s	
18478/22950 (epoch 40.257), train_loss = 0.90244571, grad/param norm = 2.7213e-01, time/batch = 15.8023s	
18479/22950 (epoch 40.259), train_loss = 0.68686960, grad/param norm = 2.2547e-01, time/batch = 16.0458s	
18480/22950 (epoch 40.261), train_loss = 0.73344992, grad/param norm = 2.4309e-01, time/batch = 16.3527s	
18481/22950 (epoch 40.264), train_loss = 0.72296081, grad/param norm = 2.2636e-01, time/batch = 16.1334s	
18482/22950 (epoch 40.266), train_loss = 0.76637673, grad/param norm = 2.5464e-01, time/batch = 15.9819s	
18483/22950 (epoch 40.268), train_loss = 0.81220983, grad/param norm = 3.8297e-01, time/batch = 15.8930s	
18484/22950 (epoch 40.270), train_loss = 0.78387974, grad/param norm = 2.2727e-01, time/batch = 16.4294s	
18485/22950 (epoch 40.272), train_loss = 0.82750660, grad/param norm = 2.7852e-01, time/batch = 16.4715s	
18486/22950 (epoch 40.275), train_loss = 0.77897469, grad/param norm = 2.7469e-01, time/batch = 15.9634s	
18487/22950 (epoch 40.277), train_loss = 0.68715915, grad/param norm = 2.5974e-01, time/batch = 16.1900s	
18488/22950 (epoch 40.279), train_loss = 0.72355132, grad/param norm = 3.0717e-01, time/batch = 16.1172s	
18489/22950 (epoch 40.281), train_loss = 0.78824934, grad/param norm = 3.2805e-01, time/batch = 16.0285s	
18490/22950 (epoch 40.283), train_loss = 0.69157353, grad/param norm = 2.1193e-01, time/batch = 15.8116s	
18491/22950 (epoch 40.285), train_loss = 0.81869642, grad/param norm = 2.4263e-01, time/batch = 16.3559s	
18492/22950 (epoch 40.288), train_loss = 0.91782351, grad/param norm = 2.5914e-01, time/batch = 15.9698s	
18493/22950 (epoch 40.290), train_loss = 0.78400119, grad/param norm = 2.5544e-01, time/batch = 15.8129s	
18494/22950 (epoch 40.292), train_loss = 0.93314673, grad/param norm = 2.7492e-01, time/batch = 15.8079s	
18495/22950 (epoch 40.294), train_loss = 0.84732995, grad/param norm = 2.3117e-01, time/batch = 16.1132s	
18496/22950 (epoch 40.296), train_loss = 0.64115847, grad/param norm = 2.1565e-01, time/batch = 16.4227s	
18497/22950 (epoch 40.298), train_loss = 0.78162203, grad/param norm = 2.5956e-01, time/batch = 15.8090s	
18498/22950 (epoch 40.301), train_loss = 0.82232849, grad/param norm = 2.4993e-01, time/batch = 16.3156s	
18499/22950 (epoch 40.303), train_loss = 0.79176547, grad/param norm = 2.3727e-01, time/batch = 16.5559s	
18500/22950 (epoch 40.305), train_loss = 0.78736949, grad/param norm = 3.1932e-01, time/batch = 15.8709s	
18501/22950 (epoch 40.307), train_loss = 0.92183594, grad/param norm = 2.7670e-01, time/batch = 15.7317s	
18502/22950 (epoch 40.309), train_loss = 0.77724726, grad/param norm = 3.0897e-01, time/batch = 16.8216s	
18503/22950 (epoch 40.312), train_loss = 0.82301639, grad/param norm = 2.3434e-01, time/batch = 16.4346s	
18504/22950 (epoch 40.314), train_loss = 0.81725731, grad/param norm = 2.3559e-01, time/batch = 15.7339s	
18505/22950 (epoch 40.316), train_loss = 0.77376431, grad/param norm = 2.3895e-01, time/batch = 15.4877s	
18506/22950 (epoch 40.318), train_loss = 0.70690560, grad/param norm = 2.0161e-01, time/batch = 15.7046s	
18507/22950 (epoch 40.320), train_loss = 0.74009651, grad/param norm = 2.1171e-01, time/batch = 15.6390s	
18508/22950 (epoch 40.322), train_loss = 0.74805326, grad/param norm = 2.4000e-01, time/batch = 15.7121s	
18509/22950 (epoch 40.325), train_loss = 0.62243252, grad/param norm = 2.0686e-01, time/batch = 16.2842s	
18510/22950 (epoch 40.327), train_loss = 0.61781896, grad/param norm = 2.0125e-01, time/batch = 16.1219s	
18511/22950 (epoch 40.329), train_loss = 0.73935605, grad/param norm = 2.4817e-01, time/batch = 16.6814s	
18512/22950 (epoch 40.331), train_loss = 0.69630763, grad/param norm = 2.1701e-01, time/batch = 15.9739s	
18513/22950 (epoch 40.333), train_loss = 0.71868836, grad/param norm = 2.2071e-01, time/batch = 16.3120s	
18514/22950 (epoch 40.336), train_loss = 0.77679982, grad/param norm = 2.9525e-01, time/batch = 19.0322s	
18515/22950 (epoch 40.338), train_loss = 0.79338076, grad/param norm = 2.2302e-01, time/batch = 16.5792s	
18516/22950 (epoch 40.340), train_loss = 0.75871872, grad/param norm = 2.7363e-01, time/batch = 17.2531s	
18517/22950 (epoch 40.342), train_loss = 0.94404935, grad/param norm = 2.5637e-01, time/batch = 17.3567s	
18518/22950 (epoch 40.344), train_loss = 0.77405130, grad/param norm = 2.5387e-01, time/batch = 17.7399s	
18519/22950 (epoch 40.346), train_loss = 0.87155469, grad/param norm = 2.6294e-01, time/batch = 20.1760s	
18520/22950 (epoch 40.349), train_loss = 0.79659775, grad/param norm = 2.3704e-01, time/batch = 19.0892s	
18521/22950 (epoch 40.351), train_loss = 0.82886738, grad/param norm = 2.6383e-01, time/batch = 17.8401s	
18522/22950 (epoch 40.353), train_loss = 0.82224329, grad/param norm = 2.8300e-01, time/batch = 16.0592s	
18523/22950 (epoch 40.355), train_loss = 0.88775739, grad/param norm = 2.7342e-01, time/batch = 16.3829s	
18524/22950 (epoch 40.357), train_loss = 0.76035932, grad/param norm = 3.0011e-01, time/batch = 16.6920s	
18525/22950 (epoch 40.359), train_loss = 0.81413945, grad/param norm = 3.0082e-01, time/batch = 17.4621s	
18526/22950 (epoch 40.362), train_loss = 0.84892949, grad/param norm = 2.9406e-01, time/batch = 18.4368s	
18527/22950 (epoch 40.364), train_loss = 0.81306735, grad/param norm = 2.7295e-01, time/batch = 18.5986s	
18528/22950 (epoch 40.366), train_loss = 0.80435163, grad/param norm = 2.3744e-01, time/batch = 19.9648s	
18529/22950 (epoch 40.368), train_loss = 0.82505268, grad/param norm = 2.6819e-01, time/batch = 18.2945s	
18530/22950 (epoch 40.370), train_loss = 0.77858120, grad/param norm = 2.6563e-01, time/batch = 17.9645s	
18531/22950 (epoch 40.373), train_loss = 0.74396104, grad/param norm = 2.4098e-01, time/batch = 17.0780s	
18532/22950 (epoch 40.375), train_loss = 0.88469207, grad/param norm = 2.6656e-01, time/batch = 18.4481s	
18533/22950 (epoch 40.377), train_loss = 0.71904885, grad/param norm = 2.4027e-01, time/batch = 19.3081s	
18534/22950 (epoch 40.379), train_loss = 0.79871380, grad/param norm = 2.3047e-01, time/batch = 17.9595s	
18535/22950 (epoch 40.381), train_loss = 0.70870855, grad/param norm = 2.6364e-01, time/batch = 19.1332s	
18536/22950 (epoch 40.383), train_loss = 0.78919208, grad/param norm = 5.6070e-01, time/batch = 19.7839s	
18537/22950 (epoch 40.386), train_loss = 0.75278374, grad/param norm = 2.7505e-01, time/batch = 17.6802s	
18538/22950 (epoch 40.388), train_loss = 0.84796718, grad/param norm = 2.5364e-01, time/batch = 19.2985s	
18539/22950 (epoch 40.390), train_loss = 0.71016093, grad/param norm = 2.6314e-01, time/batch = 16.3196s	
18540/22950 (epoch 40.392), train_loss = 0.74325888, grad/param norm = 2.6796e-01, time/batch = 16.9369s	
18541/22950 (epoch 40.394), train_loss = 0.75922275, grad/param norm = 2.5970e-01, time/batch = 18.6046s	
18542/22950 (epoch 40.397), train_loss = 0.89250964, grad/param norm = 2.4013e-01, time/batch = 17.0380s	
18543/22950 (epoch 40.399), train_loss = 0.87698120, grad/param norm = 3.0405e-01, time/batch = 17.6308s	
18544/22950 (epoch 40.401), train_loss = 0.93241774, grad/param norm = 2.8870e-01, time/batch = 19.1930s	
18545/22950 (epoch 40.403), train_loss = 0.79347157, grad/param norm = 2.5823e-01, time/batch = 19.8683s	
18546/22950 (epoch 40.405), train_loss = 0.93673442, grad/param norm = 3.3109e-01, time/batch = 19.7163s	
18547/22950 (epoch 40.407), train_loss = 0.96413358, grad/param norm = 2.5979e-01, time/batch = 18.1989s	
18548/22950 (epoch 40.410), train_loss = 0.84388289, grad/param norm = 2.6738e-01, time/batch = 17.9775s	
18549/22950 (epoch 40.412), train_loss = 0.79190494, grad/param norm = 2.9682e-01, time/batch = 19.3765s	
18550/22950 (epoch 40.414), train_loss = 0.90983298, grad/param norm = 2.5172e-01, time/batch = 18.0237s	
18551/22950 (epoch 40.416), train_loss = 0.82455843, grad/param norm = 3.2202e-01, time/batch = 19.0448s	
18552/22950 (epoch 40.418), train_loss = 0.81280557, grad/param norm = 2.7175e-01, time/batch = 18.6127s	
18553/22950 (epoch 40.420), train_loss = 0.87378880, grad/param norm = 3.0704e-01, time/batch = 16.7987s	
18554/22950 (epoch 40.423), train_loss = 0.76733271, grad/param norm = 2.4113e-01, time/batch = 18.5379s	
18555/22950 (epoch 40.425), train_loss = 0.80730672, grad/param norm = 2.6453e-01, time/batch = 17.2855s	
18556/22950 (epoch 40.427), train_loss = 0.82681753, grad/param norm = 2.5716e-01, time/batch = 18.8415s	
18557/22950 (epoch 40.429), train_loss = 0.82253474, grad/param norm = 2.4292e-01, time/batch = 18.3778s	
18558/22950 (epoch 40.431), train_loss = 0.87420733, grad/param norm = 2.6633e-01, time/batch = 17.8084s	
18559/22950 (epoch 40.434), train_loss = 0.81464358, grad/param norm = 2.4997e-01, time/batch = 17.7988s	
18560/22950 (epoch 40.436), train_loss = 0.88977825, grad/param norm = 3.3365e-01, time/batch = 18.9420s	
18561/22950 (epoch 40.438), train_loss = 0.80034523, grad/param norm = 2.3794e-01, time/batch = 19.0491s	
18562/22950 (epoch 40.440), train_loss = 0.90247411, grad/param norm = 2.4815e-01, time/batch = 19.6272s	
18563/22950 (epoch 40.442), train_loss = 0.94673715, grad/param norm = 2.7138e-01, time/batch = 19.1922s	
18564/22950 (epoch 40.444), train_loss = 0.84699752, grad/param norm = 2.8705e-01, time/batch = 18.9565s	
18565/22950 (epoch 40.447), train_loss = 0.96276260, grad/param norm = 2.9968e-01, time/batch = 17.0115s	
18566/22950 (epoch 40.449), train_loss = 0.74446488, grad/param norm = 2.2127e-01, time/batch = 18.3724s	
18567/22950 (epoch 40.451), train_loss = 0.83112802, grad/param norm = 2.8641e-01, time/batch = 17.4521s	
18568/22950 (epoch 40.453), train_loss = 0.84384525, grad/param norm = 3.0650e-01, time/batch = 19.1345s	
18569/22950 (epoch 40.455), train_loss = 0.82623090, grad/param norm = 2.2960e-01, time/batch = 18.3571s	
18570/22950 (epoch 40.458), train_loss = 0.82424781, grad/param norm = 2.7300e-01, time/batch = 18.9956s	
18571/22950 (epoch 40.460), train_loss = 0.86932381, grad/param norm = 2.9572e-01, time/batch = 19.4396s	
18572/22950 (epoch 40.462), train_loss = 0.87451503, grad/param norm = 2.8684e-01, time/batch = 17.8049s	
18573/22950 (epoch 40.464), train_loss = 0.78714254, grad/param norm = 2.5032e-01, time/batch = 19.4509s	
18574/22950 (epoch 40.466), train_loss = 0.89978185, grad/param norm = 2.5950e-01, time/batch = 17.7990s	
18575/22950 (epoch 40.468), train_loss = 0.87717492, grad/param norm = 2.7515e-01, time/batch = 16.8887s	
18576/22950 (epoch 40.471), train_loss = 0.85596475, grad/param norm = 2.8960e-01, time/batch = 16.9616s	
18577/22950 (epoch 40.473), train_loss = 0.85354212, grad/param norm = 2.4622e-01, time/batch = 18.8041s	
18578/22950 (epoch 40.475), train_loss = 0.99481491, grad/param norm = 3.3261e-01, time/batch = 19.8700s	
18579/22950 (epoch 40.477), train_loss = 0.80409731, grad/param norm = 2.5656e-01, time/batch = 16.7846s	
18580/22950 (epoch 40.479), train_loss = 0.72088659, grad/param norm = 2.4136e-01, time/batch = 19.6441s	
18581/22950 (epoch 40.481), train_loss = 0.90694210, grad/param norm = 3.1771e-01, time/batch = 20.9607s	
18582/22950 (epoch 40.484), train_loss = 0.86047043, grad/param norm = 2.7361e-01, time/batch = 18.4571s	
18583/22950 (epoch 40.486), train_loss = 0.73476521, grad/param norm = 2.5311e-01, time/batch = 17.9276s	
18584/22950 (epoch 40.488), train_loss = 0.75048074, grad/param norm = 2.8660e-01, time/batch = 18.5078s	
18585/22950 (epoch 40.490), train_loss = 0.69172933, grad/param norm = 2.7446e-01, time/batch = 19.2839s	
18586/22950 (epoch 40.492), train_loss = 0.78668398, grad/param norm = 2.4512e-01, time/batch = 18.5411s	
18587/22950 (epoch 40.495), train_loss = 0.74376517, grad/param norm = 2.4310e-01, time/batch = 19.2933s	
18588/22950 (epoch 40.497), train_loss = 0.84462342, grad/param norm = 2.6522e-01, time/batch = 19.2246s	
18589/22950 (epoch 40.499), train_loss = 0.93514136, grad/param norm = 2.4856e-01, time/batch = 18.3814s	
18590/22950 (epoch 40.501), train_loss = 0.80902293, grad/param norm = 2.5038e-01, time/batch = 19.4645s	
18591/22950 (epoch 40.503), train_loss = 0.94441395, grad/param norm = 2.6673e-01, time/batch = 16.9617s	
18592/22950 (epoch 40.505), train_loss = 0.69996859, grad/param norm = 2.5720e-01, time/batch = 17.3682s	
18593/22950 (epoch 40.508), train_loss = 0.89006277, grad/param norm = 2.6771e-01, time/batch = 19.4637s	
18594/22950 (epoch 40.510), train_loss = 0.78241699, grad/param norm = 2.2963e-01, time/batch = 18.2956s	
18595/22950 (epoch 40.512), train_loss = 0.70334172, grad/param norm = 2.3878e-01, time/batch = 18.7821s	
18596/22950 (epoch 40.514), train_loss = 0.78740915, grad/param norm = 2.2452e-01, time/batch = 19.4567s	
18597/22950 (epoch 40.516), train_loss = 0.82767830, grad/param norm = 2.6089e-01, time/batch = 19.1106s	
18598/22950 (epoch 40.519), train_loss = 0.81428450, grad/param norm = 2.3299e-01, time/batch = 16.0922s	
18599/22950 (epoch 40.521), train_loss = 0.83421807, grad/param norm = 2.8552e-01, time/batch = 19.8575s	
18600/22950 (epoch 40.523), train_loss = 0.65488794, grad/param norm = 2.2865e-01, time/batch = 18.8105s	
18601/22950 (epoch 40.525), train_loss = 0.73298421, grad/param norm = 2.4510e-01, time/batch = 18.4426s	
18602/22950 (epoch 40.527), train_loss = 0.71522565, grad/param norm = 2.3254e-01, time/batch = 19.1799s	
18603/22950 (epoch 40.529), train_loss = 0.80238972, grad/param norm = 2.4212e-01, time/batch = 17.7271s	
18604/22950 (epoch 40.532), train_loss = 0.79928236, grad/param norm = 2.6611e-01, time/batch = 19.7681s	
18605/22950 (epoch 40.534), train_loss = 0.81928081, grad/param norm = 2.5166e-01, time/batch = 16.7103s	
18606/22950 (epoch 40.536), train_loss = 0.85399064, grad/param norm = 3.5988e-01, time/batch = 19.6872s	
18607/22950 (epoch 40.538), train_loss = 0.80897139, grad/param norm = 2.5284e-01, time/batch = 16.8750s	
18608/22950 (epoch 40.540), train_loss = 0.84440807, grad/param norm = 2.5950e-01, time/batch = 17.7020s	
18609/22950 (epoch 40.542), train_loss = 0.96303709, grad/param norm = 3.0720e-01, time/batch = 19.0354s	
18610/22950 (epoch 40.545), train_loss = 0.80483350, grad/param norm = 2.1821e-01, time/batch = 17.3828s	
18611/22950 (epoch 40.547), train_loss = 0.77963315, grad/param norm = 2.2566e-01, time/batch = 18.1816s	
18612/22950 (epoch 40.549), train_loss = 0.76761874, grad/param norm = 3.0053e-01, time/batch = 19.7065s	
18613/22950 (epoch 40.551), train_loss = 0.78893763, grad/param norm = 2.5920e-01, time/batch = 19.6173s	
18614/22950 (epoch 40.553), train_loss = 0.75551502, grad/param norm = 2.6465e-01, time/batch = 18.2772s	
18615/22950 (epoch 40.556), train_loss = 0.84963915, grad/param norm = 2.7273e-01, time/batch = 18.8747s	
18616/22950 (epoch 40.558), train_loss = 0.69033624, grad/param norm = 2.5336e-01, time/batch = 20.7115s	
18617/22950 (epoch 40.560), train_loss = 0.75847919, grad/param norm = 2.4186e-01, time/batch = 18.5301s	
18618/22950 (epoch 40.562), train_loss = 0.77162336, grad/param norm = 2.5928e-01, time/batch = 18.1120s	
18619/22950 (epoch 40.564), train_loss = 0.83873048, grad/param norm = 2.7008e-01, time/batch = 18.2171s	
18620/22950 (epoch 40.566), train_loss = 0.84426253, grad/param norm = 2.6032e-01, time/batch = 16.4426s	
18621/22950 (epoch 40.569), train_loss = 0.80038283, grad/param norm = 2.5299e-01, time/batch = 17.1993s	
18622/22950 (epoch 40.571), train_loss = 0.75190964, grad/param norm = 2.5485e-01, time/batch = 15.9257s	
18623/22950 (epoch 40.573), train_loss = 0.78021918, grad/param norm = 2.6648e-01, time/batch = 19.5120s	
18624/22950 (epoch 40.575), train_loss = 0.87044627, grad/param norm = 2.9490e-01, time/batch = 18.1813s	
18625/22950 (epoch 40.577), train_loss = 0.82104261, grad/param norm = 3.3056e-01, time/batch = 18.2942s	
18626/22950 (epoch 40.580), train_loss = 0.86851146, grad/param norm = 3.3351e-01, time/batch = 20.6229s	
18627/22950 (epoch 40.582), train_loss = 0.94171755, grad/param norm = 2.8400e-01, time/batch = 18.2713s	
18628/22950 (epoch 40.584), train_loss = 0.70362550, grad/param norm = 2.5595e-01, time/batch = 19.2850s	
18629/22950 (epoch 40.586), train_loss = 0.77291747, grad/param norm = 2.6530e-01, time/batch = 20.7783s	
18630/22950 (epoch 40.588), train_loss = 0.92745551, grad/param norm = 2.9788e-01, time/batch = 18.2030s	
18631/22950 (epoch 40.590), train_loss = 0.90396695, grad/param norm = 2.9595e-01, time/batch = 19.7825s	
18632/22950 (epoch 40.593), train_loss = 0.78672698, grad/param norm = 2.6020e-01, time/batch = 18.7925s	
18633/22950 (epoch 40.595), train_loss = 0.77178120, grad/param norm = 3.5404e-01, time/batch = 19.3513s	
18634/22950 (epoch 40.597), train_loss = 0.85638921, grad/param norm = 2.6912e-01, time/batch = 17.0527s	
18635/22950 (epoch 40.599), train_loss = 0.82046877, grad/param norm = 3.1857e-01, time/batch = 17.9731s	
18636/22950 (epoch 40.601), train_loss = 0.89230962, grad/param norm = 2.8983e-01, time/batch = 18.1259s	
18637/22950 (epoch 40.603), train_loss = 0.92517777, grad/param norm = 2.5876e-01, time/batch = 17.9537s	
18638/22950 (epoch 40.606), train_loss = 0.79006230, grad/param norm = 2.4273e-01, time/batch = 18.8008s	
18639/22950 (epoch 40.608), train_loss = 0.78778060, grad/param norm = 2.5780e-01, time/batch = 18.7860s	
18640/22950 (epoch 40.610), train_loss = 0.80193099, grad/param norm = 2.4013e-01, time/batch = 17.4244s	
18641/22950 (epoch 40.612), train_loss = 0.82657057, grad/param norm = 2.6420e-01, time/batch = 16.8572s	
18642/22950 (epoch 40.614), train_loss = 0.93260127, grad/param norm = 3.0267e-01, time/batch = 18.7088s	
18643/22950 (epoch 40.617), train_loss = 0.81293589, grad/param norm = 2.4095e-01, time/batch = 18.6263s	
18644/22950 (epoch 40.619), train_loss = 0.74211622, grad/param norm = 2.2125e-01, time/batch = 19.9392s	
18645/22950 (epoch 40.621), train_loss = 0.88258700, grad/param norm = 2.7796e-01, time/batch = 18.7129s	
18646/22950 (epoch 40.623), train_loss = 0.86232735, grad/param norm = 2.5051e-01, time/batch = 19.0415s	
18647/22950 (epoch 40.625), train_loss = 0.80077852, grad/param norm = 2.4145e-01, time/batch = 18.1281s	
18648/22950 (epoch 40.627), train_loss = 0.78174089, grad/param norm = 2.5763e-01, time/batch = 18.2995s	
18649/22950 (epoch 40.630), train_loss = 0.71389100, grad/param norm = 2.1551e-01, time/batch = 19.5322s	
18650/22950 (epoch 40.632), train_loss = 0.76861133, grad/param norm = 2.7120e-01, time/batch = 30.1643s	
18651/22950 (epoch 40.634), train_loss = 0.83375702, grad/param norm = 2.6410e-01, time/batch = 18.2092s	
18652/22950 (epoch 40.636), train_loss = 0.81422435, grad/param norm = 2.5558e-01, time/batch = 17.0301s	
18653/22950 (epoch 40.638), train_loss = 0.80498034, grad/param norm = 2.7509e-01, time/batch = 16.7949s	
18654/22950 (epoch 40.641), train_loss = 0.79177430, grad/param norm = 2.5113e-01, time/batch = 18.4696s	
18655/22950 (epoch 40.643), train_loss = 0.83298537, grad/param norm = 3.0251e-01, time/batch = 17.0403s	
18656/22950 (epoch 40.645), train_loss = 0.78471615, grad/param norm = 2.8499e-01, time/batch = 17.2130s	
18657/22950 (epoch 40.647), train_loss = 0.78866821, grad/param norm = 3.0526e-01, time/batch = 16.7141s	
18658/22950 (epoch 40.649), train_loss = 0.74573157, grad/param norm = 2.7848e-01, time/batch = 18.8720s	
18659/22950 (epoch 40.651), train_loss = 0.88798670, grad/param norm = 2.7560e-01, time/batch = 18.1876s	
18660/22950 (epoch 40.654), train_loss = 0.70363483, grad/param norm = 2.2880e-01, time/batch = 17.0038s	
18661/22950 (epoch 40.656), train_loss = 0.85744726, grad/param norm = 2.7521e-01, time/batch = 19.6166s	
18662/22950 (epoch 40.658), train_loss = 0.73434475, grad/param norm = 2.9569e-01, time/batch = 19.1885s	
18663/22950 (epoch 40.660), train_loss = 0.65920486, grad/param norm = 2.6095e-01, time/batch = 19.5394s	
18664/22950 (epoch 40.662), train_loss = 0.68310445, grad/param norm = 2.5896e-01, time/batch = 20.0276s	
18665/22950 (epoch 40.664), train_loss = 0.77482892, grad/param norm = 2.4676e-01, time/batch = 16.8732s	
18666/22950 (epoch 40.667), train_loss = 0.79059710, grad/param norm = 2.3671e-01, time/batch = 18.0916s	
18667/22950 (epoch 40.669), train_loss = 0.80686355, grad/param norm = 2.6370e-01, time/batch = 17.4528s	
18668/22950 (epoch 40.671), train_loss = 0.79930405, grad/param norm = 2.7197e-01, time/batch = 19.4443s	
18669/22950 (epoch 40.673), train_loss = 0.75357318, grad/param norm = 2.7860e-01, time/batch = 17.4672s	
18670/22950 (epoch 40.675), train_loss = 0.81583805, grad/param norm = 2.6678e-01, time/batch = 19.4562s	
18671/22950 (epoch 40.678), train_loss = 0.79361833, grad/param norm = 2.5443e-01, time/batch = 18.4488s	
18672/22950 (epoch 40.680), train_loss = 0.83539854, grad/param norm = 2.4532e-01, time/batch = 17.2635s	
18673/22950 (epoch 40.682), train_loss = 0.78150189, grad/param norm = 2.5743e-01, time/batch = 18.6194s	
18674/22950 (epoch 40.684), train_loss = 0.91144505, grad/param norm = 2.6550e-01, time/batch = 19.8002s	
18675/22950 (epoch 40.686), train_loss = 0.91632200, grad/param norm = 2.6740e-01, time/batch = 18.1190s	
18676/22950 (epoch 40.688), train_loss = 0.83397926, grad/param norm = 2.6872e-01, time/batch = 20.0296s	
18677/22950 (epoch 40.691), train_loss = 0.79901026, grad/param norm = 2.7015e-01, time/batch = 20.2817s	
18678/22950 (epoch 40.693), train_loss = 0.73673570, grad/param norm = 2.7474e-01, time/batch = 18.4554s	
18679/22950 (epoch 40.695), train_loss = 0.92196697, grad/param norm = 3.0588e-01, time/batch = 18.9570s	
18680/22950 (epoch 40.697), train_loss = 0.84976099, grad/param norm = 3.3722e-01, time/batch = 18.8641s	
18681/22950 (epoch 40.699), train_loss = 0.83985408, grad/param norm = 2.4462e-01, time/batch = 16.1769s	
18682/22950 (epoch 40.702), train_loss = 0.87907988, grad/param norm = 3.0195e-01, time/batch = 18.9083s	
18683/22950 (epoch 40.704), train_loss = 0.97202830, grad/param norm = 3.4729e-01, time/batch = 18.1241s	
18684/22950 (epoch 40.706), train_loss = 0.89180610, grad/param norm = 2.7006e-01, time/batch = 19.3599s	
18685/22950 (epoch 40.708), train_loss = 0.71429262, grad/param norm = 2.5683e-01, time/batch = 18.6027s	
18686/22950 (epoch 40.710), train_loss = 0.81224039, grad/param norm = 2.4815e-01, time/batch = 19.1212s	
18687/22950 (epoch 40.712), train_loss = 0.94775863, grad/param norm = 2.8875e-01, time/batch = 18.2032s	
18688/22950 (epoch 40.715), train_loss = 0.85267366, grad/param norm = 2.9047e-01, time/batch = 18.8526s	
18689/22950 (epoch 40.717), train_loss = 0.86819264, grad/param norm = 2.5235e-01, time/batch = 20.2752s	
18690/22950 (epoch 40.719), train_loss = 0.80213604, grad/param norm = 2.8609e-01, time/batch = 15.8704s	
18691/22950 (epoch 40.721), train_loss = 0.90611559, grad/param norm = 3.0735e-01, time/batch = 17.0150s	
18692/22950 (epoch 40.723), train_loss = 0.83060149, grad/param norm = 2.8556e-01, time/batch = 20.2099s	
18693/22950 (epoch 40.725), train_loss = 0.87488859, grad/param norm = 2.5432e-01, time/batch = 19.2112s	
18694/22950 (epoch 40.728), train_loss = 0.81986997, grad/param norm = 3.6468e-01, time/batch = 18.4520s	
18695/22950 (epoch 40.730), train_loss = 0.84162195, grad/param norm = 3.0363e-01, time/batch = 17.5472s	
18696/22950 (epoch 40.732), train_loss = 0.92495816, grad/param norm = 3.1272e-01, time/batch = 19.7859s	
18697/22950 (epoch 40.734), train_loss = 0.77807313, grad/param norm = 2.7294e-01, time/batch = 19.1879s	
18698/22950 (epoch 40.736), train_loss = 0.87998497, grad/param norm = 2.8373e-01, time/batch = 17.8351s	
18699/22950 (epoch 40.739), train_loss = 0.88736612, grad/param norm = 2.8365e-01, time/batch = 18.7138s	
18700/22950 (epoch 40.741), train_loss = 0.89953046, grad/param norm = 2.9401e-01, time/batch = 19.3748s	
18701/22950 (epoch 40.743), train_loss = 0.98269242, grad/param norm = 3.4219e-01, time/batch = 16.2562s	
18702/22950 (epoch 40.745), train_loss = 1.05669286, grad/param norm = 3.2618e-01, time/batch = 18.6217s	
18703/22950 (epoch 40.747), train_loss = 0.91110691, grad/param norm = 3.1024e-01, time/batch = 18.8678s	
18704/22950 (epoch 40.749), train_loss = 0.76945048, grad/param norm = 2.7020e-01, time/batch = 18.7496s	
18705/22950 (epoch 40.752), train_loss = 0.99449335, grad/param norm = 2.8488e-01, time/batch = 18.1050s	
18706/22950 (epoch 40.754), train_loss = 0.87840755, grad/param norm = 2.9037e-01, time/batch = 20.0355s	
18707/22950 (epoch 40.756), train_loss = 0.80906590, grad/param norm = 2.5821e-01, time/batch = 18.9477s	
18708/22950 (epoch 40.758), train_loss = 0.86090278, grad/param norm = 2.4641e-01, time/batch = 19.2180s	
18709/22950 (epoch 40.760), train_loss = 0.83342596, grad/param norm = 2.4884e-01, time/batch = 19.0413s	
18710/22950 (epoch 40.763), train_loss = 0.85620330, grad/param norm = 2.6132e-01, time/batch = 19.9413s	
18711/22950 (epoch 40.765), train_loss = 0.83713330, grad/param norm = 2.9670e-01, time/batch = 20.2181s	
18712/22950 (epoch 40.767), train_loss = 1.03880184, grad/param norm = 3.2989e-01, time/batch = 18.5309s	
18713/22950 (epoch 40.769), train_loss = 0.88324070, grad/param norm = 2.6994e-01, time/batch = 19.9356s	
18714/22950 (epoch 40.771), train_loss = 0.77487224, grad/param norm = 3.1669e-01, time/batch = 19.1142s	
18715/22950 (epoch 40.773), train_loss = 0.63334338, grad/param norm = 2.2567e-01, time/batch = 18.6353s	
18716/22950 (epoch 40.776), train_loss = 0.75502963, grad/param norm = 2.3857e-01, time/batch = 18.8680s	
18717/22950 (epoch 40.778), train_loss = 0.75218226, grad/param norm = 2.7030e-01, time/batch = 16.5391s	
18718/22950 (epoch 40.780), train_loss = 0.84240895, grad/param norm = 2.7250e-01, time/batch = 19.5998s	
18719/22950 (epoch 40.782), train_loss = 0.88417660, grad/param norm = 2.6370e-01, time/batch = 17.1228s	
18720/22950 (epoch 40.784), train_loss = 0.78359755, grad/param norm = 2.5977e-01, time/batch = 16.9533s	
18721/22950 (epoch 40.786), train_loss = 0.83619575, grad/param norm = 2.5628e-01, time/batch = 18.0214s	
18722/22950 (epoch 40.789), train_loss = 0.70406544, grad/param norm = 2.6416e-01, time/batch = 18.4621s	
18723/22950 (epoch 40.791), train_loss = 0.71248782, grad/param norm = 2.4184e-01, time/batch = 19.0380s	
18724/22950 (epoch 40.793), train_loss = 0.93163927, grad/param norm = 2.7742e-01, time/batch = 17.9495s	
18725/22950 (epoch 40.795), train_loss = 0.79841151, grad/param norm = 2.4256e-01, time/batch = 19.0230s	
18726/22950 (epoch 40.797), train_loss = 0.95385835, grad/param norm = 3.1689e-01, time/batch = 18.8638s	
18727/22950 (epoch 40.800), train_loss = 0.76921269, grad/param norm = 2.9399e-01, time/batch = 19.9541s	
18728/22950 (epoch 40.802), train_loss = 0.80679742, grad/param norm = 2.5413e-01, time/batch = 18.6279s	
18729/22950 (epoch 40.804), train_loss = 0.82132771, grad/param norm = 2.7598e-01, time/batch = 19.1223s	
18730/22950 (epoch 40.806), train_loss = 0.71354856, grad/param norm = 2.4350e-01, time/batch = 18.0062s	
18731/22950 (epoch 40.808), train_loss = 0.83739175, grad/param norm = 2.3544e-01, time/batch = 17.6073s	
18732/22950 (epoch 40.810), train_loss = 0.79307348, grad/param norm = 2.9169e-01, time/batch = 20.0468s	
18733/22950 (epoch 40.813), train_loss = 0.69334170, grad/param norm = 2.4370e-01, time/batch = 18.1825s	
18734/22950 (epoch 40.815), train_loss = 0.65539851, grad/param norm = 2.7385e-01, time/batch = 20.1257s	
18735/22950 (epoch 40.817), train_loss = 0.73445723, grad/param norm = 2.2429e-01, time/batch = 17.8014s	
18736/22950 (epoch 40.819), train_loss = 0.77070422, grad/param norm = 2.4945e-01, time/batch = 16.9345s	
18737/22950 (epoch 40.821), train_loss = 0.79057451, grad/param norm = 2.9938e-01, time/batch = 19.1841s	
18738/22950 (epoch 40.824), train_loss = 0.83015440, grad/param norm = 2.4014e-01, time/batch = 19.9654s	
18739/22950 (epoch 40.826), train_loss = 0.84626359, grad/param norm = 2.7244e-01, time/batch = 18.2876s	
18740/22950 (epoch 40.828), train_loss = 0.76611574, grad/param norm = 2.5791e-01, time/batch = 20.2003s	
18741/22950 (epoch 40.830), train_loss = 0.76955268, grad/param norm = 2.4832e-01, time/batch = 19.3633s	
18742/22950 (epoch 40.832), train_loss = 0.83733742, grad/param norm = 3.0587e-01, time/batch = 19.0374s	
18743/22950 (epoch 40.834), train_loss = 0.66451601, grad/param norm = 2.5990e-01, time/batch = 19.8828s	
18744/22950 (epoch 40.837), train_loss = 0.83266267, grad/param norm = 2.6606e-01, time/batch = 18.2622s	
18745/22950 (epoch 40.839), train_loss = 0.67793319, grad/param norm = 2.3244e-01, time/batch = 19.3560s	
18746/22950 (epoch 40.841), train_loss = 0.78199557, grad/param norm = 2.1721e-01, time/batch = 18.1099s	
18747/22950 (epoch 40.843), train_loss = 0.76965993, grad/param norm = 2.7259e-01, time/batch = 19.2063s	
18748/22950 (epoch 40.845), train_loss = 0.80028051, grad/param norm = 2.7548e-01, time/batch = 19.0235s	
18749/22950 (epoch 40.847), train_loss = 0.83431698, grad/param norm = 2.6267e-01, time/batch = 19.0920s	
18750/22950 (epoch 40.850), train_loss = 0.88793363, grad/param norm = 2.7983e-01, time/batch = 17.4490s	
18751/22950 (epoch 40.852), train_loss = 0.85989655, grad/param norm = 2.6937e-01, time/batch = 18.4616s	
18752/22950 (epoch 40.854), train_loss = 0.81383104, grad/param norm = 2.5617e-01, time/batch = 16.9642s	
18753/22950 (epoch 40.856), train_loss = 0.92132554, grad/param norm = 2.9873e-01, time/batch = 16.4169s	
18754/22950 (epoch 40.858), train_loss = 0.88920219, grad/param norm = 2.7038e-01, time/batch = 19.0424s	
18755/22950 (epoch 40.861), train_loss = 0.85505942, grad/param norm = 2.5602e-01, time/batch = 18.1186s	
18756/22950 (epoch 40.863), train_loss = 0.90119320, grad/param norm = 2.8137e-01, time/batch = 19.2736s	
18757/22950 (epoch 40.865), train_loss = 0.94848120, grad/param norm = 2.7986e-01, time/batch = 18.6355s	
18758/22950 (epoch 40.867), train_loss = 0.84067130, grad/param norm = 2.9161e-01, time/batch = 18.6054s	
18759/22950 (epoch 40.869), train_loss = 0.98744448, grad/param norm = 2.9333e-01, time/batch = 19.4247s	
18760/22950 (epoch 40.871), train_loss = 0.83360352, grad/param norm = 2.8593e-01, time/batch = 19.9604s	
18761/22950 (epoch 40.874), train_loss = 0.86988442, grad/param norm = 2.2807e-01, time/batch = 19.7744s	
18762/22950 (epoch 40.876), train_loss = 0.92645156, grad/param norm = 3.0121e-01, time/batch = 16.4416s	
18763/22950 (epoch 40.878), train_loss = 0.85786731, grad/param norm = 2.6186e-01, time/batch = 17.0224s	
18764/22950 (epoch 40.880), train_loss = 0.99101955, grad/param norm = 2.7497e-01, time/batch = 19.3723s	
18765/22950 (epoch 40.882), train_loss = 0.73493269, grad/param norm = 2.4871e-01, time/batch = 18.4410s	
18766/22950 (epoch 40.885), train_loss = 0.85064044, grad/param norm = 2.8385e-01, time/batch = 19.1995s	
18767/22950 (epoch 40.887), train_loss = 0.82321081, grad/param norm = 2.2991e-01, time/batch = 17.7048s	
18768/22950 (epoch 40.889), train_loss = 0.85341184, grad/param norm = 2.4871e-01, time/batch = 18.9473s	
18769/22950 (epoch 40.891), train_loss = 0.76219860, grad/param norm = 2.4739e-01, time/batch = 18.6132s	
18770/22950 (epoch 40.893), train_loss = 0.84582027, grad/param norm = 2.4777e-01, time/batch = 20.0314s	
18771/22950 (epoch 40.895), train_loss = 0.97096192, grad/param norm = 2.9290e-01, time/batch = 16.8748s	
18772/22950 (epoch 40.898), train_loss = 0.88373494, grad/param norm = 2.5209e-01, time/batch = 20.0191s	
18773/22950 (epoch 40.900), train_loss = 0.78261046, grad/param norm = 2.2506e-01, time/batch = 19.6368s	
18774/22950 (epoch 40.902), train_loss = 0.84400979, grad/param norm = 2.8388e-01, time/batch = 18.1379s	
18775/22950 (epoch 40.904), train_loss = 0.82346329, grad/param norm = 2.5007e-01, time/batch = 17.6047s	
18776/22950 (epoch 40.906), train_loss = 0.83729221, grad/param norm = 2.8617e-01, time/batch = 16.8879s	
18777/22950 (epoch 40.908), train_loss = 0.74144774, grad/param norm = 2.5704e-01, time/batch = 18.6057s	
18778/22950 (epoch 40.911), train_loss = 0.67503568, grad/param norm = 2.3640e-01, time/batch = 17.5111s	
18779/22950 (epoch 40.913), train_loss = 0.82892431, grad/param norm = 2.6608e-01, time/batch = 19.4530s	
18780/22950 (epoch 40.915), train_loss = 0.93141781, grad/param norm = 2.6228e-01, time/batch = 19.7825s	
18781/22950 (epoch 40.917), train_loss = 0.73241945, grad/param norm = 2.4827e-01, time/batch = 18.5238s	
18782/22950 (epoch 40.919), train_loss = 0.85114545, grad/param norm = 2.4993e-01, time/batch = 19.6847s	
18783/22950 (epoch 40.922), train_loss = 0.82643331, grad/param norm = 2.8516e-01, time/batch = 17.7893s	
18784/22950 (epoch 40.924), train_loss = 0.86969117, grad/param norm = 2.9074e-01, time/batch = 18.3573s	
18785/22950 (epoch 40.926), train_loss = 0.69944137, grad/param norm = 2.8209e-01, time/batch = 18.9669s	
18786/22950 (epoch 40.928), train_loss = 0.74996277, grad/param norm = 2.4317e-01, time/batch = 18.9681s	
18787/22950 (epoch 40.930), train_loss = 0.73304067, grad/param norm = 2.3432e-01, time/batch = 18.3640s	
18788/22950 (epoch 40.932), train_loss = 0.68113566, grad/param norm = 2.3201e-01, time/batch = 19.1307s	
18789/22950 (epoch 40.935), train_loss = 0.86204904, grad/param norm = 2.5669e-01, time/batch = 18.6250s	
18790/22950 (epoch 40.937), train_loss = 0.81619946, grad/param norm = 2.9509e-01, time/batch = 18.9510s	
18791/22950 (epoch 40.939), train_loss = 0.76022034, grad/param norm = 2.5783e-01, time/batch = 20.0264s	
18792/22950 (epoch 40.941), train_loss = 0.79975412, grad/param norm = 2.4962e-01, time/batch = 19.0265s	
18793/22950 (epoch 40.943), train_loss = 0.82913384, grad/param norm = 2.4621e-01, time/batch = 19.6257s	
18794/22950 (epoch 40.946), train_loss = 0.67236618, grad/param norm = 2.2935e-01, time/batch = 17.7059s	
18795/22950 (epoch 40.948), train_loss = 0.90502608, grad/param norm = 2.6734e-01, time/batch = 18.8850s	
18796/22950 (epoch 40.950), train_loss = 0.79857758, grad/param norm = 2.6247e-01, time/batch = 19.8802s	
18797/22950 (epoch 40.952), train_loss = 0.86224727, grad/param norm = 2.4459e-01, time/batch = 17.7766s	
18798/22950 (epoch 40.954), train_loss = 0.85647037, grad/param norm = 2.4310e-01, time/batch = 18.2043s	
18799/22950 (epoch 40.956), train_loss = 0.76449786, grad/param norm = 2.7007e-01, time/batch = 18.6013s	
18800/22950 (epoch 40.959), train_loss = 0.72496229, grad/param norm = 2.3133e-01, time/batch = 17.0179s	
18801/22950 (epoch 40.961), train_loss = 0.80884660, grad/param norm = 2.5574e-01, time/batch = 20.2047s	
18802/22950 (epoch 40.963), train_loss = 0.81961177, grad/param norm = 2.6946e-01, time/batch = 18.8711s	
18803/22950 (epoch 40.965), train_loss = 0.88895154, grad/param norm = 2.9818e-01, time/batch = 18.7013s	
18804/22950 (epoch 40.967), train_loss = 0.77919931, grad/param norm = 2.6171e-01, time/batch = 18.5369s	
18805/22950 (epoch 40.969), train_loss = 0.71575848, grad/param norm = 2.4434e-01, time/batch = 20.0366s	
18806/22950 (epoch 40.972), train_loss = 0.79371614, grad/param norm = 2.3691e-01, time/batch = 18.4446s	
18807/22950 (epoch 40.974), train_loss = 0.77024435, grad/param norm = 2.6330e-01, time/batch = 19.5280s	
18808/22950 (epoch 40.976), train_loss = 0.80911773, grad/param norm = 2.4020e-01, time/batch = 19.7987s	
18809/22950 (epoch 40.978), train_loss = 0.75069755, grad/param norm = 2.6129e-01, time/batch = 18.4351s	
18810/22950 (epoch 40.980), train_loss = 0.77123766, grad/param norm = 2.9768e-01, time/batch = 18.0264s	
18811/22950 (epoch 40.983), train_loss = 0.86071418, grad/param norm = 2.5976e-01, time/batch = 16.6914s	
18812/22950 (epoch 40.985), train_loss = 0.74089445, grad/param norm = 2.8837e-01, time/batch = 19.6177s	
18813/22950 (epoch 40.987), train_loss = 0.74107278, grad/param norm = 2.3379e-01, time/batch = 17.0194s	
18814/22950 (epoch 40.989), train_loss = 0.82728999, grad/param norm = 2.4095e-01, time/batch = 19.1204s	
18815/22950 (epoch 40.991), train_loss = 0.71112946, grad/param norm = 2.3313e-01, time/batch = 18.7790s	
18816/22950 (epoch 40.993), train_loss = 0.82905495, grad/param norm = 2.4932e-01, time/batch = 17.8600s	
18817/22950 (epoch 40.996), train_loss = 0.79619049, grad/param norm = 2.5978e-01, time/batch = 19.7130s	
18818/22950 (epoch 40.998), train_loss = 0.71216147, grad/param norm = 2.5990e-01, time/batch = 19.3764s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
18819/22950 (epoch 41.000), train_loss = 0.69662075, grad/param norm = 2.4083e-01, time/batch = 18.6127s	
18820/22950 (epoch 41.002), train_loss = 0.96631214, grad/param norm = 2.8409e-01, time/batch = 20.6973s	
18821/22950 (epoch 41.004), train_loss = 0.85880355, grad/param norm = 2.6415e-01, time/batch = 18.7846s	
18822/22950 (epoch 41.007), train_loss = 0.78669627, grad/param norm = 2.7689e-01, time/batch = 18.3699s	
18823/22950 (epoch 41.009), train_loss = 0.92851972, grad/param norm = 2.9487e-01, time/batch = 19.8778s	
18824/22950 (epoch 41.011), train_loss = 0.70764554, grad/param norm = 2.7623e-01, time/batch = 18.9630s	
18825/22950 (epoch 41.013), train_loss = 0.77428808, grad/param norm = 2.7137e-01, time/batch = 18.7696s	
18826/22950 (epoch 41.015), train_loss = 0.82449228, grad/param norm = 2.5011e-01, time/batch = 18.0385s	
18827/22950 (epoch 41.017), train_loss = 0.81874166, grad/param norm = 2.4729e-01, time/batch = 18.3494s	
18828/22950 (epoch 41.020), train_loss = 0.84464884, grad/param norm = 2.2840e-01, time/batch = 19.6174s	
18829/22950 (epoch 41.022), train_loss = 0.70408054, grad/param norm = 2.2178e-01, time/batch = 16.8705s	
18830/22950 (epoch 41.024), train_loss = 0.77447611, grad/param norm = 2.3950e-01, time/batch = 18.0175s	
18831/22950 (epoch 41.026), train_loss = 0.84128154, grad/param norm = 2.4541e-01, time/batch = 17.8584s	
18832/22950 (epoch 41.028), train_loss = 0.86682319, grad/param norm = 2.5447e-01, time/batch = 17.4500s	
18833/22950 (epoch 41.031), train_loss = 0.77630587, grad/param norm = 2.8560e-01, time/batch = 20.3665s	
18834/22950 (epoch 41.033), train_loss = 0.91430588, grad/param norm = 2.9832e-01, time/batch = 19.5305s	
18835/22950 (epoch 41.035), train_loss = 0.80115610, grad/param norm = 2.3606e-01, time/batch = 19.0395s	
18836/22950 (epoch 41.037), train_loss = 0.82154690, grad/param norm = 3.0017e-01, time/batch = 18.2864s	
18837/22950 (epoch 41.039), train_loss = 0.82777550, grad/param norm = 2.7206e-01, time/batch = 19.2883s	
18838/22950 (epoch 41.041), train_loss = 0.76573702, grad/param norm = 3.1357e-01, time/batch = 16.6032s	
18839/22950 (epoch 41.044), train_loss = 0.84032069, grad/param norm = 2.6998e-01, time/batch = 19.8655s	
18840/22950 (epoch 41.046), train_loss = 0.79942049, grad/param norm = 2.3990e-01, time/batch = 18.2852s	
18841/22950 (epoch 41.048), train_loss = 0.81908672, grad/param norm = 2.8439e-01, time/batch = 22.2367s	
18842/22950 (epoch 41.050), train_loss = 0.77387552, grad/param norm = 3.5684e-01, time/batch = 31.2362s	
18843/22950 (epoch 41.052), train_loss = 0.83361056, grad/param norm = 2.5449e-01, time/batch = 19.2801s	
18844/22950 (epoch 41.054), train_loss = 0.94527483, grad/param norm = 2.7326e-01, time/batch = 18.2827s	
18845/22950 (epoch 41.057), train_loss = 0.92350286, grad/param norm = 2.6712e-01, time/batch = 19.1169s	
18846/22950 (epoch 41.059), train_loss = 0.93770891, grad/param norm = 2.7425e-01, time/batch = 17.1885s	
18847/22950 (epoch 41.061), train_loss = 0.75588296, grad/param norm = 2.5033e-01, time/batch = 18.7677s	
18848/22950 (epoch 41.063), train_loss = 0.85840947, grad/param norm = 3.1892e-01, time/batch = 19.3789s	
18849/22950 (epoch 41.065), train_loss = 0.74440623, grad/param norm = 2.5983e-01, time/batch = 16.7963s	
18850/22950 (epoch 41.068), train_loss = 0.85536585, grad/param norm = 2.7773e-01, time/batch = 18.4144s	
18851/22950 (epoch 41.070), train_loss = 0.73367046, grad/param norm = 2.1360e-01, time/batch = 19.1277s	
18852/22950 (epoch 41.072), train_loss = 0.87369510, grad/param norm = 3.1600e-01, time/batch = 16.6934s	
18853/22950 (epoch 41.074), train_loss = 0.86710543, grad/param norm = 2.7860e-01, time/batch = 19.0479s	
18854/22950 (epoch 41.076), train_loss = 0.85155976, grad/param norm = 2.7461e-01, time/batch = 19.4292s	
18855/22950 (epoch 41.078), train_loss = 0.92102173, grad/param norm = 2.6472e-01, time/batch = 20.1950s	
18856/22950 (epoch 41.081), train_loss = 0.94416760, grad/param norm = 2.8445e-01, time/batch = 19.7912s	
18857/22950 (epoch 41.083), train_loss = 0.83617009, grad/param norm = 2.7936e-01, time/batch = 19.2543s	
18858/22950 (epoch 41.085), train_loss = 0.70921350, grad/param norm = 2.4072e-01, time/batch = 19.0245s	
18859/22950 (epoch 41.087), train_loss = 0.75563972, grad/param norm = 2.7263e-01, time/batch = 18.6988s	
18860/22950 (epoch 41.089), train_loss = 0.85113154, grad/param norm = 3.1588e-01, time/batch = 17.3511s	
18861/22950 (epoch 41.092), train_loss = 0.77081547, grad/param norm = 2.6957e-01, time/batch = 18.6085s	
18862/22950 (epoch 41.094), train_loss = 0.77560918, grad/param norm = 3.1274e-01, time/batch = 18.8843s	
18863/22950 (epoch 41.096), train_loss = 0.92589050, grad/param norm = 3.0923e-01, time/batch = 17.9405s	
18864/22950 (epoch 41.098), train_loss = 0.87451956, grad/param norm = 3.0945e-01, time/batch = 17.9630s	
18865/22950 (epoch 41.100), train_loss = 0.80171671, grad/param norm = 2.7575e-01, time/batch = 20.2821s	
18866/22950 (epoch 41.102), train_loss = 0.82199235, grad/param norm = 2.5712e-01, time/batch = 17.7064s	
18867/22950 (epoch 41.105), train_loss = 0.67978207, grad/param norm = 2.2353e-01, time/batch = 19.7072s	
18868/22950 (epoch 41.107), train_loss = 0.76705558, grad/param norm = 2.8014e-01, time/batch = 20.0460s	
18869/22950 (epoch 41.109), train_loss = 0.77504530, grad/param norm = 2.4816e-01, time/batch = 17.2723s	
18870/22950 (epoch 41.111), train_loss = 0.69085632, grad/param norm = 2.3793e-01, time/batch = 16.4496s	
18871/22950 (epoch 41.113), train_loss = 0.84027523, grad/param norm = 2.5621e-01, time/batch = 18.8671s	
18872/22950 (epoch 41.115), train_loss = 0.82505067, grad/param norm = 2.5336e-01, time/batch = 20.2017s	
18873/22950 (epoch 41.118), train_loss = 0.90565932, grad/param norm = 2.4463e-01, time/batch = 16.8370s	
18874/22950 (epoch 41.120), train_loss = 0.71796725, grad/param norm = 2.4688e-01, time/batch = 17.8641s	
18875/22950 (epoch 41.122), train_loss = 0.88846796, grad/param norm = 2.7475e-01, time/batch = 20.2117s	
18876/22950 (epoch 41.124), train_loss = 0.71978289, grad/param norm = 2.2942e-01, time/batch = 17.1971s	
18877/22950 (epoch 41.126), train_loss = 0.80683791, grad/param norm = 2.2181e-01, time/batch = 19.4625s	
18878/22950 (epoch 41.129), train_loss = 0.74879471, grad/param norm = 2.1232e-01, time/batch = 19.0420s	
18879/22950 (epoch 41.131), train_loss = 0.79123789, grad/param norm = 2.3845e-01, time/batch = 18.6717s	
18880/22950 (epoch 41.133), train_loss = 0.85202408, grad/param norm = 2.4553e-01, time/batch = 20.3021s	
18881/22950 (epoch 41.135), train_loss = 0.81142550, grad/param norm = 2.3880e-01, time/batch = 19.3646s	
18882/22950 (epoch 41.137), train_loss = 0.88679680, grad/param norm = 3.9319e-01, time/batch = 17.5227s	
18883/22950 (epoch 41.139), train_loss = 0.77343695, grad/param norm = 2.7852e-01, time/batch = 20.0770s	
18884/22950 (epoch 41.142), train_loss = 0.74690952, grad/param norm = 2.1871e-01, time/batch = 18.7118s	
18885/22950 (epoch 41.144), train_loss = 0.78076797, grad/param norm = 2.3923e-01, time/batch = 18.1930s	
18886/22950 (epoch 41.146), train_loss = 0.73377193, grad/param norm = 2.6396e-01, time/batch = 19.6107s	
18887/22950 (epoch 41.148), train_loss = 0.74514842, grad/param norm = 2.6427e-01, time/batch = 19.5491s	
18888/22950 (epoch 41.150), train_loss = 0.82789755, grad/param norm = 2.6872e-01, time/batch = 18.0046s	
18889/22950 (epoch 41.153), train_loss = 0.70821350, grad/param norm = 2.1920e-01, time/batch = 16.2448s	
18890/22950 (epoch 41.155), train_loss = 0.75445011, grad/param norm = 2.3383e-01, time/batch = 19.4488s	
18891/22950 (epoch 41.157), train_loss = 0.79792931, grad/param norm = 2.3709e-01, time/batch = 20.0396s	
18892/22950 (epoch 41.159), train_loss = 0.70961184, grad/param norm = 2.1420e-01, time/batch = 17.9528s	
18893/22950 (epoch 41.161), train_loss = 0.76352897, grad/param norm = 2.4565e-01, time/batch = 18.8678s	
18894/22950 (epoch 41.163), train_loss = 0.70898543, grad/param norm = 2.4279e-01, time/batch = 16.7875s	
18895/22950 (epoch 41.166), train_loss = 0.83585695, grad/param norm = 2.9855e-01, time/batch = 17.4458s	
18896/22950 (epoch 41.168), train_loss = 0.82975214, grad/param norm = 3.8267e-01, time/batch = 19.9525s	
18897/22950 (epoch 41.170), train_loss = 0.82283221, grad/param norm = 2.6336e-01, time/batch = 18.0587s	
18898/22950 (epoch 41.172), train_loss = 0.79598016, grad/param norm = 2.5122e-01, time/batch = 18.1120s	
18899/22950 (epoch 41.174), train_loss = 0.86637858, grad/param norm = 2.4250e-01, time/batch = 17.1327s	
18900/22950 (epoch 41.176), train_loss = 0.87621591, grad/param norm = 3.2999e-01, time/batch = 19.2146s	
18901/22950 (epoch 41.179), train_loss = 0.85388946, grad/param norm = 2.8392e-01, time/batch = 19.4530s	
18902/22950 (epoch 41.181), train_loss = 1.03916857, grad/param norm = 2.9550e-01, time/batch = 19.6966s	
18903/22950 (epoch 41.183), train_loss = 0.84040487, grad/param norm = 2.5732e-01, time/batch = 18.8598s	
18904/22950 (epoch 41.185), train_loss = 0.87633759, grad/param norm = 2.6669e-01, time/batch = 19.4652s	
18905/22950 (epoch 41.187), train_loss = 0.73820760, grad/param norm = 2.5428e-01, time/batch = 18.1829s	
18906/22950 (epoch 41.190), train_loss = 0.65425413, grad/param norm = 2.2902e-01, time/batch = 19.1316s	
18907/22950 (epoch 41.192), train_loss = 0.64690951, grad/param norm = 2.8313e-01, time/batch = 18.2698s	
18908/22950 (epoch 41.194), train_loss = 0.78226766, grad/param norm = 2.5960e-01, time/batch = 16.6120s	
18909/22950 (epoch 41.196), train_loss = 0.59836413, grad/param norm = 2.6259e-01, time/batch = 18.6202s	
18910/22950 (epoch 41.198), train_loss = 0.83222813, grad/param norm = 2.7342e-01, time/batch = 19.6188s	
18911/22950 (epoch 41.200), train_loss = 0.72983175, grad/param norm = 2.3600e-01, time/batch = 17.1676s	
18912/22950 (epoch 41.203), train_loss = 0.69346236, grad/param norm = 2.3376e-01, time/batch = 18.0240s	
18913/22950 (epoch 41.205), train_loss = 0.75293933, grad/param norm = 2.5120e-01, time/batch = 18.7116s	
18914/22950 (epoch 41.207), train_loss = 0.82386477, grad/param norm = 2.7253e-01, time/batch = 18.4627s	
18915/22950 (epoch 41.209), train_loss = 0.77864436, grad/param norm = 2.9494e-01, time/batch = 19.2746s	
18916/22950 (epoch 41.211), train_loss = 0.66077183, grad/param norm = 2.4770e-01, time/batch = 18.8074s	
18917/22950 (epoch 41.214), train_loss = 0.74384916, grad/param norm = 2.6558e-01, time/batch = 19.0416s	
18918/22950 (epoch 41.216), train_loss = 0.89230963, grad/param norm = 2.7334e-01, time/batch = 17.2110s	
18919/22950 (epoch 41.218), train_loss = 0.77826956, grad/param norm = 2.3791e-01, time/batch = 18.9817s	
18920/22950 (epoch 41.220), train_loss = 0.87759190, grad/param norm = 2.7734e-01, time/batch = 16.7757s	
18921/22950 (epoch 41.222), train_loss = 0.89670632, grad/param norm = 3.0190e-01, time/batch = 18.9121s	
18922/22950 (epoch 41.224), train_loss = 0.78882254, grad/param norm = 2.7340e-01, time/batch = 19.6221s	
18923/22950 (epoch 41.227), train_loss = 0.86044577, grad/param norm = 2.6348e-01, time/batch = 17.7196s	
18924/22950 (epoch 41.229), train_loss = 0.93069407, grad/param norm = 2.9036e-01, time/batch = 18.6224s	
18925/22950 (epoch 41.231), train_loss = 0.64692998, grad/param norm = 2.3435e-01, time/batch = 19.1206s	
18926/22950 (epoch 41.233), train_loss = 0.74574031, grad/param norm = 2.6383e-01, time/batch = 19.5335s	
18927/22950 (epoch 41.235), train_loss = 0.91244199, grad/param norm = 2.3808e-01, time/batch = 17.6761s	
18928/22950 (epoch 41.237), train_loss = 0.76098945, grad/param norm = 2.3558e-01, time/batch = 20.0387s	
18929/22950 (epoch 41.240), train_loss = 0.80576519, grad/param norm = 2.3603e-01, time/batch = 19.7822s	
18930/22950 (epoch 41.242), train_loss = 0.93561897, grad/param norm = 2.5659e-01, time/batch = 18.8585s	
18931/22950 (epoch 41.244), train_loss = 0.91177404, grad/param norm = 2.8701e-01, time/batch = 19.1870s	
18932/22950 (epoch 41.246), train_loss = 0.91434319, grad/param norm = 2.6712e-01, time/batch = 20.8676s	
18933/22950 (epoch 41.248), train_loss = 0.82613954, grad/param norm = 2.7627e-01, time/batch = 19.5206s	
18934/22950 (epoch 41.251), train_loss = 0.75098536, grad/param norm = 2.7036e-01, time/batch = 19.6314s	
18935/22950 (epoch 41.253), train_loss = 0.72368531, grad/param norm = 2.5023e-01, time/batch = 20.2129s	
18936/22950 (epoch 41.255), train_loss = 0.82855377, grad/param norm = 2.4708e-01, time/batch = 16.0338s	
18937/22950 (epoch 41.257), train_loss = 0.89546531, grad/param norm = 2.8504e-01, time/batch = 18.0919s	
18938/22950 (epoch 41.259), train_loss = 0.67636462, grad/param norm = 2.1683e-01, time/batch = 19.0489s	
18939/22950 (epoch 41.261), train_loss = 0.73645112, grad/param norm = 2.7141e-01, time/batch = 19.7879s	
18940/22950 (epoch 41.264), train_loss = 0.72177116, grad/param norm = 2.6509e-01, time/batch = 17.2944s	
18941/22950 (epoch 41.266), train_loss = 0.75481581, grad/param norm = 2.4045e-01, time/batch = 18.6254s	
18942/22950 (epoch 41.268), train_loss = 0.82516233, grad/param norm = 3.5492e-01, time/batch = 18.6145s	
18943/22950 (epoch 41.270), train_loss = 0.80214302, grad/param norm = 2.8594e-01, time/batch = 18.3662s	
18944/22950 (epoch 41.272), train_loss = 0.83018475, grad/param norm = 3.3139e-01, time/batch = 18.1234s	
18945/22950 (epoch 41.275), train_loss = 0.75090169, grad/param norm = 2.3677e-01, time/batch = 20.2885s	
18946/22950 (epoch 41.277), train_loss = 0.67807047, grad/param norm = 2.7314e-01, time/batch = 18.0367s	
18947/22950 (epoch 41.279), train_loss = 0.71485794, grad/param norm = 3.4889e-01, time/batch = 18.8723s	
18948/22950 (epoch 41.281), train_loss = 0.79598789, grad/param norm = 2.8520e-01, time/batch = 19.6379s	
18949/22950 (epoch 41.283), train_loss = 0.69811953, grad/param norm = 2.2908e-01, time/batch = 18.5191s	
18950/22950 (epoch 41.285), train_loss = 0.80088755, grad/param norm = 2.6594e-01, time/batch = 20.1154s	
18951/22950 (epoch 41.288), train_loss = 0.88964302, grad/param norm = 2.5671e-01, time/batch = 19.3654s	
18952/22950 (epoch 41.290), train_loss = 0.78724617, grad/param norm = 2.8987e-01, time/batch = 19.0329s	
18953/22950 (epoch 41.292), train_loss = 0.91048971, grad/param norm = 2.6309e-01, time/batch = 18.6155s	
18954/22950 (epoch 41.294), train_loss = 0.83622018, grad/param norm = 2.4218e-01, time/batch = 17.4653s	
18955/22950 (epoch 41.296), train_loss = 0.64342174, grad/param norm = 2.2346e-01, time/batch = 18.9635s	
18956/22950 (epoch 41.298), train_loss = 0.77246767, grad/param norm = 2.3125e-01, time/batch = 18.9375s	
18957/22950 (epoch 41.301), train_loss = 0.80894812, grad/param norm = 2.4254e-01, time/batch = 15.6960s	
18958/22950 (epoch 41.303), train_loss = 0.78173260, grad/param norm = 2.5625e-01, time/batch = 18.0341s	
18959/22950 (epoch 41.305), train_loss = 0.79530708, grad/param norm = 2.7214e-01, time/batch = 18.0279s	
18960/22950 (epoch 41.307), train_loss = 0.91412304, grad/param norm = 2.7652e-01, time/batch = 19.7185s	
18961/22950 (epoch 41.309), train_loss = 0.76308901, grad/param norm = 2.5058e-01, time/batch = 18.4593s	
18962/22950 (epoch 41.312), train_loss = 0.82815447, grad/param norm = 2.6108e-01, time/batch = 18.2903s	
18963/22950 (epoch 41.314), train_loss = 0.80575386, grad/param norm = 2.2114e-01, time/batch = 19.7936s	
18964/22950 (epoch 41.316), train_loss = 0.76076447, grad/param norm = 2.5018e-01, time/batch = 18.9597s	
18965/22950 (epoch 41.318), train_loss = 0.69943859, grad/param norm = 2.0018e-01, time/batch = 17.9441s	
18966/22950 (epoch 41.320), train_loss = 0.74160224, grad/param norm = 2.2950e-01, time/batch = 19.3817s	
18967/22950 (epoch 41.322), train_loss = 0.74657861, grad/param norm = 2.5298e-01, time/batch = 18.8633s	
18968/22950 (epoch 41.325), train_loss = 0.60957205, grad/param norm = 2.1318e-01, time/batch = 19.1003s	
18969/22950 (epoch 41.327), train_loss = 0.61838705, grad/param norm = 2.1922e-01, time/batch = 17.4301s	
18970/22950 (epoch 41.329), train_loss = 0.72457689, grad/param norm = 2.1931e-01, time/batch = 17.1863s	
18971/22950 (epoch 41.331), train_loss = 0.68411868, grad/param norm = 2.1654e-01, time/batch = 19.9538s	
18972/22950 (epoch 41.333), train_loss = 0.70700882, grad/param norm = 2.3239e-01, time/batch = 18.7738s	
18973/22950 (epoch 41.336), train_loss = 0.76479059, grad/param norm = 2.6684e-01, time/batch = 18.9507s	
18974/22950 (epoch 41.338), train_loss = 0.78618429, grad/param norm = 2.3609e-01, time/batch = 17.7812s	
18975/22950 (epoch 41.340), train_loss = 0.76118996, grad/param norm = 3.0750e-01, time/batch = 17.3435s	
18976/22950 (epoch 41.342), train_loss = 0.93190845, grad/param norm = 2.4171e-01, time/batch = 19.1293s	
18977/22950 (epoch 41.344), train_loss = 0.77379039, grad/param norm = 2.8752e-01, time/batch = 18.7138s	
18978/22950 (epoch 41.346), train_loss = 0.87703763, grad/param norm = 2.7949e-01, time/batch = 18.5244s	
18979/22950 (epoch 41.349), train_loss = 0.78275898, grad/param norm = 2.4125e-01, time/batch = 18.8732s	
18980/22950 (epoch 41.351), train_loss = 0.82556940, grad/param norm = 3.2333e-01, time/batch = 20.5431s	
18981/22950 (epoch 41.353), train_loss = 0.81491880, grad/param norm = 2.9859e-01, time/batch = 18.4463s	
18982/22950 (epoch 41.355), train_loss = 0.86244279, grad/param norm = 2.8480e-01, time/batch = 19.2853s	
18983/22950 (epoch 41.357), train_loss = 0.74812776, grad/param norm = 3.0582e-01, time/batch = 18.6300s	
18984/22950 (epoch 41.359), train_loss = 0.78891006, grad/param norm = 2.6003e-01, time/batch = 18.5268s	
18985/22950 (epoch 41.362), train_loss = 0.83237284, grad/param norm = 2.5395e-01, time/batch = 19.6940s	
18986/22950 (epoch 41.364), train_loss = 0.80553565, grad/param norm = 3.0668e-01, time/batch = 18.4539s	
18987/22950 (epoch 41.366), train_loss = 0.80205473, grad/param norm = 2.4119e-01, time/batch = 18.5514s	
18988/22950 (epoch 41.368), train_loss = 0.83787837, grad/param norm = 3.0914e-01, time/batch = 20.2705s	
18989/22950 (epoch 41.370), train_loss = 0.78572178, grad/param norm = 2.7385e-01, time/batch = 15.7773s	
18990/22950 (epoch 41.373), train_loss = 0.73748033, grad/param norm = 2.6597e-01, time/batch = 18.7756s	
18991/22950 (epoch 41.375), train_loss = 0.90608194, grad/param norm = 3.4732e-01, time/batch = 17.9445s	
18992/22950 (epoch 41.377), train_loss = 0.73610676, grad/param norm = 2.9493e-01, time/batch = 19.1213s	
18993/22950 (epoch 41.379), train_loss = 0.79194042, grad/param norm = 2.4846e-01, time/batch = 19.9493s	
18994/22950 (epoch 41.381), train_loss = 0.69346567, grad/param norm = 2.4053e-01, time/batch = 17.4338s	
18995/22950 (epoch 41.383), train_loss = 0.78274804, grad/param norm = 3.1718e-01, time/batch = 19.3809s	
18996/22950 (epoch 41.386), train_loss = 0.73248539, grad/param norm = 2.6350e-01, time/batch = 18.1321s	
18997/22950 (epoch 41.388), train_loss = 0.85365443, grad/param norm = 2.6895e-01, time/batch = 17.7179s	
18998/22950 (epoch 41.390), train_loss = 0.70766614, grad/param norm = 2.6898e-01, time/batch = 19.0374s	
18999/22950 (epoch 41.392), train_loss = 0.74805625, grad/param norm = 2.7273e-01, time/batch = 19.8717s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch41.39_2.1082.t7	
19000/22950 (epoch 41.394), train_loss = 0.74527853, grad/param norm = 2.3538e-01, time/batch = 18.2866s	
19001/22950 (epoch 41.397), train_loss = 1.40616387, grad/param norm = 3.3786e-01, time/batch = 17.4371s	
19002/22950 (epoch 41.399), train_loss = 0.87363270, grad/param norm = 2.9270e-01, time/batch = 20.3563s	
19003/22950 (epoch 41.401), train_loss = 0.92347615, grad/param norm = 3.3860e-01, time/batch = 18.8761s	
19004/22950 (epoch 41.403), train_loss = 0.78779595, grad/param norm = 2.4396e-01, time/batch = 18.4530s	
19005/22950 (epoch 41.405), train_loss = 0.93235804, grad/param norm = 3.0416e-01, time/batch = 20.3623s	
19006/22950 (epoch 41.407), train_loss = 0.96507378, grad/param norm = 2.5809e-01, time/batch = 18.3684s	
19007/22950 (epoch 41.410), train_loss = 0.83053228, grad/param norm = 2.4735e-01, time/batch = 17.7437s	
19008/22950 (epoch 41.412), train_loss = 0.77164172, grad/param norm = 2.7385e-01, time/batch = 17.9665s	
19009/22950 (epoch 41.414), train_loss = 0.89038700, grad/param norm = 2.5091e-01, time/batch = 19.0483s	
19010/22950 (epoch 41.416), train_loss = 0.84274112, grad/param norm = 4.0642e-01, time/batch = 19.2866s	
19011/22950 (epoch 41.418), train_loss = 0.80746410, grad/param norm = 2.8873e-01, time/batch = 16.3688s	
19012/22950 (epoch 41.420), train_loss = 0.86666441, grad/param norm = 3.0375e-01, time/batch = 19.1094s	
19013/22950 (epoch 41.423), train_loss = 0.76029645, grad/param norm = 2.5726e-01, time/batch = 19.4485s	
19014/22950 (epoch 41.425), train_loss = 0.79062264, grad/param norm = 2.6838e-01, time/batch = 18.3716s	
19015/22950 (epoch 41.427), train_loss = 0.82496933, grad/param norm = 2.7199e-01, time/batch = 19.2039s	
19016/22950 (epoch 41.429), train_loss = 0.82056826, grad/param norm = 2.4040e-01, time/batch = 19.0958s	
19017/22950 (epoch 41.431), train_loss = 0.87328118, grad/param norm = 2.6780e-01, time/batch = 17.0292s	
19018/22950 (epoch 41.434), train_loss = 0.80665636, grad/param norm = 2.7646e-01, time/batch = 17.3739s	
19019/22950 (epoch 41.436), train_loss = 0.88686094, grad/param norm = 3.0508e-01, time/batch = 20.1179s	
19020/22950 (epoch 41.438), train_loss = 0.80083482, grad/param norm = 2.6602e-01, time/batch = 19.2719s	
19021/22950 (epoch 41.440), train_loss = 0.90186203, grad/param norm = 2.4436e-01, time/batch = 16.2635s	
19022/22950 (epoch 41.442), train_loss = 0.94346329, grad/param norm = 2.6944e-01, time/batch = 19.5282s	
19023/22950 (epoch 41.444), train_loss = 0.84598127, grad/param norm = 3.4979e-01, time/batch = 19.7060s	
19024/22950 (epoch 41.447), train_loss = 0.96544193, grad/param norm = 2.9142e-01, time/batch = 18.0384s	
19025/22950 (epoch 41.449), train_loss = 0.73445928, grad/param norm = 2.3566e-01, time/batch = 19.9613s	
19026/22950 (epoch 41.451), train_loss = 0.81090092, grad/param norm = 2.9197e-01, time/batch = 19.7910s	
19027/22950 (epoch 41.453), train_loss = 0.84277611, grad/param norm = 2.6022e-01, time/batch = 35.1590s	
19028/22950 (epoch 41.455), train_loss = 0.81788797, grad/param norm = 2.3165e-01, time/batch = 18.3616s	
19029/22950 (epoch 41.458), train_loss = 0.81505215, grad/param norm = 2.8391e-01, time/batch = 17.9341s	
19030/22950 (epoch 41.460), train_loss = 0.86469643, grad/param norm = 2.8575e-01, time/batch = 18.6082s	
19031/22950 (epoch 41.462), train_loss = 0.85441885, grad/param norm = 2.6684e-01, time/batch = 17.9474s	
19032/22950 (epoch 41.464), train_loss = 0.75719466, grad/param norm = 2.2094e-01, time/batch = 16.7769s	
19033/22950 (epoch 41.466), train_loss = 0.89407033, grad/param norm = 2.9092e-01, time/batch = 18.4666s	
19034/22950 (epoch 41.468), train_loss = 0.85994488, grad/param norm = 2.6460e-01, time/batch = 19.3883s	
19035/22950 (epoch 41.471), train_loss = 0.85784232, grad/param norm = 2.8054e-01, time/batch = 15.9491s	
19036/22950 (epoch 41.473), train_loss = 0.86018475, grad/param norm = 2.8222e-01, time/batch = 17.1137s	
19037/22950 (epoch 41.475), train_loss = 0.96666508, grad/param norm = 2.8197e-01, time/batch = 19.3112s	
19038/22950 (epoch 41.477), train_loss = 0.79433214, grad/param norm = 2.9209e-01, time/batch = 19.0427s	
19039/22950 (epoch 41.479), train_loss = 0.72452758, grad/param norm = 2.5502e-01, time/batch = 17.8783s	
19040/22950 (epoch 41.481), train_loss = 0.87295774, grad/param norm = 2.8182e-01, time/batch = 19.6319s	
19041/22950 (epoch 41.484), train_loss = 0.84750816, grad/param norm = 3.2497e-01, time/batch = 18.6294s	
19042/22950 (epoch 41.486), train_loss = 0.71501314, grad/param norm = 2.5021e-01, time/batch = 17.3781s	
19043/22950 (epoch 41.488), train_loss = 0.72788413, grad/param norm = 2.7437e-01, time/batch = 19.0379s	
19044/22950 (epoch 41.490), train_loss = 0.68444971, grad/param norm = 2.3427e-01, time/batch = 18.8705s	
19045/22950 (epoch 41.492), train_loss = 0.76624868, grad/param norm = 2.3192e-01, time/batch = 18.9592s	
19046/22950 (epoch 41.495), train_loss = 0.75575715, grad/param norm = 2.8419e-01, time/batch = 17.6952s	
19047/22950 (epoch 41.497), train_loss = 0.84640781, grad/param norm = 2.7692e-01, time/batch = 20.2773s	
19048/22950 (epoch 41.499), train_loss = 0.91151162, grad/param norm = 2.3564e-01, time/batch = 17.7892s	
19049/22950 (epoch 41.501), train_loss = 0.81495547, grad/param norm = 2.8775e-01, time/batch = 18.1315s	
19050/22950 (epoch 41.503), train_loss = 0.91597924, grad/param norm = 2.5950e-01, time/batch = 18.6171s	
19051/22950 (epoch 41.505), train_loss = 0.67988264, grad/param norm = 2.2568e-01, time/batch = 19.5453s	
19052/22950 (epoch 41.508), train_loss = 0.87158784, grad/param norm = 2.4433e-01, time/batch = 18.7816s	
19053/22950 (epoch 41.510), train_loss = 0.77035560, grad/param norm = 2.5417e-01, time/batch = 16.2008s	
19054/22950 (epoch 41.512), train_loss = 0.70234142, grad/param norm = 2.5972e-01, time/batch = 19.9299s	
19055/22950 (epoch 41.514), train_loss = 0.78495355, grad/param norm = 2.2900e-01, time/batch = 18.8763s	
19056/22950 (epoch 41.516), train_loss = 0.80402623, grad/param norm = 2.3419e-01, time/batch = 19.6345s	
19057/22950 (epoch 41.519), train_loss = 0.80893044, grad/param norm = 2.3350e-01, time/batch = 19.0576s	
19058/22950 (epoch 41.521), train_loss = 0.81813626, grad/param norm = 2.6099e-01, time/batch = 18.5257s	
19059/22950 (epoch 41.523), train_loss = 0.64215532, grad/param norm = 2.2139e-01, time/batch = 19.0986s	
19060/22950 (epoch 41.525), train_loss = 0.72809702, grad/param norm = 2.5215e-01, time/batch = 19.5413s	
19061/22950 (epoch 41.527), train_loss = 0.70770742, grad/param norm = 2.2365e-01, time/batch = 18.7094s	
19062/22950 (epoch 41.529), train_loss = 0.79653989, grad/param norm = 2.6644e-01, time/batch = 19.5598s	
19063/22950 (epoch 41.532), train_loss = 0.77650896, grad/param norm = 2.4665e-01, time/batch = 18.4533s	
19064/22950 (epoch 41.534), train_loss = 0.80118960, grad/param norm = 2.5248e-01, time/batch = 16.1183s	
19065/22950 (epoch 41.536), train_loss = 0.85541692, grad/param norm = 3.3154e-01, time/batch = 20.0472s	
19066/22950 (epoch 41.538), train_loss = 0.78256661, grad/param norm = 2.4645e-01, time/batch = 17.3065s	
19067/22950 (epoch 41.540), train_loss = 0.83876898, grad/param norm = 2.5940e-01, time/batch = 20.6220s	
19068/22950 (epoch 41.542), train_loss = 0.96626506, grad/param norm = 2.9250e-01, time/batch = 20.6897s	
19069/22950 (epoch 41.545), train_loss = 0.80499414, grad/param norm = 2.4804e-01, time/batch = 18.0572s	
19070/22950 (epoch 41.547), train_loss = 0.80311389, grad/param norm = 2.6030e-01, time/batch = 19.7207s	
19071/22950 (epoch 41.549), train_loss = 0.77518510, grad/param norm = 3.8266e-01, time/batch = 16.4259s	
19072/22950 (epoch 41.551), train_loss = 0.77982135, grad/param norm = 2.6710e-01, time/batch = 18.9734s	
19073/22950 (epoch 41.553), train_loss = 0.74777521, grad/param norm = 2.5494e-01, time/batch = 18.8012s	
19074/22950 (epoch 41.556), train_loss = 0.84388417, grad/param norm = 2.6167e-01, time/batch = 15.2037s	
19075/22950 (epoch 41.558), train_loss = 0.67575918, grad/param norm = 2.4206e-01, time/batch = 0.6755s	
19076/22950 (epoch 41.560), train_loss = 0.78248412, grad/param norm = 3.0190e-01, time/batch = 0.6767s	
19077/22950 (epoch 41.562), train_loss = 0.76275379, grad/param norm = 2.4131e-01, time/batch = 0.6779s	
19078/22950 (epoch 41.564), train_loss = 0.82202137, grad/param norm = 2.5629e-01, time/batch = 0.6868s	
19079/22950 (epoch 41.566), train_loss = 0.82248915, grad/param norm = 2.5980e-01, time/batch = 0.6792s	
19080/22950 (epoch 41.569), train_loss = 0.78555733, grad/param norm = 2.6755e-01, time/batch = 0.6805s	
19081/22950 (epoch 41.571), train_loss = 0.76465762, grad/param norm = 2.4800e-01, time/batch = 0.6801s	
19082/22950 (epoch 41.573), train_loss = 0.76922755, grad/param norm = 2.8954e-01, time/batch = 0.9332s	
19083/22950 (epoch 41.575), train_loss = 0.83947593, grad/param norm = 2.8892e-01, time/batch = 0.9958s	
19084/22950 (epoch 41.577), train_loss = 0.80537639, grad/param norm = 3.2136e-01, time/batch = 0.9846s	
19085/22950 (epoch 41.580), train_loss = 0.85690525, grad/param norm = 3.0569e-01, time/batch = 0.9921s	
19086/22950 (epoch 41.582), train_loss = 0.92373027, grad/param norm = 2.9169e-01, time/batch = 0.9929s	
19087/22950 (epoch 41.584), train_loss = 0.69838878, grad/param norm = 3.2519e-01, time/batch = 1.6237s	
19088/22950 (epoch 41.586), train_loss = 0.75577242, grad/param norm = 2.8464e-01, time/batch = 1.8382s	
19089/22950 (epoch 41.588), train_loss = 0.89515031, grad/param norm = 2.5434e-01, time/batch = 2.6047s	
19090/22950 (epoch 41.590), train_loss = 0.87656605, grad/param norm = 2.5541e-01, time/batch = 18.6208s	
19091/22950 (epoch 41.593), train_loss = 0.76666406, grad/param norm = 2.5080e-01, time/batch = 19.1223s	
19092/22950 (epoch 41.595), train_loss = 0.74980327, grad/param norm = 2.7281e-01, time/batch = 20.5117s	
19093/22950 (epoch 41.597), train_loss = 0.84569035, grad/param norm = 2.7470e-01, time/batch = 19.8592s	
19094/22950 (epoch 41.599), train_loss = 0.82804539, grad/param norm = 3.2399e-01, time/batch = 17.3866s	
19095/22950 (epoch 41.601), train_loss = 0.86369602, grad/param norm = 2.4754e-01, time/batch = 16.6279s	
19096/22950 (epoch 41.603), train_loss = 0.90954958, grad/param norm = 2.6143e-01, time/batch = 19.9550s	
19097/22950 (epoch 41.606), train_loss = 0.79152505, grad/param norm = 2.6008e-01, time/batch = 20.6280s	
19098/22950 (epoch 41.608), train_loss = 0.76591436, grad/param norm = 2.5119e-01, time/batch = 18.2039s	
19099/22950 (epoch 41.610), train_loss = 0.78500997, grad/param norm = 2.2652e-01, time/batch = 19.0408s	
19100/22950 (epoch 41.612), train_loss = 0.80550534, grad/param norm = 2.4955e-01, time/batch = 20.2983s	
19101/22950 (epoch 41.614), train_loss = 0.91280173, grad/param norm = 3.0114e-01, time/batch = 18.2883s	
19102/22950 (epoch 41.617), train_loss = 0.82006630, grad/param norm = 2.7089e-01, time/batch = 18.8691s	
19103/22950 (epoch 41.619), train_loss = 0.75076646, grad/param norm = 2.5676e-01, time/batch = 19.8029s	
19104/22950 (epoch 41.621), train_loss = 0.86292454, grad/param norm = 2.5962e-01, time/batch = 17.2831s	
19105/22950 (epoch 41.623), train_loss = 0.84991145, grad/param norm = 2.5714e-01, time/batch = 18.6447s	
19106/22950 (epoch 41.625), train_loss = 0.80131492, grad/param norm = 2.5547e-01, time/batch = 15.8372s	
19107/22950 (epoch 41.627), train_loss = 0.77804608, grad/param norm = 2.8593e-01, time/batch = 15.0612s	
19108/22950 (epoch 41.630), train_loss = 0.69373788, grad/param norm = 2.0435e-01, time/batch = 15.7344s	
19109/22950 (epoch 41.632), train_loss = 0.78295030, grad/param norm = 2.9432e-01, time/batch = 17.5548s	
19110/22950 (epoch 41.634), train_loss = 0.82745452, grad/param norm = 2.5959e-01, time/batch = 18.6291s	
19111/22950 (epoch 41.636), train_loss = 0.81295781, grad/param norm = 3.1910e-01, time/batch = 17.6956s	
19112/22950 (epoch 41.638), train_loss = 0.80015085, grad/param norm = 2.9596e-01, time/batch = 17.7133s	
19113/22950 (epoch 41.641), train_loss = 0.78609587, grad/param norm = 2.5192e-01, time/batch = 19.2262s	
19114/22950 (epoch 41.643), train_loss = 0.83147693, grad/param norm = 3.4320e-01, time/batch = 18.5537s	
19115/22950 (epoch 41.645), train_loss = 0.77355824, grad/param norm = 2.5119e-01, time/batch = 18.6207s	
19116/22950 (epoch 41.647), train_loss = 0.76664431, grad/param norm = 2.5104e-01, time/batch = 18.9400s	
19117/22950 (epoch 41.649), train_loss = 0.72817317, grad/param norm = 2.6971e-01, time/batch = 18.7860s	
19118/22950 (epoch 41.651), train_loss = 0.87656744, grad/param norm = 2.9215e-01, time/batch = 19.4642s	
19119/22950 (epoch 41.654), train_loss = 0.68890157, grad/param norm = 2.1801e-01, time/batch = 18.2976s	
19120/22950 (epoch 41.656), train_loss = 0.84175743, grad/param norm = 2.9303e-01, time/batch = 19.6289s	
19121/22950 (epoch 41.658), train_loss = 0.71008038, grad/param norm = 2.7375e-01, time/batch = 19.6635s	
19122/22950 (epoch 41.660), train_loss = 0.64396433, grad/param norm = 2.6079e-01, time/batch = 18.7152s	
19123/22950 (epoch 41.662), train_loss = 0.67058811, grad/param norm = 2.7837e-01, time/batch = 16.4477s	
19124/22950 (epoch 41.664), train_loss = 0.76359525, grad/param norm = 2.7451e-01, time/batch = 18.5328s	
19125/22950 (epoch 41.667), train_loss = 0.78318050, grad/param norm = 2.6434e-01, time/batch = 19.9548s	
19126/22950 (epoch 41.669), train_loss = 0.79676833, grad/param norm = 2.7726e-01, time/batch = 17.5406s	
19127/22950 (epoch 41.671), train_loss = 0.78015136, grad/param norm = 2.6688e-01, time/batch = 17.6900s	
19128/22950 (epoch 41.673), train_loss = 0.73678303, grad/param norm = 2.9050e-01, time/batch = 20.0338s	
19129/22950 (epoch 41.675), train_loss = 0.81570233, grad/param norm = 2.7471e-01, time/batch = 20.0415s	
19130/22950 (epoch 41.678), train_loss = 0.78787807, grad/param norm = 2.5940e-01, time/batch = 17.9609s	
19131/22950 (epoch 41.680), train_loss = 0.83360506, grad/param norm = 2.4925e-01, time/batch = 19.1147s	
19132/22950 (epoch 41.682), train_loss = 0.78358628, grad/param norm = 2.5025e-01, time/batch = 18.7877s	
19133/22950 (epoch 41.684), train_loss = 0.89799604, grad/param norm = 2.9777e-01, time/batch = 17.4531s	
19134/22950 (epoch 41.686), train_loss = 0.90001034, grad/param norm = 2.4987e-01, time/batch = 20.4549s	
19135/22950 (epoch 41.688), train_loss = 0.80981600, grad/param norm = 2.7131e-01, time/batch = 19.1962s	
19136/22950 (epoch 41.691), train_loss = 0.78635434, grad/param norm = 2.5022e-01, time/batch = 18.6263s	
19137/22950 (epoch 41.693), train_loss = 0.73088584, grad/param norm = 2.5291e-01, time/batch = 20.3577s	
19138/22950 (epoch 41.695), train_loss = 0.88746869, grad/param norm = 3.0034e-01, time/batch = 18.7195s	
19139/22950 (epoch 41.697), train_loss = 0.83100196, grad/param norm = 2.9488e-01, time/batch = 19.5323s	
19140/22950 (epoch 41.699), train_loss = 0.83295250, grad/param norm = 2.5807e-01, time/batch = 18.4589s	
19141/22950 (epoch 41.702), train_loss = 0.86838774, grad/param norm = 2.9961e-01, time/batch = 19.3732s	
19142/22950 (epoch 41.704), train_loss = 0.96768558, grad/param norm = 3.4564e-01, time/batch = 17.8824s	
19143/22950 (epoch 41.706), train_loss = 0.88554159, grad/param norm = 2.8608e-01, time/batch = 16.3596s	
19144/22950 (epoch 41.708), train_loss = 0.69641857, grad/param norm = 2.5050e-01, time/batch = 15.9485s	
19145/22950 (epoch 41.710), train_loss = 0.79628737, grad/param norm = 2.5735e-01, time/batch = 20.1150s	
19146/22950 (epoch 41.712), train_loss = 0.93642959, grad/param norm = 3.1118e-01, time/batch = 17.9576s	
19147/22950 (epoch 41.715), train_loss = 0.84840986, grad/param norm = 3.1004e-01, time/batch = 19.4609s	
19148/22950 (epoch 41.717), train_loss = 0.84833847, grad/param norm = 2.3988e-01, time/batch = 19.2109s	
19149/22950 (epoch 41.719), train_loss = 0.81055450, grad/param norm = 3.0402e-01, time/batch = 17.4471s	
19150/22950 (epoch 41.721), train_loss = 0.87643886, grad/param norm = 2.8638e-01, time/batch = 20.6923s	
19151/22950 (epoch 41.723), train_loss = 0.83314358, grad/param norm = 3.2433e-01, time/batch = 18.8709s	
19152/22950 (epoch 41.725), train_loss = 0.86663533, grad/param norm = 2.9892e-01, time/batch = 18.7094s	
19153/22950 (epoch 41.728), train_loss = 0.80736363, grad/param norm = 2.8337e-01, time/batch = 19.1163s	
19154/22950 (epoch 41.730), train_loss = 0.84099656, grad/param norm = 3.0688e-01, time/batch = 18.2917s	
19155/22950 (epoch 41.732), train_loss = 0.90391513, grad/param norm = 2.9662e-01, time/batch = 19.5361s	
19156/22950 (epoch 41.734), train_loss = 0.78910508, grad/param norm = 2.9847e-01, time/batch = 19.2610s	
19157/22950 (epoch 41.736), train_loss = 0.86214806, grad/param norm = 2.7951e-01, time/batch = 19.5321s	
19158/22950 (epoch 41.739), train_loss = 0.87809723, grad/param norm = 3.1465e-01, time/batch = 18.0439s	
19159/22950 (epoch 41.741), train_loss = 0.89452928, grad/param norm = 2.9960e-01, time/batch = 17.9307s	
19160/22950 (epoch 41.743), train_loss = 0.97277801, grad/param norm = 4.5862e-01, time/batch = 19.9520s	
19161/22950 (epoch 41.745), train_loss = 1.05204246, grad/param norm = 3.2948e-01, time/batch = 20.3712s	
19162/22950 (epoch 41.747), train_loss = 0.91756910, grad/param norm = 4.0371e-01, time/batch = 17.0960s	
19163/22950 (epoch 41.749), train_loss = 0.75798081, grad/param norm = 2.6325e-01, time/batch = 19.5253s	
19164/22950 (epoch 41.752), train_loss = 1.00032901, grad/param norm = 3.2472e-01, time/batch = 19.9535s	
19165/22950 (epoch 41.754), train_loss = 0.87169797, grad/param norm = 3.2406e-01, time/batch = 18.6241s	
19166/22950 (epoch 41.756), train_loss = 0.80991391, grad/param norm = 2.8460e-01, time/batch = 19.4566s	
19167/22950 (epoch 41.758), train_loss = 0.85027794, grad/param norm = 2.5091e-01, time/batch = 18.7195s	
19168/22950 (epoch 41.760), train_loss = 0.82243516, grad/param norm = 2.6756e-01, time/batch = 17.7782s	
19169/22950 (epoch 41.763), train_loss = 0.86470328, grad/param norm = 2.8203e-01, time/batch = 18.0279s	
19170/22950 (epoch 41.765), train_loss = 0.83424523, grad/param norm = 3.0115e-01, time/batch = 18.0385s	
19171/22950 (epoch 41.767), train_loss = 1.02282467, grad/param norm = 3.4224e-01, time/batch = 18.6315s	
19172/22950 (epoch 41.769), train_loss = 0.85501802, grad/param norm = 2.6053e-01, time/batch = 17.7042s	
19173/22950 (epoch 41.771), train_loss = 0.73397212, grad/param norm = 2.6044e-01, time/batch = 18.7944s	
19174/22950 (epoch 41.773), train_loss = 0.63617093, grad/param norm = 2.4727e-01, time/batch = 18.3744s	
19175/22950 (epoch 41.776), train_loss = 0.75088042, grad/param norm = 2.1465e-01, time/batch = 19.0244s	
19176/22950 (epoch 41.778), train_loss = 0.75390336, grad/param norm = 2.6876e-01, time/batch = 19.1335s	
19177/22950 (epoch 41.780), train_loss = 0.83296337, grad/param norm = 2.5586e-01, time/batch = 17.1959s	
19178/22950 (epoch 41.782), train_loss = 0.87171220, grad/param norm = 2.5415e-01, time/batch = 17.2057s	
19179/22950 (epoch 41.784), train_loss = 0.77318848, grad/param norm = 2.7957e-01, time/batch = 20.0420s	
19180/22950 (epoch 41.786), train_loss = 0.82804081, grad/param norm = 2.8379e-01, time/batch = 19.9572s	
19181/22950 (epoch 41.789), train_loss = 0.68713824, grad/param norm = 2.8539e-01, time/batch = 18.2089s	
19182/22950 (epoch 41.791), train_loss = 0.71229727, grad/param norm = 2.4334e-01, time/batch = 19.2900s	
19183/22950 (epoch 41.793), train_loss = 0.94128706, grad/param norm = 3.4491e-01, time/batch = 19.7949s	
19184/22950 (epoch 41.795), train_loss = 0.78422216, grad/param norm = 2.3494e-01, time/batch = 18.4437s	
19185/22950 (epoch 41.797), train_loss = 0.93612121, grad/param norm = 2.8075e-01, time/batch = 18.7943s	
19186/22950 (epoch 41.800), train_loss = 0.77227648, grad/param norm = 2.5407e-01, time/batch = 17.6358s	
19187/22950 (epoch 41.802), train_loss = 0.80932440, grad/param norm = 2.9488e-01, time/batch = 19.3665s	
19188/22950 (epoch 41.804), train_loss = 0.80851608, grad/param norm = 2.4635e-01, time/batch = 19.2843s	
19189/22950 (epoch 41.806), train_loss = 0.70561787, grad/param norm = 2.3775e-01, time/batch = 20.1130s	
19190/22950 (epoch 41.808), train_loss = 0.85062121, grad/param norm = 2.5153e-01, time/batch = 17.6918s	
19191/22950 (epoch 41.810), train_loss = 0.75971053, grad/param norm = 2.6047e-01, time/batch = 18.9370s	
19192/22950 (epoch 41.813), train_loss = 0.68216951, grad/param norm = 2.3252e-01, time/batch = 16.9466s	
19193/22950 (epoch 41.815), train_loss = 0.64663033, grad/param norm = 2.5324e-01, time/batch = 19.6993s	
19194/22950 (epoch 41.817), train_loss = 0.72967918, grad/param norm = 2.3979e-01, time/batch = 19.1095s	
19195/22950 (epoch 41.819), train_loss = 0.76748066, grad/param norm = 2.6694e-01, time/batch = 18.2113s	
19196/22950 (epoch 41.821), train_loss = 0.77157931, grad/param norm = 2.7520e-01, time/batch = 19.3884s	
19197/22950 (epoch 41.824), train_loss = 0.81811897, grad/param norm = 2.3893e-01, time/batch = 17.7831s	
19198/22950 (epoch 41.826), train_loss = 0.84035158, grad/param norm = 2.9194e-01, time/batch = 18.3019s	
19199/22950 (epoch 41.828), train_loss = 0.75633979, grad/param norm = 2.4434e-01, time/batch = 19.0613s	
19200/22950 (epoch 41.830), train_loss = 0.77623427, grad/param norm = 3.2601e-01, time/batch = 18.1221s	
19201/22950 (epoch 41.832), train_loss = 0.83029797, grad/param norm = 2.4569e-01, time/batch = 19.8732s	
19202/22950 (epoch 41.834), train_loss = 0.65093574, grad/param norm = 2.5428e-01, time/batch = 19.1147s	
19203/22950 (epoch 41.837), train_loss = 0.82233925, grad/param norm = 2.9285e-01, time/batch = 18.8734s	
19204/22950 (epoch 41.839), train_loss = 0.67190580, grad/param norm = 2.4105e-01, time/batch = 18.3959s	
19205/22950 (epoch 41.841), train_loss = 0.78505883, grad/param norm = 2.4330e-01, time/batch = 19.4538s	
19206/22950 (epoch 41.843), train_loss = 0.76535134, grad/param norm = 2.5705e-01, time/batch = 16.5346s	
19207/22950 (epoch 41.845), train_loss = 0.79253293, grad/param norm = 2.5737e-01, time/batch = 18.7683s	
19208/22950 (epoch 41.847), train_loss = 0.82556314, grad/param norm = 2.6405e-01, time/batch = 19.7179s	
19209/22950 (epoch 41.850), train_loss = 0.84867358, grad/param norm = 2.5291e-01, time/batch = 18.2213s	
19210/22950 (epoch 41.852), train_loss = 0.87029182, grad/param norm = 2.8550e-01, time/batch = 19.1153s	
19211/22950 (epoch 41.854), train_loss = 0.81133738, grad/param norm = 2.4859e-01, time/batch = 19.1348s	
19212/22950 (epoch 41.856), train_loss = 0.89555336, grad/param norm = 2.8866e-01, time/batch = 21.0252s	
19213/22950 (epoch 41.858), train_loss = 0.87111220, grad/param norm = 2.6640e-01, time/batch = 18.1078s	
19214/22950 (epoch 41.861), train_loss = 0.84919456, grad/param norm = 2.8061e-01, time/batch = 19.8795s	
19215/22950 (epoch 41.863), train_loss = 0.88949011, grad/param norm = 3.2843e-01, time/batch = 17.9389s	
19216/22950 (epoch 41.865), train_loss = 0.93129585, grad/param norm = 2.9544e-01, time/batch = 17.0047s	
19217/22950 (epoch 41.867), train_loss = 0.83657302, grad/param norm = 2.8790e-01, time/batch = 21.0428s	
19218/22950 (epoch 41.869), train_loss = 0.97860984, grad/param norm = 2.8538e-01, time/batch = 18.4582s	
19219/22950 (epoch 41.871), train_loss = 0.83167877, grad/param norm = 3.0601e-01, time/batch = 19.5416s	
19220/22950 (epoch 41.874), train_loss = 0.84083287, grad/param norm = 2.2363e-01, time/batch = 20.3653s	
19221/22950 (epoch 41.876), train_loss = 0.92565748, grad/param norm = 3.1872e-01, time/batch = 20.6207s	
19222/22950 (epoch 41.878), train_loss = 0.84828261, grad/param norm = 2.9269e-01, time/batch = 17.8524s	
19223/22950 (epoch 41.880), train_loss = 0.98863018, grad/param norm = 2.7460e-01, time/batch = 19.5379s	
19224/22950 (epoch 41.882), train_loss = 0.73802383, grad/param norm = 2.4437e-01, time/batch = 18.1376s	
19225/22950 (epoch 41.885), train_loss = 0.82933941, grad/param norm = 2.5594e-01, time/batch = 18.7117s	
19226/22950 (epoch 41.887), train_loss = 0.80994253, grad/param norm = 2.6584e-01, time/batch = 18.9657s	
19227/22950 (epoch 41.889), train_loss = 0.86116275, grad/param norm = 2.9912e-01, time/batch = 18.8827s	
19228/22950 (epoch 41.891), train_loss = 0.75777564, grad/param norm = 2.5159e-01, time/batch = 17.8576s	
19229/22950 (epoch 41.893), train_loss = 0.83816649, grad/param norm = 2.7584e-01, time/batch = 19.2097s	
19230/22950 (epoch 41.895), train_loss = 0.96647407, grad/param norm = 2.7964e-01, time/batch = 18.6315s	
19231/22950 (epoch 41.898), train_loss = 0.88151776, grad/param norm = 2.5749e-01, time/batch = 17.0348s	
19232/22950 (epoch 41.900), train_loss = 0.78229378, grad/param norm = 2.5801e-01, time/batch = 32.8353s	
19233/22950 (epoch 41.902), train_loss = 0.83462702, grad/param norm = 2.7500e-01, time/batch = 19.0392s	
19234/22950 (epoch 41.904), train_loss = 0.83180499, grad/param norm = 2.8023e-01, time/batch = 18.0260s	
19235/22950 (epoch 41.906), train_loss = 0.83651318, grad/param norm = 2.7184e-01, time/batch = 18.3827s	
19236/22950 (epoch 41.908), train_loss = 0.74352251, grad/param norm = 2.7633e-01, time/batch = 17.2246s	
19237/22950 (epoch 41.911), train_loss = 0.66574562, grad/param norm = 2.2805e-01, time/batch = 17.7830s	
19238/22950 (epoch 41.913), train_loss = 0.82144144, grad/param norm = 2.5809e-01, time/batch = 16.9509s	
19239/22950 (epoch 41.915), train_loss = 0.92996541, grad/param norm = 2.8743e-01, time/batch = 16.1570s	
19240/22950 (epoch 41.917), train_loss = 0.73257745, grad/param norm = 2.6068e-01, time/batch = 19.2100s	
19241/22950 (epoch 41.919), train_loss = 0.82967782, grad/param norm = 2.5299e-01, time/batch = 18.1248s	
19242/22950 (epoch 41.922), train_loss = 0.81807592, grad/param norm = 2.4988e-01, time/batch = 18.8095s	
19243/22950 (epoch 41.924), train_loss = 0.86570941, grad/param norm = 2.7868e-01, time/batch = 19.0573s	
19244/22950 (epoch 41.926), train_loss = 0.67565294, grad/param norm = 2.5812e-01, time/batch = 18.3846s	
19245/22950 (epoch 41.928), train_loss = 0.74354840, grad/param norm = 2.3765e-01, time/batch = 19.2158s	
19246/22950 (epoch 41.930), train_loss = 0.72852180, grad/param norm = 2.3961e-01, time/batch = 18.7031s	
19247/22950 (epoch 41.932), train_loss = 0.67862284, grad/param norm = 2.1194e-01, time/batch = 18.5289s	
19248/22950 (epoch 41.935), train_loss = 0.85289105, grad/param norm = 2.4984e-01, time/batch = 18.7805s	
19249/22950 (epoch 41.937), train_loss = 0.81420253, grad/param norm = 2.7683e-01, time/batch = 19.2984s	
19250/22950 (epoch 41.939), train_loss = 0.75368068, grad/param norm = 2.5736e-01, time/batch = 18.9506s	
19251/22950 (epoch 41.941), train_loss = 0.80211108, grad/param norm = 2.7543e-01, time/batch = 16.6187s	
19252/22950 (epoch 41.943), train_loss = 0.81778938, grad/param norm = 2.5426e-01, time/batch = 19.5492s	
19253/22950 (epoch 41.946), train_loss = 0.66267915, grad/param norm = 2.4527e-01, time/batch = 17.9610s	
19254/22950 (epoch 41.948), train_loss = 0.89797937, grad/param norm = 2.7298e-01, time/batch = 18.5289s	
19255/22950 (epoch 41.950), train_loss = 0.81563615, grad/param norm = 2.9783e-01, time/batch = 20.1334s	
19256/22950 (epoch 41.952), train_loss = 0.86527182, grad/param norm = 2.6578e-01, time/batch = 17.7899s	
19257/22950 (epoch 41.954), train_loss = 0.85614527, grad/param norm = 2.8107e-01, time/batch = 17.5553s	
19258/22950 (epoch 41.956), train_loss = 0.75383524, grad/param norm = 2.5508e-01, time/batch = 18.3853s	
19259/22950 (epoch 41.959), train_loss = 0.73315221, grad/param norm = 2.5026e-01, time/batch = 19.3888s	
19260/22950 (epoch 41.961), train_loss = 0.79961000, grad/param norm = 2.4871e-01, time/batch = 17.9539s	
19261/22950 (epoch 41.963), train_loss = 0.80158296, grad/param norm = 2.5364e-01, time/batch = 18.8985s	
19262/22950 (epoch 41.965), train_loss = 0.88366740, grad/param norm = 2.9954e-01, time/batch = 15.5412s	
19263/22950 (epoch 41.967), train_loss = 0.76415710, grad/param norm = 2.6331e-01, time/batch = 17.8030s	
19264/22950 (epoch 41.969), train_loss = 0.70529313, grad/param norm = 2.4747e-01, time/batch = 18.6943s	
19265/22950 (epoch 41.972), train_loss = 0.78076168, grad/param norm = 2.3502e-01, time/batch = 17.8028s	
19266/22950 (epoch 41.974), train_loss = 0.75528366, grad/param norm = 2.3969e-01, time/batch = 18.1442s	
19267/22950 (epoch 41.976), train_loss = 0.81058293, grad/param norm = 2.5026e-01, time/batch = 17.8761s	
19268/22950 (epoch 41.978), train_loss = 0.72392742, grad/param norm = 2.2912e-01, time/batch = 18.9738s	
19269/22950 (epoch 41.980), train_loss = 0.75268938, grad/param norm = 2.6608e-01, time/batch = 18.2928s	
19270/22950 (epoch 41.983), train_loss = 0.85258239, grad/param norm = 2.4019e-01, time/batch = 16.4404s	
19271/22950 (epoch 41.985), train_loss = 0.73883746, grad/param norm = 2.5368e-01, time/batch = 20.0262s	
19272/22950 (epoch 41.987), train_loss = 0.74908877, grad/param norm = 2.7210e-01, time/batch = 19.8770s	
19273/22950 (epoch 41.989), train_loss = 0.81663194, grad/param norm = 2.7213e-01, time/batch = 18.7041s	
19274/22950 (epoch 41.991), train_loss = 0.68513430, grad/param norm = 2.1690e-01, time/batch = 19.9598s	
19275/22950 (epoch 41.993), train_loss = 0.80563085, grad/param norm = 2.4925e-01, time/batch = 20.4500s	
19276/22950 (epoch 41.996), train_loss = 0.78881405, grad/param norm = 2.8318e-01, time/batch = 19.0440s	
19277/22950 (epoch 41.998), train_loss = 0.69900262, grad/param norm = 2.6289e-01, time/batch = 19.8446s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
19278/22950 (epoch 42.000), train_loss = 0.68728122, grad/param norm = 2.3730e-01, time/batch = 19.4702s	
19279/22950 (epoch 42.002), train_loss = 0.94827609, grad/param norm = 5.2361e-01, time/batch = 15.9372s	
19280/22950 (epoch 42.004), train_loss = 0.86729282, grad/param norm = 3.0329e-01, time/batch = 18.9149s	
19281/22950 (epoch 42.007), train_loss = 0.78958718, grad/param norm = 2.8319e-01, time/batch = 18.3665s	
19282/22950 (epoch 42.009), train_loss = 0.91326634, grad/param norm = 3.0504e-01, time/batch = 18.9649s	
19283/22950 (epoch 42.011), train_loss = 0.68820091, grad/param norm = 2.8485e-01, time/batch = 18.1031s	
19284/22950 (epoch 42.013), train_loss = 0.76187703, grad/param norm = 2.5941e-01, time/batch = 18.3832s	
19285/22950 (epoch 42.015), train_loss = 0.83070491, grad/param norm = 3.1818e-01, time/batch = 19.7204s	
19286/22950 (epoch 42.017), train_loss = 0.81258918, grad/param norm = 2.6274e-01, time/batch = 18.6820s	
19287/22950 (epoch 42.020), train_loss = 0.83927225, grad/param norm = 2.4087e-01, time/batch = 18.3663s	
19288/22950 (epoch 42.022), train_loss = 0.71531421, grad/param norm = 2.5188e-01, time/batch = 20.1855s	
19289/22950 (epoch 42.024), train_loss = 0.77791461, grad/param norm = 2.6346e-01, time/batch = 18.1013s	
19290/22950 (epoch 42.026), train_loss = 0.82593013, grad/param norm = 2.3092e-01, time/batch = 20.3803s	
19291/22950 (epoch 42.028), train_loss = 0.85749672, grad/param norm = 2.5154e-01, time/batch = 19.8791s	
19292/22950 (epoch 42.031), train_loss = 0.76525805, grad/param norm = 2.7438e-01, time/batch = 17.7004s	
19293/22950 (epoch 42.033), train_loss = 0.89287455, grad/param norm = 3.0246e-01, time/batch = 20.7953s	
19294/22950 (epoch 42.035), train_loss = 0.79490992, grad/param norm = 2.2552e-01, time/batch = 16.2666s	
19295/22950 (epoch 42.037), train_loss = 0.80716181, grad/param norm = 2.7518e-01, time/batch = 18.9606s	
19296/22950 (epoch 42.039), train_loss = 0.77529585, grad/param norm = 2.4182e-01, time/batch = 17.1119s	
19297/22950 (epoch 42.041), train_loss = 0.75583607, grad/param norm = 3.0526e-01, time/batch = 18.9561s	
19298/22950 (epoch 42.044), train_loss = 0.83776881, grad/param norm = 2.9536e-01, time/batch = 20.2143s	
19299/22950 (epoch 42.046), train_loss = 0.78728987, grad/param norm = 2.2607e-01, time/batch = 17.5579s	
19300/22950 (epoch 42.048), train_loss = 0.81495240, grad/param norm = 2.9745e-01, time/batch = 18.9663s	
19301/22950 (epoch 42.050), train_loss = 0.76542455, grad/param norm = 3.1600e-01, time/batch = 18.6161s	
19302/22950 (epoch 42.052), train_loss = 0.82858368, grad/param norm = 2.5054e-01, time/batch = 17.9566s	
19303/22950 (epoch 42.054), train_loss = 0.94942209, grad/param norm = 2.8950e-01, time/batch = 19.4002s	
19304/22950 (epoch 42.057), train_loss = 0.92966439, grad/param norm = 2.8788e-01, time/batch = 17.6326s	
19305/22950 (epoch 42.059), train_loss = 0.92831569, grad/param norm = 2.6057e-01, time/batch = 18.4510s	
19306/22950 (epoch 42.061), train_loss = 0.75092831, grad/param norm = 2.4878e-01, time/batch = 19.3787s	
19307/22950 (epoch 42.063), train_loss = 0.85941292, grad/param norm = 3.2309e-01, time/batch = 18.6310s	
19308/22950 (epoch 42.065), train_loss = 0.73213529, grad/param norm = 2.6410e-01, time/batch = 15.8548s	
19309/22950 (epoch 42.068), train_loss = 0.83257718, grad/param norm = 2.9849e-01, time/batch = 18.0201s	
19310/22950 (epoch 42.070), train_loss = 0.73011217, grad/param norm = 2.5261e-01, time/batch = 20.0504s	
19311/22950 (epoch 42.072), train_loss = 0.84918496, grad/param norm = 2.7136e-01, time/batch = 19.7023s	
19312/22950 (epoch 42.074), train_loss = 0.87671524, grad/param norm = 3.0801e-01, time/batch = 19.9442s	
19313/22950 (epoch 42.076), train_loss = 0.84719758, grad/param norm = 2.5430e-01, time/batch = 19.1259s	
19314/22950 (epoch 42.078), train_loss = 0.89261794, grad/param norm = 2.6892e-01, time/batch = 19.5324s	
19315/22950 (epoch 42.081), train_loss = 0.94569013, grad/param norm = 3.0697e-01, time/batch = 20.0357s	
19316/22950 (epoch 42.083), train_loss = 0.82761856, grad/param norm = 2.7752e-01, time/batch = 16.3026s	
19317/22950 (epoch 42.085), train_loss = 0.69274352, grad/param norm = 2.5093e-01, time/batch = 18.5930s	
19318/22950 (epoch 42.087), train_loss = 0.74145404, grad/param norm = 2.4622e-01, time/batch = 18.1104s	
19319/22950 (epoch 42.089), train_loss = 0.83492051, grad/param norm = 2.7002e-01, time/batch = 19.7766s	
19320/22950 (epoch 42.092), train_loss = 0.76060983, grad/param norm = 3.2119e-01, time/batch = 19.3638s	
19321/22950 (epoch 42.094), train_loss = 0.76649315, grad/param norm = 2.5227e-01, time/batch = 17.7142s	
19322/22950 (epoch 42.096), train_loss = 0.91280639, grad/param norm = 2.9247e-01, time/batch = 19.7328s	
19323/22950 (epoch 42.098), train_loss = 0.86894900, grad/param norm = 2.7029e-01, time/batch = 18.7829s	
19324/22950 (epoch 42.100), train_loss = 0.80745675, grad/param norm = 2.6938e-01, time/batch = 18.2970s	
19325/22950 (epoch 42.102), train_loss = 0.84465757, grad/param norm = 2.8787e-01, time/batch = 19.0397s	
19326/22950 (epoch 42.105), train_loss = 0.69296865, grad/param norm = 2.6559e-01, time/batch = 20.3727s	
19327/22950 (epoch 42.107), train_loss = 0.74791054, grad/param norm = 2.3216e-01, time/batch = 17.6359s	
19328/22950 (epoch 42.109), train_loss = 0.78928320, grad/param norm = 2.7948e-01, time/batch = 19.2822s	
19329/22950 (epoch 42.111), train_loss = 0.68209783, grad/param norm = 2.3384e-01, time/batch = 18.9601s	
19330/22950 (epoch 42.113), train_loss = 0.83845572, grad/param norm = 2.7281e-01, time/batch = 18.1277s	
19331/22950 (epoch 42.115), train_loss = 0.80992150, grad/param norm = 2.4993e-01, time/batch = 19.4567s	
19332/22950 (epoch 42.118), train_loss = 0.89360527, grad/param norm = 2.4250e-01, time/batch = 18.1323s	
19333/22950 (epoch 42.120), train_loss = 0.70692919, grad/param norm = 2.3889e-01, time/batch = 17.9518s	
19334/22950 (epoch 42.122), train_loss = 0.86202757, grad/param norm = 2.5037e-01, time/batch = 16.6922s	
19335/22950 (epoch 42.124), train_loss = 0.71146580, grad/param norm = 2.0765e-01, time/batch = 17.7884s	
19336/22950 (epoch 42.126), train_loss = 0.78587538, grad/param norm = 2.3337e-01, time/batch = 18.8640s	
19337/22950 (epoch 42.129), train_loss = 0.74798719, grad/param norm = 2.0067e-01, time/batch = 17.4396s	
19338/22950 (epoch 42.131), train_loss = 0.78796129, grad/param norm = 2.6177e-01, time/batch = 20.0348s	
19339/22950 (epoch 42.133), train_loss = 0.85236846, grad/param norm = 2.3919e-01, time/batch = 18.7044s	
19340/22950 (epoch 42.135), train_loss = 0.80701944, grad/param norm = 2.2369e-01, time/batch = 18.5297s	
19341/22950 (epoch 42.137), train_loss = 0.85798075, grad/param norm = 3.3641e-01, time/batch = 19.4565s	
19342/22950 (epoch 42.139), train_loss = 0.74326843, grad/param norm = 2.2317e-01, time/batch = 18.1242s	
19343/22950 (epoch 42.142), train_loss = 0.73045345, grad/param norm = 2.1578e-01, time/batch = 18.7891s	
19344/22950 (epoch 42.144), train_loss = 0.77982865, grad/param norm = 2.3910e-01, time/batch = 18.7916s	
19345/22950 (epoch 42.146), train_loss = 0.72008692, grad/param norm = 2.5246e-01, time/batch = 17.5315s	
19346/22950 (epoch 42.148), train_loss = 0.73104573, grad/param norm = 2.4496e-01, time/batch = 19.3026s	
19347/22950 (epoch 42.150), train_loss = 0.80501470, grad/param norm = 2.2980e-01, time/batch = 19.0219s	
19348/22950 (epoch 42.153), train_loss = 0.70668156, grad/param norm = 2.2680e-01, time/batch = 18.7919s	
19349/22950 (epoch 42.155), train_loss = 0.74661057, grad/param norm = 2.6464e-01, time/batch = 17.3577s	
19350/22950 (epoch 42.157), train_loss = 0.77473983, grad/param norm = 2.2148e-01, time/batch = 17.5167s	
19351/22950 (epoch 42.159), train_loss = 0.72521512, grad/param norm = 2.6203e-01, time/batch = 18.5586s	
19352/22950 (epoch 42.161), train_loss = 0.75377923, grad/param norm = 2.3023e-01, time/batch = 19.8013s	
19353/22950 (epoch 42.163), train_loss = 0.69963357, grad/param norm = 2.0870e-01, time/batch = 17.8724s	
19354/22950 (epoch 42.166), train_loss = 0.82761694, grad/param norm = 3.9852e-01, time/batch = 19.6337s	
19355/22950 (epoch 42.168), train_loss = 0.83649069, grad/param norm = 3.6816e-01, time/batch = 18.8774s	
19356/22950 (epoch 42.170), train_loss = 0.82431441, grad/param norm = 2.7388e-01, time/batch = 18.1293s	
19357/22950 (epoch 42.172), train_loss = 0.78169057, grad/param norm = 2.5092e-01, time/batch = 20.5449s	
19358/22950 (epoch 42.174), train_loss = 0.86730701, grad/param norm = 2.4743e-01, time/batch = 16.9590s	
19359/22950 (epoch 42.176), train_loss = 0.86505444, grad/param norm = 2.8225e-01, time/batch = 18.9371s	
19360/22950 (epoch 42.179), train_loss = 0.82313029, grad/param norm = 2.4165e-01, time/batch = 17.3635s	
19361/22950 (epoch 42.181), train_loss = 1.03618601, grad/param norm = 2.8890e-01, time/batch = 18.7857s	
19362/22950 (epoch 42.183), train_loss = 0.84956802, grad/param norm = 2.5373e-01, time/batch = 19.9465s	
19363/22950 (epoch 42.185), train_loss = 0.86232479, grad/param norm = 2.5328e-01, time/batch = 19.3629s	
19364/22950 (epoch 42.187), train_loss = 0.73511882, grad/param norm = 2.5438e-01, time/batch = 18.3094s	
19365/22950 (epoch 42.190), train_loss = 0.64947259, grad/param norm = 2.5325e-01, time/batch = 18.7901s	
19366/22950 (epoch 42.192), train_loss = 0.61914583, grad/param norm = 2.3024e-01, time/batch = 16.6258s	
19367/22950 (epoch 42.194), train_loss = 0.76638389, grad/param norm = 2.6948e-01, time/batch = 19.8917s	
19368/22950 (epoch 42.196), train_loss = 0.58978310, grad/param norm = 2.6429e-01, time/batch = 17.0406s	
19369/22950 (epoch 42.198), train_loss = 0.83695143, grad/param norm = 2.9033e-01, time/batch = 17.1217s	
19370/22950 (epoch 42.200), train_loss = 0.72741293, grad/param norm = 2.3572e-01, time/batch = 19.3814s	
19371/22950 (epoch 42.203), train_loss = 0.67462279, grad/param norm = 2.1822e-01, time/batch = 18.6259s	
19372/22950 (epoch 42.205), train_loss = 0.74660759, grad/param norm = 2.5661e-01, time/batch = 18.9505s	
19373/22950 (epoch 42.207), train_loss = 0.81418666, grad/param norm = 2.6014e-01, time/batch = 15.9547s	
19374/22950 (epoch 42.209), train_loss = 0.76858449, grad/param norm = 2.6865e-01, time/batch = 19.1316s	
19375/22950 (epoch 42.211), train_loss = 0.65766212, grad/param norm = 2.9964e-01, time/batch = 19.7037s	
19376/22950 (epoch 42.214), train_loss = 0.72981982, grad/param norm = 2.3423e-01, time/batch = 17.9425s	
19377/22950 (epoch 42.216), train_loss = 0.86847654, grad/param norm = 2.6326e-01, time/batch = 18.8947s	
19378/22950 (epoch 42.218), train_loss = 0.77467132, grad/param norm = 2.4082e-01, time/batch = 18.3049s	
19379/22950 (epoch 42.220), train_loss = 0.85638986, grad/param norm = 3.0226e-01, time/batch = 16.8342s	
19380/22950 (epoch 42.222), train_loss = 0.87734981, grad/param norm = 2.6802e-01, time/batch = 14.7935s	
19381/22950 (epoch 42.224), train_loss = 0.78689160, grad/param norm = 2.8038e-01, time/batch = 17.4298s	
19382/22950 (epoch 42.227), train_loss = 0.84492058, grad/param norm = 2.5275e-01, time/batch = 17.1933s	
19383/22950 (epoch 42.229), train_loss = 0.91567755, grad/param norm = 2.7315e-01, time/batch = 17.3626s	
19384/22950 (epoch 42.231), train_loss = 0.63276235, grad/param norm = 2.6367e-01, time/batch = 19.7170s	
19385/22950 (epoch 42.233), train_loss = 0.74030566, grad/param norm = 2.5187e-01, time/batch = 19.2060s	
19386/22950 (epoch 42.235), train_loss = 0.90843352, grad/param norm = 2.6165e-01, time/batch = 17.9483s	
19387/22950 (epoch 42.237), train_loss = 0.74878540, grad/param norm = 2.3773e-01, time/batch = 18.3928s	
19388/22950 (epoch 42.240), train_loss = 0.78908110, grad/param norm = 2.3741e-01, time/batch = 18.9786s	
19389/22950 (epoch 42.242), train_loss = 0.92046444, grad/param norm = 2.5681e-01, time/batch = 17.0957s	
19390/22950 (epoch 42.244), train_loss = 0.90843692, grad/param norm = 2.8660e-01, time/batch = 19.3866s	
19391/22950 (epoch 42.246), train_loss = 0.89881595, grad/param norm = 2.6053e-01, time/batch = 19.6045s	
19392/22950 (epoch 42.248), train_loss = 0.80226451, grad/param norm = 2.7965e-01, time/batch = 17.6125s	
19393/22950 (epoch 42.251), train_loss = 0.73220250, grad/param norm = 2.2358e-01, time/batch = 19.7886s	
19394/22950 (epoch 42.253), train_loss = 0.71887968, grad/param norm = 2.7408e-01, time/batch = 19.5356s	
19395/22950 (epoch 42.255), train_loss = 0.83777280, grad/param norm = 2.5917e-01, time/batch = 18.2052s	
19396/22950 (epoch 42.257), train_loss = 0.89544800, grad/param norm = 2.9451e-01, time/batch = 18.1483s	
19397/22950 (epoch 42.259), train_loss = 0.69025413, grad/param norm = 2.3530e-01, time/batch = 18.8867s	
19398/22950 (epoch 42.261), train_loss = 0.72133214, grad/param norm = 2.5926e-01, time/batch = 18.2050s	
19399/22950 (epoch 42.264), train_loss = 0.70581310, grad/param norm = 2.2948e-01, time/batch = 20.1113s	
19400/22950 (epoch 42.266), train_loss = 0.76198005, grad/param norm = 2.8873e-01, time/batch = 16.7004s	
19401/22950 (epoch 42.268), train_loss = 0.79168555, grad/param norm = 3.0523e-01, time/batch = 17.7961s	
19402/22950 (epoch 42.270), train_loss = 0.79004582, grad/param norm = 2.6650e-01, time/batch = 18.4586s	
19403/22950 (epoch 42.272), train_loss = 0.80287216, grad/param norm = 3.2104e-01, time/batch = 19.2833s	
19404/22950 (epoch 42.275), train_loss = 0.77863393, grad/param norm = 3.8860e-01, time/batch = 20.2790s	
19405/22950 (epoch 42.277), train_loss = 0.67595201, grad/param norm = 2.5300e-01, time/batch = 18.2108s	
19406/22950 (epoch 42.279), train_loss = 0.70184633, grad/param norm = 3.0351e-01, time/batch = 19.8114s	
19407/22950 (epoch 42.281), train_loss = 0.78088557, grad/param norm = 2.5208e-01, time/batch = 19.1936s	
19408/22950 (epoch 42.283), train_loss = 0.68910331, grad/param norm = 2.1171e-01, time/batch = 17.2008s	
19409/22950 (epoch 42.285), train_loss = 0.79738555, grad/param norm = 2.5033e-01, time/batch = 19.2629s	
19410/22950 (epoch 42.288), train_loss = 0.89420400, grad/param norm = 2.5904e-01, time/batch = 18.2005s	
19411/22950 (epoch 42.290), train_loss = 0.76853562, grad/param norm = 2.6194e-01, time/batch = 18.2936s	
19412/22950 (epoch 42.292), train_loss = 0.89898866, grad/param norm = 2.8311e-01, time/batch = 18.8885s	
19413/22950 (epoch 42.294), train_loss = 0.82781871, grad/param norm = 2.2748e-01, time/batch = 18.6027s	
19414/22950 (epoch 42.296), train_loss = 0.62766692, grad/param norm = 2.0357e-01, time/batch = 16.5354s	
19415/22950 (epoch 42.298), train_loss = 0.77326421, grad/param norm = 2.7206e-01, time/batch = 18.1188s	
19416/22950 (epoch 42.301), train_loss = 0.79916621, grad/param norm = 2.5182e-01, time/batch = 19.4665s	
19417/22950 (epoch 42.303), train_loss = 0.77080816, grad/param norm = 2.7947e-01, time/batch = 19.8871s	
19418/22950 (epoch 42.305), train_loss = 0.79056699, grad/param norm = 3.2114e-01, time/batch = 16.1835s	
19419/22950 (epoch 42.307), train_loss = 0.89544957, grad/param norm = 2.7291e-01, time/batch = 19.3694s	
19420/22950 (epoch 42.309), train_loss = 0.74084625, grad/param norm = 2.5785e-01, time/batch = 20.3709s	
19421/22950 (epoch 42.312), train_loss = 0.81931503, grad/param norm = 2.3055e-01, time/batch = 17.8762s	
19422/22950 (epoch 42.314), train_loss = 0.79623637, grad/param norm = 2.4117e-01, time/batch = 19.3558s	
19423/22950 (epoch 42.316), train_loss = 0.76300585, grad/param norm = 2.4472e-01, time/batch = 19.6457s	
19424/22950 (epoch 42.318), train_loss = 0.69768127, grad/param norm = 2.4279e-01, time/batch = 28.9228s	
19425/22950 (epoch 42.320), train_loss = 0.72398306, grad/param norm = 2.2220e-01, time/batch = 23.5817s	
19426/22950 (epoch 42.322), train_loss = 0.73452198, grad/param norm = 2.6028e-01, time/batch = 19.1126s	
19427/22950 (epoch 42.325), train_loss = 0.60890121, grad/param norm = 2.1943e-01, time/batch = 18.8856s	
19428/22950 (epoch 42.327), train_loss = 0.60480320, grad/param norm = 2.1201e-01, time/batch = 17.3810s	
19429/22950 (epoch 42.329), train_loss = 0.72439408, grad/param norm = 2.1959e-01, time/batch = 18.4612s	
19430/22950 (epoch 42.331), train_loss = 0.68859833, grad/param norm = 2.4138e-01, time/batch = 17.2736s	
19431/22950 (epoch 42.333), train_loss = 0.69825884, grad/param norm = 2.3970e-01, time/batch = 19.8618s	
19432/22950 (epoch 42.336), train_loss = 0.75468749, grad/param norm = 2.8064e-01, time/batch = 16.0964s	
19433/22950 (epoch 42.338), train_loss = 0.79692018, grad/param norm = 2.3424e-01, time/batch = 17.4469s	
19434/22950 (epoch 42.340), train_loss = 0.73927225, grad/param norm = 2.6835e-01, time/batch = 20.2803s	
19435/22950 (epoch 42.342), train_loss = 0.92869782, grad/param norm = 2.6534e-01, time/batch = 19.0370s	
19436/22950 (epoch 42.344), train_loss = 0.75484595, grad/param norm = 2.6954e-01, time/batch = 18.6976s	
19437/22950 (epoch 42.346), train_loss = 0.89283636, grad/param norm = 3.5595e-01, time/batch = 19.1306s	
19438/22950 (epoch 42.349), train_loss = 0.77650534, grad/param norm = 2.1929e-01, time/batch = 19.8809s	
19439/22950 (epoch 42.351), train_loss = 0.79732250, grad/param norm = 2.3956e-01, time/batch = 18.1201s	
19440/22950 (epoch 42.353), train_loss = 0.80300601, grad/param norm = 2.8723e-01, time/batch = 18.3046s	
19441/22950 (epoch 42.355), train_loss = 0.85104991, grad/param norm = 2.6168e-01, time/batch = 18.1345s	
19442/22950 (epoch 42.357), train_loss = 0.73634917, grad/param norm = 3.3950e-01, time/batch = 19.4405s	
19443/22950 (epoch 42.359), train_loss = 0.79336789, grad/param norm = 2.6549e-01, time/batch = 17.9569s	
19444/22950 (epoch 42.362), train_loss = 0.82564022, grad/param norm = 2.6363e-01, time/batch = 20.1241s	
19445/22950 (epoch 42.364), train_loss = 0.80397996, grad/param norm = 3.4564e-01, time/batch = 18.2915s	
19446/22950 (epoch 42.366), train_loss = 0.79692495, grad/param norm = 2.4935e-01, time/batch = 19.2740s	
19447/22950 (epoch 42.368), train_loss = 0.80825642, grad/param norm = 2.6229e-01, time/batch = 17.9490s	
19448/22950 (epoch 42.370), train_loss = 0.75750801, grad/param norm = 2.5912e-01, time/batch = 20.4629s	
19449/22950 (epoch 42.373), train_loss = 0.73143998, grad/param norm = 2.4304e-01, time/batch = 17.8630s	
19450/22950 (epoch 42.375), train_loss = 0.86947805, grad/param norm = 3.1872e-01, time/batch = 17.7146s	
19451/22950 (epoch 42.377), train_loss = 0.73654499, grad/param norm = 3.1047e-01, time/batch = 18.9348s	
19452/22950 (epoch 42.379), train_loss = 0.79396622, grad/param norm = 2.9800e-01, time/batch = 17.2996s	
19453/22950 (epoch 42.381), train_loss = 0.69616298, grad/param norm = 2.3885e-01, time/batch = 18.7271s	
19454/22950 (epoch 42.383), train_loss = 0.76238884, grad/param norm = 2.5114e-01, time/batch = 19.3848s	
19455/22950 (epoch 42.386), train_loss = 0.73778857, grad/param norm = 2.9491e-01, time/batch = 18.6146s	
19456/22950 (epoch 42.388), train_loss = 0.81493108, grad/param norm = 2.8744e-01, time/batch = 20.0240s	
19457/22950 (epoch 42.390), train_loss = 0.69109179, grad/param norm = 2.5447e-01, time/batch = 19.2801s	
19458/22950 (epoch 42.392), train_loss = 0.72666780, grad/param norm = 2.5214e-01, time/batch = 18.8756s	
19459/22950 (epoch 42.394), train_loss = 0.74872267, grad/param norm = 2.4289e-01, time/batch = 18.7958s	
19460/22950 (epoch 42.397), train_loss = 0.89443752, grad/param norm = 2.5681e-01, time/batch = 18.9613s	
19461/22950 (epoch 42.399), train_loss = 0.84894139, grad/param norm = 2.7560e-01, time/batch = 17.9320s	
19462/22950 (epoch 42.401), train_loss = 0.93351469, grad/param norm = 4.0716e-01, time/batch = 18.1248s	
19463/22950 (epoch 42.403), train_loss = 0.78805068, grad/param norm = 3.1552e-01, time/batch = 19.2074s	
19464/22950 (epoch 42.405), train_loss = 0.92624525, grad/param norm = 3.4125e-01, time/batch = 20.1381s	
19465/22950 (epoch 42.407), train_loss = 0.94638290, grad/param norm = 2.3547e-01, time/batch = 18.8788s	
19466/22950 (epoch 42.410), train_loss = 0.82727567, grad/param norm = 2.5713e-01, time/batch = 18.7068s	
19467/22950 (epoch 42.412), train_loss = 0.76578313, grad/param norm = 2.8448e-01, time/batch = 18.7778s	
19468/22950 (epoch 42.414), train_loss = 0.89788548, grad/param norm = 2.7062e-01, time/batch = 16.7739s	
19469/22950 (epoch 42.416), train_loss = 0.83841553, grad/param norm = 2.9168e-01, time/batch = 19.8809s	
19470/22950 (epoch 42.418), train_loss = 0.82039033, grad/param norm = 2.9285e-01, time/batch = 18.7931s	
19471/22950 (epoch 42.420), train_loss = 0.84912006, grad/param norm = 2.6783e-01, time/batch = 16.3384s	
19472/22950 (epoch 42.423), train_loss = 0.75051295, grad/param norm = 2.7507e-01, time/batch = 19.8807s	
19473/22950 (epoch 42.425), train_loss = 0.77630210, grad/param norm = 2.6983e-01, time/batch = 17.9598s	
19474/22950 (epoch 42.427), train_loss = 0.81436972, grad/param norm = 3.0030e-01, time/batch = 19.1271s	
19475/22950 (epoch 42.429), train_loss = 0.82533022, grad/param norm = 2.4712e-01, time/batch = 19.9519s	
19476/22950 (epoch 42.431), train_loss = 0.85171425, grad/param norm = 2.5726e-01, time/batch = 18.8790s	
19477/22950 (epoch 42.434), train_loss = 0.79829490, grad/param norm = 2.5825e-01, time/batch = 17.1250s	
19478/22950 (epoch 42.436), train_loss = 0.89518666, grad/param norm = 4.0587e-01, time/batch = 17.9610s	
19479/22950 (epoch 42.438), train_loss = 0.79666157, grad/param norm = 2.7092e-01, time/batch = 18.8953s	
19480/22950 (epoch 42.440), train_loss = 0.89818043, grad/param norm = 2.6003e-01, time/batch = 18.7843s	
19481/22950 (epoch 42.442), train_loss = 0.93571468, grad/param norm = 2.9580e-01, time/batch = 16.6987s	
19482/22950 (epoch 42.444), train_loss = 0.84298821, grad/param norm = 3.1635e-01, time/batch = 19.4677s	
19483/22950 (epoch 42.447), train_loss = 0.95377923, grad/param norm = 3.0856e-01, time/batch = 16.0437s	
19484/22950 (epoch 42.449), train_loss = 0.71957864, grad/param norm = 2.2526e-01, time/batch = 17.6322s	
19485/22950 (epoch 42.451), train_loss = 0.81208868, grad/param norm = 2.7125e-01, time/batch = 20.2097s	
19486/22950 (epoch 42.453), train_loss = 0.82672401, grad/param norm = 2.5875e-01, time/batch = 18.9811s	
19487/22950 (epoch 42.455), train_loss = 0.80376003, grad/param norm = 2.2781e-01, time/batch = 19.0180s	
19488/22950 (epoch 42.458), train_loss = 0.79485781, grad/param norm = 2.7949e-01, time/batch = 18.2868s	
19489/22950 (epoch 42.460), train_loss = 0.86330649, grad/param norm = 2.9130e-01, time/batch = 18.8829s	
19490/22950 (epoch 42.462), train_loss = 0.85908951, grad/param norm = 2.5155e-01, time/batch = 20.1085s	
19491/22950 (epoch 42.464), train_loss = 0.76423420, grad/param norm = 2.4658e-01, time/batch = 16.4885s	
19492/22950 (epoch 42.466), train_loss = 0.89215612, grad/param norm = 2.8496e-01, time/batch = 18.8712s	
19493/22950 (epoch 42.468), train_loss = 0.85085134, grad/param norm = 2.6934e-01, time/batch = 18.9518s	
19494/22950 (epoch 42.471), train_loss = 0.83920302, grad/param norm = 2.8299e-01, time/batch = 18.3637s	
19495/22950 (epoch 42.473), train_loss = 0.84551936, grad/param norm = 2.6802e-01, time/batch = 17.8681s	
19496/22950 (epoch 42.475), train_loss = 0.96536475, grad/param norm = 2.7901e-01, time/batch = 18.6089s	
19497/22950 (epoch 42.477), train_loss = 0.78702692, grad/param norm = 2.7838e-01, time/batch = 16.3534s	
19498/22950 (epoch 42.479), train_loss = 0.71930476, grad/param norm = 2.3880e-01, time/batch = 18.4491s	
19499/22950 (epoch 42.481), train_loss = 0.87876064, grad/param norm = 3.1062e-01, time/batch = 19.8652s	
19500/22950 (epoch 42.484), train_loss = 0.84903189, grad/param norm = 3.4705e-01, time/batch = 18.6149s	
19501/22950 (epoch 42.486), train_loss = 0.69280688, grad/param norm = 2.4065e-01, time/batch = 19.3891s	
19502/22950 (epoch 42.488), train_loss = 0.72028045, grad/param norm = 3.0513e-01, time/batch = 20.1862s	
19503/22950 (epoch 42.490), train_loss = 0.66684862, grad/param norm = 2.3490e-01, time/batch = 18.3702s	
19504/22950 (epoch 42.492), train_loss = 0.77441209, grad/param norm = 2.3459e-01, time/batch = 19.0123s	
19505/22950 (epoch 42.495), train_loss = 0.74888904, grad/param norm = 2.4618e-01, time/batch = 18.6180s	
19506/22950 (epoch 42.497), train_loss = 0.82287131, grad/param norm = 2.8244e-01, time/batch = 19.5802s	
19507/22950 (epoch 42.499), train_loss = 0.91394481, grad/param norm = 2.6671e-01, time/batch = 17.9343s	
19508/22950 (epoch 42.501), train_loss = 0.80269702, grad/param norm = 2.4605e-01, time/batch = 17.6166s	
19509/22950 (epoch 42.503), train_loss = 0.92732038, grad/param norm = 2.8493e-01, time/batch = 18.7788s	
19510/22950 (epoch 42.505), train_loss = 0.69220440, grad/param norm = 2.7629e-01, time/batch = 17.0169s	
19511/22950 (epoch 42.508), train_loss = 0.85736543, grad/param norm = 2.4990e-01, time/batch = 18.9441s	
19512/22950 (epoch 42.510), train_loss = 0.76451495, grad/param norm = 2.3843e-01, time/batch = 16.0253s	
19513/22950 (epoch 42.512), train_loss = 0.67506981, grad/param norm = 2.3810e-01, time/batch = 18.4514s	
19514/22950 (epoch 42.514), train_loss = 0.77435337, grad/param norm = 2.3251e-01, time/batch = 18.0988s	
19515/22950 (epoch 42.516), train_loss = 0.80048590, grad/param norm = 2.3944e-01, time/batch = 18.5407s	
19516/22950 (epoch 42.519), train_loss = 0.81455881, grad/param norm = 2.5840e-01, time/batch = 19.6193s	
19517/22950 (epoch 42.521), train_loss = 0.80498551, grad/param norm = 2.6181e-01, time/batch = 19.7899s	
19518/22950 (epoch 42.523), train_loss = 0.62933244, grad/param norm = 1.9824e-01, time/batch = 18.9670s	
19519/22950 (epoch 42.525), train_loss = 0.72329141, grad/param norm = 2.9474e-01, time/batch = 18.8827s	
19520/22950 (epoch 42.527), train_loss = 0.69745171, grad/param norm = 2.2343e-01, time/batch = 17.2877s	
19521/22950 (epoch 42.529), train_loss = 0.79067091, grad/param norm = 2.3964e-01, time/batch = 18.9605s	
19522/22950 (epoch 42.532), train_loss = 0.77335117, grad/param norm = 2.4499e-01, time/batch = 18.6203s	
19523/22950 (epoch 42.534), train_loss = 0.80223326, grad/param norm = 2.2662e-01, time/batch = 18.0466s	
19524/22950 (epoch 42.536), train_loss = 0.84926545, grad/param norm = 4.1116e-01, time/batch = 17.5685s	
19525/22950 (epoch 42.538), train_loss = 0.79536330, grad/param norm = 2.6395e-01, time/batch = 19.1270s	
19526/22950 (epoch 42.540), train_loss = 0.83023538, grad/param norm = 2.6228e-01, time/batch = 17.5217s	
19527/22950 (epoch 42.542), train_loss = 0.94664240, grad/param norm = 3.0860e-01, time/batch = 20.0443s	
19528/22950 (epoch 42.545), train_loss = 0.79989476, grad/param norm = 2.3549e-01, time/batch = 18.9578s	
19529/22950 (epoch 42.547), train_loss = 0.76799091, grad/param norm = 2.2506e-01, time/batch = 17.3805s	
19530/22950 (epoch 42.549), train_loss = 0.74082722, grad/param norm = 2.5564e-01, time/batch = 19.5471s	
19531/22950 (epoch 42.551), train_loss = 0.76380358, grad/param norm = 2.5973e-01, time/batch = 18.7991s	
19532/22950 (epoch 42.553), train_loss = 0.74960402, grad/param norm = 2.7873e-01, time/batch = 18.7846s	
19533/22950 (epoch 42.556), train_loss = 0.83888172, grad/param norm = 2.6649e-01, time/batch = 20.4263s	
19534/22950 (epoch 42.558), train_loss = 0.68003403, grad/param norm = 2.6623e-01, time/batch = 17.8905s	
19535/22950 (epoch 42.560), train_loss = 0.76683075, grad/param norm = 3.2779e-01, time/batch = 18.2093s	
19536/22950 (epoch 42.562), train_loss = 0.74304492, grad/param norm = 2.3202e-01, time/batch = 19.0143s	
19537/22950 (epoch 42.564), train_loss = 0.82431931, grad/param norm = 2.8236e-01, time/batch = 16.6916s	
19538/22950 (epoch 42.566), train_loss = 0.83185100, grad/param norm = 2.7794e-01, time/batch = 19.2964s	
19539/22950 (epoch 42.569), train_loss = 0.78148683, grad/param norm = 2.6530e-01, time/batch = 18.7811s	
19540/22950 (epoch 42.571), train_loss = 0.75727416, grad/param norm = 2.8374e-01, time/batch = 19.2118s	
19541/22950 (epoch 42.573), train_loss = 0.76728641, grad/param norm = 2.7239e-01, time/batch = 19.8731s	
19542/22950 (epoch 42.575), train_loss = 0.84898918, grad/param norm = 3.2512e-01, time/batch = 17.6890s	
19543/22950 (epoch 42.577), train_loss = 0.79708208, grad/param norm = 2.9470e-01, time/batch = 19.9676s	
19544/22950 (epoch 42.580), train_loss = 0.85227756, grad/param norm = 3.2922e-01, time/batch = 19.5312s	
19545/22950 (epoch 42.582), train_loss = 0.90718161, grad/param norm = 2.8352e-01, time/batch = 18.0341s	
19546/22950 (epoch 42.584), train_loss = 0.70198426, grad/param norm = 3.5547e-01, time/batch = 19.4526s	
19547/22950 (epoch 42.586), train_loss = 0.75103567, grad/param norm = 2.7880e-01, time/batch = 19.8765s	
19548/22950 (epoch 42.588), train_loss = 0.91272114, grad/param norm = 3.2721e-01, time/batch = 18.1030s	
19549/22950 (epoch 42.590), train_loss = 0.88007484, grad/param norm = 2.7702e-01, time/batch = 19.7932s	
19550/22950 (epoch 42.593), train_loss = 0.76601361, grad/param norm = 2.3466e-01, time/batch = 18.3051s	
19551/22950 (epoch 42.595), train_loss = 0.73855169, grad/param norm = 3.2859e-01, time/batch = 19.4385s	
19552/22950 (epoch 42.597), train_loss = 0.83384837, grad/param norm = 2.7056e-01, time/batch = 19.1117s	
19553/22950 (epoch 42.599), train_loss = 0.81819923, grad/param norm = 3.4217e-01, time/batch = 18.0598s	
19554/22950 (epoch 42.601), train_loss = 0.86599969, grad/param norm = 2.5264e-01, time/batch = 18.9700s	
19555/22950 (epoch 42.603), train_loss = 0.92191647, grad/param norm = 2.9054e-01, time/batch = 17.6180s	
19556/22950 (epoch 42.606), train_loss = 0.78103949, grad/param norm = 2.7539e-01, time/batch = 18.7021s	
19557/22950 (epoch 42.608), train_loss = 0.76528508, grad/param norm = 2.4471e-01, time/batch = 18.3818s	
19558/22950 (epoch 42.610), train_loss = 0.77644759, grad/param norm = 2.3073e-01, time/batch = 16.8604s	
19559/22950 (epoch 42.612), train_loss = 0.82279404, grad/param norm = 2.8676e-01, time/batch = 16.2912s	
19560/22950 (epoch 42.614), train_loss = 0.92294604, grad/param norm = 3.2299e-01, time/batch = 18.0500s	
19561/22950 (epoch 42.617), train_loss = 0.80080283, grad/param norm = 2.6815e-01, time/batch = 17.7897s	
19562/22950 (epoch 42.619), train_loss = 0.72314017, grad/param norm = 2.1716e-01, time/batch = 15.7301s	
19563/22950 (epoch 42.621), train_loss = 0.86292101, grad/param norm = 2.6281e-01, time/batch = 15.7448s	
19564/22950 (epoch 42.623), train_loss = 0.84720803, grad/param norm = 2.5317e-01, time/batch = 15.1260s	
19565/22950 (epoch 42.625), train_loss = 0.77711741, grad/param norm = 2.2823e-01, time/batch = 17.1895s	
19566/22950 (epoch 42.627), train_loss = 0.75996472, grad/param norm = 2.6445e-01, time/batch = 18.1253s	
19567/22950 (epoch 42.630), train_loss = 0.69421720, grad/param norm = 2.2396e-01, time/batch = 20.2982s	
19568/22950 (epoch 42.632), train_loss = 0.75935187, grad/param norm = 3.1071e-01, time/batch = 18.6066s	
19569/22950 (epoch 42.634), train_loss = 0.81635587, grad/param norm = 2.4532e-01, time/batch = 19.6056s	
19570/22950 (epoch 42.636), train_loss = 0.80402679, grad/param norm = 2.8929e-01, time/batch = 19.2226s	
19571/22950 (epoch 42.638), train_loss = 0.79410248, grad/param norm = 2.9281e-01, time/batch = 19.1985s	
19572/22950 (epoch 42.641), train_loss = 0.77545024, grad/param norm = 2.6557e-01, time/batch = 19.6298s	
19573/22950 (epoch 42.643), train_loss = 0.83268309, grad/param norm = 3.2837e-01, time/batch = 20.0399s	
19574/22950 (epoch 42.645), train_loss = 0.77450758, grad/param norm = 2.4734e-01, time/batch = 17.2849s	
19575/22950 (epoch 42.647), train_loss = 0.77646876, grad/param norm = 2.8141e-01, time/batch = 18.5334s	
19576/22950 (epoch 42.649), train_loss = 0.71869197, grad/param norm = 2.4216e-01, time/batch = 19.9580s	
19577/22950 (epoch 42.651), train_loss = 0.88015153, grad/param norm = 3.0239e-01, time/batch = 19.4624s	
19578/22950 (epoch 42.654), train_loss = 0.69308430, grad/param norm = 2.3540e-01, time/batch = 17.4933s	
19579/22950 (epoch 42.656), train_loss = 0.83551637, grad/param norm = 3.1217e-01, time/batch = 19.5424s	
19580/22950 (epoch 42.658), train_loss = 0.69973970, grad/param norm = 2.3673e-01, time/batch = 17.9652s	
19581/22950 (epoch 42.660), train_loss = 0.63883989, grad/param norm = 2.7734e-01, time/batch = 18.0462s	
19582/22950 (epoch 42.662), train_loss = 0.67226826, grad/param norm = 2.5320e-01, time/batch = 19.7952s	
19583/22950 (epoch 42.664), train_loss = 0.76195861, grad/param norm = 2.5342e-01, time/batch = 17.3710s	
19584/22950 (epoch 42.667), train_loss = 0.78782979, grad/param norm = 2.7746e-01, time/batch = 16.6002s	
19585/22950 (epoch 42.669), train_loss = 0.78466311, grad/param norm = 2.5079e-01, time/batch = 19.1354s	
19586/22950 (epoch 42.671), train_loss = 0.77789010, grad/param norm = 3.4190e-01, time/batch = 17.1357s	
19587/22950 (epoch 42.673), train_loss = 0.73393422, grad/param norm = 2.9154e-01, time/batch = 17.2171s	
19588/22950 (epoch 42.675), train_loss = 0.80567544, grad/param norm = 2.7419e-01, time/batch = 16.0753s	
19589/22950 (epoch 42.678), train_loss = 0.77339401, grad/param norm = 2.7962e-01, time/batch = 17.9708s	
19590/22950 (epoch 42.680), train_loss = 0.83487640, grad/param norm = 2.5081e-01, time/batch = 18.5460s	
19591/22950 (epoch 42.682), train_loss = 0.76784008, grad/param norm = 2.6498e-01, time/batch = 17.8617s	
19592/22950 (epoch 42.684), train_loss = 0.88728395, grad/param norm = 2.9804e-01, time/batch = 19.2102s	
19593/22950 (epoch 42.686), train_loss = 0.89137316, grad/param norm = 2.5957e-01, time/batch = 19.5422s	
19594/22950 (epoch 42.688), train_loss = 0.80067907, grad/param norm = 2.7695e-01, time/batch = 17.8757s	
19595/22950 (epoch 42.691), train_loss = 0.77448575, grad/param norm = 2.6888e-01, time/batch = 18.9477s	
19596/22950 (epoch 42.693), train_loss = 0.71624146, grad/param norm = 2.7580e-01, time/batch = 17.6368s	
19597/22950 (epoch 42.695), train_loss = 0.89424069, grad/param norm = 3.2339e-01, time/batch = 19.4543s	
19598/22950 (epoch 42.697), train_loss = 0.82622594, grad/param norm = 3.1221e-01, time/batch = 17.1832s	
19599/22950 (epoch 42.699), train_loss = 0.83514864, grad/param norm = 2.8339e-01, time/batch = 18.0457s	
19600/22950 (epoch 42.702), train_loss = 0.86199605, grad/param norm = 2.8814e-01, time/batch = 20.2131s	
19601/22950 (epoch 42.704), train_loss = 0.95926069, grad/param norm = 2.9929e-01, time/batch = 18.6972s	
19602/22950 (epoch 42.706), train_loss = 0.86931404, grad/param norm = 2.8497e-01, time/batch = 18.5358s	
19603/22950 (epoch 42.708), train_loss = 0.69531168, grad/param norm = 2.8094e-01, time/batch = 19.7847s	
19604/22950 (epoch 42.710), train_loss = 0.79183991, grad/param norm = 2.5816e-01, time/batch = 18.0507s	
19605/22950 (epoch 42.712), train_loss = 0.92202828, grad/param norm = 2.9943e-01, time/batch = 18.8709s	
19606/22950 (epoch 42.715), train_loss = 0.82778700, grad/param norm = 3.0441e-01, time/batch = 18.8056s	
19607/22950 (epoch 42.717), train_loss = 0.84258767, grad/param norm = 2.4966e-01, time/batch = 17.3583s	
19608/22950 (epoch 42.719), train_loss = 0.79611553, grad/param norm = 3.5132e-01, time/batch = 19.2218s	
19609/22950 (epoch 42.721), train_loss = 0.88889061, grad/param norm = 3.3258e-01, time/batch = 18.8887s	
19610/22950 (epoch 42.723), train_loss = 0.83338904, grad/param norm = 4.0915e-01, time/batch = 18.1312s	
19611/22950 (epoch 42.725), train_loss = 0.86205226, grad/param norm = 3.3516e-01, time/batch = 19.4635s	
19612/22950 (epoch 42.728), train_loss = 0.79803876, grad/param norm = 2.8919e-01, time/batch = 20.5386s	
19613/22950 (epoch 42.730), train_loss = 0.84199213, grad/param norm = 2.9714e-01, time/batch = 17.1173s	
19614/22950 (epoch 42.732), train_loss = 0.89708055, grad/param norm = 3.5067e-01, time/batch = 20.3694s	
19615/22950 (epoch 42.734), train_loss = 0.76828177, grad/param norm = 2.6543e-01, time/batch = 19.2918s	
19616/22950 (epoch 42.736), train_loss = 0.86304560, grad/param norm = 2.8083e-01, time/batch = 20.1801s	
19617/22950 (epoch 42.739), train_loss = 0.88879952, grad/param norm = 3.4822e-01, time/batch = 28.5442s	
19618/22950 (epoch 42.741), train_loss = 0.89045930, grad/param norm = 3.0259e-01, time/batch = 18.8768s	
19619/22950 (epoch 42.743), train_loss = 0.95407350, grad/param norm = 3.7289e-01, time/batch = 17.3725s	
19620/22950 (epoch 42.745), train_loss = 1.03149525, grad/param norm = 3.5874e-01, time/batch = 19.0335s	
19621/22950 (epoch 42.747), train_loss = 0.89616784, grad/param norm = 2.8880e-01, time/batch = 18.3638s	
19622/22950 (epoch 42.749), train_loss = 0.76520396, grad/param norm = 2.6498e-01, time/batch = 16.5463s	
19623/22950 (epoch 42.752), train_loss = 0.98621565, grad/param norm = 2.9930e-01, time/batch = 18.5383s	
19624/22950 (epoch 42.754), train_loss = 0.87392312, grad/param norm = 2.9231e-01, time/batch = 19.9662s	
19625/22950 (epoch 42.756), train_loss = 0.78806128, grad/param norm = 2.6596e-01, time/batch = 19.6987s	
19626/22950 (epoch 42.758), train_loss = 0.84273105, grad/param norm = 2.4752e-01, time/batch = 17.2022s	
19627/22950 (epoch 42.760), train_loss = 0.82994030, grad/param norm = 2.8979e-01, time/batch = 19.2175s	
19628/22950 (epoch 42.763), train_loss = 0.82227897, grad/param norm = 2.4953e-01, time/batch = 20.6202s	
19629/22950 (epoch 42.765), train_loss = 0.83357733, grad/param norm = 3.0979e-01, time/batch = 19.9226s	
19630/22950 (epoch 42.767), train_loss = 1.00297050, grad/param norm = 3.0248e-01, time/batch = 18.4565s	
19631/22950 (epoch 42.769), train_loss = 0.85144789, grad/param norm = 2.7804e-01, time/batch = 19.3965s	
19632/22950 (epoch 42.771), train_loss = 0.73562495, grad/param norm = 2.9406e-01, time/batch = 18.7658s	
19633/22950 (epoch 42.773), train_loss = 0.62354236, grad/param norm = 2.3642e-01, time/batch = 19.9553s	
19634/22950 (epoch 42.776), train_loss = 0.75828441, grad/param norm = 2.4234e-01, time/batch = 17.9530s	
19635/22950 (epoch 42.778), train_loss = 0.75750810, grad/param norm = 3.1211e-01, time/batch = 17.5407s	
19636/22950 (epoch 42.780), train_loss = 0.82450249, grad/param norm = 2.9304e-01, time/batch = 18.2176s	
19637/22950 (epoch 42.782), train_loss = 0.87857055, grad/param norm = 2.8605e-01, time/batch = 17.8980s	
19638/22950 (epoch 42.784), train_loss = 0.75364741, grad/param norm = 2.5542e-01, time/batch = 16.6917s	
19639/22950 (epoch 42.786), train_loss = 0.81530221, grad/param norm = 2.6752e-01, time/batch = 15.9250s	
19640/22950 (epoch 42.789), train_loss = 0.68033984, grad/param norm = 2.6092e-01, time/batch = 19.3019s	
19641/22950 (epoch 42.791), train_loss = 0.70139772, grad/param norm = 2.5816e-01, time/batch = 19.0517s	
19642/22950 (epoch 42.793), train_loss = 0.90804479, grad/param norm = 2.6389e-01, time/batch = 18.5403s	
19643/22950 (epoch 42.795), train_loss = 0.77833067, grad/param norm = 2.6630e-01, time/batch = 20.4461s	
19644/22950 (epoch 42.797), train_loss = 0.92238421, grad/param norm = 2.8284e-01, time/batch = 19.3856s	
19645/22950 (epoch 42.800), train_loss = 0.76745099, grad/param norm = 2.5277e-01, time/batch = 19.4397s	
19646/22950 (epoch 42.802), train_loss = 0.78999324, grad/param norm = 2.6245e-01, time/batch = 19.0424s	
19647/22950 (epoch 42.804), train_loss = 0.80789016, grad/param norm = 2.8259e-01, time/batch = 19.9600s	
19648/22950 (epoch 42.806), train_loss = 0.70092075, grad/param norm = 2.2941e-01, time/batch = 16.7361s	
19649/22950 (epoch 42.808), train_loss = 0.83336932, grad/param norm = 2.2258e-01, time/batch = 18.9667s	
19650/22950 (epoch 42.810), train_loss = 0.77497944, grad/param norm = 2.7924e-01, time/batch = 17.5532s	
19651/22950 (epoch 42.813), train_loss = 0.67830838, grad/param norm = 2.5587e-01, time/batch = 18.8798s	
19652/22950 (epoch 42.815), train_loss = 0.63829125, grad/param norm = 3.3615e-01, time/batch = 18.8834s	
19653/22950 (epoch 42.817), train_loss = 0.72336106, grad/param norm = 2.3749e-01, time/batch = 16.9512s	
19654/22950 (epoch 42.819), train_loss = 0.75275463, grad/param norm = 2.5428e-01, time/batch = 17.0952s	
19655/22950 (epoch 42.821), train_loss = 0.76359962, grad/param norm = 2.4559e-01, time/batch = 19.2730s	
19656/22950 (epoch 42.824), train_loss = 0.82185519, grad/param norm = 2.6215e-01, time/batch = 19.3768s	
19657/22950 (epoch 42.826), train_loss = 0.83558736, grad/param norm = 2.8706e-01, time/batch = 18.7986s	
19658/22950 (epoch 42.828), train_loss = 0.74604956, grad/param norm = 2.9362e-01, time/batch = 18.4637s	
19659/22950 (epoch 42.830), train_loss = 0.75298223, grad/param norm = 2.5661e-01, time/batch = 18.9648s	
19660/22950 (epoch 42.832), train_loss = 0.81412993, grad/param norm = 2.7595e-01, time/batch = 19.5577s	
19661/22950 (epoch 42.834), train_loss = 0.64039755, grad/param norm = 2.5282e-01, time/batch = 18.1225s	
19662/22950 (epoch 42.837), train_loss = 0.81820106, grad/param norm = 2.9647e-01, time/batch = 18.7215s	
19663/22950 (epoch 42.839), train_loss = 0.66839788, grad/param norm = 2.4372e-01, time/batch = 19.2069s	
19664/22950 (epoch 42.841), train_loss = 0.76961536, grad/param norm = 2.3067e-01, time/batch = 17.3296s	
19665/22950 (epoch 42.843), train_loss = 0.76126992, grad/param norm = 2.5850e-01, time/batch = 18.9633s	
19666/22950 (epoch 42.845), train_loss = 0.80028166, grad/param norm = 4.6884e-01, time/batch = 17.3710s	
19667/22950 (epoch 42.847), train_loss = 0.82699154, grad/param norm = 2.8897e-01, time/batch = 15.6096s	
19668/22950 (epoch 42.850), train_loss = 0.89006221, grad/param norm = 2.7995e-01, time/batch = 19.7987s	
19669/22950 (epoch 42.852), train_loss = 0.84372896, grad/param norm = 2.7709e-01, time/batch = 18.1544s	
19670/22950 (epoch 42.854), train_loss = 0.80180948, grad/param norm = 2.5216e-01, time/batch = 17.8785s	
19671/22950 (epoch 42.856), train_loss = 0.90118569, grad/param norm = 3.2492e-01, time/batch = 17.6280s	
19672/22950 (epoch 42.858), train_loss = 0.87288144, grad/param norm = 2.5724e-01, time/batch = 19.7098s	
19673/22950 (epoch 42.861), train_loss = 0.84197848, grad/param norm = 2.7713e-01, time/batch = 20.0487s	
19674/22950 (epoch 42.863), train_loss = 0.88625836, grad/param norm = 2.8968e-01, time/batch = 18.7792s	
19675/22950 (epoch 42.865), train_loss = 0.93705324, grad/param norm = 3.1280e-01, time/batch = 18.7056s	
19676/22950 (epoch 42.867), train_loss = 0.83941681, grad/param norm = 3.4840e-01, time/batch = 19.3053s	
19677/22950 (epoch 42.869), train_loss = 0.96775677, grad/param norm = 3.1261e-01, time/batch = 16.5315s	
19678/22950 (epoch 42.871), train_loss = 0.83711412, grad/param norm = 3.4015e-01, time/batch = 20.2964s	
19679/22950 (epoch 42.874), train_loss = 0.84451537, grad/param norm = 2.4385e-01, time/batch = 16.5128s	
19680/22950 (epoch 42.876), train_loss = 0.92554932, grad/param norm = 4.3857e-01, time/batch = 18.4518s	
19681/22950 (epoch 42.878), train_loss = 0.84513930, grad/param norm = 3.5359e-01, time/batch = 19.5227s	
19682/22950 (epoch 42.880), train_loss = 0.98639967, grad/param norm = 2.8393e-01, time/batch = 19.2152s	
19683/22950 (epoch 42.882), train_loss = 0.73557938, grad/param norm = 2.6088e-01, time/batch = 18.7777s	
19684/22950 (epoch 42.885), train_loss = 0.85112022, grad/param norm = 3.1260e-01, time/batch = 17.8099s	
19685/22950 (epoch 42.887), train_loss = 0.81048646, grad/param norm = 2.5256e-01, time/batch = 18.0434s	
19686/22950 (epoch 42.889), train_loss = 0.84456494, grad/param norm = 2.6153e-01, time/batch = 17.6271s	
19687/22950 (epoch 42.891), train_loss = 0.74168757, grad/param norm = 2.2835e-01, time/batch = 18.9454s	
19688/22950 (epoch 42.893), train_loss = 0.84238742, grad/param norm = 2.5709e-01, time/batch = 18.8056s	
19689/22950 (epoch 42.895), train_loss = 0.95650658, grad/param norm = 2.7408e-01, time/batch = 19.8075s	
19690/22950 (epoch 42.898), train_loss = 0.86211022, grad/param norm = 2.3661e-01, time/batch = 17.2826s	
19691/22950 (epoch 42.900), train_loss = 0.77867736, grad/param norm = 2.7520e-01, time/batch = 17.2458s	
19692/22950 (epoch 42.902), train_loss = 0.81987458, grad/param norm = 2.7613e-01, time/batch = 20.1378s	
19693/22950 (epoch 42.904), train_loss = 0.81659786, grad/param norm = 2.7150e-01, time/batch = 17.2973s	
19694/22950 (epoch 42.906), train_loss = 0.83274301, grad/param norm = 2.7427e-01, time/batch = 19.4561s	
19695/22950 (epoch 42.908), train_loss = 0.72518833, grad/param norm = 2.5049e-01, time/batch = 19.9538s	
19696/22950 (epoch 42.911), train_loss = 0.66415125, grad/param norm = 2.3740e-01, time/batch = 18.7798s	
19697/22950 (epoch 42.913), train_loss = 0.81467637, grad/param norm = 2.6941e-01, time/batch = 1.5750s	
19698/22950 (epoch 42.915), train_loss = 0.92274502, grad/param norm = 2.9255e-01, time/batch = 0.6894s	
19699/22950 (epoch 42.917), train_loss = 0.72656114, grad/param norm = 2.4012e-01, time/batch = 0.6896s	
19700/22950 (epoch 42.919), train_loss = 0.85202125, grad/param norm = 2.8320e-01, time/batch = 0.6869s	
19701/22950 (epoch 42.922), train_loss = 0.80934049, grad/param norm = 2.5226e-01, time/batch = 0.6889s	
19702/22950 (epoch 42.924), train_loss = 0.86114082, grad/param norm = 2.7875e-01, time/batch = 0.6898s	
19703/22950 (epoch 42.926), train_loss = 0.69406971, grad/param norm = 2.8861e-01, time/batch = 0.6874s	
19704/22950 (epoch 42.928), train_loss = 0.73698898, grad/param norm = 2.9821e-01, time/batch = 0.9441s	
19705/22950 (epoch 42.930), train_loss = 0.74127688, grad/param norm = 2.4772e-01, time/batch = 1.0451s	
19706/22950 (epoch 42.932), train_loss = 0.67308875, grad/param norm = 2.2090e-01, time/batch = 1.0128s	
19707/22950 (epoch 42.935), train_loss = 0.86201645, grad/param norm = 2.5716e-01, time/batch = 1.0103s	
19708/22950 (epoch 42.937), train_loss = 0.80450101, grad/param norm = 2.9786e-01, time/batch = 1.0165s	
19709/22950 (epoch 42.939), train_loss = 0.74424626, grad/param norm = 2.5416e-01, time/batch = 1.7694s	
19710/22950 (epoch 42.941), train_loss = 0.78298238, grad/param norm = 2.4760e-01, time/batch = 1.9450s	
19711/22950 (epoch 42.943), train_loss = 0.81064901, grad/param norm = 2.9868e-01, time/batch = 7.2533s	
19712/22950 (epoch 42.946), train_loss = 0.67071138, grad/param norm = 2.7463e-01, time/batch = 18.2047s	
19713/22950 (epoch 42.948), train_loss = 0.90893326, grad/param norm = 3.1156e-01, time/batch = 17.7179s	
19714/22950 (epoch 42.950), train_loss = 0.80444595, grad/param norm = 2.6078e-01, time/batch = 19.3774s	
19715/22950 (epoch 42.952), train_loss = 0.84434821, grad/param norm = 2.5436e-01, time/batch = 19.9417s	
19716/22950 (epoch 42.954), train_loss = 0.84035505, grad/param norm = 2.6545e-01, time/batch = 16.4572s	
19717/22950 (epoch 42.956), train_loss = 0.75459249, grad/param norm = 3.0182e-01, time/batch = 19.3659s	
19718/22950 (epoch 42.959), train_loss = 0.72605346, grad/param norm = 2.3096e-01, time/batch = 19.2330s	
19719/22950 (epoch 42.961), train_loss = 0.79806598, grad/param norm = 2.6199e-01, time/batch = 19.9527s	
19720/22950 (epoch 42.963), train_loss = 0.79208169, grad/param norm = 2.4448e-01, time/batch = 19.6190s	
19721/22950 (epoch 42.965), train_loss = 0.88591977, grad/param norm = 2.9872e-01, time/batch = 17.7032s	
19722/22950 (epoch 42.967), train_loss = 0.75015165, grad/param norm = 2.4994e-01, time/batch = 19.1465s	
19723/22950 (epoch 42.969), train_loss = 0.70806983, grad/param norm = 2.6916e-01, time/batch = 17.9373s	
19724/22950 (epoch 42.972), train_loss = 0.77434260, grad/param norm = 2.5078e-01, time/batch = 20.2874s	
19725/22950 (epoch 42.974), train_loss = 0.74647119, grad/param norm = 2.4601e-01, time/batch = 19.4537s	
19726/22950 (epoch 42.976), train_loss = 0.80192747, grad/param norm = 2.4849e-01, time/batch = 15.9979s	
19727/22950 (epoch 42.978), train_loss = 0.73073869, grad/param norm = 2.7497e-01, time/batch = 19.2875s	
19728/22950 (epoch 42.980), train_loss = 0.73788239, grad/param norm = 2.4082e-01, time/batch = 18.7171s	
19729/22950 (epoch 42.983), train_loss = 0.86147168, grad/param norm = 2.5326e-01, time/batch = 18.3761s	
19730/22950 (epoch 42.985), train_loss = 0.73639526, grad/param norm = 2.4853e-01, time/batch = 20.0273s	
19731/22950 (epoch 42.987), train_loss = 0.73284586, grad/param norm = 2.3920e-01, time/batch = 19.6289s	
19732/22950 (epoch 42.989), train_loss = 0.80517365, grad/param norm = 2.7941e-01, time/batch = 16.2011s	
19733/22950 (epoch 42.991), train_loss = 0.69327777, grad/param norm = 2.5047e-01, time/batch = 20.4582s	
19734/22950 (epoch 42.993), train_loss = 0.79962809, grad/param norm = 2.4939e-01, time/batch = 19.2197s	
19735/22950 (epoch 42.996), train_loss = 0.77512641, grad/param norm = 2.8780e-01, time/batch = 18.5112s	
19736/22950 (epoch 42.998), train_loss = 0.70671946, grad/param norm = 2.9907e-01, time/batch = 19.7954s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
19737/22950 (epoch 43.000), train_loss = 0.68637188, grad/param norm = 2.5719e-01, time/batch = 19.3667s	
19738/22950 (epoch 43.002), train_loss = 0.96325167, grad/param norm = 3.3877e-01, time/batch = 19.5509s	
19739/22950 (epoch 43.004), train_loss = 0.84863821, grad/param norm = 2.6677e-01, time/batch = 16.6703s	
19740/22950 (epoch 43.007), train_loss = 0.78534543, grad/param norm = 2.7379e-01, time/batch = 19.0368s	
19741/22950 (epoch 43.009), train_loss = 0.93700236, grad/param norm = 3.2331e-01, time/batch = 20.7196s	
19742/22950 (epoch 43.011), train_loss = 0.68078519, grad/param norm = 2.6560e-01, time/batch = 18.2709s	
19743/22950 (epoch 43.013), train_loss = 0.75416114, grad/param norm = 2.5392e-01, time/batch = 19.1324s	
19744/22950 (epoch 43.015), train_loss = 0.81896207, grad/param norm = 2.9334e-01, time/batch = 19.1975s	
19745/22950 (epoch 43.017), train_loss = 0.81772840, grad/param norm = 2.8151e-01, time/batch = 17.3796s	
19746/22950 (epoch 43.020), train_loss = 0.83211157, grad/param norm = 2.5168e-01, time/batch = 19.1181s	
19747/22950 (epoch 43.022), train_loss = 0.72471995, grad/param norm = 2.5947e-01, time/batch = 19.0511s	
19748/22950 (epoch 43.024), train_loss = 0.76594338, grad/param norm = 2.6425e-01, time/batch = 17.1229s	
19749/22950 (epoch 43.026), train_loss = 0.82521170, grad/param norm = 2.4968e-01, time/batch = 17.0046s	
19750/22950 (epoch 43.028), train_loss = 0.84319549, grad/param norm = 2.4469e-01, time/batch = 18.4600s	
19751/22950 (epoch 43.031), train_loss = 0.74861427, grad/param norm = 2.4373e-01, time/batch = 19.0235s	
19752/22950 (epoch 43.033), train_loss = 0.89950955, grad/param norm = 3.4268e-01, time/batch = 19.7904s	
19753/22950 (epoch 43.035), train_loss = 0.79117083, grad/param norm = 2.5765e-01, time/batch = 19.9574s	
19754/22950 (epoch 43.037), train_loss = 0.80144801, grad/param norm = 2.6544e-01, time/batch = 17.7925s	
19755/22950 (epoch 43.039), train_loss = 0.77338659, grad/param norm = 2.3127e-01, time/batch = 18.7863s	
19756/22950 (epoch 43.041), train_loss = 0.73082970, grad/param norm = 2.7758e-01, time/batch = 18.5589s	
19757/22950 (epoch 43.044), train_loss = 0.82748573, grad/param norm = 2.5840e-01, time/batch = 18.3752s	
19758/22950 (epoch 43.046), train_loss = 0.78768542, grad/param norm = 2.6948e-01, time/batch = 17.4554s	
19759/22950 (epoch 43.048), train_loss = 0.80145321, grad/param norm = 2.5133e-01, time/batch = 18.7077s	
19760/22950 (epoch 43.050), train_loss = 0.74649434, grad/param norm = 2.8016e-01, time/batch = 17.5406s	
19761/22950 (epoch 43.052), train_loss = 0.81335504, grad/param norm = 2.7140e-01, time/batch = 18.1331s	
19762/22950 (epoch 43.054), train_loss = 0.93713910, grad/param norm = 4.0630e-01, time/batch = 19.3974s	
19763/22950 (epoch 43.057), train_loss = 0.93744606, grad/param norm = 3.3485e-01, time/batch = 16.9701s	
19764/22950 (epoch 43.059), train_loss = 0.93623443, grad/param norm = 2.9457e-01, time/batch = 16.3766s	
19765/22950 (epoch 43.061), train_loss = 0.73919921, grad/param norm = 2.5155e-01, time/batch = 18.4719s	
19766/22950 (epoch 43.063), train_loss = 0.85845814, grad/param norm = 2.8146e-01, time/batch = 18.3051s	
19767/22950 (epoch 43.065), train_loss = 0.71448853, grad/param norm = 2.6396e-01, time/batch = 16.0280s	
19768/22950 (epoch 43.068), train_loss = 0.85536399, grad/param norm = 4.0070e-01, time/batch = 17.9641s	
19769/22950 (epoch 43.070), train_loss = 0.71744427, grad/param norm = 2.3503e-01, time/batch = 18.5572s	
19770/22950 (epoch 43.072), train_loss = 0.85712517, grad/param norm = 2.8320e-01, time/batch = 17.5513s	
19771/22950 (epoch 43.074), train_loss = 0.86821626, grad/param norm = 3.0986e-01, time/batch = 18.3685s	
19772/22950 (epoch 43.076), train_loss = 0.85780192, grad/param norm = 2.9210e-01, time/batch = 18.1334s	
19773/22950 (epoch 43.078), train_loss = 0.90624099, grad/param norm = 3.1938e-01, time/batch = 20.2090s	
19774/22950 (epoch 43.081), train_loss = 0.93051597, grad/param norm = 3.0466e-01, time/batch = 18.3578s	
19775/22950 (epoch 43.083), train_loss = 0.82759325, grad/param norm = 2.7823e-01, time/batch = 17.7134s	
19776/22950 (epoch 43.085), train_loss = 0.70183868, grad/param norm = 2.8476e-01, time/batch = 18.9508s	
19777/22950 (epoch 43.087), train_loss = 0.73715042, grad/param norm = 2.7264e-01, time/batch = 19.2136s	
19778/22950 (epoch 43.089), train_loss = 0.84099545, grad/param norm = 2.9290e-01, time/batch = 19.2936s	
19779/22950 (epoch 43.092), train_loss = 0.75932265, grad/param norm = 2.8175e-01, time/batch = 18.7119s	
19780/22950 (epoch 43.094), train_loss = 0.75780314, grad/param norm = 2.7598e-01, time/batch = 18.7116s	
19781/22950 (epoch 43.096), train_loss = 0.93206461, grad/param norm = 3.3000e-01, time/batch = 18.0288s	
19782/22950 (epoch 43.098), train_loss = 0.85920165, grad/param norm = 3.0711e-01, time/batch = 17.5306s	
19783/22950 (epoch 43.100), train_loss = 0.79027673, grad/param norm = 2.6142e-01, time/batch = 19.6189s	
19784/22950 (epoch 43.102), train_loss = 0.80467942, grad/param norm = 2.7537e-01, time/batch = 18.0406s	
19785/22950 (epoch 43.105), train_loss = 0.67753618, grad/param norm = 2.3816e-01, time/batch = 18.1859s	
19786/22950 (epoch 43.107), train_loss = 0.73347157, grad/param norm = 2.2240e-01, time/batch = 20.1249s	
19787/22950 (epoch 43.109), train_loss = 0.77218042, grad/param norm = 2.4763e-01, time/batch = 16.7594s	
19788/22950 (epoch 43.111), train_loss = 0.68507018, grad/param norm = 2.5478e-01, time/batch = 19.5352s	
19789/22950 (epoch 43.113), train_loss = 0.83753754, grad/param norm = 2.4751e-01, time/batch = 18.8760s	
19790/22950 (epoch 43.115), train_loss = 0.79458166, grad/param norm = 2.4889e-01, time/batch = 18.4494s	
19791/22950 (epoch 43.118), train_loss = 0.89307030, grad/param norm = 2.3153e-01, time/batch = 18.9587s	
19792/22950 (epoch 43.120), train_loss = 0.71121771, grad/param norm = 2.5231e-01, time/batch = 19.3033s	
19793/22950 (epoch 43.122), train_loss = 0.85951090, grad/param norm = 2.6123e-01, time/batch = 18.8777s	
19794/22950 (epoch 43.124), train_loss = 0.69980038, grad/param norm = 2.2097e-01, time/batch = 16.8973s	
19795/22950 (epoch 43.126), train_loss = 0.79806216, grad/param norm = 2.5882e-01, time/batch = 19.9669s	
19796/22950 (epoch 43.129), train_loss = 0.74081899, grad/param norm = 2.2250e-01, time/batch = 19.0424s	
19797/22950 (epoch 43.131), train_loss = 0.77593086, grad/param norm = 2.4226e-01, time/batch = 17.8429s	
19798/22950 (epoch 43.133), train_loss = 0.84154615, grad/param norm = 2.6032e-01, time/batch = 19.4604s	
19799/22950 (epoch 43.135), train_loss = 0.83575277, grad/param norm = 2.4095e-01, time/batch = 18.8070s	
19800/22950 (epoch 43.137), train_loss = 0.84696435, grad/param norm = 3.1509e-01, time/batch = 18.6213s	
19801/22950 (epoch 43.139), train_loss = 0.73857456, grad/param norm = 2.5825e-01, time/batch = 19.3685s	
19802/22950 (epoch 43.142), train_loss = 0.73861323, grad/param norm = 2.1283e-01, time/batch = 20.3782s	
19803/22950 (epoch 43.144), train_loss = 0.75825854, grad/param norm = 2.2168e-01, time/batch = 17.6271s	
19804/22950 (epoch 43.146), train_loss = 0.70990303, grad/param norm = 2.4042e-01, time/batch = 18.4640s	
19805/22950 (epoch 43.148), train_loss = 0.72107517, grad/param norm = 2.8021e-01, time/batch = 19.2991s	
19806/22950 (epoch 43.150), train_loss = 0.80204088, grad/param norm = 2.4527e-01, time/batch = 17.4619s	
19807/22950 (epoch 43.153), train_loss = 0.69379001, grad/param norm = 2.2299e-01, time/batch = 17.8063s	
19808/22950 (epoch 43.155), train_loss = 0.73408325, grad/param norm = 2.2168e-01, time/batch = 18.5411s	
19809/22950 (epoch 43.157), train_loss = 0.76173044, grad/param norm = 2.2337e-01, time/batch = 18.5529s	
19810/22950 (epoch 43.159), train_loss = 0.70644875, grad/param norm = 2.3445e-01, time/batch = 16.3396s	
19811/22950 (epoch 43.161), train_loss = 0.75428706, grad/param norm = 2.5597e-01, time/batch = 20.1348s	
19812/22950 (epoch 43.163), train_loss = 0.68722531, grad/param norm = 2.4119e-01, time/batch = 18.1161s	
19813/22950 (epoch 43.166), train_loss = 0.82016601, grad/param norm = 3.6065e-01, time/batch = 19.1093s	
19814/22950 (epoch 43.168), train_loss = 0.81922506, grad/param norm = 2.9809e-01, time/batch = 19.1342s	
19815/22950 (epoch 43.170), train_loss = 0.81649108, grad/param norm = 2.9540e-01, time/batch = 19.8773s	
19816/22950 (epoch 43.172), train_loss = 0.79868260, grad/param norm = 2.9157e-01, time/batch = 18.6081s	
19817/22950 (epoch 43.174), train_loss = 0.86703130, grad/param norm = 3.2222e-01, time/batch = 19.9604s	
19818/22950 (epoch 43.176), train_loss = 0.86304590, grad/param norm = 2.6993e-01, time/batch = 19.0458s	
19819/22950 (epoch 43.179), train_loss = 0.83180151, grad/param norm = 3.0250e-01, time/batch = 17.8794s	
19820/22950 (epoch 43.181), train_loss = 1.02052598, grad/param norm = 2.6782e-01, time/batch = 20.2749s	
19821/22950 (epoch 43.183), train_loss = 0.83376466, grad/param norm = 2.7156e-01, time/batch = 17.0389s	
19822/22950 (epoch 43.185), train_loss = 0.84999618, grad/param norm = 2.6387e-01, time/batch = 22.7005s	
19823/22950 (epoch 43.187), train_loss = 0.72805793, grad/param norm = 2.3066e-01, time/batch = 26.9521s	
19824/22950 (epoch 43.190), train_loss = 0.63876617, grad/param norm = 2.9520e-01, time/batch = 20.1364s	
19825/22950 (epoch 43.192), train_loss = 0.61941072, grad/param norm = 2.3799e-01, time/batch = 18.4400s	
19826/22950 (epoch 43.194), train_loss = 0.77869706, grad/param norm = 2.8487e-01, time/batch = 17.3714s	
19827/22950 (epoch 43.196), train_loss = 0.58923576, grad/param norm = 3.2028e-01, time/batch = 19.3044s	
19828/22950 (epoch 43.198), train_loss = 0.81592932, grad/param norm = 3.0377e-01, time/batch = 17.0196s	
19829/22950 (epoch 43.200), train_loss = 0.73116633, grad/param norm = 2.4520e-01, time/batch = 18.9597s	
19830/22950 (epoch 43.203), train_loss = 0.67274987, grad/param norm = 2.2197e-01, time/batch = 19.0552s	
19831/22950 (epoch 43.205), train_loss = 0.74483680, grad/param norm = 2.5800e-01, time/batch = 19.1994s	
19832/22950 (epoch 43.207), train_loss = 0.80883746, grad/param norm = 2.6504e-01, time/batch = 17.9642s	
19833/22950 (epoch 43.209), train_loss = 0.77116261, grad/param norm = 3.1764e-01, time/batch = 16.2703s	
19834/22950 (epoch 43.211), train_loss = 0.65171186, grad/param norm = 2.6243e-01, time/batch = 18.0283s	
19835/22950 (epoch 43.214), train_loss = 0.73403681, grad/param norm = 2.6159e-01, time/batch = 18.1212s	
19836/22950 (epoch 43.216), train_loss = 0.87609917, grad/param norm = 2.6059e-01, time/batch = 20.1304s	
19837/22950 (epoch 43.218), train_loss = 0.77032912, grad/param norm = 2.3724e-01, time/batch = 19.3887s	
19838/22950 (epoch 43.220), train_loss = 0.85090275, grad/param norm = 2.6295e-01, time/batch = 17.9465s	
19839/22950 (epoch 43.222), train_loss = 0.87543960, grad/param norm = 3.2204e-01, time/batch = 19.6293s	
19840/22950 (epoch 43.224), train_loss = 0.77681569, grad/param norm = 2.6917e-01, time/batch = 18.1933s	
19841/22950 (epoch 43.227), train_loss = 0.84096676, grad/param norm = 2.4319e-01, time/batch = 18.1137s	
19842/22950 (epoch 43.229), train_loss = 0.89192097, grad/param norm = 2.5929e-01, time/batch = 19.5400s	
19843/22950 (epoch 43.231), train_loss = 0.62901482, grad/param norm = 2.3841e-01, time/batch = 18.7962s	
19844/22950 (epoch 43.233), train_loss = 0.74933434, grad/param norm = 2.6146e-01, time/batch = 17.3809s	
19845/22950 (epoch 43.235), train_loss = 0.91053093, grad/param norm = 2.6982e-01, time/batch = 17.3692s	
19846/22950 (epoch 43.237), train_loss = 0.73854793, grad/param norm = 2.1831e-01, time/batch = 18.1119s	
19847/22950 (epoch 43.240), train_loss = 0.79245163, grad/param norm = 2.6238e-01, time/batch = 18.4733s	
19848/22950 (epoch 43.242), train_loss = 0.91058157, grad/param norm = 2.5525e-01, time/batch = 19.3698s	
19849/22950 (epoch 43.244), train_loss = 0.90192943, grad/param norm = 2.6264e-01, time/batch = 18.4636s	
19850/22950 (epoch 43.246), train_loss = 0.89149714, grad/param norm = 2.6335e-01, time/batch = 15.8682s	
19851/22950 (epoch 43.248), train_loss = 0.80624003, grad/param norm = 3.3067e-01, time/batch = 17.2696s	
19852/22950 (epoch 43.251), train_loss = 0.74889300, grad/param norm = 2.8482e-01, time/batch = 19.1316s	
19853/22950 (epoch 43.253), train_loss = 0.72742627, grad/param norm = 3.0683e-01, time/batch = 19.1112s	
19854/22950 (epoch 43.255), train_loss = 0.81488609, grad/param norm = 2.6656e-01, time/batch = 17.5253s	
19855/22950 (epoch 43.257), train_loss = 0.87603106, grad/param norm = 2.8835e-01, time/batch = 18.1365s	
19856/22950 (epoch 43.259), train_loss = 0.65843325, grad/param norm = 2.2351e-01, time/batch = 18.8011s	
19857/22950 (epoch 43.261), train_loss = 0.69370988, grad/param norm = 2.2928e-01, time/batch = 17.6299s	
19858/22950 (epoch 43.264), train_loss = 0.70106628, grad/param norm = 2.2946e-01, time/batch = 17.7259s	
19859/22950 (epoch 43.266), train_loss = 0.74017919, grad/param norm = 2.2980e-01, time/batch = 18.7120s	
19860/22950 (epoch 43.268), train_loss = 0.77184197, grad/param norm = 2.9681e-01, time/batch = 17.7055s	
19861/22950 (epoch 43.270), train_loss = 0.76849209, grad/param norm = 2.4197e-01, time/batch = 16.0075s	
19862/22950 (epoch 43.272), train_loss = 0.80076039, grad/param norm = 3.1159e-01, time/batch = 19.1243s	
19863/22950 (epoch 43.275), train_loss = 0.76930704, grad/param norm = 2.9004e-01, time/batch = 19.3026s	
19864/22950 (epoch 43.277), train_loss = 0.66500749, grad/param norm = 2.4825e-01, time/batch = 15.6020s	
19865/22950 (epoch 43.279), train_loss = 0.69008233, grad/param norm = 2.7932e-01, time/batch = 14.9722s	
19866/22950 (epoch 43.281), train_loss = 0.75934737, grad/param norm = 2.6998e-01, time/batch = 16.4475s	
19867/22950 (epoch 43.283), train_loss = 0.67805986, grad/param norm = 2.3854e-01, time/batch = 15.2672s	
19868/22950 (epoch 43.285), train_loss = 0.78869473, grad/param norm = 2.4990e-01, time/batch = 15.2940s	
19869/22950 (epoch 43.288), train_loss = 0.87933231, grad/param norm = 2.6579e-01, time/batch = 15.3973s	
19870/22950 (epoch 43.290), train_loss = 0.75753076, grad/param norm = 2.7771e-01, time/batch = 15.9520s	
19871/22950 (epoch 43.292), train_loss = 0.89344250, grad/param norm = 2.8973e-01, time/batch = 17.1881s	
19872/22950 (epoch 43.294), train_loss = 0.82539118, grad/param norm = 2.2424e-01, time/batch = 17.6006s	
19873/22950 (epoch 43.296), train_loss = 0.63345729, grad/param norm = 2.3767e-01, time/batch = 18.3093s	
19874/22950 (epoch 43.298), train_loss = 0.75841898, grad/param norm = 4.1435e-01, time/batch = 20.2142s	
19875/22950 (epoch 43.301), train_loss = 0.80128342, grad/param norm = 2.5219e-01, time/batch = 18.8494s	
19876/22950 (epoch 43.303), train_loss = 0.77861565, grad/param norm = 2.8701e-01, time/batch = 19.5605s	
19877/22950 (epoch 43.305), train_loss = 0.76138026, grad/param norm = 2.4295e-01, time/batch = 18.7815s	
19878/22950 (epoch 43.307), train_loss = 0.90121032, grad/param norm = 2.9694e-01, time/batch = 17.6912s	
19879/22950 (epoch 43.309), train_loss = 0.73698388, grad/param norm = 2.5578e-01, time/batch = 19.1430s	
19880/22950 (epoch 43.312), train_loss = 0.82457476, grad/param norm = 2.8577e-01, time/batch = 19.2216s	
19881/22950 (epoch 43.314), train_loss = 0.77941537, grad/param norm = 2.2209e-01, time/batch = 17.7222s	
19882/22950 (epoch 43.316), train_loss = 0.76630195, grad/param norm = 2.6323e-01, time/batch = 19.2957s	
19883/22950 (epoch 43.318), train_loss = 0.68561849, grad/param norm = 1.9399e-01, time/batch = 16.7231s	
19884/22950 (epoch 43.320), train_loss = 0.73603646, grad/param norm = 2.5352e-01, time/batch = 15.5071s	
19885/22950 (epoch 43.322), train_loss = 0.72123988, grad/param norm = 2.5012e-01, time/batch = 18.0479s	
19886/22950 (epoch 43.325), train_loss = 0.61270655, grad/param norm = 2.2350e-01, time/batch = 19.1504s	
19887/22950 (epoch 43.327), train_loss = 0.60426201, grad/param norm = 2.1654e-01, time/batch = 19.3954s	
19888/22950 (epoch 43.329), train_loss = 0.71435332, grad/param norm = 2.3837e-01, time/batch = 18.0958s	
19889/22950 (epoch 43.331), train_loss = 0.67717034, grad/param norm = 2.2580e-01, time/batch = 17.8820s	
19890/22950 (epoch 43.333), train_loss = 0.70003299, grad/param norm = 2.3686e-01, time/batch = 18.3887s	
19891/22950 (epoch 43.336), train_loss = 0.75357876, grad/param norm = 2.7684e-01, time/batch = 16.8572s	
19892/22950 (epoch 43.338), train_loss = 0.79208073, grad/param norm = 2.3161e-01, time/batch = 18.3570s	
19893/22950 (epoch 43.340), train_loss = 0.74285373, grad/param norm = 2.8316e-01, time/batch = 16.3855s	
19894/22950 (epoch 43.342), train_loss = 0.92652988, grad/param norm = 2.6731e-01, time/batch = 17.0250s	
19895/22950 (epoch 43.344), train_loss = 0.75979314, grad/param norm = 2.9643e-01, time/batch = 17.8752s	
19896/22950 (epoch 43.346), train_loss = 0.86897116, grad/param norm = 3.1516e-01, time/batch = 19.0503s	
19897/22950 (epoch 43.349), train_loss = 0.77626843, grad/param norm = 2.4854e-01, time/batch = 19.6353s	
19898/22950 (epoch 43.351), train_loss = 0.80344060, grad/param norm = 2.6963e-01, time/batch = 19.0986s	
19899/22950 (epoch 43.353), train_loss = 0.77632659, grad/param norm = 2.8319e-01, time/batch = 19.9704s	
19900/22950 (epoch 43.355), train_loss = 0.83837168, grad/param norm = 2.9108e-01, time/batch = 17.8276s	
19901/22950 (epoch 43.357), train_loss = 0.72879295, grad/param norm = 2.7999e-01, time/batch = 18.2008s	
19902/22950 (epoch 43.359), train_loss = 0.78335914, grad/param norm = 2.9048e-01, time/batch = 20.6328s	
19903/22950 (epoch 43.362), train_loss = 0.82643888, grad/param norm = 2.9203e-01, time/batch = 18.5423s	
19904/22950 (epoch 43.364), train_loss = 0.81615447, grad/param norm = 3.9234e-01, time/batch = 16.7092s	
19905/22950 (epoch 43.366), train_loss = 0.79273977, grad/param norm = 2.5189e-01, time/batch = 17.0204s	
19906/22950 (epoch 43.368), train_loss = 0.81981827, grad/param norm = 3.0843e-01, time/batch = 19.3016s	
19907/22950 (epoch 43.370), train_loss = 0.77224226, grad/param norm = 2.7645e-01, time/batch = 19.3763s	
19908/22950 (epoch 43.373), train_loss = 0.72468697, grad/param norm = 2.6702e-01, time/batch = 18.9543s	
19909/22950 (epoch 43.375), train_loss = 0.86410250, grad/param norm = 2.9054e-01, time/batch = 20.7100s	
19910/22950 (epoch 43.377), train_loss = 0.71573596, grad/param norm = 2.6331e-01, time/batch = 18.0312s	
19911/22950 (epoch 43.379), train_loss = 0.77170603, grad/param norm = 2.7274e-01, time/batch = 18.8772s	
19912/22950 (epoch 43.381), train_loss = 0.68644653, grad/param norm = 2.4059e-01, time/batch = 18.7960s	
19913/22950 (epoch 43.383), train_loss = 0.75686017, grad/param norm = 3.0552e-01, time/batch = 18.3771s	
19914/22950 (epoch 43.386), train_loss = 0.72884937, grad/param norm = 2.8083e-01, time/batch = 19.2115s	
19915/22950 (epoch 43.388), train_loss = 0.80512188, grad/param norm = 2.6137e-01, time/batch = 18.0571s	
19916/22950 (epoch 43.390), train_loss = 0.68629253, grad/param norm = 2.4236e-01, time/batch = 18.8744s	
19917/22950 (epoch 43.392), train_loss = 0.72202682, grad/param norm = 2.5421e-01, time/batch = 18.1184s	
19918/22950 (epoch 43.394), train_loss = 0.73378367, grad/param norm = 2.5155e-01, time/batch = 19.5532s	
19919/22950 (epoch 43.397), train_loss = 0.86614101, grad/param norm = 2.5297e-01, time/batch = 18.5516s	
19920/22950 (epoch 43.399), train_loss = 0.84389916, grad/param norm = 2.7948e-01, time/batch = 17.7058s	
19921/22950 (epoch 43.401), train_loss = 0.91756365, grad/param norm = 3.6448e-01, time/batch = 19.0275s	
19922/22950 (epoch 43.403), train_loss = 0.79187622, grad/param norm = 2.9341e-01, time/batch = 18.9594s	
19923/22950 (epoch 43.405), train_loss = 0.90942516, grad/param norm = 3.3974e-01, time/batch = 17.7826s	
19924/22950 (epoch 43.407), train_loss = 0.94785186, grad/param norm = 2.6584e-01, time/batch = 18.7295s	
19925/22950 (epoch 43.410), train_loss = 0.81258066, grad/param norm = 2.3787e-01, time/batch = 18.1326s	
19926/22950 (epoch 43.412), train_loss = 0.76919740, grad/param norm = 2.8555e-01, time/batch = 16.7075s	
19927/22950 (epoch 43.414), train_loss = 0.88205927, grad/param norm = 2.6200e-01, time/batch = 19.3018s	
19928/22950 (epoch 43.416), train_loss = 0.79927735, grad/param norm = 2.7719e-01, time/batch = 16.1204s	
19929/22950 (epoch 43.418), train_loss = 0.78801730, grad/param norm = 2.7569e-01, time/batch = 19.0451s	
19930/22950 (epoch 43.420), train_loss = 0.84363172, grad/param norm = 3.0877e-01, time/batch = 17.3881s	
19931/22950 (epoch 43.423), train_loss = 0.73302495, grad/param norm = 2.5588e-01, time/batch = 18.3796s	
19932/22950 (epoch 43.425), train_loss = 0.76108208, grad/param norm = 2.4334e-01, time/batch = 17.3783s	
19933/22950 (epoch 43.427), train_loss = 0.79563362, grad/param norm = 2.5932e-01, time/batch = 17.7128s	
19934/22950 (epoch 43.429), train_loss = 0.82009322, grad/param norm = 2.5170e-01, time/batch = 19.2752s	
19935/22950 (epoch 43.431), train_loss = 0.85046140, grad/param norm = 2.7818e-01, time/batch = 19.2214s	
19936/22950 (epoch 43.434), train_loss = 0.78989031, grad/param norm = 2.5659e-01, time/batch = 17.3798s	
19937/22950 (epoch 43.436), train_loss = 0.86058422, grad/param norm = 3.1056e-01, time/batch = 19.1813s	
19938/22950 (epoch 43.438), train_loss = 0.78135367, grad/param norm = 2.6007e-01, time/batch = 18.6305s	
19939/22950 (epoch 43.440), train_loss = 0.89010872, grad/param norm = 2.5665e-01, time/batch = 19.6241s	
19940/22950 (epoch 43.442), train_loss = 0.93726192, grad/param norm = 2.8345e-01, time/batch = 19.0330s	
19941/22950 (epoch 43.444), train_loss = 0.83801576, grad/param norm = 3.3658e-01, time/batch = 19.4593s	
19942/22950 (epoch 43.447), train_loss = 0.92973810, grad/param norm = 2.7771e-01, time/batch = 18.2736s	
19943/22950 (epoch 43.449), train_loss = 0.72975856, grad/param norm = 2.4574e-01, time/batch = 17.9176s	
19944/22950 (epoch 43.451), train_loss = 0.82150535, grad/param norm = 3.4467e-01, time/batch = 17.4474s	
19945/22950 (epoch 43.453), train_loss = 0.81287056, grad/param norm = 2.4681e-01, time/batch = 20.0300s	
19946/22950 (epoch 43.455), train_loss = 0.79302102, grad/param norm = 2.3027e-01, time/batch = 17.7840s	
19947/22950 (epoch 43.458), train_loss = 0.79748747, grad/param norm = 2.8373e-01, time/batch = 20.0533s	
19948/22950 (epoch 43.460), train_loss = 0.83876379, grad/param norm = 2.7280e-01, time/batch = 20.7797s	
19949/22950 (epoch 43.462), train_loss = 0.84601272, grad/param norm = 3.0102e-01, time/batch = 18.5312s	
19950/22950 (epoch 43.464), train_loss = 0.75091792, grad/param norm = 2.3512e-01, time/batch = 19.7063s	
19951/22950 (epoch 43.466), train_loss = 0.88559070, grad/param norm = 2.8487e-01, time/batch = 18.5509s	
19952/22950 (epoch 43.468), train_loss = 0.85612595, grad/param norm = 3.3448e-01, time/batch = 17.5444s	
19953/22950 (epoch 43.471), train_loss = 0.83339653, grad/param norm = 2.8937e-01, time/batch = 18.8786s	
19954/22950 (epoch 43.473), train_loss = 0.83560138, grad/param norm = 2.7362e-01, time/batch = 18.9388s	
19955/22950 (epoch 43.475), train_loss = 0.96051712, grad/param norm = 2.9311e-01, time/batch = 19.0379s	
19956/22950 (epoch 43.477), train_loss = 0.77453550, grad/param norm = 2.6849e-01, time/batch = 19.0290s	
19957/22950 (epoch 43.479), train_loss = 0.71746601, grad/param norm = 2.6328e-01, time/batch = 18.3978s	
19958/22950 (epoch 43.481), train_loss = 0.88004932, grad/param norm = 2.9580e-01, time/batch = 18.2039s	
19959/22950 (epoch 43.484), train_loss = 0.84221296, grad/param norm = 2.7866e-01, time/batch = 19.1237s	
19960/22950 (epoch 43.486), train_loss = 0.69771501, grad/param norm = 2.4990e-01, time/batch = 18.9583s	
19961/22950 (epoch 43.488), train_loss = 0.72020983, grad/param norm = 2.9275e-01, time/batch = 20.4420s	
19962/22950 (epoch 43.490), train_loss = 0.66517317, grad/param norm = 2.7191e-01, time/batch = 18.6076s	
19963/22950 (epoch 43.492), train_loss = 0.76272056, grad/param norm = 2.4113e-01, time/batch = 20.4474s	
19964/22950 (epoch 43.495), train_loss = 0.73344062, grad/param norm = 2.2507e-01, time/batch = 15.9454s	
19965/22950 (epoch 43.497), train_loss = 0.82089370, grad/param norm = 2.7906e-01, time/batch = 18.1150s	
19966/22950 (epoch 43.499), train_loss = 0.90415207, grad/param norm = 2.4806e-01, time/batch = 19.7946s	
19967/22950 (epoch 43.501), train_loss = 0.78738178, grad/param norm = 2.4647e-01, time/batch = 17.7153s	
19968/22950 (epoch 43.503), train_loss = 0.89864045, grad/param norm = 2.4817e-01, time/batch = 18.1986s	
19969/22950 (epoch 43.505), train_loss = 0.67395959, grad/param norm = 2.2899e-01, time/batch = 18.8919s	
19970/22950 (epoch 43.508), train_loss = 0.84619593, grad/param norm = 2.4501e-01, time/batch = 17.7221s	
19971/22950 (epoch 43.510), train_loss = 0.76401676, grad/param norm = 2.6520e-01, time/batch = 18.2927s	
19972/22950 (epoch 43.512), train_loss = 0.68129582, grad/param norm = 2.7163e-01, time/batch = 19.1888s	
19973/22950 (epoch 43.514), train_loss = 0.75737950, grad/param norm = 2.2817e-01, time/batch = 20.5369s	
19974/22950 (epoch 43.516), train_loss = 0.79240246, grad/param norm = 2.4873e-01, time/batch = 17.8631s	
19975/22950 (epoch 43.519), train_loss = 0.79188107, grad/param norm = 2.3984e-01, time/batch = 18.7998s	
19976/22950 (epoch 43.521), train_loss = 0.78807790, grad/param norm = 2.6591e-01, time/batch = 19.6381s	
19977/22950 (epoch 43.523), train_loss = 0.63140361, grad/param norm = 2.3296e-01, time/batch = 19.3755s	
19978/22950 (epoch 43.525), train_loss = 0.70645611, grad/param norm = 2.2871e-01, time/batch = 18.8815s	
19979/22950 (epoch 43.527), train_loss = 0.69697998, grad/param norm = 2.4590e-01, time/batch = 18.3184s	
19980/22950 (epoch 43.529), train_loss = 0.79077081, grad/param norm = 2.8548e-01, time/batch = 18.0468s	
19981/22950 (epoch 43.532), train_loss = 0.77122656, grad/param norm = 2.6269e-01, time/batch = 17.5385s	
19982/22950 (epoch 43.534), train_loss = 0.79044850, grad/param norm = 2.3377e-01, time/batch = 16.7928s	
19983/22950 (epoch 43.536), train_loss = 0.82918578, grad/param norm = 3.4394e-01, time/batch = 16.9309s	
19984/22950 (epoch 43.538), train_loss = 0.76741207, grad/param norm = 2.4547e-01, time/batch = 17.2906s	
19985/22950 (epoch 43.540), train_loss = 0.82669561, grad/param norm = 2.6532e-01, time/batch = 18.9809s	
19986/22950 (epoch 43.542), train_loss = 0.94203522, grad/param norm = 2.7631e-01, time/batch = 19.2045s	
19987/22950 (epoch 43.545), train_loss = 0.78947117, grad/param norm = 2.5231e-01, time/batch = 18.0507s	
19988/22950 (epoch 43.547), train_loss = 0.77845291, grad/param norm = 2.4513e-01, time/batch = 15.9965s	
19989/22950 (epoch 43.549), train_loss = 0.73965351, grad/param norm = 2.8639e-01, time/batch = 17.3099s	
19990/22950 (epoch 43.551), train_loss = 0.75592322, grad/param norm = 2.8123e-01, time/batch = 18.7220s	
19991/22950 (epoch 43.553), train_loss = 0.74568826, grad/param norm = 2.9193e-01, time/batch = 17.1236s	
19992/22950 (epoch 43.556), train_loss = 0.82526054, grad/param norm = 2.5460e-01, time/batch = 17.2375s	
19993/22950 (epoch 43.558), train_loss = 0.65975233, grad/param norm = 2.6457e-01, time/batch = 19.6297s	
19994/22950 (epoch 43.560), train_loss = 0.73529278, grad/param norm = 2.5505e-01, time/batch = 16.8768s	
19995/22950 (epoch 43.562), train_loss = 0.74659279, grad/param norm = 2.3908e-01, time/batch = 20.0367s	
19996/22950 (epoch 43.564), train_loss = 0.80587090, grad/param norm = 2.6313e-01, time/batch = 18.8655s	
19997/22950 (epoch 43.566), train_loss = 0.81379291, grad/param norm = 2.8746e-01, time/batch = 15.7757s	
19998/22950 (epoch 43.569), train_loss = 0.77504410, grad/param norm = 2.6887e-01, time/batch = 17.8747s	
19999/22950 (epoch 43.571), train_loss = 0.73919496, grad/param norm = 2.4191e-01, time/batch = 18.3089s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch43.57_2.1228.t7	
20000/22950 (epoch 43.573), train_loss = 0.75436909, grad/param norm = 2.7762e-01, time/batch = 19.5604s	
20001/22950 (epoch 43.575), train_loss = 1.36965649, grad/param norm = 4.6581e-01, time/batch = 17.2811s	
20002/22950 (epoch 43.577), train_loss = 0.79089660, grad/param norm = 3.6770e-01, time/batch = 18.9450s	
20003/22950 (epoch 43.580), train_loss = 0.85811234, grad/param norm = 3.2963e-01, time/batch = 19.8717s	
20004/22950 (epoch 43.582), train_loss = 0.92456513, grad/param norm = 3.0536e-01, time/batch = 19.4527s	
20005/22950 (epoch 43.584), train_loss = 0.71444625, grad/param norm = 3.5820e-01, time/batch = 17.5293s	
20006/22950 (epoch 43.586), train_loss = 0.74005638, grad/param norm = 2.7000e-01, time/batch = 19.7967s	
20007/22950 (epoch 43.588), train_loss = 0.88688688, grad/param norm = 3.0740e-01, time/batch = 19.7047s	
20008/22950 (epoch 43.590), train_loss = 0.88100793, grad/param norm = 2.9075e-01, time/batch = 16.8726s	
20009/22950 (epoch 43.593), train_loss = 0.77300144, grad/param norm = 2.8901e-01, time/batch = 19.9609s	
20010/22950 (epoch 43.595), train_loss = 0.75199303, grad/param norm = 2.8333e-01, time/batch = 20.2946s	
20011/22950 (epoch 43.597), train_loss = 0.85492782, grad/param norm = 2.9810e-01, time/batch = 28.7362s	
20012/22950 (epoch 43.599), train_loss = 0.80045686, grad/param norm = 2.7828e-01, time/batch = 22.8456s	
20013/22950 (epoch 43.601), train_loss = 0.86007176, grad/param norm = 2.6128e-01, time/batch = 16.5208s	
20014/22950 (epoch 43.603), train_loss = 0.90182048, grad/param norm = 2.6452e-01, time/batch = 17.6246s	
20015/22950 (epoch 43.606), train_loss = 0.77007101, grad/param norm = 2.5178e-01, time/batch = 20.5318s	
20016/22950 (epoch 43.608), train_loss = 0.75992405, grad/param norm = 2.5295e-01, time/batch = 17.8632s	
20017/22950 (epoch 43.610), train_loss = 0.76688617, grad/param norm = 2.1496e-01, time/batch = 18.7806s	
20018/22950 (epoch 43.612), train_loss = 0.80025537, grad/param norm = 2.9937e-01, time/batch = 20.1167s	
20019/22950 (epoch 43.614), train_loss = 0.91131904, grad/param norm = 3.1077e-01, time/batch = 20.5291s	
20020/22950 (epoch 43.617), train_loss = 0.79108223, grad/param norm = 2.5041e-01, time/batch = 18.6183s	
20021/22950 (epoch 43.619), train_loss = 0.73115463, grad/param norm = 2.7596e-01, time/batch = 18.9346s	
20022/22950 (epoch 43.621), train_loss = 0.84844917, grad/param norm = 2.4459e-01, time/batch = 19.6263s	
20023/22950 (epoch 43.623), train_loss = 0.83588066, grad/param norm = 2.5238e-01, time/batch = 18.3457s	
20024/22950 (epoch 43.625), train_loss = 0.78607286, grad/param norm = 2.6665e-01, time/batch = 19.7831s	
20025/22950 (epoch 43.627), train_loss = 0.75885193, grad/param norm = 2.7232e-01, time/batch = 18.5573s	
20026/22950 (epoch 43.630), train_loss = 0.69585139, grad/param norm = 2.1883e-01, time/batch = 17.2839s	
20027/22950 (epoch 43.632), train_loss = 0.76010909, grad/param norm = 2.7391e-01, time/batch = 16.6014s	
20028/22950 (epoch 43.634), train_loss = 0.79635947, grad/param norm = 2.2768e-01, time/batch = 18.4551s	
20029/22950 (epoch 43.636), train_loss = 0.78946346, grad/param norm = 2.8492e-01, time/batch = 18.7057s	
20030/22950 (epoch 43.638), train_loss = 0.78385773, grad/param norm = 2.5883e-01, time/batch = 18.9645s	
20031/22950 (epoch 43.641), train_loss = 0.76453880, grad/param norm = 2.4060e-01, time/batch = 19.7183s	
20032/22950 (epoch 43.643), train_loss = 0.80805597, grad/param norm = 3.1597e-01, time/batch = 18.4473s	
20033/22950 (epoch 43.645), train_loss = 0.76299779, grad/param norm = 2.3678e-01, time/batch = 19.4492s	
20034/22950 (epoch 43.647), train_loss = 0.75738537, grad/param norm = 3.2064e-01, time/batch = 19.0441s	
20035/22950 (epoch 43.649), train_loss = 0.72186849, grad/param norm = 3.0690e-01, time/batch = 20.0360s	
20036/22950 (epoch 43.651), train_loss = 0.86923564, grad/param norm = 2.7814e-01, time/batch = 18.1151s	
20037/22950 (epoch 43.654), train_loss = 0.67184182, grad/param norm = 2.1984e-01, time/batch = 20.2155s	
20038/22950 (epoch 43.656), train_loss = 0.85846634, grad/param norm = 4.3061e-01, time/batch = 17.2082s	
20039/22950 (epoch 43.658), train_loss = 0.70019723, grad/param norm = 2.5943e-01, time/batch = 17.9521s	
20040/22950 (epoch 43.660), train_loss = 0.64178963, grad/param norm = 2.5228e-01, time/batch = 18.8845s	
20041/22950 (epoch 43.662), train_loss = 0.65705522, grad/param norm = 2.7076e-01, time/batch = 19.7053s	
20042/22950 (epoch 43.664), train_loss = 0.76198430, grad/param norm = 2.7510e-01, time/batch = 17.9521s	
20043/22950 (epoch 43.667), train_loss = 0.76996357, grad/param norm = 2.5428e-01, time/batch = 17.3798s	
20044/22950 (epoch 43.669), train_loss = 0.79354113, grad/param norm = 2.9303e-01, time/batch = 18.0358s	
20045/22950 (epoch 43.671), train_loss = 0.77034637, grad/param norm = 3.1527e-01, time/batch = 18.6951s	
20046/22950 (epoch 43.673), train_loss = 0.72761888, grad/param norm = 2.9331e-01, time/batch = 18.2022s	
20047/22950 (epoch 43.675), train_loss = 0.80249558, grad/param norm = 2.9119e-01, time/batch = 19.2902s	
20048/22950 (epoch 43.678), train_loss = 0.77410661, grad/param norm = 2.8064e-01, time/batch = 18.5351s	
20049/22950 (epoch 43.680), train_loss = 0.81659486, grad/param norm = 2.5004e-01, time/batch = 20.6240s	
20050/22950 (epoch 43.682), train_loss = 0.78091064, grad/param norm = 2.5882e-01, time/batch = 18.7928s	
20051/22950 (epoch 43.684), train_loss = 0.86481685, grad/param norm = 2.7713e-01, time/batch = 19.2703s	
20052/22950 (epoch 43.686), train_loss = 0.89543669, grad/param norm = 2.7591e-01, time/batch = 20.8536s	
20053/22950 (epoch 43.688), train_loss = 0.78581619, grad/param norm = 2.8252e-01, time/batch = 18.4601s	
20054/22950 (epoch 43.691), train_loss = 0.77468780, grad/param norm = 2.6683e-01, time/batch = 20.1202s	
20055/22950 (epoch 43.693), train_loss = 0.71710525, grad/param norm = 2.9522e-01, time/batch = 19.1930s	
20056/22950 (epoch 43.695), train_loss = 0.87839982, grad/param norm = 3.2636e-01, time/batch = 18.2982s	
20057/22950 (epoch 43.697), train_loss = 0.82700140, grad/param norm = 3.4998e-01, time/batch = 18.6076s	
20058/22950 (epoch 43.699), train_loss = 0.82276087, grad/param norm = 2.7843e-01, time/batch = 17.0760s	
20059/22950 (epoch 43.702), train_loss = 0.87121435, grad/param norm = 3.1258e-01, time/batch = 19.9433s	
20060/22950 (epoch 43.704), train_loss = 0.94588083, grad/param norm = 3.3867e-01, time/batch = 19.8721s	
20061/22950 (epoch 43.706), train_loss = 0.85805856, grad/param norm = 2.9638e-01, time/batch = 17.6183s	
20062/22950 (epoch 43.708), train_loss = 0.71963733, grad/param norm = 3.0935e-01, time/batch = 19.9556s	
20063/22950 (epoch 43.710), train_loss = 0.78777769, grad/param norm = 2.8869e-01, time/batch = 20.2800s	
20064/22950 (epoch 43.712), train_loss = 0.91599665, grad/param norm = 2.8407e-01, time/batch = 17.3682s	
20065/22950 (epoch 43.715), train_loss = 0.83244674, grad/param norm = 3.1504e-01, time/batch = 18.4491s	
20066/22950 (epoch 43.717), train_loss = 0.85152708, grad/param norm = 2.7368e-01, time/batch = 19.2128s	
20067/22950 (epoch 43.719), train_loss = 0.80523009, grad/param norm = 3.1183e-01, time/batch = 19.1348s	
20068/22950 (epoch 43.721), train_loss = 0.86387514, grad/param norm = 2.6924e-01, time/batch = 19.6125s	
20069/22950 (epoch 43.723), train_loss = 0.81391401, grad/param norm = 2.7022e-01, time/batch = 19.5435s	
20070/22950 (epoch 43.725), train_loss = 0.86148888, grad/param norm = 3.1774e-01, time/batch = 18.4471s	
20071/22950 (epoch 43.728), train_loss = 0.79316463, grad/param norm = 2.8637e-01, time/batch = 18.9462s	
20072/22950 (epoch 43.730), train_loss = 0.82843502, grad/param norm = 2.9487e-01, time/batch = 19.2077s	
20073/22950 (epoch 43.732), train_loss = 0.90068509, grad/param norm = 3.5274e-01, time/batch = 19.2784s	
20074/22950 (epoch 43.734), train_loss = 0.76720817, grad/param norm = 2.9109e-01, time/batch = 19.5454s	
20075/22950 (epoch 43.736), train_loss = 0.85398657, grad/param norm = 2.7395e-01, time/batch = 17.7906s	
20076/22950 (epoch 43.739), train_loss = 0.87609833, grad/param norm = 3.5778e-01, time/batch = 19.8672s	
20077/22950 (epoch 43.741), train_loss = 0.87728509, grad/param norm = 3.2521e-01, time/batch = 16.3878s	
20078/22950 (epoch 43.743), train_loss = 0.94748697, grad/param norm = 3.5601e-01, time/batch = 20.0270s	
20079/22950 (epoch 43.745), train_loss = 1.02936741, grad/param norm = 3.7817e-01, time/batch = 19.7159s	
20080/22950 (epoch 43.747), train_loss = 0.88389083, grad/param norm = 3.0476e-01, time/batch = 17.0192s	
20081/22950 (epoch 43.749), train_loss = 0.75767485, grad/param norm = 2.8746e-01, time/batch = 17.5091s	
20082/22950 (epoch 43.752), train_loss = 0.97647268, grad/param norm = 3.2415e-01, time/batch = 19.0445s	
20083/22950 (epoch 43.754), train_loss = 0.85690697, grad/param norm = 2.9416e-01, time/batch = 18.9543s	
20084/22950 (epoch 43.756), train_loss = 0.78090367, grad/param norm = 2.4752e-01, time/batch = 18.3699s	
20085/22950 (epoch 43.758), train_loss = 0.83194072, grad/param norm = 2.4076e-01, time/batch = 19.5482s	
20086/22950 (epoch 43.760), train_loss = 0.81287073, grad/param norm = 2.6068e-01, time/batch = 18.6855s	
20087/22950 (epoch 43.763), train_loss = 0.84264811, grad/param norm = 3.0861e-01, time/batch = 19.1213s	
20088/22950 (epoch 43.765), train_loss = 0.81884462, grad/param norm = 3.0257e-01, time/batch = 20.2179s	
20089/22950 (epoch 43.767), train_loss = 0.99621601, grad/param norm = 3.7898e-01, time/batch = 20.9821s	
20090/22950 (epoch 43.769), train_loss = 0.84784185, grad/param norm = 2.9263e-01, time/batch = 20.3118s	
20091/22950 (epoch 43.771), train_loss = 0.74022585, grad/param norm = 3.1440e-01, time/batch = 22.4054s	
20092/22950 (epoch 43.773), train_loss = 0.60743136, grad/param norm = 2.3547e-01, time/batch = 27.4270s	
20093/22950 (epoch 43.776), train_loss = 0.75056714, grad/param norm = 2.2755e-01, time/batch = 26.8778s	
20094/22950 (epoch 43.778), train_loss = 0.73571109, grad/param norm = 2.6915e-01, time/batch = 25.3667s	
20095/22950 (epoch 43.780), train_loss = 0.83340156, grad/param norm = 2.9880e-01, time/batch = 27.3820s	
20096/22950 (epoch 43.782), train_loss = 0.84926979, grad/param norm = 2.6877e-01, time/batch = 28.0378s	
20097/22950 (epoch 43.784), train_loss = 0.74556913, grad/param norm = 2.5938e-01, time/batch = 26.4721s	
20098/22950 (epoch 43.786), train_loss = 0.83873561, grad/param norm = 3.0682e-01, time/batch = 26.4748s	
20099/22950 (epoch 43.789), train_loss = 0.66804043, grad/param norm = 2.7869e-01, time/batch = 21.5814s	
20100/22950 (epoch 43.791), train_loss = 0.69362438, grad/param norm = 2.5622e-01, time/batch = 23.1560s	
20101/22950 (epoch 43.793), train_loss = 0.91628100, grad/param norm = 3.1533e-01, time/batch = 22.9414s	
20102/22950 (epoch 43.795), train_loss = 0.77903794, grad/param norm = 2.6866e-01, time/batch = 26.2832s	
20103/22950 (epoch 43.797), train_loss = 0.92838181, grad/param norm = 3.0143e-01, time/batch = 25.9663s	
20104/22950 (epoch 43.800), train_loss = 0.76908602, grad/param norm = 2.7129e-01, time/batch = 24.7152s	
20105/22950 (epoch 43.802), train_loss = 0.79083865, grad/param norm = 2.5824e-01, time/batch = 23.1714s	
20106/22950 (epoch 43.804), train_loss = 0.80271318, grad/param norm = 2.6016e-01, time/batch = 23.9523s	
20107/22950 (epoch 43.806), train_loss = 0.69048866, grad/param norm = 2.4042e-01, time/batch = 25.2953s	
20108/22950 (epoch 43.808), train_loss = 0.84774440, grad/param norm = 2.6519e-01, time/batch = 24.5263s	
20109/22950 (epoch 43.810), train_loss = 0.76120390, grad/param norm = 2.6947e-01, time/batch = 34.1102s	
20110/22950 (epoch 43.813), train_loss = 0.68081297, grad/param norm = 2.5499e-01, time/batch = 21.9501s	
20111/22950 (epoch 43.815), train_loss = 0.63440378, grad/param norm = 2.5326e-01, time/batch = 17.6853s	
20112/22950 (epoch 43.817), train_loss = 0.71291687, grad/param norm = 2.3422e-01, time/batch = 19.2105s	
20113/22950 (epoch 43.819), train_loss = 0.74660067, grad/param norm = 2.5013e-01, time/batch = 20.1249s	
20114/22950 (epoch 43.821), train_loss = 0.76591948, grad/param norm = 3.0545e-01, time/batch = 17.9457s	
20115/22950 (epoch 43.824), train_loss = 0.80403498, grad/param norm = 2.5243e-01, time/batch = 19.6262s	
20116/22950 (epoch 43.826), train_loss = 0.82552909, grad/param norm = 2.9529e-01, time/batch = 19.8479s	
20117/22950 (epoch 43.828), train_loss = 0.73695232, grad/param norm = 2.6880e-01, time/batch = 17.9459s	
20118/22950 (epoch 43.830), train_loss = 0.75398968, grad/param norm = 2.5629e-01, time/batch = 20.2009s	
20119/22950 (epoch 43.832), train_loss = 0.80799556, grad/param norm = 2.7447e-01, time/batch = 18.2804s	
20120/22950 (epoch 43.834), train_loss = 0.65264622, grad/param norm = 3.1761e-01, time/batch = 16.6066s	
20121/22950 (epoch 43.837), train_loss = 0.81750171, grad/param norm = 3.2983e-01, time/batch = 18.6103s	
20122/22950 (epoch 43.839), train_loss = 0.67056663, grad/param norm = 2.5078e-01, time/batch = 18.2992s	
20123/22950 (epoch 43.841), train_loss = 0.76489458, grad/param norm = 2.5059e-01, time/batch = 18.2935s	
20124/22950 (epoch 43.843), train_loss = 0.74746997, grad/param norm = 2.6072e-01, time/batch = 18.0190s	
20125/22950 (epoch 43.845), train_loss = 0.79067305, grad/param norm = 2.6864e-01, time/batch = 18.0501s	
20126/22950 (epoch 43.847), train_loss = 0.81656762, grad/param norm = 2.8497e-01, time/batch = 19.3045s	
20127/22950 (epoch 43.850), train_loss = 0.85144083, grad/param norm = 2.7099e-01, time/batch = 16.7044s	
20128/22950 (epoch 43.852), train_loss = 0.85993470, grad/param norm = 2.8994e-01, time/batch = 18.2858s	
20129/22950 (epoch 43.854), train_loss = 0.79686730, grad/param norm = 2.6120e-01, time/batch = 19.9680s	
20130/22950 (epoch 43.856), train_loss = 0.88241165, grad/param norm = 3.0835e-01, time/batch = 16.5398s	
20131/22950 (epoch 43.858), train_loss = 0.87976761, grad/param norm = 2.7492e-01, time/batch = 18.2936s	
20132/22950 (epoch 43.861), train_loss = 0.81975542, grad/param norm = 2.6578e-01, time/batch = 18.9697s	
20133/22950 (epoch 43.863), train_loss = 0.88516057, grad/param norm = 3.3455e-01, time/batch = 17.8420s	
20134/22950 (epoch 43.865), train_loss = 0.93818453, grad/param norm = 3.1015e-01, time/batch = 19.1151s	
20135/22950 (epoch 43.867), train_loss = 0.82697323, grad/param norm = 2.9902e-01, time/batch = 19.0401s	
20136/22950 (epoch 43.869), train_loss = 0.96141049, grad/param norm = 3.0640e-01, time/batch = 18.5996s	
20137/22950 (epoch 43.871), train_loss = 0.81802061, grad/param norm = 2.8212e-01, time/batch = 19.8733s	
20138/22950 (epoch 43.874), train_loss = 0.83476669, grad/param norm = 2.3062e-01, time/batch = 19.2124s	
20139/22950 (epoch 43.876), train_loss = 0.90837237, grad/param norm = 3.2245e-01, time/batch = 19.2700s	
20140/22950 (epoch 43.878), train_loss = 0.85159283, grad/param norm = 3.0581e-01, time/batch = 19.4148s	
20141/22950 (epoch 43.880), train_loss = 0.98004444, grad/param norm = 3.0958e-01, time/batch = 19.9472s	
20142/22950 (epoch 43.882), train_loss = 0.72726564, grad/param norm = 2.6050e-01, time/batch = 20.2080s	
20143/22950 (epoch 43.885), train_loss = 0.83710740, grad/param norm = 3.0476e-01, time/batch = 21.0338s	
20144/22950 (epoch 43.887), train_loss = 0.79512388, grad/param norm = 2.2979e-01, time/batch = 18.1427s	
20145/22950 (epoch 43.889), train_loss = 0.84741018, grad/param norm = 2.8828e-01, time/batch = 19.5465s	
20146/22950 (epoch 43.891), train_loss = 0.73964704, grad/param norm = 2.5126e-01, time/batch = 18.6737s	
20147/22950 (epoch 43.893), train_loss = 0.81867934, grad/param norm = 2.5713e-01, time/batch = 18.0444s	
20148/22950 (epoch 43.895), train_loss = 0.94265915, grad/param norm = 2.6985e-01, time/batch = 17.2732s	
20149/22950 (epoch 43.898), train_loss = 0.86723369, grad/param norm = 2.6517e-01, time/batch = 17.1077s	
20150/22950 (epoch 43.900), train_loss = 0.75724353, grad/param norm = 2.3556e-01, time/batch = 19.3011s	
20151/22950 (epoch 43.902), train_loss = 0.81507620, grad/param norm = 2.7812e-01, time/batch = 19.2770s	
20152/22950 (epoch 43.904), train_loss = 0.79893653, grad/param norm = 2.6373e-01, time/batch = 16.7040s	
20153/22950 (epoch 43.906), train_loss = 0.81689245, grad/param norm = 3.0407e-01, time/batch = 19.1275s	
20154/22950 (epoch 43.908), train_loss = 0.72662672, grad/param norm = 2.6950e-01, time/batch = 19.6329s	
20155/22950 (epoch 43.911), train_loss = 0.65930868, grad/param norm = 2.5281e-01, time/batch = 18.6294s	
20156/22950 (epoch 43.913), train_loss = 0.80281530, grad/param norm = 2.4698e-01, time/batch = 19.3118s	
20157/22950 (epoch 43.915), train_loss = 0.92202436, grad/param norm = 3.0356e-01, time/batch = 18.6261s	
20158/22950 (epoch 43.917), train_loss = 0.70523005, grad/param norm = 2.4771e-01, time/batch = 19.6182s	
20159/22950 (epoch 43.919), train_loss = 0.82758912, grad/param norm = 2.8260e-01, time/batch = 16.7162s	
20160/22950 (epoch 43.922), train_loss = 0.81025352, grad/param norm = 2.6766e-01, time/batch = 19.3903s	
20161/22950 (epoch 43.924), train_loss = 0.84896773, grad/param norm = 2.9853e-01, time/batch = 19.3009s	
20162/22950 (epoch 43.926), train_loss = 0.67842590, grad/param norm = 2.4863e-01, time/batch = 16.4106s	
20163/22950 (epoch 43.928), train_loss = 0.72904251, grad/param norm = 2.4347e-01, time/batch = 18.3039s	
20164/22950 (epoch 43.930), train_loss = 0.71283122, grad/param norm = 2.2534e-01, time/batch = 17.9641s	
20165/22950 (epoch 43.932), train_loss = 0.65633183, grad/param norm = 2.1761e-01, time/batch = 17.8569s	
20166/22950 (epoch 43.935), train_loss = 0.84546521, grad/param norm = 2.4721e-01, time/batch = 18.3222s	
20167/22950 (epoch 43.937), train_loss = 0.79875137, grad/param norm = 2.8173e-01, time/batch = 19.2178s	
20168/22950 (epoch 43.939), train_loss = 0.75647094, grad/param norm = 3.5634e-01, time/batch = 18.1856s	
20169/22950 (epoch 43.941), train_loss = 0.79488747, grad/param norm = 3.0165e-01, time/batch = 18.3613s	
20170/22950 (epoch 43.943), train_loss = 0.81170745, grad/param norm = 2.7005e-01, time/batch = 17.6213s	
20171/22950 (epoch 43.946), train_loss = 0.66074728, grad/param norm = 2.7306e-01, time/batch = 18.1360s	
20172/22950 (epoch 43.948), train_loss = 0.87697199, grad/param norm = 2.8633e-01, time/batch = 19.7738s	
20173/22950 (epoch 43.950), train_loss = 0.78713018, grad/param norm = 2.8234e-01, time/batch = 20.2078s	
20174/22950 (epoch 43.952), train_loss = 0.85500284, grad/param norm = 2.7414e-01, time/batch = 19.2181s	
20175/22950 (epoch 43.954), train_loss = 0.83672894, grad/param norm = 2.8187e-01, time/batch = 18.3435s	
20176/22950 (epoch 43.956), train_loss = 0.74407998, grad/param norm = 2.8121e-01, time/batch = 19.1310s	
20177/22950 (epoch 43.959), train_loss = 0.71955189, grad/param norm = 2.4068e-01, time/batch = 18.4734s	
20178/22950 (epoch 43.961), train_loss = 0.78582086, grad/param norm = 2.5904e-01, time/batch = 17.3461s	
20179/22950 (epoch 43.963), train_loss = 0.78894487, grad/param norm = 2.9998e-01, time/batch = 18.4427s	
20180/22950 (epoch 43.965), train_loss = 0.86354279, grad/param norm = 2.7581e-01, time/batch = 17.2909s	
20181/22950 (epoch 43.967), train_loss = 0.74571892, grad/param norm = 2.5707e-01, time/batch = 17.1864s	
20182/22950 (epoch 43.969), train_loss = 0.69475674, grad/param norm = 2.5620e-01, time/batch = 19.6963s	
20183/22950 (epoch 43.972), train_loss = 0.76732205, grad/param norm = 2.6256e-01, time/batch = 19.4506s	
20184/22950 (epoch 43.974), train_loss = 0.75144763, grad/param norm = 2.6668e-01, time/batch = 17.8597s	
20185/22950 (epoch 43.976), train_loss = 0.78998479, grad/param norm = 2.5293e-01, time/batch = 19.1351s	
20186/22950 (epoch 43.978), train_loss = 0.72500321, grad/param norm = 2.4514e-01, time/batch = 18.1431s	
20187/22950 (epoch 43.980), train_loss = 0.73940017, grad/param norm = 2.4258e-01, time/batch = 19.7875s	
20188/22950 (epoch 43.983), train_loss = 0.84364650, grad/param norm = 2.5045e-01, time/batch = 18.9365s	
20189/22950 (epoch 43.985), train_loss = 0.72344382, grad/param norm = 2.6216e-01, time/batch = 19.9568s	
20190/22950 (epoch 43.987), train_loss = 0.71959920, grad/param norm = 2.3796e-01, time/batch = 19.1242s	
20191/22950 (epoch 43.989), train_loss = 0.79962525, grad/param norm = 2.6744e-01, time/batch = 17.4507s	
20192/22950 (epoch 43.991), train_loss = 0.68088656, grad/param norm = 2.3159e-01, time/batch = 19.0574s	
20193/22950 (epoch 43.993), train_loss = 0.80640248, grad/param norm = 2.7055e-01, time/batch = 19.6364s	
20194/22950 (epoch 43.996), train_loss = 0.78422459, grad/param norm = 3.7447e-01, time/batch = 24.0911s	
20195/22950 (epoch 43.998), train_loss = 0.71431286, grad/param norm = 2.7995e-01, time/batch = 29.3508s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
20196/22950 (epoch 44.000), train_loss = 0.67037993, grad/param norm = 2.5262e-01, time/batch = 17.6220s	
20197/22950 (epoch 44.002), train_loss = 0.94439924, grad/param norm = 2.9193e-01, time/batch = 18.4419s	
20198/22950 (epoch 44.004), train_loss = 0.83813751, grad/param norm = 2.6284e-01, time/batch = 19.6311s	
20199/22950 (epoch 44.007), train_loss = 0.76900392, grad/param norm = 2.6197e-01, time/batch = 18.6879s	
20200/22950 (epoch 44.009), train_loss = 0.90848589, grad/param norm = 2.8230e-01, time/batch = 19.9545s	
20201/22950 (epoch 44.011), train_loss = 0.66481284, grad/param norm = 2.2695e-01, time/batch = 18.6325s	
20202/22950 (epoch 44.013), train_loss = 0.73718681, grad/param norm = 2.4780e-01, time/batch = 20.2065s	
20203/22950 (epoch 44.015), train_loss = 0.80536404, grad/param norm = 2.8993e-01, time/batch = 18.4500s	
20204/22950 (epoch 44.017), train_loss = 0.80249874, grad/param norm = 2.7790e-01, time/batch = 19.8897s	
20205/22950 (epoch 44.020), train_loss = 0.83738662, grad/param norm = 2.6657e-01, time/batch = 19.7858s	
20206/22950 (epoch 44.022), train_loss = 0.71009924, grad/param norm = 2.4515e-01, time/batch = 18.6192s	
20207/22950 (epoch 44.024), train_loss = 0.75419684, grad/param norm = 2.5316e-01, time/batch = 17.8690s	
20208/22950 (epoch 44.026), train_loss = 0.83775229, grad/param norm = 2.7098e-01, time/batch = 17.1172s	
20209/22950 (epoch 44.028), train_loss = 0.85340045, grad/param norm = 3.0091e-01, time/batch = 17.7014s	
20210/22950 (epoch 44.031), train_loss = 0.75273829, grad/param norm = 2.8188e-01, time/batch = 19.4589s	
20211/22950 (epoch 44.033), train_loss = 0.85846467, grad/param norm = 2.6779e-01, time/batch = 17.7991s	
20212/22950 (epoch 44.035), train_loss = 0.78959038, grad/param norm = 2.3658e-01, time/batch = 18.2172s	
20213/22950 (epoch 44.037), train_loss = 0.79116666, grad/param norm = 2.6005e-01, time/batch = 18.6260s	
20214/22950 (epoch 44.039), train_loss = 0.79336856, grad/param norm = 2.5942e-01, time/batch = 18.1290s	
20215/22950 (epoch 44.041), train_loss = 0.72646433, grad/param norm = 2.8482e-01, time/batch = 16.1881s	
20216/22950 (epoch 44.044), train_loss = 0.81255234, grad/param norm = 2.9229e-01, time/batch = 18.0429s	
20217/22950 (epoch 44.046), train_loss = 0.79168473, grad/param norm = 2.7637e-01, time/batch = 18.5350s	
20218/22950 (epoch 44.048), train_loss = 0.78197007, grad/param norm = 2.3397e-01, time/batch = 20.0531s	
20219/22950 (epoch 44.050), train_loss = 0.74731485, grad/param norm = 3.5453e-01, time/batch = 18.1999s	
20220/22950 (epoch 44.052), train_loss = 0.82651042, grad/param norm = 2.6917e-01, time/batch = 18.8859s	
20221/22950 (epoch 44.054), train_loss = 0.92148734, grad/param norm = 2.9284e-01, time/batch = 20.2006s	
20222/22950 (epoch 44.057), train_loss = 0.91354449, grad/param norm = 3.0829e-01, time/batch = 17.2823s	
20223/22950 (epoch 44.059), train_loss = 0.90478147, grad/param norm = 2.8471e-01, time/batch = 20.4760s	
20224/22950 (epoch 44.061), train_loss = 0.73702168, grad/param norm = 2.4735e-01, time/batch = 19.3093s	
20225/22950 (epoch 44.063), train_loss = 0.84449440, grad/param norm = 2.9998e-01, time/batch = 17.1795s	
20226/22950 (epoch 44.065), train_loss = 0.70595704, grad/param norm = 2.5494e-01, time/batch = 19.6885s	
20227/22950 (epoch 44.068), train_loss = 0.82685507, grad/param norm = 2.6479e-01, time/batch = 17.6259s	
20228/22950 (epoch 44.070), train_loss = 0.71530439, grad/param norm = 2.4163e-01, time/batch = 17.9673s	
20229/22950 (epoch 44.072), train_loss = 0.83858506, grad/param norm = 2.7973e-01, time/batch = 18.0333s	
20230/22950 (epoch 44.074), train_loss = 0.85564024, grad/param norm = 2.7050e-01, time/batch = 18.0157s	
20231/22950 (epoch 44.076), train_loss = 0.82921008, grad/param norm = 2.8424e-01, time/batch = 18.1278s	
20232/22950 (epoch 44.078), train_loss = 0.88881990, grad/param norm = 2.9056e-01, time/batch = 19.1011s	
20233/22950 (epoch 44.081), train_loss = 0.92427500, grad/param norm = 2.9974e-01, time/batch = 20.2933s	
20234/22950 (epoch 44.083), train_loss = 0.83022019, grad/param norm = 3.0441e-01, time/batch = 18.9811s	
20235/22950 (epoch 44.085), train_loss = 0.69607520, grad/param norm = 2.4681e-01, time/batch = 19.9362s	
20236/22950 (epoch 44.087), train_loss = 0.72918621, grad/param norm = 2.6265e-01, time/batch = 19.0510s	
20237/22950 (epoch 44.089), train_loss = 0.81664089, grad/param norm = 2.6280e-01, time/batch = 19.6225s	
20238/22950 (epoch 44.092), train_loss = 0.74551833, grad/param norm = 2.6447e-01, time/batch = 19.1247s	
20239/22950 (epoch 44.094), train_loss = 0.74419291, grad/param norm = 2.5566e-01, time/batch = 19.7053s	
20240/22950 (epoch 44.096), train_loss = 0.90092778, grad/param norm = 2.8242e-01, time/batch = 17.2812s	
20241/22950 (epoch 44.098), train_loss = 0.85349439, grad/param norm = 2.7325e-01, time/batch = 17.3917s	
20242/22950 (epoch 44.100), train_loss = 0.79304349, grad/param norm = 2.4951e-01, time/batch = 18.7779s	
20243/22950 (epoch 44.102), train_loss = 0.81550216, grad/param norm = 3.0592e-01, time/batch = 16.6066s	
20244/22950 (epoch 44.105), train_loss = 0.67289816, grad/param norm = 2.3918e-01, time/batch = 18.6326s	
20245/22950 (epoch 44.107), train_loss = 0.72474273, grad/param norm = 2.3757e-01, time/batch = 19.3744s	
20246/22950 (epoch 44.109), train_loss = 0.75591819, grad/param norm = 2.5216e-01, time/batch = 18.3792s	
20247/22950 (epoch 44.111), train_loss = 0.66113398, grad/param norm = 2.3026e-01, time/batch = 18.4380s	
20248/22950 (epoch 44.113), train_loss = 0.82945012, grad/param norm = 2.6352e-01, time/batch = 18.7902s	
20249/22950 (epoch 44.115), train_loss = 0.79632157, grad/param norm = 2.5976e-01, time/batch = 18.1288s	
20250/22950 (epoch 44.118), train_loss = 0.87437414, grad/param norm = 2.3473e-01, time/batch = 20.2885s	
20251/22950 (epoch 44.120), train_loss = 0.69682232, grad/param norm = 2.6085e-01, time/batch = 20.1106s	
20252/22950 (epoch 44.122), train_loss = 0.86563130, grad/param norm = 2.6869e-01, time/batch = 18.6187s	
20253/22950 (epoch 44.124), train_loss = 0.69732995, grad/param norm = 2.2166e-01, time/batch = 19.6334s	
20254/22950 (epoch 44.126), train_loss = 0.77920431, grad/param norm = 2.3949e-01, time/batch = 18.9243s	
20255/22950 (epoch 44.129), train_loss = 0.72883395, grad/param norm = 2.0634e-01, time/batch = 17.6078s	
20256/22950 (epoch 44.131), train_loss = 0.77116640, grad/param norm = 2.2896e-01, time/batch = 20.4669s	
20257/22950 (epoch 44.133), train_loss = 0.83211538, grad/param norm = 2.5119e-01, time/batch = 18.6863s	
20258/22950 (epoch 44.135), train_loss = 0.80352425, grad/param norm = 2.0924e-01, time/batch = 18.5512s	
20259/22950 (epoch 44.137), train_loss = 0.81986900, grad/param norm = 2.8335e-01, time/batch = 16.1936s	
20260/22950 (epoch 44.139), train_loss = 0.74865705, grad/param norm = 2.4660e-01, time/batch = 17.1073s	
20261/22950 (epoch 44.142), train_loss = 0.71386008, grad/param norm = 2.0565e-01, time/batch = 18.1475s	
20262/22950 (epoch 44.144), train_loss = 0.75726626, grad/param norm = 2.4439e-01, time/batch = 18.4731s	
20263/22950 (epoch 44.146), train_loss = 0.69800256, grad/param norm = 2.6227e-01, time/batch = 18.1027s	
20264/22950 (epoch 44.148), train_loss = 0.71566390, grad/param norm = 2.8242e-01, time/batch = 19.4449s	
20265/22950 (epoch 44.150), train_loss = 0.80013837, grad/param norm = 2.7096e-01, time/batch = 18.8095s	
20266/22950 (epoch 44.153), train_loss = 0.68349321, grad/param norm = 2.0598e-01, time/batch = 19.5359s	
20267/22950 (epoch 44.155), train_loss = 0.72098248, grad/param norm = 2.5068e-01, time/batch = 18.6878s	
20268/22950 (epoch 44.157), train_loss = 0.76799973, grad/param norm = 2.3603e-01, time/batch = 18.2228s	
20269/22950 (epoch 44.159), train_loss = 0.68351965, grad/param norm = 2.1625e-01, time/batch = 18.7989s	
20270/22950 (epoch 44.161), train_loss = 0.73915659, grad/param norm = 2.4052e-01, time/batch = 17.5336s	
20271/22950 (epoch 44.163), train_loss = 0.68288482, grad/param norm = 2.3279e-01, time/batch = 21.1235s	
20272/22950 (epoch 44.166), train_loss = 0.81618891, grad/param norm = 3.5069e-01, time/batch = 18.9583s	
20273/22950 (epoch 44.168), train_loss = 0.80736629, grad/param norm = 3.3374e-01, time/batch = 19.0959s	
20274/22950 (epoch 44.170), train_loss = 0.79699721, grad/param norm = 2.4607e-01, time/batch = 20.3606s	
20275/22950 (epoch 44.172), train_loss = 0.76996600, grad/param norm = 2.4218e-01, time/batch = 16.2691s	
20276/22950 (epoch 44.174), train_loss = 0.85859478, grad/param norm = 2.6032e-01, time/batch = 17.7040s	
20277/22950 (epoch 44.176), train_loss = 0.84664475, grad/param norm = 3.0055e-01, time/batch = 18.7842s	
20278/22950 (epoch 44.179), train_loss = 0.81798735, grad/param norm = 2.7157e-01, time/batch = 19.5537s	
20279/22950 (epoch 44.181), train_loss = 1.01560458, grad/param norm = 2.7843e-01, time/batch = 17.9445s	
20280/22950 (epoch 44.183), train_loss = 0.82337723, grad/param norm = 2.6925e-01, time/batch = 18.7798s	
20281/22950 (epoch 44.185), train_loss = 0.84032500, grad/param norm = 2.5231e-01, time/batch = 18.5522s	
20282/22950 (epoch 44.187), train_loss = 0.70821294, grad/param norm = 2.2679e-01, time/batch = 19.4524s	
20283/22950 (epoch 44.190), train_loss = 0.63892777, grad/param norm = 2.6022e-01, time/batch = 19.2999s	
20284/22950 (epoch 44.192), train_loss = 0.61562952, grad/param norm = 2.3974e-01, time/batch = 18.7174s	
20285/22950 (epoch 44.194), train_loss = 0.75196245, grad/param norm = 2.5976e-01, time/batch = 19.3000s	
20286/22950 (epoch 44.196), train_loss = 0.59224681, grad/param norm = 3.1625e-01, time/batch = 19.4534s	
20287/22950 (epoch 44.198), train_loss = 0.80854754, grad/param norm = 2.8090e-01, time/batch = 18.7125s	
20288/22950 (epoch 44.200), train_loss = 0.71131840, grad/param norm = 2.2891e-01, time/batch = 19.8855s	
20289/22950 (epoch 44.203), train_loss = 0.65663063, grad/param norm = 2.1394e-01, time/batch = 17.3395s	
20290/22950 (epoch 44.205), train_loss = 0.73117687, grad/param norm = 2.5024e-01, time/batch = 19.1976s	
20291/22950 (epoch 44.207), train_loss = 0.79855412, grad/param norm = 2.8022e-01, time/batch = 16.0231s	
20292/22950 (epoch 44.209), train_loss = 0.75945111, grad/param norm = 3.0475e-01, time/batch = 19.0429s	
20293/22950 (epoch 44.211), train_loss = 0.67066244, grad/param norm = 3.0856e-01, time/batch = 18.3015s	
20294/22950 (epoch 44.214), train_loss = 0.73016236, grad/param norm = 2.8600e-01, time/batch = 19.5429s	
20295/22950 (epoch 44.216), train_loss = 0.85451437, grad/param norm = 2.4404e-01, time/batch = 17.3775s	
20296/22950 (epoch 44.218), train_loss = 0.75304916, grad/param norm = 2.2726e-01, time/batch = 19.9427s	
20297/22950 (epoch 44.220), train_loss = 0.84350713, grad/param norm = 2.6371e-01, time/batch = 19.4486s	
20298/22950 (epoch 44.222), train_loss = 0.86900382, grad/param norm = 3.1627e-01, time/batch = 18.4617s	
20299/22950 (epoch 44.224), train_loss = 0.75856480, grad/param norm = 2.5288e-01, time/batch = 18.5504s	
20300/22950 (epoch 44.227), train_loss = 0.83084513, grad/param norm = 2.5111e-01, time/batch = 19.2994s	
20301/22950 (epoch 44.229), train_loss = 0.89687521, grad/param norm = 2.9770e-01, time/batch = 19.5374s	
20302/22950 (epoch 44.231), train_loss = 0.60677524, grad/param norm = 2.3173e-01, time/batch = 20.6116s	
20303/22950 (epoch 44.233), train_loss = 0.74074142, grad/param norm = 2.6267e-01, time/batch = 16.8124s	
20304/22950 (epoch 44.235), train_loss = 0.88632425, grad/param norm = 2.3776e-01, time/batch = 20.0463s	
20305/22950 (epoch 44.237), train_loss = 0.75431372, grad/param norm = 2.5399e-01, time/batch = 10.8535s	
20306/22950 (epoch 44.240), train_loss = 0.78560532, grad/param norm = 2.4933e-01, time/batch = 0.6873s	
20307/22950 (epoch 44.242), train_loss = 0.90332611, grad/param norm = 2.6258e-01, time/batch = 0.6929s	
20308/22950 (epoch 44.244), train_loss = 0.90080801, grad/param norm = 2.8879e-01, time/batch = 0.6886s	
20309/22950 (epoch 44.246), train_loss = 0.89770873, grad/param norm = 3.1024e-01, time/batch = 0.6933s	
20310/22950 (epoch 44.248), train_loss = 0.78925437, grad/param norm = 2.8109e-01, time/batch = 0.6938s	
20311/22950 (epoch 44.251), train_loss = 0.73606144, grad/param norm = 2.4275e-01, time/batch = 0.6929s	
20312/22950 (epoch 44.253), train_loss = 0.70472204, grad/param norm = 2.7111e-01, time/batch = 0.7528s	
20313/22950 (epoch 44.255), train_loss = 0.83036041, grad/param norm = 2.7423e-01, time/batch = 1.0148s	
20314/22950 (epoch 44.257), train_loss = 0.88764487, grad/param norm = 2.9716e-01, time/batch = 1.0141s	
20315/22950 (epoch 44.259), train_loss = 0.66432677, grad/param norm = 2.2561e-01, time/batch = 1.0037s	
20316/22950 (epoch 44.261), train_loss = 0.68927614, grad/param norm = 2.4909e-01, time/batch = 1.0051s	
20317/22950 (epoch 44.264), train_loss = 0.70574357, grad/param norm = 2.7854e-01, time/batch = 1.2281s	
20318/22950 (epoch 44.266), train_loss = 0.74482845, grad/param norm = 2.4123e-01, time/batch = 1.9012s	
20319/22950 (epoch 44.268), train_loss = 0.77417247, grad/param norm = 2.8842e-01, time/batch = 1.8629s	
20320/22950 (epoch 44.270), train_loss = 0.77000713, grad/param norm = 2.4433e-01, time/batch = 12.4900s	
20321/22950 (epoch 44.272), train_loss = 0.78271450, grad/param norm = 2.4599e-01, time/batch = 18.8810s	
20322/22950 (epoch 44.275), train_loss = 0.75114459, grad/param norm = 3.0432e-01, time/batch = 18.2052s	
20323/22950 (epoch 44.277), train_loss = 0.64645643, grad/param norm = 2.2672e-01, time/batch = 20.1241s	
20324/22950 (epoch 44.279), train_loss = 0.67556504, grad/param norm = 2.6152e-01, time/batch = 18.9640s	
20325/22950 (epoch 44.281), train_loss = 0.76837717, grad/param norm = 2.8367e-01, time/batch = 16.7626s	
20326/22950 (epoch 44.283), train_loss = 0.67117149, grad/param norm = 2.1719e-01, time/batch = 15.9916s	
20327/22950 (epoch 44.285), train_loss = 0.77366849, grad/param norm = 2.3961e-01, time/batch = 18.4349s	
20328/22950 (epoch 44.288), train_loss = 0.87467214, grad/param norm = 2.8778e-01, time/batch = 18.7705s	
20329/22950 (epoch 44.290), train_loss = 0.74987874, grad/param norm = 2.7083e-01, time/batch = 20.1295s	
20330/22950 (epoch 44.292), train_loss = 0.88031610, grad/param norm = 2.8031e-01, time/batch = 19.1319s	
20331/22950 (epoch 44.294), train_loss = 0.80763513, grad/param norm = 2.3040e-01, time/batch = 19.1857s	
20332/22950 (epoch 44.296), train_loss = 0.61209663, grad/param norm = 2.0915e-01, time/batch = 19.0390s	
20333/22950 (epoch 44.298), train_loss = 0.76575279, grad/param norm = 3.1741e-01, time/batch = 19.0401s	
20334/22950 (epoch 44.301), train_loss = 0.80669392, grad/param norm = 2.6582e-01, time/batch = 19.9497s	
20335/22950 (epoch 44.303), train_loss = 0.76739074, grad/param norm = 2.5910e-01, time/batch = 18.0406s	
20336/22950 (epoch 44.305), train_loss = 0.76812027, grad/param norm = 3.5041e-01, time/batch = 17.9703s	
20337/22950 (epoch 44.307), train_loss = 0.87862904, grad/param norm = 2.9845e-01, time/batch = 19.2156s	
20338/22950 (epoch 44.309), train_loss = 0.73395446, grad/param norm = 2.8362e-01, time/batch = 17.9580s	
20339/22950 (epoch 44.312), train_loss = 0.80443291, grad/param norm = 2.7671e-01, time/batch = 20.2982s	
20340/22950 (epoch 44.314), train_loss = 0.78399331, grad/param norm = 2.5292e-01, time/batch = 17.9794s	
20341/22950 (epoch 44.316), train_loss = 0.76499616, grad/param norm = 2.6302e-01, time/batch = 16.9212s	
20342/22950 (epoch 44.318), train_loss = 0.68288391, grad/param norm = 2.1575e-01, time/batch = 20.0364s	
20343/22950 (epoch 44.320), train_loss = 0.71124582, grad/param norm = 2.3844e-01, time/batch = 19.0446s	
20344/22950 (epoch 44.322), train_loss = 0.71817961, grad/param norm = 2.3028e-01, time/batch = 18.4559s	
20345/22950 (epoch 44.325), train_loss = 0.59972356, grad/param norm = 2.2014e-01, time/batch = 18.9778s	
20346/22950 (epoch 44.327), train_loss = 0.60004817, grad/param norm = 2.2182e-01, time/batch = 17.9640s	
20347/22950 (epoch 44.329), train_loss = 0.70616234, grad/param norm = 2.2007e-01, time/batch = 18.7899s	
20348/22950 (epoch 44.331), train_loss = 0.65426518, grad/param norm = 2.0567e-01, time/batch = 17.6815s	
20349/22950 (epoch 44.333), train_loss = 0.68680495, grad/param norm = 2.3938e-01, time/batch = 19.1089s	
20350/22950 (epoch 44.336), train_loss = 0.75072429, grad/param norm = 3.4823e-01, time/batch = 19.0500s	
20351/22950 (epoch 44.338), train_loss = 0.76758399, grad/param norm = 2.3636e-01, time/batch = 18.7710s	
20352/22950 (epoch 44.340), train_loss = 0.71653323, grad/param norm = 2.6625e-01, time/batch = 18.7981s	
20353/22950 (epoch 44.342), train_loss = 0.91595942, grad/param norm = 2.4586e-01, time/batch = 18.2931s	
20354/22950 (epoch 44.344), train_loss = 0.74660646, grad/param norm = 3.0504e-01, time/batch = 19.6076s	
20355/22950 (epoch 44.346), train_loss = 0.87019629, grad/param norm = 3.8415e-01, time/batch = 17.7932s	
20356/22950 (epoch 44.349), train_loss = 0.76588358, grad/param norm = 2.4890e-01, time/batch = 19.3730s	
20357/22950 (epoch 44.351), train_loss = 0.79409659, grad/param norm = 2.6974e-01, time/batch = 17.3575s	
20358/22950 (epoch 44.353), train_loss = 0.78105914, grad/param norm = 3.1131e-01, time/batch = 19.6266s	
20359/22950 (epoch 44.355), train_loss = 0.85687236, grad/param norm = 3.2383e-01, time/batch = 18.7135s	
20360/22950 (epoch 44.357), train_loss = 0.72008208, grad/param norm = 2.7745e-01, time/batch = 18.7814s	
20361/22950 (epoch 44.359), train_loss = 0.78150108, grad/param norm = 3.0040e-01, time/batch = 19.5408s	
20362/22950 (epoch 44.362), train_loss = 0.82008799, grad/param norm = 5.0996e-01, time/batch = 19.7795s	
20363/22950 (epoch 44.364), train_loss = 0.80618163, grad/param norm = 3.4763e-01, time/batch = 18.1170s	
20364/22950 (epoch 44.366), train_loss = 0.78586551, grad/param norm = 2.4987e-01, time/batch = 17.4353s	
20365/22950 (epoch 44.368), train_loss = 0.80104816, grad/param norm = 2.6912e-01, time/batch = 18.8769s	
20366/22950 (epoch 44.370), train_loss = 0.76131198, grad/param norm = 2.8325e-01, time/batch = 18.9427s	
20367/22950 (epoch 44.373), train_loss = 0.72205160, grad/param norm = 2.5617e-01, time/batch = 19.1326s	
20368/22950 (epoch 44.375), train_loss = 0.85698155, grad/param norm = 3.0401e-01, time/batch = 18.2985s	
20369/22950 (epoch 44.377), train_loss = 0.72348694, grad/param norm = 2.9465e-01, time/batch = 19.3764s	
20370/22950 (epoch 44.379), train_loss = 0.78641642, grad/param norm = 3.1082e-01, time/batch = 17.0667s	
20371/22950 (epoch 44.381), train_loss = 0.69518684, grad/param norm = 2.2847e-01, time/batch = 20.1136s	
20372/22950 (epoch 44.383), train_loss = 0.73639801, grad/param norm = 2.5846e-01, time/batch = 19.0457s	
20373/22950 (epoch 44.386), train_loss = 0.71855932, grad/param norm = 2.7328e-01, time/batch = 17.0303s	
20374/22950 (epoch 44.388), train_loss = 0.83350785, grad/param norm = 2.7769e-01, time/batch = 19.1229s	
20375/22950 (epoch 44.390), train_loss = 0.67409825, grad/param norm = 2.5120e-01, time/batch = 20.0420s	
20376/22950 (epoch 44.392), train_loss = 0.70973481, grad/param norm = 2.5531e-01, time/batch = 16.5873s	
20377/22950 (epoch 44.394), train_loss = 0.72772649, grad/param norm = 2.3536e-01, time/batch = 18.6227s	
20378/22950 (epoch 44.397), train_loss = 0.84022556, grad/param norm = 2.3349e-01, time/batch = 20.6339s	
20379/22950 (epoch 44.399), train_loss = 0.84121820, grad/param norm = 3.0453e-01, time/batch = 17.8754s	
20380/22950 (epoch 44.401), train_loss = 0.92115941, grad/param norm = 3.8933e-01, time/batch = 19.1197s	
20381/22950 (epoch 44.403), train_loss = 0.76553415, grad/param norm = 2.4408e-01, time/batch = 20.6968s	
20382/22950 (epoch 44.405), train_loss = 0.90719257, grad/param norm = 3.5409e-01, time/batch = 17.7915s	
20383/22950 (epoch 44.407), train_loss = 0.94775596, grad/param norm = 2.8260e-01, time/batch = 18.4539s	
20384/22950 (epoch 44.410), train_loss = 0.81798660, grad/param norm = 2.7506e-01, time/batch = 16.9551s	
20385/22950 (epoch 44.412), train_loss = 0.76797061, grad/param norm = 2.7182e-01, time/batch = 19.2952s	
20386/22950 (epoch 44.414), train_loss = 0.87414364, grad/param norm = 2.4986e-01, time/batch = 18.5963s	
20387/22950 (epoch 44.416), train_loss = 0.81974703, grad/param norm = 3.4045e-01, time/batch = 19.0366s	
20388/22950 (epoch 44.418), train_loss = 0.78743596, grad/param norm = 2.8898e-01, time/batch = 18.7923s	
20389/22950 (epoch 44.420), train_loss = 0.83943975, grad/param norm = 2.7942e-01, time/batch = 17.4477s	
20390/22950 (epoch 44.423), train_loss = 0.73925016, grad/param norm = 2.6662e-01, time/batch = 19.9614s	
20391/22950 (epoch 44.425), train_loss = 0.76996106, grad/param norm = 2.7805e-01, time/batch = 20.4497s	
20392/22950 (epoch 44.427), train_loss = 0.78836327, grad/param norm = 2.6453e-01, time/batch = 18.4575s	
20393/22950 (epoch 44.429), train_loss = 0.81516750, grad/param norm = 2.5647e-01, time/batch = 18.5441s	
20394/22950 (epoch 44.431), train_loss = 0.85086138, grad/param norm = 2.7144e-01, time/batch = 18.4214s	
20395/22950 (epoch 44.434), train_loss = 0.79294173, grad/param norm = 2.6743e-01, time/batch = 17.7674s	
20396/22950 (epoch 44.436), train_loss = 0.84895352, grad/param norm = 3.1282e-01, time/batch = 19.1332s	
20397/22950 (epoch 44.438), train_loss = 0.78901866, grad/param norm = 2.5851e-01, time/batch = 18.9593s	
20398/22950 (epoch 44.440), train_loss = 0.88212146, grad/param norm = 2.4253e-01, time/batch = 18.7806s	
20399/22950 (epoch 44.442), train_loss = 0.92335644, grad/param norm = 2.8811e-01, time/batch = 32.4550s	
20400/22950 (epoch 44.444), train_loss = 0.82778317, grad/param norm = 2.9380e-01, time/batch = 18.5404s	
20401/22950 (epoch 44.447), train_loss = 0.92878525, grad/param norm = 3.0439e-01, time/batch = 16.3708s	
20402/22950 (epoch 44.449), train_loss = 0.71559963, grad/param norm = 2.2983e-01, time/batch = 19.5557s	
20403/22950 (epoch 44.451), train_loss = 0.80175053, grad/param norm = 2.7839e-01, time/batch = 17.6909s	
20404/22950 (epoch 44.453), train_loss = 0.81256676, grad/param norm = 2.4530e-01, time/batch = 17.1125s	
20405/22950 (epoch 44.455), train_loss = 0.79393374, grad/param norm = 2.4720e-01, time/batch = 19.2937s	
20406/22950 (epoch 44.458), train_loss = 0.78714117, grad/param norm = 2.9016e-01, time/batch = 19.4676s	
20407/22950 (epoch 44.460), train_loss = 0.84676488, grad/param norm = 2.7871e-01, time/batch = 18.9572s	
20408/22950 (epoch 44.462), train_loss = 0.84242493, grad/param norm = 2.6409e-01, time/batch = 18.7083s	
20409/22950 (epoch 44.464), train_loss = 0.74252160, grad/param norm = 2.3163e-01, time/batch = 19.2869s	
20410/22950 (epoch 44.466), train_loss = 0.87420967, grad/param norm = 2.6751e-01, time/batch = 19.2914s	
20411/22950 (epoch 44.468), train_loss = 0.85240413, grad/param norm = 2.8220e-01, time/batch = 18.3589s	
20412/22950 (epoch 44.471), train_loss = 0.82825854, grad/param norm = 3.0773e-01, time/batch = 16.1906s	
20413/22950 (epoch 44.473), train_loss = 0.82176096, grad/param norm = 2.9040e-01, time/batch = 17.3906s	
20414/22950 (epoch 44.475), train_loss = 0.94419126, grad/param norm = 3.1321e-01, time/batch = 17.7662s	
20415/22950 (epoch 44.477), train_loss = 0.77750416, grad/param norm = 2.7921e-01, time/batch = 18.4505s	
20416/22950 (epoch 44.479), train_loss = 0.69674520, grad/param norm = 2.4497e-01, time/batch = 18.3842s	
20417/22950 (epoch 44.481), train_loss = 0.85360039, grad/param norm = 3.1228e-01, time/batch = 17.8601s	
20418/22950 (epoch 44.484), train_loss = 0.83032496, grad/param norm = 3.0365e-01, time/batch = 19.0523s	
20419/22950 (epoch 44.486), train_loss = 0.69575593, grad/param norm = 2.7283e-01, time/batch = 20.0374s	
20420/22950 (epoch 44.488), train_loss = 0.70703988, grad/param norm = 2.6644e-01, time/batch = 17.8723s	
20421/22950 (epoch 44.490), train_loss = 0.65363726, grad/param norm = 2.4747e-01, time/batch = 20.4579s	
20422/22950 (epoch 44.492), train_loss = 0.77123051, grad/param norm = 2.6502e-01, time/batch = 19.3735s	
20423/22950 (epoch 44.495), train_loss = 0.72889411, grad/param norm = 2.4542e-01, time/batch = 18.7029s	
20424/22950 (epoch 44.497), train_loss = 0.80590065, grad/param norm = 2.5710e-01, time/batch = 20.5323s	
20425/22950 (epoch 44.499), train_loss = 0.89861853, grad/param norm = 2.9795e-01, time/batch = 19.3776s	
20426/22950 (epoch 44.501), train_loss = 0.78672240, grad/param norm = 2.6509e-01, time/batch = 19.1287s	
20427/22950 (epoch 44.503), train_loss = 0.89320559, grad/param norm = 2.5752e-01, time/batch = 16.0996s	
20428/22950 (epoch 44.505), train_loss = 0.67637649, grad/param norm = 2.4061e-01, time/batch = 19.5527s	
20429/22950 (epoch 44.508), train_loss = 0.83317230, grad/param norm = 2.4320e-01, time/batch = 20.0460s	
20430/22950 (epoch 44.510), train_loss = 0.75512901, grad/param norm = 2.6290e-01, time/batch = 17.5962s	
20431/22950 (epoch 44.512), train_loss = 0.65401926, grad/param norm = 2.3405e-01, time/batch = 18.9613s	
20432/22950 (epoch 44.514), train_loss = 0.76678012, grad/param norm = 2.3911e-01, time/batch = 18.2961s	
20433/22950 (epoch 44.516), train_loss = 0.78333386, grad/param norm = 2.6316e-01, time/batch = 18.0215s	
20434/22950 (epoch 44.519), train_loss = 0.79106420, grad/param norm = 2.5176e-01, time/batch = 19.1292s	
20435/22950 (epoch 44.521), train_loss = 0.78697648, grad/param norm = 2.5541e-01, time/batch = 19.1340s	
20436/22950 (epoch 44.523), train_loss = 0.61727349, grad/param norm = 2.2464e-01, time/batch = 17.7663s	
20437/22950 (epoch 44.525), train_loss = 0.69553170, grad/param norm = 2.3473e-01, time/batch = 20.4539s	
20438/22950 (epoch 44.527), train_loss = 0.67885518, grad/param norm = 2.2960e-01, time/batch = 19.9604s	
20439/22950 (epoch 44.529), train_loss = 0.76818612, grad/param norm = 2.3724e-01, time/batch = 18.1162s	
20440/22950 (epoch 44.532), train_loss = 0.74704347, grad/param norm = 2.5330e-01, time/batch = 19.3673s	
20441/22950 (epoch 44.534), train_loss = 0.78615296, grad/param norm = 2.4716e-01, time/batch = 20.4537s	
20442/22950 (epoch 44.536), train_loss = 0.83946455, grad/param norm = 3.8869e-01, time/batch = 18.0359s	
20443/22950 (epoch 44.538), train_loss = 0.77373248, grad/param norm = 2.6683e-01, time/batch = 19.2187s	
20444/22950 (epoch 44.540), train_loss = 0.80536588, grad/param norm = 2.4100e-01, time/batch = 20.2113s	
20445/22950 (epoch 44.542), train_loss = 0.91687047, grad/param norm = 2.7453e-01, time/batch = 17.6692s	
20446/22950 (epoch 44.545), train_loss = 0.77839896, grad/param norm = 2.2448e-01, time/batch = 18.4911s	
20447/22950 (epoch 44.547), train_loss = 0.76438225, grad/param norm = 2.4903e-01, time/batch = 18.5531s	
20448/22950 (epoch 44.549), train_loss = 0.73439650, grad/param norm = 3.0425e-01, time/batch = 17.2809s	
20449/22950 (epoch 44.551), train_loss = 0.74505846, grad/param norm = 2.8598e-01, time/batch = 17.9561s	
20450/22950 (epoch 44.553), train_loss = 0.73584348, grad/param norm = 2.9597e-01, time/batch = 17.2755s	
20451/22950 (epoch 44.556), train_loss = 0.81392588, grad/param norm = 2.5409e-01, time/batch = 20.7823s	
20452/22950 (epoch 44.558), train_loss = 0.65693789, grad/param norm = 2.7594e-01, time/batch = 17.1091s	
20453/22950 (epoch 44.560), train_loss = 0.73867198, grad/param norm = 2.8336e-01, time/batch = 20.6352s	
20454/22950 (epoch 44.562), train_loss = 0.72899742, grad/param norm = 2.2539e-01, time/batch = 20.1245s	
20455/22950 (epoch 44.564), train_loss = 0.79061393, grad/param norm = 2.7263e-01, time/batch = 18.5466s	
20456/22950 (epoch 44.566), train_loss = 0.81301005, grad/param norm = 2.8761e-01, time/batch = 19.5361s	
20457/22950 (epoch 44.569), train_loss = 0.76349627, grad/param norm = 2.4905e-01, time/batch = 19.8862s	
20458/22950 (epoch 44.571), train_loss = 0.72990296, grad/param norm = 2.5051e-01, time/batch = 17.2723s	
20459/22950 (epoch 44.573), train_loss = 0.73251026, grad/param norm = 2.5995e-01, time/batch = 19.1162s	
20460/22950 (epoch 44.575), train_loss = 0.83893259, grad/param norm = 3.1742e-01, time/batch = 18.7925s	
20461/22950 (epoch 44.577), train_loss = 0.79036960, grad/param norm = 3.3873e-01, time/batch = 16.8429s	
20462/22950 (epoch 44.580), train_loss = 0.85796909, grad/param norm = 3.6441e-01, time/batch = 19.0345s	
20463/22950 (epoch 44.582), train_loss = 0.89965585, grad/param norm = 2.8217e-01, time/batch = 18.4643s	
20464/22950 (epoch 44.584), train_loss = 0.70353572, grad/param norm = 3.0867e-01, time/batch = 19.6231s	
20465/22950 (epoch 44.586), train_loss = 0.74587403, grad/param norm = 2.5977e-01, time/batch = 16.5608s	
20466/22950 (epoch 44.588), train_loss = 0.89397501, grad/param norm = 3.1306e-01, time/batch = 18.9557s	
20467/22950 (epoch 44.590), train_loss = 0.87751996, grad/param norm = 2.8153e-01, time/batch = 18.8837s	
20468/22950 (epoch 44.593), train_loss = 0.75365198, grad/param norm = 2.5031e-01, time/batch = 17.7716s	
20469/22950 (epoch 44.595), train_loss = 0.73655403, grad/param norm = 2.7798e-01, time/batch = 18.7220s	
20470/22950 (epoch 44.597), train_loss = 0.83473706, grad/param norm = 3.1376e-01, time/batch = 19.6272s	
20471/22950 (epoch 44.599), train_loss = 0.79854273, grad/param norm = 3.0172e-01, time/batch = 18.8746s	
20472/22950 (epoch 44.601), train_loss = 0.85527707, grad/param norm = 2.6011e-01, time/batch = 19.7904s	
20473/22950 (epoch 44.603), train_loss = 0.89356572, grad/param norm = 2.8625e-01, time/batch = 18.7932s	
20474/22950 (epoch 44.606), train_loss = 0.76091843, grad/param norm = 2.4800e-01, time/batch = 18.1945s	
20475/22950 (epoch 44.608), train_loss = 0.76188605, grad/param norm = 2.5494e-01, time/batch = 18.9582s	
20476/22950 (epoch 44.610), train_loss = 0.76309832, grad/param norm = 2.3599e-01, time/batch = 18.8885s	
20477/22950 (epoch 44.612), train_loss = 0.79916553, grad/param norm = 2.7277e-01, time/batch = 18.7950s	
20478/22950 (epoch 44.614), train_loss = 0.88121954, grad/param norm = 2.8436e-01, time/batch = 15.7707s	
20479/22950 (epoch 44.617), train_loss = 0.78481039, grad/param norm = 2.6639e-01, time/batch = 18.5564s	
20480/22950 (epoch 44.619), train_loss = 0.70794587, grad/param norm = 2.1536e-01, time/batch = 18.7208s	
20481/22950 (epoch 44.621), train_loss = 0.84845549, grad/param norm = 2.4170e-01, time/batch = 18.5356s	
20482/22950 (epoch 44.623), train_loss = 0.83193197, grad/param norm = 3.0704e-01, time/batch = 18.5617s	
20483/22950 (epoch 44.625), train_loss = 0.78353449, grad/param norm = 2.5251e-01, time/batch = 17.4470s	
20484/22950 (epoch 44.627), train_loss = 0.74810718, grad/param norm = 2.7527e-01, time/batch = 17.8690s	
20485/22950 (epoch 44.630), train_loss = 0.68034910, grad/param norm = 2.2733e-01, time/batch = 20.6150s	
20486/22950 (epoch 44.632), train_loss = 0.74794860, grad/param norm = 2.8510e-01, time/batch = 18.3736s	
20487/22950 (epoch 44.634), train_loss = 0.80337977, grad/param norm = 2.9853e-01, time/batch = 18.1836s	
20488/22950 (epoch 44.636), train_loss = 0.78707916, grad/param norm = 2.9198e-01, time/batch = 20.5402s	
20489/22950 (epoch 44.638), train_loss = 0.76844422, grad/param norm = 2.6588e-01, time/batch = 20.1211s	
20490/22950 (epoch 44.641), train_loss = 0.76639694, grad/param norm = 2.7247e-01, time/batch = 18.6312s	
20491/22950 (epoch 44.643), train_loss = 0.82629421, grad/param norm = 3.5563e-01, time/batch = 18.5095s	
20492/22950 (epoch 44.645), train_loss = 0.77565659, grad/param norm = 2.7282e-01, time/batch = 19.8614s	
20493/22950 (epoch 44.647), train_loss = 0.75239081, grad/param norm = 2.9313e-01, time/batch = 18.7702s	
20494/22950 (epoch 44.649), train_loss = 0.68976777, grad/param norm = 2.7224e-01, time/batch = 19.0489s	
20495/22950 (epoch 44.651), train_loss = 0.85395558, grad/param norm = 2.9546e-01, time/batch = 18.8895s	
20496/22950 (epoch 44.654), train_loss = 0.66549650, grad/param norm = 2.2330e-01, time/batch = 18.8844s	
20497/22950 (epoch 44.656), train_loss = 0.83279904, grad/param norm = 2.9943e-01, time/batch = 16.5331s	
20498/22950 (epoch 44.658), train_loss = 0.69311100, grad/param norm = 2.9305e-01, time/batch = 18.0201s	
20499/22950 (epoch 44.660), train_loss = 0.61802695, grad/param norm = 2.6155e-01, time/batch = 18.2176s	
20500/22950 (epoch 44.662), train_loss = 0.65320085, grad/param norm = 2.5130e-01, time/batch = 16.6882s	
20501/22950 (epoch 44.664), train_loss = 0.74366920, grad/param norm = 2.7229e-01, time/batch = 16.4653s	
20502/22950 (epoch 44.667), train_loss = 0.76384094, grad/param norm = 2.5733e-01, time/batch = 19.7281s	
20503/22950 (epoch 44.669), train_loss = 0.77432276, grad/param norm = 2.7836e-01, time/batch = 17.8635s	
20504/22950 (epoch 44.671), train_loss = 0.76913199, grad/param norm = 2.6661e-01, time/batch = 18.7198s	
20505/22950 (epoch 44.673), train_loss = 0.70374253, grad/param norm = 2.6347e-01, time/batch = 19.3027s	
20506/22950 (epoch 44.675), train_loss = 0.80092284, grad/param norm = 2.9040e-01, time/batch = 18.9573s	
20507/22950 (epoch 44.678), train_loss = 0.75946079, grad/param norm = 2.8242e-01, time/batch = 19.3745s	
20508/22950 (epoch 44.680), train_loss = 0.80425588, grad/param norm = 2.4760e-01, time/batch = 19.8019s	
20509/22950 (epoch 44.682), train_loss = 0.76921674, grad/param norm = 2.8092e-01, time/batch = 18.7137s	
20510/22950 (epoch 44.684), train_loss = 0.87637662, grad/param norm = 2.9134e-01, time/batch = 18.2665s	
20511/22950 (epoch 44.686), train_loss = 0.88415236, grad/param norm = 2.7651e-01, time/batch = 19.2260s	
20512/22950 (epoch 44.688), train_loss = 0.77065312, grad/param norm = 2.6104e-01, time/batch = 18.7917s	
20513/22950 (epoch 44.691), train_loss = 0.76152666, grad/param norm = 2.6639e-01, time/batch = 16.7609s	
20514/22950 (epoch 44.693), train_loss = 0.70856959, grad/param norm = 2.6133e-01, time/batch = 17.1893s	
20515/22950 (epoch 44.695), train_loss = 0.85592525, grad/param norm = 2.9919e-01, time/batch = 19.2861s	
20516/22950 (epoch 44.697), train_loss = 0.81535876, grad/param norm = 3.1906e-01, time/batch = 17.3570s	
20517/22950 (epoch 44.699), train_loss = 0.80407550, grad/param norm = 2.6457e-01, time/batch = 19.0361s	
20518/22950 (epoch 44.702), train_loss = 0.84898664, grad/param norm = 3.1424e-01, time/batch = 18.5539s	
20519/22950 (epoch 44.704), train_loss = 0.94028585, grad/param norm = 3.3921e-01, time/batch = 18.0484s	
20520/22950 (epoch 44.706), train_loss = 0.85690768, grad/param norm = 2.8720e-01, time/batch = 18.8761s	
20521/22950 (epoch 44.708), train_loss = 0.70024592, grad/param norm = 3.6835e-01, time/batch = 18.2013s	
20522/22950 (epoch 44.710), train_loss = 0.77913899, grad/param norm = 2.5930e-01, time/batch = 17.1221s	
20523/22950 (epoch 44.712), train_loss = 0.91919258, grad/param norm = 3.6439e-01, time/batch = 18.2077s	
20524/22950 (epoch 44.715), train_loss = 0.82620926, grad/param norm = 3.3172e-01, time/batch = 19.8816s	
20525/22950 (epoch 44.717), train_loss = 0.82844393, grad/param norm = 2.5456e-01, time/batch = 19.6312s	
20526/22950 (epoch 44.719), train_loss = 0.77803741, grad/param norm = 2.6760e-01, time/batch = 17.8648s	
20527/22950 (epoch 44.721), train_loss = 0.86166762, grad/param norm = 2.9660e-01, time/batch = 18.7973s	
20528/22950 (epoch 44.723), train_loss = 0.80297868, grad/param norm = 2.6269e-01, time/batch = 19.6137s	
20529/22950 (epoch 44.725), train_loss = 0.86107229, grad/param norm = 3.2398e-01, time/batch = 17.2121s	
20530/22950 (epoch 44.728), train_loss = 0.79204497, grad/param norm = 3.0136e-01, time/batch = 18.6036s	
20531/22950 (epoch 44.730), train_loss = 0.81422342, grad/param norm = 2.9996e-01, time/batch = 20.2984s	
20532/22950 (epoch 44.732), train_loss = 0.88527703, grad/param norm = 2.9739e-01, time/batch = 17.5192s	
20533/22950 (epoch 44.734), train_loss = 0.73967652, grad/param norm = 2.7057e-01, time/batch = 18.3778s	
20534/22950 (epoch 44.736), train_loss = 0.83692898, grad/param norm = 2.7301e-01, time/batch = 18.4545s	
20535/22950 (epoch 44.739), train_loss = 0.86247182, grad/param norm = 3.3615e-01, time/batch = 16.9351s	
20536/22950 (epoch 44.741), train_loss = 0.86762443, grad/param norm = 2.8730e-01, time/batch = 18.1952s	
20537/22950 (epoch 44.743), train_loss = 0.95191213, grad/param norm = 3.8766e-01, time/batch = 19.0405s	
20538/22950 (epoch 44.745), train_loss = 1.01238066, grad/param norm = 3.2289e-01, time/batch = 19.6071s	
20539/22950 (epoch 44.747), train_loss = 0.88246290, grad/param norm = 2.8366e-01, time/batch = 16.7869s	
20540/22950 (epoch 44.749), train_loss = 0.73817875, grad/param norm = 2.6239e-01, time/batch = 19.6991s	
20541/22950 (epoch 44.752), train_loss = 0.96431114, grad/param norm = 3.0588e-01, time/batch = 20.6968s	
20542/22950 (epoch 44.754), train_loss = 0.85033881, grad/param norm = 2.9722e-01, time/batch = 17.7086s	
20543/22950 (epoch 44.756), train_loss = 0.77279230, grad/param norm = 2.5285e-01, time/batch = 16.6061s	
20544/22950 (epoch 44.758), train_loss = 0.83626973, grad/param norm = 2.5327e-01, time/batch = 18.2937s	
20545/22950 (epoch 44.760), train_loss = 0.79504636, grad/param norm = 3.0125e-01, time/batch = 18.7641s	
20546/22950 (epoch 44.763), train_loss = 0.82495915, grad/param norm = 2.6825e-01, time/batch = 19.9555s	
20547/22950 (epoch 44.765), train_loss = 0.81810692, grad/param norm = 3.1338e-01, time/batch = 17.8862s	
20548/22950 (epoch 44.767), train_loss = 0.98606145, grad/param norm = 3.2921e-01, time/batch = 18.5289s	
20549/22950 (epoch 44.769), train_loss = 0.84952592, grad/param norm = 2.8525e-01, time/batch = 18.7851s	
20550/22950 (epoch 44.771), train_loss = 0.73719940, grad/param norm = 3.2033e-01, time/batch = 19.7967s	
20551/22950 (epoch 44.773), train_loss = 0.62251760, grad/param norm = 2.5420e-01, time/batch = 17.8640s	
20552/22950 (epoch 44.776), train_loss = 0.74865418, grad/param norm = 2.4380e-01, time/batch = 19.2067s	
20553/22950 (epoch 44.778), train_loss = 0.72794531, grad/param norm = 2.8892e-01, time/batch = 17.0258s	
20554/22950 (epoch 44.780), train_loss = 0.81420567, grad/param norm = 2.7191e-01, time/batch = 16.4527s	
20555/22950 (epoch 44.782), train_loss = 0.86895049, grad/param norm = 2.8610e-01, time/batch = 16.9302s	
20556/22950 (epoch 44.784), train_loss = 0.75469203, grad/param norm = 2.7166e-01, time/batch = 19.4723s	
20557/22950 (epoch 44.786), train_loss = 0.79733943, grad/param norm = 2.4742e-01, time/batch = 18.2877s	
20558/22950 (epoch 44.789), train_loss = 0.66665959, grad/param norm = 2.7031e-01, time/batch = 17.6260s	
20559/22950 (epoch 44.791), train_loss = 0.70113804, grad/param norm = 3.3367e-01, time/batch = 18.3864s	
20560/22950 (epoch 44.793), train_loss = 0.89798014, grad/param norm = 3.0027e-01, time/batch = 17.7131s	
20561/22950 (epoch 44.795), train_loss = 0.75630471, grad/param norm = 2.3287e-01, time/batch = 18.1261s	
20562/22950 (epoch 44.797), train_loss = 0.90558629, grad/param norm = 2.8480e-01, time/batch = 15.9136s	
20563/22950 (epoch 44.800), train_loss = 0.77610513, grad/param norm = 2.8385e-01, time/batch = 19.8027s	
20564/22950 (epoch 44.802), train_loss = 0.78134003, grad/param norm = 2.7868e-01, time/batch = 18.2268s	
20565/22950 (epoch 44.804), train_loss = 0.80457546, grad/param norm = 2.7083e-01, time/batch = 16.8623s	
20566/22950 (epoch 44.806), train_loss = 0.68450852, grad/param norm = 2.5307e-01, time/batch = 19.4640s	
20567/22950 (epoch 44.808), train_loss = 0.83859271, grad/param norm = 2.4259e-01, time/batch = 18.4587s	
20568/22950 (epoch 44.810), train_loss = 0.74098202, grad/param norm = 2.6378e-01, time/batch = 17.5254s	
20569/22950 (epoch 44.813), train_loss = 0.68928977, grad/param norm = 2.6804e-01, time/batch = 18.3809s	
20570/22950 (epoch 44.815), train_loss = 0.63079366, grad/param norm = 2.7262e-01, time/batch = 19.5467s	
20571/22950 (epoch 44.817), train_loss = 0.70468882, grad/param norm = 2.5017e-01, time/batch = 16.8428s	
20572/22950 (epoch 44.819), train_loss = 0.74028708, grad/param norm = 2.8392e-01, time/batch = 18.2971s	
20573/22950 (epoch 44.821), train_loss = 0.75417541, grad/param norm = 3.6481e-01, time/batch = 20.2825s	
20574/22950 (epoch 44.824), train_loss = 0.80426592, grad/param norm = 2.7812e-01, time/batch = 19.0343s	
20575/22950 (epoch 44.826), train_loss = 0.81771503, grad/param norm = 2.7747e-01, time/batch = 19.8443s	
20576/22950 (epoch 44.828), train_loss = 0.73047684, grad/param norm = 2.9977e-01, time/batch = 18.6390s	
20577/22950 (epoch 44.830), train_loss = 0.74110423, grad/param norm = 2.8551e-01, time/batch = 18.7929s	
20578/22950 (epoch 44.832), train_loss = 0.81611879, grad/param norm = 2.7493e-01, time/batch = 17.6039s	
20579/22950 (epoch 44.834), train_loss = 0.62821934, grad/param norm = 2.4335e-01, time/batch = 19.2281s	
20580/22950 (epoch 44.837), train_loss = 0.80615678, grad/param norm = 3.0309e-01, time/batch = 20.4703s	
20581/22950 (epoch 44.839), train_loss = 0.66776416, grad/param norm = 2.5918e-01, time/batch = 18.1101s	
20582/22950 (epoch 44.841), train_loss = 0.75311269, grad/param norm = 2.6753e-01, time/batch = 19.4723s	
20583/22950 (epoch 44.843), train_loss = 0.73684731, grad/param norm = 2.5925e-01, time/batch = 19.1270s	
20584/22950 (epoch 44.845), train_loss = 0.76965478, grad/param norm = 2.6036e-01, time/batch = 16.9699s	
20585/22950 (epoch 44.847), train_loss = 0.79995682, grad/param norm = 2.8900e-01, time/batch = 20.1322s	
20586/22950 (epoch 44.850), train_loss = 0.85088605, grad/param norm = 3.0072e-01, time/batch = 20.2120s	
20587/22950 (epoch 44.852), train_loss = 0.84996878, grad/param norm = 3.0207e-01, time/batch = 18.0277s	
20588/22950 (epoch 44.854), train_loss = 0.79274269, grad/param norm = 2.7343e-01, time/batch = 16.5092s	
20589/22950 (epoch 44.856), train_loss = 0.87757298, grad/param norm = 3.0887e-01, time/batch = 18.7982s	
20590/22950 (epoch 44.858), train_loss = 0.85120258, grad/param norm = 2.5635e-01, time/batch = 20.0088s	
20591/22950 (epoch 44.861), train_loss = 0.82395882, grad/param norm = 2.7110e-01, time/batch = 30.8406s	
20592/22950 (epoch 44.863), train_loss = 0.86400056, grad/param norm = 3.1665e-01, time/batch = 17.5198s	
20593/22950 (epoch 44.865), train_loss = 0.92313584, grad/param norm = 2.9332e-01, time/batch = 17.2197s	
20594/22950 (epoch 44.867), train_loss = 0.80945082, grad/param norm = 2.9387e-01, time/batch = 19.4677s	
20595/22950 (epoch 44.869), train_loss = 0.95092968, grad/param norm = 2.8934e-01, time/batch = 19.1054s	
20596/22950 (epoch 44.871), train_loss = 0.81326344, grad/param norm = 3.2022e-01, time/batch = 17.1141s	
20597/22950 (epoch 44.874), train_loss = 0.81869131, grad/param norm = 2.3444e-01, time/batch = 19.7771s	
20598/22950 (epoch 44.876), train_loss = 0.90931946, grad/param norm = 3.3365e-01, time/batch = 18.7095s	
20599/22950 (epoch 44.878), train_loss = 0.83750887, grad/param norm = 2.6878e-01, time/batch = 16.2011s	
20600/22950 (epoch 44.880), train_loss = 0.95211081, grad/param norm = 2.9504e-01, time/batch = 19.1302s	
20601/22950 (epoch 44.882), train_loss = 0.71847055, grad/param norm = 2.5416e-01, time/batch = 18.4601s	
20602/22950 (epoch 44.885), train_loss = 0.82322758, grad/param norm = 2.6033e-01, time/batch = 19.1965s	
20603/22950 (epoch 44.887), train_loss = 0.78056283, grad/param norm = 2.2957e-01, time/batch = 18.7652s	
20604/22950 (epoch 44.889), train_loss = 0.82760209, grad/param norm = 2.6518e-01, time/batch = 20.1236s	
20605/22950 (epoch 44.891), train_loss = 0.72178105, grad/param norm = 2.2666e-01, time/batch = 19.2876s	
20606/22950 (epoch 44.893), train_loss = 0.79991784, grad/param norm = 2.4670e-01, time/batch = 16.6885s	
20607/22950 (epoch 44.895), train_loss = 0.93679396, grad/param norm = 2.6669e-01, time/batch = 19.8661s	
20608/22950 (epoch 44.898), train_loss = 0.85560792, grad/param norm = 2.5406e-01, time/batch = 18.1132s	
20609/22950 (epoch 44.900), train_loss = 0.74189236, grad/param norm = 2.4624e-01, time/batch = 17.2832s	
20610/22950 (epoch 44.902), train_loss = 0.80365835, grad/param norm = 2.8078e-01, time/batch = 18.6990s	
20611/22950 (epoch 44.904), train_loss = 0.79867730, grad/param norm = 2.7552e-01, time/batch = 18.5240s	
20612/22950 (epoch 44.906), train_loss = 0.81829079, grad/param norm = 3.2166e-01, time/batch = 18.0851s	
20613/22950 (epoch 44.908), train_loss = 0.72604604, grad/param norm = 2.8616e-01, time/batch = 19.4608s	
20614/22950 (epoch 44.911), train_loss = 0.65337011, grad/param norm = 2.3015e-01, time/batch = 19.5242s	
20615/22950 (epoch 44.913), train_loss = 0.79557354, grad/param norm = 2.3572e-01, time/batch = 19.1110s	
20616/22950 (epoch 44.915), train_loss = 0.89694691, grad/param norm = 2.9460e-01, time/batch = 16.8837s	
20617/22950 (epoch 44.917), train_loss = 0.71003861, grad/param norm = 2.2862e-01, time/batch = 19.4614s	
20618/22950 (epoch 44.919), train_loss = 0.81309257, grad/param norm = 2.6850e-01, time/batch = 19.3794s	
20619/22950 (epoch 44.922), train_loss = 0.78937795, grad/param norm = 2.5696e-01, time/batch = 17.8522s	
20620/22950 (epoch 44.924), train_loss = 0.84680449, grad/param norm = 2.8884e-01, time/batch = 19.8038s	
20621/22950 (epoch 44.926), train_loss = 0.67289010, grad/param norm = 2.6309e-01, time/batch = 17.3016s	
20622/22950 (epoch 44.928), train_loss = 0.70292930, grad/param norm = 2.2131e-01, time/batch = 17.0907s	
20623/22950 (epoch 44.930), train_loss = 0.70489787, grad/param norm = 2.4158e-01, time/batch = 19.2295s	
20624/22950 (epoch 44.932), train_loss = 0.64838141, grad/param norm = 2.1768e-01, time/batch = 17.4761s	
20625/22950 (epoch 44.935), train_loss = 0.84509162, grad/param norm = 2.5706e-01, time/batch = 19.2183s	
20626/22950 (epoch 44.937), train_loss = 0.78196231, grad/param norm = 2.9584e-01, time/batch = 19.3078s	
20627/22950 (epoch 44.939), train_loss = 0.74021027, grad/param norm = 2.7143e-01, time/batch = 18.3826s	
20628/22950 (epoch 44.941), train_loss = 0.76475507, grad/param norm = 2.7247e-01, time/batch = 17.8572s	
20629/22950 (epoch 44.943), train_loss = 0.79435475, grad/param norm = 2.6766e-01, time/batch = 19.7181s	
20630/22950 (epoch 44.946), train_loss = 0.64803153, grad/param norm = 3.0302e-01, time/batch = 18.7941s	
20631/22950 (epoch 44.948), train_loss = 0.86717047, grad/param norm = 2.7773e-01, time/batch = 19.1123s	
20632/22950 (epoch 44.950), train_loss = 0.79056077, grad/param norm = 3.2633e-01, time/batch = 19.7861s	
20633/22950 (epoch 44.952), train_loss = 0.85056407, grad/param norm = 3.1529e-01, time/batch = 17.6245s	
20634/22950 (epoch 44.954), train_loss = 0.82722277, grad/param norm = 2.7722e-01, time/batch = 19.2187s	
20635/22950 (epoch 44.956), train_loss = 0.73433936, grad/param norm = 2.8970e-01, time/batch = 18.3631s	
20636/22950 (epoch 44.959), train_loss = 0.71533855, grad/param norm = 2.2336e-01, time/batch = 20.0522s	
20637/22950 (epoch 44.961), train_loss = 0.78229398, grad/param norm = 2.4512e-01, time/batch = 18.5504s	
20638/22950 (epoch 44.963), train_loss = 0.78197425, grad/param norm = 2.6905e-01, time/batch = 17.4989s	
20639/22950 (epoch 44.965), train_loss = 0.85897609, grad/param norm = 2.9888e-01, time/batch = 19.7038s	
20640/22950 (epoch 44.967), train_loss = 0.74023235, grad/param norm = 2.4578e-01, time/batch = 18.9493s	
20641/22950 (epoch 44.969), train_loss = 0.68422176, grad/param norm = 3.0896e-01, time/batch = 18.8699s	
20642/22950 (epoch 44.972), train_loss = 0.75076303, grad/param norm = 2.4707e-01, time/batch = 19.1218s	
20643/22950 (epoch 44.974), train_loss = 0.74386453, grad/param norm = 2.5063e-01, time/batch = 19.5214s	
20644/22950 (epoch 44.976), train_loss = 0.79952554, grad/param norm = 2.6582e-01, time/batch = 17.5302s	
20645/22950 (epoch 44.978), train_loss = 0.71005845, grad/param norm = 2.5636e-01, time/batch = 17.1784s	
20646/22950 (epoch 44.980), train_loss = 0.72871179, grad/param norm = 2.7813e-01, time/batch = 20.2909s	
20647/22950 (epoch 44.983), train_loss = 0.85726150, grad/param norm = 2.6680e-01, time/batch = 18.3505s	
20648/22950 (epoch 44.985), train_loss = 0.73702062, grad/param norm = 2.7892e-01, time/batch = 20.1151s	
20649/22950 (epoch 44.987), train_loss = 0.71553913, grad/param norm = 2.4591e-01, time/batch = 20.2911s	
20650/22950 (epoch 44.989), train_loss = 0.78572540, grad/param norm = 2.6154e-01, time/batch = 18.3657s	
20651/22950 (epoch 44.991), train_loss = 0.67944520, grad/param norm = 2.4643e-01, time/batch = 19.5484s	
20652/22950 (epoch 44.993), train_loss = 0.78454700, grad/param norm = 2.4053e-01, time/batch = 18.2143s	
20653/22950 (epoch 44.996), train_loss = 0.76265503, grad/param norm = 3.1043e-01, time/batch = 16.2852s	
20654/22950 (epoch 44.998), train_loss = 0.69525518, grad/param norm = 2.8981e-01, time/batch = 18.6675s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
20655/22950 (epoch 45.000), train_loss = 0.65689902, grad/param norm = 2.2543e-01, time/batch = 18.6118s	
20656/22950 (epoch 45.002), train_loss = 0.93105757, grad/param norm = 2.9776e-01, time/batch = 19.2845s	
20657/22950 (epoch 45.004), train_loss = 0.82946640, grad/param norm = 2.4750e-01, time/batch = 16.6797s	
20658/22950 (epoch 45.007), train_loss = 0.77334845, grad/param norm = 3.0674e-01, time/batch = 18.0737s	
20659/22950 (epoch 45.009), train_loss = 0.91333111, grad/param norm = 3.0225e-01, time/batch = 19.0424s	
20660/22950 (epoch 45.011), train_loss = 0.66544285, grad/param norm = 2.6139e-01, time/batch = 17.1889s	
20661/22950 (epoch 45.013), train_loss = 0.74227669, grad/param norm = 2.7136e-01, time/batch = 20.6181s	
20662/22950 (epoch 45.015), train_loss = 0.80820772, grad/param norm = 3.3691e-01, time/batch = 18.5384s	
20663/22950 (epoch 45.017), train_loss = 0.78481310, grad/param norm = 2.6039e-01, time/batch = 19.1154s	
20664/22950 (epoch 45.020), train_loss = 0.81122146, grad/param norm = 2.4437e-01, time/batch = 20.8739s	
20665/22950 (epoch 45.022), train_loss = 0.69528445, grad/param norm = 2.7154e-01, time/batch = 19.6266s	
20666/22950 (epoch 45.024), train_loss = 0.74003978, grad/param norm = 2.5342e-01, time/batch = 17.8390s	
20667/22950 (epoch 45.026), train_loss = 0.82145325, grad/param norm = 2.6166e-01, time/batch = 18.3409s	
20668/22950 (epoch 45.028), train_loss = 0.82151252, grad/param norm = 2.5778e-01, time/batch = 20.0311s	
20669/22950 (epoch 45.031), train_loss = 0.74263082, grad/param norm = 2.4349e-01, time/batch = 20.0189s	
20670/22950 (epoch 45.033), train_loss = 0.84712508, grad/param norm = 2.7484e-01, time/batch = 19.1201s	
20671/22950 (epoch 45.035), train_loss = 0.77980945, grad/param norm = 2.2417e-01, time/batch = 18.8915s	
20672/22950 (epoch 45.037), train_loss = 0.78188721, grad/param norm = 2.3912e-01, time/batch = 19.7841s	
20673/22950 (epoch 45.039), train_loss = 0.77116444, grad/param norm = 2.6186e-01, time/batch = 19.2879s	
20674/22950 (epoch 45.041), train_loss = 0.71090686, grad/param norm = 2.8518e-01, time/batch = 18.6391s	
20675/22950 (epoch 45.044), train_loss = 0.81934781, grad/param norm = 3.3697e-01, time/batch = 19.1334s	
20676/22950 (epoch 45.046), train_loss = 0.77735040, grad/param norm = 2.7440e-01, time/batch = 17.6811s	
20677/22950 (epoch 45.048), train_loss = 0.78331052, grad/param norm = 2.5756e-01, time/batch = 19.9650s	
20678/22950 (epoch 45.050), train_loss = 0.74290915, grad/param norm = 3.1153e-01, time/batch = 19.6403s	
20679/22950 (epoch 45.052), train_loss = 0.80286520, grad/param norm = 2.6365e-01, time/batch = 17.7088s	
20680/22950 (epoch 45.054), train_loss = 0.91482468, grad/param norm = 3.1480e-01, time/batch = 19.4592s	
20681/22950 (epoch 45.057), train_loss = 0.91116653, grad/param norm = 2.7376e-01, time/batch = 19.5343s	
20682/22950 (epoch 45.059), train_loss = 0.90766423, grad/param norm = 2.8665e-01, time/batch = 16.1835s	
20683/22950 (epoch 45.061), train_loss = 0.73470701, grad/param norm = 2.5163e-01, time/batch = 18.5363s	
20684/22950 (epoch 45.063), train_loss = 0.84626893, grad/param norm = 2.9347e-01, time/batch = 19.7869s	
20685/22950 (epoch 45.065), train_loss = 0.70325540, grad/param norm = 2.4929e-01, time/batch = 18.4474s	
20686/22950 (epoch 45.068), train_loss = 0.79612001, grad/param norm = 2.6040e-01, time/batch = 19.5318s	
20687/22950 (epoch 45.070), train_loss = 0.70380436, grad/param norm = 2.1596e-01, time/batch = 18.8719s	
20688/22950 (epoch 45.072), train_loss = 0.83961535, grad/param norm = 3.1949e-01, time/batch = 18.9519s	
20689/22950 (epoch 45.074), train_loss = 0.83701966, grad/param norm = 2.7189e-01, time/batch = 18.0492s	
20690/22950 (epoch 45.076), train_loss = 0.82326972, grad/param norm = 2.8523e-01, time/batch = 17.8109s	
20691/22950 (epoch 45.078), train_loss = 0.87765560, grad/param norm = 2.8378e-01, time/batch = 18.3787s	
20692/22950 (epoch 45.081), train_loss = 0.91007524, grad/param norm = 2.8805e-01, time/batch = 16.6245s	
20693/22950 (epoch 45.083), train_loss = 0.82449593, grad/param norm = 2.9548e-01, time/batch = 17.6178s	
20694/22950 (epoch 45.085), train_loss = 0.68618080, grad/param norm = 2.5027e-01, time/batch = 18.8830s	
20695/22950 (epoch 45.087), train_loss = 0.71648515, grad/param norm = 2.8752e-01, time/batch = 17.4456s	
20696/22950 (epoch 45.089), train_loss = 0.81305177, grad/param norm = 2.9948e-01, time/batch = 18.7243s	
20697/22950 (epoch 45.092), train_loss = 0.73412773, grad/param norm = 3.0344e-01, time/batch = 17.3818s	
20698/22950 (epoch 45.094), train_loss = 0.74601757, grad/param norm = 3.3394e-01, time/batch = 17.2719s	
20699/22950 (epoch 45.096), train_loss = 0.91180870, grad/param norm = 3.1712e-01, time/batch = 19.0471s	
20700/22950 (epoch 45.098), train_loss = 0.83690241, grad/param norm = 2.6213e-01, time/batch = 18.6233s	
20701/22950 (epoch 45.100), train_loss = 0.78673580, grad/param norm = 2.6486e-01, time/batch = 18.8033s	
20702/22950 (epoch 45.102), train_loss = 0.80992930, grad/param norm = 3.2815e-01, time/batch = 18.5260s	
20703/22950 (epoch 45.105), train_loss = 0.66896456, grad/param norm = 2.4264e-01, time/batch = 16.9669s	
20704/22950 (epoch 45.107), train_loss = 0.72457799, grad/param norm = 2.4533e-01, time/batch = 19.2830s	
20705/22950 (epoch 45.109), train_loss = 0.75737332, grad/param norm = 2.5570e-01, time/batch = 17.9545s	
20706/22950 (epoch 45.111), train_loss = 0.64963494, grad/param norm = 2.3834e-01, time/batch = 18.8087s	
20707/22950 (epoch 45.113), train_loss = 0.83192071, grad/param norm = 2.6039e-01, time/batch = 20.7079s	
20708/22950 (epoch 45.115), train_loss = 0.78677319, grad/param norm = 2.7498e-01, time/batch = 17.6030s	
20709/22950 (epoch 45.118), train_loss = 0.88025889, grad/param norm = 2.5623e-01, time/batch = 20.6201s	
20710/22950 (epoch 45.120), train_loss = 0.70517404, grad/param norm = 2.4641e-01, time/batch = 17.8644s	
20711/22950 (epoch 45.122), train_loss = 0.86084754, grad/param norm = 2.6366e-01, time/batch = 18.7864s	
20712/22950 (epoch 45.124), train_loss = 0.69541408, grad/param norm = 2.2141e-01, time/batch = 19.6975s	
20713/22950 (epoch 45.126), train_loss = 0.76628469, grad/param norm = 2.3781e-01, time/batch = 17.5198s	
20714/22950 (epoch 45.129), train_loss = 0.72317747, grad/param norm = 2.1356e-01, time/batch = 18.5465s	
20715/22950 (epoch 45.131), train_loss = 0.76731129, grad/param norm = 2.7617e-01, time/batch = 20.6274s	
20716/22950 (epoch 45.133), train_loss = 0.82817052, grad/param norm = 2.7234e-01, time/batch = 18.2946s	
20717/22950 (epoch 45.135), train_loss = 0.80460063, grad/param norm = 2.2624e-01, time/batch = 18.7932s	
20718/22950 (epoch 45.137), train_loss = 0.82787976, grad/param norm = 2.8341e-01, time/batch = 18.3320s	
20719/22950 (epoch 45.139), train_loss = 0.74311535, grad/param norm = 2.6230e-01, time/batch = 19.0419s	
20720/22950 (epoch 45.142), train_loss = 0.71904322, grad/param norm = 2.2697e-01, time/batch = 19.0551s	
20721/22950 (epoch 45.144), train_loss = 0.76131628, grad/param norm = 2.5214e-01, time/batch = 16.9378s	
20722/22950 (epoch 45.146), train_loss = 0.70320822, grad/param norm = 2.3849e-01, time/batch = 19.1340s	
20723/22950 (epoch 45.148), train_loss = 0.69806281, grad/param norm = 2.2918e-01, time/batch = 18.7835s	
20724/22950 (epoch 45.150), train_loss = 0.79201982, grad/param norm = 2.7960e-01, time/batch = 16.5818s	
20725/22950 (epoch 45.153), train_loss = 0.68502042, grad/param norm = 2.4434e-01, time/batch = 18.2248s	
20726/22950 (epoch 45.155), train_loss = 0.72921824, grad/param norm = 2.3073e-01, time/batch = 19.1266s	
20727/22950 (epoch 45.157), train_loss = 0.75411239, grad/param norm = 2.3950e-01, time/batch = 18.3626s	
20728/22950 (epoch 45.159), train_loss = 0.68868101, grad/param norm = 2.3167e-01, time/batch = 18.6824s	
20729/22950 (epoch 45.161), train_loss = 0.73781270, grad/param norm = 2.6075e-01, time/batch = 19.1170s	
20730/22950 (epoch 45.163), train_loss = 0.68730669, grad/param norm = 2.5676e-01, time/batch = 17.3606s	
20731/22950 (epoch 45.166), train_loss = 0.80048298, grad/param norm = 3.2846e-01, time/batch = 18.6312s	
20732/22950 (epoch 45.168), train_loss = 0.78587165, grad/param norm = 2.6431e-01, time/batch = 18.3924s	
20733/22950 (epoch 45.170), train_loss = 0.79070150, grad/param norm = 2.6665e-01, time/batch = 20.7869s	
20734/22950 (epoch 45.172), train_loss = 0.76464173, grad/param norm = 2.5338e-01, time/batch = 18.5938s	
20735/22950 (epoch 45.174), train_loss = 0.84710799, grad/param norm = 2.4621e-01, time/batch = 19.3076s	
20736/22950 (epoch 45.176), train_loss = 0.82487636, grad/param norm = 2.7050e-01, time/batch = 19.2046s	
20737/22950 (epoch 45.179), train_loss = 0.82740513, grad/param norm = 2.9807e-01, time/batch = 16.6170s	
20738/22950 (epoch 45.181), train_loss = 1.00058056, grad/param norm = 2.8423e-01, time/batch = 18.4301s	
20739/22950 (epoch 45.183), train_loss = 0.81930055, grad/param norm = 2.6891e-01, time/batch = 19.8803s	
20740/22950 (epoch 45.185), train_loss = 0.83943851, grad/param norm = 2.9049e-01, time/batch = 17.9412s	
20741/22950 (epoch 45.187), train_loss = 0.70458773, grad/param norm = 2.5626e-01, time/batch = 19.5326s	
20742/22950 (epoch 45.190), train_loss = 0.61596294, grad/param norm = 2.6193e-01, time/batch = 19.2063s	
20743/22950 (epoch 45.192), train_loss = 0.62157599, grad/param norm = 2.7471e-01, time/batch = 19.2796s	
20744/22950 (epoch 45.194), train_loss = 0.74569784, grad/param norm = 2.6765e-01, time/batch = 18.6200s	
20745/22950 (epoch 45.196), train_loss = 0.57281496, grad/param norm = 2.7101e-01, time/batch = 18.6203s	
20746/22950 (epoch 45.198), train_loss = 0.78853804, grad/param norm = 2.9663e-01, time/batch = 18.6852s	
20747/22950 (epoch 45.200), train_loss = 0.71867526, grad/param norm = 2.4919e-01, time/batch = 19.3725s	
20748/22950 (epoch 45.203), train_loss = 0.65286083, grad/param norm = 2.2809e-01, time/batch = 18.8697s	
20749/22950 (epoch 45.205), train_loss = 0.72530436, grad/param norm = 2.7204e-01, time/batch = 18.6258s	
20750/22950 (epoch 45.207), train_loss = 0.79569615, grad/param norm = 2.6147e-01, time/batch = 18.1153s	
20751/22950 (epoch 45.209), train_loss = 0.74953875, grad/param norm = 3.0887e-01, time/batch = 18.0205s	
20752/22950 (epoch 45.211), train_loss = 0.64180104, grad/param norm = 2.5241e-01, time/batch = 19.0442s	
20753/22950 (epoch 45.214), train_loss = 0.71400510, grad/param norm = 2.5002e-01, time/batch = 16.5540s	
20754/22950 (epoch 45.216), train_loss = 0.85654135, grad/param norm = 2.6794e-01, time/batch = 17.3396s	
20755/22950 (epoch 45.218), train_loss = 0.75099126, grad/param norm = 2.2687e-01, time/batch = 19.0500s	
20756/22950 (epoch 45.220), train_loss = 0.83912772, grad/param norm = 3.1040e-01, time/batch = 17.6794s	
20757/22950 (epoch 45.222), train_loss = 0.85162941, grad/param norm = 3.2645e-01, time/batch = 18.1317s	
20758/22950 (epoch 45.224), train_loss = 0.76070558, grad/param norm = 2.9439e-01, time/batch = 19.5508s	
20759/22950 (epoch 45.227), train_loss = 0.83054531, grad/param norm = 2.5710e-01, time/batch = 17.5489s	
20760/22950 (epoch 45.229), train_loss = 0.88676984, grad/param norm = 2.7719e-01, time/batch = 18.1223s	
20761/22950 (epoch 45.231), train_loss = 0.59828631, grad/param norm = 2.3432e-01, time/batch = 19.6154s	
20762/22950 (epoch 45.233), train_loss = 0.72825256, grad/param norm = 2.6012e-01, time/batch = 18.9642s	
20763/22950 (epoch 45.235), train_loss = 0.88161656, grad/param norm = 2.6800e-01, time/batch = 19.3780s	
20764/22950 (epoch 45.237), train_loss = 0.72889252, grad/param norm = 2.1392e-01, time/batch = 18.0512s	
20765/22950 (epoch 45.240), train_loss = 0.77892788, grad/param norm = 2.6964e-01, time/batch = 19.3051s	
20766/22950 (epoch 45.242), train_loss = 0.88970842, grad/param norm = 2.5423e-01, time/batch = 17.6149s	
20767/22950 (epoch 45.244), train_loss = 0.90100470, grad/param norm = 3.1435e-01, time/batch = 19.9594s	
20768/22950 (epoch 45.246), train_loss = 0.88399149, grad/param norm = 2.7255e-01, time/batch = 18.4684s	
20769/22950 (epoch 45.248), train_loss = 0.80474475, grad/param norm = 2.8783e-01, time/batch = 18.1995s	
20770/22950 (epoch 45.251), train_loss = 0.74143199, grad/param norm = 2.7670e-01, time/batch = 18.7197s	
20771/22950 (epoch 45.253), train_loss = 0.69427217, grad/param norm = 2.5920e-01, time/batch = 21.0960s	
20772/22950 (epoch 45.255), train_loss = 0.80214998, grad/param norm = 2.7399e-01, time/batch = 17.1969s	
20773/22950 (epoch 45.257), train_loss = 0.86715461, grad/param norm = 2.9593e-01, time/batch = 19.0364s	
20774/22950 (epoch 45.259), train_loss = 0.65830771, grad/param norm = 2.2907e-01, time/batch = 18.4543s	
20775/22950 (epoch 45.261), train_loss = 0.67970127, grad/param norm = 2.4939e-01, time/batch = 17.1778s	
20776/22950 (epoch 45.264), train_loss = 0.68348816, grad/param norm = 2.3008e-01, time/batch = 19.0192s	
20777/22950 (epoch 45.266), train_loss = 0.71760220, grad/param norm = 2.3988e-01, time/batch = 18.1922s	
20778/22950 (epoch 45.268), train_loss = 0.75007958, grad/param norm = 2.9078e-01, time/batch = 19.8377s	
20779/22950 (epoch 45.270), train_loss = 0.75347537, grad/param norm = 2.4892e-01, time/batch = 20.9449s	
20780/22950 (epoch 45.272), train_loss = 0.77252968, grad/param norm = 2.4288e-01, time/batch = 18.3819s	
20781/22950 (epoch 45.275), train_loss = 0.73543008, grad/param norm = 2.8039e-01, time/batch = 20.2644s	
20782/22950 (epoch 45.277), train_loss = 0.65029459, grad/param norm = 2.5129e-01, time/batch = 31.5468s	
20783/22950 (epoch 45.279), train_loss = 0.66926850, grad/param norm = 2.6953e-01, time/batch = 20.1308s	
20784/22950 (epoch 45.281), train_loss = 0.74648780, grad/param norm = 2.7454e-01, time/batch = 18.1090s	
20785/22950 (epoch 45.283), train_loss = 0.66139650, grad/param norm = 2.2280e-01, time/batch = 19.3054s	
20786/22950 (epoch 45.285), train_loss = 0.76932002, grad/param norm = 2.3981e-01, time/batch = 19.8571s	
20787/22950 (epoch 45.288), train_loss = 0.87142751, grad/param norm = 2.8007e-01, time/batch = 16.9280s	
20788/22950 (epoch 45.290), train_loss = 0.73273098, grad/param norm = 2.4853e-01, time/batch = 19.3513s	
20789/22950 (epoch 45.292), train_loss = 0.87452443, grad/param norm = 2.9009e-01, time/batch = 19.9525s	
20790/22950 (epoch 45.294), train_loss = 0.80818494, grad/param norm = 2.3006e-01, time/batch = 18.5392s	
20791/22950 (epoch 45.296), train_loss = 0.60930698, grad/param norm = 2.0629e-01, time/batch = 19.7125s	
20792/22950 (epoch 45.298), train_loss = 0.74205897, grad/param norm = 2.5552e-01, time/batch = 16.8891s	
20793/22950 (epoch 45.301), train_loss = 0.79255974, grad/param norm = 2.4906e-01, time/batch = 15.9406s	
20794/22950 (epoch 45.303), train_loss = 0.75727145, grad/param norm = 2.4782e-01, time/batch = 18.5344s	
20795/22950 (epoch 45.305), train_loss = 0.74654082, grad/param norm = 2.6790e-01, time/batch = 18.0566s	
20796/22950 (epoch 45.307), train_loss = 0.87624324, grad/param norm = 2.9090e-01, time/batch = 19.2182s	
20797/22950 (epoch 45.309), train_loss = 0.71833746, grad/param norm = 2.2407e-01, time/batch = 17.6147s	
20798/22950 (epoch 45.312), train_loss = 0.80018827, grad/param norm = 2.3019e-01, time/batch = 19.6244s	
20799/22950 (epoch 45.314), train_loss = 0.76483672, grad/param norm = 2.2196e-01, time/batch = 18.4448s	
20800/22950 (epoch 45.316), train_loss = 0.74652167, grad/param norm = 2.5545e-01, time/batch = 17.6203s	
20801/22950 (epoch 45.318), train_loss = 0.68366624, grad/param norm = 2.1070e-01, time/batch = 18.4611s	
20802/22950 (epoch 45.320), train_loss = 0.69625129, grad/param norm = 2.3000e-01, time/batch = 20.1372s	
20803/22950 (epoch 45.322), train_loss = 0.71868479, grad/param norm = 2.6186e-01, time/batch = 17.3489s	
20804/22950 (epoch 45.325), train_loss = 0.60135542, grad/param norm = 2.3980e-01, time/batch = 19.0453s	
20805/22950 (epoch 45.327), train_loss = 0.59174625, grad/param norm = 2.2080e-01, time/batch = 19.8760s	
20806/22950 (epoch 45.329), train_loss = 0.69701201, grad/param norm = 2.0947e-01, time/batch = 18.6287s	
20807/22950 (epoch 45.331), train_loss = 0.65628644, grad/param norm = 2.3244e-01, time/batch = 19.2974s	
20808/22950 (epoch 45.333), train_loss = 0.67591630, grad/param norm = 2.4254e-01, time/batch = 19.2942s	
20809/22950 (epoch 45.336), train_loss = 0.73112634, grad/param norm = 3.3829e-01, time/batch = 19.5269s	
20810/22950 (epoch 45.338), train_loss = 0.78837512, grad/param norm = 3.1902e-01, time/batch = 19.2036s	
20811/22950 (epoch 45.340), train_loss = 0.71824263, grad/param norm = 2.7074e-01, time/batch = 16.7581s	
20812/22950 (epoch 45.342), train_loss = 0.91342527, grad/param norm = 3.1080e-01, time/batch = 18.2163s	
20813/22950 (epoch 45.344), train_loss = 0.75304572, grad/param norm = 2.8473e-01, time/batch = 17.8362s	
20814/22950 (epoch 45.346), train_loss = 0.87437139, grad/param norm = 3.2743e-01, time/batch = 18.2911s	
20815/22950 (epoch 45.349), train_loss = 0.77043982, grad/param norm = 2.5102e-01, time/batch = 19.5368s	
20816/22950 (epoch 45.351), train_loss = 0.80100285, grad/param norm = 2.9471e-01, time/batch = 18.6833s	
20817/22950 (epoch 45.353), train_loss = 0.76735138, grad/param norm = 3.3924e-01, time/batch = 19.7180s	
20818/22950 (epoch 45.355), train_loss = 0.83331877, grad/param norm = 2.9516e-01, time/batch = 19.2084s	
20819/22950 (epoch 45.357), train_loss = 0.71655583, grad/param norm = 3.2354e-01, time/batch = 17.4446s	
20820/22950 (epoch 45.359), train_loss = 0.75391670, grad/param norm = 2.6293e-01, time/batch = 18.9380s	
20821/22950 (epoch 45.362), train_loss = 0.80467114, grad/param norm = 2.8984e-01, time/batch = 19.4620s	
20822/22950 (epoch 45.364), train_loss = 0.78927956, grad/param norm = 3.6804e-01, time/batch = 17.8634s	
20823/22950 (epoch 45.366), train_loss = 0.77435439, grad/param norm = 2.3989e-01, time/batch = 18.3601s	
20824/22950 (epoch 45.368), train_loss = 0.81454414, grad/param norm = 3.0812e-01, time/batch = 19.0513s	
20825/22950 (epoch 45.370), train_loss = 0.74464901, grad/param norm = 2.7402e-01, time/batch = 18.2933s	
20826/22950 (epoch 45.373), train_loss = 0.70380683, grad/param norm = 2.4615e-01, time/batch = 20.1061s	
20827/22950 (epoch 45.375), train_loss = 0.83851047, grad/param norm = 2.9171e-01, time/batch = 18.3720s	
20828/22950 (epoch 45.377), train_loss = 0.70643299, grad/param norm = 2.9876e-01, time/batch = 18.4720s	
20829/22950 (epoch 45.379), train_loss = 0.76544407, grad/param norm = 2.4379e-01, time/batch = 16.6038s	
20830/22950 (epoch 45.381), train_loss = 0.69141668, grad/param norm = 2.4474e-01, time/batch = 18.7181s	
20831/22950 (epoch 45.383), train_loss = 0.74397288, grad/param norm = 2.7389e-01, time/batch = 18.7279s	
20832/22950 (epoch 45.386), train_loss = 0.69372226, grad/param norm = 2.4919e-01, time/batch = 17.0825s	
20833/22950 (epoch 45.388), train_loss = 0.79127865, grad/param norm = 2.4857e-01, time/batch = 19.8761s	
20834/22950 (epoch 45.390), train_loss = 0.66934003, grad/param norm = 2.4660e-01, time/batch = 20.1244s	
20835/22950 (epoch 45.392), train_loss = 0.70223339, grad/param norm = 2.4541e-01, time/batch = 17.1811s	
20836/22950 (epoch 45.394), train_loss = 0.71569388, grad/param norm = 2.6805e-01, time/batch = 20.5203s	
20837/22950 (epoch 45.397), train_loss = 0.86860923, grad/param norm = 2.7974e-01, time/batch = 18.7866s	
20838/22950 (epoch 45.399), train_loss = 0.81424600, grad/param norm = 2.8636e-01, time/batch = 18.5371s	
20839/22950 (epoch 45.401), train_loss = 0.89054913, grad/param norm = 3.3784e-01, time/batch = 16.0880s	
20840/22950 (epoch 45.403), train_loss = 0.76387163, grad/param norm = 2.7417e-01, time/batch = 15.7664s	
20841/22950 (epoch 45.405), train_loss = 0.90197387, grad/param norm = 3.9757e-01, time/batch = 16.7877s	
20842/22950 (epoch 45.407), train_loss = 0.93633999, grad/param norm = 2.6840e-01, time/batch = 16.1463s	
20843/22950 (epoch 45.410), train_loss = 0.80489288, grad/param norm = 2.4506e-01, time/batch = 15.6878s	
20844/22950 (epoch 45.412), train_loss = 0.75635097, grad/param norm = 2.7521e-01, time/batch = 16.1395s	
20845/22950 (epoch 45.414), train_loss = 0.86611896, grad/param norm = 2.8286e-01, time/batch = 17.8656s	
20846/22950 (epoch 45.416), train_loss = 0.79472357, grad/param norm = 2.8951e-01, time/batch = 17.6008s	
20847/22950 (epoch 45.418), train_loss = 0.78577936, grad/param norm = 2.8066e-01, time/batch = 19.7973s	
20848/22950 (epoch 45.420), train_loss = 0.81252534, grad/param norm = 3.0243e-01, time/batch = 16.8007s	
20849/22950 (epoch 45.423), train_loss = 0.73297894, grad/param norm = 2.6662e-01, time/batch = 16.8629s	
20850/22950 (epoch 45.425), train_loss = 0.75387621, grad/param norm = 2.7103e-01, time/batch = 17.9817s	
20851/22950 (epoch 45.427), train_loss = 0.77680031, grad/param norm = 2.5960e-01, time/batch = 19.6032s	
20852/22950 (epoch 45.429), train_loss = 0.80999145, grad/param norm = 2.4241e-01, time/batch = 17.0332s	
20853/22950 (epoch 45.431), train_loss = 0.83156929, grad/param norm = 2.7753e-01, time/batch = 19.6877s	
20854/22950 (epoch 45.434), train_loss = 0.78839662, grad/param norm = 2.9383e-01, time/batch = 19.9570s	
20855/22950 (epoch 45.436), train_loss = 0.84202742, grad/param norm = 3.6588e-01, time/batch = 19.4573s	
20856/22950 (epoch 45.438), train_loss = 0.77456886, grad/param norm = 2.6026e-01, time/batch = 18.8782s	
20857/22950 (epoch 45.440), train_loss = 0.86826820, grad/param norm = 2.8134e-01, time/batch = 19.7935s	
20858/22950 (epoch 45.442), train_loss = 0.92511385, grad/param norm = 3.2500e-01, time/batch = 19.3744s	
20859/22950 (epoch 45.444), train_loss = 0.81516633, grad/param norm = 3.7246e-01, time/batch = 19.8786s	
20860/22950 (epoch 45.447), train_loss = 0.90180176, grad/param norm = 3.0273e-01, time/batch = 18.7097s	
20861/22950 (epoch 45.449), train_loss = 0.69981429, grad/param norm = 2.3152e-01, time/batch = 17.8540s	
20862/22950 (epoch 45.451), train_loss = 0.80422090, grad/param norm = 3.3545e-01, time/batch = 19.9468s	
20863/22950 (epoch 45.453), train_loss = 0.82123027, grad/param norm = 2.6961e-01, time/batch = 18.5398s	
20864/22950 (epoch 45.455), train_loss = 0.77795182, grad/param norm = 2.3760e-01, time/batch = 19.9640s	
20865/22950 (epoch 45.458), train_loss = 0.77418172, grad/param norm = 2.9215e-01, time/batch = 18.6015s	
20866/22950 (epoch 45.460), train_loss = 0.82850531, grad/param norm = 2.8511e-01, time/batch = 19.2157s	
20867/22950 (epoch 45.462), train_loss = 0.83552495, grad/param norm = 2.6399e-01, time/batch = 19.9609s	
20868/22950 (epoch 45.464), train_loss = 0.74650774, grad/param norm = 2.5483e-01, time/batch = 17.7607s	
20869/22950 (epoch 45.466), train_loss = 0.86614456, grad/param norm = 2.9538e-01, time/batch = 17.1920s	
20870/22950 (epoch 45.468), train_loss = 0.83418130, grad/param norm = 2.8534e-01, time/batch = 19.9508s	
20871/22950 (epoch 45.471), train_loss = 0.80893179, grad/param norm = 2.8068e-01, time/batch = 19.1163s	
20872/22950 (epoch 45.473), train_loss = 0.81831370, grad/param norm = 2.7808e-01, time/batch = 18.6873s	
20873/22950 (epoch 45.475), train_loss = 0.92768577, grad/param norm = 2.8819e-01, time/batch = 19.7819s	
20874/22950 (epoch 45.477), train_loss = 0.76412344, grad/param norm = 2.6717e-01, time/batch = 19.0358s	
20875/22950 (epoch 45.479), train_loss = 0.70226199, grad/param norm = 2.4670e-01, time/batch = 19.1179s	
20876/22950 (epoch 45.481), train_loss = 0.84434415, grad/param norm = 2.8170e-01, time/batch = 20.1153s	
20877/22950 (epoch 45.484), train_loss = 0.82637387, grad/param norm = 3.2418e-01, time/batch = 17.3626s	
20878/22950 (epoch 45.486), train_loss = 0.67742306, grad/param norm = 2.5016e-01, time/batch = 18.7924s	
20879/22950 (epoch 45.488), train_loss = 0.70007691, grad/param norm = 2.6844e-01, time/batch = 17.2740s	
20880/22950 (epoch 45.490), train_loss = 0.63927483, grad/param norm = 2.6335e-01, time/batch = 18.8576s	
20881/22950 (epoch 45.492), train_loss = 0.75956797, grad/param norm = 2.6864e-01, time/batch = 18.7019s	
20882/22950 (epoch 45.495), train_loss = 0.72524377, grad/param norm = 2.4868e-01, time/batch = 19.7114s	
20883/22950 (epoch 45.497), train_loss = 0.79286959, grad/param norm = 2.5706e-01, time/batch = 19.1341s	
20884/22950 (epoch 45.499), train_loss = 0.88454256, grad/param norm = 2.8328e-01, time/batch = 16.3427s	
20885/22950 (epoch 45.501), train_loss = 0.78510324, grad/param norm = 2.5498e-01, time/batch = 19.5448s	
20886/22950 (epoch 45.503), train_loss = 0.89902899, grad/param norm = 2.7953e-01, time/batch = 20.0332s	
20887/22950 (epoch 45.505), train_loss = 0.66673877, grad/param norm = 2.9261e-01, time/batch = 18.6891s	
20888/22950 (epoch 45.508), train_loss = 0.82866509, grad/param norm = 2.5862e-01, time/batch = 18.8773s	
20889/22950 (epoch 45.510), train_loss = 0.74924107, grad/param norm = 2.5557e-01, time/batch = 19.8695s	
20890/22950 (epoch 45.512), train_loss = 0.65264166, grad/param norm = 2.6325e-01, time/batch = 18.1149s	
20891/22950 (epoch 45.514), train_loss = 0.76010961, grad/param norm = 2.3342e-01, time/batch = 18.8108s	
20892/22950 (epoch 45.516), train_loss = 0.77384786, grad/param norm = 2.4955e-01, time/batch = 19.0548s	
20893/22950 (epoch 45.519), train_loss = 0.77461533, grad/param norm = 2.3670e-01, time/batch = 17.6112s	
20894/22950 (epoch 45.521), train_loss = 0.77996371, grad/param norm = 2.6274e-01, time/batch = 19.1298s	
20895/22950 (epoch 45.523), train_loss = 0.61177654, grad/param norm = 2.2113e-01, time/batch = 18.3797s	
20896/22950 (epoch 45.525), train_loss = 0.70121781, grad/param norm = 2.6402e-01, time/batch = 17.5313s	
20897/22950 (epoch 45.527), train_loss = 0.67913252, grad/param norm = 2.3090e-01, time/batch = 19.3392s	
20898/22950 (epoch 45.529), train_loss = 0.75688349, grad/param norm = 2.2836e-01, time/batch = 18.9682s	
20899/22950 (epoch 45.532), train_loss = 0.72876481, grad/param norm = 2.4915e-01, time/batch = 19.0513s	
20900/22950 (epoch 45.534), train_loss = 0.76391835, grad/param norm = 2.3176e-01, time/batch = 18.1770s	
20901/22950 (epoch 45.536), train_loss = 0.80238038, grad/param norm = 3.2290e-01, time/batch = 19.4651s	
20902/22950 (epoch 45.538), train_loss = 0.74217568, grad/param norm = 2.4793e-01, time/batch = 16.5244s	
20903/22950 (epoch 45.540), train_loss = 0.79458547, grad/param norm = 2.4269e-01, time/batch = 18.1249s	
20904/22950 (epoch 45.542), train_loss = 0.92691354, grad/param norm = 3.4238e-01, time/batch = 19.3721s	
20905/22950 (epoch 45.545), train_loss = 0.78187460, grad/param norm = 2.6172e-01, time/batch = 20.3751s	
20906/22950 (epoch 45.547), train_loss = 0.75341836, grad/param norm = 2.3611e-01, time/batch = 17.6253s	
20907/22950 (epoch 45.549), train_loss = 0.72336227, grad/param norm = 3.2550e-01, time/batch = 19.4612s	
20908/22950 (epoch 45.551), train_loss = 0.72868162, grad/param norm = 2.6867e-01, time/batch = 19.2947s	
20909/22950 (epoch 45.553), train_loss = 0.73266210, grad/param norm = 2.9587e-01, time/batch = 15.0189s	
20910/22950 (epoch 45.556), train_loss = 0.80688484, grad/param norm = 2.5424e-01, time/batch = 0.6992s	
20911/22950 (epoch 45.558), train_loss = 0.64467463, grad/param norm = 2.8584e-01, time/batch = 0.6959s	
20912/22950 (epoch 45.560), train_loss = 0.73967411, grad/param norm = 2.7824e-01, time/batch = 0.6955s	
20913/22950 (epoch 45.562), train_loss = 0.73628903, grad/param norm = 2.6613e-01, time/batch = 0.6909s	
20914/22950 (epoch 45.564), train_loss = 0.78431683, grad/param norm = 2.7342e-01, time/batch = 0.6896s	
20915/22950 (epoch 45.566), train_loss = 0.79301343, grad/param norm = 2.5857e-01, time/batch = 0.6883s	
20916/22950 (epoch 45.569), train_loss = 0.76394658, grad/param norm = 2.7806e-01, time/batch = 0.6977s	
20917/22950 (epoch 45.571), train_loss = 0.71936574, grad/param norm = 2.4788e-01, time/batch = 1.0441s	
20918/22950 (epoch 45.573), train_loss = 0.73880805, grad/param norm = 2.7470e-01, time/batch = 1.0112s	
20919/22950 (epoch 45.575), train_loss = 0.82947180, grad/param norm = 3.1184e-01, time/batch = 1.0426s	
20920/22950 (epoch 45.577), train_loss = 0.77582570, grad/param norm = 4.0209e-01, time/batch = 1.0227s	
20921/22950 (epoch 45.580), train_loss = 0.83548315, grad/param norm = 3.4500e-01, time/batch = 1.2105s	
20922/22950 (epoch 45.582), train_loss = 0.87280908, grad/param norm = 2.8074e-01, time/batch = 1.9101s	
20923/22950 (epoch 45.584), train_loss = 0.68397392, grad/param norm = 2.9444e-01, time/batch = 1.8829s	
20924/22950 (epoch 45.586), train_loss = 0.71900692, grad/param norm = 2.6246e-01, time/batch = 11.6535s	
20925/22950 (epoch 45.588), train_loss = 0.88589441, grad/param norm = 3.5417e-01, time/batch = 18.1290s	
20926/22950 (epoch 45.590), train_loss = 0.85716734, grad/param norm = 2.8080e-01, time/batch = 16.8443s	
20927/22950 (epoch 45.593), train_loss = 0.76842342, grad/param norm = 2.6323e-01, time/batch = 20.6961s	
20928/22950 (epoch 45.595), train_loss = 0.74502274, grad/param norm = 3.1781e-01, time/batch = 19.6136s	
20929/22950 (epoch 45.597), train_loss = 0.81588025, grad/param norm = 2.9765e-01, time/batch = 17.6204s	
20930/22950 (epoch 45.599), train_loss = 0.78390747, grad/param norm = 3.1196e-01, time/batch = 17.7074s	
20931/22950 (epoch 45.601), train_loss = 0.83845848, grad/param norm = 2.3846e-01, time/batch = 19.8763s	
20932/22950 (epoch 45.603), train_loss = 0.87689771, grad/param norm = 2.7363e-01, time/batch = 19.6158s	
20933/22950 (epoch 45.606), train_loss = 0.77903840, grad/param norm = 3.0976e-01, time/batch = 19.0410s	
20934/22950 (epoch 45.608), train_loss = 0.75058941, grad/param norm = 2.6858e-01, time/batch = 17.1191s	
20935/22950 (epoch 45.610), train_loss = 0.73944628, grad/param norm = 2.3431e-01, time/batch = 17.9518s	
20936/22950 (epoch 45.612), train_loss = 0.80421402, grad/param norm = 2.9010e-01, time/batch = 17.0183s	
20937/22950 (epoch 45.614), train_loss = 0.88882021, grad/param norm = 3.0328e-01, time/batch = 20.2080s	
20938/22950 (epoch 45.617), train_loss = 0.78900243, grad/param norm = 2.7195e-01, time/batch = 19.5367s	
20939/22950 (epoch 45.619), train_loss = 0.71351714, grad/param norm = 2.3505e-01, time/batch = 16.9503s	
20940/22950 (epoch 45.621), train_loss = 0.85828884, grad/param norm = 2.6892e-01, time/batch = 19.8614s	
20941/22950 (epoch 45.623), train_loss = 0.82696424, grad/param norm = 2.6903e-01, time/batch = 19.3704s	
20942/22950 (epoch 45.625), train_loss = 0.77607431, grad/param norm = 2.5812e-01, time/batch = 18.9430s	
20943/22950 (epoch 45.627), train_loss = 0.73863775, grad/param norm = 2.6583e-01, time/batch = 18.7030s	
20944/22950 (epoch 45.630), train_loss = 0.68112474, grad/param norm = 2.1766e-01, time/batch = 19.0281s	
20945/22950 (epoch 45.632), train_loss = 0.74420508, grad/param norm = 3.1076e-01, time/batch = 18.7666s	
20946/22950 (epoch 45.634), train_loss = 0.79123086, grad/param norm = 2.4417e-01, time/batch = 18.7006s	
20947/22950 (epoch 45.636), train_loss = 0.77246926, grad/param norm = 2.4192e-01, time/batch = 20.4568s	
20948/22950 (epoch 45.638), train_loss = 0.76202310, grad/param norm = 2.6160e-01, time/batch = 19.3628s	
20949/22950 (epoch 45.641), train_loss = 0.76167625, grad/param norm = 2.5783e-01, time/batch = 18.3628s	
20950/22950 (epoch 45.643), train_loss = 0.78706815, grad/param norm = 3.0227e-01, time/batch = 19.6166s	
20951/22950 (epoch 45.645), train_loss = 0.75439648, grad/param norm = 2.6884e-01, time/batch = 17.6933s	
20952/22950 (epoch 45.647), train_loss = 0.73895088, grad/param norm = 2.8177e-01, time/batch = 18.8547s	
20953/22950 (epoch 45.649), train_loss = 0.69989690, grad/param norm = 3.1196e-01, time/batch = 19.2013s	
20954/22950 (epoch 45.651), train_loss = 0.86097682, grad/param norm = 2.8033e-01, time/batch = 20.6243s	
20955/22950 (epoch 45.654), train_loss = 0.67273497, grad/param norm = 2.4412e-01, time/batch = 17.0222s	
20956/22950 (epoch 45.656), train_loss = 0.82195886, grad/param norm = 3.0532e-01, time/batch = 20.2824s	
20957/22950 (epoch 45.658), train_loss = 0.68853304, grad/param norm = 2.6458e-01, time/batch = 18.6186s	
20958/22950 (epoch 45.660), train_loss = 0.61824352, grad/param norm = 2.5494e-01, time/batch = 17.2525s	
20959/22950 (epoch 45.662), train_loss = 0.63651451, grad/param norm = 2.5518e-01, time/batch = 19.4947s	
20960/22950 (epoch 45.664), train_loss = 0.73945861, grad/param norm = 3.0551e-01, time/batch = 18.9529s	
20961/22950 (epoch 45.667), train_loss = 0.75062764, grad/param norm = 2.7271e-01, time/batch = 17.0210s	
20962/22950 (epoch 45.669), train_loss = 0.78560906, grad/param norm = 3.0231e-01, time/batch = 18.2882s	
20963/22950 (epoch 45.671), train_loss = 0.75981364, grad/param norm = 3.6613e-01, time/batch = 20.3064s	
20964/22950 (epoch 45.673), train_loss = 0.70244644, grad/param norm = 2.9871e-01, time/batch = 18.7971s	
20965/22950 (epoch 45.675), train_loss = 0.81018953, grad/param norm = 3.6795e-01, time/batch = 19.7868s	
20966/22950 (epoch 45.678), train_loss = 0.73971543, grad/param norm = 2.6355e-01, time/batch = 20.8643s	
20967/22950 (epoch 45.680), train_loss = 0.79770768, grad/param norm = 2.5540e-01, time/batch = 17.4566s	
20968/22950 (epoch 45.682), train_loss = 0.76931902, grad/param norm = 2.8745e-01, time/batch = 20.2860s	
20969/22950 (epoch 45.684), train_loss = 0.86574764, grad/param norm = 2.8857e-01, time/batch = 19.4566s	
20970/22950 (epoch 45.686), train_loss = 0.88530323, grad/param norm = 3.0765e-01, time/batch = 18.8519s	
20971/22950 (epoch 45.688), train_loss = 0.76771553, grad/param norm = 2.8111e-01, time/batch = 19.4528s	
20972/22950 (epoch 45.691), train_loss = 0.74763569, grad/param norm = 2.5836e-01, time/batch = 15.8581s	
20973/22950 (epoch 45.693), train_loss = 0.68587929, grad/param norm = 2.6678e-01, time/batch = 18.8774s	
20974/22950 (epoch 45.695), train_loss = 0.87325748, grad/param norm = 3.4558e-01, time/batch = 18.6892s	
20975/22950 (epoch 45.697), train_loss = 0.80594363, grad/param norm = 3.0095e-01, time/batch = 17.1979s	
20976/22950 (epoch 45.699), train_loss = 0.81416261, grad/param norm = 2.9365e-01, time/batch = 20.6993s	
20977/22950 (epoch 45.702), train_loss = 0.85458709, grad/param norm = 3.1552e-01, time/batch = 16.4506s	
20978/22950 (epoch 45.704), train_loss = 0.92341392, grad/param norm = 3.4946e-01, time/batch = 21.1127s	
20979/22950 (epoch 45.706), train_loss = 0.86022006, grad/param norm = 2.9379e-01, time/batch = 20.1946s	
20980/22950 (epoch 45.708), train_loss = 0.68929381, grad/param norm = 2.8204e-01, time/batch = 17.7780s	
20981/22950 (epoch 45.710), train_loss = 0.77530233, grad/param norm = 2.7333e-01, time/batch = 18.9408s	
20982/22950 (epoch 45.712), train_loss = 0.92507110, grad/param norm = 3.4435e-01, time/batch = 19.9573s	
20983/22950 (epoch 45.715), train_loss = 0.82906099, grad/param norm = 3.3555e-01, time/batch = 18.2819s	
20984/22950 (epoch 45.717), train_loss = 0.82717586, grad/param norm = 2.3983e-01, time/batch = 18.9639s	
20985/22950 (epoch 45.719), train_loss = 0.78948971, grad/param norm = 3.7813e-01, time/batch = 20.2120s	
20986/22950 (epoch 45.721), train_loss = 0.85208866, grad/param norm = 2.9476e-01, time/batch = 20.7767s	
20987/22950 (epoch 45.723), train_loss = 0.80129875, grad/param norm = 2.7216e-01, time/batch = 26.5208s	
20988/22950 (epoch 45.725), train_loss = 0.83613690, grad/param norm = 3.2393e-01, time/batch = 19.7980s	
20989/22950 (epoch 45.728), train_loss = 0.78655618, grad/param norm = 3.1783e-01, time/batch = 17.8638s	
20990/22950 (epoch 45.730), train_loss = 0.81564550, grad/param norm = 2.9408e-01, time/batch = 18.8622s	
20991/22950 (epoch 45.732), train_loss = 0.87252863, grad/param norm = 2.9909e-01, time/batch = 19.9489s	
20992/22950 (epoch 45.734), train_loss = 0.73569315, grad/param norm = 3.0153e-01, time/batch = 16.2884s	
20993/22950 (epoch 45.736), train_loss = 0.83495919, grad/param norm = 2.9308e-01, time/batch = 16.9287s	
20994/22950 (epoch 45.739), train_loss = 0.85305182, grad/param norm = 3.0814e-01, time/batch = 17.8006s	
20995/22950 (epoch 45.741), train_loss = 0.85707104, grad/param norm = 3.1384e-01, time/batch = 19.8583s	
20996/22950 (epoch 45.743), train_loss = 0.93378546, grad/param norm = 3.2826e-01, time/batch = 19.4545s	
20997/22950 (epoch 45.745), train_loss = 1.00984065, grad/param norm = 3.4941e-01, time/batch = 19.7160s	
20998/22950 (epoch 45.747), train_loss = 0.87192138, grad/param norm = 3.4213e-01, time/batch = 19.1349s	
20999/22950 (epoch 45.749), train_loss = 0.72366285, grad/param norm = 3.5472e-01, time/batch = 19.4437s	
evaluating loss over split index 2	
1/25...	
2/25...	
3/25...	
4/25...	
5/25...	
6/25...	
7/25...	
8/25...	
9/25...	
10/25...	
11/25...	
12/25...	
13/25...	
14/25...	
15/25...	
16/25...	
17/25...	
18/25...	
19/25...	
20/25...	
21/25...	
22/25...	
23/25...	
24/25...	
25/25...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_github_epoch45.75_2.1419.t7	
21000/22950 (epoch 45.752), train_loss = 0.97013964, grad/param norm = 4.1196e-01, time/batch = 19.9623s	
21001/22950 (epoch 45.754), train_loss = 1.55024926, grad/param norm = 4.5054e-01, time/batch = 18.0555s	
21002/22950 (epoch 45.756), train_loss = 0.78251131, grad/param norm = 2.7765e-01, time/batch = 17.9523s	
21003/22950 (epoch 45.758), train_loss = 0.83609134, grad/param norm = 2.7235e-01, time/batch = 18.1205s	
21004/22950 (epoch 45.760), train_loss = 0.79540199, grad/param norm = 2.6537e-01, time/batch = 19.6319s	
21005/22950 (epoch 45.763), train_loss = 0.82095387, grad/param norm = 2.7223e-01, time/batch = 18.2015s	
21006/22950 (epoch 45.765), train_loss = 0.80863132, grad/param norm = 3.0384e-01, time/batch = 19.1366s	
21007/22950 (epoch 45.767), train_loss = 0.97958222, grad/param norm = 2.8591e-01, time/batch = 16.2844s	
21008/22950 (epoch 45.769), train_loss = 0.85454162, grad/param norm = 2.7837e-01, time/batch = 19.2625s	
21009/22950 (epoch 45.771), train_loss = 0.71168320, grad/param norm = 2.9418e-01, time/batch = 17.1188s	
21010/22950 (epoch 45.773), train_loss = 0.60836767, grad/param norm = 2.3825e-01, time/batch = 19.0496s	
21011/22950 (epoch 45.776), train_loss = 0.73747629, grad/param norm = 2.3634e-01, time/batch = 19.2859s	
21012/22950 (epoch 45.778), train_loss = 0.73171404, grad/param norm = 2.6380e-01, time/batch = 16.8748s	
21013/22950 (epoch 45.780), train_loss = 0.81632983, grad/param norm = 2.7387e-01, time/batch = 17.6923s	
21014/22950 (epoch 45.782), train_loss = 0.83980143, grad/param norm = 2.9342e-01, time/batch = 19.6347s	
21015/22950 (epoch 45.784), train_loss = 0.73332036, grad/param norm = 2.8181e-01, time/batch = 18.5326s	
21016/22950 (epoch 45.786), train_loss = 0.80621228, grad/param norm = 2.7222e-01, time/batch = 18.0233s	
21017/22950 (epoch 45.789), train_loss = 0.65926732, grad/param norm = 2.5839e-01, time/batch = 19.4618s	
21018/22950 (epoch 45.791), train_loss = 0.69069508, grad/param norm = 2.5292e-01, time/batch = 18.3797s	
21019/22950 (epoch 45.793), train_loss = 0.88978058, grad/param norm = 2.9848e-01, time/batch = 17.6825s	
21020/22950 (epoch 45.795), train_loss = 0.76659642, grad/param norm = 2.9126e-01, time/batch = 19.2973s	
21021/22950 (epoch 45.797), train_loss = 0.90480854, grad/param norm = 3.0088e-01, time/batch = 19.5488s	
21022/22950 (epoch 45.800), train_loss = 0.75681441, grad/param norm = 2.5836e-01, time/batch = 19.7849s	
21023/22950 (epoch 45.802), train_loss = 0.77518991, grad/param norm = 3.2236e-01, time/batch = 19.5379s	
21024/22950 (epoch 45.804), train_loss = 0.78698437, grad/param norm = 2.6437e-01, time/batch = 19.8720s	
21025/22950 (epoch 45.806), train_loss = 0.68965210, grad/param norm = 2.5837e-01, time/batch = 17.5166s	
21026/22950 (epoch 45.808), train_loss = 0.82848208, grad/param norm = 2.4808e-01, time/batch = 17.2248s	
21027/22950 (epoch 45.810), train_loss = 0.73915766, grad/param norm = 2.5176e-01, time/batch = 19.7054s	
21028/22950 (epoch 45.813), train_loss = 0.65491519, grad/param norm = 2.3337e-01, time/batch = 16.2425s	
21029/22950 (epoch 45.815), train_loss = 0.61704265, grad/param norm = 2.6804e-01, time/batch = 18.7025s	
21030/22950 (epoch 45.817), train_loss = 0.70667502, grad/param norm = 2.3553e-01, time/batch = 18.0399s	
21031/22950 (epoch 45.819), train_loss = 0.75018432, grad/param norm = 2.6693e-01, time/batch = 16.0050s	
21032/22950 (epoch 45.821), train_loss = 0.76544472, grad/param norm = 3.1463e-01, time/batch = 19.7977s	
21033/22950 (epoch 45.824), train_loss = 0.81321386, grad/param norm = 2.6641e-01, time/batch = 19.3808s	
21034/22950 (epoch 45.826), train_loss = 0.81553254, grad/param norm = 3.5671e-01, time/batch = 20.4444s	
21035/22950 (epoch 45.828), train_loss = 0.71903472, grad/param norm = 2.8666e-01, time/batch = 20.2650s	
21036/22950 (epoch 45.830), train_loss = 0.73922040, grad/param norm = 2.4440e-01, time/batch = 18.7153s	
21037/22950 (epoch 45.832), train_loss = 0.81407049, grad/param norm = 2.5579e-01, time/batch = 19.5373s	
21038/22950 (epoch 45.834), train_loss = 0.62776249, grad/param norm = 2.6319e-01, time/batch = 18.1927s	
21039/22950 (epoch 45.837), train_loss = 0.79258352, grad/param norm = 2.9218e-01, time/batch = 20.0538s	
21040/22950 (epoch 45.839), train_loss = 0.64093428, grad/param norm = 2.4701e-01, time/batch = 19.2091s	
21041/22950 (epoch 45.841), train_loss = 0.74736172, grad/param norm = 2.4920e-01, time/batch = 18.4417s	
21042/22950 (epoch 45.843), train_loss = 0.74341147, grad/param norm = 2.6076e-01, time/batch = 18.9564s	
21043/22950 (epoch 45.845), train_loss = 0.76067894, grad/param norm = 2.6613e-01, time/batch = 20.6192s	
21044/22950 (epoch 45.847), train_loss = 0.77845191, grad/param norm = 2.6764e-01, time/batch = 17.1797s	
21045/22950 (epoch 45.850), train_loss = 0.83165925, grad/param norm = 2.7363e-01, time/batch = 20.0310s	
21046/22950 (epoch 45.852), train_loss = 0.84775236, grad/param norm = 3.2909e-01, time/batch = 19.8639s	
21047/22950 (epoch 45.854), train_loss = 0.78602358, grad/param norm = 2.8678e-01, time/batch = 16.6712s	
21048/22950 (epoch 45.856), train_loss = 0.86635335, grad/param norm = 3.0523e-01, time/batch = 17.5727s	
21049/22950 (epoch 45.858), train_loss = 0.85191580, grad/param norm = 2.5779e-01, time/batch = 19.7961s	
21050/22950 (epoch 45.861), train_loss = 0.81618962, grad/param norm = 2.9476e-01, time/batch = 17.5298s	
21051/22950 (epoch 45.863), train_loss = 0.86447147, grad/param norm = 3.2121e-01, time/batch = 19.2132s	
21052/22950 (epoch 45.865), train_loss = 0.90766206, grad/param norm = 3.1865e-01, time/batch = 16.4506s	
21053/22950 (epoch 45.867), train_loss = 0.80212481, grad/param norm = 3.1094e-01, time/batch = 19.7699s	
21054/22950 (epoch 45.869), train_loss = 0.93489949, grad/param norm = 2.8300e-01, time/batch = 18.1282s	
21055/22950 (epoch 45.871), train_loss = 0.81077284, grad/param norm = 3.5782e-01, time/batch = 19.6374s	
21056/22950 (epoch 45.874), train_loss = 0.83177524, grad/param norm = 2.7915e-01, time/batch = 19.8764s	
21057/22950 (epoch 45.876), train_loss = 0.90133231, grad/param norm = 3.7313e-01, time/batch = 19.4287s	
21058/22950 (epoch 45.878), train_loss = 0.82436805, grad/param norm = 2.7670e-01, time/batch = 20.3643s	
21059/22950 (epoch 45.880), train_loss = 0.95461140, grad/param norm = 2.8764e-01, time/batch = 20.1188s	
21060/22950 (epoch 45.882), train_loss = 0.73257409, grad/param norm = 2.8792e-01, time/batch = 17.5944s	
21061/22950 (epoch 45.885), train_loss = 0.82240359, grad/param norm = 3.9741e-01, time/batch = 19.2058s	
21062/22950 (epoch 45.887), train_loss = 0.78113865, grad/param norm = 2.4968e-01, time/batch = 18.7118s	
21063/22950 (epoch 45.889), train_loss = 0.83388469, grad/param norm = 2.9524e-01, time/batch = 16.1765s	
21064/22950 (epoch 45.891), train_loss = 0.70237903, grad/param norm = 2.4747e-01, time/batch = 18.5436s	
21065/22950 (epoch 45.893), train_loss = 0.81212003, grad/param norm = 2.6043e-01, time/batch = 18.6993s	
21066/22950 (epoch 45.895), train_loss = 0.93311917, grad/param norm = 2.7473e-01, time/batch = 17.5375s	
21067/22950 (epoch 45.898), train_loss = 0.87137714, grad/param norm = 3.0189e-01, time/batch = 18.6170s	
21068/22950 (epoch 45.900), train_loss = 0.74759506, grad/param norm = 2.7804e-01, time/batch = 20.1246s	
21069/22950 (epoch 45.902), train_loss = 0.78864760, grad/param norm = 2.7647e-01, time/batch = 18.9406s	
21070/22950 (epoch 45.904), train_loss = 0.79037384, grad/param norm = 2.7407e-01, time/batch = 20.2861s	
21071/22950 (epoch 45.906), train_loss = 0.82373026, grad/param norm = 3.0817e-01, time/batch = 18.8718s	
21072/22950 (epoch 45.908), train_loss = 0.70528393, grad/param norm = 2.7747e-01, time/batch = 19.1959s	
21073/22950 (epoch 45.911), train_loss = 0.63519224, grad/param norm = 2.2943e-01, time/batch = 20.2046s	
21074/22950 (epoch 45.913), train_loss = 0.80512665, grad/param norm = 2.8163e-01, time/batch = 19.8698s	
21075/22950 (epoch 45.915), train_loss = 0.88849562, grad/param norm = 2.7691e-01, time/batch = 19.1108s	
21076/22950 (epoch 45.917), train_loss = 0.71242716, grad/param norm = 2.7556e-01, time/batch = 17.2910s	
21077/22950 (epoch 45.919), train_loss = 0.80201692, grad/param norm = 2.6063e-01, time/batch = 16.7046s	
21078/22950 (epoch 45.922), train_loss = 0.77931186, grad/param norm = 2.6137e-01, time/batch = 18.4751s	
21079/22950 (epoch 45.924), train_loss = 0.84196123, grad/param norm = 3.4362e-01, time/batch = 18.8742s	
21080/22950 (epoch 45.926), train_loss = 0.67045994, grad/param norm = 2.5993e-01, time/batch = 18.7124s	
21081/22950 (epoch 45.928), train_loss = 0.70006182, grad/param norm = 2.4861e-01, time/batch = 20.1143s	
21082/22950 (epoch 45.930), train_loss = 0.70822064, grad/param norm = 2.2657e-01, time/batch = 15.9328s	
21083/22950 (epoch 45.932), train_loss = 0.65986242, grad/param norm = 2.8111e-01, time/batch = 18.5988s	
21084/22950 (epoch 45.935), train_loss = 0.83925957, grad/param norm = 2.7400e-01, time/batch = 19.8586s	
21085/22950 (epoch 45.937), train_loss = 0.77731582, grad/param norm = 3.0292e-01, time/batch = 18.0397s	
21086/22950 (epoch 45.939), train_loss = 0.73187314, grad/param norm = 3.1485e-01, time/batch = 19.6155s	
21087/22950 (epoch 45.941), train_loss = 0.76727356, grad/param norm = 2.6713e-01, time/batch = 18.8821s	
21088/22950 (epoch 45.943), train_loss = 0.80573595, grad/param norm = 2.9092e-01, time/batch = 18.5251s	
21089/22950 (epoch 45.946), train_loss = 0.63755925, grad/param norm = 2.7592e-01, time/batch = 18.0403s	
21090/22950 (epoch 45.948), train_loss = 0.86963753, grad/param norm = 3.0344e-01, time/batch = 19.7814s	
21091/22950 (epoch 45.950), train_loss = 0.77782589, grad/param norm = 2.8645e-01, time/batch = 19.4538s	
21092/22950 (epoch 45.952), train_loss = 0.81902911, grad/param norm = 2.6526e-01, time/batch = 18.6882s	
21093/22950 (epoch 45.954), train_loss = 0.82514164, grad/param norm = 2.6525e-01, time/batch = 18.0517s	
21094/22950 (epoch 45.956), train_loss = 0.74321404, grad/param norm = 3.0149e-01, time/batch = 19.3008s	
21095/22950 (epoch 45.959), train_loss = 0.71710657, grad/param norm = 2.5149e-01, time/batch = 17.1972s	
21096/22950 (epoch 45.961), train_loss = 0.76936697, grad/param norm = 2.3876e-01, time/batch = 19.0406s	
21097/22950 (epoch 45.963), train_loss = 0.75715239, grad/param norm = 2.4687e-01, time/batch = 19.3687s	
21098/22950 (epoch 45.965), train_loss = 0.84514177, grad/param norm = 2.7965e-01, time/batch = 16.4422s	
21099/22950 (epoch 45.967), train_loss = 0.74096319, grad/param norm = 2.6916e-01, time/batch = 19.7965s	
21100/22950 (epoch 45.969), train_loss = 0.68157601, grad/param norm = 2.6943e-01, time/batch = 20.2098s	
21101/22950 (epoch 45.972), train_loss = 0.75824002, grad/param norm = 2.6979e-01, time/batch = 17.0214s	
21102/22950 (epoch 45.974), train_loss = 0.73047451, grad/param norm = 2.6988e-01, time/batch = 20.4493s	
21103/22950 (epoch 45.976), train_loss = 0.77840549, grad/param norm = 2.6121e-01, time/batch = 20.0392s	
21104/22950 (epoch 45.978), train_loss = 0.70132686, grad/param norm = 2.4448e-01, time/batch = 18.7018s	
21105/22950 (epoch 45.980), train_loss = 0.73382976, grad/param norm = 2.7765e-01, time/batch = 20.0428s	
21106/22950 (epoch 45.983), train_loss = 0.85149679, grad/param norm = 2.6064e-01, time/batch = 16.0125s	
21107/22950 (epoch 45.985), train_loss = 0.71788034, grad/param norm = 3.1088e-01, time/batch = 19.5142s	
21108/22950 (epoch 45.987), train_loss = 0.72007626, grad/param norm = 2.7112e-01, time/batch = 18.8657s	
21109/22950 (epoch 45.989), train_loss = 0.78416967, grad/param norm = 2.7696e-01, time/batch = 18.6978s	
21110/22950 (epoch 45.991), train_loss = 0.67416115, grad/param norm = 2.4622e-01, time/batch = 19.4583s	
21111/22950 (epoch 45.993), train_loss = 0.78335868, grad/param norm = 2.6944e-01, time/batch = 19.8740s	
21112/22950 (epoch 45.996), train_loss = 0.74847773, grad/param norm = 2.4236e-01, time/batch = 19.5264s	
21113/22950 (epoch 45.998), train_loss = 0.68075764, grad/param norm = 2.5396e-01, time/batch = 18.8688s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
21114/22950 (epoch 46.000), train_loss = 0.66289355, grad/param norm = 2.5201e-01, time/batch = 19.6733s	
21115/22950 (epoch 46.002), train_loss = 0.91864754, grad/param norm = 2.7468e-01, time/batch = 17.8857s	
21116/22950 (epoch 46.004), train_loss = 0.82081398, grad/param norm = 2.6309e-01, time/batch = 17.6111s	
21117/22950 (epoch 46.007), train_loss = 0.76356898, grad/param norm = 3.2359e-01, time/batch = 16.2961s	
21118/22950 (epoch 46.009), train_loss = 0.90159837, grad/param norm = 2.7758e-01, time/batch = 19.8806s	
21119/22950 (epoch 46.011), train_loss = 0.65113324, grad/param norm = 2.3708e-01, time/batch = 18.9691s	
21120/22950 (epoch 46.013), train_loss = 0.73565825, grad/param norm = 2.9510e-01, time/batch = 16.7864s	
21121/22950 (epoch 46.015), train_loss = 0.78584503, grad/param norm = 2.7707e-01, time/batch = 19.8608s	
21122/22950 (epoch 46.017), train_loss = 0.79616336, grad/param norm = 2.9497e-01, time/batch = 19.0583s	
21123/22950 (epoch 46.020), train_loss = 0.79659877, grad/param norm = 2.2709e-01, time/batch = 18.2772s	
21124/22950 (epoch 46.022), train_loss = 0.69369586, grad/param norm = 2.6414e-01, time/batch = 17.5359s	
21125/22950 (epoch 46.024), train_loss = 0.73554948, grad/param norm = 2.4335e-01, time/batch = 15.6262s	
21126/22950 (epoch 46.026), train_loss = 0.81005085, grad/param norm = 2.4670e-01, time/batch = 19.6220s	
21127/22950 (epoch 46.028), train_loss = 0.82812173, grad/param norm = 2.5790e-01, time/batch = 18.7009s	
21128/22950 (epoch 46.031), train_loss = 0.73406858, grad/param norm = 2.4985e-01, time/batch = 19.1179s	
21129/22950 (epoch 46.033), train_loss = 0.84476731, grad/param norm = 2.7587e-01, time/batch = 19.7009s	
21130/22950 (epoch 46.035), train_loss = 0.76918557, grad/param norm = 2.1428e-01, time/batch = 16.9397s	
21131/22950 (epoch 46.037), train_loss = 0.77752118, grad/param norm = 2.4063e-01, time/batch = 18.8727s	
21132/22950 (epoch 46.039), train_loss = 0.76129455, grad/param norm = 2.6189e-01, time/batch = 20.5432s	
21133/22950 (epoch 46.041), train_loss = 0.71215800, grad/param norm = 3.1228e-01, time/batch = 18.8616s	
21134/22950 (epoch 46.044), train_loss = 0.81355496, grad/param norm = 3.0100e-01, time/batch = 19.7702s	
21135/22950 (epoch 46.046), train_loss = 0.76189178, grad/param norm = 2.4958e-01, time/batch = 20.2063s	
21136/22950 (epoch 46.048), train_loss = 0.78374949, grad/param norm = 2.6968e-01, time/batch = 17.4591s	
21137/22950 (epoch 46.050), train_loss = 0.73293018, grad/param norm = 4.8630e-01, time/batch = 19.9492s	
21138/22950 (epoch 46.052), train_loss = 0.80284997, grad/param norm = 2.7837e-01, time/batch = 18.7854s	
21139/22950 (epoch 46.054), train_loss = 0.89425856, grad/param norm = 2.9023e-01, time/batch = 18.7688s	
21140/22950 (epoch 46.057), train_loss = 0.89092560, grad/param norm = 2.8072e-01, time/batch = 19.2061s	
21141/22950 (epoch 46.059), train_loss = 0.90956555, grad/param norm = 2.9852e-01, time/batch = 18.5361s	
21142/22950 (epoch 46.061), train_loss = 0.72857661, grad/param norm = 2.6072e-01, time/batch = 17.5248s	
21143/22950 (epoch 46.063), train_loss = 0.82933924, grad/param norm = 2.6116e-01, time/batch = 16.3742s	
21144/22950 (epoch 46.065), train_loss = 0.69627016, grad/param norm = 2.4334e-01, time/batch = 19.4474s	
21145/22950 (epoch 46.068), train_loss = 0.80239589, grad/param norm = 2.8109e-01, time/batch = 20.2747s	
21146/22950 (epoch 46.070), train_loss = 0.70469415, grad/param norm = 2.4000e-01, time/batch = 18.3435s	
21147/22950 (epoch 46.072), train_loss = 0.82053095, grad/param norm = 2.7681e-01, time/batch = 19.4683s	
21148/22950 (epoch 46.074), train_loss = 0.83669788, grad/param norm = 2.7310e-01, time/batch = 18.1187s	
21149/22950 (epoch 46.076), train_loss = 0.80920875, grad/param norm = 2.5042e-01, time/batch = 17.9485s	
21150/22950 (epoch 46.078), train_loss = 0.86684401, grad/param norm = 2.8410e-01, time/batch = 18.3029s	
21151/22950 (epoch 46.081), train_loss = 0.89940098, grad/param norm = 3.1809e-01, time/batch = 19.4665s	
21152/22950 (epoch 46.083), train_loss = 0.81217575, grad/param norm = 3.1167e-01, time/batch = 19.4379s	
21153/22950 (epoch 46.085), train_loss = 0.67265634, grad/param norm = 2.5312e-01, time/batch = 19.3675s	
21154/22950 (epoch 46.087), train_loss = 0.72117663, grad/param norm = 2.9027e-01, time/batch = 20.3640s	
21155/22950 (epoch 46.089), train_loss = 0.81512430, grad/param norm = 2.7506e-01, time/batch = 17.3627s	
21156/22950 (epoch 46.092), train_loss = 0.72851161, grad/param norm = 2.9751e-01, time/batch = 19.5413s	
21157/22950 (epoch 46.094), train_loss = 0.73931650, grad/param norm = 3.9056e-01, time/batch = 19.2857s	
21158/22950 (epoch 46.096), train_loss = 0.92074882, grad/param norm = 3.7539e-01, time/batch = 17.0227s	
21159/22950 (epoch 46.098), train_loss = 0.83515502, grad/param norm = 2.8384e-01, time/batch = 19.5093s	
21160/22950 (epoch 46.100), train_loss = 0.78613582, grad/param norm = 2.5967e-01, time/batch = 19.2000s	
21161/22950 (epoch 46.102), train_loss = 0.78507759, grad/param norm = 2.6092e-01, time/batch = 19.2792s	
21162/22950 (epoch 46.105), train_loss = 0.65471458, grad/param norm = 2.3220e-01, time/batch = 19.2571s	
21163/22950 (epoch 46.107), train_loss = 0.71027000, grad/param norm = 2.4815e-01, time/batch = 19.9581s	
21164/22950 (epoch 46.109), train_loss = 0.75226896, grad/param norm = 2.8812e-01, time/batch = 19.7043s	
21165/22950 (epoch 46.111), train_loss = 0.67772803, grad/param norm = 2.8601e-01, time/batch = 19.4507s	
21166/22950 (epoch 46.113), train_loss = 0.83349671, grad/param norm = 2.6123e-01, time/batch = 17.7111s	
21167/22950 (epoch 46.115), train_loss = 0.77924662, grad/param norm = 2.5535e-01, time/batch = 17.5074s	
21168/22950 (epoch 46.118), train_loss = 0.86894357, grad/param norm = 2.4161e-01, time/batch = 17.1874s	
21169/22950 (epoch 46.120), train_loss = 0.68863336, grad/param norm = 2.7659e-01, time/batch = 20.7844s	
21170/22950 (epoch 46.122), train_loss = 0.86074968, grad/param norm = 2.6162e-01, time/batch = 20.7034s	
