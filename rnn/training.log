tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 613, val: 33, test: 0	
vocab size: 167	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 305703	
cloning rnn	
cloning criterion	
1/30650 (epoch 0.002), train_loss = 5.10301207, grad/param norm = 5.1858e-01, time/batch = 0.7197s	
2/30650 (epoch 0.003), train_loss = 4.55807183, grad/param norm = 1.9087e+00, time/batch = 0.6807s	
3/30650 (epoch 0.005), train_loss = 3.79219434, grad/param norm = 1.3735e+00, time/batch = 0.6761s	
4/30650 (epoch 0.007), train_loss = 3.84029322, grad/param norm = 6.6979e-01, time/batch = 0.6770s	
5/30650 (epoch 0.008), train_loss = 3.71136438, grad/param norm = 6.2641e-01, time/batch = 0.6767s	
6/30650 (epoch 0.010), train_loss = 3.67114235, grad/param norm = 6.2289e-01, time/batch = 0.6761s	
7/30650 (epoch 0.011), train_loss = 3.46215233, grad/param norm = 9.5338e-01, time/batch = 0.6784s	
8/30650 (epoch 0.013), train_loss = 3.87127416, grad/param norm = 8.8299e-01, time/batch = 0.6763s	
9/30650 (epoch 0.015), train_loss = 3.62291939, grad/param norm = 8.0025e-01, time/batch = 0.6762s	
10/30650 (epoch 0.016), train_loss = 3.55304752, grad/param norm = 7.4123e-01, time/batch = 0.6765s	
11/30650 (epoch 0.018), train_loss = 3.60388496, grad/param norm = 5.9547e-01, time/batch = 0.6770s	
12/30650 (epoch 0.020), train_loss = 3.50579205, grad/param norm = 6.9682e-01, time/batch = 0.6759s	
13/30650 (epoch 0.021), train_loss = 3.67578707, grad/param norm = 7.5720e-01, time/batch = 0.6795s	
14/30650 (epoch 0.023), train_loss = 3.64382325, grad/param norm = 7.6507e-01, time/batch = 0.6805s	
15/30650 (epoch 0.024), train_loss = 3.69095143, grad/param norm = 8.3335e-01, time/batch = 0.6855s	
16/30650 (epoch 0.026), train_loss = 3.54806944, grad/param norm = 6.5220e-01, time/batch = 0.6807s	
17/30650 (epoch 0.028), train_loss = 3.70152658, grad/param norm = 7.9260e-01, time/batch = 0.6783s	
18/30650 (epoch 0.029), train_loss = 3.54922571, grad/param norm = 7.3536e-01, time/batch = 0.6765s	
19/30650 (epoch 0.031), train_loss = 3.62143945, grad/param norm = 6.6092e-01, time/batch = 0.6749s	
20/30650 (epoch 0.033), train_loss = 3.43957957, grad/param norm = 6.7246e-01, time/batch = 0.6804s	
21/30650 (epoch 0.034), train_loss = 3.53058976, grad/param norm = 8.4912e-01, time/batch = 0.6820s	
22/30650 (epoch 0.036), train_loss = 3.54023367, grad/param norm = 7.6529e-01, time/batch = 0.6785s	
23/30650 (epoch 0.038), train_loss = 3.47823132, grad/param norm = 6.5826e-01, time/batch = 0.6775s	
24/30650 (epoch 0.039), train_loss = 3.55988159, grad/param norm = 6.1755e-01, time/batch = 0.6767s	
25/30650 (epoch 0.041), train_loss = 3.64872903, grad/param norm = 8.2516e-01, time/batch = 0.6772s	
26/30650 (epoch 0.042), train_loss = 3.54947056, grad/param norm = 7.5135e-01, time/batch = 0.6778s	
27/30650 (epoch 0.044), train_loss = 3.48202091, grad/param norm = 6.1786e-01, time/batch = 0.6826s	
28/30650 (epoch 0.046), train_loss = 3.57861773, grad/param norm = 6.2784e-01, time/batch = 0.6779s	
29/30650 (epoch 0.047), train_loss = 3.48337478, grad/param norm = 6.3867e-01, time/batch = 0.6772s	
30/30650 (epoch 0.049), train_loss = 3.44548391, grad/param norm = 6.7732e-01, time/batch = 0.6779s	
31/30650 (epoch 0.051), train_loss = 3.51899645, grad/param norm = 6.3916e-01, time/batch = 0.6778s	
32/30650 (epoch 0.052), train_loss = 3.41228084, grad/param norm = 6.0134e-01, time/batch = 0.6794s	
33/30650 (epoch 0.054), train_loss = 3.47427740, grad/param norm = 9.9072e-01, time/batch = 0.6777s	
34/30650 (epoch 0.055), train_loss = 3.59095598, grad/param norm = 8.0563e-01, time/batch = 0.6801s	
35/30650 (epoch 0.057), train_loss = 3.47972898, grad/param norm = 6.1152e-01, time/batch = 0.7191s	
36/30650 (epoch 0.059), train_loss = 3.44245349, grad/param norm = 6.2023e-01, time/batch = 0.7027s	
37/30650 (epoch 0.060), train_loss = 3.37324594, grad/param norm = 5.7251e-01, time/batch = 0.7052s	
38/30650 (epoch 0.062), train_loss = 3.51271357, grad/param norm = 6.0776e-01, time/batch = 0.7119s	
39/30650 (epoch 0.064), train_loss = 3.58804777, grad/param norm = 7.5257e-01, time/batch = 0.7100s	
40/30650 (epoch 0.065), train_loss = 3.60826374, grad/param norm = 5.5990e-01, time/batch = 0.7141s	
41/30650 (epoch 0.067), train_loss = 3.71795575, grad/param norm = 6.9006e-01, time/batch = 0.7063s	
42/30650 (epoch 0.069), train_loss = 3.48869278, grad/param norm = 7.9794e-01, time/batch = 0.7083s	
43/30650 (epoch 0.070), train_loss = 3.61728574, grad/param norm = 8.5657e-01, time/batch = 0.7080s	
44/30650 (epoch 0.072), train_loss = 3.45508485, grad/param norm = 6.4996e-01, time/batch = 0.7087s	
45/30650 (epoch 0.073), train_loss = 3.49236673, grad/param norm = 6.4777e-01, time/batch = 0.7224s	
46/30650 (epoch 0.075), train_loss = 3.45769871, grad/param norm = 6.4468e-01, time/batch = 0.7105s	
47/30650 (epoch 0.077), train_loss = 3.44740562, grad/param norm = 5.0385e-01, time/batch = 0.6895s	
48/30650 (epoch 0.078), train_loss = 3.49337638, grad/param norm = 7.6484e-01, time/batch = 0.6951s	
49/30650 (epoch 0.080), train_loss = 3.50451395, grad/param norm = 9.3457e-01, time/batch = 0.6939s	
50/30650 (epoch 0.082), train_loss = 3.48552512, grad/param norm = 5.3981e-01, time/batch = 0.6837s	
51/30650 (epoch 0.083), train_loss = 3.51376840, grad/param norm = 6.3632e-01, time/batch = 0.6831s	
52/30650 (epoch 0.085), train_loss = 3.57936374, grad/param norm = 6.3750e-01, time/batch = 0.6835s	
53/30650 (epoch 0.086), train_loss = 3.60727204, grad/param norm = 7.2657e-01, time/batch = 0.6838s	
54/30650 (epoch 0.088), train_loss = 3.56674093, grad/param norm = 5.8797e-01, time/batch = 0.6789s	
55/30650 (epoch 0.090), train_loss = 3.52230025, grad/param norm = 7.1276e-01, time/batch = 0.6953s	
56/30650 (epoch 0.091), train_loss = 3.56258173, grad/param norm = 5.7974e-01, time/batch = 0.6909s	
57/30650 (epoch 0.093), train_loss = 3.51140145, grad/param norm = 6.1834e-01, time/batch = 0.6973s	
58/30650 (epoch 0.095), train_loss = 3.56847940, grad/param norm = 7.5775e-01, time/batch = 0.7051s	
59/30650 (epoch 0.096), train_loss = 3.46131652, grad/param norm = 6.5925e-01, time/batch = 0.7177s	
60/30650 (epoch 0.098), train_loss = 3.45725567, grad/param norm = 6.1231e-01, time/batch = 0.7151s	
61/30650 (epoch 0.100), train_loss = 3.39686704, grad/param norm = 7.5953e-01, time/batch = 0.7147s	
62/30650 (epoch 0.101), train_loss = 3.45295036, grad/param norm = 6.0623e-01, time/batch = 0.7132s	
63/30650 (epoch 0.103), train_loss = 3.51483820, grad/param norm = 6.8741e-01, time/batch = 0.7119s	
64/30650 (epoch 0.104), train_loss = 3.53273545, grad/param norm = 5.3060e-01, time/batch = 0.6967s	
65/30650 (epoch 0.106), train_loss = 3.33508395, grad/param norm = 6.1454e-01, time/batch = 0.6856s	
66/30650 (epoch 0.108), train_loss = 3.51515587, grad/param norm = 7.9743e-01, time/batch = 0.6757s	
67/30650 (epoch 0.109), train_loss = 3.41364732, grad/param norm = 6.1145e-01, time/batch = 0.6765s	
68/30650 (epoch 0.111), train_loss = 3.43815623, grad/param norm = 5.4824e-01, time/batch = 0.6756s	
69/30650 (epoch 0.113), train_loss = 3.57695059, grad/param norm = 6.5509e-01, time/batch = 0.7095s	
70/30650 (epoch 0.114), train_loss = 3.52922069, grad/param norm = 4.8925e-01, time/batch = 0.7108s	
71/30650 (epoch 0.116), train_loss = 3.50993748, grad/param norm = 6.2677e-01, time/batch = 0.6813s	
72/30650 (epoch 0.117), train_loss = 3.58398239, grad/param norm = 7.2276e-01, time/batch = 0.6950s	
73/30650 (epoch 0.119), train_loss = 3.73755659, grad/param norm = 6.6613e-01, time/batch = 0.6817s	
74/30650 (epoch 0.121), train_loss = 4.05582742, grad/param norm = 8.6400e-01, time/batch = 0.6817s	
75/30650 (epoch 0.122), train_loss = 3.61599919, grad/param norm = 6.1605e-01, time/batch = 0.6762s	
76/30650 (epoch 0.124), train_loss = 3.43787337, grad/param norm = 6.4515e-01, time/batch = 0.6818s	
77/30650 (epoch 0.126), train_loss = 3.55558135, grad/param norm = 6.2387e-01, time/batch = 0.6817s	
78/30650 (epoch 0.127), train_loss = 3.51681787, grad/param norm = 5.9080e-01, time/batch = 0.6744s	
79/30650 (epoch 0.129), train_loss = 3.46768281, grad/param norm = 5.0590e-01, time/batch = 0.6771s	
80/30650 (epoch 0.131), train_loss = 3.60282955, grad/param norm = 5.8368e-01, time/batch = 0.6787s	
81/30650 (epoch 0.132), train_loss = 3.63022044, grad/param norm = 5.8328e-01, time/batch = 0.6764s	
82/30650 (epoch 0.134), train_loss = 3.41689294, grad/param norm = 5.3977e-01, time/batch = 0.6853s	
83/30650 (epoch 0.135), train_loss = 3.34856830, grad/param norm = 4.5356e-01, time/batch = 0.6859s	
84/30650 (epoch 0.137), train_loss = 3.47730901, grad/param norm = 5.9897e-01, time/batch = 0.7206s	
85/30650 (epoch 0.139), train_loss = 3.47670365, grad/param norm = 5.0852e-01, time/batch = 0.6812s	
86/30650 (epoch 0.140), train_loss = 3.46373378, grad/param norm = 6.1545e-01, time/batch = 0.6773s	
87/30650 (epoch 0.142), train_loss = 3.37902527, grad/param norm = 5.5658e-01, time/batch = 0.6806s	
88/30650 (epoch 0.144), train_loss = 3.45826094, grad/param norm = 7.2675e-01, time/batch = 0.6912s	
89/30650 (epoch 0.145), train_loss = 3.50608547, grad/param norm = 4.8131e-01, time/batch = 0.6777s	
90/30650 (epoch 0.147), train_loss = 3.48785662, grad/param norm = 6.3261e-01, time/batch = 0.6757s	
91/30650 (epoch 0.148), train_loss = 3.59229548, grad/param norm = 6.2722e-01, time/batch = 0.6755s	
92/30650 (epoch 0.150), train_loss = 3.52047811, grad/param norm = 6.0007e-01, time/batch = 0.6776s	
93/30650 (epoch 0.152), train_loss = 3.45854399, grad/param norm = 5.3114e-01, time/batch = 0.6772s	
94/30650 (epoch 0.153), train_loss = 3.51534052, grad/param norm = 5.5478e-01, time/batch = 0.6764s	
95/30650 (epoch 0.155), train_loss = 3.44005770, grad/param norm = 4.9185e-01, time/batch = 0.6757s	
96/30650 (epoch 0.157), train_loss = 3.49401190, grad/param norm = 5.7641e-01, time/batch = 0.6752s	
97/30650 (epoch 0.158), train_loss = 3.38298560, grad/param norm = 5.6857e-01, time/batch = 0.6740s	
98/30650 (epoch 0.160), train_loss = 3.55506892, grad/param norm = 5.6616e-01, time/batch = 0.7049s	
99/30650 (epoch 0.162), train_loss = 3.39036394, grad/param norm = 6.2191e-01, time/batch = 0.7106s	
100/30650 (epoch 0.163), train_loss = 3.59286418, grad/param norm = 6.9419e-01, time/batch = 0.6770s	
101/30650 (epoch 0.165), train_loss = 3.50009667, grad/param norm = 5.6639e-01, time/batch = 0.6771s	
102/30650 (epoch 0.166), train_loss = 3.66831837, grad/param norm = 5.9840e-01, time/batch = 0.6770s	
103/30650 (epoch 0.168), train_loss = 3.53149727, grad/param norm = 7.9603e-01, time/batch = 0.6770s	
104/30650 (epoch 0.170), train_loss = 3.46580142, grad/param norm = 5.8481e-01, time/batch = 0.6785s	
105/30650 (epoch 0.171), train_loss = 3.44451132, grad/param norm = 6.3372e-01, time/batch = 0.6775s	
106/30650 (epoch 0.173), train_loss = 3.53061204, grad/param norm = 5.5472e-01, time/batch = 0.6759s	
107/30650 (epoch 0.175), train_loss = 3.49336465, grad/param norm = 6.7512e-01, time/batch = 0.6784s	
108/30650 (epoch 0.176), train_loss = 3.30825542, grad/param norm = 5.4266e-01, time/batch = 0.6762s	
109/30650 (epoch 0.178), train_loss = 3.54131335, grad/param norm = 8.3937e-01, time/batch = 0.6764s	
110/30650 (epoch 0.179), train_loss = 3.53831293, grad/param norm = 4.4338e-01, time/batch = 0.6777s	
111/30650 (epoch 0.181), train_loss = 3.51640240, grad/param norm = 5.6006e-01, time/batch = 0.6799s	
112/30650 (epoch 0.183), train_loss = 3.53978885, grad/param norm = 4.4854e-01, time/batch = 0.6790s	
113/30650 (epoch 0.184), train_loss = 3.48282458, grad/param norm = 4.5850e-01, time/batch = 0.6813s	
114/30650 (epoch 0.186), train_loss = 3.48309384, grad/param norm = 5.4214e-01, time/batch = 0.6784s	
115/30650 (epoch 0.188), train_loss = 3.42465454, grad/param norm = 4.2643e-01, time/batch = 0.6972s	
116/30650 (epoch 0.189), train_loss = 3.53191229, grad/param norm = 5.6811e-01, time/batch = 0.6763s	
117/30650 (epoch 0.191), train_loss = 3.51996644, grad/param norm = 4.6838e-01, time/batch = 0.6776s	
118/30650 (epoch 0.192), train_loss = 3.43898980, grad/param norm = 3.2909e-01, time/batch = 0.6792s	
119/30650 (epoch 0.194), train_loss = 3.47917786, grad/param norm = 3.7037e-01, time/batch = 0.6784s	
120/30650 (epoch 0.196), train_loss = 3.36190460, grad/param norm = 5.1310e-01, time/batch = 0.6783s	
121/30650 (epoch 0.197), train_loss = 3.47824318, grad/param norm = 7.1058e-01, time/batch = 0.6815s	
122/30650 (epoch 0.199), train_loss = 3.63423528, grad/param norm = 1.3354e+00, time/batch = 0.6796s	
123/30650 (epoch 0.201), train_loss = 3.56150473, grad/param norm = 4.9079e-01, time/batch = 0.6802s	
124/30650 (epoch 0.202), train_loss = 3.54454548, grad/param norm = 3.9428e-01, time/batch = 0.6791s	
125/30650 (epoch 0.204), train_loss = 3.44846968, grad/param norm = 7.2043e-01, time/batch = 0.6790s	
126/30650 (epoch 0.206), train_loss = 3.55110674, grad/param norm = 7.1562e-01, time/batch = 0.6779s	
127/30650 (epoch 0.207), train_loss = 3.41902717, grad/param norm = 5.6319e-01, time/batch = 0.6881s	
128/30650 (epoch 0.209), train_loss = 3.48876125, grad/param norm = 5.6412e-01, time/batch = 0.6829s	
129/30650 (epoch 0.210), train_loss = 3.54768048, grad/param norm = 4.7504e-01, time/batch = 0.6825s	
130/30650 (epoch 0.212), train_loss = 3.46278035, grad/param norm = 5.5546e-01, time/batch = 0.6777s	
131/30650 (epoch 0.214), train_loss = 3.48300568, grad/param norm = 4.5715e-01, time/batch = 0.6784s	
132/30650 (epoch 0.215), train_loss = 3.64480121, grad/param norm = 5.5045e-01, time/batch = 0.6807s	
133/30650 (epoch 0.217), train_loss = 3.36674559, grad/param norm = 6.5284e-01, time/batch = 0.6771s	
134/30650 (epoch 0.219), train_loss = 3.42538331, grad/param norm = 7.4502e-01, time/batch = 0.6774s	
135/30650 (epoch 0.220), train_loss = 3.42349953, grad/param norm = 7.4190e-01, time/batch = 0.6758s	
136/30650 (epoch 0.222), train_loss = 3.34632727, grad/param norm = 6.0582e-01, time/batch = 0.6774s	
137/30650 (epoch 0.223), train_loss = 3.37712817, grad/param norm = 4.4890e-01, time/batch = 0.6786s	
138/30650 (epoch 0.225), train_loss = 3.31735342, grad/param norm = 7.4517e-01, time/batch = 0.6766s	
139/30650 (epoch 0.227), train_loss = 3.45054519, grad/param norm = 7.3164e-01, time/batch = 0.6776s	
140/30650 (epoch 0.228), train_loss = 3.57101937, grad/param norm = 5.1467e-01, time/batch = 0.6777s	
141/30650 (epoch 0.230), train_loss = 3.40549128, grad/param norm = 4.1580e-01, time/batch = 0.6794s	
142/30650 (epoch 0.232), train_loss = 3.44364146, grad/param norm = 5.1909e-01, time/batch = 0.6780s	
143/30650 (epoch 0.233), train_loss = 3.34956848, grad/param norm = 6.5040e-01, time/batch = 0.6849s	
144/30650 (epoch 0.235), train_loss = 3.47245406, grad/param norm = 7.8816e-01, time/batch = 0.6772s	
145/30650 (epoch 0.237), train_loss = 3.51939966, grad/param norm = 8.5399e-01, time/batch = 0.6772s	
146/30650 (epoch 0.238), train_loss = 3.43037412, grad/param norm = 5.5320e-01, time/batch = 0.6893s	
147/30650 (epoch 0.240), train_loss = 3.43604072, grad/param norm = 4.6403e-01, time/batch = 0.6802s	
148/30650 (epoch 0.241), train_loss = 3.40411971, grad/param norm = 6.2085e-01, time/batch = 0.6812s	
149/30650 (epoch 0.243), train_loss = 3.45161207, grad/param norm = 6.1643e-01, time/batch = 0.6743s	
150/30650 (epoch 0.245), train_loss = 3.44282210, grad/param norm = 5.4078e-01, time/batch = 0.6768s	
151/30650 (epoch 0.246), train_loss = 3.37770241, grad/param norm = 6.0226e-01, time/batch = 0.6798s	
152/30650 (epoch 0.248), train_loss = 3.38493680, grad/param norm = 5.6978e-01, time/batch = 0.6770s	
153/30650 (epoch 0.250), train_loss = 3.39609162, grad/param norm = 4.5816e-01, time/batch = 0.6787s	
154/30650 (epoch 0.251), train_loss = 3.44108733, grad/param norm = 5.2980e-01, time/batch = 0.6767s	
155/30650 (epoch 0.253), train_loss = 3.45641899, grad/param norm = 8.2419e-01, time/batch = 0.6790s	
156/30650 (epoch 0.254), train_loss = 3.51729945, grad/param norm = 1.8091e+00, time/batch = 0.6762s	
157/30650 (epoch 0.256), train_loss = 3.27032508, grad/param norm = 1.0444e+00, time/batch = 0.6770s	
158/30650 (epoch 0.258), train_loss = 3.39018322, grad/param norm = 6.0049e-01, time/batch = 0.6991s	
159/30650 (epoch 0.259), train_loss = 3.41110974, grad/param norm = 4.0540e-01, time/batch = 0.6877s	
160/30650 (epoch 0.261), train_loss = 3.20276786, grad/param norm = 4.2222e-01, time/batch = 0.6803s	
161/30650 (epoch 0.263), train_loss = 3.37369597, grad/param norm = 6.9987e-01, time/batch = 0.6848s	
162/30650 (epoch 0.264), train_loss = 3.30967629, grad/param norm = 6.4284e-01, time/batch = 0.6835s	
163/30650 (epoch 0.266), train_loss = 3.36616518, grad/param norm = 8.2285e-01, time/batch = 0.6910s	
164/30650 (epoch 0.268), train_loss = 3.22191395, grad/param norm = 1.0038e+00, time/batch = 0.6765s	
165/30650 (epoch 0.269), train_loss = 3.26316720, grad/param norm = 7.5468e-01, time/batch = 0.6878s	
166/30650 (epoch 0.271), train_loss = 3.22363918, grad/param norm = 4.8624e-01, time/batch = 0.6984s	
167/30650 (epoch 0.272), train_loss = 3.21130849, grad/param norm = 3.7158e-01, time/batch = 0.6967s	
168/30650 (epoch 0.274), train_loss = 3.17879472, grad/param norm = 3.0577e-01, time/batch = 0.6976s	
169/30650 (epoch 0.276), train_loss = 3.18220202, grad/param norm = 2.9777e-01, time/batch = 0.6980s	
170/30650 (epoch 0.277), train_loss = 3.23385785, grad/param norm = 5.1731e-01, time/batch = 0.6953s	
171/30650 (epoch 0.279), train_loss = 3.23255117, grad/param norm = 7.3216e-01, time/batch = 0.7157s	
172/30650 (epoch 0.281), train_loss = 3.31750123, grad/param norm = 8.6450e-01, time/batch = 0.7163s	
173/30650 (epoch 0.282), train_loss = 3.20861242, grad/param norm = 8.8410e-01, time/batch = 0.6987s	
174/30650 (epoch 0.284), train_loss = 3.32749099, grad/param norm = 7.2984e-01, time/batch = 0.7025s	
175/30650 (epoch 0.285), train_loss = 3.16127843, grad/param norm = 4.7309e-01, time/batch = 0.6891s	
176/30650 (epoch 0.287), train_loss = 3.31641374, grad/param norm = 4.4704e-01, time/batch = 0.6760s	
177/30650 (epoch 0.289), train_loss = 3.15153838, grad/param norm = 4.3936e-01, time/batch = 0.6792s	
178/30650 (epoch 0.290), train_loss = 3.23353768, grad/param norm = 3.8941e-01, time/batch = 0.6783s	
179/30650 (epoch 0.292), train_loss = 3.16077676, grad/param norm = 3.6486e-01, time/batch = 0.6757s	
180/30650 (epoch 0.294), train_loss = 3.17988229, grad/param norm = 6.8701e-01, time/batch = 0.6753s	
181/30650 (epoch 0.295), train_loss = 3.28875805, grad/param norm = 1.0567e+00, time/batch = 0.6778s	
182/30650 (epoch 0.297), train_loss = 3.32912609, grad/param norm = 1.2920e+00, time/batch = 0.6777s	
183/30650 (epoch 0.299), train_loss = 3.15166450, grad/param norm = 9.4036e-01, time/batch = 0.6763s	
184/30650 (epoch 0.300), train_loss = 3.16304120, grad/param norm = 5.6086e-01, time/batch = 0.6771s	
185/30650 (epoch 0.302), train_loss = 3.22958798, grad/param norm = 4.9381e-01, time/batch = 0.6783s	
186/30650 (epoch 0.303), train_loss = 3.19710709, grad/param norm = 4.2592e-01, time/batch = 0.6760s	
187/30650 (epoch 0.305), train_loss = 3.14675529, grad/param norm = 5.0791e-01, time/batch = 0.6863s	
188/30650 (epoch 0.307), train_loss = 3.24004674, grad/param norm = 4.8817e-01, time/batch = 0.6763s	
189/30650 (epoch 0.308), train_loss = 3.31546386, grad/param norm = 3.4401e-01, time/batch = 0.6756s	
190/30650 (epoch 0.310), train_loss = 3.14789510, grad/param norm = 4.5437e-01, time/batch = 0.6869s	
191/30650 (epoch 0.312), train_loss = 3.72474512, grad/param norm = 1.1721e+00, time/batch = 0.6850s	
192/30650 (epoch 0.313), train_loss = 3.63155792, grad/param norm = 2.1463e+00, time/batch = 0.6942s	
193/30650 (epoch 0.315), train_loss = 3.73774734, grad/param norm = 1.4996e+00, time/batch = 0.6881s	
194/30650 (epoch 0.316), train_loss = 3.67522189, grad/param norm = 7.2687e-01, time/batch = 0.6791s	
195/30650 (epoch 0.318), train_loss = 4.20766204, grad/param norm = 5.1099e+00, time/batch = 0.6741s	
196/30650 (epoch 0.320), train_loss = 3.42116722, grad/param norm = 1.3504e+00, time/batch = 0.7180s	
197/30650 (epoch 0.321), train_loss = 3.49762418, grad/param norm = 8.6128e-01, time/batch = 0.6968s	
198/30650 (epoch 0.323), train_loss = 3.13705401, grad/param norm = 5.5262e-01, time/batch = 0.6756s	
199/30650 (epoch 0.325), train_loss = 3.11572966, grad/param norm = 4.4484e-01, time/batch = 0.6770s	
200/30650 (epoch 0.326), train_loss = 3.09952711, grad/param norm = 5.7779e-01, time/batch = 0.6779s	
201/30650 (epoch 0.328), train_loss = 3.23916440, grad/param norm = 6.7762e-01, time/batch = 0.6785s	
202/30650 (epoch 0.330), train_loss = 3.23362894, grad/param norm = 3.7460e-01, time/batch = 0.6795s	
203/30650 (epoch 0.331), train_loss = 3.21761119, grad/param norm = 3.5668e-01, time/batch = 0.6763s	
204/30650 (epoch 0.333), train_loss = 3.26979103, grad/param norm = 3.8576e-01, time/batch = 0.6761s	
205/30650 (epoch 0.334), train_loss = 3.16691709, grad/param norm = 3.7405e-01, time/batch = 0.6784s	
206/30650 (epoch 0.336), train_loss = 3.18721093, grad/param norm = 3.6760e-01, time/batch = 0.6811s	
207/30650 (epoch 0.338), train_loss = 3.13665676, grad/param norm = 3.0651e-01, time/batch = 0.6765s	
208/30650 (epoch 0.339), train_loss = 3.19085601, grad/param norm = 4.4687e-01, time/batch = 0.6963s	
209/30650 (epoch 0.341), train_loss = 3.11975398, grad/param norm = 7.3748e-01, time/batch = 0.6821s	
210/30650 (epoch 0.343), train_loss = 3.03135721, grad/param norm = 7.8179e-01, time/batch = 0.6744s	
211/30650 (epoch 0.344), train_loss = 3.13544994, grad/param norm = 8.5691e-01, time/batch = 0.6796s	
212/30650 (epoch 0.346), train_loss = 3.02976695, grad/param norm = 7.7314e-01, time/batch = 0.6787s	
213/30650 (epoch 0.347), train_loss = 3.14878060, grad/param norm = 5.4589e-01, time/batch = 0.6747s	
214/30650 (epoch 0.349), train_loss = 3.15864181, grad/param norm = 4.2825e-01, time/batch = 0.6766s	
215/30650 (epoch 0.351), train_loss = 3.33885599, grad/param norm = 9.3499e-01, time/batch = 0.6829s	
216/30650 (epoch 0.352), train_loss = 3.35806262, grad/param norm = 8.0683e-01, time/batch = 0.6746s	
217/30650 (epoch 0.354), train_loss = 3.20927040, grad/param norm = 7.2921e-01, time/batch = 0.6781s	
218/30650 (epoch 0.356), train_loss = 3.26253956, grad/param norm = 5.3467e-01, time/batch = 0.6805s	
219/30650 (epoch 0.357), train_loss = 3.18595705, grad/param norm = 4.5959e-01, time/batch = 0.6761s	
220/30650 (epoch 0.359), train_loss = 3.33280624, grad/param norm = 4.9135e-01, time/batch = 0.6767s	
221/30650 (epoch 0.361), train_loss = 3.37257292, grad/param norm = 3.8333e-01, time/batch = 0.6812s	
222/30650 (epoch 0.362), train_loss = 3.20589540, grad/param norm = 3.8542e-01, time/batch = 0.6782s	
223/30650 (epoch 0.364), train_loss = 3.28476981, grad/param norm = 3.3878e-01, time/batch = 0.6814s	
224/30650 (epoch 0.365), train_loss = 3.10810043, grad/param norm = 4.9243e-01, time/batch = 0.6767s	
225/30650 (epoch 0.367), train_loss = 3.37522045, grad/param norm = 8.4251e-01, time/batch = 0.6769s	
226/30650 (epoch 0.369), train_loss = 3.31553184, grad/param norm = 6.1870e-01, time/batch = 0.6776s	
227/30650 (epoch 0.370), train_loss = 3.19260495, grad/param norm = 3.4136e-01, time/batch = 0.6764s	
228/30650 (epoch 0.372), train_loss = 3.33272597, grad/param norm = 4.4095e-01, time/batch = 0.6784s	
229/30650 (epoch 0.374), train_loss = 3.36705989, grad/param norm = 5.8491e+00, time/batch = 0.6876s	
230/30650 (epoch 0.375), train_loss = 3.23892299, grad/param norm = 6.2492e-01, time/batch = 0.7161s	
231/30650 (epoch 0.377), train_loss = 3.25876048, grad/param norm = 6.1582e-01, time/batch = 0.6784s	
232/30650 (epoch 0.378), train_loss = 3.04976316, grad/param norm = 5.0616e-01, time/batch = 0.6799s	
233/30650 (epoch 0.380), train_loss = 3.04410872, grad/param norm = 3.9612e-01, time/batch = 0.6762s	
234/30650 (epoch 0.382), train_loss = 2.99555637, grad/param norm = 3.3612e-01, time/batch = 0.6765s	
235/30650 (epoch 0.383), train_loss = 3.12276775, grad/param norm = 3.4181e-01, time/batch = 0.6769s	
236/30650 (epoch 0.385), train_loss = 2.98762572, grad/param norm = 3.1427e-01, time/batch = 0.6808s	
237/30650 (epoch 0.387), train_loss = 2.86486327, grad/param norm = 3.7563e-01, time/batch = 0.6763s	
238/30650 (epoch 0.388), train_loss = 3.06672541, grad/param norm = 3.8740e-01, time/batch = 0.6782s	
239/30650 (epoch 0.390), train_loss = 2.92947970, grad/param norm = 5.4423e-01, time/batch = 0.6765s	
240/30650 (epoch 0.392), train_loss = 2.90902215, grad/param norm = 7.8371e-01, time/batch = 0.6758s	
241/30650 (epoch 0.393), train_loss = 3.00203428, grad/param norm = 1.2656e+00, time/batch = 0.6781s	
242/30650 (epoch 0.395), train_loss = 3.03236420, grad/param norm = 1.0128e+00, time/batch = 0.6775s	
243/30650 (epoch 0.396), train_loss = 3.16834154, grad/param norm = 1.1435e+00, time/batch = 0.6783s	
244/30650 (epoch 0.398), train_loss = 3.10795652, grad/param norm = 9.5430e-01, time/batch = 0.7062s	
245/30650 (epoch 0.400), train_loss = 2.96950665, grad/param norm = 4.6610e-01, time/batch = 0.7182s	
246/30650 (epoch 0.401), train_loss = 2.91807886, grad/param norm = 3.5981e-01, time/batch = 0.6870s	
247/30650 (epoch 0.403), train_loss = 2.91796223, grad/param norm = 3.8285e-01, time/batch = 0.6873s	
248/30650 (epoch 0.405), train_loss = 2.91333631, grad/param norm = 3.5414e-01, time/batch = 0.6821s	
249/30650 (epoch 0.406), train_loss = 2.94503186, grad/param norm = 4.9417e-01, time/batch = 0.6800s	
250/30650 (epoch 0.408), train_loss = 3.07317188, grad/param norm = 4.1351e-01, time/batch = 0.6813s	
251/30650 (epoch 0.409), train_loss = 3.01061261, grad/param norm = 5.5436e-01, time/batch = 0.6794s	
252/30650 (epoch 0.411), train_loss = 2.99349972, grad/param norm = 1.3512e+00, time/batch = 0.6778s	
253/30650 (epoch 0.413), train_loss = 3.08364268, grad/param norm = 1.3024e+00, time/batch = 0.6789s	
254/30650 (epoch 0.414), train_loss = 2.97590094, grad/param norm = 4.0896e-01, time/batch = 0.6794s	
255/30650 (epoch 0.416), train_loss = 3.01581693, grad/param norm = 3.7846e-01, time/batch = 0.6789s	
256/30650 (epoch 0.418), train_loss = 3.04282525, grad/param norm = 3.8833e-01, time/batch = 0.6759s	
257/30650 (epoch 0.419), train_loss = 3.03517793, grad/param norm = 4.0977e-01, time/batch = 0.6796s	
258/30650 (epoch 0.421), train_loss = 3.00980545, grad/param norm = 4.0881e-01, time/batch = 0.6931s	
259/30650 (epoch 0.423), train_loss = 2.96811329, grad/param norm = 6.0047e-01, time/batch = 0.7216s	
260/30650 (epoch 0.424), train_loss = 3.09561663, grad/param norm = 5.6958e-01, time/batch = 0.6893s	
261/30650 (epoch 0.426), train_loss = 2.84328088, grad/param norm = 7.8015e-01, time/batch = 0.6821s	
262/30650 (epoch 0.427), train_loss = 3.16508130, grad/param norm = 9.1020e-01, time/batch = 0.6852s	
263/30650 (epoch 0.429), train_loss = 2.92850431, grad/param norm = 6.6800e-01, time/batch = 0.6842s	
264/30650 (epoch 0.431), train_loss = 2.96862169, grad/param norm = 3.5915e-01, time/batch = 0.6819s	
265/30650 (epoch 0.432), train_loss = 2.98141752, grad/param norm = 3.7807e-01, time/batch = 0.6859s	
266/30650 (epoch 0.434), train_loss = 3.15218889, grad/param norm = 6.8493e-01, time/batch = 0.6803s	
267/30650 (epoch 0.436), train_loss = 3.24319217, grad/param norm = 6.6073e-01, time/batch = 0.6776s	
268/30650 (epoch 0.437), train_loss = 3.12661377, grad/param norm = 5.3520e-01, time/batch = 0.6804s	
269/30650 (epoch 0.439), train_loss = 3.05264210, grad/param norm = 7.1748e-01, time/batch = 0.6784s	
270/30650 (epoch 0.440), train_loss = 2.96879811, grad/param norm = 5.9199e-01, time/batch = 0.6765s	
271/30650 (epoch 0.442), train_loss = 2.86033693, grad/param norm = 7.1880e-01, time/batch = 0.6786s	
272/30650 (epoch 0.444), train_loss = 2.89552809, grad/param norm = 6.3743e-01, time/batch = 0.6785s	
273/30650 (epoch 0.445), train_loss = 3.02003252, grad/param norm = 3.5278e-01, time/batch = 0.6802s	
274/30650 (epoch 0.447), train_loss = 3.08302553, grad/param norm = 5.9577e-01, time/batch = 0.6855s	
275/30650 (epoch 0.449), train_loss = 2.87972917, grad/param norm = 6.8565e-01, time/batch = 0.6766s	
276/30650 (epoch 0.450), train_loss = 2.98579671, grad/param norm = 7.7334e-01, time/batch = 0.6746s	
277/30650 (epoch 0.452), train_loss = 2.99053280, grad/param norm = 8.8692e-01, time/batch = 0.6746s	
278/30650 (epoch 0.454), train_loss = 2.96950898, grad/param norm = 1.0018e+00, time/batch = 0.6766s	
279/30650 (epoch 0.455), train_loss = 3.01904021, grad/param norm = 6.6900e-01, time/batch = 0.6770s	
280/30650 (epoch 0.457), train_loss = 2.88788753, grad/param norm = 5.3584e-01, time/batch = 0.6780s	
281/30650 (epoch 0.458), train_loss = 2.94585360, grad/param norm = 4.2520e-01, time/batch = 0.6783s	
282/30650 (epoch 0.460), train_loss = 2.88881031, grad/param norm = 3.6203e-01, time/batch = 0.6783s	
283/30650 (epoch 0.462), train_loss = 2.93208499, grad/param norm = 3.8808e-01, time/batch = 0.6774s	
284/30650 (epoch 0.463), train_loss = 2.78658608, grad/param norm = 6.3983e-01, time/batch = 0.6775s	
285/30650 (epoch 0.465), train_loss = 3.13956308, grad/param norm = 9.0394e-01, time/batch = 0.6786s	
286/30650 (epoch 0.467), train_loss = 3.10788100, grad/param norm = 5.9177e-01, time/batch = 0.6789s	
287/30650 (epoch 0.468), train_loss = 3.17353432, grad/param norm = 4.7693e-01, time/batch = 0.6784s	
288/30650 (epoch 0.470), train_loss = 2.95316297, grad/param norm = 6.0684e-01, time/batch = 0.7158s	
289/30650 (epoch 0.471), train_loss = 2.89307364, grad/param norm = 7.0023e-01, time/batch = 0.7052s	
290/30650 (epoch 0.473), train_loss = 3.05901149, grad/param norm = 7.3841e-01, time/batch = 0.6790s	
291/30650 (epoch 0.475), train_loss = 2.97673479, grad/param norm = 6.3288e-01, time/batch = 0.6787s	
292/30650 (epoch 0.476), train_loss = 2.98654062, grad/param norm = 5.3377e-01, time/batch = 0.6771s	
293/30650 (epoch 0.478), train_loss = 2.88302378, grad/param norm = 4.9918e-01, time/batch = 0.6807s	
294/30650 (epoch 0.480), train_loss = 2.91144884, grad/param norm = 3.7342e-01, time/batch = 0.6790s	
295/30650 (epoch 0.481), train_loss = 2.76759433, grad/param norm = 3.7898e-01, time/batch = 0.6762s	
296/30650 (epoch 0.483), train_loss = 2.92617721, grad/param norm = 6.8115e-01, time/batch = 0.6781s	
297/30650 (epoch 0.485), train_loss = 3.05836280, grad/param norm = 7.8875e-01, time/batch = 0.6764s	
298/30650 (epoch 0.486), train_loss = 2.99785145, grad/param norm = 6.6913e-01, time/batch = 0.6759s	
299/30650 (epoch 0.488), train_loss = 2.89826836, grad/param norm = 4.3284e-01, time/batch = 0.6763s	
300/30650 (epoch 0.489), train_loss = 2.83904932, grad/param norm = 4.4340e-01, time/batch = 0.6793s	
301/30650 (epoch 0.491), train_loss = 2.85390523, grad/param norm = 6.3046e-01, time/batch = 0.6804s	
302/30650 (epoch 0.493), train_loss = 2.91045140, grad/param norm = 1.0044e+00, time/batch = 0.6928s	
303/30650 (epoch 0.494), train_loss = 2.89385936, grad/param norm = 9.8153e-01, time/batch = 0.6873s	
304/30650 (epoch 0.496), train_loss = 2.83289829, grad/param norm = 4.0297e-01, time/batch = 0.6796s	
305/30650 (epoch 0.498), train_loss = 2.87280174, grad/param norm = 5.2326e-01, time/batch = 0.6792s	
306/30650 (epoch 0.499), train_loss = 2.99706462, grad/param norm = 7.2712e-01, time/batch = 0.6757s	
307/30650 (epoch 0.501), train_loss = 3.06433387, grad/param norm = 5.6766e-01, time/batch = 0.6764s	
308/30650 (epoch 0.502), train_loss = 2.93827346, grad/param norm = 5.4623e-01, time/batch = 0.6755s	
309/30650 (epoch 0.504), train_loss = 2.93719557, grad/param norm = 4.0157e-01, time/batch = 0.6794s	
310/30650 (epoch 0.506), train_loss = 2.91976608, grad/param norm = 4.4286e-01, time/batch = 0.6790s	
311/30650 (epoch 0.507), train_loss = 2.79297454, grad/param norm = 3.5900e-01, time/batch = 0.6772s	
312/30650 (epoch 0.509), train_loss = 2.83774572, grad/param norm = 3.5048e-01, time/batch = 0.6777s	
313/30650 (epoch 0.511), train_loss = 2.80813873, grad/param norm = 2.9920e-01, time/batch = 0.6753s	
314/30650 (epoch 0.512), train_loss = 2.74037286, grad/param norm = 3.8483e-01, time/batch = 0.6748s	
315/30650 (epoch 0.514), train_loss = 2.87490521, grad/param norm = 5.5474e-01, time/batch = 0.6780s	
316/30650 (epoch 0.515), train_loss = 2.89925248, grad/param norm = 9.1650e-01, time/batch = 0.6814s	
317/30650 (epoch 0.517), train_loss = 2.87757055, grad/param norm = 8.8191e-01, time/batch = 0.7054s	
318/30650 (epoch 0.519), train_loss = 2.90392688, grad/param norm = 5.8527e-01, time/batch = 0.7101s	
319/30650 (epoch 0.520), train_loss = 2.81588955, grad/param norm = 5.4219e-01, time/batch = 0.6768s	
320/30650 (epoch 0.522), train_loss = 3.24523306, grad/param norm = 6.8437e-01, time/batch = 0.6762s	
321/30650 (epoch 0.524), train_loss = 2.81708821, grad/param norm = 4.7480e-01, time/batch = 0.6774s	
322/30650 (epoch 0.525), train_loss = 2.69930715, grad/param norm = 5.5772e-01, time/batch = 0.6761s	
323/30650 (epoch 0.527), train_loss = 2.95999831, grad/param norm = 4.1554e-01, time/batch = 0.6780s	
324/30650 (epoch 0.529), train_loss = 2.85761717, grad/param norm = 3.5334e-01, time/batch = 0.6783s	
325/30650 (epoch 0.530), train_loss = 2.85851129, grad/param norm = 4.2929e-01, time/batch = 0.6751s	
326/30650 (epoch 0.532), train_loss = 2.71728728, grad/param norm = 5.3421e-01, time/batch = 0.6766s	
327/30650 (epoch 0.533), train_loss = 2.86242629, grad/param norm = 8.3302e-01, time/batch = 0.6768s	
328/30650 (epoch 0.535), train_loss = 2.97737899, grad/param norm = 1.1152e+00, time/batch = 0.6760s	
329/30650 (epoch 0.537), train_loss = 3.04388648, grad/param norm = 7.7834e-01, time/batch = 0.6750s	
330/30650 (epoch 0.538), train_loss = 2.89181071, grad/param norm = 4.3344e-01, time/batch = 0.6761s	
331/30650 (epoch 0.540), train_loss = 2.84311612, grad/param norm = 3.8798e-01, time/batch = 0.6812s	
332/30650 (epoch 0.542), train_loss = 2.89299003, grad/param norm = 4.6073e-01, time/batch = 0.7221s	
333/30650 (epoch 0.543), train_loss = 2.92548819, grad/param norm = 5.1352e-01, time/batch = 0.7052s	
334/30650 (epoch 0.545), train_loss = 2.83418020, grad/param norm = 7.1731e-01, time/batch = 0.6906s	
335/30650 (epoch 0.546), train_loss = 2.79970739, grad/param norm = 7.6848e-01, time/batch = 0.6971s	
336/30650 (epoch 0.548), train_loss = 2.90276834, grad/param norm = 4.2213e-01, time/batch = 0.6906s	
337/30650 (epoch 0.550), train_loss = 2.86722913, grad/param norm = 3.4593e-01, time/batch = 0.6777s	
338/30650 (epoch 0.551), train_loss = 2.82467587, grad/param norm = 3.0865e-01, time/batch = 0.6816s	
339/30650 (epoch 0.553), train_loss = 2.92356341, grad/param norm = 3.4938e-01, time/batch = 0.6809s	
340/30650 (epoch 0.555), train_loss = 2.81483216, grad/param norm = 3.7398e-01, time/batch = 0.6775s	
341/30650 (epoch 0.556), train_loss = 2.72933707, grad/param norm = 3.9837e-01, time/batch = 0.6791s	
342/30650 (epoch 0.558), train_loss = 2.84098653, grad/param norm = 4.4409e-01, time/batch = 0.6785s	
343/30650 (epoch 0.560), train_loss = 2.82775121, grad/param norm = 5.5080e-01, time/batch = 0.6777s	
344/30650 (epoch 0.561), train_loss = 2.85470919, grad/param norm = 6.1958e-01, time/batch = 0.6903s	
345/30650 (epoch 0.563), train_loss = 2.83898194, grad/param norm = 6.4843e-01, time/batch = 0.6859s	
346/30650 (epoch 0.564), train_loss = 2.74801437, grad/param norm = 5.6196e-01, time/batch = 0.7019s	
347/30650 (epoch 0.566), train_loss = 2.77585892, grad/param norm = 4.5339e-01, time/batch = 0.7023s	
348/30650 (epoch 0.568), train_loss = 2.90189926, grad/param norm = 4.8247e-01, time/batch = 0.6828s	
349/30650 (epoch 0.569), train_loss = 2.77065854, grad/param norm = 5.6107e-01, time/batch = 0.6788s	
350/30650 (epoch 0.571), train_loss = 2.86490403, grad/param norm = 6.1634e-01, time/batch = 0.6804s	
351/30650 (epoch 0.573), train_loss = 2.79250631, grad/param norm = 4.7900e-01, time/batch = 0.6787s	
352/30650 (epoch 0.574), train_loss = 2.79288297, grad/param norm = 3.0778e-01, time/batch = 0.6768s	
353/30650 (epoch 0.576), train_loss = 2.72661054, grad/param norm = 5.5081e-01, time/batch = 0.6771s	
354/30650 (epoch 0.577), train_loss = 2.79230158, grad/param norm = 6.7841e-01, time/batch = 0.6764s	
355/30650 (epoch 0.579), train_loss = 2.83751758, grad/param norm = 6.7904e-01, time/batch = 0.6770s	
356/30650 (epoch 0.581), train_loss = 2.83763447, grad/param norm = 5.2448e-01, time/batch = 0.6768s	
357/30650 (epoch 0.582), train_loss = 2.74227236, grad/param norm = 3.8659e-01, time/batch = 0.6759s	
358/30650 (epoch 0.584), train_loss = 2.90727492, grad/param norm = 3.6961e-01, time/batch = 0.6753s	
359/30650 (epoch 0.586), train_loss = 2.85369707, grad/param norm = 4.4444e-01, time/batch = 0.6775s	
360/30650 (epoch 0.587), train_loss = 2.84990737, grad/param norm = 4.4816e-01, time/batch = 0.6776s	
361/30650 (epoch 0.589), train_loss = 2.80170361, grad/param norm = 6.4474e-01, time/batch = 0.7210s	
362/30650 (epoch 0.591), train_loss = 2.83507291, grad/param norm = 6.6493e-01, time/batch = 0.6996s	
363/30650 (epoch 0.592), train_loss = 2.84715176, grad/param norm = 6.2374e-01, time/batch = 0.6795s	
364/30650 (epoch 0.594), train_loss = 2.90347600, grad/param norm = 6.5700e-01, time/batch = 0.6775s	
365/30650 (epoch 0.595), train_loss = 2.90276673, grad/param norm = 1.2364e+00, time/batch = 0.6767s	
366/30650 (epoch 0.597), train_loss = 2.74404141, grad/param norm = 6.3674e-01, time/batch = 0.6787s	
367/30650 (epoch 0.599), train_loss = 2.83294838, grad/param norm = 4.6513e-01, time/batch = 0.6786s	
368/30650 (epoch 0.600), train_loss = 2.73403773, grad/param norm = 3.6357e-01, time/batch = 0.6761s	
369/30650 (epoch 0.602), train_loss = 2.69629481, grad/param norm = 3.8350e-01, time/batch = 0.6764s	
370/30650 (epoch 0.604), train_loss = 2.70355098, grad/param norm = 4.1281e-01, time/batch = 0.6785s	
371/30650 (epoch 0.605), train_loss = 2.62904337, grad/param norm = 7.6404e-01, time/batch = 0.6786s	
372/30650 (epoch 0.607), train_loss = 2.80615368, grad/param norm = 9.7796e-01, time/batch = 0.6767s	
373/30650 (epoch 0.608), train_loss = 2.69939414, grad/param norm = 8.1984e-01, time/batch = 0.6768s	
374/30650 (epoch 0.610), train_loss = 2.88457073, grad/param norm = 6.9463e-01, time/batch = 0.6830s	
375/30650 (epoch 0.612), train_loss = 2.82713714, grad/param norm = 4.1896e-01, time/batch = 0.6966s	
376/30650 (epoch 0.613), train_loss = 2.83824776, grad/param norm = 4.0082e-01, time/batch = 0.7215s	
377/30650 (epoch 0.615), train_loss = 2.74558994, grad/param norm = 3.5777e-01, time/batch = 0.6859s	
378/30650 (epoch 0.617), train_loss = 2.76417658, grad/param norm = 4.9248e-01, time/batch = 0.6769s	
379/30650 (epoch 0.618), train_loss = 2.94314263, grad/param norm = 5.3634e-01, time/batch = 0.6792s	
380/30650 (epoch 0.620), train_loss = 2.75636947, grad/param norm = 5.4664e-01, time/batch = 0.6846s	
381/30650 (epoch 0.622), train_loss = 2.62506248, grad/param norm = 4.8613e-01, time/batch = 0.6838s	
382/30650 (epoch 0.623), train_loss = 2.66628293, grad/param norm = 5.7070e-01, time/batch = 0.6798s	
383/30650 (epoch 0.625), train_loss = 2.80673739, grad/param norm = 6.3992e-01, time/batch = 0.6775s	
384/30650 (epoch 0.626), train_loss = 2.84159955, grad/param norm = 4.9940e-01, time/batch = 0.6800s	
385/30650 (epoch 0.628), train_loss = 2.90285219, grad/param norm = 5.0602e-01, time/batch = 0.6795s	
386/30650 (epoch 0.630), train_loss = 2.76156306, grad/param norm = 4.3264e-01, time/batch = 0.6771s	
387/30650 (epoch 0.631), train_loss = 2.73732491, grad/param norm = 3.1822e-01, time/batch = 0.6779s	
388/30650 (epoch 0.633), train_loss = 2.75114810, grad/param norm = 3.4317e-01, time/batch = 0.6782s	
389/30650 (epoch 0.635), train_loss = 2.73133767, grad/param norm = 4.1421e-01, time/batch = 0.6794s	
390/30650 (epoch 0.636), train_loss = 2.69042541, grad/param norm = 3.4704e-01, time/batch = 0.7127s	
391/30650 (epoch 0.638), train_loss = 2.73756127, grad/param norm = 4.8195e-01, time/batch = 0.7050s	
392/30650 (epoch 0.639), train_loss = 2.85412972, grad/param norm = 5.6548e-01, time/batch = 0.6861s	
393/30650 (epoch 0.641), train_loss = 2.78637423, grad/param norm = 4.9441e-01, time/batch = 0.6958s	
394/30650 (epoch 0.643), train_loss = 2.81873630, grad/param norm = 3.7488e-01, time/batch = 0.6974s	
395/30650 (epoch 0.644), train_loss = 2.79189822, grad/param norm = 3.4397e-01, time/batch = 0.6985s	
396/30650 (epoch 0.646), train_loss = 2.83731722, grad/param norm = 4.2431e-01, time/batch = 0.6991s	
397/30650 (epoch 0.648), train_loss = 2.63855030, grad/param norm = 4.9375e-01, time/batch = 0.7035s	
398/30650 (epoch 0.649), train_loss = 2.71702341, grad/param norm = 5.7272e-01, time/batch = 0.6965s	
399/30650 (epoch 0.651), train_loss = 2.63988285, grad/param norm = 5.1571e-01, time/batch = 0.7002s	
400/30650 (epoch 0.653), train_loss = 2.75464267, grad/param norm = 8.2227e-01, time/batch = 0.6985s	
401/30650 (epoch 0.654), train_loss = 2.59987527, grad/param norm = 8.3238e-01, time/batch = 0.7004s	
402/30650 (epoch 0.656), train_loss = 2.72313222, grad/param norm = 5.1766e-01, time/batch = 0.7101s	
403/30650 (epoch 0.657), train_loss = 2.72744744, grad/param norm = 4.3727e-01, time/batch = 0.6892s	
404/30650 (epoch 0.659), train_loss = 2.65519868, grad/param norm = 3.8447e-01, time/batch = 0.7103s	
405/30650 (epoch 0.661), train_loss = 2.74643492, grad/param norm = 4.8657e-01, time/batch = 0.7178s	
406/30650 (epoch 0.662), train_loss = 2.67963574, grad/param norm = 3.8905e-01, time/batch = 0.6872s	
407/30650 (epoch 0.664), train_loss = 2.67405634, grad/param norm = 4.0792e-01, time/batch = 0.6895s	
408/30650 (epoch 0.666), train_loss = 2.64085069, grad/param norm = 4.2830e-01, time/batch = 0.6891s	
409/30650 (epoch 0.667), train_loss = 2.70433478, grad/param norm = 5.6029e-01, time/batch = 0.6929s	
410/30650 (epoch 0.669), train_loss = 2.75538313, grad/param norm = 5.4933e-01, time/batch = 0.6987s	
411/30650 (epoch 0.670), train_loss = 2.81537980, grad/param norm = 4.2946e-01, time/batch = 0.7058s	
412/30650 (epoch 0.672), train_loss = 2.80098643, grad/param norm = 3.1449e-01, time/batch = 0.6949s	
413/30650 (epoch 0.674), train_loss = 2.75733108, grad/param norm = 4.0606e-01, time/batch = 0.6883s	
414/30650 (epoch 0.675), train_loss = 2.85640695, grad/param norm = 4.9217e-01, time/batch = 0.6930s	
415/30650 (epoch 0.677), train_loss = 2.72429515, grad/param norm = 5.3716e-01, time/batch = 0.6941s	
416/30650 (epoch 0.679), train_loss = 2.69542396, grad/param norm = 4.4447e-01, time/batch = 0.6904s	
417/30650 (epoch 0.680), train_loss = 2.91453487, grad/param norm = 3.7817e-01, time/batch = 0.6975s	
418/30650 (epoch 0.682), train_loss = 2.69926719, grad/param norm = 3.4222e-01, time/batch = 0.6965s	
419/30650 (epoch 0.684), train_loss = 2.71259442, grad/param norm = 4.5844e-01, time/batch = 0.7212s	
420/30650 (epoch 0.685), train_loss = 2.69256791, grad/param norm = 5.7847e-01, time/batch = 0.6963s	
421/30650 (epoch 0.687), train_loss = 2.69116887, grad/param norm = 4.7358e-01, time/batch = 0.7015s	
422/30650 (epoch 0.688), train_loss = 2.66385856, grad/param norm = 5.8161e-01, time/batch = 0.7070s	
423/30650 (epoch 0.690), train_loss = 2.55622691, grad/param norm = 6.2595e-01, time/batch = 0.6829s	
424/30650 (epoch 0.692), train_loss = 2.67848522, grad/param norm = 4.8326e-01, time/batch = 0.6926s	
425/30650 (epoch 0.693), train_loss = 2.54648468, grad/param norm = 3.3900e-01, time/batch = 0.6925s	
426/30650 (epoch 0.695), train_loss = 2.53462604, grad/param norm = 4.1256e-01, time/batch = 0.6942s	
427/30650 (epoch 0.697), train_loss = 2.65320960, grad/param norm = 4.6383e-01, time/batch = 0.6828s	
428/30650 (epoch 0.698), train_loss = 2.58102164, grad/param norm = 5.0415e-01, time/batch = 0.6901s	
429/30650 (epoch 0.700), train_loss = 2.76479317, grad/param norm = 5.2584e-01, time/batch = 0.7212s	
430/30650 (epoch 0.701), train_loss = 2.58034652, grad/param norm = 5.7325e-01, time/batch = 0.6843s	
431/30650 (epoch 0.703), train_loss = 2.57793742, grad/param norm = 5.8453e-01, time/batch = 0.6810s	
432/30650 (epoch 0.705), train_loss = 2.52094253, grad/param norm = 4.6714e-01, time/batch = 0.6803s	
433/30650 (epoch 0.706), train_loss = 2.58901324, grad/param norm = 4.3373e-01, time/batch = 0.7020s	
434/30650 (epoch 0.708), train_loss = 2.76542858, grad/param norm = 4.8424e-01, time/batch = 0.6958s	
435/30650 (epoch 0.710), train_loss = 2.73512600, grad/param norm = 4.7066e-01, time/batch = 0.6986s	
436/30650 (epoch 0.711), train_loss = 2.77563409, grad/param norm = 4.0606e-01, time/batch = 0.6806s	
437/30650 (epoch 0.713), train_loss = 2.71596392, grad/param norm = 4.1557e-01, time/batch = 0.6840s	
438/30650 (epoch 0.715), train_loss = 2.74196856, grad/param norm = 4.1126e-01, time/batch = 0.6894s	
439/30650 (epoch 0.716), train_loss = 2.70412642, grad/param norm = 3.8071e-01, time/batch = 0.6779s	
440/30650 (epoch 0.718), train_loss = 2.62930318, grad/param norm = 3.8022e-01, time/batch = 0.6764s	
441/30650 (epoch 0.719), train_loss = 2.65120485, grad/param norm = 5.0797e-01, time/batch = 0.6773s	
442/30650 (epoch 0.721), train_loss = 2.78293264, grad/param norm = 6.1472e-01, time/batch = 0.6770s	
443/30650 (epoch 0.723), train_loss = 2.54249480, grad/param norm = 5.2164e-01, time/batch = 0.7119s	
444/30650 (epoch 0.724), train_loss = 2.67092646, grad/param norm = 5.0753e-01, time/batch = 0.7042s	
445/30650 (epoch 0.726), train_loss = 2.45805863, grad/param norm = 5.1135e-01, time/batch = 0.6762s	
446/30650 (epoch 0.728), train_loss = 2.61147769, grad/param norm = 4.8838e-01, time/batch = 0.6753s	
447/30650 (epoch 0.729), train_loss = 2.75139924, grad/param norm = 5.4438e-01, time/batch = 0.6764s	
448/30650 (epoch 0.731), train_loss = 2.76263565, grad/param norm = 5.0674e-01, time/batch = 0.6831s	
449/30650 (epoch 0.732), train_loss = 2.68828315, grad/param norm = 5.5797e-01, time/batch = 0.6811s	
450/30650 (epoch 0.734), train_loss = 2.70420502, grad/param norm = 4.7749e-01, time/batch = 0.6768s	
451/30650 (epoch 0.736), train_loss = 2.74150586, grad/param norm = 3.9769e-01, time/batch = 0.6794s	
452/30650 (epoch 0.737), train_loss = 2.68710863, grad/param norm = 2.9890e-01, time/batch = 0.6755s	
453/30650 (epoch 0.739), train_loss = 2.57016638, grad/param norm = 3.1873e-01, time/batch = 0.6763s	
454/30650 (epoch 0.741), train_loss = 2.67040262, grad/param norm = 3.1564e-01, time/batch = 0.6786s	
455/30650 (epoch 0.742), train_loss = 2.71849817, grad/param norm = 3.2877e-01, time/batch = 0.6760s	
456/30650 (epoch 0.744), train_loss = 2.67363199, grad/param norm = 2.8672e-01, time/batch = 0.6814s	
457/30650 (epoch 0.746), train_loss = 2.66674482, grad/param norm = 3.9143e-01, time/batch = 0.6854s	
458/30650 (epoch 0.747), train_loss = 2.71698790, grad/param norm = 4.1006e-01, time/batch = 0.7212s	
459/30650 (epoch 0.749), train_loss = 2.61279427, grad/param norm = 3.5255e-01, time/batch = 0.6853s	
460/30650 (epoch 0.750), train_loss = 2.49469994, grad/param norm = 3.7798e-01, time/batch = 0.6773s	
461/30650 (epoch 0.752), train_loss = 2.52020729, grad/param norm = 5.0005e-01, time/batch = 0.6784s	
462/30650 (epoch 0.754), train_loss = 2.61614371, grad/param norm = 4.0091e-01, time/batch = 0.6799s	
463/30650 (epoch 0.755), train_loss = 2.68584794, grad/param norm = 4.3391e-01, time/batch = 0.6826s	
464/30650 (epoch 0.757), train_loss = 2.67437580, grad/param norm = 3.8820e-01, time/batch = 0.6802s	
465/30650 (epoch 0.759), train_loss = 2.68014513, grad/param norm = 3.5966e-01, time/batch = 0.6788s	
466/30650 (epoch 0.760), train_loss = 2.71372014, grad/param norm = 5.8015e-01, time/batch = 0.6770s	
467/30650 (epoch 0.762), train_loss = 2.65182607, grad/param norm = 7.6022e-01, time/batch = 0.6754s	
468/30650 (epoch 0.763), train_loss = 2.67391525, grad/param norm = 7.5747e-01, time/batch = 0.6809s	
469/30650 (epoch 0.765), train_loss = 2.57258897, grad/param norm = 5.5046e-01, time/batch = 0.6788s	
470/30650 (epoch 0.767), train_loss = 2.65085750, grad/param norm = 4.1812e-01, time/batch = 0.6767s	
471/30650 (epoch 0.768), train_loss = 2.70272387, grad/param norm = 3.8591e-01, time/batch = 0.6769s	
472/30650 (epoch 0.770), train_loss = 2.69142508, grad/param norm = 3.9415e-01, time/batch = 0.6767s	
473/30650 (epoch 0.772), train_loss = 2.75315801, grad/param norm = 3.4567e-01, time/batch = 0.6765s	
474/30650 (epoch 0.773), train_loss = 2.69867232, grad/param norm = 2.8120e-01, time/batch = 0.6752s	
475/30650 (epoch 0.775), train_loss = 2.74646236, grad/param norm = 2.9116e-01, time/batch = 0.6811s	
476/30650 (epoch 0.777), train_loss = 2.58135296, grad/param norm = 4.2460e-01, time/batch = 0.6768s	
477/30650 (epoch 0.778), train_loss = 2.55744492, grad/param norm = 4.4037e-01, time/batch = 0.6756s	
478/30650 (epoch 0.780), train_loss = 2.66023265, grad/param norm = 5.7711e-01, time/batch = 0.6816s	
479/30650 (epoch 0.781), train_loss = 2.73021387, grad/param norm = 4.9359e-01, time/batch = 0.6860s	
480/30650 (epoch 0.783), train_loss = 2.70517344, grad/param norm = 3.9771e-01, time/batch = 0.7020s	
481/30650 (epoch 0.785), train_loss = 2.69385912, grad/param norm = 4.4940e-01, time/batch = 0.7148s	
482/30650 (epoch 0.786), train_loss = 2.53249830, grad/param norm = 3.9713e-01, time/batch = 0.7129s	
483/30650 (epoch 0.788), train_loss = 2.77987108, grad/param norm = 2.9827e-01, time/batch = 0.7013s	
484/30650 (epoch 0.790), train_loss = 2.53712200, grad/param norm = 3.2091e-01, time/batch = 0.6973s	
485/30650 (epoch 0.791), train_loss = 2.52496194, grad/param norm = 3.8129e-01, time/batch = 0.6769s	
486/30650 (epoch 0.793), train_loss = 2.72615310, grad/param norm = 3.2335e-01, time/batch = 0.6870s	
487/30650 (epoch 0.794), train_loss = 2.64377235, grad/param norm = 3.5461e-01, time/batch = 0.6749s	
488/30650 (epoch 0.796), train_loss = 2.55381152, grad/param norm = 4.6373e-01, time/batch = 0.6789s	
489/30650 (epoch 0.798), train_loss = 2.45740070, grad/param norm = 4.2860e-01, time/batch = 0.6919s	
490/30650 (epoch 0.799), train_loss = 2.66644963, grad/param norm = 4.9549e-01, time/batch = 0.6758s	
491/30650 (epoch 0.801), train_loss = 2.48648080, grad/param norm = 4.6605e-01, time/batch = 0.6803s	
492/30650 (epoch 0.803), train_loss = 2.79974929, grad/param norm = 5.2220e-01, time/batch = 0.6929s	
493/30650 (epoch 0.804), train_loss = 2.54896936, grad/param norm = 5.7092e-01, time/batch = 0.6772s	
494/30650 (epoch 0.806), train_loss = 2.62288905, grad/param norm = 5.3499e-01, time/batch = 0.6770s	
495/30650 (epoch 0.808), train_loss = 2.69027325, grad/param norm = 4.2652e-01, time/batch = 0.6751s	
496/30650 (epoch 0.809), train_loss = 2.39099131, grad/param norm = 4.8636e-01, time/batch = 0.6766s	
497/30650 (epoch 0.811), train_loss = 2.70825387, grad/param norm = 4.4147e-01, time/batch = 0.6760s	
498/30650 (epoch 0.812), train_loss = 2.73454259, grad/param norm = 3.9692e-01, time/batch = 0.6757s	
499/30650 (epoch 0.814), train_loss = 2.62068685, grad/param norm = 2.9424e-01, time/batch = 0.6745s	
500/30650 (epoch 0.816), train_loss = 2.71018193, grad/param norm = 2.7894e-01, time/batch = 0.6780s	
501/30650 (epoch 0.817), train_loss = 2.53994627, grad/param norm = 2.3008e-01, time/batch = 0.7011s	
502/30650 (epoch 0.819), train_loss = 2.50320461, grad/param norm = 3.9889e-01, time/batch = 0.7182s	
503/30650 (epoch 0.821), train_loss = 2.55881567, grad/param norm = 6.7850e-01, time/batch = 0.6812s	
504/30650 (epoch 0.822), train_loss = 2.59592726, grad/param norm = 4.8889e-01, time/batch = 0.6776s	
505/30650 (epoch 0.824), train_loss = 2.38695976, grad/param norm = 3.9580e-01, time/batch = 0.6776s	
506/30650 (epoch 0.825), train_loss = 2.64711937, grad/param norm = 6.0033e-01, time/batch = 0.6837s	
507/30650 (epoch 0.827), train_loss = 2.58639578, grad/param norm = 7.1992e-01, time/batch = 0.6993s	
508/30650 (epoch 0.829), train_loss = 2.63461197, grad/param norm = 6.7952e-01, time/batch = 0.6922s	
509/30650 (epoch 0.830), train_loss = 2.49080319, grad/param norm = 4.3033e-01, time/batch = 0.6865s	
510/30650 (epoch 0.832), train_loss = 2.46040068, grad/param norm = 3.4839e-01, time/batch = 0.6837s	
511/30650 (epoch 0.834), train_loss = 2.69380449, grad/param norm = 3.9788e-01, time/batch = 0.6807s	
512/30650 (epoch 0.835), train_loss = 2.62215688, grad/param norm = 4.1663e-01, time/batch = 0.6840s	
513/30650 (epoch 0.837), train_loss = 2.67713987, grad/param norm = 2.9955e-01, time/batch = 0.6797s	
514/30650 (epoch 0.838), train_loss = 2.52517429, grad/param norm = 3.1964e-01, time/batch = 0.6802s	
515/30650 (epoch 0.840), train_loss = 2.61984654, grad/param norm = 3.7176e-01, time/batch = 0.6794s	
516/30650 (epoch 0.842), train_loss = 2.48373039, grad/param norm = 3.9185e-01, time/batch = 0.7260s	
517/30650 (epoch 0.843), train_loss = 2.50769078, grad/param norm = 3.1130e-01, time/batch = 0.7017s	
518/30650 (epoch 0.845), train_loss = 2.68741716, grad/param norm = 4.5820e-01, time/batch = 0.6833s	
519/30650 (epoch 0.847), train_loss = 2.61967102, grad/param norm = 3.4276e-01, time/batch = 0.6796s	
520/30650 (epoch 0.848), train_loss = 2.55637124, grad/param norm = 3.7139e-01, time/batch = 0.6775s	
521/30650 (epoch 0.850), train_loss = 2.55680046, grad/param norm = 3.7995e-01, time/batch = 0.6801s	
522/30650 (epoch 0.852), train_loss = 2.74661004, grad/param norm = 3.6465e-01, time/batch = 0.6816s	
523/30650 (epoch 0.853), train_loss = 2.52047488, grad/param norm = 3.2522e-01, time/batch = 0.6788s	
524/30650 (epoch 0.855), train_loss = 2.57875158, grad/param norm = 3.0604e-01, time/batch = 0.6828s	
525/30650 (epoch 0.856), train_loss = 2.62612609, grad/param norm = 3.5218e-01, time/batch = 0.6773s	
526/30650 (epoch 0.858), train_loss = 2.58158382, grad/param norm = 5.4172e-01, time/batch = 0.6810s	
527/30650 (epoch 0.860), train_loss = 2.44033875, grad/param norm = 5.5399e-01, time/batch = 0.6795s	
528/30650 (epoch 0.861), train_loss = 2.50331957, grad/param norm = 4.9298e-01, time/batch = 0.6782s	
529/30650 (epoch 0.863), train_loss = 2.56880014, grad/param norm = 4.0386e-01, time/batch = 0.6870s	
530/30650 (epoch 0.865), train_loss = 2.71907182, grad/param norm = 4.1635e-01, time/batch = 0.6820s	
531/30650 (epoch 0.866), train_loss = 2.64111612, grad/param norm = 4.9825e-01, time/batch = 0.6785s	
532/30650 (epoch 0.868), train_loss = 2.56409963, grad/param norm = 3.6230e-01, time/batch = 0.6778s	
533/30650 (epoch 0.869), train_loss = 2.62766255, grad/param norm = 3.2648e-01, time/batch = 0.6772s	
534/30650 (epoch 0.871), train_loss = 2.52504699, grad/param norm = 4.1004e-01, time/batch = 0.6767s	
535/30650 (epoch 0.873), train_loss = 2.47318876, grad/param norm = 4.3623e-01, time/batch = 0.6764s	
536/30650 (epoch 0.874), train_loss = 2.43536020, grad/param norm = 5.1037e-01, time/batch = 0.6851s	
537/30650 (epoch 0.876), train_loss = 2.40531683, grad/param norm = 5.5429e-01, time/batch = 0.6760s	
538/30650 (epoch 0.878), train_loss = 2.44407949, grad/param norm = 5.1335e-01, time/batch = 0.6750s	
539/30650 (epoch 0.879), train_loss = 2.64566447, grad/param norm = 5.8598e-01, time/batch = 0.6809s	
540/30650 (epoch 0.881), train_loss = 2.62426685, grad/param norm = 4.5828e-01, time/batch = 0.6878s	
541/30650 (epoch 0.883), train_loss = 2.52276480, grad/param norm = 3.2142e-01, time/batch = 0.6840s	
542/30650 (epoch 0.884), train_loss = 2.42850935, grad/param norm = 3.7514e-01, time/batch = 0.6789s	
543/30650 (epoch 0.886), train_loss = 2.34583076, grad/param norm = 4.4106e-01, time/batch = 0.6785s	
544/30650 (epoch 0.887), train_loss = 2.55082044, grad/param norm = 3.3663e-01, time/batch = 0.6787s	
545/30650 (epoch 0.889), train_loss = 2.36971485, grad/param norm = 3.3796e-01, time/batch = 0.7131s	
546/30650 (epoch 0.891), train_loss = 2.59470502, grad/param norm = 4.5278e-01, time/batch = 0.7022s	
547/30650 (epoch 0.892), train_loss = 2.53325679, grad/param norm = 4.1973e-01, time/batch = 0.6768s	
548/30650 (epoch 0.894), train_loss = 2.44280259, grad/param norm = 3.9888e-01, time/batch = 0.6789s	
549/30650 (epoch 0.896), train_loss = 2.44789109, grad/param norm = 3.9024e-01, time/batch = 0.6788s	
550/30650 (epoch 0.897), train_loss = 2.51752442, grad/param norm = 3.7962e-01, time/batch = 0.6820s	
551/30650 (epoch 0.899), train_loss = 2.44417120, grad/param norm = 4.4485e-01, time/batch = 0.6845s	
552/30650 (epoch 0.900), train_loss = 2.73642347, grad/param norm = 3.4367e-01, time/batch = 0.6779s	
553/30650 (epoch 0.902), train_loss = 2.68587011, grad/param norm = 3.2996e-01, time/batch = 0.6770s	
554/30650 (epoch 0.904), train_loss = 2.46081923, grad/param norm = 3.9913e-01, time/batch = 0.6752s	
555/30650 (epoch 0.905), train_loss = 2.57446582, grad/param norm = 4.0931e-01, time/batch = 0.6779s	
556/30650 (epoch 0.907), train_loss = 2.57443612, grad/param norm = 5.1580e-01, time/batch = 0.6843s	
557/30650 (epoch 0.909), train_loss = 2.55847592, grad/param norm = 6.0449e-01, time/batch = 0.6784s	
558/30650 (epoch 0.910), train_loss = 2.35993135, grad/param norm = 4.6159e-01, time/batch = 0.6826s	
559/30650 (epoch 0.912), train_loss = 2.51936056, grad/param norm = 4.3789e-01, time/batch = 0.6820s	
560/30650 (epoch 0.914), train_loss = 2.42956863, grad/param norm = 4.1664e-01, time/batch = 0.7045s	
561/30650 (epoch 0.915), train_loss = 2.59169240, grad/param norm = 4.0473e-01, time/batch = 0.6829s	
562/30650 (epoch 0.917), train_loss = 2.65169550, grad/param norm = 4.2676e-01, time/batch = 0.6775s	
563/30650 (epoch 0.918), train_loss = 2.52880215, grad/param norm = 3.6135e-01, time/batch = 0.6771s	
564/30650 (epoch 0.920), train_loss = 2.51766019, grad/param norm = 4.0830e-01, time/batch = 0.6834s	
565/30650 (epoch 0.922), train_loss = 2.43363848, grad/param norm = 3.6523e-01, time/batch = 0.6765s	
566/30650 (epoch 0.923), train_loss = 2.68119299, grad/param norm = 3.3595e-01, time/batch = 0.6864s	
567/30650 (epoch 0.925), train_loss = 2.50162043, grad/param norm = 3.2432e-01, time/batch = 0.6754s	
568/30650 (epoch 0.927), train_loss = 2.66666708, grad/param norm = 3.1986e-01, time/batch = 0.6780s	
569/30650 (epoch 0.928), train_loss = 2.46769335, grad/param norm = 3.7127e-01, time/batch = 0.6771s	
570/30650 (epoch 0.930), train_loss = 2.50414399, grad/param norm = 3.4751e-01, time/batch = 0.6795s	
571/30650 (epoch 0.931), train_loss = 2.42190801, grad/param norm = 3.2433e-01, time/batch = 0.6801s	
572/30650 (epoch 0.933), train_loss = 2.44296094, grad/param norm = 2.7453e-01, time/batch = 0.6863s	
573/30650 (epoch 0.935), train_loss = 2.54331938, grad/param norm = 3.4814e-01, time/batch = 0.6775s	
574/30650 (epoch 0.936), train_loss = 2.53309421, grad/param norm = 4.1417e-01, time/batch = 0.7054s	
575/30650 (epoch 0.938), train_loss = 2.51769888, grad/param norm = 4.9150e-01, time/batch = 0.7099s	
576/30650 (epoch 0.940), train_loss = 2.70332181, grad/param norm = 4.6460e-01, time/batch = 0.6781s	
577/30650 (epoch 0.941), train_loss = 2.58491287, grad/param norm = 3.1526e-01, time/batch = 0.6786s	
578/30650 (epoch 0.943), train_loss = 2.51415543, grad/param norm = 3.2715e-01, time/batch = 0.6774s	
579/30650 (epoch 0.945), train_loss = 2.62964301, grad/param norm = 3.2404e-01, time/batch = 0.6844s	
580/30650 (epoch 0.946), train_loss = 2.41359074, grad/param norm = 3.5145e-01, time/batch = 0.6819s	
581/30650 (epoch 0.948), train_loss = 2.53757882, grad/param norm = 4.1516e-01, time/batch = 0.6812s	
582/30650 (epoch 0.949), train_loss = 2.55465472, grad/param norm = 3.6629e-01, time/batch = 0.6794s	
583/30650 (epoch 0.951), train_loss = 2.50600584, grad/param norm = 3.0088e-01, time/batch = 0.6782s	
584/30650 (epoch 0.953), train_loss = 2.35697955, grad/param norm = 3.6316e-01, time/batch = 0.6889s	
585/30650 (epoch 0.954), train_loss = 2.38069653, grad/param norm = 3.8036e-01, time/batch = 0.6921s	
586/30650 (epoch 0.956), train_loss = 2.45707674, grad/param norm = 3.5181e-01, time/batch = 0.6770s	
587/30650 (epoch 0.958), train_loss = 2.47494949, grad/param norm = 2.8819e-01, time/batch = 0.6802s	
588/30650 (epoch 0.959), train_loss = 2.44251050, grad/param norm = 3.1586e-01, time/batch = 0.6831s	
589/30650 (epoch 0.961), train_loss = 2.49790110, grad/param norm = 3.9837e-01, time/batch = 0.7212s	
590/30650 (epoch 0.962), train_loss = 2.56757339, grad/param norm = 2.8801e-01, time/batch = 0.6905s	
591/30650 (epoch 0.964), train_loss = 2.40161990, grad/param norm = 2.8536e-01, time/batch = 0.6792s	
592/30650 (epoch 0.966), train_loss = 2.34941747, grad/param norm = 2.7219e-01, time/batch = 0.6801s	
593/30650 (epoch 0.967), train_loss = 2.49829840, grad/param norm = 3.1029e-01, time/batch = 0.6779s	
594/30650 (epoch 0.969), train_loss = 2.43225800, grad/param norm = 3.7238e-01, time/batch = 0.6969s	
595/30650 (epoch 0.971), train_loss = 2.37561390, grad/param norm = 3.7180e-01, time/batch = 0.6869s	
596/30650 (epoch 0.972), train_loss = 2.49992475, grad/param norm = 3.2787e-01, time/batch = 0.6890s	
597/30650 (epoch 0.974), train_loss = 2.53398254, grad/param norm = 4.1154e-01, time/batch = 0.6848s	
598/30650 (epoch 0.976), train_loss = 2.50905423, grad/param norm = 3.4363e-01, time/batch = 0.6776s	
599/30650 (epoch 0.977), train_loss = 2.55752206, grad/param norm = 3.4312e-01, time/batch = 0.6753s	
600/30650 (epoch 0.979), train_loss = 2.52701769, grad/param norm = 3.0025e-01, time/batch = 0.6885s	
601/30650 (epoch 0.980), train_loss = 2.47787145, grad/param norm = 3.5724e-01, time/batch = 0.6886s	
602/30650 (epoch 0.982), train_loss = 2.55427802, grad/param norm = 3.5787e-01, time/batch = 0.6793s	
603/30650 (epoch 0.984), train_loss = 2.54275546, grad/param norm = 3.1558e-01, time/batch = 0.7053s	
604/30650 (epoch 0.985), train_loss = 2.48617773, grad/param norm = 2.8491e-01, time/batch = 0.7153s	
605/30650 (epoch 0.987), train_loss = 2.42967958, grad/param norm = 2.9351e-01, time/batch = 0.6846s	
606/30650 (epoch 0.989), train_loss = 2.46759017, grad/param norm = 3.2204e-01, time/batch = 0.6792s	
607/30650 (epoch 0.990), train_loss = 2.38526956, grad/param norm = 3.8281e-01, time/batch = 0.6751s	
608/30650 (epoch 0.992), train_loss = 2.52452241, grad/param norm = 3.4652e-01, time/batch = 0.6826s	
609/30650 (epoch 0.993), train_loss = 2.49370378, grad/param norm = 3.2514e-01, time/batch = 0.6765s	
610/30650 (epoch 0.995), train_loss = 2.46996380, grad/param norm = 3.0529e-01, time/batch = 0.6766s	
611/30650 (epoch 0.997), train_loss = 2.66898348, grad/param norm = 3.5281e-01, time/batch = 0.6764s	
612/30650 (epoch 0.998), train_loss = 2.37758578, grad/param norm = 3.3990e-01, time/batch = 0.6795s	
613/30650 (epoch 1.000), train_loss = 2.64590447, grad/param norm = 3.7022e-01, time/batch = 0.6755s	
614/30650 (epoch 1.002), train_loss = 2.45579140, grad/param norm = 3.9491e-01, time/batch = 0.6763s	
615/30650 (epoch 1.003), train_loss = 2.41221959, grad/param norm = 3.6047e-01, time/batch = 0.6772s	
616/30650 (epoch 1.005), train_loss = 2.54355984, grad/param norm = 3.8446e-01, time/batch = 0.6764s	
617/30650 (epoch 1.007), train_loss = 2.74399614, grad/param norm = 3.8536e-01, time/batch = 0.6803s	
618/30650 (epoch 1.008), train_loss = 2.32958136, grad/param norm = 3.8812e-01, time/batch = 0.7221s	
619/30650 (epoch 1.010), train_loss = 2.40162556, grad/param norm = 3.8248e-01, time/batch = 0.6952s	
620/30650 (epoch 1.011), train_loss = 2.46337129, grad/param norm = 3.7684e-01, time/batch = 0.6766s	
621/30650 (epoch 1.013), train_loss = 2.54126035, grad/param norm = 4.4503e-01, time/batch = 0.6784s	
622/30650 (epoch 1.015), train_loss = 2.56410978, grad/param norm = 3.7865e-01, time/batch = 0.6761s	
623/30650 (epoch 1.016), train_loss = 2.53957475, grad/param norm = 3.0444e-01, time/batch = 0.6879s	
624/30650 (epoch 1.018), train_loss = 2.58614177, grad/param norm = 3.4812e-01, time/batch = 0.6767s	
625/30650 (epoch 1.020), train_loss = 2.47896740, grad/param norm = 2.6482e-01, time/batch = 0.6767s	
626/30650 (epoch 1.021), train_loss = 2.51800602, grad/param norm = 3.0573e-01, time/batch = 0.6791s	
627/30650 (epoch 1.023), train_loss = 2.53847064, grad/param norm = 3.1173e-01, time/batch = 0.6796s	
628/30650 (epoch 1.024), train_loss = 2.60895334, grad/param norm = 3.5892e-01, time/batch = 0.6911s	
629/30650 (epoch 1.026), train_loss = 2.47058786, grad/param norm = 2.6971e-01, time/batch = 0.6947s	
630/30650 (epoch 1.028), train_loss = 2.37793206, grad/param norm = 2.8534e-01, time/batch = 0.6787s	
631/30650 (epoch 1.029), train_loss = 2.59392444, grad/param norm = 3.8499e-01, time/batch = 0.6796s	
632/30650 (epoch 1.031), train_loss = 2.68913604, grad/param norm = 3.9210e-01, time/batch = 0.6769s	
633/30650 (epoch 1.033), train_loss = 2.43532798, grad/param norm = 4.5579e-01, time/batch = 0.6772s	
634/30650 (epoch 1.034), train_loss = 2.48195988, grad/param norm = 4.8179e-01, time/batch = 0.6771s	
635/30650 (epoch 1.036), train_loss = 2.37192142, grad/param norm = 4.1316e-01, time/batch = 0.6781s	
636/30650 (epoch 1.038), train_loss = 2.63560678, grad/param norm = 3.6835e-01, time/batch = 0.6777s	
637/30650 (epoch 1.039), train_loss = 2.39691214, grad/param norm = 3.9845e-01, time/batch = 0.6772s	
638/30650 (epoch 1.041), train_loss = 2.53865806, grad/param norm = 4.1332e-01, time/batch = 0.6819s	
639/30650 (epoch 1.042), train_loss = 2.42647978, grad/param norm = 3.8060e-01, time/batch = 0.6817s	
640/30650 (epoch 1.044), train_loss = 2.42623762, grad/param norm = 4.4015e-01, time/batch = 0.6768s	
641/30650 (epoch 1.046), train_loss = 2.40197349, grad/param norm = 4.0271e-01, time/batch = 0.6780s	
642/30650 (epoch 1.047), train_loss = 2.38562239, grad/param norm = 3.6653e-01, time/batch = 0.6772s	
643/30650 (epoch 1.049), train_loss = 2.38591309, grad/param norm = 3.5342e-01, time/batch = 0.6805s	
644/30650 (epoch 1.051), train_loss = 2.64241112, grad/param norm = 3.3370e-01, time/batch = 0.6878s	
645/30650 (epoch 1.052), train_loss = 2.34578382, grad/param norm = 3.2386e-01, time/batch = 0.7070s	
646/30650 (epoch 1.054), train_loss = 2.56011180, grad/param norm = 4.3863e-01, time/batch = 0.6928s	
647/30650 (epoch 1.055), train_loss = 2.45161689, grad/param norm = 4.1960e-01, time/batch = 0.7197s	
648/30650 (epoch 1.057), train_loss = 2.31799800, grad/param norm = 4.5215e-01, time/batch = 0.7001s	
649/30650 (epoch 1.059), train_loss = 2.52258589, grad/param norm = 3.4003e-01, time/batch = 0.6776s	
650/30650 (epoch 1.060), train_loss = 2.45906527, grad/param norm = 2.8418e-01, time/batch = 0.6784s	
651/30650 (epoch 1.062), train_loss = 2.64775053, grad/param norm = 2.9563e-01, time/batch = 0.6930s	
652/30650 (epoch 1.064), train_loss = 2.59254992, grad/param norm = 3.4935e-01, time/batch = 0.6772s	
653/30650 (epoch 1.065), train_loss = 2.48156350, grad/param norm = 3.3385e-01, time/batch = 0.6796s	
654/30650 (epoch 1.067), train_loss = 2.57873452, grad/param norm = 2.9903e-01, time/batch = 0.6820s	
655/30650 (epoch 1.069), train_loss = 2.49559760, grad/param norm = 2.4313e-01, time/batch = 0.6783s	
656/30650 (epoch 1.070), train_loss = 2.39330282, grad/param norm = 2.8771e-01, time/batch = 0.6761s	
657/30650 (epoch 1.072), train_loss = 2.46335501, grad/param norm = 3.2755e-01, time/batch = 0.6763s	
658/30650 (epoch 1.073), train_loss = 2.22351314, grad/param norm = 3.8381e-01, time/batch = 0.6781s	
659/30650 (epoch 1.075), train_loss = 2.43435781, grad/param norm = 2.9627e-01, time/batch = 0.6778s	
660/30650 (epoch 1.077), train_loss = 2.35750150, grad/param norm = 2.2801e-01, time/batch = 0.6775s	
661/30650 (epoch 1.078), train_loss = 2.52145989, grad/param norm = 2.8980e-01, time/batch = 0.6942s	
662/30650 (epoch 1.080), train_loss = 2.61631394, grad/param norm = 3.1467e-01, time/batch = 0.7217s	
663/30650 (epoch 1.082), train_loss = 2.50019806, grad/param norm = 2.9854e-01, time/batch = 0.6786s	
664/30650 (epoch 1.083), train_loss = 2.34675822, grad/param norm = 3.0060e-01, time/batch = 0.6759s	
665/30650 (epoch 1.085), train_loss = 2.57952593, grad/param norm = 2.9846e-01, time/batch = 0.6762s	
666/30650 (epoch 1.086), train_loss = 2.41427061, grad/param norm = 3.6851e-01, time/batch = 0.6758s	
667/30650 (epoch 1.088), train_loss = 2.48847894, grad/param norm = 3.3674e-01, time/batch = 0.6845s	
668/30650 (epoch 1.090), train_loss = 2.39028702, grad/param norm = 2.7743e-01, time/batch = 0.6780s	
669/30650 (epoch 1.091), train_loss = 2.37885047, grad/param norm = 2.4751e-01, time/batch = 0.6825s	
670/30650 (epoch 1.093), train_loss = 2.43546761, grad/param norm = 2.4481e-01, time/batch = 0.6806s	
671/30650 (epoch 1.095), train_loss = 2.34087546, grad/param norm = 3.0974e-01, time/batch = 0.6795s	
672/30650 (epoch 1.096), train_loss = 2.31710138, grad/param norm = 3.0225e-01, time/batch = 0.6817s	
673/30650 (epoch 1.098), train_loss = 2.37923496, grad/param norm = 2.9153e-01, time/batch = 0.6982s	
674/30650 (epoch 1.100), train_loss = 2.53984614, grad/param norm = 4.1297e-01, time/batch = 0.6999s	
675/30650 (epoch 1.101), train_loss = 2.36643384, grad/param norm = 3.7659e-01, time/batch = 0.7011s	
676/30650 (epoch 1.103), train_loss = 2.53259248, grad/param norm = 2.7288e-01, time/batch = 0.7176s	
677/30650 (epoch 1.104), train_loss = 2.30962254, grad/param norm = 2.8701e-01, time/batch = 0.7093s	
678/30650 (epoch 1.106), train_loss = 2.42093888, grad/param norm = 3.5333e-01, time/batch = 0.6938s	
679/30650 (epoch 1.108), train_loss = 2.75113683, grad/param norm = 5.5922e-01, time/batch = 0.6999s	
680/30650 (epoch 1.109), train_loss = 2.33722299, grad/param norm = 4.6196e-01, time/batch = 0.6983s	
681/30650 (epoch 1.111), train_loss = 2.35277678, grad/param norm = 3.5545e-01, time/batch = 0.7088s	
682/30650 (epoch 1.113), train_loss = 2.36014928, grad/param norm = 2.9310e-01, time/batch = 0.7195s	
683/30650 (epoch 1.114), train_loss = 2.32084240, grad/param norm = 2.3634e-01, time/batch = 0.6982s	
684/30650 (epoch 1.116), train_loss = 2.52771628, grad/param norm = 2.7493e-01, time/batch = 0.6874s	
685/30650 (epoch 1.117), train_loss = 2.51448364, grad/param norm = 3.1053e-01, time/batch = 0.6824s	
686/30650 (epoch 1.119), train_loss = 2.48861460, grad/param norm = 3.1585e-01, time/batch = 0.6967s	
687/30650 (epoch 1.121), train_loss = 2.69643728, grad/param norm = 2.8707e-01, time/batch = 0.7081s	
688/30650 (epoch 1.122), train_loss = 2.48374405, grad/param norm = 3.1463e-01, time/batch = 0.7043s	
689/30650 (epoch 1.124), train_loss = 2.46012743, grad/param norm = 3.1939e-01, time/batch = 0.6987s	
690/30650 (epoch 1.126), train_loss = 2.47149283, grad/param norm = 3.2799e-01, time/batch = 0.7146s	
691/30650 (epoch 1.127), train_loss = 2.53176897, grad/param norm = 3.4850e-01, time/batch = 0.7161s	
692/30650 (epoch 1.129), train_loss = 2.44804674, grad/param norm = 3.1984e-01, time/batch = 0.7076s	
693/30650 (epoch 1.131), train_loss = 2.73790046, grad/param norm = 3.2185e-01, time/batch = 0.6983s	
694/30650 (epoch 1.132), train_loss = 2.52277768, grad/param norm = 3.0776e-01, time/batch = 0.6981s	
695/30650 (epoch 1.134), train_loss = 2.23990874, grad/param norm = 2.9387e-01, time/batch = 0.7094s	
696/30650 (epoch 1.135), train_loss = 2.36345547, grad/param norm = 2.4920e-01, time/batch = 0.6839s	
697/30650 (epoch 1.137), train_loss = 2.42009329, grad/param norm = 2.7400e-01, time/batch = 0.6805s	
698/30650 (epoch 1.139), train_loss = 2.27819274, grad/param norm = 2.9650e-01, time/batch = 0.6826s	
699/30650 (epoch 1.140), train_loss = 2.39198419, grad/param norm = 2.7704e-01, time/batch = 0.6806s	
700/30650 (epoch 1.142), train_loss = 2.29438954, grad/param norm = 2.3674e-01, time/batch = 0.6861s	
701/30650 (epoch 1.144), train_loss = 2.14678894, grad/param norm = 3.3135e-01, time/batch = 0.6928s	
702/30650 (epoch 1.145), train_loss = 2.35617484, grad/param norm = 4.2575e-01, time/batch = 0.6788s	
703/30650 (epoch 1.147), train_loss = 2.43087967, grad/param norm = 4.5109e-01, time/batch = 0.6756s	
704/30650 (epoch 1.148), train_loss = 2.35444363, grad/param norm = 3.4463e-01, time/batch = 0.6763s	
705/30650 (epoch 1.150), train_loss = 2.44438547, grad/param norm = 3.1328e-01, time/batch = 0.6759s	
706/30650 (epoch 1.152), train_loss = 2.36910809, grad/param norm = 3.4324e-01, time/batch = 0.6764s	
707/30650 (epoch 1.153), train_loss = 2.41955739, grad/param norm = 3.1395e-01, time/batch = 0.6786s	
708/30650 (epoch 1.155), train_loss = 2.43675458, grad/param norm = 2.7506e-01, time/batch = 0.6811s	
709/30650 (epoch 1.157), train_loss = 2.41254863, grad/param norm = 3.4684e-01, time/batch = 0.6793s	
710/30650 (epoch 1.158), train_loss = 2.20643202, grad/param norm = 3.1801e-01, time/batch = 0.6796s	
711/30650 (epoch 1.160), train_loss = 2.37383656, grad/param norm = 2.5526e-01, time/batch = 0.6785s	
712/30650 (epoch 1.162), train_loss = 2.35658810, grad/param norm = 3.1569e-01, time/batch = 0.6773s	
713/30650 (epoch 1.163), train_loss = 2.36895277, grad/param norm = 2.7778e-01, time/batch = 0.6770s	
714/30650 (epoch 1.165), train_loss = 2.54455072, grad/param norm = 3.1165e-01, time/batch = 0.6766s	
715/30650 (epoch 1.166), train_loss = 2.49107377, grad/param norm = 2.4699e-01, time/batch = 0.6781s	
716/30650 (epoch 1.168), train_loss = 2.42979613, grad/param norm = 3.6446e-01, time/batch = 0.6773s	
717/30650 (epoch 1.170), train_loss = 2.11842550, grad/param norm = 3.8964e-01, time/batch = 0.6770s	
718/30650 (epoch 1.171), train_loss = 2.34844124, grad/param norm = 4.0288e-01, time/batch = 0.6791s	
719/30650 (epoch 1.173), train_loss = 2.40627343, grad/param norm = 3.8506e-01, time/batch = 0.7026s	
720/30650 (epoch 1.175), train_loss = 2.54642049, grad/param norm = 3.2785e-01, time/batch = 0.7124s	
721/30650 (epoch 1.176), train_loss = 2.43272617, grad/param norm = 3.0533e-01, time/batch = 0.6781s	
722/30650 (epoch 1.178), train_loss = 2.44615379, grad/param norm = 3.2017e-01, time/batch = 0.6832s	
723/30650 (epoch 1.179), train_loss = 2.55141257, grad/param norm = 2.4704e-01, time/batch = 0.6800s	
724/30650 (epoch 1.181), train_loss = 2.54330150, grad/param norm = 3.2156e-01, time/batch = 0.6774s	
725/30650 (epoch 1.183), train_loss = 2.42644950, grad/param norm = 3.0688e-01, time/batch = 0.6842s	
726/30650 (epoch 1.184), train_loss = 2.32800765, grad/param norm = 3.0679e-01, time/batch = 0.6777s	
727/30650 (epoch 1.186), train_loss = 2.46526231, grad/param norm = 3.6109e-01, time/batch = 0.6782s	
728/30650 (epoch 1.188), train_loss = 2.32054706, grad/param norm = 2.9663e-01, time/batch = 0.6773s	
729/30650 (epoch 1.189), train_loss = 2.38357246, grad/param norm = 3.0789e-01, time/batch = 0.6756s	
730/30650 (epoch 1.191), train_loss = 2.49599728, grad/param norm = 3.7085e-01, time/batch = 0.6780s	
731/30650 (epoch 1.192), train_loss = 2.29108525, grad/param norm = 2.8420e-01, time/batch = 0.6771s	
732/30650 (epoch 1.194), train_loss = 2.35603342, grad/param norm = 2.6773e-01, time/batch = 0.6776s	
733/30650 (epoch 1.196), train_loss = 2.32574930, grad/param norm = 2.8874e-01, time/batch = 0.6777s	
734/30650 (epoch 1.197), train_loss = 2.38201707, grad/param norm = 2.9232e-01, time/batch = 0.6774s	
735/30650 (epoch 1.199), train_loss = 2.34055773, grad/param norm = 3.1722e-01, time/batch = 0.6758s	
736/30650 (epoch 1.201), train_loss = 2.43158061, grad/param norm = 3.3561e-01, time/batch = 0.6775s	
737/30650 (epoch 1.202), train_loss = 2.34681592, grad/param norm = 3.1030e-01, time/batch = 0.6888s	
738/30650 (epoch 1.204), train_loss = 2.37598685, grad/param norm = 3.1039e-01, time/batch = 0.6891s	
739/30650 (epoch 1.206), train_loss = 2.31350952, grad/param norm = 3.1670e-01, time/batch = 0.6758s	
740/30650 (epoch 1.207), train_loss = 2.40781979, grad/param norm = 2.8641e-01, time/batch = 0.6782s	
741/30650 (epoch 1.209), train_loss = 2.24444065, grad/param norm = 2.6006e-01, time/batch = 0.6794s	
742/30650 (epoch 1.210), train_loss = 2.23037535, grad/param norm = 2.7833e-01, time/batch = 0.6800s	
743/30650 (epoch 1.212), train_loss = 2.50750589, grad/param norm = 3.1974e-01, time/batch = 0.6800s	
744/30650 (epoch 1.214), train_loss = 2.49750558, grad/param norm = 3.0806e-01, time/batch = 0.6800s	
745/30650 (epoch 1.215), train_loss = 2.38803607, grad/param norm = 3.2602e-01, time/batch = 0.6776s	
746/30650 (epoch 1.217), train_loss = 2.26810464, grad/param norm = 3.0337e-01, time/batch = 0.6751s	
747/30650 (epoch 1.219), train_loss = 2.42905602, grad/param norm = 3.6774e-01, time/batch = 0.6765s	
748/30650 (epoch 1.220), train_loss = 2.37896778, grad/param norm = 3.8781e-01, time/batch = 0.6906s	
749/30650 (epoch 1.222), train_loss = 2.28051832, grad/param norm = 3.7992e-01, time/batch = 0.7196s	
750/30650 (epoch 1.223), train_loss = 2.38435405, grad/param norm = 4.3094e-01, time/batch = 0.6769s	
751/30650 (epoch 1.225), train_loss = 2.40115712, grad/param norm = 5.2198e-01, time/batch = 0.6775s	
752/30650 (epoch 1.227), train_loss = 2.55683263, grad/param norm = 5.0241e-01, time/batch = 0.6780s	
753/30650 (epoch 1.228), train_loss = 2.42104706, grad/param norm = 3.8044e-01, time/batch = 0.6800s	
754/30650 (epoch 1.230), train_loss = 2.37350447, grad/param norm = 3.0068e-01, time/batch = 0.6815s	
755/30650 (epoch 1.232), train_loss = 2.41433965, grad/param norm = 3.3795e-01, time/batch = 0.6775s	
756/30650 (epoch 1.233), train_loss = 2.43093282, grad/param norm = 3.6216e-01, time/batch = 0.6750s	
757/30650 (epoch 1.235), train_loss = 2.45475289, grad/param norm = 2.9961e-01, time/batch = 0.6762s	
758/30650 (epoch 1.237), train_loss = 2.46921987, grad/param norm = 2.6064e-01, time/batch = 0.6775s	
759/30650 (epoch 1.238), train_loss = 2.59810114, grad/param norm = 2.5847e-01, time/batch = 0.6814s	
760/30650 (epoch 1.240), train_loss = 2.45738671, grad/param norm = 2.8540e-01, time/batch = 0.6870s	
761/30650 (epoch 1.241), train_loss = 2.37667201, grad/param norm = 2.3764e-01, time/batch = 0.6832s	
762/30650 (epoch 1.243), train_loss = 2.54771439, grad/param norm = 2.6931e-01, time/batch = 0.6802s	
763/30650 (epoch 1.245), train_loss = 2.40642325, grad/param norm = 3.0063e-01, time/batch = 0.6804s	
764/30650 (epoch 1.246), train_loss = 2.30367217, grad/param norm = 3.5638e-01, time/batch = 0.6809s	
765/30650 (epoch 1.248), train_loss = 2.50208363, grad/param norm = 3.2088e-01, time/batch = 0.6773s	
766/30650 (epoch 1.250), train_loss = 2.48136213, grad/param norm = 3.2017e-01, time/batch = 0.6782s	
767/30650 (epoch 1.251), train_loss = 2.41981641, grad/param norm = 3.2585e-01, time/batch = 0.6786s	
768/30650 (epoch 1.253), train_loss = 2.39532251, grad/param norm = 3.0093e-01, time/batch = 0.6862s	
769/30650 (epoch 1.254), train_loss = 2.37367648, grad/param norm = 2.9503e-01, time/batch = 0.6940s	
770/30650 (epoch 1.256), train_loss = 2.29319421, grad/param norm = 3.1891e-01, time/batch = 0.6865s	
771/30650 (epoch 1.258), train_loss = 2.43358025, grad/param norm = 3.0403e-01, time/batch = 0.6916s	
772/30650 (epoch 1.259), train_loss = 2.32962791, grad/param norm = 2.7183e-01, time/batch = 0.6872s	
773/30650 (epoch 1.261), train_loss = 2.32440842, grad/param norm = 2.7912e-01, time/batch = 0.6806s	
774/30650 (epoch 1.263), train_loss = 2.22394694, grad/param norm = 3.5064e-01, time/batch = 0.6797s	
775/30650 (epoch 1.264), train_loss = 2.40814749, grad/param norm = 2.9612e-01, time/batch = 0.6792s	
776/30650 (epoch 1.266), train_loss = 2.36929010, grad/param norm = 2.6314e-01, time/batch = 0.6831s	
777/30650 (epoch 1.268), train_loss = 2.28677819, grad/param norm = 3.2374e-01, time/batch = 0.6978s	
778/30650 (epoch 1.269), train_loss = 2.34566168, grad/param norm = 2.9446e-01, time/batch = 0.7075s	
779/30650 (epoch 1.271), train_loss = 2.36240532, grad/param norm = 3.0581e-01, time/batch = 0.6914s	
780/30650 (epoch 1.272), train_loss = 2.35675666, grad/param norm = 3.5055e-01, time/batch = 0.6850s	
781/30650 (epoch 1.274), train_loss = 2.19557703, grad/param norm = 2.6703e-01, time/batch = 0.6831s	
782/30650 (epoch 1.276), train_loss = 2.23344358, grad/param norm = 2.6447e-01, time/batch = 0.6840s	
783/30650 (epoch 1.277), train_loss = 2.24145696, grad/param norm = 3.0351e-01, time/batch = 0.6879s	
784/30650 (epoch 1.279), train_loss = 2.35251434, grad/param norm = 3.6167e-01, time/batch = 0.6859s	
785/30650 (epoch 1.281), train_loss = 2.46675025, grad/param norm = 3.1496e-01, time/batch = 0.6801s	
786/30650 (epoch 1.282), train_loss = 2.27140456, grad/param norm = 2.7219e-01, time/batch = 0.6817s	
787/30650 (epoch 1.284), train_loss = 2.53748735, grad/param norm = 3.7568e-01, time/batch = 0.6810s	
788/30650 (epoch 1.285), train_loss = 2.31999401, grad/param norm = 5.6727e-01, time/batch = 0.6815s	
789/30650 (epoch 1.287), train_loss = 2.47417274, grad/param norm = 4.4837e-01, time/batch = 0.6831s	
790/30650 (epoch 1.289), train_loss = 2.35824462, grad/param norm = 2.6367e-01, time/batch = 0.6810s	
791/30650 (epoch 1.290), train_loss = 2.39468280, grad/param norm = 3.0453e-01, time/batch = 0.6812s	
792/30650 (epoch 1.292), train_loss = 2.35103427, grad/param norm = 3.3952e-01, time/batch = 0.7104s	
793/30650 (epoch 1.294), train_loss = 2.22291417, grad/param norm = 3.2846e-01, time/batch = 0.7077s	
794/30650 (epoch 1.295), train_loss = 2.33558963, grad/param norm = 3.0523e-01, time/batch = 0.6819s	
795/30650 (epoch 1.297), train_loss = 2.25258566, grad/param norm = 2.6953e-01, time/batch = 0.6891s	
796/30650 (epoch 1.299), train_loss = 2.16723064, grad/param norm = 2.8454e-01, time/batch = 0.6800s	
797/30650 (epoch 1.300), train_loss = 2.24698761, grad/param norm = 3.2702e-01, time/batch = 0.6776s	
798/30650 (epoch 1.302), train_loss = 2.28407312, grad/param norm = 2.8324e-01, time/batch = 0.6825s	
799/30650 (epoch 1.303), train_loss = 2.17782630, grad/param norm = 2.6876e-01, time/batch = 0.6808s	
800/30650 (epoch 1.305), train_loss = 2.42274875, grad/param norm = 3.0294e-01, time/batch = 0.6797s	
801/30650 (epoch 1.307), train_loss = 2.27363446, grad/param norm = 3.0455e-01, time/batch = 0.6795s	
802/30650 (epoch 1.308), train_loss = 2.24610866, grad/param norm = 3.7478e-01, time/batch = 0.6800s	
803/30650 (epoch 1.310), train_loss = 2.42058854, grad/param norm = 3.3032e-01, time/batch = 0.6966s	
804/30650 (epoch 1.312), train_loss = 2.49394675, grad/param norm = 3.1944e-01, time/batch = 0.6912s	
805/30650 (epoch 1.313), train_loss = 2.53070707, grad/param norm = 2.7052e-01, time/batch = 0.6785s	
806/30650 (epoch 1.315), train_loss = 2.46150011, grad/param norm = 2.7814e-01, time/batch = 0.6809s	
807/30650 (epoch 1.316), train_loss = 2.45618939, grad/param norm = 2.4518e-01, time/batch = 0.6781s	
808/30650 (epoch 1.318), train_loss = 2.52038960, grad/param norm = 2.8514e-01, time/batch = 0.6795s	
809/30650 (epoch 1.320), train_loss = 2.35748667, grad/param norm = 2.8064e-01, time/batch = 0.6806s	
810/30650 (epoch 1.321), train_loss = 2.45594295, grad/param norm = 2.8229e-01, time/batch = 0.6830s	
811/30650 (epoch 1.323), train_loss = 2.19393647, grad/param norm = 3.1548e-01, time/batch = 0.6830s	
812/30650 (epoch 1.325), train_loss = 2.36634480, grad/param norm = 3.2408e-01, time/batch = 0.6816s	
813/30650 (epoch 1.326), train_loss = 2.27592813, grad/param norm = 3.3626e-01, time/batch = 0.6853s	
814/30650 (epoch 1.328), train_loss = 2.25006801, grad/param norm = 3.8832e-01, time/batch = 0.6780s	
815/30650 (epoch 1.330), train_loss = 2.45188235, grad/param norm = 3.4647e-01, time/batch = 0.6788s	
816/30650 (epoch 1.331), train_loss = 2.44067753, grad/param norm = 3.3107e-01, time/batch = 0.6781s	
817/30650 (epoch 1.333), train_loss = 2.37549178, grad/param norm = 2.6257e-01, time/batch = 0.6782s	
818/30650 (epoch 1.334), train_loss = 2.41162779, grad/param norm = 2.4370e-01, time/batch = 0.6808s	
819/30650 (epoch 1.336), train_loss = 2.33786236, grad/param norm = 2.6396e-01, time/batch = 0.6797s	
820/30650 (epoch 1.338), train_loss = 2.59485356, grad/param norm = 2.6673e-01, time/batch = 0.6805s	
821/30650 (epoch 1.339), train_loss = 2.56878415, grad/param norm = 2.5756e-01, time/batch = 0.7058s	
822/30650 (epoch 1.341), train_loss = 2.40219082, grad/param norm = 2.9673e-01, time/batch = 0.7127s	
823/30650 (epoch 1.343), train_loss = 2.29580270, grad/param norm = 2.8472e-01, time/batch = 0.6780s	
824/30650 (epoch 1.344), train_loss = 2.37788322, grad/param norm = 3.4914e-01, time/batch = 0.6816s	
825/30650 (epoch 1.346), train_loss = 2.50316187, grad/param norm = 3.9922e-01, time/batch = 0.6806s	
826/30650 (epoch 1.347), train_loss = 2.37672807, grad/param norm = 3.4993e-01, time/batch = 0.6868s	
827/30650 (epoch 1.349), train_loss = 2.30907020, grad/param norm = 3.4611e-01, time/batch = 0.6791s	
828/30650 (epoch 1.351), train_loss = 2.27705857, grad/param norm = 3.1824e-01, time/batch = 0.6853s	
829/30650 (epoch 1.352), train_loss = 2.39936311, grad/param norm = 3.2926e-01, time/batch = 0.6761s	
830/30650 (epoch 1.354), train_loss = 2.21712627, grad/param norm = 3.2591e-01, time/batch = 0.6762s	
831/30650 (epoch 1.356), train_loss = 2.29198344, grad/param norm = 3.8452e-01, time/batch = 0.6832s	
832/30650 (epoch 1.357), train_loss = 2.33475909, grad/param norm = 3.8604e-01, time/batch = 0.6801s	
833/30650 (epoch 1.359), train_loss = 2.41374623, grad/param norm = 3.6635e-01, time/batch = 0.6768s	
834/30650 (epoch 1.361), train_loss = 2.46466286, grad/param norm = 2.8374e-01, time/batch = 0.6778s	
835/30650 (epoch 1.362), train_loss = 2.35862572, grad/param norm = 3.0507e-01, time/batch = 0.6799s	
836/30650 (epoch 1.364), train_loss = 2.31489701, grad/param norm = 3.2212e-01, time/batch = 0.7212s	
837/30650 (epoch 1.365), train_loss = 2.37503799, grad/param norm = 3.0910e-01, time/batch = 0.6943s	
838/30650 (epoch 1.367), train_loss = 2.30865155, grad/param norm = 2.7378e-01, time/batch = 0.6785s	
839/30650 (epoch 1.369), train_loss = 2.22537013, grad/param norm = 3.0585e-01, time/batch = 0.6779s	
840/30650 (epoch 1.370), train_loss = 2.36360253, grad/param norm = 3.0660e-01, time/batch = 0.6810s	
841/30650 (epoch 1.372), train_loss = 2.37513985, grad/param norm = 2.8156e-01, time/batch = 0.6918s	
842/30650 (epoch 1.374), train_loss = 2.28741381, grad/param norm = 3.5255e-01, time/batch = 0.6817s	
843/30650 (epoch 1.375), train_loss = 2.39833518, grad/param norm = 3.8801e-01, time/batch = 0.6811s	
844/30650 (epoch 1.377), train_loss = 2.46275416, grad/param norm = 2.8826e-01, time/batch = 0.6791s	
845/30650 (epoch 1.378), train_loss = 2.31654766, grad/param norm = 2.6887e-01, time/batch = 0.6784s	
846/30650 (epoch 1.380), train_loss = 2.42349962, grad/param norm = 2.5070e-01, time/batch = 0.6769s	
847/30650 (epoch 1.382), train_loss = 2.25883908, grad/param norm = 2.9475e-01, time/batch = 0.6789s	
848/30650 (epoch 1.383), train_loss = 2.39589059, grad/param norm = 2.3525e-01, time/batch = 0.6777s	
849/30650 (epoch 1.385), train_loss = 2.35583179, grad/param norm = 2.7630e-01, time/batch = 0.6808s	
850/30650 (epoch 1.387), train_loss = 2.07947332, grad/param norm = 2.4464e-01, time/batch = 0.7013s	
851/30650 (epoch 1.388), train_loss = 2.33557870, grad/param norm = 2.5467e-01, time/batch = 0.7188s	
852/30650 (epoch 1.390), train_loss = 2.05662172, grad/param norm = 2.6079e-01, time/batch = 0.6786s	
853/30650 (epoch 1.392), train_loss = 2.18327681, grad/param norm = 2.8042e-01, time/batch = 0.6803s	
854/30650 (epoch 1.393), train_loss = 2.11722515, grad/param norm = 2.6764e-01, time/batch = 0.6806s	
855/30650 (epoch 1.395), train_loss = 2.14896337, grad/param norm = 2.8399e-01, time/batch = 0.6851s	
856/30650 (epoch 1.396), train_loss = 2.28516890, grad/param norm = 3.0250e-01, time/batch = 0.7005s	
857/30650 (epoch 1.398), train_loss = 2.26513750, grad/param norm = 3.1622e-01, time/batch = 0.6857s	
858/30650 (epoch 1.400), train_loss = 2.27247285, grad/param norm = 3.0327e-01, time/batch = 0.6983s	
859/30650 (epoch 1.401), train_loss = 2.09596023, grad/param norm = 2.8295e-01, time/batch = 0.6963s	
860/30650 (epoch 1.403), train_loss = 2.27702913, grad/param norm = 3.5159e-01, time/batch = 0.6854s	
861/30650 (epoch 1.405), train_loss = 2.24593532, grad/param norm = 3.8963e-01, time/batch = 0.6826s	
862/30650 (epoch 1.406), train_loss = 2.27143703, grad/param norm = 3.9523e-01, time/batch = 0.6802s	
863/30650 (epoch 1.408), train_loss = 2.39282267, grad/param norm = 2.9796e-01, time/batch = 0.6789s	
864/30650 (epoch 1.409), train_loss = 2.42132036, grad/param norm = 3.3987e-01, time/batch = 0.6893s	
865/30650 (epoch 1.411), train_loss = 2.22102110, grad/param norm = 3.7905e-01, time/batch = 0.6935s	
866/30650 (epoch 1.413), train_loss = 2.14731063, grad/param norm = 2.5711e-01, time/batch = 0.6938s	
867/30650 (epoch 1.414), train_loss = 2.29109336, grad/param norm = 2.7210e-01, time/batch = 0.6853s	
868/30650 (epoch 1.416), train_loss = 2.30039097, grad/param norm = 2.6944e-01, time/batch = 0.6789s	
869/30650 (epoch 1.418), train_loss = 2.26680862, grad/param norm = 2.9160e-01, time/batch = 0.6763s	
870/30650 (epoch 1.419), train_loss = 2.34455858, grad/param norm = 2.9122e-01, time/batch = 0.6815s	
871/30650 (epoch 1.421), train_loss = 2.23571626, grad/param norm = 3.0152e-01, time/batch = 0.6819s	
872/30650 (epoch 1.423), train_loss = 2.28297008, grad/param norm = 2.7990e-01, time/batch = 0.6837s	
873/30650 (epoch 1.424), train_loss = 2.51330106, grad/param norm = 2.8775e-01, time/batch = 0.6856s	
874/30650 (epoch 1.426), train_loss = 2.16316615, grad/param norm = 3.5324e-01, time/batch = 0.6842s	
875/30650 (epoch 1.427), train_loss = 2.38509319, grad/param norm = 4.7061e-01, time/batch = 0.6793s	
876/30650 (epoch 1.429), train_loss = 2.33028293, grad/param norm = 3.6088e-01, time/batch = 0.6796s	
877/30650 (epoch 1.431), train_loss = 2.38316384, grad/param norm = 2.8714e-01, time/batch = 0.6751s	
878/30650 (epoch 1.432), train_loss = 2.39123046, grad/param norm = 2.9299e-01, time/batch = 0.6780s	
879/30650 (epoch 1.434), train_loss = 2.31662239, grad/param norm = 2.9423e-01, time/batch = 0.6760s	
880/30650 (epoch 1.436), train_loss = 2.30675535, grad/param norm = 2.4554e-01, time/batch = 0.6772s	
881/30650 (epoch 1.437), train_loss = 2.34286764, grad/param norm = 2.5200e-01, time/batch = 0.6773s	
882/30650 (epoch 1.439), train_loss = 2.10469628, grad/param norm = 2.8785e-01, time/batch = 0.6762s	
883/30650 (epoch 1.440), train_loss = 2.21257733, grad/param norm = 3.2869e-01, time/batch = 0.6789s	
884/30650 (epoch 1.442), train_loss = 2.06559649, grad/param norm = 3.5281e-01, time/batch = 0.6758s	
885/30650 (epoch 1.444), train_loss = 2.24080362, grad/param norm = 2.9348e-01, time/batch = 0.6814s	
886/30650 (epoch 1.445), train_loss = 2.13220873, grad/param norm = 3.3833e-01, time/batch = 0.6767s	
887/30650 (epoch 1.447), train_loss = 2.38317374, grad/param norm = 3.2887e-01, time/batch = 0.6760s	
888/30650 (epoch 1.449), train_loss = 2.13645286, grad/param norm = 2.9783e-01, time/batch = 0.6766s	
889/30650 (epoch 1.450), train_loss = 2.31027290, grad/param norm = 3.0706e-01, time/batch = 0.6780s	
890/30650 (epoch 1.452), train_loss = 2.12979119, grad/param norm = 2.4972e-01, time/batch = 0.6829s	
891/30650 (epoch 1.454), train_loss = 2.21491860, grad/param norm = 3.0135e-01, time/batch = 0.6821s	
892/30650 (epoch 1.455), train_loss = 2.24873983, grad/param norm = 2.7850e-01, time/batch = 0.6803s	
893/30650 (epoch 1.457), train_loss = 2.17486219, grad/param norm = 3.2448e-01, time/batch = 0.6816s	
894/30650 (epoch 1.458), train_loss = 2.27751848, grad/param norm = 3.0316e-01, time/batch = 0.6790s	
895/30650 (epoch 1.460), train_loss = 2.27055799, grad/param norm = 2.6896e-01, time/batch = 0.6799s	
896/30650 (epoch 1.462), train_loss = 2.32805979, grad/param norm = 2.7734e-01, time/batch = 0.6785s	
897/30650 (epoch 1.463), train_loss = 2.15524751, grad/param norm = 3.9857e-01, time/batch = 0.6771s	
898/30650 (epoch 1.465), train_loss = 2.43322516, grad/param norm = 4.1798e-01, time/batch = 0.6931s	
899/30650 (epoch 1.467), train_loss = 2.31715931, grad/param norm = 2.8989e-01, time/batch = 0.7211s	
900/30650 (epoch 1.468), train_loss = 2.34088405, grad/param norm = 2.5626e-01, time/batch = 0.6829s	
901/30650 (epoch 1.470), train_loss = 2.16593593, grad/param norm = 2.9320e-01, time/batch = 0.6799s	
902/30650 (epoch 1.471), train_loss = 2.08753118, grad/param norm = 2.6098e-01, time/batch = 0.6789s	
903/30650 (epoch 1.473), train_loss = 2.48414869, grad/param norm = 2.7781e-01, time/batch = 0.6765s	
904/30650 (epoch 1.475), train_loss = 2.21852662, grad/param norm = 2.3803e-01, time/batch = 0.6767s	
905/30650 (epoch 1.476), train_loss = 2.25787132, grad/param norm = 2.4397e-01, time/batch = 0.6807s	
906/30650 (epoch 1.478), train_loss = 2.21715234, grad/param norm = 2.5769e-01, time/batch = 0.6789s	
907/30650 (epoch 1.480), train_loss = 2.31949508, grad/param norm = 2.6640e-01, time/batch = 0.6787s	
908/30650 (epoch 1.481), train_loss = 2.13541667, grad/param norm = 2.9650e-01, time/batch = 0.6802s	
909/30650 (epoch 1.483), train_loss = 2.21748952, grad/param norm = 2.9472e-01, time/batch = 0.6774s	
910/30650 (epoch 1.485), train_loss = 2.17064946, grad/param norm = 2.7249e-01, time/batch = 0.6766s	
911/30650 (epoch 1.486), train_loss = 2.30892396, grad/param norm = 2.5188e-01, time/batch = 0.6773s	
912/30650 (epoch 1.488), train_loss = 2.11143168, grad/param norm = 2.6687e-01, time/batch = 0.6826s	
913/30650 (epoch 1.489), train_loss = 2.27488959, grad/param norm = 2.9059e-01, time/batch = 0.6896s	
914/30650 (epoch 1.491), train_loss = 2.22127482, grad/param norm = 3.4789e-01, time/batch = 0.6878s	
915/30650 (epoch 1.493), train_loss = 2.34177476, grad/param norm = 3.5535e-01, time/batch = 0.6773s	
916/30650 (epoch 1.494), train_loss = 2.14623256, grad/param norm = 3.1926e-01, time/batch = 0.6783s	
917/30650 (epoch 1.496), train_loss = 2.27577702, grad/param norm = 2.6561e-01, time/batch = 0.6793s	
918/30650 (epoch 1.498), train_loss = 2.16605402, grad/param norm = 3.1373e-01, time/batch = 0.6780s	
919/30650 (epoch 1.499), train_loss = 2.28979082, grad/param norm = 2.7174e-01, time/batch = 0.6784s	
920/30650 (epoch 1.501), train_loss = 2.39396744, grad/param norm = 2.9973e-01, time/batch = 0.6768s	
921/30650 (epoch 1.502), train_loss = 2.41798215, grad/param norm = 3.5047e-01, time/batch = 0.6781s	
922/30650 (epoch 1.504), train_loss = 2.37224800, grad/param norm = 3.1661e-01, time/batch = 0.6782s	
923/30650 (epoch 1.506), train_loss = 2.22404952, grad/param norm = 2.9183e-01, time/batch = 0.6817s	
924/30650 (epoch 1.507), train_loss = 2.19703219, grad/param norm = 2.5868e-01, time/batch = 0.6961s	
925/30650 (epoch 1.509), train_loss = 2.15452703, grad/param norm = 2.7529e-01, time/batch = 0.7022s	
926/30650 (epoch 1.511), train_loss = 2.24198258, grad/param norm = 2.7638e-01, time/batch = 0.6977s	
927/30650 (epoch 1.512), train_loss = 2.18177533, grad/param norm = 2.8519e-01, time/batch = 0.7077s	
928/30650 (epoch 1.514), train_loss = 2.36609005, grad/param norm = 2.9397e-01, time/batch = 0.7142s	
929/30650 (epoch 1.515), train_loss = 2.27954975, grad/param norm = 2.3540e-01, time/batch = 0.6917s	
930/30650 (epoch 1.517), train_loss = 2.28528842, grad/param norm = 2.5691e-01, time/batch = 0.6958s	
931/30650 (epoch 1.519), train_loss = 2.29028982, grad/param norm = 2.4362e-01, time/batch = 0.6990s	
932/30650 (epoch 1.520), train_loss = 2.20984202, grad/param norm = 2.5560e-01, time/batch = 0.6958s	
933/30650 (epoch 1.522), train_loss = 2.54159150, grad/param norm = 3.1985e-01, time/batch = 0.6977s	
934/30650 (epoch 1.524), train_loss = 2.29248553, grad/param norm = 2.5969e-01, time/batch = 0.6921s	
935/30650 (epoch 1.525), train_loss = 2.06431730, grad/param norm = 3.3392e-01, time/batch = 0.6776s	
936/30650 (epoch 1.527), train_loss = 2.45680132, grad/param norm = 2.8412e-01, time/batch = 0.6784s	
937/30650 (epoch 1.529), train_loss = 2.35499098, grad/param norm = 2.8742e-01, time/batch = 0.6786s	
938/30650 (epoch 1.530), train_loss = 2.26185291, grad/param norm = 2.7822e-01, time/batch = 0.6798s	
939/30650 (epoch 1.532), train_loss = 2.19081805, grad/param norm = 3.5122e-01, time/batch = 0.6802s	
940/30650 (epoch 1.533), train_loss = 2.24892566, grad/param norm = 3.2077e-01, time/batch = 0.6778s	
941/30650 (epoch 1.535), train_loss = 2.33877290, grad/param norm = 3.4356e-01, time/batch = 0.6809s	
942/30650 (epoch 1.537), train_loss = 2.44940450, grad/param norm = 2.7467e-01, time/batch = 0.7145s	
943/30650 (epoch 1.538), train_loss = 2.26801589, grad/param norm = 2.4448e-01, time/batch = 0.7077s	
944/30650 (epoch 1.540), train_loss = 2.27130714, grad/param norm = 2.8331e-01, time/batch = 0.6846s	
945/30650 (epoch 1.542), train_loss = 2.47051844, grad/param norm = 2.7399e-01, time/batch = 0.6824s	
946/30650 (epoch 1.543), train_loss = 2.40390628, grad/param norm = 2.8372e-01, time/batch = 0.6817s	
947/30650 (epoch 1.545), train_loss = 2.34777772, grad/param norm = 2.5739e-01, time/batch = 0.6779s	
948/30650 (epoch 1.546), train_loss = 2.15951155, grad/param norm = 2.3300e-01, time/batch = 0.6760s	
949/30650 (epoch 1.548), train_loss = 2.33838330, grad/param norm = 3.3066e-01, time/batch = 0.6790s	
950/30650 (epoch 1.550), train_loss = 2.33147168, grad/param norm = 2.4921e-01, time/batch = 0.6766s	
951/30650 (epoch 1.551), train_loss = 2.27503568, grad/param norm = 2.3446e-01, time/batch = 0.6782s	
952/30650 (epoch 1.553), train_loss = 2.49846669, grad/param norm = 2.7981e-01, time/batch = 0.6791s	
953/30650 (epoch 1.555), train_loss = 2.37104735, grad/param norm = 2.5471e-01, time/batch = 0.6968s	
954/30650 (epoch 1.556), train_loss = 2.25876072, grad/param norm = 2.7772e-01, time/batch = 0.6750s	
955/30650 (epoch 1.558), train_loss = 2.42697764, grad/param norm = 3.5586e-01, time/batch = 0.6769s	
956/30650 (epoch 1.560), train_loss = 2.32324177, grad/param norm = 3.5348e-01, time/batch = 0.6880s	
957/30650 (epoch 1.561), train_loss = 2.41923642, grad/param norm = 2.8908e-01, time/batch = 0.7213s	
958/30650 (epoch 1.563), train_loss = 2.27296374, grad/param norm = 2.8698e-01, time/batch = 0.6809s	
959/30650 (epoch 1.564), train_loss = 2.12105790, grad/param norm = 3.0930e-01, time/batch = 0.6764s	
960/30650 (epoch 1.566), train_loss = 2.25303222, grad/param norm = 2.3380e-01, time/batch = 0.6848s	
961/30650 (epoch 1.568), train_loss = 2.36795395, grad/param norm = 2.8158e-01, time/batch = 0.6830s	
962/30650 (epoch 1.569), train_loss = 2.22357249, grad/param norm = 2.6059e-01, time/batch = 0.6750s	
963/30650 (epoch 1.571), train_loss = 2.31932087, grad/param norm = 2.8112e-01, time/batch = 0.6765s	
964/30650 (epoch 1.573), train_loss = 2.18344873, grad/param norm = 2.9210e-01, time/batch = 0.6744s	
965/30650 (epoch 1.574), train_loss = 2.32677613, grad/param norm = 3.1713e-01, time/batch = 0.6736s	
966/30650 (epoch 1.576), train_loss = 2.22309789, grad/param norm = 3.3105e-01, time/batch = 0.6754s	
967/30650 (epoch 1.577), train_loss = 2.16835920, grad/param norm = 2.3838e-01, time/batch = 0.6847s	
968/30650 (epoch 1.579), train_loss = 2.28724018, grad/param norm = 2.6000e-01, time/batch = 0.6779s	
969/30650 (epoch 1.581), train_loss = 2.26261548, grad/param norm = 2.3923e-01, time/batch = 0.6749s	
970/30650 (epoch 1.582), train_loss = 2.24763688, grad/param norm = 2.7008e-01, time/batch = 0.6759s	
971/30650 (epoch 1.584), train_loss = 2.27323715, grad/param norm = 2.9209e-01, time/batch = 0.7081s	
972/30650 (epoch 1.586), train_loss = 2.26612339, grad/param norm = 3.2917e-01, time/batch = 0.7131s	
973/30650 (epoch 1.587), train_loss = 2.38834938, grad/param norm = 3.2067e-01, time/batch = 0.6796s	
974/30650 (epoch 1.589), train_loss = 2.14578559, grad/param norm = 3.0147e-01, time/batch = 0.6761s	
975/30650 (epoch 1.591), train_loss = 2.22638201, grad/param norm = 2.9189e-01, time/batch = 0.6764s	
976/30650 (epoch 1.592), train_loss = 2.16293059, grad/param norm = 2.8643e-01, time/batch = 0.6752s	
977/30650 (epoch 1.594), train_loss = 2.43212679, grad/param norm = 3.0984e-01, time/batch = 0.6748s	
978/30650 (epoch 1.595), train_loss = 2.30724248, grad/param norm = 3.6491e-01, time/batch = 0.6770s	
979/30650 (epoch 1.597), train_loss = 2.22376255, grad/param norm = 2.6974e-01, time/batch = 0.6775s	
980/30650 (epoch 1.599), train_loss = 2.32591111, grad/param norm = 2.6867e-01, time/batch = 0.6766s	
981/30650 (epoch 1.600), train_loss = 2.08586408, grad/param norm = 2.6898e-01, time/batch = 0.7044s	
982/30650 (epoch 1.602), train_loss = 2.12095674, grad/param norm = 2.6759e-01, time/batch = 0.6937s	
983/30650 (epoch 1.604), train_loss = 2.09349054, grad/param norm = 2.4486e-01, time/batch = 0.6750s	
984/30650 (epoch 1.605), train_loss = 1.97396571, grad/param norm = 3.0167e-01, time/batch = 0.6766s	
985/30650 (epoch 1.607), train_loss = 2.23205022, grad/param norm = 3.6332e-01, time/batch = 0.6824s	
986/30650 (epoch 1.608), train_loss = 2.08746648, grad/param norm = 2.7123e-01, time/batch = 0.7212s	
987/30650 (epoch 1.610), train_loss = 2.27345860, grad/param norm = 3.3834e-01, time/batch = 0.6901s	
988/30650 (epoch 1.612), train_loss = 2.36753004, grad/param norm = 3.3646e-01, time/batch = 0.6785s	
989/30650 (epoch 1.613), train_loss = 2.36239834, grad/param norm = 3.0057e-01, time/batch = 0.6750s	
990/30650 (epoch 1.615), train_loss = 2.23246834, grad/param norm = 2.3599e-01, time/batch = 0.6769s	
991/30650 (epoch 1.617), train_loss = 2.08298411, grad/param norm = 2.8956e-01, time/batch = 0.6776s	
992/30650 (epoch 1.618), train_loss = 2.44790758, grad/param norm = 2.7503e-01, time/batch = 0.6779s	
993/30650 (epoch 1.620), train_loss = 2.17457086, grad/param norm = 2.6959e-01, time/batch = 0.6806s	
994/30650 (epoch 1.622), train_loss = 1.92194845, grad/param norm = 2.6200e-01, time/batch = 0.6778s	
995/30650 (epoch 1.623), train_loss = 2.13405485, grad/param norm = 2.8694e-01, time/batch = 0.6758s	
996/30650 (epoch 1.625), train_loss = 2.24433218, grad/param norm = 3.0066e-01, time/batch = 0.6782s	
997/30650 (epoch 1.626), train_loss = 2.31853916, grad/param norm = 3.1121e-01, time/batch = 0.6763s	
998/30650 (epoch 1.628), train_loss = 2.29177400, grad/param norm = 2.6935e-01, time/batch = 0.6777s	
999/30650 (epoch 1.630), train_loss = 2.17596713, grad/param norm = 2.5890e-01, time/batch = 0.6780s	
evaluating loss over split index 2	
1/33...	
2/33...	
3/33...	
4/33...	
5/33...	
6/33...	
7/33...	
8/33...	
9/33...	
10/33...	
11/33...	
12/33...	
13/33...	
14/33...	
15/33...	
16/33...	
17/33...	
18/33...	
19/33...	
20/33...	
21/33...	
22/33...	
23/33...	
24/33...	
25/33...	
26/33...	
27/33...	
28/33...	
29/33...	
30/33...	
31/33...	
32/33...	
33/33...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_nicole_epoch1.63_2.3778.t7	
1000/30650 (epoch 1.631), train_loss = 2.21408547, grad/param norm = 2.2973e-01, time/batch = 0.7007s	
1001/30650 (epoch 1.633), train_loss = 2.27673411, grad/param norm = 2.5998e-01, time/batch = 0.6832s	
1002/30650 (epoch 1.635), train_loss = 2.21718115, grad/param norm = 2.6211e-01, time/batch = 0.6784s	
1003/30650 (epoch 1.636), train_loss = 2.19018268, grad/param norm = 2.5712e-01, time/batch = 0.6765s	
1004/30650 (epoch 1.638), train_loss = 2.20356229, grad/param norm = 2.7603e-01, time/batch = 0.6797s	
1005/30650 (epoch 1.639), train_loss = 2.39331424, grad/param norm = 2.7086e-01, time/batch = 0.6803s	
1006/30650 (epoch 1.641), train_loss = 2.18805519, grad/param norm = 2.4372e-01, time/batch = 0.7195s	
1007/30650 (epoch 1.643), train_loss = 2.30518301, grad/param norm = 2.2942e-01, time/batch = 0.7032s	
1008/30650 (epoch 1.644), train_loss = 2.30553402, grad/param norm = 2.5374e-01, time/batch = 0.6812s	
1009/30650 (epoch 1.646), train_loss = 2.38686071, grad/param norm = 2.9869e-01, time/batch = 0.6806s	
1010/30650 (epoch 1.648), train_loss = 2.11829460, grad/param norm = 2.6706e-01, time/batch = 0.6889s	
1011/30650 (epoch 1.649), train_loss = 2.09801755, grad/param norm = 2.5420e-01, time/batch = 0.6794s	
1012/30650 (epoch 1.651), train_loss = 2.11621423, grad/param norm = 2.2318e-01, time/batch = 0.6778s	
1013/30650 (epoch 1.653), train_loss = 2.16687197, grad/param norm = 2.8751e-01, time/batch = 0.6772s	
1014/30650 (epoch 1.654), train_loss = 1.98659535, grad/param norm = 2.5917e-01, time/batch = 0.6775s	
1015/30650 (epoch 1.656), train_loss = 2.17413248, grad/param norm = 2.6902e-01, time/batch = 0.6743s	
1016/30650 (epoch 1.657), train_loss = 2.24206314, grad/param norm = 2.9461e-01, time/batch = 0.6832s	
1017/30650 (epoch 1.659), train_loss = 2.16534887, grad/param norm = 2.6379e-01, time/batch = 0.6796s	
1018/30650 (epoch 1.661), train_loss = 2.17419884, grad/param norm = 2.5793e-01, time/batch = 0.6759s	
1019/30650 (epoch 1.662), train_loss = 2.09370738, grad/param norm = 2.6791e-01, time/batch = 0.6754s	
1020/30650 (epoch 1.664), train_loss = 2.21287159, grad/param norm = 2.6456e-01, time/batch = 0.6771s	
1021/30650 (epoch 1.666), train_loss = 2.17169003, grad/param norm = 2.4053e-01, time/batch = 0.6867s	
1022/30650 (epoch 1.667), train_loss = 2.37292868, grad/param norm = 3.1305e-01, time/batch = 0.6870s	
1023/30650 (epoch 1.669), train_loss = 2.22919846, grad/param norm = 2.9360e-01, time/batch = 0.6829s	
1024/30650 (epoch 1.670), train_loss = 2.20023277, grad/param norm = 2.8786e-01, time/batch = 0.6847s	
1025/30650 (epoch 1.672), train_loss = 2.29770451, grad/param norm = 2.7392e-01, time/batch = 0.6850s	
1026/30650 (epoch 1.674), train_loss = 2.17153752, grad/param norm = 2.7133e-01, time/batch = 0.6770s	
1027/30650 (epoch 1.675), train_loss = 2.26433129, grad/param norm = 2.6018e-01, time/batch = 0.6788s	
1028/30650 (epoch 1.677), train_loss = 2.11173350, grad/param norm = 2.6029e-01, time/batch = 0.6800s	
1029/30650 (epoch 1.679), train_loss = 2.19234984, grad/param norm = 2.1913e-01, time/batch = 0.6853s	
1030/30650 (epoch 1.680), train_loss = 2.36593322, grad/param norm = 2.6003e-01, time/batch = 0.6971s	
1031/30650 (epoch 1.682), train_loss = 2.20260983, grad/param norm = 2.4144e-01, time/batch = 0.7007s	
1032/30650 (epoch 1.684), train_loss = 2.25124165, grad/param norm = 2.4876e-01, time/batch = 0.6950s	
1033/30650 (epoch 1.685), train_loss = 2.12954999, grad/param norm = 2.6707e-01, time/batch = 0.7077s	
1034/30650 (epoch 1.687), train_loss = 2.24073552, grad/param norm = 3.1353e-01, time/batch = 0.6965s	
1035/30650 (epoch 1.688), train_loss = 2.14962988, grad/param norm = 3.3212e-01, time/batch = 0.6954s	
1036/30650 (epoch 1.690), train_loss = 2.05736595, grad/param norm = 2.9684e-01, time/batch = 0.7033s	
1037/30650 (epoch 1.692), train_loss = 2.21240322, grad/param norm = 3.1262e-01, time/batch = 0.7128s	
1038/30650 (epoch 1.693), train_loss = 1.98191323, grad/param norm = 3.3151e-01, time/batch = 0.6897s	
1039/30650 (epoch 1.695), train_loss = 2.09224574, grad/param norm = 4.4047e-01, time/batch = 0.6968s	
1040/30650 (epoch 1.697), train_loss = 2.09933216, grad/param norm = 3.4438e-01, time/batch = 0.6942s	
1041/30650 (epoch 1.698), train_loss = 2.12734021, grad/param norm = 2.3715e-01, time/batch = 0.6935s	
1042/30650 (epoch 1.700), train_loss = 2.19082160, grad/param norm = 2.5660e-01, time/batch = 0.6950s	
1043/30650 (epoch 1.701), train_loss = 2.02394979, grad/param norm = 2.3499e-01, time/batch = 0.6909s	
1044/30650 (epoch 1.703), train_loss = 2.03839022, grad/param norm = 2.4630e-01, time/batch = 0.6957s	
1045/30650 (epoch 1.705), train_loss = 1.97914884, grad/param norm = 2.6956e-01, time/batch = 0.7245s	
1046/30650 (epoch 1.706), train_loss = 2.16152653, grad/param norm = 2.5818e-01, time/batch = 0.7002s	
1047/30650 (epoch 1.708), train_loss = 2.31881959, grad/param norm = 2.8957e-01, time/batch = 0.6779s	
1048/30650 (epoch 1.710), train_loss = 2.23490847, grad/param norm = 2.9868e-01, time/batch = 0.6769s	
1049/30650 (epoch 1.711), train_loss = 2.29830804, grad/param norm = 3.0155e-01, time/batch = 0.6785s	
1050/30650 (epoch 1.713), train_loss = 2.25541707, grad/param norm = 2.9473e-01, time/batch = 0.6775s	
1051/30650 (epoch 1.715), train_loss = 2.24087876, grad/param norm = 2.3818e-01, time/batch = 0.6766s	
1052/30650 (epoch 1.716), train_loss = 2.23638744, grad/param norm = 2.3610e-01, time/batch = 0.6760s	
1053/30650 (epoch 1.718), train_loss = 2.12777077, grad/param norm = 2.5245e-01, time/batch = 0.6822s	
1054/30650 (epoch 1.719), train_loss = 2.08665171, grad/param norm = 2.6126e-01, time/batch = 0.6903s	
1055/30650 (epoch 1.721), train_loss = 2.29496728, grad/param norm = 2.7418e-01, time/batch = 0.7154s	
1056/30650 (epoch 1.723), train_loss = 2.00101965, grad/param norm = 2.3412e-01, time/batch = 0.7202s	
1057/30650 (epoch 1.724), train_loss = 2.25131067, grad/param norm = 2.6511e-01, time/batch = 0.7184s	
1058/30650 (epoch 1.726), train_loss = 2.00660830, grad/param norm = 2.6567e-01, time/batch = 0.7149s	
1059/30650 (epoch 1.728), train_loss = 2.16255695, grad/param norm = 3.0102e-01, time/batch = 0.7208s	
1060/30650 (epoch 1.729), train_loss = 2.29084509, grad/param norm = 3.2022e-01, time/batch = 0.7194s	
1061/30650 (epoch 1.731), train_loss = 2.34695206, grad/param norm = 2.5010e-01, time/batch = 0.7281s	
1062/30650 (epoch 1.732), train_loss = 2.27116491, grad/param norm = 3.0833e-01, time/batch = 0.6956s	
1063/30650 (epoch 1.734), train_loss = 2.34372861, grad/param norm = 2.9143e-01, time/batch = 0.6871s	
1064/30650 (epoch 1.736), train_loss = 2.32212967, grad/param norm = 2.7764e-01, time/batch = 0.6924s	
1065/30650 (epoch 1.737), train_loss = 2.20194590, grad/param norm = 2.8099e-01, time/batch = 0.6987s	
1066/30650 (epoch 1.739), train_loss = 2.09555455, grad/param norm = 2.6912e-01, time/batch = 0.6946s	
1067/30650 (epoch 1.741), train_loss = 2.21669922, grad/param norm = 2.3929e-01, time/batch = 0.7002s	
1068/30650 (epoch 1.742), train_loss = 2.36878426, grad/param norm = 2.5507e-01, time/batch = 0.7205s	
1069/30650 (epoch 1.744), train_loss = 2.22431398, grad/param norm = 2.3538e-01, time/batch = 0.7107s	
1070/30650 (epoch 1.746), train_loss = 2.21504205, grad/param norm = 2.6681e-01, time/batch = 0.6982s	
1071/30650 (epoch 1.747), train_loss = 2.28176352, grad/param norm = 2.5185e-01, time/batch = 0.7064s	
1072/30650 (epoch 1.749), train_loss = 2.21088505, grad/param norm = 2.3953e-01, time/batch = 0.7249s	
1073/30650 (epoch 1.750), train_loss = 2.10080887, grad/param norm = 2.3183e-01, time/batch = 0.7234s	
1074/30650 (epoch 1.752), train_loss = 2.08995013, grad/param norm = 2.5748e-01, time/batch = 0.6838s	
1075/30650 (epoch 1.754), train_loss = 2.09755845, grad/param norm = 2.9507e-01, time/batch = 0.6812s	
1076/30650 (epoch 1.755), train_loss = 2.22941801, grad/param norm = 3.3270e-01, time/batch = 0.6769s	
1077/30650 (epoch 1.757), train_loss = 2.16118539, grad/param norm = 2.3126e-01, time/batch = 0.6786s	
1078/30650 (epoch 1.759), train_loss = 2.31213451, grad/param norm = 2.9510e-01, time/batch = 0.6791s	
1079/30650 (epoch 1.760), train_loss = 2.24156768, grad/param norm = 3.7056e-01, time/batch = 0.6927s	
1080/30650 (epoch 1.762), train_loss = 2.13579987, grad/param norm = 2.9931e-01, time/batch = 0.6815s	
1081/30650 (epoch 1.763), train_loss = 2.13354844, grad/param norm = 2.6348e-01, time/batch = 0.6816s	
1082/30650 (epoch 1.765), train_loss = 2.11273339, grad/param norm = 2.6747e-01, time/batch = 0.6805s	
1083/30650 (epoch 1.767), train_loss = 1.99794344, grad/param norm = 2.3684e-01, time/batch = 0.6822s	
1084/30650 (epoch 1.768), train_loss = 2.17007480, grad/param norm = 2.5306e-01, time/batch = 0.6779s	
1085/30650 (epoch 1.770), train_loss = 2.23656290, grad/param norm = 2.5509e-01, time/batch = 0.6776s	
1086/30650 (epoch 1.772), train_loss = 2.25239300, grad/param norm = 2.2137e-01, time/batch = 0.6793s	
1087/30650 (epoch 1.773), train_loss = 2.26556351, grad/param norm = 2.4176e-01, time/batch = 0.6790s	
1088/30650 (epoch 1.775), train_loss = 2.30218520, grad/param norm = 2.7076e-01, time/batch = 0.7175s	
1089/30650 (epoch 1.777), train_loss = 2.03863570, grad/param norm = 2.7435e-01, time/batch = 0.6970s	
1090/30650 (epoch 1.778), train_loss = 2.15063571, grad/param norm = 2.6844e-01, time/batch = 0.6868s	
1091/30650 (epoch 1.780), train_loss = 2.19627736, grad/param norm = 3.1119e-01, time/batch = 0.7083s	
1092/30650 (epoch 1.781), train_loss = 2.35691234, grad/param norm = 2.9318e-01, time/batch = 0.7143s	
1093/30650 (epoch 1.783), train_loss = 2.38716430, grad/param norm = 2.8722e-01, time/batch = 0.7129s	
1094/30650 (epoch 1.785), train_loss = 2.25644018, grad/param norm = 3.3402e-01, time/batch = 0.7053s	
1095/30650 (epoch 1.786), train_loss = 2.08643342, grad/param norm = 2.9201e-01, time/batch = 0.7020s	
1096/30650 (epoch 1.788), train_loss = 2.25827126, grad/param norm = 2.7290e-01, time/batch = 0.6979s	
1097/30650 (epoch 1.790), train_loss = 2.08563729, grad/param norm = 2.4870e-01, time/batch = 0.6765s	
1098/30650 (epoch 1.791), train_loss = 2.09138933, grad/param norm = 2.3630e-01, time/batch = 0.7207s	
1099/30650 (epoch 1.793), train_loss = 2.35854268, grad/param norm = 2.2154e-01, time/batch = 0.6991s	
1100/30650 (epoch 1.794), train_loss = 2.26744097, grad/param norm = 2.9033e-01, time/batch = 0.6841s	
1101/30650 (epoch 1.796), train_loss = 2.18499494, grad/param norm = 2.5165e-01, time/batch = 0.6794s	
1102/30650 (epoch 1.798), train_loss = 1.98890015, grad/param norm = 2.7229e-01, time/batch = 0.6848s	
1103/30650 (epoch 1.799), train_loss = 2.28186750, grad/param norm = 3.9358e-01, time/batch = 0.6995s	
1104/30650 (epoch 1.801), train_loss = 2.09224504, grad/param norm = 2.3483e-01, time/batch = 0.6780s	
1105/30650 (epoch 1.803), train_loss = 2.27634082, grad/param norm = 2.4391e-01, time/batch = 0.6776s	
1106/30650 (epoch 1.804), train_loss = 2.16898390, grad/param norm = 2.4589e-01, time/batch = 0.6783s	
1107/30650 (epoch 1.806), train_loss = 2.14908025, grad/param norm = 2.5607e-01, time/batch = 0.6878s	
1108/30650 (epoch 1.808), train_loss = 2.12677831, grad/param norm = 2.7250e-01, time/batch = 0.6915s	
1109/30650 (epoch 1.809), train_loss = 1.90701483, grad/param norm = 2.8986e-01, time/batch = 0.6884s	
1110/30650 (epoch 1.811), train_loss = 2.21865067, grad/param norm = 2.8574e-01, time/batch = 0.6925s	
1111/30650 (epoch 1.812), train_loss = 2.30738497, grad/param norm = 3.3531e-01, time/batch = 0.6902s	
1112/30650 (epoch 1.814), train_loss = 2.19426601, grad/param norm = 2.5136e-01, time/batch = 0.7066s	
1113/30650 (epoch 1.816), train_loss = 2.33828799, grad/param norm = 2.5614e-01, time/batch = 0.7175s	
1114/30650 (epoch 1.817), train_loss = 2.20629395, grad/param norm = 2.3307e-01, time/batch = 0.6834s	
1115/30650 (epoch 1.819), train_loss = 2.07982414, grad/param norm = 2.6942e-01, time/batch = 0.6802s	
1116/30650 (epoch 1.821), train_loss = 2.07550889, grad/param norm = 3.0665e-01, time/batch = 0.6898s	
1117/30650 (epoch 1.822), train_loss = 2.15525139, grad/param norm = 3.0635e-01, time/batch = 0.7009s	
1118/30650 (epoch 1.824), train_loss = 1.93216148, grad/param norm = 2.6813e-01, time/batch = 0.6826s	
1119/30650 (epoch 1.825), train_loss = 2.23093078, grad/param norm = 3.1210e-01, time/batch = 0.6770s	
1120/30650 (epoch 1.827), train_loss = 2.07948211, grad/param norm = 2.9389e-01, time/batch = 0.6867s	
1121/30650 (epoch 1.829), train_loss = 2.22152979, grad/param norm = 3.0375e-01, time/batch = 0.6851s	
1122/30650 (epoch 1.830), train_loss = 2.07451836, grad/param norm = 2.7441e-01, time/batch = 0.6824s	
1123/30650 (epoch 1.832), train_loss = 2.08735043, grad/param norm = 2.6619e-01, time/batch = 0.6822s	
1124/30650 (epoch 1.834), train_loss = 2.26764186, grad/param norm = 2.5708e-01, time/batch = 0.6768s	
1125/30650 (epoch 1.835), train_loss = 2.20445732, grad/param norm = 2.8523e-01, time/batch = 0.6785s	
1126/30650 (epoch 1.837), train_loss = 2.28139954, grad/param norm = 2.4256e-01, time/batch = 0.6819s	
1127/30650 (epoch 1.838), train_loss = 2.07229746, grad/param norm = 2.7921e-01, time/batch = 0.7178s	
1128/30650 (epoch 1.840), train_loss = 2.13722804, grad/param norm = 2.6121e-01, time/batch = 0.6769s	
1129/30650 (epoch 1.842), train_loss = 2.03795075, grad/param norm = 2.7116e-01, time/batch = 0.6921s	
1130/30650 (epoch 1.843), train_loss = 2.17334082, grad/param norm = 2.2794e-01, time/batch = 0.6858s	
1131/30650 (epoch 1.845), train_loss = 2.23951636, grad/param norm = 2.8109e-01, time/batch = 0.6815s	
1132/30650 (epoch 1.847), train_loss = 2.25349840, grad/param norm = 2.6842e-01, time/batch = 0.6772s	
1133/30650 (epoch 1.848), train_loss = 2.13454499, grad/param norm = 2.4567e-01, time/batch = 0.6755s	
1134/30650 (epoch 1.850), train_loss = 2.17775468, grad/param norm = 2.5830e-01, time/batch = 0.6776s	
1135/30650 (epoch 1.852), train_loss = 2.40548948, grad/param norm = 3.1844e-01, time/batch = 0.6807s	
1136/30650 (epoch 1.853), train_loss = 2.13423637, grad/param norm = 2.7887e-01, time/batch = 0.6787s	
1137/30650 (epoch 1.855), train_loss = 2.29519294, grad/param norm = 3.0584e-01, time/batch = 0.6804s	
1138/30650 (epoch 1.856), train_loss = 2.22339824, grad/param norm = 2.2536e-01, time/batch = 0.6802s	
1139/30650 (epoch 1.858), train_loss = 2.16584167, grad/param norm = 2.7158e-01, time/batch = 0.6785s	
1140/30650 (epoch 1.860), train_loss = 2.06281871, grad/param norm = 2.6997e-01, time/batch = 0.6778s	
1141/30650 (epoch 1.861), train_loss = 2.12905224, grad/param norm = 2.3945e-01, time/batch = 0.7015s	
1142/30650 (epoch 1.863), train_loss = 2.13540501, grad/param norm = 2.3049e-01, time/batch = 0.7158s	
1143/30650 (epoch 1.865), train_loss = 2.38612922, grad/param norm = 2.6300e-01, time/batch = 0.6861s	
1144/30650 (epoch 1.866), train_loss = 2.15569319, grad/param norm = 2.6017e-01, time/batch = 0.6827s	
1145/30650 (epoch 1.868), train_loss = 2.12027718, grad/param norm = 2.2935e-01, time/batch = 0.6797s	
1146/30650 (epoch 1.869), train_loss = 2.29814457, grad/param norm = 2.2385e-01, time/batch = 0.6866s	
1147/30650 (epoch 1.871), train_loss = 2.11150262, grad/param norm = 2.6740e-01, time/batch = 0.7094s	
1148/30650 (epoch 1.873), train_loss = 2.15483822, grad/param norm = 2.6426e-01, time/batch = 0.7022s	
1149/30650 (epoch 1.874), train_loss = 2.05852504, grad/param norm = 2.4287e-01, time/batch = 0.6887s	
1150/30650 (epoch 1.876), train_loss = 1.85302992, grad/param norm = 2.5425e-01, time/batch = 0.6804s	
1151/30650 (epoch 1.878), train_loss = 1.91146156, grad/param norm = 2.6260e-01, time/batch = 0.6816s	
1152/30650 (epoch 1.879), train_loss = 2.20168628, grad/param norm = 2.9387e-01, time/batch = 0.6786s	
1153/30650 (epoch 1.881), train_loss = 2.28494074, grad/param norm = 3.1807e-01, time/batch = 0.6778s	
1154/30650 (epoch 1.883), train_loss = 2.07816904, grad/param norm = 2.3783e-01, time/batch = 0.6758s	
1155/30650 (epoch 1.884), train_loss = 1.95431830, grad/param norm = 2.9867e-01, time/batch = 0.6783s	
1156/30650 (epoch 1.886), train_loss = 1.93773607, grad/param norm = 3.2025e-01, time/batch = 0.7215s	
1157/30650 (epoch 1.887), train_loss = 2.11835550, grad/param norm = 2.4709e-01, time/batch = 0.6922s	
1158/30650 (epoch 1.889), train_loss = 1.98638781, grad/param norm = 2.2546e-01, time/batch = 0.6806s	
1159/30650 (epoch 1.891), train_loss = 2.27371203, grad/param norm = 2.7615e-01, time/batch = 0.6771s	
1160/30650 (epoch 1.892), train_loss = 2.21098537, grad/param norm = 2.4967e-01, time/batch = 0.6762s	
1161/30650 (epoch 1.894), train_loss = 2.07490380, grad/param norm = 2.6270e-01, time/batch = 0.6779s	
1162/30650 (epoch 1.896), train_loss = 2.04560632, grad/param norm = 2.5533e-01, time/batch = 0.6756s	
1163/30650 (epoch 1.897), train_loss = 2.11953095, grad/param norm = 3.0411e-01, time/batch = 0.6773s	
1164/30650 (epoch 1.899), train_loss = 1.87182286, grad/param norm = 2.9026e-01, time/batch = 0.6781s	
1165/30650 (epoch 1.900), train_loss = 2.34518018, grad/param norm = 2.6852e-01, time/batch = 0.6829s	
1166/30650 (epoch 1.902), train_loss = 2.25533926, grad/param norm = 3.3699e-01, time/batch = 0.6858s	
1167/30650 (epoch 1.904), train_loss = 2.03205371, grad/param norm = 2.7186e-01, time/batch = 0.6781s	
1168/30650 (epoch 1.905), train_loss = 2.23236093, grad/param norm = 2.5737e-01, time/batch = 0.6757s	
1169/30650 (epoch 1.907), train_loss = 2.26563240, grad/param norm = 3.1104e-01, time/batch = 0.6759s	
1170/30650 (epoch 1.909), train_loss = 2.14308130, grad/param norm = 3.4686e-01, time/batch = 0.6768s	
1171/30650 (epoch 1.910), train_loss = 1.90420797, grad/param norm = 2.4774e-01, time/batch = 0.6778s	
1172/30650 (epoch 1.912), train_loss = 2.02652057, grad/param norm = 2.2317e-01, time/batch = 0.6772s	
1173/30650 (epoch 1.914), train_loss = 2.03005141, grad/param norm = 2.3387e-01, time/batch = 0.6789s	
1174/30650 (epoch 1.915), train_loss = 2.12620895, grad/param norm = 2.7101e-01, time/batch = 0.6825s	
1175/30650 (epoch 1.917), train_loss = 2.22663129, grad/param norm = 2.6071e-01, time/batch = 0.7045s	
1176/30650 (epoch 1.918), train_loss = 2.08749292, grad/param norm = 2.3902e-01, time/batch = 0.6877s	
1177/30650 (epoch 1.920), train_loss = 2.15345767, grad/param norm = 2.9183e-01, time/batch = 0.6815s	
1178/30650 (epoch 1.922), train_loss = 2.00292274, grad/param norm = 2.6631e-01, time/batch = 0.6796s	
1179/30650 (epoch 1.923), train_loss = 2.29299526, grad/param norm = 2.6669e-01, time/batch = 0.6794s	
1180/30650 (epoch 1.925), train_loss = 2.12799630, grad/param norm = 2.4937e-01, time/batch = 0.6794s	
1181/30650 (epoch 1.927), train_loss = 2.33077101, grad/param norm = 3.0259e-01, time/batch = 0.6830s	
1182/30650 (epoch 1.928), train_loss = 2.06727673, grad/param norm = 3.5067e-01, time/batch = 0.6798s	
1183/30650 (epoch 1.930), train_loss = 2.21754308, grad/param norm = 2.5846e-01, time/batch = 0.6772s	
1184/30650 (epoch 1.931), train_loss = 2.09753312, grad/param norm = 2.5212e-01, time/batch = 0.6764s	
1185/30650 (epoch 1.933), train_loss = 2.14444013, grad/param norm = 2.8469e-01, time/batch = 0.6941s	
1186/30650 (epoch 1.935), train_loss = 2.18077504, grad/param norm = 2.6845e-01, time/batch = 0.6884s	
1187/30650 (epoch 1.936), train_loss = 2.11486796, grad/param norm = 2.6634e-01, time/batch = 0.6867s	
1188/30650 (epoch 1.938), train_loss = 2.18173877, grad/param norm = 2.6719e-01, time/batch = 0.6770s	
1189/30650 (epoch 1.940), train_loss = 2.38293359, grad/param norm = 2.7262e-01, time/batch = 0.6970s	
1190/30650 (epoch 1.941), train_loss = 2.14365952, grad/param norm = 2.2960e-01, time/batch = 0.7173s	
1191/30650 (epoch 1.943), train_loss = 2.02951001, grad/param norm = 2.3001e-01, time/batch = 0.6773s	
1192/30650 (epoch 1.945), train_loss = 2.26210583, grad/param norm = 2.3467e-01, time/batch = 0.6803s	
1193/30650 (epoch 1.946), train_loss = 2.05078927, grad/param norm = 2.2325e-01, time/batch = 0.6873s	
1194/30650 (epoch 1.948), train_loss = 2.14386852, grad/param norm = 2.3921e-01, time/batch = 0.7079s	
1195/30650 (epoch 1.949), train_loss = 2.23159228, grad/param norm = 2.4091e-01, time/batch = 0.6978s	
1196/30650 (epoch 1.951), train_loss = 2.06853245, grad/param norm = 2.2040e-01, time/batch = 0.6904s	
1197/30650 (epoch 1.953), train_loss = 1.94789819, grad/param norm = 2.2558e-01, time/batch = 0.6932s	
1198/30650 (epoch 1.954), train_loss = 1.94809363, grad/param norm = 2.2302e-01, time/batch = 0.6820s	
1199/30650 (epoch 1.956), train_loss = 2.15288293, grad/param norm = 2.6528e-01, time/batch = 0.6819s	
1200/30650 (epoch 1.958), train_loss = 2.02926175, grad/param norm = 2.4749e-01, time/batch = 0.6773s	
1201/30650 (epoch 1.959), train_loss = 2.03532303, grad/param norm = 2.3677e-01, time/batch = 0.6799s	
1202/30650 (epoch 1.961), train_loss = 2.17176744, grad/param norm = 2.8315e-01, time/batch = 0.6786s	
1203/30650 (epoch 1.962), train_loss = 2.15981096, grad/param norm = 2.4546e-01, time/batch = 0.6809s	
1204/30650 (epoch 1.964), train_loss = 2.10992576, grad/param norm = 2.4272e-01, time/batch = 0.7196s	
1205/30650 (epoch 1.966), train_loss = 1.94242832, grad/param norm = 2.3097e-01, time/batch = 0.6952s	
1206/30650 (epoch 1.967), train_loss = 2.05884402, grad/param norm = 2.4640e-01, time/batch = 0.6950s	
1207/30650 (epoch 1.969), train_loss = 2.03229219, grad/param norm = 2.3740e-01, time/batch = 0.6793s	
1208/30650 (epoch 1.971), train_loss = 1.90155261, grad/param norm = 2.3940e-01, time/batch = 0.6773s	
1209/30650 (epoch 1.972), train_loss = 2.14917121, grad/param norm = 2.3530e-01, time/batch = 0.6969s	
1210/30650 (epoch 1.974), train_loss = 2.17910957, grad/param norm = 3.0176e-01, time/batch = 0.6924s	
1211/30650 (epoch 1.976), train_loss = 2.19814427, grad/param norm = 2.8839e-01, time/batch = 0.6854s	
1212/30650 (epoch 1.977), train_loss = 2.22660412, grad/param norm = 2.5473e-01, time/batch = 0.6795s	
1213/30650 (epoch 1.979), train_loss = 2.18477028, grad/param norm = 2.5039e-01, time/batch = 0.6950s	
1214/30650 (epoch 1.980), train_loss = 2.10787780, grad/param norm = 2.8510e-01, time/batch = 0.6766s	
1215/30650 (epoch 1.982), train_loss = 2.18514126, grad/param norm = 2.2397e-01, time/batch = 0.6760s	
1216/30650 (epoch 1.984), train_loss = 2.20124286, grad/param norm = 2.7606e-01, time/batch = 0.6781s	
1217/30650 (epoch 1.985), train_loss = 2.15726182, grad/param norm = 2.5836e-01, time/batch = 0.6772s	
1218/30650 (epoch 1.987), train_loss = 2.10369240, grad/param norm = 2.1810e-01, time/batch = 0.7002s	
1219/30650 (epoch 1.989), train_loss = 2.16524986, grad/param norm = 2.3562e-01, time/batch = 0.7152s	
1220/30650 (epoch 1.990), train_loss = 1.98213536, grad/param norm = 2.5099e-01, time/batch = 0.6756s	
1221/30650 (epoch 1.992), train_loss = 2.21353091, grad/param norm = 2.4631e-01, time/batch = 0.6792s	
1222/30650 (epoch 1.993), train_loss = 2.12885012, grad/param norm = 2.2509e-01, time/batch = 0.6832s	
1223/30650 (epoch 1.995), train_loss = 2.10035030, grad/param norm = 2.3146e-01, time/batch = 0.6832s	
1224/30650 (epoch 1.997), train_loss = 2.25244331, grad/param norm = 2.8767e-01, time/batch = 0.6776s	
1225/30650 (epoch 1.998), train_loss = 2.00456941, grad/param norm = 2.2192e-01, time/batch = 0.6842s	
1226/30650 (epoch 2.000), train_loss = 2.31602278, grad/param norm = 2.7207e-01, time/batch = 0.6772s	
1227/30650 (epoch 2.002), train_loss = 2.15311597, grad/param norm = 2.8227e-01, time/batch = 0.6773s	
1228/30650 (epoch 2.003), train_loss = 2.12106245, grad/param norm = 2.5979e-01, time/batch = 0.6766s	
1229/30650 (epoch 2.005), train_loss = 2.20121400, grad/param norm = 2.3012e-01, time/batch = 0.6806s	
1230/30650 (epoch 2.007), train_loss = 2.30458700, grad/param norm = 2.2115e-01, time/batch = 0.6778s	
1231/30650 (epoch 2.008), train_loss = 1.91364450, grad/param norm = 2.4124e-01, time/batch = 0.6807s	
1232/30650 (epoch 2.010), train_loss = 2.03847406, grad/param norm = 2.2794e-01, time/batch = 0.6780s	
1233/30650 (epoch 2.011), train_loss = 2.12311332, grad/param norm = 2.3865e-01, time/batch = 0.7202s	
1234/30650 (epoch 2.013), train_loss = 2.08117824, grad/param norm = 2.5640e-01, time/batch = 0.6944s	
1235/30650 (epoch 2.015), train_loss = 2.17964120, grad/param norm = 2.6704e-01, time/batch = 0.6775s	
1236/30650 (epoch 2.016), train_loss = 2.22534571, grad/param norm = 2.5231e-01, time/batch = 0.6791s	
1237/30650 (epoch 2.018), train_loss = 2.27321694, grad/param norm = 2.7659e-01, time/batch = 0.6778s	
1238/30650 (epoch 2.020), train_loss = 2.20547935, grad/param norm = 2.3108e-01, time/batch = 0.6827s	
1239/30650 (epoch 2.021), train_loss = 2.11106752, grad/param norm = 2.3654e-01, time/batch = 0.6786s	
1240/30650 (epoch 2.023), train_loss = 2.17063167, grad/param norm = 2.4250e-01, time/batch = 0.6771s	
1241/30650 (epoch 2.024), train_loss = 2.26278388, grad/param norm = 2.9266e-01, time/batch = 0.6776s	
1242/30650 (epoch 2.026), train_loss = 2.08404510, grad/param norm = 2.0974e-01, time/batch = 0.6808s	
1243/30650 (epoch 2.028), train_loss = 1.96089369, grad/param norm = 2.1203e-01, time/batch = 0.6844s	
1244/30650 (epoch 2.029), train_loss = 2.25069388, grad/param norm = 2.4927e-01, time/batch = 0.6762s	
1245/30650 (epoch 2.031), train_loss = 2.37737402, grad/param norm = 2.4174e-01, time/batch = 0.6791s	
1246/30650 (epoch 2.033), train_loss = 2.07352977, grad/param norm = 1.9163e-01, time/batch = 0.6765s	
1247/30650 (epoch 2.034), train_loss = 2.09970074, grad/param norm = 2.2559e-01, time/batch = 0.6961s	
1248/30650 (epoch 2.036), train_loss = 1.93922433, grad/param norm = 2.1451e-01, time/batch = 0.7204s	
1249/30650 (epoch 2.038), train_loss = 2.34484910, grad/param norm = 2.4069e-01, time/batch = 0.6744s	
1250/30650 (epoch 2.039), train_loss = 2.06679353, grad/param norm = 2.6386e-01, time/batch = 0.6752s	
1251/30650 (epoch 2.041), train_loss = 2.21072744, grad/param norm = 2.6876e-01, time/batch = 0.6812s	
1252/30650 (epoch 2.042), train_loss = 2.11562128, grad/param norm = 2.6122e-01, time/batch = 0.6820s	
1253/30650 (epoch 2.044), train_loss = 2.02527209, grad/param norm = 2.5641e-01, time/batch = 0.6792s	
1254/30650 (epoch 2.046), train_loss = 2.03364629, grad/param norm = 2.5985e-01, time/batch = 0.6791s	
1255/30650 (epoch 2.047), train_loss = 2.00916647, grad/param norm = 2.4565e-01, time/batch = 0.6763s	
1256/30650 (epoch 2.049), train_loss = 2.00323749, grad/param norm = 2.5155e-01, time/batch = 0.6758s	
1257/30650 (epoch 2.051), train_loss = 2.29852349, grad/param norm = 2.4616e-01, time/batch = 0.6777s	
1258/30650 (epoch 2.052), train_loss = 2.03412068, grad/param norm = 2.7109e-01, time/batch = 0.6773s	
1259/30650 (epoch 2.054), train_loss = 2.21434304, grad/param norm = 3.1265e-01, time/batch = 0.6758s	
1260/30650 (epoch 2.055), train_loss = 2.05594600, grad/param norm = 2.8310e-01, time/batch = 0.6820s	
1261/30650 (epoch 2.057), train_loss = 1.98229565, grad/param norm = 2.7296e-01, time/batch = 0.6769s	
1262/30650 (epoch 2.059), train_loss = 2.14368019, grad/param norm = 2.4023e-01, time/batch = 0.7131s	
1263/30650 (epoch 2.060), train_loss = 2.16521533, grad/param norm = 2.6458e-01, time/batch = 0.7030s	
1264/30650 (epoch 2.062), train_loss = 2.43832656, grad/param norm = 2.5866e-01, time/batch = 0.6769s	
1265/30650 (epoch 2.064), train_loss = 2.25979325, grad/param norm = 2.6538e-01, time/batch = 0.6784s	
1266/30650 (epoch 2.065), train_loss = 2.12024686, grad/param norm = 2.3273e-01, time/batch = 0.6779s	
1267/30650 (epoch 2.067), train_loss = 2.23882386, grad/param norm = 2.2645e-01, time/batch = 0.6984s	
1268/30650 (epoch 2.069), train_loss = 2.19714368, grad/param norm = 2.1757e-01, time/batch = 0.6785s	
1269/30650 (epoch 2.070), train_loss = 2.04804749, grad/param norm = 2.2764e-01, time/batch = 0.6786s	
1270/30650 (epoch 2.072), train_loss = 2.11498320, grad/param norm = 2.5755e-01, time/batch = 0.6769s	
1271/30650 (epoch 2.073), train_loss = 1.84710170, grad/param norm = 2.6806e-01, time/batch = 0.6802s	
1272/30650 (epoch 2.075), train_loss = 2.10926755, grad/param norm = 2.4001e-01, time/batch = 0.6784s	
1273/30650 (epoch 2.077), train_loss = 1.96776584, grad/param norm = 2.3005e-01, time/batch = 0.6786s	
1274/30650 (epoch 2.078), train_loss = 2.25281371, grad/param norm = 2.3322e-01, time/batch = 0.6784s	
1275/30650 (epoch 2.080), train_loss = 2.29969829, grad/param norm = 2.4940e-01, time/batch = 0.6794s	
1276/30650 (epoch 2.082), train_loss = 2.11647004, grad/param norm = 2.4935e-01, time/batch = 0.6887s	
1277/30650 (epoch 2.083), train_loss = 2.01279529, grad/param norm = 2.3702e-01, time/batch = 0.7213s	
1278/30650 (epoch 2.085), train_loss = 2.20636660, grad/param norm = 2.4422e-01, time/batch = 0.6851s	
1279/30650 (epoch 2.086), train_loss = 2.01876911, grad/param norm = 2.4934e-01, time/batch = 0.6779s	
1280/30650 (epoch 2.088), train_loss = 2.15857685, grad/param norm = 2.6981e-01, time/batch = 0.6804s	
1281/30650 (epoch 2.090), train_loss = 2.01694326, grad/param norm = 2.7166e-01, time/batch = 0.6827s	
1282/30650 (epoch 2.091), train_loss = 2.03657811, grad/param norm = 2.3054e-01, time/batch = 0.7009s	
1283/30650 (epoch 2.093), train_loss = 2.09091065, grad/param norm = 2.1983e-01, time/batch = 0.7054s	
1284/30650 (epoch 2.095), train_loss = 1.99934542, grad/param norm = 2.2602e-01, time/batch = 0.7026s	
1285/30650 (epoch 2.096), train_loss = 1.90734785, grad/param norm = 2.4446e-01, time/batch = 0.6787s	
1286/30650 (epoch 2.098), train_loss = 2.09618176, grad/param norm = 2.0856e-01, time/batch = 0.6814s	
1287/30650 (epoch 2.100), train_loss = 2.14859969, grad/param norm = 2.5534e-01, time/batch = 0.6743s	
1288/30650 (epoch 2.101), train_loss = 2.06137516, grad/param norm = 2.4895e-01, time/batch = 0.6730s	
1289/30650 (epoch 2.103), train_loss = 2.24563324, grad/param norm = 2.2597e-01, time/batch = 0.6818s	
1290/30650 (epoch 2.104), train_loss = 1.94802237, grad/param norm = 2.0507e-01, time/batch = 0.6805s	
1291/30650 (epoch 2.106), train_loss = 2.12786218, grad/param norm = 2.5020e-01, time/batch = 0.6911s	
1292/30650 (epoch 2.108), train_loss = 2.38491051, grad/param norm = 3.5483e-01, time/batch = 0.6932s	
1293/30650 (epoch 2.109), train_loss = 1.95564368, grad/param norm = 2.9450e-01, time/batch = 0.6876s	
1294/30650 (epoch 2.111), train_loss = 2.05366410, grad/param norm = 2.6300e-01, time/batch = 0.6767s	
1295/30650 (epoch 2.113), train_loss = 1.99184881, grad/param norm = 2.4792e-01, time/batch = 0.6764s	
1296/30650 (epoch 2.114), train_loss = 2.04777756, grad/param norm = 2.0835e-01, time/batch = 0.6747s	
1297/30650 (epoch 2.116), train_loss = 2.20105060, grad/param norm = 2.3319e-01, time/batch = 0.6844s	
1298/30650 (epoch 2.117), train_loss = 2.14682939, grad/param norm = 2.2390e-01, time/batch = 0.6776s	
1299/30650 (epoch 2.119), train_loss = 2.16491491, grad/param norm = 2.6137e-01, time/batch = 0.6777s	
1300/30650 (epoch 2.121), train_loss = 2.36963888, grad/param norm = 2.4177e-01, time/batch = 0.6774s	
1301/30650 (epoch 2.122), train_loss = 2.16491546, grad/param norm = 2.7415e-01, time/batch = 0.6779s	
1302/30650 (epoch 2.124), train_loss = 2.15861809, grad/param norm = 2.7362e-01, time/batch = 0.6765s	
1303/30650 (epoch 2.126), train_loss = 2.06363634, grad/param norm = 2.5089e-01, time/batch = 0.6773s	
1304/30650 (epoch 2.127), train_loss = 2.21640358, grad/param norm = 2.8081e-01, time/batch = 0.6771s	
1305/30650 (epoch 2.129), train_loss = 2.10370042, grad/param norm = 2.3089e-01, time/batch = 0.6766s	
1306/30650 (epoch 2.131), train_loss = 2.48062042, grad/param norm = 2.5610e-01, time/batch = 0.6864s	
1307/30650 (epoch 2.132), train_loss = 2.12205593, grad/param norm = 2.5016e-01, time/batch = 0.6935s	
1308/30650 (epoch 2.134), train_loss = 1.87444015, grad/param norm = 2.2707e-01, time/batch = 0.6876s	
1309/30650 (epoch 2.135), train_loss = 2.04800263, grad/param norm = 2.1915e-01, time/batch = 0.6877s	
1310/30650 (epoch 2.137), train_loss = 2.17472889, grad/param norm = 2.4865e-01, time/batch = 0.6908s	
1311/30650 (epoch 2.139), train_loss = 1.94264606, grad/param norm = 2.3638e-01, time/batch = 0.7038s	
1312/30650 (epoch 2.140), train_loss = 2.07773735, grad/param norm = 2.2490e-01, time/batch = 0.6881s	
1313/30650 (epoch 2.142), train_loss = 1.95911794, grad/param norm = 2.1788e-01, time/batch = 0.6832s	
1314/30650 (epoch 2.144), train_loss = 1.82962073, grad/param norm = 2.8635e-01, time/batch = 0.6876s	
1315/30650 (epoch 2.145), train_loss = 1.94017182, grad/param norm = 2.2690e-01, time/batch = 0.6811s	
1316/30650 (epoch 2.147), train_loss = 2.03020395, grad/param norm = 2.4748e-01, time/batch = 0.6767s	
1317/30650 (epoch 2.148), train_loss = 1.93601642, grad/param norm = 2.4024e-01, time/batch = 0.6752s	
1318/30650 (epoch 2.150), train_loss = 2.05100548, grad/param norm = 2.4359e-01, time/batch = 0.6786s	
1319/30650 (epoch 2.152), train_loss = 1.97812813, grad/param norm = 2.2481e-01, time/batch = 0.6774s	
1320/30650 (epoch 2.153), train_loss = 2.08331196, grad/param norm = 2.3022e-01, time/batch = 0.7018s	
1321/30650 (epoch 2.155), train_loss = 2.12927455, grad/param norm = 2.1467e-01, time/batch = 0.7131s	
1322/30650 (epoch 2.157), train_loss = 2.04959079, grad/param norm = 2.3863e-01, time/batch = 0.6812s	
1323/30650 (epoch 2.158), train_loss = 1.85259200, grad/param norm = 2.1820e-01, time/batch = 0.6774s	
1324/30650 (epoch 2.160), train_loss = 1.98192598, grad/param norm = 2.1092e-01, time/batch = 0.6786s	
1325/30650 (epoch 2.162), train_loss = 2.05556697, grad/param norm = 2.6199e-01, time/batch = 0.6820s	
1326/30650 (epoch 2.163), train_loss = 2.04229689, grad/param norm = 2.4332e-01, time/batch = 0.6874s	
1327/30650 (epoch 2.165), train_loss = 2.26139479, grad/param norm = 2.7984e-01, time/batch = 0.6791s	
1328/30650 (epoch 2.166), train_loss = 2.20940069, grad/param norm = 2.2718e-01, time/batch = 0.6784s	
1329/30650 (epoch 2.168), train_loss = 2.12578430, grad/param norm = 2.8024e-01, time/batch = 0.6755s	
1330/30650 (epoch 2.170), train_loss = 1.78919578, grad/param norm = 2.3094e-01, time/batch = 0.6764s	
1331/30650 (epoch 2.171), train_loss = 2.05014181, grad/param norm = 2.3146e-01, time/batch = 0.6843s	
1332/30650 (epoch 2.173), train_loss = 1.95279628, grad/param norm = 2.2866e-01, time/batch = 0.6816s	
1333/30650 (epoch 2.175), train_loss = 2.20663104, grad/param norm = 2.3890e-01, time/batch = 0.6827s	
1334/30650 (epoch 2.176), train_loss = 2.12421232, grad/param norm = 2.4556e-01, time/batch = 0.6804s	
1335/30650 (epoch 2.178), train_loss = 2.16787188, grad/param norm = 2.7472e-01, time/batch = 0.7213s	
1336/30650 (epoch 2.179), train_loss = 2.28706495, grad/param norm = 2.2290e-01, time/batch = 0.6943s	
1337/30650 (epoch 2.181), train_loss = 2.28873982, grad/param norm = 2.7906e-01, time/batch = 0.6872s	
1338/30650 (epoch 2.183), train_loss = 2.08827124, grad/param norm = 2.5670e-01, time/batch = 0.6781s	
1339/30650 (epoch 2.184), train_loss = 1.97641234, grad/param norm = 2.4444e-01, time/batch = 0.6783s	
1340/30650 (epoch 2.186), train_loss = 2.10422775, grad/param norm = 2.4648e-01, time/batch = 0.6842s	
1341/30650 (epoch 2.188), train_loss = 1.98656486, grad/param norm = 2.2969e-01, time/batch = 0.6823s	
1342/30650 (epoch 2.189), train_loss = 2.00463594, grad/param norm = 2.5001e-01, time/batch = 0.6766s	
1343/30650 (epoch 2.191), train_loss = 2.09424237, grad/param norm = 2.2747e-01, time/batch = 0.6748s	
1344/30650 (epoch 2.192), train_loss = 2.00569712, grad/param norm = 2.0945e-01, time/batch = 0.6771s	
1345/30650 (epoch 2.194), train_loss = 2.04434949, grad/param norm = 2.4111e-01, time/batch = 0.6750s	
1346/30650 (epoch 2.196), train_loss = 2.07186823, grad/param norm = 2.6629e-01, time/batch = 0.6758s	
1347/30650 (epoch 2.197), train_loss = 2.07371999, grad/param norm = 2.8561e-01, time/batch = 0.6752s	
1348/30650 (epoch 2.199), train_loss = 1.98987366, grad/param norm = 2.6909e-01, time/batch = 0.6772s	
1349/30650 (epoch 2.201), train_loss = 2.01658490, grad/param norm = 2.4499e-01, time/batch = 0.6970s	
1350/30650 (epoch 2.202), train_loss = 1.98395926, grad/param norm = 2.3981e-01, time/batch = 0.7181s	
1351/30650 (epoch 2.204), train_loss = 1.96843210, grad/param norm = 2.4258e-01, time/batch = 0.6771s	
1352/30650 (epoch 2.206), train_loss = 1.99061866, grad/param norm = 2.3110e-01, time/batch = 0.6780s	
1353/30650 (epoch 2.207), train_loss = 2.11173345, grad/param norm = 2.2093e-01, time/batch = 0.6779s	
1354/30650 (epoch 2.209), train_loss = 1.89265179, grad/param norm = 2.0321e-01, time/batch = 0.6798s	
1355/30650 (epoch 2.210), train_loss = 1.93981206, grad/param norm = 2.3801e-01, time/batch = 0.6791s	
1356/30650 (epoch 2.212), train_loss = 2.21141396, grad/param norm = 2.5558e-01, time/batch = 0.6750s	
1357/30650 (epoch 2.214), train_loss = 2.24881961, grad/param norm = 2.3939e-01, time/batch = 0.6745s	
1358/30650 (epoch 2.215), train_loss = 2.05451820, grad/param norm = 2.2152e-01, time/batch = 0.6747s	
1359/30650 (epoch 2.217), train_loss = 1.99105101, grad/param norm = 2.4692e-01, time/batch = 0.6775s	
1360/30650 (epoch 2.219), train_loss = 2.10976214, grad/param norm = 2.3879e-01, time/batch = 0.6767s	
1361/30650 (epoch 2.220), train_loss = 2.04874615, grad/param norm = 2.2989e-01, time/batch = 0.6772s	
1362/30650 (epoch 2.222), train_loss = 1.94214885, grad/param norm = 2.5842e-01, time/batch = 0.6792s	
1363/30650 (epoch 2.223), train_loss = 2.06888639, grad/param norm = 2.5415e-01, time/batch = 0.6769s	
1364/30650 (epoch 2.225), train_loss = 2.01599280, grad/param norm = 2.2474e-01, time/batch = 0.6785s	
1365/30650 (epoch 2.227), train_loss = 2.19580867, grad/param norm = 2.2973e-01, time/batch = 0.6766s	
1366/30650 (epoch 2.228), train_loss = 2.15106102, grad/param norm = 2.2812e-01, time/batch = 0.6770s	
1367/30650 (epoch 2.230), train_loss = 2.04614338, grad/param norm = 2.3265e-01, time/batch = 0.6773s	
1368/30650 (epoch 2.232), train_loss = 2.07434298, grad/param norm = 2.5929e-01, time/batch = 0.6963s	
1369/30650 (epoch 2.233), train_loss = 2.14784816, grad/param norm = 2.5766e-01, time/batch = 0.7246s	
1370/30650 (epoch 2.235), train_loss = 2.13495303, grad/param norm = 2.2919e-01, time/batch = 0.6870s	
1371/30650 (epoch 2.237), train_loss = 2.19020359, grad/param norm = 2.1907e-01, time/batch = 0.6906s	
1372/30650 (epoch 2.238), train_loss = 2.35522105, grad/param norm = 2.3726e-01, time/batch = 0.7063s	
1373/30650 (epoch 2.240), train_loss = 2.15040464, grad/param norm = 2.4565e-01, time/batch = 0.6825s	
1374/30650 (epoch 2.241), train_loss = 2.07686882, grad/param norm = 2.1896e-01, time/batch = 0.6778s	
1375/30650 (epoch 2.243), train_loss = 2.26021192, grad/param norm = 2.5451e-01, time/batch = 0.6833s	
1376/30650 (epoch 2.245), train_loss = 2.15140364, grad/param norm = 2.4333e-01, time/batch = 0.6793s	
1377/30650 (epoch 2.246), train_loss = 2.01377487, grad/param norm = 2.3041e-01, time/batch = 0.6820s	
1378/30650 (epoch 2.248), train_loss = 2.15171638, grad/param norm = 2.5153e-01, time/batch = 0.6931s	
1379/30650 (epoch 2.250), train_loss = 2.12756036, grad/param norm = 2.2904e-01, time/batch = 0.7213s	
1380/30650 (epoch 2.251), train_loss = 2.05296098, grad/param norm = 2.5283e-01, time/batch = 0.6776s	
1381/30650 (epoch 2.253), train_loss = 2.10777843, grad/param norm = 2.8944e-01, time/batch = 0.6842s	
1382/30650 (epoch 2.254), train_loss = 2.10308020, grad/param norm = 2.7826e-01, time/batch = 0.6803s	
1383/30650 (epoch 2.256), train_loss = 1.99918785, grad/param norm = 2.5806e-01, time/batch = 0.6911s	
1384/30650 (epoch 2.258), train_loss = 2.08923813, grad/param norm = 2.4152e-01, time/batch = 0.6891s	
1385/30650 (epoch 2.259), train_loss = 2.00364179, grad/param norm = 2.1737e-01, time/batch = 0.6851s	
1386/30650 (epoch 2.261), train_loss = 2.03762223, grad/param norm = 2.0750e-01, time/batch = 0.6806s	
1387/30650 (epoch 2.263), train_loss = 1.96847434, grad/param norm = 2.2385e-01, time/batch = 0.6807s	
1388/30650 (epoch 2.264), train_loss = 2.10315933, grad/param norm = 2.1595e-01, time/batch = 0.6797s	
1389/30650 (epoch 2.266), train_loss = 2.00494660, grad/param norm = 2.3377e-01, time/batch = 0.6788s	
1390/30650 (epoch 2.268), train_loss = 1.94043887, grad/param norm = 2.6134e-01, time/batch = 0.6803s	
1391/30650 (epoch 2.269), train_loss = 1.97326972, grad/param norm = 2.4854e-01, time/batch = 0.6798s	
1392/30650 (epoch 2.271), train_loss = 1.98155262, grad/param norm = 2.2195e-01, time/batch = 0.6779s	
1393/30650 (epoch 2.272), train_loss = 1.92881228, grad/param norm = 2.4968e-01, time/batch = 0.7152s	
1394/30650 (epoch 2.274), train_loss = 1.88623084, grad/param norm = 2.2240e-01, time/batch = 0.7011s	
1395/30650 (epoch 2.276), train_loss = 1.87763094, grad/param norm = 2.2988e-01, time/batch = 0.6771s	
1396/30650 (epoch 2.277), train_loss = 1.94573775, grad/param norm = 2.1586e-01, time/batch = 0.6777s	
1397/30650 (epoch 2.279), train_loss = 2.06255360, grad/param norm = 2.6231e-01, time/batch = 0.6775s	
1398/30650 (epoch 2.281), train_loss = 2.13911842, grad/param norm = 2.3555e-01, time/batch = 0.6781s	
1399/30650 (epoch 2.282), train_loss = 1.93615714, grad/param norm = 2.3907e-01, time/batch = 0.6825s	
1400/30650 (epoch 2.284), train_loss = 2.21018789, grad/param norm = 2.6925e-01, time/batch = 0.6869s	
1401/30650 (epoch 2.285), train_loss = 1.96356265, grad/param norm = 3.3628e-01, time/batch = 0.6821s	
1402/30650 (epoch 2.287), train_loss = 2.12783274, grad/param norm = 2.3033e-01, time/batch = 0.6769s	
1403/30650 (epoch 2.289), train_loss = 2.12082095, grad/param norm = 2.6202e-01, time/batch = 0.6768s	
1404/30650 (epoch 2.290), train_loss = 2.13962092, grad/param norm = 2.6565e-01, time/batch = 0.6753s	
1405/30650 (epoch 2.292), train_loss = 2.14471770, grad/param norm = 2.2274e-01, time/batch = 0.6757s	
1406/30650 (epoch 2.294), train_loss = 1.88448461, grad/param norm = 2.5403e-01, time/batch = 0.6766s	
1407/30650 (epoch 2.295), train_loss = 1.95907330, grad/param norm = 2.1944e-01, time/batch = 0.6764s	
1408/30650 (epoch 2.297), train_loss = 1.86476825, grad/param norm = 2.1997e-01, time/batch = 0.6763s	
1409/30650 (epoch 2.299), train_loss = 1.88069067, grad/param norm = 2.2784e-01, time/batch = 0.6759s	
1410/30650 (epoch 2.300), train_loss = 1.96436688, grad/param norm = 2.3916e-01, time/batch = 0.6748s	
1411/30650 (epoch 2.302), train_loss = 1.98193611, grad/param norm = 2.2062e-01, time/batch = 0.6781s	
1412/30650 (epoch 2.303), train_loss = 1.91002744, grad/param norm = 2.2814e-01, time/batch = 0.7156s	
1413/30650 (epoch 2.305), train_loss = 2.12461987, grad/param norm = 2.4400e-01, time/batch = 0.7061s	
1414/30650 (epoch 2.307), train_loss = 2.01144087, grad/param norm = 2.3458e-01, time/batch = 0.6787s	
1415/30650 (epoch 2.308), train_loss = 1.96792410, grad/param norm = 2.5088e-01, time/batch = 0.6833s	
1416/30650 (epoch 2.310), train_loss = 2.10294242, grad/param norm = 2.7401e-01, time/batch = 0.6801s	
1417/30650 (epoch 2.312), train_loss = 2.08353099, grad/param norm = 2.4198e-01, time/batch = 0.6776s	
1418/30650 (epoch 2.313), train_loss = 2.19828149, grad/param norm = 2.3584e-01, time/batch = 0.6758s	
1419/30650 (epoch 2.315), train_loss = 2.11720972, grad/param norm = 2.3529e-01, time/batch = 0.6778s	
1420/30650 (epoch 2.316), train_loss = 2.03858189, grad/param norm = 2.1222e-01, time/batch = 0.6802s	
1421/30650 (epoch 2.318), train_loss = 2.16958706, grad/param norm = 2.4611e-01, time/batch = 0.6779s	
1422/30650 (epoch 2.320), train_loss = 2.07895605, grad/param norm = 2.4301e-01, time/batch = 0.7107s	
1423/30650 (epoch 2.321), train_loss = 2.15806712, grad/param norm = 2.4440e-01, time/batch = 0.7078s	
1424/30650 (epoch 2.323), train_loss = 1.88337500, grad/param norm = 2.5846e-01, time/batch = 0.6768s	
1425/30650 (epoch 2.325), train_loss = 2.09013503, grad/param norm = 2.5203e-01, time/batch = 0.6779s	
1426/30650 (epoch 2.326), train_loss = 1.97872812, grad/param norm = 2.5694e-01, time/batch = 0.6778s	
1427/30650 (epoch 2.328), train_loss = 1.89399943, grad/param norm = 2.3942e-01, time/batch = 0.6836s	
1428/30650 (epoch 2.330), train_loss = 2.11280045, grad/param norm = 2.1589e-01, time/batch = 0.6834s	
1429/30650 (epoch 2.331), train_loss = 2.19456990, grad/param norm = 2.5891e-01, time/batch = 0.6811s	
1430/30650 (epoch 2.333), train_loss = 2.10089831, grad/param norm = 2.2462e-01, time/batch = 0.6757s	
1431/30650 (epoch 2.334), train_loss = 2.14402814, grad/param norm = 2.3140e-01, time/batch = 0.6841s	
1432/30650 (epoch 2.336), train_loss = 1.98931743, grad/param norm = 2.3231e-01, time/batch = 0.6759s	
1433/30650 (epoch 2.338), train_loss = 2.37151770, grad/param norm = 2.6281e-01, time/batch = 0.6762s	
1434/30650 (epoch 2.339), train_loss = 2.33341659, grad/param norm = 2.2673e-01, time/batch = 0.6748s	
1435/30650 (epoch 2.341), train_loss = 2.11413219, grad/param norm = 2.4702e-01, time/batch = 0.6833s	
1436/30650 (epoch 2.343), train_loss = 1.99114782, grad/param norm = 2.5239e-01, time/batch = 0.6823s	
1437/30650 (epoch 2.344), train_loss = 2.14138683, grad/param norm = 2.6046e-01, time/batch = 0.7217s	
1438/30650 (epoch 2.346), train_loss = 2.22042333, grad/param norm = 2.2439e-01, time/batch = 0.6904s	
1439/30650 (epoch 2.347), train_loss = 2.04529105, grad/param norm = 2.2877e-01, time/batch = 0.6826s	
1440/30650 (epoch 2.349), train_loss = 1.98281461, grad/param norm = 2.2378e-01, time/batch = 0.6775s	
1441/30650 (epoch 2.351), train_loss = 1.99192706, grad/param norm = 2.3297e-01, time/batch = 0.6779s	
1442/30650 (epoch 2.352), train_loss = 2.16074103, grad/param norm = 2.5373e-01, time/batch = 0.6854s	
1443/30650 (epoch 2.354), train_loss = 1.93073004, grad/param norm = 2.6174e-01, time/batch = 0.6773s	
1444/30650 (epoch 2.356), train_loss = 1.93323888, grad/param norm = 2.9368e-01, time/batch = 0.6802s	
1445/30650 (epoch 2.357), train_loss = 2.04832422, grad/param norm = 3.0443e-01, time/batch = 0.6766s	
1446/30650 (epoch 2.359), train_loss = 2.03524645, grad/param norm = 2.4500e-01, time/batch = 0.6772s	
1447/30650 (epoch 2.361), train_loss = 2.15143011, grad/param norm = 2.4211e-01, time/batch = 0.6769s	
1448/30650 (epoch 2.362), train_loss = 2.03770271, grad/param norm = 2.3336e-01, time/batch = 0.6789s	
1449/30650 (epoch 2.364), train_loss = 2.02748748, grad/param norm = 2.5442e-01, time/batch = 0.6774s	
1450/30650 (epoch 2.365), train_loss = 2.16458226, grad/param norm = 2.4449e-01, time/batch = 0.6786s	
1451/30650 (epoch 2.367), train_loss = 2.05477844, grad/param norm = 2.2344e-01, time/batch = 0.6802s	
1452/30650 (epoch 2.369), train_loss = 1.94873977, grad/param norm = 2.2810e-01, time/batch = 0.6818s	
1453/30650 (epoch 2.370), train_loss = 2.13609428, grad/param norm = 2.3076e-01, time/batch = 0.6796s	
1454/30650 (epoch 2.372), train_loss = 2.11741609, grad/param norm = 2.3812e-01, time/batch = 0.6773s	
1455/30650 (epoch 2.374), train_loss = 2.00804442, grad/param norm = 2.8003e-01, time/batch = 0.6802s	
1456/30650 (epoch 2.375), train_loss = 2.11930674, grad/param norm = 2.7899e-01, time/batch = 0.6842s	
1457/30650 (epoch 2.377), train_loss = 2.11508866, grad/param norm = 2.2178e-01, time/batch = 0.6985s	
1458/30650 (epoch 2.378), train_loss = 2.07113870, grad/param norm = 2.5324e-01, time/batch = 0.6864s	
1459/30650 (epoch 2.380), train_loss = 2.16096218, grad/param norm = 2.3874e-01, time/batch = 0.6814s	
1460/30650 (epoch 2.382), train_loss = 2.00177969, grad/param norm = 2.6367e-01, time/batch = 0.6811s	
1461/30650 (epoch 2.383), train_loss = 2.06748152, grad/param norm = 2.2553e-01, time/batch = 0.6794s	
1462/30650 (epoch 2.385), train_loss = 2.10895047, grad/param norm = 2.4518e-01, time/batch = 0.6774s	
1463/30650 (epoch 2.387), train_loss = 1.83503148, grad/param norm = 2.3440e-01, time/batch = 0.6825s	
1464/30650 (epoch 2.388), train_loss = 2.09741948, grad/param norm = 2.1752e-01, time/batch = 0.6792s	
1465/30650 (epoch 2.390), train_loss = 1.72677303, grad/param norm = 2.1398e-01, time/batch = 0.6791s	
1466/30650 (epoch 2.392), train_loss = 1.89350968, grad/param norm = 2.4274e-01, time/batch = 0.6971s	
1467/30650 (epoch 2.393), train_loss = 1.81598673, grad/param norm = 2.1723e-01, time/batch = 0.6813s	
1468/30650 (epoch 2.395), train_loss = 1.94161009, grad/param norm = 2.2035e-01, time/batch = 0.6779s	
1469/30650 (epoch 2.396), train_loss = 1.98667331, grad/param norm = 2.2057e-01, time/batch = 0.6779s	
1470/30650 (epoch 2.398), train_loss = 1.97628188, grad/param norm = 2.3378e-01, time/batch = 0.6771s	
1471/30650 (epoch 2.400), train_loss = 2.00970635, grad/param norm = 2.5939e-01, time/batch = 0.6801s	
1472/30650 (epoch 2.401), train_loss = 1.79156777, grad/param norm = 2.2911e-01, time/batch = 0.6792s	
1473/30650 (epoch 2.403), train_loss = 2.01370318, grad/param norm = 2.7810e-01, time/batch = 0.6776s	
1474/30650 (epoch 2.405), train_loss = 2.01854147, grad/param norm = 2.8960e-01, time/batch = 0.6803s	
1475/30650 (epoch 2.406), train_loss = 1.94304827, grad/param norm = 2.8449e-01, time/batch = 0.6851s	
1476/30650 (epoch 2.408), train_loss = 2.06705050, grad/param norm = 2.3570e-01, time/batch = 0.6830s	
1477/30650 (epoch 2.409), train_loss = 2.17388841, grad/param norm = 2.6104e-01, time/batch = 0.6812s	
1478/30650 (epoch 2.411), train_loss = 1.97849039, grad/param norm = 2.4704e-01, time/batch = 0.7014s	
1479/30650 (epoch 2.413), train_loss = 1.86471511, grad/param norm = 2.1542e-01, time/batch = 0.6989s	
1480/30650 (epoch 2.414), train_loss = 2.05617591, grad/param norm = 2.5466e-01, time/batch = 0.6977s	
1481/30650 (epoch 2.416), train_loss = 1.98187781, grad/param norm = 2.2684e-01, time/batch = 0.7001s	
1482/30650 (epoch 2.418), train_loss = 1.92976305, grad/param norm = 2.2894e-01, time/batch = 0.6951s	
1483/30650 (epoch 2.419), train_loss = 2.08491218, grad/param norm = 2.4785e-01, time/batch = 0.7080s	
1484/30650 (epoch 2.421), train_loss = 1.93049549, grad/param norm = 2.4923e-01, time/batch = 0.7184s	
1485/30650 (epoch 2.423), train_loss = 1.98959036, grad/param norm = 2.5385e-01, time/batch = 0.7009s	
1486/30650 (epoch 2.424), train_loss = 2.27384524, grad/param norm = 2.4934e-01, time/batch = 0.7069s	
1487/30650 (epoch 2.426), train_loss = 1.84181027, grad/param norm = 2.4256e-01, time/batch = 0.6922s	
1488/30650 (epoch 2.427), train_loss = 2.08109566, grad/param norm = 2.7012e-01, time/batch = 0.6954s	
1489/30650 (epoch 2.429), train_loss = 2.04551835, grad/param norm = 2.6897e-01, time/batch = 0.6822s	
1490/30650 (epoch 2.431), train_loss = 2.11532580, grad/param norm = 2.5724e-01, time/batch = 0.7141s	
1491/30650 (epoch 2.432), train_loss = 2.16222471, grad/param norm = 2.3104e-01, time/batch = 0.7003s	
1492/30650 (epoch 2.434), train_loss = 2.06138255, grad/param norm = 2.2832e-01, time/batch = 0.6916s	
1493/30650 (epoch 2.436), train_loss = 2.03265923, grad/param norm = 2.1693e-01, time/batch = 0.6951s	
1494/30650 (epoch 2.437), train_loss = 2.09130296, grad/param norm = 2.5437e-01, time/batch = 0.6899s	
1495/30650 (epoch 2.439), train_loss = 1.75608644, grad/param norm = 2.3305e-01, time/batch = 0.6933s	
1496/30650 (epoch 2.440), train_loss = 1.94763805, grad/param norm = 2.6278e-01, time/batch = 0.6919s	
1497/30650 (epoch 2.442), train_loss = 1.77642321, grad/param norm = 2.5279e-01, time/batch = 0.6900s	
1498/30650 (epoch 2.444), train_loss = 1.98165134, grad/param norm = 2.4425e-01, time/batch = 0.6885s	
1499/30650 (epoch 2.445), train_loss = 1.80139428, grad/param norm = 2.4215e-01, time/batch = 0.6950s	
1500/30650 (epoch 2.447), train_loss = 2.05671679, grad/param norm = 2.2545e-01, time/batch = 0.6953s	
1501/30650 (epoch 2.449), train_loss = 1.86870302, grad/param norm = 2.2960e-01, time/batch = 0.7025s	
1502/30650 (epoch 2.450), train_loss = 2.01859582, grad/param norm = 2.3022e-01, time/batch = 0.6944s	
1503/30650 (epoch 2.452), train_loss = 1.83990351, grad/param norm = 2.1793e-01, time/batch = 0.6941s	
1504/30650 (epoch 2.454), train_loss = 1.93008034, grad/param norm = 2.5243e-01, time/batch = 0.6905s	
1505/30650 (epoch 2.455), train_loss = 1.92208300, grad/param norm = 2.2436e-01, time/batch = 0.6782s	
1506/30650 (epoch 2.457), train_loss = 1.91581837, grad/param norm = 2.2519e-01, time/batch = 0.6888s	
1507/30650 (epoch 2.458), train_loss = 1.99779620, grad/param norm = 2.3602e-01, time/batch = 0.6910s	
1508/30650 (epoch 2.460), train_loss = 2.04995844, grad/param norm = 2.4376e-01, time/batch = 0.6892s	
1509/30650 (epoch 2.462), train_loss = 2.09013445, grad/param norm = 2.5714e-01, time/batch = 0.7149s	
1510/30650 (epoch 2.463), train_loss = 1.90390191, grad/param norm = 2.6964e-01, time/batch = 0.7062s	
1511/30650 (epoch 2.465), train_loss = 2.16595843, grad/param norm = 2.7222e-01, time/batch = 0.6972s	
1512/30650 (epoch 2.467), train_loss = 2.08815386, grad/param norm = 2.2821e-01, time/batch = 0.6795s	
1513/30650 (epoch 2.468), train_loss = 2.07458122, grad/param norm = 2.2149e-01, time/batch = 0.7065s	
1514/30650 (epoch 2.470), train_loss = 1.85881186, grad/param norm = 2.2918e-01, time/batch = 0.6985s	
1515/30650 (epoch 2.471), train_loss = 1.75622771, grad/param norm = 2.1904e-01, time/batch = 0.6826s	
1516/30650 (epoch 2.473), train_loss = 2.16646274, grad/param norm = 2.3933e-01, time/batch = 0.6855s	
1517/30650 (epoch 2.475), train_loss = 1.92924504, grad/param norm = 2.1007e-01, time/batch = 0.6794s	
1518/30650 (epoch 2.476), train_loss = 1.86298345, grad/param norm = 2.1100e-01, time/batch = 0.6779s	
1519/30650 (epoch 2.478), train_loss = 1.94808538, grad/param norm = 2.1904e-01, time/batch = 0.6770s	
1520/30650 (epoch 2.480), train_loss = 1.99938066, grad/param norm = 2.3144e-01, time/batch = 0.6800s	
1521/30650 (epoch 2.481), train_loss = 1.84981919, grad/param norm = 2.4210e-01, time/batch = 0.6973s	
1522/30650 (epoch 2.483), train_loss = 1.97085384, grad/param norm = 2.1597e-01, time/batch = 0.6829s	
1523/30650 (epoch 2.485), train_loss = 1.85262027, grad/param norm = 2.3147e-01, time/batch = 0.6767s	
1524/30650 (epoch 2.486), train_loss = 2.03562463, grad/param norm = 2.3325e-01, time/batch = 0.6799s	
1525/30650 (epoch 2.488), train_loss = 1.83105579, grad/param norm = 2.3950e-01, time/batch = 0.6799s	
1526/30650 (epoch 2.489), train_loss = 2.02285274, grad/param norm = 2.3946e-01, time/batch = 0.6777s	
1527/30650 (epoch 2.491), train_loss = 2.02303431, grad/param norm = 2.7451e-01, time/batch = 0.6787s	
1528/30650 (epoch 2.493), train_loss = 2.08107572, grad/param norm = 2.6941e-01, time/batch = 0.7174s	
1529/30650 (epoch 2.494), train_loss = 1.90141877, grad/param norm = 2.2011e-01, time/batch = 0.6994s	
1530/30650 (epoch 2.496), train_loss = 2.02422951, grad/param norm = 2.2292e-01, time/batch = 0.6775s	
1531/30650 (epoch 2.498), train_loss = 1.87909594, grad/param norm = 2.3879e-01, time/batch = 0.6792s	
1532/30650 (epoch 2.499), train_loss = 1.97091042, grad/param norm = 2.1694e-01, time/batch = 0.6782s	
1533/30650 (epoch 2.501), train_loss = 2.04157628, grad/param norm = 2.3557e-01, time/batch = 0.6797s	
1534/30650 (epoch 2.502), train_loss = 2.15196440, grad/param norm = 2.1767e-01, time/batch = 0.6808s	
1535/30650 (epoch 2.504), train_loss = 2.11179327, grad/param norm = 2.3205e-01, time/batch = 0.6902s	
1536/30650 (epoch 2.506), train_loss = 1.93152729, grad/param norm = 2.1532e-01, time/batch = 0.6952s	
1537/30650 (epoch 2.507), train_loss = 1.91759135, grad/param norm = 2.1835e-01, time/batch = 0.6814s	
1538/30650 (epoch 2.509), train_loss = 1.87067453, grad/param norm = 2.3480e-01, time/batch = 0.6777s	
1539/30650 (epoch 2.511), train_loss = 1.96924822, grad/param norm = 2.3614e-01, time/batch = 0.6787s	
1540/30650 (epoch 2.512), train_loss = 1.98122168, grad/param norm = 2.2218e-01, time/batch = 0.6800s	
1541/30650 (epoch 2.514), train_loss = 2.17535656, grad/param norm = 2.4022e-01, time/batch = 0.6792s	
1542/30650 (epoch 2.515), train_loss = 2.05594019, grad/param norm = 2.1657e-01, time/batch = 0.6968s	
1543/30650 (epoch 2.517), train_loss = 2.03203924, grad/param norm = 2.3755e-01, time/batch = 0.7223s	
1544/30650 (epoch 2.519), train_loss = 2.08323170, grad/param norm = 2.0837e-01, time/batch = 0.6948s	
1545/30650 (epoch 2.520), train_loss = 1.96289866, grad/param norm = 2.1441e-01, time/batch = 0.6867s	
1546/30650 (epoch 2.522), train_loss = 2.25844717, grad/param norm = 2.5791e-01, time/batch = 0.6892s	
1547/30650 (epoch 2.524), train_loss = 2.08726174, grad/param norm = 2.2196e-01, time/batch = 0.6836s	
1548/30650 (epoch 2.525), train_loss = 1.80755788, grad/param norm = 2.3493e-01, time/batch = 0.7019s	
1549/30650 (epoch 2.527), train_loss = 2.20567644, grad/param norm = 2.4269e-01, time/batch = 0.7133s	
1550/30650 (epoch 2.529), train_loss = 2.07551153, grad/param norm = 2.4670e-01, time/batch = 0.7128s	
1551/30650 (epoch 2.530), train_loss = 2.00079076, grad/param norm = 2.2259e-01, time/batch = 0.7067s	
1552/30650 (epoch 2.532), train_loss = 1.91547047, grad/param norm = 2.2944e-01, time/batch = 0.7238s	
1553/30650 (epoch 2.533), train_loss = 1.91892462, grad/param norm = 2.2959e-01, time/batch = 0.7179s	
1554/30650 (epoch 2.535), train_loss = 2.03638158, grad/param norm = 2.5736e-01, time/batch = 0.6774s	
1555/30650 (epoch 2.537), train_loss = 2.18612161, grad/param norm = 2.2559e-01, time/batch = 0.6763s	
1556/30650 (epoch 2.538), train_loss = 2.03031695, grad/param norm = 2.3637e-01, time/batch = 0.6926s	
1557/30650 (epoch 2.540), train_loss = 1.98755962, grad/param norm = 2.4263e-01, time/batch = 0.6934s	
1558/30650 (epoch 2.542), train_loss = 2.29452335, grad/param norm = 2.4759e-01, time/batch = 0.6796s	
1559/30650 (epoch 2.543), train_loss = 2.17154692, grad/param norm = 2.3296e-01, time/batch = 0.6798s	
1560/30650 (epoch 2.545), train_loss = 2.07421757, grad/param norm = 2.3346e-01, time/batch = 0.6753s	
1561/30650 (epoch 2.546), train_loss = 1.90921305, grad/param norm = 2.3486e-01, time/batch = 0.6778s	
1562/30650 (epoch 2.548), train_loss = 2.11603078, grad/param norm = 3.0816e-01, time/batch = 0.6777s	
1563/30650 (epoch 2.550), train_loss = 2.10100765, grad/param norm = 2.1176e-01, time/batch = 0.6776s	
1564/30650 (epoch 2.551), train_loss = 2.02103403, grad/param norm = 2.0489e-01, time/batch = 0.6758s	
1565/30650 (epoch 2.553), train_loss = 2.26744351, grad/param norm = 2.4564e-01, time/batch = 0.6759s	
1566/30650 (epoch 2.555), train_loss = 2.15503512, grad/param norm = 2.3663e-01, time/batch = 0.6763s	
1567/30650 (epoch 2.556), train_loss = 2.02177028, grad/param norm = 2.1025e-01, time/batch = 0.7178s	
1568/30650 (epoch 2.558), train_loss = 2.17858353, grad/param norm = 2.3976e-01, time/batch = 0.6990s	
1569/30650 (epoch 2.560), train_loss = 1.98019526, grad/param norm = 2.2117e-01, time/batch = 0.6772s	
1570/30650 (epoch 2.561), train_loss = 2.13323074, grad/param norm = 2.0442e-01, time/batch = 0.6765s	
1571/30650 (epoch 2.563), train_loss = 2.00840585, grad/param norm = 2.2264e-01, time/batch = 0.6852s	
1572/30650 (epoch 2.564), train_loss = 1.82648510, grad/param norm = 2.4930e-01, time/batch = 0.6848s	
1573/30650 (epoch 2.566), train_loss = 1.99776667, grad/param norm = 2.2491e-01, time/batch = 0.6845s	
1574/30650 (epoch 2.568), train_loss = 2.09610942, grad/param norm = 2.7004e-01, time/batch = 0.6794s	
1575/30650 (epoch 2.569), train_loss = 1.94228157, grad/param norm = 2.1713e-01, time/batch = 0.6799s	
1576/30650 (epoch 2.571), train_loss = 2.06941743, grad/param norm = 2.3494e-01, time/batch = 0.6764s	
1577/30650 (epoch 2.573), train_loss = 1.84329332, grad/param norm = 2.3521e-01, time/batch = 0.6774s	
1578/30650 (epoch 2.574), train_loss = 2.09037719, grad/param norm = 2.6299e-01, time/batch = 0.6783s	
1579/30650 (epoch 2.576), train_loss = 1.97642657, grad/param norm = 2.5523e-01, time/batch = 0.6764s	
1580/30650 (epoch 2.577), train_loss = 1.90927516, grad/param norm = 2.0493e-01, time/batch = 0.6768s	
1581/30650 (epoch 2.579), train_loss = 2.09164789, grad/param norm = 2.2751e-01, time/batch = 0.6812s	
1582/30650 (epoch 2.581), train_loss = 2.02434624, grad/param norm = 2.2688e-01, time/batch = 0.6790s	
1583/30650 (epoch 2.582), train_loss = 1.99099890, grad/param norm = 2.2573e-01, time/batch = 0.6785s	
1584/30650 (epoch 2.584), train_loss = 2.07211671, grad/param norm = 2.2245e-01, time/batch = 0.6820s	
1585/30650 (epoch 2.586), train_loss = 1.97736572, grad/param norm = 2.4612e-01, time/batch = 0.6793s	
1586/30650 (epoch 2.587), train_loss = 2.10855155, grad/param norm = 2.3695e-01, time/batch = 0.6787s	
1587/30650 (epoch 2.589), train_loss = 1.88486759, grad/param norm = 2.6610e-01, time/batch = 0.6776s	
1588/30650 (epoch 2.591), train_loss = 1.97647564, grad/param norm = 2.3162e-01, time/batch = 0.6848s	
1589/30650 (epoch 2.592), train_loss = 1.84861815, grad/param norm = 2.0723e-01, time/batch = 0.6808s	
1590/30650 (epoch 2.594), train_loss = 2.18385196, grad/param norm = 2.4381e-01, time/batch = 0.6784s	
1591/30650 (epoch 2.595), train_loss = 1.98152079, grad/param norm = 2.7674e-01, time/batch = 0.6786s	
1592/30650 (epoch 2.597), train_loss = 1.97652210, grad/param norm = 2.3947e-01, time/batch = 0.6782s	
1593/30650 (epoch 2.599), train_loss = 2.14869495, grad/param norm = 2.4907e-01, time/batch = 0.6769s	
1594/30650 (epoch 2.600), train_loss = 1.83350421, grad/param norm = 2.6776e-01, time/batch = 0.6856s	
1595/30650 (epoch 2.602), train_loss = 1.85627290, grad/param norm = 2.2990e-01, time/batch = 0.6890s	
1596/30650 (epoch 2.604), train_loss = 1.86492972, grad/param norm = 2.2311e-01, time/batch = 0.6789s	
1597/30650 (epoch 2.605), train_loss = 1.75672670, grad/param norm = 2.2862e-01, time/batch = 0.6772s	
1598/30650 (epoch 2.607), train_loss = 1.96690713, grad/param norm = 2.7935e-01, time/batch = 0.6759s	
1599/30650 (epoch 2.608), train_loss = 1.87562271, grad/param norm = 2.1304e-01, time/batch = 0.6756s	
1600/30650 (epoch 2.610), train_loss = 1.99632730, grad/param norm = 2.5333e-01, time/batch = 0.6915s	
1601/30650 (epoch 2.612), train_loss = 2.18040437, grad/param norm = 2.4147e-01, time/batch = 0.7235s	
1602/30650 (epoch 2.613), train_loss = 2.14221512, grad/param norm = 2.3430e-01, time/batch = 0.6807s	
1603/30650 (epoch 2.615), train_loss = 2.03614009, grad/param norm = 2.2444e-01, time/batch = 0.6755s	
1604/30650 (epoch 2.617), train_loss = 1.80910167, grad/param norm = 2.6549e-01, time/batch = 0.6765s	
1605/30650 (epoch 2.618), train_loss = 2.17878812, grad/param norm = 2.2099e-01, time/batch = 0.6786s	
1606/30650 (epoch 2.620), train_loss = 1.87240207, grad/param norm = 2.2638e-01, time/batch = 0.6782s	
1607/30650 (epoch 2.622), train_loss = 1.71001475, grad/param norm = 2.1834e-01, time/batch = 0.6768s	
1608/30650 (epoch 2.623), train_loss = 1.90380256, grad/param norm = 2.4443e-01, time/batch = 0.6798s	
1609/30650 (epoch 2.625), train_loss = 1.99615401, grad/param norm = 2.5168e-01, time/batch = 0.6773s	
1610/30650 (epoch 2.626), train_loss = 2.09798569, grad/param norm = 2.5146e-01, time/batch = 0.6795s	
1611/30650 (epoch 2.628), train_loss = 2.05940781, grad/param norm = 2.1867e-01, time/batch = 0.6809s	
1612/30650 (epoch 2.630), train_loss = 1.93404723, grad/param norm = 2.3249e-01, time/batch = 0.6783s	
1613/30650 (epoch 2.631), train_loss = 1.99526252, grad/param norm = 2.2562e-01, time/batch = 0.6803s	
1614/30650 (epoch 2.633), train_loss = 2.00233381, grad/param norm = 2.2356e-01, time/batch = 0.6807s	
1615/30650 (epoch 2.635), train_loss = 2.05452969, grad/param norm = 2.3515e-01, time/batch = 0.7093s	
1616/30650 (epoch 2.636), train_loss = 1.96366921, grad/param norm = 2.1928e-01, time/batch = 0.6931s	
1617/30650 (epoch 2.638), train_loss = 1.94144879, grad/param norm = 2.4128e-01, time/batch = 0.6783s	
1618/30650 (epoch 2.639), train_loss = 2.20018057, grad/param norm = 2.3223e-01, time/batch = 0.6807s	
1619/30650 (epoch 2.641), train_loss = 1.97493361, grad/param norm = 2.2693e-01, time/batch = 0.6755s	
1620/30650 (epoch 2.643), train_loss = 2.04833333, grad/param norm = 1.9452e-01, time/batch = 0.6759s	
1621/30650 (epoch 2.644), train_loss = 2.12750291, grad/param norm = 2.3221e-01, time/batch = 0.6784s	
1622/30650 (epoch 2.646), train_loss = 2.15300042, grad/param norm = 2.4862e-01, time/batch = 0.6756s	
1623/30650 (epoch 2.648), train_loss = 1.90339163, grad/param norm = 2.4118e-01, time/batch = 0.6777s	
1624/30650 (epoch 2.649), train_loss = 1.86414165, grad/param norm = 2.3215e-01, time/batch = 0.6836s	
1625/30650 (epoch 2.651), train_loss = 1.91420981, grad/param norm = 2.0991e-01, time/batch = 0.6775s	
1626/30650 (epoch 2.653), train_loss = 1.95121176, grad/param norm = 2.0738e-01, time/batch = 0.6802s	
1627/30650 (epoch 2.654), train_loss = 1.74845853, grad/param norm = 2.0064e-01, time/batch = 0.6822s	
1628/30650 (epoch 2.656), train_loss = 1.92194070, grad/param norm = 2.4642e-01, time/batch = 0.6782s	
1629/30650 (epoch 2.657), train_loss = 1.99520054, grad/param norm = 2.4134e-01, time/batch = 0.6802s	
1630/30650 (epoch 2.659), train_loss = 1.90696226, grad/param norm = 2.1173e-01, time/batch = 0.6882s	
1631/30650 (epoch 2.661), train_loss = 1.93465992, grad/param norm = 2.1290e-01, time/batch = 0.6922s	
1632/30650 (epoch 2.662), train_loss = 1.82281848, grad/param norm = 2.1164e-01, time/batch = 0.7034s	
1633/30650 (epoch 2.664), train_loss = 1.97735410, grad/param norm = 2.2033e-01, time/batch = 0.7002s	
1634/30650 (epoch 2.666), train_loss = 1.95890086, grad/param norm = 2.2017e-01, time/batch = 0.6761s	
1635/30650 (epoch 2.667), train_loss = 2.20533825, grad/param norm = 2.4369e-01, time/batch = 0.6771s	
1636/30650 (epoch 2.669), train_loss = 1.93614534, grad/param norm = 2.1363e-01, time/batch = 0.6831s	
1637/30650 (epoch 2.670), train_loss = 1.89458629, grad/param norm = 2.1564e-01, time/batch = 0.6937s	
1638/30650 (epoch 2.672), train_loss = 2.02066371, grad/param norm = 2.0626e-01, time/batch = 0.6805s	
1639/30650 (epoch 2.674), train_loss = 1.90209808, grad/param norm = 1.9787e-01, time/batch = 0.6794s	
1640/30650 (epoch 2.675), train_loss = 2.02668541, grad/param norm = 2.2599e-01, time/batch = 0.6783s	
1641/30650 (epoch 2.677), train_loss = 1.83815766, grad/param norm = 2.1911e-01, time/batch = 0.6806s	
1642/30650 (epoch 2.679), train_loss = 1.95620182, grad/param norm = 2.0378e-01, time/batch = 0.6773s	
1643/30650 (epoch 2.680), train_loss = 2.05725948, grad/param norm = 2.2554e-01, time/batch = 0.6818s	
1644/30650 (epoch 2.682), train_loss = 1.92310144, grad/param norm = 2.1655e-01, time/batch = 0.6782s	
1645/30650 (epoch 2.684), train_loss = 2.05653288, grad/param norm = 2.1124e-01, time/batch = 0.6838s	
1646/30650 (epoch 2.685), train_loss = 1.86643240, grad/param norm = 2.1846e-01, time/batch = 0.6799s	
1647/30650 (epoch 2.687), train_loss = 1.96293830, grad/param norm = 2.6584e-01, time/batch = 0.6770s	
1648/30650 (epoch 2.688), train_loss = 1.90364946, grad/param norm = 2.6992e-01, time/batch = 0.6885s	
1649/30650 (epoch 2.690), train_loss = 1.83401364, grad/param norm = 2.5303e-01, time/batch = 0.7224s	
1650/30650 (epoch 2.692), train_loss = 1.99740753, grad/param norm = 2.5588e-01, time/batch = 0.6858s	
1651/30650 (epoch 2.693), train_loss = 1.72686469, grad/param norm = 2.6482e-01, time/batch = 0.6784s	
1652/30650 (epoch 2.695), train_loss = 1.87746170, grad/param norm = 3.3088e-01, time/batch = 0.6787s	
1653/30650 (epoch 2.697), train_loss = 1.86528816, grad/param norm = 2.6872e-01, time/batch = 0.6805s	
1654/30650 (epoch 2.698), train_loss = 1.89833122, grad/param norm = 2.1186e-01, time/batch = 0.6783s	
1655/30650 (epoch 2.700), train_loss = 1.94935397, grad/param norm = 2.2004e-01, time/batch = 0.6826s	
1656/30650 (epoch 2.701), train_loss = 1.79630225, grad/param norm = 2.2005e-01, time/batch = 0.6904s	
1657/30650 (epoch 2.703), train_loss = 1.80845595, grad/param norm = 2.1630e-01, time/batch = 0.6790s	
1658/30650 (epoch 2.705), train_loss = 1.71818220, grad/param norm = 2.0461e-01, time/batch = 0.6818s	
1659/30650 (epoch 2.706), train_loss = 1.92396186, grad/param norm = 2.0605e-01, time/batch = 0.6839s	
1660/30650 (epoch 2.708), train_loss = 2.02589585, grad/param norm = 2.3929e-01, time/batch = 0.6998s	
1661/30650 (epoch 2.710), train_loss = 1.98521211, grad/param norm = 2.4907e-01, time/batch = 0.7167s	
1662/30650 (epoch 2.711), train_loss = 2.03557676, grad/param norm = 2.3052e-01, time/batch = 0.6954s	
1663/30650 (epoch 2.713), train_loss = 2.03767815, grad/param norm = 2.4802e-01, time/batch = 0.7150s	
1664/30650 (epoch 2.715), train_loss = 2.00976249, grad/param norm = 2.0981e-01, time/batch = 0.6953s	
1665/30650 (epoch 2.716), train_loss = 2.04217417, grad/param norm = 2.2156e-01, time/batch = 0.6842s	
1666/30650 (epoch 2.718), train_loss = 1.89663099, grad/param norm = 2.0880e-01, time/batch = 0.6770s	
1667/30650 (epoch 2.719), train_loss = 1.82911004, grad/param norm = 2.0430e-01, time/batch = 0.6771s	
1668/30650 (epoch 2.721), train_loss = 2.06676162, grad/param norm = 2.2426e-01, time/batch = 0.6769s	
1669/30650 (epoch 2.723), train_loss = 1.72742259, grad/param norm = 1.8615e-01, time/batch = 0.6808s	
1670/30650 (epoch 2.724), train_loss = 2.06769808, grad/param norm = 2.2857e-01, time/batch = 0.6789s	
1671/30650 (epoch 2.726), train_loss = 1.79471597, grad/param norm = 2.1521e-01, time/batch = 0.6816s	
1672/30650 (epoch 2.728), train_loss = 1.93888365, grad/param norm = 2.6754e-01, time/batch = 0.6819s	
1673/30650 (epoch 2.729), train_loss = 2.02138688, grad/param norm = 2.6073e-01, time/batch = 0.6807s	
1674/30650 (epoch 2.731), train_loss = 2.10041980, grad/param norm = 2.1685e-01, time/batch = 0.6850s	
1675/30650 (epoch 2.732), train_loss = 2.05756687, grad/param norm = 2.6872e-01, time/batch = 0.6766s	
1676/30650 (epoch 2.734), train_loss = 2.16376964, grad/param norm = 2.6125e-01, time/batch = 0.6784s	
1677/30650 (epoch 2.736), train_loss = 2.11108990, grad/param norm = 2.3333e-01, time/batch = 0.6890s	
1678/30650 (epoch 2.737), train_loss = 1.93479237, grad/param norm = 2.3218e-01, time/batch = 0.7214s	
1679/30650 (epoch 2.739), train_loss = 1.82035052, grad/param norm = 2.1223e-01, time/batch = 0.6871s	
1680/30650 (epoch 2.741), train_loss = 2.01400009, grad/param norm = 2.1185e-01, time/batch = 0.6774s	
1681/30650 (epoch 2.742), train_loss = 2.14152011, grad/param norm = 2.2738e-01, time/batch = 0.6817s	
1682/30650 (epoch 2.744), train_loss = 2.01863777, grad/param norm = 2.1372e-01, time/batch = 0.6806s	
1683/30650 (epoch 2.746), train_loss = 2.05058386, grad/param norm = 2.2697e-01, time/batch = 0.6801s	
1684/30650 (epoch 2.747), train_loss = 2.09544047, grad/param norm = 2.1593e-01, time/batch = 0.6786s	
1685/30650 (epoch 2.749), train_loss = 1.98754916, grad/param norm = 2.1734e-01, time/batch = 0.6790s	
1686/30650 (epoch 2.750), train_loss = 1.90140033, grad/param norm = 2.1102e-01, time/batch = 0.6776s	
1687/30650 (epoch 2.752), train_loss = 1.89716574, grad/param norm = 2.1699e-01, time/batch = 0.6952s	
1688/30650 (epoch 2.754), train_loss = 1.81222975, grad/param norm = 2.4790e-01, time/batch = 0.6971s	
1689/30650 (epoch 2.755), train_loss = 2.02271414, grad/param norm = 2.7722e-01, time/batch = 0.6859s	
1690/30650 (epoch 2.757), train_loss = 1.94712411, grad/param norm = 2.0604e-01, time/batch = 0.6790s	
1691/30650 (epoch 2.759), train_loss = 2.09231413, grad/param norm = 2.5447e-01, time/batch = 0.6790s	
1692/30650 (epoch 2.760), train_loss = 2.01528878, grad/param norm = 2.7649e-01, time/batch = 0.6818s	
1693/30650 (epoch 2.762), train_loss = 1.89266272, grad/param norm = 2.3511e-01, time/batch = 0.6784s	
1694/30650 (epoch 2.763), train_loss = 1.87924868, grad/param norm = 2.2468e-01, time/batch = 0.6812s	
1695/30650 (epoch 2.765), train_loss = 1.90443677, grad/param norm = 2.1848e-01, time/batch = 0.6799s	
1696/30650 (epoch 2.767), train_loss = 1.74732168, grad/param norm = 1.9405e-01, time/batch = 0.6978s	
1697/30650 (epoch 2.768), train_loss = 1.96318090, grad/param norm = 2.2043e-01, time/batch = 0.7028s	
1698/30650 (epoch 2.770), train_loss = 2.02079605, grad/param norm = 2.3593e-01, time/batch = 0.6988s	
1699/30650 (epoch 2.772), train_loss = 2.00040388, grad/param norm = 2.0602e-01, time/batch = 0.7135s	
1700/30650 (epoch 2.773), train_loss = 2.06814394, grad/param norm = 2.3948e-01, time/batch = 0.6949s	
1701/30650 (epoch 2.775), train_loss = 2.06026135, grad/param norm = 2.4663e-01, time/batch = 0.7133s	
1702/30650 (epoch 2.777), train_loss = 1.81507738, grad/param norm = 2.3216e-01, time/batch = 0.6954s	
1703/30650 (epoch 2.778), train_loss = 1.96167325, grad/param norm = 2.4162e-01, time/batch = 0.6927s	
1704/30650 (epoch 2.780), train_loss = 2.00690750, grad/param norm = 2.6201e-01, time/batch = 0.6928s	
1705/30650 (epoch 2.781), train_loss = 2.13975112, grad/param norm = 2.3751e-01, time/batch = 0.6761s	
1706/30650 (epoch 2.783), train_loss = 2.25505062, grad/param norm = 2.5302e-01, time/batch = 0.6910s	
1707/30650 (epoch 2.785), train_loss = 2.03204118, grad/param norm = 2.6687e-01, time/batch = 0.7214s	
1708/30650 (epoch 2.786), train_loss = 1.83914122, grad/param norm = 2.0772e-01, time/batch = 0.6806s	
1709/30650 (epoch 2.788), train_loss = 1.98530764, grad/param norm = 2.1328e-01, time/batch = 0.6763s	
1710/30650 (epoch 2.790), train_loss = 1.85902878, grad/param norm = 2.1287e-01, time/batch = 0.6812s	
1711/30650 (epoch 2.791), train_loss = 1.85871399, grad/param norm = 2.0927e-01, time/batch = 0.6776s	
1712/30650 (epoch 2.793), train_loss = 2.14799902, grad/param norm = 2.0479e-01, time/batch = 0.6767s	
1713/30650 (epoch 2.794), train_loss = 2.06597945, grad/param norm = 2.4538e-01, time/batch = 0.6791s	
1714/30650 (epoch 2.796), train_loss = 1.98413633, grad/param norm = 2.3105e-01, time/batch = 0.6762s	
1715/30650 (epoch 2.798), train_loss = 1.77251100, grad/param norm = 2.3991e-01, time/batch = 0.6768s	
1716/30650 (epoch 2.799), train_loss = 2.02715097, grad/param norm = 2.8944e-01, time/batch = 0.6780s	
1717/30650 (epoch 2.801), train_loss = 1.92125967, grad/param norm = 2.0794e-01, time/batch = 0.6848s	
1718/30650 (epoch 2.803), train_loss = 2.06028723, grad/param norm = 2.2484e-01, time/batch = 0.6864s	
1719/30650 (epoch 2.804), train_loss = 1.94813058, grad/param norm = 2.1230e-01, time/batch = 0.6992s	
1720/30650 (epoch 2.806), train_loss = 1.92063857, grad/param norm = 2.0522e-01, time/batch = 0.6960s	
1721/30650 (epoch 2.808), train_loss = 1.86694138, grad/param norm = 2.1746e-01, time/batch = 0.7215s	
1722/30650 (epoch 2.809), train_loss = 1.69407662, grad/param norm = 2.5004e-01, time/batch = 0.7041s	
1723/30650 (epoch 2.811), train_loss = 1.96410417, grad/param norm = 2.2191e-01, time/batch = 0.6820s	
1724/30650 (epoch 2.812), train_loss = 2.13103385, grad/param norm = 2.4320e-01, time/batch = 0.6767s	
1725/30650 (epoch 2.814), train_loss = 1.93330905, grad/param norm = 2.0423e-01, time/batch = 0.6812s	
1726/30650 (epoch 2.816), train_loss = 2.13054587, grad/param norm = 2.4004e-01, time/batch = 0.6783s	
1727/30650 (epoch 2.817), train_loss = 2.03103251, grad/param norm = 2.2844e-01, time/batch = 0.6936s	
1728/30650 (epoch 2.819), train_loss = 1.88156309, grad/param norm = 2.2419e-01, time/batch = 0.6818s	
1729/30650 (epoch 2.821), train_loss = 1.83738082, grad/param norm = 2.4044e-01, time/batch = 0.6802s	
1730/30650 (epoch 2.822), train_loss = 1.95578302, grad/param norm = 2.3367e-01, time/batch = 0.6806s	
1731/30650 (epoch 2.824), train_loss = 1.71045279, grad/param norm = 2.2139e-01, time/batch = 0.6818s	
1732/30650 (epoch 2.825), train_loss = 2.01676280, grad/param norm = 2.4416e-01, time/batch = 0.6834s	
1733/30650 (epoch 2.827), train_loss = 1.82491534, grad/param norm = 2.4554e-01, time/batch = 0.6835s	
1734/30650 (epoch 2.829), train_loss = 2.03773738, grad/param norm = 2.3934e-01, time/batch = 0.6804s	
1735/30650 (epoch 2.830), train_loss = 1.86255201, grad/param norm = 2.3329e-01, time/batch = 0.6922s	
1736/30650 (epoch 2.832), train_loss = 1.90133800, grad/param norm = 2.2872e-01, time/batch = 0.7219s	
1737/30650 (epoch 2.834), train_loss = 2.02610464, grad/param norm = 2.2632e-01, time/batch = 0.6824s	
1738/30650 (epoch 2.835), train_loss = 1.97912799, grad/param norm = 2.5063e-01, time/batch = 0.6893s	
1739/30650 (epoch 2.837), train_loss = 2.00188247, grad/param norm = 2.2967e-01, time/batch = 0.6826s	
1740/30650 (epoch 2.838), train_loss = 1.88296661, grad/param norm = 2.2919e-01, time/batch = 0.7035s	
1741/30650 (epoch 2.840), train_loss = 1.88996302, grad/param norm = 2.2687e-01, time/batch = 0.7134s	
1742/30650 (epoch 2.842), train_loss = 1.79831862, grad/param norm = 2.2459e-01, time/batch = 0.7173s	
1743/30650 (epoch 2.843), train_loss = 1.98550605, grad/param norm = 2.2265e-01, time/batch = 0.7000s	
1744/30650 (epoch 2.845), train_loss = 2.02160743, grad/param norm = 2.5818e-01, time/batch = 0.6990s	
1745/30650 (epoch 2.847), train_loss = 2.04333326, grad/param norm = 2.2490e-01, time/batch = 0.6953s	
1746/30650 (epoch 2.848), train_loss = 1.94365174, grad/param norm = 2.1656e-01, time/batch = 0.6987s	
1747/30650 (epoch 2.850), train_loss = 1.97169677, grad/param norm = 2.1358e-01, time/batch = 0.7015s	
1748/30650 (epoch 2.852), train_loss = 2.17126541, grad/param norm = 2.8230e-01, time/batch = 0.6968s	
1749/30650 (epoch 2.853), train_loss = 1.93639492, grad/param norm = 2.2653e-01, time/batch = 0.7004s	
1750/30650 (epoch 2.855), train_loss = 2.15165291, grad/param norm = 2.4786e-01, time/batch = 0.7221s	
1751/30650 (epoch 2.856), train_loss = 2.01236335, grad/param norm = 1.9804e-01, time/batch = 0.6903s	
1752/30650 (epoch 2.858), train_loss = 1.98414596, grad/param norm = 2.4104e-01, time/batch = 0.6754s	
1753/30650 (epoch 2.860), train_loss = 1.88741395, grad/param norm = 2.1375e-01, time/batch = 0.6740s	
1754/30650 (epoch 2.861), train_loss = 1.94083226, grad/param norm = 2.1362e-01, time/batch = 0.6753s	
1755/30650 (epoch 2.863), train_loss = 1.91009731, grad/param norm = 2.3066e-01, time/batch = 0.6747s	
1756/30650 (epoch 2.865), train_loss = 2.21677087, grad/param norm = 2.4448e-01, time/batch = 0.6789s	
1757/30650 (epoch 2.866), train_loss = 1.88881093, grad/param norm = 2.0729e-01, time/batch = 0.6768s	
1758/30650 (epoch 2.868), train_loss = 1.88940704, grad/param norm = 2.0590e-01, time/batch = 0.6807s	
1759/30650 (epoch 2.869), train_loss = 2.10778268, grad/param norm = 2.1828e-01, time/batch = 0.6775s	
1760/30650 (epoch 2.871), train_loss = 1.86677561, grad/param norm = 2.2698e-01, time/batch = 0.6782s	
1761/30650 (epoch 2.873), train_loss = 1.97843068, grad/param norm = 2.4712e-01, time/batch = 0.6932s	
1762/30650 (epoch 2.874), train_loss = 1.81145988, grad/param norm = 2.2281e-01, time/batch = 0.6798s	
1763/30650 (epoch 2.876), train_loss = 1.63846168, grad/param norm = 2.0223e-01, time/batch = 0.6768s	
1764/30650 (epoch 2.878), train_loss = 1.61689861, grad/param norm = 2.0777e-01, time/batch = 0.7002s	
1765/30650 (epoch 2.879), train_loss = 2.00780444, grad/param norm = 2.2800e-01, time/batch = 0.7161s	
1766/30650 (epoch 2.881), train_loss = 2.09349558, grad/param norm = 2.4725e-01, time/batch = 0.6769s	
1767/30650 (epoch 2.883), train_loss = 1.87260708, grad/param norm = 1.9082e-01, time/batch = 0.6758s	
1768/30650 (epoch 2.884), train_loss = 1.73584382, grad/param norm = 2.3251e-01, time/batch = 0.6780s	
1769/30650 (epoch 2.886), train_loss = 1.71993168, grad/param norm = 2.4652e-01, time/batch = 0.6797s	
1770/30650 (epoch 2.887), train_loss = 1.87948770, grad/param norm = 2.3079e-01, time/batch = 0.6798s	
1771/30650 (epoch 2.889), train_loss = 1.82217045, grad/param norm = 2.2065e-01, time/batch = 0.6837s	
1772/30650 (epoch 2.891), train_loss = 2.09681928, grad/param norm = 2.3948e-01, time/batch = 0.7085s	
1773/30650 (epoch 2.892), train_loss = 2.05263084, grad/param norm = 2.3659e-01, time/batch = 0.7061s	
1774/30650 (epoch 2.894), train_loss = 1.84192830, grad/param norm = 2.1300e-01, time/batch = 0.7107s	
1775/30650 (epoch 2.896), train_loss = 1.81582215, grad/param norm = 2.1518e-01, time/batch = 0.7131s	
1776/30650 (epoch 2.897), train_loss = 1.87559310, grad/param norm = 2.3493e-01, time/batch = 0.7073s	
1777/30650 (epoch 2.899), train_loss = 1.62267013, grad/param norm = 2.1189e-01, time/batch = 0.7095s	
1778/30650 (epoch 2.900), train_loss = 2.12848641, grad/param norm = 2.4770e-01, time/batch = 0.7155s	
1779/30650 (epoch 2.902), train_loss = 1.99666687, grad/param norm = 2.8106e-01, time/batch = 0.7224s	
1780/30650 (epoch 2.904), train_loss = 1.77306639, grad/param norm = 2.1556e-01, time/batch = 0.7213s	
1781/30650 (epoch 2.905), train_loss = 1.99881099, grad/param norm = 2.2940e-01, time/batch = 0.6923s	
1782/30650 (epoch 2.907), train_loss = 2.08900336, grad/param norm = 2.2992e-01, time/batch = 0.6985s	
1783/30650 (epoch 2.909), train_loss = 1.88170576, grad/param norm = 2.3980e-01, time/batch = 0.7224s	
1784/30650 (epoch 2.910), train_loss = 1.65709534, grad/param norm = 2.0152e-01, time/batch = 0.6926s	
1785/30650 (epoch 2.912), train_loss = 1.78704161, grad/param norm = 2.1744e-01, time/batch = 0.7089s	
1786/30650 (epoch 2.914), train_loss = 1.83596570, grad/param norm = 2.2564e-01, time/batch = 0.7162s	
1787/30650 (epoch 2.915), train_loss = 1.91059864, grad/param norm = 2.3541e-01, time/batch = 0.6945s	
1788/30650 (epoch 2.917), train_loss = 1.98797503, grad/param norm = 2.1720e-01, time/batch = 0.6991s	
1789/30650 (epoch 2.918), train_loss = 1.89148304, grad/param norm = 2.1269e-01, time/batch = 0.6872s	
1790/30650 (epoch 2.920), train_loss = 1.95705467, grad/param norm = 2.5817e-01, time/batch = 0.6866s	
1791/30650 (epoch 2.922), train_loss = 1.76560512, grad/param norm = 2.2033e-01, time/batch = 0.6950s	
1792/30650 (epoch 2.923), train_loss = 2.08075382, grad/param norm = 2.2251e-01, time/batch = 0.6846s	
1793/30650 (epoch 2.925), train_loss = 1.92701966, grad/param norm = 2.3748e-01, time/batch = 0.7218s	
1794/30650 (epoch 2.927), train_loss = 2.13132724, grad/param norm = 2.6507e-01, time/batch = 0.6932s	
1795/30650 (epoch 2.928), train_loss = 1.82648961, grad/param norm = 2.7014e-01, time/batch = 0.6978s	
1796/30650 (epoch 2.930), train_loss = 2.05694557, grad/param norm = 2.2310e-01, time/batch = 0.6877s	
1797/30650 (epoch 2.931), train_loss = 1.93503684, grad/param norm = 2.3473e-01, time/batch = 0.6801s	
1798/30650 (epoch 2.933), train_loss = 1.98116316, grad/param norm = 2.4303e-01, time/batch = 0.6853s	
1799/30650 (epoch 2.935), train_loss = 1.92692071, grad/param norm = 2.1675e-01, time/batch = 0.6860s	
1800/30650 (epoch 2.936), train_loss = 1.88650537, grad/param norm = 2.1621e-01, time/batch = 0.6785s	
1801/30650 (epoch 2.938), train_loss = 1.99884107, grad/param norm = 2.4113e-01, time/batch = 0.6848s	
1802/30650 (epoch 2.940), train_loss = 2.17306254, grad/param norm = 2.5269e-01, time/batch = 0.6884s	
1803/30650 (epoch 2.941), train_loss = 1.86734828, grad/param norm = 2.3059e-01, time/batch = 0.6883s	
1804/30650 (epoch 2.943), train_loss = 1.77551292, grad/param norm = 2.0197e-01, time/batch = 0.7022s	
1805/30650 (epoch 2.945), train_loss = 2.04473416, grad/param norm = 2.1492e-01, time/batch = 0.6818s	
1806/30650 (epoch 2.946), train_loss = 1.89568948, grad/param norm = 2.0445e-01, time/batch = 0.6919s	
1807/30650 (epoch 2.948), train_loss = 1.91829071, grad/param norm = 2.1394e-01, time/batch = 0.6853s	
1808/30650 (epoch 2.949), train_loss = 2.09949090, grad/param norm = 2.1799e-01, time/batch = 0.6868s	
1809/30650 (epoch 2.951), train_loss = 1.85216808, grad/param norm = 2.1331e-01, time/batch = 0.6855s	
1810/30650 (epoch 2.953), train_loss = 1.73672867, grad/param norm = 1.9549e-01, time/batch = 0.6857s	
1811/30650 (epoch 2.954), train_loss = 1.73804125, grad/param norm = 1.8343e-01, time/batch = 0.7006s	
1812/30650 (epoch 2.956), train_loss = 1.95970066, grad/param norm = 2.3354e-01, time/batch = 0.6869s	
1813/30650 (epoch 2.958), train_loss = 1.81600947, grad/param norm = 2.0261e-01, time/batch = 0.6798s	
1814/30650 (epoch 2.959), train_loss = 1.81968159, grad/param norm = 2.0149e-01, time/batch = 0.6820s	
1815/30650 (epoch 2.961), train_loss = 1.96152101, grad/param norm = 2.4537e-01, time/batch = 0.6869s	
1816/30650 (epoch 2.962), train_loss = 1.94512641, grad/param norm = 2.1042e-01, time/batch = 0.6901s	
1817/30650 (epoch 2.964), train_loss = 1.92366130, grad/param norm = 2.2097e-01, time/batch = 0.6830s	
1818/30650 (epoch 2.966), train_loss = 1.72991325, grad/param norm = 2.0881e-01, time/batch = 0.6906s	
1819/30650 (epoch 2.967), train_loss = 1.84299195, grad/param norm = 2.0613e-01, time/batch = 0.7004s	
1820/30650 (epoch 2.969), train_loss = 1.83553002, grad/param norm = 2.1134e-01, time/batch = 0.6874s	
1821/30650 (epoch 2.971), train_loss = 1.66416270, grad/param norm = 1.9993e-01, time/batch = 0.6811s	
1822/30650 (epoch 2.972), train_loss = 1.96008158, grad/param norm = 2.0975e-01, time/batch = 0.6810s	
1823/30650 (epoch 2.974), train_loss = 1.91642637, grad/param norm = 2.5050e-01, time/batch = 0.6810s	
1824/30650 (epoch 2.976), train_loss = 1.96363824, grad/param norm = 2.3597e-01, time/batch = 0.6826s	
1825/30650 (epoch 2.977), train_loss = 1.99638280, grad/param norm = 2.1442e-01, time/batch = 0.6797s	
1826/30650 (epoch 2.979), train_loss = 1.96541931, grad/param norm = 2.1532e-01, time/batch = 0.6815s	
1827/30650 (epoch 2.980), train_loss = 1.89318855, grad/param norm = 2.3296e-01, time/batch = 0.6816s	
1828/30650 (epoch 2.982), train_loss = 1.99732571, grad/param norm = 2.0411e-01, time/batch = 0.6817s	
1829/30650 (epoch 2.984), train_loss = 1.98916235, grad/param norm = 2.4394e-01, time/batch = 0.6773s	
1830/30650 (epoch 2.985), train_loss = 1.92729267, grad/param norm = 2.3041e-01, time/batch = 0.6831s	
1831/30650 (epoch 2.987), train_loss = 1.92593701, grad/param norm = 1.8874e-01, time/batch = 0.6809s	
1832/30650 (epoch 2.989), train_loss = 2.01038741, grad/param norm = 2.1179e-01, time/batch = 0.6801s	
1833/30650 (epoch 2.990), train_loss = 1.81129660, grad/param norm = 2.0456e-01, time/batch = 0.6803s	
1834/30650 (epoch 2.992), train_loss = 2.01443620, grad/param norm = 2.2934e-01, time/batch = 0.6779s	
1835/30650 (epoch 2.993), train_loss = 1.96896027, grad/param norm = 2.0800e-01, time/batch = 0.6779s	
1836/30650 (epoch 2.995), train_loss = 1.90599247, grad/param norm = 2.0659e-01, time/batch = 0.6827s	
1837/30650 (epoch 2.997), train_loss = 2.05499177, grad/param norm = 2.3485e-01, time/batch = 0.6809s	
1838/30650 (epoch 2.998), train_loss = 1.78248206, grad/param norm = 1.8551e-01, time/batch = 0.6816s	
1839/30650 (epoch 3.000), train_loss = 2.10693919, grad/param norm = 2.4681e-01, time/batch = 0.6826s	
1840/30650 (epoch 3.002), train_loss = 2.00269175, grad/param norm = 2.1802e-01, time/batch = 0.6800s	
1841/30650 (epoch 3.003), train_loss = 1.92023397, grad/param norm = 2.1293e-01, time/batch = 0.6850s	
1842/30650 (epoch 3.005), train_loss = 2.04440354, grad/param norm = 2.1031e-01, time/batch = 0.6854s	
1843/30650 (epoch 3.007), train_loss = 2.08724617, grad/param norm = 2.0069e-01, time/batch = 0.6977s	
1844/30650 (epoch 3.008), train_loss = 1.70187561, grad/param norm = 2.0767e-01, time/batch = 0.6986s	
1845/30650 (epoch 3.010), train_loss = 1.84506441, grad/param norm = 2.1174e-01, time/batch = 0.7043s	
1846/30650 (epoch 3.011), train_loss = 1.88820593, grad/param norm = 2.0387e-01, time/batch = 0.7042s	
1847/30650 (epoch 3.013), train_loss = 1.88403112, grad/param norm = 2.1890e-01, time/batch = 0.6935s	
1848/30650 (epoch 3.015), train_loss = 1.97763757, grad/param norm = 2.0547e-01, time/batch = 0.6915s	
1849/30650 (epoch 3.016), train_loss = 2.01451105, grad/param norm = 2.1219e-01, time/batch = 0.6961s	
1850/30650 (epoch 3.018), train_loss = 2.08027417, grad/param norm = 2.3143e-01, time/batch = 0.6879s	
1851/30650 (epoch 3.020), train_loss = 2.09750107, grad/param norm = 2.3313e-01, time/batch = 0.7257s	
1852/30650 (epoch 3.021), train_loss = 1.91274919, grad/param norm = 2.1023e-01, time/batch = 0.7167s	
1853/30650 (epoch 3.023), train_loss = 1.97860552, grad/param norm = 2.0832e-01, time/batch = 0.7129s	
1854/30650 (epoch 3.024), train_loss = 2.02151421, grad/param norm = 2.3659e-01, time/batch = 0.6857s	
1855/30650 (epoch 3.026), train_loss = 1.89853357, grad/param norm = 1.8687e-01, time/batch = 0.7167s	
1856/30650 (epoch 3.028), train_loss = 1.76394826, grad/param norm = 1.9088e-01, time/batch = 0.7210s	
1857/30650 (epoch 3.029), train_loss = 2.06126434, grad/param norm = 2.3518e-01, time/batch = 0.7120s	
1858/30650 (epoch 3.031), train_loss = 2.19094708, grad/param norm = 2.4233e-01, time/batch = 0.6914s	
1859/30650 (epoch 3.033), train_loss = 1.89186002, grad/param norm = 1.9085e-01, time/batch = 0.6994s	
1860/30650 (epoch 3.034), train_loss = 1.90684776, grad/param norm = 2.1861e-01, time/batch = 0.7040s	
1861/30650 (epoch 3.036), train_loss = 1.73355420, grad/param norm = 1.8941e-01, time/batch = 0.6913s	
1862/30650 (epoch 3.038), train_loss = 2.22300080, grad/param norm = 2.2513e-01, time/batch = 0.6929s	
1863/30650 (epoch 3.039), train_loss = 1.89101794, grad/param norm = 2.3257e-01, time/batch = 0.6805s	
1864/30650 (epoch 3.041), train_loss = 2.02601110, grad/param norm = 2.3003e-01, time/batch = 0.6770s	
1865/30650 (epoch 3.042), train_loss = 1.93976694, grad/param norm = 2.3341e-01, time/batch = 0.7178s	
1866/30650 (epoch 3.044), train_loss = 1.79350748, grad/param norm = 2.0412e-01, time/batch = 0.7049s	
1867/30650 (epoch 3.046), train_loss = 1.83265034, grad/param norm = 2.1817e-01, time/batch = 0.7216s	
1868/30650 (epoch 3.047), train_loss = 1.83805400, grad/param norm = 2.2867e-01, time/batch = 0.7219s	
1869/30650 (epoch 3.049), train_loss = 1.81001789, grad/param norm = 2.2540e-01, time/batch = 0.7229s	
1870/30650 (epoch 3.051), train_loss = 2.10889967, grad/param norm = 2.1946e-01, time/batch = 0.7061s	
1871/30650 (epoch 3.052), train_loss = 1.84882271, grad/param norm = 2.3057e-01, time/batch = 0.6798s	
1872/30650 (epoch 3.054), train_loss = 2.04626752, grad/param norm = 2.6371e-01, time/batch = 0.6794s	
1873/30650 (epoch 3.055), train_loss = 1.86743291, grad/param norm = 2.2675e-01, time/batch = 0.6781s	
1874/30650 (epoch 3.057), train_loss = 1.81304317, grad/param norm = 2.1132e-01, time/batch = 0.6791s	
1875/30650 (epoch 3.059), train_loss = 1.91229578, grad/param norm = 2.1135e-01, time/batch = 0.6794s	
1876/30650 (epoch 3.060), train_loss = 2.00141549, grad/param norm = 2.3271e-01, time/batch = 0.6881s	
1877/30650 (epoch 3.062), train_loss = 2.30358927, grad/param norm = 2.4396e-01, time/batch = 0.6823s	
1878/30650 (epoch 3.064), train_loss = 2.08601060, grad/param norm = 2.6168e-01, time/batch = 0.6805s	
1879/30650 (epoch 3.065), train_loss = 1.95457127, grad/param norm = 2.1870e-01, time/batch = 0.7039s	
1880/30650 (epoch 3.067), train_loss = 2.06748066, grad/param norm = 2.0707e-01, time/batch = 0.7124s	
1881/30650 (epoch 3.069), train_loss = 2.01984032, grad/param norm = 1.9339e-01, time/batch = 0.6783s	
1882/30650 (epoch 3.070), train_loss = 1.85537587, grad/param norm = 2.0871e-01, time/batch = 0.6769s	
1883/30650 (epoch 3.072), train_loss = 1.90017976, grad/param norm = 2.0024e-01, time/batch = 0.6778s	
1884/30650 (epoch 3.073), train_loss = 1.61532719, grad/param norm = 1.9384e-01, time/batch = 0.6790s	
1885/30650 (epoch 3.075), train_loss = 1.90249832, grad/param norm = 2.2578e-01, time/batch = 0.6776s	
1886/30650 (epoch 3.077), train_loss = 1.77793245, grad/param norm = 2.3298e-01, time/batch = 0.6791s	
1887/30650 (epoch 3.078), train_loss = 2.08940112, grad/param norm = 2.2988e-01, time/batch = 0.6773s	
1888/30650 (epoch 3.080), train_loss = 2.09773638, grad/param norm = 2.2985e-01, time/batch = 0.6768s	
1889/30650 (epoch 3.082), train_loss = 1.93322963, grad/param norm = 2.2751e-01, time/batch = 0.6782s	
1890/30650 (epoch 3.083), train_loss = 1.81740747, grad/param norm = 2.1559e-01, time/batch = 0.6939s	
1891/30650 (epoch 3.085), train_loss = 1.97132753, grad/param norm = 2.1595e-01, time/batch = 0.6884s	
1892/30650 (epoch 3.086), train_loss = 1.81634641, grad/param norm = 2.0271e-01, time/batch = 0.6919s	
1893/30650 (epoch 3.088), train_loss = 1.93242569, grad/param norm = 2.2695e-01, time/batch = 0.6950s	
1894/30650 (epoch 3.090), train_loss = 1.83477572, grad/param norm = 2.3458e-01, time/batch = 0.7246s	
1895/30650 (epoch 3.091), train_loss = 1.83663473, grad/param norm = 2.0228e-01, time/batch = 0.6965s	
1896/30650 (epoch 3.093), train_loss = 1.91388605, grad/param norm = 2.0467e-01, time/batch = 0.6814s	
1897/30650 (epoch 3.095), train_loss = 1.81531359, grad/param norm = 2.1058e-01, time/batch = 0.6807s	
1898/30650 (epoch 3.096), train_loss = 1.69481102, grad/param norm = 2.1904e-01, time/batch = 0.6855s	
1899/30650 (epoch 3.098), train_loss = 1.94444517, grad/param norm = 2.0482e-01, time/batch = 0.6814s	
1900/30650 (epoch 3.100), train_loss = 1.95941486, grad/param norm = 2.3854e-01, time/batch = 0.6866s	
1901/30650 (epoch 3.101), train_loss = 1.88724339, grad/param norm = 2.2737e-01, time/batch = 0.6825s	
1902/30650 (epoch 3.103), train_loss = 2.04445295, grad/param norm = 2.1623e-01, time/batch = 0.6788s	
1903/30650 (epoch 3.104), train_loss = 1.75872324, grad/param norm = 2.0032e-01, time/batch = 0.6801s	
1904/30650 (epoch 3.106), train_loss = 1.97054198, grad/param norm = 2.1758e-01, time/batch = 0.6801s	
1905/30650 (epoch 3.108), train_loss = 2.15492670, grad/param norm = 2.6501e-01, time/batch = 0.6835s	
1906/30650 (epoch 3.109), train_loss = 1.76244072, grad/param norm = 2.1295e-01, time/batch = 0.6834s	
1907/30650 (epoch 3.111), train_loss = 1.87035301, grad/param norm = 2.2448e-01, time/batch = 0.6786s	
1908/30650 (epoch 3.113), train_loss = 1.77564004, grad/param norm = 2.0633e-01, time/batch = 0.7009s	
1909/30650 (epoch 3.114), train_loss = 1.86967402, grad/param norm = 1.8997e-01, time/batch = 0.7138s	
1910/30650 (epoch 3.116), train_loss = 2.02809864, grad/param norm = 2.2124e-01, time/batch = 0.6914s	
1911/30650 (epoch 3.117), train_loss = 1.94100546, grad/param norm = 1.9232e-01, time/batch = 0.6831s	
1912/30650 (epoch 3.119), train_loss = 1.97886771, grad/param norm = 2.2414e-01, time/batch = 0.6809s	
1913/30650 (epoch 3.121), train_loss = 2.20902714, grad/param norm = 2.1938e-01, time/batch = 0.6798s	
1914/30650 (epoch 3.122), train_loss = 1.98316369, grad/param norm = 2.2985e-01, time/batch = 0.6794s	
1915/30650 (epoch 3.124), train_loss = 1.93876981, grad/param norm = 2.3693e-01, time/batch = 0.6790s	
1916/30650 (epoch 3.126), train_loss = 1.82811194, grad/param norm = 2.3269e-01, time/batch = 0.6786s	
1917/30650 (epoch 3.127), train_loss = 1.99283542, grad/param norm = 2.3871e-01, time/batch = 0.6784s	
1918/30650 (epoch 3.129), train_loss = 1.93773292, grad/param norm = 2.0835e-01, time/batch = 0.6892s	
1919/30650 (epoch 3.131), train_loss = 2.32086993, grad/param norm = 2.2354e-01, time/batch = 0.7055s	
1920/30650 (epoch 3.132), train_loss = 1.89782829, grad/param norm = 2.1737e-01, time/batch = 0.7126s	
1921/30650 (epoch 3.134), train_loss = 1.68842685, grad/param norm = 2.0055e-01, time/batch = 0.7137s	
1922/30650 (epoch 3.135), train_loss = 1.87597607, grad/param norm = 1.9240e-01, time/batch = 0.7022s	
1923/30650 (epoch 3.137), train_loss = 2.00807594, grad/param norm = 2.3228e-01, time/batch = 0.6954s	
1924/30650 (epoch 3.139), train_loss = 1.75603886, grad/param norm = 2.1155e-01, time/batch = 0.6757s	
1925/30650 (epoch 3.140), train_loss = 1.91360370, grad/param norm = 2.0609e-01, time/batch = 0.6761s	
1926/30650 (epoch 3.142), train_loss = 1.76174954, grad/param norm = 1.9344e-01, time/batch = 0.6798s	
1927/30650 (epoch 3.144), train_loss = 1.64058876, grad/param norm = 2.2730e-01, time/batch = 0.6888s	
1928/30650 (epoch 3.145), train_loss = 1.73487156, grad/param norm = 1.9476e-01, time/batch = 0.6797s	
1929/30650 (epoch 3.147), train_loss = 1.80943531, grad/param norm = 2.3157e-01, time/batch = 0.6767s	
1930/30650 (epoch 3.148), train_loss = 1.75943009, grad/param norm = 2.0452e-01, time/batch = 0.6832s	
1931/30650 (epoch 3.150), train_loss = 1.86742984, grad/param norm = 2.2087e-01, time/batch = 0.6776s	
1932/30650 (epoch 3.152), train_loss = 1.79203083, grad/param norm = 1.9147e-01, time/batch = 0.6794s	
1933/30650 (epoch 3.153), train_loss = 1.93007785, grad/param norm = 2.2696e-01, time/batch = 0.6769s	
1934/30650 (epoch 3.155), train_loss = 1.98104611, grad/param norm = 2.0076e-01, time/batch = 0.6808s	
1935/30650 (epoch 3.157), train_loss = 1.84378636, grad/param norm = 1.9307e-01, time/batch = 0.6777s	
1936/30650 (epoch 3.158), train_loss = 1.70361137, grad/param norm = 2.0676e-01, time/batch = 0.6775s	
1937/30650 (epoch 3.160), train_loss = 1.77438021, grad/param norm = 1.9840e-01, time/batch = 0.7028s	
1938/30650 (epoch 3.162), train_loss = 1.86770539, grad/param norm = 2.2001e-01, time/batch = 0.7155s	
1939/30650 (epoch 3.163), train_loss = 1.87113566, grad/param norm = 2.1233e-01, time/batch = 0.6853s	
1940/30650 (epoch 3.165), train_loss = 2.09657118, grad/param norm = 2.3480e-01, time/batch = 0.6797s	
1941/30650 (epoch 3.166), train_loss = 2.04848761, grad/param norm = 2.2405e-01, time/batch = 0.6822s	
1942/30650 (epoch 3.168), train_loss = 1.95051020, grad/param norm = 2.4442e-01, time/batch = 0.6792s	
1943/30650 (epoch 3.170), train_loss = 1.62304850, grad/param norm = 1.9181e-01, time/batch = 0.6777s	
1944/30650 (epoch 3.171), train_loss = 1.85796722, grad/param norm = 2.1654e-01, time/batch = 0.6793s	
1945/30650 (epoch 3.173), train_loss = 1.71828997, grad/param norm = 2.0566e-01, time/batch = 0.6784s	
1946/30650 (epoch 3.175), train_loss = 1.96610677, grad/param norm = 2.0367e-01, time/batch = 0.6916s	
1947/30650 (epoch 3.176), train_loss = 1.94681845, grad/param norm = 2.2453e-01, time/batch = 0.6905s	
1948/30650 (epoch 3.178), train_loss = 2.01317115, grad/param norm = 2.5222e-01, time/batch = 0.6910s	
1949/30650 (epoch 3.179), train_loss = 2.13073252, grad/param norm = 2.1090e-01, time/batch = 0.6861s	
1950/30650 (epoch 3.181), train_loss = 2.11347429, grad/param norm = 2.2451e-01, time/batch = 0.6806s	
1951/30650 (epoch 3.183), train_loss = 1.92328346, grad/param norm = 2.2311e-01, time/batch = 0.6894s	
1952/30650 (epoch 3.184), train_loss = 1.75518960, grad/param norm = 2.2726e-01, time/batch = 0.7225s	
1953/30650 (epoch 3.186), train_loss = 1.89245783, grad/param norm = 2.3346e-01, time/batch = 0.6901s	
1954/30650 (epoch 3.188), train_loss = 1.83071470, grad/param norm = 2.0817e-01, time/batch = 0.6761s	
1955/30650 (epoch 3.189), train_loss = 1.82739522, grad/param norm = 2.0934e-01, time/batch = 0.6786s	
1956/30650 (epoch 3.191), train_loss = 1.84886598, grad/param norm = 2.0091e-01, time/batch = 0.6770s	
1957/30650 (epoch 3.192), train_loss = 1.82612368, grad/param norm = 1.8461e-01, time/batch = 0.6786s	
1958/30650 (epoch 3.194), train_loss = 1.85314411, grad/param norm = 2.2819e-01, time/batch = 0.6769s	
1959/30650 (epoch 3.196), train_loss = 1.92234352, grad/param norm = 2.3369e-01, time/batch = 0.6790s	
1960/30650 (epoch 3.197), train_loss = 1.88931150, grad/param norm = 2.2987e-01, time/batch = 0.6760s	
1961/30650 (epoch 3.199), train_loss = 1.80394452, grad/param norm = 2.1762e-01, time/batch = 0.6801s	
1962/30650 (epoch 3.201), train_loss = 1.77258062, grad/param norm = 2.1397e-01, time/batch = 0.6805s	
1963/30650 (epoch 3.202), train_loss = 1.81497899, grad/param norm = 2.0203e-01, time/batch = 0.6865s	
1964/30650 (epoch 3.204), train_loss = 1.76405309, grad/param norm = 1.9080e-01, time/batch = 0.6782s	
1965/30650 (epoch 3.206), train_loss = 1.80049696, grad/param norm = 1.9372e-01, time/batch = 0.6786s	
1966/30650 (epoch 3.207), train_loss = 1.89837855, grad/param norm = 1.9744e-01, time/batch = 0.6770s	
1967/30650 (epoch 3.209), train_loss = 1.70944156, grad/param norm = 1.8897e-01, time/batch = 0.6751s	
1968/30650 (epoch 3.210), train_loss = 1.78049557, grad/param norm = 2.1345e-01, time/batch = 0.6760s	
1969/30650 (epoch 3.212), train_loss = 2.03734949, grad/param norm = 2.3979e-01, time/batch = 0.6788s	
1970/30650 (epoch 3.214), train_loss = 2.10903343, grad/param norm = 2.0634e-01, time/batch = 0.6938s	
1971/30650 (epoch 3.215), train_loss = 1.85356559, grad/param norm = 1.8758e-01, time/batch = 0.6947s	
1972/30650 (epoch 3.217), train_loss = 1.81952286, grad/param norm = 2.0311e-01, time/batch = 0.6848s	
1973/30650 (epoch 3.219), train_loss = 1.93770225, grad/param norm = 2.1483e-01, time/batch = 0.6798s	
1974/30650 (epoch 3.220), train_loss = 1.86097222, grad/param norm = 2.1488e-01, time/batch = 0.6774s	
1975/30650 (epoch 3.222), train_loss = 1.76632384, grad/param norm = 2.3741e-01, time/batch = 0.6781s	
1976/30650 (epoch 3.223), train_loss = 1.91917012, grad/param norm = 2.1732e-01, time/batch = 0.6780s	
1977/30650 (epoch 3.225), train_loss = 1.81622180, grad/param norm = 1.9782e-01, time/batch = 0.6893s	
1978/30650 (epoch 3.227), train_loss = 2.01451883, grad/param norm = 2.0128e-01, time/batch = 0.6931s	
1979/30650 (epoch 3.228), train_loss = 1.96217324, grad/param norm = 2.0083e-01, time/batch = 0.6996s	
1980/30650 (epoch 3.230), train_loss = 1.87943718, grad/param norm = 2.0179e-01, time/batch = 0.6975s	
1981/30650 (epoch 3.232), train_loss = 1.87014711, grad/param norm = 2.2554e-01, time/batch = 0.6792s	
1982/30650 (epoch 3.233), train_loss = 1.93571255, grad/param norm = 2.1243e-01, time/batch = 0.6777s	
1983/30650 (epoch 3.235), train_loss = 1.96070391, grad/param norm = 2.1562e-01, time/batch = 0.6762s	
1984/30650 (epoch 3.237), train_loss = 2.01683793, grad/param norm = 1.9598e-01, time/batch = 0.6797s	
1985/30650 (epoch 3.238), train_loss = 2.18818053, grad/param norm = 2.2027e-01, time/batch = 0.7065s	
1986/30650 (epoch 3.240), train_loss = 1.95358670, grad/param norm = 2.0280e-01, time/batch = 0.6922s	
1987/30650 (epoch 3.241), train_loss = 1.91002818, grad/param norm = 1.7926e-01, time/batch = 0.6773s	
1988/30650 (epoch 3.243), train_loss = 2.05527213, grad/param norm = 2.0213e-01, time/batch = 0.6768s	
1989/30650 (epoch 3.245), train_loss = 1.98908804, grad/param norm = 2.0564e-01, time/batch = 0.6789s	
1990/30650 (epoch 3.246), train_loss = 1.84441482, grad/param norm = 2.1256e-01, time/batch = 0.6797s	
1991/30650 (epoch 3.248), train_loss = 1.95605751, grad/param norm = 2.1822e-01, time/batch = 0.6847s	
1992/30650 (epoch 3.250), train_loss = 1.90148670, grad/param norm = 1.9717e-01, time/batch = 0.6840s	
1993/30650 (epoch 3.251), train_loss = 1.83996620, grad/param norm = 2.2592e-01, time/batch = 0.6805s	
1994/30650 (epoch 3.253), train_loss = 1.95681698, grad/param norm = 2.4731e-01, time/batch = 0.6777s	
1995/30650 (epoch 3.254), train_loss = 1.92495319, grad/param norm = 2.1990e-01, time/batch = 0.6783s	
1996/30650 (epoch 3.256), train_loss = 1.84510844, grad/param norm = 2.1888e-01, time/batch = 0.6782s	
1997/30650 (epoch 3.258), train_loss = 1.88858119, grad/param norm = 2.0407e-01, time/batch = 0.6779s	
1998/30650 (epoch 3.259), train_loss = 1.83765315, grad/param norm = 1.9698e-01, time/batch = 0.6784s	
1999/30650 (epoch 3.261), train_loss = 1.91048299, grad/param norm = 1.9333e-01, time/batch = 0.6790s	
evaluating loss over split index 2	
1/33...	
2/33...	
3/33...	
4/33...	
5/33...	
6/33...	
7/33...	
8/33...	
9/33...	
10/33...	
11/33...	
12/33...	
13/33...	
14/33...	
15/33...	
16/33...	
17/33...	
18/33...	
19/33...	
20/33...	
21/33...	
22/33...	
23/33...	
24/33...	
25/33...	
26/33...	
27/33...	
28/33...	
29/33...	
30/33...	
31/33...	
32/33...	
33/33...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_nicole_epoch3.26_2.1042.t7	
2000/30650 (epoch 3.263), train_loss = 1.84375189, grad/param norm = 2.0895e-01, time/batch = 0.7208s	
2001/30650 (epoch 3.264), train_loss = 2.00636236, grad/param norm = 2.1621e-01, time/batch = 0.7064s	
2002/30650 (epoch 3.266), train_loss = 1.84121278, grad/param norm = 2.1907e-01, time/batch = 0.6872s	
2003/30650 (epoch 3.268), train_loss = 1.76472185, grad/param norm = 2.1470e-01, time/batch = 0.6788s	
2004/30650 (epoch 3.269), train_loss = 1.74614043, grad/param norm = 2.0517e-01, time/batch = 0.6806s	
2005/30650 (epoch 3.271), train_loss = 1.75989934, grad/param norm = 2.0510e-01, time/batch = 0.7206s	
2006/30650 (epoch 3.272), train_loss = 1.69501584, grad/param norm = 2.1552e-01, time/batch = 0.7069s	
2007/30650 (epoch 3.274), train_loss = 1.71592041, grad/param norm = 1.8886e-01, time/batch = 0.6816s	
2008/30650 (epoch 3.276), train_loss = 1.64330996, grad/param norm = 1.9616e-01, time/batch = 0.6823s	
2009/30650 (epoch 3.277), train_loss = 1.80101438, grad/param norm = 2.0319e-01, time/batch = 0.6799s	
2010/30650 (epoch 3.279), train_loss = 1.88804767, grad/param norm = 2.1790e-01, time/batch = 0.6790s	
2011/30650 (epoch 3.281), train_loss = 1.94350472, grad/param norm = 2.0996e-01, time/batch = 0.6800s	
2012/30650 (epoch 3.282), train_loss = 1.73457827, grad/param norm = 2.3828e-01, time/batch = 0.6817s	
2013/30650 (epoch 3.284), train_loss = 2.00747213, grad/param norm = 2.3439e-01, time/batch = 0.6804s	
2014/30650 (epoch 3.285), train_loss = 1.75643329, grad/param norm = 2.7235e-01, time/batch = 0.6786s	
2015/30650 (epoch 3.287), train_loss = 1.95985946, grad/param norm = 1.9954e-01, time/batch = 0.7063s	
2016/30650 (epoch 3.289), train_loss = 1.96125648, grad/param norm = 2.2366e-01, time/batch = 0.7109s	
2017/30650 (epoch 3.290), train_loss = 1.98720059, grad/param norm = 2.3065e-01, time/batch = 0.6809s	
2018/30650 (epoch 3.292), train_loss = 1.98705667, grad/param norm = 2.0216e-01, time/batch = 0.6795s	
2019/30650 (epoch 3.294), train_loss = 1.68487235, grad/param norm = 2.1766e-01, time/batch = 0.6805s	
2020/30650 (epoch 3.295), train_loss = 1.70858431, grad/param norm = 1.8946e-01, time/batch = 0.6840s	
2021/30650 (epoch 3.297), train_loss = 1.63473765, grad/param norm = 1.8394e-01, time/batch = 0.6814s	
2022/30650 (epoch 3.299), train_loss = 1.72380347, grad/param norm = 1.9271e-01, time/batch = 0.6836s	
2023/30650 (epoch 3.300), train_loss = 1.81061725, grad/param norm = 1.9131e-01, time/batch = 0.6803s	
2024/30650 (epoch 3.302), train_loss = 1.81001802, grad/param norm = 2.0293e-01, time/batch = 0.6797s	
2025/30650 (epoch 3.303), train_loss = 1.74031251, grad/param norm = 2.1320e-01, time/batch = 0.6797s	
2026/30650 (epoch 3.305), train_loss = 1.96568721, grad/param norm = 2.0225e-01, time/batch = 0.6968s	
2027/30650 (epoch 3.307), train_loss = 1.80624760, grad/param norm = 2.1158e-01, time/batch = 0.6802s	
2028/30650 (epoch 3.308), train_loss = 1.79712786, grad/param norm = 2.2382e-01, time/batch = 0.6799s	
2029/30650 (epoch 3.310), train_loss = 1.93245874, grad/param norm = 2.6168e-01, time/batch = 0.6914s	
2030/30650 (epoch 3.312), train_loss = 1.85118266, grad/param norm = 2.0692e-01, time/batch = 0.7215s	
2031/30650 (epoch 3.313), train_loss = 1.97941226, grad/param norm = 2.1933e-01, time/batch = 0.6928s	
2032/30650 (epoch 3.315), train_loss = 1.86549929, grad/param norm = 2.0425e-01, time/batch = 0.6802s	
2033/30650 (epoch 3.316), train_loss = 1.84310771, grad/param norm = 2.0926e-01, time/batch = 0.6820s	
2034/30650 (epoch 3.318), train_loss = 1.96158632, grad/param norm = 2.2942e-01, time/batch = 0.6786s	
2035/30650 (epoch 3.320), train_loss = 1.95414585, grad/param norm = 2.3053e-01, time/batch = 0.6887s	
2036/30650 (epoch 3.321), train_loss = 1.98857339, grad/param norm = 2.1389e-01, time/batch = 0.6835s	
2037/30650 (epoch 3.323), train_loss = 1.70383942, grad/param norm = 2.0635e-01, time/batch = 0.6829s	
2038/30650 (epoch 3.325), train_loss = 1.91388861, grad/param norm = 2.2010e-01, time/batch = 0.6810s	
2039/30650 (epoch 3.326), train_loss = 1.79300383, grad/param norm = 2.1081e-01, time/batch = 0.6790s	
2040/30650 (epoch 3.328), train_loss = 1.72335481, grad/param norm = 2.1857e-01, time/batch = 0.6775s	
2041/30650 (epoch 3.330), train_loss = 1.91823989, grad/param norm = 2.0836e-01, time/batch = 0.6876s	
2042/30650 (epoch 3.331), train_loss = 2.03511124, grad/param norm = 2.2459e-01, time/batch = 0.6798s	
2043/30650 (epoch 3.333), train_loss = 1.91557524, grad/param norm = 1.8810e-01, time/batch = 0.6813s	
2044/30650 (epoch 3.334), train_loss = 1.98634256, grad/param norm = 2.0638e-01, time/batch = 0.7054s	
2045/30650 (epoch 3.336), train_loss = 1.77709235, grad/param norm = 2.0014e-01, time/batch = 0.7118s	
2046/30650 (epoch 3.338), train_loss = 2.19646956, grad/param norm = 2.2295e-01, time/batch = 0.6796s	
2047/30650 (epoch 3.339), train_loss = 2.18813657, grad/param norm = 2.1047e-01, time/batch = 0.6777s	
2048/30650 (epoch 3.341), train_loss = 1.93155229, grad/param norm = 2.1016e-01, time/batch = 0.6777s	
2049/30650 (epoch 3.343), train_loss = 1.81522602, grad/param norm = 2.0170e-01, time/batch = 0.6777s	
2050/30650 (epoch 3.344), train_loss = 2.00531630, grad/param norm = 2.2033e-01, time/batch = 0.6775s	
2051/30650 (epoch 3.346), train_loss = 2.03586720, grad/param norm = 2.0319e-01, time/batch = 0.6818s	
2052/30650 (epoch 3.347), train_loss = 1.85545917, grad/param norm = 2.0222e-01, time/batch = 0.6794s	
2053/30650 (epoch 3.349), train_loss = 1.77431212, grad/param norm = 1.9757e-01, time/batch = 0.6775s	
2054/30650 (epoch 3.351), train_loss = 1.83559775, grad/param norm = 2.1712e-01, time/batch = 0.6776s	
2055/30650 (epoch 3.352), train_loss = 2.02303135, grad/param norm = 2.1393e-01, time/batch = 0.6939s	
2056/30650 (epoch 3.354), train_loss = 1.74469929, grad/param norm = 2.2179e-01, time/batch = 0.6848s	
2057/30650 (epoch 3.356), train_loss = 1.72628986, grad/param norm = 2.1744e-01, time/batch = 0.6921s	
2058/30650 (epoch 3.357), train_loss = 1.83656099, grad/param norm = 2.3005e-01, time/batch = 0.6850s	
2059/30650 (epoch 3.359), train_loss = 1.83608668, grad/param norm = 2.0019e-01, time/batch = 0.7224s	
2060/30650 (epoch 3.361), train_loss = 1.95934949, grad/param norm = 2.1896e-01, time/batch = 0.6923s	
2061/30650 (epoch 3.362), train_loss = 1.87013292, grad/param norm = 1.9427e-01, time/batch = 0.6805s	
2062/30650 (epoch 3.364), train_loss = 1.81848734, grad/param norm = 1.9966e-01, time/batch = 0.6811s	
2063/30650 (epoch 3.365), train_loss = 2.03620172, grad/param norm = 2.2459e-01, time/batch = 0.6797s	
2064/30650 (epoch 3.367), train_loss = 1.87682886, grad/param norm = 1.9108e-01, time/batch = 0.6798s	
2065/30650 (epoch 3.369), train_loss = 1.77970239, grad/param norm = 1.9400e-01, time/batch = 0.6763s	
2066/30650 (epoch 3.370), train_loss = 1.99434301, grad/param norm = 2.1062e-01, time/batch = 0.6785s	
2067/30650 (epoch 3.372), train_loss = 1.98583614, grad/param norm = 2.1755e-01, time/batch = 0.6813s	
2068/30650 (epoch 3.374), train_loss = 1.85408878, grad/param norm = 2.4316e-01, time/batch = 0.6782s	
2069/30650 (epoch 3.375), train_loss = 1.94679928, grad/param norm = 2.3865e-01, time/batch = 0.6806s	
2070/30650 (epoch 3.377), train_loss = 1.92360098, grad/param norm = 2.0259e-01, time/batch = 0.6828s	
2071/30650 (epoch 3.378), train_loss = 1.89611215, grad/param norm = 2.3135e-01, time/batch = 0.6793s	
2072/30650 (epoch 3.380), train_loss = 1.99084006, grad/param norm = 2.1550e-01, time/batch = 0.6777s	
2073/30650 (epoch 3.382), train_loss = 1.83212638, grad/param norm = 2.2884e-01, time/batch = 0.7045s	
2074/30650 (epoch 3.383), train_loss = 1.88000229, grad/param norm = 2.0748e-01, time/batch = 0.7152s	
2075/30650 (epoch 3.385), train_loss = 1.96058083, grad/param norm = 2.2860e-01, time/batch = 0.6779s	
2076/30650 (epoch 3.387), train_loss = 1.69729662, grad/param norm = 2.1555e-01, time/batch = 0.6866s	
2077/30650 (epoch 3.388), train_loss = 1.94880658, grad/param norm = 2.0415e-01, time/batch = 0.6776s	
2078/30650 (epoch 3.390), train_loss = 1.56123119, grad/param norm = 1.8509e-01, time/batch = 0.6785s	
2079/30650 (epoch 3.392), train_loss = 1.71144920, grad/param norm = 2.0748e-01, time/batch = 0.6770s	
2080/30650 (epoch 3.393), train_loss = 1.67193887, grad/param norm = 1.8801e-01, time/batch = 0.6808s	
2081/30650 (epoch 3.395), train_loss = 1.78987492, grad/param norm = 1.8756e-01, time/batch = 0.6814s	
2082/30650 (epoch 3.396), train_loss = 1.80488268, grad/param norm = 2.0190e-01, time/batch = 0.6790s	
2083/30650 (epoch 3.398), train_loss = 1.84945006, grad/param norm = 2.0461e-01, time/batch = 0.6913s	
2084/30650 (epoch 3.400), train_loss = 1.87544964, grad/param norm = 2.2315e-01, time/batch = 0.6760s	
2085/30650 (epoch 3.401), train_loss = 1.64310965, grad/param norm = 2.0132e-01, time/batch = 0.6811s	
2086/30650 (epoch 3.403), train_loss = 1.85469933, grad/param norm = 2.1606e-01, time/batch = 0.6802s	
2087/30650 (epoch 3.405), train_loss = 1.84922146, grad/param norm = 2.3121e-01, time/batch = 0.6760s	
2088/30650 (epoch 3.406), train_loss = 1.76352180, grad/param norm = 2.1703e-01, time/batch = 0.7202s	
2089/30650 (epoch 3.408), train_loss = 1.87708836, grad/param norm = 2.0328e-01, time/batch = 0.6985s	
2090/30650 (epoch 3.409), train_loss = 2.01104167, grad/param norm = 2.3638e-01, time/batch = 0.6831s	
2091/30650 (epoch 3.411), train_loss = 1.86075342, grad/param norm = 2.2194e-01, time/batch = 0.7091s	
2092/30650 (epoch 3.413), train_loss = 1.69831447, grad/param norm = 1.9461e-01, time/batch = 0.6814s	
2093/30650 (epoch 3.414), train_loss = 1.90694669, grad/param norm = 2.1477e-01, time/batch = 0.6768s	
2094/30650 (epoch 3.416), train_loss = 1.82778071, grad/param norm = 2.0243e-01, time/batch = 0.6756s	
2095/30650 (epoch 3.418), train_loss = 1.72104830, grad/param norm = 1.9606e-01, time/batch = 0.6773s	
2096/30650 (epoch 3.419), train_loss = 1.92121072, grad/param norm = 2.2330e-01, time/batch = 0.6777s	
2097/30650 (epoch 3.421), train_loss = 1.74209942, grad/param norm = 2.2620e-01, time/batch = 0.6771s	
2098/30650 (epoch 3.423), train_loss = 1.81014363, grad/param norm = 2.1829e-01, time/batch = 0.6772s	
2099/30650 (epoch 3.424), train_loss = 2.10439902, grad/param norm = 2.2060e-01, time/batch = 0.6771s	
2100/30650 (epoch 3.426), train_loss = 1.67793884, grad/param norm = 2.0930e-01, time/batch = 0.6800s	
2101/30650 (epoch 3.427), train_loss = 1.88089880, grad/param norm = 2.3124e-01, time/batch = 0.6788s	
2102/30650 (epoch 3.429), train_loss = 1.86394913, grad/param norm = 2.2334e-01, time/batch = 0.6974s	
2103/30650 (epoch 3.431), train_loss = 1.94239471, grad/param norm = 2.3154e-01, time/batch = 0.7192s	
2104/30650 (epoch 3.432), train_loss = 2.04004680, grad/param norm = 2.3439e-01, time/batch = 0.6766s	
2105/30650 (epoch 3.434), train_loss = 1.91103507, grad/param norm = 1.8616e-01, time/batch = 0.6772s	
2106/30650 (epoch 3.436), train_loss = 1.88670198, grad/param norm = 2.1231e-01, time/batch = 0.6768s	
2107/30650 (epoch 3.437), train_loss = 1.92769225, grad/param norm = 2.2431e-01, time/batch = 0.6801s	
2108/30650 (epoch 3.439), train_loss = 1.57923009, grad/param norm = 1.9216e-01, time/batch = 0.6787s	
2109/30650 (epoch 3.440), train_loss = 1.80409133, grad/param norm = 2.2271e-01, time/batch = 0.6753s	
2110/30650 (epoch 3.442), train_loss = 1.61687156, grad/param norm = 2.0303e-01, time/batch = 0.6762s	
2111/30650 (epoch 3.444), train_loss = 1.80952906, grad/param norm = 2.0548e-01, time/batch = 0.6782s	
2112/30650 (epoch 3.445), train_loss = 1.63601340, grad/param norm = 2.1574e-01, time/batch = 0.6993s	
2113/30650 (epoch 3.447), train_loss = 1.87449699, grad/param norm = 2.0453e-01, time/batch = 0.6882s	
2114/30650 (epoch 3.449), train_loss = 1.71004527, grad/param norm = 1.9946e-01, time/batch = 0.6810s	
2115/30650 (epoch 3.450), train_loss = 1.82006603, grad/param norm = 1.9722e-01, time/batch = 0.6783s	
2116/30650 (epoch 3.452), train_loss = 1.67683862, grad/param norm = 1.9965e-01, time/batch = 0.6783s	
2117/30650 (epoch 3.454), train_loss = 1.76351335, grad/param norm = 2.2298e-01, time/batch = 0.7159s	
2118/30650 (epoch 3.455), train_loss = 1.70979735, grad/param norm = 1.9078e-01, time/batch = 0.6991s	
2119/30650 (epoch 3.457), train_loss = 1.75315652, grad/param norm = 2.0359e-01, time/batch = 0.6763s	
2120/30650 (epoch 3.458), train_loss = 1.82625349, grad/param norm = 2.0960e-01, time/batch = 0.6924s	
2121/30650 (epoch 3.460), train_loss = 1.89541997, grad/param norm = 2.1572e-01, time/batch = 0.6858s	
2122/30650 (epoch 3.462), train_loss = 1.91409546, grad/param norm = 2.2385e-01, time/batch = 0.6807s	
2123/30650 (epoch 3.463), train_loss = 1.76039107, grad/param norm = 2.2498e-01, time/batch = 0.6793s	
2124/30650 (epoch 3.465), train_loss = 1.99541593, grad/param norm = 2.2901e-01, time/batch = 0.6774s	
2125/30650 (epoch 3.467), train_loss = 1.93324732, grad/param norm = 2.1099e-01, time/batch = 0.6788s	
2126/30650 (epoch 3.468), train_loss = 1.92624237, grad/param norm = 1.9248e-01, time/batch = 0.6795s	
2127/30650 (epoch 3.470), train_loss = 1.70193049, grad/param norm = 2.0160e-01, time/batch = 0.6774s	
2128/30650 (epoch 3.471), train_loss = 1.54717690, grad/param norm = 1.9807e-01, time/batch = 0.6804s	
2129/30650 (epoch 3.473), train_loss = 1.94916071, grad/param norm = 2.1449e-01, time/batch = 0.6791s	
2130/30650 (epoch 3.475), train_loss = 1.76441376, grad/param norm = 1.9852e-01, time/batch = 0.6771s	
2131/30650 (epoch 3.476), train_loss = 1.64515999, grad/param norm = 1.9245e-01, time/batch = 0.6795s	
2132/30650 (epoch 3.478), train_loss = 1.76015884, grad/param norm = 2.0312e-01, time/batch = 0.6789s	
2133/30650 (epoch 3.480), train_loss = 1.76256062, grad/param norm = 2.0301e-01, time/batch = 0.6783s	
2134/30650 (epoch 3.481), train_loss = 1.66535136, grad/param norm = 2.1098e-01, time/batch = 0.6781s	
2135/30650 (epoch 3.483), train_loss = 1.81498807, grad/param norm = 1.8949e-01, time/batch = 0.6795s	
2136/30650 (epoch 3.485), train_loss = 1.69168840, grad/param norm = 1.9624e-01, time/batch = 0.6804s	
2137/30650 (epoch 3.486), train_loss = 1.85654960, grad/param norm = 2.0460e-01, time/batch = 0.6764s	
2138/30650 (epoch 3.488), train_loss = 1.65604027, grad/param norm = 1.9518e-01, time/batch = 0.6763s	
2139/30650 (epoch 3.489), train_loss = 1.88455236, grad/param norm = 2.2415e-01, time/batch = 0.6775s	
2140/30650 (epoch 3.491), train_loss = 1.90609925, grad/param norm = 2.5086e-01, time/batch = 0.6793s	
2141/30650 (epoch 3.493), train_loss = 1.91467713, grad/param norm = 2.1771e-01, time/batch = 0.6796s	
2142/30650 (epoch 3.494), train_loss = 1.77666697, grad/param norm = 1.8490e-01, time/batch = 0.6865s	
2143/30650 (epoch 3.496), train_loss = 1.88058400, grad/param norm = 2.1394e-01, time/batch = 0.6907s	
2144/30650 (epoch 3.498), train_loss = 1.71156383, grad/param norm = 2.1763e-01, time/batch = 0.6873s	
2145/30650 (epoch 3.499), train_loss = 1.77787381, grad/param norm = 1.9090e-01, time/batch = 0.7075s	
2146/30650 (epoch 3.501), train_loss = 1.81173192, grad/param norm = 2.0593e-01, time/batch = 0.6915s	
2147/30650 (epoch 3.502), train_loss = 1.98719722, grad/param norm = 2.0536e-01, time/batch = 0.6803s	
2148/30650 (epoch 3.504), train_loss = 1.92194489, grad/param norm = 2.2565e-01, time/batch = 0.6779s	
2149/30650 (epoch 3.506), train_loss = 1.74247356, grad/param norm = 1.8946e-01, time/batch = 0.6924s	
2150/30650 (epoch 3.507), train_loss = 1.76865699, grad/param norm = 2.0998e-01, time/batch = 0.6914s	
2151/30650 (epoch 3.509), train_loss = 1.72165668, grad/param norm = 2.1215e-01, time/batch = 0.6818s	
2152/30650 (epoch 3.511), train_loss = 1.79433977, grad/param norm = 2.2141e-01, time/batch = 0.6785s	
2153/30650 (epoch 3.512), train_loss = 1.83434768, grad/param norm = 2.0291e-01, time/batch = 0.6778s	
2154/30650 (epoch 3.514), train_loss = 2.05049402, grad/param norm = 2.1980e-01, time/batch = 0.6762s	
2155/30650 (epoch 3.515), train_loss = 1.92835444, grad/param norm = 2.0752e-01, time/batch = 0.6770s	
2156/30650 (epoch 3.517), train_loss = 1.87924125, grad/param norm = 2.2718e-01, time/batch = 0.7067s	
2157/30650 (epoch 3.519), train_loss = 1.95729546, grad/param norm = 1.9045e-01, time/batch = 0.7193s	
2158/30650 (epoch 3.520), train_loss = 1.81272682, grad/param norm = 2.1567e-01, time/batch = 0.6830s	
2159/30650 (epoch 3.522), train_loss = 2.04971664, grad/param norm = 2.3146e-01, time/batch = 0.6827s	
2160/30650 (epoch 3.524), train_loss = 1.94377647, grad/param norm = 2.1510e-01, time/batch = 0.6754s	
2161/30650 (epoch 3.525), train_loss = 1.64849674, grad/param norm = 1.9825e-01, time/batch = 0.6821s	
2162/30650 (epoch 3.527), train_loss = 2.02168106, grad/param norm = 2.0939e-01, time/batch = 0.6774s	
2163/30650 (epoch 3.529), train_loss = 1.88995320, grad/param norm = 2.1648e-01, time/batch = 0.6768s	
2164/30650 (epoch 3.530), train_loss = 1.85502630, grad/param norm = 2.0942e-01, time/batch = 0.6755s	
2165/30650 (epoch 3.532), train_loss = 1.77184929, grad/param norm = 1.8175e-01, time/batch = 0.6761s	
2166/30650 (epoch 3.533), train_loss = 1.74155859, grad/param norm = 1.9911e-01, time/batch = 0.6762s	
2167/30650 (epoch 3.535), train_loss = 1.86205038, grad/param norm = 2.1833e-01, time/batch = 0.6746s	
2168/30650 (epoch 3.537), train_loss = 2.02603414, grad/param norm = 2.0740e-01, time/batch = 0.6769s	
2169/30650 (epoch 3.538), train_loss = 1.88628393, grad/param norm = 2.0667e-01, time/batch = 0.6750s	
2170/30650 (epoch 3.540), train_loss = 1.81173153, grad/param norm = 2.1448e-01, time/batch = 0.6825s	
2171/30650 (epoch 3.542), train_loss = 2.14227216, grad/param norm = 2.1436e-01, time/batch = 0.6778s	
2172/30650 (epoch 3.543), train_loss = 2.02182250, grad/param norm = 2.1177e-01, time/batch = 0.6781s	
2173/30650 (epoch 3.545), train_loss = 1.89853268, grad/param norm = 2.0445e-01, time/batch = 0.6776s	
2174/30650 (epoch 3.546), train_loss = 1.75191628, grad/param norm = 2.1070e-01, time/batch = 0.6771s	
2175/30650 (epoch 3.548), train_loss = 1.96646491, grad/param norm = 2.5308e-01, time/batch = 0.6762s	
2176/30650 (epoch 3.550), train_loss = 1.95432252, grad/param norm = 1.9644e-01, time/batch = 0.6842s	
2177/30650 (epoch 3.551), train_loss = 1.85459706, grad/param norm = 1.9034e-01, time/batch = 0.6864s	
2178/30650 (epoch 3.553), train_loss = 2.10093605, grad/param norm = 2.2644e-01, time/batch = 0.6756s	
2179/30650 (epoch 3.555), train_loss = 2.00457383, grad/param norm = 2.2057e-01, time/batch = 0.6752s	
2180/30650 (epoch 3.556), train_loss = 1.84599316, grad/param norm = 1.9897e-01, time/batch = 0.6765s	
2181/30650 (epoch 3.558), train_loss = 2.00226357, grad/param norm = 2.1766e-01, time/batch = 0.6785s	
2182/30650 (epoch 3.560), train_loss = 1.81150942, grad/param norm = 1.9401e-01, time/batch = 0.6763s	
2183/30650 (epoch 3.561), train_loss = 1.96517239, grad/param norm = 1.9612e-01, time/batch = 0.6796s	
2184/30650 (epoch 3.563), train_loss = 1.83350562, grad/param norm = 1.9484e-01, time/batch = 0.6783s	
2185/30650 (epoch 3.564), train_loss = 1.68806115, grad/param norm = 2.1124e-01, time/batch = 0.6791s	
2186/30650 (epoch 3.566), train_loss = 1.83909661, grad/param norm = 2.0875e-01, time/batch = 0.6840s	
2187/30650 (epoch 3.568), train_loss = 1.91361379, grad/param norm = 2.3413e-01, time/batch = 0.6846s	
2188/30650 (epoch 3.569), train_loss = 1.75992143, grad/param norm = 1.9347e-01, time/batch = 0.6830s	
2189/30650 (epoch 3.571), train_loss = 1.89140167, grad/param norm = 2.1346e-01, time/batch = 0.6779s	
2190/30650 (epoch 3.573), train_loss = 1.59697211, grad/param norm = 2.0133e-01, time/batch = 0.7160s	
2191/30650 (epoch 3.574), train_loss = 1.95041476, grad/param norm = 2.4750e-01, time/batch = 0.6991s	
2192/30650 (epoch 3.576), train_loss = 1.83118845, grad/param norm = 2.1032e-01, time/batch = 0.6767s	
2193/30650 (epoch 3.577), train_loss = 1.75245842, grad/param norm = 1.8923e-01, time/batch = 0.6778s	
2194/30650 (epoch 3.579), train_loss = 1.96590456, grad/param norm = 2.1143e-01, time/batch = 0.6770s	
2195/30650 (epoch 3.581), train_loss = 1.88792948, grad/param norm = 2.0969e-01, time/batch = 0.6803s	
2196/30650 (epoch 3.582), train_loss = 1.84694787, grad/param norm = 2.1351e-01, time/batch = 0.6772s	
2197/30650 (epoch 3.584), train_loss = 1.93985043, grad/param norm = 2.0930e-01, time/batch = 0.6758s	
2198/30650 (epoch 3.586), train_loss = 1.80241733, grad/param norm = 2.1594e-01, time/batch = 0.6775s	
2199/30650 (epoch 3.587), train_loss = 1.96141941, grad/param norm = 2.2069e-01, time/batch = 0.6773s	
2200/30650 (epoch 3.589), train_loss = 1.73474697, grad/param norm = 2.2858e-01, time/batch = 0.6842s	
2201/30650 (epoch 3.591), train_loss = 1.85220661, grad/param norm = 1.9650e-01, time/batch = 0.6833s	
2202/30650 (epoch 3.592), train_loss = 1.67284601, grad/param norm = 1.8616e-01, time/batch = 0.6773s	
2203/30650 (epoch 3.594), train_loss = 2.03786463, grad/param norm = 2.2247e-01, time/batch = 0.6792s	
2204/30650 (epoch 3.595), train_loss = 1.77103246, grad/param norm = 2.1977e-01, time/batch = 0.6993s	
2205/30650 (epoch 3.597), train_loss = 1.80934171, grad/param norm = 2.2493e-01, time/batch = 0.7224s	
2206/30650 (epoch 3.599), train_loss = 2.00521185, grad/param norm = 2.3763e-01, time/batch = 0.6790s	
2207/30650 (epoch 3.600), train_loss = 1.66076345, grad/param norm = 2.3291e-01, time/batch = 0.6773s	
2208/30650 (epoch 3.602), train_loss = 1.68231744, grad/param norm = 1.9587e-01, time/batch = 0.6766s	
2209/30650 (epoch 3.604), train_loss = 1.75209472, grad/param norm = 1.8975e-01, time/batch = 0.6777s	
2210/30650 (epoch 3.605), train_loss = 1.62068851, grad/param norm = 2.1100e-01, time/batch = 0.6764s	
2211/30650 (epoch 3.607), train_loss = 1.78205088, grad/param norm = 2.3603e-01, time/batch = 0.6795s	
2212/30650 (epoch 3.608), train_loss = 1.74035513, grad/param norm = 1.9623e-01, time/batch = 0.6800s	
2213/30650 (epoch 3.610), train_loss = 1.83427665, grad/param norm = 2.1571e-01, time/batch = 0.6774s	
2214/30650 (epoch 3.612), train_loss = 2.07652272, grad/param norm = 2.2660e-01, time/batch = 0.6773s	
2215/30650 (epoch 3.613), train_loss = 2.00880737, grad/param norm = 2.1632e-01, time/batch = 0.6769s	
2216/30650 (epoch 3.615), train_loss = 1.91926737, grad/param norm = 2.1061e-01, time/batch = 0.6807s	
2217/30650 (epoch 3.617), train_loss = 1.63694366, grad/param norm = 2.1204e-01, time/batch = 0.6825s	
2218/30650 (epoch 3.618), train_loss = 2.03344584, grad/param norm = 2.0271e-01, time/batch = 0.6775s	
2219/30650 (epoch 3.620), train_loss = 1.71341889, grad/param norm = 1.9981e-01, time/batch = 0.6768s	
2220/30650 (epoch 3.622), train_loss = 1.60025541, grad/param norm = 2.1156e-01, time/batch = 0.6778s	
2221/30650 (epoch 3.623), train_loss = 1.76176779, grad/param norm = 2.0983e-01, time/batch = 0.6789s	
2222/30650 (epoch 3.625), train_loss = 1.84980335, grad/param norm = 2.3430e-01, time/batch = 0.6871s	
2223/30650 (epoch 3.626), train_loss = 1.97373670, grad/param norm = 2.3743e-01, time/batch = 0.6966s	
2224/30650 (epoch 3.628), train_loss = 1.88878027, grad/param norm = 1.9525e-01, time/batch = 0.6893s	
2225/30650 (epoch 3.630), train_loss = 1.76820932, grad/param norm = 2.0198e-01, time/batch = 0.6897s	
2226/30650 (epoch 3.631), train_loss = 1.85644450, grad/param norm = 2.0349e-01, time/batch = 0.7013s	
2227/30650 (epoch 3.633), train_loss = 1.83046331, grad/param norm = 2.0885e-01, time/batch = 0.6899s	
2228/30650 (epoch 3.635), train_loss = 1.93842943, grad/param norm = 2.1487e-01, time/batch = 0.6901s	
2229/30650 (epoch 3.636), train_loss = 1.82885976, grad/param norm = 2.0918e-01, time/batch = 0.6867s	
2230/30650 (epoch 3.638), train_loss = 1.76014531, grad/param norm = 2.0896e-01, time/batch = 0.7029s	
2231/30650 (epoch 3.639), train_loss = 2.07527361, grad/param norm = 2.2162e-01, time/batch = 0.7030s	
2232/30650 (epoch 3.641), train_loss = 1.83438347, grad/param norm = 2.1062e-01, time/batch = 0.6958s	
2233/30650 (epoch 3.643), train_loss = 1.87097948, grad/param norm = 1.7759e-01, time/batch = 0.6961s	
2234/30650 (epoch 3.644), train_loss = 1.99373534, grad/param norm = 2.1438e-01, time/batch = 0.6994s	
2235/30650 (epoch 3.646), train_loss = 2.02131869, grad/param norm = 2.3087e-01, time/batch = 0.7038s	
2236/30650 (epoch 3.648), train_loss = 1.77070855, grad/param norm = 2.1521e-01, time/batch = 0.7130s	
2237/30650 (epoch 3.649), train_loss = 1.73231815, grad/param norm = 2.2670e-01, time/batch = 0.7019s	
2238/30650 (epoch 3.651), train_loss = 1.77816427, grad/param norm = 1.9921e-01, time/batch = 0.6795s	
2239/30650 (epoch 3.653), train_loss = 1.80413673, grad/param norm = 1.8883e-01, time/batch = 0.7108s	
2240/30650 (epoch 3.654), train_loss = 1.59982954, grad/param norm = 1.8177e-01, time/batch = 0.7106s	
2241/30650 (epoch 3.656), train_loss = 1.76018631, grad/param norm = 2.3468e-01, time/batch = 0.6799s	
2242/30650 (epoch 3.657), train_loss = 1.81100926, grad/param norm = 2.0910e-01, time/batch = 0.6796s	
2243/30650 (epoch 3.659), train_loss = 1.73629122, grad/param norm = 1.8552e-01, time/batch = 0.6845s	
2244/30650 (epoch 3.661), train_loss = 1.79292234, grad/param norm = 1.9491e-01, time/batch = 0.6982s	
2245/30650 (epoch 3.662), train_loss = 1.66986864, grad/param norm = 1.8995e-01, time/batch = 0.6846s	
2246/30650 (epoch 3.664), train_loss = 1.82493651, grad/param norm = 2.0167e-01, time/batch = 0.6787s	
2247/30650 (epoch 3.666), train_loss = 1.81480555, grad/param norm = 1.9119e-01, time/batch = 0.6769s	
2248/30650 (epoch 3.667), train_loss = 2.08725680, grad/param norm = 2.2391e-01, time/batch = 0.6792s	
2249/30650 (epoch 3.669), train_loss = 1.74640394, grad/param norm = 1.9185e-01, time/batch = 0.6774s	
2250/30650 (epoch 3.670), train_loss = 1.71678723, grad/param norm = 1.9449e-01, time/batch = 0.6793s	
2251/30650 (epoch 3.672), train_loss = 1.85611431, grad/param norm = 1.8722e-01, time/batch = 0.6794s	
2252/30650 (epoch 3.674), train_loss = 1.75947471, grad/param norm = 1.8721e-01, time/batch = 0.6769s	
2253/30650 (epoch 3.675), train_loss = 1.87385473, grad/param norm = 2.1178e-01, time/batch = 0.6829s	
2254/30650 (epoch 3.677), train_loss = 1.66754373, grad/param norm = 1.9600e-01, time/batch = 0.7218s	
2255/30650 (epoch 3.679), train_loss = 1.78590121, grad/param norm = 1.7935e-01, time/batch = 0.6897s	
2256/30650 (epoch 3.680), train_loss = 1.86358758, grad/param norm = 2.0382e-01, time/batch = 0.6777s	
2257/30650 (epoch 3.682), train_loss = 1.75324036, grad/param norm = 2.0603e-01, time/batch = 0.6797s	
2258/30650 (epoch 3.684), train_loss = 1.90595791, grad/param norm = 1.9230e-01, time/batch = 0.6785s	
2259/30650 (epoch 3.685), train_loss = 1.71255997, grad/param norm = 2.0307e-01, time/batch = 0.6768s	
2260/30650 (epoch 3.687), train_loss = 1.78369787, grad/param norm = 2.1820e-01, time/batch = 0.6806s	
2261/30650 (epoch 3.688), train_loss = 1.73557533, grad/param norm = 2.0296e-01, time/batch = 0.6780s	
2262/30650 (epoch 3.690), train_loss = 1.69556021, grad/param norm = 2.1613e-01, time/batch = 0.6772s	
2263/30650 (epoch 3.692), train_loss = 1.84978613, grad/param norm = 2.0047e-01, time/batch = 0.6781s	
2264/30650 (epoch 3.693), train_loss = 1.56061373, grad/param norm = 2.3289e-01, time/batch = 0.6803s	
2265/30650 (epoch 3.695), train_loss = 1.72567959, grad/param norm = 2.5812e-01, time/batch = 0.6772s	
2266/30650 (epoch 3.697), train_loss = 1.71267165, grad/param norm = 2.1878e-01, time/batch = 0.6771s	
2267/30650 (epoch 3.698), train_loss = 1.72945267, grad/param norm = 1.8703e-01, time/batch = 0.6786s	
2268/30650 (epoch 3.700), train_loss = 1.78892857, grad/param norm = 1.9136e-01, time/batch = 0.6778s	
2269/30650 (epoch 3.701), train_loss = 1.64272231, grad/param norm = 2.0307e-01, time/batch = 0.6811s	
2270/30650 (epoch 3.703), train_loss = 1.68454256, grad/param norm = 2.0901e-01, time/batch = 0.6792s	
2271/30650 (epoch 3.705), train_loss = 1.56514484, grad/param norm = 1.8618e-01, time/batch = 0.6812s	
2272/30650 (epoch 3.706), train_loss = 1.77249650, grad/param norm = 1.8830e-01, time/batch = 0.6790s	
2273/30650 (epoch 3.708), train_loss = 1.82971572, grad/param norm = 2.0342e-01, time/batch = 0.6793s	
2274/30650 (epoch 3.710), train_loss = 1.81599094, grad/param norm = 2.1967e-01, time/batch = 0.6816s	
2275/30650 (epoch 3.711), train_loss = 1.86935242, grad/param norm = 2.0987e-01, time/batch = 0.6762s	
2276/30650 (epoch 3.713), train_loss = 1.90449693, grad/param norm = 2.2793e-01, time/batch = 0.6785s	
2277/30650 (epoch 3.715), train_loss = 1.86852872, grad/param norm = 1.9749e-01, time/batch = 0.6761s	
2278/30650 (epoch 3.716), train_loss = 1.90731708, grad/param norm = 2.0997e-01, time/batch = 0.6958s	
2279/30650 (epoch 3.718), train_loss = 1.75415368, grad/param norm = 1.8672e-01, time/batch = 0.7096s	
2280/30650 (epoch 3.719), train_loss = 1.69888004, grad/param norm = 2.0177e-01, time/batch = 0.6816s	
2281/30650 (epoch 3.721), train_loss = 1.93704445, grad/param norm = 2.1555e-01, time/batch = 0.6824s	
2282/30650 (epoch 3.723), train_loss = 1.57587172, grad/param norm = 1.6853e-01, time/batch = 0.6831s	
2283/30650 (epoch 3.724), train_loss = 1.91285364, grad/param norm = 2.0943e-01, time/batch = 0.6797s	
2284/30650 (epoch 3.726), train_loss = 1.62416360, grad/param norm = 2.0187e-01, time/batch = 0.6771s	
2285/30650 (epoch 3.728), train_loss = 1.78065489, grad/param norm = 2.4973e-01, time/batch = 0.6768s	
2286/30650 (epoch 3.729), train_loss = 1.85461007, grad/param norm = 2.3106e-01, time/batch = 0.6794s	
2287/30650 (epoch 3.731), train_loss = 1.97688604, grad/param norm = 2.1220e-01, time/batch = 0.6838s	
2288/30650 (epoch 3.732), train_loss = 1.90828195, grad/param norm = 2.4389e-01, time/batch = 0.6787s	
2289/30650 (epoch 3.734), train_loss = 2.01918858, grad/param norm = 2.4132e-01, time/batch = 0.6789s	
2290/30650 (epoch 3.736), train_loss = 1.94063338, grad/param norm = 2.0888e-01, time/batch = 0.6775s	
2291/30650 (epoch 3.737), train_loss = 1.77678636, grad/param norm = 1.9202e-01, time/batch = 0.6781s	
2292/30650 (epoch 3.739), train_loss = 1.64031606, grad/param norm = 1.8928e-01, time/batch = 0.6761s	
2293/30650 (epoch 3.741), train_loss = 1.85605076, grad/param norm = 1.8524e-01, time/batch = 0.6755s	
2294/30650 (epoch 3.742), train_loss = 1.98936937, grad/param norm = 2.0352e-01, time/batch = 0.6768s	
2295/30650 (epoch 3.744), train_loss = 1.88521848, grad/param norm = 2.0523e-01, time/batch = 0.6771s	
2296/30650 (epoch 3.746), train_loss = 1.95152966, grad/param norm = 2.0018e-01, time/batch = 0.6776s	
2297/30650 (epoch 3.747), train_loss = 1.98012938, grad/param norm = 2.0586e-01, time/batch = 0.6801s	
2298/30650 (epoch 3.749), train_loss = 1.80829834, grad/param norm = 1.9672e-01, time/batch = 0.6755s	
2299/30650 (epoch 3.750), train_loss = 1.78104691, grad/param norm = 1.9431e-01, time/batch = 0.6764s	
2300/30650 (epoch 3.752), train_loss = 1.75241559, grad/param norm = 1.9081e-01, time/batch = 0.6776s	
2301/30650 (epoch 3.754), train_loss = 1.64974563, grad/param norm = 1.9934e-01, time/batch = 0.6833s	
2302/30650 (epoch 3.755), train_loss = 1.87828935, grad/param norm = 2.2873e-01, time/batch = 0.6802s	
2303/30650 (epoch 3.757), train_loss = 1.79234061, grad/param norm = 1.9235e-01, time/batch = 0.6797s	
2304/30650 (epoch 3.759), train_loss = 1.92474719, grad/param norm = 2.3341e-01, time/batch = 0.6831s	
2305/30650 (epoch 3.760), train_loss = 1.88044967, grad/param norm = 2.2621e-01, time/batch = 0.6979s	
2306/30650 (epoch 3.762), train_loss = 1.74021762, grad/param norm = 2.0605e-01, time/batch = 0.6790s	
2307/30650 (epoch 3.763), train_loss = 1.72111752, grad/param norm = 2.0752e-01, time/batch = 0.6779s	
2308/30650 (epoch 3.765), train_loss = 1.77334213, grad/param norm = 2.0924e-01, time/batch = 0.6788s	
2309/30650 (epoch 3.767), train_loss = 1.60647152, grad/param norm = 1.8223e-01, time/batch = 0.6768s	
2310/30650 (epoch 3.768), train_loss = 1.82414364, grad/param norm = 2.1179e-01, time/batch = 0.6761s	
2311/30650 (epoch 3.770), train_loss = 1.87874133, grad/param norm = 2.2751e-01, time/batch = 0.6811s	
2312/30650 (epoch 3.772), train_loss = 1.83998509, grad/param norm = 1.8799e-01, time/batch = 0.6790s	
2313/30650 (epoch 3.773), train_loss = 1.91551775, grad/param norm = 2.2391e-01, time/batch = 0.6804s	
2314/30650 (epoch 3.775), train_loss = 1.89884194, grad/param norm = 2.2106e-01, time/batch = 0.6789s	
2315/30650 (epoch 3.777), train_loss = 1.65324142, grad/param norm = 2.0521e-01, time/batch = 0.6784s	
2316/30650 (epoch 3.778), train_loss = 1.80940216, grad/param norm = 2.1660e-01, time/batch = 0.6774s	
2317/30650 (epoch 3.780), train_loss = 1.85049945, grad/param norm = 2.2304e-01, time/batch = 0.6944s	
2318/30650 (epoch 3.781), train_loss = 1.98618711, grad/param norm = 2.1590e-01, time/batch = 0.6877s	
2319/30650 (epoch 3.783), train_loss = 2.13446912, grad/param norm = 2.4196e-01, time/batch = 0.6879s	
2320/30650 (epoch 3.785), train_loss = 1.87541580, grad/param norm = 2.3280e-01, time/batch = 0.6834s	
2321/30650 (epoch 3.786), train_loss = 1.70783627, grad/param norm = 1.9210e-01, time/batch = 0.6851s	
2322/30650 (epoch 3.788), train_loss = 1.83248067, grad/param norm = 1.9600e-01, time/batch = 0.6955s	
2323/30650 (epoch 3.790), train_loss = 1.72626779, grad/param norm = 2.0819e-01, time/batch = 0.7201s	
2324/30650 (epoch 3.791), train_loss = 1.69166586, grad/param norm = 1.9206e-01, time/batch = 0.6795s	
2325/30650 (epoch 3.793), train_loss = 2.00360332, grad/param norm = 1.9600e-01, time/batch = 0.6783s	
2326/30650 (epoch 3.794), train_loss = 1.93579425, grad/param norm = 2.1537e-01, time/batch = 0.6769s	
2327/30650 (epoch 3.796), train_loss = 1.87330060, grad/param norm = 2.2570e-01, time/batch = 0.6809s	
2328/30650 (epoch 3.798), train_loss = 1.61780732, grad/param norm = 2.2086e-01, time/batch = 0.6781s	
2329/30650 (epoch 3.799), train_loss = 1.85120580, grad/param norm = 2.3314e-01, time/batch = 0.6774s	
2330/30650 (epoch 3.801), train_loss = 1.79182477, grad/param norm = 1.8940e-01, time/batch = 0.6770s	
2331/30650 (epoch 3.803), train_loss = 1.90164906, grad/param norm = 2.0095e-01, time/batch = 0.6789s	
2332/30650 (epoch 3.804), train_loss = 1.78238944, grad/param norm = 1.8780e-01, time/batch = 0.6888s	
2333/30650 (epoch 3.806), train_loss = 1.77717895, grad/param norm = 1.8487e-01, time/batch = 0.6992s	
2334/30650 (epoch 3.808), train_loss = 1.70546301, grad/param norm = 1.8809e-01, time/batch = 0.6782s	
2335/30650 (epoch 3.809), train_loss = 1.55969984, grad/param norm = 2.0831e-01, time/batch = 0.6883s	
2336/30650 (epoch 3.811), train_loss = 1.77044866, grad/param norm = 1.9173e-01, time/batch = 0.6789s	
2337/30650 (epoch 3.812), train_loss = 1.98404940, grad/param norm = 2.0207e-01, time/batch = 0.7163s	
2338/30650 (epoch 3.814), train_loss = 1.76318320, grad/param norm = 1.8496e-01, time/batch = 0.6994s	
2339/30650 (epoch 3.816), train_loss = 1.99411492, grad/param norm = 2.1315e-01, time/batch = 0.6770s	
2340/30650 (epoch 3.817), train_loss = 1.87986132, grad/param norm = 2.0647e-01, time/batch = 0.6855s	
2341/30650 (epoch 3.819), train_loss = 1.76768412, grad/param norm = 2.0632e-01, time/batch = 0.7033s	
2342/30650 (epoch 3.821), train_loss = 1.68901321, grad/param norm = 1.9943e-01, time/batch = 0.7141s	
2343/30650 (epoch 3.822), train_loss = 1.81178377, grad/param norm = 2.0323e-01, time/batch = 0.7113s	
2344/30650 (epoch 3.824), train_loss = 1.55224373, grad/param norm = 2.0222e-01, time/batch = 0.7022s	
2345/30650 (epoch 3.825), train_loss = 1.88368420, grad/param norm = 2.2304e-01, time/batch = 0.6952s	
2346/30650 (epoch 3.827), train_loss = 1.66562167, grad/param norm = 2.0653e-01, time/batch = 0.6805s	
2347/30650 (epoch 3.829), train_loss = 1.88800486, grad/param norm = 2.0934e-01, time/batch = 0.6805s	
2348/30650 (epoch 3.830), train_loss = 1.73647253, grad/param norm = 2.3580e-01, time/batch = 0.6863s	
2349/30650 (epoch 3.832), train_loss = 1.74665848, grad/param norm = 2.0586e-01, time/batch = 0.6822s	
2350/30650 (epoch 3.834), train_loss = 1.85802994, grad/param norm = 2.1214e-01, time/batch = 0.6786s	
2351/30650 (epoch 3.835), train_loss = 1.82268241, grad/param norm = 2.3011e-01, time/batch = 0.7212s	
2352/30650 (epoch 3.837), train_loss = 1.82747752, grad/param norm = 2.1699e-01, time/batch = 0.7138s	
2353/30650 (epoch 3.838), train_loss = 1.76151930, grad/param norm = 2.1229e-01, time/batch = 0.6772s	
2354/30650 (epoch 3.840), train_loss = 1.72906776, grad/param norm = 2.0541e-01, time/batch = 0.6835s	
2355/30650 (epoch 3.842), train_loss = 1.63903501, grad/param norm = 2.0701e-01, time/batch = 0.6828s	
2356/30650 (epoch 3.843), train_loss = 1.86439165, grad/param norm = 2.1502e-01, time/batch = 0.6793s	
2357/30650 (epoch 3.845), train_loss = 1.86831874, grad/param norm = 2.1292e-01, time/batch = 0.6806s	
2358/30650 (epoch 3.847), train_loss = 1.88878574, grad/param norm = 2.1259e-01, time/batch = 0.6800s	
2359/30650 (epoch 3.848), train_loss = 1.80507920, grad/param norm = 2.0603e-01, time/batch = 0.6915s	
2360/30650 (epoch 3.850), train_loss = 1.84569639, grad/param norm = 1.8361e-01, time/batch = 0.6926s	
2361/30650 (epoch 3.852), train_loss = 1.98314708, grad/param norm = 2.5542e-01, time/batch = 0.6928s	
2362/30650 (epoch 3.853), train_loss = 1.81189886, grad/param norm = 2.2020e-01, time/batch = 0.6906s	
2363/30650 (epoch 3.855), train_loss = 2.04163273, grad/param norm = 2.2747e-01, time/batch = 0.6769s	
2364/30650 (epoch 3.856), train_loss = 1.88037730, grad/param norm = 1.9458e-01, time/batch = 0.6784s	
2365/30650 (epoch 3.858), train_loss = 1.83796179, grad/param norm = 2.1486e-01, time/batch = 0.6809s	
2366/30650 (epoch 3.860), train_loss = 1.74030939, grad/param norm = 1.8575e-01, time/batch = 0.7215s	
2367/30650 (epoch 3.861), train_loss = 1.82052892, grad/param norm = 2.0162e-01, time/batch = 0.6919s	
2368/30650 (epoch 3.863), train_loss = 1.75198127, grad/param norm = 1.9960e-01, time/batch = 0.6810s	
2369/30650 (epoch 3.865), train_loss = 2.08851012, grad/param norm = 2.1879e-01, time/batch = 0.6916s	
2370/30650 (epoch 3.866), train_loss = 1.70111801, grad/param norm = 1.9891e-01, time/batch = 0.6866s	
2371/30650 (epoch 3.868), train_loss = 1.73889085, grad/param norm = 1.8633e-01, time/batch = 0.6886s	
2372/30650 (epoch 3.869), train_loss = 1.94285594, grad/param norm = 2.0658e-01, time/batch = 0.6789s	
2373/30650 (epoch 3.871), train_loss = 1.70202737, grad/param norm = 1.9468e-01, time/batch = 0.6780s	
2374/30650 (epoch 3.873), train_loss = 1.83730218, grad/param norm = 2.1761e-01, time/batch = 0.6827s	
2375/30650 (epoch 3.874), train_loss = 1.64744993, grad/param norm = 1.9776e-01, time/batch = 0.6957s	
2376/30650 (epoch 3.876), train_loss = 1.51881707, grad/param norm = 1.7246e-01, time/batch = 0.6791s	
2377/30650 (epoch 3.878), train_loss = 1.43092135, grad/param norm = 1.7514e-01, time/batch = 0.6848s	
2378/30650 (epoch 3.879), train_loss = 1.88548393, grad/param norm = 2.0546e-01, time/batch = 0.6852s	
2379/30650 (epoch 3.881), train_loss = 1.95934287, grad/param norm = 2.1981e-01, time/batch = 0.6784s	
2380/30650 (epoch 3.883), train_loss = 1.74356953, grad/param norm = 1.7898e-01, time/batch = 0.7042s	
2381/30650 (epoch 3.884), train_loss = 1.59958513, grad/param norm = 2.2080e-01, time/batch = 0.7133s	
2382/30650 (epoch 3.886), train_loss = 1.58792513, grad/param norm = 2.1038e-01, time/batch = 0.6780s	
2383/30650 (epoch 3.887), train_loss = 1.70221578, grad/param norm = 2.0167e-01, time/batch = 0.6793s	
2384/30650 (epoch 3.889), train_loss = 1.71034170, grad/param norm = 2.0044e-01, time/batch = 0.6793s	
2385/30650 (epoch 3.891), train_loss = 1.97490864, grad/param norm = 2.1896e-01, time/batch = 0.6786s	
2386/30650 (epoch 3.892), train_loss = 1.92625585, grad/param norm = 2.1289e-01, time/batch = 0.6786s	
2387/30650 (epoch 3.894), train_loss = 1.67653493, grad/param norm = 1.8423e-01, time/batch = 0.6787s	
2388/30650 (epoch 3.896), train_loss = 1.67585857, grad/param norm = 1.9293e-01, time/batch = 0.6792s	
2389/30650 (epoch 3.897), train_loss = 1.71823205, grad/param norm = 1.9923e-01, time/batch = 0.6795s	
2390/30650 (epoch 3.899), train_loss = 1.48698730, grad/param norm = 1.8450e-01, time/batch = 0.7090s	
2391/30650 (epoch 3.900), train_loss = 1.96738048, grad/param norm = 2.2568e-01, time/batch = 0.6881s	
2392/30650 (epoch 3.902), train_loss = 1.81394600, grad/param norm = 2.5907e-01, time/batch = 0.6778s	
2393/30650 (epoch 3.904), train_loss = 1.59596582, grad/param norm = 1.9618e-01, time/batch = 0.6802s	
2394/30650 (epoch 3.905), train_loss = 1.82371098, grad/param norm = 2.0644e-01, time/batch = 0.6834s	
2395/30650 (epoch 3.907), train_loss = 1.97741058, grad/param norm = 2.0402e-01, time/batch = 0.7089s	
2396/30650 (epoch 3.909), train_loss = 1.73102276, grad/param norm = 2.0714e-01, time/batch = 0.6855s	
2397/30650 (epoch 3.910), train_loss = 1.49857418, grad/param norm = 1.8181e-01, time/batch = 0.6917s	
2398/30650 (epoch 3.912), train_loss = 1.64365061, grad/param norm = 2.0706e-01, time/batch = 0.6959s	
2399/30650 (epoch 3.914), train_loss = 1.70481382, grad/param norm = 2.0644e-01, time/batch = 0.7040s	
2400/30650 (epoch 3.915), train_loss = 1.76826375, grad/param norm = 1.9451e-01, time/batch = 0.7088s	
2401/30650 (epoch 3.917), train_loss = 1.81448200, grad/param norm = 1.9314e-01, time/batch = 0.7160s	
2402/30650 (epoch 3.918), train_loss = 1.75378246, grad/param norm = 1.9115e-01, time/batch = 0.6944s	
2403/30650 (epoch 3.920), train_loss = 1.82495874, grad/param norm = 2.3292e-01, time/batch = 0.7055s	
2404/30650 (epoch 3.922), train_loss = 1.62691557, grad/param norm = 1.9945e-01, time/batch = 0.7092s	
2405/30650 (epoch 3.923), train_loss = 1.95176645, grad/param norm = 2.0534e-01, time/batch = 0.6951s	
2406/30650 (epoch 3.925), train_loss = 1.78228448, grad/param norm = 2.1642e-01, time/batch = 0.7026s	
2407/30650 (epoch 3.927), train_loss = 1.99227073, grad/param norm = 2.3906e-01, time/batch = 0.6843s	
2408/30650 (epoch 3.928), train_loss = 1.66264563, grad/param norm = 2.2504e-01, time/batch = 0.6785s	
2409/30650 (epoch 3.930), train_loss = 1.96950152, grad/param norm = 2.2140e-01, time/batch = 0.7135s	
2410/30650 (epoch 3.931), train_loss = 1.82407373, grad/param norm = 1.9416e-01, time/batch = 0.7019s	
2411/30650 (epoch 3.933), train_loss = 1.86345734, grad/param norm = 2.1939e-01, time/batch = 0.6789s	
2412/30650 (epoch 3.935), train_loss = 1.75262584, grad/param norm = 1.9457e-01, time/batch = 0.6794s	
2413/30650 (epoch 3.936), train_loss = 1.75000444, grad/param norm = 1.9833e-01, time/batch = 0.6837s	
2414/30650 (epoch 3.938), train_loss = 1.87329059, grad/param norm = 2.1152e-01, time/batch = 0.6776s	
2415/30650 (epoch 3.940), train_loss = 2.00198028, grad/param norm = 2.1910e-01, time/batch = 0.6780s	
2416/30650 (epoch 3.941), train_loss = 1.70285000, grad/param norm = 2.1975e-01, time/batch = 0.6814s	
2417/30650 (epoch 3.943), train_loss = 1.63214859, grad/param norm = 1.8797e-01, time/batch = 0.6799s	
2418/30650 (epoch 3.945), train_loss = 1.87524224, grad/param norm = 1.8639e-01, time/batch = 0.6941s	
2419/30650 (epoch 3.946), train_loss = 1.78479538, grad/param norm = 1.8951e-01, time/batch = 0.6876s	
2420/30650 (epoch 3.948), train_loss = 1.77374940, grad/param norm = 2.0218e-01, time/batch = 0.6840s	
2421/30650 (epoch 3.949), train_loss = 2.01518038, grad/param norm = 2.0734e-01, time/batch = 0.6792s	
2422/30650 (epoch 3.951), train_loss = 1.72432108, grad/param norm = 2.0638e-01, time/batch = 0.6761s	
2423/30650 (epoch 3.953), train_loss = 1.59761476, grad/param norm = 1.7781e-01, time/batch = 0.6948s	
2424/30650 (epoch 3.954), train_loss = 1.60356046, grad/param norm = 1.6505e-01, time/batch = 0.7220s	
2425/30650 (epoch 3.956), train_loss = 1.81794563, grad/param norm = 2.2215e-01, time/batch = 0.6793s	
2426/30650 (epoch 3.958), train_loss = 1.69250800, grad/param norm = 1.9671e-01, time/batch = 0.6774s	
2427/30650 (epoch 3.959), train_loss = 1.67644175, grad/param norm = 1.8954e-01, time/batch = 0.6760s	
2428/30650 (epoch 3.961), train_loss = 1.78868084, grad/param norm = 2.2598e-01, time/batch = 0.6758s	
2429/30650 (epoch 3.962), train_loss = 1.81366377, grad/param norm = 2.0354e-01, time/batch = 0.6769s	
2430/30650 (epoch 3.964), train_loss = 1.78342720, grad/param norm = 2.0251e-01, time/batch = 0.6765s	
2431/30650 (epoch 3.966), train_loss = 1.59801655, grad/param norm = 1.8474e-01, time/batch = 0.6796s	
2432/30650 (epoch 3.967), train_loss = 1.69964514, grad/param norm = 1.9118e-01, time/batch = 0.6789s	
2433/30650 (epoch 3.969), train_loss = 1.71007656, grad/param norm = 1.9237e-01, time/batch = 0.6761s	
2434/30650 (epoch 3.971), train_loss = 1.51457898, grad/param norm = 1.7945e-01, time/batch = 0.6820s	
2435/30650 (epoch 3.972), train_loss = 1.83217352, grad/param norm = 2.0168e-01, time/batch = 0.6762s	
2436/30650 (epoch 3.974), train_loss = 1.75540077, grad/param norm = 2.2204e-01, time/batch = 0.6814s	
2437/30650 (epoch 3.976), train_loss = 1.81230359, grad/param norm = 2.1343e-01, time/batch = 0.6819s	
2438/30650 (epoch 3.977), train_loss = 1.85053471, grad/param norm = 1.8726e-01, time/batch = 0.7094s	
2439/30650 (epoch 3.979), train_loss = 1.82926689, grad/param norm = 2.0161e-01, time/batch = 0.7087s	
2440/30650 (epoch 3.980), train_loss = 1.76601797, grad/param norm = 2.0602e-01, time/batch = 0.6756s	
2441/30650 (epoch 3.982), train_loss = 1.86506016, grad/param norm = 2.0417e-01, time/batch = 0.6773s	
2442/30650 (epoch 3.984), train_loss = 1.82835082, grad/param norm = 2.2403e-01, time/batch = 0.6795s	
2443/30650 (epoch 3.985), train_loss = 1.76726851, grad/param norm = 2.0737e-01, time/batch = 0.6769s	
2444/30650 (epoch 3.987), train_loss = 1.79593255, grad/param norm = 1.6896e-01, time/batch = 0.6782s	
2445/30650 (epoch 3.989), train_loss = 1.90915115, grad/param norm = 2.1012e-01, time/batch = 0.6783s	
2446/30650 (epoch 3.990), train_loss = 1.70151443, grad/param norm = 1.8661e-01, time/batch = 0.6807s	
2447/30650 (epoch 3.992), train_loss = 1.83355359, grad/param norm = 2.0177e-01, time/batch = 0.6841s	
2448/30650 (epoch 3.993), train_loss = 1.85264577, grad/param norm = 1.8722e-01, time/batch = 0.6795s	
2449/30650 (epoch 3.995), train_loss = 1.76244342, grad/param norm = 1.7743e-01, time/batch = 0.6782s	
2450/30650 (epoch 3.997), train_loss = 1.92251914, grad/param norm = 2.0050e-01, time/batch = 0.6766s	
2451/30650 (epoch 3.998), train_loss = 1.63813917, grad/param norm = 1.6394e-01, time/batch = 0.6805s	
2452/30650 (epoch 4.000), train_loss = 1.95516905, grad/param norm = 2.1569e-01, time/batch = 0.6833s	
2453/30650 (epoch 4.002), train_loss = 1.91090576, grad/param norm = 2.0734e-01, time/batch = 0.7222s	
2454/30650 (epoch 4.003), train_loss = 1.77803455, grad/param norm = 2.0104e-01, time/batch = 0.6878s	
2455/30650 (epoch 4.005), train_loss = 1.95118853, grad/param norm = 2.0310e-01, time/batch = 0.6804s	
2456/30650 (epoch 4.007), train_loss = 1.95144759, grad/param norm = 1.8007e-01, time/batch = 0.6777s	
2457/30650 (epoch 4.008), train_loss = 1.54745171, grad/param norm = 1.8458e-01, time/batch = 0.6779s	
2458/30650 (epoch 4.010), train_loss = 1.72336566, grad/param norm = 2.0208e-01, time/batch = 0.6782s	
2459/30650 (epoch 4.011), train_loss = 1.74351300, grad/param norm = 2.0513e-01, time/batch = 0.6793s	
2460/30650 (epoch 4.013), train_loss = 1.75259267, grad/param norm = 2.0746e-01, time/batch = 0.6766s	
2461/30650 (epoch 4.015), train_loss = 1.86871659, grad/param norm = 1.9190e-01, time/batch = 0.6803s	
2462/30650 (epoch 4.016), train_loss = 1.86760415, grad/param norm = 1.9945e-01, time/batch = 0.6866s	
2463/30650 (epoch 4.018), train_loss = 1.92773035, grad/param norm = 2.1591e-01, time/batch = 0.6802s	
2464/30650 (epoch 4.020), train_loss = 2.00979289, grad/param norm = 2.3016e-01, time/batch = 0.6796s	
2465/30650 (epoch 4.021), train_loss = 1.79176803, grad/param norm = 1.9518e-01, time/batch = 0.6777s	
2466/30650 (epoch 4.023), train_loss = 1.86323238, grad/param norm = 1.8601e-01, time/batch = 0.6760s	
2467/30650 (epoch 4.024), train_loss = 1.85566258, grad/param norm = 2.1103e-01, time/batch = 0.6779s	
2468/30650 (epoch 4.026), train_loss = 1.78129051, grad/param norm = 1.7619e-01, time/batch = 0.6783s	
2469/30650 (epoch 4.028), train_loss = 1.61839520, grad/param norm = 1.7571e-01, time/batch = 0.6833s	
2470/30650 (epoch 4.029), train_loss = 1.93501351, grad/param norm = 2.1263e-01, time/batch = 0.6808s	
2471/30650 (epoch 4.031), train_loss = 2.02475778, grad/param norm = 2.2313e-01, time/batch = 0.6850s	
2472/30650 (epoch 4.033), train_loss = 1.77097361, grad/param norm = 1.7861e-01, time/batch = 0.6943s	
2473/30650 (epoch 4.034), train_loss = 1.77158817, grad/param norm = 2.0485e-01, time/batch = 0.6838s	
2474/30650 (epoch 4.036), train_loss = 1.61159335, grad/param norm = 1.7963e-01, time/batch = 0.6822s	
2475/30650 (epoch 4.038), train_loss = 2.13082938, grad/param norm = 2.2003e-01, time/batch = 0.6801s	
2476/30650 (epoch 4.039), train_loss = 1.73918963, grad/param norm = 2.0100e-01, time/batch = 0.6783s	
2477/30650 (epoch 4.041), train_loss = 1.89606150, grad/param norm = 2.0411e-01, time/batch = 0.6795s	
2478/30650 (epoch 4.042), train_loss = 1.83685794, grad/param norm = 2.0167e-01, time/batch = 0.6819s	
2479/30650 (epoch 4.044), train_loss = 1.64024045, grad/param norm = 1.8404e-01, time/batch = 0.6767s	
2480/30650 (epoch 4.046), train_loss = 1.69842217, grad/param norm = 1.9763e-01, time/batch = 0.6755s	
2481/30650 (epoch 4.047), train_loss = 1.71731211, grad/param norm = 2.1218e-01, time/batch = 0.6778s	
2482/30650 (epoch 4.049), train_loss = 1.66684289, grad/param norm = 2.0165e-01, time/batch = 0.6760s	
2483/30650 (epoch 4.051), train_loss = 1.97565657, grad/param norm = 2.0069e-01, time/batch = 0.6755s	
2484/30650 (epoch 4.052), train_loss = 1.75420256, grad/param norm = 2.0150e-01, time/batch = 0.6756s	
2485/30650 (epoch 4.054), train_loss = 1.91681336, grad/param norm = 2.3736e-01, time/batch = 0.6760s	
2486/30650 (epoch 4.055), train_loss = 1.76647055, grad/param norm = 2.0369e-01, time/batch = 0.6769s	
2487/30650 (epoch 4.057), train_loss = 1.69014344, grad/param norm = 1.8641e-01, time/batch = 0.6769s	
2488/30650 (epoch 4.059), train_loss = 1.76228900, grad/param norm = 1.8706e-01, time/batch = 0.6767s	
2489/30650 (epoch 4.060), train_loss = 1.88717967, grad/param norm = 2.1000e-01, time/batch = 0.6838s	
2490/30650 (epoch 4.062), train_loss = 2.17869883, grad/param norm = 2.3361e-01, time/batch = 0.7137s	
2491/30650 (epoch 4.064), train_loss = 1.93109306, grad/param norm = 2.2231e-01, time/batch = 0.7217s	
2492/30650 (epoch 4.065), train_loss = 1.83697284, grad/param norm = 1.9186e-01, time/batch = 0.7139s	
2493/30650 (epoch 4.067), train_loss = 1.94737423, grad/param norm = 1.9678e-01, time/batch = 0.7137s	
2494/30650 (epoch 4.069), train_loss = 1.89803515, grad/param norm = 1.8924e-01, time/batch = 0.7245s	
2495/30650 (epoch 4.070), train_loss = 1.70521559, grad/param norm = 1.9148e-01, time/batch = 0.7116s	
2496/30650 (epoch 4.072), train_loss = 1.74875692, grad/param norm = 1.8624e-01, time/batch = 0.7259s	
2497/30650 (epoch 4.073), train_loss = 1.47373882, grad/param norm = 1.6794e-01, time/batch = 0.7146s	
2498/30650 (epoch 4.075), train_loss = 1.77493632, grad/param norm = 2.1575e-01, time/batch = 0.7272s	
2499/30650 (epoch 4.077), train_loss = 1.63796723, grad/param norm = 2.1543e-01, time/batch = 0.7239s	
2500/30650 (epoch 4.078), train_loss = 1.96888560, grad/param norm = 2.3183e-01, time/batch = 0.7034s	
2501/30650 (epoch 4.080), train_loss = 1.94370746, grad/param norm = 2.1474e-01, time/batch = 0.7076s	
2502/30650 (epoch 4.082), train_loss = 1.81283437, grad/param norm = 2.1254e-01, time/batch = 0.7234s	
2503/30650 (epoch 4.083), train_loss = 1.66597739, grad/param norm = 1.9473e-01, time/batch = 0.7208s	
2504/30650 (epoch 4.085), train_loss = 1.80694692, grad/param norm = 2.0268e-01, time/batch = 0.6906s	
2505/30650 (epoch 4.086), train_loss = 1.67734163, grad/param norm = 1.8289e-01, time/batch = 0.7005s	
2506/30650 (epoch 4.088), train_loss = 1.78474904, grad/param norm = 2.0327e-01, time/batch = 0.6856s	
2507/30650 (epoch 4.090), train_loss = 1.71609052, grad/param norm = 2.0806e-01, time/batch = 0.6772s	
2508/30650 (epoch 4.091), train_loss = 1.70185687, grad/param norm = 1.9365e-01, time/batch = 0.6960s	
2509/30650 (epoch 4.093), train_loss = 1.81091075, grad/param norm = 1.9684e-01, time/batch = 0.6886s	
2510/30650 (epoch 4.095), train_loss = 1.69999672, grad/param norm = 1.9604e-01, time/batch = 0.7005s	
2511/30650 (epoch 4.096), train_loss = 1.56840776, grad/param norm = 1.9345e-01, time/batch = 0.6958s	
2512/30650 (epoch 4.098), train_loss = 1.83106178, grad/param norm = 2.0126e-01, time/batch = 0.6867s	
2513/30650 (epoch 4.100), train_loss = 1.82421556, grad/param norm = 2.3305e-01, time/batch = 0.6854s	
2514/30650 (epoch 4.101), train_loss = 1.74410943, grad/param norm = 2.0979e-01, time/batch = 0.6768s	
2515/30650 (epoch 4.103), train_loss = 1.92189708, grad/param norm = 2.1723e-01, time/batch = 0.6765s	
2516/30650 (epoch 4.104), train_loss = 1.63942521, grad/param norm = 1.8559e-01, time/batch = 0.6783s	
2517/30650 (epoch 4.106), train_loss = 1.87025503, grad/param norm = 2.0841e-01, time/batch = 0.6795s	
2518/30650 (epoch 4.108), train_loss = 2.00510583, grad/param norm = 2.5627e-01, time/batch = 0.6795s	
2519/30650 (epoch 4.109), train_loss = 1.64434304, grad/param norm = 2.0371e-01, time/batch = 0.6837s	
2520/30650 (epoch 4.111), train_loss = 1.73455587, grad/param norm = 2.1215e-01, time/batch = 0.6842s	
2521/30650 (epoch 4.113), train_loss = 1.63971260, grad/param norm = 1.9321e-01, time/batch = 0.6802s	
2522/30650 (epoch 4.114), train_loss = 1.73366595, grad/param norm = 1.7715e-01, time/batch = 0.6771s	
2523/30650 (epoch 4.116), train_loss = 1.91620070, grad/param norm = 2.0204e-01, time/batch = 0.6768s	
2524/30650 (epoch 4.117), train_loss = 1.81461815, grad/param norm = 1.8096e-01, time/batch = 0.6792s	
2525/30650 (epoch 4.119), train_loss = 1.84620812, grad/param norm = 2.0021e-01, time/batch = 0.7183s	
2526/30650 (epoch 4.121), train_loss = 2.09507336, grad/param norm = 2.2639e-01, time/batch = 0.6975s	
2527/30650 (epoch 4.122), train_loss = 1.86929781, grad/param norm = 2.1020e-01, time/batch = 0.6783s	
2528/30650 (epoch 4.124), train_loss = 1.79536987, grad/param norm = 2.1069e-01, time/batch = 0.6817s	
2529/30650 (epoch 4.126), train_loss = 1.67721227, grad/param norm = 2.0558e-01, time/batch = 0.6776s	
2530/30650 (epoch 4.127), train_loss = 1.86132018, grad/param norm = 2.0376e-01, time/batch = 0.6775s	
2531/30650 (epoch 4.129), train_loss = 1.84684199, grad/param norm = 2.0068e-01, time/batch = 0.6778s	
2532/30650 (epoch 4.131), train_loss = 2.19529225, grad/param norm = 2.1761e-01, time/batch = 0.6837s	
2533/30650 (epoch 4.132), train_loss = 1.78296409, grad/param norm = 2.0900e-01, time/batch = 0.6919s	
2534/30650 (epoch 4.134), train_loss = 1.56437520, grad/param norm = 1.7848e-01, time/batch = 0.6898s	
2535/30650 (epoch 4.135), train_loss = 1.76316131, grad/param norm = 1.8102e-01, time/batch = 0.7024s	
2536/30650 (epoch 4.137), train_loss = 1.87233307, grad/param norm = 2.1831e-01, time/batch = 0.6844s	
2537/30650 (epoch 4.139), train_loss = 1.64596242, grad/param norm = 1.7880e-01, time/batch = 0.6822s	
2538/30650 (epoch 4.140), train_loss = 1.80998461, grad/param norm = 1.9934e-01, time/batch = 0.6800s	
2539/30650 (epoch 4.142), train_loss = 1.60975622, grad/param norm = 1.7882e-01, time/batch = 0.6972s	
2540/30650 (epoch 4.144), train_loss = 1.50520754, grad/param norm = 2.0210e-01, time/batch = 0.7203s	
2541/30650 (epoch 4.145), train_loss = 1.62528794, grad/param norm = 1.8500e-01, time/batch = 0.6809s	
2542/30650 (epoch 4.147), train_loss = 1.66021596, grad/param norm = 2.1779e-01, time/batch = 0.6803s	
2543/30650 (epoch 4.148), train_loss = 1.65679949, grad/param norm = 1.8279e-01, time/batch = 0.6804s	
2544/30650 (epoch 4.150), train_loss = 1.73317608, grad/param norm = 2.0482e-01, time/batch = 0.6851s	
2545/30650 (epoch 4.152), train_loss = 1.68874162, grad/param norm = 1.8375e-01, time/batch = 0.6787s	
2546/30650 (epoch 4.153), train_loss = 1.79638681, grad/param norm = 2.0605e-01, time/batch = 0.6799s	
2547/30650 (epoch 4.155), train_loss = 1.86055438, grad/param norm = 1.8448e-01, time/batch = 0.6889s	
2548/30650 (epoch 4.157), train_loss = 1.73324889, grad/param norm = 1.8024e-01, time/batch = 0.6803s	
2549/30650 (epoch 4.158), train_loss = 1.60471702, grad/param norm = 1.9885e-01, time/batch = 0.6872s	
2550/30650 (epoch 4.160), train_loss = 1.63557838, grad/param norm = 1.7981e-01, time/batch = 0.6822s	
2551/30650 (epoch 4.162), train_loss = 1.75909442, grad/param norm = 2.0425e-01, time/batch = 0.6852s	
2552/30650 (epoch 4.163), train_loss = 1.76143811, grad/param norm = 2.0243e-01, time/batch = 0.6779s	
2553/30650 (epoch 4.165), train_loss = 1.97773373, grad/param norm = 2.1483e-01, time/batch = 0.6780s	
2554/30650 (epoch 4.166), train_loss = 1.92590762, grad/param norm = 2.1677e-01, time/batch = 0.7184s	
2555/30650 (epoch 4.168), train_loss = 1.81683767, grad/param norm = 2.2385e-01, time/batch = 0.7004s	
2556/30650 (epoch 4.170), train_loss = 1.50506165, grad/param norm = 1.7526e-01, time/batch = 0.6785s	
2557/30650 (epoch 4.171), train_loss = 1.73168550, grad/param norm = 2.0787e-01, time/batch = 0.6950s	
2558/30650 (epoch 4.173), train_loss = 1.58684492, grad/param norm = 1.8477e-01, time/batch = 0.6777s	
2559/30650 (epoch 4.175), train_loss = 1.82391211, grad/param norm = 1.8771e-01, time/batch = 0.6788s	
2560/30650 (epoch 4.176), train_loss = 1.82429714, grad/param norm = 2.0698e-01, time/batch = 0.6752s	
2561/30650 (epoch 4.178), train_loss = 1.90038165, grad/param norm = 2.3307e-01, time/batch = 0.6770s	
2562/30650 (epoch 4.179), train_loss = 1.99916268, grad/param norm = 1.8956e-01, time/batch = 0.6770s	
2563/30650 (epoch 4.181), train_loss = 1.99157021, grad/param norm = 2.0707e-01, time/batch = 0.6842s	
2564/30650 (epoch 4.183), train_loss = 1.81328113, grad/param norm = 2.0360e-01, time/batch = 0.6773s	
2565/30650 (epoch 4.184), train_loss = 1.61870186, grad/param norm = 2.0404e-01, time/batch = 0.6761s	
2566/30650 (epoch 4.186), train_loss = 1.75650706, grad/param norm = 2.0771e-01, time/batch = 0.6790s	
2567/30650 (epoch 4.188), train_loss = 1.72784820, grad/param norm = 1.8768e-01, time/batch = 0.6868s	
2568/30650 (epoch 4.189), train_loss = 1.71645858, grad/param norm = 1.8366e-01, time/batch = 0.7079s	
2569/30650 (epoch 4.191), train_loss = 1.69012386, grad/param norm = 1.8430e-01, time/batch = 0.7185s	
2570/30650 (epoch 4.192), train_loss = 1.70417499, grad/param norm = 1.6669e-01, time/batch = 0.6765s	
2571/30650 (epoch 4.194), train_loss = 1.71308663, grad/param norm = 1.9985e-01, time/batch = 0.6775s	
2572/30650 (epoch 4.196), train_loss = 1.79864797, grad/param norm = 2.0153e-01, time/batch = 0.6755s	
2573/30650 (epoch 4.197), train_loss = 1.78552114, grad/param norm = 2.0593e-01, time/batch = 0.6768s	
2574/30650 (epoch 4.199), train_loss = 1.67357169, grad/param norm = 1.8791e-01, time/batch = 0.6758s	
2575/30650 (epoch 4.201), train_loss = 1.62556173, grad/param norm = 1.8809e-01, time/batch = 0.6773s	
2576/30650 (epoch 4.202), train_loss = 1.69300283, grad/param norm = 1.9350e-01, time/batch = 0.6769s	
2577/30650 (epoch 4.204), train_loss = 1.64439169, grad/param norm = 1.7796e-01, time/batch = 0.6785s	
2578/30650 (epoch 4.206), train_loss = 1.68496622, grad/param norm = 1.7538e-01, time/batch = 0.6982s	
2579/30650 (epoch 4.207), train_loss = 1.78100378, grad/param norm = 1.9138e-01, time/batch = 0.6838s	
2580/30650 (epoch 4.209), train_loss = 1.58296925, grad/param norm = 1.7644e-01, time/batch = 1.0036s	
2581/30650 (epoch 4.210), train_loss = 1.67458301, grad/param norm = 1.9766e-01, time/batch = 1.3288s	
2582/30650 (epoch 4.212), train_loss = 1.90155061, grad/param norm = 2.2183e-01, time/batch = 0.6843s	
2583/30650 (epoch 4.214), train_loss = 2.02616333, grad/param norm = 2.0752e-01, time/batch = 0.6785s	
2584/30650 (epoch 4.215), train_loss = 1.71615211, grad/param norm = 1.7537e-01, time/batch = 0.6750s	
2585/30650 (epoch 4.217), train_loss = 1.69415086, grad/param norm = 1.8592e-01, time/batch = 0.6994s	
2586/30650 (epoch 4.219), train_loss = 1.82219367, grad/param norm = 1.9325e-01, time/batch = 0.6947s	
2587/30650 (epoch 4.220), train_loss = 1.72214556, grad/param norm = 1.9814e-01, time/batch = 0.7374s	
2588/30650 (epoch 4.222), train_loss = 1.62627190, grad/param norm = 2.0490e-01, time/batch = 0.6932s	
2589/30650 (epoch 4.223), train_loss = 1.82799558, grad/param norm = 1.8994e-01, time/batch = 0.6777s	
2590/30650 (epoch 4.225), train_loss = 1.69124625, grad/param norm = 1.7443e-01, time/batch = 0.6861s	
2591/30650 (epoch 4.227), train_loss = 1.90711336, grad/param norm = 1.8297e-01, time/batch = 0.6860s	
2592/30650 (epoch 4.228), train_loss = 1.81156724, grad/param norm = 1.9312e-01, time/batch = 0.6930s	
2593/30650 (epoch 4.230), train_loss = 1.78398649, grad/param norm = 1.9219e-01, time/batch = 0.6784s	
