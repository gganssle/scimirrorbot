tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 521, val: 28, test: 0	
vocab size: 136	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 285832	
cloning rnn	
cloning criterion	
1/26050 (epoch 0.002), train_loss = 4.92163106, grad/param norm = 5.6071e-01, time/batch = 0.7101s	
2/26050 (epoch 0.004), train_loss = 4.59126397, grad/param norm = 1.6650e+00, time/batch = 0.6440s	
3/26050 (epoch 0.006), train_loss = 3.79198034, grad/param norm = 1.1353e+00, time/batch = 0.6751s	
4/26050 (epoch 0.008), train_loss = 3.50360345, grad/param norm = 7.6045e-01, time/batch = 0.6804s	
5/26050 (epoch 0.010), train_loss = 3.69571659, grad/param norm = 9.5982e-01, time/batch = 0.6393s	
6/26050 (epoch 0.012), train_loss = 3.62391407, grad/param norm = 5.7481e-01, time/batch = 0.6400s	
7/26050 (epoch 0.013), train_loss = 3.67711362, grad/param norm = 8.3643e-01, time/batch = 0.6379s	
8/26050 (epoch 0.015), train_loss = 3.46286064, grad/param norm = 8.0972e-01, time/batch = 0.6400s	
9/26050 (epoch 0.017), train_loss = 3.50489147, grad/param norm = 8.8169e-01, time/batch = 0.6378s	
10/26050 (epoch 0.019), train_loss = 3.49390191, grad/param norm = 5.1986e-01, time/batch = 0.6426s	
11/26050 (epoch 0.021), train_loss = 3.40492143, grad/param norm = 6.8335e-01, time/batch = 0.6377s	
12/26050 (epoch 0.023), train_loss = 3.49554823, grad/param norm = 8.5484e-01, time/batch = 0.6387s	
13/26050 (epoch 0.025), train_loss = 3.39006821, grad/param norm = 7.7387e-01, time/batch = 0.6422s	
14/26050 (epoch 0.027), train_loss = 3.54607690, grad/param norm = 8.9881e-01, time/batch = 0.6374s	
15/26050 (epoch 0.029), train_loss = 3.39956436, grad/param norm = 8.4834e-01, time/batch = 0.6400s	
16/26050 (epoch 0.031), train_loss = 3.42923414, grad/param norm = 6.7008e-01, time/batch = 0.6384s	
17/26050 (epoch 0.033), train_loss = 3.40206496, grad/param norm = 5.0876e-01, time/batch = 0.6402s	
18/26050 (epoch 0.035), train_loss = 3.60172930, grad/param norm = 7.3693e-01, time/batch = 0.6443s	
19/26050 (epoch 0.036), train_loss = 3.52850047, grad/param norm = 7.3864e-01, time/batch = 0.6816s	
20/26050 (epoch 0.038), train_loss = 3.42953049, grad/param norm = 6.2132e-01, time/batch = 0.6578s	
21/26050 (epoch 0.040), train_loss = 3.42214345, grad/param norm = 5.7267e-01, time/batch = 0.6425s	
22/26050 (epoch 0.042), train_loss = 3.49207636, grad/param norm = 5.5788e-01, time/batch = 0.6376s	
23/26050 (epoch 0.044), train_loss = 3.46997238, grad/param norm = 5.8632e-01, time/batch = 0.6364s	
24/26050 (epoch 0.046), train_loss = 3.62522699, grad/param norm = 7.5255e-01, time/batch = 0.6387s	
25/26050 (epoch 0.048), train_loss = 3.37992367, grad/param norm = 7.1668e-01, time/batch = 0.6388s	
26/26050 (epoch 0.050), train_loss = 3.30069825, grad/param norm = 6.8889e-01, time/batch = 0.6388s	
27/26050 (epoch 0.052), train_loss = 3.58785652, grad/param norm = 7.2630e-01, time/batch = 0.6370s	
28/26050 (epoch 0.054), train_loss = 3.41622591, grad/param norm = 7.0446e-01, time/batch = 0.6370s	
29/26050 (epoch 0.056), train_loss = 3.46914531, grad/param norm = 7.0462e-01, time/batch = 0.6383s	
30/26050 (epoch 0.058), train_loss = 3.47767374, grad/param norm = 6.0513e-01, time/batch = 0.6380s	
31/26050 (epoch 0.060), train_loss = 3.39864310, grad/param norm = 5.6617e-01, time/batch = 0.6385s	
32/26050 (epoch 0.061), train_loss = 3.60421356, grad/param norm = 8.0735e-01, time/batch = 0.6384s	
33/26050 (epoch 0.063), train_loss = 3.47419142, grad/param norm = 5.2138e-01, time/batch = 0.6428s	
34/26050 (epoch 0.065), train_loss = 3.53837030, grad/param norm = 5.9773e-01, time/batch = 0.6421s	
35/26050 (epoch 0.067), train_loss = 3.43084214, grad/param norm = 6.1525e-01, time/batch = 0.6381s	
36/26050 (epoch 0.069), train_loss = 3.49259581, grad/param norm = 5.6059e-01, time/batch = 0.6381s	
37/26050 (epoch 0.071), train_loss = 3.51750057, grad/param norm = 5.6578e-01, time/batch = 0.6388s	
38/26050 (epoch 0.073), train_loss = 3.62099008, grad/param norm = 6.5942e-01, time/batch = 0.6375s	
39/26050 (epoch 0.075), train_loss = 3.53999933, grad/param norm = 6.0516e-01, time/batch = 0.6395s	
40/26050 (epoch 0.077), train_loss = 3.47727117, grad/param norm = 6.5047e-01, time/batch = 0.6545s	
41/26050 (epoch 0.079), train_loss = 3.62318795, grad/param norm = 7.2697e-01, time/batch = 0.6438s	
42/26050 (epoch 0.081), train_loss = 3.47745657, grad/param norm = 7.8877e-01, time/batch = 0.6392s	
43/26050 (epoch 0.083), train_loss = 3.46162560, grad/param norm = 6.1824e-01, time/batch = 0.6373s	
44/26050 (epoch 0.084), train_loss = 3.51741803, grad/param norm = 6.2304e-01, time/batch = 0.6369s	
45/26050 (epoch 0.086), train_loss = 3.52911602, grad/param norm = 5.8381e-01, time/batch = 0.6374s	
46/26050 (epoch 0.088), train_loss = 3.46228013, grad/param norm = 6.1317e-01, time/batch = 0.6362s	
47/26050 (epoch 0.090), train_loss = 3.46168945, grad/param norm = 6.3015e-01, time/batch = 0.6386s	
48/26050 (epoch 0.092), train_loss = 3.45602105, grad/param norm = 6.6627e-01, time/batch = 0.6371s	
49/26050 (epoch 0.094), train_loss = 3.48894115, grad/param norm = 6.2498e-01, time/batch = 0.6390s	
50/26050 (epoch 0.096), train_loss = 3.36251985, grad/param norm = 6.9575e-01, time/batch = 0.6402s	
51/26050 (epoch 0.098), train_loss = 3.47112302, grad/param norm = 5.6802e-01, time/batch = 0.6379s	
52/26050 (epoch 0.100), train_loss = 3.55160514, grad/param norm = 7.3681e-01, time/batch = 0.6364s	
53/26050 (epoch 0.102), train_loss = 3.59340439, grad/param norm = 5.1555e-01, time/batch = 0.6400s	
54/26050 (epoch 0.104), train_loss = 3.49118541, grad/param norm = 6.7687e-01, time/batch = 0.6530s	
55/26050 (epoch 0.106), train_loss = 3.43381660, grad/param norm = 7.6563e-01, time/batch = 0.6811s	
56/26050 (epoch 0.107), train_loss = 3.42805596, grad/param norm = 4.8328e-01, time/batch = 0.6487s	
57/26050 (epoch 0.109), train_loss = 3.49533909, grad/param norm = 6.4143e-01, time/batch = 0.6388s	
58/26050 (epoch 0.111), train_loss = 3.59287329, grad/param norm = 6.3598e-01, time/batch = 0.6374s	
59/26050 (epoch 0.113), train_loss = 3.34472756, grad/param norm = 7.5812e-01, time/batch = 0.6386s	
60/26050 (epoch 0.115), train_loss = 3.56205549, grad/param norm = 6.4092e-01, time/batch = 0.6379s	
61/26050 (epoch 0.117), train_loss = 3.65056121, grad/param norm = 7.4935e-01, time/batch = 0.6375s	
62/26050 (epoch 0.119), train_loss = 3.52502894, grad/param norm = 6.3947e-01, time/batch = 0.6377s	
63/26050 (epoch 0.121), train_loss = 3.51054062, grad/param norm = 5.5005e-01, time/batch = 0.6368s	
64/26050 (epoch 0.123), train_loss = 3.45658377, grad/param norm = 5.1487e-01, time/batch = 0.6435s	
65/26050 (epoch 0.125), train_loss = 3.47215758, grad/param norm = 7.2652e-01, time/batch = 0.6389s	
66/26050 (epoch 0.127), train_loss = 3.46610215, grad/param norm = 5.2019e-01, time/batch = 0.6377s	
67/26050 (epoch 0.129), train_loss = 3.58459649, grad/param norm = 6.3838e-01, time/batch = 0.6374s	
68/26050 (epoch 0.131), train_loss = 3.48555012, grad/param norm = 5.7784e-01, time/batch = 0.6364s	
69/26050 (epoch 0.132), train_loss = 3.48433494, grad/param norm = 6.5934e-01, time/batch = 0.6365s	
70/26050 (epoch 0.134), train_loss = 3.62201226, grad/param norm = 6.9942e-01, time/batch = 0.6723s	
71/26050 (epoch 0.136), train_loss = 3.50696305, grad/param norm = 6.0453e-01, time/batch = 0.6707s	
72/26050 (epoch 0.138), train_loss = 3.45682655, grad/param norm = 5.4977e-01, time/batch = 0.6424s	
73/26050 (epoch 0.140), train_loss = 3.50547495, grad/param norm = 4.6156e-01, time/batch = 0.6378s	
74/26050 (epoch 0.142), train_loss = 3.46365599, grad/param norm = 5.4735e-01, time/batch = 0.6371s	
75/26050 (epoch 0.144), train_loss = 3.50480263, grad/param norm = 4.7344e-01, time/batch = 0.6387s	
76/26050 (epoch 0.146), train_loss = 3.41739550, grad/param norm = 4.3496e-01, time/batch = 0.6384s	
77/26050 (epoch 0.148), train_loss = 3.59538184, grad/param norm = 5.3148e-01, time/batch = 0.6375s	
78/26050 (epoch 0.150), train_loss = 3.48510698, grad/param norm = 7.8245e-01, time/batch = 0.6392s	
79/26050 (epoch 0.152), train_loss = 3.60745203, grad/param norm = 9.4964e-01, time/batch = 0.6464s	
80/26050 (epoch 0.154), train_loss = 3.58400125, grad/param norm = 5.9642e-01, time/batch = 0.6521s	
81/26050 (epoch 0.155), train_loss = 3.48099427, grad/param norm = 4.6997e-01, time/batch = 0.6561s	
82/26050 (epoch 0.157), train_loss = 3.55430711, grad/param norm = 4.8448e-01, time/batch = 0.6426s	
83/26050 (epoch 0.159), train_loss = 3.45880004, grad/param norm = 4.4668e-01, time/batch = 0.6454s	
84/26050 (epoch 0.161), train_loss = 3.43312988, grad/param norm = 5.4970e-01, time/batch = 0.6379s	
85/26050 (epoch 0.163), train_loss = 3.43473276, grad/param norm = 5.9213e-01, time/batch = 0.6463s	
86/26050 (epoch 0.165), train_loss = 3.49204101, grad/param norm = 7.4425e-01, time/batch = 0.6393s	
87/26050 (epoch 0.167), train_loss = 3.41067114, grad/param norm = 7.4167e-01, time/batch = 0.6399s	
88/26050 (epoch 0.169), train_loss = 3.61490753, grad/param norm = 7.0220e-01, time/batch = 0.6397s	
89/26050 (epoch 0.171), train_loss = 3.50292357, grad/param norm = 4.4009e-01, time/batch = 0.6400s	
90/26050 (epoch 0.173), train_loss = 3.43354607, grad/param norm = 4.4231e-01, time/batch = 0.6372s	
91/26050 (epoch 0.175), train_loss = 3.56390885, grad/param norm = 6.8486e-01, time/batch = 0.6499s	
92/26050 (epoch 0.177), train_loss = 3.39883693, grad/param norm = 6.0457e-01, time/batch = 0.6404s	
93/26050 (epoch 0.179), train_loss = 3.50067375, grad/param norm = 7.3225e-01, time/batch = 0.6382s	
94/26050 (epoch 0.180), train_loss = 3.48403944, grad/param norm = 9.0968e-01, time/batch = 0.6397s	
95/26050 (epoch 0.182), train_loss = 3.55947537, grad/param norm = 8.8935e-01, time/batch = 0.6435s	
96/26050 (epoch 0.184), train_loss = 3.52462685, grad/param norm = 5.6140e-01, time/batch = 0.6396s	
97/26050 (epoch 0.186), train_loss = 3.50859287, grad/param norm = 4.6637e-01, time/batch = 0.6400s	
98/26050 (epoch 0.188), train_loss = 3.52274351, grad/param norm = 5.8470e-01, time/batch = 0.6405s	
99/26050 (epoch 0.190), train_loss = 3.45468963, grad/param norm = 4.4528e-01, time/batch = 0.6379s	
100/26050 (epoch 0.192), train_loss = 3.52578559, grad/param norm = 5.1139e-01, time/batch = 0.6374s	
101/26050 (epoch 0.194), train_loss = 3.35001356, grad/param norm = 5.3103e-01, time/batch = 0.6394s	
102/26050 (epoch 0.196), train_loss = 3.39975077, grad/param norm = 5.9756e-01, time/batch = 0.6391s	
103/26050 (epoch 0.198), train_loss = 3.32101589, grad/param norm = 6.3451e-01, time/batch = 0.6400s	
104/26050 (epoch 0.200), train_loss = 3.35700080, grad/param norm = 5.1327e-01, time/batch = 0.6397s	
105/26050 (epoch 0.202), train_loss = 3.48101606, grad/param norm = 1.1128e+00, time/batch = 0.6470s	
106/26050 (epoch 0.203), train_loss = 3.43605382, grad/param norm = 1.3463e+00, time/batch = 0.6783s	
107/26050 (epoch 0.205), train_loss = 3.32946759, grad/param norm = 5.9178e-01, time/batch = 0.6496s	
108/26050 (epoch 0.207), train_loss = 3.49500332, grad/param norm = 8.0887e-01, time/batch = 0.6419s	
109/26050 (epoch 0.209), train_loss = 3.41449291, grad/param norm = 1.0083e+00, time/batch = 0.6429s	
110/26050 (epoch 0.211), train_loss = 3.34858196, grad/param norm = 6.0239e-01, time/batch = 0.6393s	
111/26050 (epoch 0.213), train_loss = 3.43214502, grad/param norm = 5.4317e-01, time/batch = 0.6444s	
112/26050 (epoch 0.215), train_loss = 3.41926732, grad/param norm = 4.3457e-01, time/batch = 0.6388s	
113/26050 (epoch 0.217), train_loss = 3.31827781, grad/param norm = 5.0650e-01, time/batch = 0.6380s	
114/26050 (epoch 0.219), train_loss = 3.22072676, grad/param norm = 3.8303e-01, time/batch = 0.6377s	
115/26050 (epoch 0.221), train_loss = 3.31886892, grad/param norm = 6.5673e-01, time/batch = 0.6382s	
116/26050 (epoch 0.223), train_loss = 3.42712466, grad/param norm = 5.3991e-01, time/batch = 0.6383s	
117/26050 (epoch 0.225), train_loss = 3.49494375, grad/param norm = 2.0519e+00, time/batch = 0.6382s	
118/26050 (epoch 0.226), train_loss = 3.60872114, grad/param norm = 1.2554e+00, time/batch = 0.6400s	
119/26050 (epoch 0.228), train_loss = 3.36292880, grad/param norm = 5.3763e-01, time/batch = 0.6393s	
120/26050 (epoch 0.230), train_loss = 3.19304811, grad/param norm = 3.5395e-01, time/batch = 0.6385s	
121/26050 (epoch 0.232), train_loss = 3.31632955, grad/param norm = 5.2047e-01, time/batch = 0.6735s	
122/26050 (epoch 0.234), train_loss = 3.30221553, grad/param norm = 5.1925e-01, time/batch = 0.6707s	
123/26050 (epoch 0.236), train_loss = 3.21616735, grad/param norm = 7.6009e-01, time/batch = 0.6391s	
124/26050 (epoch 0.238), train_loss = 3.38106679, grad/param norm = 1.0044e+00, time/batch = 0.6392s	
125/26050 (epoch 0.240), train_loss = 3.22685131, grad/param norm = 1.0547e+00, time/batch = 0.6399s	
126/26050 (epoch 0.242), train_loss = 3.36956165, grad/param norm = 8.3303e-01, time/batch = 0.6405s	
127/26050 (epoch 0.244), train_loss = 3.30376597, grad/param norm = 6.8121e-01, time/batch = 0.6443s	
128/26050 (epoch 0.246), train_loss = 3.31525917, grad/param norm = 5.3503e-01, time/batch = 0.6402s	
129/26050 (epoch 0.248), train_loss = 3.34138828, grad/param norm = 4.7597e-01, time/batch = 0.6417s	
130/26050 (epoch 0.250), train_loss = 3.24437774, grad/param norm = 4.7683e-01, time/batch = 0.6398s	
131/26050 (epoch 0.251), train_loss = 3.22356130, grad/param norm = 9.7513e-01, time/batch = 0.6405s	
132/26050 (epoch 0.253), train_loss = 3.23532364, grad/param norm = 1.5648e+00, time/batch = 0.6412s	
133/26050 (epoch 0.255), train_loss = 3.51246965, grad/param norm = 1.1608e+00, time/batch = 0.6410s	
134/26050 (epoch 0.257), train_loss = 3.11243331, grad/param norm = 4.3539e-01, time/batch = 0.6412s	
135/26050 (epoch 0.259), train_loss = 3.15821033, grad/param norm = 7.5427e-01, time/batch = 0.6399s	
136/26050 (epoch 0.261), train_loss = 3.31451462, grad/param norm = 7.6239e-01, time/batch = 0.6522s	
137/26050 (epoch 0.263), train_loss = 3.20784334, grad/param norm = 5.4965e-01, time/batch = 0.6823s	
138/26050 (epoch 0.265), train_loss = 3.36380695, grad/param norm = 4.9146e-01, time/batch = 0.6477s	
139/26050 (epoch 0.267), train_loss = 3.17511370, grad/param norm = 4.9044e-01, time/batch = 0.6487s	
140/26050 (epoch 0.269), train_loss = 3.24389971, grad/param norm = 5.3222e-01, time/batch = 0.6465s	
141/26050 (epoch 0.271), train_loss = 3.17164189, grad/param norm = 7.3027e-01, time/batch = 0.6466s	
142/26050 (epoch 0.273), train_loss = 3.31625121, grad/param norm = 9.0370e-01, time/batch = 0.6395s	
143/26050 (epoch 0.274), train_loss = 3.33252814, grad/param norm = 1.1776e+00, time/batch = 0.6394s	
144/26050 (epoch 0.276), train_loss = 3.26536383, grad/param norm = 8.3611e-01, time/batch = 0.6448s	
145/26050 (epoch 0.278), train_loss = 3.16347882, grad/param norm = 7.1405e-01, time/batch = 0.6462s	
146/26050 (epoch 0.280), train_loss = 3.17600069, grad/param norm = 6.5237e-01, time/batch = 0.6541s	
147/26050 (epoch 0.282), train_loss = 3.15694490, grad/param norm = 7.0525e-01, time/batch = 0.6569s	
148/26050 (epoch 0.284), train_loss = 3.16610220, grad/param norm = 1.1950e+00, time/batch = 0.6471s	
149/26050 (epoch 0.286), train_loss = 3.25066744, grad/param norm = 1.7483e+00, time/batch = 0.6437s	
150/26050 (epoch 0.288), train_loss = 3.13055659, grad/param norm = 1.2582e+00, time/batch = 0.6432s	
151/26050 (epoch 0.290), train_loss = 3.15720153, grad/param norm = 5.3621e-01, time/batch = 0.6405s	
152/26050 (epoch 0.292), train_loss = 3.20665318, grad/param norm = 5.2153e-01, time/batch = 0.6820s	
153/26050 (epoch 0.294), train_loss = 3.14926888, grad/param norm = 4.6037e-01, time/batch = 0.6625s	
154/26050 (epoch 0.296), train_loss = 3.13970502, grad/param norm = 5.0370e-01, time/batch = 0.6418s	
155/26050 (epoch 0.298), train_loss = 3.10762289, grad/param norm = 7.2023e-01, time/batch = 0.6431s	
156/26050 (epoch 0.299), train_loss = 3.12653222, grad/param norm = 9.7413e-01, time/batch = 0.6494s	
157/26050 (epoch 0.301), train_loss = 3.20403946, grad/param norm = 1.2151e+00, time/batch = 0.6551s	
158/26050 (epoch 0.303), train_loss = 3.10452034, grad/param norm = 6.6860e-01, time/batch = 0.6404s	
159/26050 (epoch 0.305), train_loss = 3.14868709, grad/param norm = 3.8552e-01, time/batch = 0.6450s	
160/26050 (epoch 0.307), train_loss = 3.03483340, grad/param norm = 5.1423e-01, time/batch = 0.6401s	
161/26050 (epoch 0.309), train_loss = 3.03663431, grad/param norm = 5.3376e-01, time/batch = 0.6387s	
162/26050 (epoch 0.311), train_loss = 3.28814417, grad/param norm = 4.7858e-01, time/batch = 0.6397s	
163/26050 (epoch 0.313), train_loss = 3.09400554, grad/param norm = 5.4861e-01, time/batch = 0.6414s	
164/26050 (epoch 0.315), train_loss = 3.15372414, grad/param norm = 7.4693e-01, time/batch = 0.6413s	
165/26050 (epoch 0.317), train_loss = 3.10290838, grad/param norm = 9.7970e-01, time/batch = 0.6534s	
166/26050 (epoch 0.319), train_loss = 3.21369963, grad/param norm = 8.3736e-01, time/batch = 0.6574s	
167/26050 (epoch 0.321), train_loss = 3.12706054, grad/param norm = 5.6222e-01, time/batch = 0.6582s	
168/26050 (epoch 0.322), train_loss = 3.01119393, grad/param norm = 5.1117e-01, time/batch = 0.6581s	
169/26050 (epoch 0.324), train_loss = 3.03388584, grad/param norm = 6.1814e-01, time/batch = 0.6562s	
170/26050 (epoch 0.326), train_loss = 3.13198653, grad/param norm = 8.6841e-01, time/batch = 0.6573s	
171/26050 (epoch 0.328), train_loss = 3.12714087, grad/param norm = 1.1459e+00, time/batch = 0.6466s	
172/26050 (epoch 0.330), train_loss = 3.18736040, grad/param norm = 1.8419e+00, time/batch = 0.6712s	
173/26050 (epoch 0.332), train_loss = 3.21811685, grad/param norm = 1.5795e+00, time/batch = 0.6709s	
174/26050 (epoch 0.334), train_loss = 3.11046495, grad/param norm = 9.5013e-01, time/batch = 0.6664s	
175/26050 (epoch 0.336), train_loss = 3.07470693, grad/param norm = 8.1357e-01, time/batch = 0.6585s	
176/26050 (epoch 0.338), train_loss = 3.01120285, grad/param norm = 5.9321e-01, time/batch = 0.6452s	
177/26050 (epoch 0.340), train_loss = 3.03952152, grad/param norm = 4.4606e-01, time/batch = 0.6414s	
178/26050 (epoch 0.342), train_loss = 3.02484161, grad/param norm = 3.7567e-01, time/batch = 0.6390s	
179/26050 (epoch 0.344), train_loss = 3.06640261, grad/param norm = 4.7726e-01, time/batch = 0.6410s	
180/26050 (epoch 0.345), train_loss = 3.01997641, grad/param norm = 5.3563e-01, time/batch = 0.6420s	
181/26050 (epoch 0.347), train_loss = 3.05751598, grad/param norm = 4.3744e-01, time/batch = 0.6411s	
182/26050 (epoch 0.349), train_loss = 2.92639301, grad/param norm = 4.6176e-01, time/batch = 0.6484s	
183/26050 (epoch 0.351), train_loss = 2.98741136, grad/param norm = 6.2251e-01, time/batch = 0.6762s	
184/26050 (epoch 0.353), train_loss = 2.93848863, grad/param norm = 7.1039e-01, time/batch = 0.6659s	
185/26050 (epoch 0.355), train_loss = 2.94626095, grad/param norm = 8.0522e-01, time/batch = 0.6753s	
186/26050 (epoch 0.357), train_loss = 2.96854295, grad/param norm = 7.6767e-01, time/batch = 0.6760s	
187/26050 (epoch 0.359), train_loss = 2.93298055, grad/param norm = 1.2248e+00, time/batch = 0.6723s	
188/26050 (epoch 0.361), train_loss = 3.04169238, grad/param norm = 1.9102e+00, time/batch = 0.6723s	
189/26050 (epoch 0.363), train_loss = 3.10385937, grad/param norm = 1.5688e+00, time/batch = 0.6420s	
190/26050 (epoch 0.365), train_loss = 2.86501225, grad/param norm = 7.4792e-01, time/batch = 0.6412s	
191/26050 (epoch 0.367), train_loss = 2.92016415, grad/param norm = 5.2656e-01, time/batch = 0.6403s	
192/26050 (epoch 0.369), train_loss = 3.08089675, grad/param norm = 7.4061e-01, time/batch = 0.6394s	
193/26050 (epoch 0.370), train_loss = 3.02333457, grad/param norm = 8.0204e-01, time/batch = 0.6386s	
194/26050 (epoch 0.372), train_loss = 3.15321644, grad/param norm = 7.4031e-01, time/batch = 0.6398s	
195/26050 (epoch 0.374), train_loss = 3.02687264, grad/param norm = 7.4700e-01, time/batch = 0.6402s	
196/26050 (epoch 0.376), train_loss = 3.07983895, grad/param norm = 5.8120e-01, time/batch = 0.6538s	
197/26050 (epoch 0.378), train_loss = 2.91286306, grad/param norm = 4.4354e-01, time/batch = 0.6452s	
198/26050 (epoch 0.380), train_loss = 3.06775787, grad/param norm = 7.6445e-01, time/batch = 0.6432s	
199/26050 (epoch 0.382), train_loss = 3.12868435, grad/param norm = 6.6069e-01, time/batch = 0.6397s	
200/26050 (epoch 0.384), train_loss = 2.95044935, grad/param norm = 6.2731e-01, time/batch = 0.6391s	
201/26050 (epoch 0.386), train_loss = 3.03121998, grad/param norm = 6.5536e-01, time/batch = 0.6467s	
202/26050 (epoch 0.388), train_loss = 2.86358696, grad/param norm = 7.1552e-01, time/batch = 0.6425s	
203/26050 (epoch 0.390), train_loss = 3.03116047, grad/param norm = 6.0345e-01, time/batch = 0.6492s	
204/26050 (epoch 0.392), train_loss = 2.82119138, grad/param norm = 5.4237e-01, time/batch = 0.6411s	
205/26050 (epoch 0.393), train_loss = 2.92199337, grad/param norm = 4.6462e-01, time/batch = 0.6400s	
206/26050 (epoch 0.395), train_loss = 2.92146177, grad/param norm = 6.1416e-01, time/batch = 0.6386s	
207/26050 (epoch 0.397), train_loss = 3.04292749, grad/param norm = 7.7945e-01, time/batch = 0.6406s	
208/26050 (epoch 0.399), train_loss = 2.81627600, grad/param norm = 7.8096e-01, time/batch = 0.6562s	
209/26050 (epoch 0.401), train_loss = 2.90043145, grad/param norm = 8.0805e-01, time/batch = 0.6824s	
210/26050 (epoch 0.403), train_loss = 2.88822241, grad/param norm = 1.1951e+00, time/batch = 0.6475s	
211/26050 (epoch 0.405), train_loss = 2.87831948, grad/param norm = 6.9379e-01, time/batch = 0.6415s	
212/26050 (epoch 0.407), train_loss = 2.91183685, grad/param norm = 8.2136e-01, time/batch = 0.6399s	
213/26050 (epoch 0.409), train_loss = 2.96860199, grad/param norm = 7.7521e-01, time/batch = 0.6395s	
214/26050 (epoch 0.411), train_loss = 2.93473907, grad/param norm = 6.6443e-01, time/batch = 0.6443s	
215/26050 (epoch 0.413), train_loss = 2.86958671, grad/param norm = 3.3940e-01, time/batch = 0.6586s	
216/26050 (epoch 0.415), train_loss = 2.88156046, grad/param norm = 5.0399e-01, time/batch = 0.6444s	
217/26050 (epoch 0.417), train_loss = 2.86197590, grad/param norm = 8.6940e-01, time/batch = 0.6447s	
218/26050 (epoch 0.418), train_loss = 3.05955939, grad/param norm = 1.2679e+00, time/batch = 0.6393s	
219/26050 (epoch 0.420), train_loss = 2.70080580, grad/param norm = 1.3011e+00, time/batch = 0.6434s	
220/26050 (epoch 0.422), train_loss = 2.87337453, grad/param norm = 9.3949e-01, time/batch = 0.6428s	
221/26050 (epoch 0.424), train_loss = 2.92609369, grad/param norm = 6.2240e-01, time/batch = 0.6425s	
222/26050 (epoch 0.426), train_loss = 2.93689487, grad/param norm = 8.1262e-01, time/batch = 0.6437s	
223/26050 (epoch 0.428), train_loss = 2.86551283, grad/param norm = 9.5576e-01, time/batch = 0.6409s	
224/26050 (epoch 0.430), train_loss = 2.81730471, grad/param norm = 7.8324e-01, time/batch = 0.6798s	
225/26050 (epoch 0.432), train_loss = 2.89306460, grad/param norm = 4.9645e-01, time/batch = 0.6726s	
226/26050 (epoch 0.434), train_loss = 3.05914269, grad/param norm = 5.1183e-01, time/batch = 0.6555s	
227/26050 (epoch 0.436), train_loss = 2.85394783, grad/param norm = 6.6563e-01, time/batch = 0.6408s	
228/26050 (epoch 0.438), train_loss = 2.79998895, grad/param norm = 6.6153e-01, time/batch = 0.6409s	
229/26050 (epoch 0.440), train_loss = 2.91708828, grad/param norm = 5.4793e-01, time/batch = 0.6392s	
230/26050 (epoch 0.441), train_loss = 2.85342384, grad/param norm = 5.3941e-01, time/batch = 0.6533s	
231/26050 (epoch 0.443), train_loss = 2.77053804, grad/param norm = 4.1225e-01, time/batch = 0.6530s	
232/26050 (epoch 0.445), train_loss = 2.74620429, grad/param norm = 4.1720e-01, time/batch = 0.6518s	
233/26050 (epoch 0.447), train_loss = 2.89436277, grad/param norm = 6.4505e-01, time/batch = 0.6629s	
234/26050 (epoch 0.449), train_loss = 2.84957337, grad/param norm = 9.7618e-01, time/batch = 0.6500s	
235/26050 (epoch 0.451), train_loss = 2.89519215, grad/param norm = 8.4515e-01, time/batch = 0.6537s	
236/26050 (epoch 0.453), train_loss = 2.68344827, grad/param norm = 6.4541e-01, time/batch = 0.6538s	
237/26050 (epoch 0.455), train_loss = 2.77496656, grad/param norm = 6.9624e-01, time/batch = 0.6470s	
238/26050 (epoch 0.457), train_loss = 2.72461036, grad/param norm = 6.4481e-01, time/batch = 0.6469s	
239/26050 (epoch 0.459), train_loss = 2.86947567, grad/param norm = 6.9184e-01, time/batch = 0.6502s	
240/26050 (epoch 0.461), train_loss = 2.69259752, grad/param norm = 7.5010e-01, time/batch = 0.6509s	
241/26050 (epoch 0.463), train_loss = 2.77942319, grad/param norm = 8.4871e-01, time/batch = 0.6545s	
242/26050 (epoch 0.464), train_loss = 2.84948535, grad/param norm = 1.2234e+00, time/batch = 0.6577s	
243/26050 (epoch 0.466), train_loss = 2.86945764, grad/param norm = 1.0739e+00, time/batch = 0.6542s	
244/26050 (epoch 0.468), train_loss = 2.84600083, grad/param norm = 8.0466e-01, time/batch = 0.6535s	
245/26050 (epoch 0.470), train_loss = 2.83619016, grad/param norm = 6.4891e-01, time/batch = 0.6565s	
246/26050 (epoch 0.472), train_loss = 2.95416253, grad/param norm = 5.2820e-01, time/batch = 0.6536s	
247/26050 (epoch 0.474), train_loss = 2.97418630, grad/param norm = 5.9307e-01, time/batch = 0.6498s	
248/26050 (epoch 0.476), train_loss = 2.90771608, grad/param norm = 5.5400e-01, time/batch = 0.6552s	
249/26050 (epoch 0.478), train_loss = 2.74073471, grad/param norm = 4.4921e-01, time/batch = 0.6492s	
250/26050 (epoch 0.480), train_loss = 2.78916640, grad/param norm = 5.6059e-01, time/batch = 0.6417s	
251/26050 (epoch 0.482), train_loss = 2.67601830, grad/param norm = 4.7996e-01, time/batch = 0.6416s	
252/26050 (epoch 0.484), train_loss = 2.75144546, grad/param norm = 4.5612e-01, time/batch = 0.6419s	
253/26050 (epoch 0.486), train_loss = 2.81706527, grad/param norm = 6.1509e-01, time/batch = 0.6416s	
254/26050 (epoch 0.488), train_loss = 2.99436320, grad/param norm = 7.4126e-01, time/batch = 0.6443s	
255/26050 (epoch 0.489), train_loss = 2.92951446, grad/param norm = 1.1255e+00, time/batch = 0.6402s	
256/26050 (epoch 0.491), train_loss = 2.74885994, grad/param norm = 8.3499e-01, time/batch = 0.6437s	
257/26050 (epoch 0.493), train_loss = 2.67087596, grad/param norm = 5.0135e-01, time/batch = 0.6418s	
258/26050 (epoch 0.495), train_loss = 2.73852356, grad/param norm = 5.7254e-01, time/batch = 0.6402s	
259/26050 (epoch 0.497), train_loss = 2.78770478, grad/param norm = 8.0414e-01, time/batch = 0.6699s	
260/26050 (epoch 0.499), train_loss = 2.58171617, grad/param norm = 9.4339e-01, time/batch = 0.6731s	
261/26050 (epoch 0.501), train_loss = 2.65236829, grad/param norm = 7.7017e-01, time/batch = 0.6432s	
262/26050 (epoch 0.503), train_loss = 2.83107698, grad/param norm = 6.0870e-01, time/batch = 0.6427s	
263/26050 (epoch 0.505), train_loss = 2.76031748, grad/param norm = 4.3230e-01, time/batch = 0.6470s	
264/26050 (epoch 0.507), train_loss = 2.74677274, grad/param norm = 3.8788e-01, time/batch = 0.6611s	
265/26050 (epoch 0.509), train_loss = 2.91387069, grad/param norm = 4.4742e-01, time/batch = 0.6527s	
266/26050 (epoch 0.511), train_loss = 2.64051941, grad/param norm = 3.3127e-01, time/batch = 0.6546s	
267/26050 (epoch 0.512), train_loss = 2.80131335, grad/param norm = 4.3697e-01, time/batch = 0.6424s	
268/26050 (epoch 0.514), train_loss = 2.79318010, grad/param norm = 5.4446e-01, time/batch = 0.6458s	
269/26050 (epoch 0.516), train_loss = 2.74449314, grad/param norm = 6.7031e-01, time/batch = 0.6410s	
270/26050 (epoch 0.518), train_loss = 2.70947518, grad/param norm = 6.6154e-01, time/batch = 0.6447s	
271/26050 (epoch 0.520), train_loss = 2.65551171, grad/param norm = 6.5906e-01, time/batch = 0.6485s	
272/26050 (epoch 0.522), train_loss = 2.77982682, grad/param norm = 7.3096e-01, time/batch = 0.6429s	
273/26050 (epoch 0.524), train_loss = 2.94468079, grad/param norm = 5.6949e-01, time/batch = 0.6415s	
274/26050 (epoch 0.526), train_loss = 2.75043361, grad/param norm = 4.2778e-01, time/batch = 0.6449s	
275/26050 (epoch 0.528), train_loss = 2.77698332, grad/param norm = 5.7253e-01, time/batch = 0.6443s	
276/26050 (epoch 0.530), train_loss = 2.79909778, grad/param norm = 7.1856e-01, time/batch = 0.6445s	
277/26050 (epoch 0.532), train_loss = 2.73143875, grad/param norm = 6.7576e-01, time/batch = 0.6418s	
278/26050 (epoch 0.534), train_loss = 2.81993384, grad/param norm = 6.1042e-01, time/batch = 0.6480s	
279/26050 (epoch 0.536), train_loss = 2.66372204, grad/param norm = 4.9545e-01, time/batch = 0.6482s	
280/26050 (epoch 0.537), train_loss = 2.71945118, grad/param norm = 4.8155e-01, time/batch = 0.6472s	
281/26050 (epoch 0.539), train_loss = 2.55112994, grad/param norm = 6.3601e-01, time/batch = 0.6412s	
282/26050 (epoch 0.541), train_loss = 2.76110089, grad/param norm = 7.1295e-01, time/batch = 0.6440s	
283/26050 (epoch 0.543), train_loss = 2.73095704, grad/param norm = 7.2071e-01, time/batch = 0.6420s	
284/26050 (epoch 0.545), train_loss = 2.73856704, grad/param norm = 8.7984e-01, time/batch = 0.6395s	
285/26050 (epoch 0.547), train_loss = 2.91266908, grad/param norm = 6.5094e-01, time/batch = 0.6400s	
286/26050 (epoch 0.549), train_loss = 2.70492841, grad/param norm = 3.9922e-01, time/batch = 0.6398s	
287/26050 (epoch 0.551), train_loss = 2.66173379, grad/param norm = 5.3296e-01, time/batch = 0.6419s	
288/26050 (epoch 0.553), train_loss = 2.68514488, grad/param norm = 5.4081e-01, time/batch = 0.6412s	
289/26050 (epoch 0.555), train_loss = 2.62888015, grad/param norm = 6.0248e-01, time/batch = 0.6386s	
290/26050 (epoch 0.557), train_loss = 2.77633667, grad/param norm = 5.0107e-01, time/batch = 0.6786s	
291/26050 (epoch 0.559), train_loss = 2.72340477, grad/param norm = 4.5701e-01, time/batch = 0.6640s	
292/26050 (epoch 0.560), train_loss = 2.70450215, grad/param norm = 5.3016e-01, time/batch = 0.6407s	
293/26050 (epoch 0.562), train_loss = 2.65794627, grad/param norm = 5.7989e-01, time/batch = 0.6448s	
294/26050 (epoch 0.564), train_loss = 2.80695494, grad/param norm = 3.9826e-01, time/batch = 0.6404s	
295/26050 (epoch 0.566), train_loss = 2.70462552, grad/param norm = 3.6291e-01, time/batch = 0.6432s	
296/26050 (epoch 0.568), train_loss = 2.66810115, grad/param norm = 3.2092e-01, time/batch = 0.6462s	
297/26050 (epoch 0.570), train_loss = 2.78293241, grad/param norm = 4.6541e-01, time/batch = 0.6396s	
298/26050 (epoch 0.572), train_loss = 2.82163552, grad/param norm = 5.1162e-01, time/batch = 0.6389s	
299/26050 (epoch 0.574), train_loss = 2.74778487, grad/param norm = 6.1663e-01, time/batch = 0.6401s	
300/26050 (epoch 0.576), train_loss = 2.72139386, grad/param norm = 9.3833e-01, time/batch = 0.6404s	
301/26050 (epoch 0.578), train_loss = 2.84297683, grad/param norm = 8.0449e-01, time/batch = 0.6503s	
302/26050 (epoch 0.580), train_loss = 2.63814996, grad/param norm = 4.8184e-01, time/batch = 0.6635s	
303/26050 (epoch 0.582), train_loss = 2.80367697, grad/param norm = 5.6421e-01, time/batch = 0.6606s	
304/26050 (epoch 0.583), train_loss = 2.78017555, grad/param norm = 7.2126e-01, time/batch = 0.6603s	
305/26050 (epoch 0.585), train_loss = 2.83225591, grad/param norm = 7.4359e-01, time/batch = 0.6755s	
306/26050 (epoch 0.587), train_loss = 2.69496600, grad/param norm = 5.4731e-01, time/batch = 0.6792s	
307/26050 (epoch 0.589), train_loss = 2.59024480, grad/param norm = 5.0988e-01, time/batch = 0.6465s	
308/26050 (epoch 0.591), train_loss = 2.75063835, grad/param norm = 6.3470e-01, time/batch = 0.6515s	
309/26050 (epoch 0.593), train_loss = 2.76319926, grad/param norm = 7.8986e-01, time/batch = 0.6591s	
310/26050 (epoch 0.595), train_loss = 2.69559576, grad/param norm = 6.9478e-01, time/batch = 0.6641s	
311/26050 (epoch 0.597), train_loss = 2.57849496, grad/param norm = 4.7792e-01, time/batch = 0.6593s	
312/26050 (epoch 0.599), train_loss = 2.50302945, grad/param norm = 5.1087e-01, time/batch = 0.6628s	
313/26050 (epoch 0.601), train_loss = 2.91395008, grad/param norm = 6.2842e-01, time/batch = 0.6539s	
314/26050 (epoch 0.603), train_loss = 2.70829399, grad/param norm = 5.8084e-01, time/batch = 0.6452s	
315/26050 (epoch 0.605), train_loss = 2.72919376, grad/param norm = 5.0135e-01, time/batch = 0.6394s	
316/26050 (epoch 0.607), train_loss = 2.66593916, grad/param norm = 4.8291e-01, time/batch = 0.6397s	
317/26050 (epoch 0.608), train_loss = 2.73005833, grad/param norm = 3.5898e-01, time/batch = 0.6492s	
318/26050 (epoch 0.610), train_loss = 2.61964562, grad/param norm = 3.7540e-01, time/batch = 0.6572s	
319/26050 (epoch 0.612), train_loss = 2.69598972, grad/param norm = 3.6016e-01, time/batch = 0.6519s	
320/26050 (epoch 0.614), train_loss = 2.58458929, grad/param norm = 5.9507e-01, time/batch = 0.6397s	
321/26050 (epoch 0.616), train_loss = 2.89334658, grad/param norm = 9.8901e-01, time/batch = 0.6413s	
322/26050 (epoch 0.618), train_loss = 2.66632208, grad/param norm = 9.9545e-01, time/batch = 0.6408s	
323/26050 (epoch 0.620), train_loss = 2.73400330, grad/param norm = 6.9777e-01, time/batch = 0.6403s	
324/26050 (epoch 0.622), train_loss = 2.48285319, grad/param norm = 3.7300e-01, time/batch = 0.6401s	
325/26050 (epoch 0.624), train_loss = 2.56555688, grad/param norm = 3.6166e-01, time/batch = 0.6398s	
326/26050 (epoch 0.626), train_loss = 2.67923540, grad/param norm = 5.6599e-01, time/batch = 0.6466s	
327/26050 (epoch 0.628), train_loss = 2.73997786, grad/param norm = 7.2367e-01, time/batch = 0.6394s	
328/26050 (epoch 0.630), train_loss = 2.72646685, grad/param norm = 7.4680e-01, time/batch = 0.6400s	
329/26050 (epoch 0.631), train_loss = 2.66596980, grad/param norm = 3.9027e-01, time/batch = 0.6391s	
330/26050 (epoch 0.633), train_loss = 2.52868287, grad/param norm = 4.4012e-01, time/batch = 0.6406s	
331/26050 (epoch 0.635), train_loss = 2.53354847, grad/param norm = 3.5674e-01, time/batch = 0.6413s	
332/26050 (epoch 0.637), train_loss = 2.54878961, grad/param norm = 3.4232e-01, time/batch = 0.6397s	
333/26050 (epoch 0.639), train_loss = 2.69350857, grad/param norm = 3.2911e-01, time/batch = 0.6419s	
334/26050 (epoch 0.641), train_loss = 2.47778658, grad/param norm = 4.8379e-01, time/batch = 0.6409s	
335/26050 (epoch 0.643), train_loss = 2.64666537, grad/param norm = 6.9330e-01, time/batch = 0.6412s	
336/26050 (epoch 0.645), train_loss = 2.77617288, grad/param norm = 7.4464e-01, time/batch = 0.6405s	
337/26050 (epoch 0.647), train_loss = 2.55913606, grad/param norm = 5.9611e-01, time/batch = 0.6398s	
338/26050 (epoch 0.649), train_loss = 2.70560484, grad/param norm = 6.4445e-01, time/batch = 0.6402s	
339/26050 (epoch 0.651), train_loss = 2.64561992, grad/param norm = 3.9997e-01, time/batch = 0.6398s	
340/26050 (epoch 0.653), train_loss = 2.54648930, grad/param norm = 3.8549e-01, time/batch = 0.6401s	
341/26050 (epoch 0.655), train_loss = 2.62200761, grad/param norm = 4.0961e-01, time/batch = 0.6403s	
342/26050 (epoch 0.656), train_loss = 2.62196726, grad/param norm = 4.9102e-01, time/batch = 0.6463s	
343/26050 (epoch 0.658), train_loss = 2.58235427, grad/param norm = 4.3871e-01, time/batch = 0.6398s	
344/26050 (epoch 0.660), train_loss = 2.53671746, grad/param norm = 4.2471e-01, time/batch = 0.6398s	
345/26050 (epoch 0.662), train_loss = 2.51704837, grad/param norm = 5.2805e-01, time/batch = 0.6407s	
346/26050 (epoch 0.664), train_loss = 2.42621813, grad/param norm = 4.3491e-01, time/batch = 0.6410s	
347/26050 (epoch 0.666), train_loss = 2.62631471, grad/param norm = 3.1738e-01, time/batch = 0.6412s	
348/26050 (epoch 0.668), train_loss = 2.33183076, grad/param norm = 4.0347e-01, time/batch = 0.6437s	
349/26050 (epoch 0.670), train_loss = 2.75022340, grad/param norm = 5.8331e-01, time/batch = 0.6424s	
350/26050 (epoch 0.672), train_loss = 2.55202369, grad/param norm = 7.5170e-01, time/batch = 0.6428s	
351/26050 (epoch 0.674), train_loss = 2.57682021, grad/param norm = 9.2931e-01, time/batch = 0.6431s	
352/26050 (epoch 0.676), train_loss = 2.64964374, grad/param norm = 7.9578e-01, time/batch = 0.6412s	
353/26050 (epoch 0.678), train_loss = 2.65845311, grad/param norm = 4.6467e-01, time/batch = 0.6429s	
354/26050 (epoch 0.679), train_loss = 2.58465020, grad/param norm = 4.5014e-01, time/batch = 0.6415s	
355/26050 (epoch 0.681), train_loss = 2.63224582, grad/param norm = 4.3064e-01, time/batch = 0.6433s	
356/26050 (epoch 0.683), train_loss = 2.50073488, grad/param norm = 4.7714e-01, time/batch = 0.6616s	
357/26050 (epoch 0.685), train_loss = 2.49714904, grad/param norm = 5.7761e-01, time/batch = 0.6540s	
358/26050 (epoch 0.687), train_loss = 2.42029278, grad/param norm = 4.5574e-01, time/batch = 0.6595s	
359/26050 (epoch 0.689), train_loss = 2.50720642, grad/param norm = 3.3033e-01, time/batch = 0.6644s	
360/26050 (epoch 0.691), train_loss = 2.48303583, grad/param norm = 4.0599e-01, time/batch = 0.6631s	
361/26050 (epoch 0.693), train_loss = 2.58826959, grad/param norm = 6.0532e-01, time/batch = 0.6422s	
362/26050 (epoch 0.695), train_loss = 2.55148889, grad/param norm = 6.3064e-01, time/batch = 0.6420s	
363/26050 (epoch 0.697), train_loss = 2.53908162, grad/param norm = 5.5111e-01, time/batch = 0.6526s	
364/26050 (epoch 0.699), train_loss = 2.58822941, grad/param norm = 6.0169e-01, time/batch = 0.6460s	
365/26050 (epoch 0.701), train_loss = 2.58746985, grad/param norm = 5.7405e-01, time/batch = 0.6434s	
366/26050 (epoch 0.702), train_loss = 2.69794785, grad/param norm = 5.5916e-01, time/batch = 0.6408s	
367/26050 (epoch 0.704), train_loss = 2.60993667, grad/param norm = 5.2384e-01, time/batch = 0.6824s	
368/26050 (epoch 0.706), train_loss = 2.50746505, grad/param norm = 3.8595e-01, time/batch = 0.6600s	
369/26050 (epoch 0.708), train_loss = 2.48680453, grad/param norm = 3.1783e-01, time/batch = 0.6487s	
370/26050 (epoch 0.710), train_loss = 2.71595090, grad/param norm = 3.9140e-01, time/batch = 0.6413s	
371/26050 (epoch 0.712), train_loss = 2.67399547, grad/param norm = 4.9297e-01, time/batch = 0.6438s	
372/26050 (epoch 0.714), train_loss = 2.54969726, grad/param norm = 6.1858e-01, time/batch = 0.6568s	
373/26050 (epoch 0.716), train_loss = 2.77504168, grad/param norm = 6.0725e-01, time/batch = 0.6423s	
374/26050 (epoch 0.718), train_loss = 2.54677009, grad/param norm = 6.1309e-01, time/batch = 0.6446s	
375/26050 (epoch 0.720), train_loss = 2.37173139, grad/param norm = 3.9533e-01, time/batch = 0.6525s	
376/26050 (epoch 0.722), train_loss = 2.60686862, grad/param norm = 3.8779e-01, time/batch = 0.6464s	
377/26050 (epoch 0.724), train_loss = 2.44487638, grad/param norm = 7.9707e-01, time/batch = 0.6394s	
378/26050 (epoch 0.726), train_loss = 2.67567469, grad/param norm = 7.6196e-01, time/batch = 0.6395s	
379/26050 (epoch 0.727), train_loss = 2.60137583, grad/param norm = 4.6330e-01, time/batch = 0.6418s	
380/26050 (epoch 0.729), train_loss = 2.58494971, grad/param norm = 3.7902e-01, time/batch = 0.6417s	
381/26050 (epoch 0.731), train_loss = 2.47257356, grad/param norm = 3.6608e-01, time/batch = 0.6537s	
382/26050 (epoch 0.733), train_loss = 2.51467729, grad/param norm = 3.6847e-01, time/batch = 0.6750s	
383/26050 (epoch 0.735), train_loss = 2.71994481, grad/param norm = 4.1541e-01, time/batch = 0.6773s	
384/26050 (epoch 0.737), train_loss = 2.55213936, grad/param norm = 3.9722e-01, time/batch = 0.6435s	
385/26050 (epoch 0.739), train_loss = 2.52314552, grad/param norm = 3.9560e-01, time/batch = 0.6418s	
386/26050 (epoch 0.741), train_loss = 2.41444522, grad/param norm = 3.3261e-01, time/batch = 0.6510s	
387/26050 (epoch 0.743), train_loss = 2.70961599, grad/param norm = 4.4593e-01, time/batch = 0.6507s	
388/26050 (epoch 0.745), train_loss = 2.51743999, grad/param norm = 9.1747e-01, time/batch = 0.6410s	
389/26050 (epoch 0.747), train_loss = 2.52471904, grad/param norm = 6.6967e-01, time/batch = 0.6444s	
390/26050 (epoch 0.749), train_loss = 2.62731150, grad/param norm = 6.9566e-01, time/batch = 0.6400s	
391/26050 (epoch 0.750), train_loss = 2.55101156, grad/param norm = 5.9784e-01, time/batch = 0.6416s	
392/26050 (epoch 0.752), train_loss = 2.55220522, grad/param norm = 5.1421e-01, time/batch = 0.6399s	
393/26050 (epoch 0.754), train_loss = 2.36810712, grad/param norm = 4.0619e-01, time/batch = 0.6419s	
394/26050 (epoch 0.756), train_loss = 2.60513427, grad/param norm = 3.3616e-01, time/batch = 0.6407s	
395/26050 (epoch 0.758), train_loss = 2.59338106, grad/param norm = 3.7057e-01, time/batch = 0.6405s	
396/26050 (epoch 0.760), train_loss = 2.42510453, grad/param norm = 4.0393e-01, time/batch = 0.6404s	
397/26050 (epoch 0.762), train_loss = 2.51173708, grad/param norm = 5.2439e-01, time/batch = 0.6519s	
398/26050 (epoch 0.764), train_loss = 2.57162735, grad/param norm = 4.4905e-01, time/batch = 0.6827s	
399/26050 (epoch 0.766), train_loss = 2.55391627, grad/param norm = 3.7713e-01, time/batch = 0.6477s	
400/26050 (epoch 0.768), train_loss = 2.48079917, grad/param norm = 3.8676e-01, time/batch = 0.6420s	
401/26050 (epoch 0.770), train_loss = 2.46218399, grad/param norm = 4.7204e-01, time/batch = 0.6410s	
402/26050 (epoch 0.772), train_loss = 2.52557147, grad/param norm = 3.9674e-01, time/batch = 0.6430s	
403/26050 (epoch 0.774), train_loss = 2.47054168, grad/param norm = 4.5966e-01, time/batch = 0.6443s	
404/26050 (epoch 0.775), train_loss = 2.46709431, grad/param norm = 5.2111e-01, time/batch = 0.6403s	
405/26050 (epoch 0.777), train_loss = 2.43425781, grad/param norm = 7.1570e-01, time/batch = 0.6411s	
406/26050 (epoch 0.779), train_loss = 2.57522979, grad/param norm = 9.1019e-01, time/batch = 0.6388s	
407/26050 (epoch 0.781), train_loss = 2.55475721, grad/param norm = 6.8676e-01, time/batch = 0.6411s	
408/26050 (epoch 0.783), train_loss = 2.42615254, grad/param norm = 3.4491e-01, time/batch = 0.6419s	
409/26050 (epoch 0.785), train_loss = 2.46151172, grad/param norm = 2.9864e-01, time/batch = 0.6420s	
410/26050 (epoch 0.787), train_loss = 2.44207540, grad/param norm = 4.1278e-01, time/batch = 0.6422s	
411/26050 (epoch 0.789), train_loss = 2.62576695, grad/param norm = 6.2308e-01, time/batch = 0.6512s	
412/26050 (epoch 0.791), train_loss = 2.53138858, grad/param norm = 5.7278e-01, time/batch = 0.6450s	
413/26050 (epoch 0.793), train_loss = 2.39178222, grad/param norm = 3.5578e-01, time/batch = 0.6795s	
414/26050 (epoch 0.795), train_loss = 2.48829146, grad/param norm = 3.5725e-01, time/batch = 0.6648s	
415/26050 (epoch 0.797), train_loss = 2.29685445, grad/param norm = 3.7124e-01, time/batch = 0.6386s	
416/26050 (epoch 0.798), train_loss = 2.35615489, grad/param norm = 3.4488e-01, time/batch = 0.6394s	
417/26050 (epoch 0.800), train_loss = 2.38851681, grad/param norm = 3.3534e-01, time/batch = 0.6395s	
418/26050 (epoch 0.802), train_loss = 2.50972211, grad/param norm = 3.4174e-01, time/batch = 0.6433s	
419/26050 (epoch 0.804), train_loss = 2.51464246, grad/param norm = 2.8824e-01, time/batch = 0.6482s	
420/26050 (epoch 0.806), train_loss = 2.53222496, grad/param norm = 3.0814e-01, time/batch = 0.6391s	
421/26050 (epoch 0.808), train_loss = 2.31831090, grad/param norm = 4.1660e-01, time/batch = 0.6405s	
422/26050 (epoch 0.810), train_loss = 2.47355865, grad/param norm = 6.4719e-01, time/batch = 0.6471s	
423/26050 (epoch 0.812), train_loss = 2.42136741, grad/param norm = 6.8493e-01, time/batch = 0.6409s	
424/26050 (epoch 0.814), train_loss = 2.39733219, grad/param norm = 4.4713e-01, time/batch = 0.6398s	
425/26050 (epoch 0.816), train_loss = 2.44089200, grad/param norm = 3.6678e-01, time/batch = 0.6424s	
426/26050 (epoch 0.818), train_loss = 2.55441823, grad/param norm = 3.6608e-01, time/batch = 0.6412s	
427/26050 (epoch 0.820), train_loss = 2.50255623, grad/param norm = 3.7249e-01, time/batch = 0.6403s	
428/26050 (epoch 0.821), train_loss = 2.52754785, grad/param norm = 3.5824e-01, time/batch = 0.6588s	
429/26050 (epoch 0.823), train_loss = 2.61913599, grad/param norm = 5.2894e-01, time/batch = 0.6821s	
430/26050 (epoch 0.825), train_loss = 2.50750186, grad/param norm = 5.5641e-01, time/batch = 0.6402s	
431/26050 (epoch 0.827), train_loss = 2.61302836, grad/param norm = 4.8995e-01, time/batch = 0.6402s	
432/26050 (epoch 0.829), train_loss = 2.52785333, grad/param norm = 4.6660e-01, time/batch = 0.6434s	
433/26050 (epoch 0.831), train_loss = 2.55891376, grad/param norm = 4.2476e-01, time/batch = 0.6492s	
434/26050 (epoch 0.833), train_loss = 2.57024096, grad/param norm = 3.8499e-01, time/batch = 0.6402s	
435/26050 (epoch 0.835), train_loss = 2.65303016, grad/param norm = 4.6314e-01, time/batch = 0.6395s	
436/26050 (epoch 0.837), train_loss = 2.39826433, grad/param norm = 6.2463e-01, time/batch = 0.6396s	
437/26050 (epoch 0.839), train_loss = 2.67972548, grad/param norm = 5.7444e-01, time/batch = 0.6506s	
438/26050 (epoch 0.841), train_loss = 2.54292729, grad/param norm = 4.2551e-01, time/batch = 0.6553s	
439/26050 (epoch 0.843), train_loss = 2.50564836, grad/param norm = 3.7783e-01, time/batch = 0.6554s	
440/26050 (epoch 0.845), train_loss = 2.35850251, grad/param norm = 3.6106e-01, time/batch = 0.6543s	
441/26050 (epoch 0.846), train_loss = 2.49338605, grad/param norm = 4.3874e-01, time/batch = 0.6602s	
442/26050 (epoch 0.848), train_loss = 2.42127527, grad/param norm = 4.3783e-01, time/batch = 0.6569s	
443/26050 (epoch 0.850), train_loss = 2.34262181, grad/param norm = 4.7420e-01, time/batch = 0.6495s	
444/26050 (epoch 0.852), train_loss = 2.52362495, grad/param norm = 5.8563e-01, time/batch = 0.6830s	
445/26050 (epoch 0.854), train_loss = 2.51714127, grad/param norm = 4.0655e-01, time/batch = 0.6640s	
446/26050 (epoch 0.856), train_loss = 2.49508311, grad/param norm = 3.5591e-01, time/batch = 0.6544s	
447/26050 (epoch 0.858), train_loss = 2.33515174, grad/param norm = 4.0364e-01, time/batch = 0.6550s	
448/26050 (epoch 0.860), train_loss = 2.50962227, grad/param norm = 3.5713e-01, time/batch = 0.6685s	
449/26050 (epoch 0.862), train_loss = 2.50419090, grad/param norm = 4.2332e-01, time/batch = 0.6727s	
450/26050 (epoch 0.864), train_loss = 2.36951488, grad/param norm = 5.9922e-01, time/batch = 0.6402s	
451/26050 (epoch 0.866), train_loss = 2.41613938, grad/param norm = 5.9125e-01, time/batch = 0.6727s	
452/26050 (epoch 0.868), train_loss = 2.58616466, grad/param norm = 5.3943e-01, time/batch = 0.6593s	
453/26050 (epoch 0.869), train_loss = 2.33369401, grad/param norm = 4.3849e-01, time/batch = 0.6429s	
454/26050 (epoch 0.871), train_loss = 2.24247080, grad/param norm = 4.0876e-01, time/batch = 0.6417s	
455/26050 (epoch 0.873), train_loss = 2.31126171, grad/param norm = 6.0450e-01, time/batch = 0.6385s	
456/26050 (epoch 0.875), train_loss = 2.42917649, grad/param norm = 6.3824e-01, time/batch = 0.6404s	
457/26050 (epoch 0.877), train_loss = 2.32907314, grad/param norm = 5.2625e-01, time/batch = 0.6410s	
458/26050 (epoch 0.879), train_loss = 2.49616380, grad/param norm = 3.9845e-01, time/batch = 0.6393s	
459/26050 (epoch 0.881), train_loss = 2.51848571, grad/param norm = 3.6424e-01, time/batch = 0.6380s	
460/26050 (epoch 0.883), train_loss = 2.49194312, grad/param norm = 4.3794e-01, time/batch = 0.6446s	
461/26050 (epoch 0.885), train_loss = 2.32165265, grad/param norm = 4.8602e-01, time/batch = 0.6389s	
462/26050 (epoch 0.887), train_loss = 2.37908636, grad/param norm = 4.1828e-01, time/batch = 0.6465s	
463/26050 (epoch 0.889), train_loss = 2.33110901, grad/param norm = 4.0030e-01, time/batch = 0.6512s	
464/26050 (epoch 0.891), train_loss = 2.21691539, grad/param norm = 4.0835e-01, time/batch = 0.6465s	
465/26050 (epoch 0.893), train_loss = 2.27133017, grad/param norm = 3.2853e-01, time/batch = 0.6501s	
466/26050 (epoch 0.894), train_loss = 2.32993346, grad/param norm = 3.9583e-01, time/batch = 0.6633s	
467/26050 (epoch 0.896), train_loss = 2.37814537, grad/param norm = 3.4875e-01, time/batch = 0.6451s	
468/26050 (epoch 0.898), train_loss = 2.41073546, grad/param norm = 3.9374e-01, time/batch = 0.6483s	
469/26050 (epoch 0.900), train_loss = 2.72501084, grad/param norm = 4.1919e-01, time/batch = 0.6470s	
470/26050 (epoch 0.902), train_loss = 2.55399549, grad/param norm = 4.8249e-01, time/batch = 0.6828s	
471/26050 (epoch 0.904), train_loss = 2.52734907, grad/param norm = 3.3000e-01, time/batch = 0.6534s	
472/26050 (epoch 0.906), train_loss = 2.41811893, grad/param norm = 3.1415e-01, time/batch = 0.6469s	
473/26050 (epoch 0.908), train_loss = 2.36639485, grad/param norm = 3.5560e-01, time/batch = 0.6468s	
474/26050 (epoch 0.910), train_loss = 2.42330643, grad/param norm = 3.5356e-01, time/batch = 0.6434s	
475/26050 (epoch 0.912), train_loss = 2.68353252, grad/param norm = 4.2309e-01, time/batch = 0.6403s	
476/26050 (epoch 0.914), train_loss = 2.55079804, grad/param norm = 4.3291e-01, time/batch = 0.6448s	
477/26050 (epoch 0.916), train_loss = 2.36832533, grad/param norm = 4.5658e-01, time/batch = 0.6413s	
478/26050 (epoch 0.917), train_loss = 2.30624111, grad/param norm = 4.0551e-01, time/batch = 0.6388s	
479/26050 (epoch 0.919), train_loss = 2.43490029, grad/param norm = 3.7050e-01, time/batch = 0.6449s	
480/26050 (epoch 0.921), train_loss = 2.21877460, grad/param norm = 5.0859e-01, time/batch = 0.6423s	
481/26050 (epoch 0.923), train_loss = 2.35886130, grad/param norm = 5.5484e-01, time/batch = 0.6390s	
482/26050 (epoch 0.925), train_loss = 2.29604065, grad/param norm = 6.3670e-01, time/batch = 0.6417s	
483/26050 (epoch 0.927), train_loss = 2.36469749, grad/param norm = 5.6026e-01, time/batch = 0.6393s	
484/26050 (epoch 0.929), train_loss = 2.35621917, grad/param norm = 4.3115e-01, time/batch = 0.6385s	
485/26050 (epoch 0.931), train_loss = 2.60471978, grad/param norm = 3.4323e-01, time/batch = 0.6732s	
486/26050 (epoch 0.933), train_loss = 2.40675615, grad/param norm = 3.6735e-01, time/batch = 0.6693s	
487/26050 (epoch 0.935), train_loss = 2.19808369, grad/param norm = 3.8288e-01, time/batch = 0.6398s	
488/26050 (epoch 0.937), train_loss = 2.38864110, grad/param norm = 3.6720e-01, time/batch = 0.6400s	
489/26050 (epoch 0.939), train_loss = 2.27729238, grad/param norm = 3.3661e-01, time/batch = 0.6397s	
490/26050 (epoch 0.940), train_loss = 2.40667159, grad/param norm = 3.9087e-01, time/batch = 0.6400s	
491/26050 (epoch 0.942), train_loss = 2.45036690, grad/param norm = 3.2856e-01, time/batch = 0.6456s	
492/26050 (epoch 0.944), train_loss = 2.33936982, grad/param norm = 3.8557e-01, time/batch = 0.6412s	
493/26050 (epoch 0.946), train_loss = 2.43867175, grad/param norm = 3.8069e-01, time/batch = 0.6395s	
494/26050 (epoch 0.948), train_loss = 2.13235339, grad/param norm = 5.2574e-01, time/batch = 0.6407s	
495/26050 (epoch 0.950), train_loss = 2.38831450, grad/param norm = 6.0955e-01, time/batch = 0.6476s	
496/26050 (epoch 0.952), train_loss = 2.51636525, grad/param norm = 5.1430e-01, time/batch = 0.6414s	
497/26050 (epoch 0.954), train_loss = 2.51553380, grad/param norm = 3.3750e-01, time/batch = 0.6401s	
498/26050 (epoch 0.956), train_loss = 2.51000011, grad/param norm = 3.9084e-01, time/batch = 0.6384s	
499/26050 (epoch 0.958), train_loss = 2.50526698, grad/param norm = 3.9008e-01, time/batch = 0.6389s	
500/26050 (epoch 0.960), train_loss = 2.44068188, grad/param norm = 3.9463e-01, time/batch = 0.6540s	
501/26050 (epoch 0.962), train_loss = 2.37924688, grad/param norm = 3.7749e-01, time/batch = 0.6833s	
502/26050 (epoch 0.964), train_loss = 2.60538133, grad/param norm = 4.3047e-01, time/batch = 0.6457s	
503/26050 (epoch 0.965), train_loss = 2.26399636, grad/param norm = 3.9996e-01, time/batch = 0.6410s	
504/26050 (epoch 0.967), train_loss = 2.65409911, grad/param norm = 3.9619e-01, time/batch = 0.6436s	
505/26050 (epoch 0.969), train_loss = 2.38013669, grad/param norm = 3.5971e-01, time/batch = 0.6502s	
506/26050 (epoch 0.971), train_loss = 2.23634482, grad/param norm = 3.9090e-01, time/batch = 0.6439s	
507/26050 (epoch 0.973), train_loss = 2.27607843, grad/param norm = 4.6262e-01, time/batch = 0.6426s	
508/26050 (epoch 0.975), train_loss = 2.39049277, grad/param norm = 3.8259e-01, time/batch = 0.6418s	
509/26050 (epoch 0.977), train_loss = 2.43827486, grad/param norm = 3.6023e-01, time/batch = 0.6417s	
510/26050 (epoch 0.979), train_loss = 2.21170193, grad/param norm = 3.5970e-01, time/batch = 0.6492s	
511/26050 (epoch 0.981), train_loss = 2.38961775, grad/param norm = 3.1527e-01, time/batch = 0.6412s	
512/26050 (epoch 0.983), train_loss = 2.37425080, grad/param norm = 3.3393e-01, time/batch = 0.6387s	
513/26050 (epoch 0.985), train_loss = 2.32470865, grad/param norm = 3.6835e-01, time/batch = 0.6395s	
514/26050 (epoch 0.987), train_loss = 2.48494325, grad/param norm = 4.0800e-01, time/batch = 0.6395s	
515/26050 (epoch 0.988), train_loss = 2.58636605, grad/param norm = 5.1502e-01, time/batch = 0.6394s	
516/26050 (epoch 0.990), train_loss = 2.46128306, grad/param norm = 4.9634e-01, time/batch = 0.6808s	
517/26050 (epoch 0.992), train_loss = 2.53640406, grad/param norm = 5.3898e-01, time/batch = 0.6643s	
518/26050 (epoch 0.994), train_loss = 2.48556337, grad/param norm = 5.1439e-01, time/batch = 0.6440s	
519/26050 (epoch 0.996), train_loss = 2.51543005, grad/param norm = 3.6094e-01, time/batch = 0.6392s	
520/26050 (epoch 0.998), train_loss = 2.38092969, grad/param norm = 4.4028e-01, time/batch = 0.6382s	
521/26050 (epoch 1.000), train_loss = 2.33866769, grad/param norm = 3.9460e-01, time/batch = 0.6399s	
522/26050 (epoch 1.002), train_loss = 2.25035843, grad/param norm = 3.7718e-01, time/batch = 0.6401s	
523/26050 (epoch 1.004), train_loss = 2.30740292, grad/param norm = 4.5265e-01, time/batch = 0.6382s	
524/26050 (epoch 1.006), train_loss = 2.24580820, grad/param norm = 4.8956e-01, time/batch = 0.6379s	
525/26050 (epoch 1.008), train_loss = 2.31739893, grad/param norm = 5.2113e-01, time/batch = 0.6399s	
526/26050 (epoch 1.010), train_loss = 2.39534992, grad/param norm = 3.9526e-01, time/batch = 0.6409s	
527/26050 (epoch 1.012), train_loss = 2.42098798, grad/param norm = 2.8253e-01, time/batch = 0.6378s	
528/26050 (epoch 1.013), train_loss = 2.75496636, grad/param norm = 3.1932e-01, time/batch = 0.6378s	
529/26050 (epoch 1.015), train_loss = 2.32253103, grad/param norm = 3.5660e-01, time/batch = 0.6389s	
530/26050 (epoch 1.017), train_loss = 2.27847869, grad/param norm = 3.1391e-01, time/batch = 0.6377s	
531/26050 (epoch 1.019), train_loss = 2.36686206, grad/param norm = 2.7202e-01, time/batch = 0.6619s	
532/26050 (epoch 1.021), train_loss = 2.40662821, grad/param norm = 3.2275e-01, time/batch = 0.6816s	
533/26050 (epoch 1.023), train_loss = 2.28033824, grad/param norm = 3.2573e-01, time/batch = 0.6408s	
534/26050 (epoch 1.025), train_loss = 2.32873663, grad/param norm = 3.5302e-01, time/batch = 0.6402s	
535/26050 (epoch 1.027), train_loss = 2.25169811, grad/param norm = 4.3547e-01, time/batch = 0.6384s	
536/26050 (epoch 1.029), train_loss = 2.36724408, grad/param norm = 5.3920e-01, time/batch = 0.6394s	
537/26050 (epoch 1.031), train_loss = 2.38052672, grad/param norm = 4.9729e-01, time/batch = 0.6409s	
538/26050 (epoch 1.033), train_loss = 2.34299183, grad/param norm = 4.2406e-01, time/batch = 0.6399s	
539/26050 (epoch 1.035), train_loss = 2.50516094, grad/param norm = 3.6777e-01, time/batch = 0.6400s	
540/26050 (epoch 1.036), train_loss = 2.30844967, grad/param norm = 3.3804e-01, time/batch = 0.6431s	
541/26050 (epoch 1.038), train_loss = 2.31754817, grad/param norm = 3.1983e-01, time/batch = 0.6578s	
542/26050 (epoch 1.040), train_loss = 2.32938963, grad/param norm = 3.7920e-01, time/batch = 0.6475s	
543/26050 (epoch 1.042), train_loss = 2.23074499, grad/param norm = 4.2031e-01, time/batch = 0.6510s	
544/26050 (epoch 1.044), train_loss = 2.32166853, grad/param norm = 3.7187e-01, time/batch = 0.6451s	
545/26050 (epoch 1.046), train_loss = 2.19415549, grad/param norm = 3.2238e-01, time/batch = 0.6477s	
546/26050 (epoch 1.048), train_loss = 2.35853210, grad/param norm = 4.0707e-01, time/batch = 0.6462s	
547/26050 (epoch 1.050), train_loss = 2.16217081, grad/param norm = 4.3042e-01, time/batch = 0.6827s	
548/26050 (epoch 1.052), train_loss = 2.33311421, grad/param norm = 4.9235e-01, time/batch = 0.6576s	
549/26050 (epoch 1.054), train_loss = 2.30609877, grad/param norm = 6.3433e-01, time/batch = 0.6463s	
550/26050 (epoch 1.056), train_loss = 2.03204851, grad/param norm = 4.5064e-01, time/batch = 0.6512s	
551/26050 (epoch 1.058), train_loss = 2.27082736, grad/param norm = 4.0089e-01, time/batch = 0.6425s	
552/26050 (epoch 1.060), train_loss = 2.31014908, grad/param norm = 3.4497e-01, time/batch = 0.6416s	
553/26050 (epoch 1.061), train_loss = 2.24309386, grad/param norm = 3.2747e-01, time/batch = 0.6466s	
554/26050 (epoch 1.063), train_loss = 2.16872819, grad/param norm = 2.4357e-01, time/batch = 0.6511s	
555/26050 (epoch 1.065), train_loss = 2.31821801, grad/param norm = 3.3697e-01, time/batch = 0.6479s	
556/26050 (epoch 1.067), train_loss = 2.28967531, grad/param norm = 4.6447e-01, time/batch = 0.6433s	
557/26050 (epoch 1.069), train_loss = 2.37383712, grad/param norm = 3.2640e-01, time/batch = 0.6526s	
558/26050 (epoch 1.071), train_loss = 2.37593960, grad/param norm = 3.2271e-01, time/batch = 0.6752s	
559/26050 (epoch 1.073), train_loss = 2.47202432, grad/param norm = 3.6565e-01, time/batch = 0.6774s	
560/26050 (epoch 1.075), train_loss = 2.32203117, grad/param norm = 3.9648e-01, time/batch = 0.6744s	
561/26050 (epoch 1.077), train_loss = 2.18133961, grad/param norm = 3.2438e-01, time/batch = 0.6716s	
562/26050 (epoch 1.079), train_loss = 2.46015690, grad/param norm = 3.4988e-01, time/batch = 0.6609s	
563/26050 (epoch 1.081), train_loss = 2.25714724, grad/param norm = 2.9519e-01, time/batch = 0.6454s	
564/26050 (epoch 1.083), train_loss = 2.35374333, grad/param norm = 3.2798e-01, time/batch = 0.6395s	
565/26050 (epoch 1.084), train_loss = 2.54000759, grad/param norm = 3.0665e-01, time/batch = 0.6395s	
566/26050 (epoch 1.086), train_loss = 2.49416268, grad/param norm = 3.2226e-01, time/batch = 0.6455s	
567/26050 (epoch 1.088), train_loss = 2.25641474, grad/param norm = 3.1300e-01, time/batch = 0.6560s	
568/26050 (epoch 1.090), train_loss = 2.44308543, grad/param norm = 3.0079e-01, time/batch = 0.6427s	
569/26050 (epoch 1.092), train_loss = 2.18127903, grad/param norm = 3.1612e-01, time/batch = 0.6444s	
570/26050 (epoch 1.094), train_loss = 2.40200948, grad/param norm = 2.9970e-01, time/batch = 0.6397s	
571/26050 (epoch 1.096), train_loss = 2.11049346, grad/param norm = 3.2221e-01, time/batch = 0.6414s	
572/26050 (epoch 1.098), train_loss = 2.20630811, grad/param norm = 3.3064e-01, time/batch = 0.6527s	
573/26050 (epoch 1.100), train_loss = 2.21757543, grad/param norm = 3.7649e-01, time/batch = 0.6827s	
574/26050 (epoch 1.102), train_loss = 2.36338058, grad/param norm = 3.7357e-01, time/batch = 0.6517s	
575/26050 (epoch 1.104), train_loss = 2.42622152, grad/param norm = 3.3984e-01, time/batch = 0.6391s	
576/26050 (epoch 1.106), train_loss = 2.18676896, grad/param norm = 4.4267e-01, time/batch = 0.6395s	
577/26050 (epoch 1.107), train_loss = 2.09516207, grad/param norm = 5.1996e-01, time/batch = 0.6441s	
578/26050 (epoch 1.109), train_loss = 2.26159512, grad/param norm = 5.5613e-01, time/batch = 0.6383s	
579/26050 (epoch 1.111), train_loss = 2.53329786, grad/param norm = 4.7466e-01, time/batch = 0.6396s	
580/26050 (epoch 1.113), train_loss = 2.28441279, grad/param norm = 4.4892e-01, time/batch = 0.6398s	
581/26050 (epoch 1.115), train_loss = 2.41528990, grad/param norm = 3.8940e-01, time/batch = 0.6394s	
582/26050 (epoch 1.117), train_loss = 2.40037021, grad/param norm = 3.9118e-01, time/batch = 0.6383s	
583/26050 (epoch 1.119), train_loss = 2.31865951, grad/param norm = 3.8859e-01, time/batch = 0.6409s	
584/26050 (epoch 1.121), train_loss = 2.29733506, grad/param norm = 4.1384e-01, time/batch = 0.6392s	
585/26050 (epoch 1.123), train_loss = 2.17677019, grad/param norm = 3.6929e-01, time/batch = 0.6408s	
586/26050 (epoch 1.125), train_loss = 1.96710921, grad/param norm = 2.9627e-01, time/batch = 0.6390s	
587/26050 (epoch 1.127), train_loss = 2.19610706, grad/param norm = 2.5974e-01, time/batch = 0.6396s	
588/26050 (epoch 1.129), train_loss = 2.10225338, grad/param norm = 3.4294e-01, time/batch = 0.6729s	
589/26050 (epoch 1.131), train_loss = 2.19654565, grad/param norm = 2.8544e-01, time/batch = 0.6712s	
590/26050 (epoch 1.132), train_loss = 2.17098917, grad/param norm = 2.2778e-01, time/batch = 0.6433s	
591/26050 (epoch 1.134), train_loss = 2.18273726, grad/param norm = 2.9417e-01, time/batch = 0.6411s	
592/26050 (epoch 1.136), train_loss = 2.25134569, grad/param norm = 2.9502e-01, time/batch = 0.6413s	
593/26050 (epoch 1.138), train_loss = 2.26096973, grad/param norm = 2.7922e-01, time/batch = 0.6565s	
594/26050 (epoch 1.140), train_loss = 2.28353716, grad/param norm = 3.2420e-01, time/batch = 0.6477s	
595/26050 (epoch 1.142), train_loss = 2.24249710, grad/param norm = 3.7573e-01, time/batch = 0.6408s	
596/26050 (epoch 1.144), train_loss = 2.14572640, grad/param norm = 3.9631e-01, time/batch = 0.6390s	
597/26050 (epoch 1.146), train_loss = 2.10954105, grad/param norm = 3.6728e-01, time/batch = 0.6393s	
598/26050 (epoch 1.148), train_loss = 2.24483809, grad/param norm = 3.4593e-01, time/batch = 0.6386s	
599/26050 (epoch 1.150), train_loss = 2.25636289, grad/param norm = 3.1552e-01, time/batch = 0.6399s	
600/26050 (epoch 1.152), train_loss = 2.49533086, grad/param norm = 4.8004e-01, time/batch = 0.6408s	
601/26050 (epoch 1.154), train_loss = 2.17602018, grad/param norm = 4.5416e-01, time/batch = 0.6401s	
602/26050 (epoch 1.155), train_loss = 2.22885727, grad/param norm = 3.5456e-01, time/batch = 0.6447s	
603/26050 (epoch 1.157), train_loss = 2.23481922, grad/param norm = 2.7914e-01, time/batch = 0.6549s	
604/26050 (epoch 1.159), train_loss = 2.33270152, grad/param norm = 2.5636e-01, time/batch = 0.6826s	
605/26050 (epoch 1.161), train_loss = 2.43132350, grad/param norm = 3.0759e-01, time/batch = 0.6593s	
606/26050 (epoch 1.163), train_loss = 2.22589628, grad/param norm = 3.5607e-01, time/batch = 0.6498s	
607/26050 (epoch 1.165), train_loss = 1.96117937, grad/param norm = 4.5855e-01, time/batch = 0.6442s	
608/26050 (epoch 1.167), train_loss = 2.45271154, grad/param norm = 5.6796e-01, time/batch = 0.6402s	
609/26050 (epoch 1.169), train_loss = 2.43405262, grad/param norm = 4.3723e-01, time/batch = 0.6394s	
610/26050 (epoch 1.171), train_loss = 2.18181121, grad/param norm = 3.2751e-01, time/batch = 0.6407s	
611/26050 (epoch 1.173), train_loss = 2.24059944, grad/param norm = 3.4884e-01, time/batch = 0.6421s	
612/26050 (epoch 1.175), train_loss = 2.32907844, grad/param norm = 4.0594e-01, time/batch = 0.6463s	
613/26050 (epoch 1.177), train_loss = 2.36850041, grad/param norm = 3.5245e-01, time/batch = 0.6503s	
614/26050 (epoch 1.179), train_loss = 1.97042694, grad/param norm = 3.4069e-01, time/batch = 0.6492s	
615/26050 (epoch 1.180), train_loss = 2.38228885, grad/param norm = 3.5686e-01, time/batch = 0.6569s	
616/26050 (epoch 1.182), train_loss = 2.60751091, grad/param norm = 3.1933e-01, time/batch = 0.6619s	
617/26050 (epoch 1.184), train_loss = 2.32286969, grad/param norm = 2.9388e-01, time/batch = 0.6568s	
618/26050 (epoch 1.186), train_loss = 2.08127169, grad/param norm = 3.0864e-01, time/batch = 0.6475s	
619/26050 (epoch 1.188), train_loss = 2.17511505, grad/param norm = 3.2805e-01, time/batch = 0.6558s	
620/26050 (epoch 1.190), train_loss = 2.28360508, grad/param norm = 3.8290e-01, time/batch = 0.6471s	
621/26050 (epoch 1.192), train_loss = 2.24773512, grad/param norm = 4.1578e-01, time/batch = 0.6401s	
622/26050 (epoch 1.194), train_loss = 2.20427676, grad/param norm = 4.3589e-01, time/batch = 0.6395s	
623/26050 (epoch 1.196), train_loss = 2.39015797, grad/param norm = 4.1730e-01, time/batch = 0.6394s	
624/26050 (epoch 1.198), train_loss = 2.10906498, grad/param norm = 3.9846e-01, time/batch = 0.6384s	
625/26050 (epoch 1.200), train_loss = 2.19572027, grad/param norm = 4.7788e-01, time/batch = 0.6438s	
626/26050 (epoch 1.202), train_loss = 2.12834732, grad/param norm = 3.2794e-01, time/batch = 0.6421s	
627/26050 (epoch 1.203), train_loss = 2.23547825, grad/param norm = 3.6685e-01, time/batch = 0.6399s	
628/26050 (epoch 1.205), train_loss = 2.17745643, grad/param norm = 3.6803e-01, time/batch = 0.6410s	
629/26050 (epoch 1.207), train_loss = 2.24448639, grad/param norm = 4.0319e-01, time/batch = 0.6398s	
630/26050 (epoch 1.209), train_loss = 2.16831719, grad/param norm = 2.9287e-01, time/batch = 0.6429s	
631/26050 (epoch 1.211), train_loss = 2.19980468, grad/param norm = 2.8391e-01, time/batch = 0.6412s	
632/26050 (epoch 1.213), train_loss = 2.31046613, grad/param norm = 3.9477e-01, time/batch = 0.6441s	
633/26050 (epoch 1.215), train_loss = 2.29944254, grad/param norm = 3.7316e-01, time/batch = 0.6561s	
634/26050 (epoch 1.217), train_loss = 2.26520367, grad/param norm = 3.7182e-01, time/batch = 0.6685s	
635/26050 (epoch 1.219), train_loss = 2.16638767, grad/param norm = 3.1485e-01, time/batch = 0.6792s	
636/26050 (epoch 1.221), train_loss = 2.15366752, grad/param norm = 3.1928e-01, time/batch = 0.6452s	
637/26050 (epoch 1.223), train_loss = 2.37737327, grad/param norm = 3.3606e-01, time/batch = 0.6390s	
638/26050 (epoch 1.225), train_loss = 2.24495438, grad/param norm = 3.2017e-01, time/batch = 0.6402s	
639/26050 (epoch 1.226), train_loss = 2.32740094, grad/param norm = 3.7523e-01, time/batch = 0.6375s	
640/26050 (epoch 1.228), train_loss = 2.31172656, grad/param norm = 2.9290e-01, time/batch = 0.6460s	
641/26050 (epoch 1.230), train_loss = 2.19994695, grad/param norm = 3.1800e-01, time/batch = 0.6510s	
642/26050 (epoch 1.232), train_loss = 2.28906330, grad/param norm = 3.1445e-01, time/batch = 0.6394s	
643/26050 (epoch 1.234), train_loss = 2.05745422, grad/param norm = 2.9302e-01, time/batch = 0.6368s	
644/26050 (epoch 1.236), train_loss = 2.30019865, grad/param norm = 3.2052e-01, time/batch = 0.6367s	
645/26050 (epoch 1.238), train_loss = 2.07695857, grad/param norm = 3.4871e-01, time/batch = 0.6398s	
646/26050 (epoch 1.240), train_loss = 2.19885970, grad/param norm = 3.4703e-01, time/batch = 0.6468s	
647/26050 (epoch 1.242), train_loss = 2.25933763, grad/param norm = 2.7990e-01, time/batch = 0.6375s	
648/26050 (epoch 1.244), train_loss = 2.29077037, grad/param norm = 3.2893e-01, time/batch = 0.6378s	
649/26050 (epoch 1.246), train_loss = 2.13870377, grad/param norm = 2.9390e-01, time/batch = 0.6527s	
650/26050 (epoch 1.248), train_loss = 2.33543782, grad/param norm = 3.3333e-01, time/batch = 0.6827s	
651/26050 (epoch 1.250), train_loss = 2.27613790, grad/param norm = 3.1155e-01, time/batch = 0.6545s	
652/26050 (epoch 1.251), train_loss = 2.11764038, grad/param norm = 3.0475e-01, time/batch = 0.6381s	
653/26050 (epoch 1.253), train_loss = 2.13093851, grad/param norm = 3.3540e-01, time/batch = 0.6368s	
654/26050 (epoch 1.255), train_loss = 2.38485800, grad/param norm = 4.6231e-01, time/batch = 0.6389s	
655/26050 (epoch 1.257), train_loss = 2.24507861, grad/param norm = 5.6770e-01, time/batch = 0.6385s	
656/26050 (epoch 1.259), train_loss = 2.25864225, grad/param norm = 6.0457e-01, time/batch = 0.6402s	
657/26050 (epoch 1.261), train_loss = 2.19806014, grad/param norm = 4.4242e-01, time/batch = 0.6390s	
658/26050 (epoch 1.263), train_loss = 2.28846316, grad/param norm = 3.9545e-01, time/batch = 0.6395s	
659/26050 (epoch 1.265), train_loss = 2.38682017, grad/param norm = 3.2883e-01, time/batch = 0.6499s	
660/26050 (epoch 1.267), train_loss = 2.28016755, grad/param norm = 2.5049e-01, time/batch = 0.6426s	
661/26050 (epoch 1.269), train_loss = 2.46138679, grad/param norm = 2.7680e-01, time/batch = 0.6460s	
662/26050 (epoch 1.271), train_loss = 2.14648310, grad/param norm = 2.9827e-01, time/batch = 0.6421s	
663/26050 (epoch 1.273), train_loss = 2.41151143, grad/param norm = 3.4933e-01, time/batch = 0.6383s	
664/26050 (epoch 1.274), train_loss = 2.26042047, grad/param norm = 3.0037e-01, time/batch = 0.6387s	
665/26050 (epoch 1.276), train_loss = 2.15358291, grad/param norm = 3.4236e-01, time/batch = 0.6727s	
666/26050 (epoch 1.278), train_loss = 2.28471168, grad/param norm = 3.6789e-01, time/batch = 0.6753s	
667/26050 (epoch 1.280), train_loss = 2.10623855, grad/param norm = 3.2951e-01, time/batch = 0.6425s	
668/26050 (epoch 1.282), train_loss = 2.20590027, grad/param norm = 3.0940e-01, time/batch = 0.6385s	
669/26050 (epoch 1.284), train_loss = 2.03220603, grad/param norm = 3.0931e-01, time/batch = 0.6382s	
670/26050 (epoch 1.286), train_loss = 2.13883848, grad/param norm = 3.2562e-01, time/batch = 0.6400s	
671/26050 (epoch 1.288), train_loss = 2.14097302, grad/param norm = 3.7979e-01, time/batch = 0.6417s	
672/26050 (epoch 1.290), train_loss = 2.08051885, grad/param norm = 3.4232e-01, time/batch = 0.6399s	
673/26050 (epoch 1.292), train_loss = 2.11817535, grad/param norm = 3.7165e-01, time/batch = 0.6396s	
674/26050 (epoch 1.294), train_loss = 2.27699997, grad/param norm = 4.3855e-01, time/batch = 0.6403s	
675/26050 (epoch 1.296), train_loss = 2.31530557, grad/param norm = 3.5705e-01, time/batch = 0.6378s	
676/26050 (epoch 1.298), train_loss = 2.16496621, grad/param norm = 3.7027e-01, time/batch = 0.6423s	
677/26050 (epoch 1.299), train_loss = 1.97659219, grad/param norm = 3.4634e-01, time/batch = 0.6399s	
678/26050 (epoch 1.301), train_loss = 2.10869717, grad/param norm = 3.0050e-01, time/batch = 0.6380s	
679/26050 (epoch 1.303), train_loss = 2.25910606, grad/param norm = 3.6089e-01, time/batch = 0.6447s	
680/26050 (epoch 1.305), train_loss = 2.21132616, grad/param norm = 3.6063e-01, time/batch = 0.6420s	
681/26050 (epoch 1.307), train_loss = 1.98809460, grad/param norm = 3.1563e-01, time/batch = 0.6547s	
682/26050 (epoch 1.309), train_loss = 2.08132325, grad/param norm = 2.9504e-01, time/batch = 0.6539s	
683/26050 (epoch 1.311), train_loss = 2.40592271, grad/param norm = 2.9751e-01, time/batch = 0.6471s	
684/26050 (epoch 1.313), train_loss = 2.25640359, grad/param norm = 3.4413e-01, time/batch = 0.6402s	
685/26050 (epoch 1.315), train_loss = 2.42835461, grad/param norm = 4.6409e-01, time/batch = 0.6397s	
686/26050 (epoch 1.317), train_loss = 2.06647611, grad/param norm = 3.8418e-01, time/batch = 0.6449s	
687/26050 (epoch 1.319), train_loss = 2.16382150, grad/param norm = 3.6021e-01, time/batch = 0.6493s	
688/26050 (epoch 1.321), train_loss = 2.23505864, grad/param norm = 3.1140e-01, time/batch = 0.6510s	
689/26050 (epoch 1.322), train_loss = 2.14414327, grad/param norm = 3.2965e-01, time/batch = 0.6386s	
690/26050 (epoch 1.324), train_loss = 2.05946279, grad/param norm = 4.1098e-01, time/batch = 0.6380s	
691/26050 (epoch 1.326), train_loss = 2.38474748, grad/param norm = 5.2544e-01, time/batch = 0.6402s	
692/26050 (epoch 1.328), train_loss = 2.21540362, grad/param norm = 4.4253e-01, time/batch = 0.6383s	
693/26050 (epoch 1.330), train_loss = 2.17344701, grad/param norm = 3.7276e-01, time/batch = 0.6388s	
694/26050 (epoch 1.332), train_loss = 2.32010813, grad/param norm = 2.6325e-01, time/batch = 0.6392s	
695/26050 (epoch 1.334), train_loss = 2.16707489, grad/param norm = 2.6374e-01, time/batch = 0.6458s	
696/26050 (epoch 1.336), train_loss = 2.04404917, grad/param norm = 2.7073e-01, time/batch = 0.6759s	
697/26050 (epoch 1.338), train_loss = 2.03208005, grad/param norm = 2.7156e-01, time/batch = 0.6666s	
698/26050 (epoch 1.340), train_loss = 2.23363307, grad/param norm = 3.3502e-01, time/batch = 0.6384s	
699/26050 (epoch 1.342), train_loss = 2.19043657, grad/param norm = 3.3279e-01, time/batch = 0.6394s	
700/26050 (epoch 1.344), train_loss = 2.16842464, grad/param norm = 3.2187e-01, time/batch = 0.6400s	
701/26050 (epoch 1.345), train_loss = 2.12931315, grad/param norm = 3.3217e-01, time/batch = 0.6394s	
702/26050 (epoch 1.347), train_loss = 2.20905865, grad/param norm = 3.4892e-01, time/batch = 0.6395s	
703/26050 (epoch 1.349), train_loss = 2.15082918, grad/param norm = 3.2806e-01, time/batch = 0.6371s	
704/26050 (epoch 1.351), train_loss = 2.09177344, grad/param norm = 2.7480e-01, time/batch = 0.6370s	
705/26050 (epoch 1.353), train_loss = 2.06762987, grad/param norm = 3.2800e-01, time/batch = 0.6366s	
706/26050 (epoch 1.355), train_loss = 2.19478426, grad/param norm = 3.5649e-01, time/batch = 0.6365s	
707/26050 (epoch 1.357), train_loss = 1.99527557, grad/param norm = 3.1156e-01, time/batch = 0.6450s	
708/26050 (epoch 1.359), train_loss = 2.07214822, grad/param norm = 3.0180e-01, time/batch = 0.6410s	
709/26050 (epoch 1.361), train_loss = 1.94363523, grad/param norm = 2.9097e-01, time/batch = 0.6399s	
710/26050 (epoch 1.363), train_loss = 2.15962232, grad/param norm = 3.6998e-01, time/batch = 0.6375s	
711/26050 (epoch 1.365), train_loss = 1.95043368, grad/param norm = 3.3076e-01, time/batch = 0.6579s	
712/26050 (epoch 1.367), train_loss = 2.09740008, grad/param norm = 3.7921e-01, time/batch = 0.6832s	
713/26050 (epoch 1.369), train_loss = 2.19165065, grad/param norm = 3.6996e-01, time/batch = 0.6425s	
714/26050 (epoch 1.370), train_loss = 2.14143040, grad/param norm = 3.4022e-01, time/batch = 0.6373s	
715/26050 (epoch 1.372), train_loss = 2.36069949, grad/param norm = 3.0108e-01, time/batch = 0.6367s	
716/26050 (epoch 1.374), train_loss = 2.34581749, grad/param norm = 3.9178e-01, time/batch = 0.6427s	
717/26050 (epoch 1.376), train_loss = 2.32090124, grad/param norm = 3.3344e-01, time/batch = 0.6386s	
718/26050 (epoch 1.378), train_loss = 2.20214610, grad/param norm = 3.3716e-01, time/batch = 0.6381s	
719/26050 (epoch 1.380), train_loss = 2.26768278, grad/param norm = 4.0220e-01, time/batch = 0.6486s	
720/26050 (epoch 1.382), train_loss = 2.43318683, grad/param norm = 2.9718e-01, time/batch = 0.6530s	
721/26050 (epoch 1.384), train_loss = 2.16556824, grad/param norm = 2.7726e-01, time/batch = 0.6522s	
722/26050 (epoch 1.386), train_loss = 2.28705585, grad/param norm = 3.3092e-01, time/batch = 0.6444s	
723/26050 (epoch 1.388), train_loss = 2.07040515, grad/param norm = 2.5995e-01, time/batch = 0.6383s	
724/26050 (epoch 1.390), train_loss = 2.07878962, grad/param norm = 2.5340e-01, time/batch = 0.6383s	
725/26050 (epoch 1.392), train_loss = 2.11570736, grad/param norm = 2.9267e-01, time/batch = 0.6521s	
726/26050 (epoch 1.393), train_loss = 2.23467379, grad/param norm = 3.0826e-01, time/batch = 0.6539s	
727/26050 (epoch 1.395), train_loss = 2.18280088, grad/param norm = 2.9891e-01, time/batch = 0.6834s	
728/26050 (epoch 1.397), train_loss = 2.26893296, grad/param norm = 2.8337e-01, time/batch = 0.6603s	
729/26050 (epoch 1.399), train_loss = 2.06575329, grad/param norm = 3.3039e-01, time/batch = 0.6453s	
730/26050 (epoch 1.401), train_loss = 2.08229000, grad/param norm = 2.9341e-01, time/batch = 0.6376s	
731/26050 (epoch 1.403), train_loss = 2.10494880, grad/param norm = 3.2579e-01, time/batch = 0.6419s	
732/26050 (epoch 1.405), train_loss = 2.15686907, grad/param norm = 3.0481e-01, time/batch = 0.6407s	
733/26050 (epoch 1.407), train_loss = 2.27065618, grad/param norm = 3.3257e-01, time/batch = 0.6400s	
734/26050 (epoch 1.409), train_loss = 2.27400122, grad/param norm = 3.2171e-01, time/batch = 0.6396s	
735/26050 (epoch 1.411), train_loss = 2.17308417, grad/param norm = 2.7835e-01, time/batch = 0.6388s	
736/26050 (epoch 1.413), train_loss = 2.20772886, grad/param norm = 2.8959e-01, time/batch = 0.6374s	
737/26050 (epoch 1.415), train_loss = 2.29582553, grad/param norm = 2.8435e-01, time/batch = 0.6436s	
738/26050 (epoch 1.417), train_loss = 2.22826265, grad/param norm = 3.0949e-01, time/batch = 0.6466s	
739/26050 (epoch 1.418), train_loss = 2.23547254, grad/param norm = 2.9022e-01, time/batch = 0.6417s	
740/26050 (epoch 1.420), train_loss = 1.92302915, grad/param norm = 2.8732e-01, time/batch = 0.6539s	
741/26050 (epoch 1.422), train_loss = 2.04456337, grad/param norm = 2.6168e-01, time/batch = 0.6428s	
742/26050 (epoch 1.424), train_loss = 2.35915282, grad/param norm = 3.0439e-01, time/batch = 0.6693s	
743/26050 (epoch 1.426), train_loss = 2.30962213, grad/param norm = 3.8959e-01, time/batch = 0.6806s	
744/26050 (epoch 1.428), train_loss = 2.08124813, grad/param norm = 2.9096e-01, time/batch = 0.6644s	
745/26050 (epoch 1.430), train_loss = 2.13238861, grad/param norm = 2.8577e-01, time/batch = 0.6457s	
746/26050 (epoch 1.432), train_loss = 2.13991446, grad/param norm = 2.7300e-01, time/batch = 0.6404s	
747/26050 (epoch 1.434), train_loss = 2.37584908, grad/param norm = 3.3355e-01, time/batch = 0.6391s	
748/26050 (epoch 1.436), train_loss = 2.32771229, grad/param norm = 3.3556e-01, time/batch = 0.6450s	
749/26050 (epoch 1.438), train_loss = 2.11395268, grad/param norm = 4.0182e-01, time/batch = 0.6571s	
750/26050 (epoch 1.440), train_loss = 2.27218674, grad/param norm = 3.6794e-01, time/batch = 0.6402s	
751/26050 (epoch 1.441), train_loss = 2.12855753, grad/param norm = 4.0139e-01, time/batch = 0.6389s	
752/26050 (epoch 1.443), train_loss = 2.07527605, grad/param norm = 4.1609e-01, time/batch = 0.6375s	
753/26050 (epoch 1.445), train_loss = 2.09987163, grad/param norm = 3.6463e-01, time/batch = 0.6787s	
754/26050 (epoch 1.447), train_loss = 2.35728725, grad/param norm = 2.9834e-01, time/batch = 0.6682s	
755/26050 (epoch 1.449), train_loss = 2.02346391, grad/param norm = 2.8547e-01, time/batch = 0.6371s	
756/26050 (epoch 1.451), train_loss = 2.21445254, grad/param norm = 3.0309e-01, time/batch = 0.6475s	
757/26050 (epoch 1.453), train_loss = 1.92228479, grad/param norm = 3.0158e-01, time/batch = 0.6395s	
758/26050 (epoch 1.455), train_loss = 2.09178633, grad/param norm = 2.8418e-01, time/batch = 0.6378s	
759/26050 (epoch 1.457), train_loss = 2.12096153, grad/param norm = 3.0885e-01, time/batch = 0.6391s	
760/26050 (epoch 1.459), train_loss = 2.31097793, grad/param norm = 3.7601e-01, time/batch = 0.6388s	
761/26050 (epoch 1.461), train_loss = 2.13700962, grad/param norm = 3.2267e-01, time/batch = 0.6399s	
762/26050 (epoch 1.463), train_loss = 2.09084484, grad/param norm = 2.8260e-01, time/batch = 0.6376s	
763/26050 (epoch 1.464), train_loss = 2.22775748, grad/param norm = 3.5315e-01, time/batch = 0.6379s	
764/26050 (epoch 1.466), train_loss = 2.20528158, grad/param norm = 2.6635e-01, time/batch = 0.6379s	
765/26050 (epoch 1.468), train_loss = 2.23785826, grad/param norm = 2.9997e-01, time/batch = 0.6488s	
766/26050 (epoch 1.470), train_loss = 2.27474957, grad/param norm = 3.4615e-01, time/batch = 0.6524s	
767/26050 (epoch 1.472), train_loss = 2.41881337, grad/param norm = 3.7787e-01, time/batch = 0.6384s	
768/26050 (epoch 1.474), train_loss = 2.39439875, grad/param norm = 3.3148e-01, time/batch = 0.6364s	
769/26050 (epoch 1.476), train_loss = 2.29969420, grad/param norm = 2.9854e-01, time/batch = 0.6389s	
770/26050 (epoch 1.478), train_loss = 2.13652559, grad/param norm = 2.7478e-01, time/batch = 0.6379s	
771/26050 (epoch 1.480), train_loss = 2.19816138, grad/param norm = 2.7907e-01, time/batch = 0.6376s	
772/26050 (epoch 1.482), train_loss = 2.05421787, grad/param norm = 3.4434e-01, time/batch = 0.6444s	
773/26050 (epoch 1.484), train_loss = 2.05721029, grad/param norm = 3.0343e-01, time/batch = 0.6393s	
774/26050 (epoch 1.486), train_loss = 2.23471277, grad/param norm = 2.7193e-01, time/batch = 0.6380s	
775/26050 (epoch 1.488), train_loss = 2.44604346, grad/param norm = 2.6920e-01, time/batch = 0.6398s	
776/26050 (epoch 1.489), train_loss = 2.32440821, grad/param norm = 3.0191e-01, time/batch = 0.6383s	
777/26050 (epoch 1.491), train_loss = 2.04969906, grad/param norm = 3.3089e-01, time/batch = 0.6382s	
778/26050 (epoch 1.493), train_loss = 2.04373036, grad/param norm = 3.6772e-01, time/batch = 0.6387s	
779/26050 (epoch 1.495), train_loss = 2.19566217, grad/param norm = 3.2065e-01, time/batch = 0.6400s	
780/26050 (epoch 1.497), train_loss = 2.12473037, grad/param norm = 3.0646e-01, time/batch = 0.6399s	
781/26050 (epoch 1.499), train_loss = 2.00767691, grad/param norm = 2.6898e-01, time/batch = 0.6410s	
782/26050 (epoch 1.501), train_loss = 2.03788253, grad/param norm = 2.8335e-01, time/batch = 0.6412s	
783/26050 (epoch 1.503), train_loss = 2.23786894, grad/param norm = 4.3642e-01, time/batch = 0.6387s	
784/26050 (epoch 1.505), train_loss = 2.21403994, grad/param norm = 4.6152e-01, time/batch = 0.6779s	
785/26050 (epoch 1.507), train_loss = 2.20532288, grad/param norm = 3.0371e-01, time/batch = 0.6581s	
786/26050 (epoch 1.509), train_loss = 2.38237823, grad/param norm = 3.0241e-01, time/batch = 0.6390s	
787/26050 (epoch 1.511), train_loss = 2.03465899, grad/param norm = 2.6506e-01, time/batch = 0.6414s	
788/26050 (epoch 1.512), train_loss = 2.19045310, grad/param norm = 2.7015e-01, time/batch = 0.6508s	
789/26050 (epoch 1.514), train_loss = 2.19557877, grad/param norm = 2.8693e-01, time/batch = 0.6429s	
790/26050 (epoch 1.516), train_loss = 2.16780129, grad/param norm = 3.0964e-01, time/batch = 0.6400s	
791/26050 (epoch 1.518), train_loss = 2.15082093, grad/param norm = 2.7404e-01, time/batch = 0.6449s	
792/26050 (epoch 1.520), train_loss = 2.12980305, grad/param norm = 3.4050e-01, time/batch = 0.6536s	
793/26050 (epoch 1.522), train_loss = 2.19697946, grad/param norm = 3.3808e-01, time/batch = 0.6517s	
794/26050 (epoch 1.524), train_loss = 2.45988635, grad/param norm = 2.7739e-01, time/batch = 0.6583s	
795/26050 (epoch 1.526), train_loss = 2.23810227, grad/param norm = 3.2567e-01, time/batch = 0.6568s	
796/26050 (epoch 1.528), train_loss = 2.22578359, grad/param norm = 3.5748e-01, time/batch = 0.6500s	
797/26050 (epoch 1.530), train_loss = 2.20533093, grad/param norm = 3.0443e-01, time/batch = 0.6512s	
798/26050 (epoch 1.532), train_loss = 2.20431754, grad/param norm = 2.9982e-01, time/batch = 0.6530s	
799/26050 (epoch 1.534), train_loss = 2.21604881, grad/param norm = 3.0324e-01, time/batch = 0.6703s	
800/26050 (epoch 1.536), train_loss = 2.10533678, grad/param norm = 3.1228e-01, time/batch = 0.6800s	
801/26050 (epoch 1.537), train_loss = 2.20309339, grad/param norm = 2.6385e-01, time/batch = 0.6591s	
802/26050 (epoch 1.539), train_loss = 2.06863114, grad/param norm = 2.4601e-01, time/batch = 0.6599s	
803/26050 (epoch 1.541), train_loss = 2.21599737, grad/param norm = 2.5574e-01, time/batch = 0.6521s	
804/26050 (epoch 1.543), train_loss = 2.01844024, grad/param norm = 2.9160e-01, time/batch = 0.6507s	
805/26050 (epoch 1.545), train_loss = 2.17540182, grad/param norm = 3.6146e-01, time/batch = 0.6511s	
806/26050 (epoch 1.547), train_loss = 2.32201449, grad/param norm = 3.8186e-01, time/batch = 0.6525s	
807/26050 (epoch 1.549), train_loss = 2.09358156, grad/param norm = 3.0345e-01, time/batch = 0.6554s	
808/26050 (epoch 1.551), train_loss = 2.18977884, grad/param norm = 3.0365e-01, time/batch = 0.6491s	
809/26050 (epoch 1.553), train_loss = 2.12482251, grad/param norm = 3.4610e-01, time/batch = 0.6438s	
810/26050 (epoch 1.555), train_loss = 2.09582986, grad/param norm = 3.1053e-01, time/batch = 0.6548s	
811/26050 (epoch 1.557), train_loss = 2.20127436, grad/param norm = 2.9332e-01, time/batch = 0.6446s	
812/26050 (epoch 1.559), train_loss = 2.16433396, grad/param norm = 2.7572e-01, time/batch = 0.6404s	
813/26050 (epoch 1.560), train_loss = 2.12456856, grad/param norm = 2.9065e-01, time/batch = 0.6408s	
814/26050 (epoch 1.562), train_loss = 2.18298625, grad/param norm = 3.0767e-01, time/batch = 0.6418s	
815/26050 (epoch 1.564), train_loss = 2.32374990, grad/param norm = 2.7717e-01, time/batch = 0.6473s	
816/26050 (epoch 1.566), train_loss = 2.12592359, grad/param norm = 2.7968e-01, time/batch = 0.6431s	
817/26050 (epoch 1.568), train_loss = 2.16818561, grad/param norm = 2.9259e-01, time/batch = 0.6450s	
818/26050 (epoch 1.570), train_loss = 2.24819052, grad/param norm = 3.3611e-01, time/batch = 0.6604s	
819/26050 (epoch 1.572), train_loss = 2.28188526, grad/param norm = 2.7035e-01, time/batch = 0.6423s	
820/26050 (epoch 1.574), train_loss = 2.27068501, grad/param norm = 3.5006e-01, time/batch = 0.6532s	
821/26050 (epoch 1.576), train_loss = 2.14064849, grad/param norm = 2.9202e-01, time/batch = 0.6490s	
822/26050 (epoch 1.578), train_loss = 2.23414328, grad/param norm = 2.5736e-01, time/batch = 0.6486s	
823/26050 (epoch 1.580), train_loss = 2.04949991, grad/param norm = 2.3797e-01, time/batch = 0.6411s	
824/26050 (epoch 1.582), train_loss = 2.24461625, grad/param norm = 3.0829e-01, time/batch = 0.6398s	
825/26050 (epoch 1.583), train_loss = 2.21961668, grad/param norm = 3.0872e-01, time/batch = 0.6465s	
826/26050 (epoch 1.585), train_loss = 2.13720797, grad/param norm = 3.5323e-01, time/batch = 0.6415s	
827/26050 (epoch 1.587), train_loss = 2.21178233, grad/param norm = 3.5074e-01, time/batch = 0.6406s	
828/26050 (epoch 1.589), train_loss = 2.13440095, grad/param norm = 3.6600e-01, time/batch = 0.6422s	
829/26050 (epoch 1.591), train_loss = 2.20848369, grad/param norm = 3.3126e-01, time/batch = 0.6438s	
830/26050 (epoch 1.593), train_loss = 2.09439641, grad/param norm = 3.0907e-01, time/batch = 0.6421s	
831/26050 (epoch 1.595), train_loss = 2.24140184, grad/param norm = 3.1357e-01, time/batch = 0.6407s	
832/26050 (epoch 1.597), train_loss = 2.08264514, grad/param norm = 2.3755e-01, time/batch = 0.6410s	
833/26050 (epoch 1.599), train_loss = 1.97161870, grad/param norm = 2.3884e-01, time/batch = 0.6415s	
834/26050 (epoch 1.601), train_loss = 2.37603152, grad/param norm = 3.1579e-01, time/batch = 0.6466s	
835/26050 (epoch 1.603), train_loss = 2.24303199, grad/param norm = 4.0651e-01, time/batch = 0.6422s	
836/26050 (epoch 1.605), train_loss = 2.11155802, grad/param norm = 3.3918e-01, time/batch = 0.6418s	
837/26050 (epoch 1.607), train_loss = 2.18803674, grad/param norm = 2.8127e-01, time/batch = 0.6397s	
838/26050 (epoch 1.608), train_loss = 2.18797521, grad/param norm = 2.6739e-01, time/batch = 0.6383s	
839/26050 (epoch 1.610), train_loss = 2.10116197, grad/param norm = 2.9385e-01, time/batch = 0.6407s	
840/26050 (epoch 1.612), train_loss = 2.17710343, grad/param norm = 3.1255e-01, time/batch = 0.6406s	
841/26050 (epoch 1.614), train_loss = 2.14459120, grad/param norm = 3.3603e-01, time/batch = 0.6429s	
842/26050 (epoch 1.616), train_loss = 2.47191936, grad/param norm = 3.4808e-01, time/batch = 0.6440s	
843/26050 (epoch 1.618), train_loss = 2.02841450, grad/param norm = 3.0662e-01, time/batch = 0.6545s	
844/26050 (epoch 1.620), train_loss = 2.28417529, grad/param norm = 3.0458e-01, time/batch = 0.6516s	
845/26050 (epoch 1.622), train_loss = 1.86924974, grad/param norm = 2.6090e-01, time/batch = 0.6484s	
846/26050 (epoch 1.624), train_loss = 2.04628651, grad/param norm = 2.8609e-01, time/batch = 0.6407s	
847/26050 (epoch 1.626), train_loss = 2.15805809, grad/param norm = 3.9116e-01, time/batch = 0.6513s	
848/26050 (epoch 1.628), train_loss = 2.20175358, grad/param norm = 3.9370e-01, time/batch = 0.6589s	
849/26050 (epoch 1.630), train_loss = 2.24397348, grad/param norm = 3.3450e-01, time/batch = 0.6606s	
850/26050 (epoch 1.631), train_loss = 2.22853755, grad/param norm = 2.9915e-01, time/batch = 0.6608s	
851/26050 (epoch 1.633), train_loss = 1.98657121, grad/param norm = 2.9466e-01, time/batch = 0.6568s	
852/26050 (epoch 1.635), train_loss = 2.04035820, grad/param norm = 2.5344e-01, time/batch = 0.6581s	
853/26050 (epoch 1.637), train_loss = 2.04011580, grad/param norm = 2.9073e-01, time/batch = 0.6514s	
854/26050 (epoch 1.639), train_loss = 2.18363664, grad/param norm = 2.6885e-01, time/batch = 0.6447s	
855/26050 (epoch 1.641), train_loss = 2.02733931, grad/param norm = 2.5803e-01, time/batch = 0.6635s	
856/26050 (epoch 1.643), train_loss = 2.07754585, grad/param norm = 2.4735e-01, time/batch = 0.6613s	
857/26050 (epoch 1.645), train_loss = 2.28615849, grad/param norm = 2.8442e-01, time/batch = 0.6549s	
858/26050 (epoch 1.647), train_loss = 2.02074758, grad/param norm = 3.0626e-01, time/batch = 0.6551s	
859/26050 (epoch 1.649), train_loss = 2.22050457, grad/param norm = 3.4350e-01, time/batch = 0.6721s	
860/26050 (epoch 1.651), train_loss = 2.18694110, grad/param norm = 3.4894e-01, time/batch = 0.6577s	
861/26050 (epoch 1.653), train_loss = 2.07702829, grad/param norm = 3.5356e-01, time/batch = 0.6536s	
862/26050 (epoch 1.655), train_loss = 2.10384501, grad/param norm = 2.9082e-01, time/batch = 0.6399s	
863/26050 (epoch 1.656), train_loss = 2.11475386, grad/param norm = 2.9384e-01, time/batch = 0.6390s	
864/26050 (epoch 1.658), train_loss = 2.21664815, grad/param norm = 2.8517e-01, time/batch = 0.6432s	
865/26050 (epoch 1.660), train_loss = 2.00948011, grad/param norm = 2.7121e-01, time/batch = 0.6436s	
866/26050 (epoch 1.662), train_loss = 1.98326029, grad/param norm = 2.8024e-01, time/batch = 0.6419s	
867/26050 (epoch 1.664), train_loss = 1.93046641, grad/param norm = 3.0694e-01, time/batch = 0.6450s	
868/26050 (epoch 1.666), train_loss = 2.14062021, grad/param norm = 2.7515e-01, time/batch = 0.6427s	
869/26050 (epoch 1.668), train_loss = 1.82654992, grad/param norm = 2.7757e-01, time/batch = 0.6377s	
870/26050 (epoch 1.670), train_loss = 2.25998175, grad/param norm = 3.1735e-01, time/batch = 0.6381s	
871/26050 (epoch 1.672), train_loss = 2.07436554, grad/param norm = 2.7371e-01, time/batch = 0.6404s	
872/26050 (epoch 1.674), train_loss = 1.96924749, grad/param norm = 2.8931e-01, time/batch = 0.6400s	
873/26050 (epoch 1.676), train_loss = 2.01172000, grad/param norm = 2.7347e-01, time/batch = 0.6465s	
874/26050 (epoch 1.678), train_loss = 2.21684711, grad/param norm = 2.9871e-01, time/batch = 0.6389s	
875/26050 (epoch 1.679), train_loss = 2.14578569, grad/param norm = 3.7184e-01, time/batch = 0.6367s	
876/26050 (epoch 1.681), train_loss = 2.18654549, grad/param norm = 3.4284e-01, time/batch = 0.6694s	
877/26050 (epoch 1.683), train_loss = 1.99571553, grad/param norm = 3.4950e-01, time/batch = 0.6654s	
878/26050 (epoch 1.685), train_loss = 2.04653656, grad/param norm = 3.7057e-01, time/batch = 0.6367s	
879/26050 (epoch 1.687), train_loss = 1.91360591, grad/param norm = 3.5725e-01, time/batch = 0.6373s	
880/26050 (epoch 1.689), train_loss = 2.04137659, grad/param norm = 3.1320e-01, time/batch = 0.6433s	
881/26050 (epoch 1.691), train_loss = 1.91853581, grad/param norm = 2.6160e-01, time/batch = 0.6385s	
882/26050 (epoch 1.693), train_loss = 2.06301263, grad/param norm = 2.7857e-01, time/batch = 0.6377s	
883/26050 (epoch 1.695), train_loss = 2.10751421, grad/param norm = 2.7638e-01, time/batch = 0.6370s	
884/26050 (epoch 1.697), train_loss = 1.97013050, grad/param norm = 3.1538e-01, time/batch = 0.6386s	
885/26050 (epoch 1.699), train_loss = 2.09761650, grad/param norm = 2.7527e-01, time/batch = 0.6373s	
886/26050 (epoch 1.701), train_loss = 1.93480091, grad/param norm = 2.7303e-01, time/batch = 0.6377s	
887/26050 (epoch 1.702), train_loss = 2.29409094, grad/param norm = 3.1920e-01, time/batch = 0.6394s	
888/26050 (epoch 1.704), train_loss = 2.10616415, grad/param norm = 2.6770e-01, time/batch = 0.6383s	
889/26050 (epoch 1.706), train_loss = 2.14053959, grad/param norm = 2.6064e-01, time/batch = 0.6390s	
890/26050 (epoch 1.708), train_loss = 2.05831945, grad/param norm = 2.1358e-01, time/batch = 0.6380s	
891/26050 (epoch 1.710), train_loss = 2.25063355, grad/param norm = 2.6804e-01, time/batch = 0.6507s	
892/26050 (epoch 1.712), train_loss = 2.26959817, grad/param norm = 2.4444e-01, time/batch = 0.6781s	
893/26050 (epoch 1.714), train_loss = 2.01314770, grad/param norm = 2.8988e-01, time/batch = 0.6446s	
894/26050 (epoch 1.716), train_loss = 2.33618205, grad/param norm = 3.3205e-01, time/batch = 0.6386s	
895/26050 (epoch 1.718), train_loss = 2.11578701, grad/param norm = 3.2880e-01, time/batch = 0.6470s	
896/26050 (epoch 1.720), train_loss = 1.89699377, grad/param norm = 2.6542e-01, time/batch = 0.6394s	
897/26050 (epoch 1.722), train_loss = 2.07508566, grad/param norm = 2.9298e-01, time/batch = 0.6386s	
898/26050 (epoch 1.724), train_loss = 1.95849693, grad/param norm = 3.3460e-01, time/batch = 0.6386s	
899/26050 (epoch 1.726), train_loss = 2.18416409, grad/param norm = 3.2226e-01, time/batch = 0.6374s	
900/26050 (epoch 1.727), train_loss = 2.15567917, grad/param norm = 2.9129e-01, time/batch = 0.6382s	
901/26050 (epoch 1.729), train_loss = 2.16824104, grad/param norm = 2.5986e-01, time/batch = 0.6403s	
902/26050 (epoch 1.731), train_loss = 2.01587435, grad/param norm = 2.5495e-01, time/batch = 0.6401s	
903/26050 (epoch 1.733), train_loss = 2.08205257, grad/param norm = 2.7974e-01, time/batch = 0.6389s	
904/26050 (epoch 1.735), train_loss = 2.26354599, grad/param norm = 2.7111e-01, time/batch = 0.6386s	
905/26050 (epoch 1.737), train_loss = 2.16852070, grad/param norm = 2.4148e-01, time/batch = 0.6378s	
906/26050 (epoch 1.739), train_loss = 2.12763029, grad/param norm = 2.5261e-01, time/batch = 0.6380s	
907/26050 (epoch 1.741), train_loss = 1.94305938, grad/param norm = 2.5461e-01, time/batch = 0.6741s	
908/26050 (epoch 1.743), train_loss = 2.26952361, grad/param norm = 3.3760e-01, time/batch = 0.6612s	
909/26050 (epoch 1.745), train_loss = 1.95560272, grad/param norm = 2.8396e-01, time/batch = 0.6454s	
910/26050 (epoch 1.747), train_loss = 2.02860549, grad/param norm = 3.2095e-01, time/batch = 0.6592s	
911/26050 (epoch 1.749), train_loss = 2.12758275, grad/param norm = 4.2131e-01, time/batch = 0.6535s	
912/26050 (epoch 1.750), train_loss = 1.99508024, grad/param norm = 2.9522e-01, time/batch = 0.6717s	
913/26050 (epoch 1.752), train_loss = 2.15160097, grad/param norm = 2.5005e-01, time/batch = 0.6802s	
914/26050 (epoch 1.754), train_loss = 1.89507628, grad/param norm = 2.5065e-01, time/batch = 0.6757s	
915/26050 (epoch 1.756), train_loss = 2.20260417, grad/param norm = 2.3766e-01, time/batch = 0.6461s	
916/26050 (epoch 1.758), train_loss = 2.16030799, grad/param norm = 3.4877e-01, time/batch = 0.6405s	
917/26050 (epoch 1.760), train_loss = 2.01912961, grad/param norm = 3.1093e-01, time/batch = 0.6406s	
918/26050 (epoch 1.762), train_loss = 2.11115939, grad/param norm = 2.8093e-01, time/batch = 0.6428s	
919/26050 (epoch 1.764), train_loss = 2.16652307, grad/param norm = 2.6607e-01, time/batch = 0.6409s	
920/26050 (epoch 1.766), train_loss = 2.08886877, grad/param norm = 2.6036e-01, time/batch = 0.6470s	
921/26050 (epoch 1.768), train_loss = 2.01691718, grad/param norm = 2.5969e-01, time/batch = 0.6404s	
922/26050 (epoch 1.770), train_loss = 2.07476091, grad/param norm = 2.8921e-01, time/batch = 0.6416s	
923/26050 (epoch 1.772), train_loss = 2.08968238, grad/param norm = 2.5344e-01, time/batch = 0.6415s	
924/26050 (epoch 1.774), train_loss = 2.01011361, grad/param norm = 2.7335e-01, time/batch = 0.6408s	
925/26050 (epoch 1.775), train_loss = 1.90322923, grad/param norm = 2.6654e-01, time/batch = 0.6418s	
926/26050 (epoch 1.777), train_loss = 1.95739232, grad/param norm = 3.1260e-01, time/batch = 0.6555s	
927/26050 (epoch 1.779), train_loss = 2.14394639, grad/param norm = 3.1965e-01, time/batch = 0.6610s	
928/26050 (epoch 1.781), train_loss = 2.03408069, grad/param norm = 3.3075e-01, time/batch = 0.6589s	
929/26050 (epoch 1.783), train_loss = 2.00255463, grad/param norm = 2.7768e-01, time/batch = 0.6642s	
930/26050 (epoch 1.785), train_loss = 2.01973482, grad/param norm = 3.0602e-01, time/batch = 0.6682s	
931/26050 (epoch 1.787), train_loss = 2.02806862, grad/param norm = 3.3855e-01, time/batch = 0.6564s	
932/26050 (epoch 1.789), train_loss = 2.16631173, grad/param norm = 3.5646e-01, time/batch = 0.6529s	
933/26050 (epoch 1.791), train_loss = 2.10148869, grad/param norm = 2.8392e-01, time/batch = 0.6824s	
934/26050 (epoch 1.793), train_loss = 1.99397580, grad/param norm = 2.6645e-01, time/batch = 0.6704s	
935/26050 (epoch 1.795), train_loss = 2.00639828, grad/param norm = 3.2098e-01, time/batch = 0.6567s	
936/26050 (epoch 1.797), train_loss = 1.90199634, grad/param norm = 2.8410e-01, time/batch = 0.6547s	
937/26050 (epoch 1.798), train_loss = 1.88506205, grad/param norm = 2.3178e-01, time/batch = 0.6555s	
938/26050 (epoch 1.800), train_loss = 1.93432069, grad/param norm = 2.5186e-01, time/batch = 0.6571s	
939/26050 (epoch 1.802), train_loss = 2.09127492, grad/param norm = 2.6879e-01, time/batch = 0.6488s	
940/26050 (epoch 1.804), train_loss = 2.13530170, grad/param norm = 2.7523e-01, time/batch = 0.6408s	
941/26050 (epoch 1.806), train_loss = 2.17518973, grad/param norm = 3.0338e-01, time/batch = 0.6482s	
942/26050 (epoch 1.808), train_loss = 1.92720856, grad/param norm = 2.9696e-01, time/batch = 0.6414s	
943/26050 (epoch 1.810), train_loss = 2.02799609, grad/param norm = 3.4249e-01, time/batch = 0.6417s	
944/26050 (epoch 1.812), train_loss = 1.90404010, grad/param norm = 3.0707e-01, time/batch = 0.6397s	
945/26050 (epoch 1.814), train_loss = 1.98374747, grad/param norm = 2.9705e-01, time/batch = 0.6392s	
946/26050 (epoch 1.816), train_loss = 2.07524216, grad/param norm = 2.6162e-01, time/batch = 0.6401s	
947/26050 (epoch 1.818), train_loss = 2.15134384, grad/param norm = 3.0909e-01, time/batch = 0.6418s	
948/26050 (epoch 1.820), train_loss = 2.07670946, grad/param norm = 2.6210e-01, time/batch = 0.6670s	
949/26050 (epoch 1.821), train_loss = 2.17262606, grad/param norm = 2.8526e-01, time/batch = 0.6753s	
950/26050 (epoch 1.823), train_loss = 2.22853642, grad/param norm = 3.2529e-01, time/batch = 0.6411s	
951/26050 (epoch 1.825), train_loss = 2.05747269, grad/param norm = 2.8458e-01, time/batch = 0.6403s	
952/26050 (epoch 1.827), train_loss = 2.14565993, grad/param norm = 3.2197e-01, time/batch = 0.6412s	
953/26050 (epoch 1.829), train_loss = 2.09580532, grad/param norm = 2.6858e-01, time/batch = 0.6407s	
954/26050 (epoch 1.831), train_loss = 2.17159001, grad/param norm = 2.5736e-01, time/batch = 0.6410s	
955/26050 (epoch 1.833), train_loss = 2.20356474, grad/param norm = 2.8251e-01, time/batch = 0.6395s	
956/26050 (epoch 1.835), train_loss = 2.29094386, grad/param norm = 2.5776e-01, time/batch = 0.6411s	
957/26050 (epoch 1.837), train_loss = 1.96900184, grad/param norm = 2.9834e-01, time/batch = 0.6452s	
958/26050 (epoch 1.839), train_loss = 2.25520213, grad/param norm = 3.3050e-01, time/batch = 0.6384s	
959/26050 (epoch 1.841), train_loss = 2.17911708, grad/param norm = 3.2967e-01, time/batch = 0.6388s	
960/26050 (epoch 1.843), train_loss = 2.12049620, grad/param norm = 2.8325e-01, time/batch = 0.6406s	
961/26050 (epoch 1.845), train_loss = 1.98356162, grad/param norm = 2.8085e-01, time/batch = 0.6409s	
962/26050 (epoch 1.846), train_loss = 2.14028311, grad/param norm = 2.9994e-01, time/batch = 0.6409s	
963/26050 (epoch 1.848), train_loss = 1.99587272, grad/param norm = 2.6331e-01, time/batch = 0.6499s	
964/26050 (epoch 1.850), train_loss = 1.98048979, grad/param norm = 2.5781e-01, time/batch = 0.6838s	
965/26050 (epoch 1.852), train_loss = 2.06091968, grad/param norm = 3.0678e-01, time/batch = 0.6507s	
966/26050 (epoch 1.854), train_loss = 2.06226978, grad/param norm = 2.8008e-01, time/batch = 0.6387s	
967/26050 (epoch 1.856), train_loss = 2.05538672, grad/param norm = 2.6537e-01, time/batch = 0.6383s	
968/26050 (epoch 1.858), train_loss = 1.84984200, grad/param norm = 2.7167e-01, time/batch = 0.6389s	
969/26050 (epoch 1.860), train_loss = 2.09382186, grad/param norm = 2.8021e-01, time/batch = 0.6394s	
970/26050 (epoch 1.862), train_loss = 2.10348948, grad/param norm = 2.9895e-01, time/batch = 0.6386s	
971/26050 (epoch 1.864), train_loss = 1.96075220, grad/param norm = 2.8590e-01, time/batch = 0.6434s	
972/26050 (epoch 1.866), train_loss = 1.94981597, grad/param norm = 2.9426e-01, time/batch = 0.6428s	
973/26050 (epoch 1.868), train_loss = 2.22564943, grad/param norm = 3.3131e-01, time/batch = 0.6389s	
974/26050 (epoch 1.869), train_loss = 1.89590956, grad/param norm = 3.0562e-01, time/batch = 0.6387s	
975/26050 (epoch 1.871), train_loss = 1.81113240, grad/param norm = 3.1669e-01, time/batch = 0.6388s	
976/26050 (epoch 1.873), train_loss = 1.92097090, grad/param norm = 3.1767e-01, time/batch = 0.6394s	
977/26050 (epoch 1.875), train_loss = 2.01817119, grad/param norm = 3.4599e-01, time/batch = 0.6407s	
978/26050 (epoch 1.877), train_loss = 1.86094828, grad/param norm = 3.3194e-01, time/batch = 0.6402s	
979/26050 (epoch 1.879), train_loss = 2.01308444, grad/param norm = 2.9228e-01, time/batch = 0.6718s	
980/26050 (epoch 1.881), train_loss = 2.18470841, grad/param norm = 2.8316e-01, time/batch = 0.6716s	
981/26050 (epoch 1.883), train_loss = 2.06261188, grad/param norm = 2.7577e-01, time/batch = 0.6398s	
982/26050 (epoch 1.885), train_loss = 1.85909150, grad/param norm = 2.8929e-01, time/batch = 0.6404s	
983/26050 (epoch 1.887), train_loss = 2.02625563, grad/param norm = 2.4670e-01, time/batch = 0.6398s	
984/26050 (epoch 1.889), train_loss = 1.89067690, grad/param norm = 2.4916e-01, time/batch = 0.6399s	
985/26050 (epoch 1.891), train_loss = 1.79884097, grad/param norm = 2.7853e-01, time/batch = 0.6413s	
986/26050 (epoch 1.893), train_loss = 1.80557887, grad/param norm = 2.2570e-01, time/batch = 0.6492s	
987/26050 (epoch 1.894), train_loss = 1.87390360, grad/param norm = 2.5170e-01, time/batch = 0.6431s	
988/26050 (epoch 1.896), train_loss = 2.06317367, grad/param norm = 2.8452e-01, time/batch = 0.6418s	
989/26050 (epoch 1.898), train_loss = 1.98180410, grad/param norm = 3.0015e-01, time/batch = 0.6397s	
990/26050 (epoch 1.900), train_loss = 2.31955268, grad/param norm = 3.0100e-01, time/batch = 0.6406s	
991/26050 (epoch 1.902), train_loss = 2.10609692, grad/param norm = 2.5110e-01, time/batch = 0.6412s	
992/26050 (epoch 1.904), train_loss = 2.07583652, grad/param norm = 2.6438e-01, time/batch = 0.6397s	
993/26050 (epoch 1.906), train_loss = 2.04442058, grad/param norm = 2.6588e-01, time/batch = 0.6404s	
994/26050 (epoch 1.908), train_loss = 2.00115874, grad/param norm = 2.8665e-01, time/batch = 0.6426s	
995/26050 (epoch 1.910), train_loss = 1.98117342, grad/param norm = 2.5116e-01, time/batch = 0.6424s	
996/26050 (epoch 1.912), train_loss = 2.33909460, grad/param norm = 2.9603e-01, time/batch = 0.6410s	
997/26050 (epoch 1.914), train_loss = 2.28728132, grad/param norm = 2.4879e-01, time/batch = 0.6392s	
998/26050 (epoch 1.916), train_loss = 2.06481126, grad/param norm = 2.3045e-01, time/batch = 0.6389s	
999/26050 (epoch 1.917), train_loss = 1.95064536, grad/param norm = 2.4634e-01, time/batch = 0.6395s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch1.92_2.0736.t7	
1000/26050 (epoch 1.919), train_loss = 2.06385295, grad/param norm = 2.6302e-01, time/batch = 0.6432s	
1001/26050 (epoch 1.921), train_loss = 1.90019157, grad/param norm = 2.6848e-01, time/batch = 0.6487s	
1002/26050 (epoch 1.923), train_loss = 1.94138740, grad/param norm = 2.9850e-01, time/batch = 0.6446s	
1003/26050 (epoch 1.925), train_loss = 1.86903585, grad/param norm = 2.9899e-01, time/batch = 0.6430s	
1004/26050 (epoch 1.927), train_loss = 1.92331892, grad/param norm = 2.6684e-01, time/batch = 0.6420s	
1005/26050 (epoch 1.929), train_loss = 1.95146777, grad/param norm = 2.5754e-01, time/batch = 0.6493s	
1006/26050 (epoch 1.931), train_loss = 2.27888274, grad/param norm = 2.8986e-01, time/batch = 0.6500s	
1007/26050 (epoch 1.933), train_loss = 2.01990177, grad/param norm = 2.9838e-01, time/batch = 0.6491s	
1008/26050 (epoch 1.935), train_loss = 1.81264368, grad/param norm = 2.8615e-01, time/batch = 0.6515s	
1009/26050 (epoch 1.937), train_loss = 1.94343475, grad/param norm = 2.7150e-01, time/batch = 0.6459s	
1010/26050 (epoch 1.939), train_loss = 1.88525382, grad/param norm = 2.7564e-01, time/batch = 0.6509s	
1011/26050 (epoch 1.940), train_loss = 2.07585518, grad/param norm = 2.8079e-01, time/batch = 0.6436s	
1012/26050 (epoch 1.942), train_loss = 2.05272457, grad/param norm = 2.6779e-01, time/batch = 0.6417s	
1013/26050 (epoch 1.944), train_loss = 1.95598182, grad/param norm = 3.0365e-01, time/batch = 0.6440s	
1014/26050 (epoch 1.946), train_loss = 2.11346670, grad/param norm = 2.9459e-01, time/batch = 0.6424s	
1015/26050 (epoch 1.948), train_loss = 1.76610882, grad/param norm = 3.2253e-01, time/batch = 0.6411s	
1016/26050 (epoch 1.950), train_loss = 1.96680731, grad/param norm = 3.4827e-01, time/batch = 0.6416s	
1017/26050 (epoch 1.952), train_loss = 2.16661191, grad/param norm = 3.1260e-01, time/batch = 0.6481s	
1018/26050 (epoch 1.954), train_loss = 2.17331350, grad/param norm = 2.5520e-01, time/batch = 0.6823s	
1019/26050 (epoch 1.956), train_loss = 2.13477751, grad/param norm = 2.3335e-01, time/batch = 0.6555s	
1020/26050 (epoch 1.958), train_loss = 2.08777987, grad/param norm = 2.8127e-01, time/batch = 0.6402s	
1021/26050 (epoch 1.960), train_loss = 2.00161774, grad/param norm = 3.0942e-01, time/batch = 0.6415s	
1022/26050 (epoch 1.962), train_loss = 1.98679798, grad/param norm = 2.8179e-01, time/batch = 0.6407s	
1023/26050 (epoch 1.964), train_loss = 2.13806527, grad/param norm = 3.4880e-01, time/batch = 0.6409s	
1024/26050 (epoch 1.965), train_loss = 1.88270577, grad/param norm = 2.7878e-01, time/batch = 0.6465s	
1025/26050 (epoch 1.967), train_loss = 2.36833072, grad/param norm = 2.8678e-01, time/batch = 0.6491s	
1026/26050 (epoch 1.969), train_loss = 1.96919282, grad/param norm = 2.7864e-01, time/batch = 0.6519s	
1027/26050 (epoch 1.971), train_loss = 1.83360504, grad/param norm = 2.7422e-01, time/batch = 0.6415s	
1028/26050 (epoch 1.973), train_loss = 1.92259859, grad/param norm = 2.4201e-01, time/batch = 0.6556s	
1029/26050 (epoch 1.975), train_loss = 2.09163103, grad/param norm = 2.6182e-01, time/batch = 0.6824s	
1030/26050 (epoch 1.977), train_loss = 2.04967815, grad/param norm = 2.2420e-01, time/batch = 0.6444s	
1031/26050 (epoch 1.979), train_loss = 1.79720210, grad/param norm = 2.4434e-01, time/batch = 0.6403s	
1032/26050 (epoch 1.981), train_loss = 2.06438817, grad/param norm = 2.6207e-01, time/batch = 0.6422s	
1033/26050 (epoch 1.983), train_loss = 2.06354557, grad/param norm = 3.3542e-01, time/batch = 0.6416s	
1034/26050 (epoch 1.985), train_loss = 2.04710455, grad/param norm = 3.0819e-01, time/batch = 0.6407s	
1035/26050 (epoch 1.987), train_loss = 2.16502001, grad/param norm = 3.0876e-01, time/batch = 0.6394s	
1036/26050 (epoch 1.988), train_loss = 2.21007527, grad/param norm = 3.3973e-01, time/batch = 0.6401s	
1037/26050 (epoch 1.990), train_loss = 2.03162313, grad/param norm = 3.3952e-01, time/batch = 0.6423s	
1038/26050 (epoch 1.992), train_loss = 2.25539326, grad/param norm = 2.9119e-01, time/batch = 0.6406s	
1039/26050 (epoch 1.994), train_loss = 2.02646734, grad/param norm = 2.8628e-01, time/batch = 0.6411s	
1040/26050 (epoch 1.996), train_loss = 2.17330033, grad/param norm = 3.0628e-01, time/batch = 0.6389s	
1041/26050 (epoch 1.998), train_loss = 2.07188357, grad/param norm = 2.6972e-01, time/batch = 0.6450s	
1042/26050 (epoch 2.000), train_loss = 1.94571338, grad/param norm = 2.4139e-01, time/batch = 0.6470s	
1043/26050 (epoch 2.002), train_loss = 1.90822396, grad/param norm = 2.1756e-01, time/batch = 0.6416s	
1044/26050 (epoch 2.004), train_loss = 1.94086211, grad/param norm = 2.4659e-01, time/batch = 0.6814s	
1045/26050 (epoch 2.006), train_loss = 1.82863620, grad/param norm = 2.2794e-01, time/batch = 0.6619s	
1046/26050 (epoch 2.008), train_loss = 1.88340693, grad/param norm = 2.4654e-01, time/batch = 0.6410s	
1047/26050 (epoch 2.010), train_loss = 1.97896139, grad/param norm = 2.2858e-01, time/batch = 0.6411s	
1048/26050 (epoch 2.012), train_loss = 2.08801525, grad/param norm = 2.8948e-01, time/batch = 0.6423s	
1049/26050 (epoch 2.013), train_loss = 2.48977647, grad/param norm = 2.8737e-01, time/batch = 0.6424s	
1050/26050 (epoch 2.015), train_loss = 1.93071955, grad/param norm = 2.6337e-01, time/batch = 0.6415s	
1051/26050 (epoch 2.017), train_loss = 1.93974190, grad/param norm = 2.5039e-01, time/batch = 0.6423s	
1052/26050 (epoch 2.019), train_loss = 1.95170660, grad/param norm = 2.3640e-01, time/batch = 0.6397s	
1053/26050 (epoch 2.021), train_loss = 2.09705461, grad/param norm = 2.9721e-01, time/batch = 0.6401s	
1054/26050 (epoch 2.023), train_loss = 1.90682080, grad/param norm = 2.6522e-01, time/batch = 0.6450s	
1055/26050 (epoch 2.025), train_loss = 1.97288183, grad/param norm = 2.9411e-01, time/batch = 0.6394s	
1056/26050 (epoch 2.027), train_loss = 1.86659444, grad/param norm = 3.2417e-01, time/batch = 0.6525s	
1057/26050 (epoch 2.029), train_loss = 1.98299364, grad/param norm = 3.4879e-01, time/batch = 0.6443s	
1058/26050 (epoch 2.031), train_loss = 2.15001926, grad/param norm = 3.2719e-01, time/batch = 0.6421s	
1059/26050 (epoch 2.033), train_loss = 2.04595737, grad/param norm = 3.0478e-01, time/batch = 0.6620s	
1060/26050 (epoch 2.035), train_loss = 2.21061794, grad/param norm = 2.9419e-01, time/batch = 0.6790s	
1061/26050 (epoch 2.036), train_loss = 1.99071515, grad/param norm = 2.7204e-01, time/batch = 0.6421s	
1062/26050 (epoch 2.038), train_loss = 1.85187547, grad/param norm = 2.7781e-01, time/batch = 0.6415s	
1063/26050 (epoch 2.040), train_loss = 2.04431070, grad/param norm = 2.3821e-01, time/batch = 0.6406s	
1064/26050 (epoch 2.042), train_loss = 1.79878227, grad/param norm = 2.4841e-01, time/batch = 0.6408s	
1065/26050 (epoch 2.044), train_loss = 2.04796976, grad/param norm = 2.5282e-01, time/batch = 0.6405s	
1066/26050 (epoch 2.046), train_loss = 1.81052328, grad/param norm = 2.7369e-01, time/batch = 0.6495s	
1067/26050 (epoch 2.048), train_loss = 1.99449321, grad/param norm = 2.7898e-01, time/batch = 0.6515s	
1068/26050 (epoch 2.050), train_loss = 1.80701832, grad/param norm = 2.5693e-01, time/batch = 0.6402s	
1069/26050 (epoch 2.052), train_loss = 1.98593801, grad/param norm = 2.8975e-01, time/batch = 0.6395s	
1070/26050 (epoch 2.054), train_loss = 1.89619486, grad/param norm = 3.5689e-01, time/batch = 0.6419s	
1071/26050 (epoch 2.056), train_loss = 1.62631819, grad/param norm = 2.8386e-01, time/batch = 0.6413s	
1072/26050 (epoch 2.058), train_loss = 1.91701981, grad/param norm = 2.8970e-01, time/batch = 0.6466s	
1073/26050 (epoch 2.060), train_loss = 1.95595572, grad/param norm = 2.5040e-01, time/batch = 0.6414s	
1074/26050 (epoch 2.061), train_loss = 1.83112257, grad/param norm = 2.6129e-01, time/batch = 0.6407s	
1075/26050 (epoch 2.063), train_loss = 1.81546431, grad/param norm = 2.1132e-01, time/batch = 0.6394s	
1076/26050 (epoch 2.065), train_loss = 1.94520520, grad/param norm = 2.4915e-01, time/batch = 0.6395s	
1077/26050 (epoch 2.067), train_loss = 2.00191016, grad/param norm = 2.8189e-01, time/batch = 0.6408s	
1078/26050 (epoch 2.069), train_loss = 2.05518241, grad/param norm = 2.5583e-01, time/batch = 0.6393s	
1079/26050 (epoch 2.071), train_loss = 2.03848397, grad/param norm = 2.6836e-01, time/batch = 0.6422s	
1080/26050 (epoch 2.073), train_loss = 2.14860217, grad/param norm = 2.8866e-01, time/batch = 0.6399s	
1081/26050 (epoch 2.075), train_loss = 1.89974311, grad/param norm = 2.6195e-01, time/batch = 0.6444s	
1082/26050 (epoch 2.077), train_loss = 1.84068640, grad/param norm = 2.6110e-01, time/batch = 0.6494s	
1083/26050 (epoch 2.079), train_loss = 2.11017376, grad/param norm = 2.8943e-01, time/batch = 0.6444s	
1084/26050 (epoch 2.081), train_loss = 1.92090949, grad/param norm = 2.5186e-01, time/batch = 0.6407s	
1085/26050 (epoch 2.083), train_loss = 2.05353382, grad/param norm = 2.7164e-01, time/batch = 0.6554s	
1086/26050 (epoch 2.084), train_loss = 2.23519250, grad/param norm = 2.7995e-01, time/batch = 0.6828s	
1087/26050 (epoch 2.086), train_loss = 2.18689306, grad/param norm = 2.7269e-01, time/batch = 0.6635s	
1088/26050 (epoch 2.088), train_loss = 1.86140415, grad/param norm = 2.6396e-01, time/batch = 0.6487s	
1089/26050 (epoch 2.090), train_loss = 2.20136132, grad/param norm = 2.7953e-01, time/batch = 0.6517s	
1090/26050 (epoch 2.092), train_loss = 1.88345646, grad/param norm = 2.8110e-01, time/batch = 0.6500s	
1091/26050 (epoch 2.094), train_loss = 2.06170576, grad/param norm = 2.4936e-01, time/batch = 0.6521s	
1092/26050 (epoch 2.096), train_loss = 1.74670774, grad/param norm = 2.4489e-01, time/batch = 0.6417s	
1093/26050 (epoch 2.098), train_loss = 1.85175654, grad/param norm = 2.3471e-01, time/batch = 0.6567s	
1094/26050 (epoch 2.100), train_loss = 1.89055926, grad/param norm = 2.7665e-01, time/batch = 0.6480s	
1095/26050 (epoch 2.102), train_loss = 2.00707418, grad/param norm = 2.4830e-01, time/batch = 0.6432s	
1096/26050 (epoch 2.104), train_loss = 2.07585897, grad/param norm = 2.5209e-01, time/batch = 0.6412s	
1097/26050 (epoch 2.106), train_loss = 1.87469010, grad/param norm = 2.8745e-01, time/batch = 0.6397s	
1098/26050 (epoch 2.107), train_loss = 1.69351515, grad/param norm = 2.9660e-01, time/batch = 0.6387s	
1099/26050 (epoch 2.109), train_loss = 1.85491286, grad/param norm = 2.7303e-01, time/batch = 0.6436s	
1100/26050 (epoch 2.111), train_loss = 2.26799734, grad/param norm = 2.6082e-01, time/batch = 0.6422s	
1101/26050 (epoch 2.113), train_loss = 1.94268171, grad/param norm = 3.0412e-01, time/batch = 0.6450s	
1102/26050 (epoch 2.115), train_loss = 2.13336099, grad/param norm = 2.5829e-01, time/batch = 0.6448s	
1103/26050 (epoch 2.117), train_loss = 2.02507390, grad/param norm = 2.8689e-01, time/batch = 0.6485s	
1104/26050 (epoch 2.119), train_loss = 1.90490742, grad/param norm = 2.7397e-01, time/batch = 0.6446s	
1105/26050 (epoch 2.121), train_loss = 1.99190049, grad/param norm = 2.9301e-01, time/batch = 0.6403s	
1106/26050 (epoch 2.123), train_loss = 1.85533611, grad/param norm = 2.5744e-01, time/batch = 0.6490s	
1107/26050 (epoch 2.125), train_loss = 1.59932279, grad/param norm = 2.2326e-01, time/batch = 0.6450s	
1108/26050 (epoch 2.127), train_loss = 1.83146301, grad/param norm = 2.3120e-01, time/batch = 0.6434s	
1109/26050 (epoch 2.129), train_loss = 1.76386251, grad/param norm = 2.5112e-01, time/batch = 0.6464s	
1110/26050 (epoch 2.131), train_loss = 1.88603525, grad/param norm = 2.3760e-01, time/batch = 0.6453s	
1111/26050 (epoch 2.132), train_loss = 1.84287659, grad/param norm = 2.2860e-01, time/batch = 0.6458s	
1112/26050 (epoch 2.134), train_loss = 1.90974943, grad/param norm = 2.3996e-01, time/batch = 0.6420s	
1113/26050 (epoch 2.136), train_loss = 1.89671973, grad/param norm = 2.2872e-01, time/batch = 0.6413s	
1114/26050 (epoch 2.138), train_loss = 1.90473761, grad/param norm = 2.6136e-01, time/batch = 0.6415s	
1115/26050 (epoch 2.140), train_loss = 1.97052413, grad/param norm = 2.8790e-01, time/batch = 0.6442s	
1116/26050 (epoch 2.142), train_loss = 1.94347331, grad/param norm = 3.1248e-01, time/batch = 0.6412s	
1117/26050 (epoch 2.144), train_loss = 1.82689853, grad/param norm = 2.8492e-01, time/batch = 0.6406s	
1118/26050 (epoch 2.146), train_loss = 1.74043721, grad/param norm = 2.6456e-01, time/batch = 0.6419s	
1119/26050 (epoch 2.148), train_loss = 1.81521979, grad/param norm = 2.3291e-01, time/batch = 0.6473s	
1120/26050 (epoch 2.150), train_loss = 2.01007076, grad/param norm = 2.6367e-01, time/batch = 0.6412s	
1121/26050 (epoch 2.152), train_loss = 2.19464082, grad/param norm = 2.7539e-01, time/batch = 0.6451s	
1122/26050 (epoch 2.154), train_loss = 1.78792336, grad/param norm = 2.4170e-01, time/batch = 0.6433s	
1123/26050 (epoch 2.155), train_loss = 1.88839070, grad/param norm = 2.4871e-01, time/batch = 0.6414s	
1124/26050 (epoch 2.157), train_loss = 1.92632850, grad/param norm = 2.5174e-01, time/batch = 0.6679s	
1125/26050 (epoch 2.159), train_loss = 2.06247722, grad/param norm = 2.6941e-01, time/batch = 0.6636s	
1126/26050 (epoch 2.161), train_loss = 2.18503231, grad/param norm = 3.0765e-01, time/batch = 0.6705s	
1127/26050 (epoch 2.163), train_loss = 1.91762241, grad/param norm = 3.5882e-01, time/batch = 0.6714s	
1128/26050 (epoch 2.165), train_loss = 1.61211287, grad/param norm = 3.0754e-01, time/batch = 0.6765s	
1129/26050 (epoch 2.167), train_loss = 2.14681812, grad/param norm = 3.3585e-01, time/batch = 0.6767s	
1130/26050 (epoch 2.169), train_loss = 2.05276297, grad/param norm = 2.6061e-01, time/batch = 0.6749s	
1131/26050 (epoch 2.171), train_loss = 1.81958658, grad/param norm = 2.5989e-01, time/batch = 0.6692s	
1132/26050 (epoch 2.173), train_loss = 1.93774722, grad/param norm = 2.9992e-01, time/batch = 0.6536s	
1133/26050 (epoch 2.175), train_loss = 2.00235807, grad/param norm = 2.9699e-01, time/batch = 0.6430s	
1134/26050 (epoch 2.177), train_loss = 2.02530711, grad/param norm = 2.5863e-01, time/batch = 0.6513s	
1135/26050 (epoch 2.179), train_loss = 1.60678931, grad/param norm = 2.5504e-01, time/batch = 0.6460s	
1136/26050 (epoch 2.180), train_loss = 2.10650957, grad/param norm = 2.6279e-01, time/batch = 0.6378s	
1137/26050 (epoch 2.182), train_loss = 2.32156461, grad/param norm = 2.8773e-01, time/batch = 0.6406s	
1138/26050 (epoch 2.184), train_loss = 2.01331062, grad/param norm = 2.7127e-01, time/batch = 0.6372s	
1139/26050 (epoch 2.186), train_loss = 1.71672964, grad/param norm = 2.2905e-01, time/batch = 0.6373s	
1140/26050 (epoch 2.188), train_loss = 1.85502379, grad/param norm = 2.3182e-01, time/batch = 0.6394s	
1141/26050 (epoch 2.190), train_loss = 1.98339638, grad/param norm = 2.2728e-01, time/batch = 0.6428s	
1142/26050 (epoch 2.192), train_loss = 1.92516742, grad/param norm = 2.3728e-01, time/batch = 0.6393s	
1143/26050 (epoch 2.194), train_loss = 1.88148083, grad/param norm = 2.5351e-01, time/batch = 0.6397s	
1144/26050 (epoch 2.196), train_loss = 2.06592214, grad/param norm = 3.0891e-01, time/batch = 0.6408s	
1145/26050 (epoch 2.198), train_loss = 1.81384718, grad/param norm = 2.5610e-01, time/batch = 0.6395s	
1146/26050 (epoch 2.200), train_loss = 1.85382121, grad/param norm = 2.4258e-01, time/batch = 0.6388s	
1147/26050 (epoch 2.202), train_loss = 1.82358586, grad/param norm = 2.6772e-01, time/batch = 0.6400s	
1148/26050 (epoch 2.203), train_loss = 1.99337669, grad/param norm = 2.6288e-01, time/batch = 0.6400s	
1149/26050 (epoch 2.205), train_loss = 1.83437828, grad/param norm = 2.5728e-01, time/batch = 0.6437s	
1150/26050 (epoch 2.207), train_loss = 1.88572059, grad/param norm = 2.5636e-01, time/batch = 0.6422s	
1151/26050 (epoch 2.209), train_loss = 1.85016557, grad/param norm = 2.4625e-01, time/batch = 0.6562s	
1152/26050 (epoch 2.211), train_loss = 1.86194898, grad/param norm = 3.3458e-01, time/batch = 0.6854s	
1153/26050 (epoch 2.213), train_loss = 2.00780376, grad/param norm = 3.4764e-01, time/batch = 0.6524s	
1154/26050 (epoch 2.215), train_loss = 1.99016988, grad/param norm = 2.9728e-01, time/batch = 0.6598s	
1155/26050 (epoch 2.217), train_loss = 1.94042766, grad/param norm = 3.3693e-01, time/batch = 0.6613s	
1156/26050 (epoch 2.219), train_loss = 1.82504641, grad/param norm = 2.4732e-01, time/batch = 0.6604s	
1157/26050 (epoch 2.221), train_loss = 1.81070936, grad/param norm = 2.5300e-01, time/batch = 0.6506s	
1158/26050 (epoch 2.223), train_loss = 2.07102090, grad/param norm = 2.7417e-01, time/batch = 0.6509s	
1159/26050 (epoch 2.225), train_loss = 1.86253836, grad/param norm = 2.6675e-01, time/batch = 0.6485s	
1160/26050 (epoch 2.226), train_loss = 2.04569393, grad/param norm = 2.7899e-01, time/batch = 0.6504s	
1161/26050 (epoch 2.228), train_loss = 2.00039672, grad/param norm = 2.8495e-01, time/batch = 0.6513s	
1162/26050 (epoch 2.230), train_loss = 1.88122056, grad/param norm = 2.6482e-01, time/batch = 0.6544s	
1163/26050 (epoch 2.232), train_loss = 2.03671640, grad/param norm = 2.7096e-01, time/batch = 0.6697s	
1164/26050 (epoch 2.234), train_loss = 1.70743011, grad/param norm = 2.2175e-01, time/batch = 0.6594s	
1165/26050 (epoch 2.236), train_loss = 1.96011564, grad/param norm = 2.7084e-01, time/batch = 0.6579s	
1166/26050 (epoch 2.238), train_loss = 1.73914611, grad/param norm = 2.8472e-01, time/batch = 0.6567s	
1167/26050 (epoch 2.240), train_loss = 1.83792171, grad/param norm = 2.3419e-01, time/batch = 0.6838s	
1168/26050 (epoch 2.242), train_loss = 1.96921317, grad/param norm = 2.5548e-01, time/batch = 0.6682s	
1169/26050 (epoch 2.244), train_loss = 1.94253910, grad/param norm = 2.5536e-01, time/batch = 0.6478s	
1170/26050 (epoch 2.246), train_loss = 1.81065718, grad/param norm = 2.3493e-01, time/batch = 0.6459s	
1171/26050 (epoch 2.248), train_loss = 2.01121643, grad/param norm = 2.5767e-01, time/batch = 0.6433s	
1172/26050 (epoch 2.250), train_loss = 1.98554409, grad/param norm = 2.8582e-01, time/batch = 0.6408s	
1173/26050 (epoch 2.251), train_loss = 1.79658826, grad/param norm = 2.6148e-01, time/batch = 0.6384s	
1174/26050 (epoch 2.253), train_loss = 1.81097913, grad/param norm = 3.0233e-01, time/batch = 0.6379s	
1175/26050 (epoch 2.255), train_loss = 2.12292026, grad/param norm = 2.8448e-01, time/batch = 0.6369s	
1176/26050 (epoch 2.257), train_loss = 1.95258241, grad/param norm = 2.7872e-01, time/batch = 0.6382s	
1177/26050 (epoch 2.259), train_loss = 1.98393978, grad/param norm = 3.2861e-01, time/batch = 0.6401s	
1178/26050 (epoch 2.261), train_loss = 1.87614320, grad/param norm = 2.6612e-01, time/batch = 0.6367s	
1179/26050 (epoch 2.263), train_loss = 1.97098870, grad/param norm = 2.7467e-01, time/batch = 0.6515s	
1180/26050 (epoch 2.265), train_loss = 2.12239587, grad/param norm = 2.3905e-01, time/batch = 0.6573s	
1181/26050 (epoch 2.267), train_loss = 1.98299260, grad/param norm = 2.3105e-01, time/batch = 0.6550s	
1182/26050 (epoch 2.269), train_loss = 2.14710530, grad/param norm = 2.6302e-01, time/batch = 0.6752s	
1183/26050 (epoch 2.271), train_loss = 1.85898193, grad/param norm = 2.1688e-01, time/batch = 0.6687s	
1184/26050 (epoch 2.273), train_loss = 2.00192759, grad/param norm = 2.6865e-01, time/batch = 0.6414s	
1185/26050 (epoch 2.274), train_loss = 1.90593513, grad/param norm = 2.1770e-01, time/batch = 0.6428s	
1186/26050 (epoch 2.276), train_loss = 1.79588845, grad/param norm = 2.2603e-01, time/batch = 0.6406s	
1187/26050 (epoch 2.278), train_loss = 1.96891453, grad/param norm = 2.4465e-01, time/batch = 0.6452s	
1188/26050 (epoch 2.280), train_loss = 1.82585145, grad/param norm = 2.1831e-01, time/batch = 0.6398s	
1189/26050 (epoch 2.282), train_loss = 1.91678426, grad/param norm = 2.2892e-01, time/batch = 0.6395s	
1190/26050 (epoch 2.284), train_loss = 1.74854669, grad/param norm = 2.6096e-01, time/batch = 0.6389s	
1191/26050 (epoch 2.286), train_loss = 1.83177319, grad/param norm = 2.8127e-01, time/batch = 0.6413s	
1192/26050 (epoch 2.288), train_loss = 1.80486089, grad/param norm = 3.1853e-01, time/batch = 0.6402s	
1193/26050 (epoch 2.290), train_loss = 1.77860874, grad/param norm = 2.6196e-01, time/batch = 0.6415s	
1194/26050 (epoch 2.292), train_loss = 1.78845856, grad/param norm = 2.6920e-01, time/batch = 0.6416s	
1195/26050 (epoch 2.294), train_loss = 1.95536304, grad/param norm = 2.9034e-01, time/batch = 0.6482s	
1196/26050 (epoch 2.296), train_loss = 1.96014237, grad/param norm = 2.4271e-01, time/batch = 0.6447s	
1197/26050 (epoch 2.298), train_loss = 1.85102714, grad/param norm = 2.5506e-01, time/batch = 0.6562s	
1198/26050 (epoch 2.299), train_loss = 1.60858654, grad/param norm = 2.5659e-01, time/batch = 0.6821s	
1199/26050 (epoch 2.301), train_loss = 1.76209428, grad/param norm = 2.5032e-01, time/batch = 0.6434s	
1200/26050 (epoch 2.303), train_loss = 1.95251467, grad/param norm = 3.2584e-01, time/batch = 0.6383s	
1201/26050 (epoch 2.305), train_loss = 1.86115262, grad/param norm = 2.9336e-01, time/batch = 0.6385s	
1202/26050 (epoch 2.307), train_loss = 1.67876773, grad/param norm = 2.4076e-01, time/batch = 0.6426s	
1203/26050 (epoch 2.309), train_loss = 1.77698394, grad/param norm = 2.5784e-01, time/batch = 0.6501s	
1204/26050 (epoch 2.311), train_loss = 2.10723970, grad/param norm = 2.7642e-01, time/batch = 0.6550s	
1205/26050 (epoch 2.313), train_loss = 1.95625638, grad/param norm = 2.4932e-01, time/batch = 0.6495s	
1206/26050 (epoch 2.315), train_loss = 2.10359971, grad/param norm = 2.7900e-01, time/batch = 0.6415s	
1207/26050 (epoch 2.317), train_loss = 1.74202845, grad/param norm = 2.7906e-01, time/batch = 0.6448s	
1208/26050 (epoch 2.319), train_loss = 1.85072329, grad/param norm = 2.7158e-01, time/batch = 0.6683s	
1209/26050 (epoch 2.321), train_loss = 1.91359899, grad/param norm = 2.4595e-01, time/batch = 0.6757s	
1210/26050 (epoch 2.322), train_loss = 1.89241002, grad/param norm = 2.8678e-01, time/batch = 0.6434s	
1211/26050 (epoch 2.324), train_loss = 1.73938787, grad/param norm = 3.0470e-01, time/batch = 0.6416s	
1212/26050 (epoch 2.326), train_loss = 2.05596093, grad/param norm = 3.2945e-01, time/batch = 0.6394s	
1213/26050 (epoch 2.328), train_loss = 1.93542377, grad/param norm = 3.0337e-01, time/batch = 0.6380s	
1214/26050 (epoch 2.330), train_loss = 1.81822658, grad/param norm = 2.7183e-01, time/batch = 0.6388s	
1215/26050 (epoch 2.332), train_loss = 2.01839439, grad/param norm = 2.3885e-01, time/batch = 0.6380s	
1216/26050 (epoch 2.334), train_loss = 1.86029984, grad/param norm = 2.3416e-01, time/batch = 0.6424s	
1217/26050 (epoch 2.336), train_loss = 1.70123044, grad/param norm = 2.2934e-01, time/batch = 0.6420s	
1218/26050 (epoch 2.338), train_loss = 1.69210831, grad/param norm = 2.2020e-01, time/batch = 0.6407s	
1219/26050 (epoch 2.340), train_loss = 1.97488270, grad/param norm = 2.4441e-01, time/batch = 0.6399s	
1220/26050 (epoch 2.342), train_loss = 1.94464126, grad/param norm = 2.8571e-01, time/batch = 0.6508s	
1221/26050 (epoch 2.344), train_loss = 1.84280621, grad/param norm = 2.7090e-01, time/batch = 0.6571s	
1222/26050 (epoch 2.345), train_loss = 1.83829110, grad/param norm = 2.5758e-01, time/batch = 0.6587s	
1223/26050 (epoch 2.347), train_loss = 1.92895728, grad/param norm = 2.6236e-01, time/batch = 0.6664s	
1224/26050 (epoch 2.349), train_loss = 1.83396107, grad/param norm = 2.5918e-01, time/batch = 0.6839s	
1225/26050 (epoch 2.351), train_loss = 1.83255731, grad/param norm = 2.3951e-01, time/batch = 0.6644s	
1226/26050 (epoch 2.353), train_loss = 1.78602848, grad/param norm = 2.6681e-01, time/batch = 0.6543s	
1227/26050 (epoch 2.355), train_loss = 1.92395948, grad/param norm = 2.8449e-01, time/batch = 0.6559s	
1228/26050 (epoch 2.357), train_loss = 1.67321454, grad/param norm = 2.4500e-01, time/batch = 0.6580s	
1229/26050 (epoch 2.359), train_loss = 1.85012239, grad/param norm = 2.4118e-01, time/batch = 0.6576s	
1230/26050 (epoch 2.361), train_loss = 1.62213492, grad/param norm = 2.2648e-01, time/batch = 0.6563s	
1231/26050 (epoch 2.363), train_loss = 1.85994642, grad/param norm = 2.4803e-01, time/batch = 0.6609s	
1232/26050 (epoch 2.365), train_loss = 1.67601688, grad/param norm = 2.5295e-01, time/batch = 0.6533s	
1233/26050 (epoch 2.367), train_loss = 1.82575004, grad/param norm = 2.9195e-01, time/batch = 0.6425s	
1234/26050 (epoch 2.369), train_loss = 1.87132814, grad/param norm = 2.4938e-01, time/batch = 0.6415s	
1235/26050 (epoch 2.370), train_loss = 1.80572332, grad/param norm = 2.7019e-01, time/batch = 0.6405s	
1236/26050 (epoch 2.372), train_loss = 2.07820617, grad/param norm = 2.7599e-01, time/batch = 0.6411s	
1237/26050 (epoch 2.374), train_loss = 2.06886455, grad/param norm = 2.9132e-01, time/batch = 0.6396s	
1238/26050 (epoch 2.376), train_loss = 2.05988245, grad/param norm = 2.5037e-01, time/batch = 0.6425s	
1239/26050 (epoch 2.378), train_loss = 1.90648249, grad/param norm = 2.7811e-01, time/batch = 0.6825s	
1240/26050 (epoch 2.380), train_loss = 1.98683879, grad/param norm = 2.8802e-01, time/batch = 0.6572s	
1241/26050 (epoch 2.382), train_loss = 2.23010984, grad/param norm = 2.6769e-01, time/batch = 0.6453s	
1242/26050 (epoch 2.384), train_loss = 1.86016204, grad/param norm = 2.5434e-01, time/batch = 0.6409s	
1243/26050 (epoch 2.386), train_loss = 1.98100301, grad/param norm = 2.5436e-01, time/batch = 0.6409s	
1244/26050 (epoch 2.388), train_loss = 1.84124755, grad/param norm = 2.1032e-01, time/batch = 0.6415s	
1245/26050 (epoch 2.390), train_loss = 1.77391308, grad/param norm = 1.9895e-01, time/batch = 0.6403s	
1246/26050 (epoch 2.392), train_loss = 1.81936264, grad/param norm = 2.3748e-01, time/batch = 0.6395s	
1247/26050 (epoch 2.393), train_loss = 1.92510979, grad/param norm = 2.4445e-01, time/batch = 0.6388s	
1248/26050 (epoch 2.395), train_loss = 1.90515162, grad/param norm = 2.4760e-01, time/batch = 0.6417s	
1249/26050 (epoch 2.397), train_loss = 1.94111597, grad/param norm = 2.4039e-01, time/batch = 0.6408s	
1250/26050 (epoch 2.399), train_loss = 1.76234191, grad/param norm = 2.9688e-01, time/batch = 0.6383s	
1251/26050 (epoch 2.401), train_loss = 1.79189243, grad/param norm = 2.4675e-01, time/batch = 0.6412s	
1252/26050 (epoch 2.403), train_loss = 1.85722225, grad/param norm = 2.7106e-01, time/batch = 0.6392s	
1253/26050 (epoch 2.405), train_loss = 1.91944848, grad/param norm = 2.7950e-01, time/batch = 0.6399s	
1254/26050 (epoch 2.407), train_loss = 2.01321215, grad/param norm = 2.5890e-01, time/batch = 0.6691s	
1255/26050 (epoch 2.409), train_loss = 2.03117471, grad/param norm = 2.7810e-01, time/batch = 0.6756s	
1256/26050 (epoch 2.411), train_loss = 1.89004787, grad/param norm = 2.3436e-01, time/batch = 0.6565s	
1257/26050 (epoch 2.413), train_loss = 1.97484577, grad/param norm = 2.4793e-01, time/batch = 0.6508s	
1258/26050 (epoch 2.415), train_loss = 2.04469748, grad/param norm = 2.5747e-01, time/batch = 0.6383s	
1259/26050 (epoch 2.417), train_loss = 2.01796664, grad/param norm = 2.4332e-01, time/batch = 0.6379s	
1260/26050 (epoch 2.418), train_loss = 1.97181601, grad/param norm = 2.5744e-01, time/batch = 0.6385s	
1261/26050 (epoch 2.420), train_loss = 1.63981266, grad/param norm = 2.2297e-01, time/batch = 0.6394s	
1262/26050 (epoch 2.422), train_loss = 1.77852166, grad/param norm = 2.5642e-01, time/batch = 0.6388s	
1263/26050 (epoch 2.424), train_loss = 2.15753332, grad/param norm = 3.1153e-01, time/batch = 0.6408s	
1264/26050 (epoch 2.426), train_loss = 2.09737467, grad/param norm = 3.5771e-01, time/batch = 0.6391s	
1265/26050 (epoch 2.428), train_loss = 1.77446862, grad/param norm = 2.2828e-01, time/batch = 0.6381s	
1266/26050 (epoch 2.430), train_loss = 1.87125920, grad/param norm = 2.4726e-01, time/batch = 0.6393s	
1267/26050 (epoch 2.432), train_loss = 1.85456684, grad/param norm = 2.5725e-01, time/batch = 0.6378s	
1268/26050 (epoch 2.434), train_loss = 2.02672122, grad/param norm = 2.6713e-01, time/batch = 0.6381s	
1269/26050 (epoch 2.436), train_loss = 2.07060009, grad/param norm = 2.3085e-01, time/batch = 0.6471s	
1270/26050 (epoch 2.438), train_loss = 1.77343877, grad/param norm = 2.4987e-01, time/batch = 0.6826s	
1271/26050 (epoch 2.440), train_loss = 1.92727725, grad/param norm = 2.6340e-01, time/batch = 0.6689s	
1272/26050 (epoch 2.441), train_loss = 1.82521892, grad/param norm = 2.8723e-01, time/batch = 0.6479s	
1273/26050 (epoch 2.443), train_loss = 1.71479850, grad/param norm = 2.3463e-01, time/batch = 0.6500s	
1274/26050 (epoch 2.445), train_loss = 1.79801445, grad/param norm = 2.6910e-01, time/batch = 0.6445s	
1275/26050 (epoch 2.447), train_loss = 2.10583709, grad/param norm = 2.3341e-01, time/batch = 0.6460s	
1276/26050 (epoch 2.449), train_loss = 1.75712086, grad/param norm = 2.4675e-01, time/batch = 0.6422s	
1277/26050 (epoch 2.451), train_loss = 1.89685899, grad/param norm = 2.7178e-01, time/batch = 0.6395s	
1278/26050 (epoch 2.453), train_loss = 1.66577069, grad/param norm = 2.4165e-01, time/batch = 0.6405s	
1279/26050 (epoch 2.455), train_loss = 1.82667139, grad/param norm = 2.2830e-01, time/batch = 0.6429s	
1280/26050 (epoch 2.457), train_loss = 1.91174375, grad/param norm = 2.7801e-01, time/batch = 0.6410s	
1281/26050 (epoch 2.459), train_loss = 2.06651925, grad/param norm = 3.2126e-01, time/batch = 0.6398s	
1282/26050 (epoch 2.461), train_loss = 1.88270895, grad/param norm = 2.6163e-01, time/batch = 0.6416s	
1283/26050 (epoch 2.463), train_loss = 1.79722841, grad/param norm = 2.3139e-01, time/batch = 0.6420s	
1284/26050 (epoch 2.464), train_loss = 1.98546581, grad/param norm = 2.6601e-01, time/batch = 0.6450s	
1285/26050 (epoch 2.466), train_loss = 1.99054832, grad/param norm = 2.1957e-01, time/batch = 0.6677s	
1286/26050 (epoch 2.468), train_loss = 1.96871644, grad/param norm = 2.2360e-01, time/batch = 0.6552s	
1287/26050 (epoch 2.470), train_loss = 2.03157520, grad/param norm = 2.5008e-01, time/batch = 0.6410s	
1288/26050 (epoch 2.472), train_loss = 2.18088993, grad/param norm = 3.0963e-01, time/batch = 0.6483s	
1289/26050 (epoch 2.474), train_loss = 2.15858660, grad/param norm = 2.6627e-01, time/batch = 0.6411s	
1290/26050 (epoch 2.476), train_loss = 2.02603486, grad/param norm = 2.2980e-01, time/batch = 0.6413s	
1291/26050 (epoch 2.478), train_loss = 1.82482340, grad/param norm = 2.2294e-01, time/batch = 0.6402s	
1292/26050 (epoch 2.480), train_loss = 1.94228536, grad/param norm = 2.3633e-01, time/batch = 0.6385s	
1293/26050 (epoch 2.482), train_loss = 1.82598108, grad/param norm = 2.3676e-01, time/batch = 0.6372s	
1294/26050 (epoch 2.484), train_loss = 1.70317571, grad/param norm = 2.4064e-01, time/batch = 0.6411s	
1295/26050 (epoch 2.486), train_loss = 2.01913945, grad/param norm = 2.5087e-01, time/batch = 0.6411s	
1296/26050 (epoch 2.488), train_loss = 2.19936882, grad/param norm = 2.3773e-01, time/batch = 0.6550s	
1297/26050 (epoch 2.489), train_loss = 2.09855757, grad/param norm = 2.6585e-01, time/batch = 0.6504s	
1298/26050 (epoch 2.491), train_loss = 1.80970461, grad/param norm = 2.7671e-01, time/batch = 0.6487s	
1299/26050 (epoch 2.493), train_loss = 1.79726908, grad/param norm = 2.4823e-01, time/batch = 0.6375s	
1300/26050 (epoch 2.495), train_loss = 1.93149725, grad/param norm = 2.6796e-01, time/batch = 0.6636s	
1301/26050 (epoch 2.497), train_loss = 1.81874170, grad/param norm = 2.4347e-01, time/batch = 0.6838s	
1302/26050 (epoch 2.499), train_loss = 1.77404179, grad/param norm = 2.3160e-01, time/batch = 0.6492s	
1303/26050 (epoch 2.501), train_loss = 1.80209253, grad/param norm = 2.2442e-01, time/batch = 0.6446s	
1304/26050 (epoch 2.503), train_loss = 1.90314665, grad/param norm = 2.5870e-01, time/batch = 0.6420s	
1305/26050 (epoch 2.505), train_loss = 1.95414171, grad/param norm = 2.5346e-01, time/batch = 0.6381s	
1306/26050 (epoch 2.507), train_loss = 1.98829934, grad/param norm = 2.7717e-01, time/batch = 0.6382s	
1307/26050 (epoch 2.509), train_loss = 2.13980275, grad/param norm = 3.0277e-01, time/batch = 0.6372s	
1308/26050 (epoch 2.511), train_loss = 1.76088808, grad/param norm = 2.2770e-01, time/batch = 0.6373s	
1309/26050 (epoch 2.512), train_loss = 1.93686475, grad/param norm = 2.3938e-01, time/batch = 0.6380s	
1310/26050 (epoch 2.514), train_loss = 1.93323513, grad/param norm = 2.4400e-01, time/batch = 0.6385s	
1311/26050 (epoch 2.516), train_loss = 1.94176906, grad/param norm = 2.3664e-01, time/batch = 0.6397s	
1312/26050 (epoch 2.518), train_loss = 1.90545157, grad/param norm = 2.3435e-01, time/batch = 0.6382s	
1313/26050 (epoch 2.520), train_loss = 1.90319856, grad/param norm = 2.5156e-01, time/batch = 0.6373s	
1314/26050 (epoch 2.522), train_loss = 1.86828891, grad/param norm = 2.4484e-01, time/batch = 0.6372s	
1315/26050 (epoch 2.524), train_loss = 2.19073599, grad/param norm = 2.6187e-01, time/batch = 0.6393s	
1316/26050 (epoch 2.526), train_loss = 1.99527292, grad/param norm = 3.0718e-01, time/batch = 0.6405s	
1317/26050 (epoch 2.528), train_loss = 2.00787457, grad/param norm = 3.0894e-01, time/batch = 0.6413s	
1318/26050 (epoch 2.530), train_loss = 1.89228124, grad/param norm = 2.6062e-01, time/batch = 0.6452s	
1319/26050 (epoch 2.532), train_loss = 1.95618850, grad/param norm = 2.5163e-01, time/batch = 0.6427s	
1320/26050 (epoch 2.534), train_loss = 1.94822281, grad/param norm = 2.5086e-01, time/batch = 0.6407s	
1321/26050 (epoch 2.536), train_loss = 1.85143603, grad/param norm = 3.0130e-01, time/batch = 0.6458s	
1322/26050 (epoch 2.537), train_loss = 1.97159457, grad/param norm = 2.4187e-01, time/batch = 0.6480s	
1323/26050 (epoch 2.539), train_loss = 1.83482177, grad/param norm = 2.3963e-01, time/batch = 0.6474s	
1324/26050 (epoch 2.541), train_loss = 2.01610877, grad/param norm = 2.4541e-01, time/batch = 0.6447s	
1325/26050 (epoch 2.543), train_loss = 1.72396828, grad/param norm = 2.5782e-01, time/batch = 0.6437s	
1326/26050 (epoch 2.545), train_loss = 1.89077660, grad/param norm = 2.3947e-01, time/batch = 0.6428s	
1327/26050 (epoch 2.547), train_loss = 2.00532122, grad/param norm = 2.7247e-01, time/batch = 0.6397s	
1328/26050 (epoch 2.549), train_loss = 1.80306623, grad/param norm = 2.3789e-01, time/batch = 0.6408s	
1329/26050 (epoch 2.551), train_loss = 1.93650976, grad/param norm = 2.4711e-01, time/batch = 0.6409s	
1330/26050 (epoch 2.553), train_loss = 1.85565003, grad/param norm = 2.5868e-01, time/batch = 0.6403s	
1331/26050 (epoch 2.555), train_loss = 1.83436952, grad/param norm = 2.4890e-01, time/batch = 0.6424s	
1332/26050 (epoch 2.557), train_loss = 1.96082512, grad/param norm = 2.5214e-01, time/batch = 0.6436s	
1333/26050 (epoch 2.559), train_loss = 1.91797226, grad/param norm = 2.7975e-01, time/batch = 0.6418s	
1334/26050 (epoch 2.560), train_loss = 1.85897557, grad/param norm = 2.2686e-01, time/batch = 0.6563s	
1335/26050 (epoch 2.562), train_loss = 1.94340718, grad/param norm = 2.5867e-01, time/batch = 0.6456s	
1336/26050 (epoch 2.564), train_loss = 2.08399124, grad/param norm = 2.4695e-01, time/batch = 0.6784s	
1337/26050 (epoch 2.566), train_loss = 1.81573543, grad/param norm = 2.3447e-01, time/batch = 0.6656s	
1338/26050 (epoch 2.568), train_loss = 1.94105647, grad/param norm = 2.3312e-01, time/batch = 0.6406s	
1339/26050 (epoch 2.570), train_loss = 1.96941089, grad/param norm = 2.6523e-01, time/batch = 0.6389s	
1340/26050 (epoch 2.572), train_loss = 1.95744998, grad/param norm = 2.5462e-01, time/batch = 0.6387s	
1341/26050 (epoch 2.574), train_loss = 2.04108843, grad/param norm = 2.9018e-01, time/batch = 0.6410s	
1342/26050 (epoch 2.576), train_loss = 1.92619963, grad/param norm = 2.6306e-01, time/batch = 0.6412s	
1343/26050 (epoch 2.578), train_loss = 1.95155542, grad/param norm = 2.2601e-01, time/batch = 0.6401s	
1344/26050 (epoch 2.580), train_loss = 1.79470210, grad/param norm = 2.3616e-01, time/batch = 0.6390s	
1345/26050 (epoch 2.582), train_loss = 1.99202039, grad/param norm = 2.5161e-01, time/batch = 0.6387s	
1346/26050 (epoch 2.583), train_loss = 1.94962592, grad/param norm = 2.5042e-01, time/batch = 0.6414s	
1347/26050 (epoch 2.585), train_loss = 1.80643963, grad/param norm = 2.6407e-01, time/batch = 0.6827s	
1348/26050 (epoch 2.587), train_loss = 1.95052251, grad/param norm = 2.5734e-01, time/batch = 0.6607s	
1349/26050 (epoch 2.589), train_loss = 1.92204015, grad/param norm = 2.5971e-01, time/batch = 0.6419s	
1350/26050 (epoch 2.591), train_loss = 1.94231316, grad/param norm = 2.4433e-01, time/batch = 0.6388s	
1351/26050 (epoch 2.593), train_loss = 1.80513088, grad/param norm = 2.6163e-01, time/batch = 0.6405s	
1352/26050 (epoch 2.595), train_loss = 2.00665777, grad/param norm = 2.6472e-01, time/batch = 0.6400s	
1353/26050 (epoch 2.597), train_loss = 1.89917283, grad/param norm = 2.3368e-01, time/batch = 0.6463s	
1354/26050 (epoch 2.599), train_loss = 1.73079571, grad/param norm = 2.1640e-01, time/batch = 0.6419s	
1355/26050 (epoch 2.601), train_loss = 2.09144267, grad/param norm = 2.4558e-01, time/batch = 0.6392s	
1356/26050 (epoch 2.603), train_loss = 1.97265082, grad/param norm = 2.6114e-01, time/batch = 0.6438s	
1357/26050 (epoch 2.605), train_loss = 1.82856727, grad/param norm = 2.1437e-01, time/batch = 0.6564s	
1358/26050 (epoch 2.607), train_loss = 1.96608948, grad/param norm = 2.5424e-01, time/batch = 0.6432s	
1359/26050 (epoch 2.608), train_loss = 1.88373171, grad/param norm = 2.3300e-01, time/batch = 0.6433s	
1360/26050 (epoch 2.610), train_loss = 1.86215399, grad/param norm = 2.4686e-01, time/batch = 0.6408s	
1361/26050 (epoch 2.612), train_loss = 1.87239741, grad/param norm = 2.4824e-01, time/batch = 0.6402s	
1362/26050 (epoch 2.614), train_loss = 1.92747171, grad/param norm = 2.9536e-01, time/batch = 0.6712s	
1363/26050 (epoch 2.616), train_loss = 2.24767909, grad/param norm = 2.7332e-01, time/batch = 0.6785s	
1364/26050 (epoch 2.618), train_loss = 1.75872636, grad/param norm = 2.6884e-01, time/batch = 0.6612s	
1365/26050 (epoch 2.620), train_loss = 2.01736312, grad/param norm = 2.7412e-01, time/batch = 0.6539s	
1366/26050 (epoch 2.622), train_loss = 1.59784153, grad/param norm = 2.3000e-01, time/batch = 0.6809s	
1367/26050 (epoch 2.624), train_loss = 1.79056591, grad/param norm = 2.2612e-01, time/batch = 0.6542s	
1368/26050 (epoch 2.626), train_loss = 1.90377273, grad/param norm = 2.9857e-01, time/batch = 0.6426s	
1369/26050 (epoch 2.628), train_loss = 1.89581976, grad/param norm = 2.7117e-01, time/batch = 0.6401s	
1370/26050 (epoch 2.630), train_loss = 2.01427656, grad/param norm = 2.3321e-01, time/batch = 0.6368s	
1371/26050 (epoch 2.631), train_loss = 1.95210853, grad/param norm = 2.1856e-01, time/batch = 0.6539s	
1372/26050 (epoch 2.633), train_loss = 1.70960063, grad/param norm = 2.1356e-01, time/batch = 0.6418s	
1373/26050 (epoch 2.635), train_loss = 1.77420121, grad/param norm = 2.2229e-01, time/batch = 0.6404s	
1374/26050 (epoch 2.637), train_loss = 1.76469685, grad/param norm = 2.4564e-01, time/batch = 0.6390s	
1375/26050 (epoch 2.639), train_loss = 1.93461567, grad/param norm = 2.2738e-01, time/batch = 0.6381s	
1376/26050 (epoch 2.641), train_loss = 1.78642762, grad/param norm = 2.2057e-01, time/batch = 0.6386s	
1377/26050 (epoch 2.643), train_loss = 1.79467888, grad/param norm = 2.1209e-01, time/batch = 0.6555s	
1378/26050 (epoch 2.645), train_loss = 2.04207531, grad/param norm = 2.4780e-01, time/batch = 0.6829s	
1379/26050 (epoch 2.647), train_loss = 1.75701120, grad/param norm = 2.4171e-01, time/batch = 0.6488s	
1380/26050 (epoch 2.649), train_loss = 1.93216555, grad/param norm = 2.6253e-01, time/batch = 0.6403s	
1381/26050 (epoch 2.651), train_loss = 1.93406927, grad/param norm = 2.6149e-01, time/batch = 0.6644s	
1382/26050 (epoch 2.653), train_loss = 1.81072961, grad/param norm = 2.6329e-01, time/batch = 0.6701s	
1383/26050 (epoch 2.655), train_loss = 1.82634957, grad/param norm = 2.4499e-01, time/batch = 0.6539s	
1384/26050 (epoch 2.656), train_loss = 1.81764305, grad/param norm = 2.4379e-01, time/batch = 0.6394s	
1385/26050 (epoch 2.658), train_loss = 2.00999296, grad/param norm = 2.4222e-01, time/batch = 0.6389s	
1386/26050 (epoch 2.660), train_loss = 1.73461691, grad/param norm = 2.8115e-01, time/batch = 0.6397s	
1387/26050 (epoch 2.662), train_loss = 1.72815374, grad/param norm = 2.4588e-01, time/batch = 0.6379s	
1388/26050 (epoch 2.664), train_loss = 1.74790153, grad/param norm = 2.5656e-01, time/batch = 0.6383s	
1389/26050 (epoch 2.666), train_loss = 1.91181765, grad/param norm = 2.6185e-01, time/batch = 0.6389s	
1390/26050 (epoch 2.668), train_loss = 1.61386515, grad/param norm = 2.3383e-01, time/batch = 0.6377s	
1391/26050 (epoch 2.670), train_loss = 2.02339390, grad/param norm = 2.7675e-01, time/batch = 0.6388s	
1392/26050 (epoch 2.672), train_loss = 1.79549645, grad/param norm = 2.5220e-01, time/batch = 0.6439s	
1393/26050 (epoch 2.674), train_loss = 1.72256219, grad/param norm = 2.3795e-01, time/batch = 0.6831s	
1394/26050 (epoch 2.676), train_loss = 1.82051599, grad/param norm = 2.3815e-01, time/batch = 0.6583s	
1395/26050 (epoch 2.678), train_loss = 2.03632176, grad/param norm = 2.4766e-01, time/batch = 0.6418s	
1396/26050 (epoch 2.679), train_loss = 1.92235400, grad/param norm = 2.5851e-01, time/batch = 0.6375s	
1397/26050 (epoch 2.681), train_loss = 1.92101325, grad/param norm = 2.5596e-01, time/batch = 0.6374s	
1398/26050 (epoch 2.683), train_loss = 1.79764806, grad/param norm = 3.1576e-01, time/batch = 0.6376s	
1399/26050 (epoch 2.685), train_loss = 1.79495061, grad/param norm = 2.5825e-01, time/batch = 0.6382s	
1400/26050 (epoch 2.687), train_loss = 1.62287437, grad/param norm = 2.2797e-01, time/batch = 0.6372s	
1401/26050 (epoch 2.689), train_loss = 1.83674168, grad/param norm = 2.2106e-01, time/batch = 0.6405s	
1402/26050 (epoch 2.691), train_loss = 1.61474315, grad/param norm = 2.2681e-01, time/batch = 0.6401s	
1403/26050 (epoch 2.693), train_loss = 1.78003698, grad/param norm = 2.5194e-01, time/batch = 0.6419s	
1404/26050 (epoch 2.695), train_loss = 1.90302854, grad/param norm = 2.6144e-01, time/batch = 0.6376s	
1405/26050 (epoch 2.697), train_loss = 1.71241300, grad/param norm = 2.5320e-01, time/batch = 0.6414s	
1406/26050 (epoch 2.699), train_loss = 1.88548357, grad/param norm = 2.6449e-01, time/batch = 0.6405s	
1407/26050 (epoch 2.701), train_loss = 1.67704045, grad/param norm = 2.3052e-01, time/batch = 0.6380s	
1408/26050 (epoch 2.702), train_loss = 2.08227226, grad/param norm = 2.5301e-01, time/batch = 0.6634s	
1409/26050 (epoch 2.704), train_loss = 1.84223596, grad/param norm = 2.2749e-01, time/batch = 0.6789s	
1410/26050 (epoch 2.706), train_loss = 1.97021373, grad/param norm = 2.3955e-01, time/batch = 0.6403s	
1411/26050 (epoch 2.708), train_loss = 1.84411892, grad/param norm = 2.0520e-01, time/batch = 0.6466s	
1412/26050 (epoch 2.710), train_loss = 1.99090129, grad/param norm = 2.2629e-01, time/batch = 0.6410s	
1413/26050 (epoch 2.712), train_loss = 2.02650263, grad/param norm = 2.2744e-01, time/batch = 0.6446s	
1414/26050 (epoch 2.714), train_loss = 1.73505025, grad/param norm = 2.4548e-01, time/batch = 0.6421s	
1415/26050 (epoch 2.716), train_loss = 2.10746314, grad/param norm = 2.6436e-01, time/batch = 0.6391s	
1416/26050 (epoch 2.718), train_loss = 1.91033452, grad/param norm = 2.7465e-01, time/batch = 0.6397s	
1417/26050 (epoch 2.720), train_loss = 1.69666479, grad/param norm = 2.3338e-01, time/batch = 0.6406s	
1418/26050 (epoch 2.722), train_loss = 1.79906306, grad/param norm = 2.8539e-01, time/batch = 0.6401s	
1419/26050 (epoch 2.724), train_loss = 1.73192374, grad/param norm = 2.7482e-01, time/batch = 0.6384s	
1420/26050 (epoch 2.726), train_loss = 1.98067924, grad/param norm = 2.4692e-01, time/batch = 0.6390s	
1421/26050 (epoch 2.727), train_loss = 1.88914249, grad/param norm = 2.3546e-01, time/batch = 0.6397s	
1422/26050 (epoch 2.729), train_loss = 1.96066645, grad/param norm = 2.3211e-01, time/batch = 0.6402s	
1423/26050 (epoch 2.731), train_loss = 1.80691211, grad/param norm = 2.2458e-01, time/batch = 0.6439s	
1424/26050 (epoch 2.733), train_loss = 1.90328488, grad/param norm = 2.6994e-01, time/batch = 0.6828s	
1425/26050 (epoch 2.735), train_loss = 2.04777530, grad/param norm = 2.4899e-01, time/batch = 0.6638s	
1426/26050 (epoch 2.737), train_loss = 1.94341147, grad/param norm = 2.3849e-01, time/batch = 0.6485s	
1427/26050 (epoch 2.739), train_loss = 1.94454226, grad/param norm = 2.5541e-01, time/batch = 0.6463s	
1428/26050 (epoch 2.741), train_loss = 1.72606111, grad/param norm = 2.4220e-01, time/batch = 0.6412s	
1429/26050 (epoch 2.743), train_loss = 2.01366265, grad/param norm = 2.9179e-01, time/batch = 0.6432s	
1430/26050 (epoch 2.745), train_loss = 1.71086504, grad/param norm = 2.1191e-01, time/batch = 0.6409s	
1431/26050 (epoch 2.747), train_loss = 1.80941482, grad/param norm = 2.1543e-01, time/batch = 0.6422s	
1432/26050 (epoch 2.749), train_loss = 1.88104612, grad/param norm = 2.7152e-01, time/batch = 0.6394s	
1433/26050 (epoch 2.750), train_loss = 1.77053475, grad/param norm = 2.2386e-01, time/batch = 0.6400s	
1434/26050 (epoch 2.752), train_loss = 1.96563992, grad/param norm = 2.5160e-01, time/batch = 0.6391s	
1435/26050 (epoch 2.754), train_loss = 1.71170844, grad/param norm = 2.1415e-01, time/batch = 0.6500s	
1436/26050 (epoch 2.756), train_loss = 1.99580016, grad/param norm = 2.2451e-01, time/batch = 0.6455s	
1437/26050 (epoch 2.758), train_loss = 1.91392438, grad/param norm = 2.7348e-01, time/batch = 0.6383s	
1438/26050 (epoch 2.760), train_loss = 1.83911455, grad/param norm = 2.2906e-01, time/batch = 0.6375s	
1439/26050 (epoch 2.762), train_loss = 1.85763468, grad/param norm = 2.3976e-01, time/batch = 0.6696s	
1440/26050 (epoch 2.764), train_loss = 1.94480611, grad/param norm = 2.3593e-01, time/batch = 0.6726s	
1441/26050 (epoch 2.766), train_loss = 1.90121156, grad/param norm = 2.2266e-01, time/batch = 0.6489s	
1442/26050 (epoch 2.768), train_loss = 1.80234036, grad/param norm = 2.1952e-01, time/batch = 0.6405s	
1443/26050 (epoch 2.770), train_loss = 1.85321925, grad/param norm = 2.5178e-01, time/batch = 0.6393s	
1444/26050 (epoch 2.772), train_loss = 1.86792059, grad/param norm = 2.6374e-01, time/batch = 0.6387s	
1445/26050 (epoch 2.774), train_loss = 1.78130371, grad/param norm = 2.6490e-01, time/batch = 0.6389s	
1446/26050 (epoch 2.775), train_loss = 1.63331554, grad/param norm = 2.4929e-01, time/batch = 0.6383s	
1447/26050 (epoch 2.777), train_loss = 1.72245193, grad/param norm = 2.3227e-01, time/batch = 0.6388s	
1448/26050 (epoch 2.779), train_loss = 1.87743142, grad/param norm = 2.5950e-01, time/batch = 0.6400s	
1449/26050 (epoch 2.781), train_loss = 1.79583451, grad/param norm = 2.5633e-01, time/batch = 0.6398s	
1450/26050 (epoch 2.783), train_loss = 1.77504641, grad/param norm = 2.0520e-01, time/batch = 0.6389s	
1451/26050 (epoch 2.785), train_loss = 1.79827407, grad/param norm = 2.7745e-01, time/batch = 0.6396s	
1452/26050 (epoch 2.787), train_loss = 1.79814612, grad/param norm = 2.8835e-01, time/batch = 0.6411s	
1453/26050 (epoch 2.789), train_loss = 1.93760640, grad/param norm = 2.8153e-01, time/batch = 0.6425s	
1454/26050 (epoch 2.791), train_loss = 1.88130096, grad/param norm = 2.2808e-01, time/batch = 0.6624s	
1455/26050 (epoch 2.793), train_loss = 1.80558225, grad/param norm = 2.5140e-01, time/batch = 0.6832s	
1456/26050 (epoch 2.795), train_loss = 1.78665173, grad/param norm = 2.6542e-01, time/batch = 0.6603s	
1457/26050 (epoch 2.797), train_loss = 1.72445514, grad/param norm = 2.2940e-01, time/batch = 0.6576s	
1458/26050 (epoch 2.798), train_loss = 1.68443000, grad/param norm = 2.1402e-01, time/batch = 0.6570s	
1459/26050 (epoch 2.800), train_loss = 1.71637355, grad/param norm = 2.2487e-01, time/batch = 0.6484s	
1460/26050 (epoch 2.802), train_loss = 1.87152627, grad/param norm = 2.2180e-01, time/batch = 0.6459s	
1461/26050 (epoch 2.804), train_loss = 1.89799184, grad/param norm = 2.5463e-01, time/batch = 0.6431s	
1462/26050 (epoch 2.806), train_loss = 1.98785103, grad/param norm = 2.7293e-01, time/batch = 0.6443s	
1463/26050 (epoch 2.808), train_loss = 1.73723436, grad/param norm = 2.3036e-01, time/batch = 0.6429s	
1464/26050 (epoch 2.810), train_loss = 1.77613622, grad/param norm = 2.5709e-01, time/batch = 0.6436s	
1465/26050 (epoch 2.812), train_loss = 1.68223038, grad/param norm = 2.3976e-01, time/batch = 0.6399s	
1466/26050 (epoch 2.814), train_loss = 1.77919473, grad/param norm = 2.5728e-01, time/batch = 0.6396s	
1467/26050 (epoch 2.816), train_loss = 1.88038576, grad/param norm = 2.2422e-01, time/batch = 0.6387s	
1468/26050 (epoch 2.818), train_loss = 1.97119377, grad/param norm = 2.8273e-01, time/batch = 0.6556s	
1469/26050 (epoch 2.820), train_loss = 1.86016358, grad/param norm = 2.2820e-01, time/batch = 0.6414s	
1470/26050 (epoch 2.821), train_loss = 1.97190108, grad/param norm = 2.4885e-01, time/batch = 0.6843s	
1471/26050 (epoch 2.823), train_loss = 2.05818724, grad/param norm = 2.7155e-01, time/batch = 0.6708s	
1472/26050 (epoch 2.825), train_loss = 1.82863573, grad/param norm = 2.4567e-01, time/batch = 0.6511s	
1473/26050 (epoch 2.827), train_loss = 1.92396550, grad/param norm = 3.0720e-01, time/batch = 0.6429s	
1474/26050 (epoch 2.829), train_loss = 1.88355229, grad/param norm = 2.2825e-01, time/batch = 0.6432s	
1475/26050 (epoch 2.831), train_loss = 1.96586778, grad/param norm = 2.1589e-01, time/batch = 0.6475s	
1476/26050 (epoch 2.833), train_loss = 2.02654525, grad/param norm = 2.5759e-01, time/batch = 0.6409s	
1477/26050 (epoch 2.835), train_loss = 2.08348348, grad/param norm = 2.3021e-01, time/batch = 0.6406s	
1478/26050 (epoch 2.837), train_loss = 1.75271486, grad/param norm = 2.3804e-01, time/batch = 0.6395s	
1479/26050 (epoch 2.839), train_loss = 2.01507965, grad/param norm = 2.5371e-01, time/batch = 0.6429s	
1480/26050 (epoch 2.841), train_loss = 1.96003252, grad/param norm = 2.7523e-01, time/batch = 0.6421s	
1481/26050 (epoch 2.843), train_loss = 1.90133219, grad/param norm = 2.4397e-01, time/batch = 0.6399s	
1482/26050 (epoch 2.845), train_loss = 1.77020592, grad/param norm = 2.3503e-01, time/batch = 0.6444s	
1483/26050 (epoch 2.846), train_loss = 1.94993922, grad/param norm = 2.5214e-01, time/batch = 0.6544s	
1484/26050 (epoch 2.848), train_loss = 1.77901356, grad/param norm = 2.2338e-01, time/batch = 0.6538s	
1485/26050 (epoch 2.850), train_loss = 1.79773518, grad/param norm = 2.2717e-01, time/batch = 0.6683s	
1486/26050 (epoch 2.852), train_loss = 1.82517646, grad/param norm = 2.4749e-01, time/batch = 0.6756s	
1487/26050 (epoch 2.854), train_loss = 1.85088359, grad/param norm = 2.3197e-01, time/batch = 0.6438s	
1488/26050 (epoch 2.856), train_loss = 1.77768379, grad/param norm = 2.3316e-01, time/batch = 0.6434s	
1489/26050 (epoch 2.858), train_loss = 1.64821319, grad/param norm = 2.6060e-01, time/batch = 0.6395s	
1490/26050 (epoch 2.860), train_loss = 1.89097226, grad/param norm = 2.8223e-01, time/batch = 0.6391s	
1491/26050 (epoch 2.862), train_loss = 1.84817243, grad/param norm = 2.6769e-01, time/batch = 0.6412s	
1492/26050 (epoch 2.864), train_loss = 1.75195211, grad/param norm = 2.5973e-01, time/batch = 0.6408s	
1493/26050 (epoch 2.866), train_loss = 1.73253729, grad/param norm = 2.5557e-01, time/batch = 0.6413s	
1494/26050 (epoch 2.868), train_loss = 2.01933546, grad/param norm = 2.8328e-01, time/batch = 0.6414s	
1495/26050 (epoch 2.869), train_loss = 1.66091862, grad/param norm = 2.4865e-01, time/batch = 0.6405s	
1496/26050 (epoch 2.871), train_loss = 1.59470158, grad/param norm = 2.3824e-01, time/batch = 0.6408s	
1497/26050 (epoch 2.873), train_loss = 1.76177277, grad/param norm = 2.6431e-01, time/batch = 0.6398s	
1498/26050 (epoch 2.875), train_loss = 1.81919730, grad/param norm = 2.8067e-01, time/batch = 0.6400s	
1499/26050 (epoch 2.877), train_loss = 1.63018904, grad/param norm = 2.4685e-01, time/batch = 0.6398s	
1500/26050 (epoch 2.879), train_loss = 1.78359808, grad/param norm = 2.2580e-01, time/batch = 0.6497s	
1501/26050 (epoch 2.881), train_loss = 2.00525557, grad/param norm = 2.3155e-01, time/batch = 0.6835s	
1502/26050 (epoch 2.883), train_loss = 1.87944994, grad/param norm = 2.4855e-01, time/batch = 0.6637s	
1503/26050 (epoch 2.885), train_loss = 1.60194280, grad/param norm = 2.2519e-01, time/batch = 0.6438s	
1504/26050 (epoch 2.887), train_loss = 1.83028330, grad/param norm = 2.2408e-01, time/batch = 0.6409s	
1505/26050 (epoch 2.889), train_loss = 1.71942725, grad/param norm = 2.3889e-01, time/batch = 0.6402s	
1506/26050 (epoch 2.891), train_loss = 1.58653757, grad/param norm = 2.5213e-01, time/batch = 0.6388s	
1507/26050 (epoch 2.893), train_loss = 1.57650692, grad/param norm = 1.9147e-01, time/batch = 0.6447s	
1508/26050 (epoch 2.894), train_loss = 1.66408442, grad/param norm = 2.0139e-01, time/batch = 0.6420s	
1509/26050 (epoch 2.896), train_loss = 1.88858440, grad/param norm = 2.2689e-01, time/batch = 0.6391s	
1510/26050 (epoch 2.898), train_loss = 1.77485658, grad/param norm = 2.3873e-01, time/batch = 0.6422s	
1511/26050 (epoch 2.900), train_loss = 2.08145300, grad/param norm = 2.4935e-01, time/batch = 0.6418s	
1512/26050 (epoch 2.902), train_loss = 1.86935743, grad/param norm = 2.2215e-01, time/batch = 0.6394s	
1513/26050 (epoch 2.904), train_loss = 1.84983455, grad/param norm = 2.4174e-01, time/batch = 0.6426s	
1514/26050 (epoch 2.906), train_loss = 1.83786568, grad/param norm = 2.3009e-01, time/batch = 0.6400s	
1515/26050 (epoch 2.908), train_loss = 1.80126251, grad/param norm = 2.5062e-01, time/batch = 0.6405s	
1516/26050 (epoch 2.910), train_loss = 1.75213529, grad/param norm = 2.2015e-01, time/batch = 0.6750s	
1517/26050 (epoch 2.912), train_loss = 2.12071658, grad/param norm = 2.6074e-01, time/batch = 0.6758s	
1518/26050 (epoch 2.914), train_loss = 2.15745608, grad/param norm = 2.3137e-01, time/batch = 0.6457s	
1519/26050 (epoch 2.916), train_loss = 1.94902833, grad/param norm = 2.1840e-01, time/batch = 0.6412s	
1520/26050 (epoch 2.917), train_loss = 1.77587542, grad/param norm = 2.2607e-01, time/batch = 0.6404s	
1521/26050 (epoch 2.919), train_loss = 1.88976022, grad/param norm = 2.3119e-01, time/batch = 0.6412s	
1522/26050 (epoch 2.921), train_loss = 1.64149592, grad/param norm = 2.2546e-01, time/batch = 0.6419s	
1523/26050 (epoch 2.923), train_loss = 1.75953170, grad/param norm = 2.6646e-01, time/batch = 0.6503s	
1524/26050 (epoch 2.925), train_loss = 1.68757809, grad/param norm = 2.6310e-01, time/batch = 0.6590s	
1525/26050 (epoch 2.927), train_loss = 1.70623925, grad/param norm = 2.1365e-01, time/batch = 0.6635s	
1526/26050 (epoch 2.929), train_loss = 1.73881993, grad/param norm = 2.2752e-01, time/batch = 0.6700s	
1527/26050 (epoch 2.931), train_loss = 2.11357622, grad/param norm = 2.7162e-01, time/batch = 0.6632s	
1528/26050 (epoch 2.933), train_loss = 1.82025247, grad/param norm = 2.5590e-01, time/batch = 0.6586s	
1529/26050 (epoch 2.935), train_loss = 1.62946233, grad/param norm = 2.1943e-01, time/batch = 0.6542s	
1530/26050 (epoch 2.937), train_loss = 1.75043816, grad/param norm = 2.2942e-01, time/batch = 0.6557s	
1531/26050 (epoch 2.939), train_loss = 1.68568699, grad/param norm = 2.4206e-01, time/batch = 0.6768s	
1532/26050 (epoch 2.940), train_loss = 1.88701464, grad/param norm = 2.4342e-01, time/batch = 0.6780s	
1533/26050 (epoch 2.942), train_loss = 1.86600499, grad/param norm = 2.4163e-01, time/batch = 0.6560s	
1534/26050 (epoch 2.944), train_loss = 1.76478916, grad/param norm = 2.4519e-01, time/batch = 0.6567s	
1535/26050 (epoch 2.946), train_loss = 1.95115098, grad/param norm = 2.4375e-01, time/batch = 0.6511s	
1536/26050 (epoch 2.948), train_loss = 1.57001978, grad/param norm = 2.6225e-01, time/batch = 0.6382s	
1537/26050 (epoch 2.950), train_loss = 1.74590220, grad/param norm = 2.3741e-01, time/batch = 0.6388s	
1538/26050 (epoch 2.952), train_loss = 1.98709854, grad/param norm = 2.4417e-01, time/batch = 0.6378s	
1539/26050 (epoch 2.954), train_loss = 1.96190418, grad/param norm = 2.1854e-01, time/batch = 0.6466s	
1540/26050 (epoch 2.956), train_loss = 1.94894307, grad/param norm = 2.2603e-01, time/batch = 0.6465s	
1541/26050 (epoch 2.958), train_loss = 1.85645437, grad/param norm = 2.3088e-01, time/batch = 0.6395s	
1542/26050 (epoch 2.960), train_loss = 1.77007876, grad/param norm = 2.3273e-01, time/batch = 0.6409s	
1543/26050 (epoch 2.962), train_loss = 1.77661896, grad/param norm = 2.2493e-01, time/batch = 0.6371s	
1544/26050 (epoch 2.964), train_loss = 1.87435626, grad/param norm = 2.7135e-01, time/batch = 0.6377s	
1545/26050 (epoch 2.965), train_loss = 1.66327533, grad/param norm = 2.1976e-01, time/batch = 0.6386s	
1546/26050 (epoch 2.967), train_loss = 2.19444114, grad/param norm = 2.4908e-01, time/batch = 0.6485s	
1547/26050 (epoch 2.969), train_loss = 1.77930883, grad/param norm = 2.6927e-01, time/batch = 0.6827s	
1548/26050 (epoch 2.971), train_loss = 1.62289272, grad/param norm = 2.4345e-01, time/batch = 0.6701s	
1549/26050 (epoch 2.973), train_loss = 1.74882280, grad/param norm = 2.3429e-01, time/batch = 0.6493s	
1550/26050 (epoch 2.975), train_loss = 1.89732177, grad/param norm = 2.3168e-01, time/batch = 0.6384s	
1551/26050 (epoch 2.977), train_loss = 1.85179002, grad/param norm = 2.1264e-01, time/batch = 0.6537s	
1552/26050 (epoch 2.979), train_loss = 1.61842033, grad/param norm = 2.2851e-01, time/batch = 0.6415s	
1553/26050 (epoch 2.981), train_loss = 1.85806206, grad/param norm = 2.2314e-01, time/batch = 0.6426s	
1554/26050 (epoch 2.983), train_loss = 1.86821722, grad/param norm = 2.5444e-01, time/batch = 0.6533s	
1555/26050 (epoch 2.985), train_loss = 1.87427700, grad/param norm = 2.5208e-01, time/batch = 0.6564s	
1556/26050 (epoch 2.987), train_loss = 1.98120061, grad/param norm = 2.4433e-01, time/batch = 0.6779s	
1557/26050 (epoch 2.988), train_loss = 2.00388150, grad/param norm = 2.6854e-01, time/batch = 0.6600s	
1558/26050 (epoch 2.990), train_loss = 1.81924180, grad/param norm = 2.9614e-01, time/batch = 0.6545s	
1559/26050 (epoch 2.992), train_loss = 2.06880237, grad/param norm = 2.6430e-01, time/batch = 0.6418s	
1560/26050 (epoch 2.994), train_loss = 1.80677106, grad/param norm = 2.3681e-01, time/batch = 0.6471s	
1561/26050 (epoch 2.996), train_loss = 1.94997864, grad/param norm = 2.8091e-01, time/batch = 0.6446s	
1562/26050 (epoch 2.998), train_loss = 1.88815494, grad/param norm = 2.1725e-01, time/batch = 0.6394s	
1563/26050 (epoch 3.000), train_loss = 1.74199764, grad/param norm = 2.1489e-01, time/batch = 0.6392s	
1564/26050 (epoch 3.002), train_loss = 1.79501403, grad/param norm = 2.1503e-01, time/batch = 0.6420s	
1565/26050 (epoch 3.004), train_loss = 1.78421249, grad/param norm = 2.3350e-01, time/batch = 0.6392s	
1566/26050 (epoch 3.006), train_loss = 1.65949153, grad/param norm = 2.2026e-01, time/batch = 0.6411s	
1567/26050 (epoch 3.008), train_loss = 1.70231342, grad/param norm = 2.2882e-01, time/batch = 0.6414s	
1568/26050 (epoch 3.010), train_loss = 1.79512796, grad/param norm = 2.1077e-01, time/batch = 0.6395s	
1569/26050 (epoch 3.012), train_loss = 1.89723186, grad/param norm = 2.7322e-01, time/batch = 0.6401s	
1570/26050 (epoch 3.013), train_loss = 2.29976158, grad/param norm = 2.5835e-01, time/batch = 0.6375s	
1571/26050 (epoch 3.015), train_loss = 1.72307844, grad/param norm = 2.4972e-01, time/batch = 0.6427s	
1572/26050 (epoch 3.017), train_loss = 1.77844006, grad/param norm = 2.2055e-01, time/batch = 0.6408s	
1573/26050 (epoch 3.019), train_loss = 1.71333048, grad/param norm = 2.2255e-01, time/batch = 0.6384s	
1574/26050 (epoch 3.021), train_loss = 1.95637829, grad/param norm = 2.5094e-01, time/batch = 0.6396s	
1575/26050 (epoch 3.023), train_loss = 1.71038333, grad/param norm = 2.2664e-01, time/batch = 0.6391s	
1576/26050 (epoch 3.025), train_loss = 1.75635331, grad/param norm = 2.5946e-01, time/batch = 0.6407s	
1577/26050 (epoch 3.027), train_loss = 1.63314014, grad/param norm = 2.6828e-01, time/batch = 0.6647s	
1578/26050 (epoch 3.029), train_loss = 1.74752270, grad/param norm = 2.5503e-01, time/batch = 0.6818s	
1579/26050 (epoch 3.031), train_loss = 1.99610128, grad/param norm = 2.7133e-01, time/batch = 0.6444s	
1580/26050 (epoch 3.033), train_loss = 1.85868048, grad/param norm = 2.6126e-01, time/batch = 0.6391s	
1581/26050 (epoch 3.035), train_loss = 2.01144694, grad/param norm = 2.5192e-01, time/batch = 0.6394s	
1582/26050 (epoch 3.036), train_loss = 1.80826826, grad/param norm = 2.5805e-01, time/batch = 0.6394s	
1583/26050 (epoch 3.038), train_loss = 1.62069162, grad/param norm = 2.5072e-01, time/batch = 0.6387s	
1584/26050 (epoch 3.040), train_loss = 1.87383914, grad/param norm = 2.2877e-01, time/batch = 0.6470s	
1585/26050 (epoch 3.042), train_loss = 1.63092638, grad/param norm = 2.2030e-01, time/batch = 0.6411s	
1586/26050 (epoch 3.044), train_loss = 1.85905266, grad/param norm = 2.1406e-01, time/batch = 0.6410s	
1587/26050 (epoch 3.046), train_loss = 1.59994606, grad/param norm = 2.3133e-01, time/batch = 0.6396s	
1588/26050 (epoch 3.048), train_loss = 1.78278940, grad/param norm = 2.1448e-01, time/batch = 0.6394s	
1589/26050 (epoch 3.050), train_loss = 1.65317633, grad/param norm = 2.4969e-01, time/batch = 0.6384s	
1590/26050 (epoch 3.052), train_loss = 1.76993623, grad/param norm = 2.3663e-01, time/batch = 0.6385s	
1591/26050 (epoch 3.054), train_loss = 1.69280034, grad/param norm = 2.9043e-01, time/batch = 0.6410s	
1592/26050 (epoch 3.056), train_loss = 1.45056377, grad/param norm = 2.2591e-01, time/batch = 0.6416s	
1593/26050 (epoch 3.058), train_loss = 1.69562565, grad/param norm = 2.2801e-01, time/batch = 0.6829s	
1594/26050 (epoch 3.060), train_loss = 1.75176698, grad/param norm = 1.9942e-01, time/batch = 0.6584s	
1595/26050 (epoch 3.061), train_loss = 1.64949728, grad/param norm = 2.2852e-01, time/batch = 0.6412s	
1596/26050 (epoch 3.063), train_loss = 1.64553215, grad/param norm = 2.1469e-01, time/batch = 0.6393s	
1597/26050 (epoch 3.065), train_loss = 1.70448015, grad/param norm = 2.2252e-01, time/batch = 0.6380s	
1598/26050 (epoch 3.067), train_loss = 1.85929854, grad/param norm = 2.7598e-01, time/batch = 0.6385s	
1599/26050 (epoch 3.069), train_loss = 1.86780554, grad/param norm = 2.4175e-01, time/batch = 0.6408s	
1600/26050 (epoch 3.071), train_loss = 1.83749571, grad/param norm = 2.4390e-01, time/batch = 0.6394s	
1601/26050 (epoch 3.073), train_loss = 1.98084154, grad/param norm = 2.3334e-01, time/batch = 0.6443s	
1602/26050 (epoch 3.075), train_loss = 1.65813879, grad/param norm = 2.2760e-01, time/batch = 0.6569s	
1603/26050 (epoch 3.077), train_loss = 1.66355841, grad/param norm = 2.3907e-01, time/batch = 0.6485s	
1604/26050 (epoch 3.079), train_loss = 1.93076145, grad/param norm = 2.4504e-01, time/batch = 0.6389s	
1605/26050 (epoch 3.081), train_loss = 1.70147001, grad/param norm = 2.0768e-01, time/batch = 0.6403s	
1606/26050 (epoch 3.083), train_loss = 1.88357796, grad/param norm = 2.5191e-01, time/batch = 0.6397s	
1607/26050 (epoch 3.084), train_loss = 2.05549194, grad/param norm = 2.7554e-01, time/batch = 0.6394s	
1608/26050 (epoch 3.086), train_loss = 1.98411027, grad/param norm = 2.5125e-01, time/batch = 0.6424s	
1609/26050 (epoch 3.088), train_loss = 1.64621645, grad/param norm = 2.1127e-01, time/batch = 0.6411s	
1610/26050 (epoch 3.090), train_loss = 2.03017887, grad/param norm = 2.3882e-01, time/batch = 0.6425s	
1611/26050 (epoch 3.092), train_loss = 1.68968611, grad/param norm = 2.3985e-01, time/batch = 0.6433s	
1612/26050 (epoch 3.094), train_loss = 1.87768526, grad/param norm = 2.3175e-01, time/batch = 0.6415s	
1613/26050 (epoch 3.096), train_loss = 1.56692533, grad/param norm = 2.2513e-01, time/batch = 0.6828s	
1614/26050 (epoch 3.098), train_loss = 1.67212677, grad/param norm = 2.0629e-01, time/batch = 0.6501s	
1615/26050 (epoch 3.100), train_loss = 1.69486375, grad/param norm = 2.4874e-01, time/batch = 0.6395s	
1616/26050 (epoch 3.102), train_loss = 1.81994254, grad/param norm = 2.2977e-01, time/batch = 0.6481s	
1617/26050 (epoch 3.104), train_loss = 1.86997482, grad/param norm = 2.4369e-01, time/batch = 0.6451s	
1618/26050 (epoch 3.106), train_loss = 1.69542255, grad/param norm = 2.3840e-01, time/batch = 0.6414s	
1619/26050 (epoch 3.107), train_loss = 1.48475529, grad/param norm = 2.4126e-01, time/batch = 0.6422s	
1620/26050 (epoch 3.109), train_loss = 1.65821772, grad/param norm = 2.4631e-01, time/batch = 0.6396s	
1621/26050 (epoch 3.111), train_loss = 2.09256937, grad/param norm = 2.4635e-01, time/batch = 0.6401s	
1622/26050 (epoch 3.113), train_loss = 1.73235215, grad/param norm = 2.5963e-01, time/batch = 0.6404s	
1623/26050 (epoch 3.115), train_loss = 1.94458505, grad/param norm = 2.2016e-01, time/batch = 0.6388s	
1624/26050 (epoch 3.117), train_loss = 1.84923659, grad/param norm = 2.4515e-01, time/batch = 0.6392s	
1625/26050 (epoch 3.119), train_loss = 1.64975846, grad/param norm = 2.2346e-01, time/batch = 0.6408s	
1626/26050 (epoch 3.121), train_loss = 1.81818529, grad/param norm = 2.5109e-01, time/batch = 0.6427s	
1627/26050 (epoch 3.123), train_loss = 1.68778248, grad/param norm = 2.4300e-01, time/batch = 0.6422s	
1628/26050 (epoch 3.125), train_loss = 1.44672117, grad/param norm = 1.8989e-01, time/batch = 0.6627s	
1629/26050 (epoch 3.127), train_loss = 1.61713532, grad/param norm = 2.1485e-01, time/batch = 0.6790s	
1630/26050 (epoch 3.129), train_loss = 1.56112307, grad/param norm = 2.1154e-01, time/batch = 0.6395s	
1631/26050 (epoch 3.131), train_loss = 1.72657146, grad/param norm = 2.0627e-01, time/batch = 0.6410s	
1632/26050 (epoch 3.132), train_loss = 1.65683779, grad/param norm = 2.0493e-01, time/batch = 0.6399s	
1633/26050 (epoch 3.134), train_loss = 1.74085064, grad/param norm = 2.4455e-01, time/batch = 0.6398s	
1634/26050 (epoch 3.136), train_loss = 1.69620123, grad/param norm = 1.9291e-01, time/batch = 0.6394s	
1635/26050 (epoch 3.138), train_loss = 1.69080476, grad/param norm = 2.3157e-01, time/batch = 0.6383s	
1636/26050 (epoch 3.140), train_loss = 1.76936933, grad/param norm = 2.3295e-01, time/batch = 0.6399s	
1637/26050 (epoch 3.142), train_loss = 1.76278710, grad/param norm = 2.5885e-01, time/batch = 0.6402s	
1638/26050 (epoch 3.144), train_loss = 1.64009711, grad/param norm = 2.4268e-01, time/batch = 0.6499s	
1639/26050 (epoch 3.146), train_loss = 1.52816648, grad/param norm = 2.4259e-01, time/batch = 0.6704s	
1640/26050 (epoch 3.148), train_loss = 1.57914393, grad/param norm = 2.0082e-01, time/batch = 0.6767s	
1641/26050 (epoch 3.150), train_loss = 1.81516314, grad/param norm = 2.4340e-01, time/batch = 0.6786s	
1642/26050 (epoch 3.152), train_loss = 2.04238412, grad/param norm = 2.5081e-01, time/batch = 0.6780s	
1643/26050 (epoch 3.154), train_loss = 1.60976073, grad/param norm = 2.3689e-01, time/batch = 0.6786s	
1644/26050 (epoch 3.155), train_loss = 1.65043113, grad/param norm = 2.1730e-01, time/batch = 0.6845s	
1645/26050 (epoch 3.157), train_loss = 1.78068087, grad/param norm = 2.3453e-01, time/batch = 0.6511s	
1646/26050 (epoch 3.159), train_loss = 1.84995626, grad/param norm = 2.4586e-01, time/batch = 0.6414s	
1647/26050 (epoch 3.161), train_loss = 1.99884661, grad/param norm = 2.4807e-01, time/batch = 0.6479s	
1648/26050 (epoch 3.163), train_loss = 1.70363006, grad/param norm = 2.3700e-01, time/batch = 0.6427s	
1649/26050 (epoch 3.165), train_loss = 1.40935498, grad/param norm = 2.0354e-01, time/batch = 0.6409s	
1650/26050 (epoch 3.167), train_loss = 1.95690401, grad/param norm = 3.0102e-01, time/batch = 0.6420s	
1651/26050 (epoch 3.169), train_loss = 1.85189107, grad/param norm = 2.5029e-01, time/batch = 0.6497s	
1652/26050 (epoch 3.171), train_loss = 1.58489662, grad/param norm = 2.0892e-01, time/batch = 0.6413s	
1653/26050 (epoch 3.173), train_loss = 1.74135737, grad/param norm = 2.5368e-01, time/batch = 0.6415s	
1654/26050 (epoch 3.175), train_loss = 1.79690992, grad/param norm = 2.6006e-01, time/batch = 0.6679s	
1655/26050 (epoch 3.177), train_loss = 1.84265925, grad/param norm = 2.2385e-01, time/batch = 0.6793s	
1656/26050 (epoch 3.179), train_loss = 1.42641022, grad/param norm = 2.0379e-01, time/batch = 0.6576s	
1657/26050 (epoch 3.180), train_loss = 1.95053911, grad/param norm = 2.2570e-01, time/batch = 0.6526s	
1658/26050 (epoch 3.182), train_loss = 2.10841760, grad/param norm = 2.4242e-01, time/batch = 0.6404s	
1659/26050 (epoch 3.184), train_loss = 1.81187707, grad/param norm = 2.2488e-01, time/batch = 0.6416s	
1660/26050 (epoch 3.186), train_loss = 1.50588009, grad/param norm = 2.0536e-01, time/batch = 0.6396s	
1661/26050 (epoch 3.188), train_loss = 1.69856716, grad/param norm = 2.2094e-01, time/batch = 0.6406s	
1662/26050 (epoch 3.190), train_loss = 1.82407973, grad/param norm = 2.2410e-01, time/batch = 0.6460s	
1663/26050 (epoch 3.192), train_loss = 1.75123877, grad/param norm = 2.1881e-01, time/batch = 0.6424s	
1664/26050 (epoch 3.194), train_loss = 1.73666240, grad/param norm = 2.2729e-01, time/batch = 0.6406s	
1665/26050 (epoch 3.196), train_loss = 1.90323640, grad/param norm = 2.9030e-01, time/batch = 0.6397s	
1666/26050 (epoch 3.198), train_loss = 1.65520490, grad/param norm = 2.1967e-01, time/batch = 0.6385s	
1667/26050 (epoch 3.200), train_loss = 1.67351571, grad/param norm = 2.4142e-01, time/batch = 0.6377s	
1668/26050 (epoch 3.202), train_loss = 1.64395271, grad/param norm = 2.3740e-01, time/batch = 0.6410s	
1669/26050 (epoch 3.203), train_loss = 1.83603643, grad/param norm = 2.5263e-01, time/batch = 0.6541s	
1670/26050 (epoch 3.205), train_loss = 1.62407332, grad/param norm = 2.3496e-01, time/batch = 0.6827s	
1671/26050 (epoch 3.207), train_loss = 1.68846478, grad/param norm = 2.0192e-01, time/batch = 0.6543s	
1672/26050 (epoch 3.209), train_loss = 1.68908358, grad/param norm = 2.1532e-01, time/batch = 0.6419s	
1673/26050 (epoch 3.211), train_loss = 1.64423211, grad/param norm = 2.5547e-01, time/batch = 0.6377s	
1674/26050 (epoch 3.213), train_loss = 1.80432834, grad/param norm = 2.5181e-01, time/batch = 0.6427s	
1675/26050 (epoch 3.215), train_loss = 1.81869390, grad/param norm = 2.3729e-01, time/batch = 0.6404s	
1676/26050 (epoch 3.217), train_loss = 1.72854388, grad/param norm = 2.6041e-01, time/batch = 0.6398s	
1677/26050 (epoch 3.219), train_loss = 1.63974386, grad/param norm = 2.2885e-01, time/batch = 0.6407s	
1678/26050 (epoch 3.221), train_loss = 1.64118737, grad/param norm = 2.2703e-01, time/batch = 0.6374s	
1679/26050 (epoch 3.223), train_loss = 1.88337388, grad/param norm = 2.4209e-01, time/batch = 0.6393s	
1680/26050 (epoch 3.225), train_loss = 1.64674143, grad/param norm = 2.3966e-01, time/batch = 0.6390s	
1681/26050 (epoch 3.226), train_loss = 1.89768297, grad/param norm = 2.7420e-01, time/batch = 0.6384s	
1682/26050 (epoch 3.228), train_loss = 1.85381033, grad/param norm = 2.6254e-01, time/batch = 0.6384s	
1683/26050 (epoch 3.230), train_loss = 1.70607588, grad/param norm = 2.1636e-01, time/batch = 0.6374s	
1684/26050 (epoch 3.232), train_loss = 1.90256522, grad/param norm = 2.4746e-01, time/batch = 0.6374s	
1685/26050 (epoch 3.234), train_loss = 1.52804507, grad/param norm = 2.1103e-01, time/batch = 0.6738s	
1686/26050 (epoch 3.236), train_loss = 1.77255688, grad/param norm = 2.5714e-01, time/batch = 0.6698s	
1687/26050 (epoch 3.238), train_loss = 1.52182322, grad/param norm = 2.4124e-01, time/batch = 0.6490s	
1688/26050 (epoch 3.240), train_loss = 1.63938747, grad/param norm = 1.9920e-01, time/batch = 0.6424s	
1689/26050 (epoch 3.242), train_loss = 1.77403310, grad/param norm = 2.5368e-01, time/batch = 0.6395s	
1690/26050 (epoch 3.244), train_loss = 1.76445571, grad/param norm = 2.4767e-01, time/batch = 0.6374s	
1691/26050 (epoch 3.246), train_loss = 1.62589985, grad/param norm = 2.2849e-01, time/batch = 0.6396s	
1692/26050 (epoch 3.248), train_loss = 1.84396854, grad/param norm = 2.4644e-01, time/batch = 0.6386s	
1693/26050 (epoch 3.250), train_loss = 1.82107566, grad/param norm = 2.5977e-01, time/batch = 0.6403s	
1694/26050 (epoch 3.251), train_loss = 1.61130141, grad/param norm = 2.4331e-01, time/batch = 0.6411s	
1695/26050 (epoch 3.253), train_loss = 1.57376155, grad/param norm = 2.4059e-01, time/batch = 0.6405s	
1696/26050 (epoch 3.255), train_loss = 1.96817874, grad/param norm = 2.4933e-01, time/batch = 0.6381s	
1697/26050 (epoch 3.257), train_loss = 1.76375170, grad/param norm = 2.3414e-01, time/batch = 0.6375s	
1698/26050 (epoch 3.259), train_loss = 1.82539663, grad/param norm = 2.4741e-01, time/batch = 0.6382s	
1699/26050 (epoch 3.261), train_loss = 1.69237807, grad/param norm = 2.2431e-01, time/batch = 0.6476s	
1700/26050 (epoch 3.263), train_loss = 1.75789422, grad/param norm = 2.4282e-01, time/batch = 0.6604s	
1701/26050 (epoch 3.265), train_loss = 1.94529072, grad/param norm = 2.1192e-01, time/batch = 0.6851s	
1702/26050 (epoch 3.267), train_loss = 1.80422152, grad/param norm = 2.3740e-01, time/batch = 0.6457s	
1703/26050 (epoch 3.269), train_loss = 1.97491974, grad/param norm = 2.5667e-01, time/batch = 0.6395s	
1704/26050 (epoch 3.271), train_loss = 1.71388394, grad/param norm = 2.1817e-01, time/batch = 0.6447s	
1705/26050 (epoch 3.273), train_loss = 1.77399395, grad/param norm = 2.4445e-01, time/batch = 0.6420s	
1706/26050 (epoch 3.274), train_loss = 1.68952101, grad/param norm = 2.1573e-01, time/batch = 0.6376s	
1707/26050 (epoch 3.276), train_loss = 1.60888691, grad/param norm = 2.1262e-01, time/batch = 0.6393s	
1708/26050 (epoch 3.278), train_loss = 1.80524436, grad/param norm = 2.1667e-01, time/batch = 0.6399s	
1709/26050 (epoch 3.280), train_loss = 1.69387466, grad/param norm = 2.0834e-01, time/batch = 0.6423s	
1710/26050 (epoch 3.282), train_loss = 1.75254293, grad/param norm = 2.1550e-01, time/batch = 0.6406s	
1711/26050 (epoch 3.284), train_loss = 1.57420426, grad/param norm = 2.3807e-01, time/batch = 0.6679s	
1712/26050 (epoch 3.286), train_loss = 1.66941467, grad/param norm = 2.5892e-01, time/batch = 0.6654s	
1713/26050 (epoch 3.288), train_loss = 1.58225408, grad/param norm = 2.2960e-01, time/batch = 0.6413s	
1714/26050 (epoch 3.290), train_loss = 1.61868160, grad/param norm = 2.2667e-01, time/batch = 0.6406s	
1715/26050 (epoch 3.292), train_loss = 1.62633954, grad/param norm = 2.1467e-01, time/batch = 0.6422s	
1716/26050 (epoch 3.294), train_loss = 1.75182294, grad/param norm = 2.3921e-01, time/batch = 0.6573s	
1717/26050 (epoch 3.296), train_loss = 1.80672944, grad/param norm = 2.1999e-01, time/batch = 0.6522s	
1718/26050 (epoch 3.298), train_loss = 1.68932193, grad/param norm = 2.3502e-01, time/batch = 0.6578s	
1719/26050 (epoch 3.299), train_loss = 1.42906637, grad/param norm = 2.1272e-01, time/batch = 0.6580s	
1720/26050 (epoch 3.301), train_loss = 1.59962411, grad/param norm = 2.2456e-01, time/batch = 0.6553s	
1721/26050 (epoch 3.303), train_loss = 1.76100351, grad/param norm = 2.6598e-01, time/batch = 0.6568s	
1722/26050 (epoch 3.305), train_loss = 1.65744282, grad/param norm = 2.2489e-01, time/batch = 0.6543s	
1723/26050 (epoch 3.307), train_loss = 1.53173323, grad/param norm = 2.2625e-01, time/batch = 0.6515s	
1724/26050 (epoch 3.309), train_loss = 1.62230003, grad/param norm = 2.2747e-01, time/batch = 0.6527s	
1725/26050 (epoch 3.311), train_loss = 1.95843821, grad/param norm = 2.6247e-01, time/batch = 0.6588s	
1726/26050 (epoch 3.313), train_loss = 1.79140037, grad/param norm = 2.4431e-01, time/batch = 0.6648s	
1727/26050 (epoch 3.315), train_loss = 1.92897872, grad/param norm = 2.6215e-01, time/batch = 0.6844s	
1728/26050 (epoch 3.317), train_loss = 1.57991583, grad/param norm = 2.2492e-01, time/batch = 0.6570s	
1729/26050 (epoch 3.319), train_loss = 1.64880114, grad/param norm = 2.1405e-01, time/batch = 0.6516s	
1730/26050 (epoch 3.321), train_loss = 1.74795781, grad/param norm = 2.4426e-01, time/batch = 0.6547s	
1731/26050 (epoch 3.322), train_loss = 1.71693495, grad/param norm = 2.5302e-01, time/batch = 0.6552s	
1732/26050 (epoch 3.324), train_loss = 1.56549253, grad/param norm = 2.4371e-01, time/batch = 0.6652s	
1733/26050 (epoch 3.326), train_loss = 1.86199923, grad/param norm = 2.4386e-01, time/batch = 0.6644s	
1734/26050 (epoch 3.328), train_loss = 1.75541770, grad/param norm = 2.1524e-01, time/batch = 0.6653s	
1735/26050 (epoch 3.330), train_loss = 1.62836978, grad/param norm = 2.3659e-01, time/batch = 0.6635s	
1736/26050 (epoch 3.332), train_loss = 1.83882928, grad/param norm = 2.2404e-01, time/batch = 0.6549s	
1737/26050 (epoch 3.334), train_loss = 1.68635216, grad/param norm = 2.2509e-01, time/batch = 0.6419s	
1738/26050 (epoch 3.336), train_loss = 1.52718085, grad/param norm = 1.9513e-01, time/batch = 0.6410s	
1739/26050 (epoch 3.338), train_loss = 1.50853871, grad/param norm = 2.0136e-01, time/batch = 0.6382s	
1740/26050 (epoch 3.340), train_loss = 1.83021669, grad/param norm = 2.4402e-01, time/batch = 0.6406s	
1741/26050 (epoch 3.342), train_loss = 1.80454605, grad/param norm = 2.4898e-01, time/batch = 0.6550s	
1742/26050 (epoch 3.344), train_loss = 1.69003137, grad/param norm = 2.3104e-01, time/batch = 0.6833s	
1743/26050 (epoch 3.345), train_loss = 1.69783666, grad/param norm = 2.2700e-01, time/batch = 0.6526s	
1744/26050 (epoch 3.347), train_loss = 1.76576087, grad/param norm = 2.4549e-01, time/batch = 0.6529s	
1745/26050 (epoch 3.349), train_loss = 1.68440620, grad/param norm = 2.2517e-01, time/batch = 0.6423s	
1746/26050 (epoch 3.351), train_loss = 1.70592717, grad/param norm = 2.2188e-01, time/batch = 0.6399s	
1747/26050 (epoch 3.353), train_loss = 1.63691701, grad/param norm = 2.3459e-01, time/batch = 0.6395s	
1748/26050 (epoch 3.355), train_loss = 1.76819778, grad/param norm = 2.4301e-01, time/batch = 0.6465s	
1749/26050 (epoch 3.357), train_loss = 1.52045278, grad/param norm = 2.2166e-01, time/batch = 0.6409s	
1750/26050 (epoch 3.359), train_loss = 1.72130259, grad/param norm = 2.0256e-01, time/batch = 0.6476s	
1751/26050 (epoch 3.361), train_loss = 1.48879635, grad/param norm = 2.0040e-01, time/batch = 0.6458s	
1752/26050 (epoch 3.363), train_loss = 1.68077437, grad/param norm = 2.1517e-01, time/batch = 0.6422s	
1753/26050 (epoch 3.365), train_loss = 1.54377602, grad/param norm = 2.2141e-01, time/batch = 0.6484s	
1754/26050 (epoch 3.367), train_loss = 1.67696834, grad/param norm = 2.4218e-01, time/batch = 0.6496s	
1755/26050 (epoch 3.369), train_loss = 1.68376990, grad/param norm = 2.1476e-01, time/batch = 0.6507s	
1756/26050 (epoch 3.370), train_loss = 1.60392962, grad/param norm = 2.3750e-01, time/batch = 0.6448s	
1757/26050 (epoch 3.372), train_loss = 1.87840649, grad/param norm = 2.3083e-01, time/batch = 0.6392s	
1758/26050 (epoch 3.374), train_loss = 1.90531942, grad/param norm = 2.5278e-01, time/batch = 0.6456s	
1759/26050 (epoch 3.376), train_loss = 1.92617628, grad/param norm = 2.1634e-01, time/batch = 0.6527s	
1760/26050 (epoch 3.378), train_loss = 1.72000543, grad/param norm = 2.3875e-01, time/batch = 0.6511s	
1761/26050 (epoch 3.380), train_loss = 1.86034031, grad/param norm = 2.3658e-01, time/batch = 0.6574s	
1762/26050 (epoch 3.382), train_loss = 2.10101619, grad/param norm = 2.4584e-01, time/batch = 0.6431s	
1763/26050 (epoch 3.384), train_loss = 1.66682023, grad/param norm = 2.2357e-01, time/batch = 0.6406s	
1764/26050 (epoch 3.386), train_loss = 1.80743929, grad/param norm = 2.3232e-01, time/batch = 0.6486s	
1765/26050 (epoch 3.388), train_loss = 1.70767610, grad/param norm = 2.0041e-01, time/batch = 0.6396s	
1766/26050 (epoch 3.390), train_loss = 1.59492103, grad/param norm = 1.9856e-01, time/batch = 0.6391s	
1767/26050 (epoch 3.392), train_loss = 1.62710336, grad/param norm = 2.1950e-01, time/batch = 0.6414s	
1768/26050 (epoch 3.393), train_loss = 1.76533165, grad/param norm = 2.2836e-01, time/batch = 0.6803s	
1769/26050 (epoch 3.395), train_loss = 1.74333319, grad/param norm = 2.2468e-01, time/batch = 0.6569s	
1770/26050 (epoch 3.397), train_loss = 1.75569309, grad/param norm = 2.1543e-01, time/batch = 0.6391s	
1771/26050 (epoch 3.399), train_loss = 1.57156027, grad/param norm = 2.0261e-01, time/batch = 0.6415s	
1772/26050 (epoch 3.401), train_loss = 1.64340652, grad/param norm = 2.2993e-01, time/batch = 0.6413s	
1773/26050 (epoch 3.403), train_loss = 1.69401964, grad/param norm = 2.5944e-01, time/batch = 0.6392s	
1774/26050 (epoch 3.405), train_loss = 1.74697030, grad/param norm = 2.5549e-01, time/batch = 0.6439s	
1775/26050 (epoch 3.407), train_loss = 1.85870147, grad/param norm = 2.3302e-01, time/batch = 0.6501s	
1776/26050 (epoch 3.409), train_loss = 1.86667737, grad/param norm = 2.4430e-01, time/batch = 0.6405s	
1777/26050 (epoch 3.411), train_loss = 1.71827083, grad/param norm = 2.2150e-01, time/batch = 0.6405s	
1778/26050 (epoch 3.413), train_loss = 1.83489017, grad/param norm = 2.1949e-01, time/batch = 0.6464s	
1779/26050 (epoch 3.415), train_loss = 1.87348081, grad/param norm = 2.3463e-01, time/batch = 0.6543s	
1780/26050 (epoch 3.417), train_loss = 1.88913182, grad/param norm = 2.3518e-01, time/batch = 0.6616s	
1781/26050 (epoch 3.418), train_loss = 1.80793261, grad/param norm = 2.1648e-01, time/batch = 0.6614s	
1782/26050 (epoch 3.420), train_loss = 1.45691922, grad/param norm = 2.0469e-01, time/batch = 0.6551s	
1783/26050 (epoch 3.422), train_loss = 1.59408731, grad/param norm = 2.2544e-01, time/batch = 0.6562s	
1784/26050 (epoch 3.424), train_loss = 2.01004872, grad/param norm = 2.6832e-01, time/batch = 0.6591s	
1785/26050 (epoch 3.426), train_loss = 1.94523149, grad/param norm = 3.0519e-01, time/batch = 0.6498s	
1786/26050 (epoch 3.428), train_loss = 1.60293526, grad/param norm = 1.9352e-01, time/batch = 0.6593s	
1787/26050 (epoch 3.430), train_loss = 1.71325497, grad/param norm = 2.3265e-01, time/batch = 0.6587s	
1788/26050 (epoch 3.432), train_loss = 1.70068894, grad/param norm = 2.3363e-01, time/batch = 0.6575s	
1789/26050 (epoch 3.434), train_loss = 1.81000811, grad/param norm = 2.2648e-01, time/batch = 0.6578s	
1790/26050 (epoch 3.436), train_loss = 1.90520215, grad/param norm = 2.1978e-01, time/batch = 0.6580s	
1791/26050 (epoch 3.438), train_loss = 1.61615878, grad/param norm = 2.2871e-01, time/batch = 0.6496s	
1792/26050 (epoch 3.440), train_loss = 1.75542226, grad/param norm = 2.2496e-01, time/batch = 0.6427s	
1793/26050 (epoch 3.441), train_loss = 1.66951031, grad/param norm = 2.5046e-01, time/batch = 0.6419s	
1794/26050 (epoch 3.443), train_loss = 1.52205163, grad/param norm = 1.8444e-01, time/batch = 0.6494s	
1795/26050 (epoch 3.445), train_loss = 1.58882425, grad/param norm = 2.2062e-01, time/batch = 0.6470s	
1796/26050 (epoch 3.447), train_loss = 1.94552357, grad/param norm = 2.1315e-01, time/batch = 0.6423s	
1797/26050 (epoch 3.449), train_loss = 1.60692101, grad/param norm = 2.2616e-01, time/batch = 0.6421s	
1798/26050 (epoch 3.451), train_loss = 1.71512073, grad/param norm = 2.2778e-01, time/batch = 0.6427s	
1799/26050 (epoch 3.453), train_loss = 1.52721935, grad/param norm = 2.0340e-01, time/batch = 0.6453s	
1800/26050 (epoch 3.455), train_loss = 1.68014593, grad/param norm = 2.0652e-01, time/batch = 0.6409s	
1801/26050 (epoch 3.457), train_loss = 1.77532622, grad/param norm = 2.5032e-01, time/batch = 0.6419s	
1802/26050 (epoch 3.459), train_loss = 1.87911636, grad/param norm = 2.8821e-01, time/batch = 0.6430s	
1803/26050 (epoch 3.461), train_loss = 1.75683707, grad/param norm = 2.3650e-01, time/batch = 0.6799s	
1804/26050 (epoch 3.463), train_loss = 1.61768125, grad/param norm = 2.0276e-01, time/batch = 0.6664s	
1805/26050 (epoch 3.464), train_loss = 1.81992541, grad/param norm = 2.3108e-01, time/batch = 0.6391s	
1806/26050 (epoch 3.466), train_loss = 1.83063373, grad/param norm = 2.0777e-01, time/batch = 0.6402s	
1807/26050 (epoch 3.468), train_loss = 1.82236542, grad/param norm = 2.1117e-01, time/batch = 0.6397s	
1808/26050 (epoch 3.470), train_loss = 1.91925368, grad/param norm = 2.3395e-01, time/batch = 0.6451s	
1809/26050 (epoch 3.472), train_loss = 2.00909254, grad/param norm = 2.5426e-01, time/batch = 0.6412s	
1810/26050 (epoch 3.474), train_loss = 2.01795617, grad/param norm = 2.4116e-01, time/batch = 0.6559s	
1811/26050 (epoch 3.476), train_loss = 1.85539237, grad/param norm = 2.1603e-01, time/batch = 0.6501s	
1812/26050 (epoch 3.478), train_loss = 1.64459365, grad/param norm = 2.0064e-01, time/batch = 0.6419s	
1813/26050 (epoch 3.480), train_loss = 1.76467839, grad/param norm = 2.0707e-01, time/batch = 0.6411s	
1814/26050 (epoch 3.482), train_loss = 1.68359196, grad/param norm = 2.2196e-01, time/batch = 0.6469s	
1815/26050 (epoch 3.484), train_loss = 1.54622834, grad/param norm = 2.1239e-01, time/batch = 0.6409s	
1816/26050 (epoch 3.486), train_loss = 1.88845440, grad/param norm = 2.3038e-01, time/batch = 0.6452s	
1817/26050 (epoch 3.488), train_loss = 2.06735786, grad/param norm = 2.3426e-01, time/batch = 0.6407s	
1818/26050 (epoch 3.489), train_loss = 1.95512440, grad/param norm = 2.3673e-01, time/batch = 0.6598s	
1819/26050 (epoch 3.491), train_loss = 1.65665401, grad/param norm = 2.2533e-01, time/batch = 0.6825s	
1820/26050 (epoch 3.493), train_loss = 1.62682152, grad/param norm = 2.0326e-01, time/batch = 0.6390s	
1821/26050 (epoch 3.495), train_loss = 1.74520031, grad/param norm = 2.3939e-01, time/batch = 0.6401s	
1822/26050 (epoch 3.497), train_loss = 1.63223220, grad/param norm = 2.1650e-01, time/batch = 0.6390s	
1823/26050 (epoch 3.499), train_loss = 1.64049637, grad/param norm = 2.2117e-01, time/batch = 0.6437s	
1824/26050 (epoch 3.501), train_loss = 1.67389723, grad/param norm = 2.1424e-01, time/batch = 0.6507s	
1825/26050 (epoch 3.503), train_loss = 1.69301473, grad/param norm = 2.1526e-01, time/batch = 0.6451s	
1826/26050 (epoch 3.505), train_loss = 1.80350840, grad/param norm = 2.1586e-01, time/batch = 0.6547s	
1827/26050 (epoch 3.507), train_loss = 1.84626731, grad/param norm = 2.3785e-01, time/batch = 0.6565s	
1828/26050 (epoch 3.509), train_loss = 1.98755212, grad/param norm = 2.9492e-01, time/batch = 0.6571s	
1829/26050 (epoch 3.511), train_loss = 1.62601766, grad/param norm = 2.1576e-01, time/batch = 0.6407s	
1830/26050 (epoch 3.512), train_loss = 1.79368998, grad/param norm = 2.3213e-01, time/batch = 0.6510s	
1831/26050 (epoch 3.514), train_loss = 1.78876051, grad/param norm = 2.2343e-01, time/batch = 0.6476s	
1832/26050 (epoch 3.516), train_loss = 1.81909995, grad/param norm = 2.1764e-01, time/batch = 0.6424s	
1833/26050 (epoch 3.518), train_loss = 1.78731060, grad/param norm = 2.3409e-01, time/batch = 0.6483s	
1834/26050 (epoch 3.520), train_loss = 1.75935596, grad/param norm = 2.2326e-01, time/batch = 0.6830s	
1835/26050 (epoch 3.522), train_loss = 1.67274791, grad/param norm = 2.2560e-01, time/batch = 0.6394s	
1836/26050 (epoch 3.524), train_loss = 2.02376945, grad/param norm = 2.3921e-01, time/batch = 0.6465s	
1837/26050 (epoch 3.526), train_loss = 1.82920654, grad/param norm = 2.5007e-01, time/batch = 0.6406s	
1838/26050 (epoch 3.528), train_loss = 1.84472231, grad/param norm = 2.5502e-01, time/batch = 0.6380s	
1839/26050 (epoch 3.530), train_loss = 1.72101227, grad/param norm = 2.1663e-01, time/batch = 0.6401s	
1840/26050 (epoch 3.532), train_loss = 1.78314209, grad/param norm = 2.1832e-01, time/batch = 0.6390s	
1841/26050 (epoch 3.534), train_loss = 1.80013239, grad/param norm = 2.2811e-01, time/batch = 0.6431s	
1842/26050 (epoch 3.536), train_loss = 1.66633286, grad/param norm = 2.4883e-01, time/batch = 0.6425s	
1843/26050 (epoch 3.537), train_loss = 1.82493529, grad/param norm = 2.0756e-01, time/batch = 0.6417s	
1844/26050 (epoch 3.539), train_loss = 1.69375272, grad/param norm = 2.2275e-01, time/batch = 0.6384s	
1845/26050 (epoch 3.541), train_loss = 1.89621197, grad/param norm = 2.4228e-01, time/batch = 0.6372s	
1846/26050 (epoch 3.543), train_loss = 1.54968935, grad/param norm = 2.1800e-01, time/batch = 0.6381s	
1847/26050 (epoch 3.545), train_loss = 1.76621217, grad/param norm = 2.3072e-01, time/batch = 0.6384s	
1848/26050 (epoch 3.547), train_loss = 1.80930219, grad/param norm = 2.3592e-01, time/batch = 0.6385s	
1849/26050 (epoch 3.549), train_loss = 1.61372506, grad/param norm = 2.1448e-01, time/batch = 0.6431s	
1850/26050 (epoch 3.551), train_loss = 1.79467775, grad/param norm = 2.3948e-01, time/batch = 0.6372s	
1851/26050 (epoch 3.553), train_loss = 1.69145611, grad/param norm = 2.3141e-01, time/batch = 0.6378s	
1852/26050 (epoch 3.555), train_loss = 1.68169918, grad/param norm = 2.2098e-01, time/batch = 0.6393s	
1853/26050 (epoch 3.557), train_loss = 1.81311088, grad/param norm = 2.2161e-01, time/batch = 0.6379s	
1854/26050 (epoch 3.559), train_loss = 1.75335414, grad/param norm = 2.5179e-01, time/batch = 0.6833s	
1855/26050 (epoch 3.560), train_loss = 1.71907663, grad/param norm = 2.0846e-01, time/batch = 0.6587s	
1856/26050 (epoch 3.562), train_loss = 1.75947393, grad/param norm = 2.2392e-01, time/batch = 0.6401s	
1857/26050 (epoch 3.564), train_loss = 1.92671950, grad/param norm = 2.5234e-01, time/batch = 0.6531s	
1858/26050 (epoch 3.566), train_loss = 1.64543172, grad/param norm = 2.2827e-01, time/batch = 0.6428s	
1859/26050 (epoch 3.568), train_loss = 1.76717537, grad/param norm = 2.0221e-01, time/batch = 0.6386s	
1860/26050 (epoch 3.570), train_loss = 1.82990395, grad/param norm = 2.3876e-01, time/batch = 0.6422s	
1861/26050 (epoch 3.572), train_loss = 1.79643333, grad/param norm = 2.2514e-01, time/batch = 0.6419s	
1862/26050 (epoch 3.574), train_loss = 1.87983401, grad/param norm = 2.5332e-01, time/batch = 0.6493s	
1863/26050 (epoch 3.576), train_loss = 1.81590032, grad/param norm = 2.3006e-01, time/batch = 0.6429s	
1864/26050 (epoch 3.578), train_loss = 1.78929873, grad/param norm = 2.2123e-01, time/batch = 0.6439s	
1865/26050 (epoch 3.580), train_loss = 1.62866559, grad/param norm = 2.1288e-01, time/batch = 0.6391s	
1866/26050 (epoch 3.582), train_loss = 1.83138398, grad/param norm = 2.2775e-01, time/batch = 0.6410s	
1867/26050 (epoch 3.583), train_loss = 1.79102850, grad/param norm = 2.2140e-01, time/batch = 0.6417s	
1868/26050 (epoch 3.585), train_loss = 1.61515814, grad/param norm = 2.2181e-01, time/batch = 0.6407s	
1869/26050 (epoch 3.587), train_loss = 1.81194959, grad/param norm = 2.3633e-01, time/batch = 0.6400s	
1870/26050 (epoch 3.589), train_loss = 1.78442592, grad/param norm = 2.4044e-01, time/batch = 0.6409s	
1871/26050 (epoch 3.591), train_loss = 1.79689319, grad/param norm = 2.2004e-01, time/batch = 0.6460s	
1872/26050 (epoch 3.593), train_loss = 1.63109468, grad/param norm = 2.2599e-01, time/batch = 0.6411s	
1873/26050 (epoch 3.595), train_loss = 1.87782241, grad/param norm = 2.6337e-01, time/batch = 0.6442s	
1874/26050 (epoch 3.597), train_loss = 1.76949759, grad/param norm = 2.4401e-01, time/batch = 0.6432s	
1875/26050 (epoch 3.599), train_loss = 1.58265740, grad/param norm = 2.0239e-01, time/batch = 0.6461s	
1876/26050 (epoch 3.601), train_loss = 1.92776113, grad/param norm = 2.3173e-01, time/batch = 0.6467s	
1877/26050 (epoch 3.603), train_loss = 1.82944761, grad/param norm = 2.2188e-01, time/batch = 0.6483s	
1878/26050 (epoch 3.605), train_loss = 1.64851840, grad/param norm = 1.8997e-01, time/batch = 0.6497s	
1879/26050 (epoch 3.607), train_loss = 1.83547609, grad/param norm = 2.3067e-01, time/batch = 0.6448s	
1880/26050 (epoch 3.608), train_loss = 1.71072585, grad/param norm = 2.0495e-01, time/batch = 0.6409s	
1881/26050 (epoch 3.610), train_loss = 1.71729716, grad/param norm = 2.4464e-01, time/batch = 0.6411s	
1882/26050 (epoch 3.612), train_loss = 1.69487606, grad/param norm = 2.3209e-01, time/batch = 0.6409s	
1883/26050 (epoch 3.614), train_loss = 1.77350046, grad/param norm = 2.4184e-01, time/batch = 0.6411s	
1884/26050 (epoch 3.616), train_loss = 2.07387410, grad/param norm = 2.3708e-01, time/batch = 0.6568s	
1885/26050 (epoch 3.618), train_loss = 1.62755656, grad/param norm = 2.3116e-01, time/batch = 0.6411s	
1886/26050 (epoch 3.620), train_loss = 1.81640086, grad/param norm = 2.4301e-01, time/batch = 0.6408s	
1887/26050 (epoch 3.622), train_loss = 1.44956159, grad/param norm = 2.0135e-01, time/batch = 0.6444s	
1888/26050 (epoch 3.624), train_loss = 1.63238510, grad/param norm = 2.1190e-01, time/batch = 0.6412s	
1889/26050 (epoch 3.626), train_loss = 1.73816535, grad/param norm = 2.5213e-01, time/batch = 0.6409s	
1890/26050 (epoch 3.628), train_loss = 1.75148674, grad/param norm = 2.3966e-01, time/batch = 0.6399s	
1891/26050 (epoch 3.630), train_loss = 1.86004940, grad/param norm = 2.1164e-01, time/batch = 0.6437s	
1892/26050 (epoch 3.631), train_loss = 1.81459580, grad/param norm = 2.1914e-01, time/batch = 0.6417s	
1893/26050 (epoch 3.633), train_loss = 1.56831328, grad/param norm = 1.9778e-01, time/batch = 0.6407s	
1894/26050 (epoch 3.635), train_loss = 1.60436044, grad/param norm = 2.1270e-01, time/batch = 0.6453s	
1895/26050 (epoch 3.637), train_loss = 1.62178233, grad/param norm = 2.1878e-01, time/batch = 0.6424s	
1896/26050 (epoch 3.639), train_loss = 1.78827161, grad/param norm = 2.1075e-01, time/batch = 0.6390s	
1897/26050 (epoch 3.641), train_loss = 1.63738496, grad/param norm = 1.9253e-01, time/batch = 0.6404s	
1898/26050 (epoch 3.643), train_loss = 1.63051840, grad/param norm = 1.9906e-01, time/batch = 0.6406s	
1899/26050 (epoch 3.645), train_loss = 1.85013630, grad/param norm = 2.2843e-01, time/batch = 0.6447s	
1900/26050 (epoch 3.647), train_loss = 1.61048466, grad/param norm = 2.1742e-01, time/batch = 0.6676s	
1901/26050 (epoch 3.649), train_loss = 1.75871677, grad/param norm = 2.2890e-01, time/batch = 0.6758s	
1902/26050 (epoch 3.651), train_loss = 1.75367456, grad/param norm = 2.2705e-01, time/batch = 0.6416s	
1903/26050 (epoch 3.653), train_loss = 1.65121060, grad/param norm = 2.2215e-01, time/batch = 0.6460s	
1904/26050 (epoch 3.655), train_loss = 1.64286154, grad/param norm = 2.2441e-01, time/batch = 0.6415s	
1905/26050 (epoch 3.656), train_loss = 1.63766711, grad/param norm = 2.1006e-01, time/batch = 0.6395s	
1906/26050 (epoch 3.658), train_loss = 1.87633918, grad/param norm = 2.3337e-01, time/batch = 0.6401s	
1907/26050 (epoch 3.660), train_loss = 1.58139817, grad/param norm = 2.5003e-01, time/batch = 0.6393s	
1908/26050 (epoch 3.662), train_loss = 1.57664083, grad/param norm = 2.1940e-01, time/batch = 0.6395s	
1909/26050 (epoch 3.664), train_loss = 1.63984619, grad/param norm = 2.2882e-01, time/batch = 0.6423s	
1910/26050 (epoch 3.666), train_loss = 1.76394148, grad/param norm = 2.3935e-01, time/batch = 0.6412s	
1911/26050 (epoch 3.668), train_loss = 1.46306159, grad/param norm = 1.9963e-01, time/batch = 0.6462s	
1912/26050 (epoch 3.670), train_loss = 1.89515111, grad/param norm = 2.6003e-01, time/batch = 0.6535s	
1913/26050 (epoch 3.672), train_loss = 1.62058509, grad/param norm = 2.1728e-01, time/batch = 0.6475s	
1914/26050 (epoch 3.674), train_loss = 1.57314132, grad/param norm = 2.0426e-01, time/batch = 0.6435s	
1915/26050 (epoch 3.676), train_loss = 1.71509690, grad/param norm = 2.2262e-01, time/batch = 0.6746s	
1916/26050 (epoch 3.678), train_loss = 1.90404336, grad/param norm = 2.3786e-01, time/batch = 0.6858s	
1917/26050 (epoch 3.679), train_loss = 1.80720463, grad/param norm = 2.4515e-01, time/batch = 0.6784s	
1918/26050 (epoch 3.681), train_loss = 1.73961131, grad/param norm = 2.2264e-01, time/batch = 0.6761s	
1919/26050 (epoch 3.683), train_loss = 1.63844617, grad/param norm = 2.5440e-01, time/batch = 0.6755s	
1920/26050 (epoch 3.685), train_loss = 1.63946120, grad/param norm = 2.2040e-01, time/batch = 0.6754s	
1921/26050 (epoch 3.687), train_loss = 1.48575835, grad/param norm = 2.0117e-01, time/batch = 0.6707s	
1922/26050 (epoch 3.689), train_loss = 1.69324977, grad/param norm = 2.0044e-01, time/batch = 0.6549s	
1923/26050 (epoch 3.691), train_loss = 1.44567981, grad/param norm = 2.1518e-01, time/batch = 0.6517s	
1924/26050 (epoch 3.693), train_loss = 1.61434202, grad/param norm = 2.3574e-01, time/batch = 0.6598s	
1925/26050 (epoch 3.695), train_loss = 1.75441219, grad/param norm = 2.2523e-01, time/batch = 0.6718s	
1926/26050 (epoch 3.697), train_loss = 1.55359129, grad/param norm = 2.2672e-01, time/batch = 0.6615s	
1927/26050 (epoch 3.699), train_loss = 1.74999739, grad/param norm = 2.3555e-01, time/batch = 0.6575s	
1928/26050 (epoch 3.701), train_loss = 1.53155617, grad/param norm = 1.9705e-01, time/batch = 0.6550s	
1929/26050 (epoch 3.702), train_loss = 1.95639506, grad/param norm = 2.2075e-01, time/batch = 0.6597s	
1930/26050 (epoch 3.704), train_loss = 1.69373318, grad/param norm = 2.1675e-01, time/batch = 0.6538s	
1931/26050 (epoch 3.706), train_loss = 1.83483114, grad/param norm = 2.3580e-01, time/batch = 0.6826s	
1932/26050 (epoch 3.708), train_loss = 1.73896713, grad/param norm = 2.1579e-01, time/batch = 0.6474s	
1933/26050 (epoch 3.710), train_loss = 1.81499767, grad/param norm = 2.0674e-01, time/batch = 0.6403s	
1934/26050 (epoch 3.712), train_loss = 1.89337861, grad/param norm = 2.2021e-01, time/batch = 0.6396s	
1935/26050 (epoch 3.714), train_loss = 1.59218270, grad/param norm = 2.2673e-01, time/batch = 0.6418s	
1936/26050 (epoch 3.716), train_loss = 1.95486943, grad/param norm = 2.5949e-01, time/batch = 0.6435s	
1937/26050 (epoch 3.718), train_loss = 1.79281248, grad/param norm = 2.3740e-01, time/batch = 0.6393s	
1938/26050 (epoch 3.720), train_loss = 1.60008025, grad/param norm = 2.2938e-01, time/batch = 0.6399s	
1939/26050 (epoch 3.722), train_loss = 1.61839742, grad/param norm = 2.5741e-01, time/batch = 0.6396s	
1940/26050 (epoch 3.724), train_loss = 1.56856401, grad/param norm = 2.2839e-01, time/batch = 0.6399s	
1941/26050 (epoch 3.726), train_loss = 1.81539457, grad/param norm = 2.2501e-01, time/batch = 0.6403s	
1942/26050 (epoch 3.727), train_loss = 1.73956987, grad/param norm = 2.1421e-01, time/batch = 0.6419s	
1943/26050 (epoch 3.729), train_loss = 1.83174135, grad/param norm = 2.4456e-01, time/batch = 0.6396s	
1944/26050 (epoch 3.731), train_loss = 1.67262230, grad/param norm = 2.0324e-01, time/batch = 0.6409s	
1945/26050 (epoch 3.733), train_loss = 1.76962985, grad/param norm = 2.6603e-01, time/batch = 0.6393s	
1946/26050 (epoch 3.735), train_loss = 1.90437511, grad/param norm = 2.2769e-01, time/batch = 0.6455s	
1947/26050 (epoch 3.737), train_loss = 1.77601806, grad/param norm = 2.2979e-01, time/batch = 0.6414s	
1948/26050 (epoch 3.739), train_loss = 1.80519568, grad/param norm = 2.3531e-01, time/batch = 0.6456s	
1949/26050 (epoch 3.741), train_loss = 1.58979218, grad/param norm = 2.0622e-01, time/batch = 0.6401s	
1950/26050 (epoch 3.743), train_loss = 1.84436927, grad/param norm = 2.5349e-01, time/batch = 0.6398s	
1951/26050 (epoch 3.745), train_loss = 1.56862295, grad/param norm = 2.0312e-01, time/batch = 0.6396s	
1952/26050 (epoch 3.747), train_loss = 1.65863227, grad/param norm = 2.0801e-01, time/batch = 0.6409s	
1953/26050 (epoch 3.749), train_loss = 1.77221993, grad/param norm = 2.5427e-01, time/batch = 0.6420s	
1954/26050 (epoch 3.750), train_loss = 1.64297449, grad/param norm = 2.0308e-01, time/batch = 0.6391s	
1955/26050 (epoch 3.752), train_loss = 1.81999613, grad/param norm = 2.3227e-01, time/batch = 0.6395s	
1956/26050 (epoch 3.754), train_loss = 1.58927924, grad/param norm = 2.0352e-01, time/batch = 0.6385s	
1957/26050 (epoch 3.756), train_loss = 1.83443288, grad/param norm = 2.2437e-01, time/batch = 0.6373s	
1958/26050 (epoch 3.758), train_loss = 1.75699353, grad/param norm = 2.3904e-01, time/batch = 0.6375s	
1959/26050 (epoch 3.760), train_loss = 1.72360164, grad/param norm = 2.1313e-01, time/batch = 0.6388s	
1960/26050 (epoch 3.762), train_loss = 1.67647757, grad/param norm = 2.3159e-01, time/batch = 0.6386s	
1961/26050 (epoch 3.764), train_loss = 1.80554420, grad/param norm = 2.2641e-01, time/batch = 0.6532s	
1962/26050 (epoch 3.766), train_loss = 1.78777518, grad/param norm = 2.2219e-01, time/batch = 0.6794s	
1963/26050 (epoch 3.768), train_loss = 1.65810387, grad/param norm = 2.0484e-01, time/batch = 0.6438s	
1964/26050 (epoch 3.770), train_loss = 1.70936562, grad/param norm = 2.2309e-01, time/batch = 0.6410s	
1965/26050 (epoch 3.772), train_loss = 1.72628516, grad/param norm = 2.4511e-01, time/batch = 0.6381s	
1966/26050 (epoch 3.774), train_loss = 1.64042395, grad/param norm = 2.2355e-01, time/batch = 0.6392s	
1967/26050 (epoch 3.775), train_loss = 1.47181845, grad/param norm = 2.1035e-01, time/batch = 0.6381s	
1968/26050 (epoch 3.777), train_loss = 1.60112177, grad/param norm = 2.1505e-01, time/batch = 0.6388s	
1969/26050 (epoch 3.779), train_loss = 1.71843341, grad/param norm = 2.4551e-01, time/batch = 0.6401s	
1970/26050 (epoch 3.781), train_loss = 1.64594823, grad/param norm = 2.3191e-01, time/batch = 0.6393s	
1971/26050 (epoch 3.783), train_loss = 1.63132293, grad/param norm = 1.9072e-01, time/batch = 0.6394s	
1972/26050 (epoch 3.785), train_loss = 1.66871653, grad/param norm = 2.4599e-01, time/batch = 0.6479s	
1973/26050 (epoch 3.787), train_loss = 1.66040662, grad/param norm = 2.2696e-01, time/batch = 0.6462s	
1974/26050 (epoch 3.789), train_loss = 1.77141218, grad/param norm = 2.4003e-01, time/batch = 0.6381s	
1975/26050 (epoch 3.791), train_loss = 1.74354158, grad/param norm = 2.1289e-01, time/batch = 0.6386s	
1976/26050 (epoch 3.793), train_loss = 1.67951181, grad/param norm = 2.3720e-01, time/batch = 0.6429s	
1977/26050 (epoch 3.795), train_loss = 1.62771786, grad/param norm = 2.2949e-01, time/batch = 0.6755s	
1978/26050 (epoch 3.797), train_loss = 1.59925629, grad/param norm = 2.0540e-01, time/batch = 0.6641s	
1979/26050 (epoch 3.798), train_loss = 1.56677553, grad/param norm = 2.1193e-01, time/batch = 0.6380s	
1980/26050 (epoch 3.800), train_loss = 1.55552419, grad/param norm = 2.0533e-01, time/batch = 0.6389s	
1981/26050 (epoch 3.802), train_loss = 1.73267958, grad/param norm = 2.1813e-01, time/batch = 0.6415s	
1982/26050 (epoch 3.804), train_loss = 1.72661099, grad/param norm = 2.1790e-01, time/batch = 0.6393s	
1983/26050 (epoch 3.806), train_loss = 1.87390951, grad/param norm = 2.4112e-01, time/batch = 0.6411s	
1984/26050 (epoch 3.808), train_loss = 1.61558392, grad/param norm = 2.1627e-01, time/batch = 0.6405s	
1985/26050 (epoch 3.810), train_loss = 1.60637635, grad/param norm = 2.3377e-01, time/batch = 0.6457s	
1986/26050 (epoch 3.812), train_loss = 1.54698380, grad/param norm = 2.2061e-01, time/batch = 0.6413s	
1987/26050 (epoch 3.814), train_loss = 1.62581407, grad/param norm = 2.3647e-01, time/batch = 0.6398s	
1988/26050 (epoch 3.816), train_loss = 1.74738985, grad/param norm = 2.2262e-01, time/batch = 0.6379s	
1989/26050 (epoch 3.818), train_loss = 1.84764602, grad/param norm = 2.6018e-01, time/batch = 0.6386s	
1990/26050 (epoch 3.820), train_loss = 1.75041844, grad/param norm = 2.3173e-01, time/batch = 0.6373s	
1991/26050 (epoch 3.821), train_loss = 1.85649173, grad/param norm = 2.5266e-01, time/batch = 0.6391s	
1992/26050 (epoch 3.823), train_loss = 1.92941342, grad/param norm = 2.4428e-01, time/batch = 0.6585s	
1993/26050 (epoch 3.825), train_loss = 1.67107885, grad/param norm = 2.3238e-01, time/batch = 0.6811s	
1994/26050 (epoch 3.827), train_loss = 1.78368260, grad/param norm = 2.8432e-01, time/batch = 0.6445s	
1995/26050 (epoch 3.829), train_loss = 1.75106660, grad/param norm = 2.0900e-01, time/batch = 0.6384s	
1996/26050 (epoch 3.831), train_loss = 1.82327300, grad/param norm = 2.0714e-01, time/batch = 0.6395s	
1997/26050 (epoch 3.833), train_loss = 1.91150438, grad/param norm = 2.6337e-01, time/batch = 0.6382s	
1998/26050 (epoch 3.835), train_loss = 1.95237547, grad/param norm = 2.1077e-01, time/batch = 0.6403s	
1999/26050 (epoch 3.837), train_loss = 1.62917487, grad/param norm = 2.1643e-01, time/batch = 0.6372s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch3.84_1.8126.t7	
2000/26050 (epoch 3.839), train_loss = 1.84457445, grad/param norm = 2.0585e-01, time/batch = 0.6406s	
2001/26050 (epoch 3.841), train_loss = 1.87652673, grad/param norm = 2.2730e-01, time/batch = 0.6857s	
2002/26050 (epoch 3.843), train_loss = 1.77121074, grad/param norm = 2.1191e-01, time/batch = 0.6506s	
2003/26050 (epoch 3.845), train_loss = 1.62776236, grad/param norm = 2.1735e-01, time/batch = 0.6587s	
2004/26050 (epoch 3.846), train_loss = 1.83412644, grad/param norm = 2.3097e-01, time/batch = 0.6448s	
2005/26050 (epoch 3.848), train_loss = 1.64255940, grad/param norm = 1.9963e-01, time/batch = 0.6434s	
2006/26050 (epoch 3.850), train_loss = 1.65750117, grad/param norm = 2.0123e-01, time/batch = 0.6479s	
2007/26050 (epoch 3.852), train_loss = 1.68327703, grad/param norm = 2.2367e-01, time/batch = 0.6430s	
2008/26050 (epoch 3.854), train_loss = 1.72330863, grad/param norm = 2.1463e-01, time/batch = 0.6469s	
2009/26050 (epoch 3.856), train_loss = 1.60929199, grad/param norm = 2.0650e-01, time/batch = 0.6477s	
2010/26050 (epoch 3.858), train_loss = 1.53025540, grad/param norm = 2.3139e-01, time/batch = 0.6460s	
2011/26050 (epoch 3.860), train_loss = 1.73950752, grad/param norm = 2.5391e-01, time/batch = 0.6787s	
2012/26050 (epoch 3.862), train_loss = 1.70768370, grad/param norm = 2.4348e-01, time/batch = 0.6629s	
2013/26050 (epoch 3.864), train_loss = 1.61195551, grad/param norm = 2.2971e-01, time/batch = 0.6386s	
2014/26050 (epoch 3.866), train_loss = 1.58326289, grad/param norm = 2.1200e-01, time/batch = 0.6418s	
2015/26050 (epoch 3.868), train_loss = 1.85997725, grad/param norm = 2.3853e-01, time/batch = 0.6398s	
2016/26050 (epoch 3.869), train_loss = 1.52293895, grad/param norm = 2.1060e-01, time/batch = 0.6383s	
2017/26050 (epoch 3.871), train_loss = 1.46713050, grad/param norm = 2.0488e-01, time/batch = 0.6448s	
2018/26050 (epoch 3.873), train_loss = 1.64017328, grad/param norm = 2.1386e-01, time/batch = 0.6440s	
2019/26050 (epoch 3.875), train_loss = 1.68528167, grad/param norm = 2.3868e-01, time/batch = 0.6418s	
2020/26050 (epoch 3.877), train_loss = 1.49666778, grad/param norm = 2.1650e-01, time/batch = 0.6406s	
2021/26050 (epoch 3.879), train_loss = 1.63287242, grad/param norm = 2.0465e-01, time/batch = 0.6448s	
2022/26050 (epoch 3.881), train_loss = 1.90530918, grad/param norm = 2.1851e-01, time/batch = 0.6468s	
2023/26050 (epoch 3.883), train_loss = 1.74027230, grad/param norm = 2.0956e-01, time/batch = 0.6572s	
2024/26050 (epoch 3.885), train_loss = 1.44970140, grad/param norm = 1.9859e-01, time/batch = 0.6450s	
2025/26050 (epoch 3.887), train_loss = 1.70849494, grad/param norm = 2.1612e-01, time/batch = 0.6401s	
2026/26050 (epoch 3.889), train_loss = 1.59164222, grad/param norm = 1.9769e-01, time/batch = 0.6388s	
2027/26050 (epoch 3.891), train_loss = 1.43816473, grad/param norm = 2.1682e-01, time/batch = 0.6380s	
2028/26050 (epoch 3.893), train_loss = 1.42705381, grad/param norm = 1.8447e-01, time/batch = 0.6384s	
2029/26050 (epoch 3.894), train_loss = 1.54359529, grad/param norm = 1.8859e-01, time/batch = 0.6393s	
2030/26050 (epoch 3.896), train_loss = 1.76490372, grad/param norm = 2.0880e-01, time/batch = 0.6378s	
2031/26050 (epoch 3.898), train_loss = 1.63014517, grad/param norm = 2.1408e-01, time/batch = 0.6759s	
2032/26050 (epoch 3.900), train_loss = 1.94051277, grad/param norm = 2.5286e-01, time/batch = 0.6658s	
2033/26050 (epoch 3.902), train_loss = 1.71750106, grad/param norm = 2.0988e-01, time/batch = 0.6424s	
2034/26050 (epoch 3.904), train_loss = 1.67665071, grad/param norm = 2.2094e-01, time/batch = 0.6397s	
2035/26050 (epoch 3.906), train_loss = 1.68234289, grad/param norm = 2.1208e-01, time/batch = 0.6429s	
2036/26050 (epoch 3.908), train_loss = 1.67254215, grad/param norm = 2.2108e-01, time/batch = 0.6411s	
2037/26050 (epoch 3.910), train_loss = 1.59849489, grad/param norm = 2.0805e-01, time/batch = 0.6410s	
2038/26050 (epoch 3.912), train_loss = 1.97289407, grad/param norm = 2.4268e-01, time/batch = 0.6391s	
2039/26050 (epoch 3.914), train_loss = 2.07870128, grad/param norm = 2.2872e-01, time/batch = 0.6420s	
2040/26050 (epoch 3.916), train_loss = 1.86118321, grad/param norm = 2.3084e-01, time/batch = 0.6435s	
2041/26050 (epoch 3.917), train_loss = 1.67980300, grad/param norm = 2.1307e-01, time/batch = 0.6408s	
2042/26050 (epoch 3.919), train_loss = 1.77577158, grad/param norm = 2.1591e-01, time/batch = 0.6396s	
2043/26050 (epoch 3.921), train_loss = 1.53957194, grad/param norm = 2.1253e-01, time/batch = 0.6393s	
2044/26050 (epoch 3.923), train_loss = 1.62482001, grad/param norm = 2.4187e-01, time/batch = 0.6386s	
2045/26050 (epoch 3.925), train_loss = 1.56436353, grad/param norm = 2.1096e-01, time/batch = 0.6388s	
2046/26050 (epoch 3.927), train_loss = 1.56084851, grad/param norm = 1.8593e-01, time/batch = 0.6553s	
2047/26050 (epoch 3.929), train_loss = 1.59147930, grad/param norm = 2.2169e-01, time/batch = 0.6811s	
2048/26050 (epoch 3.931), train_loss = 2.00195536, grad/param norm = 2.7087e-01, time/batch = 0.6432s	
2049/26050 (epoch 3.933), train_loss = 1.68978636, grad/param norm = 2.3289e-01, time/batch = 0.6473s	
2050/26050 (epoch 3.935), train_loss = 1.52062807, grad/param norm = 2.0683e-01, time/batch = 0.6383s	
2051/26050 (epoch 3.937), train_loss = 1.63348188, grad/param norm = 2.2169e-01, time/batch = 0.6427s	
2052/26050 (epoch 3.939), train_loss = 1.56096239, grad/param norm = 2.2214e-01, time/batch = 0.6381s	
2053/26050 (epoch 3.940), train_loss = 1.74237845, grad/param norm = 2.1280e-01, time/batch = 0.6385s	
2054/26050 (epoch 3.942), train_loss = 1.73897083, grad/param norm = 2.3521e-01, time/batch = 0.6395s	
2055/26050 (epoch 3.944), train_loss = 1.62843303, grad/param norm = 2.3132e-01, time/batch = 0.6419s	
2056/26050 (epoch 3.946), train_loss = 1.84808102, grad/param norm = 2.2425e-01, time/batch = 0.6400s	
2057/26050 (epoch 3.948), train_loss = 1.45652667, grad/param norm = 2.5407e-01, time/batch = 0.6385s	
2058/26050 (epoch 3.950), train_loss = 1.61238502, grad/param norm = 2.2837e-01, time/batch = 0.6374s	
2059/26050 (epoch 3.952), train_loss = 1.86210415, grad/param norm = 2.3269e-01, time/batch = 0.6376s	
2060/26050 (epoch 3.954), train_loss = 1.81071384, grad/param norm = 2.0560e-01, time/batch = 0.6391s	
2061/26050 (epoch 3.956), train_loss = 1.82885732, grad/param norm = 2.2479e-01, time/batch = 0.6387s	
2062/26050 (epoch 3.958), train_loss = 1.70539225, grad/param norm = 2.0874e-01, time/batch = 0.6792s	
2063/26050 (epoch 3.960), train_loss = 1.61490220, grad/param norm = 2.0630e-01, time/batch = 0.6822s	
2064/26050 (epoch 3.962), train_loss = 1.61456666, grad/param norm = 2.0578e-01, time/batch = 0.6827s	
2065/26050 (epoch 3.964), train_loss = 1.68157676, grad/param norm = 2.2213e-01, time/batch = 0.6409s	
2066/26050 (epoch 3.965), train_loss = 1.52210644, grad/param norm = 1.9540e-01, time/batch = 0.6451s	
2067/26050 (epoch 3.967), train_loss = 2.04571973, grad/param norm = 2.3989e-01, time/batch = 0.6393s	
2068/26050 (epoch 3.969), train_loss = 1.63773892, grad/param norm = 2.3560e-01, time/batch = 0.6407s	
2069/26050 (epoch 3.971), train_loss = 1.47938282, grad/param norm = 2.0020e-01, time/batch = 0.6469s	
2070/26050 (epoch 3.973), train_loss = 1.62289312, grad/param norm = 2.4137e-01, time/batch = 0.6455s	
2071/26050 (epoch 3.975), train_loss = 1.76616254, grad/param norm = 2.1097e-01, time/batch = 0.6428s	
2072/26050 (epoch 3.977), train_loss = 1.70885411, grad/param norm = 2.0053e-01, time/batch = 0.6452s	
2073/26050 (epoch 3.979), train_loss = 1.50248075, grad/param norm = 2.0674e-01, time/batch = 0.6465s	
2074/26050 (epoch 3.981), train_loss = 1.72880949, grad/param norm = 1.9769e-01, time/batch = 0.6430s	
2075/26050 (epoch 3.983), train_loss = 1.74753778, grad/param norm = 2.2735e-01, time/batch = 0.6423s	
2076/26050 (epoch 3.985), train_loss = 1.74796293, grad/param norm = 2.3004e-01, time/batch = 0.6434s	
2077/26050 (epoch 3.987), train_loss = 1.85601667, grad/param norm = 2.2613e-01, time/batch = 0.6392s	
2078/26050 (epoch 3.988), train_loss = 1.85408024, grad/param norm = 2.3906e-01, time/batch = 0.6391s	
2079/26050 (epoch 3.990), train_loss = 1.65794319, grad/param norm = 2.5027e-01, time/batch = 0.6426s	
2080/26050 (epoch 3.992), train_loss = 1.91739439, grad/param norm = 2.5136e-01, time/batch = 0.6394s	
2081/26050 (epoch 3.994), train_loss = 1.65799495, grad/param norm = 2.2421e-01, time/batch = 0.6411s	
2082/26050 (epoch 3.996), train_loss = 1.78673653, grad/param norm = 2.8186e-01, time/batch = 0.6821s	
2083/26050 (epoch 3.998), train_loss = 1.75785988, grad/param norm = 2.1105e-01, time/batch = 0.6605s	
2084/26050 (epoch 4.000), train_loss = 1.63497556, grad/param norm = 2.0239e-01, time/batch = 0.6390s	
2085/26050 (epoch 4.002), train_loss = 1.69543461, grad/param norm = 2.0132e-01, time/batch = 0.6407s	
2086/26050 (epoch 4.004), train_loss = 1.65328839, grad/param norm = 2.2250e-01, time/batch = 0.6405s	
2087/26050 (epoch 4.006), train_loss = 1.55693340, grad/param norm = 2.0580e-01, time/batch = 0.6405s	
2088/26050 (epoch 4.008), train_loss = 1.59627721, grad/param norm = 2.0409e-01, time/batch = 0.6397s	
2089/26050 (epoch 4.010), train_loss = 1.65058504, grad/param norm = 1.8897e-01, time/batch = 0.6401s	
2090/26050 (epoch 4.012), train_loss = 1.75053271, grad/param norm = 2.3434e-01, time/batch = 0.6433s	
2091/26050 (epoch 4.013), train_loss = 2.16007068, grad/param norm = 2.2644e-01, time/batch = 0.6420s	
2092/26050 (epoch 4.015), train_loss = 1.55938490, grad/param norm = 2.1957e-01, time/batch = 0.6405s	
2093/26050 (epoch 4.017), train_loss = 1.66211812, grad/param norm = 2.1226e-01, time/batch = 0.6409s	
2094/26050 (epoch 4.019), train_loss = 1.54138389, grad/param norm = 1.9947e-01, time/batch = 0.6598s	
2095/26050 (epoch 4.021), train_loss = 1.84757533, grad/param norm = 2.4324e-01, time/batch = 0.6492s	
2096/26050 (epoch 4.023), train_loss = 1.57718037, grad/param norm = 2.1561e-01, time/batch = 0.6596s	
2097/26050 (epoch 4.025), train_loss = 1.61345472, grad/param norm = 2.3428e-01, time/batch = 0.6693s	
2098/26050 (epoch 4.027), train_loss = 1.44655886, grad/param norm = 1.9926e-01, time/batch = 0.6651s	
2099/26050 (epoch 4.029), train_loss = 1.59361981, grad/param norm = 2.0004e-01, time/batch = 0.6409s	
2100/26050 (epoch 4.031), train_loss = 1.87011594, grad/param norm = 2.4172e-01, time/batch = 0.6411s	
2101/26050 (epoch 4.033), train_loss = 1.71825580, grad/param norm = 2.4623e-01, time/batch = 0.6419s	
2102/26050 (epoch 4.035), train_loss = 1.87252104, grad/param norm = 2.2205e-01, time/batch = 0.6419s	
2103/26050 (epoch 4.036), train_loss = 1.66327866, grad/param norm = 2.3023e-01, time/batch = 0.6416s	
2104/26050 (epoch 4.038), train_loss = 1.47706237, grad/param norm = 2.3015e-01, time/batch = 0.6402s	
2105/26050 (epoch 4.040), train_loss = 1.74448561, grad/param norm = 2.3257e-01, time/batch = 0.6398s	
2106/26050 (epoch 4.042), train_loss = 1.50821540, grad/param norm = 2.0015e-01, time/batch = 0.6412s	
2107/26050 (epoch 4.044), train_loss = 1.72921007, grad/param norm = 2.0155e-01, time/batch = 0.6396s	
2108/26050 (epoch 4.046), train_loss = 1.47172062, grad/param norm = 2.0902e-01, time/batch = 0.6399s	
2109/26050 (epoch 4.048), train_loss = 1.66911049, grad/param norm = 2.0550e-01, time/batch = 0.6397s	
2110/26050 (epoch 4.050), train_loss = 1.54065737, grad/param norm = 2.2387e-01, time/batch = 0.6484s	
2111/26050 (epoch 4.052), train_loss = 1.65632523, grad/param norm = 2.2126e-01, time/batch = 0.6440s	
2112/26050 (epoch 4.054), train_loss = 1.55313896, grad/param norm = 2.5475e-01, time/batch = 0.6481s	
2113/26050 (epoch 4.056), train_loss = 1.32056379, grad/param norm = 2.0030e-01, time/batch = 0.6825s	
2114/26050 (epoch 4.058), train_loss = 1.55229415, grad/param norm = 2.0266e-01, time/batch = 0.6539s	
2115/26050 (epoch 4.060), train_loss = 1.62207578, grad/param norm = 1.8861e-01, time/batch = 0.6396s	
2116/26050 (epoch 4.061), train_loss = 1.51937027, grad/param norm = 2.0539e-01, time/batch = 0.6399s	
2117/26050 (epoch 4.063), train_loss = 1.52851470, grad/param norm = 1.9102e-01, time/batch = 0.6423s	
2118/26050 (epoch 4.065), train_loss = 1.52123641, grad/param norm = 2.0728e-01, time/batch = 0.6420s	
2119/26050 (epoch 4.067), train_loss = 1.74674317, grad/param norm = 2.5153e-01, time/batch = 0.6410s	
2120/26050 (epoch 4.069), train_loss = 1.73810107, grad/param norm = 2.2235e-01, time/batch = 0.6419s	
2121/26050 (epoch 4.071), train_loss = 1.72074437, grad/param norm = 2.3163e-01, time/batch = 0.6415s	
2122/26050 (epoch 4.073), train_loss = 1.87449647, grad/param norm = 2.1599e-01, time/batch = 0.6475s	
2123/26050 (epoch 4.075), train_loss = 1.52340399, grad/param norm = 2.0384e-01, time/batch = 0.6429s	
2124/26050 (epoch 4.077), train_loss = 1.54640628, grad/param norm = 2.2649e-01, time/batch = 0.6398s	
2125/26050 (epoch 4.079), train_loss = 1.79659534, grad/param norm = 2.1610e-01, time/batch = 0.6391s	
2126/26050 (epoch 4.081), train_loss = 1.56748768, grad/param norm = 1.9597e-01, time/batch = 0.6420s	
2127/26050 (epoch 4.083), train_loss = 1.75096802, grad/param norm = 2.3117e-01, time/batch = 0.6390s	
2128/26050 (epoch 4.084), train_loss = 1.91984935, grad/param norm = 2.5236e-01, time/batch = 0.6391s	
2129/26050 (epoch 4.086), train_loss = 1.83511477, grad/param norm = 2.4315e-01, time/batch = 0.6443s	
2130/26050 (epoch 4.088), train_loss = 1.50274512, grad/param norm = 1.8735e-01, time/batch = 0.6570s	
2131/26050 (epoch 4.090), train_loss = 1.88726439, grad/param norm = 2.2475e-01, time/batch = 0.6473s	
2132/26050 (epoch 4.092), train_loss = 1.55947194, grad/param norm = 2.2028e-01, time/batch = 0.6451s	
2133/26050 (epoch 4.094), train_loss = 1.73182292, grad/param norm = 2.1184e-01, time/batch = 0.6603s	
2134/26050 (epoch 4.096), train_loss = 1.46192712, grad/param norm = 2.0160e-01, time/batch = 0.6556s	
2135/26050 (epoch 4.098), train_loss = 1.55846664, grad/param norm = 1.9780e-01, time/batch = 0.6390s	
2136/26050 (epoch 4.100), train_loss = 1.57691796, grad/param norm = 2.4181e-01, time/batch = 0.6383s	
2137/26050 (epoch 4.102), train_loss = 1.70769496, grad/param norm = 2.0997e-01, time/batch = 0.6383s	
2138/26050 (epoch 4.104), train_loss = 1.75072063, grad/param norm = 2.2622e-01, time/batch = 0.6389s	
2139/26050 (epoch 4.106), train_loss = 1.56945774, grad/param norm = 2.0731e-01, time/batch = 0.6545s	
2140/26050 (epoch 4.107), train_loss = 1.35539462, grad/param norm = 2.0891e-01, time/batch = 0.6639s	
2141/26050 (epoch 4.109), train_loss = 1.53563621, grad/param norm = 2.0575e-01, time/batch = 0.6593s	
2142/26050 (epoch 4.111), train_loss = 1.94730348, grad/param norm = 2.4683e-01, time/batch = 0.6582s	
2143/26050 (epoch 4.113), train_loss = 1.56946551, grad/param norm = 2.3002e-01, time/batch = 0.6564s	
2144/26050 (epoch 4.115), train_loss = 1.80731505, grad/param norm = 2.1173e-01, time/batch = 0.6572s	
2145/26050 (epoch 4.117), train_loss = 1.71388048, grad/param norm = 2.2796e-01, time/batch = 0.6522s	
2146/26050 (epoch 4.119), train_loss = 1.48248137, grad/param norm = 2.0615e-01, time/batch = 0.6605s	
2147/26050 (epoch 4.121), train_loss = 1.68064159, grad/param norm = 2.2481e-01, time/batch = 0.6523s	
2148/26050 (epoch 4.123), train_loss = 1.57645723, grad/param norm = 2.2260e-01, time/batch = 0.6584s	
2149/26050 (epoch 4.125), train_loss = 1.36284025, grad/param norm = 1.8090e-01, time/batch = 0.6564s	
2150/26050 (epoch 4.127), train_loss = 1.45883714, grad/param norm = 2.0599e-01, time/batch = 0.6579s	
2151/26050 (epoch 4.129), train_loss = 1.42994978, grad/param norm = 1.9476e-01, time/batch = 0.6447s	
2152/26050 (epoch 4.131), train_loss = 1.62698938, grad/param norm = 2.1026e-01, time/batch = 0.6405s	
2153/26050 (epoch 4.132), train_loss = 1.54822029, grad/param norm = 1.9186e-01, time/batch = 0.6388s	
2154/26050 (epoch 4.134), train_loss = 1.60500097, grad/param norm = 2.2255e-01, time/batch = 0.6410s	
2155/26050 (epoch 4.136), train_loss = 1.58371198, grad/param norm = 1.9275e-01, time/batch = 0.6382s	
2156/26050 (epoch 4.138), train_loss = 1.55618482, grad/param norm = 2.2510e-01, time/batch = 0.6451s	
2157/26050 (epoch 4.140), train_loss = 1.62413841, grad/param norm = 2.1204e-01, time/batch = 0.6383s	
2158/26050 (epoch 4.142), train_loss = 1.63692684, grad/param norm = 2.1657e-01, time/batch = 0.6380s	
2159/26050 (epoch 4.144), train_loss = 1.49782548, grad/param norm = 2.1759e-01, time/batch = 0.6386s	
2160/26050 (epoch 4.146), train_loss = 1.37940908, grad/param norm = 2.0098e-01, time/batch = 0.6385s	
2161/26050 (epoch 4.148), train_loss = 1.42644120, grad/param norm = 1.8229e-01, time/batch = 0.6389s	
2162/26050 (epoch 4.150), train_loss = 1.65385327, grad/param norm = 2.1869e-01, time/batch = 0.6437s	
2163/26050 (epoch 4.152), train_loss = 1.93576854, grad/param norm = 2.3901e-01, time/batch = 0.6399s	
2164/26050 (epoch 4.154), train_loss = 1.47987419, grad/param norm = 2.1532e-01, time/batch = 0.6384s	
2165/26050 (epoch 4.155), train_loss = 1.49671017, grad/param norm = 1.9700e-01, time/batch = 0.6383s	
2166/26050 (epoch 4.157), train_loss = 1.65265218, grad/param norm = 2.2239e-01, time/batch = 0.6381s	
2167/26050 (epoch 4.159), train_loss = 1.68238698, grad/param norm = 2.2946e-01, time/batch = 0.6391s	
2168/26050 (epoch 4.161), train_loss = 1.86711473, grad/param norm = 2.3167e-01, time/batch = 0.6384s	
2169/26050 (epoch 4.163), train_loss = 1.52999439, grad/param norm = 1.9604e-01, time/batch = 0.6420s	
2170/26050 (epoch 4.165), train_loss = 1.29133431, grad/param norm = 1.8277e-01, time/batch = 0.6525s	
2171/26050 (epoch 4.167), train_loss = 1.80460771, grad/param norm = 2.6851e-01, time/batch = 0.6435s	
2172/26050 (epoch 4.169), train_loss = 1.70902372, grad/param norm = 2.3323e-01, time/batch = 0.6463s	
2173/26050 (epoch 4.171), train_loss = 1.42456960, grad/param norm = 1.8281e-01, time/batch = 0.6374s	
2174/26050 (epoch 4.173), train_loss = 1.60048460, grad/param norm = 2.2591e-01, time/batch = 0.6621s	
2175/26050 (epoch 4.175), train_loss = 1.64618395, grad/param norm = 2.3294e-01, time/batch = 0.6774s	
2176/26050 (epoch 4.177), train_loss = 1.71326662, grad/param norm = 2.1368e-01, time/batch = 0.6425s	
2177/26050 (epoch 4.179), train_loss = 1.30915255, grad/param norm = 1.8874e-01, time/batch = 0.6422s	
2178/26050 (epoch 4.180), train_loss = 1.84854017, grad/param norm = 2.0739e-01, time/batch = 0.6407s	
2179/26050 (epoch 4.182), train_loss = 1.96281066, grad/param norm = 2.2127e-01, time/batch = 0.6389s	
2180/26050 (epoch 4.184), train_loss = 1.68707023, grad/param norm = 2.1496e-01, time/batch = 0.6389s	
2181/26050 (epoch 4.186), train_loss = 1.37171608, grad/param norm = 1.9530e-01, time/batch = 0.6396s	
2182/26050 (epoch 4.188), train_loss = 1.60103579, grad/param norm = 2.0092e-01, time/batch = 0.6394s	
2183/26050 (epoch 4.190), train_loss = 1.70771525, grad/param norm = 2.0937e-01, time/batch = 0.6379s	
2184/26050 (epoch 4.192), train_loss = 1.62887125, grad/param norm = 2.1640e-01, time/batch = 0.6370s	
2185/26050 (epoch 4.194), train_loss = 1.63735948, grad/param norm = 2.1244e-01, time/batch = 0.6377s	
2186/26050 (epoch 4.196), train_loss = 1.75500903, grad/param norm = 2.3601e-01, time/batch = 0.6517s	
2187/26050 (epoch 4.198), train_loss = 1.53147109, grad/param norm = 2.0600e-01, time/batch = 0.6561s	
2188/26050 (epoch 4.200), train_loss = 1.55409960, grad/param norm = 2.2284e-01, time/batch = 0.6389s	
2189/26050 (epoch 4.202), train_loss = 1.52561644, grad/param norm = 2.1366e-01, time/batch = 0.6570s	
2190/26050 (epoch 4.203), train_loss = 1.69955551, grad/param norm = 2.2396e-01, time/batch = 0.6824s	
2191/26050 (epoch 4.205), train_loss = 1.49240627, grad/param norm = 2.0835e-01, time/batch = 0.6567s	
2192/26050 (epoch 4.207), train_loss = 1.56868455, grad/param norm = 1.8520e-01, time/batch = 0.6450s	
2193/26050 (epoch 4.209), train_loss = 1.56749342, grad/param norm = 2.0195e-01, time/batch = 0.6406s	
2194/26050 (epoch 4.211), train_loss = 1.49409634, grad/param norm = 2.2885e-01, time/batch = 0.6586s	
2195/26050 (epoch 4.213), train_loss = 1.67083102, grad/param norm = 2.2127e-01, time/batch = 0.6693s	
2196/26050 (epoch 4.215), train_loss = 1.69493323, grad/param norm = 2.3050e-01, time/batch = 0.6558s	
2197/26050 (epoch 4.217), train_loss = 1.58040440, grad/param norm = 2.2597e-01, time/batch = 0.6419s	
2198/26050 (epoch 4.219), train_loss = 1.53268502, grad/param norm = 2.1707e-01, time/batch = 0.6413s	
2199/26050 (epoch 4.221), train_loss = 1.50871727, grad/param norm = 2.1169e-01, time/batch = 0.6421s	
2200/26050 (epoch 4.223), train_loss = 1.75872172, grad/param norm = 2.3586e-01, time/batch = 0.6400s	
2201/26050 (epoch 4.225), train_loss = 1.52091881, grad/param norm = 2.2329e-01, time/batch = 0.6403s	
2202/26050 (epoch 4.226), train_loss = 1.79699994, grad/param norm = 2.5841e-01, time/batch = 0.6423s	
2203/26050 (epoch 4.228), train_loss = 1.74877817, grad/param norm = 2.4349e-01, time/batch = 0.6449s	
2204/26050 (epoch 4.230), train_loss = 1.60959288, grad/param norm = 2.0596e-01, time/batch = 0.6417s	
2205/26050 (epoch 4.232), train_loss = 1.79559947, grad/param norm = 2.3330e-01, time/batch = 0.6747s	
2206/26050 (epoch 4.234), train_loss = 1.40131523, grad/param norm = 1.9630e-01, time/batch = 0.6692s	
2207/26050 (epoch 4.236), train_loss = 1.64156842, grad/param norm = 2.1889e-01, time/batch = 0.6381s	
2208/26050 (epoch 4.238), train_loss = 1.38402454, grad/param norm = 1.9949e-01, time/batch = 0.6398s	
2209/26050 (epoch 4.240), train_loss = 1.53233919, grad/param norm = 1.9168e-01, time/batch = 0.6400s	
2210/26050 (epoch 4.242), train_loss = 1.61737020, grad/param norm = 2.1906e-01, time/batch = 0.6391s	
2211/26050 (epoch 4.244), train_loss = 1.65595757, grad/param norm = 2.3071e-01, time/batch = 0.6410s	
2212/26050 (epoch 4.246), train_loss = 1.51743011, grad/param norm = 2.0657e-01, time/batch = 0.6476s	
2213/26050 (epoch 4.248), train_loss = 1.72405185, grad/param norm = 2.3435e-01, time/batch = 0.6522s	
2214/26050 (epoch 4.250), train_loss = 1.70594401, grad/param norm = 2.2492e-01, time/batch = 0.6526s	
2215/26050 (epoch 4.251), train_loss = 1.49763933, grad/param norm = 2.2414e-01, time/batch = 0.6513s	
2216/26050 (epoch 4.253), train_loss = 1.42404319, grad/param norm = 2.1074e-01, time/batch = 0.6389s	
2217/26050 (epoch 4.255), train_loss = 1.85482386, grad/param norm = 2.2201e-01, time/batch = 0.6472s	
2218/26050 (epoch 4.257), train_loss = 1.62999435, grad/param norm = 2.0493e-01, time/batch = 0.6404s	
2219/26050 (epoch 4.259), train_loss = 1.72541081, grad/param norm = 2.2508e-01, time/batch = 0.6384s	
2220/26050 (epoch 4.261), train_loss = 1.55302045, grad/param norm = 2.1135e-01, time/batch = 0.6558s	
2221/26050 (epoch 4.263), train_loss = 1.61930887, grad/param norm = 2.1413e-01, time/batch = 0.6687s	
2222/26050 (epoch 4.265), train_loss = 1.82110397, grad/param norm = 2.0139e-01, time/batch = 0.6395s	
2223/26050 (epoch 4.267), train_loss = 1.67307136, grad/param norm = 2.2568e-01, time/batch = 0.6460s	
2224/26050 (epoch 4.269), train_loss = 1.83277341, grad/param norm = 2.4088e-01, time/batch = 0.6413s	
2225/26050 (epoch 4.271), train_loss = 1.59860566, grad/param norm = 2.0237e-01, time/batch = 0.6380s	
2226/26050 (epoch 4.273), train_loss = 1.62050715, grad/param norm = 2.2708e-01, time/batch = 0.6401s	
2227/26050 (epoch 4.274), train_loss = 1.55220645, grad/param norm = 2.0097e-01, time/batch = 0.6384s	
2228/26050 (epoch 4.276), train_loss = 1.49087624, grad/param norm = 1.9512e-01, time/batch = 0.6384s	
2229/26050 (epoch 4.278), train_loss = 1.69602459, grad/param norm = 2.0533e-01, time/batch = 0.6474s	
2230/26050 (epoch 4.280), train_loss = 1.59987583, grad/param norm = 2.0131e-01, time/batch = 0.6437s	
2231/26050 (epoch 4.282), train_loss = 1.63802694, grad/param norm = 2.0851e-01, time/batch = 0.6420s	
2232/26050 (epoch 4.284), train_loss = 1.44860972, grad/param norm = 2.1089e-01, time/batch = 0.6410s	
2233/26050 (epoch 4.286), train_loss = 1.56710108, grad/param norm = 2.3307e-01, time/batch = 0.6488s	
2234/26050 (epoch 4.288), train_loss = 1.45633217, grad/param norm = 2.0412e-01, time/batch = 0.6403s	
2235/26050 (epoch 4.290), train_loss = 1.52529519, grad/param norm = 2.0868e-01, time/batch = 0.6410s	
2236/26050 (epoch 4.292), train_loss = 1.50942673, grad/param norm = 1.9384e-01, time/batch = 0.6415s	
2237/26050 (epoch 4.294), train_loss = 1.64096566, grad/param norm = 2.3291e-01, time/batch = 0.6392s	
2238/26050 (epoch 4.296), train_loss = 1.70070697, grad/param norm = 2.1098e-01, time/batch = 0.6389s	
2239/26050 (epoch 4.298), train_loss = 1.57400854, grad/param norm = 2.0443e-01, time/batch = 0.6471s	
2240/26050 (epoch 4.299), train_loss = 1.32403041, grad/param norm = 1.8084e-01, time/batch = 0.6408s	
2241/26050 (epoch 4.301), train_loss = 1.49419083, grad/param norm = 2.0740e-01, time/batch = 0.6406s	
2242/26050 (epoch 4.303), train_loss = 1.63848714, grad/param norm = 2.3660e-01, time/batch = 0.6407s	
2243/26050 (epoch 4.305), train_loss = 1.51387687, grad/param norm = 2.0953e-01, time/batch = 0.6398s	
2244/26050 (epoch 4.307), train_loss = 1.42234848, grad/param norm = 2.0533e-01, time/batch = 0.6387s	
2245/26050 (epoch 4.309), train_loss = 1.50863349, grad/param norm = 2.1410e-01, time/batch = 0.6402s	
2246/26050 (epoch 4.311), train_loss = 1.83395470, grad/param norm = 2.3804e-01, time/batch = 0.6417s	
2247/26050 (epoch 4.313), train_loss = 1.66676271, grad/param norm = 2.3104e-01, time/batch = 0.6446s	
2248/26050 (epoch 4.315), train_loss = 1.79833546, grad/param norm = 2.4134e-01, time/batch = 0.6425s	
2249/26050 (epoch 4.317), train_loss = 1.47977824, grad/param norm = 2.0134e-01, time/batch = 0.6564s	
2250/26050 (epoch 4.319), train_loss = 1.52995308, grad/param norm = 1.9563e-01, time/batch = 0.6407s	
2251/26050 (epoch 4.321), train_loss = 1.62223674, grad/param norm = 2.1434e-01, time/batch = 0.6681s	
2252/26050 (epoch 4.322), train_loss = 1.60917173, grad/param norm = 2.1063e-01, time/batch = 0.6806s	
2253/26050 (epoch 4.324), train_loss = 1.43037910, grad/param norm = 2.0823e-01, time/batch = 0.6382s	
2254/26050 (epoch 4.326), train_loss = 1.74750040, grad/param norm = 2.2886e-01, time/batch = 0.6399s	
2255/26050 (epoch 4.328), train_loss = 1.63149313, grad/param norm = 2.0420e-01, time/batch = 0.6396s	
2256/26050 (epoch 4.330), train_loss = 1.51094986, grad/param norm = 2.2388e-01, time/batch = 0.6390s	
2257/26050 (epoch 4.332), train_loss = 1.69663861, grad/param norm = 2.0981e-01, time/batch = 0.6398s	
2258/26050 (epoch 4.334), train_loss = 1.57031974, grad/param norm = 2.2135e-01, time/batch = 0.6380s	
2259/26050 (epoch 4.336), train_loss = 1.41652492, grad/param norm = 1.7576e-01, time/batch = 0.6387s	
2260/26050 (epoch 4.338), train_loss = 1.40210086, grad/param norm = 1.9466e-01, time/batch = 0.6380s	
2261/26050 (epoch 4.340), train_loss = 1.70544874, grad/param norm = 2.2840e-01, time/batch = 0.6417s	
2262/26050 (epoch 4.342), train_loss = 1.71732011, grad/param norm = 2.2209e-01, time/batch = 0.6548s	
2263/26050 (epoch 4.344), train_loss = 1.57578674, grad/param norm = 2.1537e-01, time/batch = 0.6629s	
2264/26050 (epoch 4.345), train_loss = 1.59728284, grad/param norm = 2.3556e-01, time/batch = 0.6459s	
2265/26050 (epoch 4.347), train_loss = 1.67570277, grad/param norm = 2.5058e-01, time/batch = 0.6556s	
2266/26050 (epoch 4.349), train_loss = 1.58977936, grad/param norm = 2.1006e-01, time/batch = 0.6547s	
2267/26050 (epoch 4.351), train_loss = 1.62167496, grad/param norm = 2.1766e-01, time/batch = 0.6505s	
2268/26050 (epoch 4.353), train_loss = 1.50979735, grad/param norm = 2.2328e-01, time/batch = 0.6482s	
2269/26050 (epoch 4.355), train_loss = 1.67490204, grad/param norm = 2.2512e-01, time/batch = 0.6516s	
2270/26050 (epoch 4.357), train_loss = 1.41674635, grad/param norm = 1.9278e-01, time/batch = 0.6492s	
2271/26050 (epoch 4.359), train_loss = 1.63842725, grad/param norm = 1.9227e-01, time/batch = 0.6571s	
2272/26050 (epoch 4.361), train_loss = 1.41087874, grad/param norm = 1.9015e-01, time/batch = 0.6496s	
2273/26050 (epoch 4.363), train_loss = 1.55996106, grad/param norm = 1.9717e-01, time/batch = 0.6509s	
2274/26050 (epoch 4.365), train_loss = 1.45275096, grad/param norm = 1.9811e-01, time/batch = 0.6508s	
2275/26050 (epoch 4.367), train_loss = 1.57323150, grad/param norm = 2.1808e-01, time/batch = 0.6577s	
2276/26050 (epoch 4.369), train_loss = 1.56224159, grad/param norm = 1.9852e-01, time/batch = 0.6476s	
2277/26050 (epoch 4.370), train_loss = 1.47772748, grad/param norm = 2.0884e-01, time/batch = 0.6564s	
2278/26050 (epoch 4.372), train_loss = 1.76165159, grad/param norm = 2.2203e-01, time/batch = 0.6557s	
2279/26050 (epoch 4.374), train_loss = 1.79821369, grad/param norm = 2.3185e-01, time/batch = 0.6681s	
2280/26050 (epoch 4.376), train_loss = 1.82620607, grad/param norm = 1.9661e-01, time/batch = 0.6753s	
2281/26050 (epoch 4.378), train_loss = 1.57892315, grad/param norm = 2.0393e-01, time/batch = 0.6745s	
2282/26050 (epoch 4.380), train_loss = 1.76866719, grad/param norm = 2.1509e-01, time/batch = 0.6887s	
2283/26050 (epoch 4.382), train_loss = 1.98367187, grad/param norm = 2.2912e-01, time/batch = 0.6680s	
2284/26050 (epoch 4.384), train_loss = 1.55180343, grad/param norm = 2.1039e-01, time/batch = 0.6412s	
2285/26050 (epoch 4.386), train_loss = 1.68130076, grad/param norm = 2.0831e-01, time/batch = 0.6492s	
2286/26050 (epoch 4.388), train_loss = 1.63271372, grad/param norm = 2.0180e-01, time/batch = 0.6418s	
2287/26050 (epoch 4.390), train_loss = 1.46933656, grad/param norm = 1.8449e-01, time/batch = 0.6438s	
2288/26050 (epoch 4.392), train_loss = 1.49720031, grad/param norm = 2.0346e-01, time/batch = 0.6442s	
2289/26050 (epoch 4.393), train_loss = 1.65432671, grad/param norm = 2.1290e-01, time/batch = 0.6389s	
2290/26050 (epoch 4.395), train_loss = 1.64852389, grad/param norm = 2.1917e-01, time/batch = 0.6373s	
2291/26050 (epoch 4.397), train_loss = 1.65128907, grad/param norm = 2.0535e-01, time/batch = 0.6414s	
2292/26050 (epoch 4.399), train_loss = 1.45584449, grad/param norm = 1.8842e-01, time/batch = 0.6400s	
2293/26050 (epoch 4.401), train_loss = 1.53590278, grad/param norm = 2.1540e-01, time/batch = 0.6396s	
2294/26050 (epoch 4.403), train_loss = 1.57960567, grad/param norm = 2.2300e-01, time/batch = 0.6539s	
2295/26050 (epoch 4.405), train_loss = 1.61401040, grad/param norm = 2.2337e-01, time/batch = 0.6489s	
2296/26050 (epoch 4.407), train_loss = 1.75065979, grad/param norm = 2.1110e-01, time/batch = 0.6368s	
2297/26050 (epoch 4.409), train_loss = 1.76947108, grad/param norm = 2.2617e-01, time/batch = 0.6614s	
2298/26050 (epoch 4.411), train_loss = 1.60321627, grad/param norm = 2.0303e-01, time/batch = 0.6780s	
2299/26050 (epoch 4.413), train_loss = 1.73951974, grad/param norm = 2.0322e-01, time/batch = 0.6486s	
2300/26050 (epoch 4.415), train_loss = 1.75124924, grad/param norm = 2.2254e-01, time/batch = 0.6412s	
2301/26050 (epoch 4.417), train_loss = 1.77675954, grad/param norm = 2.2033e-01, time/batch = 0.6421s	
2302/26050 (epoch 4.418), train_loss = 1.68550023, grad/param norm = 2.0964e-01, time/batch = 0.6403s	
2303/26050 (epoch 4.420), train_loss = 1.35186207, grad/param norm = 1.8846e-01, time/batch = 0.6424s	
2304/26050 (epoch 4.422), train_loss = 1.46262952, grad/param norm = 2.2028e-01, time/batch = 0.6387s	
2305/26050 (epoch 4.424), train_loss = 1.90056002, grad/param norm = 2.5412e-01, time/batch = 0.6448s	
2306/26050 (epoch 4.426), train_loss = 1.82861437, grad/param norm = 2.6546e-01, time/batch = 0.6496s	
2307/26050 (epoch 4.428), train_loss = 1.49158057, grad/param norm = 1.9015e-01, time/batch = 0.6395s	
2308/26050 (epoch 4.430), train_loss = 1.61642383, grad/param norm = 2.1535e-01, time/batch = 0.6459s	
2309/26050 (epoch 4.432), train_loss = 1.59030433, grad/param norm = 2.1843e-01, time/batch = 0.6428s	
2310/26050 (epoch 4.434), train_loss = 1.66142716, grad/param norm = 1.9386e-01, time/batch = 0.6508s	
2311/26050 (epoch 4.436), train_loss = 1.78011215, grad/param norm = 2.0395e-01, time/batch = 0.6400s	
2312/26050 (epoch 4.438), train_loss = 1.50507815, grad/param norm = 2.0640e-01, time/batch = 0.6401s	
2313/26050 (epoch 4.440), train_loss = 1.62795340, grad/param norm = 2.0967e-01, time/batch = 0.6394s	
2314/26050 (epoch 4.441), train_loss = 1.57481278, grad/param norm = 2.2240e-01, time/batch = 0.6390s	
2315/26050 (epoch 4.443), train_loss = 1.40383346, grad/param norm = 1.7278e-01, time/batch = 0.6383s	
2316/26050 (epoch 4.445), train_loss = 1.47039806, grad/param norm = 2.0318e-01, time/batch = 0.6399s	
2317/26050 (epoch 4.447), train_loss = 1.83693268, grad/param norm = 2.0934e-01, time/batch = 0.6613s	
2318/26050 (epoch 4.449), train_loss = 1.48772145, grad/param norm = 2.0987e-01, time/batch = 0.6786s	
2319/26050 (epoch 4.451), train_loss = 1.61506412, grad/param norm = 1.9627e-01, time/batch = 0.6412s	
2320/26050 (epoch 4.453), train_loss = 1.42565471, grad/param norm = 1.8065e-01, time/batch = 0.6590s	
2321/26050 (epoch 4.455), train_loss = 1.59182339, grad/param norm = 2.0780e-01, time/batch = 0.6749s	
2322/26050 (epoch 4.457), train_loss = 1.66624791, grad/param norm = 2.2974e-01, time/batch = 0.6769s	
2323/26050 (epoch 4.459), train_loss = 1.74934230, grad/param norm = 2.4197e-01, time/batch = 0.6736s	
2324/26050 (epoch 4.461), train_loss = 1.67209656, grad/param norm = 2.1729e-01, time/batch = 0.6637s	
2325/26050 (epoch 4.463), train_loss = 1.51121818, grad/param norm = 1.9175e-01, time/batch = 0.6512s	
2326/26050 (epoch 4.464), train_loss = 1.69814660, grad/param norm = 2.1898e-01, time/batch = 0.6417s	
2327/26050 (epoch 4.466), train_loss = 1.71439781, grad/param norm = 1.9543e-01, time/batch = 0.6395s	
2328/26050 (epoch 4.468), train_loss = 1.70845364, grad/param norm = 2.0152e-01, time/batch = 0.6831s	
2329/26050 (epoch 4.470), train_loss = 1.83953932, grad/param norm = 2.2692e-01, time/batch = 0.6596s	
2330/26050 (epoch 4.472), train_loss = 1.88995975, grad/param norm = 2.3033e-01, time/batch = 0.6387s	
2331/26050 (epoch 4.474), train_loss = 1.91006060, grad/param norm = 2.2388e-01, time/batch = 0.6424s	
2332/26050 (epoch 4.476), train_loss = 1.72481091, grad/param norm = 1.9916e-01, time/batch = 0.6424s	
2333/26050 (epoch 4.478), train_loss = 1.52162564, grad/param norm = 1.9256e-01, time/batch = 0.6408s	
2334/26050 (epoch 4.480), train_loss = 1.64226962, grad/param norm = 1.9830e-01, time/batch = 0.6494s	
2335/26050 (epoch 4.482), train_loss = 1.58197331, grad/param norm = 2.1377e-01, time/batch = 0.6492s	
2336/26050 (epoch 4.484), train_loss = 1.44677246, grad/param norm = 2.0865e-01, time/batch = 0.6402s	
2337/26050 (epoch 4.486), train_loss = 1.80036928, grad/param norm = 2.2831e-01, time/batch = 0.6397s	
2338/26050 (epoch 4.488), train_loss = 1.98177722, grad/param norm = 2.2452e-01, time/batch = 0.6455s	
2339/26050 (epoch 4.489), train_loss = 1.85293342, grad/param norm = 2.1639e-01, time/batch = 0.6395s	
2340/26050 (epoch 4.491), train_loss = 1.54267393, grad/param norm = 2.0626e-01, time/batch = 0.6474s	
2341/26050 (epoch 4.493), train_loss = 1.52101083, grad/param norm = 1.9065e-01, time/batch = 0.6425s	
2342/26050 (epoch 4.495), train_loss = 1.60903621, grad/param norm = 2.1843e-01, time/batch = 0.6389s	
2343/26050 (epoch 4.497), train_loss = 1.53365338, grad/param norm = 2.0520e-01, time/batch = 0.6418s	
2344/26050 (epoch 4.499), train_loss = 1.55041435, grad/param norm = 2.1845e-01, time/batch = 0.6401s	
2345/26050 (epoch 4.501), train_loss = 1.57460140, grad/param norm = 2.0158e-01, time/batch = 0.6392s	
2346/26050 (epoch 4.503), train_loss = 1.55614581, grad/param norm = 2.0341e-01, time/batch = 0.6391s	
2347/26050 (epoch 4.505), train_loss = 1.70700549, grad/param norm = 2.0077e-01, time/batch = 0.6393s	
2348/26050 (epoch 4.507), train_loss = 1.73379824, grad/param norm = 2.2176e-01, time/batch = 0.6794s	
2349/26050 (epoch 4.509), train_loss = 1.87493148, grad/param norm = 2.2741e-01, time/batch = 0.6621s	
2350/26050 (epoch 4.511), train_loss = 1.51416306, grad/param norm = 1.9702e-01, time/batch = 0.6392s	
2351/26050 (epoch 4.512), train_loss = 1.69549207, grad/param norm = 2.3073e-01, time/batch = 0.6399s	
2352/26050 (epoch 4.514), train_loss = 1.68677683, grad/param norm = 2.0227e-01, time/batch = 0.6579s	
2353/26050 (epoch 4.516), train_loss = 1.72684119, grad/param norm = 2.0804e-01, time/batch = 0.6590s	
2354/26050 (epoch 4.518), train_loss = 1.69738002, grad/param norm = 2.3264e-01, time/batch = 0.6588s	
2355/26050 (epoch 4.520), train_loss = 1.65289139, grad/param norm = 2.0848e-01, time/batch = 0.6591s	
2356/26050 (epoch 4.522), train_loss = 1.54044329, grad/param norm = 2.0764e-01, time/batch = 0.6591s	
2357/26050 (epoch 4.524), train_loss = 1.89705123, grad/param norm = 2.1755e-01, time/batch = 0.6534s	
2358/26050 (epoch 4.526), train_loss = 1.70963181, grad/param norm = 2.2444e-01, time/batch = 0.6527s	
2359/26050 (epoch 4.528), train_loss = 1.72090690, grad/param norm = 2.2635e-01, time/batch = 0.6560s	
2360/26050 (epoch 4.530), train_loss = 1.60952907, grad/param norm = 2.0337e-01, time/batch = 0.6564s	
2361/26050 (epoch 4.532), train_loss = 1.65981187, grad/param norm = 2.0365e-01, time/batch = 0.6587s	
2362/26050 (epoch 4.534), train_loss = 1.70822167, grad/param norm = 2.1450e-01, time/batch = 0.6583s	
2363/26050 (epoch 4.536), train_loss = 1.54165533, grad/param norm = 2.1259e-01, time/batch = 0.6590s	
2364/26050 (epoch 4.537), train_loss = 1.73120481, grad/param norm = 1.9158e-01, time/batch = 0.6573s	
2365/26050 (epoch 4.539), train_loss = 1.58797942, grad/param norm = 2.0626e-01, time/batch = 0.6425s	
2366/26050 (epoch 4.541), train_loss = 1.79890683, grad/param norm = 2.2948e-01, time/batch = 0.6387s	
2367/26050 (epoch 4.543), train_loss = 1.43408537, grad/param norm = 2.0399e-01, time/batch = 0.6386s	
2368/26050 (epoch 4.545), train_loss = 1.67495936, grad/param norm = 2.2172e-01, time/batch = 0.6394s	
2369/26050 (epoch 4.547), train_loss = 1.67676748, grad/param norm = 2.2542e-01, time/batch = 0.6390s	
2370/26050 (epoch 4.549), train_loss = 1.49205712, grad/param norm = 2.0785e-01, time/batch = 0.6473s	
2371/26050 (epoch 4.551), train_loss = 1.68310594, grad/param norm = 2.3289e-01, time/batch = 0.6597s	
2372/26050 (epoch 4.553), train_loss = 1.57166557, grad/param norm = 2.1692e-01, time/batch = 0.6528s	
2373/26050 (epoch 4.555), train_loss = 1.56186268, grad/param norm = 2.0395e-01, time/batch = 0.6489s	
2374/26050 (epoch 4.557), train_loss = 1.71555260, grad/param norm = 2.0657e-01, time/batch = 0.6518s	
2375/26050 (epoch 4.559), train_loss = 1.64293363, grad/param norm = 2.2674e-01, time/batch = 0.6429s	
2376/26050 (epoch 4.560), train_loss = 1.62807550, grad/param norm = 2.0721e-01, time/batch = 0.6544s	
2377/26050 (epoch 4.562), train_loss = 1.62615172, grad/param norm = 2.0521e-01, time/batch = 0.6629s	
2378/26050 (epoch 4.564), train_loss = 1.82021080, grad/param norm = 2.4256e-01, time/batch = 0.6749s	
2379/26050 (epoch 4.566), train_loss = 1.52650933, grad/param norm = 2.1529e-01, time/batch = 0.6841s	
2380/26050 (epoch 4.568), train_loss = 1.65865594, grad/param norm = 1.9304e-01, time/batch = 0.6567s	
2381/26050 (epoch 4.570), train_loss = 1.74124459, grad/param norm = 2.2202e-01, time/batch = 0.6537s	
2382/26050 (epoch 4.572), train_loss = 1.68951087, grad/param norm = 2.0182e-01, time/batch = 0.6524s	
2383/26050 (epoch 4.574), train_loss = 1.76918226, grad/param norm = 2.4606e-01, time/batch = 0.6610s	
2384/26050 (epoch 4.576), train_loss = 1.72687207, grad/param norm = 2.1516e-01, time/batch = 0.6606s	
2385/26050 (epoch 4.578), train_loss = 1.66497811, grad/param norm = 2.1393e-01, time/batch = 0.6604s	
2386/26050 (epoch 4.580), train_loss = 1.50796945, grad/param norm = 1.9374e-01, time/batch = 0.6647s	
2387/26050 (epoch 4.582), train_loss = 1.70168259, grad/param norm = 2.0728e-01, time/batch = 0.6642s	
2388/26050 (epoch 4.583), train_loss = 1.69119049, grad/param norm = 2.0625e-01, time/batch = 0.6441s	
2389/26050 (epoch 4.585), train_loss = 1.49963162, grad/param norm = 2.0563e-01, time/batch = 0.6401s	
2390/26050 (epoch 4.587), train_loss = 1.70918102, grad/param norm = 2.1387e-01, time/batch = 0.6416s	
2391/26050 (epoch 4.589), train_loss = 1.69668919, grad/param norm = 2.3099e-01, time/batch = 0.6442s	
2392/26050 (epoch 4.591), train_loss = 1.69004486, grad/param norm = 1.9921e-01, time/batch = 0.6396s	
2393/26050 (epoch 4.593), train_loss = 1.52107276, grad/param norm = 2.0995e-01, time/batch = 0.6533s	
2394/26050 (epoch 4.595), train_loss = 1.79218939, grad/param norm = 2.5854e-01, time/batch = 0.6826s	
2395/26050 (epoch 4.597), train_loss = 1.66839026, grad/param norm = 2.3106e-01, time/batch = 0.6482s	
2396/26050 (epoch 4.599), train_loss = 1.47422299, grad/param norm = 1.8335e-01, time/batch = 0.6406s	
2397/26050 (epoch 4.601), train_loss = 1.82914593, grad/param norm = 2.0899e-01, time/batch = 0.6383s	
2398/26050 (epoch 4.603), train_loss = 1.71535055, grad/param norm = 2.0790e-01, time/batch = 0.6402s	
2399/26050 (epoch 4.605), train_loss = 1.53788335, grad/param norm = 1.7986e-01, time/batch = 0.6449s	
2400/26050 (epoch 4.607), train_loss = 1.73475343, grad/param norm = 2.1186e-01, time/batch = 0.6529s	
2401/26050 (epoch 4.608), train_loss = 1.58805821, grad/param norm = 1.9852e-01, time/batch = 0.6449s	
2402/26050 (epoch 4.610), train_loss = 1.62065463, grad/param norm = 2.3385e-01, time/batch = 0.6510s	
2403/26050 (epoch 4.612), train_loss = 1.57054505, grad/param norm = 2.1811e-01, time/batch = 0.6388s	
2404/26050 (epoch 4.614), train_loss = 1.66632437, grad/param norm = 2.1926e-01, time/batch = 0.6409s	
2405/26050 (epoch 4.616), train_loss = 1.93751148, grad/param norm = 2.1749e-01, time/batch = 0.6414s	
2406/26050 (epoch 4.618), train_loss = 1.54383465, grad/param norm = 2.1304e-01, time/batch = 0.6409s	
2407/26050 (epoch 4.620), train_loss = 1.68483992, grad/param norm = 2.3120e-01, time/batch = 0.6395s	
2408/26050 (epoch 4.622), train_loss = 1.35714252, grad/param norm = 1.9049e-01, time/batch = 0.6441s	
2409/26050 (epoch 4.624), train_loss = 1.51122307, grad/param norm = 1.8950e-01, time/batch = 0.6763s	
2410/26050 (epoch 4.626), train_loss = 1.62498413, grad/param norm = 2.2343e-01, time/batch = 0.6658s	
2411/26050 (epoch 4.628), train_loss = 1.64175715, grad/param norm = 2.2196e-01, time/batch = 0.6424s	
2412/26050 (epoch 4.630), train_loss = 1.75410401, grad/param norm = 2.0576e-01, time/batch = 0.6419s	
2413/26050 (epoch 4.631), train_loss = 1.73194546, grad/param norm = 2.1413e-01, time/batch = 0.6420s	
2414/26050 (epoch 4.633), train_loss = 1.47095084, grad/param norm = 1.8635e-01, time/batch = 0.6431s	
2415/26050 (epoch 4.635), train_loss = 1.48579735, grad/param norm = 1.9241e-01, time/batch = 0.6408s	
2416/26050 (epoch 4.637), train_loss = 1.51352620, grad/param norm = 1.9999e-01, time/batch = 0.6416s	
2417/26050 (epoch 4.639), train_loss = 1.70726355, grad/param norm = 2.1478e-01, time/batch = 0.6439s	
2418/26050 (epoch 4.641), train_loss = 1.53642372, grad/param norm = 1.8143e-01, time/batch = 0.6454s	
2419/26050 (epoch 4.643), train_loss = 1.51861621, grad/param norm = 1.9083e-01, time/batch = 0.6406s	
2420/26050 (epoch 4.645), train_loss = 1.70612007, grad/param norm = 2.1433e-01, time/batch = 0.6434s	
2421/26050 (epoch 4.647), train_loss = 1.52596315, grad/param norm = 2.0122e-01, time/batch = 0.6439s	
2422/26050 (epoch 4.649), train_loss = 1.65811340, grad/param norm = 2.1779e-01, time/batch = 0.6426s	
2423/26050 (epoch 4.651), train_loss = 1.61168506, grad/param norm = 2.0492e-01, time/batch = 0.6435s	
2424/26050 (epoch 4.653), train_loss = 1.55681927, grad/param norm = 2.0390e-01, time/batch = 0.6556s	
2425/26050 (epoch 4.655), train_loss = 1.51945191, grad/param norm = 2.0603e-01, time/batch = 0.6741s	
2426/26050 (epoch 4.656), train_loss = 1.50817902, grad/param norm = 1.9608e-01, time/batch = 0.6468s	
2427/26050 (epoch 4.658), train_loss = 1.78215282, grad/param norm = 2.2556e-01, time/batch = 0.6423s	
2428/26050 (epoch 4.660), train_loss = 1.49720587, grad/param norm = 2.3009e-01, time/batch = 0.6390s	
2429/26050 (epoch 4.662), train_loss = 1.46406855, grad/param norm = 2.0402e-01, time/batch = 0.6410s	
2430/26050 (epoch 4.664), train_loss = 1.56340583, grad/param norm = 2.1777e-01, time/batch = 0.6403s	
2431/26050 (epoch 4.666), train_loss = 1.65452880, grad/param norm = 2.2389e-01, time/batch = 0.6411s	
2432/26050 (epoch 4.668), train_loss = 1.34882562, grad/param norm = 1.7792e-01, time/batch = 0.6511s	
2433/26050 (epoch 4.670), train_loss = 1.78752589, grad/param norm = 2.3211e-01, time/batch = 0.6422s	
2434/26050 (epoch 4.672), train_loss = 1.49843606, grad/param norm = 1.9452e-01, time/batch = 0.6394s	
2435/26050 (epoch 4.674), train_loss = 1.47160132, grad/param norm = 1.8937e-01, time/batch = 0.6420s	
2436/26050 (epoch 4.676), train_loss = 1.61927024, grad/param norm = 2.1364e-01, time/batch = 0.6422s	
2437/26050 (epoch 4.678), train_loss = 1.79925961, grad/param norm = 2.1928e-01, time/batch = 0.6468s	
2438/26050 (epoch 4.679), train_loss = 1.72785236, grad/param norm = 2.2185e-01, time/batch = 0.6413s	
2439/26050 (epoch 4.681), train_loss = 1.62580580, grad/param norm = 2.2210e-01, time/batch = 0.6424s	
2440/26050 (epoch 4.683), train_loss = 1.53882275, grad/param norm = 2.1638e-01, time/batch = 0.6825s	
2441/26050 (epoch 4.685), train_loss = 1.54061688, grad/param norm = 1.9933e-01, time/batch = 0.6593s	
2442/26050 (epoch 4.687), train_loss = 1.39337738, grad/param norm = 1.9106e-01, time/batch = 0.6409s	
2443/26050 (epoch 4.689), train_loss = 1.59946584, grad/param norm = 2.0308e-01, time/batch = 0.6404s	
2444/26050 (epoch 4.691), train_loss = 1.31804970, grad/param norm = 1.9910e-01, time/batch = 0.6399s	
2445/26050 (epoch 4.693), train_loss = 1.50416954, grad/param norm = 2.1709e-01, time/batch = 0.6426s	
2446/26050 (epoch 4.695), train_loss = 1.64975133, grad/param norm = 2.0593e-01, time/batch = 0.6405s	
2447/26050 (epoch 4.697), train_loss = 1.44848036, grad/param norm = 2.0946e-01, time/batch = 0.6406s	
2448/26050 (epoch 4.699), train_loss = 1.65478295, grad/param norm = 2.1830e-01, time/batch = 0.6465s	
2449/26050 (epoch 4.701), train_loss = 1.42553707, grad/param norm = 1.8916e-01, time/batch = 0.6426s	
2450/26050 (epoch 4.702), train_loss = 1.85385794, grad/param norm = 2.0451e-01, time/batch = 0.6414s	
2451/26050 (epoch 4.704), train_loss = 1.59050678, grad/param norm = 2.0005e-01, time/batch = 0.6423s	
2452/26050 (epoch 4.706), train_loss = 1.72028387, grad/param norm = 2.2056e-01, time/batch = 0.6419s	
2453/26050 (epoch 4.708), train_loss = 1.66520890, grad/param norm = 2.0481e-01, time/batch = 0.6416s	
2454/26050 (epoch 4.710), train_loss = 1.69725812, grad/param norm = 2.0911e-01, time/batch = 0.6416s	
2455/26050 (epoch 4.712), train_loss = 1.79746032, grad/param norm = 2.2026e-01, time/batch = 0.6698s	
2456/26050 (epoch 4.714), train_loss = 1.49116119, grad/param norm = 2.1863e-01, time/batch = 0.6761s	
2457/26050 (epoch 4.716), train_loss = 1.85449538, grad/param norm = 2.5467e-01, time/batch = 0.6428s	
2458/26050 (epoch 4.718), train_loss = 1.70663361, grad/param norm = 2.3621e-01, time/batch = 0.6405s	
2459/26050 (epoch 4.720), train_loss = 1.51929822, grad/param norm = 2.1248e-01, time/batch = 0.6413s	
2460/26050 (epoch 4.722), train_loss = 1.49235292, grad/param norm = 2.1878e-01, time/batch = 0.6413s	
2461/26050 (epoch 4.724), train_loss = 1.45880369, grad/param norm = 1.9758e-01, time/batch = 0.6429s	
2462/26050 (epoch 4.726), train_loss = 1.70651923, grad/param norm = 2.0979e-01, time/batch = 0.6505s	
2463/26050 (epoch 4.727), train_loss = 1.65167017, grad/param norm = 2.0355e-01, time/batch = 0.6546s	
2464/26050 (epoch 4.729), train_loss = 1.71532284, grad/param norm = 2.3652e-01, time/batch = 0.6697s	
2465/26050 (epoch 4.731), train_loss = 1.57366935, grad/param norm = 1.9203e-01, time/batch = 0.6457s	
2466/26050 (epoch 4.733), train_loss = 1.65375009, grad/param norm = 2.4966e-01, time/batch = 0.6440s	
2467/26050 (epoch 4.735), train_loss = 1.80534015, grad/param norm = 2.1279e-01, time/batch = 0.6571s	
2468/26050 (epoch 4.737), train_loss = 1.65994344, grad/param norm = 2.1413e-01, time/batch = 0.6432s	
2469/26050 (epoch 4.739), train_loss = 1.67063878, grad/param norm = 2.1546e-01, time/batch = 0.6416s	
2470/26050 (epoch 4.741), train_loss = 1.48729054, grad/param norm = 1.8938e-01, time/batch = 0.6588s	
2471/26050 (epoch 4.743), train_loss = 1.73679977, grad/param norm = 2.6491e-01, time/batch = 0.6865s	
2472/26050 (epoch 4.745), train_loss = 1.46651882, grad/param norm = 1.9829e-01, time/batch = 0.6493s	
2473/26050 (epoch 4.747), train_loss = 1.54482324, grad/param norm = 2.0615e-01, time/batch = 0.6418s	
2474/26050 (epoch 4.749), train_loss = 1.67631254, grad/param norm = 2.3068e-01, time/batch = 0.6413s	
2475/26050 (epoch 4.750), train_loss = 1.54981825, grad/param norm = 1.8957e-01, time/batch = 0.6415s	
2476/26050 (epoch 4.752), train_loss = 1.70415867, grad/param norm = 2.1973e-01, time/batch = 0.6455s	
2477/26050 (epoch 4.754), train_loss = 1.50263474, grad/param norm = 1.9999e-01, time/batch = 0.6408s	
2478/26050 (epoch 4.756), train_loss = 1.72766334, grad/param norm = 2.5595e-01, time/batch = 0.6443s	
2479/26050 (epoch 4.758), train_loss = 1.65250299, grad/param norm = 2.3259e-01, time/batch = 0.6496s	
2480/26050 (epoch 4.760), train_loss = 1.64328473, grad/param norm = 2.0823e-01, time/batch = 0.6406s	
2481/26050 (epoch 4.762), train_loss = 1.55555519, grad/param norm = 2.1753e-01, time/batch = 0.6441s	
2482/26050 (epoch 4.764), train_loss = 1.71665984, grad/param norm = 2.1814e-01, time/batch = 0.6441s	
2483/26050 (epoch 4.766), train_loss = 1.70388716, grad/param norm = 2.2010e-01, time/batch = 0.6403s	
2484/26050 (epoch 4.768), train_loss = 1.53823710, grad/param norm = 1.8674e-01, time/batch = 0.6403s	
2485/26050 (epoch 4.770), train_loss = 1.61177520, grad/param norm = 2.0787e-01, time/batch = 0.6410s	
2486/26050 (epoch 4.772), train_loss = 1.61707942, grad/param norm = 2.2011e-01, time/batch = 0.6453s	
2487/26050 (epoch 4.774), train_loss = 1.53732997, grad/param norm = 1.9943e-01, time/batch = 0.6420s	
2488/26050 (epoch 4.775), train_loss = 1.36110460, grad/param norm = 2.0275e-01, time/batch = 0.6394s	
2489/26050 (epoch 4.777), train_loss = 1.51661359, grad/param norm = 2.0539e-01, time/batch = 0.6404s	
2490/26050 (epoch 4.779), train_loss = 1.59265133, grad/param norm = 2.2276e-01, time/batch = 0.6410s	
2491/26050 (epoch 4.781), train_loss = 1.54002760, grad/param norm = 2.0577e-01, time/batch = 0.6497s	
2492/26050 (epoch 4.783), train_loss = 1.52989681, grad/param norm = 1.8071e-01, time/batch = 0.6419s	
2493/26050 (epoch 4.785), train_loss = 1.58161625, grad/param norm = 2.3359e-01, time/batch = 0.6417s	
2494/26050 (epoch 4.787), train_loss = 1.55537629, grad/param norm = 2.0211e-01, time/batch = 0.6434s	
2495/26050 (epoch 4.789), train_loss = 1.63924593, grad/param norm = 2.2030e-01, time/batch = 0.6518s	
2496/26050 (epoch 4.791), train_loss = 1.62679633, grad/param norm = 1.9719e-01, time/batch = 0.6397s	
2497/26050 (epoch 4.793), train_loss = 1.58669500, grad/param norm = 2.2062e-01, time/batch = 0.6405s	
2498/26050 (epoch 4.795), train_loss = 1.49022021, grad/param norm = 1.9783e-01, time/batch = 0.6397s	
2499/26050 (epoch 4.797), train_loss = 1.49486861, grad/param norm = 1.9129e-01, time/batch = 0.6386s	
2500/26050 (epoch 4.798), train_loss = 1.47390148, grad/param norm = 2.1392e-01, time/batch = 0.6399s	
2501/26050 (epoch 4.800), train_loss = 1.44881885, grad/param norm = 1.9824e-01, time/batch = 0.6620s	
2502/26050 (epoch 4.802), train_loss = 1.62660050, grad/param norm = 2.1088e-01, time/batch = 0.6827s	
2503/26050 (epoch 4.804), train_loss = 1.59771777, grad/param norm = 2.0053e-01, time/batch = 0.6410s	
2504/26050 (epoch 4.806), train_loss = 1.78034504, grad/param norm = 2.2355e-01, time/batch = 0.6408s	
2505/26050 (epoch 4.808), train_loss = 1.53497177, grad/param norm = 2.0352e-01, time/batch = 0.6396s	
2506/26050 (epoch 4.810), train_loss = 1.50695806, grad/param norm = 2.2055e-01, time/batch = 0.6415s	
2507/26050 (epoch 4.812), train_loss = 1.45016245, grad/param norm = 1.9920e-01, time/batch = 0.6395s	
2508/26050 (epoch 4.814), train_loss = 1.51588251, grad/param norm = 2.2848e-01, time/batch = 0.6390s	
2509/26050 (epoch 4.816), train_loss = 1.64969584, grad/param norm = 2.1500e-01, time/batch = 0.6509s	
2510/26050 (epoch 4.818), train_loss = 1.75552207, grad/param norm = 2.3976e-01, time/batch = 0.6414s	
2511/26050 (epoch 4.820), train_loss = 1.65509878, grad/param norm = 2.2679e-01, time/batch = 0.6420s	
2512/26050 (epoch 4.821), train_loss = 1.77969070, grad/param norm = 2.4274e-01, time/batch = 0.6421s	
2513/26050 (epoch 4.823), train_loss = 1.82673399, grad/param norm = 2.2035e-01, time/batch = 0.6544s	
2514/26050 (epoch 4.825), train_loss = 1.53428036, grad/param norm = 2.1581e-01, time/batch = 0.6418s	
2515/26050 (epoch 4.827), train_loss = 1.67597457, grad/param norm = 2.5027e-01, time/batch = 0.6403s	
2516/26050 (epoch 4.829), train_loss = 1.67365396, grad/param norm = 2.0193e-01, time/batch = 0.6514s	
2517/26050 (epoch 4.831), train_loss = 1.73723928, grad/param norm = 2.0614e-01, time/batch = 0.6840s	
2518/26050 (epoch 4.833), train_loss = 1.80459418, grad/param norm = 2.4192e-01, time/batch = 0.6643s	
2519/26050 (epoch 4.835), train_loss = 1.86216635, grad/param norm = 2.1098e-01, time/batch = 0.6426s	
2520/26050 (epoch 4.837), train_loss = 1.53471218, grad/param norm = 2.0365e-01, time/batch = 0.6404s	
2521/26050 (epoch 4.839), train_loss = 1.72858984, grad/param norm = 1.9724e-01, time/batch = 0.6424s	
2522/26050 (epoch 4.841), train_loss = 1.69619586, grad/param norm = 2.0006e-01, time/batch = 0.6425s	
2523/26050 (epoch 4.843), train_loss = 1.67211381, grad/param norm = 2.0729e-01, time/batch = 0.6413s	
2524/26050 (epoch 4.845), train_loss = 1.53025176, grad/param norm = 2.1018e-01, time/batch = 0.6422s	
2525/26050 (epoch 4.846), train_loss = 1.74121897, grad/param norm = 2.1266e-01, time/batch = 0.6454s	
2526/26050 (epoch 4.848), train_loss = 1.54121016, grad/param norm = 1.9099e-01, time/batch = 0.6424s	
2527/26050 (epoch 4.850), train_loss = 1.55158291, grad/param norm = 1.8867e-01, time/batch = 0.6416s	
2528/26050 (epoch 4.852), train_loss = 1.58596941, grad/param norm = 2.2168e-01, time/batch = 0.6437s	
2529/26050 (epoch 4.854), train_loss = 1.62045661, grad/param norm = 2.0307e-01, time/batch = 0.6440s	
2530/26050 (epoch 4.856), train_loss = 1.49976117, grad/param norm = 2.0012e-01, time/batch = 0.6412s	
2531/26050 (epoch 4.858), train_loss = 1.44215271, grad/param norm = 2.1413e-01, time/batch = 0.6437s	
2532/26050 (epoch 4.860), train_loss = 1.62767611, grad/param norm = 2.2711e-01, time/batch = 0.6458s	
2533/26050 (epoch 4.862), train_loss = 1.61287119, grad/param norm = 2.2825e-01, time/batch = 0.6439s	
2534/26050 (epoch 4.864), train_loss = 1.51466163, grad/param norm = 2.0384e-01, time/batch = 0.6413s	
2535/26050 (epoch 4.866), train_loss = 1.47588739, grad/param norm = 1.8862e-01, time/batch = 0.6422s	
2536/26050 (epoch 4.868), train_loss = 1.73845327, grad/param norm = 2.1505e-01, time/batch = 0.6460s	
2537/26050 (epoch 4.869), train_loss = 1.43547897, grad/param norm = 1.8343e-01, time/batch = 0.6413s	
2538/26050 (epoch 4.871), train_loss = 1.37373888, grad/param norm = 1.8946e-01, time/batch = 0.6418s	
2539/26050 (epoch 4.873), train_loss = 1.56953457, grad/param norm = 2.0537e-01, time/batch = 0.6476s	
2540/26050 (epoch 4.875), train_loss = 1.58104571, grad/param norm = 2.2022e-01, time/batch = 0.6454s	
2541/26050 (epoch 4.877), train_loss = 1.39852669, grad/param norm = 2.0593e-01, time/batch = 0.6480s	
2542/26050 (epoch 4.879), train_loss = 1.52835512, grad/param norm = 1.8961e-01, time/batch = 0.6468s	
2543/26050 (epoch 4.881), train_loss = 1.81608297, grad/param norm = 2.1171e-01, time/batch = 0.6473s	
2544/26050 (epoch 4.883), train_loss = 1.62879929, grad/param norm = 1.9195e-01, time/batch = 0.6436s	
2545/26050 (epoch 4.885), train_loss = 1.33249918, grad/param norm = 1.8093e-01, time/batch = 0.6425s	
2546/26050 (epoch 4.887), train_loss = 1.61807047, grad/param norm = 2.0911e-01, time/batch = 0.6434s	
2547/26050 (epoch 4.889), train_loss = 1.49917575, grad/param norm = 1.9054e-01, time/batch = 0.6453s	
2548/26050 (epoch 4.891), train_loss = 1.33985868, grad/param norm = 1.9541e-01, time/batch = 0.6427s	
2549/26050 (epoch 4.893), train_loss = 1.31466442, grad/param norm = 1.7388e-01, time/batch = 0.6402s	
2550/26050 (epoch 4.894), train_loss = 1.43879598, grad/param norm = 1.7756e-01, time/batch = 0.6397s	
2551/26050 (epoch 4.896), train_loss = 1.67438342, grad/param norm = 1.9872e-01, time/batch = 0.6417s	
2552/26050 (epoch 4.898), train_loss = 1.51671354, grad/param norm = 1.9540e-01, time/batch = 0.6664s	
2553/26050 (epoch 4.900), train_loss = 1.83669397, grad/param norm = 2.2956e-01, time/batch = 0.6772s	
2554/26050 (epoch 4.902), train_loss = 1.61678037, grad/param norm = 2.0551e-01, time/batch = 0.6389s	
2555/26050 (epoch 4.904), train_loss = 1.56032934, grad/param norm = 2.0941e-01, time/batch = 0.6626s	
2556/26050 (epoch 4.906), train_loss = 1.58609921, grad/param norm = 2.0375e-01, time/batch = 0.6449s	
2557/26050 (epoch 4.908), train_loss = 1.57321174, grad/param norm = 2.0726e-01, time/batch = 0.6505s	
2558/26050 (epoch 4.910), train_loss = 1.50372955, grad/param norm = 1.8793e-01, time/batch = 0.6432s	
2559/26050 (epoch 4.912), train_loss = 1.86435977, grad/param norm = 2.2295e-01, time/batch = 0.6465s	
2560/26050 (epoch 4.914), train_loss = 2.02277139, grad/param norm = 2.2575e-01, time/batch = 0.6388s	
2561/26050 (epoch 4.916), train_loss = 1.78457228, grad/param norm = 2.2356e-01, time/batch = 0.6405s	
2562/26050 (epoch 4.917), train_loss = 1.59540857, grad/param norm = 1.9575e-01, time/batch = 0.6414s	
2563/26050 (epoch 4.919), train_loss = 1.68525379, grad/param norm = 2.0310e-01, time/batch = 0.6406s	
2564/26050 (epoch 4.921), train_loss = 1.46890002, grad/param norm = 2.0844e-01, time/batch = 0.6410s	
2565/26050 (epoch 4.923), train_loss = 1.52396004, grad/param norm = 2.1557e-01, time/batch = 0.6394s	
2566/26050 (epoch 4.925), train_loss = 1.48503558, grad/param norm = 1.8948e-01, time/batch = 0.6404s	
2567/26050 (epoch 4.927), train_loss = 1.46627949, grad/param norm = 1.7784e-01, time/batch = 0.6537s	
2568/26050 (epoch 4.929), train_loss = 1.49204648, grad/param norm = 2.1475e-01, time/batch = 0.6822s	
2569/26050 (epoch 4.931), train_loss = 1.90233741, grad/param norm = 2.5954e-01, time/batch = 0.6542s	
2570/26050 (epoch 4.933), train_loss = 1.57357267, grad/param norm = 2.1738e-01, time/batch = 0.6432s	
2571/26050 (epoch 4.935), train_loss = 1.46137766, grad/param norm = 2.0694e-01, time/batch = 0.6475s	
2572/26050 (epoch 4.937), train_loss = 1.54550992, grad/param norm = 1.9887e-01, time/batch = 0.6453s	
2573/26050 (epoch 4.939), train_loss = 1.44853307, grad/param norm = 2.0191e-01, time/batch = 0.6398s	
2574/26050 (epoch 4.940), train_loss = 1.63178488, grad/param norm = 1.9666e-01, time/batch = 0.6429s	
2575/26050 (epoch 4.942), train_loss = 1.64285337, grad/param norm = 2.2765e-01, time/batch = 0.6451s	
2576/26050 (epoch 4.944), train_loss = 1.53840940, grad/param norm = 2.2733e-01, time/batch = 0.6448s	
2577/26050 (epoch 4.946), train_loss = 1.74142235, grad/param norm = 1.9420e-01, time/batch = 0.6402s	
2578/26050 (epoch 4.948), train_loss = 1.37581996, grad/param norm = 2.3640e-01, time/batch = 0.6428s	
2579/26050 (epoch 4.950), train_loss = 1.52201338, grad/param norm = 2.1185e-01, time/batch = 0.6439s	
2580/26050 (epoch 4.952), train_loss = 1.76386246, grad/param norm = 2.1972e-01, time/batch = 0.6503s	
2581/26050 (epoch 4.954), train_loss = 1.69390129, grad/param norm = 1.9588e-01, time/batch = 0.6530s	
2582/26050 (epoch 4.956), train_loss = 1.72598298, grad/param norm = 2.1873e-01, time/batch = 0.6414s	
2583/26050 (epoch 4.958), train_loss = 1.59038788, grad/param norm = 1.9254e-01, time/batch = 0.6441s	
2584/26050 (epoch 4.960), train_loss = 1.50660617, grad/param norm = 1.9129e-01, time/batch = 0.6614s	
2585/26050 (epoch 4.962), train_loss = 1.49860334, grad/param norm = 1.9670e-01, time/batch = 0.6596s	
2586/26050 (epoch 4.964), train_loss = 1.55642370, grad/param norm = 2.0223e-01, time/batch = 0.6678s	
2587/26050 (epoch 4.965), train_loss = 1.43493782, grad/param norm = 1.9582e-01, time/batch = 0.6553s	
2588/26050 (epoch 4.967), train_loss = 1.93301019, grad/param norm = 2.2547e-01, time/batch = 0.6554s	
2589/26050 (epoch 4.969), train_loss = 1.53327724, grad/param norm = 2.0571e-01, time/batch = 0.6476s	
2590/26050 (epoch 4.971), train_loss = 1.38223342, grad/param norm = 1.8036e-01, time/batch = 0.6465s	
2591/26050 (epoch 4.973), train_loss = 1.53946780, grad/param norm = 2.2461e-01, time/batch = 0.6540s	
2592/26050 (epoch 4.975), train_loss = 1.65796318, grad/param norm = 1.9393e-01, time/batch = 0.6567s	
2593/26050 (epoch 4.977), train_loss = 1.60004342, grad/param norm = 1.8130e-01, time/batch = 0.6575s	
2594/26050 (epoch 4.979), train_loss = 1.41456075, grad/param norm = 1.9086e-01, time/batch = 0.6560s	
2595/26050 (epoch 4.981), train_loss = 1.64312680, grad/param norm = 1.8378e-01, time/batch = 0.6598s	
2596/26050 (epoch 4.983), train_loss = 1.66113905, grad/param norm = 2.0955e-01, time/batch = 0.6425s	
2597/26050 (epoch 4.985), train_loss = 1.64187533, grad/param norm = 2.1201e-01, time/batch = 0.6467s	
2598/26050 (epoch 4.987), train_loss = 1.75992822, grad/param norm = 2.2148e-01, time/batch = 0.6541s	
2599/26050 (epoch 4.988), train_loss = 1.74157886, grad/param norm = 2.2530e-01, time/batch = 0.6529s	
2600/26050 (epoch 4.990), train_loss = 1.54539127, grad/param norm = 2.2117e-01, time/batch = 0.6379s	
2601/26050 (epoch 4.992), train_loss = 1.79898256, grad/param norm = 2.3769e-01, time/batch = 0.6442s	
2602/26050 (epoch 4.994), train_loss = 1.55167541, grad/param norm = 2.0835e-01, time/batch = 0.6459s	
2603/26050 (epoch 4.996), train_loss = 1.64330750, grad/param norm = 2.5833e-01, time/batch = 0.6428s	
2604/26050 (epoch 4.998), train_loss = 1.66283299, grad/param norm = 2.0899e-01, time/batch = 0.6583s	
2605/26050 (epoch 5.000), train_loss = 1.55924217, grad/param norm = 2.0072e-01, time/batch = 0.6610s	
2606/26050 (epoch 5.002), train_loss = 1.61255647, grad/param norm = 1.9299e-01, time/batch = 0.6405s	
2607/26050 (epoch 5.004), train_loss = 1.54503514, grad/param norm = 2.1002e-01, time/batch = 0.6395s	
2608/26050 (epoch 5.006), train_loss = 1.47512258, grad/param norm = 1.8708e-01, time/batch = 0.6405s	
2609/26050 (epoch 5.008), train_loss = 1.50427844, grad/param norm = 1.9387e-01, time/batch = 0.6409s	
2610/26050 (epoch 5.010), train_loss = 1.55219086, grad/param norm = 1.8694e-01, time/batch = 0.6416s	
2611/26050 (epoch 5.012), train_loss = 1.64224253, grad/param norm = 2.1983e-01, time/batch = 0.6401s	
2612/26050 (epoch 5.013), train_loss = 2.05193255, grad/param norm = 2.1625e-01, time/batch = 0.6400s	
2613/26050 (epoch 5.015), train_loss = 1.44576714, grad/param norm = 1.9345e-01, time/batch = 0.6489s	
2614/26050 (epoch 5.017), train_loss = 1.58379090, grad/param norm = 2.0644e-01, time/batch = 0.6760s	
2615/26050 (epoch 5.019), train_loss = 1.41533724, grad/param norm = 1.7045e-01, time/batch = 0.6393s	
2616/26050 (epoch 5.021), train_loss = 1.74498317, grad/param norm = 2.3448e-01, time/batch = 0.6397s	
2617/26050 (epoch 5.023), train_loss = 1.46969111, grad/param norm = 2.0711e-01, time/batch = 0.6543s	
2618/26050 (epoch 5.025), train_loss = 1.51876598, grad/param norm = 2.1375e-01, time/batch = 0.6486s	
2619/26050 (epoch 5.027), train_loss = 1.33667689, grad/param norm = 1.8549e-01, time/batch = 0.6410s	
2620/26050 (epoch 5.029), train_loss = 1.50922348, grad/param norm = 1.9143e-01, time/batch = 0.6387s	
2621/26050 (epoch 5.031), train_loss = 1.77314695, grad/param norm = 2.2934e-01, time/batch = 0.6434s	
2622/26050 (epoch 5.033), train_loss = 1.61403587, grad/param norm = 2.1467e-01, time/batch = 0.6415s	
2623/26050 (epoch 5.035), train_loss = 1.74905869, grad/param norm = 1.9748e-01, time/batch = 0.6410s	
2624/26050 (epoch 5.036), train_loss = 1.55790228, grad/param norm = 2.1480e-01, time/batch = 0.6411s	
2625/26050 (epoch 5.038), train_loss = 1.36836812, grad/param norm = 2.0341e-01, time/batch = 0.6395s	
2626/26050 (epoch 5.040), train_loss = 1.64365337, grad/param norm = 2.2226e-01, time/batch = 0.6393s	
2627/26050 (epoch 5.042), train_loss = 1.42430446, grad/param norm = 1.9552e-01, time/batch = 0.6390s	
2628/26050 (epoch 5.044), train_loss = 1.62050140, grad/param norm = 1.9317e-01, time/batch = 0.6388s	
2629/26050 (epoch 5.046), train_loss = 1.38080903, grad/param norm = 2.0651e-01, time/batch = 0.6706s	
2630/26050 (epoch 5.048), train_loss = 1.58678919, grad/param norm = 1.9251e-01, time/batch = 0.6700s	
2631/26050 (epoch 5.050), train_loss = 1.45770408, grad/param norm = 2.1267e-01, time/batch = 0.6402s	
2632/26050 (epoch 5.052), train_loss = 1.57961168, grad/param norm = 2.0575e-01, time/batch = 0.6462s	
2633/26050 (epoch 5.054), train_loss = 1.43455279, grad/param norm = 2.2119e-01, time/batch = 0.6411s	
2634/26050 (epoch 5.056), train_loss = 1.23396378, grad/param norm = 1.7607e-01, time/batch = 0.6406s	
2635/26050 (epoch 5.058), train_loss = 1.46033717, grad/param norm = 1.9174e-01, time/batch = 0.6438s	
2636/26050 (epoch 5.060), train_loss = 1.53273406, grad/param norm = 1.8541e-01, time/batch = 0.6481s	
2637/26050 (epoch 5.061), train_loss = 1.43481136, grad/param norm = 1.9388e-01, time/batch = 0.6396s	
2638/26050 (epoch 5.063), train_loss = 1.45231769, grad/param norm = 1.7437e-01, time/batch = 0.6399s	
2639/26050 (epoch 5.065), train_loss = 1.39371521, grad/param norm = 1.9318e-01, time/batch = 0.6425s	
2640/26050 (epoch 5.067), train_loss = 1.65314135, grad/param norm = 2.2401e-01, time/batch = 0.6420s	
2641/26050 (epoch 5.069), train_loss = 1.64303966, grad/param norm = 2.0567e-01, time/batch = 0.6416s	
2642/26050 (epoch 5.071), train_loss = 1.62614696, grad/param norm = 2.1409e-01, time/batch = 0.6410s	
2643/26050 (epoch 5.073), train_loss = 1.78522968, grad/param norm = 1.9831e-01, time/batch = 0.6411s	
2644/26050 (epoch 5.075), train_loss = 1.43077644, grad/param norm = 1.8533e-01, time/batch = 0.6545s	
2645/26050 (epoch 5.077), train_loss = 1.44892636, grad/param norm = 2.0372e-01, time/batch = 0.6825s	
2646/26050 (epoch 5.079), train_loss = 1.68359106, grad/param norm = 2.0824e-01, time/batch = 0.6474s	
2647/26050 (epoch 5.081), train_loss = 1.46936327, grad/param norm = 1.8478e-01, time/batch = 0.6552s	
2648/26050 (epoch 5.083), train_loss = 1.64288973, grad/param norm = 2.1362e-01, time/batch = 0.6574s	
2649/26050 (epoch 5.084), train_loss = 1.81231287, grad/param norm = 2.3563e-01, time/batch = 0.6398s	
2650/26050 (epoch 5.086), train_loss = 1.73374929, grad/param norm = 2.2809e-01, time/batch = 0.6501s	
2651/26050 (epoch 5.088), train_loss = 1.40999269, grad/param norm = 1.7462e-01, time/batch = 0.6479s	
2652/26050 (epoch 5.090), train_loss = 1.75762652, grad/param norm = 2.0281e-01, time/batch = 0.6426s	
2653/26050 (epoch 5.092), train_loss = 1.48324324, grad/param norm = 2.1311e-01, time/batch = 0.6463s	
2654/26050 (epoch 5.094), train_loss = 1.62181450, grad/param norm = 2.0098e-01, time/batch = 0.6444s	
2655/26050 (epoch 5.096), train_loss = 1.40405256, grad/param norm = 1.8261e-01, time/batch = 0.6429s	
2656/26050 (epoch 5.098), train_loss = 1.46941156, grad/param norm = 1.9282e-01, time/batch = 0.6518s	
2657/26050 (epoch 5.100), train_loss = 1.47579623, grad/param norm = 2.2302e-01, time/batch = 0.6452s	
2658/26050 (epoch 5.102), train_loss = 1.60357156, grad/param norm = 1.9430e-01, time/batch = 0.6421s	
2659/26050 (epoch 5.104), train_loss = 1.64492596, grad/param norm = 2.0822e-01, time/batch = 0.6406s	
2660/26050 (epoch 5.106), train_loss = 1.49129630, grad/param norm = 1.9711e-01, time/batch = 0.6824s	
2661/26050 (epoch 5.107), train_loss = 1.26722923, grad/param norm = 1.8558e-01, time/batch = 0.6597s	
2662/26050 (epoch 5.109), train_loss = 1.44395886, grad/param norm = 1.8448e-01, time/batch = 0.6473s	
2663/26050 (epoch 5.111), train_loss = 1.82924395, grad/param norm = 2.3331e-01, time/batch = 0.6480s	
2664/26050 (epoch 5.113), train_loss = 1.46741481, grad/param norm = 2.0888e-01, time/batch = 0.6492s	
2665/26050 (epoch 5.115), train_loss = 1.70155280, grad/param norm = 2.0063e-01, time/batch = 0.6412s	
2666/26050 (epoch 5.117), train_loss = 1.62056086, grad/param norm = 2.1467e-01, time/batch = 0.6427s	
2667/26050 (epoch 5.119), train_loss = 1.36567407, grad/param norm = 1.9625e-01, time/batch = 0.6457s	
2668/26050 (epoch 5.121), train_loss = 1.58707983, grad/param norm = 2.1214e-01, time/batch = 0.6425s	
2669/26050 (epoch 5.123), train_loss = 1.48906174, grad/param norm = 2.1654e-01, time/batch = 0.6416s	
2670/26050 (epoch 5.125), train_loss = 1.29520097, grad/param norm = 1.7248e-01, time/batch = 0.6441s	
2671/26050 (epoch 5.127), train_loss = 1.34064070, grad/param norm = 1.8947e-01, time/batch = 0.6441s	
2672/26050 (epoch 5.129), train_loss = 1.32571000, grad/param norm = 1.8146e-01, time/batch = 0.6529s	
2673/26050 (epoch 5.131), train_loss = 1.55498775, grad/param norm = 2.1035e-01, time/batch = 0.6624s	
2674/26050 (epoch 5.132), train_loss = 1.47350993, grad/param norm = 1.8777e-01, time/batch = 0.6548s	
2675/26050 (epoch 5.134), train_loss = 1.50810379, grad/param norm = 2.1209e-01, time/batch = 0.6772s	
2676/26050 (epoch 5.136), train_loss = 1.50201811, grad/param norm = 1.8592e-01, time/batch = 0.6728s	
2677/26050 (epoch 5.138), train_loss = 1.45553108, grad/param norm = 2.3792e-01, time/batch = 0.6421s	
2678/26050 (epoch 5.140), train_loss = 1.49812409, grad/param norm = 1.9564e-01, time/batch = 0.6447s	
2679/26050 (epoch 5.142), train_loss = 1.53561684, grad/param norm = 1.9733e-01, time/batch = 0.6462s	
2680/26050 (epoch 5.144), train_loss = 1.38208449, grad/param norm = 1.9807e-01, time/batch = 0.6416s	
2681/26050 (epoch 5.146), train_loss = 1.28621734, grad/param norm = 1.8136e-01, time/batch = 0.6425s	
2682/26050 (epoch 5.148), train_loss = 1.31983194, grad/param norm = 1.7102e-01, time/batch = 0.6462s	
2683/26050 (epoch 5.150), train_loss = 1.55436073, grad/param norm = 2.0574e-01, time/batch = 0.6433s	
2684/26050 (epoch 5.152), train_loss = 1.84055698, grad/param norm = 2.2561e-01, time/batch = 0.6615s	
2685/26050 (epoch 5.154), train_loss = 1.37494948, grad/param norm = 1.9739e-01, time/batch = 0.6517s	
2686/26050 (epoch 5.155), train_loss = 1.37883847, grad/param norm = 1.8498e-01, time/batch = 0.6412s	
2687/26050 (epoch 5.157), train_loss = 1.54416488, grad/param norm = 2.0788e-01, time/batch = 0.6394s	
2688/26050 (epoch 5.159), train_loss = 1.55763575, grad/param norm = 2.1758e-01, time/batch = 0.6413s	
2689/26050 (epoch 5.161), train_loss = 1.77011405, grad/param norm = 2.2052e-01, time/batch = 0.6395s	
2690/26050 (epoch 5.163), train_loss = 1.41788901, grad/param norm = 1.8737e-01, time/batch = 0.6540s	
2691/26050 (epoch 5.165), train_loss = 1.21589242, grad/param norm = 1.7734e-01, time/batch = 0.6835s	
2692/26050 (epoch 5.167), train_loss = 1.68481636, grad/param norm = 2.4508e-01, time/batch = 0.6434s	
2693/26050 (epoch 5.169), train_loss = 1.61314061, grad/param norm = 2.1022e-01, time/batch = 0.6392s	
2694/26050 (epoch 5.171), train_loss = 1.32017536, grad/param norm = 1.6994e-01, time/batch = 0.6466s	
2695/26050 (epoch 5.173), train_loss = 1.50174386, grad/param norm = 2.0955e-01, time/batch = 0.6398s	
2696/26050 (epoch 5.175), train_loss = 1.53923976, grad/param norm = 2.2225e-01, time/batch = 0.6392s	
2697/26050 (epoch 5.177), train_loss = 1.61069279, grad/param norm = 2.0262e-01, time/batch = 0.6391s	
2698/26050 (epoch 5.179), train_loss = 1.21852819, grad/param norm = 1.7755e-01, time/batch = 0.6413s	
2699/26050 (epoch 5.180), train_loss = 1.78139915, grad/param norm = 2.0015e-01, time/batch = 0.6385s	
2700/26050 (epoch 5.182), train_loss = 1.85812745, grad/param norm = 2.1344e-01, time/batch = 0.6396s	
2701/26050 (epoch 5.184), train_loss = 1.58703432, grad/param norm = 1.9812e-01, time/batch = 0.6431s	
2702/26050 (epoch 5.186), train_loss = 1.27757032, grad/param norm = 1.7722e-01, time/batch = 0.6410s	
2703/26050 (epoch 5.188), train_loss = 1.52494184, grad/param norm = 1.8565e-01, time/batch = 0.6399s	
2704/26050 (epoch 5.190), train_loss = 1.61480927, grad/param norm = 2.0972e-01, time/batch = 0.6387s	
2705/26050 (epoch 5.192), train_loss = 1.55261682, grad/param norm = 2.0891e-01, time/batch = 0.6381s	
2706/26050 (epoch 5.194), train_loss = 1.56203236, grad/param norm = 2.0105e-01, time/batch = 0.6385s	
2707/26050 (epoch 5.196), train_loss = 1.64354400, grad/param norm = 2.2302e-01, time/batch = 0.6386s	
2708/26050 (epoch 5.198), train_loss = 1.44235745, grad/param norm = 1.9140e-01, time/batch = 0.6395s	
2709/26050 (epoch 5.200), train_loss = 1.45388222, grad/param norm = 1.9813e-01, time/batch = 0.6414s	
2710/26050 (epoch 5.202), train_loss = 1.45127774, grad/param norm = 1.9995e-01, time/batch = 0.6391s	
2711/26050 (epoch 5.203), train_loss = 1.61780753, grad/param norm = 2.0920e-01, time/batch = 0.6388s	
2712/26050 (epoch 5.205), train_loss = 1.40853360, grad/param norm = 1.9195e-01, time/batch = 0.6384s	
2713/26050 (epoch 5.207), train_loss = 1.48826893, grad/param norm = 1.7661e-01, time/batch = 0.6401s	
2714/26050 (epoch 5.209), train_loss = 1.47415553, grad/param norm = 1.9383e-01, time/batch = 0.6387s	
2715/26050 (epoch 5.211), train_loss = 1.39082078, grad/param norm = 2.0712e-01, time/batch = 0.6377s	
2716/26050 (epoch 5.213), train_loss = 1.57502974, grad/param norm = 1.9252e-01, time/batch = 0.6388s	
2717/26050 (epoch 5.215), train_loss = 1.59138070, grad/param norm = 2.1692e-01, time/batch = 0.6393s	
2718/26050 (epoch 5.217), train_loss = 1.46783878, grad/param norm = 1.9887e-01, time/batch = 0.6391s	
2719/26050 (epoch 5.219), train_loss = 1.45395107, grad/param norm = 2.0454e-01, time/batch = 0.6389s	
2720/26050 (epoch 5.221), train_loss = 1.41022963, grad/param norm = 2.0549e-01, time/batch = 0.6390s	
2721/26050 (epoch 5.223), train_loss = 1.65382207, grad/param norm = 2.2435e-01, time/batch = 0.6403s	
2722/26050 (epoch 5.225), train_loss = 1.42559977, grad/param norm = 2.1312e-01, time/batch = 0.6397s	
2723/26050 (epoch 5.226), train_loss = 1.69707086, grad/param norm = 2.3125e-01, time/batch = 0.6407s	
2724/26050 (epoch 5.228), train_loss = 1.67858675, grad/param norm = 2.2759e-01, time/batch = 0.6401s	
2725/26050 (epoch 5.230), train_loss = 1.53988251, grad/param norm = 2.0187e-01, time/batch = 0.6487s	
2726/26050 (epoch 5.232), train_loss = 1.69827628, grad/param norm = 2.1614e-01, time/batch = 0.6720s	
2727/26050 (epoch 5.234), train_loss = 1.31297226, grad/param norm = 1.8828e-01, time/batch = 0.6728s	
2728/26050 (epoch 5.236), train_loss = 1.55880296, grad/param norm = 2.1094e-01, time/batch = 0.6384s	
2729/26050 (epoch 5.238), train_loss = 1.29258257, grad/param norm = 1.8068e-01, time/batch = 0.6383s	
2730/26050 (epoch 5.240), train_loss = 1.45953349, grad/param norm = 1.8280e-01, time/batch = 0.6387s	
2731/26050 (epoch 5.242), train_loss = 1.49533432, grad/param norm = 1.9329e-01, time/batch = 0.6394s	
2732/26050 (epoch 5.244), train_loss = 1.58735114, grad/param norm = 2.2316e-01, time/batch = 0.6403s	
2733/26050 (epoch 5.246), train_loss = 1.43697292, grad/param norm = 1.8795e-01, time/batch = 0.6396s	
2734/26050 (epoch 5.248), train_loss = 1.62010046, grad/param norm = 2.1726e-01, time/batch = 0.6380s	
2735/26050 (epoch 5.250), train_loss = 1.60893148, grad/param norm = 2.1211e-01, time/batch = 0.6492s	
2736/26050 (epoch 5.251), train_loss = 1.40137356, grad/param norm = 2.0180e-01, time/batch = 0.6406s	
2737/26050 (epoch 5.253), train_loss = 1.32727350, grad/param norm = 1.9365e-01, time/batch = 0.6786s	
2738/26050 (epoch 5.255), train_loss = 1.75768392, grad/param norm = 2.0659e-01, time/batch = 0.6454s	
2739/26050 (epoch 5.257), train_loss = 1.52673367, grad/param norm = 1.9465e-01, time/batch = 0.6412s	
2740/26050 (epoch 5.259), train_loss = 1.64962829, grad/param norm = 2.0822e-01, time/batch = 0.6564s	
2741/26050 (epoch 5.261), train_loss = 1.45232098, grad/param norm = 1.9987e-01, time/batch = 0.9120s	
2742/26050 (epoch 5.263), train_loss = 1.52130403, grad/param norm = 1.9923e-01, time/batch = 1.2405s	
2743/26050 (epoch 5.265), train_loss = 1.72349396, grad/param norm = 1.8865e-01, time/batch = 0.6842s	
2744/26050 (epoch 5.267), train_loss = 1.56873858, grad/param norm = 2.0927e-01, time/batch = 0.6486s	
2745/26050 (epoch 5.269), train_loss = 1.74007829, grad/param norm = 2.2955e-01, time/batch = 0.6436s	
2746/26050 (epoch 5.271), train_loss = 1.51381115, grad/param norm = 1.8625e-01, time/batch = 0.6403s	
2747/26050 (epoch 5.273), train_loss = 1.50649009, grad/param norm = 2.0592e-01, time/batch = 0.6427s	
2748/26050 (epoch 5.274), train_loss = 1.45090968, grad/param norm = 1.9162e-01, time/batch = 0.6388s	
2749/26050 (epoch 5.276), train_loss = 1.41765775, grad/param norm = 1.8545e-01, time/batch = 0.6395s	
2750/26050 (epoch 5.278), train_loss = 1.61550240, grad/param norm = 2.0417e-01, time/batch = 0.6414s	
2751/26050 (epoch 5.280), train_loss = 1.50949198, grad/param norm = 1.8857e-01, time/batch = 0.6859s	
2752/26050 (epoch 5.282), train_loss = 1.55643554, grad/param norm = 2.0175e-01, time/batch = 0.6723s	
2753/26050 (epoch 5.284), train_loss = 1.37017731, grad/param norm = 2.0484e-01, time/batch = 0.6468s	
2754/26050 (epoch 5.286), train_loss = 1.49276519, grad/param norm = 2.1925e-01, time/batch = 0.6471s	
2755/26050 (epoch 5.288), train_loss = 1.36651064, grad/param norm = 1.9165e-01, time/batch = 0.6459s	
2756/26050 (epoch 5.290), train_loss = 1.45430875, grad/param norm = 1.9762e-01, time/batch = 0.6423s	
2757/26050 (epoch 5.292), train_loss = 1.42229593, grad/param norm = 1.8431e-01, time/batch = 0.6412s	
2758/26050 (epoch 5.294), train_loss = 1.55779517, grad/param norm = 2.3114e-01, time/batch = 0.6460s	
2759/26050 (epoch 5.296), train_loss = 1.61857913, grad/param norm = 1.9571e-01, time/batch = 0.6397s	
2760/26050 (epoch 5.298), train_loss = 1.47934684, grad/param norm = 1.8445e-01, time/batch = 0.6406s	
2761/26050 (epoch 5.299), train_loss = 1.24948257, grad/param norm = 1.7011e-01, time/batch = 0.6443s	
2762/26050 (epoch 5.301), train_loss = 1.42484948, grad/param norm = 1.9486e-01, time/batch = 0.6423s	
2763/26050 (epoch 5.303), train_loss = 1.54638751, grad/param norm = 2.0971e-01, time/batch = 0.6407s	
2764/26050 (epoch 5.305), train_loss = 1.40127907, grad/param norm = 1.9434e-01, time/batch = 0.6491s	
2765/26050 (epoch 5.307), train_loss = 1.35291599, grad/param norm = 1.9690e-01, time/batch = 0.6440s	
2766/26050 (epoch 5.309), train_loss = 1.44197361, grad/param norm = 2.0697e-01, time/batch = 0.6653s	
2767/26050 (epoch 5.311), train_loss = 1.73761339, grad/param norm = 2.2029e-01, time/batch = 0.6788s	
2768/26050 (epoch 5.313), train_loss = 1.55659232, grad/param norm = 2.2225e-01, time/batch = 0.6386s	
2769/26050 (epoch 5.315), train_loss = 1.68960250, grad/param norm = 2.2654e-01, time/batch = 0.6399s	
2770/26050 (epoch 5.317), train_loss = 1.40766552, grad/param norm = 1.8928e-01, time/batch = 0.6451s	
2771/26050 (epoch 5.319), train_loss = 1.46563425, grad/param norm = 1.8176e-01, time/batch = 0.6413s	
2772/26050 (epoch 5.321), train_loss = 1.51229194, grad/param norm = 1.8286e-01, time/batch = 0.6398s	
2773/26050 (epoch 5.322), train_loss = 1.52390189, grad/param norm = 1.8680e-01, time/batch = 0.6402s	
2774/26050 (epoch 5.324), train_loss = 1.33051880, grad/param norm = 1.7877e-01, time/batch = 0.6397s	
2775/26050 (epoch 5.326), train_loss = 1.66337241, grad/param norm = 2.1802e-01, time/batch = 0.6388s	
2776/26050 (epoch 5.328), train_loss = 1.54369906, grad/param norm = 1.9098e-01, time/batch = 0.6393s	
2777/26050 (epoch 5.330), train_loss = 1.42818975, grad/param norm = 2.0711e-01, time/batch = 0.6400s	
2778/26050 (epoch 5.332), train_loss = 1.60034769, grad/param norm = 2.0121e-01, time/batch = 0.6394s	
2779/26050 (epoch 5.334), train_loss = 1.47834358, grad/param norm = 2.1139e-01, time/batch = 0.6376s	
2780/26050 (epoch 5.336), train_loss = 1.34517087, grad/param norm = 1.7039e-01, time/batch = 0.6381s	
2781/26050 (epoch 5.338), train_loss = 1.31771963, grad/param norm = 1.8196e-01, time/batch = 0.6463s	
2782/26050 (epoch 5.340), train_loss = 1.61514352, grad/param norm = 2.1404e-01, time/batch = 0.6830s	
2783/26050 (epoch 5.342), train_loss = 1.64486705, grad/param norm = 2.0235e-01, time/batch = 0.6554s	
2784/26050 (epoch 5.344), train_loss = 1.49220854, grad/param norm = 2.0426e-01, time/batch = 0.6385s	
2785/26050 (epoch 5.345), train_loss = 1.51356694, grad/param norm = 2.2239e-01, time/batch = 0.6417s	
2786/26050 (epoch 5.347), train_loss = 1.58822009, grad/param norm = 2.2027e-01, time/batch = 0.6438s	
2787/26050 (epoch 5.349), train_loss = 1.51665541, grad/param norm = 2.0201e-01, time/batch = 0.6382s	
2788/26050 (epoch 5.351), train_loss = 1.55110471, grad/param norm = 2.0862e-01, time/batch = 0.6373s	
2789/26050 (epoch 5.353), train_loss = 1.42321057, grad/param norm = 2.1408e-01, time/batch = 0.6414s	
2790/26050 (epoch 5.355), train_loss = 1.60357592, grad/param norm = 2.1126e-01, time/batch = 0.6424s	
2791/26050 (epoch 5.357), train_loss = 1.34189915, grad/param norm = 1.7337e-01, time/batch = 0.6406s	
2792/26050 (epoch 5.359), train_loss = 1.57747272, grad/param norm = 1.9122e-01, time/batch = 0.6425s	
2793/26050 (epoch 5.361), train_loss = 1.35263985, grad/param norm = 1.8649e-01, time/batch = 0.6391s	
2794/26050 (epoch 5.363), train_loss = 1.48174005, grad/param norm = 1.9025e-01, time/batch = 0.6398s	
2795/26050 (epoch 5.365), train_loss = 1.38081873, grad/param norm = 1.8062e-01, time/batch = 0.6391s	
2796/26050 (epoch 5.367), train_loss = 1.50243000, grad/param norm = 1.9977e-01, time/batch = 0.6381s	
2797/26050 (epoch 5.369), train_loss = 1.47519070, grad/param norm = 1.8491e-01, time/batch = 0.6686s	
2798/26050 (epoch 5.370), train_loss = 1.38846574, grad/param norm = 1.9044e-01, time/batch = 0.6735s	
2799/26050 (epoch 5.372), train_loss = 1.67309037, grad/param norm = 2.1854e-01, time/batch = 0.6380s	
2800/26050 (epoch 5.374), train_loss = 1.71472093, grad/param norm = 2.1812e-01, time/batch = 0.6426s	
2801/26050 (epoch 5.376), train_loss = 1.74619026, grad/param norm = 1.9100e-01, time/batch = 0.6467s	
2802/26050 (epoch 5.378), train_loss = 1.49197447, grad/param norm = 2.0078e-01, time/batch = 0.6426s	
2803/26050 (epoch 5.380), train_loss = 1.70534898, grad/param norm = 2.0935e-01, time/batch = 0.6426s	
2804/26050 (epoch 5.382), train_loss = 1.90077296, grad/param norm = 2.2348e-01, time/batch = 0.6440s	
2805/26050 (epoch 5.384), train_loss = 1.46367839, grad/param norm = 1.9630e-01, time/batch = 0.6427s	
2806/26050 (epoch 5.386), train_loss = 1.60135632, grad/param norm = 1.9490e-01, time/batch = 0.6421s	
2807/26050 (epoch 5.388), train_loss = 1.55852792, grad/param norm = 1.8535e-01, time/batch = 0.6427s	
2808/26050 (epoch 5.390), train_loss = 1.37707011, grad/param norm = 1.7341e-01, time/batch = 0.6431s	
2809/26050 (epoch 5.392), train_loss = 1.40575308, grad/param norm = 1.9298e-01, time/batch = 0.6465s	
2810/26050 (epoch 5.393), train_loss = 1.56838173, grad/param norm = 1.9263e-01, time/batch = 0.6525s	
2811/26050 (epoch 5.395), train_loss = 1.57687144, grad/param norm = 2.0451e-01, time/batch = 0.6510s	
2812/26050 (epoch 5.397), train_loss = 1.57186114, grad/param norm = 1.9640e-01, time/batch = 0.6668s	
2813/26050 (epoch 5.399), train_loss = 1.37663370, grad/param norm = 1.7769e-01, time/batch = 0.6838s	
2814/26050 (epoch 5.401), train_loss = 1.45042813, grad/param norm = 1.9116e-01, time/batch = 0.6614s	
2815/26050 (epoch 5.403), train_loss = 1.50988493, grad/param norm = 2.0196e-01, time/batch = 0.6531s	
2816/26050 (epoch 5.405), train_loss = 1.51608501, grad/param norm = 2.0769e-01, time/batch = 0.6558s	
2817/26050 (epoch 5.407), train_loss = 1.67214215, grad/param norm = 2.0213e-01, time/batch = 0.6507s	
2818/26050 (epoch 5.409), train_loss = 1.69867995, grad/param norm = 2.1138e-01, time/batch = 0.6513s	
2819/26050 (epoch 5.411), train_loss = 1.53591980, grad/param norm = 1.9984e-01, time/batch = 0.6518s	
2820/26050 (epoch 5.413), train_loss = 1.65825644, grad/param norm = 1.9071e-01, time/batch = 0.6553s	
2821/26050 (epoch 5.415), train_loss = 1.66174239, grad/param norm = 2.1153e-01, time/batch = 0.6523s	
2822/26050 (epoch 5.417), train_loss = 1.70133737, grad/param norm = 2.0908e-01, time/batch = 0.6557s	
2823/26050 (epoch 5.418), train_loss = 1.59572708, grad/param norm = 1.9937e-01, time/batch = 0.6493s	
2824/26050 (epoch 5.420), train_loss = 1.27675629, grad/param norm = 1.7268e-01, time/batch = 0.6495s	
2825/26050 (epoch 5.422), train_loss = 1.37352481, grad/param norm = 2.0577e-01, time/batch = 0.6564s	
2826/26050 (epoch 5.424), train_loss = 1.79503878, grad/param norm = 2.3821e-01, time/batch = 0.6474s	
2827/26050 (epoch 5.426), train_loss = 1.73334756, grad/param norm = 2.4396e-01, time/batch = 0.6462s	
2828/26050 (epoch 5.428), train_loss = 1.41470168, grad/param norm = 1.7805e-01, time/batch = 0.6830s	
2829/26050 (epoch 5.430), train_loss = 1.54745913, grad/param norm = 2.0609e-01, time/batch = 0.6539s	
2830/26050 (epoch 5.432), train_loss = 1.49840211, grad/param norm = 2.0011e-01, time/batch = 0.6502s	
2831/26050 (epoch 5.434), train_loss = 1.56377041, grad/param norm = 1.8555e-01, time/batch = 0.6524s	
2832/26050 (epoch 5.436), train_loss = 1.68420778, grad/param norm = 1.9548e-01, time/batch = 0.6495s	
2833/26050 (epoch 5.438), train_loss = 1.41560773, grad/param norm = 1.8625e-01, time/batch = 0.6557s	
2834/26050 (epoch 5.440), train_loss = 1.53771516, grad/param norm = 2.0076e-01, time/batch = 0.6445s	
2835/26050 (epoch 5.441), train_loss = 1.50480869, grad/param norm = 2.0599e-01, time/batch = 0.6523s	
2836/26050 (epoch 5.443), train_loss = 1.31338248, grad/param norm = 1.6938e-01, time/batch = 0.6466s	
2837/26050 (epoch 5.445), train_loss = 1.38121464, grad/param norm = 1.9342e-01, time/batch = 0.6408s	
2838/26050 (epoch 5.447), train_loss = 1.75946919, grad/param norm = 2.0377e-01, time/batch = 0.6444s	
2839/26050 (epoch 5.449), train_loss = 1.40544256, grad/param norm = 1.9416e-01, time/batch = 0.6410s	
2840/26050 (epoch 5.451), train_loss = 1.56250419, grad/param norm = 1.7928e-01, time/batch = 0.6394s	
2841/26050 (epoch 5.453), train_loss = 1.35754325, grad/param norm = 1.7304e-01, time/batch = 0.6412s	
2842/26050 (epoch 5.455), train_loss = 1.53067618, grad/param norm = 1.9664e-01, time/batch = 0.6423s	
2843/26050 (epoch 5.457), train_loss = 1.58016291, grad/param norm = 2.1869e-01, time/batch = 0.6796s	
2844/26050 (epoch 5.459), train_loss = 1.65236816, grad/param norm = 2.1454e-01, time/batch = 0.6702s	
2845/26050 (epoch 5.461), train_loss = 1.59590534, grad/param norm = 2.0454e-01, time/batch = 0.6410s	
2846/26050 (epoch 5.463), train_loss = 1.43825150, grad/param norm = 1.8031e-01, time/batch = 0.6454s	
2847/26050 (epoch 5.464), train_loss = 1.60529632, grad/param norm = 2.1320e-01, time/batch = 0.6447s	
2848/26050 (epoch 5.466), train_loss = 1.62540049, grad/param norm = 1.8874e-01, time/batch = 0.6409s	
2849/26050 (epoch 5.468), train_loss = 1.62150190, grad/param norm = 1.8976e-01, time/batch = 0.6398s	
2850/26050 (epoch 5.470), train_loss = 1.75862951, grad/param norm = 2.1902e-01, time/batch = 0.6446s	
2851/26050 (epoch 5.472), train_loss = 1.79486677, grad/param norm = 2.1253e-01, time/batch = 0.6426s	
2852/26050 (epoch 5.474), train_loss = 1.82346192, grad/param norm = 2.0112e-01, time/batch = 0.6436s	
2853/26050 (epoch 5.476), train_loss = 1.62729213, grad/param norm = 1.8421e-01, time/batch = 0.6429s	
2854/26050 (epoch 5.478), train_loss = 1.43617319, grad/param norm = 1.8074e-01, time/batch = 0.6407s	
2855/26050 (epoch 5.480), train_loss = 1.55092862, grad/param norm = 1.8303e-01, time/batch = 0.6400s	
2856/26050 (epoch 5.482), train_loss = 1.49710460, grad/param norm = 1.9703e-01, time/batch = 0.6389s	
2857/26050 (epoch 5.484), train_loss = 1.37431342, grad/param norm = 1.9604e-01, time/batch = 0.6398s	
2858/26050 (epoch 5.486), train_loss = 1.70671457, grad/param norm = 2.1572e-01, time/batch = 0.6563s	
2859/26050 (epoch 5.488), train_loss = 1.90605824, grad/param norm = 2.1491e-01, time/batch = 0.6670s	
2860/26050 (epoch 5.489), train_loss = 1.78281816, grad/param norm = 2.0821e-01, time/batch = 0.6503s	
2861/26050 (epoch 5.491), train_loss = 1.46116443, grad/param norm = 1.9884e-01, time/batch = 0.6428s	
2862/26050 (epoch 5.493), train_loss = 1.44459763, grad/param norm = 1.8528e-01, time/batch = 0.6437s	
2863/26050 (epoch 5.495), train_loss = 1.52867717, grad/param norm = 2.1263e-01, time/batch = 0.6451s	
2864/26050 (epoch 5.497), train_loss = 1.45637733, grad/param norm = 1.9524e-01, time/batch = 0.6566s	
2865/26050 (epoch 5.499), train_loss = 1.47104509, grad/param norm = 2.1290e-01, time/batch = 0.6515s	
2866/26050 (epoch 5.501), train_loss = 1.50901293, grad/param norm = 2.0198e-01, time/batch = 0.6684s	
2867/26050 (epoch 5.503), train_loss = 1.45728292, grad/param norm = 1.9553e-01, time/batch = 0.6763s	
2868/26050 (epoch 5.505), train_loss = 1.64048144, grad/param norm = 1.9618e-01, time/batch = 0.6760s	
2869/26050 (epoch 5.507), train_loss = 1.65475853, grad/param norm = 2.1273e-01, time/batch = 0.6716s	
2870/26050 (epoch 5.509), train_loss = 1.78678595, grad/param norm = 2.1607e-01, time/batch = 0.6652s	
2871/26050 (epoch 5.511), train_loss = 1.43502090, grad/param norm = 1.9653e-01, time/batch = 0.6495s	
2872/26050 (epoch 5.512), train_loss = 1.59967913, grad/param norm = 2.1887e-01, time/batch = 0.6429s	
2873/26050 (epoch 5.514), train_loss = 1.61081611, grad/param norm = 1.9221e-01, time/batch = 0.6471s	
2874/26050 (epoch 5.516), train_loss = 1.64862557, grad/param norm = 2.0566e-01, time/batch = 0.6643s	
2875/26050 (epoch 5.518), train_loss = 1.60999673, grad/param norm = 2.1502e-01, time/batch = 0.6458s	
2876/26050 (epoch 5.520), train_loss = 1.56021327, grad/param norm = 2.0155e-01, time/batch = 0.6432s	
2877/26050 (epoch 5.522), train_loss = 1.43536466, grad/param norm = 1.9225e-01, time/batch = 0.6445s	
2878/26050 (epoch 5.524), train_loss = 1.79748146, grad/param norm = 2.1634e-01, time/batch = 0.6472s	
2879/26050 (epoch 5.526), train_loss = 1.61513027, grad/param norm = 2.0442e-01, time/batch = 0.6400s	
2880/26050 (epoch 5.528), train_loss = 1.61839788, grad/param norm = 2.0782e-01, time/batch = 0.6405s	
2881/26050 (epoch 5.530), train_loss = 1.52535615, grad/param norm = 1.9546e-01, time/batch = 0.6443s	
2882/26050 (epoch 5.532), train_loss = 1.56564691, grad/param norm = 1.9131e-01, time/batch = 0.6482s	
2883/26050 (epoch 5.534), train_loss = 1.63812739, grad/param norm = 2.0277e-01, time/batch = 0.6390s	
2884/26050 (epoch 5.536), train_loss = 1.46693500, grad/param norm = 2.0464e-01, time/batch = 0.6421s	
2885/26050 (epoch 5.537), train_loss = 1.65945386, grad/param norm = 1.8847e-01, time/batch = 0.6393s	
2886/26050 (epoch 5.539), train_loss = 1.50841630, grad/param norm = 1.9019e-01, time/batch = 0.6392s	
2887/26050 (epoch 5.541), train_loss = 1.73590889, grad/param norm = 2.2864e-01, time/batch = 0.6568s	
2888/26050 (epoch 5.543), train_loss = 1.35369754, grad/param norm = 1.9471e-01, time/batch = 0.6662s	
2889/26050 (epoch 5.545), train_loss = 1.60827641, grad/param norm = 2.1011e-01, time/batch = 0.6822s	
2890/26050 (epoch 5.547), train_loss = 1.57838290, grad/param norm = 2.0632e-01, time/batch = 0.6724s	
2891/26050 (epoch 5.549), train_loss = 1.39495198, grad/param norm = 1.9337e-01, time/batch = 0.6613s	
2892/26050 (epoch 5.551), train_loss = 1.60123686, grad/param norm = 2.2120e-01, time/batch = 0.6571s	
2893/26050 (epoch 5.553), train_loss = 1.47542168, grad/param norm = 2.0366e-01, time/batch = 0.6416s	
2894/26050 (epoch 5.555), train_loss = 1.48072030, grad/param norm = 1.9480e-01, time/batch = 0.6508s	
2895/26050 (epoch 5.557), train_loss = 1.63244569, grad/param norm = 1.9737e-01, time/batch = 0.6571s	
2896/26050 (epoch 5.559), train_loss = 1.56215216, grad/param norm = 2.1048e-01, time/batch = 0.6581s	
2897/26050 (epoch 5.560), train_loss = 1.54480826, grad/param norm = 2.0377e-01, time/batch = 0.6559s	
2898/26050 (epoch 5.562), train_loss = 1.52809990, grad/param norm = 2.0396e-01, time/batch = 0.6576s	
2899/26050 (epoch 5.564), train_loss = 1.74149909, grad/param norm = 2.2974e-01, time/batch = 0.6530s	
2900/26050 (epoch 5.566), train_loss = 1.43089500, grad/param norm = 1.9585e-01, time/batch = 0.6400s	
2901/26050 (epoch 5.568), train_loss = 1.57673113, grad/param norm = 1.9006e-01, time/batch = 0.6432s	
2902/26050 (epoch 5.570), train_loss = 1.67011930, grad/param norm = 2.0830e-01, time/batch = 0.6399s	
2903/26050 (epoch 5.572), train_loss = 1.58314991, grad/param norm = 1.9425e-01, time/batch = 0.6394s	
2904/26050 (epoch 5.574), train_loss = 1.67808680, grad/param norm = 2.3846e-01, time/batch = 0.6471s	
2905/26050 (epoch 5.576), train_loss = 1.64995246, grad/param norm = 2.0897e-01, time/batch = 0.6517s	
2906/26050 (epoch 5.578), train_loss = 1.56488622, grad/param norm = 2.0921e-01, time/batch = 0.6615s	
2907/26050 (epoch 5.580), train_loss = 1.42327312, grad/param norm = 1.8386e-01, time/batch = 0.6482s	
2908/26050 (epoch 5.582), train_loss = 1.61026933, grad/param norm = 1.9613e-01, time/batch = 0.6462s	
2909/26050 (epoch 5.583), train_loss = 1.61596079, grad/param norm = 1.9709e-01, time/batch = 0.6425s	
2910/26050 (epoch 5.585), train_loss = 1.42079139, grad/param norm = 1.9170e-01, time/batch = 0.6401s	
2911/26050 (epoch 5.587), train_loss = 1.61918147, grad/param norm = 1.9483e-01, time/batch = 0.6401s	
2912/26050 (epoch 5.589), train_loss = 1.63121079, grad/param norm = 2.2304e-01, time/batch = 0.6408s	
2913/26050 (epoch 5.591), train_loss = 1.60838596, grad/param norm = 1.9273e-01, time/batch = 0.6402s	
2914/26050 (epoch 5.593), train_loss = 1.44075467, grad/param norm = 2.1141e-01, time/batch = 0.6414s	
2915/26050 (epoch 5.595), train_loss = 1.72412994, grad/param norm = 2.4526e-01, time/batch = 0.6425s	
2916/26050 (epoch 5.597), train_loss = 1.58647904, grad/param norm = 2.1313e-01, time/batch = 0.6408s	
2917/26050 (epoch 5.599), train_loss = 1.40250049, grad/param norm = 1.7683e-01, time/batch = 0.6392s	
2918/26050 (epoch 5.601), train_loss = 1.75222550, grad/param norm = 2.0308e-01, time/batch = 0.6398s	
2919/26050 (epoch 5.603), train_loss = 1.63011790, grad/param norm = 2.0014e-01, time/batch = 0.6392s	
2920/26050 (epoch 5.605), train_loss = 1.46583407, grad/param norm = 1.7384e-01, time/batch = 0.6385s	
2921/26050 (epoch 5.607), train_loss = 1.65711063, grad/param norm = 2.0197e-01, time/batch = 0.6408s	
2922/26050 (epoch 5.608), train_loss = 1.49274197, grad/param norm = 1.8297e-01, time/batch = 0.6556s	
2923/26050 (epoch 5.610), train_loss = 1.53620945, grad/param norm = 2.1470e-01, time/batch = 0.6555s	
2924/26050 (epoch 5.612), train_loss = 1.49205339, grad/param norm = 2.0616e-01, time/batch = 0.6537s	
2925/26050 (epoch 5.614), train_loss = 1.58420182, grad/param norm = 1.9957e-01, time/batch = 0.6430s	
2926/26050 (epoch 5.616), train_loss = 1.84290876, grad/param norm = 2.0563e-01, time/batch = 0.6421s	
2927/26050 (epoch 5.618), train_loss = 1.47057859, grad/param norm = 2.0069e-01, time/batch = 0.6394s	
2928/26050 (epoch 5.620), train_loss = 1.58300185, grad/param norm = 2.2365e-01, time/batch = 0.6422s	
2929/26050 (epoch 5.622), train_loss = 1.28649338, grad/param norm = 1.7655e-01, time/batch = 0.6401s	
2930/26050 (epoch 5.624), train_loss = 1.41570997, grad/param norm = 1.7942e-01, time/batch = 0.6604s	
2931/26050 (epoch 5.626), train_loss = 1.55070140, grad/param norm = 2.0625e-01, time/batch = 0.6840s	
2932/26050 (epoch 5.628), train_loss = 1.55972340, grad/param norm = 2.1518e-01, time/batch = 0.6632s	
2933/26050 (epoch 5.630), train_loss = 1.67020748, grad/param norm = 1.9628e-01, time/batch = 0.6441s	
2934/26050 (epoch 5.631), train_loss = 1.66101343, grad/param norm = 2.0862e-01, time/batch = 0.6403s	
2935/26050 (epoch 5.633), train_loss = 1.39774643, grad/param norm = 1.7650e-01, time/batch = 0.6416s	
2936/26050 (epoch 5.635), train_loss = 1.40798180, grad/param norm = 1.8361e-01, time/batch = 0.6400s	
2937/26050 (epoch 5.637), train_loss = 1.42990300, grad/param norm = 1.8847e-01, time/batch = 0.6415s	
2938/26050 (epoch 5.639), train_loss = 1.64225182, grad/param norm = 2.0320e-01, time/batch = 0.6421s	
2939/26050 (epoch 5.641), train_loss = 1.45302629, grad/param norm = 1.7010e-01, time/batch = 0.6446s	
2940/26050 (epoch 5.643), train_loss = 1.42979139, grad/param norm = 1.8051e-01, time/batch = 0.6399s	
2941/26050 (epoch 5.645), train_loss = 1.60212828, grad/param norm = 2.0435e-01, time/batch = 0.6425s	
2942/26050 (epoch 5.647), train_loss = 1.46378236, grad/param norm = 1.9065e-01, time/batch = 0.6485s	
2943/26050 (epoch 5.649), train_loss = 1.58000441, grad/param norm = 2.0843e-01, time/batch = 0.6412s	
2944/26050 (epoch 5.651), train_loss = 1.50426825, grad/param norm = 1.9256e-01, time/batch = 0.6436s	
2945/26050 (epoch 5.653), train_loss = 1.50234137, grad/param norm = 1.9888e-01, time/batch = 0.6423s	
2946/26050 (epoch 5.655), train_loss = 1.43354942, grad/param norm = 1.9856e-01, time/batch = 0.6414s	
2947/26050 (epoch 5.656), train_loss = 1.42087042, grad/param norm = 1.8828e-01, time/batch = 0.6482s	
2948/26050 (epoch 5.658), train_loss = 1.71495323, grad/param norm = 2.1360e-01, time/batch = 0.6455s	
2949/26050 (epoch 5.660), train_loss = 1.42403529, grad/param norm = 2.1770e-01, time/batch = 0.6424s	
2950/26050 (epoch 5.662), train_loss = 1.38169941, grad/param norm = 1.8906e-01, time/batch = 0.6386s	
2951/26050 (epoch 5.664), train_loss = 1.50057666, grad/param norm = 2.1057e-01, time/batch = 0.6387s	
2952/26050 (epoch 5.666), train_loss = 1.57042052, grad/param norm = 2.1660e-01, time/batch = 0.6442s	
2953/26050 (epoch 5.668), train_loss = 1.27883166, grad/param norm = 1.7017e-01, time/batch = 0.6437s	
2954/26050 (epoch 5.670), train_loss = 1.71165668, grad/param norm = 2.2523e-01, time/batch = 0.6389s	
2955/26050 (epoch 5.672), train_loss = 1.42357450, grad/param norm = 1.8778e-01, time/batch = 0.6418s	
2956/26050 (epoch 5.674), train_loss = 1.39634968, grad/param norm = 1.8046e-01, time/batch = 0.6380s	
2957/26050 (epoch 5.676), train_loss = 1.54619203, grad/param norm = 1.9985e-01, time/batch = 0.6375s	
2958/26050 (epoch 5.678), train_loss = 1.70899153, grad/param norm = 2.0747e-01, time/batch = 0.6383s	
2959/26050 (epoch 5.679), train_loss = 1.67776398, grad/param norm = 2.1779e-01, time/batch = 0.6404s	
2960/26050 (epoch 5.681), train_loss = 1.54506730, grad/param norm = 2.1221e-01, time/batch = 0.6397s	
2961/26050 (epoch 5.683), train_loss = 1.46648508, grad/param norm = 2.0160e-01, time/batch = 0.6452s	
2962/26050 (epoch 5.685), train_loss = 1.46382763, grad/param norm = 1.8500e-01, time/batch = 0.6416s	
2963/26050 (epoch 5.687), train_loss = 1.31043713, grad/param norm = 1.7618e-01, time/batch = 0.6393s	
2964/26050 (epoch 5.689), train_loss = 1.51625781, grad/param norm = 1.9481e-01, time/batch = 0.6396s	
2965/26050 (epoch 5.691), train_loss = 1.24036294, grad/param norm = 1.8543e-01, time/batch = 0.6383s	
2966/26050 (epoch 5.693), train_loss = 1.42956015, grad/param norm = 2.0150e-01, time/batch = 0.6756s	
2967/26050 (epoch 5.695), train_loss = 1.55925567, grad/param norm = 1.9940e-01, time/batch = 0.6673s	
2968/26050 (epoch 5.697), train_loss = 1.37466453, grad/param norm = 1.9887e-01, time/batch = 0.6390s	
2969/26050 (epoch 5.699), train_loss = 1.57981313, grad/param norm = 2.0676e-01, time/batch = 0.6509s	
2970/26050 (epoch 5.701), train_loss = 1.34181456, grad/param norm = 1.8143e-01, time/batch = 0.6420s	
2971/26050 (epoch 5.702), train_loss = 1.77101105, grad/param norm = 1.9281e-01, time/batch = 0.6402s	
2972/26050 (epoch 5.704), train_loss = 1.51519221, grad/param norm = 1.9204e-01, time/batch = 0.6428s	
2973/26050 (epoch 5.706), train_loss = 1.62982700, grad/param norm = 2.1896e-01, time/batch = 0.6410s	
2974/26050 (epoch 5.708), train_loss = 1.60006531, grad/param norm = 1.9523e-01, time/batch = 0.6414s	
2975/26050 (epoch 5.710), train_loss = 1.61681546, grad/param norm = 2.0392e-01, time/batch = 0.6409s	
2976/26050 (epoch 5.712), train_loss = 1.71718982, grad/param norm = 2.1140e-01, time/batch = 0.6474s	
2977/26050 (epoch 5.714), train_loss = 1.41508751, grad/param norm = 2.0914e-01, time/batch = 0.6584s	
2978/26050 (epoch 5.716), train_loss = 1.77050359, grad/param norm = 2.4074e-01, time/batch = 0.6451s	
2979/26050 (epoch 5.718), train_loss = 1.63395446, grad/param norm = 2.2271e-01, time/batch = 0.6395s	
2980/26050 (epoch 5.720), train_loss = 1.44812767, grad/param norm = 1.9871e-01, time/batch = 0.6403s	
2981/26050 (epoch 5.722), train_loss = 1.40210310, grad/param norm = 2.0214e-01, time/batch = 0.6617s	
2982/26050 (epoch 5.724), train_loss = 1.38094543, grad/param norm = 1.9079e-01, time/batch = 0.6645s	
2983/26050 (epoch 5.726), train_loss = 1.62703345, grad/param norm = 1.9674e-01, time/batch = 0.6419s	
2984/26050 (epoch 5.727), train_loss = 1.59277946, grad/param norm = 1.9865e-01, time/batch = 0.6418s	
2985/26050 (epoch 5.729), train_loss = 1.62383925, grad/param norm = 2.2312e-01, time/batch = 0.6468s	
2986/26050 (epoch 5.731), train_loss = 1.50287604, grad/param norm = 1.8220e-01, time/batch = 0.6417s	
2987/26050 (epoch 5.733), train_loss = 1.55209362, grad/param norm = 2.3272e-01, time/batch = 0.6499s	
2988/26050 (epoch 5.735), train_loss = 1.73883455, grad/param norm = 2.1051e-01, time/batch = 0.6464s	
2989/26050 (epoch 5.737), train_loss = 1.57025540, grad/param norm = 2.0324e-01, time/batch = 0.6494s	
2990/26050 (epoch 5.739), train_loss = 1.56884471, grad/param norm = 1.9346e-01, time/batch = 0.6569s	
2991/26050 (epoch 5.741), train_loss = 1.41878563, grad/param norm = 1.8111e-01, time/batch = 0.6477s	
2992/26050 (epoch 5.743), train_loss = 1.64461262, grad/param norm = 2.2683e-01, time/batch = 0.6422s	
2993/26050 (epoch 5.745), train_loss = 1.39528608, grad/param norm = 1.9659e-01, time/batch = 0.6399s	
2994/26050 (epoch 5.747), train_loss = 1.45203964, grad/param norm = 1.9734e-01, time/batch = 0.6388s	
2995/26050 (epoch 5.749), train_loss = 1.60401265, grad/param norm = 2.1108e-01, time/batch = 0.6406s	
2996/26050 (epoch 5.750), train_loss = 1.47857264, grad/param norm = 1.8312e-01, time/batch = 0.6444s	
2997/26050 (epoch 5.752), train_loss = 1.60096229, grad/param norm = 2.1810e-01, time/batch = 0.6826s	
2998/26050 (epoch 5.754), train_loss = 1.44806699, grad/param norm = 1.9758e-01, time/batch = 0.6566s	
2999/26050 (epoch 5.756), train_loss = 1.62779090, grad/param norm = 2.3275e-01, time/batch = 0.6442s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch5.76_1.6913.t7	
3000/26050 (epoch 5.758), train_loss = 1.56593005, grad/param norm = 2.1170e-01, time/batch = 0.6411s	
3001/26050 (epoch 5.760), train_loss = 1.71657079, grad/param norm = 2.1707e-01, time/batch = 0.6478s	
3002/26050 (epoch 5.762), train_loss = 1.45526302, grad/param norm = 1.9644e-01, time/batch = 0.6398s	
3003/26050 (epoch 5.764), train_loss = 1.64192462, grad/param norm = 2.0619e-01, time/batch = 0.6404s	
3004/26050 (epoch 5.766), train_loss = 1.63161855, grad/param norm = 2.1349e-01, time/batch = 0.6517s	
3005/26050 (epoch 5.768), train_loss = 1.45256317, grad/param norm = 1.7592e-01, time/batch = 0.6837s	
3006/26050 (epoch 5.770), train_loss = 1.53490738, grad/param norm = 2.0147e-01, time/batch = 0.6590s	
3007/26050 (epoch 5.772), train_loss = 1.53526662, grad/param norm = 2.0194e-01, time/batch = 0.6620s	
3008/26050 (epoch 5.774), train_loss = 1.44464789, grad/param norm = 1.8892e-01, time/batch = 0.6573s	
3009/26050 (epoch 5.775), train_loss = 1.26241356, grad/param norm = 1.9799e-01, time/batch = 0.6576s	
3010/26050 (epoch 5.777), train_loss = 1.44432022, grad/param norm = 1.9518e-01, time/batch = 0.6466s	
3011/26050 (epoch 5.779), train_loss = 1.50609956, grad/param norm = 2.0851e-01, time/batch = 0.6440s	
3012/26050 (epoch 5.781), train_loss = 1.46690429, grad/param norm = 1.8748e-01, time/batch = 0.6383s	
3013/26050 (epoch 5.783), train_loss = 1.44480485, grad/param norm = 1.7144e-01, time/batch = 0.6410s	
3014/26050 (epoch 5.785), train_loss = 1.49842679, grad/param norm = 2.1809e-01, time/batch = 0.6375s	
3015/26050 (epoch 5.787), train_loss = 1.46563608, grad/param norm = 1.8899e-01, time/batch = 0.6451s	
3016/26050 (epoch 5.789), train_loss = 1.53667288, grad/param norm = 2.0936e-01, time/batch = 0.6413s	
3017/26050 (epoch 5.791), train_loss = 1.54346768, grad/param norm = 1.8737e-01, time/batch = 0.6373s	
3018/26050 (epoch 5.793), train_loss = 1.50904711, grad/param norm = 2.0185e-01, time/batch = 0.6427s	
3019/26050 (epoch 5.795), train_loss = 1.38278881, grad/param norm = 1.8416e-01, time/batch = 0.6529s	
3020/26050 (epoch 5.797), train_loss = 1.40699886, grad/param norm = 1.8007e-01, time/batch = 0.6803s	
3021/26050 (epoch 5.798), train_loss = 1.38973921, grad/param norm = 2.0018e-01, time/batch = 0.6629s	
3022/26050 (epoch 5.800), train_loss = 1.37174307, grad/param norm = 1.8975e-01, time/batch = 0.6403s	
3023/26050 (epoch 5.802), train_loss = 1.53391310, grad/param norm = 1.9730e-01, time/batch = 0.6443s	
3024/26050 (epoch 5.804), train_loss = 1.50318116, grad/param norm = 1.9491e-01, time/batch = 0.6511s	
3025/26050 (epoch 5.806), train_loss = 1.70535196, grad/param norm = 2.2169e-01, time/batch = 0.6398s	
3026/26050 (epoch 5.808), train_loss = 1.46842861, grad/param norm = 1.9005e-01, time/batch = 0.6504s	
3027/26050 (epoch 5.810), train_loss = 1.42133651, grad/param norm = 2.1260e-01, time/batch = 0.6527s	
3028/26050 (epoch 5.812), train_loss = 1.38076137, grad/param norm = 1.9104e-01, time/batch = 0.6422s	
3029/26050 (epoch 5.814), train_loss = 1.41707879, grad/param norm = 2.1300e-01, time/batch = 0.6405s	
3030/26050 (epoch 5.816), train_loss = 1.57317463, grad/param norm = 2.0182e-01, time/batch = 0.6411s	
3031/26050 (epoch 5.818), train_loss = 1.69074159, grad/param norm = 2.2979e-01, time/batch = 0.6421s	
3032/26050 (epoch 5.820), train_loss = 1.56322223, grad/param norm = 2.0655e-01, time/batch = 0.6401s	
3033/26050 (epoch 5.821), train_loss = 1.70535422, grad/param norm = 2.1832e-01, time/batch = 0.6399s	
3034/26050 (epoch 5.823), train_loss = 1.74570205, grad/param norm = 2.0924e-01, time/batch = 0.6402s	
3035/26050 (epoch 5.825), train_loss = 1.44376368, grad/param norm = 2.0293e-01, time/batch = 0.6408s	
3036/26050 (epoch 5.827), train_loss = 1.59911826, grad/param norm = 2.2100e-01, time/batch = 0.6397s	
3037/26050 (epoch 5.829), train_loss = 1.60693731, grad/param norm = 1.9318e-01, time/batch = 0.6455s	
3038/26050 (epoch 5.831), train_loss = 1.67235151, grad/param norm = 2.0006e-01, time/batch = 0.6448s	
3039/26050 (epoch 5.833), train_loss = 1.72210158, grad/param norm = 2.0814e-01, time/batch = 0.6463s	
3040/26050 (epoch 5.835), train_loss = 1.79423439, grad/param norm = 2.0950e-01, time/batch = 0.6413s	
3041/26050 (epoch 5.837), train_loss = 1.45711425, grad/param norm = 1.9192e-01, time/batch = 0.6415s	
3042/26050 (epoch 5.839), train_loss = 1.63416232, grad/param norm = 1.8965e-01, time/batch = 0.6410s	
3043/26050 (epoch 5.841), train_loss = 1.62474003, grad/param norm = 1.9216e-01, time/batch = 0.6415s	
3044/26050 (epoch 5.843), train_loss = 1.58995686, grad/param norm = 1.9505e-01, time/batch = 0.6422s	
3045/26050 (epoch 5.845), train_loss = 1.45321105, grad/param norm = 1.9644e-01, time/batch = 0.6412s	
3046/26050 (epoch 5.846), train_loss = 1.65361940, grad/param norm = 2.0089e-01, time/batch = 0.6417s	
3047/26050 (epoch 5.848), train_loss = 1.46803967, grad/param norm = 1.9183e-01, time/batch = 0.6433s	
3048/26050 (epoch 5.850), train_loss = 1.46651378, grad/param norm = 1.8202e-01, time/batch = 0.6439s	
3049/26050 (epoch 5.852), train_loss = 1.51525008, grad/param norm = 2.1721e-01, time/batch = 0.6567s	
3050/26050 (epoch 5.854), train_loss = 1.55525864, grad/param norm = 2.0359e-01, time/batch = 0.6429s	
3051/26050 (epoch 5.856), train_loss = 1.41938109, grad/param norm = 1.8713e-01, time/batch = 0.6834s	
3052/26050 (epoch 5.858), train_loss = 1.38780270, grad/param norm = 1.9997e-01, time/batch = 0.6553s	
3053/26050 (epoch 5.860), train_loss = 1.54420407, grad/param norm = 2.1110e-01, time/batch = 0.6421s	
3054/26050 (epoch 5.862), train_loss = 1.53538998, grad/param norm = 2.0589e-01, time/batch = 0.6648s	
3055/26050 (epoch 5.864), train_loss = 1.45717831, grad/param norm = 1.9633e-01, time/batch = 0.6611s	
3056/26050 (epoch 5.866), train_loss = 1.40228537, grad/param norm = 1.8545e-01, time/batch = 0.6605s	
3057/26050 (epoch 5.868), train_loss = 1.65310932, grad/param norm = 2.1000e-01, time/batch = 0.6581s	
3058/26050 (epoch 5.869), train_loss = 1.36128293, grad/param norm = 1.7625e-01, time/batch = 0.6598s	
3059/26050 (epoch 5.871), train_loss = 1.30493207, grad/param norm = 1.7607e-01, time/batch = 0.6517s	
3060/26050 (epoch 5.873), train_loss = 1.50707986, grad/param norm = 1.9358e-01, time/batch = 0.6497s	
3061/26050 (epoch 5.875), train_loss = 1.50329694, grad/param norm = 2.0483e-01, time/batch = 0.6603s	
3062/26050 (epoch 5.877), train_loss = 1.33206432, grad/param norm = 1.9938e-01, time/batch = 0.6614s	
3063/26050 (epoch 5.879), train_loss = 1.45713683, grad/param norm = 1.7690e-01, time/batch = 0.6568s	
3064/26050 (epoch 5.881), train_loss = 1.72900047, grad/param norm = 2.0955e-01, time/batch = 0.6583s	
3065/26050 (epoch 5.883), train_loss = 1.53928099, grad/param norm = 1.8253e-01, time/batch = 0.6605s	
3066/26050 (epoch 5.885), train_loss = 1.24109328, grad/param norm = 1.7245e-01, time/batch = 0.6783s	
3067/26050 (epoch 5.887), train_loss = 1.55715117, grad/param norm = 1.9884e-01, time/batch = 0.6397s	
3068/26050 (epoch 5.889), train_loss = 1.42488678, grad/param norm = 1.8584e-01, time/batch = 0.6438s	
3069/26050 (epoch 5.891), train_loss = 1.26813453, grad/param norm = 1.8029e-01, time/batch = 0.6419s	
3070/26050 (epoch 5.893), train_loss = 1.22722451, grad/param norm = 1.6198e-01, time/batch = 0.6468s	
3071/26050 (epoch 5.894), train_loss = 1.37209712, grad/param norm = 1.6739e-01, time/batch = 0.6397s	
3072/26050 (epoch 5.896), train_loss = 1.60452180, grad/param norm = 1.9229e-01, time/batch = 0.6385s	
3073/26050 (epoch 5.898), train_loss = 1.43990656, grad/param norm = 1.8831e-01, time/batch = 0.6438s	
3074/26050 (epoch 5.900), train_loss = 1.74942326, grad/param norm = 2.1125e-01, time/batch = 0.6408s	
3075/26050 (epoch 5.902), train_loss = 1.52692893, grad/param norm = 1.9190e-01, time/batch = 0.6601s	
3076/26050 (epoch 5.904), train_loss = 1.46945720, grad/param norm = 1.9246e-01, time/batch = 0.6631s	
3077/26050 (epoch 5.906), train_loss = 1.49848617, grad/param norm = 1.9303e-01, time/batch = 0.6624s	
3078/26050 (epoch 5.908), train_loss = 1.48391580, grad/param norm = 1.9752e-01, time/batch = 0.6457s	
3079/26050 (epoch 5.910), train_loss = 1.43529886, grad/param norm = 1.8038e-01, time/batch = 0.6452s	
3080/26050 (epoch 5.912), train_loss = 1.79340686, grad/param norm = 2.1240e-01, time/batch = 0.6488s	
3081/26050 (epoch 5.914), train_loss = 1.96519795, grad/param norm = 2.1425e-01, time/batch = 0.6718s	
3082/26050 (epoch 5.916), train_loss = 1.70641020, grad/param norm = 2.1653e-01, time/batch = 0.6762s	
3083/26050 (epoch 5.917), train_loss = 1.54567732, grad/param norm = 1.9784e-01, time/batch = 0.6585s	
3084/26050 (epoch 5.919), train_loss = 1.61623406, grad/param norm = 1.9590e-01, time/batch = 0.6483s	
3085/26050 (epoch 5.921), train_loss = 1.40721127, grad/param norm = 2.1019e-01, time/batch = 0.6401s	
3086/26050 (epoch 5.923), train_loss = 1.45538924, grad/param norm = 2.0252e-01, time/batch = 0.6393s	
3087/26050 (epoch 5.925), train_loss = 1.43027662, grad/param norm = 1.8202e-01, time/batch = 0.6387s	
3088/26050 (epoch 5.927), train_loss = 1.38588645, grad/param norm = 1.7103e-01, time/batch = 0.6406s	
3089/26050 (epoch 5.929), train_loss = 1.42269039, grad/param norm = 1.9739e-01, time/batch = 0.6400s	
3090/26050 (epoch 5.931), train_loss = 1.80693528, grad/param norm = 2.4355e-01, time/batch = 0.6397s	
3091/26050 (epoch 5.933), train_loss = 1.48706105, grad/param norm = 2.1160e-01, time/batch = 0.6419s	
3092/26050 (epoch 5.935), train_loss = 1.40441721, grad/param norm = 1.9924e-01, time/batch = 0.6425s	
3093/26050 (epoch 5.937), train_loss = 1.47916538, grad/param norm = 1.8435e-01, time/batch = 0.6395s	
3094/26050 (epoch 5.939), train_loss = 1.36678464, grad/param norm = 1.8739e-01, time/batch = 0.6380s	
3095/26050 (epoch 5.940), train_loss = 1.54937077, grad/param norm = 1.9173e-01, time/batch = 0.6385s	
3096/26050 (epoch 5.942), train_loss = 1.56303714, grad/param norm = 2.1439e-01, time/batch = 0.6501s	
3097/26050 (epoch 5.944), train_loss = 1.45795116, grad/param norm = 2.0432e-01, time/batch = 0.6716s	
3098/26050 (epoch 5.946), train_loss = 1.65576962, grad/param norm = 1.8080e-01, time/batch = 0.6412s	
3099/26050 (epoch 5.948), train_loss = 1.30312007, grad/param norm = 2.2299e-01, time/batch = 0.6527s	
3100/26050 (epoch 5.950), train_loss = 1.45466208, grad/param norm = 1.9201e-01, time/batch = 0.6551s	
3101/26050 (epoch 5.952), train_loss = 1.68685820, grad/param norm = 2.1229e-01, time/batch = 0.6527s	
3102/26050 (epoch 5.954), train_loss = 1.61778172, grad/param norm = 1.9101e-01, time/batch = 0.6630s	
3103/26050 (epoch 5.956), train_loss = 1.62985832, grad/param norm = 2.0978e-01, time/batch = 0.6799s	
3104/26050 (epoch 5.958), train_loss = 1.50754336, grad/param norm = 1.9039e-01, time/batch = 0.6482s	
3105/26050 (epoch 5.960), train_loss = 1.43596076, grad/param norm = 1.8471e-01, time/batch = 0.6438s	
3106/26050 (epoch 5.962), train_loss = 1.41532001, grad/param norm = 1.8512e-01, time/batch = 0.6493s	
3107/26050 (epoch 5.964), train_loss = 1.47429116, grad/param norm = 1.9315e-01, time/batch = 0.6510s	
3108/26050 (epoch 5.965), train_loss = 1.36585766, grad/param norm = 1.8999e-01, time/batch = 0.6472s	
3109/26050 (epoch 5.967), train_loss = 1.84371505, grad/param norm = 2.1312e-01, time/batch = 0.6424s	
3110/26050 (epoch 5.969), train_loss = 1.46109770, grad/param norm = 1.9305e-01, time/batch = 0.6423s	
3111/26050 (epoch 5.971), train_loss = 1.32833600, grad/param norm = 1.7140e-01, time/batch = 0.6427s	
3112/26050 (epoch 5.973), train_loss = 1.47449799, grad/param norm = 2.1821e-01, time/batch = 0.6415s	
3113/26050 (epoch 5.975), train_loss = 1.57541795, grad/param norm = 1.8140e-01, time/batch = 0.6418s	
3114/26050 (epoch 5.977), train_loss = 1.51286749, grad/param norm = 1.6719e-01, time/batch = 0.6448s	
3115/26050 (epoch 5.979), train_loss = 1.34982145, grad/param norm = 1.8291e-01, time/batch = 0.6483s	
3116/26050 (epoch 5.981), train_loss = 1.58135767, grad/param norm = 1.7896e-01, time/batch = 0.6421s	
3117/26050 (epoch 5.983), train_loss = 1.59534332, grad/param norm = 2.0418e-01, time/batch = 0.6415s	
3118/26050 (epoch 5.985), train_loss = 1.54613135, grad/param norm = 1.9659e-01, time/batch = 0.6420s	
3119/26050 (epoch 5.987), train_loss = 1.68508032, grad/param norm = 2.1211e-01, time/batch = 0.6451s	
3120/26050 (epoch 5.988), train_loss = 1.65172390, grad/param norm = 2.1166e-01, time/batch = 0.6420s	
3121/26050 (epoch 5.990), train_loss = 1.46016528, grad/param norm = 2.0676e-01, time/batch = 0.6427s	
3122/26050 (epoch 5.992), train_loss = 1.71198008, grad/param norm = 2.2804e-01, time/batch = 0.6485s	
3123/26050 (epoch 5.994), train_loss = 1.48338177, grad/param norm = 2.0944e-01, time/batch = 0.6427s	
3124/26050 (epoch 5.996), train_loss = 1.53463320, grad/param norm = 2.4470e-01, time/batch = 0.6399s	
3125/26050 (epoch 5.998), train_loss = 1.56859481, grad/param norm = 1.9939e-01, time/batch = 0.6469s	
3126/26050 (epoch 6.000), train_loss = 1.50325822, grad/param norm = 2.0330e-01, time/batch = 0.6523s	
3127/26050 (epoch 6.002), train_loss = 1.53641444, grad/param norm = 1.9087e-01, time/batch = 0.6504s	
3128/26050 (epoch 6.004), train_loss = 1.46031564, grad/param norm = 1.9956e-01, time/batch = 0.6702s	
3129/26050 (epoch 6.006), train_loss = 1.41399336, grad/param norm = 1.7999e-01, time/batch = 0.6530s	
3130/26050 (epoch 6.008), train_loss = 1.42090533, grad/param norm = 1.8638e-01, time/batch = 0.6535s	
3131/26050 (epoch 6.010), train_loss = 1.47192774, grad/param norm = 1.8232e-01, time/batch = 0.6647s	
3132/26050 (epoch 6.012), train_loss = 1.55984221, grad/param norm = 2.0932e-01, time/batch = 0.6834s	
3133/26050 (epoch 6.013), train_loss = 1.96866998, grad/param norm = 2.1508e-01, time/batch = 0.6612s	
3134/26050 (epoch 6.015), train_loss = 1.36969269, grad/param norm = 1.7860e-01, time/batch = 0.6476s	
3135/26050 (epoch 6.017), train_loss = 1.52102200, grad/param norm = 2.0240e-01, time/batch = 0.6440s	
3136/26050 (epoch 6.019), train_loss = 1.32838629, grad/param norm = 1.6085e-01, time/batch = 0.6410s	
3137/26050 (epoch 6.021), train_loss = 1.65815154, grad/param norm = 2.1796e-01, time/batch = 0.6498s	
3138/26050 (epoch 6.023), train_loss = 1.38300638, grad/param norm = 1.9605e-01, time/batch = 0.6414s	
3139/26050 (epoch 6.025), train_loss = 1.43666859, grad/param norm = 1.9194e-01, time/batch = 0.6405s	
3140/26050 (epoch 6.027), train_loss = 1.26255844, grad/param norm = 1.7523e-01, time/batch = 0.6388s	
3141/26050 (epoch 6.029), train_loss = 1.44485625, grad/param norm = 1.8526e-01, time/batch = 0.6406s	
3142/26050 (epoch 6.031), train_loss = 1.69122015, grad/param norm = 2.1872e-01, time/batch = 0.6393s	
3143/26050 (epoch 6.033), train_loss = 1.54639899, grad/param norm = 1.9894e-01, time/batch = 0.6394s	
3144/26050 (epoch 6.035), train_loss = 1.65660962, grad/param norm = 1.9218e-01, time/batch = 0.6396s	
3145/26050 (epoch 6.036), train_loss = 1.47201144, grad/param norm = 2.0801e-01, time/batch = 0.6395s	
3146/26050 (epoch 6.038), train_loss = 1.28931318, grad/param norm = 1.8117e-01, time/batch = 0.6463s	
3147/26050 (epoch 6.040), train_loss = 1.57158340, grad/param norm = 2.0313e-01, time/batch = 0.6685s	
3148/26050 (epoch 6.042), train_loss = 1.35203717, grad/param norm = 1.7584e-01, time/batch = 0.6764s	
3149/26050 (epoch 6.044), train_loss = 1.53427494, grad/param norm = 1.8657e-01, time/batch = 0.6387s	
3150/26050 (epoch 6.046), train_loss = 1.29778365, grad/param norm = 1.9444e-01, time/batch = 0.6412s	
3151/26050 (epoch 6.048), train_loss = 1.52041936, grad/param norm = 1.8881e-01, time/batch = 0.6445s	
3152/26050 (epoch 6.050), train_loss = 1.38681728, grad/param norm = 2.0854e-01, time/batch = 0.6411s	
3153/26050 (epoch 6.052), train_loss = 1.51370457, grad/param norm = 1.9778e-01, time/batch = 0.6430s	
3154/26050 (epoch 6.054), train_loss = 1.34463482, grad/param norm = 1.9932e-01, time/batch = 0.6405s	
3155/26050 (epoch 6.056), train_loss = 1.16982204, grad/param norm = 1.5942e-01, time/batch = 0.6434s	
3156/26050 (epoch 6.058), train_loss = 1.39324905, grad/param norm = 1.7820e-01, time/batch = 0.6590s	
3157/26050 (epoch 6.060), train_loss = 1.46361323, grad/param norm = 1.7866e-01, time/batch = 0.6551s	
3158/26050 (epoch 6.061), train_loss = 1.36995950, grad/param norm = 1.8335e-01, time/batch = 0.6558s	
3159/26050 (epoch 6.063), train_loss = 1.40073320, grad/param norm = 1.6616e-01, time/batch = 0.6563s	
3160/26050 (epoch 6.065), train_loss = 1.30520828, grad/param norm = 1.8048e-01, time/batch = 0.6556s	
3161/26050 (epoch 6.067), train_loss = 1.57272534, grad/param norm = 2.0532e-01, time/batch = 0.6524s	
3162/26050 (epoch 6.069), train_loss = 1.57105007, grad/param norm = 1.9690e-01, time/batch = 0.6598s	
3163/26050 (epoch 6.071), train_loss = 1.55880594, grad/param norm = 2.0658e-01, time/batch = 0.6842s	
3164/26050 (epoch 6.073), train_loss = 1.70796042, grad/param norm = 1.8966e-01, time/batch = 0.6558s	
3165/26050 (epoch 6.075), train_loss = 1.37116096, grad/param norm = 1.7729e-01, time/batch = 0.6545s	
3166/26050 (epoch 6.077), train_loss = 1.37321031, grad/param norm = 1.8583e-01, time/batch = 0.6629s	
3167/26050 (epoch 6.079), train_loss = 1.59398157, grad/param norm = 1.9997e-01, time/batch = 0.6553s	
3168/26050 (epoch 6.081), train_loss = 1.40963393, grad/param norm = 1.8501e-01, time/batch = 0.6430s	
3169/26050 (epoch 6.083), train_loss = 1.56165629, grad/param norm = 2.0252e-01, time/batch = 0.6403s	
3170/26050 (epoch 6.084), train_loss = 1.70772275, grad/param norm = 2.2641e-01, time/batch = 0.6396s	
3171/26050 (epoch 6.086), train_loss = 1.64648600, grad/param norm = 2.0528e-01, time/batch = 0.6432s	
3172/26050 (epoch 6.088), train_loss = 1.33898006, grad/param norm = 1.6702e-01, time/batch = 0.6495s	
3173/26050 (epoch 6.090), train_loss = 1.64623530, grad/param norm = 1.9355e-01, time/batch = 0.6413s	
3174/26050 (epoch 6.092), train_loss = 1.42525879, grad/param norm = 1.9884e-01, time/batch = 0.6414s	
3175/26050 (epoch 6.094), train_loss = 1.52732944, grad/param norm = 1.9572e-01, time/batch = 0.6435s	
3176/26050 (epoch 6.096), train_loss = 1.36752378, grad/param norm = 1.7070e-01, time/batch = 0.6444s	
3177/26050 (epoch 6.098), train_loss = 1.40379329, grad/param norm = 1.9024e-01, time/batch = 0.6452s	
3178/26050 (epoch 6.100), train_loss = 1.39074882, grad/param norm = 2.0593e-01, time/batch = 0.6825s	
3179/26050 (epoch 6.102), train_loss = 1.52176503, grad/param norm = 1.9045e-01, time/batch = 0.6607s	
3180/26050 (epoch 6.104), train_loss = 1.55939057, grad/param norm = 1.9751e-01, time/batch = 0.6397s	
3181/26050 (epoch 6.106), train_loss = 1.43543530, grad/param norm = 1.9343e-01, time/batch = 0.6396s	
3182/26050 (epoch 6.107), train_loss = 1.20367906, grad/param norm = 1.7706e-01, time/batch = 0.6433s	
3183/26050 (epoch 6.109), train_loss = 1.37699212, grad/param norm = 1.7369e-01, time/batch = 0.6497s	
3184/26050 (epoch 6.111), train_loss = 1.73762706, grad/param norm = 2.1946e-01, time/batch = 0.6415s	
3185/26050 (epoch 6.113), train_loss = 1.39606924, grad/param norm = 1.9810e-01, time/batch = 0.6406s	
3186/26050 (epoch 6.115), train_loss = 1.61400643, grad/param norm = 1.9077e-01, time/batch = 0.6397s	
3187/26050 (epoch 6.117), train_loss = 1.54889946, grad/param norm = 2.0403e-01, time/batch = 0.6392s	
3188/26050 (epoch 6.119), train_loss = 1.27379777, grad/param norm = 1.7997e-01, time/batch = 0.6404s	
3189/26050 (epoch 6.121), train_loss = 1.52357611, grad/param norm = 1.9709e-01, time/batch = 0.6393s	
3190/26050 (epoch 6.123), train_loss = 1.42334130, grad/param norm = 2.1795e-01, time/batch = 0.6409s	
3191/26050 (epoch 6.125), train_loss = 1.24476012, grad/param norm = 1.6752e-01, time/batch = 0.6548s	
3192/26050 (epoch 6.127), train_loss = 1.26043471, grad/param norm = 1.8104e-01, time/batch = 0.6634s	
3193/26050 (epoch 6.129), train_loss = 1.25082258, grad/param norm = 1.6971e-01, time/batch = 0.6963s	
3194/26050 (epoch 6.131), train_loss = 1.48590810, grad/param norm = 1.9795e-01, time/batch = 0.6790s	
3195/26050 (epoch 6.132), train_loss = 1.40290258, grad/param norm = 1.7687e-01, time/batch = 0.6542s	
3196/26050 (epoch 6.134), train_loss = 1.43515349, grad/param norm = 2.0265e-01, time/batch = 0.6708s	
3197/26050 (epoch 6.136), train_loss = 1.44098748, grad/param norm = 1.8043e-01, time/batch = 0.6566s	
3198/26050 (epoch 6.138), train_loss = 1.35684804, grad/param norm = 2.2475e-01, time/batch = 0.6557s	
3199/26050 (epoch 6.140), train_loss = 1.39717108, grad/param norm = 1.8944e-01, time/batch = 0.6539s	
3200/26050 (epoch 6.142), train_loss = 1.44683383, grad/param norm = 1.8915e-01, time/batch = 0.6531s	
3201/26050 (epoch 6.144), train_loss = 1.28789480, grad/param norm = 1.8947e-01, time/batch = 0.6542s	
3202/26050 (epoch 6.146), train_loss = 1.21690650, grad/param norm = 1.7665e-01, time/batch = 0.6513s	
3203/26050 (epoch 6.148), train_loss = 1.23544545, grad/param norm = 1.5427e-01, time/batch = 0.6514s	
3204/26050 (epoch 6.150), train_loss = 1.47109922, grad/param norm = 1.9350e-01, time/batch = 0.6500s	
3205/26050 (epoch 6.152), train_loss = 1.75963708, grad/param norm = 2.1486e-01, time/batch = 0.6523s	
3206/26050 (epoch 6.154), train_loss = 1.28911928, grad/param norm = 1.8527e-01, time/batch = 0.6559s	
3207/26050 (epoch 6.155), train_loss = 1.29154598, grad/param norm = 1.7608e-01, time/batch = 0.6659s	
3208/26050 (epoch 6.157), train_loss = 1.47007890, grad/param norm = 2.0198e-01, time/batch = 0.6762s	
3209/26050 (epoch 6.159), train_loss = 1.46616026, grad/param norm = 2.0830e-01, time/batch = 0.6804s	
3210/26050 (epoch 6.161), train_loss = 1.68424574, grad/param norm = 2.1542e-01, time/batch = 0.6473s	
3211/26050 (epoch 6.163), train_loss = 1.32763295, grad/param norm = 1.7650e-01, time/batch = 0.6608s	
3212/26050 (epoch 6.165), train_loss = 1.15034354, grad/param norm = 1.6922e-01, time/batch = 0.6607s	
3213/26050 (epoch 6.167), train_loss = 1.60256247, grad/param norm = 2.3171e-01, time/batch = 0.6613s	
3214/26050 (epoch 6.169), train_loss = 1.54466067, grad/param norm = 2.0499e-01, time/batch = 0.6560s	
3215/26050 (epoch 6.171), train_loss = 1.24519973, grad/param norm = 1.6228e-01, time/batch = 0.6495s	
3216/26050 (epoch 6.173), train_loss = 1.43106051, grad/param norm = 1.9891e-01, time/batch = 0.6471s	
3217/26050 (epoch 6.175), train_loss = 1.46410947, grad/param norm = 2.0573e-01, time/batch = 0.6558s	
3218/26050 (epoch 6.177), train_loss = 1.53523100, grad/param norm = 1.9389e-01, time/batch = 0.6568s	
3219/26050 (epoch 6.179), train_loss = 1.15057900, grad/param norm = 1.7219e-01, time/batch = 0.6602s	
3220/26050 (epoch 6.180), train_loss = 1.71535238, grad/param norm = 1.9341e-01, time/batch = 0.6565s	
3221/26050 (epoch 6.182), train_loss = 1.77043331, grad/param norm = 2.0313e-01, time/batch = 0.6584s	
3222/26050 (epoch 6.184), train_loss = 1.50387855, grad/param norm = 1.8439e-01, time/batch = 0.6571s	
3223/26050 (epoch 6.186), train_loss = 1.20828394, grad/param norm = 1.6438e-01, time/batch = 0.6588s	
3224/26050 (epoch 6.188), train_loss = 1.44945460, grad/param norm = 1.7702e-01, time/batch = 0.6533s	
3225/26050 (epoch 6.190), train_loss = 1.53041182, grad/param norm = 2.0356e-01, time/batch = 0.6533s	
3226/26050 (epoch 6.192), train_loss = 1.49773964, grad/param norm = 2.0108e-01, time/batch = 0.6573s	
3227/26050 (epoch 6.194), train_loss = 1.49463001, grad/param norm = 1.9246e-01, time/batch = 0.6516s	
3228/26050 (epoch 6.196), train_loss = 1.56021685, grad/param norm = 2.0942e-01, time/batch = 0.6575s	
3229/26050 (epoch 6.198), train_loss = 1.37679895, grad/param norm = 1.8627e-01, time/batch = 0.6444s	
3230/26050 (epoch 6.200), train_loss = 1.38167443, grad/param norm = 1.9079e-01, time/batch = 0.6591s	
3231/26050 (epoch 6.202), train_loss = 1.38783491, grad/param norm = 1.9775e-01, time/batch = 0.6505s	
3232/26050 (epoch 6.203), train_loss = 1.55579631, grad/param norm = 2.0924e-01, time/batch = 0.6658s	
3233/26050 (epoch 6.205), train_loss = 1.34376910, grad/param norm = 1.8261e-01, time/batch = 0.6450s	
3234/26050 (epoch 6.207), train_loss = 1.43156260, grad/param norm = 1.7262e-01, time/batch = 0.6845s	
3235/26050 (epoch 6.209), train_loss = 1.40589765, grad/param norm = 1.8383e-01, time/batch = 0.6802s	
3236/26050 (epoch 6.211), train_loss = 1.31358542, grad/param norm = 1.9290e-01, time/batch = 0.6585s	
3237/26050 (epoch 6.213), train_loss = 1.49659923, grad/param norm = 1.7634e-01, time/batch = 0.6545s	
3238/26050 (epoch 6.215), train_loss = 1.51827337, grad/param norm = 2.1321e-01, time/batch = 0.6572s	
3239/26050 (epoch 6.217), train_loss = 1.39100580, grad/param norm = 1.8496e-01, time/batch = 0.6480s	
3240/26050 (epoch 6.219), train_loss = 1.39047863, grad/param norm = 1.9812e-01, time/batch = 0.6509s	
3241/26050 (epoch 6.221), train_loss = 1.32591647, grad/param norm = 1.8758e-01, time/batch = 0.6534s	
3242/26050 (epoch 6.223), train_loss = 1.56785617, grad/param norm = 2.1685e-01, time/batch = 0.6442s	
3243/26050 (epoch 6.225), train_loss = 1.35229651, grad/param norm = 2.0068e-01, time/batch = 0.6459s	
3244/26050 (epoch 6.226), train_loss = 1.62005243, grad/param norm = 2.1028e-01, time/batch = 0.6448s	
3245/26050 (epoch 6.228), train_loss = 1.62040774, grad/param norm = 2.1190e-01, time/batch = 0.6427s	
3246/26050 (epoch 6.230), train_loss = 1.48215816, grad/param norm = 1.9576e-01, time/batch = 0.6440s	
3247/26050 (epoch 6.232), train_loss = 1.61012414, grad/param norm = 2.1072e-01, time/batch = 0.6457s	
3248/26050 (epoch 6.234), train_loss = 1.25389252, grad/param norm = 1.8776e-01, time/batch = 0.6435s	
3249/26050 (epoch 6.236), train_loss = 1.50541955, grad/param norm = 2.1219e-01, time/batch = 0.6664s	
3250/26050 (epoch 6.238), train_loss = 1.22426879, grad/param norm = 1.7947e-01, time/batch = 0.6815s	
3251/26050 (epoch 6.240), train_loss = 1.39516608, grad/param norm = 1.7893e-01, time/batch = 0.6542s	
3252/26050 (epoch 6.242), train_loss = 1.41153363, grad/param norm = 1.8236e-01, time/batch = 0.6661s	
3253/26050 (epoch 6.244), train_loss = 1.52412262, grad/param norm = 2.1635e-01, time/batch = 0.6609s	
3254/26050 (epoch 6.246), train_loss = 1.37666017, grad/param norm = 1.7766e-01, time/batch = 0.6554s	
3255/26050 (epoch 6.248), train_loss = 1.53242737, grad/param norm = 2.0277e-01, time/batch = 0.6474s	
3256/26050 (epoch 6.250), train_loss = 1.51966969, grad/param norm = 2.0811e-01, time/batch = 0.6578s	
3257/26050 (epoch 6.251), train_loss = 1.33806445, grad/param norm = 1.8771e-01, time/batch = 0.6490s	
3258/26050 (epoch 6.253), train_loss = 1.25755561, grad/param norm = 1.8553e-01, time/batch = 0.6501s	
3259/26050 (epoch 6.255), train_loss = 1.67642365, grad/param norm = 1.9653e-01, time/batch = 0.6489s	
3260/26050 (epoch 6.257), train_loss = 1.45124547, grad/param norm = 1.9346e-01, time/batch = 0.6840s	
3261/26050 (epoch 6.259), train_loss = 1.59027234, grad/param norm = 1.9752e-01, time/batch = 0.6669s	
3262/26050 (epoch 6.261), train_loss = 1.38619750, grad/param norm = 1.9201e-01, time/batch = 0.6664s	
3263/26050 (epoch 6.263), train_loss = 1.44714557, grad/param norm = 1.9473e-01, time/batch = 0.6662s	
3264/26050 (epoch 6.265), train_loss = 1.64500456, grad/param norm = 1.8081e-01, time/batch = 0.6692s	
3265/26050 (epoch 6.267), train_loss = 1.49697526, grad/param norm = 1.9810e-01, time/batch = 0.6675s	
3266/26050 (epoch 6.269), train_loss = 1.67211265, grad/param norm = 2.1678e-01, time/batch = 0.6667s	
3267/26050 (epoch 6.271), train_loss = 1.44473080, grad/param norm = 1.7538e-01, time/batch = 0.6608s	
3268/26050 (epoch 6.273), train_loss = 1.41415842, grad/param norm = 1.9003e-01, time/batch = 0.6550s	
3269/26050 (epoch 6.274), train_loss = 1.38238053, grad/param norm = 1.8869e-01, time/batch = 0.6535s	
3270/26050 (epoch 6.276), train_loss = 1.36149857, grad/param norm = 1.8370e-01, time/batch = 0.6484s	
3271/26050 (epoch 6.278), train_loss = 1.56109462, grad/param norm = 2.0216e-01, time/batch = 0.6505s	
3272/26050 (epoch 6.280), train_loss = 1.43269191, grad/param norm = 1.7916e-01, time/batch = 0.6497s	
3273/26050 (epoch 6.282), train_loss = 1.49382039, grad/param norm = 1.9997e-01, time/batch = 0.6489s	
3274/26050 (epoch 6.284), train_loss = 1.31774675, grad/param norm = 1.9120e-01, time/batch = 0.6446s	
3275/26050 (epoch 6.286), train_loss = 1.42819524, grad/param norm = 2.0364e-01, time/batch = 0.6821s	
3276/26050 (epoch 6.288), train_loss = 1.28953316, grad/param norm = 1.8035e-01, time/batch = 0.6636s	
3277/26050 (epoch 6.290), train_loss = 1.40070015, grad/param norm = 1.9051e-01, time/batch = 0.6402s	
3278/26050 (epoch 6.292), train_loss = 1.35916595, grad/param norm = 1.7818e-01, time/batch = 0.6404s	
3279/26050 (epoch 6.294), train_loss = 1.48984718, grad/param norm = 2.1799e-01, time/batch = 0.6507s	
3280/26050 (epoch 6.296), train_loss = 1.56236856, grad/param norm = 1.8878e-01, time/batch = 0.6571s	
3281/26050 (epoch 6.298), train_loss = 1.41106866, grad/param norm = 1.7441e-01, time/batch = 0.6534s	
3282/26050 (epoch 6.299), train_loss = 1.19230354, grad/param norm = 1.6142e-01, time/batch = 0.6718s	
3283/26050 (epoch 6.301), train_loss = 1.37421596, grad/param norm = 1.9294e-01, time/batch = 0.6633s	
3284/26050 (epoch 6.303), train_loss = 1.48089343, grad/param norm = 1.9436e-01, time/batch = 0.6672s	
3285/26050 (epoch 6.305), train_loss = 1.31143215, grad/param norm = 1.8324e-01, time/batch = 0.6534s	
3286/26050 (epoch 6.307), train_loss = 1.30761022, grad/param norm = 1.8682e-01, time/batch = 0.6480s	
3287/26050 (epoch 6.309), train_loss = 1.39027011, grad/param norm = 1.9967e-01, time/batch = 0.6495s	
3288/26050 (epoch 6.311), train_loss = 1.66599091, grad/param norm = 2.1396e-01, time/batch = 0.6481s	
3289/26050 (epoch 6.313), train_loss = 1.46527972, grad/param norm = 2.0769e-01, time/batch = 0.6539s	
3290/26050 (epoch 6.315), train_loss = 1.60437352, grad/param norm = 2.1150e-01, time/batch = 0.6736s	
3291/26050 (epoch 6.317), train_loss = 1.35595726, grad/param norm = 1.8177e-01, time/batch = 0.6774s	
3292/26050 (epoch 6.319), train_loss = 1.42252719, grad/param norm = 1.7092e-01, time/batch = 0.6548s	
3293/26050 (epoch 6.321), train_loss = 1.42733046, grad/param norm = 1.7676e-01, time/batch = 0.6529s	
3294/26050 (epoch 6.322), train_loss = 1.46106939, grad/param norm = 1.8116e-01, time/batch = 0.6582s	
3295/26050 (epoch 6.324), train_loss = 1.25940584, grad/param norm = 1.7098e-01, time/batch = 0.6577s	
3296/26050 (epoch 6.326), train_loss = 1.60381199, grad/param norm = 2.0827e-01, time/batch = 0.6449s	
3297/26050 (epoch 6.328), train_loss = 1.48228532, grad/param norm = 1.8693e-01, time/batch = 0.6425s	
3298/26050 (epoch 6.330), train_loss = 1.34736596, grad/param norm = 1.9366e-01, time/batch = 0.6533s	
3299/26050 (epoch 6.332), train_loss = 1.53180395, grad/param norm = 1.9390e-01, time/batch = 0.6499s	
3300/26050 (epoch 6.334), train_loss = 1.40471982, grad/param norm = 1.9260e-01, time/batch = 0.6446s	
3301/26050 (epoch 6.336), train_loss = 1.29442179, grad/param norm = 1.6413e-01, time/batch = 0.6566s	
3302/26050 (epoch 6.338), train_loss = 1.25866225, grad/param norm = 1.7264e-01, time/batch = 0.6543s	
3303/26050 (epoch 6.340), train_loss = 1.54769393, grad/param norm = 2.0558e-01, time/batch = 0.6431s	
3304/26050 (epoch 6.342), train_loss = 1.58508698, grad/param norm = 1.8894e-01, time/batch = 0.6535s	
3305/26050 (epoch 6.344), train_loss = 1.43218401, grad/param norm = 1.9897e-01, time/batch = 0.6723s	
3306/26050 (epoch 6.345), train_loss = 1.44330918, grad/param norm = 2.0797e-01, time/batch = 0.6823s	
3307/26050 (epoch 6.347), train_loss = 1.51285625, grad/param norm = 2.0159e-01, time/batch = 0.6568s	
3308/26050 (epoch 6.349), train_loss = 1.45369045, grad/param norm = 1.8839e-01, time/batch = 0.6566s	
3309/26050 (epoch 6.351), train_loss = 1.49451874, grad/param norm = 2.0737e-01, time/batch = 0.6510s	
3310/26050 (epoch 6.353), train_loss = 1.36796958, grad/param norm = 2.0165e-01, time/batch = 0.6519s	
3311/26050 (epoch 6.355), train_loss = 1.54397086, grad/param norm = 2.0801e-01, time/batch = 0.6605s	
3312/26050 (epoch 6.357), train_loss = 1.28262449, grad/param norm = 1.6386e-01, time/batch = 0.6534s	
3313/26050 (epoch 6.359), train_loss = 1.53369119, grad/param norm = 1.9317e-01, time/batch = 0.6504s	
3314/26050 (epoch 6.361), train_loss = 1.31194980, grad/param norm = 1.8123e-01, time/batch = 0.6574s	
3315/26050 (epoch 6.363), train_loss = 1.43021705, grad/param norm = 1.8534e-01, time/batch = 0.6487s	
3316/26050 (epoch 6.365), train_loss = 1.32889458, grad/param norm = 1.7288e-01, time/batch = 0.6488s	
3317/26050 (epoch 6.367), train_loss = 1.43789223, grad/param norm = 1.9047e-01, time/batch = 0.6437s	
3318/26050 (epoch 6.369), train_loss = 1.40241609, grad/param norm = 1.7320e-01, time/batch = 0.6535s	
3319/26050 (epoch 6.370), train_loss = 1.32388859, grad/param norm = 1.7938e-01, time/batch = 0.6562s	
3320/26050 (epoch 6.372), train_loss = 1.58231091, grad/param norm = 2.1023e-01, time/batch = 0.6511s	
3321/26050 (epoch 6.374), train_loss = 1.66191812, grad/param norm = 2.1788e-01, time/batch = 0.6538s	
3322/26050 (epoch 6.376), train_loss = 1.67940947, grad/param norm = 1.8445e-01, time/batch = 0.6431s	
3323/26050 (epoch 6.378), train_loss = 1.43135836, grad/param norm = 1.9281e-01, time/batch = 0.6386s	
3324/26050 (epoch 6.380), train_loss = 1.65881405, grad/param norm = 2.0595e-01, time/batch = 0.6379s	
3325/26050 (epoch 6.382), train_loss = 1.84194503, grad/param norm = 2.2330e-01, time/batch = 0.6385s	
3326/26050 (epoch 6.384), train_loss = 1.40107528, grad/param norm = 1.8473e-01, time/batch = 0.6605s	
3327/26050 (epoch 6.386), train_loss = 1.54260202, grad/param norm = 1.8448e-01, time/batch = 0.6447s	
3328/26050 (epoch 6.388), train_loss = 1.49229766, grad/param norm = 1.7880e-01, time/batch = 0.6437s	
3329/26050 (epoch 6.390), train_loss = 1.30769475, grad/param norm = 1.6784e-01, time/batch = 0.6498s	
3330/26050 (epoch 6.392), train_loss = 1.32694833, grad/param norm = 1.8205e-01, time/batch = 0.6642s	
3331/26050 (epoch 6.393), train_loss = 1.50516766, grad/param norm = 1.8267e-01, time/batch = 0.6783s	
3332/26050 (epoch 6.395), train_loss = 1.51664024, grad/param norm = 1.9118e-01, time/batch = 0.6768s	
3333/26050 (epoch 6.397), train_loss = 1.50486951, grad/param norm = 1.9150e-01, time/batch = 0.6736s	
3334/26050 (epoch 6.399), train_loss = 1.31603432, grad/param norm = 1.7462e-01, time/batch = 0.6666s	
3335/26050 (epoch 6.401), train_loss = 1.38369745, grad/param norm = 1.7743e-01, time/batch = 0.6587s	
3336/26050 (epoch 6.403), train_loss = 1.45891663, grad/param norm = 1.9245e-01, time/batch = 0.6410s	
3337/26050 (epoch 6.405), train_loss = 1.44104528, grad/param norm = 1.9660e-01, time/batch = 0.6404s	
3338/26050 (epoch 6.407), train_loss = 1.61767561, grad/param norm = 1.9692e-01, time/batch = 0.6394s	
3339/26050 (epoch 6.409), train_loss = 1.64386728, grad/param norm = 2.0767e-01, time/batch = 0.6416s	
3340/26050 (epoch 6.411), train_loss = 1.49350426, grad/param norm = 1.9017e-01, time/batch = 0.6402s	
3341/26050 (epoch 6.413), train_loss = 1.58862503, grad/param norm = 1.8350e-01, time/batch = 0.6617s	
3342/26050 (epoch 6.415), train_loss = 1.59285271, grad/param norm = 2.0592e-01, time/batch = 0.6519s	
3343/26050 (epoch 6.417), train_loss = 1.64643852, grad/param norm = 2.0462e-01, time/batch = 0.6397s	
3344/26050 (epoch 6.418), train_loss = 1.53890738, grad/param norm = 1.9754e-01, time/batch = 0.6439s	
3345/26050 (epoch 6.420), train_loss = 1.22710218, grad/param norm = 1.6531e-01, time/batch = 0.6403s	
3346/26050 (epoch 6.422), train_loss = 1.31626739, grad/param norm = 1.9487e-01, time/batch = 0.6407s	
3347/26050 (epoch 6.424), train_loss = 1.70851242, grad/param norm = 2.2695e-01, time/batch = 0.6397s	
3348/26050 (epoch 6.426), train_loss = 1.65353572, grad/param norm = 2.2777e-01, time/batch = 0.6406s	
3349/26050 (epoch 6.428), train_loss = 1.35770648, grad/param norm = 1.7604e-01, time/batch = 0.6409s	
3350/26050 (epoch 6.430), train_loss = 1.49477160, grad/param norm = 2.0360e-01, time/batch = 0.6406s	
3351/26050 (epoch 6.432), train_loss = 1.42060978, grad/param norm = 1.9186e-01, time/batch = 0.6430s	
3352/26050 (epoch 6.434), train_loss = 1.48595515, grad/param norm = 1.8794e-01, time/batch = 0.6426s	
3353/26050 (epoch 6.436), train_loss = 1.60493767, grad/param norm = 1.8928e-01, time/batch = 0.6406s	
3354/26050 (epoch 6.438), train_loss = 1.33691942, grad/param norm = 1.7198e-01, time/batch = 0.6405s	
3355/26050 (epoch 6.440), train_loss = 1.47668528, grad/param norm = 1.9203e-01, time/batch = 0.6407s	
3356/26050 (epoch 6.441), train_loss = 1.44760514, grad/param norm = 1.8931e-01, time/batch = 0.6399s	
3357/26050 (epoch 6.443), train_loss = 1.24209182, grad/param norm = 1.6268e-01, time/batch = 0.6410s	
3358/26050 (epoch 6.445), train_loss = 1.31348648, grad/param norm = 1.8259e-01, time/batch = 0.6436s	
3359/26050 (epoch 6.447), train_loss = 1.69627556, grad/param norm = 1.9928e-01, time/batch = 0.6423s	
3360/26050 (epoch 6.449), train_loss = 1.34319424, grad/param norm = 1.7905e-01, time/batch = 0.6415s	
3361/26050 (epoch 6.451), train_loss = 1.52477336, grad/param norm = 1.7140e-01, time/batch = 0.6424s	
3362/26050 (epoch 6.453), train_loss = 1.30378213, grad/param norm = 1.6840e-01, time/batch = 0.6415s	
3363/26050 (epoch 6.455), train_loss = 1.47965675, grad/param norm = 1.9156e-01, time/batch = 0.6415s	
3364/26050 (epoch 6.457), train_loss = 1.49876403, grad/param norm = 1.9615e-01, time/batch = 0.6418s	
3365/26050 (epoch 6.459), train_loss = 1.58051453, grad/param norm = 1.9359e-01, time/batch = 0.6461s	
3366/26050 (epoch 6.461), train_loss = 1.53788082, grad/param norm = 1.9463e-01, time/batch = 0.6462s	
3367/26050 (epoch 6.463), train_loss = 1.38060658, grad/param norm = 1.7283e-01, time/batch = 0.6418s	
3368/26050 (epoch 6.464), train_loss = 1.53347879, grad/param norm = 2.0807e-01, time/batch = 0.6456s	
3369/26050 (epoch 6.466), train_loss = 1.56345281, grad/param norm = 1.8714e-01, time/batch = 0.6416s	
3370/26050 (epoch 6.468), train_loss = 1.55357985, grad/param norm = 1.7977e-01, time/batch = 0.6399s	
3371/26050 (epoch 6.470), train_loss = 1.68886835, grad/param norm = 2.0868e-01, time/batch = 0.6424s	
3372/26050 (epoch 6.472), train_loss = 1.71201251, grad/param norm = 1.9875e-01, time/batch = 0.6421s	
3373/26050 (epoch 6.474), train_loss = 1.74883491, grad/param norm = 1.9243e-01, time/batch = 0.6410s	
3374/26050 (epoch 6.476), train_loss = 1.55186532, grad/param norm = 1.7802e-01, time/batch = 0.6605s	
3375/26050 (epoch 6.478), train_loss = 1.36637314, grad/param norm = 1.7104e-01, time/batch = 0.6661s	
3376/26050 (epoch 6.480), train_loss = 1.47766555, grad/param norm = 1.6826e-01, time/batch = 0.6680s	
3377/26050 (epoch 6.482), train_loss = 1.42904033, grad/param norm = 1.8457e-01, time/batch = 0.6731s	
3378/26050 (epoch 6.484), train_loss = 1.31419000, grad/param norm = 1.8894e-01, time/batch = 0.6835s	
3379/26050 (epoch 6.486), train_loss = 1.63714728, grad/param norm = 2.0276e-01, time/batch = 0.6615s	
3380/26050 (epoch 6.488), train_loss = 1.83618609, grad/param norm = 2.0432e-01, time/batch = 0.6551s	
3381/26050 (epoch 6.489), train_loss = 1.72549964, grad/param norm = 1.9917e-01, time/batch = 0.6507s	
3382/26050 (epoch 6.491), train_loss = 1.38977646, grad/param norm = 1.8566e-01, time/batch = 0.6715s	
3383/26050 (epoch 6.493), train_loss = 1.39425543, grad/param norm = 1.8118e-01, time/batch = 0.6582s	
3384/26050 (epoch 6.495), train_loss = 1.45517125, grad/param norm = 1.9772e-01, time/batch = 0.6572s	
3385/26050 (epoch 6.497), train_loss = 1.39061598, grad/param norm = 1.8302e-01, time/batch = 0.6592s	
3386/26050 (epoch 6.499), train_loss = 1.40193281, grad/param norm = 1.9829e-01, time/batch = 0.6630s	
3387/26050 (epoch 6.501), train_loss = 1.46392768, grad/param norm = 2.0155e-01, time/batch = 0.6462s	
3388/26050 (epoch 6.503), train_loss = 1.38740218, grad/param norm = 1.9081e-01, time/batch = 0.6437s	
3389/26050 (epoch 6.505), train_loss = 1.58824215, grad/param norm = 1.8992e-01, time/batch = 0.6509s	
3390/26050 (epoch 6.507), train_loss = 1.59673498, grad/param norm = 2.0291e-01, time/batch = 0.6424s	
3391/26050 (epoch 6.509), train_loss = 1.72323760, grad/param norm = 2.1591e-01, time/batch = 0.6420s	
3392/26050 (epoch 6.511), train_loss = 1.36837603, grad/param norm = 1.8760e-01, time/batch = 0.6561s	
3393/26050 (epoch 6.512), train_loss = 1.52074143, grad/param norm = 2.1072e-01, time/batch = 0.6833s	
3394/26050 (epoch 6.514), train_loss = 1.54338833, grad/param norm = 1.9129e-01, time/batch = 0.6501s	
3395/26050 (epoch 6.516), train_loss = 1.58960900, grad/param norm = 2.0489e-01, time/batch = 0.6428s	
3396/26050 (epoch 6.518), train_loss = 1.54597859, grad/param norm = 1.9617e-01, time/batch = 0.6419s	
3397/26050 (epoch 6.520), train_loss = 1.49038295, grad/param norm = 1.9183e-01, time/batch = 0.6447s	
3398/26050 (epoch 6.522), train_loss = 1.34134897, grad/param norm = 1.8114e-01, time/batch = 0.6416s	
3399/26050 (epoch 6.524), train_loss = 1.70374624, grad/param norm = 2.0456e-01, time/batch = 0.6395s	
3400/26050 (epoch 6.526), train_loss = 1.54187219, grad/param norm = 1.8930e-01, time/batch = 0.6402s	
3401/26050 (epoch 6.528), train_loss = 1.55055781, grad/param norm = 2.0350e-01, time/batch = 0.6415s	
3402/26050 (epoch 6.530), train_loss = 1.45798766, grad/param norm = 1.8385e-01, time/batch = 0.6421s	
3403/26050 (epoch 6.532), train_loss = 1.48540358, grad/param norm = 1.8577e-01, time/batch = 0.6480s	
3404/26050 (epoch 6.534), train_loss = 1.56938013, grad/param norm = 1.9152e-01, time/batch = 0.6420s	
3405/26050 (epoch 6.536), train_loss = 1.40601658, grad/param norm = 1.9425e-01, time/batch = 0.6463s	
3406/26050 (epoch 6.537), train_loss = 1.59919041, grad/param norm = 1.8969e-01, time/batch = 0.6415s	
3407/26050 (epoch 6.539), train_loss = 1.44513102, grad/param norm = 1.7991e-01, time/batch = 0.6414s	
3408/26050 (epoch 6.541), train_loss = 1.69163123, grad/param norm = 2.2916e-01, time/batch = 0.6792s	
3409/26050 (epoch 6.543), train_loss = 1.29566394, grad/param norm = 1.8236e-01, time/batch = 0.6649s	
3410/26050 (epoch 6.545), train_loss = 1.54499855, grad/param norm = 1.9804e-01, time/batch = 0.6525s	
3411/26050 (epoch 6.547), train_loss = 1.50170390, grad/param norm = 1.9406e-01, time/batch = 0.6426s	
3412/26050 (epoch 6.549), train_loss = 1.31884949, grad/param norm = 1.8413e-01, time/batch = 0.6442s	
3413/26050 (epoch 6.551), train_loss = 1.53572164, grad/param norm = 2.0262e-01, time/batch = 0.6422s	
3414/26050 (epoch 6.553), train_loss = 1.39650904, grad/param norm = 1.9185e-01, time/batch = 0.6418s	
3415/26050 (epoch 6.555), train_loss = 1.41128702, grad/param norm = 1.8133e-01, time/batch = 0.6426s	
3416/26050 (epoch 6.557), train_loss = 1.55639372, grad/param norm = 1.8799e-01, time/batch = 0.6399s	
3417/26050 (epoch 6.559), train_loss = 1.49309927, grad/param norm = 1.9802e-01, time/batch = 0.6501s	
3418/26050 (epoch 6.560), train_loss = 1.46862607, grad/param norm = 1.9623e-01, time/batch = 0.6542s	
3419/26050 (epoch 6.562), train_loss = 1.45071654, grad/param norm = 1.9453e-01, time/batch = 0.6455s	
3420/26050 (epoch 6.564), train_loss = 1.67074133, grad/param norm = 2.1478e-01, time/batch = 0.6434s	
3421/26050 (epoch 6.566), train_loss = 1.35152700, grad/param norm = 1.7721e-01, time/batch = 0.6495s	
3422/26050 (epoch 6.568), train_loss = 1.50086897, grad/param norm = 1.8048e-01, time/batch = 0.6405s	
3423/26050 (epoch 6.570), train_loss = 1.61884666, grad/param norm = 2.0288e-01, time/batch = 0.6652s	
3424/26050 (epoch 6.572), train_loss = 1.49701773, grad/param norm = 1.8276e-01, time/batch = 0.6776s	
3425/26050 (epoch 6.574), train_loss = 1.59961050, grad/param norm = 2.2386e-01, time/batch = 0.6398s	
3426/26050 (epoch 6.576), train_loss = 1.57374349, grad/param norm = 1.9939e-01, time/batch = 0.6402s	
3427/26050 (epoch 6.578), train_loss = 1.48942391, grad/param norm = 1.9656e-01, time/batch = 0.6475s	
3428/26050 (epoch 6.580), train_loss = 1.35114448, grad/param norm = 1.8094e-01, time/batch = 0.6512s	
3429/26050 (epoch 6.582), train_loss = 1.54186460, grad/param norm = 1.9210e-01, time/batch = 0.6407s	
3430/26050 (epoch 6.583), train_loss = 1.54770796, grad/param norm = 1.8929e-01, time/batch = 0.6409s	
3431/26050 (epoch 6.585), train_loss = 1.35978446, grad/param norm = 1.8101e-01, time/batch = 0.6421s	
3432/26050 (epoch 6.587), train_loss = 1.54991115, grad/param norm = 1.9220e-01, time/batch = 0.6415s	
3433/26050 (epoch 6.589), train_loss = 1.56934953, grad/param norm = 2.1088e-01, time/batch = 0.6449s	
3434/26050 (epoch 6.591), train_loss = 1.53730126, grad/param norm = 1.9071e-01, time/batch = 0.6434s	
3435/26050 (epoch 6.593), train_loss = 1.37516454, grad/param norm = 2.0412e-01, time/batch = 0.6462s	
3436/26050 (epoch 6.595), train_loss = 1.66313627, grad/param norm = 2.3441e-01, time/batch = 0.6405s	
3437/26050 (epoch 6.597), train_loss = 1.52898177, grad/param norm = 2.0224e-01, time/batch = 0.6399s	
3438/26050 (epoch 6.599), train_loss = 1.36157561, grad/param norm = 1.7890e-01, time/batch = 0.6472s	
3439/26050 (epoch 6.601), train_loss = 1.68784427, grad/param norm = 1.9469e-01, time/batch = 0.6730s	
3440/26050 (epoch 6.603), train_loss = 1.55191861, grad/param norm = 1.9298e-01, time/batch = 0.6405s	
3441/26050 (epoch 6.605), train_loss = 1.40426708, grad/param norm = 1.7120e-01, time/batch = 0.6434s	
3442/26050 (epoch 6.607), train_loss = 1.59413971, grad/param norm = 2.0048e-01, time/batch = 0.6416s	
3443/26050 (epoch 6.608), train_loss = 1.42064750, grad/param norm = 1.7306e-01, time/batch = 0.6426s	
3444/26050 (epoch 6.610), train_loss = 1.45643115, grad/param norm = 1.9471e-01, time/batch = 0.6413s	
3445/26050 (epoch 6.612), train_loss = 1.42743632, grad/param norm = 1.9586e-01, time/batch = 0.6397s	
3446/26050 (epoch 6.614), train_loss = 1.52508347, grad/param norm = 1.8972e-01, time/batch = 0.6414s	
3447/26050 (epoch 6.616), train_loss = 1.77040568, grad/param norm = 1.9767e-01, time/batch = 0.6409s	
3448/26050 (epoch 6.618), train_loss = 1.40422712, grad/param norm = 1.8694e-01, time/batch = 0.6406s	
3449/26050 (epoch 6.620), train_loss = 1.49847647, grad/param norm = 2.0054e-01, time/batch = 0.6400s	
3450/26050 (epoch 6.622), train_loss = 1.22569900, grad/param norm = 1.6706e-01, time/batch = 0.6403s	
3451/26050 (epoch 6.624), train_loss = 1.34725099, grad/param norm = 1.7098e-01, time/batch = 0.6483s	
3452/26050 (epoch 6.626), train_loss = 1.49908111, grad/param norm = 1.9460e-01, time/batch = 0.6438s	
3453/26050 (epoch 6.628), train_loss = 1.48205185, grad/param norm = 2.0044e-01, time/batch = 0.6403s	
3454/26050 (epoch 6.630), train_loss = 1.60225941, grad/param norm = 1.8482e-01, time/batch = 0.6419s	
3455/26050 (epoch 6.631), train_loss = 1.60670537, grad/param norm = 2.0441e-01, time/batch = 0.6405s	
3456/26050 (epoch 6.633), train_loss = 1.34280669, grad/param norm = 1.7267e-01, time/batch = 0.6405s	
3457/26050 (epoch 6.635), train_loss = 1.34844095, grad/param norm = 1.7319e-01, time/batch = 0.6412s	
3458/26050 (epoch 6.637), train_loss = 1.36792279, grad/param norm = 1.8297e-01, time/batch = 0.6432s	
3459/26050 (epoch 6.639), train_loss = 1.57537867, grad/param norm = 1.9073e-01, time/batch = 0.6413s	
3460/26050 (epoch 6.641), train_loss = 1.38220881, grad/param norm = 1.5936e-01, time/batch = 0.6407s	
3461/26050 (epoch 6.643), train_loss = 1.36035472, grad/param norm = 1.7448e-01, time/batch = 0.6416s	
3462/26050 (epoch 6.645), train_loss = 1.51954703, grad/param norm = 1.9736e-01, time/batch = 0.6416s	
3463/26050 (epoch 6.647), train_loss = 1.41249759, grad/param norm = 1.8559e-01, time/batch = 0.6422s	
3464/26050 (epoch 6.649), train_loss = 1.52493193, grad/param norm = 2.0517e-01, time/batch = 0.6466s	
3465/26050 (epoch 6.651), train_loss = 1.42359285, grad/param norm = 1.8667e-01, time/batch = 0.6412s	
3466/26050 (epoch 6.653), train_loss = 1.46308699, grad/param norm = 1.9475e-01, time/batch = 0.6620s	
3467/26050 (epoch 6.655), train_loss = 1.36590986, grad/param norm = 1.8908e-01, time/batch = 0.6591s	
3468/26050 (epoch 6.656), train_loss = 1.34997309, grad/param norm = 1.8144e-01, time/batch = 0.6593s	
3469/26050 (epoch 6.658), train_loss = 1.65781669, grad/param norm = 1.9913e-01, time/batch = 0.6564s	
3470/26050 (epoch 6.660), train_loss = 1.36187082, grad/param norm = 2.0918e-01, time/batch = 0.6534s	
3471/26050 (epoch 6.662), train_loss = 1.31870733, grad/param norm = 1.7322e-01, time/batch = 0.6469s	
3472/26050 (epoch 6.664), train_loss = 1.45010499, grad/param norm = 2.0063e-01, time/batch = 0.6433s	
3473/26050 (epoch 6.666), train_loss = 1.50808982, grad/param norm = 2.0690e-01, time/batch = 0.6534s	
3474/26050 (epoch 6.668), train_loss = 1.22714103, grad/param norm = 1.6289e-01, time/batch = 0.6548s	
3475/26050 (epoch 6.670), train_loss = 1.64954877, grad/param norm = 2.1812e-01, time/batch = 0.6613s	
3476/26050 (epoch 6.672), train_loss = 1.36815810, grad/param norm = 1.8048e-01, time/batch = 0.6468s	
3477/26050 (epoch 6.674), train_loss = 1.33065269, grad/param norm = 1.6801e-01, time/batch = 0.6438s	
3478/26050 (epoch 6.676), train_loss = 1.49111376, grad/param norm = 1.8721e-01, time/batch = 0.6446s	
3479/26050 (epoch 6.678), train_loss = 1.62622369, grad/param norm = 2.0136e-01, time/batch = 0.6429s	
3480/26050 (epoch 6.679), train_loss = 1.63364215, grad/param norm = 2.1237e-01, time/batch = 0.6416s	
3481/26050 (epoch 6.681), train_loss = 1.48588311, grad/param norm = 2.0383e-01, time/batch = 0.6431s	
3482/26050 (epoch 6.683), train_loss = 1.41133810, grad/param norm = 2.0083e-01, time/batch = 0.6480s	
3483/26050 (epoch 6.685), train_loss = 1.40167573, grad/param norm = 1.7507e-01, time/batch = 0.6400s	
3484/26050 (epoch 6.687), train_loss = 1.25376840, grad/param norm = 1.7168e-01, time/batch = 0.6405s	
3485/26050 (epoch 6.689), train_loss = 1.44745902, grad/param norm = 1.9210e-01, time/batch = 0.6393s	
3486/26050 (epoch 6.691), train_loss = 1.18012165, grad/param norm = 1.7312e-01, time/batch = 0.6404s	
3487/26050 (epoch 6.693), train_loss = 1.37591564, grad/param norm = 1.9421e-01, time/batch = 0.6383s	
3488/26050 (epoch 6.695), train_loss = 1.48869756, grad/param norm = 1.9547e-01, time/batch = 0.6386s	
3489/26050 (epoch 6.697), train_loss = 1.31519827, grad/param norm = 1.8926e-01, time/batch = 0.6529s	
3490/26050 (epoch 6.699), train_loss = 1.52298331, grad/param norm = 1.9863e-01, time/batch = 0.6827s	
3491/26050 (epoch 6.701), train_loss = 1.28298582, grad/param norm = 1.7542e-01, time/batch = 0.6463s	
3492/26050 (epoch 6.702), train_loss = 1.69854854, grad/param norm = 1.8649e-01, time/batch = 0.6384s	
3493/26050 (epoch 6.704), train_loss = 1.45738896, grad/param norm = 1.8444e-01, time/batch = 0.6379s	
3494/26050 (epoch 6.706), train_loss = 1.55553293, grad/param norm = 2.1878e-01, time/batch = 0.6384s	
3495/26050 (epoch 6.708), train_loss = 1.53339544, grad/param norm = 1.8982e-01, time/batch = 0.6405s	
3496/26050 (epoch 6.710), train_loss = 1.54648718, grad/param norm = 1.9157e-01, time/batch = 0.6385s	
3497/26050 (epoch 6.712), train_loss = 1.64927890, grad/param norm = 1.9907e-01, time/batch = 0.6403s	
3498/26050 (epoch 6.714), train_loss = 1.34944130, grad/param norm = 1.9653e-01, time/batch = 0.6401s	
3499/26050 (epoch 6.716), train_loss = 1.70874775, grad/param norm = 2.2944e-01, time/batch = 0.6420s	
3500/26050 (epoch 6.718), train_loss = 1.57147516, grad/param norm = 2.0774e-01, time/batch = 0.6441s	
3501/26050 (epoch 6.720), train_loss = 1.39207193, grad/param norm = 1.9155e-01, time/batch = 0.6412s	
3502/26050 (epoch 6.722), train_loss = 1.32664859, grad/param norm = 1.8389e-01, time/batch = 0.6385s	
3503/26050 (epoch 6.724), train_loss = 1.32223169, grad/param norm = 1.8729e-01, time/batch = 0.6381s	
3504/26050 (epoch 6.726), train_loss = 1.56804353, grad/param norm = 1.8983e-01, time/batch = 0.6384s	
3505/26050 (epoch 6.727), train_loss = 1.54371945, grad/param norm = 1.9166e-01, time/batch = 0.6748s	
3506/26050 (epoch 6.729), train_loss = 1.55658899, grad/param norm = 2.1185e-01, time/batch = 0.6680s	
3507/26050 (epoch 6.731), train_loss = 1.45040129, grad/param norm = 1.7460e-01, time/batch = 0.6375s	
3508/26050 (epoch 6.733), train_loss = 1.45918674, grad/param norm = 2.2197e-01, time/batch = 0.6380s	
3509/26050 (epoch 6.735), train_loss = 1.68359356, grad/param norm = 2.0996e-01, time/batch = 0.6374s	
3510/26050 (epoch 6.737), train_loss = 1.50407837, grad/param norm = 1.9730e-01, time/batch = 0.6375s	
3511/26050 (epoch 6.739), train_loss = 1.49497337, grad/param norm = 1.8171e-01, time/batch = 0.6394s	
3512/26050 (epoch 6.741), train_loss = 1.36529600, grad/param norm = 1.7597e-01, time/batch = 0.6386s	
3513/26050 (epoch 6.743), train_loss = 1.57130678, grad/param norm = 2.4320e-01, time/batch = 0.6420s	
3514/26050 (epoch 6.745), train_loss = 1.33037518, grad/param norm = 1.8307e-01, time/batch = 0.6444s	
3515/26050 (epoch 6.747), train_loss = 1.37644473, grad/param norm = 1.8852e-01, time/batch = 0.6377s	
3516/26050 (epoch 6.749), train_loss = 1.55359147, grad/param norm = 1.9990e-01, time/batch = 0.6374s	
3517/26050 (epoch 6.750), train_loss = 1.42223210, grad/param norm = 1.7957e-01, time/batch = 0.6387s	
3518/26050 (epoch 6.752), train_loss = 1.51097012, grad/param norm = 2.0850e-01, time/batch = 0.6377s	
3519/26050 (epoch 6.754), train_loss = 1.40703021, grad/param norm = 1.9298e-01, time/batch = 0.6382s	
3520/26050 (epoch 6.756), train_loss = 1.55733019, grad/param norm = 2.2798e-01, time/batch = 0.6539s	
3521/26050 (epoch 6.758), train_loss = 1.49170280, grad/param norm = 1.9900e-01, time/batch = 0.6841s	
3522/26050 (epoch 6.760), train_loss = 1.55791330, grad/param norm = 2.0824e-01, time/batch = 0.6431s	
3523/26050 (epoch 6.762), train_loss = 1.37336915, grad/param norm = 1.7861e-01, time/batch = 0.6381s	
3524/26050 (epoch 6.764), train_loss = 1.57814866, grad/param norm = 1.9977e-01, time/batch = 0.6384s	
3525/26050 (epoch 6.766), train_loss = 1.57034040, grad/param norm = 2.0470e-01, time/batch = 0.6398s	
3526/26050 (epoch 6.768), train_loss = 1.37501834, grad/param norm = 1.7052e-01, time/batch = 0.6394s	
3527/26050 (epoch 6.770), train_loss = 1.46195543, grad/param norm = 1.9311e-01, time/batch = 0.6410s	
3528/26050 (epoch 6.772), train_loss = 1.46261488, grad/param norm = 1.9225e-01, time/batch = 0.6438s	
3529/26050 (epoch 6.774), train_loss = 1.36671724, grad/param norm = 1.8888e-01, time/batch = 0.6411s	
3530/26050 (epoch 6.775), train_loss = 1.17521783, grad/param norm = 1.8261e-01, time/batch = 0.6384s	
3531/26050 (epoch 6.777), train_loss = 1.38383441, grad/param norm = 1.8819e-01, time/batch = 0.6411s	
3532/26050 (epoch 6.779), train_loss = 1.44176098, grad/param norm = 2.0554e-01, time/batch = 0.6393s	
3533/26050 (epoch 6.781), train_loss = 1.41078043, grad/param norm = 1.8292e-01, time/batch = 0.6396s	
3534/26050 (epoch 6.783), train_loss = 1.37418449, grad/param norm = 1.6624e-01, time/batch = 0.6413s	
3535/26050 (epoch 6.785), train_loss = 1.42995576, grad/param norm = 2.0805e-01, time/batch = 0.6392s	
3536/26050 (epoch 6.787), train_loss = 1.39228144, grad/param norm = 1.8392e-01, time/batch = 0.6407s	
3537/26050 (epoch 6.789), train_loss = 1.46878784, grad/param norm = 2.0611e-01, time/batch = 0.6394s	
3538/26050 (epoch 6.791), train_loss = 1.47784042, grad/param norm = 1.8643e-01, time/batch = 0.6381s	
3539/26050 (epoch 6.793), train_loss = 1.45634489, grad/param norm = 1.9723e-01, time/batch = 0.6392s	
3540/26050 (epoch 6.795), train_loss = 1.30003889, grad/param norm = 1.7997e-01, time/batch = 0.6399s	
3541/26050 (epoch 6.797), train_loss = 1.33432807, grad/param norm = 1.7157e-01, time/batch = 0.6402s	
3542/26050 (epoch 6.798), train_loss = 1.32650155, grad/param norm = 1.9093e-01, time/batch = 0.6415s	
3543/26050 (epoch 6.800), train_loss = 1.30161619, grad/param norm = 1.7647e-01, time/batch = 0.6406s	
3544/26050 (epoch 6.802), train_loss = 1.46258535, grad/param norm = 1.9146e-01, time/batch = 0.6467s	
3545/26050 (epoch 6.804), train_loss = 1.42935827, grad/param norm = 1.8175e-01, time/batch = 0.6448s	
3546/26050 (epoch 6.806), train_loss = 1.63242488, grad/param norm = 2.1901e-01, time/batch = 0.6400s	
3547/26050 (epoch 6.808), train_loss = 1.41252509, grad/param norm = 1.8087e-01, time/batch = 0.6390s	
3548/26050 (epoch 6.810), train_loss = 1.36058097, grad/param norm = 1.9022e-01, time/batch = 0.6393s	
3549/26050 (epoch 6.812), train_loss = 1.31572936, grad/param norm = 1.8180e-01, time/batch = 0.6427s	
3550/26050 (epoch 6.814), train_loss = 1.33358404, grad/param norm = 2.0498e-01, time/batch = 0.6421s	
3551/26050 (epoch 6.816), train_loss = 1.52802708, grad/param norm = 1.9643e-01, time/batch = 0.6561s	
3552/26050 (epoch 6.818), train_loss = 1.62664134, grad/param norm = 2.0983e-01, time/batch = 0.6534s	
3553/26050 (epoch 6.820), train_loss = 1.48709464, grad/param norm = 1.8973e-01, time/batch = 0.6529s	
3554/26050 (epoch 6.821), train_loss = 1.63945268, grad/param norm = 2.0945e-01, time/batch = 0.6557s	
3555/26050 (epoch 6.823), train_loss = 1.68703573, grad/param norm = 2.0366e-01, time/batch = 0.6506s	
3556/26050 (epoch 6.825), train_loss = 1.38973519, grad/param norm = 1.9541e-01, time/batch = 0.6767s	
3557/26050 (epoch 6.827), train_loss = 1.53104855, grad/param norm = 2.0593e-01, time/batch = 0.6725s	
3558/26050 (epoch 6.829), train_loss = 1.54174040, grad/param norm = 1.9312e-01, time/batch = 0.6634s	
3559/26050 (epoch 6.831), train_loss = 1.60854708, grad/param norm = 1.9699e-01, time/batch = 0.6652s	
3560/26050 (epoch 6.833), train_loss = 1.66146906, grad/param norm = 1.9547e-01, time/batch = 0.6651s	
3561/26050 (epoch 6.835), train_loss = 1.73268497, grad/param norm = 2.0349e-01, time/batch = 0.6654s	
3562/26050 (epoch 6.837), train_loss = 1.39678529, grad/param norm = 1.8345e-01, time/batch = 0.6577s	
3563/26050 (epoch 6.839), train_loss = 1.55809505, grad/param norm = 1.8390e-01, time/batch = 0.6562s	
3564/26050 (epoch 6.841), train_loss = 1.56282373, grad/param norm = 1.8332e-01, time/batch = 0.6549s	
3565/26050 (epoch 6.843), train_loss = 1.52708476, grad/param norm = 1.8544e-01, time/batch = 0.6520s	
3566/26050 (epoch 6.845), train_loss = 1.38310915, grad/param norm = 1.8708e-01, time/batch = 0.6670s	
3567/26050 (epoch 6.846), train_loss = 1.58621290, grad/param norm = 1.9065e-01, time/batch = 0.6839s	
3568/26050 (epoch 6.848), train_loss = 1.41190454, grad/param norm = 1.8577e-01, time/batch = 0.6700s	
3569/26050 (epoch 6.850), train_loss = 1.39851344, grad/param norm = 1.7717e-01, time/batch = 0.6587s	
3570/26050 (epoch 6.852), train_loss = 1.44678057, grad/param norm = 2.0298e-01, time/batch = 0.6433s	
3571/26050 (epoch 6.854), train_loss = 1.48740819, grad/param norm = 1.9507e-01, time/batch = 0.6426s	
3572/26050 (epoch 6.856), train_loss = 1.37125359, grad/param norm = 1.8474e-01, time/batch = 0.6407s	
3573/26050 (epoch 6.858), train_loss = 1.34014784, grad/param norm = 1.9303e-01, time/batch = 0.6450s	
3574/26050 (epoch 6.860), train_loss = 1.49316212, grad/param norm = 2.0294e-01, time/batch = 0.6542s	
3575/26050 (epoch 6.862), train_loss = 1.47649216, grad/param norm = 1.9617e-01, time/batch = 0.6417s	
3576/26050 (epoch 6.864), train_loss = 1.40865670, grad/param norm = 1.9345e-01, time/batch = 0.6387s	
3577/26050 (epoch 6.866), train_loss = 1.33942283, grad/param norm = 1.7525e-01, time/batch = 0.6403s	
3578/26050 (epoch 6.868), train_loss = 1.58992328, grad/param norm = 2.0766e-01, time/batch = 0.6410s	
3579/26050 (epoch 6.869), train_loss = 1.29758702, grad/param norm = 1.7083e-01, time/batch = 0.6422s	
3580/26050 (epoch 6.871), train_loss = 1.25390850, grad/param norm = 1.6680e-01, time/batch = 0.6398s	
3581/26050 (epoch 6.873), train_loss = 1.46363064, grad/param norm = 1.7948e-01, time/batch = 0.6415s	
3582/26050 (epoch 6.875), train_loss = 1.43620326, grad/param norm = 1.8789e-01, time/batch = 0.6825s	
3583/26050 (epoch 6.877), train_loss = 1.28544987, grad/param norm = 1.8850e-01, time/batch = 0.6617s	
3584/26050 (epoch 6.879), train_loss = 1.40719313, grad/param norm = 1.7030e-01, time/batch = 0.6474s	
3585/26050 (epoch 6.881), train_loss = 1.64921243, grad/param norm = 2.0498e-01, time/batch = 0.6542s	
3586/26050 (epoch 6.883), train_loss = 1.46943728, grad/param norm = 1.7748e-01, time/batch = 0.6536s	
3587/26050 (epoch 6.885), train_loss = 1.16814604, grad/param norm = 1.6309e-01, time/batch = 0.6425s	
3588/26050 (epoch 6.887), train_loss = 1.50734798, grad/param norm = 1.9187e-01, time/batch = 0.6487s	
3589/26050 (epoch 6.889), train_loss = 1.35697283, grad/param norm = 1.7684e-01, time/batch = 0.6387s	
3590/26050 (epoch 6.891), train_loss = 1.21018004, grad/param norm = 1.6740e-01, time/batch = 0.6427s	
3591/26050 (epoch 6.893), train_loss = 1.16578080, grad/param norm = 1.5537e-01, time/batch = 0.6441s	
3592/26050 (epoch 6.894), train_loss = 1.32590777, grad/param norm = 1.6319e-01, time/batch = 0.6412s	
3593/26050 (epoch 6.896), train_loss = 1.55261170, grad/param norm = 1.8965e-01, time/batch = 0.6389s	
3594/26050 (epoch 6.898), train_loss = 1.38050919, grad/param norm = 1.8979e-01, time/batch = 0.6404s	
3595/26050 (epoch 6.900), train_loss = 1.67555347, grad/param norm = 2.0328e-01, time/batch = 0.6403s	
3596/26050 (epoch 6.902), train_loss = 1.45652878, grad/param norm = 1.8042e-01, time/batch = 0.6395s	
3597/26050 (epoch 6.904), train_loss = 1.39739471, grad/param norm = 1.7957e-01, time/batch = 0.6658s	
3598/26050 (epoch 6.906), train_loss = 1.42487550, grad/param norm = 1.8578e-01, time/batch = 0.6776s	
3599/26050 (epoch 6.908), train_loss = 1.41352305, grad/param norm = 1.8835e-01, time/batch = 0.6388s	
3600/26050 (epoch 6.910), train_loss = 1.36594036, grad/param norm = 1.7468e-01, time/batch = 0.6396s	
3601/26050 (epoch 6.912), train_loss = 1.72773265, grad/param norm = 2.0186e-01, time/batch = 0.6402s	
3602/26050 (epoch 6.914), train_loss = 1.90889032, grad/param norm = 2.0529e-01, time/batch = 0.6389s	
3603/26050 (epoch 6.916), train_loss = 1.64004542, grad/param norm = 2.1621e-01, time/batch = 0.6399s	
3604/26050 (epoch 6.917), train_loss = 1.49796501, grad/param norm = 1.9781e-01, time/batch = 0.6581s	
3605/26050 (epoch 6.919), train_loss = 1.56120804, grad/param norm = 2.0010e-01, time/batch = 0.6455s	
3606/26050 (epoch 6.921), train_loss = 1.35999001, grad/param norm = 2.1002e-01, time/batch = 0.6414s	
3607/26050 (epoch 6.923), train_loss = 1.41573385, grad/param norm = 2.0043e-01, time/batch = 0.6387s	
3608/26050 (epoch 6.925), train_loss = 1.38472181, grad/param norm = 1.7858e-01, time/batch = 0.6393s	
3609/26050 (epoch 6.927), train_loss = 1.31758370, grad/param norm = 1.6417e-01, time/batch = 0.6389s	
3610/26050 (epoch 6.929), train_loss = 1.36370652, grad/param norm = 1.8722e-01, time/batch = 0.6385s	
3611/26050 (epoch 6.931), train_loss = 1.73401826, grad/param norm = 2.3975e-01, time/batch = 0.6409s	
3612/26050 (epoch 6.933), train_loss = 1.42834172, grad/param norm = 2.1249e-01, time/batch = 0.6493s	
3613/26050 (epoch 6.935), train_loss = 1.35991496, grad/param norm = 1.9166e-01, time/batch = 0.6832s	
3614/26050 (epoch 6.937), train_loss = 1.42524966, grad/param norm = 1.7201e-01, time/batch = 0.6520s	
3615/26050 (epoch 6.939), train_loss = 1.31691506, grad/param norm = 1.7615e-01, time/batch = 0.6388s	
3616/26050 (epoch 6.940), train_loss = 1.47576807, grad/param norm = 1.8223e-01, time/batch = 0.6442s	
3617/26050 (epoch 6.942), train_loss = 1.49381052, grad/param norm = 2.0450e-01, time/batch = 0.6390s	
3618/26050 (epoch 6.944), train_loss = 1.39801213, grad/param norm = 1.9215e-01, time/batch = 0.6390s	
3619/26050 (epoch 6.946), train_loss = 1.59800904, grad/param norm = 1.8189e-01, time/batch = 0.6389s	
3620/26050 (epoch 6.948), train_loss = 1.24689235, grad/param norm = 2.0697e-01, time/batch = 0.6425s	
3621/26050 (epoch 6.950), train_loss = 1.40098570, grad/param norm = 1.8169e-01, time/batch = 0.6419s	
3622/26050 (epoch 6.952), train_loss = 1.62089629, grad/param norm = 1.9984e-01, time/batch = 0.6377s	
3623/26050 (epoch 6.954), train_loss = 1.54595736, grad/param norm = 1.8129e-01, time/batch = 0.6383s	
3624/26050 (epoch 6.956), train_loss = 1.55507028, grad/param norm = 2.0186e-01, time/batch = 0.6385s	
3625/26050 (epoch 6.958), train_loss = 1.44361802, grad/param norm = 1.8800e-01, time/batch = 0.6379s	
3626/26050 (epoch 6.960), train_loss = 1.38862083, grad/param norm = 1.8116e-01, time/batch = 0.6385s	
3627/26050 (epoch 6.962), train_loss = 1.35289465, grad/param norm = 1.7918e-01, time/batch = 0.6428s	
3628/26050 (epoch 6.964), train_loss = 1.41218900, grad/param norm = 1.8274e-01, time/batch = 0.6565s	
3629/26050 (epoch 6.965), train_loss = 1.30635929, grad/param norm = 1.8213e-01, time/batch = 0.6419s	
3630/26050 (epoch 6.967), train_loss = 1.77352982, grad/param norm = 1.9378e-01, time/batch = 0.6507s	
3631/26050 (epoch 6.969), train_loss = 1.39728001, grad/param norm = 1.7533e-01, time/batch = 0.6522s	
3632/26050 (epoch 6.971), train_loss = 1.28888942, grad/param norm = 1.6725e-01, time/batch = 0.6546s	
3633/26050 (epoch 6.973), train_loss = 1.41264250, grad/param norm = 2.0379e-01, time/batch = 0.6543s	
3634/26050 (epoch 6.975), train_loss = 1.51279227, grad/param norm = 1.7169e-01, time/batch = 0.6541s	
3635/26050 (epoch 6.977), train_loss = 1.45398053, grad/param norm = 1.6230e-01, time/batch = 0.6508s	
3636/26050 (epoch 6.979), train_loss = 1.28753705, grad/param norm = 1.7883e-01, time/batch = 0.6548s	
3637/26050 (epoch 6.981), train_loss = 1.53214031, grad/param norm = 1.7785e-01, time/batch = 0.6585s	
3638/26050 (epoch 6.983), train_loss = 1.53731989, grad/param norm = 1.9208e-01, time/batch = 0.6555s	
3639/26050 (epoch 6.985), train_loss = 1.47684334, grad/param norm = 1.8501e-01, time/batch = 0.6570s	
3640/26050 (epoch 6.987), train_loss = 1.61961154, grad/param norm = 1.9963e-01, time/batch = 0.6574s	
3641/26050 (epoch 6.988), train_loss = 1.57594423, grad/param norm = 2.0336e-01, time/batch = 0.6606s	
3642/26050 (epoch 6.990), train_loss = 1.38566116, grad/param norm = 1.8805e-01, time/batch = 0.6482s	
3643/26050 (epoch 6.992), train_loss = 1.64351751, grad/param norm = 2.1302e-01, time/batch = 0.6631s	
3644/26050 (epoch 6.994), train_loss = 1.43654905, grad/param norm = 1.9643e-01, time/batch = 0.6824s	
3645/26050 (epoch 6.996), train_loss = 1.45515056, grad/param norm = 2.2519e-01, time/batch = 0.6399s	
3646/26050 (epoch 6.998), train_loss = 1.48606433, grad/param norm = 1.9274e-01, time/batch = 0.6438s	
3647/26050 (epoch 7.000), train_loss = 1.43979580, grad/param norm = 1.9306e-01, time/batch = 0.6403s	
3648/26050 (epoch 7.002), train_loss = 1.47718505, grad/param norm = 1.8805e-01, time/batch = 0.6404s	
3649/26050 (epoch 7.004), train_loss = 1.39059287, grad/param norm = 1.9337e-01, time/batch = 0.6399s	
3650/26050 (epoch 7.006), train_loss = 1.36133085, grad/param norm = 1.7162e-01, time/batch = 0.6469s	
3651/26050 (epoch 7.008), train_loss = 1.35228925, grad/param norm = 1.8230e-01, time/batch = 0.6642s	
3652/26050 (epoch 7.010), train_loss = 1.40591306, grad/param norm = 1.7707e-01, time/batch = 0.6408s	
3653/26050 (epoch 7.012), train_loss = 1.49673558, grad/param norm = 1.9741e-01, time/batch = 0.6666s	
3654/26050 (epoch 7.013), train_loss = 1.90112277, grad/param norm = 2.1073e-01, time/batch = 0.6510s	
3655/26050 (epoch 7.015), train_loss = 1.31776192, grad/param norm = 1.7392e-01, time/batch = 0.6404s	
3656/26050 (epoch 7.017), train_loss = 1.47344625, grad/param norm = 1.9499e-01, time/batch = 0.6420s	
3657/26050 (epoch 7.019), train_loss = 1.25610783, grad/param norm = 1.5668e-01, time/batch = 0.6423s	
3658/26050 (epoch 7.021), train_loss = 1.58413312, grad/param norm = 2.0324e-01, time/batch = 0.6426s	
3659/26050 (epoch 7.023), train_loss = 1.31003886, grad/param norm = 1.7548e-01, time/batch = 0.6620s	
3660/26050 (epoch 7.025), train_loss = 1.37750396, grad/param norm = 1.7825e-01, time/batch = 0.6467s	
3661/26050 (epoch 7.027), train_loss = 1.20571475, grad/param norm = 1.6769e-01, time/batch = 0.6421s	
3662/26050 (epoch 7.029), train_loss = 1.38848765, grad/param norm = 1.7599e-01, time/batch = 0.6404s	
3663/26050 (epoch 7.031), train_loss = 1.63762235, grad/param norm = 2.0992e-01, time/batch = 0.6422s	
3664/26050 (epoch 7.033), train_loss = 1.49249418, grad/param norm = 1.9069e-01, time/batch = 0.6411s	
3665/26050 (epoch 7.035), train_loss = 1.59321307, grad/param norm = 1.8950e-01, time/batch = 0.6409s	
3666/26050 (epoch 7.036), train_loss = 1.40547883, grad/param norm = 2.0260e-01, time/batch = 0.6513s	
3667/26050 (epoch 7.038), train_loss = 1.23337107, grad/param norm = 1.7104e-01, time/batch = 0.6572s	
3668/26050 (epoch 7.040), train_loss = 1.50777626, grad/param norm = 1.8465e-01, time/batch = 0.6454s	
3669/26050 (epoch 7.042), train_loss = 1.29592711, grad/param norm = 1.9810e-01, time/batch = 0.6415s	
3670/26050 (epoch 7.044), train_loss = 1.48137085, grad/param norm = 1.8076e-01, time/batch = 0.6425s	
3671/26050 (epoch 7.046), train_loss = 1.23253274, grad/param norm = 1.8926e-01, time/batch = 0.6450s	
3672/26050 (epoch 7.048), train_loss = 1.46255631, grad/param norm = 1.8910e-01, time/batch = 0.6428s	
3673/26050 (epoch 7.050), train_loss = 1.32648727, grad/param norm = 1.9688e-01, time/batch = 0.6435s	
3674/26050 (epoch 7.052), train_loss = 1.44267147, grad/param norm = 1.9885e-01, time/batch = 0.6734s	
3675/26050 (epoch 7.054), train_loss = 1.26430460, grad/param norm = 1.7793e-01, time/batch = 0.6751s	
3676/26050 (epoch 7.056), train_loss = 1.12334386, grad/param norm = 1.5094e-01, time/batch = 0.6456s	
3677/26050 (epoch 7.058), train_loss = 1.33726487, grad/param norm = 1.7290e-01, time/batch = 0.6428s	
3678/26050 (epoch 7.060), train_loss = 1.40591090, grad/param norm = 1.6748e-01, time/batch = 0.6425s	
3679/26050 (epoch 7.061), train_loss = 1.31668396, grad/param norm = 1.7617e-01, time/batch = 0.6449s	
3680/26050 (epoch 7.063), train_loss = 1.36155877, grad/param norm = 1.6517e-01, time/batch = 0.6419s	
3681/26050 (epoch 7.065), train_loss = 1.24565343, grad/param norm = 1.8272e-01, time/batch = 0.6474s	
3682/26050 (epoch 7.067), train_loss = 1.51227211, grad/param norm = 1.9615e-01, time/batch = 0.6461s	
3683/26050 (epoch 7.069), train_loss = 1.49900873, grad/param norm = 1.8393e-01, time/batch = 0.6502s	
3684/26050 (epoch 7.071), train_loss = 1.49752202, grad/param norm = 1.9920e-01, time/batch = 0.6466s	
3685/26050 (epoch 7.073), train_loss = 1.65313634, grad/param norm = 1.8152e-01, time/batch = 0.6773s	
3686/26050 (epoch 7.075), train_loss = 1.31536130, grad/param norm = 1.7065e-01, time/batch = 0.6417s	
3687/26050 (epoch 7.077), train_loss = 1.31816975, grad/param norm = 1.8000e-01, time/batch = 0.6412s	
3688/26050 (epoch 7.079), train_loss = 1.52156023, grad/param norm = 1.9719e-01, time/batch = 0.6400s	
3689/26050 (epoch 7.081), train_loss = 1.36617992, grad/param norm = 1.8937e-01, time/batch = 0.6432s	
3690/26050 (epoch 7.083), train_loss = 1.50309733, grad/param norm = 1.9238e-01, time/batch = 0.6451s	
3691/26050 (epoch 7.084), train_loss = 1.61580631, grad/param norm = 2.2233e-01, time/batch = 0.6424s	
3692/26050 (epoch 7.086), train_loss = 1.57277146, grad/param norm = 1.9257e-01, time/batch = 0.6431s	
3693/26050 (epoch 7.088), train_loss = 1.28437052, grad/param norm = 1.6402e-01, time/batch = 0.6425s	
3694/26050 (epoch 7.090), train_loss = 1.55193344, grad/param norm = 1.8813e-01, time/batch = 0.6422s	
3695/26050 (epoch 7.092), train_loss = 1.39421898, grad/param norm = 1.9373e-01, time/batch = 0.6547s	
3696/26050 (epoch 7.094), train_loss = 1.44870686, grad/param norm = 1.8688e-01, time/batch = 0.6602s	
3697/26050 (epoch 7.096), train_loss = 1.33445299, grad/param norm = 1.7485e-01, time/batch = 0.6661s	
3698/26050 (epoch 7.098), train_loss = 1.35163170, grad/param norm = 1.8225e-01, time/batch = 0.6582s	
3699/26050 (epoch 7.100), train_loss = 1.32962159, grad/param norm = 1.9592e-01, time/batch = 0.6589s	
3700/26050 (epoch 7.102), train_loss = 1.45993131, grad/param norm = 1.8725e-01, time/batch = 0.6760s	
3701/26050 (epoch 7.104), train_loss = 1.48436473, grad/param norm = 1.8848e-01, time/batch = 0.6767s	
3702/26050 (epoch 7.106), train_loss = 1.38457090, grad/param norm = 1.8563e-01, time/batch = 0.6600s	
3703/26050 (epoch 7.107), train_loss = 1.15624763, grad/param norm = 1.7890e-01, time/batch = 0.6600s	
3704/26050 (epoch 7.109), train_loss = 1.32641033, grad/param norm = 1.7317e-01, time/batch = 0.6570s	
3705/26050 (epoch 7.111), train_loss = 1.67006008, grad/param norm = 2.1283e-01, time/batch = 0.6608s	
3706/26050 (epoch 7.113), train_loss = 1.34652659, grad/param norm = 1.9025e-01, time/batch = 0.6599s	
3707/26050 (epoch 7.115), train_loss = 1.54529178, grad/param norm = 1.8433e-01, time/batch = 0.6444s	
3708/26050 (epoch 7.117), train_loss = 1.48980527, grad/param norm = 1.9526e-01, time/batch = 0.6389s	
3709/26050 (epoch 7.119), train_loss = 1.20425083, grad/param norm = 1.7134e-01, time/batch = 0.6402s	
3710/26050 (epoch 7.121), train_loss = 1.47679554, grad/param norm = 1.8813e-01, time/batch = 0.6415s	
3711/26050 (epoch 7.123), train_loss = 1.37142079, grad/param norm = 2.1879e-01, time/batch = 0.6403s	
3712/26050 (epoch 7.125), train_loss = 1.19859092, grad/param norm = 1.5939e-01, time/batch = 0.6420s	
3713/26050 (epoch 7.127), train_loss = 1.19684473, grad/param norm = 1.7609e-01, time/batch = 0.6524s	
3714/26050 (epoch 7.129), train_loss = 1.19374554, grad/param norm = 1.6326e-01, time/batch = 0.6402s	
3715/26050 (epoch 7.131), train_loss = 1.42182511, grad/param norm = 1.8289e-01, time/batch = 0.6649s	
3716/26050 (epoch 7.132), train_loss = 1.34822853, grad/param norm = 1.7201e-01, time/batch = 0.6821s	
3717/26050 (epoch 7.134), train_loss = 1.37343973, grad/param norm = 1.8656e-01, time/batch = 0.6402s	
3718/26050 (epoch 7.136), train_loss = 1.39296235, grad/param norm = 1.7876e-01, time/batch = 0.6472s	
3719/26050 (epoch 7.138), train_loss = 1.26732223, grad/param norm = 2.1190e-01, time/batch = 0.6504s	
3720/26050 (epoch 7.140), train_loss = 1.31289920, grad/param norm = 1.8258e-01, time/batch = 0.6470s	
3721/26050 (epoch 7.142), train_loss = 1.36516382, grad/param norm = 1.8092e-01, time/batch = 0.6430s	
3722/26050 (epoch 7.144), train_loss = 1.21691758, grad/param norm = 1.7346e-01, time/batch = 0.6417s	
3723/26050 (epoch 7.146), train_loss = 1.15302394, grad/param norm = 1.6735e-01, time/batch = 0.6415s	
3724/26050 (epoch 7.148), train_loss = 1.16797039, grad/param norm = 1.4498e-01, time/batch = 0.6420s	
3725/26050 (epoch 7.150), train_loss = 1.39469968, grad/param norm = 1.8307e-01, time/batch = 0.6402s	
3726/26050 (epoch 7.152), train_loss = 1.69087809, grad/param norm = 2.0771e-01, time/batch = 0.6452s	
3727/26050 (epoch 7.154), train_loss = 1.22015691, grad/param norm = 1.7876e-01, time/batch = 0.6471s	
3728/26050 (epoch 7.155), train_loss = 1.22452463, grad/param norm = 1.6630e-01, time/batch = 0.6417s	
3729/26050 (epoch 7.157), train_loss = 1.40710296, grad/param norm = 1.9936e-01, time/batch = 0.6416s	
3730/26050 (epoch 7.159), train_loss = 1.39948321, grad/param norm = 1.9425e-01, time/batch = 0.6415s	
3731/26050 (epoch 7.161), train_loss = 1.60716755, grad/param norm = 2.1452e-01, time/batch = 0.6500s	
3732/26050 (epoch 7.163), train_loss = 1.26155722, grad/param norm = 1.7042e-01, time/batch = 0.6475s	
3733/26050 (epoch 7.165), train_loss = 1.09906765, grad/param norm = 1.6076e-01, time/batch = 0.6437s	
3734/26050 (epoch 7.167), train_loss = 1.54296010, grad/param norm = 2.2051e-01, time/batch = 0.6424s	
3735/26050 (epoch 7.169), train_loss = 1.47655275, grad/param norm = 1.9610e-01, time/batch = 0.6435s	
3736/26050 (epoch 7.171), train_loss = 1.18633393, grad/param norm = 1.5706e-01, time/batch = 0.6430s	
3737/26050 (epoch 7.173), train_loss = 1.36890268, grad/param norm = 1.9187e-01, time/batch = 0.6416s	
3738/26050 (epoch 7.175), train_loss = 1.41026899, grad/param norm = 1.9677e-01, time/batch = 0.6421s	
3739/26050 (epoch 7.177), train_loss = 1.47864292, grad/param norm = 1.8629e-01, time/batch = 0.6408s	
3740/26050 (epoch 7.179), train_loss = 1.09929146, grad/param norm = 1.6743e-01, time/batch = 0.6402s	
3741/26050 (epoch 7.180), train_loss = 1.66120956, grad/param norm = 1.8518e-01, time/batch = 0.6423s	
3742/26050 (epoch 7.182), train_loss = 1.69417409, grad/param norm = 1.9067e-01, time/batch = 0.6455s	
3743/26050 (epoch 7.184), train_loss = 1.43413408, grad/param norm = 1.7632e-01, time/batch = 0.6683s	
3744/26050 (epoch 7.186), train_loss = 1.15848606, grad/param norm = 1.5878e-01, time/batch = 0.6475s	
3745/26050 (epoch 7.188), train_loss = 1.38312144, grad/param norm = 1.7000e-01, time/batch = 0.6521s	
3746/26050 (epoch 7.190), train_loss = 1.45803964, grad/param norm = 1.9519e-01, time/batch = 0.6449s	
3747/26050 (epoch 7.192), train_loss = 1.45084606, grad/param norm = 1.9043e-01, time/batch = 0.6475s	
3748/26050 (epoch 7.194), train_loss = 1.42982364, grad/param norm = 1.8305e-01, time/batch = 0.6398s	
3749/26050 (epoch 7.196), train_loss = 1.49707322, grad/param norm = 1.9793e-01, time/batch = 0.6412s	
3750/26050 (epoch 7.198), train_loss = 1.33257918, grad/param norm = 1.9010e-01, time/batch = 0.6445s	
3751/26050 (epoch 7.200), train_loss = 1.32558680, grad/param norm = 1.8815e-01, time/batch = 0.6841s	
3752/26050 (epoch 7.202), train_loss = 1.33226584, grad/param norm = 1.9425e-01, time/batch = 0.6637s	
3753/26050 (epoch 7.203), train_loss = 1.49120836, grad/param norm = 2.0311e-01, time/batch = 0.6460s	
3754/26050 (epoch 7.205), train_loss = 1.29197462, grad/param norm = 1.7891e-01, time/batch = 0.6438s	
3755/26050 (epoch 7.207), train_loss = 1.37894115, grad/param norm = 1.6555e-01, time/batch = 0.6431s	
3756/26050 (epoch 7.209), train_loss = 1.35959651, grad/param norm = 1.8263e-01, time/batch = 0.6398s	
3757/26050 (epoch 7.211), train_loss = 1.24610446, grad/param norm = 1.8009e-01, time/batch = 0.6396s	
3758/26050 (epoch 7.213), train_loss = 1.44055371, grad/param norm = 1.6959e-01, time/batch = 0.6465s	
3759/26050 (epoch 7.215), train_loss = 1.45792678, grad/param norm = 2.0896e-01, time/batch = 0.6477s	
3760/26050 (epoch 7.217), train_loss = 1.33446960, grad/param norm = 1.7475e-01, time/batch = 0.6565s	
3761/26050 (epoch 7.219), train_loss = 1.32482763, grad/param norm = 1.8836e-01, time/batch = 0.6428s	
3762/26050 (epoch 7.221), train_loss = 1.25916979, grad/param norm = 1.7805e-01, time/batch = 0.6412s	
3763/26050 (epoch 7.223), train_loss = 1.48977958, grad/param norm = 1.9750e-01, time/batch = 0.6423s	
3764/26050 (epoch 7.225), train_loss = 1.30005342, grad/param norm = 1.9703e-01, time/batch = 0.6420s	
3765/26050 (epoch 7.226), train_loss = 1.55523193, grad/param norm = 1.9613e-01, time/batch = 0.6449s	
3766/26050 (epoch 7.228), train_loss = 1.57175731, grad/param norm = 2.0739e-01, time/batch = 0.6707s	
3767/26050 (epoch 7.230), train_loss = 1.44290285, grad/param norm = 1.9422e-01, time/batch = 0.6733s	
3768/26050 (epoch 7.232), train_loss = 1.54497624, grad/param norm = 2.0586e-01, time/batch = 0.6392s	
3769/26050 (epoch 7.234), train_loss = 1.20964218, grad/param norm = 1.8108e-01, time/batch = 0.6395s	
3770/26050 (epoch 7.236), train_loss = 1.45819873, grad/param norm = 2.0902e-01, time/batch = 0.6400s	
3771/26050 (epoch 7.238), train_loss = 1.18215957, grad/param norm = 1.8302e-01, time/batch = 0.6456s	
3772/26050 (epoch 7.240), train_loss = 1.33145958, grad/param norm = 1.6715e-01, time/batch = 0.6417s	
3773/26050 (epoch 7.242), train_loss = 1.35071479, grad/param norm = 1.7544e-01, time/batch = 0.6410s	
3774/26050 (epoch 7.244), train_loss = 1.46417391, grad/param norm = 2.1118e-01, time/batch = 0.6473s	
3775/26050 (epoch 7.246), train_loss = 1.32055472, grad/param norm = 1.6875e-01, time/batch = 0.6412s	
3776/26050 (epoch 7.248), train_loss = 1.45135951, grad/param norm = 1.8960e-01, time/batch = 0.6399s	
3777/26050 (epoch 7.250), train_loss = 1.44353629, grad/param norm = 2.0322e-01, time/batch = 0.6406s	
3778/26050 (epoch 7.251), train_loss = 1.29001832, grad/param norm = 1.7994e-01, time/batch = 0.6404s	
3779/26050 (epoch 7.253), train_loss = 1.20228960, grad/param norm = 1.8067e-01, time/batch = 0.6400s	
3780/26050 (epoch 7.255), train_loss = 1.62027041, grad/param norm = 1.9334e-01, time/batch = 0.6400s	
3781/26050 (epoch 7.257), train_loss = 1.39828927, grad/param norm = 1.9793e-01, time/batch = 0.6540s	
3782/26050 (epoch 7.259), train_loss = 1.54098256, grad/param norm = 1.8910e-01, time/batch = 0.6838s	
3783/26050 (epoch 7.261), train_loss = 1.33491251, grad/param norm = 1.9440e-01, time/batch = 0.6548s	
3784/26050 (epoch 7.263), train_loss = 1.38890584, grad/param norm = 1.8966e-01, time/batch = 0.6497s	
3785/26050 (epoch 7.265), train_loss = 1.58668232, grad/param norm = 1.7926e-01, time/batch = 0.6407s	
3786/26050 (epoch 7.267), train_loss = 1.45160754, grad/param norm = 1.8696e-01, time/batch = 0.6395s	
3787/26050 (epoch 7.269), train_loss = 1.59956209, grad/param norm = 2.0109e-01, time/batch = 0.6423s	
3788/26050 (epoch 7.271), train_loss = 1.39640207, grad/param norm = 1.7581e-01, time/batch = 0.6396s	
3789/26050 (epoch 7.273), train_loss = 1.34248811, grad/param norm = 1.8077e-01, time/batch = 0.6457s	
3790/26050 (epoch 7.274), train_loss = 1.32902304, grad/param norm = 1.8161e-01, time/batch = 0.6431s	
3791/26050 (epoch 7.276), train_loss = 1.31377485, grad/param norm = 1.8349e-01, time/batch = 0.6428s	
3792/26050 (epoch 7.278), train_loss = 1.50593678, grad/param norm = 1.9327e-01, time/batch = 0.6412s	
3793/26050 (epoch 7.280), train_loss = 1.37572301, grad/param norm = 1.7155e-01, time/batch = 0.6398s	
3794/26050 (epoch 7.282), train_loss = 1.44715193, grad/param norm = 1.9921e-01, time/batch = 0.6404s	
3795/26050 (epoch 7.284), train_loss = 1.27267506, grad/param norm = 1.8104e-01, time/batch = 0.6403s	
3796/26050 (epoch 7.286), train_loss = 1.37350056, grad/param norm = 1.9515e-01, time/batch = 0.6431s	
3797/26050 (epoch 7.288), train_loss = 1.22814277, grad/param norm = 1.7049e-01, time/batch = 0.6770s	
3798/26050 (epoch 7.290), train_loss = 1.35779646, grad/param norm = 1.8615e-01, time/batch = 0.6660s	
3799/26050 (epoch 7.292), train_loss = 1.31306644, grad/param norm = 1.7586e-01, time/batch = 0.6420s	
3800/26050 (epoch 7.294), train_loss = 1.43280717, grad/param norm = 2.0854e-01, time/batch = 0.6405s	
3801/26050 (epoch 7.296), train_loss = 1.50999792, grad/param norm = 1.8786e-01, time/batch = 0.6405s	
3802/26050 (epoch 7.298), train_loss = 1.36257759, grad/param norm = 1.7149e-01, time/batch = 0.6411s	
3803/26050 (epoch 7.299), train_loss = 1.13974726, grad/param norm = 1.5245e-01, time/batch = 0.6415s	
3804/26050 (epoch 7.301), train_loss = 1.32737253, grad/param norm = 1.8994e-01, time/batch = 0.6445s	
3805/26050 (epoch 7.303), train_loss = 1.43620130, grad/param norm = 1.8842e-01, time/batch = 0.6405s	
3806/26050 (epoch 7.305), train_loss = 1.24151277, grad/param norm = 1.7715e-01, time/batch = 0.6398s	
3807/26050 (epoch 7.307), train_loss = 1.26824840, grad/param norm = 1.8188e-01, time/batch = 0.6424s	
3808/26050 (epoch 7.309), train_loss = 1.34552474, grad/param norm = 1.9120e-01, time/batch = 0.6405s	
3809/26050 (epoch 7.311), train_loss = 1.60044394, grad/param norm = 2.0872e-01, time/batch = 0.6400s	
3810/26050 (epoch 7.313), train_loss = 1.39918823, grad/param norm = 1.9549e-01, time/batch = 0.6394s	
3811/26050 (epoch 7.315), train_loss = 1.54345120, grad/param norm = 2.0039e-01, time/batch = 0.6411s	
3812/26050 (epoch 7.317), train_loss = 1.31343935, grad/param norm = 1.8004e-01, time/batch = 0.6604s	
3813/26050 (epoch 7.319), train_loss = 1.37101597, grad/param norm = 1.6517e-01, time/batch = 0.6833s	
3814/26050 (epoch 7.321), train_loss = 1.36319913, grad/param norm = 1.8124e-01, time/batch = 0.6451s	
3815/26050 (epoch 7.322), train_loss = 1.40519159, grad/param norm = 1.8272e-01, time/batch = 0.6392s	
3816/26050 (epoch 7.324), train_loss = 1.20257250, grad/param norm = 1.7134e-01, time/batch = 0.6379s	
3817/26050 (epoch 7.326), train_loss = 1.54773189, grad/param norm = 2.0810e-01, time/batch = 0.6381s	
3818/26050 (epoch 7.328), train_loss = 1.43492398, grad/param norm = 1.8780e-01, time/batch = 0.6382s	
3819/26050 (epoch 7.330), train_loss = 1.28334810, grad/param norm = 1.8369e-01, time/batch = 0.6381s	
3820/26050 (epoch 7.332), train_loss = 1.48091984, grad/param norm = 1.9000e-01, time/batch = 0.6467s	
3821/26050 (epoch 7.334), train_loss = 1.35016455, grad/param norm = 1.7892e-01, time/batch = 0.6419s	
3822/26050 (epoch 7.336), train_loss = 1.25420104, grad/param norm = 1.6070e-01, time/batch = 0.6381s	
3823/26050 (epoch 7.338), train_loss = 1.21825082, grad/param norm = 1.6644e-01, time/batch = 0.6393s	
3824/26050 (epoch 7.340), train_loss = 1.48905978, grad/param norm = 2.0364e-01, time/batch = 0.6392s	
3825/26050 (epoch 7.342), train_loss = 1.53617829, grad/param norm = 1.8780e-01, time/batch = 0.6497s	
3826/26050 (epoch 7.344), train_loss = 1.38046136, grad/param norm = 1.9631e-01, time/batch = 0.6709s	
3827/26050 (epoch 7.345), train_loss = 1.38920982, grad/param norm = 2.0264e-01, time/batch = 0.6784s	
3828/26050 (epoch 7.347), train_loss = 1.45890322, grad/param norm = 1.9468e-01, time/batch = 0.6853s	
3829/26050 (epoch 7.349), train_loss = 1.40711344, grad/param norm = 1.8415e-01, time/batch = 0.6760s	
3830/26050 (epoch 7.351), train_loss = 1.44160459, grad/param norm = 2.0747e-01, time/batch = 0.6595s	
3831/26050 (epoch 7.353), train_loss = 1.32361717, grad/param norm = 1.9255e-01, time/batch = 0.6472s	
3832/26050 (epoch 7.355), train_loss = 1.48924169, grad/param norm = 1.9800e-01, time/batch = 0.6415s	
3833/26050 (epoch 7.357), train_loss = 1.23418450, grad/param norm = 1.5876e-01, time/batch = 0.6556s	
3834/26050 (epoch 7.359), train_loss = 1.49128465, grad/param norm = 1.9323e-01, time/batch = 0.6546s	
3835/26050 (epoch 7.361), train_loss = 1.27507814, grad/param norm = 1.7352e-01, time/batch = 0.6588s	
3836/26050 (epoch 7.363), train_loss = 1.39548356, grad/param norm = 1.7888e-01, time/batch = 0.6484s	
3837/26050 (epoch 7.365), train_loss = 1.28680652, grad/param norm = 1.6875e-01, time/batch = 0.6507s	
3838/26050 (epoch 7.367), train_loss = 1.38619349, grad/param norm = 1.8656e-01, time/batch = 0.6476s	
3839/26050 (epoch 7.369), train_loss = 1.34407514, grad/param norm = 1.6569e-01, time/batch = 0.6389s	
3840/26050 (epoch 7.370), train_loss = 1.26775929, grad/param norm = 1.6893e-01, time/batch = 0.6458s	
3841/26050 (epoch 7.372), train_loss = 1.51156052, grad/param norm = 2.0334e-01, time/batch = 0.6488s	
3842/26050 (epoch 7.374), train_loss = 1.60478233, grad/param norm = 2.1596e-01, time/batch = 0.6458s	
3843/26050 (epoch 7.376), train_loss = 1.63224443, grad/param norm = 1.8538e-01, time/batch = 0.6780s	
3844/26050 (epoch 7.378), train_loss = 1.37623462, grad/param norm = 1.8704e-01, time/batch = 0.6673s	
3845/26050 (epoch 7.380), train_loss = 1.60835127, grad/param norm = 2.0020e-01, time/batch = 0.6406s	
3846/26050 (epoch 7.382), train_loss = 1.76595723, grad/param norm = 2.1640e-01, time/batch = 0.6385s	
3847/26050 (epoch 7.384), train_loss = 1.34915944, grad/param norm = 1.7802e-01, time/batch = 0.6400s	
3848/26050 (epoch 7.386), train_loss = 1.49545017, grad/param norm = 1.8468e-01, time/batch = 0.6392s	
3849/26050 (epoch 7.388), train_loss = 1.42774791, grad/param norm = 1.6824e-01, time/batch = 0.6520s	
3850/26050 (epoch 7.390), train_loss = 1.25412570, grad/param norm = 1.6548e-01, time/batch = 0.6611s	
3851/26050 (epoch 7.392), train_loss = 1.26699526, grad/param norm = 1.7434e-01, time/batch = 0.6622s	
3852/26050 (epoch 7.393), train_loss = 1.45218728, grad/param norm = 1.7554e-01, time/batch = 0.6600s	
3853/26050 (epoch 7.395), train_loss = 1.46580019, grad/param norm = 1.8499e-01, time/batch = 0.6693s	
3854/26050 (epoch 7.397), train_loss = 1.44869487, grad/param norm = 1.8658e-01, time/batch = 0.6838s	
3855/26050 (epoch 7.399), train_loss = 1.26584505, grad/param norm = 1.6748e-01, time/batch = 0.6637s	
3856/26050 (epoch 7.401), train_loss = 1.32841661, grad/param norm = 1.7150e-01, time/batch = 0.6601s	
3857/26050 (epoch 7.403), train_loss = 1.41427133, grad/param norm = 1.8491e-01, time/batch = 0.6604s	
3858/26050 (epoch 7.405), train_loss = 1.38536321, grad/param norm = 1.8527e-01, time/batch = 0.6617s	
3859/26050 (epoch 7.407), train_loss = 1.56838633, grad/param norm = 1.9290e-01, time/batch = 0.6570s	
3860/26050 (epoch 7.409), train_loss = 1.59061278, grad/param norm = 2.0367e-01, time/batch = 0.6595s	
3861/26050 (epoch 7.411), train_loss = 1.44586135, grad/param norm = 1.8700e-01, time/batch = 0.6485s	
3862/26050 (epoch 7.413), train_loss = 1.53588657, grad/param norm = 1.7959e-01, time/batch = 0.6399s	
3863/26050 (epoch 7.415), train_loss = 1.53618776, grad/param norm = 1.9236e-01, time/batch = 0.6461s	
3864/26050 (epoch 7.417), train_loss = 1.60951540, grad/param norm = 1.9971e-01, time/batch = 0.6432s	
3865/26050 (epoch 7.418), train_loss = 1.49633212, grad/param norm = 1.9930e-01, time/batch = 0.6389s	
3866/26050 (epoch 7.420), train_loss = 1.18135800, grad/param norm = 1.6226e-01, time/batch = 0.6465s	
3867/26050 (epoch 7.422), train_loss = 1.26109868, grad/param norm = 1.8433e-01, time/batch = 0.6443s	
3868/26050 (epoch 7.424), train_loss = 1.63600224, grad/param norm = 2.1726e-01, time/batch = 0.6526s	
3869/26050 (epoch 7.426), train_loss = 1.57659455, grad/param norm = 2.0894e-01, time/batch = 0.6834s	
3870/26050 (epoch 7.428), train_loss = 1.30384459, grad/param norm = 1.7036e-01, time/batch = 0.6587s	
3871/26050 (epoch 7.430), train_loss = 1.44977673, grad/param norm = 2.0130e-01, time/batch = 0.6415s	
3872/26050 (epoch 7.432), train_loss = 1.35330463, grad/param norm = 1.8533e-01, time/batch = 0.6404s	
3873/26050 (epoch 7.434), train_loss = 1.42281504, grad/param norm = 1.8569e-01, time/batch = 0.6445s	
3874/26050 (epoch 7.436), train_loss = 1.54164722, grad/param norm = 1.8113e-01, time/batch = 0.6434s	
3875/26050 (epoch 7.438), train_loss = 1.28112149, grad/param norm = 1.6913e-01, time/batch = 0.6393s	
3876/26050 (epoch 7.440), train_loss = 1.42858717, grad/param norm = 1.8371e-01, time/batch = 0.6396s	
3877/26050 (epoch 7.441), train_loss = 1.39709000, grad/param norm = 1.8170e-01, time/batch = 0.6398s	
3878/26050 (epoch 7.443), train_loss = 1.18687313, grad/param norm = 1.5646e-01, time/batch = 0.6538s	
3879/26050 (epoch 7.445), train_loss = 1.26132554, grad/param norm = 1.7718e-01, time/batch = 0.6408s	
3880/26050 (epoch 7.447), train_loss = 1.63455168, grad/param norm = 1.9352e-01, time/batch = 0.6394s	
3881/26050 (epoch 7.449), train_loss = 1.29140047, grad/param norm = 1.7265e-01, time/batch = 0.6417s	
3882/26050 (epoch 7.451), train_loss = 1.49385016, grad/param norm = 1.6825e-01, time/batch = 0.6515s	
3883/26050 (epoch 7.453), train_loss = 1.25588172, grad/param norm = 1.6408e-01, time/batch = 0.6431s	
3884/26050 (epoch 7.455), train_loss = 1.42871615, grad/param norm = 1.8453e-01, time/batch = 0.6395s	
3885/26050 (epoch 7.457), train_loss = 1.43916076, grad/param norm = 1.8932e-01, time/batch = 0.6406s	
3886/26050 (epoch 7.459), train_loss = 1.53131296, grad/param norm = 1.9243e-01, time/batch = 0.6390s	
3887/26050 (epoch 7.461), train_loss = 1.48183708, grad/param norm = 1.9328e-01, time/batch = 0.6399s	
3888/26050 (epoch 7.463), train_loss = 1.32496324, grad/param norm = 1.6740e-01, time/batch = 0.6446s	
3889/26050 (epoch 7.464), train_loss = 1.48076044, grad/param norm = 1.9609e-01, time/batch = 0.6559s	
3890/26050 (epoch 7.466), train_loss = 1.50667242, grad/param norm = 1.8748e-01, time/batch = 0.6437s	
3891/26050 (epoch 7.468), train_loss = 1.50384881, grad/param norm = 1.7475e-01, time/batch = 0.6394s	
3892/26050 (epoch 7.470), train_loss = 1.63196491, grad/param norm = 2.0371e-01, time/batch = 0.6389s	
3893/26050 (epoch 7.472), train_loss = 1.63540217, grad/param norm = 1.9355e-01, time/batch = 0.6383s	
3894/26050 (epoch 7.474), train_loss = 1.68180414, grad/param norm = 1.8796e-01, time/batch = 0.6389s	
3895/26050 (epoch 7.476), train_loss = 1.49386287, grad/param norm = 1.7487e-01, time/batch = 0.6378s	
3896/26050 (epoch 7.478), train_loss = 1.30945686, grad/param norm = 1.6288e-01, time/batch = 0.6424s	
3897/26050 (epoch 7.480), train_loss = 1.42353617, grad/param norm = 1.6187e-01, time/batch = 0.6411s	
3898/26050 (epoch 7.482), train_loss = 1.38042346, grad/param norm = 1.7975e-01, time/batch = 0.6409s	
3899/26050 (epoch 7.484), train_loss = 1.27159347, grad/param norm = 1.8008e-01, time/batch = 0.6425s	
3900/26050 (epoch 7.486), train_loss = 1.58070930, grad/param norm = 1.9022e-01, time/batch = 0.6826s	
3901/26050 (epoch 7.488), train_loss = 1.77414279, grad/param norm = 1.9911e-01, time/batch = 0.6546s	
3902/26050 (epoch 7.489), train_loss = 1.68190988, grad/param norm = 2.0092e-01, time/batch = 0.6386s	
3903/26050 (epoch 7.491), train_loss = 1.33144701, grad/param norm = 1.7534e-01, time/batch = 0.6415s	
3904/26050 (epoch 7.493), train_loss = 1.34992935, grad/param norm = 1.7590e-01, time/batch = 0.6396s	
3905/26050 (epoch 7.495), train_loss = 1.38459962, grad/param norm = 1.7899e-01, time/batch = 0.6401s	
3906/26050 (epoch 7.497), train_loss = 1.34634341, grad/param norm = 1.7670e-01, time/batch = 0.6471s	
3907/26050 (epoch 7.499), train_loss = 1.35059328, grad/param norm = 1.8347e-01, time/batch = 0.6430s	
3908/26050 (epoch 7.501), train_loss = 1.43054092, grad/param norm = 1.9811e-01, time/batch = 0.6405s	
3909/26050 (epoch 7.503), train_loss = 1.33526790, grad/param norm = 1.8561e-01, time/batch = 0.6428s	
3910/26050 (epoch 7.505), train_loss = 1.54277077, grad/param norm = 1.8287e-01, time/batch = 0.6445s	
3911/26050 (epoch 7.507), train_loss = 1.54880707, grad/param norm = 1.9232e-01, time/batch = 0.6478s	
3912/26050 (epoch 7.509), train_loss = 1.66327086, grad/param norm = 2.1826e-01, time/batch = 0.6459s	
3913/26050 (epoch 7.511), train_loss = 1.31303899, grad/param norm = 1.7956e-01, time/batch = 0.6495s	
3914/26050 (epoch 7.512), train_loss = 1.44948425, grad/param norm = 2.0283e-01, time/batch = 0.6558s	
3915/26050 (epoch 7.514), train_loss = 1.48757967, grad/param norm = 1.8774e-01, time/batch = 0.6779s	
3916/26050 (epoch 7.516), train_loss = 1.53083194, grad/param norm = 1.9558e-01, time/batch = 0.6722s	
3917/26050 (epoch 7.518), train_loss = 1.48346250, grad/param norm = 1.8706e-01, time/batch = 0.6431s	
3918/26050 (epoch 7.520), train_loss = 1.44455216, grad/param norm = 1.8900e-01, time/batch = 0.6426s	
3919/26050 (epoch 7.522), train_loss = 1.26610134, grad/param norm = 1.7632e-01, time/batch = 0.6446s	
3920/26050 (epoch 7.524), train_loss = 1.62135056, grad/param norm = 1.9921e-01, time/batch = 0.6420s	
3921/26050 (epoch 7.526), train_loss = 1.49489134, grad/param norm = 1.8547e-01, time/batch = 0.6428s	
3922/26050 (epoch 7.528), train_loss = 1.49108194, grad/param norm = 1.9998e-01, time/batch = 0.6442s	
3923/26050 (epoch 7.530), train_loss = 1.40406039, grad/param norm = 1.7619e-01, time/batch = 0.6400s	
3924/26050 (epoch 7.532), train_loss = 1.42743843, grad/param norm = 1.8857e-01, time/batch = 0.6404s	
3925/26050 (epoch 7.534), train_loss = 1.51400825, grad/param norm = 1.8275e-01, time/batch = 0.6433s	
3926/26050 (epoch 7.536), train_loss = 1.35602125, grad/param norm = 1.7874e-01, time/batch = 0.6405s	
3927/26050 (epoch 7.537), train_loss = 1.54735959, grad/param norm = 1.8995e-01, time/batch = 0.6574s	
3928/26050 (epoch 7.539), train_loss = 1.39059680, grad/param norm = 1.7330e-01, time/batch = 0.6510s	
3929/26050 (epoch 7.541), train_loss = 1.63879681, grad/param norm = 2.2319e-01, time/batch = 0.6649s	
3930/26050 (epoch 7.543), train_loss = 1.24970067, grad/param norm = 1.7557e-01, time/batch = 0.6490s	
3931/26050 (epoch 7.545), train_loss = 1.49203582, grad/param norm = 1.8775e-01, time/batch = 0.6540s	
3932/26050 (epoch 7.547), train_loss = 1.44716978, grad/param norm = 1.8988e-01, time/batch = 0.6560s	
3933/26050 (epoch 7.549), train_loss = 1.25221881, grad/param norm = 1.8058e-01, time/batch = 0.6556s	
3934/26050 (epoch 7.551), train_loss = 1.48545368, grad/param norm = 1.9343e-01, time/batch = 0.6499s	
3935/26050 (epoch 7.553), train_loss = 1.32955633, grad/param norm = 1.7982e-01, time/batch = 0.6585s	
3936/26050 (epoch 7.555), train_loss = 1.36163002, grad/param norm = 1.7451e-01, time/batch = 0.6559s	
3937/26050 (epoch 7.557), train_loss = 1.48925856, grad/param norm = 1.7864e-01, time/batch = 0.6535s	
3938/26050 (epoch 7.559), train_loss = 1.43150938, grad/param norm = 1.8788e-01, time/batch = 0.6549s	
3939/26050 (epoch 7.560), train_loss = 1.41304295, grad/param norm = 1.8842e-01, time/batch = 0.6531s	
3940/26050 (epoch 7.562), train_loss = 1.39761962, grad/param norm = 1.9654e-01, time/batch = 0.6505s	
3941/26050 (epoch 7.564), train_loss = 1.61678273, grad/param norm = 2.0288e-01, time/batch = 0.6509s	
3942/26050 (epoch 7.566), train_loss = 1.29727695, grad/param norm = 1.7116e-01, time/batch = 0.6564s	
3943/26050 (epoch 7.568), train_loss = 1.44056296, grad/param norm = 1.7736e-01, time/batch = 0.6728s	
3944/26050 (epoch 7.570), train_loss = 1.56620609, grad/param norm = 1.9909e-01, time/batch = 0.6607s	
3945/26050 (epoch 7.572), train_loss = 1.42721795, grad/param norm = 1.7771e-01, time/batch = 0.6524s	
3946/26050 (epoch 7.574), train_loss = 1.52987260, grad/param norm = 2.1182e-01, time/batch = 0.6519s	
3947/26050 (epoch 7.576), train_loss = 1.50883024, grad/param norm = 1.9314e-01, time/batch = 0.6598s	
3948/26050 (epoch 7.578), train_loss = 1.42419944, grad/param norm = 1.8874e-01, time/batch = 0.6493s	
3949/26050 (epoch 7.580), train_loss = 1.29522381, grad/param norm = 1.7441e-01, time/batch = 0.6607s	
3950/26050 (epoch 7.582), train_loss = 1.48013435, grad/param norm = 1.8533e-01, time/batch = 0.6557s	
3951/26050 (epoch 7.583), train_loss = 1.49584654, grad/param norm = 1.8774e-01, time/batch = 0.6458s	
3952/26050 (epoch 7.585), train_loss = 1.30672553, grad/param norm = 1.7205e-01, time/batch = 0.6394s	
3953/26050 (epoch 7.587), train_loss = 1.48958453, grad/param norm = 1.8922e-01, time/batch = 0.6406s	
3954/26050 (epoch 7.589), train_loss = 1.51469885, grad/param norm = 2.0626e-01, time/batch = 0.6426s	
3955/26050 (epoch 7.591), train_loss = 1.46762852, grad/param norm = 1.8684e-01, time/batch = 0.6511s	
3956/26050 (epoch 7.593), train_loss = 1.31339214, grad/param norm = 1.9574e-01, time/batch = 0.6475s	
3957/26050 (epoch 7.595), train_loss = 1.60568868, grad/param norm = 2.1944e-01, time/batch = 0.6457s	
3958/26050 (epoch 7.597), train_loss = 1.47367450, grad/param norm = 1.8906e-01, time/batch = 0.6443s	
3959/26050 (epoch 7.599), train_loss = 1.33074660, grad/param norm = 1.7650e-01, time/batch = 0.6440s	
3960/26050 (epoch 7.601), train_loss = 1.62922888, grad/param norm = 1.9033e-01, time/batch = 0.6421s	
3961/26050 (epoch 7.603), train_loss = 1.48960740, grad/param norm = 1.8740e-01, time/batch = 0.6426s	
3962/26050 (epoch 7.605), train_loss = 1.35086819, grad/param norm = 1.7284e-01, time/batch = 0.6453s	
3963/26050 (epoch 7.607), train_loss = 1.54957700, grad/param norm = 1.9865e-01, time/batch = 0.6419s	
3964/26050 (epoch 7.608), train_loss = 1.36308863, grad/param norm = 1.6677e-01, time/batch = 0.6429s	
3965/26050 (epoch 7.610), train_loss = 1.40312953, grad/param norm = 1.8769e-01, time/batch = 0.6419s	
3966/26050 (epoch 7.612), train_loss = 1.38403636, grad/param norm = 1.9400e-01, time/batch = 0.6413s	
3967/26050 (epoch 7.614), train_loss = 1.47910580, grad/param norm = 1.8419e-01, time/batch = 0.6706s	
3968/26050 (epoch 7.616), train_loss = 1.71270268, grad/param norm = 1.9488e-01, time/batch = 0.6740s	
3969/26050 (epoch 7.618), train_loss = 1.34791344, grad/param norm = 1.8126e-01, time/batch = 0.6431s	
3970/26050 (epoch 7.620), train_loss = 1.43654566, grad/param norm = 1.8707e-01, time/batch = 0.6426s	
3971/26050 (epoch 7.622), train_loss = 1.17781559, grad/param norm = 1.6095e-01, time/batch = 0.6456s	
3972/26050 (epoch 7.624), train_loss = 1.29559481, grad/param norm = 1.6700e-01, time/batch = 0.6535s	
3973/26050 (epoch 7.626), train_loss = 1.46535061, grad/param norm = 1.9091e-01, time/batch = 0.6596s	
3974/26050 (epoch 7.628), train_loss = 1.41109379, grad/param norm = 1.9265e-01, time/batch = 0.6450s	
3975/26050 (epoch 7.630), train_loss = 1.55035079, grad/param norm = 1.8021e-01, time/batch = 0.6401s	
3976/26050 (epoch 7.631), train_loss = 1.55445548, grad/param norm = 1.9906e-01, time/batch = 0.6382s	
3977/26050 (epoch 7.633), train_loss = 1.29754587, grad/param norm = 1.7168e-01, time/batch = 0.6388s	
3978/26050 (epoch 7.635), train_loss = 1.30323191, grad/param norm = 1.6684e-01, time/batch = 0.6377s	
3979/26050 (epoch 7.637), train_loss = 1.31657401, grad/param norm = 1.8250e-01, time/batch = 0.6392s	
3980/26050 (epoch 7.639), train_loss = 1.52056422, grad/param norm = 1.8353e-01, time/batch = 0.6399s	
3981/26050 (epoch 7.641), train_loss = 1.33182329, grad/param norm = 1.5623e-01, time/batch = 0.6392s	
3982/26050 (epoch 7.643), train_loss = 1.30199781, grad/param norm = 1.6927e-01, time/batch = 0.6547s	
3983/26050 (epoch 7.645), train_loss = 1.46051952, grad/param norm = 1.9062e-01, time/batch = 0.6831s	
3984/26050 (epoch 7.647), train_loss = 1.36586678, grad/param norm = 1.7790e-01, time/batch = 0.6633s	
3985/26050 (epoch 7.649), train_loss = 1.47316113, grad/param norm = 2.0476e-01, time/batch = 0.6437s	
3986/26050 (epoch 7.651), train_loss = 1.36190392, grad/param norm = 1.8599e-01, time/batch = 0.6395s	
3987/26050 (epoch 7.653), train_loss = 1.42161874, grad/param norm = 1.9355e-01, time/batch = 0.6391s	
3988/26050 (epoch 7.655), train_loss = 1.31512153, grad/param norm = 1.8161e-01, time/batch = 0.6426s	
3989/26050 (epoch 7.656), train_loss = 1.28632308, grad/param norm = 1.7673e-01, time/batch = 0.6451s	
3990/26050 (epoch 7.658), train_loss = 1.60418617, grad/param norm = 1.8854e-01, time/batch = 0.6392s	
3991/26050 (epoch 7.660), train_loss = 1.30928184, grad/param norm = 1.9708e-01, time/batch = 0.6408s	
3992/26050 (epoch 7.662), train_loss = 1.27271737, grad/param norm = 1.6750e-01, time/batch = 0.6517s	
3993/26050 (epoch 7.664), train_loss = 1.39560787, grad/param norm = 1.8966e-01, time/batch = 0.6476s	
3994/26050 (epoch 7.666), train_loss = 1.45795666, grad/param norm = 1.9966e-01, time/batch = 0.6446s	
3995/26050 (epoch 7.668), train_loss = 1.17973825, grad/param norm = 1.5652e-01, time/batch = 0.6412s	
3996/26050 (epoch 7.670), train_loss = 1.59952986, grad/param norm = 2.1413e-01, time/batch = 0.6438s	
3997/26050 (epoch 7.672), train_loss = 1.32937163, grad/param norm = 1.8276e-01, time/batch = 0.6417s	
3998/26050 (epoch 7.674), train_loss = 1.28346967, grad/param norm = 1.6150e-01, time/batch = 0.6802s	
3999/26050 (epoch 7.676), train_loss = 1.44413306, grad/param norm = 1.7976e-01, time/batch = 0.6626s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch7.68_1.6465.t7	
4000/26050 (epoch 7.678), train_loss = 1.55998664, grad/param norm = 1.9365e-01, time/batch = 0.6392s	
4001/26050 (epoch 7.679), train_loss = 1.82664307, grad/param norm = 2.2239e-01, time/batch = 0.6463s	
4002/26050 (epoch 7.681), train_loss = 1.43530742, grad/param norm = 1.9304e-01, time/batch = 0.6412s	
4003/26050 (epoch 7.683), train_loss = 1.35806210, grad/param norm = 1.9515e-01, time/batch = 0.6415s	
4004/26050 (epoch 7.685), train_loss = 1.35020643, grad/param norm = 1.6729e-01, time/batch = 0.6449s	
4005/26050 (epoch 7.687), train_loss = 1.20121708, grad/param norm = 1.6738e-01, time/batch = 0.6477s	
4006/26050 (epoch 7.689), train_loss = 1.38744665, grad/param norm = 1.8393e-01, time/batch = 0.6652s	
4007/26050 (epoch 7.691), train_loss = 1.12825556, grad/param norm = 1.6815e-01, time/batch = 0.6490s	
4008/26050 (epoch 7.693), train_loss = 1.32302616, grad/param norm = 1.8545e-01, time/batch = 0.6465s	
4009/26050 (epoch 7.695), train_loss = 1.43071138, grad/param norm = 1.8772e-01, time/batch = 0.6444s	
4010/26050 (epoch 7.697), train_loss = 1.26854969, grad/param norm = 1.8199e-01, time/batch = 0.6453s	
4011/26050 (epoch 7.699), train_loss = 1.47356773, grad/param norm = 1.8842e-01, time/batch = 0.6589s	
4012/26050 (epoch 7.701), train_loss = 1.23653015, grad/param norm = 1.7076e-01, time/batch = 0.6512s	
4013/26050 (epoch 7.702), train_loss = 1.64311523, grad/param norm = 1.8658e-01, time/batch = 0.6425s	
4014/26050 (epoch 7.704), train_loss = 1.40863120, grad/param norm = 1.7704e-01, time/batch = 0.6741s	
4015/26050 (epoch 7.706), train_loss = 1.49852002, grad/param norm = 2.1309e-01, time/batch = 0.6523s	
4016/26050 (epoch 7.708), train_loss = 1.47365718, grad/param norm = 1.7911e-01, time/batch = 0.6500s	
4017/26050 (epoch 7.710), train_loss = 1.48750025, grad/param norm = 1.8500e-01, time/batch = 0.6421s	
4018/26050 (epoch 7.712), train_loss = 1.59298350, grad/param norm = 1.9036e-01, time/batch = 0.6416s	
4019/26050 (epoch 7.714), train_loss = 1.27942317, grad/param norm = 1.8316e-01, time/batch = 0.6435s	
4020/26050 (epoch 7.716), train_loss = 1.66246840, grad/param norm = 2.1298e-01, time/batch = 0.6406s	
4021/26050 (epoch 7.718), train_loss = 1.51973442, grad/param norm = 1.9339e-01, time/batch = 0.6430s	
4022/26050 (epoch 7.720), train_loss = 1.33447783, grad/param norm = 1.8076e-01, time/batch = 0.6411s	
4023/26050 (epoch 7.722), train_loss = 1.27210840, grad/param norm = 1.7035e-01, time/batch = 0.6399s	
4024/26050 (epoch 7.724), train_loss = 1.27859305, grad/param norm = 1.8306e-01, time/batch = 0.6451s	
4025/26050 (epoch 7.726), train_loss = 1.51403298, grad/param norm = 1.8526e-01, time/batch = 0.6472s	
4026/26050 (epoch 7.727), train_loss = 1.48604663, grad/param norm = 1.8446e-01, time/batch = 0.6420s	
4027/26050 (epoch 7.729), train_loss = 1.49890820, grad/param norm = 1.9982e-01, time/batch = 0.6425s	
4028/26050 (epoch 7.731), train_loss = 1.40892435, grad/param norm = 1.6762e-01, time/batch = 0.6515s	
4029/26050 (epoch 7.733), train_loss = 1.38463661, grad/param norm = 2.0926e-01, time/batch = 0.6456s	
4030/26050 (epoch 7.735), train_loss = 1.62413027, grad/param norm = 2.0070e-01, time/batch = 0.6392s	
4031/26050 (epoch 7.737), train_loss = 1.44119946, grad/param norm = 1.9327e-01, time/batch = 0.6398s	
4032/26050 (epoch 7.739), train_loss = 1.44308158, grad/param norm = 1.8273e-01, time/batch = 0.6408s	
4033/26050 (epoch 7.741), train_loss = 1.31461522, grad/param norm = 1.7635e-01, time/batch = 0.6394s	
4034/26050 (epoch 7.743), train_loss = 1.50719797, grad/param norm = 2.2235e-01, time/batch = 0.6418s	
4035/26050 (epoch 7.745), train_loss = 1.27553314, grad/param norm = 1.7646e-01, time/batch = 0.6406s	
4036/26050 (epoch 7.747), train_loss = 1.31221791, grad/param norm = 1.8275e-01, time/batch = 0.6428s	
4037/26050 (epoch 7.749), train_loss = 1.51823324, grad/param norm = 1.9602e-01, time/batch = 0.6536s	
4038/26050 (epoch 7.750), train_loss = 1.37108883, grad/param norm = 1.7464e-01, time/batch = 0.6516s	
4039/26050 (epoch 7.752), train_loss = 1.44369392, grad/param norm = 2.0235e-01, time/batch = 0.6545s	
4040/26050 (epoch 7.754), train_loss = 1.37411101, grad/param norm = 1.8445e-01, time/batch = 0.6420s	
4041/26050 (epoch 7.756), train_loss = 1.49141633, grad/param norm = 1.9727e-01, time/batch = 0.6480s	
4042/26050 (epoch 7.758), train_loss = 1.43988523, grad/param norm = 1.9075e-01, time/batch = 0.6467s	
4043/26050 (epoch 7.760), train_loss = 1.51074448, grad/param norm = 2.0032e-01, time/batch = 0.6419s	
4044/26050 (epoch 7.762), train_loss = 1.30770693, grad/param norm = 1.7223e-01, time/batch = 0.6446s	
4045/26050 (epoch 7.764), train_loss = 1.52179396, grad/param norm = 1.9250e-01, time/batch = 0.6450s	
4046/26050 (epoch 7.766), train_loss = 1.51765233, grad/param norm = 1.9734e-01, time/batch = 0.6474s	
4047/26050 (epoch 7.768), train_loss = 1.30120433, grad/param norm = 1.6442e-01, time/batch = 0.6462s	
4048/26050 (epoch 7.770), train_loss = 1.40869504, grad/param norm = 1.8562e-01, time/batch = 0.6401s	
4049/26050 (epoch 7.772), train_loss = 1.40261151, grad/param norm = 1.8507e-01, time/batch = 0.6399s	
4050/26050 (epoch 7.774), train_loss = 1.30035105, grad/param norm = 1.9146e-01, time/batch = 0.6406s	
4051/26050 (epoch 7.775), train_loss = 1.11580482, grad/param norm = 1.7934e-01, time/batch = 0.6421s	
4052/26050 (epoch 7.777), train_loss = 1.33197216, grad/param norm = 1.8108e-01, time/batch = 0.6419s	
4053/26050 (epoch 7.779), train_loss = 1.37974299, grad/param norm = 1.8548e-01, time/batch = 0.6401s	
4054/26050 (epoch 7.781), train_loss = 1.36211668, grad/param norm = 1.8138e-01, time/batch = 0.6431s	
4055/26050 (epoch 7.783), train_loss = 1.31995871, grad/param norm = 1.6700e-01, time/batch = 0.6394s	
4056/26050 (epoch 7.785), train_loss = 1.36803159, grad/param norm = 1.9752e-01, time/batch = 0.6530s	
4057/26050 (epoch 7.787), train_loss = 1.33942617, grad/param norm = 1.7458e-01, time/batch = 0.6445s	
4058/26050 (epoch 7.789), train_loss = 1.40493222, grad/param norm = 1.9718e-01, time/batch = 0.6479s	
4059/26050 (epoch 7.791), train_loss = 1.41911447, grad/param norm = 1.8736e-01, time/batch = 0.6403s	
4060/26050 (epoch 7.793), train_loss = 1.39971796, grad/param norm = 1.9056e-01, time/batch = 0.6401s	
4061/26050 (epoch 7.795), train_loss = 1.23070523, grad/param norm = 1.7305e-01, time/batch = 0.6413s	
4062/26050 (epoch 7.797), train_loss = 1.27881693, grad/param norm = 1.6520e-01, time/batch = 0.6399s	
4063/26050 (epoch 7.798), train_loss = 1.27472702, grad/param norm = 1.8275e-01, time/batch = 0.6415s	
4064/26050 (epoch 7.800), train_loss = 1.25156454, grad/param norm = 1.6694e-01, time/batch = 0.6429s	
4065/26050 (epoch 7.802), train_loss = 1.40394026, grad/param norm = 1.8697e-01, time/batch = 0.6490s	
4066/26050 (epoch 7.804), train_loss = 1.37038287, grad/param norm = 1.7797e-01, time/batch = 0.6404s	
4067/26050 (epoch 7.806), train_loss = 1.55536562, grad/param norm = 2.0662e-01, time/batch = 0.6410s	
4068/26050 (epoch 7.808), train_loss = 1.35902198, grad/param norm = 1.7328e-01, time/batch = 0.6408s	
4069/26050 (epoch 7.810), train_loss = 1.32399022, grad/param norm = 1.8983e-01, time/batch = 0.6393s	
4070/26050 (epoch 7.812), train_loss = 1.27083793, grad/param norm = 1.8066e-01, time/batch = 0.6402s	
4071/26050 (epoch 7.814), train_loss = 1.26977348, grad/param norm = 1.9113e-01, time/batch = 0.6407s	
4072/26050 (epoch 7.816), train_loss = 1.47720212, grad/param norm = 1.9113e-01, time/batch = 0.6408s	
4073/26050 (epoch 7.818), train_loss = 1.57224311, grad/param norm = 2.1038e-01, time/batch = 0.6397s	
4074/26050 (epoch 7.820), train_loss = 1.43038903, grad/param norm = 1.8728e-01, time/batch = 0.6433s	
4075/26050 (epoch 7.821), train_loss = 1.57803428, grad/param norm = 2.1065e-01, time/batch = 0.6407s	
4076/26050 (epoch 7.823), train_loss = 1.62873600, grad/param norm = 1.9804e-01, time/batch = 0.6414s	
4077/26050 (epoch 7.825), train_loss = 1.34519537, grad/param norm = 1.9089e-01, time/batch = 0.6480s	
4078/26050 (epoch 7.827), train_loss = 1.47567643, grad/param norm = 2.0105e-01, time/batch = 0.6474s	
4079/26050 (epoch 7.829), train_loss = 1.47892532, grad/param norm = 1.9669e-01, time/batch = 0.6409s	
4080/26050 (epoch 7.831), train_loss = 1.55569684, grad/param norm = 1.9470e-01, time/batch = 0.6438s	
4081/26050 (epoch 7.833), train_loss = 1.61329104, grad/param norm = 1.8539e-01, time/batch = 0.6433s	
4082/26050 (epoch 7.835), train_loss = 1.66716633, grad/param norm = 1.9973e-01, time/batch = 0.6424s	
4083/26050 (epoch 7.837), train_loss = 1.35101060, grad/param norm = 1.7904e-01, time/batch = 0.6412s	
4084/26050 (epoch 7.839), train_loss = 1.49617169, grad/param norm = 1.8202e-01, time/batch = 0.6413s	
4085/26050 (epoch 7.841), train_loss = 1.51453259, grad/param norm = 1.7889e-01, time/batch = 0.6403s	
4086/26050 (epoch 7.843), train_loss = 1.47618732, grad/param norm = 1.8424e-01, time/batch = 0.6421s	
4087/26050 (epoch 7.845), train_loss = 1.32762591, grad/param norm = 1.7950e-01, time/batch = 0.6455s	
4088/26050 (epoch 7.846), train_loss = 1.54254743, grad/param norm = 1.8739e-01, time/batch = 0.6413s	
4089/26050 (epoch 7.848), train_loss = 1.36387428, grad/param norm = 1.8232e-01, time/batch = 0.6410s	
4090/26050 (epoch 7.850), train_loss = 1.35148510, grad/param norm = 1.7534e-01, time/batch = 0.6460s	
4091/26050 (epoch 7.852), train_loss = 1.39208452, grad/param norm = 1.9452e-01, time/batch = 0.6410s	
4092/26050 (epoch 7.854), train_loss = 1.42722631, grad/param norm = 1.8937e-01, time/batch = 0.6410s	
4093/26050 (epoch 7.856), train_loss = 1.32375297, grad/param norm = 1.8210e-01, time/batch = 0.6405s	
4094/26050 (epoch 7.858), train_loss = 1.29543857, grad/param norm = 1.8747e-01, time/batch = 0.6395s	
4095/26050 (epoch 7.860), train_loss = 1.45039783, grad/param norm = 2.0078e-01, time/batch = 0.6408s	
4096/26050 (epoch 7.862), train_loss = 1.42586020, grad/param norm = 1.8853e-01, time/batch = 0.6417s	
4097/26050 (epoch 7.864), train_loss = 1.36337251, grad/param norm = 1.9040e-01, time/batch = 0.6424s	
4098/26050 (epoch 7.866), train_loss = 1.29748431, grad/param norm = 1.6814e-01, time/batch = 0.6412s	
4099/26050 (epoch 7.868), train_loss = 1.53578238, grad/param norm = 2.0792e-01, time/batch = 0.6402s	
4100/26050 (epoch 7.869), train_loss = 1.24401439, grad/param norm = 1.6282e-01, time/batch = 0.6395s	
4101/26050 (epoch 7.871), train_loss = 1.21159877, grad/param norm = 1.6147e-01, time/batch = 0.6422s	
4102/26050 (epoch 7.873), train_loss = 1.43290067, grad/param norm = 1.7325e-01, time/batch = 0.6416s	
4103/26050 (epoch 7.875), train_loss = 1.38089425, grad/param norm = 1.7941e-01, time/batch = 0.6571s	
4104/26050 (epoch 7.877), train_loss = 1.24037394, grad/param norm = 1.7832e-01, time/batch = 0.6786s	
4105/26050 (epoch 7.879), train_loss = 1.37147953, grad/param norm = 1.6989e-01, time/batch = 0.6561s	
4106/26050 (epoch 7.881), train_loss = 1.58571821, grad/param norm = 1.9728e-01, time/batch = 0.6418s	
4107/26050 (epoch 7.883), train_loss = 1.41740460, grad/param norm = 1.7408e-01, time/batch = 0.6785s	
4108/26050 (epoch 7.885), train_loss = 1.11440518, grad/param norm = 1.5946e-01, time/batch = 0.6551s	
4109/26050 (epoch 7.887), train_loss = 1.45392834, grad/param norm = 1.7911e-01, time/batch = 0.6394s	
4110/26050 (epoch 7.889), train_loss = 1.30805588, grad/param norm = 1.6566e-01, time/batch = 0.6415s	
4111/26050 (epoch 7.891), train_loss = 1.15779970, grad/param norm = 1.5995e-01, time/batch = 0.6404s	
4112/26050 (epoch 7.893), train_loss = 1.12089116, grad/param norm = 1.5232e-01, time/batch = 0.6460s	
4113/26050 (epoch 7.894), train_loss = 1.28984233, grad/param norm = 1.6449e-01, time/batch = 0.6421s	
4114/26050 (epoch 7.896), train_loss = 1.50825502, grad/param norm = 1.8826e-01, time/batch = 0.6421s	
4115/26050 (epoch 7.898), train_loss = 1.33206766, grad/param norm = 1.9032e-01, time/batch = 0.6400s	
4116/26050 (epoch 7.900), train_loss = 1.61336031, grad/param norm = 1.9699e-01, time/batch = 0.6394s	
4117/26050 (epoch 7.902), train_loss = 1.40001823, grad/param norm = 1.7401e-01, time/batch = 0.6388s	
4118/26050 (epoch 7.904), train_loss = 1.33815451, grad/param norm = 1.7105e-01, time/batch = 0.6406s	
4119/26050 (epoch 7.906), train_loss = 1.36738873, grad/param norm = 1.7903e-01, time/batch = 0.6416s	
4120/26050 (epoch 7.908), train_loss = 1.36663177, grad/param norm = 1.8369e-01, time/batch = 0.6432s	
4121/26050 (epoch 7.910), train_loss = 1.30416160, grad/param norm = 1.6948e-01, time/batch = 0.6588s	
4122/26050 (epoch 7.912), train_loss = 1.67025114, grad/param norm = 1.9408e-01, time/batch = 0.6494s	
4123/26050 (epoch 7.914), train_loss = 1.85003089, grad/param norm = 1.9655e-01, time/batch = 0.6399s	
4124/26050 (epoch 7.916), train_loss = 1.57337930, grad/param norm = 2.0654e-01, time/batch = 0.6449s	
4125/26050 (epoch 7.917), train_loss = 1.45236520, grad/param norm = 1.9791e-01, time/batch = 0.6487s	
4126/26050 (epoch 7.919), train_loss = 1.51421777, grad/param norm = 1.9900e-01, time/batch = 0.6483s	
4127/26050 (epoch 7.921), train_loss = 1.31693583, grad/param norm = 2.1041e-01, time/batch = 0.6460s	
4128/26050 (epoch 7.923), train_loss = 1.38311610, grad/param norm = 1.9885e-01, time/batch = 0.6429s	
4129/26050 (epoch 7.925), train_loss = 1.34667253, grad/param norm = 1.7391e-01, time/batch = 0.6502s	
4130/26050 (epoch 7.927), train_loss = 1.26139374, grad/param norm = 1.5959e-01, time/batch = 0.6425s	
4131/26050 (epoch 7.929), train_loss = 1.31499944, grad/param norm = 1.8148e-01, time/batch = 0.6475s	
4132/26050 (epoch 7.931), train_loss = 1.66936677, grad/param norm = 2.2069e-01, time/batch = 0.6418s	
4133/26050 (epoch 7.933), train_loss = 1.36790121, grad/param norm = 1.9410e-01, time/batch = 0.6451s	
4134/26050 (epoch 7.935), train_loss = 1.31503124, grad/param norm = 1.7972e-01, time/batch = 0.6413s	
4135/26050 (epoch 7.937), train_loss = 1.39160484, grad/param norm = 1.6702e-01, time/batch = 0.6447s	
4136/26050 (epoch 7.939), train_loss = 1.27399482, grad/param norm = 1.6817e-01, time/batch = 0.6417s	
4137/26050 (epoch 7.940), train_loss = 1.41137840, grad/param norm = 1.7641e-01, time/batch = 0.6403s	
4138/26050 (epoch 7.942), train_loss = 1.43583923, grad/param norm = 1.9943e-01, time/batch = 0.6426s	
4139/26050 (epoch 7.944), train_loss = 1.35282327, grad/param norm = 1.8626e-01, time/batch = 0.6406s	
4140/26050 (epoch 7.946), train_loss = 1.54577292, grad/param norm = 1.8288e-01, time/batch = 0.6453s	
4141/26050 (epoch 7.948), train_loss = 1.20496249, grad/param norm = 2.0012e-01, time/batch = 0.6436s	
4142/26050 (epoch 7.950), train_loss = 1.36196334, grad/param norm = 1.7606e-01, time/batch = 0.6430s	
4143/26050 (epoch 7.952), train_loss = 1.55840215, grad/param norm = 1.9405e-01, time/batch = 0.6424s	
4144/26050 (epoch 7.954), train_loss = 1.49346056, grad/param norm = 1.8379e-01, time/batch = 0.6485s	
4145/26050 (epoch 7.956), train_loss = 1.49343068, grad/param norm = 1.9635e-01, time/batch = 0.6552s	
4146/26050 (epoch 7.958), train_loss = 1.39108303, grad/param norm = 1.8427e-01, time/batch = 0.6452s	
4147/26050 (epoch 7.960), train_loss = 1.35620438, grad/param norm = 1.7829e-01, time/batch = 0.6432s	
4148/26050 (epoch 7.962), train_loss = 1.30313856, grad/param norm = 1.7682e-01, time/batch = 0.6402s	
4149/26050 (epoch 7.964), train_loss = 1.36014444, grad/param norm = 1.7539e-01, time/batch = 0.6417s	
4150/26050 (epoch 7.965), train_loss = 1.25878569, grad/param norm = 1.7839e-01, time/batch = 0.6405s	
4151/26050 (epoch 7.967), train_loss = 1.72266544, grad/param norm = 1.8765e-01, time/batch = 0.6469s	
4152/26050 (epoch 7.969), train_loss = 1.34861372, grad/param norm = 1.6693e-01, time/batch = 0.6414s	
4153/26050 (epoch 7.971), train_loss = 1.25544341, grad/param norm = 1.6512e-01, time/batch = 0.6417s	
4154/26050 (epoch 7.973), train_loss = 1.36267307, grad/param norm = 1.9718e-01, time/batch = 0.6443s	
4155/26050 (epoch 7.975), train_loss = 1.46156732, grad/param norm = 1.6839e-01, time/batch = 0.6413s	
4156/26050 (epoch 7.977), train_loss = 1.40405358, grad/param norm = 1.6006e-01, time/batch = 0.6405s	
4157/26050 (epoch 7.979), train_loss = 1.22818811, grad/param norm = 1.7336e-01, time/batch = 0.6396s	
4158/26050 (epoch 7.981), train_loss = 1.49027924, grad/param norm = 1.8009e-01, time/batch = 0.6443s	
4159/26050 (epoch 7.983), train_loss = 1.49243161, grad/param norm = 1.8591e-01, time/batch = 0.6415s	
4160/26050 (epoch 7.985), train_loss = 1.42435078, grad/param norm = 1.8308e-01, time/batch = 0.6420s	
4161/26050 (epoch 7.987), train_loss = 1.56791016, grad/param norm = 1.9750e-01, time/batch = 0.6414s	
4162/26050 (epoch 7.988), train_loss = 1.52172267, grad/param norm = 2.2999e-01, time/batch = 0.6432s	
4163/26050 (epoch 7.990), train_loss = 1.32612944, grad/param norm = 1.7692e-01, time/batch = 0.6403s	
4164/26050 (epoch 7.992), train_loss = 1.58753384, grad/param norm = 2.0501e-01, time/batch = 0.6416s	
4165/26050 (epoch 7.994), train_loss = 1.40114353, grad/param norm = 1.9003e-01, time/batch = 0.6400s	
4166/26050 (epoch 7.996), train_loss = 1.39182469, grad/param norm = 2.1600e-01, time/batch = 0.6394s	
4167/26050 (epoch 7.998), train_loss = 1.41667145, grad/param norm = 1.9000e-01, time/batch = 0.6460s	
4168/26050 (epoch 8.000), train_loss = 1.37236451, grad/param norm = 1.8814e-01, time/batch = 0.6393s	
4169/26050 (epoch 8.002), train_loss = 1.43268816, grad/param norm = 1.8444e-01, time/batch = 0.6416s	
4170/26050 (epoch 8.004), train_loss = 1.32703969, grad/param norm = 1.9456e-01, time/batch = 0.6390s	
4171/26050 (epoch 8.006), train_loss = 1.31654206, grad/param norm = 1.6755e-01, time/batch = 0.6422s	
4172/26050 (epoch 8.008), train_loss = 1.29224328, grad/param norm = 1.7246e-01, time/batch = 0.6528s	
4173/26050 (epoch 8.010), train_loss = 1.35573679, grad/param norm = 1.7031e-01, time/batch = 0.6561s	
4174/26050 (epoch 8.012), train_loss = 1.44344130, grad/param norm = 1.8922e-01, time/batch = 0.6508s	
4175/26050 (epoch 8.013), train_loss = 1.83473126, grad/param norm = 2.0293e-01, time/batch = 0.6616s	
4176/26050 (epoch 8.015), train_loss = 1.26969666, grad/param norm = 1.6819e-01, time/batch = 0.6585s	
4177/26050 (epoch 8.017), train_loss = 1.42737209, grad/param norm = 1.8680e-01, time/batch = 0.6538s	
4178/26050 (epoch 8.019), train_loss = 1.19882478, grad/param norm = 1.5168e-01, time/batch = 0.6613s	
4179/26050 (epoch 8.021), train_loss = 1.52255120, grad/param norm = 1.9668e-01, time/batch = 0.6734s	
4180/26050 (epoch 8.023), train_loss = 1.24738076, grad/param norm = 1.7155e-01, time/batch = 0.6663s	
4181/26050 (epoch 8.025), train_loss = 1.32965155, grad/param norm = 1.7591e-01, time/batch = 0.6737s	
4182/26050 (epoch 8.027), train_loss = 1.15359752, grad/param norm = 1.6656e-01, time/batch = 0.6708s	
4183/26050 (epoch 8.029), train_loss = 1.34174991, grad/param norm = 1.6533e-01, time/batch = 0.6694s	
4184/26050 (epoch 8.031), train_loss = 1.58638958, grad/param norm = 2.0775e-01, time/batch = 0.6706s	
4185/26050 (epoch 8.033), train_loss = 1.43719820, grad/param norm = 1.8627e-01, time/batch = 0.6828s	
4186/26050 (epoch 8.035), train_loss = 1.53590233, grad/param norm = 1.8384e-01, time/batch = 0.6652s	
4187/26050 (epoch 8.036), train_loss = 1.34238294, grad/param norm = 2.0097e-01, time/batch = 0.6695s	
4188/26050 (epoch 8.038), train_loss = 1.19221702, grad/param norm = 1.6679e-01, time/batch = 0.6699s	
4189/26050 (epoch 8.040), train_loss = 1.45128343, grad/param norm = 1.7631e-01, time/batch = 0.6676s	
4190/26050 (epoch 8.042), train_loss = 1.25548427, grad/param norm = 1.7780e-01, time/batch = 0.6702s	
4191/26050 (epoch 8.044), train_loss = 1.43682097, grad/param norm = 1.8424e-01, time/batch = 0.6524s	
4192/26050 (epoch 8.046), train_loss = 1.18314484, grad/param norm = 1.8726e-01, time/batch = 0.6425s	
4193/26050 (epoch 8.048), train_loss = 1.41008656, grad/param norm = 1.8384e-01, time/batch = 0.6405s	
4194/26050 (epoch 8.050), train_loss = 1.27193179, grad/param norm = 1.9037e-01, time/batch = 0.6410s	
4195/26050 (epoch 8.052), train_loss = 1.37949793, grad/param norm = 1.8558e-01, time/batch = 0.6385s	
4196/26050 (epoch 8.054), train_loss = 1.20801245, grad/param norm = 1.6824e-01, time/batch = 0.6572s	
4197/26050 (epoch 8.056), train_loss = 1.08518074, grad/param norm = 1.4678e-01, time/batch = 0.6629s	
4198/26050 (epoch 8.058), train_loss = 1.28777137, grad/param norm = 1.6752e-01, time/batch = 0.6422s	
4199/26050 (epoch 8.060), train_loss = 1.36645189, grad/param norm = 1.6345e-01, time/batch = 0.6492s	
4200/26050 (epoch 8.061), train_loss = 1.26750086, grad/param norm = 1.7148e-01, time/batch = 0.6413s	
4201/26050 (epoch 8.063), train_loss = 1.33086912, grad/param norm = 1.6426e-01, time/batch = 0.6423s	
4202/26050 (epoch 8.065), train_loss = 1.19149689, grad/param norm = 1.7318e-01, time/batch = 0.6452s	
4203/26050 (epoch 8.067), train_loss = 1.45839199, grad/param norm = 1.9244e-01, time/batch = 0.6447s	
4204/26050 (epoch 8.069), train_loss = 1.44459202, grad/param norm = 1.7339e-01, time/batch = 0.6641s	
4205/26050 (epoch 8.071), train_loss = 1.45705451, grad/param norm = 1.9859e-01, time/batch = 0.6505s	
4206/26050 (epoch 8.073), train_loss = 1.60808852, grad/param norm = 1.7515e-01, time/batch = 0.6418s	
4207/26050 (epoch 8.075), train_loss = 1.26822945, grad/param norm = 1.7264e-01, time/batch = 0.6404s	
4208/26050 (epoch 8.077), train_loss = 1.27299472, grad/param norm = 1.7211e-01, time/batch = 0.6405s	
4209/26050 (epoch 8.079), train_loss = 1.46278407, grad/param norm = 1.9782e-01, time/batch = 0.6404s	
4210/26050 (epoch 8.081), train_loss = 1.33052970, grad/param norm = 1.9226e-01, time/batch = 0.6422s	
4211/26050 (epoch 8.083), train_loss = 1.45988363, grad/param norm = 1.8633e-01, time/batch = 0.6437s	
4212/26050 (epoch 8.084), train_loss = 1.53638623, grad/param norm = 2.1520e-01, time/batch = 0.6438s	
4213/26050 (epoch 8.086), train_loss = 1.51585657, grad/param norm = 1.8430e-01, time/batch = 0.6402s	
4214/26050 (epoch 8.088), train_loss = 1.24106084, grad/param norm = 1.6307e-01, time/batch = 0.6410s	
4215/26050 (epoch 8.090), train_loss = 1.47630303, grad/param norm = 1.8253e-01, time/batch = 0.6542s	
4216/26050 (epoch 8.092), train_loss = 1.37060019, grad/param norm = 1.8866e-01, time/batch = 0.6562s	
4217/26050 (epoch 8.094), train_loss = 1.37761624, grad/param norm = 1.7775e-01, time/batch = 0.6421s	
4218/26050 (epoch 8.096), train_loss = 1.30683954, grad/param norm = 1.7627e-01, time/batch = 0.6397s	
4219/26050 (epoch 8.098), train_loss = 1.30770829, grad/param norm = 1.7429e-01, time/batch = 0.6410s	
4220/26050 (epoch 8.100), train_loss = 1.27506982, grad/param norm = 1.8520e-01, time/batch = 0.6391s	
4221/26050 (epoch 8.102), train_loss = 1.40983696, grad/param norm = 1.8521e-01, time/batch = 0.6413s	
4222/26050 (epoch 8.104), train_loss = 1.42608912, grad/param norm = 1.8218e-01, time/batch = 0.6412s	
4223/26050 (epoch 8.106), train_loss = 1.33476212, grad/param norm = 1.7727e-01, time/batch = 0.6396s	
4224/26050 (epoch 8.107), train_loss = 1.11466166, grad/param norm = 1.7372e-01, time/batch = 0.6404s	
4225/26050 (epoch 8.109), train_loss = 1.28819559, grad/param norm = 1.7556e-01, time/batch = 0.6393s	
4226/26050 (epoch 8.111), train_loss = 1.61326786, grad/param norm = 2.0842e-01, time/batch = 0.6660s	
4227/26050 (epoch 8.113), train_loss = 1.31085420, grad/param norm = 1.8704e-01, time/batch = 0.6548s	
4228/26050 (epoch 8.115), train_loss = 1.49489942, grad/param norm = 1.7958e-01, time/batch = 0.6422s	
4229/26050 (epoch 8.117), train_loss = 1.44032285, grad/param norm = 1.8986e-01, time/batch = 0.6400s	
4230/26050 (epoch 8.119), train_loss = 1.15341931, grad/param norm = 1.6903e-01, time/batch = 0.6390s	
4231/26050 (epoch 8.121), train_loss = 1.43521503, grad/param norm = 1.8124e-01, time/batch = 0.6391s	
4232/26050 (epoch 8.123), train_loss = 1.31626380, grad/param norm = 2.0539e-01, time/batch = 0.6392s	
4233/26050 (epoch 8.125), train_loss = 1.15934892, grad/param norm = 1.5314e-01, time/batch = 0.6404s	
4234/26050 (epoch 8.127), train_loss = 1.14476072, grad/param norm = 1.7080e-01, time/batch = 0.6463s	
4235/26050 (epoch 8.129), train_loss = 1.14490407, grad/param norm = 1.6133e-01, time/batch = 0.6534s	
4236/26050 (epoch 8.131), train_loss = 1.36464423, grad/param norm = 1.8204e-01, time/batch = 0.6551s	
4237/26050 (epoch 8.132), train_loss = 1.30338245, grad/param norm = 1.7410e-01, time/batch = 0.6390s	
4238/26050 (epoch 8.134), train_loss = 1.32578454, grad/param norm = 1.8155e-01, time/batch = 0.6393s	
4239/26050 (epoch 8.136), train_loss = 1.34566790, grad/param norm = 1.7516e-01, time/batch = 0.6378s	
4240/26050 (epoch 8.138), train_loss = 1.19907446, grad/param norm = 1.9343e-01, time/batch = 0.6385s	
4241/26050 (epoch 8.140), train_loss = 1.24125905, grad/param norm = 1.7372e-01, time/batch = 0.6415s	
4242/26050 (epoch 8.142), train_loss = 1.29669117, grad/param norm = 1.7644e-01, time/batch = 0.6437s	
4243/26050 (epoch 8.144), train_loss = 1.16814540, grad/param norm = 1.6468e-01, time/batch = 0.6432s	
4244/26050 (epoch 8.146), train_loss = 1.09292355, grad/param norm = 1.5754e-01, time/batch = 0.6445s	
4245/26050 (epoch 8.148), train_loss = 1.11408680, grad/param norm = 1.4229e-01, time/batch = 0.6486s	
4246/26050 (epoch 8.150), train_loss = 1.34066603, grad/param norm = 1.9404e-01, time/batch = 0.6556s	
4247/26050 (epoch 8.152), train_loss = 1.63279887, grad/param norm = 2.0162e-01, time/batch = 0.6569s	
4248/26050 (epoch 8.154), train_loss = 1.16516863, grad/param norm = 1.8318e-01, time/batch = 0.6547s	
4249/26050 (epoch 8.155), train_loss = 1.17231012, grad/param norm = 1.6207e-01, time/batch = 0.6567s	
4250/26050 (epoch 8.157), train_loss = 1.34879723, grad/param norm = 1.9048e-01, time/batch = 0.6559s	
4251/26050 (epoch 8.159), train_loss = 1.34914864, grad/param norm = 1.8524e-01, time/batch = 0.6499s	
4252/26050 (epoch 8.161), train_loss = 1.54134496, grad/param norm = 2.1486e-01, time/batch = 0.6502s	
4253/26050 (epoch 8.163), train_loss = 1.20341446, grad/param norm = 1.6985e-01, time/batch = 0.6588s	
4254/26050 (epoch 8.165), train_loss = 1.05791081, grad/param norm = 1.5777e-01, time/batch = 0.6574s	
4255/26050 (epoch 8.167), train_loss = 1.48600616, grad/param norm = 2.1134e-01, time/batch = 0.6554s	
4256/26050 (epoch 8.169), train_loss = 1.42015517, grad/param norm = 1.8106e-01, time/batch = 0.6571s	
4257/26050 (epoch 8.171), train_loss = 1.13330483, grad/param norm = 1.5066e-01, time/batch = 0.6548s	
4258/26050 (epoch 8.173), train_loss = 1.31015815, grad/param norm = 1.8708e-01, time/batch = 0.6426s	
4259/26050 (epoch 8.175), train_loss = 1.35655671, grad/param norm = 1.8331e-01, time/batch = 0.6436s	
4260/26050 (epoch 8.177), train_loss = 1.43529692, grad/param norm = 1.8038e-01, time/batch = 0.6404s	
4261/26050 (epoch 8.179), train_loss = 1.05785330, grad/param norm = 1.6075e-01, time/batch = 0.6488s	
4262/26050 (epoch 8.180), train_loss = 1.61495112, grad/param norm = 1.8023e-01, time/batch = 0.6556s	
4263/26050 (epoch 8.182), train_loss = 1.64013231, grad/param norm = 1.9092e-01, time/batch = 0.6388s	
4264/26050 (epoch 8.184), train_loss = 1.37870310, grad/param norm = 1.7517e-01, time/batch = 0.6477s	
4265/26050 (epoch 8.186), train_loss = 1.11773647, grad/param norm = 1.5674e-01, time/batch = 0.6435s	
4266/26050 (epoch 8.188), train_loss = 1.33580288, grad/param norm = 1.6647e-01, time/batch = 0.6458s	
4267/26050 (epoch 8.190), train_loss = 1.40159521, grad/param norm = 1.8505e-01, time/batch = 0.6453s	
4268/26050 (epoch 8.192), train_loss = 1.39382672, grad/param norm = 1.7864e-01, time/batch = 0.6387s	
4269/26050 (epoch 8.194), train_loss = 1.38792438, grad/param norm = 1.7963e-01, time/batch = 0.6373s	
4270/26050 (epoch 8.196), train_loss = 1.45235801, grad/param norm = 1.8952e-01, time/batch = 0.6379s	
4271/26050 (epoch 8.198), train_loss = 1.28640247, grad/param norm = 1.8719e-01, time/batch = 0.6395s	
4272/26050 (epoch 8.200), train_loss = 1.27295683, grad/param norm = 1.8486e-01, time/batch = 0.6399s	
4273/26050 (epoch 8.202), train_loss = 1.28027682, grad/param norm = 1.8588e-01, time/batch = 0.6400s	
4274/26050 (epoch 8.203), train_loss = 1.44036110, grad/param norm = 2.0403e-01, time/batch = 0.6409s	
4275/26050 (epoch 8.205), train_loss = 1.24923703, grad/param norm = 1.7488e-01, time/batch = 0.6423s	
4276/26050 (epoch 8.207), train_loss = 1.33189911, grad/param norm = 1.6158e-01, time/batch = 0.6593s	
4277/26050 (epoch 8.209), train_loss = 1.32957390, grad/param norm = 1.7917e-01, time/batch = 0.6717s	
4278/26050 (epoch 8.211), train_loss = 1.19026993, grad/param norm = 1.6866e-01, time/batch = 0.6557s	
4279/26050 (epoch 8.213), train_loss = 1.39478763, grad/param norm = 1.7051e-01, time/batch = 0.6427s	
4280/26050 (epoch 8.215), train_loss = 1.39893367, grad/param norm = 2.0154e-01, time/batch = 0.6513s	
4281/26050 (epoch 8.217), train_loss = 1.29458060, grad/param norm = 1.7031e-01, time/batch = 0.6426s	
4282/26050 (epoch 8.219), train_loss = 1.27324332, grad/param norm = 1.8553e-01, time/batch = 0.6404s	
4283/26050 (epoch 8.221), train_loss = 1.19593355, grad/param norm = 1.6704e-01, time/batch = 0.6383s	
4284/26050 (epoch 8.223), train_loss = 1.42558583, grad/param norm = 1.9041e-01, time/batch = 0.6391s	
4285/26050 (epoch 8.225), train_loss = 1.25523340, grad/param norm = 1.9658e-01, time/batch = 0.6379s	
4286/26050 (epoch 8.226), train_loss = 1.50320974, grad/param norm = 1.8835e-01, time/batch = 0.6393s	
4287/26050 (epoch 8.228), train_loss = 1.51273216, grad/param norm = 1.9627e-01, time/batch = 0.6406s	
4288/26050 (epoch 8.230), train_loss = 1.39424640, grad/param norm = 1.8431e-01, time/batch = 0.6469s	
4289/26050 (epoch 8.232), train_loss = 1.48837895, grad/param norm = 2.0083e-01, time/batch = 0.6565s	
4290/26050 (epoch 8.234), train_loss = 1.17624375, grad/param norm = 1.7828e-01, time/batch = 0.6628s	
4291/26050 (epoch 8.236), train_loss = 1.41901033, grad/param norm = 2.0084e-01, time/batch = 0.6445s	
4292/26050 (epoch 8.238), train_loss = 1.15309506, grad/param norm = 1.7749e-01, time/batch = 0.6554s	
4293/26050 (epoch 8.240), train_loss = 1.28969760, grad/param norm = 1.7155e-01, time/batch = 0.6452s	
4294/26050 (epoch 8.242), train_loss = 1.30744591, grad/param norm = 1.6903e-01, time/batch = 0.6455s	
4295/26050 (epoch 8.244), train_loss = 1.40735025, grad/param norm = 2.0379e-01, time/batch = 0.6423s	
4296/26050 (epoch 8.246), train_loss = 1.26875209, grad/param norm = 1.6202e-01, time/batch = 0.6442s	
4297/26050 (epoch 8.248), train_loss = 1.39195277, grad/param norm = 1.8147e-01, time/batch = 0.6481s	
4298/26050 (epoch 8.250), train_loss = 1.38006071, grad/param norm = 1.9710e-01, time/batch = 0.6448s	
4299/26050 (epoch 8.251), train_loss = 1.24434842, grad/param norm = 1.7332e-01, time/batch = 0.6424s	
4300/26050 (epoch 8.253), train_loss = 1.15948361, grad/param norm = 1.7895e-01, time/batch = 0.6412s	
4301/26050 (epoch 8.255), train_loss = 1.58029275, grad/param norm = 1.9234e-01, time/batch = 0.6440s	
4302/26050 (epoch 8.257), train_loss = 1.35550967, grad/param norm = 1.9898e-01, time/batch = 0.6420s	
4303/26050 (epoch 8.259), train_loss = 1.49506449, grad/param norm = 1.8326e-01, time/batch = 0.6434s	
4304/26050 (epoch 8.261), train_loss = 1.29073080, grad/param norm = 1.9008e-01, time/batch = 0.6468s	
4305/26050 (epoch 8.263), train_loss = 1.34099578, grad/param norm = 1.8312e-01, time/batch = 0.6456s	
4306/26050 (epoch 8.265), train_loss = 1.53776758, grad/param norm = 1.8076e-01, time/batch = 0.6410s	
4307/26050 (epoch 8.267), train_loss = 1.41616301, grad/param norm = 1.8530e-01, time/batch = 0.6409s	
4308/26050 (epoch 8.269), train_loss = 1.54577508, grad/param norm = 1.9349e-01, time/batch = 0.6418s	
4309/26050 (epoch 8.271), train_loss = 1.37321272, grad/param norm = 1.7981e-01, time/batch = 0.6479s	
4310/26050 (epoch 8.273), train_loss = 1.29934634, grad/param norm = 1.7819e-01, time/batch = 0.6423s	
4311/26050 (epoch 8.274), train_loss = 1.28791429, grad/param norm = 1.7594e-01, time/batch = 0.6471s	
4312/26050 (epoch 8.276), train_loss = 1.26832839, grad/param norm = 1.8348e-01, time/batch = 0.6603s	
4313/26050 (epoch 8.278), train_loss = 1.45930440, grad/param norm = 1.8578e-01, time/batch = 0.6608s	
4314/26050 (epoch 8.280), train_loss = 1.32521871, grad/param norm = 1.6673e-01, time/batch = 0.6434s	
4315/26050 (epoch 8.282), train_loss = 1.39981111, grad/param norm = 1.9423e-01, time/batch = 0.6410s	
4316/26050 (epoch 8.284), train_loss = 1.23424662, grad/param norm = 1.7921e-01, time/batch = 0.6416s	
4317/26050 (epoch 8.286), train_loss = 1.33014154, grad/param norm = 1.9090e-01, time/batch = 0.6598s	
4318/26050 (epoch 8.288), train_loss = 1.16923163, grad/param norm = 1.5990e-01, time/batch = 0.6554s	
4319/26050 (epoch 8.290), train_loss = 1.32220564, grad/param norm = 1.7893e-01, time/batch = 0.6427s	
4320/26050 (epoch 8.292), train_loss = 1.27604261, grad/param norm = 1.7095e-01, time/batch = 0.6510s	
4321/26050 (epoch 8.294), train_loss = 1.36672373, grad/param norm = 1.9575e-01, time/batch = 0.6403s	
4322/26050 (epoch 8.296), train_loss = 1.46101476, grad/param norm = 1.8625e-01, time/batch = 0.6402s	
4323/26050 (epoch 8.298), train_loss = 1.32899795, grad/param norm = 1.7310e-01, time/batch = 0.6396s	
4324/26050 (epoch 8.299), train_loss = 1.09569726, grad/param norm = 1.4884e-01, time/batch = 0.6394s	
4325/26050 (epoch 8.301), train_loss = 1.28248417, grad/param norm = 1.8479e-01, time/batch = 0.6392s	
4326/26050 (epoch 8.303), train_loss = 1.39543007, grad/param norm = 1.8021e-01, time/batch = 0.6391s	
4327/26050 (epoch 8.305), train_loss = 1.18391655, grad/param norm = 1.7111e-01, time/batch = 0.6403s	
4328/26050 (epoch 8.307), train_loss = 1.22752557, grad/param norm = 1.7906e-01, time/batch = 0.6409s	
4329/26050 (epoch 8.309), train_loss = 1.30686015, grad/param norm = 1.8701e-01, time/batch = 0.6384s	
4330/26050 (epoch 8.311), train_loss = 1.54263759, grad/param norm = 2.0611e-01, time/batch = 0.6411s	
4331/26050 (epoch 8.313), train_loss = 1.34688239, grad/param norm = 1.9361e-01, time/batch = 0.6403s	
4332/26050 (epoch 8.315), train_loss = 1.49393158, grad/param norm = 1.9319e-01, time/batch = 0.6401s	
4333/26050 (epoch 8.317), train_loss = 1.27285341, grad/param norm = 1.7481e-01, time/batch = 0.6430s	
4334/26050 (epoch 8.319), train_loss = 1.31710431, grad/param norm = 1.6269e-01, time/batch = 0.6577s	
4335/26050 (epoch 8.321), train_loss = 1.31711217, grad/param norm = 1.8623e-01, time/batch = 0.6603s	
4336/26050 (epoch 8.322), train_loss = 1.35680258, grad/param norm = 1.7647e-01, time/batch = 0.6625s	
4337/26050 (epoch 8.324), train_loss = 1.14867426, grad/param norm = 1.7175e-01, time/batch = 0.6392s	
4338/26050 (epoch 8.326), train_loss = 1.49277146, grad/param norm = 1.9725e-01, time/batch = 0.6435s	
4339/26050 (epoch 8.328), train_loss = 1.38502785, grad/param norm = 1.7933e-01, time/batch = 0.6412s	
4340/26050 (epoch 8.330), train_loss = 1.23378957, grad/param norm = 1.7670e-01, time/batch = 0.6398s	
4341/26050 (epoch 8.332), train_loss = 1.43778722, grad/param norm = 1.8476e-01, time/batch = 0.6461s	
4342/26050 (epoch 8.334), train_loss = 1.31386244, grad/param norm = 1.7526e-01, time/batch = 0.6492s	
4343/26050 (epoch 8.336), train_loss = 1.21783957, grad/param norm = 1.6123e-01, time/batch = 0.6796s	
4344/26050 (epoch 8.338), train_loss = 1.18581659, grad/param norm = 1.5926e-01, time/batch = 0.6683s	
4345/26050 (epoch 8.340), train_loss = 1.44244435, grad/param norm = 1.9991e-01, time/batch = 0.6417s	
4346/26050 (epoch 8.342), train_loss = 1.49719876, grad/param norm = 1.8975e-01, time/batch = 0.6383s	
4347/26050 (epoch 8.344), train_loss = 1.33558395, grad/param norm = 1.9861e-01, time/batch = 0.6380s	
4348/26050 (epoch 8.345), train_loss = 1.34620243, grad/param norm = 2.0086e-01, time/batch = 0.6382s	
4349/26050 (epoch 8.347), train_loss = 1.41693660, grad/param norm = 1.8817e-01, time/batch = 0.6408s	
4350/26050 (epoch 8.349), train_loss = 1.36861669, grad/param norm = 1.8430e-01, time/batch = 0.6417s	
4351/26050 (epoch 8.351), train_loss = 1.38736480, grad/param norm = 1.9596e-01, time/batch = 0.6425s	
4352/26050 (epoch 8.353), train_loss = 1.28346412, grad/param norm = 1.8914e-01, time/batch = 0.6414s	
4353/26050 (epoch 8.355), train_loss = 1.44435228, grad/param norm = 1.9032e-01, time/batch = 0.6418s	
4354/26050 (epoch 8.357), train_loss = 1.19710946, grad/param norm = 1.6000e-01, time/batch = 0.6558s	
4355/26050 (epoch 8.359), train_loss = 1.44614522, grad/param norm = 1.9175e-01, time/batch = 0.6562s	
4356/26050 (epoch 8.361), train_loss = 1.24875864, grad/param norm = 1.7396e-01, time/batch = 0.6569s	
4357/26050 (epoch 8.363), train_loss = 1.36280303, grad/param norm = 1.7471e-01, time/batch = 0.6559s	
4358/26050 (epoch 8.365), train_loss = 1.25710894, grad/param norm = 1.6370e-01, time/batch = 0.6496s	
4359/26050 (epoch 8.367), train_loss = 1.33984882, grad/param norm = 1.7837e-01, time/batch = 0.6410s	
4360/26050 (epoch 8.369), train_loss = 1.30150325, grad/param norm = 1.6248e-01, time/batch = 0.6376s	
4361/26050 (epoch 8.370), train_loss = 1.22323073, grad/param norm = 1.6182e-01, time/batch = 0.6415s	
4362/26050 (epoch 8.372), train_loss = 1.45185454, grad/param norm = 1.9599e-01, time/batch = 0.6392s	
4363/26050 (epoch 8.374), train_loss = 1.55819353, grad/param norm = 2.0673e-01, time/batch = 0.6376s	
4364/26050 (epoch 8.376), train_loss = 1.58830281, grad/param norm = 1.8696e-01, time/batch = 0.6381s	
4365/26050 (epoch 8.378), train_loss = 1.32759760, grad/param norm = 1.8413e-01, time/batch = 0.6387s	
4366/26050 (epoch 8.380), train_loss = 1.55942206, grad/param norm = 1.9415e-01, time/batch = 0.6467s	
4367/26050 (epoch 8.382), train_loss = 1.69974339, grad/param norm = 2.1210e-01, time/batch = 0.6389s	
4368/26050 (epoch 8.384), train_loss = 1.31677017, grad/param norm = 1.7484e-01, time/batch = 0.6382s	
4369/26050 (epoch 8.386), train_loss = 1.45960143, grad/param norm = 1.8443e-01, time/batch = 0.6373s	
4370/26050 (epoch 8.388), train_loss = 1.38006543, grad/param norm = 1.6994e-01, time/batch = 0.6383s	
4371/26050 (epoch 8.390), train_loss = 1.21351580, grad/param norm = 1.6362e-01, time/batch = 0.6399s	
4372/26050 (epoch 8.392), train_loss = 1.22947251, grad/param norm = 1.6623e-01, time/batch = 0.6389s	
4373/26050 (epoch 8.393), train_loss = 1.40961285, grad/param norm = 1.7382e-01, time/batch = 0.6395s	
4374/26050 (epoch 8.395), train_loss = 1.41972513, grad/param norm = 1.7729e-01, time/batch = 0.6385s	
4375/26050 (epoch 8.397), train_loss = 1.40572589, grad/param norm = 1.9117e-01, time/batch = 0.6376s	
4376/26050 (epoch 8.399), train_loss = 1.21737584, grad/param norm = 1.6076e-01, time/batch = 0.6463s	
4377/26050 (epoch 8.401), train_loss = 1.28570886, grad/param norm = 1.6412e-01, time/batch = 0.6424s	
4378/26050 (epoch 8.403), train_loss = 1.36625667, grad/param norm = 1.7677e-01, time/batch = 0.6436s	
4379/26050 (epoch 8.405), train_loss = 1.34569600, grad/param norm = 1.8059e-01, time/batch = 0.6391s	
4380/26050 (epoch 8.407), train_loss = 1.51777194, grad/param norm = 1.9083e-01, time/batch = 0.6413s	
4381/26050 (epoch 8.409), train_loss = 1.54330096, grad/param norm = 1.9976e-01, time/batch = 0.6616s	
4382/26050 (epoch 8.411), train_loss = 1.40334389, grad/param norm = 1.8464e-01, time/batch = 0.6502s	
4383/26050 (epoch 8.413), train_loss = 1.48793828, grad/param norm = 1.7705e-01, time/batch = 0.6552s	
4384/26050 (epoch 8.415), train_loss = 1.48711223, grad/param norm = 1.9383e-01, time/batch = 0.6482s	
4385/26050 (epoch 8.417), train_loss = 1.57697269, grad/param norm = 1.9492e-01, time/batch = 0.6424s	
4386/26050 (epoch 8.418), train_loss = 1.45610826, grad/param norm = 2.0095e-01, time/batch = 0.6433s	
4387/26050 (epoch 8.420), train_loss = 1.14615466, grad/param norm = 1.5957e-01, time/batch = 0.6398s	
4388/26050 (epoch 8.422), train_loss = 1.21709281, grad/param norm = 1.7937e-01, time/batch = 0.6552s	
4389/26050 (epoch 8.424), train_loss = 1.57672392, grad/param norm = 2.1371e-01, time/batch = 0.6436s	
4390/26050 (epoch 8.426), train_loss = 1.52048331, grad/param norm = 1.9903e-01, time/batch = 0.6411s	
4391/26050 (epoch 8.428), train_loss = 1.25480486, grad/param norm = 1.6124e-01, time/batch = 0.6423s	
4392/26050 (epoch 8.430), train_loss = 1.40881480, grad/param norm = 1.9707e-01, time/batch = 0.6398s	
4393/26050 (epoch 8.432), train_loss = 1.30041672, grad/param norm = 1.8027e-01, time/batch = 0.6389s	
4394/26050 (epoch 8.434), train_loss = 1.36705272, grad/param norm = 1.8481e-01, time/batch = 0.6374s	
4395/26050 (epoch 8.436), train_loss = 1.49083238, grad/param norm = 1.7474e-01, time/batch = 0.6383s	
4396/26050 (epoch 8.438), train_loss = 1.23396796, grad/param norm = 1.6672e-01, time/batch = 0.6388s	
4397/26050 (epoch 8.440), train_loss = 1.39146584, grad/param norm = 1.7822e-01, time/batch = 0.6429s	
4398/26050 (epoch 8.441), train_loss = 1.35434524, grad/param norm = 1.7520e-01, time/batch = 0.6402s	
4399/26050 (epoch 8.443), train_loss = 1.14560404, grad/param norm = 1.5066e-01, time/batch = 0.6381s	
4400/26050 (epoch 8.445), train_loss = 1.22045255, grad/param norm = 1.7207e-01, time/batch = 0.6384s	
4401/26050 (epoch 8.447), train_loss = 1.57961718, grad/param norm = 1.9097e-01, time/batch = 0.6492s	
4402/26050 (epoch 8.449), train_loss = 1.25107550, grad/param norm = 1.7367e-01, time/batch = 0.6478s	
4403/26050 (epoch 8.451), train_loss = 1.45640177, grad/param norm = 1.6736e-01, time/batch = 0.6416s	
4404/26050 (epoch 8.453), train_loss = 1.21606493, grad/param norm = 1.6316e-01, time/batch = 0.6433s	
4405/26050 (epoch 8.455), train_loss = 1.37847759, grad/param norm = 1.7571e-01, time/batch = 0.6425s	
4406/26050 (epoch 8.457), train_loss = 1.38193959, grad/param norm = 1.7786e-01, time/batch = 0.6401s	
4407/26050 (epoch 8.459), train_loss = 1.48420373, grad/param norm = 1.8720e-01, time/batch = 0.6420s	
4408/26050 (epoch 8.461), train_loss = 1.42438079, grad/param norm = 1.8969e-01, time/batch = 0.6420s	
4409/26050 (epoch 8.463), train_loss = 1.27821846, grad/param norm = 1.6193e-01, time/batch = 0.6414s	
4410/26050 (epoch 8.464), train_loss = 1.43038510, grad/param norm = 1.8577e-01, time/batch = 0.6490s	
4411/26050 (epoch 8.466), train_loss = 1.45740488, grad/param norm = 1.8749e-01, time/batch = 0.6464s	
4412/26050 (epoch 8.468), train_loss = 1.45909910, grad/param norm = 1.7089e-01, time/batch = 0.6484s	
4413/26050 (epoch 8.470), train_loss = 1.57439462, grad/param norm = 1.9903e-01, time/batch = 0.6445s	
4414/26050 (epoch 8.472), train_loss = 1.56370901, grad/param norm = 1.9023e-01, time/batch = 0.6409s	
4415/26050 (epoch 8.474), train_loss = 1.63168519, grad/param norm = 1.8591e-01, time/batch = 0.6404s	
4416/26050 (epoch 8.476), train_loss = 1.44592406, grad/param norm = 1.6979e-01, time/batch = 0.6465s	
4417/26050 (epoch 8.478), train_loss = 1.26455652, grad/param norm = 1.5924e-01, time/batch = 0.6637s	
4418/26050 (epoch 8.480), train_loss = 1.37866554, grad/param norm = 1.6033e-01, time/batch = 0.6734s	
4419/26050 (epoch 8.482), train_loss = 1.33626573, grad/param norm = 1.7707e-01, time/batch = 0.6764s	
4420/26050 (epoch 8.484), train_loss = 1.23911897, grad/param norm = 1.8041e-01, time/batch = 0.6747s	
4421/26050 (epoch 8.486), train_loss = 1.53185457, grad/param norm = 1.8074e-01, time/batch = 0.6758s	
4422/26050 (epoch 8.488), train_loss = 1.72034099, grad/param norm = 1.9683e-01, time/batch = 0.6632s	
4423/26050 (epoch 8.489), train_loss = 1.63999215, grad/param norm = 2.0184e-01, time/batch = 0.6412s	
4424/26050 (epoch 8.491), train_loss = 1.27921915, grad/param norm = 1.6782e-01, time/batch = 0.6390s	
4425/26050 (epoch 8.493), train_loss = 1.31867068, grad/param norm = 1.7302e-01, time/batch = 0.6390s	
4426/26050 (epoch 8.495), train_loss = 1.32827537, grad/param norm = 1.6755e-01, time/batch = 0.6396s	
4427/26050 (epoch 8.497), train_loss = 1.31477584, grad/param norm = 1.7532e-01, time/batch = 0.6501s	
4428/26050 (epoch 8.499), train_loss = 1.31724523, grad/param norm = 1.7866e-01, time/batch = 0.6494s	
4429/26050 (epoch 8.501), train_loss = 1.40283750, grad/param norm = 1.9173e-01, time/batch = 0.6407s	
4430/26050 (epoch 8.503), train_loss = 1.29632898, grad/param norm = 1.8451e-01, time/batch = 0.6399s	
4431/26050 (epoch 8.505), train_loss = 1.50082033, grad/param norm = 1.7890e-01, time/batch = 0.6418s	
4432/26050 (epoch 8.507), train_loss = 1.50067177, grad/param norm = 1.8296e-01, time/batch = 0.6422s	
4433/26050 (epoch 8.509), train_loss = 1.60621112, grad/param norm = 2.1317e-01, time/batch = 0.6446s	
4434/26050 (epoch 8.511), train_loss = 1.27470561, grad/param norm = 1.7745e-01, time/batch = 0.6551s	
4435/26050 (epoch 8.512), train_loss = 1.37935903, grad/param norm = 1.9180e-01, time/batch = 0.6496s	
4436/26050 (epoch 8.514), train_loss = 1.43799636, grad/param norm = 1.8291e-01, time/batch = 0.6581s	
4437/26050 (epoch 8.516), train_loss = 1.48558639, grad/param norm = 1.8796e-01, time/batch = 0.6661s	
4438/26050 (epoch 8.518), train_loss = 1.43147855, grad/param norm = 1.8324e-01, time/batch = 0.6509s	
4439/26050 (epoch 8.520), train_loss = 1.39948591, grad/param norm = 1.8660e-01, time/batch = 0.6490s	
4440/26050 (epoch 8.522), train_loss = 1.20577021, grad/param norm = 1.6921e-01, time/batch = 0.6497s	
4441/26050 (epoch 8.524), train_loss = 1.55396577, grad/param norm = 1.9300e-01, time/batch = 0.6542s	
4442/26050 (epoch 8.526), train_loss = 1.45877597, grad/param norm = 1.8888e-01, time/batch = 0.6507s	
4443/26050 (epoch 8.528), train_loss = 1.43899762, grad/param norm = 1.9117e-01, time/batch = 0.6511s	
4444/26050 (epoch 8.530), train_loss = 1.35355189, grad/param norm = 1.7064e-01, time/batch = 0.6595s	
4445/26050 (epoch 8.532), train_loss = 1.38046746, grad/param norm = 1.8492e-01, time/batch = 0.6516s	
4446/26050 (epoch 8.534), train_loss = 1.46856252, grad/param norm = 2.0135e-01, time/batch = 0.6513s	
4447/26050 (epoch 8.536), train_loss = 1.31452826, grad/param norm = 1.6853e-01, time/batch = 0.6535s	
4448/26050 (epoch 8.537), train_loss = 1.49951697, grad/param norm = 1.9348e-01, time/batch = 0.6588s	
4449/26050 (epoch 8.539), train_loss = 1.35431923, grad/param norm = 1.7087e-01, time/batch = 0.6579s	
4450/26050 (epoch 8.541), train_loss = 1.59287733, grad/param norm = 2.1959e-01, time/batch = 0.6489s	
4451/26050 (epoch 8.543), train_loss = 1.19818828, grad/param norm = 1.6602e-01, time/batch = 0.6466s	
4452/26050 (epoch 8.545), train_loss = 1.44860622, grad/param norm = 1.8418e-01, time/batch = 0.6568s	
4453/26050 (epoch 8.547), train_loss = 1.39832867, grad/param norm = 1.8409e-01, time/batch = 0.6428s	
4454/26050 (epoch 8.549), train_loss = 1.19906427, grad/param norm = 1.8331e-01, time/batch = 0.6424s	
4455/26050 (epoch 8.551), train_loss = 1.43541236, grad/param norm = 1.8582e-01, time/batch = 0.6407s	
4456/26050 (epoch 8.553), train_loss = 1.27637746, grad/param norm = 1.7598e-01, time/batch = 0.6410s	
4457/26050 (epoch 8.555), train_loss = 1.31667575, grad/param norm = 1.7012e-01, time/batch = 0.6406s	
4458/26050 (epoch 8.557), train_loss = 1.43921874, grad/param norm = 1.7349e-01, time/batch = 0.6467s	
4459/26050 (epoch 8.559), train_loss = 1.38380784, grad/param norm = 1.8251e-01, time/batch = 0.6412s	
4460/26050 (epoch 8.560), train_loss = 1.36519471, grad/param norm = 1.8575e-01, time/batch = 0.6401s	
4461/26050 (epoch 8.562), train_loss = 1.34827903, grad/param norm = 1.7819e-01, time/batch = 0.6531s	
4462/26050 (epoch 8.564), train_loss = 1.58086048, grad/param norm = 1.9935e-01, time/batch = 0.6817s	
4463/26050 (epoch 8.566), train_loss = 1.25207956, grad/param norm = 1.6554e-01, time/batch = 0.6629s	
4464/26050 (epoch 8.568), train_loss = 1.39139814, grad/param norm = 1.7704e-01, time/batch = 0.6548s	
4465/26050 (epoch 8.570), train_loss = 1.51532091, grad/param norm = 1.9329e-01, time/batch = 0.6410s	
4466/26050 (epoch 8.572), train_loss = 1.36847340, grad/param norm = 1.7193e-01, time/batch = 0.6546s	
4467/26050 (epoch 8.574), train_loss = 1.47763701, grad/param norm = 2.0631e-01, time/batch = 0.6537s	
4468/26050 (epoch 8.576), train_loss = 1.46622042, grad/param norm = 1.9266e-01, time/batch = 0.6391s	
4469/26050 (epoch 8.578), train_loss = 1.37035786, grad/param norm = 1.8315e-01, time/batch = 0.6397s	
4470/26050 (epoch 8.580), train_loss = 1.25511194, grad/param norm = 1.7369e-01, time/batch = 0.6430s	
4471/26050 (epoch 8.582), train_loss = 1.43598843, grad/param norm = 1.8863e-01, time/batch = 0.6432s	
4472/26050 (epoch 8.583), train_loss = 1.45591202, grad/param norm = 1.8479e-01, time/batch = 0.6450s	
4473/26050 (epoch 8.585), train_loss = 1.26058199, grad/param norm = 1.7254e-01, time/batch = 0.6588s	
4474/26050 (epoch 8.587), train_loss = 1.44028947, grad/param norm = 1.8511e-01, time/batch = 0.6527s	
4475/26050 (epoch 8.589), train_loss = 1.47017083, grad/param norm = 2.0532e-01, time/batch = 0.6640s	
4476/26050 (epoch 8.591), train_loss = 1.41605839, grad/param norm = 1.8733e-01, time/batch = 0.6640s	
4477/26050 (epoch 8.593), train_loss = 1.25788337, grad/param norm = 1.9239e-01, time/batch = 0.6839s	
4478/26050 (epoch 8.595), train_loss = 1.55389298, grad/param norm = 2.1277e-01, time/batch = 0.6602s	
4479/26050 (epoch 8.597), train_loss = 1.42047268, grad/param norm = 1.8315e-01, time/batch = 0.6434s	
4480/26050 (epoch 8.599), train_loss = 1.30289769, grad/param norm = 1.7586e-01, time/batch = 0.6442s	
4481/26050 (epoch 8.601), train_loss = 1.59031080, grad/param norm = 1.8893e-01, time/batch = 0.6474s	
4482/26050 (epoch 8.603), train_loss = 1.44216693, grad/param norm = 1.8427e-01, time/batch = 0.6512s	
4483/26050 (epoch 8.605), train_loss = 1.30583397, grad/param norm = 1.7153e-01, time/batch = 0.6420s	
4484/26050 (epoch 8.607), train_loss = 1.51515081, grad/param norm = 1.9119e-01, time/batch = 0.6421s	
4485/26050 (epoch 8.608), train_loss = 1.31428032, grad/param norm = 1.6227e-01, time/batch = 0.6437s	
4486/26050 (epoch 8.610), train_loss = 1.35453396, grad/param norm = 1.8255e-01, time/batch = 0.6416s	
4487/26050 (epoch 8.612), train_loss = 1.34263001, grad/param norm = 1.8430e-01, time/batch = 0.6417s	
4488/26050 (epoch 8.614), train_loss = 1.44089854, grad/param norm = 1.8052e-01, time/batch = 0.6460s	
4489/26050 (epoch 8.616), train_loss = 1.65395608, grad/param norm = 1.9340e-01, time/batch = 0.6481s	
4490/26050 (epoch 8.618), train_loss = 1.29655923, grad/param norm = 1.7946e-01, time/batch = 0.6425s	
4491/26050 (epoch 8.620), train_loss = 1.39556984, grad/param norm = 1.8434e-01, time/batch = 0.6429s	
4492/26050 (epoch 8.622), train_loss = 1.14288759, grad/param norm = 1.6015e-01, time/batch = 0.6744s	
4493/26050 (epoch 8.624), train_loss = 1.25279636, grad/param norm = 1.6632e-01, time/batch = 0.6629s	
4494/26050 (epoch 8.626), train_loss = 1.43720150, grad/param norm = 1.9015e-01, time/batch = 0.6446s	
4495/26050 (epoch 8.628), train_loss = 1.35612407, grad/param norm = 1.9033e-01, time/batch = 0.6443s	
4496/26050 (epoch 8.630), train_loss = 1.50578880, grad/param norm = 1.7728e-01, time/batch = 0.6433s	
4497/26050 (epoch 8.631), train_loss = 1.51543024, grad/param norm = 1.9537e-01, time/batch = 0.6417s	
4498/26050 (epoch 8.633), train_loss = 1.26983339, grad/param norm = 1.7437e-01, time/batch = 0.6429s	
4499/26050 (epoch 8.635), train_loss = 1.26518268, grad/param norm = 1.6565e-01, time/batch = 0.6529s	
4500/26050 (epoch 8.637), train_loss = 1.27420561, grad/param norm = 1.8211e-01, time/batch = 0.6544s	
4501/26050 (epoch 8.639), train_loss = 1.47728956, grad/param norm = 1.8088e-01, time/batch = 0.6563s	
4502/26050 (epoch 8.641), train_loss = 1.29647100, grad/param norm = 1.5747e-01, time/batch = 0.6728s	
4503/26050 (epoch 8.643), train_loss = 1.24811089, grad/param norm = 1.5864e-01, time/batch = 0.6589s	
4504/26050 (epoch 8.645), train_loss = 1.40984543, grad/param norm = 1.8733e-01, time/batch = 0.6621s	
4505/26050 (epoch 8.647), train_loss = 1.32659071, grad/param norm = 1.7339e-01, time/batch = 0.6600s	
4506/26050 (epoch 8.649), train_loss = 1.42214295, grad/param norm = 1.9929e-01, time/batch = 0.6539s	
4507/26050 (epoch 8.651), train_loss = 1.31298646, grad/param norm = 1.8664e-01, time/batch = 0.6479s	
4508/26050 (epoch 8.653), train_loss = 1.37043743, grad/param norm = 1.8524e-01, time/batch = 0.6506s	
4509/26050 (epoch 8.655), train_loss = 1.27053106, grad/param norm = 1.7572e-01, time/batch = 0.6761s	
4510/26050 (epoch 8.656), train_loss = 1.24087932, grad/param norm = 1.7602e-01, time/batch = 0.6804s	
4511/26050 (epoch 8.658), train_loss = 1.57057084, grad/param norm = 1.8470e-01, time/batch = 0.6792s	
4512/26050 (epoch 8.660), train_loss = 1.26232991, grad/param norm = 1.9656e-01, time/batch = 0.6601s	
4513/26050 (epoch 8.662), train_loss = 1.23096768, grad/param norm = 1.6314e-01, time/batch = 0.6534s	
4514/26050 (epoch 8.664), train_loss = 1.34607519, grad/param norm = 1.8244e-01, time/batch = 0.6419s	
4515/26050 (epoch 8.666), train_loss = 1.41279236, grad/param norm = 1.9498e-01, time/batch = 0.6407s	
4516/26050 (epoch 8.668), train_loss = 1.14135665, grad/param norm = 1.5615e-01, time/batch = 0.6401s	
4517/26050 (epoch 8.670), train_loss = 1.55329758, grad/param norm = 2.0396e-01, time/batch = 0.6433s	
4518/26050 (epoch 8.672), train_loss = 1.29032776, grad/param norm = 1.8089e-01, time/batch = 0.6436s	
4519/26050 (epoch 8.674), train_loss = 1.24654263, grad/param norm = 1.5819e-01, time/batch = 0.6409s	
4520/26050 (epoch 8.676), train_loss = 1.40503789, grad/param norm = 1.7498e-01, time/batch = 0.6501s	
4521/26050 (epoch 8.678), train_loss = 1.51436792, grad/param norm = 1.8672e-01, time/batch = 0.6416s	
4522/26050 (epoch 8.679), train_loss = 1.56633433, grad/param norm = 2.0145e-01, time/batch = 0.6418s	
4523/26050 (epoch 8.681), train_loss = 1.39006002, grad/param norm = 1.8906e-01, time/batch = 0.6432s	
4524/26050 (epoch 8.683), train_loss = 1.30184637, grad/param norm = 1.9739e-01, time/batch = 0.6422s	
4525/26050 (epoch 8.685), train_loss = 1.30079364, grad/param norm = 1.6356e-01, time/batch = 0.6418s	
4526/26050 (epoch 8.687), train_loss = 1.16250164, grad/param norm = 1.6576e-01, time/batch = 0.6413s	
4527/26050 (epoch 8.689), train_loss = 1.34201999, grad/param norm = 1.7688e-01, time/batch = 0.6446s	
4528/26050 (epoch 8.691), train_loss = 1.08904760, grad/param norm = 1.6891e-01, time/batch = 0.6422s	
4529/26050 (epoch 8.693), train_loss = 1.28032485, grad/param norm = 1.7932e-01, time/batch = 0.6399s	
4530/26050 (epoch 8.695), train_loss = 1.38756801, grad/param norm = 1.8360e-01, time/batch = 0.6403s	
4531/26050 (epoch 8.697), train_loss = 1.23177770, grad/param norm = 1.7706e-01, time/batch = 0.6402s	
4532/26050 (epoch 8.699), train_loss = 1.42965297, grad/param norm = 1.8284e-01, time/batch = 0.6392s	
4533/26050 (epoch 8.701), train_loss = 1.19223602, grad/param norm = 1.6665e-01, time/batch = 0.6406s	
4534/26050 (epoch 8.702), train_loss = 1.59286491, grad/param norm = 1.9046e-01, time/batch = 0.6459s	
4535/26050 (epoch 8.704), train_loss = 1.37509351, grad/param norm = 1.7392e-01, time/batch = 0.6440s	
4536/26050 (epoch 8.706), train_loss = 1.44428713, grad/param norm = 2.0451e-01, time/batch = 0.6402s	
4537/26050 (epoch 8.708), train_loss = 1.42664882, grad/param norm = 1.7515e-01, time/batch = 0.6394s	
4538/26050 (epoch 8.710), train_loss = 1.43817940, grad/param norm = 1.8261e-01, time/batch = 0.6514s	
4539/26050 (epoch 8.712), train_loss = 1.54495391, grad/param norm = 1.8491e-01, time/batch = 0.6418s	
4540/26050 (epoch 8.714), train_loss = 1.22189894, grad/param norm = 1.7754e-01, time/batch = 0.6384s	
4541/26050 (epoch 8.716), train_loss = 1.62178395, grad/param norm = 2.0937e-01, time/batch = 0.6423s	
4542/26050 (epoch 8.718), train_loss = 1.48043578, grad/param norm = 1.8886e-01, time/batch = 0.6425s	
4543/26050 (epoch 8.720), train_loss = 1.28738140, grad/param norm = 1.7521e-01, time/batch = 0.6414s	
4544/26050 (epoch 8.722), train_loss = 1.22620649, grad/param norm = 1.6571e-01, time/batch = 0.6394s	
4545/26050 (epoch 8.724), train_loss = 1.23282587, grad/param norm = 1.7558e-01, time/batch = 0.6395s	
4546/26050 (epoch 8.726), train_loss = 1.47186778, grad/param norm = 1.8109e-01, time/batch = 0.6407s	
4547/26050 (epoch 8.727), train_loss = 1.43263490, grad/param norm = 1.7562e-01, time/batch = 0.6392s	
4548/26050 (epoch 8.729), train_loss = 1.43763112, grad/param norm = 1.8730e-01, time/batch = 0.6401s	
4549/26050 (epoch 8.731), train_loss = 1.37011126, grad/param norm = 1.6326e-01, time/batch = 0.6398s	
4550/26050 (epoch 8.733), train_loss = 1.33369658, grad/param norm = 2.0765e-01, time/batch = 0.6444s	
4551/26050 (epoch 8.735), train_loss = 1.56961736, grad/param norm = 1.8864e-01, time/batch = 0.6482s	
4552/26050 (epoch 8.737), train_loss = 1.38175936, grad/param norm = 1.8646e-01, time/batch = 0.6408s	
4553/26050 (epoch 8.739), train_loss = 1.39800506, grad/param norm = 1.7548e-01, time/batch = 0.6490s	
4554/26050 (epoch 8.741), train_loss = 1.26473457, grad/param norm = 1.6918e-01, time/batch = 0.6831s	
4555/26050 (epoch 8.743), train_loss = 1.44409708, grad/param norm = 2.1861e-01, time/batch = 0.6532s	
4556/26050 (epoch 8.745), train_loss = 1.24534403, grad/param norm = 1.8768e-01, time/batch = 0.6411s	
4557/26050 (epoch 8.747), train_loss = 1.26758069, grad/param norm = 1.8025e-01, time/batch = 0.6404s	
4558/26050 (epoch 8.749), train_loss = 1.50214775, grad/param norm = 1.9600e-01, time/batch = 0.6400s	
4559/26050 (epoch 8.750), train_loss = 1.31991826, grad/param norm = 1.6802e-01, time/batch = 0.6398s	
4560/26050 (epoch 8.752), train_loss = 1.40019224, grad/param norm = 2.0942e-01, time/batch = 0.6396s	
4561/26050 (epoch 8.754), train_loss = 1.35614258, grad/param norm = 1.7926e-01, time/batch = 0.6424s	
4562/26050 (epoch 8.756), train_loss = 1.43757134, grad/param norm = 1.9394e-01, time/batch = 0.6404s	
4563/26050 (epoch 8.758), train_loss = 1.38432301, grad/param norm = 1.8126e-01, time/batch = 0.6399s	
4564/26050 (epoch 8.760), train_loss = 1.46692391, grad/param norm = 1.8937e-01, time/batch = 0.6410s	
4565/26050 (epoch 8.762), train_loss = 1.26150453, grad/param norm = 1.6575e-01, time/batch = 0.6492s	
4566/26050 (epoch 8.764), train_loss = 1.46778374, grad/param norm = 1.8386e-01, time/batch = 0.6489s	
4567/26050 (epoch 8.766), train_loss = 1.46545138, grad/param norm = 1.9130e-01, time/batch = 0.6768s	
4568/26050 (epoch 8.768), train_loss = 1.23196706, grad/param norm = 1.5580e-01, time/batch = 0.6534s	
4569/26050 (epoch 8.770), train_loss = 1.37227441, grad/param norm = 1.8249e-01, time/batch = 0.6649s	
4570/26050 (epoch 8.772), train_loss = 1.35199045, grad/param norm = 1.6998e-01, time/batch = 0.6579s	
4571/26050 (epoch 8.774), train_loss = 1.24547850, grad/param norm = 1.8470e-01, time/batch = 0.6585s	
4572/26050 (epoch 8.775), train_loss = 1.06439588, grad/param norm = 1.7262e-01, time/batch = 0.6449s	
4573/26050 (epoch 8.777), train_loss = 1.28804337, grad/param norm = 1.8089e-01, time/batch = 0.6442s	
4574/26050 (epoch 8.779), train_loss = 1.32588162, grad/param norm = 1.7359e-01, time/batch = 0.6553s	
4575/26050 (epoch 8.781), train_loss = 1.31025278, grad/param norm = 1.7407e-01, time/batch = 0.6425s	
4576/26050 (epoch 8.783), train_loss = 1.27819161, grad/param norm = 1.6530e-01, time/batch = 0.6415s	
4577/26050 (epoch 8.785), train_loss = 1.31623925, grad/param norm = 1.9176e-01, time/batch = 0.6415s	
4578/26050 (epoch 8.787), train_loss = 1.28968945, grad/param norm = 1.7143e-01, time/batch = 0.6395s	
4579/26050 (epoch 8.789), train_loss = 1.35335552, grad/param norm = 1.9624e-01, time/batch = 0.6425s	
4580/26050 (epoch 8.791), train_loss = 1.36900343, grad/param norm = 1.8226e-01, time/batch = 0.6409s	
4581/26050 (epoch 8.793), train_loss = 1.35236071, grad/param norm = 1.8507e-01, time/batch = 0.6458s	
4582/26050 (epoch 8.795), train_loss = 1.17731550, grad/param norm = 1.6416e-01, time/batch = 0.6444s	
4583/26050 (epoch 8.797), train_loss = 1.23969476, grad/param norm = 1.6306e-01, time/batch = 0.6405s	
4584/26050 (epoch 8.798), train_loss = 1.22950368, grad/param norm = 1.7605e-01, time/batch = 0.6649s	
4585/26050 (epoch 8.800), train_loss = 1.20833107, grad/param norm = 1.6084e-01, time/batch = 0.6848s	
4586/26050 (epoch 8.802), train_loss = 1.34140144, grad/param norm = 1.8061e-01, time/batch = 0.6466s	
4587/26050 (epoch 8.804), train_loss = 1.32440009, grad/param norm = 1.6850e-01, time/batch = 0.6460s	
4588/26050 (epoch 8.806), train_loss = 1.48966706, grad/param norm = 1.9263e-01, time/batch = 0.6508s	
4589/26050 (epoch 8.808), train_loss = 1.31890752, grad/param norm = 1.7251e-01, time/batch = 0.6431s	
4590/26050 (epoch 8.810), train_loss = 1.29183731, grad/param norm = 1.8830e-01, time/batch = 0.6513s	
4591/26050 (epoch 8.812), train_loss = 1.22903471, grad/param norm = 1.7812e-01, time/batch = 0.6483s	
4592/26050 (epoch 8.814), train_loss = 1.22620872, grad/param norm = 1.8480e-01, time/batch = 0.6426s	
4593/26050 (epoch 8.816), train_loss = 1.42731128, grad/param norm = 1.8912e-01, time/batch = 0.6411s	
4594/26050 (epoch 8.818), train_loss = 1.52854481, grad/param norm = 2.1092e-01, time/batch = 0.6438s	
4595/26050 (epoch 8.820), train_loss = 1.37505183, grad/param norm = 1.8513e-01, time/batch = 0.6394s	
4596/26050 (epoch 8.821), train_loss = 1.53060271, grad/param norm = 2.1291e-01, time/batch = 0.6400s	
4597/26050 (epoch 8.823), train_loss = 1.57054993, grad/param norm = 1.9101e-01, time/batch = 0.6430s	
4598/26050 (epoch 8.825), train_loss = 1.30991968, grad/param norm = 1.9043e-01, time/batch = 0.6414s	
4599/26050 (epoch 8.827), train_loss = 1.41501936, grad/param norm = 1.9589e-01, time/batch = 0.6408s	
4600/26050 (epoch 8.829), train_loss = 1.42453199, grad/param norm = 1.9148e-01, time/batch = 0.6403s	
4601/26050 (epoch 8.831), train_loss = 1.51204117, grad/param norm = 1.9345e-01, time/batch = 0.6445s	
4602/26050 (epoch 8.833), train_loss = 1.56975992, grad/param norm = 1.7950e-01, time/batch = 0.6433s	
4603/26050 (epoch 8.835), train_loss = 1.60290026, grad/param norm = 1.9288e-01, time/batch = 0.6426s	
4604/26050 (epoch 8.837), train_loss = 1.31026996, grad/param norm = 1.7763e-01, time/batch = 0.6425s	
4605/26050 (epoch 8.839), train_loss = 1.45002556, grad/param norm = 1.8988e-01, time/batch = 0.6421s	
4606/26050 (epoch 8.841), train_loss = 1.47334200, grad/param norm = 1.7274e-01, time/batch = 0.6396s	
4607/26050 (epoch 8.843), train_loss = 1.43067223, grad/param norm = 1.8524e-01, time/batch = 0.6402s	
4608/26050 (epoch 8.845), train_loss = 1.28284733, grad/param norm = 1.7843e-01, time/batch = 0.6417s	
4609/26050 (epoch 8.846), train_loss = 1.50804881, grad/param norm = 1.8486e-01, time/batch = 0.6389s	
4610/26050 (epoch 8.848), train_loss = 1.32182359, grad/param norm = 1.7678e-01, time/batch = 0.6410s	
4611/26050 (epoch 8.850), train_loss = 1.31207513, grad/param norm = 1.7419e-01, time/batch = 0.6440s	
4612/26050 (epoch 8.852), train_loss = 1.34234274, grad/param norm = 1.8559e-01, time/batch = 0.6481s	
4613/26050 (epoch 8.854), train_loss = 1.37424444, grad/param norm = 1.8251e-01, time/batch = 0.6416s	
4614/26050 (epoch 8.856), train_loss = 1.28924932, grad/param norm = 1.8316e-01, time/batch = 0.6404s	
4615/26050 (epoch 8.858), train_loss = 1.24518374, grad/param norm = 1.8403e-01, time/batch = 0.6412s	
4616/26050 (epoch 8.860), train_loss = 1.40947852, grad/param norm = 1.9627e-01, time/batch = 0.6390s	
4617/26050 (epoch 8.862), train_loss = 1.37896594, grad/param norm = 1.8354e-01, time/batch = 0.6443s	
4618/26050 (epoch 8.864), train_loss = 1.33136209, grad/param norm = 1.8631e-01, time/batch = 0.6426s	
4619/26050 (epoch 8.866), train_loss = 1.26132357, grad/param norm = 1.6668e-01, time/batch = 0.6399s	
4620/26050 (epoch 8.868), train_loss = 1.47681981, grad/param norm = 2.0048e-01, time/batch = 0.6420s	
4621/26050 (epoch 8.869), train_loss = 1.20682597, grad/param norm = 1.6088e-01, time/batch = 0.6410s	
4622/26050 (epoch 8.871), train_loss = 1.17422943, grad/param norm = 1.5674e-01, time/batch = 0.6397s	
4623/26050 (epoch 8.873), train_loss = 1.40153405, grad/param norm = 1.7413e-01, time/batch = 0.6405s	
4624/26050 (epoch 8.875), train_loss = 1.33164235, grad/param norm = 1.7826e-01, time/batch = 0.6403s	
4625/26050 (epoch 8.877), train_loss = 1.19877925, grad/param norm = 1.7342e-01, time/batch = 0.6395s	
4626/26050 (epoch 8.879), train_loss = 1.33822267, grad/param norm = 1.6905e-01, time/batch = 0.6392s	
4627/26050 (epoch 8.881), train_loss = 1.52656657, grad/param norm = 1.9011e-01, time/batch = 0.6424s	
4628/26050 (epoch 8.883), train_loss = 1.38006304, grad/param norm = 1.7424e-01, time/batch = 0.6473s	
4629/26050 (epoch 8.885), train_loss = 1.07228990, grad/param norm = 1.5691e-01, time/batch = 0.6401s	
4630/26050 (epoch 8.887), train_loss = 1.40731486, grad/param norm = 1.7482e-01, time/batch = 0.6447s	
4631/26050 (epoch 8.889), train_loss = 1.27622723, grad/param norm = 1.6341e-01, time/batch = 0.6838s	
4632/26050 (epoch 8.891), train_loss = 1.11392760, grad/param norm = 1.5723e-01, time/batch = 0.6552s	
4633/26050 (epoch 8.893), train_loss = 1.08677231, grad/param norm = 1.5287e-01, time/batch = 0.6410s	
4634/26050 (epoch 8.894), train_loss = 1.26150562, grad/param norm = 1.6649e-01, time/batch = 0.6407s	
4635/26050 (epoch 8.896), train_loss = 1.46930761, grad/param norm = 1.8654e-01, time/batch = 0.6423s	
4636/26050 (epoch 8.898), train_loss = 1.28760784, grad/param norm = 1.8773e-01, time/batch = 0.6426s	
4637/26050 (epoch 8.900), train_loss = 1.55251489, grad/param norm = 1.9052e-01, time/batch = 0.6401s	
4638/26050 (epoch 8.902), train_loss = 1.35237548, grad/param norm = 1.7404e-01, time/batch = 0.6406s	
4639/26050 (epoch 8.904), train_loss = 1.29165226, grad/param norm = 1.6354e-01, time/batch = 0.6401s	
4640/26050 (epoch 8.906), train_loss = 1.32571046, grad/param norm = 1.7957e-01, time/batch = 0.6400s	
4641/26050 (epoch 8.908), train_loss = 1.32169998, grad/param norm = 1.7701e-01, time/batch = 0.6433s	
4642/26050 (epoch 8.910), train_loss = 1.24966559, grad/param norm = 1.6128e-01, time/batch = 0.6430s	
4643/26050 (epoch 8.912), train_loss = 1.62357596, grad/param norm = 1.9571e-01, time/batch = 0.6441s	
4644/26050 (epoch 8.914), train_loss = 1.79472648, grad/param norm = 1.9502e-01, time/batch = 0.6477s	
4645/26050 (epoch 8.916), train_loss = 1.50875926, grad/param norm = 1.9764e-01, time/batch = 0.6398s	
4646/26050 (epoch 8.917), train_loss = 1.41107328, grad/param norm = 1.9890e-01, time/batch = 0.6547s	
4647/26050 (epoch 8.919), train_loss = 1.47403432, grad/param norm = 1.9451e-01, time/batch = 0.6581s	
4648/26050 (epoch 8.921), train_loss = 1.28042913, grad/param norm = 2.0756e-01, time/batch = 0.6396s	
4649/26050 (epoch 8.923), train_loss = 1.35107462, grad/param norm = 1.9753e-01, time/batch = 0.6399s	
4650/26050 (epoch 8.925), train_loss = 1.31301152, grad/param norm = 1.7027e-01, time/batch = 0.6449s	
4651/26050 (epoch 8.927), train_loss = 1.21526262, grad/param norm = 1.5527e-01, time/batch = 0.6453s	
4652/26050 (epoch 8.929), train_loss = 1.27210520, grad/param norm = 1.7901e-01, time/batch = 0.6431s	
4653/26050 (epoch 8.931), train_loss = 1.61697227, grad/param norm = 2.1648e-01, time/batch = 0.6420s	
4654/26050 (epoch 8.933), train_loss = 1.30543344, grad/param norm = 1.8408e-01, time/batch = 0.6436s	
4655/26050 (epoch 8.935), train_loss = 1.27602593, grad/param norm = 1.7220e-01, time/batch = 0.6422s	
4656/26050 (epoch 8.937), train_loss = 1.36551558, grad/param norm = 1.6692e-01, time/batch = 0.6425s	
4657/26050 (epoch 8.939), train_loss = 1.23231095, grad/param norm = 1.6492e-01, time/batch = 0.6445s	
4658/26050 (epoch 8.940), train_loss = 1.36122876, grad/param norm = 1.7255e-01, time/batch = 0.6673s	
4659/26050 (epoch 8.942), train_loss = 1.38662770, grad/param norm = 2.0002e-01, time/batch = 0.6542s	
4660/26050 (epoch 8.944), train_loss = 1.31641521, grad/param norm = 1.9661e-01, time/batch = 0.6426s	
4661/26050 (epoch 8.946), train_loss = 1.50313712, grad/param norm = 1.8122e-01, time/batch = 0.6546s	
4662/26050 (epoch 8.948), train_loss = 1.17373772, grad/param norm = 1.9545e-01, time/batch = 0.6412s	
4663/26050 (epoch 8.950), train_loss = 1.31699935, grad/param norm = 1.6891e-01, time/batch = 0.6562s	
4664/26050 (epoch 8.952), train_loss = 1.50666894, grad/param norm = 1.9355e-01, time/batch = 0.6587s	
4665/26050 (epoch 8.954), train_loss = 1.44801476, grad/param norm = 1.8011e-01, time/batch = 0.6556s	
4666/26050 (epoch 8.956), train_loss = 1.42857639, grad/param norm = 1.9388e-01, time/batch = 0.6478s	
4667/26050 (epoch 8.958), train_loss = 1.33673947, grad/param norm = 1.8032e-01, time/batch = 0.6437s	
4668/26050 (epoch 8.960), train_loss = 1.32565291, grad/param norm = 1.7201e-01, time/batch = 0.6412s	
4669/26050 (epoch 8.962), train_loss = 1.26099033, grad/param norm = 1.7423e-01, time/batch = 0.6401s	
4670/26050 (epoch 8.964), train_loss = 1.32165699, grad/param norm = 1.6991e-01, time/batch = 0.6425s	
4671/26050 (epoch 8.965), train_loss = 1.22217318, grad/param norm = 1.7645e-01, time/batch = 0.6431s	
4672/26050 (epoch 8.967), train_loss = 1.67998688, grad/param norm = 1.8393e-01, time/batch = 0.6414s	
4673/26050 (epoch 8.969), train_loss = 1.30507617, grad/param norm = 1.6304e-01, time/batch = 0.6403s	
4674/26050 (epoch 8.971), train_loss = 1.22717950, grad/param norm = 1.6535e-01, time/batch = 0.6468s	
4675/26050 (epoch 8.973), train_loss = 1.31216413, grad/param norm = 1.9012e-01, time/batch = 0.6499s	
4676/26050 (epoch 8.975), train_loss = 1.41183831, grad/param norm = 1.6813e-01, time/batch = 0.6440s	
4677/26050 (epoch 8.977), train_loss = 1.36279914, grad/param norm = 1.5860e-01, time/batch = 0.6609s	
4678/26050 (epoch 8.979), train_loss = 1.18332611, grad/param norm = 1.7021e-01, time/batch = 0.6540s	
4679/26050 (epoch 8.981), train_loss = 1.45026407, grad/param norm = 1.7884e-01, time/batch = 0.6442s	
4680/26050 (epoch 8.983), train_loss = 1.45774844, grad/param norm = 1.8122e-01, time/batch = 0.6402s	
4681/26050 (epoch 8.985), train_loss = 1.38214439, grad/param norm = 1.8357e-01, time/batch = 0.6457s	
4682/26050 (epoch 8.987), train_loss = 1.52609482, grad/param norm = 1.9865e-01, time/batch = 0.6513s	
4683/26050 (epoch 8.988), train_loss = 1.46198754, grad/param norm = 1.8735e-01, time/batch = 0.6614s	
4684/26050 (epoch 8.990), train_loss = 1.27189021, grad/param norm = 1.6839e-01, time/batch = 0.6645s	
4685/26050 (epoch 8.992), train_loss = 1.52122030, grad/param norm = 1.9657e-01, time/batch = 0.6754s	
4686/26050 (epoch 8.994), train_loss = 1.36493946, grad/param norm = 1.8016e-01, time/batch = 0.6522s	
4687/26050 (epoch 8.996), train_loss = 1.32923338, grad/param norm = 2.0293e-01, time/batch = 0.6507s	
4688/26050 (epoch 8.998), train_loss = 1.37273494, grad/param norm = 1.8802e-01, time/batch = 0.6426s	
4689/26050 (epoch 9.000), train_loss = 1.31864029, grad/param norm = 1.8186e-01, time/batch = 0.6437s	
4690/26050 (epoch 9.002), train_loss = 1.39242484, grad/param norm = 1.8068e-01, time/batch = 0.6423s	
4691/26050 (epoch 9.004), train_loss = 1.26834903, grad/param norm = 1.8822e-01, time/batch = 0.6419s	
4692/26050 (epoch 9.006), train_loss = 1.27677647, grad/param norm = 1.6754e-01, time/batch = 0.6576s	
4693/26050 (epoch 9.008), train_loss = 1.24821038, grad/param norm = 1.7796e-01, time/batch = 0.6617s	
4694/26050 (epoch 9.010), train_loss = 1.30323541, grad/param norm = 1.6827e-01, time/batch = 0.6407s	
4695/26050 (epoch 9.012), train_loss = 1.38573324, grad/param norm = 1.8298e-01, time/batch = 0.6408s	
4696/26050 (epoch 9.013), train_loss = 1.77782131, grad/param norm = 2.0529e-01, time/batch = 0.6421s	
4697/26050 (epoch 9.015), train_loss = 1.23464024, grad/param norm = 1.6484e-01, time/batch = 0.6409s	
4698/26050 (epoch 9.017), train_loss = 1.38485708, grad/param norm = 1.8186e-01, time/batch = 0.6408s	
4699/26050 (epoch 9.019), train_loss = 1.15158041, grad/param norm = 1.4946e-01, time/batch = 0.6407s	
4700/26050 (epoch 9.021), train_loss = 1.47060834, grad/param norm = 1.9354e-01, time/batch = 0.6466s	
4701/26050 (epoch 9.023), train_loss = 1.18588374, grad/param norm = 1.6690e-01, time/batch = 0.6419s	
4702/26050 (epoch 9.025), train_loss = 1.29953897, grad/param norm = 1.7684e-01, time/batch = 0.6392s	
4703/26050 (epoch 9.027), train_loss = 1.10786793, grad/param norm = 1.6362e-01, time/batch = 0.6398s	
4704/26050 (epoch 9.029), train_loss = 1.29551259, grad/param norm = 1.6004e-01, time/batch = 0.6428s	
4705/26050 (epoch 9.031), train_loss = 1.53425963, grad/param norm = 2.0259e-01, time/batch = 0.6436s	
4706/26050 (epoch 9.033), train_loss = 1.39400798, grad/param norm = 1.8554e-01, time/batch = 0.6412s	
4707/26050 (epoch 9.035), train_loss = 1.47571301, grad/param norm = 1.7730e-01, time/batch = 0.6413s	
4708/26050 (epoch 9.036), train_loss = 1.27994025, grad/param norm = 1.9884e-01, time/batch = 0.6413s	
4709/26050 (epoch 9.038), train_loss = 1.15582037, grad/param norm = 1.7002e-01, time/batch = 0.6400s	
4710/26050 (epoch 9.040), train_loss = 1.40435992, grad/param norm = 1.7854e-01, time/batch = 0.6403s	
4711/26050 (epoch 9.042), train_loss = 1.21357348, grad/param norm = 1.7673e-01, time/batch = 0.6441s	
4712/26050 (epoch 9.044), train_loss = 1.41025130, grad/param norm = 1.8840e-01, time/batch = 0.6456s	
4713/26050 (epoch 9.046), train_loss = 1.14220193, grad/param norm = 1.8362e-01, time/batch = 0.6434s	
4714/26050 (epoch 9.048), train_loss = 1.37418821, grad/param norm = 1.8163e-01, time/batch = 0.6396s	
4715/26050 (epoch 9.050), train_loss = 1.23052883, grad/param norm = 1.8945e-01, time/batch = 0.6416s	
4716/26050 (epoch 9.052), train_loss = 1.32521850, grad/param norm = 1.7574e-01, time/batch = 0.6425s	
4717/26050 (epoch 9.054), train_loss = 1.16436197, grad/param norm = 1.6426e-01, time/batch = 0.6401s	
4718/26050 (epoch 9.056), train_loss = 1.05314936, grad/param norm = 1.4381e-01, time/batch = 0.6451s	
4719/26050 (epoch 9.058), train_loss = 1.24917555, grad/param norm = 1.6532e-01, time/batch = 0.6740s	
4720/26050 (epoch 9.060), train_loss = 1.32877688, grad/param norm = 1.6539e-01, time/batch = 0.6657s	
4721/26050 (epoch 9.061), train_loss = 1.22131521, grad/param norm = 1.7016e-01, time/batch = 0.6625s	
4722/26050 (epoch 9.063), train_loss = 1.30877739, grad/param norm = 1.6576e-01, time/batch = 0.6567s	
4723/26050 (epoch 9.065), train_loss = 1.14655499, grad/param norm = 1.6472e-01, time/batch = 0.6796s	
4724/26050 (epoch 9.067), train_loss = 1.41249790, grad/param norm = 1.9340e-01, time/batch = 0.6731s	
4725/26050 (epoch 9.069), train_loss = 1.39393050, grad/param norm = 1.6918e-01, time/batch = 0.6614s	
4726/26050 (epoch 9.071), train_loss = 1.41091668, grad/param norm = 1.9089e-01, time/batch = 0.6673s	
4727/26050 (epoch 9.073), train_loss = 1.55788714, grad/param norm = 1.7497e-01, time/batch = 0.6719s	
4728/26050 (epoch 9.075), train_loss = 1.23040389, grad/param norm = 1.7192e-01, time/batch = 0.6688s	
4729/26050 (epoch 9.077), train_loss = 1.23537837, grad/param norm = 1.7019e-01, time/batch = 0.6656s	
4730/26050 (epoch 9.079), train_loss = 1.40294392, grad/param norm = 1.9436e-01, time/batch = 0.6666s	
4731/26050 (epoch 9.081), train_loss = 1.28992370, grad/param norm = 1.8448e-01, time/batch = 0.6554s	
4732/26050 (epoch 9.083), train_loss = 1.42592720, grad/param norm = 1.8404e-01, time/batch = 0.6568s	
4733/26050 (epoch 9.084), train_loss = 1.46881135, grad/param norm = 2.1010e-01, time/batch = 0.6579s	
4734/26050 (epoch 9.086), train_loss = 1.47406611, grad/param norm = 1.8532e-01, time/batch = 0.6572s	
4735/26050 (epoch 9.088), train_loss = 1.20132698, grad/param norm = 1.6070e-01, time/batch = 0.6530s	
4736/26050 (epoch 9.090), train_loss = 1.42168502, grad/param norm = 1.8262e-01, time/batch = 0.6561s	
4737/26050 (epoch 9.092), train_loss = 1.35088165, grad/param norm = 1.8661e-01, time/batch = 0.6519s	
4738/26050 (epoch 9.094), train_loss = 1.32264257, grad/param norm = 1.7480e-01, time/batch = 0.6543s	
4739/26050 (epoch 9.096), train_loss = 1.27743224, grad/param norm = 1.7174e-01, time/batch = 0.6665s	
4740/26050 (epoch 9.098), train_loss = 1.27609470, grad/param norm = 1.7571e-01, time/batch = 0.6743s	
4741/26050 (epoch 9.100), train_loss = 1.22710357, grad/param norm = 1.8129e-01, time/batch = 0.6544s	
4742/26050 (epoch 9.102), train_loss = 1.36929321, grad/param norm = 1.8204e-01, time/batch = 0.6504s	
4743/26050 (epoch 9.104), train_loss = 1.37381663, grad/param norm = 1.7741e-01, time/batch = 0.6501s	
4744/26050 (epoch 9.106), train_loss = 1.29568550, grad/param norm = 1.7225e-01, time/batch = 0.6403s	
4745/26050 (epoch 9.107), train_loss = 1.08310189, grad/param norm = 1.7113e-01, time/batch = 0.6410s	
4746/26050 (epoch 9.109), train_loss = 1.25031819, grad/param norm = 1.7498e-01, time/batch = 0.6412s	
4747/26050 (epoch 9.111), train_loss = 1.55589608, grad/param norm = 2.0396e-01, time/batch = 0.6427s	
4748/26050 (epoch 9.113), train_loss = 1.26265056, grad/param norm = 1.8216e-01, time/batch = 0.6400s	
4749/26050 (epoch 9.115), train_loss = 1.44774847, grad/param norm = 1.8134e-01, time/batch = 0.6499s	
4750/26050 (epoch 9.117), train_loss = 1.39207127, grad/param norm = 1.8397e-01, time/batch = 0.6601s	
4751/26050 (epoch 9.119), train_loss = 1.10831603, grad/param norm = 1.6226e-01, time/batch = 0.6529s	
4752/26050 (epoch 9.121), train_loss = 1.39899796, grad/param norm = 1.7858e-01, time/batch = 0.6537s	
4753/26050 (epoch 9.123), train_loss = 1.25522784, grad/param norm = 1.9245e-01, time/batch = 0.6493s	
4754/26050 (epoch 9.125), train_loss = 1.12671138, grad/param norm = 1.5183e-01, time/batch = 0.6384s	
4755/26050 (epoch 9.127), train_loss = 1.09686837, grad/param norm = 1.6454e-01, time/batch = 0.6436s	
4756/26050 (epoch 9.129), train_loss = 1.10842362, grad/param norm = 1.5636e-01, time/batch = 0.6427s	
4757/26050 (epoch 9.131), train_loss = 1.31051170, grad/param norm = 1.8256e-01, time/batch = 0.6439s	
4758/26050 (epoch 9.132), train_loss = 1.26344506, grad/param norm = 1.7242e-01, time/batch = 0.6461s	
4759/26050 (epoch 9.134), train_loss = 1.28435387, grad/param norm = 1.7982e-01, time/batch = 0.6628s	
4760/26050 (epoch 9.136), train_loss = 1.30226166, grad/param norm = 1.7389e-01, time/batch = 0.6462s	
4761/26050 (epoch 9.138), train_loss = 1.14559665, grad/param norm = 1.8634e-01, time/batch = 0.6402s	
4762/26050 (epoch 9.140), train_loss = 1.19030248, grad/param norm = 1.6661e-01, time/batch = 0.6417s	
4763/26050 (epoch 9.142), train_loss = 1.24085176, grad/param norm = 1.7842e-01, time/batch = 0.6387s	
4764/26050 (epoch 9.144), train_loss = 1.12602476, grad/param norm = 1.6172e-01, time/batch = 0.6420s	
4765/26050 (epoch 9.146), train_loss = 1.03923158, grad/param norm = 1.5467e-01, time/batch = 0.6439s	
4766/26050 (epoch 9.148), train_loss = 1.06628135, grad/param norm = 1.4170e-01, time/batch = 0.6397s	
4767/26050 (epoch 9.150), train_loss = 1.29997085, grad/param norm = 2.1014e-01, time/batch = 0.6399s	
4768/26050 (epoch 9.152), train_loss = 1.57581137, grad/param norm = 1.9745e-01, time/batch = 0.6409s	
4769/26050 (epoch 9.154), train_loss = 1.11914342, grad/param norm = 1.8874e-01, time/batch = 0.6570s	
4770/26050 (epoch 9.155), train_loss = 1.12476851, grad/param norm = 1.6064e-01, time/batch = 0.6479s	
4771/26050 (epoch 9.157), train_loss = 1.29597087, grad/param norm = 1.9651e-01, time/batch = 0.6458s	
4772/26050 (epoch 9.159), train_loss = 1.29952229, grad/param norm = 1.7975e-01, time/batch = 0.6402s	
4773/26050 (epoch 9.161), train_loss = 1.48664485, grad/param norm = 2.0899e-01, time/batch = 0.6424s	
4774/26050 (epoch 9.163), train_loss = 1.15614292, grad/param norm = 1.6894e-01, time/batch = 0.6403s	
4775/26050 (epoch 9.165), train_loss = 1.01398167, grad/param norm = 1.5040e-01, time/batch = 0.6439s	
4776/26050 (epoch 9.167), train_loss = 1.42697095, grad/param norm = 2.0641e-01, time/batch = 0.6483s	
4777/26050 (epoch 9.169), train_loss = 1.38211711, grad/param norm = 1.7481e-01, time/batch = 0.6400s	
4778/26050 (epoch 9.171), train_loss = 1.08935026, grad/param norm = 1.4648e-01, time/batch = 0.6374s	
4779/26050 (epoch 9.173), train_loss = 1.25622047, grad/param norm = 1.8104e-01, time/batch = 0.6412s	
4780/26050 (epoch 9.175), train_loss = 1.31665321, grad/param norm = 1.8115e-01, time/batch = 0.6378s	
4781/26050 (epoch 9.177), train_loss = 1.39684693, grad/param norm = 1.7341e-01, time/batch = 0.6478s	
4782/26050 (epoch 9.179), train_loss = 1.01986782, grad/param norm = 1.5389e-01, time/batch = 0.6405s	
4783/26050 (epoch 9.180), train_loss = 1.57165973, grad/param norm = 1.7668e-01, time/batch = 0.6386s	
4784/26050 (epoch 9.182), train_loss = 1.58837213, grad/param norm = 1.9144e-01, time/batch = 0.6407s	
4785/26050 (epoch 9.184), train_loss = 1.32584559, grad/param norm = 1.6970e-01, time/batch = 0.6407s	
4786/26050 (epoch 9.186), train_loss = 1.08308557, grad/param norm = 1.5356e-01, time/batch = 0.6381s	
4787/26050 (epoch 9.188), train_loss = 1.29473972, grad/param norm = 1.6292e-01, time/batch = 0.6397s	
4788/26050 (epoch 9.190), train_loss = 1.35895152, grad/param norm = 1.8100e-01, time/batch = 0.6402s	
4789/26050 (epoch 9.192), train_loss = 1.34823766, grad/param norm = 1.7159e-01, time/batch = 0.6395s	
4790/26050 (epoch 9.194), train_loss = 1.34616285, grad/param norm = 1.7794e-01, time/batch = 0.6388s	
4791/26050 (epoch 9.196), train_loss = 1.41442587, grad/param norm = 1.8950e-01, time/batch = 0.6394s	
4792/26050 (epoch 9.198), train_loss = 1.24336532, grad/param norm = 1.7816e-01, time/batch = 0.6392s	
4793/26050 (epoch 9.200), train_loss = 1.22928656, grad/param norm = 1.8350e-01, time/batch = 0.6395s	
4794/26050 (epoch 9.202), train_loss = 1.23582185, grad/param norm = 1.7805e-01, time/batch = 0.6381s	
4795/26050 (epoch 9.203), train_loss = 1.39164651, grad/param norm = 1.8853e-01, time/batch = 0.6388s	
4796/26050 (epoch 9.205), train_loss = 1.20318544, grad/param norm = 1.6454e-01, time/batch = 0.6386s	
4797/26050 (epoch 9.207), train_loss = 1.29573272, grad/param norm = 1.6861e-01, time/batch = 0.6471s	
4798/26050 (epoch 9.209), train_loss = 1.29657966, grad/param norm = 1.7505e-01, time/batch = 0.6410s	
4799/26050 (epoch 9.211), train_loss = 1.14544253, grad/param norm = 1.6299e-01, time/batch = 0.6443s	
4800/26050 (epoch 9.213), train_loss = 1.34737681, grad/param norm = 1.6873e-01, time/batch = 0.6402s	
4801/26050 (epoch 9.215), train_loss = 1.35157736, grad/param norm = 1.9695e-01, time/batch = 0.6408s	
4802/26050 (epoch 9.217), train_loss = 1.26257418, grad/param norm = 1.7066e-01, time/batch = 0.6418s	
4803/26050 (epoch 9.219), train_loss = 1.23441474, grad/param norm = 1.8418e-01, time/batch = 0.6558s	
4804/26050 (epoch 9.221), train_loss = 1.16140317, grad/param norm = 1.6825e-01, time/batch = 0.6481s	
4805/26050 (epoch 9.223), train_loss = 1.36338452, grad/param norm = 1.8522e-01, time/batch = 0.6430s	
4806/26050 (epoch 9.225), train_loss = 1.20488237, grad/param norm = 1.8562e-01, time/batch = 0.6398s	
4807/26050 (epoch 9.226), train_loss = 1.44996514, grad/param norm = 1.8545e-01, time/batch = 0.6416s	
4808/26050 (epoch 9.228), train_loss = 1.45784012, grad/param norm = 1.8598e-01, time/batch = 0.6396s	
4809/26050 (epoch 9.230), train_loss = 1.35193101, grad/param norm = 1.8001e-01, time/batch = 0.6412s	
4810/26050 (epoch 9.232), train_loss = 1.43953888, grad/param norm = 1.9420e-01, time/batch = 0.6399s	
4811/26050 (epoch 9.234), train_loss = 1.14145600, grad/param norm = 1.7885e-01, time/batch = 0.6474s	
4812/26050 (epoch 9.236), train_loss = 1.38401807, grad/param norm = 1.9544e-01, time/batch = 0.6418s	
4813/26050 (epoch 9.238), train_loss = 1.12340535, grad/param norm = 1.7517e-01, time/batch = 0.6404s	
4814/26050 (epoch 9.240), train_loss = 1.26048786, grad/param norm = 1.8471e-01, time/batch = 0.6391s	
4815/26050 (epoch 9.242), train_loss = 1.27538898, grad/param norm = 1.6249e-01, time/batch = 0.6398s	
4816/26050 (epoch 9.244), train_loss = 1.35914777, grad/param norm = 1.9224e-01, time/batch = 0.6458s	
4817/26050 (epoch 9.246), train_loss = 1.22964035, grad/param norm = 1.6507e-01, time/batch = 0.6379s	
4818/26050 (epoch 9.248), train_loss = 1.34614365, grad/param norm = 1.8089e-01, time/batch = 0.6397s	
4819/26050 (epoch 9.250), train_loss = 1.33942513, grad/param norm = 1.9300e-01, time/batch = 0.6397s	
4820/26050 (epoch 9.251), train_loss = 1.20510466, grad/param norm = 1.6716e-01, time/batch = 0.6400s	
4821/26050 (epoch 9.253), train_loss = 1.11953863, grad/param norm = 1.7371e-01, time/batch = 0.6415s	
4822/26050 (epoch 9.255), train_loss = 1.54096766, grad/param norm = 1.8824e-01, time/batch = 0.6397s	
4823/26050 (epoch 9.257), train_loss = 1.31134951, grad/param norm = 1.9767e-01, time/batch = 0.6386s	
4824/26050 (epoch 9.259), train_loss = 1.45634041, grad/param norm = 1.7951e-01, time/batch = 0.6400s	
4825/26050 (epoch 9.261), train_loss = 1.24219207, grad/param norm = 1.8624e-01, time/batch = 0.6401s	
4826/26050 (epoch 9.263), train_loss = 1.30610641, grad/param norm = 1.7594e-01, time/batch = 0.6388s	
4827/26050 (epoch 9.265), train_loss = 1.49127980, grad/param norm = 1.7567e-01, time/batch = 0.6406s	
4828/26050 (epoch 9.267), train_loss = 1.38628383, grad/param norm = 1.8716e-01, time/batch = 0.6407s	
4829/26050 (epoch 9.269), train_loss = 1.50875509, grad/param norm = 1.9743e-01, time/batch = 0.6392s	
4830/26050 (epoch 9.271), train_loss = 1.34761478, grad/param norm = 1.8177e-01, time/batch = 0.6389s	
4831/26050 (epoch 9.273), train_loss = 1.26145319, grad/param norm = 1.7153e-01, time/batch = 0.6838s	
4832/26050 (epoch 9.274), train_loss = 1.25825634, grad/param norm = 1.7736e-01, time/batch = 0.6624s	
4833/26050 (epoch 9.276), train_loss = 1.23025736, grad/param norm = 1.8079e-01, time/batch = 0.6457s	
4834/26050 (epoch 9.278), train_loss = 1.42064182, grad/param norm = 1.8007e-01, time/batch = 0.6428s	
4835/26050 (epoch 9.280), train_loss = 1.28291402, grad/param norm = 1.6710e-01, time/batch = 0.6408s	
4836/26050 (epoch 9.282), train_loss = 1.36536153, grad/param norm = 1.9366e-01, time/batch = 0.6405s	
4837/26050 (epoch 9.284), train_loss = 1.19837911, grad/param norm = 1.7339e-01, time/batch = 0.6391s	
4838/26050 (epoch 9.286), train_loss = 1.29368914, grad/param norm = 1.8577e-01, time/batch = 0.6398s	
4839/26050 (epoch 9.288), train_loss = 1.12311507, grad/param norm = 1.5226e-01, time/batch = 0.6389s	
4840/26050 (epoch 9.290), train_loss = 1.28240378, grad/param norm = 1.8223e-01, time/batch = 0.6395s	
4841/26050 (epoch 9.292), train_loss = 1.23265847, grad/param norm = 1.6981e-01, time/batch = 0.6409s	
4842/26050 (epoch 9.294), train_loss = 1.32226569, grad/param norm = 1.8925e-01, time/batch = 0.6493s	
4843/26050 (epoch 9.296), train_loss = 1.42952996, grad/param norm = 1.8359e-01, time/batch = 0.6556s	
4844/26050 (epoch 9.298), train_loss = 1.29395124, grad/param norm = 1.6932e-01, time/batch = 0.6481s	
4845/26050 (epoch 9.299), train_loss = 1.05187788, grad/param norm = 1.4692e-01, time/batch = 0.6492s	
4846/26050 (epoch 9.301), train_loss = 1.23851928, grad/param norm = 1.8105e-01, time/batch = 0.6535s	
4847/26050 (epoch 9.303), train_loss = 1.35256028, grad/param norm = 1.7648e-01, time/batch = 0.6582s	
4848/26050 (epoch 9.305), train_loss = 1.13518111, grad/param norm = 1.6397e-01, time/batch = 0.6395s	
4849/26050 (epoch 9.307), train_loss = 1.19555544, grad/param norm = 1.7655e-01, time/batch = 0.6412s	
4850/26050 (epoch 9.309), train_loss = 1.27358821, grad/param norm = 1.8202e-01, time/batch = 0.6451s	
4851/26050 (epoch 9.311), train_loss = 1.49115028, grad/param norm = 2.0572e-01, time/batch = 0.6443s	
4852/26050 (epoch 9.313), train_loss = 1.30440593, grad/param norm = 1.8868e-01, time/batch = 0.6422s	
4853/26050 (epoch 9.315), train_loss = 1.44590977, grad/param norm = 1.8902e-01, time/batch = 0.6411s	
4854/26050 (epoch 9.317), train_loss = 1.24005021, grad/param norm = 1.7161e-01, time/batch = 0.6390s	
4855/26050 (epoch 9.319), train_loss = 1.26278000, grad/param norm = 1.6012e-01, time/batch = 0.6414s	
4856/26050 (epoch 9.321), train_loss = 1.26777993, grad/param norm = 1.7849e-01, time/batch = 0.6395s	
4857/26050 (epoch 9.322), train_loss = 1.32514779, grad/param norm = 1.7038e-01, time/batch = 0.6411s	
4858/26050 (epoch 9.324), train_loss = 1.11147139, grad/param norm = 1.7307e-01, time/batch = 0.6651s	
4859/26050 (epoch 9.326), train_loss = 1.45454381, grad/param norm = 1.8908e-01, time/batch = 0.6561s	
4860/26050 (epoch 9.328), train_loss = 1.34505872, grad/param norm = 1.7386e-01, time/batch = 0.6437s	
4861/26050 (epoch 9.330), train_loss = 1.19148911, grad/param norm = 1.7273e-01, time/batch = 0.6512s	
4862/26050 (epoch 9.332), train_loss = 1.40021035, grad/param norm = 1.8125e-01, time/batch = 0.6834s	
4863/26050 (epoch 9.334), train_loss = 1.28165280, grad/param norm = 1.7553e-01, time/batch = 0.6510s	
4864/26050 (epoch 9.336), train_loss = 1.18805201, grad/param norm = 1.5688e-01, time/batch = 0.6421s	
4865/26050 (epoch 9.338), train_loss = 1.15868098, grad/param norm = 1.5812e-01, time/batch = 0.6421s	
4866/26050 (epoch 9.340), train_loss = 1.40236212, grad/param norm = 1.9476e-01, time/batch = 0.6429s	
4867/26050 (epoch 9.342), train_loss = 1.45222185, grad/param norm = 1.8264e-01, time/batch = 0.6416s	
4868/26050 (epoch 9.344), train_loss = 1.29284354, grad/param norm = 1.8626e-01, time/batch = 0.6393s	
4869/26050 (epoch 9.345), train_loss = 1.30957676, grad/param norm = 1.9682e-01, time/batch = 0.6409s	
4870/26050 (epoch 9.347), train_loss = 1.38118035, grad/param norm = 1.8753e-01, time/batch = 0.6402s	
4871/26050 (epoch 9.349), train_loss = 1.33539559, grad/param norm = 1.8921e-01, time/batch = 0.6406s	
4872/26050 (epoch 9.351), train_loss = 1.34760038, grad/param norm = 1.9591e-01, time/batch = 0.6463s	
4873/26050 (epoch 9.353), train_loss = 1.24366268, grad/param norm = 1.8130e-01, time/batch = 0.6403s	
4874/26050 (epoch 9.355), train_loss = 1.40060642, grad/param norm = 1.9109e-01, time/batch = 0.6451s	
4875/26050 (epoch 9.357), train_loss = 1.16524040, grad/param norm = 1.6446e-01, time/batch = 0.6403s	
4876/26050 (epoch 9.359), train_loss = 1.40135890, grad/param norm = 1.8516e-01, time/batch = 0.6412s	
4877/26050 (epoch 9.361), train_loss = 1.22526806, grad/param norm = 1.7441e-01, time/batch = 0.6753s	
4878/26050 (epoch 9.363), train_loss = 1.34372974, grad/param norm = 1.7571e-01, time/batch = 0.6730s	
4879/26050 (epoch 9.365), train_loss = 1.23339637, grad/param norm = 1.6015e-01, time/batch = 0.6448s	
4880/26050 (epoch 9.367), train_loss = 1.29866546, grad/param norm = 1.7126e-01, time/batch = 0.6462s	
4881/26050 (epoch 9.369), train_loss = 1.26460089, grad/param norm = 1.6119e-01, time/batch = 0.6414s	
4882/26050 (epoch 9.370), train_loss = 1.18338537, grad/param norm = 1.5808e-01, time/batch = 0.6416s	
4883/26050 (epoch 9.372), train_loss = 1.40928370, grad/param norm = 1.9115e-01, time/batch = 0.6409s	
4884/26050 (epoch 9.374), train_loss = 1.51175128, grad/param norm = 1.8929e-01, time/batch = 0.6490s	
4885/26050 (epoch 9.376), train_loss = 1.54525419, grad/param norm = 1.8605e-01, time/batch = 0.6442s	
4886/26050 (epoch 9.378), train_loss = 1.28347383, grad/param norm = 1.8039e-01, time/batch = 0.6401s	
4887/26050 (epoch 9.380), train_loss = 1.51421061, grad/param norm = 1.9093e-01, time/batch = 0.6464s	
4888/26050 (epoch 9.382), train_loss = 1.65027398, grad/param norm = 2.1643e-01, time/batch = 0.6477s	
4889/26050 (epoch 9.384), train_loss = 1.27840765, grad/param norm = 1.7127e-01, time/batch = 0.6425s	
4890/26050 (epoch 9.386), train_loss = 1.42954765, grad/param norm = 1.8846e-01, time/batch = 0.6479s	
4891/26050 (epoch 9.388), train_loss = 1.34475807, grad/param norm = 1.7617e-01, time/batch = 0.6408s	
4892/26050 (epoch 9.390), train_loss = 1.17146459, grad/param norm = 1.5446e-01, time/batch = 0.6604s	
4893/26050 (epoch 9.392), train_loss = 1.19234136, grad/param norm = 1.6405e-01, time/batch = 0.6828s	
4894/26050 (epoch 9.393), train_loss = 1.37357014, grad/param norm = 1.7671e-01, time/batch = 0.6389s	
4895/26050 (epoch 9.395), train_loss = 1.38031348, grad/param norm = 1.7638e-01, time/batch = 0.6408s	
4896/26050 (epoch 9.397), train_loss = 1.37164129, grad/param norm = 1.9524e-01, time/batch = 0.6418s	
4897/26050 (epoch 9.399), train_loss = 1.17294556, grad/param norm = 1.5422e-01, time/batch = 0.6415s	
4898/26050 (epoch 9.401), train_loss = 1.25300363, grad/param norm = 1.6155e-01, time/batch = 0.6435s	
4899/26050 (epoch 9.403), train_loss = 1.31801743, grad/param norm = 1.7072e-01, time/batch = 0.6472s	
4900/26050 (epoch 9.405), train_loss = 1.31386314, grad/param norm = 1.8102e-01, time/batch = 0.6417s	
4901/26050 (epoch 9.407), train_loss = 1.46628061, grad/param norm = 1.8930e-01, time/batch = 0.6424s	
4902/26050 (epoch 9.409), train_loss = 1.50110885, grad/param norm = 1.9569e-01, time/batch = 0.6396s	
4903/26050 (epoch 9.411), train_loss = 1.36232163, grad/param norm = 1.7923e-01, time/batch = 0.6395s	
4904/26050 (epoch 9.413), train_loss = 1.44605605, grad/param norm = 1.7361e-01, time/batch = 0.6467s	
4905/26050 (epoch 9.415), train_loss = 1.44563757, grad/param norm = 1.9407e-01, time/batch = 0.6409s	
4906/26050 (epoch 9.417), train_loss = 1.55093971, grad/param norm = 1.9116e-01, time/batch = 0.6393s	
4907/26050 (epoch 9.418), train_loss = 1.42437377, grad/param norm = 1.9854e-01, time/batch = 0.6404s	
4908/26050 (epoch 9.420), train_loss = 1.11718842, grad/param norm = 1.5746e-01, time/batch = 0.6707s	
4909/26050 (epoch 9.422), train_loss = 1.17498240, grad/param norm = 1.7271e-01, time/batch = 0.6423s	
4910/26050 (epoch 9.424), train_loss = 1.52820441, grad/param norm = 2.1462e-01, time/batch = 0.6392s	
4911/26050 (epoch 9.426), train_loss = 1.47924289, grad/param norm = 1.9480e-01, time/batch = 0.6406s	
4912/26050 (epoch 9.428), train_loss = 1.21871689, grad/param norm = 1.5658e-01, time/batch = 0.6428s	
4913/26050 (epoch 9.430), train_loss = 1.36616234, grad/param norm = 1.8681e-01, time/batch = 0.6430s	
4914/26050 (epoch 9.432), train_loss = 1.25574564, grad/param norm = 1.7498e-01, time/batch = 0.6406s	
4915/26050 (epoch 9.434), train_loss = 1.32421179, grad/param norm = 1.8531e-01, time/batch = 0.6412s	
4916/26050 (epoch 9.436), train_loss = 1.44434022, grad/param norm = 1.6671e-01, time/batch = 0.6388s	
4917/26050 (epoch 9.438), train_loss = 1.19747441, grad/param norm = 1.6541e-01, time/batch = 0.6404s	
4918/26050 (epoch 9.440), train_loss = 1.35519904, grad/param norm = 1.7291e-01, time/batch = 0.6403s	
4919/26050 (epoch 9.441), train_loss = 1.31684925, grad/param norm = 1.6678e-01, time/batch = 0.6393s	
4920/26050 (epoch 9.443), train_loss = 1.11417912, grad/param norm = 1.5034e-01, time/batch = 0.6461s	
4921/26050 (epoch 9.445), train_loss = 1.18416002, grad/param norm = 1.6689e-01, time/batch = 0.6420s	
4922/26050 (epoch 9.447), train_loss = 1.53382586, grad/param norm = 1.9493e-01, time/batch = 0.6410s	
4923/26050 (epoch 9.449), train_loss = 1.21837319, grad/param norm = 1.7046e-01, time/batch = 0.6415s	
4924/26050 (epoch 9.451), train_loss = 1.42137085, grad/param norm = 1.6565e-01, time/batch = 0.6396s	
4925/26050 (epoch 9.453), train_loss = 1.19166265, grad/param norm = 1.6314e-01, time/batch = 0.6405s	
4926/26050 (epoch 9.455), train_loss = 1.34041118, grad/param norm = 1.7515e-01, time/batch = 0.6521s	
4927/26050 (epoch 9.457), train_loss = 1.33465356, grad/param norm = 1.7394e-01, time/batch = 0.6613s	
4928/26050 (epoch 9.459), train_loss = 1.44233475, grad/param norm = 1.8281e-01, time/batch = 0.6726s	
4929/26050 (epoch 9.461), train_loss = 1.38471703, grad/param norm = 1.8704e-01, time/batch = 0.6703s	
4930/26050 (epoch 9.463), train_loss = 1.24255989, grad/param norm = 1.5945e-01, time/batch = 0.6741s	
4931/26050 (epoch 9.464), train_loss = 1.39711588, grad/param norm = 1.8230e-01, time/batch = 0.6771s	
4932/26050 (epoch 9.466), train_loss = 1.41296647, grad/param norm = 1.8908e-01, time/batch = 0.6773s	
4933/26050 (epoch 9.468), train_loss = 1.41483564, grad/param norm = 1.6495e-01, time/batch = 0.6766s	
4934/26050 (epoch 9.470), train_loss = 1.53470138, grad/param norm = 2.0046e-01, time/batch = 0.6812s	
4935/26050 (epoch 9.472), train_loss = 1.50555753, grad/param norm = 1.8856e-01, time/batch = 0.6676s	
4936/26050 (epoch 9.474), train_loss = 1.58299917, grad/param norm = 1.8562e-01, time/batch = 0.6754s	
4937/26050 (epoch 9.476), train_loss = 1.40719302, grad/param norm = 1.6702e-01, time/batch = 0.6576s	
4938/26050 (epoch 9.478), train_loss = 1.22833172, grad/param norm = 1.5818e-01, time/batch = 0.6657s	
4939/26050 (epoch 9.480), train_loss = 1.33915453, grad/param norm = 1.5954e-01, time/batch = 0.6778s	
4940/26050 (epoch 9.482), train_loss = 1.29400121, grad/param norm = 1.7324e-01, time/batch = 0.6420s	
4941/26050 (epoch 9.484), train_loss = 1.21512583, grad/param norm = 1.7624e-01, time/batch = 0.6504s	
4942/26050 (epoch 9.486), train_loss = 1.49589724, grad/param norm = 1.7566e-01, time/batch = 0.6451s	
4943/26050 (epoch 9.488), train_loss = 1.66939141, grad/param norm = 1.9211e-01, time/batch = 0.6396s	
4944/26050 (epoch 9.489), train_loss = 1.60134796, grad/param norm = 1.9980e-01, time/batch = 0.6406s	
4945/26050 (epoch 9.491), train_loss = 1.23258598, grad/param norm = 1.6934e-01, time/batch = 0.6394s	
4946/26050 (epoch 9.493), train_loss = 1.29034676, grad/param norm = 1.6768e-01, time/batch = 0.6384s	
4947/26050 (epoch 9.495), train_loss = 1.28898071, grad/param norm = 1.6506e-01, time/batch = 0.6431s	
4948/26050 (epoch 9.497), train_loss = 1.27697788, grad/param norm = 1.6966e-01, time/batch = 0.6465s	
4949/26050 (epoch 9.499), train_loss = 1.28686009, grad/param norm = 1.7802e-01, time/batch = 0.6419s	
4950/26050 (epoch 9.501), train_loss = 1.37771619, grad/param norm = 1.8206e-01, time/batch = 0.6448s	
4951/26050 (epoch 9.503), train_loss = 1.26292956, grad/param norm = 1.8572e-01, time/batch = 0.6408s	
4952/26050 (epoch 9.505), train_loss = 1.45900359, grad/param norm = 1.7849e-01, time/batch = 0.6400s	
4953/26050 (epoch 9.507), train_loss = 1.46686990, grad/param norm = 1.8988e-01, time/batch = 0.6445s	
4954/26050 (epoch 9.509), train_loss = 1.56153733, grad/param norm = 1.9694e-01, time/batch = 0.6618s	
4955/26050 (epoch 9.511), train_loss = 1.23976153, grad/param norm = 1.7598e-01, time/batch = 0.6465s	
4956/26050 (epoch 9.512), train_loss = 1.32057920, grad/param norm = 1.8493e-01, time/batch = 0.6417s	
4957/26050 (epoch 9.514), train_loss = 1.39653052, grad/param norm = 1.7971e-01, time/batch = 0.6417s	
4958/26050 (epoch 9.516), train_loss = 1.44026688, grad/param norm = 1.8151e-01, time/batch = 0.6412s	
4959/26050 (epoch 9.518), train_loss = 1.38899921, grad/param norm = 1.8285e-01, time/batch = 0.6400s	
4960/26050 (epoch 9.520), train_loss = 1.35044516, grad/param norm = 1.7481e-01, time/batch = 0.6546s	
4961/26050 (epoch 9.522), train_loss = 1.15729400, grad/param norm = 1.6528e-01, time/batch = 0.6619s	
4962/26050 (epoch 9.524), train_loss = 1.49891218, grad/param norm = 1.8780e-01, time/batch = 0.6611s	
4963/26050 (epoch 9.526), train_loss = 1.41882394, grad/param norm = 1.8021e-01, time/batch = 0.6558s	
4964/26050 (epoch 9.528), train_loss = 1.39404348, grad/param norm = 1.8139e-01, time/batch = 0.6423s	
4965/26050 (epoch 9.530), train_loss = 1.31256574, grad/param norm = 1.6347e-01, time/batch = 0.6434s	
4966/26050 (epoch 9.532), train_loss = 1.33222599, grad/param norm = 1.7565e-01, time/batch = 0.6480s	
4967/26050 (epoch 9.534), train_loss = 1.42688576, grad/param norm = 1.8367e-01, time/batch = 0.6418s	
4968/26050 (epoch 9.536), train_loss = 1.28399921, grad/param norm = 1.5878e-01, time/batch = 0.6413s	
4969/26050 (epoch 9.537), train_loss = 1.45265456, grad/param norm = 1.8800e-01, time/batch = 0.6749s	
4970/26050 (epoch 9.539), train_loss = 1.32436949, grad/param norm = 1.7020e-01, time/batch = 0.6687s	
4971/26050 (epoch 9.541), train_loss = 1.54502976, grad/param norm = 2.0842e-01, time/batch = 0.6428s	
4972/26050 (epoch 9.543), train_loss = 1.15741600, grad/param norm = 1.6275e-01, time/batch = 0.6428s	
4973/26050 (epoch 9.545), train_loss = 1.40245935, grad/param norm = 1.7908e-01, time/batch = 0.6431s	
4974/26050 (epoch 9.547), train_loss = 1.36210010, grad/param norm = 1.8126e-01, time/batch = 0.6424s	
4975/26050 (epoch 9.549), train_loss = 1.15393608, grad/param norm = 1.7495e-01, time/batch = 0.6414s	
4976/26050 (epoch 9.551), train_loss = 1.38525271, grad/param norm = 1.8618e-01, time/batch = 0.6438s	
4977/26050 (epoch 9.553), train_loss = 1.23017280, grad/param norm = 1.6668e-01, time/batch = 0.6427s	
4978/26050 (epoch 9.555), train_loss = 1.27941305, grad/param norm = 1.6737e-01, time/batch = 0.6420s	
4979/26050 (epoch 9.557), train_loss = 1.39422058, grad/param norm = 1.6870e-01, time/batch = 0.6514s	
4980/26050 (epoch 9.559), train_loss = 1.34222192, grad/param norm = 1.7869e-01, time/batch = 0.6560s	
4981/26050 (epoch 9.560), train_loss = 1.32379108, grad/param norm = 1.8129e-01, time/batch = 0.6620s	
4982/26050 (epoch 9.562), train_loss = 1.30843970, grad/param norm = 1.7659e-01, time/batch = 0.6607s	
4983/26050 (epoch 9.564), train_loss = 1.54239633, grad/param norm = 1.8743e-01, time/batch = 0.6579s	
4984/26050 (epoch 9.566), train_loss = 1.21140052, grad/param norm = 1.6801e-01, time/batch = 0.6722s	
4985/26050 (epoch 9.568), train_loss = 1.34901177, grad/param norm = 1.7544e-01, time/batch = 0.6788s	
4986/26050 (epoch 9.570), train_loss = 1.46330781, grad/param norm = 1.8957e-01, time/batch = 0.6544s	
4987/26050 (epoch 9.572), train_loss = 1.31418724, grad/param norm = 1.6564e-01, time/batch = 0.6555s	
4988/26050 (epoch 9.574), train_loss = 1.42943208, grad/param norm = 2.0424e-01, time/batch = 0.6565s	
4989/26050 (epoch 9.576), train_loss = 1.42143567, grad/param norm = 1.9494e-01, time/batch = 0.6523s	
4990/26050 (epoch 9.578), train_loss = 1.33117923, grad/param norm = 1.8148e-01, time/batch = 0.6558s	
4991/26050 (epoch 9.580), train_loss = 1.21966075, grad/param norm = 1.7254e-01, time/batch = 0.6508s	
4992/26050 (epoch 9.582), train_loss = 1.38782904, grad/param norm = 1.8565e-01, time/batch = 0.6391s	
4993/26050 (epoch 9.583), train_loss = 1.42380298, grad/param norm = 1.8281e-01, time/batch = 0.6392s	
4994/26050 (epoch 9.585), train_loss = 1.22347645, grad/param norm = 1.7854e-01, time/batch = 0.6403s	
4995/26050 (epoch 9.587), train_loss = 1.39806871, grad/param norm = 1.7904e-01, time/batch = 0.6429s	
4996/26050 (epoch 9.589), train_loss = 1.43239371, grad/param norm = 1.9564e-01, time/batch = 0.6410s	
4997/26050 (epoch 9.591), train_loss = 1.37044974, grad/param norm = 1.8775e-01, time/batch = 0.6413s	
4998/26050 (epoch 9.593), train_loss = 1.21125678, grad/param norm = 1.8981e-01, time/batch = 0.6402s	
4999/26050 (epoch 9.595), train_loss = 1.50660304, grad/param norm = 2.1032e-01, time/batch = 0.6492s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch9.60_1.6043.t7	
5000/26050 (epoch 9.597), train_loss = 1.37654598, grad/param norm = 1.8793e-01, time/batch = 0.6793s	
5001/26050 (epoch 9.599), train_loss = 1.49157123, grad/param norm = 1.9802e-01, time/batch = 0.6471s	
5002/26050 (epoch 9.601), train_loss = 1.54874047, grad/param norm = 1.8568e-01, time/batch = 0.6409s	
5003/26050 (epoch 9.603), train_loss = 1.40410242, grad/param norm = 1.8130e-01, time/batch = 0.6414s	
5004/26050 (epoch 9.605), train_loss = 1.26703876, grad/param norm = 1.6926e-01, time/batch = 0.6457s	
5005/26050 (epoch 9.607), train_loss = 1.47695800, grad/param norm = 1.8907e-01, time/batch = 0.6413s	
5006/26050 (epoch 9.608), train_loss = 1.27127001, grad/param norm = 1.6080e-01, time/batch = 0.6457s	
5007/26050 (epoch 9.610), train_loss = 1.30999482, grad/param norm = 1.8017e-01, time/batch = 0.6428s	
5008/26050 (epoch 9.612), train_loss = 1.30209831, grad/param norm = 1.7536e-01, time/batch = 0.6434s	
5009/26050 (epoch 9.614), train_loss = 1.40495085, grad/param norm = 1.7940e-01, time/batch = 0.6450s	
5010/26050 (epoch 9.616), train_loss = 1.60335657, grad/param norm = 1.9181e-01, time/batch = 0.6430s	
5011/26050 (epoch 9.618), train_loss = 1.26260749, grad/param norm = 1.8358e-01, time/batch = 0.6412s	
5012/26050 (epoch 9.620), train_loss = 1.35929746, grad/param norm = 1.8701e-01, time/batch = 0.6415s	
5013/26050 (epoch 9.622), train_loss = 1.11756028, grad/param norm = 1.5887e-01, time/batch = 0.6407s	
5014/26050 (epoch 9.624), train_loss = 1.20779996, grad/param norm = 1.6471e-01, time/batch = 0.6399s	
5015/26050 (epoch 9.626), train_loss = 1.40391988, grad/param norm = 1.8654e-01, time/batch = 0.6391s	
5016/26050 (epoch 9.628), train_loss = 1.30973416, grad/param norm = 1.8989e-01, time/batch = 0.6396s	
5017/26050 (epoch 9.630), train_loss = 1.46438899, grad/param norm = 1.7477e-01, time/batch = 0.6408s	
5018/26050 (epoch 9.631), train_loss = 1.48255797, grad/param norm = 1.8753e-01, time/batch = 0.6408s	
5019/26050 (epoch 9.633), train_loss = 1.24411280, grad/param norm = 1.7466e-01, time/batch = 0.6552s	
5020/26050 (epoch 9.635), train_loss = 1.23033887, grad/param norm = 1.6128e-01, time/batch = 0.6547s	
5021/26050 (epoch 9.637), train_loss = 1.23872174, grad/param norm = 1.7945e-01, time/batch = 0.6697s	
5022/26050 (epoch 9.639), train_loss = 1.43534759, grad/param norm = 1.7372e-01, time/batch = 0.6584s	
5023/26050 (epoch 9.641), train_loss = 1.27046134, grad/param norm = 1.5801e-01, time/batch = 0.6597s	
5024/26050 (epoch 9.643), train_loss = 1.20189051, grad/param norm = 1.5132e-01, time/batch = 0.6590s	
5025/26050 (epoch 9.645), train_loss = 1.37234490, grad/param norm = 2.0174e-01, time/batch = 0.6562s	
5026/26050 (epoch 9.647), train_loss = 1.29083194, grad/param norm = 1.7191e-01, time/batch = 0.6408s	
5027/26050 (epoch 9.649), train_loss = 1.37960659, grad/param norm = 1.9443e-01, time/batch = 0.6409s	
5028/26050 (epoch 9.651), train_loss = 1.26796013, grad/param norm = 1.8160e-01, time/batch = 0.6405s	
5029/26050 (epoch 9.653), train_loss = 1.32712191, grad/param norm = 1.7787e-01, time/batch = 0.6505s	
5030/26050 (epoch 9.655), train_loss = 1.23635769, grad/param norm = 1.7212e-01, time/batch = 0.6600s	
5031/26050 (epoch 9.656), train_loss = 1.19966859, grad/param norm = 1.7382e-01, time/batch = 0.6556s	
5032/26050 (epoch 9.658), train_loss = 1.54059977, grad/param norm = 1.8257e-01, time/batch = 0.6438s	
5033/26050 (epoch 9.660), train_loss = 1.21823832, grad/param norm = 1.9195e-01, time/batch = 0.6577s	
5034/26050 (epoch 9.662), train_loss = 1.19918142, grad/param norm = 1.6183e-01, time/batch = 0.6723s	
5035/26050 (epoch 9.664), train_loss = 1.30336451, grad/param norm = 1.7677e-01, time/batch = 0.6766s	
5036/26050 (epoch 9.666), train_loss = 1.36518569, grad/param norm = 1.9020e-01, time/batch = 0.6616s	
5037/26050 (epoch 9.668), train_loss = 1.10991458, grad/param norm = 1.5800e-01, time/batch = 0.6505s	
5038/26050 (epoch 9.670), train_loss = 1.50825881, grad/param norm = 1.9557e-01, time/batch = 0.6764s	
5039/26050 (epoch 9.672), train_loss = 1.25689758, grad/param norm = 1.7876e-01, time/batch = 0.6767s	
5040/26050 (epoch 9.674), train_loss = 1.21561681, grad/param norm = 1.6087e-01, time/batch = 0.6554s	
5041/26050 (epoch 9.676), train_loss = 1.36650668, grad/param norm = 1.6850e-01, time/batch = 0.6546s	
5042/26050 (epoch 9.678), train_loss = 1.48277086, grad/param norm = 1.8282e-01, time/batch = 0.6424s	
5043/26050 (epoch 9.679), train_loss = 1.54246635, grad/param norm = 1.9727e-01, time/batch = 0.6428s	
5044/26050 (epoch 9.681), train_loss = 1.35413533, grad/param norm = 1.8224e-01, time/batch = 0.6407s	
5045/26050 (epoch 9.683), train_loss = 1.25367488, grad/param norm = 2.0085e-01, time/batch = 0.6424s	
5046/26050 (epoch 9.685), train_loss = 1.26404559, grad/param norm = 1.6209e-01, time/batch = 0.6427s	
5047/26050 (epoch 9.687), train_loss = 1.12659760, grad/param norm = 1.5856e-01, time/batch = 0.6461s	
5048/26050 (epoch 9.689), train_loss = 1.30087639, grad/param norm = 1.7110e-01, time/batch = 0.6449s	
5049/26050 (epoch 9.691), train_loss = 1.05012165, grad/param norm = 1.6549e-01, time/batch = 0.6420s	
5050/26050 (epoch 9.693), train_loss = 1.24485130, grad/param norm = 1.7532e-01, time/batch = 0.6438s	
5051/26050 (epoch 9.695), train_loss = 1.34181212, grad/param norm = 1.7811e-01, time/batch = 0.6463s	
5052/26050 (epoch 9.697), train_loss = 1.20022522, grad/param norm = 1.7214e-01, time/batch = 0.6420s	
5053/26050 (epoch 9.699), train_loss = 1.38755088, grad/param norm = 1.8189e-01, time/batch = 0.6640s	
5054/26050 (epoch 9.701), train_loss = 1.15236917, grad/param norm = 1.5873e-01, time/batch = 0.6801s	
5055/26050 (epoch 9.702), train_loss = 1.54435049, grad/param norm = 1.9289e-01, time/batch = 0.6423s	
5056/26050 (epoch 9.704), train_loss = 1.34668062, grad/param norm = 1.7086e-01, time/batch = 0.6457s	
5057/26050 (epoch 9.706), train_loss = 1.39576890, grad/param norm = 2.0009e-01, time/batch = 0.6442s	
5058/26050 (epoch 9.708), train_loss = 1.39448188, grad/param norm = 1.7494e-01, time/batch = 0.6434s	
5059/26050 (epoch 9.710), train_loss = 1.39291526, grad/param norm = 1.7775e-01, time/batch = 0.6408s	
5060/26050 (epoch 9.712), train_loss = 1.49824382, grad/param norm = 1.8413e-01, time/batch = 0.6409s	
5061/26050 (epoch 9.714), train_loss = 1.18139594, grad/param norm = 1.7812e-01, time/batch = 0.6424s	
5062/26050 (epoch 9.716), train_loss = 1.58875435, grad/param norm = 2.0684e-01, time/batch = 0.6417s	
5063/26050 (epoch 9.718), train_loss = 1.44202566, grad/param norm = 1.8750e-01, time/batch = 0.6411s	
5064/26050 (epoch 9.720), train_loss = 1.25262789, grad/param norm = 1.7148e-01, time/batch = 0.6395s	
5065/26050 (epoch 9.722), train_loss = 1.19825740, grad/param norm = 1.6719e-01, time/batch = 0.6432s	
5066/26050 (epoch 9.724), train_loss = 1.20267672, grad/param norm = 1.7268e-01, time/batch = 0.6401s	
5067/26050 (epoch 9.726), train_loss = 1.43644963, grad/param norm = 1.7701e-01, time/batch = 0.6390s	
5068/26050 (epoch 9.727), train_loss = 1.38942218, grad/param norm = 1.7239e-01, time/batch = 0.6443s	
5069/26050 (epoch 9.729), train_loss = 1.38660593, grad/param norm = 1.8073e-01, time/batch = 0.6826s	
5070/26050 (epoch 9.731), train_loss = 1.33777586, grad/param norm = 1.5981e-01, time/batch = 0.6562s	
5071/26050 (epoch 9.733), train_loss = 1.29843056, grad/param norm = 2.1491e-01, time/batch = 0.6438s	
5072/26050 (epoch 9.735), train_loss = 1.52372065, grad/param norm = 1.8302e-01, time/batch = 0.6472s	
5073/26050 (epoch 9.737), train_loss = 1.33382986, grad/param norm = 1.8184e-01, time/batch = 0.6438s	
5074/26050 (epoch 9.739), train_loss = 1.36185388, grad/param norm = 1.6671e-01, time/batch = 0.6406s	
5075/26050 (epoch 9.741), train_loss = 1.22742583, grad/param norm = 1.6579e-01, time/batch = 0.6440s	
5076/26050 (epoch 9.743), train_loss = 1.40939898, grad/param norm = 2.3930e-01, time/batch = 0.6428s	
5077/26050 (epoch 9.745), train_loss = 1.20186419, grad/param norm = 1.7382e-01, time/batch = 0.6415s	
5078/26050 (epoch 9.747), train_loss = 1.22286317, grad/param norm = 1.7440e-01, time/batch = 0.6422s	
5079/26050 (epoch 9.749), train_loss = 1.45621088, grad/param norm = 1.8859e-01, time/batch = 0.6432s	
5080/26050 (epoch 9.750), train_loss = 1.30108471, grad/param norm = 1.6339e-01, time/batch = 0.6408s	
5081/26050 (epoch 9.752), train_loss = 1.34559928, grad/param norm = 1.8942e-01, time/batch = 0.6521s	
5082/26050 (epoch 9.754), train_loss = 1.32254808, grad/param norm = 1.6799e-01, time/batch = 0.6436s	
5083/26050 (epoch 9.756), train_loss = 1.38032513, grad/param norm = 2.0127e-01, time/batch = 0.6413s	
5084/26050 (epoch 9.758), train_loss = 1.34426180, grad/param norm = 1.7664e-01, time/batch = 0.6710s	
5085/26050 (epoch 9.760), train_loss = 1.42987336, grad/param norm = 1.8473e-01, time/batch = 0.6747s	
5086/26050 (epoch 9.762), train_loss = 1.21953186, grad/param norm = 1.6098e-01, time/batch = 0.6457s	
5087/26050 (epoch 9.764), train_loss = 1.43210872, grad/param norm = 1.9935e-01, time/batch = 0.6429s	
5088/26050 (epoch 9.766), train_loss = 1.42318261, grad/param norm = 1.9309e-01, time/batch = 0.6419s	
5089/26050 (epoch 9.768), train_loss = 1.17980958, grad/param norm = 1.5379e-01, time/batch = 0.6449s	
5090/26050 (epoch 9.770), train_loss = 1.33545519, grad/param norm = 1.8038e-01, time/batch = 0.6438s	
5091/26050 (epoch 9.772), train_loss = 1.31253818, grad/param norm = 1.6704e-01, time/batch = 0.6441s	
5092/26050 (epoch 9.774), train_loss = 1.18288563, grad/param norm = 1.7505e-01, time/batch = 0.6417s	
5093/26050 (epoch 9.775), train_loss = 1.02191967, grad/param norm = 1.5980e-01, time/batch = 0.6427s	
5094/26050 (epoch 9.777), train_loss = 1.24471919, grad/param norm = 1.7512e-01, time/batch = 0.6428s	
5095/26050 (epoch 9.779), train_loss = 1.28776622, grad/param norm = 1.7277e-01, time/batch = 0.6404s	
5096/26050 (epoch 9.781), train_loss = 1.26888403, grad/param norm = 1.6838e-01, time/batch = 0.6441s	
5097/26050 (epoch 9.783), train_loss = 1.23723945, grad/param norm = 1.6764e-01, time/batch = 0.6491s	
5098/26050 (epoch 9.785), train_loss = 1.26871146, grad/param norm = 1.8429e-01, time/batch = 0.6441s	
5099/26050 (epoch 9.787), train_loss = 1.24875734, grad/param norm = 1.7237e-01, time/batch = 0.6577s	
5100/26050 (epoch 9.789), train_loss = 1.30163297, grad/param norm = 1.9350e-01, time/batch = 0.6827s	
5101/26050 (epoch 9.791), train_loss = 1.31956724, grad/param norm = 1.7309e-01, time/batch = 0.6469s	
5102/26050 (epoch 9.793), train_loss = 1.30036377, grad/param norm = 1.7899e-01, time/batch = 0.6444s	
5103/26050 (epoch 9.795), train_loss = 1.12998619, grad/param norm = 1.5621e-01, time/batch = 0.6446s	
5104/26050 (epoch 9.797), train_loss = 1.21698548, grad/param norm = 1.6745e-01, time/batch = 0.6449s	
5105/26050 (epoch 9.798), train_loss = 1.18244816, grad/param norm = 1.7309e-01, time/batch = 0.6439s	
5106/26050 (epoch 9.800), train_loss = 1.16305213, grad/param norm = 1.5134e-01, time/batch = 0.6436s	
5107/26050 (epoch 9.802), train_loss = 1.29178309, grad/param norm = 1.7695e-01, time/batch = 0.6584s	
5108/26050 (epoch 9.804), train_loss = 1.28485268, grad/param norm = 1.6523e-01, time/batch = 0.6586s	
5109/26050 (epoch 9.806), train_loss = 1.43973532, grad/param norm = 1.8971e-01, time/batch = 0.6519s	
5110/26050 (epoch 9.808), train_loss = 1.28361545, grad/param norm = 1.7624e-01, time/batch = 0.6589s	
5111/26050 (epoch 9.810), train_loss = 1.25839856, grad/param norm = 1.7374e-01, time/batch = 0.6771s	
5112/26050 (epoch 9.812), train_loss = 1.18673046, grad/param norm = 1.7810e-01, time/batch = 0.6604s	
5113/26050 (epoch 9.814), train_loss = 1.19778918, grad/param norm = 1.9265e-01, time/batch = 0.6659s	
5114/26050 (epoch 9.816), train_loss = 1.38623304, grad/param norm = 1.8343e-01, time/batch = 0.6658s	
5115/26050 (epoch 9.818), train_loss = 1.49232088, grad/param norm = 2.1266e-01, time/batch = 0.6850s	
5116/26050 (epoch 9.820), train_loss = 1.33186365, grad/param norm = 1.8163e-01, time/batch = 0.6629s	
5117/26050 (epoch 9.821), train_loss = 1.48910248, grad/param norm = 2.1503e-01, time/batch = 0.6496s	
5118/26050 (epoch 9.823), train_loss = 1.52363781, grad/param norm = 1.8827e-01, time/batch = 0.6567s	
5119/26050 (epoch 9.825), train_loss = 1.27286429, grad/param norm = 1.8875e-01, time/batch = 0.6572s	
5120/26050 (epoch 9.827), train_loss = 1.36501518, grad/param norm = 1.8950e-01, time/batch = 0.6651s	
5121/26050 (epoch 9.829), train_loss = 1.37410444, grad/param norm = 1.8036e-01, time/batch = 0.6641s	
5122/26050 (epoch 9.831), train_loss = 1.45830604, grad/param norm = 1.8219e-01, time/batch = 0.6630s	
5123/26050 (epoch 9.833), train_loss = 1.53261401, grad/param norm = 1.8364e-01, time/batch = 0.6635s	
5124/26050 (epoch 9.835), train_loss = 1.55857215, grad/param norm = 1.9010e-01, time/batch = 0.6684s	
5125/26050 (epoch 9.837), train_loss = 1.27452419, grad/param norm = 1.6919e-01, time/batch = 0.6682s	
5126/26050 (epoch 9.839), train_loss = 1.40674024, grad/param norm = 1.9842e-01, time/batch = 0.6569s	
5127/26050 (epoch 9.841), train_loss = 1.44306459, grad/param norm = 1.7771e-01, time/batch = 0.6568s	
5128/26050 (epoch 9.843), train_loss = 1.38253409, grad/param norm = 1.8603e-01, time/batch = 0.6520s	
5129/26050 (epoch 9.845), train_loss = 1.24292580, grad/param norm = 1.6838e-01, time/batch = 0.6476s	
5130/26050 (epoch 9.846), train_loss = 1.47266741, grad/param norm = 1.8580e-01, time/batch = 0.6412s	
5131/26050 (epoch 9.848), train_loss = 1.27595509, grad/param norm = 1.7310e-01, time/batch = 0.6549s	
5132/26050 (epoch 9.850), train_loss = 1.26894763, grad/param norm = 1.7091e-01, time/batch = 0.6588s	
5133/26050 (epoch 9.852), train_loss = 1.29653828, grad/param norm = 1.7892e-01, time/batch = 0.6581s	
5134/26050 (epoch 9.854), train_loss = 1.32803070, grad/param norm = 1.7540e-01, time/batch = 0.6572s	
5135/26050 (epoch 9.856), train_loss = 1.25651474, grad/param norm = 1.8159e-01, time/batch = 0.6633s	
5136/26050 (epoch 9.858), train_loss = 1.19993165, grad/param norm = 1.7969e-01, time/batch = 0.6435s	
5137/26050 (epoch 9.860), train_loss = 1.36765888, grad/param norm = 1.9381e-01, time/batch = 0.6385s	
5138/26050 (epoch 9.862), train_loss = 1.33369076, grad/param norm = 1.8108e-01, time/batch = 0.6428s	
5139/26050 (epoch 9.864), train_loss = 1.30803476, grad/param norm = 1.8284e-01, time/batch = 0.6428s	
5140/26050 (epoch 9.866), train_loss = 1.22995461, grad/param norm = 1.6219e-01, time/batch = 0.6587s	
5141/26050 (epoch 9.868), train_loss = 1.42931134, grad/param norm = 1.9631e-01, time/batch = 0.6842s	
5142/26050 (epoch 9.869), train_loss = 1.18166380, grad/param norm = 1.6135e-01, time/batch = 0.6417s	
5143/26050 (epoch 9.871), train_loss = 1.13742669, grad/param norm = 1.5477e-01, time/batch = 0.6421s	
5144/26050 (epoch 9.873), train_loss = 1.36949775, grad/param norm = 1.7697e-01, time/batch = 0.6388s	
5145/26050 (epoch 9.875), train_loss = 1.29628740, grad/param norm = 1.7702e-01, time/batch = 0.6446s	
5146/26050 (epoch 9.877), train_loss = 1.17514443, grad/param norm = 1.7248e-01, time/batch = 0.6677s	
5147/26050 (epoch 9.879), train_loss = 1.30462936, grad/param norm = 1.6449e-01, time/batch = 0.6400s	
5148/26050 (epoch 9.881), train_loss = 1.47865460, grad/param norm = 1.8748e-01, time/batch = 0.6405s	
5149/26050 (epoch 9.883), train_loss = 1.34732267, grad/param norm = 1.7411e-01, time/batch = 0.6413s	
5150/26050 (epoch 9.885), train_loss = 1.03785717, grad/param norm = 1.5276e-01, time/batch = 0.6409s	
5151/26050 (epoch 9.887), train_loss = 1.36593855, grad/param norm = 1.7777e-01, time/batch = 0.6405s	
5152/26050 (epoch 9.889), train_loss = 1.24791798, grad/param norm = 1.6377e-01, time/batch = 0.6409s	
5153/26050 (epoch 9.891), train_loss = 1.08000313, grad/param norm = 1.5506e-01, time/batch = 0.6406s	
5154/26050 (epoch 9.893), train_loss = 1.05948593, grad/param norm = 1.5298e-01, time/batch = 0.6402s	
5155/26050 (epoch 9.894), train_loss = 1.23798626, grad/param norm = 1.6485e-01, time/batch = 0.6455s	
5156/26050 (epoch 9.896), train_loss = 1.42811842, grad/param norm = 1.7906e-01, time/batch = 0.6830s	
5157/26050 (epoch 9.898), train_loss = 1.25350602, grad/param norm = 1.8911e-01, time/batch = 0.6604s	
5158/26050 (epoch 9.900), train_loss = 1.49642771, grad/param norm = 1.8645e-01, time/batch = 0.6396s	
5159/26050 (epoch 9.902), train_loss = 1.31759775, grad/param norm = 1.7679e-01, time/batch = 0.6386s	
5160/26050 (epoch 9.904), train_loss = 1.26153985, grad/param norm = 1.6129e-01, time/batch = 0.6407s	
5161/26050 (epoch 9.906), train_loss = 1.29090651, grad/param norm = 1.7446e-01, time/batch = 0.6412s	
5162/26050 (epoch 9.908), train_loss = 1.28018937, grad/param norm = 1.7230e-01, time/batch = 0.6417s	
5163/26050 (epoch 9.910), train_loss = 1.20489637, grad/param norm = 1.5503e-01, time/batch = 0.6413s	
5164/26050 (epoch 9.912), train_loss = 1.57723278, grad/param norm = 1.9688e-01, time/batch = 0.6436s	
5165/26050 (epoch 9.914), train_loss = 1.74291556, grad/param norm = 1.9752e-01, time/batch = 0.6416s	
5166/26050 (epoch 9.916), train_loss = 1.46062538, grad/param norm = 1.9676e-01, time/batch = 0.6410s	
5167/26050 (epoch 9.917), train_loss = 1.37650910, grad/param norm = 2.1315e-01, time/batch = 0.6449s	
5168/26050 (epoch 9.919), train_loss = 1.43581500, grad/param norm = 1.8612e-01, time/batch = 0.6401s	
5169/26050 (epoch 9.921), train_loss = 1.25007963, grad/param norm = 2.0509e-01, time/batch = 0.6417s	
5170/26050 (epoch 9.923), train_loss = 1.31986694, grad/param norm = 1.9257e-01, time/batch = 0.6537s	
5171/26050 (epoch 9.925), train_loss = 1.28324134, grad/param norm = 1.7000e-01, time/batch = 0.6462s	
5172/26050 (epoch 9.927), train_loss = 1.17977657, grad/param norm = 1.5225e-01, time/batch = 0.6416s	
5173/26050 (epoch 9.929), train_loss = 1.23398181, grad/param norm = 1.7646e-01, time/batch = 0.6549s	
5174/26050 (epoch 9.931), train_loss = 1.57276846, grad/param norm = 2.1397e-01, time/batch = 0.6391s	
5175/26050 (epoch 9.933), train_loss = 1.26293754, grad/param norm = 1.8182e-01, time/batch = 0.6387s	
5176/26050 (epoch 9.935), train_loss = 1.22829745, grad/param norm = 1.6382e-01, time/batch = 0.6389s	
5177/26050 (epoch 9.937), train_loss = 1.34503900, grad/param norm = 1.6797e-01, time/batch = 0.6479s	
5178/26050 (epoch 9.939), train_loss = 1.19423326, grad/param norm = 1.6279e-01, time/batch = 0.6383s	
5179/26050 (epoch 9.940), train_loss = 1.32227665, grad/param norm = 1.6591e-01, time/batch = 0.6436s	
5180/26050 (epoch 9.942), train_loss = 1.34495566, grad/param norm = 1.9536e-01, time/batch = 0.6394s	
5181/26050 (epoch 9.944), train_loss = 1.27186034, grad/param norm = 1.7361e-01, time/batch = 0.6407s	
5182/26050 (epoch 9.946), train_loss = 1.46372477, grad/param norm = 1.7824e-01, time/batch = 0.6395s	
5183/26050 (epoch 9.948), train_loss = 1.13724775, grad/param norm = 1.9133e-01, time/batch = 0.6395s	
5184/26050 (epoch 9.950), train_loss = 1.28427549, grad/param norm = 1.6942e-01, time/batch = 0.6384s	
5185/26050 (epoch 9.952), train_loss = 1.45894886, grad/param norm = 1.9225e-01, time/batch = 0.6378s	
5186/26050 (epoch 9.954), train_loss = 1.40623053, grad/param norm = 1.7650e-01, time/batch = 0.6409s	
5187/26050 (epoch 9.956), train_loss = 1.36137280, grad/param norm = 1.8178e-01, time/batch = 0.6486s	
5188/26050 (epoch 9.958), train_loss = 1.28271883, grad/param norm = 1.7374e-01, time/batch = 0.6419s	
5189/26050 (epoch 9.960), train_loss = 1.29977916, grad/param norm = 1.7353e-01, time/batch = 0.6426s	
5190/26050 (epoch 9.962), train_loss = 1.22184329, grad/param norm = 1.7103e-01, time/batch = 0.6393s	
5191/26050 (epoch 9.964), train_loss = 1.29636124, grad/param norm = 1.7229e-01, time/batch = 0.6515s	
5192/26050 (epoch 9.965), train_loss = 1.18897230, grad/param norm = 1.7125e-01, time/batch = 0.6606s	
5193/26050 (epoch 9.967), train_loss = 1.64522706, grad/param norm = 1.8444e-01, time/batch = 0.6498s	
5194/26050 (epoch 9.969), train_loss = 1.27251392, grad/param norm = 1.6246e-01, time/batch = 0.6541s	
5195/26050 (epoch 9.971), train_loss = 1.19729144, grad/param norm = 1.6121e-01, time/batch = 0.6425s	
5196/26050 (epoch 9.973), train_loss = 1.27878231, grad/param norm = 1.8717e-01, time/batch = 0.6409s	
5197/26050 (epoch 9.975), train_loss = 1.37099755, grad/param norm = 1.6525e-01, time/batch = 0.6400s	
5198/26050 (epoch 9.977), train_loss = 1.32613387, grad/param norm = 1.5720e-01, time/batch = 0.6399s	
5199/26050 (epoch 9.979), train_loss = 1.14011345, grad/param norm = 1.6762e-01, time/batch = 0.6409s	
5200/26050 (epoch 9.981), train_loss = 1.42014307, grad/param norm = 1.7359e-01, time/batch = 0.6435s	
5201/26050 (epoch 9.983), train_loss = 1.42479040, grad/param norm = 1.8248e-01, time/batch = 0.6424s	
5202/26050 (epoch 9.985), train_loss = 1.34486550, grad/param norm = 1.8590e-01, time/batch = 0.6500s	
5203/26050 (epoch 9.987), train_loss = 1.48016330, grad/param norm = 1.9589e-01, time/batch = 0.6665s	
5204/26050 (epoch 9.988), train_loss = 1.42530025, grad/param norm = 1.8439e-01, time/batch = 0.6484s	
5205/26050 (epoch 9.990), train_loss = 1.22662780, grad/param norm = 1.6377e-01, time/batch = 0.6475s	
5206/26050 (epoch 9.992), train_loss = 1.46476510, grad/param norm = 1.8742e-01, time/batch = 0.6510s	
5207/26050 (epoch 9.994), train_loss = 1.32817488, grad/param norm = 1.7766e-01, time/batch = 0.6830s	
5208/26050 (epoch 9.996), train_loss = 1.28360167, grad/param norm = 1.9971e-01, time/batch = 0.6634s	
5209/26050 (epoch 9.998), train_loss = 1.33009710, grad/param norm = 1.8202e-01, time/batch = 0.6422s	
decayed learning rate by a factor 0.97 to 0.00194	
5210/26050 (epoch 10.000), train_loss = 1.27821630, grad/param norm = 1.7778e-01, time/batch = 0.6489s	
5211/26050 (epoch 10.002), train_loss = 1.36309541, grad/param norm = 1.8583e-01, time/batch = 0.6496s	
5212/26050 (epoch 10.004), train_loss = 1.21566972, grad/param norm = 1.7837e-01, time/batch = 0.6450s	
5213/26050 (epoch 10.006), train_loss = 1.23830254, grad/param norm = 1.6964e-01, time/batch = 0.6415s	
5214/26050 (epoch 10.008), train_loss = 1.21178714, grad/param norm = 1.8321e-01, time/batch = 0.6400s	
5215/26050 (epoch 10.010), train_loss = 1.25341520, grad/param norm = 1.6356e-01, time/batch = 0.6383s	
5216/26050 (epoch 10.012), train_loss = 1.33418054, grad/param norm = 1.7941e-01, time/batch = 0.6390s	
5217/26050 (epoch 10.013), train_loss = 1.73406266, grad/param norm = 2.0769e-01, time/batch = 0.6416s	
5218/26050 (epoch 10.015), train_loss = 1.20373717, grad/param norm = 1.6280e-01, time/batch = 0.6407s	
5219/26050 (epoch 10.017), train_loss = 1.34859634, grad/param norm = 1.7715e-01, time/batch = 0.6430s	
5220/26050 (epoch 10.019), train_loss = 1.11241358, grad/param norm = 1.4737e-01, time/batch = 0.6482s	
5221/26050 (epoch 10.021), train_loss = 1.41887988, grad/param norm = 1.8491e-01, time/batch = 0.6782s	
5222/26050 (epoch 10.023), train_loss = 1.13723467, grad/param norm = 1.6558e-01, time/batch = 0.6676s	
5223/26050 (epoch 10.025), train_loss = 1.26975623, grad/param norm = 1.7563e-01, time/batch = 0.6550s	
5224/26050 (epoch 10.027), train_loss = 1.06477311, grad/param norm = 1.5734e-01, time/batch = 0.6517s	
5225/26050 (epoch 10.029), train_loss = 1.26460894, grad/param norm = 1.5975e-01, time/batch = 0.6487s	
5226/26050 (epoch 10.031), train_loss = 1.47859717, grad/param norm = 1.9892e-01, time/batch = 0.6491s	
5227/26050 (epoch 10.033), train_loss = 1.35625324, grad/param norm = 1.7885e-01, time/batch = 0.6416s	
5228/26050 (epoch 10.035), train_loss = 1.41761951, grad/param norm = 1.7011e-01, time/batch = 0.6413s	
5229/26050 (epoch 10.036), train_loss = 1.22586635, grad/param norm = 1.8842e-01, time/batch = 0.6410s	
5230/26050 (epoch 10.038), train_loss = 1.12282171, grad/param norm = 1.6732e-01, time/batch = 0.6418s	
5231/26050 (epoch 10.040), train_loss = 1.36426943, grad/param norm = 1.8246e-01, time/batch = 0.6417s	
5232/26050 (epoch 10.042), train_loss = 1.17366439, grad/param norm = 1.7862e-01, time/batch = 0.6503s	
5233/26050 (epoch 10.044), train_loss = 1.38119595, grad/param norm = 1.8510e-01, time/batch = 0.6428s	
5234/26050 (epoch 10.046), train_loss = 1.10162313, grad/param norm = 1.7626e-01, time/batch = 0.6500s	
5235/26050 (epoch 10.048), train_loss = 1.34055092, grad/param norm = 1.8372e-01, time/batch = 0.6404s	
5236/26050 (epoch 10.050), train_loss = 1.19659264, grad/param norm = 1.8730e-01, time/batch = 0.6397s	
5237/26050 (epoch 10.052), train_loss = 1.28063673, grad/param norm = 1.7498e-01, time/batch = 0.6611s	
5238/26050 (epoch 10.054), train_loss = 1.12773795, grad/param norm = 1.5953e-01, time/batch = 0.6833s	
5239/26050 (epoch 10.056), train_loss = 1.02200396, grad/param norm = 1.4105e-01, time/batch = 0.6426s	
5240/26050 (epoch 10.058), train_loss = 1.21743741, grad/param norm = 1.6471e-01, time/batch = 0.6445s	
5241/26050 (epoch 10.060), train_loss = 1.29435520, grad/param norm = 1.6203e-01, time/batch = 0.6439s	
5242/26050 (epoch 10.061), train_loss = 1.18176346, grad/param norm = 1.6602e-01, time/batch = 0.6504s	
5243/26050 (epoch 10.063), train_loss = 1.28364649, grad/param norm = 1.6588e-01, time/batch = 0.6430s	
5244/26050 (epoch 10.065), train_loss = 1.10975363, grad/param norm = 1.6501e-01, time/batch = 0.6427s	
5245/26050 (epoch 10.067), train_loss = 1.36655972, grad/param norm = 1.9441e-01, time/batch = 0.6409s	
5246/26050 (epoch 10.069), train_loss = 1.35120802, grad/param norm = 1.6913e-01, time/batch = 0.6422s	
5247/26050 (epoch 10.071), train_loss = 1.36723859, grad/param norm = 1.8480e-01, time/batch = 0.6427s	
5248/26050 (epoch 10.073), train_loss = 1.51052508, grad/param norm = 1.7330e-01, time/batch = 0.6414s	
5249/26050 (epoch 10.075), train_loss = 1.18944944, grad/param norm = 1.5973e-01, time/batch = 0.6464s	
5250/26050 (epoch 10.077), train_loss = 1.18786020, grad/param norm = 1.6560e-01, time/batch = 0.6465s	
5251/26050 (epoch 10.079), train_loss = 1.35964130, grad/param norm = 1.8945e-01, time/batch = 0.6406s	
5252/26050 (epoch 10.081), train_loss = 1.24759222, grad/param norm = 1.7175e-01, time/batch = 0.6409s	
5253/26050 (epoch 10.083), train_loss = 1.38269648, grad/param norm = 1.7730e-01, time/batch = 0.6405s	
5254/26050 (epoch 10.084), train_loss = 1.41115629, grad/param norm = 1.9698e-01, time/batch = 0.6447s	
5255/26050 (epoch 10.086), train_loss = 1.43485538, grad/param norm = 1.8442e-01, time/batch = 0.6401s	
5256/26050 (epoch 10.088), train_loss = 1.17352186, grad/param norm = 1.5882e-01, time/batch = 0.6509s	
5257/26050 (epoch 10.090), train_loss = 1.37660646, grad/param norm = 1.8629e-01, time/batch = 0.6673s	
5258/26050 (epoch 10.092), train_loss = 1.31516896, grad/param norm = 1.7711e-01, time/batch = 0.6836s	
5259/26050 (epoch 10.094), train_loss = 1.28076826, grad/param norm = 1.7521e-01, time/batch = 0.6433s	
5260/26050 (epoch 10.096), train_loss = 1.24804041, grad/param norm = 1.6710e-01, time/batch = 0.6407s	
5261/26050 (epoch 10.098), train_loss = 1.24708190, grad/param norm = 1.7334e-01, time/batch = 0.6481s	
5262/26050 (epoch 10.100), train_loss = 1.18561169, grad/param norm = 1.8095e-01, time/batch = 0.6414s	
5263/26050 (epoch 10.102), train_loss = 1.32967101, grad/param norm = 1.7974e-01, time/batch = 0.6409s	
5264/26050 (epoch 10.104), train_loss = 1.32292074, grad/param norm = 1.7693e-01, time/batch = 0.6408s	
5265/26050 (epoch 10.106), train_loss = 1.26297818, grad/param norm = 1.7185e-01, time/batch = 0.6441s	
5266/26050 (epoch 10.107), train_loss = 1.05193572, grad/param norm = 1.6686e-01, time/batch = 0.6445s	
5267/26050 (epoch 10.109), train_loss = 1.21207219, grad/param norm = 1.7125e-01, time/batch = 0.6413s	
5268/26050 (epoch 10.111), train_loss = 1.50416839, grad/param norm = 2.0031e-01, time/batch = 0.6409s	
5269/26050 (epoch 10.113), train_loss = 1.21486042, grad/param norm = 1.7382e-01, time/batch = 0.6436s	
5270/26050 (epoch 10.115), train_loss = 1.39815021, grad/param norm = 1.8142e-01, time/batch = 0.6422s	
5271/26050 (epoch 10.117), train_loss = 1.35080362, grad/param norm = 1.7956e-01, time/batch = 0.6429s	
5272/26050 (epoch 10.119), train_loss = 1.07247296, grad/param norm = 1.5541e-01, time/batch = 0.6442s	
5273/26050 (epoch 10.121), train_loss = 1.35392515, grad/param norm = 1.7437e-01, time/batch = 0.6829s	
5274/26050 (epoch 10.123), train_loss = 1.20027122, grad/param norm = 1.8226e-01, time/batch = 0.6692s	
5275/26050 (epoch 10.125), train_loss = 1.09450017, grad/param norm = 1.5225e-01, time/batch = 0.6469s	
5276/26050 (epoch 10.127), train_loss = 1.05624917, grad/param norm = 1.6477e-01, time/batch = 0.6433s	
5277/26050 (epoch 10.129), train_loss = 1.07729781, grad/param norm = 1.4966e-01, time/batch = 0.6399s	
5278/26050 (epoch 10.131), train_loss = 1.26261364, grad/param norm = 1.7496e-01, time/batch = 0.6409s	
5279/26050 (epoch 10.132), train_loss = 1.23232499, grad/param norm = 1.6543e-01, time/batch = 0.6441s	
5280/26050 (epoch 10.134), train_loss = 1.24715383, grad/param norm = 1.6897e-01, time/batch = 0.6468s	
5281/26050 (epoch 10.136), train_loss = 1.26822273, grad/param norm = 1.7015e-01, time/batch = 0.6461s	
5282/26050 (epoch 10.138), train_loss = 1.08726093, grad/param norm = 1.7821e-01, time/batch = 0.6439s	
5283/26050 (epoch 10.140), train_loss = 1.14420610, grad/param norm = 1.6455e-01, time/batch = 0.6434s	
5284/26050 (epoch 10.142), train_loss = 1.19494571, grad/param norm = 1.7407e-01, time/batch = 0.6431s	
5285/26050 (epoch 10.144), train_loss = 1.09313769, grad/param norm = 1.5925e-01, time/batch = 0.6509s	
5286/26050 (epoch 10.146), train_loss = 0.99818496, grad/param norm = 1.5388e-01, time/batch = 0.6505s	
5287/26050 (epoch 10.148), train_loss = 1.02569032, grad/param norm = 1.3622e-01, time/batch = 0.6476s	
5288/26050 (epoch 10.150), train_loss = 1.25495111, grad/param norm = 1.9308e-01, time/batch = 0.6748s	
5289/26050 (epoch 10.152), train_loss = 1.52142618, grad/param norm = 1.9708e-01, time/batch = 0.6733s	
5290/26050 (epoch 10.154), train_loss = 1.07866319, grad/param norm = 1.7517e-01, time/batch = 0.6403s	
5291/26050 (epoch 10.155), train_loss = 1.09075245, grad/param norm = 1.5897e-01, time/batch = 0.6417s	
5292/26050 (epoch 10.157), train_loss = 1.24451151, grad/param norm = 1.8942e-01, time/batch = 0.6424s	
5293/26050 (epoch 10.159), train_loss = 1.25125619, grad/param norm = 1.8067e-01, time/batch = 0.6406s	
5294/26050 (epoch 10.161), train_loss = 1.42492376, grad/param norm = 1.9523e-01, time/batch = 0.6417s	
5295/26050 (epoch 10.163), train_loss = 1.11731869, grad/param norm = 1.7647e-01, time/batch = 0.6585s	
5296/26050 (epoch 10.165), train_loss = 0.97336329, grad/param norm = 1.4851e-01, time/batch = 0.6487s	
5297/26050 (epoch 10.167), train_loss = 1.38028501, grad/param norm = 1.9651e-01, time/batch = 0.6508s	
5298/26050 (epoch 10.169), train_loss = 1.34522611, grad/param norm = 1.7656e-01, time/batch = 0.6427s	
5299/26050 (epoch 10.171), train_loss = 1.04821808, grad/param norm = 1.4451e-01, time/batch = 0.6831s	
5300/26050 (epoch 10.173), train_loss = 1.20697065, grad/param norm = 1.7540e-01, time/batch = 0.6681s	
5301/26050 (epoch 10.175), train_loss = 1.28401538, grad/param norm = 1.7957e-01, time/batch = 0.6565s	
5302/26050 (epoch 10.177), train_loss = 1.35630532, grad/param norm = 1.7073e-01, time/batch = 0.6419s	
5303/26050 (epoch 10.179), train_loss = 0.99835700, grad/param norm = 1.5666e-01, time/batch = 0.6543s	
5304/26050 (epoch 10.180), train_loss = 1.53898949, grad/param norm = 1.7985e-01, time/batch = 0.6817s	
5305/26050 (epoch 10.182), train_loss = 1.54364074, grad/param norm = 1.9027e-01, time/batch = 0.6406s	
5306/26050 (epoch 10.184), train_loss = 1.28616267, grad/param norm = 1.6751e-01, time/batch = 0.6382s	
5307/26050 (epoch 10.186), train_loss = 1.05424200, grad/param norm = 1.5434e-01, time/batch = 0.6415s	
5308/26050 (epoch 10.188), train_loss = 1.26716374, grad/param norm = 1.6267e-01, time/batch = 0.6371s	
5309/26050 (epoch 10.190), train_loss = 1.31956250, grad/param norm = 1.7650e-01, time/batch = 0.6396s	
5310/26050 (epoch 10.192), train_loss = 1.31248540, grad/param norm = 1.7188e-01, time/batch = 0.6440s	
5311/26050 (epoch 10.194), train_loss = 1.30637874, grad/param norm = 1.7297e-01, time/batch = 0.6454s	
5312/26050 (epoch 10.196), train_loss = 1.37185234, grad/param norm = 1.9129e-01, time/batch = 0.6577s	
5313/26050 (epoch 10.198), train_loss = 1.20146945, grad/param norm = 1.6829e-01, time/batch = 0.6393s	
5314/26050 (epoch 10.200), train_loss = 1.18702868, grad/param norm = 1.7368e-01, time/batch = 0.6703s	
5315/26050 (epoch 10.202), train_loss = 1.20540881, grad/param norm = 1.7379e-01, time/batch = 0.6724s	
5316/26050 (epoch 10.203), train_loss = 1.35661905, grad/param norm = 1.8341e-01, time/batch = 0.6414s	
5317/26050 (epoch 10.205), train_loss = 1.16996086, grad/param norm = 1.6389e-01, time/batch = 0.6386s	
5318/26050 (epoch 10.207), train_loss = 1.25128247, grad/param norm = 1.6783e-01, time/batch = 0.6408s	
5319/26050 (epoch 10.209), train_loss = 1.26382577, grad/param norm = 1.6979e-01, time/batch = 0.6425s	
5320/26050 (epoch 10.211), train_loss = 1.10798419, grad/param norm = 1.7021e-01, time/batch = 0.6406s	
5321/26050 (epoch 10.213), train_loss = 1.31391260, grad/param norm = 1.7275e-01, time/batch = 0.6411s	
5322/26050 (epoch 10.215), train_loss = 1.30270474, grad/param norm = 1.9669e-01, time/batch = 0.6398s	
5323/26050 (epoch 10.217), train_loss = 1.23359624, grad/param norm = 1.6959e-01, time/batch = 0.6462s	
5324/26050 (epoch 10.219), train_loss = 1.19991711, grad/param norm = 1.8300e-01, time/batch = 0.6507s	
5325/26050 (epoch 10.221), train_loss = 1.13621427, grad/param norm = 1.6102e-01, time/batch = 0.6419s	
5326/26050 (epoch 10.223), train_loss = 1.30307260, grad/param norm = 1.7439e-01, time/batch = 0.6458s	
5327/26050 (epoch 10.225), train_loss = 1.16560141, grad/param norm = 1.8301e-01, time/batch = 0.6404s	
5328/26050 (epoch 10.226), train_loss = 1.39515338, grad/param norm = 1.8024e-01, time/batch = 0.6387s	
5329/26050 (epoch 10.228), train_loss = 1.40747720, grad/param norm = 1.8049e-01, time/batch = 0.6387s	
5330/26050 (epoch 10.230), train_loss = 1.31744319, grad/param norm = 1.7783e-01, time/batch = 0.6385s	
5331/26050 (epoch 10.232), train_loss = 1.39200071, grad/param norm = 1.8526e-01, time/batch = 0.6409s	
5332/26050 (epoch 10.234), train_loss = 1.10589089, grad/param norm = 1.6968e-01, time/batch = 0.6426s	
5333/26050 (epoch 10.236), train_loss = 1.35198382, grad/param norm = 1.9053e-01, time/batch = 0.6409s	
5334/26050 (epoch 10.238), train_loss = 1.08801643, grad/param norm = 1.6744e-01, time/batch = 0.6407s	
5335/26050 (epoch 10.240), train_loss = 1.22087723, grad/param norm = 1.6763e-01, time/batch = 0.6526s	
5336/26050 (epoch 10.242), train_loss = 1.24696324, grad/param norm = 1.5958e-01, time/batch = 0.6479s	
5337/26050 (epoch 10.244), train_loss = 1.32278818, grad/param norm = 1.9446e-01, time/batch = 0.6435s	
5338/26050 (epoch 10.246), train_loss = 1.19198657, grad/param norm = 1.6489e-01, time/batch = 0.6382s	
5339/26050 (epoch 10.248), train_loss = 1.29676466, grad/param norm = 1.7202e-01, time/batch = 0.6384s	
5340/26050 (epoch 10.250), train_loss = 1.28951160, grad/param norm = 1.9104e-01, time/batch = 0.6409s	
5341/26050 (epoch 10.251), train_loss = 1.17426179, grad/param norm = 1.6709e-01, time/batch = 0.6412s	
5342/26050 (epoch 10.253), train_loss = 1.08798183, grad/param norm = 1.6634e-01, time/batch = 0.6457s	
5343/26050 (epoch 10.255), train_loss = 1.49833209, grad/param norm = 1.8068e-01, time/batch = 0.6406s	
5344/26050 (epoch 10.257), train_loss = 1.27050428, grad/param norm = 1.9289e-01, time/batch = 0.6407s	
5345/26050 (epoch 10.259), train_loss = 1.41521836, grad/param norm = 1.7388e-01, time/batch = 0.6386s	
5346/26050 (epoch 10.261), train_loss = 1.19360500, grad/param norm = 1.8942e-01, time/batch = 0.6410s	
5347/26050 (epoch 10.263), train_loss = 1.27791636, grad/param norm = 1.7663e-01, time/batch = 0.6548s	
5348/26050 (epoch 10.265), train_loss = 1.45399375, grad/param norm = 1.7825e-01, time/batch = 0.6487s	
5349/26050 (epoch 10.267), train_loss = 1.35569890, grad/param norm = 1.8233e-01, time/batch = 0.6482s	
5350/26050 (epoch 10.269), train_loss = 1.46874335, grad/param norm = 1.9695e-01, time/batch = 0.6826s	
5351/26050 (epoch 10.271), train_loss = 1.32529764, grad/param norm = 1.7633e-01, time/batch = 0.6534s	
5352/26050 (epoch 10.273), train_loss = 1.22267740, grad/param norm = 1.8212e-01, time/batch = 0.6412s	
5353/26050 (epoch 10.274), train_loss = 1.22360492, grad/param norm = 1.7141e-01, time/batch = 0.6416s	
5354/26050 (epoch 10.276), train_loss = 1.19324450, grad/param norm = 1.7813e-01, time/batch = 0.6402s	
5355/26050 (epoch 10.278), train_loss = 1.38538757, grad/param norm = 1.7746e-01, time/batch = 0.6398s	
5356/26050 (epoch 10.280), train_loss = 1.25402049, grad/param norm = 1.6988e-01, time/batch = 0.6432s	
5357/26050 (epoch 10.282), train_loss = 1.32674321, grad/param norm = 1.8954e-01, time/batch = 0.6427s	
5358/26050 (epoch 10.284), train_loss = 1.16379138, grad/param norm = 1.6744e-01, time/batch = 0.6412s	
5359/26050 (epoch 10.286), train_loss = 1.25885923, grad/param norm = 1.7964e-01, time/batch = 0.6396s	
5360/26050 (epoch 10.288), train_loss = 1.08576235, grad/param norm = 1.4781e-01, time/batch = 0.6398s	
5361/26050 (epoch 10.290), train_loss = 1.23871869, grad/param norm = 1.7480e-01, time/batch = 0.6432s	
5362/26050 (epoch 10.292), train_loss = 1.19389707, grad/param norm = 1.7391e-01, time/batch = 0.6411s	
5363/26050 (epoch 10.294), train_loss = 1.29232385, grad/param norm = 1.9615e-01, time/batch = 0.6412s	
5364/26050 (epoch 10.296), train_loss = 1.39718459, grad/param norm = 1.8247e-01, time/batch = 0.6420s	
5365/26050 (epoch 10.298), train_loss = 1.25946794, grad/param norm = 1.6751e-01, time/batch = 0.6715s	
5366/26050 (epoch 10.299), train_loss = 1.01533120, grad/param norm = 1.4438e-01, time/batch = 0.6730s	
5367/26050 (epoch 10.301), train_loss = 1.19690848, grad/param norm = 1.7807e-01, time/batch = 0.6406s	
5368/26050 (epoch 10.303), train_loss = 1.30790838, grad/param norm = 1.7207e-01, time/batch = 0.6402s	
5369/26050 (epoch 10.305), train_loss = 1.09744927, grad/param norm = 1.6302e-01, time/batch = 0.6400s	
5370/26050 (epoch 10.307), train_loss = 1.15464100, grad/param norm = 1.6795e-01, time/batch = 0.6394s	
5371/26050 (epoch 10.309), train_loss = 1.24117262, grad/param norm = 1.8083e-01, time/batch = 0.6573s	
5372/26050 (epoch 10.311), train_loss = 1.43576548, grad/param norm = 2.0019e-01, time/batch = 0.6550s	
5373/26050 (epoch 10.313), train_loss = 1.27132169, grad/param norm = 1.8818e-01, time/batch = 0.6415s	
5374/26050 (epoch 10.315), train_loss = 1.40740036, grad/param norm = 1.8590e-01, time/batch = 0.6390s	
5375/26050 (epoch 10.317), train_loss = 1.21200273, grad/param norm = 1.6772e-01, time/batch = 0.6390s	
5376/26050 (epoch 10.319), train_loss = 1.21572224, grad/param norm = 1.6070e-01, time/batch = 0.6392s	
5377/26050 (epoch 10.321), train_loss = 1.22875833, grad/param norm = 1.7984e-01, time/batch = 0.6393s	
5378/26050 (epoch 10.322), train_loss = 1.29761613, grad/param norm = 1.7321e-01, time/batch = 0.6390s	
5379/26050 (epoch 10.324), train_loss = 1.07960064, grad/param norm = 1.7181e-01, time/batch = 0.6399s	
5380/26050 (epoch 10.326), train_loss = 1.42240705, grad/param norm = 1.8672e-01, time/batch = 0.6527s	
5381/26050 (epoch 10.328), train_loss = 1.31833630, grad/param norm = 1.7376e-01, time/batch = 0.6843s	
5382/26050 (epoch 10.330), train_loss = 1.16063316, grad/param norm = 1.7493e-01, time/batch = 0.6450s	
5383/26050 (epoch 10.332), train_loss = 1.36270082, grad/param norm = 1.8085e-01, time/batch = 0.6413s	
5384/26050 (epoch 10.334), train_loss = 1.23723234, grad/param norm = 1.7355e-01, time/batch = 0.6476s	
5385/26050 (epoch 10.336), train_loss = 1.16297802, grad/param norm = 1.5841e-01, time/batch = 0.6400s	
5386/26050 (epoch 10.338), train_loss = 1.13241206, grad/param norm = 1.5924e-01, time/batch = 0.6405s	
5387/26050 (epoch 10.340), train_loss = 1.36615538, grad/param norm = 1.8867e-01, time/batch = 0.6545s	
5388/26050 (epoch 10.342), train_loss = 1.40966358, grad/param norm = 1.7829e-01, time/batch = 0.6517s	
5389/26050 (epoch 10.344), train_loss = 1.26221390, grad/param norm = 1.8385e-01, time/batch = 0.6435s	
5390/26050 (epoch 10.345), train_loss = 1.25927931, grad/param norm = 1.7974e-01, time/batch = 0.6484s	
5391/26050 (epoch 10.347), train_loss = 1.34897239, grad/param norm = 1.8530e-01, time/batch = 0.6452s	
5392/26050 (epoch 10.349), train_loss = 1.29966411, grad/param norm = 1.8361e-01, time/batch = 0.6409s	
5393/26050 (epoch 10.351), train_loss = 1.30264275, grad/param norm = 1.9166e-01, time/batch = 0.6430s	
5394/26050 (epoch 10.353), train_loss = 1.21494799, grad/param norm = 1.7827e-01, time/batch = 0.6451s	
5395/26050 (epoch 10.355), train_loss = 1.35559808, grad/param norm = 1.8998e-01, time/batch = 0.6411s	
5396/26050 (epoch 10.357), train_loss = 1.12909728, grad/param norm = 1.6436e-01, time/batch = 0.6813s	
5397/26050 (epoch 10.359), train_loss = 1.35642547, grad/param norm = 1.7854e-01, time/batch = 0.6607s	
5398/26050 (epoch 10.361), train_loss = 1.19728668, grad/param norm = 1.7349e-01, time/batch = 0.6389s	
5399/26050 (epoch 10.363), train_loss = 1.31569895, grad/param norm = 1.7082e-01, time/batch = 0.6381s	
5400/26050 (epoch 10.365), train_loss = 1.20742163, grad/param norm = 1.5542e-01, time/batch = 0.6386s	
5401/26050 (epoch 10.367), train_loss = 1.26186331, grad/param norm = 1.7008e-01, time/batch = 0.6416s	
5402/26050 (epoch 10.369), train_loss = 1.23041415, grad/param norm = 1.5838e-01, time/batch = 0.6418s	
5403/26050 (epoch 10.370), train_loss = 1.15238243, grad/param norm = 1.5721e-01, time/batch = 0.6425s	
5404/26050 (epoch 10.372), train_loss = 1.36086797, grad/param norm = 1.8907e-01, time/batch = 0.6387s	
5405/26050 (epoch 10.374), train_loss = 1.46693402, grad/param norm = 1.8508e-01, time/batch = 0.6384s	
5406/26050 (epoch 10.376), train_loss = 1.50133258, grad/param norm = 1.8812e-01, time/batch = 0.6380s	
5407/26050 (epoch 10.378), train_loss = 1.24727885, grad/param norm = 1.7681e-01, time/batch = 0.6405s	
5408/26050 (epoch 10.380), train_loss = 1.48203052, grad/param norm = 1.9697e-01, time/batch = 0.6387s	
5409/26050 (epoch 10.382), train_loss = 1.61254468, grad/param norm = 2.1293e-01, time/batch = 0.6509s	
5410/26050 (epoch 10.384), train_loss = 1.23636352, grad/param norm = 1.6651e-01, time/batch = 0.6469s	
5411/26050 (epoch 10.386), train_loss = 1.38885292, grad/param norm = 1.9390e-01, time/batch = 0.6448s	
5412/26050 (epoch 10.388), train_loss = 1.31232238, grad/param norm = 1.7903e-01, time/batch = 0.6408s	
5413/26050 (epoch 10.390), train_loss = 1.13720780, grad/param norm = 1.5037e-01, time/batch = 0.6513s	
5414/26050 (epoch 10.392), train_loss = 1.15980678, grad/param norm = 1.6052e-01, time/batch = 0.6605s	
5415/26050 (epoch 10.393), train_loss = 1.33458905, grad/param norm = 1.6860e-01, time/batch = 0.6524s	
5416/26050 (epoch 10.395), train_loss = 1.34390753, grad/param norm = 1.7673e-01, time/batch = 0.6383s	
5417/26050 (epoch 10.397), train_loss = 1.33974635, grad/param norm = 1.9872e-01, time/batch = 0.6489s	
5418/26050 (epoch 10.399), train_loss = 1.13690235, grad/param norm = 1.4905e-01, time/batch = 0.6378s	
5419/26050 (epoch 10.401), train_loss = 1.22162374, grad/param norm = 1.5634e-01, time/batch = 0.6425s	
5420/26050 (epoch 10.403), train_loss = 1.27654493, grad/param norm = 1.6133e-01, time/batch = 0.6420s	
5421/26050 (epoch 10.405), train_loss = 1.27186165, grad/param norm = 1.7828e-01, time/batch = 0.6388s	
5422/26050 (epoch 10.407), train_loss = 1.42189851, grad/param norm = 1.8258e-01, time/batch = 0.6449s	
5423/26050 (epoch 10.409), train_loss = 1.46263464, grad/param norm = 1.9546e-01, time/batch = 0.6446s	
5424/26050 (epoch 10.411), train_loss = 1.32222615, grad/param norm = 1.7940e-01, time/batch = 0.6413s	
5425/26050 (epoch 10.413), train_loss = 1.41258560, grad/param norm = 1.6795e-01, time/batch = 0.6399s	
5426/26050 (epoch 10.415), train_loss = 1.40405674, grad/param norm = 1.9024e-01, time/batch = 0.6400s	
5427/26050 (epoch 10.417), train_loss = 1.52228187, grad/param norm = 1.9256e-01, time/batch = 0.6387s	
5428/26050 (epoch 10.418), train_loss = 1.38600630, grad/param norm = 1.9353e-01, time/batch = 0.6380s	
5429/26050 (epoch 10.420), train_loss = 1.09155393, grad/param norm = 1.5285e-01, time/batch = 0.6384s	
5430/26050 (epoch 10.422), train_loss = 1.14079330, grad/param norm = 1.6849e-01, time/batch = 0.6383s	
5431/26050 (epoch 10.424), train_loss = 1.48219995, grad/param norm = 2.1108e-01, time/batch = 0.6578s	
5432/26050 (epoch 10.426), train_loss = 1.44199931, grad/param norm = 1.8958e-01, time/batch = 0.6821s	
5433/26050 (epoch 10.428), train_loss = 1.18485685, grad/param norm = 1.5682e-01, time/batch = 0.6412s	
5434/26050 (epoch 10.430), train_loss = 1.33056535, grad/param norm = 1.7998e-01, time/batch = 0.6428s	
5435/26050 (epoch 10.432), train_loss = 1.22156479, grad/param norm = 1.7375e-01, time/batch = 0.6461s	
5436/26050 (epoch 10.434), train_loss = 1.29141755, grad/param norm = 1.8418e-01, time/batch = 0.6390s	
5437/26050 (epoch 10.436), train_loss = 1.39977855, grad/param norm = 1.6318e-01, time/batch = 0.6452s	
5438/26050 (epoch 10.438), train_loss = 1.17168237, grad/param norm = 1.6728e-01, time/batch = 0.6399s	
5439/26050 (epoch 10.440), train_loss = 1.31530966, grad/param norm = 1.6860e-01, time/batch = 0.6397s	
5440/26050 (epoch 10.441), train_loss = 1.28327871, grad/param norm = 1.6006e-01, time/batch = 0.6404s	
5441/26050 (epoch 10.443), train_loss = 1.07976204, grad/param norm = 1.5044e-01, time/batch = 0.6620s	
5442/26050 (epoch 10.445), train_loss = 1.14904788, grad/param norm = 1.7070e-01, time/batch = 0.6536s	
5443/26050 (epoch 10.447), train_loss = 1.48836712, grad/param norm = 1.9354e-01, time/batch = 0.6416s	
5444/26050 (epoch 10.449), train_loss = 1.17988191, grad/param norm = 1.6906e-01, time/batch = 0.6420s	
5445/26050 (epoch 10.451), train_loss = 1.39075241, grad/param norm = 1.6799e-01, time/batch = 0.6403s	
5446/26050 (epoch 10.453), train_loss = 1.17528410, grad/param norm = 1.6404e-01, time/batch = 0.6405s	
5447/26050 (epoch 10.455), train_loss = 1.30928572, grad/param norm = 1.7430e-01, time/batch = 0.6411s	
5448/26050 (epoch 10.457), train_loss = 1.29112896, grad/param norm = 1.7065e-01, time/batch = 0.6397s	
5449/26050 (epoch 10.459), train_loss = 1.41113867, grad/param norm = 1.8334e-01, time/batch = 0.6498s	
5450/26050 (epoch 10.461), train_loss = 1.34858408, grad/param norm = 1.8470e-01, time/batch = 0.6390s	
5451/26050 (epoch 10.463), train_loss = 1.20620928, grad/param norm = 1.5618e-01, time/batch = 0.6431s	
5452/26050 (epoch 10.464), train_loss = 1.36763953, grad/param norm = 1.8563e-01, time/batch = 0.6609s	
5453/26050 (epoch 10.466), train_loss = 1.36599074, grad/param norm = 1.8504e-01, time/batch = 0.6588s	
5454/26050 (epoch 10.468), train_loss = 1.37328280, grad/param norm = 1.6373e-01, time/batch = 0.6596s	
5455/26050 (epoch 10.470), train_loss = 1.50238766, grad/param norm = 2.0114e-01, time/batch = 0.6580s	
5456/26050 (epoch 10.472), train_loss = 1.45741055, grad/param norm = 1.8771e-01, time/batch = 0.6564s	
5457/26050 (epoch 10.474), train_loss = 1.53156678, grad/param norm = 1.8262e-01, time/batch = 0.6513s	
5458/26050 (epoch 10.476), train_loss = 1.37788244, grad/param norm = 1.6590e-01, time/batch = 0.6510s	
5459/26050 (epoch 10.478), train_loss = 1.19231605, grad/param norm = 1.5316e-01, time/batch = 0.6553s	
5460/26050 (epoch 10.480), train_loss = 1.31007091, grad/param norm = 1.5980e-01, time/batch = 0.6574s	
5461/26050 (epoch 10.482), train_loss = 1.25364928, grad/param norm = 1.6834e-01, time/batch = 0.6575s	
5462/26050 (epoch 10.484), train_loss = 1.18949070, grad/param norm = 1.6799e-01, time/batch = 0.6590s	
5463/26050 (epoch 10.486), train_loss = 1.46539013, grad/param norm = 1.7387e-01, time/batch = 0.6551s	
5464/26050 (epoch 10.488), train_loss = 1.62224286, grad/param norm = 1.8870e-01, time/batch = 0.6409s	
5465/26050 (epoch 10.489), train_loss = 1.55739484, grad/param norm = 1.9988e-01, time/batch = 0.6456s	
5466/26050 (epoch 10.491), train_loss = 1.19254902, grad/param norm = 1.7231e-01, time/batch = 0.6403s	
5467/26050 (epoch 10.493), train_loss = 1.27092442, grad/param norm = 1.6952e-01, time/batch = 0.6385s	
5468/26050 (epoch 10.495), train_loss = 1.25216348, grad/param norm = 1.6672e-01, time/batch = 0.6386s	
5469/26050 (epoch 10.497), train_loss = 1.23581239, grad/param norm = 1.7014e-01, time/batch = 0.6383s	
5470/26050 (epoch 10.499), train_loss = 1.25227264, grad/param norm = 1.7861e-01, time/batch = 0.6373s	
5471/26050 (epoch 10.501), train_loss = 1.35597071, grad/param norm = 1.7782e-01, time/batch = 0.6402s	
5472/26050 (epoch 10.503), train_loss = 1.22233944, grad/param norm = 1.8628e-01, time/batch = 0.6408s	
5473/26050 (epoch 10.505), train_loss = 1.41972122, grad/param norm = 1.7786e-01, time/batch = 0.6806s	
5474/26050 (epoch 10.507), train_loss = 1.42364682, grad/param norm = 1.9474e-01, time/batch = 0.6617s	
5475/26050 (epoch 10.509), train_loss = 1.52393780, grad/param norm = 1.9164e-01, time/batch = 0.6374s	
5476/26050 (epoch 10.511), train_loss = 1.19560731, grad/param norm = 1.6825e-01, time/batch = 0.6380s	
5477/26050 (epoch 10.512), train_loss = 1.27058555, grad/param norm = 1.8211e-01, time/batch = 0.6395s	
5478/26050 (epoch 10.514), train_loss = 1.36286588, grad/param norm = 1.7931e-01, time/batch = 0.6379s	
5479/26050 (epoch 10.516), train_loss = 1.40169368, grad/param norm = 1.8124e-01, time/batch = 0.6432s	
5480/26050 (epoch 10.518), train_loss = 1.35779694, grad/param norm = 1.8480e-01, time/batch = 0.6559s	
5481/26050 (epoch 10.520), train_loss = 1.29732352, grad/param norm = 1.6726e-01, time/batch = 0.6527s	
5482/26050 (epoch 10.522), train_loss = 1.11334350, grad/param norm = 1.6640e-01, time/batch = 0.6743s	
5483/26050 (epoch 10.524), train_loss = 1.44724036, grad/param norm = 1.8656e-01, time/batch = 0.6628s	
5484/26050 (epoch 10.526), train_loss = 1.38665572, grad/param norm = 1.7817e-01, time/batch = 0.6444s	
5485/26050 (epoch 10.528), train_loss = 1.35118704, grad/param norm = 1.7430e-01, time/batch = 0.6407s	
5486/26050 (epoch 10.530), train_loss = 1.27336148, grad/param norm = 1.5874e-01, time/batch = 0.6451s	
5487/26050 (epoch 10.532), train_loss = 1.28258861, grad/param norm = 1.6159e-01, time/batch = 0.6422s	
5488/26050 (epoch 10.534), train_loss = 1.38494088, grad/param norm = 1.8290e-01, time/batch = 0.6386s	
5489/26050 (epoch 10.536), train_loss = 1.26052449, grad/param norm = 1.5666e-01, time/batch = 0.6395s	
5490/26050 (epoch 10.537), train_loss = 1.40917846, grad/param norm = 1.9350e-01, time/batch = 0.6392s	
5491/26050 (epoch 10.539), train_loss = 1.29176891, grad/param norm = 1.7039e-01, time/batch = 0.6400s	
5492/26050 (epoch 10.541), train_loss = 1.49789708, grad/param norm = 2.0130e-01, time/batch = 0.6421s	
5493/26050 (epoch 10.543), train_loss = 1.12390890, grad/param norm = 1.7034e-01, time/batch = 0.6401s	
5494/26050 (epoch 10.545), train_loss = 1.34933241, grad/param norm = 1.7315e-01, time/batch = 0.6403s	
5495/26050 (epoch 10.547), train_loss = 1.32962621, grad/param norm = 1.7567e-01, time/batch = 0.6510s	
5496/26050 (epoch 10.549), train_loss = 1.11162525, grad/param norm = 1.6942e-01, time/batch = 0.6466s	
5497/26050 (epoch 10.551), train_loss = 1.33722021, grad/param norm = 1.8162e-01, time/batch = 0.6417s	
5498/26050 (epoch 10.553), train_loss = 1.18782808, grad/param norm = 1.6183e-01, time/batch = 0.6394s	
5499/26050 (epoch 10.555), train_loss = 1.24332099, grad/param norm = 1.6586e-01, time/batch = 0.6421s	
5500/26050 (epoch 10.557), train_loss = 1.35358469, grad/param norm = 1.6228e-01, time/batch = 0.6393s	
5501/26050 (epoch 10.559), train_loss = 1.29856572, grad/param norm = 1.7234e-01, time/batch = 0.6417s	
5502/26050 (epoch 10.560), train_loss = 1.28339531, grad/param norm = 1.7876e-01, time/batch = 0.6412s	
5503/26050 (epoch 10.562), train_loss = 1.27585911, grad/param norm = 1.7477e-01, time/batch = 0.6519s	
5504/26050 (epoch 10.564), train_loss = 1.50600351, grad/param norm = 1.8059e-01, time/batch = 0.6468s	
5505/26050 (epoch 10.566), train_loss = 1.17218099, grad/param norm = 1.6642e-01, time/batch = 0.6392s	
5506/26050 (epoch 10.568), train_loss = 1.31010110, grad/param norm = 1.7168e-01, time/batch = 0.6384s	
5507/26050 (epoch 10.570), train_loss = 1.41820938, grad/param norm = 1.8548e-01, time/batch = 0.6397s	
5508/26050 (epoch 10.572), train_loss = 1.27582005, grad/param norm = 1.6528e-01, time/batch = 0.6588s	
5509/26050 (epoch 10.574), train_loss = 1.38092896, grad/param norm = 2.0185e-01, time/batch = 0.6830s	
5510/26050 (epoch 10.576), train_loss = 1.38005323, grad/param norm = 1.9361e-01, time/batch = 0.6446s	
5511/26050 (epoch 10.578), train_loss = 1.30105360, grad/param norm = 1.8671e-01, time/batch = 0.6457s	
5512/26050 (epoch 10.580), train_loss = 1.18575123, grad/param norm = 1.7451e-01, time/batch = 0.6468s	
5513/26050 (epoch 10.582), train_loss = 1.34559628, grad/param norm = 1.8286e-01, time/batch = 0.6388s	
5514/26050 (epoch 10.583), train_loss = 1.38614203, grad/param norm = 1.8083e-01, time/batch = 0.6388s	
5515/26050 (epoch 10.585), train_loss = 1.18978988, grad/param norm = 1.7569e-01, time/batch = 0.6412s	
5516/26050 (epoch 10.587), train_loss = 1.35338843, grad/param norm = 1.7416e-01, time/batch = 0.6382s	
5517/26050 (epoch 10.589), train_loss = 1.39425938, grad/param norm = 1.9090e-01, time/batch = 0.6398s	
5518/26050 (epoch 10.591), train_loss = 1.32662995, grad/param norm = 1.8211e-01, time/batch = 0.6400s	
5519/26050 (epoch 10.593), train_loss = 1.17057452, grad/param norm = 1.7981e-01, time/batch = 0.6391s	
5520/26050 (epoch 10.595), train_loss = 1.45737612, grad/param norm = 2.0848e-01, time/batch = 0.6412s	
5521/26050 (epoch 10.597), train_loss = 1.32796033, grad/param norm = 1.7942e-01, time/batch = 0.6399s	
5522/26050 (epoch 10.599), train_loss = 1.26318665, grad/param norm = 1.7530e-01, time/batch = 0.6394s	
5523/26050 (epoch 10.601), train_loss = 1.51026389, grad/param norm = 1.8571e-01, time/batch = 0.6432s	
5524/26050 (epoch 10.603), train_loss = 1.35690697, grad/param norm = 1.7686e-01, time/batch = 0.6830s	
5525/26050 (epoch 10.605), train_loss = 1.22597721, grad/param norm = 1.6623e-01, time/batch = 0.6587s	
5526/26050 (epoch 10.607), train_loss = 1.44529599, grad/param norm = 1.8769e-01, time/batch = 0.6451s	
5527/26050 (epoch 10.608), train_loss = 1.22629084, grad/param norm = 1.6045e-01, time/batch = 0.6407s	
5528/26050 (epoch 10.610), train_loss = 1.28163983, grad/param norm = 1.8241e-01, time/batch = 0.6392s	
5529/26050 (epoch 10.612), train_loss = 1.26891485, grad/param norm = 1.7221e-01, time/batch = 0.6416s	
5530/26050 (epoch 10.614), train_loss = 1.37215302, grad/param norm = 1.7792e-01, time/batch = 0.6389s	
5531/26050 (epoch 10.616), train_loss = 1.55574585, grad/param norm = 1.9429e-01, time/batch = 0.6415s	
5532/26050 (epoch 10.618), train_loss = 1.22961486, grad/param norm = 1.7643e-01, time/batch = 0.6401s	
5533/26050 (epoch 10.620), train_loss = 1.32158013, grad/param norm = 1.7893e-01, time/batch = 0.6452s	
5534/26050 (epoch 10.622), train_loss = 1.09342368, grad/param norm = 1.5225e-01, time/batch = 0.6427s	
5535/26050 (epoch 10.624), train_loss = 1.16762997, grad/param norm = 1.6339e-01, time/batch = 0.6421s	
5536/26050 (epoch 10.626), train_loss = 1.36620951, grad/param norm = 1.8235e-01, time/batch = 0.6472s	
5537/26050 (epoch 10.628), train_loss = 1.26317429, grad/param norm = 1.8708e-01, time/batch = 0.6427s	
5538/26050 (epoch 10.630), train_loss = 1.42665154, grad/param norm = 1.7280e-01, time/batch = 0.6417s	
5539/26050 (epoch 10.631), train_loss = 1.45199537, grad/param norm = 1.8613e-01, time/batch = 0.6660s	
5540/26050 (epoch 10.633), train_loss = 1.21353158, grad/param norm = 1.7580e-01, time/batch = 0.6442s	
5541/26050 (epoch 10.635), train_loss = 1.19660408, grad/param norm = 1.5824e-01, time/batch = 0.6465s	
5542/26050 (epoch 10.637), train_loss = 1.19944166, grad/param norm = 1.7958e-01, time/batch = 0.6535s	
5543/26050 (epoch 10.639), train_loss = 1.39681917, grad/param norm = 1.7076e-01, time/batch = 0.6478s	
5544/26050 (epoch 10.641), train_loss = 1.24038979, grad/param norm = 1.5948e-01, time/batch = 0.6420s	
5545/26050 (epoch 10.643), train_loss = 1.15818983, grad/param norm = 1.5090e-01, time/batch = 0.6441s	
5546/26050 (epoch 10.645), train_loss = 1.33535948, grad/param norm = 1.8866e-01, time/batch = 0.6410s	
5547/26050 (epoch 10.647), train_loss = 1.25629862, grad/param norm = 1.7664e-01, time/batch = 0.6412s	
5548/26050 (epoch 10.649), train_loss = 1.33206920, grad/param norm = 1.9227e-01, time/batch = 0.6394s	
5549/26050 (epoch 10.651), train_loss = 1.23873318, grad/param norm = 1.8228e-01, time/batch = 0.6401s	
5550/26050 (epoch 10.653), train_loss = 1.29492207, grad/param norm = 1.7435e-01, time/batch = 0.6403s	
5551/26050 (epoch 10.655), train_loss = 1.20974025, grad/param norm = 1.7012e-01, time/batch = 0.6412s	
5552/26050 (epoch 10.656), train_loss = 1.15940511, grad/param norm = 1.6713e-01, time/batch = 0.6412s	
5553/26050 (epoch 10.658), train_loss = 1.50430466, grad/param norm = 1.8264e-01, time/batch = 0.6409s	
5554/26050 (epoch 10.660), train_loss = 1.17807104, grad/param norm = 1.8142e-01, time/batch = 0.6480s	
5555/26050 (epoch 10.662), train_loss = 1.16497285, grad/param norm = 1.5569e-01, time/batch = 0.6829s	
5556/26050 (epoch 10.664), train_loss = 1.26090434, grad/param norm = 1.7352e-01, time/batch = 0.6539s	
5557/26050 (epoch 10.666), train_loss = 1.30986057, grad/param norm = 1.8261e-01, time/batch = 0.6418s	
5558/26050 (epoch 10.668), train_loss = 1.07565043, grad/param norm = 1.6455e-01, time/batch = 0.6485s	
5559/26050 (epoch 10.670), train_loss = 1.45845179, grad/param norm = 1.9299e-01, time/batch = 0.6384s	
5560/26050 (epoch 10.672), train_loss = 1.22053830, grad/param norm = 1.7066e-01, time/batch = 0.6392s	
5561/26050 (epoch 10.674), train_loss = 1.17983175, grad/param norm = 1.6689e-01, time/batch = 0.6394s	
5562/26050 (epoch 10.676), train_loss = 1.33097284, grad/param norm = 1.6946e-01, time/batch = 0.6392s	
5563/26050 (epoch 10.678), train_loss = 1.42925580, grad/param norm = 1.7411e-01, time/batch = 0.6384s	
5564/26050 (epoch 10.679), train_loss = 1.51654784, grad/param norm = 1.9637e-01, time/batch = 0.6404s	
5565/26050 (epoch 10.681), train_loss = 1.31481033, grad/param norm = 1.7624e-01, time/batch = 0.6400s	
5566/26050 (epoch 10.683), train_loss = 1.20856268, grad/param norm = 2.0362e-01, time/batch = 0.6384s	
5567/26050 (epoch 10.685), train_loss = 1.22890111, grad/param norm = 1.5727e-01, time/batch = 0.6381s	
5568/26050 (epoch 10.687), train_loss = 1.09630488, grad/param norm = 1.5798e-01, time/batch = 0.6380s	
5569/26050 (epoch 10.689), train_loss = 1.26429784, grad/param norm = 1.7298e-01, time/batch = 0.6385s	
5570/26050 (epoch 10.691), train_loss = 1.01330504, grad/param norm = 1.5435e-01, time/batch = 0.6688s	
5571/26050 (epoch 10.693), train_loss = 1.20555914, grad/param norm = 1.7497e-01, time/batch = 0.6714s	
5572/26050 (epoch 10.695), train_loss = 1.29743765, grad/param norm = 1.7107e-01, time/batch = 0.6584s	
5573/26050 (epoch 10.697), train_loss = 1.16931002, grad/param norm = 1.6826e-01, time/batch = 0.6581s	
5574/26050 (epoch 10.699), train_loss = 1.35773976, grad/param norm = 1.8528e-01, time/batch = 0.6404s	
5575/26050 (epoch 10.701), train_loss = 1.12112342, grad/param norm = 1.5674e-01, time/batch = 0.6572s	
5576/26050 (epoch 10.702), train_loss = 1.49570619, grad/param norm = 1.9006e-01, time/batch = 0.6436s	
5577/26050 (epoch 10.704), train_loss = 1.32542805, grad/param norm = 1.7184e-01, time/batch = 0.6403s	
5578/26050 (epoch 10.706), train_loss = 1.34677242, grad/param norm = 2.0068e-01, time/batch = 0.6414s	
5579/26050 (epoch 10.708), train_loss = 1.35939092, grad/param norm = 1.7496e-01, time/batch = 0.6387s	
5580/26050 (epoch 10.710), train_loss = 1.34972978, grad/param norm = 1.7632e-01, time/batch = 0.6425s	
5581/26050 (epoch 10.712), train_loss = 1.44314716, grad/param norm = 1.8017e-01, time/batch = 0.6444s	
5582/26050 (epoch 10.714), train_loss = 1.14288226, grad/param norm = 1.7861e-01, time/batch = 0.6417s	
5583/26050 (epoch 10.716), train_loss = 1.55927881, grad/param norm = 2.0826e-01, time/batch = 0.6488s	
5584/26050 (epoch 10.718), train_loss = 1.40496666, grad/param norm = 1.9156e-01, time/batch = 0.6496s	
5585/26050 (epoch 10.720), train_loss = 1.21400192, grad/param norm = 1.7062e-01, time/batch = 0.6604s	
5586/26050 (epoch 10.722), train_loss = 1.16155681, grad/param norm = 1.6932e-01, time/batch = 0.6838s	
5587/26050 (epoch 10.724), train_loss = 1.16980710, grad/param norm = 1.6686e-01, time/batch = 0.6580s	
5588/26050 (epoch 10.726), train_loss = 1.40530539, grad/param norm = 1.7523e-01, time/batch = 0.6605s	
5589/26050 (epoch 10.727), train_loss = 1.34663113, grad/param norm = 1.7343e-01, time/batch = 0.6466s	
5590/26050 (epoch 10.729), train_loss = 1.34720164, grad/param norm = 1.7351e-01, time/batch = 0.6402s	
5591/26050 (epoch 10.731), train_loss = 1.31257393, grad/param norm = 1.5948e-01, time/batch = 0.6439s	
5592/26050 (epoch 10.733), train_loss = 1.25055387, grad/param norm = 1.9627e-01, time/batch = 0.6407s	
5593/26050 (epoch 10.735), train_loss = 1.48647865, grad/param norm = 1.8513e-01, time/batch = 0.6409s	
5594/26050 (epoch 10.737), train_loss = 1.28438009, grad/param norm = 1.7576e-01, time/batch = 0.6454s	
5595/26050 (epoch 10.739), train_loss = 1.32986486, grad/param norm = 1.6529e-01, time/batch = 0.6427s	
5596/26050 (epoch 10.741), train_loss = 1.19641365, grad/param norm = 1.6567e-01, time/batch = 0.6424s	
5597/26050 (epoch 10.743), train_loss = 1.36279167, grad/param norm = 2.4128e-01, time/batch = 0.6416s	
5598/26050 (epoch 10.745), train_loss = 1.17733097, grad/param norm = 1.7337e-01, time/batch = 0.6414s	
5599/26050 (epoch 10.747), train_loss = 1.18930928, grad/param norm = 1.7105e-01, time/batch = 0.6424s	
5600/26050 (epoch 10.749), train_loss = 1.44142141, grad/param norm = 1.9193e-01, time/batch = 0.6429s	
5601/26050 (epoch 10.750), train_loss = 1.26636247, grad/param norm = 1.5921e-01, time/batch = 0.6843s	
5602/26050 (epoch 10.752), train_loss = 1.30504219, grad/param norm = 1.9955e-01, time/batch = 0.6651s	
5603/26050 (epoch 10.754), train_loss = 1.31190244, grad/param norm = 1.7341e-01, time/batch = 0.6427s	
5604/26050 (epoch 10.756), train_loss = 1.32823475, grad/param norm = 1.8430e-01, time/batch = 0.6467s	
5605/26050 (epoch 10.758), train_loss = 1.31328754, grad/param norm = 1.7411e-01, time/batch = 0.6432s	
5606/26050 (epoch 10.760), train_loss = 1.39963102, grad/param norm = 1.8099e-01, time/batch = 0.6401s	
5607/26050 (epoch 10.762), train_loss = 1.19240678, grad/param norm = 1.5875e-01, time/batch = 0.6392s	
5608/26050 (epoch 10.764), train_loss = 1.39324632, grad/param norm = 1.9446e-01, time/batch = 0.6398s	
5609/26050 (epoch 10.766), train_loss = 1.38386719, grad/param norm = 1.8904e-01, time/batch = 0.6397s	
5610/26050 (epoch 10.768), train_loss = 1.14359487, grad/param norm = 1.5180e-01, time/batch = 0.6413s	
5611/26050 (epoch 10.770), train_loss = 1.28727057, grad/param norm = 1.7825e-01, time/batch = 0.6427s	
5612/26050 (epoch 10.772), train_loss = 1.27085167, grad/param norm = 1.6216e-01, time/batch = 0.6452s	
5613/26050 (epoch 10.774), train_loss = 1.14874068, grad/param norm = 1.7373e-01, time/batch = 0.6424s	
5614/26050 (epoch 10.775), train_loss = 0.98636214, grad/param norm = 1.5639e-01, time/batch = 0.6422s	
5615/26050 (epoch 10.777), train_loss = 1.20183064, grad/param norm = 1.6826e-01, time/batch = 0.6549s	
5616/26050 (epoch 10.779), train_loss = 1.25659786, grad/param norm = 1.7666e-01, time/batch = 0.6757s	
5617/26050 (epoch 10.781), train_loss = 1.23148619, grad/param norm = 1.6430e-01, time/batch = 0.6785s	
5618/26050 (epoch 10.783), train_loss = 1.18715752, grad/param norm = 1.6424e-01, time/batch = 0.6606s	
5619/26050 (epoch 10.785), train_loss = 1.23952067, grad/param norm = 1.8168e-01, time/batch = 0.6595s	
5620/26050 (epoch 10.787), train_loss = 1.20645589, grad/param norm = 1.6791e-01, time/batch = 0.6542s	
5621/26050 (epoch 10.789), train_loss = 1.24456349, grad/param norm = 1.8555e-01, time/batch = 0.6517s	
5622/26050 (epoch 10.791), train_loss = 1.28200571, grad/param norm = 1.8298e-01, time/batch = 0.6536s	
5623/26050 (epoch 10.793), train_loss = 1.26133019, grad/param norm = 1.8232e-01, time/batch = 0.6534s	
5624/26050 (epoch 10.795), train_loss = 1.09796191, grad/param norm = 1.5158e-01, time/batch = 0.6558s	
5625/26050 (epoch 10.797), train_loss = 1.19339923, grad/param norm = 1.7534e-01, time/batch = 0.6531s	
5626/26050 (epoch 10.798), train_loss = 1.15019063, grad/param norm = 1.7278e-01, time/batch = 0.6605s	
5627/26050 (epoch 10.800), train_loss = 1.12244813, grad/param norm = 1.4693e-01, time/batch = 0.6620s	
5628/26050 (epoch 10.802), train_loss = 1.25024159, grad/param norm = 1.7502e-01, time/batch = 0.6516s	
5629/26050 (epoch 10.804), train_loss = 1.24887578, grad/param norm = 1.6758e-01, time/batch = 0.6400s	
5630/26050 (epoch 10.806), train_loss = 1.38906363, grad/param norm = 1.8709e-01, time/batch = 0.6403s	
5631/26050 (epoch 10.808), train_loss = 1.24629272, grad/param norm = 1.6970e-01, time/batch = 0.6502s	
5632/26050 (epoch 10.810), train_loss = 1.21963667, grad/param norm = 1.7411e-01, time/batch = 0.6583s	
5633/26050 (epoch 10.812), train_loss = 1.14833670, grad/param norm = 1.7558e-01, time/batch = 0.6418s	
5634/26050 (epoch 10.814), train_loss = 1.15856753, grad/param norm = 2.0539e-01, time/batch = 0.6435s	
5635/26050 (epoch 10.816), train_loss = 1.35538179, grad/param norm = 1.8277e-01, time/batch = 0.6508s	
5636/26050 (epoch 10.818), train_loss = 1.44083586, grad/param norm = 2.0501e-01, time/batch = 0.6408s	
5637/26050 (epoch 10.820), train_loss = 1.29162532, grad/param norm = 1.7840e-01, time/batch = 0.6403s	
5638/26050 (epoch 10.821), train_loss = 1.44851852, grad/param norm = 2.1660e-01, time/batch = 0.6397s	
5639/26050 (epoch 10.823), train_loss = 1.47044216, grad/param norm = 1.8395e-01, time/batch = 0.6405s	
5640/26050 (epoch 10.825), train_loss = 1.24536439, grad/param norm = 1.9993e-01, time/batch = 0.6388s	
5641/26050 (epoch 10.827), train_loss = 1.31848756, grad/param norm = 1.8542e-01, time/batch = 0.6415s	
5642/26050 (epoch 10.829), train_loss = 1.33168245, grad/param norm = 1.8404e-01, time/batch = 0.6417s	
5643/26050 (epoch 10.831), train_loss = 1.41400036, grad/param norm = 1.7423e-01, time/batch = 0.6411s	
5644/26050 (epoch 10.833), train_loss = 1.49520361, grad/param norm = 1.8085e-01, time/batch = 0.6406s	
5645/26050 (epoch 10.835), train_loss = 1.51552106, grad/param norm = 1.9513e-01, time/batch = 0.6415s	
5646/26050 (epoch 10.837), train_loss = 1.24523394, grad/param norm = 1.7117e-01, time/batch = 0.6422s	
5647/26050 (epoch 10.839), train_loss = 1.36030519, grad/param norm = 1.9585e-01, time/batch = 0.6825s	
5648/26050 (epoch 10.841), train_loss = 1.41276347, grad/param norm = 1.7870e-01, time/batch = 0.6580s	
5649/26050 (epoch 10.843), train_loss = 1.33452608, grad/param norm = 1.8083e-01, time/batch = 0.6398s	
5650/26050 (epoch 10.845), train_loss = 1.21312687, grad/param norm = 1.6562e-01, time/batch = 0.6432s	
5651/26050 (epoch 10.846), train_loss = 1.42481955, grad/param norm = 1.8029e-01, time/batch = 0.6417s	
5652/26050 (epoch 10.848), train_loss = 1.24253090, grad/param norm = 1.7111e-01, time/batch = 0.6394s	
5653/26050 (epoch 10.850), train_loss = 1.22684123, grad/param norm = 1.6722e-01, time/batch = 0.6390s	
5654/26050 (epoch 10.852), train_loss = 1.25545587, grad/param norm = 1.7584e-01, time/batch = 0.6389s	
5655/26050 (epoch 10.854), train_loss = 1.27712785, grad/param norm = 1.7121e-01, time/batch = 0.6385s	
5656/26050 (epoch 10.856), train_loss = 1.22000664, grad/param norm = 1.8187e-01, time/batch = 0.6433s	
5657/26050 (epoch 10.858), train_loss = 1.15821734, grad/param norm = 1.7418e-01, time/batch = 0.6456s	
5658/26050 (epoch 10.860), train_loss = 1.32745461, grad/param norm = 1.9353e-01, time/batch = 0.6590s	
5659/26050 (epoch 10.862), train_loss = 1.29326256, grad/param norm = 1.7707e-01, time/batch = 0.6469s	
5660/26050 (epoch 10.864), train_loss = 1.28318170, grad/param norm = 1.8629e-01, time/batch = 0.6406s	
5661/26050 (epoch 10.866), train_loss = 1.20622246, grad/param norm = 1.6142e-01, time/batch = 0.6472s	
5662/26050 (epoch 10.868), train_loss = 1.38681016, grad/param norm = 1.9759e-01, time/batch = 0.6428s	
5663/26050 (epoch 10.869), train_loss = 1.15790312, grad/param norm = 1.6201e-01, time/batch = 0.6402s	
5664/26050 (epoch 10.871), train_loss = 1.11002234, grad/param norm = 1.5482e-01, time/batch = 0.6507s	
5665/26050 (epoch 10.873), train_loss = 1.33826004, grad/param norm = 1.7465e-01, time/batch = 0.6589s	
5666/26050 (epoch 10.875), train_loss = 1.26561429, grad/param norm = 1.7549e-01, time/batch = 0.6626s	
5667/26050 (epoch 10.877), train_loss = 1.14620746, grad/param norm = 1.7087e-01, time/batch = 0.6733s	
5668/26050 (epoch 10.879), train_loss = 1.27252176, grad/param norm = 1.6125e-01, time/batch = 0.6425s	
5669/26050 (epoch 10.881), train_loss = 1.42579250, grad/param norm = 1.8088e-01, time/batch = 0.6444s	
5670/26050 (epoch 10.883), train_loss = 1.31237649, grad/param norm = 1.7448e-01, time/batch = 0.6409s	
5671/26050 (epoch 10.885), train_loss = 1.00462449, grad/param norm = 1.5209e-01, time/batch = 0.6414s	
5672/26050 (epoch 10.887), train_loss = 1.32576722, grad/param norm = 1.7841e-01, time/batch = 0.6435s	
5673/26050 (epoch 10.889), train_loss = 1.21668846, grad/param norm = 1.6161e-01, time/batch = 0.6433s	
5674/26050 (epoch 10.891), train_loss = 1.04026400, grad/param norm = 1.5408e-01, time/batch = 0.6403s	
5675/26050 (epoch 10.893), train_loss = 1.02702129, grad/param norm = 1.5246e-01, time/batch = 0.6402s	
5676/26050 (epoch 10.894), train_loss = 1.21032041, grad/param norm = 1.6288e-01, time/batch = 0.6420s	
5677/26050 (epoch 10.896), train_loss = 1.39278002, grad/param norm = 1.7742e-01, time/batch = 0.6539s	
5678/26050 (epoch 10.898), train_loss = 1.21745822, grad/param norm = 1.8528e-01, time/batch = 0.6827s	
5679/26050 (epoch 10.900), train_loss = 1.43214139, grad/param norm = 1.7805e-01, time/batch = 0.6497s	
5680/26050 (epoch 10.902), train_loss = 1.27671718, grad/param norm = 1.7873e-01, time/batch = 0.6584s	
5681/26050 (epoch 10.904), train_loss = 1.23146372, grad/param norm = 1.6098e-01, time/batch = 0.6640s	
5682/26050 (epoch 10.906), train_loss = 1.25321109, grad/param norm = 1.7191e-01, time/batch = 0.6570s	
5683/26050 (epoch 10.908), train_loss = 1.24017569, grad/param norm = 1.7008e-01, time/batch = 0.6562s	
5684/26050 (epoch 10.910), train_loss = 1.16674382, grad/param norm = 1.5250e-01, time/batch = 0.6568s	
5685/26050 (epoch 10.912), train_loss = 1.53169199, grad/param norm = 1.9180e-01, time/batch = 0.6603s	
5686/26050 (epoch 10.914), train_loss = 1.68875074, grad/param norm = 1.9840e-01, time/batch = 0.6562s	
5687/26050 (epoch 10.916), train_loss = 1.41287993, grad/param norm = 1.9443e-01, time/batch = 0.6615s	
5688/26050 (epoch 10.917), train_loss = 1.32602086, grad/param norm = 2.0204e-01, time/batch = 0.6594s	
5689/26050 (epoch 10.919), train_loss = 1.39046594, grad/param norm = 1.8429e-01, time/batch = 0.6604s	
5690/26050 (epoch 10.921), train_loss = 1.21926931, grad/param norm = 1.9766e-01, time/batch = 0.6577s	
5691/26050 (epoch 10.923), train_loss = 1.28576408, grad/param norm = 1.9072e-01, time/batch = 0.6619s	
5692/26050 (epoch 10.925), train_loss = 1.25294542, grad/param norm = 1.6741e-01, time/batch = 0.6532s	
5693/26050 (epoch 10.927), train_loss = 1.14393974, grad/param norm = 1.4938e-01, time/batch = 0.6837s	
5694/26050 (epoch 10.929), train_loss = 1.18934656, grad/param norm = 1.7494e-01, time/batch = 0.6520s	
5695/26050 (epoch 10.931), train_loss = 1.52479950, grad/param norm = 2.1375e-01, time/batch = 0.6477s	
5696/26050 (epoch 10.933), train_loss = 1.23299141, grad/param norm = 1.7940e-01, time/batch = 0.6425s	
5697/26050 (epoch 10.935), train_loss = 1.19717385, grad/param norm = 1.5948e-01, time/batch = 0.6397s	
5698/26050 (epoch 10.937), train_loss = 1.32078105, grad/param norm = 1.6969e-01, time/batch = 0.6392s	
5699/26050 (epoch 10.939), train_loss = 1.15509599, grad/param norm = 1.5463e-01, time/batch = 0.6398s	
5700/26050 (epoch 10.940), train_loss = 1.28491747, grad/param norm = 1.6246e-01, time/batch = 0.6402s	
5701/26050 (epoch 10.942), train_loss = 1.31296009, grad/param norm = 1.9509e-01, time/batch = 0.6417s	
5702/26050 (epoch 10.944), train_loss = 1.24229004, grad/param norm = 1.9153e-01, time/batch = 0.6411s	
5703/26050 (epoch 10.946), train_loss = 1.43717936, grad/param norm = 1.7894e-01, time/batch = 0.6487s	
5704/26050 (epoch 10.948), train_loss = 1.10257715, grad/param norm = 1.8582e-01, time/batch = 0.6570s	
5705/26050 (epoch 10.950), train_loss = 1.24890563, grad/param norm = 1.7773e-01, time/batch = 0.6507s	
5706/26050 (epoch 10.952), train_loss = 1.41452747, grad/param norm = 1.9454e-01, time/batch = 0.6542s	
5707/26050 (epoch 10.954), train_loss = 1.38309400, grad/param norm = 1.7927e-01, time/batch = 0.6561s	
5708/26050 (epoch 10.956), train_loss = 1.31126121, grad/param norm = 1.8947e-01, time/batch = 0.6496s	
5709/26050 (epoch 10.958), train_loss = 1.24437280, grad/param norm = 1.7159e-01, time/batch = 0.6502s	
5710/26050 (epoch 10.960), train_loss = 1.26069863, grad/param norm = 1.7096e-01, time/batch = 0.6521s	
5711/26050 (epoch 10.962), train_loss = 1.18617510, grad/param norm = 1.6676e-01, time/batch = 0.6562s	
5712/26050 (epoch 10.964), train_loss = 1.26320287, grad/param norm = 1.7280e-01, time/batch = 0.6488s	
5713/26050 (epoch 10.965), train_loss = 1.16532848, grad/param norm = 1.6691e-01, time/batch = 0.6474s	
5714/26050 (epoch 10.967), train_loss = 1.60101470, grad/param norm = 1.7999e-01, time/batch = 0.6490s	
5715/26050 (epoch 10.969), train_loss = 1.24299269, grad/param norm = 1.6055e-01, time/batch = 0.6522s	
5716/26050 (epoch 10.971), train_loss = 1.16888982, grad/param norm = 1.5588e-01, time/batch = 0.6598s	
5717/26050 (epoch 10.973), train_loss = 1.23597401, grad/param norm = 1.8215e-01, time/batch = 0.6511s	
5718/26050 (epoch 10.975), train_loss = 1.33312559, grad/param norm = 1.6530e-01, time/batch = 0.6687s	
5719/26050 (epoch 10.977), train_loss = 1.29123676, grad/param norm = 1.5722e-01, time/batch = 0.6606s	
5720/26050 (epoch 10.979), train_loss = 1.10044527, grad/param norm = 1.6768e-01, time/batch = 0.6490s	
5721/26050 (epoch 10.981), train_loss = 1.39181945, grad/param norm = 1.7008e-01, time/batch = 0.6458s	
5722/26050 (epoch 10.983), train_loss = 1.39206657, grad/param norm = 1.7575e-01, time/batch = 0.6546s	
5723/26050 (epoch 10.985), train_loss = 1.30327703, grad/param norm = 1.7534e-01, time/batch = 0.6420s	
5724/26050 (epoch 10.987), train_loss = 1.43464309, grad/param norm = 1.9109e-01, time/batch = 0.6434s	
5725/26050 (epoch 10.988), train_loss = 1.38015995, grad/param norm = 1.7299e-01, time/batch = 0.6416s	
5726/26050 (epoch 10.990), train_loss = 1.18190565, grad/param norm = 1.5744e-01, time/batch = 0.6439s	
5727/26050 (epoch 10.992), train_loss = 1.43373333, grad/param norm = 1.8652e-01, time/batch = 0.6457s	
5728/26050 (epoch 10.994), train_loss = 1.29988386, grad/param norm = 1.7876e-01, time/batch = 0.6436s	
5729/26050 (epoch 10.996), train_loss = 1.23865737, grad/param norm = 1.9175e-01, time/batch = 0.6429s	
5730/26050 (epoch 10.998), train_loss = 1.29436516, grad/param norm = 1.7416e-01, time/batch = 0.6430s	
decayed learning rate by a factor 0.97 to 0.0018818	
5731/26050 (epoch 11.000), train_loss = 1.24085240, grad/param norm = 1.7555e-01, time/batch = 0.6446s	
5732/26050 (epoch 11.002), train_loss = 1.34149392, grad/param norm = 1.8864e-01, time/batch = 0.6508s	
5733/26050 (epoch 11.004), train_loss = 1.17590722, grad/param norm = 1.7192e-01, time/batch = 0.6469s	
5734/26050 (epoch 11.006), train_loss = 1.20177689, grad/param norm = 1.7052e-01, time/batch = 0.6487s	
5735/26050 (epoch 11.008), train_loss = 1.18040089, grad/param norm = 1.7512e-01, time/batch = 0.6406s	
5736/26050 (epoch 11.010), train_loss = 1.20981546, grad/param norm = 1.6566e-01, time/batch = 0.6658s	
5737/26050 (epoch 11.012), train_loss = 1.29499277, grad/param norm = 1.7710e-01, time/batch = 0.6508s	
5738/26050 (epoch 11.013), train_loss = 1.69420986, grad/param norm = 2.0352e-01, time/batch = 0.6482s	
5739/26050 (epoch 11.015), train_loss = 1.17591815, grad/param norm = 1.6696e-01, time/batch = 0.6830s	
5740/26050 (epoch 11.017), train_loss = 1.30287774, grad/param norm = 1.7071e-01, time/batch = 0.6605s	
5741/26050 (epoch 11.019), train_loss = 1.06715429, grad/param norm = 1.4191e-01, time/batch = 0.6461s	
5742/26050 (epoch 11.021), train_loss = 1.37088080, grad/param norm = 1.7676e-01, time/batch = 0.6425s	
5743/26050 (epoch 11.023), train_loss = 1.10243594, grad/param norm = 1.6259e-01, time/batch = 0.6398s	
5744/26050 (epoch 11.025), train_loss = 1.23167041, grad/param norm = 1.6747e-01, time/batch = 0.6401s	
5745/26050 (epoch 11.027), train_loss = 1.03498936, grad/param norm = 1.5876e-01, time/batch = 0.6398s	
5746/26050 (epoch 11.029), train_loss = 1.24164897, grad/param norm = 1.6640e-01, time/batch = 0.6399s	
5747/26050 (epoch 11.031), train_loss = 1.42216539, grad/param norm = 1.9372e-01, time/batch = 0.6394s	
5748/26050 (epoch 11.033), train_loss = 1.32231486, grad/param norm = 1.7717e-01, time/batch = 0.6409s	
5749/26050 (epoch 11.035), train_loss = 1.36295713, grad/param norm = 1.6470e-01, time/batch = 0.6421s	
5750/26050 (epoch 11.036), train_loss = 1.18181527, grad/param norm = 2.0239e-01, time/batch = 0.6419s	
5751/26050 (epoch 11.038), train_loss = 1.09701132, grad/param norm = 1.6687e-01, time/batch = 0.6405s	
5752/26050 (epoch 11.040), train_loss = 1.32103907, grad/param norm = 1.8559e-01, time/batch = 0.6405s	
5753/26050 (epoch 11.042), train_loss = 1.13386273, grad/param norm = 1.7982e-01, time/batch = 0.6406s	
5754/26050 (epoch 11.044), train_loss = 1.35042372, grad/param norm = 1.7725e-01, time/batch = 0.6736s	
5755/26050 (epoch 11.046), train_loss = 1.06099967, grad/param norm = 1.7210e-01, time/batch = 0.6693s	
5756/26050 (epoch 11.048), train_loss = 1.30312219, grad/param norm = 1.8057e-01, time/batch = 0.6532s	
5757/26050 (epoch 11.050), train_loss = 1.15835176, grad/param norm = 1.8504e-01, time/batch = 0.6544s	
5758/26050 (epoch 11.052), train_loss = 1.23251887, grad/param norm = 1.7014e-01, time/batch = 0.6514s	
5759/26050 (epoch 11.054), train_loss = 1.08877004, grad/param norm = 1.5687e-01, time/batch = 0.6484s	
5760/26050 (epoch 11.056), train_loss = 0.99965468, grad/param norm = 1.4174e-01, time/batch = 0.6422s	
5761/26050 (epoch 11.058), train_loss = 1.18031955, grad/param norm = 1.6412e-01, time/batch = 0.6456s	
5762/26050 (epoch 11.060), train_loss = 1.27085571, grad/param norm = 1.6198e-01, time/batch = 0.6435s	
5763/26050 (epoch 11.061), train_loss = 1.15053969, grad/param norm = 1.6456e-01, time/batch = 0.6402s	
5764/26050 (epoch 11.063), train_loss = 1.25842822, grad/param norm = 1.6534e-01, time/batch = 0.6446s	
5765/26050 (epoch 11.065), train_loss = 1.07535288, grad/param norm = 1.7296e-01, time/batch = 0.6446s	
5766/26050 (epoch 11.067), train_loss = 1.32128873, grad/param norm = 1.8811e-01, time/batch = 0.6522s	
5767/26050 (epoch 11.069), train_loss = 1.31019646, grad/param norm = 1.6290e-01, time/batch = 0.6467s	
5768/26050 (epoch 11.071), train_loss = 1.32803276, grad/param norm = 1.8078e-01, time/batch = 0.6441s	
5769/26050 (epoch 11.073), train_loss = 1.47211216, grad/param norm = 1.7465e-01, time/batch = 0.6627s	
5770/26050 (epoch 11.075), train_loss = 1.16147904, grad/param norm = 1.5741e-01, time/batch = 0.6846s	
5771/26050 (epoch 11.077), train_loss = 1.15407391, grad/param norm = 1.6275e-01, time/batch = 0.6605s	
5772/26050 (epoch 11.079), train_loss = 1.31319940, grad/param norm = 1.8597e-01, time/batch = 0.6473s	
5773/26050 (epoch 11.081), train_loss = 1.21108996, grad/param norm = 1.6406e-01, time/batch = 0.6430s	
5774/26050 (epoch 11.083), train_loss = 1.34711775, grad/param norm = 1.7504e-01, time/batch = 0.6403s	
5775/26050 (epoch 11.084), train_loss = 1.36211008, grad/param norm = 1.8323e-01, time/batch = 0.6400s	
5776/26050 (epoch 11.086), train_loss = 1.40194093, grad/param norm = 1.8508e-01, time/batch = 0.6400s	
5777/26050 (epoch 11.088), train_loss = 1.14473160, grad/param norm = 1.5775e-01, time/batch = 0.6392s	
5778/26050 (epoch 11.090), train_loss = 1.33513970, grad/param norm = 1.8323e-01, time/batch = 0.6443s	
5779/26050 (epoch 11.092), train_loss = 1.28704146, grad/param norm = 1.7333e-01, time/batch = 0.6408s	
5780/26050 (epoch 11.094), train_loss = 1.23857263, grad/param norm = 1.7377e-01, time/batch = 0.6417s	
5781/26050 (epoch 11.096), train_loss = 1.21811690, grad/param norm = 1.6603e-01, time/batch = 0.6430s	
5782/26050 (epoch 11.098), train_loss = 1.22256152, grad/param norm = 1.7253e-01, time/batch = 0.6407s	
5783/26050 (epoch 11.100), train_loss = 1.14686046, grad/param norm = 1.7574e-01, time/batch = 0.6577s	
5784/26050 (epoch 11.102), train_loss = 1.27996801, grad/param norm = 1.7608e-01, time/batch = 0.6730s	
5785/26050 (epoch 11.104), train_loss = 1.27146068, grad/param norm = 1.7477e-01, time/batch = 0.6798s	
5786/26050 (epoch 11.106), train_loss = 1.23607162, grad/param norm = 1.7763e-01, time/batch = 0.6763s	
5787/26050 (epoch 11.107), train_loss = 1.02741566, grad/param norm = 1.6344e-01, time/batch = 0.6788s	
5788/26050 (epoch 11.109), train_loss = 1.18182585, grad/param norm = 1.7277e-01, time/batch = 0.6613s	
5789/26050 (epoch 11.111), train_loss = 1.45847327, grad/param norm = 1.9739e-01, time/batch = 0.6538s	
5790/26050 (epoch 11.113), train_loss = 1.18489989, grad/param norm = 1.6686e-01, time/batch = 0.6384s	
5791/26050 (epoch 11.115), train_loss = 1.35034976, grad/param norm = 1.7996e-01, time/batch = 0.6388s	
5792/26050 (epoch 11.117), train_loss = 1.31084182, grad/param norm = 1.8124e-01, time/batch = 0.6398s	
5793/26050 (epoch 11.119), train_loss = 1.03689424, grad/param norm = 1.5386e-01, time/batch = 0.6479s	
5794/26050 (epoch 11.121), train_loss = 1.30724915, grad/param norm = 1.7006e-01, time/batch = 0.6465s	
5795/26050 (epoch 11.123), train_loss = 1.15515719, grad/param norm = 1.8130e-01, time/batch = 0.6640s	
5796/26050 (epoch 11.125), train_loss = 1.06296584, grad/param norm = 1.5233e-01, time/batch = 0.6795s	
5797/26050 (epoch 11.127), train_loss = 1.01623613, grad/param norm = 1.5917e-01, time/batch = 0.6421s	
5798/26050 (epoch 11.129), train_loss = 1.05217106, grad/param norm = 1.5005e-01, time/batch = 0.6396s	
5799/26050 (epoch 11.131), train_loss = 1.22902086, grad/param norm = 1.7313e-01, time/batch = 0.6395s	
5800/26050 (epoch 11.132), train_loss = 1.20653205, grad/param norm = 1.6420e-01, time/batch = 0.6384s	
5801/26050 (epoch 11.134), train_loss = 1.21541852, grad/param norm = 1.6725e-01, time/batch = 0.6395s	
5802/26050 (epoch 11.136), train_loss = 1.24204951, grad/param norm = 1.7123e-01, time/batch = 0.6400s	
5803/26050 (epoch 11.138), train_loss = 1.04658843, grad/param norm = 1.7073e-01, time/batch = 0.6432s	
5804/26050 (epoch 11.140), train_loss = 1.10736907, grad/param norm = 1.6733e-01, time/batch = 0.6395s	
5805/26050 (epoch 11.142), train_loss = 1.15844439, grad/param norm = 1.7056e-01, time/batch = 0.6401s	
5806/26050 (epoch 11.144), train_loss = 1.06276149, grad/param norm = 1.5347e-01, time/batch = 0.6389s	
5807/26050 (epoch 11.146), train_loss = 0.97566008, grad/param norm = 1.6062e-01, time/batch = 0.6391s	
5808/26050 (epoch 11.148), train_loss = 0.99086233, grad/param norm = 1.3391e-01, time/batch = 0.6397s	
5809/26050 (epoch 11.150), train_loss = 1.21880540, grad/param norm = 1.8298e-01, time/batch = 0.6390s	
5810/26050 (epoch 11.152), train_loss = 1.47063235, grad/param norm = 1.9590e-01, time/batch = 0.6424s	
5811/26050 (epoch 11.154), train_loss = 1.03187019, grad/param norm = 1.7318e-01, time/batch = 0.6413s	
5812/26050 (epoch 11.155), train_loss = 1.05240857, grad/param norm = 1.5908e-01, time/batch = 0.6390s	
5813/26050 (epoch 11.157), train_loss = 1.20323906, grad/param norm = 1.8620e-01, time/batch = 0.6389s	
5814/26050 (epoch 11.159), train_loss = 1.21313805, grad/param norm = 1.8301e-01, time/batch = 0.6406s	
5815/26050 (epoch 11.161), train_loss = 1.36789764, grad/param norm = 1.9136e-01, time/batch = 0.6473s	
5816/26050 (epoch 11.163), train_loss = 1.06903873, grad/param norm = 1.6604e-01, time/batch = 0.6560s	
5817/26050 (epoch 11.165), train_loss = 0.94498883, grad/param norm = 1.5002e-01, time/batch = 0.6434s	
5818/26050 (epoch 11.167), train_loss = 1.34137938, grad/param norm = 1.9064e-01, time/batch = 0.6456s	
5819/26050 (epoch 11.169), train_loss = 1.30247879, grad/param norm = 1.7201e-01, time/batch = 0.6392s	
5820/26050 (epoch 11.171), train_loss = 1.01647922, grad/param norm = 1.4350e-01, time/batch = 0.6404s	
5821/26050 (epoch 11.173), train_loss = 1.16740859, grad/param norm = 1.7727e-01, time/batch = 0.6406s	
5822/26050 (epoch 11.175), train_loss = 1.25366072, grad/param norm = 1.7599e-01, time/batch = 0.6407s	
5823/26050 (epoch 11.177), train_loss = 1.32907852, grad/param norm = 1.6753e-01, time/batch = 0.6386s	
5824/26050 (epoch 11.179), train_loss = 0.97360726, grad/param norm = 1.5394e-01, time/batch = 0.6392s	
5825/26050 (epoch 11.180), train_loss = 1.49850610, grad/param norm = 1.7788e-01, time/batch = 0.6394s	
5826/26050 (epoch 11.182), train_loss = 1.50587718, grad/param norm = 1.9580e-01, time/batch = 0.6398s	
5827/26050 (epoch 11.184), train_loss = 1.25248130, grad/param norm = 1.6490e-01, time/batch = 0.6404s	
5828/26050 (epoch 11.186), train_loss = 1.02444691, grad/param norm = 1.5221e-01, time/batch = 0.6379s	
5829/26050 (epoch 11.188), train_loss = 1.23181184, grad/param norm = 1.6429e-01, time/batch = 0.6377s	
5830/26050 (epoch 11.190), train_loss = 1.28743701, grad/param norm = 1.7856e-01, time/batch = 0.6398s	
5831/26050 (epoch 11.192), train_loss = 1.27981087, grad/param norm = 1.7249e-01, time/batch = 0.6383s	
5832/26050 (epoch 11.194), train_loss = 1.26799238, grad/param norm = 1.7049e-01, time/batch = 0.6411s	
5833/26050 (epoch 11.196), train_loss = 1.33299704, grad/param norm = 1.8761e-01, time/batch = 0.6462s	
5834/26050 (epoch 11.198), train_loss = 1.15794455, grad/param norm = 1.6095e-01, time/batch = 0.6472s	
5835/26050 (epoch 11.200), train_loss = 1.15283064, grad/param norm = 1.7154e-01, time/batch = 0.6390s	
5836/26050 (epoch 11.202), train_loss = 1.18279442, grad/param norm = 1.7064e-01, time/batch = 0.6388s	
5837/26050 (epoch 11.203), train_loss = 1.33194728, grad/param norm = 1.8254e-01, time/batch = 0.6380s	
5838/26050 (epoch 11.205), train_loss = 1.13984332, grad/param norm = 1.6225e-01, time/batch = 0.6388s	
5839/26050 (epoch 11.207), train_loss = 1.20924422, grad/param norm = 1.6716e-01, time/batch = 0.6424s	
5840/26050 (epoch 11.209), train_loss = 1.23110308, grad/param norm = 1.6766e-01, time/batch = 0.6385s	
5841/26050 (epoch 11.211), train_loss = 1.07387895, grad/param norm = 1.7209e-01, time/batch = 0.6417s	
5842/26050 (epoch 11.213), train_loss = 1.27820793, grad/param norm = 1.7247e-01, time/batch = 0.6414s	
5843/26050 (epoch 11.215), train_loss = 1.25246186, grad/param norm = 1.8615e-01, time/batch = 0.6382s	
5844/26050 (epoch 11.217), train_loss = 1.20890603, grad/param norm = 1.6483e-01, time/batch = 0.6393s	
5845/26050 (epoch 11.219), train_loss = 1.17071515, grad/param norm = 1.7925e-01, time/batch = 0.6384s	
5846/26050 (epoch 11.221), train_loss = 1.10130317, grad/param norm = 1.5948e-01, time/batch = 0.6547s	
5847/26050 (epoch 11.223), train_loss = 1.26113040, grad/param norm = 1.7032e-01, time/batch = 0.6828s	
5848/26050 (epoch 11.225), train_loss = 1.13299113, grad/param norm = 1.8498e-01, time/batch = 0.6484s	
5849/26050 (epoch 11.226), train_loss = 1.34230638, grad/param norm = 1.7846e-01, time/batch = 0.6576s	
5850/26050 (epoch 11.228), train_loss = 1.37289381, grad/param norm = 1.7717e-01, time/batch = 0.6679s	
5851/26050 (epoch 11.230), train_loss = 1.28115553, grad/param norm = 1.7313e-01, time/batch = 0.6616s	
5852/26050 (epoch 11.232), train_loss = 1.35272321, grad/param norm = 1.8210e-01, time/batch = 0.6588s	
5853/26050 (epoch 11.234), train_loss = 1.07567996, grad/param norm = 1.6635e-01, time/batch = 0.6540s	
5854/26050 (epoch 11.236), train_loss = 1.32749260, grad/param norm = 1.8842e-01, time/batch = 0.6581s	
5855/26050 (epoch 11.238), train_loss = 1.05477937, grad/param norm = 1.6520e-01, time/batch = 0.6615s	
5856/26050 (epoch 11.240), train_loss = 1.19520714, grad/param norm = 1.7747e-01, time/batch = 0.6749s	
5857/26050 (epoch 11.242), train_loss = 1.22690146, grad/param norm = 1.6002e-01, time/batch = 0.6591s	
5858/26050 (epoch 11.244), train_loss = 1.27897612, grad/param norm = 1.9844e-01, time/batch = 0.6545s	
5859/26050 (epoch 11.246), train_loss = 1.15284557, grad/param norm = 1.6042e-01, time/batch = 0.6590s	
5860/26050 (epoch 11.248), train_loss = 1.25221881, grad/param norm = 1.6838e-01, time/batch = 0.6592s	
5861/26050 (epoch 11.250), train_loss = 1.24137807, grad/param norm = 1.8756e-01, time/batch = 0.6612s	
5862/26050 (epoch 11.251), train_loss = 1.14741230, grad/param norm = 1.6765e-01, time/batch = 0.6603s	
5863/26050 (epoch 11.253), train_loss = 1.06133830, grad/param norm = 1.6546e-01, time/batch = 0.6614s	
5864/26050 (epoch 11.255), train_loss = 1.45417506, grad/param norm = 1.7744e-01, time/batch = 0.6570s	
5865/26050 (epoch 11.257), train_loss = 1.23581953, grad/param norm = 1.8972e-01, time/batch = 0.6531s	
5866/26050 (epoch 11.259), train_loss = 1.37694907, grad/param norm = 1.7344e-01, time/batch = 0.6402s	
5867/26050 (epoch 11.261), train_loss = 1.14893845, grad/param norm = 1.8688e-01, time/batch = 0.6435s	
5868/26050 (epoch 11.263), train_loss = 1.24838296, grad/param norm = 1.7683e-01, time/batch = 0.6401s	
5869/26050 (epoch 11.265), train_loss = 1.41304207, grad/param norm = 1.7790e-01, time/batch = 0.6396s	
5870/26050 (epoch 11.267), train_loss = 1.32252862, grad/param norm = 1.7409e-01, time/batch = 0.6470s	
5871/26050 (epoch 11.269), train_loss = 1.42830174, grad/param norm = 1.9750e-01, time/batch = 0.6461s	
5872/26050 (epoch 11.271), train_loss = 1.29969877, grad/param norm = 1.8515e-01, time/batch = 0.6671s	
5873/26050 (epoch 11.273), train_loss = 1.20457780, grad/param norm = 1.9953e-01, time/batch = 0.6772s	
5874/26050 (epoch 11.274), train_loss = 1.19206866, grad/param norm = 1.7195e-01, time/batch = 0.6547s	
5875/26050 (epoch 11.276), train_loss = 1.16030728, grad/param norm = 1.7653e-01, time/batch = 0.6537s	
5876/26050 (epoch 11.278), train_loss = 1.35173993, grad/param norm = 1.7467e-01, time/batch = 0.6510s	
5877/26050 (epoch 11.280), train_loss = 1.22193070, grad/param norm = 1.6826e-01, time/batch = 0.6530s	
5878/26050 (epoch 11.282), train_loss = 1.28060393, grad/param norm = 1.7937e-01, time/batch = 0.6420s	
5879/26050 (epoch 11.284), train_loss = 1.14115538, grad/param norm = 1.7013e-01, time/batch = 0.6418s	
5880/26050 (epoch 11.286), train_loss = 1.23252981, grad/param norm = 1.7365e-01, time/batch = 0.6530s	
5881/26050 (epoch 11.288), train_loss = 1.05182794, grad/param norm = 1.4475e-01, time/batch = 0.6442s	
5882/26050 (epoch 11.290), train_loss = 1.20657280, grad/param norm = 1.7257e-01, time/batch = 0.6421s	
5883/26050 (epoch 11.292), train_loss = 1.14869743, grad/param norm = 1.6755e-01, time/batch = 0.6424s	
5884/26050 (epoch 11.294), train_loss = 1.26783375, grad/param norm = 1.9482e-01, time/batch = 0.6423s	
5885/26050 (epoch 11.296), train_loss = 1.36311172, grad/param norm = 1.7557e-01, time/batch = 0.6436s	
5886/26050 (epoch 11.298), train_loss = 1.22954399, grad/param norm = 1.6575e-01, time/batch = 0.6413s	
5887/26050 (epoch 11.299), train_loss = 0.98746492, grad/param norm = 1.4629e-01, time/batch = 0.6418s	
5888/26050 (epoch 11.301), train_loss = 1.15500085, grad/param norm = 1.7535e-01, time/batch = 0.6420s	
5889/26050 (epoch 11.303), train_loss = 1.27135676, grad/param norm = 1.7710e-01, time/batch = 0.6485s	
5890/26050 (epoch 11.305), train_loss = 1.06991982, grad/param norm = 1.6608e-01, time/batch = 0.6397s	
5891/26050 (epoch 11.307), train_loss = 1.13326482, grad/param norm = 1.7164e-01, time/batch = 0.6401s	
5892/26050 (epoch 11.309), train_loss = 1.20270963, grad/param norm = 1.7498e-01, time/batch = 0.6395s	
5893/26050 (epoch 11.311), train_loss = 1.38737597, grad/param norm = 1.9241e-01, time/batch = 0.6402s	
5894/26050 (epoch 11.313), train_loss = 1.23409009, grad/param norm = 1.8935e-01, time/batch = 0.6446s	
5895/26050 (epoch 11.315), train_loss = 1.35956798, grad/param norm = 1.8383e-01, time/batch = 0.6421s	
5896/26050 (epoch 11.317), train_loss = 1.18318568, grad/param norm = 1.6592e-01, time/batch = 0.6421s	
5897/26050 (epoch 11.319), train_loss = 1.17780689, grad/param norm = 1.6373e-01, time/batch = 0.6406s	
5898/26050 (epoch 11.321), train_loss = 1.19339463, grad/param norm = 1.7961e-01, time/batch = 0.6391s	
5899/26050 (epoch 11.322), train_loss = 1.25836555, grad/param norm = 1.7254e-01, time/batch = 0.6387s	
5900/26050 (epoch 11.324), train_loss = 1.05272728, grad/param norm = 1.7219e-01, time/batch = 0.6382s	
5901/26050 (epoch 11.326), train_loss = 1.39371264, grad/param norm = 1.8350e-01, time/batch = 0.6412s	
5902/26050 (epoch 11.328), train_loss = 1.27865400, grad/param norm = 1.7291e-01, time/batch = 0.6401s	
5903/26050 (epoch 11.330), train_loss = 1.12901861, grad/param norm = 1.7062e-01, time/batch = 0.6715s	
5904/26050 (epoch 11.332), train_loss = 1.32802618, grad/param norm = 1.7631e-01, time/batch = 0.6697s	
5905/26050 (epoch 11.334), train_loss = 1.20182821, grad/param norm = 1.7303e-01, time/batch = 0.6375s	
5906/26050 (epoch 11.336), train_loss = 1.12897771, grad/param norm = 1.5580e-01, time/batch = 0.6493s	
5907/26050 (epoch 11.338), train_loss = 1.10393981, grad/param norm = 1.5970e-01, time/batch = 0.6443s	
5908/26050 (epoch 11.340), train_loss = 1.33383171, grad/param norm = 1.8523e-01, time/batch = 0.6434s	
5909/26050 (epoch 11.342), train_loss = 1.38441702, grad/param norm = 1.8128e-01, time/batch = 0.6383s	
5910/26050 (epoch 11.344), train_loss = 1.23225468, grad/param norm = 1.8455e-01, time/batch = 0.6443s	
5911/26050 (epoch 11.345), train_loss = 1.21593703, grad/param norm = 1.7893e-01, time/batch = 0.6429s	
5912/26050 (epoch 11.347), train_loss = 1.32145158, grad/param norm = 1.8513e-01, time/batch = 0.6472s	
5913/26050 (epoch 11.349), train_loss = 1.27153916, grad/param norm = 1.7812e-01, time/batch = 0.6445s	
5914/26050 (epoch 11.351), train_loss = 1.25655335, grad/param norm = 1.8036e-01, time/batch = 0.6424s	
5915/26050 (epoch 11.353), train_loss = 1.18550000, grad/param norm = 1.8510e-01, time/batch = 0.6396s	
5916/26050 (epoch 11.355), train_loss = 1.31134929, grad/param norm = 1.8555e-01, time/batch = 0.6387s	
5917/26050 (epoch 11.357), train_loss = 1.10174345, grad/param norm = 1.5844e-01, time/batch = 0.6382s	
5918/26050 (epoch 11.359), train_loss = 1.31919468, grad/param norm = 1.7318e-01, time/batch = 0.6407s	
5919/26050 (epoch 11.361), train_loss = 1.16531613, grad/param norm = 1.7004e-01, time/batch = 0.6403s	
5920/26050 (epoch 11.363), train_loss = 1.28199198, grad/param norm = 1.6355e-01, time/batch = 0.6384s	
5921/26050 (epoch 11.365), train_loss = 1.18122440, grad/param norm = 1.5432e-01, time/batch = 0.6409s	
5922/26050 (epoch 11.367), train_loss = 1.23277878, grad/param norm = 1.7424e-01, time/batch = 0.6411s	
5923/26050 (epoch 11.369), train_loss = 1.20672070, grad/param norm = 1.5783e-01, time/batch = 0.6384s	
5924/26050 (epoch 11.370), train_loss = 1.12053324, grad/param norm = 1.5411e-01, time/batch = 0.6391s	
5925/26050 (epoch 11.372), train_loss = 1.31518614, grad/param norm = 1.8785e-01, time/batch = 0.6405s	
5926/26050 (epoch 11.374), train_loss = 1.42736967, grad/param norm = 1.8382e-01, time/batch = 0.6464s	
5927/26050 (epoch 11.376), train_loss = 1.44636041, grad/param norm = 1.8060e-01, time/batch = 0.6437s	
5928/26050 (epoch 11.378), train_loss = 1.21017007, grad/param norm = 1.7419e-01, time/batch = 0.6392s	
5929/26050 (epoch 11.380), train_loss = 1.45383115, grad/param norm = 2.0190e-01, time/batch = 0.6402s	
5930/26050 (epoch 11.382), train_loss = 1.59446226, grad/param norm = 2.1945e-01, time/batch = 0.6379s	
5931/26050 (epoch 11.384), train_loss = 1.19810799, grad/param norm = 1.6358e-01, time/batch = 0.6391s	
5932/26050 (epoch 11.386), train_loss = 1.35403532, grad/param norm = 1.8534e-01, time/batch = 0.6399s	
5933/26050 (epoch 11.388), train_loss = 1.28508027, grad/param norm = 1.7934e-01, time/batch = 0.6471s	
5934/26050 (epoch 11.390), train_loss = 1.11621294, grad/param norm = 1.4983e-01, time/batch = 0.6404s	
5935/26050 (epoch 11.392), train_loss = 1.12955256, grad/param norm = 1.5868e-01, time/batch = 0.6397s	
5936/26050 (epoch 11.393), train_loss = 1.30247256, grad/param norm = 1.6822e-01, time/batch = 0.6396s	
5937/26050 (epoch 11.395), train_loss = 1.30964881, grad/param norm = 1.7081e-01, time/batch = 0.6381s	
5938/26050 (epoch 11.397), train_loss = 1.30369549, grad/param norm = 1.9057e-01, time/batch = 0.6453s	
5939/26050 (epoch 11.399), train_loss = 1.11104362, grad/param norm = 1.5576e-01, time/batch = 0.6827s	
5940/26050 (epoch 11.401), train_loss = 1.19830467, grad/param norm = 1.5195e-01, time/batch = 0.6549s	
5941/26050 (epoch 11.403), train_loss = 1.24668893, grad/param norm = 1.5788e-01, time/batch = 0.6668s	
5942/26050 (epoch 11.405), train_loss = 1.22759593, grad/param norm = 1.7618e-01, time/batch = 0.6514s	
5943/26050 (epoch 11.407), train_loss = 1.38686315, grad/param norm = 1.8143e-01, time/batch = 0.6657s	
5944/26050 (epoch 11.409), train_loss = 1.42862443, grad/param norm = 1.9264e-01, time/batch = 0.6576s	
5945/26050 (epoch 11.411), train_loss = 1.28489807, grad/param norm = 1.8077e-01, time/batch = 0.6451s	
5946/26050 (epoch 11.413), train_loss = 1.38395239, grad/param norm = 1.6238e-01, time/batch = 0.6409s	
5947/26050 (epoch 11.415), train_loss = 1.36910323, grad/param norm = 1.8639e-01, time/batch = 0.6405s	
5948/26050 (epoch 11.417), train_loss = 1.48359480, grad/param norm = 1.9073e-01, time/batch = 0.6398s	
5949/26050 (epoch 11.418), train_loss = 1.34830008, grad/param norm = 1.9001e-01, time/batch = 0.6487s	
5950/26050 (epoch 11.420), train_loss = 1.06177206, grad/param norm = 1.4978e-01, time/batch = 0.6527s	
5951/26050 (epoch 11.422), train_loss = 1.10894118, grad/param norm = 1.6945e-01, time/batch = 0.6407s	
5952/26050 (epoch 11.424), train_loss = 1.44030900, grad/param norm = 2.0757e-01, time/batch = 0.6542s	
5953/26050 (epoch 11.426), train_loss = 1.39781822, grad/param norm = 1.8381e-01, time/batch = 0.6564s	
5954/26050 (epoch 11.428), train_loss = 1.14850963, grad/param norm = 1.5054e-01, time/batch = 0.6798s	
5955/26050 (epoch 11.430), train_loss = 1.30133543, grad/param norm = 1.7437e-01, time/batch = 0.6641s	
5956/26050 (epoch 11.432), train_loss = 1.18560893, grad/param norm = 1.6826e-01, time/batch = 0.6413s	
5957/26050 (epoch 11.434), train_loss = 1.26383888, grad/param norm = 1.8490e-01, time/batch = 0.6512s	
5958/26050 (epoch 11.436), train_loss = 1.36776491, grad/param norm = 1.6362e-01, time/batch = 0.6414s	
5959/26050 (epoch 11.438), train_loss = 1.14680755, grad/param norm = 1.6720e-01, time/batch = 0.6411s	
5960/26050 (epoch 11.440), train_loss = 1.28609946, grad/param norm = 1.7353e-01, time/batch = 0.6404s	
5961/26050 (epoch 11.441), train_loss = 1.25201102, grad/param norm = 1.5687e-01, time/batch = 0.6423s	
5962/26050 (epoch 11.443), train_loss = 1.05412427, grad/param norm = 1.4960e-01, time/batch = 0.6481s	
5963/26050 (epoch 11.445), train_loss = 1.11794600, grad/param norm = 1.7330e-01, time/batch = 0.6497s	
5964/26050 (epoch 11.447), train_loss = 1.44002869, grad/param norm = 1.8663e-01, time/batch = 0.6491s	
5965/26050 (epoch 11.449), train_loss = 1.14412491, grad/param norm = 1.7260e-01, time/batch = 0.6429s	
5966/26050 (epoch 11.451), train_loss = 1.36870028, grad/param norm = 1.7386e-01, time/batch = 0.6419s	
5967/26050 (epoch 11.453), train_loss = 1.15477267, grad/param norm = 1.6153e-01, time/batch = 0.6419s	
5968/26050 (epoch 11.455), train_loss = 1.28150972, grad/param norm = 1.6892e-01, time/batch = 0.6421s	
5969/26050 (epoch 11.457), train_loss = 1.26027120, grad/param norm = 1.6993e-01, time/batch = 0.6638s	
5970/26050 (epoch 11.459), train_loss = 1.36875752, grad/param norm = 1.7935e-01, time/batch = 0.6807s	
5971/26050 (epoch 11.461), train_loss = 1.31779617, grad/param norm = 1.8740e-01, time/batch = 0.6457s	
5972/26050 (epoch 11.463), train_loss = 1.17723598, grad/param norm = 1.5152e-01, time/batch = 0.6425s	
5973/26050 (epoch 11.464), train_loss = 1.32718566, grad/param norm = 1.8321e-01, time/batch = 0.6428s	
5974/26050 (epoch 11.466), train_loss = 1.32581039, grad/param norm = 1.8065e-01, time/batch = 0.6428s	
5975/26050 (epoch 11.468), train_loss = 1.33985057, grad/param norm = 1.6213e-01, time/batch = 0.6442s	
5976/26050 (epoch 11.470), train_loss = 1.46290064, grad/param norm = 1.9636e-01, time/batch = 0.6436s	
5977/26050 (epoch 11.472), train_loss = 1.41903871, grad/param norm = 1.8271e-01, time/batch = 0.6408s	
5978/26050 (epoch 11.474), train_loss = 1.48645046, grad/param norm = 1.7852e-01, time/batch = 0.6428s	
5979/26050 (epoch 11.476), train_loss = 1.35189040, grad/param norm = 1.7100e-01, time/batch = 0.6420s	
5980/26050 (epoch 11.478), train_loss = 1.16192762, grad/param norm = 1.4944e-01, time/batch = 0.6512s	
5981/26050 (epoch 11.480), train_loss = 1.28059842, grad/param norm = 1.6291e-01, time/batch = 0.6529s	
5982/26050 (epoch 11.482), train_loss = 1.21408537, grad/param norm = 1.6503e-01, time/batch = 0.6483s	
5983/26050 (epoch 11.484), train_loss = 1.16350259, grad/param norm = 1.6203e-01, time/batch = 0.6421s	
5984/26050 (epoch 11.486), train_loss = 1.42703727, grad/param norm = 1.7476e-01, time/batch = 0.6496s	
5985/26050 (epoch 11.488), train_loss = 1.59601612, grad/param norm = 1.9447e-01, time/batch = 0.6828s	
5986/26050 (epoch 11.489), train_loss = 1.51499616, grad/param norm = 2.0424e-01, time/batch = 0.6528s	
5987/26050 (epoch 11.491), train_loss = 1.15248642, grad/param norm = 1.6234e-01, time/batch = 0.6450s	
5988/26050 (epoch 11.493), train_loss = 1.24729509, grad/param norm = 1.7198e-01, time/batch = 0.6419s	
5989/26050 (epoch 11.495), train_loss = 1.21905736, grad/param norm = 1.6499e-01, time/batch = 0.6421s	
5990/26050 (epoch 11.497), train_loss = 1.19849629, grad/param norm = 1.6694e-01, time/batch = 0.6417s	
5991/26050 (epoch 11.499), train_loss = 1.21965495, grad/param norm = 1.7359e-01, time/batch = 0.6415s	
5992/26050 (epoch 11.501), train_loss = 1.33345856, grad/param norm = 1.7814e-01, time/batch = 0.6428s	
5993/26050 (epoch 11.503), train_loss = 1.18380059, grad/param norm = 1.8704e-01, time/batch = 0.6435s	
5994/26050 (epoch 11.505), train_loss = 1.38263278, grad/param norm = 1.7479e-01, time/batch = 0.6430s	
5995/26050 (epoch 11.507), train_loss = 1.36953181, grad/param norm = 1.9450e-01, time/batch = 0.6482s	
5996/26050 (epoch 11.509), train_loss = 1.48953250, grad/param norm = 1.9310e-01, time/batch = 0.6418s	
5997/26050 (epoch 11.511), train_loss = 1.15339630, grad/param norm = 1.6408e-01, time/batch = 0.6408s	
5998/26050 (epoch 11.512), train_loss = 1.22385996, grad/param norm = 1.8241e-01, time/batch = 0.6417s	
5999/26050 (epoch 11.514), train_loss = 1.33261382, grad/param norm = 1.7945e-01, time/batch = 0.6426s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch11.52_1.5958.t7	
6000/26050 (epoch 11.516), train_loss = 1.36918974, grad/param norm = 1.8523e-01, time/batch = 0.6401s	
6001/26050 (epoch 11.518), train_loss = 1.50431425, grad/param norm = 1.9651e-01, time/batch = 0.6479s	
6002/26050 (epoch 11.520), train_loss = 1.24858289, grad/param norm = 1.5987e-01, time/batch = 0.6417s	
6003/26050 (epoch 11.522), train_loss = 1.07205470, grad/param norm = 1.6285e-01, time/batch = 0.6435s	
6004/26050 (epoch 11.524), train_loss = 1.39269145, grad/param norm = 1.8442e-01, time/batch = 0.6441s	
6005/26050 (epoch 11.526), train_loss = 1.36474806, grad/param norm = 1.7905e-01, time/batch = 0.6427s	
6006/26050 (epoch 11.528), train_loss = 1.33059192, grad/param norm = 1.8121e-01, time/batch = 0.6491s	
6007/26050 (epoch 11.530), train_loss = 1.24214167, grad/param norm = 1.5864e-01, time/batch = 0.6467s	
6008/26050 (epoch 11.532), train_loss = 1.24584289, grad/param norm = 1.5472e-01, time/batch = 0.6475s	
6009/26050 (epoch 11.534), train_loss = 1.34865680, grad/param norm = 2.2425e-01, time/batch = 0.6484s	
6010/26050 (epoch 11.536), train_loss = 1.24132384, grad/param norm = 1.6420e-01, time/batch = 0.6465s	
6011/26050 (epoch 11.537), train_loss = 1.37171123, grad/param norm = 1.9005e-01, time/batch = 0.6479s	
6012/26050 (epoch 11.539), train_loss = 1.25952879, grad/param norm = 1.7107e-01, time/batch = 0.6608s	
6013/26050 (epoch 11.541), train_loss = 1.45339205, grad/param norm = 1.9461e-01, time/batch = 0.6833s	
6014/26050 (epoch 11.543), train_loss = 1.08546764, grad/param norm = 1.6674e-01, time/batch = 0.6431s	
6015/26050 (epoch 11.545), train_loss = 1.30698192, grad/param norm = 1.6956e-01, time/batch = 0.6409s	
6016/26050 (epoch 11.547), train_loss = 1.29968619, grad/param norm = 1.7747e-01, time/batch = 0.6407s	
6017/26050 (epoch 11.549), train_loss = 1.07448460, grad/param norm = 1.6355e-01, time/batch = 0.6422s	
6018/26050 (epoch 11.551), train_loss = 1.29841060, grad/param norm = 1.7435e-01, time/batch = 0.6408s	
6019/26050 (epoch 11.553), train_loss = 1.15965918, grad/param norm = 1.5968e-01, time/batch = 0.6421s	
6020/26050 (epoch 11.555), train_loss = 1.20443418, grad/param norm = 1.6618e-01, time/batch = 0.6403s	
6021/26050 (epoch 11.557), train_loss = 1.31711682, grad/param norm = 1.6031e-01, time/batch = 0.6444s	
6022/26050 (epoch 11.559), train_loss = 1.26166048, grad/param norm = 1.6867e-01, time/batch = 0.6414s	
6023/26050 (epoch 11.560), train_loss = 1.24666576, grad/param norm = 1.7439e-01, time/batch = 0.6653s	
6024/26050 (epoch 11.562), train_loss = 1.23739566, grad/param norm = 1.7126e-01, time/batch = 0.6433s	
6025/26050 (epoch 11.564), train_loss = 1.46963312, grad/param norm = 1.7710e-01, time/batch = 0.6539s	
6026/26050 (epoch 11.566), train_loss = 1.14039658, grad/param norm = 1.6577e-01, time/batch = 0.6544s	
6027/26050 (epoch 11.568), train_loss = 1.28337562, grad/param norm = 1.7005e-01, time/batch = 0.6505s	
6028/26050 (epoch 11.570), train_loss = 1.37524837, grad/param norm = 1.8011e-01, time/batch = 0.6597s	
6029/26050 (epoch 11.572), train_loss = 1.23595266, grad/param norm = 1.6367e-01, time/batch = 0.6553s	
6030/26050 (epoch 11.574), train_loss = 1.34219228, grad/param norm = 2.0375e-01, time/batch = 0.6411s	
6031/26050 (epoch 11.576), train_loss = 1.34071884, grad/param norm = 1.8893e-01, time/batch = 0.6446s	
6032/26050 (epoch 11.578), train_loss = 1.27341033, grad/param norm = 1.8510e-01, time/batch = 0.6408s	
6033/26050 (epoch 11.580), train_loss = 1.15423417, grad/param norm = 1.7514e-01, time/batch = 0.6404s	
6034/26050 (epoch 11.582), train_loss = 1.30721571, grad/param norm = 1.7779e-01, time/batch = 0.6405s	
6035/26050 (epoch 11.583), train_loss = 1.34731392, grad/param norm = 1.7441e-01, time/batch = 0.6386s	
6036/26050 (epoch 11.585), train_loss = 1.15896179, grad/param norm = 1.7380e-01, time/batch = 0.6386s	
6037/26050 (epoch 11.587), train_loss = 1.30956509, grad/param norm = 1.7448e-01, time/batch = 0.6423s	
6038/26050 (epoch 11.589), train_loss = 1.36048828, grad/param norm = 1.9079e-01, time/batch = 0.6445s	
6039/26050 (epoch 11.591), train_loss = 1.27815118, grad/param norm = 1.7562e-01, time/batch = 0.6380s	
6040/26050 (epoch 11.593), train_loss = 1.13974080, grad/param norm = 1.7476e-01, time/batch = 0.6431s	
6041/26050 (epoch 11.595), train_loss = 1.40400545, grad/param norm = 2.0147e-01, time/batch = 0.6432s	
6042/26050 (epoch 11.597), train_loss = 1.29476018, grad/param norm = 1.7391e-01, time/batch = 0.6452s	
6043/26050 (epoch 11.599), train_loss = 1.23590134, grad/param norm = 1.7335e-01, time/batch = 0.6379s	
6044/26050 (epoch 11.601), train_loss = 1.47452520, grad/param norm = 1.8379e-01, time/batch = 0.6389s	
6045/26050 (epoch 11.603), train_loss = 1.32153326, grad/param norm = 1.7284e-01, time/batch = 0.6397s	
6046/26050 (epoch 11.605), train_loss = 1.19147571, grad/param norm = 1.6399e-01, time/batch = 0.6411s	
6047/26050 (epoch 11.607), train_loss = 1.41729902, grad/param norm = 1.8879e-01, time/batch = 0.6410s	
6048/26050 (epoch 11.608), train_loss = 1.17420313, grad/param norm = 1.5613e-01, time/batch = 0.6416s	
6049/26050 (epoch 11.610), train_loss = 1.24698822, grad/param norm = 1.8036e-01, time/batch = 0.6403s	
6050/26050 (epoch 11.612), train_loss = 1.25152276, grad/param norm = 1.7443e-01, time/batch = 0.6385s	
6051/26050 (epoch 11.614), train_loss = 1.34614504, grad/param norm = 1.7466e-01, time/batch = 0.6388s	
6052/26050 (epoch 11.616), train_loss = 1.51230542, grad/param norm = 1.9870e-01, time/batch = 0.6401s	
6053/26050 (epoch 11.618), train_loss = 1.20342274, grad/param norm = 1.7232e-01, time/batch = 0.6404s	
6054/26050 (epoch 11.620), train_loss = 1.28942707, grad/param norm = 1.7960e-01, time/batch = 0.6710s	
6055/26050 (epoch 11.622), train_loss = 1.07747359, grad/param norm = 1.5083e-01, time/batch = 0.6713s	
6056/26050 (epoch 11.624), train_loss = 1.12922501, grad/param norm = 1.6402e-01, time/batch = 0.6416s	
6057/26050 (epoch 11.626), train_loss = 1.33098234, grad/param norm = 1.7860e-01, time/batch = 0.6426s	
6058/26050 (epoch 11.628), train_loss = 1.22034008, grad/param norm = 1.8832e-01, time/batch = 0.6402s	
6059/26050 (epoch 11.630), train_loss = 1.40129769, grad/param norm = 1.7377e-01, time/batch = 0.6385s	
6060/26050 (epoch 11.631), train_loss = 1.42524795, grad/param norm = 1.8660e-01, time/batch = 0.6381s	
6061/26050 (epoch 11.633), train_loss = 1.17927868, grad/param norm = 1.7457e-01, time/batch = 0.6419s	
6062/26050 (epoch 11.635), train_loss = 1.16748901, grad/param norm = 1.5461e-01, time/batch = 0.6499s	
6063/26050 (epoch 11.637), train_loss = 1.15520644, grad/param norm = 1.7557e-01, time/batch = 0.6397s	
6064/26050 (epoch 11.639), train_loss = 1.36648652, grad/param norm = 1.6853e-01, time/batch = 0.6404s	
6065/26050 (epoch 11.641), train_loss = 1.20613161, grad/param norm = 1.5597e-01, time/batch = 0.6395s	
6066/26050 (epoch 11.643), train_loss = 1.12044178, grad/param norm = 1.5239e-01, time/batch = 0.6394s	
6067/26050 (epoch 11.645), train_loss = 1.30084484, grad/param norm = 1.8459e-01, time/batch = 0.6378s	
6068/26050 (epoch 11.647), train_loss = 1.22511459, grad/param norm = 1.7351e-01, time/batch = 0.6453s	
6069/26050 (epoch 11.649), train_loss = 1.29326423, grad/param norm = 1.9429e-01, time/batch = 0.6539s	
6070/26050 (epoch 11.651), train_loss = 1.19962582, grad/param norm = 1.7788e-01, time/batch = 0.6831s	
6071/26050 (epoch 11.653), train_loss = 1.26124260, grad/param norm = 1.7216e-01, time/batch = 0.6453s	
6072/26050 (epoch 11.655), train_loss = 1.17681269, grad/param norm = 1.6591e-01, time/batch = 0.6482s	
6073/26050 (epoch 11.656), train_loss = 1.12352762, grad/param norm = 1.6446e-01, time/batch = 0.6397s	
6074/26050 (epoch 11.658), train_loss = 1.47072204, grad/param norm = 1.8135e-01, time/batch = 0.6423s	
6075/26050 (epoch 11.660), train_loss = 1.14099083, grad/param norm = 1.7187e-01, time/batch = 0.6384s	
6076/26050 (epoch 11.662), train_loss = 1.14127616, grad/param norm = 1.5731e-01, time/batch = 0.6368s	
6077/26050 (epoch 11.664), train_loss = 1.23028736, grad/param norm = 1.7483e-01, time/batch = 0.6382s	
6078/26050 (epoch 11.666), train_loss = 1.26660383, grad/param norm = 1.8222e-01, time/batch = 0.6404s	
6079/26050 (epoch 11.668), train_loss = 1.05055485, grad/param norm = 1.6087e-01, time/batch = 0.6402s	
6080/26050 (epoch 11.670), train_loss = 1.41037692, grad/param norm = 1.8437e-01, time/batch = 0.6420s	
6081/26050 (epoch 11.672), train_loss = 1.19029199, grad/param norm = 1.6539e-01, time/batch = 0.6396s	
6082/26050 (epoch 11.674), train_loss = 1.14419914, grad/param norm = 1.7139e-01, time/batch = 0.6401s	
6083/26050 (epoch 11.676), train_loss = 1.28936962, grad/param norm = 1.6980e-01, time/batch = 0.6401s	
6084/26050 (epoch 11.678), train_loss = 1.39665313, grad/param norm = 1.7734e-01, time/batch = 0.6414s	
6085/26050 (epoch 11.679), train_loss = 1.48049736, grad/param norm = 1.9814e-01, time/batch = 0.6795s	
6086/26050 (epoch 11.681), train_loss = 1.27588885, grad/param norm = 1.7099e-01, time/batch = 0.6726s	
6087/26050 (epoch 11.683), train_loss = 1.16145637, grad/param norm = 2.0809e-01, time/batch = 0.6557s	
6088/26050 (epoch 11.685), train_loss = 1.19758723, grad/param norm = 1.5352e-01, time/batch = 0.6584s	
6089/26050 (epoch 11.687), train_loss = 1.06641138, grad/param norm = 1.5950e-01, time/batch = 0.6546s	
6090/26050 (epoch 11.689), train_loss = 1.23108203, grad/param norm = 1.7307e-01, time/batch = 0.6503s	
6091/26050 (epoch 11.691), train_loss = 0.98728654, grad/param norm = 1.5499e-01, time/batch = 0.6450s	
6092/26050 (epoch 11.693), train_loss = 1.16517505, grad/param norm = 1.7082e-01, time/batch = 0.6574s	
6093/26050 (epoch 11.695), train_loss = 1.26507884, grad/param norm = 1.7403e-01, time/batch = 0.6564s	
6094/26050 (epoch 11.697), train_loss = 1.14766463, grad/param norm = 1.7060e-01, time/batch = 0.6548s	
6095/26050 (epoch 11.699), train_loss = 1.32656269, grad/param norm = 1.8466e-01, time/batch = 0.6577s	
6096/26050 (epoch 11.701), train_loss = 1.09083969, grad/param norm = 1.5241e-01, time/batch = 0.6616s	
6097/26050 (epoch 11.702), train_loss = 1.45429331, grad/param norm = 1.8852e-01, time/batch = 0.6407s	
6098/26050 (epoch 11.704), train_loss = 1.29568212, grad/param norm = 1.7236e-01, time/batch = 0.6398s	
6099/26050 (epoch 11.706), train_loss = 1.30341217, grad/param norm = 1.9871e-01, time/batch = 0.6394s	
6100/26050 (epoch 11.708), train_loss = 1.33129741, grad/param norm = 1.7926e-01, time/batch = 0.6405s	
6101/26050 (epoch 11.710), train_loss = 1.31056028, grad/param norm = 1.7462e-01, time/batch = 0.6419s	
6102/26050 (epoch 11.712), train_loss = 1.38700079, grad/param norm = 1.7760e-01, time/batch = 0.6461s	
6103/26050 (epoch 11.714), train_loss = 1.10682773, grad/param norm = 1.7263e-01, time/batch = 0.6438s	
6104/26050 (epoch 11.716), train_loss = 1.53533618, grad/param norm = 2.1187e-01, time/batch = 0.6411s	
6105/26050 (epoch 11.718), train_loss = 1.37104726, grad/param norm = 1.8706e-01, time/batch = 0.6405s	
6106/26050 (epoch 11.720), train_loss = 1.18240368, grad/param norm = 1.6839e-01, time/batch = 0.6404s	
6107/26050 (epoch 11.722), train_loss = 1.13175586, grad/param norm = 1.7121e-01, time/batch = 0.6406s	
6108/26050 (epoch 11.724), train_loss = 1.13597664, grad/param norm = 1.7105e-01, time/batch = 0.6409s	
6109/26050 (epoch 11.726), train_loss = 1.37276663, grad/param norm = 1.7439e-01, time/batch = 0.6403s	
6110/26050 (epoch 11.727), train_loss = 1.31299304, grad/param norm = 1.7453e-01, time/batch = 0.6448s	
6111/26050 (epoch 11.729), train_loss = 1.31391785, grad/param norm = 1.7170e-01, time/batch = 0.6417s	
6112/26050 (epoch 11.731), train_loss = 1.28639591, grad/param norm = 1.5853e-01, time/batch = 0.6406s	
6113/26050 (epoch 11.733), train_loss = 1.21493362, grad/param norm = 1.9711e-01, time/batch = 0.6396s	
6114/26050 (epoch 11.735), train_loss = 1.44753466, grad/param norm = 1.8542e-01, time/batch = 0.6405s	
6115/26050 (epoch 11.737), train_loss = 1.24775633, grad/param norm = 1.7326e-01, time/batch = 0.6422s	
6116/26050 (epoch 11.739), train_loss = 1.30986693, grad/param norm = 1.6500e-01, time/batch = 0.6408s	
6117/26050 (epoch 11.741), train_loss = 1.16174643, grad/param norm = 1.6547e-01, time/batch = 0.6403s	
6118/26050 (epoch 11.743), train_loss = 1.33660151, grad/param norm = 2.2604e-01, time/batch = 0.6616s	
6119/26050 (epoch 11.745), train_loss = 1.13399317, grad/param norm = 1.6639e-01, time/batch = 0.6502s	
6120/26050 (epoch 11.747), train_loss = 1.14807831, grad/param norm = 1.6234e-01, time/batch = 0.6528s	
6121/26050 (epoch 11.749), train_loss = 1.39803902, grad/param norm = 1.8784e-01, time/batch = 0.6492s	
6122/26050 (epoch 11.750), train_loss = 1.25310864, grad/param norm = 1.5876e-01, time/batch = 0.6443s	
6123/26050 (epoch 11.752), train_loss = 1.24748477, grad/param norm = 1.8171e-01, time/batch = 0.6594s	
6124/26050 (epoch 11.754), train_loss = 1.27543688, grad/param norm = 1.7489e-01, time/batch = 0.6619s	
6125/26050 (epoch 11.756), train_loss = 1.28187451, grad/param norm = 1.8761e-01, time/batch = 0.6466s	
6126/26050 (epoch 11.758), train_loss = 1.27586479, grad/param norm = 1.7891e-01, time/batch = 0.6476s	
6127/26050 (epoch 11.760), train_loss = 1.37698203, grad/param norm = 1.7670e-01, time/batch = 0.6498s	
6128/26050 (epoch 11.762), train_loss = 1.16699028, grad/param norm = 1.5962e-01, time/batch = 0.6454s	
6129/26050 (epoch 11.764), train_loss = 1.34684229, grad/param norm = 1.9545e-01, time/batch = 0.6416s	
6130/26050 (epoch 11.766), train_loss = 1.35216582, grad/param norm = 1.9401e-01, time/batch = 0.6400s	
6131/26050 (epoch 11.768), train_loss = 1.12039673, grad/param norm = 1.5611e-01, time/batch = 0.6405s	
6132/26050 (epoch 11.770), train_loss = 1.24564856, grad/param norm = 1.8352e-01, time/batch = 0.6407s	
6133/26050 (epoch 11.772), train_loss = 1.23259356, grad/param norm = 1.6553e-01, time/batch = 0.6469s	
6134/26050 (epoch 11.774), train_loss = 1.11072762, grad/param norm = 1.7608e-01, time/batch = 0.6411s	
6135/26050 (epoch 11.775), train_loss = 0.95490100, grad/param norm = 1.5727e-01, time/batch = 0.6411s	
6136/26050 (epoch 11.777), train_loss = 1.15583758, grad/param norm = 1.6285e-01, time/batch = 0.6392s	
6137/26050 (epoch 11.779), train_loss = 1.23260217, grad/param norm = 1.8307e-01, time/batch = 0.6416s	
6138/26050 (epoch 11.781), train_loss = 1.19764583, grad/param norm = 1.6541e-01, time/batch = 0.6424s	
6139/26050 (epoch 11.783), train_loss = 1.15379438, grad/param norm = 1.5913e-01, time/batch = 0.6407s	
6140/26050 (epoch 11.785), train_loss = 1.20562642, grad/param norm = 1.7732e-01, time/batch = 0.6430s	
6141/26050 (epoch 11.787), train_loss = 1.17744448, grad/param norm = 1.6683e-01, time/batch = 0.6477s	
6142/26050 (epoch 11.789), train_loss = 1.20416299, grad/param norm = 1.8821e-01, time/batch = 0.6839s	
6143/26050 (epoch 11.791), train_loss = 1.23595086, grad/param norm = 1.6915e-01, time/batch = 0.6616s	
6144/26050 (epoch 11.793), train_loss = 1.22487171, grad/param norm = 1.8358e-01, time/batch = 0.6519s	
6145/26050 (epoch 11.795), train_loss = 1.06128119, grad/param norm = 1.4977e-01, time/batch = 0.6546s	
6146/26050 (epoch 11.797), train_loss = 1.17058652, grad/param norm = 1.7209e-01, time/batch = 0.6546s	
6147/26050 (epoch 11.798), train_loss = 1.11113381, grad/param norm = 1.6887e-01, time/batch = 0.6551s	
6148/26050 (epoch 11.800), train_loss = 1.08734025, grad/param norm = 1.4548e-01, time/batch = 0.6516s	
6149/26050 (epoch 11.802), train_loss = 1.21723102, grad/param norm = 1.8003e-01, time/batch = 0.6569s	
6150/26050 (epoch 11.804), train_loss = 1.20273953, grad/param norm = 1.6454e-01, time/batch = 0.6537s	
6151/26050 (epoch 11.806), train_loss = 1.33799791, grad/param norm = 1.8020e-01, time/batch = 0.6735s	
6152/26050 (epoch 11.808), train_loss = 1.20615830, grad/param norm = 1.6641e-01, time/batch = 0.6760s	
6153/26050 (epoch 11.810), train_loss = 1.17906486, grad/param norm = 1.6517e-01, time/batch = 0.6476s	
6154/26050 (epoch 11.812), train_loss = 1.12329116, grad/param norm = 1.8654e-01, time/batch = 0.6506s	
6155/26050 (epoch 11.814), train_loss = 1.10805284, grad/param norm = 1.7021e-01, time/batch = 0.6561s	
6156/26050 (epoch 11.816), train_loss = 1.33080309, grad/param norm = 1.8321e-01, time/batch = 0.6553s	
6157/26050 (epoch 11.818), train_loss = 1.39768007, grad/param norm = 2.1126e-01, time/batch = 0.6694s	
6158/26050 (epoch 11.820), train_loss = 1.26316951, grad/param norm = 1.8055e-01, time/batch = 0.6704s	
6159/26050 (epoch 11.821), train_loss = 1.40746209, grad/param norm = 2.0367e-01, time/batch = 0.6812s	
6160/26050 (epoch 11.823), train_loss = 1.43200709, grad/param norm = 1.8458e-01, time/batch = 0.6524s	
6161/26050 (epoch 11.825), train_loss = 1.22782781, grad/param norm = 2.0056e-01, time/batch = 0.6416s	
6162/26050 (epoch 11.827), train_loss = 1.27554353, grad/param norm = 1.8542e-01, time/batch = 0.6414s	
6163/26050 (epoch 11.829), train_loss = 1.30049648, grad/param norm = 1.8366e-01, time/batch = 0.6432s	
6164/26050 (epoch 11.831), train_loss = 1.37984717, grad/param norm = 1.7493e-01, time/batch = 0.6438s	
6165/26050 (epoch 11.833), train_loss = 1.45158613, grad/param norm = 1.7628e-01, time/batch = 0.6461s	
6166/26050 (epoch 11.835), train_loss = 1.47606697, grad/param norm = 1.9082e-01, time/batch = 0.6420s	
6167/26050 (epoch 11.837), train_loss = 1.21548567, grad/param norm = 1.7457e-01, time/batch = 0.6408s	
6168/26050 (epoch 11.839), train_loss = 1.31624009, grad/param norm = 1.9785e-01, time/batch = 0.6407s	
6169/26050 (epoch 11.841), train_loss = 1.37775816, grad/param norm = 1.7801e-01, time/batch = 0.6395s	
6170/26050 (epoch 11.843), train_loss = 1.28703779, grad/param norm = 1.8185e-01, time/batch = 0.6410s	
6171/26050 (epoch 11.845), train_loss = 1.17751525, grad/param norm = 1.6065e-01, time/batch = 0.6593s	
6172/26050 (epoch 11.846), train_loss = 1.38026090, grad/param norm = 1.7875e-01, time/batch = 0.6741s	
6173/26050 (epoch 11.848), train_loss = 1.20385561, grad/param norm = 1.6163e-01, time/batch = 0.6801s	
6174/26050 (epoch 11.850), train_loss = 1.19061333, grad/param norm = 1.7436e-01, time/batch = 0.6416s	
6175/26050 (epoch 11.852), train_loss = 1.22202077, grad/param norm = 1.7321e-01, time/batch = 0.6414s	
6176/26050 (epoch 11.854), train_loss = 1.24158591, grad/param norm = 1.6725e-01, time/batch = 0.6461s	
6177/26050 (epoch 11.856), train_loss = 1.19074269, grad/param norm = 1.9074e-01, time/batch = 0.6437s	
6178/26050 (epoch 11.858), train_loss = 1.12242299, grad/param norm = 1.7145e-01, time/batch = 0.6393s	
6179/26050 (epoch 11.860), train_loss = 1.29888239, grad/param norm = 1.8786e-01, time/batch = 0.6445s	
6180/26050 (epoch 11.862), train_loss = 1.26308289, grad/param norm = 1.7505e-01, time/batch = 0.6555s	
6181/26050 (epoch 11.864), train_loss = 1.25866989, grad/param norm = 1.8670e-01, time/batch = 0.6412s	
6182/26050 (epoch 11.866), train_loss = 1.17884386, grad/param norm = 1.5856e-01, time/batch = 0.6402s	
6183/26050 (epoch 11.868), train_loss = 1.34995582, grad/param norm = 1.9030e-01, time/batch = 0.6407s	
6184/26050 (epoch 11.869), train_loss = 1.13184598, grad/param norm = 1.5986e-01, time/batch = 0.6414s	
6185/26050 (epoch 11.871), train_loss = 1.08028017, grad/param norm = 1.6020e-01, time/batch = 0.6401s	
6186/26050 (epoch 11.873), train_loss = 1.30336575, grad/param norm = 1.7167e-01, time/batch = 0.6394s	
6187/26050 (epoch 11.875), train_loss = 1.24466569, grad/param norm = 1.8043e-01, time/batch = 0.6466s	
6188/26050 (epoch 11.877), train_loss = 1.12157707, grad/param norm = 1.7209e-01, time/batch = 0.6829s	
6189/26050 (epoch 11.879), train_loss = 1.24857012, grad/param norm = 1.6157e-01, time/batch = 0.6541s	
6190/26050 (epoch 11.881), train_loss = 1.38128072, grad/param norm = 1.7529e-01, time/batch = 0.6387s	
6191/26050 (epoch 11.883), train_loss = 1.28114851, grad/param norm = 1.7606e-01, time/batch = 0.6409s	
6192/26050 (epoch 11.885), train_loss = 0.97597470, grad/param norm = 1.5028e-01, time/batch = 0.6411s	
6193/26050 (epoch 11.887), train_loss = 1.28388301, grad/param norm = 1.7784e-01, time/batch = 0.6389s	
6194/26050 (epoch 11.889), train_loss = 1.18555047, grad/param norm = 1.6096e-01, time/batch = 0.6399s	
6195/26050 (epoch 11.891), train_loss = 1.00100145, grad/param norm = 1.5197e-01, time/batch = 0.6441s	
6196/26050 (epoch 11.893), train_loss = 1.00244818, grad/param norm = 1.5579e-01, time/batch = 0.6405s	
6197/26050 (epoch 11.894), train_loss = 1.19294799, grad/param norm = 1.6337e-01, time/batch = 0.6398s	
6198/26050 (epoch 11.896), train_loss = 1.36442521, grad/param norm = 1.8113e-01, time/batch = 0.6392s	
6199/26050 (epoch 11.898), train_loss = 1.18411904, grad/param norm = 1.8818e-01, time/batch = 0.6396s	
6200/26050 (epoch 11.900), train_loss = 1.37241285, grad/param norm = 1.7966e-01, time/batch = 0.6394s	
6201/26050 (epoch 11.902), train_loss = 1.23522901, grad/param norm = 1.7731e-01, time/batch = 0.6419s	
6202/26050 (epoch 11.904), train_loss = 1.19767789, grad/param norm = 1.6070e-01, time/batch = 0.6413s	
6203/26050 (epoch 11.906), train_loss = 1.22050300, grad/param norm = 1.7182e-01, time/batch = 0.6698s	
6204/26050 (epoch 11.908), train_loss = 1.20695257, grad/param norm = 1.7036e-01, time/batch = 0.6725s	
6205/26050 (epoch 11.910), train_loss = 1.13679100, grad/param norm = 1.4977e-01, time/batch = 0.6393s	
6206/26050 (epoch 11.912), train_loss = 1.48917937, grad/param norm = 1.9083e-01, time/batch = 0.6392s	
6207/26050 (epoch 11.914), train_loss = 1.64330275, grad/param norm = 2.0328e-01, time/batch = 0.6451s	
6208/26050 (epoch 11.916), train_loss = 1.37454131, grad/param norm = 1.9174e-01, time/batch = 0.6450s	
6209/26050 (epoch 11.917), train_loss = 1.28021211, grad/param norm = 2.0048e-01, time/batch = 0.6437s	
6210/26050 (epoch 11.919), train_loss = 1.35189972, grad/param norm = 1.9362e-01, time/batch = 0.6590s	
6211/26050 (epoch 11.921), train_loss = 1.18673992, grad/param norm = 1.8791e-01, time/batch = 0.6597s	
6212/26050 (epoch 11.923), train_loss = 1.25250812, grad/param norm = 1.8712e-01, time/batch = 0.6543s	
6213/26050 (epoch 11.925), train_loss = 1.22985920, grad/param norm = 1.6929e-01, time/batch = 0.6447s	
6214/26050 (epoch 11.927), train_loss = 1.11578060, grad/param norm = 1.5309e-01, time/batch = 0.6551s	
6215/26050 (epoch 11.929), train_loss = 1.15327473, grad/param norm = 1.7197e-01, time/batch = 0.6436s	
6216/26050 (epoch 11.931), train_loss = 1.47695128, grad/param norm = 2.0842e-01, time/batch = 0.6446s	
6217/26050 (epoch 11.933), train_loss = 1.21046364, grad/param norm = 1.8547e-01, time/batch = 0.6462s	
6218/26050 (epoch 11.935), train_loss = 1.16637947, grad/param norm = 1.5697e-01, time/batch = 0.6597s	
6219/26050 (epoch 11.937), train_loss = 1.29651298, grad/param norm = 1.7099e-01, time/batch = 0.6836s	
6220/26050 (epoch 11.939), train_loss = 1.12348672, grad/param norm = 1.4798e-01, time/batch = 0.6448s	
6221/26050 (epoch 11.940), train_loss = 1.25322132, grad/param norm = 1.6823e-01, time/batch = 0.6421s	
6222/26050 (epoch 11.942), train_loss = 1.28293256, grad/param norm = 1.9151e-01, time/batch = 0.6561s	
6223/26050 (epoch 11.944), train_loss = 1.21001596, grad/param norm = 1.7403e-01, time/batch = 0.6516s	
6224/26050 (epoch 11.946), train_loss = 1.40333239, grad/param norm = 1.8338e-01, time/batch = 0.6414s	
6225/26050 (epoch 11.948), train_loss = 1.08134406, grad/param norm = 2.9760e-01, time/batch = 0.6454s	
6226/26050 (epoch 11.950), train_loss = 1.22923183, grad/param norm = 1.7896e-01, time/batch = 0.6533s	
6227/26050 (epoch 11.952), train_loss = 1.38159146, grad/param norm = 1.9412e-01, time/batch = 0.6408s	
6228/26050 (epoch 11.954), train_loss = 1.35636237, grad/param norm = 1.8121e-01, time/batch = 0.6397s	
6229/26050 (epoch 11.956), train_loss = 1.26607042, grad/param norm = 1.8714e-01, time/batch = 0.6404s	
6230/26050 (epoch 11.958), train_loss = 1.20491869, grad/param norm = 1.7139e-01, time/batch = 0.6405s	
6231/26050 (epoch 11.960), train_loss = 1.23624698, grad/param norm = 1.7464e-01, time/batch = 0.6405s	
6232/26050 (epoch 11.962), train_loss = 1.16726682, grad/param norm = 1.6980e-01, time/batch = 0.6430s	
6233/26050 (epoch 11.964), train_loss = 1.23493322, grad/param norm = 1.7740e-01, time/batch = 0.6432s	
6234/26050 (epoch 11.965), train_loss = 1.13741580, grad/param norm = 1.7572e-01, time/batch = 0.6832s	
6235/26050 (epoch 11.967), train_loss = 1.55986635, grad/param norm = 1.7812e-01, time/batch = 0.6590s	
6236/26050 (epoch 11.969), train_loss = 1.21786858, grad/param norm = 1.6835e-01, time/batch = 0.6403s	
6237/26050 (epoch 11.971), train_loss = 1.14670102, grad/param norm = 1.5462e-01, time/batch = 0.6408s	
6238/26050 (epoch 11.973), train_loss = 1.21014201, grad/param norm = 1.8913e-01, time/batch = 0.6400s	
6239/26050 (epoch 11.975), train_loss = 1.30446191, grad/param norm = 1.6188e-01, time/batch = 0.6433s	
6240/26050 (epoch 11.977), train_loss = 1.27039282, grad/param norm = 1.6461e-01, time/batch = 0.6440s	
6241/26050 (epoch 11.979), train_loss = 1.06398331, grad/param norm = 1.6590e-01, time/batch = 0.6463s	
6242/26050 (epoch 11.981), train_loss = 1.36554711, grad/param norm = 1.6772e-01, time/batch = 0.6428s	
6243/26050 (epoch 11.983), train_loss = 1.36057272, grad/param norm = 1.7535e-01, time/batch = 0.6407s	
6244/26050 (epoch 11.985), train_loss = 1.27069887, grad/param norm = 1.7749e-01, time/batch = 0.6418s	
6245/26050 (epoch 11.987), train_loss = 1.40227303, grad/param norm = 1.9578e-01, time/batch = 0.6411s	
6246/26050 (epoch 11.988), train_loss = 1.34759144, grad/param norm = 1.7338e-01, time/batch = 0.6401s	
6247/26050 (epoch 11.990), train_loss = 1.14527137, grad/param norm = 1.5533e-01, time/batch = 0.6428s	
6248/26050 (epoch 11.992), train_loss = 1.39420757, grad/param norm = 1.8208e-01, time/batch = 0.6449s	
6249/26050 (epoch 11.994), train_loss = 1.26813084, grad/param norm = 1.7853e-01, time/batch = 0.6760s	
6250/26050 (epoch 11.996), train_loss = 1.20206881, grad/param norm = 1.8205e-01, time/batch = 0.6837s	
6251/26050 (epoch 11.998), train_loss = 1.25831019, grad/param norm = 1.7499e-01, time/batch = 0.6788s	
decayed learning rate by a factor 0.97 to 0.001825346	
6252/26050 (epoch 12.000), train_loss = 1.20335774, grad/param norm = 1.7803e-01, time/batch = 0.6717s	
6253/26050 (epoch 12.002), train_loss = 1.32127998, grad/param norm = 1.9152e-01, time/batch = 0.6644s	
6254/26050 (epoch 12.004), train_loss = 1.13779341, grad/param norm = 1.7291e-01, time/batch = 0.6720s	
6255/26050 (epoch 12.006), train_loss = 1.16079606, grad/param norm = 1.6566e-01, time/batch = 0.6646s	
6256/26050 (epoch 12.008), train_loss = 1.14072047, grad/param norm = 1.7015e-01, time/batch = 0.6735s	
6257/26050 (epoch 12.010), train_loss = 1.17360092, grad/param norm = 1.6016e-01, time/batch = 0.6722s	
6258/26050 (epoch 12.012), train_loss = 1.26282289, grad/param norm = 1.7442e-01, time/batch = 0.6633s	
6259/26050 (epoch 12.013), train_loss = 1.65098977, grad/param norm = 1.9903e-01, time/batch = 0.6627s	
6260/26050 (epoch 12.015), train_loss = 1.15018682, grad/param norm = 1.6100e-01, time/batch = 0.6830s	
6261/26050 (epoch 12.017), train_loss = 1.26301058, grad/param norm = 1.6454e-01, time/batch = 0.6640s	
6262/26050 (epoch 12.019), train_loss = 1.03733405, grad/param norm = 1.4023e-01, time/batch = 0.6615s	
6263/26050 (epoch 12.021), train_loss = 1.32298322, grad/param norm = 1.7540e-01, time/batch = 0.6600s	
6264/26050 (epoch 12.023), train_loss = 1.07996595, grad/param norm = 1.6674e-01, time/batch = 0.6592s	
6265/26050 (epoch 12.025), train_loss = 1.20392812, grad/param norm = 1.6151e-01, time/batch = 0.6597s	
6266/26050 (epoch 12.027), train_loss = 1.00573890, grad/param norm = 1.6343e-01, time/batch = 0.6419s	
6267/26050 (epoch 12.029), train_loss = 1.21810077, grad/param norm = 1.6567e-01, time/batch = 0.6395s	
6268/26050 (epoch 12.031), train_loss = 1.37959901, grad/param norm = 1.9616e-01, time/batch = 0.6423s	
6269/26050 (epoch 12.033), train_loss = 1.27749694, grad/param norm = 1.7119e-01, time/batch = 0.6422s	
6270/26050 (epoch 12.035), train_loss = 1.31735658, grad/param norm = 1.6139e-01, time/batch = 0.6396s	
6271/26050 (epoch 12.036), train_loss = 1.13232065, grad/param norm = 1.8396e-01, time/batch = 0.6445s	
6272/26050 (epoch 12.038), train_loss = 1.06252314, grad/param norm = 1.6501e-01, time/batch = 0.6489s	
6273/26050 (epoch 12.040), train_loss = 1.27704265, grad/param norm = 1.7955e-01, time/batch = 0.6394s	
6274/26050 (epoch 12.042), train_loss = 1.08943113, grad/param norm = 1.7915e-01, time/batch = 0.6407s	
6275/26050 (epoch 12.044), train_loss = 1.32460023, grad/param norm = 1.7310e-01, time/batch = 0.6827s	
6276/26050 (epoch 12.046), train_loss = 1.02967209, grad/param norm = 1.6816e-01, time/batch = 0.6612s	
6277/26050 (epoch 12.048), train_loss = 1.26949721, grad/param norm = 1.7583e-01, time/batch = 0.6407s	
6278/26050 (epoch 12.050), train_loss = 1.12675035, grad/param norm = 1.7955e-01, time/batch = 0.6413s	
6279/26050 (epoch 12.052), train_loss = 1.20479637, grad/param norm = 1.6994e-01, time/batch = 0.6425s	
6280/26050 (epoch 12.054), train_loss = 1.06512431, grad/param norm = 1.5717e-01, time/batch = 0.6409s	
6281/26050 (epoch 12.056), train_loss = 0.98307173, grad/param norm = 1.4233e-01, time/batch = 0.6421s	
6282/26050 (epoch 12.058), train_loss = 1.15268166, grad/param norm = 1.6048e-01, time/batch = 0.6409s	
6283/26050 (epoch 12.060), train_loss = 1.25381867, grad/param norm = 1.6434e-01, time/batch = 0.6457s	
6284/26050 (epoch 12.061), train_loss = 1.12751950, grad/param norm = 1.6687e-01, time/batch = 0.6515s	
6285/26050 (epoch 12.063), train_loss = 1.23643645, grad/param norm = 1.6842e-01, time/batch = 0.6462s	
6286/26050 (epoch 12.065), train_loss = 1.03720158, grad/param norm = 1.6066e-01, time/batch = 0.6422s	
6287/26050 (epoch 12.067), train_loss = 1.27738192, grad/param norm = 1.7890e-01, time/batch = 0.6436s	
6288/26050 (epoch 12.069), train_loss = 1.27467672, grad/param norm = 1.6087e-01, time/batch = 0.6409s	
6289/26050 (epoch 12.071), train_loss = 1.28365227, grad/param norm = 1.7139e-01, time/batch = 0.6408s	
6290/26050 (epoch 12.073), train_loss = 1.44358789, grad/param norm = 1.7798e-01, time/batch = 0.6646s	
6291/26050 (epoch 12.075), train_loss = 1.12925217, grad/param norm = 1.5763e-01, time/batch = 0.6777s	
6292/26050 (epoch 12.077), train_loss = 1.12348139, grad/param norm = 1.6245e-01, time/batch = 0.6393s	
6293/26050 (epoch 12.079), train_loss = 1.27287686, grad/param norm = 1.8322e-01, time/batch = 0.6397s	
6294/26050 (epoch 12.081), train_loss = 1.17309793, grad/param norm = 1.6495e-01, time/batch = 0.6413s	
6295/26050 (epoch 12.083), train_loss = 1.31054767, grad/param norm = 1.7371e-01, time/batch = 0.6412s	
6296/26050 (epoch 12.084), train_loss = 1.32055789, grad/param norm = 1.8540e-01, time/batch = 0.6405s	
6297/26050 (epoch 12.086), train_loss = 1.37106633, grad/param norm = 1.8636e-01, time/batch = 0.6401s	
6298/26050 (epoch 12.088), train_loss = 1.11670357, grad/param norm = 1.5840e-01, time/batch = 0.6408s	
6299/26050 (epoch 12.090), train_loss = 1.29607444, grad/param norm = 1.8254e-01, time/batch = 0.6411s	
6300/26050 (epoch 12.092), train_loss = 1.25818208, grad/param norm = 1.7403e-01, time/batch = 0.6409s	
6301/26050 (epoch 12.094), train_loss = 1.19468195, grad/param norm = 1.7475e-01, time/batch = 0.6447s	
6302/26050 (epoch 12.096), train_loss = 1.18106091, grad/param norm = 1.6507e-01, time/batch = 0.6667s	
6303/26050 (epoch 12.098), train_loss = 1.19870727, grad/param norm = 1.7085e-01, time/batch = 0.6426s	
6304/26050 (epoch 12.100), train_loss = 1.11647865, grad/param norm = 1.7671e-01, time/batch = 0.6535s	
6305/26050 (epoch 12.102), train_loss = 1.23593995, grad/param norm = 1.6730e-01, time/batch = 0.6660s	
6306/26050 (epoch 12.104), train_loss = 1.23205617, grad/param norm = 1.7367e-01, time/batch = 0.6833s	
6307/26050 (epoch 12.106), train_loss = 1.20727573, grad/param norm = 1.8207e-01, time/batch = 0.6507s	
6308/26050 (epoch 12.107), train_loss = 1.00720851, grad/param norm = 1.6413e-01, time/batch = 0.6593s	
6309/26050 (epoch 12.109), train_loss = 1.15014412, grad/param norm = 1.7423e-01, time/batch = 0.6836s	
6310/26050 (epoch 12.111), train_loss = 1.41847323, grad/param norm = 1.8992e-01, time/batch = 0.6827s	
6311/26050 (epoch 12.113), train_loss = 1.16206637, grad/param norm = 1.6601e-01, time/batch = 0.6699s	
6312/26050 (epoch 12.115), train_loss = 1.30509848, grad/param norm = 1.7713e-01, time/batch = 0.6405s	
6313/26050 (epoch 12.117), train_loss = 1.27079731, grad/param norm = 1.7473e-01, time/batch = 0.6396s	
6314/26050 (epoch 12.119), train_loss = 1.00107654, grad/param norm = 1.5106e-01, time/batch = 0.6473s	
6315/26050 (epoch 12.121), train_loss = 1.26957717, grad/param norm = 1.6830e-01, time/batch = 0.6406s	
6316/26050 (epoch 12.123), train_loss = 1.11977091, grad/param norm = 1.7563e-01, time/batch = 0.6393s	
6317/26050 (epoch 12.125), train_loss = 1.03799921, grad/param norm = 1.5406e-01, time/batch = 0.6404s	
6318/26050 (epoch 12.127), train_loss = 0.98017663, grad/param norm = 1.5549e-01, time/batch = 0.6660s	
6319/26050 (epoch 12.129), train_loss = 1.02700252, grad/param norm = 1.4987e-01, time/batch = 0.6551s	
6320/26050 (epoch 12.131), train_loss = 1.19386324, grad/param norm = 1.6892e-01, time/batch = 0.6443s	
6321/26050 (epoch 12.132), train_loss = 1.17816191, grad/param norm = 1.6678e-01, time/batch = 0.6846s	
6322/26050 (epoch 12.134), train_loss = 1.18522065, grad/param norm = 1.7555e-01, time/batch = 0.6559s	
6323/26050 (epoch 12.136), train_loss = 1.21367540, grad/param norm = 1.7148e-01, time/batch = 0.6449s	
6324/26050 (epoch 12.138), train_loss = 1.01954231, grad/param norm = 1.7192e-01, time/batch = 0.6451s	
6325/26050 (epoch 12.140), train_loss = 1.07161389, grad/param norm = 1.6768e-01, time/batch = 0.6417s	
6326/26050 (epoch 12.142), train_loss = 1.12104877, grad/param norm = 1.6866e-01, time/batch = 0.6549s	
6327/26050 (epoch 12.144), train_loss = 1.02950226, grad/param norm = 1.5770e-01, time/batch = 0.6549s	
6328/26050 (epoch 12.146), train_loss = 0.95088762, grad/param norm = 1.6316e-01, time/batch = 0.6575s	
6329/26050 (epoch 12.148), train_loss = 0.96344967, grad/param norm = 1.3833e-01, time/batch = 0.6442s	
6330/26050 (epoch 12.150), train_loss = 1.19140072, grad/param norm = 1.8636e-01, time/batch = 0.6427s	
6331/26050 (epoch 12.152), train_loss = 1.43795400, grad/param norm = 2.0974e-01, time/batch = 0.6546s	
6332/26050 (epoch 12.154), train_loss = 0.99188185, grad/param norm = 1.6129e-01, time/batch = 0.6548s	
6333/26050 (epoch 12.155), train_loss = 1.02616234, grad/param norm = 1.5845e-01, time/batch = 0.6423s	
6334/26050 (epoch 12.157), train_loss = 1.16358974, grad/param norm = 1.8544e-01, time/batch = 0.6515s	
6335/26050 (epoch 12.159), train_loss = 1.17514339, grad/param norm = 1.7419e-01, time/batch = 0.6419s	
6336/26050 (epoch 12.161), train_loss = 1.32204636, grad/param norm = 1.8902e-01, time/batch = 0.6750s	
6337/26050 (epoch 12.163), train_loss = 1.02979108, grad/param norm = 1.6289e-01, time/batch = 0.6697s	
6338/26050 (epoch 12.165), train_loss = 0.91934738, grad/param norm = 1.4977e-01, time/batch = 0.6427s	
6339/26050 (epoch 12.167), train_loss = 1.30508833, grad/param norm = 1.8726e-01, time/batch = 0.6431s	
6340/26050 (epoch 12.169), train_loss = 1.25920503, grad/param norm = 1.6788e-01, time/batch = 0.6418s	
6341/26050 (epoch 12.171), train_loss = 0.98936722, grad/param norm = 1.4391e-01, time/batch = 0.6429s	
6342/26050 (epoch 12.173), train_loss = 1.14123731, grad/param norm = 1.8230e-01, time/batch = 0.6405s	
6343/26050 (epoch 12.175), train_loss = 1.20988988, grad/param norm = 1.7071e-01, time/batch = 0.6416s	
6344/26050 (epoch 12.177), train_loss = 1.30861198, grad/param norm = 1.6982e-01, time/batch = 0.6428s	
6345/26050 (epoch 12.179), train_loss = 0.94425880, grad/param norm = 1.5066e-01, time/batch = 0.6411s	
6346/26050 (epoch 12.180), train_loss = 1.45499292, grad/param norm = 1.7458e-01, time/batch = 0.6421s	
6347/26050 (epoch 12.182), train_loss = 1.46424023, grad/param norm = 1.9888e-01, time/batch = 0.6413s	
6348/26050 (epoch 12.184), train_loss = 1.21698838, grad/param norm = 1.6311e-01, time/batch = 0.6484s	
6349/26050 (epoch 12.186), train_loss = 0.99609354, grad/param norm = 1.4921e-01, time/batch = 0.6539s	
6350/26050 (epoch 12.188), train_loss = 1.20119498, grad/param norm = 1.6311e-01, time/batch = 0.6487s	
6351/26050 (epoch 12.190), train_loss = 1.25292584, grad/param norm = 1.7439e-01, time/batch = 0.6650s	
6352/26050 (epoch 12.192), train_loss = 1.24646993, grad/param norm = 1.7249e-01, time/batch = 0.6834s	
6353/26050 (epoch 12.194), train_loss = 1.23600702, grad/param norm = 1.6824e-01, time/batch = 0.6414s	
6354/26050 (epoch 12.196), train_loss = 1.30302815, grad/param norm = 1.8834e-01, time/batch = 0.6432s	
6355/26050 (epoch 12.198), train_loss = 1.12563566, grad/param norm = 1.6190e-01, time/batch = 0.6577s	
6356/26050 (epoch 12.200), train_loss = 1.10882767, grad/param norm = 1.6704e-01, time/batch = 0.6442s	
6357/26050 (epoch 12.202), train_loss = 1.15205708, grad/param norm = 1.7458e-01, time/batch = 0.6392s	
6358/26050 (epoch 12.203), train_loss = 1.30048231, grad/param norm = 1.7885e-01, time/batch = 0.6393s	
6359/26050 (epoch 12.205), train_loss = 1.11451496, grad/param norm = 1.6486e-01, time/batch = 0.6397s	
6360/26050 (epoch 12.207), train_loss = 1.16735031, grad/param norm = 1.6249e-01, time/batch = 0.6428s	
6361/26050 (epoch 12.209), train_loss = 1.19502172, grad/param norm = 1.6612e-01, time/batch = 0.6420s	
6362/26050 (epoch 12.211), train_loss = 1.03767340, grad/param norm = 1.6722e-01, time/batch = 0.6407s	
6363/26050 (epoch 12.213), train_loss = 1.25463791, grad/param norm = 1.7842e-01, time/batch = 0.6432s	
6364/26050 (epoch 12.215), train_loss = 1.20215155, grad/param norm = 1.8085e-01, time/batch = 0.6463s	
6365/26050 (epoch 12.217), train_loss = 1.17937216, grad/param norm = 1.6554e-01, time/batch = 0.6392s	
6366/26050 (epoch 12.219), train_loss = 1.14335229, grad/param norm = 1.7930e-01, time/batch = 0.6447s	
6367/26050 (epoch 12.221), train_loss = 1.06857509, grad/param norm = 1.5181e-01, time/batch = 0.6611s	
6368/26050 (epoch 12.223), train_loss = 1.22278348, grad/param norm = 1.6645e-01, time/batch = 0.6404s	
6369/26050 (epoch 12.225), train_loss = 1.10178431, grad/param norm = 1.7859e-01, time/batch = 0.6403s	
6370/26050 (epoch 12.226), train_loss = 1.29788460, grad/param norm = 1.8036e-01, time/batch = 0.6433s	
6371/26050 (epoch 12.228), train_loss = 1.34543136, grad/param norm = 1.8112e-01, time/batch = 0.6492s	
6372/26050 (epoch 12.230), train_loss = 1.24193965, grad/param norm = 1.6715e-01, time/batch = 0.6438s	
6373/26050 (epoch 12.232), train_loss = 1.31648721, grad/param norm = 1.8348e-01, time/batch = 0.6410s	
6374/26050 (epoch 12.234), train_loss = 1.04609901, grad/param norm = 1.6342e-01, time/batch = 0.6402s	
6375/26050 (epoch 12.236), train_loss = 1.29761276, grad/param norm = 1.8209e-01, time/batch = 0.6413s	
6376/26050 (epoch 12.238), train_loss = 1.02557240, grad/param norm = 1.6532e-01, time/batch = 0.6436s	
6377/26050 (epoch 12.240), train_loss = 1.17356724, grad/param norm = 1.7842e-01, time/batch = 0.6414s	
6378/26050 (epoch 12.242), train_loss = 1.20194844, grad/param norm = 1.5681e-01, time/batch = 0.6404s	
6379/26050 (epoch 12.244), train_loss = 1.23362965, grad/param norm = 1.9033e-01, time/batch = 0.6440s	
6380/26050 (epoch 12.246), train_loss = 1.11739889, grad/param norm = 1.5798e-01, time/batch = 0.6451s	
6381/26050 (epoch 12.248), train_loss = 1.21774855, grad/param norm = 1.6594e-01, time/batch = 0.6398s	
6382/26050 (epoch 12.250), train_loss = 1.19874554, grad/param norm = 1.8633e-01, time/batch = 0.6658s	
6383/26050 (epoch 12.251), train_loss = 1.12258709, grad/param norm = 1.6413e-01, time/batch = 0.6766s	
6384/26050 (epoch 12.253), train_loss = 1.04472576, grad/param norm = 1.6525e-01, time/batch = 0.6409s	
6385/26050 (epoch 12.255), train_loss = 1.41193386, grad/param norm = 1.7640e-01, time/batch = 0.6397s	
6386/26050 (epoch 12.257), train_loss = 1.20817317, grad/param norm = 1.9115e-01, time/batch = 0.6403s	
6387/26050 (epoch 12.259), train_loss = 1.34339868, grad/param norm = 1.7048e-01, time/batch = 0.6427s	
6388/26050 (epoch 12.261), train_loss = 1.10261174, grad/param norm = 1.8165e-01, time/batch = 0.6396s	
6389/26050 (epoch 12.263), train_loss = 1.22284438, grad/param norm = 1.7318e-01, time/batch = 0.6424s	
6390/26050 (epoch 12.265), train_loss = 1.38471827, grad/param norm = 1.8054e-01, time/batch = 0.6389s	
6391/26050 (epoch 12.267), train_loss = 1.29577046, grad/param norm = 1.7117e-01, time/batch = 0.6401s	
6392/26050 (epoch 12.269), train_loss = 1.39800148, grad/param norm = 1.9862e-01, time/batch = 0.6410s	
6393/26050 (epoch 12.271), train_loss = 1.26508302, grad/param norm = 1.8172e-01, time/batch = 0.6466s	
6394/26050 (epoch 12.273), train_loss = 1.17083346, grad/param norm = 1.8476e-01, time/batch = 0.6629s	
6395/26050 (epoch 12.274), train_loss = 1.16883858, grad/param norm = 1.7562e-01, time/batch = 0.6416s	
6396/26050 (epoch 12.276), train_loss = 1.13433468, grad/param norm = 1.7884e-01, time/batch = 0.6617s	
6397/26050 (epoch 12.278), train_loss = 1.33372443, grad/param norm = 1.8103e-01, time/batch = 0.6553s	
6398/26050 (epoch 12.280), train_loss = 1.19266706, grad/param norm = 1.6746e-01, time/batch = 0.6840s	
6399/26050 (epoch 12.282), train_loss = 1.25012629, grad/param norm = 1.8247e-01, time/batch = 0.6548s	
6400/26050 (epoch 12.284), train_loss = 1.12907205, grad/param norm = 1.7605e-01, time/batch = 0.6497s	
6401/26050 (epoch 12.286), train_loss = 1.21015414, grad/param norm = 1.7396e-01, time/batch = 0.6495s	
6402/26050 (epoch 12.288), train_loss = 1.03580013, grad/param norm = 1.5966e-01, time/batch = 0.6405s	
6403/26050 (epoch 12.290), train_loss = 1.18259084, grad/param norm = 1.7454e-01, time/batch = 0.6404s	
6404/26050 (epoch 12.292), train_loss = 1.11071213, grad/param norm = 1.6465e-01, time/batch = 0.6392s	
6405/26050 (epoch 12.294), train_loss = 1.23808496, grad/param norm = 1.8576e-01, time/batch = 0.6382s	
6406/26050 (epoch 12.296), train_loss = 1.33295436, grad/param norm = 1.7393e-01, time/batch = 0.6416s	
6407/26050 (epoch 12.298), train_loss = 1.20426648, grad/param norm = 1.6849e-01, time/batch = 0.6392s	
6408/26050 (epoch 12.299), train_loss = 0.95734714, grad/param norm = 1.4550e-01, time/batch = 0.6387s	
6409/26050 (epoch 12.301), train_loss = 1.12055789, grad/param norm = 1.7548e-01, time/batch = 0.6383s	
6410/26050 (epoch 12.303), train_loss = 1.23874376, grad/param norm = 1.7893e-01, time/batch = 0.6448s	
6411/26050 (epoch 12.305), train_loss = 1.04287548, grad/param norm = 1.6668e-01, time/batch = 0.6393s	
6412/26050 (epoch 12.307), train_loss = 1.11159491, grad/param norm = 1.7127e-01, time/batch = 0.6385s	
6413/26050 (epoch 12.309), train_loss = 1.17135159, grad/param norm = 1.7577e-01, time/batch = 0.6758s	
6414/26050 (epoch 12.311), train_loss = 1.34301628, grad/param norm = 1.8249e-01, time/batch = 0.6663s	
6415/26050 (epoch 12.313), train_loss = 1.20121632, grad/param norm = 1.9616e-01, time/batch = 0.6374s	
6416/26050 (epoch 12.315), train_loss = 1.31436256, grad/param norm = 1.8359e-01, time/batch = 0.6422s	
6417/26050 (epoch 12.317), train_loss = 1.15997896, grad/param norm = 1.6373e-01, time/batch = 0.6400s	
6418/26050 (epoch 12.319), train_loss = 1.15188368, grad/param norm = 1.8340e-01, time/batch = 0.6397s	
6419/26050 (epoch 12.321), train_loss = 1.15821455, grad/param norm = 1.7931e-01, time/batch = 0.6392s	
6420/26050 (epoch 12.322), train_loss = 1.22474853, grad/param norm = 1.6915e-01, time/batch = 0.6399s	
6421/26050 (epoch 12.324), train_loss = 1.02724000, grad/param norm = 1.7597e-01, time/batch = 0.6405s	
6422/26050 (epoch 12.326), train_loss = 1.35785479, grad/param norm = 1.8252e-01, time/batch = 0.6389s	
6423/26050 (epoch 12.328), train_loss = 1.25687722, grad/param norm = 1.6839e-01, time/batch = 0.6432s	
6424/26050 (epoch 12.330), train_loss = 1.09542692, grad/param norm = 1.6801e-01, time/batch = 0.6428s	
6425/26050 (epoch 12.332), train_loss = 1.28939641, grad/param norm = 1.8529e-01, time/batch = 0.6452s	
6426/26050 (epoch 12.334), train_loss = 1.17057768, grad/param norm = 1.7655e-01, time/batch = 0.6387s	
6427/26050 (epoch 12.336), train_loss = 1.11034599, grad/param norm = 1.6113e-01, time/batch = 0.6381s	
6428/26050 (epoch 12.338), train_loss = 1.07329603, grad/param norm = 1.5790e-01, time/batch = 0.6546s	
6429/26050 (epoch 12.340), train_loss = 1.31148486, grad/param norm = 1.8413e-01, time/batch = 0.6827s	
6430/26050 (epoch 12.342), train_loss = 1.35771702, grad/param norm = 1.8468e-01, time/batch = 0.6439s	
6431/26050 (epoch 12.344), train_loss = 1.19359321, grad/param norm = 1.7810e-01, time/batch = 0.6409s	
6432/26050 (epoch 12.345), train_loss = 1.17551761, grad/param norm = 1.7559e-01, time/batch = 0.6416s	
6433/26050 (epoch 12.347), train_loss = 1.29304400, grad/param norm = 1.8696e-01, time/batch = 0.6415s	
6434/26050 (epoch 12.349), train_loss = 1.24681457, grad/param norm = 1.7188e-01, time/batch = 0.6399s	
6435/26050 (epoch 12.351), train_loss = 1.22270853, grad/param norm = 1.8118e-01, time/batch = 0.6405s	
6436/26050 (epoch 12.353), train_loss = 1.16841497, grad/param norm = 1.8212e-01, time/batch = 0.6398s	
6437/26050 (epoch 12.355), train_loss = 1.27583074, grad/param norm = 1.8464e-01, time/batch = 0.6404s	
6438/26050 (epoch 12.357), train_loss = 1.06082261, grad/param norm = 1.5310e-01, time/batch = 0.6392s	
6439/26050 (epoch 12.359), train_loss = 1.28254920, grad/param norm = 1.6970e-01, time/batch = 0.6392s	
6440/26050 (epoch 12.361), train_loss = 1.13481358, grad/param norm = 1.6720e-01, time/batch = 0.6432s	
6441/26050 (epoch 12.363), train_loss = 1.25041154, grad/param norm = 1.5986e-01, time/batch = 0.6422s	
6442/26050 (epoch 12.365), train_loss = 1.15865035, grad/param norm = 1.5261e-01, time/batch = 0.6385s	
6443/26050 (epoch 12.367), train_loss = 1.20542986, grad/param norm = 1.6748e-01, time/batch = 0.6397s	
6444/26050 (epoch 12.369), train_loss = 1.17926458, grad/param norm = 1.5575e-01, time/batch = 0.6385s	
6445/26050 (epoch 12.370), train_loss = 1.08857953, grad/param norm = 1.5142e-01, time/batch = 0.6389s	
6446/26050 (epoch 12.372), train_loss = 1.28280744, grad/param norm = 1.9178e-01, time/batch = 0.6389s	
6447/26050 (epoch 12.374), train_loss = 1.38338547, grad/param norm = 1.7931e-01, time/batch = 0.6402s	
6448/26050 (epoch 12.376), train_loss = 1.41207497, grad/param norm = 1.7910e-01, time/batch = 0.6408s	
6449/26050 (epoch 12.378), train_loss = 1.17996212, grad/param norm = 1.7437e-01, time/batch = 0.6398s	
6450/26050 (epoch 12.380), train_loss = 1.41371810, grad/param norm = 2.0036e-01, time/batch = 0.6380s	
6451/26050 (epoch 12.382), train_loss = 1.55589336, grad/param norm = 2.1466e-01, time/batch = 0.6410s	
6452/26050 (epoch 12.384), train_loss = 1.16173829, grad/param norm = 1.6048e-01, time/batch = 0.6381s	
6453/26050 (epoch 12.386), train_loss = 1.32917394, grad/param norm = 1.9420e-01, time/batch = 0.6409s	
6454/26050 (epoch 12.388), train_loss = 1.24704356, grad/param norm = 1.7590e-01, time/batch = 0.6394s	
6455/26050 (epoch 12.390), train_loss = 1.09388158, grad/param norm = 1.5327e-01, time/batch = 0.6380s	
6456/26050 (epoch 12.392), train_loss = 1.09952088, grad/param norm = 1.5484e-01, time/batch = 0.6412s	
6457/26050 (epoch 12.393), train_loss = 1.25640954, grad/param norm = 1.6487e-01, time/batch = 0.6420s	
6458/26050 (epoch 12.395), train_loss = 1.27671218, grad/param norm = 1.6718e-01, time/batch = 0.6392s	
6459/26050 (epoch 12.397), train_loss = 1.26061491, grad/param norm = 1.8642e-01, time/batch = 0.6418s	
6460/26050 (epoch 12.399), train_loss = 1.08415694, grad/param norm = 1.6045e-01, time/batch = 0.6412s	
6461/26050 (epoch 12.401), train_loss = 1.17481185, grad/param norm = 1.5281e-01, time/batch = 0.6397s	
6462/26050 (epoch 12.403), train_loss = 1.22697033, grad/param norm = 1.6018e-01, time/batch = 0.6407s	
6463/26050 (epoch 12.405), train_loss = 1.19644256, grad/param norm = 1.7757e-01, time/batch = 0.6408s	
6464/26050 (epoch 12.407), train_loss = 1.35539431, grad/param norm = 1.7785e-01, time/batch = 0.6687s	
6465/26050 (epoch 12.409), train_loss = 1.39675321, grad/param norm = 1.9059e-01, time/batch = 0.6792s	
6466/26050 (epoch 12.411), train_loss = 1.25263213, grad/param norm = 1.8203e-01, time/batch = 0.6454s	
6467/26050 (epoch 12.413), train_loss = 1.36017206, grad/param norm = 1.5988e-01, time/batch = 0.6389s	
6468/26050 (epoch 12.415), train_loss = 1.33490396, grad/param norm = 1.8883e-01, time/batch = 0.6384s	
6469/26050 (epoch 12.417), train_loss = 1.44856116, grad/param norm = 1.9193e-01, time/batch = 0.6396s	
6470/26050 (epoch 12.418), train_loss = 1.32215457, grad/param norm = 1.9474e-01, time/batch = 0.6480s	
6471/26050 (epoch 12.420), train_loss = 1.03092576, grad/param norm = 1.4838e-01, time/batch = 0.6504s	
6472/26050 (epoch 12.422), train_loss = 1.07489618, grad/param norm = 1.6896e-01, time/batch = 0.6407s	
6473/26050 (epoch 12.424), train_loss = 1.39351791, grad/param norm = 2.0604e-01, time/batch = 0.6416s	
6474/26050 (epoch 12.426), train_loss = 1.35885784, grad/param norm = 1.7913e-01, time/batch = 0.6461s	
6475/26050 (epoch 12.428), train_loss = 1.12187212, grad/param norm = 1.4729e-01, time/batch = 0.6430s	
6476/26050 (epoch 12.430), train_loss = 1.27918416, grad/param norm = 1.7482e-01, time/batch = 0.6402s	
6477/26050 (epoch 12.432), train_loss = 1.15633909, grad/param norm = 1.6753e-01, time/batch = 0.6384s	
6478/26050 (epoch 12.434), train_loss = 1.23339210, grad/param norm = 1.8827e-01, time/batch = 0.6398s	
6479/26050 (epoch 12.436), train_loss = 1.34004757, grad/param norm = 1.6396e-01, time/batch = 0.6522s	
6480/26050 (epoch 12.438), train_loss = 1.12875163, grad/param norm = 1.6917e-01, time/batch = 0.6828s	
6481/26050 (epoch 12.440), train_loss = 1.25366944, grad/param norm = 1.7014e-01, time/batch = 0.6473s	
6482/26050 (epoch 12.441), train_loss = 1.22947426, grad/param norm = 1.5807e-01, time/batch = 0.6407s	
6483/26050 (epoch 12.443), train_loss = 1.02894229, grad/param norm = 1.5301e-01, time/batch = 0.6431s	
6484/26050 (epoch 12.445), train_loss = 1.09237773, grad/param norm = 1.6015e-01, time/batch = 0.6403s	
6485/26050 (epoch 12.447), train_loss = 1.40959578, grad/param norm = 1.8735e-01, time/batch = 0.6435s	
6486/26050 (epoch 12.449), train_loss = 1.11806604, grad/param norm = 1.7691e-01, time/batch = 0.6563s	
6487/26050 (epoch 12.451), train_loss = 1.35047891, grad/param norm = 1.7688e-01, time/batch = 0.6581s	
6488/26050 (epoch 12.453), train_loss = 1.12577669, grad/param norm = 1.6256e-01, time/batch = 0.6463s	
6489/26050 (epoch 12.455), train_loss = 1.25648316, grad/param norm = 1.6268e-01, time/batch = 0.6502s	
6490/26050 (epoch 12.457), train_loss = 1.24006896, grad/param norm = 1.7424e-01, time/batch = 0.6394s	
6491/26050 (epoch 12.459), train_loss = 1.33159010, grad/param norm = 1.7417e-01, time/batch = 0.6428s	
6492/26050 (epoch 12.461), train_loss = 1.29831385, grad/param norm = 1.9539e-01, time/batch = 0.6397s	
6493/26050 (epoch 12.463), train_loss = 1.15400296, grad/param norm = 1.5329e-01, time/batch = 0.6404s	
6494/26050 (epoch 12.464), train_loss = 1.28661859, grad/param norm = 1.7755e-01, time/batch = 0.6449s	
6495/26050 (epoch 12.466), train_loss = 1.30410429, grad/param norm = 1.7612e-01, time/batch = 0.6830s	
6496/26050 (epoch 12.468), train_loss = 1.31284448, grad/param norm = 1.6057e-01, time/batch = 0.6618s	
6497/26050 (epoch 12.470), train_loss = 1.43085665, grad/param norm = 2.0139e-01, time/batch = 0.6399s	
6498/26050 (epoch 12.472), train_loss = 1.38574780, grad/param norm = 1.9133e-01, time/batch = 0.6396s	
6499/26050 (epoch 12.474), train_loss = 1.44971106, grad/param norm = 1.8200e-01, time/batch = 0.6428s	
6500/26050 (epoch 12.476), train_loss = 1.32431800, grad/param norm = 1.7321e-01, time/batch = 0.6404s	
6501/26050 (epoch 12.478), train_loss = 1.14263640, grad/param norm = 1.5357e-01, time/batch = 0.6434s	
6502/26050 (epoch 12.480), train_loss = 1.25247195, grad/param norm = 1.6542e-01, time/batch = 0.6427s	
6503/26050 (epoch 12.482), train_loss = 1.18316779, grad/param norm = 1.6316e-01, time/batch = 0.6415s	
6504/26050 (epoch 12.484), train_loss = 1.14730340, grad/param norm = 1.5907e-01, time/batch = 0.6400s	
6505/26050 (epoch 12.486), train_loss = 1.38954516, grad/param norm = 1.7580e-01, time/batch = 0.6395s	
6506/26050 (epoch 12.488), train_loss = 1.55750709, grad/param norm = 1.9772e-01, time/batch = 0.6407s	
6507/26050 (epoch 12.489), train_loss = 1.47024097, grad/param norm = 2.0284e-01, time/batch = 0.6384s	
6508/26050 (epoch 12.491), train_loss = 1.11842748, grad/param norm = 1.6075e-01, time/batch = 0.6403s	
6509/26050 (epoch 12.493), train_loss = 1.21995210, grad/param norm = 1.7084e-01, time/batch = 0.6432s	
6510/26050 (epoch 12.495), train_loss = 1.19500818, grad/param norm = 1.6593e-01, time/batch = 0.6618s	
6511/26050 (epoch 12.497), train_loss = 1.16069903, grad/param norm = 1.6432e-01, time/batch = 0.6802s	
6512/26050 (epoch 12.499), train_loss = 1.18540646, grad/param norm = 1.6824e-01, time/batch = 0.6493s	
6513/26050 (epoch 12.501), train_loss = 1.30451260, grad/param norm = 1.7494e-01, time/batch = 0.6446s	
6514/26050 (epoch 12.503), train_loss = 1.15520711, grad/param norm = 1.8475e-01, time/batch = 0.6406s	
6515/26050 (epoch 12.505), train_loss = 1.35376438, grad/param norm = 1.7581e-01, time/batch = 0.6410s	
6516/26050 (epoch 12.507), train_loss = 1.32496981, grad/param norm = 1.9406e-01, time/batch = 0.6457s	
6517/26050 (epoch 12.509), train_loss = 1.45646388, grad/param norm = 1.8416e-01, time/batch = 0.6443s	
6518/26050 (epoch 12.511), train_loss = 1.12159858, grad/param norm = 1.5990e-01, time/batch = 0.6438s	
6519/26050 (epoch 12.512), train_loss = 1.18365895, grad/param norm = 1.8403e-01, time/batch = 0.6406s	
6520/26050 (epoch 12.514), train_loss = 1.30836700, grad/param norm = 1.7816e-01, time/batch = 0.6442s	
6521/26050 (epoch 12.516), train_loss = 1.32880353, grad/param norm = 1.7815e-01, time/batch = 0.6430s	
6522/26050 (epoch 12.518), train_loss = 1.30551913, grad/param norm = 1.8828e-01, time/batch = 0.6420s	
6523/26050 (epoch 12.520), train_loss = 1.22084651, grad/param norm = 1.6248e-01, time/batch = 0.6402s	
6524/26050 (epoch 12.522), train_loss = 1.03516771, grad/param norm = 1.6253e-01, time/batch = 0.6433s	
6525/26050 (epoch 12.524), train_loss = 1.35457230, grad/param norm = 1.8548e-01, time/batch = 0.6487s	
6526/26050 (epoch 12.526), train_loss = 1.33969979, grad/param norm = 1.8308e-01, time/batch = 0.6828s	
6527/26050 (epoch 12.528), train_loss = 1.29034745, grad/param norm = 1.7597e-01, time/batch = 0.6530s	
6528/26050 (epoch 12.530), train_loss = 1.22031643, grad/param norm = 1.6162e-01, time/batch = 0.6406s	
6529/26050 (epoch 12.532), train_loss = 1.21790306, grad/param norm = 1.5292e-01, time/batch = 0.6401s	
6530/26050 (epoch 12.534), train_loss = 1.32095511, grad/param norm = 1.8498e-01, time/batch = 0.6396s	
6531/26050 (epoch 12.536), train_loss = 1.21690431, grad/param norm = 1.6246e-01, time/batch = 0.6583s	
6532/26050 (epoch 12.537), train_loss = 1.35313221, grad/param norm = 1.9074e-01, time/batch = 0.6571s	
6533/26050 (epoch 12.539), train_loss = 1.23882937, grad/param norm = 1.7076e-01, time/batch = 0.6623s	
6534/26050 (epoch 12.541), train_loss = 1.42537808, grad/param norm = 1.9305e-01, time/batch = 0.6565s	
6535/26050 (epoch 12.543), train_loss = 1.06073630, grad/param norm = 1.6391e-01, time/batch = 0.6556s	
6536/26050 (epoch 12.545), train_loss = 1.27778816, grad/param norm = 1.7146e-01, time/batch = 0.6546s	
6537/26050 (epoch 12.547), train_loss = 1.25883268, grad/param norm = 1.7273e-01, time/batch = 0.6578s	
6538/26050 (epoch 12.549), train_loss = 1.03471934, grad/param norm = 1.5029e-01, time/batch = 0.6589s	
6539/26050 (epoch 12.551), train_loss = 1.26147169, grad/param norm = 1.6781e-01, time/batch = 0.6587s	
6540/26050 (epoch 12.553), train_loss = 1.12975264, grad/param norm = 1.5578e-01, time/batch = 0.6594s	
6541/26050 (epoch 12.555), train_loss = 1.17476019, grad/param norm = 1.6668e-01, time/batch = 0.6852s	
6542/26050 (epoch 12.557), train_loss = 1.28145692, grad/param norm = 1.5749e-01, time/batch = 0.6822s	
6543/26050 (epoch 12.559), train_loss = 1.22819972, grad/param norm = 1.6661e-01, time/batch = 0.6617s	
6544/26050 (epoch 12.560), train_loss = 1.20894116, grad/param norm = 1.7273e-01, time/batch = 0.6413s	
6545/26050 (epoch 12.562), train_loss = 1.20282423, grad/param norm = 1.7294e-01, time/batch = 0.6405s	
6546/26050 (epoch 12.564), train_loss = 1.43419591, grad/param norm = 1.7578e-01, time/batch = 0.6400s	
6547/26050 (epoch 12.566), train_loss = 1.11076676, grad/param norm = 1.7191e-01, time/batch = 0.6410s	
6548/26050 (epoch 12.568), train_loss = 1.25413348, grad/param norm = 1.6422e-01, time/batch = 0.6420s	
6549/26050 (epoch 12.570), train_loss = 1.34072320, grad/param norm = 1.8758e-01, time/batch = 0.6410s	
6550/26050 (epoch 12.572), train_loss = 1.20303705, grad/param norm = 1.6670e-01, time/batch = 0.6395s	
6551/26050 (epoch 12.574), train_loss = 1.30520950, grad/param norm = 2.0080e-01, time/batch = 0.6419s	
6552/26050 (epoch 12.576), train_loss = 1.29505221, grad/param norm = 1.8661e-01, time/batch = 0.6419s	
6553/26050 (epoch 12.578), train_loss = 1.23988567, grad/param norm = 1.8263e-01, time/batch = 0.6408s	
6554/26050 (epoch 12.580), train_loss = 1.12479265, grad/param norm = 1.7438e-01, time/batch = 0.6405s	
6555/26050 (epoch 12.582), train_loss = 1.27044393, grad/param norm = 1.7698e-01, time/batch = 0.6420s	
6556/26050 (epoch 12.583), train_loss = 1.31412688, grad/param norm = 1.7158e-01, time/batch = 0.6521s	
6557/26050 (epoch 12.585), train_loss = 1.12674441, grad/param norm = 1.7323e-01, time/batch = 0.6573s	
6558/26050 (epoch 12.587), train_loss = 1.26903354, grad/param norm = 1.7467e-01, time/batch = 0.6405s	
6559/26050 (epoch 12.589), train_loss = 1.33830708, grad/param norm = 1.9719e-01, time/batch = 0.6387s	
6560/26050 (epoch 12.591), train_loss = 1.23960432, grad/param norm = 1.7892e-01, time/batch = 0.6489s	
6561/26050 (epoch 12.593), train_loss = 1.11402587, grad/param norm = 1.8932e-01, time/batch = 0.6446s	
6562/26050 (epoch 12.595), train_loss = 1.37080444, grad/param norm = 2.0312e-01, time/batch = 0.6402s	
6563/26050 (epoch 12.597), train_loss = 1.26588141, grad/param norm = 1.7660e-01, time/batch = 0.6466s	
6564/26050 (epoch 12.599), train_loss = 1.20358935, grad/param norm = 1.7139e-01, time/batch = 0.6435s	
6565/26050 (epoch 12.601), train_loss = 1.43766198, grad/param norm = 1.8143e-01, time/batch = 0.6405s	
6566/26050 (epoch 12.603), train_loss = 1.29754007, grad/param norm = 1.7764e-01, time/batch = 0.6403s	
6567/26050 (epoch 12.605), train_loss = 1.17121733, grad/param norm = 1.6325e-01, time/batch = 0.6405s	
6568/26050 (epoch 12.607), train_loss = 1.38666113, grad/param norm = 1.9418e-01, time/batch = 0.6401s	
6569/26050 (epoch 12.608), train_loss = 1.12750990, grad/param norm = 1.5660e-01, time/batch = 0.6416s	
6570/26050 (epoch 12.610), train_loss = 1.21028441, grad/param norm = 1.7353e-01, time/batch = 0.6454s	
6571/26050 (epoch 12.612), train_loss = 1.22214058, grad/param norm = 1.7633e-01, time/batch = 0.6503s	
6572/26050 (epoch 12.614), train_loss = 1.32210685, grad/param norm = 1.7967e-01, time/batch = 0.6835s	
6573/26050 (epoch 12.616), train_loss = 1.46737966, grad/param norm = 1.9629e-01, time/batch = 0.6527s	
6574/26050 (epoch 12.618), train_loss = 1.17940372, grad/param norm = 1.7758e-01, time/batch = 0.6393s	
6575/26050 (epoch 12.620), train_loss = 1.25704826, grad/param norm = 1.7666e-01, time/batch = 0.6396s	
6576/26050 (epoch 12.622), train_loss = 1.06015795, grad/param norm = 1.5889e-01, time/batch = 0.6396s	
6577/26050 (epoch 12.624), train_loss = 1.09604587, grad/param norm = 1.6437e-01, time/batch = 0.6405s	
6578/26050 (epoch 12.626), train_loss = 1.29843255, grad/param norm = 1.7656e-01, time/batch = 0.6692s	
6579/26050 (epoch 12.628), train_loss = 1.18705511, grad/param norm = 1.8934e-01, time/batch = 0.6503s	
6580/26050 (epoch 12.630), train_loss = 1.37402412, grad/param norm = 1.7306e-01, time/batch = 0.6597s	
6581/26050 (epoch 12.631), train_loss = 1.39838040, grad/param norm = 1.8690e-01, time/batch = 0.6450s	
6582/26050 (epoch 12.633), train_loss = 1.14994305, grad/param norm = 1.7593e-01, time/batch = 0.6596s	
6583/26050 (epoch 12.635), train_loss = 1.13909213, grad/param norm = 1.5211e-01, time/batch = 0.6496s	
6584/26050 (epoch 12.637), train_loss = 1.12366380, grad/param norm = 1.7436e-01, time/batch = 0.6587s	
6585/26050 (epoch 12.639), train_loss = 1.33875888, grad/param norm = 1.6867e-01, time/batch = 0.6704s	
6586/26050 (epoch 12.641), train_loss = 1.17832629, grad/param norm = 1.5725e-01, time/batch = 0.6773s	
6587/26050 (epoch 12.643), train_loss = 1.08392221, grad/param norm = 1.4957e-01, time/batch = 0.6751s	
6588/26050 (epoch 12.645), train_loss = 1.27019840, grad/param norm = 1.8769e-01, time/batch = 0.6669s	
6589/26050 (epoch 12.647), train_loss = 1.18649266, grad/param norm = 1.7040e-01, time/batch = 0.6624s	
6590/26050 (epoch 12.649), train_loss = 1.25422791, grad/param norm = 1.8646e-01, time/batch = 0.6410s	
6591/26050 (epoch 12.651), train_loss = 1.16485649, grad/param norm = 1.7761e-01, time/batch = 0.6423s	
6592/26050 (epoch 12.653), train_loss = 1.23185102, grad/param norm = 1.7109e-01, time/batch = 0.6429s	
6593/26050 (epoch 12.655), train_loss = 1.14365478, grad/param norm = 1.6210e-01, time/batch = 0.6473s	
6594/26050 (epoch 12.656), train_loss = 1.08289076, grad/param norm = 1.7262e-01, time/batch = 0.6560s	
6595/26050 (epoch 12.658), train_loss = 1.42899521, grad/param norm = 1.7964e-01, time/batch = 0.6444s	
6596/26050 (epoch 12.660), train_loss = 1.11315940, grad/param norm = 1.6811e-01, time/batch = 0.6404s	
6597/26050 (epoch 12.662), train_loss = 1.11577941, grad/param norm = 1.5590e-01, time/batch = 0.6421s	
6598/26050 (epoch 12.664), train_loss = 1.20112507, grad/param norm = 1.7675e-01, time/batch = 0.6417s	
6599/26050 (epoch 12.666), train_loss = 1.22654948, grad/param norm = 1.8664e-01, time/batch = 0.6407s	
6600/26050 (epoch 12.668), train_loss = 1.02930395, grad/param norm = 1.7787e-01, time/batch = 0.6430s	
6601/26050 (epoch 12.670), train_loss = 1.38268428, grad/param norm = 1.8813e-01, time/batch = 0.6448s	
6602/26050 (epoch 12.672), train_loss = 1.16684389, grad/param norm = 1.6928e-01, time/batch = 0.6684s	
6603/26050 (epoch 12.674), train_loss = 1.11222746, grad/param norm = 1.7195e-01, time/batch = 0.6744s	
6604/26050 (epoch 12.676), train_loss = 1.25043371, grad/param norm = 1.7496e-01, time/batch = 0.6387s	
6605/26050 (epoch 12.678), train_loss = 1.36003163, grad/param norm = 1.8281e-01, time/batch = 0.6394s	
6606/26050 (epoch 12.679), train_loss = 1.44711766, grad/param norm = 1.9576e-01, time/batch = 0.6411s	
6607/26050 (epoch 12.681), train_loss = 1.24425169, grad/param norm = 1.8025e-01, time/batch = 0.6456s	
6608/26050 (epoch 12.683), train_loss = 1.12321830, grad/param norm = 2.0450e-01, time/batch = 0.6384s	
6609/26050 (epoch 12.685), train_loss = 1.18030816, grad/param norm = 1.6137e-01, time/batch = 0.6428s	
6610/26050 (epoch 12.687), train_loss = 1.03360340, grad/param norm = 1.6257e-01, time/batch = 0.6395s	
6611/26050 (epoch 12.689), train_loss = 1.19213645, grad/param norm = 1.7174e-01, time/batch = 0.6389s	
6612/26050 (epoch 12.691), train_loss = 0.95934106, grad/param norm = 1.5568e-01, time/batch = 0.6404s	
6613/26050 (epoch 12.693), train_loss = 1.12463095, grad/param norm = 1.6860e-01, time/batch = 0.6404s	
6614/26050 (epoch 12.695), train_loss = 1.23568584, grad/param norm = 1.7629e-01, time/batch = 0.6480s	
6615/26050 (epoch 12.697), train_loss = 1.12221302, grad/param norm = 1.7421e-01, time/batch = 0.6439s	
6616/26050 (epoch 12.699), train_loss = 1.28365787, grad/param norm = 1.8241e-01, time/batch = 0.6413s	
6617/26050 (epoch 12.701), train_loss = 1.07028622, grad/param norm = 1.5270e-01, time/batch = 0.6555s	
6618/26050 (epoch 12.702), train_loss = 1.41968656, grad/param norm = 1.8966e-01, time/batch = 0.6832s	
6619/26050 (epoch 12.704), train_loss = 1.26965014, grad/param norm = 1.7080e-01, time/batch = 0.6527s	
6620/26050 (epoch 12.706), train_loss = 1.27154315, grad/param norm = 1.9689e-01, time/batch = 0.6388s	
6621/26050 (epoch 12.708), train_loss = 1.30873157, grad/param norm = 1.8205e-01, time/batch = 0.6392s	
6622/26050 (epoch 12.710), train_loss = 1.27907249, grad/param norm = 1.7702e-01, time/batch = 0.6401s	
6623/26050 (epoch 12.712), train_loss = 1.35019486, grad/param norm = 1.7922e-01, time/batch = 0.6385s	
6624/26050 (epoch 12.714), train_loss = 1.06516374, grad/param norm = 1.6971e-01, time/batch = 0.6391s	
6625/26050 (epoch 12.716), train_loss = 1.49406462, grad/param norm = 2.0560e-01, time/batch = 0.6411s	
6626/26050 (epoch 12.718), train_loss = 1.33868226, grad/param norm = 1.8597e-01, time/batch = 0.6382s	
6627/26050 (epoch 12.720), train_loss = 1.15219568, grad/param norm = 1.6772e-01, time/batch = 0.6379s	
6628/26050 (epoch 12.722), train_loss = 1.09859314, grad/param norm = 1.6887e-01, time/batch = 0.6393s	
6629/26050 (epoch 12.724), train_loss = 1.10542761, grad/param norm = 1.7384e-01, time/batch = 0.6405s	
6630/26050 (epoch 12.726), train_loss = 1.34655672, grad/param norm = 1.8060e-01, time/batch = 0.6394s	
6631/26050 (epoch 12.727), train_loss = 1.27810333, grad/param norm = 1.7227e-01, time/batch = 0.6399s	
6632/26050 (epoch 12.729), train_loss = 1.28072568, grad/param norm = 1.7260e-01, time/batch = 0.6467s	
6633/26050 (epoch 12.731), train_loss = 1.26097399, grad/param norm = 1.6216e-01, time/batch = 0.6743s	
6634/26050 (epoch 12.733), train_loss = 1.18668020, grad/param norm = 1.9308e-01, time/batch = 0.6698s	
6635/26050 (epoch 12.735), train_loss = 1.41477694, grad/param norm = 1.8855e-01, time/batch = 0.6391s	
6636/26050 (epoch 12.737), train_loss = 1.21834819, grad/param norm = 1.7166e-01, time/batch = 0.6395s	
6637/26050 (epoch 12.739), train_loss = 1.28695561, grad/param norm = 1.6806e-01, time/batch = 0.6396s	
6638/26050 (epoch 12.741), train_loss = 1.14457904, grad/param norm = 1.7428e-01, time/batch = 0.6420s	
6639/26050 (epoch 12.743), train_loss = 1.28761125, grad/param norm = 1.8820e-01, time/batch = 0.6404s	
6640/26050 (epoch 12.745), train_loss = 1.11316243, grad/param norm = 1.7156e-01, time/batch = 0.6434s	
6641/26050 (epoch 12.747), train_loss = 1.11889892, grad/param norm = 1.5306e-01, time/batch = 0.6486s	
6642/26050 (epoch 12.749), train_loss = 1.37485017, grad/param norm = 1.8696e-01, time/batch = 0.6399s	
6643/26050 (epoch 12.750), train_loss = 1.22375276, grad/param norm = 1.6029e-01, time/batch = 0.6547s	
6644/26050 (epoch 12.752), train_loss = 1.21482641, grad/param norm = 1.9660e-01, time/batch = 0.6570s	
6645/26050 (epoch 12.754), train_loss = 1.24442767, grad/param norm = 1.7621e-01, time/batch = 0.6518s	
6646/26050 (epoch 12.756), train_loss = 1.23814052, grad/param norm = 1.7833e-01, time/batch = 0.6493s	
6647/26050 (epoch 12.758), train_loss = 1.24285810, grad/param norm = 1.8032e-01, time/batch = 0.6497s	
6648/26050 (epoch 12.760), train_loss = 1.34567643, grad/param norm = 1.6935e-01, time/batch = 0.6678s	
6649/26050 (epoch 12.762), train_loss = 1.14223892, grad/param norm = 1.6153e-01, time/batch = 0.6834s	
6650/26050 (epoch 12.764), train_loss = 1.30298035, grad/param norm = 1.7945e-01, time/batch = 0.6500s	
6651/26050 (epoch 12.766), train_loss = 1.31442984, grad/param norm = 1.9020e-01, time/batch = 0.6509s	
6652/26050 (epoch 12.768), train_loss = 1.09998676, grad/param norm = 1.5192e-01, time/batch = 0.6466s	
6653/26050 (epoch 12.770), train_loss = 1.20475806, grad/param norm = 1.8839e-01, time/batch = 0.6446s	
6654/26050 (epoch 12.772), train_loss = 1.20369175, grad/param norm = 1.7162e-01, time/batch = 0.6537s	
6655/26050 (epoch 12.774), train_loss = 1.08277076, grad/param norm = 1.7074e-01, time/batch = 0.6609s	
6656/26050 (epoch 12.775), train_loss = 0.92395205, grad/param norm = 1.5747e-01, time/batch = 0.6524s	
6657/26050 (epoch 12.777), train_loss = 1.12520100, grad/param norm = 1.6084e-01, time/batch = 0.6507s	
6658/26050 (epoch 12.779), train_loss = 1.19589711, grad/param norm = 1.7469e-01, time/batch = 0.6482s	
6659/26050 (epoch 12.781), train_loss = 1.16697354, grad/param norm = 1.6740e-01, time/batch = 0.6430s	
6660/26050 (epoch 12.783), train_loss = 1.12923564, grad/param norm = 1.6066e-01, time/batch = 0.6420s	
6661/26050 (epoch 12.785), train_loss = 1.18472966, grad/param norm = 1.7453e-01, time/batch = 0.6440s	
6662/26050 (epoch 12.787), train_loss = 1.15151500, grad/param norm = 1.6697e-01, time/batch = 0.6438s	
6663/26050 (epoch 12.789), train_loss = 1.15586010, grad/param norm = 1.8764e-01, time/batch = 0.6435s	
6664/26050 (epoch 12.791), train_loss = 1.20115391, grad/param norm = 1.6791e-01, time/batch = 0.6425s	
6665/26050 (epoch 12.793), train_loss = 1.18930916, grad/param norm = 1.8291e-01, time/batch = 0.6403s	
6666/26050 (epoch 12.795), train_loss = 1.04061918, grad/param norm = 1.5084e-01, time/batch = 0.6392s	
6667/26050 (epoch 12.797), train_loss = 1.14153435, grad/param norm = 1.7225e-01, time/batch = 0.6380s	
6668/26050 (epoch 12.798), train_loss = 1.07465562, grad/param norm = 1.6457e-01, time/batch = 0.6409s	
6669/26050 (epoch 12.800), train_loss = 1.05892111, grad/param norm = 1.4476e-01, time/batch = 0.6409s	
6670/26050 (epoch 12.802), train_loss = 1.18425013, grad/param norm = 1.7776e-01, time/batch = 0.6475s	
6671/26050 (epoch 12.804), train_loss = 1.17163429, grad/param norm = 1.6718e-01, time/batch = 0.6583s	
6672/26050 (epoch 12.806), train_loss = 1.30459720, grad/param norm = 1.8922e-01, time/batch = 0.6515s	
6673/26050 (epoch 12.808), train_loss = 1.17830008, grad/param norm = 1.6849e-01, time/batch = 0.6414s	
6674/26050 (epoch 12.810), train_loss = 1.14345008, grad/param norm = 1.6473e-01, time/batch = 0.6483s	
6675/26050 (epoch 12.812), train_loss = 1.09102890, grad/param norm = 1.8517e-01, time/batch = 0.6421s	
6676/26050 (epoch 12.814), train_loss = 1.07819298, grad/param norm = 1.7838e-01, time/batch = 0.6398s	
6677/26050 (epoch 12.816), train_loss = 1.30563208, grad/param norm = 1.7977e-01, time/batch = 0.6530s	
6678/26050 (epoch 12.818), train_loss = 1.35827240, grad/param norm = 1.9760e-01, time/batch = 0.6622s	
6679/26050 (epoch 12.820), train_loss = 1.23117409, grad/param norm = 1.7724e-01, time/batch = 0.6804s	
6680/26050 (epoch 12.821), train_loss = 1.37111361, grad/param norm = 1.9779e-01, time/batch = 0.6767s	
6681/26050 (epoch 12.823), train_loss = 1.39349922, grad/param norm = 1.8646e-01, time/batch = 0.6613s	
6682/26050 (epoch 12.825), train_loss = 1.20086557, grad/param norm = 1.8571e-01, time/batch = 0.6536s	
6683/26050 (epoch 12.827), train_loss = 1.24379094, grad/param norm = 1.9209e-01, time/batch = 0.6541s	
6684/26050 (epoch 12.829), train_loss = 1.27007640, grad/param norm = 1.8729e-01, time/batch = 0.6594s	
6685/26050 (epoch 12.831), train_loss = 1.34683328, grad/param norm = 1.7777e-01, time/batch = 0.6631s	
6686/26050 (epoch 12.833), train_loss = 1.41830729, grad/param norm = 1.8467e-01, time/batch = 0.6690s	
6687/26050 (epoch 12.835), train_loss = 1.44034729, grad/param norm = 1.9036e-01, time/batch = 0.6662s	
6688/26050 (epoch 12.837), train_loss = 1.19992864, grad/param norm = 1.8388e-01, time/batch = 0.6556s	
6689/26050 (epoch 12.839), train_loss = 1.27244131, grad/param norm = 1.9356e-01, time/batch = 0.6515s	
6690/26050 (epoch 12.841), train_loss = 1.33732856, grad/param norm = 1.7482e-01, time/batch = 0.6392s	
6691/26050 (epoch 12.843), train_loss = 1.24358713, grad/param norm = 1.8017e-01, time/batch = 0.6399s	
6692/26050 (epoch 12.845), train_loss = 1.14489549, grad/param norm = 1.5607e-01, time/batch = 0.6440s	
6693/26050 (epoch 12.846), train_loss = 1.33921300, grad/param norm = 1.7748e-01, time/batch = 0.6443s	
6694/26050 (epoch 12.848), train_loss = 1.17883088, grad/param norm = 1.8065e-01, time/batch = 0.6719s	
6695/26050 (epoch 12.850), train_loss = 1.15366225, grad/param norm = 1.7707e-01, time/batch = 0.6787s	
6696/26050 (epoch 12.852), train_loss = 1.18550691, grad/param norm = 1.7234e-01, time/batch = 0.6418s	
6697/26050 (epoch 12.854), train_loss = 1.21219616, grad/param norm = 1.8633e-01, time/batch = 0.6400s	
6698/26050 (epoch 12.856), train_loss = 1.15992296, grad/param norm = 1.7947e-01, time/batch = 0.6537s	
6699/26050 (epoch 12.858), train_loss = 1.09540859, grad/param norm = 1.6745e-01, time/batch = 0.6592s	
6700/26050 (epoch 12.860), train_loss = 1.26043958, grad/param norm = 1.8449e-01, time/batch = 0.6420s	
6701/26050 (epoch 12.862), train_loss = 1.24091414, grad/param norm = 1.6959e-01, time/batch = 0.6461s	
6702/26050 (epoch 12.864), train_loss = 1.24391797, grad/param norm = 1.9403e-01, time/batch = 0.6403s	
6703/26050 (epoch 12.866), train_loss = 1.15409069, grad/param norm = 1.5884e-01, time/batch = 0.6393s	
6704/26050 (epoch 12.868), train_loss = 1.30760064, grad/param norm = 1.8169e-01, time/batch = 0.6405s	
6705/26050 (epoch 12.869), train_loss = 1.10552661, grad/param norm = 1.5935e-01, time/batch = 0.6412s	
6706/26050 (epoch 12.871), train_loss = 1.05154875, grad/param norm = 1.6117e-01, time/batch = 0.6392s	
6707/26050 (epoch 12.873), train_loss = 1.27025378, grad/param norm = 1.6850e-01, time/batch = 0.6387s	
6708/26050 (epoch 12.875), train_loss = 1.20544463, grad/param norm = 1.7372e-01, time/batch = 0.6424s	
6709/26050 (epoch 12.877), train_loss = 1.09408454, grad/param norm = 1.7290e-01, time/batch = 0.6490s	
6710/26050 (epoch 12.879), train_loss = 1.21596020, grad/param norm = 1.5750e-01, time/batch = 0.6832s	
6711/26050 (epoch 12.881), train_loss = 1.34667418, grad/param norm = 1.7492e-01, time/batch = 0.6513s	
6712/26050 (epoch 12.883), train_loss = 1.25605903, grad/param norm = 1.7564e-01, time/batch = 0.6394s	
6713/26050 (epoch 12.885), train_loss = 0.95320442, grad/param norm = 1.5173e-01, time/batch = 0.6394s	
6714/26050 (epoch 12.887), train_loss = 1.24386563, grad/param norm = 1.7690e-01, time/batch = 0.6388s	
6715/26050 (epoch 12.889), train_loss = 1.15785511, grad/param norm = 1.6048e-01, time/batch = 0.6421s	
6716/26050 (epoch 12.891), train_loss = 0.96936065, grad/param norm = 1.4941e-01, time/batch = 0.6383s	
6717/26050 (epoch 12.893), train_loss = 0.98396946, grad/param norm = 1.5566e-01, time/batch = 0.6440s	
6718/26050 (epoch 12.894), train_loss = 1.17682413, grad/param norm = 1.6827e-01, time/batch = 0.6454s	
6719/26050 (epoch 12.896), train_loss = 1.33003669, grad/param norm = 1.7966e-01, time/batch = 0.6394s	
6720/26050 (epoch 12.898), train_loss = 1.14935678, grad/param norm = 1.8062e-01, time/batch = 0.6401s	
6721/26050 (epoch 12.900), train_loss = 1.32175776, grad/param norm = 1.8032e-01, time/batch = 0.6412s	
6722/26050 (epoch 12.902), train_loss = 1.20365784, grad/param norm = 1.7991e-01, time/batch = 0.6405s	
6723/26050 (epoch 12.904), train_loss = 1.17452689, grad/param norm = 1.6543e-01, time/batch = 0.6398s	
6724/26050 (epoch 12.906), train_loss = 1.19743025, grad/param norm = 1.7782e-01, time/batch = 0.6458s	
6725/26050 (epoch 12.908), train_loss = 1.17702324, grad/param norm = 1.6817e-01, time/batch = 0.6749s	
6726/26050 (epoch 12.910), train_loss = 1.10793461, grad/param norm = 1.5065e-01, time/batch = 0.6685s	
6727/26050 (epoch 12.912), train_loss = 1.45220373, grad/param norm = 1.9056e-01, time/batch = 0.6409s	
6728/26050 (epoch 12.914), train_loss = 1.59577130, grad/param norm = 1.9726e-01, time/batch = 0.6401s	
6729/26050 (epoch 12.916), train_loss = 1.33077578, grad/param norm = 1.9529e-01, time/batch = 0.6401s	
6730/26050 (epoch 12.917), train_loss = 1.23711483, grad/param norm = 2.0202e-01, time/batch = 0.6419s	
6731/26050 (epoch 12.919), train_loss = 1.31034541, grad/param norm = 1.8877e-01, time/batch = 0.6400s	
6732/26050 (epoch 12.921), train_loss = 1.15583309, grad/param norm = 1.8089e-01, time/batch = 0.6409s	
6733/26050 (epoch 12.923), train_loss = 1.22601791, grad/param norm = 1.8439e-01, time/batch = 0.6447s	
6734/26050 (epoch 12.925), train_loss = 1.20571243, grad/param norm = 1.6994e-01, time/batch = 0.6402s	
6735/26050 (epoch 12.927), train_loss = 1.08677488, grad/param norm = 1.5539e-01, time/batch = 0.6449s	
6736/26050 (epoch 12.929), train_loss = 1.11876742, grad/param norm = 1.6720e-01, time/batch = 0.6484s	
6737/26050 (epoch 12.931), train_loss = 1.42962457, grad/param norm = 2.0738e-01, time/batch = 0.6438s	
6738/26050 (epoch 12.933), train_loss = 1.18346610, grad/param norm = 1.8352e-01, time/batch = 0.6402s	
6739/26050 (epoch 12.935), train_loss = 1.14548225, grad/param norm = 1.5618e-01, time/batch = 0.6420s	
6740/26050 (epoch 12.937), train_loss = 1.27840236, grad/param norm = 1.7870e-01, time/batch = 0.6427s	
6741/26050 (epoch 12.939), train_loss = 1.09900194, grad/param norm = 1.4321e-01, time/batch = 0.6415s	
6742/26050 (epoch 12.940), train_loss = 1.22481286, grad/param norm = 1.6707e-01, time/batch = 0.6408s	
6743/26050 (epoch 12.942), train_loss = 1.25441525, grad/param norm = 1.9036e-01, time/batch = 0.6397s	
6744/26050 (epoch 12.944), train_loss = 1.17285003, grad/param norm = 1.7028e-01, time/batch = 0.6404s	
6745/26050 (epoch 12.946), train_loss = 1.38089211, grad/param norm = 1.8286e-01, time/batch = 0.6404s	
6746/26050 (epoch 12.948), train_loss = 1.04622164, grad/param norm = 1.8794e-01, time/batch = 0.6413s	
6747/26050 (epoch 12.950), train_loss = 1.20676111, grad/param norm = 1.8063e-01, time/batch = 0.6429s	
6748/26050 (epoch 12.952), train_loss = 1.34602387, grad/param norm = 1.9529e-01, time/batch = 0.6441s	
6749/26050 (epoch 12.954), train_loss = 1.32177717, grad/param norm = 1.8434e-01, time/batch = 0.6405s	
6750/26050 (epoch 12.956), train_loss = 1.22847639, grad/param norm = 1.8342e-01, time/batch = 0.6390s	
6751/26050 (epoch 12.958), train_loss = 1.17579197, grad/param norm = 1.7489e-01, time/batch = 0.6411s	
6752/26050 (epoch 12.960), train_loss = 1.21254888, grad/param norm = 1.8085e-01, time/batch = 0.6417s	
6753/26050 (epoch 12.962), train_loss = 1.14042269, grad/param norm = 1.6518e-01, time/batch = 0.6405s	
6754/26050 (epoch 12.964), train_loss = 1.20904223, grad/param norm = 1.7220e-01, time/batch = 0.6407s	
6755/26050 (epoch 12.965), train_loss = 1.11229062, grad/param norm = 1.7362e-01, time/batch = 0.6462s	
6756/26050 (epoch 12.967), train_loss = 1.52067248, grad/param norm = 1.7640e-01, time/batch = 0.6780s	
6757/26050 (epoch 12.969), train_loss = 1.19952506, grad/param norm = 1.6606e-01, time/batch = 0.6662s	
6758/26050 (epoch 12.971), train_loss = 1.12005250, grad/param norm = 1.5185e-01, time/batch = 0.6420s	
6759/26050 (epoch 12.973), train_loss = 1.18377496, grad/param norm = 1.9161e-01, time/batch = 0.6405s	
6760/26050 (epoch 12.975), train_loss = 1.27451671, grad/param norm = 1.6333e-01, time/batch = 0.6387s	
6761/26050 (epoch 12.977), train_loss = 1.24651662, grad/param norm = 1.6574e-01, time/batch = 0.6421s	
6762/26050 (epoch 12.979), train_loss = 1.04772078, grad/param norm = 1.6706e-01, time/batch = 0.6493s	
6763/26050 (epoch 12.981), train_loss = 1.33950215, grad/param norm = 1.6496e-01, time/batch = 0.6581s	
6764/26050 (epoch 12.983), train_loss = 1.32482461, grad/param norm = 1.7597e-01, time/batch = 0.6488s	
6765/26050 (epoch 12.985), train_loss = 1.24599904, grad/param norm = 1.7433e-01, time/batch = 0.6495s	
6766/26050 (epoch 12.987), train_loss = 1.35804492, grad/param norm = 1.8833e-01, time/batch = 0.6438s	
6767/26050 (epoch 12.988), train_loss = 1.31475117, grad/param norm = 1.7081e-01, time/batch = 0.6488s	
6768/26050 (epoch 12.990), train_loss = 1.10478833, grad/param norm = 1.5001e-01, time/batch = 0.6436s	
6769/26050 (epoch 12.992), train_loss = 1.35877395, grad/param norm = 1.8109e-01, time/batch = 0.6386s	
6770/26050 (epoch 12.994), train_loss = 1.24095042, grad/param norm = 1.8114e-01, time/batch = 0.6491s	
6771/26050 (epoch 12.996), train_loss = 1.17819538, grad/param norm = 1.8083e-01, time/batch = 0.6526s	
6772/26050 (epoch 12.998), train_loss = 1.22389789, grad/param norm = 1.7884e-01, time/batch = 0.6415s	
decayed learning rate by a factor 0.97 to 0.00177058562	
6773/26050 (epoch 13.000), train_loss = 1.17451227, grad/param norm = 1.7925e-01, time/batch = 0.6399s	
6774/26050 (epoch 13.002), train_loss = 1.29098093, grad/param norm = 1.9083e-01, time/batch = 0.6401s	
6775/26050 (epoch 13.004), train_loss = 1.10574946, grad/param norm = 1.7118e-01, time/batch = 0.6395s	
6776/26050 (epoch 13.006), train_loss = 1.12176668, grad/param norm = 1.6514e-01, time/batch = 0.6427s	
6777/26050 (epoch 13.008), train_loss = 1.10815042, grad/param norm = 1.7272e-01, time/batch = 0.6404s	
6778/26050 (epoch 13.010), train_loss = 1.15010834, grad/param norm = 1.7122e-01, time/batch = 0.6485s	
6779/26050 (epoch 13.012), train_loss = 1.23962632, grad/param norm = 1.7438e-01, time/batch = 0.6412s	
6780/26050 (epoch 13.013), train_loss = 1.60048606, grad/param norm = 1.9696e-01, time/batch = 0.6405s	
6781/26050 (epoch 13.015), train_loss = 1.12237708, grad/param norm = 1.5425e-01, time/batch = 0.6398s	
6782/26050 (epoch 13.017), train_loss = 1.22617420, grad/param norm = 1.6903e-01, time/batch = 0.6790s	
6783/26050 (epoch 13.019), train_loss = 1.01861643, grad/param norm = 1.4181e-01, time/batch = 0.6731s	
6784/26050 (epoch 13.021), train_loss = 1.28750723, grad/param norm = 1.7573e-01, time/batch = 0.6406s	
6785/26050 (epoch 13.023), train_loss = 1.05713521, grad/param norm = 1.6774e-01, time/batch = 0.6433s	
6786/26050 (epoch 13.025), train_loss = 1.19214958, grad/param norm = 1.6653e-01, time/batch = 0.6470s	
6787/26050 (epoch 13.027), train_loss = 0.98135311, grad/param norm = 1.6796e-01, time/batch = 0.6508s	
6788/26050 (epoch 13.029), train_loss = 1.19366558, grad/param norm = 1.6390e-01, time/batch = 0.6519s	
6789/26050 (epoch 13.031), train_loss = 1.33719050, grad/param norm = 1.8867e-01, time/batch = 0.6510s	
6790/26050 (epoch 13.033), train_loss = 1.24758754, grad/param norm = 1.7156e-01, time/batch = 0.6489s	
6791/26050 (epoch 13.035), train_loss = 1.28118751, grad/param norm = 1.6080e-01, time/batch = 0.6474s	
6792/26050 (epoch 13.036), train_loss = 1.09322846, grad/param norm = 1.8566e-01, time/batch = 0.6457s	
6793/26050 (epoch 13.038), train_loss = 1.04135309, grad/param norm = 1.6461e-01, time/batch = 0.6394s	
6794/26050 (epoch 13.040), train_loss = 1.23852493, grad/param norm = 1.8138e-01, time/batch = 0.6535s	
6795/26050 (epoch 13.042), train_loss = 1.05226207, grad/param norm = 1.8734e-01, time/batch = 0.6488s	
6796/26050 (epoch 13.044), train_loss = 1.29023222, grad/param norm = 1.6891e-01, time/batch = 0.6416s	
6797/26050 (epoch 13.046), train_loss = 1.00134527, grad/param norm = 1.6423e-01, time/batch = 0.6563s	
6798/26050 (epoch 13.048), train_loss = 1.24226520, grad/param norm = 1.7577e-01, time/batch = 0.6831s	
6799/26050 (epoch 13.050), train_loss = 1.10066032, grad/param norm = 1.7657e-01, time/batch = 0.6425s	
6800/26050 (epoch 13.052), train_loss = 1.17598987, grad/param norm = 1.7390e-01, time/batch = 0.6388s	
6801/26050 (epoch 13.054), train_loss = 1.03761745, grad/param norm = 1.5588e-01, time/batch = 0.6419s	
6802/26050 (epoch 13.056), train_loss = 0.96109284, grad/param norm = 1.3905e-01, time/batch = 0.6406s	
6803/26050 (epoch 13.058), train_loss = 1.12623534, grad/param norm = 1.5723e-01, time/batch = 0.6401s	
6804/26050 (epoch 13.060), train_loss = 1.22569656, grad/param norm = 1.6396e-01, time/batch = 0.6398s	
6805/26050 (epoch 13.061), train_loss = 1.10669850, grad/param norm = 1.6837e-01, time/batch = 0.6383s	
6806/26050 (epoch 13.063), train_loss = 1.20381860, grad/param norm = 1.6816e-01, time/batch = 0.6392s	
6807/26050 (epoch 13.065), train_loss = 1.01103700, grad/param norm = 1.5734e-01, time/batch = 0.6383s	
6808/26050 (epoch 13.067), train_loss = 1.23208359, grad/param norm = 1.7369e-01, time/batch = 0.6393s	
6809/26050 (epoch 13.069), train_loss = 1.24468473, grad/param norm = 1.6270e-01, time/batch = 0.6398s	
6810/26050 (epoch 13.071), train_loss = 1.25239065, grad/param norm = 1.6718e-01, time/batch = 0.6431s	
6811/26050 (epoch 13.073), train_loss = 1.41389813, grad/param norm = 1.8605e-01, time/batch = 0.6392s	
6812/26050 (epoch 13.075), train_loss = 1.10544095, grad/param norm = 1.6066e-01, time/batch = 0.6383s	
6813/26050 (epoch 13.077), train_loss = 1.10160941, grad/param norm = 1.6351e-01, time/batch = 0.6389s	
6814/26050 (epoch 13.079), train_loss = 1.22876410, grad/param norm = 1.7458e-01, time/batch = 0.6386s	
6815/26050 (epoch 13.081), train_loss = 1.14490228, grad/param norm = 1.9424e-01, time/batch = 0.6392s	
6816/26050 (epoch 13.083), train_loss = 1.27377096, grad/param norm = 1.7063e-01, time/batch = 0.6403s	
6817/26050 (epoch 13.084), train_loss = 1.27242826, grad/param norm = 1.8350e-01, time/batch = 0.6470s	
6818/26050 (epoch 13.086), train_loss = 1.34391657, grad/param norm = 1.8391e-01, time/batch = 0.6393s	
6819/26050 (epoch 13.088), train_loss = 1.08895362, grad/param norm = 1.6065e-01, time/batch = 0.6388s	
6820/26050 (epoch 13.090), train_loss = 1.25199814, grad/param norm = 1.7954e-01, time/batch = 0.6410s	
6821/26050 (epoch 13.092), train_loss = 1.22891194, grad/param norm = 1.7515e-01, time/batch = 0.6565s	
6822/26050 (epoch 13.094), train_loss = 1.16402887, grad/param norm = 1.8034e-01, time/batch = 0.6473s	
6823/26050 (epoch 13.096), train_loss = 1.15736561, grad/param norm = 1.6160e-01, time/batch = 0.6518s	
6824/26050 (epoch 13.098), train_loss = 1.17161395, grad/param norm = 1.7272e-01, time/batch = 0.6603s	
6825/26050 (epoch 13.100), train_loss = 1.08603276, grad/param norm = 1.7585e-01, time/batch = 0.6547s	
6826/26050 (epoch 13.102), train_loss = 1.19550142, grad/param norm = 1.6327e-01, time/batch = 0.6547s	
6827/26050 (epoch 13.104), train_loss = 1.19846322, grad/param norm = 1.7550e-01, time/batch = 0.6524s	
6828/26050 (epoch 13.106), train_loss = 1.18544684, grad/param norm = 1.8478e-01, time/batch = 0.6556s	
6829/26050 (epoch 13.107), train_loss = 0.98153224, grad/param norm = 1.6179e-01, time/batch = 0.6571s	
6830/26050 (epoch 13.109), train_loss = 1.12108274, grad/param norm = 1.7123e-01, time/batch = 0.6570s	
6831/26050 (epoch 13.111), train_loss = 1.37542771, grad/param norm = 1.8487e-01, time/batch = 0.6625s	
6832/26050 (epoch 13.113), train_loss = 1.14232837, grad/param norm = 1.6603e-01, time/batch = 0.6633s	
6833/26050 (epoch 13.115), train_loss = 1.28124190, grad/param norm = 1.7776e-01, time/batch = 0.6684s	
6834/26050 (epoch 13.117), train_loss = 1.24033258, grad/param norm = 1.7131e-01, time/batch = 0.6632s	
6835/26050 (epoch 13.119), train_loss = 0.97762660, grad/param norm = 1.5256e-01, time/batch = 0.6649s	
6836/26050 (epoch 13.121), train_loss = 1.23604188, grad/param norm = 1.6684e-01, time/batch = 0.6522s	
6837/26050 (epoch 13.123), train_loss = 1.08642665, grad/param norm = 1.7353e-01, time/batch = 0.6508s	
6838/26050 (epoch 13.125), train_loss = 1.01934071, grad/param norm = 1.5670e-01, time/batch = 0.6571s	
6839/26050 (epoch 13.127), train_loss = 0.95162288, grad/param norm = 1.5211e-01, time/batch = 0.6542s	
6840/26050 (epoch 13.129), train_loss = 1.00176483, grad/param norm = 1.5183e-01, time/batch = 0.6439s	
6841/26050 (epoch 13.131), train_loss = 1.16269794, grad/param norm = 1.6744e-01, time/batch = 0.6406s	
6842/26050 (epoch 13.132), train_loss = 1.14914115, grad/param norm = 1.6875e-01, time/batch = 0.6397s	
6843/26050 (epoch 13.134), train_loss = 1.14489554, grad/param norm = 1.7267e-01, time/batch = 0.6400s	
6844/26050 (epoch 13.136), train_loss = 1.18738377, grad/param norm = 1.6829e-01, time/batch = 0.6403s	
6845/26050 (epoch 13.138), train_loss = 0.98434214, grad/param norm = 1.6675e-01, time/batch = 0.6390s	
6846/26050 (epoch 13.140), train_loss = 1.03341211, grad/param norm = 1.6783e-01, time/batch = 0.6404s	
6847/26050 (epoch 13.142), train_loss = 1.08981091, grad/param norm = 1.6955e-01, time/batch = 0.6415s	
6848/26050 (epoch 13.144), train_loss = 1.00004572, grad/param norm = 1.6405e-01, time/batch = 0.6405s	
6849/26050 (epoch 13.146), train_loss = 0.92878555, grad/param norm = 1.6356e-01, time/batch = 0.6401s	
6850/26050 (epoch 13.148), train_loss = 0.94172586, grad/param norm = 1.3731e-01, time/batch = 0.6392s	
6851/26050 (epoch 13.150), train_loss = 1.16679654, grad/param norm = 1.9339e-01, time/batch = 0.6442s	
6852/26050 (epoch 13.152), train_loss = 1.39820800, grad/param norm = 2.1172e-01, time/batch = 0.6421s	
6853/26050 (epoch 13.154), train_loss = 0.95064026, grad/param norm = 1.5805e-01, time/batch = 0.6427s	
6854/26050 (epoch 13.155), train_loss = 1.00118637, grad/param norm = 1.5999e-01, time/batch = 0.6420s	
6855/26050 (epoch 13.157), train_loss = 1.12137227, grad/param norm = 1.9132e-01, time/batch = 0.6583s	
6856/26050 (epoch 13.159), train_loss = 1.14285680, grad/param norm = 1.8334e-01, time/batch = 0.6609s	
6857/26050 (epoch 13.161), train_loss = 1.27891813, grad/param norm = 1.9090e-01, time/batch = 0.6543s	
6858/26050 (epoch 13.163), train_loss = 0.99836805, grad/param norm = 1.6225e-01, time/batch = 0.6617s	
6859/26050 (epoch 13.165), train_loss = 0.90156355, grad/param norm = 1.4893e-01, time/batch = 0.6572s	
6860/26050 (epoch 13.167), train_loss = 1.27917170, grad/param norm = 1.8865e-01, time/batch = 0.6410s	
6861/26050 (epoch 13.169), train_loss = 1.22619769, grad/param norm = 1.6770e-01, time/batch = 0.6403s	
6862/26050 (epoch 13.171), train_loss = 0.96915271, grad/param norm = 1.4580e-01, time/batch = 0.6600s	
6863/26050 (epoch 13.173), train_loss = 1.11620583, grad/param norm = 1.8811e-01, time/batch = 0.6651s	
6864/26050 (epoch 13.175), train_loss = 1.16742128, grad/param norm = 1.6553e-01, time/batch = 0.6848s	
6865/26050 (epoch 13.177), train_loss = 1.28676546, grad/param norm = 1.7362e-01, time/batch = 0.6513s	
6866/26050 (epoch 13.179), train_loss = 0.92224485, grad/param norm = 1.5094e-01, time/batch = 0.6419s	
6867/26050 (epoch 13.180), train_loss = 1.41310011, grad/param norm = 1.7625e-01, time/batch = 0.6651s	
6868/26050 (epoch 13.182), train_loss = 1.42496292, grad/param norm = 1.9554e-01, time/batch = 0.6633s	
6869/26050 (epoch 13.184), train_loss = 1.18444759, grad/param norm = 1.6476e-01, time/batch = 0.6611s	
6870/26050 (epoch 13.186), train_loss = 0.97288117, grad/param norm = 1.4753e-01, time/batch = 0.6613s	
6871/26050 (epoch 13.188), train_loss = 1.17286572, grad/param norm = 1.6663e-01, time/batch = 0.6642s	
6872/26050 (epoch 13.190), train_loss = 1.22861750, grad/param norm = 1.7568e-01, time/batch = 0.6548s	
6873/26050 (epoch 13.192), train_loss = 1.21092880, grad/param norm = 1.5915e-01, time/batch = 0.6555s	
6874/26050 (epoch 13.194), train_loss = 1.20189507, grad/param norm = 1.6612e-01, time/batch = 0.6608s	
6875/26050 (epoch 13.196), train_loss = 1.27136524, grad/param norm = 1.8300e-01, time/batch = 0.6600s	
6876/26050 (epoch 13.198), train_loss = 1.09938360, grad/param norm = 1.6448e-01, time/batch = 0.6594s	
6877/26050 (epoch 13.200), train_loss = 1.07471096, grad/param norm = 1.6943e-01, time/batch = 0.6673s	
6878/26050 (epoch 13.202), train_loss = 1.12806193, grad/param norm = 1.7702e-01, time/batch = 0.6696s	
6879/26050 (epoch 13.203), train_loss = 1.27967995, grad/param norm = 1.8366e-01, time/batch = 0.6466s	
6880/26050 (epoch 13.205), train_loss = 1.10074935, grad/param norm = 1.6680e-01, time/batch = 0.6392s	
6881/26050 (epoch 13.207), train_loss = 1.12876631, grad/param norm = 1.6084e-01, time/batch = 0.6396s	
6882/26050 (epoch 13.209), train_loss = 1.16893449, grad/param norm = 1.6160e-01, time/batch = 0.6389s	
6883/26050 (epoch 13.211), train_loss = 1.00406762, grad/param norm = 1.6119e-01, time/batch = 0.6390s	
6884/26050 (epoch 13.213), train_loss = 1.23274263, grad/param norm = 1.8262e-01, time/batch = 0.6439s	
6885/26050 (epoch 13.215), train_loss = 1.16517961, grad/param norm = 1.8285e-01, time/batch = 0.6385s	
6886/26050 (epoch 13.217), train_loss = 1.14963195, grad/param norm = 1.6413e-01, time/batch = 0.6522s	
6887/26050 (epoch 13.219), train_loss = 1.11447801, grad/param norm = 1.7525e-01, time/batch = 0.6498s	
6888/26050 (epoch 13.221), train_loss = 1.04113194, grad/param norm = 1.5719e-01, time/batch = 0.6394s	
6889/26050 (epoch 13.223), train_loss = 1.18843127, grad/param norm = 1.6724e-01, time/batch = 0.6581s	
6890/26050 (epoch 13.225), train_loss = 1.07399526, grad/param norm = 1.7602e-01, time/batch = 0.6830s	
6891/26050 (epoch 13.226), train_loss = 1.26422510, grad/param norm = 1.8001e-01, time/batch = 0.6434s	
6892/26050 (epoch 13.228), train_loss = 1.30749750, grad/param norm = 1.8085e-01, time/batch = 0.6413s	
6893/26050 (epoch 13.230), train_loss = 1.21276948, grad/param norm = 1.6620e-01, time/batch = 0.6413s	
6894/26050 (epoch 13.232), train_loss = 1.29217527, grad/param norm = 1.8275e-01, time/batch = 0.6430s	
6895/26050 (epoch 13.234), train_loss = 1.02979098, grad/param norm = 1.6445e-01, time/batch = 0.6396s	
6896/26050 (epoch 13.236), train_loss = 1.26389543, grad/param norm = 1.7705e-01, time/batch = 0.6414s	
6897/26050 (epoch 13.238), train_loss = 1.00533952, grad/param norm = 1.6112e-01, time/batch = 0.6416s	
6898/26050 (epoch 13.240), train_loss = 1.14699463, grad/param norm = 1.6955e-01, time/batch = 0.6396s	
6899/26050 (epoch 13.242), train_loss = 1.17169232, grad/param norm = 1.5544e-01, time/batch = 0.6397s	
6900/26050 (epoch 13.244), train_loss = 1.18648307, grad/param norm = 1.8385e-01, time/batch = 0.6408s	
6901/26050 (epoch 13.246), train_loss = 1.09894531, grad/param norm = 1.6200e-01, time/batch = 0.6443s	
6902/26050 (epoch 13.248), train_loss = 1.19190261, grad/param norm = 1.6840e-01, time/batch = 0.6456s	
6903/26050 (epoch 13.250), train_loss = 1.17029509, grad/param norm = 1.8053e-01, time/batch = 0.6410s	
6904/26050 (epoch 13.251), train_loss = 1.10137587, grad/param norm = 1.6324e-01, time/batch = 0.6400s	
6905/26050 (epoch 13.253), train_loss = 1.02724761, grad/param norm = 1.6322e-01, time/batch = 0.6400s	
6906/26050 (epoch 13.255), train_loss = 1.37720018, grad/param norm = 1.7192e-01, time/batch = 0.6413s	
6907/26050 (epoch 13.257), train_loss = 1.18212720, grad/param norm = 1.8790e-01, time/batch = 0.6397s	
6908/26050 (epoch 13.259), train_loss = 1.32439757, grad/param norm = 1.7591e-01, time/batch = 0.6438s	
6909/26050 (epoch 13.261), train_loss = 1.07362741, grad/param norm = 1.8574e-01, time/batch = 0.6425s	
6910/26050 (epoch 13.263), train_loss = 1.20324199, grad/param norm = 1.7274e-01, time/batch = 0.6396s	
6911/26050 (epoch 13.265), train_loss = 1.35121955, grad/param norm = 1.8215e-01, time/batch = 0.6426s	
6912/26050 (epoch 13.267), train_loss = 1.26892188, grad/param norm = 1.6877e-01, time/batch = 0.6413s	
6913/26050 (epoch 13.269), train_loss = 1.36076528, grad/param norm = 1.9535e-01, time/batch = 0.6528s	
6914/26050 (epoch 13.271), train_loss = 1.23676278, grad/param norm = 1.8354e-01, time/batch = 0.6524s	
6915/26050 (epoch 13.273), train_loss = 1.13992214, grad/param norm = 1.8495e-01, time/batch = 0.6458s	
6916/26050 (epoch 13.274), train_loss = 1.13585940, grad/param norm = 1.6939e-01, time/batch = 0.6500s	
6917/26050 (epoch 13.276), train_loss = 1.10711923, grad/param norm = 1.7786e-01, time/batch = 0.8048s	
6918/26050 (epoch 13.278), train_loss = 1.30731048, grad/param norm = 1.8222e-01, time/batch = 0.9418s	
6919/26050 (epoch 13.280), train_loss = 1.15901651, grad/param norm = 1.6058e-01, time/batch = 0.9401s	
6920/26050 (epoch 13.282), train_loss = 1.21729862, grad/param norm = 1.8221e-01, time/batch = 0.9410s	
6921/26050 (epoch 13.284), train_loss = 1.11089447, grad/param norm = 1.7320e-01, time/batch = 0.9427s	
6922/26050 (epoch 13.286), train_loss = 1.18678028, grad/param norm = 1.7405e-01, time/batch = 1.1638s	
6923/26050 (epoch 13.288), train_loss = 1.01741606, grad/param norm = 1.6508e-01, time/batch = 1.7524s	
6924/26050 (epoch 13.290), train_loss = 1.15321575, grad/param norm = 1.6395e-01, time/batch = 1.7423s	
6925/26050 (epoch 13.292), train_loss = 1.07723206, grad/param norm = 1.5625e-01, time/batch = 9.4238s	
6926/26050 (epoch 13.294), train_loss = 1.20806933, grad/param norm = 1.8596e-01, time/batch = 16.4801s	
6927/26050 (epoch 13.296), train_loss = 1.30624138, grad/param norm = 1.7485e-01, time/batch = 18.0727s	
6928/26050 (epoch 13.298), train_loss = 1.17954473, grad/param norm = 1.6906e-01, time/batch = 17.7386s	
6929/26050 (epoch 13.299), train_loss = 0.93492611, grad/param norm = 1.4709e-01, time/batch = 16.7471s	
6930/26050 (epoch 13.301), train_loss = 1.08583871, grad/param norm = 1.8070e-01, time/batch = 18.1530s	
6931/26050 (epoch 13.303), train_loss = 1.21101603, grad/param norm = 1.7998e-01, time/batch = 17.5677s	
6932/26050 (epoch 13.305), train_loss = 1.02385560, grad/param norm = 1.8167e-01, time/batch = 16.8351s	
6933/26050 (epoch 13.307), train_loss = 1.09050140, grad/param norm = 1.7389e-01, time/batch = 16.1291s	
6934/26050 (epoch 13.309), train_loss = 1.14815092, grad/param norm = 1.7871e-01, time/batch = 16.2976s	
6935/26050 (epoch 13.311), train_loss = 1.30842520, grad/param norm = 1.8685e-01, time/batch = 18.6505s	
6936/26050 (epoch 13.313), train_loss = 1.16615666, grad/param norm = 1.9260e-01, time/batch = 17.8218s	
6937/26050 (epoch 13.315), train_loss = 1.28305048, grad/param norm = 1.7527e-01, time/batch = 17.3944s	
6938/26050 (epoch 13.317), train_loss = 1.14299787, grad/param norm = 1.6614e-01, time/batch = 18.4910s	
6939/26050 (epoch 13.319), train_loss = 1.12320238, grad/param norm = 1.6709e-01, time/batch = 17.4784s	
6940/26050 (epoch 13.321), train_loss = 1.12679984, grad/param norm = 1.7333e-01, time/batch = 18.0705s	
6941/26050 (epoch 13.322), train_loss = 1.20168635, grad/param norm = 1.7516e-01, time/batch = 18.2322s	
6942/26050 (epoch 13.324), train_loss = 1.00110131, grad/param norm = 1.7375e-01, time/batch = 18.4773s	
6943/26050 (epoch 13.326), train_loss = 1.33798877, grad/param norm = 1.8129e-01, time/batch = 16.7984s	
6944/26050 (epoch 13.328), train_loss = 1.22500086, grad/param norm = 1.6555e-01, time/batch = 16.3905s	
6945/26050 (epoch 13.330), train_loss = 1.07343632, grad/param norm = 1.6992e-01, time/batch = 15.4677s	
6946/26050 (epoch 13.332), train_loss = 1.24764218, grad/param norm = 1.7530e-01, time/batch = 17.3238s	
6947/26050 (epoch 13.334), train_loss = 1.13701228, grad/param norm = 1.7675e-01, time/batch = 18.0742s	
6948/26050 (epoch 13.336), train_loss = 1.08353308, grad/param norm = 1.6077e-01, time/batch = 18.1666s	
6949/26050 (epoch 13.338), train_loss = 1.04566885, grad/param norm = 1.5834e-01, time/batch = 18.4685s	
6950/26050 (epoch 13.340), train_loss = 1.28450339, grad/param norm = 1.8378e-01, time/batch = 18.2940s	
6951/26050 (epoch 13.342), train_loss = 1.33153590, grad/param norm = 1.8912e-01, time/batch = 18.9826s	
6952/26050 (epoch 13.344), train_loss = 1.16082463, grad/param norm = 1.7608e-01, time/batch = 17.1274s	
6953/26050 (epoch 13.345), train_loss = 1.13865003, grad/param norm = 1.6842e-01, time/batch = 17.1440s	
6954/26050 (epoch 13.347), train_loss = 1.26682342, grad/param norm = 1.8977e-01, time/batch = 17.5633s	
6955/26050 (epoch 13.349), train_loss = 1.21776131, grad/param norm = 1.6777e-01, time/batch = 18.8176s	
6956/26050 (epoch 13.351), train_loss = 1.18751927, grad/param norm = 1.7468e-01, time/batch = 16.9814s	
6957/26050 (epoch 13.353), train_loss = 1.14881473, grad/param norm = 1.8142e-01, time/batch = 17.6439s	
6958/26050 (epoch 13.355), train_loss = 1.25308401, grad/param norm = 1.9401e-01, time/batch = 15.4530s	
6959/26050 (epoch 13.357), train_loss = 1.03723682, grad/param norm = 1.5304e-01, time/batch = 18.4968s	
6960/26050 (epoch 13.359), train_loss = 1.24018131, grad/param norm = 1.6844e-01, time/batch = 17.1955s	
6961/26050 (epoch 13.361), train_loss = 1.10831184, grad/param norm = 1.6801e-01, time/batch = 18.3279s	
6962/26050 (epoch 13.363), train_loss = 1.23000416, grad/param norm = 1.6234e-01, time/batch = 15.7279s	
6963/26050 (epoch 13.365), train_loss = 1.13929740, grad/param norm = 1.4940e-01, time/batch = 17.6349s	
6964/26050 (epoch 13.367), train_loss = 1.18491857, grad/param norm = 1.7149e-01, time/batch = 18.4901s	
6965/26050 (epoch 13.369), train_loss = 1.15212860, grad/param norm = 1.5843e-01, time/batch = 17.7413s	
6966/26050 (epoch 13.370), train_loss = 1.06117596, grad/param norm = 1.4928e-01, time/batch = 18.1521s	
6967/26050 (epoch 13.372), train_loss = 1.25351367, grad/param norm = 1.9531e-01, time/batch = 18.5609s	
6968/26050 (epoch 13.374), train_loss = 1.34656127, grad/param norm = 1.8401e-01, time/batch = 18.2379s	
6969/26050 (epoch 13.376), train_loss = 1.38202654, grad/param norm = 1.8243e-01, time/batch = 18.6618s	
6970/26050 (epoch 13.378), train_loss = 1.15018218, grad/param norm = 1.7245e-01, time/batch = 17.6424s	
6971/26050 (epoch 13.380), train_loss = 1.38265996, grad/param norm = 1.9814e-01, time/batch = 15.9701s	
6972/26050 (epoch 13.382), train_loss = 1.51611409, grad/param norm = 2.1029e-01, time/batch = 17.0461s	
6973/26050 (epoch 13.384), train_loss = 1.13404974, grad/param norm = 1.6006e-01, time/batch = 15.6097s	
6974/26050 (epoch 13.386), train_loss = 1.29535627, grad/param norm = 1.9876e-01, time/batch = 33.2572s	
6975/26050 (epoch 13.388), train_loss = 1.21158259, grad/param norm = 1.7039e-01, time/batch = 22.5280s	
6976/26050 (epoch 13.390), train_loss = 1.07457628, grad/param norm = 1.5502e-01, time/batch = 18.0541s	
6977/26050 (epoch 13.392), train_loss = 1.06702162, grad/param norm = 1.5778e-01, time/batch = 18.1237s	
6978/26050 (epoch 13.393), train_loss = 1.21983211, grad/param norm = 1.6482e-01, time/batch = 14.8920s	
6979/26050 (epoch 13.395), train_loss = 1.24345784, grad/param norm = 1.6663e-01, time/batch = 17.3203s	
6980/26050 (epoch 13.397), train_loss = 1.22903037, grad/param norm = 1.8810e-01, time/batch = 18.8865s	
6981/26050 (epoch 13.399), train_loss = 1.06166209, grad/param norm = 1.6018e-01, time/batch = 17.9830s	
6982/26050 (epoch 13.401), train_loss = 1.14906544, grad/param norm = 1.5602e-01, time/batch = 17.4978s	
6983/26050 (epoch 13.403), train_loss = 1.20713189, grad/param norm = 1.5938e-01, time/batch = 18.8177s	
6984/26050 (epoch 13.405), train_loss = 1.16650450, grad/param norm = 1.7349e-01, time/batch = 18.1614s	
6985/26050 (epoch 13.407), train_loss = 1.32212991, grad/param norm = 1.7527e-01, time/batch = 17.7380s	
6986/26050 (epoch 13.409), train_loss = 1.36928306, grad/param norm = 1.8659e-01, time/batch = 17.7290s	
6987/26050 (epoch 13.411), train_loss = 1.22169172, grad/param norm = 1.8465e-01, time/batch = 18.5573s	
6988/26050 (epoch 13.413), train_loss = 1.33823948, grad/param norm = 1.5962e-01, time/batch = 18.5730s	
6989/26050 (epoch 13.415), train_loss = 1.30692049, grad/param norm = 1.9312e-01, time/batch = 17.7232s	
6990/26050 (epoch 13.417), train_loss = 1.41774544, grad/param norm = 1.9328e-01, time/batch = 17.6486s	
6991/26050 (epoch 13.418), train_loss = 1.29810214, grad/param norm = 1.9926e-01, time/batch = 18.9864s	
6992/26050 (epoch 13.420), train_loss = 1.00965281, grad/param norm = 1.5026e-01, time/batch = 17.6568s	
6993/26050 (epoch 13.422), train_loss = 1.04619253, grad/param norm = 1.6505e-01, time/batch = 18.3971s	
6994/26050 (epoch 13.424), train_loss = 1.36473153, grad/param norm = 2.0846e-01, time/batch = 18.1587s	
6995/26050 (epoch 13.426), train_loss = 1.32850109, grad/param norm = 1.8019e-01, time/batch = 14.4881s	
6996/26050 (epoch 13.428), train_loss = 1.10257866, grad/param norm = 1.4973e-01, time/batch = 16.8779s	
6997/26050 (epoch 13.430), train_loss = 1.25766103, grad/param norm = 1.7309e-01, time/batch = 16.9641s	
6998/26050 (epoch 13.432), train_loss = 1.13493388, grad/param norm = 1.6883e-01, time/batch = 15.6572s	
6999/26050 (epoch 13.434), train_loss = 1.20142523, grad/param norm = 1.9278e-01, time/batch = 17.8091s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch13.44_1.6270.t7	
7000/26050 (epoch 13.436), train_loss = 1.30479774, grad/param norm = 1.6336e-01, time/batch = 17.6479s	
7001/26050 (epoch 13.438), train_loss = 1.37651749, grad/param norm = 2.0389e-01, time/batch = 18.2423s	
7002/26050 (epoch 13.440), train_loss = 1.22053689, grad/param norm = 1.6740e-01, time/batch = 18.8269s	
7003/26050 (epoch 13.441), train_loss = 1.20194598, grad/param norm = 1.6058e-01, time/batch = 17.7183s	
7004/26050 (epoch 13.443), train_loss = 1.00498561, grad/param norm = 1.5177e-01, time/batch = 18.5682s	
7005/26050 (epoch 13.445), train_loss = 1.07169210, grad/param norm = 1.5718e-01, time/batch = 18.1544s	
7006/26050 (epoch 13.447), train_loss = 1.37319589, grad/param norm = 1.8869e-01, time/batch = 16.7947s	
7007/26050 (epoch 13.449), train_loss = 1.09571532, grad/param norm = 1.6715e-01, time/batch = 18.0695s	
7008/26050 (epoch 13.451), train_loss = 1.32395058, grad/param norm = 1.7388e-01, time/batch = 17.9910s	
7009/26050 (epoch 13.453), train_loss = 1.10646980, grad/param norm = 1.6388e-01, time/batch = 15.3834s	
7010/26050 (epoch 13.455), train_loss = 1.23927796, grad/param norm = 1.6764e-01, time/batch = 17.3830s	
7011/26050 (epoch 13.457), train_loss = 1.21895007, grad/param norm = 1.7220e-01, time/batch = 16.9542s	
7012/26050 (epoch 13.459), train_loss = 1.30132754, grad/param norm = 1.7118e-01, time/batch = 17.7467s	
7013/26050 (epoch 13.461), train_loss = 1.27687595, grad/param norm = 2.1991e-01, time/batch = 17.9080s	
7014/26050 (epoch 13.463), train_loss = 1.13882806, grad/param norm = 1.6049e-01, time/batch = 17.1541s	
7015/26050 (epoch 13.464), train_loss = 1.25224218, grad/param norm = 1.7471e-01, time/batch = 18.7473s	
7016/26050 (epoch 13.466), train_loss = 1.28611431, grad/param norm = 1.8477e-01, time/batch = 14.5729s	
7017/26050 (epoch 13.468), train_loss = 1.29014535, grad/param norm = 1.6033e-01, time/batch = 17.4791s	
7018/26050 (epoch 13.470), train_loss = 1.40900105, grad/param norm = 2.0323e-01, time/batch = 17.6526s	
7019/26050 (epoch 13.472), train_loss = 1.35612290, grad/param norm = 1.9532e-01, time/batch = 18.3062s	
7020/26050 (epoch 13.474), train_loss = 1.41343340, grad/param norm = 1.8002e-01, time/batch = 17.6500s	
7021/26050 (epoch 13.476), train_loss = 1.30465549, grad/param norm = 1.7436e-01, time/batch = 18.3079s	
7022/26050 (epoch 13.478), train_loss = 1.12881375, grad/param norm = 1.5987e-01, time/batch = 18.7264s	
7023/26050 (epoch 13.480), train_loss = 1.22326536, grad/param norm = 1.6674e-01, time/batch = 17.8984s	
7024/26050 (epoch 13.482), train_loss = 1.15371018, grad/param norm = 1.6565e-01, time/batch = 18.0529s	
7025/26050 (epoch 13.484), train_loss = 1.13334202, grad/param norm = 1.6309e-01, time/batch = 15.8877s	
7026/26050 (epoch 13.486), train_loss = 1.36388206, grad/param norm = 1.7626e-01, time/batch = 18.8196s	
7027/26050 (epoch 13.488), train_loss = 1.51895403, grad/param norm = 1.9695e-01, time/batch = 17.4847s	
7028/26050 (epoch 13.489), train_loss = 1.43007419, grad/param norm = 1.9799e-01, time/batch = 18.2434s	
7029/26050 (epoch 13.491), train_loss = 1.09105918, grad/param norm = 1.5854e-01, time/batch = 16.6234s	
7030/26050 (epoch 13.493), train_loss = 1.19861203, grad/param norm = 1.7227e-01, time/batch = 17.7399s	
7031/26050 (epoch 13.495), train_loss = 1.17334584, grad/param norm = 1.6487e-01, time/batch = 16.5771s	
7032/26050 (epoch 13.497), train_loss = 1.12884093, grad/param norm = 1.6675e-01, time/batch = 18.8445s	
7033/26050 (epoch 13.499), train_loss = 1.15726108, grad/param norm = 1.6679e-01, time/batch = 15.7204s	
7034/26050 (epoch 13.501), train_loss = 1.26978118, grad/param norm = 1.7208e-01, time/batch = 14.5449s	
7035/26050 (epoch 13.503), train_loss = 1.13422095, grad/param norm = 1.8468e-01, time/batch = 17.7258s	
7036/26050 (epoch 13.505), train_loss = 1.32898263, grad/param norm = 1.7668e-01, time/batch = 18.3837s	
7037/26050 (epoch 13.507), train_loss = 1.28667458, grad/param norm = 1.8867e-01, time/batch = 18.0508s	
7038/26050 (epoch 13.509), train_loss = 1.41654458, grad/param norm = 1.8377e-01, time/batch = 17.4697s	
7039/26050 (epoch 13.511), train_loss = 1.09420387, grad/param norm = 1.5186e-01, time/batch = 17.5203s	
7040/26050 (epoch 13.512), train_loss = 1.15565266, grad/param norm = 1.8625e-01, time/batch = 18.9050s	
7041/26050 (epoch 13.514), train_loss = 1.27274757, grad/param norm = 1.7856e-01, time/batch = 18.0465s	
7042/26050 (epoch 13.516), train_loss = 1.29715220, grad/param norm = 1.7616e-01, time/batch = 18.1331s	
7043/26050 (epoch 13.518), train_loss = 1.26769439, grad/param norm = 1.8678e-01, time/batch = 15.7226s	
7044/26050 (epoch 13.520), train_loss = 1.18952186, grad/param norm = 1.6359e-01, time/batch = 16.6405s	
7045/26050 (epoch 13.522), train_loss = 1.00263254, grad/param norm = 1.5928e-01, time/batch = 15.3921s	
7046/26050 (epoch 13.524), train_loss = 1.32803265, grad/param norm = 1.8771e-01, time/batch = 17.8127s	
7047/26050 (epoch 13.526), train_loss = 1.31569853, grad/param norm = 1.8320e-01, time/batch = 18.4904s	
7048/26050 (epoch 13.528), train_loss = 1.25725051, grad/param norm = 1.7311e-01, time/batch = 18.1496s	
7049/26050 (epoch 13.530), train_loss = 1.19735954, grad/param norm = 1.6631e-01, time/batch = 18.3980s	
7050/26050 (epoch 13.532), train_loss = 1.18717882, grad/param norm = 1.5179e-01, time/batch = 18.1473s	
7051/26050 (epoch 13.534), train_loss = 1.28023385, grad/param norm = 1.8927e-01, time/batch = 17.3889s	
7052/26050 (epoch 13.536), train_loss = 1.18653706, grad/param norm = 1.6263e-01, time/batch = 17.8257s	
7053/26050 (epoch 13.537), train_loss = 1.31951907, grad/param norm = 1.9865e-01, time/batch = 18.1584s	
7054/26050 (epoch 13.539), train_loss = 1.20151294, grad/param norm = 1.7303e-01, time/batch = 17.3177s	
7055/26050 (epoch 13.541), train_loss = 1.39882498, grad/param norm = 1.9144e-01, time/batch = 18.5536s	
7056/26050 (epoch 13.543), train_loss = 1.03224076, grad/param norm = 1.6773e-01, time/batch = 18.8122s	
7057/26050 (epoch 13.545), train_loss = 1.24737804, grad/param norm = 1.7131e-01, time/batch = 18.3208s	
7058/26050 (epoch 13.547), train_loss = 1.21724577, grad/param norm = 1.6950e-01, time/batch = 16.5425s	
7059/26050 (epoch 13.549), train_loss = 0.99630601, grad/param norm = 1.4924e-01, time/batch = 18.4129s	
7060/26050 (epoch 13.551), train_loss = 1.23240874, grad/param norm = 1.7542e-01, time/batch = 18.3223s	
7061/26050 (epoch 13.553), train_loss = 1.10824761, grad/param norm = 1.5656e-01, time/batch = 17.6542s	
7062/26050 (epoch 13.555), train_loss = 1.14574132, grad/param norm = 1.7042e-01, time/batch = 16.9637s	
7063/26050 (epoch 13.557), train_loss = 1.25445823, grad/param norm = 1.5751e-01, time/batch = 17.6481s	
7064/26050 (epoch 13.559), train_loss = 1.19784546, grad/param norm = 1.6652e-01, time/batch = 15.3053s	
7065/26050 (epoch 13.560), train_loss = 1.18535510, grad/param norm = 1.7728e-01, time/batch = 15.0525s	
7066/26050 (epoch 13.562), train_loss = 1.18363265, grad/param norm = 1.7859e-01, time/batch = 18.7355s	
7067/26050 (epoch 13.564), train_loss = 1.39966865, grad/param norm = 1.7585e-01, time/batch = 18.5641s	
7068/26050 (epoch 13.566), train_loss = 1.08230045, grad/param norm = 1.6275e-01, time/batch = 16.8006s	
7069/26050 (epoch 13.568), train_loss = 1.22590185, grad/param norm = 1.6194e-01, time/batch = 18.2474s	
7070/26050 (epoch 13.570), train_loss = 1.30654481, grad/param norm = 1.7909e-01, time/batch = 18.4920s	
7071/26050 (epoch 13.572), train_loss = 1.17778116, grad/param norm = 1.8285e-01, time/batch = 17.7220s	
7072/26050 (epoch 13.574), train_loss = 1.27347773, grad/param norm = 1.9691e-01, time/batch = 18.5603s	
7073/26050 (epoch 13.576), train_loss = 1.25596406, grad/param norm = 1.8358e-01, time/batch = 16.9806s	
7074/26050 (epoch 13.578), train_loss = 1.20337318, grad/param norm = 1.7600e-01, time/batch = 17.9704s	
7075/26050 (epoch 13.580), train_loss = 1.10514428, grad/param norm = 1.7835e-01, time/batch = 17.4909s	
7076/26050 (epoch 13.582), train_loss = 1.24725416, grad/param norm = 1.7556e-01, time/batch = 16.2278s	
7077/26050 (epoch 13.583), train_loss = 1.28876551, grad/param norm = 1.7156e-01, time/batch = 18.7421s	
7078/26050 (epoch 13.585), train_loss = 1.10213545, grad/param norm = 1.7277e-01, time/batch = 14.9045s	
7079/26050 (epoch 13.587), train_loss = 1.23960314, grad/param norm = 1.8051e-01, time/batch = 18.1461s	
7080/26050 (epoch 13.589), train_loss = 1.33222125, grad/param norm = 2.0668e-01, time/batch = 17.4877s	
7081/26050 (epoch 13.591), train_loss = 1.20311185, grad/param norm = 1.7023e-01, time/batch = 16.9720s	
7082/26050 (epoch 13.593), train_loss = 1.08021886, grad/param norm = 1.7636e-01, time/batch = 18.1433s	
7083/26050 (epoch 13.595), train_loss = 1.33149854, grad/param norm = 2.0218e-01, time/batch = 17.7380s	
7084/26050 (epoch 13.597), train_loss = 1.23327266, grad/param norm = 1.7342e-01, time/batch = 18.8271s	
7085/26050 (epoch 13.599), train_loss = 1.17624837, grad/param norm = 1.6731e-01, time/batch = 17.5639s	
7086/26050 (epoch 13.601), train_loss = 1.40477333, grad/param norm = 1.8133e-01, time/batch = 18.1529s	
7087/26050 (epoch 13.603), train_loss = 1.26748458, grad/param norm = 1.7872e-01, time/batch = 17.1592s	
7088/26050 (epoch 13.605), train_loss = 1.13830608, grad/param norm = 1.5728e-01, time/batch = 16.9538s	
7089/26050 (epoch 13.607), train_loss = 1.34599308, grad/param norm = 1.9010e-01, time/batch = 18.0858s	
7090/26050 (epoch 13.608), train_loss = 1.08793026, grad/param norm = 1.5453e-01, time/batch = 17.6500s	
7091/26050 (epoch 13.610), train_loss = 1.18347185, grad/param norm = 1.7553e-01, time/batch = 18.3927s	
7092/26050 (epoch 13.612), train_loss = 1.20508897, grad/param norm = 1.7827e-01, time/batch = 17.3290s	
7093/26050 (epoch 13.614), train_loss = 1.28713547, grad/param norm = 1.7993e-01, time/batch = 17.7353s	
7094/26050 (epoch 13.616), train_loss = 1.41686342, grad/param norm = 1.9482e-01, time/batch = 15.9734s	
7095/26050 (epoch 13.618), train_loss = 1.14678507, grad/param norm = 1.7595e-01, time/batch = 15.5500s	
7096/26050 (epoch 13.620), train_loss = 1.23103811, grad/param norm = 1.7501e-01, time/batch = 17.6506s	
7097/26050 (epoch 13.622), train_loss = 1.04277925, grad/param norm = 1.5278e-01, time/batch = 18.6349s	
7098/26050 (epoch 13.624), train_loss = 1.06919414, grad/param norm = 1.6417e-01, time/batch = 16.0511s	
7099/26050 (epoch 13.626), train_loss = 1.26203429, grad/param norm = 1.6754e-01, time/batch = 17.6528s	
7100/26050 (epoch 13.628), train_loss = 1.15076377, grad/param norm = 1.7792e-01, time/batch = 18.3253s	
7101/26050 (epoch 13.630), train_loss = 1.34692684, grad/param norm = 1.7376e-01, time/batch = 18.3167s	
7102/26050 (epoch 13.631), train_loss = 1.37205024, grad/param norm = 1.8741e-01, time/batch = 16.1298s	
7103/26050 (epoch 13.633), train_loss = 1.12427729, grad/param norm = 1.7510e-01, time/batch = 17.7435s	
7104/26050 (epoch 13.635), train_loss = 1.11811032, grad/param norm = 1.5367e-01, time/batch = 17.8010s	
7105/26050 (epoch 13.637), train_loss = 1.09349239, grad/param norm = 1.7284e-01, time/batch = 17.4787s	
7106/26050 (epoch 13.639), train_loss = 1.32191096, grad/param norm = 1.7320e-01, time/batch = 17.5739s	
7107/26050 (epoch 13.641), train_loss = 1.15439872, grad/param norm = 1.6282e-01, time/batch = 18.2410s	
7108/26050 (epoch 13.643), train_loss = 1.05789621, grad/param norm = 1.5136e-01, time/batch = 18.0618s	
7109/26050 (epoch 13.645), train_loss = 1.23592503, grad/param norm = 1.8108e-01, time/batch = 17.8082s	
7110/26050 (epoch 13.647), train_loss = 1.15739221, grad/param norm = 1.6899e-01, time/batch = 17.8119s	
7111/26050 (epoch 13.649), train_loss = 1.21917588, grad/param norm = 1.9421e-01, time/batch = 18.3175s	
7112/26050 (epoch 13.651), train_loss = 1.13282708, grad/param norm = 1.7733e-01, time/batch = 15.6281s	
7113/26050 (epoch 13.653), train_loss = 1.20730506, grad/param norm = 1.6959e-01, time/batch = 17.3781s	
7114/26050 (epoch 13.655), train_loss = 1.12371619, grad/param norm = 1.6166e-01, time/batch = 15.8201s	
7115/26050 (epoch 13.656), train_loss = 1.05488871, grad/param norm = 1.7629e-01, time/batch = 18.4798s	
7116/26050 (epoch 13.658), train_loss = 1.39134020, grad/param norm = 1.8372e-01, time/batch = 17.3103s	
7117/26050 (epoch 13.660), train_loss = 1.07769637, grad/param norm = 1.6157e-01, time/batch = 15.6480s	
7118/26050 (epoch 13.662), train_loss = 1.08374780, grad/param norm = 1.5314e-01, time/batch = 18.2339s	
7119/26050 (epoch 13.664), train_loss = 1.17486183, grad/param norm = 1.7623e-01, time/batch = 14.9639s	
7120/26050 (epoch 13.666), train_loss = 1.18596365, grad/param norm = 1.7898e-01, time/batch = 16.2110s	
7121/26050 (epoch 13.668), train_loss = 1.00087316, grad/param norm = 1.5821e-01, time/batch = 17.9843s	
7122/26050 (epoch 13.670), train_loss = 1.37248163, grad/param norm = 1.9452e-01, time/batch = 17.9824s	
7123/26050 (epoch 13.672), train_loss = 1.15147322, grad/param norm = 1.7132e-01, time/batch = 15.7410s	
7124/26050 (epoch 13.674), train_loss = 1.08108054, grad/param norm = 1.6662e-01, time/batch = 18.0615s	
7125/26050 (epoch 13.676), train_loss = 1.20881983, grad/param norm = 1.7427e-01, time/batch = 18.3971s	
7126/26050 (epoch 13.678), train_loss = 1.32946704, grad/param norm = 1.7820e-01, time/batch = 17.0672s	
7127/26050 (epoch 13.679), train_loss = 1.41067459, grad/param norm = 1.9343e-01, time/batch = 16.1247s	
7128/26050 (epoch 13.681), train_loss = 1.21053297, grad/param norm = 1.7134e-01, time/batch = 18.2324s	
7129/26050 (epoch 13.683), train_loss = 1.09910363, grad/param norm = 2.0439e-01, time/batch = 18.2365s	
7130/26050 (epoch 13.685), train_loss = 1.15827761, grad/param norm = 1.6622e-01, time/batch = 18.5470s	
7131/26050 (epoch 13.687), train_loss = 1.01074855, grad/param norm = 1.6394e-01, time/batch = 17.6675s	
7132/26050 (epoch 13.689), train_loss = 1.16257154, grad/param norm = 1.7267e-01, time/batch = 18.7472s	
7133/26050 (epoch 13.691), train_loss = 0.93371282, grad/param norm = 1.5377e-01, time/batch = 17.4040s	
7134/26050 (epoch 13.693), train_loss = 1.09621526, grad/param norm = 1.6926e-01, time/batch = 15.2205s	
7135/26050 (epoch 13.695), train_loss = 1.20334007, grad/param norm = 1.7385e-01, time/batch = 18.2371s	
7136/26050 (epoch 13.697), train_loss = 1.08924646, grad/param norm = 1.6933e-01, time/batch = 17.2302s	
7137/26050 (epoch 13.699), train_loss = 1.25681873, grad/param norm = 1.8502e-01, time/batch = 14.6118s	
7138/26050 (epoch 13.701), train_loss = 1.05469627, grad/param norm = 1.5542e-01, time/batch = 18.7233s	
7139/26050 (epoch 13.702), train_loss = 1.37707523, grad/param norm = 1.9371e-01, time/batch = 18.4674s	
7140/26050 (epoch 13.704), train_loss = 1.23845734, grad/param norm = 1.6539e-01, time/batch = 16.3860s	
7141/26050 (epoch 13.706), train_loss = 1.23472536, grad/param norm = 2.0165e-01, time/batch = 18.1321s	
7142/26050 (epoch 13.708), train_loss = 1.28450160, grad/param norm = 1.7981e-01, time/batch = 18.3119s	
7143/26050 (epoch 13.710), train_loss = 1.25990404, grad/param norm = 1.7802e-01, time/batch = 17.5499s	
7144/26050 (epoch 13.712), train_loss = 1.31309806, grad/param norm = 1.8425e-01, time/batch = 17.5710s	
7145/26050 (epoch 13.714), train_loss = 1.03323051, grad/param norm = 1.7071e-01, time/batch = 18.4780s	
7146/26050 (epoch 13.716), train_loss = 1.46215772, grad/param norm = 2.0376e-01, time/batch = 17.1527s	
7147/26050 (epoch 13.718), train_loss = 1.31138261, grad/param norm = 1.8526e-01, time/batch = 17.9017s	
7148/26050 (epoch 13.720), train_loss = 1.13592314, grad/param norm = 1.7201e-01, time/batch = 15.2396s	
7149/26050 (epoch 13.722), train_loss = 1.06943184, grad/param norm = 1.6721e-01, time/batch = 18.9052s	
7150/26050 (epoch 13.724), train_loss = 1.08848330, grad/param norm = 1.7743e-01, time/batch = 17.2332s	
7151/26050 (epoch 13.726), train_loss = 1.31869031, grad/param norm = 1.8401e-01, time/batch = 15.8092s	
7152/26050 (epoch 13.727), train_loss = 1.25468160, grad/param norm = 1.7090e-01, time/batch = 18.4871s	
7153/26050 (epoch 13.729), train_loss = 1.25099333, grad/param norm = 1.7513e-01, time/batch = 17.4869s	
7154/26050 (epoch 13.731), train_loss = 1.22659454, grad/param norm = 1.6202e-01, time/batch = 16.9877s	
7155/26050 (epoch 13.733), train_loss = 1.16494699, grad/param norm = 2.0261e-01, time/batch = 17.3267s	
7156/26050 (epoch 13.735), train_loss = 1.38936391, grad/param norm = 1.9134e-01, time/batch = 18.4267s	
7157/26050 (epoch 13.737), train_loss = 1.18816247, grad/param norm = 1.6871e-01, time/batch = 15.0523s	
7158/26050 (epoch 13.739), train_loss = 1.25761471, grad/param norm = 1.6791e-01, time/batch = 14.9508s	
7159/26050 (epoch 13.741), train_loss = 1.12258719, grad/param norm = 1.7629e-01, time/batch = 18.3273s	
7160/26050 (epoch 13.743), train_loss = 1.24494618, grad/param norm = 1.9410e-01, time/batch = 17.8342s	
7161/26050 (epoch 13.745), train_loss = 1.08526499, grad/param norm = 1.7367e-01, time/batch = 17.7456s	
7162/26050 (epoch 13.747), train_loss = 1.09326762, grad/param norm = 1.5586e-01, time/batch = 18.4948s	
7163/26050 (epoch 13.749), train_loss = 1.34864364, grad/param norm = 1.8559e-01, time/batch = 18.8246s	
7164/26050 (epoch 13.750), train_loss = 1.19365582, grad/param norm = 1.5702e-01, time/batch = 17.7336s	
7165/26050 (epoch 13.752), train_loss = 1.17795738, grad/param norm = 2.0640e-01, time/batch = 17.1502s	
7166/26050 (epoch 13.754), train_loss = 1.21672903, grad/param norm = 1.7339e-01, time/batch = 16.3045s	
7167/26050 (epoch 13.756), train_loss = 1.19966592, grad/param norm = 1.8052e-01, time/batch = 15.7224s	
7168/26050 (epoch 13.758), train_loss = 1.21012266, grad/param norm = 1.7763e-01, time/batch = 18.1503s	
7169/26050 (epoch 13.760), train_loss = 1.33427256, grad/param norm = 1.7442e-01, time/batch = 17.4125s	
7170/26050 (epoch 13.762), train_loss = 1.12081866, grad/param norm = 1.6358e-01, time/batch = 15.5622s	
7171/26050 (epoch 13.764), train_loss = 1.25661941, grad/param norm = 1.7557e-01, time/batch = 28.5946s	
7172/26050 (epoch 13.766), train_loss = 1.28669682, grad/param norm = 1.9203e-01, time/batch = 28.0236s	
7173/26050 (epoch 13.768), train_loss = 1.07989405, grad/param norm = 1.5245e-01, time/batch = 17.0539s	
7174/26050 (epoch 13.770), train_loss = 1.17496733, grad/param norm = 1.8566e-01, time/batch = 15.7171s	
7175/26050 (epoch 13.772), train_loss = 1.17411195, grad/param norm = 1.6246e-01, time/batch = 17.8014s	
7176/26050 (epoch 13.774), train_loss = 1.05012225, grad/param norm = 1.7129e-01, time/batch = 17.8158s	
7177/26050 (epoch 13.775), train_loss = 0.89875669, grad/param norm = 1.6083e-01, time/batch = 17.7437s	
7178/26050 (epoch 13.777), train_loss = 1.10479208, grad/param norm = 1.6255e-01, time/batch = 15.3699s	
7179/26050 (epoch 13.779), train_loss = 1.16492508, grad/param norm = 1.7533e-01, time/batch = 16.1494s	
7180/26050 (epoch 13.781), train_loss = 1.13756519, grad/param norm = 1.7288e-01, time/batch = 17.9843s	
7181/26050 (epoch 13.783), train_loss = 1.09886173, grad/param norm = 1.6697e-01, time/batch = 18.7340s	
7182/26050 (epoch 13.785), train_loss = 1.15818488, grad/param norm = 1.7204e-01, time/batch = 18.4922s	
7183/26050 (epoch 13.787), train_loss = 1.12477235, grad/param norm = 1.6990e-01, time/batch = 17.5709s	
7184/26050 (epoch 13.789), train_loss = 1.12533024, grad/param norm = 1.9590e-01, time/batch = 17.9870s	
7185/26050 (epoch 13.791), train_loss = 1.15880475, grad/param norm = 1.6655e-01, time/batch = 17.6588s	
7186/26050 (epoch 13.793), train_loss = 1.17052977, grad/param norm = 1.8971e-01, time/batch = 18.6609s	
7187/26050 (epoch 13.795), train_loss = 1.01364442, grad/param norm = 1.5547e-01, time/batch = 16.9609s	
7188/26050 (epoch 13.797), train_loss = 1.10452751, grad/param norm = 1.6538e-01, time/batch = 17.0517s	
7189/26050 (epoch 13.798), train_loss = 1.04582368, grad/param norm = 1.6590e-01, time/batch = 18.2416s	
7190/26050 (epoch 13.800), train_loss = 1.03347142, grad/param norm = 1.4786e-01, time/batch = 16.5682s	
7191/26050 (epoch 13.802), train_loss = 1.15558712, grad/param norm = 1.8170e-01, time/batch = 17.8337s	
7192/26050 (epoch 13.804), train_loss = 1.14575934, grad/param norm = 1.6907e-01, time/batch = 18.3354s	
7193/26050 (epoch 13.806), train_loss = 1.26777471, grad/param norm = 1.7603e-01, time/batch = 17.9088s	
7194/26050 (epoch 13.808), train_loss = 1.15102680, grad/param norm = 1.6434e-01, time/batch = 17.8947s	
7195/26050 (epoch 13.810), train_loss = 1.11638812, grad/param norm = 1.7781e-01, time/batch = 14.6510s	
7196/26050 (epoch 13.812), train_loss = 1.05589067, grad/param norm = 1.7851e-01, time/batch = 18.5758s	
7197/26050 (epoch 13.814), train_loss = 1.06475556, grad/param norm = 1.9387e-01, time/batch = 17.0760s	
7198/26050 (epoch 13.816), train_loss = 1.28484977, grad/param norm = 1.8260e-01, time/batch = 16.9832s	
7199/26050 (epoch 13.818), train_loss = 1.33718780, grad/param norm = 2.0754e-01, time/batch = 18.7388s	
7200/26050 (epoch 13.820), train_loss = 1.19609425, grad/param norm = 1.7592e-01, time/batch = 17.6571s	
7201/26050 (epoch 13.821), train_loss = 1.33678690, grad/param norm = 1.9402e-01, time/batch = 16.8664s	
7202/26050 (epoch 13.823), train_loss = 1.36394598, grad/param norm = 1.9082e-01, time/batch = 18.1453s	
7203/26050 (epoch 13.825), train_loss = 1.17170372, grad/param norm = 1.7826e-01, time/batch = 18.7347s	
7204/26050 (epoch 13.827), train_loss = 1.22243408, grad/param norm = 1.9709e-01, time/batch = 18.6378s	
7205/26050 (epoch 13.829), train_loss = 1.23680028, grad/param norm = 1.7518e-01, time/batch = 18.0782s	
7206/26050 (epoch 13.831), train_loss = 1.31231016, grad/param norm = 1.7453e-01, time/batch = 18.5777s	
7207/26050 (epoch 13.833), train_loss = 1.38341025, grad/param norm = 1.8352e-01, time/batch = 16.6625s	
7208/26050 (epoch 13.835), train_loss = 1.40849973, grad/param norm = 1.8825e-01, time/batch = 18.4010s	
7209/26050 (epoch 13.837), train_loss = 1.17261763, grad/param norm = 1.8573e-01, time/batch = 16.1394s	
7210/26050 (epoch 13.839), train_loss = 1.23086940, grad/param norm = 2.0662e-01, time/batch = 17.4860s	
7211/26050 (epoch 13.841), train_loss = 1.29903888, grad/param norm = 1.7679e-01, time/batch = 17.3112s	
7212/26050 (epoch 13.843), train_loss = 1.20116211, grad/param norm = 1.8083e-01, time/batch = 15.1353s	
7213/26050 (epoch 13.845), train_loss = 1.10698002, grad/param norm = 1.5480e-01, time/batch = 15.7960s	
7214/26050 (epoch 13.846), train_loss = 1.29850103, grad/param norm = 1.7201e-01, time/batch = 14.9604s	
7215/26050 (epoch 13.848), train_loss = 1.15271277, grad/param norm = 1.6041e-01, time/batch = 18.0578s	
7216/26050 (epoch 13.850), train_loss = 1.11525638, grad/param norm = 1.7111e-01, time/batch = 18.8223s	
7217/26050 (epoch 13.852), train_loss = 1.15775106, grad/param norm = 1.6744e-01, time/batch = 17.3244s	
7218/26050 (epoch 13.854), train_loss = 1.16478412, grad/param norm = 1.6443e-01, time/batch = 18.0527s	
7219/26050 (epoch 13.856), train_loss = 1.14045153, grad/param norm = 1.8564e-01, time/batch = 18.8092s	
7220/26050 (epoch 13.858), train_loss = 1.07624324, grad/param norm = 1.6702e-01, time/batch = 18.4980s	
7221/26050 (epoch 13.860), train_loss = 1.23910750, grad/param norm = 1.7997e-01, time/batch = 15.2124s	
7222/26050 (epoch 13.862), train_loss = 1.22323338, grad/param norm = 1.7528e-01, time/batch = 18.0697s	
7223/26050 (epoch 13.864), train_loss = 1.21780527, grad/param norm = 1.9705e-01, time/batch = 18.6465s	
7224/26050 (epoch 13.866), train_loss = 1.12227575, grad/param norm = 1.5975e-01, time/batch = 17.3288s	
7225/26050 (epoch 13.868), train_loss = 1.27128338, grad/param norm = 1.9131e-01, time/batch = 18.3265s	
7226/26050 (epoch 13.869), train_loss = 1.07651128, grad/param norm = 1.5468e-01, time/batch = 16.9187s	
7227/26050 (epoch 13.871), train_loss = 1.02476635, grad/param norm = 1.6402e-01, time/batch = 17.3891s	
7228/26050 (epoch 13.873), train_loss = 1.24526568, grad/param norm = 1.7412e-01, time/batch = 17.4908s	
7229/26050 (epoch 13.875), train_loss = 1.17687024, grad/param norm = 1.7543e-01, time/batch = 18.2425s	
7230/26050 (epoch 13.877), train_loss = 1.06466732, grad/param norm = 1.6448e-01, time/batch = 18.6666s	
7231/26050 (epoch 13.879), train_loss = 1.18554095, grad/param norm = 1.5761e-01, time/batch = 17.5650s	
7232/26050 (epoch 13.881), train_loss = 1.32632486, grad/param norm = 1.8168e-01, time/batch = 17.8158s	
7233/26050 (epoch 13.883), train_loss = 1.23300616, grad/param norm = 1.8276e-01, time/batch = 16.6457s	
7234/26050 (epoch 13.885), train_loss = 0.93080185, grad/param norm = 1.5380e-01, time/batch = 17.3094s	
7235/26050 (epoch 13.887), train_loss = 1.22060307, grad/param norm = 1.7590e-01, time/batch = 15.7878s	
7236/26050 (epoch 13.889), train_loss = 1.13394235, grad/param norm = 1.6171e-01, time/batch = 16.3829s	
7237/26050 (epoch 13.891), train_loss = 0.94179782, grad/param norm = 1.4976e-01, time/batch = 17.3988s	
7238/26050 (epoch 13.893), train_loss = 0.96598952, grad/param norm = 1.5804e-01, time/batch = 17.3072s	
7239/26050 (epoch 13.894), train_loss = 1.14733999, grad/param norm = 1.6932e-01, time/batch = 17.9743s	
7240/26050 (epoch 13.896), train_loss = 1.29721590, grad/param norm = 1.7305e-01, time/batch = 18.3210s	
7241/26050 (epoch 13.898), train_loss = 1.11733121, grad/param norm = 1.7814e-01, time/batch = 17.9981s	
7242/26050 (epoch 13.900), train_loss = 1.27422756, grad/param norm = 1.7722e-01, time/batch = 17.9901s	
7243/26050 (epoch 13.902), train_loss = 1.17961018, grad/param norm = 1.8156e-01, time/batch = 16.2296s	
7244/26050 (epoch 13.904), train_loss = 1.15086100, grad/param norm = 1.6581e-01, time/batch = 17.3976s	
7245/26050 (epoch 13.906), train_loss = 1.16734819, grad/param norm = 1.8463e-01, time/batch = 18.2247s	
7246/26050 (epoch 13.908), train_loss = 1.15132787, grad/param norm = 1.6820e-01, time/batch = 18.3982s	
7247/26050 (epoch 13.910), train_loss = 1.08359006, grad/param norm = 1.5266e-01, time/batch = 17.8258s	
7248/26050 (epoch 13.912), train_loss = 1.42673900, grad/param norm = 1.9492e-01, time/batch = 16.4073s	
7249/26050 (epoch 13.914), train_loss = 1.55487559, grad/param norm = 2.0263e-01, time/batch = 17.8847s	
7250/26050 (epoch 13.916), train_loss = 1.29264790, grad/param norm = 1.8881e-01, time/batch = 18.5678s	
7251/26050 (epoch 13.917), train_loss = 1.20279598, grad/param norm = 2.0367e-01, time/batch = 17.9708s	
7252/26050 (epoch 13.919), train_loss = 1.27595040, grad/param norm = 1.8755e-01, time/batch = 17.7981s	
7253/26050 (epoch 13.921), train_loss = 1.13072709, grad/param norm = 1.7966e-01, time/batch = 18.4064s	
7254/26050 (epoch 13.923), train_loss = 1.20098675, grad/param norm = 1.8112e-01, time/batch = 17.8137s	
7255/26050 (epoch 13.925), train_loss = 1.18775875, grad/param norm = 1.7421e-01, time/batch = 15.9511s	
7256/26050 (epoch 13.927), train_loss = 1.06001080, grad/param norm = 1.5406e-01, time/batch = 16.3008s	
7257/26050 (epoch 13.929), train_loss = 1.08984729, grad/param norm = 1.6663e-01, time/batch = 18.4088s	
7258/26050 (epoch 13.931), train_loss = 1.38480212, grad/param norm = 1.9693e-01, time/batch = 16.9784s	
7259/26050 (epoch 13.933), train_loss = 1.15526414, grad/param norm = 1.8592e-01, time/batch = 15.1323s	
7260/26050 (epoch 13.935), train_loss = 1.13124544, grad/param norm = 1.6376e-01, time/batch = 18.5655s	
7261/26050 (epoch 13.937), train_loss = 1.25745607, grad/param norm = 1.7556e-01, time/batch = 15.9616s	
7262/26050 (epoch 13.939), train_loss = 1.06905628, grad/param norm = 1.4171e-01, time/batch = 17.0635s	
7263/26050 (epoch 13.940), train_loss = 1.18919977, grad/param norm = 1.6196e-01, time/batch = 18.5859s	
7264/26050 (epoch 13.942), train_loss = 1.21640345, grad/param norm = 1.8526e-01, time/batch = 16.2432s	
7265/26050 (epoch 13.944), train_loss = 1.13927692, grad/param norm = 1.6867e-01, time/batch = 17.0652s	
7266/26050 (epoch 13.946), train_loss = 1.35534256, grad/param norm = 1.8787e-01, time/batch = 18.7373s	
7267/26050 (epoch 13.948), train_loss = 1.01523783, grad/param norm = 1.8698e-01, time/batch = 14.9836s	
7268/26050 (epoch 13.950), train_loss = 1.18001958, grad/param norm = 1.8490e-01, time/batch = 18.7323s	
7269/26050 (epoch 13.952), train_loss = 1.31117156, grad/param norm = 1.9116e-01, time/batch = 17.3947s	
7270/26050 (epoch 13.954), train_loss = 1.28202422, grad/param norm = 1.8245e-01, time/batch = 18.1487s	
7271/26050 (epoch 13.956), train_loss = 1.18661589, grad/param norm = 1.7884e-01, time/batch = 18.0849s	
7272/26050 (epoch 13.958), train_loss = 1.14465782, grad/param norm = 1.7309e-01, time/batch = 14.4758s	
7273/26050 (epoch 13.960), train_loss = 1.17754212, grad/param norm = 1.7516e-01, time/batch = 13.9708s	
7274/26050 (epoch 13.962), train_loss = 1.11913972, grad/param norm = 1.6504e-01, time/batch = 13.9274s	
7275/26050 (epoch 13.964), train_loss = 1.17858926, grad/param norm = 1.7393e-01, time/batch = 14.1495s	
7276/26050 (epoch 13.965), train_loss = 1.09294966, grad/param norm = 1.7928e-01, time/batch = 16.6371s	
7277/26050 (epoch 13.967), train_loss = 1.48158452, grad/param norm = 1.7978e-01, time/batch = 17.7951s	
7278/26050 (epoch 13.969), train_loss = 1.17827528, grad/param norm = 1.6649e-01, time/batch = 18.7206s	
7279/26050 (epoch 13.971), train_loss = 1.10370447, grad/param norm = 1.5239e-01, time/batch = 18.4015s	
7280/26050 (epoch 13.973), train_loss = 1.15368433, grad/param norm = 1.9353e-01, time/batch = 17.5810s	
7281/26050 (epoch 13.975), train_loss = 1.24670468, grad/param norm = 1.6295e-01, time/batch = 17.7403s	
7282/26050 (epoch 13.977), train_loss = 1.22047416, grad/param norm = 1.6373e-01, time/batch = 18.8963s	
7283/26050 (epoch 13.979), train_loss = 1.02358097, grad/param norm = 1.6759e-01, time/batch = 17.3933s	
7284/26050 (epoch 13.981), train_loss = 1.31540021, grad/param norm = 1.6699e-01, time/batch = 15.3954s	
7285/26050 (epoch 13.983), train_loss = 1.29408273, grad/param norm = 1.7330e-01, time/batch = 18.4013s	
7286/26050 (epoch 13.985), train_loss = 1.22606302, grad/param norm = 1.8068e-01, time/batch = 18.0636s	
7287/26050 (epoch 13.987), train_loss = 1.32529391, grad/param norm = 1.9157e-01, time/batch = 17.1445s	
7288/26050 (epoch 13.988), train_loss = 1.28444223, grad/param norm = 1.6988e-01, time/batch = 15.4026s	
7289/26050 (epoch 13.990), train_loss = 1.07867831, grad/param norm = 1.5114e-01, time/batch = 18.4626s	
7290/26050 (epoch 13.992), train_loss = 1.33224918, grad/param norm = 1.8588e-01, time/batch = 16.8123s	
7291/26050 (epoch 13.994), train_loss = 1.20434981, grad/param norm = 1.8787e-01, time/batch = 18.4062s	
7292/26050 (epoch 13.996), train_loss = 1.14163780, grad/param norm = 1.7650e-01, time/batch = 16.3811s	
7293/26050 (epoch 13.998), train_loss = 1.19094885, grad/param norm = 1.7350e-01, time/batch = 17.6538s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
7294/26050 (epoch 14.000), train_loss = 1.14041669, grad/param norm = 1.7879e-01, time/batch = 17.9083s	
7295/26050 (epoch 14.002), train_loss = 1.27624814, grad/param norm = 1.9577e-01, time/batch = 18.1686s	
7296/26050 (epoch 14.004), train_loss = 1.08238057, grad/param norm = 1.7264e-01, time/batch = 17.9847s	
7297/26050 (epoch 14.006), train_loss = 1.09896481, grad/param norm = 1.6568e-01, time/batch = 18.0794s	
7298/26050 (epoch 14.008), train_loss = 1.08314148, grad/param norm = 1.7475e-01, time/batch = 15.2320s	
7299/26050 (epoch 14.010), train_loss = 1.11693785, grad/param norm = 1.6400e-01, time/batch = 17.9118s	
7300/26050 (epoch 14.012), train_loss = 1.20254531, grad/param norm = 1.7157e-01, time/batch = 16.6132s	
7301/26050 (epoch 14.013), train_loss = 1.56358082, grad/param norm = 2.0088e-01, time/batch = 16.2280s	
7302/26050 (epoch 14.015), train_loss = 1.09829705, grad/param norm = 1.5010e-01, time/batch = 17.3855s	
7303/26050 (epoch 14.017), train_loss = 1.19766233, grad/param norm = 1.8376e-01, time/batch = 17.8367s	
7304/26050 (epoch 14.019), train_loss = 1.00325029, grad/param norm = 1.4550e-01, time/batch = 18.0774s	
7305/26050 (epoch 14.021), train_loss = 1.26336641, grad/param norm = 1.8169e-01, time/batch = 15.9879s	
7306/26050 (epoch 14.023), train_loss = 1.03589862, grad/param norm = 1.6858e-01, time/batch = 18.4741s	
7307/26050 (epoch 14.025), train_loss = 1.16835170, grad/param norm = 1.6717e-01, time/batch = 16.7519s	
7308/26050 (epoch 14.027), train_loss = 0.95858593, grad/param norm = 1.7457e-01, time/batch = 18.4000s	
7309/26050 (epoch 14.029), train_loss = 1.17404237, grad/param norm = 1.6237e-01, time/batch = 18.0651s	
7310/26050 (epoch 14.031), train_loss = 1.31763991, grad/param norm = 1.9811e-01, time/batch = 18.0630s	
7311/26050 (epoch 14.033), train_loss = 1.21973607, grad/param norm = 1.7311e-01, time/batch = 17.2454s	
7312/26050 (epoch 14.035), train_loss = 1.24952997, grad/param norm = 1.6170e-01, time/batch = 16.1428s	
7313/26050 (epoch 14.036), train_loss = 1.06460837, grad/param norm = 1.9284e-01, time/batch = 18.5660s	
7314/26050 (epoch 14.038), train_loss = 1.00536013, grad/param norm = 1.5992e-01, time/batch = 17.8045s	
7315/26050 (epoch 14.040), train_loss = 1.20058248, grad/param norm = 1.8102e-01, time/batch = 17.2893s	
7316/26050 (epoch 14.042), train_loss = 1.01976716, grad/param norm = 1.7466e-01, time/batch = 15.7289s	
7317/26050 (epoch 14.044), train_loss = 1.26758492, grad/param norm = 1.6936e-01, time/batch = 17.9702s	
7318/26050 (epoch 14.046), train_loss = 0.96894261, grad/param norm = 1.5503e-01, time/batch = 17.9681s	
7319/26050 (epoch 14.048), train_loss = 1.20658611, grad/param norm = 1.7142e-01, time/batch = 16.9041s	
7320/26050 (epoch 14.050), train_loss = 1.07838393, grad/param norm = 1.7312e-01, time/batch = 18.2263s	
7321/26050 (epoch 14.052), train_loss = 1.13322928, grad/param norm = 1.6505e-01, time/batch = 18.3942s	
7322/26050 (epoch 14.054), train_loss = 1.00443144, grad/param norm = 1.5716e-01, time/batch = 18.0650s	
7323/26050 (epoch 14.056), train_loss = 0.94385806, grad/param norm = 1.3958e-01, time/batch = 18.5690s	
7324/26050 (epoch 14.058), train_loss = 1.10542512, grad/param norm = 1.5871e-01, time/batch = 14.6183s	
7325/26050 (epoch 14.060), train_loss = 1.19698456, grad/param norm = 1.6189e-01, time/batch = 15.9776s	
7326/26050 (epoch 14.061), train_loss = 1.08563261, grad/param norm = 1.6543e-01, time/batch = 18.6473s	
7327/26050 (epoch 14.063), train_loss = 1.18369510, grad/param norm = 1.6889e-01, time/batch = 17.8098s	
7328/26050 (epoch 14.065), train_loss = 0.98267831, grad/param norm = 1.5047e-01, time/batch = 16.5596s	
7329/26050 (epoch 14.067), train_loss = 1.19451231, grad/param norm = 1.7768e-01, time/batch = 18.8222s	
7330/26050 (epoch 14.069), train_loss = 1.21875365, grad/param norm = 1.6220e-01, time/batch = 16.2252s	
7331/26050 (epoch 14.071), train_loss = 1.22612909, grad/param norm = 1.6930e-01, time/batch = 17.5637s	
7332/26050 (epoch 14.073), train_loss = 1.37426565, grad/param norm = 1.8192e-01, time/batch = 17.3224s	
7333/26050 (epoch 14.075), train_loss = 1.08160257, grad/param norm = 1.5655e-01, time/batch = 15.1572s	
7334/26050 (epoch 14.077), train_loss = 1.08081959, grad/param norm = 1.6694e-01, time/batch = 16.9763s	
7335/26050 (epoch 14.079), train_loss = 1.19589177, grad/param norm = 1.7131e-01, time/batch = 18.4766s	
7336/26050 (epoch 14.081), train_loss = 1.12181094, grad/param norm = 1.8924e-01, time/batch = 18.6491s	
7337/26050 (epoch 14.083), train_loss = 1.24016331, grad/param norm = 1.6619e-01, time/batch = 17.8127s	
7338/26050 (epoch 14.084), train_loss = 1.23820637, grad/param norm = 1.8158e-01, time/batch = 17.3807s	
7339/26050 (epoch 14.086), train_loss = 1.31702246, grad/param norm = 1.7937e-01, time/batch = 14.8841s	
7340/26050 (epoch 14.088), train_loss = 1.06106053, grad/param norm = 1.6129e-01, time/batch = 15.1542s	
7341/26050 (epoch 14.090), train_loss = 1.21168796, grad/param norm = 1.7967e-01, time/batch = 17.2382s	
7342/26050 (epoch 14.092), train_loss = 1.20801004, grad/param norm = 1.7552e-01, time/batch = 17.6491s	
7343/26050 (epoch 14.094), train_loss = 1.13491545, grad/param norm = 1.7653e-01, time/batch = 18.7308s	
7344/26050 (epoch 14.096), train_loss = 1.13804495, grad/param norm = 1.6252e-01, time/batch = 17.0492s	
7345/26050 (epoch 14.098), train_loss = 1.14106298, grad/param norm = 1.7181e-01, time/batch = 14.4806s	
7346/26050 (epoch 14.100), train_loss = 1.05998978, grad/param norm = 1.7579e-01, time/batch = 18.4789s	
7347/26050 (epoch 14.102), train_loss = 1.16971121, grad/param norm = 1.6920e-01, time/batch = 18.8963s	
7348/26050 (epoch 14.104), train_loss = 1.18038898, grad/param norm = 1.7958e-01, time/batch = 17.6445s	
7349/26050 (epoch 14.106), train_loss = 1.16584161, grad/param norm = 1.8325e-01, time/batch = 18.2391s	
7350/26050 (epoch 14.107), train_loss = 0.95597490, grad/param norm = 1.5591e-01, time/batch = 18.3236s	
7351/26050 (epoch 14.109), train_loss = 1.09566164, grad/param norm = 1.7138e-01, time/batch = 18.5584s	
7352/26050 (epoch 14.111), train_loss = 1.34792723, grad/param norm = 1.9075e-01, time/batch = 15.3010s	
7353/26050 (epoch 14.113), train_loss = 1.12262611, grad/param norm = 1.6999e-01, time/batch = 18.7318s	
7354/26050 (epoch 14.115), train_loss = 1.25568517, grad/param norm = 1.7347e-01, time/batch = 18.4892s	
7355/26050 (epoch 14.117), train_loss = 1.20608012, grad/param norm = 1.6546e-01, time/batch = 15.4756s	
7356/26050 (epoch 14.119), train_loss = 0.95784605, grad/param norm = 1.5238e-01, time/batch = 15.3924s	
7357/26050 (epoch 14.121), train_loss = 1.20486708, grad/param norm = 1.6737e-01, time/batch = 18.3054s	
7358/26050 (epoch 14.123), train_loss = 1.05421015, grad/param norm = 1.7273e-01, time/batch = 18.2304s	
7359/26050 (epoch 14.125), train_loss = 1.00536400, grad/param norm = 1.6160e-01, time/batch = 4.0845s	
7360/26050 (epoch 14.127), train_loss = 0.92995703, grad/param norm = 1.4896e-01, time/batch = 0.6469s	
7361/26050 (epoch 14.129), train_loss = 0.97902704, grad/param norm = 1.5483e-01, time/batch = 0.6424s	
7362/26050 (epoch 14.131), train_loss = 1.12738197, grad/param norm = 1.6618e-01, time/batch = 0.6521s	
7363/26050 (epoch 14.132), train_loss = 1.12749919, grad/param norm = 1.6508e-01, time/batch = 0.6413s	
7364/26050 (epoch 14.134), train_loss = 1.12213135, grad/param norm = 1.7250e-01, time/batch = 0.6406s	
7365/26050 (epoch 14.136), train_loss = 1.15950583, grad/param norm = 1.6369e-01, time/batch = 0.6516s	
7366/26050 (epoch 14.138), train_loss = 0.95258635, grad/param norm = 1.6150e-01, time/batch = 0.6585s	
7367/26050 (epoch 14.140), train_loss = 0.99832589, grad/param norm = 1.6840e-01, time/batch = 0.9331s	
7368/26050 (epoch 14.142), train_loss = 1.05635267, grad/param norm = 1.7320e-01, time/batch = 0.9388s	
7369/26050 (epoch 14.144), train_loss = 0.96555433, grad/param norm = 1.7284e-01, time/batch = 0.9487s	
7370/26050 (epoch 14.146), train_loss = 0.90385341, grad/param norm = 1.5901e-01, time/batch = 0.9444s	
7371/26050 (epoch 14.148), train_loss = 0.92730685, grad/param norm = 1.4037e-01, time/batch = 0.9430s	
7372/26050 (epoch 14.150), train_loss = 1.13461120, grad/param norm = 1.7678e-01, time/batch = 1.6228s	
7373/26050 (epoch 14.152), train_loss = 1.36403137, grad/param norm = 2.0819e-01, time/batch = 1.8837s	
7374/26050 (epoch 14.154), train_loss = 0.92466159, grad/param norm = 1.6209e-01, time/batch = 2.4056s	
7375/26050 (epoch 14.155), train_loss = 0.97794007, grad/param norm = 1.6466e-01, time/batch = 16.3290s	
7376/26050 (epoch 14.157), train_loss = 1.08802924, grad/param norm = 1.8888e-01, time/batch = 17.8811s	
7377/26050 (epoch 14.159), train_loss = 1.11455262, grad/param norm = 1.8481e-01, time/batch = 17.0685s	
7378/26050 (epoch 14.161), train_loss = 1.23791072, grad/param norm = 1.9024e-01, time/batch = 18.0655s	
7379/26050 (epoch 14.163), train_loss = 0.97174120, grad/param norm = 1.6737e-01, time/batch = 18.7277s	
7380/26050 (epoch 14.165), train_loss = 0.87213256, grad/param norm = 1.4868e-01, time/batch = 14.7993s	
7381/26050 (epoch 14.167), train_loss = 1.25324458, grad/param norm = 1.9005e-01, time/batch = 18.4839s	
7382/26050 (epoch 14.169), train_loss = 1.20095014, grad/param norm = 1.6828e-01, time/batch = 17.9860s	
7383/26050 (epoch 14.171), train_loss = 0.94484057, grad/param norm = 1.4698e-01, time/batch = 18.3083s	
7384/26050 (epoch 14.173), train_loss = 1.08826457, grad/param norm = 1.8249e-01, time/batch = 18.6308s	
7385/26050 (epoch 14.175), train_loss = 1.13186965, grad/param norm = 1.6287e-01, time/batch = 16.1351s	
7386/26050 (epoch 14.177), train_loss = 1.26748483, grad/param norm = 1.7056e-01, time/batch = 18.2400s	
7387/26050 (epoch 14.179), train_loss = 0.89787790, grad/param norm = 1.4904e-01, time/batch = 15.5770s	
7388/26050 (epoch 14.180), train_loss = 1.37734935, grad/param norm = 1.7667e-01, time/batch = 17.3744s	
7389/26050 (epoch 14.182), train_loss = 1.38574860, grad/param norm = 1.9130e-01, time/batch = 16.9013s	
7390/26050 (epoch 14.184), train_loss = 1.15907120, grad/param norm = 1.6476e-01, time/batch = 16.6458s	
7391/26050 (epoch 14.186), train_loss = 0.95103320, grad/param norm = 1.4905e-01, time/batch = 31.2450s	
7392/26050 (epoch 14.188), train_loss = 1.14771777, grad/param norm = 1.6899e-01, time/batch = 22.9081s	
7393/26050 (epoch 14.190), train_loss = 1.19995236, grad/param norm = 1.7750e-01, time/batch = 17.0669s	
7394/26050 (epoch 14.192), train_loss = 1.18684458, grad/param norm = 1.6010e-01, time/batch = 17.5610s	
7395/26050 (epoch 14.194), train_loss = 1.17490925, grad/param norm = 1.6832e-01, time/batch = 18.8882s	
7396/26050 (epoch 14.196), train_loss = 1.24461102, grad/param norm = 1.8034e-01, time/batch = 17.9660s	
7397/26050 (epoch 14.198), train_loss = 1.07072057, grad/param norm = 1.6180e-01, time/batch = 17.1270s	
7398/26050 (epoch 14.200), train_loss = 1.04810202, grad/param norm = 1.7016e-01, time/batch = 17.2289s	
7399/26050 (epoch 14.202), train_loss = 1.10705696, grad/param norm = 1.7761e-01, time/batch = 18.2380s	
7400/26050 (epoch 14.203), train_loss = 1.25202437, grad/param norm = 1.8792e-01, time/batch = 18.3894s	
7401/26050 (epoch 14.205), train_loss = 1.08243958, grad/param norm = 1.6683e-01, time/batch = 16.7270s	
7402/26050 (epoch 14.207), train_loss = 1.09363537, grad/param norm = 1.6536e-01, time/batch = 18.5643s	
7403/26050 (epoch 14.209), train_loss = 1.14610472, grad/param norm = 1.5890e-01, time/batch = 17.0715s	
7404/26050 (epoch 14.211), train_loss = 0.98271728, grad/param norm = 1.6158e-01, time/batch = 17.3849s	
7405/26050 (epoch 14.213), train_loss = 1.20363411, grad/param norm = 1.8079e-01, time/batch = 19.1630s	
7406/26050 (epoch 14.215), train_loss = 1.14317981, grad/param norm = 1.8968e-01, time/batch = 17.8199s	
7407/26050 (epoch 14.217), train_loss = 1.12270927, grad/param norm = 1.6264e-01, time/batch = 17.3940s	
7408/26050 (epoch 14.219), train_loss = 1.10250635, grad/param norm = 1.8085e-01, time/batch = 17.9102s	
7409/26050 (epoch 14.221), train_loss = 1.01500036, grad/param norm = 1.5983e-01, time/batch = 16.7120s	
7410/26050 (epoch 14.223), train_loss = 1.16087780, grad/param norm = 1.6660e-01, time/batch = 17.6532s	
7411/26050 (epoch 14.225), train_loss = 1.04542649, grad/param norm = 1.6818e-01, time/batch = 16.1365s	
7412/26050 (epoch 14.226), train_loss = 1.23257124, grad/param norm = 1.8095e-01, time/batch = 18.7379s	
7413/26050 (epoch 14.228), train_loss = 1.27739639, grad/param norm = 1.7768e-01, time/batch = 14.7183s	
7414/26050 (epoch 14.230), train_loss = 1.19282978, grad/param norm = 1.7618e-01, time/batch = 18.2301s	
7415/26050 (epoch 14.232), train_loss = 1.26451361, grad/param norm = 1.7994e-01, time/batch = 17.4134s	
7416/26050 (epoch 14.234), train_loss = 1.00690595, grad/param norm = 1.6459e-01, time/batch = 18.9910s	
7417/26050 (epoch 14.236), train_loss = 1.23925304, grad/param norm = 1.7661e-01, time/batch = 17.6523s	
7418/26050 (epoch 14.238), train_loss = 0.98157770, grad/param norm = 1.5397e-01, time/batch = 18.5674s	
7419/26050 (epoch 14.240), train_loss = 1.12903002, grad/param norm = 1.7437e-01, time/batch = 17.6811s	
7420/26050 (epoch 14.242), train_loss = 1.14277454, grad/param norm = 1.5529e-01, time/batch = 17.9833s	
7421/26050 (epoch 14.244), train_loss = 1.14675430, grad/param norm = 1.8533e-01, time/batch = 15.6362s	
7422/26050 (epoch 14.246), train_loss = 1.07405286, grad/param norm = 1.5585e-01, time/batch = 18.6593s	
7423/26050 (epoch 14.248), train_loss = 1.15538589, grad/param norm = 1.6568e-01, time/batch = 17.5482s	
7424/26050 (epoch 14.250), train_loss = 1.14586685, grad/param norm = 1.8782e-01, time/batch = 18.0686s	
7425/26050 (epoch 14.251), train_loss = 1.08644416, grad/param norm = 1.6472e-01, time/batch = 18.6349s	
7426/26050 (epoch 14.253), train_loss = 1.00863249, grad/param norm = 1.6457e-01, time/batch = 18.1509s	
7427/26050 (epoch 14.255), train_loss = 1.34463977, grad/param norm = 1.7446e-01, time/batch = 17.7244s	
7428/26050 (epoch 14.257), train_loss = 1.15554428, grad/param norm = 1.8991e-01, time/batch = 18.3907s	
7429/26050 (epoch 14.259), train_loss = 1.30070882, grad/param norm = 1.7798e-01, time/batch = 18.8920s	
7430/26050 (epoch 14.261), train_loss = 1.04246522, grad/param norm = 1.7804e-01, time/batch = 17.2345s	
7431/26050 (epoch 14.263), train_loss = 1.17678393, grad/param norm = 1.6785e-01, time/batch = 15.3929s	
7432/26050 (epoch 14.265), train_loss = 1.33009047, grad/param norm = 1.9165e-01, time/batch = 17.7325s	
7433/26050 (epoch 14.267), train_loss = 1.24736041, grad/param norm = 1.7038e-01, time/batch = 16.7918s	
7434/26050 (epoch 14.269), train_loss = 1.33215709, grad/param norm = 1.9303e-01, time/batch = 16.9805s	
7435/26050 (epoch 14.271), train_loss = 1.20569239, grad/param norm = 1.7703e-01, time/batch = 18.1564s	
7436/26050 (epoch 14.273), train_loss = 1.11450868, grad/param norm = 1.8752e-01, time/batch = 18.3771s	
7437/26050 (epoch 14.274), train_loss = 1.11021946, grad/param norm = 1.6523e-01, time/batch = 15.5296s	
7438/26050 (epoch 14.276), train_loss = 1.08514867, grad/param norm = 1.7153e-01, time/batch = 17.6478s	
7439/26050 (epoch 14.278), train_loss = 1.28308296, grad/param norm = 1.8231e-01, time/batch = 18.3182s	
7440/26050 (epoch 14.280), train_loss = 1.13318237, grad/param norm = 1.5949e-01, time/batch = 17.6342s	
7441/26050 (epoch 14.282), train_loss = 1.18569848, grad/param norm = 1.7909e-01, time/batch = 17.2393s	
7442/26050 (epoch 14.284), train_loss = 1.08697176, grad/param norm = 1.7538e-01, time/batch = 15.9930s	
7443/26050 (epoch 14.286), train_loss = 1.16341043, grad/param norm = 1.7256e-01, time/batch = 18.1328s	
7444/26050 (epoch 14.288), train_loss = 0.99742447, grad/param norm = 1.6196e-01, time/batch = 15.5783s	
7445/26050 (epoch 14.290), train_loss = 1.13314639, grad/param norm = 1.6545e-01, time/batch = 18.1507s	
7446/26050 (epoch 14.292), train_loss = 1.05458490, grad/param norm = 1.6085e-01, time/batch = 18.3297s	
7447/26050 (epoch 14.294), train_loss = 1.17948568, grad/param norm = 1.8991e-01, time/batch = 16.8918s	
7448/26050 (epoch 14.296), train_loss = 1.28292820, grad/param norm = 1.7721e-01, time/batch = 17.7163s	
7449/26050 (epoch 14.298), train_loss = 1.14272954, grad/param norm = 1.6299e-01, time/batch = 16.5808s	
7450/26050 (epoch 14.299), train_loss = 0.91053995, grad/param norm = 1.5017e-01, time/batch = 18.8130s	
7451/26050 (epoch 14.301), train_loss = 1.04378845, grad/param norm = 1.7420e-01, time/batch = 18.6461s	
7452/26050 (epoch 14.303), train_loss = 1.17620323, grad/param norm = 1.7965e-01, time/batch = 16.0581s	
7453/26050 (epoch 14.305), train_loss = 0.99101068, grad/param norm = 1.7449e-01, time/batch = 16.4595s	
7454/26050 (epoch 14.307), train_loss = 1.05801629, grad/param norm = 1.7306e-01, time/batch = 17.3189s	
7455/26050 (epoch 14.309), train_loss = 1.11927807, grad/param norm = 1.7545e-01, time/batch = 17.1431s	
7456/26050 (epoch 14.311), train_loss = 1.27037876, grad/param norm = 2.0189e-01, time/batch = 18.1629s	
7457/26050 (epoch 14.313), train_loss = 1.14633442, grad/param norm = 2.0493e-01, time/batch = 17.7383s	
7458/26050 (epoch 14.315), train_loss = 1.24891365, grad/param norm = 1.7948e-01, time/batch = 17.4055s	
7459/26050 (epoch 14.317), train_loss = 1.12067277, grad/param norm = 1.6488e-01, time/batch = 16.6433s	
7460/26050 (epoch 14.319), train_loss = 1.09473108, grad/param norm = 1.6245e-01, time/batch = 18.0926s	
7461/26050 (epoch 14.321), train_loss = 1.10466192, grad/param norm = 1.7302e-01, time/batch = 16.2390s	
7462/26050 (epoch 14.322), train_loss = 1.17703078, grad/param norm = 1.7869e-01, time/batch = 18.6446s	
7463/26050 (epoch 14.324), train_loss = 0.97032404, grad/param norm = 1.7517e-01, time/batch = 15.1464s	
7464/26050 (epoch 14.326), train_loss = 1.30729229, grad/param norm = 1.7958e-01, time/batch = 18.2452s	
7465/26050 (epoch 14.328), train_loss = 1.19419173, grad/param norm = 1.6450e-01, time/batch = 18.2330s	
7466/26050 (epoch 14.330), train_loss = 1.04346792, grad/param norm = 1.7095e-01, time/batch = 17.9038s	
7467/26050 (epoch 14.332), train_loss = 1.21062787, grad/param norm = 1.7315e-01, time/batch = 18.0828s	
7468/26050 (epoch 14.334), train_loss = 1.11886066, grad/param norm = 1.8051e-01, time/batch = 17.0710s	
7469/26050 (epoch 14.336), train_loss = 1.05842953, grad/param norm = 1.6228e-01, time/batch = 18.1566s	
7470/26050 (epoch 14.338), train_loss = 1.01891187, grad/param norm = 1.5810e-01, time/batch = 18.8186s	
7471/26050 (epoch 14.340), train_loss = 1.25822160, grad/param norm = 1.8559e-01, time/batch = 15.8875s	
7472/26050 (epoch 14.342), train_loss = 1.29616284, grad/param norm = 1.8559e-01, time/batch = 17.3131s	
7473/26050 (epoch 14.344), train_loss = 1.12369918, grad/param norm = 1.7045e-01, time/batch = 18.1473s	
7474/26050 (epoch 14.345), train_loss = 1.11193454, grad/param norm = 1.6858e-01, time/batch = 18.0634s	
7475/26050 (epoch 14.347), train_loss = 1.23752359, grad/param norm = 1.8320e-01, time/batch = 14.4682s	
7476/26050 (epoch 14.349), train_loss = 1.19300926, grad/param norm = 1.7012e-01, time/batch = 17.9057s	
7477/26050 (epoch 14.351), train_loss = 1.16211049, grad/param norm = 1.7565e-01, time/batch = 18.2398s	
7478/26050 (epoch 14.353), train_loss = 1.13166203, grad/param norm = 1.7771e-01, time/batch = 15.1381s	
7479/26050 (epoch 14.355), train_loss = 1.22334642, grad/param norm = 1.9953e-01, time/batch = 18.8873s	
7480/26050 (epoch 14.357), train_loss = 1.02193135, grad/param norm = 1.5156e-01, time/batch = 17.7395s	
7481/26050 (epoch 14.359), train_loss = 1.20755817, grad/param norm = 1.6621e-01, time/batch = 18.1501s	
7482/26050 (epoch 14.361), train_loss = 1.08369498, grad/param norm = 1.6611e-01, time/batch = 17.2354s	
7483/26050 (epoch 14.363), train_loss = 1.20005108, grad/param norm = 1.6133e-01, time/batch = 15.9575s	
7484/26050 (epoch 14.365), train_loss = 1.11951915, grad/param norm = 1.4639e-01, time/batch = 18.7401s	
7485/26050 (epoch 14.367), train_loss = 1.16100274, grad/param norm = 1.6815e-01, time/batch = 16.3125s	
7486/26050 (epoch 14.369), train_loss = 1.12693929, grad/param norm = 1.6108e-01, time/batch = 15.3718s	
7487/26050 (epoch 14.370), train_loss = 1.03939221, grad/param norm = 1.5054e-01, time/batch = 18.3188s	
7488/26050 (epoch 14.372), train_loss = 1.22134190, grad/param norm = 1.9148e-01, time/batch = 16.7964s	
7489/26050 (epoch 14.374), train_loss = 1.31716280, grad/param norm = 1.8326e-01, time/batch = 17.1307s	
7490/26050 (epoch 14.376), train_loss = 1.35748216, grad/param norm = 1.8569e-01, time/batch = 17.8888s	
7491/26050 (epoch 14.378), train_loss = 1.12676349, grad/param norm = 1.7288e-01, time/batch = 18.5567s	
7492/26050 (epoch 14.380), train_loss = 1.35601476, grad/param norm = 2.0019e-01, time/batch = 16.9760s	
7493/26050 (epoch 14.382), train_loss = 1.47198278, grad/param norm = 1.9992e-01, time/batch = 18.3018s	
7494/26050 (epoch 14.384), train_loss = 1.12196964, grad/param norm = 1.6358e-01, time/batch = 18.3989s	
7495/26050 (epoch 14.386), train_loss = 1.26035755, grad/param norm = 1.8741e-01, time/batch = 17.4715s	
7496/26050 (epoch 14.388), train_loss = 1.18108595, grad/param norm = 1.7028e-01, time/batch = 17.9701s	
7497/26050 (epoch 14.390), train_loss = 1.05793570, grad/param norm = 1.6494e-01, time/batch = 17.9805s	
7498/26050 (epoch 14.392), train_loss = 1.04023869, grad/param norm = 1.5786e-01, time/batch = 18.3147s	
7499/26050 (epoch 14.393), train_loss = 1.19402206, grad/param norm = 1.7005e-01, time/batch = 18.4725s	
7500/26050 (epoch 14.395), train_loss = 1.21861412, grad/param norm = 1.6954e-01, time/batch = 17.4019s	
7501/26050 (epoch 14.397), train_loss = 1.19723218, grad/param norm = 1.9161e-01, time/batch = 16.7257s	
7502/26050 (epoch 14.399), train_loss = 1.05256234, grad/param norm = 1.6529e-01, time/batch = 14.6824s	
7503/26050 (epoch 14.401), train_loss = 1.12193178, grad/param norm = 1.5623e-01, time/batch = 18.8943s	
7504/26050 (epoch 14.403), train_loss = 1.18392986, grad/param norm = 1.6237e-01, time/batch = 18.4896s	
7505/26050 (epoch 14.405), train_loss = 1.14511929, grad/param norm = 1.7258e-01, time/batch = 17.4027s	
7506/26050 (epoch 14.407), train_loss = 1.30503004, grad/param norm = 1.8053e-01, time/batch = 16.3938s	
7507/26050 (epoch 14.409), train_loss = 1.34238025, grad/param norm = 1.8089e-01, time/batch = 18.1337s	
7508/26050 (epoch 14.411), train_loss = 1.20070748, grad/param norm = 1.9107e-01, time/batch = 18.4845s	
7509/26050 (epoch 14.413), train_loss = 1.30693087, grad/param norm = 1.6186e-01, time/batch = 17.0676s	
7510/26050 (epoch 14.415), train_loss = 1.28018686, grad/param norm = 1.9206e-01, time/batch = 17.5657s	
7511/26050 (epoch 14.417), train_loss = 1.38758600, grad/param norm = 1.8953e-01, time/batch = 18.7375s	
7512/26050 (epoch 14.418), train_loss = 1.28471452, grad/param norm = 2.0161e-01, time/batch = 17.3154s	
7513/26050 (epoch 14.420), train_loss = 0.98098338, grad/param norm = 1.5126e-01, time/batch = 18.9814s	
7514/26050 (epoch 14.422), train_loss = 1.01885971, grad/param norm = 1.6225e-01, time/batch = 15.6434s	
7515/26050 (epoch 14.424), train_loss = 1.32539681, grad/param norm = 2.0582e-01, time/batch = 18.0023s	
7516/26050 (epoch 14.426), train_loss = 1.29027278, grad/param norm = 1.8054e-01, time/batch = 17.6416s	
7517/26050 (epoch 14.428), train_loss = 1.08046400, grad/param norm = 1.5149e-01, time/batch = 17.9951s	
7518/26050 (epoch 14.430), train_loss = 1.23394627, grad/param norm = 1.7266e-01, time/batch = 18.4030s	
7519/26050 (epoch 14.432), train_loss = 1.10978498, grad/param norm = 1.7119e-01, time/batch = 16.4654s	
7520/26050 (epoch 14.434), train_loss = 1.17630742, grad/param norm = 2.0078e-01, time/batch = 14.3544s	
7521/26050 (epoch 14.436), train_loss = 1.28197133, grad/param norm = 1.6863e-01, time/batch = 18.2384s	
7522/26050 (epoch 14.438), train_loss = 1.12278279, grad/param norm = 1.8113e-01, time/batch = 18.0566s	
7523/26050 (epoch 14.440), train_loss = 1.19151094, grad/param norm = 1.6999e-01, time/batch = 17.5661s	
7524/26050 (epoch 14.441), train_loss = 1.17802647, grad/param norm = 1.6322e-01, time/batch = 18.5686s	
7525/26050 (epoch 14.443), train_loss = 0.97897755, grad/param norm = 1.5437e-01, time/batch = 18.9863s	
7526/26050 (epoch 14.445), train_loss = 1.04971939, grad/param norm = 1.6094e-01, time/batch = 17.9728s	
7527/26050 (epoch 14.447), train_loss = 1.34342693, grad/param norm = 1.9268e-01, time/batch = 17.6545s	
7528/26050 (epoch 14.449), train_loss = 1.07929056, grad/param norm = 1.7364e-01, time/batch = 18.5749s	
7529/26050 (epoch 14.451), train_loss = 1.30956552, grad/param norm = 1.7995e-01, time/batch = 16.9844s	
7530/26050 (epoch 14.453), train_loss = 1.07555214, grad/param norm = 1.5874e-01, time/batch = 18.9783s	
7531/26050 (epoch 14.455), train_loss = 1.20809119, grad/param norm = 1.6983e-01, time/batch = 15.3930s	
7532/26050 (epoch 14.457), train_loss = 1.19204359, grad/param norm = 1.7286e-01, time/batch = 17.7312s	
7533/26050 (epoch 14.459), train_loss = 1.28256661, grad/param norm = 1.7761e-01, time/batch = 18.1485s	
7534/26050 (epoch 14.461), train_loss = 1.24620641, grad/param norm = 1.9640e-01, time/batch = 17.8373s	
7535/26050 (epoch 14.463), train_loss = 1.11305510, grad/param norm = 1.6535e-01, time/batch = 16.1333s	
7536/26050 (epoch 14.464), train_loss = 1.21761634, grad/param norm = 1.6970e-01, time/batch = 16.1322s	
7537/26050 (epoch 14.466), train_loss = 1.26006721, grad/param norm = 1.8789e-01, time/batch = 16.9633s	
7538/26050 (epoch 14.468), train_loss = 1.27023229, grad/param norm = 1.6143e-01, time/batch = 17.5743s	
7539/26050 (epoch 14.470), train_loss = 1.37430960, grad/param norm = 2.0147e-01, time/batch = 16.4013s	
7540/26050 (epoch 14.472), train_loss = 1.31927522, grad/param norm = 1.9582e-01, time/batch = 18.4021s	
7541/26050 (epoch 14.474), train_loss = 1.38519207, grad/param norm = 1.7749e-01, time/batch = 18.1443s	
7542/26050 (epoch 14.476), train_loss = 1.29245306, grad/param norm = 1.7844e-01, time/batch = 18.2287s	
7543/26050 (epoch 14.478), train_loss = 1.10928494, grad/param norm = 1.6463e-01, time/batch = 17.7172s	
7544/26050 (epoch 14.480), train_loss = 1.20116722, grad/param norm = 1.7333e-01, time/batch = 15.1457s	
7545/26050 (epoch 14.482), train_loss = 1.12085862, grad/param norm = 1.6624e-01, time/batch = 18.4774s	
7546/26050 (epoch 14.484), train_loss = 1.12205695, grad/param norm = 1.7320e-01, time/batch = 17.4004s	
7547/26050 (epoch 14.486), train_loss = 1.34191349, grad/param norm = 1.7712e-01, time/batch = 16.8188s	
7548/26050 (epoch 14.488), train_loss = 1.48559668, grad/param norm = 1.9501e-01, time/batch = 18.3234s	
7549/26050 (epoch 14.489), train_loss = 1.39778532, grad/param norm = 1.9802e-01, time/batch = 17.0529s	
7550/26050 (epoch 14.491), train_loss = 1.06798592, grad/param norm = 1.6181e-01, time/batch = 17.7221s	
7551/26050 (epoch 14.493), train_loss = 1.17758751, grad/param norm = 1.7652e-01, time/batch = 17.7360s	
7552/26050 (epoch 14.495), train_loss = 1.15642045, grad/param norm = 1.7492e-01, time/batch = 15.2409s	
7553/26050 (epoch 14.497), train_loss = 1.09247676, grad/param norm = 1.6663e-01, time/batch = 17.4771s	
7554/26050 (epoch 14.499), train_loss = 1.12995250, grad/param norm = 1.6579e-01, time/batch = 15.5527s	
7555/26050 (epoch 14.501), train_loss = 1.24032628, grad/param norm = 1.7014e-01, time/batch = 18.2495s	
7556/26050 (epoch 14.503), train_loss = 1.11213746, grad/param norm = 1.8438e-01, time/batch = 18.2442s	
7557/26050 (epoch 14.505), train_loss = 1.30102099, grad/param norm = 1.7728e-01, time/batch = 17.9002s	
7558/26050 (epoch 14.507), train_loss = 1.26142205, grad/param norm = 1.8986e-01, time/batch = 17.4790s	
7559/26050 (epoch 14.509), train_loss = 1.38071209, grad/param norm = 1.8205e-01, time/batch = 18.7339s	
7560/26050 (epoch 14.511), train_loss = 1.07304666, grad/param norm = 1.5186e-01, time/batch = 17.1408s	
7561/26050 (epoch 14.512), train_loss = 1.12528051, grad/param norm = 1.8841e-01, time/batch = 17.4792s	
7562/26050 (epoch 14.514), train_loss = 1.25340343, grad/param norm = 1.8230e-01, time/batch = 17.8810s	
7563/26050 (epoch 14.516), train_loss = 1.27439012, grad/param norm = 1.8406e-01, time/batch = 18.0651s	
7564/26050 (epoch 14.518), train_loss = 1.23452642, grad/param norm = 1.8371e-01, time/batch = 18.1507s	
7565/26050 (epoch 14.520), train_loss = 1.15637723, grad/param norm = 1.6025e-01, time/batch = 17.4899s	
7566/26050 (epoch 14.522), train_loss = 0.97660227, grad/param norm = 1.6311e-01, time/batch = 18.6554s	
7567/26050 (epoch 14.524), train_loss = 1.29489620, grad/param norm = 1.8629e-01, time/batch = 18.3902s	
7568/26050 (epoch 14.526), train_loss = 1.28786860, grad/param norm = 1.8324e-01, time/batch = 17.9843s	
7569/26050 (epoch 14.528), train_loss = 1.22597597, grad/param norm = 1.7326e-01, time/batch = 16.3976s	
7570/26050 (epoch 14.530), train_loss = 1.17557367, grad/param norm = 1.7188e-01, time/batch = 17.3780s	
7571/26050 (epoch 14.532), train_loss = 1.16814572, grad/param norm = 1.5787e-01, time/batch = 16.9857s	
7572/26050 (epoch 14.534), train_loss = 1.24503960, grad/param norm = 1.8877e-01, time/batch = 18.2427s	
7573/26050 (epoch 14.536), train_loss = 1.16733374, grad/param norm = 1.5833e-01, time/batch = 15.9678s	
7574/26050 (epoch 14.537), train_loss = 1.30792841, grad/param norm = 2.0065e-01, time/batch = 17.9003s	
7575/26050 (epoch 14.539), train_loss = 1.18320918, grad/param norm = 1.8105e-01, time/batch = 16.4741s	
7576/26050 (epoch 14.541), train_loss = 1.36895802, grad/param norm = 1.9242e-01, time/batch = 17.8059s	
7577/26050 (epoch 14.543), train_loss = 1.00803067, grad/param norm = 1.6891e-01, time/batch = 14.7091s	
7578/26050 (epoch 14.545), train_loss = 1.22754901, grad/param norm = 1.7427e-01, time/batch = 17.8208s	
7579/26050 (epoch 14.547), train_loss = 1.18341001, grad/param norm = 1.6620e-01, time/batch = 19.0590s	
7580/26050 (epoch 14.549), train_loss = 0.97331865, grad/param norm = 1.5423e-01, time/batch = 17.4872s	
7581/26050 (epoch 14.551), train_loss = 1.20928309, grad/param norm = 1.7823e-01, time/batch = 17.8229s	
7582/26050 (epoch 14.553), train_loss = 1.09312828, grad/param norm = 1.6249e-01, time/batch = 18.4808s	
7583/26050 (epoch 14.555), train_loss = 1.11919742, grad/param norm = 1.7743e-01, time/batch = 18.2341s	
7584/26050 (epoch 14.557), train_loss = 1.22788747, grad/param norm = 1.5849e-01, time/batch = 18.4779s	
7585/26050 (epoch 14.559), train_loss = 1.17194763, grad/param norm = 1.6496e-01, time/batch = 17.9848s	
7586/26050 (epoch 14.560), train_loss = 1.16052990, grad/param norm = 1.7742e-01, time/batch = 18.5550s	
7587/26050 (epoch 14.562), train_loss = 1.15916079, grad/param norm = 1.7655e-01, time/batch = 15.9067s	
7588/26050 (epoch 14.564), train_loss = 1.36674027, grad/param norm = 1.7489e-01, time/batch = 18.5764s	
7589/26050 (epoch 14.566), train_loss = 1.06760464, grad/param norm = 1.6382e-01, time/batch = 17.7280s	
7590/26050 (epoch 14.568), train_loss = 1.20378411, grad/param norm = 1.6311e-01, time/batch = 17.6597s	
7591/26050 (epoch 14.570), train_loss = 1.27966274, grad/param norm = 1.7801e-01, time/batch = 17.5615s	
7592/26050 (epoch 14.572), train_loss = 1.15436009, grad/param norm = 1.7551e-01, time/batch = 18.6506s	
7593/26050 (epoch 14.574), train_loss = 1.24857199, grad/param norm = 2.0217e-01, time/batch = 17.6599s	
7594/26050 (epoch 14.576), train_loss = 1.21479496, grad/param norm = 1.8210e-01, time/batch = 23.9994s	
7595/26050 (epoch 14.578), train_loss = 1.17165595, grad/param norm = 1.7862e-01, time/batch = 26.5761s	
7596/26050 (epoch 14.580), train_loss = 1.08076882, grad/param norm = 1.7756e-01, time/batch = 17.2951s	
7597/26050 (epoch 14.582), train_loss = 1.22281712, grad/param norm = 1.7411e-01, time/batch = 18.2310s	
7598/26050 (epoch 14.583), train_loss = 1.26456878, grad/param norm = 1.6866e-01, time/batch = 17.9998s	
7599/26050 (epoch 14.585), train_loss = 1.06614776, grad/param norm = 1.6808e-01, time/batch = 18.1630s	
7600/26050 (epoch 14.587), train_loss = 1.21054420, grad/param norm = 1.7705e-01, time/batch = 18.8000s	
7601/26050 (epoch 14.589), train_loss = 1.32236628, grad/param norm = 2.0816e-01, time/batch = 16.9957s	
7602/26050 (epoch 14.591), train_loss = 1.17565503, grad/param norm = 1.6996e-01, time/batch = 17.1509s	
7603/26050 (epoch 14.593), train_loss = 1.05444108, grad/param norm = 1.8028e-01, time/batch = 16.5542s	
7604/26050 (epoch 14.595), train_loss = 1.29313281, grad/param norm = 2.0452e-01, time/batch = 17.8039s	
7605/26050 (epoch 14.597), train_loss = 1.20544014, grad/param norm = 1.7074e-01, time/batch = 18.4043s	
7606/26050 (epoch 14.599), train_loss = 1.14409790, grad/param norm = 1.6467e-01, time/batch = 15.3127s	
7607/26050 (epoch 14.601), train_loss = 1.37118679, grad/param norm = 1.7887e-01, time/batch = 18.1474s	
7608/26050 (epoch 14.603), train_loss = 1.23233048, grad/param norm = 1.7647e-01, time/batch = 16.7266s	
7609/26050 (epoch 14.605), train_loss = 1.11603408, grad/param norm = 1.6220e-01, time/batch = 18.2313s	
7610/26050 (epoch 14.607), train_loss = 1.32041363, grad/param norm = 1.9931e-01, time/batch = 14.8829s	
7611/26050 (epoch 14.608), train_loss = 1.05272416, grad/param norm = 1.5079e-01, time/batch = 17.8974s	
7612/26050 (epoch 14.610), train_loss = 1.15675908, grad/param norm = 1.7483e-01, time/batch = 18.2448s	
7613/26050 (epoch 14.612), train_loss = 1.18545519, grad/param norm = 1.8189e-01, time/batch = 18.1465s	
7614/26050 (epoch 14.614), train_loss = 1.25390161, grad/param norm = 1.8157e-01, time/batch = 18.4050s	
7615/26050 (epoch 14.616), train_loss = 1.37912848, grad/param norm = 1.8951e-01, time/batch = 14.8221s	
7616/26050 (epoch 14.618), train_loss = 1.11926144, grad/param norm = 1.7514e-01, time/batch = 17.9211s	
7617/26050 (epoch 14.620), train_loss = 1.20264791, grad/param norm = 1.7081e-01, time/batch = 17.9837s	
7618/26050 (epoch 14.622), train_loss = 1.03236118, grad/param norm = 1.6448e-01, time/batch = 18.2401s	
7619/26050 (epoch 14.624), train_loss = 1.04584626, grad/param norm = 1.6129e-01, time/batch = 18.4793s	
7620/26050 (epoch 14.626), train_loss = 1.23601836, grad/param norm = 1.6973e-01, time/batch = 18.0712s	
7621/26050 (epoch 14.628), train_loss = 1.12327629, grad/param norm = 1.7576e-01, time/batch = 18.9909s	
7622/26050 (epoch 14.630), train_loss = 1.30934997, grad/param norm = 1.7069e-01, time/batch = 18.5715s	
7623/26050 (epoch 14.631), train_loss = 1.33755880, grad/param norm = 1.8044e-01, time/batch = 15.3039s	
7624/26050 (epoch 14.633), train_loss = 1.09705447, grad/param norm = 1.7017e-01, time/batch = 18.1436s	
7625/26050 (epoch 14.635), train_loss = 1.09404989, grad/param norm = 1.5133e-01, time/batch = 18.5628s	
7626/26050 (epoch 14.637), train_loss = 1.06758708, grad/param norm = 1.7458e-01, time/batch = 15.3813s	
7627/26050 (epoch 14.639), train_loss = 1.29673314, grad/param norm = 1.7797e-01, time/batch = 14.7973s	
7628/26050 (epoch 14.641), train_loss = 1.12990100, grad/param norm = 1.5928e-01, time/batch = 18.0747s	
7629/26050 (epoch 14.643), train_loss = 1.03073665, grad/param norm = 1.4959e-01, time/batch = 18.6426s	
7630/26050 (epoch 14.645), train_loss = 1.19846198, grad/param norm = 1.7058e-01, time/batch = 17.6603s	
7631/26050 (epoch 14.647), train_loss = 1.12750871, grad/param norm = 1.6530e-01, time/batch = 17.2182s	
7632/26050 (epoch 14.649), train_loss = 1.19168359, grad/param norm = 1.8646e-01, time/batch = 18.4932s	
7633/26050 (epoch 14.651), train_loss = 1.09944543, grad/param norm = 1.8065e-01, time/batch = 18.6432s	
7634/26050 (epoch 14.653), train_loss = 1.19553456, grad/param norm = 1.7674e-01, time/batch = 17.4011s	
7635/26050 (epoch 14.655), train_loss = 1.10207791, grad/param norm = 1.6304e-01, time/batch = 16.3107s	
7636/26050 (epoch 14.656), train_loss = 1.01600007, grad/param norm = 1.6803e-01, time/batch = 18.0566s	
7637/26050 (epoch 14.658), train_loss = 1.35990819, grad/param norm = 1.8594e-01, time/batch = 18.1351s	
7638/26050 (epoch 14.660), train_loss = 1.04496576, grad/param norm = 1.6521e-01, time/batch = 17.8160s	
7639/26050 (epoch 14.662), train_loss = 1.05856437, grad/param norm = 1.5315e-01, time/batch = 18.3964s	
7640/26050 (epoch 14.664), train_loss = 1.14659592, grad/param norm = 1.7575e-01, time/batch = 17.9029s	
7641/26050 (epoch 14.666), train_loss = 1.16229810, grad/param norm = 1.8391e-01, time/batch = 17.7302s	
7642/26050 (epoch 14.668), train_loss = 0.97933084, grad/param norm = 1.8518e-01, time/batch = 18.6476s	
7643/26050 (epoch 14.670), train_loss = 1.34590765, grad/param norm = 1.8947e-01, time/batch = 18.4101s	
7644/26050 (epoch 14.672), train_loss = 1.12352040, grad/param norm = 1.7419e-01, time/batch = 15.6138s	
7645/26050 (epoch 14.674), train_loss = 1.05905941, grad/param norm = 1.6734e-01, time/batch = 16.5754s	
7646/26050 (epoch 14.676), train_loss = 1.17694271, grad/param norm = 1.7243e-01, time/batch = 18.3411s	
7647/26050 (epoch 14.678), train_loss = 1.29876976, grad/param norm = 1.8214e-01, time/batch = 15.8104s	
7648/26050 (epoch 14.679), train_loss = 1.37776288, grad/param norm = 1.9035e-01, time/batch = 17.5431s	
7649/26050 (epoch 14.681), train_loss = 1.18801996, grad/param norm = 1.7287e-01, time/batch = 17.9763s	
7650/26050 (epoch 14.683), train_loss = 1.06139123, grad/param norm = 2.0074e-01, time/batch = 17.7477s	
7651/26050 (epoch 14.685), train_loss = 1.12777080, grad/param norm = 1.6953e-01, time/batch = 16.7189s	
7652/26050 (epoch 14.687), train_loss = 0.98755370, grad/param norm = 1.6497e-01, time/batch = 17.5704s	
7653/26050 (epoch 14.689), train_loss = 1.13988853, grad/param norm = 1.8559e-01, time/batch = 18.2288s	
7654/26050 (epoch 14.691), train_loss = 0.91399670, grad/param norm = 1.5124e-01, time/batch = 15.9600s	
7655/26050 (epoch 14.693), train_loss = 1.06236747, grad/param norm = 1.6660e-01, time/batch = 18.7231s	
7656/26050 (epoch 14.695), train_loss = 1.17276667, grad/param norm = 1.7399e-01, time/batch = 18.1458s	
7657/26050 (epoch 14.697), train_loss = 1.06254888, grad/param norm = 1.6905e-01, time/batch = 17.8881s	
7658/26050 (epoch 14.699), train_loss = 1.23021179, grad/param norm = 1.8374e-01, time/batch = 17.8989s	
7659/26050 (epoch 14.701), train_loss = 1.03703155, grad/param norm = 1.6225e-01, time/batch = 18.1393s	
7660/26050 (epoch 14.702), train_loss = 1.33268013, grad/param norm = 1.9333e-01, time/batch = 15.3867s	
7661/26050 (epoch 14.704), train_loss = 1.21300735, grad/param norm = 1.6102e-01, time/batch = 16.8941s	
7662/26050 (epoch 14.706), train_loss = 1.19321169, grad/param norm = 1.9900e-01, time/batch = 14.2101s	
7663/26050 (epoch 14.708), train_loss = 1.26417865, grad/param norm = 1.8172e-01, time/batch = 18.1352s	
7664/26050 (epoch 14.710), train_loss = 1.23424361, grad/param norm = 1.7971e-01, time/batch = 17.5569s	
7665/26050 (epoch 14.712), train_loss = 1.28903793, grad/param norm = 1.9229e-01, time/batch = 17.8966s	
7666/26050 (epoch 14.714), train_loss = 1.00862333, grad/param norm = 1.7019e-01, time/batch = 18.6396s	
7667/26050 (epoch 14.716), train_loss = 1.43301812, grad/param norm = 1.9753e-01, time/batch = 18.7399s	
7668/26050 (epoch 14.718), train_loss = 1.27796915, grad/param norm = 1.8448e-01, time/batch = 17.8965s	
7669/26050 (epoch 14.720), train_loss = 1.11651775, grad/param norm = 1.7053e-01, time/batch = 18.4868s	
7670/26050 (epoch 14.722), train_loss = 1.04976839, grad/param norm = 1.6588e-01, time/batch = 16.1468s	
7671/26050 (epoch 14.724), train_loss = 1.07186727, grad/param norm = 1.8081e-01, time/batch = 16.5445s	
7672/26050 (epoch 14.726), train_loss = 1.28359610, grad/param norm = 1.8484e-01, time/batch = 14.9030s	
7673/26050 (epoch 14.727), train_loss = 1.23232871, grad/param norm = 1.7231e-01, time/batch = 16.5466s	
7674/26050 (epoch 14.729), train_loss = 1.22186943, grad/param norm = 1.7355e-01, time/batch = 18.2414s	
7675/26050 (epoch 14.731), train_loss = 1.20620671, grad/param norm = 1.6934e-01, time/batch = 17.5683s	
7676/26050 (epoch 14.733), train_loss = 1.14172032, grad/param norm = 2.0102e-01, time/batch = 16.9121s	
7677/26050 (epoch 14.735), train_loss = 1.37776964, grad/param norm = 1.9723e-01, time/batch = 17.4102s	
7678/26050 (epoch 14.737), train_loss = 1.15201785, grad/param norm = 1.6686e-01, time/batch = 15.1387s	
7679/26050 (epoch 14.739), train_loss = 1.23737730, grad/param norm = 1.8048e-01, time/batch = 18.4852s	
7680/26050 (epoch 14.741), train_loss = 1.09773774, grad/param norm = 1.7706e-01, time/batch = 17.4030s	
7681/26050 (epoch 14.743), train_loss = 1.21199132, grad/param norm = 1.8705e-01, time/batch = 18.4760s	
7682/26050 (epoch 14.745), train_loss = 1.06199234, grad/param norm = 1.7936e-01, time/batch = 17.9943s	
7683/26050 (epoch 14.747), train_loss = 1.06608004, grad/param norm = 1.5369e-01, time/batch = 18.0802s	
7684/26050 (epoch 14.749), train_loss = 1.32343044, grad/param norm = 1.8394e-01, time/batch = 18.5768s	
7685/26050 (epoch 14.750), train_loss = 1.16737035, grad/param norm = 1.5841e-01, time/batch = 16.2129s	
7686/26050 (epoch 14.752), train_loss = 1.14163302, grad/param norm = 2.0199e-01, time/batch = 15.1401s	
7687/26050 (epoch 14.754), train_loss = 1.18749078, grad/param norm = 1.7045e-01, time/batch = 17.4987s	
7688/26050 (epoch 14.756), train_loss = 1.17655020, grad/param norm = 1.7814e-01, time/batch = 18.0654s	
7689/26050 (epoch 14.758), train_loss = 1.18627881, grad/param norm = 1.7614e-01, time/batch = 18.4867s	
7690/26050 (epoch 14.760), train_loss = 1.31414226, grad/param norm = 1.7868e-01, time/batch = 15.3988s	
7691/26050 (epoch 14.762), train_loss = 1.09396526, grad/param norm = 1.6109e-01, time/batch = 18.8093s	
7692/26050 (epoch 14.764), train_loss = 1.21675293, grad/param norm = 1.8197e-01, time/batch = 17.4762s	
7693/26050 (epoch 14.766), train_loss = 1.26933677, grad/param norm = 2.0716e-01, time/batch = 17.0741s	
7694/26050 (epoch 14.768), train_loss = 1.05338917, grad/param norm = 1.5735e-01, time/batch = 17.1588s	
7695/26050 (epoch 14.770), train_loss = 1.14358653, grad/param norm = 1.7912e-01, time/batch = 15.8895s	
7696/26050 (epoch 14.772), train_loss = 1.15774157, grad/param norm = 1.6452e-01, time/batch = 17.3115s	
7697/26050 (epoch 14.774), train_loss = 1.02656666, grad/param norm = 1.6823e-01, time/batch = 18.8247s	
7698/26050 (epoch 14.775), train_loss = 0.87228229, grad/param norm = 1.6428e-01, time/batch = 18.2367s	
7699/26050 (epoch 14.777), train_loss = 1.08655488, grad/param norm = 1.6025e-01, time/batch = 15.7077s	
7700/26050 (epoch 14.779), train_loss = 1.13514101, grad/param norm = 1.8232e-01, time/batch = 18.1402s	
7701/26050 (epoch 14.781), train_loss = 1.09174417, grad/param norm = 1.6502e-01, time/batch = 18.0826s	
7702/26050 (epoch 14.783), train_loss = 1.06577712, grad/param norm = 1.6527e-01, time/batch = 17.9026s	
7703/26050 (epoch 14.785), train_loss = 1.13649109, grad/param norm = 1.7422e-01, time/batch = 16.4071s	
7704/26050 (epoch 14.787), train_loss = 1.09455134, grad/param norm = 1.7009e-01, time/batch = 16.2960s	
7705/26050 (epoch 14.789), train_loss = 1.08862078, grad/param norm = 1.9090e-01, time/batch = 18.2365s	
7706/26050 (epoch 14.791), train_loss = 1.13848241, grad/param norm = 1.7366e-01, time/batch = 16.7891s	
7707/26050 (epoch 14.793), train_loss = 1.14232219, grad/param norm = 1.9313e-01, time/batch = 18.7348s	
7708/26050 (epoch 14.795), train_loss = 0.98739493, grad/param norm = 1.5601e-01, time/batch = 17.5817s	
7709/26050 (epoch 14.797), train_loss = 1.07379805, grad/param norm = 1.6647e-01, time/batch = 17.2301s	
7710/26050 (epoch 14.798), train_loss = 1.01891534, grad/param norm = 1.7207e-01, time/batch = 15.4008s	
7711/26050 (epoch 14.800), train_loss = 1.00684312, grad/param norm = 1.4866e-01, time/batch = 18.0639s	
7712/26050 (epoch 14.802), train_loss = 1.11405480, grad/param norm = 1.7584e-01, time/batch = 17.6482s	
7713/26050 (epoch 14.804), train_loss = 1.12344598, grad/param norm = 1.7038e-01, time/batch = 18.1407s	
7714/26050 (epoch 14.806), train_loss = 1.24025011, grad/param norm = 1.7787e-01, time/batch = 17.9019s	
7715/26050 (epoch 14.808), train_loss = 1.13190148, grad/param norm = 1.6783e-01, time/batch = 18.0918s	
7716/26050 (epoch 14.810), train_loss = 1.07900606, grad/param norm = 1.7052e-01, time/batch = 17.5689s	
7717/26050 (epoch 14.812), train_loss = 1.02910705, grad/param norm = 1.7625e-01, time/batch = 17.7387s	
7718/26050 (epoch 14.814), train_loss = 1.02608972, grad/param norm = 1.9103e-01, time/batch = 15.9619s	
7719/26050 (epoch 14.816), train_loss = 1.27617037, grad/param norm = 1.9024e-01, time/batch = 14.5340s	
7720/26050 (epoch 14.818), train_loss = 1.30432429, grad/param norm = 2.2098e-01, time/batch = 18.0641s	
7721/26050 (epoch 14.820), train_loss = 1.16718937, grad/param norm = 1.7462e-01, time/batch = 17.9778s	
7722/26050 (epoch 14.821), train_loss = 1.30391449, grad/param norm = 1.9118e-01, time/batch = 18.7338s	
7723/26050 (epoch 14.823), train_loss = 1.33776335, grad/param norm = 1.9872e-01, time/batch = 17.4010s	
7724/26050 (epoch 14.825), train_loss = 1.13972576, grad/param norm = 1.7882e-01, time/batch = 17.9729s	
7725/26050 (epoch 14.827), train_loss = 1.17531459, grad/param norm = 1.9444e-01, time/batch = 17.9936s	
7726/26050 (epoch 14.829), train_loss = 1.20523263, grad/param norm = 1.7507e-01, time/batch = 17.3190s	
7727/26050 (epoch 14.831), train_loss = 1.28211350, grad/param norm = 1.7589e-01, time/batch = 17.0623s	
7728/26050 (epoch 14.833), train_loss = 1.36807900, grad/param norm = 1.9680e-01, time/batch = 17.4906s	
7729/26050 (epoch 14.835), train_loss = 1.37826214, grad/param norm = 1.8702e-01, time/batch = 18.1704s	
7730/26050 (epoch 14.837), train_loss = 1.14998506, grad/param norm = 1.7919e-01, time/batch = 17.8991s	
7731/26050 (epoch 14.839), train_loss = 1.18784196, grad/param norm = 1.9015e-01, time/batch = 18.5700s	
7732/26050 (epoch 14.841), train_loss = 1.26683418, grad/param norm = 1.8375e-01, time/batch = 18.0652s	
7733/26050 (epoch 14.843), train_loss = 1.17070429, grad/param norm = 1.7340e-01, time/batch = 17.3169s	
7734/26050 (epoch 14.845), train_loss = 1.08339438, grad/param norm = 1.5704e-01, time/batch = 15.8126s	
7735/26050 (epoch 14.846), train_loss = 1.26942296, grad/param norm = 1.6951e-01, time/batch = 18.2973s	
7736/26050 (epoch 14.848), train_loss = 1.14078440, grad/param norm = 1.6562e-01, time/batch = 17.2277s	
7737/26050 (epoch 14.850), train_loss = 1.07535294, grad/param norm = 1.6587e-01, time/batch = 18.0657s	
7738/26050 (epoch 14.852), train_loss = 1.13352594, grad/param norm = 1.7046e-01, time/batch = 15.4441s	
7739/26050 (epoch 14.854), train_loss = 1.13150925, grad/param norm = 1.6724e-01, time/batch = 17.7730s	
7740/26050 (epoch 14.856), train_loss = 1.11280131, grad/param norm = 1.9095e-01, time/batch = 17.4852s	
7741/26050 (epoch 14.858), train_loss = 1.05241706, grad/param norm = 1.7067e-01, time/batch = 18.6497s	
7742/26050 (epoch 14.860), train_loss = 1.21018014, grad/param norm = 1.7646e-01, time/batch = 18.3931s	
7743/26050 (epoch 14.862), train_loss = 1.20029546, grad/param norm = 1.7761e-01, time/batch = 18.0662s	
7744/26050 (epoch 14.864), train_loss = 1.19478311, grad/param norm = 1.9438e-01, time/batch = 17.8183s	
7745/26050 (epoch 14.866), train_loss = 1.09783539, grad/param norm = 1.6198e-01, time/batch = 18.1530s	
7746/26050 (epoch 14.868), train_loss = 1.23837916, grad/param norm = 1.9655e-01, time/batch = 17.5538s	
7747/26050 (epoch 14.869), train_loss = 1.05266087, grad/param norm = 1.6018e-01, time/batch = 17.2316s	
7748/26050 (epoch 14.871), train_loss = 0.99789365, grad/param norm = 1.6379e-01, time/batch = 17.8072s	
7749/26050 (epoch 14.873), train_loss = 1.22154629, grad/param norm = 1.7614e-01, time/batch = 17.0605s	
7750/26050 (epoch 14.875), train_loss = 1.15027350, grad/param norm = 1.7944e-01, time/batch = 16.8867s	
7751/26050 (epoch 14.877), train_loss = 1.03714222, grad/param norm = 1.6119e-01, time/batch = 15.3864s	
7752/26050 (epoch 14.879), train_loss = 1.16746501, grad/param norm = 1.6192e-01, time/batch = 18.6381s	
7753/26050 (epoch 14.881), train_loss = 1.30489116, grad/param norm = 1.7810e-01, time/batch = 16.4775s	
7754/26050 (epoch 14.883), train_loss = 1.20116644, grad/param norm = 1.8273e-01, time/batch = 16.9786s	
7755/26050 (epoch 14.885), train_loss = 0.90640812, grad/param norm = 1.5829e-01, time/batch = 18.0708s	
7756/26050 (epoch 14.887), train_loss = 1.20156654, grad/param norm = 1.7859e-01, time/batch = 16.7074s	
7757/26050 (epoch 14.889), train_loss = 1.11590115, grad/param norm = 1.6484e-01, time/batch = 17.3956s	
7758/26050 (epoch 14.891), train_loss = 0.91967358, grad/param norm = 1.4820e-01, time/batch = 17.9833s	
7759/26050 (epoch 14.893), train_loss = 0.95652729, grad/param norm = 1.5669e-01, time/batch = 18.6586s	
7760/26050 (epoch 14.894), train_loss = 1.12337946, grad/param norm = 1.7352e-01, time/batch = 16.1364s	
7761/26050 (epoch 14.896), train_loss = 1.26442903, grad/param norm = 1.6825e-01, time/batch = 17.6407s	
7762/26050 (epoch 14.898), train_loss = 1.08608891, grad/param norm = 1.7948e-01, time/batch = 18.1411s	
7763/26050 (epoch 14.900), train_loss = 1.23586609, grad/param norm = 1.8592e-01, time/batch = 18.4876s	
7764/26050 (epoch 14.902), train_loss = 1.15753525, grad/param norm = 1.7921e-01, time/batch = 17.7372s	
7765/26050 (epoch 14.904), train_loss = 1.13657512, grad/param norm = 1.7559e-01, time/batch = 18.5712s	
7766/26050 (epoch 14.906), train_loss = 1.13681790, grad/param norm = 1.7957e-01, time/batch = 17.9947s	
7767/26050 (epoch 14.908), train_loss = 1.13237842, grad/param norm = 1.7426e-01, time/batch = 17.1496s	
7768/26050 (epoch 14.910), train_loss = 1.06104676, grad/param norm = 1.5541e-01, time/batch = 15.3171s	
7769/26050 (epoch 14.912), train_loss = 1.39453774, grad/param norm = 1.9958e-01, time/batch = 15.2226s	
7770/26050 (epoch 14.914), train_loss = 1.52556693, grad/param norm = 2.1046e-01, time/batch = 17.9557s	
7771/26050 (epoch 14.916), train_loss = 1.27016638, grad/param norm = 1.9120e-01, time/batch = 18.4838s	
7772/26050 (epoch 14.917), train_loss = 1.16862284, grad/param norm = 2.0012e-01, time/batch = 18.0753s	
7773/26050 (epoch 14.919), train_loss = 1.25373216, grad/param norm = 1.9416e-01, time/batch = 17.2213s	
7774/26050 (epoch 14.921), train_loss = 1.10667301, grad/param norm = 1.8303e-01, time/batch = 17.1488s	
7775/26050 (epoch 14.923), train_loss = 1.18405592, grad/param norm = 1.8449e-01, time/batch = 18.9901s	
7776/26050 (epoch 14.925), train_loss = 1.17017389, grad/param norm = 1.7329e-01, time/batch = 18.9789s	
7777/26050 (epoch 14.927), train_loss = 1.03155998, grad/param norm = 1.4971e-01, time/batch = 14.8114s	
7778/26050 (epoch 14.929), train_loss = 1.06052125, grad/param norm = 1.7216e-01, time/batch = 17.8102s	
7779/26050 (epoch 14.931), train_loss = 1.35758449, grad/param norm = 2.0303e-01, time/batch = 18.3027s	
7780/26050 (epoch 14.933), train_loss = 1.12610625, grad/param norm = 1.7477e-01, time/batch = 18.5668s	
7781/26050 (epoch 14.935), train_loss = 1.11800877, grad/param norm = 1.6816e-01, time/batch = 17.8010s	
7782/26050 (epoch 14.937), train_loss = 1.23866487, grad/param norm = 1.7552e-01, time/batch = 18.0653s	
7783/26050 (epoch 14.939), train_loss = 1.04596766, grad/param norm = 1.4639e-01, time/batch = 17.1395s	
7784/26050 (epoch 14.940), train_loss = 1.15946636, grad/param norm = 1.6062e-01, time/batch = 16.9684s	
7785/26050 (epoch 14.942), train_loss = 1.18149450, grad/param norm = 1.8322e-01, time/batch = 18.8101s	
7786/26050 (epoch 14.944), train_loss = 1.10946081, grad/param norm = 1.8076e-01, time/batch = 14.7996s	
7787/26050 (epoch 14.946), train_loss = 1.31477861, grad/param norm = 1.8727e-01, time/batch = 18.1395s	
7788/26050 (epoch 14.948), train_loss = 1.00894536, grad/param norm = 1.9020e-01, time/batch = 15.4448s	
7789/26050 (epoch 14.950), train_loss = 1.14734618, grad/param norm = 1.8517e-01, time/batch = 18.3051s	
7790/26050 (epoch 14.952), train_loss = 1.28337641, grad/param norm = 1.9428e-01, time/batch = 18.2219s	
7791/26050 (epoch 14.954), train_loss = 1.25207732, grad/param norm = 1.8233e-01, time/batch = 18.1416s	
7792/26050 (epoch 14.956), train_loss = 1.15298795, grad/param norm = 1.8093e-01, time/batch = 17.9922s	
7793/26050 (epoch 14.958), train_loss = 1.10960677, grad/param norm = 1.7241e-01, time/batch = 18.6468s	
7794/26050 (epoch 14.960), train_loss = 1.15109999, grad/param norm = 1.6912e-01, time/batch = 17.4006s	
7795/26050 (epoch 14.962), train_loss = 1.08813989, grad/param norm = 1.6173e-01, time/batch = 17.8160s	
7796/26050 (epoch 14.964), train_loss = 1.14975629, grad/param norm = 1.7376e-01, time/batch = 18.1568s	
7797/26050 (epoch 14.965), train_loss = 1.06358265, grad/param norm = 1.7219e-01, time/batch = 15.8278s	
7798/26050 (epoch 14.967), train_loss = 1.46057110, grad/param norm = 1.8335e-01, time/batch = 28.5011s	
7799/26050 (epoch 14.969), train_loss = 1.15063325, grad/param norm = 1.6158e-01, time/batch = 28.6593s	
7800/26050 (epoch 14.971), train_loss = 1.08295393, grad/param norm = 1.5283e-01, time/batch = 16.1014s	
7801/26050 (epoch 14.973), train_loss = 1.12844242, grad/param norm = 1.8643e-01, time/batch = 17.9913s	
7802/26050 (epoch 14.975), train_loss = 1.22490017, grad/param norm = 1.6952e-01, time/batch = 18.8904s	
7803/26050 (epoch 14.977), train_loss = 1.19091824, grad/param norm = 1.5841e-01, time/batch = 16.3063s	
7804/26050 (epoch 14.979), train_loss = 0.99117947, grad/param norm = 1.6623e-01, time/batch = 17.6514s	
7805/26050 (epoch 14.981), train_loss = 1.28865202, grad/param norm = 1.7116e-01, time/batch = 17.2385s	
7806/26050 (epoch 14.983), train_loss = 1.25979708, grad/param norm = 1.6909e-01, time/batch = 17.8206s	
7807/26050 (epoch 14.985), train_loss = 1.20790064, grad/param norm = 1.8673e-01, time/batch = 16.5548s	
7808/26050 (epoch 14.987), train_loss = 1.28850195, grad/param norm = 1.8494e-01, time/batch = 18.1219s	
7809/26050 (epoch 14.988), train_loss = 1.24824231, grad/param norm = 1.7048e-01, time/batch = 17.7382s	
7810/26050 (epoch 14.990), train_loss = 1.04178879, grad/param norm = 1.4999e-01, time/batch = 18.0616s	
7811/26050 (epoch 14.992), train_loss = 1.30286891, grad/param norm = 1.8512e-01, time/batch = 18.0605s	
7812/26050 (epoch 14.994), train_loss = 1.16633462, grad/param norm = 1.9094e-01, time/batch = 18.4149s	
7813/26050 (epoch 14.996), train_loss = 1.12046714, grad/param norm = 1.8121e-01, time/batch = 17.1553s	
7814/26050 (epoch 14.998), train_loss = 1.16378121, grad/param norm = 1.7196e-01, time/batch = 18.6354s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
7815/26050 (epoch 15.000), train_loss = 1.11372157, grad/param norm = 1.8103e-01, time/batch = 16.5399s	
7816/26050 (epoch 15.002), train_loss = 1.25788085, grad/param norm = 1.9997e-01, time/batch = 16.2182s	
7817/26050 (epoch 15.004), train_loss = 1.06379973, grad/param norm = 1.7742e-01, time/batch = 17.3205s	
7818/26050 (epoch 15.006), train_loss = 1.08052568, grad/param norm = 1.7039e-01, time/batch = 18.0640s	
7819/26050 (epoch 15.008), train_loss = 1.06290608, grad/param norm = 1.8011e-01, time/batch = 14.3145s	
7820/26050 (epoch 15.010), train_loss = 1.08996350, grad/param norm = 1.6827e-01, time/batch = 17.3223s	
7821/26050 (epoch 15.012), train_loss = 1.18103250, grad/param norm = 1.7502e-01, time/batch = 18.6596s	
7822/26050 (epoch 15.013), train_loss = 1.53514811, grad/param norm = 2.0162e-01, time/batch = 17.8279s	
7823/26050 (epoch 15.015), train_loss = 1.08992841, grad/param norm = 1.5896e-01, time/batch = 17.1541s	
7824/26050 (epoch 15.017), train_loss = 1.16733892, grad/param norm = 1.7273e-01, time/batch = 17.0494s	
7825/26050 (epoch 15.019), train_loss = 0.98085501, grad/param norm = 1.4493e-01, time/batch = 15.9096s	
7826/26050 (epoch 15.021), train_loss = 1.23356898, grad/param norm = 1.7917e-01, time/batch = 18.3154s	
7827/26050 (epoch 15.023), train_loss = 1.02908222, grad/param norm = 2.0070e-01, time/batch = 17.4046s	
7828/26050 (epoch 15.025), train_loss = 1.14738022, grad/param norm = 1.7362e-01, time/batch = 17.7378s	
7829/26050 (epoch 15.027), train_loss = 0.93804406, grad/param norm = 1.8055e-01, time/batch = 14.5456s	
7830/26050 (epoch 15.029), train_loss = 1.16258799, grad/param norm = 1.6507e-01, time/batch = 18.6478s	
7831/26050 (epoch 15.031), train_loss = 1.28280213, grad/param norm = 1.9749e-01, time/batch = 16.6442s	
7832/26050 (epoch 15.033), train_loss = 1.20015419, grad/param norm = 1.7350e-01, time/batch = 18.6504s	
7833/26050 (epoch 15.035), train_loss = 1.21912680, grad/param norm = 1.6821e-01, time/batch = 18.5845s	
7834/26050 (epoch 15.036), train_loss = 1.04707282, grad/param norm = 2.0757e-01, time/batch = 15.3889s	
7835/26050 (epoch 15.038), train_loss = 0.97319333, grad/param norm = 1.6075e-01, time/batch = 17.7062s	
7836/26050 (epoch 15.040), train_loss = 1.16658074, grad/param norm = 1.8537e-01, time/batch = 18.8943s	
7837/26050 (epoch 15.042), train_loss = 0.99212073, grad/param norm = 1.5900e-01, time/batch = 17.8283s	
7838/26050 (epoch 15.044), train_loss = 1.24588814, grad/param norm = 1.6879e-01, time/batch = 17.4719s	
7839/26050 (epoch 15.046), train_loss = 0.93922480, grad/param norm = 1.4708e-01, time/batch = 15.4700s	
7840/26050 (epoch 15.048), train_loss = 1.16383869, grad/param norm = 1.6571e-01, time/batch = 16.6282s	
7841/26050 (epoch 15.050), train_loss = 1.06471817, grad/param norm = 1.7827e-01, time/batch = 18.1387s	
7842/26050 (epoch 15.052), train_loss = 1.10224208, grad/param norm = 1.6425e-01, time/batch = 17.9751s	
7843/26050 (epoch 15.054), train_loss = 0.97958343, grad/param norm = 1.5726e-01, time/batch = 18.7350s	
7844/26050 (epoch 15.056), train_loss = 0.92592184, grad/param norm = 1.3834e-01, time/batch = 17.4847s	
7845/26050 (epoch 15.058), train_loss = 1.08704726, grad/param norm = 1.6091e-01, time/batch = 18.3260s	
7846/26050 (epoch 15.060), train_loss = 1.17080018, grad/param norm = 1.6479e-01, time/batch = 18.3876s	
7847/26050 (epoch 15.061), train_loss = 1.06587257, grad/param norm = 1.6691e-01, time/batch = 17.8305s	
7848/26050 (epoch 15.063), train_loss = 1.16619438, grad/param norm = 1.7429e-01, time/batch = 15.7117s	
7849/26050 (epoch 15.065), train_loss = 0.96420225, grad/param norm = 1.5620e-01, time/batch = 16.9945s	
7850/26050 (epoch 15.067), train_loss = 1.16776837, grad/param norm = 1.7965e-01, time/batch = 18.4908s	
7851/26050 (epoch 15.069), train_loss = 1.19464046, grad/param norm = 1.6152e-01, time/batch = 17.2140s	
7852/26050 (epoch 15.071), train_loss = 1.20208235, grad/param norm = 1.6783e-01, time/batch = 15.0558s	
7853/26050 (epoch 15.073), train_loss = 1.34884060, grad/param norm = 1.8463e-01, time/batch = 16.5490s	
7854/26050 (epoch 15.075), train_loss = 1.05692293, grad/param norm = 1.5998e-01, time/batch = 18.4904s	
7855/26050 (epoch 15.077), train_loss = 1.05684281, grad/param norm = 1.5936e-01, time/batch = 17.8874s	
7856/26050 (epoch 15.079), train_loss = 1.17162702, grad/param norm = 1.6903e-01, time/batch = 18.2402s	
7857/26050 (epoch 15.081), train_loss = 1.10477957, grad/param norm = 1.8812e-01, time/batch = 16.9814s	
7858/26050 (epoch 15.083), train_loss = 1.21577031, grad/param norm = 1.6194e-01, time/batch = 17.1385s	
7859/26050 (epoch 15.084), train_loss = 1.21432128, grad/param norm = 2.0034e-01, time/batch = 15.0598s	
7860/26050 (epoch 15.086), train_loss = 1.28678847, grad/param norm = 1.8291e-01, time/batch = 18.8202s	
7861/26050 (epoch 15.088), train_loss = 1.03390580, grad/param norm = 1.6065e-01, time/batch = 18.1495s	
7862/26050 (epoch 15.090), train_loss = 1.18810203, grad/param norm = 1.9163e-01, time/batch = 15.4582s	
7863/26050 (epoch 15.092), train_loss = 1.19017363, grad/param norm = 1.7501e-01, time/batch = 17.3105s	
7864/26050 (epoch 15.094), train_loss = 1.10814734, grad/param norm = 1.7633e-01, time/batch = 18.6137s	
7865/26050 (epoch 15.096), train_loss = 1.12182011, grad/param norm = 1.6411e-01, time/batch = 17.2255s	
7866/26050 (epoch 15.098), train_loss = 1.10512536, grad/param norm = 1.7118e-01, time/batch = 17.9127s	
7867/26050 (epoch 15.100), train_loss = 1.03438227, grad/param norm = 1.7803e-01, time/batch = 18.3999s	
7868/26050 (epoch 15.102), train_loss = 1.14851145, grad/param norm = 1.7300e-01, time/batch = 14.8891s	
7869/26050 (epoch 15.104), train_loss = 1.15012619, grad/param norm = 1.8154e-01, time/batch = 18.1441s	
7870/26050 (epoch 15.106), train_loss = 1.14960920, grad/param norm = 1.8941e-01, time/batch = 18.4026s	
7871/26050 (epoch 15.107), train_loss = 0.92635764, grad/param norm = 1.4678e-01, time/batch = 18.2304s	
7872/26050 (epoch 15.109), train_loss = 1.07089074, grad/param norm = 1.7570e-01, time/batch = 16.4693s	
7873/26050 (epoch 15.111), train_loss = 1.32313652, grad/param norm = 1.9272e-01, time/batch = 17.9885s	
7874/26050 (epoch 15.113), train_loss = 1.09438179, grad/param norm = 1.6991e-01, time/batch = 18.4932s	
7875/26050 (epoch 15.115), train_loss = 1.23807123, grad/param norm = 1.7582e-01, time/batch = 17.4007s	
7876/26050 (epoch 15.117), train_loss = 1.17768718, grad/param norm = 1.6506e-01, time/batch = 18.8986s	
7877/26050 (epoch 15.119), train_loss = 0.94907382, grad/param norm = 1.5918e-01, time/batch = 17.8151s	
7878/26050 (epoch 15.121), train_loss = 1.17382509, grad/param norm = 1.6655e-01, time/batch = 17.9017s	
7879/26050 (epoch 15.123), train_loss = 1.03151574, grad/param norm = 1.7608e-01, time/batch = 14.7383s	
7880/26050 (epoch 15.125), train_loss = 0.99326866, grad/param norm = 1.6386e-01, time/batch = 17.9041s	
7881/26050 (epoch 15.127), train_loss = 0.90834580, grad/param norm = 1.5076e-01, time/batch = 17.9773s	
7882/26050 (epoch 15.129), train_loss = 0.96335112, grad/param norm = 1.6092e-01, time/batch = 17.4834s	
7883/26050 (epoch 15.131), train_loss = 1.10280888, grad/param norm = 1.6994e-01, time/batch = 18.2991s	
7884/26050 (epoch 15.132), train_loss = 1.10985254, grad/param norm = 1.6538e-01, time/batch = 17.8904s	
7885/26050 (epoch 15.134), train_loss = 1.10850639, grad/param norm = 1.8930e-01, time/batch = 16.3787s	
7886/26050 (epoch 15.136), train_loss = 1.13593172, grad/param norm = 1.6715e-01, time/batch = 17.0607s	
7887/26050 (epoch 15.138), train_loss = 0.92756127, grad/param norm = 1.6496e-01, time/batch = 18.1526s	
7888/26050 (epoch 15.140), train_loss = 0.97192017, grad/param norm = 1.6999e-01, time/batch = 17.3805s	
7889/26050 (epoch 15.142), train_loss = 1.02351371, grad/param norm = 1.6602e-01, time/batch = 17.1324s	
7890/26050 (epoch 15.144), train_loss = 0.93969752, grad/param norm = 1.6760e-01, time/batch = 18.6398s	
7891/26050 (epoch 15.146), train_loss = 0.87307586, grad/param norm = 1.5833e-01, time/batch = 17.1382s	
7892/26050 (epoch 15.148), train_loss = 0.90788371, grad/param norm = 1.4128e-01, time/batch = 17.2111s	
7893/26050 (epoch 15.150), train_loss = 1.10349468, grad/param norm = 1.7431e-01, time/batch = 18.8086s	
7894/26050 (epoch 15.152), train_loss = 1.32663434, grad/param norm = 2.0809e-01, time/batch = 16.2205s	
7895/26050 (epoch 15.154), train_loss = 0.89916263, grad/param norm = 1.6460e-01, time/batch = 18.1574s	
7896/26050 (epoch 15.155), train_loss = 0.95044498, grad/param norm = 1.6946e-01, time/batch = 17.4917s	
7897/26050 (epoch 15.157), train_loss = 1.05522330, grad/param norm = 1.9313e-01, time/batch = 17.3057s	
7898/26050 (epoch 15.159), train_loss = 1.09906570, grad/param norm = 1.9919e-01, time/batch = 18.9979s	
7899/26050 (epoch 15.161), train_loss = 1.20363526, grad/param norm = 1.8779e-01, time/batch = 16.9755s	
7900/26050 (epoch 15.163), train_loss = 0.95543288, grad/param norm = 1.6874e-01, time/batch = 18.6589s	
7901/26050 (epoch 15.165), train_loss = 0.85896945, grad/param norm = 1.4802e-01, time/batch = 18.6617s	
7902/26050 (epoch 15.167), train_loss = 1.22355226, grad/param norm = 1.9308e-01, time/batch = 17.5658s	
7903/26050 (epoch 15.169), train_loss = 1.18658374, grad/param norm = 1.8313e-01, time/batch = 17.9864s	
7904/26050 (epoch 15.171), train_loss = 0.91853958, grad/param norm = 1.4595e-01, time/batch = 15.4056s	
7905/26050 (epoch 15.173), train_loss = 1.05661776, grad/param norm = 1.7955e-01, time/batch = 18.4759s	
7906/26050 (epoch 15.175), train_loss = 1.10323267, grad/param norm = 1.6796e-01, time/batch = 15.4834s	
7907/26050 (epoch 15.177), train_loss = 1.24507970, grad/param norm = 1.7345e-01, time/batch = 17.6363s	
7908/26050 (epoch 15.179), train_loss = 0.87966920, grad/param norm = 1.5134e-01, time/batch = 16.6284s	
7909/26050 (epoch 15.180), train_loss = 1.33819605, grad/param norm = 1.7436e-01, time/batch = 17.4887s	
7910/26050 (epoch 15.182), train_loss = 1.35427619, grad/param norm = 1.8255e-01, time/batch = 16.5598s	
7911/26050 (epoch 15.184), train_loss = 1.13908407, grad/param norm = 1.6665e-01, time/batch = 17.0579s	
7912/26050 (epoch 15.186), train_loss = 0.92411321, grad/param norm = 1.4861e-01, time/batch = 18.6606s	
7913/26050 (epoch 15.188), train_loss = 1.11779738, grad/param norm = 1.6553e-01, time/batch = 16.8172s	
7914/26050 (epoch 15.190), train_loss = 1.17376523, grad/param norm = 1.8239e-01, time/batch = 17.6456s	
7915/26050 (epoch 15.192), train_loss = 1.17266269, grad/param norm = 1.6389e-01, time/batch = 18.3200s	
7916/26050 (epoch 15.194), train_loss = 1.15396545, grad/param norm = 1.6862e-01, time/batch = 17.5642s	
7917/26050 (epoch 15.196), train_loss = 1.21968472, grad/param norm = 1.7765e-01, time/batch = 18.4002s	
7918/26050 (epoch 15.198), train_loss = 1.04404528, grad/param norm = 1.5721e-01, time/batch = 17.8060s	
7919/26050 (epoch 15.200), train_loss = 1.02814581, grad/param norm = 1.6910e-01, time/batch = 18.1518s	
7920/26050 (epoch 15.202), train_loss = 1.08507114, grad/param norm = 1.7630e-01, time/batch = 15.2274s	
7921/26050 (epoch 15.203), train_loss = 1.23437958, grad/param norm = 1.9099e-01, time/batch = 18.3146s	
7922/26050 (epoch 15.205), train_loss = 1.06526773, grad/param norm = 1.7275e-01, time/batch = 18.4773s	
7923/26050 (epoch 15.207), train_loss = 1.05761109, grad/param norm = 1.6358e-01, time/batch = 17.5684s	
7924/26050 (epoch 15.209), train_loss = 1.12845004, grad/param norm = 1.5904e-01, time/batch = 15.4792s	
7925/26050 (epoch 15.211), train_loss = 0.95603623, grad/param norm = 1.6117e-01, time/batch = 16.1323s	
7926/26050 (epoch 15.213), train_loss = 1.17785668, grad/param norm = 1.8529e-01, time/batch = 17.4127s	
7927/26050 (epoch 15.215), train_loss = 1.12271143, grad/param norm = 1.9271e-01, time/batch = 18.7288s	
7928/26050 (epoch 15.217), train_loss = 1.10886568, grad/param norm = 1.6977e-01, time/batch = 17.7281s	
7929/26050 (epoch 15.219), train_loss = 1.08812299, grad/param norm = 1.8661e-01, time/batch = 17.9658s	
7930/26050 (epoch 15.221), train_loss = 1.00345369, grad/param norm = 1.7073e-01, time/batch = 17.0653s	
7931/26050 (epoch 15.223), train_loss = 1.13472556, grad/param norm = 1.6663e-01, time/batch = 17.7357s	
7932/26050 (epoch 15.225), train_loss = 1.01943039, grad/param norm = 1.6545e-01, time/batch = 18.1549s	
7933/26050 (epoch 15.226), train_loss = 1.21033492, grad/param norm = 1.9178e-01, time/batch = 16.4743s	
7934/26050 (epoch 15.228), train_loss = 1.25272201, grad/param norm = 1.7415e-01, time/batch = 18.1517s	
7935/26050 (epoch 15.230), train_loss = 1.16317131, grad/param norm = 1.6750e-01, time/batch = 16.9997s	
7936/26050 (epoch 15.232), train_loss = 1.24706455, grad/param norm = 1.9160e-01, time/batch = 18.0788s	
7937/26050 (epoch 15.234), train_loss = 0.98629380, grad/param norm = 1.6493e-01, time/batch = 16.1554s	
7938/26050 (epoch 15.236), train_loss = 1.20967148, grad/param norm = 1.7812e-01, time/batch = 17.8808s	
7939/26050 (epoch 15.238), train_loss = 0.96668695, grad/param norm = 1.5755e-01, time/batch = 17.3093s	
7940/26050 (epoch 15.240), train_loss = 1.10966475, grad/param norm = 1.7395e-01, time/batch = 15.7267s	
7941/26050 (epoch 15.242), train_loss = 1.11736724, grad/param norm = 1.5703e-01, time/batch = 17.2330s	
7942/26050 (epoch 15.244), train_loss = 1.11315272, grad/param norm = 1.9059e-01, time/batch = 17.9909s	
7943/26050 (epoch 15.246), train_loss = 1.05762781, grad/param norm = 1.5780e-01, time/batch = 17.1979s	
7944/26050 (epoch 15.248), train_loss = 1.13130202, grad/param norm = 1.7247e-01, time/batch = 18.4179s	
7945/26050 (epoch 15.250), train_loss = 1.12342058, grad/param norm = 1.9927e-01, time/batch = 17.9088s	
7946/26050 (epoch 15.251), train_loss = 1.07531041, grad/param norm = 1.6760e-01, time/batch = 16.3048s	
7947/26050 (epoch 15.253), train_loss = 0.99155560, grad/param norm = 1.6028e-01, time/batch = 17.4103s	
7948/26050 (epoch 15.255), train_loss = 1.31380354, grad/param norm = 1.7238e-01, time/batch = 17.1578s	
7949/26050 (epoch 15.257), train_loss = 1.12894572, grad/param norm = 1.8542e-01, time/batch = 18.4971s	
7950/26050 (epoch 15.259), train_loss = 1.27268381, grad/param norm = 1.7880e-01, time/batch = 17.8171s	
7951/26050 (epoch 15.261), train_loss = 1.01202186, grad/param norm = 1.7483e-01, time/batch = 18.4062s	
7952/26050 (epoch 15.263), train_loss = 1.15067743, grad/param norm = 1.7129e-01, time/batch = 17.8121s	
7953/26050 (epoch 15.265), train_loss = 1.29723065, grad/param norm = 1.8618e-01, time/batch = 18.3987s	
7954/26050 (epoch 15.267), train_loss = 1.22274396, grad/param norm = 1.7258e-01, time/batch = 15.8000s	
7955/26050 (epoch 15.269), train_loss = 1.31046581, grad/param norm = 1.9508e-01, time/batch = 15.2294s	
7956/26050 (epoch 15.271), train_loss = 1.18018266, grad/param norm = 1.7781e-01, time/batch = 16.6297s	
7957/26050 (epoch 15.273), train_loss = 1.08716198, grad/param norm = 1.8559e-01, time/batch = 18.1445s	
7958/26050 (epoch 15.274), train_loss = 1.08769336, grad/param norm = 1.6946e-01, time/batch = 15.1460s	
7959/26050 (epoch 15.276), train_loss = 1.05593399, grad/param norm = 1.7444e-01, time/batch = 17.8201s	
7960/26050 (epoch 15.278), train_loss = 1.25461606, grad/param norm = 1.7950e-01, time/batch = 17.4840s	
7961/26050 (epoch 15.280), train_loss = 1.10685082, grad/param norm = 1.6188e-01, time/batch = 17.6522s	
7962/26050 (epoch 15.282), train_loss = 1.15380257, grad/param norm = 1.7376e-01, time/batch = 18.1536s	
7963/26050 (epoch 15.284), train_loss = 1.06564146, grad/param norm = 1.7287e-01, time/batch = 16.7124s	
7964/26050 (epoch 15.286), train_loss = 1.14377949, grad/param norm = 1.6946e-01, time/batch = 17.7228s	
7965/26050 (epoch 15.288), train_loss = 0.97394328, grad/param norm = 1.5721e-01, time/batch = 17.7361s	
7966/26050 (epoch 15.290), train_loss = 1.11158025, grad/param norm = 1.7185e-01, time/batch = 17.9949s	
7967/26050 (epoch 15.292), train_loss = 1.03008486, grad/param norm = 1.5648e-01, time/batch = 18.0714s	
7968/26050 (epoch 15.294), train_loss = 1.15697271, grad/param norm = 1.8947e-01, time/batch = 17.4703s	
7969/26050 (epoch 15.296), train_loss = 1.25390093, grad/param norm = 1.8114e-01, time/batch = 18.7118s	
7970/26050 (epoch 15.298), train_loss = 1.12489766, grad/param norm = 1.6836e-01, time/batch = 18.7316s	
7971/26050 (epoch 15.299), train_loss = 0.89033902, grad/param norm = 1.5307e-01, time/batch = 16.6317s	
7972/26050 (epoch 15.301), train_loss = 1.01474079, grad/param norm = 1.7810e-01, time/batch = 18.8215s	
7973/26050 (epoch 15.303), train_loss = 1.15261132, grad/param norm = 1.7964e-01, time/batch = 15.3065s	
7974/26050 (epoch 15.305), train_loss = 0.95942064, grad/param norm = 1.7388e-01, time/batch = 16.1114s	
7975/26050 (epoch 15.307), train_loss = 1.04545898, grad/param norm = 1.7848e-01, time/batch = 17.4848s	
7976/26050 (epoch 15.309), train_loss = 1.09418456, grad/param norm = 1.7427e-01, time/batch = 17.7358s	
7977/26050 (epoch 15.311), train_loss = 1.23802956, grad/param norm = 1.9532e-01, time/batch = 18.4077s	
7978/26050 (epoch 15.313), train_loss = 1.10652695, grad/param norm = 2.0589e-01, time/batch = 18.0711s	
7979/26050 (epoch 15.315), train_loss = 1.21661673, grad/param norm = 1.9104e-01, time/batch = 17.3373s	
7980/26050 (epoch 15.317), train_loss = 1.09973705, grad/param norm = 1.6626e-01, time/batch = 17.9134s	
7981/26050 (epoch 15.319), train_loss = 1.06612592, grad/param norm = 1.7000e-01, time/batch = 17.8983s	
7982/26050 (epoch 15.321), train_loss = 1.08316668, grad/param norm = 1.8036e-01, time/batch = 17.2337s	
7983/26050 (epoch 15.322), train_loss = 1.14893750, grad/param norm = 1.7362e-01, time/batch = 18.4152s	
7984/26050 (epoch 15.324), train_loss = 0.94689294, grad/param norm = 1.7562e-01, time/batch = 17.3272s	
7985/26050 (epoch 15.326), train_loss = 1.27870538, grad/param norm = 1.7750e-01, time/batch = 18.6562s	
7986/26050 (epoch 15.328), train_loss = 1.16823096, grad/param norm = 1.5998e-01, time/batch = 17.3208s	
7987/26050 (epoch 15.330), train_loss = 1.01352473, grad/param norm = 1.7146e-01, time/batch = 16.6926s	
7988/26050 (epoch 15.332), train_loss = 1.18613490, grad/param norm = 1.7164e-01, time/batch = 16.5391s	
7989/26050 (epoch 15.334), train_loss = 1.08934406, grad/param norm = 1.7933e-01, time/batch = 17.9941s	
7990/26050 (epoch 15.336), train_loss = 1.04103988, grad/param norm = 1.6273e-01, time/batch = 18.1716s	
7991/26050 (epoch 15.338), train_loss = 0.99551708, grad/param norm = 1.5733e-01, time/batch = 16.4832s	
7992/26050 (epoch 15.340), train_loss = 1.23306912, grad/param norm = 1.8836e-01, time/batch = 17.9534s	
7993/26050 (epoch 15.342), train_loss = 1.26992092, grad/param norm = 1.8467e-01, time/batch = 16.2133s	
7994/26050 (epoch 15.344), train_loss = 1.10029124, grad/param norm = 1.7539e-01, time/batch = 18.2190s	
7995/26050 (epoch 15.345), train_loss = 1.08395165, grad/param norm = 1.7155e-01, time/batch = 17.3934s	
7996/26050 (epoch 15.347), train_loss = 1.22181049, grad/param norm = 1.8860e-01, time/batch = 17.9129s	
7997/26050 (epoch 15.349), train_loss = 1.17202370, grad/param norm = 1.7291e-01, time/batch = 16.9905s	
7998/26050 (epoch 15.351), train_loss = 1.13353154, grad/param norm = 1.7869e-01, time/batch = 16.0644s	
7999/26050 (epoch 15.353), train_loss = 1.10630240, grad/param norm = 1.8017e-01, time/batch = 17.9855s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch15.36_1.6379.t7	
8000/26050 (epoch 15.355), train_loss = 1.19525494, grad/param norm = 2.0205e-01, time/batch = 18.4023s	
8001/26050 (epoch 15.357), train_loss = 1.35416730, grad/param norm = 2.0429e-01, time/batch = 0.9207s	
8002/26050 (epoch 15.359), train_loss = 1.18582078, grad/param norm = 1.6639e-01, time/batch = 0.9455s	
8003/26050 (epoch 15.361), train_loss = 1.05998237, grad/param norm = 1.6320e-01, time/batch = 0.9389s	
8004/26050 (epoch 15.363), train_loss = 1.18612009, grad/param norm = 1.6556e-01, time/batch = 0.9334s	
8005/26050 (epoch 15.365), train_loss = 1.09872519, grad/param norm = 1.4794e-01, time/batch = 0.9422s	
8006/26050 (epoch 15.367), train_loss = 1.15050179, grad/param norm = 1.7512e-01, time/batch = 1.4292s	
8007/26050 (epoch 15.369), train_loss = 1.10777855, grad/param norm = 1.6511e-01, time/batch = 1.8013s	
8008/26050 (epoch 15.370), train_loss = 1.01476988, grad/param norm = 1.5246e-01, time/batch = 1.8207s	
8009/26050 (epoch 15.372), train_loss = 1.19838166, grad/param norm = 1.9310e-01, time/batch = 16.2014s	
8010/26050 (epoch 15.374), train_loss = 1.28254771, grad/param norm = 1.8042e-01, time/batch = 18.8927s	
8011/26050 (epoch 15.376), train_loss = 1.34012111, grad/param norm = 1.8785e-01, time/batch = 15.6324s	
8012/26050 (epoch 15.378), train_loss = 1.10792935, grad/param norm = 1.7105e-01, time/batch = 18.3791s	
8013/26050 (epoch 15.380), train_loss = 1.33041569, grad/param norm = 1.9691e-01, time/batch = 18.3038s	
8014/26050 (epoch 15.382), train_loss = 1.44602991, grad/param norm = 2.0747e-01, time/batch = 17.6523s	
8015/26050 (epoch 15.384), train_loss = 1.11012822, grad/param norm = 1.6980e-01, time/batch = 17.5557s	
8016/26050 (epoch 15.386), train_loss = 1.23068879, grad/param norm = 1.9417e-01, time/batch = 15.0701s	
8017/26050 (epoch 15.388), train_loss = 1.15003687, grad/param norm = 1.6659e-01, time/batch = 17.8952s	
8018/26050 (epoch 15.390), train_loss = 1.04587839, grad/param norm = 1.6235e-01, time/batch = 16.3660s	
8019/26050 (epoch 15.392), train_loss = 1.01421535, grad/param norm = 1.6128e-01, time/batch = 17.9752s	
8020/26050 (epoch 15.393), train_loss = 1.16727912, grad/param norm = 1.6371e-01, time/batch = 16.6541s	
8021/26050 (epoch 15.395), train_loss = 1.19130372, grad/param norm = 1.6174e-01, time/batch = 17.4039s	
8022/26050 (epoch 15.397), train_loss = 1.16443497, grad/param norm = 1.8889e-01, time/batch = 18.5645s	
8023/26050 (epoch 15.399), train_loss = 1.04023781, grad/param norm = 1.6977e-01, time/batch = 16.4777s	
8024/26050 (epoch 15.401), train_loss = 1.11367700, grad/param norm = 1.6360e-01, time/batch = 18.3876s	
8025/26050 (epoch 15.403), train_loss = 1.16218013, grad/param norm = 1.6274e-01, time/batch = 18.6224s	
8026/26050 (epoch 15.405), train_loss = 1.12582176, grad/param norm = 1.7846e-01, time/batch = 17.2158s	
8027/26050 (epoch 15.407), train_loss = 1.27424268, grad/param norm = 1.8322e-01, time/batch = 18.6351s	
8028/26050 (epoch 15.409), train_loss = 1.31941910, grad/param norm = 1.8087e-01, time/batch = 17.0705s	
8029/26050 (epoch 15.411), train_loss = 1.17833998, grad/param norm = 1.8842e-01, time/batch = 18.6356s	
8030/26050 (epoch 15.413), train_loss = 1.28094113, grad/param norm = 1.6330e-01, time/batch = 16.8196s	
8031/26050 (epoch 15.415), train_loss = 1.24725862, grad/param norm = 1.9882e-01, time/batch = 17.3806s	
8032/26050 (epoch 15.417), train_loss = 1.37519262, grad/param norm = 2.0038e-01, time/batch = 18.3086s	
8033/26050 (epoch 15.418), train_loss = 1.26330539, grad/param norm = 2.1214e-01, time/batch = 17.3404s	
8034/26050 (epoch 15.420), train_loss = 0.95821809, grad/param norm = 1.5207e-01, time/batch = 18.4909s	
8035/26050 (epoch 15.422), train_loss = 0.99121347, grad/param norm = 1.6079e-01, time/batch = 18.0712s	
8036/26050 (epoch 15.424), train_loss = 1.30271743, grad/param norm = 2.0964e-01, time/batch = 18.4834s	
8037/26050 (epoch 15.426), train_loss = 1.26650278, grad/param norm = 1.8367e-01, time/batch = 18.0647s	
8038/26050 (epoch 15.428), train_loss = 1.05772155, grad/param norm = 1.5141e-01, time/batch = 17.3198s	
8039/26050 (epoch 15.430), train_loss = 1.21734097, grad/param norm = 1.7576e-01, time/batch = 17.4133s	
8040/26050 (epoch 15.432), train_loss = 1.10248757, grad/param norm = 1.7810e-01, time/batch = 15.0712s	
8041/26050 (epoch 15.434), train_loss = 1.13069386, grad/param norm = 1.8745e-01, time/batch = 17.5609s	
8042/26050 (epoch 15.436), train_loss = 1.26218781, grad/param norm = 1.7480e-01, time/batch = 14.7845s	
8043/26050 (epoch 15.438), train_loss = 1.10561086, grad/param norm = 1.7919e-01, time/batch = 18.7250s	
8044/26050 (epoch 15.440), train_loss = 1.17044779, grad/param norm = 1.6983e-01, time/batch = 18.6520s	
8045/26050 (epoch 15.441), train_loss = 1.15409339, grad/param norm = 1.6876e-01, time/batch = 16.8113s	
8046/26050 (epoch 15.443), train_loss = 0.95716050, grad/param norm = 1.5110e-01, time/batch = 18.7358s	
8047/26050 (epoch 15.445), train_loss = 1.02296436, grad/param norm = 1.5955e-01, time/batch = 18.7335s	
8048/26050 (epoch 15.447), train_loss = 1.31262468, grad/param norm = 1.9644e-01, time/batch = 17.6632s	
8049/26050 (epoch 15.449), train_loss = 1.04825993, grad/param norm = 1.6831e-01, time/batch = 17.8201s	
8050/26050 (epoch 15.451), train_loss = 1.28933530, grad/param norm = 1.8444e-01, time/batch = 17.2440s	
8051/26050 (epoch 15.453), train_loss = 1.06222935, grad/param norm = 1.6318e-01, time/batch = 14.8073s	
8052/26050 (epoch 15.455), train_loss = 1.17758579, grad/param norm = 1.7158e-01, time/batch = 17.4593s	
8053/26050 (epoch 15.457), train_loss = 1.16330209, grad/param norm = 1.7301e-01, time/batch = 18.3981s	
8054/26050 (epoch 15.459), train_loss = 1.26266527, grad/param norm = 1.8123e-01, time/batch = 18.6597s	
8055/26050 (epoch 15.461), train_loss = 1.21622762, grad/param norm = 1.9129e-01, time/batch = 15.9648s	
8056/26050 (epoch 15.463), train_loss = 1.08357437, grad/param norm = 1.6225e-01, time/batch = 17.7329s	
8057/26050 (epoch 15.464), train_loss = 1.18579470, grad/param norm = 1.7028e-01, time/batch = 18.3102s	
8058/26050 (epoch 15.466), train_loss = 1.23226189, grad/param norm = 1.8906e-01, time/batch = 18.2149s	
8059/26050 (epoch 15.468), train_loss = 1.24620473, grad/param norm = 1.5951e-01, time/batch = 17.6503s	
8060/26050 (epoch 15.470), train_loss = 1.33960911, grad/param norm = 2.0075e-01, time/batch = 18.0558s	
8061/26050 (epoch 15.472), train_loss = 1.29018027, grad/param norm = 1.9614e-01, time/batch = 18.0603s	
8062/26050 (epoch 15.474), train_loss = 1.36166071, grad/param norm = 1.7557e-01, time/batch = 17.3298s	
8063/26050 (epoch 15.476), train_loss = 1.27398957, grad/param norm = 1.8456e-01, time/batch = 17.7473s	
8064/26050 (epoch 15.478), train_loss = 1.09232228, grad/param norm = 1.6479e-01, time/batch = 18.8200s	
8065/26050 (epoch 15.480), train_loss = 1.17749382, grad/param norm = 1.7485e-01, time/batch = 17.0637s	
8066/26050 (epoch 15.482), train_loss = 1.09729378, grad/param norm = 1.6832e-01, time/batch = 16.0259s	
8067/26050 (epoch 15.484), train_loss = 1.10019043, grad/param norm = 1.7536e-01, time/batch = 16.7630s	
8068/26050 (epoch 15.486), train_loss = 1.31188565, grad/param norm = 1.7689e-01, time/batch = 18.4974s	
8069/26050 (epoch 15.488), train_loss = 1.44962904, grad/param norm = 1.9869e-01, time/batch = 15.3769s	
8070/26050 (epoch 15.489), train_loss = 1.36872103, grad/param norm = 2.0039e-01, time/batch = 16.2205s	
8071/26050 (epoch 15.491), train_loss = 1.04859201, grad/param norm = 1.6678e-01, time/batch = 19.1554s	
8072/26050 (epoch 15.493), train_loss = 1.15214799, grad/param norm = 1.7081e-01, time/batch = 17.4867s	
8073/26050 (epoch 15.495), train_loss = 1.13533570, grad/param norm = 1.7178e-01, time/batch = 17.5611s	
8074/26050 (epoch 15.497), train_loss = 1.06381825, grad/param norm = 1.6941e-01, time/batch = 17.9118s	
8075/26050 (epoch 15.499), train_loss = 1.09917901, grad/param norm = 1.6734e-01, time/batch = 17.9042s	
8076/26050 (epoch 15.501), train_loss = 1.21619786, grad/param norm = 1.7593e-01, time/batch = 17.8867s	
8077/26050 (epoch 15.503), train_loss = 1.08796415, grad/param norm = 1.7891e-01, time/batch = 18.2412s	
8078/26050 (epoch 15.505), train_loss = 1.27164046, grad/param norm = 1.7361e-01, time/batch = 18.4840s	
8079/26050 (epoch 15.507), train_loss = 1.23581147, grad/param norm = 1.8306e-01, time/batch = 17.4818s	
8080/26050 (epoch 15.509), train_loss = 1.35376104, grad/param norm = 1.8478e-01, time/batch = 17.9804s	
8081/26050 (epoch 15.511), train_loss = 1.05616937, grad/param norm = 1.5112e-01, time/batch = 15.4633s	
8082/26050 (epoch 15.512), train_loss = 1.10337212, grad/param norm = 1.8364e-01, time/batch = 14.4537s	
8083/26050 (epoch 15.514), train_loss = 1.23386422, grad/param norm = 1.8048e-01, time/batch = 18.4736s	
8084/26050 (epoch 15.516), train_loss = 1.25615907, grad/param norm = 1.8552e-01, time/batch = 17.7367s	
8085/26050 (epoch 15.518), train_loss = 1.19670447, grad/param norm = 1.8134e-01, time/batch = 18.3999s	
8086/26050 (epoch 15.520), train_loss = 1.12682529, grad/param norm = 1.6197e-01, time/batch = 16.2958s	
8087/26050 (epoch 15.522), train_loss = 0.94370032, grad/param norm = 1.6120e-01, time/batch = 18.3261s	
8088/26050 (epoch 15.524), train_loss = 1.26928579, grad/param norm = 1.9334e-01, time/batch = 18.6594s	
8089/26050 (epoch 15.526), train_loss = 1.25882762, grad/param norm = 1.8380e-01, time/batch = 17.3966s	
8090/26050 (epoch 15.528), train_loss = 1.19868871, grad/param norm = 1.8239e-01, time/batch = 17.7322s	
8091/26050 (epoch 15.530), train_loss = 1.15251487, grad/param norm = 1.8382e-01, time/batch = 18.0379s	
8092/26050 (epoch 15.532), train_loss = 1.14846970, grad/param norm = 1.6438e-01, time/batch = 18.1389s	
8093/26050 (epoch 15.534), train_loss = 1.21107372, grad/param norm = 1.8377e-01, time/batch = 17.9703s	
8094/26050 (epoch 15.536), train_loss = 1.14051167, grad/param norm = 1.5597e-01, time/batch = 17.6476s	
8095/26050 (epoch 15.537), train_loss = 1.27307973, grad/param norm = 2.0520e-01, time/batch = 18.8976s	
8096/26050 (epoch 15.539), train_loss = 1.15795337, grad/param norm = 1.7602e-01, time/batch = 16.7365s	
8097/26050 (epoch 15.541), train_loss = 1.34937253, grad/param norm = 2.0056e-01, time/batch = 14.4735s	
8098/26050 (epoch 15.543), train_loss = 0.98093242, grad/param norm = 1.6820e-01, time/batch = 15.3022s	
8099/26050 (epoch 15.545), train_loss = 1.20603852, grad/param norm = 1.7495e-01, time/batch = 18.4012s	
8100/26050 (epoch 15.547), train_loss = 1.15875108, grad/param norm = 1.7272e-01, time/batch = 18.3228s	
8101/26050 (epoch 15.549), train_loss = 0.95497692, grad/param norm = 1.5384e-01, time/batch = 17.8169s	
8102/26050 (epoch 15.551), train_loss = 1.18793966, grad/param norm = 1.7494e-01, time/batch = 18.9012s	
8103/26050 (epoch 15.553), train_loss = 1.06903703, grad/param norm = 1.6157e-01, time/batch = 14.3721s	
8104/26050 (epoch 15.555), train_loss = 1.09225748, grad/param norm = 1.7890e-01, time/batch = 17.3258s	
8105/26050 (epoch 15.557), train_loss = 1.20389086, grad/param norm = 1.5770e-01, time/batch = 17.9828s	
8106/26050 (epoch 15.559), train_loss = 1.14690612, grad/param norm = 1.6417e-01, time/batch = 17.7186s	
8107/26050 (epoch 15.560), train_loss = 1.13136724, grad/param norm = 1.7590e-01, time/batch = 17.8339s	
8108/26050 (epoch 15.562), train_loss = 1.13440980, grad/param norm = 1.7710e-01, time/batch = 17.5649s	
8109/26050 (epoch 15.564), train_loss = 1.33523972, grad/param norm = 1.6741e-01, time/batch = 18.0720s	
8110/26050 (epoch 15.566), train_loss = 1.05269264, grad/param norm = 1.7080e-01, time/batch = 17.0663s	
8111/26050 (epoch 15.568), train_loss = 1.18009441, grad/param norm = 1.6075e-01, time/batch = 17.4891s	
8112/26050 (epoch 15.570), train_loss = 1.25379503, grad/param norm = 1.7983e-01, time/batch = 17.4029s	
8113/26050 (epoch 15.572), train_loss = 1.12712976, grad/param norm = 1.7657e-01, time/batch = 14.0067s	
8114/26050 (epoch 15.574), train_loss = 1.22318092, grad/param norm = 1.9927e-01, time/batch = 13.9147s	
8115/26050 (epoch 15.576), train_loss = 1.18621247, grad/param norm = 1.7808e-01, time/batch = 13.7685s	
8116/26050 (epoch 15.578), train_loss = 1.13475107, grad/param norm = 1.7182e-01, time/batch = 14.0716s	
8117/26050 (epoch 15.580), train_loss = 1.05758290, grad/param norm = 1.7481e-01, time/batch = 14.6307s	
8118/26050 (epoch 15.582), train_loss = 1.19767398, grad/param norm = 1.6993e-01, time/batch = 18.3949s	
8119/26050 (epoch 15.583), train_loss = 1.24251697, grad/param norm = 1.6950e-01, time/batch = 16.8817s	
8120/26050 (epoch 15.585), train_loss = 1.03876721, grad/param norm = 1.6994e-01, time/batch = 18.3201s	
8121/26050 (epoch 15.587), train_loss = 1.18367155, grad/param norm = 1.8790e-01, time/batch = 14.7784s	
8122/26050 (epoch 15.589), train_loss = 1.30080174, grad/param norm = 2.0148e-01, time/batch = 18.4826s	
8123/26050 (epoch 15.591), train_loss = 1.14563566, grad/param norm = 1.6906e-01, time/batch = 18.8985s	
8124/26050 (epoch 15.593), train_loss = 1.03380602, grad/param norm = 1.7830e-01, time/batch = 17.3934s	
8125/26050 (epoch 15.595), train_loss = 1.25929861, grad/param norm = 2.0679e-01, time/batch = 18.2421s	
8126/26050 (epoch 15.597), train_loss = 1.18214095, grad/param norm = 1.6784e-01, time/batch = 17.5701s	
8127/26050 (epoch 15.599), train_loss = 1.11601946, grad/param norm = 1.6669e-01, time/batch = 18.6643s	
8128/26050 (epoch 15.601), train_loss = 1.34827385, grad/param norm = 1.8258e-01, time/batch = 18.4729s	
8129/26050 (epoch 15.603), train_loss = 1.20261120, grad/param norm = 1.7374e-01, time/batch = 17.1424s	
8130/26050 (epoch 15.605), train_loss = 1.08698536, grad/param norm = 1.6025e-01, time/batch = 16.8667s	
8131/26050 (epoch 15.607), train_loss = 1.28844718, grad/param norm = 1.9815e-01, time/batch = 17.4782s	
8132/26050 (epoch 15.608), train_loss = 1.02122417, grad/param norm = 1.5112e-01, time/batch = 18.2457s	
8133/26050 (epoch 15.610), train_loss = 1.13459103, grad/param norm = 1.8104e-01, time/batch = 18.8921s	
8134/26050 (epoch 15.612), train_loss = 1.16814811, grad/param norm = 1.8257e-01, time/batch = 18.0722s	
8135/26050 (epoch 15.614), train_loss = 1.22483727, grad/param norm = 1.8278e-01, time/batch = 18.4918s	
8136/26050 (epoch 15.616), train_loss = 1.33806179, grad/param norm = 1.9027e-01, time/batch = 17.0757s	
8137/26050 (epoch 15.618), train_loss = 1.10221819, grad/param norm = 1.8911e-01, time/batch = 14.8024s	
8138/26050 (epoch 15.620), train_loss = 1.17823942, grad/param norm = 1.7474e-01, time/batch = 16.8847s	
8139/26050 (epoch 15.622), train_loss = 1.01683403, grad/param norm = 1.6556e-01, time/batch = 17.4149s	
8140/26050 (epoch 15.624), train_loss = 1.02253472, grad/param norm = 1.5873e-01, time/batch = 18.2322s	
8141/26050 (epoch 15.626), train_loss = 1.20790645, grad/param norm = 1.7076e-01, time/batch = 16.2083s	
8142/26050 (epoch 15.628), train_loss = 1.09358672, grad/param norm = 1.7857e-01, time/batch = 18.0718s	
8143/26050 (epoch 15.630), train_loss = 1.27233522, grad/param norm = 1.6942e-01, time/batch = 18.0674s	
8144/26050 (epoch 15.631), train_loss = 1.30860583, grad/param norm = 1.7823e-01, time/batch = 18.4958s	
8145/26050 (epoch 15.633), train_loss = 1.06935850, grad/param norm = 1.6852e-01, time/batch = 18.0627s	
8146/26050 (epoch 15.635), train_loss = 1.07310489, grad/param norm = 1.5207e-01, time/batch = 17.6459s	
8147/26050 (epoch 15.637), train_loss = 1.04794288, grad/param norm = 1.7222e-01, time/batch = 18.9177s	
8148/26050 (epoch 15.639), train_loss = 1.26741430, grad/param norm = 1.7941e-01, time/batch = 16.6516s	
8149/26050 (epoch 15.641), train_loss = 1.11008728, grad/param norm = 1.6080e-01, time/batch = 16.6433s	
8150/26050 (epoch 15.643), train_loss = 1.00575432, grad/param norm = 1.4657e-01, time/batch = 17.7965s	
8151/26050 (epoch 15.645), train_loss = 1.18002434, grad/param norm = 1.7488e-01, time/batch = 17.8165s	
8152/26050 (epoch 15.647), train_loss = 1.10120770, grad/param norm = 1.6773e-01, time/batch = 16.9664s	
8153/26050 (epoch 15.649), train_loss = 1.17009607, grad/param norm = 1.8840e-01, time/batch = 17.6457s	
8154/26050 (epoch 15.651), train_loss = 1.06647314, grad/param norm = 1.7548e-01, time/batch = 16.7119s	
8155/26050 (epoch 15.653), train_loss = 1.17739115, grad/param norm = 1.7721e-01, time/batch = 17.9000s	
8156/26050 (epoch 15.655), train_loss = 1.07776831, grad/param norm = 1.6608e-01, time/batch = 18.3074s	
8157/26050 (epoch 15.656), train_loss = 0.98342480, grad/param norm = 1.6556e-01, time/batch = 17.8231s	
8158/26050 (epoch 15.658), train_loss = 1.34609626, grad/param norm = 1.9287e-01, time/batch = 17.5649s	
8159/26050 (epoch 15.660), train_loss = 1.01550811, grad/param norm = 1.5894e-01, time/batch = 15.3093s	
8160/26050 (epoch 15.662), train_loss = 1.03901579, grad/param norm = 1.5389e-01, time/batch = 14.3969s	
8161/26050 (epoch 15.664), train_loss = 1.12704570, grad/param norm = 1.7885e-01, time/batch = 18.4713s	
8162/26050 (epoch 15.666), train_loss = 1.14151083, grad/param norm = 1.9363e-01, time/batch = 17.7859s	
8163/26050 (epoch 15.668), train_loss = 0.95728431, grad/param norm = 1.7821e-01, time/batch = 18.1498s	
8164/26050 (epoch 15.670), train_loss = 1.32410209, grad/param norm = 1.9527e-01, time/batch = 18.3229s	
8165/26050 (epoch 15.672), train_loss = 1.10610292, grad/param norm = 1.7349e-01, time/batch = 16.7378s	
8166/26050 (epoch 15.674), train_loss = 1.04639024, grad/param norm = 1.7885e-01, time/batch = 16.7168s	
8167/26050 (epoch 15.676), train_loss = 1.14897748, grad/param norm = 1.7223e-01, time/batch = 17.0451s	
8168/26050 (epoch 15.678), train_loss = 1.26839931, grad/param norm = 1.8206e-01, time/batch = 18.1550s	
8169/26050 (epoch 15.679), train_loss = 1.35148355, grad/param norm = 1.9540e-01, time/batch = 16.1151s	
8170/26050 (epoch 15.681), train_loss = 1.16787623, grad/param norm = 1.7471e-01, time/batch = 18.4785s	
8171/26050 (epoch 15.683), train_loss = 1.03797732, grad/param norm = 1.9471e-01, time/batch = 18.3002s	
8172/26050 (epoch 15.685), train_loss = 1.09694956, grad/param norm = 1.6134e-01, time/batch = 16.4855s	
8173/26050 (epoch 15.687), train_loss = 0.97647263, grad/param norm = 1.7794e-01, time/batch = 17.8121s	
8174/26050 (epoch 15.689), train_loss = 1.12261697, grad/param norm = 1.8768e-01, time/batch = 15.3916s	
8175/26050 (epoch 15.691), train_loss = 0.88836325, grad/param norm = 1.4731e-01, time/batch = 18.3154s	
8176/26050 (epoch 15.693), train_loss = 1.03545998, grad/param norm = 1.5941e-01, time/batch = 17.5594s	
8177/26050 (epoch 15.695), train_loss = 1.13437665, grad/param norm = 1.7113e-01, time/batch = 18.0583s	
8178/26050 (epoch 15.697), train_loss = 1.03102562, grad/param norm = 1.6625e-01, time/batch = 18.3185s	
8179/26050 (epoch 15.699), train_loss = 1.19714358, grad/param norm = 1.8477e-01, time/batch = 16.2331s	
8180/26050 (epoch 15.701), train_loss = 1.01453763, grad/param norm = 1.6343e-01, time/batch = 17.7387s	
8181/26050 (epoch 15.702), train_loss = 1.29549926, grad/param norm = 1.9204e-01, time/batch = 14.2985s	
8182/26050 (epoch 15.704), train_loss = 1.19509207, grad/param norm = 1.6179e-01, time/batch = 17.5612s	
8183/26050 (epoch 15.706), train_loss = 1.15236756, grad/param norm = 1.9074e-01, time/batch = 18.2293s	
8184/26050 (epoch 15.708), train_loss = 1.23621800, grad/param norm = 1.8410e-01, time/batch = 17.6503s	
8185/26050 (epoch 15.710), train_loss = 1.20986611, grad/param norm = 1.7200e-01, time/batch = 18.7310s	
8186/26050 (epoch 15.712), train_loss = 1.25686700, grad/param norm = 1.9175e-01, time/batch = 17.7370s	
8187/26050 (epoch 15.714), train_loss = 0.98854635, grad/param norm = 1.7934e-01, time/batch = 17.3765s	
8188/26050 (epoch 15.716), train_loss = 1.41539740, grad/param norm = 1.9929e-01, time/batch = 17.9012s	
8189/26050 (epoch 15.718), train_loss = 1.24771880, grad/param norm = 1.7810e-01, time/batch = 16.1463s	
8190/26050 (epoch 15.720), train_loss = 1.11006303, grad/param norm = 1.7302e-01, time/batch = 17.7214s	
8191/26050 (epoch 15.722), train_loss = 1.03232950, grad/param norm = 1.6785e-01, time/batch = 18.1566s	
8192/26050 (epoch 15.724), train_loss = 1.05626178, grad/param norm = 1.8155e-01, time/batch = 17.9849s	
8193/26050 (epoch 15.726), train_loss = 1.25433466, grad/param norm = 1.8059e-01, time/batch = 18.1634s	
8194/26050 (epoch 15.727), train_loss = 1.22574685, grad/param norm = 1.8410e-01, time/batch = 17.9747s	
8195/26050 (epoch 15.729), train_loss = 1.19323582, grad/param norm = 1.7532e-01, time/batch = 15.5538s	
8196/26050 (epoch 15.731), train_loss = 1.17816521, grad/param norm = 1.7129e-01, time/batch = 16.3899s	
8197/26050 (epoch 15.733), train_loss = 1.12007472, grad/param norm = 2.1673e-01, time/batch = 18.5652s	
8198/26050 (epoch 15.735), train_loss = 1.35733724, grad/param norm = 1.9866e-01, time/batch = 16.0575s	
8199/26050 (epoch 15.737), train_loss = 1.11716047, grad/param norm = 1.7176e-01, time/batch = 17.3000s	
8200/26050 (epoch 15.739), train_loss = 1.21000870, grad/param norm = 1.8486e-01, time/batch = 17.8191s	
8201/26050 (epoch 15.741), train_loss = 1.06819419, grad/param norm = 1.7332e-01, time/batch = 18.3142s	
8202/26050 (epoch 15.743), train_loss = 1.19408188, grad/param norm = 2.2726e-01, time/batch = 18.4138s	
8203/26050 (epoch 15.745), train_loss = 1.03039528, grad/param norm = 1.7826e-01, time/batch = 17.7925s	
8204/26050 (epoch 15.747), train_loss = 1.03983580, grad/param norm = 1.5368e-01, time/batch = 18.2481s	
8205/26050 (epoch 15.749), train_loss = 1.28669523, grad/param norm = 1.8322e-01, time/batch = 15.8312s	
8206/26050 (epoch 15.750), train_loss = 1.14211627, grad/param norm = 1.6186e-01, time/batch = 18.0489s	
8207/26050 (epoch 15.752), train_loss = 1.09940148, grad/param norm = 1.9589e-01, time/batch = 18.4104s	
8208/26050 (epoch 15.754), train_loss = 1.17221555, grad/param norm = 1.7525e-01, time/batch = 14.9714s	
8209/26050 (epoch 15.756), train_loss = 1.14999205, grad/param norm = 1.8271e-01, time/batch = 17.4794s	
8210/26050 (epoch 15.758), train_loss = 1.15567713, grad/param norm = 1.7690e-01, time/batch = 16.8001s	
8211/26050 (epoch 15.760), train_loss = 1.29118778, grad/param norm = 1.8027e-01, time/batch = 17.4005s	
8212/26050 (epoch 15.762), train_loss = 1.07627299, grad/param norm = 1.6811e-01, time/batch = 18.5642s	
8213/26050 (epoch 15.764), train_loss = 1.19198733, grad/param norm = 1.8420e-01, time/batch = 20.9191s	
8214/26050 (epoch 15.766), train_loss = 1.23948412, grad/param norm = 1.9002e-01, time/batch = 32.6935s	
8215/26050 (epoch 15.768), train_loss = 1.04401521, grad/param norm = 1.6286e-01, time/batch = 18.6036s	
8216/26050 (epoch 15.770), train_loss = 1.12282386, grad/param norm = 1.7487e-01, time/batch = 18.3684s	
8217/26050 (epoch 15.772), train_loss = 1.13689336, grad/param norm = 1.6791e-01, time/batch = 18.0533s	
8218/26050 (epoch 15.774), train_loss = 1.01618677, grad/param norm = 1.7854e-01, time/batch = 14.9832s	
8219/26050 (epoch 15.775), train_loss = 0.83891388, grad/param norm = 1.5709e-01, time/batch = 16.7240s	
8220/26050 (epoch 15.777), train_loss = 1.07525069, grad/param norm = 1.6502e-01, time/batch = 18.3155s	
8221/26050 (epoch 15.779), train_loss = 1.11823774, grad/param norm = 1.8967e-01, time/batch = 18.8215s	
8222/26050 (epoch 15.781), train_loss = 1.06345770, grad/param norm = 1.6492e-01, time/batch = 17.2255s	
8223/26050 (epoch 15.783), train_loss = 1.03209448, grad/param norm = 1.6291e-01, time/batch = 15.5332s	
8224/26050 (epoch 15.785), train_loss = 1.11601393, grad/param norm = 1.6928e-01, time/batch = 18.3232s	
8225/26050 (epoch 15.787), train_loss = 1.06061015, grad/param norm = 1.6045e-01, time/batch = 18.3340s	
8226/26050 (epoch 15.789), train_loss = 1.06926529, grad/param norm = 1.9829e-01, time/batch = 18.0620s	
8227/26050 (epoch 15.791), train_loss = 1.11806220, grad/param norm = 1.7507e-01, time/batch = 17.4021s	
8228/26050 (epoch 15.793), train_loss = 1.10830999, grad/param norm = 1.8855e-01, time/batch = 17.9163s	
8229/26050 (epoch 15.795), train_loss = 0.95683141, grad/param norm = 1.5485e-01, time/batch = 17.7233s	
8230/26050 (epoch 15.797), train_loss = 1.03984209, grad/param norm = 1.5927e-01, time/batch = 18.8079s	
8231/26050 (epoch 15.798), train_loss = 0.98611023, grad/param norm = 1.7078e-01, time/batch = 16.5579s	
8232/26050 (epoch 15.800), train_loss = 0.98701474, grad/param norm = 1.5346e-01, time/batch = 17.4557s	
8233/26050 (epoch 15.802), train_loss = 1.08518407, grad/param norm = 1.7244e-01, time/batch = 18.3164s	
8234/26050 (epoch 15.804), train_loss = 1.10756077, grad/param norm = 1.7501e-01, time/batch = 18.3291s	
8235/26050 (epoch 15.806), train_loss = 1.21499579, grad/param norm = 1.8283e-01, time/batch = 15.3998s	
8236/26050 (epoch 15.808), train_loss = 1.11425587, grad/param norm = 1.7366e-01, time/batch = 17.6408s	
8237/26050 (epoch 15.810), train_loss = 1.05341980, grad/param norm = 1.6844e-01, time/batch = 18.6390s	
8238/26050 (epoch 15.812), train_loss = 1.00834366, grad/param norm = 1.7537e-01, time/batch = 18.4774s	
8239/26050 (epoch 15.814), train_loss = 1.00107176, grad/param norm = 1.9332e-01, time/batch = 17.5537s	
8240/26050 (epoch 15.816), train_loss = 1.25002812, grad/param norm = 1.8786e-01, time/batch = 16.5544s	
8241/26050 (epoch 15.818), train_loss = 1.26967808, grad/param norm = 2.1800e-01, time/batch = 17.2248s	
8242/26050 (epoch 15.820), train_loss = 1.14066523, grad/param norm = 1.7954e-01, time/batch = 18.3240s	
8243/26050 (epoch 15.821), train_loss = 1.29188110, grad/param norm = 2.0177e-01, time/batch = 17.7268s	
8244/26050 (epoch 15.823), train_loss = 1.31112008, grad/param norm = 1.9918e-01, time/batch = 18.1551s	
8245/26050 (epoch 15.825), train_loss = 1.11642474, grad/param norm = 1.7772e-01, time/batch = 17.8158s	
8246/26050 (epoch 15.827), train_loss = 1.15775367, grad/param norm = 2.1787e-01, time/batch = 16.6264s	
8247/26050 (epoch 15.829), train_loss = 1.18832718, grad/param norm = 1.7577e-01, time/batch = 18.1460s	
8248/26050 (epoch 15.831), train_loss = 1.25581761, grad/param norm = 1.7598e-01, time/batch = 18.2347s	
8249/26050 (epoch 15.833), train_loss = 1.33806662, grad/param norm = 1.9022e-01, time/batch = 18.3267s	
8250/26050 (epoch 15.835), train_loss = 1.35837989, grad/param norm = 1.9707e-01, time/batch = 17.4973s	
8251/26050 (epoch 15.837), train_loss = 1.12935891, grad/param norm = 1.7830e-01, time/batch = 18.6564s	
8252/26050 (epoch 15.839), train_loss = 1.16492372, grad/param norm = 2.1432e-01, time/batch = 18.3078s	
8253/26050 (epoch 15.841), train_loss = 1.23916872, grad/param norm = 1.7579e-01, time/batch = 18.3978s	
8254/26050 (epoch 15.843), train_loss = 1.14642805, grad/param norm = 1.7311e-01, time/batch = 17.8361s	
8255/26050 (epoch 15.845), train_loss = 1.05659601, grad/param norm = 1.5509e-01, time/batch = 18.9809s	
8256/26050 (epoch 15.846), train_loss = 1.24490539, grad/param norm = 1.7228e-01, time/batch = 18.3023s	
8257/26050 (epoch 15.848), train_loss = 1.11620703, grad/param norm = 1.6722e-01, time/batch = 16.3247s	
8258/26050 (epoch 15.850), train_loss = 1.04281141, grad/param norm = 1.6383e-01, time/batch = 14.8499s	
8259/26050 (epoch 15.852), train_loss = 1.10169680, grad/param norm = 1.6901e-01, time/batch = 17.9085s	
8260/26050 (epoch 15.854), train_loss = 1.11238597, grad/param norm = 1.6677e-01, time/batch = 17.6669s	
8261/26050 (epoch 15.856), train_loss = 1.08612105, grad/param norm = 1.8698e-01, time/batch = 17.8271s	
8262/26050 (epoch 15.858), train_loss = 1.03388295, grad/param norm = 1.6866e-01, time/batch = 17.9005s	
8263/26050 (epoch 15.860), train_loss = 1.17780028, grad/param norm = 1.7869e-01, time/batch = 18.8036s	
8264/26050 (epoch 15.862), train_loss = 1.18303427, grad/param norm = 1.7993e-01, time/batch = 17.3155s	
8265/26050 (epoch 15.864), train_loss = 1.16856352, grad/param norm = 1.9514e-01, time/batch = 16.1280s	
8266/26050 (epoch 15.866), train_loss = 1.08262712, grad/param norm = 1.6543e-01, time/batch = 17.7278s	
8267/26050 (epoch 15.868), train_loss = 1.19849045, grad/param norm = 1.7992e-01, time/batch = 18.0661s	
8268/26050 (epoch 15.869), train_loss = 1.02676697, grad/param norm = 1.6774e-01, time/batch = 17.1662s	
8269/26050 (epoch 15.871), train_loss = 0.96830320, grad/param norm = 1.6598e-01, time/batch = 17.6713s	
8270/26050 (epoch 15.873), train_loss = 1.20043336, grad/param norm = 1.7920e-01, time/batch = 18.5454s	
8271/26050 (epoch 15.875), train_loss = 1.12064314, grad/param norm = 1.7872e-01, time/batch = 15.7049s	
8272/26050 (epoch 15.877), train_loss = 1.02107056, grad/param norm = 1.6486e-01, time/batch = 18.8151s	
8273/26050 (epoch 15.879), train_loss = 1.15512838, grad/param norm = 1.6470e-01, time/batch = 16.8202s	
8274/26050 (epoch 15.881), train_loss = 1.26304464, grad/param norm = 1.7369e-01, time/batch = 15.0733s	
8275/26050 (epoch 15.883), train_loss = 1.17300584, grad/param norm = 1.8980e-01, time/batch = 16.5528s	
8276/26050 (epoch 15.885), train_loss = 0.87741137, grad/param norm = 1.6390e-01, time/batch = 17.2420s	
8277/26050 (epoch 15.887), train_loss = 1.17273201, grad/param norm = 1.7906e-01, time/batch = 18.0544s	
8278/26050 (epoch 15.889), train_loss = 1.09220259, grad/param norm = 1.6502e-01, time/batch = 17.9894s	
8279/26050 (epoch 15.891), train_loss = 0.91090828, grad/param norm = 1.5740e-01, time/batch = 18.0661s	
8280/26050 (epoch 15.893), train_loss = 0.95719199, grad/param norm = 1.6006e-01, time/batch = 14.6229s	
8281/26050 (epoch 15.894), train_loss = 1.09706353, grad/param norm = 1.7261e-01, time/batch = 17.4448s	
8282/26050 (epoch 15.896), train_loss = 1.23604070, grad/param norm = 1.7231e-01, time/batch = 18.6395s	
8283/26050 (epoch 15.898), train_loss = 1.06255183, grad/param norm = 1.8174e-01, time/batch = 17.7332s	
8284/26050 (epoch 15.900), train_loss = 1.19764661, grad/param norm = 1.7822e-01, time/batch = 18.0634s	
8285/26050 (epoch 15.902), train_loss = 1.12386860, grad/param norm = 1.7294e-01, time/batch = 18.3979s	
8286/26050 (epoch 15.904), train_loss = 1.11766132, grad/param norm = 1.7777e-01, time/batch = 18.6466s	
8287/26050 (epoch 15.906), train_loss = 1.11631580, grad/param norm = 1.8540e-01, time/batch = 18.1409s	
8288/26050 (epoch 15.908), train_loss = 1.11985120, grad/param norm = 1.7821e-01, time/batch = 15.4667s	
8289/26050 (epoch 15.910), train_loss = 1.04086349, grad/param norm = 1.5503e-01, time/batch = 18.2369s	
8290/26050 (epoch 15.912), train_loss = 1.36424778, grad/param norm = 1.9691e-01, time/batch = 17.7422s	
8291/26050 (epoch 15.914), train_loss = 1.50527746, grad/param norm = 2.1101e-01, time/batch = 17.9019s	
8292/26050 (epoch 15.916), train_loss = 1.23906586, grad/param norm = 1.8665e-01, time/batch = 18.7262s	
8293/26050 (epoch 15.917), train_loss = 1.14724355, grad/param norm = 1.9701e-01, time/batch = 18.0652s	
8294/26050 (epoch 15.919), train_loss = 1.22664411, grad/param norm = 1.9302e-01, time/batch = 17.3126s	
8295/26050 (epoch 15.921), train_loss = 1.09023517, grad/param norm = 1.7953e-01, time/batch = 17.5628s	
8296/26050 (epoch 15.923), train_loss = 1.16185215, grad/param norm = 1.9039e-01, time/batch = 15.4042s	
8297/26050 (epoch 15.925), train_loss = 1.14320763, grad/param norm = 1.6981e-01, time/batch = 16.4493s	
8298/26050 (epoch 15.927), train_loss = 1.00476767, grad/param norm = 1.4765e-01, time/batch = 18.6522s	
8299/26050 (epoch 15.929), train_loss = 1.02674910, grad/param norm = 1.7139e-01, time/batch = 18.2354s	
8300/26050 (epoch 15.931), train_loss = 1.32817330, grad/param norm = 1.9319e-01, time/batch = 17.8168s	
8301/26050 (epoch 15.933), train_loss = 1.09612421, grad/param norm = 1.7232e-01, time/batch = 15.3949s	
8302/26050 (epoch 15.935), train_loss = 1.10275546, grad/param norm = 1.7359e-01, time/batch = 18.1588s	
8303/26050 (epoch 15.937), train_loss = 1.21371562, grad/param norm = 1.7263e-01, time/batch = 15.7182s	
8304/26050 (epoch 15.939), train_loss = 1.02758063, grad/param norm = 1.4923e-01, time/batch = 17.7367s	
8305/26050 (epoch 15.940), train_loss = 1.12261276, grad/param norm = 1.5323e-01, time/batch = 18.0584s	
8306/26050 (epoch 15.942), train_loss = 1.16023075, grad/param norm = 1.8427e-01, time/batch = 18.6522s	
8307/26050 (epoch 15.944), train_loss = 1.08045883, grad/param norm = 1.7205e-01, time/batch = 17.3893s	
8308/26050 (epoch 15.946), train_loss = 1.28183976, grad/param norm = 1.8319e-01, time/batch = 18.0609s	
8309/26050 (epoch 15.948), train_loss = 1.00008355, grad/param norm = 1.9310e-01, time/batch = 18.6358s	
8310/26050 (epoch 15.950), train_loss = 1.11619927, grad/param norm = 1.8826e-01, time/batch = 17.3976s	
8311/26050 (epoch 15.952), train_loss = 1.25889720, grad/param norm = 1.9848e-01, time/batch = 18.2317s	
8312/26050 (epoch 15.954), train_loss = 1.22089170, grad/param norm = 1.8220e-01, time/batch = 17.5568s	
8313/26050 (epoch 15.956), train_loss = 1.12286816, grad/param norm = 1.7605e-01, time/batch = 17.1332s	
8314/26050 (epoch 15.958), train_loss = 1.08595843, grad/param norm = 1.7508e-01, time/batch = 16.0445s	
8315/26050 (epoch 15.960), train_loss = 1.12704542, grad/param norm = 1.7324e-01, time/batch = 16.9816s	
8316/26050 (epoch 15.962), train_loss = 1.05731892, grad/param norm = 1.5943e-01, time/batch = 17.6420s	
8317/26050 (epoch 15.964), train_loss = 1.11921681, grad/param norm = 1.7471e-01, time/batch = 14.8065s	
8318/26050 (epoch 15.965), train_loss = 1.04470854, grad/param norm = 1.7110e-01, time/batch = 17.8193s	
8319/26050 (epoch 15.967), train_loss = 1.43949205, grad/param norm = 1.8122e-01, time/batch = 18.5658s	
8320/26050 (epoch 15.969), train_loss = 1.11879074, grad/param norm = 1.6059e-01, time/batch = 18.3252s	
8321/26050 (epoch 15.971), train_loss = 1.06416488, grad/param norm = 1.5056e-01, time/batch = 18.0501s	
8322/26050 (epoch 15.973), train_loss = 1.09656228, grad/param norm = 1.8570e-01, time/batch = 17.9861s	
8323/26050 (epoch 15.975), train_loss = 1.19586267, grad/param norm = 1.6867e-01, time/batch = 18.6490s	
8324/26050 (epoch 15.977), train_loss = 1.16403131, grad/param norm = 1.6446e-01, time/batch = 17.3998s	
8325/26050 (epoch 15.979), train_loss = 0.96221053, grad/param norm = 1.6708e-01, time/batch = 14.4676s	
8326/26050 (epoch 15.981), train_loss = 1.26279188, grad/param norm = 1.7006e-01, time/batch = 14.0596s	
8327/26050 (epoch 15.983), train_loss = 1.22377083, grad/param norm = 1.7296e-01, time/batch = 15.4693s	
8328/26050 (epoch 15.985), train_loss = 1.18737583, grad/param norm = 1.9839e-01, time/batch = 14.3635s	
8329/26050 (epoch 15.987), train_loss = 1.25642031, grad/param norm = 1.8480e-01, time/batch = 15.0425s	
8330/26050 (epoch 15.988), train_loss = 1.21640091, grad/param norm = 1.7022e-01, time/batch = 16.8834s	
8331/26050 (epoch 15.990), train_loss = 1.01854667, grad/param norm = 1.5497e-01, time/batch = 18.8979s	
8332/26050 (epoch 15.992), train_loss = 1.28138105, grad/param norm = 1.8517e-01, time/batch = 18.1474s	
8333/26050 (epoch 15.994), train_loss = 1.12961559, grad/param norm = 1.9210e-01, time/batch = 17.4838s	
8334/26050 (epoch 15.996), train_loss = 1.09461278, grad/param norm = 1.8237e-01, time/batch = 18.7243s	
8335/26050 (epoch 15.998), train_loss = 1.13606651, grad/param norm = 1.6805e-01, time/batch = 15.2189s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
8336/26050 (epoch 16.000), train_loss = 1.09482685, grad/param norm = 1.8304e-01, time/batch = 18.2223s	
8337/26050 (epoch 16.002), train_loss = 1.22591440, grad/param norm = 1.9877e-01, time/batch = 17.9848s	
8338/26050 (epoch 16.004), train_loss = 1.04813826, grad/param norm = 1.7791e-01, time/batch = 17.2476s	
8339/26050 (epoch 16.006), train_loss = 1.06101844, grad/param norm = 1.7673e-01, time/batch = 18.5777s	
8340/26050 (epoch 16.008), train_loss = 1.05325785, grad/param norm = 1.8890e-01, time/batch = 16.1343s	
8341/26050 (epoch 16.010), train_loss = 1.06900076, grad/param norm = 1.6619e-01, time/batch = 18.6488s	
8342/26050 (epoch 16.012), train_loss = 1.15214538, grad/param norm = 1.7220e-01, time/batch = 18.3101s	
8343/26050 (epoch 16.013), train_loss = 1.50785745, grad/param norm = 2.3590e-01, time/batch = 17.4889s	
8344/26050 (epoch 16.015), train_loss = 1.07120670, grad/param norm = 1.5378e-01, time/batch = 18.1605s	
8345/26050 (epoch 16.017), train_loss = 1.14840781, grad/param norm = 1.7296e-01, time/batch = 17.4068s	
8346/26050 (epoch 16.019), train_loss = 0.95658155, grad/param norm = 1.4560e-01, time/batch = 15.8086s	
8347/26050 (epoch 16.021), train_loss = 1.20380269, grad/param norm = 1.7775e-01, time/batch = 17.1359s	
8348/26050 (epoch 16.023), train_loss = 1.00866838, grad/param norm = 1.9790e-01, time/batch = 18.7390s	
8349/26050 (epoch 16.025), train_loss = 1.12692281, grad/param norm = 1.7185e-01, time/batch = 17.6418s	
8350/26050 (epoch 16.027), train_loss = 0.91636218, grad/param norm = 1.7693e-01, time/batch = 16.3738s	
8351/26050 (epoch 16.029), train_loss = 1.15153313, grad/param norm = 1.6635e-01, time/batch = 18.6451s	
8352/26050 (epoch 16.031), train_loss = 1.26095308, grad/param norm = 2.0112e-01, time/batch = 17.5630s	
8353/26050 (epoch 16.033), train_loss = 1.17774791, grad/param norm = 1.7813e-01, time/batch = 18.2416s	
8354/26050 (epoch 16.035), train_loss = 1.19247305, grad/param norm = 1.6963e-01, time/batch = 18.4175s	
8355/26050 (epoch 16.036), train_loss = 1.03044132, grad/param norm = 1.9270e-01, time/batch = 17.8205s	
8356/26050 (epoch 16.038), train_loss = 0.94396147, grad/param norm = 1.5702e-01, time/batch = 15.9592s	
8357/26050 (epoch 16.040), train_loss = 1.14196877, grad/param norm = 1.8398e-01, time/batch = 16.8043s	
8358/26050 (epoch 16.042), train_loss = 0.97675599, grad/param norm = 1.7064e-01, time/batch = 16.9635s	
8359/26050 (epoch 16.044), train_loss = 1.21996056, grad/param norm = 1.6841e-01, time/batch = 16.6321s	
8360/26050 (epoch 16.046), train_loss = 0.90843648, grad/param norm = 1.4837e-01, time/batch = 17.5638s	
8361/26050 (epoch 16.048), train_loss = 1.14765560, grad/param norm = 1.6687e-01, time/batch = 18.7390s	
8362/26050 (epoch 16.050), train_loss = 1.03888689, grad/param norm = 1.7234e-01, time/batch = 16.8978s	
8363/26050 (epoch 16.052), train_loss = 1.08790988, grad/param norm = 1.8531e-01, time/batch = 18.4819s	
8364/26050 (epoch 16.054), train_loss = 0.95497852, grad/param norm = 1.5822e-01, time/batch = 17.9733s	
8365/26050 (epoch 16.056), train_loss = 0.90658659, grad/param norm = 1.4061e-01, time/batch = 18.7390s	
8366/26050 (epoch 16.058), train_loss = 1.07224984, grad/param norm = 1.6253e-01, time/batch = 18.3271s	
8367/26050 (epoch 16.060), train_loss = 1.15787922, grad/param norm = 1.6855e-01, time/batch = 14.8125s	
8368/26050 (epoch 16.061), train_loss = 1.04031799, grad/param norm = 1.6662e-01, time/batch = 18.7291s	
8369/26050 (epoch 16.063), train_loss = 1.15318972, grad/param norm = 1.7231e-01, time/batch = 17.1485s	
8370/26050 (epoch 16.065), train_loss = 0.93594425, grad/param norm = 1.5679e-01, time/batch = 14.3084s	
8371/26050 (epoch 16.067), train_loss = 1.14596132, grad/param norm = 1.8663e-01, time/batch = 17.0522s	
8372/26050 (epoch 16.069), train_loss = 1.17875053, grad/param norm = 1.6711e-01, time/batch = 18.4674s	
8373/26050 (epoch 16.071), train_loss = 1.18479245, grad/param norm = 1.6938e-01, time/batch = 18.3922s	
8374/26050 (epoch 16.073), train_loss = 1.31783121, grad/param norm = 1.8846e-01, time/batch = 17.9922s	
8375/26050 (epoch 16.075), train_loss = 1.03080118, grad/param norm = 1.5818e-01, time/batch = 18.4093s	
8376/26050 (epoch 16.077), train_loss = 1.03387921, grad/param norm = 1.5838e-01, time/batch = 17.3282s	
8377/26050 (epoch 16.079), train_loss = 1.15535729, grad/param norm = 1.7444e-01, time/batch = 17.8168s	
8378/26050 (epoch 16.081), train_loss = 1.08882454, grad/param norm = 1.8935e-01, time/batch = 17.0562s	
8379/26050 (epoch 16.083), train_loss = 1.19103433, grad/param norm = 1.6118e-01, time/batch = 17.7144s	
8380/26050 (epoch 16.084), train_loss = 1.17539647, grad/param norm = 1.9675e-01, time/batch = 17.5687s	
8381/26050 (epoch 16.086), train_loss = 1.26626381, grad/param norm = 1.8664e-01, time/batch = 15.8945s	
8382/26050 (epoch 16.088), train_loss = 1.01316549, grad/param norm = 1.6368e-01, time/batch = 15.8032s	
8383/26050 (epoch 16.090), train_loss = 1.15565824, grad/param norm = 1.8179e-01, time/batch = 16.9852s	
8384/26050 (epoch 16.092), train_loss = 1.16484331, grad/param norm = 1.6848e-01, time/batch = 18.5659s	
8385/26050 (epoch 16.094), train_loss = 1.06563427, grad/param norm = 1.7002e-01, time/batch = 17.7280s	
8386/26050 (epoch 16.096), train_loss = 1.10270584, grad/param norm = 1.6664e-01, time/batch = 17.1374s	
8387/26050 (epoch 16.098), train_loss = 1.08293402, grad/param norm = 1.7931e-01, time/batch = 18.2406s	
8388/26050 (epoch 16.100), train_loss = 1.01046691, grad/param norm = 1.8023e-01, time/batch = 15.4781s	
8389/26050 (epoch 16.102), train_loss = 1.12898955, grad/param norm = 1.7259e-01, time/batch = 19.0750s	
8390/26050 (epoch 16.104), train_loss = 1.13341293, grad/param norm = 1.9217e-01, time/batch = 18.1390s	
8391/26050 (epoch 16.106), train_loss = 1.12918731, grad/param norm = 1.9381e-01, time/batch = 18.1540s	
8392/26050 (epoch 16.107), train_loss = 0.90661589, grad/param norm = 1.4727e-01, time/batch = 18.3933s	
8393/26050 (epoch 16.109), train_loss = 1.04797835, grad/param norm = 1.7317e-01, time/batch = 17.2393s	
8394/26050 (epoch 16.111), train_loss = 1.29413299, grad/param norm = 1.9532e-01, time/batch = 17.0048s	
8395/26050 (epoch 16.113), train_loss = 1.06153532, grad/param norm = 1.6875e-01, time/batch = 17.6656s	
8396/26050 (epoch 16.115), train_loss = 1.21959986, grad/param norm = 1.7539e-01, time/batch = 18.0687s	
8397/26050 (epoch 16.117), train_loss = 1.15212090, grad/param norm = 1.6417e-01, time/batch = 14.4548s	
8398/26050 (epoch 16.119), train_loss = 0.93942741, grad/param norm = 1.6805e-01, time/batch = 17.8788s	
8399/26050 (epoch 16.121), train_loss = 1.15002141, grad/param norm = 1.6805e-01, time/batch = 17.8195s	
8400/26050 (epoch 16.123), train_loss = 1.01311487, grad/param norm = 1.7022e-01, time/batch = 16.7353s	
8401/26050 (epoch 16.125), train_loss = 0.97976875, grad/param norm = 1.6926e-01, time/batch = 18.1266s	
8402/26050 (epoch 16.127), train_loss = 0.89045416, grad/param norm = 1.5156e-01, time/batch = 17.7399s	
8403/26050 (epoch 16.129), train_loss = 0.95131960, grad/param norm = 1.6850e-01, time/batch = 17.5821s	
8404/26050 (epoch 16.131), train_loss = 1.08495832, grad/param norm = 1.7047e-01, time/batch = 17.9050s	
8405/26050 (epoch 16.132), train_loss = 1.08908270, grad/param norm = 1.6859e-01, time/batch = 17.9974s	
8406/26050 (epoch 16.134), train_loss = 1.09340845, grad/param norm = 1.8551e-01, time/batch = 14.3985s	
8407/26050 (epoch 16.136), train_loss = 1.10888653, grad/param norm = 1.6130e-01, time/batch = 14.5521s	
8408/26050 (epoch 16.138), train_loss = 0.90264004, grad/param norm = 1.7046e-01, time/batch = 18.9019s	
8409/26050 (epoch 16.140), train_loss = 0.94499345, grad/param norm = 1.6366e-01, time/batch = 17.5669s	
8410/26050 (epoch 16.142), train_loss = 0.99952849, grad/param norm = 1.6497e-01, time/batch = 18.2237s	
8411/26050 (epoch 16.144), train_loss = 0.91703892, grad/param norm = 1.6590e-01, time/batch = 17.6559s	
8412/26050 (epoch 16.146), train_loss = 0.84928785, grad/param norm = 1.6132e-01, time/batch = 17.9977s	
8413/26050 (epoch 16.148), train_loss = 0.88627380, grad/param norm = 1.3913e-01, time/batch = 18.3174s	
8414/26050 (epoch 16.150), train_loss = 1.08329172, grad/param norm = 1.7049e-01, time/batch = 15.2283s	
8415/26050 (epoch 16.152), train_loss = 1.28976705, grad/param norm = 2.0793e-01, time/batch = 17.3210s	
8416/26050 (epoch 16.154), train_loss = 0.87842927, grad/param norm = 1.5859e-01, time/batch = 17.9917s	
8417/26050 (epoch 16.155), train_loss = 0.92111756, grad/param norm = 1.5945e-01, time/batch = 19.7686s	
8418/26050 (epoch 16.157), train_loss = 1.03767643, grad/param norm = 2.0831e-01, time/batch = 36.0806s	
8419/26050 (epoch 16.159), train_loss = 1.08934709, grad/param norm = 1.9590e-01, time/batch = 17.8987s	
8420/26050 (epoch 16.161), train_loss = 1.17766593, grad/param norm = 1.9386e-01, time/batch = 15.1980s	
8421/26050 (epoch 16.163), train_loss = 0.92415417, grad/param norm = 1.6484e-01, time/batch = 18.2406s	
8422/26050 (epoch 16.165), train_loss = 0.83603095, grad/param norm = 1.4933e-01, time/batch = 18.9806s	
8423/26050 (epoch 16.167), train_loss = 1.20313093, grad/param norm = 1.9010e-01, time/batch = 16.4615s	
8424/26050 (epoch 16.169), train_loss = 1.15624659, grad/param norm = 1.8748e-01, time/batch = 16.3676s	
8425/26050 (epoch 16.171), train_loss = 0.89883366, grad/param norm = 1.4630e-01, time/batch = 17.3290s	
8426/26050 (epoch 16.173), train_loss = 1.02117307, grad/param norm = 1.7316e-01, time/batch = 18.3122s	
8427/26050 (epoch 16.175), train_loss = 1.07965806, grad/param norm = 1.6357e-01, time/batch = 17.2306s	
8428/26050 (epoch 16.177), train_loss = 1.21757708, grad/param norm = 1.7644e-01, time/batch = 14.8718s	
8429/26050 (epoch 16.179), train_loss = 0.86552731, grad/param norm = 1.5327e-01, time/batch = 18.7362s	
8430/26050 (epoch 16.180), train_loss = 1.31496460, grad/param norm = 1.7813e-01, time/batch = 17.3077s	
8431/26050 (epoch 16.182), train_loss = 1.33279785, grad/param norm = 1.9838e-01, time/batch = 16.9928s	
8432/26050 (epoch 16.184), train_loss = 1.11596978, grad/param norm = 1.6376e-01, time/batch = 18.1565s	
8433/26050 (epoch 16.186), train_loss = 0.90362323, grad/param norm = 1.4944e-01, time/batch = 18.0525s	
8434/26050 (epoch 16.188), train_loss = 1.08243806, grad/param norm = 1.6493e-01, time/batch = 18.3196s	
8435/26050 (epoch 16.190), train_loss = 1.15017171, grad/param norm = 1.8058e-01, time/batch = 17.3989s	
8436/26050 (epoch 16.192), train_loss = 1.15410610, grad/param norm = 1.6610e-01, time/batch = 14.9900s	
8437/26050 (epoch 16.194), train_loss = 1.13169564, grad/param norm = 1.6950e-01, time/batch = 18.2353s	
8438/26050 (epoch 16.196), train_loss = 1.19865206, grad/param norm = 1.7689e-01, time/batch = 17.9920s	
8439/26050 (epoch 16.198), train_loss = 1.01955218, grad/param norm = 1.6063e-01, time/batch = 18.5710s	
8440/26050 (epoch 16.200), train_loss = 1.00465614, grad/param norm = 1.6582e-01, time/batch = 17.0509s	
8441/26050 (epoch 16.202), train_loss = 1.07178220, grad/param norm = 1.7647e-01, time/batch = 15.8010s	
8442/26050 (epoch 16.203), train_loss = 1.21102120, grad/param norm = 1.8892e-01, time/batch = 17.5695s	
8443/26050 (epoch 16.205), train_loss = 1.03504851, grad/param norm = 1.6852e-01, time/batch = 18.3155s	
8444/26050 (epoch 16.207), train_loss = 1.03989581, grad/param norm = 1.6753e-01, time/batch = 18.0685s	
8445/26050 (epoch 16.209), train_loss = 1.11851339, grad/param norm = 1.6408e-01, time/batch = 15.5224s	
8446/26050 (epoch 16.211), train_loss = 0.93640580, grad/param norm = 1.5693e-01, time/batch = 17.9042s	
8447/26050 (epoch 16.213), train_loss = 1.15429406, grad/param norm = 1.7929e-01, time/batch = 17.0702s	
8448/26050 (epoch 16.215), train_loss = 1.09331244, grad/param norm = 1.8688e-01, time/batch = 17.7356s	
8449/26050 (epoch 16.217), train_loss = 1.08881722, grad/param norm = 1.6435e-01, time/batch = 17.9900s	
8450/26050 (epoch 16.219), train_loss = 1.07193858, grad/param norm = 1.8754e-01, time/batch = 17.8994s	
8451/26050 (epoch 16.221), train_loss = 0.98775954, grad/param norm = 1.7316e-01, time/batch = 18.8068s	
8452/26050 (epoch 16.223), train_loss = 1.11871388, grad/param norm = 1.6856e-01, time/batch = 18.0743s	
8453/26050 (epoch 16.225), train_loss = 0.99314702, grad/param norm = 1.6439e-01, time/batch = 18.0683s	
8454/26050 (epoch 16.226), train_loss = 1.16936349, grad/param norm = 1.8594e-01, time/batch = 18.4753s	
8455/26050 (epoch 16.228), train_loss = 1.23129265, grad/param norm = 1.7618e-01, time/batch = 15.0557s	
8456/26050 (epoch 16.230), train_loss = 1.13313932, grad/param norm = 1.6811e-01, time/batch = 16.7159s	
8457/26050 (epoch 16.232), train_loss = 1.22239009, grad/param norm = 1.8988e-01, time/batch = 14.6442s	
8458/26050 (epoch 16.234), train_loss = 0.96415566, grad/param norm = 1.7035e-01, time/batch = 18.3170s	
8459/26050 (epoch 16.236), train_loss = 1.18874816, grad/param norm = 1.8212e-01, time/batch = 17.8966s	
8460/26050 (epoch 16.238), train_loss = 0.94635917, grad/param norm = 1.5683e-01, time/batch = 17.5543s	
8461/26050 (epoch 16.240), train_loss = 1.09251453, grad/param norm = 1.7132e-01, time/batch = 17.4790s	
8462/26050 (epoch 16.242), train_loss = 1.09981876, grad/param norm = 1.6169e-01, time/batch = 18.3238s	
8463/26050 (epoch 16.244), train_loss = 1.09611862, grad/param norm = 2.0099e-01, time/batch = 18.3950s	
8464/26050 (epoch 16.246), train_loss = 1.03317379, grad/param norm = 1.5670e-01, time/batch = 17.9044s	
8465/26050 (epoch 16.248), train_loss = 1.10373625, grad/param norm = 1.7046e-01, time/batch = 17.3168s	
8466/26050 (epoch 16.250), train_loss = 1.10857728, grad/param norm = 1.9770e-01, time/batch = 18.2423s	
8467/26050 (epoch 16.251), train_loss = 1.06187555, grad/param norm = 1.7323e-01, time/batch = 17.8810s	
8468/26050 (epoch 16.253), train_loss = 0.96484918, grad/param norm = 1.6034e-01, time/batch = 14.8117s	
8469/26050 (epoch 16.255), train_loss = 1.28475110, grad/param norm = 1.7370e-01, time/batch = 17.6548s	
8470/26050 (epoch 16.257), train_loss = 1.10011152, grad/param norm = 1.8194e-01, time/batch = 18.9008s	
8471/26050 (epoch 16.259), train_loss = 1.24817890, grad/param norm = 1.8263e-01, time/batch = 17.4074s	
8472/26050 (epoch 16.261), train_loss = 0.98716885, grad/param norm = 1.7817e-01, time/batch = 18.3221s	
8473/26050 (epoch 16.263), train_loss = 1.14019426, grad/param norm = 1.7312e-01, time/batch = 17.8309s	
8474/26050 (epoch 16.265), train_loss = 1.26232087, grad/param norm = 1.8772e-01, time/batch = 17.4790s	
8475/26050 (epoch 16.267), train_loss = 1.19922937, grad/param norm = 1.6800e-01, time/batch = 17.9832s	
8476/26050 (epoch 16.269), train_loss = 1.28304969, grad/param norm = 1.9704e-01, time/batch = 15.9438s	
8477/26050 (epoch 16.271), train_loss = 1.15905484, grad/param norm = 1.8349e-01, time/batch = 18.2313s	
8478/26050 (epoch 16.273), train_loss = 1.05416658, grad/param norm = 1.8557e-01, time/batch = 18.2330s	
8479/26050 (epoch 16.274), train_loss = 1.06433074, grad/param norm = 1.6930e-01, time/batch = 18.1392s	
8480/26050 (epoch 16.276), train_loss = 1.03266542, grad/param norm = 1.7181e-01, time/batch = 18.1429s	
8481/26050 (epoch 16.278), train_loss = 1.23270695, grad/param norm = 1.7705e-01, time/batch = 17.8077s	
8482/26050 (epoch 16.280), train_loss = 1.08687852, grad/param norm = 1.6271e-01, time/batch = 17.4064s	
8483/26050 (epoch 16.282), train_loss = 1.12854774, grad/param norm = 1.7021e-01, time/batch = 14.9834s	
8484/26050 (epoch 16.284), train_loss = 1.04142976, grad/param norm = 1.7245e-01, time/batch = 18.1412s	
8485/26050 (epoch 16.286), train_loss = 1.12336266, grad/param norm = 1.7248e-01, time/batch = 17.2330s	
8486/26050 (epoch 16.288), train_loss = 0.95414389, grad/param norm = 1.5366e-01, time/batch = 17.9017s	
8487/26050 (epoch 16.290), train_loss = 1.09121326, grad/param norm = 1.8096e-01, time/batch = 17.5672s	
8488/26050 (epoch 16.292), train_loss = 1.01066793, grad/param norm = 1.5996e-01, time/batch = 17.8979s	
8489/26050 (epoch 16.294), train_loss = 1.13834067, grad/param norm = 1.9375e-01, time/batch = 17.8242s	
8490/26050 (epoch 16.296), train_loss = 1.21909578, grad/param norm = 1.8457e-01, time/batch = 14.5590s	
8491/26050 (epoch 16.298), train_loss = 1.10090271, grad/param norm = 1.6804e-01, time/batch = 15.3797s	
8492/26050 (epoch 16.299), train_loss = 0.87585180, grad/param norm = 1.5001e-01, time/batch = 17.4874s	
8493/26050 (epoch 16.301), train_loss = 0.99646827, grad/param norm = 1.8139e-01, time/batch = 17.3013s	
8494/26050 (epoch 16.303), train_loss = 1.12250753, grad/param norm = 1.7977e-01, time/batch = 18.9144s	
8495/26050 (epoch 16.305), train_loss = 0.93064977, grad/param norm = 1.7290e-01, time/batch = 18.3081s	
8496/26050 (epoch 16.307), train_loss = 1.02458996, grad/param norm = 1.7509e-01, time/batch = 16.5591s	
8497/26050 (epoch 16.309), train_loss = 1.07776347, grad/param norm = 1.8049e-01, time/batch = 18.0449s	
8498/26050 (epoch 16.311), train_loss = 1.20907519, grad/param norm = 2.1634e-01, time/batch = 17.3134s	
8499/26050 (epoch 16.313), train_loss = 1.08331047, grad/param norm = 1.8882e-01, time/batch = 18.7129s	
8500/26050 (epoch 16.315), train_loss = 1.18655069, grad/param norm = 1.7500e-01, time/batch = 18.9757s	
8501/26050 (epoch 16.317), train_loss = 1.07999041, grad/param norm = 1.6763e-01, time/batch = 17.8833s	
8502/26050 (epoch 16.319), train_loss = 1.04883339, grad/param norm = 1.7007e-01, time/batch = 17.8910s	
8503/26050 (epoch 16.321), train_loss = 1.06885556, grad/param norm = 1.7980e-01, time/batch = 15.3903s	
8504/26050 (epoch 16.322), train_loss = 1.12425109, grad/param norm = 1.7310e-01, time/batch = 18.6482s	
8505/26050 (epoch 16.324), train_loss = 0.92646809, grad/param norm = 1.8064e-01, time/batch = 17.8928s	
8506/26050 (epoch 16.326), train_loss = 1.25320746, grad/param norm = 1.8036e-01, time/batch = 18.5697s	
8507/26050 (epoch 16.328), train_loss = 1.14187522, grad/param norm = 1.6035e-01, time/batch = 18.3909s	
8508/26050 (epoch 16.330), train_loss = 0.98899256, grad/param norm = 1.7031e-01, time/batch = 17.1174s	
8509/26050 (epoch 16.332), train_loss = 1.15800759, grad/param norm = 1.7031e-01, time/batch = 14.7154s	
8510/26050 (epoch 16.334), train_loss = 1.06527058, grad/param norm = 1.8404e-01, time/batch = 15.9621s	
8511/26050 (epoch 16.336), train_loss = 1.03555213, grad/param norm = 1.7133e-01, time/batch = 18.8158s	
8512/26050 (epoch 16.338), train_loss = 0.96850864, grad/param norm = 1.5366e-01, time/batch = 18.5603s	
8513/26050 (epoch 16.340), train_loss = 1.21572122, grad/param norm = 1.9919e-01, time/batch = 18.5575s	
8514/26050 (epoch 16.342), train_loss = 1.23647126, grad/param norm = 1.8454e-01, time/batch = 17.8103s	
8515/26050 (epoch 16.344), train_loss = 1.07162693, grad/param norm = 1.7728e-01, time/batch = 16.6408s	
8516/26050 (epoch 16.345), train_loss = 1.06291208, grad/param norm = 1.6553e-01, time/batch = 17.2879s	
8517/26050 (epoch 16.347), train_loss = 1.20507841, grad/param norm = 1.8215e-01, time/batch = 18.4741s	
8518/26050 (epoch 16.349), train_loss = 1.15044097, grad/param norm = 1.7734e-01, time/batch = 17.6490s	
8519/26050 (epoch 16.351), train_loss = 1.11031343, grad/param norm = 1.7357e-01, time/batch = 17.2218s	
8520/26050 (epoch 16.353), train_loss = 1.09136312, grad/param norm = 1.7948e-01, time/batch = 18.1342s	
8521/26050 (epoch 16.355), train_loss = 1.16282967, grad/param norm = 1.9166e-01, time/batch = 18.6460s	
8522/26050 (epoch 16.357), train_loss = 1.01890985, grad/param norm = 1.6172e-01, time/batch = 17.8886s	
8523/26050 (epoch 16.359), train_loss = 1.17137697, grad/param norm = 1.6607e-01, time/batch = 18.8952s	
8524/26050 (epoch 16.361), train_loss = 1.03781673, grad/param norm = 1.7065e-01, time/batch = 18.4049s	
8525/26050 (epoch 16.363), train_loss = 1.15736816, grad/param norm = 1.6270e-01, time/batch = 17.2303s	
8526/26050 (epoch 16.365), train_loss = 1.07689200, grad/param norm = 1.4859e-01, time/batch = 18.6532s	
8527/26050 (epoch 16.367), train_loss = 1.13199275, grad/param norm = 1.7148e-01, time/batch = 14.6426s	
8528/26050 (epoch 16.369), train_loss = 1.07387606, grad/param norm = 1.6264e-01, time/batch = 17.9053s	
8529/26050 (epoch 16.370), train_loss = 0.99133931, grad/param norm = 1.5449e-01, time/batch = 18.2448s	
8530/26050 (epoch 16.372), train_loss = 1.16980431, grad/param norm = 1.8432e-01, time/batch = 17.8305s	
8531/26050 (epoch 16.374), train_loss = 1.26050738, grad/param norm = 1.8891e-01, time/batch = 17.6482s	
8532/26050 (epoch 16.376), train_loss = 1.31341762, grad/param norm = 1.8388e-01, time/batch = 18.0650s	
8533/26050 (epoch 16.378), train_loss = 1.09572252, grad/param norm = 1.7784e-01, time/batch = 16.4751s	
8534/26050 (epoch 16.380), train_loss = 1.30264783, grad/param norm = 2.0260e-01, time/batch = 14.5568s	
8535/26050 (epoch 16.382), train_loss = 1.41796934, grad/param norm = 2.2458e-01, time/batch = 17.5393s	
8536/26050 (epoch 16.384), train_loss = 1.09525758, grad/param norm = 1.6781e-01, time/batch = 17.3865s	
8537/26050 (epoch 16.386), train_loss = 1.20590843, grad/param norm = 1.9489e-01, time/batch = 17.6382s	
8538/26050 (epoch 16.388), train_loss = 1.12568034, grad/param norm = 1.7690e-01, time/batch = 15.1932s	
8539/26050 (epoch 16.390), train_loss = 1.03156591, grad/param norm = 1.7492e-01, time/batch = 17.2322s	
8540/26050 (epoch 16.392), train_loss = 0.98927951, grad/param norm = 1.5782e-01, time/batch = 18.7260s	
8541/26050 (epoch 16.393), train_loss = 1.14941471, grad/param norm = 1.7537e-01, time/batch = 18.2429s	
8542/26050 (epoch 16.395), train_loss = 1.16752809, grad/param norm = 1.7587e-01, time/batch = 17.8133s	
8543/26050 (epoch 16.397), train_loss = 1.15399081, grad/param norm = 1.9336e-01, time/batch = 18.3931s	
8544/26050 (epoch 16.399), train_loss = 1.02683019, grad/param norm = 1.6495e-01, time/batch = 17.6607s	
8545/26050 (epoch 16.401), train_loss = 1.09737279, grad/param norm = 1.6688e-01, time/batch = 18.3176s	
8546/26050 (epoch 16.403), train_loss = 1.14285604, grad/param norm = 1.6863e-01, time/batch = 15.9013s	
8547/26050 (epoch 16.405), train_loss = 1.10351094, grad/param norm = 1.7524e-01, time/batch = 18.4753s	
8548/26050 (epoch 16.407), train_loss = 1.25316381, grad/param norm = 1.8372e-01, time/batch = 17.7332s	
8549/26050 (epoch 16.409), train_loss = 1.29747386, grad/param norm = 1.8764e-01, time/batch = 17.8213s	
8550/26050 (epoch 16.411), train_loss = 1.16729988, grad/param norm = 2.0732e-01, time/batch = 17.7368s	
8551/26050 (epoch 16.413), train_loss = 1.25794523, grad/param norm = 1.6613e-01, time/batch = 18.2438s	
8552/26050 (epoch 16.415), train_loss = 1.25805499, grad/param norm = 2.1945e-01, time/batch = 17.3181s	
8553/26050 (epoch 16.417), train_loss = 1.34514346, grad/param norm = 2.0095e-01, time/batch = 17.7331s	
8554/26050 (epoch 16.418), train_loss = 1.23021450, grad/param norm = 2.0034e-01, time/batch = 15.4837s	
8555/26050 (epoch 16.420), train_loss = 0.93813915, grad/param norm = 1.5659e-01, time/batch = 16.0775s	
8556/26050 (epoch 16.422), train_loss = 0.96518478, grad/param norm = 1.6144e-01, time/batch = 16.8012s	
8557/26050 (epoch 16.424), train_loss = 1.28092716, grad/param norm = 2.0941e-01, time/batch = 18.3206s	
8558/26050 (epoch 16.426), train_loss = 1.23909852, grad/param norm = 1.8694e-01, time/batch = 18.8858s	
8559/26050 (epoch 16.428), train_loss = 1.03357941, grad/param norm = 1.5317e-01, time/batch = 17.3873s	
8560/26050 (epoch 16.430), train_loss = 1.19937944, grad/param norm = 1.7761e-01, time/batch = 18.8991s	
8561/26050 (epoch 16.432), train_loss = 1.07736098, grad/param norm = 1.7348e-01, time/batch = 16.7387s	
8562/26050 (epoch 16.434), train_loss = 1.10336285, grad/param norm = 1.9754e-01, time/batch = 17.3725s	
8563/26050 (epoch 16.436), train_loss = 1.23987295, grad/param norm = 1.7601e-01, time/batch = 17.1257s	
8564/26050 (epoch 16.438), train_loss = 1.09454595, grad/param norm = 1.8133e-01, time/batch = 18.4053s	
8565/26050 (epoch 16.440), train_loss = 1.14008503, grad/param norm = 1.7093e-01, time/batch = 18.6540s	
8566/26050 (epoch 16.441), train_loss = 1.12415002, grad/param norm = 1.7000e-01, time/batch = 17.5697s	
8567/26050 (epoch 16.443), train_loss = 0.93322759, grad/param norm = 1.4939e-01, time/batch = 17.8951s	
8568/26050 (epoch 16.445), train_loss = 1.01101595, grad/param norm = 1.6441e-01, time/batch = 18.9924s	
8569/26050 (epoch 16.447), train_loss = 1.26908591, grad/param norm = 1.9802e-01, time/batch = 16.7228s	
8570/26050 (epoch 16.449), train_loss = 1.01967574, grad/param norm = 1.6674e-01, time/batch = 17.1542s	
8571/26050 (epoch 16.451), train_loss = 1.27374263, grad/param norm = 1.8617e-01, time/batch = 15.2172s	
8572/26050 (epoch 16.453), train_loss = 1.03795407, grad/param norm = 1.6272e-01, time/batch = 15.4805s	
8573/26050 (epoch 16.455), train_loss = 1.15503626, grad/param norm = 1.6918e-01, time/batch = 16.4892s	
8574/26050 (epoch 16.457), train_loss = 1.13302942, grad/param norm = 1.7169e-01, time/batch = 17.7319s	
8575/26050 (epoch 16.459), train_loss = 1.23035812, grad/param norm = 1.8574e-01, time/batch = 18.2248s	
8576/26050 (epoch 16.461), train_loss = 1.19885616, grad/param norm = 2.0862e-01, time/batch = 17.3994s	
8577/26050 (epoch 16.463), train_loss = 1.06462275, grad/param norm = 1.6364e-01, time/batch = 15.7952s	
8578/26050 (epoch 16.464), train_loss = 1.16480297, grad/param norm = 1.6941e-01, time/batch = 18.2328s	
8579/26050 (epoch 16.466), train_loss = 1.21342572, grad/param norm = 1.9590e-01, time/batch = 18.8113s	
8580/26050 (epoch 16.468), train_loss = 1.20789879, grad/param norm = 1.5661e-01, time/batch = 14.7096s	
8581/26050 (epoch 16.470), train_loss = 1.32013177, grad/param norm = 2.0531e-01, time/batch = 17.6426s	
8582/26050 (epoch 16.472), train_loss = 1.26298922, grad/param norm = 2.0321e-01, time/batch = 16.3122s	
8583/26050 (epoch 16.474), train_loss = 1.32331245, grad/param norm = 1.7169e-01, time/batch = 17.1527s	
8584/26050 (epoch 16.476), train_loss = 1.25820997, grad/param norm = 1.8776e-01, time/batch = 17.1710s	
8585/26050 (epoch 16.478), train_loss = 1.07904104, grad/param norm = 1.6959e-01, time/batch = 15.4780s	
8586/26050 (epoch 16.480), train_loss = 1.16026876, grad/param norm = 1.8314e-01, time/batch = 18.2613s	
8587/26050 (epoch 16.482), train_loss = 1.08246869, grad/param norm = 1.8234e-01, time/batch = 17.3977s	
8588/26050 (epoch 16.484), train_loss = 1.07397263, grad/param norm = 1.7077e-01, time/batch = 18.2157s	
8589/26050 (epoch 16.486), train_loss = 1.29080339, grad/param norm = 1.8271e-01, time/batch = 16.7955s	
8590/26050 (epoch 16.488), train_loss = 1.41613864, grad/param norm = 1.9412e-01, time/batch = 18.2313s	
8591/26050 (epoch 16.489), train_loss = 1.34625305, grad/param norm = 1.9792e-01, time/batch = 18.8022s	
8592/26050 (epoch 16.491), train_loss = 1.03071369, grad/param norm = 1.6976e-01, time/batch = 17.9750s	
8593/26050 (epoch 16.493), train_loss = 1.13611584, grad/param norm = 1.7443e-01, time/batch = 17.9867s	
8594/26050 (epoch 16.495), train_loss = 1.11148702, grad/param norm = 1.6597e-01, time/batch = 16.5509s	
8595/26050 (epoch 16.497), train_loss = 1.03771643, grad/param norm = 1.6828e-01, time/batch = 16.4750s	
8596/26050 (epoch 16.499), train_loss = 1.07960538, grad/param norm = 1.6817e-01, time/batch = 15.2244s	
8597/26050 (epoch 16.501), train_loss = 1.19237242, grad/param norm = 1.7882e-01, time/batch = 16.0490s	
8598/26050 (epoch 16.503), train_loss = 1.06746388, grad/param norm = 1.7558e-01, time/batch = 18.0631s	
8599/26050 (epoch 16.505), train_loss = 1.25410634, grad/param norm = 1.7132e-01, time/batch = 18.1523s	
8600/26050 (epoch 16.507), train_loss = 1.21851691, grad/param norm = 1.8778e-01, time/batch = 18.4973s	
8601/26050 (epoch 16.509), train_loss = 1.32954164, grad/param norm = 1.8333e-01, time/batch = 18.4635s	
8602/26050 (epoch 16.511), train_loss = 1.03193971, grad/param norm = 1.5500e-01, time/batch = 17.9062s	
8603/26050 (epoch 16.512), train_loss = 1.08547816, grad/param norm = 1.8557e-01, time/batch = 16.4771s	
8604/26050 (epoch 16.514), train_loss = 1.20805087, grad/param norm = 1.8304e-01, time/batch = 16.5225s	
8605/26050 (epoch 16.516), train_loss = 1.23895203, grad/param norm = 1.8585e-01, time/batch = 18.8183s	
8606/26050 (epoch 16.518), train_loss = 1.15976089, grad/param norm = 1.7947e-01, time/batch = 17.9189s	
8607/26050 (epoch 16.520), train_loss = 1.11007254, grad/param norm = 1.6728e-01, time/batch = 17.1494s	
8608/26050 (epoch 16.522), train_loss = 0.91926512, grad/param norm = 1.6030e-01, time/batch = 16.8115s	
8609/26050 (epoch 16.524), train_loss = 1.23629484, grad/param norm = 1.9832e-01, time/batch = 18.8331s	
8610/26050 (epoch 16.526), train_loss = 1.23479869, grad/param norm = 1.8916e-01, time/batch = 17.9808s	
8611/26050 (epoch 16.528), train_loss = 1.17476939, grad/param norm = 1.8171e-01, time/batch = 18.2285s	
8612/26050 (epoch 16.530), train_loss = 1.12769545, grad/param norm = 1.8125e-01, time/batch = 18.0641s	
8613/26050 (epoch 16.532), train_loss = 1.12200628, grad/param norm = 1.6500e-01, time/batch = 15.2176s	
8614/26050 (epoch 16.534), train_loss = 1.18569706, grad/param norm = 1.9737e-01, time/batch = 17.3163s	
8615/26050 (epoch 16.536), train_loss = 1.12254463, grad/param norm = 1.6234e-01, time/batch = 18.4817s	
8616/26050 (epoch 16.537), train_loss = 1.24693437, grad/param norm = 1.8497e-01, time/batch = 18.4042s	
8617/26050 (epoch 16.539), train_loss = 1.13195397, grad/param norm = 1.8376e-01, time/batch = 15.7343s	
8618/26050 (epoch 16.541), train_loss = 1.34304957, grad/param norm = 2.1358e-01, time/batch = 17.9013s	
8619/26050 (epoch 16.543), train_loss = 0.95788929, grad/param norm = 1.7799e-01, time/batch = 16.1458s	
8620/26050 (epoch 16.545), train_loss = 1.18583196, grad/param norm = 1.7391e-01, time/batch = 16.3954s	
8621/26050 (epoch 16.547), train_loss = 1.13030033, grad/param norm = 1.7429e-01, time/batch = 22.0667s	
8622/26050 (epoch 16.549), train_loss = 0.93391853, grad/param norm = 1.6528e-01, time/batch = 29.6013s	
8623/26050 (epoch 16.551), train_loss = 1.17433617, grad/param norm = 1.7555e-01, time/batch = 20.5412s	
8624/26050 (epoch 16.553), train_loss = 1.05489963, grad/param norm = 1.6887e-01, time/batch = 18.8964s	
8625/26050 (epoch 16.555), train_loss = 1.06802015, grad/param norm = 1.7570e-01, time/batch = 17.8990s	
8626/26050 (epoch 16.557), train_loss = 1.18397207, grad/param norm = 1.6560e-01, time/batch = 17.2171s	
8627/26050 (epoch 16.559), train_loss = 1.12240542, grad/param norm = 1.6362e-01, time/batch = 17.3165s	
8628/26050 (epoch 16.560), train_loss = 1.09707419, grad/param norm = 1.7212e-01, time/batch = 14.8148s	
8629/26050 (epoch 16.562), train_loss = 1.11094198, grad/param norm = 1.7473e-01, time/batch = 18.4652s	
8630/26050 (epoch 16.564), train_loss = 1.31534966, grad/param norm = 1.7429e-01, time/batch = 18.0668s	
8631/26050 (epoch 16.566), train_loss = 1.03390954, grad/param norm = 1.7262e-01, time/batch = 16.3803s	
8632/26050 (epoch 16.568), train_loss = 1.15478811, grad/param norm = 1.6676e-01, time/batch = 16.6504s	
8633/26050 (epoch 16.570), train_loss = 1.23440650, grad/param norm = 1.8224e-01, time/batch = 18.6548s	
8634/26050 (epoch 16.572), train_loss = 1.10210624, grad/param norm = 1.8188e-01, time/batch = 18.3859s	
8635/26050 (epoch 16.574), train_loss = 1.20019134, grad/param norm = 2.0360e-01, time/batch = 16.9788s	
8636/26050 (epoch 16.576), train_loss = 1.16194712, grad/param norm = 1.7955e-01, time/batch = 18.2443s	
8637/26050 (epoch 16.578), train_loss = 1.10031511, grad/param norm = 1.7155e-01, time/batch = 13.4732s	
8638/26050 (epoch 16.580), train_loss = 1.04085110, grad/param norm = 1.7580e-01, time/batch = 0.6489s	
8639/26050 (epoch 16.582), train_loss = 1.16980203, grad/param norm = 1.6729e-01, time/batch = 0.6520s	
8640/26050 (epoch 16.583), train_loss = 1.23280382, grad/param norm = 1.7153e-01, time/batch = 0.6411s	
8641/26050 (epoch 16.585), train_loss = 1.01120089, grad/param norm = 1.7297e-01, time/batch = 0.6398s	
8642/26050 (epoch 16.587), train_loss = 1.16143231, grad/param norm = 1.8246e-01, time/batch = 0.6648s	
8643/26050 (epoch 16.589), train_loss = 1.28219524, grad/param norm = 2.0418e-01, time/batch = 0.6563s	
8644/26050 (epoch 16.591), train_loss = 1.11805814, grad/param norm = 1.7144e-01, time/batch = 0.6514s	
8645/26050 (epoch 16.593), train_loss = 1.01186020, grad/param norm = 1.7063e-01, time/batch = 0.8110s	
8646/26050 (epoch 16.595), train_loss = 1.22676428, grad/param norm = 2.0633e-01, time/batch = 0.9427s	
8647/26050 (epoch 16.597), train_loss = 1.15938131, grad/param norm = 1.6580e-01, time/batch = 0.9412s	
8648/26050 (epoch 16.599), train_loss = 1.10959877, grad/param norm = 1.7725e-01, time/batch = 0.9422s	
8649/26050 (epoch 16.601), train_loss = 1.31487008, grad/param norm = 1.7757e-01, time/batch = 0.9442s	
8650/26050 (epoch 16.603), train_loss = 1.17505750, grad/param norm = 1.7322e-01, time/batch = 1.1556s	
8651/26050 (epoch 16.605), train_loss = 1.06863949, grad/param norm = 1.6459e-01, time/batch = 1.7657s	
8652/26050 (epoch 16.607), train_loss = 1.25103499, grad/param norm = 1.9349e-01, time/batch = 1.8185s	
8653/26050 (epoch 16.608), train_loss = 0.99435306, grad/param norm = 1.4966e-01, time/batch = 10.6269s	
8654/26050 (epoch 16.610), train_loss = 1.11329442, grad/param norm = 1.8912e-01, time/batch = 17.6433s	
8655/26050 (epoch 16.612), train_loss = 1.14441990, grad/param norm = 1.8745e-01, time/batch = 17.0768s	
8656/26050 (epoch 16.614), train_loss = 1.19893226, grad/param norm = 1.8206e-01, time/batch = 16.1235s	
8657/26050 (epoch 16.616), train_loss = 1.30415746, grad/param norm = 1.9111e-01, time/batch = 16.8907s	
8658/26050 (epoch 16.618), train_loss = 1.08403151, grad/param norm = 1.9295e-01, time/batch = 15.8067s	
8659/26050 (epoch 16.620), train_loss = 1.16145991, grad/param norm = 1.8247e-01, time/batch = 17.3279s	
8660/26050 (epoch 16.622), train_loss = 0.99900475, grad/param norm = 1.6482e-01, time/batch = 18.3159s	
8661/26050 (epoch 16.624), train_loss = 1.00095097, grad/param norm = 1.6307e-01, time/batch = 18.0752s	
8662/26050 (epoch 16.626), train_loss = 1.17905994, grad/param norm = 1.7192e-01, time/batch = 17.2291s	
8663/26050 (epoch 16.628), train_loss = 1.06919701, grad/param norm = 1.8436e-01, time/batch = 18.5696s	
8664/26050 (epoch 16.630), train_loss = 1.24100089, grad/param norm = 1.6895e-01, time/batch = 18.3993s	
8665/26050 (epoch 16.631), train_loss = 1.28609818, grad/param norm = 1.8000e-01, time/batch = 15.7212s	
8666/26050 (epoch 16.633), train_loss = 1.04540903, grad/param norm = 1.7020e-01, time/batch = 17.8247s	
8667/26050 (epoch 16.635), train_loss = 1.04750762, grad/param norm = 1.5176e-01, time/batch = 18.1427s	
8668/26050 (epoch 16.637), train_loss = 1.01943891, grad/param norm = 1.7315e-01, time/batch = 17.8997s	
8669/26050 (epoch 16.639), train_loss = 1.23530004, grad/param norm = 1.8058e-01, time/batch = 15.3849s	
8670/26050 (epoch 16.641), train_loss = 1.09188574, grad/param norm = 1.6195e-01, time/batch = 17.5586s	
8671/26050 (epoch 16.643), train_loss = 0.98902013, grad/param norm = 1.5025e-01, time/batch = 18.3886s	
8672/26050 (epoch 16.645), train_loss = 1.15165021, grad/param norm = 1.7761e-01, time/batch = 17.8277s	
8673/26050 (epoch 16.647), train_loss = 1.07580394, grad/param norm = 1.7041e-01, time/batch = 17.9902s	
8674/26050 (epoch 16.649), train_loss = 1.15338698, grad/param norm = 2.2515e-01, time/batch = 15.5697s	
8675/26050 (epoch 16.651), train_loss = 1.04614847, grad/param norm = 1.8112e-01, time/batch = 18.4894s	
8676/26050 (epoch 16.653), train_loss = 1.14841055, grad/param norm = 1.7337e-01, time/batch = 16.6242s	
8677/26050 (epoch 16.655), train_loss = 1.05170381, grad/param norm = 1.6293e-01, time/batch = 18.1394s	
8678/26050 (epoch 16.656), train_loss = 0.96539464, grad/param norm = 1.6828e-01, time/batch = 18.0674s	
8679/26050 (epoch 16.658), train_loss = 1.31001443, grad/param norm = 1.9109e-01, time/batch = 16.6167s	
8680/26050 (epoch 16.660), train_loss = 0.99863173, grad/param norm = 1.6522e-01, time/batch = 18.1369s	
8681/26050 (epoch 16.662), train_loss = 1.01905573, grad/param norm = 1.6115e-01, time/batch = 18.2988s	
8682/26050 (epoch 16.664), train_loss = 1.10947008, grad/param norm = 1.7988e-01, time/batch = 18.2417s	
8683/26050 (epoch 16.666), train_loss = 1.11655226, grad/param norm = 1.9898e-01, time/batch = 18.0698s	
8684/26050 (epoch 16.668), train_loss = 0.94508323, grad/param norm = 1.8030e-01, time/batch = 17.0582s	
8685/26050 (epoch 16.670), train_loss = 1.28672100, grad/param norm = 1.9820e-01, time/batch = 18.4792s	
8686/26050 (epoch 16.672), train_loss = 1.08356867, grad/param norm = 1.7748e-01, time/batch = 16.5709s	
8687/26050 (epoch 16.674), train_loss = 1.02988512, grad/param norm = 1.7789e-01, time/batch = 18.2405s	
8688/26050 (epoch 16.676), train_loss = 1.13723178, grad/param norm = 1.7854e-01, time/batch = 14.8791s	
8689/26050 (epoch 16.678), train_loss = 1.23453257, grad/param norm = 1.8258e-01, time/batch = 15.6399s	
8690/26050 (epoch 16.679), train_loss = 1.32571352, grad/param norm = 1.9933e-01, time/batch = 18.4694s	
8691/26050 (epoch 16.681), train_loss = 1.14539341, grad/param norm = 1.7810e-01, time/batch = 17.8190s	
8692/26050 (epoch 16.683), train_loss = 1.00820421, grad/param norm = 1.9016e-01, time/batch = 15.1564s	
8693/26050 (epoch 16.685), train_loss = 1.06964584, grad/param norm = 1.5855e-01, time/batch = 17.4725s	
8694/26050 (epoch 16.687), train_loss = 0.95243164, grad/param norm = 1.7102e-01, time/batch = 18.7324s	
8695/26050 (epoch 16.689), train_loss = 1.09362461, grad/param norm = 1.8832e-01, time/batch = 18.3120s	
8696/26050 (epoch 16.691), train_loss = 0.87497492, grad/param norm = 1.4933e-01, time/batch = 15.5586s	
8697/26050 (epoch 16.693), train_loss = 1.01391759, grad/param norm = 1.6303e-01, time/batch = 16.3849s	
8698/26050 (epoch 16.695), train_loss = 1.11524690, grad/param norm = 1.7072e-01, time/batch = 17.2362s	
8699/26050 (epoch 16.697), train_loss = 1.01481987, grad/param norm = 1.7068e-01, time/batch = 18.2519s	
8700/26050 (epoch 16.699), train_loss = 1.16986044, grad/param norm = 1.9082e-01, time/batch = 16.9903s	
8701/26050 (epoch 16.701), train_loss = 0.98817936, grad/param norm = 1.6108e-01, time/batch = 17.9042s	
8702/26050 (epoch 16.702), train_loss = 1.26118944, grad/param norm = 1.9245e-01, time/batch = 18.1543s	
8703/26050 (epoch 16.704), train_loss = 1.18300383, grad/param norm = 1.6374e-01, time/batch = 17.2333s	
8704/26050 (epoch 16.706), train_loss = 1.12402148, grad/param norm = 1.9379e-01, time/batch = 17.8086s	
8705/26050 (epoch 16.708), train_loss = 1.21875988, grad/param norm = 1.8777e-01, time/batch = 18.3931s	
8706/26050 (epoch 16.710), train_loss = 1.19281877, grad/param norm = 1.7964e-01, time/batch = 16.2302s	
8707/26050 (epoch 16.712), train_loss = 1.21577112, grad/param norm = 1.8680e-01, time/batch = 16.6265s	
8708/26050 (epoch 16.714), train_loss = 0.95718989, grad/param norm = 1.6656e-01, time/batch = 16.7132s	
8709/26050 (epoch 16.716), train_loss = 1.37137322, grad/param norm = 1.9893e-01, time/batch = 18.7360s	
8710/26050 (epoch 16.718), train_loss = 1.22603813, grad/param norm = 1.8269e-01, time/batch = 17.5667s	
8711/26050 (epoch 16.720), train_loss = 1.09621457, grad/param norm = 1.7996e-01, time/batch = 18.3072s	
8712/26050 (epoch 16.722), train_loss = 1.01167208, grad/param norm = 1.7231e-01, time/batch = 16.2253s	
8713/26050 (epoch 16.724), train_loss = 1.04120794, grad/param norm = 1.8214e-01, time/batch = 18.3179s	
8714/26050 (epoch 16.726), train_loss = 1.22622922, grad/param norm = 1.7882e-01, time/batch = 17.8190s	
8715/26050 (epoch 16.727), train_loss = 1.21702566, grad/param norm = 1.8866e-01, time/batch = 17.2291s	
8716/26050 (epoch 16.729), train_loss = 1.16046559, grad/param norm = 1.7597e-01, time/batch = 17.6375s	
8717/26050 (epoch 16.731), train_loss = 1.15717211, grad/param norm = 1.7454e-01, time/batch = 17.4061s	
8718/26050 (epoch 16.733), train_loss = 1.08992368, grad/param norm = 2.1407e-01, time/batch = 14.9753s	
8719/26050 (epoch 16.735), train_loss = 1.32645449, grad/param norm = 1.9585e-01, time/batch = 17.6416s	
8720/26050 (epoch 16.737), train_loss = 1.09059167, grad/param norm = 1.7364e-01, time/batch = 17.8887s	
8721/26050 (epoch 16.739), train_loss = 1.17723681, grad/param norm = 1.7720e-01, time/batch = 15.5521s	
8722/26050 (epoch 16.741), train_loss = 1.05019559, grad/param norm = 1.8033e-01, time/batch = 18.3937s	
8723/26050 (epoch 16.743), train_loss = 1.15752285, grad/param norm = 1.8696e-01, time/batch = 18.5609s	
8724/26050 (epoch 16.745), train_loss = 0.99597928, grad/param norm = 1.7007e-01, time/batch = 17.2305s	
8725/26050 (epoch 16.747), train_loss = 1.01569681, grad/param norm = 1.5359e-01, time/batch = 18.9016s	
8726/26050 (epoch 16.749), train_loss = 1.25502258, grad/param norm = 1.8824e-01, time/batch = 17.9827s	
8727/26050 (epoch 16.750), train_loss = 1.10867108, grad/param norm = 1.6481e-01, time/batch = 17.8979s	
8728/26050 (epoch 16.752), train_loss = 1.08670156, grad/param norm = 2.0099e-01, time/batch = 16.3882s	
8729/26050 (epoch 16.754), train_loss = 1.14834403, grad/param norm = 1.7739e-01, time/batch = 17.8793s	
8730/26050 (epoch 16.756), train_loss = 1.13913733, grad/param norm = 2.0381e-01, time/batch = 18.1291s	
8731/26050 (epoch 16.758), train_loss = 1.13244093, grad/param norm = 1.8018e-01, time/batch = 18.1502s	
8732/26050 (epoch 16.760), train_loss = 1.28302412, grad/param norm = 1.8405e-01, time/batch = 17.8138s	
8733/26050 (epoch 16.762), train_loss = 1.06048759, grad/param norm = 1.7064e-01, time/batch = 16.1790s	
8734/26050 (epoch 16.764), train_loss = 1.16784243, grad/param norm = 1.9640e-01, time/batch = 15.9691s	
8735/26050 (epoch 16.766), train_loss = 1.21472915, grad/param norm = 1.9586e-01, time/batch = 18.0695s	
8736/26050 (epoch 16.768), train_loss = 1.02344556, grad/param norm = 1.6316e-01, time/batch = 18.7285s	
8737/26050 (epoch 16.770), train_loss = 1.10000628, grad/param norm = 1.7856e-01, time/batch = 17.3085s	
8738/26050 (epoch 16.772), train_loss = 1.10915875, grad/param norm = 1.6351e-01, time/batch = 18.3243s	
8739/26050 (epoch 16.774), train_loss = 0.99424707, grad/param norm = 1.7937e-01, time/batch = 18.2323s	
8740/26050 (epoch 16.775), train_loss = 0.81644736, grad/param norm = 1.5773e-01, time/batch = 17.0545s	
8741/26050 (epoch 16.777), train_loss = 1.05258123, grad/param norm = 1.6491e-01, time/batch = 18.1399s	
8742/26050 (epoch 16.779), train_loss = 1.09611501, grad/param norm = 1.8267e-01, time/batch = 18.0732s	
8743/26050 (epoch 16.781), train_loss = 1.02696855, grad/param norm = 1.6623e-01, time/batch = 18.0846s	
8744/26050 (epoch 16.783), train_loss = 1.01061035, grad/param norm = 1.7617e-01, time/batch = 17.6491s	
8745/26050 (epoch 16.785), train_loss = 1.09476911, grad/param norm = 1.7179e-01, time/batch = 18.3205s	
8746/26050 (epoch 16.787), train_loss = 1.03983251, grad/param norm = 1.6226e-01, time/batch = 17.3330s	
8747/26050 (epoch 16.789), train_loss = 1.04380462, grad/param norm = 1.9817e-01, time/batch = 16.9739s	
8748/26050 (epoch 16.791), train_loss = 1.08745130, grad/param norm = 1.7696e-01, time/batch = 16.5634s	
8749/26050 (epoch 16.793), train_loss = 1.08708249, grad/param norm = 1.9666e-01, time/batch = 18.1508s	
8750/26050 (epoch 16.795), train_loss = 0.92764918, grad/param norm = 1.5667e-01, time/batch = 17.6460s	
8751/26050 (epoch 16.797), train_loss = 1.01990915, grad/param norm = 1.5806e-01, time/batch = 17.2278s	
8752/26050 (epoch 16.798), train_loss = 0.95700020, grad/param norm = 1.6996e-01, time/batch = 17.5772s	
8753/26050 (epoch 16.800), train_loss = 0.95903599, grad/param norm = 1.5322e-01, time/batch = 17.9835s	
8754/26050 (epoch 16.802), train_loss = 1.05685280, grad/param norm = 1.7580e-01, time/batch = 17.9058s	
8755/26050 (epoch 16.804), train_loss = 1.07936976, grad/param norm = 1.7314e-01, time/batch = 17.6461s	
8756/26050 (epoch 16.806), train_loss = 1.19530810, grad/param norm = 1.8293e-01, time/batch = 15.0379s	
8757/26050 (epoch 16.808), train_loss = 1.09274167, grad/param norm = 1.7891e-01, time/batch = 18.3976s	
8758/26050 (epoch 16.810), train_loss = 1.03296726, grad/param norm = 1.7040e-01, time/batch = 17.4891s	
8759/26050 (epoch 16.812), train_loss = 0.99305071, grad/param norm = 1.8060e-01, time/batch = 17.2350s	
8760/26050 (epoch 16.814), train_loss = 0.98585920, grad/param norm = 1.9191e-01, time/batch = 17.8961s	
8761/26050 (epoch 16.816), train_loss = 1.23192295, grad/param norm = 1.9263e-01, time/batch = 15.3842s	
8762/26050 (epoch 16.818), train_loss = 1.23083770, grad/param norm = 1.9776e-01, time/batch = 18.4689s	
8763/26050 (epoch 16.820), train_loss = 1.12044708, grad/param norm = 1.7579e-01, time/batch = 16.7549s	
8764/26050 (epoch 16.821), train_loss = 1.25783498, grad/param norm = 1.9092e-01, time/batch = 18.7349s	
8765/26050 (epoch 16.823), train_loss = 1.28150465, grad/param norm = 1.9503e-01, time/batch = 16.8758s	
8766/26050 (epoch 16.825), train_loss = 1.10002697, grad/param norm = 1.8109e-01, time/batch = 18.2953s	
8767/26050 (epoch 16.827), train_loss = 1.12683621, grad/param norm = 2.0511e-01, time/batch = 18.0757s	
8768/26050 (epoch 16.829), train_loss = 1.17233394, grad/param norm = 1.7986e-01, time/batch = 17.8928s	
8769/26050 (epoch 16.831), train_loss = 1.22740003, grad/param norm = 1.7809e-01, time/batch = 17.8970s	
8770/26050 (epoch 16.833), train_loss = 1.32531003, grad/param norm = 1.9278e-01, time/batch = 18.4886s	
8771/26050 (epoch 16.835), train_loss = 1.32899550, grad/param norm = 1.9804e-01, time/batch = 17.1479s	
8772/26050 (epoch 16.837), train_loss = 1.10527425, grad/param norm = 1.7687e-01, time/batch = 18.7147s	
8773/26050 (epoch 16.839), train_loss = 1.12787794, grad/param norm = 1.8403e-01, time/batch = 18.2330s	
8774/26050 (epoch 16.841), train_loss = 1.22224467, grad/param norm = 1.8179e-01, time/batch = 14.5580s	
8775/26050 (epoch 16.843), train_loss = 1.13215292, grad/param norm = 1.7818e-01, time/batch = 17.6433s	
8776/26050 (epoch 16.845), train_loss = 1.04201200, grad/param norm = 1.5868e-01, time/batch = 17.1451s	
8777/26050 (epoch 16.846), train_loss = 1.21632010, grad/param norm = 1.6933e-01, time/batch = 18.3086s	
8778/26050 (epoch 16.848), train_loss = 1.11433065, grad/param norm = 1.7428e-01, time/batch = 17.4029s	
8779/26050 (epoch 16.850), train_loss = 1.02467914, grad/param norm = 1.6232e-01, time/batch = 18.7421s	
8780/26050 (epoch 16.852), train_loss = 1.08746235, grad/param norm = 1.7290e-01, time/batch = 17.8388s	
8781/26050 (epoch 16.854), train_loss = 1.09408187, grad/param norm = 1.7037e-01, time/batch = 16.3056s	
8782/26050 (epoch 16.856), train_loss = 1.07062423, grad/param norm = 1.8509e-01, time/batch = 18.4833s	
8783/26050 (epoch 16.858), train_loss = 1.01283326, grad/param norm = 1.6837e-01, time/batch = 17.1223s	
8784/26050 (epoch 16.860), train_loss = 1.14843189, grad/param norm = 1.8834e-01, time/batch = 14.3133s	
8785/26050 (epoch 16.862), train_loss = 1.16031818, grad/param norm = 1.7308e-01, time/batch = 17.0873s	
8786/26050 (epoch 16.864), train_loss = 1.15063515, grad/param norm = 2.0634e-01, time/batch = 18.0719s	
8787/26050 (epoch 16.866), train_loss = 1.05893680, grad/param norm = 1.7181e-01, time/batch = 17.6520s	
8788/26050 (epoch 16.868), train_loss = 1.17045239, grad/param norm = 1.8244e-01, time/batch = 17.7357s	
8789/26050 (epoch 16.869), train_loss = 1.00669935, grad/param norm = 1.6712e-01, time/batch = 16.8193s	
8790/26050 (epoch 16.871), train_loss = 0.94216392, grad/param norm = 1.6871e-01, time/batch = 15.3939s	
8791/26050 (epoch 16.873), train_loss = 1.16555051, grad/param norm = 1.8156e-01, time/batch = 18.1469s	
8792/26050 (epoch 16.875), train_loss = 1.10167323, grad/param norm = 1.8117e-01, time/batch = 17.2306s	
8793/26050 (epoch 16.877), train_loss = 1.00363871, grad/param norm = 1.6830e-01, time/batch = 17.1566s	
8794/26050 (epoch 16.879), train_loss = 1.13119795, grad/param norm = 1.6642e-01, time/batch = 18.8288s	
8795/26050 (epoch 16.881), train_loss = 1.24223913, grad/param norm = 1.7905e-01, time/batch = 17.3977s	
8796/26050 (epoch 16.883), train_loss = 1.16003975, grad/param norm = 1.8358e-01, time/batch = 18.3987s	
8797/26050 (epoch 16.885), train_loss = 0.85337066, grad/param norm = 1.6102e-01, time/batch = 15.2136s	
8798/26050 (epoch 16.887), train_loss = 1.15179372, grad/param norm = 1.8069e-01, time/batch = 18.6581s	
8799/26050 (epoch 16.889), train_loss = 1.07096670, grad/param norm = 1.6506e-01, time/batch = 14.5482s	
8800/26050 (epoch 16.891), train_loss = 0.89772789, grad/param norm = 1.5502e-01, time/batch = 17.7049s	
8801/26050 (epoch 16.893), train_loss = 0.94783053, grad/param norm = 1.6144e-01, time/batch = 15.8766s	
8802/26050 (epoch 16.894), train_loss = 1.06738504, grad/param norm = 1.7002e-01, time/batch = 17.2168s	
8803/26050 (epoch 16.896), train_loss = 1.21605458, grad/param norm = 1.7197e-01, time/batch = 17.6523s	
8804/26050 (epoch 16.898), train_loss = 1.03763280, grad/param norm = 1.7853e-01, time/batch = 17.7367s	
8805/26050 (epoch 16.900), train_loss = 1.16274331, grad/param norm = 1.7917e-01, time/batch = 18.6518s	
8806/26050 (epoch 16.902), train_loss = 1.09953630, grad/param norm = 1.7756e-01, time/batch = 16.4090s	
8807/26050 (epoch 16.904), train_loss = 1.09135893, grad/param norm = 1.7740e-01, time/batch = 18.6661s	
8808/26050 (epoch 16.906), train_loss = 1.08631024, grad/param norm = 1.8318e-01, time/batch = 15.5639s	
8809/26050 (epoch 16.908), train_loss = 1.09686416, grad/param norm = 1.7836e-01, time/batch = 15.7118s	
8810/26050 (epoch 16.910), train_loss = 1.02951614, grad/param norm = 1.5772e-01, time/batch = 18.1378s	
8811/26050 (epoch 16.912), train_loss = 1.34774452, grad/param norm = 2.0992e-01, time/batch = 18.2291s	
8812/26050 (epoch 16.914), train_loss = 1.46106700, grad/param norm = 2.0277e-01, time/batch = 18.0827s	
8813/26050 (epoch 16.916), train_loss = 1.21486472, grad/param norm = 1.9283e-01, time/batch = 17.5638s	
8814/26050 (epoch 16.917), train_loss = 1.13550717, grad/param norm = 1.9913e-01, time/batch = 18.3871s	
8815/26050 (epoch 16.919), train_loss = 1.19865575, grad/param norm = 1.9638e-01, time/batch = 14.9792s	
8816/26050 (epoch 16.921), train_loss = 1.06485544, grad/param norm = 1.8117e-01, time/batch = 17.5712s	
8817/26050 (epoch 16.923), train_loss = 1.14344770, grad/param norm = 1.8990e-01, time/batch = 17.7125s	
8818/26050 (epoch 16.925), train_loss = 1.12779506, grad/param norm = 1.7651e-01, time/batch = 17.8297s	
8819/26050 (epoch 16.927), train_loss = 0.98300871, grad/param norm = 1.4837e-01, time/batch = 18.3213s	
8820/26050 (epoch 16.929), train_loss = 0.99852843, grad/param norm = 1.6817e-01, time/batch = 16.3889s	
8821/26050 (epoch 16.931), train_loss = 1.30615789, grad/param norm = 2.0583e-01, time/batch = 17.9730s	
8822/26050 (epoch 16.933), train_loss = 1.07081752, grad/param norm = 1.7407e-01, time/batch = 18.2340s	
8823/26050 (epoch 16.935), train_loss = 1.08534857, grad/param norm = 1.8273e-01, time/batch = 17.4729s	
8824/26050 (epoch 16.937), train_loss = 1.19939056, grad/param norm = 1.7956e-01, time/batch = 16.9674s	
8825/26050 (epoch 16.939), train_loss = 1.00510528, grad/param norm = 1.4858e-01, time/batch = 17.9839s	
8826/26050 (epoch 16.940), train_loss = 1.09727867, grad/param norm = 1.5817e-01, time/batch = 16.6467s	
8827/26050 (epoch 16.942), train_loss = 1.13212458, grad/param norm = 1.8219e-01, time/batch = 17.8151s	
8828/26050 (epoch 16.944), train_loss = 1.05381871, grad/param norm = 1.6433e-01, time/batch = 18.2417s	
8829/26050 (epoch 16.946), train_loss = 1.24445792, grad/param norm = 1.9372e-01, time/batch = 18.1637s	
8830/26050 (epoch 16.948), train_loss = 0.99359047, grad/param norm = 2.0654e-01, time/batch = 17.1534s	
8831/26050 (epoch 16.950), train_loss = 1.08545106, grad/param norm = 1.8216e-01, time/batch = 18.2433s	
8832/26050 (epoch 16.952), train_loss = 1.23426002, grad/param norm = 1.9861e-01, time/batch = 18.4889s	
8833/26050 (epoch 16.954), train_loss = 1.21039608, grad/param norm = 1.8236e-01, time/batch = 17.3884s	
8834/26050 (epoch 16.956), train_loss = 1.10415090, grad/param norm = 1.7638e-01, time/batch = 16.1597s	
8835/26050 (epoch 16.958), train_loss = 1.05880797, grad/param norm = 1.7410e-01, time/batch = 17.3989s	
8836/26050 (epoch 16.960), train_loss = 1.10653864, grad/param norm = 1.7286e-01, time/batch = 18.2299s	
8837/26050 (epoch 16.962), train_loss = 1.02985737, grad/param norm = 1.5832e-01, time/batch = 17.9799s	
8838/26050 (epoch 16.964), train_loss = 1.09126998, grad/param norm = 1.7749e-01, time/batch = 16.9818s	
8839/26050 (epoch 16.965), train_loss = 1.02676703, grad/param norm = 1.7092e-01, time/batch = 17.2414s	
8840/26050 (epoch 16.967), train_loss = 1.42720440, grad/param norm = 1.8336e-01, time/batch = 21.7204s	
8841/26050 (epoch 16.969), train_loss = 1.09048934, grad/param norm = 1.6368e-01, time/batch = 34.3556s	
8842/26050 (epoch 16.971), train_loss = 1.05103011, grad/param norm = 1.5067e-01, time/batch = 17.2148s	
8843/26050 (epoch 16.973), train_loss = 1.07569156, grad/param norm = 1.8843e-01, time/batch = 18.7374s	
8844/26050 (epoch 16.975), train_loss = 1.17106812, grad/param norm = 1.7236e-01, time/batch = 17.2079s	
8845/26050 (epoch 16.977), train_loss = 1.15127037, grad/param norm = 1.6795e-01, time/batch = 15.1561s	
8846/26050 (epoch 16.979), train_loss = 0.93504056, grad/param norm = 1.6549e-01, time/batch = 18.4766s	
8847/26050 (epoch 16.981), train_loss = 1.23977602, grad/param norm = 1.7058e-01, time/batch = 17.8276s	
8848/26050 (epoch 16.983), train_loss = 1.19955307, grad/param norm = 1.7847e-01, time/batch = 18.4795s	
8849/26050 (epoch 16.985), train_loss = 1.16144236, grad/param norm = 1.7784e-01, time/batch = 17.2233s	
8850/26050 (epoch 16.987), train_loss = 1.22709897, grad/param norm = 1.7502e-01, time/batch = 14.6476s	
8851/26050 (epoch 16.988), train_loss = 1.20041897, grad/param norm = 1.7243e-01, time/batch = 14.9661s	
8852/26050 (epoch 16.990), train_loss = 0.98266778, grad/param norm = 1.4955e-01, time/batch = 18.8858s	
8853/26050 (epoch 16.992), train_loss = 1.26918110, grad/param norm = 1.9071e-01, time/batch = 18.3024s	
8854/26050 (epoch 16.994), train_loss = 1.09719746, grad/param norm = 1.8557e-01, time/batch = 18.0759s	
8855/26050 (epoch 16.996), train_loss = 1.07463423, grad/param norm = 1.8735e-01, time/batch = 17.5733s	
8856/26050 (epoch 16.998), train_loss = 1.12178523, grad/param norm = 1.7194e-01, time/batch = 17.2363s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
8857/26050 (epoch 17.000), train_loss = 1.06415345, grad/param norm = 1.8486e-01, time/batch = 18.5689s	
8858/26050 (epoch 17.002), train_loss = 1.19640016, grad/param norm = 1.9569e-01, time/batch = 17.8206s	
8859/26050 (epoch 17.004), train_loss = 1.01730572, grad/param norm = 1.7361e-01, time/batch = 17.7265s	
8860/26050 (epoch 17.006), train_loss = 1.03795119, grad/param norm = 1.7553e-01, time/batch = 19.3839s	
8861/26050 (epoch 17.008), train_loss = 1.02479075, grad/param norm = 1.8276e-01, time/batch = 18.3180s	
8862/26050 (epoch 17.010), train_loss = 1.04061637, grad/param norm = 1.7426e-01, time/batch = 18.0756s	
8863/26050 (epoch 17.012), train_loss = 1.12617166, grad/param norm = 1.7212e-01, time/batch = 17.4459s	
8864/26050 (epoch 17.013), train_loss = 1.45773454, grad/param norm = 2.0420e-01, time/batch = 17.9925s	
8865/26050 (epoch 17.015), train_loss = 1.05646776, grad/param norm = 1.7187e-01, time/batch = 17.8111s	
8866/26050 (epoch 17.017), train_loss = 1.12228349, grad/param norm = 1.7417e-01, time/batch = 16.3011s	
8867/26050 (epoch 17.019), train_loss = 0.94805283, grad/param norm = 1.4896e-01, time/batch = 16.7074s	
8868/26050 (epoch 17.021), train_loss = 1.17839828, grad/param norm = 1.7751e-01, time/batch = 17.8846s	
8869/26050 (epoch 17.023), train_loss = 0.96170471, grad/param norm = 1.7218e-01, time/batch = 15.7144s	
8870/26050 (epoch 17.025), train_loss = 1.10878950, grad/param norm = 1.7071e-01, time/batch = 17.4865s	
8871/26050 (epoch 17.027), train_loss = 0.89489276, grad/param norm = 1.6386e-01, time/batch = 17.8243s	
8872/26050 (epoch 17.029), train_loss = 1.13549807, grad/param norm = 1.7115e-01, time/batch = 18.9123s	
8873/26050 (epoch 17.031), train_loss = 1.24332105, grad/param norm = 2.0407e-01, time/batch = 17.0613s	
8874/26050 (epoch 17.033), train_loss = 1.15541402, grad/param norm = 1.8520e-01, time/batch = 17.7443s	
8875/26050 (epoch 17.035), train_loss = 1.16761416, grad/param norm = 1.8193e-01, time/batch = 18.7334s	
8876/26050 (epoch 17.036), train_loss = 1.01102834, grad/param norm = 1.8881e-01, time/batch = 18.0502s	
8877/26050 (epoch 17.038), train_loss = 0.92746356, grad/param norm = 1.6306e-01, time/batch = 15.3067s	
8878/26050 (epoch 17.040), train_loss = 1.11781864, grad/param norm = 1.8858e-01, time/batch = 17.9022s	
8879/26050 (epoch 17.042), train_loss = 0.94849165, grad/param norm = 1.6725e-01, time/batch = 18.5512s	
8880/26050 (epoch 17.044), train_loss = 1.19219448, grad/param norm = 1.6771e-01, time/batch = 18.2952s	
8881/26050 (epoch 17.046), train_loss = 0.88687074, grad/param norm = 1.4913e-01, time/batch = 17.9640s	
8882/26050 (epoch 17.048), train_loss = 1.12737904, grad/param norm = 1.6904e-01, time/batch = 18.7344s	
8883/26050 (epoch 17.050), train_loss = 1.01853669, grad/param norm = 1.7194e-01, time/batch = 17.5470s	
8884/26050 (epoch 17.052), train_loss = 1.05969905, grad/param norm = 1.8034e-01, time/batch = 16.2320s	
8885/26050 (epoch 17.054), train_loss = 0.93955118, grad/param norm = 1.5745e-01, time/batch = 18.3150s	
8886/26050 (epoch 17.056), train_loss = 0.88753550, grad/param norm = 1.3988e-01, time/batch = 16.9792s	
8887/26050 (epoch 17.058), train_loss = 1.05683677, grad/param norm = 1.6354e-01, time/batch = 18.4723s	
8888/26050 (epoch 17.060), train_loss = 1.13480746, grad/param norm = 1.7111e-01, time/batch = 17.4769s	
8889/26050 (epoch 17.061), train_loss = 1.01697016, grad/param norm = 1.7193e-01, time/batch = 15.7143s	
8890/26050 (epoch 17.063), train_loss = 1.14602508, grad/param norm = 1.7992e-01, time/batch = 17.4660s	
8891/26050 (epoch 17.065), train_loss = 0.91074113, grad/param norm = 1.5623e-01, time/batch = 17.9090s	
8892/26050 (epoch 17.067), train_loss = 1.12066144, grad/param norm = 1.8153e-01, time/batch = 17.8080s	
8893/26050 (epoch 17.069), train_loss = 1.15144204, grad/param norm = 1.6980e-01, time/batch = 15.5429s	
8894/26050 (epoch 17.071), train_loss = 1.17375630, grad/param norm = 1.7567e-01, time/batch = 18.0663s	
8895/26050 (epoch 17.073), train_loss = 1.29218385, grad/param norm = 1.9365e-01, time/batch = 18.2996s	
8896/26050 (epoch 17.075), train_loss = 1.01563090, grad/param norm = 1.6276e-01, time/batch = 17.2205s	
8897/26050 (epoch 17.077), train_loss = 1.01711258, grad/param norm = 1.6434e-01, time/batch = 18.1348s	
8898/26050 (epoch 17.079), train_loss = 1.12887930, grad/param norm = 1.7815e-01, time/batch = 18.1531s	
8899/26050 (epoch 17.081), train_loss = 1.06077676, grad/param norm = 1.7022e-01, time/batch = 18.7316s	
8900/26050 (epoch 17.083), train_loss = 1.16795875, grad/param norm = 1.6344e-01, time/batch = 16.8960s	
8901/26050 (epoch 17.084), train_loss = 1.14273204, grad/param norm = 2.0575e-01, time/batch = 18.4698s	
8902/26050 (epoch 17.086), train_loss = 1.24697936, grad/param norm = 1.8493e-01, time/batch = 15.8899s	
8903/26050 (epoch 17.088), train_loss = 0.99775104, grad/param norm = 1.6948e-01, time/batch = 17.3812s	
8904/26050 (epoch 17.090), train_loss = 1.13320193, grad/param norm = 1.8594e-01, time/batch = 18.3069s	
8905/26050 (epoch 17.092), train_loss = 1.15243128, grad/param norm = 1.7597e-01, time/batch = 17.4982s	
8906/26050 (epoch 17.094), train_loss = 1.04898777, grad/param norm = 1.7174e-01, time/batch = 18.9058s	
8907/26050 (epoch 17.096), train_loss = 1.08527546, grad/param norm = 1.6911e-01, time/batch = 15.5340s	
8908/26050 (epoch 17.098), train_loss = 1.05383983, grad/param norm = 1.8092e-01, time/batch = 18.1627s	
8909/26050 (epoch 17.100), train_loss = 0.99330377, grad/param norm = 1.7705e-01, time/batch = 17.3876s	
8910/26050 (epoch 17.102), train_loss = 1.11466200, grad/param norm = 1.6947e-01, time/batch = 14.8715s	
8911/26050 (epoch 17.104), train_loss = 1.10570403, grad/param norm = 1.9216e-01, time/batch = 17.8148s	
8912/26050 (epoch 17.106), train_loss = 1.11251807, grad/param norm = 1.9445e-01, time/batch = 18.2331s	
8913/26050 (epoch 17.107), train_loss = 0.88870390, grad/param norm = 1.5134e-01, time/batch = 18.2351s	
8914/26050 (epoch 17.109), train_loss = 1.02444064, grad/param norm = 1.7824e-01, time/batch = 17.9786s	
8915/26050 (epoch 17.111), train_loss = 1.27168253, grad/param norm = 1.9169e-01, time/batch = 17.7248s	
8916/26050 (epoch 17.113), train_loss = 1.03632396, grad/param norm = 1.6908e-01, time/batch = 16.0474s	
8917/26050 (epoch 17.115), train_loss = 1.20112899, grad/param norm = 1.7529e-01, time/batch = 17.3958s	
8918/26050 (epoch 17.117), train_loss = 1.12576551, grad/param norm = 1.6342e-01, time/batch = 18.8812s	
8919/26050 (epoch 17.119), train_loss = 0.92439949, grad/param norm = 1.6935e-01, time/batch = 17.8264s	
8920/26050 (epoch 17.121), train_loss = 1.12891956, grad/param norm = 1.8295e-01, time/batch = 17.9752s	
8921/26050 (epoch 17.123), train_loss = 0.99226434, grad/param norm = 1.6478e-01, time/batch = 17.7299s	
8922/26050 (epoch 17.125), train_loss = 0.96658446, grad/param norm = 1.7035e-01, time/batch = 14.6225s	
8923/26050 (epoch 17.127), train_loss = 0.87294838, grad/param norm = 1.5145e-01, time/batch = 17.7367s	
8924/26050 (epoch 17.129), train_loss = 0.93049406, grad/param norm = 1.7151e-01, time/batch = 16.8232s	
8925/26050 (epoch 17.131), train_loss = 1.06217671, grad/param norm = 1.7243e-01, time/batch = 18.8159s	
8926/26050 (epoch 17.132), train_loss = 1.06390770, grad/param norm = 1.6644e-01, time/batch = 17.4153s	
8927/26050 (epoch 17.134), train_loss = 1.07837785, grad/param norm = 1.9668e-01, time/batch = 17.8194s	
8928/26050 (epoch 17.136), train_loss = 1.08973647, grad/param norm = 1.6683e-01, time/batch = 14.9862s	
8929/26050 (epoch 17.138), train_loss = 0.87049994, grad/param norm = 1.6405e-01, time/batch = 17.9921s	
8930/26050 (epoch 17.140), train_loss = 0.92478839, grad/param norm = 1.7035e-01, time/batch = 17.8939s	
8931/26050 (epoch 17.142), train_loss = 0.96657500, grad/param norm = 1.6469e-01, time/batch = 18.0528s	
8932/26050 (epoch 17.144), train_loss = 0.89837685, grad/param norm = 1.6324e-01, time/batch = 17.7308s	
8933/26050 (epoch 17.146), train_loss = 0.82553321, grad/param norm = 1.6172e-01, time/batch = 18.3850s	
8934/26050 (epoch 17.148), train_loss = 0.86315645, grad/param norm = 1.4976e-01, time/batch = 17.3197s	
8935/26050 (epoch 17.150), train_loss = 1.06444929, grad/param norm = 1.8177e-01, time/batch = 17.9888s	
8936/26050 (epoch 17.152), train_loss = 1.25697460, grad/param norm = 2.0153e-01, time/batch = 18.7995s	
8937/26050 (epoch 17.154), train_loss = 0.85467329, grad/param norm = 1.6315e-01, time/batch = 17.6489s	
8938/26050 (epoch 17.155), train_loss = 0.89957554, grad/param norm = 1.5850e-01, time/batch = 18.3836s	
8939/26050 (epoch 17.157), train_loss = 1.01177530, grad/param norm = 2.0149e-01, time/batch = 15.2221s	
8940/26050 (epoch 17.159), train_loss = 1.07068180, grad/param norm = 1.8974e-01, time/batch = 18.8125s	
8941/26050 (epoch 17.161), train_loss = 1.14439042, grad/param norm = 1.8673e-01, time/batch = 16.7364s	
8942/26050 (epoch 17.163), train_loss = 0.89811707, grad/param norm = 1.6362e-01, time/batch = 17.4951s	
8943/26050 (epoch 17.165), train_loss = 0.81807709, grad/param norm = 1.4812e-01, time/batch = 18.0649s	
8944/26050 (epoch 17.167), train_loss = 1.17170476, grad/param norm = 1.8385e-01, time/batch = 14.8821s	
8945/26050 (epoch 17.169), train_loss = 1.12881935, grad/param norm = 1.8128e-01, time/batch = 15.9848s	
8946/26050 (epoch 17.171), train_loss = 0.87569802, grad/param norm = 1.5149e-01, time/batch = 16.4778s	
8947/26050 (epoch 17.173), train_loss = 1.00525070, grad/param norm = 1.7574e-01, time/batch = 15.0992s	
8948/26050 (epoch 17.175), train_loss = 1.05684262, grad/param norm = 1.6616e-01, time/batch = 14.2478s	
8949/26050 (epoch 17.177), train_loss = 1.19288652, grad/param norm = 1.7847e-01, time/batch = 13.9188s	
8950/26050 (epoch 17.179), train_loss = 0.85034465, grad/param norm = 1.5649e-01, time/batch = 13.9362s	
8951/26050 (epoch 17.180), train_loss = 1.29281872, grad/param norm = 1.8260e-01, time/batch = 17.7317s	
8952/26050 (epoch 17.182), train_loss = 1.30533680, grad/param norm = 1.8971e-01, time/batch = 17.9011s	
8953/26050 (epoch 17.184), train_loss = 1.10047691, grad/param norm = 1.7018e-01, time/batch = 16.3857s	
8954/26050 (epoch 17.186), train_loss = 0.89027679, grad/param norm = 1.5684e-01, time/batch = 18.4630s	
8955/26050 (epoch 17.188), train_loss = 1.07201291, grad/param norm = 1.7500e-01, time/batch = 14.4666s	
8956/26050 (epoch 17.190), train_loss = 1.12946523, grad/param norm = 1.7931e-01, time/batch = 18.2234s	
8957/26050 (epoch 17.192), train_loss = 1.13447838, grad/param norm = 1.6582e-01, time/batch = 17.0589s	
8958/26050 (epoch 17.194), train_loss = 1.11537416, grad/param norm = 1.6948e-01, time/batch = 18.3976s	
8959/26050 (epoch 17.196), train_loss = 1.17133057, grad/param norm = 1.8059e-01, time/batch = 17.0598s	
8960/26050 (epoch 17.198), train_loss = 0.99815453, grad/param norm = 1.6135e-01, time/batch = 18.4832s	
8961/26050 (epoch 17.200), train_loss = 0.97926680, grad/param norm = 1.7364e-01, time/batch = 17.5858s	
8962/26050 (epoch 17.202), train_loss = 1.06200871, grad/param norm = 1.7607e-01, time/batch = 15.6333s	
8963/26050 (epoch 17.203), train_loss = 1.19058601, grad/param norm = 1.9348e-01, time/batch = 18.0706s	
8964/26050 (epoch 17.205), train_loss = 1.01117566, grad/param norm = 1.6474e-01, time/batch = 18.8058s	
8965/26050 (epoch 17.207), train_loss = 1.01467894, grad/param norm = 1.7004e-01, time/batch = 18.8948s	
8966/26050 (epoch 17.209), train_loss = 1.10195475, grad/param norm = 1.6754e-01, time/batch = 17.6397s	
8967/26050 (epoch 17.211), train_loss = 0.91968503, grad/param norm = 1.5925e-01, time/batch = 17.9689s	
8968/26050 (epoch 17.213), train_loss = 1.13806900, grad/param norm = 1.7698e-01, time/batch = 18.1604s	
8969/26050 (epoch 17.215), train_loss = 1.06457516, grad/param norm = 1.8771e-01, time/batch = 17.0003s	
8970/26050 (epoch 17.217), train_loss = 1.07385797, grad/param norm = 1.7033e-01, time/batch = 15.9059s	
8971/26050 (epoch 17.219), train_loss = 1.05515234, grad/param norm = 1.9783e-01, time/batch = 14.5384s	
8972/26050 (epoch 17.221), train_loss = 0.97819308, grad/param norm = 1.8071e-01, time/batch = 18.6409s	
8973/26050 (epoch 17.223), train_loss = 1.09381067, grad/param norm = 1.7257e-01, time/batch = 18.6357s	
8974/26050 (epoch 17.225), train_loss = 0.97391962, grad/param norm = 1.6754e-01, time/batch = 18.1539s	
8975/26050 (epoch 17.226), train_loss = 1.15456176, grad/param norm = 1.9561e-01, time/batch = 18.4874s	
8976/26050 (epoch 17.228), train_loss = 1.21166992, grad/param norm = 1.8249e-01, time/batch = 16.3879s	
8977/26050 (epoch 17.230), train_loss = 1.10861974, grad/param norm = 1.6984e-01, time/batch = 18.2370s	
8978/26050 (epoch 17.232), train_loss = 1.19726897, grad/param norm = 1.9383e-01, time/batch = 18.0585s	
8979/26050 (epoch 17.234), train_loss = 0.94764797, grad/param norm = 1.7494e-01, time/batch = 18.3171s	
8980/26050 (epoch 17.236), train_loss = 1.16700576, grad/param norm = 1.8780e-01, time/batch = 17.5849s	
8981/26050 (epoch 17.238), train_loss = 0.92878548, grad/param norm = 1.6221e-01, time/batch = 17.3190s	
8982/26050 (epoch 17.240), train_loss = 1.07325589, grad/param norm = 1.7420e-01, time/batch = 18.4851s	
8983/26050 (epoch 17.242), train_loss = 1.07885419, grad/param norm = 1.6606e-01, time/batch = 17.8059s	
8984/26050 (epoch 17.244), train_loss = 1.06859782, grad/param norm = 2.0014e-01, time/batch = 15.0632s	
8985/26050 (epoch 17.246), train_loss = 1.02104826, grad/param norm = 1.6937e-01, time/batch = 17.9774s	
8986/26050 (epoch 17.248), train_loss = 1.07765251, grad/param norm = 1.6833e-01, time/batch = 16.3857s	
8987/26050 (epoch 17.250), train_loss = 1.09018717, grad/param norm = 2.0198e-01, time/batch = 17.4114s	
8988/26050 (epoch 17.251), train_loss = 1.04598098, grad/param norm = 1.8154e-01, time/batch = 18.3250s	
8989/26050 (epoch 17.253), train_loss = 0.94225355, grad/param norm = 1.6316e-01, time/batch = 18.3737s	
8990/26050 (epoch 17.255), train_loss = 1.25594050, grad/param norm = 1.7485e-01, time/batch = 18.1587s	
8991/26050 (epoch 17.257), train_loss = 1.07195360, grad/param norm = 1.7961e-01, time/batch = 16.8163s	
8992/26050 (epoch 17.259), train_loss = 1.22171808, grad/param norm = 1.7971e-01, time/batch = 14.9784s	
8993/26050 (epoch 17.261), train_loss = 0.96494349, grad/param norm = 1.7717e-01, time/batch = 16.1460s	
8994/26050 (epoch 17.263), train_loss = 1.13031098, grad/param norm = 1.7722e-01, time/batch = 18.5895s	
8995/26050 (epoch 17.265), train_loss = 1.24622684, grad/param norm = 1.8458e-01, time/batch = 16.8307s	
8996/26050 (epoch 17.267), train_loss = 1.18125071, grad/param norm = 1.6737e-01, time/batch = 18.1414s	
8997/26050 (epoch 17.269), train_loss = 1.24907346, grad/param norm = 2.0022e-01, time/batch = 15.8408s	
8998/26050 (epoch 17.271), train_loss = 1.13583010, grad/param norm = 1.7921e-01, time/batch = 18.3010s	
8999/26050 (epoch 17.273), train_loss = 1.04161629, grad/param norm = 1.8466e-01, time/batch = 18.1296s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch17.27_1.6478.t7	
9000/26050 (epoch 17.274), train_loss = 1.04781501, grad/param norm = 1.7025e-01, time/batch = 16.9047s	
9001/26050 (epoch 17.276), train_loss = 1.28684870, grad/param norm = 2.0510e-01, time/batch = 15.6282s	
9002/26050 (epoch 17.278), train_loss = 1.22011665, grad/param norm = 1.7963e-01, time/batch = 17.7339s	
9003/26050 (epoch 17.280), train_loss = 1.06880908, grad/param norm = 1.6606e-01, time/batch = 18.4017s	
9004/26050 (epoch 17.282), train_loss = 1.10347808, grad/param norm = 1.6653e-01, time/batch = 15.7111s	
9005/26050 (epoch 17.284), train_loss = 1.02420606, grad/param norm = 1.7546e-01, time/batch = 18.7374s	
9006/26050 (epoch 17.286), train_loss = 1.10182272, grad/param norm = 1.7625e-01, time/batch = 15.5547s	
9007/26050 (epoch 17.288), train_loss = 0.93049304, grad/param norm = 1.5520e-01, time/batch = 18.0522s	
9008/26050 (epoch 17.290), train_loss = 1.08006704, grad/param norm = 1.8505e-01, time/batch = 18.2365s	
9009/26050 (epoch 17.292), train_loss = 0.99734680, grad/param norm = 1.6904e-01, time/batch = 18.9819s	
9010/26050 (epoch 17.294), train_loss = 1.12224076, grad/param norm = 1.9862e-01, time/batch = 17.2964s	
9011/26050 (epoch 17.296), train_loss = 1.18129284, grad/param norm = 1.8026e-01, time/batch = 17.7216s	
9012/26050 (epoch 17.298), train_loss = 1.08500027, grad/param norm = 1.7101e-01, time/batch = 17.6559s	
9013/26050 (epoch 17.299), train_loss = 0.86747145, grad/param norm = 1.5460e-01, time/batch = 17.6367s	
9014/26050 (epoch 17.301), train_loss = 0.96657668, grad/param norm = 1.8332e-01, time/batch = 16.6387s	
9015/26050 (epoch 17.303), train_loss = 1.10474765, grad/param norm = 1.9846e-01, time/batch = 17.4017s	
9016/26050 (epoch 17.305), train_loss = 0.90603313, grad/param norm = 1.7397e-01, time/batch = 16.4777s	
9017/26050 (epoch 17.307), train_loss = 0.99991913, grad/param norm = 1.7255e-01, time/batch = 17.0467s	
9018/26050 (epoch 17.309), train_loss = 1.05980257, grad/param norm = 1.7885e-01, time/batch = 18.3039s	
9019/26050 (epoch 17.311), train_loss = 1.18419370, grad/param norm = 2.1114e-01, time/batch = 17.6483s	
9020/26050 (epoch 17.313), train_loss = 1.06208795, grad/param norm = 1.9671e-01, time/batch = 18.4814s	
9021/26050 (epoch 17.315), train_loss = 1.18090514, grad/param norm = 2.3148e-01, time/batch = 17.0571s	
9022/26050 (epoch 17.317), train_loss = 1.06787826, grad/param norm = 1.7009e-01, time/batch = 15.8898s	
9023/26050 (epoch 17.319), train_loss = 1.02719741, grad/param norm = 1.8311e-01, time/batch = 17.5631s	
9024/26050 (epoch 17.321), train_loss = 1.05574495, grad/param norm = 1.8343e-01, time/batch = 17.9737s	
9025/26050 (epoch 17.322), train_loss = 1.10277632, grad/param norm = 1.6758e-01, time/batch = 18.2056s	
9026/26050 (epoch 17.324), train_loss = 0.90651198, grad/param norm = 1.7277e-01, time/batch = 18.4574s	
9027/26050 (epoch 17.326), train_loss = 1.22409027, grad/param norm = 1.7421e-01, time/batch = 17.2378s	
9028/26050 (epoch 17.328), train_loss = 1.12728361, grad/param norm = 1.6843e-01, time/batch = 18.0581s	
9029/26050 (epoch 17.330), train_loss = 0.96557013, grad/param norm = 1.6774e-01, time/batch = 16.9055s	
9030/26050 (epoch 17.332), train_loss = 1.13178363, grad/param norm = 1.7482e-01, time/batch = 17.6258s	
9031/26050 (epoch 17.334), train_loss = 1.05227142, grad/param norm = 2.0152e-01, time/batch = 18.3049s	
9032/26050 (epoch 17.336), train_loss = 1.01573913, grad/param norm = 1.6615e-01, time/batch = 18.7292s	
9033/26050 (epoch 17.338), train_loss = 0.96117635, grad/param norm = 1.5771e-01, time/batch = 17.9748s	
9034/26050 (epoch 17.340), train_loss = 1.19678995, grad/param norm = 1.9433e-01, time/batch = 14.9846s	
9035/26050 (epoch 17.342), train_loss = 1.21103617, grad/param norm = 1.8267e-01, time/batch = 18.2310s	
9036/26050 (epoch 17.344), train_loss = 1.03912880, grad/param norm = 1.7841e-01, time/batch = 17.7252s	
9037/26050 (epoch 17.345), train_loss = 1.04991737, grad/param norm = 1.7808e-01, time/batch = 17.8211s	
9038/26050 (epoch 17.347), train_loss = 1.18949388, grad/param norm = 1.8177e-01, time/batch = 19.8850s	
9039/26050 (epoch 17.349), train_loss = 1.13061821, grad/param norm = 1.8182e-01, time/batch = 35.0064s	
9040/26050 (epoch 17.351), train_loss = 1.09578395, grad/param norm = 1.8061e-01, time/batch = 17.4489s	
9041/26050 (epoch 17.353), train_loss = 1.07643931, grad/param norm = 1.8336e-01, time/batch = 17.6483s	
9042/26050 (epoch 17.355), train_loss = 1.14033398, grad/param norm = 1.9636e-01, time/batch = 17.2805s	
9043/26050 (epoch 17.357), train_loss = 1.00304605, grad/param norm = 1.6139e-01, time/batch = 18.1679s	
9044/26050 (epoch 17.359), train_loss = 1.16115026, grad/param norm = 1.7482e-01, time/batch = 17.5540s	
9045/26050 (epoch 17.361), train_loss = 1.01035359, grad/param norm = 1.6857e-01, time/batch = 17.9724s	
9046/26050 (epoch 17.363), train_loss = 1.14242292, grad/param norm = 1.7368e-01, time/batch = 18.6399s	
9047/26050 (epoch 17.365), train_loss = 1.05932864, grad/param norm = 1.5293e-01, time/batch = 17.3108s	
9048/26050 (epoch 17.367), train_loss = 1.11669714, grad/param norm = 1.7245e-01, time/batch = 18.2139s	
9049/26050 (epoch 17.369), train_loss = 1.05228221, grad/param norm = 1.6756e-01, time/batch = 19.0566s	
9050/26050 (epoch 17.370), train_loss = 0.97036128, grad/param norm = 1.5759e-01, time/batch = 15.9733s	
9051/26050 (epoch 17.372), train_loss = 1.14843277, grad/param norm = 1.8504e-01, time/batch = 14.5363s	
9052/26050 (epoch 17.374), train_loss = 1.23304616, grad/param norm = 1.9373e-01, time/batch = 17.7447s	
9053/26050 (epoch 17.376), train_loss = 1.29376228, grad/param norm = 1.8578e-01, time/batch = 18.5662s	
9054/26050 (epoch 17.378), train_loss = 1.06445242, grad/param norm = 1.7311e-01, time/batch = 17.9666s	
9055/26050 (epoch 17.380), train_loss = 1.27473848, grad/param norm = 2.0056e-01, time/batch = 17.2419s	
9056/26050 (epoch 17.382), train_loss = 1.38526202, grad/param norm = 2.2497e-01, time/batch = 17.5567s	
9057/26050 (epoch 17.384), train_loss = 1.08136997, grad/param norm = 1.8466e-01, time/batch = 17.8937s	
9058/26050 (epoch 17.386), train_loss = 1.18088089, grad/param norm = 2.0668e-01, time/batch = 17.8293s	
9059/26050 (epoch 17.388), train_loss = 1.09671212, grad/param norm = 1.7336e-01, time/batch = 16.8846s	
9060/26050 (epoch 17.390), train_loss = 1.01573943, grad/param norm = 1.7389e-01, time/batch = 18.1622s	
9061/26050 (epoch 17.392), train_loss = 0.96467083, grad/param norm = 1.5885e-01, time/batch = 18.8153s	
9062/26050 (epoch 17.393), train_loss = 1.12540625, grad/param norm = 1.7434e-01, time/batch = 18.0600s	
9063/26050 (epoch 17.395), train_loss = 1.14183331, grad/param norm = 1.6201e-01, time/batch = 15.2188s	
9064/26050 (epoch 17.397), train_loss = 1.13818868, grad/param norm = 2.0218e-01, time/batch = 17.2367s	
9065/26050 (epoch 17.399), train_loss = 1.01035772, grad/param norm = 1.6798e-01, time/batch = 17.8171s	
9066/26050 (epoch 17.401), train_loss = 1.09238691, grad/param norm = 1.8537e-01, time/batch = 18.4760s	
9067/26050 (epoch 17.403), train_loss = 1.12577783, grad/param norm = 1.7219e-01, time/batch = 16.0655s	
9068/26050 (epoch 17.405), train_loss = 1.09047941, grad/param norm = 1.7362e-01, time/batch = 17.5489s	
9069/26050 (epoch 17.407), train_loss = 1.23435031, grad/param norm = 1.8974e-01, time/batch = 17.6579s	
9070/26050 (epoch 17.409), train_loss = 1.27049325, grad/param norm = 1.9048e-01, time/batch = 18.3183s	
9071/26050 (epoch 17.411), train_loss = 1.14257966, grad/param norm = 2.0073e-01, time/batch = 16.5647s	
9072/26050 (epoch 17.413), train_loss = 1.23629279, grad/param norm = 1.6559e-01, time/batch = 17.6351s	
9073/26050 (epoch 17.415), train_loss = 1.21730285, grad/param norm = 2.1547e-01, time/batch = 18.4052s	
9074/26050 (epoch 17.417), train_loss = 1.30924904, grad/param norm = 1.9980e-01, time/batch = 17.6449s	
9075/26050 (epoch 17.418), train_loss = 1.20104997, grad/param norm = 1.9710e-01, time/batch = 18.8293s	
9076/26050 (epoch 17.420), train_loss = 0.92017186, grad/param norm = 1.5982e-01, time/batch = 18.5640s	
9077/26050 (epoch 17.422), train_loss = 0.94832459, grad/param norm = 1.6239e-01, time/batch = 17.4909s	
9078/26050 (epoch 17.424), train_loss = 1.25778076, grad/param norm = 2.1407e-01, time/batch = 18.8192s	
9079/26050 (epoch 17.426), train_loss = 1.21615414, grad/param norm = 1.8664e-01, time/batch = 14.8748s	
9080/26050 (epoch 17.428), train_loss = 1.01684376, grad/param norm = 1.5860e-01, time/batch = 16.9827s	
9081/26050 (epoch 17.430), train_loss = 1.18950758, grad/param norm = 1.7667e-01, time/batch = 16.9748s	
9082/26050 (epoch 17.432), train_loss = 1.06316905, grad/param norm = 1.7373e-01, time/batch = 18.1533s	
9083/26050 (epoch 17.434), train_loss = 1.08071111, grad/param norm = 1.9853e-01, time/batch = 14.1381s	
9084/26050 (epoch 17.436), train_loss = 1.22138400, grad/param norm = 1.8418e-01, time/batch = 14.1374s	
9085/26050 (epoch 17.438), train_loss = 1.09047574, grad/param norm = 1.8347e-01, time/batch = 15.2171s	
9086/26050 (epoch 17.440), train_loss = 1.11015426, grad/param norm = 1.7006e-01, time/batch = 15.2940s	
9087/26050 (epoch 17.441), train_loss = 1.09963596, grad/param norm = 1.7590e-01, time/batch = 17.8857s	
9088/26050 (epoch 17.443), train_loss = 0.92127860, grad/param norm = 1.5229e-01, time/batch = 17.8180s	
9089/26050 (epoch 17.445), train_loss = 1.00156716, grad/param norm = 1.6633e-01, time/batch = 17.3898s	
9090/26050 (epoch 17.447), train_loss = 1.24468146, grad/param norm = 1.9956e-01, time/batch = 18.6587s	
9091/26050 (epoch 17.449), train_loss = 0.99825274, grad/param norm = 1.6943e-01, time/batch = 18.8830s	
9092/26050 (epoch 17.451), train_loss = 1.24857339, grad/param norm = 1.8781e-01, time/batch = 17.0418s	
9093/26050 (epoch 17.453), train_loss = 1.01753953, grad/param norm = 1.6281e-01, time/batch = 18.3282s	
9094/26050 (epoch 17.455), train_loss = 1.13103932, grad/param norm = 1.6775e-01, time/batch = 18.4773s	
9095/26050 (epoch 17.457), train_loss = 1.10828141, grad/param norm = 1.7220e-01, time/batch = 17.9759s	
9096/26050 (epoch 17.459), train_loss = 1.20806854, grad/param norm = 1.9051e-01, time/batch = 14.4574s	
9097/26050 (epoch 17.461), train_loss = 1.17916202, grad/param norm = 2.0739e-01, time/batch = 17.1433s	
9098/26050 (epoch 17.463), train_loss = 1.06057245, grad/param norm = 1.7357e-01, time/batch = 18.3893s	
9099/26050 (epoch 17.464), train_loss = 1.14469472, grad/param norm = 1.7825e-01, time/batch = 15.2944s	
9100/26050 (epoch 17.466), train_loss = 1.17263212, grad/param norm = 1.7223e-01, time/batch = 17.5582s	
9101/26050 (epoch 17.468), train_loss = 1.18711743, grad/param norm = 1.5951e-01, time/batch = 17.1226s	
9102/26050 (epoch 17.470), train_loss = 1.28391725, grad/param norm = 2.0625e-01, time/batch = 16.5754s	
9103/26050 (epoch 17.472), train_loss = 1.23747687, grad/param norm = 1.9801e-01, time/batch = 18.5749s	
9104/26050 (epoch 17.474), train_loss = 1.29258576, grad/param norm = 1.8034e-01, time/batch = 17.8795s	
9105/26050 (epoch 17.476), train_loss = 1.23437491, grad/param norm = 1.8958e-01, time/batch = 17.7273s	
9106/26050 (epoch 17.478), train_loss = 1.06110406, grad/param norm = 1.6860e-01, time/batch = 18.0555s	
9107/26050 (epoch 17.480), train_loss = 1.12986474, grad/param norm = 1.7317e-01, time/batch = 17.5673s	
9108/26050 (epoch 17.482), train_loss = 1.06500829, grad/param norm = 1.7950e-01, time/batch = 18.7365s	
9109/26050 (epoch 17.484), train_loss = 1.05513214, grad/param norm = 1.7934e-01, time/batch = 16.5720s	
9110/26050 (epoch 17.486), train_loss = 1.26938849, grad/param norm = 1.8749e-01, time/batch = 14.8005s	
9111/26050 (epoch 17.488), train_loss = 1.38206203, grad/param norm = 1.9517e-01, time/batch = 14.4527s	
9112/26050 (epoch 17.489), train_loss = 1.32497368, grad/param norm = 2.1132e-01, time/batch = 15.2735s	
9113/26050 (epoch 17.491), train_loss = 1.01672632, grad/param norm = 1.7646e-01, time/batch = 15.3503s	
9114/26050 (epoch 17.493), train_loss = 1.12155014, grad/param norm = 1.7898e-01, time/batch = 14.2816s	
9115/26050 (epoch 17.495), train_loss = 1.09317566, grad/param norm = 1.6490e-01, time/batch = 15.4535s	
9116/26050 (epoch 17.497), train_loss = 1.00976475, grad/param norm = 1.6679e-01, time/batch = 17.5528s	
9117/26050 (epoch 17.499), train_loss = 1.06129451, grad/param norm = 1.7439e-01, time/batch = 18.4058s	
9118/26050 (epoch 17.501), train_loss = 1.17632969, grad/param norm = 1.8390e-01, time/batch = 18.0726s	
9119/26050 (epoch 17.503), train_loss = 1.05250967, grad/param norm = 1.7875e-01, time/batch = 17.9979s	
9120/26050 (epoch 17.505), train_loss = 1.23366011, grad/param norm = 1.6901e-01, time/batch = 16.7228s	
9121/26050 (epoch 17.507), train_loss = 1.18563243, grad/param norm = 1.8329e-01, time/batch = 18.4125s	
9122/26050 (epoch 17.509), train_loss = 1.30812542, grad/param norm = 1.8850e-01, time/batch = 16.9055s	
9123/26050 (epoch 17.511), train_loss = 1.02293611, grad/param norm = 1.5330e-01, time/batch = 14.6140s	
9124/26050 (epoch 17.512), train_loss = 1.05674699, grad/param norm = 2.0213e-01, time/batch = 18.3863s	
9125/26050 (epoch 17.514), train_loss = 1.18015130, grad/param norm = 1.8661e-01, time/batch = 18.3916s	
9126/26050 (epoch 17.516), train_loss = 1.21743302, grad/param norm = 1.8645e-01, time/batch = 18.4742s	
9127/26050 (epoch 17.518), train_loss = 1.12247339, grad/param norm = 1.7091e-01, time/batch = 17.8125s	
9128/26050 (epoch 17.520), train_loss = 1.09360908, grad/param norm = 1.6919e-01, time/batch = 16.6485s	
9129/26050 (epoch 17.522), train_loss = 0.89647155, grad/param norm = 1.6213e-01, time/batch = 18.1187s	
9130/26050 (epoch 17.524), train_loss = 1.20270360, grad/param norm = 1.9187e-01, time/batch = 18.2330s	
9131/26050 (epoch 17.526), train_loss = 1.21226346, grad/param norm = 1.8979e-01, time/batch = 18.4260s	
9132/26050 (epoch 17.528), train_loss = 1.15463002, grad/param norm = 1.8559e-01, time/batch = 17.9746s	
9133/26050 (epoch 17.530), train_loss = 1.09140869, grad/param norm = 1.8509e-01, time/batch = 17.8853s	
9134/26050 (epoch 17.532), train_loss = 1.10312907, grad/param norm = 1.6841e-01, time/batch = 17.6160s	
9135/26050 (epoch 17.534), train_loss = 1.16815519, grad/param norm = 2.4583e-01, time/batch = 18.3967s	
9136/26050 (epoch 17.536), train_loss = 1.09837587, grad/param norm = 1.7025e-01, time/batch = 18.4749s	
9137/26050 (epoch 17.537), train_loss = 1.20463070, grad/param norm = 1.8772e-01, time/batch = 17.8161s	
9138/26050 (epoch 17.539), train_loss = 1.11276923, grad/param norm = 1.8802e-01, time/batch = 16.1490s	
9139/26050 (epoch 17.541), train_loss = 1.31608459, grad/param norm = 2.0440e-01, time/batch = 17.8163s	
9140/26050 (epoch 17.543), train_loss = 0.94129157, grad/param norm = 1.7534e-01, time/batch = 15.2187s	
9141/26050 (epoch 17.545), train_loss = 1.17605120, grad/param norm = 1.8389e-01, time/batch = 17.9756s	
9142/26050 (epoch 17.547), train_loss = 1.10584415, grad/param norm = 1.7210e-01, time/batch = 18.0693s	
9143/26050 (epoch 17.549), train_loss = 0.91219950, grad/param norm = 1.6315e-01, time/batch = 18.3094s	
9144/26050 (epoch 17.551), train_loss = 1.16731477, grad/param norm = 1.7779e-01, time/batch = 16.7916s	
9145/26050 (epoch 17.553), train_loss = 1.03338195, grad/param norm = 1.6846e-01, time/batch = 16.8853s	
9146/26050 (epoch 17.555), train_loss = 1.04512681, grad/param norm = 1.7223e-01, time/batch = 17.8866s	
9147/26050 (epoch 17.557), train_loss = 1.16675232, grad/param norm = 1.7372e-01, time/batch = 17.8044s	
9148/26050 (epoch 17.559), train_loss = 1.09893361, grad/param norm = 1.6466e-01, time/batch = 19.0660s	
9149/26050 (epoch 17.560), train_loss = 1.07434053, grad/param norm = 1.7016e-01, time/batch = 17.7510s	
9150/26050 (epoch 17.562), train_loss = 1.08347830, grad/param norm = 1.7022e-01, time/batch = 18.1598s	
9151/26050 (epoch 17.564), train_loss = 1.29248086, grad/param norm = 1.7567e-01, time/batch = 18.5707s	
9152/26050 (epoch 17.566), train_loss = 1.01849267, grad/param norm = 1.7412e-01, time/batch = 18.2349s	
9153/26050 (epoch 17.568), train_loss = 1.13643946, grad/param norm = 1.6738e-01, time/batch = 14.8950s	
9154/26050 (epoch 17.570), train_loss = 1.20490263, grad/param norm = 1.8160e-01, time/batch = 17.7087s	
9155/26050 (epoch 17.572), train_loss = 1.08237446, grad/param norm = 1.8302e-01, time/batch = 18.3073s	
9156/26050 (epoch 17.574), train_loss = 1.17601703, grad/param norm = 1.9878e-01, time/batch = 18.5674s	
9157/26050 (epoch 17.576), train_loss = 1.13974350, grad/param norm = 1.9042e-01, time/batch = 15.6342s	
9158/26050 (epoch 17.578), train_loss = 1.07870076, grad/param norm = 1.7922e-01, time/batch = 17.3125s	
9159/26050 (epoch 17.580), train_loss = 1.02759383, grad/param norm = 1.8531e-01, time/batch = 17.0861s	
9160/26050 (epoch 17.582), train_loss = 1.14540883, grad/param norm = 1.6889e-01, time/batch = 18.3948s	
9161/26050 (epoch 17.583), train_loss = 1.21585460, grad/param norm = 1.7549e-01, time/batch = 16.3033s	
9162/26050 (epoch 17.585), train_loss = 0.98787577, grad/param norm = 1.8022e-01, time/batch = 18.1574s	
9163/26050 (epoch 17.587), train_loss = 1.14610740, grad/param norm = 1.8745e-01, time/batch = 18.0728s	
9164/26050 (epoch 17.589), train_loss = 1.26215841, grad/param norm = 2.0150e-01, time/batch = 16.4849s	
9165/26050 (epoch 17.591), train_loss = 1.09358766, grad/param norm = 1.6203e-01, time/batch = 18.7322s	
9166/26050 (epoch 17.593), train_loss = 0.98638837, grad/param norm = 1.7268e-01, time/batch = 18.3274s	
9167/26050 (epoch 17.595), train_loss = 1.19999732, grad/param norm = 2.0073e-01, time/batch = 18.3098s	
9168/26050 (epoch 17.597), train_loss = 1.14115018, grad/param norm = 1.6913e-01, time/batch = 18.0769s	
9169/26050 (epoch 17.599), train_loss = 1.10541817, grad/param norm = 1.8312e-01, time/batch = 16.3840s	
9170/26050 (epoch 17.601), train_loss = 1.29832505, grad/param norm = 1.8257e-01, time/batch = 18.6603s	
9171/26050 (epoch 17.603), train_loss = 1.15204978, grad/param norm = 1.8034e-01, time/batch = 15.5531s	
9172/26050 (epoch 17.605), train_loss = 1.04910397, grad/param norm = 1.6869e-01, time/batch = 17.8876s	
9173/26050 (epoch 17.607), train_loss = 1.22120507, grad/param norm = 1.9144e-01, time/batch = 15.1397s	
9174/26050 (epoch 17.608), train_loss = 0.97561427, grad/param norm = 1.5129e-01, time/batch = 17.8138s	
9175/26050 (epoch 17.610), train_loss = 1.09107980, grad/param norm = 1.9434e-01, time/batch = 17.9850s	
9176/26050 (epoch 17.612), train_loss = 1.12385183, grad/param norm = 1.8221e-01, time/batch = 18.3085s	
9177/26050 (epoch 17.614), train_loss = 1.16782840, grad/param norm = 1.8635e-01, time/batch = 18.2239s	
9178/26050 (epoch 17.616), train_loss = 1.28251162, grad/param norm = 1.9404e-01, time/batch = 14.7172s	
9179/26050 (epoch 17.618), train_loss = 1.07344967, grad/param norm = 1.9382e-01, time/batch = 16.4716s	
9180/26050 (epoch 17.620), train_loss = 1.13638769, grad/param norm = 1.7957e-01, time/batch = 18.6561s	
9181/26050 (epoch 17.622), train_loss = 0.97377641, grad/param norm = 1.5807e-01, time/batch = 16.8835s	
9182/26050 (epoch 17.624), train_loss = 0.98250921, grad/param norm = 1.6433e-01, time/batch = 13.9312s	
9183/26050 (epoch 17.626), train_loss = 1.16084750, grad/param norm = 1.7810e-01, time/batch = 13.9276s	
9184/26050 (epoch 17.628), train_loss = 1.03779661, grad/param norm = 1.8476e-01, time/batch = 18.0621s	
9185/26050 (epoch 17.630), train_loss = 1.22192865, grad/param norm = 2.0078e-01, time/batch = 17.5831s	
9186/26050 (epoch 17.631), train_loss = 1.27120693, grad/param norm = 1.8747e-01, time/batch = 18.5665s	
9187/26050 (epoch 17.633), train_loss = 1.02170335, grad/param norm = 1.6998e-01, time/batch = 17.8110s	
9188/26050 (epoch 17.635), train_loss = 1.03088166, grad/param norm = 1.5278e-01, time/batch = 15.6244s	
9189/26050 (epoch 17.637), train_loss = 0.99644450, grad/param norm = 1.7612e-01, time/batch = 18.1462s	
9190/26050 (epoch 17.639), train_loss = 1.21490910, grad/param norm = 1.7662e-01, time/batch = 17.6356s	
9191/26050 (epoch 17.641), train_loss = 1.06886419, grad/param norm = 1.6104e-01, time/batch = 18.3155s	
9192/26050 (epoch 17.643), train_loss = 0.98176296, grad/param norm = 1.5463e-01, time/batch = 17.4558s	
9193/26050 (epoch 17.645), train_loss = 1.12674111, grad/param norm = 1.8664e-01, time/batch = 15.1139s	
9194/26050 (epoch 17.647), train_loss = 1.05622507, grad/param norm = 1.7123e-01, time/batch = 17.8165s	
9195/26050 (epoch 17.649), train_loss = 1.13446570, grad/param norm = 2.3494e-01, time/batch = 17.9646s	
9196/26050 (epoch 17.651), train_loss = 1.04197105, grad/param norm = 2.0466e-01, time/batch = 15.3960s	
9197/26050 (epoch 17.653), train_loss = 1.13259222, grad/param norm = 1.8485e-01, time/batch = 18.3927s	
9198/26050 (epoch 17.655), train_loss = 1.03133213, grad/param norm = 1.6866e-01, time/batch = 18.4189s	
9199/26050 (epoch 17.656), train_loss = 0.94840081, grad/param norm = 1.7384e-01, time/batch = 18.0515s	
9200/26050 (epoch 17.658), train_loss = 1.28239986, grad/param norm = 1.8161e-01, time/batch = 17.4844s	
9201/26050 (epoch 17.660), train_loss = 0.97864454, grad/param norm = 1.7247e-01, time/batch = 18.8101s	
9202/26050 (epoch 17.662), train_loss = 1.00676071, grad/param norm = 1.6646e-01, time/batch = 17.3092s	
9203/26050 (epoch 17.664), train_loss = 1.08924031, grad/param norm = 1.8001e-01, time/batch = 18.2376s	
9204/26050 (epoch 17.666), train_loss = 1.08774939, grad/param norm = 1.9311e-01, time/batch = 18.3196s	
9205/26050 (epoch 17.668), train_loss = 0.92356776, grad/param norm = 1.7802e-01, time/batch = 16.8928s	
9206/26050 (epoch 17.670), train_loss = 1.25472031, grad/param norm = 1.9400e-01, time/batch = 16.3959s	
9207/26050 (epoch 17.672), train_loss = 1.05435447, grad/param norm = 1.8355e-01, time/batch = 16.0637s	
9208/26050 (epoch 17.674), train_loss = 1.00702385, grad/param norm = 1.7391e-01, time/batch = 18.3911s	
9209/26050 (epoch 17.676), train_loss = 1.14152138, grad/param norm = 1.8695e-01, time/batch = 17.3052s	
9210/26050 (epoch 17.678), train_loss = 1.21359433, grad/param norm = 1.9207e-01, time/batch = 16.9857s	
9211/26050 (epoch 17.679), train_loss = 1.30760870, grad/param norm = 2.0658e-01, time/batch = 15.3834s	
9212/26050 (epoch 17.681), train_loss = 1.12100211, grad/param norm = 1.7820e-01, time/batch = 16.9581s	
9213/26050 (epoch 17.683), train_loss = 0.99534430, grad/param norm = 2.0082e-01, time/batch = 18.5725s	
9214/26050 (epoch 17.685), train_loss = 1.04758357, grad/param norm = 1.6307e-01, time/batch = 17.6572s	
9215/26050 (epoch 17.687), train_loss = 0.92878616, grad/param norm = 1.6821e-01, time/batch = 18.1562s	
9216/26050 (epoch 17.689), train_loss = 1.07959884, grad/param norm = 1.8678e-01, time/batch = 17.3978s	
9217/26050 (epoch 17.691), train_loss = 0.85471344, grad/param norm = 1.4880e-01, time/batch = 16.9731s	
9218/26050 (epoch 17.693), train_loss = 0.99947290, grad/param norm = 1.7273e-01, time/batch = 18.1455s	
9219/26050 (epoch 17.695), train_loss = 1.08763273, grad/param norm = 1.6980e-01, time/batch = 16.2947s	
9220/26050 (epoch 17.697), train_loss = 0.99904966, grad/param norm = 1.6956e-01, time/batch = 17.9079s	
9221/26050 (epoch 17.699), train_loss = 1.16031626, grad/param norm = 1.9106e-01, time/batch = 17.4960s	
9222/26050 (epoch 17.701), train_loss = 0.98603728, grad/param norm = 1.7234e-01, time/batch = 16.5046s	
9223/26050 (epoch 17.702), train_loss = 1.22581111, grad/param norm = 1.8209e-01, time/batch = 18.1594s	
9224/26050 (epoch 17.704), train_loss = 1.16973969, grad/param norm = 1.6471e-01, time/batch = 17.4955s	
9225/26050 (epoch 17.706), train_loss = 1.09876853, grad/param norm = 2.0354e-01, time/batch = 15.5701s	
9226/26050 (epoch 17.708), train_loss = 1.21002161, grad/param norm = 1.9773e-01, time/batch = 17.5640s	
9227/26050 (epoch 17.710), train_loss = 1.16892742, grad/param norm = 1.8347e-01, time/batch = 18.3115s	
9228/26050 (epoch 17.712), train_loss = 1.18931181, grad/param norm = 1.9686e-01, time/batch = 14.4723s	
9229/26050 (epoch 17.714), train_loss = 0.93924411, grad/param norm = 1.6474e-01, time/batch = 17.8203s	
9230/26050 (epoch 17.716), train_loss = 1.33992861, grad/param norm = 1.9439e-01, time/batch = 17.1271s	
9231/26050 (epoch 17.718), train_loss = 1.20592389, grad/param norm = 1.9051e-01, time/batch = 18.6559s	
9232/26050 (epoch 17.720), train_loss = 1.07947403, grad/param norm = 1.8003e-01, time/batch = 17.9798s	
9233/26050 (epoch 17.722), train_loss = 0.97732028, grad/param norm = 1.6988e-01, time/batch = 17.4934s	
9234/26050 (epoch 17.724), train_loss = 1.02441665, grad/param norm = 1.8657e-01, time/batch = 17.3126s	
9235/26050 (epoch 17.726), train_loss = 1.20194058, grad/param norm = 1.8518e-01, time/batch = 16.8062s	
9236/26050 (epoch 17.727), train_loss = 1.20729644, grad/param norm = 1.8871e-01, time/batch = 18.0547s	
9237/26050 (epoch 17.729), train_loss = 1.14244610, grad/param norm = 1.8092e-01, time/batch = 18.0596s	
9238/26050 (epoch 17.731), train_loss = 1.13860679, grad/param norm = 1.7963e-01, time/batch = 15.4841s	
9239/26050 (epoch 17.733), train_loss = 1.06874607, grad/param norm = 2.1739e-01, time/batch = 18.7320s	
9240/26050 (epoch 17.735), train_loss = 1.28856405, grad/param norm = 1.8438e-01, time/batch = 17.3276s	
9241/26050 (epoch 17.737), train_loss = 1.06403222, grad/param norm = 1.8114e-01, time/batch = 18.1628s	
9242/26050 (epoch 17.739), train_loss = 1.15229267, grad/param norm = 1.8296e-01, time/batch = 17.8123s	
9243/26050 (epoch 17.741), train_loss = 1.02856071, grad/param norm = 1.8426e-01, time/batch = 19.2599s	
9244/26050 (epoch 17.743), train_loss = 1.14121465, grad/param norm = 2.5046e-01, time/batch = 30.2444s	
9245/26050 (epoch 17.745), train_loss = 0.97100466, grad/param norm = 1.6817e-01, time/batch = 21.0874s	
9246/26050 (epoch 17.747), train_loss = 1.00010206, grad/param norm = 1.5937e-01, time/batch = 16.8145s	
9247/26050 (epoch 17.749), train_loss = 1.23911595, grad/param norm = 1.9193e-01, time/batch = 18.4826s	
9248/26050 (epoch 17.750), train_loss = 1.08259068, grad/param norm = 1.6390e-01, time/batch = 18.1543s	
9249/26050 (epoch 17.752), train_loss = 1.06735666, grad/param norm = 1.9457e-01, time/batch = 15.3893s	
9250/26050 (epoch 17.754), train_loss = 1.12048716, grad/param norm = 1.8429e-01, time/batch = 17.8901s	
9251/26050 (epoch 17.756), train_loss = 1.10846737, grad/param norm = 1.9095e-01, time/batch = 16.1459s	
9252/26050 (epoch 17.758), train_loss = 1.10002430, grad/param norm = 1.8226e-01, time/batch = 17.9928s	
9253/26050 (epoch 17.760), train_loss = 1.26312077, grad/param norm = 1.8728e-01, time/batch = 18.1519s	
9254/26050 (epoch 17.762), train_loss = 1.04018692, grad/param norm = 1.8003e-01, time/batch = 18.7280s	
9255/26050 (epoch 17.764), train_loss = 1.13582714, grad/param norm = 1.8594e-01, time/batch = 18.8237s	
9256/26050 (epoch 17.766), train_loss = 1.19117751, grad/param norm = 1.9919e-01, time/batch = 17.6221s	
9257/26050 (epoch 17.768), train_loss = 1.00522367, grad/param norm = 1.6378e-01, time/batch = 17.5468s	
9258/26050 (epoch 17.770), train_loss = 1.07796202, grad/param norm = 1.7623e-01, time/batch = 18.4122s	
9259/26050 (epoch 17.772), train_loss = 1.09007748, grad/param norm = 1.6690e-01, time/batch = 14.9752s	
9260/26050 (epoch 17.774), train_loss = 0.95928779, grad/param norm = 1.6953e-01, time/batch = 18.3753s	
9261/26050 (epoch 17.775), train_loss = 0.79063095, grad/param norm = 1.5190e-01, time/batch = 17.9726s	
9262/26050 (epoch 17.777), train_loss = 1.02813272, grad/param norm = 1.6652e-01, time/batch = 14.8009s	
9263/26050 (epoch 17.779), train_loss = 1.06995570, grad/param norm = 1.8565e-01, time/batch = 18.1496s	
9264/26050 (epoch 17.781), train_loss = 1.00417524, grad/param norm = 1.6800e-01, time/batch = 18.5665s	
9265/26050 (epoch 17.783), train_loss = 0.98941693, grad/param norm = 1.7304e-01, time/batch = 18.6614s	
9266/26050 (epoch 17.785), train_loss = 1.07609995, grad/param norm = 1.6845e-01, time/batch = 17.1717s	
9267/26050 (epoch 17.787), train_loss = 1.02783625, grad/param norm = 1.8162e-01, time/batch = 16.2974s	
9268/26050 (epoch 17.789), train_loss = 1.03115194, grad/param norm = 2.0340e-01, time/batch = 18.0703s	
9269/26050 (epoch 17.791), train_loss = 1.06253101, grad/param norm = 1.7956e-01, time/batch = 17.7319s	
9270/26050 (epoch 17.793), train_loss = 1.06312265, grad/param norm = 1.9290e-01, time/batch = 17.4720s	
9271/26050 (epoch 17.795), train_loss = 0.90928659, grad/param norm = 1.5427e-01, time/batch = 16.7972s	
9272/26050 (epoch 17.797), train_loss = 0.99766792, grad/param norm = 1.5603e-01, time/batch = 18.6569s	
9273/26050 (epoch 17.798), train_loss = 0.92822735, grad/param norm = 1.6712e-01, time/batch = 17.0620s	
9274/26050 (epoch 17.800), train_loss = 0.93144089, grad/param norm = 1.4482e-01, time/batch = 15.6299s	
9275/26050 (epoch 17.802), train_loss = 1.02934642, grad/param norm = 1.8241e-01, time/batch = 15.5463s	
9276/26050 (epoch 17.804), train_loss = 1.06056179, grad/param norm = 1.7170e-01, time/batch = 17.1648s	
9277/26050 (epoch 17.806), train_loss = 1.18138500, grad/param norm = 1.8650e-01, time/batch = 3.7498s	
9278/26050 (epoch 17.808), train_loss = 1.08745424, grad/param norm = 1.7975e-01, time/batch = 0.6407s	
9279/26050 (epoch 17.810), train_loss = 1.01504894, grad/param norm = 1.7986e-01, time/batch = 0.6415s	
9280/26050 (epoch 17.812), train_loss = 0.98643659, grad/param norm = 1.8563e-01, time/batch = 0.6517s	
9281/26050 (epoch 17.814), train_loss = 0.97190228, grad/param norm = 1.9250e-01, time/batch = 0.6450s	
9282/26050 (epoch 17.816), train_loss = 1.19867376, grad/param norm = 1.9055e-01, time/batch = 0.6459s	
9283/26050 (epoch 17.818), train_loss = 1.21483079, grad/param norm = 2.1772e-01, time/batch = 0.6440s	
9284/26050 (epoch 17.820), train_loss = 1.10642119, grad/param norm = 1.8142e-01, time/batch = 0.6776s	
9285/26050 (epoch 17.821), train_loss = 1.24251718, grad/param norm = 2.0070e-01, time/batch = 0.9399s	
9286/26050 (epoch 17.823), train_loss = 1.25704183, grad/param norm = 1.9873e-01, time/batch = 0.9403s	
9287/26050 (epoch 17.825), train_loss = 1.08248755, grad/param norm = 1.8784e-01, time/batch = 0.9303s	
9288/26050 (epoch 17.827), train_loss = 1.10075327, grad/param norm = 2.0716e-01, time/batch = 0.9397s	
9289/26050 (epoch 17.829), train_loss = 1.16054240, grad/param norm = 1.8758e-01, time/batch = 0.9421s	
9290/26050 (epoch 17.831), train_loss = 1.21454020, grad/param norm = 1.8446e-01, time/batch = 1.5920s	
9291/26050 (epoch 17.833), train_loss = 1.29937667, grad/param norm = 1.8936e-01, time/batch = 1.7902s	
9292/26050 (epoch 17.835), train_loss = 1.28994578, grad/param norm = 1.9410e-01, time/batch = 2.6732s	
9293/26050 (epoch 17.837), train_loss = 1.08988036, grad/param norm = 1.7587e-01, time/batch = 17.9084s	
9294/26050 (epoch 17.839), train_loss = 1.12544714, grad/param norm = 2.0831e-01, time/batch = 14.6556s	
9295/26050 (epoch 17.841), train_loss = 1.20715266, grad/param norm = 1.8354e-01, time/batch = 15.9645s	
9296/26050 (epoch 17.843), train_loss = 1.10082164, grad/param norm = 1.7410e-01, time/batch = 18.8924s	
9297/26050 (epoch 17.845), train_loss = 1.02113079, grad/param norm = 1.5658e-01, time/batch = 17.9069s	
9298/26050 (epoch 17.846), train_loss = 1.19569760, grad/param norm = 1.7318e-01, time/batch = 17.2353s	
9299/26050 (epoch 17.848), train_loss = 1.09411836, grad/param norm = 1.7844e-01, time/batch = 17.8185s	
9300/26050 (epoch 17.850), train_loss = 0.99732882, grad/param norm = 1.6342e-01, time/batch = 17.7499s	
9301/26050 (epoch 17.852), train_loss = 1.07283388, grad/param norm = 1.7870e-01, time/batch = 18.2320s	
9302/26050 (epoch 17.854), train_loss = 1.07443419, grad/param norm = 1.7224e-01, time/batch = 15.7992s	
9303/26050 (epoch 17.856), train_loss = 1.05241284, grad/param norm = 1.8305e-01, time/batch = 18.2348s	
9304/26050 (epoch 17.858), train_loss = 0.99322194, grad/param norm = 1.7354e-01, time/batch = 18.7505s	
9305/26050 (epoch 17.860), train_loss = 1.12391827, grad/param norm = 1.8902e-01, time/batch = 17.8002s	
9306/26050 (epoch 17.862), train_loss = 1.13529139, grad/param norm = 1.7396e-01, time/batch = 18.2193s	
9307/26050 (epoch 17.864), train_loss = 1.13564213, grad/param norm = 2.1303e-01, time/batch = 18.1397s	
9308/26050 (epoch 17.866), train_loss = 1.03697260, grad/param norm = 1.6976e-01, time/batch = 16.8848s	
9309/26050 (epoch 17.868), train_loss = 1.15171197, grad/param norm = 1.8980e-01, time/batch = 17.5638s	
9310/26050 (epoch 17.869), train_loss = 0.98237187, grad/param norm = 1.6071e-01, time/batch = 18.0945s	
9311/26050 (epoch 17.871), train_loss = 0.92164737, grad/param norm = 1.6636e-01, time/batch = 17.1554s	
9312/26050 (epoch 17.873), train_loss = 1.14406742, grad/param norm = 1.8769e-01, time/batch = 14.4748s	
9313/26050 (epoch 17.875), train_loss = 1.08200304, grad/param norm = 1.8301e-01, time/batch = 17.9865s	
9314/26050 (epoch 17.877), train_loss = 0.98309463, grad/param norm = 1.6873e-01, time/batch = 17.9899s	
9315/26050 (epoch 17.879), train_loss = 1.12743703, grad/param norm = 1.7117e-01, time/batch = 15.7798s	
9316/26050 (epoch 17.881), train_loss = 1.22067890, grad/param norm = 1.8673e-01, time/batch = 16.8054s	
9317/26050 (epoch 17.883), train_loss = 1.14197732, grad/param norm = 1.8506e-01, time/batch = 17.4719s	
9318/26050 (epoch 17.885), train_loss = 0.83290951, grad/param norm = 1.5982e-01, time/batch = 18.6487s	
9319/26050 (epoch 17.887), train_loss = 1.12902437, grad/param norm = 1.7659e-01, time/batch = 18.0624s	
9320/26050 (epoch 17.889), train_loss = 1.04301756, grad/param norm = 1.6182e-01, time/batch = 18.1425s	
9321/26050 (epoch 17.891), train_loss = 0.87981135, grad/param norm = 1.5463e-01, time/batch = 17.7396s	
9322/26050 (epoch 17.893), train_loss = 0.94383935, grad/param norm = 1.6843e-01, time/batch = 17.3301s	
9323/26050 (epoch 17.894), train_loss = 1.05135623, grad/param norm = 1.7806e-01, time/batch = 18.6451s	
9324/26050 (epoch 17.896), train_loss = 1.18359484, grad/param norm = 1.7038e-01, time/batch = 16.8973s	
9325/26050 (epoch 17.898), train_loss = 1.02380019, grad/param norm = 1.8292e-01, time/batch = 15.3673s	
9326/26050 (epoch 17.900), train_loss = 1.13427317, grad/param norm = 1.7570e-01, time/batch = 16.3620s	
9327/26050 (epoch 17.902), train_loss = 1.07776102, grad/param norm = 1.7567e-01, time/batch = 17.3881s	
9328/26050 (epoch 17.904), train_loss = 1.07737792, grad/param norm = 1.7365e-01, time/batch = 17.0482s	
9329/26050 (epoch 17.906), train_loss = 1.07568193, grad/param norm = 1.8743e-01, time/batch = 17.3916s	
9330/26050 (epoch 17.908), train_loss = 1.06631443, grad/param norm = 1.6741e-01, time/batch = 18.4864s	
9331/26050 (epoch 17.910), train_loss = 1.01242174, grad/param norm = 1.6190e-01, time/batch = 18.3847s	
9332/26050 (epoch 17.912), train_loss = 1.31349466, grad/param norm = 2.0499e-01, time/batch = 17.4129s	
9333/26050 (epoch 17.914), train_loss = 1.44916251, grad/param norm = 2.1028e-01, time/batch = 17.2812s	
9334/26050 (epoch 17.916), train_loss = 1.18145256, grad/param norm = 1.8610e-01, time/batch = 17.7427s	
9335/26050 (epoch 17.917), train_loss = 1.12105080, grad/param norm = 2.0797e-01, time/batch = 16.8747s	
9336/26050 (epoch 17.919), train_loss = 1.17939655, grad/param norm = 2.0306e-01, time/batch = 16.3848s	
9337/26050 (epoch 17.921), train_loss = 1.03776618, grad/param norm = 1.8107e-01, time/batch = 16.5577s	
9338/26050 (epoch 17.923), train_loss = 1.11714198, grad/param norm = 1.8967e-01, time/batch = 18.8032s	
9339/26050 (epoch 17.925), train_loss = 1.09404520, grad/param norm = 1.7191e-01, time/batch = 17.1523s	
9340/26050 (epoch 17.927), train_loss = 0.95562963, grad/param norm = 1.4628e-01, time/batch = 18.2266s	
9341/26050 (epoch 17.929), train_loss = 0.97548638, grad/param norm = 1.7666e-01, time/batch = 17.6549s	
9342/26050 (epoch 17.931), train_loss = 1.28355033, grad/param norm = 2.0577e-01, time/batch = 18.4891s	
9343/26050 (epoch 17.933), train_loss = 1.04896840, grad/param norm = 1.7499e-01, time/batch = 17.3985s	
9344/26050 (epoch 17.935), train_loss = 1.07004261, grad/param norm = 1.8274e-01, time/batch = 18.3798s	
9345/26050 (epoch 17.937), train_loss = 1.18185271, grad/param norm = 1.7847e-01, time/batch = 17.6368s	
9346/26050 (epoch 17.939), train_loss = 0.99741781, grad/param norm = 1.5458e-01, time/batch = 16.4733s	
9347/26050 (epoch 17.940), train_loss = 1.07009079, grad/param norm = 1.5815e-01, time/batch = 18.2343s	
9348/26050 (epoch 17.942), train_loss = 1.09949819, grad/param norm = 1.7643e-01, time/batch = 18.4086s	
9349/26050 (epoch 17.944), train_loss = 1.02954732, grad/param norm = 1.6601e-01, time/batch = 17.9040s	
9350/26050 (epoch 17.946), train_loss = 1.21771803, grad/param norm = 1.8529e-01, time/batch = 15.3812s	
9351/26050 (epoch 17.948), train_loss = 0.97121690, grad/param norm = 1.8743e-01, time/batch = 18.4114s	
9352/26050 (epoch 17.950), train_loss = 1.06722803, grad/param norm = 1.8871e-01, time/batch = 18.3890s	
9353/26050 (epoch 17.952), train_loss = 1.21215201, grad/param norm = 2.0345e-01, time/batch = 17.4918s	
9354/26050 (epoch 17.954), train_loss = 1.18706954, grad/param norm = 1.7824e-01, time/batch = 17.8161s	
9355/26050 (epoch 17.956), train_loss = 1.08341771, grad/param norm = 1.8452e-01, time/batch = 18.4754s	
9356/26050 (epoch 17.958), train_loss = 1.02667806, grad/param norm = 1.6762e-01, time/batch = 18.1317s	
9357/26050 (epoch 17.960), train_loss = 1.08954726, grad/param norm = 1.8499e-01, time/batch = 18.1551s	
9358/26050 (epoch 17.962), train_loss = 1.00598098, grad/param norm = 1.5521e-01, time/batch = 17.4940s	
9359/26050 (epoch 17.964), train_loss = 1.07764983, grad/param norm = 1.8174e-01, time/batch = 15.3878s	
9360/26050 (epoch 17.965), train_loss = 1.00612406, grad/param norm = 1.6807e-01, time/batch = 15.1485s	
9361/26050 (epoch 17.967), train_loss = 1.41479106, grad/param norm = 1.9343e-01, time/batch = 17.9801s	
9362/26050 (epoch 17.969), train_loss = 1.06205102, grad/param norm = 1.7339e-01, time/batch = 16.9945s	
9363/26050 (epoch 17.971), train_loss = 1.03574812, grad/param norm = 1.5740e-01, time/batch = 17.0496s	
9364/26050 (epoch 17.973), train_loss = 1.06616727, grad/param norm = 1.9026e-01, time/batch = 19.0563s	
9365/26050 (epoch 17.975), train_loss = 1.13628914, grad/param norm = 1.7024e-01, time/batch = 17.2434s	
9366/26050 (epoch 17.977), train_loss = 1.12362402, grad/param norm = 1.6104e-01, time/batch = 18.0582s	
9367/26050 (epoch 17.979), train_loss = 0.91856148, grad/param norm = 1.6676e-01, time/batch = 18.7310s	
9368/26050 (epoch 17.981), train_loss = 1.22068493, grad/param norm = 1.6908e-01, time/batch = 15.7205s	
9369/26050 (epoch 17.983), train_loss = 1.16762518, grad/param norm = 1.7801e-01, time/batch = 18.4656s	
9370/26050 (epoch 17.985), train_loss = 1.13504810, grad/param norm = 1.7963e-01, time/batch = 17.5696s	
9371/26050 (epoch 17.987), train_loss = 1.20113506, grad/param norm = 1.6961e-01, time/batch = 18.4932s	
9372/26050 (epoch 17.988), train_loss = 1.18276465, grad/param norm = 1.7648e-01, time/batch = 18.4950s	
9373/26050 (epoch 17.990), train_loss = 0.96527165, grad/param norm = 1.4961e-01, time/batch = 17.2972s	
9374/26050 (epoch 17.992), train_loss = 1.24146291, grad/param norm = 1.8871e-01, time/batch = 15.4743s	
9375/26050 (epoch 17.994), train_loss = 1.06455795, grad/param norm = 1.8441e-01, time/batch = 17.4047s	
9376/26050 (epoch 17.996), train_loss = 1.04797485, grad/param norm = 1.9281e-01, time/batch = 16.3172s	
9377/26050 (epoch 17.998), train_loss = 1.10124955, grad/param norm = 1.6910e-01, time/batch = 16.6316s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
9378/26050 (epoch 18.000), train_loss = 1.03674574, grad/param norm = 1.8916e-01, time/batch = 18.1423s	
9379/26050 (epoch 18.002), train_loss = 1.17127179, grad/param norm = 2.0334e-01, time/batch = 18.1508s	
9380/26050 (epoch 18.004), train_loss = 1.00038258, grad/param norm = 1.7761e-01, time/batch = 18.0749s	
9381/26050 (epoch 18.006), train_loss = 1.02792889, grad/param norm = 1.8319e-01, time/batch = 17.8884s	
9382/26050 (epoch 18.008), train_loss = 1.00043291, grad/param norm = 1.9181e-01, time/batch = 16.0381s	
9383/26050 (epoch 18.010), train_loss = 1.01447972, grad/param norm = 1.6908e-01, time/batch = 17.6516s	
9384/26050 (epoch 18.012), train_loss = 1.10409271, grad/param norm = 1.7444e-01, time/batch = 17.3018s	
9385/26050 (epoch 18.013), train_loss = 1.41910102, grad/param norm = 2.1691e-01, time/batch = 17.8234s	
9386/26050 (epoch 18.015), train_loss = 1.03212546, grad/param norm = 1.5458e-01, time/batch = 18.2279s	
9387/26050 (epoch 18.017), train_loss = 1.10662979, grad/param norm = 1.7599e-01, time/batch = 17.3121s	
9388/26050 (epoch 18.019), train_loss = 0.92780563, grad/param norm = 1.5424e-01, time/batch = 17.6706s	
9389/26050 (epoch 18.021), train_loss = 1.15389193, grad/param norm = 1.7262e-01, time/batch = 14.4724s	
9390/26050 (epoch 18.023), train_loss = 0.92723456, grad/param norm = 1.8213e-01, time/batch = 18.1592s	
9391/26050 (epoch 18.025), train_loss = 1.08466323, grad/param norm = 1.7457e-01, time/batch = 17.8147s	
9392/26050 (epoch 18.027), train_loss = 0.87887357, grad/param norm = 1.6918e-01, time/batch = 17.3099s	
9393/26050 (epoch 18.029), train_loss = 1.10949891, grad/param norm = 1.6730e-01, time/batch = 17.0555s	
9394/26050 (epoch 18.031), train_loss = 1.22562722, grad/param norm = 2.2103e-01, time/batch = 15.3767s	
9395/26050 (epoch 18.033), train_loss = 1.12651111, grad/param norm = 1.8775e-01, time/batch = 17.2354s	
9396/26050 (epoch 18.035), train_loss = 1.13903583, grad/param norm = 1.7655e-01, time/batch = 17.5078s	
9397/26050 (epoch 18.036), train_loss = 0.99851764, grad/param norm = 1.8999e-01, time/batch = 17.7335s	
9398/26050 (epoch 18.038), train_loss = 0.90310533, grad/param norm = 1.6101e-01, time/batch = 18.0726s	
9399/26050 (epoch 18.040), train_loss = 1.09715074, grad/param norm = 1.9726e-01, time/batch = 17.4993s	
9400/26050 (epoch 18.042), train_loss = 0.93005822, grad/param norm = 1.6297e-01, time/batch = 18.7370s	
9401/26050 (epoch 18.044), train_loss = 1.17197897, grad/param norm = 1.6737e-01, time/batch = 17.4083s	
9402/26050 (epoch 18.046), train_loss = 0.86225966, grad/param norm = 1.3752e-01, time/batch = 18.4697s	
9403/26050 (epoch 18.048), train_loss = 1.10035861, grad/param norm = 1.7584e-01, time/batch = 17.8205s	
9404/26050 (epoch 18.050), train_loss = 1.00176123, grad/param norm = 1.6519e-01, time/batch = 17.3221s	
9405/26050 (epoch 18.052), train_loss = 1.03449728, grad/param norm = 1.9305e-01, time/batch = 15.8560s	
9406/26050 (epoch 18.054), train_loss = 0.92095995, grad/param norm = 1.5637e-01, time/batch = 14.3893s	
9407/26050 (epoch 18.056), train_loss = 0.87227509, grad/param norm = 1.4752e-01, time/batch = 17.8866s	
9408/26050 (epoch 18.058), train_loss = 1.04477942, grad/param norm = 1.6960e-01, time/batch = 18.2337s	
9409/26050 (epoch 18.060), train_loss = 1.12941436, grad/param norm = 1.7841e-01, time/batch = 18.2278s	
9410/26050 (epoch 18.061), train_loss = 0.98914984, grad/param norm = 1.6786e-01, time/batch = 18.5497s	
9411/26050 (epoch 18.063), train_loss = 1.13018857, grad/param norm = 1.8152e-01, time/batch = 15.3820s	
9412/26050 (epoch 18.065), train_loss = 0.89153596, grad/param norm = 1.5266e-01, time/batch = 18.8064s	
9413/26050 (epoch 18.067), train_loss = 1.09839339, grad/param norm = 1.8994e-01, time/batch = 16.4819s	
9414/26050 (epoch 18.069), train_loss = 1.13890164, grad/param norm = 1.8248e-01, time/batch = 14.9776s	
9415/26050 (epoch 18.071), train_loss = 1.14503911, grad/param norm = 1.7367e-01, time/batch = 16.0569s	
9416/26050 (epoch 18.073), train_loss = 1.26025525, grad/param norm = 1.9719e-01, time/batch = 18.2276s	
9417/26050 (epoch 18.075), train_loss = 1.00388818, grad/param norm = 1.7533e-01, time/batch = 18.0606s	
9418/26050 (epoch 18.077), train_loss = 0.99791016, grad/param norm = 1.6719e-01, time/batch = 17.1599s	
9419/26050 (epoch 18.079), train_loss = 1.11052469, grad/param norm = 1.8249e-01, time/batch = 18.8842s	
9420/26050 (epoch 18.081), train_loss = 1.04760891, grad/param norm = 1.9257e-01, time/batch = 18.0605s	
9421/26050 (epoch 18.083), train_loss = 1.14487600, grad/param norm = 1.6757e-01, time/batch = 18.3091s	
9422/26050 (epoch 18.084), train_loss = 1.09947255, grad/param norm = 1.9531e-01, time/batch = 16.7322s	
9423/26050 (epoch 18.086), train_loss = 1.23219984, grad/param norm = 1.9068e-01, time/batch = 15.7267s	
9424/26050 (epoch 18.088), train_loss = 0.97855207, grad/param norm = 1.7136e-01, time/batch = 18.3917s	
9425/26050 (epoch 18.090), train_loss = 1.11742740, grad/param norm = 1.8845e-01, time/batch = 16.0350s	
9426/26050 (epoch 18.092), train_loss = 1.13269238, grad/param norm = 1.7045e-01, time/batch = 16.9803s	
9427/26050 (epoch 18.094), train_loss = 1.02508367, grad/param norm = 1.6888e-01, time/batch = 17.4908s	
9428/26050 (epoch 18.096), train_loss = 1.06607272, grad/param norm = 1.6526e-01, time/batch = 17.7210s	
9429/26050 (epoch 18.098), train_loss = 1.03166090, grad/param norm = 1.7821e-01, time/batch = 18.2353s	
9430/26050 (epoch 18.100), train_loss = 0.96237041, grad/param norm = 1.7017e-01, time/batch = 17.9841s	
9431/26050 (epoch 18.102), train_loss = 1.10160032, grad/param norm = 1.7779e-01, time/batch = 18.4093s	
9432/26050 (epoch 18.104), train_loss = 1.09009419, grad/param norm = 1.9563e-01, time/batch = 18.1494s	
9433/26050 (epoch 18.106), train_loss = 1.08479804, grad/param norm = 1.9174e-01, time/batch = 18.3965s	
9434/26050 (epoch 18.107), train_loss = 0.86590620, grad/param norm = 1.5113e-01, time/batch = 17.5572s	
9435/26050 (epoch 18.109), train_loss = 1.00285416, grad/param norm = 1.7990e-01, time/batch = 16.3720s	
9436/26050 (epoch 18.111), train_loss = 1.25530459, grad/param norm = 1.9536e-01, time/batch = 16.9734s	
9437/26050 (epoch 18.113), train_loss = 1.02512408, grad/param norm = 1.7410e-01, time/batch = 15.6332s	
9438/26050 (epoch 18.115), train_loss = 1.17881426, grad/param norm = 1.7398e-01, time/batch = 17.8062s	
9439/26050 (epoch 18.117), train_loss = 1.10465164, grad/param norm = 1.7064e-01, time/batch = 18.1449s	
9440/26050 (epoch 18.119), train_loss = 0.90508079, grad/param norm = 1.6158e-01, time/batch = 18.5615s	
9441/26050 (epoch 18.121), train_loss = 1.10673489, grad/param norm = 1.7342e-01, time/batch = 16.4655s	
9442/26050 (epoch 18.123), train_loss = 0.96853002, grad/param norm = 1.6325e-01, time/batch = 17.3154s	
9443/26050 (epoch 18.125), train_loss = 0.94357546, grad/param norm = 1.6998e-01, time/batch = 18.9048s	
9444/26050 (epoch 18.127), train_loss = 0.86286808, grad/param norm = 1.6274e-01, time/batch = 17.6489s	
9445/26050 (epoch 18.129), train_loss = 0.91922337, grad/param norm = 1.8179e-01, time/batch = 17.3072s	
9446/26050 (epoch 18.131), train_loss = 1.04539200, grad/param norm = 1.7214e-01, time/batch = 18.0728s	
9447/26050 (epoch 18.132), train_loss = 1.04184606, grad/param norm = 1.6707e-01, time/batch = 18.6649s	
9448/26050 (epoch 18.134), train_loss = 1.07698334, grad/param norm = 1.9844e-01, time/batch = 17.4038s	
9449/26050 (epoch 18.136), train_loss = 1.06678744, grad/param norm = 1.6901e-01, time/batch = 17.9780s	
9450/26050 (epoch 18.138), train_loss = 0.83544551, grad/param norm = 1.5993e-01, time/batch = 16.6359s	
9451/26050 (epoch 18.140), train_loss = 0.90067086, grad/param norm = 1.7416e-01, time/batch = 15.3052s	
9452/26050 (epoch 18.142), train_loss = 0.94411882, grad/param norm = 1.7161e-01, time/batch = 16.5781s	
9453/26050 (epoch 18.144), train_loss = 0.87248059, grad/param norm = 1.5801e-01, time/batch = 18.5741s	
9454/26050 (epoch 18.146), train_loss = 0.80511814, grad/param norm = 1.6099e-01, time/batch = 18.0798s	
9455/26050 (epoch 18.148), train_loss = 0.84727959, grad/param norm = 1.4556e-01, time/batch = 17.9849s	
9456/26050 (epoch 18.150), train_loss = 1.04043000, grad/param norm = 1.8445e-01, time/batch = 17.9925s	
9457/26050 (epoch 18.152), train_loss = 1.25353242, grad/param norm = 2.2424e-01, time/batch = 14.8070s	
9458/26050 (epoch 18.154), train_loss = 0.83885947, grad/param norm = 1.9188e-01, time/batch = 17.8067s	
9459/26050 (epoch 18.155), train_loss = 0.87923828, grad/param norm = 1.5656e-01, time/batch = 17.3165s	
9460/26050 (epoch 18.157), train_loss = 0.99195270, grad/param norm = 2.0472e-01, time/batch = 17.9134s	
9461/26050 (epoch 18.159), train_loss = 1.05590168, grad/param norm = 1.9070e-01, time/batch = 17.9790s	
9462/26050 (epoch 18.161), train_loss = 1.12017687, grad/param norm = 1.9305e-01, time/batch = 18.6295s	
9463/26050 (epoch 18.163), train_loss = 0.88563446, grad/param norm = 1.6727e-01, time/batch = 31.5066s	
9464/26050 (epoch 18.165), train_loss = 0.80493199, grad/param norm = 1.6243e-01, time/batch = 23.9775s	
9465/26050 (epoch 18.167), train_loss = 1.14302106, grad/param norm = 1.8341e-01, time/batch = 17.7418s	
9466/26050 (epoch 18.169), train_loss = 1.10346813, grad/param norm = 1.8538e-01, time/batch = 16.7971s	
9467/26050 (epoch 18.171), train_loss = 0.86292513, grad/param norm = 1.5416e-01, time/batch = 18.3245s	
9468/26050 (epoch 18.173), train_loss = 0.98300390, grad/param norm = 1.7384e-01, time/batch = 17.4655s	
9469/26050 (epoch 18.175), train_loss = 1.03122133, grad/param norm = 1.6797e-01, time/batch = 19.0702s	
9470/26050 (epoch 18.177), train_loss = 1.15483348, grad/param norm = 1.7219e-01, time/batch = 14.4819s	
9471/26050 (epoch 18.179), train_loss = 0.82976205, grad/param norm = 1.6021e-01, time/batch = 17.4720s	
9472/26050 (epoch 18.180), train_loss = 1.27621285, grad/param norm = 1.8810e-01, time/batch = 18.3137s	
9473/26050 (epoch 18.182), train_loss = 1.27392471, grad/param norm = 1.8942e-01, time/batch = 15.8845s	
9474/26050 (epoch 18.184), train_loss = 1.08379817, grad/param norm = 1.7438e-01, time/batch = 18.2306s	
9475/26050 (epoch 18.186), train_loss = 0.87805992, grad/param norm = 1.5443e-01, time/batch = 17.3184s	
9476/26050 (epoch 18.188), train_loss = 1.04269513, grad/param norm = 1.7882e-01, time/batch = 17.7423s	
9477/26050 (epoch 18.190), train_loss = 1.11299445, grad/param norm = 1.8086e-01, time/batch = 17.4872s	
9478/26050 (epoch 18.192), train_loss = 1.11407145, grad/param norm = 1.6823e-01, time/batch = 17.6490s	
9479/26050 (epoch 18.194), train_loss = 1.09706544, grad/param norm = 1.7611e-01, time/batch = 18.3262s	
9480/26050 (epoch 18.196), train_loss = 1.14874612, grad/param norm = 1.8291e-01, time/batch = 18.3974s	
9481/26050 (epoch 18.198), train_loss = 0.97873831, grad/param norm = 1.6449e-01, time/batch = 17.4919s	
9482/26050 (epoch 18.200), train_loss = 0.97122536, grad/param norm = 1.6693e-01, time/batch = 17.3976s	
9483/26050 (epoch 18.202), train_loss = 1.03803221, grad/param norm = 1.7448e-01, time/batch = 18.8996s	
9484/26050 (epoch 18.203), train_loss = 1.18294262, grad/param norm = 1.9657e-01, time/batch = 17.0776s	
9485/26050 (epoch 18.205), train_loss = 0.99688322, grad/param norm = 1.7056e-01, time/batch = 16.1272s	
9486/26050 (epoch 18.207), train_loss = 0.99227241, grad/param norm = 1.6265e-01, time/batch = 18.3999s	
9487/26050 (epoch 18.209), train_loss = 1.09070761, grad/param norm = 1.7525e-01, time/batch = 16.5450s	
9488/26050 (epoch 18.211), train_loss = 0.89116019, grad/param norm = 1.5430e-01, time/batch = 17.9951s	
9489/26050 (epoch 18.213), train_loss = 1.11416743, grad/param norm = 1.8383e-01, time/batch = 18.2364s	
9490/26050 (epoch 18.215), train_loss = 1.04720081, grad/param norm = 1.8945e-01, time/batch = 18.3061s	
9491/26050 (epoch 18.217), train_loss = 1.03637654, grad/param norm = 1.7421e-01, time/batch = 16.5442s	
9492/26050 (epoch 18.219), train_loss = 1.03802589, grad/param norm = 1.9158e-01, time/batch = 17.8804s	
9493/26050 (epoch 18.221), train_loss = 0.96107114, grad/param norm = 1.7740e-01, time/batch = 18.5421s	
9494/26050 (epoch 18.223), train_loss = 1.07753916, grad/param norm = 1.7274e-01, time/batch = 18.3866s	
9495/26050 (epoch 18.225), train_loss = 0.95222367, grad/param norm = 1.6746e-01, time/batch = 16.5650s	
9496/26050 (epoch 18.226), train_loss = 1.11090793, grad/param norm = 1.9192e-01, time/batch = 17.9759s	
9497/26050 (epoch 18.228), train_loss = 1.18594653, grad/param norm = 1.8408e-01, time/batch = 18.8117s	
9498/26050 (epoch 18.230), train_loss = 1.09684536, grad/param norm = 1.7516e-01, time/batch = 17.5762s	
9499/26050 (epoch 18.232), train_loss = 1.16937236, grad/param norm = 1.9536e-01, time/batch = 16.3951s	
9500/26050 (epoch 18.234), train_loss = 0.93844977, grad/param norm = 1.7280e-01, time/batch = 15.3109s	
9501/26050 (epoch 18.236), train_loss = 1.15358038, grad/param norm = 1.9434e-01, time/batch = 18.2273s	
9502/26050 (epoch 18.238), train_loss = 0.91155875, grad/param norm = 1.5978e-01, time/batch = 17.7285s	
9503/26050 (epoch 18.240), train_loss = 1.05989016, grad/param norm = 1.9674e-01, time/batch = 14.9644s	
9504/26050 (epoch 18.242), train_loss = 1.07132698, grad/param norm = 1.6945e-01, time/batch = 17.7354s	
9505/26050 (epoch 18.244), train_loss = 1.04629841, grad/param norm = 1.9717e-01, time/batch = 17.4042s	
9506/26050 (epoch 18.246), train_loss = 0.99794093, grad/param norm = 1.7146e-01, time/batch = 18.1373s	
9507/26050 (epoch 18.248), train_loss = 1.05920617, grad/param norm = 1.7337e-01, time/batch = 18.5691s	
9508/26050 (epoch 18.250), train_loss = 1.07418767, grad/param norm = 2.0843e-01, time/batch = 18.0764s	
9509/26050 (epoch 18.251), train_loss = 1.02582996, grad/param norm = 1.7143e-01, time/batch = 17.4015s	
9510/26050 (epoch 18.253), train_loss = 0.92552038, grad/param norm = 1.6493e-01, time/batch = 17.9991s	
9511/26050 (epoch 18.255), train_loss = 1.23682411, grad/param norm = 1.8664e-01, time/batch = 18.1387s	
9512/26050 (epoch 18.257), train_loss = 1.04705411, grad/param norm = 1.8273e-01, time/batch = 16.4852s	
9513/26050 (epoch 18.259), train_loss = 1.19916247, grad/param norm = 1.8641e-01, time/batch = 18.8917s	
9514/26050 (epoch 18.261), train_loss = 0.95416581, grad/param norm = 1.7837e-01, time/batch = 15.6403s	
9515/26050 (epoch 18.263), train_loss = 1.11199498, grad/param norm = 1.7967e-01, time/batch = 17.7286s	
9516/26050 (epoch 18.265), train_loss = 1.23217878, grad/param norm = 1.9010e-01, time/batch = 17.5742s	
9517/26050 (epoch 18.267), train_loss = 1.16690985, grad/param norm = 1.7262e-01, time/batch = 18.4821s	
9518/26050 (epoch 18.269), train_loss = 1.21303228, grad/param norm = 1.8995e-01, time/batch = 17.5678s	
9519/26050 (epoch 18.271), train_loss = 1.11530244, grad/param norm = 1.7806e-01, time/batch = 17.9035s	
9520/26050 (epoch 18.273), train_loss = 1.02393055, grad/param norm = 1.9228e-01, time/batch = 17.3792s	
9521/26050 (epoch 18.274), train_loss = 1.02945810, grad/param norm = 1.6945e-01, time/batch = 18.2283s	
9522/26050 (epoch 18.276), train_loss = 1.01899011, grad/param norm = 1.8600e-01, time/batch = 15.4639s	
9523/26050 (epoch 18.278), train_loss = 1.18885758, grad/param norm = 1.7588e-01, time/batch = 17.7475s	
9524/26050 (epoch 18.280), train_loss = 1.05098372, grad/param norm = 1.6828e-01, time/batch = 18.1602s	
9525/26050 (epoch 18.282), train_loss = 1.08891242, grad/param norm = 1.6535e-01, time/batch = 15.2470s	
9526/26050 (epoch 18.284), train_loss = 1.00234776, grad/param norm = 1.7218e-01, time/batch = 16.8000s	
9527/26050 (epoch 18.286), train_loss = 1.07885425, grad/param norm = 1.7793e-01, time/batch = 16.4936s	
9528/26050 (epoch 18.288), train_loss = 0.91408746, grad/param norm = 1.5866e-01, time/batch = 18.1604s	
9529/26050 (epoch 18.290), train_loss = 1.06121515, grad/param norm = 1.8080e-01, time/batch = 17.5685s	
9530/26050 (epoch 18.292), train_loss = 0.97659781, grad/param norm = 1.6493e-01, time/batch = 15.3977s	
9531/26050 (epoch 18.294), train_loss = 1.09110819, grad/param norm = 1.9460e-01, time/batch = 18.8857s	
9532/26050 (epoch 18.296), train_loss = 1.17168558, grad/param norm = 1.8688e-01, time/batch = 18.1509s	
9533/26050 (epoch 18.298), train_loss = 1.06011988, grad/param norm = 1.6955e-01, time/batch = 18.1468s	
9534/26050 (epoch 18.299), train_loss = 0.83942043, grad/param norm = 1.4888e-01, time/batch = 18.1638s	
9535/26050 (epoch 18.301), train_loss = 0.94859562, grad/param norm = 1.8097e-01, time/batch = 17.8207s	
9536/26050 (epoch 18.303), train_loss = 1.07525659, grad/param norm = 1.8590e-01, time/batch = 17.1553s	
9537/26050 (epoch 18.305), train_loss = 0.89553312, grad/param norm = 1.8591e-01, time/batch = 14.5578s	
9538/26050 (epoch 18.307), train_loss = 0.97382363, grad/param norm = 1.6997e-01, time/batch = 17.3989s	
9539/26050 (epoch 18.309), train_loss = 1.04003898, grad/param norm = 1.7435e-01, time/batch = 16.9726s	
9540/26050 (epoch 18.311), train_loss = 1.16912359, grad/param norm = 2.2753e-01, time/batch = 18.1395s	
9541/26050 (epoch 18.313), train_loss = 1.04840902, grad/param norm = 1.9979e-01, time/batch = 18.8016s	
9542/26050 (epoch 18.315), train_loss = 1.16270881, grad/param norm = 1.8382e-01, time/batch = 17.7340s	
9543/26050 (epoch 18.317), train_loss = 1.05713065, grad/param norm = 1.7661e-01, time/batch = 15.7117s	
9544/26050 (epoch 18.319), train_loss = 1.00265973, grad/param norm = 1.7213e-01, time/batch = 18.4054s	
9545/26050 (epoch 18.321), train_loss = 1.03010851, grad/param norm = 1.7635e-01, time/batch = 17.1523s	
9546/26050 (epoch 18.322), train_loss = 1.08971316, grad/param norm = 1.7516e-01, time/batch = 17.7875s	
9547/26050 (epoch 18.324), train_loss = 0.89449219, grad/param norm = 1.7783e-01, time/batch = 18.1391s	
9548/26050 (epoch 18.326), train_loss = 1.20000526, grad/param norm = 1.8498e-01, time/batch = 15.6517s	
9549/26050 (epoch 18.328), train_loss = 1.10884792, grad/param norm = 1.7625e-01, time/batch = 17.5679s	
9550/26050 (epoch 18.330), train_loss = 0.94633056, grad/param norm = 1.7179e-01, time/batch = 17.4074s	
9551/26050 (epoch 18.332), train_loss = 1.10451012, grad/param norm = 1.6997e-01, time/batch = 18.5709s	
9552/26050 (epoch 18.334), train_loss = 1.02213828, grad/param norm = 1.8489e-01, time/batch = 17.3018s	
9553/26050 (epoch 18.336), train_loss = 0.99480444, grad/param norm = 1.7959e-01, time/batch = 17.2243s	
9554/26050 (epoch 18.338), train_loss = 0.93231250, grad/param norm = 1.5227e-01, time/batch = 17.9109s	
9555/26050 (epoch 18.340), train_loss = 1.16864070, grad/param norm = 1.9530e-01, time/batch = 17.7409s	
9556/26050 (epoch 18.342), train_loss = 1.18574709, grad/param norm = 1.9174e-01, time/batch = 18.4752s	
9557/26050 (epoch 18.344), train_loss = 1.01473230, grad/param norm = 1.8065e-01, time/batch = 17.7316s	
9558/26050 (epoch 18.345), train_loss = 1.02879003, grad/param norm = 1.6675e-01, time/batch = 18.1647s	
9559/26050 (epoch 18.347), train_loss = 1.18127750, grad/param norm = 1.8715e-01, time/batch = 15.4458s	
9560/26050 (epoch 18.349), train_loss = 1.11126089, grad/param norm = 1.8156e-01, time/batch = 16.6389s	
9561/26050 (epoch 18.351), train_loss = 1.07701735, grad/param norm = 1.7005e-01, time/batch = 18.5786s	
9562/26050 (epoch 18.353), train_loss = 1.06346520, grad/param norm = 1.8952e-01, time/batch = 17.0802s	
9563/26050 (epoch 18.355), train_loss = 1.12138071, grad/param norm = 1.9193e-01, time/batch = 17.8991s	
9564/26050 (epoch 18.357), train_loss = 0.99622358, grad/param norm = 1.6677e-01, time/batch = 17.9682s	
9565/26050 (epoch 18.359), train_loss = 1.14920055, grad/param norm = 1.7564e-01, time/batch = 18.5752s	
9566/26050 (epoch 18.361), train_loss = 0.99022548, grad/param norm = 1.7216e-01, time/batch = 17.3739s	
9567/26050 (epoch 18.363), train_loss = 1.12601741, grad/param norm = 1.7471e-01, time/batch = 17.2991s	
9568/26050 (epoch 18.365), train_loss = 1.04058581, grad/param norm = 1.6145e-01, time/batch = 18.3872s	
9569/26050 (epoch 18.367), train_loss = 1.09937007, grad/param norm = 1.6854e-01, time/batch = 17.0591s	
9570/26050 (epoch 18.369), train_loss = 1.02183282, grad/param norm = 1.6731e-01, time/batch = 17.7195s	
9571/26050 (epoch 18.370), train_loss = 0.94743669, grad/param norm = 1.5784e-01, time/batch = 17.5580s	
9572/26050 (epoch 18.372), train_loss = 1.12207392, grad/param norm = 1.8288e-01, time/batch = 17.7470s	
9573/26050 (epoch 18.374), train_loss = 1.20934055, grad/param norm = 1.9363e-01, time/batch = 18.5687s	
9574/26050 (epoch 18.376), train_loss = 1.27819471, grad/param norm = 1.8789e-01, time/batch = 17.1302s	
9575/26050 (epoch 18.378), train_loss = 1.04321382, grad/param norm = 1.7745e-01, time/batch = 18.2311s	
9576/26050 (epoch 18.380), train_loss = 1.26070616, grad/param norm = 2.0876e-01, time/batch = 18.2276s	
9577/26050 (epoch 18.382), train_loss = 1.34946494, grad/param norm = 2.2687e-01, time/batch = 15.3682s	
9578/26050 (epoch 18.384), train_loss = 1.06599555, grad/param norm = 1.9179e-01, time/batch = 17.8987s	
9579/26050 (epoch 18.386), train_loss = 1.15629062, grad/param norm = 2.1644e-01, time/batch = 17.3119s	
9580/26050 (epoch 18.388), train_loss = 1.08921304, grad/param norm = 1.8586e-01, time/batch = 17.9690s	
9581/26050 (epoch 18.390), train_loss = 0.99432250, grad/param norm = 1.7253e-01, time/batch = 18.2397s	
9582/26050 (epoch 18.392), train_loss = 0.93812697, grad/param norm = 1.5651e-01, time/batch = 18.2215s	
9583/26050 (epoch 18.393), train_loss = 1.12634867, grad/param norm = 2.0848e-01, time/batch = 17.2272s	
9584/26050 (epoch 18.395), train_loss = 1.12183186, grad/param norm = 1.6896e-01, time/batch = 17.2930s	
9585/26050 (epoch 18.397), train_loss = 1.13256886, grad/param norm = 2.1690e-01, time/batch = 18.2294s	
9586/26050 (epoch 18.399), train_loss = 0.98078751, grad/param norm = 1.7746e-01, time/batch = 17.9737s	
9587/26050 (epoch 18.401), train_loss = 1.05895228, grad/param norm = 1.6944e-01, time/batch = 17.3950s	
9588/26050 (epoch 18.403), train_loss = 1.10025252, grad/param norm = 1.8637e-01, time/batch = 18.4663s	
9589/26050 (epoch 18.405), train_loss = 1.08447873, grad/param norm = 1.7978e-01, time/batch = 18.5479s	
9590/26050 (epoch 18.407), train_loss = 1.21419851, grad/param norm = 1.9315e-01, time/batch = 15.1470s	
9591/26050 (epoch 18.409), train_loss = 1.25112046, grad/param norm = 1.9011e-01, time/batch = 17.8998s	
9592/26050 (epoch 18.411), train_loss = 1.14210584, grad/param norm = 2.2128e-01, time/batch = 16.0351s	
9593/26050 (epoch 18.413), train_loss = 1.22776133, grad/param norm = 1.7200e-01, time/batch = 18.6496s	
9594/26050 (epoch 18.415), train_loss = 1.19306454, grad/param norm = 2.0222e-01, time/batch = 17.2472s	
9595/26050 (epoch 18.417), train_loss = 1.29030003, grad/param norm = 1.9952e-01, time/batch = 18.7199s	
9596/26050 (epoch 18.418), train_loss = 1.19123115, grad/param norm = 2.0548e-01, time/batch = 17.8712s	
9597/26050 (epoch 18.420), train_loss = 0.91126748, grad/param norm = 1.6161e-01, time/batch = 15.7788s	
9598/26050 (epoch 18.422), train_loss = 0.92971051, grad/param norm = 1.6788e-01, time/batch = 17.7345s	
9599/26050 (epoch 18.424), train_loss = 1.22123525, grad/param norm = 2.0526e-01, time/batch = 18.3994s	
9600/26050 (epoch 18.426), train_loss = 1.19221791, grad/param norm = 1.8684e-01, time/batch = 15.2229s	
9601/26050 (epoch 18.428), train_loss = 0.99379513, grad/param norm = 1.6886e-01, time/batch = 17.4114s	
9602/26050 (epoch 18.430), train_loss = 1.17685501, grad/param norm = 1.8729e-01, time/batch = 14.6305s	
9603/26050 (epoch 18.432), train_loss = 1.04978349, grad/param norm = 1.7695e-01, time/batch = 15.4923s	
9604/26050 (epoch 18.434), train_loss = 1.05565038, grad/param norm = 1.9378e-01, time/batch = 18.2435s	
9605/26050 (epoch 18.436), train_loss = 1.19838216, grad/param norm = 1.8746e-01, time/batch = 15.4801s	
9606/26050 (epoch 18.438), train_loss = 1.08609296, grad/param norm = 1.8390e-01, time/batch = 18.0564s	
9607/26050 (epoch 18.440), train_loss = 1.09284722, grad/param norm = 1.7760e-01, time/batch = 18.7380s	
9608/26050 (epoch 18.441), train_loss = 1.07384231, grad/param norm = 1.8792e-01, time/batch = 17.6593s	
9609/26050 (epoch 18.443), train_loss = 0.91695121, grad/param norm = 1.5395e-01, time/batch = 17.7327s	
9610/26050 (epoch 18.445), train_loss = 0.98759072, grad/param norm = 1.6697e-01, time/batch = 18.6560s	
9611/26050 (epoch 18.447), train_loss = 1.21867306, grad/param norm = 1.9636e-01, time/batch = 16.9542s	
9612/26050 (epoch 18.449), train_loss = 0.98782577, grad/param norm = 1.8264e-01, time/batch = 15.3881s	
9613/26050 (epoch 18.451), train_loss = 1.23088331, grad/param norm = 1.8755e-01, time/batch = 17.3374s	
9614/26050 (epoch 18.453), train_loss = 0.99883157, grad/param norm = 1.5993e-01, time/batch = 18.9050s	
9615/26050 (epoch 18.455), train_loss = 1.10824735, grad/param norm = 1.6866e-01, time/batch = 17.2251s	
9616/26050 (epoch 18.457), train_loss = 1.09049937, grad/param norm = 1.7877e-01, time/batch = 18.1483s	
9617/26050 (epoch 18.459), train_loss = 1.19154194, grad/param norm = 1.9141e-01, time/batch = 17.9752s	
9618/26050 (epoch 18.461), train_loss = 1.16312362, grad/param norm = 1.9201e-01, time/batch = 17.5585s	
9619/26050 (epoch 18.463), train_loss = 1.03367363, grad/param norm = 1.6654e-01, time/batch = 16.0141s	
9620/26050 (epoch 18.464), train_loss = 1.12632399, grad/param norm = 1.8369e-01, time/batch = 18.0547s	
9621/26050 (epoch 18.466), train_loss = 1.16163506, grad/param norm = 2.0104e-01, time/batch = 18.0600s	
9622/26050 (epoch 18.468), train_loss = 1.16523222, grad/param norm = 1.6087e-01, time/batch = 18.8155s	
9623/26050 (epoch 18.470), train_loss = 1.25159924, grad/param norm = 2.0499e-01, time/batch = 18.0621s	
9624/26050 (epoch 18.472), train_loss = 1.21786661, grad/param norm = 2.0547e-01, time/batch = 15.3768s	
9625/26050 (epoch 18.474), train_loss = 1.26471164, grad/param norm = 1.7638e-01, time/batch = 16.1395s	
9626/26050 (epoch 18.476), train_loss = 1.21144647, grad/param norm = 1.7942e-01, time/batch = 18.0623s	
9627/26050 (epoch 18.478), train_loss = 1.04883887, grad/param norm = 1.7690e-01, time/batch = 18.2294s	
9628/26050 (epoch 18.480), train_loss = 1.10493432, grad/param norm = 1.7730e-01, time/batch = 17.5680s	
9629/26050 (epoch 18.482), train_loss = 1.04498703, grad/param norm = 1.8250e-01, time/batch = 18.4830s	
9630/26050 (epoch 18.484), train_loss = 1.03915972, grad/param norm = 1.8536e-01, time/batch = 16.8139s	
9631/26050 (epoch 18.486), train_loss = 1.23910039, grad/param norm = 1.8690e-01, time/batch = 15.5664s	
9632/26050 (epoch 18.488), train_loss = 1.34780095, grad/param norm = 1.9576e-01, time/batch = 16.4039s	
9633/26050 (epoch 18.489), train_loss = 1.30005073, grad/param norm = 2.1514e-01, time/batch = 18.5768s	
9634/26050 (epoch 18.491), train_loss = 0.99260390, grad/param norm = 1.7540e-01, time/batch = 15.0680s	
9635/26050 (epoch 18.493), train_loss = 1.10591729, grad/param norm = 1.8362e-01, time/batch = 17.7211s	
9636/26050 (epoch 18.495), train_loss = 1.07881322, grad/param norm = 1.7008e-01, time/batch = 17.5645s	
9637/26050 (epoch 18.497), train_loss = 1.00075977, grad/param norm = 1.6993e-01, time/batch = 18.0695s	
9638/26050 (epoch 18.499), train_loss = 1.04241537, grad/param norm = 1.7087e-01, time/batch = 18.6639s	
9639/26050 (epoch 18.501), train_loss = 1.15511773, grad/param norm = 1.8197e-01, time/batch = 17.4757s	
9640/26050 (epoch 18.503), train_loss = 1.03032150, grad/param norm = 1.7521e-01, time/batch = 18.3278s	
9641/26050 (epoch 18.505), train_loss = 1.21561787, grad/param norm = 1.6983e-01, time/batch = 16.7310s	
9642/26050 (epoch 18.507), train_loss = 1.16840412, grad/param norm = 1.9224e-01, time/batch = 15.5474s	
9643/26050 (epoch 18.509), train_loss = 1.27896761, grad/param norm = 1.8980e-01, time/batch = 16.3626s	
9644/26050 (epoch 18.511), train_loss = 1.00976496, grad/param norm = 1.6060e-01, time/batch = 16.4613s	
9645/26050 (epoch 18.512), train_loss = 1.02137835, grad/param norm = 1.9241e-01, time/batch = 18.7267s	
9646/26050 (epoch 18.514), train_loss = 1.16152308, grad/param norm = 1.7967e-01, time/batch = 18.2353s	
9647/26050 (epoch 18.516), train_loss = 1.21156291, grad/param norm = 1.9884e-01, time/batch = 17.9755s	
9648/26050 (epoch 18.518), train_loss = 1.10550529, grad/param norm = 1.8951e-01, time/batch = 18.1551s	
9649/26050 (epoch 18.520), train_loss = 1.08044854, grad/param norm = 1.7054e-01, time/batch = 15.6301s	
9650/26050 (epoch 18.522), train_loss = 0.87076830, grad/param norm = 1.6005e-01, time/batch = 18.4758s	
9651/26050 (epoch 18.524), train_loss = 1.18600770, grad/param norm = 2.0544e-01, time/batch = 14.4669s	
9652/26050 (epoch 18.526), train_loss = 1.21074645, grad/param norm = 2.5982e-01, time/batch = 18.2346s	
9653/26050 (epoch 18.528), train_loss = 1.14196064, grad/param norm = 1.9444e-01, time/batch = 16.8858s	
9654/26050 (epoch 18.530), train_loss = 1.07758057, grad/param norm = 1.8720e-01, time/batch = 18.6608s	
9655/26050 (epoch 18.532), train_loss = 1.08774945, grad/param norm = 1.7648e-01, time/batch = 17.9801s	
9656/26050 (epoch 18.534), train_loss = 1.16374831, grad/param norm = 2.4326e-01, time/batch = 17.4064s	
9657/26050 (epoch 18.536), train_loss = 1.09186620, grad/param norm = 1.7849e-01, time/batch = 18.4826s	
9658/26050 (epoch 18.537), train_loss = 1.17781817, grad/param norm = 2.0192e-01, time/batch = 15.7971s	
9659/26050 (epoch 18.539), train_loss = 1.08895720, grad/param norm = 1.7511e-01, time/batch = 17.8134s	
9660/26050 (epoch 18.541), train_loss = 1.30444690, grad/param norm = 2.0550e-01, time/batch = 17.7326s	
9661/26050 (epoch 18.543), train_loss = 0.92040780, grad/param norm = 1.7751e-01, time/batch = 18.8226s	
9662/26050 (epoch 18.545), train_loss = 1.16346265, grad/param norm = 1.9004e-01, time/batch = 18.4878s	
9663/26050 (epoch 18.547), train_loss = 1.08370451, grad/param norm = 1.7859e-01, time/batch = 18.1405s	
9664/26050 (epoch 18.549), train_loss = 0.90532555, grad/param norm = 1.7795e-01, time/batch = 18.9704s	
9665/26050 (epoch 18.551), train_loss = 1.14688688, grad/param norm = 1.8177e-01, time/batch = 16.6228s	
9666/26050 (epoch 18.553), train_loss = 1.01590527, grad/param norm = 1.6985e-01, time/batch = 20.5059s	
9667/26050 (epoch 18.555), train_loss = 1.02960617, grad/param norm = 1.6805e-01, time/batch = 33.8335s	
9668/26050 (epoch 18.557), train_loss = 1.15032830, grad/param norm = 1.6961e-01, time/batch = 19.6230s	
9669/26050 (epoch 18.559), train_loss = 1.08026286, grad/param norm = 1.6862e-01, time/batch = 15.1241s	
9670/26050 (epoch 18.560), train_loss = 1.05564683, grad/param norm = 1.7366e-01, time/batch = 15.4715s	
9671/26050 (epoch 18.562), train_loss = 1.05667884, grad/param norm = 1.7214e-01, time/batch = 18.9082s	
9672/26050 (epoch 18.564), train_loss = 1.26213548, grad/param norm = 1.7551e-01, time/batch = 17.7266s	
9673/26050 (epoch 18.566), train_loss = 0.99314331, grad/param norm = 1.7036e-01, time/batch = 18.4015s	
9674/26050 (epoch 18.568), train_loss = 1.12033052, grad/param norm = 1.7808e-01, time/batch = 17.9932s	
9675/26050 (epoch 18.570), train_loss = 1.17865028, grad/param norm = 1.8354e-01, time/batch = 17.4827s	
9676/26050 (epoch 18.572), train_loss = 1.05715330, grad/param norm = 1.8308e-01, time/batch = 15.8013s	
9677/26050 (epoch 18.574), train_loss = 1.15820853, grad/param norm = 2.0454e-01, time/batch = 18.4089s	
9678/26050 (epoch 18.576), train_loss = 1.11291813, grad/param norm = 1.8123e-01, time/batch = 18.1514s	
9679/26050 (epoch 18.578), train_loss = 1.05569708, grad/param norm = 1.7587e-01, time/batch = 18.3017s	
9680/26050 (epoch 18.580), train_loss = 1.01009416, grad/param norm = 1.8436e-01, time/batch = 17.4051s	
9681/26050 (epoch 18.582), train_loss = 1.11179136, grad/param norm = 1.6689e-01, time/batch = 15.8082s	
9682/26050 (epoch 18.583), train_loss = 1.20034960, grad/param norm = 1.7753e-01, time/batch = 16.4630s	
9683/26050 (epoch 18.585), train_loss = 0.96007080, grad/param norm = 1.7544e-01, time/batch = 18.3348s	
9684/26050 (epoch 18.587), train_loss = 1.13642306, grad/param norm = 1.9881e-01, time/batch = 15.1581s	
9685/26050 (epoch 18.589), train_loss = 1.24988773, grad/param norm = 2.0869e-01, time/batch = 17.2158s	
9686/26050 (epoch 18.591), train_loss = 1.07422117, grad/param norm = 1.7362e-01, time/batch = 18.0743s	
9687/26050 (epoch 18.593), train_loss = 0.95742712, grad/param norm = 1.6948e-01, time/batch = 17.9887s	
9688/26050 (epoch 18.595), train_loss = 1.17168448, grad/param norm = 2.0379e-01, time/batch = 17.6673s	
9689/26050 (epoch 18.597), train_loss = 1.13017190, grad/param norm = 1.8073e-01, time/batch = 17.6590s	
9690/26050 (epoch 18.599), train_loss = 1.08596949, grad/param norm = 1.8953e-01, time/batch = 16.5563s	
9691/26050 (epoch 18.601), train_loss = 1.27864608, grad/param norm = 1.8831e-01, time/batch = 17.5918s	
9692/26050 (epoch 18.603), train_loss = 1.13147199, grad/param norm = 1.8717e-01, time/batch = 17.4017s	
9693/26050 (epoch 18.605), train_loss = 1.03679249, grad/param norm = 1.7304e-01, time/batch = 17.8172s	
9694/26050 (epoch 18.607), train_loss = 1.19876843, grad/param norm = 1.9202e-01, time/batch = 18.5606s	
9695/26050 (epoch 18.608), train_loss = 0.95014962, grad/param norm = 1.4694e-01, time/batch = 18.8072s	
9696/26050 (epoch 18.610), train_loss = 1.07798922, grad/param norm = 1.9005e-01, time/batch = 18.0460s	
9697/26050 (epoch 18.612), train_loss = 1.09234586, grad/param norm = 1.8531e-01, time/batch = 18.3089s	
9698/26050 (epoch 18.614), train_loss = 1.13737429, grad/param norm = 1.7934e-01, time/batch = 17.4965s	
9699/26050 (epoch 18.616), train_loss = 1.25679429, grad/param norm = 2.0487e-01, time/batch = 14.2920s	
9700/26050 (epoch 18.618), train_loss = 1.04277962, grad/param norm = 1.9324e-01, time/batch = 18.2128s	
9701/26050 (epoch 18.620), train_loss = 1.12628334, grad/param norm = 1.8331e-01, time/batch = 17.5659s	
9702/26050 (epoch 18.622), train_loss = 0.95845218, grad/param norm = 1.5323e-01, time/batch = 18.2271s	
9703/26050 (epoch 18.624), train_loss = 0.95656348, grad/param norm = 1.6385e-01, time/batch = 18.2328s	
9704/26050 (epoch 18.626), train_loss = 1.13879044, grad/param norm = 1.8008e-01, time/batch = 17.1379s	
9705/26050 (epoch 18.628), train_loss = 1.01768909, grad/param norm = 1.8020e-01, time/batch = 16.1579s	
9706/26050 (epoch 18.630), train_loss = 1.20051548, grad/param norm = 1.8389e-01, time/batch = 16.5568s	
9707/26050 (epoch 18.631), train_loss = 1.25109047, grad/param norm = 1.8547e-01, time/batch = 18.8291s	
9708/26050 (epoch 18.633), train_loss = 0.99006703, grad/param norm = 1.6672e-01, time/batch = 17.4071s	
9709/26050 (epoch 18.635), train_loss = 1.00378388, grad/param norm = 1.5326e-01, time/batch = 17.7083s	
9710/26050 (epoch 18.637), train_loss = 0.98359499, grad/param norm = 1.7749e-01, time/batch = 17.4789s	
9711/26050 (epoch 18.639), train_loss = 1.19559587, grad/param norm = 1.7634e-01, time/batch = 18.4872s	
9712/26050 (epoch 18.641), train_loss = 1.05303393, grad/param norm = 1.6386e-01, time/batch = 16.4703s	
9713/26050 (epoch 18.643), train_loss = 0.97109006, grad/param norm = 1.5939e-01, time/batch = 16.9749s	
9714/26050 (epoch 18.645), train_loss = 1.09572661, grad/param norm = 1.8143e-01, time/batch = 17.3952s	
9715/26050 (epoch 18.647), train_loss = 1.03614106, grad/param norm = 1.7523e-01, time/batch = 17.4038s	
9716/26050 (epoch 18.649), train_loss = 1.12960273, grad/param norm = 2.0914e-01, time/batch = 17.5491s	
9717/26050 (epoch 18.651), train_loss = 1.02003495, grad/param norm = 1.9026e-01, time/batch = 17.4851s	
9718/26050 (epoch 18.653), train_loss = 1.09966703, grad/param norm = 1.7095e-01, time/batch = 18.5624s	
9719/26050 (epoch 18.655), train_loss = 1.01531847, grad/param norm = 1.6821e-01, time/batch = 15.7848s	
9720/26050 (epoch 18.656), train_loss = 0.93335268, grad/param norm = 1.7557e-01, time/batch = 18.2204s	
9721/26050 (epoch 18.658), train_loss = 1.27124968, grad/param norm = 1.8940e-01, time/batch = 18.5576s	
9722/26050 (epoch 18.660), train_loss = 0.96176166, grad/param norm = 1.6868e-01, time/batch = 18.5587s	
9723/26050 (epoch 18.662), train_loss = 0.99789104, grad/param norm = 1.6657e-01, time/batch = 17.4096s	
9724/26050 (epoch 18.664), train_loss = 1.06518718, grad/param norm = 1.8193e-01, time/batch = 18.0823s	
9725/26050 (epoch 18.666), train_loss = 1.05997673, grad/param norm = 1.8912e-01, time/batch = 16.4065s	
9726/26050 (epoch 18.668), train_loss = 0.91560402, grad/param norm = 1.8919e-01, time/batch = 14.3816s	
9727/26050 (epoch 18.670), train_loss = 1.23740473, grad/param norm = 1.9907e-01, time/batch = 18.0761s	
9728/26050 (epoch 18.672), train_loss = 1.05582546, grad/param norm = 1.9556e-01, time/batch = 18.3307s	
9729/26050 (epoch 18.674), train_loss = 1.00054915, grad/param norm = 1.7659e-01, time/batch = 18.7273s	
9730/26050 (epoch 18.676), train_loss = 1.13376699, grad/param norm = 2.0801e-01, time/batch = 17.6467s	
9731/26050 (epoch 18.678), train_loss = 1.20247640, grad/param norm = 1.9136e-01, time/batch = 17.7453s	
9732/26050 (epoch 18.679), train_loss = 1.27685199, grad/param norm = 2.0885e-01, time/batch = 16.6197s	
9733/26050 (epoch 18.681), train_loss = 1.10484822, grad/param norm = 1.8848e-01, time/batch = 17.3933s	
9734/26050 (epoch 18.683), train_loss = 0.98118158, grad/param norm = 2.2811e-01, time/batch = 18.8007s	
9735/26050 (epoch 18.685), train_loss = 1.02723517, grad/param norm = 1.6810e-01, time/batch = 17.3830s	
9736/26050 (epoch 18.687), train_loss = 0.91718818, grad/param norm = 1.7258e-01, time/batch = 14.8898s	
9737/26050 (epoch 18.689), train_loss = 1.06291105, grad/param norm = 2.1350e-01, time/batch = 17.8953s	
9738/26050 (epoch 18.691), train_loss = 0.84210821, grad/param norm = 1.5029e-01, time/batch = 18.9014s	
9739/26050 (epoch 18.693), train_loss = 0.97697717, grad/param norm = 1.6723e-01, time/batch = 17.5741s	
9740/26050 (epoch 18.695), train_loss = 1.08114268, grad/param norm = 1.7547e-01, time/batch = 17.8257s	
9741/26050 (epoch 18.697), train_loss = 0.98412297, grad/param norm = 1.7366e-01, time/batch = 18.0596s	
9742/26050 (epoch 18.699), train_loss = 1.13518052, grad/param norm = 1.9082e-01, time/batch = 14.5724s	
9743/26050 (epoch 18.701), train_loss = 0.97577330, grad/param norm = 1.7600e-01, time/batch = 17.8254s	
9744/26050 (epoch 18.702), train_loss = 1.19612777, grad/param norm = 1.8231e-01, time/batch = 17.2418s	
9745/26050 (epoch 18.704), train_loss = 1.15551332, grad/param norm = 1.6407e-01, time/batch = 16.5473s	
9746/26050 (epoch 18.706), train_loss = 1.07562336, grad/param norm = 2.0103e-01, time/batch = 18.0787s	
9747/26050 (epoch 18.708), train_loss = 1.17918755, grad/param norm = 1.9031e-01, time/batch = 16.7353s	
9748/26050 (epoch 18.710), train_loss = 1.15855605, grad/param norm = 1.9249e-01, time/batch = 17.9098s	
9749/26050 (epoch 18.712), train_loss = 1.16923938, grad/param norm = 2.0106e-01, time/batch = 15.3030s	
9750/26050 (epoch 18.714), train_loss = 0.92083020, grad/param norm = 1.6085e-01, time/batch = 18.0658s	
9751/26050 (epoch 18.716), train_loss = 1.32511401, grad/param norm = 1.9755e-01, time/batch = 18.0465s	
9752/26050 (epoch 18.718), train_loss = 1.18586495, grad/param norm = 1.8505e-01, time/batch = 18.2438s	
9753/26050 (epoch 18.720), train_loss = 1.06283659, grad/param norm = 1.8717e-01, time/batch = 17.8193s	
9754/26050 (epoch 18.722), train_loss = 0.95105425, grad/param norm = 1.7159e-01, time/batch = 14.7298s	
9755/26050 (epoch 18.724), train_loss = 1.00219621, grad/param norm = 1.9412e-01, time/batch = 16.9731s	
9756/26050 (epoch 18.726), train_loss = 1.16979268, grad/param norm = 1.9092e-01, time/batch = 18.9664s	
9757/26050 (epoch 18.727), train_loss = 1.18054514, grad/param norm = 2.0003e-01, time/batch = 17.6675s	
9758/26050 (epoch 18.729), train_loss = 1.12302918, grad/param norm = 1.8049e-01, time/batch = 17.4190s	
9759/26050 (epoch 18.731), train_loss = 1.12272114, grad/param norm = 1.8871e-01, time/batch = 18.3292s	
9760/26050 (epoch 18.733), train_loss = 1.04621487, grad/param norm = 2.2486e-01, time/batch = 18.5637s	
9761/26050 (epoch 18.735), train_loss = 1.27898673, grad/param norm = 1.9627e-01, time/batch = 18.3913s	
9762/26050 (epoch 18.737), train_loss = 1.04187820, grad/param norm = 1.7058e-01, time/batch = 18.1603s	
9763/26050 (epoch 18.739), train_loss = 1.12525642, grad/param norm = 1.8288e-01, time/batch = 16.6355s	
9764/26050 (epoch 18.741), train_loss = 1.01108062, grad/param norm = 1.8564e-01, time/batch = 16.9881s	
9765/26050 (epoch 18.743), train_loss = 1.12149778, grad/param norm = 2.1444e-01, time/batch = 17.7208s	
9766/26050 (epoch 18.745), train_loss = 0.95041366, grad/param norm = 1.8088e-01, time/batch = 17.8895s	
9767/26050 (epoch 18.747), train_loss = 0.98690980, grad/param norm = 1.7086e-01, time/batch = 15.9634s	
9768/26050 (epoch 18.749), train_loss = 1.21496810, grad/param norm = 1.9164e-01, time/batch = 15.3081s	
9769/26050 (epoch 18.750), train_loss = 1.06519207, grad/param norm = 1.6451e-01, time/batch = 18.3087s	
9770/26050 (epoch 18.752), train_loss = 1.06191105, grad/param norm = 1.9977e-01, time/batch = 18.4677s	
9771/26050 (epoch 18.754), train_loss = 1.10283251, grad/param norm = 1.8963e-01, time/batch = 17.8929s	
9772/26050 (epoch 18.756), train_loss = 1.08416932, grad/param norm = 1.9238e-01, time/batch = 17.9835s	
9773/26050 (epoch 18.758), train_loss = 1.07573661, grad/param norm = 1.8641e-01, time/batch = 15.3177s	
9774/26050 (epoch 18.760), train_loss = 1.24563426, grad/param norm = 1.8199e-01, time/batch = 17.8156s	
9775/26050 (epoch 18.762), train_loss = 1.02104052, grad/param norm = 1.7866e-01, time/batch = 15.2188s	
9776/26050 (epoch 18.764), train_loss = 1.10583718, grad/param norm = 1.8188e-01, time/batch = 18.1430s	
9777/26050 (epoch 18.766), train_loss = 1.16101865, grad/param norm = 1.9572e-01, time/batch = 14.0958s	
9778/26050 (epoch 18.768), train_loss = 0.98530648, grad/param norm = 1.7414e-01, time/batch = 14.0631s	
9779/26050 (epoch 18.770), train_loss = 1.06692220, grad/param norm = 1.8798e-01, time/batch = 14.0955s	
9780/26050 (epoch 18.772), train_loss = 1.05987614, grad/param norm = 1.5739e-01, time/batch = 13.9365s	
9781/26050 (epoch 18.774), train_loss = 0.94477577, grad/param norm = 1.7416e-01, time/batch = 18.2181s	
9782/26050 (epoch 18.775), train_loss = 0.77187449, grad/param norm = 1.5272e-01, time/batch = 16.0618s	
9783/26050 (epoch 18.777), train_loss = 0.99795366, grad/param norm = 1.6562e-01, time/batch = 18.7378s	
9784/26050 (epoch 18.779), train_loss = 1.05248939, grad/param norm = 1.8625e-01, time/batch = 16.8263s	
9785/26050 (epoch 18.781), train_loss = 0.98182836, grad/param norm = 1.7294e-01, time/batch = 17.7301s	
9786/26050 (epoch 18.783), train_loss = 0.96613507, grad/param norm = 1.7096e-01, time/batch = 17.6416s	
9787/26050 (epoch 18.785), train_loss = 1.05276932, grad/param norm = 1.6962e-01, time/batch = 18.6316s	
9788/26050 (epoch 18.787), train_loss = 0.99927299, grad/param norm = 1.7385e-01, time/batch = 16.9700s	
9789/26050 (epoch 18.789), train_loss = 0.99811613, grad/param norm = 1.9644e-01, time/batch = 15.8927s	
9790/26050 (epoch 18.791), train_loss = 1.03100583, grad/param norm = 1.7336e-01, time/batch = 18.3985s	
9791/26050 (epoch 18.793), train_loss = 1.04269526, grad/param norm = 1.9735e-01, time/batch = 17.3082s	
9792/26050 (epoch 18.795), train_loss = 0.88573151, grad/param norm = 1.5869e-01, time/batch = 14.4642s	
9793/26050 (epoch 18.797), train_loss = 0.98272115, grad/param norm = 1.5706e-01, time/batch = 17.8256s	
9794/26050 (epoch 18.798), train_loss = 0.90892482, grad/param norm = 1.6950e-01, time/batch = 17.5584s	
9795/26050 (epoch 18.800), train_loss = 0.92125075, grad/param norm = 1.5839e-01, time/batch = 17.4743s	
9796/26050 (epoch 18.802), train_loss = 1.01262777, grad/param norm = 1.7685e-01, time/batch = 17.3906s	
9797/26050 (epoch 18.804), train_loss = 1.04006895, grad/param norm = 1.7762e-01, time/batch = 18.5638s	
9798/26050 (epoch 18.806), train_loss = 1.17914383, grad/param norm = 2.0143e-01, time/batch = 18.4717s	
9799/26050 (epoch 18.808), train_loss = 1.06564253, grad/param norm = 1.7497e-01, time/batch = 17.9641s	
9800/26050 (epoch 18.810), train_loss = 1.00062505, grad/param norm = 1.9411e-01, time/batch = 16.2976s	
9801/26050 (epoch 18.812), train_loss = 0.96153442, grad/param norm = 1.8750e-01, time/batch = 17.9070s	
9802/26050 (epoch 18.814), train_loss = 0.95585620, grad/param norm = 2.2559e-01, time/batch = 18.0877s	
9803/26050 (epoch 18.816), train_loss = 1.17602951, grad/param norm = 2.0414e-01, time/batch = 17.5625s	
9804/26050 (epoch 18.818), train_loss = 1.18854815, grad/param norm = 2.1161e-01, time/batch = 14.7780s	
9805/26050 (epoch 18.820), train_loss = 1.07697447, grad/param norm = 1.8051e-01, time/batch = 18.4089s	
9806/26050 (epoch 18.821), train_loss = 1.20913447, grad/param norm = 1.9104e-01, time/batch = 17.1530s	
9807/26050 (epoch 18.823), train_loss = 1.22082716, grad/param norm = 1.9684e-01, time/batch = 17.2106s	
9808/26050 (epoch 18.825), train_loss = 1.05743314, grad/param norm = 1.8736e-01, time/batch = 18.3138s	
9809/26050 (epoch 18.827), train_loss = 1.09186469, grad/param norm = 2.0498e-01, time/batch = 17.9083s	
9810/26050 (epoch 18.829), train_loss = 1.15048648, grad/param norm = 1.8927e-01, time/batch = 18.3183s	
9811/26050 (epoch 18.831), train_loss = 1.19400682, grad/param norm = 1.7148e-01, time/batch = 18.4087s	
9812/26050 (epoch 18.833), train_loss = 1.29058810, grad/param norm = 1.9914e-01, time/batch = 18.3205s	
9813/26050 (epoch 18.835), train_loss = 1.26039460, grad/param norm = 1.8991e-01, time/batch = 17.8031s	
9814/26050 (epoch 18.837), train_loss = 1.07434285, grad/param norm = 1.8159e-01, time/batch = 15.0596s	
9815/26050 (epoch 18.839), train_loss = 1.09769090, grad/param norm = 1.9129e-01, time/batch = 18.7383s	
9816/26050 (epoch 18.841), train_loss = 1.20436876, grad/param norm = 1.8654e-01, time/batch = 17.0698s	
9817/26050 (epoch 18.843), train_loss = 1.08272448, grad/param norm = 1.7355e-01, time/batch = 18.4674s	
9818/26050 (epoch 18.845), train_loss = 1.01292145, grad/param norm = 1.6043e-01, time/batch = 17.4867s	
9819/26050 (epoch 18.846), train_loss = 1.16851093, grad/param norm = 1.7283e-01, time/batch = 17.0607s	
9820/26050 (epoch 18.848), train_loss = 1.07201586, grad/param norm = 1.7196e-01, time/batch = 16.6965s	
9821/26050 (epoch 18.850), train_loss = 0.98693929, grad/param norm = 1.6548e-01, time/batch = 18.1716s	
9822/26050 (epoch 18.852), train_loss = 1.07181551, grad/param norm = 1.8198e-01, time/batch = 17.7534s	
9823/26050 (epoch 18.854), train_loss = 1.06683794, grad/param norm = 1.9515e-01, time/batch = 17.4779s	
9824/26050 (epoch 18.856), train_loss = 1.04077308, grad/param norm = 1.8988e-01, time/batch = 18.2029s	
9825/26050 (epoch 18.858), train_loss = 0.97742825, grad/param norm = 1.7287e-01, time/batch = 18.3917s	
9826/26050 (epoch 18.860), train_loss = 1.10840002, grad/param norm = 1.8582e-01, time/batch = 14.6370s	
9827/26050 (epoch 18.862), train_loss = 1.12887927, grad/param norm = 1.8314e-01, time/batch = 17.4936s	
9828/26050 (epoch 18.864), train_loss = 1.11730653, grad/param norm = 2.0742e-01, time/batch = 15.7816s	
9829/26050 (epoch 18.866), train_loss = 1.01988826, grad/param norm = 1.7079e-01, time/batch = 17.9057s	
9830/26050 (epoch 18.868), train_loss = 1.12905597, grad/param norm = 1.7901e-01, time/batch = 17.4071s	
9831/26050 (epoch 18.869), train_loss = 0.96333290, grad/param norm = 1.6643e-01, time/batch = 18.3986s	
9832/26050 (epoch 18.871), train_loss = 0.90475875, grad/param norm = 1.7275e-01, time/batch = 18.7347s	
9833/26050 (epoch 18.873), train_loss = 1.12086710, grad/param norm = 1.9465e-01, time/batch = 18.0747s	
9834/26050 (epoch 18.875), train_loss = 1.07020988, grad/param norm = 1.8729e-01, time/batch = 16.4744s	
9835/26050 (epoch 18.877), train_loss = 0.96943779, grad/param norm = 1.7483e-01, time/batch = 17.5498s	
9836/26050 (epoch 18.879), train_loss = 1.09963235, grad/param norm = 1.7042e-01, time/batch = 18.4777s	
9837/26050 (epoch 18.881), train_loss = 1.19781137, grad/param norm = 1.9201e-01, time/batch = 17.2355s	
9838/26050 (epoch 18.883), train_loss = 1.12894016, grad/param norm = 1.8563e-01, time/batch = 17.7536s	
9839/26050 (epoch 18.885), train_loss = 0.81096831, grad/param norm = 1.6004e-01, time/batch = 18.2366s	
9840/26050 (epoch 18.887), train_loss = 1.11156625, grad/param norm = 1.7961e-01, time/batch = 15.3936s	
9841/26050 (epoch 18.889), train_loss = 1.03078289, grad/param norm = 1.7047e-01, time/batch = 18.6581s	
9842/26050 (epoch 18.891), train_loss = 0.87233281, grad/param norm = 1.5938e-01, time/batch = 16.9548s	
9843/26050 (epoch 18.893), train_loss = 0.92594958, grad/param norm = 1.6969e-01, time/batch = 17.5765s	
9844/26050 (epoch 18.894), train_loss = 1.02678219, grad/param norm = 1.7089e-01, time/batch = 18.2299s	
9845/26050 (epoch 18.896), train_loss = 1.16515405, grad/param norm = 1.7313e-01, time/batch = 17.9829s	
9846/26050 (epoch 18.898), train_loss = 1.01182031, grad/param norm = 1.7936e-01, time/batch = 18.2282s	
9847/26050 (epoch 18.900), train_loss = 1.11098175, grad/param norm = 1.8091e-01, time/batch = 18.0505s	
9848/26050 (epoch 18.902), train_loss = 1.05367681, grad/param norm = 1.7415e-01, time/batch = 17.5543s	
9849/26050 (epoch 18.904), train_loss = 1.05025852, grad/param norm = 1.7169e-01, time/batch = 18.3063s	
9850/26050 (epoch 18.906), train_loss = 1.04569210, grad/param norm = 1.8924e-01, time/batch = 17.8960s	
9851/26050 (epoch 18.908), train_loss = 1.05511344, grad/param norm = 1.7527e-01, time/batch = 14.6475s	
9852/26050 (epoch 18.910), train_loss = 1.00524950, grad/param norm = 1.6731e-01, time/batch = 16.4780s	
9853/26050 (epoch 18.912), train_loss = 1.28885051, grad/param norm = 2.0498e-01, time/batch = 17.9502s	
9854/26050 (epoch 18.914), train_loss = 1.42091973, grad/param norm = 2.1016e-01, time/batch = 18.3012s	
9855/26050 (epoch 18.916), train_loss = 1.17634131, grad/param norm = 1.9470e-01, time/batch = 17.9781s	
9856/26050 (epoch 18.917), train_loss = 1.09033921, grad/param norm = 2.1650e-01, time/batch = 18.1271s	
9857/26050 (epoch 18.919), train_loss = 1.15965031, grad/param norm = 2.1154e-01, time/batch = 17.4013s	
9858/26050 (epoch 18.921), train_loss = 1.02679153, grad/param norm = 1.8589e-01, time/batch = 19.2030s	
9859/26050 (epoch 18.923), train_loss = 1.09866263, grad/param norm = 1.9330e-01, time/batch = 18.5454s	
9860/26050 (epoch 18.925), train_loss = 1.07646911, grad/param norm = 1.8157e-01, time/batch = 16.8166s	
9861/26050 (epoch 18.927), train_loss = 0.93861979, grad/param norm = 1.4595e-01, time/batch = 18.8007s	
9862/26050 (epoch 18.929), train_loss = 0.94557071, grad/param norm = 1.7358e-01, time/batch = 15.2966s	
9863/26050 (epoch 18.931), train_loss = 1.26592321, grad/param norm = 2.1554e-01, time/batch = 15.2302s	
9864/26050 (epoch 18.933), train_loss = 1.01682720, grad/param norm = 1.7030e-01, time/batch = 17.1467s	
9865/26050 (epoch 18.935), train_loss = 1.05442349, grad/param norm = 1.8277e-01, time/batch = 18.2430s	
9866/26050 (epoch 18.937), train_loss = 1.15597174, grad/param norm = 1.7899e-01, time/batch = 15.2820s	
9867/26050 (epoch 18.939), train_loss = 0.96948405, grad/param norm = 1.4896e-01, time/batch = 17.7354s	
9868/26050 (epoch 18.940), train_loss = 1.05031824, grad/param norm = 1.6335e-01, time/batch = 18.1394s	
9869/26050 (epoch 18.942), train_loss = 1.07805247, grad/param norm = 1.7524e-01, time/batch = 17.9046s	
9870/26050 (epoch 18.944), train_loss = 1.00636630, grad/param norm = 1.6226e-01, time/batch = 17.9689s	
9871/26050 (epoch 18.946), train_loss = 1.19935331, grad/param norm = 1.9295e-01, time/batch = 25.6946s	
9872/26050 (epoch 18.948), train_loss = 0.95089986, grad/param norm = 1.9052e-01, time/batch = 30.8175s	
9873/26050 (epoch 18.950), train_loss = 1.04556748, grad/param norm = 1.8442e-01, time/batch = 15.4223s	
9874/26050 (epoch 18.952), train_loss = 1.18633906, grad/param norm = 1.9939e-01, time/batch = 17.7342s	
9875/26050 (epoch 18.954), train_loss = 1.17309084, grad/param norm = 1.8281e-01, time/batch = 17.8296s	
9876/26050 (epoch 18.956), train_loss = 1.05947873, grad/param norm = 1.8475e-01, time/batch = 18.2216s	
9877/26050 (epoch 18.958), train_loss = 1.01584488, grad/param norm = 1.7196e-01, time/batch = 18.8626s	
9878/26050 (epoch 18.960), train_loss = 1.07580162, grad/param norm = 1.8121e-01, time/batch = 17.7339s	
9879/26050 (epoch 18.962), train_loss = 0.99966562, grad/param norm = 1.6260e-01, time/batch = 18.2402s	
9880/26050 (epoch 18.964), train_loss = 1.06427061, grad/param norm = 1.8631e-01, time/batch = 17.5554s	
9881/26050 (epoch 18.965), train_loss = 0.99252234, grad/param norm = 1.7585e-01, time/batch = 18.3103s	
9882/26050 (epoch 18.967), train_loss = 1.39858346, grad/param norm = 1.9457e-01, time/batch = 15.4829s	
9883/26050 (epoch 18.969), train_loss = 1.05157203, grad/param norm = 1.7755e-01, time/batch = 17.8980s	
9884/26050 (epoch 18.971), train_loss = 1.02101861, grad/param norm = 1.6004e-01, time/batch = 18.4796s	
9885/26050 (epoch 18.973), train_loss = 1.05038881, grad/param norm = 1.9869e-01, time/batch = 17.0715s	
9886/26050 (epoch 18.975), train_loss = 1.11173496, grad/param norm = 1.6773e-01, time/batch = 18.0657s	
9887/26050 (epoch 18.977), train_loss = 1.10045171, grad/param norm = 1.5958e-01, time/batch = 17.8131s	
9888/26050 (epoch 18.979), train_loss = 0.89871687, grad/param norm = 1.6698e-01, time/batch = 17.8248s	
9889/26050 (epoch 18.981), train_loss = 1.20861374, grad/param norm = 1.6844e-01, time/batch = 18.1644s	
9890/26050 (epoch 18.983), train_loss = 1.15461555, grad/param norm = 1.8545e-01, time/batch = 17.3306s	
9891/26050 (epoch 18.985), train_loss = 1.11071181, grad/param norm = 1.7192e-01, time/batch = 18.5664s	
9892/26050 (epoch 18.987), train_loss = 1.18246821, grad/param norm = 1.7666e-01, time/batch = 17.9824s	
9893/26050 (epoch 18.988), train_loss = 1.16840155, grad/param norm = 1.8041e-01, time/batch = 15.2137s	
9894/26050 (epoch 18.990), train_loss = 0.95175232, grad/param norm = 1.4968e-01, time/batch = 14.4831s	
9895/26050 (epoch 18.992), train_loss = 1.22570379, grad/param norm = 1.9061e-01, time/batch = 17.9079s	
9896/26050 (epoch 18.994), train_loss = 1.03767690, grad/param norm = 1.8652e-01, time/batch = 17.7226s	
9897/26050 (epoch 18.996), train_loss = 1.02308824, grad/param norm = 1.9140e-01, time/batch = 17.1443s	
9898/26050 (epoch 18.998), train_loss = 1.08142489, grad/param norm = 1.6911e-01, time/batch = 15.7949s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
9899/26050 (epoch 19.000), train_loss = 1.01295031, grad/param norm = 1.8071e-01, time/batch = 18.3973s	
9900/26050 (epoch 19.002), train_loss = 1.14899936, grad/param norm = 2.0063e-01, time/batch = 17.9821s	
9901/26050 (epoch 19.004), train_loss = 0.97913564, grad/param norm = 1.7249e-01, time/batch = 18.5508s	
9902/26050 (epoch 19.006), train_loss = 1.01621861, grad/param norm = 1.8551e-01, time/batch = 17.3222s	
9903/26050 (epoch 19.008), train_loss = 0.97689775, grad/param norm = 1.8829e-01, time/batch = 16.3858s	
9904/26050 (epoch 19.010), train_loss = 0.99717960, grad/param norm = 1.7674e-01, time/batch = 17.1275s	
9905/26050 (epoch 19.012), train_loss = 1.07799531, grad/param norm = 1.7193e-01, time/batch = 18.5602s	
9906/26050 (epoch 19.013), train_loss = 1.38542988, grad/param norm = 2.1083e-01, time/batch = 16.0581s	
9907/26050 (epoch 19.015), train_loss = 1.02224529, grad/param norm = 1.5962e-01, time/batch = 16.6512s	
9908/26050 (epoch 19.017), train_loss = 1.08345018, grad/param norm = 1.7346e-01, time/batch = 17.9044s	
9909/26050 (epoch 19.019), train_loss = 0.91467958, grad/param norm = 1.5707e-01, time/batch = 18.4882s	
9910/26050 (epoch 19.021), train_loss = 1.13290047, grad/param norm = 1.8459e-01, time/batch = 18.2994s	
9911/26050 (epoch 19.023), train_loss = 0.90720788, grad/param norm = 1.6788e-01, time/batch = 17.3831s	
9912/26050 (epoch 19.025), train_loss = 1.07037116, grad/param norm = 1.7345e-01, time/batch = 18.0759s	
9913/26050 (epoch 19.027), train_loss = 0.86784208, grad/param norm = 1.8125e-01, time/batch = 18.8069s	
9914/26050 (epoch 19.029), train_loss = 1.08508265, grad/param norm = 1.6772e-01, time/batch = 17.3941s	
9915/26050 (epoch 19.031), train_loss = 1.19864250, grad/param norm = 2.1270e-01, time/batch = 17.2267s	
9916/26050 (epoch 19.033), train_loss = 1.10334562, grad/param norm = 1.8341e-01, time/batch = 16.6903s	
9917/26050 (epoch 19.035), train_loss = 1.12775418, grad/param norm = 1.8933e-01, time/batch = 17.9785s	
9918/26050 (epoch 19.036), train_loss = 0.97922467, grad/param norm = 1.9633e-01, time/batch = 18.4018s	
9919/26050 (epoch 19.038), train_loss = 0.90107832, grad/param norm = 1.9720e-01, time/batch = 17.2235s	
9920/26050 (epoch 19.040), train_loss = 1.06660979, grad/param norm = 1.8214e-01, time/batch = 18.4102s	
9921/26050 (epoch 19.042), train_loss = 0.91692469, grad/param norm = 1.6382e-01, time/batch = 6.8877s	
9922/26050 (epoch 19.044), train_loss = 1.15214524, grad/param norm = 1.6727e-01, time/batch = 0.6500s	
9923/26050 (epoch 19.046), train_loss = 0.86079883, grad/param norm = 1.5048e-01, time/batch = 0.6833s	
9924/26050 (epoch 19.048), train_loss = 1.07955473, grad/param norm = 1.7793e-01, time/batch = 0.6614s	
9925/26050 (epoch 19.050), train_loss = 0.98188424, grad/param norm = 1.6648e-01, time/batch = 0.6444s	
9926/26050 (epoch 19.052), train_loss = 1.01863883, grad/param norm = 1.9103e-01, time/batch = 0.6502s	
9927/26050 (epoch 19.054), train_loss = 0.90550305, grad/param norm = 1.5437e-01, time/batch = 0.6466s	
9928/26050 (epoch 19.056), train_loss = 0.85558948, grad/param norm = 1.4660e-01, time/batch = 0.6671s	
9929/26050 (epoch 19.058), train_loss = 1.02456739, grad/param norm = 1.7068e-01, time/batch = 0.9425s	
9930/26050 (epoch 19.060), train_loss = 1.11972557, grad/param norm = 1.8147e-01, time/batch = 0.9425s	
9931/26050 (epoch 19.061), train_loss = 0.97351675, grad/param norm = 1.7158e-01, time/batch = 0.9443s	
9932/26050 (epoch 19.063), train_loss = 1.10802090, grad/param norm = 1.8271e-01, time/batch = 0.9403s	
9933/26050 (epoch 19.065), train_loss = 0.86631894, grad/param norm = 1.4753e-01, time/batch = 0.9326s	
9934/26050 (epoch 19.067), train_loss = 1.07143694, grad/param norm = 1.7716e-01, time/batch = 1.6053s	
9935/26050 (epoch 19.069), train_loss = 1.11389127, grad/param norm = 1.7223e-01, time/batch = 1.8136s	
9936/26050 (epoch 19.071), train_loss = 1.12234666, grad/param norm = 1.7522e-01, time/batch = 1.7348s	
9937/26050 (epoch 19.073), train_loss = 1.25249229, grad/param norm = 2.0003e-01, time/batch = 16.9760s	
9938/26050 (epoch 19.075), train_loss = 0.97781332, grad/param norm = 1.6255e-01, time/batch = 17.8129s	
9939/26050 (epoch 19.077), train_loss = 0.98717912, grad/param norm = 1.6936e-01, time/batch = 17.4820s	
9940/26050 (epoch 19.079), train_loss = 1.09121624, grad/param norm = 1.9471e-01, time/batch = 17.8327s	
9941/26050 (epoch 19.081), train_loss = 1.02628626, grad/param norm = 1.6928e-01, time/batch = 18.2478s	
9942/26050 (epoch 19.083), train_loss = 1.14274669, grad/param norm = 1.7589e-01, time/batch = 15.8958s	
9943/26050 (epoch 19.084), train_loss = 1.08194662, grad/param norm = 1.9574e-01, time/batch = 18.3858s	
9944/26050 (epoch 19.086), train_loss = 1.21618194, grad/param norm = 1.8484e-01, time/batch = 18.0082s	
9945/26050 (epoch 19.088), train_loss = 0.96628274, grad/param norm = 1.6651e-01, time/batch = 17.6551s	
9946/26050 (epoch 19.090), train_loss = 1.08781754, grad/param norm = 1.8172e-01, time/batch = 15.6347s	
9947/26050 (epoch 19.092), train_loss = 1.10991128, grad/param norm = 1.7293e-01, time/batch = 15.1955s	
9948/26050 (epoch 19.094), train_loss = 1.00170267, grad/param norm = 1.7383e-01, time/batch = 18.1429s	
9949/26050 (epoch 19.096), train_loss = 1.04290333, grad/param norm = 1.6340e-01, time/batch = 17.3962s	
9950/26050 (epoch 19.098), train_loss = 1.01498744, grad/param norm = 1.8163e-01, time/batch = 18.3937s	
9951/26050 (epoch 19.100), train_loss = 0.94757245, grad/param norm = 1.6845e-01, time/batch = 17.3860s	
9952/26050 (epoch 19.102), train_loss = 1.08938760, grad/param norm = 1.7363e-01, time/batch = 17.2363s	
9953/26050 (epoch 19.104), train_loss = 1.07085590, grad/param norm = 1.9465e-01, time/batch = 16.9747s	
9954/26050 (epoch 19.106), train_loss = 1.07028494, grad/param norm = 1.9948e-01, time/batch = 18.5638s	
9955/26050 (epoch 19.107), train_loss = 0.84968830, grad/param norm = 1.6459e-01, time/batch = 17.1478s	
9956/26050 (epoch 19.109), train_loss = 0.98666930, grad/param norm = 1.8323e-01, time/batch = 16.7954s	
9957/26050 (epoch 19.111), train_loss = 1.22676420, grad/param norm = 1.8727e-01, time/batch = 18.1539s	
9958/26050 (epoch 19.113), train_loss = 1.00150019, grad/param norm = 1.7150e-01, time/batch = 18.3998s	
9959/26050 (epoch 19.115), train_loss = 1.15589931, grad/param norm = 1.7761e-01, time/batch = 17.6586s	
9960/26050 (epoch 19.117), train_loss = 1.07540809, grad/param norm = 1.6828e-01, time/batch = 14.6248s	
9961/26050 (epoch 19.119), train_loss = 0.88422942, grad/param norm = 1.6252e-01, time/batch = 17.7386s	
9962/26050 (epoch 19.121), train_loss = 1.08474273, grad/param norm = 1.8025e-01, time/batch = 14.3824s	
9963/26050 (epoch 19.123), train_loss = 0.95462912, grad/param norm = 1.6452e-01, time/batch = 15.1932s	
9964/26050 (epoch 19.125), train_loss = 0.91198432, grad/param norm = 1.6282e-01, time/batch = 15.6096s	
9965/26050 (epoch 19.127), train_loss = 0.84372574, grad/param norm = 1.6147e-01, time/batch = 18.4030s	
9966/26050 (epoch 19.129), train_loss = 0.90213022, grad/param norm = 1.7401e-01, time/batch = 18.2139s	
9967/26050 (epoch 19.131), train_loss = 1.01537902, grad/param norm = 1.6923e-01, time/batch = 17.8996s	
9968/26050 (epoch 19.132), train_loss = 1.02277264, grad/param norm = 1.6848e-01, time/batch = 18.8016s	
9969/26050 (epoch 19.134), train_loss = 1.05601957, grad/param norm = 2.0754e-01, time/batch = 19.0329s	
9970/26050 (epoch 19.136), train_loss = 1.04580562, grad/param norm = 1.7346e-01, time/batch = 17.8000s	
9971/26050 (epoch 19.138), train_loss = 0.81152019, grad/param norm = 1.6062e-01, time/batch = 17.6596s	
9972/26050 (epoch 19.140), train_loss = 0.88426944, grad/param norm = 1.7862e-01, time/batch = 17.2085s	
9973/26050 (epoch 19.142), train_loss = 0.91210407, grad/param norm = 1.5962e-01, time/batch = 17.6481s	
9974/26050 (epoch 19.144), train_loss = 0.85329934, grad/param norm = 1.6585e-01, time/batch = 17.6469s	
9975/26050 (epoch 19.146), train_loss = 0.79534909, grad/param norm = 1.6121e-01, time/batch = 18.7510s	
9976/26050 (epoch 19.148), train_loss = 0.82778882, grad/param norm = 1.4585e-01, time/batch = 16.2121s	
9977/26050 (epoch 19.150), train_loss = 1.02208898, grad/param norm = 1.9295e-01, time/batch = 18.2407s	
9978/26050 (epoch 19.152), train_loss = 1.23123831, grad/param norm = 2.1289e-01, time/batch = 17.9687s	
9979/26050 (epoch 19.154), train_loss = 0.81469138, grad/param norm = 1.6311e-01, time/batch = 18.5649s	
9980/26050 (epoch 19.155), train_loss = 0.85543783, grad/param norm = 1.5365e-01, time/batch = 16.3121s	
9981/26050 (epoch 19.157), train_loss = 0.98990169, grad/param norm = 2.0848e-01, time/batch = 16.8834s	
9982/26050 (epoch 19.159), train_loss = 1.04695821, grad/param norm = 1.9462e-01, time/batch = 16.1344s	
9983/26050 (epoch 19.161), train_loss = 1.09811839, grad/param norm = 1.8499e-01, time/batch = 17.7856s	
9984/26050 (epoch 19.163), train_loss = 0.85398633, grad/param norm = 1.5334e-01, time/batch = 18.5739s	
9985/26050 (epoch 19.165), train_loss = 0.80181313, grad/param norm = 1.5598e-01, time/batch = 17.9787s	
9986/26050 (epoch 19.167), train_loss = 1.12311884, grad/param norm = 1.8478e-01, time/batch = 18.4090s	
9987/26050 (epoch 19.169), train_loss = 1.07620365, grad/param norm = 1.7784e-01, time/batch = 17.7185s	
9988/26050 (epoch 19.171), train_loss = 0.85337989, grad/param norm = 1.5379e-01, time/batch = 18.6537s	
9989/26050 (epoch 19.173), train_loss = 0.96887976, grad/param norm = 1.8743e-01, time/batch = 18.7930s	
9990/26050 (epoch 19.175), train_loss = 1.00341564, grad/param norm = 1.6462e-01, time/batch = 17.3096s	
9991/26050 (epoch 19.177), train_loss = 1.13673471, grad/param norm = 1.7017e-01, time/batch = 15.3777s	
9992/26050 (epoch 19.179), train_loss = 0.80537844, grad/param norm = 1.5534e-01, time/batch = 18.3096s	
9993/26050 (epoch 19.180), train_loss = 1.25146169, grad/param norm = 1.9144e-01, time/batch = 16.3850s	
9994/26050 (epoch 19.182), train_loss = 1.26066722, grad/param norm = 1.9566e-01, time/batch = 17.4994s	
9995/26050 (epoch 19.184), train_loss = 1.06562157, grad/param norm = 1.6855e-01, time/batch = 17.4957s	
9996/26050 (epoch 19.186), train_loss = 0.86913712, grad/param norm = 1.5464e-01, time/batch = 17.1215s	
9997/26050 (epoch 19.188), train_loss = 1.02897469, grad/param norm = 1.7947e-01, time/batch = 17.5508s	
9998/26050 (epoch 19.190), train_loss = 1.09727880, grad/param norm = 1.8518e-01, time/batch = 18.3000s	
9999/26050 (epoch 19.192), train_loss = 1.09336813, grad/param norm = 1.6482e-01, time/batch = 16.5626s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch19.19_1.6589.t7	
10000/26050 (epoch 19.194), train_loss = 1.08363924, grad/param norm = 1.7402e-01, time/batch = 16.9639s	
10001/26050 (epoch 19.196), train_loss = 1.38796217, grad/param norm = 2.0191e-01, time/batch = 17.5731s	
10002/26050 (epoch 19.198), train_loss = 0.95058395, grad/param norm = 1.6218e-01, time/batch = 17.4859s	
10003/26050 (epoch 19.200), train_loss = 0.95559945, grad/param norm = 1.7809e-01, time/batch = 18.5569s	
10004/26050 (epoch 19.202), train_loss = 1.03658352, grad/param norm = 1.7949e-01, time/batch = 16.8834s	
10005/26050 (epoch 19.203), train_loss = 1.16214436, grad/param norm = 1.9278e-01, time/batch = 18.2059s	
10006/26050 (epoch 19.205), train_loss = 0.97650992, grad/param norm = 1.7034e-01, time/batch = 15.4754s	
10007/26050 (epoch 19.207), train_loss = 0.97706866, grad/param norm = 1.6762e-01, time/batch = 18.6483s	
10008/26050 (epoch 19.209), train_loss = 1.08484616, grad/param norm = 1.8288e-01, time/batch = 14.8823s	
10009/26050 (epoch 19.211), train_loss = 0.87875010, grad/param norm = 1.5728e-01, time/batch = 18.2406s	
10010/26050 (epoch 19.213), train_loss = 1.08845318, grad/param norm = 1.9157e-01, time/batch = 18.1789s	
10011/26050 (epoch 19.215), train_loss = 1.04030529, grad/param norm = 2.0408e-01, time/batch = 17.5700s	
10012/26050 (epoch 19.217), train_loss = 1.00921803, grad/param norm = 1.7108e-01, time/batch = 18.1495s	
10013/26050 (epoch 19.219), train_loss = 1.01467133, grad/param norm = 1.9930e-01, time/batch = 17.4738s	
10014/26050 (epoch 19.221), train_loss = 0.94616014, grad/param norm = 1.8108e-01, time/batch = 17.5692s	
10015/26050 (epoch 19.223), train_loss = 1.07040130, grad/param norm = 1.8013e-01, time/batch = 16.5500s	
10016/26050 (epoch 19.225), train_loss = 0.92820155, grad/param norm = 1.7116e-01, time/batch = 17.8243s	
10017/26050 (epoch 19.226), train_loss = 1.08676003, grad/param norm = 1.9853e-01, time/batch = 17.7406s	
10018/26050 (epoch 19.228), train_loss = 1.16933557, grad/param norm = 1.8009e-01, time/batch = 15.2870s	
10019/26050 (epoch 19.230), train_loss = 1.06683914, grad/param norm = 1.6605e-01, time/batch = 18.1421s	
10020/26050 (epoch 19.232), train_loss = 1.13295475, grad/param norm = 1.9607e-01, time/batch = 18.7976s	
10021/26050 (epoch 19.234), train_loss = 0.92262226, grad/param norm = 1.7210e-01, time/batch = 14.9663s	
10022/26050 (epoch 19.236), train_loss = 1.12894634, grad/param norm = 1.9197e-01, time/batch = 18.3704s	
10023/26050 (epoch 19.238), train_loss = 0.89785727, grad/param norm = 1.6710e-01, time/batch = 18.1555s	
10024/26050 (epoch 19.240), train_loss = 1.02877354, grad/param norm = 1.7797e-01, time/batch = 17.2048s	
10025/26050 (epoch 19.242), train_loss = 1.04427012, grad/param norm = 1.6798e-01, time/batch = 17.6186s	
10026/26050 (epoch 19.244), train_loss = 1.03103134, grad/param norm = 1.9651e-01, time/batch = 18.4786s	
10027/26050 (epoch 19.246), train_loss = 0.97371296, grad/param norm = 1.7781e-01, time/batch = 18.7320s	
10028/26050 (epoch 19.248), train_loss = 1.04974781, grad/param norm = 1.7850e-01, time/batch = 17.6548s	
10029/26050 (epoch 19.250), train_loss = 1.04673758, grad/param norm = 2.0984e-01, time/batch = 18.4869s	
10030/26050 (epoch 19.251), train_loss = 1.00659822, grad/param norm = 1.6462e-01, time/batch = 14.7231s	
10031/26050 (epoch 19.253), train_loss = 0.89962013, grad/param norm = 1.6386e-01, time/batch = 17.7352s	
10032/26050 (epoch 19.255), train_loss = 1.22318130, grad/param norm = 1.8140e-01, time/batch = 18.2961s	
10033/26050 (epoch 19.257), train_loss = 1.03836435, grad/param norm = 1.9472e-01, time/batch = 17.4878s	
10034/26050 (epoch 19.259), train_loss = 1.18583817, grad/param norm = 1.9344e-01, time/batch = 18.6641s	
10035/26050 (epoch 19.261), train_loss = 0.93352297, grad/param norm = 1.7386e-01, time/batch = 17.2214s	
10036/26050 (epoch 19.263), train_loss = 1.10550812, grad/param norm = 1.9319e-01, time/batch = 17.7320s	
10037/26050 (epoch 19.265), train_loss = 1.21292485, grad/param norm = 2.0557e-01, time/batch = 18.6633s	
10038/26050 (epoch 19.267), train_loss = 1.15650197, grad/param norm = 1.7033e-01, time/batch = 16.9107s	
10039/26050 (epoch 19.269), train_loss = 1.18668193, grad/param norm = 1.9122e-01, time/batch = 15.6043s	
10040/26050 (epoch 19.271), train_loss = 1.10290936, grad/param norm = 1.8424e-01, time/batch = 17.8392s	
10041/26050 (epoch 19.273), train_loss = 1.00706648, grad/param norm = 1.9185e-01, time/batch = 18.0799s	
10042/26050 (epoch 19.274), train_loss = 1.01391434, grad/param norm = 1.7145e-01, time/batch = 18.3091s	
10043/26050 (epoch 19.276), train_loss = 1.00601141, grad/param norm = 2.0011e-01, time/batch = 16.6378s	
10044/26050 (epoch 19.278), train_loss = 1.17664271, grad/param norm = 1.7396e-01, time/batch = 15.4881s	
10045/26050 (epoch 19.280), train_loss = 1.03582396, grad/param norm = 1.6783e-01, time/batch = 17.2316s	
10046/26050 (epoch 19.282), train_loss = 1.07983164, grad/param norm = 1.7900e-01, time/batch = 18.6541s	
10047/26050 (epoch 19.284), train_loss = 0.99285113, grad/param norm = 1.7264e-01, time/batch = 17.0825s	
10048/26050 (epoch 19.286), train_loss = 1.06498747, grad/param norm = 1.9018e-01, time/batch = 17.4164s	
10049/26050 (epoch 19.288), train_loss = 0.90058345, grad/param norm = 1.6436e-01, time/batch = 17.5661s	
10050/26050 (epoch 19.290), train_loss = 1.05985320, grad/param norm = 2.0227e-01, time/batch = 17.9094s	
10051/26050 (epoch 19.292), train_loss = 0.95201064, grad/param norm = 1.5631e-01, time/batch = 18.6585s	
10052/26050 (epoch 19.294), train_loss = 1.06457587, grad/param norm = 1.9388e-01, time/batch = 17.4845s	
10053/26050 (epoch 19.296), train_loss = 1.14438497, grad/param norm = 1.8155e-01, time/batch = 16.5686s	
10054/26050 (epoch 19.298), train_loss = 1.04706021, grad/param norm = 1.7213e-01, time/batch = 15.2707s	
10055/26050 (epoch 19.299), train_loss = 0.83553604, grad/param norm = 1.4898e-01, time/batch = 16.4876s	
10056/26050 (epoch 19.301), train_loss = 0.91677729, grad/param norm = 1.7739e-01, time/batch = 18.4785s	
10057/26050 (epoch 19.303), train_loss = 1.05763692, grad/param norm = 1.9611e-01, time/batch = 18.4746s	
10058/26050 (epoch 19.305), train_loss = 0.87107063, grad/param norm = 1.7314e-01, time/batch = 18.8120s	
10059/26050 (epoch 19.307), train_loss = 0.96342352, grad/param norm = 1.7478e-01, time/batch = 16.9726s	
10060/26050 (epoch 19.309), train_loss = 1.02204018, grad/param norm = 1.9144e-01, time/batch = 18.4861s	
10061/26050 (epoch 19.311), train_loss = 1.15137883, grad/param norm = 2.2632e-01, time/batch = 17.3273s	
10062/26050 (epoch 19.313), train_loss = 1.04184792, grad/param norm = 2.0673e-01, time/batch = 17.5596s	
10063/26050 (epoch 19.315), train_loss = 1.15512618, grad/param norm = 2.0099e-01, time/batch = 14.9767s	
10064/26050 (epoch 19.317), train_loss = 1.05181455, grad/param norm = 1.8538e-01, time/batch = 14.6292s	
10065/26050 (epoch 19.319), train_loss = 0.97355408, grad/param norm = 1.7023e-01, time/batch = 18.7254s	
10066/26050 (epoch 19.321), train_loss = 0.99825867, grad/param norm = 1.6518e-01, time/batch = 17.6413s	
10067/26050 (epoch 19.322), train_loss = 1.05861523, grad/param norm = 1.6209e-01, time/batch = 18.3923s	
10068/26050 (epoch 19.324), train_loss = 0.87005437, grad/param norm = 1.7158e-01, time/batch = 16.7936s	
10069/26050 (epoch 19.326), train_loss = 1.17230485, grad/param norm = 1.8322e-01, time/batch = 17.1402s	
10070/26050 (epoch 19.328), train_loss = 1.08926815, grad/param norm = 1.7740e-01, time/batch = 17.7394s	
10071/26050 (epoch 19.330), train_loss = 0.93163886, grad/param norm = 1.7359e-01, time/batch = 17.5797s	
10072/26050 (epoch 19.332), train_loss = 1.08264991, grad/param norm = 1.7858e-01, time/batch = 18.2149s	
10073/26050 (epoch 19.334), train_loss = 1.00878210, grad/param norm = 1.8432e-01, time/batch = 18.0443s	
10074/26050 (epoch 19.336), train_loss = 0.97496796, grad/param norm = 1.7457e-01, time/batch = 18.3184s	
10075/26050 (epoch 19.338), train_loss = 0.91993642, grad/param norm = 1.5186e-01, time/batch = 18.6495s	
10076/26050 (epoch 19.340), train_loss = 1.14657327, grad/param norm = 1.9952e-01, time/batch = 16.3780s	
10077/26050 (epoch 19.342), train_loss = 1.16239750, grad/param norm = 1.9303e-01, time/batch = 18.2336s	
10078/26050 (epoch 19.344), train_loss = 0.99037764, grad/param norm = 1.8345e-01, time/batch = 18.3898s	
10079/26050 (epoch 19.345), train_loss = 1.01758068, grad/param norm = 1.8448e-01, time/batch = 15.8770s	
10080/26050 (epoch 19.347), train_loss = 1.16670937, grad/param norm = 1.8697e-01, time/batch = 17.9641s	
10081/26050 (epoch 19.349), train_loss = 1.10391161, grad/param norm = 1.9502e-01, time/batch = 14.9597s	
10082/26050 (epoch 19.351), train_loss = 1.06929763, grad/param norm = 1.9913e-01, time/batch = 18.5663s	
10083/26050 (epoch 19.353), train_loss = 1.05098150, grad/param norm = 2.0934e-01, time/batch = 24.9507s	
10084/26050 (epoch 19.355), train_loss = 1.09693650, grad/param norm = 1.9955e-01, time/batch = 32.5429s	
10085/26050 (epoch 19.357), train_loss = 0.97605026, grad/param norm = 1.5900e-01, time/batch = 17.2883s	
10086/26050 (epoch 19.359), train_loss = 1.13287690, grad/param norm = 1.7839e-01, time/batch = 18.1484s	
10087/26050 (epoch 19.361), train_loss = 0.96451997, grad/param norm = 1.6575e-01, time/batch = 18.8041s	
10088/26050 (epoch 19.363), train_loss = 1.10735145, grad/param norm = 1.7402e-01, time/batch = 18.0788s	
10089/26050 (epoch 19.365), train_loss = 1.00960384, grad/param norm = 1.5854e-01, time/batch = 17.9079s	
10090/26050 (epoch 19.367), train_loss = 1.09122380, grad/param norm = 1.8333e-01, time/batch = 16.6358s	
10091/26050 (epoch 19.369), train_loss = 0.99585487, grad/param norm = 1.7424e-01, time/batch = 18.8045s	
10092/26050 (epoch 19.370), train_loss = 0.93639267, grad/param norm = 1.5943e-01, time/batch = 18.3969s	
10093/26050 (epoch 19.372), train_loss = 1.09908539, grad/param norm = 1.7334e-01, time/batch = 15.8043s	
10094/26050 (epoch 19.374), train_loss = 1.18234622, grad/param norm = 1.8935e-01, time/batch = 18.4031s	
10095/26050 (epoch 19.376), train_loss = 1.25325782, grad/param norm = 1.9184e-01, time/batch = 14.8749s	
10096/26050 (epoch 19.378), train_loss = 1.01980878, grad/param norm = 1.6888e-01, time/batch = 17.8983s	
10097/26050 (epoch 19.380), train_loss = 1.23474127, grad/param norm = 2.0506e-01, time/batch = 17.1645s	
10098/26050 (epoch 19.382), train_loss = 1.32624496, grad/param norm = 2.1606e-01, time/batch = 17.2348s	
10099/26050 (epoch 19.384), train_loss = 1.06119857, grad/param norm = 1.9594e-01, time/batch = 18.2937s	
10100/26050 (epoch 19.386), train_loss = 1.13705015, grad/param norm = 2.3498e-01, time/batch = 18.1521s	
10101/26050 (epoch 19.388), train_loss = 1.06469165, grad/param norm = 1.9236e-01, time/batch = 18.5641s	
10102/26050 (epoch 19.390), train_loss = 0.98651625, grad/param norm = 1.7563e-01, time/batch = 16.7309s	
10103/26050 (epoch 19.392), train_loss = 0.92914833, grad/param norm = 1.6666e-01, time/batch = 18.8310s	
10104/26050 (epoch 19.393), train_loss = 1.10958461, grad/param norm = 1.8947e-01, time/batch = 18.0880s	
10105/26050 (epoch 19.395), train_loss = 1.10110313, grad/param norm = 1.7354e-01, time/batch = 18.1365s	
10106/26050 (epoch 19.397), train_loss = 1.10214825, grad/param norm = 1.9376e-01, time/batch = 18.6434s	
10107/26050 (epoch 19.399), train_loss = 0.96642111, grad/param norm = 1.7407e-01, time/batch = 15.8977s	
10108/26050 (epoch 19.401), train_loss = 1.05965017, grad/param norm = 2.0250e-01, time/batch = 18.1497s	
10109/26050 (epoch 19.403), train_loss = 1.07369333, grad/param norm = 1.8154e-01, time/batch = 17.9515s	
10110/26050 (epoch 19.405), train_loss = 1.06508178, grad/param norm = 1.7872e-01, time/batch = 18.7359s	
10111/26050 (epoch 19.407), train_loss = 1.19107651, grad/param norm = 1.8524e-01, time/batch = 19.0612s	
10112/26050 (epoch 19.409), train_loss = 1.23105997, grad/param norm = 1.9816e-01, time/batch = 17.8002s	
10113/26050 (epoch 19.411), train_loss = 1.10727486, grad/param norm = 1.9089e-01, time/batch = 16.4076s	
10114/26050 (epoch 19.413), train_loss = 1.22061024, grad/param norm = 1.7738e-01, time/batch = 16.4742s	
10115/26050 (epoch 19.415), train_loss = 1.17643109, grad/param norm = 2.0314e-01, time/batch = 17.7292s	
10116/26050 (epoch 19.417), train_loss = 1.27542608, grad/param norm = 2.0517e-01, time/batch = 17.1608s	
10117/26050 (epoch 19.418), train_loss = 1.16915802, grad/param norm = 2.0333e-01, time/batch = 18.4025s	
10118/26050 (epoch 19.420), train_loss = 0.89689765, grad/param norm = 1.8195e-01, time/batch = 16.8783s	
10119/26050 (epoch 19.422), train_loss = 0.90954532, grad/param norm = 1.7148e-01, time/batch = 17.1329s	
10120/26050 (epoch 19.424), train_loss = 1.20300103, grad/param norm = 2.2042e-01, time/batch = 16.4685s	
10121/26050 (epoch 19.426), train_loss = 1.18050242, grad/param norm = 1.9078e-01, time/batch = 18.3982s	
10122/26050 (epoch 19.428), train_loss = 0.97825973, grad/param norm = 1.5699e-01, time/batch = 16.8133s	
10123/26050 (epoch 19.430), train_loss = 1.15862027, grad/param norm = 1.7456e-01, time/batch = 18.9613s	
10124/26050 (epoch 19.432), train_loss = 1.02460611, grad/param norm = 1.8019e-01, time/batch = 17.8154s	
10125/26050 (epoch 19.434), train_loss = 1.03700574, grad/param norm = 1.9359e-01, time/batch = 15.8094s	
10126/26050 (epoch 19.436), train_loss = 1.18301411, grad/param norm = 1.9540e-01, time/batch = 18.0463s	
10127/26050 (epoch 19.438), train_loss = 1.07640180, grad/param norm = 1.7975e-01, time/batch = 18.2999s	
10128/26050 (epoch 19.440), train_loss = 1.07394479, grad/param norm = 1.8218e-01, time/batch = 18.1323s	
10129/26050 (epoch 19.441), train_loss = 1.06306300, grad/param norm = 1.8763e-01, time/batch = 17.1518s	
10130/26050 (epoch 19.443), train_loss = 0.90224866, grad/param norm = 1.5235e-01, time/batch = 18.3262s	
10131/26050 (epoch 19.445), train_loss = 0.98342469, grad/param norm = 1.6875e-01, time/batch = 17.0827s	
10132/26050 (epoch 19.447), train_loss = 1.21206733, grad/param norm = 2.0478e-01, time/batch = 17.6526s	
10133/26050 (epoch 19.449), train_loss = 0.97575897, grad/param norm = 1.6898e-01, time/batch = 18.0751s	
10134/26050 (epoch 19.451), train_loss = 1.21793277, grad/param norm = 1.9434e-01, time/batch = 15.3117s	
10135/26050 (epoch 19.453), train_loss = 0.98826447, grad/param norm = 1.6369e-01, time/batch = 16.8269s	
10136/26050 (epoch 19.455), train_loss = 1.08861981, grad/param norm = 1.7224e-01, time/batch = 16.0489s	
10137/26050 (epoch 19.457), train_loss = 1.06475616, grad/param norm = 1.7906e-01, time/batch = 18.7353s	
10138/26050 (epoch 19.459), train_loss = 1.16919252, grad/param norm = 1.8630e-01, time/batch = 18.7379s	
10139/26050 (epoch 19.461), train_loss = 1.16197916, grad/param norm = 2.1327e-01, time/batch = 17.5708s	
10140/26050 (epoch 19.463), train_loss = 1.02753029, grad/param norm = 1.7656e-01, time/batch = 14.9803s	
10141/26050 (epoch 19.464), train_loss = 1.10938862, grad/param norm = 1.7868e-01, time/batch = 17.7497s	
10142/26050 (epoch 19.466), train_loss = 1.12746520, grad/param norm = 1.8814e-01, time/batch = 18.5717s	
10143/26050 (epoch 19.468), train_loss = 1.14996102, grad/param norm = 1.6599e-01, time/batch = 18.1568s	
10144/26050 (epoch 19.470), train_loss = 1.21701162, grad/param norm = 2.0393e-01, time/batch = 18.3178s	
10145/26050 (epoch 19.472), train_loss = 1.21291863, grad/param norm = 2.1153e-01, time/batch = 17.8117s	
10146/26050 (epoch 19.474), train_loss = 1.23638807, grad/param norm = 1.8606e-01, time/batch = 15.3136s	
10147/26050 (epoch 19.476), train_loss = 1.19405248, grad/param norm = 1.8007e-01, time/batch = 18.7124s	
10148/26050 (epoch 19.478), train_loss = 1.04742849, grad/param norm = 1.8172e-01, time/batch = 17.6513s	
10149/26050 (epoch 19.480), train_loss = 1.06559485, grad/param norm = 1.6204e-01, time/batch = 15.4037s	
10150/26050 (epoch 19.482), train_loss = 1.02090238, grad/param norm = 1.8014e-01, time/batch = 17.5367s	
10151/26050 (epoch 19.484), train_loss = 1.02012967, grad/param norm = 1.8044e-01, time/batch = 18.7070s	
10152/26050 (epoch 19.486), train_loss = 1.21725671, grad/param norm = 1.9065e-01, time/batch = 18.4800s	
10153/26050 (epoch 19.488), train_loss = 1.31803139, grad/param norm = 2.0374e-01, time/batch = 17.1625s	
10154/26050 (epoch 19.489), train_loss = 1.26830981, grad/param norm = 2.1826e-01, time/batch = 17.5770s	
10155/26050 (epoch 19.491), train_loss = 0.97837746, grad/param norm = 1.7940e-01, time/batch = 18.2378s	
10156/26050 (epoch 19.493), train_loss = 1.09765269, grad/param norm = 1.9143e-01, time/batch = 18.3155s	
10157/26050 (epoch 19.495), train_loss = 1.06640766, grad/param norm = 1.7375e-01, time/batch = 18.5637s	
10158/26050 (epoch 19.497), train_loss = 0.98121762, grad/param norm = 1.7079e-01, time/batch = 17.6426s	
10159/26050 (epoch 19.499), train_loss = 1.02792359, grad/param norm = 1.7502e-01, time/batch = 15.7990s	
10160/26050 (epoch 19.501), train_loss = 1.14912144, grad/param norm = 1.9604e-01, time/batch = 17.9732s	
10161/26050 (epoch 19.503), train_loss = 1.01715093, grad/param norm = 1.7382e-01, time/batch = 18.5687s	
10162/26050 (epoch 19.505), train_loss = 1.19599967, grad/param norm = 1.7080e-01, time/batch = 18.4844s	
10163/26050 (epoch 19.507), train_loss = 1.15297149, grad/param norm = 1.9015e-01, time/batch = 16.6364s	
10164/26050 (epoch 19.509), train_loss = 1.26227465, grad/param norm = 1.8379e-01, time/batch = 17.9936s	
10165/26050 (epoch 19.511), train_loss = 1.00081663, grad/param norm = 1.6372e-01, time/batch = 17.7492s	
10166/26050 (epoch 19.512), train_loss = 0.99980358, grad/param norm = 1.7447e-01, time/batch = 15.7990s	
10167/26050 (epoch 19.514), train_loss = 1.13890520, grad/param norm = 1.9066e-01, time/batch = 18.3147s	
10168/26050 (epoch 19.516), train_loss = 1.19548944, grad/param norm = 1.9327e-01, time/batch = 18.7373s	
10169/26050 (epoch 19.518), train_loss = 1.07647071, grad/param norm = 1.8911e-01, time/batch = 17.7350s	
10170/26050 (epoch 19.520), train_loss = 1.04747786, grad/param norm = 1.6873e-01, time/batch = 14.4566s	
10171/26050 (epoch 19.522), train_loss = 0.84383030, grad/param norm = 1.5552e-01, time/batch = 16.2245s	
10172/26050 (epoch 19.524), train_loss = 1.16819856, grad/param norm = 2.0192e-01, time/batch = 18.0713s	
10173/26050 (epoch 19.526), train_loss = 1.18819247, grad/param norm = 2.0684e-01, time/batch = 16.9574s	
10174/26050 (epoch 19.528), train_loss = 1.13170456, grad/param norm = 2.1920e-01, time/batch = 18.5683s	
10175/26050 (epoch 19.530), train_loss = 1.05343764, grad/param norm = 1.8694e-01, time/batch = 17.6521s	
10176/26050 (epoch 19.532), train_loss = 1.07950586, grad/param norm = 1.7682e-01, time/batch = 18.7124s	
10177/26050 (epoch 19.534), train_loss = 1.13723788, grad/param norm = 2.0678e-01, time/batch = 17.3887s	
10178/26050 (epoch 19.536), train_loss = 1.06397626, grad/param norm = 1.7732e-01, time/batch = 16.9645s	
10179/26050 (epoch 19.537), train_loss = 1.15772140, grad/param norm = 1.8842e-01, time/batch = 18.0676s	
10180/26050 (epoch 19.539), train_loss = 1.09257863, grad/param norm = 2.0632e-01, time/batch = 17.0640s	
10181/26050 (epoch 19.541), train_loss = 1.29759968, grad/param norm = 2.1350e-01, time/batch = 18.8049s	
10182/26050 (epoch 19.543), train_loss = 0.91741920, grad/param norm = 1.8221e-01, time/batch = 17.9778s	
10183/26050 (epoch 19.545), train_loss = 1.14061156, grad/param norm = 1.9315e-01, time/batch = 17.9046s	
10184/26050 (epoch 19.547), train_loss = 1.06619588, grad/param norm = 1.7524e-01, time/batch = 18.1401s	
10185/26050 (epoch 19.549), train_loss = 0.88607872, grad/param norm = 1.6574e-01, time/batch = 17.0659s	
10186/26050 (epoch 19.551), train_loss = 1.14031947, grad/param norm = 1.7898e-01, time/batch = 14.4543s	
10187/26050 (epoch 19.553), train_loss = 0.99638195, grad/param norm = 1.6995e-01, time/batch = 16.9977s	
10188/26050 (epoch 19.555), train_loss = 1.01376463, grad/param norm = 1.6954e-01, time/batch = 18.3274s	
10189/26050 (epoch 19.557), train_loss = 1.12969379, grad/param norm = 1.7471e-01, time/batch = 18.3924s	
10190/26050 (epoch 19.559), train_loss = 1.05811789, grad/param norm = 1.7341e-01, time/batch = 17.8074s	
10191/26050 (epoch 19.560), train_loss = 1.04043794, grad/param norm = 1.8295e-01, time/batch = 18.1509s	
10192/26050 (epoch 19.562), train_loss = 1.03624854, grad/param norm = 1.7768e-01, time/batch = 16.2937s	
10193/26050 (epoch 19.564), train_loss = 1.23831862, grad/param norm = 1.7681e-01, time/batch = 18.3836s	
10194/26050 (epoch 19.566), train_loss = 0.97765650, grad/param norm = 1.6385e-01, time/batch = 19.7130s	
10195/26050 (epoch 19.568), train_loss = 1.10748322, grad/param norm = 1.8822e-01, time/batch = 18.1467s	
10196/26050 (epoch 19.570), train_loss = 1.14849652, grad/param norm = 1.9246e-01, time/batch = 18.1512s	
10197/26050 (epoch 19.572), train_loss = 1.04518748, grad/param norm = 1.8956e-01, time/batch = 16.9778s	
10198/26050 (epoch 19.574), train_loss = 1.13445075, grad/param norm = 2.1135e-01, time/batch = 18.5691s	
10199/26050 (epoch 19.576), train_loss = 1.09398429, grad/param norm = 1.8162e-01, time/batch = 16.3039s	
10200/26050 (epoch 19.578), train_loss = 1.04024027, grad/param norm = 1.8215e-01, time/batch = 16.4534s	
10201/26050 (epoch 19.580), train_loss = 0.99642679, grad/param norm = 1.8499e-01, time/batch = 17.8601s	
10202/26050 (epoch 19.582), train_loss = 1.10238150, grad/param norm = 1.8423e-01, time/batch = 17.8850s	
10203/26050 (epoch 19.583), train_loss = 1.18247971, grad/param norm = 1.7667e-01, time/batch = 18.2205s	
10204/26050 (epoch 19.585), train_loss = 0.94789374, grad/param norm = 1.8207e-01, time/batch = 17.5468s	
10205/26050 (epoch 19.587), train_loss = 1.12685716, grad/param norm = 2.0029e-01, time/batch = 18.9046s	
10206/26050 (epoch 19.589), train_loss = 1.22919945, grad/param norm = 2.0403e-01, time/batch = 18.1644s	
10207/26050 (epoch 19.591), train_loss = 1.04285753, grad/param norm = 1.7118e-01, time/batch = 17.2284s	
10208/26050 (epoch 19.593), train_loss = 0.94451441, grad/param norm = 1.7144e-01, time/batch = 16.7446s	
10209/26050 (epoch 19.595), train_loss = 1.16045995, grad/param norm = 2.0795e-01, time/batch = 16.5394s	
10210/26050 (epoch 19.597), train_loss = 1.10262163, grad/param norm = 1.7875e-01, time/batch = 14.6559s	
10211/26050 (epoch 19.599), train_loss = 1.07637763, grad/param norm = 1.9514e-01, time/batch = 18.1494s	
10212/26050 (epoch 19.601), train_loss = 1.24850309, grad/param norm = 1.8504e-01, time/batch = 18.7965s	
10213/26050 (epoch 19.603), train_loss = 1.10282013, grad/param norm = 1.8612e-01, time/batch = 17.8982s	
10214/26050 (epoch 19.605), train_loss = 1.01781458, grad/param norm = 1.7607e-01, time/batch = 14.4803s	
10215/26050 (epoch 19.607), train_loss = 1.18417271, grad/param norm = 1.9723e-01, time/batch = 18.4894s	
10216/26050 (epoch 19.608), train_loss = 0.92995352, grad/param norm = 1.5097e-01, time/batch = 17.1528s	
10217/26050 (epoch 19.610), train_loss = 1.05249216, grad/param norm = 1.9054e-01, time/batch = 17.7323s	
10218/26050 (epoch 19.612), train_loss = 1.07050392, grad/param norm = 1.9036e-01, time/batch = 17.3280s	
10219/26050 (epoch 19.614), train_loss = 1.10919503, grad/param norm = 1.8470e-01, time/batch = 15.7149s	
10220/26050 (epoch 19.616), train_loss = 1.23655223, grad/param norm = 2.0781e-01, time/batch = 17.9010s	
10221/26050 (epoch 19.618), train_loss = 1.02632945, grad/param norm = 1.9264e-01, time/batch = 14.9730s	
10222/26050 (epoch 19.620), train_loss = 1.10783546, grad/param norm = 1.7903e-01, time/batch = 16.8795s	
10223/26050 (epoch 19.622), train_loss = 0.94488207, grad/param norm = 1.4951e-01, time/batch = 18.5806s	
10224/26050 (epoch 19.624), train_loss = 0.93228318, grad/param norm = 1.5937e-01, time/batch = 17.9762s	
10225/26050 (epoch 19.626), train_loss = 1.12428611, grad/param norm = 1.8227e-01, time/batch = 18.1361s	
10226/26050 (epoch 19.628), train_loss = 0.99365332, grad/param norm = 1.7344e-01, time/batch = 18.2124s	
10227/26050 (epoch 19.630), train_loss = 1.18208375, grad/param norm = 1.7922e-01, time/batch = 18.2386s	
10228/26050 (epoch 19.631), train_loss = 1.22928710, grad/param norm = 1.8676e-01, time/batch = 15.5550s	
10229/26050 (epoch 19.633), train_loss = 0.96675470, grad/param norm = 1.6593e-01, time/batch = 17.8133s	
10230/26050 (epoch 19.635), train_loss = 0.98823824, grad/param norm = 1.6053e-01, time/batch = 17.8981s	
10231/26050 (epoch 19.637), train_loss = 0.95875498, grad/param norm = 1.7254e-01, time/batch = 17.4645s	
10232/26050 (epoch 19.639), train_loss = 1.16817746, grad/param norm = 1.7840e-01, time/batch = 18.6392s	
10233/26050 (epoch 19.641), train_loss = 1.03914823, grad/param norm = 1.6751e-01, time/batch = 14.8936s	
10234/26050 (epoch 19.643), train_loss = 0.95056819, grad/param norm = 1.5269e-01, time/batch = 18.2323s	
10235/26050 (epoch 19.645), train_loss = 1.07045836, grad/param norm = 1.7997e-01, time/batch = 18.2972s	
10236/26050 (epoch 19.647), train_loss = 1.00962123, grad/param norm = 1.8361e-01, time/batch = 18.6425s	
10237/26050 (epoch 19.649), train_loss = 1.09784877, grad/param norm = 1.9607e-01, time/batch = 18.1365s	
10238/26050 (epoch 19.651), train_loss = 1.00396697, grad/param norm = 1.8277e-01, time/batch = 16.7157s	
10239/26050 (epoch 19.653), train_loss = 1.08104191, grad/param norm = 1.7546e-01, time/batch = 17.7906s	
10240/26050 (epoch 19.655), train_loss = 0.99483359, grad/param norm = 1.7106e-01, time/batch = 18.4751s	
10241/26050 (epoch 19.656), train_loss = 0.92022576, grad/param norm = 1.6766e-01, time/batch = 17.5647s	
10242/26050 (epoch 19.658), train_loss = 1.25833747, grad/param norm = 1.9782e-01, time/batch = 18.9131s	
10243/26050 (epoch 19.660), train_loss = 0.94624917, grad/param norm = 1.7507e-01, time/batch = 18.2345s	
10244/26050 (epoch 19.662), train_loss = 0.99274127, grad/param norm = 1.7162e-01, time/batch = 16.1236s	
10245/26050 (epoch 19.664), train_loss = 1.04194258, grad/param norm = 1.7663e-01, time/batch = 18.2079s	
10246/26050 (epoch 19.666), train_loss = 1.04263363, grad/param norm = 1.9912e-01, time/batch = 18.6608s	
10247/26050 (epoch 19.668), train_loss = 0.89462101, grad/param norm = 1.8303e-01, time/batch = 17.8995s	
10248/26050 (epoch 19.670), train_loss = 1.20413109, grad/param norm = 2.0066e-01, time/batch = 17.0553s	
10249/26050 (epoch 19.672), train_loss = 1.03369540, grad/param norm = 1.7614e-01, time/batch = 17.9881s	
10250/26050 (epoch 19.674), train_loss = 0.97351390, grad/param norm = 1.7125e-01, time/batch = 16.3898s	
10251/26050 (epoch 19.676), train_loss = 1.11365819, grad/param norm = 1.9805e-01, time/batch = 17.2249s	
10252/26050 (epoch 19.678), train_loss = 1.18817760, grad/param norm = 2.0213e-01, time/batch = 16.9940s	
10253/26050 (epoch 19.679), train_loss = 1.24818605, grad/param norm = 1.9706e-01, time/batch = 18.7967s	
10254/26050 (epoch 19.681), train_loss = 1.07509084, grad/param norm = 1.8340e-01, time/batch = 16.4599s	
10255/26050 (epoch 19.683), train_loss = 0.96377768, grad/param norm = 1.9699e-01, time/batch = 14.8055s	
10256/26050 (epoch 19.685), train_loss = 1.00699575, grad/param norm = 1.7285e-01, time/batch = 17.7527s	
10257/26050 (epoch 19.687), train_loss = 0.90334348, grad/param norm = 1.6599e-01, time/batch = 18.3277s	
10258/26050 (epoch 19.689), train_loss = 1.03394664, grad/param norm = 1.8623e-01, time/batch = 17.5778s	
10259/26050 (epoch 19.691), train_loss = 0.83814729, grad/param norm = 1.5694e-01, time/batch = 16.7336s	
10260/26050 (epoch 19.693), train_loss = 0.95383706, grad/param norm = 1.7545e-01, time/batch = 17.2208s	
10261/26050 (epoch 19.695), train_loss = 1.06109066, grad/param norm = 1.7702e-01, time/batch = 18.4910s	
10262/26050 (epoch 19.697), train_loss = 0.96707766, grad/param norm = 1.7334e-01, time/batch = 16.3706s	
10263/26050 (epoch 19.699), train_loss = 1.10534333, grad/param norm = 1.8873e-01, time/batch = 17.4834s	
10264/26050 (epoch 19.701), train_loss = 0.95792618, grad/param norm = 1.6698e-01, time/batch = 18.7351s	
10265/26050 (epoch 19.702), train_loss = 1.17137602, grad/param norm = 1.8182e-01, time/batch = 17.9033s	
10266/26050 (epoch 19.704), train_loss = 1.14421068, grad/param norm = 1.6351e-01, time/batch = 18.4928s	
10267/26050 (epoch 19.706), train_loss = 1.04983950, grad/param norm = 1.9744e-01, time/batch = 17.8298s	
10268/26050 (epoch 19.708), train_loss = 1.14497644, grad/param norm = 1.8318e-01, time/batch = 17.1686s	
10269/26050 (epoch 19.710), train_loss = 1.13667482, grad/param norm = 2.0222e-01, time/batch = 18.2114s	
10270/26050 (epoch 19.712), train_loss = 1.13968024, grad/param norm = 1.8999e-01, time/batch = 15.7225s	
10271/26050 (epoch 19.714), train_loss = 0.90922000, grad/param norm = 1.6311e-01, time/batch = 18.0496s	
10272/26050 (epoch 19.716), train_loss = 1.30496288, grad/param norm = 2.0566e-01, time/batch = 17.1469s	
10273/26050 (epoch 19.718), train_loss = 1.16150234, grad/param norm = 1.8909e-01, time/batch = 16.2288s	
10274/26050 (epoch 19.720), train_loss = 1.03860161, grad/param norm = 1.9030e-01, time/batch = 17.2300s	
10275/26050 (epoch 19.722), train_loss = 0.93389312, grad/param norm = 1.7330e-01, time/batch = 15.0617s	
10276/26050 (epoch 19.724), train_loss = 0.97927616, grad/param norm = 1.8895e-01, time/batch = 17.0356s	
10277/26050 (epoch 19.726), train_loss = 1.14970714, grad/param norm = 1.9275e-01, time/batch = 17.9886s	
10278/26050 (epoch 19.727), train_loss = 1.14865325, grad/param norm = 1.9734e-01, time/batch = 18.5712s	
10279/26050 (epoch 19.729), train_loss = 1.10406511, grad/param norm = 1.8271e-01, time/batch = 17.6387s	
10280/26050 (epoch 19.731), train_loss = 1.10237083, grad/param norm = 1.9455e-01, time/batch = 18.1603s	
10281/26050 (epoch 19.733), train_loss = 1.02553965, grad/param norm = 2.1379e-01, time/batch = 18.5807s	
10282/26050 (epoch 19.735), train_loss = 1.25603261, grad/param norm = 1.9829e-01, time/batch = 16.8278s	
10283/26050 (epoch 19.737), train_loss = 1.00542183, grad/param norm = 1.7232e-01, time/batch = 14.7779s	
10284/26050 (epoch 19.739), train_loss = 1.08777550, grad/param norm = 1.7853e-01, time/batch = 18.4070s	
10285/26050 (epoch 19.741), train_loss = 0.97079996, grad/param norm = 1.7875e-01, time/batch = 18.6402s	
10286/26050 (epoch 19.743), train_loss = 1.09094105, grad/param norm = 2.0533e-01, time/batch = 26.3748s	
10287/26050 (epoch 19.745), train_loss = 0.93649414, grad/param norm = 1.6870e-01, time/batch = 30.3005s	
10288/26050 (epoch 19.747), train_loss = 0.95569479, grad/param norm = 1.6854e-01, time/batch = 15.9229s	
10289/26050 (epoch 19.749), train_loss = 1.18267294, grad/param norm = 1.9167e-01, time/batch = 18.3950s	
10290/26050 (epoch 19.750), train_loss = 1.04593111, grad/param norm = 1.6833e-01, time/batch = 18.4999s	
10291/26050 (epoch 19.752), train_loss = 1.03837516, grad/param norm = 1.9495e-01, time/batch = 17.4006s	
10292/26050 (epoch 19.754), train_loss = 1.08445077, grad/param norm = 1.8749e-01, time/batch = 17.9194s	
10293/26050 (epoch 19.756), train_loss = 1.06239327, grad/param norm = 1.9367e-01, time/batch = 17.3275s	
10294/26050 (epoch 19.758), train_loss = 1.05306705, grad/param norm = 1.9458e-01, time/batch = 18.4902s	
10295/26050 (epoch 19.760), train_loss = 1.23892758, grad/param norm = 1.8701e-01, time/batch = 15.6286s	
10296/26050 (epoch 19.762), train_loss = 0.99424122, grad/param norm = 1.7038e-01, time/batch = 18.4851s	
10297/26050 (epoch 19.764), train_loss = 1.08847298, grad/param norm = 1.9236e-01, time/batch = 18.5649s	
10298/26050 (epoch 19.766), train_loss = 1.12990318, grad/param norm = 1.9779e-01, time/batch = 16.9798s	
10299/26050 (epoch 19.768), train_loss = 0.95818300, grad/param norm = 1.6035e-01, time/batch = 16.9682s	
10300/26050 (epoch 19.770), train_loss = 1.05125421, grad/param norm = 1.9050e-01, time/batch = 15.6582s	
10301/26050 (epoch 19.772), train_loss = 1.04534944, grad/param norm = 1.6620e-01, time/batch = 18.1500s	
10302/26050 (epoch 19.774), train_loss = 0.91956867, grad/param norm = 1.6646e-01, time/batch = 17.3063s	
10303/26050 (epoch 19.775), train_loss = 0.76396393, grad/param norm = 1.6007e-01, time/batch = 18.0790s	
10304/26050 (epoch 19.777), train_loss = 0.98291381, grad/param norm = 1.7364e-01, time/batch = 17.9203s	
10305/26050 (epoch 19.779), train_loss = 1.03666040, grad/param norm = 1.9403e-01, time/batch = 16.8078s	
10306/26050 (epoch 19.781), train_loss = 0.97298483, grad/param norm = 1.9837e-01, time/batch = 18.4757s	
10307/26050 (epoch 19.783), train_loss = 0.95261671, grad/param norm = 1.8229e-01, time/batch = 17.5359s	
10308/26050 (epoch 19.785), train_loss = 1.04256954, grad/param norm = 1.7625e-01, time/batch = 17.6399s	
10309/26050 (epoch 19.787), train_loss = 0.97959525, grad/param norm = 1.7096e-01, time/batch = 16.7996s	
10310/26050 (epoch 19.789), train_loss = 1.00469819, grad/param norm = 2.1777e-01, time/batch = 17.8992s	
10311/26050 (epoch 19.791), train_loss = 1.00899384, grad/param norm = 1.8397e-01, time/batch = 18.4834s	
10312/26050 (epoch 19.793), train_loss = 1.04138428, grad/param norm = 1.9144e-01, time/batch = 14.5526s	
10313/26050 (epoch 19.795), train_loss = 0.86097085, grad/param norm = 1.4533e-01, time/batch = 18.4863s	
10314/26050 (epoch 19.797), train_loss = 0.96439586, grad/param norm = 1.5788e-01, time/batch = 18.8229s	
10315/26050 (epoch 19.798), train_loss = 0.89095824, grad/param norm = 1.6962e-01, time/batch = 14.6296s	
10316/26050 (epoch 19.800), train_loss = 0.90829040, grad/param norm = 1.5192e-01, time/batch = 18.5582s	
10317/26050 (epoch 19.802), train_loss = 1.00091142, grad/param norm = 1.8546e-01, time/batch = 18.1379s	
10318/26050 (epoch 19.804), train_loss = 1.02913072, grad/param norm = 1.8720e-01, time/batch = 18.3281s	
10319/26050 (epoch 19.806), train_loss = 1.14535088, grad/param norm = 1.9079e-01, time/batch = 17.6320s	
10320/26050 (epoch 19.808), train_loss = 1.04307449, grad/param norm = 1.7112e-01, time/batch = 18.6595s	
10321/26050 (epoch 19.810), train_loss = 0.99567868, grad/param norm = 1.8430e-01, time/batch = 18.5395s	
10322/26050 (epoch 19.812), train_loss = 0.95063042, grad/param norm = 1.8797e-01, time/batch = 17.1529s	
10323/26050 (epoch 19.814), train_loss = 0.94580413, grad/param norm = 2.0946e-01, time/batch = 18.1260s	
10324/26050 (epoch 19.816), train_loss = 1.15162380, grad/param norm = 2.0028e-01, time/batch = 17.4613s	
10325/26050 (epoch 19.818), train_loss = 1.16103816, grad/param norm = 2.1160e-01, time/batch = 17.5530s	
10326/26050 (epoch 19.820), train_loss = 1.06331011, grad/param norm = 1.7473e-01, time/batch = 17.8836s	
10327/26050 (epoch 19.821), train_loss = 1.19767559, grad/param norm = 2.0312e-01, time/batch = 18.3887s	
10328/26050 (epoch 19.823), train_loss = 1.19041227, grad/param norm = 1.9703e-01, time/batch = 17.8903s	
10329/26050 (epoch 19.825), train_loss = 1.03787400, grad/param norm = 1.8181e-01, time/batch = 17.8867s	
10330/26050 (epoch 19.827), train_loss = 1.06290404, grad/param norm = 2.0831e-01, time/batch = 18.4005s	
10331/26050 (epoch 19.829), train_loss = 1.15781403, grad/param norm = 1.9926e-01, time/batch = 17.0707s	
10332/26050 (epoch 19.831), train_loss = 1.17744016, grad/param norm = 1.9755e-01, time/batch = 17.0375s	
10333/26050 (epoch 19.833), train_loss = 1.26031074, grad/param norm = 1.9919e-01, time/batch = 18.5696s	
10334/26050 (epoch 19.835), train_loss = 1.24315704, grad/param norm = 1.9607e-01, time/batch = 17.6386s	
10335/26050 (epoch 19.837), train_loss = 1.05395424, grad/param norm = 1.7632e-01, time/batch = 17.5505s	
10336/26050 (epoch 19.839), train_loss = 1.09130604, grad/param norm = 2.1308e-01, time/batch = 18.3122s	
10337/26050 (epoch 19.841), train_loss = 1.19257833, grad/param norm = 2.0103e-01, time/batch = 18.3161s	
10338/26050 (epoch 19.843), train_loss = 1.05044787, grad/param norm = 1.7227e-01, time/batch = 18.0734s	
10339/26050 (epoch 19.845), train_loss = 1.00153765, grad/param norm = 1.6311e-01, time/batch = 14.9721s	
10340/26050 (epoch 19.846), train_loss = 1.14539924, grad/param norm = 1.7404e-01, time/batch = 16.6257s	
10341/26050 (epoch 19.848), train_loss = 1.04521621, grad/param norm = 1.7942e-01, time/batch = 18.8986s	
10342/26050 (epoch 19.850), train_loss = 0.96775522, grad/param norm = 1.6449e-01, time/batch = 15.9684s	
10343/26050 (epoch 19.852), train_loss = 1.06342931, grad/param norm = 1.7891e-01, time/batch = 18.5512s	
10344/26050 (epoch 19.854), train_loss = 1.03312868, grad/param norm = 1.7739e-01, time/batch = 17.4829s	
10345/26050 (epoch 19.856), train_loss = 1.02296394, grad/param norm = 1.8841e-01, time/batch = 17.9134s	
10346/26050 (epoch 19.858), train_loss = 0.95146519, grad/param norm = 1.7080e-01, time/batch = 18.4815s	
10347/26050 (epoch 19.860), train_loss = 1.08914317, grad/param norm = 1.8990e-01, time/batch = 18.3975s	
10348/26050 (epoch 19.862), train_loss = 1.11760445, grad/param norm = 1.7946e-01, time/batch = 18.2263s	
10349/26050 (epoch 19.864), train_loss = 1.09751476, grad/param norm = 2.1056e-01, time/batch = 17.1432s	
10350/26050 (epoch 19.866), train_loss = 1.00988963, grad/param norm = 1.6730e-01, time/batch = 16.0755s	
10351/26050 (epoch 19.868), train_loss = 1.10769957, grad/param norm = 1.8356e-01, time/batch = 15.3770s	
10352/26050 (epoch 19.869), train_loss = 0.94371299, grad/param norm = 1.6736e-01, time/batch = 17.1503s	
10353/26050 (epoch 19.871), train_loss = 0.88149120, grad/param norm = 1.6237e-01, time/batch = 17.6518s	
10354/26050 (epoch 19.873), train_loss = 1.09896888, grad/param norm = 2.0444e-01, time/batch = 18.2505s	
10355/26050 (epoch 19.875), train_loss = 1.04400119, grad/param norm = 1.9235e-01, time/batch = 18.2437s	
10356/26050 (epoch 19.877), train_loss = 0.95061389, grad/param norm = 1.7039e-01, time/batch = 14.4653s	
10357/26050 (epoch 19.879), train_loss = 1.07671840, grad/param norm = 1.7119e-01, time/batch = 18.3942s	
10358/26050 (epoch 19.881), train_loss = 1.16627137, grad/param norm = 1.9465e-01, time/batch = 16.4007s	
10359/26050 (epoch 19.883), train_loss = 1.10554004, grad/param norm = 1.8268e-01, time/batch = 17.1355s	
10360/26050 (epoch 19.885), train_loss = 0.78895855, grad/param norm = 1.5346e-01, time/batch = 18.1500s	
10361/26050 (epoch 19.887), train_loss = 1.10002417, grad/param norm = 1.8101e-01, time/batch = 17.9852s	
10362/26050 (epoch 19.889), train_loss = 1.01370245, grad/param norm = 1.7568e-01, time/batch = 18.6488s	
10363/26050 (epoch 19.891), train_loss = 0.85968860, grad/param norm = 1.5926e-01, time/batch = 15.5237s	
10364/26050 (epoch 19.893), train_loss = 0.91410371, grad/param norm = 1.6905e-01, time/batch = 18.2890s	
10365/26050 (epoch 19.894), train_loss = 1.01053964, grad/param norm = 1.7178e-01, time/batch = 18.4833s	
10366/26050 (epoch 19.896), train_loss = 1.14117562, grad/param norm = 1.7332e-01, time/batch = 17.7309s	
10367/26050 (epoch 19.898), train_loss = 0.98552071, grad/param norm = 1.7969e-01, time/batch = 18.9080s	
10368/26050 (epoch 19.900), train_loss = 1.08620720, grad/param norm = 1.8538e-01, time/batch = 17.5525s	
10369/26050 (epoch 19.902), train_loss = 1.03171587, grad/param norm = 1.7478e-01, time/batch = 17.9037s	
10370/26050 (epoch 19.904), train_loss = 1.03125050, grad/param norm = 1.7808e-01, time/batch = 14.4730s	
10371/26050 (epoch 19.906), train_loss = 1.03646694, grad/param norm = 1.9491e-01, time/batch = 18.4795s	
10372/26050 (epoch 19.908), train_loss = 1.03926232, grad/param norm = 1.7654e-01, time/batch = 17.9852s	
10373/26050 (epoch 19.910), train_loss = 0.98711756, grad/param norm = 1.6391e-01, time/batch = 16.8985s	
10374/26050 (epoch 19.912), train_loss = 1.25985723, grad/param norm = 2.0403e-01, time/batch = 17.5704s	
10375/26050 (epoch 19.914), train_loss = 1.40449786, grad/param norm = 2.2014e-01, time/batch = 18.5686s	
10376/26050 (epoch 19.916), train_loss = 1.16388435, grad/param norm = 2.0731e-01, time/batch = 17.1471s	
10377/26050 (epoch 19.917), train_loss = 1.07628041, grad/param norm = 2.1582e-01, time/batch = 18.8220s	
10378/26050 (epoch 19.919), train_loss = 1.14632745, grad/param norm = 2.1178e-01, time/batch = 17.9978s	
10379/26050 (epoch 19.921), train_loss = 1.00212307, grad/param norm = 1.9324e-01, time/batch = 16.7388s	
10380/26050 (epoch 19.923), train_loss = 1.06123093, grad/param norm = 1.8143e-01, time/batch = 17.0298s	
10381/26050 (epoch 19.925), train_loss = 1.05039396, grad/param norm = 1.8012e-01, time/batch = 18.7386s	
10382/26050 (epoch 19.927), train_loss = 0.92033158, grad/param norm = 1.4784e-01, time/batch = 18.3236s	
10383/26050 (epoch 19.929), train_loss = 0.91612010, grad/param norm = 1.7058e-01, time/batch = 17.4866s	
10384/26050 (epoch 19.931), train_loss = 1.24829838, grad/param norm = 2.1945e-01, time/batch = 14.9708s	
10385/26050 (epoch 19.933), train_loss = 0.99830675, grad/param norm = 1.7332e-01, time/batch = 16.8808s	
10386/26050 (epoch 19.935), train_loss = 1.03554505, grad/param norm = 1.8664e-01, time/batch = 17.4497s	
10387/26050 (epoch 19.937), train_loss = 1.14297716, grad/param norm = 1.8366e-01, time/batch = 17.4074s	
10388/26050 (epoch 19.939), train_loss = 0.96744325, grad/param norm = 1.5750e-01, time/batch = 18.7393s	
10389/26050 (epoch 19.940), train_loss = 1.02739673, grad/param norm = 1.6614e-01, time/batch = 18.3349s	
10390/26050 (epoch 19.942), train_loss = 1.04850384, grad/param norm = 1.8071e-01, time/batch = 17.3015s	
10391/26050 (epoch 19.944), train_loss = 0.98877240, grad/param norm = 1.6162e-01, time/batch = 16.4675s	
10392/26050 (epoch 19.946), train_loss = 1.18837752, grad/param norm = 1.9599e-01, time/batch = 18.5538s	
10393/26050 (epoch 19.948), train_loss = 0.94636475, grad/param norm = 1.9005e-01, time/batch = 17.0717s	
10394/26050 (epoch 19.950), train_loss = 1.01840430, grad/param norm = 1.7693e-01, time/batch = 18.3220s	
10395/26050 (epoch 19.952), train_loss = 1.15727343, grad/param norm = 1.9752e-01, time/batch = 17.5546s	
10396/26050 (epoch 19.954), train_loss = 1.15651309, grad/param norm = 1.9118e-01, time/batch = 17.3121s	
10397/26050 (epoch 19.956), train_loss = 1.05286742, grad/param norm = 1.8950e-01, time/batch = 16.8687s	
10398/26050 (epoch 19.958), train_loss = 0.99342159, grad/param norm = 1.7008e-01, time/batch = 18.6382s	
10399/26050 (epoch 19.960), train_loss = 1.06760348, grad/param norm = 1.8761e-01, time/batch = 18.4994s	
10400/26050 (epoch 19.962), train_loss = 0.97765247, grad/param norm = 1.5650e-01, time/batch = 17.1471s	
10401/26050 (epoch 19.964), train_loss = 1.04523472, grad/param norm = 1.8414e-01, time/batch = 15.1378s	
10402/26050 (epoch 19.965), train_loss = 0.97468721, grad/param norm = 1.7995e-01, time/batch = 17.8956s	
10403/26050 (epoch 19.967), train_loss = 1.37616023, grad/param norm = 1.9845e-01, time/batch = 15.5591s	
10404/26050 (epoch 19.969), train_loss = 1.04143019, grad/param norm = 1.7520e-01, time/batch = 17.2055s	
10405/26050 (epoch 19.971), train_loss = 1.00158689, grad/param norm = 1.6187e-01, time/batch = 17.6626s	
10406/26050 (epoch 19.973), train_loss = 1.04008363, grad/param norm = 1.8674e-01, time/batch = 17.8222s	
10407/26050 (epoch 19.975), train_loss = 1.08143293, grad/param norm = 1.6765e-01, time/batch = 16.8244s	
10408/26050 (epoch 19.977), train_loss = 1.08066940, grad/param norm = 1.6362e-01, time/batch = 18.7312s	
10409/26050 (epoch 19.979), train_loss = 0.88646081, grad/param norm = 1.6874e-01, time/batch = 18.8984s	
10410/26050 (epoch 19.981), train_loss = 1.18091102, grad/param norm = 1.7225e-01, time/batch = 17.3041s	
10411/26050 (epoch 19.983), train_loss = 1.13893051, grad/param norm = 2.1206e-01, time/batch = 17.2897s	
10412/26050 (epoch 19.985), train_loss = 1.10949976, grad/param norm = 1.8891e-01, time/batch = 15.0660s	
10413/26050 (epoch 19.987), train_loss = 1.16033191, grad/param norm = 1.7784e-01, time/batch = 18.2335s	
10414/26050 (epoch 19.988), train_loss = 1.14826179, grad/param norm = 1.9068e-01, time/batch = 17.5679s	
10415/26050 (epoch 19.990), train_loss = 0.94150737, grad/param norm = 1.5239e-01, time/batch = 18.6495s	
10416/26050 (epoch 19.992), train_loss = 1.21865335, grad/param norm = 2.0164e-01, time/batch = 17.9107s	
10417/26050 (epoch 19.994), train_loss = 1.02745981, grad/param norm = 1.9576e-01, time/batch = 17.7317s	
10418/26050 (epoch 19.996), train_loss = 1.00939404, grad/param norm = 1.9083e-01, time/batch = 18.4861s	
10419/26050 (epoch 19.998), train_loss = 1.05756894, grad/param norm = 1.6616e-01, time/batch = 17.1510s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
10420/26050 (epoch 20.000), train_loss = 1.00792353, grad/param norm = 1.9161e-01, time/batch = 17.0591s	
10421/26050 (epoch 20.002), train_loss = 1.12647427, grad/param norm = 2.0029e-01, time/batch = 18.6344s	
10422/26050 (epoch 20.004), train_loss = 0.96585121, grad/param norm = 1.7772e-01, time/batch = 15.3882s	
10423/26050 (epoch 20.006), train_loss = 0.99866725, grad/param norm = 1.8554e-01, time/batch = 16.5418s	
10424/26050 (epoch 20.008), train_loss = 0.96287615, grad/param norm = 1.8864e-01, time/batch = 15.6442s	
10425/26050 (epoch 20.010), train_loss = 0.97634437, grad/param norm = 1.8276e-01, time/batch = 16.7474s	
10426/26050 (epoch 20.012), train_loss = 1.05766842, grad/param norm = 1.7855e-01, time/batch = 18.5792s	
10427/26050 (epoch 20.013), train_loss = 1.36216590, grad/param norm = 2.0809e-01, time/batch = 18.1480s	
10428/26050 (epoch 20.015), train_loss = 1.00151305, grad/param norm = 1.5505e-01, time/batch = 18.6169s	
10429/26050 (epoch 20.017), train_loss = 1.06147664, grad/param norm = 1.7646e-01, time/batch = 15.2403s	
10430/26050 (epoch 20.019), train_loss = 0.90464343, grad/param norm = 1.5749e-01, time/batch = 18.4803s	
10431/26050 (epoch 20.021), train_loss = 1.11301648, grad/param norm = 1.8283e-01, time/batch = 17.3903s	
10432/26050 (epoch 20.023), train_loss = 0.88066326, grad/param norm = 1.6616e-01, time/batch = 18.8133s	
10433/26050 (epoch 20.025), train_loss = 1.05146888, grad/param norm = 1.7743e-01, time/batch = 18.0712s	
10434/26050 (epoch 20.027), train_loss = 0.84984600, grad/param norm = 1.7534e-01, time/batch = 17.1439s	
10435/26050 (epoch 20.029), train_loss = 1.06566043, grad/param norm = 1.6559e-01, time/batch = 18.3202s	
10436/26050 (epoch 20.031), train_loss = 1.18378969, grad/param norm = 2.1152e-01, time/batch = 15.6568s	
10437/26050 (epoch 20.033), train_loss = 1.07425010, grad/param norm = 1.8259e-01, time/batch = 18.7193s	
10438/26050 (epoch 20.035), train_loss = 1.10128978, grad/param norm = 1.8159e-01, time/batch = 16.3798s	
10439/26050 (epoch 20.036), train_loss = 0.95691463, grad/param norm = 1.8861e-01, time/batch = 18.5687s	
10440/26050 (epoch 20.038), train_loss = 0.87941468, grad/param norm = 1.7487e-01, time/batch = 17.9919s	
10441/26050 (epoch 20.040), train_loss = 1.03676947, grad/param norm = 1.8474e-01, time/batch = 17.5682s	
10442/26050 (epoch 20.042), train_loss = 0.90281867, grad/param norm = 1.8930e-01, time/batch = 17.0535s	
10443/26050 (epoch 20.044), train_loss = 1.12931466, grad/param norm = 1.6580e-01, time/batch = 18.1562s	
10444/26050 (epoch 20.046), train_loss = 0.84693042, grad/param norm = 1.5048e-01, time/batch = 17.5697s	
10445/26050 (epoch 20.048), train_loss = 1.05738470, grad/param norm = 1.8099e-01, time/batch = 17.8138s	
10446/26050 (epoch 20.050), train_loss = 0.97680344, grad/param norm = 1.7145e-01, time/batch = 15.5482s	
10447/26050 (epoch 20.052), train_loss = 0.99420663, grad/param norm = 1.9459e-01, time/batch = 17.3063s	
10448/26050 (epoch 20.054), train_loss = 0.88364646, grad/param norm = 1.5735e-01, time/batch = 17.0248s	
10449/26050 (epoch 20.056), train_loss = 0.84610637, grad/param norm = 1.5334e-01, time/batch = 18.2271s	
10450/26050 (epoch 20.058), train_loss = 0.99980232, grad/param norm = 1.6905e-01, time/batch = 18.7949s	
10451/26050 (epoch 20.060), train_loss = 1.10814436, grad/param norm = 1.8243e-01, time/batch = 17.8068s	
10452/26050 (epoch 20.061), train_loss = 0.94828816, grad/param norm = 1.7368e-01, time/batch = 18.2413s	
10453/26050 (epoch 20.063), train_loss = 1.08560596, grad/param norm = 1.8059e-01, time/batch = 18.5478s	
10454/26050 (epoch 20.065), train_loss = 0.84907681, grad/param norm = 1.5166e-01, time/batch = 18.2284s	
10455/26050 (epoch 20.067), train_loss = 1.04979621, grad/param norm = 1.7634e-01, time/batch = 16.8188s	
10456/26050 (epoch 20.069), train_loss = 1.09199883, grad/param norm = 1.7498e-01, time/batch = 18.6374s	
10457/26050 (epoch 20.071), train_loss = 1.10799556, grad/param norm = 1.7948e-01, time/batch = 18.1672s	
10458/26050 (epoch 20.073), train_loss = 1.22928803, grad/param norm = 2.0047e-01, time/batch = 15.4519s	
10459/26050 (epoch 20.075), train_loss = 0.95914218, grad/param norm = 1.6636e-01, time/batch = 18.2171s	
10460/26050 (epoch 20.077), train_loss = 0.97859958, grad/param norm = 1.7518e-01, time/batch = 18.9788s	
10461/26050 (epoch 20.079), train_loss = 1.07009801, grad/param norm = 1.8557e-01, time/batch = 17.8066s	
10462/26050 (epoch 20.081), train_loss = 1.00128700, grad/param norm = 1.6678e-01, time/batch = 18.3091s	
10463/26050 (epoch 20.083), train_loss = 1.13011909, grad/param norm = 1.7511e-01, time/batch = 18.2424s	
10464/26050 (epoch 20.084), train_loss = 1.05407157, grad/param norm = 1.9088e-01, time/batch = 17.6541s	
10465/26050 (epoch 20.086), train_loss = 1.20585440, grad/param norm = 2.0556e-01, time/batch = 15.3901s	
10466/26050 (epoch 20.088), train_loss = 0.96288572, grad/param norm = 1.7736e-01, time/batch = 18.3945s	
10467/26050 (epoch 20.090), train_loss = 1.06248265, grad/param norm = 1.8361e-01, time/batch = 15.2312s	
10468/26050 (epoch 20.092), train_loss = 1.10065912, grad/param norm = 1.7928e-01, time/batch = 17.5688s	
10469/26050 (epoch 20.094), train_loss = 0.98467439, grad/param norm = 1.7939e-01, time/batch = 18.7185s	
10470/26050 (epoch 20.096), train_loss = 1.02491840, grad/param norm = 1.6981e-01, time/batch = 17.9053s	
10471/26050 (epoch 20.098), train_loss = 0.99579754, grad/param norm = 1.9053e-01, time/batch = 18.3092s	
10472/26050 (epoch 20.100), train_loss = 0.94013160, grad/param norm = 1.8014e-01, time/batch = 17.8038s	
10473/26050 (epoch 20.102), train_loss = 1.07280896, grad/param norm = 1.8033e-01, time/batch = 18.1634s	
10474/26050 (epoch 20.104), train_loss = 1.03682777, grad/param norm = 1.8575e-01, time/batch = 18.8179s	
10475/26050 (epoch 20.106), train_loss = 1.04296072, grad/param norm = 1.9810e-01, time/batch = 17.2192s	
10476/26050 (epoch 20.107), train_loss = 0.83593667, grad/param norm = 1.6118e-01, time/batch = 17.0574s	
10477/26050 (epoch 20.109), train_loss = 0.96179732, grad/param norm = 1.8081e-01, time/batch = 15.3590s	
10478/26050 (epoch 20.111), train_loss = 1.21626271, grad/param norm = 1.9693e-01, time/batch = 16.4745s	
10479/26050 (epoch 20.113), train_loss = 0.98347003, grad/param norm = 1.7761e-01, time/batch = 18.3987s	
10480/26050 (epoch 20.115), train_loss = 1.12838710, grad/param norm = 1.7445e-01, time/batch = 17.9062s	
10481/26050 (epoch 20.117), train_loss = 1.05961194, grad/param norm = 1.7535e-01, time/batch = 18.4947s	
10482/26050 (epoch 20.119), train_loss = 0.87351451, grad/param norm = 1.7154e-01, time/batch = 18.4750s	
10483/26050 (epoch 20.121), train_loss = 1.06395799, grad/param norm = 1.7166e-01, time/batch = 17.6641s	
10484/26050 (epoch 20.123), train_loss = 0.93898625, grad/param norm = 1.6327e-01, time/batch = 17.7454s	
10485/26050 (epoch 20.125), train_loss = 0.89120567, grad/param norm = 1.6691e-01, time/batch = 17.3993s	
10486/26050 (epoch 20.127), train_loss = 0.83101256, grad/param norm = 1.7649e-01, time/batch = 18.9055s	
10487/26050 (epoch 20.129), train_loss = 0.89226797, grad/param norm = 1.7727e-01, time/batch = 14.6879s	
10488/26050 (epoch 20.131), train_loss = 1.00083107, grad/param norm = 1.6825e-01, time/batch = 17.9754s	
10489/26050 (epoch 20.132), train_loss = 1.00331660, grad/param norm = 1.5976e-01, time/batch = 32.0147s	
10490/26050 (epoch 20.134), train_loss = 1.04565750, grad/param norm = 2.0446e-01, time/batch = 24.3867s	
10491/26050 (epoch 20.136), train_loss = 1.03707110, grad/param norm = 1.7612e-01, time/batch = 15.7217s	
10492/26050 (epoch 20.138), train_loss = 0.78539665, grad/param norm = 1.5493e-01, time/batch = 18.1439s	
10493/26050 (epoch 20.140), train_loss = 0.85729036, grad/param norm = 1.7372e-01, time/batch = 18.0746s	
10494/26050 (epoch 20.142), train_loss = 0.89777767, grad/param norm = 1.8878e-01, time/batch = 18.0632s	
10495/26050 (epoch 20.144), train_loss = 0.83414867, grad/param norm = 1.7177e-01, time/batch = 18.4001s	
10496/26050 (epoch 20.146), train_loss = 0.78539790, grad/param norm = 1.6690e-01, time/batch = 15.6664s	
10497/26050 (epoch 20.148), train_loss = 0.81427966, grad/param norm = 1.4440e-01, time/batch = 17.8830s	
10498/26050 (epoch 20.150), train_loss = 0.99752770, grad/param norm = 1.8102e-01, time/batch = 16.4683s	
10499/26050 (epoch 20.152), train_loss = 1.22170707, grad/param norm = 2.3680e-01, time/batch = 18.6273s	
10500/26050 (epoch 20.154), train_loss = 0.80872236, grad/param norm = 1.6369e-01, time/batch = 18.1538s	
10501/26050 (epoch 20.155), train_loss = 0.85388196, grad/param norm = 1.6560e-01, time/batch = 16.7357s	
10502/26050 (epoch 20.157), train_loss = 0.96876982, grad/param norm = 2.0401e-01, time/batch = 18.3967s	
10503/26050 (epoch 20.159), train_loss = 1.02716050, grad/param norm = 1.9074e-01, time/batch = 17.8258s	
10504/26050 (epoch 20.161), train_loss = 1.07491854, grad/param norm = 1.9188e-01, time/batch = 14.3069s	
10505/26050 (epoch 20.163), train_loss = 0.84389886, grad/param norm = 1.7134e-01, time/batch = 15.8811s	
10506/26050 (epoch 20.165), train_loss = 0.78473512, grad/param norm = 1.6149e-01, time/batch = 14.8980s	
10507/26050 (epoch 20.167), train_loss = 1.11725618, grad/param norm = 1.8893e-01, time/batch = 17.9877s	
10508/26050 (epoch 20.169), train_loss = 1.05633950, grad/param norm = 1.9589e-01, time/batch = 17.0733s	
10509/26050 (epoch 20.171), train_loss = 0.85327274, grad/param norm = 1.6007e-01, time/batch = 18.8166s	
10510/26050 (epoch 20.173), train_loss = 0.96059649, grad/param norm = 1.9261e-01, time/batch = 18.3913s	
10511/26050 (epoch 20.175), train_loss = 0.98025346, grad/param norm = 1.6076e-01, time/batch = 17.3914s	
10512/26050 (epoch 20.177), train_loss = 1.12389588, grad/param norm = 1.7756e-01, time/batch = 16.4871s	
10513/26050 (epoch 20.179), train_loss = 0.78783167, grad/param norm = 1.5875e-01, time/batch = 17.0591s	
10514/26050 (epoch 20.180), train_loss = 1.22342098, grad/param norm = 1.8252e-01, time/batch = 18.8124s	
10515/26050 (epoch 20.182), train_loss = 1.24272917, grad/param norm = 1.8867e-01, time/batch = 17.8919s	
10516/26050 (epoch 20.184), train_loss = 1.04244529, grad/param norm = 1.7335e-01, time/batch = 14.9063s	
10517/26050 (epoch 20.186), train_loss = 0.86035942, grad/param norm = 1.6147e-01, time/batch = 18.4127s	
10518/26050 (epoch 20.188), train_loss = 1.00798812, grad/param norm = 1.8144e-01, time/batch = 18.0492s	
10519/26050 (epoch 20.190), train_loss = 1.07420743, grad/param norm = 1.8710e-01, time/batch = 18.5698s	
10520/26050 (epoch 20.192), train_loss = 1.07135193, grad/param norm = 1.6511e-01, time/batch = 17.7159s	
10521/26050 (epoch 20.194), train_loss = 1.07310598, grad/param norm = 1.8723e-01, time/batch = 17.9802s	
10522/26050 (epoch 20.196), train_loss = 1.12450349, grad/param norm = 1.9264e-01, time/batch = 18.3739s	
10523/26050 (epoch 20.198), train_loss = 0.93725560, grad/param norm = 1.6668e-01, time/batch = 16.5448s	
10524/26050 (epoch 20.200), train_loss = 0.93176972, grad/param norm = 1.7287e-01, time/batch = 15.2934s	
10525/26050 (epoch 20.202), train_loss = 1.02546962, grad/param norm = 1.8496e-01, time/batch = 17.2274s	
10526/26050 (epoch 20.203), train_loss = 1.14179392, grad/param norm = 2.0046e-01, time/batch = 16.3858s	
10527/26050 (epoch 20.205), train_loss = 0.95757186, grad/param norm = 1.7047e-01, time/batch = 18.2348s	
10528/26050 (epoch 20.207), train_loss = 0.95416215, grad/param norm = 1.6819e-01, time/batch = 18.2551s	
10529/26050 (epoch 20.209), train_loss = 1.06073773, grad/param norm = 1.6801e-01, time/batch = 18.2942s	
10530/26050 (epoch 20.211), train_loss = 0.86502060, grad/param norm = 1.5842e-01, time/batch = 18.3125s	
10531/26050 (epoch 20.213), train_loss = 1.07373908, grad/param norm = 1.9032e-01, time/batch = 14.4859s	
10532/26050 (epoch 20.215), train_loss = 1.01282781, grad/param norm = 1.9321e-01, time/batch = 17.3106s	
10533/26050 (epoch 20.217), train_loss = 0.97982364, grad/param norm = 1.7036e-01, time/batch = 18.7242s	
10534/26050 (epoch 20.219), train_loss = 1.00995025, grad/param norm = 1.9683e-01, time/batch = 19.1496s	
10535/26050 (epoch 20.221), train_loss = 0.92837242, grad/param norm = 1.8157e-01, time/batch = 17.2320s	
10536/26050 (epoch 20.223), train_loss = 1.05415607, grad/param norm = 1.8862e-01, time/batch = 17.8260s	
10537/26050 (epoch 20.225), train_loss = 0.91376156, grad/param norm = 1.8488e-01, time/batch = 15.4875s	
10538/26050 (epoch 20.226), train_loss = 1.06829184, grad/param norm = 2.0673e-01, time/batch = 18.2120s	
10539/26050 (epoch 20.228), train_loss = 1.15536777, grad/param norm = 1.9094e-01, time/batch = 16.8092s	
10540/26050 (epoch 20.230), train_loss = 1.05796384, grad/param norm = 1.7275e-01, time/batch = 18.4149s	
10541/26050 (epoch 20.232), train_loss = 1.11331160, grad/param norm = 1.9947e-01, time/batch = 18.2357s	
10542/26050 (epoch 20.234), train_loss = 0.90831382, grad/param norm = 1.7472e-01, time/batch = 17.4927s	
10543/26050 (epoch 20.236), train_loss = 1.11751443, grad/param norm = 2.0074e-01, time/batch = 17.4780s	
10544/26050 (epoch 20.238), train_loss = 0.89028128, grad/param norm = 1.6820e-01, time/batch = 16.1274s	
10545/26050 (epoch 20.240), train_loss = 1.02262619, grad/param norm = 1.8133e-01, time/batch = 14.3001s	
10546/26050 (epoch 20.242), train_loss = 1.02660635, grad/param norm = 1.7161e-01, time/batch = 14.6201s	
10547/26050 (epoch 20.244), train_loss = 1.02771322, grad/param norm = 2.0466e-01, time/batch = 15.5358s	
10548/26050 (epoch 20.246), train_loss = 0.95103759, grad/param norm = 1.6506e-01, time/batch = 14.4424s	
10549/26050 (epoch 20.248), train_loss = 1.03353376, grad/param norm = 1.7697e-01, time/batch = 15.3063s	
10550/26050 (epoch 20.250), train_loss = 1.02294716, grad/param norm = 1.9818e-01, time/batch = 16.8040s	
10551/26050 (epoch 20.251), train_loss = 0.98844355, grad/param norm = 1.7040e-01, time/batch = 14.8916s	
10552/26050 (epoch 20.253), train_loss = 0.89482066, grad/param norm = 1.7186e-01, time/batch = 19.1485s	
10553/26050 (epoch 20.255), train_loss = 1.19507458, grad/param norm = 1.9450e-01, time/batch = 17.7429s	
10554/26050 (epoch 20.257), train_loss = 1.01599707, grad/param norm = 2.0468e-01, time/batch = 18.1577s	
10555/26050 (epoch 20.259), train_loss = 1.16889185, grad/param norm = 1.9834e-01, time/batch = 18.3152s	
10556/26050 (epoch 20.261), train_loss = 0.92021312, grad/param norm = 1.8379e-01, time/batch = 18.3325s	
10557/26050 (epoch 20.263), train_loss = 1.08812332, grad/param norm = 1.9243e-01, time/batch = 7.9824s	
10558/26050 (epoch 20.265), train_loss = 1.17213300, grad/param norm = 1.8238e-01, time/batch = 0.6513s	
10559/26050 (epoch 20.267), train_loss = 1.13596287, grad/param norm = 1.6985e-01, time/batch = 0.6506s	
10560/26050 (epoch 20.269), train_loss = 1.15993082, grad/param norm = 1.8789e-01, time/batch = 0.6571s	
10561/26050 (epoch 20.271), train_loss = 1.07467640, grad/param norm = 1.8550e-01, time/batch = 0.6605s	
10562/26050 (epoch 20.273), train_loss = 0.98626320, grad/param norm = 2.0141e-01, time/batch = 0.6521s	
10563/26050 (epoch 20.274), train_loss = 0.99881500, grad/param norm = 1.6897e-01, time/batch = 0.6569s	
10564/26050 (epoch 20.276), train_loss = 0.98262280, grad/param norm = 1.8414e-01, time/batch = 0.6519s	
10565/26050 (epoch 20.278), train_loss = 1.15325444, grad/param norm = 1.7551e-01, time/batch = 0.9089s	
10566/26050 (epoch 20.280), train_loss = 1.02517445, grad/param norm = 1.6975e-01, time/batch = 0.9651s	
10567/26050 (epoch 20.282), train_loss = 1.06806336, grad/param norm = 1.8965e-01, time/batch = 0.9452s	
10568/26050 (epoch 20.284), train_loss = 0.97993232, grad/param norm = 1.8283e-01, time/batch = 0.9396s	
10569/26050 (epoch 20.286), train_loss = 1.05159696, grad/param norm = 2.0050e-01, time/batch = 0.9405s	
10570/26050 (epoch 20.288), train_loss = 0.88247515, grad/param norm = 1.6191e-01, time/batch = 1.4386s	
10571/26050 (epoch 20.290), train_loss = 1.04393464, grad/param norm = 1.7997e-01, time/batch = 1.8110s	
10572/26050 (epoch 20.292), train_loss = 0.93375158, grad/param norm = 1.5929e-01, time/batch = 1.7631s	
10573/26050 (epoch 20.294), train_loss = 1.04895694, grad/param norm = 2.1241e-01, time/batch = 15.6460s	
10574/26050 (epoch 20.296), train_loss = 1.12272237, grad/param norm = 1.7997e-01, time/batch = 18.1423s	
10575/26050 (epoch 20.298), train_loss = 1.02842547, grad/param norm = 1.6469e-01, time/batch = 17.0412s	
10576/26050 (epoch 20.299), train_loss = 0.82351204, grad/param norm = 1.4632e-01, time/batch = 17.6488s	
10577/26050 (epoch 20.301), train_loss = 0.90655900, grad/param norm = 1.8039e-01, time/batch = 18.4826s	
10578/26050 (epoch 20.303), train_loss = 1.02105699, grad/param norm = 1.8789e-01, time/batch = 15.3796s	
10579/26050 (epoch 20.305), train_loss = 0.86165048, grad/param norm = 1.8262e-01, time/batch = 17.3020s	
10580/26050 (epoch 20.307), train_loss = 0.94487309, grad/param norm = 1.7783e-01, time/batch = 17.8296s	
10581/26050 (epoch 20.309), train_loss = 1.00858607, grad/param norm = 2.0787e-01, time/batch = 18.8998s	
10582/26050 (epoch 20.311), train_loss = 1.12829151, grad/param norm = 2.2285e-01, time/batch = 18.3792s	
10583/26050 (epoch 20.313), train_loss = 1.02935078, grad/param norm = 2.3337e-01, time/batch = 18.4022s	
10584/26050 (epoch 20.315), train_loss = 1.13486423, grad/param norm = 1.9406e-01, time/batch = 18.1663s	
10585/26050 (epoch 20.317), train_loss = 1.03811419, grad/param norm = 1.8154e-01, time/batch = 16.4151s	
10586/26050 (epoch 20.319), train_loss = 0.95195907, grad/param norm = 1.7875e-01, time/batch = 18.7416s	
10587/26050 (epoch 20.321), train_loss = 0.98780647, grad/param norm = 1.7253e-01, time/batch = 15.3144s	
10588/26050 (epoch 20.322), train_loss = 1.04866161, grad/param norm = 1.6880e-01, time/batch = 14.8022s	
10589/26050 (epoch 20.324), train_loss = 0.85975875, grad/param norm = 1.8215e-01, time/batch = 20.6022s	
10590/26050 (epoch 20.326), train_loss = 1.16199527, grad/param norm = 2.1569e-01, time/batch = 20.5684s	
10591/26050 (epoch 20.328), train_loss = 1.06675872, grad/param norm = 1.8422e-01, time/batch = 23.5911s	
10592/26050 (epoch 20.330), train_loss = 0.91450561, grad/param norm = 1.6749e-01, time/batch = 24.4760s	
10593/26050 (epoch 20.332), train_loss = 1.07491842, grad/param norm = 1.7467e-01, time/batch = 25.0104s	
10594/26050 (epoch 20.334), train_loss = 0.97979286, grad/param norm = 1.9597e-01, time/batch = 23.9230s	
10595/26050 (epoch 20.336), train_loss = 0.97470833, grad/param norm = 1.8605e-01, time/batch = 21.9107s	
10596/26050 (epoch 20.338), train_loss = 0.90031764, grad/param norm = 1.5225e-01, time/batch = 18.2237s	
10597/26050 (epoch 20.340), train_loss = 1.12243054, grad/param norm = 1.8910e-01, time/batch = 23.3824s	
10598/26050 (epoch 20.342), train_loss = 1.14020457, grad/param norm = 1.8776e-01, time/batch = 22.4760s	
10599/26050 (epoch 20.344), train_loss = 0.97181593, grad/param norm = 1.8974e-01, time/batch = 23.2487s	
10600/26050 (epoch 20.345), train_loss = 1.00913400, grad/param norm = 2.0305e-01, time/batch = 24.2292s	
10601/26050 (epoch 20.347), train_loss = 1.15313138, grad/param norm = 1.9243e-01, time/batch = 24.3166s	
10602/26050 (epoch 20.349), train_loss = 1.08564791, grad/param norm = 1.9698e-01, time/batch = 22.4899s	
10603/26050 (epoch 20.351), train_loss = 1.05134288, grad/param norm = 1.7772e-01, time/batch = 23.8415s	
10604/26050 (epoch 20.353), train_loss = 1.02905209, grad/param norm = 1.8070e-01, time/batch = 19.4353s	
10605/26050 (epoch 20.355), train_loss = 1.08548494, grad/param norm = 2.0500e-01, time/batch = 33.8651s	
10606/26050 (epoch 20.357), train_loss = 0.95830593, grad/param norm = 1.6887e-01, time/batch = 18.7125s	
10607/26050 (epoch 20.359), train_loss = 1.12791047, grad/param norm = 1.8739e-01, time/batch = 17.8032s	
10608/26050 (epoch 20.361), train_loss = 0.94594855, grad/param norm = 1.6778e-01, time/batch = 14.6458s	
10609/26050 (epoch 20.363), train_loss = 1.09671700, grad/param norm = 1.8137e-01, time/batch = 16.1443s	
10610/26050 (epoch 20.365), train_loss = 0.98936673, grad/param norm = 1.6040e-01, time/batch = 16.3937s	
10611/26050 (epoch 20.367), train_loss = 1.07744022, grad/param norm = 1.7190e-01, time/batch = 18.7434s	
10612/26050 (epoch 20.369), train_loss = 0.97708233, grad/param norm = 1.6341e-01, time/batch = 17.0934s	
10613/26050 (epoch 20.370), train_loss = 0.91462172, grad/param norm = 1.5570e-01, time/batch = 13.9178s	
10614/26050 (epoch 20.372), train_loss = 1.08700754, grad/param norm = 1.9106e-01, time/batch = 14.0737s	
10615/26050 (epoch 20.374), train_loss = 1.16111280, grad/param norm = 1.8570e-01, time/batch = 14.0137s	
10616/26050 (epoch 20.376), train_loss = 1.24672786, grad/param norm = 1.9853e-01, time/batch = 13.8456s	
10617/26050 (epoch 20.378), train_loss = 0.98371734, grad/param norm = 1.6954e-01, time/batch = 16.7203s	
10618/26050 (epoch 20.380), train_loss = 1.22671076, grad/param norm = 2.2534e-01, time/batch = 16.8910s	
10619/26050 (epoch 20.382), train_loss = 1.29586258, grad/param norm = 2.2139e-01, time/batch = 17.8207s	
10620/26050 (epoch 20.384), train_loss = 1.03379324, grad/param norm = 2.0251e-01, time/batch = 16.7210s	
10621/26050 (epoch 20.386), train_loss = 1.10962806, grad/param norm = 2.1787e-01, time/batch = 17.3286s	
10622/26050 (epoch 20.388), train_loss = 1.04685664, grad/param norm = 1.8218e-01, time/batch = 17.7312s	
10623/26050 (epoch 20.390), train_loss = 0.96914577, grad/param norm = 1.7467e-01, time/batch = 18.5757s	
10624/26050 (epoch 20.392), train_loss = 0.91044418, grad/param norm = 1.5692e-01, time/batch = 15.1546s	
10625/26050 (epoch 20.393), train_loss = 1.07982314, grad/param norm = 1.9158e-01, time/batch = 16.3204s	
10626/26050 (epoch 20.395), train_loss = 1.07864270, grad/param norm = 1.6997e-01, time/batch = 17.7321s	
10627/26050 (epoch 20.397), train_loss = 1.08229514, grad/param norm = 1.9727e-01, time/batch = 17.9715s	
10628/26050 (epoch 20.399), train_loss = 0.96052342, grad/param norm = 1.9225e-01, time/batch = 17.4021s	
10629/26050 (epoch 20.401), train_loss = 1.03564242, grad/param norm = 1.9835e-01, time/batch = 17.5577s	
10630/26050 (epoch 20.403), train_loss = 1.05187995, grad/param norm = 1.8938e-01, time/batch = 18.3126s	
10631/26050 (epoch 20.405), train_loss = 1.05794722, grad/param norm = 1.8149e-01, time/batch = 16.5687s	
10632/26050 (epoch 20.407), train_loss = 1.18764982, grad/param norm = 1.8783e-01, time/batch = 15.2971s	
10633/26050 (epoch 20.409), train_loss = 1.20742779, grad/param norm = 2.0048e-01, time/batch = 17.1449s	
10634/26050 (epoch 20.411), train_loss = 1.10053886, grad/param norm = 1.9911e-01, time/batch = 17.8312s	
10635/26050 (epoch 20.413), train_loss = 1.19981472, grad/param norm = 1.7845e-01, time/batch = 17.4765s	
10636/26050 (epoch 20.415), train_loss = 1.15565115, grad/param norm = 1.8392e-01, time/batch = 17.1450s	
10637/26050 (epoch 20.417), train_loss = 1.24781419, grad/param norm = 1.9180e-01, time/batch = 18.4918s	
10638/26050 (epoch 20.418), train_loss = 1.15933387, grad/param norm = 2.1312e-01, time/batch = 18.4772s	
10639/26050 (epoch 20.420), train_loss = 0.88946277, grad/param norm = 1.6639e-01, time/batch = 15.6365s	
10640/26050 (epoch 20.422), train_loss = 0.89362912, grad/param norm = 1.7612e-01, time/batch = 18.0749s	
10641/26050 (epoch 20.424), train_loss = 1.17645390, grad/param norm = 2.0537e-01, time/batch = 18.1561s	
10642/26050 (epoch 20.426), train_loss = 1.15381173, grad/param norm = 1.8412e-01, time/batch = 17.2277s	
10643/26050 (epoch 20.428), train_loss = 0.97156814, grad/param norm = 1.6069e-01, time/batch = 18.5568s	
10644/26050 (epoch 20.430), train_loss = 1.15671552, grad/param norm = 1.7770e-01, time/batch = 18.0711s	
10645/26050 (epoch 20.432), train_loss = 1.01048285, grad/param norm = 1.7612e-01, time/batch = 16.6306s	
10646/26050 (epoch 20.434), train_loss = 1.02115389, grad/param norm = 1.9640e-01, time/batch = 16.5539s	
10647/26050 (epoch 20.436), train_loss = 1.16591282, grad/param norm = 1.9404e-01, time/batch = 17.8854s	
10648/26050 (epoch 20.438), train_loss = 1.08340475, grad/param norm = 1.9595e-01, time/batch = 18.7485s	
10649/26050 (epoch 20.440), train_loss = 1.06036738, grad/param norm = 1.8815e-01, time/batch = 17.5779s	
10650/26050 (epoch 20.441), train_loss = 1.02214336, grad/param norm = 1.7536e-01, time/batch = 18.6566s	
10651/26050 (epoch 20.443), train_loss = 0.89341582, grad/param norm = 1.4991e-01, time/batch = 17.6556s	
10652/26050 (epoch 20.445), train_loss = 0.96760115, grad/param norm = 1.7868e-01, time/batch = 16.7216s	
10653/26050 (epoch 20.447), train_loss = 1.18133361, grad/param norm = 1.9780e-01, time/batch = 17.6374s	
10654/26050 (epoch 20.449), train_loss = 0.95599305, grad/param norm = 1.6562e-01, time/batch = 17.9991s	
10655/26050 (epoch 20.451), train_loss = 1.20336903, grad/param norm = 1.9958e-01, time/batch = 18.0799s	
10656/26050 (epoch 20.453), train_loss = 0.96401419, grad/param norm = 1.5998e-01, time/batch = 16.7435s	
10657/26050 (epoch 20.455), train_loss = 1.07599320, grad/param norm = 1.7937e-01, time/batch = 18.0514s	
10658/26050 (epoch 20.457), train_loss = 1.03368585, grad/param norm = 1.7050e-01, time/batch = 15.5139s	
10659/26050 (epoch 20.459), train_loss = 1.14588284, grad/param norm = 1.8562e-01, time/batch = 15.8880s	
10660/26050 (epoch 20.461), train_loss = 1.14419752, grad/param norm = 2.0886e-01, time/batch = 18.0701s	
10661/26050 (epoch 20.463), train_loss = 1.01079338, grad/param norm = 1.7099e-01, time/batch = 18.3171s	
10662/26050 (epoch 20.464), train_loss = 1.08794960, grad/param norm = 1.8075e-01, time/batch = 17.7260s	
10663/26050 (epoch 20.466), train_loss = 1.11054248, grad/param norm = 1.9420e-01, time/batch = 16.0649s	
10664/26050 (epoch 20.468), train_loss = 1.13419919, grad/param norm = 1.6943e-01, time/batch = 17.7293s	
10665/26050 (epoch 20.470), train_loss = 1.19008617, grad/param norm = 1.9672e-01, time/batch = 18.6632s	
10666/26050 (epoch 20.472), train_loss = 1.18085087, grad/param norm = 2.0423e-01, time/batch = 17.2325s	
10667/26050 (epoch 20.474), train_loss = 1.19205657, grad/param norm = 1.7381e-01, time/batch = 18.6558s	
10668/26050 (epoch 20.476), train_loss = 1.17104078, grad/param norm = 1.8393e-01, time/batch = 17.8147s	
10669/26050 (epoch 20.478), train_loss = 1.03559517, grad/param norm = 1.8002e-01, time/batch = 17.2265s	
10670/26050 (epoch 20.480), train_loss = 1.05444684, grad/param norm = 1.7112e-01, time/batch = 18.2261s	
10671/26050 (epoch 20.482), train_loss = 0.99984898, grad/param norm = 1.7700e-01, time/batch = 18.2192s	
10672/26050 (epoch 20.484), train_loss = 0.99906425, grad/param norm = 1.8455e-01, time/batch = 17.9814s	
10673/26050 (epoch 20.486), train_loss = 1.18585946, grad/param norm = 1.8124e-01, time/batch = 14.7984s	
10674/26050 (epoch 20.488), train_loss = 1.28665319, grad/param norm = 1.9892e-01, time/batch = 17.9450s	
10675/26050 (epoch 20.489), train_loss = 1.22432025, grad/param norm = 2.1970e-01, time/batch = 17.7093s	
10676/26050 (epoch 20.491), train_loss = 0.97050389, grad/param norm = 1.7974e-01, time/batch = 15.7960s	
10677/26050 (epoch 20.493), train_loss = 1.06256450, grad/param norm = 1.9235e-01, time/batch = 17.7320s	
10678/26050 (epoch 20.495), train_loss = 1.04286793, grad/param norm = 1.6598e-01, time/batch = 17.8900s	
10679/26050 (epoch 20.497), train_loss = 0.97102820, grad/param norm = 1.7247e-01, time/batch = 18.3082s	
10680/26050 (epoch 20.499), train_loss = 1.01309247, grad/param norm = 1.7259e-01, time/batch = 18.0555s	
10681/26050 (epoch 20.501), train_loss = 1.12526185, grad/param norm = 1.9134e-01, time/batch = 18.6449s	
10682/26050 (epoch 20.503), train_loss = 1.00696718, grad/param norm = 1.7500e-01, time/batch = 18.1516s	
10683/26050 (epoch 20.505), train_loss = 1.18325508, grad/param norm = 1.7979e-01, time/batch = 17.8878s	
10684/26050 (epoch 20.507), train_loss = 1.12945915, grad/param norm = 1.9401e-01, time/batch = 17.8193s	
10685/26050 (epoch 20.509), train_loss = 1.23422344, grad/param norm = 1.8139e-01, time/batch = 17.1519s	
10686/26050 (epoch 20.511), train_loss = 0.98954406, grad/param norm = 1.6281e-01, time/batch = 17.4104s	
10687/26050 (epoch 20.512), train_loss = 0.97754873, grad/param norm = 1.8165e-01, time/batch = 18.8052s	
10688/26050 (epoch 20.514), train_loss = 1.13059133, grad/param norm = 1.9300e-01, time/batch = 18.4991s	
10689/26050 (epoch 20.516), train_loss = 1.17978215, grad/param norm = 1.7890e-01, time/batch = 17.9802s	
10690/26050 (epoch 20.518), train_loss = 1.05316030, grad/param norm = 1.8439e-01, time/batch = 18.3229s	
10691/26050 (epoch 20.520), train_loss = 1.03788113, grad/param norm = 1.7203e-01, time/batch = 18.5673s	
10692/26050 (epoch 20.522), train_loss = 0.82535443, grad/param norm = 1.5799e-01, time/batch = 18.7428s	
10693/26050 (epoch 20.524), train_loss = 1.14209493, grad/param norm = 2.2525e-01, time/batch = 16.3674s	
10694/26050 (epoch 20.526), train_loss = 1.17279441, grad/param norm = 2.2659e-01, time/batch = 18.8079s	
10695/26050 (epoch 20.528), train_loss = 1.10613619, grad/param norm = 1.9110e-01, time/batch = 17.6443s	
10696/26050 (epoch 20.530), train_loss = 1.02585340, grad/param norm = 1.8710e-01, time/batch = 15.8843s	
10697/26050 (epoch 20.532), train_loss = 1.06896805, grad/param norm = 1.8448e-01, time/batch = 18.4739s	
10698/26050 (epoch 20.534), train_loss = 1.12551756, grad/param norm = 2.0416e-01, time/batch = 14.3879s	
10699/26050 (epoch 20.536), train_loss = 1.05203563, grad/param norm = 1.7803e-01, time/batch = 17.9714s	
10700/26050 (epoch 20.537), train_loss = 1.14222184, grad/param norm = 1.9501e-01, time/batch = 17.9690s	
10701/26050 (epoch 20.539), train_loss = 1.04966364, grad/param norm = 1.8026e-01, time/batch = 14.8288s	
10702/26050 (epoch 20.541), train_loss = 1.27456003, grad/param norm = 2.1646e-01, time/batch = 17.6411s	
10703/26050 (epoch 20.543), train_loss = 0.89928914, grad/param norm = 1.6545e-01, time/batch = 20.7467s	
10704/26050 (epoch 20.545), train_loss = 1.11422050, grad/param norm = 1.8814e-01, time/batch = 32.3305s	
10705/26050 (epoch 20.547), train_loss = 1.05178614, grad/param norm = 1.7854e-01, time/batch = 20.6428s	
10706/26050 (epoch 20.549), train_loss = 0.88474839, grad/param norm = 1.7522e-01, time/batch = 18.5461s	
10707/26050 (epoch 20.551), train_loss = 1.10587274, grad/param norm = 1.7811e-01, time/batch = 18.3942s	
10708/26050 (epoch 20.553), train_loss = 0.98387892, grad/param norm = 1.7141e-01, time/batch = 18.1502s	
10709/26050 (epoch 20.555), train_loss = 0.99059081, grad/param norm = 1.7531e-01, time/batch = 17.7221s	
10710/26050 (epoch 20.557), train_loss = 1.10213597, grad/param norm = 1.6993e-01, time/batch = 14.8636s	
10711/26050 (epoch 20.559), train_loss = 1.03845186, grad/param norm = 1.7879e-01, time/batch = 18.1448s	
10712/26050 (epoch 20.560), train_loss = 1.02174502, grad/param norm = 1.8300e-01, time/batch = 18.4579s	
10713/26050 (epoch 20.562), train_loss = 1.01393630, grad/param norm = 1.7250e-01, time/batch = 18.1372s	
10714/26050 (epoch 20.564), train_loss = 1.21932093, grad/param norm = 1.7773e-01, time/batch = 18.6435s	
10715/26050 (epoch 20.566), train_loss = 0.95787052, grad/param norm = 1.7347e-01, time/batch = 17.4616s	
10716/26050 (epoch 20.568), train_loss = 1.09322311, grad/param norm = 1.8986e-01, time/batch = 16.5531s	
10717/26050 (epoch 20.570), train_loss = 1.12098995, grad/param norm = 1.8330e-01, time/batch = 18.0708s	
10718/26050 (epoch 20.572), train_loss = 1.01380090, grad/param norm = 1.8412e-01, time/batch = 17.9824s	
10719/26050 (epoch 20.574), train_loss = 1.11313961, grad/param norm = 2.0840e-01, time/batch = 17.2092s	
10720/26050 (epoch 20.576), train_loss = 1.07691570, grad/param norm = 1.8829e-01, time/batch = 17.7211s	
10721/26050 (epoch 20.578), train_loss = 1.02135571, grad/param norm = 1.8963e-01, time/batch = 18.5676s	
10722/26050 (epoch 20.580), train_loss = 0.97969455, grad/param norm = 1.8426e-01, time/batch = 17.7197s	
10723/26050 (epoch 20.582), train_loss = 1.08268069, grad/param norm = 1.8434e-01, time/batch = 17.2287s	
10724/26050 (epoch 20.583), train_loss = 1.15396892, grad/param norm = 1.7963e-01, time/batch = 17.8912s	
10725/26050 (epoch 20.585), train_loss = 0.92336379, grad/param norm = 1.8640e-01, time/batch = 18.2374s	
10726/26050 (epoch 20.587), train_loss = 1.10600639, grad/param norm = 2.0110e-01, time/batch = 18.3125s	
10727/26050 (epoch 20.589), train_loss = 1.20436601, grad/param norm = 2.0878e-01, time/batch = 18.0072s	
10728/26050 (epoch 20.591), train_loss = 1.02687524, grad/param norm = 1.8149e-01, time/batch = 14.9969s	
10729/26050 (epoch 20.593), train_loss = 0.92679118, grad/param norm = 1.7625e-01, time/batch = 16.7508s	
10730/26050 (epoch 20.595), train_loss = 1.12753206, grad/param norm = 2.2459e-01, time/batch = 17.9088s	
10731/26050 (epoch 20.597), train_loss = 1.09198165, grad/param norm = 1.8660e-01, time/batch = 17.1708s	
10732/26050 (epoch 20.599), train_loss = 1.06479156, grad/param norm = 1.9961e-01, time/batch = 17.4749s	
10733/26050 (epoch 20.601), train_loss = 1.23718243, grad/param norm = 1.7937e-01, time/batch = 16.1193s	
10734/26050 (epoch 20.603), train_loss = 1.08413310, grad/param norm = 1.8162e-01, time/batch = 16.7882s	
10735/26050 (epoch 20.605), train_loss = 1.00646579, grad/param norm = 1.8782e-01, time/batch = 17.4026s	
10736/26050 (epoch 20.607), train_loss = 1.15830446, grad/param norm = 1.9137e-01, time/batch = 17.5575s	
10737/26050 (epoch 20.608), train_loss = 0.91185080, grad/param norm = 1.5544e-01, time/batch = 17.7420s	
10738/26050 (epoch 20.610), train_loss = 1.03532585, grad/param norm = 1.8180e-01, time/batch = 18.1409s	
10739/26050 (epoch 20.612), train_loss = 1.04974395, grad/param norm = 1.8457e-01, time/batch = 17.1462s	
10740/26050 (epoch 20.614), train_loss = 1.08362318, grad/param norm = 1.8181e-01, time/batch = 17.3175s	
10741/26050 (epoch 20.616), train_loss = 1.21183195, grad/param norm = 2.1379e-01, time/batch = 18.4102s	
10742/26050 (epoch 20.618), train_loss = 1.00645102, grad/param norm = 1.9329e-01, time/batch = 15.3973s	
10743/26050 (epoch 20.620), train_loss = 1.10027416, grad/param norm = 1.9158e-01, time/batch = 17.3891s	
10744/26050 (epoch 20.622), train_loss = 0.93427515, grad/param norm = 1.5152e-01, time/batch = 17.8127s	
10745/26050 (epoch 20.624), train_loss = 0.92161803, grad/param norm = 1.6962e-01, time/batch = 18.2423s	
10746/26050 (epoch 20.626), train_loss = 1.11450260, grad/param norm = 1.8344e-01, time/batch = 16.2251s	
10747/26050 (epoch 20.628), train_loss = 0.97776892, grad/param norm = 1.9328e-01, time/batch = 18.4754s	
10748/26050 (epoch 20.630), train_loss = 1.17002985, grad/param norm = 1.8728e-01, time/batch = 15.5558s	
10749/26050 (epoch 20.631), train_loss = 1.21981989, grad/param norm = 1.9211e-01, time/batch = 16.3740s	
10750/26050 (epoch 20.633), train_loss = 0.95049365, grad/param norm = 1.6867e-01, time/batch = 17.4067s	
10751/26050 (epoch 20.635), train_loss = 0.97242378, grad/param norm = 1.5610e-01, time/batch = 18.0662s	
10752/26050 (epoch 20.637), train_loss = 0.95381604, grad/param norm = 1.8059e-01, time/batch = 18.0688s	
10753/26050 (epoch 20.639), train_loss = 1.15245789, grad/param norm = 1.7698e-01, time/batch = 17.7188s	
10754/26050 (epoch 20.641), train_loss = 1.02478064, grad/param norm = 1.6750e-01, time/batch = 17.9918s	
10755/26050 (epoch 20.643), train_loss = 0.94166868, grad/param norm = 1.5655e-01, time/batch = 17.3900s	
10756/26050 (epoch 20.645), train_loss = 1.04299001, grad/param norm = 1.8142e-01, time/batch = 17.7332s	
10757/26050 (epoch 20.647), train_loss = 0.99352677, grad/param norm = 1.7849e-01, time/batch = 16.5631s	
10758/26050 (epoch 20.649), train_loss = 1.06741201, grad/param norm = 1.9586e-01, time/batch = 15.5487s	
10759/26050 (epoch 20.651), train_loss = 0.98437888, grad/param norm = 1.8515e-01, time/batch = 18.3877s	
10760/26050 (epoch 20.653), train_loss = 1.05126750, grad/param norm = 1.8017e-01, time/batch = 18.1302s	
10761/26050 (epoch 20.655), train_loss = 0.97779275, grad/param norm = 1.7288e-01, time/batch = 17.7406s	
10762/26050 (epoch 20.656), train_loss = 0.89913312, grad/param norm = 1.6984e-01, time/batch = 16.2150s	
10763/26050 (epoch 20.658), train_loss = 1.23369976, grad/param norm = 1.8768e-01, time/batch = 17.4058s	
10764/26050 (epoch 20.660), train_loss = 0.92531495, grad/param norm = 1.7605e-01, time/batch = 17.8962s	
10765/26050 (epoch 20.662), train_loss = 0.98391393, grad/param norm = 1.7259e-01, time/batch = 14.9748s	
10766/26050 (epoch 20.664), train_loss = 1.02137732, grad/param norm = 1.8219e-01, time/batch = 17.9889s	
10767/26050 (epoch 20.666), train_loss = 1.02248342, grad/param norm = 2.0472e-01, time/batch = 16.5696s	
10768/26050 (epoch 20.668), train_loss = 0.87791597, grad/param norm = 2.2620e-01, time/batch = 15.9604s	
10769/26050 (epoch 20.670), train_loss = 1.18121991, grad/param norm = 2.1797e-01, time/batch = 18.2274s	
10770/26050 (epoch 20.672), train_loss = 1.02848029, grad/param norm = 1.8329e-01, time/batch = 17.3067s	
10771/26050 (epoch 20.674), train_loss = 0.95882361, grad/param norm = 1.8211e-01, time/batch = 18.3983s	
10772/26050 (epoch 20.676), train_loss = 1.09485795, grad/param norm = 1.9431e-01, time/batch = 17.2389s	
10773/26050 (epoch 20.678), train_loss = 1.17707201, grad/param norm = 1.9964e-01, time/batch = 18.5671s	
10774/26050 (epoch 20.679), train_loss = 1.23251424, grad/param norm = 2.1500e-01, time/batch = 16.9669s	
10775/26050 (epoch 20.681), train_loss = 1.06720712, grad/param norm = 1.9855e-01, time/batch = 18.5530s	
10776/26050 (epoch 20.683), train_loss = 0.95294870, grad/param norm = 2.2760e-01, time/batch = 17.5553s	
10777/26050 (epoch 20.685), train_loss = 1.00360880, grad/param norm = 1.7465e-01, time/batch = 16.8723s	
10778/26050 (epoch 20.687), train_loss = 0.89295380, grad/param norm = 1.6553e-01, time/batch = 16.1395s	
10779/26050 (epoch 20.689), train_loss = 1.01505666, grad/param norm = 1.9198e-01, time/batch = 17.4093s	
10780/26050 (epoch 20.691), train_loss = 0.83223434, grad/param norm = 1.7820e-01, time/batch = 18.8070s	
10781/26050 (epoch 20.693), train_loss = 0.96349522, grad/param norm = 1.8608e-01, time/batch = 18.0488s	
10782/26050 (epoch 20.695), train_loss = 1.04009708, grad/param norm = 1.7757e-01, time/batch = 17.5490s	
10783/26050 (epoch 20.697), train_loss = 0.94924861, grad/param norm = 1.7288e-01, time/batch = 14.8226s	
10784/26050 (epoch 20.699), train_loss = 1.08481944, grad/param norm = 1.8999e-01, time/batch = 17.6388s	
10785/26050 (epoch 20.701), train_loss = 0.94228303, grad/param norm = 1.6203e-01, time/batch = 17.8256s	
10786/26050 (epoch 20.702), train_loss = 1.16013594, grad/param norm = 1.8947e-01, time/batch = 18.3803s	
10787/26050 (epoch 20.704), train_loss = 1.12231421, grad/param norm = 1.6855e-01, time/batch = 18.2245s	
10788/26050 (epoch 20.706), train_loss = 1.02721935, grad/param norm = 1.9761e-01, time/batch = 18.4716s	
10789/26050 (epoch 20.708), train_loss = 1.11673504, grad/param norm = 1.9009e-01, time/batch = 15.7101s	
10790/26050 (epoch 20.710), train_loss = 1.10576056, grad/param norm = 1.9029e-01, time/batch = 17.2143s	
10791/26050 (epoch 20.712), train_loss = 1.12255229, grad/param norm = 2.0057e-01, time/batch = 16.7408s	
10792/26050 (epoch 20.714), train_loss = 0.89577780, grad/param norm = 1.6873e-01, time/batch = 17.5698s	
10793/26050 (epoch 20.716), train_loss = 1.28456690, grad/param norm = 2.0022e-01, time/batch = 18.7277s	
10794/26050 (epoch 20.718), train_loss = 1.13626666, grad/param norm = 1.8334e-01, time/batch = 18.1601s	
10795/26050 (epoch 20.720), train_loss = 1.01584128, grad/param norm = 1.9197e-01, time/batch = 18.4107s	
10796/26050 (epoch 20.722), train_loss = 0.90360860, grad/param norm = 1.7059e-01, time/batch = 17.5791s	
10797/26050 (epoch 20.724), train_loss = 0.96122671, grad/param norm = 1.8818e-01, time/batch = 18.4854s	
10798/26050 (epoch 20.726), train_loss = 1.12143641, grad/param norm = 2.0265e-01, time/batch = 17.8946s	
10799/26050 (epoch 20.727), train_loss = 1.11601331, grad/param norm = 1.9741e-01, time/batch = 18.3963s	
10800/26050 (epoch 20.729), train_loss = 1.09125752, grad/param norm = 1.8150e-01, time/batch = 18.3837s	
10801/26050 (epoch 20.731), train_loss = 1.07464040, grad/param norm = 1.8215e-01, time/batch = 17.9664s	
10802/26050 (epoch 20.733), train_loss = 1.00951560, grad/param norm = 2.1850e-01, time/batch = 18.4900s	
10803/26050 (epoch 20.735), train_loss = 1.25615164, grad/param norm = 2.0824e-01, time/batch = 16.6630s	
10804/26050 (epoch 20.737), train_loss = 0.99129041, grad/param norm = 1.7978e-01, time/batch = 14.3019s	
10805/26050 (epoch 20.739), train_loss = 1.06947014, grad/param norm = 1.7997e-01, time/batch = 18.3171s	
10806/26050 (epoch 20.741), train_loss = 0.96480960, grad/param norm = 1.9038e-01, time/batch = 17.3048s	
10807/26050 (epoch 20.743), train_loss = 1.08317314, grad/param norm = 1.9745e-01, time/batch = 14.8823s	
10808/26050 (epoch 20.745), train_loss = 0.92135534, grad/param norm = 1.7019e-01, time/batch = 17.5653s	
10809/26050 (epoch 20.747), train_loss = 0.95033242, grad/param norm = 1.7382e-01, time/batch = 18.7372s	
10810/26050 (epoch 20.749), train_loss = 1.16221841, grad/param norm = 1.9907e-01, time/batch = 16.0571s	
10811/26050 (epoch 20.750), train_loss = 1.03734593, grad/param norm = 1.7541e-01, time/batch = 17.0722s	
10812/26050 (epoch 20.752), train_loss = 1.00575726, grad/param norm = 1.9338e-01, time/batch = 18.6518s	
10813/26050 (epoch 20.754), train_loss = 1.05610551, grad/param norm = 1.8172e-01, time/batch = 17.4122s	
10814/26050 (epoch 20.756), train_loss = 1.04347131, grad/param norm = 1.9590e-01, time/batch = 16.2282s	
10815/26050 (epoch 20.758), train_loss = 1.03677877, grad/param norm = 2.0434e-01, time/batch = 17.4697s	
10816/26050 (epoch 20.760), train_loss = 1.22260693, grad/param norm = 1.9522e-01, time/batch = 18.2338s	
10817/26050 (epoch 20.762), train_loss = 0.98617619, grad/param norm = 1.8030e-01, time/batch = 18.1518s	
10818/26050 (epoch 20.764), train_loss = 1.05894342, grad/param norm = 1.9215e-01, time/batch = 17.3961s	
10819/26050 (epoch 20.766), train_loss = 1.10590607, grad/param norm = 2.0342e-01, time/batch = 18.5406s	
10820/26050 (epoch 20.768), train_loss = 0.94566741, grad/param norm = 1.7558e-01, time/batch = 17.6494s	
10821/26050 (epoch 20.770), train_loss = 1.02583561, grad/param norm = 1.9352e-01, time/batch = 17.8165s	
10822/26050 (epoch 20.772), train_loss = 1.02704790, grad/param norm = 1.6851e-01, time/batch = 15.0523s	
10823/26050 (epoch 20.774), train_loss = 0.91125127, grad/param norm = 1.8296e-01, time/batch = 17.9017s	
10824/26050 (epoch 20.775), train_loss = 0.74844408, grad/param norm = 1.5614e-01, time/batch = 18.0742s	
10825/26050 (epoch 20.777), train_loss = 0.97594162, grad/param norm = 1.7526e-01, time/batch = 17.0636s	
10826/26050 (epoch 20.779), train_loss = 1.01157879, grad/param norm = 1.8553e-01, time/batch = 17.3250s	
10827/26050 (epoch 20.781), train_loss = 0.93991033, grad/param norm = 1.8155e-01, time/batch = 18.8969s	
10828/26050 (epoch 20.783), train_loss = 0.92001746, grad/param norm = 1.6359e-01, time/batch = 17.8276s	
10829/26050 (epoch 20.785), train_loss = 1.02226484, grad/param norm = 1.7618e-01, time/batch = 18.1505s	
10830/26050 (epoch 20.787), train_loss = 0.95384323, grad/param norm = 1.7873e-01, time/batch = 17.3303s	
10831/26050 (epoch 20.789), train_loss = 0.97636232, grad/param norm = 2.0160e-01, time/batch = 14.3016s	
10832/26050 (epoch 20.791), train_loss = 0.98543588, grad/param norm = 1.7819e-01, time/batch = 16.3076s	
10833/26050 (epoch 20.793), train_loss = 1.02639204, grad/param norm = 1.9887e-01, time/batch = 17.9798s	
10834/26050 (epoch 20.795), train_loss = 0.84401490, grad/param norm = 1.4847e-01, time/batch = 16.7107s	
10835/26050 (epoch 20.797), train_loss = 0.94786018, grad/param norm = 1.5879e-01, time/batch = 17.3336s	
10836/26050 (epoch 20.798), train_loss = 0.87936904, grad/param norm = 1.6935e-01, time/batch = 17.8268s	
10837/26050 (epoch 20.800), train_loss = 0.90711877, grad/param norm = 1.6524e-01, time/batch = 15.8130s	
10838/26050 (epoch 20.802), train_loss = 0.98674149, grad/param norm = 1.7598e-01, time/batch = 17.8874s	
10839/26050 (epoch 20.804), train_loss = 1.02321226, grad/param norm = 1.8360e-01, time/batch = 16.6312s	
10840/26050 (epoch 20.806), train_loss = 1.13031201, grad/param norm = 1.9329e-01, time/batch = 15.9788s	
10841/26050 (epoch 20.808), train_loss = 1.02102092, grad/param norm = 1.7824e-01, time/batch = 15.1548s	
10842/26050 (epoch 20.810), train_loss = 0.98227061, grad/param norm = 1.9039e-01, time/batch = 17.6456s	
10843/26050 (epoch 20.812), train_loss = 0.92943118, grad/param norm = 1.8965e-01, time/batch = 18.1485s	
10844/26050 (epoch 20.814), train_loss = 0.92116806, grad/param norm = 1.9196e-01, time/batch = 18.5551s	
10845/26050 (epoch 20.816), train_loss = 1.13133407, grad/param norm = 2.0258e-01, time/batch = 18.6471s	
10846/26050 (epoch 20.818), train_loss = 1.14226638, grad/param norm = 2.2164e-01, time/batch = 17.8152s	
10847/26050 (epoch 20.820), train_loss = 1.03434075, grad/param norm = 1.7362e-01, time/batch = 15.5618s	
10848/26050 (epoch 20.821), train_loss = 1.16365964, grad/param norm = 1.9496e-01, time/batch = 18.1526s	
10849/26050 (epoch 20.823), train_loss = 1.16998964, grad/param norm = 1.9981e-01, time/batch = 17.7145s	
10850/26050 (epoch 20.825), train_loss = 1.01775816, grad/param norm = 1.8403e-01, time/batch = 16.2186s	
10851/26050 (epoch 20.827), train_loss = 1.05939668, grad/param norm = 2.0357e-01, time/batch = 18.3924s	
10852/26050 (epoch 20.829), train_loss = 1.12748186, grad/param norm = 2.0323e-01, time/batch = 18.6446s	
10853/26050 (epoch 20.831), train_loss = 1.15843179, grad/param norm = 1.8120e-01, time/batch = 18.6416s	
10854/26050 (epoch 20.833), train_loss = 1.23351211, grad/param norm = 1.9773e-01, time/batch = 18.2340s	
10855/26050 (epoch 20.835), train_loss = 1.23132830, grad/param norm = 2.2446e-01, time/batch = 16.0469s	
10856/26050 (epoch 20.837), train_loss = 1.03618342, grad/param norm = 1.8137e-01, time/batch = 14.3673s	
10857/26050 (epoch 20.839), train_loss = 1.06790221, grad/param norm = 2.3349e-01, time/batch = 17.9612s	
10858/26050 (epoch 20.841), train_loss = 1.18115394, grad/param norm = 1.9720e-01, time/batch = 18.4906s	
10859/26050 (epoch 20.843), train_loss = 1.03196354, grad/param norm = 1.7207e-01, time/batch = 18.1443s	
10860/26050 (epoch 20.845), train_loss = 0.98731375, grad/param norm = 1.7073e-01, time/batch = 14.7930s	
10861/26050 (epoch 20.846), train_loss = 1.11865481, grad/param norm = 1.7267e-01, time/batch = 18.8098s	
10862/26050 (epoch 20.848), train_loss = 1.02722853, grad/param norm = 1.7942e-01, time/batch = 18.2323s	
10863/26050 (epoch 20.850), train_loss = 0.94061689, grad/param norm = 1.6258e-01, time/batch = 17.6387s	
10864/26050 (epoch 20.852), train_loss = 1.04164975, grad/param norm = 1.7750e-01, time/batch = 17.8239s	
10865/26050 (epoch 20.854), train_loss = 1.02572216, grad/param norm = 1.8656e-01, time/batch = 18.1505s	
10866/26050 (epoch 20.856), train_loss = 1.00377484, grad/param norm = 1.9041e-01, time/batch = 17.8170s	
10867/26050 (epoch 20.858), train_loss = 0.94316626, grad/param norm = 1.7446e-01, time/batch = 18.2327s	
10868/26050 (epoch 20.860), train_loss = 1.06908461, grad/param norm = 1.8816e-01, time/batch = 17.9047s	
10869/26050 (epoch 20.862), train_loss = 1.10312477, grad/param norm = 1.8548e-01, time/batch = 14.3035s	
10870/26050 (epoch 20.864), train_loss = 1.07488866, grad/param norm = 2.1236e-01, time/batch = 16.4747s	
10871/26050 (epoch 20.866), train_loss = 0.98877889, grad/param norm = 1.7665e-01, time/batch = 17.7201s	
10872/26050 (epoch 20.868), train_loss = 1.08359049, grad/param norm = 1.8250e-01, time/batch = 17.7351s	
10873/26050 (epoch 20.869), train_loss = 0.93470831, grad/param norm = 1.7118e-01, time/batch = 17.1545s	
10874/26050 (epoch 20.871), train_loss = 0.87353079, grad/param norm = 1.7079e-01, time/batch = 17.9129s	
10875/26050 (epoch 20.873), train_loss = 1.08899263, grad/param norm = 2.0429e-01, time/batch = 16.1424s	
10876/26050 (epoch 20.875), train_loss = 1.03262391, grad/param norm = 1.9565e-01, time/batch = 17.8033s	
10877/26050 (epoch 20.877), train_loss = 0.92324714, grad/param norm = 1.6599e-01, time/batch = 17.3141s	
10878/26050 (epoch 20.879), train_loss = 1.05211896, grad/param norm = 1.6520e-01, time/batch = 18.6335s	
10879/26050 (epoch 20.881), train_loss = 1.15868193, grad/param norm = 2.0617e-01, time/batch = 16.6176s	
10880/26050 (epoch 20.883), train_loss = 1.09155501, grad/param norm = 1.8359e-01, time/batch = 17.7279s	
10881/26050 (epoch 20.885), train_loss = 0.78054582, grad/param norm = 1.5943e-01, time/batch = 18.2293s	
10882/26050 (epoch 20.887), train_loss = 1.07517948, grad/param norm = 1.8317e-01, time/batch = 18.1697s	
10883/26050 (epoch 20.889), train_loss = 0.99549494, grad/param norm = 1.7568e-01, time/batch = 17.1630s	
10884/26050 (epoch 20.891), train_loss = 0.84996508, grad/param norm = 1.6194e-01, time/batch = 18.0705s	
10885/26050 (epoch 20.893), train_loss = 0.90475926, grad/param norm = 1.7589e-01, time/batch = 18.4000s	
10886/26050 (epoch 20.894), train_loss = 0.98450989, grad/param norm = 1.6757e-01, time/batch = 18.8978s	
10887/26050 (epoch 20.896), train_loss = 1.12318404, grad/param norm = 1.8538e-01, time/batch = 18.0514s	
10888/26050 (epoch 20.898), train_loss = 0.96442635, grad/param norm = 1.8307e-01, time/batch = 18.5614s	
10889/26050 (epoch 20.900), train_loss = 1.06379145, grad/param norm = 1.8793e-01, time/batch = 17.8060s	
10890/26050 (epoch 20.902), train_loss = 1.01316262, grad/param norm = 1.7608e-01, time/batch = 16.3899s	
10891/26050 (epoch 20.904), train_loss = 1.01417043, grad/param norm = 1.7333e-01, time/batch = 18.0565s	
10892/26050 (epoch 20.906), train_loss = 1.01076179, grad/param norm = 1.9153e-01, time/batch = 17.9939s	
10893/26050 (epoch 20.908), train_loss = 1.03171990, grad/param norm = 1.8057e-01, time/batch = 17.9164s	
10894/26050 (epoch 20.910), train_loss = 0.98073386, grad/param norm = 1.6592e-01, time/batch = 14.7298s	
10895/26050 (epoch 20.912), train_loss = 1.22849284, grad/param norm = 2.0440e-01, time/batch = 16.9717s	
10896/26050 (epoch 20.914), train_loss = 1.39122427, grad/param norm = 2.3009e-01, time/batch = 18.2327s	
10897/26050 (epoch 20.916), train_loss = 1.14143625, grad/param norm = 2.0160e-01, time/batch = 17.5793s	
10898/26050 (epoch 20.917), train_loss = 1.04843777, grad/param norm = 2.1018e-01, time/batch = 18.3159s	
10899/26050 (epoch 20.919), train_loss = 1.12353007, grad/param norm = 2.0913e-01, time/batch = 17.5541s	
10900/26050 (epoch 20.921), train_loss = 0.98593056, grad/param norm = 1.8035e-01, time/batch = 17.8175s	
10901/26050 (epoch 20.923), train_loss = 1.04967060, grad/param norm = 1.8925e-01, time/batch = 17.8318s	
10902/26050 (epoch 20.925), train_loss = 1.02581576, grad/param norm = 1.7503e-01, time/batch = 18.2443s	
10903/26050 (epoch 20.927), train_loss = 0.90870521, grad/param norm = 1.4849e-01, time/batch = 16.2404s	
10904/26050 (epoch 20.929), train_loss = 0.89611816, grad/param norm = 1.7342e-01, time/batch = 18.1341s	
10905/26050 (epoch 20.931), train_loss = 1.21019029, grad/param norm = 2.1487e-01, time/batch = 18.0735s	
10906/26050 (epoch 20.933), train_loss = 0.97973822, grad/param norm = 1.7170e-01, time/batch = 17.3130s	
10907/26050 (epoch 20.935), train_loss = 1.01871338, grad/param norm = 1.7593e-01, time/batch = 22.5713s	
10908/26050 (epoch 20.937), train_loss = 1.11712186, grad/param norm = 1.8107e-01, time/batch = 28.6680s	
10909/26050 (epoch 20.939), train_loss = 0.95479559, grad/param norm = 1.6128e-01, time/batch = 18.7704s	
10910/26050 (epoch 20.940), train_loss = 0.99982384, grad/param norm = 1.6400e-01, time/batch = 18.5562s	
10911/26050 (epoch 20.942), train_loss = 1.02316694, grad/param norm = 1.7732e-01, time/batch = 17.3252s	
10912/26050 (epoch 20.944), train_loss = 0.97909711, grad/param norm = 1.7701e-01, time/batch = 18.4859s	
10913/26050 (epoch 20.946), train_loss = 1.17061290, grad/param norm = 1.9463e-01, time/batch = 17.4815s	
10914/26050 (epoch 20.948), train_loss = 0.92569192, grad/param norm = 1.8750e-01, time/batch = 18.6713s	
10915/26050 (epoch 20.950), train_loss = 1.00517889, grad/param norm = 1.8533e-01, time/batch = 18.0753s	
10916/26050 (epoch 20.952), train_loss = 1.13978260, grad/param norm = 1.9469e-01, time/batch = 14.9823s	
10917/26050 (epoch 20.954), train_loss = 1.13769989, grad/param norm = 1.9634e-01, time/batch = 18.0658s	
10918/26050 (epoch 20.956), train_loss = 1.02794921, grad/param norm = 1.9748e-01, time/batch = 18.1438s	
10919/26050 (epoch 20.958), train_loss = 0.98383962, grad/param norm = 1.8641e-01, time/batch = 17.9784s	
10920/26050 (epoch 20.960), train_loss = 1.05556355, grad/param norm = 1.9039e-01, time/batch = 17.8860s	
10921/26050 (epoch 20.962), train_loss = 0.96974078, grad/param norm = 1.5372e-01, time/batch = 18.7492s	
10922/26050 (epoch 20.964), train_loss = 1.03113271, grad/param norm = 1.9070e-01, time/batch = 17.6539s	
10923/26050 (epoch 20.965), train_loss = 0.96131028, grad/param norm = 1.7654e-01, time/batch = 17.3934s	
10924/26050 (epoch 20.967), train_loss = 1.35686560, grad/param norm = 1.9759e-01, time/batch = 16.5618s	
10925/26050 (epoch 20.969), train_loss = 1.03169690, grad/param norm = 1.8195e-01, time/batch = 17.0793s	
10926/26050 (epoch 20.971), train_loss = 0.97857036, grad/param norm = 1.5943e-01, time/batch = 18.0630s	
10927/26050 (epoch 20.973), train_loss = 1.03734255, grad/param norm = 2.0961e-01, time/batch = 17.3247s	
10928/26050 (epoch 20.975), train_loss = 1.06331301, grad/param norm = 1.6900e-01, time/batch = 15.2378s	
10929/26050 (epoch 20.977), train_loss = 1.06837172, grad/param norm = 1.6286e-01, time/batch = 18.1401s	
10930/26050 (epoch 20.979), train_loss = 0.87885813, grad/param norm = 1.7400e-01, time/batch = 14.8125s	
10931/26050 (epoch 20.981), train_loss = 1.16071583, grad/param norm = 1.7663e-01, time/batch = 18.0625s	
10932/26050 (epoch 20.983), train_loss = 1.12147583, grad/param norm = 2.0537e-01, time/batch = 18.0709s	
10933/26050 (epoch 20.985), train_loss = 1.08611495, grad/param norm = 1.7489e-01, time/batch = 18.2407s	
10934/26050 (epoch 20.987), train_loss = 1.15217486, grad/param norm = 1.7803e-01, time/batch = 17.9912s	
10935/26050 (epoch 20.988), train_loss = 1.12005996, grad/param norm = 1.8318e-01, time/batch = 17.7199s	
10936/26050 (epoch 20.990), train_loss = 0.92197718, grad/param norm = 1.5675e-01, time/batch = 16.2266s	
10937/26050 (epoch 20.992), train_loss = 1.19003911, grad/param norm = 1.8966e-01, time/batch = 16.8856s	
10938/26050 (epoch 20.994), train_loss = 0.99775384, grad/param norm = 1.8279e-01, time/batch = 18.3353s	
10939/26050 (epoch 20.996), train_loss = 0.98326630, grad/param norm = 1.8532e-01, time/batch = 17.5568s	
10940/26050 (epoch 20.998), train_loss = 1.03990260, grad/param norm = 1.7449e-01, time/batch = 17.6425s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
10941/26050 (epoch 21.000), train_loss = 0.99137793, grad/param norm = 1.9293e-01, time/batch = 16.5542s	
10942/26050 (epoch 21.002), train_loss = 1.10815182, grad/param norm = 2.0565e-01, time/batch = 18.2359s	
10943/26050 (epoch 21.004), train_loss = 0.94761817, grad/param norm = 1.7521e-01, time/batch = 17.7375s	
10944/26050 (epoch 21.006), train_loss = 0.97714366, grad/param norm = 1.8499e-01, time/batch = 18.2570s	
10945/26050 (epoch 21.008), train_loss = 0.96195017, grad/param norm = 1.9299e-01, time/batch = 18.7294s	
10946/26050 (epoch 21.010), train_loss = 0.95749963, grad/param norm = 1.7369e-01, time/batch = 17.7433s	
10947/26050 (epoch 21.012), train_loss = 1.05355385, grad/param norm = 1.8679e-01, time/batch = 18.3149s	
10948/26050 (epoch 21.013), train_loss = 1.33751765, grad/param norm = 2.4062e-01, time/batch = 17.9806s	
10949/26050 (epoch 21.015), train_loss = 0.99580394, grad/param norm = 1.6337e-01, time/batch = 18.3210s	
10950/26050 (epoch 21.017), train_loss = 1.04129136, grad/param norm = 1.7745e-01, time/batch = 17.1203s	
10951/26050 (epoch 21.019), train_loss = 0.89769033, grad/param norm = 1.6598e-01, time/batch = 18.6471s	
10952/26050 (epoch 21.021), train_loss = 1.09229102, grad/param norm = 1.7850e-01, time/batch = 16.4791s	
10953/26050 (epoch 21.023), train_loss = 0.87595539, grad/param norm = 1.8475e-01, time/batch = 17.2925s	
10954/26050 (epoch 21.025), train_loss = 1.04368767, grad/param norm = 1.8484e-01, time/batch = 15.0597s	
10955/26050 (epoch 21.027), train_loss = 0.83976521, grad/param norm = 1.8109e-01, time/batch = 17.3913s	
10956/26050 (epoch 21.029), train_loss = 1.05336914, grad/param norm = 1.6852e-01, time/batch = 16.5653s	
10957/26050 (epoch 21.031), train_loss = 1.17168726, grad/param norm = 2.0818e-01, time/batch = 17.8936s	
10958/26050 (epoch 21.033), train_loss = 1.06333341, grad/param norm = 1.8016e-01, time/batch = 18.3862s	
10959/26050 (epoch 21.035), train_loss = 1.07293989, grad/param norm = 1.8043e-01, time/batch = 16.0657s	
10960/26050 (epoch 21.036), train_loss = 0.93010230, grad/param norm = 1.7975e-01, time/batch = 17.9687s	
10961/26050 (epoch 21.038), train_loss = 0.85694055, grad/param norm = 1.6190e-01, time/batch = 18.2325s	
10962/26050 (epoch 21.040), train_loss = 1.02398241, grad/param norm = 1.9407e-01, time/batch = 18.4068s	
10963/26050 (epoch 21.042), train_loss = 0.88909151, grad/param norm = 1.7346e-01, time/batch = 18.3155s	
10964/26050 (epoch 21.044), train_loss = 1.11154891, grad/param norm = 1.7074e-01, time/batch = 15.6415s	
10965/26050 (epoch 21.046), train_loss = 0.83592875, grad/param norm = 1.4833e-01, time/batch = 17.7892s	
10966/26050 (epoch 21.048), train_loss = 1.03695789, grad/param norm = 1.7982e-01, time/batch = 17.8980s	
10967/26050 (epoch 21.050), train_loss = 0.95870197, grad/param norm = 1.7327e-01, time/batch = 16.8230s	
10968/26050 (epoch 21.052), train_loss = 0.97452729, grad/param norm = 1.8583e-01, time/batch = 18.5580s	
10969/26050 (epoch 21.054), train_loss = 0.86770285, grad/param norm = 1.6368e-01, time/batch = 18.0616s	
10970/26050 (epoch 21.056), train_loss = 0.83142285, grad/param norm = 1.5236e-01, time/batch = 16.8040s	
10971/26050 (epoch 21.058), train_loss = 0.97768520, grad/param norm = 1.6842e-01, time/batch = 18.3856s	
10972/26050 (epoch 21.060), train_loss = 1.08798517, grad/param norm = 1.8191e-01, time/batch = 19.0536s	
10973/26050 (epoch 21.061), train_loss = 0.93411469, grad/param norm = 1.7067e-01, time/batch = 17.8148s	
10974/26050 (epoch 21.063), train_loss = 1.06581214, grad/param norm = 1.7743e-01, time/batch = 16.8217s	
10975/26050 (epoch 21.065), train_loss = 0.83209824, grad/param norm = 1.5386e-01, time/batch = 16.7378s	
10976/26050 (epoch 21.067), train_loss = 1.02623773, grad/param norm = 1.8048e-01, time/batch = 14.7106s	
10977/26050 (epoch 21.069), train_loss = 1.07846318, grad/param norm = 2.0811e-01, time/batch = 17.2010s	
10978/26050 (epoch 21.071), train_loss = 1.09552282, grad/param norm = 1.8559e-01, time/batch = 17.0531s	
10979/26050 (epoch 21.073), train_loss = 1.21839952, grad/param norm = 2.0896e-01, time/batch = 18.8201s	
10980/26050 (epoch 21.075), train_loss = 0.94517612, grad/param norm = 1.6778e-01, time/batch = 18.3254s	
10981/26050 (epoch 21.077), train_loss = 0.95853205, grad/param norm = 1.8271e-01, time/batch = 16.9061s	
10982/26050 (epoch 21.079), train_loss = 1.04539950, grad/param norm = 1.8241e-01, time/batch = 18.4049s	
10983/26050 (epoch 21.081), train_loss = 0.98865835, grad/param norm = 1.7025e-01, time/batch = 18.3125s	
10984/26050 (epoch 21.083), train_loss = 1.12336152, grad/param norm = 1.8329e-01, time/batch = 15.3922s	
10985/26050 (epoch 21.084), train_loss = 1.04431772, grad/param norm = 2.0959e-01, time/batch = 18.3279s	
10986/26050 (epoch 21.086), train_loss = 1.19420071, grad/param norm = 2.0054e-01, time/batch = 17.7430s	
10987/26050 (epoch 21.088), train_loss = 0.95055574, grad/param norm = 1.7518e-01, time/batch = 18.4096s	
10988/26050 (epoch 21.090), train_loss = 1.04396339, grad/param norm = 1.9143e-01, time/batch = 18.4892s	
10989/26050 (epoch 21.092), train_loss = 1.07983175, grad/param norm = 1.8001e-01, time/batch = 18.0614s	
10990/26050 (epoch 21.094), train_loss = 0.95676325, grad/param norm = 1.7804e-01, time/batch = 17.4028s	
10991/26050 (epoch 21.096), train_loss = 1.01657905, grad/param norm = 1.7197e-01, time/batch = 17.8224s	
10992/26050 (epoch 21.098), train_loss = 0.96684482, grad/param norm = 1.7568e-01, time/batch = 18.1341s	
10993/26050 (epoch 21.100), train_loss = 0.92675146, grad/param norm = 1.8228e-01, time/batch = 16.7324s	
10994/26050 (epoch 21.102), train_loss = 1.05846790, grad/param norm = 1.9369e-01, time/batch = 17.5316s	
10995/26050 (epoch 21.104), train_loss = 1.00817881, grad/param norm = 1.9072e-01, time/batch = 18.2154s	
10996/26050 (epoch 21.106), train_loss = 1.02490805, grad/param norm = 1.9450e-01, time/batch = 18.8241s	
10997/26050 (epoch 21.107), train_loss = 0.82527389, grad/param norm = 1.7448e-01, time/batch = 14.9695s	
10998/26050 (epoch 21.109), train_loss = 0.93715338, grad/param norm = 1.8330e-01, time/batch = 16.2145s	
10999/26050 (epoch 21.111), train_loss = 1.18556488, grad/param norm = 1.9910e-01, time/batch = 18.8861s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch21.11_1.6813.t7	
11000/26050 (epoch 21.113), train_loss = 0.96332794, grad/param norm = 1.7974e-01, time/batch = 15.8828s	
11001/26050 (epoch 21.115), train_loss = 1.51738745, grad/param norm = 2.1567e-01, time/batch = 18.0515s	
11002/26050 (epoch 21.117), train_loss = 1.04834925, grad/param norm = 1.8086e-01, time/batch = 16.5680s	
11003/26050 (epoch 21.119), train_loss = 0.85352291, grad/param norm = 1.5687e-01, time/batch = 18.4956s	
11004/26050 (epoch 21.121), train_loss = 1.04298911, grad/param norm = 1.6939e-01, time/batch = 18.6408s	
11005/26050 (epoch 21.123), train_loss = 0.92362259, grad/param norm = 1.6552e-01, time/batch = 17.8021s	
11006/26050 (epoch 21.125), train_loss = 0.88578420, grad/param norm = 1.6579e-01, time/batch = 18.4728s	
11007/26050 (epoch 21.127), train_loss = 0.81810809, grad/param norm = 1.6578e-01, time/batch = 18.8985s	
11008/26050 (epoch 21.129), train_loss = 0.86965697, grad/param norm = 1.7079e-01, time/batch = 17.0467s	
11009/26050 (epoch 21.131), train_loss = 0.99150696, grad/param norm = 1.7482e-01, time/batch = 18.6499s	
11010/26050 (epoch 21.132), train_loss = 0.98653653, grad/param norm = 1.6620e-01, time/batch = 18.7295s	
11011/26050 (epoch 21.134), train_loss = 1.03546405, grad/param norm = 2.0179e-01, time/batch = 18.2310s	
11012/26050 (epoch 21.136), train_loss = 1.02120145, grad/param norm = 1.8281e-01, time/batch = 17.6352s	
11013/26050 (epoch 21.138), train_loss = 0.77402406, grad/param norm = 1.6751e-01, time/batch = 18.4761s	
11014/26050 (epoch 21.140), train_loss = 0.85003388, grad/param norm = 1.7790e-01, time/batch = 17.7324s	
11015/26050 (epoch 21.142), train_loss = 0.88238014, grad/param norm = 1.7084e-01, time/batch = 15.2232s	
11016/26050 (epoch 21.144), train_loss = 0.81315610, grad/param norm = 1.6234e-01, time/batch = 18.4064s	
11017/26050 (epoch 21.146), train_loss = 0.76148600, grad/param norm = 1.6340e-01, time/batch = 18.5626s	
11018/26050 (epoch 21.148), train_loss = 0.80028573, grad/param norm = 1.4914e-01, time/batch = 18.2957s	
11019/26050 (epoch 21.150), train_loss = 0.98107572, grad/param norm = 1.8670e-01, time/batch = 15.1299s	
11020/26050 (epoch 21.152), train_loss = 1.20322342, grad/param norm = 2.4080e-01, time/batch = 17.9821s	
11021/26050 (epoch 21.154), train_loss = 0.80234955, grad/param norm = 1.8543e-01, time/batch = 18.2271s	
11022/26050 (epoch 21.155), train_loss = 0.84585657, grad/param norm = 1.6866e-01, time/batch = 17.3101s	
11023/26050 (epoch 21.157), train_loss = 0.95238965, grad/param norm = 1.9417e-01, time/batch = 15.3849s	
11024/26050 (epoch 21.159), train_loss = 1.01396157, grad/param norm = 2.0773e-01, time/batch = 18.1473s	
11025/26050 (epoch 21.161), train_loss = 1.05361910, grad/param norm = 2.0224e-01, time/batch = 16.1953s	
11026/26050 (epoch 21.163), train_loss = 0.84869420, grad/param norm = 1.8790e-01, time/batch = 18.1531s	
11027/26050 (epoch 21.165), train_loss = 0.78053637, grad/param norm = 1.6097e-01, time/batch = 17.6440s	
11028/26050 (epoch 21.167), train_loss = 1.10831559, grad/param norm = 1.8708e-01, time/batch = 18.3164s	
11029/26050 (epoch 21.169), train_loss = 1.02850190, grad/param norm = 1.8419e-01, time/batch = 16.1381s	
11030/26050 (epoch 21.171), train_loss = 0.83686583, grad/param norm = 1.5649e-01, time/batch = 18.1428s	
11031/26050 (epoch 21.173), train_loss = 0.93975153, grad/param norm = 1.9387e-01, time/batch = 18.1639s	
11032/26050 (epoch 21.175), train_loss = 0.96792447, grad/param norm = 1.6371e-01, time/batch = 17.8993s	
11033/26050 (epoch 21.177), train_loss = 1.09551537, grad/param norm = 1.7483e-01, time/batch = 15.3174s	
11034/26050 (epoch 21.179), train_loss = 0.76334771, grad/param norm = 1.6391e-01, time/batch = 18.4720s	
11035/26050 (epoch 21.180), train_loss = 1.20011901, grad/param norm = 1.8830e-01, time/batch = 18.1463s	
11036/26050 (epoch 21.182), train_loss = 1.22561090, grad/param norm = 1.9737e-01, time/batch = 17.3869s	
11037/26050 (epoch 21.184), train_loss = 1.03705044, grad/param norm = 1.7758e-01, time/batch = 18.2234s	
11038/26050 (epoch 21.186), train_loss = 0.83765626, grad/param norm = 1.5569e-01, time/batch = 18.0582s	
11039/26050 (epoch 21.188), train_loss = 0.99796547, grad/param norm = 1.7801e-01, time/batch = 17.4964s	
11040/26050 (epoch 21.190), train_loss = 1.04968516, grad/param norm = 1.7743e-01, time/batch = 18.0068s	
11041/26050 (epoch 21.192), train_loss = 1.06616978, grad/param norm = 1.7731e-01, time/batch = 14.8666s	
11042/26050 (epoch 21.194), train_loss = 1.05961578, grad/param norm = 1.9376e-01, time/batch = 18.0631s	
11043/26050 (epoch 21.196), train_loss = 1.10566341, grad/param norm = 1.9733e-01, time/batch = 18.0536s	
11044/26050 (epoch 21.198), train_loss = 0.91883331, grad/param norm = 1.6594e-01, time/batch = 18.3099s	
11045/26050 (epoch 21.200), train_loss = 0.92482770, grad/param norm = 1.7863e-01, time/batch = 18.6358s	
11046/26050 (epoch 21.202), train_loss = 1.01665021, grad/param norm = 1.8176e-01, time/batch = 17.7342s	
11047/26050 (epoch 21.203), train_loss = 1.12002183, grad/param norm = 1.9864e-01, time/batch = 15.9554s	
11048/26050 (epoch 21.205), train_loss = 0.94864802, grad/param norm = 1.7276e-01, time/batch = 18.4755s	
11049/26050 (epoch 21.207), train_loss = 0.93794655, grad/param norm = 1.6802e-01, time/batch = 17.3144s	
11050/26050 (epoch 21.209), train_loss = 1.05032265, grad/param norm = 1.6939e-01, time/batch = 17.9060s	
11051/26050 (epoch 21.211), train_loss = 0.83923515, grad/param norm = 1.5631e-01, time/batch = 18.5587s	
11052/26050 (epoch 21.213), train_loss = 1.05611526, grad/param norm = 1.9854e-01, time/batch = 18.3719s	
11053/26050 (epoch 21.215), train_loss = 0.99228436, grad/param norm = 1.9990e-01, time/batch = 18.6455s	
11054/26050 (epoch 21.217), train_loss = 0.96237524, grad/param norm = 1.7133e-01, time/batch = 18.3176s	
11055/26050 (epoch 21.219), train_loss = 0.97408031, grad/param norm = 1.9135e-01, time/batch = 16.3895s	
11056/26050 (epoch 21.221), train_loss = 0.91123819, grad/param norm = 1.8863e-01, time/batch = 16.5768s	
11057/26050 (epoch 21.223), train_loss = 1.04301192, grad/param norm = 1.8364e-01, time/batch = 18.0592s	
11058/26050 (epoch 21.225), train_loss = 0.89437063, grad/param norm = 1.7806e-01, time/batch = 16.0468s	
11059/26050 (epoch 21.226), train_loss = 1.05682378, grad/param norm = 2.2032e-01, time/batch = 17.6115s	
11060/26050 (epoch 21.228), train_loss = 1.14711141, grad/param norm = 1.9314e-01, time/batch = 18.2196s	
11061/26050 (epoch 21.230), train_loss = 1.04027695, grad/param norm = 1.7322e-01, time/batch = 18.4126s	
11062/26050 (epoch 21.232), train_loss = 1.09424155, grad/param norm = 2.1431e-01, time/batch = 18.7481s	
11063/26050 (epoch 21.234), train_loss = 0.88604976, grad/param norm = 1.7051e-01, time/batch = 16.1519s	
11064/26050 (epoch 21.236), train_loss = 1.09434719, grad/param norm = 1.9064e-01, time/batch = 18.4767s	
11065/26050 (epoch 21.238), train_loss = 0.87214713, grad/param norm = 1.6772e-01, time/batch = 17.4102s	
11066/26050 (epoch 21.240), train_loss = 1.01576291, grad/param norm = 1.8565e-01, time/batch = 17.5616s	
11067/26050 (epoch 21.242), train_loss = 1.00051206, grad/param norm = 1.7120e-01, time/batch = 18.9727s	
11068/26050 (epoch 21.244), train_loss = 1.00325731, grad/param norm = 1.9804e-01, time/batch = 17.6608s	
11069/26050 (epoch 21.246), train_loss = 0.93053042, grad/param norm = 1.7405e-01, time/batch = 17.3176s	
11070/26050 (epoch 21.248), train_loss = 1.01871298, grad/param norm = 1.8617e-01, time/batch = 17.1494s	
11071/26050 (epoch 21.250), train_loss = 1.00346831, grad/param norm = 1.9206e-01, time/batch = 15.9724s	
11072/26050 (epoch 21.251), train_loss = 0.96553557, grad/param norm = 1.6760e-01, time/batch = 16.8838s	
11073/26050 (epoch 21.253), train_loss = 0.88595850, grad/param norm = 1.7467e-01, time/batch = 14.9811s	
11074/26050 (epoch 21.255), train_loss = 1.17916754, grad/param norm = 1.8889e-01, time/batch = 18.8288s	
11075/26050 (epoch 21.257), train_loss = 0.99840315, grad/param norm = 1.9364e-01, time/batch = 18.0609s	
11076/26050 (epoch 21.259), train_loss = 1.13518155, grad/param norm = 1.8586e-01, time/batch = 17.6266s	
11077/26050 (epoch 21.261), train_loss = 0.89936733, grad/param norm = 1.7367e-01, time/batch = 17.7286s	
11078/26050 (epoch 21.263), train_loss = 1.06737431, grad/param norm = 1.9535e-01, time/batch = 15.9724s	
11079/26050 (epoch 21.265), train_loss = 1.15793142, grad/param norm = 1.9584e-01, time/batch = 18.2470s	
11080/26050 (epoch 21.267), train_loss = 1.12522361, grad/param norm = 1.7407e-01, time/batch = 16.2387s	
11081/26050 (epoch 21.269), train_loss = 1.13155596, grad/param norm = 2.0365e-01, time/batch = 18.5702s	
11082/26050 (epoch 21.271), train_loss = 1.05764026, grad/param norm = 1.8833e-01, time/batch = 18.6497s	
11083/26050 (epoch 21.273), train_loss = 0.97428493, grad/param norm = 1.9838e-01, time/batch = 16.9042s	
11084/26050 (epoch 21.274), train_loss = 0.98393318, grad/param norm = 1.6905e-01, time/batch = 17.9899s	
11085/26050 (epoch 21.276), train_loss = 0.96272214, grad/param norm = 2.0123e-01, time/batch = 18.1390s	
11086/26050 (epoch 21.278), train_loss = 1.14387233, grad/param norm = 1.8526e-01, time/batch = 18.2167s	
11087/26050 (epoch 21.280), train_loss = 1.00394180, grad/param norm = 1.7695e-01, time/batch = 18.4086s	
11088/26050 (epoch 21.282), train_loss = 1.04279879, grad/param norm = 1.8426e-01, time/batch = 14.7974s	
11089/26050 (epoch 21.284), train_loss = 0.96656434, grad/param norm = 1.7186e-01, time/batch = 18.1364s	
11090/26050 (epoch 21.286), train_loss = 1.02700411, grad/param norm = 1.9524e-01, time/batch = 15.8201s	
11091/26050 (epoch 21.288), train_loss = 0.87141757, grad/param norm = 1.6188e-01, time/batch = 17.9028s	
11092/26050 (epoch 21.290), train_loss = 1.02052939, grad/param norm = 1.8005e-01, time/batch = 18.9636s	
11093/26050 (epoch 21.292), train_loss = 0.92216526, grad/param norm = 1.6015e-01, time/batch = 17.5805s	
11094/26050 (epoch 21.294), train_loss = 1.02451092, grad/param norm = 2.0371e-01, time/batch = 17.5567s	
11095/26050 (epoch 21.296), train_loss = 1.10905943, grad/param norm = 1.8839e-01, time/batch = 17.1400s	
11096/26050 (epoch 21.298), train_loss = 1.02453504, grad/param norm = 1.7795e-01, time/batch = 16.9553s	
11097/26050 (epoch 21.299), train_loss = 0.81677615, grad/param norm = 1.5003e-01, time/batch = 16.9819s	
11098/26050 (epoch 21.301), train_loss = 0.87981675, grad/param norm = 1.7612e-01, time/batch = 18.7353s	
11099/26050 (epoch 21.303), train_loss = 1.00421257, grad/param norm = 1.8922e-01, time/batch = 17.9616s	
11100/26050 (epoch 21.305), train_loss = 0.83748952, grad/param norm = 1.7317e-01, time/batch = 14.8924s	
11101/26050 (epoch 21.307), train_loss = 0.93598032, grad/param norm = 1.8508e-01, time/batch = 18.7913s	
11102/26050 (epoch 21.309), train_loss = 0.99326119, grad/param norm = 1.9267e-01, time/batch = 18.1609s	
11103/26050 (epoch 21.311), train_loss = 1.09981899, grad/param norm = 2.0495e-01, time/batch = 18.6354s	
11104/26050 (epoch 21.313), train_loss = 1.00655786, grad/param norm = 2.1296e-01, time/batch = 31.7985s	
11105/26050 (epoch 21.315), train_loss = 1.11557188, grad/param norm = 1.9889e-01, time/batch = 25.8291s	
11106/26050 (epoch 21.317), train_loss = 1.01995884, grad/param norm = 1.8521e-01, time/batch = 17.8310s	
11107/26050 (epoch 21.319), train_loss = 0.92792052, grad/param norm = 1.6546e-01, time/batch = 18.8064s	
11108/26050 (epoch 21.321), train_loss = 0.97028007, grad/param norm = 1.7604e-01, time/batch = 17.4025s	
11109/26050 (epoch 21.322), train_loss = 1.02738543, grad/param norm = 1.6841e-01, time/batch = 16.0295s	
11110/26050 (epoch 21.324), train_loss = 0.83612868, grad/param norm = 1.7100e-01, time/batch = 16.8780s	
11111/26050 (epoch 21.326), train_loss = 1.15018109, grad/param norm = 1.9891e-01, time/batch = 18.4027s	
11112/26050 (epoch 21.328), train_loss = 1.04517025, grad/param norm = 1.8175e-01, time/batch = 17.7351s	
11113/26050 (epoch 21.330), train_loss = 0.89687453, grad/param norm = 1.7415e-01, time/batch = 17.9900s	
11114/26050 (epoch 21.332), train_loss = 1.05761262, grad/param norm = 1.8877e-01, time/batch = 18.3151s	
11115/26050 (epoch 21.334), train_loss = 0.96264049, grad/param norm = 1.8331e-01, time/batch = 16.8079s	
11116/26050 (epoch 21.336), train_loss = 0.97017233, grad/param norm = 1.9461e-01, time/batch = 17.1506s	
11117/26050 (epoch 21.338), train_loss = 0.88487092, grad/param norm = 1.5747e-01, time/batch = 18.6508s	
11118/26050 (epoch 21.340), train_loss = 1.09976633, grad/param norm = 1.9269e-01, time/batch = 17.7301s	
11119/26050 (epoch 21.342), train_loss = 1.10622724, grad/param norm = 1.8715e-01, time/batch = 16.8093s	
11120/26050 (epoch 21.344), train_loss = 0.95616800, grad/param norm = 1.9130e-01, time/batch = 17.7399s	
11121/26050 (epoch 21.345), train_loss = 0.99908606, grad/param norm = 1.8821e-01, time/batch = 16.8884s	
11122/26050 (epoch 21.347), train_loss = 1.13791052, grad/param norm = 2.0349e-01, time/batch = 18.2243s	
11123/26050 (epoch 21.349), train_loss = 1.07568331, grad/param norm = 2.0628e-01, time/batch = 17.3066s	
11124/26050 (epoch 21.351), train_loss = 1.03839523, grad/param norm = 1.7958e-01, time/batch = 17.1483s	
11125/26050 (epoch 21.353), train_loss = 1.01872673, grad/param norm = 1.9658e-01, time/batch = 15.1443s	
11126/26050 (epoch 21.355), train_loss = 1.06441002, grad/param norm = 1.9684e-01, time/batch = 16.7227s	
11127/26050 (epoch 21.357), train_loss = 0.94495605, grad/param norm = 1.6517e-01, time/batch = 17.9099s	
11128/26050 (epoch 21.359), train_loss = 1.12147302, grad/param norm = 1.8496e-01, time/batch = 18.2201s	
11129/26050 (epoch 21.361), train_loss = 0.93015829, grad/param norm = 1.6415e-01, time/batch = 18.4798s	
11130/26050 (epoch 21.363), train_loss = 1.07447779, grad/param norm = 1.8073e-01, time/batch = 17.8198s	
11131/26050 (epoch 21.365), train_loss = 0.96452582, grad/param norm = 1.6240e-01, time/batch = 18.9619s	
11132/26050 (epoch 21.367), train_loss = 1.05887350, grad/param norm = 1.7434e-01, time/batch = 18.5652s	
11133/26050 (epoch 21.369), train_loss = 0.96851619, grad/param norm = 1.9664e-01, time/batch = 17.1595s	
11134/26050 (epoch 21.370), train_loss = 0.89347180, grad/param norm = 1.5663e-01, time/batch = 17.4172s	
11135/26050 (epoch 21.372), train_loss = 1.05010727, grad/param norm = 1.8516e-01, time/batch = 17.5652s	
11136/26050 (epoch 21.374), train_loss = 1.13010615, grad/param norm = 1.8877e-01, time/batch = 16.8732s	
11137/26050 (epoch 21.376), train_loss = 1.22786649, grad/param norm = 2.0840e-01, time/batch = 15.2214s	
11138/26050 (epoch 21.378), train_loss = 0.97023466, grad/param norm = 1.7673e-01, time/batch = 17.9198s	
11139/26050 (epoch 21.380), train_loss = 1.20023624, grad/param norm = 2.1482e-01, time/batch = 18.2322s	
11140/26050 (epoch 21.382), train_loss = 1.28327619, grad/param norm = 2.2503e-01, time/batch = 17.4653s	
11141/26050 (epoch 21.384), train_loss = 1.01287437, grad/param norm = 1.9726e-01, time/batch = 18.2405s	
11142/26050 (epoch 21.386), train_loss = 1.08219858, grad/param norm = 2.2229e-01, time/batch = 17.8938s	
11143/26050 (epoch 21.388), train_loss = 1.02297552, grad/param norm = 1.8683e-01, time/batch = 17.9648s	
11144/26050 (epoch 21.390), train_loss = 0.95221787, grad/param norm = 1.8417e-01, time/batch = 15.1418s	
11145/26050 (epoch 21.392), train_loss = 0.90238553, grad/param norm = 1.6850e-01, time/batch = 17.7435s	
11146/26050 (epoch 21.393), train_loss = 1.06392020, grad/param norm = 1.9757e-01, time/batch = 18.2373s	
11147/26050 (epoch 21.395), train_loss = 1.06774457, grad/param norm = 1.7591e-01, time/batch = 17.7509s	
11148/26050 (epoch 21.397), train_loss = 1.07660030, grad/param norm = 1.9996e-01, time/batch = 18.6603s	
11149/26050 (epoch 21.399), train_loss = 0.94468520, grad/param norm = 1.8446e-01, time/batch = 18.1545s	
11150/26050 (epoch 21.401), train_loss = 1.02535605, grad/param norm = 1.8611e-01, time/batch = 14.5604s	
11151/26050 (epoch 21.403), train_loss = 1.04115891, grad/param norm = 1.9370e-01, time/batch = 17.3007s	
11152/26050 (epoch 21.405), train_loss = 1.03240888, grad/param norm = 1.8408e-01, time/batch = 17.7113s	
11153/26050 (epoch 21.407), train_loss = 1.16573321, grad/param norm = 1.8662e-01, time/batch = 17.6444s	
11154/26050 (epoch 21.409), train_loss = 1.17428486, grad/param norm = 2.0430e-01, time/batch = 18.0551s	
11155/26050 (epoch 21.411), train_loss = 1.07683168, grad/param norm = 1.8847e-01, time/batch = 18.7242s	
11156/26050 (epoch 21.413), train_loss = 1.17571656, grad/param norm = 1.7576e-01, time/batch = 16.6403s	
11157/26050 (epoch 21.415), train_loss = 1.14381199, grad/param norm = 2.0059e-01, time/batch = 17.9101s	
11158/26050 (epoch 21.417), train_loss = 1.24332325, grad/param norm = 2.0435e-01, time/batch = 18.9717s	
11159/26050 (epoch 21.418), train_loss = 1.14334057, grad/param norm = 2.0499e-01, time/batch = 18.0663s	
11160/26050 (epoch 21.420), train_loss = 0.87620489, grad/param norm = 1.7894e-01, time/batch = 17.9765s	
11161/26050 (epoch 21.422), train_loss = 0.87885685, grad/param norm = 1.7382e-01, time/batch = 15.9832s	
11162/26050 (epoch 21.424), train_loss = 1.17915785, grad/param norm = 2.1673e-01, time/batch = 17.8382s	
11163/26050 (epoch 21.426), train_loss = 1.13141409, grad/param norm = 1.8557e-01, time/batch = 17.9017s	
11164/26050 (epoch 21.428), train_loss = 0.94930210, grad/param norm = 1.5585e-01, time/batch = 17.6490s	
11165/26050 (epoch 21.430), train_loss = 1.14260543, grad/param norm = 1.8482e-01, time/batch = 18.6516s	
11166/26050 (epoch 21.432), train_loss = 0.98994179, grad/param norm = 1.7392e-01, time/batch = 15.2098s	
11167/26050 (epoch 21.434), train_loss = 1.00709969, grad/param norm = 2.0201e-01, time/batch = 16.9839s	
11168/26050 (epoch 21.436), train_loss = 1.15710075, grad/param norm = 2.1143e-01, time/batch = 17.7434s	
11169/26050 (epoch 21.438), train_loss = 1.07730267, grad/param norm = 2.0929e-01, time/batch = 18.7957s	
11170/26050 (epoch 21.440), train_loss = 1.05193826, grad/param norm = 1.9926e-01, time/batch = 17.2350s	
11171/26050 (epoch 21.441), train_loss = 1.01820961, grad/param norm = 1.7730e-01, time/batch = 4.2457s	
11172/26050 (epoch 21.443), train_loss = 0.87713665, grad/param norm = 1.5165e-01, time/batch = 0.6655s	
11173/26050 (epoch 21.445), train_loss = 0.95765678, grad/param norm = 1.7798e-01, time/batch = 0.6859s	
11174/26050 (epoch 21.447), train_loss = 1.16959624, grad/param norm = 2.0523e-01, time/batch = 0.6570s	
11175/26050 (epoch 21.449), train_loss = 0.93729662, grad/param norm = 1.7518e-01, time/batch = 0.6579s	
11176/26050 (epoch 21.451), train_loss = 1.18742219, grad/param norm = 1.9636e-01, time/batch = 0.6683s	
11177/26050 (epoch 21.453), train_loss = 0.94144420, grad/param norm = 1.5833e-01, time/batch = 0.6588s	
11178/26050 (epoch 21.455), train_loss = 1.03648878, grad/param norm = 1.7581e-01, time/batch = 0.7180s	
11179/26050 (epoch 21.457), train_loss = 1.01538925, grad/param norm = 1.7771e-01, time/batch = 0.9522s	
11180/26050 (epoch 21.459), train_loss = 1.12027062, grad/param norm = 1.8485e-01, time/batch = 0.9584s	
11181/26050 (epoch 21.461), train_loss = 1.12373211, grad/param norm = 2.1768e-01, time/batch = 0.9683s	
11182/26050 (epoch 21.463), train_loss = 0.99587746, grad/param norm = 1.7095e-01, time/batch = 0.9437s	
11183/26050 (epoch 21.464), train_loss = 1.06478168, grad/param norm = 1.7356e-01, time/batch = 0.9399s	
11184/26050 (epoch 21.466), train_loss = 1.08948653, grad/param norm = 1.9461e-01, time/batch = 1.7696s	
11185/26050 (epoch 21.468), train_loss = 1.12764770, grad/param norm = 1.7264e-01, time/batch = 1.7486s	
11186/26050 (epoch 21.470), train_loss = 1.16505412, grad/param norm = 2.0695e-01, time/batch = 5.0010s	
11187/26050 (epoch 21.472), train_loss = 1.17643260, grad/param norm = 2.2216e-01, time/batch = 18.8335s	
11188/26050 (epoch 21.474), train_loss = 1.17040251, grad/param norm = 1.7578e-01, time/batch = 16.5758s	
11189/26050 (epoch 21.476), train_loss = 1.15259939, grad/param norm = 1.7982e-01, time/batch = 14.9673s	
11190/26050 (epoch 21.478), train_loss = 1.02076279, grad/param norm = 1.8227e-01, time/batch = 18.1404s	
11191/26050 (epoch 21.480), train_loss = 1.02643167, grad/param norm = 1.6665e-01, time/batch = 18.7211s	
11192/26050 (epoch 21.482), train_loss = 0.98724319, grad/param norm = 1.8183e-01, time/batch = 17.5608s	
11193/26050 (epoch 21.484), train_loss = 0.97938605, grad/param norm = 1.8272e-01, time/batch = 18.4086s	
11194/26050 (epoch 21.486), train_loss = 1.16332785, grad/param norm = 1.8898e-01, time/batch = 16.3924s	
11195/26050 (epoch 21.488), train_loss = 1.26956911, grad/param norm = 2.0360e-01, time/batch = 16.9718s	
11196/26050 (epoch 21.489), train_loss = 1.19606424, grad/param norm = 2.2643e-01, time/batch = 17.8132s	
11197/26050 (epoch 21.491), train_loss = 0.95900559, grad/param norm = 1.7880e-01, time/batch = 18.0707s	
11198/26050 (epoch 21.493), train_loss = 1.05309130, grad/param norm = 1.9807e-01, time/batch = 17.9070s	
11199/26050 (epoch 21.495), train_loss = 1.02770473, grad/param norm = 1.7756e-01, time/batch = 17.7322s	
11200/26050 (epoch 21.497), train_loss = 0.95716510, grad/param norm = 1.7396e-01, time/batch = 18.6538s	
11201/26050 (epoch 21.499), train_loss = 1.00011116, grad/param norm = 1.7457e-01, time/batch = 17.2336s	
11202/26050 (epoch 21.501), train_loss = 1.10763951, grad/param norm = 1.9196e-01, time/batch = 15.4735s	
11203/26050 (epoch 21.503), train_loss = 0.98458405, grad/param norm = 1.8348e-01, time/batch = 17.3921s	
11204/26050 (epoch 21.505), train_loss = 1.16606858, grad/param norm = 1.7985e-01, time/batch = 15.2261s	
11205/26050 (epoch 21.507), train_loss = 1.10657850, grad/param norm = 1.9164e-01, time/batch = 17.5722s	
11206/26050 (epoch 21.509), train_loss = 1.20958360, grad/param norm = 1.8009e-01, time/batch = 17.7240s	
11207/26050 (epoch 21.511), train_loss = 0.97745573, grad/param norm = 1.6540e-01, time/batch = 17.9892s	
11208/26050 (epoch 21.512), train_loss = 0.95922210, grad/param norm = 1.9630e-01, time/batch = 18.3170s	
11209/26050 (epoch 21.514), train_loss = 1.10107200, grad/param norm = 1.9502e-01, time/batch = 16.9821s	
11210/26050 (epoch 21.516), train_loss = 1.17049580, grad/param norm = 2.0323e-01, time/batch = 18.1351s	
11211/26050 (epoch 21.518), train_loss = 1.04172910, grad/param norm = 1.9125e-01, time/batch = 17.3309s	
11212/26050 (epoch 21.520), train_loss = 1.01717226, grad/param norm = 1.7518e-01, time/batch = 15.7109s	
11213/26050 (epoch 21.522), train_loss = 0.80882232, grad/param norm = 1.5473e-01, time/batch = 15.9048s	
11214/26050 (epoch 21.524), train_loss = 1.11670296, grad/param norm = 2.0008e-01, time/batch = 17.7258s	
11215/26050 (epoch 21.526), train_loss = 1.15321355, grad/param norm = 1.9199e-01, time/batch = 18.2234s	
11216/26050 (epoch 21.528), train_loss = 1.09663819, grad/param norm = 2.0577e-01, time/batch = 16.6593s	
11217/26050 (epoch 21.530), train_loss = 1.00432766, grad/param norm = 1.7899e-01, time/batch = 18.2361s	
11218/26050 (epoch 21.532), train_loss = 1.05446247, grad/param norm = 1.8372e-01, time/batch = 18.5801s	
11219/26050 (epoch 21.534), train_loss = 1.10569504, grad/param norm = 2.0951e-01, time/batch = 16.7387s	
11220/26050 (epoch 21.536), train_loss = 1.03611734, grad/param norm = 1.7636e-01, time/batch = 17.4873s	
11221/26050 (epoch 21.537), train_loss = 1.11170697, grad/param norm = 1.9426e-01, time/batch = 14.9599s	
11222/26050 (epoch 21.539), train_loss = 1.04893157, grad/param norm = 1.8613e-01, time/batch = 18.9116s	
11223/26050 (epoch 21.541), train_loss = 1.24278421, grad/param norm = 2.0545e-01, time/batch = 17.8217s	
11224/26050 (epoch 21.543), train_loss = 0.88780484, grad/param norm = 1.9653e-01, time/batch = 14.7998s	
11225/26050 (epoch 21.545), train_loss = 1.09812091, grad/param norm = 1.9421e-01, time/batch = 18.8819s	
11226/26050 (epoch 21.547), train_loss = 1.02464704, grad/param norm = 1.7460e-01, time/batch = 17.7377s	
11227/26050 (epoch 21.549), train_loss = 0.86357852, grad/param norm = 1.7375e-01, time/batch = 15.6508s	
11228/26050 (epoch 21.551), train_loss = 1.09039071, grad/param norm = 1.8333e-01, time/batch = 17.3985s	
11229/26050 (epoch 21.553), train_loss = 0.97116790, grad/param norm = 1.7559e-01, time/batch = 18.7399s	
11230/26050 (epoch 21.555), train_loss = 0.98183631, grad/param norm = 1.7784e-01, time/batch = 18.2285s	
11231/26050 (epoch 21.557), train_loss = 1.06833909, grad/param norm = 1.6821e-01, time/batch = 17.9802s	
11232/26050 (epoch 21.559), train_loss = 1.01184299, grad/param norm = 1.8146e-01, time/batch = 19.0668s	
11233/26050 (epoch 21.560), train_loss = 1.00413361, grad/param norm = 1.9463e-01, time/batch = 17.1468s	
11234/26050 (epoch 21.562), train_loss = 1.01049031, grad/param norm = 1.8044e-01, time/batch = 17.9876s	
11235/26050 (epoch 21.564), train_loss = 1.20347848, grad/param norm = 1.8242e-01, time/batch = 17.9828s	
11236/26050 (epoch 21.566), train_loss = 0.93758757, grad/param norm = 1.7099e-01, time/batch = 17.3122s	
11237/26050 (epoch 21.568), train_loss = 1.07738400, grad/param norm = 1.7859e-01, time/batch = 18.3940s	
11238/26050 (epoch 21.570), train_loss = 1.10004759, grad/param norm = 1.9100e-01, time/batch = 15.0686s	
11239/26050 (epoch 21.572), train_loss = 1.00949867, grad/param norm = 1.8713e-01, time/batch = 18.3218s	
11240/26050 (epoch 21.574), train_loss = 1.07934382, grad/param norm = 2.1072e-01, time/batch = 16.3782s	
11241/26050 (epoch 21.576), train_loss = 1.05957352, grad/param norm = 1.8689e-01, time/batch = 18.3192s	
11242/26050 (epoch 21.578), train_loss = 1.00751680, grad/param norm = 1.8882e-01, time/batch = 18.4828s	
11243/26050 (epoch 21.580), train_loss = 0.97760493, grad/param norm = 1.9570e-01, time/batch = 17.4004s	
11244/26050 (epoch 21.582), train_loss = 1.05702963, grad/param norm = 1.8135e-01, time/batch = 18.6548s	
11245/26050 (epoch 21.583), train_loss = 1.13717904, grad/param norm = 1.7387e-01, time/batch = 15.6616s	
11246/26050 (epoch 21.585), train_loss = 0.89906642, grad/param norm = 1.8599e-01, time/batch = 17.9867s	
11247/26050 (epoch 21.587), train_loss = 1.08692616, grad/param norm = 2.0965e-01, time/batch = 17.2205s	
11248/26050 (epoch 21.589), train_loss = 1.19849727, grad/param norm = 2.0499e-01, time/batch = 16.6310s	
11249/26050 (epoch 21.591), train_loss = 1.01140682, grad/param norm = 1.9015e-01, time/batch = 18.6658s	
11250/26050 (epoch 21.593), train_loss = 0.92030458, grad/param norm = 1.7967e-01, time/batch = 17.7268s	
11251/26050 (epoch 21.595), train_loss = 1.09810053, grad/param norm = 2.0284e-01, time/batch = 16.3908s	
11252/26050 (epoch 21.597), train_loss = 1.06472373, grad/param norm = 1.8971e-01, time/batch = 18.5594s	
11253/26050 (epoch 21.599), train_loss = 1.05209735, grad/param norm = 1.9732e-01, time/batch = 16.5496s	
11254/26050 (epoch 21.601), train_loss = 1.21763748, grad/param norm = 1.8898e-01, time/batch = 17.6621s	
11255/26050 (epoch 21.603), train_loss = 1.05393903, grad/param norm = 1.8264e-01, time/batch = 16.0608s	
11256/26050 (epoch 21.605), train_loss = 0.98142923, grad/param norm = 1.7363e-01, time/batch = 18.8242s	
11257/26050 (epoch 21.607), train_loss = 1.15749637, grad/param norm = 2.0793e-01, time/batch = 17.1504s	
11258/26050 (epoch 21.608), train_loss = 0.89761744, grad/param norm = 1.5748e-01, time/batch = 18.3143s	
11259/26050 (epoch 21.610), train_loss = 1.02466702, grad/param norm = 1.8834e-01, time/batch = 18.4155s	
11260/26050 (epoch 21.612), train_loss = 1.02869155, grad/param norm = 1.8970e-01, time/batch = 16.5457s	
11261/26050 (epoch 21.614), train_loss = 1.05773243, grad/param norm = 1.7852e-01, time/batch = 14.8090s	
11262/26050 (epoch 21.616), train_loss = 1.18401182, grad/param norm = 2.1918e-01, time/batch = 17.6493s	
11263/26050 (epoch 21.618), train_loss = 0.98498391, grad/param norm = 1.9063e-01, time/batch = 17.4614s	
11264/26050 (epoch 21.620), train_loss = 1.08170958, grad/param norm = 1.8133e-01, time/batch = 17.4802s	
11265/26050 (epoch 21.622), train_loss = 0.91207218, grad/param norm = 1.5134e-01, time/batch = 17.7340s	
11266/26050 (epoch 21.624), train_loss = 0.89785112, grad/param norm = 1.7393e-01, time/batch = 18.8971s	
11267/26050 (epoch 21.626), train_loss = 1.10372471, grad/param norm = 1.9304e-01, time/batch = 17.5584s	
11268/26050 (epoch 21.628), train_loss = 0.95850499, grad/param norm = 1.7681e-01, time/batch = 18.5664s	
11269/26050 (epoch 21.630), train_loss = 1.16439476, grad/param norm = 1.8133e-01, time/batch = 18.3277s	
11270/26050 (epoch 21.631), train_loss = 1.19717168, grad/param norm = 1.9441e-01, time/batch = 17.6426s	
11271/26050 (epoch 21.633), train_loss = 0.92507641, grad/param norm = 1.6458e-01, time/batch = 18.1475s	
11272/26050 (epoch 21.635), train_loss = 0.95093932, grad/param norm = 1.6177e-01, time/batch = 15.9529s	
11273/26050 (epoch 21.637), train_loss = 0.93350305, grad/param norm = 1.8103e-01, time/batch = 17.7918s	
11274/26050 (epoch 21.639), train_loss = 1.13588428, grad/param norm = 1.8341e-01, time/batch = 16.7947s	
11275/26050 (epoch 21.641), train_loss = 1.00461341, grad/param norm = 1.6695e-01, time/batch = 18.1960s	
11276/26050 (epoch 21.643), train_loss = 0.92880343, grad/param norm = 1.6107e-01, time/batch = 18.5692s	
11277/26050 (epoch 21.645), train_loss = 1.02100286, grad/param norm = 1.7884e-01, time/batch = 17.7334s	
11278/26050 (epoch 21.647), train_loss = 0.97778356, grad/param norm = 1.8087e-01, time/batch = 15.3020s	
11279/26050 (epoch 21.649), train_loss = 1.05357282, grad/param norm = 2.1386e-01, time/batch = 17.9049s	
11280/26050 (epoch 21.651), train_loss = 0.97883469, grad/param norm = 1.8237e-01, time/batch = 18.6329s	
11281/26050 (epoch 21.653), train_loss = 1.03221672, grad/param norm = 1.7832e-01, time/batch = 18.5410s	
11282/26050 (epoch 21.655), train_loss = 0.96215664, grad/param norm = 1.7856e-01, time/batch = 15.4713s	
11283/26050 (epoch 21.656), train_loss = 0.88575717, grad/param norm = 1.6377e-01, time/batch = 17.2163s	
11284/26050 (epoch 21.658), train_loss = 1.21140969, grad/param norm = 1.9428e-01, time/batch = 16.2047s	
11285/26050 (epoch 21.660), train_loss = 0.90333198, grad/param norm = 1.8157e-01, time/batch = 18.1565s	
11286/26050 (epoch 21.662), train_loss = 0.98832548, grad/param norm = 1.8001e-01, time/batch = 18.7282s	
11287/26050 (epoch 21.664), train_loss = 1.01589527, grad/param norm = 1.7967e-01, time/batch = 17.4878s	
11288/26050 (epoch 21.666), train_loss = 0.99394792, grad/param norm = 1.9168e-01, time/batch = 17.8858s	
11289/26050 (epoch 21.668), train_loss = 0.84875339, grad/param norm = 1.9523e-01, time/batch = 18.7377s	
11290/26050 (epoch 21.670), train_loss = 1.16677265, grad/param norm = 2.1202e-01, time/batch = 19.0570s	
11291/26050 (epoch 21.672), train_loss = 1.02577827, grad/param norm = 2.0272e-01, time/batch = 17.4740s	
11292/26050 (epoch 21.674), train_loss = 0.94103677, grad/param norm = 1.7642e-01, time/batch = 18.9747s	
11293/26050 (epoch 21.676), train_loss = 1.07762973, grad/param norm = 2.0318e-01, time/batch = 18.0627s	
11294/26050 (epoch 21.678), train_loss = 1.15689737, grad/param norm = 2.0406e-01, time/batch = 17.1411s	
11295/26050 (epoch 21.679), train_loss = 1.22089874, grad/param norm = 2.0568e-01, time/batch = 18.1285s	
11296/26050 (epoch 21.681), train_loss = 1.04530160, grad/param norm = 1.8507e-01, time/batch = 17.8162s	
11297/26050 (epoch 21.683), train_loss = 0.95412322, grad/param norm = 2.5738e-01, time/batch = 17.8116s	
11298/26050 (epoch 21.685), train_loss = 1.00076316, grad/param norm = 1.9295e-01, time/batch = 17.4806s	
11299/26050 (epoch 21.687), train_loss = 0.89185974, grad/param norm = 1.7988e-01, time/batch = 15.2324s	
11300/26050 (epoch 21.689), train_loss = 0.99403577, grad/param norm = 1.9605e-01, time/batch = 17.9784s	
11301/26050 (epoch 21.691), train_loss = 0.81634359, grad/param norm = 1.6275e-01, time/batch = 17.1480s	
11302/26050 (epoch 21.693), train_loss = 0.93587739, grad/param norm = 1.8737e-01, time/batch = 14.9012s	
11303/26050 (epoch 21.695), train_loss = 1.03340170, grad/param norm = 1.8761e-01, time/batch = 18.4061s	
11304/26050 (epoch 21.697), train_loss = 0.92624208, grad/param norm = 1.6448e-01, time/batch = 14.9635s	
11305/26050 (epoch 21.699), train_loss = 1.08126839, grad/param norm = 2.0323e-01, time/batch = 17.0309s	
11306/26050 (epoch 21.701), train_loss = 0.92281962, grad/param norm = 1.6472e-01, time/batch = 17.6593s	
11307/26050 (epoch 21.702), train_loss = 1.14561093, grad/param norm = 1.9342e-01, time/batch = 18.9797s	
11308/26050 (epoch 21.704), train_loss = 1.11465968, grad/param norm = 1.7023e-01, time/batch = 17.1533s	
11309/26050 (epoch 21.706), train_loss = 1.00615127, grad/param norm = 2.0505e-01, time/batch = 17.3202s	
11310/26050 (epoch 21.708), train_loss = 1.10342264, grad/param norm = 1.8836e-01, time/batch = 18.3083s	
11311/26050 (epoch 21.710), train_loss = 1.09206416, grad/param norm = 2.0098e-01, time/batch = 15.2929s	
11312/26050 (epoch 21.712), train_loss = 1.07350234, grad/param norm = 1.8895e-01, time/batch = 18.3178s	
11313/26050 (epoch 21.714), train_loss = 0.88897487, grad/param norm = 1.8456e-01, time/batch = 17.4868s	
11314/26050 (epoch 21.716), train_loss = 1.26575520, grad/param norm = 2.0176e-01, time/batch = 18.8193s	
11315/26050 (epoch 21.718), train_loss = 1.11568842, grad/param norm = 1.9362e-01, time/batch = 16.9045s	
11316/26050 (epoch 21.720), train_loss = 1.00835046, grad/param norm = 1.9040e-01, time/batch = 18.8920s	
11317/26050 (epoch 21.722), train_loss = 0.89053143, grad/param norm = 1.7372e-01, time/batch = 16.7129s	
11318/26050 (epoch 21.724), train_loss = 0.95388350, grad/param norm = 1.9001e-01, time/batch = 16.9903s	
11319/26050 (epoch 21.726), train_loss = 1.09862671, grad/param norm = 1.9722e-01, time/batch = 18.8976s	
11320/26050 (epoch 21.727), train_loss = 1.08029926, grad/param norm = 1.9227e-01, time/batch = 18.4650s	
11321/26050 (epoch 21.729), train_loss = 1.08504323, grad/param norm = 1.8751e-01, time/batch = 18.2920s	
11322/26050 (epoch 21.731), train_loss = 1.05522307, grad/param norm = 1.7386e-01, time/batch = 32.1080s	
11323/26050 (epoch 21.733), train_loss = 0.99817961, grad/param norm = 2.2465e-01, time/batch = 24.3087s	
11324/26050 (epoch 21.735), train_loss = 1.23087923, grad/param norm = 2.0416e-01, time/batch = 16.2669s	
11325/26050 (epoch 21.737), train_loss = 0.97368061, grad/param norm = 1.8545e-01, time/batch = 16.9689s	
11326/26050 (epoch 21.739), train_loss = 1.04704073, grad/param norm = 1.7691e-01, time/batch = 18.9886s	
11327/26050 (epoch 21.741), train_loss = 0.95511792, grad/param norm = 1.9894e-01, time/batch = 17.3973s	
11328/26050 (epoch 21.743), train_loss = 1.08431406, grad/param norm = 2.8605e-01, time/batch = 18.8851s	
11329/26050 (epoch 21.745), train_loss = 0.90703959, grad/param norm = 1.8361e-01, time/batch = 18.3209s	
11330/26050 (epoch 21.747), train_loss = 0.92876884, grad/param norm = 1.7545e-01, time/batch = 17.6650s	
11331/26050 (epoch 21.749), train_loss = 1.15379354, grad/param norm = 1.9324e-01, time/batch = 17.9922s	
11332/26050 (epoch 21.750), train_loss = 1.01739390, grad/param norm = 1.6275e-01, time/batch = 18.6474s	
11333/26050 (epoch 21.752), train_loss = 1.00705017, grad/param norm = 2.2877e-01, time/batch = 17.4755s	
11334/26050 (epoch 21.754), train_loss = 1.04702766, grad/param norm = 1.8781e-01, time/batch = 18.0329s	
11335/26050 (epoch 21.756), train_loss = 1.02668919, grad/param norm = 2.2510e-01, time/batch = 18.3161s	
11336/26050 (epoch 21.758), train_loss = 1.01385171, grad/param norm = 2.1024e-01, time/batch = 16.1293s	
11337/26050 (epoch 21.760), train_loss = 1.21917959, grad/param norm = 2.0167e-01, time/batch = 17.0585s	
11338/26050 (epoch 21.762), train_loss = 0.97958282, grad/param norm = 1.8337e-01, time/batch = 18.7130s	
11339/26050 (epoch 21.764), train_loss = 1.04314328, grad/param norm = 1.8875e-01, time/batch = 18.4887s	
11340/26050 (epoch 21.766), train_loss = 1.09246211, grad/param norm = 2.2554e-01, time/batch = 17.5800s	
11341/26050 (epoch 21.768), train_loss = 0.92345830, grad/param norm = 1.6635e-01, time/batch = 15.1462s	
11342/26050 (epoch 21.770), train_loss = 1.02495195, grad/param norm = 2.2013e-01, time/batch = 17.9848s	
11343/26050 (epoch 21.772), train_loss = 1.02369031, grad/param norm = 1.7106e-01, time/batch = 18.8107s	
11344/26050 (epoch 21.774), train_loss = 0.89209702, grad/param norm = 1.8862e-01, time/batch = 17.4154s	
11345/26050 (epoch 21.775), train_loss = 0.74174894, grad/param norm = 1.6026e-01, time/batch = 16.8790s	
11346/26050 (epoch 21.777), train_loss = 0.95337292, grad/param norm = 1.8070e-01, time/batch = 18.0662s	
11347/26050 (epoch 21.779), train_loss = 0.98818618, grad/param norm = 1.8415e-01, time/batch = 18.3191s	
11348/26050 (epoch 21.781), train_loss = 0.91170567, grad/param norm = 1.7897e-01, time/batch = 18.4704s	
11349/26050 (epoch 21.783), train_loss = 0.90715536, grad/param norm = 1.8288e-01, time/batch = 15.0546s	
11350/26050 (epoch 21.785), train_loss = 1.01276336, grad/param norm = 1.8542e-01, time/batch = 17.8167s	
11351/26050 (epoch 21.787), train_loss = 0.93588106, grad/param norm = 1.8616e-01, time/batch = 18.4639s	
11352/26050 (epoch 21.789), train_loss = 0.96248684, grad/param norm = 2.1049e-01, time/batch = 18.4854s	
11353/26050 (epoch 21.791), train_loss = 0.96353889, grad/param norm = 1.8999e-01, time/batch = 17.5675s	
11354/26050 (epoch 21.793), train_loss = 1.01810828, grad/param norm = 1.9689e-01, time/batch = 16.4847s	
11355/26050 (epoch 21.795), train_loss = 0.82991103, grad/param norm = 1.5314e-01, time/batch = 18.2407s	
11356/26050 (epoch 21.797), train_loss = 0.94050353, grad/param norm = 1.7307e-01, time/batch = 18.1530s	
11357/26050 (epoch 21.798), train_loss = 0.86917751, grad/param norm = 1.7256e-01, time/batch = 17.8250s	
11358/26050 (epoch 21.800), train_loss = 0.88493555, grad/param norm = 1.6218e-01, time/batch = 18.5488s	
11359/26050 (epoch 21.802), train_loss = 0.96980509, grad/param norm = 1.9263e-01, time/batch = 17.4028s	
11360/26050 (epoch 21.804), train_loss = 1.01025386, grad/param norm = 1.8773e-01, time/batch = 17.7938s	
11361/26050 (epoch 21.806), train_loss = 1.09561296, grad/param norm = 1.8725e-01, time/batch = 17.9581s	
11362/26050 (epoch 21.808), train_loss = 1.00894515, grad/param norm = 1.7509e-01, time/batch = 18.8045s	
11363/26050 (epoch 21.810), train_loss = 0.96890540, grad/param norm = 1.8274e-01, time/batch = 18.6501s	
11364/26050 (epoch 21.812), train_loss = 0.90108507, grad/param norm = 1.8431e-01, time/batch = 16.6418s	
11365/26050 (epoch 21.814), train_loss = 0.90269287, grad/param norm = 1.9287e-01, time/batch = 17.2727s	
11366/26050 (epoch 21.816), train_loss = 1.10110902, grad/param norm = 2.0307e-01, time/batch = 18.6607s	
11367/26050 (epoch 21.818), train_loss = 1.10919743, grad/param norm = 2.0173e-01, time/batch = 17.0803s	
11368/26050 (epoch 21.820), train_loss = 1.03063181, grad/param norm = 1.8550e-01, time/batch = 17.7393s	
11369/26050 (epoch 21.821), train_loss = 1.14253506, grad/param norm = 2.0098e-01, time/batch = 18.7285s	
11370/26050 (epoch 21.823), train_loss = 1.15904657, grad/param norm = 1.9988e-01, time/batch = 17.9773s	
11371/26050 (epoch 21.825), train_loss = 1.00094481, grad/param norm = 1.9386e-01, time/batch = 18.6978s	
11372/26050 (epoch 21.827), train_loss = 1.04086591, grad/param norm = 2.0331e-01, time/batch = 15.9726s	
11373/26050 (epoch 21.829), train_loss = 1.11161397, grad/param norm = 2.0116e-01, time/batch = 15.4987s	
11374/26050 (epoch 21.831), train_loss = 1.15605621, grad/param norm = 1.8147e-01, time/batch = 16.2253s	
11375/26050 (epoch 21.833), train_loss = 1.21994276, grad/param norm = 2.0093e-01, time/batch = 17.7427s	
11376/26050 (epoch 21.835), train_loss = 1.20366812, grad/param norm = 1.9553e-01, time/batch = 15.2245s	
11377/26050 (epoch 21.837), train_loss = 1.02324023, grad/param norm = 1.7184e-01, time/batch = 18.6583s	
11378/26050 (epoch 21.839), train_loss = 1.04896025, grad/param norm = 2.1039e-01, time/batch = 17.6364s	
11379/26050 (epoch 21.841), train_loss = 1.17034646, grad/param norm = 1.9400e-01, time/batch = 18.7376s	
11380/26050 (epoch 21.843), train_loss = 1.01402339, grad/param norm = 1.7747e-01, time/batch = 18.2988s	
11381/26050 (epoch 21.845), train_loss = 0.97697913, grad/param norm = 1.7439e-01, time/batch = 16.8777s	
11382/26050 (epoch 21.846), train_loss = 1.10613613, grad/param norm = 1.7760e-01, time/batch = 15.0688s	
11383/26050 (epoch 21.848), train_loss = 1.00697876, grad/param norm = 1.7766e-01, time/batch = 15.2368s	
11384/26050 (epoch 21.850), train_loss = 0.93136521, grad/param norm = 1.7450e-01, time/batch = 17.9062s	
11385/26050 (epoch 21.852), train_loss = 1.02133517, grad/param norm = 1.7774e-01, time/batch = 18.0549s	
11386/26050 (epoch 21.854), train_loss = 1.00787243, grad/param norm = 1.8523e-01, time/batch = 18.9902s	
11387/26050 (epoch 21.856), train_loss = 0.98752590, grad/param norm = 1.9698e-01, time/batch = 16.9013s	
11388/26050 (epoch 21.858), train_loss = 0.93491107, grad/param norm = 1.8443e-01, time/batch = 16.6325s	
11389/26050 (epoch 21.860), train_loss = 1.04864672, grad/param norm = 1.8195e-01, time/batch = 18.5776s	
11390/26050 (epoch 21.862), train_loss = 1.09034816, grad/param norm = 1.9047e-01, time/batch = 18.4007s	
11391/26050 (epoch 21.864), train_loss = 1.05571561, grad/param norm = 2.0814e-01, time/batch = 18.0643s	
11392/26050 (epoch 21.866), train_loss = 0.97509938, grad/param norm = 1.6666e-01, time/batch = 17.3922s	
11393/26050 (epoch 21.868), train_loss = 1.06588529, grad/param norm = 1.9570e-01, time/batch = 16.2161s	
11394/26050 (epoch 21.869), train_loss = 0.91518998, grad/param norm = 1.6539e-01, time/batch = 15.2229s	
11395/26050 (epoch 21.871), train_loss = 0.85194791, grad/param norm = 1.6392e-01, time/batch = 17.5608s	
11396/26050 (epoch 21.873), train_loss = 1.08391421, grad/param norm = 2.0901e-01, time/batch = 17.9648s	
11397/26050 (epoch 21.875), train_loss = 1.02384906, grad/param norm = 2.0008e-01, time/batch = 14.7313s	
11398/26050 (epoch 21.877), train_loss = 0.90785066, grad/param norm = 1.6892e-01, time/batch = 17.6638s	
11399/26050 (epoch 21.879), train_loss = 1.03453904, grad/param norm = 1.6602e-01, time/batch = 18.0654s	
11400/26050 (epoch 21.881), train_loss = 1.12232552, grad/param norm = 2.0002e-01, time/batch = 18.7308s	
11401/26050 (epoch 21.883), train_loss = 1.06425770, grad/param norm = 1.7749e-01, time/batch = 19.0696s	
11402/26050 (epoch 21.885), train_loss = 0.77591237, grad/param norm = 1.6290e-01, time/batch = 16.4591s	
11403/26050 (epoch 21.887), train_loss = 1.06511396, grad/param norm = 1.8132e-01, time/batch = 16.2248s	
11404/26050 (epoch 21.889), train_loss = 0.96924637, grad/param norm = 1.7612e-01, time/batch = 18.3257s	
11405/26050 (epoch 21.891), train_loss = 0.84614711, grad/param norm = 1.6553e-01, time/batch = 17.3699s	
11406/26050 (epoch 21.893), train_loss = 0.88527899, grad/param norm = 1.7091e-01, time/batch = 16.8887s	
11407/26050 (epoch 21.894), train_loss = 0.96620723, grad/param norm = 1.7153e-01, time/batch = 17.4561s	
11408/26050 (epoch 21.896), train_loss = 1.10370104, grad/param norm = 1.8482e-01, time/batch = 18.7195s	
11409/26050 (epoch 21.898), train_loss = 0.95502620, grad/param norm = 1.8986e-01, time/batch = 17.1542s	
11410/26050 (epoch 21.900), train_loss = 1.05491742, grad/param norm = 1.8635e-01, time/batch = 18.6372s	
11411/26050 (epoch 21.902), train_loss = 1.00038702, grad/param norm = 1.7707e-01, time/batch = 18.5646s	
11412/26050 (epoch 21.904), train_loss = 1.00270301, grad/param norm = 1.8752e-01, time/batch = 14.7031s	
11413/26050 (epoch 21.906), train_loss = 1.00643063, grad/param norm = 1.9438e-01, time/batch = 18.1691s	
11414/26050 (epoch 21.908), train_loss = 1.01270795, grad/param norm = 1.7205e-01, time/batch = 15.1532s	
11415/26050 (epoch 21.910), train_loss = 0.97960291, grad/param norm = 1.8081e-01, time/batch = 18.1576s	
11416/26050 (epoch 21.912), train_loss = 1.21732607, grad/param norm = 2.0349e-01, time/batch = 18.0680s	
11417/26050 (epoch 21.914), train_loss = 1.36731189, grad/param norm = 2.2289e-01, time/batch = 18.4835s	
11418/26050 (epoch 21.916), train_loss = 1.12979391, grad/param norm = 2.0134e-01, time/batch = 18.6584s	
11419/26050 (epoch 21.917), train_loss = 1.02689704, grad/param norm = 2.0913e-01, time/batch = 16.3719s	
11420/26050 (epoch 21.919), train_loss = 1.09866064, grad/param norm = 2.0296e-01, time/batch = 17.6373s	
11421/26050 (epoch 21.921), train_loss = 0.97075144, grad/param norm = 1.9160e-01, time/batch = 17.7367s	
11422/26050 (epoch 21.923), train_loss = 1.03307914, grad/param norm = 1.9185e-01, time/batch = 16.2278s	
11423/26050 (epoch 21.925), train_loss = 1.00736504, grad/param norm = 1.7468e-01, time/batch = 18.0847s	
11424/26050 (epoch 21.927), train_loss = 0.90063595, grad/param norm = 1.4757e-01, time/batch = 18.3904s	
11425/26050 (epoch 21.929), train_loss = 0.88096398, grad/param norm = 1.7219e-01, time/batch = 16.8811s	
11426/26050 (epoch 21.931), train_loss = 1.18066994, grad/param norm = 2.1458e-01, time/batch = 14.4626s	
11427/26050 (epoch 21.933), train_loss = 0.97361674, grad/param norm = 1.7665e-01, time/batch = 14.8883s	
11428/26050 (epoch 21.935), train_loss = 0.99645673, grad/param norm = 1.8203e-01, time/batch = 18.8188s	
11429/26050 (epoch 21.937), train_loss = 1.10909466, grad/param norm = 1.8617e-01, time/batch = 17.4862s	
11430/26050 (epoch 21.939), train_loss = 0.93487030, grad/param norm = 1.5439e-01, time/batch = 15.4839s	
11431/26050 (epoch 21.940), train_loss = 0.97588626, grad/param norm = 1.5879e-01, time/batch = 18.5659s	
11432/26050 (epoch 21.942), train_loss = 1.00573136, grad/param norm = 1.8057e-01, time/batch = 18.2355s	
11433/26050 (epoch 21.944), train_loss = 0.97034175, grad/param norm = 1.6324e-01, time/batch = 17.5669s	
11434/26050 (epoch 21.946), train_loss = 1.15102592, grad/param norm = 1.9566e-01, time/batch = 18.8155s	
11435/26050 (epoch 21.948), train_loss = 0.91084603, grad/param norm = 2.0052e-01, time/batch = 18.2390s	
11436/26050 (epoch 21.950), train_loss = 0.99114230, grad/param norm = 1.7858e-01, time/batch = 16.4983s	
11437/26050 (epoch 21.952), train_loss = 1.09713687, grad/param norm = 1.9455e-01, time/batch = 15.2340s	
11438/26050 (epoch 21.954), train_loss = 1.11070855, grad/param norm = 1.8364e-01, time/batch = 15.3411s	
11439/26050 (epoch 21.956), train_loss = 1.00813969, grad/param norm = 1.8652e-01, time/batch = 13.9247s	
11440/26050 (epoch 21.958), train_loss = 0.96080364, grad/param norm = 1.7137e-01, time/batch = 14.2153s	
11441/26050 (epoch 21.960), train_loss = 1.04210673, grad/param norm = 1.9561e-01, time/batch = 14.1549s	
11442/26050 (epoch 21.962), train_loss = 0.96191628, grad/param norm = 1.6063e-01, time/batch = 18.0438s	
11443/26050 (epoch 21.964), train_loss = 1.01452134, grad/param norm = 1.8638e-01, time/batch = 18.1646s	
11444/26050 (epoch 21.965), train_loss = 0.94280062, grad/param norm = 1.7965e-01, time/batch = 16.8111s	
11445/26050 (epoch 21.967), train_loss = 1.34446000, grad/param norm = 1.9378e-01, time/batch = 17.6534s	
11446/26050 (epoch 21.969), train_loss = 1.04076284, grad/param norm = 2.1051e-01, time/batch = 16.8078s	
11447/26050 (epoch 21.971), train_loss = 0.97003714, grad/param norm = 1.6836e-01, time/batch = 17.8958s	
11448/26050 (epoch 21.973), train_loss = 1.02975191, grad/param norm = 1.9058e-01, time/batch = 17.8985s	
11449/26050 (epoch 21.975), train_loss = 1.04994718, grad/param norm = 1.8227e-01, time/batch = 14.3928s	
11450/26050 (epoch 21.977), train_loss = 1.04114070, grad/param norm = 1.6971e-01, time/batch = 18.8891s	
11451/26050 (epoch 21.979), train_loss = 0.85332446, grad/param norm = 1.6948e-01, time/batch = 16.9189s	
11452/26050 (epoch 21.981), train_loss = 1.15540512, grad/param norm = 1.7858e-01, time/batch = 15.7171s	
11453/26050 (epoch 21.983), train_loss = 1.09625986, grad/param norm = 1.9460e-01, time/batch = 18.7341s	
11454/26050 (epoch 21.985), train_loss = 1.06534215, grad/param norm = 1.8749e-01, time/batch = 17.0738s	
11455/26050 (epoch 21.987), train_loss = 1.12473593, grad/param norm = 1.8080e-01, time/batch = 18.1504s	
11456/26050 (epoch 21.988), train_loss = 1.09454641, grad/param norm = 1.9266e-01, time/batch = 18.3249s	
11457/26050 (epoch 21.990), train_loss = 0.91060071, grad/param norm = 1.5607e-01, time/batch = 16.8163s	
11458/26050 (epoch 21.992), train_loss = 1.17540343, grad/param norm = 1.9021e-01, time/batch = 18.0545s	
11459/26050 (epoch 21.994), train_loss = 0.98545771, grad/param norm = 1.8225e-01, time/batch = 17.7361s	
11460/26050 (epoch 21.996), train_loss = 0.96426591, grad/param norm = 1.7943e-01, time/batch = 18.6515s	
11461/26050 (epoch 21.998), train_loss = 1.02438629, grad/param norm = 1.8057e-01, time/batch = 17.8858s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
11462/26050 (epoch 22.000), train_loss = 0.97834458, grad/param norm = 1.9822e-01, time/batch = 17.6543s	
11463/26050 (epoch 22.002), train_loss = 1.08734840, grad/param norm = 2.0014e-01, time/batch = 14.3724s	
11464/26050 (epoch 22.004), train_loss = 0.93632318, grad/param norm = 1.8381e-01, time/batch = 18.1346s	
11465/26050 (epoch 22.006), train_loss = 0.96355399, grad/param norm = 1.9367e-01, time/batch = 18.1451s	
11466/26050 (epoch 22.008), train_loss = 0.96054295, grad/param norm = 1.9387e-01, time/batch = 16.8062s	
11467/26050 (epoch 22.010), train_loss = 0.94783320, grad/param norm = 1.9131e-01, time/batch = 18.4750s	
11468/26050 (epoch 22.012), train_loss = 1.02916341, grad/param norm = 1.8670e-01, time/batch = 18.3003s	
11469/26050 (epoch 22.013), train_loss = 1.32580297, grad/param norm = 2.2975e-01, time/batch = 16.5580s	
11470/26050 (epoch 22.015), train_loss = 0.97636654, grad/param norm = 1.6781e-01, time/batch = 17.9805s	
11471/26050 (epoch 22.017), train_loss = 1.01928146, grad/param norm = 1.7547e-01, time/batch = 17.6461s	
11472/26050 (epoch 22.019), train_loss = 0.88376512, grad/param norm = 1.6575e-01, time/batch = 17.9005s	
11473/26050 (epoch 22.021), train_loss = 1.07762958, grad/param norm = 1.7945e-01, time/batch = 18.6416s	
11474/26050 (epoch 22.023), train_loss = 0.84481682, grad/param norm = 1.7900e-01, time/batch = 17.2294s	
11475/26050 (epoch 22.025), train_loss = 1.02013953, grad/param norm = 1.7451e-01, time/batch = 16.5119s	
11476/26050 (epoch 22.027), train_loss = 0.82622741, grad/param norm = 1.7969e-01, time/batch = 18.7496s	
11477/26050 (epoch 22.029), train_loss = 1.03936158, grad/param norm = 1.7497e-01, time/batch = 18.6540s	
11478/26050 (epoch 22.031), train_loss = 1.14333417, grad/param norm = 2.1044e-01, time/batch = 15.9015s	
11479/26050 (epoch 22.033), train_loss = 1.04231821, grad/param norm = 1.8515e-01, time/batch = 17.6363s	
11480/26050 (epoch 22.035), train_loss = 1.04219636, grad/param norm = 1.6770e-01, time/batch = 16.5523s	
11481/26050 (epoch 22.036), train_loss = 0.90381361, grad/param norm = 1.8109e-01, time/batch = 16.9048s	
11482/26050 (epoch 22.038), train_loss = 0.83972905, grad/param norm = 1.6103e-01, time/batch = 18.4719s	
11483/26050 (epoch 22.040), train_loss = 0.99744547, grad/param norm = 1.8192e-01, time/batch = 18.1420s	
11484/26050 (epoch 22.042), train_loss = 0.86714728, grad/param norm = 2.0138e-01, time/batch = 18.3113s	
11485/26050 (epoch 22.044), train_loss = 1.08229420, grad/param norm = 1.6634e-01, time/batch = 15.1374s	
11486/26050 (epoch 22.046), train_loss = 0.82780136, grad/param norm = 1.6989e-01, time/batch = 14.7247s	
11487/26050 (epoch 22.048), train_loss = 1.01707019, grad/param norm = 1.7406e-01, time/batch = 18.6543s	
11488/26050 (epoch 22.050), train_loss = 0.95222773, grad/param norm = 1.7578e-01, time/batch = 17.4815s	
11489/26050 (epoch 22.052), train_loss = 0.93871861, grad/param norm = 1.8046e-01, time/batch = 18.2264s	
11490/26050 (epoch 22.054), train_loss = 0.85386970, grad/param norm = 1.6505e-01, time/batch = 18.6479s	
11491/26050 (epoch 22.056), train_loss = 0.82277565, grad/param norm = 1.5729e-01, time/batch = 17.3170s	
11492/26050 (epoch 22.058), train_loss = 0.96336505, grad/param norm = 1.6199e-01, time/batch = 16.0479s	
11493/26050 (epoch 22.060), train_loss = 1.07934620, grad/param norm = 1.8582e-01, time/batch = 18.3207s	
11494/26050 (epoch 22.061), train_loss = 0.92386638, grad/param norm = 1.7405e-01, time/batch = 16.4795s	
11495/26050 (epoch 22.063), train_loss = 1.04333517, grad/param norm = 1.7836e-01, time/batch = 16.3906s	
11496/26050 (epoch 22.065), train_loss = 0.82034545, grad/param norm = 1.4984e-01, time/batch = 17.8883s	
11497/26050 (epoch 22.067), train_loss = 1.00172435, grad/param norm = 1.8077e-01, time/batch = 19.0581s	
11498/26050 (epoch 22.069), train_loss = 1.05760192, grad/param norm = 1.8915e-01, time/batch = 17.4077s	
11499/26050 (epoch 22.071), train_loss = 1.08085189, grad/param norm = 1.9102e-01, time/batch = 18.5548s	
11500/26050 (epoch 22.073), train_loss = 1.18896902, grad/param norm = 2.0131e-01, time/batch = 16.6304s	
11501/26050 (epoch 22.075), train_loss = 0.94106551, grad/param norm = 1.7435e-01, time/batch = 18.8920s	
11502/26050 (epoch 22.077), train_loss = 0.94635316, grad/param norm = 1.9259e-01, time/batch = 17.8072s	
11503/26050 (epoch 22.079), train_loss = 1.02941706, grad/param norm = 1.8191e-01, time/batch = 17.6691s	
11504/26050 (epoch 22.081), train_loss = 0.96205138, grad/param norm = 1.6877e-01, time/batch = 17.0684s	
11505/26050 (epoch 22.083), train_loss = 1.11904864, grad/param norm = 1.8892e-01, time/batch = 17.1335s	
11506/26050 (epoch 22.084), train_loss = 1.03252189, grad/param norm = 2.0620e-01, time/batch = 18.8151s	
11507/26050 (epoch 22.086), train_loss = 1.18962386, grad/param norm = 2.2235e-01, time/batch = 17.6506s	
11508/26050 (epoch 22.088), train_loss = 0.95448657, grad/param norm = 1.8987e-01, time/batch = 17.2154s	
11509/26050 (epoch 22.090), train_loss = 1.02934122, grad/param norm = 1.9982e-01, time/batch = 16.8776s	
11510/26050 (epoch 22.092), train_loss = 1.06893391, grad/param norm = 1.7681e-01, time/batch = 14.9759s	
11511/26050 (epoch 22.094), train_loss = 0.94530813, grad/param norm = 1.8808e-01, time/batch = 15.9613s	
11512/26050 (epoch 22.096), train_loss = 1.00337682, grad/param norm = 1.7152e-01, time/batch = 17.5657s	
11513/26050 (epoch 22.098), train_loss = 0.95820817, grad/param norm = 1.9545e-01, time/batch = 17.9123s	
11514/26050 (epoch 22.100), train_loss = 0.90106527, grad/param norm = 1.7630e-01, time/batch = 17.6574s	
11515/26050 (epoch 22.102), train_loss = 1.05911978, grad/param norm = 1.9367e-01, time/batch = 18.0640s	
11516/26050 (epoch 22.104), train_loss = 0.99234025, grad/param norm = 1.8871e-01, time/batch = 18.9793s	
11517/26050 (epoch 22.106), train_loss = 1.01020617, grad/param norm = 2.0167e-01, time/batch = 18.2343s	
11518/26050 (epoch 22.107), train_loss = 0.80932227, grad/param norm = 1.6543e-01, time/batch = 17.6514s	
11519/26050 (epoch 22.109), train_loss = 0.93057571, grad/param norm = 1.9568e-01, time/batch = 17.5695s	
11520/26050 (epoch 22.111), train_loss = 1.17624349, grad/param norm = 2.1552e-01, time/batch = 16.2341s	
11521/26050 (epoch 22.113), train_loss = 0.94964710, grad/param norm = 1.7982e-01, time/batch = 15.8881s	
11522/26050 (epoch 22.115), train_loss = 1.10963597, grad/param norm = 1.8382e-01, time/batch = 17.3983s	
11523/26050 (epoch 22.117), train_loss = 1.02690660, grad/param norm = 1.8140e-01, time/batch = 18.5663s	
11524/26050 (epoch 22.119), train_loss = 0.84514444, grad/param norm = 1.6149e-01, time/batch = 18.4081s	
11525/26050 (epoch 22.121), train_loss = 1.02357664, grad/param norm = 1.7129e-01, time/batch = 18.2364s	
11526/26050 (epoch 22.123), train_loss = 0.91338473, grad/param norm = 1.7852e-01, time/batch = 30.3274s	
11527/26050 (epoch 22.125), train_loss = 0.86697374, grad/param norm = 1.6797e-01, time/batch = 24.6067s	
11528/26050 (epoch 22.127), train_loss = 0.81433077, grad/param norm = 1.8908e-01, time/batch = 16.8134s	
11529/26050 (epoch 22.129), train_loss = 0.85962554, grad/param norm = 1.6997e-01, time/batch = 18.6373s	
11530/26050 (epoch 22.131), train_loss = 0.97949309, grad/param norm = 1.9200e-01, time/batch = 18.0765s	
11531/26050 (epoch 22.132), train_loss = 0.97861682, grad/param norm = 1.6932e-01, time/batch = 15.9649s	
11532/26050 (epoch 22.134), train_loss = 1.02004578, grad/param norm = 2.0605e-01, time/batch = 17.9870s	
11533/26050 (epoch 22.136), train_loss = 1.00437422, grad/param norm = 1.8501e-01, time/batch = 15.4788s	
11534/26050 (epoch 22.138), train_loss = 0.75755904, grad/param norm = 1.6046e-01, time/batch = 18.8900s	
11535/26050 (epoch 22.140), train_loss = 0.83565802, grad/param norm = 1.7655e-01, time/batch = 18.5429s	
11536/26050 (epoch 22.142), train_loss = 0.87071733, grad/param norm = 1.6969e-01, time/batch = 17.8955s	
11537/26050 (epoch 22.144), train_loss = 0.80199013, grad/param norm = 1.7614e-01, time/batch = 18.1612s	
11538/26050 (epoch 22.146), train_loss = 0.75130171, grad/param norm = 1.6249e-01, time/batch = 15.9871s	
11539/26050 (epoch 22.148), train_loss = 0.78555779, grad/param norm = 1.5212e-01, time/batch = 17.3319s	
11540/26050 (epoch 22.150), train_loss = 0.95773697, grad/param norm = 1.8376e-01, time/batch = 18.4002s	
11541/26050 (epoch 22.152), train_loss = 1.18413430, grad/param norm = 2.4635e-01, time/batch = 15.6154s	
11542/26050 (epoch 22.154), train_loss = 0.78583768, grad/param norm = 1.8180e-01, time/batch = 18.4664s	
11543/26050 (epoch 22.155), train_loss = 0.83147559, grad/param norm = 1.7095e-01, time/batch = 18.4067s	
11544/26050 (epoch 22.157), train_loss = 0.94786898, grad/param norm = 2.1431e-01, time/batch = 18.4804s	
11545/26050 (epoch 22.159), train_loss = 0.99769328, grad/param norm = 1.9184e-01, time/batch = 17.0608s	
11546/26050 (epoch 22.161), train_loss = 1.02676739, grad/param norm = 1.9498e-01, time/batch = 18.4723s	
11547/26050 (epoch 22.163), train_loss = 0.81819228, grad/param norm = 1.6926e-01, time/batch = 16.8118s	
11548/26050 (epoch 22.165), train_loss = 0.75868116, grad/param norm = 1.6166e-01, time/batch = 17.8890s	
11549/26050 (epoch 22.167), train_loss = 1.09254217, grad/param norm = 1.8772e-01, time/batch = 18.1550s	
11550/26050 (epoch 22.169), train_loss = 1.00815740, grad/param norm = 1.8770e-01, time/batch = 18.1582s	
11551/26050 (epoch 22.171), train_loss = 0.83130707, grad/param norm = 1.7005e-01, time/batch = 17.8107s	
11552/26050 (epoch 22.173), train_loss = 0.93548128, grad/param norm = 2.0252e-01, time/batch = 16.2936s	
11553/26050 (epoch 22.175), train_loss = 0.95135418, grad/param norm = 1.6395e-01, time/batch = 18.7357s	
11554/26050 (epoch 22.177), train_loss = 1.08917433, grad/param norm = 1.8547e-01, time/batch = 17.8960s	
11555/26050 (epoch 22.179), train_loss = 0.74066343, grad/param norm = 1.5316e-01, time/batch = 17.4777s	
11556/26050 (epoch 22.180), train_loss = 1.18523009, grad/param norm = 1.9271e-01, time/batch = 17.8241s	
11557/26050 (epoch 22.182), train_loss = 1.20360632, grad/param norm = 1.8911e-01, time/batch = 17.1647s	
11558/26050 (epoch 22.184), train_loss = 1.01224426, grad/param norm = 1.7989e-01, time/batch = 16.9556s	
11559/26050 (epoch 22.186), train_loss = 0.82687186, grad/param norm = 1.6581e-01, time/batch = 18.0696s	
11560/26050 (epoch 22.188), train_loss = 0.98027387, grad/param norm = 1.7780e-01, time/batch = 18.4128s	
11561/26050 (epoch 22.190), train_loss = 1.02694430, grad/param norm = 1.7329e-01, time/batch = 16.6417s	
11562/26050 (epoch 22.192), train_loss = 1.04221612, grad/param norm = 1.6268e-01, time/batch = 17.8836s	
11563/26050 (epoch 22.194), train_loss = 1.03358574, grad/param norm = 1.8000e-01, time/batch = 15.1443s	
11564/26050 (epoch 22.196), train_loss = 1.08216172, grad/param norm = 1.8337e-01, time/batch = 16.8097s	
11565/26050 (epoch 22.198), train_loss = 0.90433047, grad/param norm = 1.6527e-01, time/batch = 17.4696s	
11566/26050 (epoch 22.200), train_loss = 0.91033098, grad/param norm = 1.8806e-01, time/batch = 18.1497s	
11567/26050 (epoch 22.202), train_loss = 1.00582036, grad/param norm = 1.8446e-01, time/batch = 17.9893s	
11568/26050 (epoch 22.203), train_loss = 1.10559795, grad/param norm = 1.9797e-01, time/batch = 16.7146s	
11569/26050 (epoch 22.205), train_loss = 0.93365276, grad/param norm = 1.7574e-01, time/batch = 18.1619s	
11570/26050 (epoch 22.207), train_loss = 0.92816163, grad/param norm = 1.8240e-01, time/batch = 18.3077s	
11571/26050 (epoch 22.209), train_loss = 1.03448210, grad/param norm = 1.6773e-01, time/batch = 18.5607s	
11572/26050 (epoch 22.211), train_loss = 0.82461160, grad/param norm = 1.6104e-01, time/batch = 17.4875s	
11573/26050 (epoch 22.213), train_loss = 1.02963690, grad/param norm = 1.8319e-01, time/batch = 17.1713s	
11574/26050 (epoch 22.215), train_loss = 0.97891124, grad/param norm = 2.0026e-01, time/batch = 18.6564s	
11575/26050 (epoch 22.217), train_loss = 0.94143332, grad/param norm = 1.6452e-01, time/batch = 17.2980s	
11576/26050 (epoch 22.219), train_loss = 0.96960199, grad/param norm = 1.9756e-01, time/batch = 18.0499s	
11577/26050 (epoch 22.221), train_loss = 0.89082542, grad/param norm = 1.8809e-01, time/batch = 15.4706s	
11578/26050 (epoch 22.223), train_loss = 1.03090849, grad/param norm = 1.9238e-01, time/batch = 19.2298s	
11579/26050 (epoch 22.225), train_loss = 0.88478316, grad/param norm = 1.8709e-01, time/batch = 17.5484s	
11580/26050 (epoch 22.226), train_loss = 1.03947083, grad/param norm = 2.1747e-01, time/batch = 15.4531s	
11581/26050 (epoch 22.228), train_loss = 1.11868545, grad/param norm = 1.9105e-01, time/batch = 18.3094s	
11582/26050 (epoch 22.230), train_loss = 1.01650117, grad/param norm = 1.7162e-01, time/batch = 17.9821s	
11583/26050 (epoch 22.232), train_loss = 1.08452489, grad/param norm = 2.1416e-01, time/batch = 16.9792s	
11584/26050 (epoch 22.234), train_loss = 0.87399873, grad/param norm = 1.6678e-01, time/batch = 16.1412s	
11585/26050 (epoch 22.236), train_loss = 1.08667002, grad/param norm = 1.9116e-01, time/batch = 18.9009s	
11586/26050 (epoch 22.238), train_loss = 0.87061517, grad/param norm = 1.8766e-01, time/batch = 18.1446s	
11587/26050 (epoch 22.240), train_loss = 0.98412396, grad/param norm = 1.8656e-01, time/batch = 18.8088s	
11588/26050 (epoch 22.242), train_loss = 0.98227784, grad/param norm = 1.7467e-01, time/batch = 17.6312s	
11589/26050 (epoch 22.244), train_loss = 0.99020375, grad/param norm = 2.0393e-01, time/batch = 16.8093s	
11590/26050 (epoch 22.246), train_loss = 0.91215397, grad/param norm = 1.7890e-01, time/batch = 17.8987s	
11591/26050 (epoch 22.248), train_loss = 1.00433016, grad/param norm = 1.9141e-01, time/batch = 18.7345s	
11592/26050 (epoch 22.250), train_loss = 0.99074413, grad/param norm = 2.1311e-01, time/batch = 14.7193s	
11593/26050 (epoch 22.251), train_loss = 0.94565973, grad/param norm = 1.7122e-01, time/batch = 17.7234s	
11594/26050 (epoch 22.253), train_loss = 0.87400065, grad/param norm = 1.7325e-01, time/batch = 18.3882s	
11595/26050 (epoch 22.255), train_loss = 1.15518409, grad/param norm = 1.8864e-01, time/batch = 16.5337s	
11596/26050 (epoch 22.257), train_loss = 0.97394800, grad/param norm = 1.8914e-01, time/batch = 16.5491s	
11597/26050 (epoch 22.259), train_loss = 1.11807001, grad/param norm = 1.9364e-01, time/batch = 15.1495s	
11598/26050 (epoch 22.261), train_loss = 0.88957208, grad/param norm = 1.8919e-01, time/batch = 17.4768s	
11599/26050 (epoch 22.263), train_loss = 1.05113847, grad/param norm = 1.9247e-01, time/batch = 18.0728s	
11600/26050 (epoch 22.265), train_loss = 1.13231494, grad/param norm = 1.8847e-01, time/batch = 17.6631s	
11601/26050 (epoch 22.267), train_loss = 1.09143499, grad/param norm = 1.7081e-01, time/batch = 18.4731s	
11602/26050 (epoch 22.269), train_loss = 1.11544140, grad/param norm = 1.8610e-01, time/batch = 15.8105s	
11603/26050 (epoch 22.271), train_loss = 1.03762819, grad/param norm = 1.7807e-01, time/batch = 17.0625s	
11604/26050 (epoch 22.273), train_loss = 0.94951288, grad/param norm = 1.9698e-01, time/batch = 18.3853s	
11605/26050 (epoch 22.274), train_loss = 0.97032899, grad/param norm = 1.6869e-01, time/batch = 18.9748s	
11606/26050 (epoch 22.276), train_loss = 0.94316507, grad/param norm = 1.9201e-01, time/batch = 17.4901s	
11607/26050 (epoch 22.278), train_loss = 1.12104940, grad/param norm = 1.8661e-01, time/batch = 18.4003s	
11608/26050 (epoch 22.280), train_loss = 0.98454593, grad/param norm = 1.7667e-01, time/batch = 17.9082s	
11609/26050 (epoch 22.282), train_loss = 1.03166045, grad/param norm = 1.9019e-01, time/batch = 17.7300s	
11610/26050 (epoch 22.284), train_loss = 0.96466030, grad/param norm = 1.9538e-01, time/batch = 15.9702s	
11611/26050 (epoch 22.286), train_loss = 1.01262921, grad/param norm = 2.0437e-01, time/batch = 17.0398s	
11612/26050 (epoch 22.288), train_loss = 0.84807058, grad/param norm = 1.5084e-01, time/batch = 18.4650s	
11613/26050 (epoch 22.290), train_loss = 1.00116411, grad/param norm = 1.9215e-01, time/batch = 15.9789s	
11614/26050 (epoch 22.292), train_loss = 0.91077071, grad/param norm = 1.6413e-01, time/batch = 17.5530s	
11615/26050 (epoch 22.294), train_loss = 1.00090385, grad/param norm = 1.9758e-01, time/batch = 18.4046s	
11616/26050 (epoch 22.296), train_loss = 1.10145555, grad/param norm = 1.9139e-01, time/batch = 17.4700s	
11617/26050 (epoch 22.298), train_loss = 1.01673515, grad/param norm = 1.8828e-01, time/batch = 18.2487s	
11618/26050 (epoch 22.299), train_loss = 0.82423189, grad/param norm = 1.6297e-01, time/batch = 18.3102s	
11619/26050 (epoch 22.301), train_loss = 0.87164453, grad/param norm = 1.7466e-01, time/batch = 18.2111s	
11620/26050 (epoch 22.303), train_loss = 0.99725535, grad/param norm = 1.9384e-01, time/batch = 17.7384s	
11621/26050 (epoch 22.305), train_loss = 0.81581962, grad/param norm = 1.6778e-01, time/batch = 16.3320s	
11622/26050 (epoch 22.307), train_loss = 0.92159950, grad/param norm = 1.8710e-01, time/batch = 17.8951s	
11623/26050 (epoch 22.309), train_loss = 0.97683001, grad/param norm = 1.9370e-01, time/batch = 15.8234s	
11624/26050 (epoch 22.311), train_loss = 1.09039115, grad/param norm = 2.5364e-01, time/batch = 17.5424s	
11625/26050 (epoch 22.313), train_loss = 1.00081454, grad/param norm = 2.1891e-01, time/batch = 18.5717s	
11626/26050 (epoch 22.315), train_loss = 1.08782681, grad/param norm = 1.9516e-01, time/batch = 17.8991s	
11627/26050 (epoch 22.317), train_loss = 1.00836254, grad/param norm = 1.8587e-01, time/batch = 17.2339s	
11628/26050 (epoch 22.319), train_loss = 0.90676714, grad/param norm = 1.7239e-01, time/batch = 18.9015s	
11629/26050 (epoch 22.321), train_loss = 0.95708833, grad/param norm = 1.7119e-01, time/batch = 18.5695s	
11630/26050 (epoch 22.322), train_loss = 1.01310748, grad/param norm = 1.6415e-01, time/batch = 17.2411s	
11631/26050 (epoch 22.324), train_loss = 0.81840596, grad/param norm = 1.6790e-01, time/batch = 18.2311s	
11632/26050 (epoch 22.326), train_loss = 1.12715267, grad/param norm = 1.8981e-01, time/batch = 14.9927s	
11633/26050 (epoch 22.328), train_loss = 1.02332064, grad/param norm = 1.7506e-01, time/batch = 18.0676s	
11634/26050 (epoch 22.330), train_loss = 0.87477615, grad/param norm = 1.8059e-01, time/batch = 18.4729s	
11635/26050 (epoch 22.332), train_loss = 1.04846858, grad/param norm = 1.9226e-01, time/batch = 17.4210s	
11636/26050 (epoch 22.334), train_loss = 0.93901209, grad/param norm = 2.0149e-01, time/batch = 18.3162s	
11637/26050 (epoch 22.336), train_loss = 0.95496106, grad/param norm = 1.8178e-01, time/batch = 18.1407s	
11638/26050 (epoch 22.338), train_loss = 0.87241304, grad/param norm = 1.6319e-01, time/batch = 17.5570s	
11639/26050 (epoch 22.340), train_loss = 1.07021888, grad/param norm = 2.0069e-01, time/batch = 17.8947s	
11640/26050 (epoch 22.342), train_loss = 1.09765737, grad/param norm = 1.9535e-01, time/batch = 17.4772s	
11641/26050 (epoch 22.344), train_loss = 0.93096422, grad/param norm = 2.0097e-01, time/batch = 15.1472s	
11642/26050 (epoch 22.345), train_loss = 0.98679805, grad/param norm = 2.2161e-01, time/batch = 19.1543s	
11643/26050 (epoch 22.347), train_loss = 1.12060117, grad/param norm = 2.0013e-01, time/batch = 15.0770s	
11644/26050 (epoch 22.349), train_loss = 1.04272040, grad/param norm = 1.8818e-01, time/batch = 17.9715s	
11645/26050 (epoch 22.351), train_loss = 1.04857057, grad/param norm = 1.9697e-01, time/batch = 18.0609s	
11646/26050 (epoch 22.353), train_loss = 0.99853131, grad/param norm = 1.8966e-01, time/batch = 17.9912s	
11647/26050 (epoch 22.355), train_loss = 1.04701404, grad/param norm = 2.0763e-01, time/batch = 16.4038s	
11648/26050 (epoch 22.357), train_loss = 0.93255952, grad/param norm = 1.7475e-01, time/batch = 17.1657s	
11649/26050 (epoch 22.359), train_loss = 1.10146444, grad/param norm = 1.9086e-01, time/batch = 15.3156s	
11650/26050 (epoch 22.361), train_loss = 0.91569600, grad/param norm = 1.6443e-01, time/batch = 17.9771s	
11651/26050 (epoch 22.363), train_loss = 1.06018871, grad/param norm = 1.7653e-01, time/batch = 17.8938s	
11652/26050 (epoch 22.365), train_loss = 0.95248253, grad/param norm = 1.6292e-01, time/batch = 18.2417s	
11653/26050 (epoch 22.367), train_loss = 1.04952982, grad/param norm = 1.7921e-01, time/batch = 17.4945s	
11654/26050 (epoch 22.369), train_loss = 0.93824711, grad/param norm = 1.6925e-01, time/batch = 14.2698s	
11655/26050 (epoch 22.370), train_loss = 0.88331931, grad/param norm = 1.6301e-01, time/batch = 18.4085s	
11656/26050 (epoch 22.372), train_loss = 1.03847234, grad/param norm = 1.9738e-01, time/batch = 18.1552s	
11657/26050 (epoch 22.374), train_loss = 1.12818103, grad/param norm = 1.9385e-01, time/batch = 18.0694s	
11658/26050 (epoch 22.376), train_loss = 1.20913061, grad/param norm = 2.0344e-01, time/batch = 17.9037s	
11659/26050 (epoch 22.378), train_loss = 0.94233578, grad/param norm = 1.6652e-01, time/batch = 18.0738s	
11660/26050 (epoch 22.380), train_loss = 1.18887807, grad/param norm = 2.2463e-01, time/batch = 18.3136s	
11661/26050 (epoch 22.382), train_loss = 1.27908408, grad/param norm = 2.2802e-01, time/batch = 18.2107s	
11662/26050 (epoch 22.384), train_loss = 1.00490249, grad/param norm = 2.0061e-01, time/batch = 18.6428s	
11663/26050 (epoch 22.386), train_loss = 1.06146356, grad/param norm = 2.1784e-01, time/batch = 18.8044s	
11664/26050 (epoch 22.388), train_loss = 1.01789045, grad/param norm = 1.8274e-01, time/batch = 16.7536s	
11665/26050 (epoch 22.390), train_loss = 0.93754377, grad/param norm = 1.7600e-01, time/batch = 18.3190s	
11666/26050 (epoch 22.392), train_loss = 0.88028311, grad/param norm = 1.6028e-01, time/batch = 16.9072s	
11667/26050 (epoch 22.393), train_loss = 1.05272699, grad/param norm = 1.9844e-01, time/batch = 16.2059s	
11668/26050 (epoch 22.395), train_loss = 1.05118814, grad/param norm = 1.8190e-01, time/batch = 17.0465s	
11669/26050 (epoch 22.397), train_loss = 1.06906088, grad/param norm = 2.1444e-01, time/batch = 17.7394s	
11670/26050 (epoch 22.399), train_loss = 0.93449829, grad/param norm = 1.9662e-01, time/batch = 16.5690s	
11671/26050 (epoch 22.401), train_loss = 1.01224145, grad/param norm = 1.8785e-01, time/batch = 17.8174s	
11672/26050 (epoch 22.403), train_loss = 1.01334352, grad/param norm = 1.9487e-01, time/batch = 16.2412s	
11673/26050 (epoch 22.405), train_loss = 1.01334578, grad/param norm = 1.7784e-01, time/batch = 18.0533s	
11674/26050 (epoch 22.407), train_loss = 1.15789909, grad/param norm = 1.9628e-01, time/batch = 17.1354s	
11675/26050 (epoch 22.409), train_loss = 1.15017640, grad/param norm = 2.0539e-01, time/batch = 18.4906s	
11676/26050 (epoch 22.411), train_loss = 1.06740758, grad/param norm = 1.9410e-01, time/batch = 18.5011s	
11677/26050 (epoch 22.413), train_loss = 1.15795626, grad/param norm = 1.7933e-01, time/batch = 17.5737s	
11678/26050 (epoch 22.415), train_loss = 1.12136937, grad/param norm = 2.4904e-01, time/batch = 18.2117s	
11679/26050 (epoch 22.417), train_loss = 1.23708319, grad/param norm = 2.1791e-01, time/batch = 17.9177s	
11680/26050 (epoch 22.418), train_loss = 1.12415627, grad/param norm = 2.2103e-01, time/batch = 17.1442s	
11681/26050 (epoch 22.420), train_loss = 0.86684563, grad/param norm = 1.7048e-01, time/batch = 14.5333s	
11682/26050 (epoch 22.422), train_loss = 0.86363115, grad/param norm = 1.8272e-01, time/batch = 15.4155s	
11683/26050 (epoch 22.424), train_loss = 1.15458880, grad/param norm = 2.0690e-01, time/batch = 18.6417s	
11684/26050 (epoch 22.426), train_loss = 1.12368317, grad/param norm = 1.9328e-01, time/batch = 18.3062s	
11685/26050 (epoch 22.428), train_loss = 0.94576843, grad/param norm = 1.6150e-01, time/batch = 17.4657s	
11686/26050 (epoch 22.430), train_loss = 1.12905520, grad/param norm = 1.8685e-01, time/batch = 16.7153s	
11687/26050 (epoch 22.432), train_loss = 0.99076500, grad/param norm = 1.9305e-01, time/batch = 18.8143s	
11688/26050 (epoch 22.434), train_loss = 0.99553532, grad/param norm = 2.0331e-01, time/batch = 17.5561s	
11689/26050 (epoch 22.436), train_loss = 1.13691203, grad/param norm = 2.0167e-01, time/batch = 18.0840s	
11690/26050 (epoch 22.438), train_loss = 1.07120200, grad/param norm = 1.8639e-01, time/batch = 16.5419s	
11691/26050 (epoch 22.440), train_loss = 1.03705291, grad/param norm = 2.1663e-01, time/batch = 17.7284s	
11692/26050 (epoch 22.441), train_loss = 1.01254476, grad/param norm = 1.9065e-01, time/batch = 17.4922s	
11693/26050 (epoch 22.443), train_loss = 0.86598471, grad/param norm = 1.5467e-01, time/batch = 18.7265s	
11694/26050 (epoch 22.445), train_loss = 0.93710319, grad/param norm = 1.7349e-01, time/batch = 17.4126s	
11695/26050 (epoch 22.447), train_loss = 1.14807771, grad/param norm = 2.1912e-01, time/batch = 16.5516s	
11696/26050 (epoch 22.449), train_loss = 0.93053237, grad/param norm = 1.7439e-01, time/batch = 16.8555s	
11697/26050 (epoch 22.451), train_loss = 1.16355783, grad/param norm = 2.0078e-01, time/batch = 18.0612s	
11698/26050 (epoch 22.453), train_loss = 0.94115799, grad/param norm = 1.6204e-01, time/batch = 18.0668s	
11699/26050 (epoch 22.455), train_loss = 1.02823442, grad/param norm = 1.8612e-01, time/batch = 17.7402s	
11700/26050 (epoch 22.457), train_loss = 0.99061470, grad/param norm = 1.7286e-01, time/batch = 18.1595s	
11701/26050 (epoch 22.459), train_loss = 1.10940074, grad/param norm = 1.8467e-01, time/batch = 18.1522s	
11702/26050 (epoch 22.461), train_loss = 1.11307510, grad/param norm = 2.3235e-01, time/batch = 15.1478s	
11703/26050 (epoch 22.463), train_loss = 0.98512787, grad/param norm = 1.7760e-01, time/batch = 17.8082s	
11704/26050 (epoch 22.464), train_loss = 1.05069419, grad/param norm = 1.7599e-01, time/batch = 18.4929s	
11705/26050 (epoch 22.466), train_loss = 1.06918380, grad/param norm = 1.9880e-01, time/batch = 17.2300s	
11706/26050 (epoch 22.468), train_loss = 1.11744409, grad/param norm = 1.6879e-01, time/batch = 16.5577s	
11707/26050 (epoch 22.470), train_loss = 1.15307865, grad/param norm = 2.2120e-01, time/batch = 17.4180s	
11708/26050 (epoch 22.472), train_loss = 1.14589369, grad/param norm = 2.1175e-01, time/batch = 17.9931s	
11709/26050 (epoch 22.474), train_loss = 1.13931710, grad/param norm = 1.7215e-01, time/batch = 17.9117s	
11710/26050 (epoch 22.476), train_loss = 1.14292583, grad/param norm = 1.9063e-01, time/batch = 17.7518s	
11711/26050 (epoch 22.478), train_loss = 1.00907125, grad/param norm = 1.8389e-01, time/batch = 18.1536s	
11712/26050 (epoch 22.480), train_loss = 1.01658995, grad/param norm = 1.7732e-01, time/batch = 17.1501s	
11713/26050 (epoch 22.482), train_loss = 0.97112514, grad/param norm = 1.7627e-01, time/batch = 18.0934s	
11714/26050 (epoch 22.484), train_loss = 0.95691819, grad/param norm = 1.7796e-01, time/batch = 17.1451s	
11715/26050 (epoch 22.486), train_loss = 1.13542727, grad/param norm = 1.8039e-01, time/batch = 16.0470s	
11716/26050 (epoch 22.488), train_loss = 1.25476705, grad/param norm = 2.1444e-01, time/batch = 18.2334s	
11717/26050 (epoch 22.489), train_loss = 1.17389553, grad/param norm = 2.1139e-01, time/batch = 17.8950s	
11718/26050 (epoch 22.491), train_loss = 0.95059893, grad/param norm = 1.8747e-01, time/batch = 18.3054s	
11719/26050 (epoch 22.493), train_loss = 1.03099704, grad/param norm = 1.9592e-01, time/batch = 16.2270s	
11720/26050 (epoch 22.495), train_loss = 1.01233947, grad/param norm = 1.7641e-01, time/batch = 18.2904s	
11721/26050 (epoch 22.497), train_loss = 0.94075393, grad/param norm = 1.8411e-01, time/batch = 14.9693s	
11722/26050 (epoch 22.499), train_loss = 0.99063515, grad/param norm = 1.7943e-01, time/batch = 17.7330s	
11723/26050 (epoch 22.501), train_loss = 1.09092531, grad/param norm = 1.8810e-01, time/batch = 17.8185s	
11724/26050 (epoch 22.503), train_loss = 0.97445725, grad/param norm = 1.7882e-01, time/batch = 18.4869s	
11725/26050 (epoch 22.505), train_loss = 1.14171268, grad/param norm = 1.8688e-01, time/batch = 17.2329s	
11726/26050 (epoch 22.507), train_loss = 1.09364919, grad/param norm = 2.0998e-01, time/batch = 18.3218s	
11727/26050 (epoch 22.509), train_loss = 1.19712416, grad/param norm = 1.8634e-01, time/batch = 17.3816s	
11728/26050 (epoch 22.511), train_loss = 0.96870636, grad/param norm = 1.7348e-01, time/batch = 17.4874s	
11729/26050 (epoch 22.512), train_loss = 0.93818559, grad/param norm = 1.9416e-01, time/batch = 25.4374s	
11730/26050 (epoch 22.514), train_loss = 1.09123497, grad/param norm = 1.9946e-01, time/batch = 31.1464s	
11731/26050 (epoch 22.516), train_loss = 1.15637391, grad/param norm = 2.0101e-01, time/batch = 17.6080s	
11732/26050 (epoch 22.518), train_loss = 1.02975094, grad/param norm = 2.0193e-01, time/batch = 18.3076s	
11733/26050 (epoch 22.520), train_loss = 1.00348790, grad/param norm = 1.7443e-01, time/batch = 17.5415s	
11734/26050 (epoch 22.522), train_loss = 0.80099225, grad/param norm = 1.6505e-01, time/batch = 17.5638s	
11735/26050 (epoch 22.524), train_loss = 1.09851810, grad/param norm = 2.3914e-01, time/batch = 18.7952s	
11736/26050 (epoch 22.526), train_loss = 1.13340660, grad/param norm = 2.0350e-01, time/batch = 17.7443s	
11737/26050 (epoch 22.528), train_loss = 1.07604517, grad/param norm = 2.1011e-01, time/batch = 14.7973s	
11738/26050 (epoch 22.530), train_loss = 0.97475767, grad/param norm = 1.8244e-01, time/batch = 17.5622s	
11739/26050 (epoch 22.532), train_loss = 1.04030264, grad/param norm = 1.8492e-01, time/batch = 17.7198s	
11740/26050 (epoch 22.534), train_loss = 1.08517124, grad/param norm = 2.1415e-01, time/batch = 18.0606s	
11741/26050 (epoch 22.536), train_loss = 1.01960809, grad/param norm = 1.7585e-01, time/batch = 17.2326s	
11742/26050 (epoch 22.537), train_loss = 1.10153902, grad/param norm = 2.2862e-01, time/batch = 18.5529s	
11743/26050 (epoch 22.539), train_loss = 1.02073666, grad/param norm = 1.8994e-01, time/batch = 18.6480s	
11744/26050 (epoch 22.541), train_loss = 1.21917267, grad/param norm = 2.1486e-01, time/batch = 16.8998s	
11745/26050 (epoch 22.543), train_loss = 0.88372259, grad/param norm = 1.7903e-01, time/batch = 17.4841s	
11746/26050 (epoch 22.545), train_loss = 1.06300202, grad/param norm = 1.9052e-01, time/batch = 18.2307s	
11747/26050 (epoch 22.547), train_loss = 1.01751255, grad/param norm = 1.8296e-01, time/batch = 16.6312s	
11748/26050 (epoch 22.549), train_loss = 0.85696039, grad/param norm = 1.8249e-01, time/batch = 17.5464s	
11749/26050 (epoch 22.551), train_loss = 1.07978190, grad/param norm = 1.7822e-01, time/batch = 16.3908s	
11750/26050 (epoch 22.553), train_loss = 0.95244238, grad/param norm = 1.7857e-01, time/batch = 17.9696s	
11751/26050 (epoch 22.555), train_loss = 0.95600559, grad/param norm = 1.7772e-01, time/batch = 17.7408s	
11752/26050 (epoch 22.557), train_loss = 1.04758681, grad/param norm = 1.6583e-01, time/batch = 18.5609s	
11753/26050 (epoch 22.559), train_loss = 0.99776481, grad/param norm = 1.8303e-01, time/batch = 17.9066s	
11754/26050 (epoch 22.560), train_loss = 0.98753481, grad/param norm = 1.7942e-01, time/batch = 18.4713s	
11755/26050 (epoch 22.562), train_loss = 1.00167948, grad/param norm = 1.7796e-01, time/batch = 17.4733s	
11756/26050 (epoch 22.564), train_loss = 1.18079318, grad/param norm = 1.7934e-01, time/batch = 18.4940s	
11757/26050 (epoch 22.566), train_loss = 0.92227959, grad/param norm = 1.7417e-01, time/batch = 18.0846s	
11758/26050 (epoch 22.568), train_loss = 1.05793590, grad/param norm = 1.7756e-01, time/batch = 15.2162s	
11759/26050 (epoch 22.570), train_loss = 1.08805874, grad/param norm = 2.0457e-01, time/batch = 18.4778s	
11760/26050 (epoch 22.572), train_loss = 0.98888470, grad/param norm = 1.9304e-01, time/batch = 18.5537s	
11761/26050 (epoch 22.574), train_loss = 1.05769674, grad/param norm = 2.1038e-01, time/batch = 17.3152s	
11762/26050 (epoch 22.576), train_loss = 1.05199776, grad/param norm = 1.9739e-01, time/batch = 14.8034s	
11763/26050 (epoch 22.578), train_loss = 0.97651929, grad/param norm = 1.8464e-01, time/batch = 18.5698s	
11764/26050 (epoch 22.580), train_loss = 0.94585315, grad/param norm = 1.8536e-01, time/batch = 18.7494s	
11765/26050 (epoch 22.582), train_loss = 1.04417033, grad/param norm = 1.8705e-01, time/batch = 15.9609s	
11766/26050 (epoch 22.583), train_loss = 1.12476135, grad/param norm = 1.8527e-01, time/batch = 17.9749s	
11767/26050 (epoch 22.585), train_loss = 0.89359818, grad/param norm = 1.9653e-01, time/batch = 17.8304s	
11768/26050 (epoch 22.587), train_loss = 1.08373858, grad/param norm = 2.0675e-01, time/batch = 18.2394s	
11769/26050 (epoch 22.589), train_loss = 1.16947547, grad/param norm = 2.0408e-01, time/batch = 18.4049s	
11770/26050 (epoch 22.591), train_loss = 0.99633802, grad/param norm = 1.7978e-01, time/batch = 17.3283s	
11771/26050 (epoch 22.593), train_loss = 0.88950842, grad/param norm = 1.7916e-01, time/batch = 18.4022s	
11772/26050 (epoch 22.595), train_loss = 1.07508989, grad/param norm = 2.0257e-01, time/batch = 17.2956s	
11773/26050 (epoch 22.597), train_loss = 1.05721783, grad/param norm = 1.9169e-01, time/batch = 17.7106s	
11774/26050 (epoch 22.599), train_loss = 1.04488274, grad/param norm = 1.9050e-01, time/batch = 17.8084s	
11775/26050 (epoch 22.601), train_loss = 1.20428616, grad/param norm = 1.9569e-01, time/batch = 17.1358s	
11776/26050 (epoch 22.603), train_loss = 1.04601749, grad/param norm = 1.9239e-01, time/batch = 18.6472s	
11777/26050 (epoch 22.605), train_loss = 0.96411670, grad/param norm = 1.7421e-01, time/batch = 18.6637s	
11778/26050 (epoch 22.607), train_loss = 1.13473482, grad/param norm = 2.0204e-01, time/batch = 15.6999s	
11779/26050 (epoch 22.608), train_loss = 0.89325102, grad/param norm = 1.6873e-01, time/batch = 14.9070s	
11780/26050 (epoch 22.610), train_loss = 1.00795217, grad/param norm = 1.8633e-01, time/batch = 18.4738s	
11781/26050 (epoch 22.612), train_loss = 1.00224564, grad/param norm = 1.8449e-01, time/batch = 18.0042s	
11782/26050 (epoch 22.614), train_loss = 1.03380361, grad/param norm = 1.7694e-01, time/batch = 17.2301s	
11783/26050 (epoch 22.616), train_loss = 1.15962394, grad/param norm = 2.1480e-01, time/batch = 17.9902s	
11784/26050 (epoch 22.618), train_loss = 0.96810788, grad/param norm = 1.8654e-01, time/batch = 18.2496s	
11785/26050 (epoch 22.620), train_loss = 1.07286157, grad/param norm = 1.9978e-01, time/batch = 17.0491s	
11786/26050 (epoch 22.622), train_loss = 0.90593622, grad/param norm = 1.8773e-01, time/batch = 18.4005s	
11787/26050 (epoch 22.624), train_loss = 0.87842051, grad/param norm = 1.7589e-01, time/batch = 15.3854s	
11788/26050 (epoch 22.626), train_loss = 1.08716390, grad/param norm = 1.8975e-01, time/batch = 18.8742s	
11789/26050 (epoch 22.628), train_loss = 0.95430418, grad/param norm = 1.8324e-01, time/batch = 14.5487s	
11790/26050 (epoch 22.630), train_loss = 1.15185974, grad/param norm = 1.9307e-01, time/batch = 17.7060s	
11791/26050 (epoch 22.631), train_loss = 1.18431253, grad/param norm = 2.0572e-01, time/batch = 18.8025s	
11792/26050 (epoch 22.633), train_loss = 0.90978254, grad/param norm = 1.6787e-01, time/batch = 17.0717s	
11793/26050 (epoch 22.635), train_loss = 0.93561794, grad/param norm = 1.5748e-01, time/batch = 18.0721s	
11794/26050 (epoch 22.637), train_loss = 0.91567858, grad/param norm = 1.8440e-01, time/batch = 17.3196s	
11795/26050 (epoch 22.639), train_loss = 1.11452436, grad/param norm = 1.8171e-01, time/batch = 16.3768s	
11796/26050 (epoch 22.641), train_loss = 0.98069762, grad/param norm = 1.7674e-01, time/batch = 17.0526s	
11797/26050 (epoch 22.643), train_loss = 0.92278585, grad/param norm = 1.5997e-01, time/batch = 17.9852s	
11798/26050 (epoch 22.645), train_loss = 1.00029508, grad/param norm = 1.8273e-01, time/batch = 18.2253s	
11799/26050 (epoch 22.647), train_loss = 0.96516390, grad/param norm = 1.9749e-01, time/batch = 17.4005s	
11800/26050 (epoch 22.649), train_loss = 1.02310275, grad/param norm = 1.9175e-01, time/batch = 18.6476s	
11801/26050 (epoch 22.651), train_loss = 0.96548469, grad/param norm = 1.8494e-01, time/batch = 17.8982s	
11802/26050 (epoch 22.653), train_loss = 1.01020204, grad/param norm = 1.7811e-01, time/batch = 16.7990s	
11803/26050 (epoch 22.655), train_loss = 0.93682704, grad/param norm = 1.7503e-01, time/batch = 18.3142s	
11804/26050 (epoch 22.656), train_loss = 0.87114046, grad/param norm = 1.6898e-01, time/batch = 18.1451s	
11805/26050 (epoch 22.658), train_loss = 1.20352433, grad/param norm = 2.0085e-01, time/batch = 18.5771s	
11806/26050 (epoch 22.660), train_loss = 0.88943315, grad/param norm = 1.8068e-01, time/batch = 15.5550s	
11807/26050 (epoch 22.662), train_loss = 0.97883330, grad/param norm = 1.8909e-01, time/batch = 18.0496s	
11808/26050 (epoch 22.664), train_loss = 0.98995161, grad/param norm = 1.7937e-01, time/batch = 18.5708s	
11809/26050 (epoch 22.666), train_loss = 0.97078319, grad/param norm = 1.9033e-01, time/batch = 17.8187s	
11810/26050 (epoch 22.668), train_loss = 0.83832222, grad/param norm = 2.4938e-01, time/batch = 19.2986s	
11811/26050 (epoch 22.670), train_loss = 1.14158456, grad/param norm = 2.3777e-01, time/batch = 17.6418s	
11812/26050 (epoch 22.672), train_loss = 1.01438286, grad/param norm = 1.9264e-01, time/batch = 16.3142s	
11813/26050 (epoch 22.674), train_loss = 0.93486632, grad/param norm = 1.9755e-01, time/batch = 6.1760s	
11814/26050 (epoch 22.676), train_loss = 1.07294479, grad/param norm = 1.9229e-01, time/batch = 0.6646s	
11815/26050 (epoch 22.678), train_loss = 1.14796340, grad/param norm = 2.0491e-01, time/batch = 0.6528s	
11816/26050 (epoch 22.679), train_loss = 1.19742900, grad/param norm = 2.2272e-01, time/batch = 0.6539s	
11817/26050 (epoch 22.681), train_loss = 1.02096488, grad/param norm = 1.8624e-01, time/batch = 0.6577s	
11818/26050 (epoch 22.683), train_loss = 0.92548411, grad/param norm = 2.1422e-01, time/batch = 0.6537s	
11819/26050 (epoch 22.685), train_loss = 0.98262297, grad/param norm = 1.9825e-01, time/batch = 0.6546s	
11820/26050 (epoch 22.687), train_loss = 0.87390477, grad/param norm = 1.8097e-01, time/batch = 0.6501s	
11821/26050 (epoch 22.689), train_loss = 0.98765152, grad/param norm = 1.9546e-01, time/batch = 0.9348s	
11822/26050 (epoch 22.691), train_loss = 0.81474117, grad/param norm = 1.6366e-01, time/batch = 0.9487s	
11823/26050 (epoch 22.693), train_loss = 0.91775300, grad/param norm = 1.7962e-01, time/batch = 0.9332s	
11824/26050 (epoch 22.695), train_loss = 1.00926359, grad/param norm = 1.7484e-01, time/batch = 0.9317s	
11825/26050 (epoch 22.697), train_loss = 0.92133290, grad/param norm = 1.7334e-01, time/batch = 0.9535s	
11826/26050 (epoch 22.699), train_loss = 1.06781293, grad/param norm = 2.0984e-01, time/batch = 1.6250s	
11827/26050 (epoch 22.701), train_loss = 0.91850616, grad/param norm = 1.6613e-01, time/batch = 1.7608s	
11828/26050 (epoch 22.702), train_loss = 1.11967070, grad/param norm = 1.9196e-01, time/batch = 1.7664s	
11829/26050 (epoch 22.704), train_loss = 1.10339234, grad/param norm = 1.8178e-01, time/batch = 17.4762s	
11830/26050 (epoch 22.706), train_loss = 0.96957969, grad/param norm = 1.8962e-01, time/batch = 16.8881s	
11831/26050 (epoch 22.708), train_loss = 1.08451063, grad/param norm = 2.0105e-01, time/batch = 17.5581s	
11832/26050 (epoch 22.710), train_loss = 1.06815077, grad/param norm = 2.0367e-01, time/batch = 18.3981s	
11833/26050 (epoch 22.712), train_loss = 1.05052952, grad/param norm = 1.9717e-01, time/batch = 18.3137s	
11834/26050 (epoch 22.714), train_loss = 0.86996393, grad/param norm = 1.7645e-01, time/batch = 15.1383s	
11835/26050 (epoch 22.716), train_loss = 1.25278935, grad/param norm = 2.1622e-01, time/batch = 18.5617s	
11836/26050 (epoch 22.718), train_loss = 1.09382599, grad/param norm = 1.9062e-01, time/batch = 17.9148s	
11837/26050 (epoch 22.720), train_loss = 0.99885766, grad/param norm = 1.9335e-01, time/batch = 17.5551s	
11838/26050 (epoch 22.722), train_loss = 0.87505409, grad/param norm = 1.7404e-01, time/batch = 17.7234s	
11839/26050 (epoch 22.724), train_loss = 0.91720321, grad/param norm = 1.7493e-01, time/batch = 15.9743s	
11840/26050 (epoch 22.726), train_loss = 1.07882669, grad/param norm = 1.9836e-01, time/batch = 17.9675s	
11841/26050 (epoch 22.727), train_loss = 1.07388754, grad/param norm = 2.0709e-01, time/batch = 17.2347s	
11842/26050 (epoch 22.729), train_loss = 1.06034441, grad/param norm = 1.7842e-01, time/batch = 18.3116s	
11843/26050 (epoch 22.731), train_loss = 1.03873311, grad/param norm = 1.7696e-01, time/batch = 18.4049s	
11844/26050 (epoch 22.733), train_loss = 0.97760316, grad/param norm = 2.1327e-01, time/batch = 16.8852s	
11845/26050 (epoch 22.735), train_loss = 1.21642795, grad/param norm = 2.2628e-01, time/batch = 18.2213s	
11846/26050 (epoch 22.737), train_loss = 0.94382107, grad/param norm = 1.8376e-01, time/batch = 18.1482s	
11847/26050 (epoch 22.739), train_loss = 1.03808182, grad/param norm = 1.8280e-01, time/batch = 18.4070s	
11848/26050 (epoch 22.741), train_loss = 0.94027476, grad/param norm = 1.8869e-01, time/batch = 18.0650s	
11849/26050 (epoch 22.743), train_loss = 1.04102098, grad/param norm = 2.0898e-01, time/batch = 17.3025s	
11850/26050 (epoch 22.745), train_loss = 0.88994262, grad/param norm = 1.8267e-01, time/batch = 18.0730s	
11851/26050 (epoch 22.747), train_loss = 0.91733263, grad/param norm = 1.7089e-01, time/batch = 14.8095s	
11852/26050 (epoch 22.749), train_loss = 1.12939850, grad/param norm = 1.9792e-01, time/batch = 18.6507s	
11853/26050 (epoch 22.750), train_loss = 1.01946902, grad/param norm = 1.7866e-01, time/batch = 17.9811s	
11854/26050 (epoch 22.752), train_loss = 0.96939078, grad/param norm = 2.1096e-01, time/batch = 17.6336s	
11855/26050 (epoch 22.754), train_loss = 1.01846385, grad/param norm = 1.8958e-01, time/batch = 16.2985s	
11856/26050 (epoch 22.756), train_loss = 0.99673842, grad/param norm = 1.9684e-01, time/batch = 18.2177s	
11857/26050 (epoch 22.758), train_loss = 0.98921779, grad/param norm = 1.8958e-01, time/batch = 17.9774s	
11858/26050 (epoch 22.760), train_loss = 1.19195668, grad/param norm = 2.0694e-01, time/batch = 17.2940s	
11859/26050 (epoch 22.762), train_loss = 0.96489739, grad/param norm = 1.7741e-01, time/batch = 18.9000s	
11860/26050 (epoch 22.764), train_loss = 1.02414125, grad/param norm = 2.1431e-01, time/batch = 18.0636s	
11861/26050 (epoch 22.766), train_loss = 1.07393730, grad/param norm = 2.2243e-01, time/batch = 17.8066s	
11862/26050 (epoch 22.768), train_loss = 0.91492441, grad/param norm = 1.7077e-01, time/batch = 16.1342s	
11863/26050 (epoch 22.770), train_loss = 0.99152649, grad/param norm = 1.9233e-01, time/batch = 17.4718s	
11864/26050 (epoch 22.772), train_loss = 1.00408722, grad/param norm = 1.7466e-01, time/batch = 15.1545s	
11865/26050 (epoch 22.774), train_loss = 0.86995049, grad/param norm = 1.8378e-01, time/batch = 17.3084s	
11866/26050 (epoch 22.775), train_loss = 0.73683586, grad/param norm = 1.6354e-01, time/batch = 17.6419s	
11867/26050 (epoch 22.777), train_loss = 0.95902680, grad/param norm = 1.8927e-01, time/batch = 17.8093s	
11868/26050 (epoch 22.779), train_loss = 0.97086764, grad/param norm = 1.8432e-01, time/batch = 17.4021s	
11869/26050 (epoch 22.781), train_loss = 0.89451674, grad/param norm = 1.7444e-01, time/batch = 18.8264s	
11870/26050 (epoch 22.783), train_loss = 0.88659876, grad/param norm = 1.6968e-01, time/batch = 15.4200s	
11871/26050 (epoch 22.785), train_loss = 1.01268853, grad/param norm = 1.9493e-01, time/batch = 17.9941s	
11872/26050 (epoch 22.787), train_loss = 0.91867959, grad/param norm = 1.7083e-01, time/batch = 17.9821s	
11873/26050 (epoch 22.789), train_loss = 0.94473481, grad/param norm = 1.9198e-01, time/batch = 18.5538s	
11874/26050 (epoch 22.791), train_loss = 0.93809580, grad/param norm = 1.8466e-01, time/batch = 16.9752s	
11875/26050 (epoch 22.793), train_loss = 0.99447805, grad/param norm = 2.0257e-01, time/batch = 17.3227s	
11876/26050 (epoch 22.795), train_loss = 0.81720624, grad/param norm = 1.4894e-01, time/batch = 15.3127s	
11877/26050 (epoch 22.797), train_loss = 0.92396635, grad/param norm = 1.7894e-01, time/batch = 16.8918s	
11878/26050 (epoch 22.798), train_loss = 0.87212028, grad/param norm = 1.8931e-01, time/batch = 15.9777s	
11879/26050 (epoch 22.800), train_loss = 0.87265336, grad/param norm = 1.6609e-01, time/batch = 17.4051s	
11880/26050 (epoch 22.802), train_loss = 0.94729843, grad/param norm = 1.8565e-01, time/batch = 18.7329s	
11881/26050 (epoch 22.804), train_loss = 0.99672862, grad/param norm = 1.9607e-01, time/batch = 18.8159s	
11882/26050 (epoch 22.806), train_loss = 1.08815175, grad/param norm = 1.9200e-01, time/batch = 17.3964s	
11883/26050 (epoch 22.808), train_loss = 0.99295788, grad/param norm = 2.0187e-01, time/batch = 18.2206s	
11884/26050 (epoch 22.810), train_loss = 0.93993881, grad/param norm = 1.7714e-01, time/batch = 15.2220s	
11885/26050 (epoch 22.812), train_loss = 0.87360224, grad/param norm = 1.7913e-01, time/batch = 17.7336s	
11886/26050 (epoch 22.814), train_loss = 0.89642909, grad/param norm = 2.0297e-01, time/batch = 16.9594s	
11887/26050 (epoch 22.816), train_loss = 1.08056664, grad/param norm = 2.0418e-01, time/batch = 18.3086s	
11888/26050 (epoch 22.818), train_loss = 1.10426978, grad/param norm = 2.4156e-01, time/batch = 18.4735s	
11889/26050 (epoch 22.820), train_loss = 1.00386607, grad/param norm = 1.7725e-01, time/batch = 18.4741s	
11890/26050 (epoch 22.821), train_loss = 1.12455346, grad/param norm = 2.1218e-01, time/batch = 18.0568s	
11891/26050 (epoch 22.823), train_loss = 1.15813518, grad/param norm = 2.0263e-01, time/batch = 18.4731s	
11892/26050 (epoch 22.825), train_loss = 0.98393361, grad/param norm = 1.8418e-01, time/batch = 15.4774s	
11893/26050 (epoch 22.827), train_loss = 1.03104121, grad/param norm = 2.0875e-01, time/batch = 17.9607s	
11894/26050 (epoch 22.829), train_loss = 1.09178401, grad/param norm = 2.0238e-01, time/batch = 17.8191s	
11895/26050 (epoch 22.831), train_loss = 1.13994396, grad/param norm = 1.9620e-01, time/batch = 17.2279s	
11896/26050 (epoch 22.833), train_loss = 1.19236063, grad/param norm = 2.0005e-01, time/batch = 17.8067s	
11897/26050 (epoch 22.835), train_loss = 1.18322505, grad/param norm = 2.0381e-01, time/batch = 18.9074s	
11898/26050 (epoch 22.837), train_loss = 1.00985843, grad/param norm = 1.8059e-01, time/batch = 18.4927s	
11899/26050 (epoch 22.839), train_loss = 1.02444657, grad/param norm = 2.2196e-01, time/batch = 16.6495s	
11900/26050 (epoch 22.841), train_loss = 1.14331009, grad/param norm = 1.9529e-01, time/batch = 17.0489s	
11901/26050 (epoch 22.843), train_loss = 0.98229586, grad/param norm = 1.6518e-01, time/batch = 14.6879s	
11902/26050 (epoch 22.845), train_loss = 0.95432157, grad/param norm = 1.6759e-01, time/batch = 18.3057s	
11903/26050 (epoch 22.846), train_loss = 1.08927779, grad/param norm = 1.9601e-01, time/batch = 18.6516s	
11904/26050 (epoch 22.848), train_loss = 0.98246153, grad/param norm = 1.7827e-01, time/batch = 17.8262s	
11905/26050 (epoch 22.850), train_loss = 0.90185058, grad/param norm = 1.6669e-01, time/batch = 17.4879s	
11906/26050 (epoch 22.852), train_loss = 1.00944485, grad/param norm = 1.7776e-01, time/batch = 17.3871s	
11907/26050 (epoch 22.854), train_loss = 1.00047907, grad/param norm = 1.9119e-01, time/batch = 18.8276s	
11908/26050 (epoch 22.856), train_loss = 0.97295315, grad/param norm = 1.9939e-01, time/batch = 18.7408s	
11909/26050 (epoch 22.858), train_loss = 0.93105921, grad/param norm = 1.8419e-01, time/batch = 15.0559s	
11910/26050 (epoch 22.860), train_loss = 1.03756991, grad/param norm = 1.9404e-01, time/batch = 16.4940s	
11911/26050 (epoch 22.862), train_loss = 1.06987374, grad/param norm = 1.9298e-01, time/batch = 18.3996s	
11912/26050 (epoch 22.864), train_loss = 1.04084665, grad/param norm = 2.2650e-01, time/batch = 17.2967s	
11913/26050 (epoch 22.866), train_loss = 0.96359444, grad/param norm = 1.8048e-01, time/batch = 14.6406s	
11914/26050 (epoch 22.868), train_loss = 1.04535927, grad/param norm = 1.9002e-01, time/batch = 17.3991s	
11915/26050 (epoch 22.869), train_loss = 0.90694615, grad/param norm = 1.7503e-01, time/batch = 18.5737s	
11916/26050 (epoch 22.871), train_loss = 0.84171865, grad/param norm = 1.6761e-01, time/batch = 17.2348s	
11917/26050 (epoch 22.873), train_loss = 1.05353121, grad/param norm = 2.1199e-01, time/batch = 17.2205s	
11918/26050 (epoch 22.875), train_loss = 1.00455508, grad/param norm = 1.9187e-01, time/batch = 16.6075s	
11919/26050 (epoch 22.877), train_loss = 0.89819692, grad/param norm = 1.6801e-01, time/batch = 18.0758s	
11920/26050 (epoch 22.879), train_loss = 1.02517611, grad/param norm = 1.6951e-01, time/batch = 17.9133s	
11921/26050 (epoch 22.881), train_loss = 1.12048182, grad/param norm = 2.3355e-01, time/batch = 18.1585s	
11922/26050 (epoch 22.883), train_loss = 1.05664485, grad/param norm = 1.9019e-01, time/batch = 17.5732s	
11923/26050 (epoch 22.885), train_loss = 0.76734365, grad/param norm = 1.6752e-01, time/batch = 17.2860s	
11924/26050 (epoch 22.887), train_loss = 1.05062942, grad/param norm = 1.8472e-01, time/batch = 17.8936s	
11925/26050 (epoch 22.889), train_loss = 0.95750864, grad/param norm = 1.7850e-01, time/batch = 18.6639s	
11926/26050 (epoch 22.891), train_loss = 0.83666304, grad/param norm = 1.6714e-01, time/batch = 17.7438s	
11927/26050 (epoch 22.893), train_loss = 0.87758541, grad/param norm = 1.7502e-01, time/batch = 18.3177s	
11928/26050 (epoch 22.894), train_loss = 0.94709537, grad/param norm = 1.6714e-01, time/batch = 18.9018s	
11929/26050 (epoch 22.896), train_loss = 1.09402058, grad/param norm = 2.0015e-01, time/batch = 16.5604s	
11930/26050 (epoch 22.898), train_loss = 0.94354746, grad/param norm = 1.9704e-01, time/batch = 15.8030s	
11931/26050 (epoch 22.900), train_loss = 1.02576743, grad/param norm = 1.7539e-01, time/batch = 14.7984s	
11932/26050 (epoch 22.902), train_loss = 0.98847612, grad/param norm = 1.8698e-01, time/batch = 17.3910s	
11933/26050 (epoch 22.904), train_loss = 0.99152839, grad/param norm = 1.8029e-01, time/batch = 17.4855s	
11934/26050 (epoch 22.906), train_loss = 0.97943386, grad/param norm = 2.0496e-01, time/batch = 18.2981s	
11935/26050 (epoch 22.908), train_loss = 1.00393652, grad/param norm = 1.7381e-01, time/batch = 18.3132s	
11936/26050 (epoch 22.910), train_loss = 0.96084314, grad/param norm = 1.6663e-01, time/batch = 17.5679s	
11937/26050 (epoch 22.912), train_loss = 1.19354542, grad/param norm = 2.0897e-01, time/batch = 18.0723s	
11938/26050 (epoch 22.914), train_loss = 1.35006130, grad/param norm = 2.2328e-01, time/batch = 18.5687s	
11939/26050 (epoch 22.916), train_loss = 1.10240217, grad/param norm = 2.1382e-01, time/batch = 16.0650s	
11940/26050 (epoch 22.917), train_loss = 1.01508880, grad/param norm = 2.0474e-01, time/batch = 16.4427s	
11941/26050 (epoch 22.919), train_loss = 1.07451289, grad/param norm = 1.9630e-01, time/batch = 17.4042s	
11942/26050 (epoch 22.921), train_loss = 0.95196268, grad/param norm = 2.1077e-01, time/batch = 18.5618s	
11943/26050 (epoch 22.923), train_loss = 1.01680309, grad/param norm = 1.8813e-01, time/batch = 17.7990s	
11944/26050 (epoch 22.925), train_loss = 1.00465219, grad/param norm = 1.7589e-01, time/batch = 18.6370s	
11945/26050 (epoch 22.927), train_loss = 0.88209312, grad/param norm = 1.4948e-01, time/batch = 18.3976s	
11946/26050 (epoch 22.929), train_loss = 0.86286815, grad/param norm = 1.6706e-01, time/batch = 15.0648s	
11947/26050 (epoch 22.931), train_loss = 1.18002662, grad/param norm = 2.4674e-01, time/batch = 31.1402s	
11948/26050 (epoch 22.933), train_loss = 0.95753583, grad/param norm = 1.8478e-01, time/batch = 25.2151s	
11949/26050 (epoch 22.935), train_loss = 0.99144486, grad/param norm = 1.9089e-01, time/batch = 16.2096s	
11950/26050 (epoch 22.937), train_loss = 1.09371016, grad/param norm = 1.8729e-01, time/batch = 18.5590s	
11951/26050 (epoch 22.939), train_loss = 0.92072638, grad/param norm = 1.6283e-01, time/batch = 18.0667s	
11952/26050 (epoch 22.940), train_loss = 0.96514095, grad/param norm = 1.6957e-01, time/batch = 17.3843s	
11953/26050 (epoch 22.942), train_loss = 0.99002916, grad/param norm = 1.8414e-01, time/batch = 17.8190s	
11954/26050 (epoch 22.944), train_loss = 0.96709459, grad/param norm = 2.7123e-01, time/batch = 15.5485s	
11955/26050 (epoch 22.946), train_loss = 1.14342353, grad/param norm = 2.0539e-01, time/batch = 18.4014s	
11956/26050 (epoch 22.948), train_loss = 0.89309427, grad/param norm = 1.8693e-01, time/batch = 17.4665s	
11957/26050 (epoch 22.950), train_loss = 0.97300546, grad/param norm = 1.9611e-01, time/batch = 18.4900s	
11958/26050 (epoch 22.952), train_loss = 1.08115142, grad/param norm = 1.9049e-01, time/batch = 16.8971s	
11959/26050 (epoch 22.954), train_loss = 1.09110239, grad/param norm = 1.8599e-01, time/batch = 17.9869s	
11960/26050 (epoch 22.956), train_loss = 0.99463942, grad/param norm = 1.9760e-01, time/batch = 17.9918s	
11961/26050 (epoch 22.958), train_loss = 0.94043457, grad/param norm = 1.8493e-01, time/batch = 18.5689s	
11962/26050 (epoch 22.960), train_loss = 1.03421571, grad/param norm = 2.0925e-01, time/batch = 17.0671s	
11963/26050 (epoch 22.962), train_loss = 0.96296324, grad/param norm = 1.7060e-01, time/batch = 14.9736s	
11964/26050 (epoch 22.964), train_loss = 1.00428865, grad/param norm = 1.8923e-01, time/batch = 14.8201s	
11965/26050 (epoch 22.965), train_loss = 0.92399997, grad/param norm = 2.1080e-01, time/batch = 18.2343s	
11966/26050 (epoch 22.967), train_loss = 1.31710539, grad/param norm = 1.9104e-01, time/batch = 17.2323s	
11967/26050 (epoch 22.969), train_loss = 1.02098516, grad/param norm = 1.8183e-01, time/batch = 18.0594s	
11968/26050 (epoch 22.971), train_loss = 0.95469008, grad/param norm = 1.6449e-01, time/batch = 17.1334s	
11969/26050 (epoch 22.973), train_loss = 1.00720543, grad/param norm = 1.9032e-01, time/batch = 15.3785s	
11970/26050 (epoch 22.975), train_loss = 1.04145314, grad/param norm = 1.8855e-01, time/batch = 18.6490s	
11971/26050 (epoch 22.977), train_loss = 1.01837253, grad/param norm = 1.6699e-01, time/batch = 16.4171s	
11972/26050 (epoch 22.979), train_loss = 0.83390597, grad/param norm = 1.6589e-01, time/batch = 18.5654s	
11973/26050 (epoch 22.981), train_loss = 1.13433933, grad/param norm = 1.8606e-01, time/batch = 17.6592s	
11974/26050 (epoch 22.983), train_loss = 1.08105351, grad/param norm = 2.0889e-01, time/batch = 16.8851s	
11975/26050 (epoch 22.985), train_loss = 1.06059317, grad/param norm = 1.9187e-01, time/batch = 18.6450s	
11976/26050 (epoch 22.987), train_loss = 1.11864464, grad/param norm = 1.8581e-01, time/batch = 17.1453s	
11977/26050 (epoch 22.988), train_loss = 1.07829008, grad/param norm = 1.8908e-01, time/batch = 18.8115s	
11978/26050 (epoch 22.990), train_loss = 0.89172911, grad/param norm = 1.5730e-01, time/batch = 17.8127s	
11979/26050 (epoch 22.992), train_loss = 1.16073271, grad/param norm = 1.8822e-01, time/batch = 17.8119s	
11980/26050 (epoch 22.994), train_loss = 0.96182209, grad/param norm = 1.9143e-01, time/batch = 18.3053s	
11981/26050 (epoch 22.996), train_loss = 0.94481486, grad/param norm = 1.8521e-01, time/batch = 18.5646s	
11982/26050 (epoch 22.998), train_loss = 1.01138800, grad/param norm = 1.7670e-01, time/batch = 18.0686s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
11983/26050 (epoch 23.000), train_loss = 0.97530846, grad/param norm = 2.1745e-01, time/batch = 14.3903s	
11984/26050 (epoch 23.002), train_loss = 1.06584306, grad/param norm = 2.0110e-01, time/batch = 15.3010s	
11985/26050 (epoch 23.004), train_loss = 0.91293457, grad/param norm = 1.8373e-01, time/batch = 18.7439s	
11986/26050 (epoch 23.006), train_loss = 0.95975533, grad/param norm = 2.0972e-01, time/batch = 17.8255s	
11987/26050 (epoch 23.008), train_loss = 0.95186302, grad/param norm = 2.0392e-01, time/batch = 18.2363s	
11988/26050 (epoch 23.010), train_loss = 0.94293342, grad/param norm = 1.8700e-01, time/batch = 18.5602s	
11989/26050 (epoch 23.012), train_loss = 1.01546608, grad/param norm = 1.8049e-01, time/batch = 17.5715s	
11990/26050 (epoch 23.013), train_loss = 1.28206472, grad/param norm = 2.1114e-01, time/batch = 17.4812s	
11991/26050 (epoch 23.015), train_loss = 0.96867687, grad/param norm = 1.6929e-01, time/batch = 16.8044s	
11992/26050 (epoch 23.017), train_loss = 1.00645722, grad/param norm = 1.7498e-01, time/batch = 18.9361s	
11993/26050 (epoch 23.019), train_loss = 0.87931559, grad/param norm = 1.7309e-01, time/batch = 16.9043s	
11994/26050 (epoch 23.021), train_loss = 1.07065883, grad/param norm = 1.9558e-01, time/batch = 18.4863s	
11995/26050 (epoch 23.023), train_loss = 0.83067921, grad/param norm = 1.7084e-01, time/batch = 18.4161s	
11996/26050 (epoch 23.025), train_loss = 1.00682992, grad/param norm = 1.7955e-01, time/batch = 15.3919s	
11997/26050 (epoch 23.027), train_loss = 0.81179778, grad/param norm = 1.8072e-01, time/batch = 17.8986s	
11998/26050 (epoch 23.029), train_loss = 1.01761987, grad/param norm = 1.6759e-01, time/batch = 17.7351s	
11999/26050 (epoch 23.031), train_loss = 1.12726690, grad/param norm = 2.0844e-01, time/batch = 17.8129s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch23.03_1.6794.t7	
12000/26050 (epoch 23.033), train_loss = 1.03011296, grad/param norm = 1.8792e-01, time/batch = 16.9066s	
12001/26050 (epoch 23.035), train_loss = 1.33231940, grad/param norm = 2.2849e-01, time/batch = 18.6429s	
12002/26050 (epoch 23.036), train_loss = 0.88577970, grad/param norm = 2.0047e-01, time/batch = 17.2497s	
12003/26050 (epoch 23.038), train_loss = 0.82059166, grad/param norm = 1.6613e-01, time/batch = 16.0219s	
12004/26050 (epoch 23.040), train_loss = 0.98534577, grad/param norm = 1.9060e-01, time/batch = 16.4869s	
12005/26050 (epoch 23.042), train_loss = 0.84299885, grad/param norm = 1.8111e-01, time/batch = 18.3127s	
12006/26050 (epoch 23.044), train_loss = 1.08722258, grad/param norm = 1.8597e-01, time/batch = 17.6467s	
12007/26050 (epoch 23.046), train_loss = 0.80933249, grad/param norm = 1.5528e-01, time/batch = 15.8889s	
12008/26050 (epoch 23.048), train_loss = 1.00187506, grad/param norm = 1.7437e-01, time/batch = 18.0613s	
12009/26050 (epoch 23.050), train_loss = 0.94219611, grad/param norm = 1.8087e-01, time/batch = 17.9088s	
12010/26050 (epoch 23.052), train_loss = 0.93603761, grad/param norm = 2.1027e-01, time/batch = 18.5714s	
12011/26050 (epoch 23.054), train_loss = 0.83753206, grad/param norm = 1.6980e-01, time/batch = 17.2330s	
12012/26050 (epoch 23.056), train_loss = 0.81770468, grad/param norm = 1.6197e-01, time/batch = 18.5534s	
12013/26050 (epoch 23.058), train_loss = 0.96430070, grad/param norm = 1.6750e-01, time/batch = 18.2956s	
12014/26050 (epoch 23.060), train_loss = 1.05764049, grad/param norm = 1.8103e-01, time/batch = 17.3959s	
12015/26050 (epoch 23.061), train_loss = 0.90449048, grad/param norm = 1.7310e-01, time/batch = 18.7938s	
12016/26050 (epoch 23.063), train_loss = 1.03036407, grad/param norm = 1.7733e-01, time/batch = 14.8567s	
12017/26050 (epoch 23.065), train_loss = 0.80080988, grad/param norm = 1.4878e-01, time/batch = 15.4598s	
12018/26050 (epoch 23.067), train_loss = 0.99961440, grad/param norm = 1.9086e-01, time/batch = 15.2146s	
12019/26050 (epoch 23.069), train_loss = 1.03803043, grad/param norm = 1.8969e-01, time/batch = 16.3223s	
12020/26050 (epoch 23.071), train_loss = 1.05769638, grad/param norm = 1.9703e-01, time/batch = 18.4783s	
12021/26050 (epoch 23.073), train_loss = 1.16544434, grad/param norm = 1.9283e-01, time/batch = 17.6550s	
12022/26050 (epoch 23.075), train_loss = 0.91523240, grad/param norm = 1.7297e-01, time/batch = 17.9937s	
12023/26050 (epoch 23.077), train_loss = 0.93783420, grad/param norm = 1.8612e-01, time/batch = 18.1590s	
12024/26050 (epoch 23.079), train_loss = 1.00778233, grad/param norm = 1.8279e-01, time/batch = 17.6599s	
12025/26050 (epoch 23.081), train_loss = 0.95539841, grad/param norm = 1.7774e-01, time/batch = 17.5231s	
12026/26050 (epoch 23.083), train_loss = 1.09461604, grad/param norm = 1.8070e-01, time/batch = 16.3904s	
12027/26050 (epoch 23.084), train_loss = 1.02537345, grad/param norm = 2.2081e-01, time/batch = 18.4095s	
12028/26050 (epoch 23.086), train_loss = 1.17159034, grad/param norm = 2.1428e-01, time/batch = 16.4093s	
12029/26050 (epoch 23.088), train_loss = 0.94090490, grad/param norm = 1.8894e-01, time/batch = 17.7314s	
12030/26050 (epoch 23.090), train_loss = 1.00678038, grad/param norm = 1.9013e-01, time/batch = 16.3854s	
12031/26050 (epoch 23.092), train_loss = 1.05020270, grad/param norm = 1.7655e-01, time/batch = 17.1664s	
12032/26050 (epoch 23.094), train_loss = 0.92172145, grad/param norm = 1.8626e-01, time/batch = 14.6439s	
12033/26050 (epoch 23.096), train_loss = 0.99255662, grad/param norm = 1.7059e-01, time/batch = 17.3216s	
12034/26050 (epoch 23.098), train_loss = 0.94228465, grad/param norm = 1.8706e-01, time/batch = 15.8176s	
12035/26050 (epoch 23.100), train_loss = 0.88919448, grad/param norm = 1.7434e-01, time/batch = 16.8197s	
12036/26050 (epoch 23.102), train_loss = 1.05050938, grad/param norm = 1.9922e-01, time/batch = 16.9060s	
12037/26050 (epoch 23.104), train_loss = 0.97715986, grad/param norm = 1.8059e-01, time/batch = 17.4886s	
12038/26050 (epoch 23.106), train_loss = 0.99413557, grad/param norm = 2.0287e-01, time/batch = 17.9038s	
12039/26050 (epoch 23.107), train_loss = 0.81279508, grad/param norm = 1.8561e-01, time/batch = 16.9088s	
12040/26050 (epoch 23.109), train_loss = 0.91773212, grad/param norm = 1.8954e-01, time/batch = 16.9891s	
12041/26050 (epoch 23.111), train_loss = 1.15481264, grad/param norm = 2.0081e-01, time/batch = 17.7457s	
12042/26050 (epoch 23.113), train_loss = 0.92899059, grad/param norm = 1.8311e-01, time/batch = 15.7329s	
12043/26050 (epoch 23.115), train_loss = 1.08199278, grad/param norm = 1.8539e-01, time/batch = 16.7418s	
12044/26050 (epoch 23.117), train_loss = 1.01666727, grad/param norm = 1.8469e-01, time/batch = 14.4795s	
12045/26050 (epoch 23.119), train_loss = 0.83267381, grad/param norm = 1.6456e-01, time/batch = 17.4798s	
12046/26050 (epoch 23.121), train_loss = 1.00282862, grad/param norm = 1.7432e-01, time/batch = 15.0472s	
12047/26050 (epoch 23.123), train_loss = 0.88359041, grad/param norm = 1.7070e-01, time/batch = 15.6423s	
12048/26050 (epoch 23.125), train_loss = 0.86254980, grad/param norm = 1.6513e-01, time/batch = 17.4162s	
12049/26050 (epoch 23.127), train_loss = 0.79771436, grad/param norm = 1.7974e-01, time/batch = 17.3254s	
12050/26050 (epoch 23.129), train_loss = 0.84118715, grad/param norm = 1.8418e-01, time/batch = 16.5637s	
12051/26050 (epoch 23.131), train_loss = 0.95038566, grad/param norm = 1.7386e-01, time/batch = 17.0747s	
12052/26050 (epoch 23.132), train_loss = 0.96878822, grad/param norm = 1.7540e-01, time/batch = 17.1583s	
12053/26050 (epoch 23.134), train_loss = 1.00446989, grad/param norm = 2.1422e-01, time/batch = 16.9117s	
12054/26050 (epoch 23.136), train_loss = 0.99048099, grad/param norm = 1.8346e-01, time/batch = 17.1693s	
12055/26050 (epoch 23.138), train_loss = 0.74527469, grad/param norm = 1.6343e-01, time/batch = 16.9804s	
12056/26050 (epoch 23.140), train_loss = 0.83845349, grad/param norm = 1.8313e-01, time/batch = 17.6632s	
12057/26050 (epoch 23.142), train_loss = 0.85443290, grad/param norm = 1.7106e-01, time/batch = 15.5509s	
12058/26050 (epoch 23.144), train_loss = 0.79149541, grad/param norm = 1.7003e-01, time/batch = 17.1449s	
12059/26050 (epoch 23.146), train_loss = 0.74388953, grad/param norm = 1.6714e-01, time/batch = 16.3964s	
12060/26050 (epoch 23.148), train_loss = 0.77898324, grad/param norm = 1.5209e-01, time/batch = 16.3083s	
12061/26050 (epoch 23.150), train_loss = 0.95391174, grad/param norm = 1.9981e-01, time/batch = 17.1463s	
12062/26050 (epoch 23.152), train_loss = 1.16393794, grad/param norm = 2.4712e-01, time/batch = 17.0686s	
12063/26050 (epoch 23.154), train_loss = 0.78140320, grad/param norm = 1.7630e-01, time/batch = 17.6637s	
12064/26050 (epoch 23.155), train_loss = 0.81695429, grad/param norm = 1.8097e-01, time/batch = 17.1467s	
12065/26050 (epoch 23.157), train_loss = 0.94444604, grad/param norm = 2.2175e-01, time/batch = 17.2358s	
12066/26050 (epoch 23.159), train_loss = 0.98166999, grad/param norm = 1.9306e-01, time/batch = 14.8032s	
12067/26050 (epoch 23.161), train_loss = 1.00967601, grad/param norm = 2.0267e-01, time/batch = 17.1676s	
12068/26050 (epoch 23.163), train_loss = 0.79839798, grad/param norm = 1.5834e-01, time/batch = 16.8345s	
12069/26050 (epoch 23.165), train_loss = 0.76241232, grad/param norm = 1.7565e-01, time/batch = 17.0744s	
12070/26050 (epoch 23.167), train_loss = 1.08123725, grad/param norm = 2.0279e-01, time/batch = 17.4147s	
12071/26050 (epoch 23.169), train_loss = 0.99143323, grad/param norm = 2.1419e-01, time/batch = 14.9642s	
12072/26050 (epoch 23.171), train_loss = 0.81472404, grad/param norm = 1.6509e-01, time/batch = 14.8194s	
12073/26050 (epoch 23.173), train_loss = 0.91780158, grad/param norm = 1.9484e-01, time/batch = 16.8172s	
12074/26050 (epoch 23.175), train_loss = 0.94926220, grad/param norm = 1.8652e-01, time/batch = 16.7184s	
12075/26050 (epoch 23.177), train_loss = 1.06736629, grad/param norm = 1.8302e-01, time/batch = 16.8046s	
12076/26050 (epoch 23.179), train_loss = 0.73028610, grad/param norm = 1.5470e-01, time/batch = 17.4170s	
12077/26050 (epoch 23.180), train_loss = 1.17482947, grad/param norm = 1.9736e-01, time/batch = 17.4940s	
12078/26050 (epoch 23.182), train_loss = 1.19911888, grad/param norm = 2.0181e-01, time/batch = 16.0640s	
12079/26050 (epoch 23.184), train_loss = 1.00522571, grad/param norm = 1.8692e-01, time/batch = 16.8936s	
12080/26050 (epoch 23.186), train_loss = 0.80338463, grad/param norm = 1.6157e-01, time/batch = 17.2404s	
12081/26050 (epoch 23.188), train_loss = 0.96885066, grad/param norm = 1.8266e-01, time/batch = 17.8088s	
12082/26050 (epoch 23.190), train_loss = 1.01798914, grad/param norm = 1.9457e-01, time/batch = 16.0734s	
12083/26050 (epoch 23.192), train_loss = 1.03015449, grad/param norm = 1.7330e-01, time/batch = 17.3282s	
12084/26050 (epoch 23.194), train_loss = 1.02132276, grad/param norm = 1.9353e-01, time/batch = 17.5044s	
12085/26050 (epoch 23.196), train_loss = 1.05878889, grad/param norm = 1.9269e-01, time/batch = 16.9156s	
12086/26050 (epoch 23.198), train_loss = 0.89330966, grad/param norm = 1.7040e-01, time/batch = 17.4974s	
12087/26050 (epoch 23.200), train_loss = 0.88645289, grad/param norm = 1.8695e-01, time/batch = 17.0891s	
12088/26050 (epoch 23.202), train_loss = 0.98885743, grad/param norm = 1.8383e-01, time/batch = 17.6483s	
12089/26050 (epoch 23.203), train_loss = 1.08748044, grad/param norm = 1.9728e-01, time/batch = 15.9373s	
12090/26050 (epoch 23.205), train_loss = 0.92214214, grad/param norm = 1.8627e-01, time/batch = 18.1347s	
12091/26050 (epoch 23.207), train_loss = 0.89989126, grad/param norm = 1.7577e-01, time/batch = 18.6562s	
12092/26050 (epoch 23.209), train_loss = 1.03675793, grad/param norm = 1.8848e-01, time/batch = 17.3137s	
12093/26050 (epoch 23.211), train_loss = 0.81467075, grad/param norm = 1.6497e-01, time/batch = 18.0580s	
12094/26050 (epoch 23.213), train_loss = 1.01704615, grad/param norm = 2.0225e-01, time/batch = 16.7428s	
12095/26050 (epoch 23.215), train_loss = 0.96605048, grad/param norm = 2.0402e-01, time/batch = 15.9543s	
12096/26050 (epoch 23.217), train_loss = 0.93588706, grad/param norm = 1.7666e-01, time/batch = 17.7304s	
12097/26050 (epoch 23.219), train_loss = 0.94829728, grad/param norm = 1.8886e-01, time/batch = 18.1432s	
12098/26050 (epoch 23.221), train_loss = 0.88341220, grad/param norm = 1.8551e-01, time/batch = 18.6507s	
12099/26050 (epoch 23.223), train_loss = 1.02077564, grad/param norm = 1.8933e-01, time/batch = 16.5499s	
12100/26050 (epoch 23.225), train_loss = 0.87759081, grad/param norm = 1.8716e-01, time/batch = 17.3921s	
12101/26050 (epoch 23.226), train_loss = 1.01764598, grad/param norm = 2.0883e-01, time/batch = 18.3267s	
12102/26050 (epoch 23.228), train_loss = 1.10834425, grad/param norm = 1.8884e-01, time/batch = 17.9032s	
12103/26050 (epoch 23.230), train_loss = 0.99119444, grad/param norm = 1.7709e-01, time/batch = 18.2289s	
12104/26050 (epoch 23.232), train_loss = 1.06815450, grad/param norm = 2.3083e-01, time/batch = 17.3259s	
12105/26050 (epoch 23.234), train_loss = 0.86580810, grad/param norm = 1.7204e-01, time/batch = 16.1473s	
12106/26050 (epoch 23.236), train_loss = 1.06521597, grad/param norm = 1.8711e-01, time/batch = 18.3111s	
12107/26050 (epoch 23.238), train_loss = 0.85059267, grad/param norm = 1.8113e-01, time/batch = 18.6338s	
12108/26050 (epoch 23.240), train_loss = 0.97154170, grad/param norm = 1.8554e-01, time/batch = 17.4659s	
12109/26050 (epoch 23.242), train_loss = 0.95359138, grad/param norm = 1.7133e-01, time/batch = 17.4694s	
12110/26050 (epoch 23.244), train_loss = 0.99093070, grad/param norm = 2.1135e-01, time/batch = 18.2350s	
12111/26050 (epoch 23.246), train_loss = 0.89116389, grad/param norm = 1.7730e-01, time/batch = 18.7340s	
12112/26050 (epoch 23.248), train_loss = 0.99646222, grad/param norm = 1.9215e-01, time/batch = 16.4693s	
12113/26050 (epoch 23.250), train_loss = 0.96889338, grad/param norm = 2.0343e-01, time/batch = 14.7676s	
12114/26050 (epoch 23.251), train_loss = 0.92840858, grad/param norm = 1.6695e-01, time/batch = 18.8089s	
12115/26050 (epoch 23.253), train_loss = 0.86384012, grad/param norm = 1.8339e-01, time/batch = 19.1551s	
12116/26050 (epoch 23.255), train_loss = 1.13545103, grad/param norm = 1.9723e-01, time/batch = 16.9790s	
12117/26050 (epoch 23.257), train_loss = 0.96918933, grad/param norm = 1.9174e-01, time/batch = 17.9850s	
12118/26050 (epoch 23.259), train_loss = 1.09279549, grad/param norm = 1.9763e-01, time/batch = 15.3806s	
12119/26050 (epoch 23.261), train_loss = 0.86939244, grad/param norm = 1.8190e-01, time/batch = 17.3113s	
12120/26050 (epoch 23.263), train_loss = 1.04478021, grad/param norm = 2.0504e-01, time/batch = 18.0616s	
12121/26050 (epoch 23.265), train_loss = 1.11831990, grad/param norm = 1.8725e-01, time/batch = 17.6436s	
12122/26050 (epoch 23.267), train_loss = 1.07874124, grad/param norm = 1.7110e-01, time/batch = 18.6518s	
12123/26050 (epoch 23.269), train_loss = 1.08716955, grad/param norm = 1.9259e-01, time/batch = 17.4907s	
12124/26050 (epoch 23.271), train_loss = 1.03547904, grad/param norm = 1.9432e-01, time/batch = 16.3854s	
12125/26050 (epoch 23.273), train_loss = 0.92065268, grad/param norm = 2.0018e-01, time/batch = 17.2321s	
12126/26050 (epoch 23.274), train_loss = 0.95497234, grad/param norm = 1.7512e-01, time/batch = 14.9829s	
12127/26050 (epoch 23.276), train_loss = 0.93603397, grad/param norm = 1.9114e-01, time/batch = 16.7445s	
12128/26050 (epoch 23.278), train_loss = 1.10396092, grad/param norm = 1.8654e-01, time/batch = 17.4679s	
12129/26050 (epoch 23.280), train_loss = 0.97146022, grad/param norm = 1.8037e-01, time/batch = 18.0678s	
12130/26050 (epoch 23.282), train_loss = 1.00998219, grad/param norm = 1.9388e-01, time/batch = 17.7175s	
12131/26050 (epoch 23.284), train_loss = 0.94543628, grad/param norm = 1.7781e-01, time/batch = 17.9910s	
12132/26050 (epoch 23.286), train_loss = 0.98446993, grad/param norm = 1.9330e-01, time/batch = 17.8163s	
12133/26050 (epoch 23.288), train_loss = 0.83558290, grad/param norm = 1.5912e-01, time/batch = 14.6003s	
12134/26050 (epoch 23.290), train_loss = 0.98632280, grad/param norm = 1.8298e-01, time/batch = 16.4679s	
12135/26050 (epoch 23.292), train_loss = 0.89720776, grad/param norm = 1.5683e-01, time/batch = 18.4827s	
12136/26050 (epoch 23.294), train_loss = 0.99223275, grad/param norm = 2.0007e-01, time/batch = 18.3105s	
12137/26050 (epoch 23.296), train_loss = 1.07774434, grad/param norm = 1.8256e-01, time/batch = 16.3724s	
12138/26050 (epoch 23.298), train_loss = 1.00100965, grad/param norm = 1.8466e-01, time/batch = 18.2241s	
12139/26050 (epoch 23.299), train_loss = 0.79910859, grad/param norm = 1.5394e-01, time/batch = 15.9096s	
12140/26050 (epoch 23.301), train_loss = 0.84369746, grad/param norm = 1.7458e-01, time/batch = 16.1241s	
12141/26050 (epoch 23.303), train_loss = 0.98271570, grad/param norm = 2.0553e-01, time/batch = 17.3066s	
12142/26050 (epoch 23.305), train_loss = 0.79450592, grad/param norm = 1.6904e-01, time/batch = 17.8993s	
12143/26050 (epoch 23.307), train_loss = 0.89513423, grad/param norm = 1.8588e-01, time/batch = 17.7359s	
12144/26050 (epoch 23.309), train_loss = 0.95501266, grad/param norm = 1.8205e-01, time/batch = 17.8849s	
12145/26050 (epoch 23.311), train_loss = 1.06211409, grad/param norm = 2.1291e-01, time/batch = 15.6394s	
12146/26050 (epoch 23.313), train_loss = 0.98248273, grad/param norm = 2.1818e-01, time/batch = 16.5711s	
12147/26050 (epoch 23.315), train_loss = 1.06844555, grad/param norm = 1.9127e-01, time/batch = 22.1481s	
12148/26050 (epoch 23.317), train_loss = 1.00496081, grad/param norm = 1.9123e-01, time/batch = 34.3526s	
12149/26050 (epoch 23.319), train_loss = 0.88955664, grad/param norm = 1.7130e-01, time/batch = 16.4085s	
12150/26050 (epoch 23.321), train_loss = 0.94971601, grad/param norm = 1.6297e-01, time/batch = 18.1446s	
12151/26050 (epoch 23.322), train_loss = 1.02304134, grad/param norm = 1.8919e-01, time/batch = 15.0440s	
12152/26050 (epoch 23.324), train_loss = 0.79732223, grad/param norm = 1.6930e-01, time/batch = 18.8002s	
12153/26050 (epoch 23.326), train_loss = 1.10953565, grad/param norm = 1.8683e-01, time/batch = 18.5564s	
12154/26050 (epoch 23.328), train_loss = 0.99278593, grad/param norm = 1.7386e-01, time/batch = 18.7380s	
12155/26050 (epoch 23.330), train_loss = 0.85332951, grad/param norm = 1.7732e-01, time/batch = 18.2450s	
12156/26050 (epoch 23.332), train_loss = 1.03213851, grad/param norm = 2.0512e-01, time/batch = 15.2315s	
12157/26050 (epoch 23.334), train_loss = 0.92692758, grad/param norm = 1.9837e-01, time/batch = 16.3730s	
12158/26050 (epoch 23.336), train_loss = 0.94033756, grad/param norm = 1.8937e-01, time/batch = 17.9940s	
12159/26050 (epoch 23.338), train_loss = 0.85686748, grad/param norm = 1.5968e-01, time/batch = 18.0763s	
12160/26050 (epoch 23.340), train_loss = 1.05638342, grad/param norm = 2.0138e-01, time/batch = 16.9935s	
12161/26050 (epoch 23.342), train_loss = 1.06593424, grad/param norm = 1.9047e-01, time/batch = 17.3992s	
12162/26050 (epoch 23.344), train_loss = 0.90499407, grad/param norm = 1.9149e-01, time/batch = 17.3159s	
12163/26050 (epoch 23.345), train_loss = 0.96302192, grad/param norm = 1.7820e-01, time/batch = 15.4440s	
12164/26050 (epoch 23.347), train_loss = 1.10782386, grad/param norm = 1.8701e-01, time/batch = 18.5388s	
12165/26050 (epoch 23.349), train_loss = 1.02462297, grad/param norm = 1.9299e-01, time/batch = 18.9916s	
12166/26050 (epoch 23.351), train_loss = 1.03122945, grad/param norm = 1.9100e-01, time/batch = 14.8869s	
12167/26050 (epoch 23.353), train_loss = 0.99370465, grad/param norm = 2.0316e-01, time/batch = 15.7878s	
12168/26050 (epoch 23.355), train_loss = 1.02991426, grad/param norm = 2.0429e-01, time/batch = 14.3690s	
12169/26050 (epoch 23.357), train_loss = 0.91204445, grad/param norm = 1.6922e-01, time/batch = 14.7930s	
12170/26050 (epoch 23.359), train_loss = 1.09436748, grad/param norm = 1.9350e-01, time/batch = 14.6068s	
12171/26050 (epoch 23.361), train_loss = 0.90256302, grad/param norm = 1.6643e-01, time/batch = 14.5348s	
12172/26050 (epoch 23.363), train_loss = 1.05093074, grad/param norm = 1.8638e-01, time/batch = 15.4458s	
12173/26050 (epoch 23.365), train_loss = 0.94319883, grad/param norm = 1.6109e-01, time/batch = 17.5738s	
12174/26050 (epoch 23.367), train_loss = 1.04063388, grad/param norm = 1.7559e-01, time/batch = 18.0789s	
12175/26050 (epoch 23.369), train_loss = 0.91148327, grad/param norm = 1.6335e-01, time/batch = 18.1730s	
12176/26050 (epoch 23.370), train_loss = 0.87527322, grad/param norm = 1.6506e-01, time/batch = 18.4030s	
12177/26050 (epoch 23.372), train_loss = 1.00390573, grad/param norm = 2.0257e-01, time/batch = 18.2305s	
12178/26050 (epoch 23.374), train_loss = 1.09890299, grad/param norm = 1.8481e-01, time/batch = 15.8084s	
12179/26050 (epoch 23.376), train_loss = 1.18413481, grad/param norm = 2.1001e-01, time/batch = 17.2473s	
12180/26050 (epoch 23.378), train_loss = 0.92634340, grad/param norm = 1.6814e-01, time/batch = 17.3825s	
12181/26050 (epoch 23.380), train_loss = 1.14924896, grad/param norm = 2.1364e-01, time/batch = 17.3010s	
12182/26050 (epoch 23.382), train_loss = 1.26648064, grad/param norm = 2.7132e-01, time/batch = 18.4965s	
12183/26050 (epoch 23.384), train_loss = 0.96864093, grad/param norm = 1.9116e-01, time/batch = 18.6586s	
12184/26050 (epoch 23.386), train_loss = 1.05508241, grad/param norm = 2.1577e-01, time/batch = 17.1566s	
12185/26050 (epoch 23.388), train_loss = 1.00283445, grad/param norm = 1.9370e-01, time/batch = 17.4647s	
12186/26050 (epoch 23.390), train_loss = 0.93353746, grad/param norm = 1.8844e-01, time/batch = 18.8954s	
12187/26050 (epoch 23.392), train_loss = 0.86042051, grad/param norm = 1.7560e-01, time/batch = 18.0744s	
12188/26050 (epoch 23.393), train_loss = 1.02955923, grad/param norm = 1.9009e-01, time/batch = 17.7276s	
12189/26050 (epoch 23.395), train_loss = 1.04529193, grad/param norm = 1.9589e-01, time/batch = 17.0584s	
12190/26050 (epoch 23.397), train_loss = 1.03504499, grad/param norm = 2.0990e-01, time/batch = 18.1343s	
12191/26050 (epoch 23.399), train_loss = 0.92872950, grad/param norm = 1.9062e-01, time/batch = 15.3008s	
12192/26050 (epoch 23.401), train_loss = 1.01062169, grad/param norm = 2.1277e-01, time/batch = 17.4580s	
12193/26050 (epoch 23.403), train_loss = 1.00718001, grad/param norm = 1.9751e-01, time/batch = 18.6312s	
12194/26050 (epoch 23.405), train_loss = 0.99635699, grad/param norm = 1.8612e-01, time/batch = 17.9905s	
12195/26050 (epoch 23.407), train_loss = 1.14780364, grad/param norm = 2.1247e-01, time/batch = 14.8992s	
12196/26050 (epoch 23.409), train_loss = 1.13521357, grad/param norm = 2.1559e-01, time/batch = 18.5612s	
12197/26050 (epoch 23.411), train_loss = 1.05944117, grad/param norm = 2.6048e-01, time/batch = 18.1524s	
12198/26050 (epoch 23.413), train_loss = 1.15285493, grad/param norm = 1.8746e-01, time/batch = 17.6430s	
12199/26050 (epoch 23.415), train_loss = 1.12271035, grad/param norm = 2.2665e-01, time/batch = 18.1544s	
12200/26050 (epoch 23.417), train_loss = 1.23263714, grad/param norm = 2.2209e-01, time/batch = 17.0433s	
12201/26050 (epoch 23.418), train_loss = 1.08896035, grad/param norm = 2.0977e-01, time/batch = 18.3144s	
12202/26050 (epoch 23.420), train_loss = 0.84481597, grad/param norm = 1.8071e-01, time/batch = 17.3847s	
12203/26050 (epoch 23.422), train_loss = 0.85067503, grad/param norm = 1.8075e-01, time/batch = 18.3157s	
12204/26050 (epoch 23.424), train_loss = 1.13642130, grad/param norm = 2.0494e-01, time/batch = 17.8147s	
12205/26050 (epoch 23.426), train_loss = 1.10150727, grad/param norm = 1.9216e-01, time/batch = 14.8699s	
12206/26050 (epoch 23.428), train_loss = 0.95107501, grad/param norm = 1.7160e-01, time/batch = 17.0655s	
12207/26050 (epoch 23.430), train_loss = 1.13373055, grad/param norm = 1.9232e-01, time/batch = 18.6561s	
12208/26050 (epoch 23.432), train_loss = 0.97466508, grad/param norm = 1.9228e-01, time/batch = 17.9746s	
12209/26050 (epoch 23.434), train_loss = 0.98437245, grad/param norm = 2.0939e-01, time/batch = 17.9152s	
12210/26050 (epoch 23.436), train_loss = 1.12617821, grad/param norm = 2.0589e-01, time/batch = 17.9783s	
12211/26050 (epoch 23.438), train_loss = 1.07349649, grad/param norm = 2.4511e-01, time/batch = 17.3071s	
12212/26050 (epoch 23.440), train_loss = 1.01871811, grad/param norm = 1.9237e-01, time/batch = 18.4735s	
12213/26050 (epoch 23.441), train_loss = 1.00428066, grad/param norm = 1.8729e-01, time/batch = 16.4615s	
12214/26050 (epoch 23.443), train_loss = 0.85170569, grad/param norm = 1.5491e-01, time/batch = 15.5719s	
12215/26050 (epoch 23.445), train_loss = 0.93309840, grad/param norm = 1.8278e-01, time/batch = 16.8655s	
12216/26050 (epoch 23.447), train_loss = 1.13011781, grad/param norm = 2.0210e-01, time/batch = 18.3259s	
12217/26050 (epoch 23.449), train_loss = 0.90959118, grad/param norm = 1.7051e-01, time/batch = 18.2304s	
12218/26050 (epoch 23.451), train_loss = 1.14571586, grad/param norm = 2.0268e-01, time/batch = 17.3204s	
12219/26050 (epoch 23.453), train_loss = 0.93236434, grad/param norm = 1.6151e-01, time/batch = 18.5603s	
12220/26050 (epoch 23.455), train_loss = 1.00798904, grad/param norm = 1.9007e-01, time/batch = 18.6594s	
12221/26050 (epoch 23.457), train_loss = 0.97501017, grad/param norm = 1.7735e-01, time/batch = 16.9999s	
12222/26050 (epoch 23.459), train_loss = 1.08603192, grad/param norm = 1.9098e-01, time/batch = 15.3863s	
12223/26050 (epoch 23.461), train_loss = 1.08999004, grad/param norm = 2.1287e-01, time/batch = 18.2340s	
12224/26050 (epoch 23.463), train_loss = 0.95692373, grad/param norm = 1.6954e-01, time/batch = 18.9805s	
12225/26050 (epoch 23.464), train_loss = 1.03751796, grad/param norm = 1.7475e-01, time/batch = 17.9689s	
12226/26050 (epoch 23.466), train_loss = 1.06335359, grad/param norm = 1.9624e-01, time/batch = 14.9587s	
12227/26050 (epoch 23.468), train_loss = 1.09798370, grad/param norm = 1.7180e-01, time/batch = 16.7921s	
12228/26050 (epoch 23.470), train_loss = 1.13285186, grad/param norm = 2.1830e-01, time/batch = 18.0708s	
12229/26050 (epoch 23.472), train_loss = 1.15462024, grad/param norm = 2.4648e-01, time/batch = 17.8261s	
12230/26050 (epoch 23.474), train_loss = 1.13534482, grad/param norm = 1.9056e-01, time/batch = 18.3148s	
12231/26050 (epoch 23.476), train_loss = 1.13206286, grad/param norm = 1.8408e-01, time/batch = 17.9884s	
12232/26050 (epoch 23.478), train_loss = 1.00216306, grad/param norm = 1.9288e-01, time/batch = 16.8088s	
12233/26050 (epoch 23.480), train_loss = 1.00943691, grad/param norm = 1.8367e-01, time/batch = 15.0354s	
12234/26050 (epoch 23.482), train_loss = 0.97199631, grad/param norm = 1.9221e-01, time/batch = 18.3105s	
12235/26050 (epoch 23.484), train_loss = 0.95595762, grad/param norm = 1.9037e-01, time/batch = 17.7229s	
12236/26050 (epoch 23.486), train_loss = 1.12715320, grad/param norm = 1.7842e-01, time/batch = 17.7230s	
12237/26050 (epoch 23.488), train_loss = 1.22750431, grad/param norm = 2.1860e-01, time/batch = 18.3053s	
12238/26050 (epoch 23.489), train_loss = 1.16943774, grad/param norm = 2.2853e-01, time/batch = 18.3943s	
12239/26050 (epoch 23.491), train_loss = 0.93316994, grad/param norm = 1.8787e-01, time/batch = 15.0583s	
12240/26050 (epoch 23.493), train_loss = 1.01940727, grad/param norm = 1.9616e-01, time/batch = 18.1477s	
12241/26050 (epoch 23.495), train_loss = 0.99950272, grad/param norm = 1.8608e-01, time/batch = 18.4022s	
12242/26050 (epoch 23.497), train_loss = 0.91858473, grad/param norm = 1.7043e-01, time/batch = 17.3030s	
12243/26050 (epoch 23.499), train_loss = 0.97115066, grad/param norm = 1.9539e-01, time/batch = 14.5542s	
12244/26050 (epoch 23.501), train_loss = 1.08502363, grad/param norm = 1.9515e-01, time/batch = 18.2404s	
12245/26050 (epoch 23.503), train_loss = 0.96324708, grad/param norm = 1.8877e-01, time/batch = 18.4198s	
12246/26050 (epoch 23.505), train_loss = 1.12397732, grad/param norm = 1.8051e-01, time/batch = 18.5579s	
12247/26050 (epoch 23.507), train_loss = 1.06960010, grad/param norm = 1.9104e-01, time/batch = 17.9845s	
12248/26050 (epoch 23.509), train_loss = 1.17475065, grad/param norm = 1.7905e-01, time/batch = 18.5664s	
12249/26050 (epoch 23.511), train_loss = 0.95134632, grad/param norm = 1.6684e-01, time/batch = 15.1844s	
12250/26050 (epoch 23.512), train_loss = 0.91875644, grad/param norm = 1.8766e-01, time/batch = 14.2081s	
12251/26050 (epoch 23.514), train_loss = 1.07081905, grad/param norm = 1.9854e-01, time/batch = 13.6870s	
12252/26050 (epoch 23.516), train_loss = 1.13361016, grad/param norm = 1.9474e-01, time/batch = 13.8247s	
12253/26050 (epoch 23.518), train_loss = 1.01010723, grad/param norm = 1.9382e-01, time/batch = 13.8378s	
12254/26050 (epoch 23.520), train_loss = 0.98703730, grad/param norm = 1.8411e-01, time/batch = 13.7590s	
12255/26050 (epoch 23.522), train_loss = 0.79306362, grad/param norm = 1.7536e-01, time/batch = 14.0638s	
12256/26050 (epoch 23.524), train_loss = 1.08432297, grad/param norm = 2.2490e-01, time/batch = 13.6013s	
12257/26050 (epoch 23.526), train_loss = 1.10877597, grad/param norm = 2.1369e-01, time/batch = 14.3756s	
12258/26050 (epoch 23.528), train_loss = 1.07375281, grad/param norm = 2.8479e-01, time/batch = 13.8450s	
12259/26050 (epoch 23.530), train_loss = 0.97359434, grad/param norm = 1.8776e-01, time/batch = 14.0098s	
12260/26050 (epoch 23.532), train_loss = 1.03748635, grad/param norm = 1.9630e-01, time/batch = 13.8463s	
12261/26050 (epoch 23.534), train_loss = 1.08457170, grad/param norm = 2.1140e-01, time/batch = 13.7659s	
12262/26050 (epoch 23.536), train_loss = 1.00633949, grad/param norm = 1.7599e-01, time/batch = 13.9161s	
12263/26050 (epoch 23.537), train_loss = 1.09256844, grad/param norm = 2.0808e-01, time/batch = 14.7173s	
12264/26050 (epoch 23.539), train_loss = 1.01569933, grad/param norm = 1.9570e-01, time/batch = 13.7650s	
12265/26050 (epoch 23.541), train_loss = 1.19931457, grad/param norm = 2.1694e-01, time/batch = 13.7730s	
12266/26050 (epoch 23.543), train_loss = 0.86052258, grad/param norm = 1.7964e-01, time/batch = 13.9203s	
12267/26050 (epoch 23.545), train_loss = 1.05038653, grad/param norm = 1.9863e-01, time/batch = 13.8297s	
12268/26050 (epoch 23.547), train_loss = 0.99204450, grad/param norm = 1.8845e-01, time/batch = 13.8440s	
12269/26050 (epoch 23.549), train_loss = 0.84611449, grad/param norm = 1.7438e-01, time/batch = 13.8444s	
12270/26050 (epoch 23.551), train_loss = 1.06764792, grad/param norm = 1.9003e-01, time/batch = 14.0869s	
12271/26050 (epoch 23.553), train_loss = 0.93539333, grad/param norm = 1.7850e-01, time/batch = 13.9296s	
12272/26050 (epoch 23.555), train_loss = 0.92743245, grad/param norm = 1.7493e-01, time/batch = 14.3867s	
12273/26050 (epoch 23.557), train_loss = 1.04129921, grad/param norm = 1.7786e-01, time/batch = 13.8382s	
12274/26050 (epoch 23.559), train_loss = 0.99638510, grad/param norm = 1.8908e-01, time/batch = 13.7614s	
12275/26050 (epoch 23.560), train_loss = 0.97669247, grad/param norm = 1.8800e-01, time/batch = 14.1542s	
12276/26050 (epoch 23.562), train_loss = 0.98833788, grad/param norm = 1.9494e-01, time/batch = 13.9131s	
12277/26050 (epoch 23.564), train_loss = 1.17181510, grad/param norm = 1.9307e-01, time/batch = 13.9152s	
12278/26050 (epoch 23.566), train_loss = 0.91734240, grad/param norm = 1.8255e-01, time/batch = 13.7636s	
12279/26050 (epoch 23.568), train_loss = 1.04825656, grad/param norm = 1.8136e-01, time/batch = 13.9319s	
12280/26050 (epoch 23.570), train_loss = 1.05267570, grad/param norm = 2.1827e-01, time/batch = 13.8551s	
12281/26050 (epoch 23.572), train_loss = 0.97539971, grad/param norm = 1.9318e-01, time/batch = 13.9344s	
12282/26050 (epoch 23.574), train_loss = 1.02346484, grad/param norm = 2.1977e-01, time/batch = 13.9072s	
12283/26050 (epoch 23.576), train_loss = 1.04778990, grad/param norm = 2.0180e-01, time/batch = 13.8456s	
12284/26050 (epoch 23.578), train_loss = 0.95995013, grad/param norm = 1.8045e-01, time/batch = 13.8475s	
12285/26050 (epoch 23.580), train_loss = 0.94316094, grad/param norm = 1.9811e-01, time/batch = 13.7524s	
12286/26050 (epoch 23.582), train_loss = 1.01884017, grad/param norm = 1.7255e-01, time/batch = 13.6098s	
12287/26050 (epoch 23.583), train_loss = 1.10309783, grad/param norm = 1.7780e-01, time/batch = 13.7559s	
12288/26050 (epoch 23.585), train_loss = 0.88324337, grad/param norm = 1.9500e-01, time/batch = 13.7583s	
12289/26050 (epoch 23.587), train_loss = 1.05953866, grad/param norm = 2.0217e-01, time/batch = 13.9005s	
12290/26050 (epoch 23.589), train_loss = 1.15634073, grad/param norm = 2.0494e-01, time/batch = 13.7651s	
12291/26050 (epoch 23.591), train_loss = 0.99306050, grad/param norm = 1.8241e-01, time/batch = 13.8487s	
12292/26050 (epoch 23.593), train_loss = 0.87337758, grad/param norm = 1.6403e-01, time/batch = 13.8391s	
12293/26050 (epoch 23.595), train_loss = 1.05668567, grad/param norm = 2.0072e-01, time/batch = 14.3110s	
12294/26050 (epoch 23.597), train_loss = 1.02589017, grad/param norm = 1.9227e-01, time/batch = 13.8493s	
12295/26050 (epoch 23.599), train_loss = 1.01721086, grad/param norm = 1.9219e-01, time/batch = 13.6936s	
12296/26050 (epoch 23.601), train_loss = 1.18547062, grad/param norm = 1.9629e-01, time/batch = 14.0729s	
12297/26050 (epoch 23.603), train_loss = 1.02640450, grad/param norm = 1.8191e-01, time/batch = 13.8483s	
12298/26050 (epoch 23.605), train_loss = 0.95386253, grad/param norm = 1.9041e-01, time/batch = 13.8547s	
12299/26050 (epoch 23.607), train_loss = 1.12069850, grad/param norm = 2.0801e-01, time/batch = 13.6766s	
12300/26050 (epoch 23.608), train_loss = 0.87811466, grad/param norm = 1.6500e-01, time/batch = 13.8367s	
12301/26050 (epoch 23.610), train_loss = 0.99211786, grad/param norm = 1.8506e-01, time/batch = 13.7647s	
12302/26050 (epoch 23.612), train_loss = 0.99019738, grad/param norm = 2.0003e-01, time/batch = 13.7739s	
12303/26050 (epoch 23.614), train_loss = 1.03152454, grad/param norm = 1.9559e-01, time/batch = 13.9364s	
12304/26050 (epoch 23.616), train_loss = 1.13328112, grad/param norm = 2.1320e-01, time/batch = 14.2220s	
12305/26050 (epoch 23.618), train_loss = 0.95729828, grad/param norm = 1.9126e-01, time/batch = 13.8392s	
12306/26050 (epoch 23.620), train_loss = 1.05381003, grad/param norm = 1.9038e-01, time/batch = 13.7612s	
12307/26050 (epoch 23.622), train_loss = 0.88735776, grad/param norm = 1.5492e-01, time/batch = 13.7599s	
12308/26050 (epoch 23.624), train_loss = 0.85971835, grad/param norm = 1.7194e-01, time/batch = 13.6819s	
12309/26050 (epoch 23.626), train_loss = 1.07541860, grad/param norm = 2.0099e-01, time/batch = 13.7666s	
12310/26050 (epoch 23.628), train_loss = 0.93155944, grad/param norm = 1.8729e-01, time/batch = 13.7587s	
12311/26050 (epoch 23.630), train_loss = 1.13407929, grad/param norm = 1.8792e-01, time/batch = 13.6866s	
12312/26050 (epoch 23.631), train_loss = 1.16816528, grad/param norm = 2.0878e-01, time/batch = 13.6812s	
12313/26050 (epoch 23.633), train_loss = 0.89117247, grad/param norm = 1.6278e-01, time/batch = 14.1562s	
12314/26050 (epoch 23.635), train_loss = 0.92631305, grad/param norm = 1.6248e-01, time/batch = 14.0674s	
12315/26050 (epoch 23.637), train_loss = 0.90361782, grad/param norm = 1.8334e-01, time/batch = 13.7647s	
12316/26050 (epoch 23.639), train_loss = 1.07544971, grad/param norm = 1.7886e-01, time/batch = 13.6821s	
12317/26050 (epoch 23.641), train_loss = 0.96626579, grad/param norm = 1.7601e-01, time/batch = 13.9902s	
12318/26050 (epoch 23.643), train_loss = 0.90406772, grad/param norm = 1.6138e-01, time/batch = 13.9122s	
12319/26050 (epoch 23.645), train_loss = 0.97579181, grad/param norm = 1.7726e-01, time/batch = 14.3775s	
12320/26050 (epoch 23.647), train_loss = 0.94110139, grad/param norm = 1.8985e-01, time/batch = 13.7581s	
12321/26050 (epoch 23.649), train_loss = 1.00877096, grad/param norm = 2.1114e-01, time/batch = 13.7670s	
12322/26050 (epoch 23.651), train_loss = 0.95213778, grad/param norm = 1.8289e-01, time/batch = 14.0496s	
12323/26050 (epoch 23.653), train_loss = 1.00000533, grad/param norm = 1.8464e-01, time/batch = 13.9212s	
12324/26050 (epoch 23.655), train_loss = 0.92680939, grad/param norm = 1.7947e-01, time/batch = 13.7659s	
12325/26050 (epoch 23.656), train_loss = 0.86923239, grad/param norm = 1.7392e-01, time/batch = 13.6060s	
12326/26050 (epoch 23.658), train_loss = 1.17016103, grad/param norm = 1.9655e-01, time/batch = 13.7463s	
12327/26050 (epoch 23.660), train_loss = 0.87322148, grad/param norm = 1.9759e-01, time/batch = 13.8458s	
12328/26050 (epoch 23.662), train_loss = 0.96578768, grad/param norm = 1.8604e-01, time/batch = 13.7656s	
12329/26050 (epoch 23.664), train_loss = 0.98398794, grad/param norm = 1.8311e-01, time/batch = 13.6871s	
12330/26050 (epoch 23.666), train_loss = 0.94429545, grad/param norm = 1.9658e-01, time/batch = 13.8441s	
12331/26050 (epoch 23.668), train_loss = 0.83069506, grad/param norm = 2.1883e-01, time/batch = 13.9872s	
12332/26050 (epoch 23.670), train_loss = 1.13509605, grad/param norm = 2.2586e-01, time/batch = 13.6932s	
12333/26050 (epoch 23.672), train_loss = 1.00139472, grad/param norm = 1.9240e-01, time/batch = 13.8446s	
12334/26050 (epoch 23.674), train_loss = 0.90597299, grad/param norm = 1.7588e-01, time/batch = 14.0596s	
12335/26050 (epoch 23.676), train_loss = 1.05959092, grad/param norm = 1.9858e-01, time/batch = 13.9135s	
12336/26050 (epoch 23.678), train_loss = 1.12685938, grad/param norm = 2.0672e-01, time/batch = 13.8402s	
12337/26050 (epoch 23.679), train_loss = 1.17828653, grad/param norm = 2.2372e-01, time/batch = 13.8439s	
12338/26050 (epoch 23.681), train_loss = 1.00544222, grad/param norm = 1.8720e-01, time/batch = 13.6817s	
12339/26050 (epoch 23.683), train_loss = 0.91536737, grad/param norm = 2.1797e-01, time/batch = 13.7660s	
12340/26050 (epoch 23.685), train_loss = 0.98426870, grad/param norm = 2.0315e-01, time/batch = 13.6863s	
12341/26050 (epoch 23.687), train_loss = 0.86769033, grad/param norm = 1.8145e-01, time/batch = 13.8428s	
12342/26050 (epoch 23.689), train_loss = 0.95345117, grad/param norm = 1.9496e-01, time/batch = 13.7408s	
12343/26050 (epoch 23.691), train_loss = 0.81409672, grad/param norm = 1.7692e-01, time/batch = 13.7582s	
12344/26050 (epoch 23.693), train_loss = 0.92069488, grad/param norm = 2.0673e-01, time/batch = 13.8353s	
12345/26050 (epoch 23.695), train_loss = 0.99856885, grad/param norm = 1.8379e-01, time/batch = 13.8347s	
12346/26050 (epoch 23.697), train_loss = 0.90419755, grad/param norm = 1.7264e-01, time/batch = 13.6815s	
12347/26050 (epoch 23.699), train_loss = 1.05958115, grad/param norm = 2.1793e-01, time/batch = 13.6924s	
12348/26050 (epoch 23.701), train_loss = 0.90428108, grad/param norm = 1.6070e-01, time/batch = 13.8473s	
12349/26050 (epoch 23.702), train_loss = 1.10211238, grad/param norm = 1.9491e-01, time/batch = 13.9712s	
12350/26050 (epoch 23.704), train_loss = 1.08263341, grad/param norm = 1.8069e-01, time/batch = 13.6818s	
12351/26050 (epoch 23.706), train_loss = 0.95037865, grad/param norm = 1.9582e-01, time/batch = 13.7662s	
12352/26050 (epoch 23.708), train_loss = 1.06850829, grad/param norm = 2.0256e-01, time/batch = 14.0714s	
12353/26050 (epoch 23.710), train_loss = 1.05131927, grad/param norm = 2.0603e-01, time/batch = 14.2456s	
12354/26050 (epoch 23.712), train_loss = 1.02091233, grad/param norm = 1.9331e-01, time/batch = 14.0499s	
12355/26050 (epoch 23.714), train_loss = 0.86607754, grad/param norm = 1.8037e-01, time/batch = 13.6869s	
12356/26050 (epoch 23.716), train_loss = 1.24255543, grad/param norm = 2.1601e-01, time/batch = 13.8479s	
12357/26050 (epoch 23.718), train_loss = 1.07764255, grad/param norm = 1.9315e-01, time/batch = 14.0881s	
12358/26050 (epoch 23.720), train_loss = 0.98725155, grad/param norm = 1.8920e-01, time/batch = 14.0933s	
12359/26050 (epoch 23.722), train_loss = 0.87240311, grad/param norm = 1.7847e-01, time/batch = 13.9302s	
12360/26050 (epoch 23.724), train_loss = 0.91870957, grad/param norm = 1.9109e-01, time/batch = 13.7718s	
12361/26050 (epoch 23.726), train_loss = 1.04717748, grad/param norm = 1.8668e-01, time/batch = 14.0069s	
12362/26050 (epoch 23.727), train_loss = 1.05140568, grad/param norm = 2.0750e-01, time/batch = 13.9760s	
12363/26050 (epoch 23.729), train_loss = 1.05620450, grad/param norm = 1.8521e-01, time/batch = 13.6863s	
12364/26050 (epoch 23.731), train_loss = 1.03284824, grad/param norm = 1.8412e-01, time/batch = 13.6888s	
12365/26050 (epoch 23.733), train_loss = 0.95869231, grad/param norm = 2.2799e-01, time/batch = 14.1003s	
12366/26050 (epoch 23.735), train_loss = 1.18870205, grad/param norm = 2.1933e-01, time/batch = 17.5731s	
12367/26050 (epoch 23.737), train_loss = 0.94081273, grad/param norm = 1.8903e-01, time/batch = 17.9129s	
12368/26050 (epoch 23.739), train_loss = 1.03666010, grad/param norm = 1.9783e-01, time/batch = 18.2550s	
12369/26050 (epoch 23.741), train_loss = 0.92824964, grad/param norm = 1.9167e-01, time/batch = 15.0476s	
12370/26050 (epoch 23.743), train_loss = 1.04482941, grad/param norm = 2.4560e-01, time/batch = 17.1481s	
12371/26050 (epoch 23.745), train_loss = 0.87871297, grad/param norm = 2.0347e-01, time/batch = 18.0031s	
12372/26050 (epoch 23.747), train_loss = 0.91538091, grad/param norm = 1.8276e-01, time/batch = 17.8139s	
12373/26050 (epoch 23.749), train_loss = 1.10743250, grad/param norm = 2.0799e-01, time/batch = 18.0886s	
12374/26050 (epoch 23.750), train_loss = 1.00337785, grad/param norm = 1.7111e-01, time/batch = 18.5619s	
12375/26050 (epoch 23.752), train_loss = 0.96172740, grad/param norm = 2.3202e-01, time/batch = 14.9578s	
12376/26050 (epoch 23.754), train_loss = 1.01748089, grad/param norm = 1.9568e-01, time/batch = 23.3596s	
12377/26050 (epoch 23.756), train_loss = 0.98507044, grad/param norm = 2.0542e-01, time/batch = 29.7289s	
12378/26050 (epoch 23.758), train_loss = 0.97647299, grad/param norm = 2.0407e-01, time/batch = 17.1961s	
12379/26050 (epoch 23.760), train_loss = 1.17283950, grad/param norm = 2.0504e-01, time/batch = 18.3253s	
12380/26050 (epoch 23.762), train_loss = 0.95546835, grad/param norm = 2.0766e-01, time/batch = 15.3749s	
12381/26050 (epoch 23.764), train_loss = 0.99384406, grad/param norm = 2.1188e-01, time/batch = 18.0626s	
12382/26050 (epoch 23.766), train_loss = 1.05457549, grad/param norm = 2.2365e-01, time/batch = 15.1471s	
12383/26050 (epoch 23.768), train_loss = 0.89290979, grad/param norm = 1.7368e-01, time/batch = 16.2872s	
12384/26050 (epoch 23.770), train_loss = 0.98326664, grad/param norm = 2.1267e-01, time/batch = 18.7321s	
12385/26050 (epoch 23.772), train_loss = 0.99364216, grad/param norm = 1.7046e-01, time/batch = 16.5722s	
12386/26050 (epoch 23.774), train_loss = 0.85311665, grad/param norm = 1.8260e-01, time/batch = 19.0713s	
12387/26050 (epoch 23.775), train_loss = 0.72147661, grad/param norm = 1.6543e-01, time/batch = 16.9775s	
12388/26050 (epoch 23.777), train_loss = 0.93958657, grad/param norm = 1.8905e-01, time/batch = 15.6486s	
12389/26050 (epoch 23.779), train_loss = 0.97438091, grad/param norm = 1.9981e-01, time/batch = 17.9002s	
12390/26050 (epoch 23.781), train_loss = 0.88100997, grad/param norm = 1.9598e-01, time/batch = 18.1571s	
12391/26050 (epoch 23.783), train_loss = 0.87294066, grad/param norm = 1.8306e-01, time/batch = 15.4675s	
12392/26050 (epoch 23.785), train_loss = 1.01494592, grad/param norm = 2.1450e-01, time/batch = 17.8758s	
12393/26050 (epoch 23.787), train_loss = 0.90528264, grad/param norm = 1.7897e-01, time/batch = 18.1650s	
12394/26050 (epoch 23.789), train_loss = 0.94339741, grad/param norm = 2.0299e-01, time/batch = 18.4906s	
12395/26050 (epoch 23.791), train_loss = 0.92184665, grad/param norm = 1.8171e-01, time/batch = 17.7227s	
12396/26050 (epoch 23.793), train_loss = 0.97717345, grad/param norm = 2.0008e-01, time/batch = 17.9840s	
12397/26050 (epoch 23.795), train_loss = 0.79680185, grad/param norm = 1.4938e-01, time/batch = 18.1470s	
12398/26050 (epoch 23.797), train_loss = 0.90109879, grad/param norm = 1.7636e-01, time/batch = 18.1626s	
12399/26050 (epoch 23.798), train_loss = 0.86110129, grad/param norm = 1.8679e-01, time/batch = 18.5690s	
12400/26050 (epoch 23.800), train_loss = 0.86186228, grad/param norm = 1.6983e-01, time/batch = 17.3057s	
12401/26050 (epoch 23.802), train_loss = 0.91975586, grad/param norm = 1.8809e-01, time/batch = 17.5240s	
12402/26050 (epoch 23.804), train_loss = 0.98130359, grad/param norm = 1.9667e-01, time/batch = 17.8193s	
12403/26050 (epoch 23.806), train_loss = 1.07044850, grad/param norm = 1.8998e-01, time/batch = 18.4833s	
12404/26050 (epoch 23.808), train_loss = 0.98344110, grad/param norm = 1.8381e-01, time/batch = 17.8200s	
12405/26050 (epoch 23.810), train_loss = 0.93515505, grad/param norm = 1.9487e-01, time/batch = 18.4082s	
12406/26050 (epoch 23.812), train_loss = 0.86356604, grad/param norm = 1.8704e-01, time/batch = 18.3175s	
12407/26050 (epoch 23.814), train_loss = 0.88649229, grad/param norm = 2.3720e-01, time/batch = 18.2393s	
12408/26050 (epoch 23.816), train_loss = 1.05314939, grad/param norm = 2.0058e-01, time/batch = 17.4842s	
12409/26050 (epoch 23.818), train_loss = 1.07772615, grad/param norm = 2.2682e-01, time/batch = 18.3177s	
12410/26050 (epoch 23.820), train_loss = 1.01061620, grad/param norm = 1.8703e-01, time/batch = 18.6598s	
12411/26050 (epoch 23.821), train_loss = 1.10330190, grad/param norm = 2.0695e-01, time/batch = 17.0796s	
12412/26050 (epoch 23.823), train_loss = 1.14518006, grad/param norm = 2.0023e-01, time/batch = 14.4544s	
12413/26050 (epoch 23.825), train_loss = 0.98010808, grad/param norm = 1.8456e-01, time/batch = 18.5632s	
12414/26050 (epoch 23.827), train_loss = 1.02858233, grad/param norm = 2.1369e-01, time/batch = 16.3969s	
12415/26050 (epoch 23.829), train_loss = 1.06917455, grad/param norm = 2.1748e-01, time/batch = 16.8792s	
12416/26050 (epoch 23.831), train_loss = 1.13386329, grad/param norm = 2.0291e-01, time/batch = 18.3134s	
12417/26050 (epoch 23.833), train_loss = 1.19234788, grad/param norm = 2.1506e-01, time/batch = 18.3127s	
12418/26050 (epoch 23.835), train_loss = 1.16510592, grad/param norm = 1.9996e-01, time/batch = 16.7453s	
12419/26050 (epoch 23.837), train_loss = 0.99339722, grad/param norm = 1.8414e-01, time/batch = 17.8809s	
12420/26050 (epoch 23.839), train_loss = 0.99350483, grad/param norm = 2.0563e-01, time/batch = 15.9797s	
12421/26050 (epoch 23.841), train_loss = 1.13505041, grad/param norm = 1.9685e-01, time/batch = 18.8071s	
12422/26050 (epoch 23.843), train_loss = 0.97116685, grad/param norm = 1.7629e-01, time/batch = 16.0516s	
12423/26050 (epoch 23.845), train_loss = 0.95582503, grad/param norm = 1.7704e-01, time/batch = 18.2248s	
12424/26050 (epoch 23.846), train_loss = 1.06862374, grad/param norm = 1.9864e-01, time/batch = 17.8898s	
12425/26050 (epoch 23.848), train_loss = 0.97210720, grad/param norm = 1.8563e-01, time/batch = 17.6533s	
12426/26050 (epoch 23.850), train_loss = 0.89827846, grad/param norm = 1.7490e-01, time/batch = 17.1476s	
12427/26050 (epoch 23.852), train_loss = 0.99611152, grad/param norm = 1.7789e-01, time/batch = 16.6395s	
12428/26050 (epoch 23.854), train_loss = 0.97744213, grad/param norm = 1.8940e-01, time/batch = 18.7315s	
12429/26050 (epoch 23.856), train_loss = 0.95350461, grad/param norm = 1.9547e-01, time/batch = 16.8746s	
12430/26050 (epoch 23.858), train_loss = 0.90962462, grad/param norm = 1.7418e-01, time/batch = 17.0713s	
12431/26050 (epoch 23.860), train_loss = 1.03700176, grad/param norm = 2.0140e-01, time/batch = 16.1080s	
12432/26050 (epoch 23.862), train_loss = 1.05472379, grad/param norm = 1.9989e-01, time/batch = 18.0606s	
12433/26050 (epoch 23.864), train_loss = 1.02209518, grad/param norm = 2.1703e-01, time/batch = 18.0655s	
12434/26050 (epoch 23.866), train_loss = 0.94887312, grad/param norm = 1.7498e-01, time/batch = 18.5618s	
12435/26050 (epoch 23.868), train_loss = 1.04572593, grad/param norm = 2.0639e-01, time/batch = 18.4978s	
12436/26050 (epoch 23.869), train_loss = 0.89358328, grad/param norm = 1.7412e-01, time/batch = 17.4940s	
12437/26050 (epoch 23.871), train_loss = 0.82452358, grad/param norm = 1.5836e-01, time/batch = 17.1649s	
12438/26050 (epoch 23.873), train_loss = 1.03134561, grad/param norm = 2.0386e-01, time/batch = 18.9073s	
12439/26050 (epoch 23.875), train_loss = 0.97527900, grad/param norm = 1.9191e-01, time/batch = 17.2412s	
12440/26050 (epoch 23.877), train_loss = 0.88642526, grad/param norm = 1.7575e-01, time/batch = 18.2427s	
12441/26050 (epoch 23.879), train_loss = 1.00924264, grad/param norm = 1.7558e-01, time/batch = 18.9043s	
12442/26050 (epoch 23.881), train_loss = 1.09984039, grad/param norm = 2.1418e-01, time/batch = 16.9095s	
12443/26050 (epoch 23.883), train_loss = 1.03823538, grad/param norm = 1.8185e-01, time/batch = 18.1570s	
12444/26050 (epoch 23.885), train_loss = 0.75627333, grad/param norm = 1.6292e-01, time/batch = 18.4850s	
12445/26050 (epoch 23.887), train_loss = 1.04623082, grad/param norm = 1.8985e-01, time/batch = 16.3917s	
12446/26050 (epoch 23.889), train_loss = 0.93640134, grad/param norm = 1.7897e-01, time/batch = 17.5614s	
12447/26050 (epoch 23.891), train_loss = 0.81189507, grad/param norm = 1.6119e-01, time/batch = 17.9828s	
12448/26050 (epoch 23.893), train_loss = 0.86219464, grad/param norm = 1.7590e-01, time/batch = 18.9118s	
12449/26050 (epoch 23.894), train_loss = 0.94174082, grad/param norm = 1.8076e-01, time/batch = 17.2307s	
12450/26050 (epoch 23.896), train_loss = 1.07171948, grad/param norm = 2.0159e-01, time/batch = 18.0761s	
12451/26050 (epoch 23.898), train_loss = 0.92946389, grad/param norm = 1.9931e-01, time/batch = 18.0812s	
12452/26050 (epoch 23.900), train_loss = 1.02750218, grad/param norm = 2.0327e-01, time/batch = 17.8221s	
12453/26050 (epoch 23.902), train_loss = 0.98464719, grad/param norm = 1.9919e-01, time/batch = 14.4749s	
12454/26050 (epoch 23.904), train_loss = 0.97098002, grad/param norm = 1.7686e-01, time/batch = 17.3531s	
12455/26050 (epoch 23.906), train_loss = 0.96466169, grad/param norm = 2.0315e-01, time/batch = 15.1403s	
12456/26050 (epoch 23.908), train_loss = 0.97873792, grad/param norm = 1.8044e-01, time/batch = 18.0583s	
12457/26050 (epoch 23.910), train_loss = 0.95087623, grad/param norm = 1.6889e-01, time/batch = 18.4882s	
12458/26050 (epoch 23.912), train_loss = 1.19049470, grad/param norm = 2.2040e-01, time/batch = 17.7194s	
12459/26050 (epoch 23.914), train_loss = 1.33849942, grad/param norm = 2.1989e-01, time/batch = 16.9051s	
12460/26050 (epoch 23.916), train_loss = 1.07068854, grad/param norm = 1.9697e-01, time/batch = 16.3035s	
12461/26050 (epoch 23.917), train_loss = 0.98823650, grad/param norm = 2.0058e-01, time/batch = 17.4820s	
12462/26050 (epoch 23.919), train_loss = 1.05052138, grad/param norm = 2.1228e-01, time/batch = 18.1301s	
12463/26050 (epoch 23.921), train_loss = 0.94267717, grad/param norm = 1.9882e-01, time/batch = 17.2407s	
12464/26050 (epoch 23.923), train_loss = 0.99947130, grad/param norm = 1.9388e-01, time/batch = 17.9004s	
12465/26050 (epoch 23.925), train_loss = 0.98566512, grad/param norm = 1.7451e-01, time/batch = 14.8237s	
12466/26050 (epoch 23.927), train_loss = 0.88724801, grad/param norm = 1.5501e-01, time/batch = 18.3209s	
12467/26050 (epoch 23.929), train_loss = 0.84254191, grad/param norm = 1.6592e-01, time/batch = 18.3969s	
12468/26050 (epoch 23.931), train_loss = 1.14366068, grad/param norm = 2.4505e-01, time/batch = 17.4154s	
12469/26050 (epoch 23.933), train_loss = 0.94882105, grad/param norm = 1.9349e-01, time/batch = 18.5726s	
12470/26050 (epoch 23.935), train_loss = 0.97745750, grad/param norm = 1.9474e-01, time/batch = 17.0828s	
12471/26050 (epoch 23.937), train_loss = 1.08086668, grad/param norm = 1.8334e-01, time/batch = 18.4747s	
12472/26050 (epoch 23.939), train_loss = 0.90900554, grad/param norm = 1.6253e-01, time/batch = 18.8979s	
12473/26050 (epoch 23.940), train_loss = 0.94694448, grad/param norm = 1.7055e-01, time/batch = 15.6486s	
12474/26050 (epoch 23.942), train_loss = 0.97786262, grad/param norm = 1.9119e-01, time/batch = 17.9724s	
12475/26050 (epoch 23.944), train_loss = 0.95285543, grad/param norm = 1.7155e-01, time/batch = 17.6445s	
12476/26050 (epoch 23.946), train_loss = 1.11657429, grad/param norm = 2.0522e-01, time/batch = 17.5579s	
12477/26050 (epoch 23.948), train_loss = 0.86094062, grad/param norm = 1.8750e-01, time/batch = 5.7083s	
12478/26050 (epoch 23.950), train_loss = 0.95987971, grad/param norm = 1.9311e-01, time/batch = 0.6428s	
12479/26050 (epoch 23.952), train_loss = 1.07824905, grad/param norm = 2.1004e-01, time/batch = 0.6424s	
12480/26050 (epoch 23.954), train_loss = 1.07380218, grad/param norm = 1.8823e-01, time/batch = 0.6416s	
12481/26050 (epoch 23.956), train_loss = 0.96520173, grad/param norm = 1.8501e-01, time/batch = 0.6439s	
12482/26050 (epoch 23.958), train_loss = 0.92199798, grad/param norm = 1.8127e-01, time/batch = 0.6583s	
12483/26050 (epoch 23.960), train_loss = 1.01535041, grad/param norm = 1.8835e-01, time/batch = 0.6448s	
12484/26050 (epoch 23.962), train_loss = 0.96212974, grad/param norm = 1.8649e-01, time/batch = 0.6407s	
12485/26050 (epoch 23.964), train_loss = 0.99126479, grad/param norm = 1.8770e-01, time/batch = 0.9491s	
12486/26050 (epoch 23.965), train_loss = 0.91072976, grad/param norm = 1.8990e-01, time/batch = 0.9463s	
12487/26050 (epoch 23.967), train_loss = 1.30125334, grad/param norm = 1.9360e-01, time/batch = 0.9951s	
12488/26050 (epoch 23.969), train_loss = 1.02254226, grad/param norm = 1.9587e-01, time/batch = 0.9444s	
12489/26050 (epoch 23.971), train_loss = 0.94641415, grad/param norm = 1.8537e-01, time/batch = 0.9411s	
12490/26050 (epoch 23.973), train_loss = 1.00460698, grad/param norm = 1.9430e-01, time/batch = 1.5501s	
12491/26050 (epoch 23.975), train_loss = 1.01668417, grad/param norm = 1.9212e-01, time/batch = 1.7695s	
12492/26050 (epoch 23.977), train_loss = 1.00265007, grad/param norm = 1.7168e-01, time/batch = 1.7677s	
12493/26050 (epoch 23.979), train_loss = 0.81752686, grad/param norm = 1.7695e-01, time/batch = 18.0514s	
12494/26050 (epoch 23.981), train_loss = 1.13092650, grad/param norm = 2.0452e-01, time/batch = 18.3209s	
12495/26050 (epoch 23.983), train_loss = 1.07112666, grad/param norm = 2.1687e-01, time/batch = 17.2977s	
12496/26050 (epoch 23.985), train_loss = 1.04510892, grad/param norm = 2.0548e-01, time/batch = 16.3967s	
12497/26050 (epoch 23.987), train_loss = 1.09864279, grad/param norm = 1.9020e-01, time/batch = 18.9042s	
12498/26050 (epoch 23.988), train_loss = 1.04593915, grad/param norm = 1.8225e-01, time/batch = 16.7386s	
12499/26050 (epoch 23.990), train_loss = 0.87753559, grad/param norm = 1.6358e-01, time/batch = 16.1444s	
12500/26050 (epoch 23.992), train_loss = 1.14096933, grad/param norm = 1.9255e-01, time/batch = 17.6744s	
12501/26050 (epoch 23.994), train_loss = 0.95729601, grad/param norm = 2.5614e-01, time/batch = 18.2419s	
12502/26050 (epoch 23.996), train_loss = 0.93329906, grad/param norm = 1.9156e-01, time/batch = 18.2287s	
12503/26050 (epoch 23.998), train_loss = 0.99273196, grad/param norm = 1.7988e-01, time/batch = 18.0615s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
12504/26050 (epoch 24.000), train_loss = 0.96321441, grad/param norm = 2.2004e-01, time/batch = 15.1563s	
12505/26050 (epoch 24.002), train_loss = 1.05398156, grad/param norm = 2.1253e-01, time/batch = 17.2362s	
12506/26050 (epoch 24.004), train_loss = 0.89913741, grad/param norm = 1.9919e-01, time/batch = 18.6507s	
12507/26050 (epoch 24.006), train_loss = 0.94598907, grad/param norm = 2.0398e-01, time/batch = 18.4017s	
12508/26050 (epoch 24.008), train_loss = 0.95348463, grad/param norm = 2.2256e-01, time/batch = 17.4716s	
12509/26050 (epoch 24.010), train_loss = 0.91759743, grad/param norm = 1.7240e-01, time/batch = 14.5564s	
12510/26050 (epoch 24.012), train_loss = 1.00320586, grad/param norm = 1.8740e-01, time/batch = 18.4765s	
12511/26050 (epoch 24.013), train_loss = 1.26916545, grad/param norm = 2.1695e-01, time/batch = 15.2363s	
12512/26050 (epoch 24.015), train_loss = 0.95238209, grad/param norm = 1.7539e-01, time/batch = 17.6420s	
12513/26050 (epoch 24.017), train_loss = 1.00947034, grad/param norm = 1.8262e-01, time/batch = 17.5710s	
12514/26050 (epoch 24.019), train_loss = 0.86927260, grad/param norm = 1.7283e-01, time/batch = 18.7403s	
12515/26050 (epoch 24.021), train_loss = 1.06396441, grad/param norm = 1.8294e-01, time/batch = 17.1642s	
12516/26050 (epoch 24.023), train_loss = 0.80636259, grad/param norm = 1.7251e-01, time/batch = 17.8112s	
12517/26050 (epoch 24.025), train_loss = 0.99065858, grad/param norm = 1.8047e-01, time/batch = 17.6598s	
12518/26050 (epoch 24.027), train_loss = 0.80314369, grad/param norm = 1.9036e-01, time/batch = 18.7423s	
12519/26050 (epoch 24.029), train_loss = 1.00193953, grad/param norm = 1.7322e-01, time/batch = 18.0756s	
12520/26050 (epoch 24.031), train_loss = 1.12659129, grad/param norm = 2.1360e-01, time/batch = 16.7131s	
12521/26050 (epoch 24.033), train_loss = 1.00351597, grad/param norm = 2.1260e-01, time/batch = 18.8870s	
12522/26050 (epoch 24.035), train_loss = 1.02411143, grad/param norm = 1.8454e-01, time/batch = 17.3270s	
12523/26050 (epoch 24.036), train_loss = 0.87407360, grad/param norm = 2.0355e-01, time/batch = 18.4835s	
12524/26050 (epoch 24.038), train_loss = 0.80874598, grad/param norm = 1.8142e-01, time/batch = 18.8295s	
12525/26050 (epoch 24.040), train_loss = 0.96218851, grad/param norm = 1.8200e-01, time/batch = 16.7396s	
12526/26050 (epoch 24.042), train_loss = 0.83567783, grad/param norm = 1.7960e-01, time/batch = 16.1539s	
12527/26050 (epoch 24.044), train_loss = 1.04319993, grad/param norm = 1.7247e-01, time/batch = 15.4774s	
12528/26050 (epoch 24.046), train_loss = 0.79882856, grad/param norm = 1.6405e-01, time/batch = 18.8270s	
12529/26050 (epoch 24.048), train_loss = 0.98159153, grad/param norm = 1.7219e-01, time/batch = 17.4938s	
12530/26050 (epoch 24.050), train_loss = 0.92449917, grad/param norm = 1.8161e-01, time/batch = 16.6532s	
12531/26050 (epoch 24.052), train_loss = 0.90186653, grad/param norm = 1.8434e-01, time/batch = 17.8714s	
12532/26050 (epoch 24.054), train_loss = 0.83277610, grad/param norm = 1.7870e-01, time/batch = 18.1510s	
12533/26050 (epoch 24.056), train_loss = 0.80455353, grad/param norm = 1.6903e-01, time/batch = 17.5711s	
12534/26050 (epoch 24.058), train_loss = 0.95121877, grad/param norm = 1.7275e-01, time/batch = 18.3146s	
12535/26050 (epoch 24.060), train_loss = 1.05216136, grad/param norm = 1.8964e-01, time/batch = 18.5308s	
12536/26050 (epoch 24.061), train_loss = 0.89030735, grad/param norm = 1.6402e-01, time/batch = 17.4690s	
12537/26050 (epoch 24.063), train_loss = 1.01049022, grad/param norm = 1.7410e-01, time/batch = 16.8899s	
12538/26050 (epoch 24.065), train_loss = 0.79578267, grad/param norm = 1.6304e-01, time/batch = 18.8202s	
12539/26050 (epoch 24.067), train_loss = 0.97898994, grad/param norm = 2.0299e-01, time/batch = 17.4807s	
12540/26050 (epoch 24.069), train_loss = 1.03246793, grad/param norm = 2.2515e-01, time/batch = 17.5747s	
12541/26050 (epoch 24.071), train_loss = 1.03051664, grad/param norm = 1.8712e-01, time/batch = 18.7373s	
12542/26050 (epoch 24.073), train_loss = 1.15176357, grad/param norm = 2.0053e-01, time/batch = 17.3169s	
12543/26050 (epoch 24.075), train_loss = 0.91403066, grad/param norm = 1.8965e-01, time/batch = 18.6340s	
12544/26050 (epoch 24.077), train_loss = 0.92699115, grad/param norm = 1.9144e-01, time/batch = 15.7327s	
12545/26050 (epoch 24.079), train_loss = 0.99279477, grad/param norm = 1.8373e-01, time/batch = 17.7298s	
12546/26050 (epoch 24.081), train_loss = 0.93726425, grad/param norm = 1.7797e-01, time/batch = 16.8984s	
12547/26050 (epoch 24.083), train_loss = 1.07191948, grad/param norm = 1.7871e-01, time/batch = 17.4740s	
12548/26050 (epoch 24.084), train_loss = 0.98879033, grad/param norm = 2.0499e-01, time/batch = 15.9646s	
12549/26050 (epoch 24.086), train_loss = 1.15679792, grad/param norm = 2.2379e-01, time/batch = 17.4022s	
12550/26050 (epoch 24.088), train_loss = 0.94369460, grad/param norm = 2.0910e-01, time/batch = 18.0633s	
12551/26050 (epoch 24.090), train_loss = 0.99196383, grad/param norm = 1.7891e-01, time/batch = 17.8243s	
12552/26050 (epoch 24.092), train_loss = 1.04255612, grad/param norm = 1.8113e-01, time/batch = 17.3097s	
12553/26050 (epoch 24.094), train_loss = 0.90224776, grad/param norm = 1.8498e-01, time/batch = 17.2974s	
12554/26050 (epoch 24.096), train_loss = 0.98616860, grad/param norm = 1.7879e-01, time/batch = 18.6625s	
12555/26050 (epoch 24.098), train_loss = 0.93070888, grad/param norm = 1.9367e-01, time/batch = 17.4834s	
12556/26050 (epoch 24.100), train_loss = 0.87132368, grad/param norm = 1.7755e-01, time/batch = 14.5638s	
12557/26050 (epoch 24.102), train_loss = 1.03191267, grad/param norm = 2.1172e-01, time/batch = 18.0606s	
12558/26050 (epoch 24.104), train_loss = 0.96053284, grad/param norm = 1.9138e-01, time/batch = 18.2377s	
12559/26050 (epoch 24.106), train_loss = 0.96933620, grad/param norm = 1.9878e-01, time/batch = 16.4694s	
12560/26050 (epoch 24.107), train_loss = 0.79431457, grad/param norm = 1.7277e-01, time/batch = 17.4745s	
12561/26050 (epoch 24.109), train_loss = 0.89282403, grad/param norm = 1.8630e-01, time/batch = 18.5527s	
12562/26050 (epoch 24.111), train_loss = 1.12406793, grad/param norm = 1.9188e-01, time/batch = 18.5703s	
12563/26050 (epoch 24.113), train_loss = 0.93576575, grad/param norm = 1.8694e-01, time/batch = 17.5723s	
12564/26050 (epoch 24.115), train_loss = 1.06497422, grad/param norm = 1.9133e-01, time/batch = 16.5437s	
12565/26050 (epoch 24.117), train_loss = 0.98766984, grad/param norm = 1.8799e-01, time/batch = 18.6369s	
12566/26050 (epoch 24.119), train_loss = 0.82564873, grad/param norm = 1.7116e-01, time/batch = 17.8122s	
12567/26050 (epoch 24.121), train_loss = 0.98819975, grad/param norm = 1.8394e-01, time/batch = 17.6505s	
12568/26050 (epoch 24.123), train_loss = 0.88254290, grad/param norm = 1.6836e-01, time/batch = 14.7341s	
12569/26050 (epoch 24.125), train_loss = 0.84514767, grad/param norm = 1.7274e-01, time/batch = 19.1327s	
12570/26050 (epoch 24.127), train_loss = 0.78614177, grad/param norm = 1.6823e-01, time/batch = 17.2362s	
12571/26050 (epoch 24.129), train_loss = 0.83105958, grad/param norm = 1.7918e-01, time/batch = 18.4024s	
12572/26050 (epoch 24.131), train_loss = 0.92941312, grad/param norm = 1.8482e-01, time/batch = 17.9899s	
12573/26050 (epoch 24.132), train_loss = 0.94971582, grad/param norm = 1.6527e-01, time/batch = 17.8988s	
12574/26050 (epoch 24.134), train_loss = 0.98707721, grad/param norm = 2.0060e-01, time/batch = 17.1249s	
12575/26050 (epoch 24.136), train_loss = 0.97041629, grad/param norm = 1.7720e-01, time/batch = 18.5725s	
12576/26050 (epoch 24.138), train_loss = 0.73073041, grad/param norm = 1.5606e-01, time/batch = 17.3021s	
12577/26050 (epoch 24.140), train_loss = 0.81710819, grad/param norm = 1.7619e-01, time/batch = 17.7430s	
12578/26050 (epoch 24.142), train_loss = 0.84745236, grad/param norm = 1.7093e-01, time/batch = 18.2927s	
12579/26050 (epoch 24.144), train_loss = 0.77835192, grad/param norm = 1.7615e-01, time/batch = 18.9014s	
12580/26050 (epoch 24.146), train_loss = 0.72708125, grad/param norm = 1.6318e-01, time/batch = 14.6303s	
12581/26050 (epoch 24.148), train_loss = 0.76029480, grad/param norm = 1.4952e-01, time/batch = 17.3955s	
12582/26050 (epoch 24.150), train_loss = 0.92441383, grad/param norm = 1.8549e-01, time/batch = 18.7287s	
12583/26050 (epoch 24.152), train_loss = 1.13170680, grad/param norm = 2.4542e-01, time/batch = 17.8908s	
12584/26050 (epoch 24.154), train_loss = 0.76799015, grad/param norm = 1.9328e-01, time/batch = 18.5631s	
12585/26050 (epoch 24.155), train_loss = 0.81155250, grad/param norm = 1.7869e-01, time/batch = 17.6438s	
12586/26050 (epoch 24.157), train_loss = 0.93581535, grad/param norm = 2.1289e-01, time/batch = 14.8954s	
12587/26050 (epoch 24.159), train_loss = 0.98631615, grad/param norm = 2.0887e-01, time/batch = 17.8893s	
12588/26050 (epoch 24.161), train_loss = 0.99647768, grad/param norm = 2.2174e-01, time/batch = 16.5391s	
12589/26050 (epoch 24.163), train_loss = 0.80069962, grad/param norm = 1.7050e-01, time/batch = 17.9751s	
12590/26050 (epoch 24.165), train_loss = 0.75324108, grad/param norm = 1.8150e-01, time/batch = 17.4036s	
12591/26050 (epoch 24.167), train_loss = 1.08764670, grad/param norm = 2.1423e-01, time/batch = 18.9077s	
12592/26050 (epoch 24.169), train_loss = 0.97901492, grad/param norm = 2.0466e-01, time/batch = 17.6589s	
12593/26050 (epoch 24.171), train_loss = 0.81471655, grad/param norm = 1.7269e-01, time/batch = 14.8023s	
12594/26050 (epoch 24.173), train_loss = 0.91846739, grad/param norm = 1.9422e-01, time/batch = 29.0790s	
12595/26050 (epoch 24.175), train_loss = 0.93293356, grad/param norm = 1.8181e-01, time/batch = 29.0575s	
12596/26050 (epoch 24.177), train_loss = 1.04713384, grad/param norm = 1.7953e-01, time/batch = 17.5835s	
12597/26050 (epoch 24.179), train_loss = 0.71293323, grad/param norm = 1.5733e-01, time/batch = 18.2498s	
12598/26050 (epoch 24.180), train_loss = 1.15185266, grad/param norm = 1.8947e-01, time/batch = 17.1523s	
12599/26050 (epoch 24.182), train_loss = 1.18577080, grad/param norm = 2.1817e-01, time/batch = 16.2986s	
12600/26050 (epoch 24.184), train_loss = 1.00006231, grad/param norm = 1.8793e-01, time/batch = 18.7429s	
12601/26050 (epoch 24.186), train_loss = 0.78689768, grad/param norm = 1.6710e-01, time/batch = 17.5798s	
12602/26050 (epoch 24.188), train_loss = 0.96990095, grad/param norm = 1.8676e-01, time/batch = 18.2311s	
12603/26050 (epoch 24.190), train_loss = 1.00904481, grad/param norm = 2.0700e-01, time/batch = 18.1400s	
12604/26050 (epoch 24.192), train_loss = 1.01011902, grad/param norm = 1.6760e-01, time/batch = 15.2743s	
12605/26050 (epoch 24.194), train_loss = 1.00479783, grad/param norm = 1.8895e-01, time/batch = 17.2255s	
12606/26050 (epoch 24.196), train_loss = 1.04695545, grad/param norm = 1.9647e-01, time/batch = 16.7034s	
12607/26050 (epoch 24.198), train_loss = 0.88062697, grad/param norm = 1.7266e-01, time/batch = 18.3190s	
12608/26050 (epoch 24.200), train_loss = 0.87269490, grad/param norm = 1.8466e-01, time/batch = 18.3034s	
12609/26050 (epoch 24.202), train_loss = 0.97399186, grad/param norm = 1.7634e-01, time/batch = 16.6468s	
12610/26050 (epoch 24.203), train_loss = 1.07597697, grad/param norm = 1.9262e-01, time/batch = 17.9046s	
12611/26050 (epoch 24.205), train_loss = 0.92150202, grad/param norm = 1.9953e-01, time/batch = 15.8623s	
12612/26050 (epoch 24.207), train_loss = 0.89286184, grad/param norm = 1.8275e-01, time/batch = 18.4861s	
12613/26050 (epoch 24.209), train_loss = 1.02526338, grad/param norm = 1.9032e-01, time/batch = 17.5531s	
12614/26050 (epoch 24.211), train_loss = 0.80484867, grad/param norm = 1.6718e-01, time/batch = 15.9719s	
12615/26050 (epoch 24.213), train_loss = 1.00119562, grad/param norm = 1.9856e-01, time/batch = 18.7258s	
12616/26050 (epoch 24.215), train_loss = 0.94942931, grad/param norm = 2.2191e-01, time/batch = 17.3953s	
12617/26050 (epoch 24.217), train_loss = 0.91985642, grad/param norm = 1.7607e-01, time/batch = 17.2335s	
12618/26050 (epoch 24.219), train_loss = 0.92930126, grad/param norm = 1.8844e-01, time/batch = 17.2331s	
12619/26050 (epoch 24.221), train_loss = 0.88345312, grad/param norm = 2.2357e-01, time/batch = 18.9022s	
12620/26050 (epoch 24.223), train_loss = 0.99990367, grad/param norm = 1.9387e-01, time/batch = 17.8994s	
12621/26050 (epoch 24.225), train_loss = 0.86374736, grad/param norm = 1.8442e-01, time/batch = 18.3255s	
12622/26050 (epoch 24.226), train_loss = 1.00488650, grad/param norm = 2.1003e-01, time/batch = 18.4899s	
12623/26050 (epoch 24.228), train_loss = 1.09457268, grad/param norm = 1.9114e-01, time/batch = 14.9809s	
12624/26050 (epoch 24.230), train_loss = 0.98493055, grad/param norm = 1.8498e-01, time/batch = 18.5505s	
12625/26050 (epoch 24.232), train_loss = 1.04799646, grad/param norm = 2.0888e-01, time/batch = 15.2983s	
12626/26050 (epoch 24.234), train_loss = 0.84972389, grad/param norm = 1.7266e-01, time/batch = 17.6526s	
12627/26050 (epoch 24.236), train_loss = 1.04906352, grad/param norm = 1.8339e-01, time/batch = 17.6477s	
12628/26050 (epoch 24.238), train_loss = 0.84661259, grad/param norm = 1.9107e-01, time/batch = 16.6438s	
12629/26050 (epoch 24.240), train_loss = 0.96767129, grad/param norm = 1.9471e-01, time/batch = 18.2426s	
12630/26050 (epoch 24.242), train_loss = 0.93562967, grad/param norm = 1.7611e-01, time/batch = 17.5670s	
12631/26050 (epoch 24.244), train_loss = 0.97867572, grad/param norm = 2.0929e-01, time/batch = 16.8830s	
12632/26050 (epoch 24.246), train_loss = 0.88243899, grad/param norm = 1.8294e-01, time/batch = 16.3991s	
12633/26050 (epoch 24.248), train_loss = 0.97872365, grad/param norm = 1.9917e-01, time/batch = 17.4033s	
12634/26050 (epoch 24.250), train_loss = 0.95760066, grad/param norm = 2.2165e-01, time/batch = 18.3922s	
12635/26050 (epoch 24.251), train_loss = 0.91761314, grad/param norm = 1.7199e-01, time/batch = 18.0599s	
12636/26050 (epoch 24.253), train_loss = 0.85936067, grad/param norm = 1.7518e-01, time/batch = 18.1473s	
12637/26050 (epoch 24.255), train_loss = 1.11899626, grad/param norm = 1.9440e-01, time/batch = 17.4029s	
12638/26050 (epoch 24.257), train_loss = 0.95434731, grad/param norm = 1.9527e-01, time/batch = 16.2152s	
12639/26050 (epoch 24.259), train_loss = 1.08137572, grad/param norm = 1.9206e-01, time/batch = 18.4947s	
12640/26050 (epoch 24.261), train_loss = 0.86119821, grad/param norm = 1.8237e-01, time/batch = 17.4726s	
12641/26050 (epoch 24.263), train_loss = 1.03723502, grad/param norm = 2.0694e-01, time/batch = 17.9127s	
12642/26050 (epoch 24.265), train_loss = 1.11438687, grad/param norm = 2.1380e-01, time/batch = 18.4923s	
12643/26050 (epoch 24.267), train_loss = 1.07007965, grad/param norm = 1.7482e-01, time/batch = 17.4057s	
12644/26050 (epoch 24.269), train_loss = 1.07884379, grad/param norm = 1.9653e-01, time/batch = 18.1505s	
12645/26050 (epoch 24.271), train_loss = 1.00164904, grad/param norm = 1.9840e-01, time/batch = 18.0593s	
12646/26050 (epoch 24.273), train_loss = 0.91121777, grad/param norm = 2.3071e-01, time/batch = 17.0666s	
12647/26050 (epoch 24.274), train_loss = 0.94947320, grad/param norm = 1.6650e-01, time/batch = 16.1370s	
12648/26050 (epoch 24.276), train_loss = 0.92836674, grad/param norm = 1.9302e-01, time/batch = 15.6546s	
12649/26050 (epoch 24.278), train_loss = 1.08154367, grad/param norm = 1.9923e-01, time/batch = 17.7936s	
12650/26050 (epoch 24.280), train_loss = 0.95514543, grad/param norm = 1.7928e-01, time/batch = 18.1537s	
12651/26050 (epoch 24.282), train_loss = 1.00536377, grad/param norm = 1.9256e-01, time/batch = 17.5736s	
12652/26050 (epoch 24.284), train_loss = 0.95412367, grad/param norm = 1.8551e-01, time/batch = 17.7461s	
12653/26050 (epoch 24.286), train_loss = 0.98085885, grad/param norm = 2.0873e-01, time/batch = 16.6247s	
12654/26050 (epoch 24.288), train_loss = 0.82462291, grad/param norm = 1.7774e-01, time/batch = 17.0034s	
12655/26050 (epoch 24.290), train_loss = 0.97586795, grad/param norm = 1.9436e-01, time/batch = 17.6470s	
12656/26050 (epoch 24.292), train_loss = 0.88411568, grad/param norm = 1.6437e-01, time/batch = 18.0783s	
12657/26050 (epoch 24.294), train_loss = 0.96615199, grad/param norm = 1.9732e-01, time/batch = 17.2859s	
12658/26050 (epoch 24.296), train_loss = 1.06386918, grad/param norm = 1.8837e-01, time/batch = 18.0655s	
12659/26050 (epoch 24.298), train_loss = 0.98830554, grad/param norm = 1.8309e-01, time/batch = 18.1465s	
12660/26050 (epoch 24.299), train_loss = 0.80078147, grad/param norm = 1.5924e-01, time/batch = 17.3191s	
12661/26050 (epoch 24.301), train_loss = 0.82453881, grad/param norm = 1.7418e-01, time/batch = 18.1305s	
12662/26050 (epoch 24.303), train_loss = 0.96409055, grad/param norm = 2.0889e-01, time/batch = 18.4798s	
12663/26050 (epoch 24.305), train_loss = 0.79704335, grad/param norm = 1.9130e-01, time/batch = 18.8992s	
12664/26050 (epoch 24.307), train_loss = 0.89478199, grad/param norm = 1.8633e-01, time/batch = 17.2316s	
12665/26050 (epoch 24.309), train_loss = 0.94195035, grad/param norm = 1.7937e-01, time/batch = 18.0659s	
12666/26050 (epoch 24.311), train_loss = 1.04689923, grad/param norm = 2.5114e-01, time/batch = 18.0688s	
12667/26050 (epoch 24.313), train_loss = 0.96729493, grad/param norm = 2.1405e-01, time/batch = 15.6404s	
12668/26050 (epoch 24.315), train_loss = 1.04178344, grad/param norm = 2.0110e-01, time/batch = 16.6506s	
12669/26050 (epoch 24.317), train_loss = 0.99027589, grad/param norm = 1.9800e-01, time/batch = 15.3905s	
12670/26050 (epoch 24.319), train_loss = 0.86931064, grad/param norm = 1.6969e-01, time/batch = 18.6564s	
12671/26050 (epoch 24.321), train_loss = 0.93637194, grad/param norm = 1.9127e-01, time/batch = 15.8073s	
12672/26050 (epoch 24.322), train_loss = 0.99169623, grad/param norm = 1.7222e-01, time/batch = 17.8541s	
12673/26050 (epoch 24.324), train_loss = 0.79230827, grad/param norm = 1.7128e-01, time/batch = 17.2003s	
12674/26050 (epoch 24.326), train_loss = 1.09383423, grad/param norm = 1.9982e-01, time/batch = 17.9784s	
12675/26050 (epoch 24.328), train_loss = 0.97917514, grad/param norm = 1.7891e-01, time/batch = 18.0732s	
12676/26050 (epoch 24.330), train_loss = 0.83996993, grad/param norm = 1.7495e-01, time/batch = 18.4880s	
12677/26050 (epoch 24.332), train_loss = 1.02876355, grad/param norm = 2.0376e-01, time/batch = 15.3180s	
12678/26050 (epoch 24.334), train_loss = 0.89890404, grad/param norm = 1.9302e-01, time/batch = 17.2996s	
12679/26050 (epoch 24.336), train_loss = 0.92257586, grad/param norm = 2.1023e-01, time/batch = 18.3221s	
12680/26050 (epoch 24.338), train_loss = 0.84903594, grad/param norm = 1.7156e-01, time/batch = 18.2373s	
12681/26050 (epoch 24.340), train_loss = 1.03929972, grad/param norm = 2.1064e-01, time/batch = 17.3128s	
12682/26050 (epoch 24.342), train_loss = 1.06100108, grad/param norm = 2.1050e-01, time/batch = 18.6542s	
12683/26050 (epoch 24.344), train_loss = 0.89059403, grad/param norm = 1.9997e-01, time/batch = 18.4029s	
12684/26050 (epoch 24.345), train_loss = 0.97604497, grad/param norm = 2.0645e-01, time/batch = 17.6584s	
12685/26050 (epoch 24.347), train_loss = 1.07424429, grad/param norm = 1.8863e-01, time/batch = 18.1441s	
12686/26050 (epoch 24.349), train_loss = 1.00456575, grad/param norm = 1.9434e-01, time/batch = 14.6787s	
12687/26050 (epoch 24.351), train_loss = 1.02318171, grad/param norm = 2.0236e-01, time/batch = 18.5581s	
12688/26050 (epoch 24.353), train_loss = 0.98350611, grad/param norm = 2.0434e-01, time/batch = 16.5736s	
12689/26050 (epoch 24.355), train_loss = 1.00215881, grad/param norm = 2.2078e-01, time/batch = 18.7329s	
12690/26050 (epoch 24.357), train_loss = 0.89514341, grad/param norm = 1.7258e-01, time/batch = 18.6451s	
12691/26050 (epoch 24.359), train_loss = 1.07180465, grad/param norm = 1.9524e-01, time/batch = 17.8953s	
12692/26050 (epoch 24.361), train_loss = 0.87918192, grad/param norm = 1.6714e-01, time/batch = 17.6347s	
12693/26050 (epoch 24.363), train_loss = 1.03080388, grad/param norm = 1.8557e-01, time/batch = 18.6412s	
12694/26050 (epoch 24.365), train_loss = 0.93460156, grad/param norm = 1.7039e-01, time/batch = 17.4780s	
12695/26050 (epoch 24.367), train_loss = 1.03299557, grad/param norm = 1.7836e-01, time/batch = 17.2402s	
12696/26050 (epoch 24.369), train_loss = 0.89735506, grad/param norm = 1.7173e-01, time/batch = 18.6477s	
12697/26050 (epoch 24.370), train_loss = 0.85445084, grad/param norm = 1.6218e-01, time/batch = 17.0493s	
12698/26050 (epoch 24.372), train_loss = 0.99159309, grad/param norm = 1.9205e-01, time/batch = 14.6348s	
12699/26050 (epoch 24.374), train_loss = 1.09332595, grad/param norm = 1.9125e-01, time/batch = 17.8896s	
12700/26050 (epoch 24.376), train_loss = 1.15707869, grad/param norm = 2.3068e-01, time/batch = 18.2393s	
12701/26050 (epoch 24.378), train_loss = 0.90317945, grad/param norm = 1.6131e-01, time/batch = 15.8798s	
12702/26050 (epoch 24.380), train_loss = 1.12931633, grad/param norm = 2.2337e-01, time/batch = 17.8275s	
12703/26050 (epoch 24.382), train_loss = 1.25921927, grad/param norm = 2.6895e-01, time/batch = 18.0703s	
12704/26050 (epoch 24.384), train_loss = 0.96397173, grad/param norm = 2.1036e-01, time/batch = 18.7982s	
12705/26050 (epoch 24.386), train_loss = 1.03722080, grad/param norm = 2.3662e-01, time/batch = 17.8089s	
12706/26050 (epoch 24.388), train_loss = 0.98330487, grad/param norm = 2.1120e-01, time/batch = 17.4978s	
12707/26050 (epoch 24.390), train_loss = 0.92102580, grad/param norm = 1.8841e-01, time/batch = 16.5576s	
12708/26050 (epoch 24.392), train_loss = 0.85113247, grad/param norm = 1.6294e-01, time/batch = 17.8312s	
12709/26050 (epoch 24.393), train_loss = 1.02414921, grad/param norm = 2.1915e-01, time/batch = 16.3929s	
12710/26050 (epoch 24.395), train_loss = 1.03003496, grad/param norm = 1.8933e-01, time/batch = 17.5553s	
12711/26050 (epoch 24.397), train_loss = 1.04412480, grad/param norm = 2.1361e-01, time/batch = 16.1279s	
12712/26050 (epoch 24.399), train_loss = 0.93020536, grad/param norm = 1.9978e-01, time/batch = 16.8681s	
12713/26050 (epoch 24.401), train_loss = 1.00133936, grad/param norm = 1.9871e-01, time/batch = 18.0712s	
12714/26050 (epoch 24.403), train_loss = 0.98694889, grad/param norm = 1.9956e-01, time/batch = 18.2401s	
12715/26050 (epoch 24.405), train_loss = 0.98091570, grad/param norm = 1.9103e-01, time/batch = 16.9130s	
12716/26050 (epoch 24.407), train_loss = 1.12622439, grad/param norm = 2.0494e-01, time/batch = 18.3144s	
12717/26050 (epoch 24.409), train_loss = 1.11254942, grad/param norm = 2.0146e-01, time/batch = 14.9771s	
12718/26050 (epoch 24.411), train_loss = 1.03011211, grad/param norm = 1.8831e-01, time/batch = 18.1590s	
12719/26050 (epoch 24.413), train_loss = 1.12370495, grad/param norm = 1.7974e-01, time/batch = 18.1428s	
12720/26050 (epoch 24.415), train_loss = 1.12791218, grad/param norm = 3.3100e-01, time/batch = 17.8187s	
12721/26050 (epoch 24.417), train_loss = 1.20609345, grad/param norm = 2.1880e-01, time/batch = 18.1586s	
12722/26050 (epoch 24.418), train_loss = 1.08695601, grad/param norm = 2.2295e-01, time/batch = 16.9958s	
12723/26050 (epoch 24.420), train_loss = 0.83842878, grad/param norm = 1.7800e-01, time/batch = 16.3908s	
12724/26050 (epoch 24.422), train_loss = 0.83362041, grad/param norm = 1.8718e-01, time/batch = 18.1387s	
12725/26050 (epoch 24.424), train_loss = 1.12858521, grad/param norm = 2.2409e-01, time/batch = 15.3207s	
12726/26050 (epoch 24.426), train_loss = 1.07838154, grad/param norm = 1.9300e-01, time/batch = 17.6480s	
12727/26050 (epoch 24.428), train_loss = 0.93561581, grad/param norm = 1.6769e-01, time/batch = 14.7954s	
12728/26050 (epoch 24.430), train_loss = 1.10973100, grad/param norm = 1.8489e-01, time/batch = 18.3296s	
12729/26050 (epoch 24.432), train_loss = 0.96280169, grad/param norm = 1.8814e-01, time/batch = 16.1505s	
12730/26050 (epoch 24.434), train_loss = 0.97339481, grad/param norm = 1.8729e-01, time/batch = 17.8272s	
12731/26050 (epoch 24.436), train_loss = 1.11586775, grad/param norm = 2.0384e-01, time/batch = 18.2330s	
12732/26050 (epoch 24.438), train_loss = 1.05504020, grad/param norm = 1.8971e-01, time/batch = 17.3432s	
12733/26050 (epoch 24.440), train_loss = 1.00990696, grad/param norm = 1.9904e-01, time/batch = 15.4638s	
12734/26050 (epoch 24.441), train_loss = 0.98843248, grad/param norm = 1.8457e-01, time/batch = 18.3922s	
12735/26050 (epoch 24.443), train_loss = 0.83865912, grad/param norm = 1.4938e-01, time/batch = 18.6523s	
12736/26050 (epoch 24.445), train_loss = 0.90621867, grad/param norm = 1.7333e-01, time/batch = 17.4846s	
12737/26050 (epoch 24.447), train_loss = 1.09491387, grad/param norm = 2.1151e-01, time/batch = 16.3897s	
12738/26050 (epoch 24.449), train_loss = 0.90005146, grad/param norm = 1.7534e-01, time/batch = 18.3139s	
12739/26050 (epoch 24.451), train_loss = 1.13886430, grad/param norm = 1.9383e-01, time/batch = 17.3914s	
12740/26050 (epoch 24.453), train_loss = 0.91996328, grad/param norm = 1.7262e-01, time/batch = 18.6340s	
12741/26050 (epoch 24.455), train_loss = 0.99525910, grad/param norm = 1.9196e-01, time/batch = 18.2348s	
12742/26050 (epoch 24.457), train_loss = 0.97033743, grad/param norm = 1.8491e-01, time/batch = 15.4714s	
12743/26050 (epoch 24.459), train_loss = 1.07544036, grad/param norm = 1.9946e-01, time/batch = 15.9635s	
12744/26050 (epoch 24.461), train_loss = 1.07676431, grad/param norm = 2.1419e-01, time/batch = 16.8778s	
12745/26050 (epoch 24.463), train_loss = 0.94342255, grad/param norm = 1.7499e-01, time/batch = 15.3067s	
12746/26050 (epoch 24.464), train_loss = 1.01757335, grad/param norm = 1.7842e-01, time/batch = 17.0769s	
12747/26050 (epoch 24.466), train_loss = 1.05426263, grad/param norm = 2.0072e-01, time/batch = 18.3187s	
12748/26050 (epoch 24.468), train_loss = 1.08568238, grad/param norm = 1.7289e-01, time/batch = 18.9165s	
12749/26050 (epoch 24.470), train_loss = 1.09790953, grad/param norm = 2.3161e-01, time/batch = 17.8256s	
12750/26050 (epoch 24.472), train_loss = 1.12590487, grad/param norm = 2.1755e-01, time/batch = 16.4757s	
12751/26050 (epoch 24.474), train_loss = 1.12496817, grad/param norm = 1.8694e-01, time/batch = 14.7250s	
12752/26050 (epoch 24.476), train_loss = 1.12260388, grad/param norm = 1.9929e-01, time/batch = 18.1464s	
12753/26050 (epoch 24.478), train_loss = 0.96806411, grad/param norm = 1.7370e-01, time/batch = 17.8952s	
12754/26050 (epoch 24.480), train_loss = 0.98993749, grad/param norm = 1.9094e-01, time/batch = 18.3302s	
12755/26050 (epoch 24.482), train_loss = 0.94446795, grad/param norm = 1.8233e-01, time/batch = 17.5681s	
12756/26050 (epoch 24.484), train_loss = 0.92776683, grad/param norm = 1.8227e-01, time/batch = 18.4969s	
12757/26050 (epoch 24.486), train_loss = 1.11573743, grad/param norm = 1.8457e-01, time/batch = 18.1444s	
12758/26050 (epoch 24.488), train_loss = 1.22626897, grad/param norm = 2.2369e-01, time/batch = 18.0755s	
12759/26050 (epoch 24.489), train_loss = 1.15360787, grad/param norm = 2.3391e-01, time/batch = 17.0480s	
12760/26050 (epoch 24.491), train_loss = 0.93856702, grad/param norm = 2.1727e-01, time/batch = 17.4099s	
12761/26050 (epoch 24.493), train_loss = 1.00412734, grad/param norm = 1.8828e-01, time/batch = 15.4668s	
12762/26050 (epoch 24.495), train_loss = 0.96981609, grad/param norm = 1.7761e-01, time/batch = 18.4836s	
12763/26050 (epoch 24.497), train_loss = 0.90184460, grad/param norm = 1.8148e-01, time/batch = 17.6438s	
12764/26050 (epoch 24.499), train_loss = 0.95992849, grad/param norm = 1.8782e-01, time/batch = 16.6511s	
12765/26050 (epoch 24.501), train_loss = 1.06307439, grad/param norm = 2.0587e-01, time/batch = 16.4846s	
12766/26050 (epoch 24.503), train_loss = 0.93982556, grad/param norm = 1.7953e-01, time/batch = 18.7531s	
12767/26050 (epoch 24.505), train_loss = 1.10695387, grad/param norm = 1.8732e-01, time/batch = 17.4826s	
12768/26050 (epoch 24.507), train_loss = 1.05936599, grad/param norm = 2.0187e-01, time/batch = 17.5606s	
12769/26050 (epoch 24.509), train_loss = 1.15730498, grad/param norm = 1.9163e-01, time/batch = 18.8185s	
12770/26050 (epoch 24.511), train_loss = 0.94525562, grad/param norm = 1.7037e-01, time/batch = 18.3028s	
12771/26050 (epoch 24.512), train_loss = 0.88707664, grad/param norm = 1.9869e-01, time/batch = 17.3178s	
12772/26050 (epoch 24.514), train_loss = 1.06072774, grad/param norm = 2.2155e-01, time/batch = 18.0709s	
12773/26050 (epoch 24.516), train_loss = 1.12009528, grad/param norm = 2.6500e-01, time/batch = 18.2334s	
12774/26050 (epoch 24.518), train_loss = 1.00511467, grad/param norm = 1.9714e-01, time/batch = 18.4148s	
12775/26050 (epoch 24.520), train_loss = 0.98011666, grad/param norm = 1.9218e-01, time/batch = 15.7074s	
12776/26050 (epoch 24.522), train_loss = 0.77725439, grad/param norm = 1.7426e-01, time/batch = 17.4076s	
12777/26050 (epoch 24.524), train_loss = 1.07241849, grad/param norm = 2.4498e-01, time/batch = 17.7268s	
12778/26050 (epoch 24.526), train_loss = 1.09917304, grad/param norm = 2.1956e-01, time/batch = 18.8091s	
12779/26050 (epoch 24.528), train_loss = 1.04592770, grad/param norm = 2.1822e-01, time/batch = 18.1549s	
12780/26050 (epoch 24.530), train_loss = 0.95506093, grad/param norm = 2.0161e-01, time/batch = 16.6389s	
12781/26050 (epoch 24.532), train_loss = 1.02252018, grad/param norm = 1.8693e-01, time/batch = 17.9687s	
12782/26050 (epoch 24.534), train_loss = 1.05694143, grad/param norm = 2.3934e-01, time/batch = 18.7486s	
12783/26050 (epoch 24.536), train_loss = 0.99649247, grad/param norm = 1.8187e-01, time/batch = 18.4840s	
12784/26050 (epoch 24.537), train_loss = 1.06363150, grad/param norm = 2.1304e-01, time/batch = 18.3084s	
12785/26050 (epoch 24.539), train_loss = 0.99519361, grad/param norm = 1.8627e-01, time/batch = 18.3193s	
12786/26050 (epoch 24.541), train_loss = 1.17816235, grad/param norm = 2.2998e-01, time/batch = 14.9050s	
12787/26050 (epoch 24.543), train_loss = 0.85097288, grad/param norm = 1.9371e-01, time/batch = 17.7335s	
12788/26050 (epoch 24.545), train_loss = 1.02788946, grad/param norm = 1.8895e-01, time/batch = 18.3049s	
12789/26050 (epoch 24.547), train_loss = 0.96778159, grad/param norm = 1.8771e-01, time/batch = 18.3944s	
12790/26050 (epoch 24.549), train_loss = 0.83445850, grad/param norm = 1.8415e-01, time/batch = 16.1183s	
12791/26050 (epoch 24.551), train_loss = 1.05667360, grad/param norm = 1.9170e-01, time/batch = 18.1270s	
12792/26050 (epoch 24.553), train_loss = 0.93539695, grad/param norm = 1.8322e-01, time/batch = 16.6571s	
12793/26050 (epoch 24.555), train_loss = 0.90646663, grad/param norm = 1.7468e-01, time/batch = 18.8093s	
12794/26050 (epoch 24.557), train_loss = 1.02343796, grad/param norm = 1.7630e-01, time/batch = 17.2434s	
12795/26050 (epoch 24.559), train_loss = 0.98393795, grad/param norm = 1.9393e-01, time/batch = 18.4022s	
12796/26050 (epoch 24.560), train_loss = 0.96870527, grad/param norm = 1.9461e-01, time/batch = 17.5533s	
12797/26050 (epoch 24.562), train_loss = 0.98258863, grad/param norm = 1.9867e-01, time/batch = 19.6939s	
12798/26050 (epoch 24.564), train_loss = 1.16343712, grad/param norm = 1.9397e-01, time/batch = 35.4488s	
12799/26050 (epoch 24.566), train_loss = 0.89976683, grad/param norm = 1.7588e-01, time/batch = 16.8877s	
12800/26050 (epoch 24.568), train_loss = 1.02285059, grad/param norm = 1.7987e-01, time/batch = 18.1500s	
12801/26050 (epoch 24.570), train_loss = 1.04127622, grad/param norm = 2.0739e-01, time/batch = 15.3062s	
12802/26050 (epoch 24.572), train_loss = 0.95152990, grad/param norm = 1.9018e-01, time/batch = 18.2464s	
12803/26050 (epoch 24.574), train_loss = 0.99887977, grad/param norm = 2.1661e-01, time/batch = 17.7410s	
12804/26050 (epoch 24.576), train_loss = 1.03522617, grad/param norm = 2.1699e-01, time/batch = 17.9025s	
12805/26050 (epoch 24.578), train_loss = 0.96565958, grad/param norm = 1.8902e-01, time/batch = 18.0868s	
12806/26050 (epoch 24.580), train_loss = 0.92416680, grad/param norm = 1.9495e-01, time/batch = 17.3994s	
12807/26050 (epoch 24.582), train_loss = 1.01252598, grad/param norm = 1.8545e-01, time/batch = 16.3879s	
12808/26050 (epoch 24.583), train_loss = 1.08436372, grad/param norm = 1.8322e-01, time/batch = 17.8805s	
12809/26050 (epoch 24.585), train_loss = 0.86633416, grad/param norm = 1.9339e-01, time/batch = 16.3868s	
12810/26050 (epoch 24.587), train_loss = 1.04958395, grad/param norm = 2.0360e-01, time/batch = 17.4732s	
12811/26050 (epoch 24.589), train_loss = 1.14039910, grad/param norm = 2.1392e-01, time/batch = 17.7282s	
12812/26050 (epoch 24.591), train_loss = 0.97804326, grad/param norm = 1.8171e-01, time/batch = 16.0523s	
12813/26050 (epoch 24.593), train_loss = 0.87434148, grad/param norm = 1.8570e-01, time/batch = 16.9645s	
12814/26050 (epoch 24.595), train_loss = 1.05247201, grad/param norm = 2.0040e-01, time/batch = 17.4612s	
12815/26050 (epoch 24.597), train_loss = 1.00564543, grad/param norm = 1.8762e-01, time/batch = 18.5733s	
12816/26050 (epoch 24.599), train_loss = 1.01180526, grad/param norm = 1.8066e-01, time/batch = 18.4085s	
12817/26050 (epoch 24.601), train_loss = 1.17850668, grad/param norm = 2.0745e-01, time/batch = 17.9823s	
12818/26050 (epoch 24.603), train_loss = 1.01416738, grad/param norm = 1.9402e-01, time/batch = 18.4734s	
12819/26050 (epoch 24.605), train_loss = 0.95735211, grad/param norm = 2.0083e-01, time/batch = 18.0681s	
12820/26050 (epoch 24.607), train_loss = 1.09733312, grad/param norm = 2.0110e-01, time/batch = 17.2428s	
12821/26050 (epoch 24.608), train_loss = 0.88533142, grad/param norm = 1.7508e-01, time/batch = 16.3809s	
12822/26050 (epoch 24.610), train_loss = 0.97683898, grad/param norm = 2.0231e-01, time/batch = 17.2417s	
12823/26050 (epoch 24.612), train_loss = 0.96371532, grad/param norm = 1.8957e-01, time/batch = 15.7420s	
12824/26050 (epoch 24.614), train_loss = 0.99461447, grad/param norm = 1.8351e-01, time/batch = 18.3314s	
12825/26050 (epoch 24.616), train_loss = 1.10765169, grad/param norm = 2.2215e-01, time/batch = 16.4087s	
12826/26050 (epoch 24.618), train_loss = 0.94485858, grad/param norm = 1.8910e-01, time/batch = 17.1286s	
12827/26050 (epoch 24.620), train_loss = 1.04017211, grad/param norm = 1.8051e-01, time/batch = 17.4843s	
12828/26050 (epoch 24.622), train_loss = 0.87305071, grad/param norm = 1.5831e-01, time/batch = 17.9149s	
12829/26050 (epoch 24.624), train_loss = 0.83910362, grad/param norm = 1.7376e-01, time/batch = 18.3994s	
12830/26050 (epoch 24.626), train_loss = 1.06182525, grad/param norm = 1.9751e-01, time/batch = 16.3172s	
12831/26050 (epoch 24.628), train_loss = 0.93045169, grad/param norm = 1.9532e-01, time/batch = 18.7445s	
12832/26050 (epoch 24.630), train_loss = 1.12066351, grad/param norm = 1.8862e-01, time/batch = 18.1616s	
12833/26050 (epoch 24.631), train_loss = 1.16153654, grad/param norm = 2.0469e-01, time/batch = 16.2845s	
12834/26050 (epoch 24.633), train_loss = 0.88853010, grad/param norm = 1.8696e-01, time/batch = 17.9909s	
12835/26050 (epoch 24.635), train_loss = 0.91579782, grad/param norm = 1.6475e-01, time/batch = 18.9897s	
12836/26050 (epoch 24.637), train_loss = 0.88184689, grad/param norm = 1.7297e-01, time/batch = 18.8205s	
12837/26050 (epoch 24.639), train_loss = 1.07203107, grad/param norm = 1.9565e-01, time/batch = 17.7267s	
12838/26050 (epoch 24.641), train_loss = 0.94972854, grad/param norm = 1.8846e-01, time/batch = 17.8150s	
12839/26050 (epoch 24.643), train_loss = 0.89077037, grad/param norm = 1.6782e-01, time/batch = 18.2288s	
12840/26050 (epoch 24.645), train_loss = 0.95257564, grad/param norm = 1.8973e-01, time/batch = 17.3004s	
12841/26050 (epoch 24.647), train_loss = 0.94167486, grad/param norm = 1.9131e-01, time/batch = 15.9329s	
12842/26050 (epoch 24.649), train_loss = 0.98537395, grad/param norm = 1.9808e-01, time/batch = 18.3087s	
12843/26050 (epoch 24.651), train_loss = 0.94125360, grad/param norm = 1.7754e-01, time/batch = 18.1530s	
12844/26050 (epoch 24.653), train_loss = 0.98134704, grad/param norm = 1.9052e-01, time/batch = 18.2166s	
12845/26050 (epoch 24.655), train_loss = 0.90464095, grad/param norm = 1.7532e-01, time/batch = 16.5535s	
12846/26050 (epoch 24.656), train_loss = 0.84303217, grad/param norm = 1.6266e-01, time/batch = 17.1432s	
12847/26050 (epoch 24.658), train_loss = 1.16026003, grad/param norm = 2.0565e-01, time/batch = 17.0577s	
12848/26050 (epoch 24.660), train_loss = 0.85705470, grad/param norm = 1.8728e-01, time/batch = 18.7232s	
12849/26050 (epoch 24.662), train_loss = 0.97148365, grad/param norm = 1.9699e-01, time/batch = 16.7220s	
12850/26050 (epoch 24.664), train_loss = 0.96301770, grad/param norm = 1.9315e-01, time/batch = 15.9702s	
12851/26050 (epoch 24.666), train_loss = 0.91408025, grad/param norm = 1.9243e-01, time/batch = 19.0605s	
12852/26050 (epoch 24.668), train_loss = 0.82581635, grad/param norm = 2.1293e-01, time/batch = 17.7425s	
12853/26050 (epoch 24.670), train_loss = 1.11230802, grad/param norm = 2.3014e-01, time/batch = 18.8240s	
12854/26050 (epoch 24.672), train_loss = 0.98117969, grad/param norm = 1.8975e-01, time/batch = 17.5739s	
12855/26050 (epoch 24.674), train_loss = 0.90329121, grad/param norm = 1.9680e-01, time/batch = 17.0477s	
12856/26050 (epoch 24.676), train_loss = 1.05880871, grad/param norm = 2.0066e-01, time/batch = 15.1404s	
12857/26050 (epoch 24.678), train_loss = 1.10691484, grad/param norm = 2.1355e-01, time/batch = 18.2327s	
12858/26050 (epoch 24.679), train_loss = 1.16005815, grad/param norm = 2.2014e-01, time/batch = 18.0568s	
12859/26050 (epoch 24.681), train_loss = 0.99263918, grad/param norm = 1.9625e-01, time/batch = 18.0611s	
12860/26050 (epoch 24.683), train_loss = 0.88906055, grad/param norm = 2.6979e-01, time/batch = 18.0733s	
12861/26050 (epoch 24.685), train_loss = 0.95408940, grad/param norm = 1.8523e-01, time/batch = 18.5537s	
12862/26050 (epoch 24.687), train_loss = 0.85795035, grad/param norm = 1.8300e-01, time/batch = 18.0460s	
12863/26050 (epoch 24.689), train_loss = 0.96595720, grad/param norm = 2.0766e-01, time/batch = 18.6525s	
12864/26050 (epoch 24.691), train_loss = 0.79795276, grad/param norm = 1.6930e-01, time/batch = 16.3101s	
12865/26050 (epoch 24.693), train_loss = 0.89145294, grad/param norm = 1.8027e-01, time/batch = 18.3112s	
12866/26050 (epoch 24.695), train_loss = 0.97949188, grad/param norm = 1.8435e-01, time/batch = 18.4697s	
12867/26050 (epoch 24.697), train_loss = 0.89976789, grad/param norm = 1.7754e-01, time/batch = 16.3904s	
12868/26050 (epoch 24.699), train_loss = 1.04613315, grad/param norm = 2.1986e-01, time/batch = 17.5591s	
12869/26050 (epoch 24.701), train_loss = 0.87296100, grad/param norm = 1.5056e-01, time/batch = 19.0685s	
12870/26050 (epoch 24.702), train_loss = 1.08189534, grad/param norm = 1.9600e-01, time/batch = 15.3868s	
12871/26050 (epoch 24.704), train_loss = 1.07140586, grad/param norm = 1.7869e-01, time/batch = 15.3124s	
12872/26050 (epoch 24.706), train_loss = 0.93415997, grad/param norm = 1.9532e-01, time/batch = 17.2244s	
12873/26050 (epoch 24.708), train_loss = 1.05871691, grad/param norm = 2.0438e-01, time/batch = 18.3883s	
12874/26050 (epoch 24.710), train_loss = 1.03272517, grad/param norm = 2.1080e-01, time/batch = 17.5620s	
12875/26050 (epoch 24.712), train_loss = 0.99707850, grad/param norm = 1.9186e-01, time/batch = 17.2870s	
12876/26050 (epoch 24.714), train_loss = 0.85261558, grad/param norm = 1.6948e-01, time/batch = 18.6489s	
12877/26050 (epoch 24.716), train_loss = 1.23251607, grad/param norm = 2.2362e-01, time/batch = 18.4878s	
12878/26050 (epoch 24.718), train_loss = 1.05598363, grad/param norm = 1.9377e-01, time/batch = 17.3151s	
12879/26050 (epoch 24.720), train_loss = 0.98126529, grad/param norm = 2.0153e-01, time/batch = 15.9809s	
12880/26050 (epoch 24.722), train_loss = 0.86070129, grad/param norm = 1.6933e-01, time/batch = 18.6406s	
12881/26050 (epoch 24.724), train_loss = 0.90543726, grad/param norm = 2.0794e-01, time/batch = 17.1304s	
12882/26050 (epoch 24.726), train_loss = 1.03564036, grad/param norm = 2.0062e-01, time/batch = 18.1380s	
12883/26050 (epoch 24.727), train_loss = 1.03594863, grad/param norm = 1.9882e-01, time/batch = 15.9450s	
12884/26050 (epoch 24.729), train_loss = 1.02929941, grad/param norm = 1.8556e-01, time/batch = 18.6399s	
12885/26050 (epoch 24.731), train_loss = 1.02412294, grad/param norm = 1.8894e-01, time/batch = 18.1545s	
12886/26050 (epoch 24.733), train_loss = 0.94745910, grad/param norm = 2.1684e-01, time/batch = 17.9791s	
12887/26050 (epoch 24.735), train_loss = 1.17828927, grad/param norm = 2.1647e-01, time/batch = 18.7217s	
12888/26050 (epoch 24.737), train_loss = 0.91864175, grad/param norm = 1.9064e-01, time/batch = 15.0434s	
12889/26050 (epoch 24.739), train_loss = 1.01227819, grad/param norm = 1.8541e-01, time/batch = 18.4941s	
12890/26050 (epoch 24.741), train_loss = 0.91546548, grad/param norm = 1.8285e-01, time/batch = 14.2270s	
12891/26050 (epoch 24.743), train_loss = 1.00951561, grad/param norm = 2.4469e-01, time/batch = 17.9845s	
12892/26050 (epoch 24.745), train_loss = 0.86609085, grad/param norm = 1.9015e-01, time/batch = 17.7382s	
12893/26050 (epoch 24.747), train_loss = 0.90261571, grad/param norm = 1.7401e-01, time/batch = 18.3278s	
12894/26050 (epoch 24.749), train_loss = 1.10453484, grad/param norm = 2.0864e-01, time/batch = 18.0787s	
12895/26050 (epoch 24.750), train_loss = 0.99505120, grad/param norm = 1.7579e-01, time/batch = 16.3707s	
12896/26050 (epoch 24.752), train_loss = 0.93572185, grad/param norm = 2.3973e-01, time/batch = 17.9883s	
12897/26050 (epoch 24.754), train_loss = 1.01085052, grad/param norm = 2.0651e-01, time/batch = 18.1651s	
12898/26050 (epoch 24.756), train_loss = 0.97516388, grad/param norm = 2.0112e-01, time/batch = 17.0726s	
12899/26050 (epoch 24.758), train_loss = 0.97164931, grad/param norm = 2.2586e-01, time/batch = 16.5492s	
12900/26050 (epoch 24.760), train_loss = 1.16051837, grad/param norm = 2.1011e-01, time/batch = 17.9864s	
12901/26050 (epoch 24.762), train_loss = 0.93431543, grad/param norm = 1.8561e-01, time/batch = 17.7473s	
12902/26050 (epoch 24.764), train_loss = 0.97998070, grad/param norm = 2.2879e-01, time/batch = 17.9786s	
12903/26050 (epoch 24.766), train_loss = 1.04594628, grad/param norm = 2.2456e-01, time/batch = 18.9756s	
12904/26050 (epoch 24.768), train_loss = 0.88220791, grad/param norm = 1.7391e-01, time/batch = 17.9730s	
12905/26050 (epoch 24.770), train_loss = 0.96504778, grad/param norm = 2.1210e-01, time/batch = 16.0675s	
12906/26050 (epoch 24.772), train_loss = 0.98278916, grad/param norm = 1.7349e-01, time/batch = 17.7798s	
12907/26050 (epoch 24.774), train_loss = 0.84745267, grad/param norm = 1.9033e-01, time/batch = 14.8907s	
12908/26050 (epoch 24.775), train_loss = 0.72035027, grad/param norm = 1.8454e-01, time/batch = 17.3994s	
12909/26050 (epoch 24.777), train_loss = 0.93454674, grad/param norm = 1.8708e-01, time/batch = 18.3867s	
12910/26050 (epoch 24.779), train_loss = 0.94718438, grad/param norm = 1.8655e-01, time/batch = 18.8143s	
12911/26050 (epoch 24.781), train_loss = 0.87112201, grad/param norm = 1.8786e-01, time/batch = 18.4810s	
12912/26050 (epoch 24.783), train_loss = 0.84898505, grad/param norm = 1.7096e-01, time/batch = 17.5689s	
12913/26050 (epoch 24.785), train_loss = 0.99889576, grad/param norm = 2.1354e-01, time/batch = 18.4123s	
12914/26050 (epoch 24.787), train_loss = 0.88730511, grad/param norm = 1.8930e-01, time/batch = 18.3254s	
12915/26050 (epoch 24.789), train_loss = 0.90470713, grad/param norm = 1.9610e-01, time/batch = 16.4752s	
12916/26050 (epoch 24.791), train_loss = 0.91318172, grad/param norm = 1.8832e-01, time/batch = 18.4801s	
12917/26050 (epoch 24.793), train_loss = 0.94540514, grad/param norm = 1.9171e-01, time/batch = 17.8996s	
12918/26050 (epoch 24.795), train_loss = 0.80331150, grad/param norm = 1.5327e-01, time/batch = 16.3094s	
12919/26050 (epoch 24.797), train_loss = 0.87935171, grad/param norm = 1.8958e-01, time/batch = 18.0602s	
12920/26050 (epoch 24.798), train_loss = 0.85089521, grad/param norm = 1.8816e-01, time/batch = 18.3983s	
12921/26050 (epoch 24.800), train_loss = 0.85155128, grad/param norm = 1.7031e-01, time/batch = 17.7120s	
12922/26050 (epoch 24.802), train_loss = 0.92268071, grad/param norm = 1.8576e-01, time/batch = 15.1972s	
12923/26050 (epoch 24.804), train_loss = 0.96871790, grad/param norm = 1.9486e-01, time/batch = 17.6509s	
12924/26050 (epoch 24.806), train_loss = 1.04942537, grad/param norm = 1.9709e-01, time/batch = 18.3259s	
12925/26050 (epoch 24.808), train_loss = 0.96593224, grad/param norm = 1.9695e-01, time/batch = 14.7215s	
12926/26050 (epoch 24.810), train_loss = 0.91823517, grad/param norm = 1.9591e-01, time/batch = 17.9691s	
12927/26050 (epoch 24.812), train_loss = 0.84030735, grad/param norm = 1.8642e-01, time/batch = 18.6488s	
12928/26050 (epoch 24.814), train_loss = 0.89226223, grad/param norm = 2.0343e-01, time/batch = 18.8327s	
12929/26050 (epoch 24.816), train_loss = 1.04014800, grad/param norm = 2.1759e-01, time/batch = 17.7345s	
12930/26050 (epoch 24.818), train_loss = 1.06690947, grad/param norm = 2.6820e-01, time/batch = 18.3974s	
12931/26050 (epoch 24.820), train_loss = 0.99264820, grad/param norm = 1.7783e-01, time/batch = 18.9047s	
12932/26050 (epoch 24.821), train_loss = 1.08221944, grad/param norm = 2.0338e-01, time/batch = 16.1443s	
12933/26050 (epoch 24.823), train_loss = 1.13176837, grad/param norm = 2.0006e-01, time/batch = 18.5679s	
12934/26050 (epoch 24.825), train_loss = 0.97132000, grad/param norm = 1.9436e-01, time/batch = 17.8117s	
12935/26050 (epoch 24.827), train_loss = 0.99513191, grad/param norm = 2.0818e-01, time/batch = 15.3894s	
12936/26050 (epoch 24.829), train_loss = 1.04450493, grad/param norm = 2.0005e-01, time/batch = 17.7841s	
12937/26050 (epoch 24.831), train_loss = 1.11717339, grad/param norm = 2.0117e-01, time/batch = 18.5597s	
12938/26050 (epoch 24.833), train_loss = 1.16772732, grad/param norm = 2.2676e-01, time/batch = 16.4700s	
12939/26050 (epoch 24.835), train_loss = 1.15256832, grad/param norm = 2.0271e-01, time/batch = 17.3036s	
12940/26050 (epoch 24.837), train_loss = 0.97754026, grad/param norm = 1.8722e-01, time/batch = 18.3210s	
12941/26050 (epoch 24.839), train_loss = 0.98344677, grad/param norm = 2.1276e-01, time/batch = 16.9917s	
12942/26050 (epoch 24.841), train_loss = 1.10656662, grad/param norm = 1.9325e-01, time/batch = 17.3958s	
12943/26050 (epoch 24.843), train_loss = 0.96073516, grad/param norm = 1.7899e-01, time/batch = 18.4751s	
12944/26050 (epoch 24.845), train_loss = 0.94401824, grad/param norm = 1.8427e-01, time/batch = 18.5611s	
12945/26050 (epoch 24.846), train_loss = 1.06415469, grad/param norm = 2.0517e-01, time/batch = 17.9876s	
12946/26050 (epoch 24.848), train_loss = 0.96214225, grad/param norm = 1.8140e-01, time/batch = 18.4756s	
12947/26050 (epoch 24.850), train_loss = 0.88767497, grad/param norm = 1.7325e-01, time/batch = 18.3929s	
12948/26050 (epoch 24.852), train_loss = 0.98437939, grad/param norm = 1.8550e-01, time/batch = 14.8032s	
12949/26050 (epoch 24.854), train_loss = 0.96313528, grad/param norm = 1.8935e-01, time/batch = 16.2253s	
12950/26050 (epoch 24.856), train_loss = 0.92787262, grad/param norm = 1.9398e-01, time/batch = 18.6511s	
12951/26050 (epoch 24.858), train_loss = 0.91031001, grad/param norm = 1.8396e-01, time/batch = 17.5525s	
12952/26050 (epoch 24.860), train_loss = 1.02230268, grad/param norm = 1.9430e-01, time/batch = 17.1341s	
12953/26050 (epoch 24.862), train_loss = 1.03923738, grad/param norm = 2.0287e-01, time/batch = 16.2998s	
12954/26050 (epoch 24.864), train_loss = 1.01840799, grad/param norm = 2.3992e-01, time/batch = 18.2218s	
12955/26050 (epoch 24.866), train_loss = 0.93517825, grad/param norm = 1.7732e-01, time/batch = 18.4605s	
12956/26050 (epoch 24.868), train_loss = 1.02232290, grad/param norm = 1.8838e-01, time/batch = 17.5622s	
12957/26050 (epoch 24.869), train_loss = 0.87956874, grad/param norm = 1.8917e-01, time/batch = 15.9845s	
12958/26050 (epoch 24.871), train_loss = 0.82204329, grad/param norm = 1.7003e-01, time/batch = 17.4649s	
12959/26050 (epoch 24.873), train_loss = 1.01709874, grad/param norm = 2.1726e-01, time/batch = 17.4872s	
12960/26050 (epoch 24.875), train_loss = 0.96475741, grad/param norm = 1.8841e-01, time/batch = 18.1465s	
12961/26050 (epoch 24.877), train_loss = 0.87484557, grad/param norm = 1.7803e-01, time/batch = 18.2056s	
12962/26050 (epoch 24.879), train_loss = 1.00037155, grad/param norm = 1.7889e-01, time/batch = 18.6248s	
12963/26050 (epoch 24.881), train_loss = 1.07966985, grad/param norm = 2.2539e-01, time/batch = 18.6370s	
12964/26050 (epoch 24.883), train_loss = 1.03128195, grad/param norm = 1.8600e-01, time/batch = 17.4948s	
12965/26050 (epoch 24.885), train_loss = 0.74449217, grad/param norm = 1.6245e-01, time/batch = 18.2362s	
12966/26050 (epoch 24.887), train_loss = 1.03177835, grad/param norm = 2.0346e-01, time/batch = 16.6524s	
12967/26050 (epoch 24.889), train_loss = 0.92540954, grad/param norm = 1.8232e-01, time/batch = 17.8233s	
12968/26050 (epoch 24.891), train_loss = 0.80482450, grad/param norm = 1.7542e-01, time/batch = 15.8914s	
12969/26050 (epoch 24.893), train_loss = 0.85145231, grad/param norm = 1.7863e-01, time/batch = 17.8187s	
12970/26050 (epoch 24.894), train_loss = 0.93048768, grad/param norm = 1.7427e-01, time/batch = 17.2985s	
12971/26050 (epoch 24.896), train_loss = 1.08259801, grad/param norm = 2.1749e-01, time/batch = 18.3299s	
12972/26050 (epoch 24.898), train_loss = 0.91763445, grad/param norm = 1.9513e-01, time/batch = 18.6610s	
12973/26050 (epoch 24.900), train_loss = 1.01185204, grad/param norm = 2.1047e-01, time/batch = 18.3946s	
12974/26050 (epoch 24.902), train_loss = 0.97871930, grad/param norm = 2.0732e-01, time/batch = 17.9902s	
12975/26050 (epoch 24.904), train_loss = 0.94740091, grad/param norm = 1.9763e-01, time/batch = 18.3865s	
12976/26050 (epoch 24.906), train_loss = 0.94074008, grad/param norm = 1.9677e-01, time/batch = 17.5742s	
12977/26050 (epoch 24.908), train_loss = 0.97133581, grad/param norm = 1.7810e-01, time/batch = 15.3927s	
12978/26050 (epoch 24.910), train_loss = 0.93953069, grad/param norm = 1.7540e-01, time/batch = 18.9043s	
12979/26050 (epoch 24.912), train_loss = 1.16865065, grad/param norm = 2.2091e-01, time/batch = 17.0846s	
12980/26050 (epoch 24.914), train_loss = 1.34040825, grad/param norm = 2.3999e-01, time/batch = 14.8755s	
12981/26050 (epoch 24.916), train_loss = 1.07486037, grad/param norm = 2.2074e-01, time/batch = 18.3086s	
12982/26050 (epoch 24.917), train_loss = 0.98467142, grad/param norm = 2.1357e-01, time/batch = 18.9043s	
12983/26050 (epoch 24.919), train_loss = 1.02778365, grad/param norm = 2.0345e-01, time/batch = 16.7269s	
12984/26050 (epoch 24.921), train_loss = 0.93211702, grad/param norm = 2.0079e-01, time/batch = 15.8115s	
12985/26050 (epoch 24.923), train_loss = 0.98758058, grad/param norm = 1.8580e-01, time/batch = 17.8150s	
12986/26050 (epoch 24.925), train_loss = 0.97242285, grad/param norm = 1.8438e-01, time/batch = 17.8201s	
12987/26050 (epoch 24.927), train_loss = 0.87879733, grad/param norm = 1.5540e-01, time/batch = 17.3991s	
12988/26050 (epoch 24.929), train_loss = 0.82858608, grad/param norm = 1.6851e-01, time/batch = 18.1465s	
12989/26050 (epoch 24.931), train_loss = 1.13454646, grad/param norm = 2.1475e-01, time/batch = 18.3173s	
12990/26050 (epoch 24.933), train_loss = 0.93522217, grad/param norm = 1.9050e-01, time/batch = 17.6452s	
12991/26050 (epoch 24.935), train_loss = 0.94954839, grad/param norm = 1.8995e-01, time/batch = 18.0763s	
12992/26050 (epoch 24.937), train_loss = 1.06255708, grad/param norm = 1.8174e-01, time/batch = 18.4984s	
12993/26050 (epoch 24.939), train_loss = 0.89586546, grad/param norm = 1.6776e-01, time/batch = 17.8990s	
12994/26050 (epoch 24.940), train_loss = 0.93208035, grad/param norm = 1.7971e-01, time/batch = 17.6360s	
12995/26050 (epoch 24.942), train_loss = 0.94949776, grad/param norm = 1.8567e-01, time/batch = 18.7925s	
12996/26050 (epoch 24.944), train_loss = 0.92740170, grad/param norm = 1.6941e-01, time/batch = 17.3232s	
12997/26050 (epoch 24.946), train_loss = 1.08792342, grad/param norm = 1.8913e-01, time/batch = 15.5499s	
12998/26050 (epoch 24.948), train_loss = 0.83865157, grad/param norm = 1.7976e-01, time/batch = 15.5664s	
12999/26050 (epoch 24.950), train_loss = 0.93932880, grad/param norm = 1.8675e-01, time/batch = 18.7304s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch24.95_1.7335.t7	
13000/26050 (epoch 24.952), train_loss = 1.04517387, grad/param norm = 1.9073e-01, time/batch = 23.7303s	
13001/26050 (epoch 24.954), train_loss = 1.53925726, grad/param norm = 2.7180e-01, time/batch = 18.2198s	
13002/26050 (epoch 24.956), train_loss = 0.97145476, grad/param norm = 2.0690e-01, time/batch = 16.8048s	
13003/26050 (epoch 24.958), train_loss = 0.90189976, grad/param norm = 1.8813e-01, time/batch = 17.8967s	
13004/26050 (epoch 24.960), train_loss = 1.01620559, grad/param norm = 2.0227e-01, time/batch = 16.3975s	
13005/26050 (epoch 24.962), train_loss = 0.96168038, grad/param norm = 1.8729e-01, time/batch = 18.2251s	
13006/26050 (epoch 24.964), train_loss = 0.98376807, grad/param norm = 1.9198e-01, time/batch = 17.1490s	
13007/26050 (epoch 24.965), train_loss = 0.88608093, grad/param norm = 1.9522e-01, time/batch = 18.8916s	
13008/26050 (epoch 24.967), train_loss = 1.28971853, grad/param norm = 2.0650e-01, time/batch = 18.8228s	
13009/26050 (epoch 24.969), train_loss = 1.00667619, grad/param norm = 2.1755e-01, time/batch = 17.2113s	
13010/26050 (epoch 24.971), train_loss = 0.92829050, grad/param norm = 1.6834e-01, time/batch = 17.8148s	
13011/26050 (epoch 24.973), train_loss = 0.97555189, grad/param norm = 1.7831e-01, time/batch = 19.0599s	
13012/26050 (epoch 24.975), train_loss = 1.01363237, grad/param norm = 1.9798e-01, time/batch = 15.5552s	
13013/26050 (epoch 24.977), train_loss = 0.97825366, grad/param norm = 1.5898e-01, time/batch = 17.8116s	
13014/26050 (epoch 24.979), train_loss = 0.80242181, grad/param norm = 1.7997e-01, time/batch = 17.9119s	
13015/26050 (epoch 24.981), train_loss = 1.11032754, grad/param norm = 1.9654e-01, time/batch = 18.1507s	
13016/26050 (epoch 24.983), train_loss = 1.05945356, grad/param norm = 2.0551e-01, time/batch = 16.9086s	
13017/26050 (epoch 24.985), train_loss = 1.03370168, grad/param norm = 1.9918e-01, time/batch = 18.5774s	
13018/26050 (epoch 24.987), train_loss = 1.08981608, grad/param norm = 1.9964e-01, time/batch = 15.3980s	
13019/26050 (epoch 24.988), train_loss = 1.03350014, grad/param norm = 1.8375e-01, time/batch = 18.8940s	
13020/26050 (epoch 24.990), train_loss = 0.86545969, grad/param norm = 1.5934e-01, time/batch = 14.9561s	
13021/26050 (epoch 24.992), train_loss = 1.12561771, grad/param norm = 1.9377e-01, time/batch = 18.0762s	
13022/26050 (epoch 24.994), train_loss = 0.95227482, grad/param norm = 2.2598e-01, time/batch = 18.9893s	
13023/26050 (epoch 24.996), train_loss = 0.92414867, grad/param norm = 2.1461e-01, time/batch = 15.3135s	
13024/26050 (epoch 24.998), train_loss = 0.98737852, grad/param norm = 1.8490e-01, time/batch = 18.1302s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
13025/26050 (epoch 25.000), train_loss = 0.93473942, grad/param norm = 2.1041e-01, time/batch = 18.7264s	
13026/26050 (epoch 25.002), train_loss = 1.03168100, grad/param norm = 2.1192e-01, time/batch = 17.3149s	
13027/26050 (epoch 25.004), train_loss = 0.88998120, grad/param norm = 1.9301e-01, time/batch = 18.0635s	
13028/26050 (epoch 25.006), train_loss = 0.92822506, grad/param norm = 2.0099e-01, time/batch = 18.0633s	
13029/26050 (epoch 25.008), train_loss = 0.92298410, grad/param norm = 1.9605e-01, time/batch = 18.7376s	
13030/26050 (epoch 25.010), train_loss = 0.92416130, grad/param norm = 1.8715e-01, time/batch = 15.7390s	
13031/26050 (epoch 25.012), train_loss = 0.97638632, grad/param norm = 1.7687e-01, time/batch = 15.6367s	
13032/26050 (epoch 25.013), train_loss = 1.25692809, grad/param norm = 2.1460e-01, time/batch = 16.1982s	
13033/26050 (epoch 25.015), train_loss = 0.94858641, grad/param norm = 1.8389e-01, time/batch = 17.9756s	
13034/26050 (epoch 25.017), train_loss = 0.98641430, grad/param norm = 1.8410e-01, time/batch = 18.8751s	
13035/26050 (epoch 25.019), train_loss = 0.86423309, grad/param norm = 1.7628e-01, time/batch = 17.6575s	
13036/26050 (epoch 25.021), train_loss = 1.05499073, grad/param norm = 1.8518e-01, time/batch = 18.0611s	
13037/26050 (epoch 25.023), train_loss = 0.80427134, grad/param norm = 1.7908e-01, time/batch = 17.2373s	
13038/26050 (epoch 25.025), train_loss = 0.96723724, grad/param norm = 1.7923e-01, time/batch = 18.4940s	
13039/26050 (epoch 25.027), train_loss = 0.80388736, grad/param norm = 1.8499e-01, time/batch = 16.2949s	
13040/26050 (epoch 25.029), train_loss = 0.99470647, grad/param norm = 1.7772e-01, time/batch = 17.5001s	
13041/26050 (epoch 25.031), train_loss = 1.11061727, grad/param norm = 2.2194e-01, time/batch = 18.2428s	
13042/26050 (epoch 25.033), train_loss = 0.98871879, grad/param norm = 1.9283e-01, time/batch = 18.7485s	
13043/26050 (epoch 25.035), train_loss = 0.99950173, grad/param norm = 1.7536e-01, time/batch = 17.4779s	
13044/26050 (epoch 25.036), train_loss = 0.85614570, grad/param norm = 2.0592e-01, time/batch = 17.9075s	
13045/26050 (epoch 25.038), train_loss = 0.78927080, grad/param norm = 1.7742e-01, time/batch = 17.8340s	
13046/26050 (epoch 25.040), train_loss = 0.96087845, grad/param norm = 1.9716e-01, time/batch = 19.0899s	
13047/26050 (epoch 25.042), train_loss = 0.81993008, grad/param norm = 1.8971e-01, time/batch = 17.9593s	
13048/26050 (epoch 25.044), train_loss = 1.04262493, grad/param norm = 1.8308e-01, time/batch = 17.7251s	
13049/26050 (epoch 25.046), train_loss = 0.80414415, grad/param norm = 1.8131e-01, time/batch = 18.9123s	
13050/26050 (epoch 25.048), train_loss = 0.99133283, grad/param norm = 1.8236e-01, time/batch = 16.7230s	
13051/26050 (epoch 25.050), train_loss = 0.91963410, grad/param norm = 1.8579e-01, time/batch = 16.2755s	
13052/26050 (epoch 25.052), train_loss = 0.89513607, grad/param norm = 1.9856e-01, time/batch = 18.1525s	
13053/26050 (epoch 25.054), train_loss = 0.81317304, grad/param norm = 1.7577e-01, time/batch = 18.2362s	
13054/26050 (epoch 25.056), train_loss = 0.78714583, grad/param norm = 1.6099e-01, time/batch = 16.7205s	
13055/26050 (epoch 25.058), train_loss = 0.93881838, grad/param norm = 1.6600e-01, time/batch = 15.6327s	
13056/26050 (epoch 25.060), train_loss = 1.03805612, grad/param norm = 1.9465e-01, time/batch = 18.4879s	
13057/26050 (epoch 25.061), train_loss = 0.87124371, grad/param norm = 1.7484e-01, time/batch = 17.2293s	
13058/26050 (epoch 25.063), train_loss = 1.00396876, grad/param norm = 1.8619e-01, time/batch = 17.6670s	
13059/26050 (epoch 25.065), train_loss = 0.78130408, grad/param norm = 1.5456e-01, time/batch = 18.7351s	
13060/26050 (epoch 25.067), train_loss = 0.95644106, grad/param norm = 1.9332e-01, time/batch = 17.6438s	
13061/26050 (epoch 25.069), train_loss = 1.01906268, grad/param norm = 2.3149e-01, time/batch = 17.8896s	
13062/26050 (epoch 25.071), train_loss = 1.03015029, grad/param norm = 1.9415e-01, time/batch = 18.6626s	
13063/26050 (epoch 25.073), train_loss = 1.14079771, grad/param norm = 2.0822e-01, time/batch = 15.3183s	
13064/26050 (epoch 25.075), train_loss = 0.89484017, grad/param norm = 1.8536e-01, time/batch = 18.1378s	
13065/26050 (epoch 25.077), train_loss = 0.93156542, grad/param norm = 2.0648e-01, time/batch = 18.2423s	
13066/26050 (epoch 25.079), train_loss = 0.97624554, grad/param norm = 1.9004e-01, time/batch = 17.6555s	
13067/26050 (epoch 25.081), train_loss = 0.93038782, grad/param norm = 1.9237e-01, time/batch = 17.2336s	
13068/26050 (epoch 25.083), train_loss = 1.07009825, grad/param norm = 1.8471e-01, time/batch = 17.1330s	
13069/26050 (epoch 25.084), train_loss = 0.98866463, grad/param norm = 2.1415e-01, time/batch = 16.9866s	
13070/26050 (epoch 25.086), train_loss = 1.12663642, grad/param norm = 2.1721e-01, time/batch = 16.3707s	
13071/26050 (epoch 25.088), train_loss = 0.92027668, grad/param norm = 1.9584e-01, time/batch = 18.8852s	
13072/26050 (epoch 25.090), train_loss = 0.96939824, grad/param norm = 1.8688e-01, time/batch = 18.2156s	
13073/26050 (epoch 25.092), train_loss = 1.02587969, grad/param norm = 1.7396e-01, time/batch = 17.8146s	
13074/26050 (epoch 25.094), train_loss = 0.89148057, grad/param norm = 2.0001e-01, time/batch = 17.0665s	
13075/26050 (epoch 25.096), train_loss = 0.96635712, grad/param norm = 1.7326e-01, time/batch = 15.5744s	
13076/26050 (epoch 25.098), train_loss = 0.91227446, grad/param norm = 1.7458e-01, time/batch = 15.5455s	
13077/26050 (epoch 25.100), train_loss = 0.86998650, grad/param norm = 1.8464e-01, time/batch = 17.9765s	
13078/26050 (epoch 25.102), train_loss = 1.02380059, grad/param norm = 1.9636e-01, time/batch = 18.3955s	
13079/26050 (epoch 25.104), train_loss = 0.92953023, grad/param norm = 1.8351e-01, time/batch = 19.0648s	
13080/26050 (epoch 25.106), train_loss = 0.96530338, grad/param norm = 1.9916e-01, time/batch = 18.2262s	
13081/26050 (epoch 25.107), train_loss = 0.78596588, grad/param norm = 1.8181e-01, time/batch = 18.1364s	
13082/26050 (epoch 25.109), train_loss = 0.89294684, grad/param norm = 1.8854e-01, time/batch = 16.7242s	
13083/26050 (epoch 25.111), train_loss = 1.11393133, grad/param norm = 1.9816e-01, time/batch = 18.4827s	
13084/26050 (epoch 25.113), train_loss = 0.91997718, grad/param norm = 1.9064e-01, time/batch = 18.0637s	
13085/26050 (epoch 25.115), train_loss = 1.04929722, grad/param norm = 1.9640e-01, time/batch = 18.3939s	
13086/26050 (epoch 25.117), train_loss = 0.97387068, grad/param norm = 1.9842e-01, time/batch = 17.4098s	
13087/26050 (epoch 25.119), train_loss = 0.81041068, grad/param norm = 1.7601e-01, time/batch = 15.2127s	
13088/26050 (epoch 25.121), train_loss = 0.97313240, grad/param norm = 1.8453e-01, time/batch = 17.5604s	
13089/26050 (epoch 25.123), train_loss = 0.87705605, grad/param norm = 1.9282e-01, time/batch = 18.9848s	
13090/26050 (epoch 25.125), train_loss = 0.83183031, grad/param norm = 1.6427e-01, time/batch = 18.6615s	
13091/26050 (epoch 25.127), train_loss = 0.78787505, grad/param norm = 1.7740e-01, time/batch = 17.0707s	
13092/26050 (epoch 25.129), train_loss = 0.80587224, grad/param norm = 1.7342e-01, time/batch = 18.3370s	
13093/26050 (epoch 25.131), train_loss = 0.91861012, grad/param norm = 1.9346e-01, time/batch = 15.8839s	
13094/26050 (epoch 25.132), train_loss = 0.93767601, grad/param norm = 1.7219e-01, time/batch = 17.2266s	
13095/26050 (epoch 25.134), train_loss = 0.98163792, grad/param norm = 2.1904e-01, time/batch = 0.7131s	
13096/26050 (epoch 25.136), train_loss = 0.95192926, grad/param norm = 1.8770e-01, time/batch = 0.6434s	
13097/26050 (epoch 25.138), train_loss = 0.72354468, grad/param norm = 1.6219e-01, time/batch = 0.6419s	
13098/26050 (epoch 25.140), train_loss = 0.81054385, grad/param norm = 1.8276e-01, time/batch = 0.6423s	
13099/26050 (epoch 25.142), train_loss = 0.83654504, grad/param norm = 1.7974e-01, time/batch = 0.6435s	
13100/26050 (epoch 25.144), train_loss = 0.74952036, grad/param norm = 1.7211e-01, time/batch = 0.6695s	
13101/26050 (epoch 25.146), train_loss = 0.70175604, grad/param norm = 1.5810e-01, time/batch = 0.6424s	
13102/26050 (epoch 25.148), train_loss = 0.74361533, grad/param norm = 1.4275e-01, time/batch = 0.7467s	
13103/26050 (epoch 25.150), train_loss = 0.90083987, grad/param norm = 1.8610e-01, time/batch = 0.9441s	
13104/26050 (epoch 25.152), train_loss = 1.10774976, grad/param norm = 2.2773e-01, time/batch = 0.9544s	
13105/26050 (epoch 25.154), train_loss = 0.76163064, grad/param norm = 1.9141e-01, time/batch = 0.9600s	
13106/26050 (epoch 25.155), train_loss = 0.80485368, grad/param norm = 1.8970e-01, time/batch = 0.9476s	
13107/26050 (epoch 25.157), train_loss = 0.92427796, grad/param norm = 2.0787e-01, time/batch = 0.9924s	
13108/26050 (epoch 25.159), train_loss = 0.96076158, grad/param norm = 2.2444e-01, time/batch = 1.7617s	
13109/26050 (epoch 25.161), train_loss = 0.96240174, grad/param norm = 1.9297e-01, time/batch = 1.8079s	
13110/26050 (epoch 25.163), train_loss = 0.79069297, grad/param norm = 1.7918e-01, time/batch = 5.5776s	
13111/26050 (epoch 25.165), train_loss = 0.73629075, grad/param norm = 1.9071e-01, time/batch = 17.3897s	
13112/26050 (epoch 25.167), train_loss = 1.05907368, grad/param norm = 2.0751e-01, time/batch = 18.3901s	
13113/26050 (epoch 25.169), train_loss = 0.96353990, grad/param norm = 1.9651e-01, time/batch = 18.0739s	
13114/26050 (epoch 25.171), train_loss = 0.79804121, grad/param norm = 1.7095e-01, time/batch = 16.6548s	
13115/26050 (epoch 25.173), train_loss = 0.90238966, grad/param norm = 2.0813e-01, time/batch = 17.3975s	
13116/26050 (epoch 25.175), train_loss = 0.91378052, grad/param norm = 1.7464e-01, time/batch = 17.5730s	
13117/26050 (epoch 25.177), train_loss = 1.03034624, grad/param norm = 1.8629e-01, time/batch = 18.4907s	
13118/26050 (epoch 25.179), train_loss = 0.70654853, grad/param norm = 1.5810e-01, time/batch = 17.6613s	
13119/26050 (epoch 25.180), train_loss = 1.14075756, grad/param norm = 1.9315e-01, time/batch = 18.0721s	
13120/26050 (epoch 25.182), train_loss = 1.18353550, grad/param norm = 2.1441e-01, time/batch = 16.6561s	
13121/26050 (epoch 25.184), train_loss = 0.97874543, grad/param norm = 1.7818e-01, time/batch = 15.2371s	
13122/26050 (epoch 25.186), train_loss = 0.78485180, grad/param norm = 1.7483e-01, time/batch = 18.5741s	
13123/26050 (epoch 25.188), train_loss = 0.96876646, grad/param norm = 2.0167e-01, time/batch = 17.9737s	
13124/26050 (epoch 25.190), train_loss = 0.97849257, grad/param norm = 1.8566e-01, time/batch = 17.9876s	
13125/26050 (epoch 25.192), train_loss = 0.98493854, grad/param norm = 1.6434e-01, time/batch = 18.4031s	
13126/26050 (epoch 25.194), train_loss = 0.99324586, grad/param norm = 1.9808e-01, time/batch = 16.3009s	
13127/26050 (epoch 25.196), train_loss = 1.02006052, grad/param norm = 1.9508e-01, time/batch = 16.3005s	
13128/26050 (epoch 25.198), train_loss = 0.87733050, grad/param norm = 1.7742e-01, time/batch = 17.7206s	
13129/26050 (epoch 25.200), train_loss = 0.85297921, grad/param norm = 1.8062e-01, time/batch = 16.4804s	
13130/26050 (epoch 25.202), train_loss = 0.96273216, grad/param norm = 1.8381e-01, time/batch = 15.0620s	
13131/26050 (epoch 25.203), train_loss = 1.06431646, grad/param norm = 1.9156e-01, time/batch = 15.2603s	
13132/26050 (epoch 25.205), train_loss = 0.89865362, grad/param norm = 1.7822e-01, time/batch = 14.6196s	
13133/26050 (epoch 25.207), train_loss = 0.87062487, grad/param norm = 1.7354e-01, time/batch = 14.1516s	
13134/26050 (epoch 25.209), train_loss = 1.01459660, grad/param norm = 2.0618e-01, time/batch = 14.2485s	
13135/26050 (epoch 25.211), train_loss = 0.78768102, grad/param norm = 1.8218e-01, time/batch = 17.2495s	
13136/26050 (epoch 25.213), train_loss = 0.98403102, grad/param norm = 1.9897e-01, time/batch = 17.3981s	
13137/26050 (epoch 25.215), train_loss = 0.93461252, grad/param norm = 2.0848e-01, time/batch = 17.7312s	
13138/26050 (epoch 25.217), train_loss = 0.91345693, grad/param norm = 1.7805e-01, time/batch = 15.7317s	
13139/26050 (epoch 25.219), train_loss = 0.91950304, grad/param norm = 1.9308e-01, time/batch = 18.8165s	
13140/26050 (epoch 25.221), train_loss = 0.86198101, grad/param norm = 2.0326e-01, time/batch = 18.7395s	
13141/26050 (epoch 25.223), train_loss = 1.00689661, grad/param norm = 2.0669e-01, time/batch = 17.8123s	
13142/26050 (epoch 25.225), train_loss = 0.86017887, grad/param norm = 1.9618e-01, time/batch = 17.8128s	
13143/26050 (epoch 25.226), train_loss = 0.99270019, grad/param norm = 2.1687e-01, time/batch = 18.4770s	
13144/26050 (epoch 25.228), train_loss = 1.08511782, grad/param norm = 1.9159e-01, time/batch = 16.9139s	
13145/26050 (epoch 25.230), train_loss = 0.97505137, grad/param norm = 1.8647e-01, time/batch = 18.4017s	
13146/26050 (epoch 25.232), train_loss = 1.03981340, grad/param norm = 2.1782e-01, time/batch = 18.3319s	
13147/26050 (epoch 25.234), train_loss = 0.84730539, grad/param norm = 2.0890e-01, time/batch = 18.1486s	
13148/26050 (epoch 25.236), train_loss = 1.04211794, grad/param norm = 2.0158e-01, time/batch = 17.0755s	
13149/26050 (epoch 25.238), train_loss = 0.82258104, grad/param norm = 2.0308e-01, time/batch = 14.7306s	
13150/26050 (epoch 25.240), train_loss = 0.96064922, grad/param norm = 2.0085e-01, time/batch = 17.5970s	
13151/26050 (epoch 25.242), train_loss = 0.92567116, grad/param norm = 1.7381e-01, time/batch = 17.9841s	
13152/26050 (epoch 25.244), train_loss = 0.96345923, grad/param norm = 2.0066e-01, time/batch = 18.3132s	
13153/26050 (epoch 25.246), train_loss = 0.87303303, grad/param norm = 1.7652e-01, time/batch = 18.5681s	
13154/26050 (epoch 25.248), train_loss = 0.95624102, grad/param norm = 1.8297e-01, time/batch = 18.3152s	
13155/26050 (epoch 25.250), train_loss = 0.93749346, grad/param norm = 2.0731e-01, time/batch = 15.7305s	
13156/26050 (epoch 25.251), train_loss = 0.90270081, grad/param norm = 1.7457e-01, time/batch = 16.7848s	
13157/26050 (epoch 25.253), train_loss = 0.83783019, grad/param norm = 1.7667e-01, time/batch = 17.9138s	
13158/26050 (epoch 25.255), train_loss = 1.09847552, grad/param norm = 1.9146e-01, time/batch = 18.8142s	
13159/26050 (epoch 25.257), train_loss = 0.94210285, grad/param norm = 1.9266e-01, time/batch = 17.4926s	
13160/26050 (epoch 25.259), train_loss = 1.05461561, grad/param norm = 1.9441e-01, time/batch = 18.7397s	
13161/26050 (epoch 25.261), train_loss = 0.85396351, grad/param norm = 1.9631e-01, time/batch = 16.4851s	
13162/26050 (epoch 25.263), train_loss = 1.03864098, grad/param norm = 2.1116e-01, time/batch = 18.5594s	
13163/26050 (epoch 25.265), train_loss = 1.09677831, grad/param norm = 2.1035e-01, time/batch = 16.0564s	
13164/26050 (epoch 25.267), train_loss = 1.05771128, grad/param norm = 1.7350e-01, time/batch = 15.9088s	
13165/26050 (epoch 25.269), train_loss = 1.06915668, grad/param norm = 2.0824e-01, time/batch = 15.6471s	
13166/26050 (epoch 25.271), train_loss = 1.00046704, grad/param norm = 1.9010e-01, time/batch = 16.2767s	
13167/26050 (epoch 25.273), train_loss = 0.89942068, grad/param norm = 2.2316e-01, time/batch = 17.8075s	
13168/26050 (epoch 25.274), train_loss = 0.92525737, grad/param norm = 1.7020e-01, time/batch = 18.0410s	
13169/26050 (epoch 25.276), train_loss = 0.90144267, grad/param norm = 1.8696e-01, time/batch = 17.8857s	
13170/26050 (epoch 25.278), train_loss = 1.06496599, grad/param norm = 1.8959e-01, time/batch = 17.9685s	
13171/26050 (epoch 25.280), train_loss = 0.94837508, grad/param norm = 1.8298e-01, time/batch = 17.3150s	
13172/26050 (epoch 25.282), train_loss = 0.98812724, grad/param norm = 1.9504e-01, time/batch = 18.4717s	
13173/26050 (epoch 25.284), train_loss = 0.92875062, grad/param norm = 1.8109e-01, time/batch = 18.3948s	
13174/26050 (epoch 25.286), train_loss = 0.95817690, grad/param norm = 1.9848e-01, time/batch = 18.5543s	
13175/26050 (epoch 25.288), train_loss = 0.81339676, grad/param norm = 1.8130e-01, time/batch = 17.8158s	
13176/26050 (epoch 25.290), train_loss = 0.96966902, grad/param norm = 2.0916e-01, time/batch = 18.8342s	
13177/26050 (epoch 25.292), train_loss = 0.86564346, grad/param norm = 1.6504e-01, time/batch = 17.7513s	
13178/26050 (epoch 25.294), train_loss = 0.95293234, grad/param norm = 2.0278e-01, time/batch = 16.0617s	
13179/26050 (epoch 25.296), train_loss = 1.06636852, grad/param norm = 2.0284e-01, time/batch = 16.3045s	
13180/26050 (epoch 25.298), train_loss = 0.97787258, grad/param norm = 1.9272e-01, time/batch = 17.9937s	
13181/26050 (epoch 25.299), train_loss = 0.77984615, grad/param norm = 1.5303e-01, time/batch = 17.4009s	
13182/26050 (epoch 25.301), train_loss = 0.81764731, grad/param norm = 1.9674e-01, time/batch = 17.3067s	
13183/26050 (epoch 25.303), train_loss = 0.96171062, grad/param norm = 2.0672e-01, time/batch = 18.9674s	
13184/26050 (epoch 25.305), train_loss = 0.77773263, grad/param norm = 1.8067e-01, time/batch = 18.3212s	
13185/26050 (epoch 25.307), train_loss = 0.88294232, grad/param norm = 1.8656e-01, time/batch = 15.0957s	
13186/26050 (epoch 25.309), train_loss = 0.93322060, grad/param norm = 1.8202e-01, time/batch = 18.3125s	
13187/26050 (epoch 25.311), train_loss = 1.03275935, grad/param norm = 2.1796e-01, time/batch = 17.5670s	
13188/26050 (epoch 25.313), train_loss = 0.94889320, grad/param norm = 2.1189e-01, time/batch = 18.2341s	
13189/26050 (epoch 25.315), train_loss = 1.03396309, grad/param norm = 1.8867e-01, time/batch = 18.2367s	
13190/26050 (epoch 25.317), train_loss = 0.97828547, grad/param norm = 1.9767e-01, time/batch = 18.7429s	
13191/26050 (epoch 25.319), train_loss = 0.87155047, grad/param norm = 1.7386e-01, time/batch = 17.9934s	
13192/26050 (epoch 25.321), train_loss = 0.93435839, grad/param norm = 1.8165e-01, time/batch = 18.3154s	
13193/26050 (epoch 25.322), train_loss = 1.00388533, grad/param norm = 1.8815e-01, time/batch = 18.9006s	
13194/26050 (epoch 25.324), train_loss = 0.76413042, grad/param norm = 1.6465e-01, time/batch = 18.6703s	
13195/26050 (epoch 25.326), train_loss = 1.08379119, grad/param norm = 2.0717e-01, time/batch = 18.1379s	
13196/26050 (epoch 25.328), train_loss = 0.97487153, grad/param norm = 1.8354e-01, time/batch = 17.6507s	
13197/26050 (epoch 25.330), train_loss = 0.81586163, grad/param norm = 1.8348e-01, time/batch = 16.9013s	
13198/26050 (epoch 25.332), train_loss = 1.01463513, grad/param norm = 2.0108e-01, time/batch = 17.7994s	
13199/26050 (epoch 25.334), train_loss = 0.88479710, grad/param norm = 1.8220e-01, time/batch = 14.4641s	
13200/26050 (epoch 25.336), train_loss = 0.90270568, grad/param norm = 1.8578e-01, time/batch = 17.8189s	
13201/26050 (epoch 25.338), train_loss = 0.83686989, grad/param norm = 1.7077e-01, time/batch = 18.5600s	
13202/26050 (epoch 25.340), train_loss = 1.02738862, grad/param norm = 2.1453e-01, time/batch = 18.2198s	
13203/26050 (epoch 25.342), train_loss = 1.03261865, grad/param norm = 1.9212e-01, time/batch = 17.7457s	
13204/26050 (epoch 25.344), train_loss = 0.86944481, grad/param norm = 1.9280e-01, time/batch = 16.5450s	
13205/26050 (epoch 25.345), train_loss = 0.93681023, grad/param norm = 1.8933e-01, time/batch = 17.6443s	
13206/26050 (epoch 25.347), train_loss = 1.08136418, grad/param norm = 1.9823e-01, time/batch = 18.3156s	
13207/26050 (epoch 25.349), train_loss = 0.99650985, grad/param norm = 2.0006e-01, time/batch = 18.0517s	
13208/26050 (epoch 25.351), train_loss = 1.00351018, grad/param norm = 1.8779e-01, time/batch = 15.1331s	
13209/26050 (epoch 25.353), train_loss = 0.96785823, grad/param norm = 1.9432e-01, time/batch = 18.4801s	
13210/26050 (epoch 25.355), train_loss = 0.99593466, grad/param norm = 2.0612e-01, time/batch = 17.8228s	
13211/26050 (epoch 25.357), train_loss = 0.88904781, grad/param norm = 1.7120e-01, time/batch = 17.9983s	
13212/26050 (epoch 25.359), train_loss = 1.06735158, grad/param norm = 2.2586e-01, time/batch = 25.1181s	
13213/26050 (epoch 25.361), train_loss = 0.87591252, grad/param norm = 1.7220e-01, time/batch = 30.2457s	
13214/26050 (epoch 25.363), train_loss = 1.02678088, grad/param norm = 1.7989e-01, time/batch = 15.9108s	
13215/26050 (epoch 25.365), train_loss = 0.92105916, grad/param norm = 1.6979e-01, time/batch = 18.4804s	
13216/26050 (epoch 25.367), train_loss = 1.00815592, grad/param norm = 1.8147e-01, time/batch = 17.9701s	
13217/26050 (epoch 25.369), train_loss = 0.88447414, grad/param norm = 1.8964e-01, time/batch = 17.6595s	
13218/26050 (epoch 25.370), train_loss = 0.84700020, grad/param norm = 1.6916e-01, time/batch = 18.2524s	
13219/26050 (epoch 25.372), train_loss = 0.97191662, grad/param norm = 1.9719e-01, time/batch = 18.0922s	
13220/26050 (epoch 25.374), train_loss = 1.08120127, grad/param norm = 1.9067e-01, time/batch = 18.6575s	
13221/26050 (epoch 25.376), train_loss = 1.13529330, grad/param norm = 2.1924e-01, time/batch = 17.3155s	
13222/26050 (epoch 25.378), train_loss = 0.89164186, grad/param norm = 1.7062e-01, time/batch = 15.9640s	
13223/26050 (epoch 25.380), train_loss = 1.12678996, grad/param norm = 2.3083e-01, time/batch = 18.3917s	
13224/26050 (epoch 25.382), train_loss = 1.24801844, grad/param norm = 2.5546e-01, time/batch = 17.1463s	
13225/26050 (epoch 25.384), train_loss = 0.92398230, grad/param norm = 1.9360e-01, time/batch = 18.3914s	
13226/26050 (epoch 25.386), train_loss = 1.04361486, grad/param norm = 2.4344e-01, time/batch = 17.6478s	
13227/26050 (epoch 25.388), train_loss = 0.97707232, grad/param norm = 2.0161e-01, time/batch = 16.4008s	
13228/26050 (epoch 25.390), train_loss = 0.90409686, grad/param norm = 1.7456e-01, time/batch = 15.6837s	
13229/26050 (epoch 25.392), train_loss = 0.84824810, grad/param norm = 1.8290e-01, time/batch = 18.2237s	
13230/26050 (epoch 25.393), train_loss = 1.00555450, grad/param norm = 2.0288e-01, time/batch = 18.8128s	
13231/26050 (epoch 25.395), train_loss = 1.04189860, grad/param norm = 2.4011e-01, time/batch = 16.9881s	
13232/26050 (epoch 25.397), train_loss = 1.03249542, grad/param norm = 2.1034e-01, time/batch = 16.9661s	
13233/26050 (epoch 25.399), train_loss = 0.91288394, grad/param norm = 2.1216e-01, time/batch = 17.9054s	
13234/26050 (epoch 25.401), train_loss = 0.99822683, grad/param norm = 2.2170e-01, time/batch = 15.0563s	
13235/26050 (epoch 25.403), train_loss = 0.99219477, grad/param norm = 2.1451e-01, time/batch = 18.3874s	
13236/26050 (epoch 25.405), train_loss = 0.96645287, grad/param norm = 1.9141e-01, time/batch = 17.8898s	
13237/26050 (epoch 25.407), train_loss = 1.10446012, grad/param norm = 2.0877e-01, time/batch = 18.1456s	
13238/26050 (epoch 25.409), train_loss = 1.10788093, grad/param norm = 2.2617e-01, time/batch = 17.5605s	
13239/26050 (epoch 25.411), train_loss = 1.03415560, grad/param norm = 2.1690e-01, time/batch = 18.4035s	
13240/26050 (epoch 25.413), train_loss = 1.12729017, grad/param norm = 1.9320e-01, time/batch = 17.8352s	
13241/26050 (epoch 25.415), train_loss = 1.10452075, grad/param norm = 2.1803e-01, time/batch = 17.9884s	
13242/26050 (epoch 25.417), train_loss = 1.18937461, grad/param norm = 2.3141e-01, time/batch = 16.4740s	
13243/26050 (epoch 25.418), train_loss = 1.06378152, grad/param norm = 2.2481e-01, time/batch = 17.7185s	
13244/26050 (epoch 25.420), train_loss = 0.83138110, grad/param norm = 1.7029e-01, time/batch = 15.6149s	
13245/26050 (epoch 25.422), train_loss = 0.82829940, grad/param norm = 1.7934e-01, time/batch = 18.2933s	
13246/26050 (epoch 25.424), train_loss = 1.09455552, grad/param norm = 2.0556e-01, time/batch = 18.2169s	
13247/26050 (epoch 25.426), train_loss = 1.06985618, grad/param norm = 1.9916e-01, time/batch = 17.9963s	
13248/26050 (epoch 25.428), train_loss = 0.93206164, grad/param norm = 1.7333e-01, time/batch = 16.1330s	
13249/26050 (epoch 25.430), train_loss = 1.11358252, grad/param norm = 2.0301e-01, time/batch = 17.9885s	
13250/26050 (epoch 25.432), train_loss = 0.95239907, grad/param norm = 1.9431e-01, time/batch = 18.7445s	
13251/26050 (epoch 25.434), train_loss = 0.95151421, grad/param norm = 1.9108e-01, time/batch = 17.3089s	
13252/26050 (epoch 25.436), train_loss = 1.10561955, grad/param norm = 2.1511e-01, time/batch = 18.4050s	
13253/26050 (epoch 25.438), train_loss = 1.03403581, grad/param norm = 2.0489e-01, time/batch = 14.5483s	
13254/26050 (epoch 25.440), train_loss = 0.99837923, grad/param norm = 2.1492e-01, time/batch = 18.0688s	
13255/26050 (epoch 25.441), train_loss = 0.98628763, grad/param norm = 1.8969e-01, time/batch = 16.9806s	
13256/26050 (epoch 25.443), train_loss = 0.83071255, grad/param norm = 1.5649e-01, time/batch = 18.2994s	
13257/26050 (epoch 25.445), train_loss = 0.88994039, grad/param norm = 1.7101e-01, time/batch = 18.3884s	
13258/26050 (epoch 25.447), train_loss = 1.09907794, grad/param norm = 2.1604e-01, time/batch = 15.4643s	
13259/26050 (epoch 25.449), train_loss = 0.88763832, grad/param norm = 1.7971e-01, time/batch = 17.9870s	
13260/26050 (epoch 25.451), train_loss = 1.12067851, grad/param norm = 2.0152e-01, time/batch = 18.5586s	
13261/26050 (epoch 25.453), train_loss = 0.91296966, grad/param norm = 1.6296e-01, time/batch = 19.0617s	
13262/26050 (epoch 25.455), train_loss = 0.97617611, grad/param norm = 1.7585e-01, time/batch = 16.8082s	
13263/26050 (epoch 25.457), train_loss = 0.95926588, grad/param norm = 1.7528e-01, time/batch = 14.7333s	
13264/26050 (epoch 25.459), train_loss = 1.06358653, grad/param norm = 2.0262e-01, time/batch = 18.4069s	
13265/26050 (epoch 25.461), train_loss = 1.06173787, grad/param norm = 2.2131e-01, time/batch = 17.0231s	
13266/26050 (epoch 25.463), train_loss = 0.92877716, grad/param norm = 1.7022e-01, time/batch = 17.8230s	
13267/26050 (epoch 25.464), train_loss = 0.99921264, grad/param norm = 1.7608e-01, time/batch = 18.1592s	
13268/26050 (epoch 25.466), train_loss = 1.02885383, grad/param norm = 2.0862e-01, time/batch = 16.5697s	
13269/26050 (epoch 25.468), train_loss = 1.07514811, grad/param norm = 1.6816e-01, time/batch = 17.3713s	
13270/26050 (epoch 25.470), train_loss = 1.07852361, grad/param norm = 2.1195e-01, time/batch = 17.5710s	
13271/26050 (epoch 25.472), train_loss = 1.11884247, grad/param norm = 2.2919e-01, time/batch = 18.3220s	
13272/26050 (epoch 25.474), train_loss = 1.10201983, grad/param norm = 1.8621e-01, time/batch = 17.6529s	
13273/26050 (epoch 25.476), train_loss = 1.10475509, grad/param norm = 1.9403e-01, time/batch = 18.0757s	
13274/26050 (epoch 25.478), train_loss = 0.96485001, grad/param norm = 1.9479e-01, time/batch = 18.3201s	
13275/26050 (epoch 25.480), train_loss = 0.98054041, grad/param norm = 1.8089e-01, time/batch = 17.6290s	
13276/26050 (epoch 25.482), train_loss = 0.94333904, grad/param norm = 1.8579e-01, time/batch = 14.9724s	
13277/26050 (epoch 25.484), train_loss = 0.92604107, grad/param norm = 1.8932e-01, time/batch = 18.5543s	
13278/26050 (epoch 25.486), train_loss = 1.11020208, grad/param norm = 1.8854e-01, time/batch = 18.7127s	
13279/26050 (epoch 25.488), train_loss = 1.19899889, grad/param norm = 2.0710e-01, time/batch = 17.6344s	
13280/26050 (epoch 25.489), train_loss = 1.15205892, grad/param norm = 3.0345e-01, time/batch = 18.4018s	
13281/26050 (epoch 25.491), train_loss = 0.91582437, grad/param norm = 2.2046e-01, time/batch = 17.4627s	
13282/26050 (epoch 25.493), train_loss = 1.00679580, grad/param norm = 2.0012e-01, time/batch = 16.5397s	
13283/26050 (epoch 25.495), train_loss = 0.96418016, grad/param norm = 1.9085e-01, time/batch = 17.8868s	
13284/26050 (epoch 25.497), train_loss = 0.88548132, grad/param norm = 1.8113e-01, time/batch = 17.6620s	
13285/26050 (epoch 25.499), train_loss = 0.94038049, grad/param norm = 1.8700e-01, time/batch = 17.8285s	
13286/26050 (epoch 25.501), train_loss = 1.05343742, grad/param norm = 1.9963e-01, time/batch = 17.4457s	
13287/26050 (epoch 25.503), train_loss = 0.92333233, grad/param norm = 1.9106e-01, time/batch = 17.5737s	
13288/26050 (epoch 25.505), train_loss = 1.09761575, grad/param norm = 1.9376e-01, time/batch = 15.2950s	
13289/26050 (epoch 25.507), train_loss = 1.05167731, grad/param norm = 2.5707e-01, time/batch = 17.7909s	
13290/26050 (epoch 25.509), train_loss = 1.13947327, grad/param norm = 1.8619e-01, time/batch = 16.0570s	
13291/26050 (epoch 25.511), train_loss = 0.92636605, grad/param norm = 1.6164e-01, time/batch = 17.8008s	
13292/26050 (epoch 25.512), train_loss = 0.87914298, grad/param norm = 2.0289e-01, time/batch = 17.2170s	
13293/26050 (epoch 25.514), train_loss = 1.05111240, grad/param norm = 2.2117e-01, time/batch = 18.3957s	
13294/26050 (epoch 25.516), train_loss = 1.10796912, grad/param norm = 1.9473e-01, time/batch = 18.0495s	
13295/26050 (epoch 25.518), train_loss = 0.98338755, grad/param norm = 2.0061e-01, time/batch = 18.7218s	
13296/26050 (epoch 25.520), train_loss = 0.96382258, grad/param norm = 1.8465e-01, time/batch = 15.1142s	
13297/26050 (epoch 25.522), train_loss = 0.77568618, grad/param norm = 1.7078e-01, time/batch = 17.7409s	
13298/26050 (epoch 25.524), train_loss = 1.05552367, grad/param norm = 2.3154e-01, time/batch = 18.3303s	
13299/26050 (epoch 25.526), train_loss = 1.07894675, grad/param norm = 2.1712e-01, time/batch = 17.4823s	
13300/26050 (epoch 25.528), train_loss = 1.02377290, grad/param norm = 2.0367e-01, time/batch = 17.3195s	
13301/26050 (epoch 25.530), train_loss = 0.93545293, grad/param norm = 1.9642e-01, time/batch = 17.8215s	
13302/26050 (epoch 25.532), train_loss = 1.00761839, grad/param norm = 1.9378e-01, time/batch = 18.1670s	
13303/26050 (epoch 25.534), train_loss = 1.05910047, grad/param norm = 2.1715e-01, time/batch = 17.4039s	
13304/26050 (epoch 25.536), train_loss = 0.98019570, grad/param norm = 1.8737e-01, time/batch = 17.8284s	
13305/26050 (epoch 25.537), train_loss = 1.06643901, grad/param norm = 2.1640e-01, time/batch = 15.8692s	
13306/26050 (epoch 25.539), train_loss = 0.98906237, grad/param norm = 1.9155e-01, time/batch = 16.8217s	
13307/26050 (epoch 25.541), train_loss = 1.15902403, grad/param norm = 2.1804e-01, time/batch = 17.5653s	
13308/26050 (epoch 25.543), train_loss = 0.81813321, grad/param norm = 1.7763e-01, time/batch = 18.5651s	
13309/26050 (epoch 25.545), train_loss = 1.01316468, grad/param norm = 2.0116e-01, time/batch = 17.8305s	
13310/26050 (epoch 25.547), train_loss = 0.96351324, grad/param norm = 1.8975e-01, time/batch = 18.7264s	
13311/26050 (epoch 25.549), train_loss = 0.81631339, grad/param norm = 1.9221e-01, time/batch = 18.3115s	
13312/26050 (epoch 25.551), train_loss = 1.04617301, grad/param norm = 2.0360e-01, time/batch = 18.5776s	
13313/26050 (epoch 25.553), train_loss = 0.91601659, grad/param norm = 1.7802e-01, time/batch = 17.7087s	
13314/26050 (epoch 25.555), train_loss = 0.89743377, grad/param norm = 1.8481e-01, time/batch = 14.5550s	
13315/26050 (epoch 25.557), train_loss = 1.00891607, grad/param norm = 1.8717e-01, time/batch = 18.2303s	
13316/26050 (epoch 25.559), train_loss = 0.97293666, grad/param norm = 1.9982e-01, time/batch = 16.2118s	
13317/26050 (epoch 25.560), train_loss = 0.95077612, grad/param norm = 1.9674e-01, time/batch = 17.3086s	
13318/26050 (epoch 25.562), train_loss = 0.96361434, grad/param norm = 1.8092e-01, time/batch = 17.6402s	
13319/26050 (epoch 25.564), train_loss = 1.15485243, grad/param norm = 2.0418e-01, time/batch = 18.2476s	
13320/26050 (epoch 25.566), train_loss = 0.88151419, grad/param norm = 1.7374e-01, time/batch = 17.2428s	
13321/26050 (epoch 25.568), train_loss = 1.02658625, grad/param norm = 1.9540e-01, time/batch = 18.5712s	
13322/26050 (epoch 25.570), train_loss = 1.02659491, grad/param norm = 2.0799e-01, time/batch = 18.7974s	
13323/26050 (epoch 25.572), train_loss = 0.95497785, grad/param norm = 2.1099e-01, time/batch = 16.7338s	
13324/26050 (epoch 25.574), train_loss = 0.99444913, grad/param norm = 2.0281e-01, time/batch = 18.6453s	
13325/26050 (epoch 25.576), train_loss = 1.01409921, grad/param norm = 2.0255e-01, time/batch = 18.5797s	
13326/26050 (epoch 25.578), train_loss = 0.94045823, grad/param norm = 1.8366e-01, time/batch = 15.2248s	
13327/26050 (epoch 25.580), train_loss = 0.90774387, grad/param norm = 1.9347e-01, time/batch = 14.7215s	
13328/26050 (epoch 25.582), train_loss = 0.99577667, grad/param norm = 1.7364e-01, time/batch = 18.4849s	
13329/26050 (epoch 25.583), train_loss = 1.07562533, grad/param norm = 1.9425e-01, time/batch = 18.2488s	
13330/26050 (epoch 25.585), train_loss = 0.85214918, grad/param norm = 1.8974e-01, time/batch = 16.9881s	
13331/26050 (epoch 25.587), train_loss = 1.02787306, grad/param norm = 2.0375e-01, time/batch = 18.3300s	
13332/26050 (epoch 25.589), train_loss = 1.12659746, grad/param norm = 2.1176e-01, time/batch = 17.8648s	
13333/26050 (epoch 25.591), train_loss = 0.97218319, grad/param norm = 1.9774e-01, time/batch = 18.1560s	
13334/26050 (epoch 25.593), train_loss = 0.85794617, grad/param norm = 1.7911e-01, time/batch = 17.8230s	
13335/26050 (epoch 25.595), train_loss = 1.04709007, grad/param norm = 2.1669e-01, time/batch = 17.9700s	
13336/26050 (epoch 25.597), train_loss = 0.98768119, grad/param norm = 1.9779e-01, time/batch = 18.4751s	
13337/26050 (epoch 25.599), train_loss = 1.00832328, grad/param norm = 1.9798e-01, time/batch = 17.4941s	
13338/26050 (epoch 25.601), train_loss = 1.14800150, grad/param norm = 1.8837e-01, time/batch = 15.2427s	
13339/26050 (epoch 25.603), train_loss = 1.00886396, grad/param norm = 1.9618e-01, time/batch = 18.4084s	
13340/26050 (epoch 25.605), train_loss = 0.94579499, grad/param norm = 1.8982e-01, time/batch = 17.8147s	
13341/26050 (epoch 25.607), train_loss = 1.07537714, grad/param norm = 2.0752e-01, time/batch = 17.3205s	
13342/26050 (epoch 25.608), train_loss = 0.87016694, grad/param norm = 1.8116e-01, time/batch = 18.3048s	
13343/26050 (epoch 25.610), train_loss = 0.97529060, grad/param norm = 1.8900e-01, time/batch = 17.9896s	
13344/26050 (epoch 25.612), train_loss = 0.95519129, grad/param norm = 1.9766e-01, time/batch = 18.0597s	
13345/26050 (epoch 25.614), train_loss = 0.98662779, grad/param norm = 1.8052e-01, time/batch = 16.4878s	
13346/26050 (epoch 25.616), train_loss = 1.09660337, grad/param norm = 2.1532e-01, time/batch = 16.3048s	
13347/26050 (epoch 25.618), train_loss = 0.93327130, grad/param norm = 2.0069e-01, time/batch = 16.7256s	
13348/26050 (epoch 25.620), train_loss = 1.02890950, grad/param norm = 1.9590e-01, time/batch = 18.4879s	
13349/26050 (epoch 25.622), train_loss = 0.87399209, grad/param norm = 1.6440e-01, time/batch = 17.6327s	
13350/26050 (epoch 25.624), train_loss = 0.83128627, grad/param norm = 1.6887e-01, time/batch = 17.7197s	
13351/26050 (epoch 25.626), train_loss = 1.03545933, grad/param norm = 1.8990e-01, time/batch = 14.8000s	
13352/26050 (epoch 25.628), train_loss = 0.90773881, grad/param norm = 1.9939e-01, time/batch = 18.3098s	
13353/26050 (epoch 25.630), train_loss = 1.10299021, grad/param norm = 1.8466e-01, time/batch = 18.8931s	
13354/26050 (epoch 25.631), train_loss = 1.13960900, grad/param norm = 2.0898e-01, time/batch = 18.0665s	
13355/26050 (epoch 25.633), train_loss = 0.87793567, grad/param norm = 1.7750e-01, time/batch = 18.1517s	
13356/26050 (epoch 25.635), train_loss = 0.90656684, grad/param norm = 1.7304e-01, time/batch = 17.8250s	
13357/26050 (epoch 25.637), train_loss = 0.87037735, grad/param norm = 1.8186e-01, time/batch = 17.5715s	
13358/26050 (epoch 25.639), train_loss = 1.05521894, grad/param norm = 1.9391e-01, time/batch = 17.4923s	
13359/26050 (epoch 25.641), train_loss = 0.92902400, grad/param norm = 1.8211e-01, time/batch = 18.4698s	
13360/26050 (epoch 25.643), train_loss = 0.88244144, grad/param norm = 1.6381e-01, time/batch = 16.2907s	
13361/26050 (epoch 25.645), train_loss = 0.92429681, grad/param norm = 1.8094e-01, time/batch = 18.7261s	
13362/26050 (epoch 25.647), train_loss = 0.91943544, grad/param norm = 2.0093e-01, time/batch = 18.3065s	
13363/26050 (epoch 25.649), train_loss = 0.96146023, grad/param norm = 1.7682e-01, time/batch = 18.8091s	
13364/26050 (epoch 25.651), train_loss = 0.93253781, grad/param norm = 1.8958e-01, time/batch = 17.1991s	
13365/26050 (epoch 25.653), train_loss = 0.97334557, grad/param norm = 2.0608e-01, time/batch = 15.5377s	
13366/26050 (epoch 25.655), train_loss = 0.90135962, grad/param norm = 1.9600e-01, time/batch = 18.0684s	
13367/26050 (epoch 25.656), train_loss = 0.84139981, grad/param norm = 1.7453e-01, time/batch = 17.7253s	
13368/26050 (epoch 25.658), train_loss = 1.14701152, grad/param norm = 2.0650e-01, time/batch = 17.2889s	
13369/26050 (epoch 25.660), train_loss = 0.84124084, grad/param norm = 1.8492e-01, time/batch = 16.9164s	
13370/26050 (epoch 25.662), train_loss = 0.95924115, grad/param norm = 1.9496e-01, time/batch = 14.8792s	
13371/26050 (epoch 25.664), train_loss = 0.95435425, grad/param norm = 1.9561e-01, time/batch = 18.7319s	
13372/26050 (epoch 25.666), train_loss = 0.90648070, grad/param norm = 1.9845e-01, time/batch = 18.0720s	
13373/26050 (epoch 25.668), train_loss = 0.79350108, grad/param norm = 2.0514e-01, time/batch = 18.5704s	
13374/26050 (epoch 25.670), train_loss = 1.09759458, grad/param norm = 2.1848e-01, time/batch = 16.7389s	
13375/26050 (epoch 25.672), train_loss = 0.97286699, grad/param norm = 1.8929e-01, time/batch = 18.5023s	
13376/26050 (epoch 25.674), train_loss = 0.87597807, grad/param norm = 1.8900e-01, time/batch = 18.1522s	
13377/26050 (epoch 25.676), train_loss = 1.02179814, grad/param norm = 2.0020e-01, time/batch = 17.7304s	
13378/26050 (epoch 25.678), train_loss = 1.06039335, grad/param norm = 2.0022e-01, time/batch = 18.6528s	
13379/26050 (epoch 25.679), train_loss = 1.13512662, grad/param norm = 2.0872e-01, time/batch = 18.1570s	
13380/26050 (epoch 25.681), train_loss = 0.98632287, grad/param norm = 1.9112e-01, time/batch = 16.3064s	
13381/26050 (epoch 25.683), train_loss = 0.87068083, grad/param norm = 2.5384e-01, time/batch = 17.8854s	
13382/26050 (epoch 25.685), train_loss = 0.95794511, grad/param norm = 2.0333e-01, time/batch = 17.7238s	
13383/26050 (epoch 25.687), train_loss = 0.84920009, grad/param norm = 1.8138e-01, time/batch = 18.7366s	
13384/26050 (epoch 25.689), train_loss = 0.93268324, grad/param norm = 1.9369e-01, time/batch = 17.5799s	
13385/26050 (epoch 25.691), train_loss = 0.78894174, grad/param norm = 1.6679e-01, time/batch = 15.5256s	
13386/26050 (epoch 25.693), train_loss = 0.89469684, grad/param norm = 1.8606e-01, time/batch = 17.6654s	
13387/26050 (epoch 25.695), train_loss = 0.96665762, grad/param norm = 1.8262e-01, time/batch = 18.2505s	
13388/26050 (epoch 25.697), train_loss = 0.87855133, grad/param norm = 1.8389e-01, time/batch = 17.0622s	
13389/26050 (epoch 25.699), train_loss = 1.01803542, grad/param norm = 2.1241e-01, time/batch = 17.8270s	
13390/26050 (epoch 25.701), train_loss = 0.87038136, grad/param norm = 1.6659e-01, time/batch = 15.8136s	
13391/26050 (epoch 25.702), train_loss = 1.06740315, grad/param norm = 1.9720e-01, time/batch = 17.3145s	
13392/26050 (epoch 25.704), train_loss = 1.06744801, grad/param norm = 1.8405e-01, time/batch = 18.5794s	
13393/26050 (epoch 25.706), train_loss = 0.93024008, grad/param norm = 2.1206e-01, time/batch = 17.8204s	
13394/26050 (epoch 25.708), train_loss = 1.05581273, grad/param norm = 2.0704e-01, time/batch = 14.7149s	
13395/26050 (epoch 25.710), train_loss = 1.03435762, grad/param norm = 2.3103e-01, time/batch = 18.1470s	
13396/26050 (epoch 25.712), train_loss = 0.98235547, grad/param norm = 1.8522e-01, time/batch = 18.4968s	
13397/26050 (epoch 25.714), train_loss = 0.85282780, grad/param norm = 1.7633e-01, time/batch = 15.4851s	
13398/26050 (epoch 25.716), train_loss = 1.20532272, grad/param norm = 2.2280e-01, time/batch = 16.7919s	
13399/26050 (epoch 25.718), train_loss = 1.03863402, grad/param norm = 1.9673e-01, time/batch = 18.4882s	
13400/26050 (epoch 25.720), train_loss = 0.95801929, grad/param norm = 1.9845e-01, time/batch = 17.1345s	
13401/26050 (epoch 25.722), train_loss = 0.85257390, grad/param norm = 1.6607e-01, time/batch = 18.0763s	
13402/26050 (epoch 25.724), train_loss = 0.90175744, grad/param norm = 1.8735e-01, time/batch = 18.1292s	
13403/26050 (epoch 25.726), train_loss = 1.01668609, grad/param norm = 1.8792e-01, time/batch = 17.9126s	
13404/26050 (epoch 25.727), train_loss = 1.02618244, grad/param norm = 2.0296e-01, time/batch = 18.7198s	
13405/26050 (epoch 25.729), train_loss = 1.00709661, grad/param norm = 1.9628e-01, time/batch = 18.0562s	
13406/26050 (epoch 25.731), train_loss = 1.00972950, grad/param norm = 1.8889e-01, time/batch = 18.1469s	
13407/26050 (epoch 25.733), train_loss = 0.94235361, grad/param norm = 2.1606e-01, time/batch = 15.2257s	
13408/26050 (epoch 25.735), train_loss = 1.15912505, grad/param norm = 2.1309e-01, time/batch = 18.0529s	
13409/26050 (epoch 25.737), train_loss = 0.91264043, grad/param norm = 1.9193e-01, time/batch = 17.5682s	
13410/26050 (epoch 25.739), train_loss = 1.01186906, grad/param norm = 1.8812e-01, time/batch = 17.1449s	
13411/26050 (epoch 25.741), train_loss = 0.90428432, grad/param norm = 1.9486e-01, time/batch = 17.5513s	
13412/26050 (epoch 25.743), train_loss = 1.00419353, grad/param norm = 2.3263e-01, time/batch = 17.5712s	
13413/26050 (epoch 25.745), train_loss = 0.87086398, grad/param norm = 1.9661e-01, time/batch = 18.8281s	
13414/26050 (epoch 25.747), train_loss = 0.88913509, grad/param norm = 1.8476e-01, time/batch = 15.1274s	
13415/26050 (epoch 25.749), train_loss = 1.08400609, grad/param norm = 2.0614e-01, time/batch = 23.9820s	
13416/26050 (epoch 25.750), train_loss = 0.96770249, grad/param norm = 1.6923e-01, time/batch = 32.8494s	
13417/26050 (epoch 25.752), train_loss = 0.91765622, grad/param norm = 2.1796e-01, time/batch = 16.8511s	
13418/26050 (epoch 25.754), train_loss = 0.99353865, grad/param norm = 2.0336e-01, time/batch = 18.5599s	
13419/26050 (epoch 25.756), train_loss = 0.97012724, grad/param norm = 2.0800e-01, time/batch = 18.8066s	
13420/26050 (epoch 25.758), train_loss = 0.94282193, grad/param norm = 2.0340e-01, time/batch = 15.1508s	
13421/26050 (epoch 25.760), train_loss = 1.14544076, grad/param norm = 2.2808e-01, time/batch = 18.5700s	
13422/26050 (epoch 25.762), train_loss = 0.93593620, grad/param norm = 2.0647e-01, time/batch = 18.0737s	
13423/26050 (epoch 25.764), train_loss = 0.95509037, grad/param norm = 1.9795e-01, time/batch = 18.7458s	
13424/26050 (epoch 25.766), train_loss = 1.01789734, grad/param norm = 2.1293e-01, time/batch = 17.1666s	
13425/26050 (epoch 25.768), train_loss = 0.85749016, grad/param norm = 1.7883e-01, time/batch = 18.6552s	
13426/26050 (epoch 25.770), train_loss = 0.95071819, grad/param norm = 2.1863e-01, time/batch = 16.6538s	
13427/26050 (epoch 25.772), train_loss = 0.96811640, grad/param norm = 1.8067e-01, time/batch = 17.5399s	
13428/26050 (epoch 25.774), train_loss = 0.84123821, grad/param norm = 2.0398e-01, time/batch = 18.3789s	
13429/26050 (epoch 25.775), train_loss = 0.71696863, grad/param norm = 1.8935e-01, time/batch = 14.8828s	
13430/26050 (epoch 25.777), train_loss = 0.91612830, grad/param norm = 1.8889e-01, time/batch = 18.8227s	
13431/26050 (epoch 25.779), train_loss = 0.94405469, grad/param norm = 2.0172e-01, time/batch = 16.5444s	
13432/26050 (epoch 25.781), train_loss = 0.84308129, grad/param norm = 1.8131e-01, time/batch = 18.2340s	
13433/26050 (epoch 25.783), train_loss = 0.83982005, grad/param norm = 1.8504e-01, time/batch = 17.4083s	
13434/26050 (epoch 25.785), train_loss = 0.98742003, grad/param norm = 2.1045e-01, time/batch = 15.3755s	
13435/26050 (epoch 25.787), train_loss = 0.87021273, grad/param norm = 2.0126e-01, time/batch = 18.6610s	
13436/26050 (epoch 25.789), train_loss = 0.91263436, grad/param norm = 2.0249e-01, time/batch = 17.9909s	
13437/26050 (epoch 25.791), train_loss = 0.89501648, grad/param norm = 1.8840e-01, time/batch = 15.3112s	
13438/26050 (epoch 25.793), train_loss = 0.93189635, grad/param norm = 1.8823e-01, time/batch = 18.7231s	
13439/26050 (epoch 25.795), train_loss = 0.78862634, grad/param norm = 1.5563e-01, time/batch = 17.8981s	
13440/26050 (epoch 25.797), train_loss = 0.86278662, grad/param norm = 1.9729e-01, time/batch = 17.7394s	
13441/26050 (epoch 25.798), train_loss = 0.82551400, grad/param norm = 1.8530e-01, time/batch = 17.3955s	
13442/26050 (epoch 25.800), train_loss = 0.83049233, grad/param norm = 1.6964e-01, time/batch = 18.3377s	
13443/26050 (epoch 25.802), train_loss = 0.91436260, grad/param norm = 1.9674e-01, time/batch = 18.3231s	
13444/26050 (epoch 25.804), train_loss = 0.95113720, grad/param norm = 2.0279e-01, time/batch = 17.4036s	
13445/26050 (epoch 25.806), train_loss = 1.03746751, grad/param norm = 1.9704e-01, time/batch = 18.8967s	
13446/26050 (epoch 25.808), train_loss = 0.96119331, grad/param norm = 2.1288e-01, time/batch = 18.5656s	
13447/26050 (epoch 25.810), train_loss = 0.89871250, grad/param norm = 1.9261e-01, time/batch = 15.3056s	
13448/26050 (epoch 25.812), train_loss = 0.82730910, grad/param norm = 1.9056e-01, time/batch = 16.7188s	
13449/26050 (epoch 25.814), train_loss = 0.87321373, grad/param norm = 2.3764e-01, time/batch = 18.4859s	
13450/26050 (epoch 25.816), train_loss = 1.02446434, grad/param norm = 2.2251e-01, time/batch = 17.9875s	
13451/26050 (epoch 25.818), train_loss = 1.05590763, grad/param norm = 2.2252e-01, time/batch = 17.6466s	
13452/26050 (epoch 25.820), train_loss = 0.98158789, grad/param norm = 1.8713e-01, time/batch = 18.8122s	
13453/26050 (epoch 25.821), train_loss = 1.07402554, grad/param norm = 2.1712e-01, time/batch = 18.9020s	
13454/26050 (epoch 25.823), train_loss = 1.13031142, grad/param norm = 1.9965e-01, time/batch = 16.2296s	
13455/26050 (epoch 25.825), train_loss = 0.95161697, grad/param norm = 2.0194e-01, time/batch = 18.1469s	
13456/26050 (epoch 25.827), train_loss = 0.99740500, grad/param norm = 2.1748e-01, time/batch = 16.2207s	
13457/26050 (epoch 25.829), train_loss = 1.02498155, grad/param norm = 2.0472e-01, time/batch = 16.1282s	
13458/26050 (epoch 25.831), train_loss = 1.10024728, grad/param norm = 1.9501e-01, time/batch = 15.8746s	
13459/26050 (epoch 25.833), train_loss = 1.13868699, grad/param norm = 2.1706e-01, time/batch = 17.4791s	
13460/26050 (epoch 25.835), train_loss = 1.13285982, grad/param norm = 2.0425e-01, time/batch = 18.5782s	
13461/26050 (epoch 25.837), train_loss = 0.96486997, grad/param norm = 1.7149e-01, time/batch = 17.9014s	
13462/26050 (epoch 25.839), train_loss = 0.96780307, grad/param norm = 2.2389e-01, time/batch = 18.2386s	
13463/26050 (epoch 25.841), train_loss = 1.09381455, grad/param norm = 2.0188e-01, time/batch = 18.2352s	
13464/26050 (epoch 25.843), train_loss = 0.94846536, grad/param norm = 1.7979e-01, time/batch = 15.3923s	
13465/26050 (epoch 25.845), train_loss = 0.92333666, grad/param norm = 1.7806e-01, time/batch = 17.1376s	
13466/26050 (epoch 25.846), train_loss = 1.03595698, grad/param norm = 2.1109e-01, time/batch = 18.2297s	
13467/26050 (epoch 25.848), train_loss = 0.93849428, grad/param norm = 1.8272e-01, time/batch = 17.0662s	
13468/26050 (epoch 25.850), train_loss = 0.87263386, grad/param norm = 1.8377e-01, time/batch = 15.8697s	
13469/26050 (epoch 25.852), train_loss = 0.98300648, grad/param norm = 1.9668e-01, time/batch = 18.3252s	
13470/26050 (epoch 25.854), train_loss = 0.94046672, grad/param norm = 1.8501e-01, time/batch = 14.6462s	
13471/26050 (epoch 25.856), train_loss = 0.90302261, grad/param norm = 1.8911e-01, time/batch = 17.9898s	
13472/26050 (epoch 25.858), train_loss = 0.89560061, grad/param norm = 1.8557e-01, time/batch = 18.4664s	
13473/26050 (epoch 25.860), train_loss = 1.00142544, grad/param norm = 1.9729e-01, time/batch = 17.9786s	
13474/26050 (epoch 25.862), train_loss = 1.04289081, grad/param norm = 1.9587e-01, time/batch = 18.3094s	
13475/26050 (epoch 25.864), train_loss = 0.99324787, grad/param norm = 2.1889e-01, time/batch = 17.7312s	
13476/26050 (epoch 25.866), train_loss = 0.92019393, grad/param norm = 1.6963e-01, time/batch = 18.3913s	
13477/26050 (epoch 25.868), train_loss = 1.00276845, grad/param norm = 2.0352e-01, time/batch = 15.7200s	
13478/26050 (epoch 25.869), train_loss = 0.86978248, grad/param norm = 1.8775e-01, time/batch = 17.2885s	
13479/26050 (epoch 25.871), train_loss = 0.80188360, grad/param norm = 1.7050e-01, time/batch = 17.4798s	
13480/26050 (epoch 25.873), train_loss = 0.99743061, grad/param norm = 1.9837e-01, time/batch = 15.3971s	
13481/26050 (epoch 25.875), train_loss = 0.95414902, grad/param norm = 2.0092e-01, time/batch = 18.2318s	
13482/26050 (epoch 25.877), train_loss = 0.86154998, grad/param norm = 1.6636e-01, time/batch = 16.5723s	
13483/26050 (epoch 25.879), train_loss = 0.98155034, grad/param norm = 1.6793e-01, time/batch = 17.4983s	
13484/26050 (epoch 25.881), train_loss = 1.07488777, grad/param norm = 2.2131e-01, time/batch = 18.7451s	
13485/26050 (epoch 25.883), train_loss = 1.01331988, grad/param norm = 1.9216e-01, time/batch = 17.9947s	
13486/26050 (epoch 25.885), train_loss = 0.74518133, grad/param norm = 1.7772e-01, time/batch = 17.7369s	
13487/26050 (epoch 25.887), train_loss = 1.02296811, grad/param norm = 2.0615e-01, time/batch = 17.9885s	
13488/26050 (epoch 25.889), train_loss = 0.89628478, grad/param norm = 1.7915e-01, time/batch = 18.7229s	
13489/26050 (epoch 25.891), train_loss = 0.79532567, grad/param norm = 1.6778e-01, time/batch = 18.2268s	
13490/26050 (epoch 25.893), train_loss = 0.84530844, grad/param norm = 1.8761e-01, time/batch = 18.1386s	
13491/26050 (epoch 25.894), train_loss = 0.92852058, grad/param norm = 1.9250e-01, time/batch = 18.4058s	
13492/26050 (epoch 25.896), train_loss = 1.05532795, grad/param norm = 2.1438e-01, time/batch = 16.3104s	
13493/26050 (epoch 25.898), train_loss = 0.91966701, grad/param norm = 2.2509e-01, time/batch = 18.2281s	
13494/26050 (epoch 25.900), train_loss = 1.00039243, grad/param norm = 2.2308e-01, time/batch = 17.2093s	
13495/26050 (epoch 25.902), train_loss = 0.95192700, grad/param norm = 2.0097e-01, time/batch = 17.2046s	
13496/26050 (epoch 25.904), train_loss = 0.92744524, grad/param norm = 1.9090e-01, time/batch = 15.4768s	
13497/26050 (epoch 25.906), train_loss = 0.92938948, grad/param norm = 2.0956e-01, time/batch = 17.5487s	
13498/26050 (epoch 25.908), train_loss = 0.95832168, grad/param norm = 1.8527e-01, time/batch = 18.2349s	
13499/26050 (epoch 25.910), train_loss = 0.92884735, grad/param norm = 1.7170e-01, time/batch = 16.7245s	
13500/26050 (epoch 25.912), train_loss = 1.15529516, grad/param norm = 2.2059e-01, time/batch = 18.4743s	
13501/26050 (epoch 25.914), train_loss = 1.30741651, grad/param norm = 2.2930e-01, time/batch = 18.1443s	
13502/26050 (epoch 25.916), train_loss = 1.05032040, grad/param norm = 2.1073e-01, time/batch = 17.7345s	
13503/26050 (epoch 25.917), train_loss = 0.96932706, grad/param norm = 2.0772e-01, time/batch = 17.4682s	
13504/26050 (epoch 25.919), train_loss = 1.00827162, grad/param norm = 2.0769e-01, time/batch = 17.3985s	
13505/26050 (epoch 25.921), train_loss = 0.91909709, grad/param norm = 1.9824e-01, time/batch = 15.8901s	
13506/26050 (epoch 25.923), train_loss = 0.98055625, grad/param norm = 1.9150e-01, time/batch = 17.6355s	
13507/26050 (epoch 25.925), train_loss = 0.97210499, grad/param norm = 1.9701e-01, time/batch = 17.8015s	
13508/26050 (epoch 25.927), train_loss = 0.86025790, grad/param norm = 1.5374e-01, time/batch = 18.0681s	
13509/26050 (epoch 25.929), train_loss = 0.82485363, grad/param norm = 1.7188e-01, time/batch = 17.6453s	
13510/26050 (epoch 25.931), train_loss = 1.13039465, grad/param norm = 2.4072e-01, time/batch = 17.8244s	
13511/26050 (epoch 25.933), train_loss = 0.91370756, grad/param norm = 1.9031e-01, time/batch = 19.0683s	
13512/26050 (epoch 25.935), train_loss = 0.93766462, grad/param norm = 1.9477e-01, time/batch = 18.0672s	
13513/26050 (epoch 25.937), train_loss = 1.05034925, grad/param norm = 1.8822e-01, time/batch = 18.5728s	
13514/26050 (epoch 25.939), train_loss = 0.87586665, grad/param norm = 1.5965e-01, time/batch = 18.5739s	
13515/26050 (epoch 25.940), train_loss = 0.91003262, grad/param norm = 1.6576e-01, time/batch = 17.8976s	
13516/26050 (epoch 25.942), train_loss = 0.94416763, grad/param norm = 1.8859e-01, time/batch = 17.6254s	
13517/26050 (epoch 25.944), train_loss = 0.92670956, grad/param norm = 1.7050e-01, time/batch = 14.8248s	
13518/26050 (epoch 25.946), train_loss = 1.08855442, grad/param norm = 2.0120e-01, time/batch = 18.6520s	
13519/26050 (epoch 25.948), train_loss = 0.82192762, grad/param norm = 1.7954e-01, time/batch = 16.3100s	
13520/26050 (epoch 25.950), train_loss = 0.92450163, grad/param norm = 1.8703e-01, time/batch = 17.9720s	
13521/26050 (epoch 25.952), train_loss = 1.03780234, grad/param norm = 1.9995e-01, time/batch = 18.6546s	
13522/26050 (epoch 25.954), train_loss = 1.07107286, grad/param norm = 2.1161e-01, time/batch = 18.3221s	
13523/26050 (epoch 25.956), train_loss = 0.94122422, grad/param norm = 2.0382e-01, time/batch = 18.7281s	
13524/26050 (epoch 25.958), train_loss = 0.88771090, grad/param norm = 1.8570e-01, time/batch = 18.1539s	
13525/26050 (epoch 25.960), train_loss = 1.00022025, grad/param norm = 2.0729e-01, time/batch = 19.2296s	
13526/26050 (epoch 25.962), train_loss = 0.93891773, grad/param norm = 1.8160e-01, time/batch = 16.6348s	
13527/26050 (epoch 25.964), train_loss = 0.96896258, grad/param norm = 1.8832e-01, time/batch = 18.3984s	
13528/26050 (epoch 25.965), train_loss = 0.88456734, grad/param norm = 1.9179e-01, time/batch = 14.8992s	
13529/26050 (epoch 25.967), train_loss = 1.28321052, grad/param norm = 2.0948e-01, time/batch = 17.2376s	
13530/26050 (epoch 25.969), train_loss = 0.99475894, grad/param norm = 1.9856e-01, time/batch = 18.3078s	
13531/26050 (epoch 25.971), train_loss = 0.92660699, grad/param norm = 1.9678e-01, time/batch = 18.7401s	
13532/26050 (epoch 25.973), train_loss = 0.95976876, grad/param norm = 1.9698e-01, time/batch = 18.0585s	
13533/26050 (epoch 25.975), train_loss = 0.99863491, grad/param norm = 2.0868e-01, time/batch = 15.0606s	
13534/26050 (epoch 25.977), train_loss = 0.97908747, grad/param norm = 1.7877e-01, time/batch = 17.8200s	
13535/26050 (epoch 25.979), train_loss = 0.80085665, grad/param norm = 1.8145e-01, time/batch = 18.5686s	
13536/26050 (epoch 25.981), train_loss = 1.10011972, grad/param norm = 1.9341e-01, time/batch = 17.4965s	
13537/26050 (epoch 25.983), train_loss = 1.04211242, grad/param norm = 2.1612e-01, time/batch = 18.1625s	
13538/26050 (epoch 25.985), train_loss = 1.00832248, grad/param norm = 1.8297e-01, time/batch = 16.3067s	
13539/26050 (epoch 25.987), train_loss = 1.07309365, grad/param norm = 2.0431e-01, time/batch = 17.5690s	
13540/26050 (epoch 25.988), train_loss = 1.01022341, grad/param norm = 1.9774e-01, time/batch = 18.0606s	
13541/26050 (epoch 25.990), train_loss = 0.85719235, grad/param norm = 1.6873e-01, time/batch = 17.8227s	
13542/26050 (epoch 25.992), train_loss = 1.12163769, grad/param norm = 1.9819e-01, time/batch = 15.4797s	
13543/26050 (epoch 25.994), train_loss = 0.92568772, grad/param norm = 2.1632e-01, time/batch = 16.9805s	
13544/26050 (epoch 25.996), train_loss = 0.88731085, grad/param norm = 2.0230e-01, time/batch = 15.2070s	
13545/26050 (epoch 25.998), train_loss = 0.96911061, grad/param norm = 1.7813e-01, time/batch = 18.2438s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
13546/26050 (epoch 26.000), train_loss = 0.93589349, grad/param norm = 2.2345e-01, time/batch = 17.9809s	
13547/26050 (epoch 26.002), train_loss = 1.03026804, grad/param norm = 2.2731e-01, time/batch = 18.2280s	
13548/26050 (epoch 26.004), train_loss = 0.86489637, grad/param norm = 1.9116e-01, time/batch = 18.2342s	
13549/26050 (epoch 26.006), train_loss = 0.91342133, grad/param norm = 2.0983e-01, time/batch = 18.2338s	
13550/26050 (epoch 26.008), train_loss = 0.89706286, grad/param norm = 1.9742e-01, time/batch = 16.8892s	
13551/26050 (epoch 26.010), train_loss = 0.89623791, grad/param norm = 1.9366e-01, time/batch = 18.3873s	
13552/26050 (epoch 26.012), train_loss = 0.96690019, grad/param norm = 1.8760e-01, time/batch = 18.8099s	
13553/26050 (epoch 26.013), train_loss = 1.21924454, grad/param norm = 2.1396e-01, time/batch = 16.3014s	
13554/26050 (epoch 26.015), train_loss = 0.94066112, grad/param norm = 1.7491e-01, time/batch = 16.3726s	
13555/26050 (epoch 26.017), train_loss = 0.98708401, grad/param norm = 1.9192e-01, time/batch = 16.7138s	
13556/26050 (epoch 26.019), train_loss = 0.85810550, grad/param norm = 1.7830e-01, time/batch = 18.2343s	
13557/26050 (epoch 26.021), train_loss = 1.05087895, grad/param norm = 2.0543e-01, time/batch = 18.7216s	
13558/26050 (epoch 26.023), train_loss = 0.78519805, grad/param norm = 1.7189e-01, time/batch = 15.3744s	
13559/26050 (epoch 26.025), train_loss = 0.95115846, grad/param norm = 1.8152e-01, time/batch = 16.9675s	
13560/26050 (epoch 26.027), train_loss = 0.78830974, grad/param norm = 1.8512e-01, time/batch = 16.7167s	
13561/26050 (epoch 26.029), train_loss = 0.97766187, grad/param norm = 1.7883e-01, time/batch = 18.8936s	
13562/26050 (epoch 26.031), train_loss = 1.08768674, grad/param norm = 2.1572e-01, time/batch = 18.2188s	
13563/26050 (epoch 26.033), train_loss = 0.97527072, grad/param norm = 2.0249e-01, time/batch = 18.3777s	
13564/26050 (epoch 26.035), train_loss = 0.98052763, grad/param norm = 1.8333e-01, time/batch = 18.2906s	
13565/26050 (epoch 26.036), train_loss = 0.82672649, grad/param norm = 1.9237e-01, time/batch = 18.0614s	
13566/26050 (epoch 26.038), train_loss = 0.77132225, grad/param norm = 1.8175e-01, time/batch = 18.3971s	
13567/26050 (epoch 26.040), train_loss = 0.93965582, grad/param norm = 1.9171e-01, time/batch = 18.1279s	
13568/26050 (epoch 26.042), train_loss = 0.81786870, grad/param norm = 1.9182e-01, time/batch = 16.1102s	
13569/26050 (epoch 26.044), train_loss = 1.01840603, grad/param norm = 1.7872e-01, time/batch = 17.6339s	
13570/26050 (epoch 26.046), train_loss = 0.78515879, grad/param norm = 1.7187e-01, time/batch = 17.4040s	
13571/26050 (epoch 26.048), train_loss = 0.96430622, grad/param norm = 1.7872e-01, time/batch = 16.5642s	
13572/26050 (epoch 26.050), train_loss = 0.90601252, grad/param norm = 1.8621e-01, time/batch = 18.0490s	
13573/26050 (epoch 26.052), train_loss = 0.87858500, grad/param norm = 1.9189e-01, time/batch = 17.8836s	
13574/26050 (epoch 26.054), train_loss = 0.80058456, grad/param norm = 1.7774e-01, time/batch = 17.7996s	
13575/26050 (epoch 26.056), train_loss = 0.78551673, grad/param norm = 1.7649e-01, time/batch = 17.7198s	
13576/26050 (epoch 26.058), train_loss = 0.93883311, grad/param norm = 1.8304e-01, time/batch = 17.1483s	
13577/26050 (epoch 26.060), train_loss = 1.02931596, grad/param norm = 1.9551e-01, time/batch = 17.0465s	
13578/26050 (epoch 26.061), train_loss = 0.86902858, grad/param norm = 1.7531e-01, time/batch = 18.6411s	
13579/26050 (epoch 26.063), train_loss = 0.98865275, grad/param norm = 1.8873e-01, time/batch = 17.9185s	
13580/26050 (epoch 26.065), train_loss = 0.78307479, grad/param norm = 1.6371e-01, time/batch = 17.3888s	
13581/26050 (epoch 26.067), train_loss = 0.94018397, grad/param norm = 1.9570e-01, time/batch = 19.0660s	
13582/26050 (epoch 26.069), train_loss = 0.99928553, grad/param norm = 1.9586e-01, time/batch = 18.2236s	
13583/26050 (epoch 26.071), train_loss = 1.00371909, grad/param norm = 1.9528e-01, time/batch = 17.6321s	
13584/26050 (epoch 26.073), train_loss = 1.09450349, grad/param norm = 1.8600e-01, time/batch = 17.9746s	
13585/26050 (epoch 26.075), train_loss = 0.87831086, grad/param norm = 1.7744e-01, time/batch = 18.8254s	
13586/26050 (epoch 26.077), train_loss = 0.91625694, grad/param norm = 2.0280e-01, time/batch = 17.9900s	
13587/26050 (epoch 26.079), train_loss = 0.94772068, grad/param norm = 1.9080e-01, time/batch = 17.8804s	
13588/26050 (epoch 26.081), train_loss = 0.93212923, grad/param norm = 1.9058e-01, time/batch = 17.9113s	
13589/26050 (epoch 26.083), train_loss = 1.05077583, grad/param norm = 1.8091e-01, time/batch = 18.4122s	
13590/26050 (epoch 26.084), train_loss = 0.97630142, grad/param norm = 2.8857e-01, time/batch = 17.1612s	
13591/26050 (epoch 26.086), train_loss = 1.12866312, grad/param norm = 2.2652e-01, time/batch = 16.7309s	
13592/26050 (epoch 26.088), train_loss = 0.90720674, grad/param norm = 2.0298e-01, time/batch = 16.0329s	
13593/26050 (epoch 26.090), train_loss = 0.94624731, grad/param norm = 1.9175e-01, time/batch = 15.1368s	
13594/26050 (epoch 26.092), train_loss = 1.01640956, grad/param norm = 1.9651e-01, time/batch = 16.8211s	
13595/26050 (epoch 26.094), train_loss = 0.86865559, grad/param norm = 1.9003e-01, time/batch = 18.0668s	
13596/26050 (epoch 26.096), train_loss = 0.96033957, grad/param norm = 1.8131e-01, time/batch = 18.5578s	
13597/26050 (epoch 26.098), train_loss = 0.89720752, grad/param norm = 1.7446e-01, time/batch = 17.5561s	
13598/26050 (epoch 26.100), train_loss = 0.86406456, grad/param norm = 1.7704e-01, time/batch = 17.8116s	
13599/26050 (epoch 26.102), train_loss = 1.01276223, grad/param norm = 2.1397e-01, time/batch = 18.5688s	
13600/26050 (epoch 26.104), train_loss = 0.91470064, grad/param norm = 1.8970e-01, time/batch = 17.7188s	
13601/26050 (epoch 26.106), train_loss = 0.94200172, grad/param norm = 2.1848e-01, time/batch = 17.7161s	
13602/26050 (epoch 26.107), train_loss = 0.77156310, grad/param norm = 1.8370e-01, time/batch = 18.8091s	
13603/26050 (epoch 26.109), train_loss = 0.87450284, grad/param norm = 1.8818e-01, time/batch = 15.1527s	
13604/26050 (epoch 26.111), train_loss = 1.11147046, grad/param norm = 2.0426e-01, time/batch = 17.6537s	
13605/26050 (epoch 26.113), train_loss = 0.90868206, grad/param norm = 1.8848e-01, time/batch = 18.0650s	
13606/26050 (epoch 26.115), train_loss = 1.04459611, grad/param norm = 2.0328e-01, time/batch = 17.3269s	
13607/26050 (epoch 26.117), train_loss = 0.94568404, grad/param norm = 1.8347e-01, time/batch = 16.2007s	
13608/26050 (epoch 26.119), train_loss = 0.79368229, grad/param norm = 1.7008e-01, time/batch = 18.1531s	
13609/26050 (epoch 26.121), train_loss = 0.95895981, grad/param norm = 1.7762e-01, time/batch = 17.6416s	
13610/26050 (epoch 26.123), train_loss = 0.87077137, grad/param norm = 1.8615e-01, time/batch = 18.3217s	
13611/26050 (epoch 26.125), train_loss = 0.83406715, grad/param norm = 1.7161e-01, time/batch = 18.9807s	
13612/26050 (epoch 26.127), train_loss = 0.77490212, grad/param norm = 1.7761e-01, time/batch = 17.0539s	
13613/26050 (epoch 26.129), train_loss = 0.79378724, grad/param norm = 1.8748e-01, time/batch = 17.7262s	
13614/26050 (epoch 26.131), train_loss = 0.90738377, grad/param norm = 1.8058e-01, time/batch = 15.3249s	
13615/26050 (epoch 26.132), train_loss = 0.92124640, grad/param norm = 1.7521e-01, time/batch = 16.3085s	
13616/26050 (epoch 26.134), train_loss = 0.95732882, grad/param norm = 1.9998e-01, time/batch = 18.3240s	
13617/26050 (epoch 26.136), train_loss = 0.93271655, grad/param norm = 1.8339e-01, time/batch = 15.0573s	
13618/26050 (epoch 26.138), train_loss = 0.71469695, grad/param norm = 1.7528e-01, time/batch = 27.6593s	
13619/26050 (epoch 26.140), train_loss = 0.79407291, grad/param norm = 1.8887e-01, time/batch = 28.4480s	
13620/26050 (epoch 26.142), train_loss = 0.82251422, grad/param norm = 1.7886e-01, time/batch = 17.5474s	
13621/26050 (epoch 26.144), train_loss = 0.75419019, grad/param norm = 1.9135e-01, time/batch = 18.8850s	
13622/26050 (epoch 26.146), train_loss = 0.71113881, grad/param norm = 1.6818e-01, time/batch = 17.9029s	
13623/26050 (epoch 26.148), train_loss = 0.74311694, grad/param norm = 1.5560e-01, time/batch = 17.2367s	
13624/26050 (epoch 26.150), train_loss = 0.89579398, grad/param norm = 1.9763e-01, time/batch = 18.8777s	
13625/26050 (epoch 26.152), train_loss = 1.09287621, grad/param norm = 2.4801e-01, time/batch = 15.8799s	
13626/26050 (epoch 26.154), train_loss = 0.74566707, grad/param norm = 1.7958e-01, time/batch = 18.2933s	
13627/26050 (epoch 26.155), train_loss = 0.81597303, grad/param norm = 2.4315e-01, time/batch = 18.3085s	
13628/26050 (epoch 26.157), train_loss = 0.90748231, grad/param norm = 2.1930e-01, time/batch = 18.6516s	
13629/26050 (epoch 26.159), train_loss = 0.95590122, grad/param norm = 2.0898e-01, time/batch = 17.9879s	
13630/26050 (epoch 26.161), train_loss = 0.95051601, grad/param norm = 2.0089e-01, time/batch = 17.0575s	
13631/26050 (epoch 26.163), train_loss = 0.76473333, grad/param norm = 1.6548e-01, time/batch = 17.8324s	
13632/26050 (epoch 26.165), train_loss = 0.73692385, grad/param norm = 1.8951e-01, time/batch = 17.1505s	
13633/26050 (epoch 26.167), train_loss = 1.05919345, grad/param norm = 2.1411e-01, time/batch = 17.1187s	
13634/26050 (epoch 26.169), train_loss = 0.93972278, grad/param norm = 1.9851e-01, time/batch = 18.1496s	
13635/26050 (epoch 26.171), train_loss = 0.79341049, grad/param norm = 1.7073e-01, time/batch = 15.7135s	
13636/26050 (epoch 26.173), train_loss = 0.89305795, grad/param norm = 1.9624e-01, time/batch = 17.6451s	
13637/26050 (epoch 26.175), train_loss = 0.89639779, grad/param norm = 1.8168e-01, time/batch = 17.8892s	
13638/26050 (epoch 26.177), train_loss = 1.02578212, grad/param norm = 1.9275e-01, time/batch = 18.3195s	
13639/26050 (epoch 26.179), train_loss = 0.67905302, grad/param norm = 1.5343e-01, time/batch = 17.5013s	
13640/26050 (epoch 26.180), train_loss = 1.13019646, grad/param norm = 1.9533e-01, time/batch = 17.6584s	
13641/26050 (epoch 26.182), train_loss = 1.15759412, grad/param norm = 2.0821e-01, time/batch = 17.3129s	
13642/26050 (epoch 26.184), train_loss = 0.96296046, grad/param norm = 1.8149e-01, time/batch = 16.6158s	
13643/26050 (epoch 26.186), train_loss = 0.78102474, grad/param norm = 1.8087e-01, time/batch = 17.9843s	
13644/26050 (epoch 26.188), train_loss = 0.95249490, grad/param norm = 1.8740e-01, time/batch = 17.3095s	
13645/26050 (epoch 26.190), train_loss = 0.97786452, grad/param norm = 1.9550e-01, time/batch = 18.1404s	
13646/26050 (epoch 26.192), train_loss = 0.98392531, grad/param norm = 1.8362e-01, time/batch = 18.5715s	
13647/26050 (epoch 26.194), train_loss = 0.97533573, grad/param norm = 1.9311e-01, time/batch = 17.7347s	
13648/26050 (epoch 26.196), train_loss = 1.00734697, grad/param norm = 1.9453e-01, time/batch = 17.2324s	
13649/26050 (epoch 26.198), train_loss = 0.85608994, grad/param norm = 1.7176e-01, time/batch = 18.1463s	
13650/26050 (epoch 26.200), train_loss = 0.83775056, grad/param norm = 1.8029e-01, time/batch = 14.8840s	
13651/26050 (epoch 26.202), train_loss = 0.94602647, grad/param norm = 1.7148e-01, time/batch = 17.1658s	
13652/26050 (epoch 26.203), train_loss = 1.04586277, grad/param norm = 1.9003e-01, time/batch = 16.4015s	
13653/26050 (epoch 26.205), train_loss = 0.90321295, grad/param norm = 1.9144e-01, time/batch = 16.7270s	
13654/26050 (epoch 26.207), train_loss = 0.86478757, grad/param norm = 1.8482e-01, time/batch = 16.3271s	
13655/26050 (epoch 26.209), train_loss = 0.99188235, grad/param norm = 1.8612e-01, time/batch = 18.3173s	
13656/26050 (epoch 26.211), train_loss = 0.77764797, grad/param norm = 1.7094e-01, time/batch = 18.4142s	
13657/26050 (epoch 26.213), train_loss = 0.96375789, grad/param norm = 2.0632e-01, time/batch = 17.0710s	
13658/26050 (epoch 26.215), train_loss = 0.92829912, grad/param norm = 2.2448e-01, time/batch = 18.6552s	
13659/26050 (epoch 26.217), train_loss = 0.89754138, grad/param norm = 1.7785e-01, time/batch = 16.3881s	
13660/26050 (epoch 26.219), train_loss = 0.91320052, grad/param norm = 2.0178e-01, time/batch = 17.5648s	
13661/26050 (epoch 26.221), train_loss = 0.85731623, grad/param norm = 2.0433e-01, time/batch = 16.3754s	
13662/26050 (epoch 26.223), train_loss = 0.99941372, grad/param norm = 1.9472e-01, time/batch = 15.0508s	
13663/26050 (epoch 26.225), train_loss = 0.85670523, grad/param norm = 2.0490e-01, time/batch = 17.9893s	
13664/26050 (epoch 26.226), train_loss = 0.98060340, grad/param norm = 2.1183e-01, time/batch = 17.6519s	
13665/26050 (epoch 26.228), train_loss = 1.06718947, grad/param norm = 1.9581e-01, time/batch = 18.5731s	
13666/26050 (epoch 26.230), train_loss = 0.94782813, grad/param norm = 1.8694e-01, time/batch = 17.9840s	
13667/26050 (epoch 26.232), train_loss = 1.02208022, grad/param norm = 2.1951e-01, time/batch = 18.3185s	
13668/26050 (epoch 26.234), train_loss = 0.83614627, grad/param norm = 1.9300e-01, time/batch = 17.2668s	
13669/26050 (epoch 26.236), train_loss = 1.03077509, grad/param norm = 1.8969e-01, time/batch = 18.3993s	
13670/26050 (epoch 26.238), train_loss = 0.82355185, grad/param norm = 1.9978e-01, time/batch = 16.0847s	
13671/26050 (epoch 26.240), train_loss = 0.95727264, grad/param norm = 2.4869e-01, time/batch = 17.0533s	
13672/26050 (epoch 26.242), train_loss = 0.91680073, grad/param norm = 1.8684e-01, time/batch = 17.8112s	
13673/26050 (epoch 26.244), train_loss = 0.95214458, grad/param norm = 1.9822e-01, time/batch = 15.8030s	
13674/26050 (epoch 26.246), train_loss = 0.86390407, grad/param norm = 2.1538e-01, time/batch = 15.4685s	
13675/26050 (epoch 26.248), train_loss = 0.94909666, grad/param norm = 1.9977e-01, time/batch = 18.3032s	
13676/26050 (epoch 26.250), train_loss = 0.92862247, grad/param norm = 2.0638e-01, time/batch = 17.4866s	
13677/26050 (epoch 26.251), train_loss = 0.88275634, grad/param norm = 1.7328e-01, time/batch = 18.4807s	
13678/26050 (epoch 26.253), train_loss = 0.83547226, grad/param norm = 1.8285e-01, time/batch = 17.4117s	
13679/26050 (epoch 26.255), train_loss = 1.09159726, grad/param norm = 2.1115e-01, time/batch = 18.2394s	
13680/26050 (epoch 26.257), train_loss = 0.93682219, grad/param norm = 2.2297e-01, time/batch = 18.7402s	
13681/26050 (epoch 26.259), train_loss = 1.04840431, grad/param norm = 1.9952e-01, time/batch = 14.6265s	
13682/26050 (epoch 26.261), train_loss = 0.84055196, grad/param norm = 2.0909e-01, time/batch = 18.0671s	
13683/26050 (epoch 26.263), train_loss = 1.04170882, grad/param norm = 2.1598e-01, time/batch = 18.5632s	
13684/26050 (epoch 26.265), train_loss = 1.08257695, grad/param norm = 2.0400e-01, time/batch = 16.3067s	
13685/26050 (epoch 26.267), train_loss = 1.05092275, grad/param norm = 1.8454e-01, time/batch = 16.4686s	
13686/26050 (epoch 26.269), train_loss = 1.05557287, grad/param norm = 1.9931e-01, time/batch = 17.7603s	
13687/26050 (epoch 26.271), train_loss = 0.99469103, grad/param norm = 2.1935e-01, time/batch = 18.3302s	
13688/26050 (epoch 26.273), train_loss = 0.88279992, grad/param norm = 2.3031e-01, time/batch = 17.8947s	
13689/26050 (epoch 26.274), train_loss = 0.92092389, grad/param norm = 1.7812e-01, time/batch = 17.2295s	
13690/26050 (epoch 26.276), train_loss = 0.91461722, grad/param norm = 2.1761e-01, time/batch = 18.1629s	
13691/26050 (epoch 26.278), train_loss = 1.04556682, grad/param norm = 1.9088e-01, time/batch = 18.3250s	
13692/26050 (epoch 26.280), train_loss = 0.93284066, grad/param norm = 1.7631e-01, time/batch = 17.5508s	
13693/26050 (epoch 26.282), train_loss = 0.98180102, grad/param norm = 1.9572e-01, time/batch = 15.6066s	
13694/26050 (epoch 26.284), train_loss = 0.92734024, grad/param norm = 1.9508e-01, time/batch = 17.9692s	
13695/26050 (epoch 26.286), train_loss = 0.96292114, grad/param norm = 2.1920e-01, time/batch = 17.9151s	
13696/26050 (epoch 26.288), train_loss = 0.80800129, grad/param norm = 1.7425e-01, time/batch = 16.5480s	
13697/26050 (epoch 26.290), train_loss = 0.95199224, grad/param norm = 1.9427e-01, time/batch = 18.3935s	
13698/26050 (epoch 26.292), train_loss = 0.87611131, grad/param norm = 1.8137e-01, time/batch = 17.5701s	
13699/26050 (epoch 26.294), train_loss = 0.94481664, grad/param norm = 2.0958e-01, time/batch = 16.6381s	
13700/26050 (epoch 26.296), train_loss = 1.04470913, grad/param norm = 1.9987e-01, time/batch = 18.8102s	
13701/26050 (epoch 26.298), train_loss = 0.95824649, grad/param norm = 1.6925e-01, time/batch = 17.1520s	
13702/26050 (epoch 26.299), train_loss = 0.78851526, grad/param norm = 1.6073e-01, time/batch = 16.1791s	
13703/26050 (epoch 26.301), train_loss = 0.80128762, grad/param norm = 1.8985e-01, time/batch = 18.0533s	
13704/26050 (epoch 26.303), train_loss = 0.95514088, grad/param norm = 2.6557e-01, time/batch = 18.5657s	
13705/26050 (epoch 26.305), train_loss = 0.75835258, grad/param norm = 1.8868e-01, time/batch = 17.4076s	
13706/26050 (epoch 26.307), train_loss = 0.85983094, grad/param norm = 2.0081e-01, time/batch = 18.6671s	
13707/26050 (epoch 26.309), train_loss = 0.91890708, grad/param norm = 2.1073e-01, time/batch = 16.6434s	
13708/26050 (epoch 26.311), train_loss = 1.01881940, grad/param norm = 2.4622e-01, time/batch = 17.6416s	
13709/26050 (epoch 26.313), train_loss = 0.93267613, grad/param norm = 2.3774e-01, time/batch = 17.4875s	
13710/26050 (epoch 26.315), train_loss = 1.01585654, grad/param norm = 1.9329e-01, time/batch = 18.1592s	
13711/26050 (epoch 26.317), train_loss = 0.95869149, grad/param norm = 1.9444e-01, time/batch = 18.2348s	
13712/26050 (epoch 26.319), train_loss = 0.85985594, grad/param norm = 2.0742e-01, time/batch = 17.2329s	
13713/26050 (epoch 26.321), train_loss = 0.92400321, grad/param norm = 1.9653e-01, time/batch = 15.3182s	
13714/26050 (epoch 26.322), train_loss = 0.99189203, grad/param norm = 1.8439e-01, time/batch = 18.7377s	
13715/26050 (epoch 26.324), train_loss = 0.75832162, grad/param norm = 1.6387e-01, time/batch = 17.2438s	
13716/26050 (epoch 26.326), train_loss = 1.07413722, grad/param norm = 2.0979e-01, time/batch = 18.1499s	
13717/26050 (epoch 26.328), train_loss = 0.94232614, grad/param norm = 1.6906e-01, time/batch = 18.4891s	
13718/26050 (epoch 26.330), train_loss = 0.79975076, grad/param norm = 1.8147e-01, time/batch = 17.4876s	
13719/26050 (epoch 26.332), train_loss = 1.00711987, grad/param norm = 2.1264e-01, time/batch = 14.3900s	
13720/26050 (epoch 26.334), train_loss = 0.86818487, grad/param norm = 1.8348e-01, time/batch = 18.0741s	
13721/26050 (epoch 26.336), train_loss = 0.87466651, grad/param norm = 1.8175e-01, time/batch = 18.3230s	
13722/26050 (epoch 26.338), train_loss = 0.82814820, grad/param norm = 1.7607e-01, time/batch = 17.8196s	
13723/26050 (epoch 26.340), train_loss = 1.01243404, grad/param norm = 2.0806e-01, time/batch = 18.0763s	
13724/26050 (epoch 26.342), train_loss = 1.02789398, grad/param norm = 1.8795e-01, time/batch = 17.9921s	
13725/26050 (epoch 26.344), train_loss = 0.86491557, grad/param norm = 1.9287e-01, time/batch = 14.7102s	
13726/26050 (epoch 26.345), train_loss = 0.92897481, grad/param norm = 2.0364e-01, time/batch = 17.6514s	
13727/26050 (epoch 26.347), train_loss = 1.06969538, grad/param norm = 1.9994e-01, time/batch = 17.2031s	
13728/26050 (epoch 26.349), train_loss = 0.99813877, grad/param norm = 2.1310e-01, time/batch = 14.3784s	
13729/26050 (epoch 26.351), train_loss = 0.98810546, grad/param norm = 1.9717e-01, time/batch = 14.1497s	
13730/26050 (epoch 26.353), train_loss = 0.95504445, grad/param norm = 2.1447e-01, time/batch = 15.9634s	
13731/26050 (epoch 26.355), train_loss = 0.97148855, grad/param norm = 2.1415e-01, time/batch = 14.3858s	
13732/26050 (epoch 26.357), train_loss = 0.88144667, grad/param norm = 1.7477e-01, time/batch = 15.2268s	
13733/26050 (epoch 26.359), train_loss = 1.04288462, grad/param norm = 2.1607e-01, time/batch = 16.1221s	
13734/26050 (epoch 26.361), train_loss = 0.87031900, grad/param norm = 1.8177e-01, time/batch = 15.4798s	
13735/26050 (epoch 26.363), train_loss = 1.01779378, grad/param norm = 1.8461e-01, time/batch = 18.9754s	
13736/26050 (epoch 26.365), train_loss = 0.90393838, grad/param norm = 1.6982e-01, time/batch = 18.5709s	
13737/26050 (epoch 26.367), train_loss = 1.01549298, grad/param norm = 1.8067e-01, time/batch = 10.9101s	
13738/26050 (epoch 26.369), train_loss = 0.86055257, grad/param norm = 1.6947e-01, time/batch = 0.6550s	
13739/26050 (epoch 26.370), train_loss = 0.84642183, grad/param norm = 1.6274e-01, time/batch = 0.6535s	
13740/26050 (epoch 26.372), train_loss = 0.95737713, grad/param norm = 1.9378e-01, time/batch = 0.6523s	
13741/26050 (epoch 26.374), train_loss = 1.05326947, grad/param norm = 1.9117e-01, time/batch = 0.6564s	
13742/26050 (epoch 26.376), train_loss = 1.11434901, grad/param norm = 2.1229e-01, time/batch = 0.6512s	
13743/26050 (epoch 26.378), train_loss = 0.88578819, grad/param norm = 1.7706e-01, time/batch = 0.6764s	
13744/26050 (epoch 26.380), train_loss = 1.10832518, grad/param norm = 2.2257e-01, time/batch = 0.6571s	
13745/26050 (epoch 26.382), train_loss = 1.20584402, grad/param norm = 2.1440e-01, time/batch = 0.9226s	
13746/26050 (epoch 26.384), train_loss = 0.92724125, grad/param norm = 2.5272e-01, time/batch = 0.9529s	
13747/26050 (epoch 26.386), train_loss = 1.00232309, grad/param norm = 2.4328e-01, time/batch = 0.9552s	
13748/26050 (epoch 26.388), train_loss = 0.96128009, grad/param norm = 1.9992e-01, time/batch = 0.9626s	
13749/26050 (epoch 26.390), train_loss = 0.90049424, grad/param norm = 1.8909e-01, time/batch = 0.9672s	
13750/26050 (epoch 26.392), train_loss = 0.83225568, grad/param norm = 1.7606e-01, time/batch = 1.4878s	
13751/26050 (epoch 26.393), train_loss = 0.99112223, grad/param norm = 1.9442e-01, time/batch = 1.8374s	
13752/26050 (epoch 26.395), train_loss = 1.02421591, grad/param norm = 2.1592e-01, time/batch = 1.7787s	
13753/26050 (epoch 26.397), train_loss = 1.02070014, grad/param norm = 2.3860e-01, time/batch = 12.8992s	
13754/26050 (epoch 26.399), train_loss = 0.89206620, grad/param norm = 1.9112e-01, time/batch = 15.6346s	
13755/26050 (epoch 26.401), train_loss = 0.97799463, grad/param norm = 1.9716e-01, time/batch = 17.5621s	
13756/26050 (epoch 26.403), train_loss = 0.97199870, grad/param norm = 2.1546e-01, time/batch = 18.9869s	
13757/26050 (epoch 26.405), train_loss = 0.95442001, grad/param norm = 1.9639e-01, time/batch = 16.6645s	
13758/26050 (epoch 26.407), train_loss = 1.10665975, grad/param norm = 2.0580e-01, time/batch = 17.3946s	
13759/26050 (epoch 26.409), train_loss = 1.08104130, grad/param norm = 2.1420e-01, time/batch = 18.4663s	
13760/26050 (epoch 26.411), train_loss = 1.00152612, grad/param norm = 1.9984e-01, time/batch = 18.2999s	
13761/26050 (epoch 26.413), train_loss = 1.10045188, grad/param norm = 1.8697e-01, time/batch = 14.8782s	
13762/26050 (epoch 26.415), train_loss = 1.10848564, grad/param norm = 2.4930e-01, time/batch = 15.1008s	
13763/26050 (epoch 26.417), train_loss = 1.16105107, grad/param norm = 2.2617e-01, time/batch = 17.8176s	
13764/26050 (epoch 26.418), train_loss = 1.04125142, grad/param norm = 2.2112e-01, time/batch = 17.9923s	
13765/26050 (epoch 26.420), train_loss = 0.81236123, grad/param norm = 1.6592e-01, time/batch = 17.7317s	
13766/26050 (epoch 26.422), train_loss = 0.80965778, grad/param norm = 1.8887e-01, time/batch = 18.8114s	
13767/26050 (epoch 26.424), train_loss = 1.08552104, grad/param norm = 2.1470e-01, time/batch = 15.1448s	
13768/26050 (epoch 26.426), train_loss = 1.05423522, grad/param norm = 2.0812e-01, time/batch = 17.9844s	
13769/26050 (epoch 26.428), train_loss = 0.91468193, grad/param norm = 1.7453e-01, time/batch = 16.3773s	
13770/26050 (epoch 26.430), train_loss = 1.10617607, grad/param norm = 1.9879e-01, time/batch = 18.2952s	
13771/26050 (epoch 26.432), train_loss = 0.93502360, grad/param norm = 1.8263e-01, time/batch = 17.3131s	
13772/26050 (epoch 26.434), train_loss = 0.94771897, grad/param norm = 1.9747e-01, time/batch = 16.6299s	
13773/26050 (epoch 26.436), train_loss = 1.09192378, grad/param norm = 2.0476e-01, time/batch = 17.5596s	
13774/26050 (epoch 26.438), train_loss = 1.02989593, grad/param norm = 2.2126e-01, time/batch = 17.0577s	
13775/26050 (epoch 26.440), train_loss = 0.98566157, grad/param norm = 1.9301e-01, time/batch = 18.6440s	
13776/26050 (epoch 26.441), train_loss = 0.96462906, grad/param norm = 1.8857e-01, time/batch = 17.8163s	
13777/26050 (epoch 26.443), train_loss = 0.81480976, grad/param norm = 1.5054e-01, time/batch = 18.0602s	
13778/26050 (epoch 26.445), train_loss = 0.88468138, grad/param norm = 1.7321e-01, time/batch = 18.4839s	
13779/26050 (epoch 26.447), train_loss = 1.06826803, grad/param norm = 2.0683e-01, time/batch = 17.7372s	
13780/26050 (epoch 26.449), train_loss = 0.89619157, grad/param norm = 1.8443e-01, time/batch = 17.9773s	
13781/26050 (epoch 26.451), train_loss = 1.10387278, grad/param norm = 1.9745e-01, time/batch = 15.3959s	
13782/26050 (epoch 26.453), train_loss = 0.90021458, grad/param norm = 1.7448e-01, time/batch = 18.3082s	
13783/26050 (epoch 26.455), train_loss = 0.96462866, grad/param norm = 1.8268e-01, time/batch = 16.3766s	
13784/26050 (epoch 26.457), train_loss = 0.94701312, grad/param norm = 1.8560e-01, time/batch = 16.7207s	
13785/26050 (epoch 26.459), train_loss = 1.03886021, grad/param norm = 1.9040e-01, time/batch = 18.6533s	
13786/26050 (epoch 26.461), train_loss = 1.05619196, grad/param norm = 2.4617e-01, time/batch = 16.2077s	
13787/26050 (epoch 26.463), train_loss = 0.91178376, grad/param norm = 1.6097e-01, time/batch = 18.7258s	
13788/26050 (epoch 26.464), train_loss = 1.00502006, grad/param norm = 2.1069e-01, time/batch = 15.8056s	
13789/26050 (epoch 26.466), train_loss = 1.02519176, grad/param norm = 2.0967e-01, time/batch = 18.0486s	
13790/26050 (epoch 26.468), train_loss = 1.06512384, grad/param norm = 1.8136e-01, time/batch = 16.7351s	
13791/26050 (epoch 26.470), train_loss = 1.06239554, grad/param norm = 2.2625e-01, time/batch = 18.3174s	
13792/26050 (epoch 26.472), train_loss = 1.09289164, grad/param norm = 2.3258e-01, time/batch = 17.9034s	
13793/26050 (epoch 26.474), train_loss = 1.08917643, grad/param norm = 2.0204e-01, time/batch = 15.3090s	
13794/26050 (epoch 26.476), train_loss = 1.09151337, grad/param norm = 1.9929e-01, time/batch = 18.1491s	
13795/26050 (epoch 26.478), train_loss = 0.94699078, grad/param norm = 1.8244e-01, time/batch = 17.7421s	
13796/26050 (epoch 26.480), train_loss = 0.97309627, grad/param norm = 1.7964e-01, time/batch = 17.9833s	
13797/26050 (epoch 26.482), train_loss = 0.92645535, grad/param norm = 1.9769e-01, time/batch = 18.3237s	
13798/26050 (epoch 26.484), train_loss = 0.90873004, grad/param norm = 1.9102e-01, time/batch = 18.6462s	
13799/26050 (epoch 26.486), train_loss = 1.09008987, grad/param norm = 1.9244e-01, time/batch = 18.3086s	
13800/26050 (epoch 26.488), train_loss = 1.16299730, grad/param norm = 2.1505e-01, time/batch = 18.1377s	
13801/26050 (epoch 26.489), train_loss = 1.12497930, grad/param norm = 2.2224e-01, time/batch = 17.4856s	
13802/26050 (epoch 26.491), train_loss = 0.90822310, grad/param norm = 2.1820e-01, time/batch = 15.6179s	
13803/26050 (epoch 26.493), train_loss = 0.98081742, grad/param norm = 2.0677e-01, time/batch = 16.4696s	
13804/26050 (epoch 26.495), train_loss = 0.93553792, grad/param norm = 1.7613e-01, time/batch = 18.7225s	
13805/26050 (epoch 26.497), train_loss = 0.87633332, grad/param norm = 1.7720e-01, time/batch = 18.4041s	
13806/26050 (epoch 26.499), train_loss = 0.92820784, grad/param norm = 1.8872e-01, time/batch = 17.3096s	
13807/26050 (epoch 26.501), train_loss = 1.03618216, grad/param norm = 1.9681e-01, time/batch = 18.5577s	
13808/26050 (epoch 26.503), train_loss = 0.91987182, grad/param norm = 1.9142e-01, time/batch = 18.6570s	
13809/26050 (epoch 26.505), train_loss = 1.07783969, grad/param norm = 1.9450e-01, time/batch = 18.5632s	
13810/26050 (epoch 26.507), train_loss = 1.04379588, grad/param norm = 2.2658e-01, time/batch = 16.8810s	
13811/26050 (epoch 26.509), train_loss = 1.12294393, grad/param norm = 1.9732e-01, time/batch = 17.3127s	
13812/26050 (epoch 26.511), train_loss = 0.92649911, grad/param norm = 1.7687e-01, time/batch = 18.6506s	
13813/26050 (epoch 26.512), train_loss = 0.85136340, grad/param norm = 1.9313e-01, time/batch = 17.6424s	
13814/26050 (epoch 26.514), train_loss = 1.04710116, grad/param norm = 2.3630e-01, time/batch = 18.0822s	
13815/26050 (epoch 26.516), train_loss = 1.10749979, grad/param norm = 2.3928e-01, time/batch = 19.0719s	
13816/26050 (epoch 26.518), train_loss = 0.96827743, grad/param norm = 2.0281e-01, time/batch = 16.8264s	
13817/26050 (epoch 26.520), train_loss = 0.96577095, grad/param norm = 1.9914e-01, time/batch = 17.5639s	
13818/26050 (epoch 26.522), train_loss = 0.75692862, grad/param norm = 1.6224e-01, time/batch = 18.6424s	
13819/26050 (epoch 26.524), train_loss = 1.03970966, grad/param norm = 2.4147e-01, time/batch = 18.7140s	
13820/26050 (epoch 26.526), train_loss = 1.06448735, grad/param norm = 2.1257e-01, time/batch = 16.1079s	
13821/26050 (epoch 26.528), train_loss = 1.00840631, grad/param norm = 2.0511e-01, time/batch = 18.1536s	
13822/26050 (epoch 26.530), train_loss = 0.91571201, grad/param norm = 2.0149e-01, time/batch = 18.5788s	
13823/26050 (epoch 26.532), train_loss = 1.00854806, grad/param norm = 1.9752e-01, time/batch = 16.8926s	
13824/26050 (epoch 26.534), train_loss = 1.06119125, grad/param norm = 4.6001e-01, time/batch = 15.5420s	
13825/26050 (epoch 26.536), train_loss = 0.98903844, grad/param norm = 1.9573e-01, time/batch = 17.9912s	
13826/26050 (epoch 26.537), train_loss = 1.06156398, grad/param norm = 2.1796e-01, time/batch = 14.5519s	
13827/26050 (epoch 26.539), train_loss = 0.99698690, grad/param norm = 2.1559e-01, time/batch = 16.2958s	
13828/26050 (epoch 26.541), train_loss = 1.16094563, grad/param norm = 2.3950e-01, time/batch = 18.4893s	
13829/26050 (epoch 26.543), train_loss = 0.82889176, grad/param norm = 2.9899e-01, time/batch = 17.9827s	
13830/26050 (epoch 26.545), train_loss = 1.00244641, grad/param norm = 2.1609e-01, time/batch = 17.7241s	
13831/26050 (epoch 26.547), train_loss = 0.95695671, grad/param norm = 2.0110e-01, time/batch = 19.0762s	
13832/26050 (epoch 26.549), train_loss = 0.80924801, grad/param norm = 1.9555e-01, time/batch = 17.8879s	
13833/26050 (epoch 26.551), train_loss = 1.03708184, grad/param norm = 2.0158e-01, time/batch = 17.8130s	
13834/26050 (epoch 26.553), train_loss = 0.92638822, grad/param norm = 1.9830e-01, time/batch = 15.9792s	
13835/26050 (epoch 26.555), train_loss = 0.88275245, grad/param norm = 1.8819e-01, time/batch = 18.9714s	
13836/26050 (epoch 26.557), train_loss = 1.00732050, grad/param norm = 1.8828e-01, time/batch = 18.4923s	
13837/26050 (epoch 26.559), train_loss = 0.97199289, grad/param norm = 1.9905e-01, time/batch = 24.7535s	
13838/26050 (epoch 26.560), train_loss = 0.95314355, grad/param norm = 2.0691e-01, time/batch = 31.3806s	
13839/26050 (epoch 26.562), train_loss = 0.95691606, grad/param norm = 1.9917e-01, time/batch = 15.4968s	
13840/26050 (epoch 26.564), train_loss = 1.13771595, grad/param norm = 2.0253e-01, time/batch = 18.3853s	
13841/26050 (epoch 26.566), train_loss = 0.88500807, grad/param norm = 1.8237e-01, time/batch = 18.0621s	
13842/26050 (epoch 26.568), train_loss = 1.01000567, grad/param norm = 1.9044e-01, time/batch = 17.9738s	
13843/26050 (epoch 26.570), train_loss = 0.99462738, grad/param norm = 2.0469e-01, time/batch = 15.3042s	
13844/26050 (epoch 26.572), train_loss = 0.95880895, grad/param norm = 2.0391e-01, time/batch = 18.2181s	
13845/26050 (epoch 26.574), train_loss = 0.99222740, grad/param norm = 2.3352e-01, time/batch = 17.6428s	
13846/26050 (epoch 26.576), train_loss = 1.02934426, grad/param norm = 2.2913e-01, time/batch = 15.4615s	
13847/26050 (epoch 26.578), train_loss = 0.94323866, grad/param norm = 2.1423e-01, time/batch = 19.0740s	
13848/26050 (epoch 26.580), train_loss = 0.91002851, grad/param norm = 2.0558e-01, time/batch = 18.4134s	
13849/26050 (epoch 26.582), train_loss = 0.98703329, grad/param norm = 1.8592e-01, time/batch = 17.9007s	
13850/26050 (epoch 26.583), train_loss = 1.04787084, grad/param norm = 1.9103e-01, time/batch = 17.2412s	
13851/26050 (epoch 26.585), train_loss = 0.85523974, grad/param norm = 2.1336e-01, time/batch = 17.0593s	
13852/26050 (epoch 26.587), train_loss = 1.00476851, grad/param norm = 2.0392e-01, time/batch = 18.4911s	
13853/26050 (epoch 26.589), train_loss = 1.11925322, grad/param norm = 2.2920e-01, time/batch = 18.2976s	
13854/26050 (epoch 26.591), train_loss = 0.96186976, grad/param norm = 1.8644e-01, time/batch = 18.3934s	
13855/26050 (epoch 26.593), train_loss = 0.84829714, grad/param norm = 1.7783e-01, time/batch = 18.0748s	
13856/26050 (epoch 26.595), train_loss = 1.04207446, grad/param norm = 2.1787e-01, time/batch = 17.1592s	
13857/26050 (epoch 26.597), train_loss = 0.98032499, grad/param norm = 1.9143e-01, time/batch = 18.6432s	
13858/26050 (epoch 26.599), train_loss = 0.99081836, grad/param norm = 1.9920e-01, time/batch = 15.6313s	
13859/26050 (epoch 26.601), train_loss = 1.13505440, grad/param norm = 1.9420e-01, time/batch = 17.7396s	
13860/26050 (epoch 26.603), train_loss = 1.00467118, grad/param norm = 2.0227e-01, time/batch = 17.9019s	
13861/26050 (epoch 26.605), train_loss = 0.93639186, grad/param norm = 2.0395e-01, time/batch = 17.6609s	
13862/26050 (epoch 26.607), train_loss = 1.05347555, grad/param norm = 2.1394e-01, time/batch = 16.5484s	
13863/26050 (epoch 26.608), train_loss = 0.85942326, grad/param norm = 1.7761e-01, time/batch = 15.2262s	
13864/26050 (epoch 26.610), train_loss = 0.96370250, grad/param norm = 1.9024e-01, time/batch = 16.5436s	
13865/26050 (epoch 26.612), train_loss = 0.94970806, grad/param norm = 2.0497e-01, time/batch = 17.5518s	
13866/26050 (epoch 26.614), train_loss = 0.97843856, grad/param norm = 2.0641e-01, time/batch = 17.6579s	
13867/26050 (epoch 26.616), train_loss = 1.08066098, grad/param norm = 2.3429e-01, time/batch = 18.4818s	
13868/26050 (epoch 26.618), train_loss = 0.91165423, grad/param norm = 1.9108e-01, time/batch = 18.4012s	
13869/26050 (epoch 26.620), train_loss = 1.00829930, grad/param norm = 1.9344e-01, time/batch = 18.7215s	
13870/26050 (epoch 26.622), train_loss = 0.86682034, grad/param norm = 1.6607e-01, time/batch = 16.1390s	
13871/26050 (epoch 26.624), train_loss = 0.82244363, grad/param norm = 1.7811e-01, time/batch = 17.7215s	
13872/26050 (epoch 26.626), train_loss = 1.02905885, grad/param norm = 2.0113e-01, time/batch = 17.6593s	
13873/26050 (epoch 26.628), train_loss = 0.89700655, grad/param norm = 1.8429e-01, time/batch = 17.4860s	
13874/26050 (epoch 26.630), train_loss = 1.09295823, grad/param norm = 1.8949e-01, time/batch = 18.3269s	
13875/26050 (epoch 26.631), train_loss = 1.12509565, grad/param norm = 2.0405e-01, time/batch = 17.1547s	
13876/26050 (epoch 26.633), train_loss = 0.87351146, grad/param norm = 1.9199e-01, time/batch = 17.4835s	
13877/26050 (epoch 26.635), train_loss = 0.91503562, grad/param norm = 2.0252e-01, time/batch = 18.0662s	
13878/26050 (epoch 26.637), train_loss = 0.86431388, grad/param norm = 1.8653e-01, time/batch = 17.8363s	
13879/26050 (epoch 26.639), train_loss = 1.04944601, grad/param norm = 2.0033e-01, time/batch = 14.9656s	
13880/26050 (epoch 26.641), train_loss = 0.92328396, grad/param norm = 1.9117e-01, time/batch = 17.0699s	
13881/26050 (epoch 26.643), train_loss = 0.86923728, grad/param norm = 1.5765e-01, time/batch = 17.3132s	
13882/26050 (epoch 26.645), train_loss = 0.91292851, grad/param norm = 1.8790e-01, time/batch = 15.1411s	
13883/26050 (epoch 26.647), train_loss = 0.91288135, grad/param norm = 2.1000e-01, time/batch = 17.9985s	
13884/26050 (epoch 26.649), train_loss = 0.96561584, grad/param norm = 2.5441e-01, time/batch = 17.8304s	
13885/26050 (epoch 26.651), train_loss = 0.91339112, grad/param norm = 2.0291e-01, time/batch = 18.6670s	
13886/26050 (epoch 26.653), train_loss = 0.94501570, grad/param norm = 1.8482e-01, time/batch = 18.2300s	
13887/26050 (epoch 26.655), train_loss = 0.87144783, grad/param norm = 1.7683e-01, time/batch = 17.2271s	
13888/26050 (epoch 26.656), train_loss = 0.82518998, grad/param norm = 1.6214e-01, time/batch = 14.9863s	
13889/26050 (epoch 26.658), train_loss = 1.13557229, grad/param norm = 2.1528e-01, time/batch = 17.1444s	
13890/26050 (epoch 26.660), train_loss = 0.82986427, grad/param norm = 1.9722e-01, time/batch = 15.8850s	
13891/26050 (epoch 26.662), train_loss = 0.95003362, grad/param norm = 2.0461e-01, time/batch = 17.8179s	
13892/26050 (epoch 26.664), train_loss = 0.93333445, grad/param norm = 1.9612e-01, time/batch = 15.3080s	
13893/26050 (epoch 26.666), train_loss = 0.89471060, grad/param norm = 1.9574e-01, time/batch = 17.6683s	
13894/26050 (epoch 26.668), train_loss = 0.78132674, grad/param norm = 2.2688e-01, time/batch = 16.9632s	
13895/26050 (epoch 26.670), train_loss = 1.10577173, grad/param norm = 2.7429e-01, time/batch = 18.7977s	
13896/26050 (epoch 26.672), train_loss = 0.96580649, grad/param norm = 2.0091e-01, time/batch = 18.0602s	
13897/26050 (epoch 26.674), train_loss = 0.86083062, grad/param norm = 2.0266e-01, time/batch = 17.6575s	
13898/26050 (epoch 26.676), train_loss = 1.00982850, grad/param norm = 1.9395e-01, time/batch = 17.8258s	
13899/26050 (epoch 26.678), train_loss = 1.06619058, grad/param norm = 2.0872e-01, time/batch = 18.3259s	
13900/26050 (epoch 26.679), train_loss = 1.13000301, grad/param norm = 2.2198e-01, time/batch = 15.5465s	
13901/26050 (epoch 26.681), train_loss = 0.96746973, grad/param norm = 1.9960e-01, time/batch = 17.2897s	
13902/26050 (epoch 26.683), train_loss = 0.86050621, grad/param norm = 2.2626e-01, time/batch = 17.9837s	
13903/26050 (epoch 26.685), train_loss = 0.94553633, grad/param norm = 1.9299e-01, time/batch = 17.6661s	
13904/26050 (epoch 26.687), train_loss = 0.84365388, grad/param norm = 1.8863e-01, time/batch = 17.0752s	
13905/26050 (epoch 26.689), train_loss = 0.92771134, grad/param norm = 2.1832e-01, time/batch = 18.4840s	
13906/26050 (epoch 26.691), train_loss = 0.78757884, grad/param norm = 1.7030e-01, time/batch = 18.7431s	
13907/26050 (epoch 26.693), train_loss = 0.88155566, grad/param norm = 1.8709e-01, time/batch = 17.8961s	
13908/26050 (epoch 26.695), train_loss = 0.95541549, grad/param norm = 1.7439e-01, time/batch = 17.5743s	
13909/26050 (epoch 26.697), train_loss = 0.88718506, grad/param norm = 2.0917e-01, time/batch = 17.3936s	
13910/26050 (epoch 26.699), train_loss = 1.01149339, grad/param norm = 2.1408e-01, time/batch = 17.5812s	
13911/26050 (epoch 26.701), train_loss = 0.86266954, grad/param norm = 1.6415e-01, time/batch = 17.8231s	
13912/26050 (epoch 26.702), train_loss = 1.05820128, grad/param norm = 2.0041e-01, time/batch = 18.4831s	
13913/26050 (epoch 26.704), train_loss = 1.05132121, grad/param norm = 1.8420e-01, time/batch = 16.8830s	
13914/26050 (epoch 26.706), train_loss = 0.90265691, grad/param norm = 2.0092e-01, time/batch = 17.7271s	
13915/26050 (epoch 26.708), train_loss = 1.04406856, grad/param norm = 2.1142e-01, time/batch = 18.5719s	
13916/26050 (epoch 26.710), train_loss = 0.99246461, grad/param norm = 2.1234e-01, time/batch = 16.6561s	
13917/26050 (epoch 26.712), train_loss = 0.96932674, grad/param norm = 1.9881e-01, time/batch = 17.8189s	
13918/26050 (epoch 26.714), train_loss = 0.83765361, grad/param norm = 1.7643e-01, time/batch = 17.3852s	
13919/26050 (epoch 26.716), train_loss = 1.21280876, grad/param norm = 2.4015e-01, time/batch = 18.7257s	
13920/26050 (epoch 26.718), train_loss = 1.01959938, grad/param norm = 1.9299e-01, time/batch = 18.1531s	
13921/26050 (epoch 26.720), train_loss = 0.95581805, grad/param norm = 2.0994e-01, time/batch = 16.2985s	
13922/26050 (epoch 26.722), train_loss = 0.84124497, grad/param norm = 1.6045e-01, time/batch = 15.6457s	
13923/26050 (epoch 26.724), train_loss = 0.88566300, grad/param norm = 1.9276e-01, time/batch = 18.0490s	
13924/26050 (epoch 26.726), train_loss = 0.99725449, grad/param norm = 1.9750e-01, time/batch = 17.8944s	
13925/26050 (epoch 26.727), train_loss = 1.01757640, grad/param norm = 1.9873e-01, time/batch = 17.3901s	
13926/26050 (epoch 26.729), train_loss = 0.99101706, grad/param norm = 1.9000e-01, time/batch = 18.7317s	
13927/26050 (epoch 26.731), train_loss = 0.99605060, grad/param norm = 1.9278e-01, time/batch = 18.2317s	
13928/26050 (epoch 26.733), train_loss = 0.94447737, grad/param norm = 2.6212e-01, time/batch = 14.9768s	
13929/26050 (epoch 26.735), train_loss = 1.13764490, grad/param norm = 2.0698e-01, time/batch = 17.8763s	
13930/26050 (epoch 26.737), train_loss = 0.90923399, grad/param norm = 2.0501e-01, time/batch = 18.3254s	
13931/26050 (epoch 26.739), train_loss = 0.98956054, grad/param norm = 1.8970e-01, time/batch = 17.8125s	
13932/26050 (epoch 26.741), train_loss = 0.88728305, grad/param norm = 1.9173e-01, time/batch = 18.4085s	
13933/26050 (epoch 26.743), train_loss = 0.99081106, grad/param norm = 2.4163e-01, time/batch = 16.7236s	
13934/26050 (epoch 26.745), train_loss = 0.84164797, grad/param norm = 1.8211e-01, time/batch = 17.0497s	
13935/26050 (epoch 26.747), train_loss = 0.87858869, grad/param norm = 1.7975e-01, time/batch = 17.9857s	
13936/26050 (epoch 26.749), train_loss = 1.07111443, grad/param norm = 2.1027e-01, time/batch = 17.5699s	
13937/26050 (epoch 26.750), train_loss = 0.95335842, grad/param norm = 1.6653e-01, time/batch = 16.6379s	
13938/26050 (epoch 26.752), train_loss = 0.92141930, grad/param norm = 2.3311e-01, time/batch = 16.8807s	
13939/26050 (epoch 26.754), train_loss = 0.97359614, grad/param norm = 1.9647e-01, time/batch = 18.0452s	
13940/26050 (epoch 26.756), train_loss = 0.94806307, grad/param norm = 2.3032e-01, time/batch = 18.7434s	
13941/26050 (epoch 26.758), train_loss = 0.92958687, grad/param norm = 2.0804e-01, time/batch = 15.6435s	
13942/26050 (epoch 26.760), train_loss = 1.11999449, grad/param norm = 2.1996e-01, time/batch = 18.6256s	
13943/26050 (epoch 26.762), train_loss = 0.92006446, grad/param norm = 2.2615e-01, time/batch = 17.8966s	
13944/26050 (epoch 26.764), train_loss = 0.94344362, grad/param norm = 2.1200e-01, time/batch = 18.2342s	
13945/26050 (epoch 26.766), train_loss = 0.99298010, grad/param norm = 2.0467e-01, time/batch = 17.0710s	
13946/26050 (epoch 26.768), train_loss = 0.84797920, grad/param norm = 1.7409e-01, time/batch = 18.0657s	
13947/26050 (epoch 26.770), train_loss = 0.93852386, grad/param norm = 1.9477e-01, time/batch = 18.7293s	
13948/26050 (epoch 26.772), train_loss = 0.95676307, grad/param norm = 1.8009e-01, time/batch = 17.4566s	
13949/26050 (epoch 26.774), train_loss = 0.83197739, grad/param norm = 2.1247e-01, time/batch = 18.6439s	
13950/26050 (epoch 26.775), train_loss = 0.68619703, grad/param norm = 1.7862e-01, time/batch = 18.4922s	
13951/26050 (epoch 26.777), train_loss = 0.89927031, grad/param norm = 1.9171e-01, time/batch = 17.5685s	
13952/26050 (epoch 26.779), train_loss = 0.94410447, grad/param norm = 2.2282e-01, time/batch = 15.8847s	
13953/26050 (epoch 26.781), train_loss = 0.84413499, grad/param norm = 2.0295e-01, time/batch = 15.4588s	
13954/26050 (epoch 26.783), train_loss = 0.82396407, grad/param norm = 1.7747e-01, time/batch = 15.3888s	
13955/26050 (epoch 26.785), train_loss = 0.97314088, grad/param norm = 2.0488e-01, time/batch = 16.8540s	
13956/26050 (epoch 26.787), train_loss = 0.86804680, grad/param norm = 1.9495e-01, time/batch = 18.4781s	
13957/26050 (epoch 26.789), train_loss = 0.89076287, grad/param norm = 1.9865e-01, time/batch = 18.3146s	
13958/26050 (epoch 26.791), train_loss = 0.88146466, grad/param norm = 1.9220e-01, time/batch = 17.2374s	
13959/26050 (epoch 26.793), train_loss = 0.92008700, grad/param norm = 1.9646e-01, time/batch = 17.7311s	
13960/26050 (epoch 26.795), train_loss = 0.77233413, grad/param norm = 1.5321e-01, time/batch = 16.6628s	
13961/26050 (epoch 26.797), train_loss = 0.85243452, grad/param norm = 2.0624e-01, time/batch = 18.0723s	
13962/26050 (epoch 26.798), train_loss = 0.82231185, grad/param norm = 1.9166e-01, time/batch = 17.0730s	
13963/26050 (epoch 26.800), train_loss = 0.82445919, grad/param norm = 1.7715e-01, time/batch = 15.0042s	
13964/26050 (epoch 26.802), train_loss = 0.89672841, grad/param norm = 1.8248e-01, time/batch = 14.4146s	
13965/26050 (epoch 26.804), train_loss = 0.93346582, grad/param norm = 1.9005e-01, time/batch = 14.4798s	
13966/26050 (epoch 26.806), train_loss = 1.02264955, grad/param norm = 2.0482e-01, time/batch = 14.5443s	
13967/26050 (epoch 26.808), train_loss = 0.94374486, grad/param norm = 1.9039e-01, time/batch = 18.0572s	
13968/26050 (epoch 26.810), train_loss = 0.89526999, grad/param norm = 2.1427e-01, time/batch = 18.5630s	
13969/26050 (epoch 26.812), train_loss = 0.82980278, grad/param norm = 2.0375e-01, time/batch = 17.6539s	
13970/26050 (epoch 26.814), train_loss = 0.87539433, grad/param norm = 2.2213e-01, time/batch = 15.9830s	
13971/26050 (epoch 26.816), train_loss = 1.01427615, grad/param norm = 2.2912e-01, time/batch = 18.0679s	
13972/26050 (epoch 26.818), train_loss = 1.03951779, grad/param norm = 2.2390e-01, time/batch = 18.6633s	
13973/26050 (epoch 26.820), train_loss = 0.96725206, grad/param norm = 1.9024e-01, time/batch = 16.8935s	
13974/26050 (epoch 26.821), train_loss = 1.06234792, grad/param norm = 2.2519e-01, time/batch = 17.3051s	
13975/26050 (epoch 26.823), train_loss = 1.11638946, grad/param norm = 2.0723e-01, time/batch = 16.8008s	
13976/26050 (epoch 26.825), train_loss = 0.94046421, grad/param norm = 1.8789e-01, time/batch = 17.6542s	
13977/26050 (epoch 26.827), train_loss = 0.96781726, grad/param norm = 2.0802e-01, time/batch = 14.9771s	
13978/26050 (epoch 26.829), train_loss = 1.00212067, grad/param norm = 1.9172e-01, time/batch = 18.6443s	
13979/26050 (epoch 26.831), train_loss = 1.09525232, grad/param norm = 2.1313e-01, time/batch = 18.1701s	
13980/26050 (epoch 26.833), train_loss = 1.11670723, grad/param norm = 2.3286e-01, time/batch = 18.3048s	
13981/26050 (epoch 26.835), train_loss = 1.11864075, grad/param norm = 1.9449e-01, time/batch = 17.9927s	
13982/26050 (epoch 26.837), train_loss = 0.93695011, grad/param norm = 1.7995e-01, time/batch = 16.5609s	
13983/26050 (epoch 26.839), train_loss = 0.93631855, grad/param norm = 1.9776e-01, time/batch = 16.2068s	
13984/26050 (epoch 26.841), train_loss = 1.06926305, grad/param norm = 2.0248e-01, time/batch = 18.8147s	
13985/26050 (epoch 26.843), train_loss = 0.92337254, grad/param norm = 1.8469e-01, time/batch = 18.9045s	
13986/26050 (epoch 26.845), train_loss = 0.91719618, grad/param norm = 1.8827e-01, time/batch = 17.4036s	
13987/26050 (epoch 26.846), train_loss = 1.01406923, grad/param norm = 2.1126e-01, time/batch = 17.8173s	
13988/26050 (epoch 26.848), train_loss = 0.94057053, grad/param norm = 1.9083e-01, time/batch = 18.5561s	
13989/26050 (epoch 26.850), train_loss = 0.86526428, grad/param norm = 1.8631e-01, time/batch = 18.9094s	
13990/26050 (epoch 26.852), train_loss = 0.97356972, grad/param norm = 1.9783e-01, time/batch = 17.7917s	
13991/26050 (epoch 26.854), train_loss = 0.93895524, grad/param norm = 1.9308e-01, time/batch = 18.6527s	
13992/26050 (epoch 26.856), train_loss = 0.89913385, grad/param norm = 2.0085e-01, time/batch = 18.1617s	
13993/26050 (epoch 26.858), train_loss = 0.87359439, grad/param norm = 1.8381e-01, time/batch = 17.1164s	
13994/26050 (epoch 26.860), train_loss = 0.99678370, grad/param norm = 2.1458e-01, time/batch = 17.2393s	
13995/26050 (epoch 26.862), train_loss = 1.02774322, grad/param norm = 2.0991e-01, time/batch = 18.3191s	
13996/26050 (epoch 26.864), train_loss = 0.97716130, grad/param norm = 2.1263e-01, time/batch = 15.1510s	
13997/26050 (epoch 26.866), train_loss = 0.91057776, grad/param norm = 1.8325e-01, time/batch = 17.9064s	
13998/26050 (epoch 26.868), train_loss = 0.99239737, grad/param norm = 1.9781e-01, time/batch = 16.9800s	
13999/26050 (epoch 26.869), train_loss = 0.84930514, grad/param norm = 1.7935e-01, time/batch = 16.3023s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch26.87_1.7838.t7	
14000/26050 (epoch 26.871), train_loss = 0.78010578, grad/param norm = 1.6782e-01, time/batch = 17.3231s	
14001/26050 (epoch 26.873), train_loss = 1.33553928, grad/param norm = 2.5398e-01, time/batch = 16.8763s	
14002/26050 (epoch 26.875), train_loss = 0.96046021, grad/param norm = 2.1423e-01, time/batch = 18.4042s	
14003/26050 (epoch 26.877), train_loss = 0.86019161, grad/param norm = 1.9558e-01, time/batch = 15.2207s	
14004/26050 (epoch 26.879), train_loss = 0.98645033, grad/param norm = 1.8877e-01, time/batch = 17.6277s	
14005/26050 (epoch 26.881), train_loss = 1.05991273, grad/param norm = 2.1745e-01, time/batch = 17.9042s	
14006/26050 (epoch 26.883), train_loss = 1.01053279, grad/param norm = 2.0386e-01, time/batch = 18.0721s	
14007/26050 (epoch 26.885), train_loss = 0.73893320, grad/param norm = 1.7384e-01, time/batch = 16.0596s	
14008/26050 (epoch 26.887), train_loss = 1.00377362, grad/param norm = 2.0400e-01, time/batch = 14.4768s	
14009/26050 (epoch 26.889), train_loss = 0.89519553, grad/param norm = 1.8602e-01, time/batch = 18.3872s	
14010/26050 (epoch 26.891), train_loss = 0.78563376, grad/param norm = 1.7473e-01, time/batch = 18.4017s	
14011/26050 (epoch 26.893), train_loss = 0.83196028, grad/param norm = 1.7308e-01, time/batch = 18.1435s	
14012/26050 (epoch 26.894), train_loss = 0.91876074, grad/param norm = 1.7944e-01, time/batch = 18.5709s	
14013/26050 (epoch 26.896), train_loss = 1.04297952, grad/param norm = 2.3607e-01, time/batch = 18.6442s	
14014/26050 (epoch 26.898), train_loss = 0.90063964, grad/param norm = 1.9369e-01, time/batch = 17.6468s	
14015/26050 (epoch 26.900), train_loss = 0.99683124, grad/param norm = 2.0082e-01, time/batch = 18.2340s	
14016/26050 (epoch 26.902), train_loss = 0.94901680, grad/param norm = 2.1323e-01, time/batch = 18.3894s	
14017/26050 (epoch 26.904), train_loss = 0.90636351, grad/param norm = 1.8610e-01, time/batch = 17.7286s	
14018/26050 (epoch 26.906), train_loss = 0.92823607, grad/param norm = 2.1177e-01, time/batch = 18.6420s	
14019/26050 (epoch 26.908), train_loss = 0.95454401, grad/param norm = 1.8971e-01, time/batch = 18.2199s	
14020/26050 (epoch 26.910), train_loss = 0.91850509, grad/param norm = 1.7269e-01, time/batch = 18.7476s	
14021/26050 (epoch 26.912), train_loss = 1.13321388, grad/param norm = 2.1814e-01, time/batch = 17.5684s	
14022/26050 (epoch 26.914), train_loss = 1.32069544, grad/param norm = 2.3288e-01, time/batch = 18.4030s	
14023/26050 (epoch 26.916), train_loss = 1.05258285, grad/param norm = 2.4387e-01, time/batch = 17.8941s	
14024/26050 (epoch 26.917), train_loss = 0.96379935, grad/param norm = 2.1767e-01, time/batch = 17.5468s	
14025/26050 (epoch 26.919), train_loss = 0.99819571, grad/param norm = 2.0434e-01, time/batch = 17.4471s	
14026/26050 (epoch 26.921), train_loss = 0.91051844, grad/param norm = 2.0442e-01, time/batch = 16.7104s	
14027/26050 (epoch 26.923), train_loss = 0.95500969, grad/param norm = 1.8814e-01, time/batch = 18.0692s	
14028/26050 (epoch 26.925), train_loss = 0.95460307, grad/param norm = 1.9381e-01, time/batch = 15.4847s	
14029/26050 (epoch 26.927), train_loss = 0.85558960, grad/param norm = 1.6108e-01, time/batch = 17.0482s	
14030/26050 (epoch 26.929), train_loss = 0.81439828, grad/param norm = 1.6716e-01, time/batch = 18.8206s	
14031/26050 (epoch 26.931), train_loss = 1.13082519, grad/param norm = 2.7660e-01, time/batch = 16.9055s	
14032/26050 (epoch 26.933), train_loss = 0.90375305, grad/param norm = 1.8843e-01, time/batch = 18.4819s	
14033/26050 (epoch 26.935), train_loss = 0.91026561, grad/param norm = 1.8243e-01, time/batch = 18.9046s	
14034/26050 (epoch 26.937), train_loss = 1.03951246, grad/param norm = 1.8865e-01, time/batch = 17.1625s	
14035/26050 (epoch 26.939), train_loss = 0.86694693, grad/param norm = 1.6851e-01, time/batch = 30.8292s	
14036/26050 (epoch 26.940), train_loss = 0.90195667, grad/param norm = 1.7321e-01, time/batch = 24.2422s	
14037/26050 (epoch 26.942), train_loss = 0.93322664, grad/param norm = 1.8880e-01, time/batch = 18.5801s	
14038/26050 (epoch 26.944), train_loss = 0.90769699, grad/param norm = 1.8525e-01, time/batch = 18.3986s	
14039/26050 (epoch 26.946), train_loss = 1.06643804, grad/param norm = 1.9201e-01, time/batch = 18.3110s	
14040/26050 (epoch 26.948), train_loss = 0.81123400, grad/param norm = 1.8861e-01, time/batch = 16.6460s	
14041/26050 (epoch 26.950), train_loss = 0.91892947, grad/param norm = 1.8885e-01, time/batch = 17.5758s	
14042/26050 (epoch 26.952), train_loss = 1.00845581, grad/param norm = 2.0107e-01, time/batch = 17.8814s	
14043/26050 (epoch 26.954), train_loss = 1.04544971, grad/param norm = 1.9816e-01, time/batch = 18.1578s	
14044/26050 (epoch 26.956), train_loss = 0.93060222, grad/param norm = 1.9771e-01, time/batch = 18.6446s	
14045/26050 (epoch 26.958), train_loss = 0.86301418, grad/param norm = 1.6206e-01, time/batch = 17.9908s	
14046/26050 (epoch 26.960), train_loss = 0.97440935, grad/param norm = 1.9918e-01, time/batch = 18.1577s	
14047/26050 (epoch 26.962), train_loss = 0.91624945, grad/param norm = 1.7971e-01, time/batch = 18.1448s	
14048/26050 (epoch 26.964), train_loss = 0.94222927, grad/param norm = 1.8622e-01, time/batch = 18.8211s	
14049/26050 (epoch 26.965), train_loss = 0.86839616, grad/param norm = 2.3242e-01, time/batch = 18.5619s	
14050/26050 (epoch 26.967), train_loss = 1.26594748, grad/param norm = 2.1437e-01, time/batch = 15.3645s	
14051/26050 (epoch 26.969), train_loss = 0.98218576, grad/param norm = 2.1396e-01, time/batch = 18.0483s	
14052/26050 (epoch 26.971), train_loss = 0.91087559, grad/param norm = 1.7502e-01, time/batch = 17.7255s	
14053/26050 (epoch 26.973), train_loss = 0.95153458, grad/param norm = 1.9778e-01, time/batch = 17.9835s	
14054/26050 (epoch 26.975), train_loss = 1.00369825, grad/param norm = 2.0502e-01, time/batch = 18.3225s	
14055/26050 (epoch 26.977), train_loss = 0.95252724, grad/param norm = 1.6680e-01, time/batch = 18.1472s	
14056/26050 (epoch 26.979), train_loss = 0.78787709, grad/param norm = 1.9643e-01, time/batch = 17.5707s	
14057/26050 (epoch 26.981), train_loss = 1.08002456, grad/param norm = 1.9573e-01, time/batch = 16.5782s	
14058/26050 (epoch 26.983), train_loss = 1.02561343, grad/param norm = 1.9037e-01, time/batch = 17.5584s	
14059/26050 (epoch 26.985), train_loss = 1.00138849, grad/param norm = 1.9455e-01, time/batch = 18.8224s	
14060/26050 (epoch 26.987), train_loss = 1.05408514, grad/param norm = 1.9633e-01, time/batch = 17.4020s	
14061/26050 (epoch 26.988), train_loss = 1.00947550, grad/param norm = 1.9911e-01, time/batch = 18.0555s	
14062/26050 (epoch 26.990), train_loss = 0.83948983, grad/param norm = 1.7437e-01, time/batch = 15.8945s	
14063/26050 (epoch 26.992), train_loss = 1.09507067, grad/param norm = 1.9430e-01, time/batch = 15.7912s	
14064/26050 (epoch 26.994), train_loss = 0.91215128, grad/param norm = 2.0299e-01, time/batch = 17.3045s	
14065/26050 (epoch 26.996), train_loss = 0.89242727, grad/param norm = 2.2644e-01, time/batch = 18.1448s	
14066/26050 (epoch 26.998), train_loss = 0.97801829, grad/param norm = 2.3336e-01, time/batch = 19.0590s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
14067/26050 (epoch 27.000), train_loss = 0.91416928, grad/param norm = 2.2822e-01, time/batch = 16.4772s	
14068/26050 (epoch 27.002), train_loss = 1.00616303, grad/param norm = 2.0222e-01, time/batch = 18.0782s	
14069/26050 (epoch 27.004), train_loss = 0.85537235, grad/param norm = 1.8880e-01, time/batch = 18.1428s	
14070/26050 (epoch 27.006), train_loss = 0.88011763, grad/param norm = 2.0367e-01, time/batch = 16.7893s	
14071/26050 (epoch 27.008), train_loss = 0.89185588, grad/param norm = 1.9153e-01, time/batch = 16.2893s	
14072/26050 (epoch 27.010), train_loss = 0.89479772, grad/param norm = 2.0468e-01, time/batch = 18.4770s	
14073/26050 (epoch 27.012), train_loss = 0.95469513, grad/param norm = 1.8322e-01, time/batch = 18.6575s	
14074/26050 (epoch 27.013), train_loss = 1.22902038, grad/param norm = 2.4711e-01, time/batch = 18.0573s	
14075/26050 (epoch 27.015), train_loss = 0.93958762, grad/param norm = 1.9895e-01, time/batch = 16.2855s	
14076/26050 (epoch 27.017), train_loss = 0.96346209, grad/param norm = 1.8720e-01, time/batch = 16.9027s	
14077/26050 (epoch 27.019), train_loss = 0.84601758, grad/param norm = 1.7615e-01, time/batch = 17.8798s	
14078/26050 (epoch 27.021), train_loss = 1.03165941, grad/param norm = 1.9659e-01, time/batch = 17.5575s	
14079/26050 (epoch 27.023), train_loss = 0.79104340, grad/param norm = 1.7612e-01, time/batch = 17.0752s	
14080/26050 (epoch 27.025), train_loss = 0.94177542, grad/param norm = 1.8540e-01, time/batch = 15.7906s	
14081/26050 (epoch 27.027), train_loss = 0.78226934, grad/param norm = 1.8899e-01, time/batch = 18.4666s	
14082/26050 (epoch 27.029), train_loss = 0.96918388, grad/param norm = 1.8540e-01, time/batch = 17.7357s	
14083/26050 (epoch 27.031), train_loss = 1.06892253, grad/param norm = 2.0770e-01, time/batch = 18.9935s	
14084/26050 (epoch 27.033), train_loss = 0.97056032, grad/param norm = 1.9383e-01, time/batch = 17.0497s	
14085/26050 (epoch 27.035), train_loss = 0.98517428, grad/param norm = 2.0710e-01, time/batch = 18.7259s	
14086/26050 (epoch 27.036), train_loss = 0.82533809, grad/param norm = 1.8533e-01, time/batch = 15.3019s	
14087/26050 (epoch 27.038), train_loss = 0.76153932, grad/param norm = 1.8536e-01, time/batch = 16.7046s	
14088/26050 (epoch 27.040), train_loss = 0.92661764, grad/param norm = 1.8819e-01, time/batch = 18.3083s	
14089/26050 (epoch 27.042), train_loss = 0.79996940, grad/param norm = 1.8004e-01, time/batch = 18.0595s	
14090/26050 (epoch 27.044), train_loss = 1.01114982, grad/param norm = 1.7851e-01, time/batch = 15.8693s	
14091/26050 (epoch 27.046), train_loss = 0.77305787, grad/param norm = 1.6218e-01, time/batch = 16.0349s	
14092/26050 (epoch 27.048), train_loss = 0.95634359, grad/param norm = 1.9061e-01, time/batch = 17.7973s	
14093/26050 (epoch 27.050), train_loss = 0.88038200, grad/param norm = 1.7591e-01, time/batch = 18.2482s	
14094/26050 (epoch 27.052), train_loss = 0.87349706, grad/param norm = 2.1207e-01, time/batch = 18.0773s	
14095/26050 (epoch 27.054), train_loss = 0.78490069, grad/param norm = 1.7087e-01, time/batch = 15.8854s	
14096/26050 (epoch 27.056), train_loss = 0.76329699, grad/param norm = 1.5839e-01, time/batch = 18.1618s	
14097/26050 (epoch 27.058), train_loss = 0.90829476, grad/param norm = 1.7209e-01, time/batch = 18.4823s	
14098/26050 (epoch 27.060), train_loss = 1.01828570, grad/param norm = 1.9792e-01, time/batch = 18.6377s	
14099/26050 (epoch 27.061), train_loss = 0.85247575, grad/param norm = 1.7770e-01, time/batch = 18.4946s	
14100/26050 (epoch 27.063), train_loss = 0.95884283, grad/param norm = 1.8214e-01, time/batch = 18.8230s	
14101/26050 (epoch 27.065), train_loss = 0.75710357, grad/param norm = 1.5191e-01, time/batch = 17.0655s	
14102/26050 (epoch 27.067), train_loss = 0.91758235, grad/param norm = 1.9578e-01, time/batch = 18.0705s	
14103/26050 (epoch 27.069), train_loss = 0.97200646, grad/param norm = 2.0371e-01, time/batch = 18.0769s	
14104/26050 (epoch 27.071), train_loss = 0.97148727, grad/param norm = 1.7717e-01, time/batch = 17.7383s	
14105/26050 (epoch 27.073), train_loss = 1.08610195, grad/param norm = 2.0525e-01, time/batch = 16.8117s	
14106/26050 (epoch 27.075), train_loss = 0.88624453, grad/param norm = 1.8409e-01, time/batch = 17.2067s	
14107/26050 (epoch 27.077), train_loss = 0.90718761, grad/param norm = 1.9727e-01, time/batch = 18.4921s	
14108/26050 (epoch 27.079), train_loss = 0.92953481, grad/param norm = 1.9319e-01, time/batch = 15.1980s	
14109/26050 (epoch 27.081), train_loss = 0.90604594, grad/param norm = 1.7785e-01, time/batch = 17.8112s	
14110/26050 (epoch 27.083), train_loss = 1.03744242, grad/param norm = 1.8155e-01, time/batch = 18.0536s	
14111/26050 (epoch 27.084), train_loss = 0.96451332, grad/param norm = 2.1298e-01, time/batch = 16.4558s	
14112/26050 (epoch 27.086), train_loss = 1.10791152, grad/param norm = 2.1196e-01, time/batch = 15.8894s	
14113/26050 (epoch 27.088), train_loss = 0.88903909, grad/param norm = 1.8301e-01, time/batch = 17.2274s	
14114/26050 (epoch 27.090), train_loss = 0.95511769, grad/param norm = 1.9579e-01, time/batch = 18.5598s	
14115/26050 (epoch 27.092), train_loss = 0.99101269, grad/param norm = 1.7388e-01, time/batch = 18.3983s	
14116/26050 (epoch 27.094), train_loss = 0.84627410, grad/param norm = 1.8672e-01, time/batch = 18.0607s	
14117/26050 (epoch 27.096), train_loss = 0.96114310, grad/param norm = 1.9033e-01, time/batch = 16.4755s	
14118/26050 (epoch 27.098), train_loss = 0.88733019, grad/param norm = 1.8954e-01, time/batch = 17.0443s	
14119/26050 (epoch 27.100), train_loss = 0.85005961, grad/param norm = 1.8964e-01, time/batch = 18.6536s	
14120/26050 (epoch 27.102), train_loss = 0.99350124, grad/param norm = 1.9264e-01, time/batch = 17.9886s	
14121/26050 (epoch 27.104), train_loss = 0.90181549, grad/param norm = 1.9889e-01, time/batch = 17.9000s	
14122/26050 (epoch 27.106), train_loss = 0.94323948, grad/param norm = 1.9516e-01, time/batch = 14.6332s	
14123/26050 (epoch 27.107), train_loss = 0.76081717, grad/param norm = 1.6794e-01, time/batch = 18.2189s	
14124/26050 (epoch 27.109), train_loss = 0.84779932, grad/param norm = 1.7961e-01, time/batch = 15.3181s	
14125/26050 (epoch 27.111), train_loss = 1.09302491, grad/param norm = 2.0643e-01, time/batch = 17.6382s	
14126/26050 (epoch 27.113), train_loss = 0.88890232, grad/param norm = 1.7949e-01, time/batch = 18.2302s	
14127/26050 (epoch 27.115), train_loss = 1.02625335, grad/param norm = 2.0371e-01, time/batch = 17.9038s	
14128/26050 (epoch 27.117), train_loss = 0.92831569, grad/param norm = 1.9795e-01, time/batch = 17.1295s	
14129/26050 (epoch 27.119), train_loss = 0.78417576, grad/param norm = 1.8249e-01, time/batch = 18.2197s	
14130/26050 (epoch 27.121), train_loss = 0.95436168, grad/param norm = 1.9435e-01, time/batch = 18.6410s	
14131/26050 (epoch 27.123), train_loss = 0.86821358, grad/param norm = 2.0560e-01, time/batch = 16.3555s	
14132/26050 (epoch 27.125), train_loss = 0.82190663, grad/param norm = 1.7149e-01, time/batch = 17.8806s	
14133/26050 (epoch 27.127), train_loss = 0.76743256, grad/param norm = 1.9308e-01, time/batch = 18.7347s	
14134/26050 (epoch 27.129), train_loss = 0.77272100, grad/param norm = 1.7928e-01, time/batch = 18.0652s	
14135/26050 (epoch 27.131), train_loss = 0.90390823, grad/param norm = 2.0833e-01, time/batch = 15.8833s	
14136/26050 (epoch 27.132), train_loss = 0.89997236, grad/param norm = 1.6691e-01, time/batch = 15.8074s	
14137/26050 (epoch 27.134), train_loss = 0.94651681, grad/param norm = 2.1324e-01, time/batch = 18.1617s	
14138/26050 (epoch 27.136), train_loss = 0.92072705, grad/param norm = 1.9974e-01, time/batch = 18.0549s	
14139/26050 (epoch 27.138), train_loss = 0.70425929, grad/param norm = 1.7876e-01, time/batch = 17.6405s	
14140/26050 (epoch 27.140), train_loss = 0.78197258, grad/param norm = 1.9392e-01, time/batch = 18.8106s	
14141/26050 (epoch 27.142), train_loss = 0.81649657, grad/param norm = 1.9191e-01, time/batch = 15.8054s	
14142/26050 (epoch 27.144), train_loss = 0.74431009, grad/param norm = 1.8712e-01, time/batch = 16.7553s	
14143/26050 (epoch 27.146), train_loss = 0.68063716, grad/param norm = 1.5793e-01, time/batch = 18.5704s	
14144/26050 (epoch 27.148), train_loss = 0.72707864, grad/param norm = 1.4964e-01, time/batch = 17.5822s	
14145/26050 (epoch 27.150), train_loss = 0.89178020, grad/param norm = 2.2419e-01, time/batch = 17.7227s	
14146/26050 (epoch 27.152), train_loss = 1.07219107, grad/param norm = 2.3385e-01, time/batch = 18.1571s	
14147/26050 (epoch 27.154), train_loss = 0.73946962, grad/param norm = 1.7598e-01, time/batch = 17.5464s	
14148/26050 (epoch 27.155), train_loss = 0.79617513, grad/param norm = 2.0350e-01, time/batch = 18.2239s	
14149/26050 (epoch 27.157), train_loss = 0.90461545, grad/param norm = 2.3783e-01, time/batch = 17.5338s	
14150/26050 (epoch 27.159), train_loss = 0.94654179, grad/param norm = 2.0910e-01, time/batch = 18.7269s	
14151/26050 (epoch 27.161), train_loss = 0.93464506, grad/param norm = 2.0303e-01, time/batch = 18.4062s	
14152/26050 (epoch 27.163), train_loss = 0.75877961, grad/param norm = 1.7119e-01, time/batch = 16.8206s	
14153/26050 (epoch 27.165), train_loss = 0.72079827, grad/param norm = 1.8415e-01, time/batch = 17.5858s	
14154/26050 (epoch 27.167), train_loss = 1.04759879, grad/param norm = 2.1336e-01, time/batch = 16.4948s	
14155/26050 (epoch 27.169), train_loss = 0.93188930, grad/param norm = 2.1818e-01, time/batch = 17.4814s	
14156/26050 (epoch 27.171), train_loss = 0.78459260, grad/param norm = 1.6935e-01, time/batch = 18.1531s	
14157/26050 (epoch 27.173), train_loss = 0.88098846, grad/param norm = 2.0561e-01, time/batch = 17.3111s	
14158/26050 (epoch 27.175), train_loss = 0.88359582, grad/param norm = 1.8993e-01, time/batch = 17.9083s	
14159/26050 (epoch 27.177), train_loss = 1.01587871, grad/param norm = 1.9235e-01, time/batch = 17.4911s	
14160/26050 (epoch 27.179), train_loss = 0.69345370, grad/param norm = 1.7893e-01, time/batch = 16.8168s	
14161/26050 (epoch 27.180), train_loss = 1.11377623, grad/param norm = 1.9154e-01, time/batch = 16.6367s	
14162/26050 (epoch 27.182), train_loss = 1.13258299, grad/param norm = 2.1084e-01, time/batch = 17.3241s	
14163/26050 (epoch 27.184), train_loss = 0.95040028, grad/param norm = 1.9162e-01, time/batch = 18.1388s	
14164/26050 (epoch 27.186), train_loss = 0.75574471, grad/param norm = 1.6977e-01, time/batch = 16.3951s	
14165/26050 (epoch 27.188), train_loss = 0.94852607, grad/param norm = 1.9349e-01, time/batch = 18.5552s	
14166/26050 (epoch 27.190), train_loss = 0.96612614, grad/param norm = 2.0546e-01, time/batch = 18.4731s	
14167/26050 (epoch 27.192), train_loss = 0.95582508, grad/param norm = 1.7068e-01, time/batch = 18.0731s	
14168/26050 (epoch 27.194), train_loss = 0.96379365, grad/param norm = 1.9834e-01, time/batch = 18.1452s	
14169/26050 (epoch 27.196), train_loss = 0.98433362, grad/param norm = 1.9767e-01, time/batch = 16.8038s	
14170/26050 (epoch 27.198), train_loss = 0.84312412, grad/param norm = 1.7645e-01, time/batch = 17.8109s	
14171/26050 (epoch 27.200), train_loss = 0.83411930, grad/param norm = 1.9286e-01, time/batch = 17.9865s	
14172/26050 (epoch 27.202), train_loss = 0.93641739, grad/param norm = 1.7005e-01, time/batch = 18.4023s	
14173/26050 (epoch 27.203), train_loss = 1.03346100, grad/param norm = 1.8782e-01, time/batch = 15.2134s	
14174/26050 (epoch 27.205), train_loss = 0.88254167, grad/param norm = 1.8680e-01, time/batch = 18.2458s	
14175/26050 (epoch 27.207), train_loss = 0.84722003, grad/param norm = 1.7773e-01, time/batch = 18.2479s	
14176/26050 (epoch 27.209), train_loss = 0.96889304, grad/param norm = 1.7835e-01, time/batch = 17.3133s	
14177/26050 (epoch 27.211), train_loss = 0.77884683, grad/param norm = 2.0100e-01, time/batch = 13.6758s	
14178/26050 (epoch 27.213), train_loss = 0.95474565, grad/param norm = 2.1941e-01, time/batch = 14.0848s	
14179/26050 (epoch 27.215), train_loss = 0.89593097, grad/param norm = 2.1512e-01, time/batch = 17.8708s	
14180/26050 (epoch 27.217), train_loss = 0.87220912, grad/param norm = 1.7750e-01, time/batch = 14.8625s	
14181/26050 (epoch 27.219), train_loss = 0.88870181, grad/param norm = 1.9393e-01, time/batch = 17.8280s	
14182/26050 (epoch 27.221), train_loss = 0.84446801, grad/param norm = 2.0579e-01, time/batch = 18.9778s	
14183/26050 (epoch 27.223), train_loss = 0.99493554, grad/param norm = 2.1353e-01, time/batch = 17.3938s	
14184/26050 (epoch 27.225), train_loss = 0.83560814, grad/param norm = 1.9283e-01, time/batch = 18.7185s	
14185/26050 (epoch 27.226), train_loss = 0.95803970, grad/param norm = 2.0321e-01, time/batch = 18.6390s	
14186/26050 (epoch 27.228), train_loss = 1.05525699, grad/param norm = 1.9431e-01, time/batch = 17.4731s	
14187/26050 (epoch 27.230), train_loss = 0.94088891, grad/param norm = 1.9704e-01, time/batch = 18.2176s	
14188/26050 (epoch 27.232), train_loss = 1.01022849, grad/param norm = 2.2460e-01, time/batch = 15.2232s	
14189/26050 (epoch 27.234), train_loss = 0.83421824, grad/param norm = 1.9585e-01, time/batch = 18.3724s	
14190/26050 (epoch 27.236), train_loss = 1.01572740, grad/param norm = 1.9539e-01, time/batch = 16.2313s	
14191/26050 (epoch 27.238), train_loss = 0.80170540, grad/param norm = 1.9843e-01, time/batch = 17.6409s	
14192/26050 (epoch 27.240), train_loss = 0.93117914, grad/param norm = 1.9110e-01, time/batch = 18.1635s	
14193/26050 (epoch 27.242), train_loss = 0.89876608, grad/param norm = 1.9289e-01, time/batch = 17.1454s	
14194/26050 (epoch 27.244), train_loss = 0.94538809, grad/param norm = 2.2345e-01, time/batch = 17.0701s	
14195/26050 (epoch 27.246), train_loss = 0.85385208, grad/param norm = 1.8474e-01, time/batch = 17.4989s	
14196/26050 (epoch 27.248), train_loss = 0.94048639, grad/param norm = 1.8612e-01, time/batch = 17.1331s	
14197/26050 (epoch 27.250), train_loss = 0.91504830, grad/param norm = 2.2692e-01, time/batch = 18.4076s	
14198/26050 (epoch 27.251), train_loss = 0.88588831, grad/param norm = 1.7671e-01, time/batch = 15.3803s	
14199/26050 (epoch 27.253), train_loss = 0.82537385, grad/param norm = 1.7254e-01, time/batch = 18.8923s	
14200/26050 (epoch 27.255), train_loss = 1.07689398, grad/param norm = 1.9235e-01, time/batch = 17.8079s	
14201/26050 (epoch 27.257), train_loss = 0.92488318, grad/param norm = 2.2772e-01, time/batch = 18.1642s	
14202/26050 (epoch 27.259), train_loss = 1.00833723, grad/param norm = 1.8591e-01, time/batch = 15.2236s	
14203/26050 (epoch 27.261), train_loss = 0.83663357, grad/param norm = 2.1551e-01, time/batch = 17.7416s	
14204/26050 (epoch 27.263), train_loss = 1.02375763, grad/param norm = 2.1510e-01, time/batch = 16.8299s	
14205/26050 (epoch 27.265), train_loss = 1.06930988, grad/param norm = 2.2273e-01, time/batch = 17.8143s	
14206/26050 (epoch 27.267), train_loss = 1.04264700, grad/param norm = 1.7601e-01, time/batch = 19.2380s	
14207/26050 (epoch 27.269), train_loss = 1.04040895, grad/param norm = 2.0883e-01, time/batch = 16.1335s	
14208/26050 (epoch 27.271), train_loss = 0.95138538, grad/param norm = 1.9330e-01, time/batch = 17.4661s	
14209/26050 (epoch 27.273), train_loss = 0.85796438, grad/param norm = 1.9230e-01, time/batch = 19.0579s	
14210/26050 (epoch 27.274), train_loss = 0.90608456, grad/param norm = 1.7387e-01, time/batch = 17.4807s	
14211/26050 (epoch 27.276), train_loss = 0.88971993, grad/param norm = 1.9329e-01, time/batch = 18.0662s	
14212/26050 (epoch 27.278), train_loss = 1.03788814, grad/param norm = 1.9956e-01, time/batch = 17.6521s	
14213/26050 (epoch 27.280), train_loss = 0.91812389, grad/param norm = 1.7911e-01, time/batch = 16.2159s	
14214/26050 (epoch 27.282), train_loss = 0.98288455, grad/param norm = 1.9958e-01, time/batch = 17.9723s	
14215/26050 (epoch 27.284), train_loss = 0.90865798, grad/param norm = 1.9435e-01, time/batch = 18.4841s	
14216/26050 (epoch 27.286), train_loss = 0.94658649, grad/param norm = 2.1707e-01, time/batch = 16.3779s	
14217/26050 (epoch 27.288), train_loss = 0.78405586, grad/param norm = 1.6719e-01, time/batch = 15.1260s	
14218/26050 (epoch 27.290), train_loss = 0.95027038, grad/param norm = 2.0701e-01, time/batch = 18.2279s	
14219/26050 (epoch 27.292), train_loss = 0.86067097, grad/param norm = 1.7968e-01, time/batch = 18.4870s	
14220/26050 (epoch 27.294), train_loss = 0.92270993, grad/param norm = 2.0253e-01, time/batch = 17.6572s	
14221/26050 (epoch 27.296), train_loss = 1.03098433, grad/param norm = 2.0245e-01, time/batch = 15.2204s	
14222/26050 (epoch 27.298), train_loss = 0.96184847, grad/param norm = 1.7921e-01, time/batch = 18.2328s	
14223/26050 (epoch 27.299), train_loss = 0.76891909, grad/param norm = 1.6825e-01, time/batch = 18.7304s	
14224/26050 (epoch 27.301), train_loss = 0.79494940, grad/param norm = 1.9186e-01, time/batch = 16.8145s	
14225/26050 (epoch 27.303), train_loss = 0.93239321, grad/param norm = 1.9983e-01, time/batch = 18.8907s	
14226/26050 (epoch 27.305), train_loss = 0.76344115, grad/param norm = 1.9065e-01, time/batch = 17.0369s	
14227/26050 (epoch 27.307), train_loss = 0.86881280, grad/param norm = 2.0786e-01, time/batch = 17.7204s	
14228/26050 (epoch 27.309), train_loss = 0.92246497, grad/param norm = 1.9489e-01, time/batch = 17.0344s	
14229/26050 (epoch 27.311), train_loss = 0.99790910, grad/param norm = 2.2840e-01, time/batch = 17.9828s	
14230/26050 (epoch 27.313), train_loss = 0.91227208, grad/param norm = 2.0367e-01, time/batch = 18.4018s	
14231/26050 (epoch 27.315), train_loss = 1.01095472, grad/param norm = 2.1961e-01, time/batch = 18.1480s	
14232/26050 (epoch 27.317), train_loss = 0.95417295, grad/param norm = 2.0287e-01, time/batch = 17.9948s	
14233/26050 (epoch 27.319), train_loss = 0.85015187, grad/param norm = 2.0011e-01, time/batch = 18.5646s	
14234/26050 (epoch 27.321), train_loss = 0.90962957, grad/param norm = 2.0632e-01, time/batch = 17.7291s	
14235/26050 (epoch 27.322), train_loss = 0.97867772, grad/param norm = 1.8666e-01, time/batch = 17.9951s	
14236/26050 (epoch 27.324), train_loss = 0.74363657, grad/param norm = 1.5858e-01, time/batch = 16.5463s	
14237/26050 (epoch 27.326), train_loss = 1.05642306, grad/param norm = 2.0901e-01, time/batch = 15.7886s	
14238/26050 (epoch 27.328), train_loss = 0.95166811, grad/param norm = 1.7529e-01, time/batch = 31.4203s	
14239/26050 (epoch 27.330), train_loss = 0.79248789, grad/param norm = 1.7795e-01, time/batch = 26.6450s	
14240/26050 (epoch 27.332), train_loss = 0.97600036, grad/param norm = 1.9200e-01, time/batch = 16.5165s	
14241/26050 (epoch 27.334), train_loss = 0.84953036, grad/param norm = 1.8579e-01, time/batch = 18.2468s	
14242/26050 (epoch 27.336), train_loss = 0.87581008, grad/param norm = 1.9116e-01, time/batch = 17.9049s	
14243/26050 (epoch 27.338), train_loss = 0.81885586, grad/param norm = 1.9204e-01, time/batch = 16.3190s	
14244/26050 (epoch 27.340), train_loss = 0.98297608, grad/param norm = 1.8726e-01, time/batch = 17.7221s	
14245/26050 (epoch 27.342), train_loss = 1.01088654, grad/param norm = 1.7894e-01, time/batch = 17.8104s	
14246/26050 (epoch 27.344), train_loss = 0.85124438, grad/param norm = 1.9169e-01, time/batch = 16.3809s	
14247/26050 (epoch 27.345), train_loss = 0.91089613, grad/param norm = 2.0309e-01, time/batch = 18.0536s	
14248/26050 (epoch 27.347), train_loss = 1.06259687, grad/param norm = 2.2924e-01, time/batch = 18.5685s	
14249/26050 (epoch 27.349), train_loss = 0.97758743, grad/param norm = 2.0184e-01, time/batch = 18.2399s	
14250/26050 (epoch 27.351), train_loss = 0.96777717, grad/param norm = 2.0138e-01, time/batch = 17.8848s	
14251/26050 (epoch 27.353), train_loss = 0.93994664, grad/param norm = 1.9687e-01, time/batch = 18.3926s	
14252/26050 (epoch 27.355), train_loss = 0.96500679, grad/param norm = 2.3823e-01, time/batch = 18.2393s	
14253/26050 (epoch 27.357), train_loss = 0.87376423, grad/param norm = 1.7631e-01, time/batch = 17.0468s	
14254/26050 (epoch 27.359), train_loss = 1.03070291, grad/param norm = 2.0823e-01, time/batch = 15.1407s	
14255/26050 (epoch 27.361), train_loss = 0.85262349, grad/param norm = 1.7606e-01, time/batch = 18.3204s	
14256/26050 (epoch 27.363), train_loss = 1.00908588, grad/param norm = 1.9188e-01, time/batch = 18.4826s	
14257/26050 (epoch 27.365), train_loss = 0.88968189, grad/param norm = 1.7604e-01, time/batch = 16.3868s	
14258/26050 (epoch 27.367), train_loss = 0.99244771, grad/param norm = 1.8185e-01, time/batch = 15.1890s	
14259/26050 (epoch 27.369), train_loss = 0.84361089, grad/param norm = 1.8227e-01, time/batch = 17.9752s	
14260/26050 (epoch 27.370), train_loss = 0.82950292, grad/param norm = 1.7048e-01, time/batch = 15.9550s	
14261/26050 (epoch 27.372), train_loss = 0.93265845, grad/param norm = 1.9486e-01, time/batch = 17.8899s	
14262/26050 (epoch 27.374), train_loss = 1.05427459, grad/param norm = 2.0558e-01, time/batch = 17.4919s	
14263/26050 (epoch 27.376), train_loss = 1.11209010, grad/param norm = 2.2583e-01, time/batch = 18.3115s	
14264/26050 (epoch 27.378), train_loss = 0.88124728, grad/param norm = 1.7986e-01, time/batch = 18.6513s	
14265/26050 (epoch 27.380), train_loss = 1.09862665, grad/param norm = 2.3820e-01, time/batch = 17.4980s	
14266/26050 (epoch 27.382), train_loss = 1.20334417, grad/param norm = 2.5612e-01, time/batch = 17.9178s	
14267/26050 (epoch 27.384), train_loss = 0.91536646, grad/param norm = 2.0257e-01, time/batch = 16.4685s	
14268/26050 (epoch 27.386), train_loss = 1.00791189, grad/param norm = 2.5753e-01, time/batch = 15.2804s	
14269/26050 (epoch 27.388), train_loss = 0.96736478, grad/param norm = 2.0987e-01, time/batch = 17.0527s	
14270/26050 (epoch 27.390), train_loss = 0.88409128, grad/param norm = 1.7956e-01, time/batch = 17.4629s	
14271/26050 (epoch 27.392), train_loss = 0.82316195, grad/param norm = 1.8451e-01, time/batch = 18.3766s	
14272/26050 (epoch 27.393), train_loss = 0.96673516, grad/param norm = 2.0440e-01, time/batch = 16.4468s	
14273/26050 (epoch 27.395), train_loss = 1.01577626, grad/param norm = 2.4939e-01, time/batch = 18.3746s	
14274/26050 (epoch 27.397), train_loss = 1.00899295, grad/param norm = 2.1848e-01, time/batch = 17.0530s	
14275/26050 (epoch 27.399), train_loss = 0.88124493, grad/param norm = 2.0299e-01, time/batch = 18.4770s	
14276/26050 (epoch 27.401), train_loss = 0.96693978, grad/param norm = 1.9713e-01, time/batch = 18.2335s	
14277/26050 (epoch 27.403), train_loss = 0.97431418, grad/param norm = 2.2548e-01, time/batch = 17.6381s	
14278/26050 (epoch 27.405), train_loss = 0.95144952, grad/param norm = 2.0291e-01, time/batch = 18.4138s	
14279/26050 (epoch 27.407), train_loss = 1.08234453, grad/param norm = 2.1192e-01, time/batch = 17.7457s	
14280/26050 (epoch 27.409), train_loss = 1.07720475, grad/param norm = 2.2843e-01, time/batch = 18.2304s	
14281/26050 (epoch 27.411), train_loss = 1.00509026, grad/param norm = 2.1667e-01, time/batch = 18.3179s	
14282/26050 (epoch 27.413), train_loss = 1.09820195, grad/param norm = 1.9125e-01, time/batch = 17.7186s	
14283/26050 (epoch 27.415), train_loss = 1.09980362, grad/param norm = 2.3978e-01, time/batch = 16.7302s	
14284/26050 (epoch 27.417), train_loss = 1.14369105, grad/param norm = 2.3211e-01, time/batch = 16.8236s	
14285/26050 (epoch 27.418), train_loss = 1.03758429, grad/param norm = 2.1858e-01, time/batch = 18.6588s	
14286/26050 (epoch 27.420), train_loss = 0.82216877, grad/param norm = 1.7906e-01, time/batch = 18.4842s	
14287/26050 (epoch 27.422), train_loss = 0.80259418, grad/param norm = 1.8257e-01, time/batch = 16.6412s	
14288/26050 (epoch 27.424), train_loss = 1.07720601, grad/param norm = 2.2192e-01, time/batch = 16.1609s	
14289/26050 (epoch 27.426), train_loss = 1.03537271, grad/param norm = 1.9489e-01, time/batch = 16.1423s	
14290/26050 (epoch 27.428), train_loss = 0.89813259, grad/param norm = 1.8586e-01, time/batch = 16.8863s	
14291/26050 (epoch 27.430), train_loss = 1.09131897, grad/param norm = 2.0572e-01, time/batch = 17.1671s	
14292/26050 (epoch 27.432), train_loss = 0.92566492, grad/param norm = 1.8485e-01, time/batch = 18.5735s	
14293/26050 (epoch 27.434), train_loss = 0.91846856, grad/param norm = 1.8040e-01, time/batch = 17.9884s	
14294/26050 (epoch 27.436), train_loss = 1.07619576, grad/param norm = 2.1986e-01, time/batch = 16.9790s	
14295/26050 (epoch 27.438), train_loss = 1.02542277, grad/param norm = 2.1508e-01, time/batch = 18.2474s	
14296/26050 (epoch 27.440), train_loss = 0.96822140, grad/param norm = 2.1261e-01, time/batch = 17.9197s	
14297/26050 (epoch 27.441), train_loss = 0.96220119, grad/param norm = 1.8862e-01, time/batch = 18.3151s	
14298/26050 (epoch 27.443), train_loss = 0.80994782, grad/param norm = 1.5776e-01, time/batch = 15.8995s	
14299/26050 (epoch 27.445), train_loss = 0.86426937, grad/param norm = 1.8034e-01, time/batch = 18.3992s	
14300/26050 (epoch 27.447), train_loss = 1.06111231, grad/param norm = 2.0399e-01, time/batch = 18.4055s	
14301/26050 (epoch 27.449), train_loss = 0.87621958, grad/param norm = 1.9509e-01, time/batch = 16.9863s	
14302/26050 (epoch 27.451), train_loss = 1.10629793, grad/param norm = 2.0064e-01, time/batch = 18.4862s	
14303/26050 (epoch 27.453), train_loss = 0.87808232, grad/param norm = 1.6569e-01, time/batch = 16.9082s	
14304/26050 (epoch 27.455), train_loss = 0.95523293, grad/param norm = 1.8194e-01, time/batch = 17.8020s	
14305/26050 (epoch 27.457), train_loss = 0.94087950, grad/param norm = 1.9078e-01, time/batch = 15.1482s	
14306/26050 (epoch 27.459), train_loss = 1.04659520, grad/param norm = 1.9759e-01, time/batch = 17.9664s	
14307/26050 (epoch 27.461), train_loss = 1.04726372, grad/param norm = 2.1565e-01, time/batch = 18.8976s	
14308/26050 (epoch 27.463), train_loss = 0.90470301, grad/param norm = 1.7017e-01, time/batch = 16.7394s	
14309/26050 (epoch 27.464), train_loss = 0.98238152, grad/param norm = 1.8475e-01, time/batch = 16.9637s	
14310/26050 (epoch 27.466), train_loss = 0.99135576, grad/param norm = 1.8559e-01, time/batch = 18.3191s	
14311/26050 (epoch 27.468), train_loss = 1.04040946, grad/param norm = 1.7458e-01, time/batch = 17.4813s	
14312/26050 (epoch 27.470), train_loss = 1.06064136, grad/param norm = 2.6186e-01, time/batch = 17.7320s	
14313/26050 (epoch 27.472), train_loss = 1.07181707, grad/param norm = 2.4626e-01, time/batch = 16.1571s	
14314/26050 (epoch 27.474), train_loss = 1.06729668, grad/param norm = 2.0631e-01, time/batch = 18.9099s	
14315/26050 (epoch 27.476), train_loss = 1.07533201, grad/param norm = 1.9555e-01, time/batch = 18.4778s	
14316/26050 (epoch 27.478), train_loss = 0.92142900, grad/param norm = 1.8586e-01, time/batch = 18.0806s	
14317/26050 (epoch 27.480), train_loss = 0.94170922, grad/param norm = 1.7715e-01, time/batch = 17.4035s	
14318/26050 (epoch 27.482), train_loss = 0.90175544, grad/param norm = 1.8866e-01, time/batch = 14.7810s	
14319/26050 (epoch 27.484), train_loss = 0.89742322, grad/param norm = 1.8555e-01, time/batch = 18.3010s	
14320/26050 (epoch 27.486), train_loss = 1.08538453, grad/param norm = 1.8463e-01, time/batch = 14.7207s	
14321/26050 (epoch 27.488), train_loss = 1.14370670, grad/param norm = 2.0673e-01, time/batch = 18.2493s	
14322/26050 (epoch 27.489), train_loss = 1.10497880, grad/param norm = 2.2149e-01, time/batch = 16.9728s	
14323/26050 (epoch 27.491), train_loss = 0.88558179, grad/param norm = 2.0755e-01, time/batch = 18.0563s	
14324/26050 (epoch 27.493), train_loss = 0.97784145, grad/param norm = 2.0725e-01, time/batch = 18.3278s	
14325/26050 (epoch 27.495), train_loss = 0.93886155, grad/param norm = 1.8581e-01, time/batch = 17.3190s	
14326/26050 (epoch 27.497), train_loss = 0.86414707, grad/param norm = 1.7912e-01, time/batch = 18.7330s	
14327/26050 (epoch 27.499), train_loss = 0.91972339, grad/param norm = 1.9519e-01, time/batch = 18.4097s	
14328/26050 (epoch 27.501), train_loss = 1.02726304, grad/param norm = 2.0180e-01, time/batch = 17.7324s	
14329/26050 (epoch 27.503), train_loss = 0.89151354, grad/param norm = 1.8748e-01, time/batch = 18.9014s	
14330/26050 (epoch 27.505), train_loss = 1.06978489, grad/param norm = 1.9977e-01, time/batch = 18.0650s	
14331/26050 (epoch 27.507), train_loss = 1.03083177, grad/param norm = 2.5788e-01, time/batch = 15.8764s	
14332/26050 (epoch 27.509), train_loss = 1.11985766, grad/param norm = 2.0107e-01, time/batch = 18.2241s	
14333/26050 (epoch 27.511), train_loss = 0.90939197, grad/param norm = 1.8162e-01, time/batch = 18.3263s	
14334/26050 (epoch 27.512), train_loss = 0.82951219, grad/param norm = 1.8958e-01, time/batch = 14.9834s	
14335/26050 (epoch 27.514), train_loss = 1.02581258, grad/param norm = 2.2026e-01, time/batch = 17.8881s	
14336/26050 (epoch 27.516), train_loss = 1.08881324, grad/param norm = 2.1410e-01, time/batch = 18.1743s	
14337/26050 (epoch 27.518), train_loss = 0.94818607, grad/param norm = 1.9857e-01, time/batch = 18.2355s	
14338/26050 (epoch 27.520), train_loss = 0.95145735, grad/param norm = 1.9352e-01, time/batch = 17.6538s	
14339/26050 (epoch 27.522), train_loss = 0.74884378, grad/param norm = 1.6687e-01, time/batch = 18.1389s	
14340/26050 (epoch 27.524), train_loss = 1.01865134, grad/param norm = 2.1979e-01, time/batch = 18.2290s	
14341/26050 (epoch 27.526), train_loss = 1.05775569, grad/param norm = 2.0773e-01, time/batch = 15.9751s	
14342/26050 (epoch 27.528), train_loss = 0.98248527, grad/param norm = 2.0024e-01, time/batch = 17.6151s	
14343/26050 (epoch 27.530), train_loss = 0.91531204, grad/param norm = 2.0610e-01, time/batch = 18.0797s	
14344/26050 (epoch 27.532), train_loss = 0.99438864, grad/param norm = 2.0989e-01, time/batch = 16.6554s	
14345/26050 (epoch 27.534), train_loss = 1.04404558, grad/param norm = 2.7430e-01, time/batch = 17.6263s	
14346/26050 (epoch 27.536), train_loss = 0.97794543, grad/param norm = 2.1221e-01, time/batch = 18.1544s	
14347/26050 (epoch 27.537), train_loss = 1.03444705, grad/param norm = 2.0833e-01, time/batch = 18.2227s	
14348/26050 (epoch 27.539), train_loss = 0.96231753, grad/param norm = 2.0918e-01, time/batch = 17.7904s	
14349/26050 (epoch 27.541), train_loss = 1.15311649, grad/param norm = 2.3575e-01, time/batch = 17.9715s	
14350/26050 (epoch 27.543), train_loss = 0.79906906, grad/param norm = 1.9194e-01, time/batch = 18.6500s	
14351/26050 (epoch 27.545), train_loss = 0.98085772, grad/param norm = 1.9741e-01, time/batch = 18.9011s	
14352/26050 (epoch 27.547), train_loss = 0.94436009, grad/param norm = 2.0086e-01, time/batch = 17.3872s	
14353/26050 (epoch 27.549), train_loss = 0.81494970, grad/param norm = 2.1661e-01, time/batch = 18.1459s	
14354/26050 (epoch 27.551), train_loss = 1.01953212, grad/param norm = 2.1366e-01, time/batch = 16.2274s	
14355/26050 (epoch 27.553), train_loss = 0.90433528, grad/param norm = 1.8393e-01, time/batch = 16.1261s	
14356/26050 (epoch 27.555), train_loss = 0.85583278, grad/param norm = 1.8625e-01, time/batch = 17.6579s	
14357/26050 (epoch 27.557), train_loss = 0.98487188, grad/param norm = 1.8743e-01, time/batch = 15.1577s	
14358/26050 (epoch 27.559), train_loss = 0.95144764, grad/param norm = 1.9452e-01, time/batch = 18.3920s	
14359/26050 (epoch 27.560), train_loss = 0.92912588, grad/param norm = 2.0846e-01, time/batch = 18.0674s	
14360/26050 (epoch 27.562), train_loss = 0.93605777, grad/param norm = 2.0381e-01, time/batch = 17.2345s	
14361/26050 (epoch 27.564), train_loss = 1.12449690, grad/param norm = 2.0500e-01, time/batch = 17.3907s	
14362/26050 (epoch 27.566), train_loss = 0.88068122, grad/param norm = 1.8475e-01, time/batch = 18.0717s	
14363/26050 (epoch 27.568), train_loss = 1.00013887, grad/param norm = 2.0099e-01, time/batch = 18.5546s	
14364/26050 (epoch 27.570), train_loss = 0.99001067, grad/param norm = 2.0141e-01, time/batch = 18.1469s	
14365/26050 (epoch 27.572), train_loss = 0.95682611, grad/param norm = 1.9515e-01, time/batch = 14.4784s	
14366/26050 (epoch 27.574), train_loss = 0.97020614, grad/param norm = 2.3648e-01, time/batch = 17.7231s	
14367/26050 (epoch 27.576), train_loss = 0.99511115, grad/param norm = 2.1775e-01, time/batch = 17.7018s	
14368/26050 (epoch 27.578), train_loss = 0.94146780, grad/param norm = 1.9481e-01, time/batch = 15.3105s	
14369/26050 (epoch 27.580), train_loss = 0.88549249, grad/param norm = 1.9682e-01, time/batch = 17.1538s	
14370/26050 (epoch 27.582), train_loss = 0.98525238, grad/param norm = 1.9278e-01, time/batch = 18.3934s	
14371/26050 (epoch 27.583), train_loss = 1.04535715, grad/param norm = 2.0496e-01, time/batch = 19.0533s	
14372/26050 (epoch 27.585), train_loss = 0.83942558, grad/param norm = 2.0258e-01, time/batch = 17.5607s	
14373/26050 (epoch 27.587), train_loss = 0.98614424, grad/param norm = 1.9286e-01, time/batch = 3.3788s	
14374/26050 (epoch 27.589), train_loss = 1.11671718, grad/param norm = 2.3008e-01, time/batch = 0.6444s	
14375/26050 (epoch 27.591), train_loss = 0.95598845, grad/param norm = 1.9999e-01, time/batch = 0.6529s	
14376/26050 (epoch 27.593), train_loss = 0.84012113, grad/param norm = 1.8467e-01, time/batch = 0.6420s	
14377/26050 (epoch 27.595), train_loss = 1.02783230, grad/param norm = 2.0731e-01, time/batch = 0.6403s	
14378/26050 (epoch 27.597), train_loss = 0.96596191, grad/param norm = 1.9125e-01, time/batch = 0.6472s	
14379/26050 (epoch 27.599), train_loss = 0.99268648, grad/param norm = 2.0243e-01, time/batch = 0.6733s	
14380/26050 (epoch 27.601), train_loss = 1.12117147, grad/param norm = 2.1795e-01, time/batch = 0.7366s	
14381/26050 (epoch 27.603), train_loss = 0.98573997, grad/param norm = 2.1889e-01, time/batch = 0.9606s	
14382/26050 (epoch 27.605), train_loss = 0.93177507, grad/param norm = 2.1773e-01, time/batch = 0.9587s	
14383/26050 (epoch 27.607), train_loss = 1.05232429, grad/param norm = 2.2102e-01, time/batch = 0.9616s	
14384/26050 (epoch 27.608), train_loss = 0.86577789, grad/param norm = 1.8036e-01, time/batch = 0.9576s	
14385/26050 (epoch 27.610), train_loss = 0.96227258, grad/param norm = 2.1041e-01, time/batch = 1.0237s	
14386/26050 (epoch 27.612), train_loss = 0.92787696, grad/param norm = 1.9477e-01, time/batch = 1.7836s	
14387/26050 (epoch 27.614), train_loss = 0.96601447, grad/param norm = 1.8812e-01, time/batch = 1.8068s	
14388/26050 (epoch 27.616), train_loss = 1.05397529, grad/param norm = 2.3180e-01, time/batch = 6.4593s	
14389/26050 (epoch 27.618), train_loss = 0.91405919, grad/param norm = 2.0679e-01, time/batch = 15.0495s	
14390/26050 (epoch 27.620), train_loss = 1.01019440, grad/param norm = 1.9353e-01, time/batch = 18.3249s	
14391/26050 (epoch 27.622), train_loss = 0.84991764, grad/param norm = 1.7407e-01, time/batch = 17.8109s	
14392/26050 (epoch 27.624), train_loss = 0.80790637, grad/param norm = 1.7483e-01, time/batch = 18.3220s	
14393/26050 (epoch 27.626), train_loss = 1.01004874, grad/param norm = 1.9514e-01, time/batch = 16.2305s	
14394/26050 (epoch 27.628), train_loss = 0.90175892, grad/param norm = 2.1722e-01, time/batch = 17.4108s	
14395/26050 (epoch 27.630), train_loss = 1.09787843, grad/param norm = 1.9270e-01, time/batch = 17.5711s	
14396/26050 (epoch 27.631), train_loss = 1.11974681, grad/param norm = 2.1433e-01, time/batch = 17.9761s	
14397/26050 (epoch 27.633), train_loss = 0.86590322, grad/param norm = 1.8138e-01, time/batch = 18.0580s	
14398/26050 (epoch 27.635), train_loss = 0.90459716, grad/param norm = 1.7020e-01, time/batch = 17.9737s	
14399/26050 (epoch 27.637), train_loss = 0.83267521, grad/param norm = 1.8516e-01, time/batch = 18.6527s	
14400/26050 (epoch 27.639), train_loss = 1.03223886, grad/param norm = 2.0004e-01, time/batch = 14.8806s	
14401/26050 (epoch 27.641), train_loss = 0.91564698, grad/param norm = 1.9581e-01, time/batch = 17.7187s	
14402/26050 (epoch 27.643), train_loss = 0.86939465, grad/param norm = 1.6309e-01, time/batch = 18.2288s	
14403/26050 (epoch 27.645), train_loss = 0.89165906, grad/param norm = 1.8709e-01, time/batch = 18.0700s	
14404/26050 (epoch 27.647), train_loss = 0.89017115, grad/param norm = 2.0473e-01, time/batch = 16.8997s	
14405/26050 (epoch 27.649), train_loss = 0.94784019, grad/param norm = 2.0916e-01, time/batch = 18.1472s	
14406/26050 (epoch 27.651), train_loss = 0.90074644, grad/param norm = 1.9714e-01, time/batch = 18.3828s	
14407/26050 (epoch 27.653), train_loss = 0.94047593, grad/param norm = 2.0734e-01, time/batch = 18.1369s	
14408/26050 (epoch 27.655), train_loss = 0.87220113, grad/param norm = 1.9512e-01, time/batch = 16.5386s	
14409/26050 (epoch 27.656), train_loss = 0.81604463, grad/param norm = 1.6634e-01, time/batch = 18.3931s	
14410/26050 (epoch 27.658), train_loss = 1.13335357, grad/param norm = 2.0916e-01, time/batch = 17.7446s	
14411/26050 (epoch 27.660), train_loss = 0.82028822, grad/param norm = 1.8983e-01, time/batch = 15.4216s	
14412/26050 (epoch 27.662), train_loss = 0.92803233, grad/param norm = 1.8826e-01, time/batch = 18.0672s	
14413/26050 (epoch 27.664), train_loss = 0.93099941, grad/param norm = 1.9797e-01, time/batch = 17.8194s	
14414/26050 (epoch 27.666), train_loss = 0.88848043, grad/param norm = 1.9086e-01, time/batch = 17.8163s	
14415/26050 (epoch 27.668), train_loss = 0.76843427, grad/param norm = 2.0397e-01, time/batch = 17.9003s	
14416/26050 (epoch 27.670), train_loss = 1.07682458, grad/param norm = 2.1894e-01, time/batch = 18.6522s	
14417/26050 (epoch 27.672), train_loss = 0.95665414, grad/param norm = 2.0679e-01, time/batch = 16.2314s	
14418/26050 (epoch 27.674), train_loss = 0.84201200, grad/param norm = 1.8951e-01, time/batch = 17.7931s	
14419/26050 (epoch 27.676), train_loss = 1.01076032, grad/param norm = 2.1858e-01, time/batch = 17.5791s	
14420/26050 (epoch 27.678), train_loss = 1.02867607, grad/param norm = 2.1852e-01, time/batch = 18.4903s	
14421/26050 (epoch 27.679), train_loss = 1.10496547, grad/param norm = 2.1217e-01, time/batch = 16.5524s	
14422/26050 (epoch 27.681), train_loss = 0.96908940, grad/param norm = 1.9448e-01, time/batch = 17.9090s	
14423/26050 (epoch 27.683), train_loss = 0.85226677, grad/param norm = 2.2948e-01, time/batch = 18.5774s	
14424/26050 (epoch 27.685), train_loss = 0.91689632, grad/param norm = 1.8558e-01, time/batch = 17.2404s	
14425/26050 (epoch 27.687), train_loss = 0.82019543, grad/param norm = 1.8688e-01, time/batch = 18.3214s	
14426/26050 (epoch 27.689), train_loss = 0.90501816, grad/param norm = 1.9115e-01, time/batch = 19.0602s	
14427/26050 (epoch 27.691), train_loss = 0.77031013, grad/param norm = 1.5735e-01, time/batch = 15.2321s	
14428/26050 (epoch 27.693), train_loss = 0.87985314, grad/param norm = 1.9294e-01, time/batch = 17.8116s	
14429/26050 (epoch 27.695), train_loss = 0.93860325, grad/param norm = 1.7158e-01, time/batch = 18.4900s	
14430/26050 (epoch 27.697), train_loss = 0.86880265, grad/param norm = 1.8547e-01, time/batch = 18.3938s	
14431/26050 (epoch 27.699), train_loss = 0.99270650, grad/param norm = 2.1156e-01, time/batch = 16.0546s	
14432/26050 (epoch 27.701), train_loss = 0.84592010, grad/param norm = 1.7867e-01, time/batch = 17.8063s	
14433/26050 (epoch 27.702), train_loss = 1.04028094, grad/param norm = 1.9980e-01, time/batch = 18.0376s	
14434/26050 (epoch 27.704), train_loss = 1.04599217, grad/param norm = 1.8725e-01, time/batch = 15.4820s	
14435/26050 (epoch 27.706), train_loss = 0.88310696, grad/param norm = 1.9279e-01, time/batch = 18.0496s	
14436/26050 (epoch 27.708), train_loss = 1.02125119, grad/param norm = 2.0230e-01, time/batch = 18.0741s	
14437/26050 (epoch 27.710), train_loss = 0.96949187, grad/param norm = 2.1435e-01, time/batch = 18.5689s	
14438/26050 (epoch 27.712), train_loss = 0.95271496, grad/param norm = 1.8961e-01, time/batch = 16.4020s	
14439/26050 (epoch 27.714), train_loss = 0.83240178, grad/param norm = 1.7447e-01, time/batch = 18.1600s	
14440/26050 (epoch 27.716), train_loss = 1.19084267, grad/param norm = 2.2022e-01, time/batch = 18.4153s	
14441/26050 (epoch 27.718), train_loss = 1.01828673, grad/param norm = 2.0636e-01, time/batch = 17.3715s	
14442/26050 (epoch 27.720), train_loss = 0.94617681, grad/param norm = 2.0398e-01, time/batch = 17.4951s	
14443/26050 (epoch 27.722), train_loss = 0.83804642, grad/param norm = 1.7922e-01, time/batch = 15.8057s	
14444/26050 (epoch 27.724), train_loss = 0.88453954, grad/param norm = 1.9434e-01, time/batch = 18.0706s	
14445/26050 (epoch 27.726), train_loss = 0.99631369, grad/param norm = 2.1084e-01, time/batch = 17.2441s	
14446/26050 (epoch 27.727), train_loss = 1.00477265, grad/param norm = 2.0867e-01, time/batch = 14.6462s	
14447/26050 (epoch 27.729), train_loss = 0.98280062, grad/param norm = 1.9213e-01, time/batch = 16.5865s	
14448/26050 (epoch 27.731), train_loss = 0.98038873, grad/param norm = 1.9276e-01, time/batch = 17.9794s	
14449/26050 (epoch 27.733), train_loss = 0.92019312, grad/param norm = 2.2363e-01, time/batch = 17.7367s	
14450/26050 (epoch 27.735), train_loss = 1.12474006, grad/param norm = 2.2572e-01, time/batch = 18.9942s	
14451/26050 (epoch 27.737), train_loss = 0.90017228, grad/param norm = 2.1454e-01, time/batch = 18.3075s	
14452/26050 (epoch 27.739), train_loss = 0.98469512, grad/param norm = 1.8902e-01, time/batch = 15.2144s	
14453/26050 (epoch 27.741), train_loss = 0.89338831, grad/param norm = 2.0176e-01, time/batch = 18.4819s	
14454/26050 (epoch 27.743), train_loss = 0.97655232, grad/param norm = 2.2046e-01, time/batch = 18.2441s	
14455/26050 (epoch 27.745), train_loss = 0.84362453, grad/param norm = 1.9726e-01, time/batch = 19.1092s	
14456/26050 (epoch 27.747), train_loss = 0.87034294, grad/param norm = 1.9388e-01, time/batch = 35.1824s	
14457/26050 (epoch 27.749), train_loss = 1.04301866, grad/param norm = 2.0876e-01, time/batch = 21.1856s	
14458/26050 (epoch 27.750), train_loss = 0.94182993, grad/param norm = 1.6785e-01, time/batch = 17.8425s	
14459/26050 (epoch 27.752), train_loss = 0.89481892, grad/param norm = 2.1222e-01, time/batch = 18.6610s	
14460/26050 (epoch 27.754), train_loss = 0.95294598, grad/param norm = 1.9864e-01, time/batch = 18.1504s	
14461/26050 (epoch 27.756), train_loss = 0.93975253, grad/param norm = 2.6779e-01, time/batch = 15.4659s	
14462/26050 (epoch 27.758), train_loss = 0.92993784, grad/param norm = 2.1088e-01, time/batch = 18.3778s	
14463/26050 (epoch 27.760), train_loss = 1.11155037, grad/param norm = 2.0763e-01, time/batch = 18.4158s	
14464/26050 (epoch 27.762), train_loss = 0.90376285, grad/param norm = 1.9879e-01, time/batch = 17.3026s	
14465/26050 (epoch 27.764), train_loss = 0.94724483, grad/param norm = 2.4722e-01, time/batch = 18.3864s	
14466/26050 (epoch 27.766), train_loss = 0.98489036, grad/param norm = 2.1861e-01, time/batch = 14.6417s	
14467/26050 (epoch 27.768), train_loss = 0.84092246, grad/param norm = 1.7250e-01, time/batch = 18.0601s	
14468/26050 (epoch 27.770), train_loss = 0.92747623, grad/param norm = 2.1679e-01, time/batch = 18.2293s	
14469/26050 (epoch 27.772), train_loss = 0.94525017, grad/param norm = 1.7695e-01, time/batch = 18.8987s	
14470/26050 (epoch 27.774), train_loss = 0.82375648, grad/param norm = 2.0651e-01, time/batch = 18.9073s	
14471/26050 (epoch 27.775), train_loss = 0.68314595, grad/param norm = 1.8212e-01, time/batch = 16.7060s	
14472/26050 (epoch 27.777), train_loss = 0.88967825, grad/param norm = 1.9489e-01, time/batch = 14.9679s	
14473/26050 (epoch 27.779), train_loss = 0.93399033, grad/param norm = 2.4942e-01, time/batch = 18.7329s	
14474/26050 (epoch 27.781), train_loss = 0.83960992, grad/param norm = 1.9031e-01, time/batch = 17.4069s	
14475/26050 (epoch 27.783), train_loss = 0.82030603, grad/param norm = 1.8364e-01, time/batch = 18.2148s	
14476/26050 (epoch 27.785), train_loss = 0.97161937, grad/param norm = 2.0455e-01, time/batch = 18.3892s	
14477/26050 (epoch 27.787), train_loss = 0.85557300, grad/param norm = 2.2117e-01, time/batch = 17.6433s	
14478/26050 (epoch 27.789), train_loss = 0.88015745, grad/param norm = 2.0614e-01, time/batch = 17.2291s	
14479/26050 (epoch 27.791), train_loss = 0.85939169, grad/param norm = 1.9321e-01, time/batch = 17.1291s	
14480/26050 (epoch 27.793), train_loss = 0.90595525, grad/param norm = 2.2231e-01, time/batch = 18.5673s	
14481/26050 (epoch 27.795), train_loss = 0.76492469, grad/param norm = 1.4949e-01, time/batch = 17.7434s	
14482/26050 (epoch 27.797), train_loss = 0.83134441, grad/param norm = 1.9156e-01, time/batch = 14.5580s	
14483/26050 (epoch 27.798), train_loss = 0.83316080, grad/param norm = 2.0176e-01, time/batch = 18.4118s	
14484/26050 (epoch 27.800), train_loss = 0.81997405, grad/param norm = 1.7783e-01, time/batch = 16.7380s	
14485/26050 (epoch 27.802), train_loss = 0.88764143, grad/param norm = 1.9804e-01, time/batch = 18.6600s	
14486/26050 (epoch 27.804), train_loss = 0.91662180, grad/param norm = 2.0621e-01, time/batch = 18.3288s	
14487/26050 (epoch 27.806), train_loss = 1.00108308, grad/param norm = 2.1649e-01, time/batch = 15.0670s	
14488/26050 (epoch 27.808), train_loss = 0.93207715, grad/param norm = 1.8511e-01, time/batch = 15.8879s	
14489/26050 (epoch 27.810), train_loss = 0.88409953, grad/param norm = 1.8267e-01, time/batch = 19.0669s	
14490/26050 (epoch 27.812), train_loss = 0.79989291, grad/param norm = 1.9871e-01, time/batch = 17.8962s	
14491/26050 (epoch 27.814), train_loss = 0.85495381, grad/param norm = 2.0391e-01, time/batch = 18.2139s	
14492/26050 (epoch 27.816), train_loss = 0.98890431, grad/param norm = 2.2192e-01, time/batch = 18.2329s	
14493/26050 (epoch 27.818), train_loss = 1.02077353, grad/param norm = 2.3436e-01, time/batch = 18.5789s	
14494/26050 (epoch 27.820), train_loss = 0.94739384, grad/param norm = 1.9009e-01, time/batch = 17.8403s	
14495/26050 (epoch 27.821), train_loss = 1.04418679, grad/param norm = 2.1025e-01, time/batch = 18.8974s	
14496/26050 (epoch 27.823), train_loss = 1.11666491, grad/param norm = 2.0957e-01, time/batch = 17.8345s	
14497/26050 (epoch 27.825), train_loss = 0.94034296, grad/param norm = 2.1517e-01, time/batch = 16.2963s	
14498/26050 (epoch 27.827), train_loss = 0.96155988, grad/param norm = 2.2252e-01, time/batch = 16.6310s	
14499/26050 (epoch 27.829), train_loss = 1.00096991, grad/param norm = 2.0027e-01, time/batch = 18.3846s	
14500/26050 (epoch 27.831), train_loss = 1.08300903, grad/param norm = 2.2224e-01, time/batch = 18.7419s	
14501/26050 (epoch 27.833), train_loss = 1.09903763, grad/param norm = 2.2979e-01, time/batch = 18.3168s	
14502/26050 (epoch 27.835), train_loss = 1.08783999, grad/param norm = 2.0772e-01, time/batch = 17.7337s	
14503/26050 (epoch 27.837), train_loss = 0.93752463, grad/param norm = 1.8035e-01, time/batch = 15.0679s	
14504/26050 (epoch 27.839), train_loss = 0.92852801, grad/param norm = 2.0902e-01, time/batch = 18.5696s	
14505/26050 (epoch 27.841), train_loss = 1.05521719, grad/param norm = 2.1717e-01, time/batch = 16.1344s	
14506/26050 (epoch 27.843), train_loss = 0.90176774, grad/param norm = 1.6923e-01, time/batch = 17.5312s	
14507/26050 (epoch 27.845), train_loss = 0.90248091, grad/param norm = 1.8053e-01, time/batch = 18.9046s	
14508/26050 (epoch 27.846), train_loss = 1.00143780, grad/param norm = 2.1877e-01, time/batch = 17.4049s	
14509/26050 (epoch 27.848), train_loss = 0.92680987, grad/param norm = 1.9985e-01, time/batch = 18.3180s	
14510/26050 (epoch 27.850), train_loss = 0.85122454, grad/param norm = 1.8796e-01, time/batch = 18.5722s	
14511/26050 (epoch 27.852), train_loss = 0.96041688, grad/param norm = 1.9989e-01, time/batch = 17.3223s	
14512/26050 (epoch 27.854), train_loss = 0.91115717, grad/param norm = 1.8671e-01, time/batch = 18.2440s	
14513/26050 (epoch 27.856), train_loss = 0.89831143, grad/param norm = 2.1276e-01, time/batch = 16.2931s	
14514/26050 (epoch 27.858), train_loss = 0.87708598, grad/param norm = 2.0089e-01, time/batch = 18.4692s	
14515/26050 (epoch 27.860), train_loss = 0.98232121, grad/param norm = 1.9557e-01, time/batch = 17.4590s	
14516/26050 (epoch 27.862), train_loss = 1.02861163, grad/param norm = 1.9252e-01, time/batch = 18.5651s	
14517/26050 (epoch 27.864), train_loss = 0.97045006, grad/param norm = 2.2200e-01, time/batch = 18.2099s	
14518/26050 (epoch 27.866), train_loss = 0.90047905, grad/param norm = 1.7078e-01, time/batch = 17.5589s	
14519/26050 (epoch 27.868), train_loss = 0.99291358, grad/param norm = 2.0979e-01, time/batch = 17.7244s	
14520/26050 (epoch 27.869), train_loss = 0.84179885, grad/param norm = 1.8490e-01, time/batch = 18.2258s	
14521/26050 (epoch 27.871), train_loss = 0.79924559, grad/param norm = 1.8909e-01, time/batch = 17.0436s	
14522/26050 (epoch 27.873), train_loss = 0.97361556, grad/param norm = 2.1152e-01, time/batch = 16.5396s	
14523/26050 (epoch 27.875), train_loss = 0.93164019, grad/param norm = 2.1175e-01, time/batch = 18.4884s	
14524/26050 (epoch 27.877), train_loss = 0.85166535, grad/param norm = 1.8434e-01, time/batch = 15.7372s	
14525/26050 (epoch 27.879), train_loss = 0.95068346, grad/param norm = 1.6704e-01, time/batch = 16.8822s	
14526/26050 (epoch 27.881), train_loss = 1.02565727, grad/param norm = 2.1843e-01, time/batch = 18.6529s	
14527/26050 (epoch 27.883), train_loss = 0.97582054, grad/param norm = 1.9152e-01, time/batch = 18.8945s	
14528/26050 (epoch 27.885), train_loss = 0.72027944, grad/param norm = 1.6087e-01, time/batch = 17.3318s	
14529/26050 (epoch 27.887), train_loss = 0.99998229, grad/param norm = 2.1192e-01, time/batch = 18.3062s	
14530/26050 (epoch 27.889), train_loss = 0.87809921, grad/param norm = 1.8278e-01, time/batch = 15.6276s	
14531/26050 (epoch 27.891), train_loss = 0.76909424, grad/param norm = 1.7355e-01, time/batch = 16.6360s	
14532/26050 (epoch 27.893), train_loss = 0.81964904, grad/param norm = 1.8166e-01, time/batch = 17.4708s	
14533/26050 (epoch 27.894), train_loss = 0.89771241, grad/param norm = 1.9205e-01, time/batch = 18.4009s	
14534/26050 (epoch 27.896), train_loss = 1.02894589, grad/param norm = 2.1186e-01, time/batch = 18.7458s	
14535/26050 (epoch 27.898), train_loss = 0.90485403, grad/param norm = 2.2282e-01, time/batch = 14.5535s	
14536/26050 (epoch 27.900), train_loss = 0.98220533, grad/param norm = 2.0700e-01, time/batch = 17.9735s	
14537/26050 (epoch 27.902), train_loss = 0.93151572, grad/param norm = 2.1334e-01, time/batch = 18.3147s	
14538/26050 (epoch 27.904), train_loss = 0.89618327, grad/param norm = 1.8849e-01, time/batch = 16.3947s	
14539/26050 (epoch 27.906), train_loss = 0.89452170, grad/param norm = 1.9915e-01, time/batch = 16.1807s	
14540/26050 (epoch 27.908), train_loss = 0.93164460, grad/param norm = 1.8766e-01, time/batch = 18.4862s	
14541/26050 (epoch 27.910), train_loss = 0.90832668, grad/param norm = 1.8772e-01, time/batch = 15.3781s	
14542/26050 (epoch 27.912), train_loss = 1.13298908, grad/param norm = 2.2562e-01, time/batch = 17.4881s	
14543/26050 (epoch 27.914), train_loss = 1.29174536, grad/param norm = 2.4999e-01, time/batch = 16.8807s	
14544/26050 (epoch 27.916), train_loss = 1.04115779, grad/param norm = 2.3526e-01, time/batch = 17.3027s	
14545/26050 (epoch 27.917), train_loss = 0.94685183, grad/param norm = 2.1823e-01, time/batch = 17.2432s	
14546/26050 (epoch 27.919), train_loss = 1.00368741, grad/param norm = 2.5938e-01, time/batch = 17.8930s	
14547/26050 (epoch 27.921), train_loss = 0.88924780, grad/param norm = 2.1465e-01, time/batch = 17.9112s	
14548/26050 (epoch 27.923), train_loss = 0.95879712, grad/param norm = 1.9180e-01, time/batch = 18.1622s	
14549/26050 (epoch 27.925), train_loss = 0.94055154, grad/param norm = 1.9363e-01, time/batch = 17.8192s	
14550/26050 (epoch 27.927), train_loss = 0.83918005, grad/param norm = 1.5348e-01, time/batch = 18.5541s	
14551/26050 (epoch 27.929), train_loss = 0.79849802, grad/param norm = 1.7147e-01, time/batch = 18.1578s	
14552/26050 (epoch 27.931), train_loss = 1.11614989, grad/param norm = 2.3822e-01, time/batch = 17.0620s	
14553/26050 (epoch 27.933), train_loss = 0.89560976, grad/param norm = 1.9012e-01, time/batch = 17.4571s	
14554/26050 (epoch 27.935), train_loss = 0.90443321, grad/param norm = 1.8850e-01, time/batch = 15.3646s	
14555/26050 (epoch 27.937), train_loss = 1.02743374, grad/param norm = 1.9867e-01, time/batch = 18.2290s	
14556/26050 (epoch 27.939), train_loss = 0.85556598, grad/param norm = 1.6713e-01, time/batch = 15.8665s	
14557/26050 (epoch 27.940), train_loss = 0.87815327, grad/param norm = 1.6032e-01, time/batch = 15.3094s	
14558/26050 (epoch 27.942), train_loss = 0.92110948, grad/param norm = 1.9485e-01, time/batch = 18.5663s	
14559/26050 (epoch 27.944), train_loss = 0.90343546, grad/param norm = 1.7679e-01, time/batch = 17.2307s	
14560/26050 (epoch 27.946), train_loss = 1.05225006, grad/param norm = 1.9646e-01, time/batch = 18.4035s	
14561/26050 (epoch 27.948), train_loss = 0.79480362, grad/param norm = 1.8394e-01, time/batch = 18.9084s	
14562/26050 (epoch 27.950), train_loss = 0.91282245, grad/param norm = 1.9951e-01, time/batch = 18.4893s	
14563/26050 (epoch 27.952), train_loss = 1.01040310, grad/param norm = 2.3251e-01, time/batch = 18.3047s	
14564/26050 (epoch 27.954), train_loss = 1.01870793, grad/param norm = 1.9744e-01, time/batch = 14.8909s	
14565/26050 (epoch 27.956), train_loss = 0.90970718, grad/param norm = 2.0983e-01, time/batch = 18.3917s	
14566/26050 (epoch 27.958), train_loss = 0.85719185, grad/param norm = 1.7665e-01, time/batch = 16.7379s	
14567/26050 (epoch 27.960), train_loss = 0.96084597, grad/param norm = 1.9580e-01, time/batch = 18.7545s	
14568/26050 (epoch 27.962), train_loss = 0.91466332, grad/param norm = 1.9208e-01, time/batch = 18.4786s	
14569/26050 (epoch 27.964), train_loss = 0.92042484, grad/param norm = 1.7772e-01, time/batch = 16.7966s	
14570/26050 (epoch 27.965), train_loss = 0.85806787, grad/param norm = 1.8236e-01, time/batch = 15.4567s	
14571/26050 (epoch 27.967), train_loss = 1.25778497, grad/param norm = 2.2196e-01, time/batch = 18.8860s	
14572/26050 (epoch 27.969), train_loss = 0.96973741, grad/param norm = 2.0216e-01, time/batch = 17.4977s	
14573/26050 (epoch 27.971), train_loss = 0.90761504, grad/param norm = 1.8335e-01, time/batch = 15.1257s	
14574/26050 (epoch 27.973), train_loss = 0.92445397, grad/param norm = 1.8255e-01, time/batch = 18.4798s	
14575/26050 (epoch 27.975), train_loss = 0.98792847, grad/param norm = 2.2802e-01, time/batch = 18.8153s	
14576/26050 (epoch 27.977), train_loss = 0.95485398, grad/param norm = 1.9403e-01, time/batch = 18.0662s	
14577/26050 (epoch 27.979), train_loss = 0.77003507, grad/param norm = 1.9267e-01, time/batch = 15.1473s	
14578/26050 (epoch 27.981), train_loss = 1.06607085, grad/param norm = 1.9594e-01, time/batch = 18.7376s	
14579/26050 (epoch 27.983), train_loss = 1.01513407, grad/param norm = 2.1112e-01, time/batch = 17.4954s	
14580/26050 (epoch 27.985), train_loss = 0.99025682, grad/param norm = 1.8813e-01, time/batch = 17.7284s	
14581/26050 (epoch 27.987), train_loss = 1.03941858, grad/param norm = 2.1764e-01, time/batch = 17.6267s	
14582/26050 (epoch 27.988), train_loss = 0.98359740, grad/param norm = 1.9429e-01, time/batch = 18.5618s	
14583/26050 (epoch 27.990), train_loss = 0.83200007, grad/param norm = 1.6677e-01, time/batch = 17.8984s	
14584/26050 (epoch 27.992), train_loss = 1.07829313, grad/param norm = 1.9236e-01, time/batch = 15.8898s	
14585/26050 (epoch 27.994), train_loss = 0.91575768, grad/param norm = 2.1948e-01, time/batch = 17.6622s	
14586/26050 (epoch 27.996), train_loss = 0.87342870, grad/param norm = 2.3595e-01, time/batch = 18.6453s	
14587/26050 (epoch 27.998), train_loss = 0.94802831, grad/param norm = 1.8102e-01, time/batch = 16.7258s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
14588/26050 (epoch 28.000), train_loss = 0.89064760, grad/param norm = 2.2127e-01, time/batch = 18.4240s	
14589/26050 (epoch 28.002), train_loss = 1.00624448, grad/param norm = 2.2541e-01, time/batch = 17.8288s	
14590/26050 (epoch 28.004), train_loss = 0.82556884, grad/param norm = 1.8821e-01, time/batch = 16.3171s	
14591/26050 (epoch 28.006), train_loss = 0.88488492, grad/param norm = 2.1243e-01, time/batch = 16.1408s	
14592/26050 (epoch 28.008), train_loss = 0.88304031, grad/param norm = 2.1777e-01, time/batch = 18.1518s	
14593/26050 (epoch 28.010), train_loss = 0.87338972, grad/param norm = 1.9108e-01, time/batch = 17.9771s	
14594/26050 (epoch 28.012), train_loss = 0.93031858, grad/param norm = 1.8992e-01, time/batch = 18.3059s	
14595/26050 (epoch 28.013), train_loss = 1.18936091, grad/param norm = 2.3175e-01, time/batch = 15.6342s	
14596/26050 (epoch 28.015), train_loss = 0.93235435, grad/param norm = 1.8648e-01, time/batch = 17.7213s	
14597/26050 (epoch 28.017), train_loss = 0.95917177, grad/param norm = 1.9200e-01, time/batch = 16.9428s	
14598/26050 (epoch 28.019), train_loss = 0.83935326, grad/param norm = 1.8448e-01, time/batch = 18.9793s	
14599/26050 (epoch 28.021), train_loss = 1.02349255, grad/param norm = 2.0433e-01, time/batch = 18.2432s	
14600/26050 (epoch 28.023), train_loss = 0.77356656, grad/param norm = 1.9512e-01, time/batch = 15.0507s	
14601/26050 (epoch 28.025), train_loss = 0.90694918, grad/param norm = 1.7025e-01, time/batch = 18.3135s	
14602/26050 (epoch 28.027), train_loss = 0.76809941, grad/param norm = 2.0449e-01, time/batch = 18.2469s	
14603/26050 (epoch 28.029), train_loss = 0.95522243, grad/param norm = 1.8635e-01, time/batch = 18.2415s	
14604/26050 (epoch 28.031), train_loss = 1.05190461, grad/param norm = 2.1252e-01, time/batch = 18.3181s	
14605/26050 (epoch 28.033), train_loss = 0.94928203, grad/param norm = 1.9545e-01, time/batch = 18.1471s	
14606/26050 (epoch 28.035), train_loss = 0.95610207, grad/param norm = 1.8359e-01, time/batch = 15.2095s	
14607/26050 (epoch 28.036), train_loss = 0.81138105, grad/param norm = 2.1257e-01, time/batch = 16.0403s	
14608/26050 (epoch 28.038), train_loss = 0.74819698, grad/param norm = 1.7881e-01, time/batch = 17.9915s	
14609/26050 (epoch 28.040), train_loss = 0.91016440, grad/param norm = 1.8783e-01, time/batch = 18.3860s	
14610/26050 (epoch 28.042), train_loss = 0.78718234, grad/param norm = 1.8048e-01, time/batch = 15.2306s	
14611/26050 (epoch 28.044), train_loss = 1.01094324, grad/param norm = 1.8235e-01, time/batch = 16.2494s	
14612/26050 (epoch 28.046), train_loss = 0.75425656, grad/param norm = 1.6619e-01, time/batch = 17.7282s	
14613/26050 (epoch 28.048), train_loss = 0.93720807, grad/param norm = 1.8071e-01, time/batch = 17.9704s	
14614/26050 (epoch 28.050), train_loss = 0.87748868, grad/param norm = 1.8147e-01, time/batch = 17.3959s	
14615/26050 (epoch 28.052), train_loss = 0.85014106, grad/param norm = 2.0251e-01, time/batch = 18.4732s	
14616/26050 (epoch 28.054), train_loss = 0.77439402, grad/param norm = 1.7675e-01, time/batch = 17.8912s	
14617/26050 (epoch 28.056), train_loss = 0.76065872, grad/param norm = 1.7695e-01, time/batch = 17.9854s	
14618/26050 (epoch 28.058), train_loss = 0.90901976, grad/param norm = 1.8182e-01, time/batch = 17.5673s	
14619/26050 (epoch 28.060), train_loss = 0.99004597, grad/param norm = 1.9895e-01, time/batch = 17.2011s	
14620/26050 (epoch 28.061), train_loss = 0.84662292, grad/param norm = 1.8409e-01, time/batch = 18.0832s	
14621/26050 (epoch 28.063), train_loss = 0.94061291, grad/param norm = 1.8480e-01, time/batch = 17.3947s	
14622/26050 (epoch 28.065), train_loss = 0.75738010, grad/param norm = 1.6118e-01, time/batch = 18.7289s	
14623/26050 (epoch 28.067), train_loss = 0.91106304, grad/param norm = 2.1375e-01, time/batch = 18.5632s	
14624/26050 (epoch 28.069), train_loss = 0.96950868, grad/param norm = 2.0250e-01, time/batch = 17.2110s	
14625/26050 (epoch 28.071), train_loss = 0.96536069, grad/param norm = 1.9199e-01, time/batch = 18.2316s	
14626/26050 (epoch 28.073), train_loss = 1.06146185, grad/param norm = 1.9230e-01, time/batch = 18.5737s	
14627/26050 (epoch 28.075), train_loss = 0.86491260, grad/param norm = 1.7978e-01, time/batch = 14.7934s	
14628/26050 (epoch 28.077), train_loss = 0.89127895, grad/param norm = 1.9865e-01, time/batch = 18.2909s	
14629/26050 (epoch 28.079), train_loss = 0.91763383, grad/param norm = 1.9876e-01, time/batch = 16.7127s	
14630/26050 (epoch 28.081), train_loss = 0.90418293, grad/param norm = 1.9461e-01, time/batch = 18.4878s	
14631/26050 (epoch 28.083), train_loss = 1.02509246, grad/param norm = 1.8758e-01, time/batch = 17.7438s	
14632/26050 (epoch 28.084), train_loss = 0.93442597, grad/param norm = 2.3073e-01, time/batch = 18.4141s	
14633/26050 (epoch 28.086), train_loss = 1.08962057, grad/param norm = 2.2414e-01, time/batch = 18.0820s	
14634/26050 (epoch 28.088), train_loss = 0.87956212, grad/param norm = 1.9139e-01, time/batch = 17.9778s	
14635/26050 (epoch 28.090), train_loss = 0.92536680, grad/param norm = 1.9858e-01, time/batch = 16.4656s	
14636/26050 (epoch 28.092), train_loss = 0.97427522, grad/param norm = 1.7172e-01, time/batch = 17.6533s	
14637/26050 (epoch 28.094), train_loss = 0.82424863, grad/param norm = 1.9907e-01, time/batch = 17.4614s	
14638/26050 (epoch 28.096), train_loss = 0.93606641, grad/param norm = 1.8188e-01, time/batch = 17.9625s	
14639/26050 (epoch 28.098), train_loss = 0.87906345, grad/param norm = 1.7907e-01, time/batch = 18.3197s	
14640/26050 (epoch 28.100), train_loss = 0.85156411, grad/param norm = 2.0745e-01, time/batch = 17.9897s	
14641/26050 (epoch 28.102), train_loss = 0.98365481, grad/param norm = 2.1309e-01, time/batch = 15.8066s	
14642/26050 (epoch 28.104), train_loss = 0.89713215, grad/param norm = 1.9516e-01, time/batch = 18.1325s	
14643/26050 (epoch 28.106), train_loss = 0.93137421, grad/param norm = 2.1059e-01, time/batch = 18.1370s	
14644/26050 (epoch 28.107), train_loss = 0.75888713, grad/param norm = 1.8322e-01, time/batch = 17.4779s	
14645/26050 (epoch 28.109), train_loss = 0.85598904, grad/param norm = 2.0240e-01, time/batch = 15.1499s	
14646/26050 (epoch 28.111), train_loss = 1.07871551, grad/param norm = 2.1489e-01, time/batch = 18.7367s	
14647/26050 (epoch 28.113), train_loss = 0.87557012, grad/param norm = 1.9639e-01, time/batch = 17.5768s	
14648/26050 (epoch 28.115), train_loss = 1.01587017, grad/param norm = 2.0951e-01, time/batch = 16.3192s	
14649/26050 (epoch 28.117), train_loss = 0.92287319, grad/param norm = 1.9035e-01, time/batch = 16.4754s	
14650/26050 (epoch 28.119), train_loss = 0.78361093, grad/param norm = 1.8356e-01, time/batch = 18.8039s	
14651/26050 (epoch 28.121), train_loss = 0.93890192, grad/param norm = 1.9217e-01, time/batch = 17.6387s	
14652/26050 (epoch 28.123), train_loss = 0.85208962, grad/param norm = 2.0154e-01, time/batch = 15.2270s	
14653/26050 (epoch 28.125), train_loss = 0.80712807, grad/param norm = 1.7900e-01, time/batch = 18.8979s	
14654/26050 (epoch 28.127), train_loss = 0.76202178, grad/param norm = 1.8024e-01, time/batch = 18.3292s	
14655/26050 (epoch 28.129), train_loss = 0.75663821, grad/param norm = 1.8281e-01, time/batch = 17.9900s	
14656/26050 (epoch 28.131), train_loss = 0.88122719, grad/param norm = 2.0645e-01, time/batch = 18.1612s	
14657/26050 (epoch 28.132), train_loss = 0.88845011, grad/param norm = 1.7414e-01, time/batch = 18.4877s	
14658/26050 (epoch 28.134), train_loss = 0.93893140, grad/param norm = 2.0663e-01, time/batch = 19.1628s	
14659/26050 (epoch 28.136), train_loss = 0.90227628, grad/param norm = 1.8381e-01, time/batch = 33.6018s	
14660/26050 (epoch 28.138), train_loss = 0.69456107, grad/param norm = 1.7546e-01, time/batch = 19.9107s	
14661/26050 (epoch 28.140), train_loss = 0.78161796, grad/param norm = 2.1775e-01, time/batch = 17.1340s	
14662/26050 (epoch 28.142), train_loss = 0.80114094, grad/param norm = 1.8295e-01, time/batch = 18.1440s	
14663/26050 (epoch 28.144), train_loss = 0.73577480, grad/param norm = 2.4699e-01, time/batch = 18.8175s	
14664/26050 (epoch 28.146), train_loss = 0.69960910, grad/param norm = 1.7887e-01, time/batch = 15.0535s	
14665/26050 (epoch 28.148), train_loss = 0.72951382, grad/param norm = 1.6702e-01, time/batch = 18.1444s	
14666/26050 (epoch 28.150), train_loss = 0.87698557, grad/param norm = 2.0695e-01, time/batch = 18.1492s	
14667/26050 (epoch 28.152), train_loss = 1.07941366, grad/param norm = 2.6146e-01, time/batch = 17.0691s	
14668/26050 (epoch 28.154), train_loss = 0.75102359, grad/param norm = 2.1252e-01, time/batch = 17.5822s	
14669/26050 (epoch 28.155), train_loss = 0.77911788, grad/param norm = 1.8440e-01, time/batch = 18.0714s	
14670/26050 (epoch 28.157), train_loss = 0.90675816, grad/param norm = 2.6842e-01, time/batch = 16.7157s	
14671/26050 (epoch 28.159), train_loss = 0.95510143, grad/param norm = 2.2365e-01, time/batch = 18.8219s	
14672/26050 (epoch 28.161), train_loss = 0.92122364, grad/param norm = 1.9423e-01, time/batch = 18.4817s	
14673/26050 (epoch 28.163), train_loss = 0.76290344, grad/param norm = 1.8273e-01, time/batch = 18.5571s	
14674/26050 (epoch 28.165), train_loss = 0.72780826, grad/param norm = 1.8719e-01, time/batch = 17.1299s	
14675/26050 (epoch 28.167), train_loss = 1.03313152, grad/param norm = 2.1887e-01, time/batch = 18.2295s	
14676/26050 (epoch 28.169), train_loss = 0.92293824, grad/param norm = 2.2017e-01, time/batch = 17.9081s	
14677/26050 (epoch 28.171), train_loss = 0.77872015, grad/param norm = 1.7124e-01, time/batch = 17.5585s	
14678/26050 (epoch 28.173), train_loss = 0.88974198, grad/param norm = 1.9667e-01, time/batch = 18.7437s	
14679/26050 (epoch 28.175), train_loss = 0.88346143, grad/param norm = 1.8720e-01, time/batch = 18.5681s	
14680/26050 (epoch 28.177), train_loss = 0.99785884, grad/param norm = 2.0033e-01, time/batch = 15.9840s	
14681/26050 (epoch 28.179), train_loss = 0.66072215, grad/param norm = 1.4975e-01, time/batch = 14.7166s	
14682/26050 (epoch 28.180), train_loss = 1.11192306, grad/param norm = 1.9545e-01, time/batch = 17.7417s	
14683/26050 (epoch 28.182), train_loss = 1.11434221, grad/param norm = 2.2192e-01, time/batch = 18.7232s	
14684/26050 (epoch 28.184), train_loss = 0.94213531, grad/param norm = 1.8165e-01, time/batch = 15.8964s	
14685/26050 (epoch 28.186), train_loss = 0.76213660, grad/param norm = 1.8223e-01, time/batch = 18.2287s	
14686/26050 (epoch 28.188), train_loss = 0.93151960, grad/param norm = 1.9378e-01, time/batch = 18.4863s	
14687/26050 (epoch 28.190), train_loss = 0.95681896, grad/param norm = 2.0953e-01, time/batch = 17.6535s	
14688/26050 (epoch 28.192), train_loss = 0.95593135, grad/param norm = 1.7218e-01, time/batch = 17.0742s	
14689/26050 (epoch 28.194), train_loss = 0.96077353, grad/param norm = 1.9748e-01, time/batch = 18.8198s	
14690/26050 (epoch 28.196), train_loss = 0.97516156, grad/param norm = 1.9531e-01, time/batch = 16.3934s	
14691/26050 (epoch 28.198), train_loss = 0.82645283, grad/param norm = 1.7547e-01, time/batch = 15.8074s	
14692/26050 (epoch 28.200), train_loss = 0.81629129, grad/param norm = 1.8829e-01, time/batch = 18.3994s	
14693/26050 (epoch 28.202), train_loss = 0.91946161, grad/param norm = 1.7756e-01, time/batch = 17.9189s	
14694/26050 (epoch 28.203), train_loss = 1.02372372, grad/param norm = 1.9174e-01, time/batch = 16.2281s	
14695/26050 (epoch 28.205), train_loss = 0.86275065, grad/param norm = 1.8451e-01, time/batch = 18.0529s	
14696/26050 (epoch 28.207), train_loss = 0.83853623, grad/param norm = 1.9755e-01, time/batch = 17.1174s	
14697/26050 (epoch 28.209), train_loss = 0.96343056, grad/param norm = 1.9421e-01, time/batch = 16.4912s	
14698/26050 (epoch 28.211), train_loss = 0.77254229, grad/param norm = 2.0239e-01, time/batch = 16.8085s	
14699/26050 (epoch 28.213), train_loss = 0.93951087, grad/param norm = 2.0198e-01, time/batch = 17.8988s	
14700/26050 (epoch 28.215), train_loss = 0.89145035, grad/param norm = 2.2562e-01, time/batch = 18.7247s	
14701/26050 (epoch 28.217), train_loss = 0.85548963, grad/param norm = 1.7200e-01, time/batch = 17.3973s	
14702/26050 (epoch 28.219), train_loss = 0.88180981, grad/param norm = 1.9735e-01, time/batch = 18.2373s	
14703/26050 (epoch 28.221), train_loss = 0.81028848, grad/param norm = 1.7490e-01, time/batch = 15.3052s	
14704/26050 (epoch 28.223), train_loss = 0.98294493, grad/param norm = 2.1201e-01, time/batch = 18.0588s	
14705/26050 (epoch 28.225), train_loss = 0.83960688, grad/param norm = 2.1239e-01, time/batch = 18.0558s	
14706/26050 (epoch 28.226), train_loss = 0.95818429, grad/param norm = 2.1356e-01, time/batch = 17.9854s	
14707/26050 (epoch 28.228), train_loss = 1.04334245, grad/param norm = 1.9278e-01, time/batch = 18.7221s	
14708/26050 (epoch 28.230), train_loss = 0.94224424, grad/param norm = 2.1015e-01, time/batch = 14.7124s	
14709/26050 (epoch 28.232), train_loss = 1.00075781, grad/param norm = 2.1811e-01, time/batch = 18.4913s	
14710/26050 (epoch 28.234), train_loss = 0.81922170, grad/param norm = 1.9464e-01, time/batch = 18.5708s	
14711/26050 (epoch 28.236), train_loss = 0.98814535, grad/param norm = 2.0037e-01, time/batch = 17.9823s	
14712/26050 (epoch 28.238), train_loss = 0.79302651, grad/param norm = 2.0976e-01, time/batch = 18.8896s	
14713/26050 (epoch 28.240), train_loss = 0.91820131, grad/param norm = 1.9719e-01, time/batch = 17.2258s	
14714/26050 (epoch 28.242), train_loss = 0.89259335, grad/param norm = 1.9448e-01, time/batch = 17.6542s	
14715/26050 (epoch 28.244), train_loss = 0.93939796, grad/param norm = 2.1695e-01, time/batch = 18.2303s	
14716/26050 (epoch 28.246), train_loss = 0.84635989, grad/param norm = 1.9316e-01, time/batch = 15.0563s	
14717/26050 (epoch 28.248), train_loss = 0.91621897, grad/param norm = 1.9135e-01, time/batch = 18.5684s	
14718/26050 (epoch 28.250), train_loss = 0.91707425, grad/param norm = 2.8199e-01, time/batch = 17.4058s	
14719/26050 (epoch 28.251), train_loss = 0.87171098, grad/param norm = 1.8429e-01, time/batch = 18.9062s	
14720/26050 (epoch 28.253), train_loss = 0.81080353, grad/param norm = 1.9009e-01, time/batch = 18.9899s	
14721/26050 (epoch 28.255), train_loss = 1.08657802, grad/param norm = 2.0358e-01, time/batch = 16.8142s	
14722/26050 (epoch 28.257), train_loss = 0.89712233, grad/param norm = 2.2837e-01, time/batch = 18.0515s	
14723/26050 (epoch 28.259), train_loss = 1.01046907, grad/param norm = 2.0107e-01, time/batch = 15.7121s	
14724/26050 (epoch 28.261), train_loss = 0.81205239, grad/param norm = 2.1626e-01, time/batch = 18.4024s	
14725/26050 (epoch 28.263), train_loss = 1.00789095, grad/param norm = 2.2208e-01, time/batch = 16.0596s	
14726/26050 (epoch 28.265), train_loss = 1.05659449, grad/param norm = 2.0145e-01, time/batch = 18.4171s	
14727/26050 (epoch 28.267), train_loss = 1.02496920, grad/param norm = 1.7732e-01, time/batch = 18.7439s	
14728/26050 (epoch 28.269), train_loss = 1.01725385, grad/param norm = 2.1395e-01, time/batch = 16.1335s	
14729/26050 (epoch 28.271), train_loss = 0.95154359, grad/param norm = 2.1261e-01, time/batch = 18.1500s	
14730/26050 (epoch 28.273), train_loss = 0.84941660, grad/param norm = 2.2061e-01, time/batch = 18.7387s	
14731/26050 (epoch 28.274), train_loss = 0.88614804, grad/param norm = 1.7554e-01, time/batch = 18.2295s	
14732/26050 (epoch 28.276), train_loss = 0.88045407, grad/param norm = 1.9755e-01, time/batch = 18.8092s	
14733/26050 (epoch 28.278), train_loss = 1.02086427, grad/param norm = 1.9833e-01, time/batch = 18.4007s	
14734/26050 (epoch 28.280), train_loss = 0.91181156, grad/param norm = 1.9148e-01, time/batch = 17.3952s	
14735/26050 (epoch 28.282), train_loss = 0.96155383, grad/param norm = 1.8816e-01, time/batch = 15.8725s	
14736/26050 (epoch 28.284), train_loss = 0.88587362, grad/param norm = 1.8210e-01, time/batch = 14.5735s	
14737/26050 (epoch 28.286), train_loss = 0.94639991, grad/param norm = 2.0713e-01, time/batch = 18.7339s	
14738/26050 (epoch 28.288), train_loss = 0.79799196, grad/param norm = 2.2439e-01, time/batch = 17.8864s	
14739/26050 (epoch 28.290), train_loss = 0.92971195, grad/param norm = 2.0561e-01, time/batch = 17.3204s	
14740/26050 (epoch 28.292), train_loss = 0.84912082, grad/param norm = 1.8234e-01, time/batch = 18.6533s	
14741/26050 (epoch 28.294), train_loss = 0.91405740, grad/param norm = 2.1027e-01, time/batch = 18.8188s	
14742/26050 (epoch 28.296), train_loss = 1.02156822, grad/param norm = 2.2012e-01, time/batch = 17.1896s	
14743/26050 (epoch 28.298), train_loss = 0.95499697, grad/param norm = 1.7220e-01, time/batch = 18.4885s	
14744/26050 (epoch 28.299), train_loss = 0.76633979, grad/param norm = 1.6986e-01, time/batch = 18.5638s	
14745/26050 (epoch 28.301), train_loss = 0.77821057, grad/param norm = 2.0883e-01, time/batch = 17.3951s	
14746/26050 (epoch 28.303), train_loss = 0.92750437, grad/param norm = 2.3276e-01, time/batch = 15.3157s	
14747/26050 (epoch 28.305), train_loss = 0.75119581, grad/param norm = 1.8729e-01, time/batch = 18.3250s	
14748/26050 (epoch 28.307), train_loss = 0.84935032, grad/param norm = 2.0021e-01, time/batch = 17.0014s	
14749/26050 (epoch 28.309), train_loss = 0.89380136, grad/param norm = 1.9309e-01, time/batch = 18.7494s	
14750/26050 (epoch 28.311), train_loss = 0.98126290, grad/param norm = 2.3626e-01, time/batch = 17.9937s	
14751/26050 (epoch 28.313), train_loss = 0.91076964, grad/param norm = 2.1398e-01, time/batch = 18.3935s	
14752/26050 (epoch 28.315), train_loss = 0.99486111, grad/param norm = 1.9947e-01, time/batch = 15.8955s	
14753/26050 (epoch 28.317), train_loss = 0.94694162, grad/param norm = 2.0752e-01, time/batch = 18.3854s	
14754/26050 (epoch 28.319), train_loss = 0.83655001, grad/param norm = 1.8216e-01, time/batch = 18.7493s	
14755/26050 (epoch 28.321), train_loss = 0.90765278, grad/param norm = 2.1148e-01, time/batch = 14.4607s	
14756/26050 (epoch 28.322), train_loss = 0.96776495, grad/param norm = 1.8322e-01, time/batch = 18.5686s	
14757/26050 (epoch 28.324), train_loss = 0.73665929, grad/param norm = 1.6866e-01, time/batch = 18.6516s	
14758/26050 (epoch 28.326), train_loss = 1.04512636, grad/param norm = 2.0730e-01, time/batch = 18.3217s	
14759/26050 (epoch 28.328), train_loss = 0.93885419, grad/param norm = 1.8057e-01, time/batch = 14.7824s	
14760/26050 (epoch 28.330), train_loss = 0.78789162, grad/param norm = 1.8891e-01, time/batch = 18.9846s	
14761/26050 (epoch 28.332), train_loss = 0.97587794, grad/param norm = 1.9969e-01, time/batch = 18.4871s	
14762/26050 (epoch 28.334), train_loss = 0.84021141, grad/param norm = 1.8096e-01, time/batch = 16.8978s	
14763/26050 (epoch 28.336), train_loss = 0.85660320, grad/param norm = 1.8845e-01, time/batch = 18.7980s	
14764/26050 (epoch 28.338), train_loss = 0.81161036, grad/param norm = 1.8913e-01, time/batch = 18.5595s	
14765/26050 (epoch 28.340), train_loss = 0.97556489, grad/param norm = 1.8981e-01, time/batch = 17.1614s	
14766/26050 (epoch 28.342), train_loss = 1.02098921, grad/param norm = 2.0057e-01, time/batch = 17.9815s	
14767/26050 (epoch 28.344), train_loss = 0.83669855, grad/param norm = 2.0008e-01, time/batch = 15.7742s	
14768/26050 (epoch 28.345), train_loss = 0.90766440, grad/param norm = 2.1155e-01, time/batch = 18.1608s	
14769/26050 (epoch 28.347), train_loss = 1.03949907, grad/param norm = 1.9389e-01, time/batch = 16.4724s	
14770/26050 (epoch 28.349), train_loss = 0.95556356, grad/param norm = 1.9152e-01, time/batch = 17.7207s	
14771/26050 (epoch 28.351), train_loss = 0.95904788, grad/param norm = 1.9915e-01, time/batch = 18.3298s	
14772/26050 (epoch 28.353), train_loss = 0.93006365, grad/param norm = 2.0651e-01, time/batch = 17.8128s	
14773/26050 (epoch 28.355), train_loss = 0.94317802, grad/param norm = 2.2657e-01, time/batch = 18.3203s	
14774/26050 (epoch 28.357), train_loss = 0.86509340, grad/param norm = 1.7815e-01, time/batch = 18.3845s	
14775/26050 (epoch 28.359), train_loss = 1.00189761, grad/param norm = 2.0244e-01, time/batch = 18.2175s	
14776/26050 (epoch 28.361), train_loss = 0.82750616, grad/param norm = 1.7034e-01, time/batch = 18.0541s	
14777/26050 (epoch 28.363), train_loss = 1.00821469, grad/param norm = 2.1119e-01, time/batch = 17.9820s	
14778/26050 (epoch 28.365), train_loss = 0.88051756, grad/param norm = 1.7379e-01, time/batch = 18.5639s	
14779/26050 (epoch 28.367), train_loss = 0.98052885, grad/param norm = 1.8790e-01, time/batch = 17.0370s	
14780/26050 (epoch 28.369), train_loss = 0.83770305, grad/param norm = 1.7241e-01, time/batch = 18.0644s	
14781/26050 (epoch 28.370), train_loss = 0.82833741, grad/param norm = 1.7014e-01, time/batch = 18.3970s	
14782/26050 (epoch 28.372), train_loss = 0.94516583, grad/param norm = 2.0513e-01, time/batch = 14.7739s	
14783/26050 (epoch 28.374), train_loss = 1.04217043, grad/param norm = 1.9784e-01, time/batch = 18.8132s	
14784/26050 (epoch 28.376), train_loss = 1.08212350, grad/param norm = 2.0915e-01, time/batch = 18.0687s	
14785/26050 (epoch 28.378), train_loss = 0.85634900, grad/param norm = 1.7347e-01, time/batch = 18.0652s	
14786/26050 (epoch 28.380), train_loss = 1.06798330, grad/param norm = 2.1873e-01, time/batch = 15.9290s	
14787/26050 (epoch 28.382), train_loss = 1.17083606, grad/param norm = 2.3656e-01, time/batch = 14.0852s	
14788/26050 (epoch 28.384), train_loss = 0.89648929, grad/param norm = 2.2022e-01, time/batch = 14.1651s	
14789/26050 (epoch 28.386), train_loss = 0.98814940, grad/param norm = 2.4188e-01, time/batch = 14.0656s	
14790/26050 (epoch 28.388), train_loss = 0.96014230, grad/param norm = 2.1570e-01, time/batch = 16.1636s	
14791/26050 (epoch 28.390), train_loss = 0.86929523, grad/param norm = 1.7476e-01, time/batch = 14.9522s	
14792/26050 (epoch 28.392), train_loss = 0.81677863, grad/param norm = 1.9376e-01, time/batch = 18.4061s	
14793/26050 (epoch 28.393), train_loss = 0.96118253, grad/param norm = 2.0953e-01, time/batch = 16.5540s	
14794/26050 (epoch 28.395), train_loss = 1.00262433, grad/param norm = 2.0494e-01, time/batch = 17.6394s	
14795/26050 (epoch 28.397), train_loss = 0.99761875, grad/param norm = 2.3429e-01, time/batch = 14.1365s	
14796/26050 (epoch 28.399), train_loss = 0.86273992, grad/param norm = 1.8270e-01, time/batch = 17.8887s	
14797/26050 (epoch 28.401), train_loss = 0.93900537, grad/param norm = 1.9063e-01, time/batch = 17.3066s	
14798/26050 (epoch 28.403), train_loss = 0.94114825, grad/param norm = 2.1682e-01, time/batch = 18.3135s	
14799/26050 (epoch 28.405), train_loss = 0.94073063, grad/param norm = 1.9980e-01, time/batch = 18.6467s	
14800/26050 (epoch 28.407), train_loss = 1.06225607, grad/param norm = 2.1033e-01, time/batch = 16.6578s	
14801/26050 (epoch 28.409), train_loss = 1.06695874, grad/param norm = 2.2144e-01, time/batch = 17.7407s	
14802/26050 (epoch 28.411), train_loss = 0.98525540, grad/param norm = 2.1858e-01, time/batch = 16.5664s	
14803/26050 (epoch 28.413), train_loss = 1.08643938, grad/param norm = 1.9072e-01, time/batch = 18.1381s	
14804/26050 (epoch 28.415), train_loss = 1.10992042, grad/param norm = 3.3486e-01, time/batch = 17.3004s	
14805/26050 (epoch 28.417), train_loss = 1.13004423, grad/param norm = 2.3257e-01, time/batch = 16.8944s	
14806/26050 (epoch 28.418), train_loss = 1.00791071, grad/param norm = 2.2695e-01, time/batch = 18.2242s	
14807/26050 (epoch 28.420), train_loss = 0.81033365, grad/param norm = 1.7209e-01, time/batch = 17.0648s	
14808/26050 (epoch 28.422), train_loss = 0.79287053, grad/param norm = 1.8600e-01, time/batch = 18.2413s	
14809/26050 (epoch 28.424), train_loss = 1.05955511, grad/param norm = 2.1882e-01, time/batch = 16.5615s	
14810/26050 (epoch 28.426), train_loss = 1.02222900, grad/param norm = 2.1489e-01, time/batch = 15.1188s	
14811/26050 (epoch 28.428), train_loss = 0.88658051, grad/param norm = 1.9019e-01, time/batch = 17.8110s	
14812/26050 (epoch 28.430), train_loss = 1.08666837, grad/param norm = 2.1651e-01, time/batch = 17.9915s	
14813/26050 (epoch 28.432), train_loss = 0.91279821, grad/param norm = 2.2131e-01, time/batch = 18.8051s	
14814/26050 (epoch 28.434), train_loss = 0.91896618, grad/param norm = 1.9984e-01, time/batch = 16.4623s	
14815/26050 (epoch 28.436), train_loss = 1.06598579, grad/param norm = 2.1586e-01, time/batch = 17.2465s	
14816/26050 (epoch 28.438), train_loss = 1.01080719, grad/param norm = 2.1892e-01, time/batch = 18.3047s	
14817/26050 (epoch 28.440), train_loss = 0.97214192, grad/param norm = 2.0639e-01, time/batch = 15.7183s	
14818/26050 (epoch 28.441), train_loss = 0.96550952, grad/param norm = 2.2571e-01, time/batch = 18.1678s	
14819/26050 (epoch 28.443), train_loss = 0.79698834, grad/param norm = 1.5884e-01, time/batch = 17.9815s	
14820/26050 (epoch 28.445), train_loss = 0.85313973, grad/param norm = 1.7842e-01, time/batch = 18.4776s	
14821/26050 (epoch 28.447), train_loss = 1.05208327, grad/param norm = 2.0463e-01, time/batch = 17.5744s	
14822/26050 (epoch 28.449), train_loss = 0.86875312, grad/param norm = 1.8709e-01, time/batch = 18.6517s	
14823/26050 (epoch 28.451), train_loss = 1.07664786, grad/param norm = 2.1369e-01, time/batch = 17.2472s	
14824/26050 (epoch 28.453), train_loss = 0.87227769, grad/param norm = 1.6741e-01, time/batch = 16.9746s	
14825/26050 (epoch 28.455), train_loss = 0.93362808, grad/param norm = 1.7826e-01, time/batch = 18.1594s	
14826/26050 (epoch 28.457), train_loss = 0.93261325, grad/param norm = 2.1144e-01, time/batch = 17.7341s	
14827/26050 (epoch 28.459), train_loss = 1.03771418, grad/param norm = 2.0396e-01, time/batch = 16.4681s	
14828/26050 (epoch 28.461), train_loss = 1.04096738, grad/param norm = 2.4288e-01, time/batch = 17.8179s	
14829/26050 (epoch 28.463), train_loss = 0.88945818, grad/param norm = 1.6858e-01, time/batch = 18.3444s	
14830/26050 (epoch 28.464), train_loss = 0.96845409, grad/param norm = 1.9431e-01, time/batch = 18.8197s	
14831/26050 (epoch 28.466), train_loss = 0.97814491, grad/param norm = 2.2513e-01, time/batch = 17.7291s	
14832/26050 (epoch 28.468), train_loss = 1.02740144, grad/param norm = 1.7639e-01, time/batch = 18.3214s	
14833/26050 (epoch 28.470), train_loss = 1.03631247, grad/param norm = 2.2959e-01, time/batch = 15.3705s	
14834/26050 (epoch 28.472), train_loss = 1.06998955, grad/param norm = 2.2410e-01, time/batch = 14.7921s	
14835/26050 (epoch 28.474), train_loss = 1.05812669, grad/param norm = 2.0806e-01, time/batch = 16.9752s	
14836/26050 (epoch 28.476), train_loss = 1.05678265, grad/param norm = 1.9369e-01, time/batch = 17.9023s	
14837/26050 (epoch 28.478), train_loss = 0.91308737, grad/param norm = 1.8654e-01, time/batch = 18.8985s	
14838/26050 (epoch 28.480), train_loss = 0.92907443, grad/param norm = 1.8651e-01, time/batch = 17.3858s	
14839/26050 (epoch 28.482), train_loss = 0.91509585, grad/param norm = 1.9365e-01, time/batch = 18.0641s	
14840/26050 (epoch 28.484), train_loss = 0.88451132, grad/param norm = 1.9308e-01, time/batch = 16.1955s	
14841/26050 (epoch 28.486), train_loss = 1.08641086, grad/param norm = 2.0992e-01, time/batch = 17.8256s	
14842/26050 (epoch 28.488), train_loss = 1.10285352, grad/param norm = 2.1341e-01, time/batch = 17.4912s	
14843/26050 (epoch 28.489), train_loss = 1.12260860, grad/param norm = 2.7985e-01, time/batch = 18.3964s	
14844/26050 (epoch 28.491), train_loss = 0.86499233, grad/param norm = 2.0775e-01, time/batch = 16.6293s	
14845/26050 (epoch 28.493), train_loss = 0.97300216, grad/param norm = 2.1870e-01, time/batch = 16.7197s	
14846/26050 (epoch 28.495), train_loss = 0.92841299, grad/param norm = 1.8919e-01, time/batch = 18.4117s	
14847/26050 (epoch 28.497), train_loss = 0.84325975, grad/param norm = 1.8464e-01, time/batch = 18.5869s	
14848/26050 (epoch 28.499), train_loss = 0.90939172, grad/param norm = 1.9395e-01, time/batch = 17.0663s	
14849/26050 (epoch 28.501), train_loss = 1.02695391, grad/param norm = 2.0455e-01, time/batch = 18.4798s	
14850/26050 (epoch 28.503), train_loss = 0.88200929, grad/param norm = 1.8856e-01, time/batch = 18.6514s	
14851/26050 (epoch 28.505), train_loss = 1.05276707, grad/param norm = 2.0227e-01, time/batch = 17.3073s	
14852/26050 (epoch 28.507), train_loss = 1.01959620, grad/param norm = 2.2223e-01, time/batch = 17.7926s	
14853/26050 (epoch 28.509), train_loss = 1.09513875, grad/param norm = 1.8884e-01, time/batch = 15.6254s	
14854/26050 (epoch 28.511), train_loss = 0.89712377, grad/param norm = 1.6805e-01, time/batch = 18.5640s	
14855/26050 (epoch 28.512), train_loss = 0.83494652, grad/param norm = 2.3070e-01, time/batch = 16.8938s	
14856/26050 (epoch 28.514), train_loss = 1.00311860, grad/param norm = 2.2353e-01, time/batch = 18.2268s	
14857/26050 (epoch 28.516), train_loss = 1.06511660, grad/param norm = 2.0781e-01, time/batch = 17.7336s	
14858/26050 (epoch 28.518), train_loss = 0.91603496, grad/param norm = 1.9763e-01, time/batch = 14.8914s	
14859/26050 (epoch 28.520), train_loss = 0.94056977, grad/param norm = 1.9359e-01, time/batch = 18.0765s	
14860/26050 (epoch 28.522), train_loss = 0.74736858, grad/param norm = 1.7689e-01, time/batch = 18.8224s	
14861/26050 (epoch 28.524), train_loss = 1.04006864, grad/param norm = 2.3595e-01, time/batch = 18.2241s	
14862/26050 (epoch 28.526), train_loss = 1.03601354, grad/param norm = 2.0503e-01, time/batch = 29.4027s	
14863/26050 (epoch 28.528), train_loss = 0.98291285, grad/param norm = 2.0878e-01, time/batch = 27.6093s	
14864/26050 (epoch 28.530), train_loss = 0.90035428, grad/param norm = 2.1984e-01, time/batch = 18.7257s	
14865/26050 (epoch 28.532), train_loss = 0.98614672, grad/param norm = 2.1934e-01, time/batch = 17.4868s	
14866/26050 (epoch 28.534), train_loss = 1.01928628, grad/param norm = 2.3802e-01, time/batch = 17.5457s	
14867/26050 (epoch 28.536), train_loss = 0.95867194, grad/param norm = 1.9179e-01, time/batch = 16.9709s	
14868/26050 (epoch 28.537), train_loss = 1.02515085, grad/param norm = 2.0333e-01, time/batch = 18.4775s	
14869/26050 (epoch 28.539), train_loss = 0.95150069, grad/param norm = 2.0225e-01, time/batch = 18.3980s	
14870/26050 (epoch 28.541), train_loss = 1.12082453, grad/param norm = 2.2126e-01, time/batch = 14.7974s	
14871/26050 (epoch 28.543), train_loss = 0.78908719, grad/param norm = 1.9068e-01, time/batch = 16.7125s	
14872/26050 (epoch 28.545), train_loss = 0.95205285, grad/param norm = 1.8660e-01, time/batch = 18.8842s	
14873/26050 (epoch 28.547), train_loss = 0.92706943, grad/param norm = 2.0303e-01, time/batch = 17.7413s	
14874/26050 (epoch 28.549), train_loss = 0.78848725, grad/param norm = 1.9298e-01, time/batch = 17.3164s	
14875/26050 (epoch 28.551), train_loss = 1.01077764, grad/param norm = 2.0358e-01, time/batch = 18.2370s	
14876/26050 (epoch 28.553), train_loss = 0.87508902, grad/param norm = 1.7983e-01, time/batch = 18.2381s	
14877/26050 (epoch 28.555), train_loss = 0.84515329, grad/param norm = 1.9431e-01, time/batch = 16.4862s	
14878/26050 (epoch 28.557), train_loss = 0.97374775, grad/param norm = 1.9365e-01, time/batch = 17.5773s	
14879/26050 (epoch 28.559), train_loss = 0.95052937, grad/param norm = 2.0265e-01, time/batch = 18.7456s	
14880/26050 (epoch 28.560), train_loss = 0.90322217, grad/param norm = 2.1397e-01, time/batch = 18.3214s	
14881/26050 (epoch 28.562), train_loss = 0.93455332, grad/param norm = 2.1057e-01, time/batch = 17.5555s	
14882/26050 (epoch 28.564), train_loss = 1.10902279, grad/param norm = 1.8987e-01, time/batch = 16.0522s	
14883/26050 (epoch 28.566), train_loss = 0.87021232, grad/param norm = 1.8086e-01, time/batch = 18.6454s	
14884/26050 (epoch 28.568), train_loss = 0.99032361, grad/param norm = 2.0139e-01, time/batch = 17.2370s	
14885/26050 (epoch 28.570), train_loss = 0.96630945, grad/param norm = 2.0277e-01, time/batch = 18.0752s	
14886/26050 (epoch 28.572), train_loss = 0.94496534, grad/param norm = 2.1184e-01, time/batch = 17.8293s	
14887/26050 (epoch 28.574), train_loss = 0.94996438, grad/param norm = 2.2222e-01, time/batch = 17.6338s	
14888/26050 (epoch 28.576), train_loss = 0.99450244, grad/param norm = 2.2069e-01, time/batch = 17.3799s	
14889/26050 (epoch 28.578), train_loss = 0.93727310, grad/param norm = 2.1204e-01, time/batch = 17.5554s	
14890/26050 (epoch 28.580), train_loss = 0.86713270, grad/param norm = 2.0125e-01, time/batch = 18.1644s	
14891/26050 (epoch 28.582), train_loss = 0.95893100, grad/param norm = 1.8834e-01, time/batch = 17.9660s	
14892/26050 (epoch 28.583), train_loss = 1.02887985, grad/param norm = 1.9124e-01, time/batch = 15.6397s	
14893/26050 (epoch 28.585), train_loss = 0.83902969, grad/param norm = 1.9450e-01, time/batch = 15.8139s	
14894/26050 (epoch 28.587), train_loss = 0.96712737, grad/param norm = 1.9730e-01, time/batch = 16.9812s	
14895/26050 (epoch 28.589), train_loss = 1.11375416, grad/param norm = 2.8526e-01, time/batch = 18.8392s	
14896/26050 (epoch 28.591), train_loss = 0.93448601, grad/param norm = 1.8227e-01, time/batch = 18.3248s	
14897/26050 (epoch 28.593), train_loss = 0.82868961, grad/param norm = 1.9002e-01, time/batch = 17.4845s	
14898/26050 (epoch 28.595), train_loss = 1.01472022, grad/param norm = 2.2855e-01, time/batch = 17.8860s	
14899/26050 (epoch 28.597), train_loss = 0.95650854, grad/param norm = 1.9570e-01, time/batch = 18.5313s	
14900/26050 (epoch 28.599), train_loss = 0.97799455, grad/param norm = 2.1209e-01, time/batch = 15.8119s	
14901/26050 (epoch 28.601), train_loss = 1.10970097, grad/param norm = 2.0926e-01, time/batch = 17.4867s	
14902/26050 (epoch 28.603), train_loss = 1.00008894, grad/param norm = 2.1430e-01, time/batch = 18.3002s	
14903/26050 (epoch 28.605), train_loss = 0.91376989, grad/param norm = 2.0468e-01, time/batch = 18.0708s	
14904/26050 (epoch 28.607), train_loss = 1.03874681, grad/param norm = 2.3354e-01, time/batch = 15.2047s	
14905/26050 (epoch 28.608), train_loss = 0.85901805, grad/param norm = 1.8979e-01, time/batch = 18.2070s	
14906/26050 (epoch 28.610), train_loss = 0.95739445, grad/param norm = 2.1246e-01, time/batch = 18.0548s	
14907/26050 (epoch 28.612), train_loss = 0.91477355, grad/param norm = 1.9235e-01, time/batch = 18.7992s	
14908/26050 (epoch 28.614), train_loss = 0.96468828, grad/param norm = 2.0081e-01, time/batch = 17.4731s	
14909/26050 (epoch 28.616), train_loss = 1.03294625, grad/param norm = 2.1469e-01, time/batch = 18.0760s	
14910/26050 (epoch 28.618), train_loss = 0.90028521, grad/param norm = 1.9888e-01, time/batch = 18.1541s	
14911/26050 (epoch 28.620), train_loss = 1.00543767, grad/param norm = 2.1270e-01, time/batch = 16.9810s	
14912/26050 (epoch 28.622), train_loss = 0.83889510, grad/param norm = 1.6608e-01, time/batch = 15.8753s	
14913/26050 (epoch 28.624), train_loss = 0.80779319, grad/param norm = 1.8849e-01, time/batch = 18.5721s	
14914/26050 (epoch 28.626), train_loss = 0.99626883, grad/param norm = 1.9914e-01, time/batch = 17.9072s	
14915/26050 (epoch 28.628), train_loss = 0.88829276, grad/param norm = 2.1370e-01, time/batch = 18.3876s	
14916/26050 (epoch 28.630), train_loss = 1.06954282, grad/param norm = 1.8470e-01, time/batch = 15.6503s	
14917/26050 (epoch 28.631), train_loss = 1.10713154, grad/param norm = 2.0893e-01, time/batch = 17.8094s	
14918/26050 (epoch 28.633), train_loss = 0.85473491, grad/param norm = 1.8539e-01, time/batch = 18.1357s	
14919/26050 (epoch 28.635), train_loss = 0.90137817, grad/param norm = 1.8803e-01, time/batch = 17.9161s	
14920/26050 (epoch 28.637), train_loss = 0.82659613, grad/param norm = 1.8038e-01, time/batch = 18.8236s	
14921/26050 (epoch 28.639), train_loss = 1.01102351, grad/param norm = 1.9003e-01, time/batch = 18.4753s	
14922/26050 (epoch 28.641), train_loss = 0.90072089, grad/param norm = 1.8411e-01, time/batch = 15.4621s	
14923/26050 (epoch 28.643), train_loss = 0.85026702, grad/param norm = 1.5748e-01, time/batch = 17.7116s	
14924/26050 (epoch 28.645), train_loss = 0.89131138, grad/param norm = 1.9727e-01, time/batch = 18.1612s	
14925/26050 (epoch 28.647), train_loss = 0.88082666, grad/param norm = 2.0961e-01, time/batch = 17.4754s	
14926/26050 (epoch 28.649), train_loss = 0.93765189, grad/param norm = 2.0223e-01, time/batch = 17.8284s	
14927/26050 (epoch 28.651), train_loss = 0.88849819, grad/param norm = 2.0584e-01, time/batch = 16.4645s	
14928/26050 (epoch 28.653), train_loss = 0.92115728, grad/param norm = 2.0124e-01, time/batch = 17.1281s	
14929/26050 (epoch 28.655), train_loss = 0.85852245, grad/param norm = 1.9841e-01, time/batch = 18.1487s	
14930/26050 (epoch 28.656), train_loss = 0.81594584, grad/param norm = 1.9199e-01, time/batch = 17.8846s	
14931/26050 (epoch 28.658), train_loss = 1.13107650, grad/param norm = 2.1894e-01, time/batch = 17.5441s	
14932/26050 (epoch 28.660), train_loss = 0.82180106, grad/param norm = 2.3200e-01, time/batch = 14.3464s	
14933/26050 (epoch 28.662), train_loss = 0.94193035, grad/param norm = 2.2025e-01, time/batch = 16.0633s	
14934/26050 (epoch 28.664), train_loss = 0.92047347, grad/param norm = 1.9623e-01, time/batch = 18.1492s	
14935/26050 (epoch 28.666), train_loss = 0.87309666, grad/param norm = 1.9362e-01, time/batch = 17.4744s	
14936/26050 (epoch 28.668), train_loss = 0.74919480, grad/param norm = 2.1738e-01, time/batch = 18.3129s	
14937/26050 (epoch 28.670), train_loss = 1.06820098, grad/param norm = 2.2523e-01, time/batch = 15.3240s	
14938/26050 (epoch 28.672), train_loss = 0.94319106, grad/param norm = 1.9362e-01, time/batch = 17.8756s	
14939/26050 (epoch 28.674), train_loss = 0.83633310, grad/param norm = 1.9774e-01, time/batch = 17.5239s	
14940/26050 (epoch 28.676), train_loss = 0.98615804, grad/param norm = 2.1697e-01, time/batch = 18.3966s	
14941/26050 (epoch 28.678), train_loss = 1.02287971, grad/param norm = 2.1993e-01, time/batch = 16.2179s	
14942/26050 (epoch 28.679), train_loss = 1.07935277, grad/param norm = 2.3429e-01, time/batch = 16.4754s	
14943/26050 (epoch 28.681), train_loss = 0.95521300, grad/param norm = 2.0840e-01, time/batch = 18.0611s	
14944/26050 (epoch 28.683), train_loss = 0.82906608, grad/param norm = 2.7711e-01, time/batch = 18.5676s	
14945/26050 (epoch 28.685), train_loss = 0.91860822, grad/param norm = 1.9713e-01, time/batch = 17.6388s	
14946/26050 (epoch 28.687), train_loss = 0.83464301, grad/param norm = 1.9664e-01, time/batch = 17.7281s	
14947/26050 (epoch 28.689), train_loss = 0.89844305, grad/param norm = 2.0713e-01, time/batch = 17.9764s	
14948/26050 (epoch 28.691), train_loss = 0.74797823, grad/param norm = 1.5660e-01, time/batch = 18.8265s	
14949/26050 (epoch 28.693), train_loss = 0.86781716, grad/param norm = 1.8659e-01, time/batch = 17.3173s	
14950/26050 (epoch 28.695), train_loss = 0.93284972, grad/param norm = 1.9158e-01, time/batch = 17.4866s	
14951/26050 (epoch 28.697), train_loss = 0.85855832, grad/param norm = 1.9343e-01, time/batch = 17.7110s	
14952/26050 (epoch 28.699), train_loss = 0.98793428, grad/param norm = 2.2200e-01, time/batch = 16.6751s	
14953/26050 (epoch 28.701), train_loss = 0.82909302, grad/param norm = 1.6777e-01, time/batch = 17.2085s	
14954/26050 (epoch 28.702), train_loss = 1.02037183, grad/param norm = 2.1056e-01, time/batch = 17.5594s	
14955/26050 (epoch 28.704), train_loss = 1.02083461, grad/param norm = 1.9018e-01, time/batch = 18.0496s	
14956/26050 (epoch 28.706), train_loss = 0.87783595, grad/param norm = 1.9299e-01, time/batch = 18.0755s	
14957/26050 (epoch 28.708), train_loss = 1.02415836, grad/param norm = 2.2308e-01, time/batch = 18.3379s	
14958/26050 (epoch 28.710), train_loss = 0.96284797, grad/param norm = 2.2568e-01, time/batch = 15.2083s	
14959/26050 (epoch 28.712), train_loss = 0.93833075, grad/param norm = 2.0661e-01, time/batch = 17.2521s	
14960/26050 (epoch 28.714), train_loss = 0.82337649, grad/param norm = 1.7189e-01, time/batch = 18.1601s	
14961/26050 (epoch 28.716), train_loss = 1.17818393, grad/param norm = 2.4694e-01, time/batch = 18.3183s	
14962/26050 (epoch 28.718), train_loss = 1.00679702, grad/param norm = 2.1241e-01, time/batch = 14.5400s	
14963/26050 (epoch 28.720), train_loss = 0.91213289, grad/param norm = 1.9016e-01, time/batch = 17.6641s	
14964/26050 (epoch 28.722), train_loss = 0.83237001, grad/param norm = 1.8132e-01, time/batch = 18.0562s	
14965/26050 (epoch 28.724), train_loss = 0.87586108, grad/param norm = 2.0697e-01, time/batch = 16.9632s	
14966/26050 (epoch 28.726), train_loss = 0.98538494, grad/param norm = 2.0554e-01, time/batch = 17.4024s	
14967/26050 (epoch 28.727), train_loss = 0.99209755, grad/param norm = 2.0678e-01, time/batch = 17.8175s	
14968/26050 (epoch 28.729), train_loss = 0.98587297, grad/param norm = 1.9601e-01, time/batch = 18.6567s	
14969/26050 (epoch 28.731), train_loss = 0.97657734, grad/param norm = 1.8762e-01, time/batch = 17.4756s	
14970/26050 (epoch 28.733), train_loss = 0.89842551, grad/param norm = 2.1391e-01, time/batch = 18.8909s	
14971/26050 (epoch 28.735), train_loss = 1.11202763, grad/param norm = 2.2809e-01, time/batch = 18.4168s	
14972/26050 (epoch 28.737), train_loss = 0.88560246, grad/param norm = 1.8876e-01, time/batch = 16.4943s	
14973/26050 (epoch 28.739), train_loss = 0.96531882, grad/param norm = 1.9029e-01, time/batch = 17.4630s	
14974/26050 (epoch 28.741), train_loss = 0.87456690, grad/param norm = 1.9875e-01, time/batch = 18.5773s	
14975/26050 (epoch 28.743), train_loss = 0.95450774, grad/param norm = 2.2261e-01, time/batch = 18.9940s	
14976/26050 (epoch 28.745), train_loss = 0.82465699, grad/param norm = 1.9314e-01, time/batch = 16.1305s	
14977/26050 (epoch 28.747), train_loss = 0.86751254, grad/param norm = 1.8809e-01, time/batch = 17.9986s	
14978/26050 (epoch 28.749), train_loss = 1.02554557, grad/param norm = 2.0717e-01, time/batch = 18.0764s	
14979/26050 (epoch 28.750), train_loss = 0.93681259, grad/param norm = 1.7919e-01, time/batch = 14.5543s	
14980/26050 (epoch 28.752), train_loss = 0.88042523, grad/param norm = 2.2753e-01, time/batch = 14.8157s	
14981/26050 (epoch 28.754), train_loss = 0.94674923, grad/param norm = 1.8713e-01, time/batch = 18.8279s	
14982/26050 (epoch 28.756), train_loss = 0.93974346, grad/param norm = 2.5262e-01, time/batch = 18.4169s	
14983/26050 (epoch 28.758), train_loss = 0.90759915, grad/param norm = 2.0129e-01, time/batch = 17.3971s	
14984/26050 (epoch 28.760), train_loss = 1.08947656, grad/param norm = 2.1572e-01, time/batch = 16.0545s	
14985/26050 (epoch 28.762), train_loss = 0.88995923, grad/param norm = 2.3634e-01, time/batch = 18.3975s	
14986/26050 (epoch 28.764), train_loss = 0.93220288, grad/param norm = 2.2854e-01, time/batch = 17.6386s	
14987/26050 (epoch 28.766), train_loss = 0.96139864, grad/param norm = 2.1689e-01, time/batch = 17.4968s	
14988/26050 (epoch 28.768), train_loss = 0.83227924, grad/param norm = 1.7781e-01, time/batch = 16.9480s	
14989/26050 (epoch 28.770), train_loss = 0.90583009, grad/param norm = 2.0138e-01, time/batch = 18.7338s	
14990/26050 (epoch 28.772), train_loss = 0.92568633, grad/param norm = 1.9058e-01, time/batch = 18.0590s	
14991/26050 (epoch 28.774), train_loss = 0.81494267, grad/param norm = 2.1084e-01, time/batch = 18.1522s	
14992/26050 (epoch 28.775), train_loss = 0.68659239, grad/param norm = 1.9283e-01, time/batch = 18.7360s	
14993/26050 (epoch 28.777), train_loss = 0.89657993, grad/param norm = 1.9623e-01, time/batch = 17.4874s	
14994/26050 (epoch 28.779), train_loss = 0.93193780, grad/param norm = 2.2164e-01, time/batch = 18.3980s	
14995/26050 (epoch 28.781), train_loss = 0.80652162, grad/param norm = 1.8272e-01, time/batch = 17.9782s	
14996/26050 (epoch 28.783), train_loss = 0.80464741, grad/param norm = 1.7771e-01, time/batch = 15.5667s	
14997/26050 (epoch 28.785), train_loss = 0.94461215, grad/param norm = 2.1311e-01, time/batch = 15.0599s	
14998/26050 (epoch 28.787), train_loss = 0.84168382, grad/param norm = 1.9751e-01, time/batch = 18.4634s	
14999/26050 (epoch 28.789), train_loss = 0.86529310, grad/param norm = 2.1423e-01, time/batch = 18.6509s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch28.79_1.8085.t7	
15000/26050 (epoch 28.791), train_loss = 0.85482827, grad/param norm = 1.9122e-01, time/batch = 17.3113s	
15001/26050 (epoch 28.793), train_loss = 1.43552928, grad/param norm = 2.9472e-01, time/batch = 17.7923s	
15002/26050 (epoch 28.795), train_loss = 0.74597847, grad/param norm = 1.5903e-01, time/batch = 18.1592s	
15003/26050 (epoch 28.797), train_loss = 0.81308238, grad/param norm = 1.9143e-01, time/batch = 18.2333s	
15004/26050 (epoch 28.798), train_loss = 0.82937728, grad/param norm = 2.1315e-01, time/batch = 18.2199s	
15005/26050 (epoch 28.800), train_loss = 0.81919084, grad/param norm = 1.8327e-01, time/batch = 18.5812s	
15006/26050 (epoch 28.802), train_loss = 0.88207428, grad/param norm = 1.9359e-01, time/batch = 18.3278s	
15007/26050 (epoch 28.804), train_loss = 0.91644021, grad/param norm = 2.0723e-01, time/batch = 12.6107s	
15008/26050 (epoch 28.806), train_loss = 0.98908727, grad/param norm = 2.2444e-01, time/batch = 0.6779s	
15009/26050 (epoch 28.808), train_loss = 0.92739517, grad/param norm = 2.1017e-01, time/batch = 0.6708s	
15010/26050 (epoch 28.810), train_loss = 0.88623702, grad/param norm = 2.1612e-01, time/batch = 0.6736s	
15011/26050 (epoch 28.812), train_loss = 0.79903015, grad/param norm = 1.9885e-01, time/batch = 0.6601s	
15012/26050 (epoch 28.814), train_loss = 0.85164654, grad/param norm = 2.3929e-01, time/batch = 0.6574s	
15013/26050 (epoch 28.816), train_loss = 0.96369372, grad/param norm = 2.0846e-01, time/batch = 0.6447s	
15014/26050 (epoch 28.818), train_loss = 1.01300359, grad/param norm = 2.4805e-01, time/batch = 0.6416s	
15015/26050 (epoch 28.820), train_loss = 0.94516636, grad/param norm = 2.0403e-01, time/batch = 0.8485s	
15016/26050 (epoch 28.821), train_loss = 1.02849416, grad/param norm = 2.2748e-01, time/batch = 0.9452s	
15017/26050 (epoch 28.823), train_loss = 1.08992031, grad/param norm = 2.0181e-01, time/batch = 0.9422s	
15018/26050 (epoch 28.825), train_loss = 0.94466635, grad/param norm = 2.1298e-01, time/batch = 0.9425s	
15019/26050 (epoch 28.827), train_loss = 0.94599631, grad/param norm = 2.1864e-01, time/batch = 0.9329s	
15020/26050 (epoch 28.829), train_loss = 0.98895119, grad/param norm = 2.0882e-01, time/batch = 1.2381s	
15021/26050 (epoch 28.831), train_loss = 1.05987397, grad/param norm = 2.0332e-01, time/batch = 1.7823s	
15022/26050 (epoch 28.833), train_loss = 1.08128725, grad/param norm = 2.1815e-01, time/batch = 1.7689s	
15023/26050 (epoch 28.835), train_loss = 1.08489267, grad/param norm = 2.2509e-01, time/batch = 11.9516s	
15024/26050 (epoch 28.837), train_loss = 0.91928456, grad/param norm = 1.7591e-01, time/batch = 18.5005s	
15025/26050 (epoch 28.839), train_loss = 0.92395104, grad/param norm = 2.1907e-01, time/batch = 17.2358s	
15026/26050 (epoch 28.841), train_loss = 1.02621849, grad/param norm = 2.0875e-01, time/batch = 17.4850s	
15027/26050 (epoch 28.843), train_loss = 0.90420353, grad/param norm = 1.8323e-01, time/batch = 18.2365s	
15028/26050 (epoch 28.845), train_loss = 0.88613916, grad/param norm = 1.8568e-01, time/batch = 15.8931s	
15029/26050 (epoch 28.846), train_loss = 0.99639283, grad/param norm = 2.0211e-01, time/batch = 17.0577s	
15030/26050 (epoch 28.848), train_loss = 0.89740185, grad/param norm = 1.8790e-01, time/batch = 17.7420s	
15031/26050 (epoch 28.850), train_loss = 0.84383514, grad/param norm = 1.8878e-01, time/batch = 18.7135s	
15032/26050 (epoch 28.852), train_loss = 0.94430277, grad/param norm = 1.8955e-01, time/batch = 17.1508s	
15033/26050 (epoch 28.854), train_loss = 0.92026286, grad/param norm = 2.1300e-01, time/batch = 18.1523s	
15034/26050 (epoch 28.856), train_loss = 0.88171470, grad/param norm = 2.1149e-01, time/batch = 16.7927s	
15035/26050 (epoch 28.858), train_loss = 0.85234518, grad/param norm = 1.9569e-01, time/batch = 15.9648s	
15036/26050 (epoch 28.860), train_loss = 0.97267861, grad/param norm = 2.0948e-01, time/batch = 18.4837s	
15037/26050 (epoch 28.862), train_loss = 1.00206922, grad/param norm = 1.9684e-01, time/batch = 18.6573s	
15038/26050 (epoch 28.864), train_loss = 0.97512660, grad/param norm = 2.4642e-01, time/batch = 18.1629s	
15039/26050 (epoch 28.866), train_loss = 0.88650644, grad/param norm = 1.7426e-01, time/batch = 17.3739s	
15040/26050 (epoch 28.868), train_loss = 0.97604101, grad/param norm = 2.2537e-01, time/batch = 18.3309s	
15041/26050 (epoch 28.869), train_loss = 0.84357873, grad/param norm = 1.9350e-01, time/batch = 17.9146s	
15042/26050 (epoch 28.871), train_loss = 0.78730959, grad/param norm = 1.7735e-01, time/batch = 15.2224s	
15043/26050 (epoch 28.873), train_loss = 0.97045879, grad/param norm = 2.0673e-01, time/batch = 18.4922s	
15044/26050 (epoch 28.875), train_loss = 0.91510385, grad/param norm = 2.0294e-01, time/batch = 18.3170s	
15045/26050 (epoch 28.877), train_loss = 0.85652210, grad/param norm = 1.9192e-01, time/batch = 17.4060s	
15046/26050 (epoch 28.879), train_loss = 0.95017583, grad/param norm = 1.8296e-01, time/batch = 16.3873s	
15047/26050 (epoch 28.881), train_loss = 1.01050098, grad/param norm = 2.2117e-01, time/batch = 17.8297s	
15048/26050 (epoch 28.883), train_loss = 0.96594713, grad/param norm = 1.8773e-01, time/batch = 18.9125s	
15049/26050 (epoch 28.885), train_loss = 0.72194399, grad/param norm = 1.8863e-01, time/batch = 17.1135s	
15050/26050 (epoch 28.887), train_loss = 0.99032800, grad/param norm = 2.1074e-01, time/batch = 18.6455s	
15051/26050 (epoch 28.889), train_loss = 0.87254428, grad/param norm = 1.9493e-01, time/batch = 16.1448s	
15052/26050 (epoch 28.891), train_loss = 0.77288024, grad/param norm = 1.7482e-01, time/batch = 15.9799s	
15053/26050 (epoch 28.893), train_loss = 0.80845182, grad/param norm = 1.8294e-01, time/batch = 18.4079s	
15054/26050 (epoch 28.894), train_loss = 0.88509835, grad/param norm = 1.9048e-01, time/batch = 17.2423s	
15055/26050 (epoch 28.896), train_loss = 1.01565798, grad/param norm = 2.3756e-01, time/batch = 18.9147s	
15056/26050 (epoch 28.898), train_loss = 0.88682340, grad/param norm = 2.1816e-01, time/batch = 17.1282s	
15057/26050 (epoch 28.900), train_loss = 0.98926923, grad/param norm = 2.2623e-01, time/batch = 16.1405s	
15058/26050 (epoch 28.902), train_loss = 0.91139604, grad/param norm = 2.3367e-01, time/batch = 18.0683s	
15059/26050 (epoch 28.904), train_loss = 0.88220907, grad/param norm = 1.8212e-01, time/batch = 17.7450s	
15060/26050 (epoch 28.906), train_loss = 0.89508015, grad/param norm = 2.2199e-01, time/batch = 18.2276s	
15061/26050 (epoch 28.908), train_loss = 0.92753511, grad/param norm = 1.9200e-01, time/batch = 15.2258s	
15062/26050 (epoch 28.910), train_loss = 0.89420761, grad/param norm = 2.1936e-01, time/batch = 18.1377s	
15063/26050 (epoch 28.912), train_loss = 1.11052213, grad/param norm = 2.1580e-01, time/batch = 16.8197s	
15064/26050 (epoch 28.914), train_loss = 1.26961525, grad/param norm = 2.3812e-01, time/batch = 17.9594s	
15065/26050 (epoch 28.916), train_loss = 1.01500180, grad/param norm = 2.0801e-01, time/batch = 17.3148s	
15066/26050 (epoch 28.917), train_loss = 0.93472134, grad/param norm = 2.1634e-01, time/batch = 17.5682s	
15067/26050 (epoch 28.919), train_loss = 0.96121462, grad/param norm = 2.3048e-01, time/batch = 18.4074s	
15068/26050 (epoch 28.921), train_loss = 0.86868012, grad/param norm = 2.1367e-01, time/batch = 17.2926s	
15069/26050 (epoch 28.923), train_loss = 0.94829917, grad/param norm = 1.9923e-01, time/batch = 16.2297s	
15070/26050 (epoch 28.925), train_loss = 0.91675066, grad/param norm = 1.9175e-01, time/batch = 16.6027s	
15071/26050 (epoch 28.927), train_loss = 0.83112667, grad/param norm = 1.5329e-01, time/batch = 18.0550s	
15072/26050 (epoch 28.929), train_loss = 0.79503566, grad/param norm = 1.7742e-01, time/batch = 18.9003s	
15073/26050 (epoch 28.931), train_loss = 1.10341314, grad/param norm = 2.3701e-01, time/batch = 24.1929s	
15074/26050 (epoch 28.933), train_loss = 0.90021814, grad/param norm = 1.8627e-01, time/batch = 30.5990s	
15075/26050 (epoch 28.935), train_loss = 0.88780041, grad/param norm = 1.9269e-01, time/batch = 17.6498s	
15076/26050 (epoch 28.937), train_loss = 1.01587824, grad/param norm = 1.9109e-01, time/batch = 18.6505s	
15077/26050 (epoch 28.939), train_loss = 0.83910349, grad/param norm = 1.6902e-01, time/batch = 18.2523s	
15078/26050 (epoch 28.940), train_loss = 0.88453747, grad/param norm = 1.7678e-01, time/batch = 17.4972s	
15079/26050 (epoch 28.942), train_loss = 0.90560910, grad/param norm = 1.9551e-01, time/batch = 18.4700s	
15080/26050 (epoch 28.944), train_loss = 0.88253974, grad/param norm = 1.7367e-01, time/batch = 17.9762s	
15081/26050 (epoch 28.946), train_loss = 1.04176926, grad/param norm = 1.9943e-01, time/batch = 18.9916s	
15082/26050 (epoch 28.948), train_loss = 0.77789475, grad/param norm = 1.8763e-01, time/batch = 18.6468s	
15083/26050 (epoch 28.950), train_loss = 0.91188255, grad/param norm = 2.1018e-01, time/batch = 15.4817s	
15084/26050 (epoch 28.952), train_loss = 0.98336455, grad/param norm = 2.1048e-01, time/batch = 17.2292s	
15085/26050 (epoch 28.954), train_loss = 1.01700713, grad/param norm = 2.2064e-01, time/batch = 15.2362s	
15086/26050 (epoch 28.956), train_loss = 0.89181787, grad/param norm = 1.9183e-01, time/batch = 14.4568s	
15087/26050 (epoch 28.958), train_loss = 0.83961678, grad/param norm = 1.6650e-01, time/batch = 18.6572s	
15088/26050 (epoch 28.960), train_loss = 0.96773338, grad/param norm = 2.3039e-01, time/batch = 18.1539s	
15089/26050 (epoch 28.962), train_loss = 0.91526208, grad/param norm = 1.9039e-01, time/batch = 17.2285s	
15090/26050 (epoch 28.964), train_loss = 0.92018826, grad/param norm = 1.9436e-01, time/batch = 17.8969s	
15091/26050 (epoch 28.965), train_loss = 0.84178231, grad/param norm = 2.0823e-01, time/batch = 18.8230s	
15092/26050 (epoch 28.967), train_loss = 1.23244001, grad/param norm = 2.1266e-01, time/batch = 17.4032s	
15093/26050 (epoch 28.969), train_loss = 0.95068447, grad/param norm = 2.0357e-01, time/batch = 18.7212s	
15094/26050 (epoch 28.971), train_loss = 0.90186213, grad/param norm = 1.8591e-01, time/batch = 18.3225s	
15095/26050 (epoch 28.973), train_loss = 0.92976723, grad/param norm = 2.0211e-01, time/batch = 15.5575s	
15096/26050 (epoch 28.975), train_loss = 0.96630623, grad/param norm = 2.0896e-01, time/batch = 15.0416s	
15097/26050 (epoch 28.977), train_loss = 0.92837577, grad/param norm = 1.7482e-01, time/batch = 18.2203s	
15098/26050 (epoch 28.979), train_loss = 0.76293657, grad/param norm = 1.9165e-01, time/batch = 17.3846s	
15099/26050 (epoch 28.981), train_loss = 1.04852959, grad/param norm = 2.0409e-01, time/batch = 17.2295s	
15100/26050 (epoch 28.983), train_loss = 0.99656577, grad/param norm = 1.9323e-01, time/batch = 18.2447s	
15101/26050 (epoch 28.985), train_loss = 0.97340895, grad/param norm = 2.0154e-01, time/batch = 18.6515s	
15102/26050 (epoch 28.987), train_loss = 1.01290900, grad/param norm = 1.9316e-01, time/batch = 18.5565s	
15103/26050 (epoch 28.988), train_loss = 0.98245921, grad/param norm = 2.1714e-01, time/batch = 16.5540s	
15104/26050 (epoch 28.990), train_loss = 0.81806304, grad/param norm = 1.6493e-01, time/batch = 16.2806s	
15105/26050 (epoch 28.992), train_loss = 1.08327288, grad/param norm = 2.1778e-01, time/batch = 18.9738s	
15106/26050 (epoch 28.994), train_loss = 0.88519131, grad/param norm = 2.0530e-01, time/batch = 16.9023s	
15107/26050 (epoch 28.996), train_loss = 0.85123733, grad/param norm = 2.0232e-01, time/batch = 18.3256s	
15108/26050 (epoch 28.998), train_loss = 0.92957000, grad/param norm = 1.7730e-01, time/batch = 18.5629s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
15109/26050 (epoch 29.000), train_loss = 0.86800240, grad/param norm = 2.0443e-01, time/batch = 18.0629s	
15110/26050 (epoch 29.002), train_loss = 0.98256947, grad/param norm = 2.1978e-01, time/batch = 17.8097s	
15111/26050 (epoch 29.004), train_loss = 0.82253584, grad/param norm = 1.8776e-01, time/batch = 17.3867s	
15112/26050 (epoch 29.006), train_loss = 0.86943008, grad/param norm = 2.2950e-01, time/batch = 18.3150s	
15113/26050 (epoch 29.008), train_loss = 0.86663132, grad/param norm = 1.8889e-01, time/batch = 17.9970s	
15114/26050 (epoch 29.010), train_loss = 0.84765842, grad/param norm = 1.8329e-01, time/batch = 17.8297s	
15115/26050 (epoch 29.012), train_loss = 0.92295631, grad/param norm = 1.8682e-01, time/batch = 15.1322s	
15116/26050 (epoch 29.013), train_loss = 1.17827900, grad/param norm = 2.3770e-01, time/batch = 17.1426s	
15117/26050 (epoch 29.015), train_loss = 0.91161574, grad/param norm = 1.8763e-01, time/batch = 17.6549s	
15118/26050 (epoch 29.017), train_loss = 0.95751405, grad/param norm = 2.1792e-01, time/batch = 16.3797s	
15119/26050 (epoch 29.019), train_loss = 0.82038306, grad/param norm = 1.7417e-01, time/batch = 18.0601s	
15120/26050 (epoch 29.021), train_loss = 1.01357114, grad/param norm = 1.8816e-01, time/batch = 17.9818s	
15121/26050 (epoch 29.023), train_loss = 0.77075537, grad/param norm = 1.8016e-01, time/batch = 18.4131s	
15122/26050 (epoch 29.025), train_loss = 0.91404956, grad/param norm = 1.8218e-01, time/batch = 18.2272s	
15123/26050 (epoch 29.027), train_loss = 0.75836579, grad/param norm = 1.8780e-01, time/batch = 17.4528s	
15124/26050 (epoch 29.029), train_loss = 0.93454269, grad/param norm = 1.7526e-01, time/batch = 17.3901s	
15125/26050 (epoch 29.031), train_loss = 1.02743419, grad/param norm = 2.1079e-01, time/batch = 16.7394s	
15126/26050 (epoch 29.033), train_loss = 0.94565292, grad/param norm = 1.9747e-01, time/batch = 17.1232s	
15127/26050 (epoch 29.035), train_loss = 0.94921495, grad/param norm = 2.0475e-01, time/batch = 17.8298s	
15128/26050 (epoch 29.036), train_loss = 0.79437967, grad/param norm = 2.0421e-01, time/batch = 18.8987s	
15129/26050 (epoch 29.038), train_loss = 0.74138020, grad/param norm = 1.8511e-01, time/batch = 17.8143s	
15130/26050 (epoch 29.040), train_loss = 0.90083080, grad/param norm = 2.0438e-01, time/batch = 14.8803s	
15131/26050 (epoch 29.042), train_loss = 0.77007213, grad/param norm = 1.7244e-01, time/batch = 16.1355s	
15132/26050 (epoch 29.044), train_loss = 0.98793424, grad/param norm = 1.8396e-01, time/batch = 17.8341s	
15133/26050 (epoch 29.046), train_loss = 0.76085703, grad/param norm = 1.6623e-01, time/batch = 16.6712s	
15134/26050 (epoch 29.048), train_loss = 0.91768345, grad/param norm = 1.8433e-01, time/batch = 18.0767s	
15135/26050 (epoch 29.050), train_loss = 0.87387548, grad/param norm = 1.8898e-01, time/batch = 18.8212s	
15136/26050 (epoch 29.052), train_loss = 0.84401743, grad/param norm = 1.9103e-01, time/batch = 17.7948s	
15137/26050 (epoch 29.054), train_loss = 0.77137616, grad/param norm = 1.8489e-01, time/batch = 17.7357s	
15138/26050 (epoch 29.056), train_loss = 0.74326583, grad/param norm = 1.7035e-01, time/batch = 14.9675s	
15139/26050 (epoch 29.058), train_loss = 0.89479472, grad/param norm = 1.8491e-01, time/batch = 18.6367s	
15140/26050 (epoch 29.060), train_loss = 0.96862669, grad/param norm = 1.9295e-01, time/batch = 16.0666s	
15141/26050 (epoch 29.061), train_loss = 0.81792659, grad/param norm = 1.7238e-01, time/batch = 17.9913s	
15142/26050 (epoch 29.063), train_loss = 0.92587945, grad/param norm = 1.8768e-01, time/batch = 15.2266s	
15143/26050 (epoch 29.065), train_loss = 0.73557906, grad/param norm = 1.4863e-01, time/batch = 16.1214s	
15144/26050 (epoch 29.067), train_loss = 0.90529578, grad/param norm = 1.9781e-01, time/batch = 18.1623s	
15145/26050 (epoch 29.069), train_loss = 0.95838814, grad/param norm = 2.2160e-01, time/batch = 17.3402s	
15146/26050 (epoch 29.071), train_loss = 0.95348657, grad/param norm = 1.8406e-01, time/batch = 18.8313s	
15147/26050 (epoch 29.073), train_loss = 1.06276980, grad/param norm = 2.1188e-01, time/batch = 17.3698s	
15148/26050 (epoch 29.075), train_loss = 0.86136163, grad/param norm = 1.8605e-01, time/batch = 17.8169s	
15149/26050 (epoch 29.077), train_loss = 0.88876389, grad/param norm = 2.4441e-01, time/batch = 17.2289s	
15150/26050 (epoch 29.079), train_loss = 0.90664369, grad/param norm = 2.1327e-01, time/batch = 17.9939s	
15151/26050 (epoch 29.081), train_loss = 0.88359607, grad/param norm = 1.8638e-01, time/batch = 16.1294s	
15152/26050 (epoch 29.083), train_loss = 1.01512592, grad/param norm = 1.8976e-01, time/batch = 17.2476s	
15153/26050 (epoch 29.084), train_loss = 0.94434004, grad/param norm = 3.5307e-01, time/batch = 18.8166s	
15154/26050 (epoch 29.086), train_loss = 1.09360767, grad/param norm = 2.2335e-01, time/batch = 17.4028s	
15155/26050 (epoch 29.088), train_loss = 0.87854998, grad/param norm = 2.0390e-01, time/batch = 15.4832s	
15156/26050 (epoch 29.090), train_loss = 0.91712400, grad/param norm = 2.0357e-01, time/batch = 17.3180s	
15157/26050 (epoch 29.092), train_loss = 0.94794876, grad/param norm = 1.8110e-01, time/batch = 17.6520s	
15158/26050 (epoch 29.094), train_loss = 0.81745105, grad/param norm = 2.0988e-01, time/batch = 17.9079s	
15159/26050 (epoch 29.096), train_loss = 0.93661636, grad/param norm = 1.8613e-01, time/batch = 18.0028s	
15160/26050 (epoch 29.098), train_loss = 0.87682625, grad/param norm = 1.8336e-01, time/batch = 17.7355s	
15161/26050 (epoch 29.100), train_loss = 0.83652797, grad/param norm = 2.0539e-01, time/batch = 18.5622s	
15162/26050 (epoch 29.102), train_loss = 0.96251768, grad/param norm = 1.9743e-01, time/batch = 18.4942s	
15163/26050 (epoch 29.104), train_loss = 0.86856097, grad/param norm = 1.9141e-01, time/batch = 18.4862s	
15164/26050 (epoch 29.106), train_loss = 0.92489569, grad/param norm = 2.2030e-01, time/batch = 17.8111s	
15165/26050 (epoch 29.107), train_loss = 0.76043355, grad/param norm = 1.9158e-01, time/batch = 18.1497s	
15166/26050 (epoch 29.109), train_loss = 0.83895520, grad/param norm = 1.8834e-01, time/batch = 15.1925s	
15167/26050 (epoch 29.111), train_loss = 1.07073945, grad/param norm = 2.1241e-01, time/batch = 14.4700s	
15168/26050 (epoch 29.113), train_loss = 0.88026741, grad/param norm = 2.0015e-01, time/batch = 18.5553s	
15169/26050 (epoch 29.115), train_loss = 1.01213127, grad/param norm = 2.1769e-01, time/batch = 18.3247s	
15170/26050 (epoch 29.117), train_loss = 0.91225159, grad/param norm = 1.9028e-01, time/batch = 18.4856s	
15171/26050 (epoch 29.119), train_loss = 0.76817535, grad/param norm = 1.7723e-01, time/batch = 18.0599s	
15172/26050 (epoch 29.121), train_loss = 0.92680948, grad/param norm = 1.9569e-01, time/batch = 17.3308s	
15173/26050 (epoch 29.123), train_loss = 0.82551739, grad/param norm = 1.9032e-01, time/batch = 16.3161s	
15174/26050 (epoch 29.125), train_loss = 0.78878417, grad/param norm = 1.7449e-01, time/batch = 17.2349s	
15175/26050 (epoch 29.127), train_loss = 0.74572121, grad/param norm = 1.7997e-01, time/batch = 16.6361s	
15176/26050 (epoch 29.129), train_loss = 0.74131916, grad/param norm = 1.8843e-01, time/batch = 18.2260s	
15177/26050 (epoch 29.131), train_loss = 0.87470886, grad/param norm = 1.9781e-01, time/batch = 18.0554s	
15178/26050 (epoch 29.132), train_loss = 0.88457267, grad/param norm = 1.7029e-01, time/batch = 18.8932s	
15179/26050 (epoch 29.134), train_loss = 0.93317630, grad/param norm = 2.2185e-01, time/batch = 18.1313s	
15180/26050 (epoch 29.136), train_loss = 0.89038519, grad/param norm = 1.9162e-01, time/batch = 18.3365s	
15181/26050 (epoch 29.138), train_loss = 0.68327844, grad/param norm = 1.7555e-01, time/batch = 18.3997s	
15182/26050 (epoch 29.140), train_loss = 0.75868469, grad/param norm = 1.8402e-01, time/batch = 18.3187s	
15183/26050 (epoch 29.142), train_loss = 0.79801585, grad/param norm = 1.7812e-01, time/batch = 14.6869s	
15184/26050 (epoch 29.144), train_loss = 0.72095533, grad/param norm = 1.9928e-01, time/batch = 17.6429s	
15185/26050 (epoch 29.146), train_loss = 0.67692953, grad/param norm = 1.8026e-01, time/batch = 18.2340s	
15186/26050 (epoch 29.148), train_loss = 0.72274774, grad/param norm = 1.7532e-01, time/batch = 17.9905s	
15187/26050 (epoch 29.150), train_loss = 0.85665503, grad/param norm = 1.9579e-01, time/batch = 16.3856s	
15188/26050 (epoch 29.152), train_loss = 1.04857759, grad/param norm = 2.3104e-01, time/batch = 18.3771s	
15189/26050 (epoch 29.154), train_loss = 0.72917693, grad/param norm = 2.0864e-01, time/batch = 18.8175s	
15190/26050 (epoch 29.155), train_loss = 0.77870711, grad/param norm = 2.1122e-01, time/batch = 16.9901s	
15191/26050 (epoch 29.157), train_loss = 0.89558493, grad/param norm = 3.0789e-01, time/batch = 16.0596s	
15192/26050 (epoch 29.159), train_loss = 0.93459451, grad/param norm = 2.3150e-01, time/batch = 18.3323s	
15193/26050 (epoch 29.161), train_loss = 0.91121382, grad/param norm = 2.0726e-01, time/batch = 15.4663s	
15194/26050 (epoch 29.163), train_loss = 0.75504213, grad/param norm = 1.9674e-01, time/batch = 17.8255s	
15195/26050 (epoch 29.165), train_loss = 0.72038048, grad/param norm = 2.0812e-01, time/batch = 18.4804s	
15196/26050 (epoch 29.167), train_loss = 1.02325928, grad/param norm = 2.2292e-01, time/batch = 16.9507s	
15197/26050 (epoch 29.169), train_loss = 0.91855444, grad/param norm = 2.1640e-01, time/batch = 17.5402s	
15198/26050 (epoch 29.171), train_loss = 0.77629839, grad/param norm = 1.8156e-01, time/batch = 16.9020s	
15199/26050 (epoch 29.173), train_loss = 0.86730353, grad/param norm = 2.1359e-01, time/batch = 15.9653s	
15200/26050 (epoch 29.175), train_loss = 0.88232182, grad/param norm = 1.9112e-01, time/batch = 14.3824s	
15201/26050 (epoch 29.177), train_loss = 0.99009938, grad/param norm = 2.0111e-01, time/batch = 15.6204s	
15202/26050 (epoch 29.179), train_loss = 0.65936178, grad/param norm = 1.5844e-01, time/batch = 14.2870s	
15203/26050 (epoch 29.180), train_loss = 1.10760051, grad/param norm = 2.0184e-01, time/batch = 14.9791s	
15204/26050 (epoch 29.182), train_loss = 1.10709138, grad/param norm = 2.4929e-01, time/batch = 14.6175s	
15205/26050 (epoch 29.184), train_loss = 0.93193056, grad/param norm = 1.9286e-01, time/batch = 18.2080s	
15206/26050 (epoch 29.186), train_loss = 0.75183872, grad/param norm = 1.7156e-01, time/batch = 18.6395s	
15207/26050 (epoch 29.188), train_loss = 0.91342382, grad/param norm = 1.9652e-01, time/batch = 18.4017s	
15208/26050 (epoch 29.190), train_loss = 0.95615013, grad/param norm = 2.2695e-01, time/batch = 18.0748s	
15209/26050 (epoch 29.192), train_loss = 0.95774020, grad/param norm = 1.9108e-01, time/batch = 16.4019s	
15210/26050 (epoch 29.194), train_loss = 0.93131301, grad/param norm = 1.9517e-01, time/batch = 18.4780s	
15211/26050 (epoch 29.196), train_loss = 0.96088599, grad/param norm = 1.9483e-01, time/batch = 18.3061s	
15212/26050 (epoch 29.198), train_loss = 0.81560902, grad/param norm = 1.7670e-01, time/batch = 17.8223s	
15213/26050 (epoch 29.200), train_loss = 0.83287190, grad/param norm = 2.0437e-01, time/batch = 18.6463s	
15214/26050 (epoch 29.202), train_loss = 0.91229437, grad/param norm = 1.7715e-01, time/batch = 17.9032s	
15215/26050 (epoch 29.203), train_loss = 1.00783871, grad/param norm = 1.8546e-01, time/batch = 15.6396s	
15216/26050 (epoch 29.205), train_loss = 0.86633706, grad/param norm = 1.9843e-01, time/batch = 17.7225s	
15217/26050 (epoch 29.207), train_loss = 0.82445357, grad/param norm = 1.8359e-01, time/batch = 18.0650s	
15218/26050 (epoch 29.209), train_loss = 0.95300421, grad/param norm = 1.7679e-01, time/batch = 18.5713s	
15219/26050 (epoch 29.211), train_loss = 0.76459666, grad/param norm = 1.8994e-01, time/batch = 16.6621s	
15220/26050 (epoch 29.213), train_loss = 0.92397823, grad/param norm = 2.0178e-01, time/batch = 18.3770s	
15221/26050 (epoch 29.215), train_loss = 0.87397136, grad/param norm = 2.0476e-01, time/batch = 19.0741s	
15222/26050 (epoch 29.217), train_loss = 0.85632788, grad/param norm = 1.8196e-01, time/batch = 17.3987s	
15223/26050 (epoch 29.219), train_loss = 0.87745423, grad/param norm = 2.0257e-01, time/batch = 15.8019s	
15224/26050 (epoch 29.221), train_loss = 0.82286669, grad/param norm = 2.1483e-01, time/batch = 17.9935s	
15225/26050 (epoch 29.223), train_loss = 0.99004947, grad/param norm = 2.1684e-01, time/batch = 18.9930s	
15226/26050 (epoch 29.225), train_loss = 0.83048813, grad/param norm = 2.0889e-01, time/batch = 16.8953s	
15227/26050 (epoch 29.226), train_loss = 0.94260739, grad/param norm = 2.0371e-01, time/batch = 16.4666s	
15228/26050 (epoch 29.228), train_loss = 1.04270290, grad/param norm = 1.9317e-01, time/batch = 17.8177s	
15229/26050 (epoch 29.230), train_loss = 0.90817452, grad/param norm = 1.8572e-01, time/batch = 18.0597s	
15230/26050 (epoch 29.232), train_loss = 0.98447414, grad/param norm = 2.2473e-01, time/batch = 17.3578s	
15231/26050 (epoch 29.234), train_loss = 0.80764137, grad/param norm = 1.9688e-01, time/batch = 18.4878s	
15232/26050 (epoch 29.236), train_loss = 0.97806622, grad/param norm = 2.0122e-01, time/batch = 17.3271s	
15233/26050 (epoch 29.238), train_loss = 0.76754168, grad/param norm = 2.0190e-01, time/batch = 15.2333s	
15234/26050 (epoch 29.240), train_loss = 0.91851097, grad/param norm = 1.9877e-01, time/batch = 18.2360s	
15235/26050 (epoch 29.242), train_loss = 0.87903728, grad/param norm = 1.9969e-01, time/batch = 18.2501s	
15236/26050 (epoch 29.244), train_loss = 0.93002785, grad/param norm = 2.2525e-01, time/batch = 17.0796s	
15237/26050 (epoch 29.246), train_loss = 0.84490600, grad/param norm = 1.8654e-01, time/batch = 18.3229s	
15238/26050 (epoch 29.248), train_loss = 0.92012231, grad/param norm = 1.9929e-01, time/batch = 18.5730s	
15239/26050 (epoch 29.250), train_loss = 0.90517909, grad/param norm = 2.2423e-01, time/batch = 18.3256s	
15240/26050 (epoch 29.251), train_loss = 0.86449980, grad/param norm = 1.9434e-01, time/batch = 18.8906s	
15241/26050 (epoch 29.253), train_loss = 0.80422939, grad/param norm = 1.9624e-01, time/batch = 18.5654s	
15242/26050 (epoch 29.255), train_loss = 1.05581165, grad/param norm = 1.9506e-01, time/batch = 15.5511s	
15243/26050 (epoch 29.257), train_loss = 0.89560724, grad/param norm = 2.2372e-01, time/batch = 16.0447s	
15244/26050 (epoch 29.259), train_loss = 1.01017194, grad/param norm = 2.0873e-01, time/batch = 15.9499s	
15245/26050 (epoch 29.261), train_loss = 0.80388872, grad/param norm = 2.0607e-01, time/batch = 18.6780s	
15246/26050 (epoch 29.263), train_loss = 0.99016412, grad/param norm = 2.1237e-01, time/batch = 16.9981s	
15247/26050 (epoch 29.265), train_loss = 1.05510777, grad/param norm = 2.3151e-01, time/batch = 19.0724s	
15248/26050 (epoch 29.267), train_loss = 1.02632786, grad/param norm = 1.9905e-01, time/batch = 18.0754s	
15249/26050 (epoch 29.269), train_loss = 1.00178557, grad/param norm = 2.0456e-01, time/batch = 17.8867s	
15250/26050 (epoch 29.271), train_loss = 0.91421087, grad/param norm = 1.8588e-01, time/batch = 18.6299s	
15251/26050 (epoch 29.273), train_loss = 0.82315423, grad/param norm = 2.1913e-01, time/batch = 16.7977s	
15252/26050 (epoch 29.274), train_loss = 0.87786457, grad/param norm = 1.7832e-01, time/batch = 18.5499s	
15253/26050 (epoch 29.276), train_loss = 0.87293805, grad/param norm = 1.8747e-01, time/batch = 17.8117s	
15254/26050 (epoch 29.278), train_loss = 1.01322511, grad/param norm = 2.0152e-01, time/batch = 17.7340s	
15255/26050 (epoch 29.280), train_loss = 0.90928081, grad/param norm = 1.7839e-01, time/batch = 17.0722s	
15256/26050 (epoch 29.282), train_loss = 0.95795240, grad/param norm = 1.9800e-01, time/batch = 15.7171s	
15257/26050 (epoch 29.284), train_loss = 0.87951683, grad/param norm = 1.8442e-01, time/batch = 18.8126s	
15258/26050 (epoch 29.286), train_loss = 0.93090926, grad/param norm = 2.0175e-01, time/batch = 17.5068s	
15259/26050 (epoch 29.288), train_loss = 0.77321660, grad/param norm = 1.7202e-01, time/batch = 18.3065s	
15260/26050 (epoch 29.290), train_loss = 0.90963956, grad/param norm = 1.9986e-01, time/batch = 17.6321s	
15261/26050 (epoch 29.292), train_loss = 0.84228927, grad/param norm = 1.8491e-01, time/batch = 18.5654s	
15262/26050 (epoch 29.294), train_loss = 0.92115133, grad/param norm = 2.2260e-01, time/batch = 17.8663s	
15263/26050 (epoch 29.296), train_loss = 0.99623177, grad/param norm = 1.9653e-01, time/batch = 15.9958s	
15264/26050 (epoch 29.298), train_loss = 0.93492271, grad/param norm = 1.7632e-01, time/batch = 18.7257s	
15265/26050 (epoch 29.299), train_loss = 0.76138428, grad/param norm = 1.7583e-01, time/batch = 18.3232s	
15266/26050 (epoch 29.301), train_loss = 0.78311441, grad/param norm = 1.9986e-01, time/batch = 17.3915s	
15267/26050 (epoch 29.303), train_loss = 0.91605586, grad/param norm = 2.0633e-01, time/batch = 16.0513s	
15268/26050 (epoch 29.305), train_loss = 0.74602896, grad/param norm = 1.9413e-01, time/batch = 18.2237s	
15269/26050 (epoch 29.307), train_loss = 0.82171485, grad/param norm = 1.9891e-01, time/batch = 17.8845s	
15270/26050 (epoch 29.309), train_loss = 0.89430817, grad/param norm = 2.0314e-01, time/batch = 17.9574s	
15271/26050 (epoch 29.311), train_loss = 0.93933980, grad/param norm = 1.9151e-01, time/batch = 17.9944s	
15272/26050 (epoch 29.313), train_loss = 0.89375391, grad/param norm = 2.0872e-01, time/batch = 17.9102s	
15273/26050 (epoch 29.315), train_loss = 0.98193728, grad/param norm = 1.8768e-01, time/batch = 16.9953s	
15274/26050 (epoch 29.317), train_loss = 0.94328738, grad/param norm = 2.2007e-01, time/batch = 18.8903s	
15275/26050 (epoch 29.319), train_loss = 0.82675889, grad/param norm = 2.0526e-01, time/batch = 16.0559s	
15276/26050 (epoch 29.321), train_loss = 0.87520483, grad/param norm = 1.8685e-01, time/batch = 17.3689s	
15277/26050 (epoch 29.322), train_loss = 0.94900546, grad/param norm = 1.9276e-01, time/batch = 33.3482s	
15278/26050 (epoch 29.324), train_loss = 0.71629335, grad/param norm = 1.7282e-01, time/batch = 20.8868s	
15279/26050 (epoch 29.326), train_loss = 1.01600987, grad/param norm = 2.0121e-01, time/batch = 17.7110s	
15280/26050 (epoch 29.328), train_loss = 0.93210743, grad/param norm = 1.7358e-01, time/batch = 18.9661s	
15281/26050 (epoch 29.330), train_loss = 0.78167892, grad/param norm = 1.8613e-01, time/batch = 18.5786s	
15282/26050 (epoch 29.332), train_loss = 0.95059966, grad/param norm = 1.8517e-01, time/batch = 17.5737s	
15283/26050 (epoch 29.334), train_loss = 0.82231329, grad/param norm = 1.8537e-01, time/batch = 15.2557s	
15284/26050 (epoch 29.336), train_loss = 0.84831153, grad/param norm = 1.7188e-01, time/batch = 17.8165s	
15285/26050 (epoch 29.338), train_loss = 0.79556995, grad/param norm = 1.8167e-01, time/batch = 17.7288s	
15286/26050 (epoch 29.340), train_loss = 0.96490276, grad/param norm = 1.9726e-01, time/batch = 18.8068s	
15287/26050 (epoch 29.342), train_loss = 0.99419348, grad/param norm = 1.9397e-01, time/batch = 18.3271s	
15288/26050 (epoch 29.344), train_loss = 0.82568076, grad/param norm = 2.2845e-01, time/batch = 16.8767s	
15289/26050 (epoch 29.345), train_loss = 0.89108317, grad/param norm = 2.1891e-01, time/batch = 17.5727s	
15290/26050 (epoch 29.347), train_loss = 1.02537817, grad/param norm = 1.9741e-01, time/batch = 17.4985s	
15291/26050 (epoch 29.349), train_loss = 0.94492167, grad/param norm = 1.9141e-01, time/batch = 18.4923s	
15292/26050 (epoch 29.351), train_loss = 0.94797026, grad/param norm = 1.9625e-01, time/batch = 17.4000s	
15293/26050 (epoch 29.353), train_loss = 0.91115146, grad/param norm = 2.0155e-01, time/batch = 18.8926s	
15294/26050 (epoch 29.355), train_loss = 0.92649993, grad/param norm = 2.2418e-01, time/batch = 16.4596s	
15295/26050 (epoch 29.357), train_loss = 0.86087421, grad/param norm = 1.7616e-01, time/batch = 15.5550s	
15296/26050 (epoch 29.359), train_loss = 0.98642808, grad/param norm = 2.1002e-01, time/batch = 18.4780s	
15297/26050 (epoch 29.361), train_loss = 0.81966176, grad/param norm = 1.7438e-01, time/batch = 14.7079s	
15298/26050 (epoch 29.363), train_loss = 0.99242756, grad/param norm = 1.9527e-01, time/batch = 17.8048s	
15299/26050 (epoch 29.365), train_loss = 0.87478395, grad/param norm = 1.8329e-01, time/batch = 17.5500s	
15300/26050 (epoch 29.367), train_loss = 0.97477856, grad/param norm = 1.9119e-01, time/batch = 18.3153s	
15301/26050 (epoch 29.369), train_loss = 0.81442457, grad/param norm = 1.6744e-01, time/batch = 17.5737s	
15302/26050 (epoch 29.370), train_loss = 0.81767922, grad/param norm = 1.7834e-01, time/batch = 17.9925s	
15303/26050 (epoch 29.372), train_loss = 0.91166872, grad/param norm = 2.0059e-01, time/batch = 15.3946s	
15304/26050 (epoch 29.374), train_loss = 1.03058428, grad/param norm = 2.0525e-01, time/batch = 19.1546s	
15305/26050 (epoch 29.376), train_loss = 1.07257098, grad/param norm = 2.1742e-01, time/batch = 18.0719s	
15306/26050 (epoch 29.378), train_loss = 0.85386288, grad/param norm = 1.8016e-01, time/batch = 16.0779s	
15307/26050 (epoch 29.380), train_loss = 1.05735012, grad/param norm = 2.1895e-01, time/batch = 18.8240s	
15308/26050 (epoch 29.382), train_loss = 1.16750184, grad/param norm = 2.5047e-01, time/batch = 18.5685s	
15309/26050 (epoch 29.384), train_loss = 0.88971985, grad/param norm = 2.1385e-01, time/batch = 17.4726s	
15310/26050 (epoch 29.386), train_loss = 0.97196855, grad/param norm = 2.7297e-01, time/batch = 15.9473s	
15311/26050 (epoch 29.388), train_loss = 0.93471018, grad/param norm = 2.0795e-01, time/batch = 15.5810s	
15312/26050 (epoch 29.390), train_loss = 0.87051870, grad/param norm = 1.8456e-01, time/batch = 18.0674s	
15313/26050 (epoch 29.392), train_loss = 0.81335849, grad/param norm = 1.9229e-01, time/batch = 17.3127s	
15314/26050 (epoch 29.393), train_loss = 0.96694793, grad/param norm = 2.3066e-01, time/batch = 17.0631s	
15315/26050 (epoch 29.395), train_loss = 1.00374579, grad/param norm = 2.6837e-01, time/batch = 18.2417s	
15316/26050 (epoch 29.397), train_loss = 0.98115457, grad/param norm = 2.2873e-01, time/batch = 17.4865s	
15317/26050 (epoch 29.399), train_loss = 0.86278506, grad/param norm = 2.0608e-01, time/batch = 18.1519s	
15318/26050 (epoch 29.401), train_loss = 0.93131034, grad/param norm = 1.9797e-01, time/batch = 17.2353s	
15319/26050 (epoch 29.403), train_loss = 0.93564060, grad/param norm = 2.2249e-01, time/batch = 18.3086s	
15320/26050 (epoch 29.405), train_loss = 0.91839849, grad/param norm = 2.1561e-01, time/batch = 17.8168s	
15321/26050 (epoch 29.407), train_loss = 1.05990569, grad/param norm = 2.2430e-01, time/batch = 17.5762s	
15322/26050 (epoch 29.409), train_loss = 1.04258420, grad/param norm = 2.2974e-01, time/batch = 14.9799s	
15323/26050 (epoch 29.411), train_loss = 0.98344684, grad/param norm = 2.1002e-01, time/batch = 15.9843s	
15324/26050 (epoch 29.413), train_loss = 1.08778032, grad/param norm = 1.9662e-01, time/batch = 17.1358s	
15325/26050 (epoch 29.415), train_loss = 1.05901173, grad/param norm = 2.3052e-01, time/batch = 18.1608s	
15326/26050 (epoch 29.417), train_loss = 1.11703343, grad/param norm = 2.4554e-01, time/batch = 17.8989s	
15327/26050 (epoch 29.418), train_loss = 1.00585887, grad/param norm = 2.1835e-01, time/batch = 17.1423s	
15328/26050 (epoch 29.420), train_loss = 0.79843970, grad/param norm = 1.7874e-01, time/batch = 14.9851s	
15329/26050 (epoch 29.422), train_loss = 0.78865074, grad/param norm = 2.0309e-01, time/batch = 17.7411s	
15330/26050 (epoch 29.424), train_loss = 1.03560801, grad/param norm = 2.1088e-01, time/batch = 17.8694s	
15331/26050 (epoch 29.426), train_loss = 1.01824756, grad/param norm = 2.1989e-01, time/batch = 18.8017s	
15332/26050 (epoch 29.428), train_loss = 0.87905675, grad/param norm = 1.9657e-01, time/batch = 18.0747s	
15333/26050 (epoch 29.430), train_loss = 1.07917651, grad/param norm = 2.1687e-01, time/batch = 16.8776s	
15334/26050 (epoch 29.432), train_loss = 0.89207230, grad/param norm = 1.9405e-01, time/batch = 17.6435s	
15335/26050 (epoch 29.434), train_loss = 0.90114142, grad/param norm = 2.1117e-01, time/batch = 17.7455s	
15336/26050 (epoch 29.436), train_loss = 1.04063077, grad/param norm = 2.0906e-01, time/batch = 18.1521s	
15337/26050 (epoch 29.438), train_loss = 0.99019542, grad/param norm = 2.2217e-01, time/batch = 17.7960s	
15338/26050 (epoch 29.440), train_loss = 0.94778968, grad/param norm = 1.8946e-01, time/batch = 18.1385s	
15339/26050 (epoch 29.441), train_loss = 0.93784579, grad/param norm = 1.8818e-01, time/batch = 15.3656s	
15340/26050 (epoch 29.443), train_loss = 0.78357902, grad/param norm = 1.5351e-01, time/batch = 17.5258s	
15341/26050 (epoch 29.445), train_loss = 0.83819310, grad/param norm = 1.7971e-01, time/batch = 18.6491s	
15342/26050 (epoch 29.447), train_loss = 1.03050458, grad/param norm = 2.0941e-01, time/batch = 18.4897s	
15343/26050 (epoch 29.449), train_loss = 0.85409278, grad/param norm = 1.9457e-01, time/batch = 17.6574s	
15344/26050 (epoch 29.451), train_loss = 1.06921918, grad/param norm = 2.0878e-01, time/batch = 17.4799s	
15345/26050 (epoch 29.453), train_loss = 0.86694039, grad/param norm = 1.6848e-01, time/batch = 18.4080s	
15346/26050 (epoch 29.455), train_loss = 0.93144389, grad/param norm = 1.8090e-01, time/batch = 16.3154s	
15347/26050 (epoch 29.457), train_loss = 0.91899993, grad/param norm = 1.8893e-01, time/batch = 17.6159s	
15348/26050 (epoch 29.459), train_loss = 1.04090557, grad/param norm = 2.2173e-01, time/batch = 15.2850s	
15349/26050 (epoch 29.461), train_loss = 1.02331138, grad/param norm = 2.1820e-01, time/batch = 17.9670s	
15350/26050 (epoch 29.463), train_loss = 0.87931375, grad/param norm = 1.6702e-01, time/batch = 17.9779s	
15351/26050 (epoch 29.464), train_loss = 0.96823958, grad/param norm = 1.9739e-01, time/batch = 17.9040s	
15352/26050 (epoch 29.466), train_loss = 0.96330623, grad/param norm = 2.0300e-01, time/batch = 18.4211s	
15353/26050 (epoch 29.468), train_loss = 1.01806753, grad/param norm = 1.8061e-01, time/batch = 18.8118s	
15354/26050 (epoch 29.470), train_loss = 1.03201494, grad/param norm = 2.4359e-01, time/batch = 18.2183s	
15355/26050 (epoch 29.472), train_loss = 1.03409263, grad/param norm = 2.1817e-01, time/batch = 19.0659s	
15356/26050 (epoch 29.474), train_loss = 1.03393247, grad/param norm = 2.0413e-01, time/batch = 17.7403s	
15357/26050 (epoch 29.476), train_loss = 1.04190049, grad/param norm = 1.9767e-01, time/batch = 16.5352s	
15358/26050 (epoch 29.478), train_loss = 0.89262164, grad/param norm = 1.8040e-01, time/batch = 18.0665s	
15359/26050 (epoch 29.480), train_loss = 0.91210568, grad/param norm = 1.8817e-01, time/batch = 18.3382s	
15360/26050 (epoch 29.482), train_loss = 0.88271140, grad/param norm = 1.9245e-01, time/batch = 17.1563s	
15361/26050 (epoch 29.484), train_loss = 0.86441523, grad/param norm = 1.9345e-01, time/batch = 16.0327s	
15362/26050 (epoch 29.486), train_loss = 1.06099972, grad/param norm = 1.9463e-01, time/batch = 19.0629s	
15363/26050 (epoch 29.488), train_loss = 1.09676687, grad/param norm = 2.2931e-01, time/batch = 16.9686s	
15364/26050 (epoch 29.489), train_loss = 1.10595509, grad/param norm = 2.4589e-01, time/batch = 17.4060s	
15365/26050 (epoch 29.491), train_loss = 0.85791664, grad/param norm = 2.1121e-01, time/batch = 16.7133s	
15366/26050 (epoch 29.493), train_loss = 0.96184655, grad/param norm = 2.3608e-01, time/batch = 18.9116s	
15367/26050 (epoch 29.495), train_loss = 0.91362532, grad/param norm = 1.8089e-01, time/batch = 15.2996s	
15368/26050 (epoch 29.497), train_loss = 0.83429703, grad/param norm = 1.8927e-01, time/batch = 18.1405s	
15369/26050 (epoch 29.499), train_loss = 0.90311828, grad/param norm = 2.0096e-01, time/batch = 17.2388s	
15370/26050 (epoch 29.501), train_loss = 1.00894002, grad/param norm = 1.9986e-01, time/batch = 18.4150s	
15371/26050 (epoch 29.503), train_loss = 0.87167806, grad/param norm = 1.9419e-01, time/batch = 17.3871s	
15372/26050 (epoch 29.505), train_loss = 1.04365832, grad/param norm = 2.0410e-01, time/batch = 14.8993s	
15373/26050 (epoch 29.507), train_loss = 1.01479697, grad/param norm = 2.6602e-01, time/batch = 18.3189s	
15374/26050 (epoch 29.509), train_loss = 1.06797927, grad/param norm = 1.8618e-01, time/batch = 17.8118s	
15375/26050 (epoch 29.511), train_loss = 0.89860101, grad/param norm = 1.7594e-01, time/batch = 18.8100s	
15376/26050 (epoch 29.512), train_loss = 0.82777087, grad/param norm = 2.2306e-01, time/batch = 14.3904s	
15377/26050 (epoch 29.514), train_loss = 1.01041242, grad/param norm = 2.5477e-01, time/batch = 18.3075s	
15378/26050 (epoch 29.516), train_loss = 1.07220159, grad/param norm = 2.3430e-01, time/batch = 17.2201s	
15379/26050 (epoch 29.518), train_loss = 0.92456794, grad/param norm = 2.1749e-01, time/batch = 18.3982s	
15380/26050 (epoch 29.520), train_loss = 0.92534271, grad/param norm = 1.9150e-01, time/batch = 17.5783s	
15381/26050 (epoch 29.522), train_loss = 0.74398211, grad/param norm = 1.7930e-01, time/batch = 18.1536s	
15382/26050 (epoch 29.524), train_loss = 1.01013229, grad/param norm = 2.3537e-01, time/batch = 18.2310s	
15383/26050 (epoch 29.526), train_loss = 1.03781489, grad/param norm = 2.9947e-01, time/batch = 18.9935s	
15384/26050 (epoch 29.528), train_loss = 0.96128935, grad/param norm = 1.9972e-01, time/batch = 15.2254s	
15385/26050 (epoch 29.530), train_loss = 0.90472428, grad/param norm = 2.3628e-01, time/batch = 16.5617s	
15386/26050 (epoch 29.532), train_loss = 0.96613811, grad/param norm = 2.0215e-01, time/batch = 17.0530s	
15387/26050 (epoch 29.534), train_loss = 1.01203813, grad/param norm = 2.4568e-01, time/batch = 18.0752s	
15388/26050 (epoch 29.536), train_loss = 0.95737681, grad/param norm = 2.1705e-01, time/batch = 15.8892s	
15389/26050 (epoch 29.537), train_loss = 1.01406854, grad/param norm = 2.1322e-01, time/batch = 17.4847s	
15390/26050 (epoch 29.539), train_loss = 0.92409557, grad/param norm = 2.0003e-01, time/batch = 17.3917s	
15391/26050 (epoch 29.541), train_loss = 1.10366806, grad/param norm = 2.2365e-01, time/batch = 15.8012s	
15392/26050 (epoch 29.543), train_loss = 0.76733582, grad/param norm = 1.9842e-01, time/batch = 17.5850s	
15393/26050 (epoch 29.545), train_loss = 0.94403922, grad/param norm = 1.9627e-01, time/batch = 18.9965s	
15394/26050 (epoch 29.547), train_loss = 0.90486497, grad/param norm = 2.0062e-01, time/batch = 14.9741s	
15395/26050 (epoch 29.549), train_loss = 0.77973947, grad/param norm = 2.0147e-01, time/batch = 17.1351s	
15396/26050 (epoch 29.551), train_loss = 0.99326344, grad/param norm = 2.0376e-01, time/batch = 18.2415s	
15397/26050 (epoch 29.553), train_loss = 0.88239884, grad/param norm = 1.9085e-01, time/batch = 17.9888s	
15398/26050 (epoch 29.555), train_loss = 0.83573940, grad/param norm = 1.9189e-01, time/batch = 17.2408s	
15399/26050 (epoch 29.557), train_loss = 0.95394871, grad/param norm = 1.8860e-01, time/batch = 18.4016s	
15400/26050 (epoch 29.559), train_loss = 0.93939954, grad/param norm = 2.0386e-01, time/batch = 18.1556s	
15401/26050 (epoch 29.560), train_loss = 0.89193850, grad/param norm = 2.0684e-01, time/batch = 17.9971s	
15402/26050 (epoch 29.562), train_loss = 0.90694705, grad/param norm = 2.2811e-01, time/batch = 18.5548s	
15403/26050 (epoch 29.564), train_loss = 1.10364714, grad/param norm = 2.0407e-01, time/batch = 15.8825s	
15404/26050 (epoch 29.566), train_loss = 0.87043813, grad/param norm = 1.9441e-01, time/batch = 17.9032s	
15405/26050 (epoch 29.568), train_loss = 0.96206654, grad/param norm = 1.9365e-01, time/batch = 17.6611s	
15406/26050 (epoch 29.570), train_loss = 0.95912887, grad/param norm = 1.9931e-01, time/batch = 18.3202s	
15407/26050 (epoch 29.572), train_loss = 0.93714496, grad/param norm = 2.0386e-01, time/batch = 15.2294s	
15408/26050 (epoch 29.574), train_loss = 0.94187303, grad/param norm = 2.2720e-01, time/batch = 16.3826s	
15409/26050 (epoch 29.576), train_loss = 0.98015173, grad/param norm = 1.9847e-01, time/batch = 18.4003s	
15410/26050 (epoch 29.578), train_loss = 0.91604446, grad/param norm = 1.9855e-01, time/batch = 14.5542s	
15411/26050 (epoch 29.580), train_loss = 0.86476080, grad/param norm = 2.1228e-01, time/batch = 18.2413s	
15412/26050 (epoch 29.582), train_loss = 0.94924502, grad/param norm = 1.8825e-01, time/batch = 16.3141s	
15413/26050 (epoch 29.583), train_loss = 1.00150868, grad/param norm = 1.9435e-01, time/batch = 15.4731s	
15414/26050 (epoch 29.585), train_loss = 0.82099224, grad/param norm = 1.8808e-01, time/batch = 18.4030s	
15415/26050 (epoch 29.587), train_loss = 0.96961739, grad/param norm = 2.0627e-01, time/batch = 17.6636s	
15416/26050 (epoch 29.589), train_loss = 1.08455484, grad/param norm = 2.3609e-01, time/batch = 18.3279s	
15417/26050 (epoch 29.591), train_loss = 0.92711219, grad/param norm = 1.9681e-01, time/batch = 18.6614s	
15418/26050 (epoch 29.593), train_loss = 0.81849186, grad/param norm = 1.8219e-01, time/batch = 18.0715s	
15419/26050 (epoch 29.595), train_loss = 1.00131779, grad/param norm = 2.1024e-01, time/batch = 18.3093s	
15420/26050 (epoch 29.597), train_loss = 0.95403221, grad/param norm = 2.0439e-01, time/batch = 17.2201s	
15421/26050 (epoch 29.599), train_loss = 0.96618166, grad/param norm = 2.0354e-01, time/batch = 18.4743s	
15422/26050 (epoch 29.601), train_loss = 1.09118492, grad/param norm = 1.9649e-01, time/batch = 15.9595s	
15423/26050 (epoch 29.603), train_loss = 0.98745440, grad/param norm = 2.2162e-01, time/batch = 18.1414s	
15424/26050 (epoch 29.605), train_loss = 0.92906004, grad/param norm = 2.3589e-01, time/batch = 18.4843s	
15425/26050 (epoch 29.607), train_loss = 1.03311068, grad/param norm = 2.3904e-01, time/batch = 17.8063s	
15426/26050 (epoch 29.608), train_loss = 0.83236397, grad/param norm = 1.7281e-01, time/batch = 18.3850s	
15427/26050 (epoch 29.610), train_loss = 0.94429873, grad/param norm = 2.0672e-01, time/batch = 14.4052s	
15428/26050 (epoch 29.612), train_loss = 0.90330687, grad/param norm = 1.9871e-01, time/batch = 18.6540s	
15429/26050 (epoch 29.614), train_loss = 0.94984387, grad/param norm = 1.9540e-01, time/batch = 15.8677s	
15430/26050 (epoch 29.616), train_loss = 1.01204588, grad/param norm = 2.0945e-01, time/batch = 17.9072s	
15431/26050 (epoch 29.618), train_loss = 0.88512999, grad/param norm = 2.0039e-01, time/batch = 19.4042s	
15432/26050 (epoch 29.620), train_loss = 1.00428508, grad/param norm = 2.0837e-01, time/batch = 17.4741s	
15433/26050 (epoch 29.622), train_loss = 0.84415797, grad/param norm = 1.8729e-01, time/batch = 16.1560s	
15434/26050 (epoch 29.624), train_loss = 0.78764547, grad/param norm = 1.7820e-01, time/batch = 18.9021s	
15435/26050 (epoch 29.626), train_loss = 0.98784941, grad/param norm = 2.1042e-01, time/batch = 17.1496s	
15436/26050 (epoch 29.628), train_loss = 0.88622050, grad/param norm = 2.2301e-01, time/batch = 17.2219s	
15437/26050 (epoch 29.630), train_loss = 1.07881459, grad/param norm = 1.9311e-01, time/batch = 18.2310s	
15438/26050 (epoch 29.631), train_loss = 1.08637553, grad/param norm = 2.0890e-01, time/batch = 18.9055s	
15439/26050 (epoch 29.633), train_loss = 0.85136601, grad/param norm = 2.0323e-01, time/batch = 16.6419s	
15440/26050 (epoch 29.635), train_loss = 0.88033556, grad/param norm = 1.7402e-01, time/batch = 16.8056s	
15441/26050 (epoch 29.637), train_loss = 0.82369218, grad/param norm = 1.8650e-01, time/batch = 18.7172s	
15442/26050 (epoch 29.639), train_loss = 1.00343275, grad/param norm = 2.1124e-01, time/batch = 16.6412s	
15443/26050 (epoch 29.641), train_loss = 0.88530009, grad/param norm = 1.9038e-01, time/batch = 14.8642s	
15444/26050 (epoch 29.643), train_loss = 0.85233943, grad/param norm = 1.6712e-01, time/batch = 17.5719s	
15445/26050 (epoch 29.645), train_loss = 0.88339309, grad/param norm = 1.8887e-01, time/batch = 18.8947s	
15446/26050 (epoch 29.647), train_loss = 0.86718829, grad/param norm = 2.0709e-01, time/batch = 16.8103s	
15447/26050 (epoch 29.649), train_loss = 0.89841754, grad/param norm = 1.8980e-01, time/batch = 17.4598s	
15448/26050 (epoch 29.651), train_loss = 0.87742554, grad/param norm = 1.8917e-01, time/batch = 18.4060s	
15449/26050 (epoch 29.653), train_loss = 0.91549081, grad/param norm = 2.2610e-01, time/batch = 17.7056s	
15450/26050 (epoch 29.655), train_loss = 0.84040772, grad/param norm = 1.9563e-01, time/batch = 18.6519s	
15451/26050 (epoch 29.656), train_loss = 0.80949192, grad/param norm = 1.7067e-01, time/batch = 18.1435s	
15452/26050 (epoch 29.658), train_loss = 1.11184427, grad/param norm = 2.0735e-01, time/batch = 18.0547s	
15453/26050 (epoch 29.660), train_loss = 0.80162936, grad/param norm = 1.9510e-01, time/batch = 18.6366s	
15454/26050 (epoch 29.662), train_loss = 0.92326439, grad/param norm = 2.0140e-01, time/batch = 16.5579s	
15455/26050 (epoch 29.664), train_loss = 0.91105349, grad/param norm = 1.8664e-01, time/batch = 18.3023s	
15456/26050 (epoch 29.666), train_loss = 0.87735282, grad/param norm = 2.0600e-01, time/batch = 17.3270s	
15457/26050 (epoch 29.668), train_loss = 0.73437463, grad/param norm = 2.0614e-01, time/batch = 18.8256s	
15458/26050 (epoch 29.670), train_loss = 1.05999884, grad/param norm = 2.4342e-01, time/batch = 18.0734s	
15459/26050 (epoch 29.672), train_loss = 0.92100403, grad/param norm = 1.8763e-01, time/batch = 16.9855s	
15460/26050 (epoch 29.674), train_loss = 0.82302944, grad/param norm = 2.1068e-01, time/batch = 18.0622s	
15461/26050 (epoch 29.676), train_loss = 0.97633408, grad/param norm = 2.0687e-01, time/batch = 18.4895s	
15462/26050 (epoch 29.678), train_loss = 1.01112879, grad/param norm = 2.2262e-01, time/batch = 17.8920s	
15463/26050 (epoch 29.679), train_loss = 1.06500791, grad/param norm = 2.2769e-01, time/batch = 17.3144s	
15464/26050 (epoch 29.681), train_loss = 0.95768495, grad/param norm = 1.9973e-01, time/batch = 14.6405s	
15465/26050 (epoch 29.683), train_loss = 0.81737226, grad/param norm = 2.1650e-01, time/batch = 19.0661s	
15466/26050 (epoch 29.685), train_loss = 0.89528446, grad/param norm = 1.9565e-01, time/batch = 16.2139s	
15467/26050 (epoch 29.687), train_loss = 0.81740629, grad/param norm = 1.8866e-01, time/batch = 18.7301s	
15468/26050 (epoch 29.689), train_loss = 0.87309088, grad/param norm = 2.0374e-01, time/batch = 15.7859s	
15469/26050 (epoch 29.691), train_loss = 0.74921248, grad/param norm = 1.6654e-01, time/batch = 18.3033s	
15470/26050 (epoch 29.693), train_loss = 0.87117812, grad/param norm = 2.0218e-01, time/batch = 17.6367s	
15471/26050 (epoch 29.695), train_loss = 0.91205082, grad/param norm = 1.8537e-01, time/batch = 18.4881s	
15472/26050 (epoch 29.697), train_loss = 0.86071609, grad/param norm = 1.8097e-01, time/batch = 18.7249s	
15473/26050 (epoch 29.699), train_loss = 0.96357122, grad/param norm = 2.1410e-01, time/batch = 17.3909s	
15474/26050 (epoch 29.701), train_loss = 0.83577324, grad/param norm = 1.7799e-01, time/batch = 18.6417s	
15475/26050 (epoch 29.702), train_loss = 1.00985000, grad/param norm = 2.1292e-01, time/batch = 18.2417s	
15476/26050 (epoch 29.704), train_loss = 1.01238763, grad/param norm = 1.9107e-01, time/batch = 17.8077s	
15477/26050 (epoch 29.706), train_loss = 0.86373011, grad/param norm = 2.0954e-01, time/batch = 16.3914s	
15478/26050 (epoch 29.708), train_loss = 1.01112125, grad/param norm = 2.2489e-01, time/batch = 18.6426s	
15479/26050 (epoch 29.710), train_loss = 0.94976675, grad/param norm = 2.3635e-01, time/batch = 18.6467s	
15480/26050 (epoch 29.712), train_loss = 0.93757254, grad/param norm = 1.9973e-01, time/batch = 24.0842s	
15481/26050 (epoch 29.714), train_loss = 0.81161671, grad/param norm = 1.6937e-01, time/batch = 30.3201s	
15482/26050 (epoch 29.716), train_loss = 1.16094688, grad/param norm = 2.2983e-01, time/batch = 16.7947s	
15483/26050 (epoch 29.718), train_loss = 0.98569307, grad/param norm = 2.0234e-01, time/batch = 17.9122s	
15484/26050 (epoch 29.720), train_loss = 0.91710120, grad/param norm = 2.0560e-01, time/batch = 18.4900s	
15485/26050 (epoch 29.722), train_loss = 0.83178995, grad/param norm = 1.9242e-01, time/batch = 16.8251s	
15486/26050 (epoch 29.724), train_loss = 0.86972502, grad/param norm = 2.2623e-01, time/batch = 18.8135s	
15487/26050 (epoch 29.726), train_loss = 0.97238350, grad/param norm = 2.1122e-01, time/batch = 15.5559s	
15488/26050 (epoch 29.727), train_loss = 0.98179574, grad/param norm = 2.2898e-01, time/batch = 17.5520s	
15489/26050 (epoch 29.729), train_loss = 0.95473384, grad/param norm = 2.0043e-01, time/batch = 18.1402s	
15490/26050 (epoch 29.731), train_loss = 0.96398007, grad/param norm = 2.0420e-01, time/batch = 15.2992s	
15491/26050 (epoch 29.733), train_loss = 0.91553213, grad/param norm = 2.6498e-01, time/batch = 18.0679s	
15492/26050 (epoch 29.735), train_loss = 1.08739249, grad/param norm = 2.2161e-01, time/batch = 16.3869s	
15493/26050 (epoch 29.737), train_loss = 0.87374194, grad/param norm = 1.9702e-01, time/batch = 18.1409s	
15494/26050 (epoch 29.739), train_loss = 0.95296997, grad/param norm = 1.9950e-01, time/batch = 17.8899s	
15495/26050 (epoch 29.741), train_loss = 0.86671900, grad/param norm = 1.9760e-01, time/batch = 18.4711s	
15496/26050 (epoch 29.743), train_loss = 0.95600089, grad/param norm = 2.2081e-01, time/batch = 17.0747s	
15497/26050 (epoch 29.745), train_loss = 0.81830015, grad/param norm = 1.9478e-01, time/batch = 18.8185s	
15498/26050 (epoch 29.747), train_loss = 0.85338691, grad/param norm = 2.0199e-01, time/batch = 14.6405s	
15499/26050 (epoch 29.749), train_loss = 1.02815758, grad/param norm = 2.2128e-01, time/batch = 17.2374s	
15500/26050 (epoch 29.750), train_loss = 0.91326872, grad/param norm = 1.6583e-01, time/batch = 17.9636s	
15501/26050 (epoch 29.752), train_loss = 0.87608715, grad/param norm = 2.3186e-01, time/batch = 17.9686s	
15502/26050 (epoch 29.754), train_loss = 0.92700138, grad/param norm = 1.9185e-01, time/batch = 15.5422s	
15503/26050 (epoch 29.756), train_loss = 0.90766720, grad/param norm = 2.1328e-01, time/batch = 17.9535s	
15504/26050 (epoch 29.758), train_loss = 0.90636100, grad/param norm = 2.0365e-01, time/batch = 16.5474s	
15505/26050 (epoch 29.760), train_loss = 1.06099437, grad/param norm = 2.1129e-01, time/batch = 18.0535s	
15506/26050 (epoch 29.762), train_loss = 0.85880024, grad/param norm = 1.8448e-01, time/batch = 17.4798s	
15507/26050 (epoch 29.764), train_loss = 0.90898457, grad/param norm = 2.2885e-01, time/batch = 18.4897s	
15508/26050 (epoch 29.766), train_loss = 0.95137907, grad/param norm = 2.3451e-01, time/batch = 18.9749s	
15509/26050 (epoch 29.768), train_loss = 0.82531745, grad/param norm = 1.8775e-01, time/batch = 17.0834s	
15510/26050 (epoch 29.770), train_loss = 0.89051248, grad/param norm = 2.1450e-01, time/batch = 15.7244s	
15511/26050 (epoch 29.772), train_loss = 0.92274513, grad/param norm = 1.8163e-01, time/batch = 18.1509s	
15512/26050 (epoch 29.774), train_loss = 0.80973999, grad/param norm = 2.1314e-01, time/batch = 18.9945s	
15513/26050 (epoch 29.775), train_loss = 0.65769384, grad/param norm = 1.6103e-01, time/batch = 16.9693s	
15514/26050 (epoch 29.777), train_loss = 0.87395274, grad/param norm = 1.9656e-01, time/batch = 18.4845s	
15515/26050 (epoch 29.779), train_loss = 0.90955853, grad/param norm = 2.0897e-01, time/batch = 17.9539s	
15516/26050 (epoch 29.781), train_loss = 0.80407233, grad/param norm = 1.8268e-01, time/batch = 15.4887s	
15517/26050 (epoch 29.783), train_loss = 0.80889817, grad/param norm = 2.0522e-01, time/batch = 18.9701s	
15518/26050 (epoch 29.785), train_loss = 0.92342911, grad/param norm = 2.0471e-01, time/batch = 17.9805s	
15519/26050 (epoch 29.787), train_loss = 0.83717900, grad/param norm = 2.1097e-01, time/batch = 17.6472s	
15520/26050 (epoch 29.789), train_loss = 0.84733956, grad/param norm = 2.2000e-01, time/batch = 18.0619s	
15521/26050 (epoch 29.791), train_loss = 0.84800213, grad/param norm = 2.2070e-01, time/batch = 17.1583s	
15522/26050 (epoch 29.793), train_loss = 0.92504793, grad/param norm = 2.3328e-01, time/batch = 15.3976s	
15523/26050 (epoch 29.795), train_loss = 0.73972775, grad/param norm = 1.5928e-01, time/batch = 16.5679s	
15524/26050 (epoch 29.797), train_loss = 0.80741083, grad/param norm = 1.9834e-01, time/batch = 17.4058s	
15525/26050 (epoch 29.798), train_loss = 0.80711157, grad/param norm = 1.8842e-01, time/batch = 18.8076s	
15526/26050 (epoch 29.800), train_loss = 0.80656947, grad/param norm = 1.9719e-01, time/batch = 14.9779s	
15527/26050 (epoch 29.802), train_loss = 0.85445844, grad/param norm = 2.0093e-01, time/batch = 18.0589s	
15528/26050 (epoch 29.804), train_loss = 0.87582254, grad/param norm = 1.8778e-01, time/batch = 16.9103s	
15529/26050 (epoch 29.806), train_loss = 0.97911906, grad/param norm = 2.0358e-01, time/batch = 18.8069s	
15530/26050 (epoch 29.808), train_loss = 0.91264632, grad/param norm = 2.1124e-01, time/batch = 16.6147s	
15531/26050 (epoch 29.810), train_loss = 0.87872221, grad/param norm = 2.1206e-01, time/batch = 18.4846s	
15532/26050 (epoch 29.812), train_loss = 0.77643754, grad/param norm = 1.8377e-01, time/batch = 15.5712s	
15533/26050 (epoch 29.814), train_loss = 0.82964999, grad/param norm = 2.0188e-01, time/batch = 17.8856s	
15534/26050 (epoch 29.816), train_loss = 0.96377411, grad/param norm = 2.3413e-01, time/batch = 18.3051s	
15535/26050 (epoch 29.818), train_loss = 1.00703596, grad/param norm = 2.5372e-01, time/batch = 18.3045s	
15536/26050 (epoch 29.820), train_loss = 0.92561628, grad/param norm = 1.9977e-01, time/batch = 16.5673s	
15537/26050 (epoch 29.821), train_loss = 1.02501609, grad/param norm = 2.1179e-01, time/batch = 17.6936s	
15538/26050 (epoch 29.823), train_loss = 1.09086404, grad/param norm = 2.2047e-01, time/batch = 18.1379s	
15539/26050 (epoch 29.825), train_loss = 0.91773999, grad/param norm = 2.1119e-01, time/batch = 18.3231s	
15540/26050 (epoch 29.827), train_loss = 0.93110135, grad/param norm = 2.1732e-01, time/batch = 17.4861s	
15541/26050 (epoch 29.829), train_loss = 0.99070838, grad/param norm = 2.1900e-01, time/batch = 18.8952s	
15542/26050 (epoch 29.831), train_loss = 1.06128659, grad/param norm = 2.2813e-01, time/batch = 17.6572s	
15543/26050 (epoch 29.833), train_loss = 1.05881527, grad/param norm = 2.3157e-01, time/batch = 17.3865s	
15544/26050 (epoch 29.835), train_loss = 1.06265184, grad/param norm = 2.0552e-01, time/batch = 18.4844s	
15545/26050 (epoch 29.837), train_loss = 0.91537754, grad/param norm = 1.8574e-01, time/batch = 18.4867s	
15546/26050 (epoch 29.839), train_loss = 0.91505871, grad/param norm = 2.1537e-01, time/batch = 15.1907s	
15547/26050 (epoch 29.841), train_loss = 1.00594204, grad/param norm = 2.0299e-01, time/batch = 16.6272s	
15548/26050 (epoch 29.843), train_loss = 0.89515987, grad/param norm = 1.7922e-01, time/batch = 18.5616s	
15549/26050 (epoch 29.845), train_loss = 0.87205681, grad/param norm = 1.8308e-01, time/batch = 18.0671s	
15550/26050 (epoch 29.846), train_loss = 0.97958525, grad/param norm = 2.0534e-01, time/batch = 17.3143s	
15551/26050 (epoch 29.848), train_loss = 0.90717139, grad/param norm = 1.9536e-01, time/batch = 18.5662s	
15552/26050 (epoch 29.850), train_loss = 0.83055444, grad/param norm = 1.9066e-01, time/batch = 18.4896s	
15553/26050 (epoch 29.852), train_loss = 0.93261917, grad/param norm = 1.8924e-01, time/batch = 17.3276s	
15554/26050 (epoch 29.854), train_loss = 0.90795096, grad/param norm = 2.0304e-01, time/batch = 15.6458s	
15555/26050 (epoch 29.856), train_loss = 0.88323391, grad/param norm = 2.2245e-01, time/batch = 18.0514s	
15556/26050 (epoch 29.858), train_loss = 0.84068910, grad/param norm = 1.8948e-01, time/batch = 18.7446s	
15557/26050 (epoch 29.860), train_loss = 0.95555176, grad/param norm = 1.9515e-01, time/batch = 17.2472s	
15558/26050 (epoch 29.862), train_loss = 0.99763689, grad/param norm = 2.1206e-01, time/batch = 17.2120s	
15559/26050 (epoch 29.864), train_loss = 0.95245529, grad/param norm = 2.3065e-01, time/batch = 18.4920s	
15560/26050 (epoch 29.866), train_loss = 0.87728659, grad/param norm = 1.7948e-01, time/batch = 17.4756s	
15561/26050 (epoch 29.868), train_loss = 0.96736020, grad/param norm = 2.0191e-01, time/batch = 18.2146s	
15562/26050 (epoch 29.869), train_loss = 0.82727331, grad/param norm = 1.8546e-01, time/batch = 18.3242s	
15563/26050 (epoch 29.871), train_loss = 0.78382591, grad/param norm = 1.9386e-01, time/batch = 18.7186s	
15564/26050 (epoch 29.873), train_loss = 0.96262711, grad/param norm = 2.2679e-01, time/batch = 21.0631s	
15565/26050 (epoch 29.875), train_loss = 0.89394797, grad/param norm = 1.9877e-01, time/batch = 19.0965s	
15566/26050 (epoch 29.877), train_loss = 0.84784288, grad/param norm = 1.8797e-01, time/batch = 20.9255s	
15567/26050 (epoch 29.879), train_loss = 0.93390485, grad/param norm = 1.8105e-01, time/batch = 22.6640s	
15568/26050 (epoch 29.881), train_loss = 1.00122825, grad/param norm = 2.2715e-01, time/batch = 23.6686s	
15569/26050 (epoch 29.883), train_loss = 0.95658936, grad/param norm = 2.0061e-01, time/batch = 21.8468s	
15570/26050 (epoch 29.885), train_loss = 0.70905488, grad/param norm = 1.8632e-01, time/batch = 24.2491s	
15571/26050 (epoch 29.887), train_loss = 0.98442845, grad/param norm = 2.3290e-01, time/batch = 23.4353s	
15572/26050 (epoch 29.889), train_loss = 0.84317428, grad/param norm = 1.8152e-01, time/batch = 24.1369s	
15573/26050 (epoch 29.891), train_loss = 0.76872976, grad/param norm = 1.8930e-01, time/batch = 24.5355s	
15574/26050 (epoch 29.893), train_loss = 0.80522875, grad/param norm = 1.9518e-01, time/batch = 24.0019s	
15575/26050 (epoch 29.894), train_loss = 0.87006112, grad/param norm = 1.9035e-01, time/batch = 24.0088s	
15576/26050 (epoch 29.896), train_loss = 1.01970682, grad/param norm = 2.3022e-01, time/batch = 24.0689s	
15577/26050 (epoch 29.898), train_loss = 0.87104154, grad/param norm = 2.2043e-01, time/batch = 23.3443s	
15578/26050 (epoch 29.900), train_loss = 0.95110672, grad/param norm = 2.0591e-01, time/batch = 24.1737s	
15579/26050 (epoch 29.902), train_loss = 0.89606962, grad/param norm = 1.9907e-01, time/batch = 22.6622s	
15580/26050 (epoch 29.904), train_loss = 0.87335625, grad/param norm = 1.8199e-01, time/batch = 30.4908s	
15581/26050 (epoch 29.906), train_loss = 0.90311064, grad/param norm = 2.5059e-01, time/batch = 14.7893s	
15582/26050 (epoch 29.908), train_loss = 0.92302260, grad/param norm = 1.9636e-01, time/batch = 17.8200s	
15583/26050 (epoch 29.910), train_loss = 0.88146262, grad/param norm = 2.1108e-01, time/batch = 18.5575s	
15584/26050 (epoch 29.912), train_loss = 1.10029877, grad/param norm = 2.3307e-01, time/batch = 16.8850s	
15585/26050 (epoch 29.914), train_loss = 1.25053127, grad/param norm = 2.4514e-01, time/batch = 16.9795s	
15586/26050 (epoch 29.916), train_loss = 1.00518952, grad/param norm = 2.6227e-01, time/batch = 18.4879s	
15587/26050 (epoch 29.917), train_loss = 0.92599279, grad/param norm = 2.1438e-01, time/batch = 18.8108s	
15588/26050 (epoch 29.919), train_loss = 0.95391163, grad/param norm = 2.1971e-01, time/batch = 17.6424s	
15589/26050 (epoch 29.921), train_loss = 0.87566260, grad/param norm = 2.2151e-01, time/batch = 17.5667s	
15590/26050 (epoch 29.923), train_loss = 0.93274343, grad/param norm = 1.8962e-01, time/batch = 15.6652s	
15591/26050 (epoch 29.925), train_loss = 0.90411135, grad/param norm = 1.9167e-01, time/batch = 18.8281s	
15592/26050 (epoch 29.927), train_loss = 0.82662972, grad/param norm = 1.5167e-01, time/batch = 16.6486s	
15593/26050 (epoch 29.929), train_loss = 0.77767287, grad/param norm = 1.7941e-01, time/batch = 18.1390s	
15594/26050 (epoch 29.931), train_loss = 1.10735603, grad/param norm = 2.9536e-01, time/batch = 16.1383s	
15595/26050 (epoch 29.933), train_loss = 0.88936293, grad/param norm = 1.9751e-01, time/batch = 18.2357s	
15596/26050 (epoch 29.935), train_loss = 0.88112506, grad/param norm = 2.0453e-01, time/batch = 17.7375s	
15597/26050 (epoch 29.937), train_loss = 1.00390149, grad/param norm = 2.0837e-01, time/batch = 18.3222s	
15598/26050 (epoch 29.939), train_loss = 0.84568421, grad/param norm = 1.7542e-01, time/batch = 16.3957s	
15599/26050 (epoch 29.940), train_loss = 0.86217362, grad/param norm = 1.8497e-01, time/batch = 15.2058s	
15600/26050 (epoch 29.942), train_loss = 0.89912595, grad/param norm = 2.0177e-01, time/batch = 17.8299s	
15601/26050 (epoch 29.944), train_loss = 0.87646256, grad/param norm = 1.7080e-01, time/batch = 18.7301s	
15602/26050 (epoch 29.946), train_loss = 1.04564984, grad/param norm = 1.9608e-01, time/batch = 15.5441s	
15603/26050 (epoch 29.948), train_loss = 0.77557302, grad/param norm = 2.0166e-01, time/batch = 17.7372s	
15604/26050 (epoch 29.950), train_loss = 0.89301220, grad/param norm = 1.9415e-01, time/batch = 18.4959s	
15605/26050 (epoch 29.952), train_loss = 0.97521550, grad/param norm = 2.0483e-01, time/batch = 18.3255s	
15606/26050 (epoch 29.954), train_loss = 0.98514302, grad/param norm = 2.0150e-01, time/batch = 15.5081s	
15607/26050 (epoch 29.956), train_loss = 0.88098654, grad/param norm = 1.9904e-01, time/batch = 14.8898s	
15608/26050 (epoch 29.958), train_loss = 0.82670730, grad/param norm = 1.7672e-01, time/batch = 14.7965s	
15609/26050 (epoch 29.960), train_loss = 0.94754432, grad/param norm = 2.1065e-01, time/batch = 13.8950s	
15610/26050 (epoch 29.962), train_loss = 0.87521946, grad/param norm = 1.7245e-01, time/batch = 16.3028s	
15611/26050 (epoch 29.964), train_loss = 0.90318882, grad/param norm = 1.9132e-01, time/batch = 18.2508s	
15612/26050 (epoch 29.965), train_loss = 0.83499280, grad/param norm = 1.9085e-01, time/batch = 17.3181s	
15613/26050 (epoch 29.967), train_loss = 1.22055113, grad/param norm = 2.0319e-01, time/batch = 16.3162s	
15614/26050 (epoch 29.969), train_loss = 0.93535494, grad/param norm = 1.9939e-01, time/batch = 18.9082s	
15615/26050 (epoch 29.971), train_loss = 0.89719233, grad/param norm = 2.0040e-01, time/batch = 18.4916s	
15616/26050 (epoch 29.973), train_loss = 0.92898381, grad/param norm = 2.0896e-01, time/batch = 17.9881s	
15617/26050 (epoch 29.975), train_loss = 0.95027263, grad/param norm = 2.0499e-01, time/batch = 18.5675s	
15618/26050 (epoch 29.977), train_loss = 0.91708342, grad/param norm = 1.7203e-01, time/batch = 17.2503s	
15619/26050 (epoch 29.979), train_loss = 0.75412023, grad/param norm = 2.0082e-01, time/batch = 15.0514s	
15620/26050 (epoch 29.981), train_loss = 1.04074062, grad/param norm = 2.0849e-01, time/batch = 16.2115s	
15621/26050 (epoch 29.983), train_loss = 0.99101056, grad/param norm = 2.0384e-01, time/batch = 18.3126s	
15622/26050 (epoch 29.985), train_loss = 0.96226472, grad/param norm = 2.0294e-01, time/batch = 18.1574s	
15623/26050 (epoch 29.987), train_loss = 1.01686238, grad/param norm = 1.9212e-01, time/batch = 15.7131s	
15624/26050 (epoch 29.988), train_loss = 0.95862602, grad/param norm = 2.2474e-01, time/batch = 18.2250s	
15625/26050 (epoch 29.990), train_loss = 0.79987198, grad/param norm = 1.6584e-01, time/batch = 18.4804s	
15626/26050 (epoch 29.992), train_loss = 1.05609292, grad/param norm = 1.9653e-01, time/batch = 18.0794s	
15627/26050 (epoch 29.994), train_loss = 0.86842812, grad/param norm = 2.0636e-01, time/batch = 17.4499s	
15628/26050 (epoch 29.996), train_loss = 0.85509174, grad/param norm = 2.4614e-01, time/batch = 18.8109s	
15629/26050 (epoch 29.998), train_loss = 0.92936585, grad/param norm = 1.8594e-01, time/batch = 17.4979s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
15630/26050 (epoch 30.000), train_loss = 0.86030617, grad/param norm = 2.0445e-01, time/batch = 17.3139s	
15631/26050 (epoch 30.002), train_loss = 0.96278609, grad/param norm = 2.1859e-01, time/batch = 16.9809s	
15632/26050 (epoch 30.004), train_loss = 0.81516915, grad/param norm = 1.9627e-01, time/batch = 18.6350s	
15633/26050 (epoch 30.006), train_loss = 0.86084404, grad/param norm = 2.1519e-01, time/batch = 15.7134s	
15634/26050 (epoch 30.008), train_loss = 0.85150570, grad/param norm = 2.0826e-01, time/batch = 17.4150s	
15635/26050 (epoch 30.010), train_loss = 0.83581271, grad/param norm = 1.9539e-01, time/batch = 18.0667s	
15636/26050 (epoch 30.012), train_loss = 0.91291400, grad/param norm = 1.8838e-01, time/batch = 16.8895s	
15637/26050 (epoch 30.013), train_loss = 1.16260112, grad/param norm = 2.5301e-01, time/batch = 16.9886s	
15638/26050 (epoch 30.015), train_loss = 0.90217373, grad/param norm = 1.8559e-01, time/batch = 18.8117s	
15639/26050 (epoch 30.017), train_loss = 0.94006719, grad/param norm = 1.9130e-01, time/batch = 14.7392s	
15640/26050 (epoch 30.019), train_loss = 0.80652389, grad/param norm = 1.7470e-01, time/batch = 17.8895s	
15641/26050 (epoch 30.021), train_loss = 1.00024084, grad/param norm = 1.9553e-01, time/batch = 17.8827s	
15642/26050 (epoch 30.023), train_loss = 0.75072445, grad/param norm = 1.9715e-01, time/batch = 18.9086s	
15643/26050 (epoch 30.025), train_loss = 0.88996203, grad/param norm = 1.8108e-01, time/batch = 17.8230s	
15644/26050 (epoch 30.027), train_loss = 0.73925870, grad/param norm = 1.9752e-01, time/batch = 8.8454s	
15645/26050 (epoch 30.029), train_loss = 0.92964888, grad/param norm = 1.9377e-01, time/batch = 0.6678s	
15646/26050 (epoch 30.031), train_loss = 1.02832638, grad/param norm = 2.2141e-01, time/batch = 0.6673s	
15647/26050 (epoch 30.033), train_loss = 0.93803455, grad/param norm = 2.0261e-01, time/batch = 0.6671s	
15648/26050 (epoch 30.035), train_loss = 0.93930654, grad/param norm = 1.9321e-01, time/batch = 0.6551s	
15649/26050 (epoch 30.036), train_loss = 0.78556152, grad/param norm = 2.1040e-01, time/batch = 0.6573s	
15650/26050 (epoch 30.038), train_loss = 0.72919628, grad/param norm = 1.7660e-01, time/batch = 0.6529s	
15651/26050 (epoch 30.040), train_loss = 0.89120109, grad/param norm = 2.0368e-01, time/batch = 0.6480s	
15652/26050 (epoch 30.042), train_loss = 0.77052436, grad/param norm = 1.8848e-01, time/batch = 0.9394s	
15653/26050 (epoch 30.044), train_loss = 0.97724975, grad/param norm = 1.8489e-01, time/batch = 0.9655s	
15654/26050 (epoch 30.046), train_loss = 0.74314996, grad/param norm = 1.6542e-01, time/batch = 0.9642s	
15655/26050 (epoch 30.048), train_loss = 0.90290574, grad/param norm = 1.8822e-01, time/batch = 0.9412s	
15656/26050 (epoch 30.050), train_loss = 0.86353020, grad/param norm = 1.8861e-01, time/batch = 0.9512s	
15657/26050 (epoch 30.052), train_loss = 0.82731096, grad/param norm = 2.1997e-01, time/batch = 1.5457s	
15658/26050 (epoch 30.054), train_loss = 0.75181240, grad/param norm = 1.7595e-01, time/batch = 1.7631s	
15659/26050 (epoch 30.056), train_loss = 0.74390075, grad/param norm = 1.7433e-01, time/batch = 1.7941s	
15660/26050 (epoch 30.058), train_loss = 0.88393520, grad/param norm = 1.8475e-01, time/batch = 17.1281s	
15661/26050 (epoch 30.060), train_loss = 0.95231916, grad/param norm = 1.9572e-01, time/batch = 18.5717s	
15662/26050 (epoch 30.061), train_loss = 0.80605762, grad/param norm = 1.7802e-01, time/batch = 16.6910s	
15663/26050 (epoch 30.063), train_loss = 0.90401878, grad/param norm = 1.9068e-01, time/batch = 18.1636s	
15664/26050 (epoch 30.065), train_loss = 0.74022663, grad/param norm = 1.5602e-01, time/batch = 18.9024s	
15665/26050 (epoch 30.067), train_loss = 0.88831174, grad/param norm = 2.0140e-01, time/batch = 17.3937s	
15666/26050 (epoch 30.069), train_loss = 0.93577947, grad/param norm = 2.0427e-01, time/batch = 17.6464s	
15667/26050 (epoch 30.071), train_loss = 0.94129952, grad/param norm = 1.8782e-01, time/batch = 16.6384s	
15668/26050 (epoch 30.073), train_loss = 1.04464116, grad/param norm = 2.0359e-01, time/batch = 17.6229s	
15669/26050 (epoch 30.075), train_loss = 0.85006881, grad/param norm = 1.9079e-01, time/batch = 17.2362s	
15670/26050 (epoch 30.077), train_loss = 0.86904318, grad/param norm = 2.4128e-01, time/batch = 17.6386s	
15671/26050 (epoch 30.079), train_loss = 0.90444458, grad/param norm = 2.2201e-01, time/batch = 18.9097s	
15672/26050 (epoch 30.081), train_loss = 0.86853908, grad/param norm = 1.8564e-01, time/batch = 17.6394s	
15673/26050 (epoch 30.083), train_loss = 1.00085197, grad/param norm = 1.9346e-01, time/batch = 17.9881s	
15674/26050 (epoch 30.084), train_loss = 0.92002633, grad/param norm = 2.4417e-01, time/batch = 18.3304s	
15675/26050 (epoch 30.086), train_loss = 1.07169683, grad/param norm = 2.4062e-01, time/batch = 16.5417s	
15676/26050 (epoch 30.088), train_loss = 0.85868974, grad/param norm = 1.9091e-01, time/batch = 16.3646s	
15677/26050 (epoch 30.090), train_loss = 0.92575384, grad/param norm = 2.2497e-01, time/batch = 17.6434s	
15678/26050 (epoch 30.092), train_loss = 0.94233775, grad/param norm = 2.0810e-01, time/batch = 16.0641s	
15679/26050 (epoch 30.094), train_loss = 0.79373190, grad/param norm = 1.8792e-01, time/batch = 17.7413s	
15680/26050 (epoch 30.096), train_loss = 0.92290506, grad/param norm = 1.8568e-01, time/batch = 18.8961s	
15681/26050 (epoch 30.098), train_loss = 0.87892005, grad/param norm = 1.9738e-01, time/batch = 18.2309s	
15682/26050 (epoch 30.100), train_loss = 0.83563719, grad/param norm = 2.1133e-01, time/batch = 17.1404s	
15683/26050 (epoch 30.102), train_loss = 0.95688669, grad/param norm = 2.0423e-01, time/batch = 18.3177s	
15684/26050 (epoch 30.104), train_loss = 0.87211588, grad/param norm = 2.0061e-01, time/batch = 18.2293s	
15685/26050 (epoch 30.106), train_loss = 0.93574175, grad/param norm = 2.1519e-01, time/batch = 17.7310s	
15686/26050 (epoch 30.107), train_loss = 0.75309357, grad/param norm = 1.9300e-01, time/batch = 18.0613s	
15687/26050 (epoch 30.109), train_loss = 0.84054566, grad/param norm = 1.8847e-01, time/batch = 18.2391s	
15688/26050 (epoch 30.111), train_loss = 1.05432267, grad/param norm = 2.5720e-01, time/batch = 18.4016s	
15689/26050 (epoch 30.113), train_loss = 0.86154053, grad/param norm = 1.8958e-01, time/batch = 18.3997s	
15690/26050 (epoch 30.115), train_loss = 0.99222291, grad/param norm = 1.8316e-01, time/batch = 16.3004s	
15691/26050 (epoch 30.117), train_loss = 0.90178795, grad/param norm = 1.8959e-01, time/batch = 18.9903s	
15692/26050 (epoch 30.119), train_loss = 0.77229861, grad/param norm = 1.9322e-01, time/batch = 20.1431s	
15693/26050 (epoch 30.121), train_loss = 0.93149037, grad/param norm = 2.0556e-01, time/batch = 31.6776s	
15694/26050 (epoch 30.123), train_loss = 0.84087529, grad/param norm = 1.9194e-01, time/batch = 19.6523s	
15695/26050 (epoch 30.125), train_loss = 0.78209026, grad/param norm = 1.7837e-01, time/batch = 18.4804s	
15696/26050 (epoch 30.127), train_loss = 0.73966976, grad/param norm = 1.7060e-01, time/batch = 15.8907s	
15697/26050 (epoch 30.129), train_loss = 0.72510577, grad/param norm = 1.7718e-01, time/batch = 17.5529s	
15698/26050 (epoch 30.131), train_loss = 0.86995920, grad/param norm = 2.2759e-01, time/batch = 17.3971s	
15699/26050 (epoch 30.132), train_loss = 0.87487843, grad/param norm = 1.6745e-01, time/batch = 18.5627s	
15700/26050 (epoch 30.134), train_loss = 0.92747787, grad/param norm = 2.2977e-01, time/batch = 18.7266s	
15701/26050 (epoch 30.136), train_loss = 0.87705714, grad/param norm = 1.8331e-01, time/batch = 15.8764s	
15702/26050 (epoch 30.138), train_loss = 0.66414073, grad/param norm = 1.8438e-01, time/batch = 17.4757s	
15703/26050 (epoch 30.140), train_loss = 0.75839545, grad/param norm = 2.0862e-01, time/batch = 18.7295s	
15704/26050 (epoch 30.142), train_loss = 0.78062899, grad/param norm = 1.9233e-01, time/batch = 16.8176s	
15705/26050 (epoch 30.144), train_loss = 0.70297019, grad/param norm = 1.8059e-01, time/batch = 17.8094s	
15706/26050 (epoch 30.146), train_loss = 0.66992184, grad/param norm = 1.7715e-01, time/batch = 17.5884s	
15707/26050 (epoch 30.148), train_loss = 0.70940777, grad/param norm = 1.5933e-01, time/batch = 18.5684s	
15708/26050 (epoch 30.150), train_loss = 0.83497090, grad/param norm = 1.9149e-01, time/batch = 15.8646s	
15709/26050 (epoch 30.152), train_loss = 1.04302454, grad/param norm = 3.0511e-01, time/batch = 16.2418s	
15710/26050 (epoch 30.154), train_loss = 0.72513003, grad/param norm = 1.9266e-01, time/batch = 17.2215s	
15711/26050 (epoch 30.155), train_loss = 0.76676591, grad/param norm = 1.9921e-01, time/batch = 17.2404s	
15712/26050 (epoch 30.157), train_loss = 0.87489473, grad/param norm = 2.1718e-01, time/batch = 18.6539s	
15713/26050 (epoch 30.159), train_loss = 0.92528236, grad/param norm = 2.2765e-01, time/batch = 15.0670s	
15714/26050 (epoch 30.161), train_loss = 0.90606542, grad/param norm = 2.1936e-01, time/batch = 17.0000s	
15715/26050 (epoch 30.163), train_loss = 0.74616427, grad/param norm = 1.8952e-01, time/batch = 17.2252s	
15716/26050 (epoch 30.165), train_loss = 0.69421657, grad/param norm = 1.7992e-01, time/batch = 18.7372s	
15717/26050 (epoch 30.167), train_loss = 1.03300050, grad/param norm = 2.2361e-01, time/batch = 18.0791s	
15718/26050 (epoch 30.169), train_loss = 0.89770089, grad/param norm = 2.1074e-01, time/batch = 17.3306s	
15719/26050 (epoch 30.171), train_loss = 0.75689424, grad/param norm = 1.7029e-01, time/batch = 17.9706s	
15720/26050 (epoch 30.173), train_loss = 0.85380603, grad/param norm = 1.9363e-01, time/batch = 15.5525s	
15721/26050 (epoch 30.175), train_loss = 0.87001982, grad/param norm = 1.8687e-01, time/batch = 18.3275s	
15722/26050 (epoch 30.177), train_loss = 0.97325285, grad/param norm = 2.0040e-01, time/batch = 17.7441s	
15723/26050 (epoch 30.179), train_loss = 0.65028334, grad/param norm = 1.6667e-01, time/batch = 18.3247s	
15724/26050 (epoch 30.180), train_loss = 1.11051623, grad/param norm = 2.1074e-01, time/batch = 18.0832s	
15725/26050 (epoch 30.182), train_loss = 1.08027036, grad/param norm = 2.2869e-01, time/batch = 16.7335s	
15726/26050 (epoch 30.184), train_loss = 0.92925192, grad/param norm = 1.8817e-01, time/batch = 18.0670s	
15727/26050 (epoch 30.186), train_loss = 0.74867001, grad/param norm = 1.8567e-01, time/batch = 18.2384s	
15728/26050 (epoch 30.188), train_loss = 0.90470554, grad/param norm = 2.0530e-01, time/batch = 17.6529s	
15729/26050 (epoch 30.190), train_loss = 0.93235898, grad/param norm = 2.0801e-01, time/batch = 14.4775s	
15730/26050 (epoch 30.192), train_loss = 0.96045276, grad/param norm = 1.9634e-01, time/batch = 18.7301s	
15731/26050 (epoch 30.194), train_loss = 0.93703454, grad/param norm = 1.9759e-01, time/batch = 15.7139s	
15732/26050 (epoch 30.196), train_loss = 0.95052050, grad/param norm = 2.0031e-01, time/batch = 16.6304s	
15733/26050 (epoch 30.198), train_loss = 0.81407148, grad/param norm = 1.8445e-01, time/batch = 18.4821s	
15734/26050 (epoch 30.200), train_loss = 0.80048491, grad/param norm = 1.8927e-01, time/batch = 17.2454s	
15735/26050 (epoch 30.202), train_loss = 0.90630400, grad/param norm = 1.7870e-01, time/batch = 16.4514s	
15736/26050 (epoch 30.203), train_loss = 0.99237586, grad/param norm = 1.9435e-01, time/batch = 17.5673s	
15737/26050 (epoch 30.205), train_loss = 0.84870989, grad/param norm = 2.0208e-01, time/batch = 18.4101s	
15738/26050 (epoch 30.207), train_loss = 0.82405026, grad/param norm = 2.1561e-01, time/batch = 18.5763s	
15739/26050 (epoch 30.209), train_loss = 0.94368896, grad/param norm = 1.9042e-01, time/batch = 17.9841s	
15740/26050 (epoch 30.211), train_loss = 0.75790756, grad/param norm = 1.8712e-01, time/batch = 18.2245s	
15741/26050 (epoch 30.213), train_loss = 0.91844821, grad/param norm = 2.3321e-01, time/batch = 18.6415s	
15742/26050 (epoch 30.215), train_loss = 0.86401202, grad/param norm = 2.1381e-01, time/batch = 16.6667s	
15743/26050 (epoch 30.217), train_loss = 0.84104871, grad/param norm = 1.8106e-01, time/batch = 17.6500s	
15744/26050 (epoch 30.219), train_loss = 0.85484673, grad/param norm = 2.1306e-01, time/batch = 17.9891s	
15745/26050 (epoch 30.221), train_loss = 0.79765212, grad/param norm = 1.8957e-01, time/batch = 17.9831s	
15746/26050 (epoch 30.223), train_loss = 0.97341197, grad/param norm = 2.2218e-01, time/batch = 18.4103s	
15747/26050 (epoch 30.225), train_loss = 0.82221249, grad/param norm = 2.1579e-01, time/batch = 17.9800s	
15748/26050 (epoch 30.226), train_loss = 0.92782732, grad/param norm = 2.1872e-01, time/batch = 15.7030s	
15749/26050 (epoch 30.228), train_loss = 1.02753856, grad/param norm = 2.0278e-01, time/batch = 16.8076s	
15750/26050 (epoch 30.230), train_loss = 0.90002587, grad/param norm = 2.0715e-01, time/batch = 14.3150s	
15751/26050 (epoch 30.232), train_loss = 0.97073313, grad/param norm = 2.3039e-01, time/batch = 18.3065s	
15752/26050 (epoch 30.234), train_loss = 0.79974345, grad/param norm = 1.9203e-01, time/batch = 17.6695s	
15753/26050 (epoch 30.236), train_loss = 0.96838026, grad/param norm = 1.9768e-01, time/batch = 17.8278s	
15754/26050 (epoch 30.238), train_loss = 0.76182566, grad/param norm = 1.9636e-01, time/batch = 18.1603s	
15755/26050 (epoch 30.240), train_loss = 0.89767846, grad/param norm = 1.9682e-01, time/batch = 18.6485s	
15756/26050 (epoch 30.242), train_loss = 0.86760203, grad/param norm = 2.0194e-01, time/batch = 17.5567s	
15757/26050 (epoch 30.244), train_loss = 0.92697771, grad/param norm = 2.3002e-01, time/batch = 14.8975s	
15758/26050 (epoch 30.246), train_loss = 0.83798773, grad/param norm = 1.8780e-01, time/batch = 18.3144s	
15759/26050 (epoch 30.248), train_loss = 0.89824408, grad/param norm = 2.0950e-01, time/batch = 17.7358s	
15760/26050 (epoch 30.250), train_loss = 0.89259938, grad/param norm = 2.2468e-01, time/batch = 15.1258s	
15761/26050 (epoch 30.251), train_loss = 0.84697852, grad/param norm = 2.0170e-01, time/batch = 18.8021s	
15762/26050 (epoch 30.253), train_loss = 0.79699527, grad/param norm = 1.9721e-01, time/batch = 17.7370s	
15763/26050 (epoch 30.255), train_loss = 1.05927445, grad/param norm = 2.1038e-01, time/batch = 18.0539s	
15764/26050 (epoch 30.257), train_loss = 0.88058156, grad/param norm = 2.3143e-01, time/batch = 18.8829s	
15765/26050 (epoch 30.259), train_loss = 0.97755390, grad/param norm = 2.0160e-01, time/batch = 19.1291s	
15766/26050 (epoch 30.261), train_loss = 0.79127290, grad/param norm = 2.0070e-01, time/batch = 17.1464s	
15767/26050 (epoch 30.263), train_loss = 0.98874128, grad/param norm = 2.2246e-01, time/batch = 18.3252s	
15768/26050 (epoch 30.265), train_loss = 1.03497521, grad/param norm = 2.2492e-01, time/batch = 18.3152s	
15769/26050 (epoch 30.267), train_loss = 1.01095364, grad/param norm = 1.8928e-01, time/batch = 16.2922s	
15770/26050 (epoch 30.269), train_loss = 1.00922456, grad/param norm = 2.4086e-01, time/batch = 18.7417s	
15771/26050 (epoch 30.271), train_loss = 0.93966976, grad/param norm = 2.2602e-01, time/batch = 15.3813s	
15772/26050 (epoch 30.273), train_loss = 0.83032076, grad/param norm = 2.0826e-01, time/batch = 18.9727s	
15773/26050 (epoch 30.274), train_loss = 0.86492743, grad/param norm = 1.7355e-01, time/batch = 18.0487s	
15774/26050 (epoch 30.276), train_loss = 0.86125449, grad/param norm = 2.0003e-01, time/batch = 18.1637s	
15775/26050 (epoch 30.278), train_loss = 0.98521067, grad/param norm = 1.9795e-01, time/batch = 14.8953s	
15776/26050 (epoch 30.280), train_loss = 0.89686167, grad/param norm = 1.8558e-01, time/batch = 17.3978s	
15777/26050 (epoch 30.282), train_loss = 0.94683439, grad/param norm = 1.8987e-01, time/batch = 17.3995s	
15778/26050 (epoch 30.284), train_loss = 0.88126949, grad/param norm = 1.9809e-01, time/batch = 18.2230s	
15779/26050 (epoch 30.286), train_loss = 0.93056301, grad/param norm = 2.2387e-01, time/batch = 18.4051s	
15780/26050 (epoch 30.288), train_loss = 0.77059403, grad/param norm = 1.7266e-01, time/batch = 18.5647s	
15781/26050 (epoch 30.290), train_loss = 0.90666491, grad/param norm = 2.0302e-01, time/batch = 18.7355s	
15782/26050 (epoch 30.292), train_loss = 0.83963040, grad/param norm = 2.0069e-01, time/batch = 17.9852s	
15783/26050 (epoch 30.294), train_loss = 0.90370320, grad/param norm = 2.1189e-01, time/batch = 17.6377s	
15784/26050 (epoch 30.296), train_loss = 0.97533340, grad/param norm = 1.9098e-01, time/batch = 18.4047s	
15785/26050 (epoch 30.298), train_loss = 0.91782555, grad/param norm = 1.8757e-01, time/batch = 18.1514s	
15786/26050 (epoch 30.299), train_loss = 0.73868623, grad/param norm = 1.7035e-01, time/batch = 17.7209s	
15787/26050 (epoch 30.301), train_loss = 0.76993779, grad/param norm = 1.9280e-01, time/batch = 18.6529s	
15788/26050 (epoch 30.303), train_loss = 0.89773829, grad/param norm = 2.0505e-01, time/batch = 18.4885s	
15789/26050 (epoch 30.305), train_loss = 0.71728730, grad/param norm = 1.8668e-01, time/batch = 16.2935s	
15790/26050 (epoch 30.307), train_loss = 0.81303638, grad/param norm = 2.0017e-01, time/batch = 18.7329s	
15791/26050 (epoch 30.309), train_loss = 0.88920866, grad/param norm = 1.9603e-01, time/batch = 17.9812s	
15792/26050 (epoch 30.311), train_loss = 0.93126431, grad/param norm = 2.1840e-01, time/batch = 17.8001s	
15793/26050 (epoch 30.313), train_loss = 0.87712288, grad/param norm = 2.0298e-01, time/batch = 17.3860s	
15794/26050 (epoch 30.315), train_loss = 0.97269133, grad/param norm = 1.9646e-01, time/batch = 15.1214s	
15795/26050 (epoch 30.317), train_loss = 0.93472059, grad/param norm = 2.3624e-01, time/batch = 17.8882s	
15796/26050 (epoch 30.319), train_loss = 0.81385635, grad/param norm = 2.0154e-01, time/batch = 17.8123s	
15797/26050 (epoch 30.321), train_loss = 0.87066783, grad/param norm = 2.1006e-01, time/batch = 18.0711s	
15798/26050 (epoch 30.322), train_loss = 0.94106981, grad/param norm = 1.9439e-01, time/batch = 18.2214s	
15799/26050 (epoch 30.324), train_loss = 0.71070120, grad/param norm = 1.7468e-01, time/batch = 17.8198s	
15800/26050 (epoch 30.326), train_loss = 1.01346090, grad/param norm = 2.0452e-01, time/batch = 18.2181s	
15801/26050 (epoch 30.328), train_loss = 0.91019504, grad/param norm = 1.7353e-01, time/batch = 18.6626s	
15802/26050 (epoch 30.330), train_loss = 0.77608589, grad/param norm = 1.9182e-01, time/batch = 18.9916s	
15803/26050 (epoch 30.332), train_loss = 0.95499542, grad/param norm = 1.9637e-01, time/batch = 17.3042s	
15804/26050 (epoch 30.334), train_loss = 0.80493587, grad/param norm = 1.7854e-01, time/batch = 17.5561s	
15805/26050 (epoch 30.336), train_loss = 0.83337998, grad/param norm = 1.9450e-01, time/batch = 15.8495s	
15806/26050 (epoch 30.338), train_loss = 0.77999696, grad/param norm = 1.8412e-01, time/batch = 17.3790s	
15807/26050 (epoch 30.340), train_loss = 0.94637347, grad/param norm = 1.9745e-01, time/batch = 18.1453s	
15808/26050 (epoch 30.342), train_loss = 0.98079372, grad/param norm = 2.0769e-01, time/batch = 18.1313s	
15809/26050 (epoch 30.344), train_loss = 0.81230169, grad/param norm = 2.0607e-01, time/batch = 17.7398s	
15810/26050 (epoch 30.345), train_loss = 0.88722931, grad/param norm = 2.1100e-01, time/batch = 15.8685s	
15811/26050 (epoch 30.347), train_loss = 1.02405537, grad/param norm = 2.0649e-01, time/batch = 18.6293s	
15812/26050 (epoch 30.349), train_loss = 0.93738707, grad/param norm = 2.0822e-01, time/batch = 16.9465s	
15813/26050 (epoch 30.351), train_loss = 0.92961926, grad/param norm = 2.3106e-01, time/batch = 17.8920s	
15814/26050 (epoch 30.353), train_loss = 0.90419734, grad/param norm = 2.0715e-01, time/batch = 17.7369s	
15815/26050 (epoch 30.355), train_loss = 0.90743985, grad/param norm = 2.2663e-01, time/batch = 18.8968s	
15816/26050 (epoch 30.357), train_loss = 0.84307144, grad/param norm = 1.7559e-01, time/batch = 17.8826s	
15817/26050 (epoch 30.359), train_loss = 0.97436753, grad/param norm = 2.1257e-01, time/batch = 17.8154s	
15818/26050 (epoch 30.361), train_loss = 0.79787003, grad/param norm = 1.6431e-01, time/batch = 15.4757s	
15819/26050 (epoch 30.363), train_loss = 0.97446374, grad/param norm = 2.0204e-01, time/batch = 18.8103s	
15820/26050 (epoch 30.365), train_loss = 0.85463633, grad/param norm = 1.8717e-01, time/batch = 15.4804s	
15821/26050 (epoch 30.367), train_loss = 0.96311147, grad/param norm = 2.1128e-01, time/batch = 17.8999s	
15822/26050 (epoch 30.369), train_loss = 0.80252712, grad/param norm = 1.7046e-01, time/batch = 18.5705s	
15823/26050 (epoch 30.370), train_loss = 0.80142719, grad/param norm = 1.6874e-01, time/batch = 17.9789s	
15824/26050 (epoch 30.372), train_loss = 0.91280221, grad/param norm = 2.1540e-01, time/batch = 17.6615s	
15825/26050 (epoch 30.374), train_loss = 1.03466776, grad/param norm = 2.1382e-01, time/batch = 17.6527s	
15826/26050 (epoch 30.376), train_loss = 1.05343925, grad/param norm = 2.2223e-01, time/batch = 15.7102s	
15827/26050 (epoch 30.378), train_loss = 0.84570743, grad/param norm = 1.8872e-01, time/batch = 17.4632s	
15828/26050 (epoch 30.380), train_loss = 1.04519134, grad/param norm = 2.2961e-01, time/batch = 18.4000s	
15829/26050 (epoch 30.382), train_loss = 1.14083907, grad/param norm = 2.5809e-01, time/batch = 16.7369s	
15830/26050 (epoch 30.384), train_loss = 0.85547566, grad/param norm = 2.2252e-01, time/batch = 17.4632s	
15831/26050 (epoch 30.386), train_loss = 0.97009035, grad/param norm = 3.0714e-01, time/batch = 17.6197s	
15832/26050 (epoch 30.388), train_loss = 0.94602469, grad/param norm = 2.3575e-01, time/batch = 18.8321s	
15833/26050 (epoch 30.390), train_loss = 0.85136364, grad/param norm = 1.9127e-01, time/batch = 17.9007s	
15834/26050 (epoch 30.392), train_loss = 0.80368478, grad/param norm = 1.7831e-01, time/batch = 14.8968s	
15835/26050 (epoch 30.393), train_loss = 0.93466639, grad/param norm = 2.3478e-01, time/batch = 17.6646s	
15836/26050 (epoch 30.395), train_loss = 0.96473178, grad/param norm = 2.1722e-01, time/batch = 17.9134s	
15837/26050 (epoch 30.397), train_loss = 0.98022626, grad/param norm = 2.3617e-01, time/batch = 17.8962s	
15838/26050 (epoch 30.399), train_loss = 0.85582845, grad/param norm = 1.9584e-01, time/batch = 18.5723s	
15839/26050 (epoch 30.401), train_loss = 0.90744103, grad/param norm = 1.8845e-01, time/batch = 15.0619s	
15840/26050 (epoch 30.403), train_loss = 0.92851108, grad/param norm = 2.2385e-01, time/batch = 17.5641s	
15841/26050 (epoch 30.405), train_loss = 0.92327650, grad/param norm = 2.2534e-01, time/batch = 18.0735s	
15842/26050 (epoch 30.407), train_loss = 1.05276537, grad/param norm = 2.2564e-01, time/batch = 18.3217s	
15843/26050 (epoch 30.409), train_loss = 1.04751537, grad/param norm = 2.4233e-01, time/batch = 18.3858s	
15844/26050 (epoch 30.411), train_loss = 0.97492304, grad/param norm = 2.3604e-01, time/batch = 17.0343s	
15845/26050 (epoch 30.413), train_loss = 1.07742299, grad/param norm = 2.0901e-01, time/batch = 16.5359s	
15846/26050 (epoch 30.415), train_loss = 1.08188853, grad/param norm = 2.4879e-01, time/batch = 18.4104s	
15847/26050 (epoch 30.417), train_loss = 1.10289450, grad/param norm = 2.2940e-01, time/batch = 16.8297s	
15848/26050 (epoch 30.418), train_loss = 0.99305078, grad/param norm = 2.2952e-01, time/batch = 16.3269s	
15849/26050 (epoch 30.420), train_loss = 0.79399371, grad/param norm = 1.9356e-01, time/batch = 18.8202s	
15850/26050 (epoch 30.422), train_loss = 0.76702296, grad/param norm = 1.7932e-01, time/batch = 17.9038s	
15851/26050 (epoch 30.424), train_loss = 1.04422145, grad/param norm = 2.3278e-01, time/batch = 16.8874s	
15852/26050 (epoch 30.426), train_loss = 1.00050973, grad/param norm = 2.1698e-01, time/batch = 17.6640s	
15853/26050 (epoch 30.428), train_loss = 0.85500225, grad/param norm = 1.9466e-01, time/batch = 17.4990s	
15854/26050 (epoch 30.430), train_loss = 1.06193368, grad/param norm = 1.9802e-01, time/batch = 16.7968s	
15855/26050 (epoch 30.432), train_loss = 0.88060590, grad/param norm = 1.8977e-01, time/batch = 17.9043s	
15856/26050 (epoch 30.434), train_loss = 0.87328684, grad/param norm = 1.8792e-01, time/batch = 15.4876s	
15857/26050 (epoch 30.436), train_loss = 1.02263200, grad/param norm = 2.1072e-01, time/batch = 17.3948s	
15858/26050 (epoch 30.438), train_loss = 0.97048333, grad/param norm = 2.2048e-01, time/batch = 18.2334s	
15859/26050 (epoch 30.440), train_loss = 0.94275929, grad/param norm = 2.2214e-01, time/batch = 18.3097s	
15860/26050 (epoch 30.441), train_loss = 0.93635289, grad/param norm = 2.0157e-01, time/batch = 18.7927s	
15861/26050 (epoch 30.443), train_loss = 0.77666092, grad/param norm = 1.5790e-01, time/batch = 17.0563s	
15862/26050 (epoch 30.445), train_loss = 0.82941488, grad/param norm = 1.7705e-01, time/batch = 17.8180s	
15863/26050 (epoch 30.447), train_loss = 1.03126696, grad/param norm = 2.0774e-01, time/batch = 18.5704s	
15864/26050 (epoch 30.449), train_loss = 0.82247248, grad/param norm = 1.8898e-01, time/batch = 17.8276s	
15865/26050 (epoch 30.451), train_loss = 1.05000744, grad/param norm = 2.0797e-01, time/batch = 18.1474s	
15866/26050 (epoch 30.453), train_loss = 0.83926294, grad/param norm = 1.6356e-01, time/batch = 15.3832s	
15867/26050 (epoch 30.455), train_loss = 0.92087449, grad/param norm = 1.8774e-01, time/batch = 14.1506s	
15868/26050 (epoch 30.457), train_loss = 0.91038228, grad/param norm = 2.0592e-01, time/batch = 16.8832s	
15869/26050 (epoch 30.459), train_loss = 1.02649590, grad/param norm = 2.3275e-01, time/batch = 17.9890s	
15870/26050 (epoch 30.461), train_loss = 1.01350927, grad/param norm = 2.1038e-01, time/batch = 18.3174s	
15871/26050 (epoch 30.463), train_loss = 0.87288311, grad/param norm = 1.6856e-01, time/batch = 17.7378s	
15872/26050 (epoch 30.464), train_loss = 0.95132402, grad/param norm = 2.0021e-01, time/batch = 18.3226s	
15873/26050 (epoch 30.466), train_loss = 0.94568545, grad/param norm = 2.1253e-01, time/batch = 18.1637s	
15874/26050 (epoch 30.468), train_loss = 1.00813659, grad/param norm = 1.8185e-01, time/batch = 18.2337s	
15875/26050 (epoch 30.470), train_loss = 1.02900106, grad/param norm = 2.3746e-01, time/batch = 17.6560s	
15876/26050 (epoch 30.472), train_loss = 1.03618670, grad/param norm = 2.5131e-01, time/batch = 15.0667s	
15877/26050 (epoch 30.474), train_loss = 1.02405948, grad/param norm = 2.1805e-01, time/batch = 17.7445s	
15878/26050 (epoch 30.476), train_loss = 1.02849027, grad/param norm = 1.9354e-01, time/batch = 16.0392s	
15879/26050 (epoch 30.478), train_loss = 0.88487050, grad/param norm = 1.8636e-01, time/batch = 18.2924s	
15880/26050 (epoch 30.480), train_loss = 0.89608642, grad/param norm = 1.8318e-01, time/batch = 18.7389s	
15881/26050 (epoch 30.482), train_loss = 0.86497916, grad/param norm = 2.0712e-01, time/batch = 17.8242s	
15882/26050 (epoch 30.484), train_loss = 0.85222176, grad/param norm = 1.9481e-01, time/batch = 18.7324s	
15883/26050 (epoch 30.486), train_loss = 1.04612280, grad/param norm = 1.9321e-01, time/batch = 17.7516s	
15884/26050 (epoch 30.488), train_loss = 1.07491912, grad/param norm = 2.0831e-01, time/batch = 17.8293s	
15885/26050 (epoch 30.489), train_loss = 1.08448212, grad/param norm = 2.3028e-01, time/batch = 18.3180s	
15886/26050 (epoch 30.491), train_loss = 0.83976394, grad/param norm = 2.1171e-01, time/batch = 16.5626s	
15887/26050 (epoch 30.493), train_loss = 0.93803009, grad/param norm = 1.9977e-01, time/batch = 17.4843s	
15888/26050 (epoch 30.495), train_loss = 0.90127231, grad/param norm = 1.7502e-01, time/batch = 17.6447s	
15889/26050 (epoch 30.497), train_loss = 0.81601339, grad/param norm = 1.9468e-01, time/batch = 18.2469s	
15890/26050 (epoch 30.499), train_loss = 0.87072239, grad/param norm = 2.0792e-01, time/batch = 16.6490s	
15891/26050 (epoch 30.501), train_loss = 0.99609891, grad/param norm = 2.0300e-01, time/batch = 16.4741s	
15892/26050 (epoch 30.503), train_loss = 0.85104371, grad/param norm = 1.8710e-01, time/batch = 17.8095s	
15893/26050 (epoch 30.505), train_loss = 1.03619757, grad/param norm = 2.0679e-01, time/batch = 18.6546s	
15894/26050 (epoch 30.507), train_loss = 0.97994407, grad/param norm = 2.2719e-01, time/batch = 18.8976s	
15895/26050 (epoch 30.509), train_loss = 1.06142777, grad/param norm = 1.8464e-01, time/batch = 26.9296s	
15896/26050 (epoch 30.511), train_loss = 0.88086361, grad/param norm = 1.7244e-01, time/batch = 30.5574s	
15897/26050 (epoch 30.512), train_loss = 0.80536701, grad/param norm = 2.1962e-01, time/batch = 16.8606s	
15898/26050 (epoch 30.514), train_loss = 0.96755740, grad/param norm = 2.1614e-01, time/batch = 18.1683s	
15899/26050 (epoch 30.516), train_loss = 1.05218633, grad/param norm = 2.1268e-01, time/batch = 14.5549s	
15900/26050 (epoch 30.518), train_loss = 0.90129155, grad/param norm = 2.0385e-01, time/batch = 17.5690s	
15901/26050 (epoch 30.520), train_loss = 0.91860304, grad/param norm = 2.0064e-01, time/batch = 18.8923s	
15902/26050 (epoch 30.522), train_loss = 0.72878922, grad/param norm = 1.7408e-01, time/batch = 17.6611s	
15903/26050 (epoch 30.524), train_loss = 1.01410964, grad/param norm = 2.4731e-01, time/batch = 18.4941s	
15904/26050 (epoch 30.526), train_loss = 1.03235122, grad/param norm = 2.9174e-01, time/batch = 17.7985s	
15905/26050 (epoch 30.528), train_loss = 0.97634115, grad/param norm = 2.5874e-01, time/batch = 16.9662s	
15906/26050 (epoch 30.530), train_loss = 0.86920795, grad/param norm = 2.2578e-01, time/batch = 16.7940s	
15907/26050 (epoch 30.532), train_loss = 0.96613728, grad/param norm = 2.3590e-01, time/batch = 17.4863s	
15908/26050 (epoch 30.534), train_loss = 0.98714560, grad/param norm = 2.6065e-01, time/batch = 17.8996s	
15909/26050 (epoch 30.536), train_loss = 0.93761751, grad/param norm = 2.0128e-01, time/batch = 18.8117s	
15910/26050 (epoch 30.537), train_loss = 0.99984881, grad/param norm = 2.1640e-01, time/batch = 17.6432s	
15911/26050 (epoch 30.539), train_loss = 0.91693405, grad/param norm = 2.0323e-01, time/batch = 17.3935s	
15912/26050 (epoch 30.541), train_loss = 1.09409645, grad/param norm = 2.2318e-01, time/batch = 16.1349s	
15913/26050 (epoch 30.543), train_loss = 0.76209315, grad/param norm = 1.9948e-01, time/batch = 18.4686s	
15914/26050 (epoch 30.545), train_loss = 0.92553859, grad/param norm = 1.9615e-01, time/batch = 17.5543s	
15915/26050 (epoch 30.547), train_loss = 0.89016243, grad/param norm = 2.0025e-01, time/batch = 18.4037s	
15916/26050 (epoch 30.549), train_loss = 0.78386862, grad/param norm = 2.1198e-01, time/batch = 18.9894s	
15917/26050 (epoch 30.551), train_loss = 0.98244026, grad/param norm = 2.0776e-01, time/batch = 16.5487s	
15918/26050 (epoch 30.553), train_loss = 0.87876223, grad/param norm = 1.9963e-01, time/batch = 17.6667s	
15919/26050 (epoch 30.555), train_loss = 0.82188426, grad/param norm = 2.1074e-01, time/batch = 17.8061s	
15920/26050 (epoch 30.557), train_loss = 0.94451163, grad/param norm = 1.9004e-01, time/batch = 16.3679s	
15921/26050 (epoch 30.559), train_loss = 0.94378334, grad/param norm = 1.9745e-01, time/batch = 18.4630s	
15922/26050 (epoch 30.560), train_loss = 0.88412069, grad/param norm = 2.2819e-01, time/batch = 17.7383s	
15923/26050 (epoch 30.562), train_loss = 0.90979707, grad/param norm = 2.3705e-01, time/batch = 18.6606s	
15924/26050 (epoch 30.564), train_loss = 1.09226071, grad/param norm = 2.1805e-01, time/batch = 14.7824s	
15925/26050 (epoch 30.566), train_loss = 0.85427768, grad/param norm = 2.0049e-01, time/batch = 18.4777s	
15926/26050 (epoch 30.568), train_loss = 0.96610158, grad/param norm = 2.0683e-01, time/batch = 17.1546s	
15927/26050 (epoch 30.570), train_loss = 0.93980714, grad/param norm = 2.1191e-01, time/batch = 17.9845s	
15928/26050 (epoch 30.572), train_loss = 0.92936165, grad/param norm = 2.1743e-01, time/batch = 17.2209s	
15929/26050 (epoch 30.574), train_loss = 0.93431159, grad/param norm = 2.3617e-01, time/batch = 17.5612s	
15930/26050 (epoch 30.576), train_loss = 0.96687093, grad/param norm = 2.1198e-01, time/batch = 18.4820s	
15931/26050 (epoch 30.578), train_loss = 0.90587639, grad/param norm = 1.9924e-01, time/batch = 17.4880s	
15932/26050 (epoch 30.580), train_loss = 0.84442368, grad/param norm = 1.9881e-01, time/batch = 18.5668s	
15933/26050 (epoch 30.582), train_loss = 0.93329448, grad/param norm = 1.8773e-01, time/batch = 17.8301s	
15934/26050 (epoch 30.583), train_loss = 1.00031317, grad/param norm = 1.9403e-01, time/batch = 15.5517s	
15935/26050 (epoch 30.585), train_loss = 0.82578675, grad/param norm = 2.0433e-01, time/batch = 18.3148s	
15936/26050 (epoch 30.587), train_loss = 0.93926036, grad/param norm = 1.9985e-01, time/batch = 14.8833s	
15937/26050 (epoch 30.589), train_loss = 1.06842152, grad/param norm = 2.2379e-01, time/batch = 17.6120s	
15938/26050 (epoch 30.591), train_loss = 0.91888841, grad/param norm = 2.2156e-01, time/batch = 18.2212s	
15939/26050 (epoch 30.593), train_loss = 0.80554143, grad/param norm = 1.7952e-01, time/batch = 14.7082s	
15940/26050 (epoch 30.595), train_loss = 0.99687843, grad/param norm = 2.1011e-01, time/batch = 18.8100s	
15941/26050 (epoch 30.597), train_loss = 0.93209064, grad/param norm = 2.1216e-01, time/batch = 18.1404s	
15942/26050 (epoch 30.599), train_loss = 0.95648489, grad/param norm = 1.9915e-01, time/batch = 18.3099s	
15943/26050 (epoch 30.601), train_loss = 1.08275965, grad/param norm = 2.0060e-01, time/batch = 18.2356s	
15944/26050 (epoch 30.603), train_loss = 0.96450752, grad/param norm = 2.0913e-01, time/batch = 16.2264s	
15945/26050 (epoch 30.605), train_loss = 0.89036842, grad/param norm = 2.0712e-01, time/batch = 17.8811s	
15946/26050 (epoch 30.607), train_loss = 1.01811152, grad/param norm = 2.5907e-01, time/batch = 18.5727s	
15947/26050 (epoch 30.608), train_loss = 0.83827244, grad/param norm = 1.8645e-01, time/batch = 18.7271s	
15948/26050 (epoch 30.610), train_loss = 0.93226566, grad/param norm = 2.1073e-01, time/batch = 17.6574s	
15949/26050 (epoch 30.612), train_loss = 0.91283821, grad/param norm = 2.1576e-01, time/batch = 17.7419s	
15950/26050 (epoch 30.614), train_loss = 0.93845497, grad/param norm = 2.0541e-01, time/batch = 18.8188s	
15951/26050 (epoch 30.616), train_loss = 1.01374983, grad/param norm = 2.3072e-01, time/batch = 18.3068s	
15952/26050 (epoch 30.618), train_loss = 0.90039943, grad/param norm = 2.2834e-01, time/batch = 17.0653s	
15953/26050 (epoch 30.620), train_loss = 0.97018787, grad/param norm = 2.1444e-01, time/batch = 16.4528s	
15954/26050 (epoch 30.622), train_loss = 0.82523559, grad/param norm = 1.7886e-01, time/batch = 18.3267s	
15955/26050 (epoch 30.624), train_loss = 0.79322237, grad/param norm = 1.9016e-01, time/batch = 18.3129s	
15956/26050 (epoch 30.626), train_loss = 0.97390386, grad/param norm = 1.8885e-01, time/batch = 16.8714s	
15957/26050 (epoch 30.628), train_loss = 0.87469557, grad/param norm = 2.4640e-01, time/batch = 18.7430s	
15958/26050 (epoch 30.630), train_loss = 1.06124425, grad/param norm = 1.8807e-01, time/batch = 16.2013s	
15959/26050 (epoch 30.631), train_loss = 1.06824408, grad/param norm = 2.1981e-01, time/batch = 18.4659s	
15960/26050 (epoch 30.633), train_loss = 0.86096043, grad/param norm = 2.1854e-01, time/batch = 18.6603s	
15961/26050 (epoch 30.635), train_loss = 0.87824244, grad/param norm = 1.8205e-01, time/batch = 16.8807s	
15962/26050 (epoch 30.637), train_loss = 0.81282216, grad/param norm = 1.9429e-01, time/batch = 17.8991s	
15963/26050 (epoch 30.639), train_loss = 0.98463743, grad/param norm = 1.9646e-01, time/batch = 17.9086s	
15964/26050 (epoch 30.641), train_loss = 0.87852012, grad/param norm = 1.8991e-01, time/batch = 18.0024s	
15965/26050 (epoch 30.643), train_loss = 0.82849073, grad/param norm = 1.5609e-01, time/batch = 15.9522s	
15966/26050 (epoch 30.645), train_loss = 0.86389489, grad/param norm = 1.9962e-01, time/batch = 15.5657s	
15967/26050 (epoch 30.647), train_loss = 0.85943218, grad/param norm = 2.1744e-01, time/batch = 18.7291s	
15968/26050 (epoch 30.649), train_loss = 0.89276055, grad/param norm = 1.8654e-01, time/batch = 17.3175s	
15969/26050 (epoch 30.651), train_loss = 0.86694803, grad/param norm = 1.9261e-01, time/batch = 18.2482s	
15970/26050 (epoch 30.653), train_loss = 0.91209315, grad/param norm = 2.2106e-01, time/batch = 16.2312s	
15971/26050 (epoch 30.655), train_loss = 0.85139063, grad/param norm = 2.1152e-01, time/batch = 18.3346s	
15972/26050 (epoch 30.656), train_loss = 0.80609679, grad/param norm = 1.7014e-01, time/batch = 18.1486s	
15973/26050 (epoch 30.658), train_loss = 1.10505019, grad/param norm = 2.1378e-01, time/batch = 17.9223s	
15974/26050 (epoch 30.660), train_loss = 0.78825148, grad/param norm = 2.1174e-01, time/batch = 18.3317s	
15975/26050 (epoch 30.662), train_loss = 0.89600420, grad/param norm = 2.0493e-01, time/batch = 16.9060s	
15976/26050 (epoch 30.664), train_loss = 0.89908875, grad/param norm = 1.9768e-01, time/batch = 17.4839s	
15977/26050 (epoch 30.666), train_loss = 0.84502955, grad/param norm = 1.8378e-01, time/batch = 17.8058s	
15978/26050 (epoch 30.668), train_loss = 0.72251199, grad/param norm = 2.0189e-01, time/batch = 17.6544s	
15979/26050 (epoch 30.670), train_loss = 1.03932337, grad/param norm = 2.4167e-01, time/batch = 17.4876s	
15980/26050 (epoch 30.672), train_loss = 0.91000439, grad/param norm = 1.9370e-01, time/batch = 17.0529s	
15981/26050 (epoch 30.674), train_loss = 0.81645002, grad/param norm = 2.0907e-01, time/batch = 18.7978s	
15982/26050 (epoch 30.676), train_loss = 0.97120615, grad/param norm = 2.1694e-01, time/batch = 18.9689s	
15983/26050 (epoch 30.678), train_loss = 1.00210354, grad/param norm = 2.1740e-01, time/batch = 17.9900s	
15984/26050 (epoch 30.679), train_loss = 1.04807840, grad/param norm = 2.1846e-01, time/batch = 17.5687s	
15985/26050 (epoch 30.681), train_loss = 0.94929560, grad/param norm = 2.1354e-01, time/batch = 16.1252s	
15986/26050 (epoch 30.683), train_loss = 0.82135598, grad/param norm = 3.2155e-01, time/batch = 18.3929s	
15987/26050 (epoch 30.685), train_loss = 0.89083885, grad/param norm = 1.8775e-01, time/batch = 17.9964s	
15988/26050 (epoch 30.687), train_loss = 0.81195907, grad/param norm = 1.9786e-01, time/batch = 18.3097s	
15989/26050 (epoch 30.689), train_loss = 0.87188492, grad/param norm = 2.0511e-01, time/batch = 18.4667s	
15990/26050 (epoch 30.691), train_loss = 0.73458052, grad/param norm = 1.5523e-01, time/batch = 16.3833s	
15991/26050 (epoch 30.693), train_loss = 0.87341415, grad/param norm = 2.0335e-01, time/batch = 18.9122s	
15992/26050 (epoch 30.695), train_loss = 0.89342395, grad/param norm = 1.8476e-01, time/batch = 18.2249s	
15993/26050 (epoch 30.697), train_loss = 0.84287584, grad/param norm = 2.0031e-01, time/batch = 18.3213s	
15994/26050 (epoch 30.699), train_loss = 0.96078495, grad/param norm = 2.2533e-01, time/batch = 17.9914s	
15995/26050 (epoch 30.701), train_loss = 0.81770463, grad/param norm = 1.7762e-01, time/batch = 17.2352s	
15996/26050 (epoch 30.702), train_loss = 0.98511106, grad/param norm = 2.1271e-01, time/batch = 18.4862s	
15997/26050 (epoch 30.704), train_loss = 0.99427364, grad/param norm = 1.9791e-01, time/batch = 18.1552s	
15998/26050 (epoch 30.706), train_loss = 0.85243951, grad/param norm = 2.1262e-01, time/batch = 16.8960s	
15999/26050 (epoch 30.708), train_loss = 0.99111223, grad/param norm = 2.1777e-01, time/batch = 17.0505s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch30.71_1.8289.t7	
16000/26050 (epoch 30.710), train_loss = 0.92856126, grad/param norm = 2.6184e-01, time/batch = 18.7426s	
16001/26050 (epoch 30.712), train_loss = 1.41547349, grad/param norm = 2.7264e-01, time/batch = 16.9616s	
16002/26050 (epoch 30.714), train_loss = 0.81304027, grad/param norm = 1.7710e-01, time/batch = 15.0544s	
16003/26050 (epoch 30.716), train_loss = 1.14714749, grad/param norm = 2.4170e-01, time/batch = 18.4945s	
16004/26050 (epoch 30.718), train_loss = 0.96739466, grad/param norm = 2.1555e-01, time/batch = 18.0778s	
16005/26050 (epoch 30.720), train_loss = 0.91060877, grad/param norm = 2.0389e-01, time/batch = 18.9739s	
16006/26050 (epoch 30.722), train_loss = 0.82276652, grad/param norm = 2.3114e-01, time/batch = 16.5438s	
16007/26050 (epoch 30.724), train_loss = 0.86296467, grad/param norm = 2.0313e-01, time/batch = 17.9845s	
16008/26050 (epoch 30.726), train_loss = 0.98283891, grad/param norm = 2.0940e-01, time/batch = 18.8316s	
16009/26050 (epoch 30.727), train_loss = 0.97206135, grad/param norm = 2.1919e-01, time/batch = 17.6493s	
16010/26050 (epoch 30.729), train_loss = 0.96847951, grad/param norm = 2.0925e-01, time/batch = 18.3899s	
16011/26050 (epoch 30.731), train_loss = 0.96451025, grad/param norm = 2.0889e-01, time/batch = 18.5006s	
16012/26050 (epoch 30.733), train_loss = 0.88905851, grad/param norm = 2.2370e-01, time/batch = 18.1609s	
16013/26050 (epoch 30.735), train_loss = 1.09569548, grad/param norm = 2.4242e-01, time/batch = 17.8933s	
16014/26050 (epoch 30.737), train_loss = 0.87228485, grad/param norm = 2.1632e-01, time/batch = 17.1681s	
16015/26050 (epoch 30.739), train_loss = 0.94123291, grad/param norm = 1.8384e-01, time/batch = 18.4077s	
16016/26050 (epoch 30.741), train_loss = 0.84580482, grad/param norm = 1.8586e-01, time/batch = 17.9554s	
16017/26050 (epoch 30.743), train_loss = 0.93652620, grad/param norm = 2.6094e-01, time/batch = 17.2242s	
16018/26050 (epoch 30.745), train_loss = 0.79763461, grad/param norm = 1.9095e-01, time/batch = 17.7424s	
16019/26050 (epoch 30.747), train_loss = 0.84485165, grad/param norm = 2.0230e-01, time/batch = 15.3074s	
16020/26050 (epoch 30.749), train_loss = 1.01971229, grad/param norm = 2.1804e-01, time/batch = 17.9787s	
16021/26050 (epoch 30.750), train_loss = 0.90004669, grad/param norm = 1.7327e-01, time/batch = 18.4864s	
16022/26050 (epoch 30.752), train_loss = 0.85499892, grad/param norm = 2.0417e-01, time/batch = 17.8097s	
16023/26050 (epoch 30.754), train_loss = 0.91462820, grad/param norm = 1.9929e-01, time/batch = 17.9083s	
16024/26050 (epoch 30.756), train_loss = 0.89615945, grad/param norm = 2.0750e-01, time/batch = 15.5463s	
16025/26050 (epoch 30.758), train_loss = 0.88047461, grad/param norm = 2.1466e-01, time/batch = 15.8034s	
16026/26050 (epoch 30.760), train_loss = 1.05678517, grad/param norm = 2.4172e-01, time/batch = 17.0617s	
16027/26050 (epoch 30.762), train_loss = 0.84916681, grad/param norm = 1.8797e-01, time/batch = 18.4832s	
16028/26050 (epoch 30.764), train_loss = 0.89410854, grad/param norm = 2.5707e-01, time/batch = 18.1497s	
16029/26050 (epoch 30.766), train_loss = 0.94137048, grad/param norm = 2.3634e-01, time/batch = 16.4668s	
16030/26050 (epoch 30.768), train_loss = 0.81588659, grad/param norm = 1.8930e-01, time/batch = 18.2290s	
16031/26050 (epoch 30.770), train_loss = 0.88363876, grad/param norm = 2.0718e-01, time/batch = 17.8922s	
16032/26050 (epoch 30.772), train_loss = 0.89965745, grad/param norm = 1.8668e-01, time/batch = 18.2998s	
16033/26050 (epoch 30.774), train_loss = 0.80271522, grad/param norm = 2.2912e-01, time/batch = 16.2227s	
16034/26050 (epoch 30.775), train_loss = 0.67044361, grad/param norm = 1.9358e-01, time/batch = 17.9976s	
16035/26050 (epoch 30.777), train_loss = 0.87510129, grad/param norm = 1.9593e-01, time/batch = 15.4900s	
16036/26050 (epoch 30.779), train_loss = 0.91835552, grad/param norm = 2.6064e-01, time/batch = 17.8098s	
16037/26050 (epoch 30.781), train_loss = 0.79952939, grad/param norm = 1.9323e-01, time/batch = 17.9872s	
16038/26050 (epoch 30.783), train_loss = 0.79337787, grad/param norm = 1.9636e-01, time/batch = 17.8265s	
16039/26050 (epoch 30.785), train_loss = 0.90565819, grad/param norm = 2.0817e-01, time/batch = 18.5771s	
16040/26050 (epoch 30.787), train_loss = 0.82496836, grad/param norm = 2.0532e-01, time/batch = 17.6227s	
16041/26050 (epoch 30.789), train_loss = 0.83265432, grad/param norm = 2.3346e-01, time/batch = 18.8017s	
16042/26050 (epoch 30.791), train_loss = 0.84094377, grad/param norm = 2.1823e-01, time/batch = 18.9732s	
16043/26050 (epoch 30.793), train_loss = 0.89843746, grad/param norm = 2.2525e-01, time/batch = 16.8019s	
16044/26050 (epoch 30.795), train_loss = 0.73507078, grad/param norm = 1.6202e-01, time/batch = 18.1435s	
16045/26050 (epoch 30.797), train_loss = 0.79756210, grad/param norm = 2.0267e-01, time/batch = 18.1557s	
16046/26050 (epoch 30.798), train_loss = 0.80496875, grad/param norm = 2.0909e-01, time/batch = 14.6051s	
16047/26050 (epoch 30.800), train_loss = 0.79064398, grad/param norm = 1.9048e-01, time/batch = 17.8141s	
16048/26050 (epoch 30.802), train_loss = 0.85083775, grad/param norm = 2.0321e-01, time/batch = 17.9130s	
16049/26050 (epoch 30.804), train_loss = 0.87360289, grad/param norm = 2.0719e-01, time/batch = 17.2169s	
16050/26050 (epoch 30.806), train_loss = 0.96652645, grad/param norm = 2.1408e-01, time/batch = 17.7241s	
16051/26050 (epoch 30.808), train_loss = 0.91000809, grad/param norm = 2.4092e-01, time/batch = 18.5451s	
16052/26050 (epoch 30.810), train_loss = 0.85959311, grad/param norm = 2.0266e-01, time/batch = 18.1554s	
16053/26050 (epoch 30.812), train_loss = 0.75875731, grad/param norm = 1.8109e-01, time/batch = 17.5549s	
16054/26050 (epoch 30.814), train_loss = 0.83169866, grad/param norm = 2.3872e-01, time/batch = 18.3167s	
16055/26050 (epoch 30.816), train_loss = 0.93697094, grad/param norm = 2.2549e-01, time/batch = 17.4863s	
16056/26050 (epoch 30.818), train_loss = 0.98346727, grad/param norm = 2.4081e-01, time/batch = 14.6488s	
16057/26050 (epoch 30.820), train_loss = 0.92689487, grad/param norm = 2.3770e-01, time/batch = 16.6356s	
16058/26050 (epoch 30.821), train_loss = 1.02629243, grad/param norm = 2.3125e-01, time/batch = 18.6351s	
16059/26050 (epoch 30.823), train_loss = 1.07124144, grad/param norm = 2.1052e-01, time/batch = 17.7437s	
16060/26050 (epoch 30.825), train_loss = 0.89766474, grad/param norm = 2.1549e-01, time/batch = 17.2383s	
16061/26050 (epoch 30.827), train_loss = 0.91843131, grad/param norm = 2.2081e-01, time/batch = 18.2412s	
16062/26050 (epoch 30.829), train_loss = 0.97882079, grad/param norm = 2.0485e-01, time/batch = 18.8287s	
16063/26050 (epoch 30.831), train_loss = 1.04230697, grad/param norm = 2.3259e-01, time/batch = 16.8150s	
16064/26050 (epoch 30.833), train_loss = 1.03917219, grad/param norm = 2.2455e-01, time/batch = 15.4548s	
16065/26050 (epoch 30.835), train_loss = 1.05277460, grad/param norm = 2.2769e-01, time/batch = 16.9595s	
16066/26050 (epoch 30.837), train_loss = 0.90825620, grad/param norm = 1.8277e-01, time/batch = 18.5731s	
16067/26050 (epoch 30.839), train_loss = 0.90021363, grad/param norm = 2.3439e-01, time/batch = 17.8131s	
16068/26050 (epoch 30.841), train_loss = 1.00956782, grad/param norm = 2.4235e-01, time/batch = 18.0726s	
16069/26050 (epoch 30.843), train_loss = 0.88918791, grad/param norm = 1.9193e-01, time/batch = 18.7248s	
16070/26050 (epoch 30.845), train_loss = 0.86455250, grad/param norm = 1.8695e-01, time/batch = 17.4738s	
16071/26050 (epoch 30.846), train_loss = 0.95121620, grad/param norm = 2.0738e-01, time/batch = 19.2390s	
16072/26050 (epoch 30.848), train_loss = 0.88901095, grad/param norm = 1.9631e-01, time/batch = 18.1548s	
16073/26050 (epoch 30.850), train_loss = 0.82030396, grad/param norm = 1.8382e-01, time/batch = 17.1511s	
16074/26050 (epoch 30.852), train_loss = 0.91421201, grad/param norm = 1.8773e-01, time/batch = 17.3233s	
16075/26050 (epoch 30.854), train_loss = 0.91685156, grad/param norm = 2.3096e-01, time/batch = 18.0651s	
16076/26050 (epoch 30.856), train_loss = 0.86489437, grad/param norm = 2.1150e-01, time/batch = 16.4586s	
16077/26050 (epoch 30.858), train_loss = 0.83480422, grad/param norm = 1.9465e-01, time/batch = 17.4809s	
16078/26050 (epoch 30.860), train_loss = 0.96568920, grad/param norm = 2.0415e-01, time/batch = 17.5618s	
16079/26050 (epoch 30.862), train_loss = 0.99220435, grad/param norm = 2.0066e-01, time/batch = 18.0643s	
16080/26050 (epoch 30.864), train_loss = 0.94678858, grad/param norm = 2.3712e-01, time/batch = 17.8183s	
16081/26050 (epoch 30.866), train_loss = 0.86192647, grad/param norm = 1.8193e-01, time/batch = 17.3989s	
16082/26050 (epoch 30.868), train_loss = 0.96441426, grad/param norm = 2.4753e-01, time/batch = 16.4856s	
16083/26050 (epoch 30.869), train_loss = 0.82365767, grad/param norm = 1.9301e-01, time/batch = 14.3775s	
16084/26050 (epoch 30.871), train_loss = 0.77660845, grad/param norm = 1.9294e-01, time/batch = 17.6602s	
16085/26050 (epoch 30.873), train_loss = 0.95090048, grad/param norm = 2.2718e-01, time/batch = 17.7350s	
16086/26050 (epoch 30.875), train_loss = 0.88187688, grad/param norm = 2.1633e-01, time/batch = 18.4887s	
16087/26050 (epoch 30.877), train_loss = 0.83641946, grad/param norm = 1.9744e-01, time/batch = 17.3065s	
16088/26050 (epoch 30.879), train_loss = 0.92580303, grad/param norm = 1.7687e-01, time/batch = 16.9683s	
16089/26050 (epoch 30.881), train_loss = 0.99223159, grad/param norm = 2.4399e-01, time/batch = 18.1166s	
16090/26050 (epoch 30.883), train_loss = 0.94401559, grad/param norm = 2.0844e-01, time/batch = 18.1578s	
16091/26050 (epoch 30.885), train_loss = 0.70483974, grad/param norm = 1.8681e-01, time/batch = 30.3574s	
16092/26050 (epoch 30.887), train_loss = 0.97061119, grad/param norm = 1.9647e-01, time/batch = 25.5936s	
16093/26050 (epoch 30.889), train_loss = 0.84387294, grad/param norm = 2.1375e-01, time/batch = 18.1668s	
16094/26050 (epoch 30.891), train_loss = 0.75366709, grad/param norm = 1.7643e-01, time/batch = 18.7414s	
16095/26050 (epoch 30.893), train_loss = 0.78232928, grad/param norm = 1.7627e-01, time/batch = 14.7807s	
16096/26050 (epoch 30.894), train_loss = 0.85926570, grad/param norm = 1.9075e-01, time/batch = 18.0644s	
16097/26050 (epoch 30.896), train_loss = 0.99611763, grad/param norm = 2.2620e-01, time/batch = 18.8820s	
16098/26050 (epoch 30.898), train_loss = 0.85944299, grad/param norm = 2.1027e-01, time/batch = 18.2349s	
16099/26050 (epoch 30.900), train_loss = 0.94195836, grad/param norm = 2.1212e-01, time/batch = 17.5227s	
16100/26050 (epoch 30.902), train_loss = 0.88335994, grad/param norm = 2.0720e-01, time/batch = 17.5578s	
16101/26050 (epoch 30.904), train_loss = 0.87216583, grad/param norm = 1.9406e-01, time/batch = 18.0561s	
16102/26050 (epoch 30.906), train_loss = 0.88565703, grad/param norm = 2.4039e-01, time/batch = 18.7379s	
16103/26050 (epoch 30.908), train_loss = 0.91690896, grad/param norm = 2.0232e-01, time/batch = 16.8806s	
16104/26050 (epoch 30.910), train_loss = 0.87783972, grad/param norm = 2.1111e-01, time/batch = 17.2176s	
16105/26050 (epoch 30.912), train_loss = 1.09217328, grad/param norm = 2.3348e-01, time/batch = 18.4091s	
16106/26050 (epoch 30.914), train_loss = 1.22634167, grad/param norm = 2.2761e-01, time/batch = 17.9848s	
16107/26050 (epoch 30.916), train_loss = 0.99804666, grad/param norm = 2.5245e-01, time/batch = 17.5645s	
16108/26050 (epoch 30.917), train_loss = 0.91281543, grad/param norm = 2.1151e-01, time/batch = 18.2303s	
16109/26050 (epoch 30.919), train_loss = 0.94889692, grad/param norm = 2.1881e-01, time/batch = 18.0672s	
16110/26050 (epoch 30.921), train_loss = 0.85879811, grad/param norm = 2.2217e-01, time/batch = 18.3140s	
16111/26050 (epoch 30.923), train_loss = 0.94189868, grad/param norm = 2.1870e-01, time/batch = 18.6488s	
16112/26050 (epoch 30.925), train_loss = 0.89907885, grad/param norm = 2.0294e-01, time/batch = 16.9627s	
16113/26050 (epoch 30.927), train_loss = 0.82994620, grad/param norm = 1.6582e-01, time/batch = 17.5538s	
16114/26050 (epoch 30.929), train_loss = 0.77214732, grad/param norm = 1.7302e-01, time/batch = 17.8225s	
16115/26050 (epoch 30.931), train_loss = 1.09149446, grad/param norm = 2.4777e-01, time/batch = 15.4811s	
16116/26050 (epoch 30.933), train_loss = 0.88032332, grad/param norm = 2.0306e-01, time/batch = 16.9888s	
16117/26050 (epoch 30.935), train_loss = 0.88120416, grad/param norm = 2.0150e-01, time/batch = 16.3860s	
16118/26050 (epoch 30.937), train_loss = 0.99056520, grad/param norm = 2.0457e-01, time/batch = 15.4873s	
16119/26050 (epoch 30.939), train_loss = 0.82986208, grad/param norm = 1.8266e-01, time/batch = 18.1510s	
16120/26050 (epoch 30.940), train_loss = 0.85259279, grad/param norm = 1.8855e-01, time/batch = 17.5638s	
16121/26050 (epoch 30.942), train_loss = 0.89518073, grad/param norm = 2.1703e-01, time/batch = 18.6476s	
16122/26050 (epoch 30.944), train_loss = 0.86442145, grad/param norm = 1.7624e-01, time/batch = 18.3089s	
16123/26050 (epoch 30.946), train_loss = 1.01813225, grad/param norm = 1.9037e-01, time/batch = 17.4117s	
16124/26050 (epoch 30.948), train_loss = 0.75573504, grad/param norm = 2.0156e-01, time/batch = 16.5802s	
16125/26050 (epoch 30.950), train_loss = 0.88229520, grad/param norm = 1.9317e-01, time/batch = 17.7262s	
16126/26050 (epoch 30.952), train_loss = 0.96587428, grad/param norm = 2.0977e-01, time/batch = 18.4865s	
16127/26050 (epoch 30.954), train_loss = 0.97849996, grad/param norm = 2.4459e-01, time/batch = 18.4082s	
16128/26050 (epoch 30.956), train_loss = 0.88344050, grad/param norm = 2.0308e-01, time/batch = 18.5782s	
16129/26050 (epoch 30.958), train_loss = 0.82134199, grad/param norm = 1.8021e-01, time/batch = 17.9882s	
16130/26050 (epoch 30.960), train_loss = 0.92750707, grad/param norm = 2.1017e-01, time/batch = 16.7252s	
16131/26050 (epoch 30.962), train_loss = 0.87504427, grad/param norm = 1.8683e-01, time/batch = 17.1462s	
16132/26050 (epoch 30.964), train_loss = 0.90297168, grad/param norm = 2.0394e-01, time/batch = 18.0765s	
16133/26050 (epoch 30.965), train_loss = 0.82367446, grad/param norm = 1.9106e-01, time/batch = 14.5645s	
16134/26050 (epoch 30.967), train_loss = 1.19776038, grad/param norm = 2.0649e-01, time/batch = 18.1484s	
16135/26050 (epoch 30.969), train_loss = 0.91879887, grad/param norm = 2.0256e-01, time/batch = 15.0618s	
16136/26050 (epoch 30.971), train_loss = 0.88363668, grad/param norm = 1.9631e-01, time/batch = 17.8996s	
16137/26050 (epoch 30.973), train_loss = 0.91161119, grad/param norm = 1.9987e-01, time/batch = 17.7214s	
16138/26050 (epoch 30.975), train_loss = 0.94651503, grad/param norm = 2.0338e-01, time/batch = 18.4043s	
16139/26050 (epoch 30.977), train_loss = 0.90401956, grad/param norm = 1.8980e-01, time/batch = 16.9012s	
16140/26050 (epoch 30.979), train_loss = 0.75646450, grad/param norm = 2.0410e-01, time/batch = 16.6314s	
16141/26050 (epoch 30.981), train_loss = 1.02432605, grad/param norm = 2.1063e-01, time/batch = 17.7385s	
16142/26050 (epoch 30.983), train_loss = 0.96409619, grad/param norm = 1.9474e-01, time/batch = 18.5856s	
16143/26050 (epoch 30.985), train_loss = 0.94409554, grad/param norm = 2.0928e-01, time/batch = 18.5762s	
16144/26050 (epoch 30.987), train_loss = 0.99933116, grad/param norm = 2.0145e-01, time/batch = 17.7063s	
16145/26050 (epoch 30.988), train_loss = 0.93594411, grad/param norm = 2.0011e-01, time/batch = 17.5671s	
16146/26050 (epoch 30.990), train_loss = 0.78804318, grad/param norm = 1.6334e-01, time/batch = 18.1590s	
16147/26050 (epoch 30.992), train_loss = 1.03815845, grad/param norm = 2.0718e-01, time/batch = 17.8176s	
16148/26050 (epoch 30.994), train_loss = 0.85114917, grad/param norm = 2.2416e-01, time/batch = 18.4839s	
16149/26050 (epoch 30.996), train_loss = 0.82314471, grad/param norm = 2.0954e-01, time/batch = 17.6684s	
16150/26050 (epoch 30.998), train_loss = 0.92818441, grad/param norm = 2.0797e-01, time/batch = 17.9931s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
16151/26050 (epoch 31.000), train_loss = 0.84640789, grad/param norm = 2.0730e-01, time/batch = 18.3247s	
16152/26050 (epoch 31.002), train_loss = 0.96541301, grad/param norm = 2.1970e-01, time/batch = 18.4918s	
16153/26050 (epoch 31.004), train_loss = 0.78789705, grad/param norm = 1.8216e-01, time/batch = 17.0501s	
16154/26050 (epoch 31.006), train_loss = 0.84529663, grad/param norm = 2.1579e-01, time/batch = 17.7870s	
16155/26050 (epoch 31.008), train_loss = 0.84297540, grad/param norm = 2.0315e-01, time/batch = 14.9057s	
16156/26050 (epoch 31.010), train_loss = 0.83586020, grad/param norm = 2.0723e-01, time/batch = 18.4011s	
16157/26050 (epoch 31.012), train_loss = 0.89956879, grad/param norm = 1.9282e-01, time/batch = 16.3844s	
16158/26050 (epoch 31.013), train_loss = 1.14872908, grad/param norm = 2.4543e-01, time/batch = 17.3038s	
16159/26050 (epoch 31.015), train_loss = 0.88905655, grad/param norm = 1.8996e-01, time/batch = 18.3090s	
16160/26050 (epoch 31.017), train_loss = 0.94342892, grad/param norm = 2.1901e-01, time/batch = 17.5561s	
16161/26050 (epoch 31.019), train_loss = 0.79191743, grad/param norm = 1.6864e-01, time/batch = 18.6452s	
16162/26050 (epoch 31.021), train_loss = 0.99359143, grad/param norm = 2.0383e-01, time/batch = 17.6488s	
16163/26050 (epoch 31.023), train_loss = 0.74173709, grad/param norm = 2.0477e-01, time/batch = 17.0471s	
16164/26050 (epoch 31.025), train_loss = 0.88525403, grad/param norm = 1.8067e-01, time/batch = 17.7308s	
16165/26050 (epoch 31.027), train_loss = 0.72983758, grad/param norm = 2.0198e-01, time/batch = 18.6356s	
16166/26050 (epoch 31.029), train_loss = 0.91671108, grad/param norm = 1.8801e-01, time/batch = 17.8178s	
16167/26050 (epoch 31.031), train_loss = 1.01863308, grad/param norm = 2.5996e-01, time/batch = 17.3964s	
16168/26050 (epoch 31.033), train_loss = 0.92582234, grad/param norm = 2.1122e-01, time/batch = 18.5771s	
16169/26050 (epoch 31.035), train_loss = 0.93267407, grad/param norm = 2.0248e-01, time/batch = 15.2144s	
16170/26050 (epoch 31.036), train_loss = 0.79601249, grad/param norm = 2.3603e-01, time/batch = 18.1648s	
16171/26050 (epoch 31.038), train_loss = 0.73216579, grad/param norm = 1.8264e-01, time/batch = 18.4784s	
16172/26050 (epoch 31.040), train_loss = 0.88024316, grad/param norm = 1.9181e-01, time/batch = 18.0734s	
16173/26050 (epoch 31.042), train_loss = 0.77356880, grad/param norm = 1.9867e-01, time/batch = 18.8065s	
16174/26050 (epoch 31.044), train_loss = 0.96871645, grad/param norm = 1.9396e-01, time/batch = 16.9802s	
16175/26050 (epoch 31.046), train_loss = 0.75568106, grad/param norm = 1.7552e-01, time/batch = 18.8169s	
16176/26050 (epoch 31.048), train_loss = 0.90211249, grad/param norm = 2.0006e-01, time/batch = 15.7209s	
16177/26050 (epoch 31.050), train_loss = 0.84046090, grad/param norm = 1.8004e-01, time/batch = 17.7226s	
16178/26050 (epoch 31.052), train_loss = 0.83414967, grad/param norm = 2.3691e-01, time/batch = 17.8078s	
16179/26050 (epoch 31.054), train_loss = 0.73613586, grad/param norm = 1.8162e-01, time/batch = 18.6557s	
16180/26050 (epoch 31.056), train_loss = 0.73802756, grad/param norm = 1.8006e-01, time/batch = 18.6375s	
16181/26050 (epoch 31.058), train_loss = 0.86775659, grad/param norm = 1.7683e-01, time/batch = 17.2270s	
16182/26050 (epoch 31.060), train_loss = 0.93754059, grad/param norm = 1.9214e-01, time/batch = 18.1392s	
16183/26050 (epoch 31.061), train_loss = 0.80093463, grad/param norm = 1.8098e-01, time/batch = 14.9429s	
16184/26050 (epoch 31.063), train_loss = 0.89012699, grad/param norm = 1.9090e-01, time/batch = 18.0468s	
16185/26050 (epoch 31.065), train_loss = 0.74028171, grad/param norm = 1.9267e-01, time/batch = 18.3041s	
16186/26050 (epoch 31.067), train_loss = 0.87215780, grad/param norm = 1.9640e-01, time/batch = 18.4900s	
16187/26050 (epoch 31.069), train_loss = 0.92633015, grad/param norm = 2.4357e-01, time/batch = 17.7321s	
16188/26050 (epoch 31.071), train_loss = 0.94261739, grad/param norm = 2.0767e-01, time/batch = 18.7412s	
16189/26050 (epoch 31.073), train_loss = 1.03611769, grad/param norm = 2.0444e-01, time/batch = 18.3820s	
16190/26050 (epoch 31.075), train_loss = 0.82125877, grad/param norm = 1.8146e-01, time/batch = 15.3212s	
16191/26050 (epoch 31.077), train_loss = 0.85683560, grad/param norm = 2.2702e-01, time/batch = 16.3151s	
16192/26050 (epoch 31.079), train_loss = 0.88888417, grad/param norm = 2.1045e-01, time/batch = 18.2394s	
16193/26050 (epoch 31.081), train_loss = 0.85841867, grad/param norm = 2.0534e-01, time/batch = 18.4080s	
16194/26050 (epoch 31.083), train_loss = 0.99063954, grad/param norm = 1.8800e-01, time/batch = 17.6455s	
16195/26050 (epoch 31.084), train_loss = 0.90647743, grad/param norm = 2.5151e-01, time/batch = 18.6623s	
16196/26050 (epoch 31.086), train_loss = 1.06867679, grad/param norm = 2.2475e-01, time/batch = 15.6321s	
16197/26050 (epoch 31.088), train_loss = 0.84822090, grad/param norm = 1.9493e-01, time/batch = 17.3755s	
16198/26050 (epoch 31.090), train_loss = 0.90076283, grad/param norm = 2.1014e-01, time/batch = 18.1393s	
16199/26050 (epoch 31.092), train_loss = 0.94558389, grad/param norm = 1.8894e-01, time/batch = 18.1606s	
16200/26050 (epoch 31.094), train_loss = 0.77995994, grad/param norm = 2.1301e-01, time/batch = 18.1540s	
16201/26050 (epoch 31.096), train_loss = 0.91636531, grad/param norm = 1.8971e-01, time/batch = 17.8223s	
16202/26050 (epoch 31.098), train_loss = 0.87409897, grad/param norm = 1.9931e-01, time/batch = 14.5569s	
16203/26050 (epoch 31.100), train_loss = 0.80317974, grad/param norm = 1.9580e-01, time/batch = 17.5632s	
16204/26050 (epoch 31.102), train_loss = 0.93959004, grad/param norm = 2.0782e-01, time/batch = 17.9011s	
16205/26050 (epoch 31.104), train_loss = 0.85989106, grad/param norm = 1.9897e-01, time/batch = 18.6384s	
16206/26050 (epoch 31.106), train_loss = 0.92511308, grad/param norm = 2.1570e-01, time/batch = 18.8911s	
16207/26050 (epoch 31.107), train_loss = 0.74614836, grad/param norm = 2.0265e-01, time/batch = 17.7276s	
16208/26050 (epoch 31.109), train_loss = 0.82475036, grad/param norm = 1.9841e-01, time/batch = 16.8924s	
16209/26050 (epoch 31.111), train_loss = 1.04211453, grad/param norm = 2.2362e-01, time/batch = 17.4067s	
16210/26050 (epoch 31.113), train_loss = 0.83626967, grad/param norm = 1.9738e-01, time/batch = 16.3888s	
16211/26050 (epoch 31.115), train_loss = 0.99474251, grad/param norm = 2.1882e-01, time/batch = 17.4642s	
16212/26050 (epoch 31.117), train_loss = 0.88973102, grad/param norm = 1.9168e-01, time/batch = 18.0649s	
16213/26050 (epoch 31.119), train_loss = 0.76684252, grad/param norm = 1.8448e-01, time/batch = 18.8394s	
16214/26050 (epoch 31.121), train_loss = 0.91204046, grad/param norm = 2.0460e-01, time/batch = 18.4127s	
16215/26050 (epoch 31.123), train_loss = 0.81159746, grad/param norm = 1.9382e-01, time/batch = 17.3251s	
16216/26050 (epoch 31.125), train_loss = 0.76613935, grad/param norm = 1.7745e-01, time/batch = 18.1567s	
16217/26050 (epoch 31.127), train_loss = 0.73459636, grad/param norm = 1.7195e-01, time/batch = 18.3273s	
16218/26050 (epoch 31.129), train_loss = 0.72412055, grad/param norm = 1.8794e-01, time/batch = 15.2362s	
16219/26050 (epoch 31.131), train_loss = 0.84749561, grad/param norm = 2.0078e-01, time/batch = 17.3027s	
16220/26050 (epoch 31.132), train_loss = 0.87867639, grad/param norm = 1.8124e-01, time/batch = 17.7399s	
16221/26050 (epoch 31.134), train_loss = 0.90745352, grad/param norm = 2.2048e-01, time/batch = 16.5514s	
16222/26050 (epoch 31.136), train_loss = 0.86409443, grad/param norm = 1.8909e-01, time/batch = 18.3056s	
16223/26050 (epoch 31.138), train_loss = 0.65890058, grad/param norm = 1.8562e-01, time/batch = 16.3011s	
16224/26050 (epoch 31.140), train_loss = 0.72804976, grad/param norm = 1.8265e-01, time/batch = 18.9037s	
16225/26050 (epoch 31.142), train_loss = 0.76989609, grad/param norm = 1.9006e-01, time/batch = 16.9031s	
16226/26050 (epoch 31.144), train_loss = 0.71370943, grad/param norm = 2.0730e-01, time/batch = 15.6555s	
16227/26050 (epoch 31.146), train_loss = 0.67164341, grad/param norm = 1.8655e-01, time/batch = 17.3185s	
16228/26050 (epoch 31.148), train_loss = 0.70169639, grad/param norm = 1.6449e-01, time/batch = 18.0653s	
16229/26050 (epoch 31.150), train_loss = 0.83138173, grad/param norm = 1.9754e-01, time/batch = 18.3995s	
16230/26050 (epoch 31.152), train_loss = 1.04306070, grad/param norm = 2.7237e-01, time/batch = 18.0796s	
16231/26050 (epoch 31.154), train_loss = 0.71018117, grad/param norm = 1.9146e-01, time/batch = 17.3819s	
16232/26050 (epoch 31.155), train_loss = 0.77139054, grad/param norm = 2.2556e-01, time/batch = 17.6215s	
16233/26050 (epoch 31.157), train_loss = 0.86494549, grad/param norm = 2.3663e-01, time/batch = 18.3202s	
16234/26050 (epoch 31.159), train_loss = 0.90784609, grad/param norm = 2.0711e-01, time/batch = 18.7199s	
16235/26050 (epoch 31.161), train_loss = 0.90207735, grad/param norm = 2.0758e-01, time/batch = 17.3125s	
16236/26050 (epoch 31.163), train_loss = 0.73364165, grad/param norm = 1.9884e-01, time/batch = 17.8122s	
16237/26050 (epoch 31.165), train_loss = 0.68862960, grad/param norm = 1.8910e-01, time/batch = 17.4882s	
16238/26050 (epoch 31.167), train_loss = 1.00741478, grad/param norm = 2.4110e-01, time/batch = 16.3075s	
16239/26050 (epoch 31.169), train_loss = 0.90755539, grad/param norm = 2.6523e-01, time/batch = 18.6287s	
16240/26050 (epoch 31.171), train_loss = 0.76391654, grad/param norm = 1.7995e-01, time/batch = 17.0688s	
16241/26050 (epoch 31.173), train_loss = 0.85564539, grad/param norm = 2.0867e-01, time/batch = 15.3893s	
16242/26050 (epoch 31.175), train_loss = 0.86104268, grad/param norm = 1.8650e-01, time/batch = 17.0714s	
16243/26050 (epoch 31.177), train_loss = 0.95422600, grad/param norm = 1.9662e-01, time/batch = 16.5380s	
16244/26050 (epoch 31.179), train_loss = 0.66012886, grad/param norm = 1.7097e-01, time/batch = 15.3790s	
16245/26050 (epoch 31.180), train_loss = 1.09206565, grad/param norm = 2.0573e-01, time/batch = 18.0663s	
16246/26050 (epoch 31.182), train_loss = 1.05413977, grad/param norm = 2.2409e-01, time/batch = 15.8230s	
16247/26050 (epoch 31.184), train_loss = 0.89593318, grad/param norm = 1.9116e-01, time/batch = 17.9931s	
16248/26050 (epoch 31.186), train_loss = 0.73642109, grad/param norm = 1.8385e-01, time/batch = 17.4989s	
16249/26050 (epoch 31.188), train_loss = 0.90258682, grad/param norm = 2.2170e-01, time/batch = 15.5682s	
16250/26050 (epoch 31.190), train_loss = 0.93218744, grad/param norm = 2.3263e-01, time/batch = 18.3999s	
16251/26050 (epoch 31.192), train_loss = 0.94950870, grad/param norm = 1.8469e-01, time/batch = 17.4925s	
16252/26050 (epoch 31.194), train_loss = 0.91996510, grad/param norm = 1.8972e-01, time/batch = 18.4682s	
16253/26050 (epoch 31.196), train_loss = 0.95004425, grad/param norm = 2.0126e-01, time/batch = 15.4596s	
16254/26050 (epoch 31.198), train_loss = 0.79309535, grad/param norm = 1.6722e-01, time/batch = 18.9788s	
16255/26050 (epoch 31.200), train_loss = 0.79092579, grad/param norm = 1.9848e-01, time/batch = 18.1766s	
16256/26050 (epoch 31.202), train_loss = 0.89224515, grad/param norm = 1.8683e-01, time/batch = 17.0722s	
16257/26050 (epoch 31.203), train_loss = 0.97480190, grad/param norm = 1.8333e-01, time/batch = 18.0730s	
16258/26050 (epoch 31.205), train_loss = 0.82960880, grad/param norm = 1.9548e-01, time/batch = 18.4059s	
16259/26050 (epoch 31.207), train_loss = 0.80431863, grad/param norm = 1.9662e-01, time/batch = 16.7292s	
16260/26050 (epoch 31.209), train_loss = 0.94224197, grad/param norm = 1.9454e-01, time/batch = 1.7725s	
16261/26050 (epoch 31.211), train_loss = 0.75571658, grad/param norm = 1.9335e-01, time/batch = 0.6418s	
16262/26050 (epoch 31.213), train_loss = 0.91869080, grad/param norm = 2.4195e-01, time/batch = 0.6498s	
16263/26050 (epoch 31.215), train_loss = 0.84810212, grad/param norm = 2.1248e-01, time/batch = 0.6410s	
16264/26050 (epoch 31.217), train_loss = 0.83682735, grad/param norm = 2.0329e-01, time/batch = 0.6425s	
16265/26050 (epoch 31.219), train_loss = 0.84224512, grad/param norm = 2.0580e-01, time/batch = 0.6422s	
16266/26050 (epoch 31.221), train_loss = 0.78747213, grad/param norm = 2.0009e-01, time/batch = 0.6412s	
16267/26050 (epoch 31.223), train_loss = 0.96113078, grad/param norm = 2.0630e-01, time/batch = 0.7000s	
16268/26050 (epoch 31.225), train_loss = 0.80818717, grad/param norm = 2.2976e-01, time/batch = 0.9683s	
16269/26050 (epoch 31.226), train_loss = 0.91264480, grad/param norm = 2.0492e-01, time/batch = 0.9648s	
16270/26050 (epoch 31.228), train_loss = 1.01908212, grad/param norm = 2.0038e-01, time/batch = 0.9470s	
16271/26050 (epoch 31.230), train_loss = 0.88125574, grad/param norm = 1.8639e-01, time/batch = 0.9447s	
16272/26050 (epoch 31.232), train_loss = 0.95970140, grad/param norm = 2.2130e-01, time/batch = 0.9996s	
16273/26050 (epoch 31.234), train_loss = 0.78455319, grad/param norm = 1.9479e-01, time/batch = 1.8189s	
16274/26050 (epoch 31.236), train_loss = 0.95685756, grad/param norm = 1.9893e-01, time/batch = 1.7699s	
16275/26050 (epoch 31.238), train_loss = 0.74807060, grad/param norm = 2.3113e-01, time/batch = 6.2693s	
16276/26050 (epoch 31.240), train_loss = 0.88449480, grad/param norm = 2.0435e-01, time/batch = 18.6591s	
16277/26050 (epoch 31.242), train_loss = 0.84966106, grad/param norm = 1.9628e-01, time/batch = 17.7235s	
16278/26050 (epoch 31.244), train_loss = 0.90453514, grad/param norm = 2.2545e-01, time/batch = 17.3136s	
16279/26050 (epoch 31.246), train_loss = 0.83810301, grad/param norm = 1.9759e-01, time/batch = 18.7268s	
16280/26050 (epoch 31.248), train_loss = 0.91524129, grad/param norm = 2.2631e-01, time/batch = 15.7088s	
16281/26050 (epoch 31.250), train_loss = 0.89632527, grad/param norm = 2.5184e-01, time/batch = 18.0402s	
16282/26050 (epoch 31.251), train_loss = 0.84379374, grad/param norm = 2.0524e-01, time/batch = 18.0652s	
16283/26050 (epoch 31.253), train_loss = 0.79901886, grad/param norm = 2.1065e-01, time/batch = 18.3694s	
16284/26050 (epoch 31.255), train_loss = 1.04763475, grad/param norm = 2.1130e-01, time/batch = 17.6505s	
16285/26050 (epoch 31.257), train_loss = 0.87809761, grad/param norm = 2.1863e-01, time/batch = 18.0740s	
16286/26050 (epoch 31.259), train_loss = 0.97363940, grad/param norm = 2.1511e-01, time/batch = 14.8195s	
16287/26050 (epoch 31.261), train_loss = 0.77495989, grad/param norm = 1.9282e-01, time/batch = 18.3245s	
16288/26050 (epoch 31.263), train_loss = 0.98825033, grad/param norm = 2.3815e-01, time/batch = 17.2278s	
16289/26050 (epoch 31.265), train_loss = 1.04199935, grad/param norm = 2.9387e-01, time/batch = 18.4936s	
16290/26050 (epoch 31.267), train_loss = 0.99599464, grad/param norm = 1.9240e-01, time/batch = 18.1427s	
16291/26050 (epoch 31.269), train_loss = 1.00369755, grad/param norm = 2.4767e-01, time/batch = 16.4661s	
16292/26050 (epoch 31.271), train_loss = 0.91439472, grad/param norm = 1.9955e-01, time/batch = 18.0330s	
16293/26050 (epoch 31.273), train_loss = 0.81019593, grad/param norm = 1.9468e-01, time/batch = 17.8252s	
16294/26050 (epoch 31.274), train_loss = 0.85406630, grad/param norm = 1.7847e-01, time/batch = 17.7367s	
16295/26050 (epoch 31.276), train_loss = 0.84329369, grad/param norm = 1.8020e-01, time/batch = 14.9636s	
16296/26050 (epoch 31.278), train_loss = 0.97431460, grad/param norm = 2.0829e-01, time/batch = 18.9773s	
16297/26050 (epoch 31.280), train_loss = 0.89124307, grad/param norm = 1.9234e-01, time/batch = 18.8144s	
16298/26050 (epoch 31.282), train_loss = 0.92780727, grad/param norm = 1.8791e-01, time/batch = 17.8878s	
16299/26050 (epoch 31.284), train_loss = 0.86019679, grad/param norm = 1.9179e-01, time/batch = 18.2234s	
16300/26050 (epoch 31.286), train_loss = 0.90833328, grad/param norm = 1.9386e-01, time/batch = 18.7213s	
16301/26050 (epoch 31.288), train_loss = 0.77293617, grad/param norm = 1.8359e-01, time/batch = 14.7941s	
16302/26050 (epoch 31.290), train_loss = 0.89257842, grad/param norm = 1.8469e-01, time/batch = 16.9825s	
16303/26050 (epoch 31.292), train_loss = 0.82677895, grad/param norm = 2.1743e-01, time/batch = 18.0777s	
16304/26050 (epoch 31.294), train_loss = 0.89185443, grad/param norm = 2.1181e-01, time/batch = 18.0648s	
16305/26050 (epoch 31.296), train_loss = 0.96726173, grad/param norm = 2.0108e-01, time/batch = 17.5594s	
16306/26050 (epoch 31.298), train_loss = 0.91874118, grad/param norm = 1.8346e-01, time/batch = 17.5361s	
16307/26050 (epoch 31.299), train_loss = 0.73435802, grad/param norm = 1.8005e-01, time/batch = 18.7331s	
16308/26050 (epoch 31.301), train_loss = 0.75913565, grad/param norm = 2.1227e-01, time/batch = 25.3555s	
16309/26050 (epoch 31.303), train_loss = 0.89534740, grad/param norm = 2.1214e-01, time/batch = 29.5344s	
16310/26050 (epoch 31.305), train_loss = 0.72149200, grad/param norm = 1.8510e-01, time/batch = 17.8351s	
16311/26050 (epoch 31.307), train_loss = 0.81727558, grad/param norm = 2.1717e-01, time/batch = 18.4774s	
16312/26050 (epoch 31.309), train_loss = 0.87558702, grad/param norm = 1.9304e-01, time/batch = 18.4064s	
16313/26050 (epoch 31.311), train_loss = 0.94475479, grad/param norm = 2.5570e-01, time/batch = 17.9829s	
16314/26050 (epoch 31.313), train_loss = 0.89460107, grad/param norm = 2.4396e-01, time/batch = 18.3907s	
16315/26050 (epoch 31.315), train_loss = 0.95803709, grad/param norm = 1.9249e-01, time/batch = 17.9981s	
16316/26050 (epoch 31.317), train_loss = 0.90430687, grad/param norm = 2.1729e-01, time/batch = 17.5509s	
16317/26050 (epoch 31.319), train_loss = 0.80844438, grad/param norm = 2.0508e-01, time/batch = 18.0584s	
16318/26050 (epoch 31.321), train_loss = 0.86466850, grad/param norm = 1.9712e-01, time/batch = 18.2436s	
16319/26050 (epoch 31.322), train_loss = 0.93151350, grad/param norm = 1.8216e-01, time/batch = 17.9188s	
16320/26050 (epoch 31.324), train_loss = 0.70277650, grad/param norm = 1.7562e-01, time/batch = 15.4548s	
16321/26050 (epoch 31.326), train_loss = 0.99904986, grad/param norm = 2.0055e-01, time/batch = 18.3294s	
16322/26050 (epoch 31.328), train_loss = 0.90954021, grad/param norm = 1.7889e-01, time/batch = 18.0582s	
16323/26050 (epoch 31.330), train_loss = 0.77497289, grad/param norm = 2.0608e-01, time/batch = 18.2236s	
16324/26050 (epoch 31.332), train_loss = 0.93981091, grad/param norm = 1.9034e-01, time/batch = 14.8791s	
16325/26050 (epoch 31.334), train_loss = 0.80199971, grad/param norm = 1.9547e-01, time/batch = 18.5588s	
16326/26050 (epoch 31.336), train_loss = 0.82175895, grad/param norm = 2.0822e-01, time/batch = 18.4289s	
16327/26050 (epoch 31.338), train_loss = 0.77349206, grad/param norm = 1.7730e-01, time/batch = 16.2105s	
16328/26050 (epoch 31.340), train_loss = 0.93345235, grad/param norm = 2.0916e-01, time/batch = 18.5007s	
16329/26050 (epoch 31.342), train_loss = 0.96683950, grad/param norm = 2.0201e-01, time/batch = 17.8269s	
16330/26050 (epoch 31.344), train_loss = 0.80548075, grad/param norm = 2.0515e-01, time/batch = 17.5671s	
16331/26050 (epoch 31.345), train_loss = 0.87027987, grad/param norm = 2.1211e-01, time/batch = 16.9042s	
16332/26050 (epoch 31.347), train_loss = 0.99777370, grad/param norm = 2.0117e-01, time/batch = 17.1464s	
16333/26050 (epoch 31.349), train_loss = 0.92432306, grad/param norm = 2.0057e-01, time/batch = 18.5644s	
16334/26050 (epoch 31.351), train_loss = 0.91411910, grad/param norm = 1.9732e-01, time/batch = 17.9778s	
16335/26050 (epoch 31.353), train_loss = 0.90943483, grad/param norm = 2.2627e-01, time/batch = 15.2239s	
16336/26050 (epoch 31.355), train_loss = 0.89968858, grad/param norm = 2.6601e-01, time/batch = 18.3152s	
16337/26050 (epoch 31.357), train_loss = 0.84226434, grad/param norm = 1.8293e-01, time/batch = 17.7363s	
16338/26050 (epoch 31.359), train_loss = 0.95005827, grad/param norm = 2.0749e-01, time/batch = 18.0019s	
16339/26050 (epoch 31.361), train_loss = 0.79261115, grad/param norm = 1.7314e-01, time/batch = 18.5784s	
16340/26050 (epoch 31.363), train_loss = 0.96591576, grad/param norm = 1.9438e-01, time/batch = 17.8140s	
16341/26050 (epoch 31.365), train_loss = 0.84925806, grad/param norm = 1.8575e-01, time/batch = 17.3886s	
16342/26050 (epoch 31.367), train_loss = 0.95099323, grad/param norm = 1.7999e-01, time/batch = 18.6370s	
16343/26050 (epoch 31.369), train_loss = 0.79793738, grad/param norm = 1.7005e-01, time/batch = 16.6391s	
16344/26050 (epoch 31.370), train_loss = 0.79139512, grad/param norm = 1.6533e-01, time/batch = 17.4754s	
16345/26050 (epoch 31.372), train_loss = 0.88579910, grad/param norm = 2.0004e-01, time/batch = 17.8300s	
16346/26050 (epoch 31.374), train_loss = 1.02538129, grad/param norm = 2.1191e-01, time/batch = 18.4875s	
16347/26050 (epoch 31.376), train_loss = 1.04580860, grad/param norm = 2.2265e-01, time/batch = 16.9038s	
16348/26050 (epoch 31.378), train_loss = 0.83210042, grad/param norm = 1.9152e-01, time/batch = 17.2936s	
16349/26050 (epoch 31.380), train_loss = 1.03197627, grad/param norm = 2.4726e-01, time/batch = 17.8332s	
16350/26050 (epoch 31.382), train_loss = 1.13250631, grad/param norm = 2.4134e-01, time/batch = 18.3102s	
16351/26050 (epoch 31.384), train_loss = 0.84979209, grad/param norm = 2.0142e-01, time/batch = 16.8809s	
16352/26050 (epoch 31.386), train_loss = 0.95326923, grad/param norm = 2.2470e-01, time/batch = 17.8161s	
16353/26050 (epoch 31.388), train_loss = 0.92605092, grad/param norm = 2.5068e-01, time/batch = 18.4115s	
16354/26050 (epoch 31.390), train_loss = 0.84381551, grad/param norm = 1.8873e-01, time/batch = 17.1345s	
16355/26050 (epoch 31.392), train_loss = 0.78472602, grad/param norm = 1.8101e-01, time/batch = 14.5351s	
16356/26050 (epoch 31.393), train_loss = 0.94913347, grad/param norm = 2.4124e-01, time/batch = 18.3741s	
16357/26050 (epoch 31.395), train_loss = 0.96294724, grad/param norm = 2.2709e-01, time/batch = 17.8989s	
16358/26050 (epoch 31.397), train_loss = 0.94908196, grad/param norm = 2.0531e-01, time/batch = 17.1385s	
16359/26050 (epoch 31.399), train_loss = 0.83486060, grad/param norm = 1.9378e-01, time/batch = 19.0597s	
16360/26050 (epoch 31.401), train_loss = 0.89524169, grad/param norm = 1.9704e-01, time/batch = 18.5464s	
16361/26050 (epoch 31.403), train_loss = 0.92218359, grad/param norm = 2.3471e-01, time/batch = 17.8841s	
16362/26050 (epoch 31.405), train_loss = 0.89570661, grad/param norm = 1.9982e-01, time/batch = 18.2353s	
16363/26050 (epoch 31.407), train_loss = 1.02296144, grad/param norm = 2.1316e-01, time/batch = 17.8129s	
16364/26050 (epoch 31.409), train_loss = 1.02784053, grad/param norm = 2.2812e-01, time/batch = 17.9871s	
16365/26050 (epoch 31.411), train_loss = 0.95914699, grad/param norm = 2.0462e-01, time/batch = 17.8982s	
16366/26050 (epoch 31.413), train_loss = 1.05313009, grad/param norm = 1.9900e-01, time/batch = 18.1461s	
16367/26050 (epoch 31.415), train_loss = 1.05290886, grad/param norm = 2.2062e-01, time/batch = 14.9777s	
16368/26050 (epoch 31.417), train_loss = 1.08526408, grad/param norm = 2.2767e-01, time/batch = 18.1559s	
16369/26050 (epoch 31.418), train_loss = 0.97059747, grad/param norm = 2.3454e-01, time/batch = 16.4776s	
16370/26050 (epoch 31.420), train_loss = 0.78743001, grad/param norm = 1.8425e-01, time/batch = 17.5300s	
16371/26050 (epoch 31.422), train_loss = 0.76898780, grad/param norm = 1.9780e-01, time/batch = 16.9701s	
16372/26050 (epoch 31.424), train_loss = 1.00198052, grad/param norm = 2.1295e-01, time/batch = 18.0553s	
16373/26050 (epoch 31.426), train_loss = 0.97501020, grad/param norm = 2.2057e-01, time/batch = 18.8114s	
16374/26050 (epoch 31.428), train_loss = 0.84250465, grad/param norm = 1.9492e-01, time/batch = 17.5688s	
16375/26050 (epoch 31.430), train_loss = 1.05222075, grad/param norm = 2.0262e-01, time/batch = 16.2375s	
16376/26050 (epoch 31.432), train_loss = 0.87114427, grad/param norm = 2.0500e-01, time/batch = 16.0597s	
16377/26050 (epoch 31.434), train_loss = 0.86407460, grad/param norm = 1.8965e-01, time/batch = 18.7513s	
16378/26050 (epoch 31.436), train_loss = 1.00103910, grad/param norm = 1.9460e-01, time/batch = 16.2227s	
16379/26050 (epoch 31.438), train_loss = 0.95480719, grad/param norm = 2.1223e-01, time/batch = 16.7174s	
16380/26050 (epoch 31.440), train_loss = 0.93837768, grad/param norm = 2.0164e-01, time/batch = 18.9091s	
16381/26050 (epoch 31.441), train_loss = 0.91562397, grad/param norm = 1.8578e-01, time/batch = 17.7444s	
16382/26050 (epoch 31.443), train_loss = 0.76717125, grad/param norm = 1.5677e-01, time/batch = 17.6565s	
16383/26050 (epoch 31.445), train_loss = 0.81591712, grad/param norm = 1.7971e-01, time/batch = 18.0702s	
16384/26050 (epoch 31.447), train_loss = 1.02009232, grad/param norm = 2.0499e-01, time/batch = 17.9074s	
16385/26050 (epoch 31.449), train_loss = 0.83124951, grad/param norm = 1.9315e-01, time/batch = 16.4413s	
16386/26050 (epoch 31.451), train_loss = 1.03592577, grad/param norm = 2.0176e-01, time/batch = 15.3263s	
16387/26050 (epoch 31.453), train_loss = 0.84786639, grad/param norm = 1.7415e-01, time/batch = 18.2413s	
16388/26050 (epoch 31.455), train_loss = 0.90391759, grad/param norm = 1.8861e-01, time/batch = 17.3980s	
16389/26050 (epoch 31.457), train_loss = 0.88929162, grad/param norm = 1.9421e-01, time/batch = 18.4709s	
16390/26050 (epoch 31.459), train_loss = 1.00747850, grad/param norm = 2.2841e-01, time/batch = 18.3174s	
16391/26050 (epoch 31.461), train_loss = 1.00409930, grad/param norm = 2.1552e-01, time/batch = 17.5620s	
16392/26050 (epoch 31.463), train_loss = 0.86973971, grad/param norm = 1.6763e-01, time/batch = 17.3065s	
16393/26050 (epoch 31.464), train_loss = 0.93611688, grad/param norm = 1.9591e-01, time/batch = 16.3995s	
16394/26050 (epoch 31.466), train_loss = 0.91944904, grad/param norm = 2.0721e-01, time/batch = 17.1240s	
16395/26050 (epoch 31.468), train_loss = 0.99726671, grad/param norm = 1.9247e-01, time/batch = 15.8756s	
16396/26050 (epoch 31.470), train_loss = 1.00053766, grad/param norm = 2.3095e-01, time/batch = 18.6482s	
16397/26050 (epoch 31.472), train_loss = 1.01317155, grad/param norm = 2.3679e-01, time/batch = 18.3131s	
16398/26050 (epoch 31.474), train_loss = 1.01735977, grad/param norm = 2.0273e-01, time/batch = 17.5661s	
16399/26050 (epoch 31.476), train_loss = 0.98337651, grad/param norm = 1.8593e-01, time/batch = 15.6499s	
16400/26050 (epoch 31.478), train_loss = 0.87738070, grad/param norm = 1.8939e-01, time/batch = 16.9792s	
16401/26050 (epoch 31.480), train_loss = 0.87497253, grad/param norm = 1.8121e-01, time/batch = 17.9857s	
16402/26050 (epoch 31.482), train_loss = 0.85907987, grad/param norm = 1.9250e-01, time/batch = 16.6711s	
16403/26050 (epoch 31.484), train_loss = 0.84990374, grad/param norm = 1.9990e-01, time/batch = 18.4026s	
16404/26050 (epoch 31.486), train_loss = 1.04031587, grad/param norm = 2.0044e-01, time/batch = 18.5740s	
16405/26050 (epoch 31.488), train_loss = 1.07129734, grad/param norm = 2.3236e-01, time/batch = 16.7449s	
16406/26050 (epoch 31.489), train_loss = 1.08301416, grad/param norm = 2.5625e-01, time/batch = 16.8123s	
16407/26050 (epoch 31.491), train_loss = 0.83045200, grad/param norm = 2.0465e-01, time/batch = 17.8147s	
16408/26050 (epoch 31.493), train_loss = 0.93671703, grad/param norm = 2.2400e-01, time/batch = 18.5682s	
16409/26050 (epoch 31.495), train_loss = 0.88279578, grad/param norm = 1.7876e-01, time/batch = 16.3901s	
16410/26050 (epoch 31.497), train_loss = 0.80331256, grad/param norm = 1.9035e-01, time/batch = 18.5657s	
16411/26050 (epoch 31.499), train_loss = 0.85378486, grad/param norm = 1.8903e-01, time/batch = 15.8963s	
16412/26050 (epoch 31.501), train_loss = 0.98251247, grad/param norm = 1.9675e-01, time/batch = 16.3004s	
16413/26050 (epoch 31.503), train_loss = 0.84996583, grad/param norm = 1.9088e-01, time/batch = 17.9877s	
16414/26050 (epoch 31.505), train_loss = 1.02627555, grad/param norm = 2.0748e-01, time/batch = 18.9061s	
16415/26050 (epoch 31.507), train_loss = 0.98226863, grad/param norm = 2.8524e-01, time/batch = 17.9033s	
16416/26050 (epoch 31.509), train_loss = 1.04959208, grad/param norm = 2.0904e-01, time/batch = 18.1568s	
16417/26050 (epoch 31.511), train_loss = 0.87011663, grad/param norm = 1.7534e-01, time/batch = 17.9116s	
16418/26050 (epoch 31.512), train_loss = 0.79522107, grad/param norm = 2.0598e-01, time/batch = 18.6538s	
16419/26050 (epoch 31.514), train_loss = 0.97923216, grad/param norm = 2.3172e-01, time/batch = 15.7996s	
16420/26050 (epoch 31.516), train_loss = 1.03803629, grad/param norm = 2.1242e-01, time/batch = 17.4775s	
16421/26050 (epoch 31.518), train_loss = 0.88425811, grad/param norm = 2.2003e-01, time/batch = 18.6561s	
16422/26050 (epoch 31.520), train_loss = 0.91766002, grad/param norm = 2.1956e-01, time/batch = 15.2081s	
16423/26050 (epoch 31.522), train_loss = 0.72204375, grad/param norm = 1.8159e-01, time/batch = 17.9902s	
16424/26050 (epoch 31.524), train_loss = 1.00603244, grad/param norm = 2.4129e-01, time/batch = 15.6337s	
16425/26050 (epoch 31.526), train_loss = 1.01772094, grad/param norm = 2.2002e-01, time/batch = 18.3298s	
16426/26050 (epoch 31.528), train_loss = 0.94583422, grad/param norm = 2.1800e-01, time/batch = 17.4666s	
16427/26050 (epoch 31.530), train_loss = 0.88740901, grad/param norm = 2.3818e-01, time/batch = 16.6217s	
16428/26050 (epoch 31.532), train_loss = 0.94138748, grad/param norm = 1.8939e-01, time/batch = 18.7341s	
16429/26050 (epoch 31.534), train_loss = 0.95932397, grad/param norm = 2.5605e-01, time/batch = 17.0785s	
16430/26050 (epoch 31.536), train_loss = 0.93203698, grad/param norm = 1.9929e-01, time/batch = 18.8125s	
16431/26050 (epoch 31.537), train_loss = 0.98133054, grad/param norm = 2.2253e-01, time/batch = 17.9811s	
16432/26050 (epoch 31.539), train_loss = 0.90573286, grad/param norm = 1.9751e-01, time/batch = 18.0496s	
16433/26050 (epoch 31.541), train_loss = 1.07149991, grad/param norm = 2.3262e-01, time/batch = 17.5667s	
16434/26050 (epoch 31.543), train_loss = 0.76497748, grad/param norm = 2.3751e-01, time/batch = 16.9026s	
16435/26050 (epoch 31.545), train_loss = 0.91943602, grad/param norm = 2.0538e-01, time/batch = 18.0597s	
16436/26050 (epoch 31.547), train_loss = 0.89735729, grad/param norm = 2.2457e-01, time/batch = 17.6541s	
16437/26050 (epoch 31.549), train_loss = 0.77922654, grad/param norm = 2.4408e-01, time/batch = 18.1602s	
16438/26050 (epoch 31.551), train_loss = 0.96208966, grad/param norm = 2.1091e-01, time/batch = 18.0835s	
16439/26050 (epoch 31.553), train_loss = 0.86643574, grad/param norm = 2.1114e-01, time/batch = 17.7338s	
16440/26050 (epoch 31.555), train_loss = 0.80988654, grad/param norm = 2.0625e-01, time/batch = 15.4774s	
16441/26050 (epoch 31.557), train_loss = 0.94271190, grad/param norm = 2.1209e-01, time/batch = 18.6304s	
16442/26050 (epoch 31.559), train_loss = 0.92569303, grad/param norm = 1.9080e-01, time/batch = 17.9818s	
16443/26050 (epoch 31.560), train_loss = 0.86247263, grad/param norm = 2.0242e-01, time/batch = 14.4989s	
16444/26050 (epoch 31.562), train_loss = 0.89557709, grad/param norm = 2.1096e-01, time/batch = 14.4554s	
16445/26050 (epoch 31.564), train_loss = 1.08337946, grad/param norm = 2.1097e-01, time/batch = 14.0750s	
16446/26050 (epoch 31.566), train_loss = 0.84690920, grad/param norm = 1.9800e-01, time/batch = 14.1531s	
16447/26050 (epoch 31.568), train_loss = 0.94365810, grad/param norm = 1.9446e-01, time/batch = 16.8878s	
16448/26050 (epoch 31.570), train_loss = 0.91743041, grad/param norm = 2.2000e-01, time/batch = 18.5742s	
16449/26050 (epoch 31.572), train_loss = 0.91149951, grad/param norm = 1.9951e-01, time/batch = 19.0534s	
16450/26050 (epoch 31.574), train_loss = 0.91395373, grad/param norm = 2.0251e-01, time/batch = 15.0405s	
16451/26050 (epoch 31.576), train_loss = 0.96173718, grad/param norm = 2.2852e-01, time/batch = 14.5445s	
16452/26050 (epoch 31.578), train_loss = 0.90543386, grad/param norm = 2.2570e-01, time/batch = 15.8788s	
16453/26050 (epoch 31.580), train_loss = 0.83119958, grad/param norm = 2.0667e-01, time/batch = 14.3792s	
16454/26050 (epoch 31.582), train_loss = 0.93872642, grad/param norm = 2.0533e-01, time/batch = 14.8859s	
16455/26050 (epoch 31.583), train_loss = 0.99817062, grad/param norm = 2.0333e-01, time/batch = 16.2193s	
16456/26050 (epoch 31.585), train_loss = 0.80957037, grad/param norm = 1.9789e-01, time/batch = 18.5694s	
16457/26050 (epoch 31.587), train_loss = 0.94619641, grad/param norm = 2.4151e-01, time/batch = 14.9095s	
16458/26050 (epoch 31.589), train_loss = 1.04557545, grad/param norm = 2.0950e-01, time/batch = 18.0651s	
16459/26050 (epoch 31.591), train_loss = 0.91211104, grad/param norm = 2.0891e-01, time/batch = 14.9873s	
16460/26050 (epoch 31.593), train_loss = 0.79296893, grad/param norm = 1.8063e-01, time/batch = 18.5857s	
16461/26050 (epoch 31.595), train_loss = 1.00069029, grad/param norm = 2.4870e-01, time/batch = 17.8904s	
16462/26050 (epoch 31.597), train_loss = 0.92189061, grad/param norm = 2.1580e-01, time/batch = 17.9809s	
16463/26050 (epoch 31.599), train_loss = 0.95018740, grad/param norm = 2.1999e-01, time/batch = 17.4885s	
16464/26050 (epoch 31.601), train_loss = 1.07674549, grad/param norm = 1.9810e-01, time/batch = 17.8258s	
16465/26050 (epoch 31.603), train_loss = 0.99233972, grad/param norm = 2.2354e-01, time/batch = 15.5921s	
16466/26050 (epoch 31.605), train_loss = 0.88501603, grad/param norm = 2.3809e-01, time/batch = 17.8819s	
16467/26050 (epoch 31.607), train_loss = 1.01956922, grad/param norm = 2.4366e-01, time/batch = 16.0619s	
16468/26050 (epoch 31.608), train_loss = 0.83151157, grad/param norm = 1.8284e-01, time/batch = 15.3926s	
16469/26050 (epoch 31.610), train_loss = 0.91769980, grad/param norm = 2.2800e-01, time/batch = 17.3803s	
16470/26050 (epoch 31.612), train_loss = 0.87330056, grad/param norm = 1.7925e-01, time/batch = 17.1449s	
16471/26050 (epoch 31.614), train_loss = 0.91897774, grad/param norm = 1.9691e-01, time/batch = 18.5637s	
16472/26050 (epoch 31.616), train_loss = 0.98655340, grad/param norm = 2.1675e-01, time/batch = 15.9606s	
16473/26050 (epoch 31.618), train_loss = 0.86358472, grad/param norm = 1.9813e-01, time/batch = 18.7348s	
16474/26050 (epoch 31.620), train_loss = 0.98032713, grad/param norm = 2.2007e-01, time/batch = 18.3203s	
16475/26050 (epoch 31.622), train_loss = 0.82126827, grad/param norm = 1.9190e-01, time/batch = 16.8981s	
16476/26050 (epoch 31.624), train_loss = 0.76764068, grad/param norm = 1.7150e-01, time/batch = 18.8935s	
16477/26050 (epoch 31.626), train_loss = 0.96153188, grad/param norm = 2.0840e-01, time/batch = 18.5384s	
16478/26050 (epoch 31.628), train_loss = 0.86416937, grad/param norm = 2.4163e-01, time/batch = 17.3940s	
16479/26050 (epoch 31.630), train_loss = 1.04678552, grad/param norm = 1.9209e-01, time/batch = 15.4526s	
16480/26050 (epoch 31.631), train_loss = 1.07385020, grad/param norm = 2.4026e-01, time/batch = 18.4992s	
16481/26050 (epoch 31.633), train_loss = 0.83052948, grad/param norm = 2.0198e-01, time/batch = 18.3188s	
16482/26050 (epoch 31.635), train_loss = 0.87682767, grad/param norm = 1.8806e-01, time/batch = 15.3732s	
16483/26050 (epoch 31.637), train_loss = 0.80866392, grad/param norm = 2.0090e-01, time/batch = 18.8171s	
16484/26050 (epoch 31.639), train_loss = 0.97271857, grad/param norm = 1.9757e-01, time/batch = 17.9040s	
16485/26050 (epoch 31.641), train_loss = 0.86858922, grad/param norm = 1.9833e-01, time/batch = 17.5615s	
16486/26050 (epoch 31.643), train_loss = 0.83665074, grad/param norm = 1.7193e-01, time/batch = 18.6628s	
16487/26050 (epoch 31.645), train_loss = 0.86210476, grad/param norm = 2.0275e-01, time/batch = 15.1156s	
16488/26050 (epoch 31.647), train_loss = 0.82798027, grad/param norm = 1.9286e-01, time/batch = 18.0745s	
16489/26050 (epoch 31.649), train_loss = 0.88737163, grad/param norm = 2.2941e-01, time/batch = 17.8180s	
16490/26050 (epoch 31.651), train_loss = 0.86594077, grad/param norm = 1.9904e-01, time/batch = 18.1561s	
16491/26050 (epoch 31.653), train_loss = 0.88921993, grad/param norm = 2.0546e-01, time/batch = 18.6719s	
16492/26050 (epoch 31.655), train_loss = 0.83545930, grad/param norm = 1.9138e-01, time/batch = 17.2243s	
16493/26050 (epoch 31.656), train_loss = 0.81600979, grad/param norm = 1.8583e-01, time/batch = 18.4736s	
16494/26050 (epoch 31.658), train_loss = 1.08786078, grad/param norm = 2.0953e-01, time/batch = 18.7232s	
16495/26050 (epoch 31.660), train_loss = 0.78499541, grad/param norm = 2.2806e-01, time/batch = 16.8987s	
16496/26050 (epoch 31.662), train_loss = 0.88307915, grad/param norm = 1.8944e-01, time/batch = 15.3793s	
16497/26050 (epoch 31.664), train_loss = 0.89541786, grad/param norm = 1.8814e-01, time/batch = 18.3957s	
16498/26050 (epoch 31.666), train_loss = 0.84930101, grad/param norm = 2.0400e-01, time/batch = 17.6601s	
16499/26050 (epoch 31.668), train_loss = 0.71858645, grad/param norm = 2.0605e-01, time/batch = 17.4754s	
16500/26050 (epoch 31.670), train_loss = 1.04041093, grad/param norm = 2.5071e-01, time/batch = 15.6526s	
16501/26050 (epoch 31.672), train_loss = 0.89580825, grad/param norm = 2.2025e-01, time/batch = 18.4684s	
16502/26050 (epoch 31.674), train_loss = 0.80326851, grad/param norm = 2.1904e-01, time/batch = 18.0596s	
16503/26050 (epoch 31.676), train_loss = 0.95994690, grad/param norm = 2.4237e-01, time/batch = 18.2317s	
16504/26050 (epoch 31.678), train_loss = 0.99275366, grad/param norm = 2.2543e-01, time/batch = 17.3847s	
16505/26050 (epoch 31.679), train_loss = 1.04487302, grad/param norm = 2.3378e-01, time/batch = 18.0291s	
16506/26050 (epoch 31.681), train_loss = 0.93903213, grad/param norm = 2.1600e-01, time/batch = 14.8818s	
16507/26050 (epoch 31.683), train_loss = 0.81263285, grad/param norm = 2.4257e-01, time/batch = 16.2537s	
16508/26050 (epoch 31.685), train_loss = 0.88375226, grad/param norm = 2.1490e-01, time/batch = 17.1578s	
16509/26050 (epoch 31.687), train_loss = 0.80045881, grad/param norm = 1.8754e-01, time/batch = 17.9839s	
16510/26050 (epoch 31.689), train_loss = 0.86821459, grad/param norm = 2.1037e-01, time/batch = 18.2234s	
16511/26050 (epoch 31.691), train_loss = 0.73230587, grad/param norm = 1.6567e-01, time/batch = 17.3016s	
16512/26050 (epoch 31.693), train_loss = 0.85381909, grad/param norm = 1.8818e-01, time/batch = 17.1996s	
16513/26050 (epoch 31.695), train_loss = 0.88863015, grad/param norm = 2.0717e-01, time/batch = 30.8185s	
16514/26050 (epoch 31.697), train_loss = 0.84352517, grad/param norm = 2.0820e-01, time/batch = 26.5153s	
16515/26050 (epoch 31.699), train_loss = 0.93238277, grad/param norm = 2.0900e-01, time/batch = 18.2316s	
16516/26050 (epoch 31.701), train_loss = 0.81331913, grad/param norm = 1.9165e-01, time/batch = 18.5634s	
16517/26050 (epoch 31.702), train_loss = 0.98988174, grad/param norm = 2.2100e-01, time/batch = 17.7940s	
16518/26050 (epoch 31.704), train_loss = 0.99968893, grad/param norm = 2.0900e-01, time/batch = 16.9573s	
16519/26050 (epoch 31.706), train_loss = 0.82962782, grad/param norm = 1.9189e-01, time/batch = 18.5690s	
16520/26050 (epoch 31.708), train_loss = 0.97183873, grad/param norm = 2.1234e-01, time/batch = 18.3292s	
16521/26050 (epoch 31.710), train_loss = 0.92069353, grad/param norm = 2.2676e-01, time/batch = 18.4842s	
16522/26050 (epoch 31.712), train_loss = 0.92776294, grad/param norm = 2.3288e-01, time/batch = 18.6499s	
16523/26050 (epoch 31.714), train_loss = 0.79902418, grad/param norm = 1.6848e-01, time/batch = 16.3024s	
16524/26050 (epoch 31.716), train_loss = 1.12992795, grad/param norm = 2.3377e-01, time/batch = 15.3844s	
16525/26050 (epoch 31.718), train_loss = 0.96684251, grad/param norm = 2.1947e-01, time/batch = 17.7323s	
16526/26050 (epoch 31.720), train_loss = 0.89662910, grad/param norm = 2.1240e-01, time/batch = 15.9663s	
16527/26050 (epoch 31.722), train_loss = 0.80946700, grad/param norm = 1.8289e-01, time/batch = 18.2565s	
16528/26050 (epoch 31.724), train_loss = 0.83697640, grad/param norm = 2.0458e-01, time/batch = 16.3172s	
16529/26050 (epoch 31.726), train_loss = 0.95674798, grad/param norm = 1.9460e-01, time/batch = 16.5542s	
16530/26050 (epoch 31.727), train_loss = 0.96273871, grad/param norm = 2.0971e-01, time/batch = 18.0667s	
16531/26050 (epoch 31.729), train_loss = 0.93404381, grad/param norm = 1.9885e-01, time/batch = 18.3240s	
16532/26050 (epoch 31.731), train_loss = 0.94653086, grad/param norm = 1.9979e-01, time/batch = 17.7329s	
16533/26050 (epoch 31.733), train_loss = 0.87710614, grad/param norm = 2.2591e-01, time/batch = 18.2341s	
16534/26050 (epoch 31.735), train_loss = 1.06583125, grad/param norm = 2.1882e-01, time/batch = 18.9030s	
16535/26050 (epoch 31.737), train_loss = 0.86239489, grad/param norm = 2.0073e-01, time/batch = 16.8164s	
16536/26050 (epoch 31.739), train_loss = 0.94579700, grad/param norm = 1.9250e-01, time/batch = 15.4084s	
16537/26050 (epoch 31.741), train_loss = 0.83636682, grad/param norm = 1.9519e-01, time/batch = 18.0581s	
16538/26050 (epoch 31.743), train_loss = 0.91011926, grad/param norm = 2.2524e-01, time/batch = 18.4047s	
16539/26050 (epoch 31.745), train_loss = 0.78940145, grad/param norm = 1.8678e-01, time/batch = 17.6509s	
16540/26050 (epoch 31.747), train_loss = 0.81473746, grad/param norm = 1.9148e-01, time/batch = 15.7002s	
16541/26050 (epoch 31.749), train_loss = 0.99464695, grad/param norm = 2.0761e-01, time/batch = 16.4678s	
16542/26050 (epoch 31.750), train_loss = 0.88166757, grad/param norm = 1.7217e-01, time/batch = 16.7065s	
16543/26050 (epoch 31.752), train_loss = 0.85805021, grad/param norm = 2.3967e-01, time/batch = 17.9012s	
16544/26050 (epoch 31.754), train_loss = 0.91124789, grad/param norm = 1.9709e-01, time/batch = 17.3285s	
16545/26050 (epoch 31.756), train_loss = 0.89431221, grad/param norm = 3.1182e-01, time/batch = 17.5646s	
16546/26050 (epoch 31.758), train_loss = 0.87658948, grad/param norm = 2.2263e-01, time/batch = 17.3808s	
16547/26050 (epoch 31.760), train_loss = 1.03762357, grad/param norm = 2.1133e-01, time/batch = 18.3232s	
16548/26050 (epoch 31.762), train_loss = 0.87354998, grad/param norm = 2.7806e-01, time/batch = 16.2990s	
16549/26050 (epoch 31.764), train_loss = 0.90139240, grad/param norm = 2.7810e-01, time/batch = 17.1576s	
16550/26050 (epoch 31.766), train_loss = 0.91978607, grad/param norm = 2.1593e-01, time/batch = 17.2438s	
16551/26050 (epoch 31.768), train_loss = 0.79385163, grad/param norm = 1.8949e-01, time/batch = 16.9790s	
16552/26050 (epoch 31.770), train_loss = 0.86313997, grad/param norm = 2.0859e-01, time/batch = 18.4793s	
16553/26050 (epoch 31.772), train_loss = 0.89600927, grad/param norm = 1.8402e-01, time/batch = 14.8988s	
16554/26050 (epoch 31.774), train_loss = 0.78640566, grad/param norm = 2.2728e-01, time/batch = 18.4869s	
16555/26050 (epoch 31.775), train_loss = 0.64708327, grad/param norm = 1.8772e-01, time/batch = 18.8056s	
16556/26050 (epoch 31.777), train_loss = 0.86277255, grad/param norm = 1.9661e-01, time/batch = 18.0542s	
16557/26050 (epoch 31.779), train_loss = 0.88951266, grad/param norm = 2.0307e-01, time/batch = 17.9865s	
16558/26050 (epoch 31.781), train_loss = 0.79425687, grad/param norm = 1.9564e-01, time/batch = 17.4088s	
16559/26050 (epoch 31.783), train_loss = 0.79471944, grad/param norm = 2.0313e-01, time/batch = 16.4825s	
16560/26050 (epoch 31.785), train_loss = 0.89634100, grad/param norm = 2.0126e-01, time/batch = 16.3131s	
16561/26050 (epoch 31.787), train_loss = 0.82667689, grad/param norm = 2.2998e-01, time/batch = 15.4629s	
16562/26050 (epoch 31.789), train_loss = 0.83492104, grad/param norm = 2.2009e-01, time/batch = 18.3110s	
16563/26050 (epoch 31.791), train_loss = 0.83526503, grad/param norm = 2.2380e-01, time/batch = 17.8047s	
16564/26050 (epoch 31.793), train_loss = 0.88968903, grad/param norm = 2.2263e-01, time/batch = 18.9020s	
16565/26050 (epoch 31.795), train_loss = 0.72163370, grad/param norm = 1.6527e-01, time/batch = 17.9026s	
16566/26050 (epoch 31.797), train_loss = 0.78698813, grad/param norm = 1.9581e-01, time/batch = 14.6339s	
16567/26050 (epoch 31.798), train_loss = 0.79889324, grad/param norm = 1.9414e-01, time/batch = 17.8835s	
16568/26050 (epoch 31.800), train_loss = 0.78558307, grad/param norm = 2.0571e-01, time/batch = 17.4829s	
16569/26050 (epoch 31.802), train_loss = 0.86034213, grad/param norm = 2.4398e-01, time/batch = 17.9936s	
16570/26050 (epoch 31.804), train_loss = 0.85720892, grad/param norm = 1.8998e-01, time/batch = 16.9701s	
16571/26050 (epoch 31.806), train_loss = 0.95464974, grad/param norm = 2.3452e-01, time/batch = 18.4755s	
16572/26050 (epoch 31.808), train_loss = 0.89685761, grad/param norm = 2.0895e-01, time/batch = 18.5691s	
16573/26050 (epoch 31.810), train_loss = 0.86879326, grad/param norm = 2.1255e-01, time/batch = 16.8747s	
16574/26050 (epoch 31.812), train_loss = 0.77424609, grad/param norm = 2.2636e-01, time/batch = 16.8950s	
16575/26050 (epoch 31.814), train_loss = 0.81169785, grad/param norm = 2.2798e-01, time/batch = 14.4647s	
16576/26050 (epoch 31.816), train_loss = 0.93141088, grad/param norm = 2.2990e-01, time/batch = 16.9698s	
16577/26050 (epoch 31.818), train_loss = 0.97773588, grad/param norm = 2.5035e-01, time/batch = 17.4907s	
16578/26050 (epoch 31.820), train_loss = 0.89637542, grad/param norm = 2.0052e-01, time/batch = 18.3934s	
16579/26050 (epoch 31.821), train_loss = 0.98893868, grad/param norm = 2.2739e-01, time/batch = 18.8140s	
16580/26050 (epoch 31.823), train_loss = 1.06944518, grad/param norm = 2.1830e-01, time/batch = 17.8071s	
16581/26050 (epoch 31.825), train_loss = 0.90679631, grad/param norm = 2.1858e-01, time/batch = 18.5606s	
16582/26050 (epoch 31.827), train_loss = 0.90888017, grad/param norm = 2.3328e-01, time/batch = 18.3161s	
16583/26050 (epoch 31.829), train_loss = 0.98256380, grad/param norm = 2.3273e-01, time/batch = 17.0536s	
16584/26050 (epoch 31.831), train_loss = 1.05377977, grad/param norm = 2.9959e-01, time/batch = 17.9901s	
16585/26050 (epoch 31.833), train_loss = 1.04421529, grad/param norm = 2.3411e-01, time/batch = 18.3321s	
16586/26050 (epoch 31.835), train_loss = 1.04296394, grad/param norm = 2.2413e-01, time/batch = 16.4617s	
16587/26050 (epoch 31.837), train_loss = 0.90270338, grad/param norm = 1.9396e-01, time/batch = 18.0622s	
16588/26050 (epoch 31.839), train_loss = 0.89681993, grad/param norm = 2.2827e-01, time/batch = 18.0751s	
16589/26050 (epoch 31.841), train_loss = 0.98071337, grad/param norm = 2.1366e-01, time/batch = 16.9677s	
16590/26050 (epoch 31.843), train_loss = 0.88353465, grad/param norm = 2.0081e-01, time/batch = 16.5617s	
16591/26050 (epoch 31.845), train_loss = 0.85499395, grad/param norm = 1.9915e-01, time/batch = 16.6486s	
16592/26050 (epoch 31.846), train_loss = 0.94685941, grad/param norm = 2.1990e-01, time/batch = 18.4905s	
16593/26050 (epoch 31.848), train_loss = 0.87683249, grad/param norm = 1.9639e-01, time/batch = 18.1469s	
16594/26050 (epoch 31.850), train_loss = 0.80598492, grad/param norm = 1.8981e-01, time/batch = 17.6562s	
16595/26050 (epoch 31.852), train_loss = 0.92435881, grad/param norm = 1.9620e-01, time/batch = 18.7419s	
16596/26050 (epoch 31.854), train_loss = 0.89714477, grad/param norm = 2.0884e-01, time/batch = 17.8808s	
16597/26050 (epoch 31.856), train_loss = 0.86747703, grad/param norm = 2.5598e-01, time/batch = 16.5662s	
16598/26050 (epoch 31.858), train_loss = 0.81604799, grad/param norm = 1.9557e-01, time/batch = 17.4554s	
16599/26050 (epoch 31.860), train_loss = 0.95267862, grad/param norm = 2.0949e-01, time/batch = 17.7245s	
16600/26050 (epoch 31.862), train_loss = 0.97752591, grad/param norm = 1.9772e-01, time/batch = 15.3070s	
16601/26050 (epoch 31.864), train_loss = 0.91830059, grad/param norm = 2.1946e-01, time/batch = 18.5496s	
16602/26050 (epoch 31.866), train_loss = 0.85051927, grad/param norm = 1.8540e-01, time/batch = 18.8188s	
16603/26050 (epoch 31.868), train_loss = 0.94635530, grad/param norm = 2.2931e-01, time/batch = 17.9778s	
16604/26050 (epoch 31.869), train_loss = 0.80827811, grad/param norm = 1.9855e-01, time/batch = 17.2384s	
16605/26050 (epoch 31.871), train_loss = 0.76533791, grad/param norm = 1.8869e-01, time/batch = 18.6603s	
16606/26050 (epoch 31.873), train_loss = 0.94317221, grad/param norm = 2.1346e-01, time/batch = 18.2382s	
16607/26050 (epoch 31.875), train_loss = 0.86278082, grad/param norm = 2.0222e-01, time/batch = 18.1428s	
16608/26050 (epoch 31.877), train_loss = 0.84367849, grad/param norm = 2.0286e-01, time/batch = 18.4854s	
16609/26050 (epoch 31.879), train_loss = 0.91316753, grad/param norm = 1.9278e-01, time/batch = 16.9827s	
16610/26050 (epoch 31.881), train_loss = 0.97408962, grad/param norm = 2.1999e-01, time/batch = 16.2864s	
16611/26050 (epoch 31.883), train_loss = 0.93432099, grad/param norm = 2.1692e-01, time/batch = 17.7297s	
16612/26050 (epoch 31.885), train_loss = 0.69044497, grad/param norm = 1.9509e-01, time/batch = 18.6614s	
16613/26050 (epoch 31.887), train_loss = 0.95837648, grad/param norm = 2.0903e-01, time/batch = 15.3045s	
16614/26050 (epoch 31.889), train_loss = 0.83301423, grad/param norm = 1.9422e-01, time/batch = 16.9820s	
16615/26050 (epoch 31.891), train_loss = 0.74692787, grad/param norm = 1.9048e-01, time/batch = 18.7346s	
16616/26050 (epoch 31.893), train_loss = 0.77271517, grad/param norm = 1.9848e-01, time/batch = 18.8236s	
16617/26050 (epoch 31.894), train_loss = 0.84720745, grad/param norm = 2.0405e-01, time/batch = 17.6362s	
16618/26050 (epoch 31.896), train_loss = 0.99710597, grad/param norm = 2.4424e-01, time/batch = 18.4798s	
16619/26050 (epoch 31.898), train_loss = 0.84426908, grad/param norm = 1.9422e-01, time/batch = 18.7269s	
16620/26050 (epoch 31.900), train_loss = 0.92982951, grad/param norm = 2.2631e-01, time/batch = 15.3738s	
16621/26050 (epoch 31.902), train_loss = 0.86572933, grad/param norm = 2.0360e-01, time/batch = 18.6619s	
16622/26050 (epoch 31.904), train_loss = 0.85408075, grad/param norm = 1.8832e-01, time/batch = 17.3422s	
16623/26050 (epoch 31.906), train_loss = 0.86445618, grad/param norm = 2.1244e-01, time/batch = 16.5439s	
16624/26050 (epoch 31.908), train_loss = 0.90710715, grad/param norm = 2.0117e-01, time/batch = 18.0713s	
16625/26050 (epoch 31.910), train_loss = 0.87478223, grad/param norm = 2.1688e-01, time/batch = 17.6437s	
16626/26050 (epoch 31.912), train_loss = 1.07160252, grad/param norm = 2.3884e-01, time/batch = 18.0544s	
16627/26050 (epoch 31.914), train_loss = 1.21700356, grad/param norm = 2.3279e-01, time/batch = 18.0435s	
16628/26050 (epoch 31.916), train_loss = 0.99940446, grad/param norm = 2.6720e-01, time/batch = 18.2348s	
16629/26050 (epoch 31.917), train_loss = 0.90699200, grad/param norm = 2.2334e-01, time/batch = 15.9813s	
16630/26050 (epoch 31.919), train_loss = 0.96789402, grad/param norm = 2.9410e-01, time/batch = 17.1453s	
16631/26050 (epoch 31.921), train_loss = 0.86486347, grad/param norm = 2.4944e-01, time/batch = 14.7195s	
16632/26050 (epoch 31.923), train_loss = 0.91583956, grad/param norm = 2.0810e-01, time/batch = 16.9661s	
16633/26050 (epoch 31.925), train_loss = 0.88944146, grad/param norm = 1.9743e-01, time/batch = 18.6628s	
16634/26050 (epoch 31.927), train_loss = 0.81633197, grad/param norm = 1.5778e-01, time/batch = 17.1502s	
16635/26050 (epoch 31.929), train_loss = 0.75107967, grad/param norm = 1.8036e-01, time/batch = 18.8168s	
16636/26050 (epoch 31.931), train_loss = 1.10212745, grad/param norm = 2.8714e-01, time/batch = 18.5553s	
16637/26050 (epoch 31.933), train_loss = 0.87525155, grad/param norm = 2.1108e-01, time/batch = 17.5663s	
16638/26050 (epoch 31.935), train_loss = 0.86790230, grad/param norm = 1.9578e-01, time/batch = 17.9272s	
16639/26050 (epoch 31.937), train_loss = 0.96836212, grad/param norm = 2.0229e-01, time/batch = 18.0743s	
16640/26050 (epoch 31.939), train_loss = 0.82069030, grad/param norm = 1.8499e-01, time/batch = 16.1616s	
16641/26050 (epoch 31.940), train_loss = 0.85691045, grad/param norm = 1.8970e-01, time/batch = 17.8888s	
16642/26050 (epoch 31.942), train_loss = 0.88179607, grad/param norm = 2.0587e-01, time/batch = 17.4911s	
16643/26050 (epoch 31.944), train_loss = 0.85461261, grad/param norm = 1.8438e-01, time/batch = 15.8041s	
16644/26050 (epoch 31.946), train_loss = 1.01085262, grad/param norm = 1.9756e-01, time/batch = 17.9795s	
16645/26050 (epoch 31.948), train_loss = 0.75232812, grad/param norm = 1.9030e-01, time/batch = 18.1491s	
16646/26050 (epoch 31.950), train_loss = 0.88748152, grad/param norm = 2.2132e-01, time/batch = 16.2371s	
16647/26050 (epoch 31.952), train_loss = 0.95268528, grad/param norm = 2.1206e-01, time/batch = 17.9661s	
16648/26050 (epoch 31.954), train_loss = 0.97708007, grad/param norm = 2.1835e-01, time/batch = 16.9809s	
16649/26050 (epoch 31.956), train_loss = 0.86127853, grad/param norm = 2.0855e-01, time/batch = 18.5562s	
16650/26050 (epoch 31.958), train_loss = 0.80423669, grad/param norm = 1.7491e-01, time/batch = 18.9832s	
16651/26050 (epoch 31.960), train_loss = 0.92571137, grad/param norm = 2.1034e-01, time/batch = 17.0556s	
16652/26050 (epoch 31.962), train_loss = 0.85811667, grad/param norm = 1.7478e-01, time/batch = 15.3863s	
16653/26050 (epoch 31.964), train_loss = 0.87613964, grad/param norm = 2.0754e-01, time/batch = 18.9082s	
16654/26050 (epoch 31.965), train_loss = 0.82075207, grad/param norm = 2.2512e-01, time/batch = 18.2390s	
16655/26050 (epoch 31.967), train_loss = 1.19721140, grad/param norm = 2.0422e-01, time/batch = 18.5651s	
16656/26050 (epoch 31.969), train_loss = 0.90415866, grad/param norm = 1.9351e-01, time/batch = 17.8297s	
16657/26050 (epoch 31.971), train_loss = 0.88491710, grad/param norm = 1.9536e-01, time/batch = 18.0688s	
16658/26050 (epoch 31.973), train_loss = 0.89094842, grad/param norm = 1.8663e-01, time/batch = 17.9058s	
16659/26050 (epoch 31.975), train_loss = 0.92924485, grad/param norm = 2.0320e-01, time/batch = 17.9567s	
16660/26050 (epoch 31.977), train_loss = 0.89775988, grad/param norm = 1.8481e-01, time/batch = 18.5748s	
16661/26050 (epoch 31.979), train_loss = 0.73616720, grad/param norm = 1.9846e-01, time/batch = 14.4640s	
16662/26050 (epoch 31.981), train_loss = 1.00684494, grad/param norm = 1.9582e-01, time/batch = 18.4971s	
16663/26050 (epoch 31.983), train_loss = 0.94724047, grad/param norm = 2.0149e-01, time/batch = 17.8250s	
16664/26050 (epoch 31.985), train_loss = 0.93366479, grad/param norm = 2.0686e-01, time/batch = 17.1458s	
16665/26050 (epoch 31.987), train_loss = 1.00057705, grad/param norm = 2.2239e-01, time/batch = 17.2357s	
16666/26050 (epoch 31.988), train_loss = 0.93836650, grad/param norm = 2.4016e-01, time/batch = 16.7398s	
16667/26050 (epoch 31.990), train_loss = 0.78087472, grad/param norm = 1.7176e-01, time/batch = 18.3067s	
16668/26050 (epoch 31.992), train_loss = 1.03799067, grad/param norm = 2.1191e-01, time/batch = 16.4047s	
16669/26050 (epoch 31.994), train_loss = 0.85573229, grad/param norm = 2.1948e-01, time/batch = 18.3071s	
16670/26050 (epoch 31.996), train_loss = 0.82013581, grad/param norm = 2.3006e-01, time/batch = 18.7313s	
16671/26050 (epoch 31.998), train_loss = 0.90713887, grad/param norm = 2.0448e-01, time/batch = 17.4016s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
16672/26050 (epoch 32.000), train_loss = 0.84726465, grad/param norm = 2.2167e-01, time/batch = 16.8877s	
16673/26050 (epoch 32.002), train_loss = 0.94726042, grad/param norm = 2.1630e-01, time/batch = 17.4082s	
16674/26050 (epoch 32.004), train_loss = 0.79611668, grad/param norm = 2.1852e-01, time/batch = 15.2327s	
16675/26050 (epoch 32.006), train_loss = 0.84267894, grad/param norm = 2.3563e-01, time/batch = 17.5626s	
16676/26050 (epoch 32.008), train_loss = 0.84065522, grad/param norm = 2.0321e-01, time/batch = 15.1389s	
16677/26050 (epoch 32.010), train_loss = 0.81725989, grad/param norm = 1.8857e-01, time/batch = 18.2444s	
16678/26050 (epoch 32.012), train_loss = 0.89948700, grad/param norm = 1.9567e-01, time/batch = 17.6385s	
16679/26050 (epoch 32.013), train_loss = 1.12469875, grad/param norm = 2.2758e-01, time/batch = 17.6634s	
16680/26050 (epoch 32.015), train_loss = 0.88004206, grad/param norm = 1.7238e-01, time/batch = 17.2466s	
16681/26050 (epoch 32.017), train_loss = 0.93737563, grad/param norm = 1.9892e-01, time/batch = 18.5681s	
16682/26050 (epoch 32.019), train_loss = 0.78021854, grad/param norm = 1.6118e-01, time/batch = 16.4637s	
16683/26050 (epoch 32.021), train_loss = 0.98374241, grad/param norm = 1.9547e-01, time/batch = 17.8969s	
16684/26050 (epoch 32.023), train_loss = 0.73557059, grad/param norm = 1.9104e-01, time/batch = 16.2263s	
16685/26050 (epoch 32.025), train_loss = 0.88140333, grad/param norm = 1.9727e-01, time/batch = 16.1368s	
16686/26050 (epoch 32.027), train_loss = 0.72313823, grad/param norm = 2.0525e-01, time/batch = 16.1189s	
16687/26050 (epoch 32.029), train_loss = 0.90558834, grad/param norm = 1.8133e-01, time/batch = 18.6329s	
16688/26050 (epoch 32.031), train_loss = 1.01032918, grad/param norm = 2.2879e-01, time/batch = 18.2351s	
16689/26050 (epoch 32.033), train_loss = 0.91510798, grad/param norm = 2.0173e-01, time/batch = 18.0622s	
16690/26050 (epoch 32.035), train_loss = 0.91965261, grad/param norm = 1.8837e-01, time/batch = 15.3898s	
16691/26050 (epoch 32.036), train_loss = 0.79442989, grad/param norm = 2.3360e-01, time/batch = 18.4900s	
16692/26050 (epoch 32.038), train_loss = 0.73062661, grad/param norm = 1.8359e-01, time/batch = 17.2335s	
16693/26050 (epoch 32.040), train_loss = 0.86410323, grad/param norm = 2.0108e-01, time/batch = 17.8904s	
16694/26050 (epoch 32.042), train_loss = 0.75422990, grad/param norm = 2.0090e-01, time/batch = 18.3927s	
16695/26050 (epoch 32.044), train_loss = 0.96065487, grad/param norm = 1.9198e-01, time/batch = 17.9043s	
16696/26050 (epoch 32.046), train_loss = 0.73768798, grad/param norm = 1.6856e-01, time/batch = 17.1463s	
16697/26050 (epoch 32.048), train_loss = 0.87929269, grad/param norm = 1.8879e-01, time/batch = 17.6425s	
16698/26050 (epoch 32.050), train_loss = 0.83105644, grad/param norm = 1.9773e-01, time/batch = 18.4190s	
16699/26050 (epoch 32.052), train_loss = 0.80930971, grad/param norm = 1.9984e-01, time/batch = 16.2908s	
16700/26050 (epoch 32.054), train_loss = 0.73111081, grad/param norm = 1.9057e-01, time/batch = 17.8913s	
16701/26050 (epoch 32.056), train_loss = 0.70993837, grad/param norm = 1.6712e-01, time/batch = 16.8200s	
16702/26050 (epoch 32.058), train_loss = 0.86880672, grad/param norm = 1.8912e-01, time/batch = 15.8956s	
16703/26050 (epoch 32.060), train_loss = 0.93913637, grad/param norm = 2.0161e-01, time/batch = 17.9160s	
16704/26050 (epoch 32.061), train_loss = 0.80031338, grad/param norm = 1.8826e-01, time/batch = 17.4672s	
16705/26050 (epoch 32.063), train_loss = 0.87254885, grad/param norm = 1.7835e-01, time/batch = 18.2311s	
16706/26050 (epoch 32.065), train_loss = 0.72671005, grad/param norm = 1.6663e-01, time/batch = 17.8793s	
16707/26050 (epoch 32.067), train_loss = 0.86439165, grad/param norm = 1.9640e-01, time/batch = 18.0755s	
16708/26050 (epoch 32.069), train_loss = 0.91555616, grad/param norm = 2.1622e-01, time/batch = 16.7321s	
16709/26050 (epoch 32.071), train_loss = 0.93127902, grad/param norm = 2.0354e-01, time/batch = 18.1347s	
16710/26050 (epoch 32.073), train_loss = 1.02220052, grad/param norm = 2.0032e-01, time/batch = 18.7436s	
16711/26050 (epoch 32.075), train_loss = 0.83460317, grad/param norm = 1.9424e-01, time/batch = 18.5827s	
16712/26050 (epoch 32.077), train_loss = 0.83764221, grad/param norm = 1.9483e-01, time/batch = 17.6529s	
16713/26050 (epoch 32.079), train_loss = 0.87058928, grad/param norm = 2.2176e-01, time/batch = 18.3927s	
16714/26050 (epoch 32.081), train_loss = 0.85069414, grad/param norm = 1.8142e-01, time/batch = 17.0620s	
16715/26050 (epoch 32.083), train_loss = 0.98537823, grad/param norm = 1.9618e-01, time/batch = 18.1393s	
16716/26050 (epoch 32.084), train_loss = 0.89035089, grad/param norm = 2.4325e-01, time/batch = 50.6896s	
16717/26050 (epoch 32.086), train_loss = 1.03446989, grad/param norm = 2.3289e-01, time/batch = 36.8583s	
16718/26050 (epoch 32.088), train_loss = 0.85661929, grad/param norm = 2.0364e-01, time/batch = 15.3344s	
16719/26050 (epoch 32.090), train_loss = 0.90231957, grad/param norm = 2.1835e-01, time/batch = 16.6367s	
16720/26050 (epoch 32.092), train_loss = 0.92659615, grad/param norm = 1.9532e-01, time/batch = 17.2124s	
16721/26050 (epoch 32.094), train_loss = 0.77202294, grad/param norm = 1.9171e-01, time/batch = 17.9022s	
16722/26050 (epoch 32.096), train_loss = 0.90267442, grad/param norm = 1.9095e-01, time/batch = 18.7382s	
16723/26050 (epoch 32.098), train_loss = 0.86430601, grad/param norm = 1.8711e-01, time/batch = 15.4538s	
16724/26050 (epoch 32.100), train_loss = 0.80372264, grad/param norm = 2.0892e-01, time/batch = 17.8193s	
16725/26050 (epoch 32.102), train_loss = 0.91054282, grad/param norm = 1.9967e-01, time/batch = 18.6582s	
16726/26050 (epoch 32.104), train_loss = 0.84757708, grad/param norm = 1.9558e-01, time/batch = 17.7402s	
16727/26050 (epoch 32.106), train_loss = 0.90870328, grad/param norm = 2.1047e-01, time/batch = 18.5767s	
16728/26050 (epoch 32.107), train_loss = 0.74698194, grad/param norm = 1.8979e-01, time/batch = 17.4914s	
16729/26050 (epoch 32.109), train_loss = 0.81418006, grad/param norm = 1.8473e-01, time/batch = 18.6502s	
16730/26050 (epoch 32.111), train_loss = 1.01108258, grad/param norm = 2.2044e-01, time/batch = 15.3762s	
16731/26050 (epoch 32.113), train_loss = 0.85403950, grad/param norm = 1.9899e-01, time/batch = 16.9094s	
16732/26050 (epoch 32.115), train_loss = 0.98733685, grad/param norm = 2.0685e-01, time/batch = 16.8831s	
16733/26050 (epoch 32.117), train_loss = 0.87979870, grad/param norm = 1.8697e-01, time/batch = 17.5700s	
16734/26050 (epoch 32.119), train_loss = 0.75576515, grad/param norm = 1.7896e-01, time/batch = 18.1452s	
16735/26050 (epoch 32.121), train_loss = 0.89278315, grad/param norm = 1.9334e-01, time/batch = 17.4203s	
16736/26050 (epoch 32.123), train_loss = 0.80087209, grad/param norm = 1.8841e-01, time/batch = 18.1623s	
16737/26050 (epoch 32.125), train_loss = 0.77257445, grad/param norm = 1.9399e-01, time/batch = 17.9867s	
16738/26050 (epoch 32.127), train_loss = 0.73748969, grad/param norm = 1.9328e-01, time/batch = 14.7161s	
16739/26050 (epoch 32.129), train_loss = 0.71151455, grad/param norm = 1.9572e-01, time/batch = 17.8126s	
16740/26050 (epoch 32.131), train_loss = 0.83216984, grad/param norm = 1.9386e-01, time/batch = 17.4856s	
16741/26050 (epoch 32.132), train_loss = 0.86744152, grad/param norm = 1.8050e-01, time/batch = 18.2457s	
16742/26050 (epoch 32.134), train_loss = 0.89377559, grad/param norm = 2.1471e-01, time/batch = 14.9857s	
16743/26050 (epoch 32.136), train_loss = 0.86102043, grad/param norm = 1.8155e-01, time/batch = 14.8132s	
16744/26050 (epoch 32.138), train_loss = 0.63365757, grad/param norm = 1.7078e-01, time/batch = 17.7989s	
16745/26050 (epoch 32.140), train_loss = 0.73165971, grad/param norm = 1.9294e-01, time/batch = 18.2471s	
16746/26050 (epoch 32.142), train_loss = 0.76153719, grad/param norm = 1.8886e-01, time/batch = 17.6565s	
16747/26050 (epoch 32.144), train_loss = 0.70051958, grad/param norm = 1.9892e-01, time/batch = 16.0474s	
16748/26050 (epoch 32.146), train_loss = 0.67127339, grad/param norm = 1.8263e-01, time/batch = 17.9520s	
16749/26050 (epoch 32.148), train_loss = 0.68895277, grad/param norm = 1.7105e-01, time/batch = 17.8846s	
16750/26050 (epoch 32.150), train_loss = 0.82333395, grad/param norm = 2.0522e-01, time/batch = 17.3249s	
16751/26050 (epoch 32.152), train_loss = 1.02260787, grad/param norm = 2.7506e-01, time/batch = 17.3025s	
16752/26050 (epoch 32.154), train_loss = 0.69558675, grad/param norm = 1.8081e-01, time/batch = 18.7199s	
16753/26050 (epoch 32.155), train_loss = 0.75618678, grad/param norm = 2.2182e-01, time/batch = 18.5703s	
16754/26050 (epoch 32.157), train_loss = 0.85811105, grad/param norm = 3.1110e-01, time/batch = 16.4562s	
16755/26050 (epoch 32.159), train_loss = 0.91672772, grad/param norm = 2.3462e-01, time/batch = 18.4833s	
16756/26050 (epoch 32.161), train_loss = 0.87520614, grad/param norm = 2.3263e-01, time/batch = 17.8328s	
16757/26050 (epoch 32.163), train_loss = 0.73241293, grad/param norm = 1.9802e-01, time/batch = 17.8018s	
16758/26050 (epoch 32.165), train_loss = 0.67315236, grad/param norm = 1.8202e-01, time/batch = 18.7233s	
16759/26050 (epoch 32.167), train_loss = 1.00756563, grad/param norm = 2.4628e-01, time/batch = 18.4115s	
16760/26050 (epoch 32.169), train_loss = 0.87379929, grad/param norm = 2.0434e-01, time/batch = 14.7942s	
16761/26050 (epoch 32.171), train_loss = 0.74629331, grad/param norm = 1.7290e-01, time/batch = 17.9360s	
16762/26050 (epoch 32.173), train_loss = 0.82072333, grad/param norm = 1.8346e-01, time/batch = 18.4675s	
16763/26050 (epoch 32.175), train_loss = 0.83447369, grad/param norm = 1.8873e-01, time/batch = 18.6395s	
16764/26050 (epoch 32.177), train_loss = 0.95401963, grad/param norm = 2.1501e-01, time/batch = 16.8133s	
16765/26050 (epoch 32.179), train_loss = 0.64786394, grad/param norm = 1.7477e-01, time/batch = 17.2110s	
16766/26050 (epoch 32.180), train_loss = 1.08244444, grad/param norm = 2.0213e-01, time/batch = 18.5659s	
16767/26050 (epoch 32.182), train_loss = 1.05251328, grad/param norm = 2.3696e-01, time/batch = 16.1217s	
16768/26050 (epoch 32.184), train_loss = 0.88856425, grad/param norm = 1.8460e-01, time/batch = 18.1287s	
16769/26050 (epoch 32.186), train_loss = 0.72076076, grad/param norm = 1.7838e-01, time/batch = 18.4767s	
16770/26050 (epoch 32.188), train_loss = 0.89616633, grad/param norm = 2.0851e-01, time/batch = 18.5678s	
16771/26050 (epoch 32.190), train_loss = 0.91434360, grad/param norm = 2.2282e-01, time/batch = 18.3867s	
16772/26050 (epoch 32.192), train_loss = 0.94675506, grad/param norm = 1.9981e-01, time/batch = 14.8951s	
16773/26050 (epoch 32.194), train_loss = 0.90136068, grad/param norm = 2.0054e-01, time/batch = 18.4011s	
16774/26050 (epoch 32.196), train_loss = 0.93585985, grad/param norm = 2.0542e-01, time/batch = 17.6465s	
16775/26050 (epoch 32.198), train_loss = 0.79552561, grad/param norm = 1.8530e-01, time/batch = 17.1579s	
16776/26050 (epoch 32.200), train_loss = 0.77064579, grad/param norm = 1.7302e-01, time/batch = 15.8790s	
16777/26050 (epoch 32.202), train_loss = 0.88635212, grad/param norm = 1.8024e-01, time/batch = 17.5463s	
16778/26050 (epoch 32.203), train_loss = 0.98222745, grad/param norm = 2.1720e-01, time/batch = 17.4822s	
16779/26050 (epoch 32.205), train_loss = 0.82178085, grad/param norm = 2.0441e-01, time/batch = 18.3236s	
16780/26050 (epoch 32.207), train_loss = 0.78575681, grad/param norm = 1.9061e-01, time/batch = 18.4072s	
16781/26050 (epoch 32.209), train_loss = 0.92208792, grad/param norm = 1.8912e-01, time/batch = 16.5791s	
16782/26050 (epoch 32.211), train_loss = 0.75914055, grad/param norm = 2.2619e-01, time/batch = 17.5626s	
16783/26050 (epoch 32.213), train_loss = 0.90172582, grad/param norm = 2.1464e-01, time/batch = 19.0447s	
16784/26050 (epoch 32.215), train_loss = 0.85542404, grad/param norm = 2.3776e-01, time/batch = 15.5486s	
16785/26050 (epoch 32.217), train_loss = 0.82635795, grad/param norm = 1.9473e-01, time/batch = 18.3275s	
16786/26050 (epoch 32.219), train_loss = 0.83078366, grad/param norm = 2.1425e-01, time/batch = 18.7297s	
16787/26050 (epoch 32.221), train_loss = 0.78286958, grad/param norm = 2.1298e-01, time/batch = 18.5723s	
16788/26050 (epoch 32.223), train_loss = 0.95263540, grad/param norm = 2.0900e-01, time/batch = 15.8669s	
16789/26050 (epoch 32.225), train_loss = 0.79977063, grad/param norm = 2.0887e-01, time/batch = 18.6552s	
16790/26050 (epoch 32.226), train_loss = 0.90763977, grad/param norm = 2.3041e-01, time/batch = 18.3310s	
16791/26050 (epoch 32.228), train_loss = 1.01755262, grad/param norm = 2.0951e-01, time/batch = 17.1565s	
16792/26050 (epoch 32.230), train_loss = 0.88464841, grad/param norm = 1.8354e-01, time/batch = 18.8185s	
16793/26050 (epoch 32.232), train_loss = 0.94028674, grad/param norm = 2.1104e-01, time/batch = 14.9762s	
16794/26050 (epoch 32.234), train_loss = 0.77439549, grad/param norm = 2.0614e-01, time/batch = 18.0648s	
16795/26050 (epoch 32.236), train_loss = 0.95336313, grad/param norm = 2.1865e-01, time/batch = 18.3247s	
16796/26050 (epoch 32.238), train_loss = 0.74277580, grad/param norm = 1.9485e-01, time/batch = 18.8245s	
16797/26050 (epoch 32.240), train_loss = 0.87819067, grad/param norm = 2.1069e-01, time/batch = 18.2303s	
16798/26050 (epoch 32.242), train_loss = 0.84377681, grad/param norm = 2.0782e-01, time/batch = 16.8157s	
16799/26050 (epoch 32.244), train_loss = 0.90091437, grad/param norm = 2.2191e-01, time/batch = 17.4979s	
16800/26050 (epoch 32.246), train_loss = 0.83517334, grad/param norm = 1.9923e-01, time/batch = 14.5393s	
16801/26050 (epoch 32.248), train_loss = 0.88173645, grad/param norm = 2.1412e-01, time/batch = 14.3981s	
16802/26050 (epoch 32.250), train_loss = 0.88825282, grad/param norm = 2.3815e-01, time/batch = 17.0680s	
16803/26050 (epoch 32.251), train_loss = 0.83030033, grad/param norm = 1.9698e-01, time/batch = 18.5568s	
16804/26050 (epoch 32.253), train_loss = 0.78705130, grad/param norm = 2.1980e-01, time/batch = 18.3180s	
16805/26050 (epoch 32.255), train_loss = 1.05048174, grad/param norm = 2.1205e-01, time/batch = 17.6485s	
16806/26050 (epoch 32.257), train_loss = 0.87772294, grad/param norm = 2.3792e-01, time/batch = 18.3982s	
16807/26050 (epoch 32.259), train_loss = 0.97979830, grad/param norm = 2.2967e-01, time/batch = 16.9572s	
16808/26050 (epoch 32.261), train_loss = 0.78086177, grad/param norm = 2.1904e-01, time/batch = 17.9685s	
16809/26050 (epoch 32.263), train_loss = 0.96883643, grad/param norm = 2.2514e-01, time/batch = 17.6570s	
16810/26050 (epoch 32.265), train_loss = 1.03342382, grad/param norm = 2.7020e-01, time/batch = 17.8248s	
16811/26050 (epoch 32.267), train_loss = 0.98872461, grad/param norm = 1.9307e-01, time/batch = 17.4591s	
16812/26050 (epoch 32.269), train_loss = 1.00237434, grad/param norm = 2.3949e-01, time/batch = 16.9102s	
16813/26050 (epoch 32.271), train_loss = 0.90325273, grad/param norm = 2.3069e-01, time/batch = 18.2375s	
16814/26050 (epoch 32.273), train_loss = 0.79956781, grad/param norm = 2.0881e-01, time/batch = 14.3823s	
16815/26050 (epoch 32.274), train_loss = 0.86035921, grad/param norm = 1.9142e-01, time/batch = 17.8077s	
16816/26050 (epoch 32.276), train_loss = 0.83823207, grad/param norm = 2.1726e-01, time/batch = 17.5837s	
16817/26050 (epoch 32.278), train_loss = 0.95917604, grad/param norm = 1.9809e-01, time/batch = 17.9086s	
16818/26050 (epoch 32.280), train_loss = 0.88824630, grad/param norm = 1.8529e-01, time/batch = 17.9757s	
16819/26050 (epoch 32.282), train_loss = 0.93736083, grad/param norm = 1.9304e-01, time/batch = 17.7255s	
16820/26050 (epoch 32.284), train_loss = 0.86156010, grad/param norm = 2.0509e-01, time/batch = 16.2247s	
16821/26050 (epoch 32.286), train_loss = 0.91598130, grad/param norm = 2.1517e-01, time/batch = 18.3902s	
16822/26050 (epoch 32.288), train_loss = 0.76402625, grad/param norm = 1.7917e-01, time/batch = 16.5525s	
16823/26050 (epoch 32.290), train_loss = 0.88251116, grad/param norm = 2.0018e-01, time/batch = 18.2461s	
16824/26050 (epoch 32.292), train_loss = 0.80690438, grad/param norm = 1.9678e-01, time/batch = 17.4224s	
16825/26050 (epoch 32.294), train_loss = 0.88112963, grad/param norm = 2.2696e-01, time/batch = 17.4068s	
16826/26050 (epoch 32.296), train_loss = 0.95285521, grad/param norm = 1.8851e-01, time/batch = 17.9135s	
16827/26050 (epoch 32.298), train_loss = 0.89546720, grad/param norm = 1.8840e-01, time/batch = 17.9721s	
16828/26050 (epoch 32.299), train_loss = 0.73080526, grad/param norm = 1.8850e-01, time/batch = 16.7230s	
16829/26050 (epoch 32.301), train_loss = 0.74564916, grad/param norm = 1.9652e-01, time/batch = 15.3957s	
16830/26050 (epoch 32.303), train_loss = 0.88514751, grad/param norm = 2.2338e-01, time/batch = 17.1319s	
16831/26050 (epoch 32.305), train_loss = 0.71532147, grad/param norm = 2.0083e-01, time/batch = 18.7377s	
16832/26050 (epoch 32.307), train_loss = 0.79786460, grad/param norm = 2.0318e-01, time/batch = 17.8179s	
16833/26050 (epoch 32.309), train_loss = 0.87461784, grad/param norm = 2.1716e-01, time/batch = 17.1622s	
16834/26050 (epoch 32.311), train_loss = 0.92142523, grad/param norm = 4.0565e-01, time/batch = 17.7404s	
16835/26050 (epoch 32.313), train_loss = 0.89299994, grad/param norm = 2.6839e-01, time/batch = 18.8231s	
16836/26050 (epoch 32.315), train_loss = 0.95420211, grad/param norm = 2.0483e-01, time/batch = 16.6349s	
16837/26050 (epoch 32.317), train_loss = 0.90542388, grad/param norm = 2.5685e-01, time/batch = 15.3057s	
16838/26050 (epoch 32.319), train_loss = 0.79729403, grad/param norm = 1.9271e-01, time/batch = 17.8200s	
16839/26050 (epoch 32.321), train_loss = 0.86385694, grad/param norm = 2.2085e-01, time/batch = 17.6386s	
16840/26050 (epoch 32.322), train_loss = 0.92532653, grad/param norm = 1.9229e-01, time/batch = 17.5848s	
16841/26050 (epoch 32.324), train_loss = 0.69544721, grad/param norm = 1.7663e-01, time/batch = 17.7485s	
16842/26050 (epoch 32.326), train_loss = 1.00427284, grad/param norm = 2.3614e-01, time/batch = 18.5787s	
16843/26050 (epoch 32.328), train_loss = 0.88909822, grad/param norm = 1.7497e-01, time/batch = 15.3804s	
16844/26050 (epoch 32.330), train_loss = 0.75839926, grad/param norm = 1.8487e-01, time/batch = 18.4108s	
16845/26050 (epoch 32.332), train_loss = 0.92995294, grad/param norm = 2.0459e-01, time/batch = 17.2345s	
16846/26050 (epoch 32.334), train_loss = 0.79833317, grad/param norm = 1.8900e-01, time/batch = 15.9696s	
16847/26050 (epoch 32.336), train_loss = 0.82712745, grad/param norm = 2.2576e-01, time/batch = 17.9827s	
16848/26050 (epoch 32.338), train_loss = 0.75591046, grad/param norm = 1.6660e-01, time/batch = 18.5630s	
16849/26050 (epoch 32.340), train_loss = 0.92310829, grad/param norm = 2.0002e-01, time/batch = 17.4838s	
16850/26050 (epoch 32.342), train_loss = 0.96193660, grad/param norm = 2.0103e-01, time/batch = 17.8978s	
16851/26050 (epoch 32.344), train_loss = 0.79582110, grad/param norm = 1.9867e-01, time/batch = 18.3987s	
16852/26050 (epoch 32.345), train_loss = 0.85014930, grad/param norm = 2.1217e-01, time/batch = 18.5067s	
16853/26050 (epoch 32.347), train_loss = 0.98222120, grad/param norm = 2.1979e-01, time/batch = 18.2275s	
16854/26050 (epoch 32.349), train_loss = 0.91316037, grad/param norm = 2.0707e-01, time/batch = 17.8074s	
16855/26050 (epoch 32.351), train_loss = 0.90344108, grad/param norm = 1.9990e-01, time/batch = 18.5748s	
16856/26050 (epoch 32.353), train_loss = 0.90091306, grad/param norm = 2.1636e-01, time/batch = 15.8007s	
16857/26050 (epoch 32.355), train_loss = 0.88097835, grad/param norm = 2.1833e-01, time/batch = 18.8997s	
16858/26050 (epoch 32.357), train_loss = 0.83458701, grad/param norm = 1.7846e-01, time/batch = 14.6085s	
16859/26050 (epoch 32.359), train_loss = 0.95840016, grad/param norm = 2.2452e-01, time/batch = 18.4786s	
16860/26050 (epoch 32.361), train_loss = 0.78263958, grad/param norm = 1.7258e-01, time/batch = 17.7354s	
16861/26050 (epoch 32.363), train_loss = 0.95510788, grad/param norm = 1.9230e-01, time/batch = 18.7382s	
16862/26050 (epoch 32.365), train_loss = 0.84529319, grad/param norm = 1.7839e-01, time/batch = 18.4216s	
16863/26050 (epoch 32.367), train_loss = 0.94479523, grad/param norm = 1.9742e-01, time/batch = 17.3067s	
16864/26050 (epoch 32.369), train_loss = 0.79123791, grad/param norm = 1.7286e-01, time/batch = 18.6539s	
16865/26050 (epoch 32.370), train_loss = 0.77481786, grad/param norm = 1.7141e-01, time/batch = 18.4927s	
16866/26050 (epoch 32.372), train_loss = 0.88415033, grad/param norm = 2.1006e-01, time/batch = 17.5564s	
16867/26050 (epoch 32.374), train_loss = 1.00925898, grad/param norm = 2.0573e-01, time/batch = 16.3009s	
16868/26050 (epoch 32.376), train_loss = 1.01639903, grad/param norm = 2.3179e-01, time/batch = 14.9069s	
16869/26050 (epoch 32.378), train_loss = 0.83130382, grad/param norm = 1.9810e-01, time/batch = 17.8227s	
16870/26050 (epoch 32.380), train_loss = 0.99892289, grad/param norm = 2.1845e-01, time/batch = 17.0383s	
16871/26050 (epoch 32.382), train_loss = 1.09527655, grad/param norm = 2.3951e-01, time/batch = 16.8767s	
16872/26050 (epoch 32.384), train_loss = 0.83411092, grad/param norm = 2.2314e-01, time/batch = 18.2437s	
16873/26050 (epoch 32.386), train_loss = 0.95200314, grad/param norm = 2.2656e-01, time/batch = 16.5633s	
16874/26050 (epoch 32.388), train_loss = 0.90399432, grad/param norm = 2.1933e-01, time/batch = 17.2987s	
16875/26050 (epoch 32.390), train_loss = 0.81821422, grad/param norm = 1.6709e-01, time/batch = 17.9797s	
16876/26050 (epoch 32.392), train_loss = 0.78145762, grad/param norm = 1.8893e-01, time/batch = 18.0678s	
16877/26050 (epoch 32.393), train_loss = 0.92076562, grad/param norm = 2.2509e-01, time/batch = 16.6344s	
16878/26050 (epoch 32.395), train_loss = 0.94254019, grad/param norm = 2.2668e-01, time/batch = 16.4620s	
16879/26050 (epoch 32.397), train_loss = 0.94455251, grad/param norm = 2.3267e-01, time/batch = 18.6610s	
16880/26050 (epoch 32.399), train_loss = 0.83426963, grad/param norm = 2.1030e-01, time/batch = 17.5761s	
16881/26050 (epoch 32.401), train_loss = 0.89800663, grad/param norm = 2.1210e-01, time/batch = 18.5820s	
16882/26050 (epoch 32.403), train_loss = 0.90156983, grad/param norm = 2.1923e-01, time/batch = 18.2286s	
16883/26050 (epoch 32.405), train_loss = 0.91439780, grad/param norm = 2.6383e-01, time/batch = 16.5452s	
16884/26050 (epoch 32.407), train_loss = 1.01696067, grad/param norm = 2.1305e-01, time/batch = 17.1525s	
16885/26050 (epoch 32.409), train_loss = 1.01361308, grad/param norm = 2.2556e-01, time/batch = 18.3158s	
16886/26050 (epoch 32.411), train_loss = 0.96430502, grad/param norm = 2.2182e-01, time/batch = 18.8159s	
16887/26050 (epoch 32.413), train_loss = 1.05166691, grad/param norm = 2.1652e-01, time/batch = 17.4822s	
16888/26050 (epoch 32.415), train_loss = 1.04452266, grad/param norm = 2.2977e-01, time/batch = 17.9867s	
16889/26050 (epoch 32.417), train_loss = 1.08148809, grad/param norm = 2.2953e-01, time/batch = 18.2364s	
16890/26050 (epoch 32.418), train_loss = 0.94960286, grad/param norm = 2.2171e-01, time/batch = 17.7461s	
16891/26050 (epoch 32.420), train_loss = 0.78626593, grad/param norm = 1.9376e-01, time/batch = 18.5619s	
16892/26050 (epoch 32.422), train_loss = 0.75496136, grad/param norm = 1.8948e-01, time/batch = 14.8844s	
16893/26050 (epoch 32.424), train_loss = 0.99344571, grad/param norm = 2.2075e-01, time/batch = 16.9564s	
16894/26050 (epoch 32.426), train_loss = 0.94622897, grad/param norm = 2.0781e-01, time/batch = 17.9065s	
16895/26050 (epoch 32.428), train_loss = 0.82894072, grad/param norm = 1.8296e-01, time/batch = 18.5771s	
16896/26050 (epoch 32.430), train_loss = 1.04169492, grad/param norm = 2.0038e-01, time/batch = 14.8044s	
16897/26050 (epoch 32.432), train_loss = 0.85469317, grad/param norm = 1.9421e-01, time/batch = 18.0705s	
16898/26050 (epoch 32.434), train_loss = 0.84784707, grad/param norm = 1.9268e-01, time/batch = 17.8963s	
16899/26050 (epoch 32.436), train_loss = 1.00321897, grad/param norm = 2.1775e-01, time/batch = 18.7434s	
16900/26050 (epoch 32.438), train_loss = 0.93761282, grad/param norm = 2.1210e-01, time/batch = 17.2206s	
16901/26050 (epoch 32.440), train_loss = 0.91140029, grad/param norm = 1.9483e-01, time/batch = 4.0384s	
16902/26050 (epoch 32.441), train_loss = 0.91599823, grad/param norm = 1.9863e-01, time/batch = 0.6405s	
16903/26050 (epoch 32.443), train_loss = 0.75921506, grad/param norm = 1.5540e-01, time/batch = 0.6412s	
16904/26050 (epoch 32.445), train_loss = 0.80002777, grad/param norm = 1.7883e-01, time/batch = 0.6517s	
16905/26050 (epoch 32.447), train_loss = 0.99964036, grad/param norm = 2.0859e-01, time/batch = 0.6517s	
16906/26050 (epoch 32.449), train_loss = 0.80815341, grad/param norm = 2.0244e-01, time/batch = 0.6452s	
16907/26050 (epoch 32.451), train_loss = 1.03716875, grad/param norm = 2.1795e-01, time/batch = 0.6417s	
16908/26050 (epoch 32.453), train_loss = 0.82334915, grad/param norm = 1.7273e-01, time/batch = 0.6576s	
16909/26050 (epoch 32.455), train_loss = 0.88915836, grad/param norm = 1.8271e-01, time/batch = 0.9394s	
16910/26050 (epoch 32.457), train_loss = 0.88822157, grad/param norm = 2.0782e-01, time/batch = 0.9461s	
16911/26050 (epoch 32.459), train_loss = 0.99709240, grad/param norm = 2.1614e-01, time/batch = 0.9595s	
16912/26050 (epoch 32.461), train_loss = 1.00110064, grad/param norm = 2.1138e-01, time/batch = 0.9548s	
16913/26050 (epoch 32.463), train_loss = 0.85301207, grad/param norm = 1.7506e-01, time/batch = 0.9458s	
16914/26050 (epoch 32.464), train_loss = 0.93409744, grad/param norm = 2.0184e-01, time/batch = 1.6459s	
16915/26050 (epoch 32.466), train_loss = 0.89854511, grad/param norm = 2.0113e-01, time/batch = 1.8030s	
16916/26050 (epoch 32.468), train_loss = 1.00242031, grad/param norm = 1.8217e-01, time/batch = 2.1947s	
16917/26050 (epoch 32.470), train_loss = 0.99035571, grad/param norm = 2.3590e-01, time/batch = 18.4710s	
16918/26050 (epoch 32.472), train_loss = 1.01225853, grad/param norm = 2.4590e-01, time/batch = 16.7202s	
16919/26050 (epoch 32.474), train_loss = 1.01082646, grad/param norm = 2.1388e-01, time/batch = 17.4723s	
16920/26050 (epoch 32.476), train_loss = 0.98014492, grad/param norm = 1.9318e-01, time/batch = 17.2520s	
16921/26050 (epoch 32.478), train_loss = 0.86279472, grad/param norm = 1.9584e-01, time/batch = 17.4809s	
16922/26050 (epoch 32.480), train_loss = 0.86874555, grad/param norm = 1.7881e-01, time/batch = 16.7140s	
16923/26050 (epoch 32.482), train_loss = 0.85796728, grad/param norm = 2.1391e-01, time/batch = 18.0666s	
16924/26050 (epoch 32.484), train_loss = 0.85146084, grad/param norm = 2.1122e-01, time/batch = 18.2404s	
16925/26050 (epoch 32.486), train_loss = 1.02379512, grad/param norm = 2.0026e-01, time/batch = 17.8138s	
16926/26050 (epoch 32.488), train_loss = 1.05449548, grad/param norm = 2.3836e-01, time/batch = 18.0606s	
16927/26050 (epoch 32.489), train_loss = 1.05943876, grad/param norm = 2.2561e-01, time/batch = 18.7375s	
16928/26050 (epoch 32.491), train_loss = 0.82163727, grad/param norm = 2.0992e-01, time/batch = 18.7577s	
16929/26050 (epoch 32.493), train_loss = 0.91655978, grad/param norm = 2.1314e-01, time/batch = 17.4854s	
16930/26050 (epoch 32.495), train_loss = 0.88316198, grad/param norm = 1.8273e-01, time/batch = 18.3278s	
16931/26050 (epoch 32.497), train_loss = 0.80145958, grad/param norm = 1.9932e-01, time/batch = 18.2377s	
16932/26050 (epoch 32.499), train_loss = 0.84607196, grad/param norm = 1.9632e-01, time/batch = 20.7170s	
16933/26050 (epoch 32.501), train_loss = 0.99036107, grad/param norm = 2.0337e-01, time/batch = 31.5826s	
16934/26050 (epoch 32.503), train_loss = 0.84879003, grad/param norm = 2.0300e-01, time/batch = 20.8975s	
16935/26050 (epoch 32.505), train_loss = 1.01086659, grad/param norm = 2.1317e-01, time/batch = 18.3716s	
16936/26050 (epoch 32.507), train_loss = 0.96367360, grad/param norm = 2.1848e-01, time/batch = 14.9839s	
16937/26050 (epoch 32.509), train_loss = 1.04226712, grad/param norm = 1.9924e-01, time/batch = 18.5742s	
16938/26050 (epoch 32.511), train_loss = 0.86410965, grad/param norm = 1.7788e-01, time/batch = 18.3173s	
16939/26050 (epoch 32.512), train_loss = 0.78940989, grad/param norm = 2.1282e-01, time/batch = 17.6492s	
16940/26050 (epoch 32.514), train_loss = 0.94425522, grad/param norm = 2.1068e-01, time/batch = 17.8234s	
16941/26050 (epoch 32.516), train_loss = 1.02271424, grad/param norm = 2.1531e-01, time/batch = 17.6560s	
16942/26050 (epoch 32.518), train_loss = 0.87044066, grad/param norm = 2.0343e-01, time/batch = 18.6493s	
16943/26050 (epoch 32.520), train_loss = 0.89950085, grad/param norm = 1.9736e-01, time/batch = 18.8958s	
16944/26050 (epoch 32.522), train_loss = 0.71979389, grad/param norm = 1.8242e-01, time/batch = 14.8917s	
16945/26050 (epoch 32.524), train_loss = 0.99868260, grad/param norm = 2.4752e-01, time/batch = 17.6327s	
16946/26050 (epoch 32.526), train_loss = 1.00048778, grad/param norm = 2.1905e-01, time/batch = 17.5645s	
16947/26050 (epoch 32.528), train_loss = 0.91374639, grad/param norm = 1.8833e-01, time/batch = 18.4997s	
16948/26050 (epoch 32.530), train_loss = 0.87443487, grad/param norm = 2.5397e-01, time/batch = 18.2193s	
16949/26050 (epoch 32.532), train_loss = 0.93549024, grad/param norm = 2.0609e-01, time/batch = 17.3313s	
16950/26050 (epoch 32.534), train_loss = 0.94779236, grad/param norm = 2.4195e-01, time/batch = 17.7413s	
16951/26050 (epoch 32.536), train_loss = 0.93269334, grad/param norm = 2.1541e-01, time/batch = 15.3933s	
16952/26050 (epoch 32.537), train_loss = 0.97195225, grad/param norm = 2.0048e-01, time/batch = 16.8784s	
16953/26050 (epoch 32.539), train_loss = 0.89372698, grad/param norm = 2.0246e-01, time/batch = 18.1568s	
16954/26050 (epoch 32.541), train_loss = 1.05821962, grad/param norm = 2.3143e-01, time/batch = 17.8870s	
16955/26050 (epoch 32.543), train_loss = 0.72500061, grad/param norm = 1.9465e-01, time/batch = 18.2362s	
16956/26050 (epoch 32.545), train_loss = 0.90794422, grad/param norm = 1.9926e-01, time/batch = 17.8900s	
16957/26050 (epoch 32.547), train_loss = 0.87098949, grad/param norm = 1.9698e-01, time/batch = 17.9795s	
16958/26050 (epoch 32.549), train_loss = 0.77623587, grad/param norm = 2.1369e-01, time/batch = 16.3677s	
16959/26050 (epoch 32.551), train_loss = 0.94414439, grad/param norm = 2.0399e-01, time/batch = 17.0607s	
16960/26050 (epoch 32.553), train_loss = 0.85899700, grad/param norm = 2.0738e-01, time/batch = 18.4680s	
16961/26050 (epoch 32.555), train_loss = 0.80595630, grad/param norm = 2.1470e-01, time/batch = 17.7315s	
16962/26050 (epoch 32.557), train_loss = 0.92590126, grad/param norm = 2.0382e-01, time/batch = 18.1628s	
16963/26050 (epoch 32.559), train_loss = 0.91455954, grad/param norm = 1.9808e-01, time/batch = 18.1444s	
16964/26050 (epoch 32.560), train_loss = 0.85892982, grad/param norm = 2.0688e-01, time/batch = 17.9755s	
16965/26050 (epoch 32.562), train_loss = 0.87798554, grad/param norm = 2.1388e-01, time/batch = 17.0467s	
16966/26050 (epoch 32.564), train_loss = 1.06392752, grad/param norm = 2.1628e-01, time/batch = 18.4679s	
16967/26050 (epoch 32.566), train_loss = 0.83261779, grad/param norm = 1.8151e-01, time/batch = 18.3917s	
16968/26050 (epoch 32.568), train_loss = 0.93308978, grad/param norm = 1.9882e-01, time/batch = 17.4587s	
16969/26050 (epoch 32.570), train_loss = 0.90003778, grad/param norm = 2.0591e-01, time/batch = 14.2401s	
16970/26050 (epoch 32.572), train_loss = 0.90916991, grad/param norm = 2.1175e-01, time/batch = 14.8097s	
16971/26050 (epoch 32.574), train_loss = 0.92707599, grad/param norm = 2.6591e-01, time/batch = 18.3871s	
16972/26050 (epoch 32.576), train_loss = 0.93954152, grad/param norm = 2.1835e-01, time/batch = 16.7280s	
16973/26050 (epoch 32.578), train_loss = 0.88762498, grad/param norm = 2.3306e-01, time/batch = 18.0689s	
16974/26050 (epoch 32.580), train_loss = 0.82935340, grad/param norm = 2.2871e-01, time/batch = 18.6438s	
16975/26050 (epoch 32.582), train_loss = 0.92294985, grad/param norm = 1.8997e-01, time/batch = 17.4730s	
16976/26050 (epoch 32.583), train_loss = 0.96626589, grad/param norm = 1.9611e-01, time/batch = 18.5649s	
16977/26050 (epoch 32.585), train_loss = 0.80931071, grad/param norm = 1.9905e-01, time/batch = 17.4132s	
16978/26050 (epoch 32.587), train_loss = 0.93424248, grad/param norm = 2.1549e-01, time/batch = 16.1359s	
16979/26050 (epoch 32.589), train_loss = 1.04060086, grad/param norm = 2.3132e-01, time/batch = 14.8054s	
16980/26050 (epoch 32.591), train_loss = 0.90283942, grad/param norm = 2.1095e-01, time/batch = 18.4767s	
16981/26050 (epoch 32.593), train_loss = 0.78438407, grad/param norm = 1.8007e-01, time/batch = 18.7260s	
16982/26050 (epoch 32.595), train_loss = 0.96423299, grad/param norm = 2.1745e-01, time/batch = 17.8816s	
16983/26050 (epoch 32.597), train_loss = 0.91197614, grad/param norm = 2.4051e-01, time/batch = 17.5473s	
16984/26050 (epoch 32.599), train_loss = 0.95209505, grad/param norm = 2.0564e-01, time/batch = 18.1345s	
16985/26050 (epoch 32.601), train_loss = 1.07928979, grad/param norm = 2.1802e-01, time/batch = 17.9829s	
16986/26050 (epoch 32.603), train_loss = 0.96784865, grad/param norm = 2.2556e-01, time/batch = 18.8123s	
16987/26050 (epoch 32.605), train_loss = 0.87948009, grad/param norm = 2.1501e-01, time/batch = 17.1526s	
16988/26050 (epoch 32.607), train_loss = 1.00333161, grad/param norm = 2.6025e-01, time/batch = 16.4723s	
16989/26050 (epoch 32.608), train_loss = 0.81373907, grad/param norm = 1.8393e-01, time/batch = 15.5523s	
16990/26050 (epoch 32.610), train_loss = 0.92291342, grad/param norm = 2.3819e-01, time/batch = 17.8962s	
16991/26050 (epoch 32.612), train_loss = 0.88002406, grad/param norm = 2.1182e-01, time/batch = 17.9824s	
16992/26050 (epoch 32.614), train_loss = 0.91256939, grad/param norm = 2.0297e-01, time/batch = 16.9620s	
16993/26050 (epoch 32.616), train_loss = 0.98174011, grad/param norm = 2.4851e-01, time/batch = 18.0643s	
16994/26050 (epoch 32.618), train_loss = 0.87894855, grad/param norm = 2.1792e-01, time/batch = 19.2304s	
16995/26050 (epoch 32.620), train_loss = 0.96247649, grad/param norm = 2.0792e-01, time/batch = 16.8102s	
16996/26050 (epoch 32.622), train_loss = 0.81924183, grad/param norm = 1.7963e-01, time/batch = 18.4867s	
16997/26050 (epoch 32.624), train_loss = 0.75770300, grad/param norm = 1.7314e-01, time/batch = 18.7384s	
16998/26050 (epoch 32.626), train_loss = 0.94411529, grad/param norm = 1.9167e-01, time/batch = 18.1362s	
16999/26050 (epoch 32.628), train_loss = 0.84839485, grad/param norm = 2.1859e-01, time/batch = 17.2863s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch32.63_1.8479.t7	
17000/26050 (epoch 32.630), train_loss = 1.03335587, grad/param norm = 2.0272e-01, time/batch = 17.2957s	
17001/26050 (epoch 32.631), train_loss = 1.50702600, grad/param norm = 2.9108e-01, time/batch = 15.5940s	
17002/26050 (epoch 32.633), train_loss = 0.83889365, grad/param norm = 2.0096e-01, time/batch = 18.0576s	
17003/26050 (epoch 32.635), train_loss = 0.85290595, grad/param norm = 1.6860e-01, time/batch = 17.8914s	
17004/26050 (epoch 32.637), train_loss = 0.80231829, grad/param norm = 2.0200e-01, time/batch = 18.4887s	
17005/26050 (epoch 32.639), train_loss = 0.95497096, grad/param norm = 1.9580e-01, time/batch = 18.0034s	
17006/26050 (epoch 32.641), train_loss = 0.85578028, grad/param norm = 1.9044e-01, time/batch = 17.8256s	
17007/26050 (epoch 32.643), train_loss = 0.83336568, grad/param norm = 1.7887e-01, time/batch = 18.8233s	
17008/26050 (epoch 32.645), train_loss = 0.84584173, grad/param norm = 1.9982e-01, time/batch = 18.3195s	
17009/26050 (epoch 32.647), train_loss = 0.82826999, grad/param norm = 2.1804e-01, time/batch = 18.0500s	
17010/26050 (epoch 32.649), train_loss = 0.88138160, grad/param norm = 2.0925e-01, time/batch = 16.5796s	
17011/26050 (epoch 32.651), train_loss = 0.85436548, grad/param norm = 2.0144e-01, time/batch = 17.7196s	
17012/26050 (epoch 32.653), train_loss = 0.87644875, grad/param norm = 2.0288e-01, time/batch = 18.7462s	
17013/26050 (epoch 32.655), train_loss = 0.81236316, grad/param norm = 1.9779e-01, time/batch = 17.4602s	
17014/26050 (epoch 32.656), train_loss = 0.80437751, grad/param norm = 1.8997e-01, time/batch = 14.7132s	
17015/26050 (epoch 32.658), train_loss = 1.08619221, grad/param norm = 2.2473e-01, time/batch = 18.5696s	
17016/26050 (epoch 32.660), train_loss = 0.76925225, grad/param norm = 2.2182e-01, time/batch = 17.9131s	
17017/26050 (epoch 32.662), train_loss = 0.88088318, grad/param norm = 1.9513e-01, time/batch = 18.0731s	
17018/26050 (epoch 32.664), train_loss = 0.88271684, grad/param norm = 1.9505e-01, time/batch = 14.9508s	
17019/26050 (epoch 32.666), train_loss = 0.84001859, grad/param norm = 1.9501e-01, time/batch = 18.2433s	
17020/26050 (epoch 32.668), train_loss = 0.70051927, grad/param norm = 1.9424e-01, time/batch = 17.7343s	
17021/26050 (epoch 32.670), train_loss = 1.01874165, grad/param norm = 2.4745e-01, time/batch = 15.3121s	
17022/26050 (epoch 32.672), train_loss = 0.87935143, grad/param norm = 2.0345e-01, time/batch = 18.4766s	
17023/26050 (epoch 32.674), train_loss = 0.79369576, grad/param norm = 2.2895e-01, time/batch = 17.6515s	
17024/26050 (epoch 32.676), train_loss = 0.94898842, grad/param norm = 2.1949e-01, time/batch = 18.7323s	
17025/26050 (epoch 32.678), train_loss = 0.97997692, grad/param norm = 2.1431e-01, time/batch = 18.3226s	
17026/26050 (epoch 32.679), train_loss = 1.02236473, grad/param norm = 2.0777e-01, time/batch = 17.2281s	
17027/26050 (epoch 32.681), train_loss = 0.92904107, grad/param norm = 2.1553e-01, time/batch = 17.6491s	
17028/26050 (epoch 32.683), train_loss = 0.78917731, grad/param norm = 2.1316e-01, time/batch = 18.5014s	
17029/26050 (epoch 32.685), train_loss = 0.87097687, grad/param norm = 1.8364e-01, time/batch = 17.0425s	
17030/26050 (epoch 32.687), train_loss = 0.79409135, grad/param norm = 1.9100e-01, time/batch = 17.8965s	
17031/26050 (epoch 32.689), train_loss = 0.84749599, grad/param norm = 2.1974e-01, time/batch = 16.8778s	
17032/26050 (epoch 32.691), train_loss = 0.72590882, grad/param norm = 1.8693e-01, time/batch = 18.4808s	
17033/26050 (epoch 32.693), train_loss = 0.84400830, grad/param norm = 1.9999e-01, time/batch = 17.5697s	
17034/26050 (epoch 32.695), train_loss = 0.87016009, grad/param norm = 1.8700e-01, time/batch = 17.9658s	
17035/26050 (epoch 32.697), train_loss = 0.82929341, grad/param norm = 2.0125e-01, time/batch = 15.9040s	
17036/26050 (epoch 32.699), train_loss = 0.93751087, grad/param norm = 2.1637e-01, time/batch = 17.8170s	
17037/26050 (epoch 32.701), train_loss = 0.81294328, grad/param norm = 1.7946e-01, time/batch = 18.4730s	
17038/26050 (epoch 32.702), train_loss = 0.96526127, grad/param norm = 2.2753e-01, time/batch = 16.0670s	
17039/26050 (epoch 32.704), train_loss = 0.98814760, grad/param norm = 1.9071e-01, time/batch = 18.1503s	
17040/26050 (epoch 32.706), train_loss = 0.82198442, grad/param norm = 1.9392e-01, time/batch = 17.4015s	
17041/26050 (epoch 32.708), train_loss = 0.96195235, grad/param norm = 2.2850e-01, time/batch = 17.6672s	
17042/26050 (epoch 32.710), train_loss = 0.91681676, grad/param norm = 2.2878e-01, time/batch = 18.5637s	
17043/26050 (epoch 32.712), train_loss = 0.89923929, grad/param norm = 2.0410e-01, time/batch = 16.9862s	
17044/26050 (epoch 32.714), train_loss = 0.79904948, grad/param norm = 1.9527e-01, time/batch = 16.8074s	
17045/26050 (epoch 32.716), train_loss = 1.11383711, grad/param norm = 2.4044e-01, time/batch = 17.9840s	
17046/26050 (epoch 32.718), train_loss = 0.94783742, grad/param norm = 2.0754e-01, time/batch = 18.7365s	
17047/26050 (epoch 32.720), train_loss = 0.88093422, grad/param norm = 2.0415e-01, time/batch = 18.0719s	
17048/26050 (epoch 32.722), train_loss = 0.80959572, grad/param norm = 1.9107e-01, time/batch = 18.8228s	
17049/26050 (epoch 32.724), train_loss = 0.84043455, grad/param norm = 2.1428e-01, time/batch = 18.2339s	
17050/26050 (epoch 32.726), train_loss = 0.94347093, grad/param norm = 2.0081e-01, time/batch = 16.1180s	
17051/26050 (epoch 32.727), train_loss = 0.94426745, grad/param norm = 2.0815e-01, time/batch = 15.4875s	
17052/26050 (epoch 32.729), train_loss = 0.92524687, grad/param norm = 1.8574e-01, time/batch = 17.2188s	
17053/26050 (epoch 32.731), train_loss = 0.93888891, grad/param norm = 2.0892e-01, time/batch = 18.1462s	
17054/26050 (epoch 32.733), train_loss = 0.86519320, grad/param norm = 2.5759e-01, time/batch = 18.3139s	
17055/26050 (epoch 32.735), train_loss = 1.04108155, grad/param norm = 1.9429e-01, time/batch = 18.8133s	
17056/26050 (epoch 32.737), train_loss = 0.85587318, grad/param norm = 2.0762e-01, time/batch = 16.5470s	
17057/26050 (epoch 32.739), train_loss = 0.93777944, grad/param norm = 2.0651e-01, time/batch = 17.7415s	
17058/26050 (epoch 32.741), train_loss = 0.82617524, grad/param norm = 1.8367e-01, time/batch = 18.3150s	
17059/26050 (epoch 32.743), train_loss = 0.89127269, grad/param norm = 2.3795e-01, time/batch = 16.9907s	
17060/26050 (epoch 32.745), train_loss = 0.78975635, grad/param norm = 1.9379e-01, time/batch = 16.3762s	
17061/26050 (epoch 32.747), train_loss = 0.81447243, grad/param norm = 1.8970e-01, time/batch = 17.0803s	
17062/26050 (epoch 32.749), train_loss = 0.99773798, grad/param norm = 2.1338e-01, time/batch = 16.2156s	
17063/26050 (epoch 32.750), train_loss = 0.88457931, grad/param norm = 1.8132e-01, time/batch = 18.5722s	
17064/26050 (epoch 32.752), train_loss = 0.83719738, grad/param norm = 2.0761e-01, time/batch = 17.8932s	
17065/26050 (epoch 32.754), train_loss = 0.90185537, grad/param norm = 1.9949e-01, time/batch = 18.1472s	
17066/26050 (epoch 32.756), train_loss = 0.87666257, grad/param norm = 2.9064e-01, time/batch = 18.5676s	
17067/26050 (epoch 32.758), train_loss = 0.88441785, grad/param norm = 2.4360e-01, time/batch = 15.4771s	
17068/26050 (epoch 32.760), train_loss = 1.02680049, grad/param norm = 2.7269e-01, time/batch = 17.6295s	
17069/26050 (epoch 32.762), train_loss = 0.85857583, grad/param norm = 2.2369e-01, time/batch = 17.7408s	
17070/26050 (epoch 32.764), train_loss = 0.86209383, grad/param norm = 2.2657e-01, time/batch = 15.4003s	
17071/26050 (epoch 32.766), train_loss = 0.89698028, grad/param norm = 2.0507e-01, time/batch = 18.1478s	
17072/26050 (epoch 32.768), train_loss = 0.78625925, grad/param norm = 1.6639e-01, time/batch = 14.9963s	
17073/26050 (epoch 32.770), train_loss = 0.86065344, grad/param norm = 2.0972e-01, time/batch = 18.8186s	
17074/26050 (epoch 32.772), train_loss = 0.89373146, grad/param norm = 2.1815e-01, time/batch = 17.9065s	
17075/26050 (epoch 32.774), train_loss = 0.78194039, grad/param norm = 2.1171e-01, time/batch = 17.5628s	
17076/26050 (epoch 32.775), train_loss = 0.64616383, grad/param norm = 1.7858e-01, time/batch = 18.2358s	
17077/26050 (epoch 32.777), train_loss = 0.85507423, grad/param norm = 1.9001e-01, time/batch = 17.8107s	
17078/26050 (epoch 32.779), train_loss = 0.89750652, grad/param norm = 2.5347e-01, time/batch = 17.3842s	
17079/26050 (epoch 32.781), train_loss = 0.79938190, grad/param norm = 2.3656e-01, time/batch = 15.8685s	
17080/26050 (epoch 32.783), train_loss = 0.77294402, grad/param norm = 2.0370e-01, time/batch = 18.3968s	
17081/26050 (epoch 32.785), train_loss = 0.88392772, grad/param norm = 2.0504e-01, time/batch = 16.9086s	
17082/26050 (epoch 32.787), train_loss = 0.80625906, grad/param norm = 2.2250e-01, time/batch = 14.4816s	
17083/26050 (epoch 32.789), train_loss = 0.80404652, grad/param norm = 2.1841e-01, time/batch = 18.4043s	
17084/26050 (epoch 32.791), train_loss = 0.81237181, grad/param norm = 2.2348e-01, time/batch = 17.5734s	
17085/26050 (epoch 32.793), train_loss = 0.88949282, grad/param norm = 2.4283e-01, time/batch = 17.8249s	
17086/26050 (epoch 32.795), train_loss = 0.70960488, grad/param norm = 1.6799e-01, time/batch = 18.0747s	
17087/26050 (epoch 32.797), train_loss = 0.77199518, grad/param norm = 2.0011e-01, time/batch = 18.0654s	
17088/26050 (epoch 32.798), train_loss = 0.79312458, grad/param norm = 2.2788e-01, time/batch = 16.7271s	
17089/26050 (epoch 32.800), train_loss = 0.78068632, grad/param norm = 2.0597e-01, time/batch = 16.2174s	
17090/26050 (epoch 32.802), train_loss = 0.83163320, grad/param norm = 2.2975e-01, time/batch = 18.3215s	
17091/26050 (epoch 32.804), train_loss = 0.84737170, grad/param norm = 2.0246e-01, time/batch = 14.8871s	
17092/26050 (epoch 32.806), train_loss = 0.94289648, grad/param norm = 2.2748e-01, time/batch = 18.3173s	
17093/26050 (epoch 32.808), train_loss = 0.87866342, grad/param norm = 2.2080e-01, time/batch = 18.0781s	
17094/26050 (epoch 32.810), train_loss = 0.85204381, grad/param norm = 2.3454e-01, time/batch = 18.3956s	
17095/26050 (epoch 32.812), train_loss = 0.73673555, grad/param norm = 1.8002e-01, time/batch = 17.8908s	
17096/26050 (epoch 32.814), train_loss = 0.80287515, grad/param norm = 2.5535e-01, time/batch = 16.3805s	
17097/26050 (epoch 32.816), train_loss = 0.92074574, grad/param norm = 2.3386e-01, time/batch = 17.7307s	
17098/26050 (epoch 32.818), train_loss = 0.96128439, grad/param norm = 2.5934e-01, time/batch = 16.8977s	
17099/26050 (epoch 32.820), train_loss = 0.90470020, grad/param norm = 2.1977e-01, time/batch = 18.2390s	
17100/26050 (epoch 32.821), train_loss = 0.99061722, grad/param norm = 2.4277e-01, time/batch = 18.8996s	
17101/26050 (epoch 32.823), train_loss = 1.06930531, grad/param norm = 2.2803e-01, time/batch = 16.7299s	
17102/26050 (epoch 32.825), train_loss = 0.87924722, grad/param norm = 2.0568e-01, time/batch = 14.1369s	
17103/26050 (epoch 32.827), train_loss = 0.90751556, grad/param norm = 2.4752e-01, time/batch = 18.1534s	
17104/26050 (epoch 32.829), train_loss = 0.97315331, grad/param norm = 2.1907e-01, time/batch = 18.5699s	
17105/26050 (epoch 32.831), train_loss = 1.02810089, grad/param norm = 2.3866e-01, time/batch = 17.6504s	
17106/26050 (epoch 32.833), train_loss = 1.02891975, grad/param norm = 2.4343e-01, time/batch = 16.5431s	
17107/26050 (epoch 32.835), train_loss = 1.03546611, grad/param norm = 2.4453e-01, time/batch = 18.8281s	
17108/26050 (epoch 32.837), train_loss = 0.89159611, grad/param norm = 1.7758e-01, time/batch = 17.8115s	
17109/26050 (epoch 32.839), train_loss = 0.87976350, grad/param norm = 2.1977e-01, time/batch = 16.2410s	
17110/26050 (epoch 32.841), train_loss = 0.97888120, grad/param norm = 2.2008e-01, time/batch = 17.9552s	
17111/26050 (epoch 32.843), train_loss = 0.87087241, grad/param norm = 1.8497e-01, time/batch = 18.9259s	
17112/26050 (epoch 32.845), train_loss = 0.84064445, grad/param norm = 1.8688e-01, time/batch = 18.4729s	
17113/26050 (epoch 32.846), train_loss = 0.92895663, grad/param norm = 2.1621e-01, time/batch = 18.3131s	
17114/26050 (epoch 32.848), train_loss = 0.87263860, grad/param norm = 1.9384e-01, time/batch = 15.3814s	
17115/26050 (epoch 32.850), train_loss = 0.80371742, grad/param norm = 1.8778e-01, time/batch = 17.2309s	
17116/26050 (epoch 32.852), train_loss = 0.90059869, grad/param norm = 1.9111e-01, time/batch = 18.7326s	
17117/26050 (epoch 32.854), train_loss = 0.88592730, grad/param norm = 2.1587e-01, time/batch = 15.5556s	
17118/26050 (epoch 32.856), train_loss = 0.84211281, grad/param norm = 2.1080e-01, time/batch = 18.6540s	
17119/26050 (epoch 32.858), train_loss = 0.81801995, grad/param norm = 2.0492e-01, time/batch = 17.9875s	
17120/26050 (epoch 32.860), train_loss = 0.93182621, grad/param norm = 2.1900e-01, time/batch = 16.7209s	
17121/26050 (epoch 32.862), train_loss = 0.95305541, grad/param norm = 1.9182e-01, time/batch = 17.9025s	
17122/26050 (epoch 32.864), train_loss = 0.91034760, grad/param norm = 2.3418e-01, time/batch = 17.8014s	
17123/26050 (epoch 32.866), train_loss = 0.84695783, grad/param norm = 1.9307e-01, time/batch = 18.1511s	
17124/26050 (epoch 32.868), train_loss = 0.94469864, grad/param norm = 2.2660e-01, time/batch = 18.5628s	
17125/26050 (epoch 32.869), train_loss = 0.80446470, grad/param norm = 1.8958e-01, time/batch = 17.6596s	
17126/26050 (epoch 32.871), train_loss = 0.77253890, grad/param norm = 1.8704e-01, time/batch = 18.3306s	
17127/26050 (epoch 32.873), train_loss = 0.93584132, grad/param norm = 2.3946e-01, time/batch = 18.4066s	
17128/26050 (epoch 32.875), train_loss = 0.85928765, grad/param norm = 2.0699e-01, time/batch = 17.9113s	
17129/26050 (epoch 32.877), train_loss = 0.82341478, grad/param norm = 2.0081e-01, time/batch = 27.7553s	
17130/26050 (epoch 32.879), train_loss = 0.91446669, grad/param norm = 1.9090e-01, time/batch = 28.7563s	
17131/26050 (epoch 32.881), train_loss = 0.96556808, grad/param norm = 2.3115e-01, time/batch = 17.5578s	
17132/26050 (epoch 32.883), train_loss = 0.91080029, grad/param norm = 1.9262e-01, time/batch = 18.3855s	
17133/26050 (epoch 32.885), train_loss = 0.68245374, grad/param norm = 1.8417e-01, time/batch = 16.9545s	
17134/26050 (epoch 32.887), train_loss = 0.94600430, grad/param norm = 2.1108e-01, time/batch = 15.8825s	
17135/26050 (epoch 32.889), train_loss = 0.81751752, grad/param norm = 1.9263e-01, time/batch = 18.1537s	
17136/26050 (epoch 32.891), train_loss = 0.74037779, grad/param norm = 1.8428e-01, time/batch = 17.2335s	
17137/26050 (epoch 32.893), train_loss = 0.76868594, grad/param norm = 2.0398e-01, time/batch = 17.4012s	
17138/26050 (epoch 32.894), train_loss = 0.82744373, grad/param norm = 2.0179e-01, time/batch = 15.1228s	
17139/26050 (epoch 32.896), train_loss = 0.97118606, grad/param norm = 2.2877e-01, time/batch = 17.5621s	
17140/26050 (epoch 32.898), train_loss = 0.84773648, grad/param norm = 2.0830e-01, time/batch = 18.4978s	
17141/26050 (epoch 32.900), train_loss = 0.91287047, grad/param norm = 2.3185e-01, time/batch = 17.2373s	
17142/26050 (epoch 32.902), train_loss = 0.85962902, grad/param norm = 2.0678e-01, time/batch = 18.2399s	
17143/26050 (epoch 32.904), train_loss = 0.84402846, grad/param norm = 1.8870e-01, time/batch = 18.6696s	
17144/26050 (epoch 32.906), train_loss = 0.85881508, grad/param norm = 2.2306e-01, time/batch = 17.9858s	
17145/26050 (epoch 32.908), train_loss = 0.89645066, grad/param norm = 2.0068e-01, time/batch = 17.4004s	
17146/26050 (epoch 32.910), train_loss = 0.85412357, grad/param norm = 2.3124e-01, time/batch = 16.3045s	
17147/26050 (epoch 32.912), train_loss = 1.08856495, grad/param norm = 2.5959e-01, time/batch = 18.0497s	
17148/26050 (epoch 32.914), train_loss = 1.20597979, grad/param norm = 2.3675e-01, time/batch = 17.1503s	
17149/26050 (epoch 32.916), train_loss = 0.96811502, grad/param norm = 2.3101e-01, time/batch = 17.9885s	
17150/26050 (epoch 32.917), train_loss = 0.90515211, grad/param norm = 2.1277e-01, time/batch = 18.9068s	
17151/26050 (epoch 32.919), train_loss = 0.91260703, grad/param norm = 2.2105e-01, time/batch = 18.0752s	
17152/26050 (epoch 32.921), train_loss = 0.83991775, grad/param norm = 2.0495e-01, time/batch = 18.3910s	
17153/26050 (epoch 32.923), train_loss = 0.89627400, grad/param norm = 2.0528e-01, time/batch = 17.5464s	
17154/26050 (epoch 32.925), train_loss = 0.88682735, grad/param norm = 1.9924e-01, time/batch = 15.2326s	
17155/26050 (epoch 32.927), train_loss = 0.80364661, grad/param norm = 1.5686e-01, time/batch = 16.7179s	
17156/26050 (epoch 32.929), train_loss = 0.74667060, grad/param norm = 1.8055e-01, time/batch = 17.3218s	
17157/26050 (epoch 32.931), train_loss = 1.06969092, grad/param norm = 3.4700e-01, time/batch = 18.4987s	
17158/26050 (epoch 32.933), train_loss = 0.88017613, grad/param norm = 2.2314e-01, time/batch = 17.9889s	
17159/26050 (epoch 32.935), train_loss = 0.85190663, grad/param norm = 1.9824e-01, time/batch = 16.5613s	
17160/26050 (epoch 32.937), train_loss = 0.96293473, grad/param norm = 2.0763e-01, time/batch = 15.1368s	
17161/26050 (epoch 32.939), train_loss = 0.80351549, grad/param norm = 1.7309e-01, time/batch = 17.7222s	
17162/26050 (epoch 32.940), train_loss = 0.84274986, grad/param norm = 2.0162e-01, time/batch = 16.6287s	
17163/26050 (epoch 32.942), train_loss = 0.86443334, grad/param norm = 2.1277e-01, time/batch = 16.2968s	
17164/26050 (epoch 32.944), train_loss = 0.85574608, grad/param norm = 2.1636e-01, time/batch = 18.0703s	
17165/26050 (epoch 32.946), train_loss = 1.00132836, grad/param norm = 1.9794e-01, time/batch = 17.3987s	
17166/26050 (epoch 32.948), train_loss = 0.73599716, grad/param norm = 1.9288e-01, time/batch = 18.2347s	
17167/26050 (epoch 32.950), train_loss = 0.87822300, grad/param norm = 2.0872e-01, time/batch = 17.3304s	
17168/26050 (epoch 32.952), train_loss = 0.95112293, grad/param norm = 2.0875e-01, time/batch = 17.4860s	
17169/26050 (epoch 32.954), train_loss = 0.95463280, grad/param norm = 2.3378e-01, time/batch = 16.1361s	
17170/26050 (epoch 32.956), train_loss = 0.85547988, grad/param norm = 2.3751e-01, time/batch = 16.9654s	
17171/26050 (epoch 32.958), train_loss = 0.80423843, grad/param norm = 1.8547e-01, time/batch = 16.6259s	
17172/26050 (epoch 32.960), train_loss = 0.92732845, grad/param norm = 2.3269e-01, time/batch = 17.5637s	
17173/26050 (epoch 32.962), train_loss = 0.86374949, grad/param norm = 1.7851e-01, time/batch = 17.6538s	
17174/26050 (epoch 32.964), train_loss = 0.89163483, grad/param norm = 2.5630e-01, time/batch = 18.8365s	
17175/26050 (epoch 32.965), train_loss = 0.80257895, grad/param norm = 2.1687e-01, time/batch = 17.4937s	
17176/26050 (epoch 32.967), train_loss = 1.18100318, grad/param norm = 2.1425e-01, time/batch = 18.0066s	
17177/26050 (epoch 32.969), train_loss = 0.88771268, grad/param norm = 2.0704e-01, time/batch = 18.0515s	
17178/26050 (epoch 32.971), train_loss = 0.87554485, grad/param norm = 1.9231e-01, time/batch = 16.8822s	
17179/26050 (epoch 32.973), train_loss = 0.89562661, grad/param norm = 2.2858e-01, time/batch = 17.3722s	
17180/26050 (epoch 32.975), train_loss = 0.91456302, grad/param norm = 1.9864e-01, time/batch = 17.4724s	
17181/26050 (epoch 32.977), train_loss = 0.88562320, grad/param norm = 1.8239e-01, time/batch = 16.8159s	
17182/26050 (epoch 32.979), train_loss = 0.74295350, grad/param norm = 2.0007e-01, time/batch = 15.3055s	
17183/26050 (epoch 32.981), train_loss = 0.99207814, grad/param norm = 1.9821e-01, time/batch = 18.5741s	
17184/26050 (epoch 32.983), train_loss = 0.94529660, grad/param norm = 2.0978e-01, time/batch = 18.6456s	
17185/26050 (epoch 32.985), train_loss = 0.94442802, grad/param norm = 2.2144e-01, time/batch = 18.2327s	
17186/26050 (epoch 32.987), train_loss = 0.98678222, grad/param norm = 1.9338e-01, time/batch = 18.6482s	
17187/26050 (epoch 32.988), train_loss = 0.92212908, grad/param norm = 2.1501e-01, time/batch = 17.0603s	
17188/26050 (epoch 32.990), train_loss = 0.78069301, grad/param norm = 1.7758e-01, time/batch = 15.9496s	
17189/26050 (epoch 32.992), train_loss = 1.03065772, grad/param norm = 2.1929e-01, time/batch = 17.6307s	
17190/26050 (epoch 32.994), train_loss = 0.84189945, grad/param norm = 2.2927e-01, time/batch = 18.4885s	
17191/26050 (epoch 32.996), train_loss = 0.80913951, grad/param norm = 2.0901e-01, time/batch = 18.7348s	
17192/26050 (epoch 32.998), train_loss = 0.90894141, grad/param norm = 2.0763e-01, time/batch = 17.2222s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
17193/26050 (epoch 33.000), train_loss = 0.83389657, grad/param norm = 1.9776e-01, time/batch = 18.3091s	
17194/26050 (epoch 33.002), train_loss = 0.95270143, grad/param norm = 2.1422e-01, time/batch = 16.3104s	
17195/26050 (epoch 33.004), train_loss = 0.78577904, grad/param norm = 1.8207e-01, time/batch = 18.8943s	
17196/26050 (epoch 33.006), train_loss = 0.81884940, grad/param norm = 2.2440e-01, time/batch = 18.0563s	
17197/26050 (epoch 33.008), train_loss = 0.82135647, grad/param norm = 2.0572e-01, time/batch = 18.5502s	
17198/26050 (epoch 33.010), train_loss = 0.80278617, grad/param norm = 1.7963e-01, time/batch = 18.1606s	
17199/26050 (epoch 33.012), train_loss = 0.87081375, grad/param norm = 1.9606e-01, time/batch = 17.7348s	
17200/26050 (epoch 33.013), train_loss = 1.10404038, grad/param norm = 2.5162e-01, time/batch = 19.6162s	
17201/26050 (epoch 33.015), train_loss = 0.88202500, grad/param norm = 1.9224e-01, time/batch = 15.1513s	
17202/26050 (epoch 33.017), train_loss = 0.91024999, grad/param norm = 1.8998e-01, time/batch = 14.7888s	
17203/26050 (epoch 33.019), train_loss = 0.77388421, grad/param norm = 1.5679e-01, time/batch = 18.7286s	
17204/26050 (epoch 33.021), train_loss = 0.97888907, grad/param norm = 2.1134e-01, time/batch = 17.3181s	
17205/26050 (epoch 33.023), train_loss = 0.73907169, grad/param norm = 2.0765e-01, time/batch = 18.3146s	
17206/26050 (epoch 33.025), train_loss = 0.85307007, grad/param norm = 2.0465e-01, time/batch = 17.7395s	
17207/26050 (epoch 33.027), train_loss = 0.71781110, grad/param norm = 1.9701e-01, time/batch = 16.4630s	
17208/26050 (epoch 33.029), train_loss = 0.90622694, grad/param norm = 2.0255e-01, time/batch = 18.8160s	
17209/26050 (epoch 33.031), train_loss = 0.99584898, grad/param norm = 2.1526e-01, time/batch = 17.1503s	
17210/26050 (epoch 33.033), train_loss = 0.89581970, grad/param norm = 2.0735e-01, time/batch = 18.2278s	
17211/26050 (epoch 33.035), train_loss = 0.92471987, grad/param norm = 2.0029e-01, time/batch = 18.2400s	
17212/26050 (epoch 33.036), train_loss = 0.77646985, grad/param norm = 2.1117e-01, time/batch = 18.3952s	
17213/26050 (epoch 33.038), train_loss = 0.70680157, grad/param norm = 1.7585e-01, time/batch = 17.2304s	
17214/26050 (epoch 33.040), train_loss = 0.85657038, grad/param norm = 1.9592e-01, time/batch = 18.3995s	
17215/26050 (epoch 33.042), train_loss = 0.75287430, grad/param norm = 1.9561e-01, time/batch = 19.1441s	
17216/26050 (epoch 33.044), train_loss = 0.94853362, grad/param norm = 1.8355e-01, time/batch = 17.3999s	
17217/26050 (epoch 33.046), train_loss = 0.73009973, grad/param norm = 1.5967e-01, time/batch = 16.1238s	
17218/26050 (epoch 33.048), train_loss = 0.87482092, grad/param norm = 1.9679e-01, time/batch = 17.9763s	
17219/26050 (epoch 33.050), train_loss = 0.82754596, grad/param norm = 1.9506e-01, time/batch = 17.6542s	
17220/26050 (epoch 33.052), train_loss = 0.80273785, grad/param norm = 2.0628e-01, time/batch = 17.9926s	
17221/26050 (epoch 33.054), train_loss = 0.72196228, grad/param norm = 1.8931e-01, time/batch = 16.9717s	
17222/26050 (epoch 33.056), train_loss = 0.70407507, grad/param norm = 1.7641e-01, time/batch = 18.2380s	
17223/26050 (epoch 33.058), train_loss = 0.85951594, grad/param norm = 1.9018e-01, time/batch = 17.9176s	
17224/26050 (epoch 33.060), train_loss = 0.91573569, grad/param norm = 1.9908e-01, time/batch = 18.1421s	
17225/26050 (epoch 33.061), train_loss = 0.78464079, grad/param norm = 1.8394e-01, time/batch = 16.7364s	
17226/26050 (epoch 33.063), train_loss = 0.86500284, grad/param norm = 1.9831e-01, time/batch = 15.7779s	
17227/26050 (epoch 33.065), train_loss = 0.71869410, grad/param norm = 1.6793e-01, time/batch = 16.3076s	
17228/26050 (epoch 33.067), train_loss = 0.85621188, grad/param norm = 1.9091e-01, time/batch = 17.1454s	
17229/26050 (epoch 33.069), train_loss = 0.90052885, grad/param norm = 2.0826e-01, time/batch = 18.5626s	
17230/26050 (epoch 33.071), train_loss = 0.90729813, grad/param norm = 2.1854e-01, time/batch = 16.7109s	
17231/26050 (epoch 33.073), train_loss = 1.01855076, grad/param norm = 2.0648e-01, time/batch = 17.8987s	
17232/26050 (epoch 33.075), train_loss = 0.81413420, grad/param norm = 1.9441e-01, time/batch = 18.5762s	
17233/26050 (epoch 33.077), train_loss = 0.81761191, grad/param norm = 2.0460e-01, time/batch = 17.1626s	
17234/26050 (epoch 33.079), train_loss = 0.86538068, grad/param norm = 2.2634e-01, time/batch = 15.6401s	
17235/26050 (epoch 33.081), train_loss = 0.83261609, grad/param norm = 1.9171e-01, time/batch = 18.6423s	
17236/26050 (epoch 33.083), train_loss = 0.96639210, grad/param norm = 1.9992e-01, time/batch = 17.3931s	
17237/26050 (epoch 33.084), train_loss = 0.89172152, grad/param norm = 2.7188e-01, time/batch = 17.7360s	
17238/26050 (epoch 33.086), train_loss = 1.02469882, grad/param norm = 2.4550e-01, time/batch = 17.7234s	
17239/26050 (epoch 33.088), train_loss = 0.84502697, grad/param norm = 2.1210e-01, time/batch = 17.7048s	
17240/26050 (epoch 33.090), train_loss = 0.89368505, grad/param norm = 2.1888e-01, time/batch = 17.4892s	
17241/26050 (epoch 33.092), train_loss = 0.90305316, grad/param norm = 1.8467e-01, time/batch = 18.6389s	
17242/26050 (epoch 33.094), train_loss = 0.76280305, grad/param norm = 1.9054e-01, time/batch = 18.5562s	
17243/26050 (epoch 33.096), train_loss = 0.89694072, grad/param norm = 1.9240e-01, time/batch = 17.1591s	
17244/26050 (epoch 33.098), train_loss = 0.86419833, grad/param norm = 1.9212e-01, time/batch = 18.8232s	
17245/26050 (epoch 33.100), train_loss = 0.79355195, grad/param norm = 2.1759e-01, time/batch = 18.4851s	
17246/26050 (epoch 33.102), train_loss = 0.90484308, grad/param norm = 2.0554e-01, time/batch = 18.0567s	
17247/26050 (epoch 33.104), train_loss = 0.83484522, grad/param norm = 2.2000e-01, time/batch = 17.0474s	
17248/26050 (epoch 33.106), train_loss = 0.90296644, grad/param norm = 2.1401e-01, time/batch = 16.0783s	
17249/26050 (epoch 33.107), train_loss = 0.71867472, grad/param norm = 1.8471e-01, time/batch = 16.7225s	
17250/26050 (epoch 33.109), train_loss = 0.80761316, grad/param norm = 1.8796e-01, time/batch = 17.4836s	
17251/26050 (epoch 33.111), train_loss = 1.00688093, grad/param norm = 2.1426e-01, time/batch = 18.3231s	
17252/26050 (epoch 33.113), train_loss = 0.83923225, grad/param norm = 1.9490e-01, time/batch = 17.9071s	
17253/26050 (epoch 33.115), train_loss = 0.97109935, grad/param norm = 2.1509e-01, time/batch = 17.5617s	
17254/26050 (epoch 33.117), train_loss = 0.87479604, grad/param norm = 1.9471e-01, time/batch = 18.4151s	
17255/26050 (epoch 33.119), train_loss = 0.75018058, grad/param norm = 1.9468e-01, time/batch = 17.9877s	
17256/26050 (epoch 33.121), train_loss = 0.89376540, grad/param norm = 2.1558e-01, time/batch = 17.2440s	
17257/26050 (epoch 33.123), train_loss = 0.78781456, grad/param norm = 1.8645e-01, time/batch = 17.8100s	
17258/26050 (epoch 33.125), train_loss = 0.74732428, grad/param norm = 1.7783e-01, time/batch = 17.7323s	
17259/26050 (epoch 33.127), train_loss = 0.71771348, grad/param norm = 1.6842e-01, time/batch = 18.9794s	
17260/26050 (epoch 33.129), train_loss = 0.69590685, grad/param norm = 2.0586e-01, time/batch = 16.8356s	
17261/26050 (epoch 33.131), train_loss = 0.83564533, grad/param norm = 2.1559e-01, time/batch = 18.3999s	
17262/26050 (epoch 33.132), train_loss = 0.85545168, grad/param norm = 1.8939e-01, time/batch = 15.0592s	
17263/26050 (epoch 33.134), train_loss = 0.89382473, grad/param norm = 2.1113e-01, time/batch = 17.9850s	
17264/26050 (epoch 33.136), train_loss = 0.84040730, grad/param norm = 1.7940e-01, time/batch = 17.4012s	
17265/26050 (epoch 33.138), train_loss = 0.62542694, grad/param norm = 1.8816e-01, time/batch = 18.2391s	
17266/26050 (epoch 33.140), train_loss = 0.72383292, grad/param norm = 2.0634e-01, time/batch = 18.8102s	
17267/26050 (epoch 33.142), train_loss = 0.76012025, grad/param norm = 1.9616e-01, time/batch = 14.3376s	
17268/26050 (epoch 33.144), train_loss = 0.69748573, grad/param norm = 1.9442e-01, time/batch = 14.2009s	
17269/26050 (epoch 33.146), train_loss = 0.65880757, grad/param norm = 1.8604e-01, time/batch = 14.4079s	
17270/26050 (epoch 33.148), train_loss = 0.69493517, grad/param norm = 1.7683e-01, time/batch = 13.9154s	
17271/26050 (epoch 33.150), train_loss = 0.80898565, grad/param norm = 2.1408e-01, time/batch = 17.0725s	
17272/26050 (epoch 33.152), train_loss = 0.99269577, grad/param norm = 2.3969e-01, time/batch = 18.5805s	
17273/26050 (epoch 33.154), train_loss = 0.70302906, grad/param norm = 1.9637e-01, time/batch = 18.4758s	
17274/26050 (epoch 33.155), train_loss = 0.73655720, grad/param norm = 2.0378e-01, time/batch = 14.4491s	
17275/26050 (epoch 33.157), train_loss = 0.84397883, grad/param norm = 2.5552e-01, time/batch = 18.2266s	
17276/26050 (epoch 33.159), train_loss = 0.89915968, grad/param norm = 2.2271e-01, time/batch = 15.3079s	
17277/26050 (epoch 33.161), train_loss = 0.88063722, grad/param norm = 2.4367e-01, time/batch = 18.2237s	
17278/26050 (epoch 33.163), train_loss = 0.71768989, grad/param norm = 1.9759e-01, time/batch = 17.4852s	
17279/26050 (epoch 33.165), train_loss = 0.65534463, grad/param norm = 1.6998e-01, time/batch = 18.4795s	
17280/26050 (epoch 33.167), train_loss = 1.00498223, grad/param norm = 2.2800e-01, time/batch = 18.8861s	
17281/26050 (epoch 33.169), train_loss = 0.87188175, grad/param norm = 2.2993e-01, time/batch = 16.9699s	
17282/26050 (epoch 33.171), train_loss = 0.75404752, grad/param norm = 1.9577e-01, time/batch = 16.4563s	
17283/26050 (epoch 33.173), train_loss = 0.84171566, grad/param norm = 2.3008e-01, time/batch = 18.3171s	
17284/26050 (epoch 33.175), train_loss = 0.84639402, grad/param norm = 1.9574e-01, time/batch = 18.1564s	
17285/26050 (epoch 33.177), train_loss = 0.94434551, grad/param norm = 2.0879e-01, time/batch = 16.1481s	
17286/26050 (epoch 33.179), train_loss = 0.63959957, grad/param norm = 1.7294e-01, time/batch = 18.7410s	
17287/26050 (epoch 33.180), train_loss = 1.08617537, grad/param norm = 2.0542e-01, time/batch = 18.2407s	
17288/26050 (epoch 33.182), train_loss = 1.03680214, grad/param norm = 2.4177e-01, time/batch = 16.6398s	
17289/26050 (epoch 33.184), train_loss = 0.87404300, grad/param norm = 1.8715e-01, time/batch = 17.7484s	
17290/26050 (epoch 33.186), train_loss = 0.71680721, grad/param norm = 1.8643e-01, time/batch = 16.4614s	
17291/26050 (epoch 33.188), train_loss = 0.90312341, grad/param norm = 2.2235e-01, time/batch = 14.6110s	
17292/26050 (epoch 33.190), train_loss = 0.89820821, grad/param norm = 2.3621e-01, time/batch = 17.6582s	
17293/26050 (epoch 33.192), train_loss = 0.94118008, grad/param norm = 1.9352e-01, time/batch = 18.1454s	
17294/26050 (epoch 33.194), train_loss = 0.89743080, grad/param norm = 2.0441e-01, time/batch = 18.3905s	
17295/26050 (epoch 33.196), train_loss = 0.93366244, grad/param norm = 2.0873e-01, time/batch = 17.2265s	
17296/26050 (epoch 33.198), train_loss = 0.77880260, grad/param norm = 1.7394e-01, time/batch = 15.3803s	
17297/26050 (epoch 33.200), train_loss = 0.76976175, grad/param norm = 1.9836e-01, time/batch = 18.3015s	
17298/26050 (epoch 33.202), train_loss = 0.87691327, grad/param norm = 1.7817e-01, time/batch = 17.8048s	
17299/26050 (epoch 33.203), train_loss = 0.95846793, grad/param norm = 1.9593e-01, time/batch = 15.2907s	
17300/26050 (epoch 33.205), train_loss = 0.79568249, grad/param norm = 1.8652e-01, time/batch = 18.4751s	
17301/26050 (epoch 33.207), train_loss = 0.80007165, grad/param norm = 2.4757e-01, time/batch = 18.8982s	
17302/26050 (epoch 33.209), train_loss = 0.92838424, grad/param norm = 2.1119e-01, time/batch = 17.5796s	
17303/26050 (epoch 33.211), train_loss = 0.75617087, grad/param norm = 2.0787e-01, time/batch = 18.7331s	
17304/26050 (epoch 33.213), train_loss = 0.89074330, grad/param norm = 2.2692e-01, time/batch = 18.4921s	
17305/26050 (epoch 33.215), train_loss = 0.84806047, grad/param norm = 2.3884e-01, time/batch = 17.3919s	
17306/26050 (epoch 33.217), train_loss = 0.81489153, grad/param norm = 1.8838e-01, time/batch = 17.1350s	
17307/26050 (epoch 33.219), train_loss = 0.82704478, grad/param norm = 2.3030e-01, time/batch = 16.4768s	
17308/26050 (epoch 33.221), train_loss = 0.77290561, grad/param norm = 1.9612e-01, time/batch = 17.4900s	
17309/26050 (epoch 33.223), train_loss = 0.94321069, grad/param norm = 2.1134e-01, time/batch = 18.4062s	
17310/26050 (epoch 33.225), train_loss = 0.77983604, grad/param norm = 2.0666e-01, time/batch = 16.3218s	
17311/26050 (epoch 33.226), train_loss = 0.89395712, grad/param norm = 2.3098e-01, time/batch = 16.8936s	
17312/26050 (epoch 33.228), train_loss = 1.01610567, grad/param norm = 2.0777e-01, time/batch = 17.1354s	
17313/26050 (epoch 33.230), train_loss = 0.85297421, grad/param norm = 1.8043e-01, time/batch = 18.8168s	
17314/26050 (epoch 33.232), train_loss = 0.94199474, grad/param norm = 2.2611e-01, time/batch = 18.1421s	
17315/26050 (epoch 33.234), train_loss = 0.76504518, grad/param norm = 1.9916e-01, time/batch = 17.1681s	
17316/26050 (epoch 33.236), train_loss = 0.94112733, grad/param norm = 2.0666e-01, time/batch = 17.0803s	
17317/26050 (epoch 33.238), train_loss = 0.72922525, grad/param norm = 1.9363e-01, time/batch = 18.1581s	
17318/26050 (epoch 33.240), train_loss = 0.87349633, grad/param norm = 2.1482e-01, time/batch = 16.9770s	
17319/26050 (epoch 33.242), train_loss = 0.82227744, grad/param norm = 1.9541e-01, time/batch = 16.6268s	
17320/26050 (epoch 33.244), train_loss = 0.88388990, grad/param norm = 2.4258e-01, time/batch = 18.2345s	
17321/26050 (epoch 33.246), train_loss = 0.81870650, grad/param norm = 1.8706e-01, time/batch = 18.0707s	
17322/26050 (epoch 33.248), train_loss = 0.86775795, grad/param norm = 1.9821e-01, time/batch = 17.2369s	
17323/26050 (epoch 33.250), train_loss = 0.87755915, grad/param norm = 2.4557e-01, time/batch = 18.1583s	
17324/26050 (epoch 33.251), train_loss = 0.81410702, grad/param norm = 2.0424e-01, time/batch = 18.3375s	
17325/26050 (epoch 33.253), train_loss = 0.78824533, grad/param norm = 2.0035e-01, time/batch = 15.1271s	
17326/26050 (epoch 33.255), train_loss = 1.02993865, grad/param norm = 2.3776e-01, time/batch = 15.8145s	
17327/26050 (epoch 33.257), train_loss = 0.87000952, grad/param norm = 2.6334e-01, time/batch = 18.1459s	
17328/26050 (epoch 33.259), train_loss = 0.96492479, grad/param norm = 2.2331e-01, time/batch = 18.8327s	
17329/26050 (epoch 33.261), train_loss = 0.77370229, grad/param norm = 2.0726e-01, time/batch = 17.9777s	
17330/26050 (epoch 33.263), train_loss = 0.96904020, grad/param norm = 2.3679e-01, time/batch = 17.4040s	
17331/26050 (epoch 33.265), train_loss = 1.00135990, grad/param norm = 2.4298e-01, time/batch = 17.0467s	
17332/26050 (epoch 33.267), train_loss = 0.98752925, grad/param norm = 2.1028e-01, time/batch = 20.0263s	
17333/26050 (epoch 33.269), train_loss = 0.96762168, grad/param norm = 2.0492e-01, time/batch = 30.3664s	
17334/26050 (epoch 33.271), train_loss = 0.88922933, grad/param norm = 2.0952e-01, time/batch = 23.0525s	
17335/26050 (epoch 33.273), train_loss = 0.78722810, grad/param norm = 2.1846e-01, time/batch = 18.4174s	
17336/26050 (epoch 33.274), train_loss = 0.82503633, grad/param norm = 1.8512e-01, time/batch = 18.4059s	
17337/26050 (epoch 33.276), train_loss = 0.82147248, grad/param norm = 1.8127e-01, time/batch = 18.5812s	
17338/26050 (epoch 33.278), train_loss = 0.94366858, grad/param norm = 2.1449e-01, time/batch = 16.9053s	
17339/26050 (epoch 33.280), train_loss = 0.86731042, grad/param norm = 1.8617e-01, time/batch = 15.4621s	
17340/26050 (epoch 33.282), train_loss = 0.91588650, grad/param norm = 1.8959e-01, time/batch = 14.5959s	
17341/26050 (epoch 33.284), train_loss = 0.84556582, grad/param norm = 1.8946e-01, time/batch = 16.6462s	
17342/26050 (epoch 33.286), train_loss = 0.90598043, grad/param norm = 2.1184e-01, time/batch = 17.0573s	
17343/26050 (epoch 33.288), train_loss = 0.74384868, grad/param norm = 1.7398e-01, time/batch = 17.2997s	
17344/26050 (epoch 33.290), train_loss = 0.87397497, grad/param norm = 2.0752e-01, time/batch = 14.1802s	
17345/26050 (epoch 33.292), train_loss = 0.79531844, grad/param norm = 2.1814e-01, time/batch = 16.4851s	
17346/26050 (epoch 33.294), train_loss = 0.87158730, grad/param norm = 2.1066e-01, time/batch = 17.9027s	
17347/26050 (epoch 33.296), train_loss = 0.95770380, grad/param norm = 2.0701e-01, time/batch = 15.0048s	
17348/26050 (epoch 33.298), train_loss = 0.89694697, grad/param norm = 1.9309e-01, time/batch = 14.0478s	
17349/26050 (epoch 33.299), train_loss = 0.72143430, grad/param norm = 1.8457e-01, time/batch = 16.1957s	
17350/26050 (epoch 33.301), train_loss = 0.73644902, grad/param norm = 1.8783e-01, time/batch = 14.6178s	
17351/26050 (epoch 33.303), train_loss = 0.86330850, grad/param norm = 2.0789e-01, time/batch = 14.3420s	
17352/26050 (epoch 33.305), train_loss = 0.70766865, grad/param norm = 1.9547e-01, time/batch = 13.9335s	
17353/26050 (epoch 33.307), train_loss = 0.78729276, grad/param norm = 2.2100e-01, time/batch = 15.6626s	
17354/26050 (epoch 33.309), train_loss = 0.87470498, grad/param norm = 2.0553e-01, time/batch = 17.0754s	
17355/26050 (epoch 33.311), train_loss = 0.88807162, grad/param norm = 2.2473e-01, time/batch = 15.7284s	
17356/26050 (epoch 33.313), train_loss = 0.86548837, grad/param norm = 2.2308e-01, time/batch = 18.9029s	
17357/26050 (epoch 33.315), train_loss = 0.92353958, grad/param norm = 1.9744e-01, time/batch = 18.1527s	
17358/26050 (epoch 33.317), train_loss = 0.88561829, grad/param norm = 2.3749e-01, time/batch = 17.7313s	
17359/26050 (epoch 33.319), train_loss = 0.80327879, grad/param norm = 2.3553e-01, time/batch = 18.5679s	
17360/26050 (epoch 33.321), train_loss = 0.87559545, grad/param norm = 2.6099e-01, time/batch = 17.0598s	
17361/26050 (epoch 33.322), train_loss = 0.94350287, grad/param norm = 2.2638e-01, time/batch = 18.4789s	
17362/26050 (epoch 33.324), train_loss = 0.68986238, grad/param norm = 1.8030e-01, time/batch = 18.0904s	
17363/26050 (epoch 33.326), train_loss = 0.97833015, grad/param norm = 2.1976e-01, time/batch = 17.2348s	
17364/26050 (epoch 33.328), train_loss = 0.89065846, grad/param norm = 1.7810e-01, time/batch = 17.6574s	
17365/26050 (epoch 33.330), train_loss = 0.76798204, grad/param norm = 2.0997e-01, time/batch = 15.4208s	
17366/26050 (epoch 33.332), train_loss = 0.92707943, grad/param norm = 2.1376e-01, time/batch = 15.1938s	
17367/26050 (epoch 33.334), train_loss = 0.78393257, grad/param norm = 1.9233e-01, time/batch = 17.0517s	
17368/26050 (epoch 33.336), train_loss = 0.81135733, grad/param norm = 1.8615e-01, time/batch = 15.9045s	
17369/26050 (epoch 33.338), train_loss = 0.75268013, grad/param norm = 1.9644e-01, time/batch = 16.4041s	
17370/26050 (epoch 33.340), train_loss = 0.89860709, grad/param norm = 2.0619e-01, time/batch = 17.7209s	
17371/26050 (epoch 33.342), train_loss = 0.95130310, grad/param norm = 1.9423e-01, time/batch = 17.8935s	
17372/26050 (epoch 33.344), train_loss = 0.79044133, grad/param norm = 2.2601e-01, time/batch = 18.4728s	
17373/26050 (epoch 33.345), train_loss = 0.84122488, grad/param norm = 2.0640e-01, time/batch = 17.0288s	
17374/26050 (epoch 33.347), train_loss = 0.96502907, grad/param norm = 2.0480e-01, time/batch = 14.9535s	
17375/26050 (epoch 33.349), train_loss = 0.89328935, grad/param norm = 2.0940e-01, time/batch = 18.0673s	
17376/26050 (epoch 33.351), train_loss = 0.89039113, grad/param norm = 2.1968e-01, time/batch = 14.5474s	
17377/26050 (epoch 33.353), train_loss = 0.89272942, grad/param norm = 2.1662e-01, time/batch = 14.9202s	
17378/26050 (epoch 33.355), train_loss = 0.87043928, grad/param norm = 2.4339e-01, time/batch = 15.1217s	
17379/26050 (epoch 33.357), train_loss = 0.82166672, grad/param norm = 1.8044e-01, time/batch = 14.4587s	
17380/26050 (epoch 33.359), train_loss = 0.94725931, grad/param norm = 2.0995e-01, time/batch = 15.3731s	
17381/26050 (epoch 33.361), train_loss = 0.77197523, grad/param norm = 1.6610e-01, time/batch = 17.1337s	
17382/26050 (epoch 33.363), train_loss = 0.94448980, grad/param norm = 2.0577e-01, time/batch = 17.8213s	
17383/26050 (epoch 33.365), train_loss = 0.83846537, grad/param norm = 1.8467e-01, time/batch = 18.0667s	
17384/26050 (epoch 33.367), train_loss = 0.93375599, grad/param norm = 1.9145e-01, time/batch = 17.9889s	
17385/26050 (epoch 33.369), train_loss = 0.76594370, grad/param norm = 1.6330e-01, time/batch = 16.7185s	
17386/26050 (epoch 33.370), train_loss = 0.75743608, grad/param norm = 1.6474e-01, time/batch = 16.9197s	
17387/26050 (epoch 33.372), train_loss = 0.86972443, grad/param norm = 2.0219e-01, time/batch = 18.4453s	
17388/26050 (epoch 33.374), train_loss = 0.98865969, grad/param norm = 2.1635e-01, time/batch = 15.9691s	
17389/26050 (epoch 33.376), train_loss = 1.01243964, grad/param norm = 2.2724e-01, time/batch = 16.7359s	
17390/26050 (epoch 33.378), train_loss = 0.83075683, grad/param norm = 1.9770e-01, time/batch = 18.7280s	
17391/26050 (epoch 33.380), train_loss = 0.99016922, grad/param norm = 2.3791e-01, time/batch = 17.8261s	
17392/26050 (epoch 33.382), train_loss = 1.08964191, grad/param norm = 2.3361e-01, time/batch = 17.4580s	
17393/26050 (epoch 33.384), train_loss = 0.82469949, grad/param norm = 2.0500e-01, time/batch = 17.1670s	
17394/26050 (epoch 33.386), train_loss = 0.92181660, grad/param norm = 2.1180e-01, time/batch = 18.8152s	
17395/26050 (epoch 33.388), train_loss = 0.89953554, grad/param norm = 2.2544e-01, time/batch = 17.5700s	
17396/26050 (epoch 33.390), train_loss = 0.82395764, grad/param norm = 1.9161e-01, time/batch = 16.2909s	
17397/26050 (epoch 33.392), train_loss = 0.75968201, grad/param norm = 1.7169e-01, time/batch = 17.6612s	
17398/26050 (epoch 33.393), train_loss = 0.91317159, grad/param norm = 2.2899e-01, time/batch = 16.1515s	
17399/26050 (epoch 33.395), train_loss = 0.93122017, grad/param norm = 2.1548e-01, time/batch = 17.3858s	
17400/26050 (epoch 33.397), train_loss = 0.93353186, grad/param norm = 2.3976e-01, time/batch = 17.8270s	
17401/26050 (epoch 33.399), train_loss = 0.83731116, grad/param norm = 2.0838e-01, time/batch = 18.4879s	
17402/26050 (epoch 33.401), train_loss = 0.90468553, grad/param norm = 2.2101e-01, time/batch = 16.4919s	
17403/26050 (epoch 33.403), train_loss = 0.90325213, grad/param norm = 2.2586e-01, time/batch = 17.5691s	
17404/26050 (epoch 33.405), train_loss = 0.89406466, grad/param norm = 2.0802e-01, time/batch = 14.3982s	
17405/26050 (epoch 33.407), train_loss = 1.00185761, grad/param norm = 2.4866e-01, time/batch = 18.5655s	
17406/26050 (epoch 33.409), train_loss = 1.01176454, grad/param norm = 2.4761e-01, time/batch = 17.9838s	
17407/26050 (epoch 33.411), train_loss = 0.94586944, grad/param norm = 2.0125e-01, time/batch = 18.0678s	
17408/26050 (epoch 33.413), train_loss = 1.04234898, grad/param norm = 2.1768e-01, time/batch = 18.7290s	
17409/26050 (epoch 33.415), train_loss = 1.02749223, grad/param norm = 2.2575e-01, time/batch = 17.5635s	
17410/26050 (epoch 33.417), train_loss = 1.06954642, grad/param norm = 2.3855e-01, time/batch = 16.4806s	
17411/26050 (epoch 33.418), train_loss = 0.94878147, grad/param norm = 2.2659e-01, time/batch = 16.8007s	
17412/26050 (epoch 33.420), train_loss = 0.76218193, grad/param norm = 1.8528e-01, time/batch = 17.8947s	
17413/26050 (epoch 33.422), train_loss = 0.73532167, grad/param norm = 1.9101e-01, time/batch = 18.1546s	
17414/26050 (epoch 33.424), train_loss = 0.97756831, grad/param norm = 2.1905e-01, time/batch = 18.5570s	
17415/26050 (epoch 33.426), train_loss = 0.95523916, grad/param norm = 2.3286e-01, time/batch = 15.3541s	
17416/26050 (epoch 33.428), train_loss = 0.84075706, grad/param norm = 2.2400e-01, time/batch = 17.9619s	
17417/26050 (epoch 33.430), train_loss = 1.03989081, grad/param norm = 2.3111e-01, time/batch = 18.3925s	
17418/26050 (epoch 33.432), train_loss = 0.86766557, grad/param norm = 2.2328e-01, time/batch = 18.3161s	
17419/26050 (epoch 33.434), train_loss = 0.84793131, grad/param norm = 2.0968e-01, time/batch = 16.7311s	
17420/26050 (epoch 33.436), train_loss = 0.97657350, grad/param norm = 2.0159e-01, time/batch = 17.7397s	
17421/26050 (epoch 33.438), train_loss = 0.91753184, grad/param norm = 2.3356e-01, time/batch = 19.1367s	
17422/26050 (epoch 33.440), train_loss = 0.90835059, grad/param norm = 2.0521e-01, time/batch = 16.5470s	
17423/26050 (epoch 33.441), train_loss = 0.91055083, grad/param norm = 1.9273e-01, time/batch = 17.9817s	
17424/26050 (epoch 33.443), train_loss = 0.75088798, grad/param norm = 1.5360e-01, time/batch = 17.5936s	
17425/26050 (epoch 33.445), train_loss = 0.78250221, grad/param norm = 1.7686e-01, time/batch = 17.6628s	
17426/26050 (epoch 33.447), train_loss = 0.98396702, grad/param norm = 2.1024e-01, time/batch = 17.0655s	
17427/26050 (epoch 33.449), train_loss = 0.79970243, grad/param norm = 1.9314e-01, time/batch = 18.0605s	
17428/26050 (epoch 33.451), train_loss = 1.02512202, grad/param norm = 2.1355e-01, time/batch = 15.9799s	
17429/26050 (epoch 33.453), train_loss = 0.82451889, grad/param norm = 1.8503e-01, time/batch = 17.2364s	
17430/26050 (epoch 33.455), train_loss = 0.87685020, grad/param norm = 1.8844e-01, time/batch = 17.7380s	
17431/26050 (epoch 33.457), train_loss = 0.87558401, grad/param norm = 2.0858e-01, time/batch = 18.0079s	
17432/26050 (epoch 33.459), train_loss = 0.97724843, grad/param norm = 2.2574e-01, time/batch = 14.1433s	
17433/26050 (epoch 33.461), train_loss = 0.99441933, grad/param norm = 2.2354e-01, time/batch = 14.9149s	
17434/26050 (epoch 33.463), train_loss = 0.84166946, grad/param norm = 1.7031e-01, time/batch = 16.4266s	
17435/26050 (epoch 33.464), train_loss = 0.91274199, grad/param norm = 1.9276e-01, time/batch = 16.3292s	
17436/26050 (epoch 33.466), train_loss = 0.88963191, grad/param norm = 2.1547e-01, time/batch = 18.1483s	
17437/26050 (epoch 33.468), train_loss = 0.99468384, grad/param norm = 1.9596e-01, time/batch = 17.7257s	
17438/26050 (epoch 33.470), train_loss = 0.97960344, grad/param norm = 2.2210e-01, time/batch = 17.9815s	
17439/26050 (epoch 33.472), train_loss = 0.99221355, grad/param norm = 2.4456e-01, time/batch = 16.6389s	
17440/26050 (epoch 33.474), train_loss = 0.99780035, grad/param norm = 2.1792e-01, time/batch = 17.2195s	
17441/26050 (epoch 33.476), train_loss = 0.96998883, grad/param norm = 1.9104e-01, time/batch = 18.6469s	
17442/26050 (epoch 33.478), train_loss = 0.84610779, grad/param norm = 1.8508e-01, time/batch = 18.6549s	
17443/26050 (epoch 33.480), train_loss = 0.86309979, grad/param norm = 1.8965e-01, time/batch = 18.2288s	
17444/26050 (epoch 33.482), train_loss = 0.82772442, grad/param norm = 2.0606e-01, time/batch = 18.3091s	
17445/26050 (epoch 33.484), train_loss = 0.81926903, grad/param norm = 1.9309e-01, time/batch = 17.3111s	
17446/26050 (epoch 33.486), train_loss = 1.00272837, grad/param norm = 1.9409e-01, time/batch = 18.5785s	
17447/26050 (epoch 33.488), train_loss = 1.02801670, grad/param norm = 2.3295e-01, time/batch = 18.3188s	
17448/26050 (epoch 33.489), train_loss = 1.05580215, grad/param norm = 2.3075e-01, time/batch = 15.2406s	
17449/26050 (epoch 33.491), train_loss = 0.82794593, grad/param norm = 2.4160e-01, time/batch = 18.8083s	
17450/26050 (epoch 33.493), train_loss = 0.90989258, grad/param norm = 2.2229e-01, time/batch = 17.4024s	
17451/26050 (epoch 33.495), train_loss = 0.86934213, grad/param norm = 1.8517e-01, time/batch = 18.1460s	
17452/26050 (epoch 33.497), train_loss = 0.79587653, grad/param norm = 2.0692e-01, time/batch = 15.2260s	
17453/26050 (epoch 33.499), train_loss = 0.83110393, grad/param norm = 2.0531e-01, time/batch = 17.9485s	
17454/26050 (epoch 33.501), train_loss = 0.97036366, grad/param norm = 1.8811e-01, time/batch = 15.4707s	
17455/26050 (epoch 33.503), train_loss = 0.83270981, grad/param norm = 1.8886e-01, time/batch = 18.5681s	
17456/26050 (epoch 33.505), train_loss = 0.98785254, grad/param norm = 2.0117e-01, time/batch = 17.4818s	
17457/26050 (epoch 33.507), train_loss = 0.96483899, grad/param norm = 2.3157e-01, time/batch = 16.5525s	
17458/26050 (epoch 33.509), train_loss = 1.02923573, grad/param norm = 2.0124e-01, time/batch = 18.6695s	
17459/26050 (epoch 33.511), train_loss = 0.85576103, grad/param norm = 1.6443e-01, time/batch = 18.1545s	
17460/26050 (epoch 33.512), train_loss = 0.78275151, grad/param norm = 2.0516e-01, time/batch = 17.5726s	
17461/26050 (epoch 33.514), train_loss = 0.92251873, grad/param norm = 1.9933e-01, time/batch = 16.7371s	
17462/26050 (epoch 33.516), train_loss = 1.01412612, grad/param norm = 2.1686e-01, time/batch = 17.6356s	
17463/26050 (epoch 33.518), train_loss = 0.85135149, grad/param norm = 1.9757e-01, time/batch = 14.8691s	
17464/26050 (epoch 33.520), train_loss = 0.89062666, grad/param norm = 1.9955e-01, time/batch = 16.7169s	
17465/26050 (epoch 33.522), train_loss = 0.70523574, grad/param norm = 1.9219e-01, time/batch = 18.0701s	
17466/26050 (epoch 33.524), train_loss = 0.99033762, grad/param norm = 2.3695e-01, time/batch = 16.7459s	
17467/26050 (epoch 33.526), train_loss = 0.99140705, grad/param norm = 2.4509e-01, time/batch = 14.0982s	
17468/26050 (epoch 33.528), train_loss = 0.91950579, grad/param norm = 2.1196e-01, time/batch = 18.2231s	
17469/26050 (epoch 33.530), train_loss = 0.86155944, grad/param norm = 2.3594e-01, time/batch = 18.3203s	
17470/26050 (epoch 33.532), train_loss = 0.91703580, grad/param norm = 2.0435e-01, time/batch = 16.3915s	
17471/26050 (epoch 33.534), train_loss = 0.92274936, grad/param norm = 2.3043e-01, time/batch = 17.0480s	
17472/26050 (epoch 33.536), train_loss = 0.90542284, grad/param norm = 1.9591e-01, time/batch = 17.8861s	
17473/26050 (epoch 33.537), train_loss = 0.96077839, grad/param norm = 2.1102e-01, time/batch = 19.2341s	
17474/26050 (epoch 33.539), train_loss = 0.88985515, grad/param norm = 1.9814e-01, time/batch = 17.1388s	
17475/26050 (epoch 33.541), train_loss = 1.04219354, grad/param norm = 2.3497e-01, time/batch = 17.6429s	
17476/26050 (epoch 33.543), train_loss = 0.71628748, grad/param norm = 1.9042e-01, time/batch = 15.1218s	
17477/26050 (epoch 33.545), train_loss = 0.89327017, grad/param norm = 2.0969e-01, time/batch = 16.0565s	
17478/26050 (epoch 33.547), train_loss = 0.86014000, grad/param norm = 2.0257e-01, time/batch = 17.3041s	
17479/26050 (epoch 33.549), train_loss = 0.77264028, grad/param norm = 2.1720e-01, time/batch = 16.6333s	
17480/26050 (epoch 33.551), train_loss = 0.92872916, grad/param norm = 1.9592e-01, time/batch = 16.0460s	
17481/26050 (epoch 33.553), train_loss = 0.84663003, grad/param norm = 2.0053e-01, time/batch = 17.9774s	
17482/26050 (epoch 33.555), train_loss = 0.79158123, grad/param norm = 2.0574e-01, time/batch = 18.1539s	
17483/26050 (epoch 33.557), train_loss = 0.90239225, grad/param norm = 1.9473e-01, time/batch = 17.7368s	
17484/26050 (epoch 33.559), train_loss = 0.88913218, grad/param norm = 2.0632e-01, time/batch = 18.8219s	
17485/26050 (epoch 33.560), train_loss = 0.84849379, grad/param norm = 2.0982e-01, time/batch = 18.3873s	
17486/26050 (epoch 33.562), train_loss = 0.88935038, grad/param norm = 2.3121e-01, time/batch = 17.8934s	
17487/26050 (epoch 33.564), train_loss = 1.06032420, grad/param norm = 2.1496e-01, time/batch = 18.4946s	
17488/26050 (epoch 33.566), train_loss = 0.82042803, grad/param norm = 1.8483e-01, time/batch = 16.7277s	
17489/26050 (epoch 33.568), train_loss = 0.92817738, grad/param norm = 2.0704e-01, time/batch = 17.2504s	
17490/26050 (epoch 33.570), train_loss = 0.89582590, grad/param norm = 2.1031e-01, time/batch = 16.2354s	
17491/26050 (epoch 33.572), train_loss = 0.89065776, grad/param norm = 2.0634e-01, time/batch = 15.3753s	
17492/26050 (epoch 33.574), train_loss = 0.89532486, grad/param norm = 2.4049e-01, time/batch = 15.6529s	
17493/26050 (epoch 33.576), train_loss = 0.92686856, grad/param norm = 2.0684e-01, time/batch = 17.2273s	
17494/26050 (epoch 33.578), train_loss = 0.88359795, grad/param norm = 2.3275e-01, time/batch = 17.2331s	
17495/26050 (epoch 33.580), train_loss = 0.82026372, grad/param norm = 2.1133e-01, time/batch = 17.7401s	
17496/26050 (epoch 33.582), train_loss = 0.91096800, grad/param norm = 2.2019e-01, time/batch = 17.5677s	
17497/26050 (epoch 33.583), train_loss = 0.97154308, grad/param norm = 2.1280e-01, time/batch = 17.5748s	
17498/26050 (epoch 33.585), train_loss = 0.79619820, grad/param norm = 2.2435e-01, time/batch = 17.9030s	
17499/26050 (epoch 33.587), train_loss = 0.92621301, grad/param norm = 2.3459e-01, time/batch = 16.6651s	
17500/26050 (epoch 33.589), train_loss = 1.02879873, grad/param norm = 2.3834e-01, time/batch = 13.9114s	
17501/26050 (epoch 33.591), train_loss = 0.88590384, grad/param norm = 2.0243e-01, time/batch = 14.1397s	
17502/26050 (epoch 33.593), train_loss = 0.77012861, grad/param norm = 1.7998e-01, time/batch = 13.9004s	
17503/26050 (epoch 33.595), train_loss = 0.96179125, grad/param norm = 2.4120e-01, time/batch = 13.9144s	
17504/26050 (epoch 33.597), train_loss = 0.90352251, grad/param norm = 2.0074e-01, time/batch = 13.8272s	
17505/26050 (epoch 33.599), train_loss = 0.93869664, grad/param norm = 2.0338e-01, time/batch = 13.8386s	
17506/26050 (epoch 33.601), train_loss = 1.05764876, grad/param norm = 2.2783e-01, time/batch = 13.6747s	
17507/26050 (epoch 33.603), train_loss = 0.94967338, grad/param norm = 2.2934e-01, time/batch = 14.3806s	
17508/26050 (epoch 33.605), train_loss = 0.87576800, grad/param norm = 2.2326e-01, time/batch = 14.3063s	
17509/26050 (epoch 33.607), train_loss = 0.99614251, grad/param norm = 2.5743e-01, time/batch = 13.9925s	
17510/26050 (epoch 33.608), train_loss = 0.80912518, grad/param norm = 1.8366e-01, time/batch = 13.6826s	
17511/26050 (epoch 33.610), train_loss = 0.92204794, grad/param norm = 2.4826e-01, time/batch = 13.9263s	
17512/26050 (epoch 33.612), train_loss = 0.86525787, grad/param norm = 1.9887e-01, time/batch = 13.8288s	
17513/26050 (epoch 33.614), train_loss = 0.91021654, grad/param norm = 2.3350e-01, time/batch = 14.0557s	
17514/26050 (epoch 33.616), train_loss = 0.97088982, grad/param norm = 2.3688e-01, time/batch = 14.0793s	
17515/26050 (epoch 33.618), train_loss = 0.85856830, grad/param norm = 2.1474e-01, time/batch = 13.8307s	
17516/26050 (epoch 33.620), train_loss = 0.96060629, grad/param norm = 2.1381e-01, time/batch = 13.9021s	
17517/26050 (epoch 33.622), train_loss = 0.80563463, grad/param norm = 1.8119e-01, time/batch = 13.9221s	
17518/26050 (epoch 33.624), train_loss = 0.75975522, grad/param norm = 1.9004e-01, time/batch = 13.7559s	
17519/26050 (epoch 33.626), train_loss = 0.94251588, grad/param norm = 2.0786e-01, time/batch = 14.4554s	
17520/26050 (epoch 33.628), train_loss = 0.85014963, grad/param norm = 2.1764e-01, time/batch = 14.3051s	
17521/26050 (epoch 33.630), train_loss = 1.03820705, grad/param norm = 2.0394e-01, time/batch = 17.4146s	
17522/26050 (epoch 33.631), train_loss = 1.05451625, grad/param norm = 2.3047e-01, time/batch = 19.0704s	
17523/26050 (epoch 33.633), train_loss = 0.81230163, grad/param norm = 2.1585e-01, time/batch = 17.9758s	
17524/26050 (epoch 33.635), train_loss = 0.84718487, grad/param norm = 1.8284e-01, time/batch = 17.4013s	
17525/26050 (epoch 33.637), train_loss = 0.79208358, grad/param norm = 2.5055e-01, time/batch = 17.6584s	
17526/26050 (epoch 33.639), train_loss = 0.93153138, grad/param norm = 1.9141e-01, time/batch = 17.7537s	
17527/26050 (epoch 33.641), train_loss = 0.84251810, grad/param norm = 2.0248e-01, time/batch = 15.2066s	
17528/26050 (epoch 33.643), train_loss = 0.82151730, grad/param norm = 1.9482e-01, time/batch = 17.4818s	
17529/26050 (epoch 33.645), train_loss = 0.82279602, grad/param norm = 1.9713e-01, time/batch = 17.9977s	
17530/26050 (epoch 33.647), train_loss = 0.81825230, grad/param norm = 2.0541e-01, time/batch = 16.9671s	
17531/26050 (epoch 33.649), train_loss = 0.85680602, grad/param norm = 1.9096e-01, time/batch = 15.7831s	
17532/26050 (epoch 33.651), train_loss = 0.83983958, grad/param norm = 2.0194e-01, time/batch = 16.4735s	
17533/26050 (epoch 33.653), train_loss = 0.88053263, grad/param norm = 2.1157e-01, time/batch = 16.4439s	
17534/26050 (epoch 33.655), train_loss = 0.79914279, grad/param norm = 1.9027e-01, time/batch = 15.1725s	
17535/26050 (epoch 33.656), train_loss = 0.77633336, grad/param norm = 1.8312e-01, time/batch = 14.7328s	
17536/26050 (epoch 33.658), train_loss = 1.08690734, grad/param norm = 2.2898e-01, time/batch = 14.8930s	
17537/26050 (epoch 33.660), train_loss = 0.77322785, grad/param norm = 2.2309e-01, time/batch = 14.8135s	
17538/26050 (epoch 33.662), train_loss = 0.88556506, grad/param norm = 1.9475e-01, time/batch = 14.7292s	
17539/26050 (epoch 33.664), train_loss = 0.87728855, grad/param norm = 2.0191e-01, time/batch = 14.5787s	
17540/26050 (epoch 33.666), train_loss = 0.83516386, grad/param norm = 2.0939e-01, time/batch = 14.8893s	
17541/26050 (epoch 33.668), train_loss = 0.70385875, grad/param norm = 2.2761e-01, time/batch = 14.9861s	
17542/26050 (epoch 33.670), train_loss = 1.01837676, grad/param norm = 2.7481e-01, time/batch = 14.8943s	
17543/26050 (epoch 33.672), train_loss = 0.87060879, grad/param norm = 2.1068e-01, time/batch = 14.9843s	
17544/26050 (epoch 33.674), train_loss = 0.78644972, grad/param norm = 2.2769e-01, time/batch = 14.6520s	
17545/26050 (epoch 33.676), train_loss = 0.92614832, grad/param norm = 2.0975e-01, time/batch = 14.4950s	
17546/26050 (epoch 33.678), train_loss = 0.97090164, grad/param norm = 2.1392e-01, time/batch = 12.5793s	
17547/26050 (epoch 33.679), train_loss = 1.00835225, grad/param norm = 2.0376e-01, time/batch = 1.3083s	
17548/26050 (epoch 33.681), train_loss = 0.91850855, grad/param norm = 2.2005e-01, time/batch = 0.6761s	
17549/26050 (epoch 33.683), train_loss = 0.79426707, grad/param norm = 2.4505e-01, time/batch = 0.6631s	
17550/26050 (epoch 33.685), train_loss = 0.86698088, grad/param norm = 2.0446e-01, time/batch = 0.6656s	
17551/26050 (epoch 33.687), train_loss = 0.78605378, grad/param norm = 2.0233e-01, time/batch = 0.6650s	
17552/26050 (epoch 33.689), train_loss = 0.84065699, grad/param norm = 2.1418e-01, time/batch = 0.7138s	
17553/26050 (epoch 33.691), train_loss = 0.70945598, grad/param norm = 1.6488e-01, time/batch = 0.9727s	
17554/26050 (epoch 33.693), train_loss = 0.84756889, grad/param norm = 2.0260e-01, time/batch = 0.9687s	
17555/26050 (epoch 33.695), train_loss = 0.87176275, grad/param norm = 2.0662e-01, time/batch = 0.9686s	
17556/26050 (epoch 33.697), train_loss = 0.82898880, grad/param norm = 2.0638e-01, time/batch = 0.9997s	
17557/26050 (epoch 33.699), train_loss = 0.92181244, grad/param norm = 2.1003e-01, time/batch = 1.0516s	
17558/26050 (epoch 33.701), train_loss = 0.79648257, grad/param norm = 1.6257e-01, time/batch = 1.8360s	
17559/26050 (epoch 33.702), train_loss = 0.95330924, grad/param norm = 2.0326e-01, time/batch = 1.8057s	
17560/26050 (epoch 33.704), train_loss = 0.96910238, grad/param norm = 1.9129e-01, time/batch = 6.0012s	
17561/26050 (epoch 33.706), train_loss = 0.81468820, grad/param norm = 2.0649e-01, time/batch = 14.8936s	
17562/26050 (epoch 33.708), train_loss = 0.93936487, grad/param norm = 2.1255e-01, time/batch = 14.8941s	
17563/26050 (epoch 33.710), train_loss = 0.88972798, grad/param norm = 2.1071e-01, time/batch = 14.9710s	
17564/26050 (epoch 33.712), train_loss = 0.88039298, grad/param norm = 2.2939e-01, time/batch = 14.7295s	
17565/26050 (epoch 33.714), train_loss = 0.77818027, grad/param norm = 1.6775e-01, time/batch = 14.7387s	
17566/26050 (epoch 33.716), train_loss = 1.08856236, grad/param norm = 2.3501e-01, time/batch = 14.6585s	
17567/26050 (epoch 33.718), train_loss = 0.92670768, grad/param norm = 2.2122e-01, time/batch = 15.1251s	
17568/26050 (epoch 33.720), train_loss = 0.87380387, grad/param norm = 2.1072e-01, time/batch = 14.7343s	
17569/26050 (epoch 33.722), train_loss = 0.79147547, grad/param norm = 1.8838e-01, time/batch = 14.7415s	
17570/26050 (epoch 33.724), train_loss = 0.82472637, grad/param norm = 2.1463e-01, time/batch = 15.0990s	
17571/26050 (epoch 33.726), train_loss = 0.94807434, grad/param norm = 2.1707e-01, time/batch = 14.9695s	
17572/26050 (epoch 33.727), train_loss = 0.93491263, grad/param norm = 2.1702e-01, time/batch = 14.8929s	
17573/26050 (epoch 33.729), train_loss = 0.91761039, grad/param norm = 2.1472e-01, time/batch = 14.6612s	
17574/26050 (epoch 33.731), train_loss = 0.92237448, grad/param norm = 1.9805e-01, time/batch = 15.0383s	
17575/26050 (epoch 33.733), train_loss = 0.84582604, grad/param norm = 2.0810e-01, time/batch = 14.8221s	
17576/26050 (epoch 33.735), train_loss = 1.03937472, grad/param norm = 2.3568e-01, time/batch = 14.7319s	
17577/26050 (epoch 33.737), train_loss = 0.83850712, grad/param norm = 2.1289e-01, time/batch = 14.8749s	
17578/26050 (epoch 33.739), train_loss = 0.91676124, grad/param norm = 2.1022e-01, time/batch = 14.7332s	
17579/26050 (epoch 33.741), train_loss = 0.81263084, grad/param norm = 1.8639e-01, time/batch = 15.1345s	
17580/26050 (epoch 33.743), train_loss = 0.89686492, grad/param norm = 2.5802e-01, time/batch = 14.8948s	
17581/26050 (epoch 33.745), train_loss = 0.77513704, grad/param norm = 1.9982e-01, time/batch = 14.8171s	
17582/26050 (epoch 33.747), train_loss = 0.80491351, grad/param norm = 1.9477e-01, time/batch = 14.7458s	
17583/26050 (epoch 33.749), train_loss = 0.98558175, grad/param norm = 2.0624e-01, time/batch = 15.0621s	
17584/26050 (epoch 33.750), train_loss = 0.86037460, grad/param norm = 1.7441e-01, time/batch = 14.9743s	
17585/26050 (epoch 33.752), train_loss = 0.82035158, grad/param norm = 2.1862e-01, time/batch = 14.7335s	
17586/26050 (epoch 33.754), train_loss = 0.88146052, grad/param norm = 2.0050e-01, time/batch = 15.2643s	
17587/26050 (epoch 33.756), train_loss = 0.86738853, grad/param norm = 2.3566e-01, time/batch = 15.2760s	
17588/26050 (epoch 33.758), train_loss = 0.87329747, grad/param norm = 2.2300e-01, time/batch = 14.7389s	
17589/26050 (epoch 33.760), train_loss = 1.00911532, grad/param norm = 2.2968e-01, time/batch = 14.8186s	
17590/26050 (epoch 33.762), train_loss = 0.83718479, grad/param norm = 2.0845e-01, time/batch = 14.6629s	
17591/26050 (epoch 33.764), train_loss = 0.85879164, grad/param norm = 2.5987e-01, time/batch = 14.7361s	
17592/26050 (epoch 33.766), train_loss = 0.88250220, grad/param norm = 2.0817e-01, time/batch = 14.4970s	
17593/26050 (epoch 33.768), train_loss = 0.77777697, grad/param norm = 1.8258e-01, time/batch = 14.7362s	
17594/26050 (epoch 33.770), train_loss = 0.84900065, grad/param norm = 2.1341e-01, time/batch = 14.3982s	
17595/26050 (epoch 33.772), train_loss = 0.87666099, grad/param norm = 1.8750e-01, time/batch = 14.8104s	
17596/26050 (epoch 33.774), train_loss = 0.75893865, grad/param norm = 2.2543e-01, time/batch = 15.1209s	
17597/26050 (epoch 33.775), train_loss = 0.65410336, grad/param norm = 2.0716e-01, time/batch = 15.0653s	
17598/26050 (epoch 33.777), train_loss = 0.83394587, grad/param norm = 1.9442e-01, time/batch = 14.7331s	
17599/26050 (epoch 33.779), train_loss = 0.89194146, grad/param norm = 2.6281e-01, time/batch = 14.8071s	
17600/26050 (epoch 33.781), train_loss = 0.78327767, grad/param norm = 1.9304e-01, time/batch = 15.3266s	
17601/26050 (epoch 33.783), train_loss = 0.76855298, grad/param norm = 2.1032e-01, time/batch = 15.3200s	
17602/26050 (epoch 33.785), train_loss = 0.88888204, grad/param norm = 2.2481e-01, time/batch = 14.8037s	
17603/26050 (epoch 33.787), train_loss = 0.79205755, grad/param norm = 2.2025e-01, time/batch = 14.8837s	
17604/26050 (epoch 33.789), train_loss = 0.78651658, grad/param norm = 1.9298e-01, time/batch = 14.8079s	
17605/26050 (epoch 33.791), train_loss = 0.79650547, grad/param norm = 2.1590e-01, time/batch = 15.1931s	
17606/26050 (epoch 33.793), train_loss = 0.86265731, grad/param norm = 2.2432e-01, time/batch = 14.6496s	
17607/26050 (epoch 33.795), train_loss = 0.70996241, grad/param norm = 1.6496e-01, time/batch = 15.3228s	
17608/26050 (epoch 33.797), train_loss = 0.76459460, grad/param norm = 1.9337e-01, time/batch = 14.8865s	
17609/26050 (epoch 33.798), train_loss = 0.78186223, grad/param norm = 2.1143e-01, time/batch = 14.8120s	
17610/26050 (epoch 33.800), train_loss = 0.75604906, grad/param norm = 1.9085e-01, time/batch = 15.0138s	
17611/26050 (epoch 33.802), train_loss = 0.82661219, grad/param norm = 1.9551e-01, time/batch = 14.8767s	
17612/26050 (epoch 33.804), train_loss = 0.84866517, grad/param norm = 2.0009e-01, time/batch = 14.7199s	
17613/26050 (epoch 33.806), train_loss = 0.92866752, grad/param norm = 2.0775e-01, time/batch = 14.5472s	
17614/26050 (epoch 33.808), train_loss = 0.88236334, grad/param norm = 2.2845e-01, time/batch = 14.6426s	
17615/26050 (epoch 33.810), train_loss = 0.85015506, grad/param norm = 2.0757e-01, time/batch = 14.8816s	
17616/26050 (epoch 33.812), train_loss = 0.73682334, grad/param norm = 1.9231e-01, time/batch = 14.8954s	
17617/26050 (epoch 33.814), train_loss = 0.77725485, grad/param norm = 2.2892e-01, time/batch = 15.0458s	
17618/26050 (epoch 33.816), train_loss = 0.90808191, grad/param norm = 2.2642e-01, time/batch = 14.8052s	
17619/26050 (epoch 33.818), train_loss = 0.96969542, grad/param norm = 3.0539e-01, time/batch = 15.1228s	
17620/26050 (epoch 33.820), train_loss = 0.87401598, grad/param norm = 1.9959e-01, time/batch = 15.1030s	
17621/26050 (epoch 33.821), train_loss = 0.97788906, grad/param norm = 2.3508e-01, time/batch = 14.8106s	
17622/26050 (epoch 33.823), train_loss = 1.06427130, grad/param norm = 2.2915e-01, time/batch = 14.8022s	
17623/26050 (epoch 33.825), train_loss = 0.86992137, grad/param norm = 2.2319e-01, time/batch = 14.8857s	
17624/26050 (epoch 33.827), train_loss = 0.90040954, grad/param norm = 2.6750e-01, time/batch = 15.3227s	
17625/26050 (epoch 33.829), train_loss = 0.97600090, grad/param norm = 2.2959e-01, time/batch = 14.7971s	
17626/26050 (epoch 33.831), train_loss = 1.02788636, grad/param norm = 2.8969e-01, time/batch = 14.9563s	
17627/26050 (epoch 33.833), train_loss = 1.03392809, grad/param norm = 2.6503e-01, time/batch = 15.0397s	
17628/26050 (epoch 33.835), train_loss = 1.01455341, grad/param norm = 2.2019e-01, time/batch = 14.7297s	
17629/26050 (epoch 33.837), train_loss = 0.88639506, grad/param norm = 1.8934e-01, time/batch = 14.8119s	
17630/26050 (epoch 33.839), train_loss = 0.87482697, grad/param norm = 2.5206e-01, time/batch = 14.4994s	
17631/26050 (epoch 33.841), train_loss = 0.96687767, grad/param norm = 2.0893e-01, time/batch = 14.8179s	
17632/26050 (epoch 33.843), train_loss = 0.86958524, grad/param norm = 1.8551e-01, time/batch = 14.9558s	
17633/26050 (epoch 33.845), train_loss = 0.82521704, grad/param norm = 1.8843e-01, time/batch = 14.7319s	
17634/26050 (epoch 33.846), train_loss = 0.91829858, grad/param norm = 2.1630e-01, time/batch = 14.8023s	
17635/26050 (epoch 33.848), train_loss = 0.86228728, grad/param norm = 1.9333e-01, time/batch = 15.0410s	
17636/26050 (epoch 33.850), train_loss = 0.78931854, grad/param norm = 1.9857e-01, time/batch = 14.7399s	
17637/26050 (epoch 33.852), train_loss = 0.90435495, grad/param norm = 2.2226e-01, time/batch = 14.8941s	
17638/26050 (epoch 33.854), train_loss = 0.87993118, grad/param norm = 2.2008e-01, time/batch = 14.6478s	
17639/26050 (epoch 33.856), train_loss = 0.83340285, grad/param norm = 2.3924e-01, time/batch = 14.7250s	
17640/26050 (epoch 33.858), train_loss = 0.79380579, grad/param norm = 1.9914e-01, time/batch = 14.8173s	
17641/26050 (epoch 33.860), train_loss = 0.93039483, grad/param norm = 2.3296e-01, time/batch = 15.1409s	
17642/26050 (epoch 33.862), train_loss = 0.96186985, grad/param norm = 1.9430e-01, time/batch = 14.9015s	
17643/26050 (epoch 33.864), train_loss = 0.89525918, grad/param norm = 2.5012e-01, time/batch = 14.8060s	
17644/26050 (epoch 33.866), train_loss = 0.83296876, grad/param norm = 1.8244e-01, time/batch = 14.8820s	
17645/26050 (epoch 33.868), train_loss = 0.94933242, grad/param norm = 2.7635e-01, time/batch = 15.0399s	
17646/26050 (epoch 33.869), train_loss = 0.78338543, grad/param norm = 1.7634e-01, time/batch = 14.7350s	
17647/26050 (epoch 33.871), train_loss = 0.75734065, grad/param norm = 2.0230e-01, time/batch = 15.0324s	
17648/26050 (epoch 33.873), train_loss = 0.92498552, grad/param norm = 2.2468e-01, time/batch = 14.6552s	
17649/26050 (epoch 33.875), train_loss = 0.83922566, grad/param norm = 2.2030e-01, time/batch = 14.9817s	
17650/26050 (epoch 33.877), train_loss = 0.81853243, grad/param norm = 1.9395e-01, time/batch = 15.1222s	
17651/26050 (epoch 33.879), train_loss = 0.90090978, grad/param norm = 1.8901e-01, time/batch = 15.2019s	
17652/26050 (epoch 33.881), train_loss = 0.96031248, grad/param norm = 2.3632e-01, time/batch = 14.7417s	
17653/26050 (epoch 33.883), train_loss = 0.91602298, grad/param norm = 2.1415e-01, time/batch = 14.5780s	
17654/26050 (epoch 33.885), train_loss = 0.67081855, grad/param norm = 1.8912e-01, time/batch = 14.7374s	
17655/26050 (epoch 33.887), train_loss = 0.95859522, grad/param norm = 2.5314e-01, time/batch = 14.8853s	
17656/26050 (epoch 33.889), train_loss = 0.81027347, grad/param norm = 1.9585e-01, time/batch = 14.7362s	
17657/26050 (epoch 33.891), train_loss = 0.72730114, grad/param norm = 2.0569e-01, time/batch = 15.3392s	
17658/26050 (epoch 33.893), train_loss = 0.74991663, grad/param norm = 2.1368e-01, time/batch = 15.2960s	
17659/26050 (epoch 33.894), train_loss = 0.83493085, grad/param norm = 2.1826e-01, time/batch = 15.1326s	
17660/26050 (epoch 33.896), train_loss = 0.95719064, grad/param norm = 2.4362e-01, time/batch = 15.9389s	
17661/26050 (epoch 33.898), train_loss = 0.82528981, grad/param norm = 2.0376e-01, time/batch = 15.2903s	
17662/26050 (epoch 33.900), train_loss = 0.91762998, grad/param norm = 2.7079e-01, time/batch = 14.5687s	
17663/26050 (epoch 33.902), train_loss = 0.85000239, grad/param norm = 2.3038e-01, time/batch = 14.8612s	
17664/26050 (epoch 33.904), train_loss = 0.84672678, grad/param norm = 2.0448e-01, time/batch = 14.8174s	
17665/26050 (epoch 33.906), train_loss = 0.85911658, grad/param norm = 2.7101e-01, time/batch = 14.6279s	
17666/26050 (epoch 33.908), train_loss = 0.88193484, grad/param norm = 2.0639e-01, time/batch = 14.2504s	
17667/26050 (epoch 33.910), train_loss = 0.83365948, grad/param norm = 1.8528e-01, time/batch = 14.2414s	
17668/26050 (epoch 33.912), train_loss = 1.05847829, grad/param norm = 2.3369e-01, time/batch = 14.1701s	
17669/26050 (epoch 33.914), train_loss = 1.18600068, grad/param norm = 2.3024e-01, time/batch = 14.3315s	
17670/26050 (epoch 33.916), train_loss = 0.98445903, grad/param norm = 2.7050e-01, time/batch = 14.3277s	
17671/26050 (epoch 33.917), train_loss = 0.90553956, grad/param norm = 2.4570e-01, time/batch = 14.3105s	
17672/26050 (epoch 33.919), train_loss = 0.91388018, grad/param norm = 3.7730e-01, time/batch = 16.4109s	
17673/26050 (epoch 33.921), train_loss = 0.84212893, grad/param norm = 2.2853e-01, time/batch = 17.5579s	
17674/26050 (epoch 33.923), train_loss = 0.89327708, grad/param norm = 2.0666e-01, time/batch = 16.3782s	
17675/26050 (epoch 33.925), train_loss = 0.87975044, grad/param norm = 2.0379e-01, time/batch = 14.7842s	
17676/26050 (epoch 33.927), train_loss = 0.79645233, grad/param norm = 1.6907e-01, time/batch = 15.0491s	
17677/26050 (epoch 33.929), train_loss = 0.75073869, grad/param norm = 1.9581e-01, time/batch = 15.8763s	
17678/26050 (epoch 33.931), train_loss = 1.07723450, grad/param norm = 3.3399e-01, time/batch = 15.6211s	
17679/26050 (epoch 33.933), train_loss = 0.87274229, grad/param norm = 2.2616e-01, time/batch = 15.2478s	
17680/26050 (epoch 33.935), train_loss = 0.85307802, grad/param norm = 2.0750e-01, time/batch = 15.3506s	
17681/26050 (epoch 33.937), train_loss = 0.94689925, grad/param norm = 2.1984e-01, time/batch = 14.3121s	
17682/26050 (epoch 33.939), train_loss = 0.79364929, grad/param norm = 1.7479e-01, time/batch = 14.3144s	
17683/26050 (epoch 33.940), train_loss = 0.84951014, grad/param norm = 2.0104e-01, time/batch = 14.5294s	
17684/26050 (epoch 33.942), train_loss = 0.86570497, grad/param norm = 2.0752e-01, time/batch = 13.9936s	
17685/26050 (epoch 33.944), train_loss = 0.84462108, grad/param norm = 1.9059e-01, time/batch = 13.8397s	
17686/26050 (epoch 33.946), train_loss = 0.99811995, grad/param norm = 2.3896e-01, time/batch = 13.9142s	
17687/26050 (epoch 33.948), train_loss = 0.74401471, grad/param norm = 1.9835e-01, time/batch = 14.0665s	
17688/26050 (epoch 33.950), train_loss = 0.86971018, grad/param norm = 1.8964e-01, time/batch = 13.8357s	
17689/26050 (epoch 33.952), train_loss = 0.94301172, grad/param norm = 2.1776e-01, time/batch = 13.9927s	
17690/26050 (epoch 33.954), train_loss = 0.93179305, grad/param norm = 2.1824e-01, time/batch = 13.9087s	
17691/26050 (epoch 33.956), train_loss = 0.84053599, grad/param norm = 2.0455e-01, time/batch = 14.2230s	
17692/26050 (epoch 33.958), train_loss = 0.78045616, grad/param norm = 1.9280e-01, time/batch = 14.2420s	
17693/26050 (epoch 33.960), train_loss = 0.91508138, grad/param norm = 2.1156e-01, time/batch = 14.4582s	
17694/26050 (epoch 33.962), train_loss = 0.86112904, grad/param norm = 1.8957e-01, time/batch = 14.3013s	
17695/26050 (epoch 33.964), train_loss = 0.87206872, grad/param norm = 2.1437e-01, time/batch = 14.2298s	
17696/26050 (epoch 33.965), train_loss = 0.80199841, grad/param norm = 2.0416e-01, time/batch = 14.4753s	
17697/26050 (epoch 33.967), train_loss = 1.15254214, grad/param norm = 2.1436e-01, time/batch = 14.3122s	
17698/26050 (epoch 33.969), train_loss = 0.86926596, grad/param norm = 1.8711e-01, time/batch = 13.9053s	
17699/26050 (epoch 33.971), train_loss = 0.87153993, grad/param norm = 2.3104e-01, time/batch = 14.2324s	
17700/26050 (epoch 33.973), train_loss = 0.88277950, grad/param norm = 1.9249e-01, time/batch = 14.4487s	
17701/26050 (epoch 33.975), train_loss = 0.89706147, grad/param norm = 2.0241e-01, time/batch = 14.1455s	
17702/26050 (epoch 33.977), train_loss = 0.87901778, grad/param norm = 1.8652e-01, time/batch = 14.7144s	
17703/26050 (epoch 33.979), train_loss = 0.72498738, grad/param norm = 1.9228e-01, time/batch = 13.9836s	
17704/26050 (epoch 33.981), train_loss = 0.99259797, grad/param norm = 1.9851e-01, time/batch = 13.9953s	
17705/26050 (epoch 33.983), train_loss = 0.93023362, grad/param norm = 2.1535e-01, time/batch = 14.2148s	
17706/26050 (epoch 33.985), train_loss = 0.92592890, grad/param norm = 2.0856e-01, time/batch = 13.9099s	
17707/26050 (epoch 33.987), train_loss = 0.98223586, grad/param norm = 2.0377e-01, time/batch = 13.9016s	
17708/26050 (epoch 33.988), train_loss = 0.90377731, grad/param norm = 2.1017e-01, time/batch = 14.0689s	
17709/26050 (epoch 33.990), train_loss = 0.77419336, grad/param norm = 1.8394e-01, time/batch = 14.2405s	
17710/26050 (epoch 33.992), train_loss = 1.01788866, grad/param norm = 2.0211e-01, time/batch = 14.0575s	
17711/26050 (epoch 33.994), train_loss = 0.83568709, grad/param norm = 2.3806e-01, time/batch = 14.5327s	
17712/26050 (epoch 33.996), train_loss = 0.78809031, grad/param norm = 2.5130e-01, time/batch = 14.4405s	
17713/26050 (epoch 33.998), train_loss = 0.89819524, grad/param norm = 2.1463e-01, time/batch = 13.9876s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
17714/26050 (epoch 34.000), train_loss = 0.82254119, grad/param norm = 2.2453e-01, time/batch = 14.2154s	
17715/26050 (epoch 34.002), train_loss = 0.92978709, grad/param norm = 2.1701e-01, time/batch = 14.3513s	
17716/26050 (epoch 34.004), train_loss = 0.77727548, grad/param norm = 1.9950e-01, time/batch = 13.9106s	
17717/26050 (epoch 34.006), train_loss = 0.81843541, grad/param norm = 2.4315e-01, time/batch = 13.9860s	
17718/26050 (epoch 34.008), train_loss = 0.79864191, grad/param norm = 2.0479e-01, time/batch = 13.9145s	
17719/26050 (epoch 34.010), train_loss = 0.81711358, grad/param norm = 2.2076e-01, time/batch = 14.1464s	
17720/26050 (epoch 34.012), train_loss = 0.86937458, grad/param norm = 2.1864e-01, time/batch = 13.9143s	
17721/26050 (epoch 34.013), train_loss = 1.11897148, grad/param norm = 2.6786e-01, time/batch = 13.9942s	
17722/26050 (epoch 34.015), train_loss = 0.87710189, grad/param norm = 2.1052e-01, time/batch = 14.2822s	
17723/26050 (epoch 34.017), train_loss = 0.92894823, grad/param norm = 2.0515e-01, time/batch = 14.2069s	
17724/26050 (epoch 34.019), train_loss = 0.76139641, grad/param norm = 1.5770e-01, time/batch = 13.9879s	
17725/26050 (epoch 34.021), train_loss = 0.97255828, grad/param norm = 2.1371e-01, time/batch = 14.6998s	
17726/26050 (epoch 34.023), train_loss = 0.73763403, grad/param norm = 2.2148e-01, time/batch = 13.8278s	
17727/26050 (epoch 34.025), train_loss = 0.85677698, grad/param norm = 2.0053e-01, time/batch = 13.9063s	
17728/26050 (epoch 34.027), train_loss = 0.71239445, grad/param norm = 2.2169e-01, time/batch = 13.7601s	
17729/26050 (epoch 34.029), train_loss = 0.89172823, grad/param norm = 1.8515e-01, time/batch = 13.9894s	
17730/26050 (epoch 34.031), train_loss = 0.97935582, grad/param norm = 2.2511e-01, time/batch = 13.9893s	
17731/26050 (epoch 34.033), train_loss = 0.87278641, grad/param norm = 1.9631e-01, time/batch = 14.1010s	
17732/26050 (epoch 34.035), train_loss = 0.90313492, grad/param norm = 1.9448e-01, time/batch = 13.8428s	
17733/26050 (epoch 34.036), train_loss = 0.77134040, grad/param norm = 2.1690e-01, time/batch = 13.9906s	
17734/26050 (epoch 34.038), train_loss = 0.70915587, grad/param norm = 1.8665e-01, time/batch = 13.8399s	
17735/26050 (epoch 34.040), train_loss = 0.84781049, grad/param norm = 1.9423e-01, time/batch = 14.0779s	
17736/26050 (epoch 34.042), train_loss = 0.72741305, grad/param norm = 1.7763e-01, time/batch = 14.0522s	
17737/26050 (epoch 34.044), train_loss = 0.94047939, grad/param norm = 1.9917e-01, time/batch = 14.1492s	
17738/26050 (epoch 34.046), train_loss = 0.73116677, grad/param norm = 1.8203e-01, time/batch = 14.0785s	
17739/26050 (epoch 34.048), train_loss = 0.85788742, grad/param norm = 1.9937e-01, time/batch = 14.0824s	
17740/26050 (epoch 34.050), train_loss = 0.81561275, grad/param norm = 1.9198e-01, time/batch = 13.7452s	
17741/26050 (epoch 34.052), train_loss = 0.79263301, grad/param norm = 2.6257e-01, time/batch = 13.8384s	
17742/26050 (epoch 34.054), train_loss = 0.72250396, grad/param norm = 1.9361e-01, time/batch = 14.7792s	
17743/26050 (epoch 34.056), train_loss = 0.69716725, grad/param norm = 1.6435e-01, time/batch = 14.3863s	
17744/26050 (epoch 34.058), train_loss = 0.84192719, grad/param norm = 1.9860e-01, time/batch = 13.9055s	
17745/26050 (epoch 34.060), train_loss = 0.90536783, grad/param norm = 1.9247e-01, time/batch = 14.6062s	
17746/26050 (epoch 34.061), train_loss = 0.77706025, grad/param norm = 2.0248e-01, time/batch = 14.9339s	
17747/26050 (epoch 34.063), train_loss = 0.85173383, grad/param norm = 1.8574e-01, time/batch = 15.4174s	
17748/26050 (epoch 34.065), train_loss = 0.70643574, grad/param norm = 1.6810e-01, time/batch = 14.5516s	
17749/26050 (epoch 34.067), train_loss = 0.85318578, grad/param norm = 1.9905e-01, time/batch = 14.3140s	
17750/26050 (epoch 34.069), train_loss = 0.89514671, grad/param norm = 2.0719e-01, time/batch = 14.5502s	
17751/26050 (epoch 34.071), train_loss = 0.91159866, grad/param norm = 2.3302e-01, time/batch = 14.3965s	
17752/26050 (epoch 34.073), train_loss = 1.01597808, grad/param norm = 2.1350e-01, time/batch = 14.7042s	
17753/26050 (epoch 34.075), train_loss = 0.81835893, grad/param norm = 1.9730e-01, time/batch = 14.3164s	
17754/26050 (epoch 34.077), train_loss = 0.83027473, grad/param norm = 2.4007e-01, time/batch = 14.4006s	
17755/26050 (epoch 34.079), train_loss = 0.85026297, grad/param norm = 2.1992e-01, time/batch = 14.4686s	
17756/26050 (epoch 34.081), train_loss = 0.82389411, grad/param norm = 1.8994e-01, time/batch = 14.3173s	
17757/26050 (epoch 34.083), train_loss = 0.94325704, grad/param norm = 2.0017e-01, time/batch = 14.5797s	
17758/26050 (epoch 34.084), train_loss = 0.87245190, grad/param norm = 2.4002e-01, time/batch = 14.4003s	
17759/26050 (epoch 34.086), train_loss = 1.02905772, grad/param norm = 2.7392e-01, time/batch = 14.3205s	
17760/26050 (epoch 34.088), train_loss = 0.84834392, grad/param norm = 2.1569e-01, time/batch = 14.2431s	
17761/26050 (epoch 34.090), train_loss = 0.90956755, grad/param norm = 2.1632e-01, time/batch = 14.3282s	
17762/26050 (epoch 34.092), train_loss = 0.92550284, grad/param norm = 2.1067e-01, time/batch = 14.4041s	
17763/26050 (epoch 34.094), train_loss = 0.74639300, grad/param norm = 1.7795e-01, time/batch = 14.4035s	
17764/26050 (epoch 34.096), train_loss = 0.89115143, grad/param norm = 1.9840e-01, time/batch = 14.6081s	
17765/26050 (epoch 34.098), train_loss = 0.84922839, grad/param norm = 1.7900e-01, time/batch = 14.4908s	
17766/26050 (epoch 34.100), train_loss = 0.78910128, grad/param norm = 2.1623e-01, time/batch = 15.2707s	
17767/26050 (epoch 34.102), train_loss = 0.90341515, grad/param norm = 2.7208e-01, time/batch = 14.5549s	
17768/26050 (epoch 34.104), train_loss = 0.82674104, grad/param norm = 2.1888e-01, time/batch = 14.3926s	
17769/26050 (epoch 34.106), train_loss = 0.91808209, grad/param norm = 2.7126e-01, time/batch = 14.2305s	
17770/26050 (epoch 34.107), train_loss = 0.72385963, grad/param norm = 1.8303e-01, time/batch = 14.2351s	
17771/26050 (epoch 34.109), train_loss = 0.80630657, grad/param norm = 1.9719e-01, time/batch = 14.3883s	
17772/26050 (epoch 34.111), train_loss = 0.99009631, grad/param norm = 2.4070e-01, time/batch = 14.7999s	
17773/26050 (epoch 34.113), train_loss = 0.82934895, grad/param norm = 2.0137e-01, time/batch = 14.5357s	
17774/26050 (epoch 34.115), train_loss = 0.96688583, grad/param norm = 2.1490e-01, time/batch = 14.2867s	
17775/26050 (epoch 34.117), train_loss = 0.85534571, grad/param norm = 1.8267e-01, time/batch = 14.3992s	
17776/26050 (epoch 34.119), train_loss = 0.74788792, grad/param norm = 1.9309e-01, time/batch = 14.4623s	
17777/26050 (epoch 34.121), train_loss = 0.87791236, grad/param norm = 1.9528e-01, time/batch = 14.4688s	
17778/26050 (epoch 34.123), train_loss = 0.78451747, grad/param norm = 1.8794e-01, time/batch = 14.3268s	
17779/26050 (epoch 34.125), train_loss = 0.73207143, grad/param norm = 1.9201e-01, time/batch = 14.4648s	
17780/26050 (epoch 34.127), train_loss = 0.72192105, grad/param norm = 1.9350e-01, time/batch = 14.4004s	
17781/26050 (epoch 34.129), train_loss = 0.68576461, grad/param norm = 1.9643e-01, time/batch = 14.2356s	
17782/26050 (epoch 34.131), train_loss = 0.83682062, grad/param norm = 2.0304e-01, time/batch = 14.2308s	
17783/26050 (epoch 34.132), train_loss = 0.85712633, grad/param norm = 1.9894e-01, time/batch = 14.7829s	
17784/26050 (epoch 34.134), train_loss = 0.90319985, grad/param norm = 2.3339e-01, time/batch = 14.4716s	
17785/26050 (epoch 34.136), train_loss = 0.83972060, grad/param norm = 1.8906e-01, time/batch = 14.3875s	
17786/26050 (epoch 34.138), train_loss = 0.61702741, grad/param norm = 1.8065e-01, time/batch = 14.6462s	
17787/26050 (epoch 34.140), train_loss = 0.71922274, grad/param norm = 1.9472e-01, time/batch = 14.7109s	
17788/26050 (epoch 34.142), train_loss = 0.76286068, grad/param norm = 2.0279e-01, time/batch = 14.4023s	
17789/26050 (epoch 34.144), train_loss = 0.69105424, grad/param norm = 2.1109e-01, time/batch = 14.3249s	
17790/26050 (epoch 34.146), train_loss = 0.65046029, grad/param norm = 1.7806e-01, time/batch = 14.3234s	
17791/26050 (epoch 34.148), train_loss = 0.68160297, grad/param norm = 1.6989e-01, time/batch = 14.3978s	
17792/26050 (epoch 34.150), train_loss = 0.79388167, grad/param norm = 2.0764e-01, time/batch = 14.5629s	
17793/26050 (epoch 34.152), train_loss = 0.99444838, grad/param norm = 3.1367e-01, time/batch = 14.3239s	
17794/26050 (epoch 34.154), train_loss = 0.67918875, grad/param norm = 1.8249e-01, time/batch = 14.3811s	
17795/26050 (epoch 34.155), train_loss = 0.74734221, grad/param norm = 2.0413e-01, time/batch = 14.6024s	
17796/26050 (epoch 34.157), train_loss = 0.81383487, grad/param norm = 2.1965e-01, time/batch = 14.2173s	
17797/26050 (epoch 34.159), train_loss = 0.90416577, grad/param norm = 2.4735e-01, time/batch = 14.0406s	
17798/26050 (epoch 34.161), train_loss = 0.86927708, grad/param norm = 2.3528e-01, time/batch = 14.2325s	
17799/26050 (epoch 34.163), train_loss = 0.71455426, grad/param norm = 2.1137e-01, time/batch = 14.2745s	
17800/26050 (epoch 34.165), train_loss = 0.64596123, grad/param norm = 1.8718e-01, time/batch = 14.2417s	
17801/26050 (epoch 34.167), train_loss = 0.99607044, grad/param norm = 2.5694e-01, time/batch = 14.2431s	
17802/26050 (epoch 34.169), train_loss = 0.85311379, grad/param norm = 2.3751e-01, time/batch = 14.2476s	
17803/26050 (epoch 34.171), train_loss = 0.73654704, grad/param norm = 1.6751e-01, time/batch = 14.3282s	
17804/26050 (epoch 34.173), train_loss = 0.80968571, grad/param norm = 1.9885e-01, time/batch = 20.7354s	
17805/26050 (epoch 34.175), train_loss = 0.82964572, grad/param norm = 1.9611e-01, time/batch = 26.0536s	
17806/26050 (epoch 34.177), train_loss = 0.90557654, grad/param norm = 2.0160e-01, time/batch = 16.4161s	
17807/26050 (epoch 34.179), train_loss = 0.63844347, grad/param norm = 1.8168e-01, time/batch = 14.3368s	
17808/26050 (epoch 34.180), train_loss = 1.07015470, grad/param norm = 2.2690e-01, time/batch = 13.9009s	
17809/26050 (epoch 34.182), train_loss = 1.01972667, grad/param norm = 2.1725e-01, time/batch = 13.9085s	
17810/26050 (epoch 34.184), train_loss = 0.87028029, grad/param norm = 1.9199e-01, time/batch = 13.7579s	
17811/26050 (epoch 34.186), train_loss = 0.71650339, grad/param norm = 1.9380e-01, time/batch = 13.9074s	
17812/26050 (epoch 34.188), train_loss = 0.87417188, grad/param norm = 2.1075e-01, time/batch = 13.8407s	
17813/26050 (epoch 34.190), train_loss = 0.87928468, grad/param norm = 2.1048e-01, time/batch = 14.3196s	
17814/26050 (epoch 34.192), train_loss = 0.93884070, grad/param norm = 1.9643e-01, time/batch = 14.3014s	
17815/26050 (epoch 34.194), train_loss = 0.89316912, grad/param norm = 1.9880e-01, time/batch = 14.2176s	
17816/26050 (epoch 34.196), train_loss = 0.91043483, grad/param norm = 2.0611e-01, time/batch = 13.9997s	
17817/26050 (epoch 34.198), train_loss = 0.76665914, grad/param norm = 1.7932e-01, time/batch = 13.8259s	
17818/26050 (epoch 34.200), train_loss = 0.75550470, grad/param norm = 2.1030e-01, time/batch = 14.0509s	
17819/26050 (epoch 34.202), train_loss = 0.86014531, grad/param norm = 1.8466e-01, time/batch = 13.9832s	
17820/26050 (epoch 34.203), train_loss = 0.95128304, grad/param norm = 1.9856e-01, time/batch = 13.9054s	
17821/26050 (epoch 34.205), train_loss = 0.80515820, grad/param norm = 2.0982e-01, time/batch = 14.0693s	
17822/26050 (epoch 34.207), train_loss = 0.75758948, grad/param norm = 1.8941e-01, time/batch = 13.8303s	
17823/26050 (epoch 34.209), train_loss = 0.92222025, grad/param norm = 2.4273e-01, time/batch = 14.3113s	
17824/26050 (epoch 34.211), train_loss = 0.74035806, grad/param norm = 2.1076e-01, time/batch = 14.0618s	
17825/26050 (epoch 34.213), train_loss = 0.88640826, grad/param norm = 2.2871e-01, time/batch = 14.0583s	
17826/26050 (epoch 34.215), train_loss = 0.82530611, grad/param norm = 2.0132e-01, time/batch = 14.0671s	
17827/26050 (epoch 34.217), train_loss = 0.80419672, grad/param norm = 1.9233e-01, time/batch = 13.8264s	
17828/26050 (epoch 34.219), train_loss = 0.83187609, grad/param norm = 2.1833e-01, time/batch = 13.8193s	
17829/26050 (epoch 34.221), train_loss = 0.76475164, grad/param norm = 2.2436e-01, time/batch = 13.7554s	
17830/26050 (epoch 34.223), train_loss = 0.93939639, grad/param norm = 2.1985e-01, time/batch = 13.9794s	
17831/26050 (epoch 34.225), train_loss = 0.77202202, grad/param norm = 2.0088e-01, time/batch = 13.9183s	
17832/26050 (epoch 34.226), train_loss = 0.87884346, grad/param norm = 2.3390e-01, time/batch = 14.0718s	
17833/26050 (epoch 34.228), train_loss = 0.98935264, grad/param norm = 2.0716e-01, time/batch = 13.9079s	
17834/26050 (epoch 34.230), train_loss = 0.85353611, grad/param norm = 1.8588e-01, time/batch = 14.0659s	
17835/26050 (epoch 34.232), train_loss = 0.92675062, grad/param norm = 2.2933e-01, time/batch = 14.3676s	
17836/26050 (epoch 34.234), train_loss = 0.74572156, grad/param norm = 1.9203e-01, time/batch = 13.9018s	
17837/26050 (epoch 34.236), train_loss = 0.92886231, grad/param norm = 2.0160e-01, time/batch = 13.9787s	
17838/26050 (epoch 34.238), train_loss = 0.73568352, grad/param norm = 1.8780e-01, time/batch = 14.0459s	
17839/26050 (epoch 34.240), train_loss = 0.86619270, grad/param norm = 2.0144e-01, time/batch = 13.9810s	
17840/26050 (epoch 34.242), train_loss = 0.83070095, grad/param norm = 2.1232e-01, time/batch = 13.9812s	
17841/26050 (epoch 34.244), train_loss = 0.88628994, grad/param norm = 2.5229e-01, time/batch = 13.9844s	
17842/26050 (epoch 34.246), train_loss = 0.82136587, grad/param norm = 2.0492e-01, time/batch = 14.0046s	
17843/26050 (epoch 34.248), train_loss = 0.85261464, grad/param norm = 1.9385e-01, time/batch = 13.6758s	
17844/26050 (epoch 34.250), train_loss = 0.88683188, grad/param norm = 2.6544e-01, time/batch = 13.7557s	
17845/26050 (epoch 34.251), train_loss = 0.79989725, grad/param norm = 2.0469e-01, time/batch = 14.5423s	
17846/26050 (epoch 34.253), train_loss = 0.76047849, grad/param norm = 2.1070e-01, time/batch = 14.5226s	
17847/26050 (epoch 34.255), train_loss = 1.03037193, grad/param norm = 2.3323e-01, time/batch = 14.1576s	
17848/26050 (epoch 34.257), train_loss = 0.85037622, grad/param norm = 2.2541e-01, time/batch = 14.0792s	
17849/26050 (epoch 34.259), train_loss = 0.94943223, grad/param norm = 2.1850e-01, time/batch = 14.0642s	
17850/26050 (epoch 34.261), train_loss = 0.77254324, grad/param norm = 2.2347e-01, time/batch = 13.9912s	
17851/26050 (epoch 34.263), train_loss = 0.95781860, grad/param norm = 2.3942e-01, time/batch = 13.9770s	
17852/26050 (epoch 34.265), train_loss = 0.98301813, grad/param norm = 2.3575e-01, time/batch = 13.9166s	
17853/26050 (epoch 34.267), train_loss = 0.99088932, grad/param norm = 2.0651e-01, time/batch = 13.9099s	
17854/26050 (epoch 34.269), train_loss = 0.99110820, grad/param norm = 2.8110e-01, time/batch = 13.9923s	
17855/26050 (epoch 34.271), train_loss = 0.87500603, grad/param norm = 2.0569e-01, time/batch = 13.8289s	
17856/26050 (epoch 34.273), train_loss = 0.78501086, grad/param norm = 2.1775e-01, time/batch = 13.8973s	
17857/26050 (epoch 34.274), train_loss = 0.81708971, grad/param norm = 1.8638e-01, time/batch = 13.9742s	
17858/26050 (epoch 34.276), train_loss = 0.81860041, grad/param norm = 2.0447e-01, time/batch = 14.0675s	
17859/26050 (epoch 34.278), train_loss = 0.93214669, grad/param norm = 1.9914e-01, time/batch = 14.1391s	
17860/26050 (epoch 34.280), train_loss = 0.86465287, grad/param norm = 1.8870e-01, time/batch = 14.0658s	
17861/26050 (epoch 34.282), train_loss = 0.92084757, grad/param norm = 1.9375e-01, time/batch = 13.9834s	
17862/26050 (epoch 34.284), train_loss = 0.85344242, grad/param norm = 2.1650e-01, time/batch = 14.0541s	
17863/26050 (epoch 34.286), train_loss = 0.90158979, grad/param norm = 2.3189e-01, time/batch = 15.8117s	
17864/26050 (epoch 34.288), train_loss = 0.74648094, grad/param norm = 1.9206e-01, time/batch = 15.5710s	
17865/26050 (epoch 34.290), train_loss = 0.87057011, grad/param norm = 2.0017e-01, time/batch = 15.5326s	
17866/26050 (epoch 34.292), train_loss = 0.77170003, grad/param norm = 1.8995e-01, time/batch = 15.3964s	
17867/26050 (epoch 34.294), train_loss = 0.87036238, grad/param norm = 2.1823e-01, time/batch = 14.2938s	
17868/26050 (epoch 34.296), train_loss = 0.94469649, grad/param norm = 2.0295e-01, time/batch = 15.5848s	
17869/26050 (epoch 34.298), train_loss = 0.88912875, grad/param norm = 2.2248e-01, time/batch = 16.1573s	
17870/26050 (epoch 34.299), train_loss = 0.71900260, grad/param norm = 1.9588e-01, time/batch = 15.0005s	
17871/26050 (epoch 34.301), train_loss = 0.72896477, grad/param norm = 1.8691e-01, time/batch = 14.6641s	
17872/26050 (epoch 34.303), train_loss = 0.86374573, grad/param norm = 2.2896e-01, time/batch = 15.8118s	
17873/26050 (epoch 34.305), train_loss = 0.69737853, grad/param norm = 1.9158e-01, time/batch = 13.9784s	
17874/26050 (epoch 34.307), train_loss = 0.78354465, grad/param norm = 2.2401e-01, time/batch = 15.6523s	
17875/26050 (epoch 34.309), train_loss = 0.86242259, grad/param norm = 2.0449e-01, time/batch = 14.5756s	
17876/26050 (epoch 34.311), train_loss = 0.88217622, grad/param norm = 2.3092e-01, time/batch = 15.8271s	
17877/26050 (epoch 34.313), train_loss = 0.88309915, grad/param norm = 3.0303e-01, time/batch = 15.4172s	
17878/26050 (epoch 34.315), train_loss = 0.92450204, grad/param norm = 1.9663e-01, time/batch = 15.4880s	
17879/26050 (epoch 34.317), train_loss = 0.87088031, grad/param norm = 2.1993e-01, time/batch = 13.8321s	
17880/26050 (epoch 34.319), train_loss = 0.78733735, grad/param norm = 2.1973e-01, time/batch = 13.9838s	
17881/26050 (epoch 34.321), train_loss = 0.83985968, grad/param norm = 1.9399e-01, time/batch = 13.7557s	
17882/26050 (epoch 34.322), train_loss = 0.92845100, grad/param norm = 2.1181e-01, time/batch = 14.0527s	
17883/26050 (epoch 34.324), train_loss = 0.67756265, grad/param norm = 1.8449e-01, time/batch = 13.9174s	
17884/26050 (epoch 34.326), train_loss = 0.97244440, grad/param norm = 2.1582e-01, time/batch = 14.4638s	
17885/26050 (epoch 34.328), train_loss = 0.87870885, grad/param norm = 1.8127e-01, time/batch = 13.6545s	
17886/26050 (epoch 34.330), train_loss = 0.74387324, grad/param norm = 1.9881e-01, time/batch = 14.2889s	
17887/26050 (epoch 34.332), train_loss = 0.91803764, grad/param norm = 2.2509e-01, time/batch = 14.3659s	
17888/26050 (epoch 34.334), train_loss = 0.78100489, grad/param norm = 2.0278e-01, time/batch = 14.2951s	
17889/26050 (epoch 34.336), train_loss = 0.80835273, grad/param norm = 2.2503e-01, time/batch = 13.9053s	
17890/26050 (epoch 34.338), train_loss = 0.74412228, grad/param norm = 1.9673e-01, time/batch = 13.9181s	
17891/26050 (epoch 34.340), train_loss = 0.90416509, grad/param norm = 2.0213e-01, time/batch = 13.9111s	
17892/26050 (epoch 34.342), train_loss = 0.95383050, grad/param norm = 2.0680e-01, time/batch = 13.9849s	
17893/26050 (epoch 34.344), train_loss = 0.77232564, grad/param norm = 1.8955e-01, time/batch = 13.9132s	
17894/26050 (epoch 34.345), train_loss = 0.82585122, grad/param norm = 2.0182e-01, time/batch = 14.0667s	
17895/26050 (epoch 34.347), train_loss = 0.96975850, grad/param norm = 2.1604e-01, time/batch = 13.9854s	
17896/26050 (epoch 34.349), train_loss = 0.89249580, grad/param norm = 2.0603e-01, time/batch = 13.8304s	
17897/26050 (epoch 34.351), train_loss = 0.86503676, grad/param norm = 2.0963e-01, time/batch = 13.9095s	
17898/26050 (epoch 34.353), train_loss = 0.86809292, grad/param norm = 2.0853e-01, time/batch = 13.8388s	
17899/26050 (epoch 34.355), train_loss = 0.84851429, grad/param norm = 2.1051e-01, time/batch = 14.0617s	
17900/26050 (epoch 34.357), train_loss = 0.82505346, grad/param norm = 1.9589e-01, time/batch = 17.7271s	
17901/26050 (epoch 34.359), train_loss = 0.93667768, grad/param norm = 2.0737e-01, time/batch = 14.8984s	
17902/26050 (epoch 34.361), train_loss = 0.77726552, grad/param norm = 1.7742e-01, time/batch = 15.7305s	
17903/26050 (epoch 34.363), train_loss = 0.92786277, grad/param norm = 2.0501e-01, time/batch = 17.4513s	
17904/26050 (epoch 34.365), train_loss = 0.83584992, grad/param norm = 1.9168e-01, time/batch = 15.4702s	
17905/26050 (epoch 34.367), train_loss = 0.91737923, grad/param norm = 1.9330e-01, time/batch = 14.3742s	
17906/26050 (epoch 34.369), train_loss = 0.76659113, grad/param norm = 1.6958e-01, time/batch = 16.2372s	
17907/26050 (epoch 34.370), train_loss = 0.76075019, grad/param norm = 1.7773e-01, time/batch = 16.0514s	
17908/26050 (epoch 34.372), train_loss = 0.85579110, grad/param norm = 2.0548e-01, time/batch = 15.4954s	
17909/26050 (epoch 34.374), train_loss = 0.98362753, grad/param norm = 2.0497e-01, time/batch = 14.9205s	
17910/26050 (epoch 34.376), train_loss = 0.98302981, grad/param norm = 2.2128e-01, time/batch = 15.8295s	
17911/26050 (epoch 34.378), train_loss = 0.81778245, grad/param norm = 1.8813e-01, time/batch = 14.8162s	
17912/26050 (epoch 34.380), train_loss = 0.97211847, grad/param norm = 2.2059e-01, time/batch = 15.8832s	
17913/26050 (epoch 34.382), train_loss = 1.08202768, grad/param norm = 2.5571e-01, time/batch = 14.4937s	
17914/26050 (epoch 34.384), train_loss = 0.81930053, grad/param norm = 2.1740e-01, time/batch = 14.9282s	
17915/26050 (epoch 34.386), train_loss = 0.92259740, grad/param norm = 2.4651e-01, time/batch = 15.4028s	
17916/26050 (epoch 34.388), train_loss = 0.90074160, grad/param norm = 2.3087e-01, time/batch = 16.3929s	
17917/26050 (epoch 34.390), train_loss = 0.81509906, grad/param norm = 1.7344e-01, time/batch = 14.3403s	
17918/26050 (epoch 34.392), train_loss = 0.75998757, grad/param norm = 2.0609e-01, time/batch = 15.8900s	
17919/26050 (epoch 34.393), train_loss = 0.87634406, grad/param norm = 1.9705e-01, time/batch = 14.6640s	
17920/26050 (epoch 34.395), train_loss = 0.91618870, grad/param norm = 2.0473e-01, time/batch = 15.9964s	
17921/26050 (epoch 34.397), train_loss = 0.91085891, grad/param norm = 2.1263e-01, time/batch = 14.3049s	
17922/26050 (epoch 34.399), train_loss = 0.80967798, grad/param norm = 1.8984e-01, time/batch = 14.7629s	
17923/26050 (epoch 34.401), train_loss = 0.87623899, grad/param norm = 2.0515e-01, time/batch = 15.9149s	
17924/26050 (epoch 34.403), train_loss = 0.88574715, grad/param norm = 2.2400e-01, time/batch = 16.0574s	
17925/26050 (epoch 34.405), train_loss = 0.88902670, grad/param norm = 2.1105e-01, time/batch = 16.1642s	
17926/26050 (epoch 34.407), train_loss = 0.98457607, grad/param norm = 2.2664e-01, time/batch = 14.7298s	
17927/26050 (epoch 34.409), train_loss = 0.99373955, grad/param norm = 2.5447e-01, time/batch = 14.8416s	
17928/26050 (epoch 34.411), train_loss = 0.94462429, grad/param norm = 2.0788e-01, time/batch = 14.8852s	
17929/26050 (epoch 34.413), train_loss = 1.02866977, grad/param norm = 2.0607e-01, time/batch = 15.7282s	
17930/26050 (epoch 34.415), train_loss = 1.02425334, grad/param norm = 2.1918e-01, time/batch = 15.9758s	
17931/26050 (epoch 34.417), train_loss = 1.05601783, grad/param norm = 2.7602e-01, time/batch = 14.5699s	
17932/26050 (epoch 34.418), train_loss = 0.96006287, grad/param norm = 2.9449e-01, time/batch = 16.1599s	
17933/26050 (epoch 34.420), train_loss = 0.75781810, grad/param norm = 1.9310e-01, time/batch = 15.0567s	
17934/26050 (epoch 34.422), train_loss = 0.74411196, grad/param norm = 2.1180e-01, time/batch = 14.3351s	
17935/26050 (epoch 34.424), train_loss = 0.96374567, grad/param norm = 2.3230e-01, time/batch = 15.5755s	
17936/26050 (epoch 34.426), train_loss = 0.92933056, grad/param norm = 2.2862e-01, time/batch = 16.0037s	
17937/26050 (epoch 34.428), train_loss = 0.83122824, grad/param norm = 2.0020e-01, time/batch = 15.3268s	
17938/26050 (epoch 34.430), train_loss = 1.02700889, grad/param norm = 2.0234e-01, time/batch = 15.8953s	
17939/26050 (epoch 34.432), train_loss = 0.85531511, grad/param norm = 2.0119e-01, time/batch = 15.1749s	
17940/26050 (epoch 34.434), train_loss = 0.82811488, grad/param norm = 2.1147e-01, time/batch = 16.5901s	
17941/26050 (epoch 34.436), train_loss = 0.96410988, grad/param norm = 2.1065e-01, time/batch = 15.5655s	
17942/26050 (epoch 34.438), train_loss = 0.91269898, grad/param norm = 2.2720e-01, time/batch = 14.5182s	
17943/26050 (epoch 34.440), train_loss = 0.87965350, grad/param norm = 1.9102e-01, time/batch = 16.1622s	
17944/26050 (epoch 34.441), train_loss = 0.89839332, grad/param norm = 1.8947e-01, time/batch = 14.9985s	
17945/26050 (epoch 34.443), train_loss = 0.74909108, grad/param norm = 1.6822e-01, time/batch = 16.2259s	
17946/26050 (epoch 34.445), train_loss = 0.78764251, grad/param norm = 1.8886e-01, time/batch = 15.4120s	
17947/26050 (epoch 34.447), train_loss = 0.98583504, grad/param norm = 2.2004e-01, time/batch = 15.2460s	
17948/26050 (epoch 34.449), train_loss = 0.77732553, grad/param norm = 1.8476e-01, time/batch = 15.1382s	
17949/26050 (epoch 34.451), train_loss = 0.99784244, grad/param norm = 2.0190e-01, time/batch = 15.1462s	
17950/26050 (epoch 34.453), train_loss = 0.81042065, grad/param norm = 1.8123e-01, time/batch = 16.1487s	
17951/26050 (epoch 34.455), train_loss = 0.87543226, grad/param norm = 1.9331e-01, time/batch = 15.8267s	
17952/26050 (epoch 34.457), train_loss = 0.86071876, grad/param norm = 2.0981e-01, time/batch = 15.0086s	
17953/26050 (epoch 34.459), train_loss = 0.98090881, grad/param norm = 2.4916e-01, time/batch = 14.7958s	
17954/26050 (epoch 34.461), train_loss = 0.98295735, grad/param norm = 2.1622e-01, time/batch = 14.2858s	
17955/26050 (epoch 34.463), train_loss = 0.82851842, grad/param norm = 1.7226e-01, time/batch = 14.8257s	
17956/26050 (epoch 34.464), train_loss = 0.91154769, grad/param norm = 2.0894e-01, time/batch = 14.6669s	
17957/26050 (epoch 34.466), train_loss = 0.88122638, grad/param norm = 1.9662e-01, time/batch = 14.9949s	
17958/26050 (epoch 34.468), train_loss = 0.98246862, grad/param norm = 1.8404e-01, time/batch = 15.4136s	
17959/26050 (epoch 34.470), train_loss = 0.97297907, grad/param norm = 2.4651e-01, time/batch = 15.6578s	
17960/26050 (epoch 34.472), train_loss = 0.98182128, grad/param norm = 2.2417e-01, time/batch = 15.6599s	
17961/26050 (epoch 34.474), train_loss = 0.99115654, grad/param norm = 2.1188e-01, time/batch = 14.5675s	
17962/26050 (epoch 34.476), train_loss = 0.95497227, grad/param norm = 2.0132e-01, time/batch = 15.6677s	
17963/26050 (epoch 34.478), train_loss = 0.84147308, grad/param norm = 1.8977e-01, time/batch = 15.4903s	
17964/26050 (epoch 34.480), train_loss = 0.84919898, grad/param norm = 1.8906e-01, time/batch = 14.8932s	
17965/26050 (epoch 34.482), train_loss = 0.83030435, grad/param norm = 1.8098e-01, time/batch = 14.5754s	
17966/26050 (epoch 34.484), train_loss = 0.82538106, grad/param norm = 2.1002e-01, time/batch = 15.5753s	
17967/26050 (epoch 34.486), train_loss = 0.99609816, grad/param norm = 1.9793e-01, time/batch = 16.5441s	
17968/26050 (epoch 34.488), train_loss = 1.03730417, grad/param norm = 2.6919e-01, time/batch = 15.0482s	
17969/26050 (epoch 34.489), train_loss = 1.05706442, grad/param norm = 2.8580e-01, time/batch = 14.1533s	
17970/26050 (epoch 34.491), train_loss = 0.80631662, grad/param norm = 2.1007e-01, time/batch = 16.0462s	
17971/26050 (epoch 34.493), train_loss = 0.90789705, grad/param norm = 2.1812e-01, time/batch = 16.1398s	
17972/26050 (epoch 34.495), train_loss = 0.86731432, grad/param norm = 1.9146e-01, time/batch = 14.4266s	
17973/26050 (epoch 34.497), train_loss = 0.78742925, grad/param norm = 1.9295e-01, time/batch = 16.3325s	
17974/26050 (epoch 34.499), train_loss = 0.82606690, grad/param norm = 2.2278e-01, time/batch = 16.4777s	
17975/26050 (epoch 34.501), train_loss = 0.97468915, grad/param norm = 2.0440e-01, time/batch = 16.2448s	
17976/26050 (epoch 34.503), train_loss = 0.84095090, grad/param norm = 2.1075e-01, time/batch = 14.4032s	
17977/26050 (epoch 34.505), train_loss = 0.97482960, grad/param norm = 2.1233e-01, time/batch = 16.2371s	
17978/26050 (epoch 34.507), train_loss = 0.94075833, grad/param norm = 2.2228e-01, time/batch = 14.6333s	
17979/26050 (epoch 34.509), train_loss = 1.02890655, grad/param norm = 2.1620e-01, time/batch = 15.5826s	
17980/26050 (epoch 34.511), train_loss = 0.84729999, grad/param norm = 1.7112e-01, time/batch = 14.1748s	
17981/26050 (epoch 34.512), train_loss = 0.77572259, grad/param norm = 2.1893e-01, time/batch = 16.1576s	
17982/26050 (epoch 34.514), train_loss = 0.92563247, grad/param norm = 2.4963e-01, time/batch = 14.8338s	
17983/26050 (epoch 34.516), train_loss = 1.00793436, grad/param norm = 2.2942e-01, time/batch = 15.9059s	
17984/26050 (epoch 34.518), train_loss = 0.84908911, grad/param norm = 2.0362e-01, time/batch = 14.6610s	
17985/26050 (epoch 34.520), train_loss = 0.89036572, grad/param norm = 1.9797e-01, time/batch = 14.7912s	
17986/26050 (epoch 34.522), train_loss = 0.70676417, grad/param norm = 1.8871e-01, time/batch = 16.4883s	
17987/26050 (epoch 34.524), train_loss = 0.97821999, grad/param norm = 2.5289e-01, time/batch = 14.3838s	
17988/26050 (epoch 34.526), train_loss = 0.97119605, grad/param norm = 2.2876e-01, time/batch = 15.1460s	
17989/26050 (epoch 34.528), train_loss = 0.89812856, grad/param norm = 2.2463e-01, time/batch = 14.7127s	
17990/26050 (epoch 34.530), train_loss = 0.83978133, grad/param norm = 2.2192e-01, time/batch = 16.1675s	
17991/26050 (epoch 34.532), train_loss = 0.89794940, grad/param norm = 1.9362e-01, time/batch = 16.1633s	
17992/26050 (epoch 34.534), train_loss = 0.89740848, grad/param norm = 2.4616e-01, time/batch = 16.2372s	
17993/26050 (epoch 34.536), train_loss = 0.90687966, grad/param norm = 2.1200e-01, time/batch = 14.7590s	
17994/26050 (epoch 34.537), train_loss = 0.94305391, grad/param norm = 2.0420e-01, time/batch = 15.0476s	
17995/26050 (epoch 34.539), train_loss = 0.89323847, grad/param norm = 2.1706e-01, time/batch = 14.9151s	
17996/26050 (epoch 34.541), train_loss = 1.02482551, grad/param norm = 2.3005e-01, time/batch = 16.0670s	
17997/26050 (epoch 34.543), train_loss = 0.71487751, grad/param norm = 2.4996e-01, time/batch = 14.7600s	
17998/26050 (epoch 34.545), train_loss = 0.87396133, grad/param norm = 1.9461e-01, time/batch = 15.9953s	
17999/26050 (epoch 34.547), train_loss = 0.86069828, grad/param norm = 2.1114e-01, time/batch = 16.4961s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch34.55_1.8672.t7	
18000/26050 (epoch 34.549), train_loss = 0.75768852, grad/param norm = 2.1613e-01, time/batch = 16.7333s	
18001/26050 (epoch 34.551), train_loss = 1.52226594, grad/param norm = 2.8898e-01, time/batch = 15.7403s	
18002/26050 (epoch 34.553), train_loss = 0.86090815, grad/param norm = 2.0919e-01, time/batch = 15.0010s	
18003/26050 (epoch 34.555), train_loss = 0.78913073, grad/param norm = 2.2125e-01, time/batch = 14.4758s	
18004/26050 (epoch 34.557), train_loss = 0.89393830, grad/param norm = 1.9460e-01, time/batch = 15.7361s	
18005/26050 (epoch 34.559), train_loss = 0.88640671, grad/param norm = 1.8922e-01, time/batch = 15.3124s	
18006/26050 (epoch 34.560), train_loss = 0.85371937, grad/param norm = 2.1512e-01, time/batch = 15.4828s	
18007/26050 (epoch 34.562), train_loss = 0.87422163, grad/param norm = 2.1734e-01, time/batch = 14.9215s	
18008/26050 (epoch 34.564), train_loss = 1.04102095, grad/param norm = 2.1630e-01, time/batch = 15.2965s	
18009/26050 (epoch 34.566), train_loss = 0.82108147, grad/param norm = 1.9396e-01, time/batch = 15.2822s	
18010/26050 (epoch 34.568), train_loss = 0.91705272, grad/param norm = 2.0251e-01, time/batch = 15.8834s	
18011/26050 (epoch 34.570), train_loss = 0.87832713, grad/param norm = 2.2269e-01, time/batch = 15.2702s	
18012/26050 (epoch 34.572), train_loss = 0.88958312, grad/param norm = 2.4267e-01, time/batch = 14.3382s	
18013/26050 (epoch 34.574), train_loss = 0.90323878, grad/param norm = 2.4210e-01, time/batch = 16.0000s	
18014/26050 (epoch 34.576), train_loss = 0.92858938, grad/param norm = 2.6305e-01, time/batch = 15.3984s	
18015/26050 (epoch 34.578), train_loss = 0.87063016, grad/param norm = 2.3823e-01, time/batch = 16.3246s	
18016/26050 (epoch 34.580), train_loss = 0.81722126, grad/param norm = 2.4641e-01, time/batch = 15.5716s	
18017/26050 (epoch 34.582), train_loss = 0.90581016, grad/param norm = 2.1448e-01, time/batch = 16.1559s	
18018/26050 (epoch 34.583), train_loss = 0.95927939, grad/param norm = 2.0739e-01, time/batch = 15.6755s	
18019/26050 (epoch 34.585), train_loss = 0.79651745, grad/param norm = 1.9109e-01, time/batch = 15.9047s	
18020/26050 (epoch 34.587), train_loss = 0.93526652, grad/param norm = 2.3438e-01, time/batch = 16.8137s	
18021/26050 (epoch 34.589), train_loss = 1.00866149, grad/param norm = 2.2084e-01, time/batch = 15.5777s	
18022/26050 (epoch 34.591), train_loss = 0.89242199, grad/param norm = 2.2254e-01, time/batch = 15.7490s	
18023/26050 (epoch 34.593), train_loss = 0.76628484, grad/param norm = 1.9230e-01, time/batch = 15.8016s	
18024/26050 (epoch 34.595), train_loss = 0.94019321, grad/param norm = 2.2421e-01, time/batch = 15.5791s	
18025/26050 (epoch 34.597), train_loss = 0.89510620, grad/param norm = 2.1199e-01, time/batch = 15.0824s	
18026/26050 (epoch 34.599), train_loss = 0.94549944, grad/param norm = 2.3265e-01, time/batch = 14.8391s	
18027/26050 (epoch 34.601), train_loss = 1.04109681, grad/param norm = 2.0814e-01, time/batch = 15.0527s	
18028/26050 (epoch 34.603), train_loss = 0.94326892, grad/param norm = 2.1875e-01, time/batch = 14.6374s	
18029/26050 (epoch 34.605), train_loss = 0.86325922, grad/param norm = 2.3233e-01, time/batch = 14.2479s	
18030/26050 (epoch 34.607), train_loss = 0.99127223, grad/param norm = 2.7394e-01, time/batch = 15.6888s	
18031/26050 (epoch 34.608), train_loss = 0.79187978, grad/param norm = 1.7419e-01, time/batch = 15.9799s	
18032/26050 (epoch 34.610), train_loss = 0.90457251, grad/param norm = 2.2876e-01, time/batch = 15.0875s	
18033/26050 (epoch 34.612), train_loss = 0.86948031, grad/param norm = 2.2316e-01, time/batch = 15.0725s	
18034/26050 (epoch 34.614), train_loss = 0.89520882, grad/param norm = 2.0930e-01, time/batch = 14.3055s	
18035/26050 (epoch 34.616), train_loss = 0.95741463, grad/param norm = 2.3217e-01, time/batch = 17.4413s	
18036/26050 (epoch 34.618), train_loss = 0.85358758, grad/param norm = 1.9908e-01, time/batch = 27.6931s	
18037/26050 (epoch 34.620), train_loss = 0.93881713, grad/param norm = 2.1654e-01, time/batch = 19.6987s	
18038/26050 (epoch 34.622), train_loss = 0.79892587, grad/param norm = 1.8833e-01, time/batch = 14.2111s	
18039/26050 (epoch 34.624), train_loss = 0.76520638, grad/param norm = 1.9372e-01, time/batch = 14.4662s	
18040/26050 (epoch 34.626), train_loss = 0.93109826, grad/param norm = 1.9915e-01, time/batch = 14.3212s	
18041/26050 (epoch 34.628), train_loss = 0.84134402, grad/param norm = 2.4761e-01, time/batch = 16.2367s	
18042/26050 (epoch 34.630), train_loss = 1.01822001, grad/param norm = 2.2539e-01, time/batch = 14.1658s	
18043/26050 (epoch 34.631), train_loss = 1.04998002, grad/param norm = 2.3734e-01, time/batch = 15.6699s	
18044/26050 (epoch 34.633), train_loss = 0.80800287, grad/param norm = 2.0216e-01, time/batch = 14.9247s	
18045/26050 (epoch 34.635), train_loss = 0.84043990, grad/param norm = 1.7860e-01, time/batch = 17.1431s	
18046/26050 (epoch 34.637), train_loss = 0.77819559, grad/param norm = 1.8366e-01, time/batch = 15.1230s	
18047/26050 (epoch 34.639), train_loss = 0.93150714, grad/param norm = 2.0570e-01, time/batch = 15.8619s	
18048/26050 (epoch 34.641), train_loss = 0.84037980, grad/param norm = 2.0506e-01, time/batch = 18.7383s	
18049/26050 (epoch 34.643), train_loss = 0.81161442, grad/param norm = 1.8894e-01, time/batch = 16.8092s	
18050/26050 (epoch 34.645), train_loss = 0.83391747, grad/param norm = 2.0146e-01, time/batch = 17.2123s	
18051/26050 (epoch 34.647), train_loss = 0.80745077, grad/param norm = 2.3562e-01, time/batch = 18.4010s	
18052/26050 (epoch 34.649), train_loss = 0.87045425, grad/param norm = 2.4162e-01, time/batch = 18.3161s	
18053/26050 (epoch 34.651), train_loss = 0.83212465, grad/param norm = 1.9113e-01, time/batch = 16.7678s	
18054/26050 (epoch 34.653), train_loss = 0.85658665, grad/param norm = 2.0447e-01, time/batch = 18.4668s	
18055/26050 (epoch 34.655), train_loss = 0.80032512, grad/param norm = 2.0819e-01, time/batch = 17.7501s	
18056/26050 (epoch 34.656), train_loss = 0.78059384, grad/param norm = 1.8683e-01, time/batch = 17.4821s	
18057/26050 (epoch 34.658), train_loss = 1.06892451, grad/param norm = 2.3051e-01, time/batch = 14.3911s	
18058/26050 (epoch 34.660), train_loss = 0.74474967, grad/param norm = 1.9390e-01, time/batch = 18.1543s	
18059/26050 (epoch 34.662), train_loss = 0.85941584, grad/param norm = 1.8488e-01, time/batch = 18.0519s	
18060/26050 (epoch 34.664), train_loss = 0.86931264, grad/param norm = 1.9435e-01, time/batch = 18.2188s	
18061/26050 (epoch 34.666), train_loss = 0.83236027, grad/param norm = 2.0584e-01, time/batch = 17.3898s	
18062/26050 (epoch 34.668), train_loss = 0.68161464, grad/param norm = 2.1274e-01, time/batch = 18.4063s	
18063/26050 (epoch 34.670), train_loss = 1.01075989, grad/param norm = 2.5075e-01, time/batch = 17.7305s	
18064/26050 (epoch 34.672), train_loss = 0.85485212, grad/param norm = 1.8380e-01, time/batch = 17.8968s	
18065/26050 (epoch 34.674), train_loss = 0.77293646, grad/param norm = 2.0368e-01, time/batch = 18.0844s	
18066/26050 (epoch 34.676), train_loss = 0.92303468, grad/param norm = 2.1288e-01, time/batch = 17.7307s	
18067/26050 (epoch 34.678), train_loss = 0.96421054, grad/param norm = 2.3420e-01, time/batch = 14.9756s	
18068/26050 (epoch 34.679), train_loss = 1.01929659, grad/param norm = 2.2977e-01, time/batch = 17.9847s	
18069/26050 (epoch 34.681), train_loss = 0.91087696, grad/param norm = 2.1598e-01, time/batch = 14.4763s	
18070/26050 (epoch 34.683), train_loss = 0.78690355, grad/param norm = 2.7276e-01, time/batch = 15.2979s	
18071/26050 (epoch 34.685), train_loss = 0.84297486, grad/param norm = 1.9135e-01, time/batch = 18.3035s	
18072/26050 (epoch 34.687), train_loss = 0.75174758, grad/param norm = 1.8256e-01, time/batch = 17.2074s	
18073/26050 (epoch 34.689), train_loss = 0.83052112, grad/param norm = 2.0214e-01, time/batch = 17.4728s	
18074/26050 (epoch 34.691), train_loss = 0.70585095, grad/param norm = 1.6445e-01, time/batch = 18.3238s	
18075/26050 (epoch 34.693), train_loss = 0.82975523, grad/param norm = 2.0151e-01, time/batch = 18.4951s	
18076/26050 (epoch 34.695), train_loss = 0.85943519, grad/param norm = 2.1644e-01, time/batch = 17.8960s	
18077/26050 (epoch 34.697), train_loss = 0.81562734, grad/param norm = 2.0422e-01, time/batch = 18.7257s	
18078/26050 (epoch 34.699), train_loss = 0.90992222, grad/param norm = 2.1757e-01, time/batch = 14.4783s	
18079/26050 (epoch 34.701), train_loss = 0.79021689, grad/param norm = 1.7863e-01, time/batch = 18.3956s	
18080/26050 (epoch 34.702), train_loss = 0.95272418, grad/param norm = 2.4208e-01, time/batch = 17.2267s	
18081/26050 (epoch 34.704), train_loss = 0.96361317, grad/param norm = 1.9452e-01, time/batch = 17.5639s	
18082/26050 (epoch 34.706), train_loss = 0.81201337, grad/param norm = 2.1170e-01, time/batch = 18.8790s	
18083/26050 (epoch 34.708), train_loss = 0.92871710, grad/param norm = 2.1908e-01, time/batch = 15.4540s	
18084/26050 (epoch 34.710), train_loss = 0.88862067, grad/param norm = 2.0783e-01, time/batch = 17.3054s	
18085/26050 (epoch 34.712), train_loss = 0.87306157, grad/param norm = 2.2542e-01, time/batch = 19.0642s	
18086/26050 (epoch 34.714), train_loss = 0.77239268, grad/param norm = 1.7593e-01, time/batch = 18.6623s	
18087/26050 (epoch 34.716), train_loss = 1.07507083, grad/param norm = 2.3393e-01, time/batch = 16.9733s	
18088/26050 (epoch 34.718), train_loss = 0.92865594, grad/param norm = 2.1662e-01, time/batch = 17.8169s	
18089/26050 (epoch 34.720), train_loss = 0.86463489, grad/param norm = 2.0787e-01, time/batch = 18.6577s	
18090/26050 (epoch 34.722), train_loss = 0.79231127, grad/param norm = 1.8639e-01, time/batch = 17.5701s	
18091/26050 (epoch 34.724), train_loss = 0.81478616, grad/param norm = 2.0539e-01, time/batch = 18.8954s	
18092/26050 (epoch 34.726), train_loss = 0.94159454, grad/param norm = 2.1444e-01, time/batch = 18.5784s	
18093/26050 (epoch 34.727), train_loss = 0.92360372, grad/param norm = 2.0483e-01, time/batch = 17.9337s	
18094/26050 (epoch 34.729), train_loss = 0.90185321, grad/param norm = 1.8726e-01, time/batch = 18.3164s	
18095/26050 (epoch 34.731), train_loss = 0.91545888, grad/param norm = 2.0484e-01, time/batch = 17.0576s	
18096/26050 (epoch 34.733), train_loss = 0.84145724, grad/param norm = 2.1086e-01, time/batch = 15.6428s	
18097/26050 (epoch 34.735), train_loss = 1.02179702, grad/param norm = 2.3062e-01, time/batch = 14.9733s	
18098/26050 (epoch 34.737), train_loss = 0.82738101, grad/param norm = 2.2249e-01, time/batch = 18.7077s	
18099/26050 (epoch 34.739), train_loss = 0.90109638, grad/param norm = 1.9568e-01, time/batch = 18.8038s	
18100/26050 (epoch 34.741), train_loss = 0.80292505, grad/param norm = 1.9807e-01, time/batch = 17.1366s	
18101/26050 (epoch 34.743), train_loss = 0.86642160, grad/param norm = 2.2457e-01, time/batch = 17.8746s	
18102/26050 (epoch 34.745), train_loss = 0.77006196, grad/param norm = 1.9773e-01, time/batch = 17.6613s	
18103/26050 (epoch 34.747), train_loss = 0.80038886, grad/param norm = 2.0352e-01, time/batch = 19.0698s	
18104/26050 (epoch 34.749), train_loss = 0.96443249, grad/param norm = 2.2316e-01, time/batch = 17.4690s	
18105/26050 (epoch 34.750), train_loss = 0.85142641, grad/param norm = 1.7886e-01, time/batch = 18.9839s	
18106/26050 (epoch 34.752), train_loss = 0.80080105, grad/param norm = 2.1669e-01, time/batch = 18.1576s	
18107/26050 (epoch 34.754), train_loss = 0.87741993, grad/param norm = 2.1602e-01, time/batch = 14.8017s	
18108/26050 (epoch 34.756), train_loss = 0.84150391, grad/param norm = 2.3053e-01, time/batch = 15.3836s	
18109/26050 (epoch 34.758), train_loss = 0.86146624, grad/param norm = 2.2619e-01, time/batch = 18.2976s	
18110/26050 (epoch 34.760), train_loss = 0.99759072, grad/param norm = 2.3111e-01, time/batch = 18.3095s	
18111/26050 (epoch 34.762), train_loss = 0.83651184, grad/param norm = 2.5223e-01, time/batch = 17.2138s	
18112/26050 (epoch 34.764), train_loss = 0.84633839, grad/param norm = 2.2213e-01, time/batch = 18.2122s	
18113/26050 (epoch 34.766), train_loss = 0.89013210, grad/param norm = 2.4235e-01, time/batch = 18.6338s	
18114/26050 (epoch 34.768), train_loss = 0.77245291, grad/param norm = 1.9823e-01, time/batch = 17.3971s	
18115/26050 (epoch 34.770), train_loss = 0.84128391, grad/param norm = 2.1416e-01, time/batch = 18.5611s	
18116/26050 (epoch 34.772), train_loss = 0.87986349, grad/param norm = 2.2862e-01, time/batch = 17.8970s	
18117/26050 (epoch 34.774), train_loss = 0.76402528, grad/param norm = 2.2983e-01, time/batch = 16.1378s	
18118/26050 (epoch 34.775), train_loss = 0.64264268, grad/param norm = 1.9665e-01, time/batch = 17.9072s	
18119/26050 (epoch 34.777), train_loss = 0.82411438, grad/param norm = 1.8710e-01, time/batch = 14.6561s	
18120/26050 (epoch 34.779), train_loss = 0.85454803, grad/param norm = 2.1657e-01, time/batch = 18.5612s	
18121/26050 (epoch 34.781), train_loss = 0.79083540, grad/param norm = 2.2219e-01, time/batch = 17.3949s	
18122/26050 (epoch 34.783), train_loss = 0.76078629, grad/param norm = 1.9607e-01, time/batch = 17.6471s	
18123/26050 (epoch 34.785), train_loss = 0.86373957, grad/param norm = 2.1323e-01, time/batch = 18.5540s	
18124/26050 (epoch 34.787), train_loss = 0.78562175, grad/param norm = 2.1174e-01, time/batch = 17.5590s	
18125/26050 (epoch 34.789), train_loss = 0.78746213, grad/param norm = 2.2598e-01, time/batch = 18.9130s	
18126/26050 (epoch 34.791), train_loss = 0.78539181, grad/param norm = 2.1784e-01, time/batch = 15.3118s	
18127/26050 (epoch 34.793), train_loss = 0.85292144, grad/param norm = 2.2870e-01, time/batch = 17.1256s	
18128/26050 (epoch 34.795), train_loss = 0.69426208, grad/param norm = 1.7114e-01, time/batch = 17.8997s	
18129/26050 (epoch 34.797), train_loss = 0.75158102, grad/param norm = 1.9857e-01, time/batch = 17.2394s	
18130/26050 (epoch 34.798), train_loss = 0.78822617, grad/param norm = 2.1362e-01, time/batch = 16.3148s	
18131/26050 (epoch 34.800), train_loss = 0.73806279, grad/param norm = 2.0052e-01, time/batch = 15.9694s	
18132/26050 (epoch 34.802), train_loss = 0.82399900, grad/param norm = 2.2174e-01, time/batch = 18.4886s	
18133/26050 (epoch 34.804), train_loss = 0.83529002, grad/param norm = 2.0431e-01, time/batch = 18.4081s	
18134/26050 (epoch 34.806), train_loss = 0.93750202, grad/param norm = 2.6857e-01, time/batch = 17.7406s	
18135/26050 (epoch 34.808), train_loss = 0.86418144, grad/param norm = 2.2353e-01, time/batch = 17.8982s	
18136/26050 (epoch 34.810), train_loss = 0.82382373, grad/param norm = 1.9934e-01, time/batch = 18.1501s	
18137/26050 (epoch 34.812), train_loss = 0.72869541, grad/param norm = 2.0347e-01, time/batch = 16.8902s	
18138/26050 (epoch 34.814), train_loss = 0.76615137, grad/param norm = 2.0025e-01, time/batch = 17.3142s	
18139/26050 (epoch 34.816), train_loss = 0.88147017, grad/param norm = 2.2266e-01, time/batch = 16.0490s	
18140/26050 (epoch 34.818), train_loss = 0.94688494, grad/param norm = 2.3947e-01, time/batch = 18.8172s	
18141/26050 (epoch 34.820), train_loss = 0.87771277, grad/param norm = 1.9939e-01, time/batch = 15.1318s	
18142/26050 (epoch 34.821), train_loss = 0.97015915, grad/param norm = 2.5076e-01, time/batch = 18.7286s	
18143/26050 (epoch 34.823), train_loss = 1.05943499, grad/param norm = 2.2546e-01, time/batch = 17.8195s	
18144/26050 (epoch 34.825), train_loss = 0.85399841, grad/param norm = 1.9806e-01, time/batch = 18.7361s	
18145/26050 (epoch 34.827), train_loss = 0.86543887, grad/param norm = 2.3440e-01, time/batch = 18.3814s	
18146/26050 (epoch 34.829), train_loss = 0.96192543, grad/param norm = 2.3527e-01, time/batch = 15.3203s	
18147/26050 (epoch 34.831), train_loss = 1.00313057, grad/param norm = 2.3470e-01, time/batch = 18.2437s	
18148/26050 (epoch 34.833), train_loss = 0.99581891, grad/param norm = 2.4084e-01, time/batch = 17.4927s	
18149/26050 (epoch 34.835), train_loss = 1.00814337, grad/param norm = 2.3491e-01, time/batch = 18.0106s	
18150/26050 (epoch 34.837), train_loss = 0.87814334, grad/param norm = 1.9493e-01, time/batch = 16.5803s	
18151/26050 (epoch 34.839), train_loss = 0.88185886, grad/param norm = 2.7035e-01, time/batch = 15.8898s	
18152/26050 (epoch 34.841), train_loss = 0.95972237, grad/param norm = 2.3548e-01, time/batch = 19.0372s	
18153/26050 (epoch 34.843), train_loss = 0.86077953, grad/param norm = 2.0781e-01, time/batch = 18.4925s	
18154/26050 (epoch 34.845), train_loss = 0.82418272, grad/param norm = 1.9232e-01, time/batch = 18.9010s	
18155/26050 (epoch 34.846), train_loss = 0.90371382, grad/param norm = 2.2231e-01, time/batch = 16.7998s	
18156/26050 (epoch 34.848), train_loss = 0.85262025, grad/param norm = 2.0448e-01, time/batch = 16.6307s	
18157/26050 (epoch 34.850), train_loss = 0.77790406, grad/param norm = 1.8409e-01, time/batch = 18.6342s	
18158/26050 (epoch 34.852), train_loss = 0.88608713, grad/param norm = 1.9357e-01, time/batch = 18.1571s	
18159/26050 (epoch 34.854), train_loss = 0.85770123, grad/param norm = 2.0959e-01, time/batch = 18.3214s	
18160/26050 (epoch 34.856), train_loss = 0.82041397, grad/param norm = 2.1509e-01, time/batch = 15.8082s	
18161/26050 (epoch 34.858), train_loss = 0.79475973, grad/param norm = 2.0483e-01, time/batch = 18.0610s	
18162/26050 (epoch 34.860), train_loss = 0.91204847, grad/param norm = 2.1571e-01, time/batch = 17.4730s	
18163/26050 (epoch 34.862), train_loss = 0.93951552, grad/param norm = 2.1009e-01, time/batch = 18.3140s	
18164/26050 (epoch 34.864), train_loss = 0.88181355, grad/param norm = 2.3008e-01, time/batch = 18.8125s	
18165/26050 (epoch 34.866), train_loss = 0.84605976, grad/param norm = 2.0824e-01, time/batch = 15.2980s	
18166/26050 (epoch 34.868), train_loss = 0.93451761, grad/param norm = 2.3633e-01, time/batch = 18.1531s	
18167/26050 (epoch 34.869), train_loss = 0.79041442, grad/param norm = 1.8464e-01, time/batch = 18.3962s	
18168/26050 (epoch 34.871), train_loss = 0.74958675, grad/param norm = 2.0482e-01, time/batch = 14.6353s	
18169/26050 (epoch 34.873), train_loss = 0.91916629, grad/param norm = 2.3126e-01, time/batch = 17.8987s	
18170/26050 (epoch 34.875), train_loss = 0.81471455, grad/param norm = 1.9962e-01, time/batch = 17.5651s	
18171/26050 (epoch 34.877), train_loss = 0.80392381, grad/param norm = 1.8685e-01, time/batch = 18.9655s	
18172/26050 (epoch 34.879), train_loss = 0.90361970, grad/param norm = 2.0407e-01, time/batch = 17.4015s	
18173/26050 (epoch 34.881), train_loss = 0.93957655, grad/param norm = 2.2921e-01, time/batch = 17.4018s	
18174/26050 (epoch 34.883), train_loss = 0.92044543, grad/param norm = 2.5789e-01, time/batch = 18.4928s	
18175/26050 (epoch 34.885), train_loss = 0.67032868, grad/param norm = 1.8648e-01, time/batch = 16.5547s	
18176/26050 (epoch 34.887), train_loss = 0.94603297, grad/param norm = 2.2508e-01, time/batch = 17.8795s	
18177/26050 (epoch 34.889), train_loss = 0.80476890, grad/param norm = 1.9666e-01, time/batch = 15.0555s	
18178/26050 (epoch 34.891), train_loss = 0.72368491, grad/param norm = 1.9451e-01, time/batch = 17.7448s	
18179/26050 (epoch 34.893), train_loss = 0.74686359, grad/param norm = 1.9965e-01, time/batch = 14.0920s	
18180/26050 (epoch 34.894), train_loss = 0.81038294, grad/param norm = 2.0174e-01, time/batch = 14.3124s	
18181/26050 (epoch 34.896), train_loss = 0.94718005, grad/param norm = 2.3000e-01, time/batch = 14.4060s	
18182/26050 (epoch 34.898), train_loss = 0.83240492, grad/param norm = 2.1818e-01, time/batch = 15.6692s	
18183/26050 (epoch 34.900), train_loss = 0.90433383, grad/param norm = 2.3632e-01, time/batch = 16.7113s	
18184/26050 (epoch 34.902), train_loss = 0.83404549, grad/param norm = 2.0940e-01, time/batch = 18.4005s	
18185/26050 (epoch 34.904), train_loss = 0.84095471, grad/param norm = 2.0052e-01, time/batch = 17.7382s	
18186/26050 (epoch 34.906), train_loss = 0.84845810, grad/param norm = 2.6561e-01, time/batch = 16.5392s	
18187/26050 (epoch 34.908), train_loss = 0.87443268, grad/param norm = 2.0054e-01, time/batch = 18.3876s	
18188/26050 (epoch 34.910), train_loss = 0.81795910, grad/param norm = 2.0909e-01, time/batch = 18.9715s	
18189/26050 (epoch 34.912), train_loss = 1.06347507, grad/param norm = 2.4226e-01, time/batch = 17.7198s	
18190/26050 (epoch 34.914), train_loss = 1.18272323, grad/param norm = 2.4628e-01, time/batch = 17.6475s	
18191/26050 (epoch 34.916), train_loss = 0.93598985, grad/param norm = 2.2914e-01, time/batch = 15.4535s	
18192/26050 (epoch 34.917), train_loss = 0.90236671, grad/param norm = 2.2192e-01, time/batch = 18.4798s	
18193/26050 (epoch 34.919), train_loss = 0.90615399, grad/param norm = 2.3375e-01, time/batch = 15.4743s	
18194/26050 (epoch 34.921), train_loss = 0.83368319, grad/param norm = 2.2492e-01, time/batch = 16.7320s	
18195/26050 (epoch 34.923), train_loss = 0.88648499, grad/param norm = 2.1783e-01, time/batch = 18.8901s	
18196/26050 (epoch 34.925), train_loss = 0.86066037, grad/param norm = 2.0176e-01, time/batch = 17.7230s	
18197/26050 (epoch 34.927), train_loss = 0.78711265, grad/param norm = 1.7945e-01, time/batch = 18.2290s	
18198/26050 (epoch 34.929), train_loss = 0.74283319, grad/param norm = 1.9312e-01, time/batch = 17.1139s	
18199/26050 (epoch 34.931), train_loss = 1.04971499, grad/param norm = 2.5674e-01, time/batch = 17.9678s	
18200/26050 (epoch 34.933), train_loss = 0.85125548, grad/param norm = 2.0410e-01, time/batch = 17.2967s	
18201/26050 (epoch 34.935), train_loss = 0.84366248, grad/param norm = 2.1702e-01, time/batch = 14.6310s	
18202/26050 (epoch 34.937), train_loss = 0.92294562, grad/param norm = 2.0080e-01, time/batch = 17.8956s	
18203/26050 (epoch 34.939), train_loss = 0.78377966, grad/param norm = 1.8758e-01, time/batch = 17.4720s	
18204/26050 (epoch 34.940), train_loss = 0.84547505, grad/param norm = 2.0000e-01, time/batch = 17.7282s	
18205/26050 (epoch 34.942), train_loss = 0.83567604, grad/param norm = 2.0708e-01, time/batch = 15.3877s	
18206/26050 (epoch 34.944), train_loss = 0.84215679, grad/param norm = 2.1166e-01, time/batch = 18.4082s	
18207/26050 (epoch 34.946), train_loss = 0.99224287, grad/param norm = 1.9408e-01, time/batch = 17.3793s	
18208/26050 (epoch 34.948), train_loss = 0.75234627, grad/param norm = 2.2824e-01, time/batch = 17.5617s	
18209/26050 (epoch 34.950), train_loss = 0.87444221, grad/param norm = 2.0100e-01, time/batch = 18.8142s	
18210/26050 (epoch 34.952), train_loss = 0.92730323, grad/param norm = 2.1112e-01, time/batch = 17.9735s	
18211/26050 (epoch 34.954), train_loss = 0.92691706, grad/param norm = 2.2875e-01, time/batch = 17.4884s	
18212/26050 (epoch 34.956), train_loss = 0.82856812, grad/param norm = 2.0402e-01, time/batch = 14.5577s	
18213/26050 (epoch 34.958), train_loss = 0.77681483, grad/param norm = 1.8482e-01, time/batch = 16.0502s	
18214/26050 (epoch 34.960), train_loss = 0.89195571, grad/param norm = 2.1076e-01, time/batch = 17.9819s	
18215/26050 (epoch 34.962), train_loss = 0.84076892, grad/param norm = 1.8716e-01, time/batch = 18.4768s	
18216/26050 (epoch 34.964), train_loss = 0.84750464, grad/param norm = 2.0355e-01, time/batch = 17.8702s	
18217/26050 (epoch 34.965), train_loss = 0.78966010, grad/param norm = 2.0827e-01, time/batch = 17.7917s	
18218/26050 (epoch 34.967), train_loss = 1.15904160, grad/param norm = 2.1210e-01, time/batch = 15.4636s	
18219/26050 (epoch 34.969), train_loss = 0.86244491, grad/param norm = 1.8350e-01, time/batch = 17.1590s	
18220/26050 (epoch 34.971), train_loss = 0.85724090, grad/param norm = 1.9042e-01, time/batch = 18.2440s	
18221/26050 (epoch 34.973), train_loss = 0.87822623, grad/param norm = 2.0783e-01, time/batch = 18.6340s	
18222/26050 (epoch 34.975), train_loss = 0.89359282, grad/param norm = 2.0778e-01, time/batch = 18.4792s	
18223/26050 (epoch 34.977), train_loss = 0.85584223, grad/param norm = 1.9153e-01, time/batch = 18.4696s	
18224/26050 (epoch 34.979), train_loss = 0.71259617, grad/param norm = 2.0793e-01, time/batch = 16.6443s	
18225/26050 (epoch 34.981), train_loss = 0.97275917, grad/param norm = 2.0086e-01, time/batch = 17.7362s	
18226/26050 (epoch 34.983), train_loss = 0.92195275, grad/param norm = 2.0092e-01, time/batch = 18.9891s	
18227/26050 (epoch 34.985), train_loss = 0.90743901, grad/param norm = 2.3989e-01, time/batch = 15.3077s	
18228/26050 (epoch 34.987), train_loss = 0.97428564, grad/param norm = 2.1375e-01, time/batch = 14.7869s	
18229/26050 (epoch 34.988), train_loss = 0.90303767, grad/param norm = 2.6788e-01, time/batch = 17.3739s	
18230/26050 (epoch 34.990), train_loss = 0.75144536, grad/param norm = 1.6904e-01, time/batch = 17.9769s	
18231/26050 (epoch 34.992), train_loss = 0.99753885, grad/param norm = 2.2346e-01, time/batch = 17.8026s	
18232/26050 (epoch 34.994), train_loss = 0.81079883, grad/param norm = 2.1180e-01, time/batch = 18.7221s	
18233/26050 (epoch 34.996), train_loss = 0.77784041, grad/param norm = 2.2954e-01, time/batch = 17.2329s	
18234/26050 (epoch 34.998), train_loss = 0.88890791, grad/param norm = 2.0096e-01, time/batch = 17.5510s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
18235/26050 (epoch 35.000), train_loss = 0.81000357, grad/param norm = 2.0575e-01, time/batch = 18.0631s	
18236/26050 (epoch 35.002), train_loss = 0.92749224, grad/param norm = 2.2340e-01, time/batch = 18.7395s	
18237/26050 (epoch 35.004), train_loss = 0.77197960, grad/param norm = 2.0665e-01, time/batch = 17.4893s	
18238/26050 (epoch 35.006), train_loss = 0.80887099, grad/param norm = 2.3241e-01, time/batch = 17.6577s	
18239/26050 (epoch 35.008), train_loss = 0.79379506, grad/param norm = 2.0822e-01, time/batch = 18.0742s	
18240/26050 (epoch 35.010), train_loss = 0.78435455, grad/param norm = 1.8946e-01, time/batch = 16.2368s	
18241/26050 (epoch 35.012), train_loss = 0.86281065, grad/param norm = 2.0219e-01, time/batch = 23.3942s	
18242/26050 (epoch 35.013), train_loss = 1.09911080, grad/param norm = 3.1942e-01, time/batch = 32.8609s	
18243/26050 (epoch 35.015), train_loss = 0.87102116, grad/param norm = 2.2246e-01, time/batch = 17.7204s	
18244/26050 (epoch 35.017), train_loss = 0.90148238, grad/param norm = 1.9979e-01, time/batch = 18.2876s	
18245/26050 (epoch 35.019), train_loss = 0.76313427, grad/param norm = 1.5918e-01, time/batch = 18.5708s	
18246/26050 (epoch 35.021), train_loss = 0.96467874, grad/param norm = 2.2154e-01, time/batch = 17.9766s	
18247/26050 (epoch 35.023), train_loss = 0.72646584, grad/param norm = 2.0462e-01, time/batch = 18.4790s	
18248/26050 (epoch 35.025), train_loss = 0.83589831, grad/param norm = 1.9157e-01, time/batch = 17.9004s	
18249/26050 (epoch 35.027), train_loss = 0.70555933, grad/param norm = 2.1691e-01, time/batch = 18.8885s	
18250/26050 (epoch 35.029), train_loss = 0.88435775, grad/param norm = 1.9475e-01, time/batch = 14.6098s	
18251/26050 (epoch 35.031), train_loss = 0.97496870, grad/param norm = 2.4673e-01, time/batch = 16.8668s	
18252/26050 (epoch 35.033), train_loss = 0.86971072, grad/param norm = 2.0209e-01, time/batch = 17.6609s	
18253/26050 (epoch 35.035), train_loss = 0.89293333, grad/param norm = 1.9236e-01, time/batch = 17.5595s	
18254/26050 (epoch 35.036), train_loss = 0.77062077, grad/param norm = 2.4678e-01, time/batch = 18.2351s	
18255/26050 (epoch 35.038), train_loss = 0.70995747, grad/param norm = 1.8912e-01, time/batch = 18.4676s	
18256/26050 (epoch 35.040), train_loss = 0.85900335, grad/param norm = 2.2727e-01, time/batch = 18.0681s	
18257/26050 (epoch 35.042), train_loss = 0.73708069, grad/param norm = 2.0446e-01, time/batch = 18.1436s	
18258/26050 (epoch 35.044), train_loss = 0.92687448, grad/param norm = 1.9586e-01, time/batch = 17.9701s	
18259/26050 (epoch 35.046), train_loss = 0.73183252, grad/param norm = 1.7838e-01, time/batch = 18.1977s	
18260/26050 (epoch 35.048), train_loss = 0.84606943, grad/param norm = 2.0156e-01, time/batch = 17.8822s	
18261/26050 (epoch 35.050), train_loss = 0.79900708, grad/param norm = 1.8604e-01, time/batch = 18.4787s	
18262/26050 (epoch 35.052), train_loss = 0.79328594, grad/param norm = 2.1848e-01, time/batch = 18.7238s	
18263/26050 (epoch 35.054), train_loss = 0.70788233, grad/param norm = 1.8831e-01, time/batch = 17.3167s	
18264/26050 (epoch 35.056), train_loss = 0.69222274, grad/param norm = 1.6140e-01, time/batch = 17.9860s	
18265/26050 (epoch 35.058), train_loss = 0.83175713, grad/param norm = 1.8903e-01, time/batch = 17.8175s	
18266/26050 (epoch 35.060), train_loss = 0.89443854, grad/param norm = 1.9267e-01, time/batch = 16.9874s	
18267/26050 (epoch 35.061), train_loss = 0.76331110, grad/param norm = 1.8594e-01, time/batch = 18.1494s	
18268/26050 (epoch 35.063), train_loss = 0.84567549, grad/param norm = 1.8990e-01, time/batch = 17.6586s	
18269/26050 (epoch 35.065), train_loss = 0.69215657, grad/param norm = 1.6815e-01, time/batch = 18.4896s	
18270/26050 (epoch 35.067), train_loss = 0.84545067, grad/param norm = 2.2155e-01, time/batch = 17.2936s	
18271/26050 (epoch 35.069), train_loss = 0.87665453, grad/param norm = 1.9812e-01, time/batch = 18.0644s	
18272/26050 (epoch 35.071), train_loss = 0.88831850, grad/param norm = 2.2323e-01, time/batch = 18.2396s	
18273/26050 (epoch 35.073), train_loss = 0.99043437, grad/param norm = 2.0391e-01, time/batch = 14.7429s	
18274/26050 (epoch 35.075), train_loss = 0.81568471, grad/param norm = 2.0172e-01, time/batch = 0.6461s	
18275/26050 (epoch 35.077), train_loss = 0.80368285, grad/param norm = 2.0599e-01, time/batch = 0.6521s	
18276/26050 (epoch 35.079), train_loss = 0.82115622, grad/param norm = 2.1583e-01, time/batch = 0.6553s	
18277/26050 (epoch 35.081), train_loss = 0.83121397, grad/param norm = 1.9732e-01, time/batch = 0.6560s	
18278/26050 (epoch 35.083), train_loss = 0.95031932, grad/param norm = 2.0354e-01, time/batch = 0.6704s	
18279/26050 (epoch 35.084), train_loss = 0.86842063, grad/param norm = 2.2393e-01, time/batch = 0.6847s	
18280/26050 (epoch 35.086), train_loss = 1.00692003, grad/param norm = 2.5990e-01, time/batch = 0.6704s	
18281/26050 (epoch 35.088), train_loss = 0.83922025, grad/param norm = 2.1004e-01, time/batch = 0.8406s	
18282/26050 (epoch 35.090), train_loss = 0.88436436, grad/param norm = 2.1731e-01, time/batch = 0.9562s	
18283/26050 (epoch 35.092), train_loss = 0.89228865, grad/param norm = 1.9337e-01, time/batch = 0.9597s	
18284/26050 (epoch 35.094), train_loss = 0.74100780, grad/param norm = 1.9126e-01, time/batch = 0.9552s	
18285/26050 (epoch 35.096), train_loss = 0.87780816, grad/param norm = 1.9746e-01, time/batch = 0.9684s	
18286/26050 (epoch 35.098), train_loss = 0.83849227, grad/param norm = 2.1026e-01, time/batch = 1.2817s	
18287/26050 (epoch 35.100), train_loss = 0.77565586, grad/param norm = 2.0487e-01, time/batch = 1.7995s	
18288/26050 (epoch 35.102), train_loss = 0.88224660, grad/param norm = 2.1797e-01, time/batch = 1.7942s	
18289/26050 (epoch 35.104), train_loss = 0.81421894, grad/param norm = 1.8729e-01, time/batch = 11.8298s	
18290/26050 (epoch 35.106), train_loss = 0.91220606, grad/param norm = 2.3620e-01, time/batch = 19.1380s	
18291/26050 (epoch 35.107), train_loss = 0.70687859, grad/param norm = 1.7729e-01, time/batch = 17.8997s	
18292/26050 (epoch 35.109), train_loss = 0.79219799, grad/param norm = 1.8969e-01, time/batch = 17.7359s	
18293/26050 (epoch 35.111), train_loss = 0.97719540, grad/param norm = 2.2546e-01, time/batch = 18.4871s	
18294/26050 (epoch 35.113), train_loss = 0.82600620, grad/param norm = 1.9353e-01, time/batch = 17.9920s	
18295/26050 (epoch 35.115), train_loss = 0.94568172, grad/param norm = 2.0784e-01, time/batch = 17.9856s	
18296/26050 (epoch 35.117), train_loss = 0.88655592, grad/param norm = 2.1488e-01, time/batch = 16.7263s	
18297/26050 (epoch 35.119), train_loss = 0.76151088, grad/param norm = 1.9169e-01, time/batch = 17.2949s	
18298/26050 (epoch 35.121), train_loss = 0.85976342, grad/param norm = 2.0570e-01, time/batch = 17.3812s	
18299/26050 (epoch 35.123), train_loss = 0.77032938, grad/param norm = 2.0191e-01, time/batch = 15.2988s	
18300/26050 (epoch 35.125), train_loss = 0.72848458, grad/param norm = 1.7418e-01, time/batch = 17.8154s	
18301/26050 (epoch 35.127), train_loss = 0.70560973, grad/param norm = 1.7856e-01, time/batch = 17.3599s	
18302/26050 (epoch 35.129), train_loss = 0.68178025, grad/param norm = 2.0515e-01, time/batch = 17.6554s	
18303/26050 (epoch 35.131), train_loss = 0.82896582, grad/param norm = 2.0611e-01, time/batch = 18.7198s	
18304/26050 (epoch 35.132), train_loss = 0.84831473, grad/param norm = 1.9540e-01, time/batch = 18.9864s	
18305/26050 (epoch 35.134), train_loss = 0.89062757, grad/param norm = 2.3237e-01, time/batch = 18.5445s	
18306/26050 (epoch 35.136), train_loss = 0.81728702, grad/param norm = 1.8607e-01, time/batch = 15.9413s	
18307/26050 (epoch 35.138), train_loss = 0.59217643, grad/param norm = 1.6916e-01, time/batch = 17.5641s	
18308/26050 (epoch 35.140), train_loss = 0.70282255, grad/param norm = 2.0199e-01, time/batch = 17.0576s	
18309/26050 (epoch 35.142), train_loss = 0.74063533, grad/param norm = 1.9864e-01, time/batch = 17.8750s	
18310/26050 (epoch 35.144), train_loss = 0.67765006, grad/param norm = 2.2783e-01, time/batch = 17.5714s	
18311/26050 (epoch 35.146), train_loss = 0.64954625, grad/param norm = 1.8123e-01, time/batch = 16.5561s	
18312/26050 (epoch 35.148), train_loss = 0.66828600, grad/param norm = 1.8186e-01, time/batch = 16.7887s	
18313/26050 (epoch 35.150), train_loss = 0.78755473, grad/param norm = 2.1491e-01, time/batch = 18.0704s	
18314/26050 (epoch 35.152), train_loss = 0.96622976, grad/param norm = 2.4103e-01, time/batch = 18.2308s	
18315/26050 (epoch 35.154), train_loss = 0.67415392, grad/param norm = 1.9864e-01, time/batch = 17.8776s	
18316/26050 (epoch 35.155), train_loss = 0.72608252, grad/param norm = 2.1130e-01, time/batch = 18.4752s	
18317/26050 (epoch 35.157), train_loss = 0.81865795, grad/param norm = 2.4707e-01, time/batch = 15.8194s	
18318/26050 (epoch 35.159), train_loss = 0.89160946, grad/param norm = 4.5278e-01, time/batch = 17.3981s	
18319/26050 (epoch 35.161), train_loss = 0.86804896, grad/param norm = 2.4650e-01, time/batch = 18.2198s	
18320/26050 (epoch 35.163), train_loss = 0.73264979, grad/param norm = 2.0557e-01, time/batch = 18.3995s	
18321/26050 (epoch 35.165), train_loss = 0.65818185, grad/param norm = 1.9327e-01, time/batch = 18.5582s	
18322/26050 (epoch 35.167), train_loss = 0.99133492, grad/param norm = 2.4555e-01, time/batch = 16.9709s	
18323/26050 (epoch 35.169), train_loss = 0.83886005, grad/param norm = 1.9777e-01, time/batch = 17.6510s	
18324/26050 (epoch 35.171), train_loss = 0.75095583, grad/param norm = 1.9698e-01, time/batch = 17.4780s	
18325/26050 (epoch 35.173), train_loss = 0.81998263, grad/param norm = 2.0622e-01, time/batch = 15.3552s	
18326/26050 (epoch 35.175), train_loss = 0.83367063, grad/param norm = 2.3885e-01, time/batch = 16.0297s	
18327/26050 (epoch 35.177), train_loss = 0.89841265, grad/param norm = 1.9379e-01, time/batch = 18.7192s	
18328/26050 (epoch 35.179), train_loss = 0.62910301, grad/param norm = 1.7253e-01, time/batch = 18.7219s	
18329/26050 (epoch 35.180), train_loss = 1.07571822, grad/param norm = 2.1531e-01, time/batch = 18.0626s	
18330/26050 (epoch 35.182), train_loss = 1.01904130, grad/param norm = 2.2589e-01, time/batch = 17.4734s	
18331/26050 (epoch 35.184), train_loss = 0.86727497, grad/param norm = 2.1210e-01, time/batch = 19.0769s	
18332/26050 (epoch 35.186), train_loss = 0.70691202, grad/param norm = 1.8655e-01, time/batch = 17.1434s	
18333/26050 (epoch 35.188), train_loss = 0.88503440, grad/param norm = 2.3560e-01, time/batch = 17.3788s	
18334/26050 (epoch 35.190), train_loss = 0.89197462, grad/param norm = 2.5231e-01, time/batch = 17.6561s	
18335/26050 (epoch 35.192), train_loss = 0.93055956, grad/param norm = 2.0587e-01, time/batch = 18.0599s	
18336/26050 (epoch 35.194), train_loss = 0.88831044, grad/param norm = 2.0403e-01, time/batch = 17.8108s	
18337/26050 (epoch 35.196), train_loss = 0.89976181, grad/param norm = 2.1504e-01, time/batch = 16.4731s	
18338/26050 (epoch 35.198), train_loss = 0.76137787, grad/param norm = 1.7562e-01, time/batch = 18.3770s	
18339/26050 (epoch 35.200), train_loss = 0.75077590, grad/param norm = 1.9241e-01, time/batch = 17.9621s	
18340/26050 (epoch 35.202), train_loss = 0.86372664, grad/param norm = 1.8837e-01, time/batch = 16.9614s	
18341/26050 (epoch 35.203), train_loss = 0.94310668, grad/param norm = 1.9772e-01, time/batch = 17.3087s	
18342/26050 (epoch 35.205), train_loss = 0.80118146, grad/param norm = 2.1056e-01, time/batch = 17.5641s	
18343/26050 (epoch 35.207), train_loss = 0.76255650, grad/param norm = 1.9471e-01, time/batch = 18.1462s	
18344/26050 (epoch 35.209), train_loss = 0.90190666, grad/param norm = 2.0707e-01, time/batch = 18.7219s	
18345/26050 (epoch 35.211), train_loss = 0.71871660, grad/param norm = 1.9776e-01, time/batch = 14.8834s	
18346/26050 (epoch 35.213), train_loss = 0.86529677, grad/param norm = 2.1652e-01, time/batch = 18.2308s	
18347/26050 (epoch 35.215), train_loss = 0.83672272, grad/param norm = 2.3105e-01, time/batch = 18.0523s	
18348/26050 (epoch 35.217), train_loss = 0.78765998, grad/param norm = 1.8265e-01, time/batch = 17.7273s	
18349/26050 (epoch 35.219), train_loss = 0.83422244, grad/param norm = 2.4387e-01, time/batch = 16.9796s	
18350/26050 (epoch 35.221), train_loss = 0.74614507, grad/param norm = 2.1986e-01, time/batch = 15.0615s	
18351/26050 (epoch 35.223), train_loss = 0.93529569, grad/param norm = 2.2627e-01, time/batch = 17.9635s	
18352/26050 (epoch 35.225), train_loss = 0.75877606, grad/param norm = 1.9043e-01, time/batch = 17.5522s	
18353/26050 (epoch 35.226), train_loss = 0.85696625, grad/param norm = 2.1655e-01, time/batch = 18.1379s	
18354/26050 (epoch 35.228), train_loss = 0.98193881, grad/param norm = 2.0703e-01, time/batch = 15.6284s	
18355/26050 (epoch 35.230), train_loss = 0.83495722, grad/param norm = 1.8150e-01, time/batch = 18.4120s	
18356/26050 (epoch 35.232), train_loss = 0.91697342, grad/param norm = 2.3014e-01, time/batch = 16.3976s	
18357/26050 (epoch 35.234), train_loss = 0.75656590, grad/param norm = 2.1693e-01, time/batch = 17.3303s	
18358/26050 (epoch 35.236), train_loss = 0.93232119, grad/param norm = 2.1739e-01, time/batch = 17.4099s	
18359/26050 (epoch 35.238), train_loss = 0.73042837, grad/param norm = 2.0403e-01, time/batch = 16.6253s	
18360/26050 (epoch 35.240), train_loss = 0.84968637, grad/param norm = 1.9844e-01, time/batch = 17.7337s	
18361/26050 (epoch 35.242), train_loss = 0.82254540, grad/param norm = 2.0141e-01, time/batch = 18.2337s	
18362/26050 (epoch 35.244), train_loss = 0.89387422, grad/param norm = 2.8182e-01, time/batch = 18.6514s	
18363/26050 (epoch 35.246), train_loss = 0.80994994, grad/param norm = 1.8832e-01, time/batch = 16.5492s	
18364/26050 (epoch 35.248), train_loss = 0.86145994, grad/param norm = 2.4976e-01, time/batch = 17.4621s	
18365/26050 (epoch 35.250), train_loss = 0.85367157, grad/param norm = 2.4881e-01, time/batch = 18.4012s	
18366/26050 (epoch 35.251), train_loss = 0.80484345, grad/param norm = 2.0027e-01, time/batch = 17.3263s	
18367/26050 (epoch 35.253), train_loss = 0.77034706, grad/param norm = 2.0470e-01, time/batch = 15.4747s	
18368/26050 (epoch 35.255), train_loss = 1.02719257, grad/param norm = 2.9693e-01, time/batch = 17.9108s	
18369/26050 (epoch 35.257), train_loss = 0.85116714, grad/param norm = 2.5910e-01, time/batch = 18.6508s	
18370/26050 (epoch 35.259), train_loss = 0.94073254, grad/param norm = 2.1824e-01, time/batch = 18.3281s	
18371/26050 (epoch 35.261), train_loss = 0.75996130, grad/param norm = 2.2165e-01, time/batch = 18.4709s	
18372/26050 (epoch 35.263), train_loss = 0.95644167, grad/param norm = 2.2898e-01, time/batch = 18.9836s	
18373/26050 (epoch 35.265), train_loss = 0.98340598, grad/param norm = 2.7275e-01, time/batch = 15.4620s	
18374/26050 (epoch 35.267), train_loss = 0.98486034, grad/param norm = 2.1521e-01, time/batch = 14.8102s	
18375/26050 (epoch 35.269), train_loss = 0.97449958, grad/param norm = 2.1251e-01, time/batch = 16.9657s	
18376/26050 (epoch 35.271), train_loss = 0.88514693, grad/param norm = 2.2064e-01, time/batch = 17.9816s	
18377/26050 (epoch 35.273), train_loss = 0.76667256, grad/param norm = 1.9517e-01, time/batch = 18.0581s	
18378/26050 (epoch 35.274), train_loss = 0.82805932, grad/param norm = 2.0782e-01, time/batch = 18.7281s	
18379/26050 (epoch 35.276), train_loss = 0.82125372, grad/param norm = 2.3261e-01, time/batch = 18.3223s	
18380/26050 (epoch 35.278), train_loss = 0.92057868, grad/param norm = 1.9931e-01, time/batch = 15.8681s	
18381/26050 (epoch 35.280), train_loss = 0.85648630, grad/param norm = 2.0935e-01, time/batch = 18.4699s	
18382/26050 (epoch 35.282), train_loss = 0.90867116, grad/param norm = 2.0057e-01, time/batch = 16.8818s	
18383/26050 (epoch 35.284), train_loss = 0.84067446, grad/param norm = 2.0118e-01, time/batch = 17.9638s	
18384/26050 (epoch 35.286), train_loss = 0.88906893, grad/param norm = 2.2529e-01, time/batch = 18.4860s	
18385/26050 (epoch 35.288), train_loss = 0.72915223, grad/param norm = 1.7816e-01, time/batch = 18.2208s	
18386/26050 (epoch 35.290), train_loss = 0.86375235, grad/param norm = 2.1559e-01, time/batch = 18.1551s	
18387/26050 (epoch 35.292), train_loss = 0.78144532, grad/param norm = 2.0254e-01, time/batch = 16.6232s	
18388/26050 (epoch 35.294), train_loss = 0.86063833, grad/param norm = 2.2325e-01, time/batch = 17.8847s	
18389/26050 (epoch 35.296), train_loss = 0.93192753, grad/param norm = 2.0035e-01, time/batch = 18.4071s	
18390/26050 (epoch 35.298), train_loss = 0.87833096, grad/param norm = 1.9237e-01, time/batch = 14.7130s	
18391/26050 (epoch 35.299), train_loss = 0.70630977, grad/param norm = 1.8526e-01, time/batch = 15.0373s	
18392/26050 (epoch 35.301), train_loss = 0.72062427, grad/param norm = 1.9906e-01, time/batch = 18.6206s	
18393/26050 (epoch 35.303), train_loss = 0.85641643, grad/param norm = 2.1215e-01, time/batch = 17.1515s	
18394/26050 (epoch 35.305), train_loss = 0.69276066, grad/param norm = 1.8779e-01, time/batch = 17.8268s	
18395/26050 (epoch 35.307), train_loss = 0.78153213, grad/param norm = 2.4922e-01, time/batch = 18.9819s	
18396/26050 (epoch 35.309), train_loss = 0.86787619, grad/param norm = 2.3535e-01, time/batch = 18.6628s	
18397/26050 (epoch 35.311), train_loss = 0.85208980, grad/param norm = 2.1923e-01, time/batch = 17.4717s	
18398/26050 (epoch 35.313), train_loss = 0.83553830, grad/param norm = 2.1236e-01, time/batch = 18.1197s	
18399/26050 (epoch 35.315), train_loss = 0.91484936, grad/param norm = 2.0131e-01, time/batch = 17.8021s	
18400/26050 (epoch 35.317), train_loss = 0.86843883, grad/param norm = 2.2768e-01, time/batch = 16.8084s	
18401/26050 (epoch 35.319), train_loss = 0.76995238, grad/param norm = 1.8239e-01, time/batch = 15.3910s	
18402/26050 (epoch 35.321), train_loss = 0.83762333, grad/param norm = 2.2714e-01, time/batch = 18.3071s	
18403/26050 (epoch 35.322), train_loss = 0.90916388, grad/param norm = 2.0717e-01, time/batch = 18.6373s	
18404/26050 (epoch 35.324), train_loss = 0.69182914, grad/param norm = 2.1164e-01, time/batch = 17.9067s	
18405/26050 (epoch 35.326), train_loss = 0.95934050, grad/param norm = 2.2272e-01, time/batch = 18.5676s	
18406/26050 (epoch 35.328), train_loss = 0.86905583, grad/param norm = 1.7966e-01, time/batch = 18.8993s	
18407/26050 (epoch 35.330), train_loss = 0.74135891, grad/param norm = 1.9842e-01, time/batch = 15.1354s	
18408/26050 (epoch 35.332), train_loss = 0.91283017, grad/param norm = 2.0774e-01, time/batch = 17.9014s	
18409/26050 (epoch 35.334), train_loss = 0.77298164, grad/param norm = 2.1160e-01, time/batch = 16.0507s	
18410/26050 (epoch 35.336), train_loss = 0.78104359, grad/param norm = 1.8475e-01, time/batch = 16.9525s	
18411/26050 (epoch 35.338), train_loss = 0.72567180, grad/param norm = 1.7598e-01, time/batch = 16.8130s	
18412/26050 (epoch 35.340), train_loss = 0.89194008, grad/param norm = 2.2382e-01, time/batch = 17.9809s	
18413/26050 (epoch 35.342), train_loss = 0.92728053, grad/param norm = 2.0762e-01, time/batch = 17.9874s	
18414/26050 (epoch 35.344), train_loss = 0.77878140, grad/param norm = 2.3040e-01, time/batch = 17.0426s	
18415/26050 (epoch 35.345), train_loss = 0.81477489, grad/param norm = 2.1372e-01, time/batch = 17.3729s	
18416/26050 (epoch 35.347), train_loss = 0.93781696, grad/param norm = 2.0497e-01, time/batch = 17.9076s	
18417/26050 (epoch 35.349), train_loss = 0.87519474, grad/param norm = 2.0143e-01, time/batch = 16.9561s	
18418/26050 (epoch 35.351), train_loss = 0.87686860, grad/param norm = 2.3529e-01, time/batch = 18.0802s	
18419/26050 (epoch 35.353), train_loss = 0.87398573, grad/param norm = 2.2506e-01, time/batch = 17.4790s	
18420/26050 (epoch 35.355), train_loss = 0.84289051, grad/param norm = 2.3410e-01, time/batch = 16.3133s	
18421/26050 (epoch 35.357), train_loss = 0.80736343, grad/param norm = 1.8276e-01, time/batch = 18.4549s	
18422/26050 (epoch 35.359), train_loss = 0.94701291, grad/param norm = 2.3263e-01, time/batch = 18.2150s	
18423/26050 (epoch 35.361), train_loss = 0.75919496, grad/param norm = 1.6336e-01, time/batch = 18.4083s	
18424/26050 (epoch 35.363), train_loss = 0.92398050, grad/param norm = 2.0266e-01, time/batch = 17.0685s	
18425/26050 (epoch 35.365), train_loss = 0.82272839, grad/param norm = 1.8869e-01, time/batch = 17.7273s	
18426/26050 (epoch 35.367), train_loss = 0.91137354, grad/param norm = 2.1104e-01, time/batch = 16.7255s	
18427/26050 (epoch 35.369), train_loss = 0.75960485, grad/param norm = 1.7684e-01, time/batch = 17.2068s	
18428/26050 (epoch 35.370), train_loss = 0.74934375, grad/param norm = 1.6988e-01, time/batch = 17.9736s	
18429/26050 (epoch 35.372), train_loss = 0.83729433, grad/param norm = 1.9575e-01, time/batch = 18.6344s	
18430/26050 (epoch 35.374), train_loss = 0.98228596, grad/param norm = 2.1956e-01, time/batch = 18.4789s	
18431/26050 (epoch 35.376), train_loss = 0.96581439, grad/param norm = 2.1470e-01, time/batch = 17.7214s	
18432/26050 (epoch 35.378), train_loss = 0.79721722, grad/param norm = 1.8899e-01, time/batch = 16.3086s	
18433/26050 (epoch 35.380), train_loss = 0.94583695, grad/param norm = 2.2200e-01, time/batch = 16.8775s	
18434/26050 (epoch 35.382), train_loss = 1.04622565, grad/param norm = 2.2867e-01, time/batch = 15.2815s	
18435/26050 (epoch 35.384), train_loss = 0.79492420, grad/param norm = 2.1905e-01, time/batch = 17.9814s	
18436/26050 (epoch 35.386), train_loss = 0.90295500, grad/param norm = 2.3357e-01, time/batch = 18.5698s	
18437/26050 (epoch 35.388), train_loss = 0.86823915, grad/param norm = 2.0417e-01, time/batch = 18.7181s	
18438/26050 (epoch 35.390), train_loss = 0.79560987, grad/param norm = 2.0509e-01, time/batch = 18.2197s	
18439/26050 (epoch 35.392), train_loss = 0.75423318, grad/param norm = 1.9952e-01, time/batch = 18.2343s	
18440/26050 (epoch 35.393), train_loss = 0.91405213, grad/param norm = 2.8373e-01, time/batch = 18.5688s	
18441/26050 (epoch 35.395), train_loss = 0.90236539, grad/param norm = 2.1518e-01, time/batch = 17.4709s	
18442/26050 (epoch 35.397), train_loss = 0.91555285, grad/param norm = 2.2916e-01, time/batch = 16.9815s	
18443/26050 (epoch 35.399), train_loss = 0.82194473, grad/param norm = 2.3796e-01, time/batch = 15.5494s	
18444/26050 (epoch 35.401), train_loss = 0.87082355, grad/param norm = 2.3135e-01, time/batch = 17.3874s	
18445/26050 (epoch 35.403), train_loss = 0.87374296, grad/param norm = 2.1365e-01, time/batch = 18.1300s	
18446/26050 (epoch 35.405), train_loss = 0.87275704, grad/param norm = 2.0744e-01, time/batch = 18.6409s	
18447/26050 (epoch 35.407), train_loss = 0.97519826, grad/param norm = 2.3999e-01, time/batch = 18.8870s	
18448/26050 (epoch 35.409), train_loss = 0.96996968, grad/param norm = 2.3963e-01, time/batch = 18.1350s	
18449/26050 (epoch 35.411), train_loss = 0.95611307, grad/param norm = 2.4208e-01, time/batch = 17.8924s	
18450/26050 (epoch 35.413), train_loss = 1.01875902, grad/param norm = 2.2964e-01, time/batch = 17.0457s	
18451/26050 (epoch 35.415), train_loss = 1.00572148, grad/param norm = 2.1481e-01, time/batch = 16.2764s	
18452/26050 (epoch 35.417), train_loss = 1.03496400, grad/param norm = 2.3504e-01, time/batch = 18.5658s	
18453/26050 (epoch 35.418), train_loss = 0.93056107, grad/param norm = 2.5434e-01, time/batch = 14.4638s	
18454/26050 (epoch 35.420), train_loss = 0.75332724, grad/param norm = 1.8655e-01, time/batch = 18.2296s	
18455/26050 (epoch 35.422), train_loss = 0.72652656, grad/param norm = 1.8307e-01, time/batch = 17.9009s	
18456/26050 (epoch 35.424), train_loss = 0.95472632, grad/param norm = 2.2361e-01, time/batch = 17.0465s	
18457/26050 (epoch 35.426), train_loss = 0.92839158, grad/param norm = 2.3927e-01, time/batch = 18.2335s	
18458/26050 (epoch 35.428), train_loss = 0.83504153, grad/param norm = 1.9979e-01, time/batch = 22.5754s	
18459/26050 (epoch 35.430), train_loss = 1.01278856, grad/param norm = 2.1304e-01, time/batch = 33.2481s	
18460/26050 (epoch 35.432), train_loss = 0.82749690, grad/param norm = 1.9802e-01, time/batch = 17.9969s	
18461/26050 (epoch 35.434), train_loss = 0.81374054, grad/param norm = 2.0740e-01, time/batch = 15.1222s	
18462/26050 (epoch 35.436), train_loss = 0.95832181, grad/param norm = 2.3052e-01, time/batch = 17.9776s	
18463/26050 (epoch 35.438), train_loss = 0.88387302, grad/param norm = 2.1919e-01, time/batch = 17.6483s	
18464/26050 (epoch 35.440), train_loss = 0.88771765, grad/param norm = 1.9947e-01, time/batch = 15.7941s	
18465/26050 (epoch 35.441), train_loss = 0.89057778, grad/param norm = 2.0164e-01, time/batch = 18.3189s	
18466/26050 (epoch 35.443), train_loss = 0.74218327, grad/param norm = 1.7449e-01, time/batch = 18.3236s	
18467/26050 (epoch 35.445), train_loss = 0.77318513, grad/param norm = 1.9613e-01, time/batch = 17.4849s	
18468/26050 (epoch 35.447), train_loss = 0.97222125, grad/param norm = 2.0548e-01, time/batch = 18.0670s	
18469/26050 (epoch 35.449), train_loss = 0.78368246, grad/param norm = 2.2318e-01, time/batch = 18.5702s	
18470/26050 (epoch 35.451), train_loss = 0.99809195, grad/param norm = 2.2740e-01, time/batch = 16.9862s	
18471/26050 (epoch 35.453), train_loss = 0.79931962, grad/param norm = 1.7249e-01, time/batch = 18.7393s	
18472/26050 (epoch 35.455), train_loss = 0.85967624, grad/param norm = 1.9604e-01, time/batch = 18.2296s	
18473/26050 (epoch 35.457), train_loss = 0.84599764, grad/param norm = 2.0914e-01, time/batch = 18.4739s	
18474/26050 (epoch 35.459), train_loss = 0.95756000, grad/param norm = 2.0224e-01, time/batch = 18.1286s	
18475/26050 (epoch 35.461), train_loss = 0.97785775, grad/param norm = 2.3049e-01, time/batch = 15.9588s	
18476/26050 (epoch 35.463), train_loss = 0.81415438, grad/param norm = 1.7288e-01, time/batch = 18.3949s	
18477/26050 (epoch 35.464), train_loss = 0.89040957, grad/param norm = 2.1249e-01, time/batch = 16.7441s	
18478/26050 (epoch 35.466), train_loss = 0.87738167, grad/param norm = 2.0619e-01, time/batch = 14.7230s	
18479/26050 (epoch 35.468), train_loss = 0.97041513, grad/param norm = 1.9195e-01, time/batch = 18.4611s	
18480/26050 (epoch 35.470), train_loss = 0.95522871, grad/param norm = 2.3703e-01, time/batch = 18.2281s	
18481/26050 (epoch 35.472), train_loss = 0.96490750, grad/param norm = 2.1922e-01, time/batch = 17.9803s	
18482/26050 (epoch 35.474), train_loss = 0.96381979, grad/param norm = 2.3728e-01, time/batch = 17.9938s	
18483/26050 (epoch 35.476), train_loss = 0.92649470, grad/param norm = 1.8464e-01, time/batch = 17.9794s	
18484/26050 (epoch 35.478), train_loss = 0.83035800, grad/param norm = 1.9755e-01, time/batch = 17.7265s	
18485/26050 (epoch 35.480), train_loss = 0.84522239, grad/param norm = 1.9311e-01, time/batch = 18.2236s	
18486/26050 (epoch 35.482), train_loss = 0.82076491, grad/param norm = 2.0506e-01, time/batch = 18.3032s	
18487/26050 (epoch 35.484), train_loss = 0.82356506, grad/param norm = 2.2188e-01, time/batch = 17.6001s	
18488/26050 (epoch 35.486), train_loss = 0.98262904, grad/param norm = 2.0209e-01, time/batch = 18.4821s	
18489/26050 (epoch 35.488), train_loss = 1.00974148, grad/param norm = 2.3967e-01, time/batch = 18.2308s	
18490/26050 (epoch 35.489), train_loss = 1.04925060, grad/param norm = 2.7031e-01, time/batch = 16.5432s	
18491/26050 (epoch 35.491), train_loss = 0.80218158, grad/param norm = 2.2536e-01, time/batch = 18.4651s	
18492/26050 (epoch 35.493), train_loss = 0.87019789, grad/param norm = 2.0805e-01, time/batch = 16.8232s	
18493/26050 (epoch 35.495), train_loss = 0.86040879, grad/param norm = 1.9757e-01, time/batch = 18.9876s	
18494/26050 (epoch 35.497), train_loss = 0.77536729, grad/param norm = 2.0332e-01, time/batch = 17.1651s	
18495/26050 (epoch 35.499), train_loss = 0.79522711, grad/param norm = 1.9547e-01, time/batch = 17.5526s	
18496/26050 (epoch 35.501), train_loss = 0.96963690, grad/param norm = 2.0405e-01, time/batch = 17.5468s	
18497/26050 (epoch 35.503), train_loss = 0.82453769, grad/param norm = 2.0437e-01, time/batch = 17.8812s	
18498/26050 (epoch 35.505), train_loss = 0.95761546, grad/param norm = 2.0093e-01, time/batch = 17.7778s	
18499/26050 (epoch 35.507), train_loss = 0.93029007, grad/param norm = 2.1922e-01, time/batch = 16.6263s	
18500/26050 (epoch 35.509), train_loss = 1.00257784, grad/param norm = 2.1600e-01, time/batch = 15.1322s	
18501/26050 (epoch 35.511), train_loss = 0.84549428, grad/param norm = 1.8077e-01, time/batch = 17.5573s	
18502/26050 (epoch 35.512), train_loss = 0.76715311, grad/param norm = 2.3427e-01, time/batch = 18.4909s	
18503/26050 (epoch 35.514), train_loss = 0.90663515, grad/param norm = 2.1742e-01, time/batch = 18.7261s	
18504/26050 (epoch 35.516), train_loss = 1.00537599, grad/param norm = 2.3476e-01, time/batch = 17.2411s	
18505/26050 (epoch 35.518), train_loss = 0.84100328, grad/param norm = 2.1619e-01, time/batch = 18.8933s	
18506/26050 (epoch 35.520), train_loss = 0.87882805, grad/param norm = 2.0443e-01, time/batch = 15.6343s	
18507/26050 (epoch 35.522), train_loss = 0.69463476, grad/param norm = 2.0486e-01, time/batch = 18.4701s	
18508/26050 (epoch 35.524), train_loss = 0.96866930, grad/param norm = 2.5582e-01, time/batch = 18.1320s	
18509/26050 (epoch 35.526), train_loss = 0.96275982, grad/param norm = 2.3976e-01, time/batch = 17.8958s	
18510/26050 (epoch 35.528), train_loss = 0.91518541, grad/param norm = 2.6180e-01, time/batch = 18.6336s	
18511/26050 (epoch 35.530), train_loss = 0.83314590, grad/param norm = 2.5211e-01, time/batch = 17.3166s	
18512/26050 (epoch 35.532), train_loss = 0.89352016, grad/param norm = 1.9738e-01, time/batch = 17.8228s	
18513/26050 (epoch 35.534), train_loss = 0.87478322, grad/param norm = 2.4019e-01, time/batch = 18.4108s	
18514/26050 (epoch 35.536), train_loss = 0.91925097, grad/param norm = 2.3790e-01, time/batch = 15.3683s	
18515/26050 (epoch 35.537), train_loss = 0.93907482, grad/param norm = 2.2997e-01, time/batch = 15.2696s	
18516/26050 (epoch 35.539), train_loss = 0.88185308, grad/param norm = 2.0770e-01, time/batch = 18.2247s	
18517/26050 (epoch 35.541), train_loss = 1.03101994, grad/param norm = 2.3616e-01, time/batch = 18.0674s	
18518/26050 (epoch 35.543), train_loss = 0.69704779, grad/param norm = 1.9778e-01, time/batch = 17.7231s	
18519/26050 (epoch 35.545), train_loss = 0.87790233, grad/param norm = 2.0679e-01, time/batch = 17.5729s	
18520/26050 (epoch 35.547), train_loss = 0.82689970, grad/param norm = 1.9596e-01, time/batch = 15.3021s	
18521/26050 (epoch 35.549), train_loss = 0.74712354, grad/param norm = 1.9979e-01, time/batch = 18.3005s	
18522/26050 (epoch 35.551), train_loss = 0.94283623, grad/param norm = 2.2107e-01, time/batch = 18.0639s	
18523/26050 (epoch 35.553), train_loss = 0.83556877, grad/param norm = 2.0042e-01, time/batch = 18.1459s	
18524/26050 (epoch 35.555), train_loss = 0.77087032, grad/param norm = 2.0594e-01, time/batch = 18.5823s	
18525/26050 (epoch 35.557), train_loss = 0.89541689, grad/param norm = 2.0269e-01, time/batch = 17.9864s	
18526/26050 (epoch 35.559), train_loss = 0.88266247, grad/param norm = 1.9813e-01, time/batch = 17.4054s	
18527/26050 (epoch 35.560), train_loss = 0.84631960, grad/param norm = 2.2858e-01, time/batch = 17.4899s	
18528/26050 (epoch 35.562), train_loss = 0.85714803, grad/param norm = 2.1989e-01, time/batch = 15.9657s	
18529/26050 (epoch 35.564), train_loss = 1.02176093, grad/param norm = 2.1651e-01, time/batch = 19.1572s	
18530/26050 (epoch 35.566), train_loss = 0.81729115, grad/param norm = 1.8626e-01, time/batch = 17.5594s	
18531/26050 (epoch 35.568), train_loss = 0.90964217, grad/param norm = 2.0729e-01, time/batch = 16.2251s	
18532/26050 (epoch 35.570), train_loss = 0.88480332, grad/param norm = 2.1010e-01, time/batch = 17.5650s	
18533/26050 (epoch 35.572), train_loss = 0.88242747, grad/param norm = 2.4795e-01, time/batch = 17.6375s	
18534/26050 (epoch 35.574), train_loss = 0.88189351, grad/param norm = 2.3299e-01, time/batch = 17.6482s	
18535/26050 (epoch 35.576), train_loss = 0.91985768, grad/param norm = 2.2810e-01, time/batch = 16.7240s	
18536/26050 (epoch 35.578), train_loss = 0.85790481, grad/param norm = 2.2689e-01, time/batch = 18.1551s	
18537/26050 (epoch 35.580), train_loss = 0.81325112, grad/param norm = 2.3533e-01, time/batch = 14.3171s	
18538/26050 (epoch 35.582), train_loss = 0.89443483, grad/param norm = 2.0692e-01, time/batch = 16.0377s	
18539/26050 (epoch 35.583), train_loss = 0.94876608, grad/param norm = 2.0686e-01, time/batch = 18.1415s	
18540/26050 (epoch 35.585), train_loss = 0.76696398, grad/param norm = 2.0426e-01, time/batch = 18.7363s	
18541/26050 (epoch 35.587), train_loss = 0.91444378, grad/param norm = 2.3400e-01, time/batch = 18.7436s	
18542/26050 (epoch 35.589), train_loss = 1.01577096, grad/param norm = 2.3601e-01, time/batch = 14.8726s	
18543/26050 (epoch 35.591), train_loss = 0.87551859, grad/param norm = 2.1097e-01, time/batch = 17.8902s	
18544/26050 (epoch 35.593), train_loss = 0.76449069, grad/param norm = 1.9562e-01, time/batch = 18.6549s	
18545/26050 (epoch 35.595), train_loss = 0.92750876, grad/param norm = 2.4191e-01, time/batch = 17.2168s	
18546/26050 (epoch 35.597), train_loss = 0.88876494, grad/param norm = 2.1414e-01, time/batch = 19.0492s	
18547/26050 (epoch 35.599), train_loss = 0.94652686, grad/param norm = 2.2439e-01, time/batch = 16.6245s	
18548/26050 (epoch 35.601), train_loss = 1.03155095, grad/param norm = 2.1388e-01, time/batch = 17.7043s	
18549/26050 (epoch 35.603), train_loss = 0.93773739, grad/param norm = 2.1853e-01, time/batch = 17.5646s	
18550/26050 (epoch 35.605), train_loss = 0.87015277, grad/param norm = 2.2886e-01, time/batch = 17.8928s	
18551/26050 (epoch 35.607), train_loss = 0.96341572, grad/param norm = 2.5333e-01, time/batch = 17.8660s	
18552/26050 (epoch 35.608), train_loss = 0.79093813, grad/param norm = 1.8968e-01, time/batch = 15.7259s	
18553/26050 (epoch 35.610), train_loss = 0.89133275, grad/param norm = 2.3343e-01, time/batch = 17.9830s	
18554/26050 (epoch 35.612), train_loss = 0.86344621, grad/param norm = 2.1272e-01, time/batch = 15.1303s	
18555/26050 (epoch 35.614), train_loss = 0.88055791, grad/param norm = 2.1295e-01, time/batch = 16.8882s	
18556/26050 (epoch 35.616), train_loss = 0.93637063, grad/param norm = 2.2160e-01, time/batch = 18.0636s	
18557/26050 (epoch 35.618), train_loss = 0.85160480, grad/param norm = 2.1121e-01, time/batch = 17.7246s	
18558/26050 (epoch 35.620), train_loss = 0.95551529, grad/param norm = 2.4466e-01, time/batch = 18.6523s	
18559/26050 (epoch 35.622), train_loss = 0.79740368, grad/param norm = 2.0373e-01, time/batch = 16.3172s	
18560/26050 (epoch 35.624), train_loss = 0.74081837, grad/param norm = 2.0298e-01, time/batch = 17.9028s	
18561/26050 (epoch 35.626), train_loss = 0.90967347, grad/param norm = 1.9983e-01, time/batch = 18.5806s	
18562/26050 (epoch 35.628), train_loss = 0.83516467, grad/param norm = 2.3875e-01, time/batch = 18.0635s	
18563/26050 (epoch 35.630), train_loss = 1.01020240, grad/param norm = 2.2173e-01, time/batch = 18.3099s	
18564/26050 (epoch 35.631), train_loss = 1.03714064, grad/param norm = 2.3164e-01, time/batch = 15.4567s	
18565/26050 (epoch 35.633), train_loss = 0.80751970, grad/param norm = 2.1808e-01, time/batch = 17.0533s	
18566/26050 (epoch 35.635), train_loss = 0.81929454, grad/param norm = 1.6334e-01, time/batch = 18.1468s	
18567/26050 (epoch 35.637), train_loss = 0.76879056, grad/param norm = 2.1686e-01, time/batch = 16.0522s	
18568/26050 (epoch 35.639), train_loss = 0.89917008, grad/param norm = 2.0356e-01, time/batch = 17.8114s	
18569/26050 (epoch 35.641), train_loss = 0.82365956, grad/param norm = 2.0885e-01, time/batch = 16.7991s	
18570/26050 (epoch 35.643), train_loss = 0.79894984, grad/param norm = 1.7058e-01, time/batch = 17.8011s	
18571/26050 (epoch 35.645), train_loss = 0.82056281, grad/param norm = 2.0706e-01, time/batch = 18.3227s	
18572/26050 (epoch 35.647), train_loss = 0.79173963, grad/param norm = 2.4797e-01, time/batch = 18.0643s	
18573/26050 (epoch 35.649), train_loss = 0.84734160, grad/param norm = 2.2710e-01, time/batch = 17.1301s	
18574/26050 (epoch 35.651), train_loss = 0.82749737, grad/param norm = 2.3450e-01, time/batch = 17.8009s	
18575/26050 (epoch 35.653), train_loss = 0.86967328, grad/param norm = 2.2066e-01, time/batch = 18.3925s	
18576/26050 (epoch 35.655), train_loss = 0.78230525, grad/param norm = 1.9622e-01, time/batch = 15.6185s	
18577/26050 (epoch 35.656), train_loss = 0.76422636, grad/param norm = 1.8540e-01, time/batch = 17.4032s	
18578/26050 (epoch 35.658), train_loss = 1.06390736, grad/param norm = 2.2501e-01, time/batch = 17.8832s	
18579/26050 (epoch 35.660), train_loss = 0.75604182, grad/param norm = 2.1122e-01, time/batch = 14.8758s	
18580/26050 (epoch 35.662), train_loss = 0.85909546, grad/param norm = 1.9213e-01, time/batch = 17.1172s	
18581/26050 (epoch 35.664), train_loss = 0.86100487, grad/param norm = 2.0962e-01, time/batch = 18.6528s	
18582/26050 (epoch 35.666), train_loss = 0.82466736, grad/param norm = 2.1196e-01, time/batch = 15.8822s	
18583/26050 (epoch 35.668), train_loss = 0.67285212, grad/param norm = 2.1342e-01, time/batch = 16.9743s	
18584/26050 (epoch 35.670), train_loss = 1.00924346, grad/param norm = 2.8045e-01, time/batch = 18.7450s	
18585/26050 (epoch 35.672), train_loss = 0.86083671, grad/param norm = 2.0290e-01, time/batch = 17.3193s	
18586/26050 (epoch 35.674), train_loss = 0.76995305, grad/param norm = 2.0056e-01, time/batch = 18.0587s	
18587/26050 (epoch 35.676), train_loss = 0.91924513, grad/param norm = 2.2168e-01, time/batch = 18.0651s	
18588/26050 (epoch 35.678), train_loss = 0.95384159, grad/param norm = 2.1957e-01, time/batch = 17.3131s	
18589/26050 (epoch 35.679), train_loss = 0.99871716, grad/param norm = 2.2821e-01, time/batch = 18.1371s	
18590/26050 (epoch 35.681), train_loss = 0.89152649, grad/param norm = 2.2417e-01, time/batch = 17.2413s	
18591/26050 (epoch 35.683), train_loss = 0.79263109, grad/param norm = 2.5873e-01, time/batch = 16.9111s	
18592/26050 (epoch 35.685), train_loss = 0.83855607, grad/param norm = 2.0041e-01, time/batch = 16.4610s	
18593/26050 (epoch 35.687), train_loss = 0.76157203, grad/param norm = 2.1411e-01, time/batch = 17.8167s	
18594/26050 (epoch 35.689), train_loss = 0.81843370, grad/param norm = 2.1672e-01, time/batch = 17.8943s	
18595/26050 (epoch 35.691), train_loss = 0.70796155, grad/param norm = 1.7637e-01, time/batch = 16.4889s	
18596/26050 (epoch 35.693), train_loss = 0.81207082, grad/param norm = 1.9619e-01, time/batch = 18.1243s	
18597/26050 (epoch 35.695), train_loss = 0.85686879, grad/param norm = 2.0802e-01, time/batch = 17.8954s	
18598/26050 (epoch 35.697), train_loss = 0.81026056, grad/param norm = 1.9582e-01, time/batch = 17.9947s	
18599/26050 (epoch 35.699), train_loss = 0.89995305, grad/param norm = 2.1446e-01, time/batch = 18.6389s	
18600/26050 (epoch 35.701), train_loss = 0.78190125, grad/param norm = 1.7811e-01, time/batch = 17.3150s	
18601/26050 (epoch 35.702), train_loss = 0.93615726, grad/param norm = 2.1871e-01, time/batch = 17.2153s	
18602/26050 (epoch 35.704), train_loss = 0.95377858, grad/param norm = 1.9338e-01, time/batch = 17.9074s	
18603/26050 (epoch 35.706), train_loss = 0.79626572, grad/param norm = 1.9907e-01, time/batch = 16.4509s	
18604/26050 (epoch 35.708), train_loss = 0.90915686, grad/param norm = 2.2059e-01, time/batch = 18.3146s	
18605/26050 (epoch 35.710), train_loss = 0.87841875, grad/param norm = 2.0352e-01, time/batch = 18.1434s	
18606/26050 (epoch 35.712), train_loss = 0.86205029, grad/param norm = 2.1359e-01, time/batch = 17.8156s	
18607/26050 (epoch 35.714), train_loss = 0.76899946, grad/param norm = 1.8981e-01, time/batch = 18.1395s	
18608/26050 (epoch 35.716), train_loss = 1.06794845, grad/param norm = 2.3761e-01, time/batch = 18.3173s	
18609/26050 (epoch 35.718), train_loss = 0.89653409, grad/param norm = 2.0398e-01, time/batch = 18.5666s	
18610/26050 (epoch 35.720), train_loss = 0.84458576, grad/param norm = 1.9642e-01, time/batch = 17.3913s	
18611/26050 (epoch 35.722), train_loss = 0.78055574, grad/param norm = 1.8996e-01, time/batch = 17.6465s	
18612/26050 (epoch 35.724), train_loss = 0.80535749, grad/param norm = 2.1676e-01, time/batch = 15.9441s	
18613/26050 (epoch 35.726), train_loss = 0.92905980, grad/param norm = 2.1002e-01, time/batch = 14.8107s	
18614/26050 (epoch 35.727), train_loss = 0.90098837, grad/param norm = 2.1023e-01, time/batch = 16.1282s	
18615/26050 (epoch 35.729), train_loss = 0.89522861, grad/param norm = 1.9683e-01, time/batch = 18.5492s	
18616/26050 (epoch 35.731), train_loss = 0.91901769, grad/param norm = 2.2586e-01, time/batch = 18.0605s	
18617/26050 (epoch 35.733), train_loss = 0.82827943, grad/param norm = 2.1410e-01, time/batch = 17.0685s	
18618/26050 (epoch 35.735), train_loss = 1.00764256, grad/param norm = 2.2407e-01, time/batch = 18.3922s	
18619/26050 (epoch 35.737), train_loss = 0.82542113, grad/param norm = 2.2173e-01, time/batch = 17.3840s	
18620/26050 (epoch 35.739), train_loss = 0.88537317, grad/param norm = 1.9886e-01, time/batch = 17.8961s	
18621/26050 (epoch 35.741), train_loss = 0.78597709, grad/param norm = 1.8935e-01, time/batch = 18.1546s	
18622/26050 (epoch 35.743), train_loss = 0.84848265, grad/param norm = 2.3959e-01, time/batch = 18.4793s	
18623/26050 (epoch 35.745), train_loss = 0.75563948, grad/param norm = 2.0339e-01, time/batch = 15.8174s	
18624/26050 (epoch 35.747), train_loss = 0.79258599, grad/param norm = 2.1262e-01, time/batch = 17.7064s	
18625/26050 (epoch 35.749), train_loss = 0.96907750, grad/param norm = 2.2496e-01, time/batch = 17.9598s	
18626/26050 (epoch 35.750), train_loss = 0.84103824, grad/param norm = 1.9398e-01, time/batch = 18.3130s	
18627/26050 (epoch 35.752), train_loss = 0.80465216, grad/param norm = 2.3202e-01, time/batch = 18.0567s	
18628/26050 (epoch 35.754), train_loss = 0.88355623, grad/param norm = 2.1737e-01, time/batch = 18.0221s	
18629/26050 (epoch 35.756), train_loss = 0.82575003, grad/param norm = 2.1970e-01, time/batch = 18.1192s	
18630/26050 (epoch 35.758), train_loss = 0.84696103, grad/param norm = 2.2094e-01, time/batch = 17.8859s	
18631/26050 (epoch 35.760), train_loss = 0.97177772, grad/param norm = 2.3594e-01, time/batch = 18.4739s	
18632/26050 (epoch 35.762), train_loss = 0.82718701, grad/param norm = 2.0081e-01, time/batch = 17.5358s	
18633/26050 (epoch 35.764), train_loss = 0.83670713, grad/param norm = 2.3096e-01, time/batch = 16.8954s	
18634/26050 (epoch 35.766), train_loss = 0.87365544, grad/param norm = 2.5367e-01, time/batch = 17.6249s	
18635/26050 (epoch 35.768), train_loss = 0.73944667, grad/param norm = 1.8438e-01, time/batch = 17.6593s	
18636/26050 (epoch 35.770), train_loss = 0.84048508, grad/param norm = 2.1558e-01, time/batch = 15.3083s	
18637/26050 (epoch 35.772), train_loss = 0.86276817, grad/param norm = 2.0309e-01, time/batch = 18.0640s	
18638/26050 (epoch 35.774), train_loss = 0.74282448, grad/param norm = 2.2220e-01, time/batch = 17.9757s	
18639/26050 (epoch 35.775), train_loss = 0.64709935, grad/param norm = 1.9933e-01, time/batch = 17.6365s	
18640/26050 (epoch 35.777), train_loss = 0.83122831, grad/param norm = 2.1020e-01, time/batch = 17.9878s	
18641/26050 (epoch 35.779), train_loss = 0.84497431, grad/param norm = 2.4281e-01, time/batch = 15.4607s	
18642/26050 (epoch 35.781), train_loss = 0.76710001, grad/param norm = 2.1646e-01, time/batch = 17.5512s	
18643/26050 (epoch 35.783), train_loss = 0.76197427, grad/param norm = 2.2642e-01, time/batch = 17.3944s	
18644/26050 (epoch 35.785), train_loss = 0.86547832, grad/param norm = 2.2808e-01, time/batch = 15.6179s	
18645/26050 (epoch 35.787), train_loss = 0.76977824, grad/param norm = 2.2963e-01, time/batch = 17.5691s	
18646/26050 (epoch 35.789), train_loss = 0.76494886, grad/param norm = 2.2085e-01, time/batch = 17.7880s	
18647/26050 (epoch 35.791), train_loss = 0.79501896, grad/param norm = 2.3725e-01, time/batch = 18.3898s	
18648/26050 (epoch 35.793), train_loss = 0.84498083, grad/param norm = 2.3205e-01, time/batch = 17.8816s	
18649/26050 (epoch 35.795), train_loss = 0.70134998, grad/param norm = 1.7809e-01, time/batch = 18.3303s	
18650/26050 (epoch 35.797), train_loss = 0.75819582, grad/param norm = 2.1728e-01, time/batch = 18.9749s	
18651/26050 (epoch 35.798), train_loss = 0.78036471, grad/param norm = 2.2088e-01, time/batch = 14.5376s	
18652/26050 (epoch 35.800), train_loss = 0.73121507, grad/param norm = 2.0386e-01, time/batch = 14.5201s	
18653/26050 (epoch 35.802), train_loss = 0.80987924, grad/param norm = 2.0636e-01, time/batch = 15.3871s	
18654/26050 (epoch 35.804), train_loss = 0.83838214, grad/param norm = 2.1244e-01, time/batch = 14.4501s	
18655/26050 (epoch 35.806), train_loss = 0.91925589, grad/param norm = 2.3932e-01, time/batch = 15.0382s	
18656/26050 (epoch 35.808), train_loss = 0.86580071, grad/param norm = 2.5483e-01, time/batch = 15.9745s	
18657/26050 (epoch 35.810), train_loss = 0.82500752, grad/param norm = 2.2066e-01, time/batch = 18.6528s	
18658/26050 (epoch 35.812), train_loss = 0.72028912, grad/param norm = 1.9190e-01, time/batch = 17.4050s	
18659/26050 (epoch 35.814), train_loss = 0.76743274, grad/param norm = 2.5926e-01, time/batch = 18.1387s	
18660/26050 (epoch 35.816), train_loss = 0.90087678, grad/param norm = 2.3781e-01, time/batch = 18.8825s	
18661/26050 (epoch 35.818), train_loss = 0.91200393, grad/param norm = 2.0613e-01, time/batch = 18.4878s	
18662/26050 (epoch 35.820), train_loss = 0.85492097, grad/param norm = 2.0526e-01, time/batch = 29.0644s	
18663/26050 (epoch 35.821), train_loss = 0.96441195, grad/param norm = 2.5729e-01, time/batch = 27.1160s	
18664/26050 (epoch 35.823), train_loss = 1.06321361, grad/param norm = 2.3601e-01, time/batch = 17.2537s	
18665/26050 (epoch 35.825), train_loss = 0.86022926, grad/param norm = 2.3146e-01, time/batch = 14.4752s	
18666/26050 (epoch 35.827), train_loss = 0.85324066, grad/param norm = 2.4502e-01, time/batch = 18.4050s	
18667/26050 (epoch 35.829), train_loss = 0.95357010, grad/param norm = 2.3811e-01, time/batch = 17.9872s	
18668/26050 (epoch 35.831), train_loss = 0.99841235, grad/param norm = 2.5173e-01, time/batch = 16.1399s	
18669/26050 (epoch 35.833), train_loss = 0.97184726, grad/param norm = 2.4144e-01, time/batch = 17.4051s	
18670/26050 (epoch 35.835), train_loss = 0.99235782, grad/param norm = 2.3479e-01, time/batch = 17.1346s	
18671/26050 (epoch 35.837), train_loss = 0.86394711, grad/param norm = 1.9362e-01, time/batch = 17.4137s	
18672/26050 (epoch 35.839), train_loss = 0.84616993, grad/param norm = 2.3115e-01, time/batch = 18.6692s	
18673/26050 (epoch 35.841), train_loss = 0.95527930, grad/param norm = 2.1365e-01, time/batch = 18.3365s	
18674/26050 (epoch 35.843), train_loss = 0.85773300, grad/param norm = 1.9371e-01, time/batch = 16.9777s	
18675/26050 (epoch 35.845), train_loss = 0.79793819, grad/param norm = 1.8453e-01, time/batch = 18.4813s	
18676/26050 (epoch 35.846), train_loss = 0.89232320, grad/param norm = 2.1223e-01, time/batch = 15.2887s	
18677/26050 (epoch 35.848), train_loss = 0.82864004, grad/param norm = 1.9409e-01, time/batch = 15.0499s	
18678/26050 (epoch 35.850), train_loss = 0.78399176, grad/param norm = 2.0363e-01, time/batch = 17.8918s	
18679/26050 (epoch 35.852), train_loss = 0.88120857, grad/param norm = 2.0601e-01, time/batch = 17.4850s	
18680/26050 (epoch 35.854), train_loss = 0.86043940, grad/param norm = 2.2285e-01, time/batch = 17.9072s	
18681/26050 (epoch 35.856), train_loss = 0.81132845, grad/param norm = 2.3518e-01, time/batch = 17.3898s	
18682/26050 (epoch 35.858), train_loss = 0.77733589, grad/param norm = 1.9713e-01, time/batch = 18.3938s	
18683/26050 (epoch 35.860), train_loss = 0.88943697, grad/param norm = 2.2454e-01, time/batch = 16.3052s	
18684/26050 (epoch 35.862), train_loss = 0.93021466, grad/param norm = 2.0689e-01, time/batch = 18.1524s	
18685/26050 (epoch 35.864), train_loss = 0.87578964, grad/param norm = 2.3473e-01, time/batch = 18.2149s	
18686/26050 (epoch 35.866), train_loss = 0.81627224, grad/param norm = 1.8047e-01, time/batch = 18.3966s	
18687/26050 (epoch 35.868), train_loss = 0.91783434, grad/param norm = 2.3339e-01, time/batch = 17.1619s	
18688/26050 (epoch 35.869), train_loss = 0.77207098, grad/param norm = 1.8295e-01, time/batch = 16.9531s	
18689/26050 (epoch 35.871), train_loss = 0.75100453, grad/param norm = 1.9898e-01, time/batch = 18.3177s	
18690/26050 (epoch 35.873), train_loss = 0.90954798, grad/param norm = 2.3102e-01, time/batch = 18.9002s	
18691/26050 (epoch 35.875), train_loss = 0.82073081, grad/param norm = 2.1895e-01, time/batch = 17.3790s	
18692/26050 (epoch 35.877), train_loss = 0.80330466, grad/param norm = 1.8859e-01, time/batch = 16.9781s	
18693/26050 (epoch 35.879), train_loss = 0.90283505, grad/param norm = 2.0230e-01, time/batch = 18.2974s	
18694/26050 (epoch 35.881), train_loss = 0.94031276, grad/param norm = 2.2389e-01, time/batch = 14.4745s	
18695/26050 (epoch 35.883), train_loss = 0.88727616, grad/param norm = 2.0927e-01, time/batch = 16.8927s	
18696/26050 (epoch 35.885), train_loss = 0.66355946, grad/param norm = 1.8840e-01, time/batch = 17.8240s	
18697/26050 (epoch 35.887), train_loss = 0.93038144, grad/param norm = 2.2090e-01, time/batch = 18.7362s	
18698/26050 (epoch 35.889), train_loss = 0.78541576, grad/param norm = 2.0266e-01, time/batch = 16.8865s	
18699/26050 (epoch 35.891), train_loss = 0.71762472, grad/param norm = 1.8789e-01, time/batch = 17.8013s	
18700/26050 (epoch 35.893), train_loss = 0.73879643, grad/param norm = 2.3450e-01, time/batch = 16.9730s	
18701/26050 (epoch 35.894), train_loss = 0.80396244, grad/param norm = 1.9974e-01, time/batch = 18.4879s	
18702/26050 (epoch 35.896), train_loss = 0.93650456, grad/param norm = 2.5940e-01, time/batch = 18.2328s	
18703/26050 (epoch 35.898), train_loss = 0.80656972, grad/param norm = 2.2184e-01, time/batch = 17.9819s	
18704/26050 (epoch 35.900), train_loss = 0.87416098, grad/param norm = 2.3741e-01, time/batch = 18.3155s	
18705/26050 (epoch 35.902), train_loss = 0.83674048, grad/param norm = 2.5659e-01, time/batch = 17.0675s	
18706/26050 (epoch 35.904), train_loss = 0.82514041, grad/param norm = 2.0947e-01, time/batch = 16.8872s	
18707/26050 (epoch 35.906), train_loss = 0.82470407, grad/param norm = 2.4219e-01, time/batch = 16.1206s	
18708/26050 (epoch 35.908), train_loss = 0.86946644, grad/param norm = 2.2256e-01, time/batch = 17.5586s	
18709/26050 (epoch 35.910), train_loss = 0.80834976, grad/param norm = 2.1253e-01, time/batch = 18.2274s	
18710/26050 (epoch 35.912), train_loss = 1.03773383, grad/param norm = 2.5099e-01, time/batch = 14.3832s	
18711/26050 (epoch 35.914), train_loss = 1.16653451, grad/param norm = 2.4269e-01, time/batch = 18.4000s	
18712/26050 (epoch 35.916), train_loss = 0.92378062, grad/param norm = 2.3920e-01, time/batch = 17.1342s	
18713/26050 (epoch 35.917), train_loss = 0.88866470, grad/param norm = 2.0489e-01, time/batch = 16.3017s	
18714/26050 (epoch 35.919), train_loss = 0.89851763, grad/param norm = 2.5350e-01, time/batch = 18.3994s	
18715/26050 (epoch 35.921), train_loss = 0.81600881, grad/param norm = 2.2723e-01, time/batch = 17.5660s	
18716/26050 (epoch 35.923), train_loss = 0.87438199, grad/param norm = 2.1275e-01, time/batch = 18.5800s	
18717/26050 (epoch 35.925), train_loss = 0.84693918, grad/param norm = 2.1915e-01, time/batch = 18.0651s	
18718/26050 (epoch 35.927), train_loss = 0.78754982, grad/param norm = 1.8156e-01, time/batch = 18.7324s	
18719/26050 (epoch 35.929), train_loss = 0.72949431, grad/param norm = 1.8958e-01, time/batch = 18.8834s	
18720/26050 (epoch 35.931), train_loss = 1.01938544, grad/param norm = 2.4094e-01, time/batch = 16.0485s	
18721/26050 (epoch 35.933), train_loss = 0.84382220, grad/param norm = 1.9158e-01, time/batch = 17.4715s	
18722/26050 (epoch 35.935), train_loss = 0.81464952, grad/param norm = 1.9503e-01, time/batch = 17.4082s	
18723/26050 (epoch 35.937), train_loss = 0.91570673, grad/param norm = 2.0939e-01, time/batch = 17.6427s	
18724/26050 (epoch 35.939), train_loss = 0.78131308, grad/param norm = 1.8455e-01, time/batch = 18.7337s	
18725/26050 (epoch 35.940), train_loss = 0.83389590, grad/param norm = 1.9682e-01, time/batch = 17.2295s	
18726/26050 (epoch 35.942), train_loss = 0.83248721, grad/param norm = 2.0468e-01, time/batch = 17.0495s	
18727/26050 (epoch 35.944), train_loss = 0.83989929, grad/param norm = 3.1640e-01, time/batch = 16.0283s	
18728/26050 (epoch 35.946), train_loss = 0.99550372, grad/param norm = 2.2605e-01, time/batch = 17.9078s	
18729/26050 (epoch 35.948), train_loss = 0.73174883, grad/param norm = 1.9582e-01, time/batch = 16.8875s	
18730/26050 (epoch 35.950), train_loss = 0.86444611, grad/param norm = 2.2508e-01, time/batch = 17.8007s	
18731/26050 (epoch 35.952), train_loss = 0.91470044, grad/param norm = 2.0785e-01, time/batch = 18.7321s	
18732/26050 (epoch 35.954), train_loss = 0.92070090, grad/param norm = 2.1752e-01, time/batch = 18.2320s	
18733/26050 (epoch 35.956), train_loss = 0.82328703, grad/param norm = 2.0703e-01, time/batch = 15.7097s	
18734/26050 (epoch 35.958), train_loss = 0.77818681, grad/param norm = 2.0131e-01, time/batch = 18.8208s	
18735/26050 (epoch 35.960), train_loss = 0.88908676, grad/param norm = 2.2574e-01, time/batch = 16.6528s	
18736/26050 (epoch 35.962), train_loss = 0.83782150, grad/param norm = 1.8644e-01, time/batch = 14.3663s	
18737/26050 (epoch 35.964), train_loss = 0.84926986, grad/param norm = 2.0793e-01, time/batch = 17.7663s	
18738/26050 (epoch 35.965), train_loss = 0.80025487, grad/param norm = 2.9888e-01, time/batch = 17.7428s	
18739/26050 (epoch 35.967), train_loss = 1.14326494, grad/param norm = 2.4895e-01, time/batch = 16.2465s	
18740/26050 (epoch 35.969), train_loss = 0.85544241, grad/param norm = 1.9917e-01, time/batch = 18.3268s	
18741/26050 (epoch 35.971), train_loss = 0.85137186, grad/param norm = 1.8862e-01, time/batch = 17.5655s	
18742/26050 (epoch 35.973), train_loss = 0.85799981, grad/param norm = 1.9431e-01, time/batch = 18.5583s	
18743/26050 (epoch 35.975), train_loss = 0.87225497, grad/param norm = 1.8536e-01, time/batch = 15.7166s	
18744/26050 (epoch 35.977), train_loss = 0.85456859, grad/param norm = 1.9371e-01, time/batch = 18.0663s	
18745/26050 (epoch 35.979), train_loss = 0.70236239, grad/param norm = 1.9119e-01, time/batch = 18.0572s	
18746/26050 (epoch 35.981), train_loss = 0.96878440, grad/param norm = 2.0663e-01, time/batch = 17.4841s	
18747/26050 (epoch 35.983), train_loss = 0.90256909, grad/param norm = 2.0147e-01, time/batch = 17.5556s	
18748/26050 (epoch 35.985), train_loss = 0.91368058, grad/param norm = 2.6697e-01, time/batch = 17.9788s	
18749/26050 (epoch 35.987), train_loss = 0.96095298, grad/param norm = 2.1285e-01, time/batch = 15.4777s	
18750/26050 (epoch 35.988), train_loss = 0.90086242, grad/param norm = 2.4561e-01, time/batch = 17.2118s	
18751/26050 (epoch 35.990), train_loss = 0.75336678, grad/param norm = 1.8678e-01, time/batch = 18.3226s	
18752/26050 (epoch 35.992), train_loss = 0.99475676, grad/param norm = 2.2329e-01, time/batch = 15.1514s	
18753/26050 (epoch 35.994), train_loss = 0.81353086, grad/param norm = 2.4154e-01, time/batch = 17.4067s	
18754/26050 (epoch 35.996), train_loss = 0.75297099, grad/param norm = 2.0932e-01, time/batch = 16.7178s	
18755/26050 (epoch 35.998), train_loss = 0.87265175, grad/param norm = 1.9955e-01, time/batch = 17.8961s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
18756/26050 (epoch 36.000), train_loss = 0.80119295, grad/param norm = 1.9830e-01, time/batch = 17.8084s	
18757/26050 (epoch 36.002), train_loss = 0.90732361, grad/param norm = 2.2236e-01, time/batch = 17.2302s	
18758/26050 (epoch 36.004), train_loss = 0.77822260, grad/param norm = 2.0605e-01, time/batch = 18.3209s	
18759/26050 (epoch 36.006), train_loss = 0.81484776, grad/param norm = 2.6270e-01, time/batch = 15.8901s	
18760/26050 (epoch 36.008), train_loss = 0.79811997, grad/param norm = 2.1593e-01, time/batch = 17.5690s	
18761/26050 (epoch 36.010), train_loss = 0.77966432, grad/param norm = 2.1378e-01, time/batch = 18.0825s	
18762/26050 (epoch 36.012), train_loss = 0.84357783, grad/param norm = 2.0428e-01, time/batch = 17.7241s	
18763/26050 (epoch 36.013), train_loss = 1.09085244, grad/param norm = 2.6196e-01, time/batch = 16.7968s	
18764/26050 (epoch 36.015), train_loss = 0.85857523, grad/param norm = 1.9682e-01, time/batch = 18.0548s	
18765/26050 (epoch 36.017), train_loss = 0.88990656, grad/param norm = 2.0345e-01, time/batch = 18.2157s	
18766/26050 (epoch 36.019), train_loss = 0.73512119, grad/param norm = 1.4693e-01, time/batch = 17.9803s	
18767/26050 (epoch 36.021), train_loss = 0.94293135, grad/param norm = 2.1407e-01, time/batch = 18.3885s	
18768/26050 (epoch 36.023), train_loss = 0.72800455, grad/param norm = 2.0791e-01, time/batch = 16.3229s	
18769/26050 (epoch 36.025), train_loss = 0.83924662, grad/param norm = 2.1791e-01, time/batch = 18.2992s	
18770/26050 (epoch 36.027), train_loss = 0.69242928, grad/param norm = 1.9315e-01, time/batch = 17.4706s	
18771/26050 (epoch 36.029), train_loss = 0.88953317, grad/param norm = 1.9597e-01, time/batch = 15.2279s	
18772/26050 (epoch 36.031), train_loss = 0.98388014, grad/param norm = 2.4077e-01, time/batch = 17.7203s	
18773/26050 (epoch 36.033), train_loss = 0.85829827, grad/param norm = 2.0272e-01, time/batch = 17.1181s	
18774/26050 (epoch 36.035), train_loss = 0.89884662, grad/param norm = 2.0524e-01, time/batch = 17.7223s	
18775/26050 (epoch 36.036), train_loss = 0.75757566, grad/param norm = 2.3786e-01, time/batch = 18.7313s	
18776/26050 (epoch 36.038), train_loss = 0.69263029, grad/param norm = 1.8282e-01, time/batch = 18.3215s	
18777/26050 (epoch 36.040), train_loss = 0.84312815, grad/param norm = 2.1956e-01, time/batch = 16.7053s	
18778/26050 (epoch 36.042), train_loss = 0.72821867, grad/param norm = 2.1666e-01, time/batch = 18.3978s	
18779/26050 (epoch 36.044), train_loss = 0.92057772, grad/param norm = 1.8971e-01, time/batch = 18.3995s	
18780/26050 (epoch 36.046), train_loss = 0.71918640, grad/param norm = 1.6975e-01, time/batch = 16.9679s	
18781/26050 (epoch 36.048), train_loss = 0.85011959, grad/param norm = 1.9420e-01, time/batch = 17.7871s	
18782/26050 (epoch 36.050), train_loss = 0.79573330, grad/param norm = 2.0400e-01, time/batch = 17.7055s	
18783/26050 (epoch 36.052), train_loss = 0.78897453, grad/param norm = 2.5001e-01, time/batch = 18.0432s	
18784/26050 (epoch 36.054), train_loss = 0.70723951, grad/param norm = 1.8963e-01, time/batch = 18.2311s	
18785/26050 (epoch 36.056), train_loss = 0.68656131, grad/param norm = 1.6732e-01, time/batch = 17.9063s	
18786/26050 (epoch 36.058), train_loss = 0.82236064, grad/param norm = 1.9715e-01, time/batch = 18.7388s	
18787/26050 (epoch 36.060), train_loss = 0.88107562, grad/param norm = 1.9779e-01, time/batch = 17.8161s	
18788/26050 (epoch 36.061), train_loss = 0.74068089, grad/param norm = 1.9347e-01, time/batch = 18.3896s	
18789/26050 (epoch 36.063), train_loss = 0.83216983, grad/param norm = 1.9687e-01, time/batch = 16.7186s	
18790/26050 (epoch 36.065), train_loss = 0.68475675, grad/param norm = 1.6897e-01, time/batch = 17.3835s	
18791/26050 (epoch 36.067), train_loss = 0.83581035, grad/param norm = 2.0786e-01, time/batch = 18.1534s	
18792/26050 (epoch 36.069), train_loss = 0.87662637, grad/param norm = 2.0423e-01, time/batch = 17.1499s	
18793/26050 (epoch 36.071), train_loss = 0.87253579, grad/param norm = 2.2997e-01, time/batch = 18.8220s	
18794/26050 (epoch 36.073), train_loss = 0.98642938, grad/param norm = 2.1026e-01, time/batch = 15.6426s	
18795/26050 (epoch 36.075), train_loss = 0.81188851, grad/param norm = 2.0317e-01, time/batch = 18.2312s	
18796/26050 (epoch 36.077), train_loss = 0.78256282, grad/param norm = 1.9669e-01, time/batch = 15.6413s	
18797/26050 (epoch 36.079), train_loss = 0.82450084, grad/param norm = 2.3053e-01, time/batch = 16.4596s	
18798/26050 (epoch 36.081), train_loss = 0.81245196, grad/param norm = 2.0295e-01, time/batch = 18.4784s	
18799/26050 (epoch 36.083), train_loss = 0.93187200, grad/param norm = 2.0262e-01, time/batch = 18.0532s	
18800/26050 (epoch 36.084), train_loss = 0.85033045, grad/param norm = 2.7159e-01, time/batch = 17.9799s	
18801/26050 (epoch 36.086), train_loss = 0.97935757, grad/param norm = 2.3430e-01, time/batch = 18.0631s	
18802/26050 (epoch 36.088), train_loss = 0.82520799, grad/param norm = 2.0641e-01, time/batch = 15.1418s	
18803/26050 (epoch 36.090), train_loss = 0.87280145, grad/param norm = 2.1508e-01, time/batch = 16.4639s	
18804/26050 (epoch 36.092), train_loss = 0.90241930, grad/param norm = 2.2415e-01, time/batch = 15.9838s	
18805/26050 (epoch 36.094), train_loss = 0.74109953, grad/param norm = 2.1692e-01, time/batch = 18.8851s	
18806/26050 (epoch 36.096), train_loss = 0.87115728, grad/param norm = 2.0330e-01, time/batch = 18.1385s	
18807/26050 (epoch 36.098), train_loss = 0.84561073, grad/param norm = 2.0850e-01, time/batch = 16.5515s	
18808/26050 (epoch 36.100), train_loss = 0.77591320, grad/param norm = 2.0584e-01, time/batch = 17.7969s	
18809/26050 (epoch 36.102), train_loss = 0.85810139, grad/param norm = 2.0868e-01, time/batch = 18.0794s	
18810/26050 (epoch 36.104), train_loss = 0.81076040, grad/param norm = 2.1584e-01, time/batch = 18.7372s	
18811/26050 (epoch 36.106), train_loss = 0.90258252, grad/param norm = 2.3223e-01, time/batch = 16.9720s	
18812/26050 (epoch 36.107), train_loss = 0.70536368, grad/param norm = 1.8592e-01, time/batch = 18.6319s	
18813/26050 (epoch 36.109), train_loss = 0.77618971, grad/param norm = 1.7995e-01, time/batch = 18.6533s	
18814/26050 (epoch 36.111), train_loss = 0.96248094, grad/param norm = 2.2654e-01, time/batch = 17.8937s	
18815/26050 (epoch 36.113), train_loss = 0.81162785, grad/param norm = 1.9229e-01, time/batch = 14.8878s	
18816/26050 (epoch 36.115), train_loss = 0.94538223, grad/param norm = 2.0663e-01, time/batch = 18.3156s	
18817/26050 (epoch 36.117), train_loss = 0.85140579, grad/param norm = 2.0813e-01, time/batch = 17.5593s	
18818/26050 (epoch 36.119), train_loss = 0.73837414, grad/param norm = 1.9656e-01, time/batch = 15.2906s	
18819/26050 (epoch 36.121), train_loss = 0.85133309, grad/param norm = 2.0899e-01, time/batch = 17.5591s	
18820/26050 (epoch 36.123), train_loss = 0.76743079, grad/param norm = 1.8937e-01, time/batch = 18.4649s	
18821/26050 (epoch 36.125), train_loss = 0.71318585, grad/param norm = 1.8091e-01, time/batch = 17.7383s	
18822/26050 (epoch 36.127), train_loss = 0.70916647, grad/param norm = 2.0481e-01, time/batch = 17.8085s	
18823/26050 (epoch 36.129), train_loss = 0.66657204, grad/param norm = 1.9733e-01, time/batch = 15.3091s	
18824/26050 (epoch 36.131), train_loss = 0.83508683, grad/param norm = 2.3532e-01, time/batch = 17.9028s	
18825/26050 (epoch 36.132), train_loss = 0.83567508, grad/param norm = 2.0517e-01, time/batch = 16.4676s	
18826/26050 (epoch 36.134), train_loss = 0.87177869, grad/param norm = 2.1872e-01, time/batch = 18.8169s	
18827/26050 (epoch 36.136), train_loss = 0.80547031, grad/param norm = 1.8787e-01, time/batch = 18.3200s	
18828/26050 (epoch 36.138), train_loss = 0.59277855, grad/param norm = 1.8334e-01, time/batch = 17.1459s	
18829/26050 (epoch 36.140), train_loss = 0.69263937, grad/param norm = 2.0300e-01, time/batch = 17.8273s	
18830/26050 (epoch 36.142), train_loss = 0.73794709, grad/param norm = 1.9585e-01, time/batch = 16.2429s	
18831/26050 (epoch 36.144), train_loss = 0.68627663, grad/param norm = 2.1356e-01, time/batch = 16.2139s	
18832/26050 (epoch 36.146), train_loss = 0.64211957, grad/param norm = 1.8033e-01, time/batch = 17.6449s	
18833/26050 (epoch 36.148), train_loss = 0.66281361, grad/param norm = 1.7523e-01, time/batch = 17.7273s	
18834/26050 (epoch 36.150), train_loss = 0.77143445, grad/param norm = 2.1229e-01, time/batch = 17.6255s	
18835/26050 (epoch 36.152), train_loss = 0.94033295, grad/param norm = 2.3916e-01, time/batch = 15.0492s	
18836/26050 (epoch 36.154), train_loss = 0.66675451, grad/param norm = 1.8990e-01, time/batch = 18.9698s	
18837/26050 (epoch 36.155), train_loss = 0.71152393, grad/param norm = 1.9053e-01, time/batch = 18.8907s	
18838/26050 (epoch 36.157), train_loss = 0.81692290, grad/param norm = 2.7377e-01, time/batch = 17.1473s	
18839/26050 (epoch 36.159), train_loss = 0.88097629, grad/param norm = 2.2638e-01, time/batch = 18.7360s	
18840/26050 (epoch 36.161), train_loss = 0.84812973, grad/param norm = 2.2219e-01, time/batch = 17.6516s	
18841/26050 (epoch 36.163), train_loss = 0.70348755, grad/param norm = 2.0255e-01, time/batch = 18.4738s	
18842/26050 (epoch 36.165), train_loss = 0.61491511, grad/param norm = 1.6748e-01, time/batch = 17.7349s	
18843/26050 (epoch 36.167), train_loss = 0.96720037, grad/param norm = 2.6482e-01, time/batch = 18.9861s	
18844/26050 (epoch 36.169), train_loss = 0.83141499, grad/param norm = 2.6597e-01, time/batch = 18.5853s	
18845/26050 (epoch 36.171), train_loss = 0.73548963, grad/param norm = 2.1044e-01, time/batch = 16.4809s	
18846/26050 (epoch 36.173), train_loss = 0.78789413, grad/param norm = 1.9962e-01, time/batch = 18.0614s	
18847/26050 (epoch 36.175), train_loss = 0.82932220, grad/param norm = 2.1922e-01, time/batch = 15.8879s	
18848/26050 (epoch 36.177), train_loss = 0.89761105, grad/param norm = 2.1175e-01, time/batch = 17.8050s	
18849/26050 (epoch 36.179), train_loss = 0.61811347, grad/param norm = 1.7103e-01, time/batch = 17.3173s	
18850/26050 (epoch 36.180), train_loss = 1.04446051, grad/param norm = 2.2251e-01, time/batch = 18.2324s	
18851/26050 (epoch 36.182), train_loss = 0.99336344, grad/param norm = 2.3429e-01, time/batch = 18.6674s	
18852/26050 (epoch 36.184), train_loss = 0.85891661, grad/param norm = 2.1347e-01, time/batch = 14.8015s	
18853/26050 (epoch 36.186), train_loss = 0.73028255, grad/param norm = 2.0803e-01, time/batch = 17.9713s	
18854/26050 (epoch 36.188), train_loss = 0.87745950, grad/param norm = 2.3182e-01, time/batch = 16.9765s	
18855/26050 (epoch 36.190), train_loss = 0.86793468, grad/param norm = 2.3267e-01, time/batch = 16.8901s	
18856/26050 (epoch 36.192), train_loss = 0.91712329, grad/param norm = 1.9126e-01, time/batch = 18.1540s	
18857/26050 (epoch 36.194), train_loss = 0.86981544, grad/param norm = 2.0325e-01, time/batch = 17.3227s	
18858/26050 (epoch 36.196), train_loss = 0.88775001, grad/param norm = 2.1355e-01, time/batch = 18.0610s	
18859/26050 (epoch 36.198), train_loss = 0.76699767, grad/param norm = 1.8180e-01, time/batch = 17.4684s	
18860/26050 (epoch 36.200), train_loss = 0.74387952, grad/param norm = 2.1655e-01, time/batch = 18.4142s	
18861/26050 (epoch 36.202), train_loss = 0.84597013, grad/param norm = 1.9091e-01, time/batch = 15.3749s	
18862/26050 (epoch 36.203), train_loss = 0.92559190, grad/param norm = 1.9625e-01, time/batch = 17.3867s	
18863/26050 (epoch 36.205), train_loss = 0.78256763, grad/param norm = 2.0380e-01, time/batch = 18.8959s	
18864/26050 (epoch 36.207), train_loss = 0.75890012, grad/param norm = 2.2107e-01, time/batch = 17.5681s	
18865/26050 (epoch 36.209), train_loss = 0.90795922, grad/param norm = 2.0545e-01, time/batch = 18.3741s	
18866/26050 (epoch 36.211), train_loss = 0.71608394, grad/param norm = 1.8460e-01, time/batch = 33.9341s	
18867/26050 (epoch 36.213), train_loss = 0.85260765, grad/param norm = 2.1263e-01, time/batch = 23.4024s	
18868/26050 (epoch 36.215), train_loss = 0.82198457, grad/param norm = 2.3934e-01, time/batch = 14.6676s	
18869/26050 (epoch 36.217), train_loss = 0.78358641, grad/param norm = 1.8340e-01, time/batch = 17.4029s	
18870/26050 (epoch 36.219), train_loss = 0.80329319, grad/param norm = 2.3050e-01, time/batch = 17.5573s	
18871/26050 (epoch 36.221), train_loss = 0.75264152, grad/param norm = 2.2672e-01, time/batch = 17.7267s	
18872/26050 (epoch 36.223), train_loss = 0.92396463, grad/param norm = 2.3462e-01, time/batch = 18.3927s	
18873/26050 (epoch 36.225), train_loss = 0.73591145, grad/param norm = 2.0000e-01, time/batch = 17.1413s	
18874/26050 (epoch 36.226), train_loss = 0.86322546, grad/param norm = 2.4677e-01, time/batch = 17.1936s	
18875/26050 (epoch 36.228), train_loss = 0.95909825, grad/param norm = 2.2114e-01, time/batch = 16.7006s	
18876/26050 (epoch 36.230), train_loss = 0.83977584, grad/param norm = 1.8429e-01, time/batch = 18.9841s	
18877/26050 (epoch 36.232), train_loss = 0.91594206, grad/param norm = 2.2503e-01, time/batch = 17.8936s	
18878/26050 (epoch 36.234), train_loss = 0.73730451, grad/param norm = 1.9783e-01, time/batch = 15.6332s	
18879/26050 (epoch 36.236), train_loss = 0.91708938, grad/param norm = 2.1761e-01, time/batch = 16.7178s	
18880/26050 (epoch 36.238), train_loss = 0.73152858, grad/param norm = 2.2886e-01, time/batch = 18.1532s	
18881/26050 (epoch 36.240), train_loss = 0.83550328, grad/param norm = 2.0601e-01, time/batch = 17.1515s	
18882/26050 (epoch 36.242), train_loss = 0.81326686, grad/param norm = 1.9870e-01, time/batch = 16.7353s	
18883/26050 (epoch 36.244), train_loss = 0.86191032, grad/param norm = 2.1759e-01, time/batch = 17.5407s	
18884/26050 (epoch 36.246), train_loss = 0.79890225, grad/param norm = 1.8921e-01, time/batch = 18.9074s	
18885/26050 (epoch 36.248), train_loss = 0.85188037, grad/param norm = 2.1081e-01, time/batch = 17.8787s	
18886/26050 (epoch 36.250), train_loss = 0.85421820, grad/param norm = 2.5646e-01, time/batch = 18.4889s	
18887/26050 (epoch 36.251), train_loss = 0.78561347, grad/param norm = 2.0480e-01, time/batch = 18.7260s	
18888/26050 (epoch 36.253), train_loss = 0.73163898, grad/param norm = 1.8513e-01, time/batch = 16.9726s	
18889/26050 (epoch 36.255), train_loss = 1.02256883, grad/param norm = 2.7052e-01, time/batch = 18.9867s	
18890/26050 (epoch 36.257), train_loss = 0.84250791, grad/param norm = 2.3326e-01, time/batch = 14.8166s	
18891/26050 (epoch 36.259), train_loss = 0.93941690, grad/param norm = 2.2780e-01, time/batch = 16.7909s	
18892/26050 (epoch 36.261), train_loss = 0.76196758, grad/param norm = 2.3608e-01, time/batch = 17.7353s	
18893/26050 (epoch 36.263), train_loss = 0.94022344, grad/param norm = 2.4390e-01, time/batch = 19.0671s	
18894/26050 (epoch 36.265), train_loss = 0.95547396, grad/param norm = 2.6191e-01, time/batch = 18.1466s	
18895/26050 (epoch 36.267), train_loss = 0.94904805, grad/param norm = 1.9602e-01, time/batch = 17.0712s	
18896/26050 (epoch 36.269), train_loss = 0.94551716, grad/param norm = 2.0925e-01, time/batch = 17.0652s	
18897/26050 (epoch 36.271), train_loss = 0.86575249, grad/param norm = 2.1766e-01, time/batch = 16.5358s	
18898/26050 (epoch 36.273), train_loss = 0.76703011, grad/param norm = 2.4386e-01, time/batch = 17.1366s	
18899/26050 (epoch 36.274), train_loss = 0.80094633, grad/param norm = 1.9703e-01, time/batch = 17.3988s	
18900/26050 (epoch 36.276), train_loss = 0.81367850, grad/param norm = 2.2474e-01, time/batch = 18.7204s	
18901/26050 (epoch 36.278), train_loss = 0.92146111, grad/param norm = 2.1097e-01, time/batch = 18.3270s	
18902/26050 (epoch 36.280), train_loss = 0.84531075, grad/param norm = 1.8975e-01, time/batch = 18.7224s	
18903/26050 (epoch 36.282), train_loss = 0.90878581, grad/param norm = 1.9695e-01, time/batch = 18.0670s	
18904/26050 (epoch 36.284), train_loss = 0.83524557, grad/param norm = 2.1861e-01, time/batch = 18.0760s	
18905/26050 (epoch 36.286), train_loss = 0.89322117, grad/param norm = 2.3495e-01, time/batch = 17.5591s	
18906/26050 (epoch 36.288), train_loss = 0.73603175, grad/param norm = 1.8597e-01, time/batch = 17.2815s	
18907/26050 (epoch 36.290), train_loss = 0.85221668, grad/param norm = 2.4751e-01, time/batch = 18.2366s	
18908/26050 (epoch 36.292), train_loss = 0.75934818, grad/param norm = 2.0042e-01, time/batch = 14.6227s	
18909/26050 (epoch 36.294), train_loss = 0.85526961, grad/param norm = 2.3168e-01, time/batch = 17.8190s	
18910/26050 (epoch 36.296), train_loss = 0.91937216, grad/param norm = 2.0339e-01, time/batch = 14.5501s	
18911/26050 (epoch 36.298), train_loss = 0.87297697, grad/param norm = 1.9858e-01, time/batch = 18.3891s	
18912/26050 (epoch 36.299), train_loss = 0.69351265, grad/param norm = 1.7734e-01, time/batch = 14.9047s	
18913/26050 (epoch 36.301), train_loss = 0.70854288, grad/param norm = 1.8841e-01, time/batch = 17.5667s	
18914/26050 (epoch 36.303), train_loss = 0.84513692, grad/param norm = 2.2271e-01, time/batch = 18.3934s	
18915/26050 (epoch 36.305), train_loss = 0.68236817, grad/param norm = 2.0048e-01, time/batch = 18.0599s	
18916/26050 (epoch 36.307), train_loss = 0.76264249, grad/param norm = 2.3060e-01, time/batch = 2.8580s	
18917/26050 (epoch 36.309), train_loss = 0.85217936, grad/param norm = 2.1063e-01, time/batch = 0.6455s	
18918/26050 (epoch 36.311), train_loss = 0.87535116, grad/param norm = 2.7017e-01, time/batch = 0.6455s	
18919/26050 (epoch 36.313), train_loss = 0.83890960, grad/param norm = 2.4327e-01, time/batch = 0.6832s	
18920/26050 (epoch 36.315), train_loss = 0.90245501, grad/param norm = 1.9963e-01, time/batch = 0.6606s	
18921/26050 (epoch 36.317), train_loss = 0.85821587, grad/param norm = 2.2924e-01, time/batch = 0.6522s	
18922/26050 (epoch 36.319), train_loss = 0.76528481, grad/param norm = 2.2870e-01, time/batch = 0.6492s	
18923/26050 (epoch 36.321), train_loss = 0.82305645, grad/param norm = 2.0207e-01, time/batch = 0.7193s	
18924/26050 (epoch 36.322), train_loss = 0.90026282, grad/param norm = 2.0691e-01, time/batch = 0.9428s	
18925/26050 (epoch 36.324), train_loss = 0.66834305, grad/param norm = 2.0070e-01, time/batch = 0.9425s	
18926/26050 (epoch 36.326), train_loss = 0.95311206, grad/param norm = 2.4252e-01, time/batch = 0.9407s	
18927/26050 (epoch 36.328), train_loss = 0.88031059, grad/param norm = 1.9714e-01, time/batch = 0.9438s	
18928/26050 (epoch 36.330), train_loss = 0.73365550, grad/param norm = 2.1568e-01, time/batch = 0.9432s	
18929/26050 (epoch 36.332), train_loss = 0.90346655, grad/param norm = 2.1146e-01, time/batch = 1.7382s	
18930/26050 (epoch 36.334), train_loss = 0.74863258, grad/param norm = 2.3175e-01, time/batch = 1.8435s	
18931/26050 (epoch 36.336), train_loss = 0.79019114, grad/param norm = 2.2144e-01, time/batch = 5.6685s	
18932/26050 (epoch 36.338), train_loss = 0.72896990, grad/param norm = 1.8825e-01, time/batch = 17.9811s	
18933/26050 (epoch 36.340), train_loss = 0.87718070, grad/param norm = 2.1208e-01, time/batch = 17.7404s	
18934/26050 (epoch 36.342), train_loss = 0.93340951, grad/param norm = 2.1796e-01, time/batch = 15.5554s	
18935/26050 (epoch 36.344), train_loss = 0.77299036, grad/param norm = 2.3231e-01, time/batch = 18.6257s	
18936/26050 (epoch 36.345), train_loss = 0.81476844, grad/param norm = 2.4494e-01, time/batch = 18.5736s	
18937/26050 (epoch 36.347), train_loss = 0.94743056, grad/param norm = 2.1122e-01, time/batch = 17.3184s	
18938/26050 (epoch 36.349), train_loss = 0.88027942, grad/param norm = 2.1126e-01, time/batch = 18.0795s	
18939/26050 (epoch 36.351), train_loss = 0.85265118, grad/param norm = 2.1394e-01, time/batch = 17.6640s	
18940/26050 (epoch 36.353), train_loss = 0.84189966, grad/param norm = 2.0871e-01, time/batch = 17.3951s	
18941/26050 (epoch 36.355), train_loss = 0.83070697, grad/param norm = 2.2786e-01, time/batch = 18.1461s	
18942/26050 (epoch 36.357), train_loss = 0.80416753, grad/param norm = 1.9933e-01, time/batch = 17.3722s	
18943/26050 (epoch 36.359), train_loss = 0.91536964, grad/param norm = 2.3043e-01, time/batch = 14.8005s	
18944/26050 (epoch 36.361), train_loss = 0.75384130, grad/param norm = 1.8435e-01, time/batch = 15.2910s	
18945/26050 (epoch 36.363), train_loss = 0.91080461, grad/param norm = 2.0973e-01, time/batch = 18.7078s	
18946/26050 (epoch 36.365), train_loss = 0.81546001, grad/param norm = 2.0204e-01, time/batch = 18.5524s	
18947/26050 (epoch 36.367), train_loss = 0.90376598, grad/param norm = 2.1213e-01, time/batch = 17.1463s	
18948/26050 (epoch 36.369), train_loss = 0.74213347, grad/param norm = 1.7272e-01, time/batch = 17.2103s	
18949/26050 (epoch 36.370), train_loss = 0.74296498, grad/param norm = 1.8458e-01, time/batch = 16.2121s	
18950/26050 (epoch 36.372), train_loss = 0.83745128, grad/param norm = 2.1337e-01, time/batch = 15.7023s	
18951/26050 (epoch 36.374), train_loss = 0.96550804, grad/param norm = 2.3619e-01, time/batch = 17.0526s	
18952/26050 (epoch 36.376), train_loss = 0.96772759, grad/param norm = 2.7674e-01, time/batch = 17.8120s	
18953/26050 (epoch 36.378), train_loss = 0.81017813, grad/param norm = 1.9392e-01, time/batch = 18.0690s	
18954/26050 (epoch 36.380), train_loss = 0.94148898, grad/param norm = 2.1686e-01, time/batch = 18.1582s	
18955/26050 (epoch 36.382), train_loss = 1.04045538, grad/param norm = 2.6096e-01, time/batch = 17.4879s	
18956/26050 (epoch 36.384), train_loss = 0.80410202, grad/param norm = 2.1718e-01, time/batch = 17.7276s	
18957/26050 (epoch 36.386), train_loss = 0.90123087, grad/param norm = 2.4661e-01, time/batch = 18.4756s	
18958/26050 (epoch 36.388), train_loss = 0.86606383, grad/param norm = 2.1480e-01, time/batch = 18.3081s	
18959/26050 (epoch 36.390), train_loss = 0.79253485, grad/param norm = 1.8472e-01, time/batch = 15.4637s	
18960/26050 (epoch 36.392), train_loss = 0.73306092, grad/param norm = 1.9134e-01, time/batch = 18.1576s	
18961/26050 (epoch 36.393), train_loss = 0.89085949, grad/param norm = 2.4487e-01, time/batch = 17.6451s	
18962/26050 (epoch 36.395), train_loss = 0.90133607, grad/param norm = 3.2390e-01, time/batch = 18.3248s	
18963/26050 (epoch 36.397), train_loss = 0.91990817, grad/param norm = 2.5593e-01, time/batch = 18.4066s	
18964/26050 (epoch 36.399), train_loss = 0.81237691, grad/param norm = 2.1887e-01, time/batch = 14.4694s	
18965/26050 (epoch 36.401), train_loss = 0.84583262, grad/param norm = 2.1138e-01, time/batch = 17.8084s	
18966/26050 (epoch 36.403), train_loss = 0.88196538, grad/param norm = 2.4205e-01, time/batch = 16.8950s	
18967/26050 (epoch 36.405), train_loss = 0.86718163, grad/param norm = 2.3236e-01, time/batch = 18.2370s	
18968/26050 (epoch 36.407), train_loss = 0.96230042, grad/param norm = 2.2740e-01, time/batch = 16.8132s	
18969/26050 (epoch 36.409), train_loss = 0.97978197, grad/param norm = 2.5336e-01, time/batch = 18.3993s	
18970/26050 (epoch 36.411), train_loss = 0.94323947, grad/param norm = 2.4705e-01, time/batch = 18.4841s	
18971/26050 (epoch 36.413), train_loss = 1.01685755, grad/param norm = 2.3470e-01, time/batch = 17.0313s	
18972/26050 (epoch 36.415), train_loss = 1.03255733, grad/param norm = 2.6701e-01, time/batch = 15.1452s	
18973/26050 (epoch 36.417), train_loss = 1.02978746, grad/param norm = 2.5124e-01, time/batch = 18.6353s	
18974/26050 (epoch 36.418), train_loss = 0.90812944, grad/param norm = 2.4733e-01, time/batch = 17.8873s	
18975/26050 (epoch 36.420), train_loss = 0.74816144, grad/param norm = 1.9986e-01, time/batch = 16.8108s	
18976/26050 (epoch 36.422), train_loss = 0.72634449, grad/param norm = 1.8619e-01, time/batch = 17.5692s	
18977/26050 (epoch 36.424), train_loss = 0.94095983, grad/param norm = 2.2499e-01, time/batch = 18.5502s	
18978/26050 (epoch 36.426), train_loss = 0.91485350, grad/param norm = 2.2838e-01, time/batch = 16.5620s	
18979/26050 (epoch 36.428), train_loss = 0.83038421, grad/param norm = 2.0942e-01, time/batch = 15.9013s	
18980/26050 (epoch 36.430), train_loss = 1.00690022, grad/param norm = 2.1605e-01, time/batch = 16.5529s	
18981/26050 (epoch 36.432), train_loss = 0.83062195, grad/param norm = 2.3250e-01, time/batch = 17.9082s	
18982/26050 (epoch 36.434), train_loss = 0.80158219, grad/param norm = 2.0764e-01, time/batch = 15.7840s	
18983/26050 (epoch 36.436), train_loss = 0.93554911, grad/param norm = 2.1174e-01, time/batch = 17.4754s	
18984/26050 (epoch 36.438), train_loss = 0.88828741, grad/param norm = 2.5633e-01, time/batch = 18.7294s	
18985/26050 (epoch 36.440), train_loss = 0.87788258, grad/param norm = 1.9640e-01, time/batch = 17.1428s	
18986/26050 (epoch 36.441), train_loss = 0.88489383, grad/param norm = 1.9563e-01, time/batch = 18.7978s	
18987/26050 (epoch 36.443), train_loss = 0.73249653, grad/param norm = 1.6452e-01, time/batch = 18.4770s	
18988/26050 (epoch 36.445), train_loss = 0.76477832, grad/param norm = 2.1064e-01, time/batch = 15.8874s	
18989/26050 (epoch 36.447), train_loss = 0.98733023, grad/param norm = 2.3157e-01, time/batch = 17.7946s	
18990/26050 (epoch 36.449), train_loss = 0.77551399, grad/param norm = 1.9371e-01, time/batch = 17.9877s	
18991/26050 (epoch 36.451), train_loss = 0.98662967, grad/param norm = 2.1070e-01, time/batch = 18.5788s	
18992/26050 (epoch 36.453), train_loss = 0.81002583, grad/param norm = 1.8260e-01, time/batch = 16.9847s	
18993/26050 (epoch 36.455), train_loss = 0.84826806, grad/param norm = 1.9507e-01, time/batch = 18.7371s	
18994/26050 (epoch 36.457), train_loss = 0.83346019, grad/param norm = 2.1461e-01, time/batch = 17.6643s	
18995/26050 (epoch 36.459), train_loss = 0.95024884, grad/param norm = 2.2028e-01, time/batch = 16.2165s	
18996/26050 (epoch 36.461), train_loss = 0.95372300, grad/param norm = 2.3566e-01, time/batch = 17.4780s	
18997/26050 (epoch 36.463), train_loss = 0.81894215, grad/param norm = 1.8580e-01, time/batch = 17.8162s	
18998/26050 (epoch 36.464), train_loss = 0.87864553, grad/param norm = 2.0924e-01, time/batch = 17.8294s	
18999/26050 (epoch 36.466), train_loss = 0.85501069, grad/param norm = 2.0254e-01, time/batch = 17.9547s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch36.47_1.8790.t7	
19000/26050 (epoch 36.468), train_loss = 0.95550067, grad/param norm = 1.9239e-01, time/batch = 17.5560s	
19001/26050 (epoch 36.470), train_loss = 1.49705537, grad/param norm = 3.1894e-01, time/batch = 18.4757s	
19002/26050 (epoch 36.472), train_loss = 0.97636005, grad/param norm = 2.6232e-01, time/batch = 17.5674s	
19003/26050 (epoch 36.474), train_loss = 0.98232852, grad/param norm = 2.2109e-01, time/batch = 15.9884s	
19004/26050 (epoch 36.476), train_loss = 0.92872998, grad/param norm = 1.9751e-01, time/batch = 17.0548s	
19005/26050 (epoch 36.478), train_loss = 0.81661074, grad/param norm = 1.9740e-01, time/batch = 18.6455s	
19006/26050 (epoch 36.480), train_loss = 0.84182444, grad/param norm = 1.9649e-01, time/batch = 17.1937s	
19007/26050 (epoch 36.482), train_loss = 0.81070617, grad/param norm = 2.0475e-01, time/batch = 15.9654s	
19008/26050 (epoch 36.484), train_loss = 0.81458198, grad/param norm = 2.2900e-01, time/batch = 18.3940s	
19009/26050 (epoch 36.486), train_loss = 0.97565194, grad/param norm = 2.1879e-01, time/batch = 17.7179s	
19010/26050 (epoch 36.488), train_loss = 1.01219283, grad/param norm = 2.7478e-01, time/batch = 18.3061s	
19011/26050 (epoch 36.489), train_loss = 1.05492628, grad/param norm = 2.8908e-01, time/batch = 17.3876s	
19012/26050 (epoch 36.491), train_loss = 0.80011306, grad/param norm = 2.1671e-01, time/batch = 18.8085s	
19013/26050 (epoch 36.493), train_loss = 0.87409577, grad/param norm = 2.1062e-01, time/batch = 18.5433s	
19014/26050 (epoch 36.495), train_loss = 0.85680218, grad/param norm = 2.0387e-01, time/batch = 14.3967s	
19015/26050 (epoch 36.497), train_loss = 0.78035357, grad/param norm = 2.1380e-01, time/batch = 17.9014s	
19016/26050 (epoch 36.499), train_loss = 0.80223431, grad/param norm = 2.1517e-01, time/batch = 16.7476s	
19017/26050 (epoch 36.501), train_loss = 0.95035423, grad/param norm = 1.9673e-01, time/batch = 18.7339s	
19018/26050 (epoch 36.503), train_loss = 0.81892773, grad/param norm = 2.0313e-01, time/batch = 17.9028s	
19019/26050 (epoch 36.505), train_loss = 0.95838555, grad/param norm = 2.1187e-01, time/batch = 15.9212s	
19020/26050 (epoch 36.507), train_loss = 0.93657266, grad/param norm = 2.3559e-01, time/batch = 14.3139s	
19021/26050 (epoch 36.509), train_loss = 0.99421790, grad/param norm = 1.9888e-01, time/batch = 14.2937s	
19022/26050 (epoch 36.511), train_loss = 0.84148320, grad/param norm = 1.8340e-01, time/batch = 14.0105s	
19023/26050 (epoch 36.512), train_loss = 0.75328194, grad/param norm = 2.1071e-01, time/batch = 17.4065s	
19024/26050 (epoch 36.514), train_loss = 0.88364912, grad/param norm = 2.1312e-01, time/batch = 15.7964s	
19025/26050 (epoch 36.516), train_loss = 0.98002028, grad/param norm = 2.1882e-01, time/batch = 17.8089s	
19026/26050 (epoch 36.518), train_loss = 0.83334566, grad/param norm = 1.9955e-01, time/batch = 18.0565s	
19027/26050 (epoch 36.520), train_loss = 0.86084440, grad/param norm = 2.1120e-01, time/batch = 16.4671s	
19028/26050 (epoch 36.522), train_loss = 0.68979682, grad/param norm = 1.8927e-01, time/batch = 16.8691s	
19029/26050 (epoch 36.524), train_loss = 0.96672827, grad/param norm = 2.4630e-01, time/batch = 18.5646s	
19030/26050 (epoch 36.526), train_loss = 0.95599783, grad/param norm = 2.1725e-01, time/batch = 18.3303s	
19031/26050 (epoch 36.528), train_loss = 0.87685641, grad/param norm = 2.0690e-01, time/batch = 15.6638s	
19032/26050 (epoch 36.530), train_loss = 0.82734058, grad/param norm = 2.3486e-01, time/batch = 18.4699s	
19033/26050 (epoch 36.532), train_loss = 0.88493519, grad/param norm = 2.0313e-01, time/batch = 18.5670s	
19034/26050 (epoch 36.534), train_loss = 0.88542753, grad/param norm = 2.6663e-01, time/batch = 17.2385s	
19035/26050 (epoch 36.536), train_loss = 0.90134759, grad/param norm = 2.0261e-01, time/batch = 16.4781s	
19036/26050 (epoch 36.537), train_loss = 0.92593047, grad/param norm = 2.0825e-01, time/batch = 17.5494s	
19037/26050 (epoch 36.539), train_loss = 0.88229828, grad/param norm = 2.1738e-01, time/batch = 17.5671s	
19038/26050 (epoch 36.541), train_loss = 1.02410053, grad/param norm = 3.0258e-01, time/batch = 16.8800s	
19039/26050 (epoch 36.543), train_loss = 0.69509896, grad/param norm = 2.0989e-01, time/batch = 18.4839s	
19040/26050 (epoch 36.545), train_loss = 0.85995751, grad/param norm = 2.0908e-01, time/batch = 18.4735s	
19041/26050 (epoch 36.547), train_loss = 0.83655073, grad/param norm = 2.1347e-01, time/batch = 17.8741s	
19042/26050 (epoch 36.549), train_loss = 0.73877232, grad/param norm = 2.0263e-01, time/batch = 17.4831s	
19043/26050 (epoch 36.551), train_loss = 0.93671963, grad/param norm = 2.1779e-01, time/batch = 17.7281s	
19044/26050 (epoch 36.553), train_loss = 0.82766946, grad/param norm = 2.1537e-01, time/batch = 16.8947s	
19045/26050 (epoch 36.555), train_loss = 0.77953395, grad/param norm = 2.3017e-01, time/batch = 18.0637s	
19046/26050 (epoch 36.557), train_loss = 0.87118652, grad/param norm = 1.8685e-01, time/batch = 17.9870s	
19047/26050 (epoch 36.559), train_loss = 0.87533210, grad/param norm = 1.9715e-01, time/batch = 18.2280s	
19048/26050 (epoch 36.560), train_loss = 0.82703611, grad/param norm = 2.1597e-01, time/batch = 18.6525s	
19049/26050 (epoch 36.562), train_loss = 0.85490407, grad/param norm = 2.2873e-01, time/batch = 17.9011s	
19050/26050 (epoch 36.564), train_loss = 1.02838187, grad/param norm = 2.4029e-01, time/batch = 18.9680s	
19051/26050 (epoch 36.566), train_loss = 0.82093001, grad/param norm = 2.1299e-01, time/batch = 14.6185s	
19052/26050 (epoch 36.568), train_loss = 0.90833207, grad/param norm = 2.1700e-01, time/batch = 18.2203s	
19053/26050 (epoch 36.570), train_loss = 0.87483936, grad/param norm = 2.2329e-01, time/batch = 16.9673s	
19054/26050 (epoch 36.572), train_loss = 0.86299188, grad/param norm = 2.2346e-01, time/batch = 17.8942s	
19055/26050 (epoch 36.574), train_loss = 0.89102508, grad/param norm = 2.9004e-01, time/batch = 18.3102s	
19056/26050 (epoch 36.576), train_loss = 0.89690659, grad/param norm = 2.2620e-01, time/batch = 17.8169s	
19057/26050 (epoch 36.578), train_loss = 0.84443140, grad/param norm = 2.0989e-01, time/batch = 16.3698s	
19058/26050 (epoch 36.580), train_loss = 0.79511788, grad/param norm = 2.1528e-01, time/batch = 18.3839s	
19059/26050 (epoch 36.582), train_loss = 0.88349715, grad/param norm = 2.1578e-01, time/batch = 17.9000s	
19060/26050 (epoch 36.583), train_loss = 0.93263230, grad/param norm = 1.9488e-01, time/batch = 17.0689s	
19061/26050 (epoch 36.585), train_loss = 0.77492676, grad/param norm = 2.0381e-01, time/batch = 15.7662s	
19062/26050 (epoch 36.587), train_loss = 0.90130135, grad/param norm = 2.2458e-01, time/batch = 18.0632s	
19063/26050 (epoch 36.589), train_loss = 1.01188687, grad/param norm = 2.2681e-01, time/batch = 18.4127s	
19064/26050 (epoch 36.591), train_loss = 0.87414922, grad/param norm = 2.0711e-01, time/batch = 17.9874s	
19065/26050 (epoch 36.593), train_loss = 0.75307433, grad/param norm = 2.0119e-01, time/batch = 18.0776s	
19066/26050 (epoch 36.595), train_loss = 0.90958607, grad/param norm = 2.2804e-01, time/batch = 17.8881s	
19067/26050 (epoch 36.597), train_loss = 0.88224885, grad/param norm = 2.1069e-01, time/batch = 18.5578s	
19068/26050 (epoch 36.599), train_loss = 0.92855439, grad/param norm = 2.2626e-01, time/batch = 15.1293s	
19069/26050 (epoch 36.601), train_loss = 1.02937888, grad/param norm = 2.7425e-01, time/batch = 17.8167s	
19070/26050 (epoch 36.603), train_loss = 0.95416375, grad/param norm = 2.3722e-01, time/batch = 17.7309s	
19071/26050 (epoch 36.605), train_loss = 0.85369677, grad/param norm = 2.2013e-01, time/batch = 18.1407s	
19072/26050 (epoch 36.607), train_loss = 0.96813887, grad/param norm = 2.7504e-01, time/batch = 17.3220s	
19073/26050 (epoch 36.608), train_loss = 0.78327679, grad/param norm = 1.7920e-01, time/batch = 18.0582s	
19074/26050 (epoch 36.610), train_loss = 0.86514225, grad/param norm = 2.1988e-01, time/batch = 18.0820s	
19075/26050 (epoch 36.612), train_loss = 0.84255904, grad/param norm = 2.2309e-01, time/batch = 17.9840s	
19076/26050 (epoch 36.614), train_loss = 0.88052121, grad/param norm = 2.2878e-01, time/batch = 18.2380s	
19077/26050 (epoch 36.616), train_loss = 0.92379010, grad/param norm = 2.1711e-01, time/batch = 18.0622s	
19078/26050 (epoch 36.618), train_loss = 0.82365415, grad/param norm = 2.1293e-01, time/batch = 24.6266s	
19079/26050 (epoch 36.620), train_loss = 0.95306343, grad/param norm = 2.4330e-01, time/batch = 33.3359s	
19080/26050 (epoch 36.622), train_loss = 0.78922689, grad/param norm = 1.9623e-01, time/batch = 15.4415s	
19081/26050 (epoch 36.624), train_loss = 0.72393730, grad/param norm = 1.8482e-01, time/batch = 15.1198s	
19082/26050 (epoch 36.626), train_loss = 0.90601145, grad/param norm = 2.1259e-01, time/batch = 17.7102s	
19083/26050 (epoch 36.628), train_loss = 0.82893065, grad/param norm = 2.2896e-01, time/batch = 18.3192s	
19084/26050 (epoch 36.630), train_loss = 1.00512288, grad/param norm = 2.0671e-01, time/batch = 18.7231s	
19085/26050 (epoch 36.631), train_loss = 1.02179088, grad/param norm = 2.3643e-01, time/batch = 16.8146s	
19086/26050 (epoch 36.633), train_loss = 0.78510869, grad/param norm = 2.1298e-01, time/batch = 17.1512s	
19087/26050 (epoch 36.635), train_loss = 0.81383134, grad/param norm = 1.7517e-01, time/batch = 14.6078s	
19088/26050 (epoch 36.637), train_loss = 0.76112826, grad/param norm = 2.0778e-01, time/batch = 18.3105s	
19089/26050 (epoch 36.639), train_loss = 0.91081526, grad/param norm = 2.0217e-01, time/batch = 17.6410s	
19090/26050 (epoch 36.641), train_loss = 0.80360992, grad/param norm = 1.8926e-01, time/batch = 17.6449s	
19091/26050 (epoch 36.643), train_loss = 0.79156597, grad/param norm = 1.7715e-01, time/batch = 14.8147s	
19092/26050 (epoch 36.645), train_loss = 0.81904438, grad/param norm = 1.9929e-01, time/batch = 18.8230s	
19093/26050 (epoch 36.647), train_loss = 0.78031390, grad/param norm = 2.3372e-01, time/batch = 18.1530s	
19094/26050 (epoch 36.649), train_loss = 0.84375067, grad/param norm = 2.2736e-01, time/batch = 17.3873s	
19095/26050 (epoch 36.651), train_loss = 0.82246574, grad/param norm = 1.9383e-01, time/batch = 17.4818s	
19096/26050 (epoch 36.653), train_loss = 0.85938288, grad/param norm = 2.2979e-01, time/batch = 19.0539s	
19097/26050 (epoch 36.655), train_loss = 0.76843318, grad/param norm = 1.9640e-01, time/batch = 17.4759s	
19098/26050 (epoch 36.656), train_loss = 0.76270364, grad/param norm = 1.7894e-01, time/batch = 18.0681s	
19099/26050 (epoch 36.658), train_loss = 1.04001603, grad/param norm = 2.3490e-01, time/batch = 15.8931s	
19100/26050 (epoch 36.660), train_loss = 0.72474765, grad/param norm = 1.9971e-01, time/batch = 18.9670s	
19101/26050 (epoch 36.662), train_loss = 0.85735960, grad/param norm = 2.3435e-01, time/batch = 18.3135s	
19102/26050 (epoch 36.664), train_loss = 0.85395925, grad/param norm = 2.0494e-01, time/batch = 18.4890s	
19103/26050 (epoch 36.666), train_loss = 0.81862368, grad/param norm = 2.1577e-01, time/batch = 17.4866s	
19104/26050 (epoch 36.668), train_loss = 0.68878646, grad/param norm = 3.2615e-01, time/batch = 16.2880s	
19105/26050 (epoch 36.670), train_loss = 1.00320678, grad/param norm = 2.6031e-01, time/batch = 15.9566s	
19106/26050 (epoch 36.672), train_loss = 0.85755379, grad/param norm = 2.1519e-01, time/batch = 18.8253s	
19107/26050 (epoch 36.674), train_loss = 0.76322365, grad/param norm = 2.0898e-01, time/batch = 17.6468s	
19108/26050 (epoch 36.676), train_loss = 0.91710047, grad/param norm = 2.3104e-01, time/batch = 18.3205s	
19109/26050 (epoch 36.678), train_loss = 0.95111061, grad/param norm = 2.3178e-01, time/batch = 18.2341s	
19110/26050 (epoch 36.679), train_loss = 1.00162457, grad/param norm = 2.3055e-01, time/batch = 18.6539s	
19111/26050 (epoch 36.681), train_loss = 0.90235281, grad/param norm = 2.2814e-01, time/batch = 18.2253s	
19112/26050 (epoch 36.683), train_loss = 0.77988259, grad/param norm = 2.5480e-01, time/batch = 16.2281s	
19113/26050 (epoch 36.685), train_loss = 0.82645316, grad/param norm = 2.1542e-01, time/batch = 18.2270s	
19114/26050 (epoch 36.687), train_loss = 0.74058802, grad/param norm = 1.9761e-01, time/batch = 17.7999s	
19115/26050 (epoch 36.689), train_loss = 0.81890591, grad/param norm = 2.0942e-01, time/batch = 18.9810s	
19116/26050 (epoch 36.691), train_loss = 0.68534082, grad/param norm = 1.5855e-01, time/batch = 16.7257s	
19117/26050 (epoch 36.693), train_loss = 0.81145671, grad/param norm = 2.2622e-01, time/batch = 17.8728s	
19118/26050 (epoch 36.695), train_loss = 0.84803396, grad/param norm = 2.2469e-01, time/batch = 17.6598s	
19119/26050 (epoch 36.697), train_loss = 0.81262019, grad/param norm = 2.6089e-01, time/batch = 18.4073s	
19120/26050 (epoch 36.699), train_loss = 0.89453981, grad/param norm = 2.2980e-01, time/batch = 16.5698s	
19121/26050 (epoch 36.701), train_loss = 0.78514481, grad/param norm = 1.8646e-01, time/batch = 17.2207s	
19122/26050 (epoch 36.702), train_loss = 0.93077930, grad/param norm = 2.3097e-01, time/batch = 17.4838s	
19123/26050 (epoch 36.704), train_loss = 0.94035648, grad/param norm = 1.9007e-01, time/batch = 14.8931s	
19124/26050 (epoch 36.706), train_loss = 0.79461835, grad/param norm = 2.0556e-01, time/batch = 17.8892s	
19125/26050 (epoch 36.708), train_loss = 0.89497659, grad/param norm = 2.0178e-01, time/batch = 15.8202s	
19126/26050 (epoch 36.710), train_loss = 0.87660652, grad/param norm = 2.0550e-01, time/batch = 17.4773s	
19127/26050 (epoch 36.712), train_loss = 0.84777751, grad/param norm = 2.0909e-01, time/batch = 17.5807s	
19128/26050 (epoch 36.714), train_loss = 0.75957296, grad/param norm = 1.8635e-01, time/batch = 16.2212s	
19129/26050 (epoch 36.716), train_loss = 1.05955892, grad/param norm = 2.5154e-01, time/batch = 17.1170s	
19130/26050 (epoch 36.718), train_loss = 0.91637353, grad/param norm = 2.3228e-01, time/batch = 18.5780s	
19131/26050 (epoch 36.720), train_loss = 0.81839879, grad/param norm = 1.9346e-01, time/batch = 17.8153s	
19132/26050 (epoch 36.722), train_loss = 0.78591627, grad/param norm = 1.9783e-01, time/batch = 17.9895s	
19133/26050 (epoch 36.724), train_loss = 0.80072307, grad/param norm = 2.2542e-01, time/batch = 17.8287s	
19134/26050 (epoch 36.726), train_loss = 0.92046699, grad/param norm = 2.0618e-01, time/batch = 14.3988s	
19135/26050 (epoch 36.727), train_loss = 0.90488502, grad/param norm = 2.2005e-01, time/batch = 17.5679s	
19136/26050 (epoch 36.729), train_loss = 0.87951397, grad/param norm = 1.8959e-01, time/batch = 17.8199s	
19137/26050 (epoch 36.731), train_loss = 0.89921056, grad/param norm = 2.0499e-01, time/batch = 16.2317s	
19138/26050 (epoch 36.733), train_loss = 0.84115180, grad/param norm = 2.6054e-01, time/batch = 18.0694s	
19139/26050 (epoch 36.735), train_loss = 0.98080415, grad/param norm = 2.1834e-01, time/batch = 19.3783s	
19140/26050 (epoch 36.737), train_loss = 0.79827404, grad/param norm = 2.1508e-01, time/batch = 18.0573s	
19141/26050 (epoch 36.739), train_loss = 0.88285673, grad/param norm = 1.9836e-01, time/batch = 18.1422s	
19142/26050 (epoch 36.741), train_loss = 0.78207541, grad/param norm = 1.8536e-01, time/batch = 17.7221s	
19143/26050 (epoch 36.743), train_loss = 0.87356691, grad/param norm = 2.7227e-01, time/batch = 18.4926s	
19144/26050 (epoch 36.745), train_loss = 0.75522069, grad/param norm = 1.9400e-01, time/batch = 18.2488s	
19145/26050 (epoch 36.747), train_loss = 0.79553117, grad/param norm = 2.2411e-01, time/batch = 17.5551s	
19146/26050 (epoch 36.749), train_loss = 0.94437803, grad/param norm = 2.1208e-01, time/batch = 17.4692s	
19147/26050 (epoch 36.750), train_loss = 0.82232193, grad/param norm = 1.9048e-01, time/batch = 18.2297s	
19148/26050 (epoch 36.752), train_loss = 0.79901686, grad/param norm = 2.3862e-01, time/batch = 15.9586s	
19149/26050 (epoch 36.754), train_loss = 0.86727510, grad/param norm = 2.0728e-01, time/batch = 18.0824s	
19150/26050 (epoch 36.756), train_loss = 0.84507799, grad/param norm = 2.9600e-01, time/batch = 16.0539s	
19151/26050 (epoch 36.758), train_loss = 0.85824080, grad/param norm = 2.5020e-01, time/batch = 18.7266s	
19152/26050 (epoch 36.760), train_loss = 0.97428941, grad/param norm = 2.6836e-01, time/batch = 18.1507s	
19153/26050 (epoch 36.762), train_loss = 0.83258225, grad/param norm = 2.3965e-01, time/batch = 18.1476s	
19154/26050 (epoch 36.764), train_loss = 0.83720765, grad/param norm = 2.2566e-01, time/batch = 15.7102s	
19155/26050 (epoch 36.766), train_loss = 0.85831755, grad/param norm = 2.1115e-01, time/batch = 17.4773s	
19156/26050 (epoch 36.768), train_loss = 0.75628625, grad/param norm = 2.0665e-01, time/batch = 18.2342s	
19157/26050 (epoch 36.770), train_loss = 0.83688863, grad/param norm = 2.1597e-01, time/batch = 14.9748s	
19158/26050 (epoch 36.772), train_loss = 0.85590176, grad/param norm = 2.2603e-01, time/batch = 18.4027s	
19159/26050 (epoch 36.774), train_loss = 0.74179712, grad/param norm = 2.4072e-01, time/batch = 17.9073s	
19160/26050 (epoch 36.775), train_loss = 0.63076632, grad/param norm = 1.9086e-01, time/batch = 18.7441s	
19161/26050 (epoch 36.777), train_loss = 0.80173844, grad/param norm = 1.9536e-01, time/batch = 18.8962s	
19162/26050 (epoch 36.779), train_loss = 0.84349099, grad/param norm = 3.2599e-01, time/batch = 16.2910s	
19163/26050 (epoch 36.781), train_loss = 0.77792143, grad/param norm = 2.0682e-01, time/batch = 17.6355s	
19164/26050 (epoch 36.783), train_loss = 0.75008857, grad/param norm = 1.9631e-01, time/batch = 17.9918s	
19165/26050 (epoch 36.785), train_loss = 0.84883061, grad/param norm = 2.2015e-01, time/batch = 17.6579s	
19166/26050 (epoch 36.787), train_loss = 0.76115290, grad/param norm = 2.2275e-01, time/batch = 18.0791s	
19167/26050 (epoch 36.789), train_loss = 0.77347189, grad/param norm = 2.3612e-01, time/batch = 17.0506s	
19168/26050 (epoch 36.791), train_loss = 0.77764106, grad/param norm = 2.5369e-01, time/batch = 18.2464s	
19169/26050 (epoch 36.793), train_loss = 0.84782412, grad/param norm = 2.3602e-01, time/batch = 17.8289s	
19170/26050 (epoch 36.795), train_loss = 0.68661990, grad/param norm = 1.6613e-01, time/batch = 14.5502s	
19171/26050 (epoch 36.797), train_loss = 0.74529501, grad/param norm = 2.0702e-01, time/batch = 17.8887s	
19172/26050 (epoch 36.798), train_loss = 0.79822160, grad/param norm = 2.3375e-01, time/batch = 17.4754s	
19173/26050 (epoch 36.800), train_loss = 0.72929653, grad/param norm = 2.0851e-01, time/batch = 18.2282s	
19174/26050 (epoch 36.802), train_loss = 0.80373554, grad/param norm = 2.2018e-01, time/batch = 14.7812s	
19175/26050 (epoch 36.804), train_loss = 0.82227791, grad/param norm = 2.4355e-01, time/batch = 18.8906s	
19176/26050 (epoch 36.806), train_loss = 0.92819700, grad/param norm = 2.9380e-01, time/batch = 18.8231s	
19177/26050 (epoch 36.808), train_loss = 0.86107947, grad/param norm = 2.0849e-01, time/batch = 18.2333s	
19178/26050 (epoch 36.810), train_loss = 0.83618062, grad/param norm = 2.2553e-01, time/batch = 17.9019s	
19179/26050 (epoch 36.812), train_loss = 0.72343975, grad/param norm = 2.3726e-01, time/batch = 17.2253s	
19180/26050 (epoch 36.814), train_loss = 0.76121046, grad/param norm = 2.3624e-01, time/batch = 17.5553s	
19181/26050 (epoch 36.816), train_loss = 0.89337155, grad/param norm = 2.6096e-01, time/batch = 16.1478s	
19182/26050 (epoch 36.818), train_loss = 0.91934451, grad/param norm = 2.0995e-01, time/batch = 15.2619s	
19183/26050 (epoch 36.820), train_loss = 0.85953560, grad/param norm = 1.9629e-01, time/batch = 18.0503s	
19184/26050 (epoch 36.821), train_loss = 0.95607829, grad/param norm = 2.5294e-01, time/batch = 18.4806s	
19185/26050 (epoch 36.823), train_loss = 1.03077483, grad/param norm = 2.1815e-01, time/batch = 18.4674s	
19186/26050 (epoch 36.825), train_loss = 0.85515293, grad/param norm = 2.2606e-01, time/batch = 18.0413s	
19187/26050 (epoch 36.827), train_loss = 0.85466191, grad/param norm = 2.6201e-01, time/batch = 18.0678s	
19188/26050 (epoch 36.829), train_loss = 0.93201300, grad/param norm = 2.3314e-01, time/batch = 18.5547s	
19189/26050 (epoch 36.831), train_loss = 0.99130708, grad/param norm = 2.2387e-01, time/batch = 17.8085s	
19190/26050 (epoch 36.833), train_loss = 0.97645259, grad/param norm = 2.5205e-01, time/batch = 17.4819s	
19191/26050 (epoch 36.835), train_loss = 0.99211956, grad/param norm = 2.5946e-01, time/batch = 16.7096s	
19192/26050 (epoch 36.837), train_loss = 0.88065023, grad/param norm = 2.1070e-01, time/batch = 17.4847s	
19193/26050 (epoch 36.839), train_loss = 0.83519715, grad/param norm = 2.3408e-01, time/batch = 18.0595s	
19194/26050 (epoch 36.841), train_loss = 0.93367245, grad/param norm = 2.2564e-01, time/batch = 18.5673s	
19195/26050 (epoch 36.843), train_loss = 0.84011674, grad/param norm = 2.0407e-01, time/batch = 18.8171s	
19196/26050 (epoch 36.845), train_loss = 0.79428740, grad/param norm = 1.9743e-01, time/batch = 16.7752s	
19197/26050 (epoch 36.846), train_loss = 0.88481246, grad/param norm = 2.0285e-01, time/batch = 16.9922s	
19198/26050 (epoch 36.848), train_loss = 0.82538990, grad/param norm = 2.0685e-01, time/batch = 18.4812s	
19199/26050 (epoch 36.850), train_loss = 0.75512737, grad/param norm = 1.7868e-01, time/batch = 15.6399s	
19200/26050 (epoch 36.852), train_loss = 0.87170439, grad/param norm = 2.0793e-01, time/batch = 17.8048s	
19201/26050 (epoch 36.854), train_loss = 0.84042803, grad/param norm = 2.1072e-01, time/batch = 18.2266s	
19202/26050 (epoch 36.856), train_loss = 0.80359643, grad/param norm = 2.3596e-01, time/batch = 17.9085s	
19203/26050 (epoch 36.858), train_loss = 0.76527229, grad/param norm = 2.0072e-01, time/batch = 15.4752s	
19204/26050 (epoch 36.860), train_loss = 0.89226361, grad/param norm = 2.3004e-01, time/batch = 18.1667s	
19205/26050 (epoch 36.862), train_loss = 0.91913585, grad/param norm = 2.0403e-01, time/batch = 17.8333s	
19206/26050 (epoch 36.864), train_loss = 0.86329224, grad/param norm = 2.4637e-01, time/batch = 16.3806s	
19207/26050 (epoch 36.866), train_loss = 0.83267770, grad/param norm = 2.0960e-01, time/batch = 17.9698s	
19208/26050 (epoch 36.868), train_loss = 0.91868089, grad/param norm = 2.2223e-01, time/batch = 18.4924s	
19209/26050 (epoch 36.869), train_loss = 0.76242701, grad/param norm = 1.9172e-01, time/batch = 15.7224s	
19210/26050 (epoch 36.871), train_loss = 0.72675381, grad/param norm = 2.0357e-01, time/batch = 19.0609s	
19211/26050 (epoch 36.873), train_loss = 0.89933749, grad/param norm = 2.3365e-01, time/batch = 18.5711s	
19212/26050 (epoch 36.875), train_loss = 0.80154287, grad/param norm = 2.1641e-01, time/batch = 18.5586s	
19213/26050 (epoch 36.877), train_loss = 0.79170173, grad/param norm = 1.9548e-01, time/batch = 17.3902s	
19214/26050 (epoch 36.879), train_loss = 0.87906787, grad/param norm = 2.1040e-01, time/batch = 15.1363s	
19215/26050 (epoch 36.881), train_loss = 0.92150643, grad/param norm = 2.6142e-01, time/batch = 17.7408s	
19216/26050 (epoch 36.883), train_loss = 0.89150044, grad/param norm = 2.1170e-01, time/batch = 16.9864s	
19217/26050 (epoch 36.885), train_loss = 0.65987934, grad/param norm = 2.0547e-01, time/batch = 16.1528s	
19218/26050 (epoch 36.887), train_loss = 0.91739451, grad/param norm = 1.9996e-01, time/batch = 16.8952s	
19219/26050 (epoch 36.889), train_loss = 0.78608334, grad/param norm = 1.9296e-01, time/batch = 18.8986s	
19220/26050 (epoch 36.891), train_loss = 0.70389221, grad/param norm = 1.8078e-01, time/batch = 17.3100s	
19221/26050 (epoch 36.893), train_loss = 0.72170544, grad/param norm = 2.0488e-01, time/batch = 13.7216s	
19222/26050 (epoch 36.894), train_loss = 0.78506366, grad/param norm = 2.0677e-01, time/batch = 14.5006s	
19223/26050 (epoch 36.896), train_loss = 0.91241958, grad/param norm = 2.2031e-01, time/batch = 17.8977s	
19224/26050 (epoch 36.898), train_loss = 0.80579298, grad/param norm = 2.0438e-01, time/batch = 17.7242s	
19225/26050 (epoch 36.900), train_loss = 0.87064848, grad/param norm = 2.3770e-01, time/batch = 17.2854s	
19226/26050 (epoch 36.902), train_loss = 0.81718825, grad/param norm = 2.2439e-01, time/batch = 15.2314s	
19227/26050 (epoch 36.904), train_loss = 0.81409725, grad/param norm = 1.9753e-01, time/batch = 17.9803s	
19228/26050 (epoch 36.906), train_loss = 0.81180489, grad/param norm = 2.3220e-01, time/batch = 16.4686s	
19229/26050 (epoch 36.908), train_loss = 0.87632331, grad/param norm = 2.2143e-01, time/batch = 18.8754s	
19230/26050 (epoch 36.910), train_loss = 0.79040490, grad/param norm = 2.0142e-01, time/batch = 18.1442s	
19231/26050 (epoch 36.912), train_loss = 1.02995609, grad/param norm = 2.5689e-01, time/batch = 18.1397s	
19232/26050 (epoch 36.914), train_loss = 1.14237250, grad/param norm = 2.2924e-01, time/batch = 16.0765s	
19233/26050 (epoch 36.916), train_loss = 0.91990524, grad/param norm = 2.8406e-01, time/batch = 16.2779s	
19234/26050 (epoch 36.917), train_loss = 0.88590670, grad/param norm = 2.3691e-01, time/batch = 16.2185s	
19235/26050 (epoch 36.919), train_loss = 0.88087203, grad/param norm = 2.2764e-01, time/batch = 17.4481s	
19236/26050 (epoch 36.921), train_loss = 0.79702079, grad/param norm = 2.0861e-01, time/batch = 17.4783s	
19237/26050 (epoch 36.923), train_loss = 0.85843673, grad/param norm = 2.1575e-01, time/batch = 17.5707s	
19238/26050 (epoch 36.925), train_loss = 0.85094623, grad/param norm = 2.1735e-01, time/batch = 18.6356s	
19239/26050 (epoch 36.927), train_loss = 0.77487817, grad/param norm = 1.7185e-01, time/batch = 17.8221s	
19240/26050 (epoch 36.929), train_loss = 0.72930164, grad/param norm = 2.0449e-01, time/batch = 17.9944s	
19241/26050 (epoch 36.931), train_loss = 0.99798188, grad/param norm = 2.4399e-01, time/batch = 17.4753s	
19242/26050 (epoch 36.933), train_loss = 0.84124535, grad/param norm = 2.1750e-01, time/batch = 18.3221s	
19243/26050 (epoch 36.935), train_loss = 0.81476985, grad/param norm = 1.9480e-01, time/batch = 18.2417s	
19244/26050 (epoch 36.937), train_loss = 0.91438324, grad/param norm = 2.1840e-01, time/batch = 17.9811s	
19245/26050 (epoch 36.939), train_loss = 0.76941456, grad/param norm = 1.7619e-01, time/batch = 17.8992s	
19246/26050 (epoch 36.940), train_loss = 0.83933488, grad/param norm = 1.9849e-01, time/batch = 16.9568s	
19247/26050 (epoch 36.942), train_loss = 0.81884626, grad/param norm = 2.1678e-01, time/batch = 17.4683s	
19248/26050 (epoch 36.944), train_loss = 0.84094970, grad/param norm = 2.2015e-01, time/batch = 17.9698s	
19249/26050 (epoch 36.946), train_loss = 0.98748023, grad/param norm = 2.0941e-01, time/batch = 16.4050s	
19250/26050 (epoch 36.948), train_loss = 0.73258108, grad/param norm = 2.0771e-01, time/batch = 14.3932s	
19251/26050 (epoch 36.950), train_loss = 0.85797452, grad/param norm = 1.9986e-01, time/batch = 16.4667s	
19252/26050 (epoch 36.952), train_loss = 0.90059249, grad/param norm = 2.1755e-01, time/batch = 17.3830s	
19253/26050 (epoch 36.954), train_loss = 0.90995413, grad/param norm = 2.1528e-01, time/batch = 18.4003s	
19254/26050 (epoch 36.956), train_loss = 0.81922517, grad/param norm = 2.1522e-01, time/batch = 17.8120s	
19255/26050 (epoch 36.958), train_loss = 0.76913846, grad/param norm = 1.8788e-01, time/batch = 18.3930s	
19256/26050 (epoch 36.960), train_loss = 0.86593271, grad/param norm = 1.9743e-01, time/batch = 17.2403s	
19257/26050 (epoch 36.962), train_loss = 0.83570996, grad/param norm = 2.0069e-01, time/batch = 16.2998s	
19258/26050 (epoch 36.964), train_loss = 0.82139990, grad/param norm = 2.0743e-01, time/batch = 17.0725s	
19259/26050 (epoch 36.965), train_loss = 0.76787910, grad/param norm = 1.9920e-01, time/batch = 18.4864s	
19260/26050 (epoch 36.967), train_loss = 1.12217706, grad/param norm = 2.2243e-01, time/batch = 18.8207s	
19261/26050 (epoch 36.969), train_loss = 0.85144398, grad/param norm = 1.9610e-01, time/batch = 17.5592s	
19262/26050 (epoch 36.971), train_loss = 0.84561511, grad/param norm = 1.9899e-01, time/batch = 17.7344s	
19263/26050 (epoch 36.973), train_loss = 0.85780446, grad/param norm = 1.9533e-01, time/batch = 16.6495s	
19264/26050 (epoch 36.975), train_loss = 0.85963848, grad/param norm = 2.1430e-01, time/batch = 14.2073s	
19265/26050 (epoch 36.977), train_loss = 0.84156741, grad/param norm = 1.8064e-01, time/batch = 16.7231s	
19266/26050 (epoch 36.979), train_loss = 0.69721272, grad/param norm = 2.0111e-01, time/batch = 16.9902s	
19267/26050 (epoch 36.981), train_loss = 0.95916002, grad/param norm = 2.1004e-01, time/batch = 18.2473s	
19268/26050 (epoch 36.983), train_loss = 0.90009148, grad/param norm = 2.0585e-01, time/batch = 17.7934s	
19269/26050 (epoch 36.985), train_loss = 0.89518917, grad/param norm = 2.3017e-01, time/batch = 17.9705s	
19270/26050 (epoch 36.987), train_loss = 0.95393160, grad/param norm = 2.1868e-01, time/batch = 18.4831s	
19271/26050 (epoch 36.988), train_loss = 0.88127683, grad/param norm = 2.1538e-01, time/batch = 17.9581s	
19272/26050 (epoch 36.990), train_loss = 0.74074613, grad/param norm = 1.7318e-01, time/batch = 17.6220s	
19273/26050 (epoch 36.992), train_loss = 0.99985550, grad/param norm = 2.4864e-01, time/batch = 16.8754s	
19274/26050 (epoch 36.994), train_loss = 0.77796883, grad/param norm = 2.0748e-01, time/batch = 14.4792s	
19275/26050 (epoch 36.996), train_loss = 0.75296487, grad/param norm = 2.5624e-01, time/batch = 17.7883s	
19276/26050 (epoch 36.998), train_loss = 0.86240871, grad/param norm = 1.9579e-01, time/batch = 18.0728s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
19277/26050 (epoch 37.000), train_loss = 0.80622553, grad/param norm = 2.2974e-01, time/batch = 15.2137s	
19278/26050 (epoch 37.002), train_loss = 0.91497113, grad/param norm = 2.2276e-01, time/batch = 18.2773s	
19279/26050 (epoch 37.004), train_loss = 0.75561418, grad/param norm = 2.0207e-01, time/batch = 18.2149s	
19280/26050 (epoch 37.006), train_loss = 0.79695743, grad/param norm = 2.3329e-01, time/batch = 17.6626s	
19281/26050 (epoch 37.008), train_loss = 0.78749719, grad/param norm = 2.3354e-01, time/batch = 18.5642s	
19282/26050 (epoch 37.010), train_loss = 0.77591680, grad/param norm = 2.1171e-01, time/batch = 24.8044s	
19283/26050 (epoch 37.012), train_loss = 0.83669194, grad/param norm = 2.0934e-01, time/batch = 31.2982s	
19284/26050 (epoch 37.013), train_loss = 1.05770011, grad/param norm = 2.4851e-01, time/batch = 17.1770s	
19285/26050 (epoch 37.015), train_loss = 0.83461754, grad/param norm = 1.9114e-01, time/batch = 18.3091s	
19286/26050 (epoch 37.017), train_loss = 0.87969216, grad/param norm = 1.9328e-01, time/batch = 16.9682s	
19287/26050 (epoch 37.019), train_loss = 0.73844415, grad/param norm = 1.5762e-01, time/batch = 17.6287s	
19288/26050 (epoch 37.021), train_loss = 0.94099784, grad/param norm = 2.1488e-01, time/batch = 17.6543s	
19289/26050 (epoch 37.023), train_loss = 0.71542255, grad/param norm = 2.3264e-01, time/batch = 18.0757s	
19290/26050 (epoch 37.025), train_loss = 0.83450103, grad/param norm = 2.0890e-01, time/batch = 15.1377s	
19291/26050 (epoch 37.027), train_loss = 0.69754066, grad/param norm = 2.1068e-01, time/batch = 16.5443s	
19292/26050 (epoch 37.029), train_loss = 0.87278380, grad/param norm = 1.8397e-01, time/batch = 17.7104s	
19293/26050 (epoch 37.031), train_loss = 0.95484473, grad/param norm = 2.4178e-01, time/batch = 18.0792s	
19294/26050 (epoch 37.033), train_loss = 0.85993338, grad/param norm = 2.1117e-01, time/batch = 16.8784s	
19295/26050 (epoch 37.035), train_loss = 0.87725301, grad/param norm = 1.9090e-01, time/batch = 18.2923s	
19296/26050 (epoch 37.036), train_loss = 0.74525721, grad/param norm = 2.1798e-01, time/batch = 18.0649s	
19297/26050 (epoch 37.038), train_loss = 0.69820800, grad/param norm = 2.0914e-01, time/batch = 18.8964s	
19298/26050 (epoch 37.040), train_loss = 0.83030646, grad/param norm = 2.0429e-01, time/batch = 16.7995s	
19299/26050 (epoch 37.042), train_loss = 0.72031836, grad/param norm = 1.9288e-01, time/batch = 17.1486s	
19300/26050 (epoch 37.044), train_loss = 0.91834590, grad/param norm = 2.0696e-01, time/batch = 17.2075s	
19301/26050 (epoch 37.046), train_loss = 0.71539685, grad/param norm = 1.7320e-01, time/batch = 17.4780s	
19302/26050 (epoch 37.048), train_loss = 0.81761835, grad/param norm = 1.9634e-01, time/batch = 18.2360s	
19303/26050 (epoch 37.050), train_loss = 0.79292731, grad/param norm = 1.9877e-01, time/batch = 18.7205s	
19304/26050 (epoch 37.052), train_loss = 0.76530151, grad/param norm = 2.1935e-01, time/batch = 18.1456s	
19305/26050 (epoch 37.054), train_loss = 0.70384283, grad/param norm = 1.9821e-01, time/batch = 18.5621s	
19306/26050 (epoch 37.056), train_loss = 0.67482004, grad/param norm = 1.6421e-01, time/batch = 17.7263s	
19307/26050 (epoch 37.058), train_loss = 0.81407651, grad/param norm = 1.9868e-01, time/batch = 18.3192s	
19308/26050 (epoch 37.060), train_loss = 0.86502810, grad/param norm = 1.8768e-01, time/batch = 18.0537s	
19309/26050 (epoch 37.061), train_loss = 0.74089652, grad/param norm = 2.0996e-01, time/batch = 18.7236s	
19310/26050 (epoch 37.063), train_loss = 0.82782694, grad/param norm = 1.9572e-01, time/batch = 17.9865s	
19311/26050 (epoch 37.065), train_loss = 0.68950752, grad/param norm = 1.9155e-01, time/batch = 15.3732s	
19312/26050 (epoch 37.067), train_loss = 0.82329741, grad/param norm = 2.0217e-01, time/batch = 14.1618s	
19313/26050 (epoch 37.069), train_loss = 0.86177664, grad/param norm = 2.3840e-01, time/batch = 14.8178s	
19314/26050 (epoch 37.071), train_loss = 0.86072558, grad/param norm = 2.0666e-01, time/batch = 15.5318s	
19315/26050 (epoch 37.073), train_loss = 0.97155273, grad/param norm = 1.9986e-01, time/batch = 16.9707s	
19316/26050 (epoch 37.075), train_loss = 0.79546961, grad/param norm = 2.0343e-01, time/batch = 17.9876s	
19317/26050 (epoch 37.077), train_loss = 0.77535973, grad/param norm = 2.1679e-01, time/batch = 17.8963s	
19318/26050 (epoch 37.079), train_loss = 0.80208672, grad/param norm = 2.0715e-01, time/batch = 18.3155s	
19319/26050 (epoch 37.081), train_loss = 0.81989212, grad/param norm = 2.0485e-01, time/batch = 18.2346s	
19320/26050 (epoch 37.083), train_loss = 0.93117161, grad/param norm = 2.0634e-01, time/batch = 17.4837s	
19321/26050 (epoch 37.084), train_loss = 0.85547008, grad/param norm = 2.5132e-01, time/batch = 17.7092s	
19322/26050 (epoch 37.086), train_loss = 0.96859003, grad/param norm = 2.4427e-01, time/batch = 16.1202s	
19323/26050 (epoch 37.088), train_loss = 0.82898828, grad/param norm = 2.1796e-01, time/batch = 18.6458s	
19324/26050 (epoch 37.090), train_loss = 0.87420125, grad/param norm = 2.2442e-01, time/batch = 18.8116s	
19325/26050 (epoch 37.092), train_loss = 0.87541191, grad/param norm = 1.9614e-01, time/batch = 17.3029s	
19326/26050 (epoch 37.094), train_loss = 0.71967293, grad/param norm = 1.9816e-01, time/batch = 17.7427s	
19327/26050 (epoch 37.096), train_loss = 0.86741347, grad/param norm = 1.9696e-01, time/batch = 16.9914s	
19328/26050 (epoch 37.098), train_loss = 0.82879882, grad/param norm = 2.0047e-01, time/batch = 14.5289s	
19329/26050 (epoch 37.100), train_loss = 0.76005326, grad/param norm = 2.0773e-01, time/batch = 17.8166s	
19330/26050 (epoch 37.102), train_loss = 0.84403085, grad/param norm = 2.1628e-01, time/batch = 18.2386s	
19331/26050 (epoch 37.104), train_loss = 0.80295490, grad/param norm = 2.0684e-01, time/batch = 18.4073s	
19332/26050 (epoch 37.106), train_loss = 0.90794349, grad/param norm = 2.5593e-01, time/batch = 17.0551s	
19333/26050 (epoch 37.107), train_loss = 0.69200367, grad/param norm = 1.9183e-01, time/batch = 15.2199s	
19334/26050 (epoch 37.109), train_loss = 0.77427768, grad/param norm = 1.8577e-01, time/batch = 17.8148s	
19335/26050 (epoch 37.111), train_loss = 0.96638730, grad/param norm = 2.2431e-01, time/batch = 18.2208s	
19336/26050 (epoch 37.113), train_loss = 0.79934180, grad/param norm = 1.8960e-01, time/batch = 18.1511s	
19337/26050 (epoch 37.115), train_loss = 0.93476636, grad/param norm = 2.1142e-01, time/batch = 15.1446s	
19338/26050 (epoch 37.117), train_loss = 0.84764582, grad/param norm = 2.2136e-01, time/batch = 18.8051s	
19339/26050 (epoch 37.119), train_loss = 0.72564926, grad/param norm = 1.7977e-01, time/batch = 17.3111s	
19340/26050 (epoch 37.121), train_loss = 0.83085909, grad/param norm = 1.8665e-01, time/batch = 18.3131s	
19341/26050 (epoch 37.123), train_loss = 0.75225098, grad/param norm = 1.9559e-01, time/batch = 14.6685s	
19342/26050 (epoch 37.125), train_loss = 0.71739511, grad/param norm = 1.8721e-01, time/batch = 17.4877s	
19343/26050 (epoch 37.127), train_loss = 0.69359515, grad/param norm = 1.9867e-01, time/batch = 16.0724s	
19344/26050 (epoch 37.129), train_loss = 0.67128175, grad/param norm = 2.1007e-01, time/batch = 15.7918s	
19345/26050 (epoch 37.131), train_loss = 0.81871094, grad/param norm = 2.0645e-01, time/batch = 16.6474s	
19346/26050 (epoch 37.132), train_loss = 0.83088580, grad/param norm = 2.0178e-01, time/batch = 16.6298s	
19347/26050 (epoch 37.134), train_loss = 0.87524869, grad/param norm = 2.3806e-01, time/batch = 17.8122s	
19348/26050 (epoch 37.136), train_loss = 0.80580946, grad/param norm = 1.9702e-01, time/batch = 18.5749s	
19349/26050 (epoch 37.138), train_loss = 0.58303161, grad/param norm = 1.8778e-01, time/batch = 17.6495s	
19350/26050 (epoch 37.140), train_loss = 0.68414484, grad/param norm = 2.3463e-01, time/batch = 17.9038s	
19351/26050 (epoch 37.142), train_loss = 0.71511980, grad/param norm = 1.9862e-01, time/batch = 15.3127s	
19352/26050 (epoch 37.144), train_loss = 0.66638462, grad/param norm = 2.3582e-01, time/batch = 18.3124s	
19353/26050 (epoch 37.146), train_loss = 0.63300454, grad/param norm = 1.8061e-01, time/batch = 17.6270s	
19354/26050 (epoch 37.148), train_loss = 0.64784743, grad/param norm = 1.8142e-01, time/batch = 18.2477s	
19355/26050 (epoch 37.150), train_loss = 0.76793648, grad/param norm = 2.0465e-01, time/batch = 18.4764s	
19356/26050 (epoch 37.152), train_loss = 0.93513264, grad/param norm = 2.7967e-01, time/batch = 17.8164s	
19357/26050 (epoch 37.154), train_loss = 0.65702115, grad/param norm = 1.8635e-01, time/batch = 15.1399s	
19358/26050 (epoch 37.155), train_loss = 0.70173981, grad/param norm = 1.8135e-01, time/batch = 17.9119s	
19359/26050 (epoch 37.157), train_loss = 0.80075976, grad/param norm = 2.7045e-01, time/batch = 17.8894s	
19360/26050 (epoch 37.159), train_loss = 0.86711925, grad/param norm = 2.3487e-01, time/batch = 17.3992s	
19361/26050 (epoch 37.161), train_loss = 0.81318248, grad/param norm = 2.1448e-01, time/batch = 18.6475s	
19362/26050 (epoch 37.163), train_loss = 0.69134450, grad/param norm = 1.9784e-01, time/batch = 17.5642s	
19363/26050 (epoch 37.165), train_loss = 0.62673803, grad/param norm = 1.9959e-01, time/batch = 16.2203s	
19364/26050 (epoch 37.167), train_loss = 0.96426413, grad/param norm = 2.4901e-01, time/batch = 18.0545s	
19365/26050 (epoch 37.169), train_loss = 0.82197039, grad/param norm = 2.1420e-01, time/batch = 18.3970s	
19366/26050 (epoch 37.171), train_loss = 0.73425632, grad/param norm = 1.8077e-01, time/batch = 16.2134s	
19367/26050 (epoch 37.173), train_loss = 0.78841686, grad/param norm = 2.0980e-01, time/batch = 15.2862s	
19368/26050 (epoch 37.175), train_loss = 0.81357150, grad/param norm = 2.0074e-01, time/batch = 17.5627s	
19369/26050 (epoch 37.177), train_loss = 0.88676417, grad/param norm = 2.0685e-01, time/batch = 17.5803s	
19370/26050 (epoch 37.179), train_loss = 0.61423287, grad/param norm = 1.8032e-01, time/batch = 16.7308s	
19371/26050 (epoch 37.180), train_loss = 1.03419436, grad/param norm = 2.0687e-01, time/batch = 18.1561s	
19372/26050 (epoch 37.182), train_loss = 0.98482559, grad/param norm = 2.4357e-01, time/batch = 18.7327s	
19373/26050 (epoch 37.184), train_loss = 0.85021155, grad/param norm = 2.1619e-01, time/batch = 18.3151s	
19374/26050 (epoch 37.186), train_loss = 0.69903078, grad/param norm = 1.9305e-01, time/batch = 18.2385s	
19375/26050 (epoch 37.188), train_loss = 0.87966092, grad/param norm = 2.1843e-01, time/batch = 18.0743s	
19376/26050 (epoch 37.190), train_loss = 0.85565669, grad/param norm = 2.0665e-01, time/batch = 17.0661s	
19377/26050 (epoch 37.192), train_loss = 0.90723388, grad/param norm = 1.8421e-01, time/batch = 16.8904s	
19378/26050 (epoch 37.194), train_loss = 0.85498659, grad/param norm = 2.0583e-01, time/batch = 17.2898s	
19379/26050 (epoch 37.196), train_loss = 0.89040113, grad/param norm = 2.1772e-01, time/batch = 16.8051s	
19380/26050 (epoch 37.198), train_loss = 0.75258341, grad/param norm = 1.8507e-01, time/batch = 16.4725s	
19381/26050 (epoch 37.200), train_loss = 0.74115773, grad/param norm = 2.0939e-01, time/batch = 17.1466s	
19382/26050 (epoch 37.202), train_loss = 0.83845659, grad/param norm = 1.9546e-01, time/batch = 17.8993s	
19383/26050 (epoch 37.203), train_loss = 0.92406474, grad/param norm = 2.0055e-01, time/batch = 18.7169s	
19384/26050 (epoch 37.205), train_loss = 0.77727680, grad/param norm = 2.1114e-01, time/batch = 18.1495s	
19385/26050 (epoch 37.207), train_loss = 0.75065716, grad/param norm = 2.1957e-01, time/batch = 17.7098s	
19386/26050 (epoch 37.209), train_loss = 0.89633996, grad/param norm = 2.0780e-01, time/batch = 16.9624s	
19387/26050 (epoch 37.211), train_loss = 0.71702588, grad/param norm = 1.9636e-01, time/batch = 17.8997s	
19388/26050 (epoch 37.213), train_loss = 0.85959601, grad/param norm = 2.5573e-01, time/batch = 18.2409s	
19389/26050 (epoch 37.215), train_loss = 0.82927088, grad/param norm = 2.3961e-01, time/batch = 17.4858s	
19390/26050 (epoch 37.217), train_loss = 0.77836779, grad/param norm = 1.8723e-01, time/batch = 18.3214s	
19391/26050 (epoch 37.219), train_loss = 0.79838766, grad/param norm = 2.3469e-01, time/batch = 18.0632s	
19392/26050 (epoch 37.221), train_loss = 0.74119471, grad/param norm = 2.2433e-01, time/batch = 17.9060s	
19393/26050 (epoch 37.223), train_loss = 0.90592906, grad/param norm = 2.2970e-01, time/batch = 15.3849s	
19394/26050 (epoch 37.225), train_loss = 0.74293681, grad/param norm = 2.2138e-01, time/batch = 16.6609s	
19395/26050 (epoch 37.226), train_loss = 0.85406887, grad/param norm = 2.4116e-01, time/batch = 17.8215s	
19396/26050 (epoch 37.228), train_loss = 0.96272384, grad/param norm = 2.2596e-01, time/batch = 14.8108s	
19397/26050 (epoch 37.230), train_loss = 0.83098805, grad/param norm = 1.7966e-01, time/batch = 17.7397s	
19398/26050 (epoch 37.232), train_loss = 0.92688795, grad/param norm = 2.4521e-01, time/batch = 17.8123s	
19399/26050 (epoch 37.234), train_loss = 0.72631653, grad/param norm = 1.8918e-01, time/batch = 15.0465s	
19400/26050 (epoch 37.236), train_loss = 0.89909731, grad/param norm = 2.1361e-01, time/batch = 17.0620s	
19401/26050 (epoch 37.238), train_loss = 0.70683843, grad/param norm = 2.0127e-01, time/batch = 17.0492s	
19402/26050 (epoch 37.240), train_loss = 0.83665016, grad/param norm = 2.1490e-01, time/batch = 17.2314s	
19403/26050 (epoch 37.242), train_loss = 0.79317605, grad/param norm = 1.9929e-01, time/batch = 18.6435s	
19404/26050 (epoch 37.244), train_loss = 0.84621476, grad/param norm = 2.3569e-01, time/batch = 16.8193s	
19405/26050 (epoch 37.246), train_loss = 0.79709249, grad/param norm = 2.2267e-01, time/batch = 17.5487s	
19406/26050 (epoch 37.248), train_loss = 0.83707962, grad/param norm = 2.2167e-01, time/batch = 17.6505s	
19407/26050 (epoch 37.250), train_loss = 0.83096868, grad/param norm = 2.2401e-01, time/batch = 17.3798s	
19408/26050 (epoch 37.251), train_loss = 0.78102063, grad/param norm = 2.1744e-01, time/batch = 17.4728s	
19409/26050 (epoch 37.253), train_loss = 0.72199138, grad/param norm = 1.8272e-01, time/batch = 18.6546s	
19410/26050 (epoch 37.255), train_loss = 0.99847325, grad/param norm = 2.5725e-01, time/batch = 18.3292s	
19411/26050 (epoch 37.257), train_loss = 0.82279368, grad/param norm = 2.2012e-01, time/batch = 17.3178s	
19412/26050 (epoch 37.259), train_loss = 0.93575162, grad/param norm = 2.2493e-01, time/batch = 15.8187s	
19413/26050 (epoch 37.261), train_loss = 0.73118576, grad/param norm = 2.0914e-01, time/batch = 17.8815s	
19414/26050 (epoch 37.263), train_loss = 0.94231711, grad/param norm = 2.3875e-01, time/batch = 18.2259s	
19415/26050 (epoch 37.265), train_loss = 0.95587250, grad/param norm = 3.1481e-01, time/batch = 15.7368s	
19416/26050 (epoch 37.267), train_loss = 0.95946707, grad/param norm = 2.2031e-01, time/batch = 17.9899s	
19417/26050 (epoch 37.269), train_loss = 0.96392822, grad/param norm = 2.2610e-01, time/batch = 17.8171s	
19418/26050 (epoch 37.271), train_loss = 0.84128382, grad/param norm = 2.1093e-01, time/batch = 17.6428s	
19419/26050 (epoch 37.273), train_loss = 0.76471148, grad/param norm = 2.2243e-01, time/batch = 17.1322s	
19420/26050 (epoch 37.274), train_loss = 0.81444687, grad/param norm = 2.0733e-01, time/batch = 18.7278s	
19421/26050 (epoch 37.276), train_loss = 0.80886837, grad/param norm = 2.2922e-01, time/batch = 16.6215s	
19422/26050 (epoch 37.278), train_loss = 0.89938781, grad/param norm = 2.0942e-01, time/batch = 18.0752s	
19423/26050 (epoch 37.280), train_loss = 0.82321751, grad/param norm = 2.0876e-01, time/batch = 17.8016s	
19424/26050 (epoch 37.282), train_loss = 0.89048215, grad/param norm = 1.9280e-01, time/batch = 18.4763s	
19425/26050 (epoch 37.284), train_loss = 0.81660376, grad/param norm = 2.1186e-01, time/batch = 18.0549s	
19426/26050 (epoch 37.286), train_loss = 0.86952907, grad/param norm = 2.2058e-01, time/batch = 17.5742s	
19427/26050 (epoch 37.288), train_loss = 0.71814877, grad/param norm = 1.8666e-01, time/batch = 17.1206s	
19428/26050 (epoch 37.290), train_loss = 0.83318340, grad/param norm = 1.9406e-01, time/batch = 16.6429s	
19429/26050 (epoch 37.292), train_loss = 0.77399579, grad/param norm = 2.0916e-01, time/batch = 18.4787s	
19430/26050 (epoch 37.294), train_loss = 0.83446612, grad/param norm = 2.3548e-01, time/batch = 18.0693s	
19431/26050 (epoch 37.296), train_loss = 0.92241090, grad/param norm = 2.1333e-01, time/batch = 17.6449s	
19432/26050 (epoch 37.298), train_loss = 0.86674735, grad/param norm = 2.0061e-01, time/batch = 17.6505s	
19433/26050 (epoch 37.299), train_loss = 0.70535470, grad/param norm = 1.8301e-01, time/batch = 18.0557s	
19434/26050 (epoch 37.301), train_loss = 0.70342691, grad/param norm = 1.9331e-01, time/batch = 15.1288s	
19435/26050 (epoch 37.303), train_loss = 0.85365131, grad/param norm = 2.6298e-01, time/batch = 15.4661s	
19436/26050 (epoch 37.305), train_loss = 0.69202924, grad/param norm = 1.9044e-01, time/batch = 17.5660s	
19437/26050 (epoch 37.307), train_loss = 0.74464055, grad/param norm = 2.1277e-01, time/batch = 17.9070s	
19438/26050 (epoch 37.309), train_loss = 0.83313012, grad/param norm = 2.0752e-01, time/batch = 17.9706s	
19439/26050 (epoch 37.311), train_loss = 0.85904380, grad/param norm = 2.7595e-01, time/batch = 15.2556s	
19440/26050 (epoch 37.313), train_loss = 0.82846927, grad/param norm = 2.6980e-01, time/batch = 16.2269s	
19441/26050 (epoch 37.315), train_loss = 0.89106169, grad/param norm = 1.9101e-01, time/batch = 17.4015s	
19442/26050 (epoch 37.317), train_loss = 0.84695329, grad/param norm = 2.8067e-01, time/batch = 17.7405s	
19443/26050 (epoch 37.319), train_loss = 0.77695263, grad/param norm = 2.1187e-01, time/batch = 18.1581s	
19444/26050 (epoch 37.321), train_loss = 0.82152496, grad/param norm = 2.1009e-01, time/batch = 17.8938s	
19445/26050 (epoch 37.322), train_loss = 0.89899088, grad/param norm = 2.2586e-01, time/batch = 16.8943s	
19446/26050 (epoch 37.324), train_loss = 0.66881328, grad/param norm = 1.9973e-01, time/batch = 17.6204s	
19447/26050 (epoch 37.326), train_loss = 0.93686502, grad/param norm = 2.2713e-01, time/batch = 16.3910s	
19448/26050 (epoch 37.328), train_loss = 0.87314142, grad/param norm = 2.1113e-01, time/batch = 18.1468s	
19449/26050 (epoch 37.330), train_loss = 0.72945540, grad/param norm = 2.1292e-01, time/batch = 16.9731s	
19450/26050 (epoch 37.332), train_loss = 0.89175070, grad/param norm = 2.2039e-01, time/batch = 18.3137s	
19451/26050 (epoch 37.334), train_loss = 0.74602006, grad/param norm = 2.1654e-01, time/batch = 18.2295s	
19452/26050 (epoch 37.336), train_loss = 0.78690056, grad/param norm = 2.1872e-01, time/batch = 17.5535s	
19453/26050 (epoch 37.338), train_loss = 0.69915610, grad/param norm = 1.7757e-01, time/batch = 14.3951s	
19454/26050 (epoch 37.340), train_loss = 0.87492603, grad/param norm = 2.2792e-01, time/batch = 18.1393s	
19455/26050 (epoch 37.342), train_loss = 0.91370961, grad/param norm = 2.1096e-01, time/batch = 15.9718s	
19456/26050 (epoch 37.344), train_loss = 0.76067654, grad/param norm = 2.2102e-01, time/batch = 17.7123s	
19457/26050 (epoch 37.345), train_loss = 0.80377185, grad/param norm = 2.0928e-01, time/batch = 16.9699s	
19458/26050 (epoch 37.347), train_loss = 0.93603691, grad/param norm = 2.2241e-01, time/batch = 18.6336s	
19459/26050 (epoch 37.349), train_loss = 0.86582488, grad/param norm = 1.9915e-01, time/batch = 17.7370s	
19460/26050 (epoch 37.351), train_loss = 0.83644863, grad/param norm = 2.1779e-01, time/batch = 16.7328s	
19461/26050 (epoch 37.353), train_loss = 0.84682489, grad/param norm = 2.2155e-01, time/batch = 18.0299s	
19462/26050 (epoch 37.355), train_loss = 0.82516416, grad/param norm = 2.3467e-01, time/batch = 18.2253s	
19463/26050 (epoch 37.357), train_loss = 0.78937809, grad/param norm = 1.9362e-01, time/batch = 18.2364s	
19464/26050 (epoch 37.359), train_loss = 0.91321205, grad/param norm = 2.1662e-01, time/batch = 16.4775s	
19465/26050 (epoch 37.361), train_loss = 0.73401445, grad/param norm = 1.7911e-01, time/batch = 17.0493s	
19466/26050 (epoch 37.363), train_loss = 0.89961450, grad/param norm = 2.1549e-01, time/batch = 17.3203s	
19467/26050 (epoch 37.365), train_loss = 0.82301018, grad/param norm = 2.1366e-01, time/batch = 18.7336s	
19468/26050 (epoch 37.367), train_loss = 0.89071388, grad/param norm = 1.9740e-01, time/batch = 18.2432s	
19469/26050 (epoch 37.369), train_loss = 0.73688502, grad/param norm = 1.7480e-01, time/batch = 17.3848s	
19470/26050 (epoch 37.370), train_loss = 0.73206597, grad/param norm = 1.7163e-01, time/batch = 17.1327s	
19471/26050 (epoch 37.372), train_loss = 0.81133212, grad/param norm = 2.0820e-01, time/batch = 16.9076s	
19472/26050 (epoch 37.374), train_loss = 0.94093972, grad/param norm = 2.0032e-01, time/batch = 14.8912s	
19473/26050 (epoch 37.376), train_loss = 0.95765661, grad/param norm = 2.8662e-01, time/batch = 16.8908s	
19474/26050 (epoch 37.378), train_loss = 0.79022731, grad/param norm = 1.9471e-01, time/batch = 18.8045s	
19475/26050 (epoch 37.380), train_loss = 0.93887142, grad/param norm = 2.5314e-01, time/batch = 18.2326s	
19476/26050 (epoch 37.382), train_loss = 1.05898256, grad/param norm = 3.0388e-01, time/batch = 15.3720s	
19477/26050 (epoch 37.384), train_loss = 0.79910558, grad/param norm = 2.1408e-01, time/batch = 18.6466s	
19478/26050 (epoch 37.386), train_loss = 0.89229045, grad/param norm = 2.3867e-01, time/batch = 17.4991s	
19479/26050 (epoch 37.388), train_loss = 0.86608708, grad/param norm = 3.0142e-01, time/batch = 17.8163s	
19480/26050 (epoch 37.390), train_loss = 0.78472801, grad/param norm = 1.8562e-01, time/batch = 18.3921s	
19481/26050 (epoch 37.392), train_loss = 0.73646587, grad/param norm = 1.9560e-01, time/batch = 18.3237s	
19482/26050 (epoch 37.393), train_loss = 0.89876171, grad/param norm = 2.5863e-01, time/batch = 17.8223s	
19483/26050 (epoch 37.395), train_loss = 0.88995550, grad/param norm = 2.5497e-01, time/batch = 17.3067s	
19484/26050 (epoch 37.397), train_loss = 0.89864007, grad/param norm = 2.5351e-01, time/batch = 16.2326s	
19485/26050 (epoch 37.399), train_loss = 0.79540222, grad/param norm = 2.2591e-01, time/batch = 18.5468s	
19486/26050 (epoch 37.401), train_loss = 0.84876583, grad/param norm = 2.1118e-01, time/batch = 19.0394s	
19487/26050 (epoch 37.403), train_loss = 0.87159082, grad/param norm = 2.3629e-01, time/batch = 32.5888s	
19488/26050 (epoch 37.405), train_loss = 0.86536512, grad/param norm = 2.3532e-01, time/batch = 22.7356s	
19489/26050 (epoch 37.407), train_loss = 0.96336310, grad/param norm = 2.3778e-01, time/batch = 17.5979s	
19490/26050 (epoch 37.409), train_loss = 0.95576301, grad/param norm = 2.5723e-01, time/batch = 15.8180s	
19491/26050 (epoch 37.411), train_loss = 0.95283654, grad/param norm = 2.3416e-01, time/batch = 18.5541s	
19492/26050 (epoch 37.413), train_loss = 1.00643494, grad/param norm = 2.2863e-01, time/batch = 17.7378s	
19493/26050 (epoch 37.415), train_loss = 1.02091994, grad/param norm = 2.4202e-01, time/batch = 18.3167s	
19494/26050 (epoch 37.417), train_loss = 1.01102646, grad/param norm = 2.6320e-01, time/batch = 17.4871s	
19495/26050 (epoch 37.418), train_loss = 0.91398544, grad/param norm = 2.3747e-01, time/batch = 17.4846s	
19496/26050 (epoch 37.420), train_loss = 0.73697590, grad/param norm = 1.8566e-01, time/batch = 14.5724s	
19497/26050 (epoch 37.422), train_loss = 0.72189541, grad/param norm = 2.0386e-01, time/batch = 17.9005s	
19498/26050 (epoch 37.424), train_loss = 0.92885801, grad/param norm = 2.1607e-01, time/batch = 17.1194s	
19499/26050 (epoch 37.426), train_loss = 0.90474246, grad/param norm = 2.3221e-01, time/batch = 17.0657s	
19500/26050 (epoch 37.428), train_loss = 0.82485173, grad/param norm = 2.0851e-01, time/batch = 16.1270s	
19501/26050 (epoch 37.430), train_loss = 0.99434818, grad/param norm = 2.3191e-01, time/batch = 18.2175s	
19502/26050 (epoch 37.432), train_loss = 0.82011530, grad/param norm = 2.0751e-01, time/batch = 17.8828s	
19503/26050 (epoch 37.434), train_loss = 0.80811811, grad/param norm = 2.3603e-01, time/batch = 18.4165s	
19504/26050 (epoch 37.436), train_loss = 0.92795489, grad/param norm = 2.1551e-01, time/batch = 17.8147s	
19505/26050 (epoch 37.438), train_loss = 0.87071223, grad/param norm = 2.4245e-01, time/batch = 17.0343s	
19506/26050 (epoch 37.440), train_loss = 0.88163225, grad/param norm = 2.0990e-01, time/batch = 17.7315s	
19507/26050 (epoch 37.441), train_loss = 0.88377762, grad/param norm = 2.1301e-01, time/batch = 18.0776s	
19508/26050 (epoch 37.443), train_loss = 0.72478241, grad/param norm = 1.6265e-01, time/batch = 17.9615s	
19509/26050 (epoch 37.445), train_loss = 0.74713471, grad/param norm = 2.1048e-01, time/batch = 15.8733s	
19510/26050 (epoch 37.447), train_loss = 0.97304868, grad/param norm = 2.1370e-01, time/batch = 14.6229s	
19511/26050 (epoch 37.449), train_loss = 0.76384898, grad/param norm = 2.1543e-01, time/batch = 17.9639s	
19512/26050 (epoch 37.451), train_loss = 0.98728521, grad/param norm = 2.3721e-01, time/batch = 17.4122s	
19513/26050 (epoch 37.453), train_loss = 0.79009323, grad/param norm = 1.7272e-01, time/batch = 17.6534s	
19514/26050 (epoch 37.455), train_loss = 0.84902331, grad/param norm = 2.1041e-01, time/batch = 18.7437s	
19515/26050 (epoch 37.457), train_loss = 0.82682971, grad/param norm = 2.2618e-01, time/batch = 18.6580s	
19516/26050 (epoch 37.459), train_loss = 0.94530348, grad/param norm = 2.2468e-01, time/batch = 17.5629s	
19517/26050 (epoch 37.461), train_loss = 0.95065412, grad/param norm = 2.3366e-01, time/batch = 18.3133s	
19518/26050 (epoch 37.463), train_loss = 0.81048435, grad/param norm = 1.8253e-01, time/batch = 18.3986s	
19519/26050 (epoch 37.464), train_loss = 0.86442255, grad/param norm = 2.0590e-01, time/batch = 14.7655s	
19520/26050 (epoch 37.466), train_loss = 0.86502352, grad/param norm = 2.3535e-01, time/batch = 17.7987s	
19521/26050 (epoch 37.468), train_loss = 0.95228405, grad/param norm = 1.9024e-01, time/batch = 16.8104s	
19522/26050 (epoch 37.470), train_loss = 0.95130444, grad/param norm = 2.8140e-01, time/batch = 17.5470s	
19523/26050 (epoch 37.472), train_loss = 0.95280873, grad/param norm = 2.5779e-01, time/batch = 17.5499s	
19524/26050 (epoch 37.474), train_loss = 0.96065929, grad/param norm = 2.2094e-01, time/batch = 17.1476s	
19525/26050 (epoch 37.476), train_loss = 0.93255658, grad/param norm = 2.1520e-01, time/batch = 17.4064s	
19526/26050 (epoch 37.478), train_loss = 0.81187849, grad/param norm = 2.0216e-01, time/batch = 17.9737s	
19527/26050 (epoch 37.480), train_loss = 0.82065173, grad/param norm = 2.0040e-01, time/batch = 18.5634s	
19528/26050 (epoch 37.482), train_loss = 0.80315312, grad/param norm = 1.8587e-01, time/batch = 17.2416s	
19529/26050 (epoch 37.484), train_loss = 0.79862055, grad/param norm = 2.2272e-01, time/batch = 18.1403s	
19530/26050 (epoch 37.486), train_loss = 0.95781999, grad/param norm = 2.0834e-01, time/batch = 15.1166s	
19531/26050 (epoch 37.488), train_loss = 1.00792420, grad/param norm = 2.4216e-01, time/batch = 18.0645s	
19532/26050 (epoch 37.489), train_loss = 1.01152380, grad/param norm = 2.6122e-01, time/batch = 17.9922s	
19533/26050 (epoch 37.491), train_loss = 0.78657115, grad/param norm = 2.2015e-01, time/batch = 15.3117s	
19534/26050 (epoch 37.493), train_loss = 0.86905525, grad/param norm = 2.2703e-01, time/batch = 18.4914s	
19535/26050 (epoch 37.495), train_loss = 0.84288455, grad/param norm = 2.0457e-01, time/batch = 18.1529s	
19536/26050 (epoch 37.497), train_loss = 0.77432875, grad/param norm = 1.9551e-01, time/batch = 18.3257s	
19537/26050 (epoch 37.499), train_loss = 0.79107091, grad/param norm = 2.4779e-01, time/batch = 5.2439s	
19538/26050 (epoch 37.501), train_loss = 0.94696499, grad/param norm = 1.9874e-01, time/batch = 0.6428s	
19539/26050 (epoch 37.503), train_loss = 0.81908059, grad/param norm = 2.2736e-01, time/batch = 0.6418s	
19540/26050 (epoch 37.505), train_loss = 0.93854322, grad/param norm = 2.0730e-01, time/batch = 0.6427s	
19541/26050 (epoch 37.507), train_loss = 0.92059165, grad/param norm = 2.1442e-01, time/batch = 0.6571s	
19542/26050 (epoch 37.509), train_loss = 0.97901195, grad/param norm = 2.2637e-01, time/batch = 0.6463s	
19543/26050 (epoch 37.511), train_loss = 0.84409691, grad/param norm = 2.0563e-01, time/batch = 0.6439s	
19544/26050 (epoch 37.512), train_loss = 0.74660498, grad/param norm = 2.1217e-01, time/batch = 0.6623s	
19545/26050 (epoch 37.514), train_loss = 0.88809934, grad/param norm = 2.3076e-01, time/batch = 0.9434s	
19546/26050 (epoch 37.516), train_loss = 0.97469970, grad/param norm = 2.2098e-01, time/batch = 0.9874s	
19547/26050 (epoch 37.518), train_loss = 0.82625569, grad/param norm = 1.9788e-01, time/batch = 0.9653s	
19548/26050 (epoch 37.520), train_loss = 0.87220099, grad/param norm = 2.2412e-01, time/batch = 0.9474s	
19549/26050 (epoch 37.522), train_loss = 0.67639050, grad/param norm = 1.9520e-01, time/batch = 0.9437s	
19550/26050 (epoch 37.524), train_loss = 0.95745475, grad/param norm = 2.8828e-01, time/batch = 1.6373s	
19551/26050 (epoch 37.526), train_loss = 0.94025126, grad/param norm = 2.1538e-01, time/batch = 1.8006s	
19552/26050 (epoch 37.528), train_loss = 0.88038575, grad/param norm = 2.3243e-01, time/batch = 3.1948s	
19553/26050 (epoch 37.530), train_loss = 0.83147144, grad/param norm = 2.3705e-01, time/batch = 17.6558s	
19554/26050 (epoch 37.532), train_loss = 0.87317700, grad/param norm = 2.0289e-01, time/batch = 15.6466s	
19555/26050 (epoch 37.534), train_loss = 0.87056354, grad/param norm = 2.4264e-01, time/batch = 16.5534s	
19556/26050 (epoch 37.536), train_loss = 0.89239216, grad/param norm = 2.2135e-01, time/batch = 18.4156s	
19557/26050 (epoch 37.537), train_loss = 0.92345331, grad/param norm = 2.1167e-01, time/batch = 18.2357s	
19558/26050 (epoch 37.539), train_loss = 0.87451833, grad/param norm = 2.1559e-01, time/batch = 17.2167s	
19559/26050 (epoch 37.541), train_loss = 0.99780829, grad/param norm = 2.3600e-01, time/batch = 17.2307s	
19560/26050 (epoch 37.543), train_loss = 0.67880472, grad/param norm = 2.3288e-01, time/batch = 16.4868s	
19561/26050 (epoch 37.545), train_loss = 0.85818004, grad/param norm = 2.1277e-01, time/batch = 16.2147s	
19562/26050 (epoch 37.547), train_loss = 0.82565822, grad/param norm = 2.1637e-01, time/batch = 17.8783s	
19563/26050 (epoch 37.549), train_loss = 0.73300477, grad/param norm = 2.3643e-01, time/batch = 17.9674s	
19564/26050 (epoch 37.551), train_loss = 0.89871110, grad/param norm = 2.0130e-01, time/batch = 18.0790s	
19565/26050 (epoch 37.553), train_loss = 0.81960339, grad/param norm = 2.2854e-01, time/batch = 17.4013s	
19566/26050 (epoch 37.555), train_loss = 0.77497392, grad/param norm = 2.2733e-01, time/batch = 18.8318s	
19567/26050 (epoch 37.557), train_loss = 0.86663419, grad/param norm = 1.8192e-01, time/batch = 18.0697s	
19568/26050 (epoch 37.559), train_loss = 0.86070899, grad/param norm = 2.0272e-01, time/batch = 14.8218s	
19569/26050 (epoch 37.560), train_loss = 0.82441338, grad/param norm = 2.2491e-01, time/batch = 17.3077s	
19570/26050 (epoch 37.562), train_loss = 0.84014097, grad/param norm = 2.2321e-01, time/batch = 17.8155s	
19571/26050 (epoch 37.564), train_loss = 1.00785368, grad/param norm = 2.1878e-01, time/batch = 18.8173s	
19572/26050 (epoch 37.566), train_loss = 0.80278282, grad/param norm = 1.8545e-01, time/batch = 17.0680s	
19573/26050 (epoch 37.568), train_loss = 0.90486480, grad/param norm = 2.3915e-01, time/batch = 18.1547s	
19574/26050 (epoch 37.570), train_loss = 0.86751264, grad/param norm = 2.2838e-01, time/batch = 18.1514s	
19575/26050 (epoch 37.572), train_loss = 0.86128551, grad/param norm = 2.8978e-01, time/batch = 18.3322s	
19576/26050 (epoch 37.574), train_loss = 0.87963725, grad/param norm = 2.4246e-01, time/batch = 15.7986s	
19577/26050 (epoch 37.576), train_loss = 0.89843195, grad/param norm = 2.3099e-01, time/batch = 17.9041s	
19578/26050 (epoch 37.578), train_loss = 0.83440838, grad/param norm = 2.3423e-01, time/batch = 18.4088s	
19579/26050 (epoch 37.580), train_loss = 0.79811403, grad/param norm = 2.5726e-01, time/batch = 17.5646s	
19580/26050 (epoch 37.582), train_loss = 0.86543808, grad/param norm = 2.0465e-01, time/batch = 16.6390s	
19581/26050 (epoch 37.583), train_loss = 0.92050266, grad/param norm = 1.9402e-01, time/batch = 14.9663s	
19582/26050 (epoch 37.585), train_loss = 0.75728041, grad/param norm = 2.0041e-01, time/batch = 17.9908s	
19583/26050 (epoch 37.587), train_loss = 0.88472780, grad/param norm = 2.4668e-01, time/batch = 18.8174s	
19584/26050 (epoch 37.589), train_loss = 0.99008999, grad/param norm = 2.0415e-01, time/batch = 18.1497s	
19585/26050 (epoch 37.591), train_loss = 0.86587263, grad/param norm = 2.0686e-01, time/batch = 17.4795s	
19586/26050 (epoch 37.593), train_loss = 0.75609990, grad/param norm = 2.0832e-01, time/batch = 17.7102s	
19587/26050 (epoch 37.595), train_loss = 0.91531523, grad/param norm = 2.5703e-01, time/batch = 17.6475s	
19588/26050 (epoch 37.597), train_loss = 0.86932320, grad/param norm = 2.2806e-01, time/batch = 18.7501s	
19589/26050 (epoch 37.599), train_loss = 0.93162044, grad/param norm = 2.3995e-01, time/batch = 17.4780s	
19590/26050 (epoch 37.601), train_loss = 1.03066065, grad/param norm = 2.3502e-01, time/batch = 16.0377s	
19591/26050 (epoch 37.603), train_loss = 0.94717706, grad/param norm = 2.3129e-01, time/batch = 17.9831s	
19592/26050 (epoch 37.605), train_loss = 0.82761956, grad/param norm = 2.0532e-01, time/batch = 18.0564s	
19593/26050 (epoch 37.607), train_loss = 0.94756284, grad/param norm = 2.3379e-01, time/batch = 18.6553s	
19594/26050 (epoch 37.608), train_loss = 0.78008133, grad/param norm = 1.8827e-01, time/batch = 18.1589s	
19595/26050 (epoch 37.610), train_loss = 0.87749161, grad/param norm = 2.5722e-01, time/batch = 18.0491s	
19596/26050 (epoch 37.612), train_loss = 0.83454079, grad/param norm = 2.2870e-01, time/batch = 18.1513s	
19597/26050 (epoch 37.614), train_loss = 0.86495197, grad/param norm = 2.1846e-01, time/batch = 17.1152s	
19598/26050 (epoch 37.616), train_loss = 0.92133866, grad/param norm = 2.6250e-01, time/batch = 17.9675s	
19599/26050 (epoch 37.618), train_loss = 0.82277660, grad/param norm = 2.1031e-01, time/batch = 16.7266s	
19600/26050 (epoch 37.620), train_loss = 0.93912245, grad/param norm = 2.3293e-01, time/batch = 18.4698s	
19601/26050 (epoch 37.622), train_loss = 0.78480093, grad/param norm = 2.0298e-01, time/batch = 18.3108s	
19602/26050 (epoch 37.624), train_loss = 0.71477371, grad/param norm = 1.7867e-01, time/batch = 16.6319s	
19603/26050 (epoch 37.626), train_loss = 0.89067495, grad/param norm = 2.0796e-01, time/batch = 14.7901s	
19604/26050 (epoch 37.628), train_loss = 0.80716284, grad/param norm = 2.3587e-01, time/batch = 16.3828s	
19605/26050 (epoch 37.630), train_loss = 0.99250922, grad/param norm = 2.0277e-01, time/batch = 16.8043s	
19606/26050 (epoch 37.631), train_loss = 1.02336450, grad/param norm = 2.4592e-01, time/batch = 17.9647s	
19607/26050 (epoch 37.633), train_loss = 0.78604009, grad/param norm = 2.3995e-01, time/batch = 18.4004s	
19608/26050 (epoch 37.635), train_loss = 0.81080130, grad/param norm = 1.7911e-01, time/batch = 18.6328s	
19609/26050 (epoch 37.637), train_loss = 0.74905051, grad/param norm = 1.8992e-01, time/batch = 17.9764s	
19610/26050 (epoch 37.639), train_loss = 0.88787530, grad/param norm = 1.9183e-01, time/batch = 18.8932s	
19611/26050 (epoch 37.641), train_loss = 0.80077647, grad/param norm = 1.9840e-01, time/batch = 17.9830s	
19612/26050 (epoch 37.643), train_loss = 0.77845540, grad/param norm = 1.7193e-01, time/batch = 17.4029s	
19613/26050 (epoch 37.645), train_loss = 0.81480231, grad/param norm = 2.1567e-01, time/batch = 15.7048s	
19614/26050 (epoch 37.647), train_loss = 0.77259292, grad/param norm = 2.0931e-01, time/batch = 15.2999s	
19615/26050 (epoch 37.649), train_loss = 0.82084040, grad/param norm = 2.3076e-01, time/batch = 18.2304s	
19616/26050 (epoch 37.651), train_loss = 0.80574519, grad/param norm = 1.9744e-01, time/batch = 17.6411s	
19617/26050 (epoch 37.653), train_loss = 0.83998744, grad/param norm = 2.1402e-01, time/batch = 17.9868s	
19618/26050 (epoch 37.655), train_loss = 0.76070414, grad/param norm = 1.9920e-01, time/batch = 18.8171s	
19619/26050 (epoch 37.656), train_loss = 0.74657371, grad/param norm = 1.9237e-01, time/batch = 17.9788s	
19620/26050 (epoch 37.658), train_loss = 1.03749296, grad/param norm = 2.3156e-01, time/batch = 15.3863s	
19621/26050 (epoch 37.660), train_loss = 0.72195404, grad/param norm = 2.1645e-01, time/batch = 17.7227s	
19622/26050 (epoch 37.662), train_loss = 0.84404611, grad/param norm = 1.9471e-01, time/batch = 17.7939s	
19623/26050 (epoch 37.664), train_loss = 0.83970565, grad/param norm = 1.9660e-01, time/batch = 17.3251s	
19624/26050 (epoch 37.666), train_loss = 0.79995605, grad/param norm = 2.0544e-01, time/batch = 17.9850s	
19625/26050 (epoch 37.668), train_loss = 0.66695079, grad/param norm = 2.3518e-01, time/batch = 18.0602s	
19626/26050 (epoch 37.670), train_loss = 0.99313443, grad/param norm = 2.5987e-01, time/batch = 17.8190s	
19627/26050 (epoch 37.672), train_loss = 0.83430942, grad/param norm = 2.2391e-01, time/batch = 18.1447s	
19628/26050 (epoch 37.674), train_loss = 0.75666864, grad/param norm = 2.1061e-01, time/batch = 16.2295s	
19629/26050 (epoch 37.676), train_loss = 0.90092507, grad/param norm = 2.2140e-01, time/batch = 17.8132s	
19630/26050 (epoch 37.678), train_loss = 0.94643188, grad/param norm = 2.5532e-01, time/batch = 18.2311s	
19631/26050 (epoch 37.679), train_loss = 0.99328797, grad/param norm = 2.5323e-01, time/batch = 17.2344s	
19632/26050 (epoch 37.681), train_loss = 0.87479751, grad/param norm = 2.3402e-01, time/batch = 16.5390s	
19633/26050 (epoch 37.683), train_loss = 0.77964109, grad/param norm = 2.8844e-01, time/batch = 17.1568s	
19634/26050 (epoch 37.685), train_loss = 0.81902408, grad/param norm = 2.1910e-01, time/batch = 18.6551s	
19635/26050 (epoch 37.687), train_loss = 0.75203251, grad/param norm = 2.0540e-01, time/batch = 18.5496s	
19636/26050 (epoch 37.689), train_loss = 0.79665636, grad/param norm = 2.0131e-01, time/batch = 17.7312s	
19637/26050 (epoch 37.691), train_loss = 0.68483954, grad/param norm = 1.6389e-01, time/batch = 18.1516s	
19638/26050 (epoch 37.693), train_loss = 0.81652927, grad/param norm = 2.2227e-01, time/batch = 17.5674s	
19639/26050 (epoch 37.695), train_loss = 0.83358616, grad/param norm = 2.0168e-01, time/batch = 18.5578s	
19640/26050 (epoch 37.697), train_loss = 0.79182206, grad/param norm = 2.1624e-01, time/batch = 17.8980s	
19641/26050 (epoch 37.699), train_loss = 0.89465686, grad/param norm = 2.2364e-01, time/batch = 15.0677s	
19642/26050 (epoch 37.701), train_loss = 0.76404340, grad/param norm = 1.7510e-01, time/batch = 16.4689s	
19643/26050 (epoch 37.702), train_loss = 0.92904949, grad/param norm = 2.2614e-01, time/batch = 18.3881s	
19644/26050 (epoch 37.704), train_loss = 0.94721912, grad/param norm = 2.1064e-01, time/batch = 17.9812s	
19645/26050 (epoch 37.706), train_loss = 0.78174603, grad/param norm = 2.0798e-01, time/batch = 17.6527s	
19646/26050 (epoch 37.708), train_loss = 0.89171573, grad/param norm = 2.2598e-01, time/batch = 16.1298s	
19647/26050 (epoch 37.710), train_loss = 0.87260302, grad/param norm = 2.3574e-01, time/batch = 18.0490s	
19648/26050 (epoch 37.712), train_loss = 0.85010275, grad/param norm = 2.4129e-01, time/batch = 18.7305s	
19649/26050 (epoch 37.714), train_loss = 0.75566418, grad/param norm = 1.8811e-01, time/batch = 16.0651s	
19650/26050 (epoch 37.716), train_loss = 1.04353824, grad/param norm = 2.3531e-01, time/batch = 16.2234s	
19651/26050 (epoch 37.718), train_loss = 0.89583951, grad/param norm = 2.1540e-01, time/batch = 18.4778s	
19652/26050 (epoch 37.720), train_loss = 0.82292267, grad/param norm = 2.2150e-01, time/batch = 16.2149s	
19653/26050 (epoch 37.722), train_loss = 0.77152775, grad/param norm = 1.9162e-01, time/batch = 17.3932s	
19654/26050 (epoch 37.724), train_loss = 0.78228217, grad/param norm = 2.0048e-01, time/batch = 16.9355s	
19655/26050 (epoch 37.726), train_loss = 0.92457707, grad/param norm = 2.1449e-01, time/batch = 17.3093s	
19656/26050 (epoch 37.727), train_loss = 0.88400769, grad/param norm = 2.0479e-01, time/batch = 17.9790s	
19657/26050 (epoch 37.729), train_loss = 0.87774207, grad/param norm = 1.9669e-01, time/batch = 17.7199s	
19658/26050 (epoch 37.731), train_loss = 0.89934693, grad/param norm = 2.2279e-01, time/batch = 17.2230s	
19659/26050 (epoch 37.733), train_loss = 0.82064815, grad/param norm = 2.1144e-01, time/batch = 16.1397s	
19660/26050 (epoch 37.735), train_loss = 0.97035046, grad/param norm = 2.3801e-01, time/batch = 16.8141s	
19661/26050 (epoch 37.737), train_loss = 0.80534552, grad/param norm = 2.3500e-01, time/batch = 15.1442s	
19662/26050 (epoch 37.739), train_loss = 0.87113621, grad/param norm = 2.0781e-01, time/batch = 18.5492s	
19663/26050 (epoch 37.741), train_loss = 0.77806393, grad/param norm = 1.9768e-01, time/batch = 18.3953s	
19664/26050 (epoch 37.743), train_loss = 0.84103202, grad/param norm = 2.4501e-01, time/batch = 17.1437s	
19665/26050 (epoch 37.745), train_loss = 0.76269758, grad/param norm = 1.9616e-01, time/batch = 18.3220s	
19666/26050 (epoch 37.747), train_loss = 0.78155698, grad/param norm = 2.0381e-01, time/batch = 18.1416s	
19667/26050 (epoch 37.749), train_loss = 0.94258481, grad/param norm = 2.1794e-01, time/batch = 17.4818s	
19668/26050 (epoch 37.750), train_loss = 0.81953535, grad/param norm = 2.0042e-01, time/batch = 17.4012s	
19669/26050 (epoch 37.752), train_loss = 0.78910054, grad/param norm = 2.3432e-01, time/batch = 18.0577s	
19670/26050 (epoch 37.754), train_loss = 0.85430865, grad/param norm = 2.2420e-01, time/batch = 18.1417s	
19671/26050 (epoch 37.756), train_loss = 0.81149809, grad/param norm = 2.4489e-01, time/batch = 17.4745s	
19672/26050 (epoch 37.758), train_loss = 0.83899026, grad/param norm = 2.6446e-01, time/batch = 17.3935s	
19673/26050 (epoch 37.760), train_loss = 0.96645617, grad/param norm = 2.2293e-01, time/batch = 18.2448s	
19674/26050 (epoch 37.762), train_loss = 0.81630015, grad/param norm = 2.1153e-01, time/batch = 17.9810s	
19675/26050 (epoch 37.764), train_loss = 0.81743471, grad/param norm = 2.2986e-01, time/batch = 18.6307s	
19676/26050 (epoch 37.766), train_loss = 0.84782073, grad/param norm = 2.3010e-01, time/batch = 18.1623s	
19677/26050 (epoch 37.768), train_loss = 0.73214573, grad/param norm = 1.8839e-01, time/batch = 16.5372s	
19678/26050 (epoch 37.770), train_loss = 0.83472743, grad/param norm = 2.2371e-01, time/batch = 17.3246s	
19679/26050 (epoch 37.772), train_loss = 0.85073527, grad/param norm = 2.1302e-01, time/batch = 17.8254s	
19680/26050 (epoch 37.774), train_loss = 0.73484178, grad/param norm = 2.2524e-01, time/batch = 15.9025s	
19681/26050 (epoch 37.775), train_loss = 0.63164830, grad/param norm = 2.2651e-01, time/batch = 17.0655s	
19682/26050 (epoch 37.777), train_loss = 0.80350409, grad/param norm = 2.1941e-01, time/batch = 18.2551s	
19683/26050 (epoch 37.779), train_loss = 0.82753477, grad/param norm = 3.4075e-01, time/batch = 15.8087s	
19684/26050 (epoch 37.781), train_loss = 0.76692154, grad/param norm = 2.2833e-01, time/batch = 16.9698s	
19685/26050 (epoch 37.783), train_loss = 0.72703813, grad/param norm = 2.1598e-01, time/batch = 18.2240s	
19686/26050 (epoch 37.785), train_loss = 0.85594585, grad/param norm = 2.6088e-01, time/batch = 18.1506s	
19687/26050 (epoch 37.787), train_loss = 0.74916008, grad/param norm = 2.0262e-01, time/batch = 18.4921s	
19688/26050 (epoch 37.789), train_loss = 0.75061199, grad/param norm = 2.1304e-01, time/batch = 17.2094s	
19689/26050 (epoch 37.791), train_loss = 0.77010617, grad/param norm = 2.5370e-01, time/batch = 17.4044s	
19690/26050 (epoch 37.793), train_loss = 0.83650962, grad/param norm = 2.2625e-01, time/batch = 17.5709s	
19691/26050 (epoch 37.795), train_loss = 0.68490864, grad/param norm = 1.7907e-01, time/batch = 18.0595s	
19692/26050 (epoch 37.797), train_loss = 0.74232571, grad/param norm = 2.2444e-01, time/batch = 19.0598s	
19693/26050 (epoch 37.798), train_loss = 0.79237143, grad/param norm = 2.2928e-01, time/batch = 18.8023s	
19694/26050 (epoch 37.800), train_loss = 0.71917728, grad/param norm = 2.0733e-01, time/batch = 18.1483s	
19695/26050 (epoch 37.802), train_loss = 0.78780022, grad/param norm = 2.1963e-01, time/batch = 16.3798s	
19696/26050 (epoch 37.804), train_loss = 0.82761693, grad/param norm = 2.2022e-01, time/batch = 18.4113s	
19697/26050 (epoch 37.806), train_loss = 0.92221800, grad/param norm = 2.7217e-01, time/batch = 18.0632s	
19698/26050 (epoch 37.808), train_loss = 0.85697481, grad/param norm = 2.9751e-01, time/batch = 18.4726s	
19699/26050 (epoch 37.810), train_loss = 0.84113823, grad/param norm = 2.2332e-01, time/batch = 18.0435s	
19700/26050 (epoch 37.812), train_loss = 0.69990073, grad/param norm = 2.1202e-01, time/batch = 18.1479s	
19701/26050 (epoch 37.814), train_loss = 0.73956181, grad/param norm = 2.0392e-01, time/batch = 15.3175s	
19702/26050 (epoch 37.816), train_loss = 0.88702416, grad/param norm = 2.5308e-01, time/batch = 14.6966s	
19703/26050 (epoch 37.818), train_loss = 0.90659913, grad/param norm = 2.4156e-01, time/batch = 18.3989s	
19704/26050 (epoch 37.820), train_loss = 0.84649704, grad/param norm = 2.1919e-01, time/batch = 18.2334s	
19705/26050 (epoch 37.821), train_loss = 0.93463168, grad/param norm = 2.3654e-01, time/batch = 25.6531s	
19706/26050 (epoch 37.823), train_loss = 1.04722377, grad/param norm = 2.5754e-01, time/batch = 30.3448s	
19707/26050 (epoch 37.825), train_loss = 0.84113225, grad/param norm = 2.1499e-01, time/batch = 17.4706s	
19708/26050 (epoch 37.827), train_loss = 0.82120018, grad/param norm = 2.4784e-01, time/batch = 16.7145s	
19709/26050 (epoch 37.829), train_loss = 0.94987921, grad/param norm = 2.4883e-01, time/batch = 18.6585s	
19710/26050 (epoch 37.831), train_loss = 0.97966370, grad/param norm = 2.3029e-01, time/batch = 18.0665s	
19711/26050 (epoch 37.833), train_loss = 0.95876656, grad/param norm = 2.6704e-01, time/batch = 19.0675s	
19712/26050 (epoch 37.835), train_loss = 0.97780274, grad/param norm = 2.5091e-01, time/batch = 17.7344s	
19713/26050 (epoch 37.837), train_loss = 0.86609528, grad/param norm = 2.0143e-01, time/batch = 16.1404s	
19714/26050 (epoch 37.839), train_loss = 0.82555558, grad/param norm = 2.3316e-01, time/batch = 14.3675s	
19715/26050 (epoch 37.841), train_loss = 0.90487697, grad/param norm = 2.1176e-01, time/batch = 18.6411s	
19716/26050 (epoch 37.843), train_loss = 0.83593796, grad/param norm = 1.9648e-01, time/batch = 18.2280s	
19717/26050 (epoch 37.845), train_loss = 0.79060950, grad/param norm = 1.8418e-01, time/batch = 17.1476s	
19718/26050 (epoch 37.846), train_loss = 0.86798863, grad/param norm = 2.1381e-01, time/batch = 18.4801s	
19719/26050 (epoch 37.848), train_loss = 0.81326025, grad/param norm = 2.0788e-01, time/batch = 18.8923s	
19720/26050 (epoch 37.850), train_loss = 0.76020866, grad/param norm = 2.0186e-01, time/batch = 17.9073s	
19721/26050 (epoch 37.852), train_loss = 0.85871906, grad/param norm = 2.0115e-01, time/batch = 15.3883s	
19722/26050 (epoch 37.854), train_loss = 0.83650113, grad/param norm = 2.0533e-01, time/batch = 17.5694s	
19723/26050 (epoch 37.856), train_loss = 0.79410531, grad/param norm = 2.2035e-01, time/batch = 18.1488s	
19724/26050 (epoch 37.858), train_loss = 0.75682840, grad/param norm = 1.9668e-01, time/batch = 17.6538s	
19725/26050 (epoch 37.860), train_loss = 0.88077755, grad/param norm = 2.4208e-01, time/batch = 17.7937s	
19726/26050 (epoch 37.862), train_loss = 0.92687824, grad/param norm = 2.2560e-01, time/batch = 17.7268s	
19727/26050 (epoch 37.864), train_loss = 0.83436300, grad/param norm = 2.3547e-01, time/batch = 16.9739s	
19728/26050 (epoch 37.866), train_loss = 0.81278564, grad/param norm = 1.9294e-01, time/batch = 16.8844s	
19729/26050 (epoch 37.868), train_loss = 0.89836215, grad/param norm = 2.9156e-01, time/batch = 17.8185s	
19730/26050 (epoch 37.869), train_loss = 0.74554276, grad/param norm = 1.8141e-01, time/batch = 18.0715s	
19731/26050 (epoch 37.871), train_loss = 0.71424292, grad/param norm = 1.9085e-01, time/batch = 18.6449s	
19732/26050 (epoch 37.873), train_loss = 0.89886677, grad/param norm = 2.2955e-01, time/batch = 16.3798s	
19733/26050 (epoch 37.875), train_loss = 0.80954567, grad/param norm = 2.5046e-01, time/batch = 18.0624s	
19734/26050 (epoch 37.877), train_loss = 0.78722846, grad/param norm = 1.9737e-01, time/batch = 16.9645s	
19735/26050 (epoch 37.879), train_loss = 0.88319174, grad/param norm = 2.1604e-01, time/batch = 18.4757s	
19736/26050 (epoch 37.881), train_loss = 0.91550033, grad/param norm = 2.4056e-01, time/batch = 15.4811s	
19737/26050 (epoch 37.883), train_loss = 0.89082648, grad/param norm = 2.3237e-01, time/batch = 16.8949s	
19738/26050 (epoch 37.885), train_loss = 0.65544554, grad/param norm = 1.8447e-01, time/batch = 16.1140s	
19739/26050 (epoch 37.887), train_loss = 0.91700482, grad/param norm = 2.4544e-01, time/batch = 17.3008s	
19740/26050 (epoch 37.889), train_loss = 0.78693758, grad/param norm = 2.2731e-01, time/batch = 18.4827s	
19741/26050 (epoch 37.891), train_loss = 0.71072826, grad/param norm = 2.0111e-01, time/batch = 17.3108s	
19742/26050 (epoch 37.893), train_loss = 0.71922483, grad/param norm = 2.0556e-01, time/batch = 18.5668s	
19743/26050 (epoch 37.894), train_loss = 0.77719382, grad/param norm = 1.9486e-01, time/batch = 18.4926s	
19744/26050 (epoch 37.896), train_loss = 0.90791831, grad/param norm = 2.5629e-01, time/batch = 17.7196s	
19745/26050 (epoch 37.898), train_loss = 0.79241853, grad/param norm = 2.2297e-01, time/batch = 18.6316s	
19746/26050 (epoch 37.900), train_loss = 0.86681987, grad/param norm = 2.6064e-01, time/batch = 15.8821s	
19747/26050 (epoch 37.902), train_loss = 0.80889801, grad/param norm = 2.2728e-01, time/batch = 17.8963s	
19748/26050 (epoch 37.904), train_loss = 0.80608056, grad/param norm = 1.8531e-01, time/batch = 18.2892s	
19749/26050 (epoch 37.906), train_loss = 0.81516217, grad/param norm = 2.6366e-01, time/batch = 17.2306s	
19750/26050 (epoch 37.908), train_loss = 0.85826706, grad/param norm = 2.0202e-01, time/batch = 16.1421s	
19751/26050 (epoch 37.910), train_loss = 0.77896594, grad/param norm = 2.1725e-01, time/batch = 16.6309s	
19752/26050 (epoch 37.912), train_loss = 1.01807275, grad/param norm = 2.7462e-01, time/batch = 18.3940s	
19753/26050 (epoch 37.914), train_loss = 1.14855511, grad/param norm = 2.6459e-01, time/batch = 18.1452s	
19754/26050 (epoch 37.916), train_loss = 0.91395155, grad/param norm = 2.5009e-01, time/batch = 17.7403s	
19755/26050 (epoch 37.917), train_loss = 0.86411866, grad/param norm = 2.1593e-01, time/batch = 17.7243s	
19756/26050 (epoch 37.919), train_loss = 0.88495190, grad/param norm = 2.5476e-01, time/batch = 15.8945s	
19757/26050 (epoch 37.921), train_loss = 0.77978649, grad/param norm = 2.1205e-01, time/batch = 17.8934s	
19758/26050 (epoch 37.923), train_loss = 0.85634035, grad/param norm = 2.1417e-01, time/batch = 17.1514s	
19759/26050 (epoch 37.925), train_loss = 0.83998044, grad/param norm = 2.0909e-01, time/batch = 18.3131s	
19760/26050 (epoch 37.927), train_loss = 0.76788130, grad/param norm = 1.6579e-01, time/batch = 18.7223s	
19761/26050 (epoch 37.929), train_loss = 0.73594363, grad/param norm = 2.0332e-01, time/batch = 15.7053s	
19762/26050 (epoch 37.931), train_loss = 0.99770734, grad/param norm = 2.8728e-01, time/batch = 18.4871s	
19763/26050 (epoch 37.933), train_loss = 0.83009200, grad/param norm = 2.1579e-01, time/batch = 17.0404s	
19764/26050 (epoch 37.935), train_loss = 0.80228913, grad/param norm = 2.0714e-01, time/batch = 18.2205s	
19765/26050 (epoch 37.937), train_loss = 0.88537862, grad/param norm = 2.0764e-01, time/batch = 16.5439s	
19766/26050 (epoch 37.939), train_loss = 0.75901512, grad/param norm = 1.8938e-01, time/batch = 15.7986s	
19767/26050 (epoch 37.940), train_loss = 0.83439627, grad/param norm = 2.0888e-01, time/batch = 17.1310s	
19768/26050 (epoch 37.942), train_loss = 0.80623774, grad/param norm = 2.0784e-01, time/batch = 17.8812s	
19769/26050 (epoch 37.944), train_loss = 0.81418024, grad/param norm = 2.0150e-01, time/batch = 17.5584s	
19770/26050 (epoch 37.946), train_loss = 0.98635574, grad/param norm = 2.0759e-01, time/batch = 16.3112s	
19771/26050 (epoch 37.948), train_loss = 0.72323269, grad/param norm = 2.0443e-01, time/batch = 18.1367s	
19772/26050 (epoch 37.950), train_loss = 0.84382778, grad/param norm = 2.0154e-01, time/batch = 17.1416s	
19773/26050 (epoch 37.952), train_loss = 0.89794156, grad/param norm = 2.2760e-01, time/batch = 17.3987s	
19774/26050 (epoch 37.954), train_loss = 0.90689695, grad/param norm = 2.1509e-01, time/batch = 17.4005s	
19775/26050 (epoch 37.956), train_loss = 0.80116788, grad/param norm = 2.0480e-01, time/batch = 17.3859s	
19776/26050 (epoch 37.958), train_loss = 0.74771628, grad/param norm = 2.0122e-01, time/batch = 18.5440s	
19777/26050 (epoch 37.960), train_loss = 0.86690725, grad/param norm = 2.1126e-01, time/batch = 17.5676s	
19778/26050 (epoch 37.962), train_loss = 0.82749513, grad/param norm = 1.8981e-01, time/batch = 18.0729s	
19779/26050 (epoch 37.964), train_loss = 0.81486022, grad/param norm = 2.1546e-01, time/batch = 17.5411s	
19780/26050 (epoch 37.965), train_loss = 0.75834253, grad/param norm = 1.9859e-01, time/batch = 18.2395s	
19781/26050 (epoch 37.967), train_loss = 1.11067912, grad/param norm = 2.5210e-01, time/batch = 18.6431s	
19782/26050 (epoch 37.969), train_loss = 0.83520111, grad/param norm = 2.0963e-01, time/batch = 16.6276s	
19783/26050 (epoch 37.971), train_loss = 0.84349167, grad/param norm = 2.0405e-01, time/batch = 14.3034s	
19784/26050 (epoch 37.973), train_loss = 0.84746339, grad/param norm = 2.2462e-01, time/batch = 16.3779s	
19785/26050 (epoch 37.975), train_loss = 0.86293323, grad/param norm = 2.1574e-01, time/batch = 17.9048s	
19786/26050 (epoch 37.977), train_loss = 0.83130030, grad/param norm = 2.0051e-01, time/batch = 15.1408s	
19787/26050 (epoch 37.979), train_loss = 0.68490276, grad/param norm = 1.9950e-01, time/batch = 18.3246s	
19788/26050 (epoch 37.981), train_loss = 0.93029240, grad/param norm = 1.9906e-01, time/batch = 18.3155s	
19789/26050 (epoch 37.983), train_loss = 0.89077461, grad/param norm = 2.1996e-01, time/batch = 16.7983s	
19790/26050 (epoch 37.985), train_loss = 0.88220478, grad/param norm = 2.3493e-01, time/batch = 17.8062s	
19791/26050 (epoch 37.987), train_loss = 0.93574581, grad/param norm = 2.1903e-01, time/batch = 16.5374s	
19792/26050 (epoch 37.988), train_loss = 0.88752198, grad/param norm = 2.5181e-01, time/batch = 18.0452s	
19793/26050 (epoch 37.990), train_loss = 0.73813746, grad/param norm = 1.8022e-01, time/batch = 17.5591s	
19794/26050 (epoch 37.992), train_loss = 0.99576247, grad/param norm = 2.4489e-01, time/batch = 18.2392s	
19795/26050 (epoch 37.994), train_loss = 0.78444898, grad/param norm = 2.3534e-01, time/batch = 18.0613s	
19796/26050 (epoch 37.996), train_loss = 0.73773950, grad/param norm = 2.2712e-01, time/batch = 15.3768s	
19797/26050 (epoch 37.998), train_loss = 0.85355333, grad/param norm = 2.0546e-01, time/batch = 15.6408s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
19798/26050 (epoch 38.000), train_loss = 0.77762565, grad/param norm = 2.1732e-01, time/batch = 17.6499s	
19799/26050 (epoch 38.002), train_loss = 0.88508218, grad/param norm = 2.2503e-01, time/batch = 17.3104s	
19800/26050 (epoch 38.004), train_loss = 0.75551871, grad/param norm = 2.1940e-01, time/batch = 18.4711s	
19801/26050 (epoch 38.006), train_loss = 0.80515343, grad/param norm = 2.8912e-01, time/batch = 15.3042s	
19802/26050 (epoch 38.008), train_loss = 0.78050297, grad/param norm = 2.4893e-01, time/batch = 18.4813s	
19803/26050 (epoch 38.010), train_loss = 0.75951616, grad/param norm = 2.0457e-01, time/batch = 16.9703s	
19804/26050 (epoch 38.012), train_loss = 0.82098364, grad/param norm = 2.1106e-01, time/batch = 18.2514s	
19805/26050 (epoch 38.013), train_loss = 1.05057191, grad/param norm = 2.4106e-01, time/batch = 18.2533s	
19806/26050 (epoch 38.015), train_loss = 0.83111392, grad/param norm = 2.0108e-01, time/batch = 17.4842s	
19807/26050 (epoch 38.017), train_loss = 0.87428655, grad/param norm = 2.0032e-01, time/batch = 17.1416s	
19808/26050 (epoch 38.019), train_loss = 0.71876049, grad/param norm = 1.4880e-01, time/batch = 16.3788s	
19809/26050 (epoch 38.021), train_loss = 0.91988996, grad/param norm = 2.0857e-01, time/batch = 18.2352s	
19810/26050 (epoch 38.023), train_loss = 0.70548141, grad/param norm = 2.1489e-01, time/batch = 18.2398s	
19811/26050 (epoch 38.025), train_loss = 0.83183914, grad/param norm = 2.1675e-01, time/batch = 18.5772s	
19812/26050 (epoch 38.027), train_loss = 0.67674326, grad/param norm = 2.0630e-01, time/batch = 18.1431s	
19813/26050 (epoch 38.029), train_loss = 0.87607936, grad/param norm = 2.0382e-01, time/batch = 16.6155s	
19814/26050 (epoch 38.031), train_loss = 0.94309379, grad/param norm = 2.2432e-01, time/batch = 18.2974s	
19815/26050 (epoch 38.033), train_loss = 0.83723373, grad/param norm = 2.0818e-01, time/batch = 17.7029s	
19816/26050 (epoch 38.035), train_loss = 0.87791630, grad/param norm = 2.1215e-01, time/batch = 17.5735s	
19817/26050 (epoch 38.036), train_loss = 0.73302524, grad/param norm = 2.4186e-01, time/batch = 18.0632s	
19818/26050 (epoch 38.038), train_loss = 0.67088581, grad/param norm = 2.0208e-01, time/batch = 18.7263s	
19819/26050 (epoch 38.040), train_loss = 0.82292600, grad/param norm = 2.0809e-01, time/batch = 18.1504s	
19820/26050 (epoch 38.042), train_loss = 0.72067093, grad/param norm = 2.0423e-01, time/batch = 17.4791s	
19821/26050 (epoch 38.044), train_loss = 0.89796531, grad/param norm = 1.9492e-01, time/batch = 18.1336s	
19822/26050 (epoch 38.046), train_loss = 0.71137569, grad/param norm = 1.7908e-01, time/batch = 17.1381s	
19823/26050 (epoch 38.048), train_loss = 0.83405800, grad/param norm = 2.0833e-01, time/batch = 16.8654s	
19824/26050 (epoch 38.050), train_loss = 0.77531514, grad/param norm = 1.9316e-01, time/batch = 17.7222s	
19825/26050 (epoch 38.052), train_loss = 0.77137159, grad/param norm = 2.1915e-01, time/batch = 17.2126s	
19826/26050 (epoch 38.054), train_loss = 0.69648937, grad/param norm = 1.8531e-01, time/batch = 17.3859s	
19827/26050 (epoch 38.056), train_loss = 0.67953094, grad/param norm = 1.7691e-01, time/batch = 17.0643s	
19828/26050 (epoch 38.058), train_loss = 0.79608353, grad/param norm = 1.8927e-01, time/batch = 16.6456s	
19829/26050 (epoch 38.060), train_loss = 0.85792867, grad/param norm = 1.9564e-01, time/batch = 18.5522s	
19830/26050 (epoch 38.061), train_loss = 0.72056243, grad/param norm = 1.9255e-01, time/batch = 17.0668s	
19831/26050 (epoch 38.063), train_loss = 0.81436831, grad/param norm = 2.2418e-01, time/batch = 18.1535s	
19832/26050 (epoch 38.065), train_loss = 0.67868702, grad/param norm = 1.7347e-01, time/batch = 15.7362s	
19833/26050 (epoch 38.067), train_loss = 0.82430554, grad/param norm = 2.1924e-01, time/batch = 16.1215s	
19834/26050 (epoch 38.069), train_loss = 0.84923020, grad/param norm = 2.1988e-01, time/batch = 16.8798s	
19835/26050 (epoch 38.071), train_loss = 0.86306500, grad/param norm = 2.6583e-01, time/batch = 18.3950s	
19836/26050 (epoch 38.073), train_loss = 0.95568192, grad/param norm = 2.0330e-01, time/batch = 18.7210s	
19837/26050 (epoch 38.075), train_loss = 0.79212863, grad/param norm = 2.0633e-01, time/batch = 17.8190s	
19838/26050 (epoch 38.077), train_loss = 0.76892470, grad/param norm = 2.2367e-01, time/batch = 18.1584s	
19839/26050 (epoch 38.079), train_loss = 0.79747288, grad/param norm = 2.3650e-01, time/batch = 18.3137s	
19840/26050 (epoch 38.081), train_loss = 0.81125791, grad/param norm = 2.1534e-01, time/batch = 17.1479s	
19841/26050 (epoch 38.083), train_loss = 0.92322145, grad/param norm = 2.0927e-01, time/batch = 17.7278s	
19842/26050 (epoch 38.084), train_loss = 0.82534165, grad/param norm = 2.1602e-01, time/batch = 18.4769s	
19843/26050 (epoch 38.086), train_loss = 0.96269428, grad/param norm = 2.2790e-01, time/batch = 17.9900s	
19844/26050 (epoch 38.088), train_loss = 0.81903214, grad/param norm = 2.1391e-01, time/batch = 18.1454s	
19845/26050 (epoch 38.090), train_loss = 0.86242690, grad/param norm = 2.3284e-01, time/batch = 16.3927s	
19846/26050 (epoch 38.092), train_loss = 0.87879359, grad/param norm = 2.0403e-01, time/batch = 18.4577s	
19847/26050 (epoch 38.094), train_loss = 0.71715071, grad/param norm = 1.9878e-01, time/batch = 17.8876s	
19848/26050 (epoch 38.096), train_loss = 0.85556914, grad/param norm = 2.0524e-01, time/batch = 17.3744s	
19849/26050 (epoch 38.098), train_loss = 0.82713571, grad/param norm = 2.0639e-01, time/batch = 18.1508s	
19850/26050 (epoch 38.100), train_loss = 0.75598594, grad/param norm = 2.2688e-01, time/batch = 17.2357s	
19851/26050 (epoch 38.102), train_loss = 0.84676322, grad/param norm = 2.1803e-01, time/batch = 17.1527s	
19852/26050 (epoch 38.104), train_loss = 0.79087606, grad/param norm = 2.1838e-01, time/batch = 18.0446s	
19853/26050 (epoch 38.106), train_loss = 0.88380825, grad/param norm = 2.3177e-01, time/batch = 14.2654s	
19854/26050 (epoch 38.107), train_loss = 0.68229592, grad/param norm = 1.7919e-01, time/batch = 14.6949s	
19855/26050 (epoch 38.109), train_loss = 0.77378600, grad/param norm = 1.9524e-01, time/batch = 14.2890s	
19856/26050 (epoch 38.111), train_loss = 0.95234911, grad/param norm = 2.2084e-01, time/batch = 13.8560s	
19857/26050 (epoch 38.113), train_loss = 0.79519073, grad/param norm = 1.9748e-01, time/batch = 18.8950s	
19858/26050 (epoch 38.115), train_loss = 0.92263551, grad/param norm = 2.1393e-01, time/batch = 17.1420s	
19859/26050 (epoch 38.117), train_loss = 0.82826736, grad/param norm = 2.0605e-01, time/batch = 17.4729s	
19860/26050 (epoch 38.119), train_loss = 0.71792025, grad/param norm = 1.8230e-01, time/batch = 18.2238s	
19861/26050 (epoch 38.121), train_loss = 0.82860195, grad/param norm = 2.0028e-01, time/batch = 17.2440s	
19862/26050 (epoch 38.123), train_loss = 0.75033548, grad/param norm = 2.2000e-01, time/batch = 16.7090s	
19863/26050 (epoch 38.125), train_loss = 0.70336019, grad/param norm = 1.8621e-01, time/batch = 18.6511s	
19864/26050 (epoch 38.127), train_loss = 0.69516095, grad/param norm = 1.9571e-01, time/batch = 17.4783s	
19865/26050 (epoch 38.129), train_loss = 0.65756578, grad/param norm = 2.0391e-01, time/batch = 15.5440s	
19866/26050 (epoch 38.131), train_loss = 0.82106805, grad/param norm = 2.4965e-01, time/batch = 16.5758s	
19867/26050 (epoch 38.132), train_loss = 0.83489070, grad/param norm = 2.1652e-01, time/batch = 17.1595s	
19868/26050 (epoch 38.134), train_loss = 0.84930766, grad/param norm = 2.1738e-01, time/batch = 16.0492s	
19869/26050 (epoch 38.136), train_loss = 0.80419144, grad/param norm = 1.9588e-01, time/batch = 18.1532s	
19870/26050 (epoch 38.138), train_loss = 0.58413858, grad/param norm = 1.9077e-01, time/batch = 18.8191s	
19871/26050 (epoch 38.140), train_loss = 0.67507181, grad/param norm = 2.1752e-01, time/batch = 16.6339s	
19872/26050 (epoch 38.142), train_loss = 0.71815968, grad/param norm = 2.0026e-01, time/batch = 17.1368s	
19873/26050 (epoch 38.144), train_loss = 0.67320750, grad/param norm = 2.0597e-01, time/batch = 18.3984s	
19874/26050 (epoch 38.146), train_loss = 0.61642322, grad/param norm = 1.7590e-01, time/batch = 18.9584s	
19875/26050 (epoch 38.148), train_loss = 0.64392504, grad/param norm = 1.8054e-01, time/batch = 17.5616s	
19876/26050 (epoch 38.150), train_loss = 0.75474973, grad/param norm = 2.7583e-01, time/batch = 17.5748s	
19877/26050 (epoch 38.152), train_loss = 0.93295410, grad/param norm = 2.6772e-01, time/batch = 14.4730s	
19878/26050 (epoch 38.154), train_loss = 0.66724777, grad/param norm = 2.2842e-01, time/batch = 17.2199s	
19879/26050 (epoch 38.155), train_loss = 0.69336574, grad/param norm = 1.9712e-01, time/batch = 16.1370s	
19880/26050 (epoch 38.157), train_loss = 0.78813935, grad/param norm = 2.3881e-01, time/batch = 17.9913s	
19881/26050 (epoch 38.159), train_loss = 0.84621655, grad/param norm = 2.4072e-01, time/batch = 18.1474s	
19882/26050 (epoch 38.161), train_loss = 0.83447307, grad/param norm = 2.5259e-01, time/batch = 17.6415s	
19883/26050 (epoch 38.163), train_loss = 0.68950303, grad/param norm = 2.1087e-01, time/batch = 18.7370s	
19884/26050 (epoch 38.165), train_loss = 0.61749589, grad/param norm = 1.8859e-01, time/batch = 17.0596s	
19885/26050 (epoch 38.167), train_loss = 0.93234116, grad/param norm = 2.2886e-01, time/batch = 17.1345s	
19886/26050 (epoch 38.169), train_loss = 0.81817494, grad/param norm = 2.1627e-01, time/batch = 18.3088s	
19887/26050 (epoch 38.171), train_loss = 0.73269217, grad/param norm = 2.1985e-01, time/batch = 18.1442s	
19888/26050 (epoch 38.173), train_loss = 0.76892018, grad/param norm = 2.1563e-01, time/batch = 15.8853s	
19889/26050 (epoch 38.175), train_loss = 0.80887246, grad/param norm = 2.0439e-01, time/batch = 15.5486s	
19890/26050 (epoch 38.177), train_loss = 0.86741325, grad/param norm = 2.1745e-01, time/batch = 18.8849s	
19891/26050 (epoch 38.179), train_loss = 0.60219262, grad/param norm = 1.7529e-01, time/batch = 17.3154s	
19892/26050 (epoch 38.180), train_loss = 1.03985163, grad/param norm = 2.2315e-01, time/batch = 16.7324s	
19893/26050 (epoch 38.182), train_loss = 0.97165591, grad/param norm = 2.1391e-01, time/batch = 17.6629s	
19894/26050 (epoch 38.184), train_loss = 0.84214120, grad/param norm = 2.0173e-01, time/batch = 18.2251s	
19895/26050 (epoch 38.186), train_loss = 0.70751422, grad/param norm = 2.1571e-01, time/batch = 16.5329s	
19896/26050 (epoch 38.188), train_loss = 0.87032178, grad/param norm = 2.1583e-01, time/batch = 15.1311s	
19897/26050 (epoch 38.190), train_loss = 0.84571060, grad/param norm = 2.2093e-01, time/batch = 14.8945s	
19898/26050 (epoch 38.192), train_loss = 0.90008865, grad/param norm = 1.9464e-01, time/batch = 18.0576s	
19899/26050 (epoch 38.194), train_loss = 0.86035375, grad/param norm = 2.3206e-01, time/batch = 17.7372s	
19900/26050 (epoch 38.196), train_loss = 0.88444646, grad/param norm = 2.4634e-01, time/batch = 18.0771s	
19901/26050 (epoch 38.198), train_loss = 0.75056916, grad/param norm = 1.7768e-01, time/batch = 18.3901s	
19902/26050 (epoch 38.200), train_loss = 0.72028094, grad/param norm = 2.0266e-01, time/batch = 17.5608s	
19903/26050 (epoch 38.202), train_loss = 0.82926660, grad/param norm = 2.0059e-01, time/batch = 15.3844s	
19904/26050 (epoch 38.203), train_loss = 0.92251336, grad/param norm = 1.9920e-01, time/batch = 18.0489s	
19905/26050 (epoch 38.205), train_loss = 0.76324439, grad/param norm = 2.0891e-01, time/batch = 18.7162s	
19906/26050 (epoch 38.207), train_loss = 0.72731285, grad/param norm = 1.8572e-01, time/batch = 17.0679s	
19907/26050 (epoch 38.209), train_loss = 0.87126012, grad/param norm = 1.9309e-01, time/batch = 18.5639s	
19908/26050 (epoch 38.211), train_loss = 0.71074649, grad/param norm = 1.9371e-01, time/batch = 18.6398s	
19909/26050 (epoch 38.213), train_loss = 0.84138162, grad/param norm = 2.2452e-01, time/batch = 17.7687s	
19910/26050 (epoch 38.215), train_loss = 0.80349070, grad/param norm = 2.0803e-01, time/batch = 28.3424s	
19911/26050 (epoch 38.217), train_loss = 0.78353295, grad/param norm = 2.0038e-01, time/batch = 19.2224s	
19912/26050 (epoch 38.219), train_loss = 0.78431949, grad/param norm = 2.2714e-01, time/batch = 15.5016s	
19913/26050 (epoch 38.221), train_loss = 0.72804029, grad/param norm = 2.1941e-01, time/batch = 16.7996s	
19914/26050 (epoch 38.223), train_loss = 0.89793230, grad/param norm = 2.3356e-01, time/batch = 18.4041s	
19915/26050 (epoch 38.225), train_loss = 0.73537993, grad/param norm = 2.1157e-01, time/batch = 16.9636s	
19916/26050 (epoch 38.226), train_loss = 0.83784236, grad/param norm = 2.3715e-01, time/batch = 14.8080s	
19917/26050 (epoch 38.228), train_loss = 0.92997394, grad/param norm = 2.1324e-01, time/batch = 17.9894s	
19918/26050 (epoch 38.230), train_loss = 0.82064099, grad/param norm = 1.8816e-01, time/batch = 18.2288s	
19919/26050 (epoch 38.232), train_loss = 0.90717536, grad/param norm = 2.3787e-01, time/batch = 17.2270s	
19920/26050 (epoch 38.234), train_loss = 0.72106135, grad/param norm = 2.2914e-01, time/batch = 17.9105s	
19921/26050 (epoch 38.236), train_loss = 0.89700927, grad/param norm = 2.1911e-01, time/batch = 18.4933s	
19922/26050 (epoch 38.238), train_loss = 0.72086066, grad/param norm = 2.0874e-01, time/batch = 14.9552s	
19923/26050 (epoch 38.240), train_loss = 0.82900655, grad/param norm = 2.1034e-01, time/batch = 17.9675s	
19924/26050 (epoch 38.242), train_loss = 0.79661185, grad/param norm = 2.0082e-01, time/batch = 18.3177s	
19925/26050 (epoch 38.244), train_loss = 0.85053341, grad/param norm = 2.2230e-01, time/batch = 16.3983s	
19926/26050 (epoch 38.246), train_loss = 0.77891040, grad/param norm = 2.0350e-01, time/batch = 18.0476s	
19927/26050 (epoch 38.248), train_loss = 0.82731746, grad/param norm = 2.1800e-01, time/batch = 17.4960s	
19928/26050 (epoch 38.250), train_loss = 0.83670830, grad/param norm = 2.7511e-01, time/batch = 18.5623s	
19929/26050 (epoch 38.251), train_loss = 0.77563749, grad/param norm = 2.0079e-01, time/batch = 16.9739s	
19930/26050 (epoch 38.253), train_loss = 0.71239544, grad/param norm = 2.0465e-01, time/batch = 18.1486s	
19931/26050 (epoch 38.255), train_loss = 1.00651069, grad/param norm = 2.3234e-01, time/batch = 18.3920s	
19932/26050 (epoch 38.257), train_loss = 0.83458765, grad/param norm = 2.3332e-01, time/batch = 17.8136s	
19933/26050 (epoch 38.259), train_loss = 0.92136316, grad/param norm = 2.2300e-01, time/batch = 17.9794s	
19934/26050 (epoch 38.261), train_loss = 0.73351242, grad/param norm = 2.4366e-01, time/batch = 16.3846s	
19935/26050 (epoch 38.263), train_loss = 0.92466129, grad/param norm = 2.3737e-01, time/batch = 17.7942s	
19936/26050 (epoch 38.265), train_loss = 0.94141269, grad/param norm = 2.2983e-01, time/batch = 17.5542s	
19937/26050 (epoch 38.267), train_loss = 0.94928725, grad/param norm = 2.1088e-01, time/batch = 15.7947s	
19938/26050 (epoch 38.269), train_loss = 0.92750087, grad/param norm = 2.1009e-01, time/batch = 15.5667s	
19939/26050 (epoch 38.271), train_loss = 0.84481298, grad/param norm = 2.2460e-01, time/batch = 17.5636s	
19940/26050 (epoch 38.273), train_loss = 0.74146157, grad/param norm = 2.1942e-01, time/batch = 18.1580s	
19941/26050 (epoch 38.274), train_loss = 0.80029355, grad/param norm = 1.9025e-01, time/batch = 18.7306s	
19942/26050 (epoch 38.276), train_loss = 0.79868514, grad/param norm = 2.3386e-01, time/batch = 18.1447s	
19943/26050 (epoch 38.278), train_loss = 0.89063878, grad/param norm = 2.0987e-01, time/batch = 18.0632s	
19944/26050 (epoch 38.280), train_loss = 0.81475044, grad/param norm = 2.0410e-01, time/batch = 17.6419s	
19945/26050 (epoch 38.282), train_loss = 0.88108271, grad/param norm = 1.8745e-01, time/batch = 17.8789s	
19946/26050 (epoch 38.284), train_loss = 0.81072461, grad/param norm = 2.1384e-01, time/batch = 17.4727s	
19947/26050 (epoch 38.286), train_loss = 0.87500055, grad/param norm = 2.5182e-01, time/batch = 18.3281s	
19948/26050 (epoch 38.288), train_loss = 0.71526545, grad/param norm = 1.8674e-01, time/batch = 18.5763s	
19949/26050 (epoch 38.290), train_loss = 0.83060352, grad/param norm = 2.2278e-01, time/batch = 17.5629s	
19950/26050 (epoch 38.292), train_loss = 0.75551616, grad/param norm = 1.9644e-01, time/batch = 18.5703s	
19951/26050 (epoch 38.294), train_loss = 0.82869174, grad/param norm = 2.3216e-01, time/batch = 17.6506s	
19952/26050 (epoch 38.296), train_loss = 0.89293865, grad/param norm = 2.0466e-01, time/batch = 18.0524s	
19953/26050 (epoch 38.298), train_loss = 0.87264524, grad/param norm = 2.9811e-01, time/batch = 18.3076s	
19954/26050 (epoch 38.299), train_loss = 0.70031687, grad/param norm = 1.8822e-01, time/batch = 18.8856s	
19955/26050 (epoch 38.301), train_loss = 0.69706140, grad/param norm = 1.8758e-01, time/batch = 15.2984s	
19956/26050 (epoch 38.303), train_loss = 0.82826050, grad/param norm = 2.2464e-01, time/batch = 17.0639s	
19957/26050 (epoch 38.305), train_loss = 0.66562718, grad/param norm = 1.8289e-01, time/batch = 17.9775s	
19958/26050 (epoch 38.307), train_loss = 0.73798453, grad/param norm = 2.1157e-01, time/batch = 18.8962s	
19959/26050 (epoch 38.309), train_loss = 0.83606085, grad/param norm = 2.0026e-01, time/batch = 17.3108s	
19960/26050 (epoch 38.311), train_loss = 0.83349941, grad/param norm = 2.2633e-01, time/batch = 14.6872s	
19961/26050 (epoch 38.313), train_loss = 0.80429787, grad/param norm = 2.0816e-01, time/batch = 17.9790s	
19962/26050 (epoch 38.315), train_loss = 0.88623330, grad/param norm = 2.1597e-01, time/batch = 18.8112s	
19963/26050 (epoch 38.317), train_loss = 0.84490440, grad/param norm = 2.3132e-01, time/batch = 15.9584s	
19964/26050 (epoch 38.319), train_loss = 0.76117678, grad/param norm = 2.5383e-01, time/batch = 18.6314s	
19965/26050 (epoch 38.321), train_loss = 0.81982401, grad/param norm = 2.2293e-01, time/batch = 16.6405s	
19966/26050 (epoch 38.322), train_loss = 0.89144781, grad/param norm = 2.2011e-01, time/batch = 17.9926s	
19967/26050 (epoch 38.324), train_loss = 0.67038992, grad/param norm = 2.0333e-01, time/batch = 17.9061s	
19968/26050 (epoch 38.326), train_loss = 0.93404463, grad/param norm = 2.2408e-01, time/batch = 18.2247s	
19969/26050 (epoch 38.328), train_loss = 0.85722390, grad/param norm = 1.9317e-01, time/batch = 18.0567s	
19970/26050 (epoch 38.330), train_loss = 0.71185143, grad/param norm = 2.1247e-01, time/batch = 18.1314s	
19971/26050 (epoch 38.332), train_loss = 0.88519117, grad/param norm = 2.0547e-01, time/batch = 17.9718s	
19972/26050 (epoch 38.334), train_loss = 0.74419512, grad/param norm = 2.3819e-01, time/batch = 18.3251s	
19973/26050 (epoch 38.336), train_loss = 0.78581544, grad/param norm = 2.1852e-01, time/batch = 17.1472s	
19974/26050 (epoch 38.338), train_loss = 0.70779704, grad/param norm = 1.8563e-01, time/batch = 16.8021s	
19975/26050 (epoch 38.340), train_loss = 0.87419813, grad/param norm = 2.8715e-01, time/batch = 18.8802s	
19976/26050 (epoch 38.342), train_loss = 0.92009845, grad/param norm = 2.3991e-01, time/batch = 17.2234s	
19977/26050 (epoch 38.344), train_loss = 0.76328777, grad/param norm = 2.3153e-01, time/batch = 18.3214s	
19978/26050 (epoch 38.345), train_loss = 0.79758895, grad/param norm = 2.5009e-01, time/batch = 17.2205s	
19979/26050 (epoch 38.347), train_loss = 0.92811274, grad/param norm = 2.0702e-01, time/batch = 18.8031s	
19980/26050 (epoch 38.349), train_loss = 0.86587257, grad/param norm = 2.1757e-01, time/batch = 17.3902s	
19981/26050 (epoch 38.351), train_loss = 0.84223513, grad/param norm = 2.5623e-01, time/batch = 16.6184s	
19982/26050 (epoch 38.353), train_loss = 0.81986710, grad/param norm = 2.1792e-01, time/batch = 15.7096s	
19983/26050 (epoch 38.355), train_loss = 0.83386100, grad/param norm = 2.5102e-01, time/batch = 15.7136s	
19984/26050 (epoch 38.357), train_loss = 0.77168230, grad/param norm = 1.8816e-01, time/batch = 18.5537s	
19985/26050 (epoch 38.359), train_loss = 0.91558286, grad/param norm = 2.2938e-01, time/batch = 17.7321s	
19986/26050 (epoch 38.361), train_loss = 0.73701183, grad/param norm = 1.9246e-01, time/batch = 18.4095s	
19987/26050 (epoch 38.363), train_loss = 0.90007093, grad/param norm = 2.2710e-01, time/batch = 17.3895s	
19988/26050 (epoch 38.365), train_loss = 0.80136436, grad/param norm = 1.9752e-01, time/batch = 17.9677s	
19989/26050 (epoch 38.367), train_loss = 0.88418535, grad/param norm = 1.9592e-01, time/batch = 17.7371s	
19990/26050 (epoch 38.369), train_loss = 0.73946239, grad/param norm = 1.8999e-01, time/batch = 17.9743s	
19991/26050 (epoch 38.370), train_loss = 0.72817842, grad/param norm = 1.7634e-01, time/batch = 18.1620s	
19992/26050 (epoch 38.372), train_loss = 0.81652454, grad/param norm = 2.1908e-01, time/batch = 18.9661s	
19993/26050 (epoch 38.374), train_loss = 0.94957766, grad/param norm = 2.0674e-01, time/batch = 17.7237s	
19994/26050 (epoch 38.376), train_loss = 0.94697722, grad/param norm = 2.3832e-01, time/batch = 17.9736s	
19995/26050 (epoch 38.378), train_loss = 0.78709228, grad/param norm = 2.0066e-01, time/batch = 16.6370s	
19996/26050 (epoch 38.380), train_loss = 0.92995209, grad/param norm = 2.3133e-01, time/batch = 17.7946s	
19997/26050 (epoch 38.382), train_loss = 1.03926820, grad/param norm = 2.6588e-01, time/batch = 14.5614s	
19998/26050 (epoch 38.384), train_loss = 0.78740639, grad/param norm = 2.2839e-01, time/batch = 18.9659s	
19999/26050 (epoch 38.386), train_loss = 0.90074634, grad/param norm = 2.6008e-01, time/batch = 17.2039s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch38.39_1.9145.t7	
20000/26050 (epoch 38.388), train_loss = 0.86604300, grad/param norm = 2.4366e-01, time/batch = 16.9897s	
20001/26050 (epoch 38.390), train_loss = 1.21441479, grad/param norm = 2.8143e-01, time/batch = 16.4628s	
20002/26050 (epoch 38.392), train_loss = 0.75107862, grad/param norm = 2.4732e-01, time/batch = 18.0520s	
20003/26050 (epoch 38.393), train_loss = 0.87704477, grad/param norm = 2.2615e-01, time/batch = 18.8923s	
20004/26050 (epoch 38.395), train_loss = 0.87657691, grad/param norm = 2.0515e-01, time/batch = 16.2908s	
20005/26050 (epoch 38.397), train_loss = 0.87932798, grad/param norm = 2.5950e-01, time/batch = 17.8086s	
20006/26050 (epoch 38.399), train_loss = 0.80492858, grad/param norm = 2.4323e-01, time/batch = 18.7181s	
20007/26050 (epoch 38.401), train_loss = 0.84142339, grad/param norm = 2.0810e-01, time/batch = 18.2864s	
20008/26050 (epoch 38.403), train_loss = 0.84639573, grad/param norm = 2.4046e-01, time/batch = 18.1474s	
20009/26050 (epoch 38.405), train_loss = 0.84684271, grad/param norm = 2.6067e-01, time/batch = 18.5431s	
20010/26050 (epoch 38.407), train_loss = 0.95907852, grad/param norm = 2.2919e-01, time/batch = 18.7305s	
20011/26050 (epoch 38.409), train_loss = 0.94358381, grad/param norm = 2.4160e-01, time/batch = 18.2475s	
20012/26050 (epoch 38.411), train_loss = 0.92972970, grad/param norm = 2.3541e-01, time/batch = 17.4864s	
20013/26050 (epoch 38.413), train_loss = 1.00458296, grad/param norm = 2.2861e-01, time/batch = 18.1434s	
20014/26050 (epoch 38.415), train_loss = 1.00131270, grad/param norm = 2.5488e-01, time/batch = 17.0616s	
20015/26050 (epoch 38.417), train_loss = 1.01555929, grad/param norm = 2.5848e-01, time/batch = 18.1515s	
20016/26050 (epoch 38.418), train_loss = 0.89217340, grad/param norm = 2.5042e-01, time/batch = 16.6371s	
20017/26050 (epoch 38.420), train_loss = 0.74332410, grad/param norm = 2.1090e-01, time/batch = 17.3068s	
20018/26050 (epoch 38.422), train_loss = 0.70846902, grad/param norm = 1.9820e-01, time/batch = 17.9642s	
20019/26050 (epoch 38.424), train_loss = 0.91753891, grad/param norm = 2.1779e-01, time/batch = 18.7362s	
20020/26050 (epoch 38.426), train_loss = 0.89598151, grad/param norm = 2.3253e-01, time/batch = 16.0378s	
20021/26050 (epoch 38.428), train_loss = 0.81011898, grad/param norm = 2.1211e-01, time/batch = 16.5252s	
20022/26050 (epoch 38.430), train_loss = 0.97776631, grad/param norm = 2.1474e-01, time/batch = 17.8968s	
20023/26050 (epoch 38.432), train_loss = 0.82701216, grad/param norm = 2.2948e-01, time/batch = 17.9037s	
20024/26050 (epoch 38.434), train_loss = 0.79217999, grad/param norm = 2.2165e-01, time/batch = 16.9811s	
20025/26050 (epoch 38.436), train_loss = 0.91183497, grad/param norm = 2.2649e-01, time/batch = 18.2228s	
20026/26050 (epoch 38.438), train_loss = 0.86555771, grad/param norm = 2.3494e-01, time/batch = 18.5674s	
20027/26050 (epoch 38.440), train_loss = 0.86415065, grad/param norm = 1.9616e-01, time/batch = 17.6487s	
20028/26050 (epoch 38.441), train_loss = 0.87240231, grad/param norm = 2.2148e-01, time/batch = 16.9924s	
20029/26050 (epoch 38.443), train_loss = 0.72639663, grad/param norm = 1.9070e-01, time/batch = 15.6380s	
20030/26050 (epoch 38.445), train_loss = 0.73991948, grad/param norm = 1.9976e-01, time/batch = 18.4892s	
20031/26050 (epoch 38.447), train_loss = 0.95909473, grad/param norm = 2.2219e-01, time/batch = 16.8201s	
20032/26050 (epoch 38.449), train_loss = 0.77213825, grad/param norm = 2.0594e-01, time/batch = 17.2732s	
20033/26050 (epoch 38.451), train_loss = 0.96757614, grad/param norm = 2.3055e-01, time/batch = 17.9822s	
20034/26050 (epoch 38.453), train_loss = 0.80137678, grad/param norm = 1.8225e-01, time/batch = 16.6521s	
20035/26050 (epoch 38.455), train_loss = 0.83643968, grad/param norm = 2.0423e-01, time/batch = 16.4731s	
20036/26050 (epoch 38.457), train_loss = 0.82277007, grad/param norm = 2.2694e-01, time/batch = 18.7391s	
20037/26050 (epoch 38.459), train_loss = 0.93829902, grad/param norm = 2.3808e-01, time/batch = 18.3191s	
20038/26050 (epoch 38.461), train_loss = 0.93401915, grad/param norm = 2.3307e-01, time/batch = 17.0570s	
20039/26050 (epoch 38.463), train_loss = 0.79408181, grad/param norm = 1.9097e-01, time/batch = 16.5490s	
20040/26050 (epoch 38.464), train_loss = 0.86954858, grad/param norm = 2.2285e-01, time/batch = 18.6441s	
20041/26050 (epoch 38.466), train_loss = 0.84488069, grad/param norm = 2.2361e-01, time/batch = 15.7127s	
20042/26050 (epoch 38.468), train_loss = 0.94861292, grad/param norm = 1.9813e-01, time/batch = 18.3118s	
20043/26050 (epoch 38.470), train_loss = 0.92545865, grad/param norm = 2.4625e-01, time/batch = 17.8335s	
20044/26050 (epoch 38.472), train_loss = 0.94041401, grad/param norm = 2.2919e-01, time/batch = 18.8200s	
20045/26050 (epoch 38.474), train_loss = 0.95821701, grad/param norm = 2.3119e-01, time/batch = 14.3527s	
20046/26050 (epoch 38.476), train_loss = 0.91421488, grad/param norm = 2.0110e-01, time/batch = 17.8022s	
20047/26050 (epoch 38.478), train_loss = 0.82054126, grad/param norm = 2.3011e-01, time/batch = 18.4834s	
20048/26050 (epoch 38.480), train_loss = 0.81420189, grad/param norm = 2.0690e-01, time/batch = 15.8739s	
20049/26050 (epoch 38.482), train_loss = 0.78628155, grad/param norm = 1.8713e-01, time/batch = 18.3029s	
20050/26050 (epoch 38.484), train_loss = 0.78383441, grad/param norm = 2.1297e-01, time/batch = 15.6330s	
20051/26050 (epoch 38.486), train_loss = 0.94413104, grad/param norm = 2.1166e-01, time/batch = 18.4978s	
20052/26050 (epoch 38.488), train_loss = 0.99747197, grad/param norm = 2.5639e-01, time/batch = 17.8036s	
20053/26050 (epoch 38.489), train_loss = 1.02891810, grad/param norm = 2.7337e-01, time/batch = 17.8129s	
20054/26050 (epoch 38.491), train_loss = 0.78804226, grad/param norm = 2.2710e-01, time/batch = 18.2240s	
20055/26050 (epoch 38.493), train_loss = 0.85539370, grad/param norm = 2.2931e-01, time/batch = 17.8033s	
20056/26050 (epoch 38.495), train_loss = 0.84329380, grad/param norm = 1.9472e-01, time/batch = 18.2344s	
20057/26050 (epoch 38.497), train_loss = 0.76861311, grad/param norm = 2.0564e-01, time/batch = 17.7997s	
20058/26050 (epoch 38.499), train_loss = 0.77473939, grad/param norm = 2.1701e-01, time/batch = 15.2294s	
20059/26050 (epoch 38.501), train_loss = 0.94728092, grad/param norm = 2.0582e-01, time/batch = 13.8883s	
20060/26050 (epoch 38.503), train_loss = 0.80302255, grad/param norm = 2.0536e-01, time/batch = 16.9857s	
20061/26050 (epoch 38.505), train_loss = 0.93694977, grad/param norm = 2.2319e-01, time/batch = 18.4025s	
20062/26050 (epoch 38.507), train_loss = 0.91441344, grad/param norm = 2.8232e-01, time/batch = 18.2174s	
20063/26050 (epoch 38.509), train_loss = 0.97015213, grad/param norm = 2.1453e-01, time/batch = 18.0476s	
20064/26050 (epoch 38.511), train_loss = 0.83237620, grad/param norm = 1.9178e-01, time/batch = 18.1544s	
20065/26050 (epoch 38.512), train_loss = 0.73273443, grad/param norm = 2.1564e-01, time/batch = 15.9623s	
20066/26050 (epoch 38.514), train_loss = 0.89412266, grad/param norm = 3.1282e-01, time/batch = 17.9740s	
20067/26050 (epoch 38.516), train_loss = 0.97286733, grad/param norm = 2.3519e-01, time/batch = 18.3917s	
20068/26050 (epoch 38.518), train_loss = 0.83137611, grad/param norm = 1.9468e-01, time/batch = 18.0590s	
20069/26050 (epoch 38.520), train_loss = 0.87231323, grad/param norm = 2.2741e-01, time/batch = 15.3067s	
20070/26050 (epoch 38.522), train_loss = 0.67183742, grad/param norm = 2.0189e-01, time/batch = 18.6374s	
20071/26050 (epoch 38.524), train_loss = 0.92707780, grad/param norm = 2.5052e-01, time/batch = 18.2415s	
20072/26050 (epoch 38.526), train_loss = 0.94526206, grad/param norm = 2.4787e-01, time/batch = 14.7083s	
20073/26050 (epoch 38.528), train_loss = 0.88120986, grad/param norm = 2.3272e-01, time/batch = 15.5542s	
20074/26050 (epoch 38.530), train_loss = 0.81431056, grad/param norm = 2.3483e-01, time/batch = 18.1334s	
20075/26050 (epoch 38.532), train_loss = 0.87342654, grad/param norm = 2.1122e-01, time/batch = 19.0582s	
20076/26050 (epoch 38.534), train_loss = 0.85266932, grad/param norm = 2.5916e-01, time/batch = 16.7381s	
20077/26050 (epoch 38.536), train_loss = 0.88968315, grad/param norm = 2.2529e-01, time/batch = 15.9790s	
20078/26050 (epoch 38.537), train_loss = 0.91328137, grad/param norm = 2.1479e-01, time/batch = 17.9659s	
20079/26050 (epoch 38.539), train_loss = 0.87851417, grad/param norm = 2.3707e-01, time/batch = 17.9480s	
20080/26050 (epoch 38.541), train_loss = 0.98961708, grad/param norm = 2.3894e-01, time/batch = 18.4642s	
20081/26050 (epoch 38.543), train_loss = 0.66348005, grad/param norm = 2.1829e-01, time/batch = 18.0815s	
20082/26050 (epoch 38.545), train_loss = 0.83348656, grad/param norm = 2.1642e-01, time/batch = 18.3036s	
20083/26050 (epoch 38.547), train_loss = 0.80971065, grad/param norm = 2.1590e-01, time/batch = 18.1433s	
20084/26050 (epoch 38.549), train_loss = 0.73012290, grad/param norm = 2.2954e-01, time/batch = 15.5698s	
20085/26050 (epoch 38.551), train_loss = 0.88420733, grad/param norm = 2.0679e-01, time/batch = 16.3011s	
20086/26050 (epoch 38.553), train_loss = 0.80960410, grad/param norm = 2.0349e-01, time/batch = 17.8790s	
20087/26050 (epoch 38.555), train_loss = 0.76129773, grad/param norm = 2.1861e-01, time/batch = 17.9930s	
20088/26050 (epoch 38.557), train_loss = 0.86426595, grad/param norm = 2.1263e-01, time/batch = 18.2374s	
20089/26050 (epoch 38.559), train_loss = 0.85154771, grad/param norm = 1.9701e-01, time/batch = 17.5438s	
20090/26050 (epoch 38.560), train_loss = 0.82015776, grad/param norm = 2.2036e-01, time/batch = 17.6553s	
20091/26050 (epoch 38.562), train_loss = 0.83530169, grad/param norm = 2.1320e-01, time/batch = 17.8000s	
20092/26050 (epoch 38.564), train_loss = 0.98944196, grad/param norm = 2.1780e-01, time/batch = 18.8943s	
20093/26050 (epoch 38.566), train_loss = 0.78785080, grad/param norm = 1.7678e-01, time/batch = 17.2257s	
20094/26050 (epoch 38.568), train_loss = 0.88257751, grad/param norm = 2.2319e-01, time/batch = 17.3827s	
20095/26050 (epoch 38.570), train_loss = 0.85481132, grad/param norm = 2.1555e-01, time/batch = 18.3242s	
20096/26050 (epoch 38.572), train_loss = 0.86084464, grad/param norm = 2.2287e-01, time/batch = 18.0556s	
20097/26050 (epoch 38.574), train_loss = 0.88614581, grad/param norm = 2.4785e-01, time/batch = 18.7308s	
20098/26050 (epoch 38.576), train_loss = 0.87719146, grad/param norm = 2.0724e-01, time/batch = 17.6297s	
20099/26050 (epoch 38.578), train_loss = 0.83046321, grad/param norm = 2.2752e-01, time/batch = 16.9508s	
20100/26050 (epoch 38.580), train_loss = 0.78482947, grad/param norm = 2.4560e-01, time/batch = 15.4437s	
20101/26050 (epoch 38.582), train_loss = 0.85878761, grad/param norm = 1.9804e-01, time/batch = 15.2139s	
20102/26050 (epoch 38.583), train_loss = 0.92193373, grad/param norm = 2.1915e-01, time/batch = 17.5803s	
20103/26050 (epoch 38.585), train_loss = 0.75591521, grad/param norm = 2.0687e-01, time/batch = 14.9434s	
20104/26050 (epoch 38.587), train_loss = 0.87711915, grad/param norm = 2.2916e-01, time/batch = 14.8171s	
20105/26050 (epoch 38.589), train_loss = 0.99095041, grad/param norm = 2.4284e-01, time/batch = 14.3260s	
20106/26050 (epoch 38.591), train_loss = 0.85203090, grad/param norm = 2.0998e-01, time/batch = 14.3359s	
20107/26050 (epoch 38.593), train_loss = 0.73733134, grad/param norm = 2.0402e-01, time/batch = 16.5516s	
20108/26050 (epoch 38.595), train_loss = 0.89431839, grad/param norm = 2.4233e-01, time/batch = 29.9592s	
20109/26050 (epoch 38.597), train_loss = 0.87209975, grad/param norm = 2.2331e-01, time/batch = 21.0906s	
20110/26050 (epoch 38.599), train_loss = 0.91706436, grad/param norm = 2.2945e-01, time/batch = 14.3474s	
20111/26050 (epoch 38.601), train_loss = 1.01088365, grad/param norm = 2.1011e-01, time/batch = 14.4181s	
20112/26050 (epoch 38.603), train_loss = 0.92289258, grad/param norm = 2.3811e-01, time/batch = 14.2487s	
20113/26050 (epoch 38.605), train_loss = 0.83916940, grad/param norm = 2.2209e-01, time/batch = 14.3313s	
20114/26050 (epoch 38.607), train_loss = 0.93995089, grad/param norm = 2.8646e-01, time/batch = 16.0958s	
20115/26050 (epoch 38.608), train_loss = 0.77029031, grad/param norm = 1.9893e-01, time/batch = 18.6476s	
20116/26050 (epoch 38.610), train_loss = 0.85528514, grad/param norm = 2.4082e-01, time/batch = 18.5777s	
20117/26050 (epoch 38.612), train_loss = 0.82980568, grad/param norm = 2.4643e-01, time/batch = 18.0665s	
20118/26050 (epoch 38.614), train_loss = 0.85499024, grad/param norm = 2.1466e-01, time/batch = 16.8786s	
20119/26050 (epoch 38.616), train_loss = 0.90907916, grad/param norm = 2.2201e-01, time/batch = 16.3868s	
20120/26050 (epoch 38.618), train_loss = 0.82030831, grad/param norm = 2.1521e-01, time/batch = 18.1298s	
20121/26050 (epoch 38.620), train_loss = 0.92656807, grad/param norm = 2.2449e-01, time/batch = 18.8078s	
20122/26050 (epoch 38.622), train_loss = 0.77827735, grad/param norm = 1.9728e-01, time/batch = 18.4805s	
20123/26050 (epoch 38.624), train_loss = 0.72172048, grad/param norm = 1.9552e-01, time/batch = 17.8920s	
20124/26050 (epoch 38.626), train_loss = 0.89309055, grad/param norm = 2.3070e-01, time/batch = 16.5240s	
20125/26050 (epoch 38.628), train_loss = 0.81615936, grad/param norm = 2.4538e-01, time/batch = 16.8045s	
20126/26050 (epoch 38.630), train_loss = 0.98051959, grad/param norm = 2.1292e-01, time/batch = 18.4893s	
20127/26050 (epoch 38.631), train_loss = 0.99439270, grad/param norm = 2.3999e-01, time/batch = 16.5499s	
20128/26050 (epoch 38.633), train_loss = 0.78231968, grad/param norm = 2.2099e-01, time/batch = 17.2091s	
20129/26050 (epoch 38.635), train_loss = 0.80052430, grad/param norm = 1.7413e-01, time/batch = 18.2324s	
20130/26050 (epoch 38.637), train_loss = 0.74749462, grad/param norm = 2.0728e-01, time/batch = 18.7384s	
20131/26050 (epoch 38.639), train_loss = 0.89139575, grad/param norm = 2.0357e-01, time/batch = 18.2258s	
20132/26050 (epoch 38.641), train_loss = 0.79912131, grad/param norm = 2.2129e-01, time/batch = 17.8945s	
20133/26050 (epoch 38.643), train_loss = 0.78190435, grad/param norm = 1.6489e-01, time/batch = 16.5568s	
20134/26050 (epoch 38.645), train_loss = 0.79956815, grad/param norm = 2.0984e-01, time/batch = 16.9824s	
20135/26050 (epoch 38.647), train_loss = 0.76156989, grad/param norm = 2.2853e-01, time/batch = 18.5666s	
20136/26050 (epoch 38.649), train_loss = 0.82319380, grad/param norm = 2.4091e-01, time/batch = 17.7354s	
20137/26050 (epoch 38.651), train_loss = 0.80550280, grad/param norm = 2.0557e-01, time/batch = 17.8143s	
20138/26050 (epoch 38.653), train_loss = 0.83745774, grad/param norm = 2.1179e-01, time/batch = 15.8200s	
20139/26050 (epoch 38.655), train_loss = 0.75453218, grad/param norm = 2.1188e-01, time/batch = 18.0682s	
20140/26050 (epoch 38.656), train_loss = 0.74917276, grad/param norm = 1.8310e-01, time/batch = 17.1557s	
20141/26050 (epoch 38.658), train_loss = 1.00884554, grad/param norm = 2.3165e-01, time/batch = 17.6346s	
20142/26050 (epoch 38.660), train_loss = 0.71105987, grad/param norm = 1.9854e-01, time/batch = 17.8998s	
20143/26050 (epoch 38.662), train_loss = 0.83337353, grad/param norm = 2.0539e-01, time/batch = 16.1330s	
20144/26050 (epoch 38.664), train_loss = 0.83681389, grad/param norm = 2.0690e-01, time/batch = 17.3930s	
20145/26050 (epoch 38.666), train_loss = 0.79517261, grad/param norm = 2.0052e-01, time/batch = 18.5742s	
20146/26050 (epoch 38.668), train_loss = 0.65485298, grad/param norm = 2.0270e-01, time/batch = 14.8833s	
20147/26050 (epoch 38.670), train_loss = 0.97681165, grad/param norm = 2.5700e-01, time/batch = 18.2322s	
20148/26050 (epoch 38.672), train_loss = 0.83777991, grad/param norm = 2.1734e-01, time/batch = 17.5731s	
20149/26050 (epoch 38.674), train_loss = 0.74847987, grad/param norm = 2.1544e-01, time/batch = 18.7349s	
20150/26050 (epoch 38.676), train_loss = 0.89894777, grad/param norm = 2.5285e-01, time/batch = 17.8224s	
20151/26050 (epoch 38.678), train_loss = 0.91831687, grad/param norm = 2.1181e-01, time/batch = 17.6436s	
20152/26050 (epoch 38.679), train_loss = 0.98068859, grad/param norm = 2.2497e-01, time/batch = 17.7296s	
20153/26050 (epoch 38.681), train_loss = 0.85144612, grad/param norm = 2.2750e-01, time/batch = 16.1188s	
20154/26050 (epoch 38.683), train_loss = 0.77162535, grad/param norm = 3.0507e-01, time/batch = 17.2041s	
20155/26050 (epoch 38.685), train_loss = 0.81428084, grad/param norm = 2.0391e-01, time/batch = 17.7181s	
20156/26050 (epoch 38.687), train_loss = 0.73524913, grad/param norm = 2.1689e-01, time/batch = 17.7301s	
20157/26050 (epoch 38.689), train_loss = 0.78953480, grad/param norm = 2.1272e-01, time/batch = 18.7341s	
20158/26050 (epoch 38.691), train_loss = 0.68555308, grad/param norm = 1.7873e-01, time/batch = 17.2094s	
20159/26050 (epoch 38.693), train_loss = 0.79850727, grad/param norm = 2.4424e-01, time/batch = 17.4988s	
20160/26050 (epoch 38.695), train_loss = 0.82367864, grad/param norm = 2.0562e-01, time/batch = 18.9012s	
20161/26050 (epoch 38.697), train_loss = 0.78580578, grad/param norm = 2.1122e-01, time/batch = 15.2213s	
20162/26050 (epoch 38.699), train_loss = 0.87515298, grad/param norm = 2.0343e-01, time/batch = 17.9928s	
20163/26050 (epoch 38.701), train_loss = 0.75463314, grad/param norm = 1.7723e-01, time/batch = 18.8235s	
20164/26050 (epoch 38.702), train_loss = 0.91671249, grad/param norm = 2.4799e-01, time/batch = 18.6513s	
20165/26050 (epoch 38.704), train_loss = 0.95123502, grad/param norm = 2.0861e-01, time/batch = 15.4648s	
20166/26050 (epoch 38.706), train_loss = 0.77715137, grad/param norm = 2.2568e-01, time/batch = 17.0700s	
20167/26050 (epoch 38.708), train_loss = 0.89614391, grad/param norm = 2.1779e-01, time/batch = 16.4572s	
20168/26050 (epoch 38.710), train_loss = 0.86522958, grad/param norm = 2.3310e-01, time/batch = 15.2977s	
20169/26050 (epoch 38.712), train_loss = 0.82423791, grad/param norm = 2.0952e-01, time/batch = 18.1470s	
20170/26050 (epoch 38.714), train_loss = 0.73273758, grad/param norm = 1.6490e-01, time/batch = 17.9680s	
20171/26050 (epoch 38.716), train_loss = 1.04351973, grad/param norm = 2.4101e-01, time/batch = 18.8961s	
20172/26050 (epoch 38.718), train_loss = 0.89606460, grad/param norm = 2.2562e-01, time/batch = 17.7270s	
20173/26050 (epoch 38.720), train_loss = 0.82273444, grad/param norm = 2.2103e-01, time/batch = 18.3142s	
20174/26050 (epoch 38.722), train_loss = 0.76204120, grad/param norm = 2.0185e-01, time/batch = 18.2253s	
20175/26050 (epoch 38.724), train_loss = 0.79586069, grad/param norm = 2.4177e-01, time/batch = 13.2741s	
20176/26050 (epoch 38.726), train_loss = 0.91125363, grad/param norm = 2.2745e-01, time/batch = 0.6772s	
20177/26050 (epoch 38.727), train_loss = 0.89013670, grad/param norm = 2.1329e-01, time/batch = 0.6755s	
20178/26050 (epoch 38.729), train_loss = 0.86485806, grad/param norm = 2.0148e-01, time/batch = 0.6712s	
20179/26050 (epoch 38.731), train_loss = 0.88052582, grad/param norm = 2.1300e-01, time/batch = 0.6737s	
20180/26050 (epoch 38.733), train_loss = 0.79634277, grad/param norm = 2.2132e-01, time/batch = 0.6501s	
20181/26050 (epoch 38.735), train_loss = 0.95986024, grad/param norm = 2.2692e-01, time/batch = 0.6543s	
20182/26050 (epoch 38.737), train_loss = 0.80831573, grad/param norm = 2.4737e-01, time/batch = 0.6502s	
20183/26050 (epoch 38.739), train_loss = 0.88008695, grad/param norm = 2.1249e-01, time/batch = 0.8584s	
20184/26050 (epoch 38.741), train_loss = 0.77596981, grad/param norm = 1.9389e-01, time/batch = 0.9456s	
20185/26050 (epoch 38.743), train_loss = 0.83742015, grad/param norm = 2.5071e-01, time/batch = 0.9436s	
20186/26050 (epoch 38.745), train_loss = 0.74941289, grad/param norm = 2.1624e-01, time/batch = 0.9502s	
20187/26050 (epoch 38.747), train_loss = 0.78708538, grad/param norm = 2.3152e-01, time/batch = 0.9458s	
20188/26050 (epoch 38.749), train_loss = 0.93413457, grad/param norm = 2.4009e-01, time/batch = 1.2691s	
20189/26050 (epoch 38.750), train_loss = 0.81497309, grad/param norm = 1.9603e-01, time/batch = 1.7727s	
20190/26050 (epoch 38.752), train_loss = 0.77264251, grad/param norm = 2.1651e-01, time/batch = 1.7880s	
20191/26050 (epoch 38.754), train_loss = 0.84368632, grad/param norm = 2.1656e-01, time/batch = 11.8590s	
20192/26050 (epoch 38.756), train_loss = 0.80186437, grad/param norm = 2.3729e-01, time/batch = 18.3152s	
20193/26050 (epoch 38.758), train_loss = 0.83032953, grad/param norm = 2.2627e-01, time/batch = 17.8090s	
20194/26050 (epoch 38.760), train_loss = 0.96353442, grad/param norm = 2.6815e-01, time/batch = 16.4100s	
20195/26050 (epoch 38.762), train_loss = 0.78302611, grad/param norm = 1.8564e-01, time/batch = 16.7961s	
20196/26050 (epoch 38.764), train_loss = 0.79747909, grad/param norm = 2.0420e-01, time/batch = 18.4747s	
20197/26050 (epoch 38.766), train_loss = 0.83284275, grad/param norm = 2.2199e-01, time/batch = 18.8893s	
20198/26050 (epoch 38.768), train_loss = 0.73370251, grad/param norm = 2.0686e-01, time/batch = 17.8934s	
20199/26050 (epoch 38.770), train_loss = 0.81554850, grad/param norm = 2.4314e-01, time/batch = 18.4146s	
20200/26050 (epoch 38.772), train_loss = 0.84864563, grad/param norm = 2.2832e-01, time/batch = 18.3913s	
20201/26050 (epoch 38.774), train_loss = 0.73236444, grad/param norm = 2.2228e-01, time/batch = 17.9100s	
20202/26050 (epoch 38.775), train_loss = 0.61316237, grad/param norm = 2.2867e-01, time/batch = 15.4789s	
20203/26050 (epoch 38.777), train_loss = 0.79321803, grad/param norm = 2.1534e-01, time/batch = 15.3089s	
20204/26050 (epoch 38.779), train_loss = 0.82688141, grad/param norm = 2.8591e-01, time/batch = 17.3843s	
20205/26050 (epoch 38.781), train_loss = 0.76888213, grad/param norm = 2.2470e-01, time/batch = 18.8858s	
20206/26050 (epoch 38.783), train_loss = 0.72834312, grad/param norm = 2.1950e-01, time/batch = 18.1440s	
20207/26050 (epoch 38.785), train_loss = 0.83036187, grad/param norm = 2.4317e-01, time/batch = 18.5499s	
20208/26050 (epoch 38.787), train_loss = 0.72379952, grad/param norm = 2.0122e-01, time/batch = 17.8971s	
20209/26050 (epoch 38.789), train_loss = 0.74826682, grad/param norm = 2.3900e-01, time/batch = 18.5671s	
20210/26050 (epoch 38.791), train_loss = 0.77288342, grad/param norm = 2.3934e-01, time/batch = 17.0707s	
20211/26050 (epoch 38.793), train_loss = 0.81673088, grad/param norm = 2.2237e-01, time/batch = 18.3187s	
20212/26050 (epoch 38.795), train_loss = 0.68036834, grad/param norm = 1.8739e-01, time/batch = 18.8175s	
20213/26050 (epoch 38.797), train_loss = 0.72852746, grad/param norm = 2.3219e-01, time/batch = 15.5627s	
20214/26050 (epoch 38.798), train_loss = 0.80666487, grad/param norm = 2.5702e-01, time/batch = 17.3861s	
20215/26050 (epoch 38.800), train_loss = 0.70333866, grad/param norm = 2.0458e-01, time/batch = 18.3145s	
20216/26050 (epoch 38.802), train_loss = 0.78169292, grad/param norm = 2.5136e-01, time/batch = 16.6207s	
20217/26050 (epoch 38.804), train_loss = 0.80591693, grad/param norm = 2.1055e-01, time/batch = 16.9762s	
20218/26050 (epoch 38.806), train_loss = 0.89892032, grad/param norm = 2.3626e-01, time/batch = 15.7175s	
20219/26050 (epoch 38.808), train_loss = 0.85223544, grad/param norm = 2.5425e-01, time/batch = 18.1401s	
20220/26050 (epoch 38.810), train_loss = 0.81180192, grad/param norm = 2.2644e-01, time/batch = 17.1613s	
20221/26050 (epoch 38.812), train_loss = 0.69025010, grad/param norm = 2.1827e-01, time/batch = 18.4825s	
20222/26050 (epoch 38.814), train_loss = 0.73538053, grad/param norm = 2.1968e-01, time/batch = 17.5693s	
20223/26050 (epoch 38.816), train_loss = 0.86820180, grad/param norm = 2.2652e-01, time/batch = 18.5748s	
20224/26050 (epoch 38.818), train_loss = 0.90020579, grad/param norm = 2.5687e-01, time/batch = 17.9696s	
20225/26050 (epoch 38.820), train_loss = 0.84111197, grad/param norm = 2.1694e-01, time/batch = 17.2208s	
20226/26050 (epoch 38.821), train_loss = 0.93446330, grad/param norm = 2.3922e-01, time/batch = 18.8100s	
20227/26050 (epoch 38.823), train_loss = 1.02277339, grad/param norm = 2.3175e-01, time/batch = 15.8959s	
20228/26050 (epoch 38.825), train_loss = 0.83562671, grad/param norm = 2.2653e-01, time/batch = 16.8993s	
20229/26050 (epoch 38.827), train_loss = 0.81983008, grad/param norm = 2.7161e-01, time/batch = 17.7532s	
20230/26050 (epoch 38.829), train_loss = 0.92502820, grad/param norm = 2.3433e-01, time/batch = 15.2129s	
20231/26050 (epoch 38.831), train_loss = 0.96722594, grad/param norm = 2.3727e-01, time/batch = 18.7430s	
20232/26050 (epoch 38.833), train_loss = 0.94814829, grad/param norm = 2.5263e-01, time/batch = 17.9702s	
20233/26050 (epoch 38.835), train_loss = 0.97988336, grad/param norm = 2.8183e-01, time/batch = 18.0758s	
20234/26050 (epoch 38.837), train_loss = 0.86494130, grad/param norm = 2.0917e-01, time/batch = 17.0695s	
20235/26050 (epoch 38.839), train_loss = 0.82622706, grad/param norm = 2.6192e-01, time/batch = 18.2255s	
20236/26050 (epoch 38.841), train_loss = 0.91131458, grad/param norm = 2.5091e-01, time/batch = 18.4879s	
20237/26050 (epoch 38.843), train_loss = 0.81367987, grad/param norm = 1.9646e-01, time/batch = 15.8712s	
20238/26050 (epoch 38.845), train_loss = 0.78008937, grad/param norm = 1.9355e-01, time/batch = 15.3097s	
20239/26050 (epoch 38.846), train_loss = 0.86770463, grad/param norm = 2.1611e-01, time/batch = 18.1381s	
20240/26050 (epoch 38.848), train_loss = 0.81540897, grad/param norm = 2.2352e-01, time/batch = 17.6486s	
20241/26050 (epoch 38.850), train_loss = 0.74712469, grad/param norm = 1.9200e-01, time/batch = 16.0965s	
20242/26050 (epoch 38.852), train_loss = 0.85715883, grad/param norm = 2.0270e-01, time/batch = 18.0493s	
20243/26050 (epoch 38.854), train_loss = 0.82755715, grad/param norm = 2.2166e-01, time/batch = 18.3133s	
20244/26050 (epoch 38.856), train_loss = 0.77816145, grad/param norm = 2.2613e-01, time/batch = 17.7908s	
20245/26050 (epoch 38.858), train_loss = 0.75845318, grad/param norm = 1.9958e-01, time/batch = 18.0417s	
20246/26050 (epoch 38.860), train_loss = 0.86237887, grad/param norm = 2.4125e-01, time/batch = 16.8948s	
20247/26050 (epoch 38.862), train_loss = 0.90070197, grad/param norm = 2.1375e-01, time/batch = 16.6352s	
20248/26050 (epoch 38.864), train_loss = 0.82936243, grad/param norm = 2.5852e-01, time/batch = 17.3747s	
20249/26050 (epoch 38.866), train_loss = 0.80834604, grad/param norm = 2.1104e-01, time/batch = 18.3961s	
20250/26050 (epoch 38.868), train_loss = 0.88417951, grad/param norm = 2.3581e-01, time/batch = 18.9795s	
20251/26050 (epoch 38.869), train_loss = 0.75452518, grad/param norm = 1.9370e-01, time/batch = 17.3191s	
20252/26050 (epoch 38.871), train_loss = 0.71407952, grad/param norm = 1.9636e-01, time/batch = 18.0666s	
20253/26050 (epoch 38.873), train_loss = 0.87862721, grad/param norm = 2.2466e-01, time/batch = 18.9786s	
20254/26050 (epoch 38.875), train_loss = 0.78818542, grad/param norm = 2.3678e-01, time/batch = 14.6467s	
20255/26050 (epoch 38.877), train_loss = 0.78332482, grad/param norm = 1.9078e-01, time/batch = 18.7168s	
20256/26050 (epoch 38.879), train_loss = 0.88538069, grad/param norm = 2.1807e-01, time/batch = 18.3844s	
20257/26050 (epoch 38.881), train_loss = 0.91346761, grad/param norm = 2.2760e-01, time/batch = 18.9707s	
20258/26050 (epoch 38.883), train_loss = 0.88102664, grad/param norm = 2.3129e-01, time/batch = 18.0616s	
20259/26050 (epoch 38.885), train_loss = 0.65593251, grad/param norm = 2.0150e-01, time/batch = 17.6507s	
20260/26050 (epoch 38.887), train_loss = 0.90253522, grad/param norm = 2.5093e-01, time/batch = 18.6452s	
20261/26050 (epoch 38.889), train_loss = 0.75900846, grad/param norm = 2.0978e-01, time/batch = 17.5578s	
20262/26050 (epoch 38.891), train_loss = 0.70187407, grad/param norm = 2.2153e-01, time/batch = 17.8145s	
20263/26050 (epoch 38.893), train_loss = 0.70742608, grad/param norm = 2.0362e-01, time/batch = 16.6259s	
20264/26050 (epoch 38.894), train_loss = 0.78427671, grad/param norm = 2.2608e-01, time/batch = 14.9653s	
20265/26050 (epoch 38.896), train_loss = 0.90459039, grad/param norm = 2.7268e-01, time/batch = 18.4711s	
20266/26050 (epoch 38.898), train_loss = 0.77875041, grad/param norm = 1.9397e-01, time/batch = 15.4650s	
20267/26050 (epoch 38.900), train_loss = 0.86587499, grad/param norm = 2.9806e-01, time/batch = 17.2067s	
20268/26050 (epoch 38.902), train_loss = 0.79330063, grad/param norm = 2.2685e-01, time/batch = 17.0518s	
20269/26050 (epoch 38.904), train_loss = 0.80523065, grad/param norm = 2.1489e-01, time/batch = 18.8915s	
20270/26050 (epoch 38.906), train_loss = 0.81614763, grad/param norm = 2.6804e-01, time/batch = 18.3938s	
20271/26050 (epoch 38.908), train_loss = 0.85734642, grad/param norm = 2.1997e-01, time/batch = 17.5705s	
20272/26050 (epoch 38.910), train_loss = 0.76888558, grad/param norm = 1.9985e-01, time/batch = 14.9754s	
20273/26050 (epoch 38.912), train_loss = 1.01354358, grad/param norm = 2.5458e-01, time/batch = 16.9829s	
20274/26050 (epoch 38.914), train_loss = 1.13805758, grad/param norm = 2.6276e-01, time/batch = 18.1465s	
20275/26050 (epoch 38.916), train_loss = 0.88825122, grad/param norm = 2.3810e-01, time/batch = 17.2345s	
20276/26050 (epoch 38.917), train_loss = 0.87209092, grad/param norm = 2.3538e-01, time/batch = 17.9708s	
20277/26050 (epoch 38.919), train_loss = 0.86356605, grad/param norm = 2.3529e-01, time/batch = 17.9847s	
20278/26050 (epoch 38.921), train_loss = 0.78216965, grad/param norm = 2.3538e-01, time/batch = 17.7227s	
20279/26050 (epoch 38.923), train_loss = 0.86478738, grad/param norm = 3.3385e-01, time/batch = 16.3651s	
20280/26050 (epoch 38.925), train_loss = 0.83521146, grad/param norm = 2.0571e-01, time/batch = 18.4874s	
20281/26050 (epoch 38.927), train_loss = 0.76820513, grad/param norm = 1.8168e-01, time/batch = 16.7250s	
20282/26050 (epoch 38.929), train_loss = 0.72155942, grad/param norm = 1.9759e-01, time/batch = 17.9536s	
20283/26050 (epoch 38.931), train_loss = 1.00362898, grad/param norm = 3.3556e-01, time/batch = 14.5687s	
20284/26050 (epoch 38.933), train_loss = 0.83124497, grad/param norm = 2.1923e-01, time/batch = 18.4662s	
20285/26050 (epoch 38.935), train_loss = 0.79937745, grad/param norm = 1.9624e-01, time/batch = 15.8753s	
20286/26050 (epoch 38.937), train_loss = 0.90328218, grad/param norm = 2.4119e-01, time/batch = 18.6584s	
20287/26050 (epoch 38.939), train_loss = 0.77180764, grad/param norm = 1.7843e-01, time/batch = 17.8350s	
20288/26050 (epoch 38.940), train_loss = 0.83885174, grad/param norm = 2.1967e-01, time/batch = 18.2284s	
20289/26050 (epoch 38.942), train_loss = 0.78850925, grad/param norm = 2.0107e-01, time/batch = 18.5690s	
20290/26050 (epoch 38.944), train_loss = 0.80877552, grad/param norm = 2.0890e-01, time/batch = 18.3850s	
20291/26050 (epoch 38.946), train_loss = 0.98499139, grad/param norm = 2.1130e-01, time/batch = 16.6427s	
20292/26050 (epoch 38.948), train_loss = 0.71185664, grad/param norm = 2.0712e-01, time/batch = 16.5244s	
20293/26050 (epoch 38.950), train_loss = 0.84083864, grad/param norm = 2.2078e-01, time/batch = 17.6547s	
20294/26050 (epoch 38.952), train_loss = 0.86544300, grad/param norm = 1.9639e-01, time/batch = 18.8028s	
20295/26050 (epoch 38.954), train_loss = 0.89841457, grad/param norm = 2.1532e-01, time/batch = 17.6302s	
20296/26050 (epoch 38.956), train_loss = 0.77967578, grad/param norm = 1.9386e-01, time/batch = 18.4944s	
20297/26050 (epoch 38.958), train_loss = 0.76158016, grad/param norm = 1.9205e-01, time/batch = 17.3195s	
20298/26050 (epoch 38.960), train_loss = 0.86435960, grad/param norm = 2.2445e-01, time/batch = 15.7424s	
20299/26050 (epoch 38.962), train_loss = 0.82609633, grad/param norm = 2.0264e-01, time/batch = 17.7150s	
20300/26050 (epoch 38.964), train_loss = 0.80386389, grad/param norm = 2.1600e-01, time/batch = 14.8762s	
20301/26050 (epoch 38.965), train_loss = 0.74621227, grad/param norm = 1.9384e-01, time/batch = 18.1526s	
20302/26050 (epoch 38.967), train_loss = 1.09557706, grad/param norm = 2.2103e-01, time/batch = 17.7313s	
20303/26050 (epoch 38.969), train_loss = 0.83166320, grad/param norm = 1.9918e-01, time/batch = 15.4802s	
20304/26050 (epoch 38.971), train_loss = 0.82774623, grad/param norm = 2.0506e-01, time/batch = 18.4904s	
20305/26050 (epoch 38.973), train_loss = 0.84499267, grad/param norm = 2.0009e-01, time/batch = 18.5643s	
20306/26050 (epoch 38.975), train_loss = 0.85067202, grad/param norm = 2.2524e-01, time/batch = 18.1499s	
20307/26050 (epoch 38.977), train_loss = 0.81409090, grad/param norm = 1.8178e-01, time/batch = 18.0771s	
20308/26050 (epoch 38.979), train_loss = 0.68129656, grad/param norm = 1.9332e-01, time/batch = 18.1574s	
20309/26050 (epoch 38.981), train_loss = 0.92719223, grad/param norm = 2.1090e-01, time/batch = 17.3931s	
20310/26050 (epoch 38.983), train_loss = 0.88833753, grad/param norm = 2.0498e-01, time/batch = 18.4881s	
20311/26050 (epoch 38.985), train_loss = 0.87230024, grad/param norm = 2.5003e-01, time/batch = 18.3244s	
20312/26050 (epoch 38.987), train_loss = 0.94138570, grad/param norm = 2.2352e-01, time/batch = 17.0524s	
20313/26050 (epoch 38.988), train_loss = 0.87434270, grad/param norm = 2.4754e-01, time/batch = 18.0700s	
20314/26050 (epoch 38.990), train_loss = 0.71994367, grad/param norm = 1.7883e-01, time/batch = 18.5789s	
20315/26050 (epoch 38.992), train_loss = 0.99160143, grad/param norm = 2.4230e-01, time/batch = 17.6372s	
20316/26050 (epoch 38.994), train_loss = 0.78282392, grad/param norm = 2.4910e-01, time/batch = 17.7673s	
20317/26050 (epoch 38.996), train_loss = 0.72976731, grad/param norm = 2.2460e-01, time/batch = 18.4923s	
20318/26050 (epoch 38.998), train_loss = 0.84744901, grad/param norm = 2.0624e-01, time/batch = 18.3942s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
20319/26050 (epoch 39.000), train_loss = 0.77979012, grad/param norm = 2.1553e-01, time/batch = 16.8881s	
20320/26050 (epoch 39.002), train_loss = 0.88132501, grad/param norm = 2.3488e-01, time/batch = 15.5531s	
20321/26050 (epoch 39.004), train_loss = 0.75205584, grad/param norm = 2.1980e-01, time/batch = 18.9740s	
20322/26050 (epoch 39.006), train_loss = 0.78930022, grad/param norm = 2.8470e-01, time/batch = 17.8132s	
20323/26050 (epoch 39.008), train_loss = 0.76333198, grad/param norm = 2.1339e-01, time/batch = 18.3343s	
20324/26050 (epoch 39.010), train_loss = 0.75845309, grad/param norm = 2.2537e-01, time/batch = 14.4466s	
20325/26050 (epoch 39.012), train_loss = 0.80763240, grad/param norm = 2.0033e-01, time/batch = 18.5664s	
20326/26050 (epoch 39.013), train_loss = 1.05651964, grad/param norm = 2.9621e-01, time/batch = 24.2091s	
20327/26050 (epoch 39.015), train_loss = 0.83434049, grad/param norm = 2.1523e-01, time/batch = 29.4971s	
20328/26050 (epoch 39.017), train_loss = 0.85785526, grad/param norm = 1.8715e-01, time/batch = 16.7181s	
20329/26050 (epoch 39.019), train_loss = 0.72628634, grad/param norm = 1.6120e-01, time/batch = 18.3215s	
20330/26050 (epoch 39.021), train_loss = 0.91725924, grad/param norm = 2.1522e-01, time/batch = 17.5719s	
20331/26050 (epoch 39.023), train_loss = 0.71094453, grad/param norm = 2.4907e-01, time/batch = 18.2172s	
20332/26050 (epoch 39.025), train_loss = 0.81414337, grad/param norm = 2.0168e-01, time/batch = 17.9857s	
20333/26050 (epoch 39.027), train_loss = 0.67147011, grad/param norm = 2.0378e-01, time/batch = 17.9192s	
20334/26050 (epoch 39.029), train_loss = 0.85705133, grad/param norm = 1.8782e-01, time/batch = 18.5576s	
20335/26050 (epoch 39.031), train_loss = 0.95192952, grad/param norm = 2.9277e-01, time/batch = 16.1290s	
20336/26050 (epoch 39.033), train_loss = 0.84252615, grad/param norm = 2.2296e-01, time/batch = 18.5707s	
20337/26050 (epoch 39.035), train_loss = 0.86032622, grad/param norm = 1.9225e-01, time/batch = 18.2320s	
20338/26050 (epoch 39.036), train_loss = 0.73564086, grad/param norm = 2.4367e-01, time/batch = 17.7328s	
20339/26050 (epoch 39.038), train_loss = 0.67550965, grad/param norm = 2.0097e-01, time/batch = 18.2354s	
20340/26050 (epoch 39.040), train_loss = 0.81305673, grad/param norm = 2.1583e-01, time/batch = 17.7444s	
20341/26050 (epoch 39.042), train_loss = 0.70702603, grad/param norm = 1.9036e-01, time/batch = 18.4741s	
20342/26050 (epoch 39.044), train_loss = 0.90147492, grad/param norm = 2.0792e-01, time/batch = 18.2282s	
20343/26050 (epoch 39.046), train_loss = 0.69994283, grad/param norm = 1.8857e-01, time/batch = 16.2915s	
20344/26050 (epoch 39.048), train_loss = 0.83084178, grad/param norm = 2.0730e-01, time/batch = 15.3839s	
20345/26050 (epoch 39.050), train_loss = 0.79141579, grad/param norm = 2.0307e-01, time/batch = 17.8960s	
20346/26050 (epoch 39.052), train_loss = 0.76223351, grad/param norm = 2.2980e-01, time/batch = 16.7932s	
20347/26050 (epoch 39.054), train_loss = 0.68289069, grad/param norm = 1.8879e-01, time/batch = 16.3855s	
20348/26050 (epoch 39.056), train_loss = 0.66125999, grad/param norm = 1.5759e-01, time/batch = 17.9045s	
20349/26050 (epoch 39.058), train_loss = 0.79746535, grad/param norm = 1.9804e-01, time/batch = 18.2202s	
20350/26050 (epoch 39.060), train_loss = 0.84709328, grad/param norm = 1.9068e-01, time/batch = 17.7379s	
20351/26050 (epoch 39.061), train_loss = 0.70027784, grad/param norm = 1.9473e-01, time/batch = 19.0718s	
20352/26050 (epoch 39.063), train_loss = 0.81746811, grad/param norm = 2.0954e-01, time/batch = 17.3221s	
20353/26050 (epoch 39.065), train_loss = 0.67282805, grad/param norm = 1.8012e-01, time/batch = 18.5616s	
20354/26050 (epoch 39.067), train_loss = 0.81084897, grad/param norm = 2.4050e-01, time/batch = 17.9632s	
20355/26050 (epoch 39.069), train_loss = 0.83928852, grad/param norm = 2.2881e-01, time/batch = 17.8890s	
20356/26050 (epoch 39.071), train_loss = 0.84802329, grad/param norm = 2.3170e-01, time/batch = 17.5542s	
20357/26050 (epoch 39.073), train_loss = 0.97206002, grad/param norm = 2.2135e-01, time/batch = 17.4668s	
20358/26050 (epoch 39.075), train_loss = 0.79355900, grad/param norm = 2.2467e-01, time/batch = 17.9701s	
20359/26050 (epoch 39.077), train_loss = 0.76436554, grad/param norm = 2.1398e-01, time/batch = 17.5636s	
20360/26050 (epoch 39.079), train_loss = 0.78971094, grad/param norm = 2.1805e-01, time/batch = 17.3173s	
20361/26050 (epoch 39.081), train_loss = 0.78980783, grad/param norm = 2.0438e-01, time/batch = 15.3037s	
20362/26050 (epoch 39.083), train_loss = 0.91270281, grad/param norm = 1.9575e-01, time/batch = 17.7255s	
20363/26050 (epoch 39.084), train_loss = 0.82375266, grad/param norm = 2.8224e-01, time/batch = 17.8990s	
20364/26050 (epoch 39.086), train_loss = 0.93673146, grad/param norm = 2.6373e-01, time/batch = 18.4891s	
20365/26050 (epoch 39.088), train_loss = 0.82461034, grad/param norm = 2.1224e-01, time/batch = 17.8094s	
20366/26050 (epoch 39.090), train_loss = 0.86175964, grad/param norm = 2.3264e-01, time/batch = 14.9740s	
20367/26050 (epoch 39.092), train_loss = 0.87882512, grad/param norm = 2.2568e-01, time/batch = 18.0708s	
20368/26050 (epoch 39.094), train_loss = 0.70982360, grad/param norm = 2.1146e-01, time/batch = 14.8007s	
20369/26050 (epoch 39.096), train_loss = 0.84304269, grad/param norm = 1.9555e-01, time/batch = 17.3838s	
20370/26050 (epoch 39.098), train_loss = 0.82078317, grad/param norm = 2.1773e-01, time/batch = 18.5478s	
20371/26050 (epoch 39.100), train_loss = 0.74143379, grad/param norm = 2.0861e-01, time/batch = 16.9472s	
20372/26050 (epoch 39.102), train_loss = 0.84292562, grad/param norm = 2.4241e-01, time/batch = 18.1277s	
20373/26050 (epoch 39.104), train_loss = 0.78895110, grad/param norm = 2.1882e-01, time/batch = 15.7033s	
20374/26050 (epoch 39.106), train_loss = 0.88885297, grad/param norm = 2.4659e-01, time/batch = 18.3761s	
20375/26050 (epoch 39.107), train_loss = 0.69017658, grad/param norm = 1.9494e-01, time/batch = 19.1171s	
20376/26050 (epoch 39.109), train_loss = 0.76396776, grad/param norm = 1.9060e-01, time/batch = 17.3004s	
20377/26050 (epoch 39.111), train_loss = 0.94539093, grad/param norm = 2.2255e-01, time/batch = 18.0543s	
20378/26050 (epoch 39.113), train_loss = 0.78853960, grad/param norm = 1.9236e-01, time/batch = 18.1520s	
20379/26050 (epoch 39.115), train_loss = 0.91592732, grad/param norm = 2.1245e-01, time/batch = 16.3904s	
20380/26050 (epoch 39.117), train_loss = 0.82554409, grad/param norm = 2.1100e-01, time/batch = 17.3278s	
20381/26050 (epoch 39.119), train_loss = 0.72115565, grad/param norm = 1.9252e-01, time/batch = 18.4048s	
20382/26050 (epoch 39.121), train_loss = 0.81385317, grad/param norm = 1.9712e-01, time/batch = 15.8144s	
20383/26050 (epoch 39.123), train_loss = 0.75789082, grad/param norm = 2.6659e-01, time/batch = 18.2341s	
20384/26050 (epoch 39.125), train_loss = 0.69387704, grad/param norm = 1.9005e-01, time/batch = 17.5599s	
20385/26050 (epoch 39.127), train_loss = 0.68707749, grad/param norm = 1.8488e-01, time/batch = 16.4429s	
20386/26050 (epoch 39.129), train_loss = 0.63751461, grad/param norm = 2.0048e-01, time/batch = 17.4005s	
20387/26050 (epoch 39.131), train_loss = 0.80809357, grad/param norm = 2.2193e-01, time/batch = 18.3972s	
20388/26050 (epoch 39.132), train_loss = 0.83608355, grad/param norm = 2.2581e-01, time/batch = 15.6418s	
20389/26050 (epoch 39.134), train_loss = 0.85930910, grad/param norm = 2.6093e-01, time/batch = 17.8097s	
20390/26050 (epoch 39.136), train_loss = 0.79030049, grad/param norm = 2.0832e-01, time/batch = 18.1459s	
20391/26050 (epoch 39.138), train_loss = 0.57398559, grad/param norm = 1.8919e-01, time/batch = 18.8994s	
20392/26050 (epoch 39.140), train_loss = 0.67264067, grad/param norm = 2.5799e-01, time/batch = 18.6443s	
20393/26050 (epoch 39.142), train_loss = 0.69308875, grad/param norm = 2.1409e-01, time/batch = 17.3974s	
20394/26050 (epoch 39.144), train_loss = 0.66356100, grad/param norm = 2.1726e-01, time/batch = 17.4707s	
20395/26050 (epoch 39.146), train_loss = 0.61137819, grad/param norm = 1.7735e-01, time/batch = 17.8611s	
20396/26050 (epoch 39.148), train_loss = 0.63909933, grad/param norm = 1.7762e-01, time/batch = 17.9007s	
20397/26050 (epoch 39.150), train_loss = 0.75149548, grad/param norm = 2.2947e-01, time/batch = 18.7316s	
20398/26050 (epoch 39.152), train_loss = 0.92036045, grad/param norm = 2.6821e-01, time/batch = 18.3083s	
20399/26050 (epoch 39.154), train_loss = 0.64253131, grad/param norm = 1.9879e-01, time/batch = 17.8208s	
20400/26050 (epoch 39.155), train_loss = 0.68816360, grad/param norm = 1.9319e-01, time/batch = 18.1378s	
20401/26050 (epoch 39.157), train_loss = 0.77477492, grad/param norm = 2.3570e-01, time/batch = 17.8136s	
20402/26050 (epoch 39.159), train_loss = 0.83636773, grad/param norm = 2.3003e-01, time/batch = 17.8110s	
20403/26050 (epoch 39.161), train_loss = 0.81674954, grad/param norm = 2.2414e-01, time/batch = 15.5550s	
20404/26050 (epoch 39.163), train_loss = 0.67555814, grad/param norm = 2.1670e-01, time/batch = 14.9823s	
20405/26050 (epoch 39.165), train_loss = 0.61537389, grad/param norm = 2.0161e-01, time/batch = 17.9747s	
20406/26050 (epoch 39.167), train_loss = 0.92087871, grad/param norm = 2.3123e-01, time/batch = 17.7344s	
20407/26050 (epoch 39.169), train_loss = 0.81506448, grad/param norm = 2.1606e-01, time/batch = 17.5016s	
20408/26050 (epoch 39.171), train_loss = 0.72096767, grad/param norm = 2.0624e-01, time/batch = 18.0727s	
20409/26050 (epoch 39.173), train_loss = 0.77150662, grad/param norm = 2.0548e-01, time/batch = 18.8994s	
20410/26050 (epoch 39.175), train_loss = 0.78768916, grad/param norm = 2.1334e-01, time/batch = 16.4674s	
20411/26050 (epoch 39.177), train_loss = 0.86636318, grad/param norm = 2.1338e-01, time/batch = 17.3166s	
20412/26050 (epoch 39.179), train_loss = 0.61846813, grad/param norm = 1.8737e-01, time/batch = 17.4895s	
20413/26050 (epoch 39.180), train_loss = 1.03127217, grad/param norm = 2.3976e-01, time/batch = 17.8842s	
20414/26050 (epoch 39.182), train_loss = 0.95693280, grad/param norm = 2.4564e-01, time/batch = 17.9787s	
20415/26050 (epoch 39.184), train_loss = 0.84007279, grad/param norm = 2.1029e-01, time/batch = 18.4100s	
20416/26050 (epoch 39.186), train_loss = 0.69239156, grad/param norm = 1.9945e-01, time/batch = 17.5721s	
20417/26050 (epoch 39.188), train_loss = 0.85059939, grad/param norm = 2.0688e-01, time/batch = 14.6282s	
20418/26050 (epoch 39.190), train_loss = 0.86107124, grad/param norm = 3.0704e-01, time/batch = 17.0369s	
20419/26050 (epoch 39.192), train_loss = 0.89993730, grad/param norm = 1.9609e-01, time/batch = 17.9775s	
20420/26050 (epoch 39.194), train_loss = 0.85335621, grad/param norm = 2.2510e-01, time/batch = 17.1475s	
20421/26050 (epoch 39.196), train_loss = 0.86113161, grad/param norm = 2.1050e-01, time/batch = 16.3900s	
20422/26050 (epoch 39.198), train_loss = 0.74760671, grad/param norm = 2.0300e-01, time/batch = 19.0499s	
20423/26050 (epoch 39.200), train_loss = 0.72164384, grad/param norm = 2.3382e-01, time/batch = 17.3824s	
20424/26050 (epoch 39.202), train_loss = 0.82156580, grad/param norm = 2.1086e-01, time/batch = 18.3984s	
20425/26050 (epoch 39.203), train_loss = 0.92289700, grad/param norm = 2.0801e-01, time/batch = 18.5685s	
20426/26050 (epoch 39.205), train_loss = 0.76196400, grad/param norm = 2.2508e-01, time/batch = 16.9734s	
20427/26050 (epoch 39.207), train_loss = 0.73952697, grad/param norm = 2.3071e-01, time/batch = 16.7828s	
20428/26050 (epoch 39.209), train_loss = 0.88047264, grad/param norm = 2.2268e-01, time/batch = 14.9689s	
20429/26050 (epoch 39.211), train_loss = 0.70820079, grad/param norm = 2.0739e-01, time/batch = 18.7211s	
20430/26050 (epoch 39.213), train_loss = 0.82920075, grad/param norm = 2.5265e-01, time/batch = 18.0479s	
20431/26050 (epoch 39.215), train_loss = 0.79801048, grad/param norm = 2.3041e-01, time/batch = 18.7071s	
20432/26050 (epoch 39.217), train_loss = 0.76587828, grad/param norm = 1.7932e-01, time/batch = 16.1276s	
20433/26050 (epoch 39.219), train_loss = 0.76806644, grad/param norm = 2.0591e-01, time/batch = 18.0637s	
20434/26050 (epoch 39.221), train_loss = 0.72657618, grad/param norm = 2.1357e-01, time/batch = 17.7947s	
20435/26050 (epoch 39.223), train_loss = 0.88740028, grad/param norm = 2.2867e-01, time/batch = 18.6469s	
20436/26050 (epoch 39.225), train_loss = 0.72325452, grad/param norm = 1.9330e-01, time/batch = 17.8214s	
20437/26050 (epoch 39.226), train_loss = 0.83734028, grad/param norm = 2.4318e-01, time/batch = 17.5450s	
20438/26050 (epoch 39.228), train_loss = 0.94501909, grad/param norm = 2.1842e-01, time/batch = 18.2532s	
20439/26050 (epoch 39.230), train_loss = 0.82308011, grad/param norm = 1.8482e-01, time/batch = 17.7364s	
20440/26050 (epoch 39.232), train_loss = 0.89520756, grad/param norm = 2.3242e-01, time/batch = 14.9611s	
20441/26050 (epoch 39.234), train_loss = 0.71376717, grad/param norm = 1.9890e-01, time/batch = 18.3100s	
20442/26050 (epoch 39.236), train_loss = 0.87576476, grad/param norm = 2.0664e-01, time/batch = 17.8151s	
20443/26050 (epoch 39.238), train_loss = 0.70632917, grad/param norm = 2.1342e-01, time/batch = 18.2301s	
20444/26050 (epoch 39.240), train_loss = 0.82636444, grad/param norm = 2.2911e-01, time/batch = 15.6978s	
20445/26050 (epoch 39.242), train_loss = 0.77372291, grad/param norm = 2.1441e-01, time/batch = 17.0478s	
20446/26050 (epoch 39.244), train_loss = 0.83866037, grad/param norm = 2.3373e-01, time/batch = 18.7311s	
20447/26050 (epoch 39.246), train_loss = 0.77862707, grad/param norm = 1.8608e-01, time/batch = 18.0544s	
20448/26050 (epoch 39.248), train_loss = 0.82461199, grad/param norm = 2.2231e-01, time/batch = 18.4827s	
20449/26050 (epoch 39.250), train_loss = 0.83379973, grad/param norm = 2.6217e-01, time/batch = 16.2345s	
20450/26050 (epoch 39.251), train_loss = 0.77964553, grad/param norm = 2.4588e-01, time/batch = 16.9802s	
20451/26050 (epoch 39.253), train_loss = 0.70593984, grad/param norm = 2.0687e-01, time/batch = 19.1417s	
20452/26050 (epoch 39.255), train_loss = 0.97928216, grad/param norm = 2.2953e-01, time/batch = 18.2212s	
20453/26050 (epoch 39.257), train_loss = 0.83767088, grad/param norm = 2.3816e-01, time/batch = 18.1559s	
20454/26050 (epoch 39.259), train_loss = 0.90693522, grad/param norm = 2.3448e-01, time/batch = 16.8306s	
20455/26050 (epoch 39.261), train_loss = 0.70610924, grad/param norm = 2.2024e-01, time/batch = 18.1388s	
20456/26050 (epoch 39.263), train_loss = 0.92745555, grad/param norm = 2.4947e-01, time/batch = 18.3137s	
20457/26050 (epoch 39.265), train_loss = 0.94567256, grad/param norm = 2.6789e-01, time/batch = 17.3187s	
20458/26050 (epoch 39.267), train_loss = 0.93345067, grad/param norm = 1.9479e-01, time/batch = 18.4003s	
20459/26050 (epoch 39.269), train_loss = 0.93467882, grad/param norm = 2.2233e-01, time/batch = 16.1289s	
20460/26050 (epoch 39.271), train_loss = 0.83481661, grad/param norm = 2.3948e-01, time/batch = 18.3149s	
20461/26050 (epoch 39.273), train_loss = 0.73864687, grad/param norm = 2.1543e-01, time/batch = 18.1493s	
20462/26050 (epoch 39.274), train_loss = 0.78775388, grad/param norm = 2.0116e-01, time/batch = 18.1446s	
20463/26050 (epoch 39.276), train_loss = 0.78003325, grad/param norm = 2.3553e-01, time/batch = 18.3977s	
20464/26050 (epoch 39.278), train_loss = 0.88208165, grad/param norm = 2.0426e-01, time/batch = 14.6290s	
20465/26050 (epoch 39.280), train_loss = 0.81515197, grad/param norm = 1.9693e-01, time/batch = 15.9793s	
20466/26050 (epoch 39.282), train_loss = 0.88597942, grad/param norm = 2.1668e-01, time/batch = 17.8948s	
20467/26050 (epoch 39.284), train_loss = 0.80528230, grad/param norm = 1.9808e-01, time/batch = 18.1298s	
20468/26050 (epoch 39.286), train_loss = 0.86925876, grad/param norm = 2.7522e-01, time/batch = 14.7238s	
20469/26050 (epoch 39.288), train_loss = 0.71445650, grad/param norm = 1.9100e-01, time/batch = 17.0725s	
20470/26050 (epoch 39.290), train_loss = 0.81776198, grad/param norm = 2.1145e-01, time/batch = 17.5249s	
20471/26050 (epoch 39.292), train_loss = 0.75153541, grad/param norm = 2.1476e-01, time/batch = 17.0322s	
20472/26050 (epoch 39.294), train_loss = 0.81648591, grad/param norm = 2.4989e-01, time/batch = 18.0602s	
20473/26050 (epoch 39.296), train_loss = 0.90391610, grad/param norm = 2.1051e-01, time/batch = 18.8023s	
20474/26050 (epoch 39.298), train_loss = 0.85751811, grad/param norm = 2.1806e-01, time/batch = 17.9632s	
20475/26050 (epoch 39.299), train_loss = 0.69395796, grad/param norm = 2.1056e-01, time/batch = 18.9712s	
20476/26050 (epoch 39.301), train_loss = 0.68926012, grad/param norm = 2.0514e-01, time/batch = 15.8145s	
20477/26050 (epoch 39.303), train_loss = 0.82032543, grad/param norm = 2.4007e-01, time/batch = 16.9679s	
20478/26050 (epoch 39.305), train_loss = 0.66214509, grad/param norm = 2.0007e-01, time/batch = 16.7236s	
20479/26050 (epoch 39.307), train_loss = 0.72721032, grad/param norm = 2.2303e-01, time/batch = 17.9926s	
20480/26050 (epoch 39.309), train_loss = 0.84358892, grad/param norm = 2.3955e-01, time/batch = 18.7122s	
20481/26050 (epoch 39.311), train_loss = 0.84287975, grad/param norm = 3.1514e-01, time/batch = 16.1316s	
20482/26050 (epoch 39.313), train_loss = 0.81609732, grad/param norm = 2.3856e-01, time/batch = 15.7377s	
20483/26050 (epoch 39.315), train_loss = 0.87729580, grad/param norm = 2.3475e-01, time/batch = 18.4778s	
20484/26050 (epoch 39.317), train_loss = 0.82812044, grad/param norm = 2.4655e-01, time/batch = 16.9592s	
20485/26050 (epoch 39.319), train_loss = 0.76290602, grad/param norm = 2.8800e-01, time/batch = 15.1227s	
20486/26050 (epoch 39.321), train_loss = 0.82464074, grad/param norm = 2.3513e-01, time/batch = 18.8179s	
20487/26050 (epoch 39.322), train_loss = 0.90345568, grad/param norm = 2.4305e-01, time/batch = 17.5680s	
20488/26050 (epoch 39.324), train_loss = 0.64419052, grad/param norm = 1.8762e-01, time/batch = 17.0790s	
20489/26050 (epoch 39.326), train_loss = 0.91638658, grad/param norm = 2.0794e-01, time/batch = 18.8225s	
20490/26050 (epoch 39.328), train_loss = 0.85902826, grad/param norm = 2.1445e-01, time/batch = 17.6471s	
20491/26050 (epoch 39.330), train_loss = 0.72439272, grad/param norm = 2.3536e-01, time/batch = 17.7364s	
20492/26050 (epoch 39.332), train_loss = 0.87399735, grad/param norm = 2.1297e-01, time/batch = 16.4563s	
20493/26050 (epoch 39.334), train_loss = 0.73413116, grad/param norm = 2.3848e-01, time/batch = 18.2432s	
20494/26050 (epoch 39.336), train_loss = 0.77915394, grad/param norm = 2.3020e-01, time/batch = 18.3156s	
20495/26050 (epoch 39.338), train_loss = 0.70223731, grad/param norm = 2.0061e-01, time/batch = 17.2304s	
20496/26050 (epoch 39.340), train_loss = 0.86125690, grad/param norm = 2.2780e-01, time/batch = 18.3171s	
20497/26050 (epoch 39.342), train_loss = 0.90311588, grad/param norm = 2.1864e-01, time/batch = 18.6330s	
20498/26050 (epoch 39.344), train_loss = 0.75313286, grad/param norm = 2.2515e-01, time/batch = 15.8131s	
20499/26050 (epoch 39.345), train_loss = 0.79746412, grad/param norm = 2.1455e-01, time/batch = 17.6416s	
20500/26050 (epoch 39.347), train_loss = 0.93846236, grad/param norm = 2.4694e-01, time/batch = 17.9955s	
20501/26050 (epoch 39.349), train_loss = 0.86116939, grad/param norm = 2.1420e-01, time/batch = 16.8888s	
20502/26050 (epoch 39.351), train_loss = 0.83477289, grad/param norm = 2.3359e-01, time/batch = 14.9609s	
20503/26050 (epoch 39.353), train_loss = 0.82762473, grad/param norm = 2.2432e-01, time/batch = 18.0500s	
20504/26050 (epoch 39.355), train_loss = 0.81440600, grad/param norm = 2.3117e-01, time/batch = 17.8032s	
20505/26050 (epoch 39.357), train_loss = 0.78170124, grad/param norm = 1.9688e-01, time/batch = 18.1584s	
20506/26050 (epoch 39.359), train_loss = 0.89993290, grad/param norm = 2.2517e-01, time/batch = 17.8068s	
20507/26050 (epoch 39.361), train_loss = 0.73788539, grad/param norm = 1.9154e-01, time/batch = 18.0709s	
20508/26050 (epoch 39.363), train_loss = 0.87918661, grad/param norm = 2.0017e-01, time/batch = 18.2211s	
20509/26050 (epoch 39.365), train_loss = 0.79401230, grad/param norm = 1.9056e-01, time/batch = 17.9060s	
20510/26050 (epoch 39.367), train_loss = 0.86874973, grad/param norm = 1.9208e-01, time/batch = 17.8884s	
20511/26050 (epoch 39.369), train_loss = 0.72365461, grad/param norm = 1.7144e-01, time/batch = 18.6460s	
20512/26050 (epoch 39.370), train_loss = 0.72744822, grad/param norm = 1.7779e-01, time/batch = 17.8067s	
20513/26050 (epoch 39.372), train_loss = 0.79312278, grad/param norm = 2.1181e-01, time/batch = 15.3795s	
20514/26050 (epoch 39.374), train_loss = 0.94253859, grad/param norm = 2.1623e-01, time/batch = 18.4718s	
20515/26050 (epoch 39.376), train_loss = 0.92911220, grad/param norm = 2.3600e-01, time/batch = 17.7401s	
20516/26050 (epoch 39.378), train_loss = 0.77216624, grad/param norm = 1.9415e-01, time/batch = 18.6522s	
20517/26050 (epoch 39.380), train_loss = 0.91262333, grad/param norm = 2.5394e-01, time/batch = 17.7456s	
20518/26050 (epoch 39.382), train_loss = 1.03055832, grad/param norm = 2.9221e-01, time/batch = 18.3141s	
20519/26050 (epoch 39.384), train_loss = 0.79541223, grad/param norm = 2.3809e-01, time/batch = 18.4669s	
20520/26050 (epoch 39.386), train_loss = 0.88561309, grad/param norm = 2.5699e-01, time/batch = 17.6476s	
20521/26050 (epoch 39.388), train_loss = 0.84305973, grad/param norm = 2.9214e-01, time/batch = 17.6536s	
20522/26050 (epoch 39.390), train_loss = 0.78609104, grad/param norm = 2.0700e-01, time/batch = 14.7863s	
20523/26050 (epoch 39.392), train_loss = 0.71240584, grad/param norm = 1.8208e-01, time/batch = 18.3272s	
20524/26050 (epoch 39.393), train_loss = 0.87786020, grad/param norm = 2.3253e-01, time/batch = 17.8853s	
20525/26050 (epoch 39.395), train_loss = 0.86947201, grad/param norm = 2.4991e-01, time/batch = 16.9603s	
20526/26050 (epoch 39.397), train_loss = 0.88164058, grad/param norm = 2.3779e-01, time/batch = 18.3740s	
20527/26050 (epoch 39.399), train_loss = 0.77154261, grad/param norm = 2.2624e-01, time/batch = 18.9673s	
20528/26050 (epoch 39.401), train_loss = 0.81836503, grad/param norm = 2.3391e-01, time/batch = 17.9902s	
20529/26050 (epoch 39.403), train_loss = 0.84645078, grad/param norm = 2.5984e-01, time/batch = 24.4345s	
20530/26050 (epoch 39.405), train_loss = 0.85854386, grad/param norm = 2.9783e-01, time/batch = 29.2417s	
20531/26050 (epoch 39.407), train_loss = 0.95376291, grad/param norm = 2.6115e-01, time/batch = 17.9849s	
20532/26050 (epoch 39.409), train_loss = 0.94230300, grad/param norm = 2.3608e-01, time/batch = 17.8199s	
20533/26050 (epoch 39.411), train_loss = 0.92635649, grad/param norm = 2.2789e-01, time/batch = 18.8085s	
20534/26050 (epoch 39.413), train_loss = 1.00094022, grad/param norm = 2.4255e-01, time/batch = 15.3133s	
20535/26050 (epoch 39.415), train_loss = 0.99092565, grad/param norm = 2.4426e-01, time/batch = 17.8781s	
20536/26050 (epoch 39.417), train_loss = 0.99307029, grad/param norm = 2.5816e-01, time/batch = 15.8005s	
20537/26050 (epoch 39.418), train_loss = 0.89001101, grad/param norm = 2.6802e-01, time/batch = 18.7125s	
20538/26050 (epoch 39.420), train_loss = 0.72857793, grad/param norm = 2.1526e-01, time/batch = 16.7251s	
20539/26050 (epoch 39.422), train_loss = 0.70457082, grad/param norm = 1.9495e-01, time/batch = 16.7343s	
20540/26050 (epoch 39.424), train_loss = 0.92253438, grad/param norm = 2.3212e-01, time/batch = 18.3039s	
20541/26050 (epoch 39.426), train_loss = 0.88726150, grad/param norm = 2.5044e-01, time/batch = 17.2247s	
20542/26050 (epoch 39.428), train_loss = 0.80807718, grad/param norm = 2.3102e-01, time/batch = 17.9019s	
20543/26050 (epoch 39.430), train_loss = 0.97188142, grad/param norm = 2.1412e-01, time/batch = 17.9119s	
20544/26050 (epoch 39.432), train_loss = 0.80943028, grad/param norm = 2.1297e-01, time/batch = 16.8932s	
20545/26050 (epoch 39.434), train_loss = 0.78565358, grad/param norm = 2.0873e-01, time/batch = 16.7127s	
20546/26050 (epoch 39.436), train_loss = 0.91608494, grad/param norm = 2.3297e-01, time/batch = 17.5623s	
20547/26050 (epoch 39.438), train_loss = 0.86445860, grad/param norm = 2.3581e-01, time/batch = 18.8926s	
20548/26050 (epoch 39.440), train_loss = 0.85158977, grad/param norm = 2.0310e-01, time/batch = 17.5651s	
20549/26050 (epoch 39.441), train_loss = 0.86367285, grad/param norm = 2.0738e-01, time/batch = 16.8989s	
20550/26050 (epoch 39.443), train_loss = 0.72644567, grad/param norm = 1.7559e-01, time/batch = 15.9824s	
20551/26050 (epoch 39.445), train_loss = 0.73646304, grad/param norm = 2.3460e-01, time/batch = 18.4803s	
20552/26050 (epoch 39.447), train_loss = 0.95750696, grad/param norm = 2.2211e-01, time/batch = 18.6413s	
20553/26050 (epoch 39.449), train_loss = 0.75526065, grad/param norm = 2.2219e-01, time/batch = 17.0457s	
20554/26050 (epoch 39.451), train_loss = 0.96877783, grad/param norm = 2.2815e-01, time/batch = 18.1376s	
20555/26050 (epoch 39.453), train_loss = 0.79459708, grad/param norm = 1.9344e-01, time/batch = 16.3310s	
20556/26050 (epoch 39.455), train_loss = 0.83482542, grad/param norm = 2.1225e-01, time/batch = 16.9519s	
20557/26050 (epoch 39.457), train_loss = 0.80369607, grad/param norm = 2.1412e-01, time/batch = 18.1616s	
20558/26050 (epoch 39.459), train_loss = 0.90525242, grad/param norm = 2.0616e-01, time/batch = 17.8241s	
20559/26050 (epoch 39.461), train_loss = 0.93336669, grad/param norm = 2.5553e-01, time/batch = 17.8968s	
20560/26050 (epoch 39.463), train_loss = 0.78769455, grad/param norm = 1.7754e-01, time/batch = 18.1673s	
20561/26050 (epoch 39.464), train_loss = 0.85020053, grad/param norm = 2.3604e-01, time/batch = 18.6341s	
20562/26050 (epoch 39.466), train_loss = 0.83721855, grad/param norm = 2.4717e-01, time/batch = 18.1486s	
20563/26050 (epoch 39.468), train_loss = 0.93878591, grad/param norm = 2.0547e-01, time/batch = 15.0603s	
20564/26050 (epoch 39.470), train_loss = 0.93563940, grad/param norm = 3.0432e-01, time/batch = 18.2374s	
20565/26050 (epoch 39.472), train_loss = 0.92158892, grad/param norm = 2.5204e-01, time/batch = 17.3944s	
20566/26050 (epoch 39.474), train_loss = 0.96558864, grad/param norm = 2.4180e-01, time/batch = 18.9015s	
20567/26050 (epoch 39.476), train_loss = 0.90960326, grad/param norm = 2.0978e-01, time/batch = 18.5791s	
20568/26050 (epoch 39.478), train_loss = 0.80184101, grad/param norm = 2.0847e-01, time/batch = 17.2349s	
20569/26050 (epoch 39.480), train_loss = 0.78698077, grad/param norm = 1.9069e-01, time/batch = 18.7426s	
20570/26050 (epoch 39.482), train_loss = 0.79166477, grad/param norm = 2.0362e-01, time/batch = 15.0452s	
20571/26050 (epoch 39.484), train_loss = 0.78581445, grad/param norm = 2.2549e-01, time/batch = 18.7178s	
20572/26050 (epoch 39.486), train_loss = 0.94023005, grad/param norm = 2.2212e-01, time/batch = 14.6358s	
20573/26050 (epoch 39.488), train_loss = 0.99322398, grad/param norm = 2.8551e-01, time/batch = 16.9204s	
20574/26050 (epoch 39.489), train_loss = 1.00325713, grad/param norm = 2.3328e-01, time/batch = 17.8862s	
20575/26050 (epoch 39.491), train_loss = 0.75995896, grad/param norm = 2.2314e-01, time/batch = 17.5625s	
20576/26050 (epoch 39.493), train_loss = 0.85514967, grad/param norm = 2.1547e-01, time/batch = 14.8927s	
20577/26050 (epoch 39.495), train_loss = 0.82199957, grad/param norm = 1.8693e-01, time/batch = 18.5770s	
20578/26050 (epoch 39.497), train_loss = 0.75387283, grad/param norm = 2.0824e-01, time/batch = 17.5740s	
20579/26050 (epoch 39.499), train_loss = 0.76550386, grad/param norm = 2.2876e-01, time/batch = 17.3887s	
20580/26050 (epoch 39.501), train_loss = 0.92663923, grad/param norm = 2.0031e-01, time/batch = 18.2957s	
20581/26050 (epoch 39.503), train_loss = 0.78299247, grad/param norm = 2.2102e-01, time/batch = 18.3102s	
20582/26050 (epoch 39.505), train_loss = 0.92060773, grad/param norm = 1.9992e-01, time/batch = 14.7878s	
20583/26050 (epoch 39.507), train_loss = 0.91281146, grad/param norm = 2.5860e-01, time/batch = 14.6398s	
20584/26050 (epoch 39.509), train_loss = 0.97268520, grad/param norm = 2.4282e-01, time/batch = 16.7123s	
20585/26050 (epoch 39.511), train_loss = 0.82485748, grad/param norm = 1.9296e-01, time/batch = 18.6604s	
20586/26050 (epoch 39.512), train_loss = 0.72800189, grad/param norm = 2.2726e-01, time/batch = 17.6506s	
20587/26050 (epoch 39.514), train_loss = 0.88135714, grad/param norm = 2.2909e-01, time/batch = 18.3110s	
20588/26050 (epoch 39.516), train_loss = 0.96404180, grad/param norm = 2.3736e-01, time/batch = 17.8247s	
20589/26050 (epoch 39.518), train_loss = 0.80659078, grad/param norm = 2.0162e-01, time/batch = 14.3875s	
20590/26050 (epoch 39.520), train_loss = 0.84540430, grad/param norm = 2.1507e-01, time/batch = 14.3020s	
20591/26050 (epoch 39.522), train_loss = 0.67155387, grad/param norm = 2.0713e-01, time/batch = 15.1424s	
20592/26050 (epoch 39.524), train_loss = 0.92003984, grad/param norm = 2.6387e-01, time/batch = 14.5362s	
20593/26050 (epoch 39.526), train_loss = 0.93127405, grad/param norm = 2.4505e-01, time/batch = 15.3611s	
20594/26050 (epoch 39.528), train_loss = 0.87223848, grad/param norm = 2.2100e-01, time/batch = 17.5380s	
20595/26050 (epoch 39.530), train_loss = 0.83264358, grad/param norm = 2.4643e-01, time/batch = 18.7329s	
20596/26050 (epoch 39.532), train_loss = 0.86828185, grad/param norm = 2.2305e-01, time/batch = 18.3271s	
20597/26050 (epoch 39.534), train_loss = 0.84368343, grad/param norm = 2.8325e-01, time/batch = 17.2285s	
20598/26050 (epoch 39.536), train_loss = 0.88360875, grad/param norm = 2.2900e-01, time/batch = 17.7202s	
20599/26050 (epoch 39.537), train_loss = 0.91091896, grad/param norm = 2.2099e-01, time/batch = 17.5531s	
20600/26050 (epoch 39.539), train_loss = 0.86212764, grad/param norm = 2.1536e-01, time/batch = 18.0636s	
20601/26050 (epoch 39.541), train_loss = 0.97911424, grad/param norm = 2.5727e-01, time/batch = 15.4609s	
20602/26050 (epoch 39.543), train_loss = 0.67294450, grad/param norm = 1.8887e-01, time/batch = 16.7133s	
20603/26050 (epoch 39.545), train_loss = 0.82643557, grad/param norm = 2.0600e-01, time/batch = 18.0463s	
20604/26050 (epoch 39.547), train_loss = 0.78292663, grad/param norm = 1.9481e-01, time/batch = 14.6385s	
20605/26050 (epoch 39.549), train_loss = 0.70332822, grad/param norm = 1.9404e-01, time/batch = 18.3958s	
20606/26050 (epoch 39.551), train_loss = 0.87306856, grad/param norm = 2.0761e-01, time/batch = 15.3271s	
20607/26050 (epoch 39.553), train_loss = 0.81045414, grad/param norm = 2.1714e-01, time/batch = 17.5512s	
20608/26050 (epoch 39.555), train_loss = 0.72934706, grad/param norm = 2.2872e-01, time/batch = 17.8947s	
20609/26050 (epoch 39.557), train_loss = 0.85265765, grad/param norm = 1.9249e-01, time/batch = 18.6642s	
20610/26050 (epoch 39.559), train_loss = 0.84789395, grad/param norm = 2.0810e-01, time/batch = 18.7341s	
20611/26050 (epoch 39.560), train_loss = 0.80803369, grad/param norm = 2.2398e-01, time/batch = 18.3793s	
20612/26050 (epoch 39.562), train_loss = 0.81536556, grad/param norm = 2.0028e-01, time/batch = 18.3067s	
20613/26050 (epoch 39.564), train_loss = 0.97701537, grad/param norm = 2.2036e-01, time/batch = 18.8110s	
20614/26050 (epoch 39.566), train_loss = 0.78048552, grad/param norm = 1.7840e-01, time/batch = 19.6083s	
20615/26050 (epoch 39.568), train_loss = 0.87302539, grad/param norm = 2.4187e-01, time/batch = 18.9514s	
20616/26050 (epoch 39.570), train_loss = 0.83813819, grad/param norm = 2.1063e-01, time/batch = 22.6828s	
20617/26050 (epoch 39.572), train_loss = 0.86225104, grad/param norm = 2.8731e-01, time/batch = 21.7543s	
20618/26050 (epoch 39.574), train_loss = 0.89030198, grad/param norm = 2.6760e-01, time/batch = 23.9324s	
20619/26050 (epoch 39.576), train_loss = 0.86973973, grad/param norm = 2.1367e-01, time/batch = 23.8228s	
20620/26050 (epoch 39.578), train_loss = 0.80855034, grad/param norm = 2.3510e-01, time/batch = 24.0728s	
20621/26050 (epoch 39.580), train_loss = 0.77570334, grad/param norm = 2.3800e-01, time/batch = 22.5947s	
20622/26050 (epoch 39.582), train_loss = 0.85652465, grad/param norm = 2.0960e-01, time/batch = 22.5750s	
20623/26050 (epoch 39.583), train_loss = 0.89766895, grad/param norm = 1.9645e-01, time/batch = 23.0252s	
20624/26050 (epoch 39.585), train_loss = 0.75324902, grad/param norm = 2.2495e-01, time/batch = 20.8303s	
20625/26050 (epoch 39.587), train_loss = 0.87205422, grad/param norm = 2.5596e-01, time/batch = 23.1507s	
20626/26050 (epoch 39.589), train_loss = 0.97883878, grad/param norm = 2.2630e-01, time/batch = 24.6449s	
20627/26050 (epoch 39.591), train_loss = 0.86601065, grad/param norm = 2.9207e-01, time/batch = 22.1713s	
20628/26050 (epoch 39.593), train_loss = 0.72258106, grad/param norm = 1.9686e-01, time/batch = 23.3237s	
20629/26050 (epoch 39.595), train_loss = 0.87809503, grad/param norm = 2.3529e-01, time/batch = 21.0040s	
20630/26050 (epoch 39.597), train_loss = 0.85683188, grad/param norm = 2.1772e-01, time/batch = 23.3284s	
20631/26050 (epoch 39.599), train_loss = 0.91555526, grad/param norm = 2.4896e-01, time/batch = 30.5816s	
20632/26050 (epoch 39.601), train_loss = 0.99928627, grad/param norm = 2.3983e-01, time/batch = 17.4849s	
20633/26050 (epoch 39.603), train_loss = 0.93712430, grad/param norm = 2.6384e-01, time/batch = 15.6388s	
20634/26050 (epoch 39.605), train_loss = 0.82501511, grad/param norm = 2.3127e-01, time/batch = 17.8159s	
20635/26050 (epoch 39.607), train_loss = 0.92749946, grad/param norm = 2.6101e-01, time/batch = 17.7298s	
20636/26050 (epoch 39.608), train_loss = 0.76946304, grad/param norm = 1.9457e-01, time/batch = 18.3094s	
20637/26050 (epoch 39.610), train_loss = 0.85092675, grad/param norm = 2.3339e-01, time/batch = 16.8867s	
20638/26050 (epoch 39.612), train_loss = 0.81446823, grad/param norm = 2.2933e-01, time/batch = 17.5391s	
20639/26050 (epoch 39.614), train_loss = 0.85317365, grad/param norm = 2.1912e-01, time/batch = 17.4737s	
20640/26050 (epoch 39.616), train_loss = 0.89552889, grad/param norm = 2.4966e-01, time/batch = 18.4640s	
20641/26050 (epoch 39.618), train_loss = 0.80652034, grad/param norm = 2.1205e-01, time/batch = 17.8090s	
20642/26050 (epoch 39.620), train_loss = 0.93397976, grad/param norm = 2.3469e-01, time/batch = 17.8956s	
20643/26050 (epoch 39.622), train_loss = 0.76814456, grad/param norm = 2.0276e-01, time/batch = 15.2188s	
20644/26050 (epoch 39.624), train_loss = 0.70138114, grad/param norm = 1.9306e-01, time/batch = 18.1531s	
20645/26050 (epoch 39.626), train_loss = 0.87644137, grad/param norm = 2.0525e-01, time/batch = 18.6514s	
20646/26050 (epoch 39.628), train_loss = 0.79442790, grad/param norm = 2.4881e-01, time/batch = 15.4571s	
20647/26050 (epoch 39.630), train_loss = 0.98708599, grad/param norm = 2.3602e-01, time/batch = 17.7153s	
20648/26050 (epoch 39.631), train_loss = 0.98832461, grad/param norm = 2.5370e-01, time/batch = 16.4930s	
20649/26050 (epoch 39.633), train_loss = 0.76775655, grad/param norm = 2.2395e-01, time/batch = 17.9787s	
20650/26050 (epoch 39.635), train_loss = 0.79702569, grad/param norm = 1.8179e-01, time/batch = 17.2095s	
20651/26050 (epoch 39.637), train_loss = 0.73995983, grad/param norm = 2.1242e-01, time/batch = 18.2173s	
20652/26050 (epoch 39.639), train_loss = 0.87325062, grad/param norm = 1.9135e-01, time/batch = 18.8002s	
20653/26050 (epoch 39.641), train_loss = 0.77906465, grad/param norm = 2.0156e-01, time/batch = 18.0315s	
20654/26050 (epoch 39.643), train_loss = 0.77278709, grad/param norm = 1.7301e-01, time/batch = 16.9586s	
20655/26050 (epoch 39.645), train_loss = 0.78102777, grad/param norm = 1.9533e-01, time/batch = 18.4872s	
20656/26050 (epoch 39.647), train_loss = 0.74420662, grad/param norm = 2.1088e-01, time/batch = 16.6476s	
20657/26050 (epoch 39.649), train_loss = 0.82671110, grad/param norm = 2.4729e-01, time/batch = 16.0554s	
20658/26050 (epoch 39.651), train_loss = 0.80127016, grad/param norm = 2.7126e-01, time/batch = 18.6578s	
20659/26050 (epoch 39.653), train_loss = 0.82627207, grad/param norm = 2.1138e-01, time/batch = 17.1505s	
20660/26050 (epoch 39.655), train_loss = 0.75046907, grad/param norm = 2.0885e-01, time/batch = 17.3825s	
20661/26050 (epoch 39.656), train_loss = 0.75063109, grad/param norm = 2.0853e-01, time/batch = 17.7144s	
20662/26050 (epoch 39.658), train_loss = 1.01186587, grad/param norm = 2.5206e-01, time/batch = 17.8834s	
20663/26050 (epoch 39.660), train_loss = 0.70124209, grad/param norm = 2.1043e-01, time/batch = 16.1348s	
20664/26050 (epoch 39.662), train_loss = 0.82594770, grad/param norm = 2.0412e-01, time/batch = 18.5780s	
20665/26050 (epoch 39.664), train_loss = 0.83391517, grad/param norm = 2.2847e-01, time/batch = 15.1645s	
20666/26050 (epoch 39.666), train_loss = 0.79424208, grad/param norm = 2.2277e-01, time/batch = 17.3008s	
20667/26050 (epoch 39.668), train_loss = 0.64580583, grad/param norm = 2.1148e-01, time/batch = 15.6448s	
20668/26050 (epoch 39.670), train_loss = 0.96277204, grad/param norm = 2.5675e-01, time/batch = 18.1491s	
20669/26050 (epoch 39.672), train_loss = 0.81172663, grad/param norm = 2.0829e-01, time/batch = 17.9730s	
20670/26050 (epoch 39.674), train_loss = 0.73253762, grad/param norm = 2.0495e-01, time/batch = 16.9035s	
20671/26050 (epoch 39.676), train_loss = 0.88445229, grad/param norm = 2.2577e-01, time/batch = 18.6515s	
20672/26050 (epoch 39.678), train_loss = 0.91482513, grad/param norm = 2.2211e-01, time/batch = 17.5785s	
20673/26050 (epoch 39.679), train_loss = 0.96002607, grad/param norm = 2.4579e-01, time/batch = 17.9857s	
20674/26050 (epoch 39.681), train_loss = 0.85102509, grad/param norm = 2.1384e-01, time/batch = 18.2435s	
20675/26050 (epoch 39.683), train_loss = 0.74750218, grad/param norm = 2.0906e-01, time/batch = 17.9896s	
20676/26050 (epoch 39.685), train_loss = 0.79825839, grad/param norm = 2.1010e-01, time/batch = 14.3990s	
20677/26050 (epoch 39.687), train_loss = 0.72553504, grad/param norm = 2.0464e-01, time/batch = 15.8737s	
20678/26050 (epoch 39.689), train_loss = 0.78723289, grad/param norm = 2.1806e-01, time/batch = 14.3011s	
20679/26050 (epoch 39.691), train_loss = 0.66810142, grad/param norm = 1.6310e-01, time/batch = 14.1683s	
20680/26050 (epoch 39.693), train_loss = 0.79740156, grad/param norm = 2.6318e-01, time/batch = 17.7844s	
20681/26050 (epoch 39.695), train_loss = 0.81961605, grad/param norm = 2.1372e-01, time/batch = 15.2470s	
20682/26050 (epoch 39.697), train_loss = 0.77567785, grad/param norm = 2.6964e-01, time/batch = 15.2305s	
20683/26050 (epoch 39.699), train_loss = 0.89306409, grad/param norm = 2.4329e-01, time/batch = 18.1534s	
20684/26050 (epoch 39.701), train_loss = 0.75044081, grad/param norm = 1.8054e-01, time/batch = 17.0760s	
20685/26050 (epoch 39.702), train_loss = 0.90404632, grad/param norm = 2.1274e-01, time/batch = 18.2363s	
20686/26050 (epoch 39.704), train_loss = 0.92187691, grad/param norm = 2.0329e-01, time/batch = 18.0614s	
20687/26050 (epoch 39.706), train_loss = 0.77162434, grad/param norm = 2.0623e-01, time/batch = 18.4117s	
20688/26050 (epoch 39.708), train_loss = 0.86690738, grad/param norm = 2.0069e-01, time/batch = 17.5595s	
20689/26050 (epoch 39.710), train_loss = 0.86388098, grad/param norm = 2.4215e-01, time/batch = 18.3152s	
20690/26050 (epoch 39.712), train_loss = 0.83601155, grad/param norm = 2.3231e-01, time/batch = 18.6452s	
20691/26050 (epoch 39.714), train_loss = 0.74292457, grad/param norm = 1.8111e-01, time/batch = 17.8886s	
20692/26050 (epoch 39.716), train_loss = 1.03162273, grad/param norm = 2.5548e-01, time/batch = 18.2272s	
20693/26050 (epoch 39.718), train_loss = 0.87774428, grad/param norm = 2.2142e-01, time/batch = 16.3160s	
20694/26050 (epoch 39.720), train_loss = 0.81496935, grad/param norm = 2.1550e-01, time/batch = 16.3737s	
20695/26050 (epoch 39.722), train_loss = 0.75560761, grad/param norm = 2.0239e-01, time/batch = 17.2917s	
20696/26050 (epoch 39.724), train_loss = 0.76102142, grad/param norm = 2.0921e-01, time/batch = 15.9565s	
20697/26050 (epoch 39.726), train_loss = 0.90194207, grad/param norm = 2.2523e-01, time/batch = 18.6564s	
20698/26050 (epoch 39.727), train_loss = 0.88741236, grad/param norm = 2.2078e-01, time/batch = 17.8994s	
20699/26050 (epoch 39.729), train_loss = 0.86323067, grad/param norm = 1.9468e-01, time/batch = 17.9015s	
20700/26050 (epoch 39.731), train_loss = 0.87296987, grad/param norm = 2.1356e-01, time/batch = 18.6335s	
20701/26050 (epoch 39.733), train_loss = 0.81084517, grad/param norm = 2.2233e-01, time/batch = 16.9837s	
20702/26050 (epoch 39.735), train_loss = 0.95312089, grad/param norm = 2.3439e-01, time/batch = 18.3920s	
20703/26050 (epoch 39.737), train_loss = 0.79746286, grad/param norm = 2.4930e-01, time/batch = 18.5528s	
20704/26050 (epoch 39.739), train_loss = 0.86682683, grad/param norm = 1.9586e-01, time/batch = 15.3841s	
20705/26050 (epoch 39.741), train_loss = 0.76258010, grad/param norm = 1.9250e-01, time/batch = 16.7093s	
20706/26050 (epoch 39.743), train_loss = 0.82930056, grad/param norm = 2.7656e-01, time/batch = 17.8233s	
20707/26050 (epoch 39.745), train_loss = 0.74109633, grad/param norm = 2.1652e-01, time/batch = 18.9722s	
20708/26050 (epoch 39.747), train_loss = 0.78310146, grad/param norm = 2.1681e-01, time/batch = 17.8206s	
20709/26050 (epoch 39.749), train_loss = 0.92829715, grad/param norm = 2.3206e-01, time/batch = 15.3075s	
20710/26050 (epoch 39.750), train_loss = 0.80711413, grad/param norm = 2.0013e-01, time/batch = 17.9910s	
20711/26050 (epoch 39.752), train_loss = 0.77422560, grad/param norm = 2.5545e-01, time/batch = 17.0661s	
20712/26050 (epoch 39.754), train_loss = 0.83963218, grad/param norm = 2.2874e-01, time/batch = 18.5823s	
20713/26050 (epoch 39.756), train_loss = 0.78691693, grad/param norm = 2.1683e-01, time/batch = 18.0635s	
20714/26050 (epoch 39.758), train_loss = 0.82491450, grad/param norm = 2.2963e-01, time/batch = 18.3097s	
20715/26050 (epoch 39.760), train_loss = 0.95160955, grad/param norm = 2.2394e-01, time/batch = 16.1264s	
20716/26050 (epoch 39.762), train_loss = 0.79674570, grad/param norm = 2.2722e-01, time/batch = 18.5504s	
20717/26050 (epoch 39.764), train_loss = 0.81178816, grad/param norm = 2.3873e-01, time/batch = 18.4738s	
20718/26050 (epoch 39.766), train_loss = 0.81992281, grad/param norm = 2.3972e-01, time/batch = 14.3935s	
20719/26050 (epoch 39.768), train_loss = 0.71852688, grad/param norm = 1.9109e-01, time/batch = 17.3042s	
20720/26050 (epoch 39.770), train_loss = 0.82579995, grad/param norm = 2.5253e-01, time/batch = 17.7211s	
20721/26050 (epoch 39.772), train_loss = 0.82906312, grad/param norm = 2.2506e-01, time/batch = 17.8859s	
20722/26050 (epoch 39.774), train_loss = 0.70923907, grad/param norm = 2.2972e-01, time/batch = 17.7340s	
20723/26050 (epoch 39.775), train_loss = 0.60797156, grad/param norm = 1.8932e-01, time/batch = 18.1345s	
20724/26050 (epoch 39.777), train_loss = 0.78248728, grad/param norm = 2.1830e-01, time/batch = 17.6231s	
20725/26050 (epoch 39.779), train_loss = 0.81036744, grad/param norm = 2.4726e-01, time/batch = 16.8026s	
20726/26050 (epoch 39.781), train_loss = 0.75513915, grad/param norm = 2.2945e-01, time/batch = 18.0796s	
20727/26050 (epoch 39.783), train_loss = 0.71824063, grad/param norm = 1.9719e-01, time/batch = 19.1582s	
20728/26050 (epoch 39.785), train_loss = 0.82481833, grad/param norm = 2.4750e-01, time/batch = 20.5059s	
20729/26050 (epoch 39.787), train_loss = 0.72140321, grad/param norm = 2.0725e-01, time/batch = 31.1209s	
20730/26050 (epoch 39.789), train_loss = 0.73364578, grad/param norm = 2.1085e-01, time/batch = 21.5200s	
20731/26050 (epoch 39.791), train_loss = 0.74411404, grad/param norm = 2.3809e-01, time/batch = 17.3548s	
20732/26050 (epoch 39.793), train_loss = 0.81276767, grad/param norm = 2.0830e-01, time/batch = 19.0546s	
20733/26050 (epoch 39.795), train_loss = 0.66728098, grad/param norm = 1.9017e-01, time/batch = 17.4563s	
20734/26050 (epoch 39.797), train_loss = 0.72363063, grad/param norm = 2.0085e-01, time/batch = 17.9659s	
20735/26050 (epoch 39.798), train_loss = 0.77319315, grad/param norm = 2.2251e-01, time/batch = 16.8355s	
20736/26050 (epoch 39.800), train_loss = 0.69532788, grad/param norm = 1.9864e-01, time/batch = 18.3166s	
20737/26050 (epoch 39.802), train_loss = 0.77699072, grad/param norm = 2.2671e-01, time/batch = 14.9717s	
20738/26050 (epoch 39.804), train_loss = 0.80047894, grad/param norm = 2.1021e-01, time/batch = 18.7423s	
20739/26050 (epoch 39.806), train_loss = 0.89678555, grad/param norm = 2.6484e-01, time/batch = 18.0545s	
20740/26050 (epoch 39.808), train_loss = 0.82401648, grad/param norm = 1.9896e-01, time/batch = 18.3143s	
20741/26050 (epoch 39.810), train_loss = 0.81139240, grad/param norm = 2.2921e-01, time/batch = 17.9713s	
20742/26050 (epoch 39.812), train_loss = 0.67829336, grad/param norm = 2.2379e-01, time/batch = 18.1396s	
20743/26050 (epoch 39.814), train_loss = 0.73279511, grad/param norm = 2.6522e-01, time/batch = 15.7198s	
20744/26050 (epoch 39.816), train_loss = 0.86601658, grad/param norm = 2.4065e-01, time/batch = 17.1450s	
20745/26050 (epoch 39.818), train_loss = 0.90069694, grad/param norm = 2.7179e-01, time/batch = 18.5745s	
20746/26050 (epoch 39.820), train_loss = 0.84397341, grad/param norm = 2.2092e-01, time/batch = 14.8882s	
20747/26050 (epoch 39.821), train_loss = 0.91114555, grad/param norm = 2.3963e-01, time/batch = 17.9809s	
20748/26050 (epoch 39.823), train_loss = 1.01303003, grad/param norm = 2.2236e-01, time/batch = 17.7147s	
20749/26050 (epoch 39.825), train_loss = 0.81395775, grad/param norm = 2.1975e-01, time/batch = 18.3162s	
20750/26050 (epoch 39.827), train_loss = 0.81389138, grad/param norm = 2.5286e-01, time/batch = 18.4881s	
20751/26050 (epoch 39.829), train_loss = 0.91426612, grad/param norm = 2.4031e-01, time/batch = 16.8642s	
20752/26050 (epoch 39.831), train_loss = 0.95728100, grad/param norm = 2.2148e-01, time/batch = 18.2134s	
20753/26050 (epoch 39.833), train_loss = 0.92448661, grad/param norm = 2.6386e-01, time/batch = 15.8123s	
20754/26050 (epoch 39.835), train_loss = 0.93891849, grad/param norm = 2.2941e-01, time/batch = 17.3103s	
20755/26050 (epoch 39.837), train_loss = 0.84601451, grad/param norm = 2.0566e-01, time/batch = 18.1503s	
20756/26050 (epoch 39.839), train_loss = 0.82671299, grad/param norm = 2.8205e-01, time/batch = 17.6685s	
20757/26050 (epoch 39.841), train_loss = 0.88237856, grad/param norm = 2.3022e-01, time/batch = 18.9096s	
20758/26050 (epoch 39.843), train_loss = 0.82163477, grad/param norm = 2.0011e-01, time/batch = 18.8942s	
20759/26050 (epoch 39.845), train_loss = 0.77133877, grad/param norm = 2.0281e-01, time/batch = 18.2462s	
20760/26050 (epoch 39.846), train_loss = 0.85770907, grad/param norm = 2.2961e-01, time/batch = 15.9557s	
20761/26050 (epoch 39.848), train_loss = 0.79336284, grad/param norm = 2.2364e-01, time/batch = 16.4073s	
20762/26050 (epoch 39.850), train_loss = 0.73405284, grad/param norm = 2.0488e-01, time/batch = 18.7366s	
20763/26050 (epoch 39.852), train_loss = 0.85252156, grad/param norm = 2.0755e-01, time/batch = 18.3152s	
20764/26050 (epoch 39.854), train_loss = 0.82664831, grad/param norm = 2.1003e-01, time/batch = 17.6550s	
20765/26050 (epoch 39.856), train_loss = 0.76755716, grad/param norm = 2.2520e-01, time/batch = 17.9064s	
20766/26050 (epoch 39.858), train_loss = 0.74444513, grad/param norm = 2.0631e-01, time/batch = 18.3095s	
20767/26050 (epoch 39.860), train_loss = 0.85892970, grad/param norm = 2.3195e-01, time/batch = 14.8350s	
20768/26050 (epoch 39.862), train_loss = 0.89290754, grad/param norm = 1.9503e-01, time/batch = 16.0193s	
20769/26050 (epoch 39.864), train_loss = 0.81097005, grad/param norm = 2.4633e-01, time/batch = 18.3949s	
20770/26050 (epoch 39.866), train_loss = 0.81409922, grad/param norm = 2.0665e-01, time/batch = 18.3937s	
20771/26050 (epoch 39.868), train_loss = 0.88289154, grad/param norm = 2.7157e-01, time/batch = 17.4686s	
20772/26050 (epoch 39.869), train_loss = 0.74699583, grad/param norm = 1.9797e-01, time/batch = 17.6553s	
20773/26050 (epoch 39.871), train_loss = 0.69982888, grad/param norm = 2.0878e-01, time/batch = 17.8140s	
20774/26050 (epoch 39.873), train_loss = 0.87083654, grad/param norm = 2.2837e-01, time/batch = 16.5554s	
20775/26050 (epoch 39.875), train_loss = 0.77375697, grad/param norm = 2.1546e-01, time/batch = 18.1267s	
20776/26050 (epoch 39.877), train_loss = 0.78597933, grad/param norm = 2.0590e-01, time/batch = 17.6612s	
20777/26050 (epoch 39.879), train_loss = 0.86474835, grad/param norm = 2.0582e-01, time/batch = 18.8121s	
20778/26050 (epoch 39.881), train_loss = 0.88913858, grad/param norm = 2.4386e-01, time/batch = 16.4800s	
20779/26050 (epoch 39.883), train_loss = 0.87848191, grad/param norm = 2.3680e-01, time/batch = 17.3968s	
20780/26050 (epoch 39.885), train_loss = 0.65593944, grad/param norm = 2.2963e-01, time/batch = 17.2845s	
20781/26050 (epoch 39.887), train_loss = 0.90640402, grad/param norm = 2.2682e-01, time/batch = 17.6475s	
20782/26050 (epoch 39.889), train_loss = 0.75740931, grad/param norm = 2.1610e-01, time/batch = 18.4812s	
20783/26050 (epoch 39.891), train_loss = 0.70011594, grad/param norm = 1.9432e-01, time/batch = 18.7281s	
20784/26050 (epoch 39.893), train_loss = 0.70356205, grad/param norm = 2.1636e-01, time/batch = 17.8123s	
20785/26050 (epoch 39.894), train_loss = 0.75350755, grad/param norm = 2.1186e-01, time/batch = 17.9567s	
20786/26050 (epoch 39.896), train_loss = 0.88565466, grad/param norm = 2.2651e-01, time/batch = 18.3060s	
20787/26050 (epoch 39.898), train_loss = 0.77188086, grad/param norm = 2.0942e-01, time/batch = 18.8825s	
20788/26050 (epoch 39.900), train_loss = 0.84617582, grad/param norm = 2.3386e-01, time/batch = 15.7793s	
20789/26050 (epoch 39.902), train_loss = 0.78395514, grad/param norm = 2.0489e-01, time/batch = 16.1278s	
20790/26050 (epoch 39.904), train_loss = 0.80417236, grad/param norm = 2.0851e-01, time/batch = 17.8967s	
20791/26050 (epoch 39.906), train_loss = 0.80545142, grad/param norm = 2.6663e-01, time/batch = 17.9699s	
20792/26050 (epoch 39.908), train_loss = 0.84844048, grad/param norm = 2.0974e-01, time/batch = 18.3202s	
20793/26050 (epoch 39.910), train_loss = 0.75847268, grad/param norm = 2.0777e-01, time/batch = 18.6480s	
20794/26050 (epoch 39.912), train_loss = 0.99033263, grad/param norm = 2.6031e-01, time/batch = 18.5689s	
20795/26050 (epoch 39.914), train_loss = 1.11381651, grad/param norm = 2.6284e-01, time/batch = 17.4636s	
20796/26050 (epoch 39.916), train_loss = 0.88920576, grad/param norm = 2.5005e-01, time/batch = 18.0692s	
20797/26050 (epoch 39.917), train_loss = 0.87496620, grad/param norm = 2.5855e-01, time/batch = 17.9080s	
20798/26050 (epoch 39.919), train_loss = 0.85743220, grad/param norm = 2.3742e-01, time/batch = 17.7360s	
20799/26050 (epoch 39.921), train_loss = 0.77562878, grad/param norm = 2.1906e-01, time/batch = 18.2339s	
20800/26050 (epoch 39.923), train_loss = 0.85798868, grad/param norm = 2.2918e-01, time/batch = 18.2350s	
20801/26050 (epoch 39.925), train_loss = 0.82325970, grad/param norm = 2.2831e-01, time/batch = 15.5264s	
20802/26050 (epoch 39.927), train_loss = 0.76471095, grad/param norm = 1.7367e-01, time/batch = 18.3840s	
20803/26050 (epoch 39.929), train_loss = 0.70287510, grad/param norm = 1.9535e-01, time/batch = 14.5562s	
20804/26050 (epoch 39.931), train_loss = 0.98823389, grad/param norm = 2.7734e-01, time/batch = 18.3915s	
20805/26050 (epoch 39.933), train_loss = 0.81920256, grad/param norm = 2.1121e-01, time/batch = 17.2397s	
20806/26050 (epoch 39.935), train_loss = 0.77801593, grad/param norm = 2.0623e-01, time/batch = 17.4889s	
20807/26050 (epoch 39.937), train_loss = 0.88404858, grad/param norm = 2.0312e-01, time/batch = 18.3138s	
20808/26050 (epoch 39.939), train_loss = 0.75639513, grad/param norm = 1.9617e-01, time/batch = 17.8180s	
20809/26050 (epoch 39.940), train_loss = 0.81214469, grad/param norm = 1.8885e-01, time/batch = 18.7296s	
20810/26050 (epoch 39.942), train_loss = 0.76824631, grad/param norm = 2.0080e-01, time/batch = 17.7327s	
20811/26050 (epoch 39.944), train_loss = 0.80704183, grad/param norm = 1.9866e-01, time/batch = 18.7426s	
20812/26050 (epoch 39.946), train_loss = 0.97442676, grad/param norm = 2.0993e-01, time/batch = 6.8519s	
20813/26050 (epoch 39.948), train_loss = 0.70261184, grad/param norm = 2.2717e-01, time/batch = 0.6459s	
20814/26050 (epoch 39.950), train_loss = 0.83132990, grad/param norm = 2.2652e-01, time/batch = 0.6518s	
20815/26050 (epoch 39.952), train_loss = 0.87022316, grad/param norm = 2.1537e-01, time/batch = 0.6455s	
20816/26050 (epoch 39.954), train_loss = 0.90282570, grad/param norm = 2.4235e-01, time/batch = 0.6513s	
20817/26050 (epoch 39.956), train_loss = 0.77449209, grad/param norm = 1.9614e-01, time/batch = 0.6493s	
20818/26050 (epoch 39.958), train_loss = 0.74852126, grad/param norm = 2.0316e-01, time/batch = 0.6502s	
20819/26050 (epoch 39.960), train_loss = 0.85318465, grad/param norm = 2.1842e-01, time/batch = 0.6482s	
20820/26050 (epoch 39.962), train_loss = 0.81717796, grad/param norm = 1.9452e-01, time/batch = 0.9253s	
20821/26050 (epoch 39.964), train_loss = 0.79296658, grad/param norm = 2.2150e-01, time/batch = 0.9570s	
20822/26050 (epoch 39.965), train_loss = 0.74714472, grad/param norm = 2.7575e-01, time/batch = 0.9437s	
20823/26050 (epoch 39.967), train_loss = 1.07636922, grad/param norm = 2.4899e-01, time/batch = 0.9448s	
20824/26050 (epoch 39.969), train_loss = 0.83582381, grad/param norm = 1.9806e-01, time/batch = 0.9419s	
20825/26050 (epoch 39.971), train_loss = 0.83463059, grad/param norm = 2.1530e-01, time/batch = 1.5188s	
20826/26050 (epoch 39.973), train_loss = 0.82919196, grad/param norm = 2.0229e-01, time/batch = 1.8165s	
20827/26050 (epoch 39.975), train_loss = 0.84575920, grad/param norm = 2.2320e-01, time/batch = 1.7919s	
20828/26050 (epoch 39.977), train_loss = 0.81138892, grad/param norm = 1.9092e-01, time/batch = 16.6611s	
20829/26050 (epoch 39.979), train_loss = 0.66693459, grad/param norm = 1.9442e-01, time/batch = 17.2367s	
20830/26050 (epoch 39.981), train_loss = 0.92133497, grad/param norm = 2.0931e-01, time/batch = 16.5444s	
20831/26050 (epoch 39.983), train_loss = 0.87337567, grad/param norm = 2.1248e-01, time/batch = 18.3110s	
20832/26050 (epoch 39.985), train_loss = 0.86438337, grad/param norm = 2.4460e-01, time/batch = 18.3171s	
20833/26050 (epoch 39.987), train_loss = 0.92483156, grad/param norm = 2.2689e-01, time/batch = 15.6466s	
20834/26050 (epoch 39.988), train_loss = 0.87245063, grad/param norm = 2.3408e-01, time/batch = 17.1485s	
20835/26050 (epoch 39.990), train_loss = 0.72198949, grad/param norm = 1.9048e-01, time/batch = 15.0697s	
20836/26050 (epoch 39.992), train_loss = 0.96358705, grad/param norm = 2.3690e-01, time/batch = 17.9032s	
20837/26050 (epoch 39.994), train_loss = 0.77293162, grad/param norm = 2.4931e-01, time/batch = 17.0683s	
20838/26050 (epoch 39.996), train_loss = 0.73218323, grad/param norm = 2.3972e-01, time/batch = 18.2225s	
20839/26050 (epoch 39.998), train_loss = 0.84692084, grad/param norm = 2.1919e-01, time/batch = 18.2067s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
20840/26050 (epoch 40.000), train_loss = 0.76571223, grad/param norm = 2.2087e-01, time/batch = 17.7179s	
20841/26050 (epoch 40.002), train_loss = 0.86928427, grad/param norm = 2.2256e-01, time/batch = 18.7177s	
20842/26050 (epoch 40.004), train_loss = 0.73553727, grad/param norm = 2.1188e-01, time/batch = 17.6394s	
20843/26050 (epoch 40.006), train_loss = 0.77832562, grad/param norm = 2.4478e-01, time/batch = 17.3952s	
20844/26050 (epoch 40.008), train_loss = 0.76879811, grad/param norm = 2.5883e-01, time/batch = 16.8867s	
20845/26050 (epoch 40.010), train_loss = 0.75474979, grad/param norm = 2.3737e-01, time/batch = 18.1426s	
20846/26050 (epoch 40.012), train_loss = 0.81237795, grad/param norm = 2.2715e-01, time/batch = 14.3156s	
20847/26050 (epoch 40.013), train_loss = 1.03154691, grad/param norm = 2.4206e-01, time/batch = 17.3985s	
20848/26050 (epoch 40.015), train_loss = 0.81339717, grad/param norm = 2.1989e-01, time/batch = 16.6347s	
20849/26050 (epoch 40.017), train_loss = 0.85278229, grad/param norm = 2.0916e-01, time/batch = 18.1477s	
20850/26050 (epoch 40.019), train_loss = 0.71079264, grad/param norm = 1.6047e-01, time/batch = 16.7296s	
20851/26050 (epoch 40.021), train_loss = 0.90396044, grad/param norm = 2.2578e-01, time/batch = 17.5697s	
20852/26050 (epoch 40.023), train_loss = 0.68896622, grad/param norm = 2.1138e-01, time/batch = 18.3026s	
20853/26050 (epoch 40.025), train_loss = 0.81183357, grad/param norm = 2.1529e-01, time/batch = 17.7323s	
20854/26050 (epoch 40.027), train_loss = 0.66584857, grad/param norm = 2.0022e-01, time/batch = 16.2111s	
20855/26050 (epoch 40.029), train_loss = 0.85931191, grad/param norm = 1.9739e-01, time/batch = 17.7426s	
20856/26050 (epoch 40.031), train_loss = 0.93247387, grad/param norm = 2.3082e-01, time/batch = 18.8189s	
20857/26050 (epoch 40.033), train_loss = 0.81560449, grad/param norm = 2.0347e-01, time/batch = 16.3001s	
20858/26050 (epoch 40.035), train_loss = 0.84961399, grad/param norm = 1.8749e-01, time/batch = 17.3030s	
20859/26050 (epoch 40.036), train_loss = 0.71000830, grad/param norm = 2.1374e-01, time/batch = 15.5547s	
20860/26050 (epoch 40.038), train_loss = 0.67838588, grad/param norm = 1.9443e-01, time/batch = 17.9694s	
20861/26050 (epoch 40.040), train_loss = 0.80340928, grad/param norm = 2.0146e-01, time/batch = 16.9010s	
20862/26050 (epoch 40.042), train_loss = 0.70325823, grad/param norm = 2.2192e-01, time/batch = 18.3271s	
20863/26050 (epoch 40.044), train_loss = 0.88366829, grad/param norm = 1.9097e-01, time/batch = 17.7257s	
20864/26050 (epoch 40.046), train_loss = 0.69495484, grad/param norm = 1.7340e-01, time/batch = 17.8158s	
20865/26050 (epoch 40.048), train_loss = 0.80983139, grad/param norm = 1.9863e-01, time/batch = 17.6592s	
20866/26050 (epoch 40.050), train_loss = 0.77135284, grad/param norm = 2.0774e-01, time/batch = 18.4847s	
20867/26050 (epoch 40.052), train_loss = 0.76007860, grad/param norm = 2.1848e-01, time/batch = 18.6531s	
20868/26050 (epoch 40.054), train_loss = 0.67950678, grad/param norm = 1.9846e-01, time/batch = 18.1285s	
20869/26050 (epoch 40.056), train_loss = 0.66911000, grad/param norm = 1.8045e-01, time/batch = 17.4812s	
20870/26050 (epoch 40.058), train_loss = 0.78475037, grad/param norm = 1.9178e-01, time/batch = 17.8973s	
20871/26050 (epoch 40.060), train_loss = 0.85037890, grad/param norm = 2.0194e-01, time/batch = 17.2442s	
20872/26050 (epoch 40.061), train_loss = 0.71146013, grad/param norm = 2.1517e-01, time/batch = 15.3056s	
20873/26050 (epoch 40.063), train_loss = 0.80255308, grad/param norm = 2.1166e-01, time/batch = 18.5580s	
20874/26050 (epoch 40.065), train_loss = 0.67076445, grad/param norm = 1.9382e-01, time/batch = 16.8061s	
20875/26050 (epoch 40.067), train_loss = 0.81622273, grad/param norm = 2.2991e-01, time/batch = 18.5510s	
20876/26050 (epoch 40.069), train_loss = 0.83132459, grad/param norm = 2.1603e-01, time/batch = 18.6398s	
20877/26050 (epoch 40.071), train_loss = 0.84516708, grad/param norm = 2.4479e-01, time/batch = 15.2062s	
20878/26050 (epoch 40.073), train_loss = 0.95338111, grad/param norm = 2.0814e-01, time/batch = 16.9632s	
20879/26050 (epoch 40.075), train_loss = 0.78655976, grad/param norm = 2.0564e-01, time/batch = 18.3176s	
20880/26050 (epoch 40.077), train_loss = 0.75493685, grad/param norm = 2.1546e-01, time/batch = 18.2399s	
20881/26050 (epoch 40.079), train_loss = 0.77632911, grad/param norm = 2.0438e-01, time/batch = 17.8811s	
20882/26050 (epoch 40.081), train_loss = 0.79069784, grad/param norm = 2.3284e-01, time/batch = 18.1394s	
20883/26050 (epoch 40.083), train_loss = 0.90326500, grad/param norm = 2.0741e-01, time/batch = 18.7374s	
20884/26050 (epoch 40.084), train_loss = 0.82213657, grad/param norm = 2.3931e-01, time/batch = 18.2188s	
20885/26050 (epoch 40.086), train_loss = 0.95128362, grad/param norm = 2.5952e-01, time/batch = 14.8813s	
20886/26050 (epoch 40.088), train_loss = 0.81336922, grad/param norm = 2.1157e-01, time/batch = 17.9779s	
20887/26050 (epoch 40.090), train_loss = 0.84395908, grad/param norm = 2.2562e-01, time/batch = 18.4009s	
20888/26050 (epoch 40.092), train_loss = 0.86386306, grad/param norm = 2.0437e-01, time/batch = 17.4002s	
20889/26050 (epoch 40.094), train_loss = 0.69072181, grad/param norm = 1.9196e-01, time/batch = 17.9056s	
20890/26050 (epoch 40.096), train_loss = 0.84577013, grad/param norm = 1.9863e-01, time/batch = 16.4671s	
20891/26050 (epoch 40.098), train_loss = 0.81562006, grad/param norm = 2.1724e-01, time/batch = 18.3103s	
20892/26050 (epoch 40.100), train_loss = 0.73673851, grad/param norm = 2.1662e-01, time/batch = 16.8817s	
20893/26050 (epoch 40.102), train_loss = 0.82817653, grad/param norm = 2.4397e-01, time/batch = 15.3009s	
20894/26050 (epoch 40.104), train_loss = 0.77788759, grad/param norm = 2.2555e-01, time/batch = 17.9710s	
20895/26050 (epoch 40.106), train_loss = 0.86670948, grad/param norm = 2.3748e-01, time/batch = 17.1353s	
20896/26050 (epoch 40.107), train_loss = 0.67986247, grad/param norm = 1.9655e-01, time/batch = 17.3923s	
20897/26050 (epoch 40.109), train_loss = 0.75045738, grad/param norm = 1.9736e-01, time/batch = 18.5597s	
20898/26050 (epoch 40.111), train_loss = 0.93798229, grad/param norm = 2.7045e-01, time/batch = 17.3935s	
20899/26050 (epoch 40.113), train_loss = 0.78165964, grad/param norm = 1.9258e-01, time/batch = 15.7463s	
20900/26050 (epoch 40.115), train_loss = 0.90576961, grad/param norm = 2.1064e-01, time/batch = 18.4824s	
20901/26050 (epoch 40.117), train_loss = 0.78469671, grad/param norm = 2.0350e-01, time/batch = 18.4039s	
20902/26050 (epoch 40.119), train_loss = 0.71326510, grad/param norm = 1.8254e-01, time/batch = 17.2144s	
20903/26050 (epoch 40.121), train_loss = 0.81185243, grad/param norm = 2.2265e-01, time/batch = 15.1462s	
20904/26050 (epoch 40.123), train_loss = 0.74220185, grad/param norm = 2.0687e-01, time/batch = 17.0278s	
20905/26050 (epoch 40.125), train_loss = 0.69003348, grad/param norm = 1.9883e-01, time/batch = 17.9740s	
20906/26050 (epoch 40.127), train_loss = 0.68881675, grad/param norm = 1.8825e-01, time/batch = 17.0571s	
20907/26050 (epoch 40.129), train_loss = 0.64768451, grad/param norm = 2.0020e-01, time/batch = 15.5562s	
20908/26050 (epoch 40.131), train_loss = 0.80447619, grad/param norm = 2.1862e-01, time/batch = 18.8088s	
20909/26050 (epoch 40.132), train_loss = 0.81309938, grad/param norm = 2.1450e-01, time/batch = 17.6447s	
20910/26050 (epoch 40.134), train_loss = 0.84095606, grad/param norm = 2.4620e-01, time/batch = 18.4743s	
20911/26050 (epoch 40.136), train_loss = 0.79149081, grad/param norm = 2.1642e-01, time/batch = 17.9679s	
20912/26050 (epoch 40.138), train_loss = 0.55655664, grad/param norm = 1.8512e-01, time/batch = 17.3647s	
20913/26050 (epoch 40.140), train_loss = 0.67009679, grad/param norm = 2.7021e-01, time/batch = 17.7393s	
20914/26050 (epoch 40.142), train_loss = 0.68869650, grad/param norm = 2.0301e-01, time/batch = 18.2259s	
20915/26050 (epoch 40.144), train_loss = 0.66287899, grad/param norm = 2.1032e-01, time/batch = 17.8332s	
20916/26050 (epoch 40.146), train_loss = 0.61098329, grad/param norm = 1.8151e-01, time/batch = 17.8919s	
20917/26050 (epoch 40.148), train_loss = 0.64071474, grad/param norm = 1.7724e-01, time/batch = 18.2395s	
20918/26050 (epoch 40.150), train_loss = 0.72556903, grad/param norm = 2.0440e-01, time/batch = 16.3248s	
20919/26050 (epoch 40.152), train_loss = 0.89181978, grad/param norm = 2.5802e-01, time/batch = 16.8816s	
20920/26050 (epoch 40.154), train_loss = 0.63468794, grad/param norm = 2.0787e-01, time/batch = 18.3240s	
20921/26050 (epoch 40.155), train_loss = 0.67299611, grad/param norm = 1.8699e-01, time/batch = 17.1939s	
20922/26050 (epoch 40.157), train_loss = 0.76071896, grad/param norm = 2.3277e-01, time/batch = 17.8151s	
20923/26050 (epoch 40.159), train_loss = 0.82421660, grad/param norm = 2.6563e-01, time/batch = 18.1398s	
20924/26050 (epoch 40.161), train_loss = 0.80915104, grad/param norm = 2.3422e-01, time/batch = 15.7219s	
20925/26050 (epoch 40.163), train_loss = 0.68484654, grad/param norm = 2.2234e-01, time/batch = 18.3190s	
20926/26050 (epoch 40.165), train_loss = 0.61228257, grad/param norm = 2.0636e-01, time/batch = 18.1416s	
20927/26050 (epoch 40.167), train_loss = 0.91904978, grad/param norm = 2.5587e-01, time/batch = 17.3269s	
20928/26050 (epoch 40.169), train_loss = 0.79269943, grad/param norm = 2.0486e-01, time/batch = 18.5677s	
20929/26050 (epoch 40.171), train_loss = 0.71817199, grad/param norm = 2.0731e-01, time/batch = 17.4846s	
20930/26050 (epoch 40.173), train_loss = 0.77245704, grad/param norm = 2.4483e-01, time/batch = 18.1633s	
20931/26050 (epoch 40.175), train_loss = 0.79508850, grad/param norm = 2.1960e-01, time/batch = 15.3828s	
20932/26050 (epoch 40.177), train_loss = 0.85836289, grad/param norm = 2.0433e-01, time/batch = 17.0277s	
20933/26050 (epoch 40.179), train_loss = 0.59749052, grad/param norm = 1.8110e-01, time/batch = 17.8161s	
20934/26050 (epoch 40.180), train_loss = 1.01553288, grad/param norm = 2.2412e-01, time/batch = 18.3941s	
20935/26050 (epoch 40.182), train_loss = 0.94537383, grad/param norm = 2.2510e-01, time/batch = 18.0606s	
20936/26050 (epoch 40.184), train_loss = 0.81392654, grad/param norm = 2.0026e-01, time/batch = 18.6281s	
20937/26050 (epoch 40.186), train_loss = 0.69048467, grad/param norm = 1.9890e-01, time/batch = 17.8960s	
20938/26050 (epoch 40.188), train_loss = 0.84143204, grad/param norm = 2.1491e-01, time/batch = 18.3861s	
20939/26050 (epoch 40.190), train_loss = 0.83368268, grad/param norm = 2.4283e-01, time/batch = 16.8853s	
20940/26050 (epoch 40.192), train_loss = 0.89403403, grad/param norm = 1.9935e-01, time/batch = 17.6408s	
20941/26050 (epoch 40.194), train_loss = 0.84838536, grad/param norm = 2.2523e-01, time/batch = 16.8154s	
20942/26050 (epoch 40.196), train_loss = 0.86143033, grad/param norm = 2.1425e-01, time/batch = 16.3043s	
20943/26050 (epoch 40.198), train_loss = 0.73460561, grad/param norm = 1.9496e-01, time/batch = 16.7991s	
20944/26050 (epoch 40.200), train_loss = 0.70777451, grad/param norm = 2.1298e-01, time/batch = 18.0702s	
20945/26050 (epoch 40.202), train_loss = 0.81097272, grad/param norm = 2.0525e-01, time/batch = 18.3255s	
20946/26050 (epoch 40.203), train_loss = 0.91452647, grad/param norm = 1.9912e-01, time/batch = 23.4681s	
20947/26050 (epoch 40.205), train_loss = 0.74431940, grad/param norm = 1.9814e-01, time/batch = 32.3508s	
20948/26050 (epoch 40.207), train_loss = 0.71794855, grad/param norm = 1.9609e-01, time/batch = 17.4400s	
20949/26050 (epoch 40.209), train_loss = 0.86823940, grad/param norm = 2.0537e-01, time/batch = 16.2134s	
20950/26050 (epoch 40.211), train_loss = 0.69483678, grad/param norm = 1.9168e-01, time/batch = 18.1501s	
20951/26050 (epoch 40.213), train_loss = 0.82624104, grad/param norm = 2.3112e-01, time/batch = 17.6677s	
20952/26050 (epoch 40.215), train_loss = 0.79320954, grad/param norm = 2.2538e-01, time/batch = 18.6991s	
20953/26050 (epoch 40.217), train_loss = 0.76872907, grad/param norm = 1.9708e-01, time/batch = 17.7940s	
20954/26050 (epoch 40.219), train_loss = 0.77165315, grad/param norm = 2.2190e-01, time/batch = 18.1288s	
20955/26050 (epoch 40.221), train_loss = 0.73727784, grad/param norm = 2.3406e-01, time/batch = 17.4776s	
20956/26050 (epoch 40.223), train_loss = 0.87207015, grad/param norm = 2.2191e-01, time/batch = 15.4020s	
20957/26050 (epoch 40.225), train_loss = 0.72830700, grad/param norm = 2.0863e-01, time/batch = 19.0590s	
20958/26050 (epoch 40.226), train_loss = 0.80546755, grad/param norm = 2.2464e-01, time/batch = 17.7352s	
20959/26050 (epoch 40.228), train_loss = 0.91706492, grad/param norm = 2.3994e-01, time/batch = 17.5622s	
20960/26050 (epoch 40.230), train_loss = 0.79885382, grad/param norm = 1.7185e-01, time/batch = 18.7454s	
20961/26050 (epoch 40.232), train_loss = 0.87774703, grad/param norm = 2.3395e-01, time/batch = 15.2956s	
20962/26050 (epoch 40.234), train_loss = 0.69895494, grad/param norm = 1.8666e-01, time/batch = 17.3810s	
20963/26050 (epoch 40.236), train_loss = 0.86541570, grad/param norm = 2.2445e-01, time/batch = 17.5645s	
20964/26050 (epoch 40.238), train_loss = 0.70518634, grad/param norm = 2.1799e-01, time/batch = 18.5791s	
20965/26050 (epoch 40.240), train_loss = 0.82084451, grad/param norm = 2.3281e-01, time/batch = 15.1394s	
20966/26050 (epoch 40.242), train_loss = 0.77832972, grad/param norm = 2.0785e-01, time/batch = 15.2379s	
20967/26050 (epoch 40.244), train_loss = 0.83119568, grad/param norm = 2.2451e-01, time/batch = 18.1321s	
20968/26050 (epoch 40.246), train_loss = 0.76633863, grad/param norm = 2.0625e-01, time/batch = 17.4671s	
20969/26050 (epoch 40.248), train_loss = 0.80797930, grad/param norm = 2.3727e-01, time/batch = 16.8038s	
20970/26050 (epoch 40.250), train_loss = 0.81920453, grad/param norm = 2.5793e-01, time/batch = 18.1342s	
20971/26050 (epoch 40.251), train_loss = 0.77475898, grad/param norm = 2.3688e-01, time/batch = 15.4003s	
20972/26050 (epoch 40.253), train_loss = 0.69780922, grad/param norm = 1.9734e-01, time/batch = 17.5413s	
20973/26050 (epoch 40.255), train_loss = 0.97881565, grad/param norm = 2.4576e-01, time/batch = 17.9820s	
20974/26050 (epoch 40.257), train_loss = 0.82764267, grad/param norm = 2.3426e-01, time/batch = 16.7878s	
20975/26050 (epoch 40.259), train_loss = 0.90136917, grad/param norm = 2.2772e-01, time/batch = 18.7927s	
20976/26050 (epoch 40.261), train_loss = 0.72676139, grad/param norm = 2.2451e-01, time/batch = 18.1385s	
20977/26050 (epoch 40.263), train_loss = 0.90311241, grad/param norm = 2.3796e-01, time/batch = 17.9728s	
20978/26050 (epoch 40.265), train_loss = 0.91010294, grad/param norm = 2.7783e-01, time/batch = 17.8924s	
20979/26050 (epoch 40.267), train_loss = 0.92971258, grad/param norm = 2.2551e-01, time/batch = 16.8972s	
20980/26050 (epoch 40.269), train_loss = 0.91112061, grad/param norm = 2.0576e-01, time/batch = 18.2247s	
20981/26050 (epoch 40.271), train_loss = 0.81612935, grad/param norm = 2.1194e-01, time/batch = 17.7987s	
20982/26050 (epoch 40.273), train_loss = 0.74367839, grad/param norm = 2.2847e-01, time/batch = 17.5389s	
20983/26050 (epoch 40.274), train_loss = 0.78122308, grad/param norm = 2.0164e-01, time/batch = 18.4811s	
20984/26050 (epoch 40.276), train_loss = 0.77461225, grad/param norm = 2.4130e-01, time/batch = 18.4809s	
20985/26050 (epoch 40.278), train_loss = 0.87469278, grad/param norm = 2.0159e-01, time/batch = 18.3170s	
20986/26050 (epoch 40.280), train_loss = 0.79569824, grad/param norm = 1.9671e-01, time/batch = 14.8838s	
20987/26050 (epoch 40.282), train_loss = 0.87721052, grad/param norm = 2.0461e-01, time/batch = 18.1532s	
20988/26050 (epoch 40.284), train_loss = 0.79611998, grad/param norm = 2.3801e-01, time/batch = 15.1440s	
20989/26050 (epoch 40.286), train_loss = 0.85019098, grad/param norm = 2.1055e-01, time/batch = 17.3886s	
20990/26050 (epoch 40.288), train_loss = 0.69383582, grad/param norm = 1.7406e-01, time/batch = 17.5534s	
20991/26050 (epoch 40.290), train_loss = 0.78889563, grad/param norm = 1.9414e-01, time/batch = 18.0669s	
20992/26050 (epoch 40.292), train_loss = 0.73891267, grad/param norm = 2.3039e-01, time/batch = 18.4069s	
20993/26050 (epoch 40.294), train_loss = 0.80619376, grad/param norm = 2.4075e-01, time/batch = 17.9839s	
20994/26050 (epoch 40.296), train_loss = 0.86516899, grad/param norm = 1.9914e-01, time/batch = 18.6423s	
20995/26050 (epoch 40.298), train_loss = 0.85611817, grad/param norm = 2.2300e-01, time/batch = 19.0608s	
20996/26050 (epoch 40.299), train_loss = 0.67947510, grad/param norm = 1.7818e-01, time/batch = 15.3791s	
20997/26050 (epoch 40.301), train_loss = 0.67823973, grad/param norm = 1.9823e-01, time/batch = 17.3084s	
20998/26050 (epoch 40.303), train_loss = 0.81712310, grad/param norm = 2.4596e-01, time/batch = 18.7166s	
20999/26050 (epoch 40.305), train_loss = 0.65431971, grad/param norm = 1.8789e-01, time/batch = 17.3571s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch40.31_1.9292.t7	
21000/26050 (epoch 40.307), train_loss = 0.72000511, grad/param norm = 2.1165e-01, time/batch = 17.7177s	
21001/26050 (epoch 40.309), train_loss = 1.33304115, grad/param norm = 2.8879e-01, time/batch = 18.3042s	
21002/26050 (epoch 40.311), train_loss = 0.83678580, grad/param norm = 2.6839e-01, time/batch = 18.8190s	
21003/26050 (epoch 40.313), train_loss = 0.79049366, grad/param norm = 2.4970e-01, time/batch = 17.5485s	
21004/26050 (epoch 40.315), train_loss = 0.87865704, grad/param norm = 2.4426e-01, time/batch = 18.7296s	
21005/26050 (epoch 40.317), train_loss = 0.82871862, grad/param norm = 2.4198e-01, time/batch = 18.3067s	
21006/26050 (epoch 40.319), train_loss = 0.74054329, grad/param norm = 1.9892e-01, time/batch = 14.5304s	
21007/26050 (epoch 40.321), train_loss = 0.80605776, grad/param norm = 2.2221e-01, time/batch = 17.6303s	
21008/26050 (epoch 40.322), train_loss = 0.88753613, grad/param norm = 2.3057e-01, time/batch = 17.4037s	
21009/26050 (epoch 40.324), train_loss = 0.65562902, grad/param norm = 2.0810e-01, time/batch = 18.9925s	
21010/26050 (epoch 40.326), train_loss = 0.92171637, grad/param norm = 2.3785e-01, time/batch = 17.7183s	
21011/26050 (epoch 40.328), train_loss = 0.83664293, grad/param norm = 2.0901e-01, time/batch = 18.3866s	
21012/26050 (epoch 40.330), train_loss = 0.71211473, grad/param norm = 2.0847e-01, time/batch = 16.5456s	
21013/26050 (epoch 40.332), train_loss = 0.86400455, grad/param norm = 2.0455e-01, time/batch = 17.4971s	
21014/26050 (epoch 40.334), train_loss = 0.72426384, grad/param norm = 2.2237e-01, time/batch = 19.0667s	
21015/26050 (epoch 40.336), train_loss = 0.77612703, grad/param norm = 2.2260e-01, time/batch = 18.1413s	
21016/26050 (epoch 40.338), train_loss = 0.70396012, grad/param norm = 1.8799e-01, time/batch = 17.9716s	
21017/26050 (epoch 40.340), train_loss = 0.85790458, grad/param norm = 2.1636e-01, time/batch = 17.9680s	
21018/26050 (epoch 40.342), train_loss = 0.89582037, grad/param norm = 2.2729e-01, time/batch = 15.8721s	
21019/26050 (epoch 40.344), train_loss = 0.74668745, grad/param norm = 2.1992e-01, time/batch = 18.5599s	
21020/26050 (epoch 40.345), train_loss = 0.80066081, grad/param norm = 2.6098e-01, time/batch = 17.5495s	
21021/26050 (epoch 40.347), train_loss = 0.91853672, grad/param norm = 2.2842e-01, time/batch = 16.1353s	
21022/26050 (epoch 40.349), train_loss = 0.85669463, grad/param norm = 2.2179e-01, time/batch = 18.6559s	
21023/26050 (epoch 40.351), train_loss = 0.82452664, grad/param norm = 2.1650e-01, time/batch = 17.8058s	
21024/26050 (epoch 40.353), train_loss = 0.80097568, grad/param norm = 2.1565e-01, time/batch = 17.8216s	
21025/26050 (epoch 40.355), train_loss = 0.81887821, grad/param norm = 2.6001e-01, time/batch = 17.7272s	
21026/26050 (epoch 40.357), train_loss = 0.75318219, grad/param norm = 1.8836e-01, time/batch = 17.8196s	
21027/26050 (epoch 40.359), train_loss = 0.90291600, grad/param norm = 2.3946e-01, time/batch = 18.3096s	
21028/26050 (epoch 40.361), train_loss = 0.73166107, grad/param norm = 2.0435e-01, time/batch = 17.4667s	
21029/26050 (epoch 40.363), train_loss = 0.87683544, grad/param norm = 2.1474e-01, time/batch = 16.1252s	
21030/26050 (epoch 40.365), train_loss = 0.79410146, grad/param norm = 2.0299e-01, time/batch = 16.9047s	
21031/26050 (epoch 40.367), train_loss = 0.87051541, grad/param norm = 2.0568e-01, time/batch = 16.8748s	
21032/26050 (epoch 40.369), train_loss = 0.71254122, grad/param norm = 1.7982e-01, time/batch = 17.0535s	
21033/26050 (epoch 40.370), train_loss = 0.70089149, grad/param norm = 1.7422e-01, time/batch = 17.6248s	
21034/26050 (epoch 40.372), train_loss = 0.79324053, grad/param norm = 2.3325e-01, time/batch = 18.0428s	
21035/26050 (epoch 40.374), train_loss = 0.92484192, grad/param norm = 2.3383e-01, time/batch = 18.0686s	
21036/26050 (epoch 40.376), train_loss = 0.92019069, grad/param norm = 2.3279e-01, time/batch = 16.9931s	
21037/26050 (epoch 40.378), train_loss = 0.77293127, grad/param norm = 1.8585e-01, time/batch = 16.9698s	
21038/26050 (epoch 40.380), train_loss = 0.92206911, grad/param norm = 2.7673e-01, time/batch = 17.3818s	
21039/26050 (epoch 40.382), train_loss = 1.00789338, grad/param norm = 2.6079e-01, time/batch = 17.4920s	
21040/26050 (epoch 40.384), train_loss = 0.77657397, grad/param norm = 2.2139e-01, time/batch = 17.8912s	
21041/26050 (epoch 40.386), train_loss = 0.86976656, grad/param norm = 2.7068e-01, time/batch = 17.5557s	
21042/26050 (epoch 40.388), train_loss = 0.85137634, grad/param norm = 2.3107e-01, time/batch = 16.5629s	
21043/26050 (epoch 40.390), train_loss = 0.76392759, grad/param norm = 1.8598e-01, time/batch = 17.3014s	
21044/26050 (epoch 40.392), train_loss = 0.70982210, grad/param norm = 2.0559e-01, time/batch = 14.8036s	
21045/26050 (epoch 40.393), train_loss = 0.87319951, grad/param norm = 2.2543e-01, time/batch = 18.9020s	
21046/26050 (epoch 40.395), train_loss = 0.87718033, grad/param norm = 2.2476e-01, time/batch = 18.1474s	
21047/26050 (epoch 40.397), train_loss = 0.87059193, grad/param norm = 2.2936e-01, time/batch = 17.7363s	
21048/26050 (epoch 40.399), train_loss = 0.77505428, grad/param norm = 2.3965e-01, time/batch = 18.9052s	
21049/26050 (epoch 40.401), train_loss = 0.81012302, grad/param norm = 2.1011e-01, time/batch = 18.3133s	
21050/26050 (epoch 40.403), train_loss = 0.83632221, grad/param norm = 2.4775e-01, time/batch = 16.9040s	
21051/26050 (epoch 40.405), train_loss = 0.84638192, grad/param norm = 2.8814e-01, time/batch = 18.2119s	
21052/26050 (epoch 40.407), train_loss = 0.95099921, grad/param norm = 2.5143e-01, time/batch = 18.4803s	
21053/26050 (epoch 40.409), train_loss = 0.92016387, grad/param norm = 2.2995e-01, time/batch = 18.6472s	
21054/26050 (epoch 40.411), train_loss = 0.91023789, grad/param norm = 2.4194e-01, time/batch = 16.9788s	
21055/26050 (epoch 40.413), train_loss = 1.01448367, grad/param norm = 2.2798e-01, time/batch = 17.8267s	
21056/26050 (epoch 40.415), train_loss = 0.99668456, grad/param norm = 3.0443e-01, time/batch = 15.3040s	
21057/26050 (epoch 40.417), train_loss = 0.98624834, grad/param norm = 2.4908e-01, time/batch = 17.2035s	
21058/26050 (epoch 40.418), train_loss = 0.89754580, grad/param norm = 2.7875e-01, time/batch = 18.0702s	
21059/26050 (epoch 40.420), train_loss = 0.72222280, grad/param norm = 2.1619e-01, time/batch = 17.4750s	
21060/26050 (epoch 40.422), train_loss = 0.70784428, grad/param norm = 2.0460e-01, time/batch = 19.1378s	
21061/26050 (epoch 40.424), train_loss = 0.90690263, grad/param norm = 2.3324e-01, time/batch = 17.3804s	
21062/26050 (epoch 40.426), train_loss = 0.89050108, grad/param norm = 2.7536e-01, time/batch = 18.7317s	
21063/26050 (epoch 40.428), train_loss = 0.80815001, grad/param norm = 2.1377e-01, time/batch = 16.7100s	
21064/26050 (epoch 40.430), train_loss = 0.97421801, grad/param norm = 2.3602e-01, time/batch = 17.8964s	
21065/26050 (epoch 40.432), train_loss = 0.79883083, grad/param norm = 2.2159e-01, time/batch = 18.3844s	
21066/26050 (epoch 40.434), train_loss = 0.77483865, grad/param norm = 2.6335e-01, time/batch = 16.9231s	
21067/26050 (epoch 40.436), train_loss = 0.90354605, grad/param norm = 2.3110e-01, time/batch = 16.6431s	
21068/26050 (epoch 40.438), train_loss = 0.85890512, grad/param norm = 2.5138e-01, time/batch = 16.8113s	
21069/26050 (epoch 40.440), train_loss = 0.86484754, grad/param norm = 2.2521e-01, time/batch = 18.2368s	
21070/26050 (epoch 40.441), train_loss = 0.85141416, grad/param norm = 2.0022e-01, time/batch = 18.7275s	
21071/26050 (epoch 40.443), train_loss = 0.71160968, grad/param norm = 1.8004e-01, time/batch = 15.4607s	
21072/26050 (epoch 40.445), train_loss = 0.73501409, grad/param norm = 2.2420e-01, time/batch = 15.0426s	
21073/26050 (epoch 40.447), train_loss = 0.93369977, grad/param norm = 2.3583e-01, time/batch = 18.2403s	
21074/26050 (epoch 40.449), train_loss = 0.76215502, grad/param norm = 2.2852e-01, time/batch = 17.1522s	
21075/26050 (epoch 40.451), train_loss = 0.96148841, grad/param norm = 2.3598e-01, time/batch = 17.8122s	
21076/26050 (epoch 40.453), train_loss = 0.77153005, grad/param norm = 1.7605e-01, time/batch = 17.8098s	
21077/26050 (epoch 40.455), train_loss = 0.84069020, grad/param norm = 2.2543e-01, time/batch = 18.4665s	
21078/26050 (epoch 40.457), train_loss = 0.79277856, grad/param norm = 2.1217e-01, time/batch = 15.3849s	
21079/26050 (epoch 40.459), train_loss = 0.90569315, grad/param norm = 2.2631e-01, time/batch = 18.0446s	
21080/26050 (epoch 40.461), train_loss = 0.91174345, grad/param norm = 2.3616e-01, time/batch = 18.6333s	
21081/26050 (epoch 40.463), train_loss = 0.78558412, grad/param norm = 2.0144e-01, time/batch = 17.9529s	
21082/26050 (epoch 40.464), train_loss = 0.82671326, grad/param norm = 2.0339e-01, time/batch = 18.5689s	
21083/26050 (epoch 40.466), train_loss = 0.83229300, grad/param norm = 3.1790e-01, time/batch = 16.3775s	
21084/26050 (epoch 40.468), train_loss = 0.93267586, grad/param norm = 2.1176e-01, time/batch = 18.3906s	
21085/26050 (epoch 40.470), train_loss = 0.91581556, grad/param norm = 2.7986e-01, time/batch = 18.0668s	
21086/26050 (epoch 40.472), train_loss = 0.93436988, grad/param norm = 2.6294e-01, time/batch = 18.7242s	
21087/26050 (epoch 40.474), train_loss = 0.94728158, grad/param norm = 2.2951e-01, time/batch = 17.5564s	
21088/26050 (epoch 40.476), train_loss = 0.89651751, grad/param norm = 1.9704e-01, time/batch = 16.0330s	
21089/26050 (epoch 40.478), train_loss = 0.79144257, grad/param norm = 2.0199e-01, time/batch = 18.4767s	
21090/26050 (epoch 40.480), train_loss = 0.79697555, grad/param norm = 1.9715e-01, time/batch = 18.9768s	
21091/26050 (epoch 40.482), train_loss = 0.79342843, grad/param norm = 2.0554e-01, time/batch = 17.6316s	
21092/26050 (epoch 40.484), train_loss = 0.77469244, grad/param norm = 2.2442e-01, time/batch = 17.7250s	
21093/26050 (epoch 40.486), train_loss = 0.93179840, grad/param norm = 2.2133e-01, time/batch = 17.0770s	
21094/26050 (epoch 40.488), train_loss = 0.98567478, grad/param norm = 2.4765e-01, time/batch = 15.9818s	
21095/26050 (epoch 40.489), train_loss = 1.01113564, grad/param norm = 2.7094e-01, time/batch = 16.4740s	
21096/26050 (epoch 40.491), train_loss = 0.77156775, grad/param norm = 2.4127e-01, time/batch = 17.3112s	
21097/26050 (epoch 40.493), train_loss = 0.84409904, grad/param norm = 2.1859e-01, time/batch = 17.9009s	
21098/26050 (epoch 40.495), train_loss = 0.82229974, grad/param norm = 1.9961e-01, time/batch = 17.9701s	
21099/26050 (epoch 40.497), train_loss = 0.75077675, grad/param norm = 2.0254e-01, time/batch = 16.3713s	
21100/26050 (epoch 40.499), train_loss = 0.76033074, grad/param norm = 2.0293e-01, time/batch = 18.1518s	
21101/26050 (epoch 40.501), train_loss = 0.91552163, grad/param norm = 1.9887e-01, time/batch = 17.0548s	
21102/26050 (epoch 40.503), train_loss = 0.78435922, grad/param norm = 2.1314e-01, time/batch = 16.7152s	
21103/26050 (epoch 40.505), train_loss = 0.92383042, grad/param norm = 2.3048e-01, time/batch = 17.2169s	
21104/26050 (epoch 40.507), train_loss = 0.90962648, grad/param norm = 2.7147e-01, time/batch = 18.7417s	
21105/26050 (epoch 40.509), train_loss = 0.95805110, grad/param norm = 2.2603e-01, time/batch = 17.4812s	
21106/26050 (epoch 40.511), train_loss = 0.82324319, grad/param norm = 2.0251e-01, time/batch = 18.2286s	
21107/26050 (epoch 40.512), train_loss = 0.73217636, grad/param norm = 2.3423e-01, time/batch = 17.8255s	
21108/26050 (epoch 40.514), train_loss = 0.87585221, grad/param norm = 2.5467e-01, time/batch = 15.6365s	
21109/26050 (epoch 40.516), train_loss = 0.96396303, grad/param norm = 2.6558e-01, time/batch = 16.3853s	
21110/26050 (epoch 40.518), train_loss = 0.81189030, grad/param norm = 2.0582e-01, time/batch = 16.7151s	
21111/26050 (epoch 40.520), train_loss = 0.84495661, grad/param norm = 2.1730e-01, time/batch = 19.1398s	
21112/26050 (epoch 40.522), train_loss = 0.65883503, grad/param norm = 2.1589e-01, time/batch = 17.3193s	
21113/26050 (epoch 40.524), train_loss = 0.91241012, grad/param norm = 2.7463e-01, time/batch = 18.8835s	
21114/26050 (epoch 40.526), train_loss = 0.91625021, grad/param norm = 2.7031e-01, time/batch = 18.5816s	
21115/26050 (epoch 40.528), train_loss = 0.86205363, grad/param norm = 2.3498e-01, time/batch = 16.2802s	
21116/26050 (epoch 40.530), train_loss = 0.79458489, grad/param norm = 2.3145e-01, time/batch = 18.7205s	
21117/26050 (epoch 40.532), train_loss = 0.86744360, grad/param norm = 2.2851e-01, time/batch = 17.4705s	
21118/26050 (epoch 40.534), train_loss = 0.84182869, grad/param norm = 2.8757e-01, time/batch = 18.5711s	
21119/26050 (epoch 40.536), train_loss = 0.87388834, grad/param norm = 2.2085e-01, time/batch = 17.9677s	
21120/26050 (epoch 40.537), train_loss = 0.89811847, grad/param norm = 2.2872e-01, time/batch = 16.8791s	
21121/26050 (epoch 40.539), train_loss = 0.86148538, grad/param norm = 2.1979e-01, time/batch = 17.7279s	
21122/26050 (epoch 40.541), train_loss = 0.99299380, grad/param norm = 2.6404e-01, time/batch = 17.5426s	
21123/26050 (epoch 40.543), train_loss = 0.66680853, grad/param norm = 2.3828e-01, time/batch = 18.3245s	
21124/26050 (epoch 40.545), train_loss = 0.82818571, grad/param norm = 2.1742e-01, time/batch = 15.4773s	
21125/26050 (epoch 40.547), train_loss = 0.79853388, grad/param norm = 2.3848e-01, time/batch = 17.4723s	
21126/26050 (epoch 40.549), train_loss = 0.71900049, grad/param norm = 2.2039e-01, time/batch = 14.6371s	
21127/26050 (epoch 40.551), train_loss = 0.87397462, grad/param norm = 2.1625e-01, time/batch = 17.7936s	
21128/26050 (epoch 40.553), train_loss = 0.79813029, grad/param norm = 2.1386e-01, time/batch = 18.9844s	
21129/26050 (epoch 40.555), train_loss = 0.73081078, grad/param norm = 2.0965e-01, time/batch = 16.4811s	
21130/26050 (epoch 40.557), train_loss = 0.83885034, grad/param norm = 1.9080e-01, time/batch = 17.3738s	
21131/26050 (epoch 40.559), train_loss = 0.84206442, grad/param norm = 2.0174e-01, time/batch = 16.8655s	
21132/26050 (epoch 40.560), train_loss = 0.81821252, grad/param norm = 2.5552e-01, time/batch = 18.3051s	
21133/26050 (epoch 40.562), train_loss = 0.81409555, grad/param norm = 2.3870e-01, time/batch = 17.8056s	
21134/26050 (epoch 40.564), train_loss = 0.97907161, grad/param norm = 2.2717e-01, time/batch = 17.6653s	
21135/26050 (epoch 40.566), train_loss = 0.78542845, grad/param norm = 2.0477e-01, time/batch = 18.5616s	
21136/26050 (epoch 40.568), train_loss = 0.87788284, grad/param norm = 2.5627e-01, time/batch = 17.8982s	
21137/26050 (epoch 40.570), train_loss = 0.83384125, grad/param norm = 2.3214e-01, time/batch = 17.7199s	
21138/26050 (epoch 40.572), train_loss = 0.85561473, grad/param norm = 2.2381e-01, time/batch = 18.4852s	
21139/26050 (epoch 40.574), train_loss = 0.87940412, grad/param norm = 2.5185e-01, time/batch = 16.0690s	
21140/26050 (epoch 40.576), train_loss = 0.86739398, grad/param norm = 2.6445e-01, time/batch = 16.5427s	
21141/26050 (epoch 40.578), train_loss = 0.80896463, grad/param norm = 2.4371e-01, time/batch = 17.6329s	
21142/26050 (epoch 40.580), train_loss = 0.76219940, grad/param norm = 2.2899e-01, time/batch = 18.1500s	
21143/26050 (epoch 40.582), train_loss = 0.86139832, grad/param norm = 2.0997e-01, time/batch = 29.4764s	
21144/26050 (epoch 40.583), train_loss = 0.89770549, grad/param norm = 2.0777e-01, time/batch = 26.0435s	
21145/26050 (epoch 40.585), train_loss = 0.73795063, grad/param norm = 2.0467e-01, time/batch = 15.7904s	
21146/26050 (epoch 40.587), train_loss = 0.86747886, grad/param norm = 2.5095e-01, time/batch = 18.0523s	
21147/26050 (epoch 40.589), train_loss = 0.97503882, grad/param norm = 2.3852e-01, time/batch = 17.7344s	
21148/26050 (epoch 40.591), train_loss = 0.86412226, grad/param norm = 2.5709e-01, time/batch = 17.6503s	
21149/26050 (epoch 40.593), train_loss = 0.72777205, grad/param norm = 2.0948e-01, time/batch = 15.4420s	
21150/26050 (epoch 40.595), train_loss = 0.87240577, grad/param norm = 2.4359e-01, time/batch = 17.5750s	
21151/26050 (epoch 40.597), train_loss = 0.84278848, grad/param norm = 2.2060e-01, time/batch = 17.1629s	
21152/26050 (epoch 40.599), train_loss = 0.89692537, grad/param norm = 2.1855e-01, time/batch = 18.0667s	
21153/26050 (epoch 40.601), train_loss = 0.99937475, grad/param norm = 2.5958e-01, time/batch = 18.8077s	
21154/26050 (epoch 40.603), train_loss = 0.90292581, grad/param norm = 2.4523e-01, time/batch = 18.1470s	
21155/26050 (epoch 40.605), train_loss = 0.83147874, grad/param norm = 2.3058e-01, time/batch = 17.5651s	
21156/26050 (epoch 40.607), train_loss = 0.92155750, grad/param norm = 2.7361e-01, time/batch = 18.3226s	
21157/26050 (epoch 40.608), train_loss = 0.75492721, grad/param norm = 1.9459e-01, time/batch = 17.4903s	
21158/26050 (epoch 40.610), train_loss = 0.85090845, grad/param norm = 2.4895e-01, time/batch = 16.2245s	
21159/26050 (epoch 40.612), train_loss = 0.80271166, grad/param norm = 2.2278e-01, time/batch = 15.9635s	
21160/26050 (epoch 40.614), train_loss = 0.85763475, grad/param norm = 2.5599e-01, time/batch = 17.6490s	
21161/26050 (epoch 40.616), train_loss = 0.88882754, grad/param norm = 2.4578e-01, time/batch = 18.5492s	
21162/26050 (epoch 40.618), train_loss = 0.78501215, grad/param norm = 2.0319e-01, time/batch = 17.4688s	
21163/26050 (epoch 40.620), train_loss = 0.91590210, grad/param norm = 2.5333e-01, time/batch = 16.1554s	
21164/26050 (epoch 40.622), train_loss = 0.76057102, grad/param norm = 2.2013e-01, time/batch = 15.1061s	
21165/26050 (epoch 40.624), train_loss = 0.70169936, grad/param norm = 2.0282e-01, time/batch = 16.7898s	
21166/26050 (epoch 40.626), train_loss = 0.87746967, grad/param norm = 2.5189e-01, time/batch = 18.1394s	
21167/26050 (epoch 40.628), train_loss = 0.79722408, grad/param norm = 2.9892e-01, time/batch = 17.7283s	
21168/26050 (epoch 40.630), train_loss = 0.97232807, grad/param norm = 2.3230e-01, time/batch = 18.6515s	
21169/26050 (epoch 40.631), train_loss = 0.98868665, grad/param norm = 2.5981e-01, time/batch = 17.3177s	
21170/26050 (epoch 40.633), train_loss = 0.76970889, grad/param norm = 2.4217e-01, time/batch = 15.2207s	
21171/26050 (epoch 40.635), train_loss = 0.77759304, grad/param norm = 1.8060e-01, time/batch = 18.5510s	
21172/26050 (epoch 40.637), train_loss = 0.73285948, grad/param norm = 2.0858e-01, time/batch = 17.9765s	
21173/26050 (epoch 40.639), train_loss = 0.87309814, grad/param norm = 2.1055e-01, time/batch = 18.1504s	
21174/26050 (epoch 40.641), train_loss = 0.77576559, grad/param norm = 1.9694e-01, time/batch = 18.3198s	
21175/26050 (epoch 40.643), train_loss = 0.78188701, grad/param norm = 1.9669e-01, time/batch = 18.6511s	
21176/26050 (epoch 40.645), train_loss = 0.78260025, grad/param norm = 2.0881e-01, time/batch = 17.4721s	
21177/26050 (epoch 40.647), train_loss = 0.73927316, grad/param norm = 2.0830e-01, time/batch = 17.6245s	
21178/26050 (epoch 40.649), train_loss = 0.80580181, grad/param norm = 2.3894e-01, time/batch = 18.1366s	
21179/26050 (epoch 40.651), train_loss = 0.79100083, grad/param norm = 2.0539e-01, time/batch = 15.2975s	
21180/26050 (epoch 40.653), train_loss = 0.83309281, grad/param norm = 2.3562e-01, time/batch = 17.3789s	
21181/26050 (epoch 40.655), train_loss = 0.74800032, grad/param norm = 2.0972e-01, time/batch = 17.9846s	
21182/26050 (epoch 40.656), train_loss = 0.72866186, grad/param norm = 1.8190e-01, time/batch = 16.8670s	
21183/26050 (epoch 40.658), train_loss = 0.99471181, grad/param norm = 2.4147e-01, time/batch = 18.4607s	
21184/26050 (epoch 40.660), train_loss = 0.70135415, grad/param norm = 2.0831e-01, time/batch = 17.8948s	
21185/26050 (epoch 40.662), train_loss = 0.80793056, grad/param norm = 2.0058e-01, time/batch = 15.1364s	
21186/26050 (epoch 40.664), train_loss = 0.82130551, grad/param norm = 2.2145e-01, time/batch = 16.9903s	
21187/26050 (epoch 40.666), train_loss = 0.77975047, grad/param norm = 2.1882e-01, time/batch = 18.2960s	
21188/26050 (epoch 40.668), train_loss = 0.63412954, grad/param norm = 1.9838e-01, time/batch = 18.1366s	
21189/26050 (epoch 40.670), train_loss = 0.94957168, grad/param norm = 2.9042e-01, time/batch = 17.0685s	
21190/26050 (epoch 40.672), train_loss = 0.81553496, grad/param norm = 2.1353e-01, time/batch = 18.0624s	
21191/26050 (epoch 40.674), train_loss = 0.73426916, grad/param norm = 2.2109e-01, time/batch = 18.7396s	
21192/26050 (epoch 40.676), train_loss = 0.86014883, grad/param norm = 2.1533e-01, time/batch = 17.9881s	
21193/26050 (epoch 40.678), train_loss = 0.89519500, grad/param norm = 2.2745e-01, time/batch = 16.0193s	
21194/26050 (epoch 40.679), train_loss = 0.95707194, grad/param norm = 2.4061e-01, time/batch = 17.3843s	
21195/26050 (epoch 40.681), train_loss = 0.85580543, grad/param norm = 2.4991e-01, time/batch = 18.3961s	
21196/26050 (epoch 40.683), train_loss = 0.75556579, grad/param norm = 2.4628e-01, time/batch = 14.6364s	
21197/26050 (epoch 40.685), train_loss = 0.78726610, grad/param norm = 2.0505e-01, time/batch = 18.2320s	
21198/26050 (epoch 40.687), train_loss = 0.72339654, grad/param norm = 1.9277e-01, time/batch = 18.6538s	
21199/26050 (epoch 40.689), train_loss = 0.76715948, grad/param norm = 2.0892e-01, time/batch = 17.5751s	
21200/26050 (epoch 40.691), train_loss = 0.66599703, grad/param norm = 1.7050e-01, time/batch = 15.5449s	
21201/26050 (epoch 40.693), train_loss = 0.80469952, grad/param norm = 3.4980e-01, time/batch = 18.2379s	
21202/26050 (epoch 40.695), train_loss = 0.82358015, grad/param norm = 2.1279e-01, time/batch = 18.1469s	
21203/26050 (epoch 40.697), train_loss = 0.76069946, grad/param norm = 2.0185e-01, time/batch = 17.0678s	
21204/26050 (epoch 40.699), train_loss = 0.87947084, grad/param norm = 2.4225e-01, time/batch = 17.8064s	
21205/26050 (epoch 40.701), train_loss = 0.74809512, grad/param norm = 2.0025e-01, time/batch = 18.8180s	
21206/26050 (epoch 40.702), train_loss = 0.90885046, grad/param norm = 2.2000e-01, time/batch = 15.0430s	
21207/26050 (epoch 40.704), train_loss = 0.92884605, grad/param norm = 2.1041e-01, time/batch = 18.1489s	
21208/26050 (epoch 40.706), train_loss = 0.75780119, grad/param norm = 2.0977e-01, time/batch = 18.7272s	
21209/26050 (epoch 40.708), train_loss = 0.87262933, grad/param norm = 2.2775e-01, time/batch = 16.0658s	
21210/26050 (epoch 40.710), train_loss = 0.84999856, grad/param norm = 2.5212e-01, time/batch = 16.5604s	
21211/26050 (epoch 40.712), train_loss = 0.82885608, grad/param norm = 2.6936e-01, time/batch = 18.0685s	
21212/26050 (epoch 40.714), train_loss = 0.72666183, grad/param norm = 1.8096e-01, time/batch = 17.6495s	
21213/26050 (epoch 40.716), train_loss = 1.04004296, grad/param norm = 2.6845e-01, time/batch = 17.5811s	
21214/26050 (epoch 40.718), train_loss = 0.88253537, grad/param norm = 2.2060e-01, time/batch = 16.6372s	
21215/26050 (epoch 40.720), train_loss = 0.81125219, grad/param norm = 2.4137e-01, time/batch = 18.2363s	
21216/26050 (epoch 40.722), train_loss = 0.75072817, grad/param norm = 1.9984e-01, time/batch = 18.8156s	
21217/26050 (epoch 40.724), train_loss = 0.77592460, grad/param norm = 2.0819e-01, time/batch = 18.6369s	
21218/26050 (epoch 40.726), train_loss = 0.89032312, grad/param norm = 2.4270e-01, time/batch = 17.1277s	
21219/26050 (epoch 40.727), train_loss = 0.87724665, grad/param norm = 2.2271e-01, time/batch = 18.2213s	
21220/26050 (epoch 40.729), train_loss = 0.84477032, grad/param norm = 1.9537e-01, time/batch = 17.4831s	
21221/26050 (epoch 40.731), train_loss = 0.88009013, grad/param norm = 2.1691e-01, time/batch = 16.3131s	
21222/26050 (epoch 40.733), train_loss = 0.81435260, grad/param norm = 2.3128e-01, time/batch = 18.1464s	
21223/26050 (epoch 40.735), train_loss = 0.94239260, grad/param norm = 2.3288e-01, time/batch = 17.8200s	
21224/26050 (epoch 40.737), train_loss = 0.80223315, grad/param norm = 3.0687e-01, time/batch = 17.4792s	
21225/26050 (epoch 40.739), train_loss = 0.84060881, grad/param norm = 1.9381e-01, time/batch = 18.5736s	
21226/26050 (epoch 40.741), train_loss = 0.76516765, grad/param norm = 2.1768e-01, time/batch = 18.7413s	
21227/26050 (epoch 40.743), train_loss = 0.83834480, grad/param norm = 2.6237e-01, time/batch = 17.3849s	
21228/26050 (epoch 40.745), train_loss = 0.73897695, grad/param norm = 2.0469e-01, time/batch = 18.4770s	
21229/26050 (epoch 40.747), train_loss = 0.77766760, grad/param norm = 2.4690e-01, time/batch = 15.5466s	
21230/26050 (epoch 40.749), train_loss = 0.91651149, grad/param norm = 2.3008e-01, time/batch = 17.3994s	
21231/26050 (epoch 40.750), train_loss = 0.78467254, grad/param norm = 1.9558e-01, time/batch = 16.5457s	
21232/26050 (epoch 40.752), train_loss = 0.77272930, grad/param norm = 2.4288e-01, time/batch = 18.1535s	
21233/26050 (epoch 40.754), train_loss = 0.81652762, grad/param norm = 2.0473e-01, time/batch = 17.3995s	
21234/26050 (epoch 40.756), train_loss = 0.77976871, grad/param norm = 2.3581e-01, time/batch = 15.9626s	
21235/26050 (epoch 40.758), train_loss = 0.80951080, grad/param norm = 2.5162e-01, time/batch = 18.3220s	
21236/26050 (epoch 40.760), train_loss = 0.94221351, grad/param norm = 2.6676e-01, time/batch = 14.8918s	
21237/26050 (epoch 40.762), train_loss = 0.80474884, grad/param norm = 2.3184e-01, time/batch = 17.7270s	
21238/26050 (epoch 40.764), train_loss = 0.82321329, grad/param norm = 2.9438e-01, time/batch = 18.0714s	
21239/26050 (epoch 40.766), train_loss = 0.82685714, grad/param norm = 2.5175e-01, time/batch = 17.8284s	
21240/26050 (epoch 40.768), train_loss = 0.72294982, grad/param norm = 2.0099e-01, time/batch = 16.9869s	
21241/26050 (epoch 40.770), train_loss = 0.79673641, grad/param norm = 2.0272e-01, time/batch = 19.3830s	
21242/26050 (epoch 40.772), train_loss = 0.82027984, grad/param norm = 2.0373e-01, time/batch = 18.5581s	
21243/26050 (epoch 40.774), train_loss = 0.69985445, grad/param norm = 2.3543e-01, time/batch = 18.6500s	
21244/26050 (epoch 40.775), train_loss = 0.59077264, grad/param norm = 2.1139e-01, time/batch = 18.1381s	
21245/26050 (epoch 40.777), train_loss = 0.78104715, grad/param norm = 2.1058e-01, time/batch = 17.3134s	
21246/26050 (epoch 40.779), train_loss = 0.79544599, grad/param norm = 2.6518e-01, time/batch = 18.4844s	
21247/26050 (epoch 40.781), train_loss = 0.74177700, grad/param norm = 2.1049e-01, time/batch = 17.1468s	
21248/26050 (epoch 40.783), train_loss = 0.72920642, grad/param norm = 2.1110e-01, time/batch = 18.7323s	
21249/26050 (epoch 40.785), train_loss = 0.82153122, grad/param norm = 2.6149e-01, time/batch = 18.9040s	
21250/26050 (epoch 40.787), train_loss = 0.72396345, grad/param norm = 2.2702e-01, time/batch = 18.0646s	
21251/26050 (epoch 40.789), train_loss = 0.74042693, grad/param norm = 2.2401e-01, time/batch = 16.7945s	
21252/26050 (epoch 40.791), train_loss = 0.76018322, grad/param norm = 2.6169e-01, time/batch = 17.8063s	
21253/26050 (epoch 40.793), train_loss = 0.81713027, grad/param norm = 2.2837e-01, time/batch = 18.8165s	
21254/26050 (epoch 40.795), train_loss = 0.65317981, grad/param norm = 1.7686e-01, time/batch = 16.2164s	
21255/26050 (epoch 40.797), train_loss = 0.72481521, grad/param norm = 2.0914e-01, time/batch = 17.7248s	
21256/26050 (epoch 40.798), train_loss = 0.78244637, grad/param norm = 2.5046e-01, time/batch = 18.7399s	
21257/26050 (epoch 40.800), train_loss = 0.68568909, grad/param norm = 2.0491e-01, time/batch = 17.2387s	
21258/26050 (epoch 40.802), train_loss = 0.77134724, grad/param norm = 2.2768e-01, time/batch = 15.1285s	
21259/26050 (epoch 40.804), train_loss = 0.78798330, grad/param norm = 2.1651e-01, time/batch = 17.3288s	
21260/26050 (epoch 40.806), train_loss = 0.87839946, grad/param norm = 2.4163e-01, time/batch = 18.3134s	
21261/26050 (epoch 40.808), train_loss = 0.83785354, grad/param norm = 2.8852e-01, time/batch = 15.7174s	
21262/26050 (epoch 40.810), train_loss = 0.80915570, grad/param norm = 2.1431e-01, time/batch = 18.3925s	
21263/26050 (epoch 40.812), train_loss = 0.67896018, grad/param norm = 2.2402e-01, time/batch = 17.9889s	
21264/26050 (epoch 40.814), train_loss = 0.73310761, grad/param norm = 2.5134e-01, time/batch = 17.3980s	
21265/26050 (epoch 40.816), train_loss = 0.84419188, grad/param norm = 2.2841e-01, time/batch = 18.9780s	
21266/26050 (epoch 40.818), train_loss = 0.88083149, grad/param norm = 2.6188e-01, time/batch = 18.8790s	
21267/26050 (epoch 40.820), train_loss = 0.82968450, grad/param norm = 2.3027e-01, time/batch = 15.3799s	
21268/26050 (epoch 40.821), train_loss = 0.90957344, grad/param norm = 2.4487e-01, time/batch = 18.4078s	
21269/26050 (epoch 40.823), train_loss = 0.99521956, grad/param norm = 2.2554e-01, time/batch = 18.2423s	
21270/26050 (epoch 40.825), train_loss = 0.80736431, grad/param norm = 2.7100e-01, time/batch = 17.7332s	
21271/26050 (epoch 40.827), train_loss = 0.81289781, grad/param norm = 2.5969e-01, time/batch = 18.0341s	
21272/26050 (epoch 40.829), train_loss = 0.90982368, grad/param norm = 2.5165e-01, time/batch = 16.6198s	
21273/26050 (epoch 40.831), train_loss = 0.96328406, grad/param norm = 2.6081e-01, time/batch = 18.3237s	
21274/26050 (epoch 40.833), train_loss = 0.93411360, grad/param norm = 2.6845e-01, time/batch = 17.2293s	
21275/26050 (epoch 40.835), train_loss = 0.94042689, grad/param norm = 2.3715e-01, time/batch = 18.2455s	
21276/26050 (epoch 40.837), train_loss = 0.85053123, grad/param norm = 2.2580e-01, time/batch = 18.9698s	
21277/26050 (epoch 40.839), train_loss = 0.79821190, grad/param norm = 2.2319e-01, time/batch = 17.3227s	
21278/26050 (epoch 40.841), train_loss = 0.87198951, grad/param norm = 2.2603e-01, time/batch = 18.0692s	
21279/26050 (epoch 40.843), train_loss = 0.80283896, grad/param norm = 2.0804e-01, time/batch = 16.6364s	
21280/26050 (epoch 40.845), train_loss = 0.76289008, grad/param norm = 2.0076e-01, time/batch = 14.3731s	
21281/26050 (epoch 40.846), train_loss = 0.85245756, grad/param norm = 2.2111e-01, time/batch = 16.2099s	
21282/26050 (epoch 40.848), train_loss = 0.79541412, grad/param norm = 2.1458e-01, time/batch = 18.9929s	
21283/26050 (epoch 40.850), train_loss = 0.73560875, grad/param norm = 2.0695e-01, time/batch = 18.7322s	
21284/26050 (epoch 40.852), train_loss = 0.83792330, grad/param norm = 2.1158e-01, time/batch = 17.7409s	
21285/26050 (epoch 40.854), train_loss = 0.80575862, grad/param norm = 2.0803e-01, time/batch = 18.2367s	
21286/26050 (epoch 40.856), train_loss = 0.76862457, grad/param norm = 2.4066e-01, time/batch = 18.1385s	
21287/26050 (epoch 40.858), train_loss = 0.73712137, grad/param norm = 1.9860e-01, time/batch = 17.7173s	
21288/26050 (epoch 40.860), train_loss = 0.83548170, grad/param norm = 2.4270e-01, time/batch = 17.9570s	
21289/26050 (epoch 40.862), train_loss = 0.88925870, grad/param norm = 2.1295e-01, time/batch = 17.9728s	
21290/26050 (epoch 40.864), train_loss = 0.81193732, grad/param norm = 2.5761e-01, time/batch = 16.6260s	
21291/26050 (epoch 40.866), train_loss = 0.78527863, grad/param norm = 1.9467e-01, time/batch = 17.1425s	
21292/26050 (epoch 40.868), train_loss = 0.87278964, grad/param norm = 2.2727e-01, time/batch = 17.9823s	
21293/26050 (epoch 40.869), train_loss = 0.73385711, grad/param norm = 1.8492e-01, time/batch = 18.5748s	
21294/26050 (epoch 40.871), train_loss = 0.69209867, grad/param norm = 2.0466e-01, time/batch = 15.7130s	
21295/26050 (epoch 40.873), train_loss = 0.86327796, grad/param norm = 2.2903e-01, time/batch = 16.4802s	
21296/26050 (epoch 40.875), train_loss = 0.76698885, grad/param norm = 2.2430e-01, time/batch = 15.6038s	
21297/26050 (epoch 40.877), train_loss = 0.77667200, grad/param norm = 2.0678e-01, time/batch = 18.2244s	
21298/26050 (epoch 40.879), train_loss = 0.87033659, grad/param norm = 2.0813e-01, time/batch = 17.4042s	
21299/26050 (epoch 40.881), train_loss = 0.88841705, grad/param norm = 2.4981e-01, time/batch = 16.7367s	
21300/26050 (epoch 40.883), train_loss = 0.86835517, grad/param norm = 2.1415e-01, time/batch = 18.1587s	
21301/26050 (epoch 40.885), train_loss = 0.63281087, grad/param norm = 1.9270e-01, time/batch = 17.8262s	
21302/26050 (epoch 40.887), train_loss = 0.90643975, grad/param norm = 2.5907e-01, time/batch = 15.2342s	
21303/26050 (epoch 40.889), train_loss = 0.74431599, grad/param norm = 2.1293e-01, time/batch = 18.1574s	
21304/26050 (epoch 40.891), train_loss = 0.68760155, grad/param norm = 2.2362e-01, time/batch = 18.4161s	
21305/26050 (epoch 40.893), train_loss = 0.69381155, grad/param norm = 1.9982e-01, time/batch = 17.1546s	
21306/26050 (epoch 40.894), train_loss = 0.76735973, grad/param norm = 2.1095e-01, time/batch = 18.2479s	
21307/26050 (epoch 40.896), train_loss = 0.88890138, grad/param norm = 2.2785e-01, time/batch = 18.2356s	
21308/26050 (epoch 40.898), train_loss = 0.76042275, grad/param norm = 2.2073e-01, time/batch = 17.6539s	
21309/26050 (epoch 40.900), train_loss = 0.84946000, grad/param norm = 2.8875e-01, time/batch = 18.4858s	
21310/26050 (epoch 40.902), train_loss = 0.77335276, grad/param norm = 2.2980e-01, time/batch = 18.1487s	
21311/26050 (epoch 40.904), train_loss = 0.79193472, grad/param norm = 2.0086e-01, time/batch = 15.0641s	
21312/26050 (epoch 40.906), train_loss = 0.78326627, grad/param norm = 2.6498e-01, time/batch = 16.8912s	
21313/26050 (epoch 40.908), train_loss = 0.84598564, grad/param norm = 2.3303e-01, time/batch = 15.4787s	
21314/26050 (epoch 40.910), train_loss = 0.75527019, grad/param norm = 2.0788e-01, time/batch = 18.2314s	
21315/26050 (epoch 40.912), train_loss = 0.98298068, grad/param norm = 2.4365e-01, time/batch = 17.3125s	
21316/26050 (epoch 40.914), train_loss = 1.10606515, grad/param norm = 2.6716e-01, time/batch = 18.8977s	
21317/26050 (epoch 40.916), train_loss = 0.86489441, grad/param norm = 2.6517e-01, time/batch = 15.7438s	
21318/26050 (epoch 40.917), train_loss = 0.85044807, grad/param norm = 2.3859e-01, time/batch = 18.2241s	
21319/26050 (epoch 40.919), train_loss = 0.84328546, grad/param norm = 2.4974e-01, time/batch = 17.6302s	
21320/26050 (epoch 40.921), train_loss = 0.76342090, grad/param norm = 2.2575e-01, time/batch = 18.0655s	
21321/26050 (epoch 40.923), train_loss = 0.82782653, grad/param norm = 2.0139e-01, time/batch = 18.8970s	
21322/26050 (epoch 40.925), train_loss = 0.81853638, grad/param norm = 2.3176e-01, time/batch = 14.2987s	
21323/26050 (epoch 40.927), train_loss = 0.75249346, grad/param norm = 1.8182e-01, time/batch = 17.5782s	
21324/26050 (epoch 40.929), train_loss = 0.70322483, grad/param norm = 2.0950e-01, time/batch = 18.8969s	
21325/26050 (epoch 40.931), train_loss = 0.98076754, grad/param norm = 2.7515e-01, time/batch = 17.5708s	
21326/26050 (epoch 40.933), train_loss = 0.82100610, grad/param norm = 2.3407e-01, time/batch = 18.1491s	
21327/26050 (epoch 40.935), train_loss = 0.77843414, grad/param norm = 2.1481e-01, time/batch = 17.2572s	
21328/26050 (epoch 40.937), train_loss = 0.89372641, grad/param norm = 2.3978e-01, time/batch = 17.9865s	
21329/26050 (epoch 40.939), train_loss = 0.75291804, grad/param norm = 1.9118e-01, time/batch = 16.5466s	
21330/26050 (epoch 40.940), train_loss = 0.81812792, grad/param norm = 2.2218e-01, time/batch = 18.4837s	
21331/26050 (epoch 40.942), train_loss = 0.77435328, grad/param norm = 2.1752e-01, time/batch = 18.6466s	
21332/26050 (epoch 40.944), train_loss = 0.78760325, grad/param norm = 2.1687e-01, time/batch = 17.3978s	
21333/26050 (epoch 40.946), train_loss = 0.97243834, grad/param norm = 2.2607e-01, time/batch = 18.4141s	
21334/26050 (epoch 40.948), train_loss = 0.70537682, grad/param norm = 2.3024e-01, time/batch = 16.8841s	
21335/26050 (epoch 40.950), train_loss = 0.83027534, grad/param norm = 2.0909e-01, time/batch = 16.8051s	
21336/26050 (epoch 40.952), train_loss = 0.86762768, grad/param norm = 2.2960e-01, time/batch = 16.7048s	
21337/26050 (epoch 40.954), train_loss = 0.87933843, grad/param norm = 2.3413e-01, time/batch = 18.2418s	
21338/26050 (epoch 40.956), train_loss = 0.76978833, grad/param norm = 2.0011e-01, time/batch = 15.9665s	
21339/26050 (epoch 40.958), train_loss = 0.73049007, grad/param norm = 1.9341e-01, time/batch = 17.2396s	
21340/26050 (epoch 40.960), train_loss = 0.85137429, grad/param norm = 2.4227e-01, time/batch = 17.8115s	
21341/26050 (epoch 40.962), train_loss = 0.81910951, grad/param norm = 2.0795e-01, time/batch = 17.8232s	
21342/26050 (epoch 40.964), train_loss = 0.79933030, grad/param norm = 2.6369e-01, time/batch = 18.0626s	
21343/26050 (epoch 40.965), train_loss = 0.74162695, grad/param norm = 2.0237e-01, time/batch = 18.5735s	
21344/26050 (epoch 40.967), train_loss = 1.08404053, grad/param norm = 2.6651e-01, time/batch = 17.9803s	
21345/26050 (epoch 40.969), train_loss = 0.81118861, grad/param norm = 1.9447e-01, time/batch = 18.6567s	
21346/26050 (epoch 40.971), train_loss = 0.82758179, grad/param norm = 2.1245e-01, time/batch = 30.7487s	
21347/26050 (epoch 40.973), train_loss = 0.84449435, grad/param norm = 2.1170e-01, time/batch = 27.8369s	
21348/26050 (epoch 40.975), train_loss = 0.84447185, grad/param norm = 2.1153e-01, time/batch = 17.0658s	
21349/26050 (epoch 40.977), train_loss = 0.80062997, grad/param norm = 2.0598e-01, time/batch = 18.2359s	
21350/26050 (epoch 40.979), train_loss = 0.65969093, grad/param norm = 1.8860e-01, time/batch = 15.6250s	
21351/26050 (epoch 40.981), train_loss = 0.89890319, grad/param norm = 2.0631e-01, time/batch = 17.4523s	
21352/26050 (epoch 40.983), train_loss = 0.85978171, grad/param norm = 2.0925e-01, time/batch = 18.3920s	
21353/26050 (epoch 40.985), train_loss = 0.85326206, grad/param norm = 2.2121e-01, time/batch = 14.4770s	
21354/26050 (epoch 40.987), train_loss = 0.91757874, grad/param norm = 2.3056e-01, time/batch = 18.1583s	
21355/26050 (epoch 40.988), train_loss = 0.86013114, grad/param norm = 2.3567e-01, time/batch = 17.8937s	
21356/26050 (epoch 40.990), train_loss = 0.72353787, grad/param norm = 2.0470e-01, time/batch = 18.8176s	
21357/26050 (epoch 40.992), train_loss = 0.95780512, grad/param norm = 2.1858e-01, time/batch = 18.3254s	
21358/26050 (epoch 40.994), train_loss = 0.77244026, grad/param norm = 2.5305e-01, time/batch = 17.3061s	
21359/26050 (epoch 40.996), train_loss = 0.71189547, grad/param norm = 2.1692e-01, time/batch = 18.3156s	
21360/26050 (epoch 40.998), train_loss = 0.83757841, grad/param norm = 2.0736e-01, time/batch = 18.7431s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
21361/26050 (epoch 41.000), train_loss = 0.75537415, grad/param norm = 2.4190e-01, time/batch = 17.7282s	
21362/26050 (epoch 41.002), train_loss = 0.86820808, grad/param norm = 2.2932e-01, time/batch = 18.8187s	
21363/26050 (epoch 41.004), train_loss = 0.72965132, grad/param norm = 2.1722e-01, time/batch = 17.4059s	
21364/26050 (epoch 41.006), train_loss = 0.77297292, grad/param norm = 2.5353e-01, time/batch = 14.7454s	
21365/26050 (epoch 41.008), train_loss = 0.75257287, grad/param norm = 2.1133e-01, time/batch = 17.5735s	
21366/26050 (epoch 41.010), train_loss = 0.75415962, grad/param norm = 2.0567e-01, time/batch = 16.9763s	
21367/26050 (epoch 41.012), train_loss = 0.79709259, grad/param norm = 2.0260e-01, time/batch = 18.5480s	
21368/26050 (epoch 41.013), train_loss = 1.02717651, grad/param norm = 2.6439e-01, time/batch = 15.4445s	
21369/26050 (epoch 41.015), train_loss = 0.80796516, grad/param norm = 2.0937e-01, time/batch = 18.5694s	
21370/26050 (epoch 41.017), train_loss = 0.84258235, grad/param norm = 1.8971e-01, time/batch = 17.6533s	
21371/26050 (epoch 41.019), train_loss = 0.71108628, grad/param norm = 1.5889e-01, time/batch = 17.9645s	
21372/26050 (epoch 41.021), train_loss = 0.88719176, grad/param norm = 2.1455e-01, time/batch = 17.5713s	
21373/26050 (epoch 41.023), train_loss = 0.68205728, grad/param norm = 2.0434e-01, time/batch = 18.4749s	
21374/26050 (epoch 41.025), train_loss = 0.80836890, grad/param norm = 2.4022e-01, time/batch = 18.2429s	
21375/26050 (epoch 41.027), train_loss = 0.64988508, grad/param norm = 2.0803e-01, time/batch = 16.5477s	
21376/26050 (epoch 41.029), train_loss = 0.86635290, grad/param norm = 1.9980e-01, time/batch = 18.4021s	
21377/26050 (epoch 41.031), train_loss = 0.91727422, grad/param norm = 2.5436e-01, time/batch = 18.8197s	
21378/26050 (epoch 41.033), train_loss = 0.80862527, grad/param norm = 2.0947e-01, time/batch = 17.9025s	
21379/26050 (epoch 41.035), train_loss = 0.84455548, grad/param norm = 1.9643e-01, time/batch = 18.7991s	
21380/26050 (epoch 41.036), train_loss = 0.70670708, grad/param norm = 2.5429e-01, time/batch = 15.0472s	
21381/26050 (epoch 41.038), train_loss = 0.65540797, grad/param norm = 1.9094e-01, time/batch = 18.2362s	
21382/26050 (epoch 41.040), train_loss = 0.79846720, grad/param norm = 2.0721e-01, time/batch = 18.1442s	
21383/26050 (epoch 41.042), train_loss = 0.70053538, grad/param norm = 2.0824e-01, time/batch = 18.3306s	
21384/26050 (epoch 41.044), train_loss = 0.88082058, grad/param norm = 1.9095e-01, time/batch = 18.5694s	
21385/26050 (epoch 41.046), train_loss = 0.68387026, grad/param norm = 1.7642e-01, time/batch = 17.2988s	
21386/26050 (epoch 41.048), train_loss = 0.82036600, grad/param norm = 2.2270e-01, time/batch = 18.7296s	
21387/26050 (epoch 41.050), train_loss = 0.77080909, grad/param norm = 2.3106e-01, time/batch = 18.0605s	
21388/26050 (epoch 41.052), train_loss = 0.74207601, grad/param norm = 2.2094e-01, time/batch = 15.2917s	
21389/26050 (epoch 41.054), train_loss = 0.66743711, grad/param norm = 1.8684e-01, time/batch = 17.0367s	
21390/26050 (epoch 41.056), train_loss = 0.65770672, grad/param norm = 1.6199e-01, time/batch = 15.4750s	
21391/26050 (epoch 41.058), train_loss = 0.78619104, grad/param norm = 2.1732e-01, time/batch = 18.1594s	
21392/26050 (epoch 41.060), train_loss = 0.83620049, grad/param norm = 2.0060e-01, time/batch = 17.7255s	
21393/26050 (epoch 41.061), train_loss = 0.68998254, grad/param norm = 2.0215e-01, time/batch = 18.5624s	
21394/26050 (epoch 41.063), train_loss = 0.80807768, grad/param norm = 2.4015e-01, time/batch = 18.1543s	
21395/26050 (epoch 41.065), train_loss = 0.66271756, grad/param norm = 1.8093e-01, time/batch = 18.0587s	
21396/26050 (epoch 41.067), train_loss = 0.80032121, grad/param norm = 2.1669e-01, time/batch = 18.7435s	
21397/26050 (epoch 41.069), train_loss = 0.82242809, grad/param norm = 2.3458e-01, time/batch = 17.5417s	
21398/26050 (epoch 41.071), train_loss = 0.84383657, grad/param norm = 2.9650e-01, time/batch = 17.4859s	
21399/26050 (epoch 41.073), train_loss = 0.94877870, grad/param norm = 2.0276e-01, time/batch = 16.9502s	
21400/26050 (epoch 41.075), train_loss = 0.76921673, grad/param norm = 2.1232e-01, time/batch = 14.1398s	
21401/26050 (epoch 41.077), train_loss = 0.74370557, grad/param norm = 2.2346e-01, time/batch = 17.2239s	
21402/26050 (epoch 41.079), train_loss = 0.76627776, grad/param norm = 1.9926e-01, time/batch = 17.5594s	
21403/26050 (epoch 41.081), train_loss = 0.77256807, grad/param norm = 1.9515e-01, time/batch = 18.8249s	
21404/26050 (epoch 41.083), train_loss = 0.89918196, grad/param norm = 2.0347e-01, time/batch = 18.1435s	
21405/26050 (epoch 41.084), train_loss = 0.81122185, grad/param norm = 2.5716e-01, time/batch = 17.6483s	
21406/26050 (epoch 41.086), train_loss = 0.93342774, grad/param norm = 2.4065e-01, time/batch = 16.9870s	
21407/26050 (epoch 41.088), train_loss = 0.80800010, grad/param norm = 2.2233e-01, time/batch = 18.5690s	
21408/26050 (epoch 41.090), train_loss = 0.83415420, grad/param norm = 2.3461e-01, time/batch = 16.9024s	
21409/26050 (epoch 41.092), train_loss = 0.87201104, grad/param norm = 2.1395e-01, time/batch = 17.4548s	
21410/26050 (epoch 41.094), train_loss = 0.69136569, grad/param norm = 2.1081e-01, time/batch = 17.7256s	
21411/26050 (epoch 41.096), train_loss = 0.83589034, grad/param norm = 2.0154e-01, time/batch = 18.5718s	
21412/26050 (epoch 41.098), train_loss = 0.80948481, grad/param norm = 2.2089e-01, time/batch = 16.3018s	
21413/26050 (epoch 41.100), train_loss = 0.71723921, grad/param norm = 1.9697e-01, time/batch = 15.8755s	
21414/26050 (epoch 41.102), train_loss = 0.82126472, grad/param norm = 2.4613e-01, time/batch = 17.8164s	
21415/26050 (epoch 41.104), train_loss = 0.77095989, grad/param norm = 2.0784e-01, time/batch = 18.3144s	
21416/26050 (epoch 41.106), train_loss = 0.85189950, grad/param norm = 2.2014e-01, time/batch = 18.0700s	
21417/26050 (epoch 41.107), train_loss = 0.67529820, grad/param norm = 1.8530e-01, time/batch = 18.3213s	
21418/26050 (epoch 41.109), train_loss = 0.74575170, grad/param norm = 1.9730e-01, time/batch = 17.0570s	
21419/26050 (epoch 41.111), train_loss = 0.94060692, grad/param norm = 2.3294e-01, time/batch = 17.1325s	
21420/26050 (epoch 41.113), train_loss = 0.78001234, grad/param norm = 1.9393e-01, time/batch = 18.8159s	
21421/26050 (epoch 41.115), train_loss = 0.90044197, grad/param norm = 2.1963e-01, time/batch = 16.9079s	
21422/26050 (epoch 41.117), train_loss = 0.79453274, grad/param norm = 2.0434e-01, time/batch = 17.2052s	
21423/26050 (epoch 41.119), train_loss = 0.70341376, grad/param norm = 1.7693e-01, time/batch = 18.5542s	
21424/26050 (epoch 41.121), train_loss = 0.80649294, grad/param norm = 1.9029e-01, time/batch = 18.3234s	
21425/26050 (epoch 41.123), train_loss = 0.73544596, grad/param norm = 2.1643e-01, time/batch = 18.0287s	
21426/26050 (epoch 41.125), train_loss = 0.68833922, grad/param norm = 1.9155e-01, time/batch = 17.6499s	
21427/26050 (epoch 41.127), train_loss = 0.68150171, grad/param norm = 1.9415e-01, time/batch = 18.8103s	
21428/26050 (epoch 41.129), train_loss = 0.62892650, grad/param norm = 2.2196e-01, time/batch = 15.8081s	
21429/26050 (epoch 41.131), train_loss = 0.80134751, grad/param norm = 2.2986e-01, time/batch = 14.6241s	
21430/26050 (epoch 41.132), train_loss = 0.79759917, grad/param norm = 2.0001e-01, time/batch = 16.9114s	
21431/26050 (epoch 41.134), train_loss = 0.84417799, grad/param norm = 2.6224e-01, time/batch = 17.7347s	
21432/26050 (epoch 41.136), train_loss = 0.77378765, grad/param norm = 1.9672e-01, time/batch = 18.2434s	
21433/26050 (epoch 41.138), train_loss = 0.56288167, grad/param norm = 1.9333e-01, time/batch = 17.8922s	
21434/26050 (epoch 41.140), train_loss = 0.65290879, grad/param norm = 1.8539e-01, time/batch = 18.4802s	
21435/26050 (epoch 41.142), train_loss = 0.68425160, grad/param norm = 2.0766e-01, time/batch = 18.2394s	
21436/26050 (epoch 41.144), train_loss = 0.65539620, grad/param norm = 2.2081e-01, time/batch = 17.5585s	
21437/26050 (epoch 41.146), train_loss = 0.60177001, grad/param norm = 1.7749e-01, time/batch = 16.9685s	
21438/26050 (epoch 41.148), train_loss = 0.62124248, grad/param norm = 1.6333e-01, time/batch = 15.0613s	
21439/26050 (epoch 41.150), train_loss = 0.72128247, grad/param norm = 2.1921e-01, time/batch = 17.5562s	
21440/26050 (epoch 41.152), train_loss = 0.89015421, grad/param norm = 2.8599e-01, time/batch = 18.1353s	
21441/26050 (epoch 41.154), train_loss = 0.63077701, grad/param norm = 2.1698e-01, time/batch = 18.5745s	
21442/26050 (epoch 41.155), train_loss = 0.67531384, grad/param norm = 2.1081e-01, time/batch = 17.3171s	
21443/26050 (epoch 41.157), train_loss = 0.76792805, grad/param norm = 2.8910e-01, time/batch = 16.9585s	
21444/26050 (epoch 41.159), train_loss = 0.82737210, grad/param norm = 2.4358e-01, time/batch = 18.4652s	
21445/26050 (epoch 41.161), train_loss = 0.80008942, grad/param norm = 2.4001e-01, time/batch = 18.4049s	
21446/26050 (epoch 41.163), train_loss = 0.67847844, grad/param norm = 2.2815e-01, time/batch = 17.0476s	
21447/26050 (epoch 41.165), train_loss = 0.62410444, grad/param norm = 2.0034e-01, time/batch = 0.6853s	
21448/26050 (epoch 41.167), train_loss = 0.91657274, grad/param norm = 2.6753e-01, time/batch = 0.6570s	
21449/26050 (epoch 41.169), train_loss = 0.79588860, grad/param norm = 2.1513e-01, time/batch = 0.6439s	
21450/26050 (epoch 41.171), train_loss = 0.71754239, grad/param norm = 1.9525e-01, time/batch = 0.6439s	
21451/26050 (epoch 41.173), train_loss = 0.75610234, grad/param norm = 2.1051e-01, time/batch = 0.6496s	
21452/26050 (epoch 41.175), train_loss = 0.78555112, grad/param norm = 1.9911e-01, time/batch = 0.6401s	
21453/26050 (epoch 41.177), train_loss = 0.83884403, grad/param norm = 2.0833e-01, time/batch = 0.6550s	
21454/26050 (epoch 41.179), train_loss = 0.59224449, grad/param norm = 1.7836e-01, time/batch = 0.7730s	
21455/26050 (epoch 41.180), train_loss = 1.00536275, grad/param norm = 2.3651e-01, time/batch = 0.9445s	
21456/26050 (epoch 41.182), train_loss = 0.94633768, grad/param norm = 2.8882e-01, time/batch = 0.9563s	
21457/26050 (epoch 41.184), train_loss = 0.82411672, grad/param norm = 2.0530e-01, time/batch = 0.9474s	
21458/26050 (epoch 41.186), train_loss = 0.67668070, grad/param norm = 1.8614e-01, time/batch = 0.9325s	
21459/26050 (epoch 41.188), train_loss = 0.83928627, grad/param norm = 2.2158e-01, time/batch = 1.1015s	
21460/26050 (epoch 41.190), train_loss = 0.82849846, grad/param norm = 2.5992e-01, time/batch = 1.8176s	
21461/26050 (epoch 41.192), train_loss = 0.88169865, grad/param norm = 1.9386e-01, time/batch = 1.7901s	
21462/26050 (epoch 41.194), train_loss = 0.83420939, grad/param norm = 2.1898e-01, time/batch = 8.5971s	
21463/26050 (epoch 41.196), train_loss = 0.84910427, grad/param norm = 2.3512e-01, time/batch = 16.0388s	
21464/26050 (epoch 41.198), train_loss = 0.72378741, grad/param norm = 1.7813e-01, time/batch = 17.6511s	
21465/26050 (epoch 41.200), train_loss = 0.70824578, grad/param norm = 2.1255e-01, time/batch = 18.4685s	
21466/26050 (epoch 41.202), train_loss = 0.80229985, grad/param norm = 2.0561e-01, time/batch = 17.5659s	
21467/26050 (epoch 41.203), train_loss = 0.91079028, grad/param norm = 2.0517e-01, time/batch = 16.5478s	
21468/26050 (epoch 41.205), train_loss = 0.74026357, grad/param norm = 2.2647e-01, time/batch = 15.3151s	
21469/26050 (epoch 41.207), train_loss = 0.71501154, grad/param norm = 2.1831e-01, time/batch = 17.2972s	
21470/26050 (epoch 41.209), train_loss = 0.86970993, grad/param norm = 2.2701e-01, time/batch = 15.7274s	
21471/26050 (epoch 41.211), train_loss = 0.68762046, grad/param norm = 1.8947e-01, time/batch = 17.7332s	
21472/26050 (epoch 41.213), train_loss = 0.81113619, grad/param norm = 2.3184e-01, time/batch = 18.1451s	
21473/26050 (epoch 41.215), train_loss = 0.77740784, grad/param norm = 2.1708e-01, time/batch = 18.4801s	
21474/26050 (epoch 41.217), train_loss = 0.76670446, grad/param norm = 2.0377e-01, time/batch = 18.5621s	
21475/26050 (epoch 41.219), train_loss = 0.75697578, grad/param norm = 2.3049e-01, time/batch = 18.4798s	
21476/26050 (epoch 41.221), train_loss = 0.71287355, grad/param norm = 2.3232e-01, time/batch = 17.7457s	
21477/26050 (epoch 41.223), train_loss = 0.85365806, grad/param norm = 2.1776e-01, time/batch = 17.9772s	
21478/26050 (epoch 41.225), train_loss = 0.71821826, grad/param norm = 2.2119e-01, time/batch = 16.8137s	
21479/26050 (epoch 41.226), train_loss = 0.80726445, grad/param norm = 2.5171e-01, time/batch = 15.5498s	
21480/26050 (epoch 41.228), train_loss = 0.90616615, grad/param norm = 2.2883e-01, time/batch = 17.2363s	
21481/26050 (epoch 41.230), train_loss = 0.80415766, grad/param norm = 1.9604e-01, time/batch = 17.7396s	
21482/26050 (epoch 41.232), train_loss = 0.88183275, grad/param norm = 2.3451e-01, time/batch = 18.2339s	
21483/26050 (epoch 41.234), train_loss = 0.69418942, grad/param norm = 2.0052e-01, time/batch = 18.9045s	
21484/26050 (epoch 41.236), train_loss = 0.86510769, grad/param norm = 2.3580e-01, time/batch = 14.5650s	
21485/26050 (epoch 41.238), train_loss = 0.69904704, grad/param norm = 2.0496e-01, time/batch = 14.5376s	
21486/26050 (epoch 41.240), train_loss = 0.80550027, grad/param norm = 2.0872e-01, time/batch = 15.8837s	
21487/26050 (epoch 41.242), train_loss = 0.76662686, grad/param norm = 1.9120e-01, time/batch = 14.3777s	
21488/26050 (epoch 41.244), train_loss = 0.81526069, grad/param norm = 2.2115e-01, time/batch = 14.4869s	
21489/26050 (epoch 41.246), train_loss = 0.76008640, grad/param norm = 1.9795e-01, time/batch = 15.3850s	
21490/26050 (epoch 41.248), train_loss = 0.79876301, grad/param norm = 2.2842e-01, time/batch = 16.1968s	
21491/26050 (epoch 41.250), train_loss = 0.80221364, grad/param norm = 2.5336e-01, time/batch = 18.0675s	
21492/26050 (epoch 41.251), train_loss = 0.75082300, grad/param norm = 2.1339e-01, time/batch = 18.1538s	
21493/26050 (epoch 41.253), train_loss = 0.67696882, grad/param norm = 1.9706e-01, time/batch = 16.9777s	
21494/26050 (epoch 41.255), train_loss = 0.96817468, grad/param norm = 2.5020e-01, time/batch = 18.6569s	
21495/26050 (epoch 41.257), train_loss = 0.82775777, grad/param norm = 2.4217e-01, time/batch = 14.9055s	
21496/26050 (epoch 41.259), train_loss = 0.88489877, grad/param norm = 2.2547e-01, time/batch = 16.9760s	
21497/26050 (epoch 41.261), train_loss = 0.73578140, grad/param norm = 2.3923e-01, time/batch = 18.7978s	
21498/26050 (epoch 41.263), train_loss = 0.89516142, grad/param norm = 2.4970e-01, time/batch = 17.4861s	
21499/26050 (epoch 41.265), train_loss = 0.90786813, grad/param norm = 2.8694e-01, time/batch = 17.8142s	
21500/26050 (epoch 41.267), train_loss = 0.91814393, grad/param norm = 2.0826e-01, time/batch = 18.0756s	
21501/26050 (epoch 41.269), train_loss = 0.90992596, grad/param norm = 2.4537e-01, time/batch = 18.5662s	
21502/26050 (epoch 41.271), train_loss = 0.81227070, grad/param norm = 2.3043e-01, time/batch = 18.4156s	
21503/26050 (epoch 41.273), train_loss = 0.72609660, grad/param norm = 2.1080e-01, time/batch = 17.1397s	
21504/26050 (epoch 41.274), train_loss = 0.76725999, grad/param norm = 1.9707e-01, time/batch = 18.5712s	
21505/26050 (epoch 41.276), train_loss = 0.77704775, grad/param norm = 2.2930e-01, time/batch = 18.8246s	
21506/26050 (epoch 41.278), train_loss = 0.88115413, grad/param norm = 2.0405e-01, time/batch = 15.3916s	
21507/26050 (epoch 41.280), train_loss = 0.79544728, grad/param norm = 2.0794e-01, time/batch = 18.6318s	
21508/26050 (epoch 41.282), train_loss = 0.87416913, grad/param norm = 2.3088e-01, time/batch = 16.8074s	
21509/26050 (epoch 41.284), train_loss = 0.79401182, grad/param norm = 2.2376e-01, time/batch = 16.3735s	
21510/26050 (epoch 41.286), train_loss = 0.84233095, grad/param norm = 2.3316e-01, time/batch = 17.8867s	
21511/26050 (epoch 41.288), train_loss = 0.69826395, grad/param norm = 1.8968e-01, time/batch = 17.3218s	
21512/26050 (epoch 41.290), train_loss = 0.79419587, grad/param norm = 2.1036e-01, time/batch = 18.7323s	
21513/26050 (epoch 41.292), train_loss = 0.73553683, grad/param norm = 2.1832e-01, time/batch = 17.4822s	
21514/26050 (epoch 41.294), train_loss = 0.81337136, grad/param norm = 2.5405e-01, time/batch = 18.2321s	
21515/26050 (epoch 41.296), train_loss = 0.87979602, grad/param norm = 2.1160e-01, time/batch = 16.9831s	
21516/26050 (epoch 41.298), train_loss = 0.85471514, grad/param norm = 2.2890e-01, time/batch = 13.9060s	
21517/26050 (epoch 41.299), train_loss = 0.69174282, grad/param norm = 1.8966e-01, time/batch = 14.3244s	
21518/26050 (epoch 41.301), train_loss = 0.67799104, grad/param norm = 2.0070e-01, time/batch = 14.1521s	
21519/26050 (epoch 41.303), train_loss = 0.79060133, grad/param norm = 2.4779e-01, time/batch = 15.4060s	
21520/26050 (epoch 41.305), train_loss = 0.64254926, grad/param norm = 1.7770e-01, time/batch = 15.6516s	
21521/26050 (epoch 41.307), train_loss = 0.70279439, grad/param norm = 2.2014e-01, time/batch = 16.7278s	
21522/26050 (epoch 41.309), train_loss = 0.84705475, grad/param norm = 2.1634e-01, time/batch = 17.1954s	
21523/26050 (epoch 41.311), train_loss = 0.81168682, grad/param norm = 2.6927e-01, time/batch = 17.5338s	
21524/26050 (epoch 41.313), train_loss = 0.80287189, grad/param norm = 2.7494e-01, time/batch = 17.8716s	
21525/26050 (epoch 41.315), train_loss = 0.85535689, grad/param norm = 2.1994e-01, time/batch = 17.9013s	
21526/26050 (epoch 41.317), train_loss = 0.81251129, grad/param norm = 2.5747e-01, time/batch = 17.9067s	
21527/26050 (epoch 41.319), train_loss = 0.74990566, grad/param norm = 2.0346e-01, time/batch = 17.8964s	
21528/26050 (epoch 41.321), train_loss = 0.80055967, grad/param norm = 2.0400e-01, time/batch = 15.8927s	
21529/26050 (epoch 41.322), train_loss = 0.86950813, grad/param norm = 2.3899e-01, time/batch = 19.0687s	
21530/26050 (epoch 41.324), train_loss = 0.64313233, grad/param norm = 1.9638e-01, time/batch = 18.6488s	
21531/26050 (epoch 41.326), train_loss = 0.90151892, grad/param norm = 2.3460e-01, time/batch = 18.0440s	
21532/26050 (epoch 41.328), train_loss = 0.84080777, grad/param norm = 2.1223e-01, time/batch = 18.3026s	
21533/26050 (epoch 41.330), train_loss = 0.70179034, grad/param norm = 2.1637e-01, time/batch = 18.8819s	
21534/26050 (epoch 41.332), train_loss = 0.86266464, grad/param norm = 2.1924e-01, time/batch = 16.4870s	
21535/26050 (epoch 41.334), train_loss = 0.70463541, grad/param norm = 2.1492e-01, time/batch = 18.8130s	
21536/26050 (epoch 41.336), train_loss = 0.76214975, grad/param norm = 2.0801e-01, time/batch = 18.4010s	
21537/26050 (epoch 41.338), train_loss = 0.68574907, grad/param norm = 1.9197e-01, time/batch = 15.0719s	
21538/26050 (epoch 41.340), train_loss = 0.84063457, grad/param norm = 2.0714e-01, time/batch = 17.1940s	
21539/26050 (epoch 41.342), train_loss = 0.89141700, grad/param norm = 2.1271e-01, time/batch = 17.8271s	
21540/26050 (epoch 41.344), train_loss = 0.73009759, grad/param norm = 2.3032e-01, time/batch = 14.9708s	
21541/26050 (epoch 41.345), train_loss = 0.79854847, grad/param norm = 2.4463e-01, time/batch = 17.4114s	
21542/26050 (epoch 41.347), train_loss = 0.91381299, grad/param norm = 2.1623e-01, time/batch = 17.5743s	
21543/26050 (epoch 41.349), train_loss = 0.85242675, grad/param norm = 2.2218e-01, time/batch = 18.7287s	
21544/26050 (epoch 41.351), train_loss = 0.81309605, grad/param norm = 2.1153e-01, time/batch = 17.7309s	
21545/26050 (epoch 41.353), train_loss = 0.79317620, grad/param norm = 2.1816e-01, time/batch = 17.5670s	
21546/26050 (epoch 41.355), train_loss = 0.82341009, grad/param norm = 2.7945e-01, time/batch = 15.4611s	
21547/26050 (epoch 41.357), train_loss = 0.74696003, grad/param norm = 1.9797e-01, time/batch = 18.3196s	
21548/26050 (epoch 41.359), train_loss = 0.89782464, grad/param norm = 2.2910e-01, time/batch = 17.5598s	
21549/26050 (epoch 41.361), train_loss = 0.71574087, grad/param norm = 1.8496e-01, time/batch = 18.4905s	
21550/26050 (epoch 41.363), train_loss = 0.88144646, grad/param norm = 2.2905e-01, time/batch = 17.3166s	
21551/26050 (epoch 41.365), train_loss = 0.77566931, grad/param norm = 1.9339e-01, time/batch = 15.7165s	
21552/26050 (epoch 41.367), train_loss = 0.84399533, grad/param norm = 1.9396e-01, time/batch = 17.0473s	
21553/26050 (epoch 41.369), train_loss = 0.70934257, grad/param norm = 1.8048e-01, time/batch = 17.9059s	
21554/26050 (epoch 41.370), train_loss = 0.70415066, grad/param norm = 1.8627e-01, time/batch = 18.1493s	
21555/26050 (epoch 41.372), train_loss = 0.78757344, grad/param norm = 2.0993e-01, time/batch = 18.8091s	
21556/26050 (epoch 41.374), train_loss = 0.91574765, grad/param norm = 2.2076e-01, time/batch = 17.8267s	
21557/26050 (epoch 41.376), train_loss = 0.93340495, grad/param norm = 2.4276e-01, time/batch = 15.1540s	
21558/26050 (epoch 41.378), train_loss = 0.76418440, grad/param norm = 2.0623e-01, time/batch = 17.3137s	
21559/26050 (epoch 41.380), train_loss = 0.90972292, grad/param norm = 2.4714e-01, time/batch = 17.8097s	
21560/26050 (epoch 41.382), train_loss = 0.99244629, grad/param norm = 2.7613e-01, time/batch = 17.3091s	
21561/26050 (epoch 41.384), train_loss = 0.75697963, grad/param norm = 2.2797e-01, time/batch = 15.4520s	
21562/26050 (epoch 41.386), train_loss = 0.85745782, grad/param norm = 2.3805e-01, time/batch = 18.0518s	
21563/26050 (epoch 41.388), train_loss = 0.81239387, grad/param norm = 2.1860e-01, time/batch = 18.4903s	
21564/26050 (epoch 41.390), train_loss = 0.74635770, grad/param norm = 1.9267e-01, time/batch = 17.6590s	
21565/26050 (epoch 41.392), train_loss = 0.69810731, grad/param norm = 2.0207e-01, time/batch = 22.5517s	
21566/26050 (epoch 41.393), train_loss = 0.88061375, grad/param norm = 2.8062e-01, time/batch = 32.7177s	
21567/26050 (epoch 41.395), train_loss = 0.85993454, grad/param norm = 2.3146e-01, time/batch = 15.2199s	
21568/26050 (epoch 41.397), train_loss = 0.85163768, grad/param norm = 2.7680e-01, time/batch = 18.5703s	
21569/26050 (epoch 41.399), train_loss = 0.77128862, grad/param norm = 2.4433e-01, time/batch = 17.9008s	
21570/26050 (epoch 41.401), train_loss = 0.81158557, grad/param norm = 2.0679e-01, time/batch = 18.3052s	
21571/26050 (epoch 41.403), train_loss = 0.82747451, grad/param norm = 2.7409e-01, time/batch = 18.5596s	
21572/26050 (epoch 41.405), train_loss = 0.82963954, grad/param norm = 2.1293e-01, time/batch = 18.1479s	
21573/26050 (epoch 41.407), train_loss = 0.93242242, grad/param norm = 2.3012e-01, time/batch = 18.6457s	
21574/26050 (epoch 41.409), train_loss = 0.93319442, grad/param norm = 2.7471e-01, time/batch = 15.5479s	
21575/26050 (epoch 41.411), train_loss = 0.89466996, grad/param norm = 2.3066e-01, time/batch = 18.7291s	
21576/26050 (epoch 41.413), train_loss = 0.99350936, grad/param norm = 2.2660e-01, time/batch = 17.4618s	
21577/26050 (epoch 41.415), train_loss = 0.97991612, grad/param norm = 2.3242e-01, time/batch = 17.5646s	
21578/26050 (epoch 41.417), train_loss = 0.97093557, grad/param norm = 2.7164e-01, time/batch = 18.3979s	
21579/26050 (epoch 41.418), train_loss = 0.87707214, grad/param norm = 2.7242e-01, time/batch = 18.3137s	
21580/26050 (epoch 41.420), train_loss = 0.70806522, grad/param norm = 2.1202e-01, time/batch = 18.4018s	
21581/26050 (epoch 41.422), train_loss = 0.69221672, grad/param norm = 2.0053e-01, time/batch = 17.7278s	
21582/26050 (epoch 41.424), train_loss = 0.89605811, grad/param norm = 2.3334e-01, time/batch = 18.3059s	
21583/26050 (epoch 41.426), train_loss = 0.87568246, grad/param norm = 2.4090e-01, time/batch = 17.0487s	
21584/26050 (epoch 41.428), train_loss = 0.78235660, grad/param norm = 1.9938e-01, time/batch = 15.8885s	
21585/26050 (epoch 41.430), train_loss = 0.96448185, grad/param norm = 2.3389e-01, time/batch = 18.4864s	
21586/26050 (epoch 41.432), train_loss = 0.79426163, grad/param norm = 2.1916e-01, time/batch = 18.7316s	
21587/26050 (epoch 41.434), train_loss = 0.77372563, grad/param norm = 2.1260e-01, time/batch = 17.4768s	
21588/26050 (epoch 41.436), train_loss = 0.88432930, grad/param norm = 2.2103e-01, time/batch = 17.3937s	
21589/26050 (epoch 41.438), train_loss = 0.84272522, grad/param norm = 2.3328e-01, time/batch = 16.0555s	
21590/26050 (epoch 41.440), train_loss = 0.83943855, grad/param norm = 2.0407e-01, time/batch = 15.8696s	
21591/26050 (epoch 41.441), train_loss = 0.85575591, grad/param norm = 2.1597e-01, time/batch = 17.3276s	
21592/26050 (epoch 41.443), train_loss = 0.72563197, grad/param norm = 2.0927e-01, time/batch = 17.8308s	
21593/26050 (epoch 41.445), train_loss = 0.73694378, grad/param norm = 2.2079e-01, time/batch = 16.3987s	
21594/26050 (epoch 41.447), train_loss = 0.94109917, grad/param norm = 2.2436e-01, time/batch = 16.8894s	
21595/26050 (epoch 41.449), train_loss = 0.73996267, grad/param norm = 2.7059e-01, time/batch = 18.0641s	
21596/26050 (epoch 41.451), train_loss = 0.94693258, grad/param norm = 2.2133e-01, time/batch = 17.9909s	
21597/26050 (epoch 41.453), train_loss = 0.78813700, grad/param norm = 1.9963e-01, time/batch = 17.8180s	
21598/26050 (epoch 41.455), train_loss = 0.82711367, grad/param norm = 2.1475e-01, time/batch = 17.6552s	
21599/26050 (epoch 41.457), train_loss = 0.78492766, grad/param norm = 2.0924e-01, time/batch = 16.5387s	
21600/26050 (epoch 41.459), train_loss = 0.89144035, grad/param norm = 2.2528e-01, time/batch = 17.9661s	
21601/26050 (epoch 41.461), train_loss = 0.90052595, grad/param norm = 2.4827e-01, time/batch = 17.7227s	
21602/26050 (epoch 41.463), train_loss = 0.77088135, grad/param norm = 1.8919e-01, time/batch = 18.6398s	
21603/26050 (epoch 41.464), train_loss = 0.84138308, grad/param norm = 2.4185e-01, time/batch = 16.9609s	
21604/26050 (epoch 41.466), train_loss = 0.81599758, grad/param norm = 2.4227e-01, time/batch = 17.8028s	
21605/26050 (epoch 41.468), train_loss = 0.92528410, grad/param norm = 2.0163e-01, time/batch = 15.8039s	
21606/26050 (epoch 41.470), train_loss = 0.90894972, grad/param norm = 2.3982e-01, time/batch = 17.7874s	
21607/26050 (epoch 41.472), train_loss = 0.91589391, grad/param norm = 2.6198e-01, time/batch = 17.1426s	
21608/26050 (epoch 41.474), train_loss = 0.95835257, grad/param norm = 2.5860e-01, time/batch = 17.0405s	
21609/26050 (epoch 41.476), train_loss = 0.88896780, grad/param norm = 1.8882e-01, time/batch = 18.8137s	
21610/26050 (epoch 41.478), train_loss = 0.80169327, grad/param norm = 2.1901e-01, time/batch = 18.1367s	
21611/26050 (epoch 41.480), train_loss = 0.78215001, grad/param norm = 2.0005e-01, time/batch = 18.0435s	
21612/26050 (epoch 41.482), train_loss = 0.77840593, grad/param norm = 2.2152e-01, time/batch = 18.3925s	
21613/26050 (epoch 41.484), train_loss = 0.76561451, grad/param norm = 2.4315e-01, time/batch = 18.4026s	
21614/26050 (epoch 41.486), train_loss = 0.92489092, grad/param norm = 2.3789e-01, time/batch = 18.5620s	
21615/26050 (epoch 41.488), train_loss = 0.97700174, grad/param norm = 2.4350e-01, time/batch = 15.5451s	
21616/26050 (epoch 41.489), train_loss = 0.99248055, grad/param norm = 2.6140e-01, time/batch = 18.5649s	
21617/26050 (epoch 41.491), train_loss = 0.74676034, grad/param norm = 2.2618e-01, time/batch = 17.4896s	
21618/26050 (epoch 41.493), train_loss = 0.83301538, grad/param norm = 2.3236e-01, time/batch = 17.5554s	
21619/26050 (epoch 41.495), train_loss = 0.80431322, grad/param norm = 1.8894e-01, time/batch = 18.1346s	
21620/26050 (epoch 41.497), train_loss = 0.74994590, grad/param norm = 2.0591e-01, time/batch = 17.9756s	
21621/26050 (epoch 41.499), train_loss = 0.75062473, grad/param norm = 2.1760e-01, time/batch = 18.3120s	
21622/26050 (epoch 41.501), train_loss = 0.90112657, grad/param norm = 1.9119e-01, time/batch = 15.4587s	
21623/26050 (epoch 41.503), train_loss = 0.76933402, grad/param norm = 1.9997e-01, time/batch = 17.7191s	
21624/26050 (epoch 41.505), train_loss = 0.91544499, grad/param norm = 2.1290e-01, time/batch = 18.5580s	
21625/26050 (epoch 41.507), train_loss = 0.90403320, grad/param norm = 2.4611e-01, time/batch = 17.6425s	
21626/26050 (epoch 41.509), train_loss = 0.93358353, grad/param norm = 2.0154e-01, time/batch = 17.0422s	
21627/26050 (epoch 41.511), train_loss = 0.80996848, grad/param norm = 1.9366e-01, time/batch = 18.6380s	
21628/26050 (epoch 41.512), train_loss = 0.72318933, grad/param norm = 2.5939e-01, time/batch = 17.8788s	
21629/26050 (epoch 41.514), train_loss = 0.86103895, grad/param norm = 2.3624e-01, time/batch = 18.7965s	
21630/26050 (epoch 41.516), train_loss = 0.94880173, grad/param norm = 2.4754e-01, time/batch = 14.5537s	
21631/26050 (epoch 41.518), train_loss = 0.80582711, grad/param norm = 2.2366e-01, time/batch = 17.4778s	
21632/26050 (epoch 41.520), train_loss = 0.83575721, grad/param norm = 2.2118e-01, time/batch = 16.6083s	
21633/26050 (epoch 41.522), train_loss = 0.65669300, grad/param norm = 2.3210e-01, time/batch = 18.4022s	
21634/26050 (epoch 41.524), train_loss = 0.91111763, grad/param norm = 2.8830e-01, time/batch = 18.2960s	
21635/26050 (epoch 41.526), train_loss = 0.92355303, grad/param norm = 2.4624e-01, time/batch = 17.8069s	
21636/26050 (epoch 41.528), train_loss = 0.85610828, grad/param norm = 2.2189e-01, time/batch = 18.3033s	
21637/26050 (epoch 41.530), train_loss = 0.80267606, grad/param norm = 2.4675e-01, time/batch = 17.0503s	
21638/26050 (epoch 41.532), train_loss = 0.86368320, grad/param norm = 2.4456e-01, time/batch = 17.7272s	
21639/26050 (epoch 41.534), train_loss = 0.83064030, grad/param norm = 2.6943e-01, time/batch = 17.7445s	
21640/26050 (epoch 41.536), train_loss = 0.86694652, grad/param norm = 2.1496e-01, time/batch = 18.4035s	
21641/26050 (epoch 41.537), train_loss = 0.89151818, grad/param norm = 2.1332e-01, time/batch = 17.3972s	
21642/26050 (epoch 41.539), train_loss = 0.85371310, grad/param norm = 2.2610e-01, time/batch = 16.5593s	
21643/26050 (epoch 41.541), train_loss = 0.97411452, grad/param norm = 2.5799e-01, time/batch = 16.5432s	
21644/26050 (epoch 41.543), train_loss = 0.66075964, grad/param norm = 2.0249e-01, time/batch = 18.5795s	
21645/26050 (epoch 41.545), train_loss = 0.81755705, grad/param norm = 2.2351e-01, time/batch = 17.8189s	
21646/26050 (epoch 41.547), train_loss = 0.76851054, grad/param norm = 2.1755e-01, time/batch = 18.3053s	
21647/26050 (epoch 41.549), train_loss = 0.72076368, grad/param norm = 2.2726e-01, time/batch = 17.4911s	
21648/26050 (epoch 41.551), train_loss = 0.88218505, grad/param norm = 2.4121e-01, time/batch = 17.6588s	
21649/26050 (epoch 41.553), train_loss = 0.81977651, grad/param norm = 2.3469e-01, time/batch = 15.2112s	
21650/26050 (epoch 41.555), train_loss = 0.71449246, grad/param norm = 2.1682e-01, time/batch = 18.7330s	
21651/26050 (epoch 41.557), train_loss = 0.84715696, grad/param norm = 1.9921e-01, time/batch = 18.1483s	
21652/26050 (epoch 41.559), train_loss = 0.83988950, grad/param norm = 2.1082e-01, time/batch = 17.4141s	
21653/26050 (epoch 41.560), train_loss = 0.79884114, grad/param norm = 2.3057e-01, time/batch = 17.9107s	
21654/26050 (epoch 41.562), train_loss = 0.80663354, grad/param norm = 2.1322e-01, time/batch = 18.3259s	
21655/26050 (epoch 41.564), train_loss = 0.96890789, grad/param norm = 2.3473e-01, time/batch = 18.1458s	
21656/26050 (epoch 41.566), train_loss = 0.77871498, grad/param norm = 1.9726e-01, time/batch = 18.4852s	
21657/26050 (epoch 41.568), train_loss = 0.85238418, grad/param norm = 2.1700e-01, time/batch = 15.4778s	
21658/26050 (epoch 41.570), train_loss = 0.82103402, grad/param norm = 2.2776e-01, time/batch = 18.3962s	
21659/26050 (epoch 41.572), train_loss = 0.84037647, grad/param norm = 2.2305e-01, time/batch = 16.4670s	
21660/26050 (epoch 41.574), train_loss = 0.84932080, grad/param norm = 2.4678e-01, time/batch = 16.9438s	
21661/26050 (epoch 41.576), train_loss = 0.84971724, grad/param norm = 2.3533e-01, time/batch = 18.3167s	
21662/26050 (epoch 41.578), train_loss = 0.79642479, grad/param norm = 2.3287e-01, time/batch = 17.8251s	
21663/26050 (epoch 41.580), train_loss = 0.76440726, grad/param norm = 2.3090e-01, time/batch = 18.6603s	
21664/26050 (epoch 41.582), train_loss = 0.84497611, grad/param norm = 2.1232e-01, time/batch = 17.3124s	
21665/26050 (epoch 41.583), train_loss = 0.88057511, grad/param norm = 2.1431e-01, time/batch = 17.8954s	
21666/26050 (epoch 41.585), train_loss = 0.73908468, grad/param norm = 2.2281e-01, time/batch = 17.6443s	
21667/26050 (epoch 41.587), train_loss = 0.84776275, grad/param norm = 2.4773e-01, time/batch = 16.5467s	
21668/26050 (epoch 41.589), train_loss = 0.97127862, grad/param norm = 2.5459e-01, time/batch = 17.2051s	
21669/26050 (epoch 41.591), train_loss = 0.83979196, grad/param norm = 2.3178e-01, time/batch = 17.7215s	
21670/26050 (epoch 41.593), train_loss = 0.69803532, grad/param norm = 1.9309e-01, time/batch = 18.3083s	
21671/26050 (epoch 41.595), train_loss = 0.85790077, grad/param norm = 2.3724e-01, time/batch = 15.2353s	
21672/26050 (epoch 41.597), train_loss = 0.83614538, grad/param norm = 2.1730e-01, time/batch = 17.9807s	
21673/26050 (epoch 41.599), train_loss = 0.88696947, grad/param norm = 2.2976e-01, time/batch = 18.0590s	
21674/26050 (epoch 41.601), train_loss = 0.97905264, grad/param norm = 2.2661e-01, time/batch = 17.6526s	
21675/26050 (epoch 41.603), train_loss = 0.89415962, grad/param norm = 2.3470e-01, time/batch = 18.3104s	
21676/26050 (epoch 41.605), train_loss = 0.80284726, grad/param norm = 2.1938e-01, time/batch = 17.8151s	
21677/26050 (epoch 41.607), train_loss = 0.92142401, grad/param norm = 2.8060e-01, time/batch = 16.7973s	
21678/26050 (epoch 41.608), train_loss = 0.75050361, grad/param norm = 1.9234e-01, time/batch = 14.7334s	
21679/26050 (epoch 41.610), train_loss = 0.82602699, grad/param norm = 2.3346e-01, time/batch = 17.4785s	
21680/26050 (epoch 41.612), train_loss = 0.80012852, grad/param norm = 2.2507e-01, time/batch = 17.4888s	
21681/26050 (epoch 41.614), train_loss = 0.83364349, grad/param norm = 2.1256e-01, time/batch = 18.6579s	
21682/26050 (epoch 41.616), train_loss = 0.86728089, grad/param norm = 2.4037e-01, time/batch = 18.7933s	
21683/26050 (epoch 41.618), train_loss = 0.78665468, grad/param norm = 2.0889e-01, time/batch = 17.1196s	
21684/26050 (epoch 41.620), train_loss = 0.89710920, grad/param norm = 2.3067e-01, time/batch = 18.9636s	
21685/26050 (epoch 41.622), train_loss = 0.76056810, grad/param norm = 2.1176e-01, time/batch = 14.8051s	
21686/26050 (epoch 41.624), train_loss = 0.69186845, grad/param norm = 1.9250e-01, time/batch = 16.9050s	
21687/26050 (epoch 41.626), train_loss = 0.86267928, grad/param norm = 2.3548e-01, time/batch = 18.6531s	
21688/26050 (epoch 41.628), train_loss = 0.79226764, grad/param norm = 2.5213e-01, time/batch = 18.8267s	
21689/26050 (epoch 41.630), train_loss = 0.97039519, grad/param norm = 2.5484e-01, time/batch = 17.8245s	
21690/26050 (epoch 41.631), train_loss = 0.96562755, grad/param norm = 2.3752e-01, time/batch = 17.4828s	
21691/26050 (epoch 41.633), train_loss = 0.77393505, grad/param norm = 2.4387e-01, time/batch = 18.4822s	
21692/26050 (epoch 41.635), train_loss = 0.79148546, grad/param norm = 1.8631e-01, time/batch = 16.5516s	
21693/26050 (epoch 41.637), train_loss = 0.72829831, grad/param norm = 1.8783e-01, time/batch = 17.0713s	
21694/26050 (epoch 41.639), train_loss = 0.85759117, grad/param norm = 2.0441e-01, time/batch = 16.4060s	
21695/26050 (epoch 41.641), train_loss = 0.77610997, grad/param norm = 2.2428e-01, time/batch = 14.7969s	
21696/26050 (epoch 41.643), train_loss = 0.76966693, grad/param norm = 1.9383e-01, time/batch = 17.3901s	
21697/26050 (epoch 41.645), train_loss = 0.77787830, grad/param norm = 2.1174e-01, time/batch = 18.2410s	
21698/26050 (epoch 41.647), train_loss = 0.74296568, grad/param norm = 2.9438e-01, time/batch = 18.3054s	
21699/26050 (epoch 41.649), train_loss = 0.79224750, grad/param norm = 2.3177e-01, time/batch = 18.9066s	
21700/26050 (epoch 41.651), train_loss = 0.76848769, grad/param norm = 1.9427e-01, time/batch = 17.7210s	
21701/26050 (epoch 41.653), train_loss = 0.81132564, grad/param norm = 2.3494e-01, time/batch = 16.9541s	
21702/26050 (epoch 41.655), train_loss = 0.73352480, grad/param norm = 2.1046e-01, time/batch = 16.6469s	
21703/26050 (epoch 41.656), train_loss = 0.73195828, grad/param norm = 2.0589e-01, time/batch = 17.4641s	
21704/26050 (epoch 41.658), train_loss = 0.99296359, grad/param norm = 2.5192e-01, time/batch = 17.9914s	
21705/26050 (epoch 41.660), train_loss = 0.68530801, grad/param norm = 2.0700e-01, time/batch = 18.2335s	
21706/26050 (epoch 41.662), train_loss = 0.81232665, grad/param norm = 1.9299e-01, time/batch = 17.8132s	
21707/26050 (epoch 41.664), train_loss = 0.80132105, grad/param norm = 1.9966e-01, time/batch = 17.9033s	
21708/26050 (epoch 41.666), train_loss = 0.77237949, grad/param norm = 2.0072e-01, time/batch = 15.8748s	
21709/26050 (epoch 41.668), train_loss = 0.63501000, grad/param norm = 2.2600e-01, time/batch = 18.3616s	
21710/26050 (epoch 41.670), train_loss = 0.94915436, grad/param norm = 2.8255e-01, time/batch = 16.8898s	
21711/26050 (epoch 41.672), train_loss = 0.81487144, grad/param norm = 2.1498e-01, time/batch = 18.8175s	
21712/26050 (epoch 41.674), train_loss = 0.72851922, grad/param norm = 2.1809e-01, time/batch = 15.8643s	
21713/26050 (epoch 41.676), train_loss = 0.86935204, grad/param norm = 2.8058e-01, time/batch = 17.7271s	
21714/26050 (epoch 41.678), train_loss = 0.89796640, grad/param norm = 2.4681e-01, time/batch = 18.1506s	
21715/26050 (epoch 41.679), train_loss = 0.93729965, grad/param norm = 2.4329e-01, time/batch = 18.9015s	
21716/26050 (epoch 41.681), train_loss = 0.85121131, grad/param norm = 2.6240e-01, time/batch = 16.3221s	
21717/26050 (epoch 41.683), train_loss = 0.75106068, grad/param norm = 4.1054e-01, time/batch = 17.3666s	
21718/26050 (epoch 41.685), train_loss = 0.77888113, grad/param norm = 2.1888e-01, time/batch = 15.1373s	
21719/26050 (epoch 41.687), train_loss = 0.70637583, grad/param norm = 2.1693e-01, time/batch = 17.8742s	
21720/26050 (epoch 41.689), train_loss = 0.78310895, grad/param norm = 2.2004e-01, time/batch = 16.5457s	
21721/26050 (epoch 41.691), train_loss = 0.65968615, grad/param norm = 1.7381e-01, time/batch = 16.3372s	
21722/26050 (epoch 41.693), train_loss = 0.78687908, grad/param norm = 2.4506e-01, time/batch = 18.5577s	
21723/26050 (epoch 41.695), train_loss = 0.80302755, grad/param norm = 2.0476e-01, time/batch = 16.9856s	
21724/26050 (epoch 41.697), train_loss = 0.74366233, grad/param norm = 2.0565e-01, time/batch = 17.9766s	
21725/26050 (epoch 41.699), train_loss = 0.86732517, grad/param norm = 2.3366e-01, time/batch = 16.8813s	
21726/26050 (epoch 41.701), train_loss = 0.73754844, grad/param norm = 1.7690e-01, time/batch = 16.1607s	
21727/26050 (epoch 41.702), train_loss = 0.88214462, grad/param norm = 2.1857e-01, time/batch = 17.2995s	
21728/26050 (epoch 41.704), train_loss = 0.93379903, grad/param norm = 2.1390e-01, time/batch = 17.8186s	
21729/26050 (epoch 41.706), train_loss = 0.76782635, grad/param norm = 2.3791e-01, time/batch = 18.4773s	
21730/26050 (epoch 41.708), train_loss = 0.86215015, grad/param norm = 2.1554e-01, time/batch = 15.0499s	
21731/26050 (epoch 41.710), train_loss = 0.83829594, grad/param norm = 2.5471e-01, time/batch = 17.8007s	
21732/26050 (epoch 41.712), train_loss = 0.80899903, grad/param norm = 2.3019e-01, time/batch = 18.2284s	
21733/26050 (epoch 41.714), train_loss = 0.72926737, grad/param norm = 1.8885e-01, time/batch = 18.8817s	
21734/26050 (epoch 41.716), train_loss = 1.03512793, grad/param norm = 2.7141e-01, time/batch = 16.9767s	
21735/26050 (epoch 41.718), train_loss = 0.88913010, grad/param norm = 2.5847e-01, time/batch = 17.9894s	
21736/26050 (epoch 41.720), train_loss = 0.80401929, grad/param norm = 2.3130e-01, time/batch = 17.6459s	
21737/26050 (epoch 41.722), train_loss = 0.74085415, grad/param norm = 2.1344e-01, time/batch = 17.7361s	
21738/26050 (epoch 41.724), train_loss = 0.76267966, grad/param norm = 2.3875e-01, time/batch = 15.1325s	
21739/26050 (epoch 41.726), train_loss = 0.88385499, grad/param norm = 2.2075e-01, time/batch = 15.9657s	
21740/26050 (epoch 41.727), train_loss = 0.87766965, grad/param norm = 2.2943e-01, time/batch = 18.8224s	
21741/26050 (epoch 41.729), train_loss = 0.86871342, grad/param norm = 2.2046e-01, time/batch = 16.2115s	
21742/26050 (epoch 41.731), train_loss = 0.85552108, grad/param norm = 2.1781e-01, time/batch = 18.1446s	
21743/26050 (epoch 41.733), train_loss = 0.78941260, grad/param norm = 2.3163e-01, time/batch = 17.8929s	
21744/26050 (epoch 41.735), train_loss = 0.93791649, grad/param norm = 2.2494e-01, time/batch = 16.1308s	
21745/26050 (epoch 41.737), train_loss = 0.79363024, grad/param norm = 2.6251e-01, time/batch = 18.2397s	
21746/26050 (epoch 41.739), train_loss = 0.84157052, grad/param norm = 2.0362e-01, time/batch = 17.8254s	
21747/26050 (epoch 41.741), train_loss = 0.74296839, grad/param norm = 2.0897e-01, time/batch = 17.8111s	
21748/26050 (epoch 41.743), train_loss = 0.82979740, grad/param norm = 2.4405e-01, time/batch = 15.1414s	
21749/26050 (epoch 41.745), train_loss = 0.74154301, grad/param norm = 2.1908e-01, time/batch = 17.3939s	
21750/26050 (epoch 41.747), train_loss = 0.76775962, grad/param norm = 2.1082e-01, time/batch = 17.4061s	
21751/26050 (epoch 41.749), train_loss = 0.90202665, grad/param norm = 2.2938e-01, time/batch = 17.3104s	
21752/26050 (epoch 41.750), train_loss = 0.78296906, grad/param norm = 2.0581e-01, time/batch = 16.6556s	
21753/26050 (epoch 41.752), train_loss = 0.76748848, grad/param norm = 2.8340e-01, time/batch = 18.0584s	
21754/26050 (epoch 41.754), train_loss = 0.81791250, grad/param norm = 2.5172e-01, time/batch = 14.3997s	
21755/26050 (epoch 41.756), train_loss = 0.77566198, grad/param norm = 2.1583e-01, time/batch = 16.7305s	
21756/26050 (epoch 41.758), train_loss = 0.80991353, grad/param norm = 2.3281e-01, time/batch = 18.4782s	
21757/26050 (epoch 41.760), train_loss = 0.93539084, grad/param norm = 2.2969e-01, time/batch = 18.9761s	
21758/26050 (epoch 41.762), train_loss = 0.78894594, grad/param norm = 2.1479e-01, time/batch = 15.8725s	
21759/26050 (epoch 41.764), train_loss = 0.81241164, grad/param norm = 2.4747e-01, time/batch = 18.3949s	
21760/26050 (epoch 41.766), train_loss = 0.81368033, grad/param norm = 2.4778e-01, time/batch = 17.9853s	
21761/26050 (epoch 41.768), train_loss = 0.70378629, grad/param norm = 1.9872e-01, time/batch = 18.3892s	
21762/26050 (epoch 41.770), train_loss = 0.80992481, grad/param norm = 2.3980e-01, time/batch = 18.3917s	
21763/26050 (epoch 41.772), train_loss = 0.82568538, grad/param norm = 2.7145e-01, time/batch = 17.8270s	
21764/26050 (epoch 41.774), train_loss = 0.69458835, grad/param norm = 2.1616e-01, time/batch = 17.7304s	
21765/26050 (epoch 41.775), train_loss = 0.59648863, grad/param norm = 2.3675e-01, time/batch = 16.6320s	
21766/26050 (epoch 41.777), train_loss = 0.76945351, grad/param norm = 2.1058e-01, time/batch = 18.7187s	
21767/26050 (epoch 41.779), train_loss = 0.80594868, grad/param norm = 3.0306e-01, time/batch = 18.7216s	
21768/26050 (epoch 41.781), train_loss = 0.72305906, grad/param norm = 2.0679e-01, time/batch = 17.7381s	
21769/26050 (epoch 41.783), train_loss = 0.71167310, grad/param norm = 2.2616e-01, time/batch = 50.9745s	
21770/26050 (epoch 41.785), train_loss = 0.80733188, grad/param norm = 2.3697e-01, time/batch = 31.8574s	
21771/26050 (epoch 41.787), train_loss = 0.72728227, grad/param norm = 2.2888e-01, time/batch = 18.7975s	
21772/26050 (epoch 41.789), train_loss = 0.74245093, grad/param norm = 2.4430e-01, time/batch = 16.3706s	
21773/26050 (epoch 41.791), train_loss = 0.74360995, grad/param norm = 2.4706e-01, time/batch = 14.8937s	
21774/26050 (epoch 41.793), train_loss = 0.79873303, grad/param norm = 2.1566e-01, time/batch = 17.8242s	
21775/26050 (epoch 41.795), train_loss = 0.66558436, grad/param norm = 2.2011e-01, time/batch = 18.9762s	
21776/26050 (epoch 41.797), train_loss = 0.72300552, grad/param norm = 2.1862e-01, time/batch = 18.2990s	
21777/26050 (epoch 41.798), train_loss = 0.78476590, grad/param norm = 2.5539e-01, time/batch = 18.3203s	
21778/26050 (epoch 41.800), train_loss = 0.67888835, grad/param norm = 2.2100e-01, time/batch = 17.8976s	
21779/26050 (epoch 41.802), train_loss = 0.77410934, grad/param norm = 2.2861e-01, time/batch = 16.8144s	
21780/26050 (epoch 41.804), train_loss = 0.80631363, grad/param norm = 2.3541e-01, time/batch = 18.4879s	
21781/26050 (epoch 41.806), train_loss = 0.87866213, grad/param norm = 2.7042e-01, time/batch = 18.4065s	
21782/26050 (epoch 41.808), train_loss = 0.81337568, grad/param norm = 2.1253e-01, time/batch = 17.0611s	
21783/26050 (epoch 41.810), train_loss = 0.78879615, grad/param norm = 2.0775e-01, time/batch = 16.2229s	
21784/26050 (epoch 41.812), train_loss = 0.66801417, grad/param norm = 2.1731e-01, time/batch = 16.7109s	
21785/26050 (epoch 41.814), train_loss = 0.70469708, grad/param norm = 2.0925e-01, time/batch = 16.8754s	
21786/26050 (epoch 41.816), train_loss = 0.83681437, grad/param norm = 2.3674e-01, time/batch = 16.5599s	
21787/26050 (epoch 41.818), train_loss = 0.87686440, grad/param norm = 2.3754e-01, time/batch = 17.7998s	
21788/26050 (epoch 41.820), train_loss = 0.80500148, grad/param norm = 2.1427e-01, time/batch = 18.1570s	
21789/26050 (epoch 41.821), train_loss = 0.89855419, grad/param norm = 2.7277e-01, time/batch = 18.1577s	
21790/26050 (epoch 41.823), train_loss = 0.99930718, grad/param norm = 2.2789e-01, time/batch = 18.2422s	
21791/26050 (epoch 41.825), train_loss = 0.79204004, grad/param norm = 2.2749e-01, time/batch = 17.8243s	
21792/26050 (epoch 41.827), train_loss = 0.79286457, grad/param norm = 2.6461e-01, time/batch = 16.8758s	
21793/26050 (epoch 41.829), train_loss = 0.90741787, grad/param norm = 2.6150e-01, time/batch = 18.5331s	
21794/26050 (epoch 41.831), train_loss = 0.94640545, grad/param norm = 2.2619e-01, time/batch = 15.2981s	
21795/26050 (epoch 41.833), train_loss = 0.90163862, grad/param norm = 2.3833e-01, time/batch = 18.4037s	
21796/26050 (epoch 41.835), train_loss = 0.93344430, grad/param norm = 2.5969e-01, time/batch = 17.3220s	
21797/26050 (epoch 41.837), train_loss = 0.84988287, grad/param norm = 1.9795e-01, time/batch = 18.5722s	
21798/26050 (epoch 41.839), train_loss = 0.79352952, grad/param norm = 2.5633e-01, time/batch = 18.2397s	
21799/26050 (epoch 41.841), train_loss = 0.86728292, grad/param norm = 2.4572e-01, time/batch = 17.4841s	
21800/26050 (epoch 41.843), train_loss = 0.79691549, grad/param norm = 2.0620e-01, time/batch = 18.3204s	
21801/26050 (epoch 41.845), train_loss = 0.74536334, grad/param norm = 1.8623e-01, time/batch = 17.4016s	
21802/26050 (epoch 41.846), train_loss = 0.84552907, grad/param norm = 2.1080e-01, time/batch = 14.9474s	
21803/26050 (epoch 41.848), train_loss = 0.78986532, grad/param norm = 2.3134e-01, time/batch = 15.8816s	
21804/26050 (epoch 41.850), train_loss = 0.71593176, grad/param norm = 1.8686e-01, time/batch = 18.2304s	
21805/26050 (epoch 41.852), train_loss = 0.82440309, grad/param norm = 2.0383e-01, time/batch = 17.5823s	
21806/26050 (epoch 41.854), train_loss = 0.81176523, grad/param norm = 2.2077e-01, time/batch = 16.3655s	
21807/26050 (epoch 41.856), train_loss = 0.76856016, grad/param norm = 2.2542e-01, time/batch = 17.4817s	
21808/26050 (epoch 41.858), train_loss = 0.72763208, grad/param norm = 2.0752e-01, time/batch = 14.8112s	
21809/26050 (epoch 41.860), train_loss = 0.84582377, grad/param norm = 2.6854e-01, time/batch = 18.5489s	
21810/26050 (epoch 41.862), train_loss = 0.88488233, grad/param norm = 1.9718e-01, time/batch = 17.2191s	
21811/26050 (epoch 41.864), train_loss = 0.79428010, grad/param norm = 2.6730e-01, time/batch = 17.5819s	
21812/26050 (epoch 41.866), train_loss = 0.79515016, grad/param norm = 2.1404e-01, time/batch = 18.5700s	
21813/26050 (epoch 41.868), train_loss = 0.86207902, grad/param norm = 2.5800e-01, time/batch = 16.2948s	
21814/26050 (epoch 41.869), train_loss = 0.74835223, grad/param norm = 2.0995e-01, time/batch = 14.9626s	
21815/26050 (epoch 41.871), train_loss = 0.70097351, grad/param norm = 2.0793e-01, time/batch = 17.9675s	
21816/26050 (epoch 41.873), train_loss = 0.86514943, grad/param norm = 2.4408e-01, time/batch = 18.1487s	
21817/26050 (epoch 41.875), train_loss = 0.75506531, grad/param norm = 2.3762e-01, time/batch = 16.3735s	
21818/26050 (epoch 41.877), train_loss = 0.76454334, grad/param norm = 2.1092e-01, time/batch = 17.1234s	
21819/26050 (epoch 41.879), train_loss = 0.85440180, grad/param norm = 2.0717e-01, time/batch = 17.8651s	
21820/26050 (epoch 41.881), train_loss = 0.89108428, grad/param norm = 2.7118e-01, time/batch = 17.3160s	
21821/26050 (epoch 41.883), train_loss = 0.86747477, grad/param norm = 2.2493e-01, time/batch = 17.8879s	
21822/26050 (epoch 41.885), train_loss = 0.62816995, grad/param norm = 1.9903e-01, time/batch = 17.8110s	
21823/26050 (epoch 41.887), train_loss = 0.88861789, grad/param norm = 2.2488e-01, time/batch = 18.9106s	
21824/26050 (epoch 41.889), train_loss = 0.73972179, grad/param norm = 2.1954e-01, time/batch = 18.7204s	
21825/26050 (epoch 41.891), train_loss = 0.68078251, grad/param norm = 2.0538e-01, time/batch = 17.3077s	
21826/26050 (epoch 41.893), train_loss = 0.68615337, grad/param norm = 1.9974e-01, time/batch = 17.5599s	
21827/26050 (epoch 41.894), train_loss = 0.75344237, grad/param norm = 2.2430e-01, time/batch = 17.3989s	
21828/26050 (epoch 41.896), train_loss = 0.87571114, grad/param norm = 2.6125e-01, time/batch = 16.1975s	
21829/26050 (epoch 41.898), train_loss = 0.74850202, grad/param norm = 2.0394e-01, time/batch = 16.9857s	
21830/26050 (epoch 41.900), train_loss = 0.85551434, grad/param norm = 2.9600e-01, time/batch = 18.4022s	
21831/26050 (epoch 41.902), train_loss = 0.77026019, grad/param norm = 2.5100e-01, time/batch = 17.1413s	
21832/26050 (epoch 41.904), train_loss = 0.78254544, grad/param norm = 2.5297e-01, time/batch = 18.9721s	
21833/26050 (epoch 41.906), train_loss = 0.76870523, grad/param norm = 2.8363e-01, time/batch = 17.6608s	
21834/26050 (epoch 41.908), train_loss = 0.82487884, grad/param norm = 2.1701e-01, time/batch = 17.3179s	
21835/26050 (epoch 41.910), train_loss = 0.73936149, grad/param norm = 2.0312e-01, time/batch = 15.2064s	
21836/26050 (epoch 41.912), train_loss = 0.97944480, grad/param norm = 2.5401e-01, time/batch = 17.9796s	
21837/26050 (epoch 41.914), train_loss = 1.08838111, grad/param norm = 2.6275e-01, time/batch = 14.3046s	
21838/26050 (epoch 41.916), train_loss = 0.87236054, grad/param norm = 3.0037e-01, time/batch = 17.3857s	
21839/26050 (epoch 41.917), train_loss = 0.83062726, grad/param norm = 2.4580e-01, time/batch = 18.6517s	
21840/26050 (epoch 41.919), train_loss = 0.85520561, grad/param norm = 2.5649e-01, time/batch = 19.0639s	
21841/26050 (epoch 41.921), train_loss = 0.75736414, grad/param norm = 2.1263e-01, time/batch = 14.5618s	
21842/26050 (epoch 41.923), train_loss = 0.83512715, grad/param norm = 2.2280e-01, time/batch = 18.3259s	
21843/26050 (epoch 41.925), train_loss = 0.80578973, grad/param norm = 2.0954e-01, time/batch = 17.6603s	
21844/26050 (epoch 41.927), train_loss = 0.75118090, grad/param norm = 1.8215e-01, time/batch = 17.8021s	
21845/26050 (epoch 41.929), train_loss = 0.67547280, grad/param norm = 1.9780e-01, time/batch = 18.3895s	
21846/26050 (epoch 41.931), train_loss = 0.95799847, grad/param norm = 2.9805e-01, time/batch = 18.7379s	
21847/26050 (epoch 41.933), train_loss = 0.80478880, grad/param norm = 2.1912e-01, time/batch = 17.6464s	
21848/26050 (epoch 41.935), train_loss = 0.77406389, grad/param norm = 2.2222e-01, time/batch = 14.9613s	
21849/26050 (epoch 41.937), train_loss = 0.86949678, grad/param norm = 2.0189e-01, time/batch = 17.8276s	
21850/26050 (epoch 41.939), train_loss = 0.74324259, grad/param norm = 1.9943e-01, time/batch = 18.2422s	
21851/26050 (epoch 41.940), train_loss = 0.81387512, grad/param norm = 2.1485e-01, time/batch = 16.1272s	
21852/26050 (epoch 41.942), train_loss = 0.76902740, grad/param norm = 2.4513e-01, time/batch = 16.8737s	
21853/26050 (epoch 41.944), train_loss = 0.79349830, grad/param norm = 2.3759e-01, time/batch = 17.8102s	
21854/26050 (epoch 41.946), train_loss = 0.95604262, grad/param norm = 2.2568e-01, time/batch = 18.3188s	
21855/26050 (epoch 41.948), train_loss = 0.69321414, grad/param norm = 2.0886e-01, time/batch = 18.1489s	
21856/26050 (epoch 41.950), train_loss = 0.83028874, grad/param norm = 2.2809e-01, time/batch = 16.6492s	
21857/26050 (epoch 41.952), train_loss = 0.85469946, grad/param norm = 2.3563e-01, time/batch = 17.8917s	
21858/26050 (epoch 41.954), train_loss = 0.88216120, grad/param norm = 2.2973e-01, time/batch = 16.1353s	
21859/26050 (epoch 41.956), train_loss = 0.76037959, grad/param norm = 2.0294e-01, time/batch = 17.4763s	
21860/26050 (epoch 41.958), train_loss = 0.74036866, grad/param norm = 2.0460e-01, time/batch = 17.8943s	
21861/26050 (epoch 41.960), train_loss = 0.84341032, grad/param norm = 2.2266e-01, time/batch = 18.0481s	
21862/26050 (epoch 41.962), train_loss = 0.80474144, grad/param norm = 1.9838e-01, time/batch = 17.1729s	
21863/26050 (epoch 41.964), train_loss = 0.76535862, grad/param norm = 2.0760e-01, time/batch = 18.3290s	
21864/26050 (epoch 41.965), train_loss = 0.74254148, grad/param norm = 2.4506e-01, time/batch = 18.9078s	
21865/26050 (epoch 41.967), train_loss = 1.05980112, grad/param norm = 2.3618e-01, time/batch = 17.9747s	
21866/26050 (epoch 41.969), train_loss = 0.81394437, grad/param norm = 2.2392e-01, time/batch = 18.4778s	
21867/26050 (epoch 41.971), train_loss = 0.82396246, grad/param norm = 2.1238e-01, time/batch = 18.3999s	
21868/26050 (epoch 41.973), train_loss = 0.82421392, grad/param norm = 2.1704e-01, time/batch = 17.0606s	
21869/26050 (epoch 41.975), train_loss = 0.82142702, grad/param norm = 2.0901e-01, time/batch = 17.3165s	
21870/26050 (epoch 41.977), train_loss = 0.80149095, grad/param norm = 2.0218e-01, time/batch = 17.3038s	
21871/26050 (epoch 41.979), train_loss = 0.66418830, grad/param norm = 2.0248e-01, time/batch = 18.1470s	
21872/26050 (epoch 41.981), train_loss = 0.89720144, grad/param norm = 2.0915e-01, time/batch = 16.9758s	
21873/26050 (epoch 41.983), train_loss = 0.85295962, grad/param norm = 2.0683e-01, time/batch = 15.8980s	
21874/26050 (epoch 41.985), train_loss = 0.84000329, grad/param norm = 2.3304e-01, time/batch = 18.4075s	
21875/26050 (epoch 41.987), train_loss = 0.91456637, grad/param norm = 2.2223e-01, time/batch = 17.8984s	
21876/26050 (epoch 41.988), train_loss = 0.85383689, grad/param norm = 2.7193e-01, time/batch = 16.2181s	
21877/26050 (epoch 41.990), train_loss = 0.69294469, grad/param norm = 1.9370e-01, time/batch = 16.3869s	
21878/26050 (epoch 41.992), train_loss = 0.93665593, grad/param norm = 2.2295e-01, time/batch = 18.3923s	
21879/26050 (epoch 41.994), train_loss = 0.74692647, grad/param norm = 2.1270e-01, time/batch = 18.0379s	
21880/26050 (epoch 41.996), train_loss = 0.72672681, grad/param norm = 2.5863e-01, time/batch = 18.6414s	
21881/26050 (epoch 41.998), train_loss = 0.82792065, grad/param norm = 2.2874e-01, time/batch = 18.3115s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
21882/26050 (epoch 42.000), train_loss = 0.75041055, grad/param norm = 2.2035e-01, time/batch = 17.4013s	
21883/26050 (epoch 42.002), train_loss = 0.86578017, grad/param norm = 2.3507e-01, time/batch = 17.0578s	
21884/26050 (epoch 42.004), train_loss = 0.71849031, grad/param norm = 2.1060e-01, time/batch = 18.2388s	
21885/26050 (epoch 42.006), train_loss = 0.76182207, grad/param norm = 2.4616e-01, time/batch = 17.3995s	
21886/26050 (epoch 42.008), train_loss = 0.75214471, grad/param norm = 2.3258e-01, time/batch = 17.8058s	
21887/26050 (epoch 42.010), train_loss = 0.74577233, grad/param norm = 2.2576e-01, time/batch = 18.0537s	
21888/26050 (epoch 42.012), train_loss = 0.79447046, grad/param norm = 2.1136e-01, time/batch = 17.7358s	
21889/26050 (epoch 42.013), train_loss = 1.00864299, grad/param norm = 2.5633e-01, time/batch = 15.4872s	
21890/26050 (epoch 42.015), train_loss = 0.81490169, grad/param norm = 2.3143e-01, time/batch = 16.7945s	
21891/26050 (epoch 42.017), train_loss = 0.83180495, grad/param norm = 1.9432e-01, time/batch = 15.1424s	
21892/26050 (epoch 42.019), train_loss = 0.70117383, grad/param norm = 1.6635e-01, time/batch = 14.7006s	
21893/26050 (epoch 42.021), train_loss = 0.87385647, grad/param norm = 2.1318e-01, time/batch = 16.7341s	
21894/26050 (epoch 42.023), train_loss = 0.66896180, grad/param norm = 2.0807e-01, time/batch = 18.5607s	
21895/26050 (epoch 42.025), train_loss = 0.80385760, grad/param norm = 2.1747e-01, time/batch = 18.1564s	
21896/26050 (epoch 42.027), train_loss = 0.64461065, grad/param norm = 1.9181e-01, time/batch = 17.3946s	
21897/26050 (epoch 42.029), train_loss = 0.85139892, grad/param norm = 1.9253e-01, time/batch = 18.2163s	
21898/26050 (epoch 42.031), train_loss = 0.91943248, grad/param norm = 2.7633e-01, time/batch = 18.0487s	
21899/26050 (epoch 42.033), train_loss = 0.80082781, grad/param norm = 2.0345e-01, time/batch = 17.6500s	
21900/26050 (epoch 42.035), train_loss = 0.83190602, grad/param norm = 1.9040e-01, time/batch = 17.5698s	
21901/26050 (epoch 42.036), train_loss = 0.70702895, grad/param norm = 2.2640e-01, time/batch = 18.4060s	
21902/26050 (epoch 42.038), train_loss = 0.65344585, grad/param norm = 1.9751e-01, time/batch = 14.9735s	
21903/26050 (epoch 42.040), train_loss = 0.77498864, grad/param norm = 2.0430e-01, time/batch = 17.9950s	
21904/26050 (epoch 42.042), train_loss = 0.69355919, grad/param norm = 2.1921e-01, time/batch = 17.8157s	
21905/26050 (epoch 42.044), train_loss = 0.86716215, grad/param norm = 1.9703e-01, time/batch = 18.8115s	
21906/26050 (epoch 42.046), train_loss = 0.67029026, grad/param norm = 1.7034e-01, time/batch = 15.7156s	
21907/26050 (epoch 42.048), train_loss = 0.78871376, grad/param norm = 2.0797e-01, time/batch = 16.7847s	
21908/26050 (epoch 42.050), train_loss = 0.75797706, grad/param norm = 2.1038e-01, time/batch = 18.3947s	
21909/26050 (epoch 42.052), train_loss = 0.75250321, grad/param norm = 2.4428e-01, time/batch = 17.2383s	
21910/26050 (epoch 42.054), train_loss = 0.67073228, grad/param norm = 1.8350e-01, time/batch = 18.6499s	
21911/26050 (epoch 42.056), train_loss = 0.66056423, grad/param norm = 1.7108e-01, time/batch = 15.2989s	
21912/26050 (epoch 42.058), train_loss = 0.77261031, grad/param norm = 1.9535e-01, time/batch = 18.0652s	
21913/26050 (epoch 42.060), train_loss = 0.83584137, grad/param norm = 1.9716e-01, time/batch = 17.8917s	
21914/26050 (epoch 42.061), train_loss = 0.68352075, grad/param norm = 2.0310e-01, time/batch = 18.2294s	
21915/26050 (epoch 42.063), train_loss = 0.79294899, grad/param norm = 2.4860e-01, time/batch = 14.3769s	
21916/26050 (epoch 42.065), train_loss = 0.64859060, grad/param norm = 1.8664e-01, time/batch = 17.8958s	
21917/26050 (epoch 42.067), train_loss = 0.79297859, grad/param norm = 2.3395e-01, time/batch = 18.4766s	
21918/26050 (epoch 42.069), train_loss = 0.81776336, grad/param norm = 2.1323e-01, time/batch = 18.6374s	
21919/26050 (epoch 42.071), train_loss = 0.82723167, grad/param norm = 2.5662e-01, time/batch = 17.3845s	
21920/26050 (epoch 42.073), train_loss = 0.94653254, grad/param norm = 2.1248e-01, time/batch = 16.8835s	
21921/26050 (epoch 42.075), train_loss = 0.76406721, grad/param norm = 2.4178e-01, time/batch = 18.6657s	
21922/26050 (epoch 42.077), train_loss = 0.74961140, grad/param norm = 2.2709e-01, time/batch = 18.5530s	
21923/26050 (epoch 42.079), train_loss = 0.77960810, grad/param norm = 2.4725e-01, time/batch = 16.3153s	
21924/26050 (epoch 42.081), train_loss = 0.77187699, grad/param norm = 2.0830e-01, time/batch = 17.9772s	
21925/26050 (epoch 42.083), train_loss = 0.89167485, grad/param norm = 2.0330e-01, time/batch = 18.0738s	
21926/26050 (epoch 42.084), train_loss = 0.81334296, grad/param norm = 2.8955e-01, time/batch = 15.1963s	
21927/26050 (epoch 42.086), train_loss = 0.91794248, grad/param norm = 2.4527e-01, time/batch = 18.2162s	
21928/26050 (epoch 42.088), train_loss = 0.79700050, grad/param norm = 2.1349e-01, time/batch = 17.6655s	
21929/26050 (epoch 42.090), train_loss = 0.84246066, grad/param norm = 2.4459e-01, time/batch = 18.2381s	
21930/26050 (epoch 42.092), train_loss = 0.84919042, grad/param norm = 2.0411e-01, time/batch = 17.9679s	
21931/26050 (epoch 42.094), train_loss = 0.67891246, grad/param norm = 1.9549e-01, time/batch = 16.5580s	
21932/26050 (epoch 42.096), train_loss = 0.83025159, grad/param norm = 2.0471e-01, time/batch = 15.7314s	
21933/26050 (epoch 42.098), train_loss = 0.79034569, grad/param norm = 2.1069e-01, time/batch = 17.5714s	
21934/26050 (epoch 42.100), train_loss = 0.72384612, grad/param norm = 2.2642e-01, time/batch = 16.5544s	
21935/26050 (epoch 42.102), train_loss = 0.81769696, grad/param norm = 2.4966e-01, time/batch = 17.7198s	
21936/26050 (epoch 42.104), train_loss = 0.75010028, grad/param norm = 2.1239e-01, time/batch = 18.1614s	
21937/26050 (epoch 42.106), train_loss = 0.86324226, grad/param norm = 2.6848e-01, time/batch = 18.3852s	
21938/26050 (epoch 42.107), train_loss = 0.67207336, grad/param norm = 1.9446e-01, time/batch = 18.8921s	
21939/26050 (epoch 42.109), train_loss = 0.74125190, grad/param norm = 1.9372e-01, time/batch = 18.1397s	
21940/26050 (epoch 42.111), train_loss = 0.93948118, grad/param norm = 2.2725e-01, time/batch = 17.7261s	
21941/26050 (epoch 42.113), train_loss = 0.76808317, grad/param norm = 1.8300e-01, time/batch = 17.5659s	
21942/26050 (epoch 42.115), train_loss = 0.89051266, grad/param norm = 2.1919e-01, time/batch = 18.3968s	
21943/26050 (epoch 42.117), train_loss = 0.79166299, grad/param norm = 2.4412e-01, time/batch = 17.8940s	
21944/26050 (epoch 42.119), train_loss = 0.69156002, grad/param norm = 1.7598e-01, time/batch = 16.8852s	
21945/26050 (epoch 42.121), train_loss = 0.78964005, grad/param norm = 2.1492e-01, time/batch = 16.0516s	
21946/26050 (epoch 42.123), train_loss = 0.74555339, grad/param norm = 2.3502e-01, time/batch = 17.4617s	
21947/26050 (epoch 42.125), train_loss = 0.68263569, grad/param norm = 2.0280e-01, time/batch = 18.0446s	
21948/26050 (epoch 42.127), train_loss = 0.67776463, grad/param norm = 2.1338e-01, time/batch = 18.4789s	
21949/26050 (epoch 42.129), train_loss = 0.63639421, grad/param norm = 2.3177e-01, time/batch = 14.8056s	
21950/26050 (epoch 42.131), train_loss = 0.79524421, grad/param norm = 2.6203e-01, time/batch = 17.6566s	
21951/26050 (epoch 42.132), train_loss = 0.81221093, grad/param norm = 2.1270e-01, time/batch = 18.4836s	
21952/26050 (epoch 42.134), train_loss = 0.83191467, grad/param norm = 2.4655e-01, time/batch = 16.3109s	
21953/26050 (epoch 42.136), train_loss = 0.77555351, grad/param norm = 2.1062e-01, time/batch = 18.2193s	
21954/26050 (epoch 42.138), train_loss = 0.55707345, grad/param norm = 2.0717e-01, time/batch = 18.2995s	
21955/26050 (epoch 42.140), train_loss = 0.65156086, grad/param norm = 2.0495e-01, time/batch = 18.2365s	
21956/26050 (epoch 42.142), train_loss = 0.67491566, grad/param norm = 2.0371e-01, time/batch = 15.3834s	
21957/26050 (epoch 42.144), train_loss = 0.64849872, grad/param norm = 2.2134e-01, time/batch = 16.8006s	
21958/26050 (epoch 42.146), train_loss = 0.58248619, grad/param norm = 1.7565e-01, time/batch = 18.4826s	
21959/26050 (epoch 42.148), train_loss = 0.63497721, grad/param norm = 1.8149e-01, time/batch = 18.4827s	
21960/26050 (epoch 42.150), train_loss = 0.70572699, grad/param norm = 2.4220e-01, time/batch = 18.0618s	
21961/26050 (epoch 42.152), train_loss = 0.88545908, grad/param norm = 2.9636e-01, time/batch = 15.5594s	
21962/26050 (epoch 42.154), train_loss = 0.62363542, grad/param norm = 2.1751e-01, time/batch = 18.0559s	
21963/26050 (epoch 42.155), train_loss = 0.67445148, grad/param norm = 2.2476e-01, time/batch = 18.5658s	
21964/26050 (epoch 42.157), train_loss = 0.77020602, grad/param norm = 4.0406e-01, time/batch = 17.2003s	
21965/26050 (epoch 42.159), train_loss = 0.81068537, grad/param norm = 2.5168e-01, time/batch = 18.0693s	
21966/26050 (epoch 42.161), train_loss = 0.79197036, grad/param norm = 2.4588e-01, time/batch = 18.8179s	
21967/26050 (epoch 42.163), train_loss = 0.65729484, grad/param norm = 2.1280e-01, time/batch = 17.4893s	
21968/26050 (epoch 42.165), train_loss = 0.59400942, grad/param norm = 1.9510e-01, time/batch = 17.5767s	
21969/26050 (epoch 42.167), train_loss = 0.89473699, grad/param norm = 2.3083e-01, time/batch = 17.6300s	
21970/26050 (epoch 42.169), train_loss = 0.77296301, grad/param norm = 2.1549e-01, time/batch = 18.3103s	
21971/26050 (epoch 42.171), train_loss = 0.71380880, grad/param norm = 2.1398e-01, time/batch = 27.4397s	
21972/26050 (epoch 42.173), train_loss = 0.75463324, grad/param norm = 2.2645e-01, time/batch = 26.5381s	
21973/26050 (epoch 42.175), train_loss = 0.78024729, grad/param norm = 2.3622e-01, time/batch = 15.6694s	
21974/26050 (epoch 42.177), train_loss = 0.83554947, grad/param norm = 2.1342e-01, time/batch = 18.3886s	
21975/26050 (epoch 42.179), train_loss = 0.58958754, grad/param norm = 1.7756e-01, time/batch = 17.6628s	
21976/26050 (epoch 42.180), train_loss = 0.99683733, grad/param norm = 2.2266e-01, time/batch = 18.2366s	
21977/26050 (epoch 42.182), train_loss = 0.92709103, grad/param norm = 2.4364e-01, time/batch = 18.3192s	
21978/26050 (epoch 42.184), train_loss = 0.80357037, grad/param norm = 1.9663e-01, time/batch = 17.4902s	
21979/26050 (epoch 42.186), train_loss = 0.69232009, grad/param norm = 2.0394e-01, time/batch = 17.8115s	
21980/26050 (epoch 42.188), train_loss = 0.84038109, grad/param norm = 2.2663e-01, time/batch = 18.5441s	
21981/26050 (epoch 42.190), train_loss = 0.83522556, grad/param norm = 2.3767e-01, time/batch = 18.4761s	
21982/26050 (epoch 42.192), train_loss = 0.88217060, grad/param norm = 2.0329e-01, time/batch = 15.8957s	
21983/26050 (epoch 42.194), train_loss = 0.82050006, grad/param norm = 2.1898e-01, time/batch = 17.7088s	
21984/26050 (epoch 42.196), train_loss = 0.85639949, grad/param norm = 2.3673e-01, time/batch = 18.0451s	
21985/26050 (epoch 42.198), train_loss = 0.73025410, grad/param norm = 1.8903e-01, time/batch = 16.1609s	
21986/26050 (epoch 42.200), train_loss = 0.70300469, grad/param norm = 2.2594e-01, time/batch = 17.6317s	
21987/26050 (epoch 42.202), train_loss = 0.80392454, grad/param norm = 2.1637e-01, time/batch = 18.2311s	
21988/26050 (epoch 42.203), train_loss = 0.90787413, grad/param norm = 2.0193e-01, time/batch = 17.1618s	
21989/26050 (epoch 42.205), train_loss = 0.73775000, grad/param norm = 2.1662e-01, time/batch = 15.6534s	
21990/26050 (epoch 42.207), train_loss = 0.72356341, grad/param norm = 2.2332e-01, time/batch = 17.2935s	
21991/26050 (epoch 42.209), train_loss = 0.86668604, grad/param norm = 2.0474e-01, time/batch = 18.0641s	
21992/26050 (epoch 42.211), train_loss = 0.68611147, grad/param norm = 1.8434e-01, time/batch = 18.1457s	
21993/26050 (epoch 42.213), train_loss = 0.80562852, grad/param norm = 2.3163e-01, time/batch = 17.4815s	
21994/26050 (epoch 42.215), train_loss = 0.76901501, grad/param norm = 2.3435e-01, time/batch = 16.5548s	
21995/26050 (epoch 42.217), train_loss = 0.76731622, grad/param norm = 2.0803e-01, time/batch = 17.8191s	
21996/26050 (epoch 42.219), train_loss = 0.75208062, grad/param norm = 2.3241e-01, time/batch = 18.1511s	
21997/26050 (epoch 42.221), train_loss = 0.71220081, grad/param norm = 2.3355e-01, time/batch = 18.1534s	
21998/26050 (epoch 42.223), train_loss = 0.85069185, grad/param norm = 2.2676e-01, time/batch = 17.7414s	
21999/26050 (epoch 42.225), train_loss = 0.70076878, grad/param norm = 1.9896e-01, time/batch = 17.3763s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch42.23_1.9339.t7	
22000/26050 (epoch 42.226), train_loss = 0.79003456, grad/param norm = 2.1635e-01, time/batch = 15.4469s	
22001/26050 (epoch 42.228), train_loss = 1.54897450, grad/param norm = 3.1033e-01, time/batch = 18.4738s	
22002/26050 (epoch 42.230), train_loss = 0.79195405, grad/param norm = 2.0109e-01, time/batch = 18.8918s	
22003/26050 (epoch 42.232), train_loss = 0.88057021, grad/param norm = 2.5474e-01, time/batch = 18.9820s	
22004/26050 (epoch 42.234), train_loss = 0.69569297, grad/param norm = 2.1175e-01, time/batch = 15.2161s	
22005/26050 (epoch 42.236), train_loss = 0.85554047, grad/param norm = 2.2540e-01, time/batch = 18.7239s	
22006/26050 (epoch 42.238), train_loss = 0.71152559, grad/param norm = 2.3668e-01, time/batch = 18.4024s	
22007/26050 (epoch 42.240), train_loss = 0.79906720, grad/param norm = 2.1575e-01, time/batch = 16.9391s	
22008/26050 (epoch 42.242), train_loss = 0.77217972, grad/param norm = 2.3342e-01, time/batch = 18.3074s	
22009/26050 (epoch 42.244), train_loss = 0.81401486, grad/param norm = 2.7241e-01, time/batch = 18.6493s	
22010/26050 (epoch 42.246), train_loss = 0.75507589, grad/param norm = 2.4055e-01, time/batch = 17.5463s	
22011/26050 (epoch 42.248), train_loss = 0.80388080, grad/param norm = 2.3137e-01, time/batch = 15.2849s	
22012/26050 (epoch 42.250), train_loss = 0.81796785, grad/param norm = 2.6019e-01, time/batch = 18.5738s	
22013/26050 (epoch 42.251), train_loss = 0.75091077, grad/param norm = 2.3145e-01, time/batch = 18.3900s	
22014/26050 (epoch 42.253), train_loss = 0.66223564, grad/param norm = 1.8977e-01, time/batch = 16.9754s	
22015/26050 (epoch 42.255), train_loss = 0.97098510, grad/param norm = 2.7512e-01, time/batch = 18.5709s	
22016/26050 (epoch 42.257), train_loss = 0.82407629, grad/param norm = 2.5730e-01, time/batch = 17.6602s	
22017/26050 (epoch 42.259), train_loss = 0.88713457, grad/param norm = 2.4545e-01, time/batch = 18.0729s	
22018/26050 (epoch 42.261), train_loss = 0.71395266, grad/param norm = 2.1958e-01, time/batch = 17.4893s	
22019/26050 (epoch 42.263), train_loss = 0.87471126, grad/param norm = 2.3625e-01, time/batch = 17.9633s	
22020/26050 (epoch 42.265), train_loss = 0.88739155, grad/param norm = 2.3406e-01, time/batch = 17.7220s	
22021/26050 (epoch 42.267), train_loss = 0.91739564, grad/param norm = 2.1646e-01, time/batch = 18.3104s	
22022/26050 (epoch 42.269), train_loss = 0.89799760, grad/param norm = 2.2040e-01, time/batch = 17.6544s	
22023/26050 (epoch 42.271), train_loss = 0.79671194, grad/param norm = 2.0694e-01, time/batch = 15.4733s	
22024/26050 (epoch 42.273), train_loss = 0.71759951, grad/param norm = 2.6599e-01, time/batch = 17.6384s	
22025/26050 (epoch 42.274), train_loss = 0.77248043, grad/param norm = 1.9180e-01, time/batch = 18.6600s	
22026/26050 (epoch 42.276), train_loss = 0.76526045, grad/param norm = 2.2143e-01, time/batch = 18.2180s	
22027/26050 (epoch 42.278), train_loss = 0.87020471, grad/param norm = 2.0157e-01, time/batch = 17.6208s	
22028/26050 (epoch 42.280), train_loss = 0.77508481, grad/param norm = 1.9587e-01, time/batch = 18.4846s	
22029/26050 (epoch 42.282), train_loss = 0.86739455, grad/param norm = 2.1900e-01, time/batch = 17.8909s	
22030/26050 (epoch 42.284), train_loss = 0.79838411, grad/param norm = 2.2075e-01, time/batch = 18.7943s	
22031/26050 (epoch 42.286), train_loss = 0.83533291, grad/param norm = 2.2521e-01, time/batch = 18.3115s	
22032/26050 (epoch 42.288), train_loss = 0.67979026, grad/param norm = 1.7793e-01, time/batch = 18.2294s	
22033/26050 (epoch 42.290), train_loss = 0.79236599, grad/param norm = 2.1575e-01, time/batch = 15.2814s	
22034/26050 (epoch 42.292), train_loss = 0.72941394, grad/param norm = 1.9627e-01, time/batch = 17.6427s	
22035/26050 (epoch 42.294), train_loss = 0.79994727, grad/param norm = 2.4269e-01, time/batch = 17.7464s	
22036/26050 (epoch 42.296), train_loss = 0.86860525, grad/param norm = 2.2401e-01, time/batch = 18.3195s	
22037/26050 (epoch 42.298), train_loss = 0.83601546, grad/param norm = 2.1727e-01, time/batch = 17.8181s	
22038/26050 (epoch 42.299), train_loss = 0.68139327, grad/param norm = 2.1737e-01, time/batch = 18.2343s	
22039/26050 (epoch 42.301), train_loss = 0.67367761, grad/param norm = 1.9217e-01, time/batch = 18.3129s	
22040/26050 (epoch 42.303), train_loss = 0.79343590, grad/param norm = 2.0846e-01, time/batch = 17.2120s	
22041/26050 (epoch 42.305), train_loss = 0.64325638, grad/param norm = 1.9891e-01, time/batch = 17.6357s	
22042/26050 (epoch 42.307), train_loss = 0.71140959, grad/param norm = 2.2797e-01, time/batch = 15.2257s	
22043/26050 (epoch 42.309), train_loss = 0.83312363, grad/param norm = 2.2842e-01, time/batch = 18.6385s	
22044/26050 (epoch 42.311), train_loss = 0.79842498, grad/param norm = 2.6300e-01, time/batch = 17.4830s	
22045/26050 (epoch 42.313), train_loss = 0.78621158, grad/param norm = 2.2402e-01, time/batch = 17.6489s	
22046/26050 (epoch 42.315), train_loss = 0.84456249, grad/param norm = 2.0370e-01, time/batch = 14.9826s	
22047/26050 (epoch 42.317), train_loss = 0.79475482, grad/param norm = 2.4271e-01, time/batch = 18.9056s	
22048/26050 (epoch 42.319), train_loss = 0.74162505, grad/param norm = 2.2332e-01, time/batch = 17.4724s	
22049/26050 (epoch 42.321), train_loss = 0.78886660, grad/param norm = 2.0741e-01, time/batch = 14.6348s	
22050/26050 (epoch 42.322), train_loss = 0.85478906, grad/param norm = 2.1925e-01, time/batch = 17.9704s	
22051/26050 (epoch 42.324), train_loss = 0.63390066, grad/param norm = 2.1033e-01, time/batch = 18.2936s	
22052/26050 (epoch 42.326), train_loss = 0.90475165, grad/param norm = 2.4344e-01, time/batch = 18.8901s	
22053/26050 (epoch 42.328), train_loss = 0.83071412, grad/param norm = 2.1325e-01, time/batch = 18.2462s	
22054/26050 (epoch 42.330), train_loss = 0.70098471, grad/param norm = 2.2639e-01, time/batch = 17.5532s	
22055/26050 (epoch 42.332), train_loss = 0.84424520, grad/param norm = 2.2094e-01, time/batch = 15.1352s	
22056/26050 (epoch 42.334), train_loss = 0.70794456, grad/param norm = 2.0846e-01, time/batch = 18.2343s	
22057/26050 (epoch 42.336), train_loss = 0.75514850, grad/param norm = 2.1840e-01, time/batch = 18.5570s	
22058/26050 (epoch 42.338), train_loss = 0.68941070, grad/param norm = 1.9041e-01, time/batch = 17.8073s	
22059/26050 (epoch 42.340), train_loss = 0.82643484, grad/param norm = 2.0488e-01, time/batch = 17.4578s	
22060/26050 (epoch 42.342), train_loss = 0.88392201, grad/param norm = 2.4324e-01, time/batch = 17.9052s	
22061/26050 (epoch 42.344), train_loss = 0.72985468, grad/param norm = 2.2737e-01, time/batch = 18.3069s	
22062/26050 (epoch 42.345), train_loss = 0.77287971, grad/param norm = 2.2679e-01, time/batch = 18.8069s	
22063/26050 (epoch 42.347), train_loss = 0.90068381, grad/param norm = 2.3747e-01, time/batch = 17.1509s	
22064/26050 (epoch 42.349), train_loss = 0.84731555, grad/param norm = 2.2850e-01, time/batch = 16.8064s	
22065/26050 (epoch 42.351), train_loss = 0.81038567, grad/param norm = 2.3430e-01, time/batch = 17.4710s	
22066/26050 (epoch 42.353), train_loss = 0.79493117, grad/param norm = 2.3321e-01, time/batch = 16.7331s	
22067/26050 (epoch 42.355), train_loss = 0.80529313, grad/param norm = 2.9497e-01, time/batch = 14.6471s	
22068/26050 (epoch 42.357), train_loss = 0.75417117, grad/param norm = 2.2571e-01, time/batch = 17.6556s	
22069/26050 (epoch 42.359), train_loss = 0.88766086, grad/param norm = 2.2670e-01, time/batch = 17.6483s	
22070/26050 (epoch 42.361), train_loss = 0.71445007, grad/param norm = 1.8689e-01, time/batch = 18.0607s	
22071/26050 (epoch 42.363), train_loss = 0.87722354, grad/param norm = 2.2347e-01, time/batch = 17.6447s	
22072/26050 (epoch 42.365), train_loss = 0.77815549, grad/param norm = 2.2851e-01, time/batch = 18.5437s	
22073/26050 (epoch 42.367), train_loss = 0.84302613, grad/param norm = 2.1586e-01, time/batch = 17.9087s	
22074/26050 (epoch 42.369), train_loss = 0.70957878, grad/param norm = 2.0298e-01, time/batch = 18.8072s	
22075/26050 (epoch 42.370), train_loss = 0.69739658, grad/param norm = 1.9258e-01, time/batch = 14.3901s	
22076/26050 (epoch 42.372), train_loss = 0.77344616, grad/param norm = 2.1612e-01, time/batch = 18.1389s	
22077/26050 (epoch 42.374), train_loss = 0.90289091, grad/param norm = 2.2813e-01, time/batch = 18.2271s	
22078/26050 (epoch 42.376), train_loss = 0.89576371, grad/param norm = 2.3518e-01, time/batch = 17.3868s	
22079/26050 (epoch 42.378), train_loss = 0.75777629, grad/param norm = 1.8802e-01, time/batch = 18.3038s	
22080/26050 (epoch 42.380), train_loss = 0.90781081, grad/param norm = 2.7695e-01, time/batch = 16.2728s	
22081/26050 (epoch 42.382), train_loss = 0.96726569, grad/param norm = 2.3069e-01, time/batch = 17.6568s	
22082/26050 (epoch 42.384), train_loss = 0.76467747, grad/param norm = 2.2464e-01, time/batch = 11.5522s	
22083/26050 (epoch 42.386), train_loss = 0.86377782, grad/param norm = 2.4253e-01, time/batch = 0.6428s	
22084/26050 (epoch 42.388), train_loss = 0.81978823, grad/param norm = 2.1839e-01, time/batch = 0.6407s	
22085/26050 (epoch 42.390), train_loss = 0.73454284, grad/param norm = 1.7765e-01, time/batch = 0.6411s	
22086/26050 (epoch 42.392), train_loss = 0.68371429, grad/param norm = 1.9741e-01, time/batch = 0.6431s	
22087/26050 (epoch 42.393), train_loss = 0.86565112, grad/param norm = 2.3171e-01, time/batch = 0.6386s	
22088/26050 (epoch 42.395), train_loss = 0.85163962, grad/param norm = 2.2366e-01, time/batch = 0.6410s	
22089/26050 (epoch 42.397), train_loss = 0.85045083, grad/param norm = 2.4073e-01, time/batch = 0.6377s	
22090/26050 (epoch 42.399), train_loss = 0.76607701, grad/param norm = 2.3520e-01, time/batch = 0.8256s	
22091/26050 (epoch 42.401), train_loss = 0.79890764, grad/param norm = 2.0871e-01, time/batch = 0.9886s	
22092/26050 (epoch 42.403), train_loss = 0.81231384, grad/param norm = 2.6839e-01, time/batch = 0.9405s	
22093/26050 (epoch 42.405), train_loss = 0.80828210, grad/param norm = 2.1521e-01, time/batch = 0.9411s	
22094/26050 (epoch 42.407), train_loss = 0.92161282, grad/param norm = 2.4607e-01, time/batch = 0.9410s	
22095/26050 (epoch 42.409), train_loss = 0.91208914, grad/param norm = 2.5157e-01, time/batch = 1.2450s	
22096/26050 (epoch 42.411), train_loss = 0.88738280, grad/param norm = 2.1313e-01, time/batch = 1.7965s	
22097/26050 (epoch 42.413), train_loss = 0.98474573, grad/param norm = 2.4141e-01, time/batch = 1.7693s	
22098/26050 (epoch 42.415), train_loss = 0.97664520, grad/param norm = 2.4844e-01, time/batch = 11.3770s	
22099/26050 (epoch 42.417), train_loss = 0.96288070, grad/param norm = 2.4106e-01, time/batch = 17.5648s	
22100/26050 (epoch 42.418), train_loss = 0.86880308, grad/param norm = 2.5609e-01, time/batch = 16.2965s	
22101/26050 (epoch 42.420), train_loss = 0.71292003, grad/param norm = 2.2481e-01, time/batch = 18.8077s	
22102/26050 (epoch 42.422), train_loss = 0.68450016, grad/param norm = 1.9733e-01, time/batch = 18.6614s	
22103/26050 (epoch 42.424), train_loss = 0.89831366, grad/param norm = 2.3102e-01, time/batch = 17.8945s	
22104/26050 (epoch 42.426), train_loss = 0.84989608, grad/param norm = 2.6069e-01, time/batch = 18.4841s	
22105/26050 (epoch 42.428), train_loss = 0.79320010, grad/param norm = 2.2254e-01, time/batch = 18.3988s	
22106/26050 (epoch 42.430), train_loss = 0.94992619, grad/param norm = 2.2288e-01, time/batch = 15.3678s	
22107/26050 (epoch 42.432), train_loss = 0.78011430, grad/param norm = 2.1265e-01, time/batch = 17.1467s	
22108/26050 (epoch 42.434), train_loss = 0.77647162, grad/param norm = 2.8948e-01, time/batch = 17.7276s	
22109/26050 (epoch 42.436), train_loss = 0.88245538, grad/param norm = 2.2824e-01, time/batch = 18.6556s	
22110/26050 (epoch 42.438), train_loss = 0.83758481, grad/param norm = 2.3142e-01, time/batch = 18.0686s	
22111/26050 (epoch 42.440), train_loss = 0.84612706, grad/param norm = 2.1257e-01, time/batch = 18.4893s	
22112/26050 (epoch 42.441), train_loss = 0.84344980, grad/param norm = 2.1045e-01, time/batch = 18.2373s	
22113/26050 (epoch 42.443), train_loss = 0.71196963, grad/param norm = 1.8002e-01, time/batch = 17.8986s	
22114/26050 (epoch 42.445), train_loss = 0.73120801, grad/param norm = 2.4527e-01, time/batch = 16.5755s	
22115/26050 (epoch 42.447), train_loss = 0.94979057, grad/param norm = 2.2961e-01, time/batch = 16.3653s	
22116/26050 (epoch 42.449), train_loss = 0.72874669, grad/param norm = 2.0708e-01, time/batch = 18.0497s	
22117/26050 (epoch 42.451), train_loss = 0.94825081, grad/param norm = 2.4636e-01, time/batch = 14.4750s	
22118/26050 (epoch 42.453), train_loss = 0.77519762, grad/param norm = 1.8762e-01, time/batch = 17.1427s	
22119/26050 (epoch 42.455), train_loss = 0.82684568, grad/param norm = 2.1702e-01, time/batch = 17.9171s	
22120/26050 (epoch 42.457), train_loss = 0.77942760, grad/param norm = 2.1373e-01, time/batch = 18.2331s	
22121/26050 (epoch 42.459), train_loss = 0.87778241, grad/param norm = 2.2060e-01, time/batch = 17.9912s	
22122/26050 (epoch 42.461), train_loss = 0.89417364, grad/param norm = 2.4114e-01, time/batch = 17.6587s	
22123/26050 (epoch 42.463), train_loss = 0.77242098, grad/param norm = 2.0389e-01, time/batch = 18.2348s	
22124/26050 (epoch 42.464), train_loss = 0.82927228, grad/param norm = 2.3172e-01, time/batch = 17.5461s	
22125/26050 (epoch 42.466), train_loss = 0.81726247, grad/param norm = 2.5383e-01, time/batch = 18.2299s	
22126/26050 (epoch 42.468), train_loss = 0.90725463, grad/param norm = 2.0179e-01, time/batch = 18.5706s	
22127/26050 (epoch 42.470), train_loss = 0.89771860, grad/param norm = 2.4647e-01, time/batch = 15.0524s	
22128/26050 (epoch 42.472), train_loss = 0.90284500, grad/param norm = 2.5105e-01, time/batch = 17.7322s	
22129/26050 (epoch 42.474), train_loss = 0.93888236, grad/param norm = 2.5637e-01, time/batch = 17.2196s	
22130/26050 (epoch 42.476), train_loss = 0.88309448, grad/param norm = 2.0119e-01, time/batch = 18.8957s	
22131/26050 (epoch 42.478), train_loss = 0.79489061, grad/param norm = 2.0365e-01, time/batch = 18.3899s	
22132/26050 (epoch 42.480), train_loss = 0.76957442, grad/param norm = 2.0133e-01, time/batch = 18.4039s	
22133/26050 (epoch 42.482), train_loss = 0.77403317, grad/param norm = 2.1263e-01, time/batch = 17.8120s	
22134/26050 (epoch 42.484), train_loss = 0.76781605, grad/param norm = 2.4931e-01, time/batch = 14.8930s	
22135/26050 (epoch 42.486), train_loss = 0.91000473, grad/param norm = 2.1266e-01, time/batch = 15.3764s	
22136/26050 (epoch 42.488), train_loss = 0.95695270, grad/param norm = 2.5223e-01, time/batch = 17.0503s	
22137/26050 (epoch 42.489), train_loss = 0.99152305, grad/param norm = 2.9246e-01, time/batch = 18.0560s	
22138/26050 (epoch 42.491), train_loss = 0.74827414, grad/param norm = 2.0967e-01, time/batch = 18.3867s	
22139/26050 (epoch 42.493), train_loss = 0.82668737, grad/param norm = 2.2627e-01, time/batch = 18.0998s	
22140/26050 (epoch 42.495), train_loss = 0.80190220, grad/param norm = 1.9712e-01, time/batch = 18.2431s	
22141/26050 (epoch 42.497), train_loss = 0.74276172, grad/param norm = 2.1059e-01, time/batch = 17.8930s	
22142/26050 (epoch 42.499), train_loss = 0.74423423, grad/param norm = 2.3261e-01, time/batch = 17.5674s	
22143/26050 (epoch 42.501), train_loss = 0.91105053, grad/param norm = 2.1534e-01, time/batch = 18.4903s	
22144/26050 (epoch 42.503), train_loss = 0.77229946, grad/param norm = 2.1668e-01, time/batch = 17.8821s	
22145/26050 (epoch 42.505), train_loss = 0.90840949, grad/param norm = 2.1694e-01, time/batch = 18.2326s	
22146/26050 (epoch 42.507), train_loss = 0.89474908, grad/param norm = 2.6975e-01, time/batch = 18.2349s	
22147/26050 (epoch 42.509), train_loss = 0.94120906, grad/param norm = 2.4318e-01, time/batch = 16.6289s	
22148/26050 (epoch 42.511), train_loss = 0.80225328, grad/param norm = 1.8626e-01, time/batch = 16.2881s	
22149/26050 (epoch 42.512), train_loss = 0.71273298, grad/param norm = 2.4927e-01, time/batch = 18.5615s	
22150/26050 (epoch 42.514), train_loss = 0.86640260, grad/param norm = 2.3030e-01, time/batch = 17.9738s	
22151/26050 (epoch 42.516), train_loss = 0.93814324, grad/param norm = 2.3235e-01, time/batch = 16.6387s	
22152/26050 (epoch 42.518), train_loss = 0.80020351, grad/param norm = 2.0106e-01, time/batch = 17.1314s	
22153/26050 (epoch 42.520), train_loss = 0.82352438, grad/param norm = 2.0288e-01, time/batch = 18.2230s	
22154/26050 (epoch 42.522), train_loss = 0.65845848, grad/param norm = 2.0268e-01, time/batch = 18.0671s	
22155/26050 (epoch 42.524), train_loss = 0.88883973, grad/param norm = 2.4180e-01, time/batch = 18.3282s	
22156/26050 (epoch 42.526), train_loss = 0.90998708, grad/param norm = 2.3578e-01, time/batch = 17.0836s	
22157/26050 (epoch 42.528), train_loss = 0.83850494, grad/param norm = 2.1549e-01, time/batch = 18.7536s	
22158/26050 (epoch 42.530), train_loss = 0.78943431, grad/param norm = 2.5891e-01, time/batch = 14.7924s	
22159/26050 (epoch 42.532), train_loss = 0.85472929, grad/param norm = 2.2976e-01, time/batch = 16.2166s	
22160/26050 (epoch 42.534), train_loss = 0.83746436, grad/param norm = 2.9620e-01, time/batch = 17.8169s	
22161/26050 (epoch 42.536), train_loss = 0.85943917, grad/param norm = 2.2386e-01, time/batch = 17.6490s	
22162/26050 (epoch 42.537), train_loss = 0.87373962, grad/param norm = 2.1049e-01, time/batch = 18.3172s	
22163/26050 (epoch 42.539), train_loss = 0.86094104, grad/param norm = 2.2518e-01, time/batch = 17.2280s	
22164/26050 (epoch 42.541), train_loss = 0.96187050, grad/param norm = 2.4297e-01, time/batch = 18.5453s	
22165/26050 (epoch 42.543), train_loss = 0.64443019, grad/param norm = 2.0295e-01, time/batch = 15.2986s	
22166/26050 (epoch 42.545), train_loss = 0.80373733, grad/param norm = 2.1839e-01, time/batch = 16.6232s	
22167/26050 (epoch 42.547), train_loss = 0.75322109, grad/param norm = 2.0755e-01, time/batch = 17.5804s	
22168/26050 (epoch 42.549), train_loss = 0.70982025, grad/param norm = 2.3400e-01, time/batch = 17.3145s	
22169/26050 (epoch 42.551), train_loss = 0.86274714, grad/param norm = 2.1419e-01, time/batch = 18.6447s	
22170/26050 (epoch 42.553), train_loss = 0.79037669, grad/param norm = 2.2309e-01, time/batch = 18.6473s	
22171/26050 (epoch 42.555), train_loss = 0.69961052, grad/param norm = 2.0726e-01, time/batch = 17.9087s	
22172/26050 (epoch 42.557), train_loss = 0.82770460, grad/param norm = 1.9371e-01, time/batch = 18.7320s	
22173/26050 (epoch 42.559), train_loss = 0.84211309, grad/param norm = 2.2097e-01, time/batch = 16.7432s	
22174/26050 (epoch 42.560), train_loss = 0.79027660, grad/param norm = 2.2660e-01, time/batch = 16.8014s	
22175/26050 (epoch 42.562), train_loss = 0.80282577, grad/param norm = 2.3613e-01, time/batch = 14.8869s	
22176/26050 (epoch 42.564), train_loss = 0.95971908, grad/param norm = 2.3080e-01, time/batch = 17.1445s	
22177/26050 (epoch 42.566), train_loss = 0.77469448, grad/param norm = 2.0656e-01, time/batch = 17.6547s	
22178/26050 (epoch 42.568), train_loss = 0.85866079, grad/param norm = 2.1904e-01, time/batch = 17.5642s	
22179/26050 (epoch 42.570), train_loss = 0.81551080, grad/param norm = 2.3107e-01, time/batch = 17.9748s	
22180/26050 (epoch 42.572), train_loss = 0.82901825, grad/param norm = 2.2516e-01, time/batch = 17.3840s	
22181/26050 (epoch 42.574), train_loss = 0.86473354, grad/param norm = 2.7053e-01, time/batch = 18.6401s	
22182/26050 (epoch 42.576), train_loss = 0.85284230, grad/param norm = 3.6261e-01, time/batch = 26.3853s	
22183/26050 (epoch 42.578), train_loss = 0.79288865, grad/param norm = 2.5621e-01, time/batch = 28.6644s	
22184/26050 (epoch 42.580), train_loss = 0.75554901, grad/param norm = 2.5395e-01, time/batch = 16.7961s	
22185/26050 (epoch 42.582), train_loss = 0.83481110, grad/param norm = 2.0532e-01, time/batch = 15.7006s	
22186/26050 (epoch 42.583), train_loss = 0.86513462, grad/param norm = 2.1829e-01, time/batch = 17.9676s	
22187/26050 (epoch 42.585), train_loss = 0.72701425, grad/param norm = 2.1028e-01, time/batch = 16.2261s	
22188/26050 (epoch 42.587), train_loss = 0.85170829, grad/param norm = 2.4915e-01, time/batch = 18.2307s	
22189/26050 (epoch 42.589), train_loss = 0.97286022, grad/param norm = 2.4361e-01, time/batch = 18.4868s	
22190/26050 (epoch 42.591), train_loss = 0.84795830, grad/param norm = 2.1323e-01, time/batch = 18.0728s	
22191/26050 (epoch 42.593), train_loss = 0.71597059, grad/param norm = 2.0339e-01, time/batch = 14.6449s	
22192/26050 (epoch 42.595), train_loss = 0.85372326, grad/param norm = 2.2628e-01, time/batch = 17.9868s	
22193/26050 (epoch 42.597), train_loss = 0.82237067, grad/param norm = 2.2239e-01, time/batch = 18.5682s	
22194/26050 (epoch 42.599), train_loss = 0.88139086, grad/param norm = 2.2735e-01, time/batch = 17.8312s	
22195/26050 (epoch 42.601), train_loss = 0.97078088, grad/param norm = 2.1932e-01, time/batch = 18.1495s	
22196/26050 (epoch 42.603), train_loss = 0.89046602, grad/param norm = 2.4855e-01, time/batch = 18.0790s	
22197/26050 (epoch 42.605), train_loss = 0.81202395, grad/param norm = 2.2626e-01, time/batch = 18.7284s	
22198/26050 (epoch 42.607), train_loss = 0.91639261, grad/param norm = 2.7774e-01, time/batch = 18.8839s	
22199/26050 (epoch 42.608), train_loss = 0.75522140, grad/param norm = 2.4104e-01, time/batch = 18.6459s	
22200/26050 (epoch 42.610), train_loss = 0.83387764, grad/param norm = 2.3612e-01, time/batch = 16.5501s	
22201/26050 (epoch 42.612), train_loss = 0.79641636, grad/param norm = 2.4984e-01, time/batch = 17.2087s	
22202/26050 (epoch 42.614), train_loss = 0.82345735, grad/param norm = 2.1403e-01, time/batch = 17.6163s	
22203/26050 (epoch 42.616), train_loss = 0.86722672, grad/param norm = 2.3734e-01, time/batch = 16.1194s	
22204/26050 (epoch 42.618), train_loss = 0.76584475, grad/param norm = 2.1474e-01, time/batch = 17.2466s	
22205/26050 (epoch 42.620), train_loss = 0.90211462, grad/param norm = 2.6039e-01, time/batch = 17.0551s	
22206/26050 (epoch 42.622), train_loss = 0.75732022, grad/param norm = 2.1369e-01, time/batch = 18.7251s	
22207/26050 (epoch 42.624), train_loss = 0.68010169, grad/param norm = 1.8799e-01, time/batch = 17.4784s	
22208/26050 (epoch 42.626), train_loss = 0.86739687, grad/param norm = 2.4950e-01, time/batch = 17.5757s	
22209/26050 (epoch 42.628), train_loss = 0.78550431, grad/param norm = 3.0933e-01, time/batch = 17.3797s	
22210/26050 (epoch 42.630), train_loss = 0.95909015, grad/param norm = 2.1480e-01, time/batch = 18.0296s	
22211/26050 (epoch 42.631), train_loss = 0.96011901, grad/param norm = 2.6159e-01, time/batch = 17.0497s	
22212/26050 (epoch 42.633), train_loss = 0.74995822, grad/param norm = 2.2064e-01, time/batch = 15.3870s	
22213/26050 (epoch 42.635), train_loss = 0.77634384, grad/param norm = 2.6888e-01, time/batch = 18.9084s	
22214/26050 (epoch 42.637), train_loss = 0.72592686, grad/param norm = 2.0553e-01, time/batch = 18.6490s	
22215/26050 (epoch 42.639), train_loss = 0.85647209, grad/param norm = 2.1479e-01, time/batch = 18.0444s	
22216/26050 (epoch 42.641), train_loss = 0.76232819, grad/param norm = 2.2865e-01, time/batch = 17.5668s	
22217/26050 (epoch 42.643), train_loss = 0.75546192, grad/param norm = 1.7463e-01, time/batch = 17.3952s	
22218/26050 (epoch 42.645), train_loss = 0.77554557, grad/param norm = 2.1234e-01, time/batch = 15.8110s	
22219/26050 (epoch 42.647), train_loss = 0.74985251, grad/param norm = 2.7776e-01, time/batch = 18.5508s	
22220/26050 (epoch 42.649), train_loss = 0.79410825, grad/param norm = 2.3098e-01, time/batch = 18.4810s	
22221/26050 (epoch 42.651), train_loss = 0.79421363, grad/param norm = 3.6665e-01, time/batch = 18.2240s	
22222/26050 (epoch 42.653), train_loss = 0.81427229, grad/param norm = 2.1741e-01, time/batch = 16.8183s	
22223/26050 (epoch 42.655), train_loss = 0.74500681, grad/param norm = 2.3330e-01, time/batch = 16.1187s	
22224/26050 (epoch 42.656), train_loss = 0.71905786, grad/param norm = 1.9507e-01, time/batch = 17.4453s	
22225/26050 (epoch 42.658), train_loss = 0.99268069, grad/param norm = 2.6736e-01, time/batch = 15.5425s	
22226/26050 (epoch 42.660), train_loss = 0.70489062, grad/param norm = 2.6574e-01, time/batch = 18.2379s	
22227/26050 (epoch 42.662), train_loss = 0.81279631, grad/param norm = 2.3945e-01, time/batch = 18.1467s	
22228/26050 (epoch 42.664), train_loss = 0.80425165, grad/param norm = 2.1138e-01, time/batch = 17.6629s	
22229/26050 (epoch 42.666), train_loss = 0.76028693, grad/param norm = 2.0341e-01, time/batch = 18.7392s	
22230/26050 (epoch 42.668), train_loss = 0.62763545, grad/param norm = 2.1542e-01, time/batch = 17.7310s	
22231/26050 (epoch 42.670), train_loss = 0.95260396, grad/param norm = 2.8783e-01, time/batch = 18.1549s	
22232/26050 (epoch 42.672), train_loss = 0.79862887, grad/param norm = 2.0699e-01, time/batch = 18.2968s	
22233/26050 (epoch 42.674), train_loss = 0.71445882, grad/param norm = 2.2451e-01, time/batch = 15.5570s	
22234/26050 (epoch 42.676), train_loss = 0.85941840, grad/param norm = 2.1806e-01, time/batch = 18.0619s	
22235/26050 (epoch 42.678), train_loss = 0.88395887, grad/param norm = 2.2027e-01, time/batch = 17.6499s	
22236/26050 (epoch 42.679), train_loss = 0.94047186, grad/param norm = 2.5555e-01, time/batch = 17.8011s	
22237/26050 (epoch 42.681), train_loss = 0.84015642, grad/param norm = 2.1829e-01, time/batch = 17.8975s	
22238/26050 (epoch 42.683), train_loss = 0.77433852, grad/param norm = 2.8287e-01, time/batch = 18.0676s	
22239/26050 (epoch 42.685), train_loss = 0.76792625, grad/param norm = 2.1540e-01, time/batch = 17.8155s	
22240/26050 (epoch 42.687), train_loss = 0.71001596, grad/param norm = 2.0543e-01, time/batch = 18.6425s	
22241/26050 (epoch 42.689), train_loss = 0.75722053, grad/param norm = 2.1317e-01, time/batch = 18.4857s	
22242/26050 (epoch 42.691), train_loss = 0.66196271, grad/param norm = 1.8373e-01, time/batch = 16.3768s	
22243/26050 (epoch 42.693), train_loss = 0.75976590, grad/param norm = 2.2427e-01, time/batch = 17.7106s	
22244/26050 (epoch 42.695), train_loss = 0.79260636, grad/param norm = 2.0132e-01, time/batch = 17.0464s	
22245/26050 (epoch 42.697), train_loss = 0.73644315, grad/param norm = 2.0062e-01, time/batch = 15.2729s	
22246/26050 (epoch 42.699), train_loss = 0.86176411, grad/param norm = 2.3356e-01, time/batch = 18.1412s	
22247/26050 (epoch 42.701), train_loss = 0.73333384, grad/param norm = 1.8990e-01, time/batch = 18.5662s	
22248/26050 (epoch 42.702), train_loss = 0.86654774, grad/param norm = 2.1314e-01, time/batch = 18.2385s	
22249/26050 (epoch 42.704), train_loss = 0.91401988, grad/param norm = 2.1434e-01, time/batch = 18.4783s	
22250/26050 (epoch 42.706), train_loss = 0.75728190, grad/param norm = 2.3232e-01, time/batch = 17.7450s	
22251/26050 (epoch 42.708), train_loss = 0.85716171, grad/param norm = 2.1412e-01, time/batch = 17.8234s	
22252/26050 (epoch 42.710), train_loss = 0.82726129, grad/param norm = 2.3930e-01, time/batch = 17.1656s	
22253/26050 (epoch 42.712), train_loss = 0.80773398, grad/param norm = 2.3344e-01, time/batch = 15.8077s	
22254/26050 (epoch 42.714), train_loss = 0.71412054, grad/param norm = 1.7531e-01, time/batch = 18.1474s	
22255/26050 (epoch 42.716), train_loss = 1.02883109, grad/param norm = 2.5183e-01, time/batch = 17.9109s	
22256/26050 (epoch 42.718), train_loss = 0.86330125, grad/param norm = 2.1804e-01, time/batch = 18.0799s	
22257/26050 (epoch 42.720), train_loss = 0.79295570, grad/param norm = 2.5558e-01, time/batch = 17.8994s	
22258/26050 (epoch 42.722), train_loss = 0.74647824, grad/param norm = 2.2041e-01, time/batch = 15.3905s	
22259/26050 (epoch 42.724), train_loss = 0.75605954, grad/param norm = 2.0439e-01, time/batch = 17.0240s	
22260/26050 (epoch 42.726), train_loss = 0.88484294, grad/param norm = 2.2827e-01, time/batch = 17.3076s	
22261/26050 (epoch 42.727), train_loss = 0.86633859, grad/param norm = 2.6535e-01, time/batch = 19.1434s	
22262/26050 (epoch 42.729), train_loss = 0.85321491, grad/param norm = 1.9590e-01, time/batch = 17.4866s	
22263/26050 (epoch 42.731), train_loss = 0.85238983, grad/param norm = 2.1838e-01, time/batch = 15.2091s	
22264/26050 (epoch 42.733), train_loss = 0.79189990, grad/param norm = 2.3510e-01, time/batch = 18.3844s	
22265/26050 (epoch 42.735), train_loss = 0.92150397, grad/param norm = 2.4620e-01, time/batch = 18.4086s	
22266/26050 (epoch 42.737), train_loss = 0.77003045, grad/param norm = 2.2739e-01, time/batch = 17.8872s	
22267/26050 (epoch 42.739), train_loss = 0.83860851, grad/param norm = 2.1337e-01, time/batch = 18.0692s	
22268/26050 (epoch 42.741), train_loss = 0.74024240, grad/param norm = 2.1651e-01, time/batch = 17.9824s	
22269/26050 (epoch 42.743), train_loss = 0.80486630, grad/param norm = 2.4316e-01, time/batch = 17.4001s	
22270/26050 (epoch 42.745), train_loss = 0.73097805, grad/param norm = 2.1643e-01, time/batch = 18.2941s	
22271/26050 (epoch 42.747), train_loss = 0.76258096, grad/param norm = 2.0823e-01, time/batch = 18.6401s	
22272/26050 (epoch 42.749), train_loss = 0.90929857, grad/param norm = 2.4960e-01, time/batch = 17.9878s	
22273/26050 (epoch 42.750), train_loss = 0.77838470, grad/param norm = 2.0867e-01, time/batch = 18.8144s	
22274/26050 (epoch 42.752), train_loss = 0.75875860, grad/param norm = 2.4642e-01, time/batch = 14.5488s	
22275/26050 (epoch 42.754), train_loss = 0.80144404, grad/param norm = 2.1627e-01, time/batch = 17.9744s	
22276/26050 (epoch 42.756), train_loss = 0.79217912, grad/param norm = 3.9350e-01, time/batch = 18.0528s	
22277/26050 (epoch 42.758), train_loss = 0.80131161, grad/param norm = 2.5200e-01, time/batch = 17.5737s	
22278/26050 (epoch 42.760), train_loss = 0.93519849, grad/param norm = 2.2566e-01, time/batch = 15.3065s	
22279/26050 (epoch 42.762), train_loss = 0.78839017, grad/param norm = 2.2957e-01, time/batch = 17.2268s	
22280/26050 (epoch 42.764), train_loss = 0.79657835, grad/param norm = 2.5530e-01, time/batch = 18.2205s	
22281/26050 (epoch 42.766), train_loss = 0.78826142, grad/param norm = 2.2120e-01, time/batch = 15.2261s	
22282/26050 (epoch 42.768), train_loss = 0.70140863, grad/param norm = 2.1271e-01, time/batch = 18.1474s	
22283/26050 (epoch 42.770), train_loss = 0.78773503, grad/param norm = 2.2541e-01, time/batch = 17.6353s	
22284/26050 (epoch 42.772), train_loss = 0.80725284, grad/param norm = 2.5038e-01, time/batch = 18.3891s	
22285/26050 (epoch 42.774), train_loss = 0.68946990, grad/param norm = 2.2207e-01, time/batch = 18.0650s	
22286/26050 (epoch 42.775), train_loss = 0.57159608, grad/param norm = 1.9638e-01, time/batch = 16.3292s	
22287/26050 (epoch 42.777), train_loss = 0.76027874, grad/param norm = 2.1020e-01, time/batch = 16.6601s	
22288/26050 (epoch 42.779), train_loss = 0.78223048, grad/param norm = 3.0061e-01, time/batch = 18.3972s	
22289/26050 (epoch 42.781), train_loss = 0.74436002, grad/param norm = 2.2775e-01, time/batch = 18.0746s	
22290/26050 (epoch 42.783), train_loss = 0.70404952, grad/param norm = 2.0449e-01, time/batch = 18.4084s	
22291/26050 (epoch 42.785), train_loss = 0.82372492, grad/param norm = 2.5666e-01, time/batch = 17.2133s	
22292/26050 (epoch 42.787), train_loss = 0.72037741, grad/param norm = 2.1020e-01, time/batch = 18.8066s	
22293/26050 (epoch 42.789), train_loss = 0.74884829, grad/param norm = 2.5912e-01, time/batch = 17.7265s	
22294/26050 (epoch 42.791), train_loss = 0.73575713, grad/param norm = 2.7140e-01, time/batch = 16.7193s	
22295/26050 (epoch 42.793), train_loss = 0.79932713, grad/param norm = 2.3243e-01, time/batch = 18.2920s	
22296/26050 (epoch 42.795), train_loss = 0.65378385, grad/param norm = 1.9215e-01, time/batch = 17.8983s	
22297/26050 (epoch 42.797), train_loss = 0.70808723, grad/param norm = 2.0694e-01, time/batch = 17.6469s	
22298/26050 (epoch 42.798), train_loss = 0.77872140, grad/param norm = 2.2919e-01, time/batch = 18.6591s	
22299/26050 (epoch 42.800), train_loss = 0.67796851, grad/param norm = 2.0454e-01, time/batch = 14.7382s	
22300/26050 (epoch 42.802), train_loss = 0.77250434, grad/param norm = 2.2493e-01, time/batch = 16.2958s	
22301/26050 (epoch 42.804), train_loss = 0.78704879, grad/param norm = 2.4974e-01, time/batch = 17.3670s	
22302/26050 (epoch 42.806), train_loss = 0.88271053, grad/param norm = 2.7626e-01, time/batch = 18.0523s	
22303/26050 (epoch 42.808), train_loss = 0.80836661, grad/param norm = 2.0792e-01, time/batch = 16.9800s	
22304/26050 (epoch 42.810), train_loss = 0.80217805, grad/param norm = 2.3871e-01, time/batch = 18.3879s	
22305/26050 (epoch 42.812), train_loss = 0.65867354, grad/param norm = 2.1385e-01, time/batch = 16.1246s	
22306/26050 (epoch 42.814), train_loss = 0.70613354, grad/param norm = 2.5830e-01, time/batch = 16.8735s	
22307/26050 (epoch 42.816), train_loss = 0.83476211, grad/param norm = 2.5750e-01, time/batch = 18.5552s	
22308/26050 (epoch 42.818), train_loss = 0.87682397, grad/param norm = 2.9158e-01, time/batch = 18.4856s	
22309/26050 (epoch 42.820), train_loss = 0.80824429, grad/param norm = 2.2188e-01, time/batch = 18.4793s	
22310/26050 (epoch 42.821), train_loss = 0.88289149, grad/param norm = 2.2946e-01, time/batch = 17.9892s	
22311/26050 (epoch 42.823), train_loss = 0.98382787, grad/param norm = 2.2248e-01, time/batch = 17.4803s	
22312/26050 (epoch 42.825), train_loss = 0.79348788, grad/param norm = 2.3072e-01, time/batch = 18.4117s	
22313/26050 (epoch 42.827), train_loss = 0.80054018, grad/param norm = 2.8230e-01, time/batch = 16.5526s	
22314/26050 (epoch 42.829), train_loss = 0.88561292, grad/param norm = 2.4953e-01, time/batch = 17.2961s	
22315/26050 (epoch 42.831), train_loss = 0.95306817, grad/param norm = 2.4604e-01, time/batch = 18.6525s	
22316/26050 (epoch 42.833), train_loss = 0.89214894, grad/param norm = 2.5151e-01, time/batch = 17.7237s	
22317/26050 (epoch 42.835), train_loss = 0.91745696, grad/param norm = 2.2406e-01, time/batch = 17.6486s	
22318/26050 (epoch 42.837), train_loss = 0.84087251, grad/param norm = 2.2271e-01, time/batch = 18.2350s	
22319/26050 (epoch 42.839), train_loss = 0.77626563, grad/param norm = 2.3896e-01, time/batch = 18.3028s	
22320/26050 (epoch 42.841), train_loss = 0.86399497, grad/param norm = 2.4351e-01, time/batch = 15.0555s	
22321/26050 (epoch 42.843), train_loss = 0.78871906, grad/param norm = 1.9403e-01, time/batch = 17.7906s	
22322/26050 (epoch 42.845), train_loss = 0.74069566, grad/param norm = 2.1204e-01, time/batch = 17.9902s	
22323/26050 (epoch 42.846), train_loss = 0.83387534, grad/param norm = 2.0544e-01, time/batch = 17.5622s	
22324/26050 (epoch 42.848), train_loss = 0.77191797, grad/param norm = 2.1780e-01, time/batch = 18.0708s	
22325/26050 (epoch 42.850), train_loss = 0.70301719, grad/param norm = 1.9415e-01, time/batch = 17.7428s	
22326/26050 (epoch 42.852), train_loss = 0.82341726, grad/param norm = 2.1740e-01, time/batch = 18.3979s	
22327/26050 (epoch 42.854), train_loss = 0.81233432, grad/param norm = 2.5649e-01, time/batch = 16.9034s	
22328/26050 (epoch 42.856), train_loss = 0.76108836, grad/param norm = 2.2637e-01, time/batch = 16.7896s	
22329/26050 (epoch 42.858), train_loss = 0.72824783, grad/param norm = 2.1059e-01, time/batch = 18.2067s	
22330/26050 (epoch 42.860), train_loss = 0.82495722, grad/param norm = 2.6046e-01, time/batch = 17.4688s	
22331/26050 (epoch 42.862), train_loss = 0.88081410, grad/param norm = 2.1871e-01, time/batch = 16.9636s	
22332/26050 (epoch 42.864), train_loss = 0.78102906, grad/param norm = 2.4174e-01, time/batch = 17.7918s	
22333/26050 (epoch 42.866), train_loss = 0.79446037, grad/param norm = 2.2690e-01, time/batch = 18.0699s	
22334/26050 (epoch 42.868), train_loss = 0.85681194, grad/param norm = 2.6213e-01, time/batch = 16.9551s	
22335/26050 (epoch 42.869), train_loss = 0.72815977, grad/param norm = 2.0021e-01, time/batch = 18.3950s	
22336/26050 (epoch 42.871), train_loss = 0.69588561, grad/param norm = 2.1862e-01, time/batch = 17.9697s	
22337/26050 (epoch 42.873), train_loss = 0.85390497, grad/param norm = 2.3765e-01, time/batch = 17.3020s	
22338/26050 (epoch 42.875), train_loss = 0.76746691, grad/param norm = 2.2962e-01, time/batch = 17.7154s	
22339/26050 (epoch 42.877), train_loss = 0.75537188, grad/param norm = 1.9393e-01, time/batch = 15.5767s	
22340/26050 (epoch 42.879), train_loss = 0.85165008, grad/param norm = 2.0891e-01, time/batch = 14.0828s	
22341/26050 (epoch 42.881), train_loss = 0.88220783, grad/param norm = 2.5817e-01, time/batch = 14.3830s	
22342/26050 (epoch 42.883), train_loss = 0.85818548, grad/param norm = 2.1706e-01, time/batch = 14.4096s	
22343/26050 (epoch 42.885), train_loss = 0.62616505, grad/param norm = 2.1560e-01, time/batch = 16.8964s	
22344/26050 (epoch 42.887), train_loss = 0.89199572, grad/param norm = 2.3458e-01, time/batch = 16.0381s	
22345/26050 (epoch 42.889), train_loss = 0.72809522, grad/param norm = 2.1068e-01, time/batch = 18.4000s	
22346/26050 (epoch 42.891), train_loss = 0.67290317, grad/param norm = 1.9867e-01, time/batch = 15.6355s	
22347/26050 (epoch 42.893), train_loss = 0.67716043, grad/param norm = 2.2871e-01, time/batch = 18.7093s	
22348/26050 (epoch 42.894), train_loss = 0.74004353, grad/param norm = 2.3640e-01, time/batch = 16.4818s	
22349/26050 (epoch 42.896), train_loss = 0.85894830, grad/param norm = 2.1553e-01, time/batch = 18.3157s	
22350/26050 (epoch 42.898), train_loss = 0.74772774, grad/param norm = 2.1700e-01, time/batch = 17.4914s	
22351/26050 (epoch 42.900), train_loss = 0.84540841, grad/param norm = 2.5417e-01, time/batch = 17.6541s	
22352/26050 (epoch 42.902), train_loss = 0.77634071, grad/param norm = 2.3552e-01, time/batch = 18.5580s	
22353/26050 (epoch 42.904), train_loss = 0.78675593, grad/param norm = 2.6240e-01, time/batch = 18.3238s	
22354/26050 (epoch 42.906), train_loss = 0.77282152, grad/param norm = 2.7459e-01, time/batch = 16.9773s	
22355/26050 (epoch 42.908), train_loss = 0.83325401, grad/param norm = 2.2106e-01, time/batch = 16.0493s	
22356/26050 (epoch 42.910), train_loss = 0.74941098, grad/param norm = 2.5165e-01, time/batch = 14.9036s	
22357/26050 (epoch 42.912), train_loss = 0.96789961, grad/param norm = 2.6294e-01, time/batch = 18.3319s	
22358/26050 (epoch 42.914), train_loss = 1.08670165, grad/param norm = 2.6692e-01, time/batch = 17.3173s	
22359/26050 (epoch 42.916), train_loss = 0.84807112, grad/param norm = 2.4452e-01, time/batch = 18.5661s	
22360/26050 (epoch 42.917), train_loss = 0.82690064, grad/param norm = 2.3592e-01, time/batch = 15.3800s	
22361/26050 (epoch 42.919), train_loss = 0.83217733, grad/param norm = 2.5028e-01, time/batch = 15.6485s	
22362/26050 (epoch 42.921), train_loss = 0.73556447, grad/param norm = 2.2480e-01, time/batch = 17.5436s	
22363/26050 (epoch 42.923), train_loss = 0.81320781, grad/param norm = 2.0886e-01, time/batch = 18.6534s	
22364/26050 (epoch 42.925), train_loss = 0.80528198, grad/param norm = 2.3464e-01, time/batch = 17.9838s	
22365/26050 (epoch 42.927), train_loss = 0.74735863, grad/param norm = 1.6889e-01, time/batch = 16.4928s	
22366/26050 (epoch 42.929), train_loss = 0.68514255, grad/param norm = 2.1646e-01, time/batch = 18.5694s	
22367/26050 (epoch 42.931), train_loss = 0.94011048, grad/param norm = 2.5915e-01, time/batch = 18.1419s	
22368/26050 (epoch 42.933), train_loss = 0.79782006, grad/param norm = 2.3355e-01, time/batch = 18.2077s	
22369/26050 (epoch 42.935), train_loss = 0.76714149, grad/param norm = 2.1755e-01, time/batch = 17.7307s	
22370/26050 (epoch 42.937), train_loss = 0.85486808, grad/param norm = 2.2497e-01, time/batch = 18.4041s	
22371/26050 (epoch 42.939), train_loss = 0.73905673, grad/param norm = 1.9432e-01, time/batch = 15.8911s	
22372/26050 (epoch 42.940), train_loss = 0.80152914, grad/param norm = 2.1249e-01, time/batch = 17.0562s	
22373/26050 (epoch 42.942), train_loss = 0.74822390, grad/param norm = 2.1592e-01, time/batch = 17.9867s	
22374/26050 (epoch 42.944), train_loss = 0.77383702, grad/param norm = 1.9784e-01, time/batch = 18.4751s	
22375/26050 (epoch 42.946), train_loss = 0.95704580, grad/param norm = 2.2002e-01, time/batch = 17.5753s	
22376/26050 (epoch 42.948), train_loss = 0.69688415, grad/param norm = 2.0833e-01, time/batch = 18.0535s	
22377/26050 (epoch 42.950), train_loss = 0.81393048, grad/param norm = 2.0583e-01, time/batch = 17.7262s	
22378/26050 (epoch 42.952), train_loss = 0.84557248, grad/param norm = 2.1248e-01, time/batch = 18.3028s	
22379/26050 (epoch 42.954), train_loss = 0.86766476, grad/param norm = 2.1980e-01, time/batch = 15.5523s	
22380/26050 (epoch 42.956), train_loss = 0.76815115, grad/param norm = 2.2830e-01, time/batch = 17.9062s	
22381/26050 (epoch 42.958), train_loss = 0.71543428, grad/param norm = 1.9478e-01, time/batch = 17.1246s	
22382/26050 (epoch 42.960), train_loss = 0.82642767, grad/param norm = 2.2781e-01, time/batch = 17.7289s	
22383/26050 (epoch 42.962), train_loss = 0.79962328, grad/param norm = 1.9635e-01, time/batch = 18.3203s	
22384/26050 (epoch 42.964), train_loss = 0.76845805, grad/param norm = 2.1918e-01, time/batch = 17.7430s	
22385/26050 (epoch 42.965), train_loss = 0.73024162, grad/param norm = 2.3677e-01, time/batch = 18.5554s	
22386/26050 (epoch 42.967), train_loss = 1.06413430, grad/param norm = 2.4949e-01, time/batch = 29.5897s	
22387/26050 (epoch 42.969), train_loss = 0.80441478, grad/param norm = 2.0804e-01, time/batch = 24.9665s	
22388/26050 (epoch 42.971), train_loss = 0.81954137, grad/param norm = 2.1747e-01, time/batch = 18.4299s	
22389/26050 (epoch 42.973), train_loss = 0.82205738, grad/param norm = 2.2594e-01, time/batch = 18.0598s	
22390/26050 (epoch 42.975), train_loss = 0.81469766, grad/param norm = 2.2158e-01, time/batch = 17.4726s	
22391/26050 (epoch 42.977), train_loss = 0.78410897, grad/param norm = 1.9762e-01, time/batch = 16.8881s	
22392/26050 (epoch 42.979), train_loss = 0.64717022, grad/param norm = 1.8964e-01, time/batch = 17.7270s	
22393/26050 (epoch 42.981), train_loss = 0.87973740, grad/param norm = 2.1193e-01, time/batch = 15.6927s	
22394/26050 (epoch 42.983), train_loss = 0.84712566, grad/param norm = 2.1429e-01, time/batch = 16.0540s	
22395/26050 (epoch 42.985), train_loss = 0.83971136, grad/param norm = 2.5103e-01, time/batch = 18.1404s	
22396/26050 (epoch 42.987), train_loss = 0.90185462, grad/param norm = 2.1721e-01, time/batch = 18.6436s	
22397/26050 (epoch 42.988), train_loss = 0.84469184, grad/param norm = 2.1220e-01, time/batch = 18.8140s	
22398/26050 (epoch 42.990), train_loss = 0.70093870, grad/param norm = 1.9274e-01, time/batch = 17.1482s	
22399/26050 (epoch 42.992), train_loss = 0.91769985, grad/param norm = 2.0838e-01, time/batch = 18.4765s	
22400/26050 (epoch 42.994), train_loss = 0.74873293, grad/param norm = 2.3442e-01, time/batch = 17.8925s	
22401/26050 (epoch 42.996), train_loss = 0.69777902, grad/param norm = 2.2001e-01, time/batch = 17.1249s	
22402/26050 (epoch 42.998), train_loss = 0.81851460, grad/param norm = 2.1373e-01, time/batch = 18.3935s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
22403/26050 (epoch 43.000), train_loss = 0.72034920, grad/param norm = 2.0970e-01, time/batch = 17.9862s	
22404/26050 (epoch 43.002), train_loss = 0.85232670, grad/param norm = 2.2222e-01, time/batch = 14.4830s	
22405/26050 (epoch 43.004), train_loss = 0.72607121, grad/param norm = 2.5318e-01, time/batch = 17.7373s	
22406/26050 (epoch 43.006), train_loss = 0.76831596, grad/param norm = 2.9818e-01, time/batch = 18.7272s	
22407/26050 (epoch 43.008), train_loss = 0.75100362, grad/param norm = 2.4646e-01, time/batch = 16.3809s	
22408/26050 (epoch 43.010), train_loss = 0.72554720, grad/param norm = 1.9587e-01, time/batch = 17.2410s	
22409/26050 (epoch 43.012), train_loss = 0.77496610, grad/param norm = 2.1404e-01, time/batch = 17.5734s	
22410/26050 (epoch 43.013), train_loss = 0.99689404, grad/param norm = 2.5790e-01, time/batch = 15.9839s	
22411/26050 (epoch 43.015), train_loss = 0.79408960, grad/param norm = 2.0602e-01, time/batch = 17.1327s	
22412/26050 (epoch 43.017), train_loss = 0.81927472, grad/param norm = 1.9976e-01, time/batch = 18.1453s	
22413/26050 (epoch 43.019), train_loss = 0.69869925, grad/param norm = 1.7792e-01, time/batch = 17.0567s	
22414/26050 (epoch 43.021), train_loss = 0.86833684, grad/param norm = 2.3942e-01, time/batch = 18.7544s	
22415/26050 (epoch 43.023), train_loss = 0.67413953, grad/param norm = 2.1830e-01, time/batch = 15.9731s	
22416/26050 (epoch 43.025), train_loss = 0.81234725, grad/param norm = 2.3619e-01, time/batch = 18.6493s	
22417/26050 (epoch 43.027), train_loss = 0.62869491, grad/param norm = 2.1726e-01, time/batch = 18.1485s	
22418/26050 (epoch 43.029), train_loss = 0.84042080, grad/param norm = 2.0886e-01, time/batch = 17.4745s	
22419/26050 (epoch 43.031), train_loss = 0.90517673, grad/param norm = 2.3735e-01, time/batch = 17.6473s	
22420/26050 (epoch 43.033), train_loss = 0.78714766, grad/param norm = 2.0740e-01, time/batch = 15.1452s	
22421/26050 (epoch 43.035), train_loss = 0.82419884, grad/param norm = 1.9852e-01, time/batch = 17.8976s	
22422/26050 (epoch 43.036), train_loss = 0.68562771, grad/param norm = 2.5770e-01, time/batch = 17.3930s	
22423/26050 (epoch 43.038), train_loss = 0.65127464, grad/param norm = 1.9130e-01, time/batch = 18.3808s	
22424/26050 (epoch 43.040), train_loss = 0.77609561, grad/param norm = 2.2870e-01, time/batch = 18.5475s	
22425/26050 (epoch 43.042), train_loss = 0.68315105, grad/param norm = 2.0838e-01, time/batch = 18.0553s	
22426/26050 (epoch 43.044), train_loss = 0.85320725, grad/param norm = 1.9123e-01, time/batch = 18.4805s	
22427/26050 (epoch 43.046), train_loss = 0.67189370, grad/param norm = 1.7990e-01, time/batch = 17.4511s	
22428/26050 (epoch 43.048), train_loss = 0.78670636, grad/param norm = 1.9876e-01, time/batch = 17.0524s	
22429/26050 (epoch 43.050), train_loss = 0.75408842, grad/param norm = 2.1783e-01, time/batch = 16.3719s	
22430/26050 (epoch 43.052), train_loss = 0.74125381, grad/param norm = 2.2552e-01, time/batch = 18.2193s	
22431/26050 (epoch 43.054), train_loss = 0.67506274, grad/param norm = 2.1051e-01, time/batch = 18.7278s	
22432/26050 (epoch 43.056), train_loss = 0.65805428, grad/param norm = 1.6259e-01, time/batch = 16.7324s	
22433/26050 (epoch 43.058), train_loss = 0.77302367, grad/param norm = 2.1180e-01, time/batch = 17.5741s	
22434/26050 (epoch 43.060), train_loss = 0.82250422, grad/param norm = 1.9281e-01, time/batch = 15.0536s	
22435/26050 (epoch 43.061), train_loss = 0.68186694, grad/param norm = 2.0288e-01, time/batch = 17.8139s	
22436/26050 (epoch 43.063), train_loss = 0.79072792, grad/param norm = 2.2028e-01, time/batch = 18.2244s	
22437/26050 (epoch 43.065), train_loss = 0.65102570, grad/param norm = 1.7948e-01, time/batch = 17.8192s	
22438/26050 (epoch 43.067), train_loss = 0.77772289, grad/param norm = 2.0253e-01, time/batch = 15.3220s	
22439/26050 (epoch 43.069), train_loss = 0.80409102, grad/param norm = 2.3070e-01, time/batch = 17.2339s	
22440/26050 (epoch 43.071), train_loss = 0.80334377, grad/param norm = 2.5034e-01, time/batch = 18.5642s	
22441/26050 (epoch 43.073), train_loss = 0.93926466, grad/param norm = 2.2106e-01, time/batch = 18.2322s	
22442/26050 (epoch 43.075), train_loss = 0.75441321, grad/param norm = 2.1830e-01, time/batch = 17.9767s	
22443/26050 (epoch 43.077), train_loss = 0.74989335, grad/param norm = 2.7163e-01, time/batch = 17.9035s	
22444/26050 (epoch 43.079), train_loss = 0.76391479, grad/param norm = 2.1970e-01, time/batch = 16.9679s	
22445/26050 (epoch 43.081), train_loss = 0.76141100, grad/param norm = 2.2412e-01, time/batch = 18.1354s	
22446/26050 (epoch 43.083), train_loss = 0.88532776, grad/param norm = 2.0990e-01, time/batch = 18.2205s	
22447/26050 (epoch 43.084), train_loss = 0.81742724, grad/param norm = 2.9048e-01, time/batch = 17.5582s	
22448/26050 (epoch 43.086), train_loss = 0.92823139, grad/param norm = 2.7112e-01, time/batch = 18.4854s	
22449/26050 (epoch 43.088), train_loss = 0.79775095, grad/param norm = 2.2054e-01, time/batch = 15.8920s	
22450/26050 (epoch 43.090), train_loss = 0.82732855, grad/param norm = 2.2921e-01, time/batch = 17.2422s	
22451/26050 (epoch 43.092), train_loss = 0.85303512, grad/param norm = 2.0474e-01, time/batch = 17.8398s	
22452/26050 (epoch 43.094), train_loss = 0.67062375, grad/param norm = 2.1338e-01, time/batch = 17.8092s	
22453/26050 (epoch 43.096), train_loss = 0.81055830, grad/param norm = 1.9384e-01, time/batch = 17.8994s	
22454/26050 (epoch 43.098), train_loss = 0.79227163, grad/param norm = 2.1570e-01, time/batch = 18.2428s	
22455/26050 (epoch 43.100), train_loss = 0.69547384, grad/param norm = 2.0347e-01, time/batch = 17.9043s	
22456/26050 (epoch 43.102), train_loss = 0.80426327, grad/param norm = 2.7561e-01, time/batch = 14.6368s	
22457/26050 (epoch 43.104), train_loss = 0.76305671, grad/param norm = 2.2285e-01, time/batch = 18.2320s	
22458/26050 (epoch 43.106), train_loss = 0.83719257, grad/param norm = 2.2943e-01, time/batch = 17.7290s	
22459/26050 (epoch 43.107), train_loss = 0.67120288, grad/param norm = 2.1116e-01, time/batch = 18.2157s	
22460/26050 (epoch 43.109), train_loss = 0.73109183, grad/param norm = 2.0454e-01, time/batch = 18.1510s	
22461/26050 (epoch 43.111), train_loss = 0.92207850, grad/param norm = 2.4760e-01, time/batch = 17.8187s	
22462/26050 (epoch 43.113), train_loss = 0.76421745, grad/param norm = 1.8452e-01, time/batch = 17.8107s	
22463/26050 (epoch 43.115), train_loss = 0.86525333, grad/param norm = 2.1102e-01, time/batch = 17.9781s	
22464/26050 (epoch 43.117), train_loss = 0.78060463, grad/param norm = 2.0708e-01, time/batch = 16.9585s	
22465/26050 (epoch 43.119), train_loss = 0.69493131, grad/param norm = 1.8056e-01, time/batch = 17.5352s	
22466/26050 (epoch 43.121), train_loss = 0.78803388, grad/param norm = 2.2618e-01, time/batch = 17.4131s	
22467/26050 (epoch 43.123), train_loss = 0.72557883, grad/param norm = 1.9794e-01, time/batch = 17.9989s	
22468/26050 (epoch 43.125), train_loss = 0.67580115, grad/param norm = 1.9313e-01, time/batch = 15.7284s	
22469/26050 (epoch 43.127), train_loss = 0.66768720, grad/param norm = 1.9719e-01, time/batch = 16.6370s	
22470/26050 (epoch 43.129), train_loss = 0.61231986, grad/param norm = 1.9397e-01, time/batch = 16.9681s	
22471/26050 (epoch 43.131), train_loss = 0.79374189, grad/param norm = 2.3248e-01, time/batch = 14.8140s	
22472/26050 (epoch 43.132), train_loss = 0.80600799, grad/param norm = 2.1539e-01, time/batch = 17.3126s	
22473/26050 (epoch 43.134), train_loss = 0.83752512, grad/param norm = 2.5276e-01, time/batch = 16.6355s	
22474/26050 (epoch 43.136), train_loss = 0.76729339, grad/param norm = 2.0648e-01, time/batch = 18.1301s	
22475/26050 (epoch 43.138), train_loss = 0.54769165, grad/param norm = 2.0056e-01, time/batch = 18.4774s	
22476/26050 (epoch 43.140), train_loss = 0.64545187, grad/param norm = 2.2875e-01, time/batch = 14.9007s	
22477/26050 (epoch 43.142), train_loss = 0.65990038, grad/param norm = 1.9572e-01, time/batch = 18.2097s	
22478/26050 (epoch 43.144), train_loss = 0.64048121, grad/param norm = 2.2427e-01, time/batch = 17.9891s	
22479/26050 (epoch 43.146), train_loss = 0.57573493, grad/param norm = 1.6701e-01, time/batch = 18.5661s	
22480/26050 (epoch 43.148), train_loss = 0.61800725, grad/param norm = 1.8965e-01, time/batch = 17.2292s	
22481/26050 (epoch 43.150), train_loss = 0.70038175, grad/param norm = 2.1641e-01, time/batch = 17.6667s	
22482/26050 (epoch 43.152), train_loss = 0.87101079, grad/param norm = 2.7516e-01, time/batch = 18.4018s	
22483/26050 (epoch 43.154), train_loss = 0.60737466, grad/param norm = 2.0577e-01, time/batch = 17.5641s	
22484/26050 (epoch 43.155), train_loss = 0.65886515, grad/param norm = 1.8835e-01, time/batch = 16.4706s	
22485/26050 (epoch 43.157), train_loss = 0.75154477, grad/param norm = 2.7457e-01, time/batch = 17.3918s	
22486/26050 (epoch 43.159), train_loss = 0.80990119, grad/param norm = 2.9321e-01, time/batch = 18.2387s	
22487/26050 (epoch 43.161), train_loss = 0.78841188, grad/param norm = 2.5144e-01, time/batch = 17.3051s	
22488/26050 (epoch 43.163), train_loss = 0.66052434, grad/param norm = 2.4230e-01, time/batch = 18.1536s	
22489/26050 (epoch 43.165), train_loss = 0.59656821, grad/param norm = 1.8633e-01, time/batch = 17.5618s	
22490/26050 (epoch 43.167), train_loss = 0.87774027, grad/param norm = 2.5982e-01, time/batch = 17.3889s	
22491/26050 (epoch 43.169), train_loss = 0.78104607, grad/param norm = 2.3511e-01, time/batch = 18.3009s	
22492/26050 (epoch 43.171), train_loss = 0.69578240, grad/param norm = 1.9250e-01, time/batch = 16.3684s	
22493/26050 (epoch 43.173), train_loss = 0.73935294, grad/param norm = 2.0490e-01, time/batch = 17.9841s	
22494/26050 (epoch 43.175), train_loss = 0.75668478, grad/param norm = 2.0844e-01, time/batch = 18.0820s	
22495/26050 (epoch 43.177), train_loss = 0.82329725, grad/param norm = 2.1693e-01, time/batch = 17.2450s	
22496/26050 (epoch 43.179), train_loss = 0.57921359, grad/param norm = 1.7983e-01, time/batch = 18.1343s	
22497/26050 (epoch 43.180), train_loss = 0.98076510, grad/param norm = 2.1027e-01, time/batch = 17.3146s	
22498/26050 (epoch 43.182), train_loss = 0.91556098, grad/param norm = 2.2977e-01, time/batch = 17.6457s	
22499/26050 (epoch 43.184), train_loss = 0.80387223, grad/param norm = 2.1722e-01, time/batch = 17.8847s	
22500/26050 (epoch 43.186), train_loss = 0.68136716, grad/param norm = 2.0835e-01, time/batch = 16.6306s	
22501/26050 (epoch 43.188), train_loss = 0.84954344, grad/param norm = 2.5593e-01, time/batch = 18.3036s	
22502/26050 (epoch 43.190), train_loss = 0.84415519, grad/param norm = 3.5455e-01, time/batch = 18.1526s	
22503/26050 (epoch 43.192), train_loss = 0.87310835, grad/param norm = 2.0313e-01, time/batch = 16.8993s	
22504/26050 (epoch 43.194), train_loss = 0.82262091, grad/param norm = 2.3508e-01, time/batch = 15.7914s	
22505/26050 (epoch 43.196), train_loss = 0.83983902, grad/param norm = 2.2328e-01, time/batch = 18.2335s	
22506/26050 (epoch 43.198), train_loss = 0.71676811, grad/param norm = 1.9618e-01, time/batch = 17.5011s	
22507/26050 (epoch 43.200), train_loss = 0.70782373, grad/param norm = 2.3544e-01, time/batch = 17.2355s	
22508/26050 (epoch 43.202), train_loss = 0.79185560, grad/param norm = 2.1671e-01, time/batch = 18.4803s	
22509/26050 (epoch 43.203), train_loss = 0.88875810, grad/param norm = 1.9468e-01, time/batch = 18.9899s	
22510/26050 (epoch 43.205), train_loss = 0.72429277, grad/param norm = 2.1422e-01, time/batch = 15.6449s	
22511/26050 (epoch 43.207), train_loss = 0.70307388, grad/param norm = 2.1382e-01, time/batch = 17.8190s	
22512/26050 (epoch 43.209), train_loss = 0.84295576, grad/param norm = 2.0437e-01, time/batch = 18.1566s	
22513/26050 (epoch 43.211), train_loss = 0.68359118, grad/param norm = 2.0257e-01, time/batch = 18.7224s	
22514/26050 (epoch 43.213), train_loss = 0.78913540, grad/param norm = 1.9753e-01, time/batch = 17.0788s	
22515/26050 (epoch 43.215), train_loss = 0.76723397, grad/param norm = 2.2572e-01, time/batch = 17.4838s	
22516/26050 (epoch 43.217), train_loss = 0.75718826, grad/param norm = 2.1900e-01, time/batch = 18.6515s	
22517/26050 (epoch 43.219), train_loss = 0.74179891, grad/param norm = 2.4841e-01, time/batch = 14.5330s	
22518/26050 (epoch 43.221), train_loss = 0.69982574, grad/param norm = 2.4575e-01, time/batch = 17.1598s	
22519/26050 (epoch 43.223), train_loss = 0.84472350, grad/param norm = 2.3321e-01, time/batch = 18.4783s	
22520/26050 (epoch 43.225), train_loss = 0.70909411, grad/param norm = 2.1363e-01, time/batch = 18.9768s	
22521/26050 (epoch 43.226), train_loss = 0.79422363, grad/param norm = 2.4110e-01, time/batch = 17.8018s	
22522/26050 (epoch 43.228), train_loss = 0.88449865, grad/param norm = 2.3534e-01, time/batch = 17.3036s	
22523/26050 (epoch 43.230), train_loss = 0.78269698, grad/param norm = 2.0233e-01, time/batch = 16.0246s	
22524/26050 (epoch 43.232), train_loss = 0.86535140, grad/param norm = 2.3416e-01, time/batch = 16.6528s	
22525/26050 (epoch 43.234), train_loss = 0.68534306, grad/param norm = 2.2410e-01, time/batch = 18.8091s	
22526/26050 (epoch 43.236), train_loss = 0.83313396, grad/param norm = 2.1894e-01, time/batch = 17.2733s	
22527/26050 (epoch 43.238), train_loss = 0.69292099, grad/param norm = 1.9720e-01, time/batch = 17.9766s	
22528/26050 (epoch 43.240), train_loss = 0.79900443, grad/param norm = 2.2796e-01, time/batch = 18.3210s	
22529/26050 (epoch 43.242), train_loss = 0.76442686, grad/param norm = 2.0397e-01, time/batch = 15.3748s	
22530/26050 (epoch 43.244), train_loss = 0.80721502, grad/param norm = 2.3253e-01, time/batch = 17.5713s	
22531/26050 (epoch 43.246), train_loss = 0.75342027, grad/param norm = 2.1085e-01, time/batch = 17.8956s	
22532/26050 (epoch 43.248), train_loss = 0.79646759, grad/param norm = 2.4283e-01, time/batch = 18.2164s	
22533/26050 (epoch 43.250), train_loss = 0.79947019, grad/param norm = 2.4551e-01, time/batch = 18.7374s	
22534/26050 (epoch 43.251), train_loss = 0.74559924, grad/param norm = 2.3063e-01, time/batch = 17.6420s	
22535/26050 (epoch 43.253), train_loss = 0.67032710, grad/param norm = 2.0325e-01, time/batch = 18.3122s	
22536/26050 (epoch 43.255), train_loss = 0.95792835, grad/param norm = 2.5320e-01, time/batch = 18.0583s	
22537/26050 (epoch 43.257), train_loss = 0.81374582, grad/param norm = 2.5143e-01, time/batch = 16.1456s	
22538/26050 (epoch 43.259), train_loss = 0.86293274, grad/param norm = 2.3036e-01, time/batch = 17.1920s	
22539/26050 (epoch 43.261), train_loss = 0.71129208, grad/param norm = 2.3783e-01, time/batch = 18.0684s	
22540/26050 (epoch 43.263), train_loss = 0.87281599, grad/param norm = 2.2721e-01, time/batch = 16.3879s	
22541/26050 (epoch 43.265), train_loss = 0.89051829, grad/param norm = 2.3781e-01, time/batch = 17.1315s	
22542/26050 (epoch 43.267), train_loss = 0.89756728, grad/param norm = 2.0354e-01, time/batch = 16.6617s	
22543/26050 (epoch 43.269), train_loss = 0.89404097, grad/param norm = 3.2092e-01, time/batch = 17.9887s	
22544/26050 (epoch 43.271), train_loss = 0.80429022, grad/param norm = 2.4234e-01, time/batch = 16.8904s	
22545/26050 (epoch 43.273), train_loss = 0.71100763, grad/param norm = 2.2922e-01, time/batch = 17.6354s	
22546/26050 (epoch 43.274), train_loss = 0.76049322, grad/param norm = 2.0405e-01, time/batch = 17.8200s	
22547/26050 (epoch 43.276), train_loss = 0.76326078, grad/param norm = 2.5673e-01, time/batch = 18.4745s	
22548/26050 (epoch 43.278), train_loss = 0.85663801, grad/param norm = 2.0728e-01, time/batch = 16.8140s	
22549/26050 (epoch 43.280), train_loss = 0.76814502, grad/param norm = 2.1169e-01, time/batch = 18.5676s	
22550/26050 (epoch 43.282), train_loss = 0.87099770, grad/param norm = 2.1918e-01, time/batch = 16.0396s	
22551/26050 (epoch 43.284), train_loss = 0.78676987, grad/param norm = 2.2736e-01, time/batch = 18.1418s	
22552/26050 (epoch 43.286), train_loss = 0.84078883, grad/param norm = 2.4798e-01, time/batch = 17.9059s	
22553/26050 (epoch 43.288), train_loss = 0.67462370, grad/param norm = 1.7382e-01, time/batch = 18.6382s	
22554/26050 (epoch 43.290), train_loss = 0.78160811, grad/param norm = 2.1174e-01, time/batch = 15.3088s	
22555/26050 (epoch 43.292), train_loss = 0.72655288, grad/param norm = 2.0403e-01, time/batch = 17.2260s	
22556/26050 (epoch 43.294), train_loss = 0.77332190, grad/param norm = 2.2550e-01, time/batch = 17.4060s	
22557/26050 (epoch 43.296), train_loss = 0.85590795, grad/param norm = 2.2031e-01, time/batch = 17.9632s	
22558/26050 (epoch 43.298), train_loss = 0.82926814, grad/param norm = 2.0725e-01, time/batch = 17.6491s	
22559/26050 (epoch 43.299), train_loss = 0.67002799, grad/param norm = 2.0697e-01, time/batch = 17.2967s	
22560/26050 (epoch 43.301), train_loss = 0.68348646, grad/param norm = 2.4318e-01, time/batch = 15.8033s	
22561/26050 (epoch 43.303), train_loss = 0.79472523, grad/param norm = 2.5980e-01, time/batch = 18.8935s	
22562/26050 (epoch 43.305), train_loss = 0.64425095, grad/param norm = 1.9616e-01, time/batch = 17.9712s	
22563/26050 (epoch 43.307), train_loss = 0.67832245, grad/param norm = 2.1326e-01, time/batch = 14.4713s	
22564/26050 (epoch 43.309), train_loss = 0.81948927, grad/param norm = 2.2354e-01, time/batch = 18.7064s	
22565/26050 (epoch 43.311), train_loss = 0.80464515, grad/param norm = 2.9382e-01, time/batch = 17.0423s	
22566/26050 (epoch 43.313), train_loss = 0.77547840, grad/param norm = 2.5356e-01, time/batch = 18.1481s	
22567/26050 (epoch 43.315), train_loss = 0.85071019, grad/param norm = 2.4907e-01, time/batch = 18.1529s	
22568/26050 (epoch 43.317), train_loss = 0.78528277, grad/param norm = 2.2442e-01, time/batch = 16.4065s	
22569/26050 (epoch 43.319), train_loss = 0.73837313, grad/param norm = 2.1695e-01, time/batch = 18.2270s	
22570/26050 (epoch 43.321), train_loss = 0.79250005, grad/param norm = 2.1737e-01, time/batch = 18.3012s	
22571/26050 (epoch 43.322), train_loss = 0.85908409, grad/param norm = 2.3638e-01, time/batch = 17.2282s	
22572/26050 (epoch 43.324), train_loss = 0.63295028, grad/param norm = 2.1560e-01, time/batch = 14.6399s	
22573/26050 (epoch 43.326), train_loss = 0.90911050, grad/param norm = 3.9431e-01, time/batch = 18.1368s	
22574/26050 (epoch 43.328), train_loss = 0.82518772, grad/param norm = 2.1071e-01, time/batch = 18.1341s	
22575/26050 (epoch 43.330), train_loss = 0.69122339, grad/param norm = 2.1561e-01, time/batch = 15.7079s	
22576/26050 (epoch 43.332), train_loss = 0.84602240, grad/param norm = 2.2449e-01, time/batch = 18.4841s	
22577/26050 (epoch 43.334), train_loss = 0.70557906, grad/param norm = 2.5331e-01, time/batch = 16.6315s	
22578/26050 (epoch 43.336), train_loss = 0.76832280, grad/param norm = 2.2077e-01, time/batch = 18.1177s	
22579/26050 (epoch 43.338), train_loss = 0.67663862, grad/param norm = 1.8241e-01, time/batch = 17.0670s	
22580/26050 (epoch 43.340), train_loss = 0.81902988, grad/param norm = 2.1760e-01, time/batch = 18.5606s	
22581/26050 (epoch 43.342), train_loss = 0.87631792, grad/param norm = 2.1208e-01, time/batch = 18.3111s	
22582/26050 (epoch 43.344), train_loss = 0.70637404, grad/param norm = 2.1759e-01, time/batch = 17.1496s	
22583/26050 (epoch 43.345), train_loss = 0.76413389, grad/param norm = 2.2712e-01, time/batch = 16.1321s	
22584/26050 (epoch 43.347), train_loss = 0.89619492, grad/param norm = 2.1959e-01, time/batch = 18.0462s	
22585/26050 (epoch 43.349), train_loss = 0.83348289, grad/param norm = 2.0876e-01, time/batch = 16.9075s	
22586/26050 (epoch 43.351), train_loss = 0.79714721, grad/param norm = 2.1356e-01, time/batch = 15.9628s	
22587/26050 (epoch 43.353), train_loss = 0.77423685, grad/param norm = 2.1052e-01, time/batch = 18.2966s	
22588/26050 (epoch 43.355), train_loss = 0.79936375, grad/param norm = 2.4379e-01, time/batch = 17.9914s	
22589/26050 (epoch 43.357), train_loss = 0.73393539, grad/param norm = 2.0013e-01, time/batch = 19.2137s	
22590/26050 (epoch 43.359), train_loss = 0.88219062, grad/param norm = 2.3399e-01, time/batch = 34.3882s	
22591/26050 (epoch 43.361), train_loss = 0.70907529, grad/param norm = 1.9504e-01, time/batch = 20.7786s	
22592/26050 (epoch 43.363), train_loss = 0.84916231, grad/param norm = 2.2735e-01, time/batch = 17.1824s	
22593/26050 (epoch 43.365), train_loss = 0.77488452, grad/param norm = 2.1087e-01, time/batch = 18.6512s	
22594/26050 (epoch 43.367), train_loss = 0.83041743, grad/param norm = 1.9979e-01, time/batch = 17.8892s	
22595/26050 (epoch 43.369), train_loss = 0.68750674, grad/param norm = 1.7353e-01, time/batch = 18.0636s	
22596/26050 (epoch 43.370), train_loss = 0.67818852, grad/param norm = 1.8577e-01, time/batch = 16.4495s	
22597/26050 (epoch 43.372), train_loss = 0.77681343, grad/param norm = 2.2958e-01, time/batch = 17.9193s	
22598/26050 (epoch 43.374), train_loss = 0.89353005, grad/param norm = 2.1024e-01, time/batch = 17.7237s	
22599/26050 (epoch 43.376), train_loss = 0.90014127, grad/param norm = 2.5241e-01, time/batch = 17.9915s	
22600/26050 (epoch 43.378), train_loss = 0.75762532, grad/param norm = 2.0682e-01, time/batch = 16.0665s	
22601/26050 (epoch 43.380), train_loss = 0.89217895, grad/param norm = 2.4176e-01, time/batch = 17.0579s	
22602/26050 (epoch 43.382), train_loss = 0.96870918, grad/param norm = 2.5780e-01, time/batch = 18.2383s	
22603/26050 (epoch 43.384), train_loss = 0.75011461, grad/param norm = 2.6352e-01, time/batch = 18.4844s	
22604/26050 (epoch 43.386), train_loss = 0.85178138, grad/param norm = 2.7242e-01, time/batch = 18.8968s	
22605/26050 (epoch 43.388), train_loss = 0.80719880, grad/param norm = 2.3473e-01, time/batch = 17.6295s	
22606/26050 (epoch 43.390), train_loss = 0.72477697, grad/param norm = 1.7987e-01, time/batch = 17.2149s	
22607/26050 (epoch 43.392), train_loss = 0.68707552, grad/param norm = 2.1152e-01, time/batch = 17.0495s	
22608/26050 (epoch 43.393), train_loss = 0.87937414, grad/param norm = 3.2296e-01, time/batch = 14.7195s	
22609/26050 (epoch 43.395), train_loss = 0.84865699, grad/param norm = 2.3516e-01, time/batch = 16.4560s	
22610/26050 (epoch 43.397), train_loss = 0.83327256, grad/param norm = 2.1270e-01, time/batch = 16.1262s	
22611/26050 (epoch 43.399), train_loss = 0.75394600, grad/param norm = 2.4561e-01, time/batch = 18.8930s	
22612/26050 (epoch 43.401), train_loss = 0.79510027, grad/param norm = 2.0906e-01, time/batch = 17.4059s	
22613/26050 (epoch 43.403), train_loss = 0.79202063, grad/param norm = 2.4026e-01, time/batch = 19.0612s	
22614/26050 (epoch 43.405), train_loss = 0.80386241, grad/param norm = 2.3986e-01, time/batch = 18.1554s	
22615/26050 (epoch 43.407), train_loss = 0.91571660, grad/param norm = 2.4231e-01, time/batch = 17.7418s	
22616/26050 (epoch 43.409), train_loss = 0.91920583, grad/param norm = 2.8207e-01, time/batch = 18.6418s	
22617/26050 (epoch 43.411), train_loss = 0.87965922, grad/param norm = 2.1840e-01, time/batch = 17.3259s	
22618/26050 (epoch 43.413), train_loss = 0.98306190, grad/param norm = 2.2862e-01, time/batch = 16.9848s	
22619/26050 (epoch 43.415), train_loss = 0.97338816, grad/param norm = 2.5682e-01, time/batch = 18.3254s	
22620/26050 (epoch 43.417), train_loss = 0.94759570, grad/param norm = 2.4603e-01, time/batch = 18.6479s	
22621/26050 (epoch 43.418), train_loss = 0.85717643, grad/param norm = 2.8637e-01, time/batch = 15.4888s	
22622/26050 (epoch 43.420), train_loss = 0.70357420, grad/param norm = 2.1538e-01, time/batch = 16.9746s	
22623/26050 (epoch 43.422), train_loss = 0.68675065, grad/param norm = 2.2552e-01, time/batch = 15.8920s	
22624/26050 (epoch 43.424), train_loss = 0.90029230, grad/param norm = 2.7058e-01, time/batch = 17.6564s	
22625/26050 (epoch 43.426), train_loss = 0.85604126, grad/param norm = 2.6208e-01, time/batch = 17.6448s	
22626/26050 (epoch 43.428), train_loss = 0.78826341, grad/param norm = 2.2033e-01, time/batch = 18.4796s	
22627/26050 (epoch 43.430), train_loss = 0.95086182, grad/param norm = 2.4113e-01, time/batch = 18.4905s	
22628/26050 (epoch 43.432), train_loss = 0.77462587, grad/param norm = 2.3442e-01, time/batch = 18.6572s	
22629/26050 (epoch 43.434), train_loss = 0.76348726, grad/param norm = 2.3404e-01, time/batch = 17.2322s	
22630/26050 (epoch 43.436), train_loss = 0.88752090, grad/param norm = 2.4020e-01, time/batch = 18.3184s	
22631/26050 (epoch 43.438), train_loss = 0.83689904, grad/param norm = 2.8974e-01, time/batch = 18.8889s	
22632/26050 (epoch 43.440), train_loss = 0.83603115, grad/param norm = 2.1958e-01, time/batch = 14.5605s	
22633/26050 (epoch 43.441), train_loss = 0.83711879, grad/param norm = 2.3345e-01, time/batch = 18.2236s	
22634/26050 (epoch 43.443), train_loss = 0.71210483, grad/param norm = 1.9906e-01, time/batch = 17.6357s	
22635/26050 (epoch 43.445), train_loss = 0.72722056, grad/param norm = 2.2030e-01, time/batch = 15.5284s	
22636/26050 (epoch 43.447), train_loss = 0.91775855, grad/param norm = 2.1094e-01, time/batch = 17.9503s	
22637/26050 (epoch 43.449), train_loss = 0.73437227, grad/param norm = 2.2103e-01, time/batch = 15.2298s	
22638/26050 (epoch 43.451), train_loss = 0.92508321, grad/param norm = 2.2495e-01, time/batch = 18.7295s	
22639/26050 (epoch 43.453), train_loss = 0.78377332, grad/param norm = 2.0537e-01, time/batch = 16.8953s	
22640/26050 (epoch 43.455), train_loss = 0.80432113, grad/param norm = 2.0263e-01, time/batch = 17.3865s	
22641/26050 (epoch 43.457), train_loss = 0.78030341, grad/param norm = 2.2033e-01, time/batch = 17.2452s	
22642/26050 (epoch 43.459), train_loss = 0.86988997, grad/param norm = 2.3351e-01, time/batch = 17.9834s	
22643/26050 (epoch 43.461), train_loss = 0.87576246, grad/param norm = 2.1885e-01, time/batch = 18.3277s	
22644/26050 (epoch 43.463), train_loss = 0.75446263, grad/param norm = 1.9656e-01, time/batch = 18.6508s	
22645/26050 (epoch 43.464), train_loss = 0.81317187, grad/param norm = 2.3312e-01, time/batch = 18.0653s	
22646/26050 (epoch 43.466), train_loss = 0.80434528, grad/param norm = 2.3433e-01, time/batch = 18.3924s	
22647/26050 (epoch 43.468), train_loss = 0.90419060, grad/param norm = 2.0312e-01, time/batch = 18.4710s	
22648/26050 (epoch 43.470), train_loss = 0.89551753, grad/param norm = 2.6127e-01, time/batch = 16.5495s	
22649/26050 (epoch 43.472), train_loss = 0.89553376, grad/param norm = 2.4528e-01, time/batch = 15.7153s	
22650/26050 (epoch 43.474), train_loss = 0.93147125, grad/param norm = 2.4512e-01, time/batch = 15.8071s	
22651/26050 (epoch 43.476), train_loss = 0.87639274, grad/param norm = 2.1554e-01, time/batch = 18.2155s	
22652/26050 (epoch 43.478), train_loss = 0.78891544, grad/param norm = 2.1321e-01, time/batch = 17.9714s	
22653/26050 (epoch 43.480), train_loss = 0.76331522, grad/param norm = 2.0355e-01, time/batch = 18.6971s	
22654/26050 (epoch 43.482), train_loss = 0.76218788, grad/param norm = 1.8828e-01, time/batch = 18.3889s	
22655/26050 (epoch 43.484), train_loss = 0.76423679, grad/param norm = 2.3393e-01, time/batch = 18.5537s	
22656/26050 (epoch 43.486), train_loss = 0.91227882, grad/param norm = 2.7082e-01, time/batch = 17.2265s	
22657/26050 (epoch 43.488), train_loss = 0.95112922, grad/param norm = 2.6922e-01, time/batch = 18.0623s	
22658/26050 (epoch 43.489), train_loss = 0.97310353, grad/param norm = 2.9876e-01, time/batch = 17.6551s	
22659/26050 (epoch 43.491), train_loss = 0.74462219, grad/param norm = 2.3892e-01, time/batch = 16.4601s	
22660/26050 (epoch 43.493), train_loss = 0.82933402, grad/param norm = 2.2159e-01, time/batch = 17.9863s	
22661/26050 (epoch 43.495), train_loss = 0.79410895, grad/param norm = 1.8741e-01, time/batch = 17.9832s	
22662/26050 (epoch 43.497), train_loss = 0.73125684, grad/param norm = 2.0521e-01, time/batch = 15.2322s	
22663/26050 (epoch 43.499), train_loss = 0.73443978, grad/param norm = 2.1143e-01, time/batch = 17.3017s	
22664/26050 (epoch 43.501), train_loss = 0.89884153, grad/param norm = 2.2229e-01, time/batch = 14.9745s	
22665/26050 (epoch 43.503), train_loss = 0.76850337, grad/param norm = 2.1251e-01, time/batch = 17.8845s	
22666/26050 (epoch 43.505), train_loss = 0.91504703, grad/param norm = 2.3203e-01, time/batch = 17.9859s	
22667/26050 (epoch 43.507), train_loss = 0.88620759, grad/param norm = 2.4136e-01, time/batch = 15.5368s	
22668/26050 (epoch 43.509), train_loss = 0.91721765, grad/param norm = 2.0371e-01, time/batch = 18.2282s	
22669/26050 (epoch 43.511), train_loss = 0.79673488, grad/param norm = 2.0693e-01, time/batch = 18.6501s	
22670/26050 (epoch 43.512), train_loss = 0.70235500, grad/param norm = 2.2853e-01, time/batch = 18.2919s	
22671/26050 (epoch 43.514), train_loss = 0.86914083, grad/param norm = 2.5307e-01, time/batch = 17.6539s	
22672/26050 (epoch 43.516), train_loss = 0.94945916, grad/param norm = 2.5455e-01, time/batch = 18.5781s	
22673/26050 (epoch 43.518), train_loss = 0.79875748, grad/param norm = 1.9754e-01, time/batch = 17.3057s	
22674/26050 (epoch 43.520), train_loss = 0.80980094, grad/param norm = 2.0268e-01, time/batch = 17.5631s	
22675/26050 (epoch 43.522), train_loss = 0.64950780, grad/param norm = 2.0125e-01, time/batch = 17.1946s	
22676/26050 (epoch 43.524), train_loss = 0.89578967, grad/param norm = 2.8164e-01, time/batch = 15.8820s	
22677/26050 (epoch 43.526), train_loss = 0.90509455, grad/param norm = 2.7657e-01, time/batch = 15.2085s	
22678/26050 (epoch 43.528), train_loss = 0.83618064, grad/param norm = 2.3313e-01, time/batch = 15.6390s	
22679/26050 (epoch 43.530), train_loss = 0.78038927, grad/param norm = 2.3519e-01, time/batch = 18.4602s	
22680/26050 (epoch 43.532), train_loss = 0.85036511, grad/param norm = 2.1552e-01, time/batch = 17.9749s	
22681/26050 (epoch 43.534), train_loss = 0.82343520, grad/param norm = 2.7213e-01, time/batch = 18.5667s	
22682/26050 (epoch 43.536), train_loss = 0.85560845, grad/param norm = 2.2665e-01, time/batch = 18.1576s	
22683/26050 (epoch 43.537), train_loss = 0.89033802, grad/param norm = 2.2452e-01, time/batch = 17.4617s	
22684/26050 (epoch 43.539), train_loss = 0.84331181, grad/param norm = 2.3120e-01, time/batch = 18.6601s	
22685/26050 (epoch 43.541), train_loss = 0.96945572, grad/param norm = 2.6679e-01, time/batch = 15.8184s	
22686/26050 (epoch 43.543), train_loss = 0.64092293, grad/param norm = 2.1413e-01, time/batch = 17.9794s	
22687/26050 (epoch 43.545), train_loss = 0.80382844, grad/param norm = 2.3779e-01, time/batch = 17.5690s	
22688/26050 (epoch 43.547), train_loss = 0.74865657, grad/param norm = 2.1849e-01, time/batch = 18.1591s	
22689/26050 (epoch 43.549), train_loss = 0.70914384, grad/param norm = 2.7172e-01, time/batch = 18.1565s	
22690/26050 (epoch 43.551), train_loss = 0.87374052, grad/param norm = 2.4209e-01, time/batch = 17.4881s	
22691/26050 (epoch 43.553), train_loss = 0.78340437, grad/param norm = 2.2301e-01, time/batch = 18.2344s	
22692/26050 (epoch 43.555), train_loss = 0.69935591, grad/param norm = 2.1720e-01, time/batch = 17.8774s	
22693/26050 (epoch 43.557), train_loss = 0.81984838, grad/param norm = 1.9048e-01, time/batch = 17.7302s	
22694/26050 (epoch 43.559), train_loss = 0.83169037, grad/param norm = 2.2523e-01, time/batch = 18.2281s	
22695/26050 (epoch 43.560), train_loss = 0.78684382, grad/param norm = 2.5814e-01, time/batch = 15.5496s	
22696/26050 (epoch 43.562), train_loss = 0.80065176, grad/param norm = 2.4623e-01, time/batch = 17.5449s	
22697/26050 (epoch 43.564), train_loss = 0.95159510, grad/param norm = 2.3110e-01, time/batch = 16.5726s	
22698/26050 (epoch 43.566), train_loss = 0.76315935, grad/param norm = 2.0295e-01, time/batch = 18.5667s	
22699/26050 (epoch 43.568), train_loss = 0.83714166, grad/param norm = 2.4587e-01, time/batch = 14.4672s	
22700/26050 (epoch 43.570), train_loss = 0.81020173, grad/param norm = 2.3419e-01, time/batch = 17.5652s	
22701/26050 (epoch 43.572), train_loss = 0.83191183, grad/param norm = 2.5872e-01, time/batch = 18.2290s	
22702/26050 (epoch 43.574), train_loss = 0.83174019, grad/param norm = 2.4315e-01, time/batch = 17.8137s	
22703/26050 (epoch 43.576), train_loss = 0.84697651, grad/param norm = 2.8674e-01, time/batch = 15.1429s	
22704/26050 (epoch 43.578), train_loss = 0.80303590, grad/param norm = 2.6777e-01, time/batch = 17.4040s	
22705/26050 (epoch 43.580), train_loss = 0.71839036, grad/param norm = 2.2647e-01, time/batch = 16.1524s	
22706/26050 (epoch 43.582), train_loss = 0.82703040, grad/param norm = 2.2204e-01, time/batch = 18.3808s	
22707/26050 (epoch 43.583), train_loss = 0.86590013, grad/param norm = 2.3672e-01, time/batch = 17.8196s	
22708/26050 (epoch 43.585), train_loss = 0.72942679, grad/param norm = 2.4008e-01, time/batch = 17.9065s	
22709/26050 (epoch 43.587), train_loss = 0.83874270, grad/param norm = 2.4333e-01, time/batch = 18.2986s	
22710/26050 (epoch 43.589), train_loss = 0.95680962, grad/param norm = 2.6408e-01, time/batch = 16.4087s	
22711/26050 (epoch 43.591), train_loss = 0.83112264, grad/param norm = 2.3227e-01, time/batch = 15.3704s	
22712/26050 (epoch 43.593), train_loss = 0.70450430, grad/param norm = 2.5425e-01, time/batch = 18.2327s	
22713/26050 (epoch 43.595), train_loss = 0.85693571, grad/param norm = 2.7967e-01, time/batch = 18.2432s	
22714/26050 (epoch 43.597), train_loss = 0.83832905, grad/param norm = 2.4697e-01, time/batch = 17.4840s	
22715/26050 (epoch 43.599), train_loss = 0.87758173, grad/param norm = 2.2473e-01, time/batch = 17.3812s	
22716/26050 (epoch 43.601), train_loss = 0.96780201, grad/param norm = 2.5106e-01, time/batch = 17.5535s	
22717/26050 (epoch 43.603), train_loss = 0.87800173, grad/param norm = 2.4176e-01, time/batch = 18.2239s	
22718/26050 (epoch 43.605), train_loss = 0.80453339, grad/param norm = 2.3447e-01, time/batch = 14.5333s	
22719/26050 (epoch 43.607), train_loss = 0.90628249, grad/param norm = 2.9724e-01, time/batch = 17.7114s	
22720/26050 (epoch 43.608), train_loss = 0.74992925, grad/param norm = 2.0614e-01, time/batch = 17.3125s	
22721/26050 (epoch 43.610), train_loss = 0.81782062, grad/param norm = 2.2457e-01, time/batch = 14.9719s	
22722/26050 (epoch 43.612), train_loss = 0.78628374, grad/param norm = 2.4921e-01, time/batch = 18.3807s	
22723/26050 (epoch 43.614), train_loss = 0.83807311, grad/param norm = 2.6598e-01, time/batch = 18.8169s	
22724/26050 (epoch 43.616), train_loss = 0.85602613, grad/param norm = 2.4047e-01, time/batch = 18.2343s	
22725/26050 (epoch 43.618), train_loss = 0.76656835, grad/param norm = 2.2256e-01, time/batch = 9.1002s	
22726/26050 (epoch 43.620), train_loss = 0.88530635, grad/param norm = 2.3675e-01, time/batch = 0.6599s	
22727/26050 (epoch 43.622), train_loss = 0.74729875, grad/param norm = 2.1587e-01, time/batch = 0.6618s	
22728/26050 (epoch 43.624), train_loss = 0.67754948, grad/param norm = 1.9961e-01, time/batch = 0.6584s	
22729/26050 (epoch 43.626), train_loss = 0.84345773, grad/param norm = 2.2284e-01, time/batch = 0.6636s	
22730/26050 (epoch 43.628), train_loss = 0.78750255, grad/param norm = 2.9599e-01, time/batch = 0.6832s	
22731/26050 (epoch 43.630), train_loss = 0.95944999, grad/param norm = 2.3144e-01, time/batch = 0.6549s	
22732/26050 (epoch 43.631), train_loss = 0.95181247, grad/param norm = 2.7287e-01, time/batch = 0.6423s	
22733/26050 (epoch 43.633), train_loss = 0.74538169, grad/param norm = 2.4093e-01, time/batch = 0.9043s	
22734/26050 (epoch 43.635), train_loss = 0.76898490, grad/param norm = 1.8793e-01, time/batch = 0.9589s	
22735/26050 (epoch 43.637), train_loss = 0.72717267, grad/param norm = 2.0235e-01, time/batch = 0.9464s	
22736/26050 (epoch 43.639), train_loss = 0.85633862, grad/param norm = 2.0096e-01, time/batch = 0.9328s	
22737/26050 (epoch 43.641), train_loss = 0.75154456, grad/param norm = 2.1288e-01, time/batch = 0.9403s	
22738/26050 (epoch 43.643), train_loss = 0.75829251, grad/param norm = 2.1605e-01, time/batch = 1.4093s	
22739/26050 (epoch 43.645), train_loss = 0.78175962, grad/param norm = 2.2594e-01, time/batch = 1.7779s	
22740/26050 (epoch 43.647), train_loss = 0.71962646, grad/param norm = 2.3066e-01, time/batch = 1.7908s	
22741/26050 (epoch 43.649), train_loss = 0.78569426, grad/param norm = 2.6805e-01, time/batch = 16.2844s	
22742/26050 (epoch 43.651), train_loss = 0.78754394, grad/param norm = 2.2910e-01, time/batch = 17.4806s	
22743/26050 (epoch 43.653), train_loss = 0.79494417, grad/param norm = 2.4798e-01, time/batch = 17.6411s	
22744/26050 (epoch 43.655), train_loss = 0.73113128, grad/param norm = 2.2567e-01, time/batch = 17.9110s	
22745/26050 (epoch 43.656), train_loss = 0.71940539, grad/param norm = 1.9969e-01, time/batch = 17.4884s	
22746/26050 (epoch 43.658), train_loss = 0.95739897, grad/param norm = 2.4245e-01, time/batch = 17.4790s	
22747/26050 (epoch 43.660), train_loss = 0.68104107, grad/param norm = 2.3434e-01, time/batch = 18.3071s	
22748/26050 (epoch 43.662), train_loss = 0.80449489, grad/param norm = 2.2074e-01, time/batch = 15.3065s	
22749/26050 (epoch 43.664), train_loss = 0.79917429, grad/param norm = 2.3214e-01, time/batch = 18.3722s	
22750/26050 (epoch 43.666), train_loss = 0.77615129, grad/param norm = 2.2623e-01, time/batch = 15.2076s	
22751/26050 (epoch 43.668), train_loss = 0.63877515, grad/param norm = 2.7682e-01, time/batch = 18.3016s	
22752/26050 (epoch 43.670), train_loss = 0.93326819, grad/param norm = 2.8280e-01, time/batch = 18.3076s	
22753/26050 (epoch 43.672), train_loss = 0.78188725, grad/param norm = 1.9223e-01, time/batch = 17.6416s	
22754/26050 (epoch 43.674), train_loss = 0.71787169, grad/param norm = 2.4925e-01, time/batch = 17.2219s	
22755/26050 (epoch 43.676), train_loss = 0.84016409, grad/param norm = 2.2344e-01, time/batch = 18.1452s	
22756/26050 (epoch 43.678), train_loss = 0.88551998, grad/param norm = 2.4061e-01, time/batch = 16.5475s	
22757/26050 (epoch 43.679), train_loss = 0.92422471, grad/param norm = 2.7900e-01, time/batch = 17.7267s	
22758/26050 (epoch 43.681), train_loss = 0.81498169, grad/param norm = 2.0974e-01, time/batch = 18.1391s	
22759/26050 (epoch 43.683), train_loss = 0.74015309, grad/param norm = 2.7931e-01, time/batch = 15.9671s	
22760/26050 (epoch 43.685), train_loss = 0.76592254, grad/param norm = 2.4912e-01, time/batch = 15.0630s	
22761/26050 (epoch 43.687), train_loss = 0.70025338, grad/param norm = 2.1527e-01, time/batch = 16.0589s	
22762/26050 (epoch 43.689), train_loss = 0.74424470, grad/param norm = 2.0488e-01, time/batch = 15.3831s	
22763/26050 (epoch 43.691), train_loss = 0.65044384, grad/param norm = 1.6481e-01, time/batch = 17.9027s	
22764/26050 (epoch 43.693), train_loss = 0.76416956, grad/param norm = 2.5008e-01, time/batch = 18.0492s	
22765/26050 (epoch 43.695), train_loss = 0.80284833, grad/param norm = 2.2259e-01, time/batch = 18.0634s	
22766/26050 (epoch 43.697), train_loss = 0.72306322, grad/param norm = 2.0579e-01, time/batch = 18.2316s	
22767/26050 (epoch 43.699), train_loss = 0.84753667, grad/param norm = 2.2347e-01, time/batch = 17.1558s	
22768/26050 (epoch 43.701), train_loss = 0.72601978, grad/param norm = 2.0811e-01, time/batch = 18.3242s	
22769/26050 (epoch 43.702), train_loss = 0.88523027, grad/param norm = 2.5516e-01, time/batch = 17.8945s	
22770/26050 (epoch 43.704), train_loss = 0.91637810, grad/param norm = 2.1555e-01, time/batch = 17.4631s	
22771/26050 (epoch 43.706), train_loss = 0.75280355, grad/param norm = 2.2106e-01, time/batch = 18.3954s	
22772/26050 (epoch 43.708), train_loss = 0.87063929, grad/param norm = 2.2630e-01, time/batch = 15.7992s	
22773/26050 (epoch 43.710), train_loss = 0.83507552, grad/param norm = 2.5978e-01, time/batch = 16.0296s	
22774/26050 (epoch 43.712), train_loss = 0.78674307, grad/param norm = 2.2038e-01, time/batch = 16.4703s	
22775/26050 (epoch 43.714), train_loss = 0.72277874, grad/param norm = 1.9686e-01, time/batch = 18.7309s	
22776/26050 (epoch 43.716), train_loss = 1.00658045, grad/param norm = 2.8286e-01, time/batch = 16.2964s	
22777/26050 (epoch 43.718), train_loss = 0.85808179, grad/param norm = 2.1970e-01, time/batch = 17.8981s	
22778/26050 (epoch 43.720), train_loss = 0.78216881, grad/param norm = 2.0629e-01, time/batch = 17.6425s	
22779/26050 (epoch 43.722), train_loss = 0.74085837, grad/param norm = 2.1948e-01, time/batch = 18.6379s	
22780/26050 (epoch 43.724), train_loss = 0.74940163, grad/param norm = 2.0993e-01, time/batch = 15.0493s	
22781/26050 (epoch 43.726), train_loss = 0.86986619, grad/param norm = 2.3135e-01, time/batch = 17.0485s	
22782/26050 (epoch 43.727), train_loss = 0.84375634, grad/param norm = 2.3617e-01, time/batch = 16.2134s	
22783/26050 (epoch 43.729), train_loss = 0.83835713, grad/param norm = 1.9843e-01, time/batch = 17.8979s	
22784/26050 (epoch 43.731), train_loss = 0.84956687, grad/param norm = 2.2937e-01, time/batch = 17.4790s	
22785/26050 (epoch 43.733), train_loss = 0.77699495, grad/param norm = 2.5803e-01, time/batch = 16.0363s	
22786/26050 (epoch 43.735), train_loss = 0.90761966, grad/param norm = 2.1981e-01, time/batch = 18.5639s	
22787/26050 (epoch 43.737), train_loss = 0.77700872, grad/param norm = 2.6172e-01, time/batch = 17.9917s	
22788/26050 (epoch 43.739), train_loss = 0.83937663, grad/param norm = 2.1962e-01, time/batch = 17.8898s	
22789/26050 (epoch 43.741), train_loss = 0.74031664, grad/param norm = 2.0512e-01, time/batch = 18.1587s	
22790/26050 (epoch 43.743), train_loss = 0.80976076, grad/param norm = 2.7526e-01, time/batch = 15.1407s	
22791/26050 (epoch 43.745), train_loss = 0.71688582, grad/param norm = 2.1820e-01, time/batch = 17.8737s	
22792/26050 (epoch 43.747), train_loss = 0.75312569, grad/param norm = 2.1818e-01, time/batch = 18.2211s	
22793/26050 (epoch 43.749), train_loss = 0.90590975, grad/param norm = 2.4135e-01, time/batch = 18.0550s	
22794/26050 (epoch 43.750), train_loss = 0.75752840, grad/param norm = 1.9108e-01, time/batch = 17.7998s	
22795/26050 (epoch 43.752), train_loss = 0.75135068, grad/param norm = 2.2729e-01, time/batch = 17.5775s	
22796/26050 (epoch 43.754), train_loss = 0.81583171, grad/param norm = 2.3355e-01, time/batch = 17.7490s	
22797/26050 (epoch 43.756), train_loss = 0.79755079, grad/param norm = 3.7196e-01, time/batch = 18.8220s	
22798/26050 (epoch 43.758), train_loss = 0.80120221, grad/param norm = 2.6675e-01, time/batch = 17.2385s	
22799/26050 (epoch 43.760), train_loss = 0.94655773, grad/param norm = 3.1960e-01, time/batch = 18.0732s	
22800/26050 (epoch 43.762), train_loss = 0.79070771, grad/param norm = 2.3263e-01, time/batch = 15.3099s	
22801/26050 (epoch 43.764), train_loss = 0.78461264, grad/param norm = 2.6147e-01, time/batch = 16.2883s	
22802/26050 (epoch 43.766), train_loss = 0.78445737, grad/param norm = 2.5797e-01, time/batch = 15.4599s	
22803/26050 (epoch 43.768), train_loss = 0.69926132, grad/param norm = 2.1386e-01, time/batch = 17.1374s	
22804/26050 (epoch 43.770), train_loss = 0.79093638, grad/param norm = 2.4300e-01, time/batch = 17.9050s	
22805/26050 (epoch 43.772), train_loss = 0.80696507, grad/param norm = 2.2397e-01, time/batch = 17.8090s	
22806/26050 (epoch 43.774), train_loss = 0.67309796, grad/param norm = 2.1939e-01, time/batch = 17.9777s	
22807/26050 (epoch 43.775), train_loss = 0.58192450, grad/param norm = 2.3061e-01, time/batch = 17.8967s	
22808/26050 (epoch 43.777), train_loss = 0.76525983, grad/param norm = 2.2566e-01, time/batch = 15.9669s	
22809/26050 (epoch 43.779), train_loss = 0.78955271, grad/param norm = 2.8301e-01, time/batch = 31.6155s	
22810/26050 (epoch 43.781), train_loss = 0.72881359, grad/param norm = 2.2738e-01, time/batch = 32.0973s	
22811/26050 (epoch 43.783), train_loss = 0.70102860, grad/param norm = 2.0559e-01, time/batch = 16.6346s	
22812/26050 (epoch 43.785), train_loss = 0.78990700, grad/param norm = 2.6122e-01, time/batch = 16.9644s	
22813/26050 (epoch 43.787), train_loss = 0.73344328, grad/param norm = 2.3764e-01, time/batch = 17.8157s	
22814/26050 (epoch 43.789), train_loss = 0.73261696, grad/param norm = 2.6232e-01, time/batch = 17.8672s	
22815/26050 (epoch 43.791), train_loss = 0.73074091, grad/param norm = 2.5084e-01, time/batch = 17.7177s	
22816/26050 (epoch 43.793), train_loss = 0.79753482, grad/param norm = 2.3687e-01, time/batch = 18.4758s	
22817/26050 (epoch 43.795), train_loss = 0.64027092, grad/param norm = 1.8965e-01, time/batch = 15.9791s	
22818/26050 (epoch 43.797), train_loss = 0.71567145, grad/param norm = 2.2037e-01, time/batch = 17.1254s	
22819/26050 (epoch 43.798), train_loss = 0.80114442, grad/param norm = 2.5175e-01, time/batch = 16.3972s	
22820/26050 (epoch 43.800), train_loss = 0.66658074, grad/param norm = 2.0554e-01, time/batch = 17.9786s	
22821/26050 (epoch 43.802), train_loss = 0.77259206, grad/param norm = 2.6965e-01, time/batch = 18.0623s	
22822/26050 (epoch 43.804), train_loss = 0.79690323, grad/param norm = 2.2736e-01, time/batch = 17.8082s	
22823/26050 (epoch 43.806), train_loss = 0.84380231, grad/param norm = 2.3426e-01, time/batch = 18.4816s	
22824/26050 (epoch 43.808), train_loss = 0.81263751, grad/param norm = 2.4644e-01, time/batch = 16.1339s	
22825/26050 (epoch 43.810), train_loss = 0.80226117, grad/param norm = 3.0984e-01, time/batch = 18.5666s	
22826/26050 (epoch 43.812), train_loss = 0.68047054, grad/param norm = 2.7557e-01, time/batch = 17.9816s	
22827/26050 (epoch 43.814), train_loss = 0.69916310, grad/param norm = 2.6288e-01, time/batch = 17.8232s	
22828/26050 (epoch 43.816), train_loss = 0.82407866, grad/param norm = 2.5562e-01, time/batch = 14.8052s	
22829/26050 (epoch 43.818), train_loss = 0.86002932, grad/param norm = 2.6228e-01, time/batch = 18.2269s	
22830/26050 (epoch 43.820), train_loss = 0.81489138, grad/param norm = 2.5550e-01, time/batch = 18.6618s	
22831/26050 (epoch 43.821), train_loss = 0.88046442, grad/param norm = 2.3567e-01, time/batch = 17.9888s	
22832/26050 (epoch 43.823), train_loss = 0.98508064, grad/param norm = 2.4079e-01, time/batch = 16.8147s	
22833/26050 (epoch 43.825), train_loss = 0.79839769, grad/param norm = 2.3537e-01, time/batch = 18.2102s	
22834/26050 (epoch 43.827), train_loss = 0.79323196, grad/param norm = 2.7390e-01, time/batch = 16.9084s	
22835/26050 (epoch 43.829), train_loss = 0.91034406, grad/param norm = 2.6906e-01, time/batch = 18.4014s	
22836/26050 (epoch 43.831), train_loss = 0.93787904, grad/param norm = 2.3018e-01, time/batch = 18.0674s	
22837/26050 (epoch 43.833), train_loss = 0.88716977, grad/param norm = 2.5347e-01, time/batch = 17.6472s	
22838/26050 (epoch 43.835), train_loss = 0.92823500, grad/param norm = 2.5851e-01, time/batch = 15.3197s	
22839/26050 (epoch 43.837), train_loss = 0.83378103, grad/param norm = 2.0956e-01, time/batch = 18.0648s	
22840/26050 (epoch 43.839), train_loss = 0.78597378, grad/param norm = 2.3671e-01, time/batch = 18.0747s	
22841/26050 (epoch 43.841), train_loss = 0.84116496, grad/param norm = 2.3031e-01, time/batch = 17.1454s	
22842/26050 (epoch 43.843), train_loss = 0.78049377, grad/param norm = 2.2896e-01, time/batch = 14.8720s	
22843/26050 (epoch 43.845), train_loss = 0.75437812, grad/param norm = 2.3176e-01, time/batch = 17.6595s	
22844/26050 (epoch 43.846), train_loss = 0.82776464, grad/param norm = 2.2321e-01, time/batch = 16.3802s	
22845/26050 (epoch 43.848), train_loss = 0.76503363, grad/param norm = 2.3777e-01, time/batch = 18.2464s	
22846/26050 (epoch 43.850), train_loss = 0.70790689, grad/param norm = 1.9928e-01, time/batch = 18.3079s	
22847/26050 (epoch 43.852), train_loss = 0.82827577, grad/param norm = 2.3513e-01, time/batch = 18.0503s	
22848/26050 (epoch 43.854), train_loss = 0.79596080, grad/param norm = 2.2469e-01, time/batch = 17.8970s	
22849/26050 (epoch 43.856), train_loss = 0.74801412, grad/param norm = 2.2704e-01, time/batch = 15.9691s	
22850/26050 (epoch 43.858), train_loss = 0.72188631, grad/param norm = 2.1262e-01, time/batch = 17.9761s	
22851/26050 (epoch 43.860), train_loss = 0.83156553, grad/param norm = 3.0289e-01, time/batch = 17.0585s	
22852/26050 (epoch 43.862), train_loss = 0.87228550, grad/param norm = 2.1825e-01, time/batch = 18.0732s	
22853/26050 (epoch 43.864), train_loss = 0.79656202, grad/param norm = 2.9738e-01, time/batch = 14.7075s	
22854/26050 (epoch 43.866), train_loss = 0.78068110, grad/param norm = 2.0459e-01, time/batch = 18.3094s	
22855/26050 (epoch 43.868), train_loss = 0.85400019, grad/param norm = 2.7388e-01, time/batch = 18.1521s	
22856/26050 (epoch 43.869), train_loss = 0.73237354, grad/param norm = 1.9466e-01, time/batch = 17.8070s	
22857/26050 (epoch 43.871), train_loss = 0.67511394, grad/param norm = 2.0657e-01, time/batch = 17.3249s	
22858/26050 (epoch 43.873), train_loss = 0.84272963, grad/param norm = 2.3579e-01, time/batch = 17.5621s	
22859/26050 (epoch 43.875), train_loss = 0.74584788, grad/param norm = 2.3207e-01, time/batch = 16.3093s	
22860/26050 (epoch 43.877), train_loss = 0.75354326, grad/param norm = 1.9833e-01, time/batch = 18.2362s	
22861/26050 (epoch 43.879), train_loss = 0.85785208, grad/param norm = 2.2923e-01, time/batch = 17.7315s	
22862/26050 (epoch 43.881), train_loss = 0.86069761, grad/param norm = 2.4582e-01, time/batch = 15.3744s	
22863/26050 (epoch 43.883), train_loss = 0.86169326, grad/param norm = 2.4395e-01, time/batch = 17.8079s	
22864/26050 (epoch 43.885), train_loss = 0.62340500, grad/param norm = 2.0138e-01, time/batch = 18.7177s	
22865/26050 (epoch 43.887), train_loss = 0.88995539, grad/param norm = 2.4879e-01, time/batch = 16.7955s	
22866/26050 (epoch 43.889), train_loss = 0.73158709, grad/param norm = 2.1572e-01, time/batch = 18.5585s	
22867/26050 (epoch 43.891), train_loss = 0.66051201, grad/param norm = 2.1195e-01, time/batch = 18.4090s	
22868/26050 (epoch 43.893), train_loss = 0.66878159, grad/param norm = 2.0281e-01, time/batch = 17.4910s	
22869/26050 (epoch 43.894), train_loss = 0.73121938, grad/param norm = 2.1743e-01, time/batch = 18.0588s	
22870/26050 (epoch 43.896), train_loss = 0.85657270, grad/param norm = 2.2792e-01, time/batch = 18.0782s	
22871/26050 (epoch 43.898), train_loss = 0.74935909, grad/param norm = 2.3883e-01, time/batch = 17.2108s	
22872/26050 (epoch 43.900), train_loss = 0.83584642, grad/param norm = 2.4899e-01, time/batch = 17.9679s	
22873/26050 (epoch 43.902), train_loss = 0.75167291, grad/param norm = 2.0847e-01, time/batch = 18.1402s	
22874/26050 (epoch 43.904), train_loss = 0.78713748, grad/param norm = 2.2954e-01, time/batch = 18.1604s	
22875/26050 (epoch 43.906), train_loss = 0.75750144, grad/param norm = 2.8405e-01, time/batch = 17.5485s	
22876/26050 (epoch 43.908), train_loss = 0.83704542, grad/param norm = 2.2804e-01, time/batch = 14.2283s	
22877/26050 (epoch 43.910), train_loss = 0.74340915, grad/param norm = 2.3168e-01, time/batch = 17.9661s	
22878/26050 (epoch 43.912), train_loss = 0.94961107, grad/param norm = 2.5294e-01, time/batch = 17.9801s	
22879/26050 (epoch 43.914), train_loss = 1.07967538, grad/param norm = 2.8437e-01, time/batch = 18.4645s	
22880/26050 (epoch 43.916), train_loss = 0.84969168, grad/param norm = 2.4950e-01, time/batch = 17.9986s	
22881/26050 (epoch 43.917), train_loss = 0.81819807, grad/param norm = 2.1438e-01, time/batch = 19.0636s	
22882/26050 (epoch 43.919), train_loss = 0.83110305, grad/param norm = 2.5485e-01, time/batch = 18.2236s	
22883/26050 (epoch 43.921), train_loss = 0.73818502, grad/param norm = 2.3157e-01, time/batch = 18.3992s	
22884/26050 (epoch 43.923), train_loss = 0.81694554, grad/param norm = 2.3488e-01, time/batch = 18.2252s	
22885/26050 (epoch 43.925), train_loss = 0.80155941, grad/param norm = 2.1509e-01, time/batch = 16.0505s	
22886/26050 (epoch 43.927), train_loss = 0.73997474, grad/param norm = 1.8959e-01, time/batch = 18.4651s	
22887/26050 (epoch 43.929), train_loss = 0.66663980, grad/param norm = 1.9957e-01, time/batch = 17.7431s	
22888/26050 (epoch 43.931), train_loss = 0.93724033, grad/param norm = 2.6103e-01, time/batch = 17.2081s	
22889/26050 (epoch 43.933), train_loss = 0.79913921, grad/param norm = 2.3043e-01, time/batch = 17.6422s	
22890/26050 (epoch 43.935), train_loss = 0.76908990, grad/param norm = 2.0912e-01, time/batch = 18.1559s	
22891/26050 (epoch 43.937), train_loss = 0.86382231, grad/param norm = 2.2036e-01, time/batch = 18.8196s	
22892/26050 (epoch 43.939), train_loss = 0.73699526, grad/param norm = 1.9740e-01, time/batch = 16.1083s	
22893/26050 (epoch 43.940), train_loss = 0.80647044, grad/param norm = 2.1997e-01, time/batch = 16.6891s	
22894/26050 (epoch 43.942), train_loss = 0.73097912, grad/param norm = 2.0024e-01, time/batch = 17.7259s	
22895/26050 (epoch 43.944), train_loss = 0.77538826, grad/param norm = 2.1734e-01, time/batch = 16.9537s	
22896/26050 (epoch 43.946), train_loss = 0.93860250, grad/param norm = 2.3116e-01, time/batch = 18.6488s	
22897/26050 (epoch 43.948), train_loss = 0.67673835, grad/param norm = 2.1803e-01, time/batch = 18.4165s	
22898/26050 (epoch 43.950), train_loss = 0.81159337, grad/param norm = 2.4024e-01, time/batch = 18.1568s	
22899/26050 (epoch 43.952), train_loss = 0.83380150, grad/param norm = 2.2881e-01, time/batch = 15.7368s	
22900/26050 (epoch 43.954), train_loss = 0.85240624, grad/param norm = 2.7873e-01, time/batch = 18.5687s	
22901/26050 (epoch 43.956), train_loss = 0.75629954, grad/param norm = 2.3741e-01, time/batch = 18.0554s	
22902/26050 (epoch 43.958), train_loss = 0.72662770, grad/param norm = 2.2027e-01, time/batch = 17.6475s	
22903/26050 (epoch 43.960), train_loss = 0.82482067, grad/param norm = 2.2119e-01, time/batch = 18.5613s	
22904/26050 (epoch 43.962), train_loss = 0.79664252, grad/param norm = 2.1353e-01, time/batch = 15.5490s	
22905/26050 (epoch 43.964), train_loss = 0.75301366, grad/param norm = 2.0512e-01, time/batch = 18.0437s	
22906/26050 (epoch 43.965), train_loss = 0.72814966, grad/param norm = 2.3313e-01, time/batch = 18.2308s	
22907/26050 (epoch 43.967), train_loss = 1.04586573, grad/param norm = 2.3120e-01, time/batch = 18.2255s	
22908/26050 (epoch 43.969), train_loss = 0.78538745, grad/param norm = 1.8834e-01, time/batch = 18.0670s	
22909/26050 (epoch 43.971), train_loss = 0.81490483, grad/param norm = 2.3364e-01, time/batch = 16.9687s	
22910/26050 (epoch 43.973), train_loss = 0.81536241, grad/param norm = 2.4426e-01, time/batch = 14.9756s	
22911/26050 (epoch 43.975), train_loss = 0.79572208, grad/param norm = 2.0482e-01, time/batch = 18.0429s	
22912/26050 (epoch 43.977), train_loss = 0.79219079, grad/param norm = 2.0019e-01, time/batch = 17.8007s	
22913/26050 (epoch 43.979), train_loss = 0.64904888, grad/param norm = 2.0750e-01, time/batch = 18.3973s	
22914/26050 (epoch 43.981), train_loss = 0.87354391, grad/param norm = 2.0379e-01, time/batch = 14.8940s	
22915/26050 (epoch 43.983), train_loss = 0.83128343, grad/param norm = 2.1493e-01, time/batch = 18.4013s	
22916/26050 (epoch 43.985), train_loss = 0.82778649, grad/param norm = 2.3697e-01, time/batch = 15.2894s	
22917/26050 (epoch 43.987), train_loss = 0.89219517, grad/param norm = 2.2260e-01, time/batch = 17.9032s	
22918/26050 (epoch 43.988), train_loss = 0.84189583, grad/param norm = 2.9136e-01, time/batch = 17.9912s	
22919/26050 (epoch 43.990), train_loss = 0.68941645, grad/param norm = 1.9204e-01, time/batch = 18.1436s	
22920/26050 (epoch 43.992), train_loss = 0.92621013, grad/param norm = 2.4208e-01, time/batch = 17.1380s	
22921/26050 (epoch 43.994), train_loss = 0.74586240, grad/param norm = 2.2112e-01, time/batch = 17.4745s	
22922/26050 (epoch 43.996), train_loss = 0.69403740, grad/param norm = 2.2974e-01, time/batch = 18.1547s	
22923/26050 (epoch 43.998), train_loss = 0.80373837, grad/param norm = 2.2043e-01, time/batch = 18.4869s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
22924/26050 (epoch 44.000), train_loss = 0.72083802, grad/param norm = 2.1316e-01, time/batch = 15.2943s	
22925/26050 (epoch 44.002), train_loss = 0.87053338, grad/param norm = 2.4028e-01, time/batch = 17.8231s	
22926/26050 (epoch 44.004), train_loss = 0.70726439, grad/param norm = 2.1889e-01, time/batch = 17.2190s	
22927/26050 (epoch 44.006), train_loss = 0.75299467, grad/param norm = 2.3150e-01, time/batch = 18.7349s	
22928/26050 (epoch 44.008), train_loss = 0.71986469, grad/param norm = 2.1207e-01, time/batch = 17.5762s	
22929/26050 (epoch 44.010), train_loss = 0.72606341, grad/param norm = 2.1548e-01, time/batch = 18.2277s	
22930/26050 (epoch 44.012), train_loss = 0.77622372, grad/param norm = 2.1801e-01, time/batch = 18.4744s	
22931/26050 (epoch 44.013), train_loss = 1.00771109, grad/param norm = 4.1205e-01, time/batch = 18.0720s	
22932/26050 (epoch 44.015), train_loss = 0.78535208, grad/param norm = 2.3342e-01, time/batch = 18.0620s	
22933/26050 (epoch 44.017), train_loss = 0.80877998, grad/param norm = 1.8949e-01, time/batch = 18.1203s	
22934/26050 (epoch 44.019), train_loss = 0.69206983, grad/param norm = 1.7443e-01, time/batch = 17.8007s	
22935/26050 (epoch 44.021), train_loss = 0.84011020, grad/param norm = 2.0233e-01, time/batch = 14.3073s	
22936/26050 (epoch 44.023), train_loss = 0.66553452, grad/param norm = 2.3459e-01, time/batch = 14.5618s	
22937/26050 (epoch 44.025), train_loss = 0.79858712, grad/param norm = 2.1977e-01, time/batch = 17.2111s	
22938/26050 (epoch 44.027), train_loss = 0.61676803, grad/param norm = 2.0213e-01, time/batch = 17.8290s	
22939/26050 (epoch 44.029), train_loss = 0.84263076, grad/param norm = 2.0268e-01, time/batch = 18.3123s	
22940/26050 (epoch 44.031), train_loss = 0.89608426, grad/param norm = 2.4484e-01, time/batch = 18.3953s	
22941/26050 (epoch 44.033), train_loss = 0.79105921, grad/param norm = 2.2757e-01, time/batch = 16.1370s	
22942/26050 (epoch 44.035), train_loss = 0.81406668, grad/param norm = 1.8962e-01, time/batch = 15.8106s	
22943/26050 (epoch 44.036), train_loss = 0.69267850, grad/param norm = 2.3717e-01, time/batch = 16.5452s	
22944/26050 (epoch 44.038), train_loss = 0.64971045, grad/param norm = 2.0629e-01, time/batch = 18.5626s	
22945/26050 (epoch 44.040), train_loss = 0.77104696, grad/param norm = 2.2869e-01, time/batch = 18.4804s	
22946/26050 (epoch 44.042), train_loss = 0.68432699, grad/param norm = 2.1814e-01, time/batch = 17.3102s	
22947/26050 (epoch 44.044), train_loss = 0.84729538, grad/param norm = 1.9567e-01, time/batch = 18.3091s	
22948/26050 (epoch 44.046), train_loss = 0.66327555, grad/param norm = 1.8044e-01, time/batch = 18.3126s	
22949/26050 (epoch 44.048), train_loss = 0.78404171, grad/param norm = 2.0749e-01, time/batch = 16.0347s	
22950/26050 (epoch 44.050), train_loss = 0.75442362, grad/param norm = 2.0906e-01, time/batch = 17.1570s	
22951/26050 (epoch 44.052), train_loss = 0.74114250, grad/param norm = 2.2012e-01, time/batch = 14.7334s	
22952/26050 (epoch 44.054), train_loss = 0.65131724, grad/param norm = 2.0468e-01, time/batch = 14.3069s	
22953/26050 (epoch 44.056), train_loss = 0.65788761, grad/param norm = 1.7351e-01, time/batch = 14.5966s	
22954/26050 (epoch 44.058), train_loss = 0.76800288, grad/param norm = 2.0918e-01, time/batch = 15.4482s	
22955/26050 (epoch 44.060), train_loss = 0.83267771, grad/param norm = 2.3523e-01, time/batch = 14.3540s	
22956/26050 (epoch 44.061), train_loss = 0.68939600, grad/param norm = 2.3274e-01, time/batch = 15.3783s	
22957/26050 (epoch 44.063), train_loss = 0.79233429, grad/param norm = 2.2405e-01, time/batch = 15.9782s	
22958/26050 (epoch 44.065), train_loss = 0.64895617, grad/param norm = 1.7458e-01, time/batch = 17.8825s	
22959/26050 (epoch 44.067), train_loss = 0.77622272, grad/param norm = 2.1095e-01, time/batch = 17.7407s	
22960/26050 (epoch 44.069), train_loss = 0.81124407, grad/param norm = 2.6988e-01, time/batch = 18.0669s	
22961/26050 (epoch 44.071), train_loss = 0.80391195, grad/param norm = 2.5081e-01, time/batch = 17.5544s	
22962/26050 (epoch 44.073), train_loss = 0.93846423, grad/param norm = 2.2885e-01, time/batch = 17.4817s	
22963/26050 (epoch 44.075), train_loss = 0.75193873, grad/param norm = 2.2113e-01, time/batch = 16.7978s	
22964/26050 (epoch 44.077), train_loss = 0.74729059, grad/param norm = 2.2623e-01, time/batch = 18.2156s	
22965/26050 (epoch 44.079), train_loss = 0.75882100, grad/param norm = 2.4244e-01, time/batch = 16.8266s	
22966/26050 (epoch 44.081), train_loss = 0.75842581, grad/param norm = 2.1490e-01, time/batch = 15.4768s	
22967/26050 (epoch 44.083), train_loss = 0.87875509, grad/param norm = 2.0431e-01, time/batch = 17.8967s	
22968/26050 (epoch 44.084), train_loss = 0.80619586, grad/param norm = 2.6717e-01, time/batch = 16.5690s	
22969/26050 (epoch 44.086), train_loss = 0.90695795, grad/param norm = 2.6963e-01, time/batch = 18.1925s	
22970/26050 (epoch 44.088), train_loss = 0.78846222, grad/param norm = 2.1376e-01, time/batch = 16.4835s	
22971/26050 (epoch 44.090), train_loss = 0.83811070, grad/param norm = 2.5161e-01, time/batch = 15.4800s	
22972/26050 (epoch 44.092), train_loss = 0.84318257, grad/param norm = 2.1625e-01, time/batch = 17.7270s	
22973/26050 (epoch 44.094), train_loss = 0.66461798, grad/param norm = 2.8123e-01, time/batch = 18.3919s	
22974/26050 (epoch 44.096), train_loss = 0.83194358, grad/param norm = 2.2435e-01, time/batch = 18.0754s	
22975/26050 (epoch 44.098), train_loss = 0.79907096, grad/param norm = 2.4853e-01, time/batch = 17.3938s	
22976/26050 (epoch 44.100), train_loss = 0.70358650, grad/param norm = 1.9871e-01, time/batch = 18.5004s	
22977/26050 (epoch 44.102), train_loss = 0.80295977, grad/param norm = 2.5726e-01, time/batch = 17.8999s	
22978/26050 (epoch 44.104), train_loss = 0.76126972, grad/param norm = 2.4971e-01, time/batch = 15.1298s	
22979/26050 (epoch 44.106), train_loss = 0.82284877, grad/param norm = 2.2727e-01, time/batch = 18.1445s	
22980/26050 (epoch 44.107), train_loss = 0.66548206, grad/param norm = 1.8902e-01, time/batch = 18.5551s	
22981/26050 (epoch 44.109), train_loss = 0.72481144, grad/param norm = 1.9718e-01, time/batch = 17.6469s	
22982/26050 (epoch 44.111), train_loss = 0.92244288, grad/param norm = 2.6759e-01, time/batch = 18.1412s	
22983/26050 (epoch 44.113), train_loss = 0.76097739, grad/param norm = 2.0533e-01, time/batch = 18.0009s	
22984/26050 (epoch 44.115), train_loss = 0.85833698, grad/param norm = 2.1592e-01, time/batch = 17.7991s	
22985/26050 (epoch 44.117), train_loss = 0.77965826, grad/param norm = 2.1017e-01, time/batch = 17.0638s	
22986/26050 (epoch 44.119), train_loss = 0.69153547, grad/param norm = 2.0406e-01, time/batch = 18.6470s	
22987/26050 (epoch 44.121), train_loss = 0.77848804, grad/param norm = 2.0023e-01, time/batch = 17.4834s	
22988/26050 (epoch 44.123), train_loss = 0.73300239, grad/param norm = 2.4618e-01, time/batch = 15.7656s	
22989/26050 (epoch 44.125), train_loss = 0.68302183, grad/param norm = 2.3027e-01, time/batch = 17.8945s	
22990/26050 (epoch 44.127), train_loss = 0.66575468, grad/param norm = 2.3156e-01, time/batch = 18.3933s	
22991/26050 (epoch 44.129), train_loss = 0.62957423, grad/param norm = 2.4414e-01, time/batch = 17.1339s	
22992/26050 (epoch 44.131), train_loss = 0.78450996, grad/param norm = 2.3393e-01, time/batch = 17.9009s	
22993/26050 (epoch 44.132), train_loss = 0.78655824, grad/param norm = 2.0275e-01, time/batch = 18.2372s	
22994/26050 (epoch 44.134), train_loss = 0.81186500, grad/param norm = 2.3522e-01, time/batch = 17.2533s	
22995/26050 (epoch 44.136), train_loss = 0.75805569, grad/param norm = 2.1605e-01, time/batch = 17.3273s	
22996/26050 (epoch 44.138), train_loss = 0.54901678, grad/param norm = 2.0530e-01, time/batch = 15.5402s	
22997/26050 (epoch 44.140), train_loss = 0.63898754, grad/param norm = 2.0084e-01, time/batch = 18.2190s	
22998/26050 (epoch 44.142), train_loss = 0.65926039, grad/param norm = 2.1524e-01, time/batch = 17.9778s	
22999/26050 (epoch 44.144), train_loss = 0.64993507, grad/param norm = 2.4377e-01, time/batch = 17.4659s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch44.15_1.9522.t7	
23000/26050 (epoch 44.146), train_loss = 0.57270309, grad/param norm = 1.7849e-01, time/batch = 18.3210s	
23001/26050 (epoch 44.148), train_loss = 0.99867672, grad/param norm = 2.6783e-01, time/batch = 17.4792s	
23002/26050 (epoch 44.150), train_loss = 0.70102405, grad/param norm = 2.3517e-01, time/batch = 17.9020s	
23003/26050 (epoch 44.152), train_loss = 0.85769365, grad/param norm = 3.8511e-01, time/batch = 18.5574s	
23004/26050 (epoch 44.154), train_loss = 0.61281232, grad/param norm = 2.4923e-01, time/batch = 17.7318s	
23005/26050 (epoch 44.155), train_loss = 0.66133967, grad/param norm = 2.1560e-01, time/batch = 15.4802s	
23006/26050 (epoch 44.157), train_loss = 0.73624298, grad/param norm = 2.5197e-01, time/batch = 21.2455s	
23007/26050 (epoch 44.159), train_loss = 0.79603284, grad/param norm = 2.6085e-01, time/batch = 36.2377s	
23008/26050 (epoch 44.161), train_loss = 0.76758487, grad/param norm = 2.3426e-01, time/batch = 28.8154s	
23009/26050 (epoch 44.163), train_loss = 0.64911831, grad/param norm = 2.2105e-01, time/batch = 18.7380s	
23010/26050 (epoch 44.165), train_loss = 0.58718095, grad/param norm = 1.9040e-01, time/batch = 17.9885s	
23011/26050 (epoch 44.167), train_loss = 0.87792119, grad/param norm = 2.4224e-01, time/batch = 17.2364s	
23012/26050 (epoch 44.169), train_loss = 0.76249965, grad/param norm = 2.2675e-01, time/batch = 17.8195s	
23013/26050 (epoch 44.171), train_loss = 0.70910393, grad/param norm = 2.0739e-01, time/batch = 17.4796s	
23014/26050 (epoch 44.173), train_loss = 0.74405495, grad/param norm = 2.1597e-01, time/batch = 16.5467s	
23015/26050 (epoch 44.175), train_loss = 0.76829636, grad/param norm = 2.2383e-01, time/batch = 16.2375s	
23016/26050 (epoch 44.177), train_loss = 0.83205584, grad/param norm = 2.3516e-01, time/batch = 16.7862s	
23017/26050 (epoch 44.179), train_loss = 0.59229777, grad/param norm = 1.8718e-01, time/batch = 18.8059s	
23018/26050 (epoch 44.180), train_loss = 0.97372915, grad/param norm = 2.1706e-01, time/batch = 17.7346s	
23019/26050 (epoch 44.182), train_loss = 0.90272041, grad/param norm = 2.3596e-01, time/batch = 17.8169s	
23020/26050 (epoch 44.184), train_loss = 0.79303576, grad/param norm = 2.0749e-01, time/batch = 17.6585s	
23021/26050 (epoch 44.186), train_loss = 0.68293144, grad/param norm = 2.1016e-01, time/batch = 15.8021s	
23022/26050 (epoch 44.188), train_loss = 0.81346863, grad/param norm = 2.2729e-01, time/batch = 18.5443s	
23023/26050 (epoch 44.190), train_loss = 0.82359548, grad/param norm = 2.4396e-01, time/batch = 17.7299s	
23024/26050 (epoch 44.192), train_loss = 0.86716678, grad/param norm = 1.9795e-01, time/batch = 17.6386s	
23025/26050 (epoch 44.194), train_loss = 0.80095592, grad/param norm = 2.1600e-01, time/batch = 17.6624s	
23026/26050 (epoch 44.196), train_loss = 0.82759105, grad/param norm = 2.3105e-01, time/batch = 18.7255s	
23027/26050 (epoch 44.198), train_loss = 0.71485663, grad/param norm = 2.0953e-01, time/batch = 18.7226s	
23028/26050 (epoch 44.200), train_loss = 0.68941760, grad/param norm = 2.0378e-01, time/batch = 17.0386s	
23029/26050 (epoch 44.202), train_loss = 0.78406353, grad/param norm = 2.0840e-01, time/batch = 18.3002s	
23030/26050 (epoch 44.203), train_loss = 0.91059443, grad/param norm = 2.1392e-01, time/batch = 16.4584s	
23031/26050 (epoch 44.205), train_loss = 0.72498230, grad/param norm = 2.2573e-01, time/batch = 18.2279s	
23032/26050 (epoch 44.207), train_loss = 0.70138406, grad/param norm = 2.1781e-01, time/batch = 18.6324s	
23033/26050 (epoch 44.209), train_loss = 0.85590765, grad/param norm = 2.3351e-01, time/batch = 14.6074s	
23034/26050 (epoch 44.211), train_loss = 0.67473058, grad/param norm = 2.0220e-01, time/batch = 18.6428s	
23035/26050 (epoch 44.213), train_loss = 0.79193642, grad/param norm = 2.4027e-01, time/batch = 18.3891s	
23036/26050 (epoch 44.215), train_loss = 0.75354901, grad/param norm = 2.3990e-01, time/batch = 18.1431s	
23037/26050 (epoch 44.217), train_loss = 0.74530548, grad/param norm = 1.9805e-01, time/batch = 18.2397s	
23038/26050 (epoch 44.219), train_loss = 0.73701242, grad/param norm = 2.2669e-01, time/batch = 16.7148s	
23039/26050 (epoch 44.221), train_loss = 0.69363666, grad/param norm = 2.4054e-01, time/batch = 18.9810s	
23040/26050 (epoch 44.223), train_loss = 0.84568209, grad/param norm = 2.3462e-01, time/batch = 17.7320s	
23041/26050 (epoch 44.225), train_loss = 0.68962032, grad/param norm = 2.0180e-01, time/batch = 14.4896s	
23042/26050 (epoch 44.226), train_loss = 0.76983904, grad/param norm = 2.2322e-01, time/batch = 17.7438s	
23043/26050 (epoch 44.228), train_loss = 0.88414463, grad/param norm = 2.2729e-01, time/batch = 16.4581s	
23044/26050 (epoch 44.230), train_loss = 0.77888078, grad/param norm = 2.0895e-01, time/batch = 17.5706s	
23045/26050 (epoch 44.232), train_loss = 0.86861246, grad/param norm = 2.6119e-01, time/batch = 17.3958s	
23046/26050 (epoch 44.234), train_loss = 0.68805199, grad/param norm = 2.4086e-01, time/batch = 18.6428s	
23047/26050 (epoch 44.236), train_loss = 0.82790381, grad/param norm = 2.3036e-01, time/batch = 18.3051s	
23048/26050 (epoch 44.238), train_loss = 0.69124429, grad/param norm = 2.1315e-01, time/batch = 17.4662s	
23049/26050 (epoch 44.240), train_loss = 0.79238337, grad/param norm = 2.3040e-01, time/batch = 18.2393s	
23050/26050 (epoch 44.242), train_loss = 0.74965518, grad/param norm = 2.1995e-01, time/batch = 18.1475s	
23051/26050 (epoch 44.244), train_loss = 0.80297178, grad/param norm = 2.3125e-01, time/batch = 17.2103s	
23052/26050 (epoch 44.246), train_loss = 0.74070368, grad/param norm = 2.0636e-01, time/batch = 16.3132s	
23053/26050 (epoch 44.248), train_loss = 0.78293941, grad/param norm = 2.3698e-01, time/batch = 16.4684s	
23054/26050 (epoch 44.250), train_loss = 0.78409820, grad/param norm = 2.4127e-01, time/batch = 18.7205s	
23055/26050 (epoch 44.251), train_loss = 0.73900042, grad/param norm = 2.2054e-01, time/batch = 17.4789s	
23056/26050 (epoch 44.253), train_loss = 0.65817981, grad/param norm = 1.8724e-01, time/batch = 18.5389s	
23057/26050 (epoch 44.255), train_loss = 0.93156244, grad/param norm = 2.5026e-01, time/batch = 16.4599s	
23058/26050 (epoch 44.257), train_loss = 0.80490353, grad/param norm = 2.3531e-01, time/batch = 17.8748s	
23059/26050 (epoch 44.259), train_loss = 0.85138771, grad/param norm = 2.2085e-01, time/batch = 18.3177s	
23060/26050 (epoch 44.261), train_loss = 0.69690752, grad/param norm = 2.1813e-01, time/batch = 18.1552s	
23061/26050 (epoch 44.263), train_loss = 0.86643022, grad/param norm = 2.5152e-01, time/batch = 18.0788s	
23062/26050 (epoch 44.265), train_loss = 0.88604941, grad/param norm = 2.8606e-01, time/batch = 16.9004s	
23063/26050 (epoch 44.267), train_loss = 0.89980052, grad/param norm = 2.1411e-01, time/batch = 18.1486s	
23064/26050 (epoch 44.269), train_loss = 0.88812890, grad/param norm = 2.3963e-01, time/batch = 18.5596s	
23065/26050 (epoch 44.271), train_loss = 0.77555349, grad/param norm = 2.2483e-01, time/batch = 16.9060s	
23066/26050 (epoch 44.273), train_loss = 0.69943830, grad/param norm = 2.0349e-01, time/batch = 16.6301s	
23067/26050 (epoch 44.274), train_loss = 0.74392163, grad/param norm = 2.0300e-01, time/batch = 17.4040s	
23068/26050 (epoch 44.276), train_loss = 0.75848180, grad/param norm = 2.3527e-01, time/batch = 18.1488s	
23069/26050 (epoch 44.278), train_loss = 0.85926961, grad/param norm = 2.1303e-01, time/batch = 18.7333s	
23070/26050 (epoch 44.280), train_loss = 0.76159712, grad/param norm = 2.1128e-01, time/batch = 17.3308s	
23071/26050 (epoch 44.282), train_loss = 0.86713494, grad/param norm = 2.4332e-01, time/batch = 14.9677s	
23072/26050 (epoch 44.284), train_loss = 0.77312505, grad/param norm = 2.0873e-01, time/batch = 17.2199s	
23073/26050 (epoch 44.286), train_loss = 0.82327462, grad/param norm = 2.3727e-01, time/batch = 18.4596s	
23074/26050 (epoch 44.288), train_loss = 0.66877513, grad/param norm = 2.2676e-01, time/batch = 17.3084s	
23075/26050 (epoch 44.290), train_loss = 0.78075674, grad/param norm = 2.1283e-01, time/batch = 18.0566s	
23076/26050 (epoch 44.292), train_loss = 0.72264071, grad/param norm = 2.3637e-01, time/batch = 18.5573s	
23077/26050 (epoch 44.294), train_loss = 0.79901217, grad/param norm = 2.6803e-01, time/batch = 15.3503s	
23078/26050 (epoch 44.296), train_loss = 0.84522574, grad/param norm = 2.1414e-01, time/batch = 18.4772s	
23079/26050 (epoch 44.298), train_loss = 0.84106651, grad/param norm = 2.2573e-01, time/batch = 17.1355s	
23080/26050 (epoch 44.299), train_loss = 0.66099722, grad/param norm = 1.9288e-01, time/batch = 15.6343s	
23081/26050 (epoch 44.301), train_loss = 0.67476850, grad/param norm = 2.1933e-01, time/batch = 17.5512s	
23082/26050 (epoch 44.303), train_loss = 0.77407943, grad/param norm = 2.4132e-01, time/batch = 18.0594s	
23083/26050 (epoch 44.305), train_loss = 0.63600936, grad/param norm = 2.0454e-01, time/batch = 18.2327s	
23084/26050 (epoch 44.307), train_loss = 0.68858454, grad/param norm = 2.4019e-01, time/batch = 17.8038s	
23085/26050 (epoch 44.309), train_loss = 0.81020879, grad/param norm = 2.1056e-01, time/batch = 18.1460s	
23086/26050 (epoch 44.311), train_loss = 0.78555110, grad/param norm = 2.5020e-01, time/batch = 18.1502s	
23087/26050 (epoch 44.313), train_loss = 0.74477840, grad/param norm = 2.0816e-01, time/batch = 17.6402s	
23088/26050 (epoch 44.315), train_loss = 0.84352269, grad/param norm = 2.2842e-01, time/batch = 18.4876s	
23089/26050 (epoch 44.317), train_loss = 0.78663075, grad/param norm = 2.4425e-01, time/batch = 17.6487s	
23090/26050 (epoch 44.319), train_loss = 0.73474894, grad/param norm = 2.2514e-01, time/batch = 17.7324s	
23091/26050 (epoch 44.321), train_loss = 0.80249823, grad/param norm = 2.2768e-01, time/batch = 18.1402s	
23092/26050 (epoch 44.322), train_loss = 0.85221814, grad/param norm = 2.2851e-01, time/batch = 17.9820s	
23093/26050 (epoch 44.324), train_loss = 0.63125656, grad/param norm = 2.1406e-01, time/batch = 18.6505s	
23094/26050 (epoch 44.326), train_loss = 0.89423634, grad/param norm = 2.4394e-01, time/batch = 18.6472s	
23095/26050 (epoch 44.328), train_loss = 0.82229306, grad/param norm = 2.2743e-01, time/batch = 18.1537s	
23096/26050 (epoch 44.330), train_loss = 0.68303411, grad/param norm = 2.3093e-01, time/batch = 17.8827s	
23097/26050 (epoch 44.332), train_loss = 0.84058120, grad/param norm = 2.4755e-01, time/batch = 16.7175s	
23098/26050 (epoch 44.334), train_loss = 0.68832610, grad/param norm = 2.1329e-01, time/batch = 18.2848s	
23099/26050 (epoch 44.336), train_loss = 0.76572948, grad/param norm = 2.2822e-01, time/batch = 14.3857s	
23100/26050 (epoch 44.338), train_loss = 0.68244497, grad/param norm = 1.9879e-01, time/batch = 16.8817s	
23101/26050 (epoch 44.340), train_loss = 0.81720742, grad/param norm = 2.3595e-01, time/batch = 14.2751s	
23102/26050 (epoch 44.342), train_loss = 0.86664637, grad/param norm = 2.1945e-01, time/batch = 13.7719s	
23103/26050 (epoch 44.344), train_loss = 0.71546867, grad/param norm = 2.3434e-01, time/batch = 13.7602s	
23104/26050 (epoch 44.345), train_loss = 0.76734405, grad/param norm = 3.0889e-01, time/batch = 13.8244s	
23105/26050 (epoch 44.347), train_loss = 0.88545004, grad/param norm = 2.3573e-01, time/batch = 13.9087s	
23106/26050 (epoch 44.349), train_loss = 0.83712874, grad/param norm = 2.6177e-01, time/batch = 13.7672s	
23107/26050 (epoch 44.351), train_loss = 0.80145436, grad/param norm = 2.7430e-01, time/batch = 13.8372s	
23108/26050 (epoch 44.353), train_loss = 0.77815276, grad/param norm = 2.2020e-01, time/batch = 13.7706s	
23109/26050 (epoch 44.355), train_loss = 0.80253101, grad/param norm = 2.7435e-01, time/batch = 13.8432s	
23110/26050 (epoch 44.357), train_loss = 0.73882320, grad/param norm = 2.2135e-01, time/batch = 14.2318s	
23111/26050 (epoch 44.359), train_loss = 0.87816892, grad/param norm = 2.3579e-01, time/batch = 13.9164s	
23112/26050 (epoch 44.361), train_loss = 0.69281010, grad/param norm = 1.8978e-01, time/batch = 14.1534s	
23113/26050 (epoch 44.363), train_loss = 0.85354524, grad/param norm = 2.2729e-01, time/batch = 13.8455s	
23114/26050 (epoch 44.365), train_loss = 0.75554402, grad/param norm = 2.0351e-01, time/batch = 14.3597s	
23115/26050 (epoch 44.367), train_loss = 0.82252311, grad/param norm = 2.3266e-01, time/batch = 13.7706s	
23116/26050 (epoch 44.369), train_loss = 0.68745977, grad/param norm = 1.9298e-01, time/batch = 13.8425s	
23117/26050 (epoch 44.370), train_loss = 0.68834031, grad/param norm = 1.9448e-01, time/batch = 13.9211s	
23118/26050 (epoch 44.372), train_loss = 0.75863610, grad/param norm = 2.3938e-01, time/batch = 13.6874s	
23119/26050 (epoch 44.374), train_loss = 0.89083914, grad/param norm = 2.1389e-01, time/batch = 13.8406s	
23120/26050 (epoch 44.376), train_loss = 0.88723968, grad/param norm = 2.7173e-01, time/batch = 13.8393s	
23121/26050 (epoch 44.378), train_loss = 0.75638712, grad/param norm = 2.1286e-01, time/batch = 13.8446s	
23122/26050 (epoch 44.380), train_loss = 0.88233377, grad/param norm = 2.3330e-01, time/batch = 13.7662s	
23123/26050 (epoch 44.382), train_loss = 0.95705909, grad/param norm = 2.9742e-01, time/batch = 13.7684s	
23124/26050 (epoch 44.384), train_loss = 0.74842705, grad/param norm = 2.1363e-01, time/batch = 13.6877s	
23125/26050 (epoch 44.386), train_loss = 0.85197171, grad/param norm = 2.7201e-01, time/batch = 13.7733s	
23126/26050 (epoch 44.388), train_loss = 0.80778224, grad/param norm = 2.2307e-01, time/batch = 13.8428s	
23127/26050 (epoch 44.390), train_loss = 0.72203480, grad/param norm = 2.0562e-01, time/batch = 13.7549s	
23128/26050 (epoch 44.392), train_loss = 0.67449614, grad/param norm = 2.0195e-01, time/batch = 13.7618s	
23129/26050 (epoch 44.393), train_loss = 0.85674338, grad/param norm = 2.6616e-01, time/batch = 14.0795s	
23130/26050 (epoch 44.395), train_loss = 0.83622778, grad/param norm = 2.3487e-01, time/batch = 13.7655s	
23131/26050 (epoch 44.397), train_loss = 0.83043712, grad/param norm = 2.6290e-01, time/batch = 13.7696s	
23132/26050 (epoch 44.399), train_loss = 0.75743565, grad/param norm = 2.5540e-01, time/batch = 13.8459s	
23133/26050 (epoch 44.401), train_loss = 0.78989701, grad/param norm = 2.3493e-01, time/batch = 13.8412s	
23134/26050 (epoch 44.403), train_loss = 0.78440798, grad/param norm = 2.4871e-01, time/batch = 13.6872s	
23135/26050 (epoch 44.405), train_loss = 0.80043322, grad/param norm = 2.4535e-01, time/batch = 14.1998s	
23136/26050 (epoch 44.407), train_loss = 0.90908266, grad/param norm = 2.3769e-01, time/batch = 13.8430s	
23137/26050 (epoch 44.409), train_loss = 0.89834255, grad/param norm = 2.6962e-01, time/batch = 13.6749s	
23138/26050 (epoch 44.411), train_loss = 0.86863727, grad/param norm = 2.5036e-01, time/batch = 13.7667s	
23139/26050 (epoch 44.413), train_loss = 0.98021693, grad/param norm = 2.3929e-01, time/batch = 13.8486s	
23140/26050 (epoch 44.415), train_loss = 0.94481087, grad/param norm = 2.5371e-01, time/batch = 13.9999s	
23141/26050 (epoch 44.417), train_loss = 0.94626115, grad/param norm = 2.5367e-01, time/batch = 14.3937s	
23142/26050 (epoch 44.418), train_loss = 0.84374336, grad/param norm = 2.5913e-01, time/batch = 13.9101s	
23143/26050 (epoch 44.420), train_loss = 0.68405837, grad/param norm = 2.1969e-01, time/batch = 13.8233s	
23144/26050 (epoch 44.422), train_loss = 0.68084863, grad/param norm = 2.0855e-01, time/batch = 13.8441s	
23145/26050 (epoch 44.424), train_loss = 0.88003552, grad/param norm = 2.4452e-01, time/batch = 13.6878s	
23146/26050 (epoch 44.426), train_loss = 0.84767483, grad/param norm = 2.6745e-01, time/batch = 13.8422s	
23147/26050 (epoch 44.428), train_loss = 0.77468354, grad/param norm = 2.0675e-01, time/batch = 13.7692s	
23148/26050 (epoch 44.430), train_loss = 0.96030256, grad/param norm = 2.6120e-01, time/batch = 13.6884s	
23149/26050 (epoch 44.432), train_loss = 0.76091105, grad/param norm = 2.0629e-01, time/batch = 13.6932s	
23150/26050 (epoch 44.434), train_loss = 0.75691160, grad/param norm = 2.2755e-01, time/batch = 13.9251s	
23151/26050 (epoch 44.436), train_loss = 0.84923122, grad/param norm = 2.2727e-01, time/batch = 13.8480s	
23152/26050 (epoch 44.438), train_loss = 0.81876245, grad/param norm = 2.3482e-01, time/batch = 14.1337s	
23153/26050 (epoch 44.440), train_loss = 0.82579272, grad/param norm = 2.0698e-01, time/batch = 13.9858s	
23154/26050 (epoch 44.441), train_loss = 0.83745981, grad/param norm = 2.2408e-01, time/batch = 13.6884s	
23155/26050 (epoch 44.443), train_loss = 0.71204569, grad/param norm = 2.0126e-01, time/batch = 14.0027s	
23156/26050 (epoch 44.445), train_loss = 0.71930962, grad/param norm = 2.3711e-01, time/batch = 13.7667s	
23157/26050 (epoch 44.447), train_loss = 0.92328823, grad/param norm = 2.5027e-01, time/batch = 13.6887s	
23158/26050 (epoch 44.449), train_loss = 0.71503477, grad/param norm = 2.0991e-01, time/batch = 13.6815s	
23159/26050 (epoch 44.451), train_loss = 0.93189039, grad/param norm = 2.6081e-01, time/batch = 13.7574s	
23160/26050 (epoch 44.453), train_loss = 0.77125951, grad/param norm = 2.0350e-01, time/batch = 13.7513s	
23161/26050 (epoch 44.455), train_loss = 0.80456264, grad/param norm = 2.2832e-01, time/batch = 13.7574s	
23162/26050 (epoch 44.457), train_loss = 0.76877551, grad/param norm = 2.2652e-01, time/batch = 13.6870s	
23163/26050 (epoch 44.459), train_loss = 0.85557748, grad/param norm = 2.3599e-01, time/batch = 13.9262s	
23164/26050 (epoch 44.461), train_loss = 0.86721186, grad/param norm = 2.2958e-01, time/batch = 13.7626s	
23165/26050 (epoch 44.463), train_loss = 0.75581205, grad/param norm = 2.1028e-01, time/batch = 13.7701s	
23166/26050 (epoch 44.464), train_loss = 0.80981375, grad/param norm = 2.3989e-01, time/batch = 13.7710s	
23167/26050 (epoch 44.466), train_loss = 0.78478308, grad/param norm = 2.3010e-01, time/batch = 13.6909s	
23168/26050 (epoch 44.468), train_loss = 0.88771757, grad/param norm = 2.1646e-01, time/batch = 13.8356s	
23169/26050 (epoch 44.470), train_loss = 0.86586341, grad/param norm = 2.2129e-01, time/batch = 13.8502s	
23170/26050 (epoch 44.472), train_loss = 0.89525947, grad/param norm = 2.8932e-01, time/batch = 14.1462s	
23171/26050 (epoch 44.474), train_loss = 0.92186926, grad/param norm = 2.6896e-01, time/batch = 13.9231s	
23172/26050 (epoch 44.476), train_loss = 0.86434410, grad/param norm = 1.9654e-01, time/batch = 14.0033s	
23173/26050 (epoch 44.478), train_loss = 0.78956919, grad/param norm = 2.3495e-01, time/batch = 13.7655s	
23174/26050 (epoch 44.480), train_loss = 0.76341587, grad/param norm = 1.9028e-01, time/batch = 13.8098s	
23175/26050 (epoch 44.482), train_loss = 0.76357188, grad/param norm = 2.3076e-01, time/batch = 13.7756s	
23176/26050 (epoch 44.484), train_loss = 0.74465793, grad/param norm = 2.4495e-01, time/batch = 13.7663s	
23177/26050 (epoch 44.486), train_loss = 0.90111682, grad/param norm = 2.4211e-01, time/batch = 14.0602s	
23178/26050 (epoch 44.488), train_loss = 0.94530693, grad/param norm = 2.7447e-01, time/batch = 13.7740s	
23179/26050 (epoch 44.489), train_loss = 0.97523794, grad/param norm = 2.6726e-01, time/batch = 13.7623s	
23180/26050 (epoch 44.491), train_loss = 0.73743507, grad/param norm = 2.4320e-01, time/batch = 13.6744s	
23181/26050 (epoch 44.493), train_loss = 0.81248463, grad/param norm = 2.2265e-01, time/batch = 13.8384s	
23182/26050 (epoch 44.495), train_loss = 0.79939060, grad/param norm = 2.0179e-01, time/batch = 13.8476s	
23183/26050 (epoch 44.497), train_loss = 0.72831860, grad/param norm = 2.1256e-01, time/batch = 13.8966s	
23184/26050 (epoch 44.499), train_loss = 0.73897445, grad/param norm = 2.4466e-01, time/batch = 14.0767s	
23185/26050 (epoch 44.501), train_loss = 0.89561450, grad/param norm = 2.0993e-01, time/batch = 14.0820s	
23186/26050 (epoch 44.503), train_loss = 0.75665042, grad/param norm = 2.1346e-01, time/batch = 13.8463s	
23187/26050 (epoch 44.505), train_loss = 0.90475840, grad/param norm = 2.4678e-01, time/batch = 13.8242s	
23188/26050 (epoch 44.507), train_loss = 0.88971899, grad/param norm = 2.8188e-01, time/batch = 14.0514s	
23189/26050 (epoch 44.509), train_loss = 0.91494310, grad/param norm = 2.3661e-01, time/batch = 14.3776s	
23190/26050 (epoch 44.511), train_loss = 0.78347704, grad/param norm = 2.0560e-01, time/batch = 13.7695s	
23191/26050 (epoch 44.512), train_loss = 0.68915533, grad/param norm = 2.1503e-01, time/batch = 13.9232s	
23192/26050 (epoch 44.514), train_loss = 0.84228891, grad/param norm = 2.2551e-01, time/batch = 13.6811s	
23193/26050 (epoch 44.516), train_loss = 0.91735455, grad/param norm = 2.3297e-01, time/batch = 13.8361s	
23194/26050 (epoch 44.518), train_loss = 0.79246586, grad/param norm = 2.0539e-01, time/batch = 13.7591s	
23195/26050 (epoch 44.520), train_loss = 0.80745349, grad/param norm = 2.0434e-01, time/batch = 13.8512s	
23196/26050 (epoch 44.522), train_loss = 0.63610038, grad/param norm = 2.0305e-01, time/batch = 13.7675s	
23197/26050 (epoch 44.524), train_loss = 0.87913915, grad/param norm = 2.5751e-01, time/batch = 13.7702s	
23198/26050 (epoch 44.526), train_loss = 0.89270333, grad/param norm = 2.4885e-01, time/batch = 13.8420s	
23199/26050 (epoch 44.528), train_loss = 0.82793761, grad/param norm = 2.4013e-01, time/batch = 13.8518s	
23200/26050 (epoch 44.530), train_loss = 0.76904581, grad/param norm = 2.5357e-01, time/batch = 13.9821s	
23201/26050 (epoch 44.532), train_loss = 0.85718506, grad/param norm = 2.1736e-01, time/batch = 13.9187s	
23202/26050 (epoch 44.534), train_loss = 0.84148068, grad/param norm = 3.1891e-01, time/batch = 14.0636s	
23203/26050 (epoch 44.536), train_loss = 0.83734543, grad/param norm = 2.1842e-01, time/batch = 13.9194s	
23204/26050 (epoch 44.537), train_loss = 0.89422204, grad/param norm = 2.3994e-01, time/batch = 14.3909s	
23205/26050 (epoch 44.539), train_loss = 0.83900608, grad/param norm = 2.2967e-01, time/batch = 13.6734s	
23206/26050 (epoch 44.541), train_loss = 0.94890050, grad/param norm = 2.7722e-01, time/batch = 13.7685s	
23207/26050 (epoch 44.543), train_loss = 0.62973365, grad/param norm = 2.2985e-01, time/batch = 13.8332s	
23208/26050 (epoch 44.545), train_loss = 0.79392977, grad/param norm = 2.1533e-01, time/batch = 13.6807s	
23209/26050 (epoch 44.547), train_loss = 0.75198557, grad/param norm = 2.1793e-01, time/batch = 13.8536s	
23210/26050 (epoch 44.549), train_loss = 0.70394369, grad/param norm = 2.3271e-01, time/batch = 13.6806s	
23211/26050 (epoch 44.551), train_loss = 0.86070224, grad/param norm = 2.2806e-01, time/batch = 13.9209s	
23212/26050 (epoch 44.553), train_loss = 0.77263695, grad/param norm = 2.2673e-01, time/batch = 13.8482s	
23213/26050 (epoch 44.555), train_loss = 0.68947459, grad/param norm = 2.1901e-01, time/batch = 13.8192s	
23214/26050 (epoch 44.557), train_loss = 0.81311168, grad/param norm = 1.9473e-01, time/batch = 13.8540s	
23215/26050 (epoch 44.559), train_loss = 0.83463807, grad/param norm = 2.1704e-01, time/batch = 14.0040s	
23216/26050 (epoch 44.560), train_loss = 0.78257346, grad/param norm = 2.4363e-01, time/batch = 13.8521s	
23217/26050 (epoch 44.562), train_loss = 0.80678104, grad/param norm = 2.8722e-01, time/batch = 13.6838s	
23218/26050 (epoch 44.564), train_loss = 0.94581811, grad/param norm = 2.3027e-01, time/batch = 13.8409s	
23219/26050 (epoch 44.566), train_loss = 0.76355437, grad/param norm = 2.2575e-01, time/batch = 13.7605s	
23220/26050 (epoch 44.568), train_loss = 0.83504773, grad/param norm = 2.8441e-01, time/batch = 13.7680s	
23221/26050 (epoch 44.570), train_loss = 0.79323803, grad/param norm = 2.2191e-01, time/batch = 13.8501s	
23222/26050 (epoch 44.572), train_loss = 0.83744248, grad/param norm = 2.7327e-01, time/batch = 13.6784s	
23223/26050 (epoch 44.574), train_loss = 0.83085416, grad/param norm = 2.4413e-01, time/batch = 13.9855s	
23224/26050 (epoch 44.576), train_loss = 0.83235653, grad/param norm = 2.4986e-01, time/batch = 13.9168s	
23225/26050 (epoch 44.578), train_loss = 0.78108578, grad/param norm = 2.5143e-01, time/batch = 13.7731s	
23226/26050 (epoch 44.580), train_loss = 0.75106405, grad/param norm = 2.6886e-01, time/batch = 14.0641s	
23227/26050 (epoch 44.582), train_loss = 0.82878356, grad/param norm = 2.3744e-01, time/batch = 13.6835s	
23228/26050 (epoch 44.583), train_loss = 0.84243924, grad/param norm = 1.9781e-01, time/batch = 13.9926s	
23229/26050 (epoch 44.585), train_loss = 0.72715745, grad/param norm = 2.2997e-01, time/batch = 13.7651s	
23230/26050 (epoch 44.587), train_loss = 0.81897269, grad/param norm = 2.6496e-01, time/batch = 13.7629s	
23231/26050 (epoch 44.589), train_loss = 0.94763984, grad/param norm = 2.3235e-01, time/batch = 16.5036s	
23232/26050 (epoch 44.591), train_loss = 0.82945686, grad/param norm = 2.0894e-01, time/batch = 14.6822s	
23233/26050 (epoch 44.593), train_loss = 0.70453226, grad/param norm = 2.2107e-01, time/batch = 18.3114s	
23234/26050 (epoch 44.595), train_loss = 0.83688471, grad/param norm = 2.3908e-01, time/batch = 18.3174s	
23235/26050 (epoch 44.597), train_loss = 0.80679113, grad/param norm = 2.1933e-01, time/batch = 17.8000s	
23236/26050 (epoch 44.599), train_loss = 0.87643550, grad/param norm = 2.2651e-01, time/batch = 23.5668s	
23237/26050 (epoch 44.601), train_loss = 0.96598940, grad/param norm = 2.3688e-01, time/batch = 26.4927s	
23238/26050 (epoch 44.603), train_loss = 0.88465866, grad/param norm = 2.4542e-01, time/batch = 15.4909s	
23239/26050 (epoch 44.605), train_loss = 0.78944190, grad/param norm = 2.7445e-01, time/batch = 17.8960s	
23240/26050 (epoch 44.607), train_loss = 0.90125508, grad/param norm = 3.0723e-01, time/batch = 18.2386s	
23241/26050 (epoch 44.608), train_loss = 0.73710232, grad/param norm = 2.0287e-01, time/batch = 18.1403s	
23242/26050 (epoch 44.610), train_loss = 0.83226612, grad/param norm = 2.5132e-01, time/batch = 17.0405s	
23243/26050 (epoch 44.612), train_loss = 0.77916908, grad/param norm = 2.2976e-01, time/batch = 18.4082s	
23244/26050 (epoch 44.614), train_loss = 0.82101884, grad/param norm = 2.1913e-01, time/batch = 18.3883s	
23245/26050 (epoch 44.616), train_loss = 0.86617997, grad/param norm = 2.4758e-01, time/batch = 18.3921s	
23246/26050 (epoch 44.618), train_loss = 0.74455978, grad/param norm = 2.0544e-01, time/batch = 18.4855s	
23247/26050 (epoch 44.620), train_loss = 0.87245809, grad/param norm = 2.3539e-01, time/batch = 18.1503s	
23248/26050 (epoch 44.622), train_loss = 0.74461407, grad/param norm = 2.2545e-01, time/batch = 17.5667s	
23249/26050 (epoch 44.624), train_loss = 0.66331917, grad/param norm = 1.9528e-01, time/batch = 18.0558s	
23250/26050 (epoch 44.626), train_loss = 0.85396760, grad/param norm = 2.4506e-01, time/batch = 18.9727s	
23251/26050 (epoch 44.628), train_loss = 0.77244938, grad/param norm = 2.9085e-01, time/batch = 17.8920s	
23252/26050 (epoch 44.630), train_loss = 0.96201297, grad/param norm = 2.3336e-01, time/batch = 17.7383s	
23253/26050 (epoch 44.631), train_loss = 0.94925891, grad/param norm = 2.4160e-01, time/batch = 16.0524s	
23254/26050 (epoch 44.633), train_loss = 0.74828112, grad/param norm = 2.8739e-01, time/batch = 16.5501s	
23255/26050 (epoch 44.635), train_loss = 0.76461820, grad/param norm = 1.9948e-01, time/batch = 17.8857s	
23256/26050 (epoch 44.637), train_loss = 0.71259712, grad/param norm = 2.0383e-01, time/batch = 15.2817s	
23257/26050 (epoch 44.639), train_loss = 0.84438764, grad/param norm = 1.9940e-01, time/batch = 18.9725s	
23258/26050 (epoch 44.641), train_loss = 0.74843671, grad/param norm = 2.1600e-01, time/batch = 17.6335s	
23259/26050 (epoch 44.643), train_loss = 0.75323924, grad/param norm = 2.0063e-01, time/batch = 18.3137s	
23260/26050 (epoch 44.645), train_loss = 0.76885104, grad/param norm = 2.1900e-01, time/batch = 17.9823s	
23261/26050 (epoch 44.647), train_loss = 0.71604901, grad/param norm = 2.2842e-01, time/batch = 17.8963s	
23262/26050 (epoch 44.649), train_loss = 0.77109633, grad/param norm = 2.5729e-01, time/batch = 17.8877s	
23263/26050 (epoch 44.651), train_loss = 0.77510394, grad/param norm = 2.0879e-01, time/batch = 14.3101s	
23264/26050 (epoch 44.653), train_loss = 0.79427086, grad/param norm = 2.2199e-01, time/batch = 17.2981s	
23265/26050 (epoch 44.655), train_loss = 0.72024124, grad/param norm = 2.1543e-01, time/batch = 18.0386s	
23266/26050 (epoch 44.656), train_loss = 0.70114912, grad/param norm = 1.7679e-01, time/batch = 18.4762s	
23267/26050 (epoch 44.658), train_loss = 0.93831239, grad/param norm = 2.3701e-01, time/batch = 18.3087s	
23268/26050 (epoch 44.660), train_loss = 0.66864921, grad/param norm = 2.2596e-01, time/batch = 15.2284s	
23269/26050 (epoch 44.662), train_loss = 0.78801538, grad/param norm = 2.2322e-01, time/batch = 18.3879s	
23270/26050 (epoch 44.664), train_loss = 0.80524100, grad/param norm = 2.2163e-01, time/batch = 15.9675s	
23271/26050 (epoch 44.666), train_loss = 0.76659003, grad/param norm = 2.2274e-01, time/batch = 18.3234s	
23272/26050 (epoch 44.668), train_loss = 0.63019781, grad/param norm = 2.3093e-01, time/batch = 17.7327s	
23273/26050 (epoch 44.670), train_loss = 0.93729526, grad/param norm = 2.7363e-01, time/batch = 17.9031s	
23274/26050 (epoch 44.672), train_loss = 0.78807208, grad/param norm = 2.1799e-01, time/batch = 18.8234s	
23275/26050 (epoch 44.674), train_loss = 0.69516128, grad/param norm = 2.0102e-01, time/batch = 17.9018s	
23276/26050 (epoch 44.676), train_loss = 0.84063658, grad/param norm = 2.1823e-01, time/batch = 17.3797s	
23277/26050 (epoch 44.678), train_loss = 0.85769600, grad/param norm = 2.1323e-01, time/batch = 14.9698s	
23278/26050 (epoch 44.679), train_loss = 0.91062238, grad/param norm = 2.4830e-01, time/batch = 14.4561s	
23279/26050 (epoch 44.681), train_loss = 0.83065217, grad/param norm = 2.5105e-01, time/batch = 17.1348s	
23280/26050 (epoch 44.683), train_loss = 0.73654306, grad/param norm = 2.7680e-01, time/batch = 18.5666s	
23281/26050 (epoch 44.685), train_loss = 0.75425973, grad/param norm = 2.1625e-01, time/batch = 18.8229s	
23282/26050 (epoch 44.687), train_loss = 0.71423722, grad/param norm = 2.2677e-01, time/batch = 17.1617s	
23283/26050 (epoch 44.689), train_loss = 0.74592635, grad/param norm = 1.9799e-01, time/batch = 17.6754s	
23284/26050 (epoch 44.691), train_loss = 0.64990362, grad/param norm = 1.7018e-01, time/batch = 18.7289s	
23285/26050 (epoch 44.693), train_loss = 0.75522685, grad/param norm = 2.3995e-01, time/batch = 16.5730s	
23286/26050 (epoch 44.695), train_loss = 0.77633131, grad/param norm = 2.1787e-01, time/batch = 17.9695s	
23287/26050 (epoch 44.697), train_loss = 0.71047681, grad/param norm = 2.0264e-01, time/batch = 17.9905s	
23288/26050 (epoch 44.699), train_loss = 0.84628565, grad/param norm = 2.3582e-01, time/batch = 17.9092s	
23289/26050 (epoch 44.701), train_loss = 0.71724790, grad/param norm = 1.9497e-01, time/batch = 16.3042s	
23290/26050 (epoch 44.702), train_loss = 0.86038405, grad/param norm = 2.1276e-01, time/batch = 15.7231s	
23291/26050 (epoch 44.704), train_loss = 0.90937991, grad/param norm = 2.2947e-01, time/batch = 18.6524s	
23292/26050 (epoch 44.706), train_loss = 0.74091609, grad/param norm = 2.0541e-01, time/batch = 17.8112s	
23293/26050 (epoch 44.708), train_loss = 0.86150730, grad/param norm = 2.4223e-01, time/batch = 17.6225s	
23294/26050 (epoch 44.710), train_loss = 0.81041890, grad/param norm = 2.3852e-01, time/batch = 17.7274s	
23295/26050 (epoch 44.712), train_loss = 0.79633249, grad/param norm = 2.5678e-01, time/batch = 18.4750s	
23296/26050 (epoch 44.714), train_loss = 0.70895957, grad/param norm = 1.7427e-01, time/batch = 17.1334s	
23297/26050 (epoch 44.716), train_loss = 1.00156653, grad/param norm = 2.5186e-01, time/batch = 17.0466s	
23298/26050 (epoch 44.718), train_loss = 0.85383368, grad/param norm = 2.2438e-01, time/batch = 17.7361s	
23299/26050 (epoch 44.720), train_loss = 0.78275165, grad/param norm = 2.1114e-01, time/batch = 17.2186s	
23300/26050 (epoch 44.722), train_loss = 0.72475453, grad/param norm = 2.0630e-01, time/batch = 14.7152s	
23301/26050 (epoch 44.724), train_loss = 0.74629758, grad/param norm = 2.1210e-01, time/batch = 18.2165s	
23302/26050 (epoch 44.726), train_loss = 0.86077580, grad/param norm = 2.2344e-01, time/batch = 18.9774s	
23303/26050 (epoch 44.727), train_loss = 0.84827661, grad/param norm = 2.0631e-01, time/batch = 17.8777s	
23304/26050 (epoch 44.729), train_loss = 0.83893520, grad/param norm = 2.2315e-01, time/batch = 18.6417s	
23305/26050 (epoch 44.731), train_loss = 0.84581211, grad/param norm = 2.1842e-01, time/batch = 17.8115s	
23306/26050 (epoch 44.733), train_loss = 0.77359308, grad/param norm = 2.5472e-01, time/batch = 17.1561s	
23307/26050 (epoch 44.735), train_loss = 0.88862240, grad/param norm = 2.1702e-01, time/batch = 18.2305s	
23308/26050 (epoch 44.737), train_loss = 0.76304479, grad/param norm = 2.4858e-01, time/batch = 17.2305s	
23309/26050 (epoch 44.739), train_loss = 0.83754723, grad/param norm = 2.5519e-01, time/batch = 16.7848s	
23310/26050 (epoch 44.741), train_loss = 0.71705683, grad/param norm = 2.1043e-01, time/batch = 18.2237s	
23311/26050 (epoch 44.743), train_loss = 0.79319628, grad/param norm = 2.3753e-01, time/batch = 18.5537s	
23312/26050 (epoch 44.745), train_loss = 0.71184560, grad/param norm = 2.1127e-01, time/batch = 18.6356s	
23313/26050 (epoch 44.747), train_loss = 0.75649292, grad/param norm = 2.2697e-01, time/batch = 17.9072s	
23314/26050 (epoch 44.749), train_loss = 0.88852535, grad/param norm = 2.3221e-01, time/batch = 18.1406s	
23315/26050 (epoch 44.750), train_loss = 0.74848295, grad/param norm = 1.8708e-01, time/batch = 16.3960s	
23316/26050 (epoch 44.752), train_loss = 0.75133210, grad/param norm = 2.5939e-01, time/batch = 17.6430s	
23317/26050 (epoch 44.754), train_loss = 0.78988203, grad/param norm = 2.3673e-01, time/batch = 18.3283s	
23318/26050 (epoch 44.756), train_loss = 0.74715710, grad/param norm = 2.3612e-01, time/batch = 18.6556s	
23319/26050 (epoch 44.758), train_loss = 0.77814038, grad/param norm = 2.3208e-01, time/batch = 17.1586s	
23320/26050 (epoch 44.760), train_loss = 0.91612223, grad/param norm = 2.2109e-01, time/batch = 14.5544s	
23321/26050 (epoch 44.762), train_loss = 0.76505572, grad/param norm = 1.9380e-01, time/batch = 18.0579s	
23322/26050 (epoch 44.764), train_loss = 0.78063774, grad/param norm = 2.7226e-01, time/batch = 18.2376s	
23323/26050 (epoch 44.766), train_loss = 0.78690813, grad/param norm = 2.4409e-01, time/batch = 17.5717s	
23324/26050 (epoch 44.768), train_loss = 0.69105165, grad/param norm = 2.2098e-01, time/batch = 18.8156s	
23325/26050 (epoch 44.770), train_loss = 0.80879496, grad/param norm = 2.8825e-01, time/batch = 18.9800s	
23326/26050 (epoch 44.772), train_loss = 0.80242100, grad/param norm = 2.3775e-01, time/batch = 16.9064s	
23327/26050 (epoch 44.774), train_loss = 0.66429976, grad/param norm = 2.2828e-01, time/batch = 18.6411s	
23328/26050 (epoch 44.775), train_loss = 0.56254154, grad/param norm = 2.1025e-01, time/batch = 15.8529s	
23329/26050 (epoch 44.777), train_loss = 0.73975418, grad/param norm = 2.1697e-01, time/batch = 17.1384s	
23330/26050 (epoch 44.779), train_loss = 0.77994202, grad/param norm = 3.2469e-01, time/batch = 17.5664s	
23331/26050 (epoch 44.781), train_loss = 0.71215334, grad/param norm = 2.2990e-01, time/batch = 17.9073s	
23332/26050 (epoch 44.783), train_loss = 0.69299579, grad/param norm = 2.3628e-01, time/batch = 15.4798s	
23333/26050 (epoch 44.785), train_loss = 0.79147707, grad/param norm = 2.4807e-01, time/batch = 17.6588s	
23334/26050 (epoch 44.787), train_loss = 0.72414311, grad/param norm = 2.1816e-01, time/batch = 14.8079s	
23335/26050 (epoch 44.789), train_loss = 0.71372584, grad/param norm = 2.3352e-01, time/batch = 18.5501s	
23336/26050 (epoch 44.791), train_loss = 0.71459477, grad/param norm = 2.7359e-01, time/batch = 18.4914s	
23337/26050 (epoch 44.793), train_loss = 0.77627663, grad/param norm = 2.2461e-01, time/batch = 17.3989s	
23338/26050 (epoch 44.795), train_loss = 0.64377113, grad/param norm = 1.8685e-01, time/batch = 18.4889s	
23339/26050 (epoch 44.797), train_loss = 0.70077139, grad/param norm = 2.1702e-01, time/batch = 17.5537s	
23340/26050 (epoch 44.798), train_loss = 0.78830494, grad/param norm = 2.7071e-01, time/batch = 16.8990s	
23341/26050 (epoch 44.800), train_loss = 0.67120995, grad/param norm = 2.2304e-01, time/batch = 17.3722s	
23342/26050 (epoch 44.802), train_loss = 0.75589147, grad/param norm = 2.7476e-01, time/batch = 17.2429s	
23343/26050 (epoch 44.804), train_loss = 0.77074945, grad/param norm = 2.1003e-01, time/batch = 17.9694s	
23344/26050 (epoch 44.806), train_loss = 0.83190872, grad/param norm = 2.1925e-01, time/batch = 16.6145s	
23345/26050 (epoch 44.808), train_loss = 0.82331534, grad/param norm = 2.1582e-01, time/batch = 16.4811s	
23346/26050 (epoch 44.810), train_loss = 0.80247914, grad/param norm = 2.8083e-01, time/batch = 14.7129s	
23347/26050 (epoch 44.812), train_loss = 0.66346702, grad/param norm = 2.4458e-01, time/batch = 16.9710s	
23348/26050 (epoch 44.814), train_loss = 0.68082860, grad/param norm = 2.1819e-01, time/batch = 18.8093s	
23349/26050 (epoch 44.816), train_loss = 0.83250964, grad/param norm = 2.6713e-01, time/batch = 18.3168s	
23350/26050 (epoch 44.818), train_loss = 0.86128042, grad/param norm = 2.7607e-01, time/batch = 17.6560s	
23351/26050 (epoch 44.820), train_loss = 0.81153619, grad/param norm = 2.5163e-01, time/batch = 17.6489s	
23352/26050 (epoch 44.821), train_loss = 0.86936607, grad/param norm = 2.5959e-01, time/batch = 18.6561s	
23353/26050 (epoch 44.823), train_loss = 0.97772941, grad/param norm = 2.5245e-01, time/batch = 15.7982s	
23354/26050 (epoch 44.825), train_loss = 0.76592111, grad/param norm = 2.4035e-01, time/batch = 17.3022s	
23355/26050 (epoch 44.827), train_loss = 0.77080941, grad/param norm = 2.7600e-01, time/batch = 18.3181s	
23356/26050 (epoch 44.829), train_loss = 0.89532285, grad/param norm = 2.7437e-01, time/batch = 18.2233s	
23357/26050 (epoch 44.831), train_loss = 0.93769912, grad/param norm = 2.3681e-01, time/batch = 17.4828s	
23358/26050 (epoch 44.833), train_loss = 0.88781099, grad/param norm = 2.5476e-01, time/batch = 18.3253s	
23359/26050 (epoch 44.835), train_loss = 0.92330130, grad/param norm = 2.7020e-01, time/batch = 16.4607s	
23360/26050 (epoch 44.837), train_loss = 0.82614583, grad/param norm = 2.1556e-01, time/batch = 18.3100s	
23361/26050 (epoch 44.839), train_loss = 0.78065904, grad/param norm = 2.9733e-01, time/batch = 17.7191s	
23362/26050 (epoch 44.841), train_loss = 0.84572420, grad/param norm = 2.5034e-01, time/batch = 15.2164s	
23363/26050 (epoch 44.843), train_loss = 0.76809547, grad/param norm = 2.0109e-01, time/batch = 14.3871s	
23364/26050 (epoch 44.845), train_loss = 0.73416556, grad/param norm = 2.0533e-01, time/batch = 17.8972s	
23365/26050 (epoch 44.846), train_loss = 0.82051795, grad/param norm = 2.3284e-01, time/batch = 17.7396s	
23366/26050 (epoch 44.848), train_loss = 0.74993806, grad/param norm = 2.0427e-01, time/batch = 17.5601s	
23367/26050 (epoch 44.850), train_loss = 0.70805765, grad/param norm = 2.1916e-01, time/batch = 18.2323s	
23368/26050 (epoch 44.852), train_loss = 0.82770618, grad/param norm = 2.2953e-01, time/batch = 17.4776s	
23369/26050 (epoch 44.854), train_loss = 0.79188285, grad/param norm = 2.3835e-01, time/batch = 18.8201s	
23370/26050 (epoch 44.856), train_loss = 0.75119251, grad/param norm = 2.4552e-01, time/batch = 18.8941s	
23371/26050 (epoch 44.858), train_loss = 0.71165427, grad/param norm = 2.0065e-01, time/batch = 16.9048s	
23372/26050 (epoch 44.860), train_loss = 0.81341376, grad/param norm = 2.5034e-01, time/batch = 17.7416s	
23373/26050 (epoch 44.862), train_loss = 0.86737593, grad/param norm = 2.3275e-01, time/batch = 17.5488s	
23374/26050 (epoch 44.864), train_loss = 0.78556648, grad/param norm = 2.7152e-01, time/batch = 17.5512s	
23375/26050 (epoch 44.866), train_loss = 0.79217155, grad/param norm = 2.1247e-01, time/batch = 14.8818s	
23376/26050 (epoch 44.868), train_loss = 0.85146502, grad/param norm = 2.7208e-01, time/batch = 18.6378s	
23377/26050 (epoch 44.869), train_loss = 0.72399705, grad/param norm = 2.0929e-01, time/batch = 19.1423s	
23378/26050 (epoch 44.871), train_loss = 0.67490913, grad/param norm = 2.1928e-01, time/batch = 17.3700s	
23379/26050 (epoch 44.873), train_loss = 0.84616585, grad/param norm = 2.4634e-01, time/batch = 14.4768s	
23380/26050 (epoch 44.875), train_loss = 0.74377912, grad/param norm = 2.3466e-01, time/batch = 18.3932s	
23381/26050 (epoch 44.877), train_loss = 0.76183681, grad/param norm = 2.1695e-01, time/batch = 18.0523s	
23382/26050 (epoch 44.879), train_loss = 0.85867922, grad/param norm = 2.1406e-01, time/batch = 18.1640s	
23383/26050 (epoch 44.881), train_loss = 0.85318535, grad/param norm = 2.6368e-01, time/batch = 17.1643s	
23384/26050 (epoch 44.883), train_loss = 0.88025252, grad/param norm = 2.7087e-01, time/batch = 18.3149s	
23385/26050 (epoch 44.885), train_loss = 0.60528165, grad/param norm = 1.9548e-01, time/batch = 17.4940s	
23386/26050 (epoch 44.887), train_loss = 0.88555614, grad/param norm = 2.3473e-01, time/batch = 18.8021s	
23387/26050 (epoch 44.889), train_loss = 0.73234625, grad/param norm = 2.0420e-01, time/batch = 17.5724s	
23388/26050 (epoch 44.891), train_loss = 0.66060250, grad/param norm = 2.0303e-01, time/batch = 13.5275s	
23389/26050 (epoch 44.893), train_loss = 0.66642630, grad/param norm = 2.2623e-01, time/batch = 0.6435s	
23390/26050 (epoch 44.894), train_loss = 0.72760306, grad/param norm = 2.1271e-01, time/batch = 0.6500s	
23391/26050 (epoch 44.896), train_loss = 0.85818339, grad/param norm = 2.2826e-01, time/batch = 0.6846s	
23392/26050 (epoch 44.898), train_loss = 0.72783948, grad/param norm = 2.2847e-01, time/batch = 0.6559s	
23393/26050 (epoch 44.900), train_loss = 0.82636828, grad/param norm = 2.3728e-01, time/batch = 0.6452s	
23394/26050 (epoch 44.902), train_loss = 0.76063428, grad/param norm = 2.2926e-01, time/batch = 0.6427s	
23395/26050 (epoch 44.904), train_loss = 0.77131458, grad/param norm = 2.4989e-01, time/batch = 0.6520s	
23396/26050 (epoch 44.906), train_loss = 0.74738702, grad/param norm = 3.0387e-01, time/batch = 0.8216s	
23397/26050 (epoch 44.908), train_loss = 0.81337094, grad/param norm = 2.1769e-01, time/batch = 0.9444s	
23398/26050 (epoch 44.910), train_loss = 0.73830359, grad/param norm = 2.1750e-01, time/batch = 0.9433s	
23399/26050 (epoch 44.912), train_loss = 0.95283867, grad/param norm = 2.7210e-01, time/batch = 0.9451s	
23400/26050 (epoch 44.914), train_loss = 1.06103065, grad/param norm = 2.3911e-01, time/batch = 0.9455s	
23401/26050 (epoch 44.916), train_loss = 0.84554226, grad/param norm = 3.1208e-01, time/batch = 1.2127s	
23402/26050 (epoch 44.917), train_loss = 0.81187626, grad/param norm = 2.2658e-01, time/batch = 1.8249s	
23403/26050 (epoch 44.919), train_loss = 0.82775779, grad/param norm = 2.7001e-01, time/batch = 1.7604s	
23404/26050 (epoch 44.921), train_loss = 0.72227788, grad/param norm = 2.1757e-01, time/batch = 11.7298s	
23405/26050 (epoch 44.923), train_loss = 0.81062340, grad/param norm = 2.2568e-01, time/batch = 17.5718s	
23406/26050 (epoch 44.925), train_loss = 0.78179853, grad/param norm = 2.1929e-01, time/batch = 17.5808s	
23407/26050 (epoch 44.927), train_loss = 0.73349799, grad/param norm = 1.8132e-01, time/batch = 17.5366s	
23408/26050 (epoch 44.929), train_loss = 0.66828803, grad/param norm = 1.9536e-01, time/batch = 18.4026s	
23409/26050 (epoch 44.931), train_loss = 0.92680701, grad/param norm = 2.6851e-01, time/batch = 14.5683s	
23410/26050 (epoch 44.933), train_loss = 0.78387195, grad/param norm = 2.0985e-01, time/batch = 18.5554s	
23411/26050 (epoch 44.935), train_loss = 0.75036668, grad/param norm = 2.1475e-01, time/batch = 17.8104s	
23412/26050 (epoch 44.937), train_loss = 0.85414525, grad/param norm = 2.2656e-01, time/batch = 14.7209s	
23413/26050 (epoch 44.939), train_loss = 0.73232221, grad/param norm = 2.0717e-01, time/batch = 16.9773s	
23414/26050 (epoch 44.940), train_loss = 0.78990528, grad/param norm = 2.1087e-01, time/batch = 18.2072s	
23415/26050 (epoch 44.942), train_loss = 0.72509421, grad/param norm = 2.2511e-01, time/batch = 17.5390s	
23416/26050 (epoch 44.944), train_loss = 0.75428900, grad/param norm = 1.8555e-01, time/batch = 17.7185s	
23417/26050 (epoch 44.946), train_loss = 0.94832004, grad/param norm = 2.2615e-01, time/batch = 17.4816s	
23418/26050 (epoch 44.948), train_loss = 0.67754840, grad/param norm = 2.1676e-01, time/batch = 18.9014s	
23419/26050 (epoch 44.950), train_loss = 0.81094926, grad/param norm = 2.0753e-01, time/batch = 18.7298s	
23420/26050 (epoch 44.952), train_loss = 0.82220874, grad/param norm = 2.2838e-01, time/batch = 17.6300s	
23421/26050 (epoch 44.954), train_loss = 0.85142684, grad/param norm = 2.2997e-01, time/batch = 18.0400s	
23422/26050 (epoch 44.956), train_loss = 0.72609598, grad/param norm = 1.8671e-01, time/batch = 16.7099s	
23423/26050 (epoch 44.958), train_loss = 0.70300986, grad/param norm = 2.0455e-01, time/batch = 17.8133s	
23424/26050 (epoch 44.960), train_loss = 0.82317379, grad/param norm = 2.5307e-01, time/batch = 17.5005s	
23425/26050 (epoch 44.962), train_loss = 0.79107297, grad/param norm = 1.9681e-01, time/batch = 18.2313s	
23426/26050 (epoch 44.964), train_loss = 0.73685430, grad/param norm = 2.1627e-01, time/batch = 17.9572s	
23427/26050 (epoch 44.965), train_loss = 0.70493170, grad/param norm = 2.5343e-01, time/batch = 14.5464s	
23428/26050 (epoch 44.967), train_loss = 1.02017879, grad/param norm = 2.4537e-01, time/batch = 17.7132s	
23429/26050 (epoch 44.969), train_loss = 0.78358117, grad/param norm = 2.0333e-01, time/batch = 18.5620s	
23430/26050 (epoch 44.971), train_loss = 0.80072321, grad/param norm = 2.0313e-01, time/batch = 17.2429s	
23431/26050 (epoch 44.973), train_loss = 0.80068158, grad/param norm = 2.2060e-01, time/batch = 18.6508s	
23432/26050 (epoch 44.975), train_loss = 0.79053304, grad/param norm = 2.1526e-01, time/batch = 15.7342s	
23433/26050 (epoch 44.977), train_loss = 0.76265289, grad/param norm = 1.9985e-01, time/batch = 18.0567s	
23434/26050 (epoch 44.979), train_loss = 0.63811216, grad/param norm = 1.8991e-01, time/batch = 18.4966s	
23435/26050 (epoch 44.981), train_loss = 0.85239170, grad/param norm = 1.9788e-01, time/batch = 16.2262s	
23436/26050 (epoch 44.983), train_loss = 0.81501575, grad/param norm = 2.2108e-01, time/batch = 18.0508s	
23437/26050 (epoch 44.985), train_loss = 0.81029263, grad/param norm = 2.2329e-01, time/batch = 17.3880s	
23438/26050 (epoch 44.987), train_loss = 0.87502208, grad/param norm = 2.0946e-01, time/batch = 18.3077s	
23439/26050 (epoch 44.988), train_loss = 0.80786772, grad/param norm = 2.2169e-01, time/batch = 17.4134s	
23440/26050 (epoch 44.990), train_loss = 0.69143005, grad/param norm = 1.9876e-01, time/batch = 17.0454s	
23441/26050 (epoch 44.992), train_loss = 0.91694288, grad/param norm = 2.3227e-01, time/batch = 14.7967s	
23442/26050 (epoch 44.994), train_loss = 0.72690526, grad/param norm = 2.4545e-01, time/batch = 16.9548s	
23443/26050 (epoch 44.996), train_loss = 0.68843678, grad/param norm = 2.5371e-01, time/batch = 18.6379s	
23444/26050 (epoch 44.998), train_loss = 0.80110302, grad/param norm = 2.1551e-01, time/batch = 18.3099s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
23445/26050 (epoch 45.000), train_loss = 0.71874417, grad/param norm = 2.2853e-01, time/batch = 18.3163s	
23446/26050 (epoch 45.002), train_loss = 0.85843148, grad/param norm = 2.4274e-01, time/batch = 18.3124s	
23447/26050 (epoch 45.004), train_loss = 0.69987622, grad/param norm = 2.3432e-01, time/batch = 17.6357s	
23448/26050 (epoch 45.006), train_loss = 0.74321366, grad/param norm = 2.3885e-01, time/batch = 16.7301s	
23449/26050 (epoch 45.008), train_loss = 0.72192166, grad/param norm = 2.1776e-01, time/batch = 17.8850s	
23450/26050 (epoch 45.010), train_loss = 0.73103364, grad/param norm = 2.6330e-01, time/batch = 17.2328s	
23451/26050 (epoch 45.012), train_loss = 0.76349281, grad/param norm = 2.2712e-01, time/batch = 18.0651s	
23452/26050 (epoch 45.013), train_loss = 1.02665803, grad/param norm = 2.7559e-01, time/batch = 18.4057s	
23453/26050 (epoch 45.015), train_loss = 0.78121048, grad/param norm = 2.0295e-01, time/batch = 15.2229s	
23454/26050 (epoch 45.017), train_loss = 0.80768369, grad/param norm = 2.0680e-01, time/batch = 23.8186s	
23455/26050 (epoch 45.019), train_loss = 0.68565346, grad/param norm = 1.7958e-01, time/batch = 31.5896s	
23456/26050 (epoch 45.021), train_loss = 0.83782423, grad/param norm = 2.0879e-01, time/batch = 17.2022s	
23457/26050 (epoch 45.023), train_loss = 0.65464586, grad/param norm = 2.1945e-01, time/batch = 18.0646s	
23458/26050 (epoch 45.025), train_loss = 0.77718119, grad/param norm = 2.2087e-01, time/batch = 16.8037s	
23459/26050 (epoch 45.027), train_loss = 0.62028292, grad/param norm = 1.9740e-01, time/batch = 18.2245s	
23460/26050 (epoch 45.029), train_loss = 0.84329586, grad/param norm = 2.1109e-01, time/batch = 18.0570s	
23461/26050 (epoch 45.031), train_loss = 0.88864392, grad/param norm = 2.7676e-01, time/batch = 17.2919s	
23462/26050 (epoch 45.033), train_loss = 0.78693057, grad/param norm = 2.2561e-01, time/batch = 18.3231s	
23463/26050 (epoch 45.035), train_loss = 0.82449382, grad/param norm = 2.0829e-01, time/batch = 18.1339s	
23464/26050 (epoch 45.036), train_loss = 0.69057048, grad/param norm = 2.2328e-01, time/batch = 17.9868s	
23465/26050 (epoch 45.038), train_loss = 0.63836805, grad/param norm = 2.2782e-01, time/batch = 15.1420s	
23466/26050 (epoch 45.040), train_loss = 0.77386845, grad/param norm = 2.7038e-01, time/batch = 17.9769s	
23467/26050 (epoch 45.042), train_loss = 0.68199504, grad/param norm = 3.5637e-01, time/batch = 17.8937s	
23468/26050 (epoch 45.044), train_loss = 0.85799634, grad/param norm = 2.3722e-01, time/batch = 18.4859s	
23469/26050 (epoch 45.046), train_loss = 0.66937009, grad/param norm = 2.0259e-01, time/batch = 18.3197s	
23470/26050 (epoch 45.048), train_loss = 0.79793498, grad/param norm = 2.3755e-01, time/batch = 17.8054s	
23471/26050 (epoch 45.050), train_loss = 0.75534230, grad/param norm = 2.2368e-01, time/batch = 18.3904s	
23472/26050 (epoch 45.052), train_loss = 0.71812154, grad/param norm = 2.2740e-01, time/batch = 16.3649s	
23473/26050 (epoch 45.054), train_loss = 0.66045289, grad/param norm = 1.9803e-01, time/batch = 16.5455s	
23474/26050 (epoch 45.056), train_loss = 0.65570711, grad/param norm = 1.6857e-01, time/batch = 16.8180s	
23475/26050 (epoch 45.058), train_loss = 0.75281346, grad/param norm = 2.0014e-01, time/batch = 18.4716s	
23476/26050 (epoch 45.060), train_loss = 0.81840782, grad/param norm = 2.0370e-01, time/batch = 17.4122s	
23477/26050 (epoch 45.061), train_loss = 0.67228824, grad/param norm = 2.0967e-01, time/batch = 18.1456s	
23478/26050 (epoch 45.063), train_loss = 0.78056347, grad/param norm = 2.2556e-01, time/batch = 18.5663s	
23479/26050 (epoch 45.065), train_loss = 0.65424795, grad/param norm = 2.0253e-01, time/batch = 17.5854s	
23480/26050 (epoch 45.067), train_loss = 0.78095834, grad/param norm = 2.3979e-01, time/batch = 18.2268s	
23481/26050 (epoch 45.069), train_loss = 0.80434569, grad/param norm = 2.4719e-01, time/batch = 16.9529s	
23482/26050 (epoch 45.071), train_loss = 0.79882932, grad/param norm = 2.8940e-01, time/batch = 17.9696s	
23483/26050 (epoch 45.073), train_loss = 0.93750604, grad/param norm = 2.3410e-01, time/batch = 17.9689s	
23484/26050 (epoch 45.075), train_loss = 0.73897285, grad/param norm = 2.2614e-01, time/batch = 18.6477s	
23485/26050 (epoch 45.077), train_loss = 0.74095201, grad/param norm = 2.2603e-01, time/batch = 18.4879s	
23486/26050 (epoch 45.079), train_loss = 0.75386461, grad/param norm = 2.3486e-01, time/batch = 17.8939s	
23487/26050 (epoch 45.081), train_loss = 0.76568784, grad/param norm = 2.8265e-01, time/batch = 14.7044s	
23488/26050 (epoch 45.083), train_loss = 0.86922901, grad/param norm = 2.0701e-01, time/batch = 18.3026s	
23489/26050 (epoch 45.084), train_loss = 0.78313652, grad/param norm = 2.4718e-01, time/batch = 18.3129s	
23490/26050 (epoch 45.086), train_loss = 0.89457595, grad/param norm = 2.5961e-01, time/batch = 17.3178s	
23491/26050 (epoch 45.088), train_loss = 0.78009498, grad/param norm = 2.1652e-01, time/batch = 18.3225s	
23492/26050 (epoch 45.090), train_loss = 0.82547136, grad/param norm = 2.6375e-01, time/batch = 18.1554s	
23493/26050 (epoch 45.092), train_loss = 0.81450587, grad/param norm = 1.9496e-01, time/batch = 18.2310s	
23494/26050 (epoch 45.094), train_loss = 0.66594746, grad/param norm = 2.3289e-01, time/batch = 17.9905s	
23495/26050 (epoch 45.096), train_loss = 0.80584485, grad/param norm = 2.2510e-01, time/batch = 14.4781s	
23496/26050 (epoch 45.098), train_loss = 0.79628123, grad/param norm = 2.3282e-01, time/batch = 18.5684s	
23497/26050 (epoch 45.100), train_loss = 0.70235288, grad/param norm = 2.4740e-01, time/batch = 17.9738s	
23498/26050 (epoch 45.102), train_loss = 0.80385288, grad/param norm = 2.6440e-01, time/batch = 18.6529s	
23499/26050 (epoch 45.104), train_loss = 0.74834558, grad/param norm = 2.2304e-01, time/batch = 17.0330s	
23500/26050 (epoch 45.106), train_loss = 0.83036842, grad/param norm = 2.7327e-01, time/batch = 16.4659s	
23501/26050 (epoch 45.107), train_loss = 0.66889809, grad/param norm = 1.9874e-01, time/batch = 17.5659s	
23502/26050 (epoch 45.109), train_loss = 0.72376673, grad/param norm = 2.0994e-01, time/batch = 18.8133s	
23503/26050 (epoch 45.111), train_loss = 0.92264674, grad/param norm = 2.6059e-01, time/batch = 17.8044s	
23504/26050 (epoch 45.113), train_loss = 0.76223155, grad/param norm = 2.1201e-01, time/batch = 18.2408s	
23505/26050 (epoch 45.115), train_loss = 0.85089034, grad/param norm = 2.1769e-01, time/batch = 16.0518s	
23506/26050 (epoch 45.117), train_loss = 0.78120164, grad/param norm = 2.4247e-01, time/batch = 17.6451s	
23507/26050 (epoch 45.119), train_loss = 0.67708984, grad/param norm = 1.8054e-01, time/batch = 17.7274s	
23508/26050 (epoch 45.121), train_loss = 0.77394093, grad/param norm = 2.1535e-01, time/batch = 14.3987s	
23509/26050 (epoch 45.123), train_loss = 0.70547498, grad/param norm = 1.9322e-01, time/batch = 18.5664s	
23510/26050 (epoch 45.125), train_loss = 0.65465090, grad/param norm = 1.8880e-01, time/batch = 17.9776s	
23511/26050 (epoch 45.127), train_loss = 0.65866046, grad/param norm = 2.0278e-01, time/batch = 17.3047s	
23512/26050 (epoch 45.129), train_loss = 0.60773132, grad/param norm = 2.1688e-01, time/batch = 17.1437s	
23513/26050 (epoch 45.131), train_loss = 0.77521934, grad/param norm = 2.5596e-01, time/batch = 15.4711s	
23514/26050 (epoch 45.132), train_loss = 0.78963106, grad/param norm = 2.2022e-01, time/batch = 16.9811s	
23515/26050 (epoch 45.134), train_loss = 0.81000637, grad/param norm = 2.4706e-01, time/batch = 18.5536s	
23516/26050 (epoch 45.136), train_loss = 0.74792148, grad/param norm = 2.1217e-01, time/batch = 17.8321s	
23517/26050 (epoch 45.138), train_loss = 0.53926942, grad/param norm = 1.9815e-01, time/batch = 15.3080s	
23518/26050 (epoch 45.140), train_loss = 0.64521098, grad/param norm = 2.1884e-01, time/batch = 18.3998s	
23519/26050 (epoch 45.142), train_loss = 0.64404655, grad/param norm = 2.0412e-01, time/batch = 17.0643s	
23520/26050 (epoch 45.144), train_loss = 0.63223479, grad/param norm = 2.1861e-01, time/batch = 16.9655s	
23521/26050 (epoch 45.146), train_loss = 0.57145049, grad/param norm = 1.8220e-01, time/batch = 16.2827s	
23522/26050 (epoch 45.148), train_loss = 0.62546823, grad/param norm = 2.0805e-01, time/batch = 18.0762s	
23523/26050 (epoch 45.150), train_loss = 0.68666536, grad/param norm = 2.5563e-01, time/batch = 17.8049s	
23524/26050 (epoch 45.152), train_loss = 0.85928205, grad/param norm = 3.9417e-01, time/batch = 17.9672s	
23525/26050 (epoch 45.154), train_loss = 0.60357960, grad/param norm = 2.1931e-01, time/batch = 17.5641s	
23526/26050 (epoch 45.155), train_loss = 0.65867357, grad/param norm = 2.4643e-01, time/batch = 18.6431s	
23527/26050 (epoch 45.157), train_loss = 0.72802162, grad/param norm = 2.3627e-01, time/batch = 15.7947s	
23528/26050 (epoch 45.159), train_loss = 0.79906983, grad/param norm = 2.5802e-01, time/batch = 15.7880s	
23529/26050 (epoch 45.161), train_loss = 0.76304372, grad/param norm = 2.4236e-01, time/batch = 15.5542s	
23530/26050 (epoch 45.163), train_loss = 0.64099194, grad/param norm = 2.1545e-01, time/batch = 18.1188s	
23531/26050 (epoch 45.165), train_loss = 0.58814831, grad/param norm = 1.8989e-01, time/batch = 17.5609s	
23532/26050 (epoch 45.167), train_loss = 0.87914467, grad/param norm = 2.4795e-01, time/batch = 18.4031s	
23533/26050 (epoch 45.169), train_loss = 0.78667674, grad/param norm = 2.8252e-01, time/batch = 18.7361s	
23534/26050 (epoch 45.171), train_loss = 0.70120671, grad/param norm = 1.9348e-01, time/batch = 17.9865s	
23535/26050 (epoch 45.173), train_loss = 0.73353603, grad/param norm = 2.3856e-01, time/batch = 17.4976s	
23536/26050 (epoch 45.175), train_loss = 0.75158461, grad/param norm = 2.2061e-01, time/batch = 18.2433s	
23537/26050 (epoch 45.177), train_loss = 0.82053268, grad/param norm = 2.2118e-01, time/batch = 18.9055s	
23538/26050 (epoch 45.179), train_loss = 0.56858654, grad/param norm = 1.8009e-01, time/batch = 17.9868s	
23539/26050 (epoch 45.180), train_loss = 0.97134891, grad/param norm = 2.2808e-01, time/batch = 14.9777s	
23540/26050 (epoch 45.182), train_loss = 0.93241890, grad/param norm = 3.7836e-01, time/batch = 17.7156s	
23541/26050 (epoch 45.184), train_loss = 0.79283321, grad/param norm = 2.2540e-01, time/batch = 17.9014s	
23542/26050 (epoch 45.186), train_loss = 0.67825308, grad/param norm = 2.1863e-01, time/batch = 18.2414s	
23543/26050 (epoch 45.188), train_loss = 0.83050594, grad/param norm = 2.4468e-01, time/batch = 18.6423s	
23544/26050 (epoch 45.190), train_loss = 0.82552864, grad/param norm = 2.2505e-01, time/batch = 18.0699s	
23545/26050 (epoch 45.192), train_loss = 0.86919846, grad/param norm = 2.1324e-01, time/batch = 18.2999s	
23546/26050 (epoch 45.194), train_loss = 0.79990519, grad/param norm = 2.0710e-01, time/batch = 17.4016s	
23547/26050 (epoch 45.196), train_loss = 0.83095454, grad/param norm = 2.4842e-01, time/batch = 14.5157s	
23548/26050 (epoch 45.198), train_loss = 0.69728253, grad/param norm = 1.7716e-01, time/batch = 16.3768s	
23549/26050 (epoch 45.200), train_loss = 0.70152703, grad/param norm = 2.4909e-01, time/batch = 16.0002s	
23550/26050 (epoch 45.202), train_loss = 0.78235237, grad/param norm = 2.2205e-01, time/batch = 17.8189s	
23551/26050 (epoch 45.203), train_loss = 0.88973166, grad/param norm = 2.0503e-01, time/batch = 14.9706s	
23552/26050 (epoch 45.205), train_loss = 0.72815645, grad/param norm = 2.1151e-01, time/batch = 18.1389s	
23553/26050 (epoch 45.207), train_loss = 0.69461278, grad/param norm = 2.1341e-01, time/batch = 17.5640s	
23554/26050 (epoch 45.209), train_loss = 0.84798715, grad/param norm = 2.1890e-01, time/batch = 16.0820s	
23555/26050 (epoch 45.211), train_loss = 0.66085857, grad/param norm = 1.7830e-01, time/batch = 15.4167s	
23556/26050 (epoch 45.213), train_loss = 0.77627741, grad/param norm = 2.2846e-01, time/batch = 17.9867s	
23557/26050 (epoch 45.215), train_loss = 0.75974226, grad/param norm = 2.2483e-01, time/batch = 17.4881s	
23558/26050 (epoch 45.217), train_loss = 0.74298998, grad/param norm = 2.0332e-01, time/batch = 17.7472s	
23559/26050 (epoch 45.219), train_loss = 0.72795518, grad/param norm = 2.5125e-01, time/batch = 16.4551s	
23560/26050 (epoch 45.221), train_loss = 0.68497201, grad/param norm = 2.6486e-01, time/batch = 18.5688s	
23561/26050 (epoch 45.223), train_loss = 0.83948803, grad/param norm = 2.3353e-01, time/batch = 16.1289s	
23562/26050 (epoch 45.225), train_loss = 0.69362891, grad/param norm = 2.1426e-01, time/batch = 16.4042s	
23563/26050 (epoch 45.226), train_loss = 0.77823352, grad/param norm = 2.9450e-01, time/batch = 15.0598s	
23564/26050 (epoch 45.228), train_loss = 0.87197395, grad/param norm = 2.3461e-01, time/batch = 17.6257s	
23565/26050 (epoch 45.230), train_loss = 0.76500496, grad/param norm = 1.9581e-01, time/batch = 14.8336s	
23566/26050 (epoch 45.232), train_loss = 0.85541528, grad/param norm = 2.4307e-01, time/batch = 17.0472s	
23567/26050 (epoch 45.234), train_loss = 0.67254756, grad/param norm = 2.3102e-01, time/batch = 14.9722s	
23568/26050 (epoch 45.236), train_loss = 0.82437368, grad/param norm = 2.2814e-01, time/batch = 18.4882s	
23569/26050 (epoch 45.238), train_loss = 0.69256266, grad/param norm = 2.1141e-01, time/batch = 17.0571s	
23570/26050 (epoch 45.240), train_loss = 0.78640825, grad/param norm = 2.4454e-01, time/batch = 16.7378s	
23571/26050 (epoch 45.242), train_loss = 0.73897028, grad/param norm = 2.0477e-01, time/batch = 17.8204s	
23572/26050 (epoch 45.244), train_loss = 0.78539363, grad/param norm = 2.4039e-01, time/batch = 15.3896s	
23573/26050 (epoch 45.246), train_loss = 0.74378900, grad/param norm = 2.2093e-01, time/batch = 17.9734s	
23574/26050 (epoch 45.248), train_loss = 0.78329176, grad/param norm = 2.3603e-01, time/batch = 18.6416s	
23575/26050 (epoch 45.250), train_loss = 0.78479859, grad/param norm = 2.5296e-01, time/batch = 17.9667s	
23576/26050 (epoch 45.251), train_loss = 0.73797950, grad/param norm = 2.2102e-01, time/batch = 14.7138s	
23577/26050 (epoch 45.253), train_loss = 0.65237925, grad/param norm = 2.4555e-01, time/batch = 18.2203s	
23578/26050 (epoch 45.255), train_loss = 0.93343910, grad/param norm = 2.6827e-01, time/batch = 18.5567s	
23579/26050 (epoch 45.257), train_loss = 0.79574227, grad/param norm = 2.4848e-01, time/batch = 18.8186s	
23580/26050 (epoch 45.259), train_loss = 0.84808550, grad/param norm = 2.1103e-01, time/batch = 18.4685s	
23581/26050 (epoch 45.261), train_loss = 0.69896651, grad/param norm = 2.3583e-01, time/batch = 17.9767s	
23582/26050 (epoch 45.263), train_loss = 0.85033945, grad/param norm = 2.2483e-01, time/batch = 16.9053s	
23583/26050 (epoch 45.265), train_loss = 0.86197920, grad/param norm = 2.4724e-01, time/batch = 15.5380s	
23584/26050 (epoch 45.267), train_loss = 0.88691429, grad/param norm = 1.9633e-01, time/batch = 18.2431s	
23585/26050 (epoch 45.269), train_loss = 0.86149407, grad/param norm = 2.2184e-01, time/batch = 18.1578s	
23586/26050 (epoch 45.271), train_loss = 0.75818991, grad/param norm = 2.1734e-01, time/batch = 16.1300s	
23587/26050 (epoch 45.273), train_loss = 0.70210885, grad/param norm = 2.2165e-01, time/batch = 18.1426s	
23588/26050 (epoch 45.274), train_loss = 0.74846854, grad/param norm = 2.0635e-01, time/batch = 18.3114s	
23589/26050 (epoch 45.276), train_loss = 0.73975805, grad/param norm = 2.3558e-01, time/batch = 18.2312s	
23590/26050 (epoch 45.278), train_loss = 0.85045921, grad/param norm = 2.1879e-01, time/batch = 16.2367s	
23591/26050 (epoch 45.280), train_loss = 0.74689419, grad/param norm = 1.9913e-01, time/batch = 18.8146s	
23592/26050 (epoch 45.282), train_loss = 0.86811214, grad/param norm = 2.5042e-01, time/batch = 18.2165s	
23593/26050 (epoch 45.284), train_loss = 0.76953482, grad/param norm = 2.2411e-01, time/batch = 16.4827s	
23594/26050 (epoch 45.286), train_loss = 0.81123365, grad/param norm = 2.2308e-01, time/batch = 17.3828s	
23595/26050 (epoch 45.288), train_loss = 0.66933386, grad/param norm = 1.9761e-01, time/batch = 17.0410s	
23596/26050 (epoch 45.290), train_loss = 0.76830299, grad/param norm = 2.2505e-01, time/batch = 19.0356s	
23597/26050 (epoch 45.292), train_loss = 0.71938622, grad/param norm = 2.3813e-01, time/batch = 17.8922s	
23598/26050 (epoch 45.294), train_loss = 0.76752058, grad/param norm = 2.3588e-01, time/batch = 18.4009s	
23599/26050 (epoch 45.296), train_loss = 0.85128366, grad/param norm = 2.2131e-01, time/batch = 18.3221s	
23600/26050 (epoch 45.298), train_loss = 0.82317147, grad/param norm = 2.1938e-01, time/batch = 15.4542s	
23601/26050 (epoch 45.299), train_loss = 0.66446741, grad/param norm = 2.0357e-01, time/batch = 17.4008s	
23602/26050 (epoch 45.301), train_loss = 0.65787817, grad/param norm = 2.2947e-01, time/batch = 16.0598s	
23603/26050 (epoch 45.303), train_loss = 0.76035149, grad/param norm = 2.3033e-01, time/batch = 17.9656s	
23604/26050 (epoch 45.305), train_loss = 0.63000627, grad/param norm = 1.9166e-01, time/batch = 18.3244s	
23605/26050 (epoch 45.307), train_loss = 0.67539522, grad/param norm = 2.1162e-01, time/batch = 18.4123s	
23606/26050 (epoch 45.309), train_loss = 0.80751212, grad/param norm = 2.1554e-01, time/batch = 14.9070s	
23607/26050 (epoch 45.311), train_loss = 0.77283313, grad/param norm = 2.4491e-01, time/batch = 17.6438s	
23608/26050 (epoch 45.313), train_loss = 0.74776165, grad/param norm = 2.5457e-01, time/batch = 18.7362s	
23609/26050 (epoch 45.315), train_loss = 0.83706961, grad/param norm = 2.5693e-01, time/batch = 18.5719s	
23610/26050 (epoch 45.317), train_loss = 0.77094235, grad/param norm = 2.2617e-01, time/batch = 17.9696s	
23611/26050 (epoch 45.319), train_loss = 0.72474653, grad/param norm = 2.3585e-01, time/batch = 15.8583s	
23612/26050 (epoch 45.321), train_loss = 0.78084756, grad/param norm = 2.2376e-01, time/batch = 17.8996s	
23613/26050 (epoch 45.322), train_loss = 0.83462955, grad/param norm = 2.1421e-01, time/batch = 19.0808s	
23614/26050 (epoch 45.324), train_loss = 0.63001699, grad/param norm = 2.0489e-01, time/batch = 18.3842s	
23615/26050 (epoch 45.326), train_loss = 0.88710142, grad/param norm = 2.3395e-01, time/batch = 15.3051s	
23616/26050 (epoch 45.328), train_loss = 0.81363130, grad/param norm = 2.0752e-01, time/batch = 17.3151s	
23617/26050 (epoch 45.330), train_loss = 0.66343415, grad/param norm = 2.1027e-01, time/batch = 17.3239s	
23618/26050 (epoch 45.332), train_loss = 0.82177082, grad/param norm = 2.0562e-01, time/batch = 18.2980s	
23619/26050 (epoch 45.334), train_loss = 0.67378133, grad/param norm = 2.1340e-01, time/batch = 17.6444s	
23620/26050 (epoch 45.336), train_loss = 0.75192842, grad/param norm = 2.1254e-01, time/batch = 17.5664s	
23621/26050 (epoch 45.338), train_loss = 0.67359091, grad/param norm = 1.8881e-01, time/batch = 18.2402s	
23622/26050 (epoch 45.340), train_loss = 0.81357180, grad/param norm = 2.2369e-01, time/batch = 17.3131s	
23623/26050 (epoch 45.342), train_loss = 0.86371801, grad/param norm = 2.3276e-01, time/batch = 17.8900s	
23624/26050 (epoch 45.344), train_loss = 0.70465491, grad/param norm = 2.4497e-01, time/batch = 17.2205s	
23625/26050 (epoch 45.345), train_loss = 0.76241532, grad/param norm = 2.5166e-01, time/batch = 18.8061s	
23626/26050 (epoch 45.347), train_loss = 0.87939506, grad/param norm = 2.2503e-01, time/batch = 17.9750s	
23627/26050 (epoch 45.349), train_loss = 0.81366597, grad/param norm = 2.1238e-01, time/batch = 17.5640s	
23628/26050 (epoch 45.351), train_loss = 0.79162977, grad/param norm = 2.2954e-01, time/batch = 18.8149s	
23629/26050 (epoch 45.353), train_loss = 0.76284864, grad/param norm = 2.3004e-01, time/batch = 17.2059s	
23630/26050 (epoch 45.355), train_loss = 0.77816113, grad/param norm = 2.4884e-01, time/batch = 15.4640s	
23631/26050 (epoch 45.357), train_loss = 0.71990443, grad/param norm = 2.0791e-01, time/batch = 18.4744s	
23632/26050 (epoch 45.359), train_loss = 0.87533615, grad/param norm = 2.5086e-01, time/batch = 18.0564s	
23633/26050 (epoch 45.361), train_loss = 0.69144400, grad/param norm = 1.9967e-01, time/batch = 18.5828s	
23634/26050 (epoch 45.363), train_loss = 0.83851542, grad/param norm = 2.1743e-01, time/batch = 15.3807s	
23635/26050 (epoch 45.365), train_loss = 0.76706438, grad/param norm = 2.3332e-01, time/batch = 18.8075s	
23636/26050 (epoch 45.367), train_loss = 0.82427514, grad/param norm = 2.2433e-01, time/batch = 18.6403s	
23637/26050 (epoch 45.369), train_loss = 0.68332674, grad/param norm = 1.8088e-01, time/batch = 17.7437s	
23638/26050 (epoch 45.370), train_loss = 0.66966387, grad/param norm = 1.8152e-01, time/batch = 16.8197s	
23639/26050 (epoch 45.372), train_loss = 0.75927259, grad/param norm = 2.2518e-01, time/batch = 18.3073s	
23640/26050 (epoch 45.374), train_loss = 0.88609613, grad/param norm = 2.2055e-01, time/batch = 18.9171s	
23641/26050 (epoch 45.376), train_loss = 0.88508022, grad/param norm = 2.5297e-01, time/batch = 17.9820s	
23642/26050 (epoch 45.378), train_loss = 0.74108414, grad/param norm = 2.0506e-01, time/batch = 18.3943s	
23643/26050 (epoch 45.380), train_loss = 0.88654142, grad/param norm = 2.6176e-01, time/batch = 16.8032s	
23644/26050 (epoch 45.382), train_loss = 0.93375841, grad/param norm = 2.4999e-01, time/batch = 16.9909s	
23645/26050 (epoch 45.384), train_loss = 0.73372803, grad/param norm = 2.3544e-01, time/batch = 17.7489s	
23646/26050 (epoch 45.386), train_loss = 0.85171843, grad/param norm = 3.7359e-01, time/batch = 16.4646s	
23647/26050 (epoch 45.388), train_loss = 0.78603354, grad/param norm = 2.1998e-01, time/batch = 17.9745s	
23648/26050 (epoch 45.390), train_loss = 0.71220072, grad/param norm = 1.9254e-01, time/batch = 18.7255s	
23649/26050 (epoch 45.392), train_loss = 0.67653424, grad/param norm = 2.0080e-01, time/batch = 17.8888s	
23650/26050 (epoch 45.393), train_loss = 0.86625881, grad/param norm = 2.8087e-01, time/batch = 18.2149s	
23651/26050 (epoch 45.395), train_loss = 0.82300817, grad/param norm = 2.2476e-01, time/batch = 18.3740s	
23652/26050 (epoch 45.397), train_loss = 0.83024955, grad/param norm = 2.2888e-01, time/batch = 18.3891s	
23653/26050 (epoch 45.399), train_loss = 0.73945216, grad/param norm = 2.2997e-01, time/batch = 14.7627s	
23654/26050 (epoch 45.401), train_loss = 0.79185978, grad/param norm = 2.4703e-01, time/batch = 17.6481s	
23655/26050 (epoch 45.403), train_loss = 0.79728063, grad/param norm = 2.8010e-01, time/batch = 18.9754s	
23656/26050 (epoch 45.405), train_loss = 0.79713089, grad/param norm = 2.3092e-01, time/batch = 18.3964s	
23657/26050 (epoch 45.407), train_loss = 0.90502377, grad/param norm = 2.5970e-01, time/batch = 18.2954s	
23658/26050 (epoch 45.409), train_loss = 0.88241735, grad/param norm = 2.6432e-01, time/batch = 31.0326s	
23659/26050 (epoch 45.411), train_loss = 0.87201015, grad/param norm = 2.4758e-01, time/batch = 24.1289s	
23660/26050 (epoch 45.413), train_loss = 0.96664416, grad/param norm = 2.3467e-01, time/batch = 15.3761s	
23661/26050 (epoch 45.415), train_loss = 0.98190874, grad/param norm = 3.7926e-01, time/batch = 18.6390s	
23662/26050 (epoch 45.417), train_loss = 0.95223913, grad/param norm = 3.0084e-01, time/batch = 17.3994s	
23663/26050 (epoch 45.418), train_loss = 0.83995444, grad/param norm = 2.5512e-01, time/batch = 17.4033s	
23664/26050 (epoch 45.420), train_loss = 0.68343694, grad/param norm = 2.2365e-01, time/batch = 17.7240s	
23665/26050 (epoch 45.422), train_loss = 0.65982701, grad/param norm = 2.0692e-01, time/batch = 17.6512s	
23666/26050 (epoch 45.424), train_loss = 0.87717930, grad/param norm = 2.4593e-01, time/batch = 16.8922s	
23667/26050 (epoch 45.426), train_loss = 0.83961022, grad/param norm = 2.6983e-01, time/batch = 15.3792s	
23668/26050 (epoch 45.428), train_loss = 0.79006269, grad/param norm = 2.5447e-01, time/batch = 18.3252s	
23669/26050 (epoch 45.430), train_loss = 0.92349420, grad/param norm = 2.2544e-01, time/batch = 18.4742s	
23670/26050 (epoch 45.432), train_loss = 0.76466365, grad/param norm = 2.4698e-01, time/batch = 17.2106s	
23671/26050 (epoch 45.434), train_loss = 0.75915241, grad/param norm = 2.2625e-01, time/batch = 19.1360s	
23672/26050 (epoch 45.436), train_loss = 0.84203501, grad/param norm = 2.3859e-01, time/batch = 18.4100s	
23673/26050 (epoch 45.438), train_loss = 0.81900980, grad/param norm = 2.6404e-01, time/batch = 16.4543s	
23674/26050 (epoch 45.440), train_loss = 0.83755134, grad/param norm = 2.2108e-01, time/batch = 16.5539s	
23675/26050 (epoch 45.441), train_loss = 0.80709600, grad/param norm = 2.1163e-01, time/batch = 14.7053s	
23676/26050 (epoch 45.443), train_loss = 0.70215205, grad/param norm = 1.9554e-01, time/batch = 17.8098s	
23677/26050 (epoch 45.445), train_loss = 0.71589662, grad/param norm = 2.3541e-01, time/batch = 17.0643s	
23678/26050 (epoch 45.447), train_loss = 0.91299094, grad/param norm = 2.3080e-01, time/batch = 18.5623s	
23679/26050 (epoch 45.449), train_loss = 0.72986207, grad/param norm = 2.5401e-01, time/batch = 17.9900s	
23680/26050 (epoch 45.451), train_loss = 0.91573118, grad/param norm = 2.4825e-01, time/batch = 18.3088s	
23681/26050 (epoch 45.453), train_loss = 0.76574645, grad/param norm = 1.9880e-01, time/batch = 15.4032s	
23682/26050 (epoch 45.455), train_loss = 0.79052603, grad/param norm = 2.2137e-01, time/batch = 17.8203s	
23683/26050 (epoch 45.457), train_loss = 0.78190692, grad/param norm = 2.5995e-01, time/batch = 15.4020s	
23684/26050 (epoch 45.459), train_loss = 0.84888845, grad/param norm = 2.3943e-01, time/batch = 17.7900s	
23685/26050 (epoch 45.461), train_loss = 0.85530887, grad/param norm = 2.3405e-01, time/batch = 18.7106s	
23686/26050 (epoch 45.463), train_loss = 0.74532359, grad/param norm = 1.9428e-01, time/batch = 17.4848s	
23687/26050 (epoch 45.464), train_loss = 0.81055709, grad/param norm = 2.3261e-01, time/batch = 17.4890s	
23688/26050 (epoch 45.466), train_loss = 0.79383605, grad/param norm = 2.4405e-01, time/batch = 16.2452s	
23689/26050 (epoch 45.468), train_loss = 0.88363608, grad/param norm = 2.0081e-01, time/batch = 18.3951s	
23690/26050 (epoch 45.470), train_loss = 0.87412794, grad/param norm = 2.7301e-01, time/batch = 18.4815s	
23691/26050 (epoch 45.472), train_loss = 0.87370256, grad/param norm = 2.5018e-01, time/batch = 17.5335s	
23692/26050 (epoch 45.474), train_loss = 0.90862252, grad/param norm = 2.5545e-01, time/batch = 18.4058s	
23693/26050 (epoch 45.476), train_loss = 0.86263589, grad/param norm = 2.0322e-01, time/batch = 17.9772s	
23694/26050 (epoch 45.478), train_loss = 0.76194109, grad/param norm = 1.9613e-01, time/batch = 15.3007s	
23695/26050 (epoch 45.480), train_loss = 0.75954576, grad/param norm = 1.9813e-01, time/batch = 19.3954s	
23696/26050 (epoch 45.482), train_loss = 0.74575982, grad/param norm = 1.9457e-01, time/batch = 16.0615s	
23697/26050 (epoch 45.484), train_loss = 0.73576665, grad/param norm = 2.3667e-01, time/batch = 16.3772s	
23698/26050 (epoch 45.486), train_loss = 0.89854712, grad/param norm = 2.4870e-01, time/batch = 18.6504s	
23699/26050 (epoch 45.488), train_loss = 0.94266252, grad/param norm = 2.9654e-01, time/batch = 18.4776s	
23700/26050 (epoch 45.489), train_loss = 0.96881552, grad/param norm = 2.7365e-01, time/batch = 18.7189s	
23701/26050 (epoch 45.491), train_loss = 0.71698237, grad/param norm = 2.1763e-01, time/batch = 18.0536s	
23702/26050 (epoch 45.493), train_loss = 0.81135902, grad/param norm = 2.3424e-01, time/batch = 15.3078s	
23703/26050 (epoch 45.495), train_loss = 0.79649577, grad/param norm = 2.0312e-01, time/batch = 18.4893s	
23704/26050 (epoch 45.497), train_loss = 0.70211725, grad/param norm = 2.0162e-01, time/batch = 17.2476s	
23705/26050 (epoch 45.499), train_loss = 0.71286410, grad/param norm = 2.1483e-01, time/batch = 18.8126s	
23706/26050 (epoch 45.501), train_loss = 0.88830301, grad/param norm = 2.0382e-01, time/batch = 18.3037s	
23707/26050 (epoch 45.503), train_loss = 0.76509350, grad/param norm = 2.3222e-01, time/batch = 17.3242s	
23708/26050 (epoch 45.505), train_loss = 0.88620856, grad/param norm = 2.0579e-01, time/batch = 18.3184s	
23709/26050 (epoch 45.507), train_loss = 0.88771541, grad/param norm = 2.7982e-01, time/batch = 18.4792s	
23710/26050 (epoch 45.509), train_loss = 0.91672275, grad/param norm = 2.5048e-01, time/batch = 18.2370s	
23711/26050 (epoch 45.511), train_loss = 0.78332318, grad/param norm = 2.1314e-01, time/batch = 17.8982s	
23712/26050 (epoch 45.512), train_loss = 0.68986625, grad/param norm = 2.2940e-01, time/batch = 14.8899s	
23713/26050 (epoch 45.514), train_loss = 0.84792076, grad/param norm = 2.6763e-01, time/batch = 18.5739s	
23714/26050 (epoch 45.516), train_loss = 0.91630096, grad/param norm = 2.4138e-01, time/batch = 17.9831s	
23715/26050 (epoch 45.518), train_loss = 0.78015526, grad/param norm = 1.9740e-01, time/batch = 16.8998s	
23716/26050 (epoch 45.520), train_loss = 0.79764096, grad/param norm = 2.1022e-01, time/batch = 17.1560s	
23717/26050 (epoch 45.522), train_loss = 0.62849376, grad/param norm = 2.0903e-01, time/batch = 17.5673s	
23718/26050 (epoch 45.524), train_loss = 0.86139399, grad/param norm = 2.5572e-01, time/batch = 18.4796s	
23719/26050 (epoch 45.526), train_loss = 0.90260150, grad/param norm = 2.6995e-01, time/batch = 18.2259s	
23720/26050 (epoch 45.528), train_loss = 0.82167482, grad/param norm = 2.3381e-01, time/batch = 14.7705s	
23721/26050 (epoch 45.530), train_loss = 0.77178629, grad/param norm = 2.5372e-01, time/batch = 17.3145s	
23722/26050 (epoch 45.532), train_loss = 0.85059890, grad/param norm = 2.2756e-01, time/batch = 18.7352s	
23723/26050 (epoch 45.534), train_loss = 0.81374897, grad/param norm = 2.8926e-01, time/batch = 17.9787s	
23724/26050 (epoch 45.536), train_loss = 0.84093660, grad/param norm = 2.3543e-01, time/batch = 17.8874s	
23725/26050 (epoch 45.537), train_loss = 0.88111733, grad/param norm = 2.8013e-01, time/batch = 18.0668s	
23726/26050 (epoch 45.539), train_loss = 0.84257334, grad/param norm = 2.5033e-01, time/batch = 14.7851s	
23727/26050 (epoch 45.541), train_loss = 0.93484436, grad/param norm = 2.5162e-01, time/batch = 16.3049s	
23728/26050 (epoch 45.543), train_loss = 0.62333346, grad/param norm = 1.9796e-01, time/batch = 17.6437s	
23729/26050 (epoch 45.545), train_loss = 0.77674350, grad/param norm = 2.2890e-01, time/batch = 18.0786s	
23730/26050 (epoch 45.547), train_loss = 0.73942032, grad/param norm = 2.3989e-01, time/batch = 18.3246s	
23731/26050 (epoch 45.549), train_loss = 0.69915603, grad/param norm = 2.3202e-01, time/batch = 17.5472s	
23732/26050 (epoch 45.551), train_loss = 0.86074943, grad/param norm = 2.5137e-01, time/batch = 18.7330s	
23733/26050 (epoch 45.553), train_loss = 0.76276662, grad/param norm = 2.1053e-01, time/batch = 18.2384s	
23734/26050 (epoch 45.555), train_loss = 0.67852006, grad/param norm = 2.1716e-01, time/batch = 17.8231s	
23735/26050 (epoch 45.557), train_loss = 0.82034576, grad/param norm = 2.1883e-01, time/batch = 14.3469s	
23736/26050 (epoch 45.559), train_loss = 0.82182337, grad/param norm = 2.2004e-01, time/batch = 18.7326s	
23737/26050 (epoch 45.560), train_loss = 0.76962640, grad/param norm = 2.5754e-01, time/batch = 17.4882s	
23738/26050 (epoch 45.562), train_loss = 0.80166300, grad/param norm = 2.6319e-01, time/batch = 17.4874s	
23739/26050 (epoch 45.564), train_loss = 0.94822175, grad/param norm = 2.3164e-01, time/batch = 18.3136s	
23740/26050 (epoch 45.566), train_loss = 0.73919081, grad/param norm = 2.1178e-01, time/batch = 18.9822s	
23741/26050 (epoch 45.568), train_loss = 0.83097976, grad/param norm = 2.1163e-01, time/batch = 17.8966s	
23742/26050 (epoch 45.570), train_loss = 0.79416409, grad/param norm = 2.3217e-01, time/batch = 16.7215s	
23743/26050 (epoch 45.572), train_loss = 0.81617289, grad/param norm = 3.1092e-01, time/batch = 16.6328s	
23744/26050 (epoch 45.574), train_loss = 0.85898019, grad/param norm = 4.1661e-01, time/batch = 18.1526s	
23745/26050 (epoch 45.576), train_loss = 0.81284260, grad/param norm = 2.3346e-01, time/batch = 17.5585s	
23746/26050 (epoch 45.578), train_loss = 0.77161012, grad/param norm = 2.6610e-01, time/batch = 18.4065s	
23747/26050 (epoch 45.580), train_loss = 0.72360048, grad/param norm = 2.2993e-01, time/batch = 18.6600s	
23748/26050 (epoch 45.582), train_loss = 0.81452205, grad/param norm = 2.2350e-01, time/batch = 17.7990s	
23749/26050 (epoch 45.583), train_loss = 0.83878385, grad/param norm = 2.1341e-01, time/batch = 17.6392s	
23750/26050 (epoch 45.585), train_loss = 0.71953344, grad/param norm = 2.1735e-01, time/batch = 17.4926s	
23751/26050 (epoch 45.587), train_loss = 0.81639867, grad/param norm = 2.3765e-01, time/batch = 15.8481s	
23752/26050 (epoch 45.589), train_loss = 0.94443774, grad/param norm = 2.4772e-01, time/batch = 19.4641s	
23753/26050 (epoch 45.591), train_loss = 0.81759428, grad/param norm = 2.0323e-01, time/batch = 17.9016s	
23754/26050 (epoch 45.593), train_loss = 0.68843712, grad/param norm = 2.1374e-01, time/batch = 16.8999s	
23755/26050 (epoch 45.595), train_loss = 0.83470369, grad/param norm = 2.2175e-01, time/batch = 16.8035s	
23756/26050 (epoch 45.597), train_loss = 0.81833963, grad/param norm = 2.4915e-01, time/batch = 14.5496s	
23757/26050 (epoch 45.599), train_loss = 0.86891598, grad/param norm = 2.2486e-01, time/batch = 18.7370s	
23758/26050 (epoch 45.601), train_loss = 0.95834039, grad/param norm = 2.4627e-01, time/batch = 17.8853s	
23759/26050 (epoch 45.603), train_loss = 0.86131928, grad/param norm = 2.4024e-01, time/batch = 17.3257s	
23760/26050 (epoch 45.605), train_loss = 0.79092042, grad/param norm = 2.2571e-01, time/batch = 15.0521s	
23761/26050 (epoch 45.607), train_loss = 0.88717262, grad/param norm = 2.9213e-01, time/batch = 17.8860s	
23762/26050 (epoch 45.608), train_loss = 0.73918995, grad/param norm = 2.1034e-01, time/batch = 16.6303s	
23763/26050 (epoch 45.610), train_loss = 0.81261774, grad/param norm = 2.5495e-01, time/batch = 18.4051s	
23764/26050 (epoch 45.612), train_loss = 0.77734196, grad/param norm = 2.4740e-01, time/batch = 18.4693s	
23765/26050 (epoch 45.614), train_loss = 0.83416619, grad/param norm = 2.5980e-01, time/batch = 17.5586s	
23766/26050 (epoch 45.616), train_loss = 0.84426064, grad/param norm = 2.7323e-01, time/batch = 16.5502s	
23767/26050 (epoch 45.618), train_loss = 0.74412540, grad/param norm = 2.1426e-01, time/batch = 17.8051s	
23768/26050 (epoch 45.620), train_loss = 0.88530377, grad/param norm = 2.6214e-01, time/batch = 17.9087s	
23769/26050 (epoch 45.622), train_loss = 0.75156741, grad/param norm = 2.1850e-01, time/batch = 17.9646s	
23770/26050 (epoch 45.624), train_loss = 0.66795208, grad/param norm = 2.2168e-01, time/batch = 15.4020s	
23771/26050 (epoch 45.626), train_loss = 0.84096681, grad/param norm = 2.3959e-01, time/batch = 17.9617s	
23772/26050 (epoch 45.628), train_loss = 0.74844950, grad/param norm = 2.8057e-01, time/batch = 16.7150s	
23773/26050 (epoch 45.630), train_loss = 0.94347645, grad/param norm = 2.2556e-01, time/batch = 18.3231s	
23774/26050 (epoch 45.631), train_loss = 0.93641899, grad/param norm = 2.5970e-01, time/batch = 18.9927s	
23775/26050 (epoch 45.633), train_loss = 0.73567104, grad/param norm = 2.1916e-01, time/batch = 15.8096s	
23776/26050 (epoch 45.635), train_loss = 0.76070974, grad/param norm = 1.9110e-01, time/batch = 18.2170s	
23777/26050 (epoch 45.637), train_loss = 0.71199119, grad/param norm = 2.0036e-01, time/batch = 18.3102s	
23778/26050 (epoch 45.639), train_loss = 0.84090624, grad/param norm = 2.2293e-01, time/batch = 18.0691s	
23779/26050 (epoch 45.641), train_loss = 0.73181856, grad/param norm = 2.1483e-01, time/batch = 17.3271s	
23780/26050 (epoch 45.643), train_loss = 0.73479496, grad/param norm = 1.8747e-01, time/batch = 18.2119s	
23781/26050 (epoch 45.645), train_loss = 0.75911037, grad/param norm = 2.1782e-01, time/batch = 18.4577s	
23782/26050 (epoch 45.647), train_loss = 0.70228243, grad/param norm = 2.4672e-01, time/batch = 17.2184s	
23783/26050 (epoch 45.649), train_loss = 0.75421836, grad/param norm = 2.1721e-01, time/batch = 17.3133s	
23784/26050 (epoch 45.651), train_loss = 0.79280589, grad/param norm = 2.3082e-01, time/batch = 17.6234s	
23785/26050 (epoch 45.653), train_loss = 0.78780382, grad/param norm = 2.3470e-01, time/batch = 18.8134s	
23786/26050 (epoch 45.655), train_loss = 0.70713015, grad/param norm = 2.0251e-01, time/batch = 17.7246s	
23787/26050 (epoch 45.656), train_loss = 0.71580385, grad/param norm = 2.1861e-01, time/batch = 16.0401s	
23788/26050 (epoch 45.658), train_loss = 0.93718456, grad/param norm = 2.3293e-01, time/batch = 17.8412s	
23789/26050 (epoch 45.660), train_loss = 0.65512453, grad/param norm = 2.0999e-01, time/batch = 16.9823s	
23790/26050 (epoch 45.662), train_loss = 0.78913798, grad/param norm = 1.9809e-01, time/batch = 14.9708s	
23791/26050 (epoch 45.664), train_loss = 0.78609203, grad/param norm = 2.0805e-01, time/batch = 18.9944s	
23792/26050 (epoch 45.666), train_loss = 0.77007197, grad/param norm = 2.2450e-01, time/batch = 17.9033s	
23793/26050 (epoch 45.668), train_loss = 0.61390056, grad/param norm = 2.3001e-01, time/batch = 17.1215s	
23794/26050 (epoch 45.670), train_loss = 0.91358734, grad/param norm = 2.8454e-01, time/batch = 17.8191s	
23795/26050 (epoch 45.672), train_loss = 0.77034990, grad/param norm = 1.9844e-01, time/batch = 16.4038s	
23796/26050 (epoch 45.674), train_loss = 0.70189426, grad/param norm = 2.7587e-01, time/batch = 17.5562s	
23797/26050 (epoch 45.676), train_loss = 0.82759059, grad/param norm = 2.8977e-01, time/batch = 17.5590s	
23798/26050 (epoch 45.678), train_loss = 0.87368691, grad/param norm = 2.4133e-01, time/batch = 18.9828s	
23799/26050 (epoch 45.679), train_loss = 0.90501649, grad/param norm = 2.5792e-01, time/batch = 17.7187s	
23800/26050 (epoch 45.681), train_loss = 0.81019990, grad/param norm = 2.1595e-01, time/batch = 18.4026s	
23801/26050 (epoch 45.683), train_loss = 0.72001279, grad/param norm = 2.5152e-01, time/batch = 17.7339s	
23802/26050 (epoch 45.685), train_loss = 0.75203916, grad/param norm = 2.2922e-01, time/batch = 18.8098s	
23803/26050 (epoch 45.687), train_loss = 0.69813905, grad/param norm = 2.1588e-01, time/batch = 18.6395s	
23804/26050 (epoch 45.689), train_loss = 0.74479406, grad/param norm = 2.4997e-01, time/batch = 14.7370s	
23805/26050 (epoch 45.691), train_loss = 0.64653500, grad/param norm = 1.7770e-01, time/batch = 16.7283s	
23806/26050 (epoch 45.693), train_loss = 0.75796760, grad/param norm = 3.0116e-01, time/batch = 15.9670s	
23807/26050 (epoch 45.695), train_loss = 0.78197113, grad/param norm = 2.2638e-01, time/batch = 18.8936s	
23808/26050 (epoch 45.697), train_loss = 0.72594944, grad/param norm = 2.3787e-01, time/batch = 17.9010s	
23809/26050 (epoch 45.699), train_loss = 0.83305138, grad/param norm = 2.4888e-01, time/batch = 18.3131s	
23810/26050 (epoch 45.701), train_loss = 0.71612293, grad/param norm = 1.9357e-01, time/batch = 18.3741s	
23811/26050 (epoch 45.702), train_loss = 0.85003463, grad/param norm = 2.3738e-01, time/batch = 18.1347s	
23812/26050 (epoch 45.704), train_loss = 0.90810232, grad/param norm = 2.2855e-01, time/batch = 18.1502s	
23813/26050 (epoch 45.706), train_loss = 0.74600542, grad/param norm = 2.5016e-01, time/batch = 16.6593s	
23814/26050 (epoch 45.708), train_loss = 0.84979179, grad/param norm = 2.4271e-01, time/batch = 18.0611s	
23815/26050 (epoch 45.710), train_loss = 0.81482934, grad/param norm = 2.4219e-01, time/batch = 16.5387s	
23816/26050 (epoch 45.712), train_loss = 0.78542140, grad/param norm = 2.5130e-01, time/batch = 17.8106s	
23817/26050 (epoch 45.714), train_loss = 0.70342991, grad/param norm = 2.0085e-01, time/batch = 18.8942s	
23818/26050 (epoch 45.716), train_loss = 0.98485662, grad/param norm = 2.3865e-01, time/batch = 16.0566s	
23819/26050 (epoch 45.718), train_loss = 0.84883010, grad/param norm = 2.3676e-01, time/batch = 16.8919s	
23820/26050 (epoch 45.720), train_loss = 0.78382343, grad/param norm = 2.6006e-01, time/batch = 17.4978s	
23821/26050 (epoch 45.722), train_loss = 0.73107425, grad/param norm = 2.7541e-01, time/batch = 17.9854s	
23822/26050 (epoch 45.724), train_loss = 0.74896128, grad/param norm = 2.3891e-01, time/batch = 17.3110s	
23823/26050 (epoch 45.726), train_loss = 0.86095548, grad/param norm = 2.3326e-01, time/batch = 16.8000s	
23824/26050 (epoch 45.727), train_loss = 0.83174737, grad/param norm = 2.3109e-01, time/batch = 18.5738s	
23825/26050 (epoch 45.729), train_loss = 0.84320838, grad/param norm = 2.2594e-01, time/batch = 18.9743s	
23826/26050 (epoch 45.731), train_loss = 0.83740288, grad/param norm = 2.2589e-01, time/batch = 16.5823s	
23827/26050 (epoch 45.733), train_loss = 0.75725402, grad/param norm = 2.4142e-01, time/batch = 17.6496s	
23828/26050 (epoch 45.735), train_loss = 0.89989169, grad/param norm = 2.5072e-01, time/batch = 16.3984s	
23829/26050 (epoch 45.737), train_loss = 0.74401060, grad/param norm = 2.2105e-01, time/batch = 16.3027s	
23830/26050 (epoch 45.739), train_loss = 0.81982974, grad/param norm = 2.0993e-01, time/batch = 17.2454s	
23831/26050 (epoch 45.741), train_loss = 0.71632708, grad/param norm = 2.0558e-01, time/batch = 14.8123s	
23832/26050 (epoch 45.743), train_loss = 0.79065953, grad/param norm = 2.7706e-01, time/batch = 18.1296s	
23833/26050 (epoch 45.745), train_loss = 0.71687203, grad/param norm = 2.0682e-01, time/batch = 18.0581s	
23834/26050 (epoch 45.747), train_loss = 0.75275550, grad/param norm = 2.1496e-01, time/batch = 18.4867s	
23835/26050 (epoch 45.749), train_loss = 0.88602675, grad/param norm = 2.6902e-01, time/batch = 17.5750s	
23836/26050 (epoch 45.750), train_loss = 0.74320804, grad/param norm = 1.9997e-01, time/batch = 17.4785s	
23837/26050 (epoch 45.752), train_loss = 0.73315701, grad/param norm = 2.4904e-01, time/batch = 16.5452s	
23838/26050 (epoch 45.754), train_loss = 0.79312376, grad/param norm = 2.4239e-01, time/batch = 17.7446s	
23839/26050 (epoch 45.756), train_loss = 0.76945458, grad/param norm = 3.3763e-01, time/batch = 18.7226s	
23840/26050 (epoch 45.758), train_loss = 0.78253511, grad/param norm = 2.8120e-01, time/batch = 17.5722s	
23841/26050 (epoch 45.760), train_loss = 0.91930201, grad/param norm = 2.8630e-01, time/batch = 18.2198s	
23842/26050 (epoch 45.762), train_loss = 0.75223395, grad/param norm = 2.1872e-01, time/batch = 18.6523s	
23843/26050 (epoch 45.764), train_loss = 0.76860145, grad/param norm = 2.7022e-01, time/batch = 17.3221s	
23844/26050 (epoch 45.766), train_loss = 0.77040291, grad/param norm = 2.3603e-01, time/batch = 18.5360s	
23845/26050 (epoch 45.768), train_loss = 0.67443481, grad/param norm = 1.9985e-01, time/batch = 15.2183s	
23846/26050 (epoch 45.770), train_loss = 0.76184641, grad/param norm = 2.0959e-01, time/batch = 17.6413s	
23847/26050 (epoch 45.772), train_loss = 0.80680961, grad/param norm = 2.3761e-01, time/batch = 16.1318s	
23848/26050 (epoch 45.774), train_loss = 0.65882319, grad/param norm = 2.2596e-01, time/batch = 18.9690s	
23849/26050 (epoch 45.775), train_loss = 0.56000185, grad/param norm = 2.2766e-01, time/batch = 18.1377s	
23850/26050 (epoch 45.777), train_loss = 0.74309513, grad/param norm = 2.2619e-01, time/batch = 16.3022s	
23851/26050 (epoch 45.779), train_loss = 0.77229500, grad/param norm = 2.6801e-01, time/batch = 19.0535s	
23852/26050 (epoch 45.781), train_loss = 0.71919123, grad/param norm = 2.2996e-01, time/batch = 18.2207s	
23853/26050 (epoch 45.783), train_loss = 0.68329394, grad/param norm = 2.0173e-01, time/batch = 18.5561s	
23854/26050 (epoch 45.785), train_loss = 0.78950540, grad/param norm = 2.4419e-01, time/batch = 18.1289s	
23855/26050 (epoch 45.787), train_loss = 0.70795322, grad/param norm = 2.3845e-01, time/batch = 18.9746s	
23856/26050 (epoch 45.789), train_loss = 0.72106816, grad/param norm = 2.7620e-01, time/batch = 17.5593s	
23857/26050 (epoch 45.791), train_loss = 0.71826814, grad/param norm = 3.1658e-01, time/batch = 15.3082s	
23858/26050 (epoch 45.793), train_loss = 0.78398452, grad/param norm = 2.2577e-01, time/batch = 17.7337s	
23859/26050 (epoch 45.795), train_loss = 0.63078714, grad/param norm = 1.9813e-01, time/batch = 18.3205s	
23860/26050 (epoch 45.797), train_loss = 0.70714382, grad/param norm = 2.5077e-01, time/batch = 17.5535s	
23861/26050 (epoch 45.798), train_loss = 0.78067697, grad/param norm = 2.6237e-01, time/batch = 32.3676s	
23862/26050 (epoch 45.800), train_loss = 0.66595780, grad/param norm = 2.2033e-01, time/batch = 25.1481s	
23863/26050 (epoch 45.802), train_loss = 0.75075086, grad/param norm = 2.2555e-01, time/batch = 15.3191s	
23864/26050 (epoch 45.804), train_loss = 0.78592794, grad/param norm = 3.1253e-01, time/batch = 18.7362s	
23865/26050 (epoch 45.806), train_loss = 0.84708398, grad/param norm = 2.6329e-01, time/batch = 18.5774s	
23866/26050 (epoch 45.808), train_loss = 0.79138179, grad/param norm = 2.0265e-01, time/batch = 17.1573s	
23867/26050 (epoch 45.810), train_loss = 0.79706276, grad/param norm = 3.2659e-01, time/batch = 18.7269s	
23868/26050 (epoch 45.812), train_loss = 0.65901968, grad/param norm = 2.6079e-01, time/batch = 18.4010s	
23869/26050 (epoch 45.814), train_loss = 0.68028206, grad/param norm = 2.9095e-01, time/batch = 15.7008s	
23870/26050 (epoch 45.816), train_loss = 0.80472108, grad/param norm = 2.4961e-01, time/batch = 15.2912s	
23871/26050 (epoch 45.818), train_loss = 0.84287685, grad/param norm = 2.9703e-01, time/batch = 17.8641s	
23872/26050 (epoch 45.820), train_loss = 0.78854306, grad/param norm = 2.2801e-01, time/batch = 19.1423s	
23873/26050 (epoch 45.821), train_loss = 0.88142689, grad/param norm = 3.0669e-01, time/batch = 17.4612s	
23874/26050 (epoch 45.823), train_loss = 0.95826595, grad/param norm = 2.3291e-01, time/batch = 18.5735s	
23875/26050 (epoch 45.825), train_loss = 0.77148599, grad/param norm = 2.2115e-01, time/batch = 18.7228s	
23876/26050 (epoch 45.827), train_loss = 0.79493932, grad/param norm = 3.0832e-01, time/batch = 16.8976s	
23877/26050 (epoch 45.829), train_loss = 0.92124677, grad/param norm = 3.3492e-01, time/batch = 18.6342s	
23878/26050 (epoch 45.831), train_loss = 0.93003997, grad/param norm = 2.6334e-01, time/batch = 18.3816s	
23879/26050 (epoch 45.833), train_loss = 0.88508480, grad/param norm = 3.1987e-01, time/batch = 16.9885s	
23880/26050 (epoch 45.835), train_loss = 0.90537299, grad/param norm = 2.3676e-01, time/batch = 17.6718s	
23881/26050 (epoch 45.837), train_loss = 0.82313700, grad/param norm = 2.2472e-01, time/batch = 18.0638s	
23882/26050 (epoch 45.839), train_loss = 0.77128277, grad/param norm = 2.5181e-01, time/batch = 18.8073s	
23883/26050 (epoch 45.841), train_loss = 0.84042810, grad/param norm = 2.5014e-01, time/batch = 17.7974s	
23884/26050 (epoch 45.843), train_loss = 0.76295205, grad/param norm = 2.0222e-01, time/batch = 17.9846s	
23885/26050 (epoch 45.845), train_loss = 0.74821901, grad/param norm = 2.2038e-01, time/batch = 18.0693s	
23886/26050 (epoch 45.846), train_loss = 0.81830397, grad/param norm = 2.2338e-01, time/batch = 15.0663s	
23887/26050 (epoch 45.848), train_loss = 0.77263975, grad/param norm = 2.6733e-01, time/batch = 16.9649s	
23888/26050 (epoch 45.850), train_loss = 0.68471892, grad/param norm = 1.8844e-01, time/batch = 17.4835s	
23889/26050 (epoch 45.852), train_loss = 0.81155980, grad/param norm = 2.1668e-01, time/batch = 17.8856s	
23890/26050 (epoch 45.854), train_loss = 0.79265493, grad/param norm = 2.5220e-01, time/batch = 14.9677s	
23891/26050 (epoch 45.856), train_loss = 0.74870147, grad/param norm = 2.3719e-01, time/batch = 17.9061s	
23892/26050 (epoch 45.858), train_loss = 0.71662194, grad/param norm = 2.2763e-01, time/batch = 17.7493s	
23893/26050 (epoch 45.860), train_loss = 0.80003262, grad/param norm = 2.6520e-01, time/batch = 16.9846s	
23894/26050 (epoch 45.862), train_loss = 0.86268056, grad/param norm = 2.3845e-01, time/batch = 14.5435s	
23895/26050 (epoch 45.864), train_loss = 0.76786082, grad/param norm = 2.8104e-01, time/batch = 18.0669s	
23896/26050 (epoch 45.866), train_loss = 0.78036195, grad/param norm = 2.1518e-01, time/batch = 17.2225s	
23897/26050 (epoch 45.868), train_loss = 0.84047003, grad/param norm = 2.8117e-01, time/batch = 16.5414s	
23898/26050 (epoch 45.869), train_loss = 0.73716030, grad/param norm = 2.2253e-01, time/batch = 18.5716s	
23899/26050 (epoch 45.871), train_loss = 0.65910851, grad/param norm = 1.9899e-01, time/batch = 15.1533s	
23900/26050 (epoch 45.873), train_loss = 0.83081507, grad/param norm = 2.3574e-01, time/batch = 16.9909s	
23901/26050 (epoch 45.875), train_loss = 0.74137739, grad/param norm = 2.5762e-01, time/batch = 15.2381s	
23902/26050 (epoch 45.877), train_loss = 0.74608419, grad/param norm = 1.9609e-01, time/batch = 17.9001s	
23903/26050 (epoch 45.879), train_loss = 0.84379256, grad/param norm = 2.1608e-01, time/batch = 18.4711s	
23904/26050 (epoch 45.881), train_loss = 0.85638586, grad/param norm = 2.4508e-01, time/batch = 17.4810s	
23905/26050 (epoch 45.883), train_loss = 0.84954370, grad/param norm = 2.3903e-01, time/batch = 18.6399s	
23906/26050 (epoch 45.885), train_loss = 0.61016253, grad/param norm = 1.9539e-01, time/batch = 18.1404s	
23907/26050 (epoch 45.887), train_loss = 0.87983367, grad/param norm = 2.6169e-01, time/batch = 17.0552s	
23908/26050 (epoch 45.889), train_loss = 0.73141065, grad/param norm = 2.2224e-01, time/batch = 18.6419s	
23909/26050 (epoch 45.891), train_loss = 0.66364713, grad/param norm = 2.2315e-01, time/batch = 18.2952s	
23910/26050 (epoch 45.893), train_loss = 0.65819052, grad/param norm = 2.1900e-01, time/batch = 15.4651s	
23911/26050 (epoch 45.894), train_loss = 0.73758029, grad/param norm = 2.3305e-01, time/batch = 18.2247s	
23912/26050 (epoch 45.896), train_loss = 0.84402064, grad/param norm = 2.3028e-01, time/batch = 18.0702s	
23913/26050 (epoch 45.898), train_loss = 0.71734918, grad/param norm = 2.1011e-01, time/batch = 14.4796s	
23914/26050 (epoch 45.900), train_loss = 0.84742099, grad/param norm = 2.8282e-01, time/batch = 17.2195s	
23915/26050 (epoch 45.902), train_loss = 0.74769793, grad/param norm = 2.2152e-01, time/batch = 18.8795s	
23916/26050 (epoch 45.904), train_loss = 0.77113676, grad/param norm = 2.5239e-01, time/batch = 18.4859s	
23917/26050 (epoch 45.906), train_loss = 0.75105826, grad/param norm = 2.7551e-01, time/batch = 18.1511s	
23918/26050 (epoch 45.908), train_loss = 0.81655322, grad/param norm = 2.5990e-01, time/batch = 16.1485s	
23919/26050 (epoch 45.910), train_loss = 0.72091683, grad/param norm = 2.1351e-01, time/batch = 17.4835s	
23920/26050 (epoch 45.912), train_loss = 0.95056667, grad/param norm = 2.6591e-01, time/batch = 16.8845s	
23921/26050 (epoch 45.914), train_loss = 1.06203978, grad/param norm = 2.6331e-01, time/batch = 17.8944s	
23922/26050 (epoch 45.916), train_loss = 0.81719812, grad/param norm = 2.2531e-01, time/batch = 18.1387s	
23923/26050 (epoch 45.917), train_loss = 0.81214706, grad/param norm = 2.5125e-01, time/batch = 18.4063s	
23924/26050 (epoch 45.919), train_loss = 0.81425111, grad/param norm = 2.8066e-01, time/batch = 17.5559s	
23925/26050 (epoch 45.921), train_loss = 0.71059296, grad/param norm = 2.1144e-01, time/batch = 17.2275s	
23926/26050 (epoch 45.923), train_loss = 0.80607176, grad/param norm = 3.6724e-01, time/batch = 17.8819s	
23927/26050 (epoch 45.925), train_loss = 0.79174247, grad/param norm = 2.6296e-01, time/batch = 17.8895s	
23928/26050 (epoch 45.927), train_loss = 0.71986011, grad/param norm = 1.6877e-01, time/batch = 15.2228s	
23929/26050 (epoch 45.929), train_loss = 0.66601580, grad/param norm = 2.1005e-01, time/batch = 16.9773s	
23930/26050 (epoch 45.931), train_loss = 0.92916130, grad/param norm = 2.8806e-01, time/batch = 17.5568s	
23931/26050 (epoch 45.933), train_loss = 0.78648073, grad/param norm = 2.4469e-01, time/batch = 17.9680s	
23932/26050 (epoch 45.935), train_loss = 0.76325058, grad/param norm = 2.0715e-01, time/batch = 18.6442s	
23933/26050 (epoch 45.937), train_loss = 0.85644825, grad/param norm = 2.2774e-01, time/batch = 16.2169s	
23934/26050 (epoch 45.939), train_loss = 0.72942580, grad/param norm = 1.8924e-01, time/batch = 18.0531s	
23935/26050 (epoch 45.940), train_loss = 0.79354443, grad/param norm = 2.2313e-01, time/batch = 18.4936s	
23936/26050 (epoch 45.942), train_loss = 0.71606826, grad/param norm = 2.2300e-01, time/batch = 17.8944s	
23937/26050 (epoch 45.944), train_loss = 0.76046917, grad/param norm = 2.0222e-01, time/batch = 16.9586s	
23938/26050 (epoch 45.946), train_loss = 0.93410076, grad/param norm = 2.4793e-01, time/batch = 17.9750s	
23939/26050 (epoch 45.948), train_loss = 0.66335814, grad/param norm = 2.1570e-01, time/batch = 18.3142s	
23940/26050 (epoch 45.950), train_loss = 0.79311086, grad/param norm = 2.1174e-01, time/batch = 15.3060s	
23941/26050 (epoch 45.952), train_loss = 0.82403700, grad/param norm = 2.3921e-01, time/batch = 17.6442s	
23942/26050 (epoch 45.954), train_loss = 0.84315400, grad/param norm = 2.3475e-01, time/batch = 18.8229s	
23943/26050 (epoch 45.956), train_loss = 0.74742215, grad/param norm = 2.4557e-01, time/batch = 18.7129s	
23944/26050 (epoch 45.958), train_loss = 0.69893007, grad/param norm = 2.0074e-01, time/batch = 17.8083s	
23945/26050 (epoch 45.960), train_loss = 0.81487663, grad/param norm = 2.2047e-01, time/batch = 17.5614s	
23946/26050 (epoch 45.962), train_loss = 0.78076242, grad/param norm = 2.0134e-01, time/batch = 17.8151s	
23947/26050 (epoch 45.964), train_loss = 0.74357109, grad/param norm = 2.2555e-01, time/batch = 18.1467s	
23948/26050 (epoch 45.965), train_loss = 0.70242263, grad/param norm = 2.0861e-01, time/batch = 16.8258s	
23949/26050 (epoch 45.967), train_loss = 1.00889798, grad/param norm = 2.3087e-01, time/batch = 18.8175s	
23950/26050 (epoch 45.969), train_loss = 0.78258587, grad/param norm = 2.3086e-01, time/batch = 15.4637s	
23951/26050 (epoch 45.971), train_loss = 0.80268806, grad/param norm = 2.3848e-01, time/batch = 15.6394s	
23952/26050 (epoch 45.973), train_loss = 0.79684678, grad/param norm = 2.1880e-01, time/batch = 18.4826s	
23953/26050 (epoch 45.975), train_loss = 0.77638220, grad/param norm = 2.0031e-01, time/batch = 15.3035s	
23954/26050 (epoch 45.977), train_loss = 0.77009847, grad/param norm = 2.2451e-01, time/batch = 19.3013s	
23955/26050 (epoch 45.979), train_loss = 0.62926993, grad/param norm = 1.9040e-01, time/batch = 16.9771s	
23956/26050 (epoch 45.981), train_loss = 0.85462475, grad/param norm = 2.0708e-01, time/batch = 16.8850s	
23957/26050 (epoch 45.983), train_loss = 0.81051068, grad/param norm = 2.1481e-01, time/batch = 18.1538s	
23958/26050 (epoch 45.985), train_loss = 0.80846049, grad/param norm = 2.7993e-01, time/batch = 17.8873s	
23959/26050 (epoch 45.987), train_loss = 0.87043242, grad/param norm = 2.4882e-01, time/batch = 17.8852s	
23960/26050 (epoch 45.988), train_loss = 0.82084401, grad/param norm = 2.4934e-01, time/batch = 18.5603s	
23961/26050 (epoch 45.990), train_loss = 0.67396874, grad/param norm = 2.0580e-01, time/batch = 18.4566s	
23962/26050 (epoch 45.992), train_loss = 0.90341732, grad/param norm = 2.3916e-01, time/batch = 17.4813s	
23963/26050 (epoch 45.994), train_loss = 0.71610248, grad/param norm = 2.4006e-01, time/batch = 18.6419s	
23964/26050 (epoch 45.996), train_loss = 0.68495894, grad/param norm = 2.2493e-01, time/batch = 17.6536s	
23965/26050 (epoch 45.998), train_loss = 0.79920259, grad/param norm = 2.4896e-01, time/batch = 16.2100s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
23966/26050 (epoch 46.000), train_loss = 0.70411120, grad/param norm = 2.1045e-01, time/batch = 17.8129s	
23967/26050 (epoch 46.002), train_loss = 0.85700547, grad/param norm = 2.3400e-01, time/batch = 18.8052s	
23968/26050 (epoch 46.004), train_loss = 0.68877116, grad/param norm = 2.2227e-01, time/batch = 17.0559s	
23969/26050 (epoch 46.006), train_loss = 0.73252117, grad/param norm = 2.3847e-01, time/batch = 18.4047s	
23970/26050 (epoch 46.008), train_loss = 0.73006663, grad/param norm = 2.2970e-01, time/batch = 18.0675s	
23971/26050 (epoch 46.010), train_loss = 0.69928010, grad/param norm = 1.9933e-01, time/batch = 15.8786s	
23972/26050 (epoch 46.012), train_loss = 0.76609877, grad/param norm = 2.1963e-01, time/batch = 16.1230s	
23973/26050 (epoch 46.013), train_loss = 0.99849785, grad/param norm = 2.5587e-01, time/batch = 17.7209s	
23974/26050 (epoch 46.015), train_loss = 0.77533238, grad/param norm = 2.1623e-01, time/batch = 16.6431s	
23975/26050 (epoch 46.017), train_loss = 0.80088168, grad/param norm = 2.0735e-01, time/batch = 17.9696s	
23976/26050 (epoch 46.019), train_loss = 0.67845529, grad/param norm = 1.7223e-01, time/batch = 18.4873s	
23977/26050 (epoch 46.021), train_loss = 0.83056733, grad/param norm = 2.2062e-01, time/batch = 18.0593s	
23978/26050 (epoch 46.023), train_loss = 0.64414573, grad/param norm = 2.2181e-01, time/batch = 18.4779s	
23979/26050 (epoch 46.025), train_loss = 0.77640824, grad/param norm = 2.2640e-01, time/batch = 17.9068s	
23980/26050 (epoch 46.027), train_loss = 0.61236063, grad/param norm = 2.0119e-01, time/batch = 17.6493s	
23981/26050 (epoch 46.029), train_loss = 0.84660984, grad/param norm = 2.1656e-01, time/batch = 17.1347s	
23982/26050 (epoch 46.031), train_loss = 0.87997023, grad/param norm = 2.7404e-01, time/batch = 16.1348s	
23983/26050 (epoch 46.033), train_loss = 0.75762585, grad/param norm = 2.1720e-01, time/batch = 18.5477s	
23984/26050 (epoch 46.035), train_loss = 0.80775028, grad/param norm = 2.0351e-01, time/batch = 18.2332s	
23985/26050 (epoch 46.036), train_loss = 0.67364276, grad/param norm = 2.3090e-01, time/batch = 17.7370s	
23986/26050 (epoch 46.038), train_loss = 0.63846291, grad/param norm = 2.2453e-01, time/batch = 17.9936s	
23987/26050 (epoch 46.040), train_loss = 0.77158840, grad/param norm = 2.5339e-01, time/batch = 17.9775s	
23988/26050 (epoch 46.042), train_loss = 0.67025835, grad/param norm = 2.2789e-01, time/batch = 16.5521s	
23989/26050 (epoch 46.044), train_loss = 0.83372102, grad/param norm = 2.0346e-01, time/batch = 18.1394s	
23990/26050 (epoch 46.046), train_loss = 0.65375569, grad/param norm = 1.9013e-01, time/batch = 18.6481s	
23991/26050 (epoch 46.048), train_loss = 0.78956622, grad/param norm = 2.1829e-01, time/batch = 17.8149s	
23992/26050 (epoch 46.050), train_loss = 0.74746477, grad/param norm = 2.2580e-01, time/batch = 17.3993s	
23993/26050 (epoch 46.052), train_loss = 0.72859060, grad/param norm = 2.2155e-01, time/batch = 16.6592s	
23994/26050 (epoch 46.054), train_loss = 0.65969750, grad/param norm = 2.2820e-01, time/batch = 16.6361s	
23995/26050 (epoch 46.056), train_loss = 0.65609250, grad/param norm = 1.7171e-01, time/batch = 15.6379s	
23996/26050 (epoch 46.058), train_loss = 0.75115208, grad/param norm = 2.0947e-01, time/batch = 16.7131s	
23997/26050 (epoch 46.060), train_loss = 0.82307480, grad/param norm = 2.0802e-01, time/batch = 18.3085s	
23998/26050 (epoch 46.061), train_loss = 0.65823984, grad/param norm = 1.9421e-01, time/batch = 17.8944s	
23999/26050 (epoch 46.063), train_loss = 0.75980232, grad/param norm = 2.2739e-01, time/batch = 15.6339s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch46.07_1.9572.t7	
24000/26050 (epoch 46.065), train_loss = 0.63286585, grad/param norm = 1.7302e-01, time/batch = 18.4860s	
24001/26050 (epoch 46.067), train_loss = 1.36328986, grad/param norm = 3.4620e-01, time/batch = 18.7048s	
24002/26050 (epoch 46.069), train_loss = 0.81852002, grad/param norm = 2.5333e-01, time/batch = 18.8039s	
24003/26050 (epoch 46.071), train_loss = 0.78061189, grad/param norm = 2.1629e-01, time/batch = 18.3116s	
24004/26050 (epoch 46.073), train_loss = 0.92194633, grad/param norm = 2.1505e-01, time/batch = 17.5706s	
24005/26050 (epoch 46.075), train_loss = 0.73145983, grad/param norm = 2.1482e-01, time/batch = 18.6627s	
24006/26050 (epoch 46.077), train_loss = 0.73447615, grad/param norm = 2.1584e-01, time/batch = 12.6378s	
24007/26050 (epoch 46.079), train_loss = 0.73994121, grad/param norm = 2.3630e-01, time/batch = 0.6932s	
24008/26050 (epoch 46.081), train_loss = 0.76413829, grad/param norm = 2.3687e-01, time/batch = 0.6873s	
24009/26050 (epoch 46.083), train_loss = 0.86478423, grad/param norm = 2.1300e-01, time/batch = 0.6843s	
24010/26050 (epoch 46.084), train_loss = 0.79932872, grad/param norm = 3.0586e-01, time/batch = 0.6764s	
24011/26050 (epoch 46.086), train_loss = 0.90805479, grad/param norm = 2.6937e-01, time/batch = 0.6654s	
24012/26050 (epoch 46.088), train_loss = 0.77381961, grad/param norm = 2.2770e-01, time/batch = 0.6472s	
24013/26050 (epoch 46.090), train_loss = 0.80350919, grad/param norm = 2.6104e-01, time/batch = 0.6618s	
24014/26050 (epoch 46.092), train_loss = 0.83730473, grad/param norm = 2.1266e-01, time/batch = 0.9339s	
24015/26050 (epoch 46.094), train_loss = 0.66349841, grad/param norm = 2.3711e-01, time/batch = 0.9576s	
24016/26050 (epoch 46.096), train_loss = 0.79841783, grad/param norm = 2.0461e-01, time/batch = 0.9617s	
24017/26050 (epoch 46.098), train_loss = 0.77071994, grad/param norm = 2.0246e-01, time/batch = 0.9406s	
24018/26050 (epoch 46.100), train_loss = 0.68806321, grad/param norm = 2.2935e-01, time/batch = 0.9320s	
24019/26050 (epoch 46.102), train_loss = 0.78079931, grad/param norm = 2.7467e-01, time/batch = 1.4771s	
24020/26050 (epoch 46.104), train_loss = 0.74387574, grad/param norm = 2.1570e-01, time/batch = 1.7908s	
24021/26050 (epoch 46.106), train_loss = 0.81746143, grad/param norm = 2.6195e-01, time/batch = 1.7736s	
24022/26050 (epoch 46.107), train_loss = 0.66082225, grad/param norm = 2.0435e-01, time/batch = 16.7053s	
24023/26050 (epoch 46.109), train_loss = 0.71936123, grad/param norm = 2.1666e-01, time/batch = 17.4760s	
24024/26050 (epoch 46.111), train_loss = 0.91010108, grad/param norm = 2.5763e-01, time/batch = 14.3902s	
24025/26050 (epoch 46.113), train_loss = 0.75361451, grad/param norm = 2.0266e-01, time/batch = 15.5725s	
24026/26050 (epoch 46.115), train_loss = 0.84494259, grad/param norm = 2.2225e-01, time/batch = 16.7959s	
24027/26050 (epoch 46.117), train_loss = 0.79237256, grad/param norm = 2.3122e-01, time/batch = 17.4015s	
24028/26050 (epoch 46.119), train_loss = 0.68239948, grad/param norm = 2.0390e-01, time/batch = 17.3011s	
24029/26050 (epoch 46.121), train_loss = 0.77195804, grad/param norm = 2.4880e-01, time/batch = 18.4054s	
24030/26050 (epoch 46.123), train_loss = 0.71915856, grad/param norm = 2.4855e-01, time/batch = 18.6517s	
24031/26050 (epoch 46.125), train_loss = 0.67564357, grad/param norm = 2.2694e-01, time/batch = 16.9062s	
24032/26050 (epoch 46.127), train_loss = 0.64316264, grad/param norm = 1.9137e-01, time/batch = 18.6503s	
24033/26050 (epoch 46.129), train_loss = 0.59750856, grad/param norm = 2.2405e-01, time/batch = 17.8147s	
24034/26050 (epoch 46.131), train_loss = 0.77753512, grad/param norm = 2.3862e-01, time/batch = 14.8483s	
24035/26050 (epoch 46.132), train_loss = 0.78632004, grad/param norm = 2.2248e-01, time/batch = 18.0014s	
24036/26050 (epoch 46.134), train_loss = 0.80064242, grad/param norm = 2.6342e-01, time/batch = 17.8959s	
24037/26050 (epoch 46.136), train_loss = 0.73956237, grad/param norm = 2.0571e-01, time/batch = 15.4603s	
24038/26050 (epoch 46.138), train_loss = 0.54497679, grad/param norm = 1.9876e-01, time/batch = 17.2273s	
24039/26050 (epoch 46.140), train_loss = 0.63354032, grad/param norm = 2.0289e-01, time/batch = 18.6569s	
24040/26050 (epoch 46.142), train_loss = 0.64461295, grad/param norm = 2.0155e-01, time/batch = 18.6413s	
24041/26050 (epoch 46.144), train_loss = 0.63270828, grad/param norm = 2.4474e-01, time/batch = 17.5624s	
24042/26050 (epoch 46.146), train_loss = 0.57146685, grad/param norm = 1.9323e-01, time/batch = 17.8985s	
24043/26050 (epoch 46.148), train_loss = 0.62410076, grad/param norm = 1.9480e-01, time/batch = 16.8910s	
24044/26050 (epoch 46.150), train_loss = 0.68793005, grad/param norm = 2.6578e-01, time/batch = 18.0610s	
24045/26050 (epoch 46.152), train_loss = 0.83656928, grad/param norm = 2.5040e-01, time/batch = 17.7306s	
24046/26050 (epoch 46.154), train_loss = 0.58993417, grad/param norm = 2.1422e-01, time/batch = 17.9981s	
24047/26050 (epoch 46.155), train_loss = 0.64035601, grad/param norm = 2.0046e-01, time/batch = 17.7245s	
24048/26050 (epoch 46.157), train_loss = 0.72157049, grad/param norm = 2.4019e-01, time/batch = 15.8885s	
24049/26050 (epoch 46.159), train_loss = 0.77745347, grad/param norm = 2.4463e-01, time/batch = 18.2212s	
24050/26050 (epoch 46.161), train_loss = 0.74942310, grad/param norm = 2.6442e-01, time/batch = 18.6497s	
24051/26050 (epoch 46.163), train_loss = 0.62905469, grad/param norm = 1.9164e-01, time/batch = 17.9046s	
24052/26050 (epoch 46.165), train_loss = 0.57090412, grad/param norm = 2.0515e-01, time/batch = 18.2195s	
24053/26050 (epoch 46.167), train_loss = 0.87716675, grad/param norm = 2.9161e-01, time/batch = 17.8244s	
24054/26050 (epoch 46.169), train_loss = 0.76372544, grad/param norm = 2.0958e-01, time/batch = 14.8522s	
24055/26050 (epoch 46.171), train_loss = 0.69610705, grad/param norm = 2.0829e-01, time/batch = 15.1181s	
24056/26050 (epoch 46.173), train_loss = 0.71909797, grad/param norm = 2.1227e-01, time/batch = 14.3558s	
24057/26050 (epoch 46.175), train_loss = 0.74462377, grad/param norm = 2.2561e-01, time/batch = 14.0494s	
24058/26050 (epoch 46.177), train_loss = 0.81171478, grad/param norm = 2.2992e-01, time/batch = 16.9097s	
24059/26050 (epoch 46.179), train_loss = 0.57472609, grad/param norm = 1.9445e-01, time/batch = 16.8178s	
24060/26050 (epoch 46.180), train_loss = 0.96081538, grad/param norm = 2.3102e-01, time/batch = 18.6611s	
24061/26050 (epoch 46.182), train_loss = 0.89315010, grad/param norm = 2.2888e-01, time/batch = 15.4794s	
24062/26050 (epoch 46.184), train_loss = 0.77513556, grad/param norm = 2.3985e-01, time/batch = 17.2082s	
24063/26050 (epoch 46.186), train_loss = 0.66886975, grad/param norm = 2.1192e-01, time/batch = 18.1456s	
24064/26050 (epoch 46.188), train_loss = 0.82522736, grad/param norm = 2.4701e-01, time/batch = 18.3966s	
24065/26050 (epoch 46.190), train_loss = 0.81371557, grad/param norm = 2.7837e-01, time/batch = 18.6457s	
24066/26050 (epoch 46.192), train_loss = 0.85752040, grad/param norm = 2.1995e-01, time/batch = 18.2273s	
24067/26050 (epoch 46.194), train_loss = 0.78530439, grad/param norm = 2.3534e-01, time/batch = 15.1332s	
24068/26050 (epoch 46.196), train_loss = 0.81579528, grad/param norm = 2.1379e-01, time/batch = 18.4843s	
24069/26050 (epoch 46.198), train_loss = 0.69098977, grad/param norm = 1.9490e-01, time/batch = 17.3950s	
24070/26050 (epoch 46.200), train_loss = 0.69730935, grad/param norm = 2.5194e-01, time/batch = 17.9800s	
24071/26050 (epoch 46.202), train_loss = 0.76763400, grad/param norm = 2.1204e-01, time/batch = 18.9737s	
24072/26050 (epoch 46.203), train_loss = 0.88268164, grad/param norm = 2.2038e-01, time/batch = 17.9622s	
24073/26050 (epoch 46.205), train_loss = 0.71842707, grad/param norm = 2.2123e-01, time/batch = 26.1111s	
24074/26050 (epoch 46.207), train_loss = 0.68443666, grad/param norm = 1.9246e-01, time/batch = 28.1447s	
24075/26050 (epoch 46.209), train_loss = 0.82691482, grad/param norm = 2.4057e-01, time/batch = 17.6824s	
24076/26050 (epoch 46.211), train_loss = 0.66277296, grad/param norm = 2.0288e-01, time/batch = 18.4836s	
24077/26050 (epoch 46.213), train_loss = 0.77240882, grad/param norm = 2.2341e-01, time/batch = 18.3925s	
24078/26050 (epoch 46.215), train_loss = 0.73017762, grad/param norm = 2.1150e-01, time/batch = 15.7132s	
24079/26050 (epoch 46.217), train_loss = 0.73932732, grad/param norm = 2.1526e-01, time/batch = 16.3758s	
24080/26050 (epoch 46.219), train_loss = 0.71947897, grad/param norm = 2.2069e-01, time/batch = 17.8181s	
24081/26050 (epoch 46.221), train_loss = 0.68780137, grad/param norm = 2.6612e-01, time/batch = 18.2456s	
24082/26050 (epoch 46.223), train_loss = 0.84025580, grad/param norm = 2.2982e-01, time/batch = 17.8832s	
24083/26050 (epoch 46.225), train_loss = 0.67800955, grad/param norm = 2.1104e-01, time/batch = 16.7946s	
24084/26050 (epoch 46.226), train_loss = 0.75689939, grad/param norm = 2.1454e-01, time/batch = 18.8927s	
24085/26050 (epoch 46.228), train_loss = 0.86338657, grad/param norm = 2.3968e-01, time/batch = 16.5534s	
24086/26050 (epoch 46.230), train_loss = 0.76939158, grad/param norm = 1.9700e-01, time/batch = 18.4784s	
24087/26050 (epoch 46.232), train_loss = 0.83832060, grad/param norm = 2.3877e-01, time/batch = 18.3056s	
24088/26050 (epoch 46.234), train_loss = 0.65277313, grad/param norm = 2.0466e-01, time/batch = 17.5704s	
24089/26050 (epoch 46.236), train_loss = 0.81608712, grad/param norm = 2.2876e-01, time/batch = 17.8130s	
24090/26050 (epoch 46.238), train_loss = 0.68830126, grad/param norm = 2.0481e-01, time/batch = 15.0662s	
24091/26050 (epoch 46.240), train_loss = 0.77848192, grad/param norm = 2.2514e-01, time/batch = 17.3142s	
24092/26050 (epoch 46.242), train_loss = 0.73863631, grad/param norm = 2.1598e-01, time/batch = 17.0738s	
24093/26050 (epoch 46.244), train_loss = 0.78444318, grad/param norm = 2.5780e-01, time/batch = 17.8050s	
24094/26050 (epoch 46.246), train_loss = 0.73081536, grad/param norm = 2.1461e-01, time/batch = 18.7485s	
24095/26050 (epoch 46.248), train_loss = 0.77380153, grad/param norm = 2.2595e-01, time/batch = 18.3905s	
24096/26050 (epoch 46.250), train_loss = 0.76949786, grad/param norm = 2.6393e-01, time/batch = 18.2478s	
24097/26050 (epoch 46.251), train_loss = 0.73439229, grad/param norm = 2.1369e-01, time/batch = 14.8084s	
24098/26050 (epoch 46.253), train_loss = 0.64402554, grad/param norm = 1.9190e-01, time/batch = 15.2055s	
24099/26050 (epoch 46.255), train_loss = 0.91939060, grad/param norm = 2.7721e-01, time/batch = 17.5581s	
24100/26050 (epoch 46.257), train_loss = 0.80343282, grad/param norm = 2.6314e-01, time/batch = 18.1511s	
24101/26050 (epoch 46.259), train_loss = 0.84448839, grad/param norm = 2.2683e-01, time/batch = 18.9854s	
24102/26050 (epoch 46.261), train_loss = 0.68086093, grad/param norm = 2.2008e-01, time/batch = 15.3929s	
24103/26050 (epoch 46.263), train_loss = 0.83216232, grad/param norm = 2.3131e-01, time/batch = 18.1476s	
24104/26050 (epoch 46.265), train_loss = 0.86004418, grad/param norm = 2.6245e-01, time/batch = 17.8843s	
24105/26050 (epoch 46.267), train_loss = 0.90435051, grad/param norm = 2.4414e-01, time/batch = 17.8859s	
24106/26050 (epoch 46.269), train_loss = 0.85272517, grad/param norm = 2.2789e-01, time/batch = 17.7418s	
24107/26050 (epoch 46.271), train_loss = 0.75922400, grad/param norm = 2.0882e-01, time/batch = 18.5623s	
24108/26050 (epoch 46.273), train_loss = 0.69340206, grad/param norm = 2.0948e-01, time/batch = 16.4548s	
24109/26050 (epoch 46.274), train_loss = 0.72288426, grad/param norm = 1.9109e-01, time/batch = 17.3863s	
24110/26050 (epoch 46.276), train_loss = 0.72478266, grad/param norm = 2.0967e-01, time/batch = 15.9910s	
24111/26050 (epoch 46.278), train_loss = 0.84103553, grad/param norm = 2.0413e-01, time/batch = 17.6301s	
24112/26050 (epoch 46.280), train_loss = 0.75463868, grad/param norm = 2.3804e-01, time/batch = 17.8173s	
24113/26050 (epoch 46.282), train_loss = 0.84947689, grad/param norm = 2.2562e-01, time/batch = 17.8946s	
24114/26050 (epoch 46.284), train_loss = 0.76383546, grad/param norm = 2.0836e-01, time/batch = 18.1444s	
24115/26050 (epoch 46.286), train_loss = 0.79523787, grad/param norm = 2.3493e-01, time/batch = 16.1523s	
24116/26050 (epoch 46.288), train_loss = 0.65905190, grad/param norm = 1.8886e-01, time/batch = 16.3768s	
24117/26050 (epoch 46.290), train_loss = 0.76354442, grad/param norm = 2.0491e-01, time/batch = 17.1437s	
24118/26050 (epoch 46.292), train_loss = 0.70968444, grad/param norm = 2.1711e-01, time/batch = 17.7107s	
24119/26050 (epoch 46.294), train_loss = 0.77108896, grad/param norm = 2.4919e-01, time/batch = 16.8143s	
24120/26050 (epoch 46.296), train_loss = 0.83796856, grad/param norm = 2.2135e-01, time/batch = 16.2161s	
24121/26050 (epoch 46.298), train_loss = 0.83349091, grad/param norm = 2.4675e-01, time/batch = 18.8212s	
24122/26050 (epoch 46.299), train_loss = 0.65780345, grad/param norm = 1.8928e-01, time/batch = 18.2490s	
24123/26050 (epoch 46.301), train_loss = 0.65936865, grad/param norm = 2.1134e-01, time/batch = 16.6125s	
24124/26050 (epoch 46.303), train_loss = 0.76050759, grad/param norm = 2.2593e-01, time/batch = 17.8035s	
24125/26050 (epoch 46.305), train_loss = 0.61959503, grad/param norm = 1.9037e-01, time/batch = 18.5526s	
24126/26050 (epoch 46.307), train_loss = 0.67234912, grad/param norm = 2.3450e-01, time/batch = 17.3973s	
24127/26050 (epoch 46.309), train_loss = 0.81481118, grad/param norm = 2.4441e-01, time/batch = 18.8992s	
24128/26050 (epoch 46.311), train_loss = 0.75949797, grad/param norm = 2.8859e-01, time/batch = 17.3022s	
24129/26050 (epoch 46.313), train_loss = 0.74528229, grad/param norm = 2.2703e-01, time/batch = 17.0374s	
24130/26050 (epoch 46.315), train_loss = 0.81964867, grad/param norm = 2.4630e-01, time/batch = 17.8935s	
24131/26050 (epoch 46.317), train_loss = 0.74683000, grad/param norm = 2.2975e-01, time/batch = 18.3145s	
24132/26050 (epoch 46.319), train_loss = 0.70853218, grad/param norm = 2.2343e-01, time/batch = 19.8193s	
24133/26050 (epoch 46.321), train_loss = 0.77710715, grad/param norm = 2.2464e-01, time/batch = 17.5415s	
24134/26050 (epoch 46.322), train_loss = 0.84718731, grad/param norm = 2.4673e-01, time/batch = 14.6382s	
24135/26050 (epoch 46.324), train_loss = 0.61977510, grad/param norm = 2.0738e-01, time/batch = 18.6558s	
24136/26050 (epoch 46.326), train_loss = 0.87136304, grad/param norm = 2.3870e-01, time/batch = 16.8211s	
24137/26050 (epoch 46.328), train_loss = 0.82177179, grad/param norm = 2.5905e-01, time/batch = 17.7332s	
24138/26050 (epoch 46.330), train_loss = 0.67498384, grad/param norm = 2.6280e-01, time/batch = 18.7342s	
24139/26050 (epoch 46.332), train_loss = 0.81294806, grad/param norm = 2.2103e-01, time/batch = 15.8874s	
24140/26050 (epoch 46.334), train_loss = 0.68396747, grad/param norm = 2.1554e-01, time/batch = 18.0477s	
24141/26050 (epoch 46.336), train_loss = 0.76237562, grad/param norm = 2.1178e-01, time/batch = 18.4722s	
24142/26050 (epoch 46.338), train_loss = 0.67432938, grad/param norm = 2.0517e-01, time/batch = 17.9868s	
24143/26050 (epoch 46.340), train_loss = 0.80758045, grad/param norm = 2.1936e-01, time/batch = 17.2309s	
24144/26050 (epoch 46.342), train_loss = 0.84936249, grad/param norm = 2.3354e-01, time/batch = 15.3868s	
24145/26050 (epoch 46.344), train_loss = 0.69339116, grad/param norm = 2.3157e-01, time/batch = 18.1425s	
24146/26050 (epoch 46.345), train_loss = 0.75021765, grad/param norm = 2.4510e-01, time/batch = 17.3157s	
24147/26050 (epoch 46.347), train_loss = 0.85947104, grad/param norm = 2.1026e-01, time/batch = 18.1457s	
24148/26050 (epoch 46.349), train_loss = 0.81452578, grad/param norm = 2.3431e-01, time/batch = 16.2362s	
24149/26050 (epoch 46.351), train_loss = 0.78645788, grad/param norm = 2.1858e-01, time/batch = 18.6393s	
24150/26050 (epoch 46.353), train_loss = 0.76259349, grad/param norm = 2.3008e-01, time/batch = 14.6125s	
24151/26050 (epoch 46.355), train_loss = 0.78122409, grad/param norm = 2.9836e-01, time/batch = 14.3698s	
24152/26050 (epoch 46.357), train_loss = 0.71898850, grad/param norm = 2.1601e-01, time/batch = 14.8805s	
24153/26050 (epoch 46.359), train_loss = 0.87365533, grad/param norm = 2.4910e-01, time/batch = 18.3094s	
24154/26050 (epoch 46.361), train_loss = 0.68540982, grad/param norm = 2.0156e-01, time/batch = 17.1472s	
24155/26050 (epoch 46.363), train_loss = 0.83770725, grad/param norm = 2.8433e-01, time/batch = 18.6429s	
24156/26050 (epoch 46.365), train_loss = 0.74280818, grad/param norm = 1.9674e-01, time/batch = 18.4028s	
24157/26050 (epoch 46.367), train_loss = 0.81421103, grad/param norm = 2.2970e-01, time/batch = 17.4031s	
24158/26050 (epoch 46.369), train_loss = 0.68051194, grad/param norm = 2.0984e-01, time/batch = 14.4793s	
24159/26050 (epoch 46.370), train_loss = 0.67448853, grad/param norm = 1.8940e-01, time/batch = 14.9720s	
24160/26050 (epoch 46.372), train_loss = 0.74422676, grad/param norm = 2.3073e-01, time/batch = 16.6518s	
24161/26050 (epoch 46.374), train_loss = 0.88025749, grad/param norm = 2.1409e-01, time/batch = 17.8005s	
24162/26050 (epoch 46.376), train_loss = 0.87848821, grad/param norm = 2.6717e-01, time/batch = 18.7299s	
24163/26050 (epoch 46.378), train_loss = 0.72586362, grad/param norm = 1.9498e-01, time/batch = 18.0607s	
24164/26050 (epoch 46.380), train_loss = 0.86935451, grad/param norm = 2.5526e-01, time/batch = 17.4066s	
24165/26050 (epoch 46.382), train_loss = 0.92265071, grad/param norm = 2.6134e-01, time/batch = 18.4731s	
24166/26050 (epoch 46.384), train_loss = 0.73128558, grad/param norm = 2.5998e-01, time/batch = 16.0420s	
24167/26050 (epoch 46.386), train_loss = 0.84529332, grad/param norm = 2.5908e-01, time/batch = 15.8947s	
24168/26050 (epoch 46.388), train_loss = 0.77001596, grad/param norm = 2.0676e-01, time/batch = 17.9805s	
24169/26050 (epoch 46.390), train_loss = 0.70979496, grad/param norm = 1.9229e-01, time/batch = 18.0735s	
24170/26050 (epoch 46.392), train_loss = 0.66445083, grad/param norm = 1.9689e-01, time/batch = 16.9779s	
24171/26050 (epoch 46.393), train_loss = 0.84251237, grad/param norm = 2.6024e-01, time/batch = 14.5360s	
24172/26050 (epoch 46.395), train_loss = 0.81986920, grad/param norm = 2.1162e-01, time/batch = 18.8960s	
24173/26050 (epoch 46.397), train_loss = 0.81190853, grad/param norm = 2.4904e-01, time/batch = 18.3114s	
24174/26050 (epoch 46.399), train_loss = 0.72817619, grad/param norm = 2.2966e-01, time/batch = 17.6458s	
24175/26050 (epoch 46.401), train_loss = 0.77855194, grad/param norm = 2.5516e-01, time/batch = 17.0411s	
24176/26050 (epoch 46.403), train_loss = 0.78767083, grad/param norm = 2.8303e-01, time/batch = 18.3225s	
24177/26050 (epoch 46.405), train_loss = 0.78265025, grad/param norm = 2.7144e-01, time/batch = 18.1586s	
24178/26050 (epoch 46.407), train_loss = 0.89997870, grad/param norm = 2.4917e-01, time/batch = 17.4058s	
24179/26050 (epoch 46.409), train_loss = 0.88309150, grad/param norm = 2.3918e-01, time/batch = 18.0678s	
24180/26050 (epoch 46.411), train_loss = 0.85754093, grad/param norm = 2.5747e-01, time/batch = 18.7279s	
24181/26050 (epoch 46.413), train_loss = 0.96767554, grad/param norm = 2.3817e-01, time/batch = 18.2111s	
24182/26050 (epoch 46.415), train_loss = 0.95079075, grad/param norm = 2.6597e-01, time/batch = 18.2326s	
24183/26050 (epoch 46.417), train_loss = 0.94922428, grad/param norm = 2.5703e-01, time/batch = 17.8915s	
24184/26050 (epoch 46.418), train_loss = 0.82695596, grad/param norm = 2.6621e-01, time/batch = 17.9622s	
24185/26050 (epoch 46.420), train_loss = 0.68234866, grad/param norm = 2.3006e-01, time/batch = 17.4928s	
24186/26050 (epoch 46.422), train_loss = 0.66367751, grad/param norm = 2.0867e-01, time/batch = 16.2159s	
24187/26050 (epoch 46.424), train_loss = 0.86499007, grad/param norm = 2.5208e-01, time/batch = 18.0657s	
24188/26050 (epoch 46.426), train_loss = 0.83564801, grad/param norm = 2.7326e-01, time/batch = 17.6250s	
24189/26050 (epoch 46.428), train_loss = 0.77148580, grad/param norm = 2.1635e-01, time/batch = 18.0566s	
24190/26050 (epoch 46.430), train_loss = 0.92087826, grad/param norm = 2.3409e-01, time/batch = 17.5730s	
24191/26050 (epoch 46.432), train_loss = 0.73929535, grad/param norm = 2.0896e-01, time/batch = 17.8143s	
24192/26050 (epoch 46.434), train_loss = 0.73892117, grad/param norm = 2.2779e-01, time/batch = 18.1288s	
24193/26050 (epoch 46.436), train_loss = 0.84617212, grad/param norm = 2.4074e-01, time/batch = 17.4670s	
24194/26050 (epoch 46.438), train_loss = 0.82524465, grad/param norm = 3.2638e-01, time/batch = 16.2896s	
24195/26050 (epoch 46.440), train_loss = 0.82711209, grad/param norm = 2.2747e-01, time/batch = 18.1518s	
24196/26050 (epoch 46.441), train_loss = 0.80572800, grad/param norm = 2.2552e-01, time/batch = 17.9853s	
24197/26050 (epoch 46.443), train_loss = 0.68722526, grad/param norm = 1.8740e-01, time/batch = 16.3866s	
24198/26050 (epoch 46.445), train_loss = 0.69698331, grad/param norm = 2.1617e-01, time/batch = 17.3195s	
24199/26050 (epoch 46.447), train_loss = 0.90533732, grad/param norm = 2.2900e-01, time/batch = 18.0750s	
24200/26050 (epoch 46.449), train_loss = 0.71234835, grad/param norm = 2.2215e-01, time/batch = 17.5734s	
24201/26050 (epoch 46.451), train_loss = 0.90592683, grad/param norm = 2.3056e-01, time/batch = 16.4655s	
24202/26050 (epoch 46.453), train_loss = 0.76455281, grad/param norm = 2.0954e-01, time/batch = 15.5571s	
24203/26050 (epoch 46.455), train_loss = 0.79033128, grad/param norm = 2.1648e-01, time/batch = 18.0527s	
24204/26050 (epoch 46.457), train_loss = 0.75877503, grad/param norm = 2.3358e-01, time/batch = 18.3252s	
24205/26050 (epoch 46.459), train_loss = 0.84820970, grad/param norm = 2.2708e-01, time/batch = 16.8115s	
24206/26050 (epoch 46.461), train_loss = 0.84868362, grad/param norm = 2.4152e-01, time/batch = 18.4859s	
24207/26050 (epoch 46.463), train_loss = 0.74495850, grad/param norm = 2.1950e-01, time/batch = 18.1359s	
24208/26050 (epoch 46.464), train_loss = 0.80646526, grad/param norm = 2.4611e-01, time/batch = 18.1317s	
24209/26050 (epoch 46.466), train_loss = 0.78239529, grad/param norm = 2.3747e-01, time/batch = 17.8084s	
24210/26050 (epoch 46.468), train_loss = 0.88105897, grad/param norm = 2.2085e-01, time/batch = 18.8175s	
24211/26050 (epoch 46.470), train_loss = 0.86518380, grad/param norm = 2.4738e-01, time/batch = 14.8558s	
24212/26050 (epoch 46.472), train_loss = 0.86854302, grad/param norm = 2.6245e-01, time/batch = 17.8925s	
24213/26050 (epoch 46.474), train_loss = 0.90579010, grad/param norm = 2.5569e-01, time/batch = 16.8797s	
24214/26050 (epoch 46.476), train_loss = 0.84921131, grad/param norm = 2.0661e-01, time/batch = 18.2430s	
24215/26050 (epoch 46.478), train_loss = 0.76438000, grad/param norm = 2.1742e-01, time/batch = 18.3113s	
24216/26050 (epoch 46.480), train_loss = 0.76175681, grad/param norm = 2.0604e-01, time/batch = 13.8568s	
24217/26050 (epoch 46.482), train_loss = 0.74790346, grad/param norm = 2.0910e-01, time/batch = 13.5773s	
24218/26050 (epoch 46.484), train_loss = 0.72771190, grad/param norm = 2.5338e-01, time/batch = 18.2989s	
24219/26050 (epoch 46.486), train_loss = 0.88148190, grad/param norm = 2.1748e-01, time/batch = 18.2187s	
24220/26050 (epoch 46.488), train_loss = 0.93027265, grad/param norm = 2.6018e-01, time/batch = 14.7127s	
24221/26050 (epoch 46.489), train_loss = 0.96237996, grad/param norm = 2.6125e-01, time/batch = 18.3845s	
24222/26050 (epoch 46.491), train_loss = 0.70705585, grad/param norm = 1.9693e-01, time/batch = 18.2382s	
24223/26050 (epoch 46.493), train_loss = 0.80379576, grad/param norm = 2.1800e-01, time/batch = 18.4798s	
24224/26050 (epoch 46.495), train_loss = 0.78432487, grad/param norm = 1.9222e-01, time/batch = 15.7197s	
24225/26050 (epoch 46.497), train_loss = 0.70740657, grad/param norm = 2.2353e-01, time/batch = 18.8146s	
24226/26050 (epoch 46.499), train_loss = 0.71237508, grad/param norm = 2.1657e-01, time/batch = 18.6388s	
24227/26050 (epoch 46.501), train_loss = 0.88565538, grad/param norm = 2.0993e-01, time/batch = 17.1389s	
24228/26050 (epoch 46.503), train_loss = 0.74672505, grad/param norm = 2.0339e-01, time/batch = 16.2873s	
24229/26050 (epoch 46.505), train_loss = 0.87199841, grad/param norm = 2.0683e-01, time/batch = 17.6355s	
24230/26050 (epoch 46.507), train_loss = 0.87253438, grad/param norm = 2.6258e-01, time/batch = 16.4800s	
24231/26050 (epoch 46.509), train_loss = 0.90420306, grad/param norm = 2.5857e-01, time/batch = 18.0709s	
24232/26050 (epoch 46.511), train_loss = 0.79415148, grad/param norm = 2.4060e-01, time/batch = 18.0657s	
24233/26050 (epoch 46.512), train_loss = 0.68573668, grad/param norm = 2.5211e-01, time/batch = 15.0549s	
24234/26050 (epoch 46.514), train_loss = 0.83767566, grad/param norm = 2.3765e-01, time/batch = 16.6995s	
24235/26050 (epoch 46.516), train_loss = 0.91516048, grad/param norm = 2.6779e-01, time/batch = 15.0324s	
24236/26050 (epoch 46.518), train_loss = 0.77359008, grad/param norm = 2.1623e-01, time/batch = 15.2787s	
24237/26050 (epoch 46.520), train_loss = 0.79095439, grad/param norm = 2.1317e-01, time/batch = 14.9831s	
24238/26050 (epoch 46.522), train_loss = 0.64547738, grad/param norm = 2.4323e-01, time/batch = 14.9896s	
24239/26050 (epoch 46.524), train_loss = 0.85911470, grad/param norm = 2.8975e-01, time/batch = 14.2193s	
24240/26050 (epoch 46.526), train_loss = 0.88754874, grad/param norm = 2.7369e-01, time/batch = 14.5476s	
24241/26050 (epoch 46.528), train_loss = 0.83352668, grad/param norm = 2.7591e-01, time/batch = 14.6149s	
24242/26050 (epoch 46.530), train_loss = 0.76390993, grad/param norm = 2.5948e-01, time/batch = 14.4792s	
24243/26050 (epoch 46.532), train_loss = 0.83642776, grad/param norm = 2.0983e-01, time/batch = 14.2413s	
24244/26050 (epoch 46.534), train_loss = 0.80447500, grad/param norm = 3.3051e-01, time/batch = 14.9928s	
24245/26050 (epoch 46.536), train_loss = 0.83017437, grad/param norm = 2.2565e-01, time/batch = 17.4886s	
24246/26050 (epoch 46.537), train_loss = 0.87424488, grad/param norm = 2.5644e-01, time/batch = 16.2256s	
24247/26050 (epoch 46.539), train_loss = 0.82367941, grad/param norm = 2.1829e-01, time/batch = 14.3145s	
24248/26050 (epoch 46.541), train_loss = 0.93055824, grad/param norm = 2.5790e-01, time/batch = 17.9585s	
24249/26050 (epoch 46.543), train_loss = 0.62227852, grad/param norm = 2.1470e-01, time/batch = 17.9835s	
24250/26050 (epoch 46.545), train_loss = 0.76455279, grad/param norm = 2.1906e-01, time/batch = 18.8914s	
24251/26050 (epoch 46.547), train_loss = 0.72820270, grad/param norm = 2.2333e-01, time/batch = 14.9762s	
24252/26050 (epoch 46.549), train_loss = 0.68914490, grad/param norm = 2.2948e-01, time/batch = 16.5527s	
24253/26050 (epoch 46.551), train_loss = 0.85305643, grad/param norm = 2.4988e-01, time/batch = 17.6656s	
24254/26050 (epoch 46.553), train_loss = 0.75285417, grad/param norm = 2.2393e-01, time/batch = 18.3268s	
24255/26050 (epoch 46.555), train_loss = 0.67291688, grad/param norm = 2.2294e-01, time/batch = 17.4801s	
24256/26050 (epoch 46.557), train_loss = 0.80689823, grad/param norm = 2.1771e-01, time/batch = 18.4975s	
24257/26050 (epoch 46.559), train_loss = 0.82003776, grad/param norm = 2.1528e-01, time/batch = 18.7374s	
24258/26050 (epoch 46.560), train_loss = 0.76371315, grad/param norm = 2.1818e-01, time/batch = 17.7241s	
24259/26050 (epoch 46.562), train_loss = 0.78163433, grad/param norm = 2.3382e-01, time/batch = 18.2158s	
24260/26050 (epoch 46.564), train_loss = 0.94555757, grad/param norm = 2.5308e-01, time/batch = 18.0689s	
24261/26050 (epoch 46.566), train_loss = 0.73705060, grad/param norm = 1.8506e-01, time/batch = 15.3163s	
24262/26050 (epoch 46.568), train_loss = 0.81813057, grad/param norm = 2.3444e-01, time/batch = 18.2152s	
24263/26050 (epoch 46.570), train_loss = 0.78985718, grad/param norm = 2.5347e-01, time/batch = 18.3201s	
24264/26050 (epoch 46.572), train_loss = 0.80683793, grad/param norm = 2.5629e-01, time/batch = 17.5617s	
24265/26050 (epoch 46.574), train_loss = 0.81059467, grad/param norm = 2.3922e-01, time/batch = 14.5513s	
24266/26050 (epoch 46.576), train_loss = 0.80113366, grad/param norm = 2.2649e-01, time/batch = 18.2277s	
24267/26050 (epoch 46.578), train_loss = 0.76805316, grad/param norm = 2.5738e-01, time/batch = 18.3968s	
24268/26050 (epoch 46.580), train_loss = 0.72111456, grad/param norm = 2.4493e-01, time/batch = 17.6501s	
24269/26050 (epoch 46.582), train_loss = 0.81212387, grad/param norm = 2.2465e-01, time/batch = 18.7306s	
24270/26050 (epoch 46.583), train_loss = 0.82153068, grad/param norm = 2.1096e-01, time/batch = 14.9578s	
24271/26050 (epoch 46.585), train_loss = 0.71516707, grad/param norm = 2.6538e-01, time/batch = 18.0607s	
24272/26050 (epoch 46.587), train_loss = 0.80206142, grad/param norm = 2.3535e-01, time/batch = 17.7303s	
24273/26050 (epoch 46.589), train_loss = 0.93238468, grad/param norm = 2.3928e-01, time/batch = 17.9689s	
24274/26050 (epoch 46.591), train_loss = 0.82513346, grad/param norm = 2.1586e-01, time/batch = 18.6226s	
24275/26050 (epoch 46.593), train_loss = 0.69836069, grad/param norm = 2.3839e-01, time/batch = 17.3868s	
24276/26050 (epoch 46.595), train_loss = 0.82857621, grad/param norm = 2.2859e-01, time/batch = 18.6551s	
24277/26050 (epoch 46.597), train_loss = 0.81268558, grad/param norm = 2.5840e-01, time/batch = 18.1639s	
24278/26050 (epoch 46.599), train_loss = 0.85491110, grad/param norm = 2.3718e-01, time/batch = 16.9826s	
24279/26050 (epoch 46.601), train_loss = 0.96008416, grad/param norm = 2.7449e-01, time/batch = 26.9620s	
24280/26050 (epoch 46.603), train_loss = 0.86051743, grad/param norm = 2.5748e-01, time/batch = 30.3777s	
24281/26050 (epoch 46.605), train_loss = 0.78304643, grad/param norm = 2.3235e-01, time/batch = 15.0965s	
24282/26050 (epoch 46.607), train_loss = 0.88207204, grad/param norm = 2.8540e-01, time/batch = 18.5688s	
24283/26050 (epoch 46.608), train_loss = 0.75232578, grad/param norm = 2.2810e-01, time/batch = 15.0190s	
24284/26050 (epoch 46.610), train_loss = 0.79572569, grad/param norm = 2.2441e-01, time/batch = 18.2271s	
24285/26050 (epoch 46.612), train_loss = 0.77002373, grad/param norm = 2.2139e-01, time/batch = 18.4022s	
24286/26050 (epoch 46.614), train_loss = 0.80498911, grad/param norm = 2.2216e-01, time/batch = 17.9937s	
24287/26050 (epoch 46.616), train_loss = 0.82537232, grad/param norm = 2.6444e-01, time/batch = 18.3254s	
24288/26050 (epoch 46.618), train_loss = 0.74379926, grad/param norm = 2.1647e-01, time/batch = 15.3763s	
24289/26050 (epoch 46.620), train_loss = 0.86790661, grad/param norm = 2.6183e-01, time/batch = 17.3091s	
24290/26050 (epoch 46.622), train_loss = 0.74209772, grad/param norm = 2.1894e-01, time/batch = 18.1422s	
24291/26050 (epoch 46.624), train_loss = 0.64928680, grad/param norm = 1.9737e-01, time/batch = 17.7167s	
24292/26050 (epoch 46.626), train_loss = 0.82651318, grad/param norm = 2.3594e-01, time/batch = 17.9755s	
24293/26050 (epoch 46.628), train_loss = 0.75075754, grad/param norm = 2.4049e-01, time/batch = 17.9803s	
24294/26050 (epoch 46.630), train_loss = 0.94087433, grad/param norm = 2.3412e-01, time/batch = 15.2130s	
24295/26050 (epoch 46.631), train_loss = 0.92215692, grad/param norm = 2.3826e-01, time/batch = 18.5515s	
24296/26050 (epoch 46.633), train_loss = 0.73243756, grad/param norm = 2.3516e-01, time/batch = 18.5671s	
24297/26050 (epoch 46.635), train_loss = 0.75834727, grad/param norm = 1.9715e-01, time/batch = 17.4967s	
24298/26050 (epoch 46.637), train_loss = 0.70258097, grad/param norm = 2.1541e-01, time/batch = 17.8161s	
24299/26050 (epoch 46.639), train_loss = 0.83479944, grad/param norm = 2.1926e-01, time/batch = 18.9799s	
24300/26050 (epoch 46.641), train_loss = 0.72520602, grad/param norm = 2.2852e-01, time/batch = 18.3880s	
24301/26050 (epoch 46.643), train_loss = 0.74101289, grad/param norm = 2.1268e-01, time/batch = 17.6450s	
24302/26050 (epoch 46.645), train_loss = 0.75946618, grad/param norm = 2.2957e-01, time/batch = 18.2420s	
24303/26050 (epoch 46.647), train_loss = 0.68472936, grad/param norm = 2.2907e-01, time/batch = 17.4814s	
24304/26050 (epoch 46.649), train_loss = 0.76179808, grad/param norm = 2.5556e-01, time/batch = 16.2871s	
24305/26050 (epoch 46.651), train_loss = 0.76992877, grad/param norm = 2.6414e-01, time/batch = 18.4763s	
24306/26050 (epoch 46.653), train_loss = 0.78271877, grad/param norm = 2.2912e-01, time/batch = 15.2273s	
24307/26050 (epoch 46.655), train_loss = 0.72564980, grad/param norm = 2.5897e-01, time/batch = 16.8770s	
24308/26050 (epoch 46.656), train_loss = 0.69588221, grad/param norm = 2.0121e-01, time/batch = 16.8979s	
24309/26050 (epoch 46.658), train_loss = 0.94289707, grad/param norm = 2.6324e-01, time/batch = 18.3154s	
24310/26050 (epoch 46.660), train_loss = 0.66083789, grad/param norm = 2.5441e-01, time/batch = 16.3049s	
24311/26050 (epoch 46.662), train_loss = 0.78171769, grad/param norm = 2.0765e-01, time/batch = 17.0406s	
24312/26050 (epoch 46.664), train_loss = 0.77837369, grad/param norm = 2.2292e-01, time/batch = 17.8928s	
24313/26050 (epoch 46.666), train_loss = 0.73486864, grad/param norm = 1.9700e-01, time/batch = 17.5809s	
24314/26050 (epoch 46.668), train_loss = 0.61334291, grad/param norm = 2.5456e-01, time/batch = 17.7426s	
24315/26050 (epoch 46.670), train_loss = 0.90228145, grad/param norm = 2.7428e-01, time/batch = 17.1539s	
24316/26050 (epoch 46.672), train_loss = 0.76591105, grad/param norm = 2.1335e-01, time/batch = 18.5720s	
24317/26050 (epoch 46.674), train_loss = 0.69122453, grad/param norm = 2.4002e-01, time/batch = 18.5695s	
24318/26050 (epoch 46.676), train_loss = 0.83956438, grad/param norm = 2.6616e-01, time/batch = 15.6329s	
24319/26050 (epoch 46.678), train_loss = 0.85978215, grad/param norm = 2.3985e-01, time/batch = 18.5526s	
24320/26050 (epoch 46.679), train_loss = 0.90339193, grad/param norm = 2.8122e-01, time/batch = 15.4105s	
24321/26050 (epoch 46.681), train_loss = 0.79793322, grad/param norm = 2.4824e-01, time/batch = 18.0632s	
24322/26050 (epoch 46.683), train_loss = 0.72156001, grad/param norm = 2.9509e-01, time/batch = 18.2183s	
24323/26050 (epoch 46.685), train_loss = 0.73226162, grad/param norm = 2.2652e-01, time/batch = 18.2380s	
24324/26050 (epoch 46.687), train_loss = 0.71640787, grad/param norm = 2.3973e-01, time/batch = 18.2246s	
24325/26050 (epoch 46.689), train_loss = 0.74249048, grad/param norm = 2.6431e-01, time/batch = 17.8965s	
24326/26050 (epoch 46.691), train_loss = 0.64771939, grad/param norm = 2.4415e-01, time/batch = 14.9693s	
24327/26050 (epoch 46.693), train_loss = 0.74636138, grad/param norm = 2.3828e-01, time/batch = 15.9762s	
24328/26050 (epoch 46.695), train_loss = 0.76767013, grad/param norm = 2.0529e-01, time/batch = 14.3677s	
24329/26050 (epoch 46.697), train_loss = 0.70121434, grad/param norm = 2.2382e-01, time/batch = 14.5357s	
24330/26050 (epoch 46.699), train_loss = 0.82425388, grad/param norm = 2.5190e-01, time/batch = 14.8826s	
24331/26050 (epoch 46.701), train_loss = 0.70221811, grad/param norm = 1.8101e-01, time/batch = 14.4574s	
24332/26050 (epoch 46.702), train_loss = 0.85464077, grad/param norm = 2.3853e-01, time/batch = 15.2921s	
24333/26050 (epoch 46.704), train_loss = 0.89706857, grad/param norm = 2.2680e-01, time/batch = 17.0717s	
24334/26050 (epoch 46.706), train_loss = 0.74099250, grad/param norm = 2.2301e-01, time/batch = 18.3136s	
24335/26050 (epoch 46.708), train_loss = 0.85338520, grad/param norm = 2.4920e-01, time/batch = 18.2389s	
24336/26050 (epoch 46.710), train_loss = 0.80917280, grad/param norm = 2.6446e-01, time/batch = 17.4082s	
24337/26050 (epoch 46.712), train_loss = 0.77603430, grad/param norm = 2.4414e-01, time/batch = 18.1571s	
24338/26050 (epoch 46.714), train_loss = 0.70827835, grad/param norm = 1.9556e-01, time/batch = 17.5707s	
24339/26050 (epoch 46.716), train_loss = 1.00096099, grad/param norm = 2.7369e-01, time/batch = 14.9672s	
24340/26050 (epoch 46.718), train_loss = 0.83911841, grad/param norm = 2.3051e-01, time/batch = 18.0477s	
24341/26050 (epoch 46.720), train_loss = 0.75038347, grad/param norm = 2.0154e-01, time/batch = 16.4487s	
24342/26050 (epoch 46.722), train_loss = 0.71090930, grad/param norm = 2.1449e-01, time/batch = 18.5712s	
24343/26050 (epoch 46.724), train_loss = 0.73624048, grad/param norm = 2.2037e-01, time/batch = 16.5726s	
24344/26050 (epoch 46.726), train_loss = 0.83858414, grad/param norm = 2.1405e-01, time/batch = 18.9004s	
24345/26050 (epoch 46.727), train_loss = 0.83370493, grad/param norm = 2.0783e-01, time/batch = 18.1562s	
24346/26050 (epoch 46.729), train_loss = 0.82810785, grad/param norm = 2.0821e-01, time/batch = 17.4821s	
24347/26050 (epoch 46.731), train_loss = 0.83857189, grad/param norm = 2.1761e-01, time/batch = 18.3912s	
24348/26050 (epoch 46.733), train_loss = 0.74528710, grad/param norm = 2.4248e-01, time/batch = 18.3953s	
24349/26050 (epoch 46.735), train_loss = 0.89153936, grad/param norm = 2.3064e-01, time/batch = 17.3863s	
24350/26050 (epoch 46.737), train_loss = 0.75306541, grad/param norm = 2.6104e-01, time/batch = 17.2108s	
24351/26050 (epoch 46.739), train_loss = 0.81480001, grad/param norm = 2.2107e-01, time/batch = 17.4722s	
24352/26050 (epoch 46.741), train_loss = 0.70610884, grad/param norm = 2.2349e-01, time/batch = 16.7532s	
24353/26050 (epoch 46.743), train_loss = 0.77969473, grad/param norm = 2.5818e-01, time/batch = 17.7278s	
24354/26050 (epoch 46.745), train_loss = 0.69421216, grad/param norm = 2.1074e-01, time/batch = 18.4226s	
24355/26050 (epoch 46.747), train_loss = 0.74002739, grad/param norm = 2.0356e-01, time/batch = 17.9962s	
24356/26050 (epoch 46.749), train_loss = 0.88068174, grad/param norm = 2.2747e-01, time/batch = 16.7946s	
24357/26050 (epoch 46.750), train_loss = 0.72831644, grad/param norm = 1.9209e-01, time/batch = 17.4806s	
24358/26050 (epoch 46.752), train_loss = 0.72111330, grad/param norm = 2.2352e-01, time/batch = 18.1530s	
24359/26050 (epoch 46.754), train_loss = 0.78133294, grad/param norm = 2.3452e-01, time/batch = 18.1601s	
24360/26050 (epoch 46.756), train_loss = 0.74768293, grad/param norm = 2.8783e-01, time/batch = 17.6390s	
24361/26050 (epoch 46.758), train_loss = 0.79334038, grad/param norm = 2.4801e-01, time/batch = 17.8989s	
24362/26050 (epoch 46.760), train_loss = 0.89397127, grad/param norm = 2.2321e-01, time/batch = 18.5527s	
24363/26050 (epoch 46.762), train_loss = 0.75817581, grad/param norm = 2.2911e-01, time/batch = 17.8859s	
24364/26050 (epoch 46.764), train_loss = 0.77290982, grad/param norm = 2.6094e-01, time/batch = 15.6379s	
24365/26050 (epoch 46.766), train_loss = 0.76373840, grad/param norm = 2.9187e-01, time/batch = 17.5415s	
24366/26050 (epoch 46.768), train_loss = 0.68500824, grad/param norm = 2.2237e-01, time/batch = 18.1546s	
24367/26050 (epoch 46.770), train_loss = 0.77429646, grad/param norm = 2.4781e-01, time/batch = 15.3053s	
24368/26050 (epoch 46.772), train_loss = 0.78722193, grad/param norm = 2.5746e-01, time/batch = 16.8884s	
24369/26050 (epoch 46.774), train_loss = 0.64185226, grad/param norm = 2.0813e-01, time/batch = 17.4913s	
24370/26050 (epoch 46.775), train_loss = 0.55242834, grad/param norm = 2.2701e-01, time/batch = 18.0630s	
24371/26050 (epoch 46.777), train_loss = 0.73475849, grad/param norm = 2.1508e-01, time/batch = 17.4651s	
24372/26050 (epoch 46.779), train_loss = 0.76736023, grad/param norm = 3.2221e-01, time/batch = 16.9106s	
24373/26050 (epoch 46.781), train_loss = 0.68393686, grad/param norm = 2.0525e-01, time/batch = 17.8163s	
24374/26050 (epoch 46.783), train_loss = 0.67499282, grad/param norm = 2.5407e-01, time/batch = 17.5550s	
24375/26050 (epoch 46.785), train_loss = 0.79234133, grad/param norm = 2.8250e-01, time/batch = 18.4004s	
24376/26050 (epoch 46.787), train_loss = 0.70858688, grad/param norm = 2.5094e-01, time/batch = 17.5639s	
24377/26050 (epoch 46.789), train_loss = 0.71565378, grad/param norm = 2.5699e-01, time/batch = 16.4649s	
24378/26050 (epoch 46.791), train_loss = 0.71124503, grad/param norm = 3.9547e-01, time/batch = 17.7294s	
24379/26050 (epoch 46.793), train_loss = 0.78116336, grad/param norm = 2.3999e-01, time/batch = 14.3945s	
24380/26050 (epoch 46.795), train_loss = 0.63014813, grad/param norm = 2.2000e-01, time/batch = 16.0535s	
24381/26050 (epoch 46.797), train_loss = 0.69541546, grad/param norm = 2.3118e-01, time/batch = 16.9764s	
24382/26050 (epoch 46.798), train_loss = 0.79725464, grad/param norm = 2.7044e-01, time/batch = 18.3210s	
24383/26050 (epoch 46.800), train_loss = 0.65751602, grad/param norm = 2.2853e-01, time/batch = 18.2434s	
24384/26050 (epoch 46.802), train_loss = 0.73585369, grad/param norm = 2.1106e-01, time/batch = 15.8141s	
24385/26050 (epoch 46.804), train_loss = 0.77412645, grad/param norm = 2.5397e-01, time/batch = 18.2288s	
24386/26050 (epoch 46.806), train_loss = 0.82389363, grad/param norm = 2.3536e-01, time/batch = 17.2306s	
24387/26050 (epoch 46.808), train_loss = 0.79615377, grad/param norm = 2.4735e-01, time/batch = 18.4783s	
24388/26050 (epoch 46.810), train_loss = 0.77843872, grad/param norm = 2.2310e-01, time/batch = 16.5360s	
24389/26050 (epoch 46.812), train_loss = 0.65068572, grad/param norm = 2.5032e-01, time/batch = 18.0657s	
24390/26050 (epoch 46.814), train_loss = 0.68266600, grad/param norm = 2.3874e-01, time/batch = 18.7220s	
24391/26050 (epoch 46.816), train_loss = 0.81005577, grad/param norm = 2.5112e-01, time/batch = 17.6519s	
24392/26050 (epoch 46.818), train_loss = 0.83770000, grad/param norm = 2.4938e-01, time/batch = 17.0724s	
24393/26050 (epoch 46.820), train_loss = 0.79591413, grad/param norm = 2.4458e-01, time/batch = 18.6667s	
24394/26050 (epoch 46.821), train_loss = 0.85690537, grad/param norm = 2.3291e-01, time/batch = 17.6526s	
24395/26050 (epoch 46.823), train_loss = 0.94772943, grad/param norm = 2.4563e-01, time/batch = 14.3853s	
24396/26050 (epoch 46.825), train_loss = 0.75647602, grad/param norm = 2.2686e-01, time/batch = 18.0742s	
24397/26050 (epoch 46.827), train_loss = 0.78972540, grad/param norm = 2.7603e-01, time/batch = 16.5580s	
24398/26050 (epoch 46.829), train_loss = 0.90160473, grad/param norm = 2.8257e-01, time/batch = 16.1266s	
24399/26050 (epoch 46.831), train_loss = 0.92885173, grad/param norm = 2.2512e-01, time/batch = 16.6320s	
24400/26050 (epoch 46.833), train_loss = 0.86858919, grad/param norm = 2.6785e-01, time/batch = 17.9098s	
24401/26050 (epoch 46.835), train_loss = 0.89863085, grad/param norm = 2.5496e-01, time/batch = 17.4841s	
24402/26050 (epoch 46.837), train_loss = 0.80011769, grad/param norm = 2.4657e-01, time/batch = 18.2295s	
24403/26050 (epoch 46.839), train_loss = 0.76201954, grad/param norm = 2.4428e-01, time/batch = 18.1550s	
24404/26050 (epoch 46.841), train_loss = 0.82411903, grad/param norm = 2.6376e-01, time/batch = 19.1375s	
24405/26050 (epoch 46.843), train_loss = 0.75855574, grad/param norm = 2.2158e-01, time/batch = 18.0621s	
24406/26050 (epoch 46.845), train_loss = 0.74738671, grad/param norm = 2.4084e-01, time/batch = 17.8271s	
24407/26050 (epoch 46.846), train_loss = 0.80216069, grad/param norm = 2.3547e-01, time/batch = 15.3175s	
24408/26050 (epoch 46.848), train_loss = 0.75536113, grad/param norm = 2.2900e-01, time/batch = 17.2374s	
24409/26050 (epoch 46.850), train_loss = 0.67960814, grad/param norm = 1.8999e-01, time/batch = 18.6376s	
24410/26050 (epoch 46.852), train_loss = 0.80607714, grad/param norm = 2.2814e-01, time/batch = 18.3211s	
24411/26050 (epoch 46.854), train_loss = 0.77437078, grad/param norm = 2.2056e-01, time/batch = 17.6520s	
24412/26050 (epoch 46.856), train_loss = 0.73600581, grad/param norm = 2.4870e-01, time/batch = 18.1422s	
24413/26050 (epoch 46.858), train_loss = 0.70039062, grad/param norm = 2.1048e-01, time/batch = 18.2367s	
24414/26050 (epoch 46.860), train_loss = 0.79260494, grad/param norm = 2.5260e-01, time/batch = 16.7284s	
24415/26050 (epoch 46.862), train_loss = 0.84714795, grad/param norm = 2.1416e-01, time/batch = 15.3710s	
24416/26050 (epoch 46.864), train_loss = 0.75736988, grad/param norm = 2.5260e-01, time/batch = 17.7127s	
24417/26050 (epoch 46.866), train_loss = 0.78491766, grad/param norm = 2.2595e-01, time/batch = 18.7334s	
24418/26050 (epoch 46.868), train_loss = 0.83103336, grad/param norm = 2.4109e-01, time/batch = 14.2993s	
24419/26050 (epoch 46.869), train_loss = 0.71331132, grad/param norm = 2.1206e-01, time/batch = 18.3987s	
24420/26050 (epoch 46.871), train_loss = 0.65400318, grad/param norm = 2.2862e-01, time/batch = 18.4889s	
24421/26050 (epoch 46.873), train_loss = 0.83035018, grad/param norm = 2.3794e-01, time/batch = 18.9144s	
24422/26050 (epoch 46.875), train_loss = 0.73711413, grad/param norm = 2.3832e-01, time/batch = 18.0426s	
24423/26050 (epoch 46.877), train_loss = 0.74838489, grad/param norm = 1.9691e-01, time/batch = 18.4849s	
24424/26050 (epoch 46.879), train_loss = 0.83892850, grad/param norm = 2.2944e-01, time/batch = 18.2253s	
24425/26050 (epoch 46.881), train_loss = 0.84440040, grad/param norm = 2.6986e-01, time/batch = 17.0598s	
24426/26050 (epoch 46.883), train_loss = 0.85307191, grad/param norm = 2.1886e-01, time/batch = 17.5506s	
24427/26050 (epoch 46.885), train_loss = 0.61543454, grad/param norm = 2.0828e-01, time/batch = 17.1555s	
24428/26050 (epoch 46.887), train_loss = 0.86904749, grad/param norm = 2.2822e-01, time/batch = 17.2221s	
24429/26050 (epoch 46.889), train_loss = 0.72644494, grad/param norm = 2.0615e-01, time/batch = 17.6614s	
24430/26050 (epoch 46.891), train_loss = 0.65599796, grad/param norm = 2.0476e-01, time/batch = 18.1563s	
24431/26050 (epoch 46.893), train_loss = 0.65230593, grad/param norm = 2.0699e-01, time/batch = 18.3219s	
24432/26050 (epoch 46.894), train_loss = 0.72762098, grad/param norm = 2.3858e-01, time/batch = 16.8685s	
24433/26050 (epoch 46.896), train_loss = 0.83320112, grad/param norm = 2.3616e-01, time/batch = 17.2247s	
24434/26050 (epoch 46.898), train_loss = 0.70862037, grad/param norm = 2.0624e-01, time/batch = 16.3051s	
24435/26050 (epoch 46.900), train_loss = 0.82508430, grad/param norm = 2.3984e-01, time/batch = 17.2016s	
24436/26050 (epoch 46.902), train_loss = 0.73188540, grad/param norm = 2.0236e-01, time/batch = 16.2351s	
24437/26050 (epoch 46.904), train_loss = 0.75352523, grad/param norm = 2.2424e-01, time/batch = 18.3270s	
24438/26050 (epoch 46.906), train_loss = 0.72424224, grad/param norm = 2.3692e-01, time/batch = 18.9202s	
24439/26050 (epoch 46.908), train_loss = 0.80534465, grad/param norm = 2.2432e-01, time/batch = 18.2309s	
24440/26050 (epoch 46.910), train_loss = 0.71711137, grad/param norm = 2.3810e-01, time/batch = 17.9845s	
24441/26050 (epoch 46.912), train_loss = 0.94047622, grad/param norm = 2.7991e-01, time/batch = 18.5824s	
24442/26050 (epoch 46.914), train_loss = 1.05638248, grad/param norm = 2.6191e-01, time/batch = 17.5781s	
24443/26050 (epoch 46.916), train_loss = 0.83312040, grad/param norm = 2.8685e-01, time/batch = 16.7344s	
24444/26050 (epoch 46.917), train_loss = 0.79959400, grad/param norm = 2.3236e-01, time/batch = 17.9796s	
24445/26050 (epoch 46.919), train_loss = 0.80554503, grad/param norm = 2.5951e-01, time/batch = 17.0529s	
24446/26050 (epoch 46.921), train_loss = 0.71766588, grad/param norm = 2.2946e-01, time/batch = 18.4043s	
24447/26050 (epoch 46.923), train_loss = 0.80604488, grad/param norm = 2.3483e-01, time/batch = 17.4841s	
24448/26050 (epoch 46.925), train_loss = 0.78770847, grad/param norm = 2.2637e-01, time/batch = 18.4725s	
24449/26050 (epoch 46.927), train_loss = 0.71088512, grad/param norm = 1.6458e-01, time/batch = 18.1337s	
24450/26050 (epoch 46.929), train_loss = 0.65863698, grad/param norm = 2.1842e-01, time/batch = 18.6487s	
24451/26050 (epoch 46.931), train_loss = 0.92122730, grad/param norm = 2.8773e-01, time/batch = 17.4089s	
24452/26050 (epoch 46.933), train_loss = 0.78013130, grad/param norm = 2.2826e-01, time/batch = 17.0765s	
24453/26050 (epoch 46.935), train_loss = 0.73664755, grad/param norm = 2.0098e-01, time/batch = 16.0491s	
24454/26050 (epoch 46.937), train_loss = 0.84579577, grad/param norm = 2.1909e-01, time/batch = 18.3180s	
24455/26050 (epoch 46.939), train_loss = 0.71768379, grad/param norm = 2.1390e-01, time/batch = 18.0727s	
24456/26050 (epoch 46.940), train_loss = 0.78811216, grad/param norm = 2.3423e-01, time/batch = 16.9919s	
24457/26050 (epoch 46.942), train_loss = 0.69993379, grad/param norm = 2.1197e-01, time/batch = 18.1240s	
24458/26050 (epoch 46.944), train_loss = 0.74794951, grad/param norm = 1.9844e-01, time/batch = 14.8000s	
24459/26050 (epoch 46.946), train_loss = 0.91133616, grad/param norm = 2.1105e-01, time/batch = 17.5287s	
24460/26050 (epoch 46.948), train_loss = 0.67315066, grad/param norm = 2.3710e-01, time/batch = 17.9036s	
24461/26050 (epoch 46.950), train_loss = 0.79013202, grad/param norm = 2.0342e-01, time/batch = 18.4826s	
24462/26050 (epoch 46.952), train_loss = 0.80944291, grad/param norm = 2.2966e-01, time/batch = 17.4818s	
24463/26050 (epoch 46.954), train_loss = 0.83939968, grad/param norm = 2.7666e-01, time/batch = 17.9170s	
24464/26050 (epoch 46.956), train_loss = 0.71628183, grad/param norm = 2.0949e-01, time/batch = 18.3078s	
24465/26050 (epoch 46.958), train_loss = 0.70879052, grad/param norm = 2.2201e-01, time/batch = 18.3127s	
24466/26050 (epoch 46.960), train_loss = 0.80153850, grad/param norm = 2.1729e-01, time/batch = 17.9863s	
24467/26050 (epoch 46.962), train_loss = 0.75778946, grad/param norm = 1.8674e-01, time/batch = 18.0699s	
24468/26050 (epoch 46.964), train_loss = 0.72560173, grad/param norm = 2.1967e-01, time/batch = 17.3303s	
24469/26050 (epoch 46.965), train_loss = 0.70096161, grad/param norm = 2.9377e-01, time/batch = 15.8862s	
24470/26050 (epoch 46.967), train_loss = 1.01262768, grad/param norm = 2.4217e-01, time/batch = 18.3213s	
24471/26050 (epoch 46.969), train_loss = 0.77212978, grad/param norm = 2.0733e-01, time/batch = 18.7400s	
24472/26050 (epoch 46.971), train_loss = 0.79264078, grad/param norm = 2.4868e-01, time/batch = 15.2183s	
24473/26050 (epoch 46.973), train_loss = 0.79332635, grad/param norm = 2.7374e-01, time/batch = 17.4073s	
24474/26050 (epoch 46.975), train_loss = 0.78553694, grad/param norm = 2.1698e-01, time/batch = 15.9543s	
24475/26050 (epoch 46.977), train_loss = 0.74936916, grad/param norm = 1.9101e-01, time/batch = 15.4816s	
24476/26050 (epoch 46.979), train_loss = 0.62395556, grad/param norm = 1.8572e-01, time/batch = 18.0390s	
24477/26050 (epoch 46.981), train_loss = 0.84159242, grad/param norm = 2.0890e-01, time/batch = 16.8813s	
24478/26050 (epoch 46.983), train_loss = 0.80233514, grad/param norm = 2.0815e-01, time/batch = 18.0680s	
24479/26050 (epoch 46.985), train_loss = 0.79995274, grad/param norm = 2.9522e-01, time/batch = 18.1361s	
24480/26050 (epoch 46.987), train_loss = 0.86640181, grad/param norm = 2.2898e-01, time/batch = 17.6515s	
24481/26050 (epoch 46.988), train_loss = 0.80373356, grad/param norm = 2.2877e-01, time/batch = 18.2462s	
24482/26050 (epoch 46.990), train_loss = 0.66095385, grad/param norm = 1.8956e-01, time/batch = 17.9791s	
24483/26050 (epoch 46.992), train_loss = 0.88398314, grad/param norm = 2.3174e-01, time/batch = 21.3222s	
24484/26050 (epoch 46.994), train_loss = 0.72251183, grad/param norm = 2.4431e-01, time/batch = 32.3846s	
24485/26050 (epoch 46.996), train_loss = 0.67218163, grad/param norm = 2.2197e-01, time/batch = 16.5910s	
24486/26050 (epoch 46.998), train_loss = 0.78787780, grad/param norm = 2.4968e-01, time/batch = 17.9566s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
24487/26050 (epoch 47.000), train_loss = 0.70145541, grad/param norm = 2.2810e-01, time/batch = 18.7265s	
24488/26050 (epoch 47.002), train_loss = 0.83840991, grad/param norm = 2.3458e-01, time/batch = 17.7393s	
24489/26050 (epoch 47.004), train_loss = 0.68712836, grad/param norm = 2.5641e-01, time/batch = 17.7454s	
24490/26050 (epoch 47.006), train_loss = 0.72264061, grad/param norm = 2.5357e-01, time/batch = 15.2297s	
24491/26050 (epoch 47.008), train_loss = 0.72004597, grad/param norm = 2.2340e-01, time/batch = 18.7414s	
24492/26050 (epoch 47.010), train_loss = 0.69626833, grad/param norm = 2.0252e-01, time/batch = 17.0533s	
24493/26050 (epoch 47.012), train_loss = 0.75804253, grad/param norm = 2.3168e-01, time/batch = 14.6316s	
24494/26050 (epoch 47.013), train_loss = 0.98371473, grad/param norm = 2.3632e-01, time/batch = 17.7326s	
24495/26050 (epoch 47.015), train_loss = 0.77470874, grad/param norm = 2.5514e-01, time/batch = 17.8904s	
24496/26050 (epoch 47.017), train_loss = 0.80595200, grad/param norm = 2.1703e-01, time/batch = 18.4775s	
24497/26050 (epoch 47.019), train_loss = 0.68217687, grad/param norm = 2.0209e-01, time/batch = 18.2298s	
24498/26050 (epoch 47.021), train_loss = 0.82616017, grad/param norm = 2.2739e-01, time/batch = 18.6565s	
24499/26050 (epoch 47.023), train_loss = 0.65138333, grad/param norm = 2.4943e-01, time/batch = 17.6310s	
24500/26050 (epoch 47.025), train_loss = 0.77029307, grad/param norm = 2.2090e-01, time/batch = 17.7321s	
24501/26050 (epoch 47.027), train_loss = 0.60230334, grad/param norm = 2.0719e-01, time/batch = 18.4054s	
24502/26050 (epoch 47.029), train_loss = 0.82430782, grad/param norm = 2.1578e-01, time/batch = 16.2084s	
24503/26050 (epoch 47.031), train_loss = 0.87145760, grad/param norm = 2.9403e-01, time/batch = 18.1441s	
24504/26050 (epoch 47.033), train_loss = 0.76860226, grad/param norm = 2.2381e-01, time/batch = 18.1535s	
24505/26050 (epoch 47.035), train_loss = 0.80271548, grad/param norm = 2.1455e-01, time/batch = 16.2339s	
24506/26050 (epoch 47.036), train_loss = 0.68291089, grad/param norm = 2.5584e-01, time/batch = 14.2845s	
24507/26050 (epoch 47.038), train_loss = 0.61990943, grad/param norm = 1.8919e-01, time/batch = 14.1956s	
24508/26050 (epoch 47.040), train_loss = 0.75627699, grad/param norm = 2.1748e-01, time/batch = 17.1101s	
24509/26050 (epoch 47.042), train_loss = 0.67570512, grad/param norm = 2.4519e-01, time/batch = 17.7480s	
24510/26050 (epoch 47.044), train_loss = 0.82987151, grad/param norm = 2.1926e-01, time/batch = 18.2100s	
24511/26050 (epoch 47.046), train_loss = 0.66045538, grad/param norm = 1.8835e-01, time/batch = 18.7340s	
24512/26050 (epoch 47.048), train_loss = 0.77569916, grad/param norm = 2.1959e-01, time/batch = 18.2350s	
24513/26050 (epoch 47.050), train_loss = 0.74377969, grad/param norm = 2.2167e-01, time/batch = 15.2917s	
24514/26050 (epoch 47.052), train_loss = 0.71185377, grad/param norm = 2.4869e-01, time/batch = 17.1613s	
24515/26050 (epoch 47.054), train_loss = 0.65430690, grad/param norm = 2.0446e-01, time/batch = 18.3930s	
24516/26050 (epoch 47.056), train_loss = 0.64448122, grad/param norm = 1.7869e-01, time/batch = 15.5258s	
24517/26050 (epoch 47.058), train_loss = 0.75287780, grad/param norm = 2.3277e-01, time/batch = 18.8190s	
24518/26050 (epoch 47.060), train_loss = 0.82650447, grad/param norm = 2.3627e-01, time/batch = 17.9929s	
24519/26050 (epoch 47.061), train_loss = 0.65757504, grad/param norm = 2.0060e-01, time/batch = 17.4909s	
24520/26050 (epoch 47.063), train_loss = 0.74904736, grad/param norm = 2.1378e-01, time/batch = 16.4738s	
24521/26050 (epoch 47.065), train_loss = 0.63259416, grad/param norm = 1.7470e-01, time/batch = 16.6129s	
24522/26050 (epoch 47.067), train_loss = 0.77015661, grad/param norm = 2.1454e-01, time/batch = 17.8070s	
24523/26050 (epoch 47.069), train_loss = 0.79080044, grad/param norm = 2.3189e-01, time/batch = 16.6549s	
24524/26050 (epoch 47.071), train_loss = 0.78399914, grad/param norm = 2.6045e-01, time/batch = 18.7319s	
24525/26050 (epoch 47.073), train_loss = 0.91601717, grad/param norm = 2.1941e-01, time/batch = 17.2391s	
24526/26050 (epoch 47.075), train_loss = 0.71943196, grad/param norm = 2.5028e-01, time/batch = 15.6970s	
24527/26050 (epoch 47.077), train_loss = 0.74352930, grad/param norm = 2.1599e-01, time/batch = 16.0462s	
24528/26050 (epoch 47.079), train_loss = 0.74632451, grad/param norm = 2.3420e-01, time/batch = 18.2231s	
24529/26050 (epoch 47.081), train_loss = 0.73704919, grad/param norm = 2.2573e-01, time/batch = 17.9815s	
24530/26050 (epoch 47.083), train_loss = 0.86072995, grad/param norm = 2.1676e-01, time/batch = 17.7309s	
24531/26050 (epoch 47.084), train_loss = 0.78808388, grad/param norm = 2.4551e-01, time/batch = 18.3139s	
24532/26050 (epoch 47.086), train_loss = 0.89606287, grad/param norm = 3.0220e-01, time/batch = 18.5738s	
24533/26050 (epoch 47.088), train_loss = 0.77048192, grad/param norm = 2.2139e-01, time/batch = 17.7344s	
24534/26050 (epoch 47.090), train_loss = 0.79985948, grad/param norm = 2.3972e-01, time/batch = 18.1578s	
24535/26050 (epoch 47.092), train_loss = 0.81558308, grad/param norm = 2.1153e-01, time/batch = 17.1572s	
24536/26050 (epoch 47.094), train_loss = 0.64672768, grad/param norm = 2.2612e-01, time/batch = 16.4669s	
24537/26050 (epoch 47.096), train_loss = 0.79961851, grad/param norm = 2.2693e-01, time/batch = 17.6394s	
24538/26050 (epoch 47.098), train_loss = 0.77495882, grad/param norm = 2.3272e-01, time/batch = 14.5617s	
24539/26050 (epoch 47.100), train_loss = 0.67826334, grad/param norm = 2.2785e-01, time/batch = 18.4106s	
24540/26050 (epoch 47.102), train_loss = 0.76819655, grad/param norm = 2.2375e-01, time/batch = 15.4374s	
24541/26050 (epoch 47.104), train_loss = 0.73307430, grad/param norm = 2.2196e-01, time/batch = 18.2339s	
24542/26050 (epoch 47.106), train_loss = 0.80047742, grad/param norm = 2.4647e-01, time/batch = 18.3091s	
24543/26050 (epoch 47.107), train_loss = 0.65219186, grad/param norm = 2.0078e-01, time/batch = 18.3127s	
24544/26050 (epoch 47.109), train_loss = 0.71314894, grad/param norm = 2.0160e-01, time/batch = 18.3321s	
24545/26050 (epoch 47.111), train_loss = 0.90996007, grad/param norm = 2.8224e-01, time/batch = 17.5695s	
24546/26050 (epoch 47.113), train_loss = 0.75399260, grad/param norm = 2.1348e-01, time/batch = 18.3200s	
24547/26050 (epoch 47.115), train_loss = 0.82441098, grad/param norm = 2.2430e-01, time/batch = 17.5647s	
24548/26050 (epoch 47.117), train_loss = 0.77892692, grad/param norm = 2.2645e-01, time/batch = 18.1696s	
24549/26050 (epoch 47.119), train_loss = 0.66635832, grad/param norm = 1.8637e-01, time/batch = 17.5783s	
24550/26050 (epoch 47.121), train_loss = 0.76453328, grad/param norm = 2.1442e-01, time/batch = 14.7991s	
24551/26050 (epoch 47.123), train_loss = 0.70386514, grad/param norm = 2.0892e-01, time/batch = 18.7317s	
24552/26050 (epoch 47.125), train_loss = 0.64541587, grad/param norm = 2.0107e-01, time/batch = 16.4555s	
24553/26050 (epoch 47.127), train_loss = 0.64157868, grad/param norm = 1.9841e-01, time/batch = 17.6509s	
24554/26050 (epoch 47.129), train_loss = 0.59607261, grad/param norm = 2.1219e-01, time/batch = 17.8205s	
24555/26050 (epoch 47.131), train_loss = 0.75876287, grad/param norm = 2.2794e-01, time/batch = 18.3954s	
24556/26050 (epoch 47.132), train_loss = 0.77942375, grad/param norm = 2.3098e-01, time/batch = 14.5743s	
24557/26050 (epoch 47.134), train_loss = 0.79357045, grad/param norm = 2.7210e-01, time/batch = 16.7307s	
24558/26050 (epoch 47.136), train_loss = 0.72402625, grad/param norm = 2.0298e-01, time/batch = 16.7998s	
24559/26050 (epoch 47.138), train_loss = 0.53848290, grad/param norm = 2.0523e-01, time/batch = 17.9014s	
24560/26050 (epoch 47.140), train_loss = 0.61875706, grad/param norm = 1.9435e-01, time/batch = 18.3937s	
24561/26050 (epoch 47.142), train_loss = 0.64390255, grad/param norm = 2.0437e-01, time/batch = 18.9715s	
24562/26050 (epoch 47.144), train_loss = 0.62033888, grad/param norm = 2.2619e-01, time/batch = 15.5568s	
24563/26050 (epoch 47.146), train_loss = 0.55594078, grad/param norm = 1.8153e-01, time/batch = 17.9821s	
24564/26050 (epoch 47.148), train_loss = 0.60391110, grad/param norm = 1.7740e-01, time/batch = 17.5677s	
24565/26050 (epoch 47.150), train_loss = 0.67746938, grad/param norm = 2.6186e-01, time/batch = 18.0733s	
24566/26050 (epoch 47.152), train_loss = 0.83757342, grad/param norm = 3.2283e-01, time/batch = 14.4580s	
24567/26050 (epoch 47.154), train_loss = 0.59408405, grad/param norm = 1.9540e-01, time/batch = 17.9124s	
24568/26050 (epoch 47.155), train_loss = 0.64273979, grad/param norm = 2.0424e-01, time/batch = 17.3997s	
24569/26050 (epoch 47.157), train_loss = 0.70977799, grad/param norm = 2.2861e-01, time/batch = 15.7214s	
24570/26050 (epoch 47.159), train_loss = 0.76355582, grad/param norm = 2.5157e-01, time/batch = 18.6379s	
24571/26050 (epoch 47.161), train_loss = 0.74405999, grad/param norm = 2.5891e-01, time/batch = 17.2345s	
24572/26050 (epoch 47.163), train_loss = 0.63278165, grad/param norm = 2.2704e-01, time/batch = 16.0528s	
24573/26050 (epoch 47.165), train_loss = 0.58056944, grad/param norm = 2.0314e-01, time/batch = 17.9789s	
24574/26050 (epoch 47.167), train_loss = 0.87098998, grad/param norm = 2.6052e-01, time/batch = 18.1634s	
24575/26050 (epoch 47.169), train_loss = 0.74689915, grad/param norm = 2.2005e-01, time/batch = 17.7278s	
24576/26050 (epoch 47.171), train_loss = 0.68235899, grad/param norm = 2.0683e-01, time/batch = 18.3200s	
24577/26050 (epoch 47.173), train_loss = 0.72452674, grad/param norm = 2.3164e-01, time/batch = 18.5593s	
24578/26050 (epoch 47.175), train_loss = 0.72845682, grad/param norm = 1.9347e-01, time/batch = 16.4786s	
24579/26050 (epoch 47.177), train_loss = 0.79023597, grad/param norm = 2.1151e-01, time/batch = 16.0264s	
24580/26050 (epoch 47.179), train_loss = 0.56346809, grad/param norm = 1.8392e-01, time/batch = 14.9751s	
24581/26050 (epoch 47.180), train_loss = 0.94731053, grad/param norm = 2.1593e-01, time/batch = 17.8116s	
24582/26050 (epoch 47.182), train_loss = 0.88392608, grad/param norm = 2.6850e-01, time/batch = 18.6436s	
24583/26050 (epoch 47.184), train_loss = 0.77145218, grad/param norm = 2.1245e-01, time/batch = 17.3165s	
24584/26050 (epoch 47.186), train_loss = 0.66917980, grad/param norm = 2.2592e-01, time/batch = 18.5779s	
24585/26050 (epoch 47.188), train_loss = 0.80555250, grad/param norm = 2.2706e-01, time/batch = 17.1497s	
24586/26050 (epoch 47.190), train_loss = 0.81423127, grad/param norm = 2.9150e-01, time/batch = 18.5604s	
24587/26050 (epoch 47.192), train_loss = 0.86389910, grad/param norm = 2.1398e-01, time/batch = 18.3685s	
24588/26050 (epoch 47.194), train_loss = 0.79527795, grad/param norm = 2.3715e-01, time/batch = 14.7147s	
24589/26050 (epoch 47.196), train_loss = 0.81444861, grad/param norm = 2.2907e-01, time/batch = 18.4711s	
24590/26050 (epoch 47.198), train_loss = 0.68194519, grad/param norm = 1.8031e-01, time/batch = 14.7172s	
24591/26050 (epoch 47.200), train_loss = 0.68603080, grad/param norm = 2.2206e-01, time/batch = 18.5744s	
24592/26050 (epoch 47.202), train_loss = 0.76201459, grad/param norm = 2.0758e-01, time/batch = 17.8896s	
24593/26050 (epoch 47.203), train_loss = 0.87518030, grad/param norm = 2.0534e-01, time/batch = 18.9806s	
24594/26050 (epoch 47.205), train_loss = 0.71755896, grad/param norm = 2.3983e-01, time/batch = 18.2306s	
24595/26050 (epoch 47.207), train_loss = 0.68038824, grad/param norm = 2.2250e-01, time/batch = 17.7338s	
24596/26050 (epoch 47.209), train_loss = 0.81273611, grad/param norm = 2.0248e-01, time/batch = 18.8309s	
24597/26050 (epoch 47.211), train_loss = 0.65685097, grad/param norm = 1.7921e-01, time/batch = 17.4974s	
24598/26050 (epoch 47.213), train_loss = 0.76970091, grad/param norm = 2.1917e-01, time/batch = 16.8853s	
24599/26050 (epoch 47.215), train_loss = 0.73341166, grad/param norm = 2.3483e-01, time/batch = 16.9705s	
24600/26050 (epoch 47.217), train_loss = 0.72004188, grad/param norm = 1.8473e-01, time/batch = 17.7280s	
24601/26050 (epoch 47.219), train_loss = 0.69921973, grad/param norm = 2.0209e-01, time/batch = 18.2368s	
24602/26050 (epoch 47.221), train_loss = 0.67009745, grad/param norm = 2.1748e-01, time/batch = 16.9722s	
24603/26050 (epoch 47.223), train_loss = 0.81686591, grad/param norm = 2.2058e-01, time/batch = 18.8123s	
24604/26050 (epoch 47.225), train_loss = 0.66515994, grad/param norm = 2.3823e-01, time/batch = 18.7328s	
24605/26050 (epoch 47.226), train_loss = 0.75142254, grad/param norm = 2.2754e-01, time/batch = 17.5476s	
24606/26050 (epoch 47.228), train_loss = 0.85100320, grad/param norm = 2.2743e-01, time/batch = 18.4831s	
24607/26050 (epoch 47.230), train_loss = 0.76002001, grad/param norm = 2.1894e-01, time/batch = 15.6925s	
24608/26050 (epoch 47.232), train_loss = 0.85090958, grad/param norm = 2.6920e-01, time/batch = 18.3906s	
24609/26050 (epoch 47.234), train_loss = 0.65589114, grad/param norm = 2.2023e-01, time/batch = 17.7263s	
24610/26050 (epoch 47.236), train_loss = 0.79455214, grad/param norm = 2.2713e-01, time/batch = 14.5592s	
24611/26050 (epoch 47.238), train_loss = 0.68232915, grad/param norm = 2.1040e-01, time/batch = 18.6446s	
24612/26050 (epoch 47.240), train_loss = 0.76589671, grad/param norm = 2.3187e-01, time/batch = 17.4840s	
24613/26050 (epoch 47.242), train_loss = 0.73924993, grad/param norm = 2.1130e-01, time/batch = 18.3959s	
24614/26050 (epoch 47.244), train_loss = 0.77829364, grad/param norm = 2.4315e-01, time/batch = 14.8092s	
24615/26050 (epoch 47.246), train_loss = 0.72018094, grad/param norm = 1.9583e-01, time/batch = 18.0463s	
24616/26050 (epoch 47.248), train_loss = 0.76840000, grad/param norm = 2.5371e-01, time/batch = 18.3939s	
24617/26050 (epoch 47.250), train_loss = 0.77081549, grad/param norm = 2.4067e-01, time/batch = 18.4889s	
24618/26050 (epoch 47.251), train_loss = 0.72553522, grad/param norm = 2.4802e-01, time/batch = 18.3931s	
24619/26050 (epoch 47.253), train_loss = 0.63330807, grad/param norm = 1.8166e-01, time/batch = 17.2163s	
24620/26050 (epoch 47.255), train_loss = 0.90897616, grad/param norm = 2.6430e-01, time/batch = 17.9899s	
24621/26050 (epoch 47.257), train_loss = 0.77886697, grad/param norm = 2.1335e-01, time/batch = 18.7211s	
24622/26050 (epoch 47.259), train_loss = 0.83204787, grad/param norm = 2.2794e-01, time/batch = 16.9792s	
24623/26050 (epoch 47.261), train_loss = 0.68864430, grad/param norm = 2.4625e-01, time/batch = 18.5493s	
24624/26050 (epoch 47.263), train_loss = 0.83379984, grad/param norm = 2.4282e-01, time/batch = 18.4770s	
24625/26050 (epoch 47.265), train_loss = 0.85345080, grad/param norm = 2.4661e-01, time/batch = 17.7321s	
24626/26050 (epoch 47.267), train_loss = 0.87787141, grad/param norm = 1.9875e-01, time/batch = 18.4021s	
24627/26050 (epoch 47.269), train_loss = 0.85415503, grad/param norm = 2.3562e-01, time/batch = 18.0723s	
24628/26050 (epoch 47.271), train_loss = 0.74989247, grad/param norm = 2.2135e-01, time/batch = 14.9700s	
24629/26050 (epoch 47.273), train_loss = 0.67307245, grad/param norm = 2.4429e-01, time/batch = 18.0752s	
24630/26050 (epoch 47.274), train_loss = 0.73015307, grad/param norm = 2.1135e-01, time/batch = 14.7220s	
24631/26050 (epoch 47.276), train_loss = 0.74381680, grad/param norm = 2.7319e-01, time/batch = 18.2108s	
24632/26050 (epoch 47.278), train_loss = 0.83304149, grad/param norm = 2.1622e-01, time/batch = 17.8050s	
24633/26050 (epoch 47.280), train_loss = 0.73571532, grad/param norm = 2.0591e-01, time/batch = 18.9078s	
24634/26050 (epoch 47.282), train_loss = 0.84912963, grad/param norm = 2.3573e-01, time/batch = 17.9065s	
24635/26050 (epoch 47.284), train_loss = 0.76667315, grad/param norm = 2.1332e-01, time/batch = 17.9026s	
24636/26050 (epoch 47.286), train_loss = 0.80874728, grad/param norm = 2.2768e-01, time/batch = 18.1414s	
24637/26050 (epoch 47.288), train_loss = 0.65410815, grad/param norm = 1.9926e-01, time/batch = 15.8240s	
24638/26050 (epoch 47.290), train_loss = 0.75814324, grad/param norm = 2.1844e-01, time/batch = 18.8252s	
24639/26050 (epoch 47.292), train_loss = 0.70152810, grad/param norm = 2.1139e-01, time/batch = 17.2361s	
24640/26050 (epoch 47.294), train_loss = 0.76456312, grad/param norm = 2.5176e-01, time/batch = 16.7472s	
24641/26050 (epoch 47.296), train_loss = 0.83637914, grad/param norm = 2.4259e-01, time/batch = 18.8255s	
24642/26050 (epoch 47.298), train_loss = 0.82251558, grad/param norm = 2.3371e-01, time/batch = 17.6535s	
24643/26050 (epoch 47.299), train_loss = 0.65862404, grad/param norm = 2.1211e-01, time/batch = 18.8123s	
24644/26050 (epoch 47.301), train_loss = 0.66052177, grad/param norm = 2.4230e-01, time/batch = 15.1957s	
24645/26050 (epoch 47.303), train_loss = 0.75082179, grad/param norm = 2.3540e-01, time/batch = 18.8252s	
24646/26050 (epoch 47.305), train_loss = 0.62368150, grad/param norm = 2.0668e-01, time/batch = 17.6418s	
24647/26050 (epoch 47.307), train_loss = 0.66928113, grad/param norm = 2.4613e-01, time/batch = 18.3919s	
24648/26050 (epoch 47.309), train_loss = 0.79480259, grad/param norm = 2.2581e-01, time/batch = 15.9562s	
24649/26050 (epoch 47.311), train_loss = 0.76544206, grad/param norm = 2.4943e-01, time/batch = 16.6386s	
24650/26050 (epoch 47.313), train_loss = 0.74678881, grad/param norm = 2.8677e-01, time/batch = 17.7110s	
24651/26050 (epoch 47.315), train_loss = 0.81287817, grad/param norm = 2.7468e-01, time/batch = 18.4949s	
24652/26050 (epoch 47.317), train_loss = 0.74805316, grad/param norm = 2.4098e-01, time/batch = 18.0775s	
24653/26050 (epoch 47.319), train_loss = 0.71382450, grad/param norm = 2.5765e-01, time/batch = 4.6020s	
24654/26050 (epoch 47.321), train_loss = 0.77763337, grad/param norm = 2.3927e-01, time/batch = 0.6458s	
24655/26050 (epoch 47.322), train_loss = 0.83719007, grad/param norm = 2.3799e-01, time/batch = 0.6761s	
24656/26050 (epoch 47.324), train_loss = 0.61625879, grad/param norm = 2.1417e-01, time/batch = 0.6722s	
24657/26050 (epoch 47.326), train_loss = 0.87067875, grad/param norm = 2.3324e-01, time/batch = 0.6449s	
24658/26050 (epoch 47.328), train_loss = 0.80089959, grad/param norm = 2.2278e-01, time/batch = 0.6451s	
24659/26050 (epoch 47.330), train_loss = 0.65223642, grad/param norm = 2.1506e-01, time/batch = 0.6576s	
24660/26050 (epoch 47.332), train_loss = 0.80701703, grad/param norm = 2.3332e-01, time/batch = 0.6852s	
24661/26050 (epoch 47.334), train_loss = 0.68474033, grad/param norm = 2.7298e-01, time/batch = 0.9458s	
24662/26050 (epoch 47.336), train_loss = 0.75306841, grad/param norm = 2.2049e-01, time/batch = 0.9444s	
24663/26050 (epoch 47.338), train_loss = 0.66491639, grad/param norm = 1.9276e-01, time/batch = 0.9460s	
24664/26050 (epoch 47.340), train_loss = 0.79946281, grad/param norm = 2.2466e-01, time/batch = 0.9361s	
24665/26050 (epoch 47.342), train_loss = 0.85419106, grad/param norm = 2.3309e-01, time/batch = 0.9441s	
24666/26050 (epoch 47.344), train_loss = 0.70280950, grad/param norm = 2.5371e-01, time/batch = 1.7017s	
24667/26050 (epoch 47.345), train_loss = 0.76645620, grad/param norm = 3.5153e-01, time/batch = 1.8217s	
24668/26050 (epoch 47.347), train_loss = 0.87230660, grad/param norm = 2.2700e-01, time/batch = 3.3116s	
24669/26050 (epoch 47.349), train_loss = 0.80334477, grad/param norm = 2.4575e-01, time/batch = 17.7437s	
24670/26050 (epoch 47.351), train_loss = 0.77824786, grad/param norm = 2.3209e-01, time/batch = 17.9876s	
24671/26050 (epoch 47.353), train_loss = 0.74518520, grad/param norm = 2.1716e-01, time/batch = 18.3150s	
24672/26050 (epoch 47.355), train_loss = 0.76597208, grad/param norm = 3.0023e-01, time/batch = 18.0580s	
24673/26050 (epoch 47.357), train_loss = 0.71229732, grad/param norm = 2.0434e-01, time/batch = 17.2139s	
24674/26050 (epoch 47.359), train_loss = 0.86144936, grad/param norm = 2.5889e-01, time/batch = 17.4807s	
24675/26050 (epoch 47.361), train_loss = 0.69189172, grad/param norm = 2.0781e-01, time/batch = 18.8688s	
24676/26050 (epoch 47.363), train_loss = 0.82073784, grad/param norm = 2.1428e-01, time/batch = 18.5669s	
24677/26050 (epoch 47.365), train_loss = 0.74688099, grad/param norm = 1.9701e-01, time/batch = 17.5706s	
24678/26050 (epoch 47.367), train_loss = 0.80803619, grad/param norm = 2.1744e-01, time/batch = 16.3837s	
24679/26050 (epoch 47.369), train_loss = 0.65865968, grad/param norm = 1.8600e-01, time/batch = 17.9000s	
24680/26050 (epoch 47.370), train_loss = 0.65324440, grad/param norm = 1.7639e-01, time/batch = 18.6407s	
24681/26050 (epoch 47.372), train_loss = 0.73689023, grad/param norm = 2.5044e-01, time/batch = 17.9704s	
24682/26050 (epoch 47.374), train_loss = 0.87204425, grad/param norm = 2.1864e-01, time/batch = 17.0721s	
24683/26050 (epoch 47.376), train_loss = 0.86577760, grad/param norm = 2.6115e-01, time/batch = 16.3823s	
24684/26050 (epoch 47.378), train_loss = 0.73472567, grad/param norm = 2.1042e-01, time/batch = 17.3972s	
24685/26050 (epoch 47.380), train_loss = 0.86178295, grad/param norm = 2.6326e-01, time/batch = 15.2239s	
24686/26050 (epoch 47.382), train_loss = 0.92525863, grad/param norm = 2.6852e-01, time/batch = 18.6300s	
24687/26050 (epoch 47.384), train_loss = 0.73948875, grad/param norm = 2.5118e-01, time/batch = 17.6457s	
24688/26050 (epoch 47.386), train_loss = 0.82847111, grad/param norm = 2.9010e-01, time/batch = 17.4568s	
24689/26050 (epoch 47.388), train_loss = 0.79777617, grad/param norm = 3.1339e-01, time/batch = 18.4591s	
24690/26050 (epoch 47.390), train_loss = 0.69944419, grad/param norm = 2.0752e-01, time/batch = 18.1435s	
24691/26050 (epoch 47.392), train_loss = 0.65019666, grad/param norm = 2.0368e-01, time/batch = 16.9491s	
24692/26050 (epoch 47.393), train_loss = 0.83029548, grad/param norm = 2.3050e-01, time/batch = 18.4703s	
24693/26050 (epoch 47.395), train_loss = 0.82794247, grad/param norm = 2.5584e-01, time/batch = 17.9837s	
24694/26050 (epoch 47.397), train_loss = 0.81311062, grad/param norm = 2.2556e-01, time/batch = 17.3899s	
24695/26050 (epoch 47.399), train_loss = 0.72214886, grad/param norm = 2.3827e-01, time/batch = 16.7318s	
24696/26050 (epoch 47.401), train_loss = 0.77143785, grad/param norm = 2.1363e-01, time/batch = 15.4836s	
24697/26050 (epoch 47.403), train_loss = 0.78644710, grad/param norm = 2.6679e-01, time/batch = 18.3097s	
24698/26050 (epoch 47.405), train_loss = 0.77252947, grad/param norm = 2.1974e-01, time/batch = 17.0651s	
24699/26050 (epoch 47.407), train_loss = 0.89268116, grad/param norm = 2.4881e-01, time/batch = 18.6503s	
24700/26050 (epoch 47.409), train_loss = 0.88175327, grad/param norm = 2.8696e-01, time/batch = 18.8140s	
24701/26050 (epoch 47.411), train_loss = 0.83976465, grad/param norm = 2.0680e-01, time/batch = 20.0230s	
24702/26050 (epoch 47.413), train_loss = 0.95680986, grad/param norm = 2.3906e-01, time/batch = 33.0763s	
24703/26050 (epoch 47.415), train_loss = 0.92383898, grad/param norm = 2.4217e-01, time/batch = 18.7067s	
24704/26050 (epoch 47.417), train_loss = 0.93256796, grad/param norm = 2.7787e-01, time/batch = 18.0608s	
24705/26050 (epoch 47.418), train_loss = 0.82497931, grad/param norm = 2.9535e-01, time/batch = 18.1541s	
24706/26050 (epoch 47.420), train_loss = 0.66424699, grad/param norm = 1.9746e-01, time/batch = 15.5768s	
24707/26050 (epoch 47.422), train_loss = 0.65837687, grad/param norm = 2.0241e-01, time/batch = 16.3132s	
24708/26050 (epoch 47.424), train_loss = 0.86438224, grad/param norm = 2.3496e-01, time/batch = 18.9795s	
24709/26050 (epoch 47.426), train_loss = 0.81482195, grad/param norm = 2.6466e-01, time/batch = 17.8165s	
24710/26050 (epoch 47.428), train_loss = 0.75864818, grad/param norm = 2.2434e-01, time/batch = 17.3875s	
24711/26050 (epoch 47.430), train_loss = 0.93113122, grad/param norm = 2.4884e-01, time/batch = 15.3084s	
24712/26050 (epoch 47.432), train_loss = 0.74409977, grad/param norm = 2.1487e-01, time/batch = 18.0559s	
24713/26050 (epoch 47.434), train_loss = 0.73009396, grad/param norm = 2.3455e-01, time/batch = 17.4958s	
24714/26050 (epoch 47.436), train_loss = 0.84507188, grad/param norm = 2.4138e-01, time/batch = 17.8090s	
24715/26050 (epoch 47.438), train_loss = 0.81307772, grad/param norm = 2.7163e-01, time/batch = 15.9755s	
24716/26050 (epoch 47.440), train_loss = 0.82319749, grad/param norm = 2.3454e-01, time/batch = 18.4123s	
24717/26050 (epoch 47.441), train_loss = 0.80564723, grad/param norm = 2.3484e-01, time/batch = 17.9712s	
24718/26050 (epoch 47.443), train_loss = 0.68141473, grad/param norm = 1.9545e-01, time/batch = 17.8151s	
24719/26050 (epoch 47.445), train_loss = 0.69759401, grad/param norm = 2.0991e-01, time/batch = 18.9057s	
24720/26050 (epoch 47.447), train_loss = 0.90694247, grad/param norm = 2.3885e-01, time/batch = 16.2977s	
24721/26050 (epoch 47.449), train_loss = 0.70300512, grad/param norm = 2.2054e-01, time/batch = 18.7304s	
24722/26050 (epoch 47.451), train_loss = 0.89513590, grad/param norm = 2.4638e-01, time/batch = 18.4842s	
24723/26050 (epoch 47.453), train_loss = 0.75078590, grad/param norm = 1.9590e-01, time/batch = 16.6227s	
24724/26050 (epoch 47.455), train_loss = 0.78112617, grad/param norm = 2.0392e-01, time/batch = 15.3887s	
24725/26050 (epoch 47.457), train_loss = 0.75062342, grad/param norm = 2.3203e-01, time/batch = 17.4679s	
24726/26050 (epoch 47.459), train_loss = 0.83350221, grad/param norm = 2.5518e-01, time/batch = 18.1419s	
24727/26050 (epoch 47.461), train_loss = 0.85121129, grad/param norm = 2.4759e-01, time/batch = 17.5652s	
24728/26050 (epoch 47.463), train_loss = 0.72868267, grad/param norm = 2.0918e-01, time/batch = 18.6574s	
24729/26050 (epoch 47.464), train_loss = 0.80250489, grad/param norm = 2.4684e-01, time/batch = 18.6401s	
24730/26050 (epoch 47.466), train_loss = 0.78182976, grad/param norm = 2.8561e-01, time/batch = 18.8147s	
24731/26050 (epoch 47.468), train_loss = 0.86710683, grad/param norm = 2.1315e-01, time/batch = 16.1326s	
24732/26050 (epoch 47.470), train_loss = 0.85282359, grad/param norm = 2.2686e-01, time/batch = 18.2175s	
24733/26050 (epoch 47.472), train_loss = 0.85448902, grad/param norm = 2.7538e-01, time/batch = 16.0662s	
24734/26050 (epoch 47.474), train_loss = 0.89949449, grad/param norm = 2.5504e-01, time/batch = 15.7254s	
24735/26050 (epoch 47.476), train_loss = 0.85963171, grad/param norm = 2.2634e-01, time/batch = 18.1507s	
24736/26050 (epoch 47.478), train_loss = 0.76452444, grad/param norm = 2.1827e-01, time/batch = 18.0702s	
24737/26050 (epoch 47.480), train_loss = 0.74510027, grad/param norm = 1.9949e-01, time/batch = 17.8952s	
24738/26050 (epoch 47.482), train_loss = 0.74868005, grad/param norm = 2.0606e-01, time/batch = 17.8206s	
24739/26050 (epoch 47.484), train_loss = 0.72394759, grad/param norm = 2.2475e-01, time/batch = 18.9059s	
24740/26050 (epoch 47.486), train_loss = 0.88051544, grad/param norm = 2.5220e-01, time/batch = 17.9868s	
24741/26050 (epoch 47.488), train_loss = 0.92146884, grad/param norm = 2.6683e-01, time/batch = 16.5726s	
24742/26050 (epoch 47.489), train_loss = 0.94986416, grad/param norm = 2.5139e-01, time/batch = 18.3096s	
24743/26050 (epoch 47.491), train_loss = 0.70737150, grad/param norm = 2.1529e-01, time/batch = 16.3819s	
24744/26050 (epoch 47.493), train_loss = 0.80309465, grad/param norm = 2.4355e-01, time/batch = 14.9003s	
24745/26050 (epoch 47.495), train_loss = 0.77732253, grad/param norm = 2.0310e-01, time/batch = 15.7067s	
24746/26050 (epoch 47.497), train_loss = 0.68568297, grad/param norm = 2.0955e-01, time/batch = 18.0681s	
24747/26050 (epoch 47.499), train_loss = 0.71226874, grad/param norm = 2.3388e-01, time/batch = 18.4803s	
24748/26050 (epoch 47.501), train_loss = 0.88608494, grad/param norm = 2.2889e-01, time/batch = 17.6565s	
24749/26050 (epoch 47.503), train_loss = 0.74993983, grad/param norm = 2.2677e-01, time/batch = 17.4102s	
24750/26050 (epoch 47.505), train_loss = 0.86296669, grad/param norm = 2.0320e-01, time/batch = 18.7374s	
24751/26050 (epoch 47.507), train_loss = 0.87097746, grad/param norm = 2.5930e-01, time/batch = 15.9560s	
24752/26050 (epoch 47.509), train_loss = 0.90403243, grad/param norm = 2.1720e-01, time/batch = 18.6312s	
24753/26050 (epoch 47.511), train_loss = 0.77399617, grad/param norm = 2.0101e-01, time/batch = 17.8241s	
24754/26050 (epoch 47.512), train_loss = 0.67607087, grad/param norm = 2.4129e-01, time/batch = 17.0812s	
24755/26050 (epoch 47.514), train_loss = 0.84132378, grad/param norm = 2.4290e-01, time/batch = 18.1396s	
24756/26050 (epoch 47.516), train_loss = 0.92022894, grad/param norm = 2.5411e-01, time/batch = 18.9839s	
24757/26050 (epoch 47.518), train_loss = 0.76624622, grad/param norm = 2.0764e-01, time/batch = 15.2825s	
24758/26050 (epoch 47.520), train_loss = 0.78083513, grad/param norm = 2.2384e-01, time/batch = 18.6260s	
24759/26050 (epoch 47.522), train_loss = 0.62685254, grad/param norm = 2.0717e-01, time/batch = 17.9910s	
24760/26050 (epoch 47.524), train_loss = 0.86504563, grad/param norm = 2.8139e-01, time/batch = 17.8181s	
24761/26050 (epoch 47.526), train_loss = 0.88068654, grad/param norm = 2.5804e-01, time/batch = 17.2353s	
24762/26050 (epoch 47.528), train_loss = 0.81092255, grad/param norm = 2.4300e-01, time/batch = 17.0550s	
24763/26050 (epoch 47.530), train_loss = 0.75891112, grad/param norm = 2.6167e-01, time/batch = 18.5714s	
24764/26050 (epoch 47.532), train_loss = 0.85202372, grad/param norm = 2.2601e-01, time/batch = 17.2525s	
24765/26050 (epoch 47.534), train_loss = 0.80653776, grad/param norm = 3.3621e-01, time/batch = 16.8972s	
24766/26050 (epoch 47.536), train_loss = 0.82458442, grad/param norm = 2.5505e-01, time/batch = 17.6529s	
24767/26050 (epoch 47.537), train_loss = 0.86818011, grad/param norm = 2.2749e-01, time/batch = 18.5727s	
24768/26050 (epoch 47.539), train_loss = 0.81773332, grad/param norm = 2.3470e-01, time/batch = 16.9745s	
24769/26050 (epoch 47.541), train_loss = 0.93706354, grad/param norm = 2.7224e-01, time/batch = 18.3247s	
24770/26050 (epoch 47.543), train_loss = 0.61240459, grad/param norm = 1.9579e-01, time/batch = 17.9813s	
24771/26050 (epoch 47.545), train_loss = 0.75944592, grad/param norm = 2.2153e-01, time/batch = 16.6224s	
24772/26050 (epoch 47.547), train_loss = 0.71427953, grad/param norm = 2.1852e-01, time/batch = 18.7315s	
24773/26050 (epoch 47.549), train_loss = 0.70298524, grad/param norm = 2.5887e-01, time/batch = 14.3123s	
24774/26050 (epoch 47.551), train_loss = 0.85341881, grad/param norm = 2.2536e-01, time/batch = 16.7179s	
24775/26050 (epoch 47.553), train_loss = 0.74711632, grad/param norm = 2.2686e-01, time/batch = 17.5563s	
24776/26050 (epoch 47.555), train_loss = 0.66288025, grad/param norm = 2.1816e-01, time/batch = 18.5591s	
24777/26050 (epoch 47.557), train_loss = 0.80353846, grad/param norm = 2.0226e-01, time/batch = 17.2410s	
24778/26050 (epoch 47.559), train_loss = 0.80695669, grad/param norm = 2.1657e-01, time/batch = 18.1525s	
24779/26050 (epoch 47.560), train_loss = 0.76588532, grad/param norm = 2.3902e-01, time/batch = 18.1518s	
24780/26050 (epoch 47.562), train_loss = 0.78343466, grad/param norm = 2.4106e-01, time/batch = 18.7126s	
24781/26050 (epoch 47.564), train_loss = 0.92899830, grad/param norm = 2.3650e-01, time/batch = 18.2403s	
24782/26050 (epoch 47.566), train_loss = 0.72050009, grad/param norm = 1.9624e-01, time/batch = 17.9693s	
24783/26050 (epoch 47.568), train_loss = 0.82506075, grad/param norm = 2.6157e-01, time/batch = 15.8818s	
24784/26050 (epoch 47.570), train_loss = 0.77397114, grad/param norm = 2.4908e-01, time/batch = 18.7418s	
24785/26050 (epoch 47.572), train_loss = 0.79963735, grad/param norm = 2.5735e-01, time/batch = 17.7282s	
24786/26050 (epoch 47.574), train_loss = 0.81204236, grad/param norm = 3.0242e-01, time/batch = 16.7934s	
24787/26050 (epoch 47.576), train_loss = 0.81658241, grad/param norm = 2.6478e-01, time/batch = 18.3163s	
24788/26050 (epoch 47.578), train_loss = 0.76393092, grad/param norm = 2.8837e-01, time/batch = 17.6408s	
24789/26050 (epoch 47.580), train_loss = 0.70492610, grad/param norm = 2.3877e-01, time/batch = 18.1372s	
24790/26050 (epoch 47.582), train_loss = 0.80533952, grad/param norm = 2.2924e-01, time/batch = 15.3878s	
24791/26050 (epoch 47.583), train_loss = 0.82472006, grad/param norm = 2.0822e-01, time/batch = 17.5477s	
24792/26050 (epoch 47.585), train_loss = 0.71037537, grad/param norm = 2.1522e-01, time/batch = 15.3903s	
24793/26050 (epoch 47.587), train_loss = 0.80079455, grad/param norm = 2.2817e-01, time/batch = 18.6350s	
24794/26050 (epoch 47.589), train_loss = 0.92593709, grad/param norm = 2.4508e-01, time/batch = 17.9855s	
24795/26050 (epoch 47.591), train_loss = 0.81785087, grad/param norm = 2.1992e-01, time/batch = 17.7326s	
24796/26050 (epoch 47.593), train_loss = 0.67665806, grad/param norm = 2.2559e-01, time/batch = 18.5822s	
24797/26050 (epoch 47.595), train_loss = 0.82086921, grad/param norm = 2.4606e-01, time/batch = 18.1489s	
24798/26050 (epoch 47.597), train_loss = 0.80816320, grad/param norm = 2.5166e-01, time/batch = 18.5670s	
24799/26050 (epoch 47.599), train_loss = 0.84395172, grad/param norm = 2.1245e-01, time/batch = 16.4472s	
24800/26050 (epoch 47.601), train_loss = 0.94199875, grad/param norm = 2.4202e-01, time/batch = 18.6400s	
24801/26050 (epoch 47.603), train_loss = 0.84701731, grad/param norm = 2.3462e-01, time/batch = 17.8368s	
24802/26050 (epoch 47.605), train_loss = 0.77185717, grad/param norm = 2.1944e-01, time/batch = 17.5647s	
24803/26050 (epoch 47.607), train_loss = 0.87502578, grad/param norm = 3.0891e-01, time/batch = 17.9867s	
24804/26050 (epoch 47.608), train_loss = 0.72539025, grad/param norm = 1.9667e-01, time/batch = 17.6199s	
24805/26050 (epoch 47.610), train_loss = 0.78896006, grad/param norm = 2.4353e-01, time/batch = 17.3166s	
24806/26050 (epoch 47.612), train_loss = 0.75564247, grad/param norm = 2.1496e-01, time/batch = 17.7131s	
24807/26050 (epoch 47.614), train_loss = 0.80680791, grad/param norm = 2.4776e-01, time/batch = 16.3704s	
24808/26050 (epoch 47.616), train_loss = 0.83359178, grad/param norm = 2.4796e-01, time/batch = 18.3115s	
24809/26050 (epoch 47.618), train_loss = 0.73014558, grad/param norm = 2.3229e-01, time/batch = 16.4823s	
24810/26050 (epoch 47.620), train_loss = 0.86913538, grad/param norm = 2.6452e-01, time/batch = 14.3668s	
24811/26050 (epoch 47.622), train_loss = 0.72573084, grad/param norm = 2.1263e-01, time/batch = 17.9642s	
24812/26050 (epoch 47.624), train_loss = 0.65083844, grad/param norm = 2.1762e-01, time/batch = 17.8113s	
24813/26050 (epoch 47.626), train_loss = 0.82649165, grad/param norm = 2.1565e-01, time/batch = 18.3961s	
24814/26050 (epoch 47.628), train_loss = 0.73638881, grad/param norm = 2.9863e-01, time/batch = 18.6403s	
24815/26050 (epoch 47.630), train_loss = 0.92752200, grad/param norm = 2.2613e-01, time/batch = 17.8962s	
24816/26050 (epoch 47.631), train_loss = 0.90557520, grad/param norm = 2.5278e-01, time/batch = 17.3910s	
24817/26050 (epoch 47.633), train_loss = 0.73118688, grad/param norm = 2.4256e-01, time/batch = 18.0689s	
24818/26050 (epoch 47.635), train_loss = 0.76240810, grad/param norm = 2.2030e-01, time/batch = 18.6565s	
24819/26050 (epoch 47.637), train_loss = 0.70693759, grad/param norm = 2.0426e-01, time/batch = 17.0692s	
24820/26050 (epoch 47.639), train_loss = 0.82595895, grad/param norm = 2.1036e-01, time/batch = 18.2310s	
24821/26050 (epoch 47.641), train_loss = 0.72432826, grad/param norm = 1.9971e-01, time/batch = 19.0710s	
24822/26050 (epoch 47.643), train_loss = 0.72704564, grad/param norm = 1.8195e-01, time/batch = 15.1323s	
24823/26050 (epoch 47.645), train_loss = 0.74386814, grad/param norm = 2.1702e-01, time/batch = 17.3153s	
24824/26050 (epoch 47.647), train_loss = 0.67981934, grad/param norm = 2.2016e-01, time/batch = 18.5636s	
24825/26050 (epoch 47.649), train_loss = 0.74817231, grad/param norm = 2.4319e-01, time/batch = 18.5752s	
24826/26050 (epoch 47.651), train_loss = 0.75916094, grad/param norm = 2.0369e-01, time/batch = 17.1655s	
24827/26050 (epoch 47.653), train_loss = 0.77815344, grad/param norm = 2.7858e-01, time/batch = 17.5736s	
24828/26050 (epoch 47.655), train_loss = 0.70195988, grad/param norm = 2.1419e-01, time/batch = 16.7874s	
24829/26050 (epoch 47.656), train_loss = 0.69335471, grad/param norm = 2.0260e-01, time/batch = 17.8054s	
24830/26050 (epoch 47.658), train_loss = 0.93895105, grad/param norm = 2.4651e-01, time/batch = 15.5540s	
24831/26050 (epoch 47.660), train_loss = 0.65336575, grad/param norm = 2.4412e-01, time/batch = 16.1345s	
24832/26050 (epoch 47.662), train_loss = 0.77028217, grad/param norm = 2.3947e-01, time/batch = 18.6550s	
24833/26050 (epoch 47.664), train_loss = 0.77266488, grad/param norm = 2.0487e-01, time/batch = 16.9009s	
24834/26050 (epoch 47.666), train_loss = 0.74690509, grad/param norm = 2.2306e-01, time/batch = 18.0778s	
24835/26050 (epoch 47.668), train_loss = 0.60554235, grad/param norm = 2.4800e-01, time/batch = 14.9829s	
24836/26050 (epoch 47.670), train_loss = 0.89129029, grad/param norm = 2.6457e-01, time/batch = 17.5668s	
24837/26050 (epoch 47.672), train_loss = 0.76420271, grad/param norm = 2.4624e-01, time/batch = 18.3138s	
24838/26050 (epoch 47.674), train_loss = 0.66240472, grad/param norm = 2.1013e-01, time/batch = 17.7304s	
24839/26050 (epoch 47.676), train_loss = 0.82054801, grad/param norm = 2.4393e-01, time/batch = 17.6549s	
24840/26050 (epoch 47.678), train_loss = 0.83852512, grad/param norm = 2.0612e-01, time/batch = 14.4739s	
24841/26050 (epoch 47.679), train_loss = 0.87308572, grad/param norm = 2.3877e-01, time/batch = 17.7369s	
24842/26050 (epoch 47.681), train_loss = 0.79779169, grad/param norm = 2.2959e-01, time/batch = 18.2374s	
24843/26050 (epoch 47.683), train_loss = 0.71250094, grad/param norm = 2.2449e-01, time/batch = 17.2374s	
24844/26050 (epoch 47.685), train_loss = 0.73580713, grad/param norm = 2.6445e-01, time/batch = 17.6438s	
24845/26050 (epoch 47.687), train_loss = 0.70684276, grad/param norm = 2.3157e-01, time/batch = 18.1405s	
24846/26050 (epoch 47.689), train_loss = 0.74234533, grad/param norm = 2.3648e-01, time/batch = 18.4790s	
24847/26050 (epoch 47.691), train_loss = 0.65469234, grad/param norm = 1.8871e-01, time/batch = 18.8802s	
24848/26050 (epoch 47.693), train_loss = 0.73533926, grad/param norm = 2.4733e-01, time/batch = 16.2898s	
24849/26050 (epoch 47.695), train_loss = 0.75596508, grad/param norm = 2.1093e-01, time/batch = 17.6362s	
24850/26050 (epoch 47.697), train_loss = 0.69724915, grad/param norm = 2.3082e-01, time/batch = 17.6397s	
24851/26050 (epoch 47.699), train_loss = 0.81629322, grad/param norm = 2.3623e-01, time/batch = 17.9100s	
24852/26050 (epoch 47.701), train_loss = 0.69474487, grad/param norm = 1.8774e-01, time/batch = 18.9031s	
24853/26050 (epoch 47.702), train_loss = 0.85845931, grad/param norm = 2.5034e-01, time/batch = 17.4820s	
24854/26050 (epoch 47.704), train_loss = 0.89117954, grad/param norm = 2.3115e-01, time/batch = 15.8084s	
24855/26050 (epoch 47.706), train_loss = 0.72085682, grad/param norm = 2.2673e-01, time/batch = 18.3314s	
24856/26050 (epoch 47.708), train_loss = 0.82917989, grad/param norm = 2.2219e-01, time/batch = 17.0548s	
24857/26050 (epoch 47.710), train_loss = 0.81931134, grad/param norm = 2.8718e-01, time/batch = 15.4350s	
24858/26050 (epoch 47.712), train_loss = 0.76803724, grad/param norm = 2.5172e-01, time/batch = 18.5261s	
24859/26050 (epoch 47.714), train_loss = 0.69504577, grad/param norm = 1.9072e-01, time/batch = 18.9031s	
24860/26050 (epoch 47.716), train_loss = 0.97936017, grad/param norm = 2.4284e-01, time/batch = 17.9699s	
24861/26050 (epoch 47.718), train_loss = 0.84076966, grad/param norm = 2.5174e-01, time/batch = 19.0581s	
24862/26050 (epoch 47.720), train_loss = 0.74570422, grad/param norm = 2.0617e-01, time/batch = 18.4888s	
24863/26050 (epoch 47.722), train_loss = 0.70915643, grad/param norm = 2.0570e-01, time/batch = 17.8951s	
24864/26050 (epoch 47.724), train_loss = 0.72889719, grad/param norm = 2.1850e-01, time/batch = 18.3083s	
24865/26050 (epoch 47.726), train_loss = 0.83712526, grad/param norm = 2.4155e-01, time/batch = 18.4693s	
24866/26050 (epoch 47.727), train_loss = 0.81226715, grad/param norm = 2.3130e-01, time/batch = 17.9115s	
24867/26050 (epoch 47.729), train_loss = 0.83441711, grad/param norm = 2.4016e-01, time/batch = 17.0441s	
24868/26050 (epoch 47.731), train_loss = 0.82081666, grad/param norm = 2.2596e-01, time/batch = 16.9639s	
24869/26050 (epoch 47.733), train_loss = 0.74084374, grad/param norm = 2.5097e-01, time/batch = 18.4729s	
24870/26050 (epoch 47.735), train_loss = 0.88308381, grad/param norm = 2.5089e-01, time/batch = 17.6526s	
24871/26050 (epoch 47.737), train_loss = 0.76230833, grad/param norm = 2.7871e-01, time/batch = 18.4880s	
24872/26050 (epoch 47.739), train_loss = 0.79755447, grad/param norm = 2.0675e-01, time/batch = 18.4895s	
24873/26050 (epoch 47.741), train_loss = 0.70509917, grad/param norm = 2.1037e-01, time/batch = 17.2253s	
24874/26050 (epoch 47.743), train_loss = 0.79078562, grad/param norm = 2.7097e-01, time/batch = 17.9898s	
24875/26050 (epoch 47.745), train_loss = 0.70208229, grad/param norm = 2.1282e-01, time/batch = 18.0752s	
24876/26050 (epoch 47.747), train_loss = 0.73289806, grad/param norm = 2.2149e-01, time/batch = 18.7519s	
24877/26050 (epoch 47.749), train_loss = 0.88073576, grad/param norm = 2.8313e-01, time/batch = 16.9797s	
24878/26050 (epoch 47.750), train_loss = 0.72844159, grad/param norm = 1.9275e-01, time/batch = 17.8347s	
24879/26050 (epoch 47.752), train_loss = 0.72909092, grad/param norm = 2.4247e-01, time/batch = 15.9612s	
24880/26050 (epoch 47.754), train_loss = 0.77410392, grad/param norm = 2.1989e-01, time/batch = 15.3745s	
24881/26050 (epoch 47.756), train_loss = 0.74108430, grad/param norm = 2.3569e-01, time/batch = 18.1181s	
24882/26050 (epoch 47.758), train_loss = 0.75594196, grad/param norm = 2.2678e-01, time/batch = 18.3085s	
24883/26050 (epoch 47.760), train_loss = 0.90546748, grad/param norm = 3.0164e-01, time/batch = 18.6486s	
24884/26050 (epoch 47.762), train_loss = 0.74925160, grad/param norm = 2.1819e-01, time/batch = 15.1484s	
24885/26050 (epoch 47.764), train_loss = 0.76151508, grad/param norm = 3.0735e-01, time/batch = 17.8214s	
24886/26050 (epoch 47.766), train_loss = 0.75888158, grad/param norm = 2.3422e-01, time/batch = 18.2367s	
24887/26050 (epoch 47.768), train_loss = 0.65072946, grad/param norm = 2.0274e-01, time/batch = 17.4812s	
24888/26050 (epoch 47.770), train_loss = 0.76610469, grad/param norm = 2.2311e-01, time/batch = 18.9145s	
24889/26050 (epoch 47.772), train_loss = 0.77921525, grad/param norm = 2.4015e-01, time/batch = 17.1538s	
24890/26050 (epoch 47.774), train_loss = 0.63862543, grad/param norm = 2.1917e-01, time/batch = 14.6592s	
24891/26050 (epoch 47.775), train_loss = 0.55419766, grad/param norm = 2.1699e-01, time/batch = 14.7191s	
24892/26050 (epoch 47.777), train_loss = 0.73890008, grad/param norm = 2.3529e-01, time/batch = 14.2756s	
24893/26050 (epoch 47.779), train_loss = 0.75536677, grad/param norm = 2.2804e-01, time/batch = 13.9142s	
24894/26050 (epoch 47.781), train_loss = 0.70479534, grad/param norm = 2.1386e-01, time/batch = 16.9417s	
24895/26050 (epoch 47.783), train_loss = 0.66851018, grad/param norm = 2.1217e-01, time/batch = 17.3821s	
24896/26050 (epoch 47.785), train_loss = 0.78956934, grad/param norm = 2.6795e-01, time/batch = 18.2953s	
24897/26050 (epoch 47.787), train_loss = 0.69599113, grad/param norm = 2.4491e-01, time/batch = 17.4060s	
24898/26050 (epoch 47.789), train_loss = 0.69749472, grad/param norm = 2.6020e-01, time/batch = 17.1565s	
24899/26050 (epoch 47.791), train_loss = 0.68990458, grad/param norm = 2.4806e-01, time/batch = 18.5757s	
24900/26050 (epoch 47.793), train_loss = 0.77886363, grad/param norm = 2.6007e-01, time/batch = 18.3900s	
24901/26050 (epoch 47.795), train_loss = 0.62311722, grad/param norm = 2.0766e-01, time/batch = 16.6552s	
24902/26050 (epoch 47.797), train_loss = 0.69110222, grad/param norm = 2.1208e-01, time/batch = 15.8938s	
24903/26050 (epoch 47.798), train_loss = 0.76573074, grad/param norm = 2.5702e-01, time/batch = 16.7918s	
24904/26050 (epoch 47.800), train_loss = 0.64749611, grad/param norm = 2.0945e-01, time/batch = 17.2165s	
24905/26050 (epoch 47.802), train_loss = 0.74195833, grad/param norm = 2.2901e-01, time/batch = 23.2582s	
24906/26050 (epoch 47.804), train_loss = 0.76310585, grad/param norm = 2.7948e-01, time/batch = 32.3167s	
24907/26050 (epoch 47.806), train_loss = 0.83081425, grad/param norm = 2.8026e-01, time/batch = 16.7960s	
24908/26050 (epoch 47.808), train_loss = 0.78378620, grad/param norm = 2.1931e-01, time/batch = 15.4726s	
24909/26050 (epoch 47.810), train_loss = 0.78168504, grad/param norm = 2.1949e-01, time/batch = 18.3103s	
24910/26050 (epoch 47.812), train_loss = 0.64296392, grad/param norm = 2.4230e-01, time/batch = 18.1538s	
24911/26050 (epoch 47.814), train_loss = 0.67510578, grad/param norm = 2.6276e-01, time/batch = 18.0532s	
24912/26050 (epoch 47.816), train_loss = 0.79475350, grad/param norm = 2.5191e-01, time/batch = 17.1537s	
24913/26050 (epoch 47.818), train_loss = 0.84477759, grad/param norm = 3.4664e-01, time/batch = 14.5447s	
24914/26050 (epoch 47.820), train_loss = 0.78324641, grad/param norm = 2.3896e-01, time/batch = 15.7118s	
24915/26050 (epoch 47.821), train_loss = 0.84834631, grad/param norm = 2.4912e-01, time/batch = 17.5656s	
24916/26050 (epoch 47.823), train_loss = 0.95249130, grad/param norm = 2.4834e-01, time/batch = 18.2391s	
24917/26050 (epoch 47.825), train_loss = 0.77399277, grad/param norm = 2.5988e-01, time/batch = 17.5605s	
24918/26050 (epoch 47.827), train_loss = 0.75406923, grad/param norm = 2.6365e-01, time/batch = 17.2339s	
24919/26050 (epoch 47.829), train_loss = 0.87931227, grad/param norm = 2.5445e-01, time/batch = 17.4740s	
24920/26050 (epoch 47.831), train_loss = 0.91627816, grad/param norm = 2.2941e-01, time/batch = 18.2385s	
24921/26050 (epoch 47.833), train_loss = 0.85630835, grad/param norm = 2.3963e-01, time/batch = 17.5472s	
24922/26050 (epoch 47.835), train_loss = 0.88390924, grad/param norm = 2.4082e-01, time/batch = 18.9727s	
24923/26050 (epoch 47.837), train_loss = 0.81451664, grad/param norm = 2.7265e-01, time/batch = 18.3961s	
24924/26050 (epoch 47.839), train_loss = 0.76321610, grad/param norm = 2.9026e-01, time/batch = 16.9855s	
24925/26050 (epoch 47.841), train_loss = 0.82085758, grad/param norm = 2.7406e-01, time/batch = 18.4906s	
24926/26050 (epoch 47.843), train_loss = 0.75254532, grad/param norm = 2.2252e-01, time/batch = 17.9015s	
24927/26050 (epoch 47.845), train_loss = 0.73198698, grad/param norm = 2.0470e-01, time/batch = 16.2100s	
24928/26050 (epoch 47.846), train_loss = 0.80626238, grad/param norm = 2.4484e-01, time/batch = 17.9757s	
24929/26050 (epoch 47.848), train_loss = 0.75571174, grad/param norm = 2.3170e-01, time/batch = 18.8931s	
24930/26050 (epoch 47.850), train_loss = 0.69086135, grad/param norm = 2.7774e-01, time/batch = 18.3114s	
24931/26050 (epoch 47.852), train_loss = 0.79889511, grad/param norm = 2.2295e-01, time/batch = 17.2818s	
24932/26050 (epoch 47.854), train_loss = 0.77799531, grad/param norm = 2.4113e-01, time/batch = 18.0727s	
24933/26050 (epoch 47.856), train_loss = 0.72906056, grad/param norm = 2.4443e-01, time/batch = 16.7294s	
24934/26050 (epoch 47.858), train_loss = 0.70290665, grad/param norm = 2.3299e-01, time/batch = 14.5470s	
24935/26050 (epoch 47.860), train_loss = 0.78360442, grad/param norm = 2.9733e-01, time/batch = 17.7194s	
24936/26050 (epoch 47.862), train_loss = 0.84507480, grad/param norm = 2.5795e-01, time/batch = 17.9011s	
24937/26050 (epoch 47.864), train_loss = 0.78189212, grad/param norm = 3.3984e-01, time/batch = 16.7161s	
24938/26050 (epoch 47.866), train_loss = 0.78780112, grad/param norm = 2.3191e-01, time/batch = 17.4008s	
24939/26050 (epoch 47.868), train_loss = 0.84922541, grad/param norm = 3.5654e-01, time/batch = 17.5597s	
24940/26050 (epoch 47.869), train_loss = 0.71746995, grad/param norm = 2.1526e-01, time/batch = 18.9691s	
24941/26050 (epoch 47.871), train_loss = 0.66448556, grad/param norm = 2.3901e-01, time/batch = 16.4757s	
24942/26050 (epoch 47.873), train_loss = 0.83035997, grad/param norm = 2.4289e-01, time/batch = 14.6567s	
24943/26050 (epoch 47.875), train_loss = 0.73469368, grad/param norm = 2.3903e-01, time/batch = 18.7119s	
24944/26050 (epoch 47.877), train_loss = 0.72305582, grad/param norm = 1.9645e-01, time/batch = 18.7318s	
24945/26050 (epoch 47.879), train_loss = 0.84567865, grad/param norm = 2.2898e-01, time/batch = 16.7085s	
24946/26050 (epoch 47.881), train_loss = 0.83838233, grad/param norm = 2.5898e-01, time/batch = 17.8815s	
24947/26050 (epoch 47.883), train_loss = 0.84972230, grad/param norm = 2.5405e-01, time/batch = 16.2134s	
24948/26050 (epoch 47.885), train_loss = 0.60448970, grad/param norm = 2.1146e-01, time/batch = 18.3758s	
24949/26050 (epoch 47.887), train_loss = 0.85473697, grad/param norm = 2.3316e-01, time/batch = 17.7471s	
24950/26050 (epoch 47.889), train_loss = 0.72634424, grad/param norm = 2.1864e-01, time/batch = 18.2323s	
24951/26050 (epoch 47.891), train_loss = 0.64325564, grad/param norm = 2.0421e-01, time/batch = 18.5635s	
24952/26050 (epoch 47.893), train_loss = 0.63668664, grad/param norm = 1.9214e-01, time/batch = 18.6440s	
24953/26050 (epoch 47.894), train_loss = 0.70899486, grad/param norm = 2.2136e-01, time/batch = 18.1456s	
24954/26050 (epoch 47.896), train_loss = 0.85156862, grad/param norm = 2.9698e-01, time/batch = 18.4729s	
24955/26050 (epoch 47.898), train_loss = 0.72330884, grad/param norm = 2.8874e-01, time/batch = 17.0493s	
24956/26050 (epoch 47.900), train_loss = 0.81724202, grad/param norm = 2.7807e-01, time/batch = 17.5393s	
24957/26050 (epoch 47.902), train_loss = 0.73758821, grad/param norm = 2.3013e-01, time/batch = 18.4719s	
24958/26050 (epoch 47.904), train_loss = 0.76031583, grad/param norm = 2.5861e-01, time/batch = 16.5605s	
24959/26050 (epoch 47.906), train_loss = 0.72530704, grad/param norm = 2.2653e-01, time/batch = 15.8168s	
24960/26050 (epoch 47.908), train_loss = 0.80187959, grad/param norm = 2.1278e-01, time/batch = 15.6241s	
24961/26050 (epoch 47.910), train_loss = 0.71277312, grad/param norm = 2.3288e-01, time/batch = 18.7895s	
24962/26050 (epoch 47.912), train_loss = 0.92592027, grad/param norm = 2.7791e-01, time/batch = 17.8018s	
24963/26050 (epoch 47.914), train_loss = 1.03657995, grad/param norm = 2.5355e-01, time/batch = 18.1579s	
24964/26050 (epoch 47.916), train_loss = 0.81612233, grad/param norm = 2.6136e-01, time/batch = 17.8964s	
24965/26050 (epoch 47.917), train_loss = 0.79727171, grad/param norm = 2.2157e-01, time/batch = 17.9057s	
24966/26050 (epoch 47.919), train_loss = 0.80599256, grad/param norm = 2.9320e-01, time/batch = 17.9761s	
24967/26050 (epoch 47.921), train_loss = 0.69888568, grad/param norm = 2.2900e-01, time/batch = 17.1226s	
24968/26050 (epoch 47.923), train_loss = 0.79259300, grad/param norm = 2.2837e-01, time/batch = 17.1446s	
24969/26050 (epoch 47.925), train_loss = 0.78348300, grad/param norm = 2.6806e-01, time/batch = 15.5402s	
24970/26050 (epoch 47.927), train_loss = 0.73384275, grad/param norm = 2.1599e-01, time/batch = 18.1447s	
24971/26050 (epoch 47.929), train_loss = 0.65429487, grad/param norm = 2.1030e-01, time/batch = 18.3279s	
24972/26050 (epoch 47.931), train_loss = 0.90352990, grad/param norm = 2.9480e-01, time/batch = 16.8901s	
24973/26050 (epoch 47.933), train_loss = 0.78329507, grad/param norm = 2.2663e-01, time/batch = 16.9668s	
24974/26050 (epoch 47.935), train_loss = 0.74729408, grad/param norm = 2.2569e-01, time/batch = 18.4141s	
24975/26050 (epoch 47.937), train_loss = 0.85224829, grad/param norm = 2.4045e-01, time/batch = 17.5571s	
24976/26050 (epoch 47.939), train_loss = 0.72054203, grad/param norm = 2.0335e-01, time/batch = 14.9722s	
24977/26050 (epoch 47.940), train_loss = 0.78584343, grad/param norm = 2.3660e-01, time/batch = 18.6508s	
24978/26050 (epoch 47.942), train_loss = 0.71136445, grad/param norm = 2.3416e-01, time/batch = 18.4769s	
24979/26050 (epoch 47.944), train_loss = 0.74181943, grad/param norm = 1.9797e-01, time/batch = 18.1352s	
24980/26050 (epoch 47.946), train_loss = 0.91733222, grad/param norm = 2.2413e-01, time/batch = 14.9735s	
24981/26050 (epoch 47.948), train_loss = 0.65224517, grad/param norm = 2.1940e-01, time/batch = 17.9780s	
24982/26050 (epoch 47.950), train_loss = 0.79197388, grad/param norm = 2.2983e-01, time/batch = 14.9765s	
24983/26050 (epoch 47.952), train_loss = 0.81079756, grad/param norm = 2.5131e-01, time/batch = 16.3233s	
24984/26050 (epoch 47.954), train_loss = 0.82682238, grad/param norm = 2.2774e-01, time/batch = 18.4051s	
24985/26050 (epoch 47.956), train_loss = 0.70957074, grad/param norm = 1.9674e-01, time/batch = 17.6669s	
24986/26050 (epoch 47.958), train_loss = 0.68861609, grad/param norm = 1.9724e-01, time/batch = 17.4890s	
24987/26050 (epoch 47.960), train_loss = 0.80436197, grad/param norm = 2.2367e-01, time/batch = 15.8844s	
24988/26050 (epoch 47.962), train_loss = 0.76289577, grad/param norm = 1.9908e-01, time/batch = 18.5584s	
24989/26050 (epoch 47.964), train_loss = 0.72498830, grad/param norm = 2.1765e-01, time/batch = 17.7287s	
24990/26050 (epoch 47.965), train_loss = 0.68729316, grad/param norm = 2.1601e-01, time/batch = 17.9874s	
24991/26050 (epoch 47.967), train_loss = 0.99190376, grad/param norm = 2.5691e-01, time/batch = 18.3191s	
24992/26050 (epoch 47.969), train_loss = 0.76225864, grad/param norm = 2.4950e-01, time/batch = 17.9620s	
24993/26050 (epoch 47.971), train_loss = 0.79201465, grad/param norm = 2.5352e-01, time/batch = 18.3118s	
24994/26050 (epoch 47.973), train_loss = 0.78099894, grad/param norm = 2.1552e-01, time/batch = 15.5394s	
24995/26050 (epoch 47.975), train_loss = 0.76978572, grad/param norm = 2.0984e-01, time/batch = 18.5614s	
24996/26050 (epoch 47.977), train_loss = 0.75184946, grad/param norm = 1.9552e-01, time/batch = 17.9158s	
24997/26050 (epoch 47.979), train_loss = 0.61716625, grad/param norm = 1.9807e-01, time/batch = 18.3116s	
24998/26050 (epoch 47.981), train_loss = 0.82943311, grad/param norm = 1.9515e-01, time/batch = 17.8926s	
24999/26050 (epoch 47.983), train_loss = 0.79228807, grad/param norm = 2.1516e-01, time/batch = 16.8763s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch47.98_1.9942.t7	
25000/26050 (epoch 47.985), train_loss = 0.78689832, grad/param norm = 2.3448e-01, time/batch = 16.5600s	
25001/26050 (epoch 47.987), train_loss = 1.36791227, grad/param norm = 3.4503e-01, time/batch = 18.8215s	
25002/26050 (epoch 47.988), train_loss = 0.81567329, grad/param norm = 2.5537e-01, time/batch = 18.0708s	
25003/26050 (epoch 47.990), train_loss = 0.66745769, grad/param norm = 2.1447e-01, time/batch = 16.2266s	
25004/26050 (epoch 47.992), train_loss = 0.89445038, grad/param norm = 2.4428e-01, time/batch = 16.7006s	
25005/26050 (epoch 47.994), train_loss = 0.70974017, grad/param norm = 2.4597e-01, time/batch = 17.0516s	
25006/26050 (epoch 47.996), train_loss = 0.68447928, grad/param norm = 2.6226e-01, time/batch = 18.8877s	
25007/26050 (epoch 47.998), train_loss = 0.77930676, grad/param norm = 2.2238e-01, time/batch = 17.8007s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
25008/26050 (epoch 48.000), train_loss = 0.69292916, grad/param norm = 2.3867e-01, time/batch = 18.5533s	
25009/26050 (epoch 48.002), train_loss = 0.83715848, grad/param norm = 2.6149e-01, time/batch = 18.8187s	
25010/26050 (epoch 48.004), train_loss = 0.67065348, grad/param norm = 2.1838e-01, time/batch = 15.8857s	
25011/26050 (epoch 48.006), train_loss = 0.73779058, grad/param norm = 2.3263e-01, time/batch = 18.8740s	
25012/26050 (epoch 48.008), train_loss = 0.69697208, grad/param norm = 2.1448e-01, time/batch = 18.7334s	
25013/26050 (epoch 48.010), train_loss = 0.69523887, grad/param norm = 2.1009e-01, time/batch = 17.4692s	
25014/26050 (epoch 48.012), train_loss = 0.74704021, grad/param norm = 2.2375e-01, time/batch = 15.5716s	
25015/26050 (epoch 48.013), train_loss = 0.97979223, grad/param norm = 2.4105e-01, time/batch = 15.7013s	
25016/26050 (epoch 48.015), train_loss = 0.75688055, grad/param norm = 2.4121e-01, time/batch = 17.5651s	
25017/26050 (epoch 48.017), train_loss = 0.79710771, grad/param norm = 2.1476e-01, time/batch = 17.4781s	
25018/26050 (epoch 48.019), train_loss = 0.66124426, grad/param norm = 1.7454e-01, time/batch = 18.1600s	
25019/26050 (epoch 48.021), train_loss = 0.82929812, grad/param norm = 2.2885e-01, time/batch = 18.7314s	
25020/26050 (epoch 48.023), train_loss = 0.62973847, grad/param norm = 2.1377e-01, time/batch = 17.0641s	
25021/26050 (epoch 48.025), train_loss = 0.78217286, grad/param norm = 2.2643e-01, time/batch = 17.7368s	
25022/26050 (epoch 48.027), train_loss = 0.60522632, grad/param norm = 2.0577e-01, time/batch = 18.6643s	
25023/26050 (epoch 48.029), train_loss = 0.83936186, grad/param norm = 2.2595e-01, time/batch = 16.3934s	
25024/26050 (epoch 48.031), train_loss = 0.87868874, grad/param norm = 2.5135e-01, time/batch = 18.3834s	
25025/26050 (epoch 48.033), train_loss = 0.75731264, grad/param norm = 2.3056e-01, time/batch = 18.0668s	
25026/26050 (epoch 48.035), train_loss = 0.79755192, grad/param norm = 2.0586e-01, time/batch = 16.6946s	
25027/26050 (epoch 48.036), train_loss = 0.67457734, grad/param norm = 2.3857e-01, time/batch = 15.8104s	
25028/26050 (epoch 48.038), train_loss = 0.62917371, grad/param norm = 2.0238e-01, time/batch = 17.9911s	
25029/26050 (epoch 48.040), train_loss = 0.74722953, grad/param norm = 2.2251e-01, time/batch = 18.4738s	
25030/26050 (epoch 48.042), train_loss = 0.65016610, grad/param norm = 2.0782e-01, time/batch = 18.0544s	
25031/26050 (epoch 48.044), train_loss = 0.82046700, grad/param norm = 2.0377e-01, time/batch = 18.1259s	
25032/26050 (epoch 48.046), train_loss = 0.64828062, grad/param norm = 1.8976e-01, time/batch = 17.5561s	
25033/26050 (epoch 48.048), train_loss = 0.76260639, grad/param norm = 2.1028e-01, time/batch = 16.9652s	
25034/26050 (epoch 48.050), train_loss = 0.74400909, grad/param norm = 2.4334e-01, time/batch = 16.9934s	
25035/26050 (epoch 48.052), train_loss = 0.70685987, grad/param norm = 2.2536e-01, time/batch = 18.1405s	
25036/26050 (epoch 48.054), train_loss = 0.64263464, grad/param norm = 2.1797e-01, time/batch = 18.4147s	
25037/26050 (epoch 48.056), train_loss = 0.64202022, grad/param norm = 1.7554e-01, time/batch = 16.4888s	
25038/26050 (epoch 48.058), train_loss = 0.73371691, grad/param norm = 2.0234e-01, time/batch = 18.2330s	
25039/26050 (epoch 48.060), train_loss = 0.81831675, grad/param norm = 2.1466e-01, time/batch = 18.4889s	
25040/26050 (epoch 48.061), train_loss = 0.64759398, grad/param norm = 2.1095e-01, time/batch = 18.4135s	
25041/26050 (epoch 48.063), train_loss = 0.74217699, grad/param norm = 2.0163e-01, time/batch = 17.8822s	
25042/26050 (epoch 48.065), train_loss = 0.62706496, grad/param norm = 1.7995e-01, time/batch = 18.3298s	
25043/26050 (epoch 48.067), train_loss = 0.76966569, grad/param norm = 2.2539e-01, time/batch = 18.3911s	
25044/26050 (epoch 48.069), train_loss = 0.79040114, grad/param norm = 2.7478e-01, time/batch = 16.9632s	
25045/26050 (epoch 48.071), train_loss = 0.76088680, grad/param norm = 2.2821e-01, time/batch = 17.8769s	
25046/26050 (epoch 48.073), train_loss = 0.91611306, grad/param norm = 2.5942e-01, time/batch = 18.7334s	
25047/26050 (epoch 48.075), train_loss = 0.72788595, grad/param norm = 2.4654e-01, time/batch = 15.6368s	
25048/26050 (epoch 48.077), train_loss = 0.74073847, grad/param norm = 2.3609e-01, time/batch = 14.7956s	
25049/26050 (epoch 48.079), train_loss = 0.72778187, grad/param norm = 2.2409e-01, time/batch = 17.3124s	
25050/26050 (epoch 48.081), train_loss = 0.74356931, grad/param norm = 2.5030e-01, time/batch = 17.6381s	
25051/26050 (epoch 48.083), train_loss = 0.86187906, grad/param norm = 2.4443e-01, time/batch = 17.1306s	
25052/26050 (epoch 48.084), train_loss = 0.80192543, grad/param norm = 2.4056e-01, time/batch = 17.4559s	
25053/26050 (epoch 48.086), train_loss = 0.90454026, grad/param norm = 2.7267e-01, time/batch = 19.0659s	
25054/26050 (epoch 48.088), train_loss = 0.76738194, grad/param norm = 2.3069e-01, time/batch = 16.3908s	
25055/26050 (epoch 48.090), train_loss = 0.78288427, grad/param norm = 2.2031e-01, time/batch = 16.9016s	
25056/26050 (epoch 48.092), train_loss = 0.81090201, grad/param norm = 2.1276e-01, time/batch = 18.3064s	
25057/26050 (epoch 48.094), train_loss = 0.65412246, grad/param norm = 2.8292e-01, time/batch = 16.2060s	
25058/26050 (epoch 48.096), train_loss = 0.78423940, grad/param norm = 2.1932e-01, time/batch = 18.2792s	
25059/26050 (epoch 48.098), train_loss = 0.76516597, grad/param norm = 2.3497e-01, time/batch = 17.7186s	
25060/26050 (epoch 48.100), train_loss = 0.67135288, grad/param norm = 2.0005e-01, time/batch = 18.4023s	
25061/26050 (epoch 48.102), train_loss = 0.77876823, grad/param norm = 2.7557e-01, time/batch = 17.4068s	
25062/26050 (epoch 48.104), train_loss = 0.74238709, grad/param norm = 2.3816e-01, time/batch = 18.7345s	
25063/26050 (epoch 48.106), train_loss = 0.79402962, grad/param norm = 2.5607e-01, time/batch = 18.0736s	
25064/26050 (epoch 48.107), train_loss = 0.64384751, grad/param norm = 2.2266e-01, time/batch = 16.3793s	
25065/26050 (epoch 48.109), train_loss = 0.71517393, grad/param norm = 2.2066e-01, time/batch = 17.8056s	
25066/26050 (epoch 48.111), train_loss = 0.89433851, grad/param norm = 2.5189e-01, time/batch = 18.4029s	
25067/26050 (epoch 48.113), train_loss = 0.73809558, grad/param norm = 2.0054e-01, time/batch = 18.4734s	
25068/26050 (epoch 48.115), train_loss = 0.82144980, grad/param norm = 2.1270e-01, time/batch = 17.7169s	
25069/26050 (epoch 48.117), train_loss = 0.78539680, grad/param norm = 2.5709e-01, time/batch = 18.1390s	
25070/26050 (epoch 48.119), train_loss = 0.66420819, grad/param norm = 2.0498e-01, time/batch = 18.0541s	
25071/26050 (epoch 48.121), train_loss = 0.75217054, grad/param norm = 2.0254e-01, time/batch = 17.3103s	
25072/26050 (epoch 48.123), train_loss = 0.70128172, grad/param norm = 2.3691e-01, time/batch = 15.5678s	
25073/26050 (epoch 48.125), train_loss = 0.63891232, grad/param norm = 2.0458e-01, time/batch = 17.9588s	
25074/26050 (epoch 48.127), train_loss = 0.63729076, grad/param norm = 2.2921e-01, time/batch = 17.4682s	
25075/26050 (epoch 48.129), train_loss = 0.59389878, grad/param norm = 2.4170e-01, time/batch = 18.5706s	
25076/26050 (epoch 48.131), train_loss = 0.75822114, grad/param norm = 2.2649e-01, time/batch = 16.7234s	
25077/26050 (epoch 48.132), train_loss = 0.77059925, grad/param norm = 2.0290e-01, time/batch = 18.5463s	
25078/26050 (epoch 48.134), train_loss = 0.77766847, grad/param norm = 2.5171e-01, time/batch = 15.4729s	
25079/26050 (epoch 48.136), train_loss = 0.71044560, grad/param norm = 1.9797e-01, time/batch = 17.9911s	
25080/26050 (epoch 48.138), train_loss = 0.53812400, grad/param norm = 2.1197e-01, time/batch = 18.0688s	
25081/26050 (epoch 48.140), train_loss = 0.62449004, grad/param norm = 2.2935e-01, time/batch = 17.4801s	
25082/26050 (epoch 48.142), train_loss = 0.62939010, grad/param norm = 1.9250e-01, time/batch = 18.4020s	
25083/26050 (epoch 48.144), train_loss = 0.61317559, grad/param norm = 2.3703e-01, time/batch = 18.3215s	
25084/26050 (epoch 48.146), train_loss = 0.55572265, grad/param norm = 1.8639e-01, time/batch = 18.6433s	
25085/26050 (epoch 48.148), train_loss = 0.60685436, grad/param norm = 2.0371e-01, time/batch = 16.3751s	
25086/26050 (epoch 48.150), train_loss = 0.67088742, grad/param norm = 2.3581e-01, time/batch = 14.5475s	
25087/26050 (epoch 48.152), train_loss = 0.82140695, grad/param norm = 2.7473e-01, time/batch = 18.6204s	
25088/26050 (epoch 48.154), train_loss = 0.58280378, grad/param norm = 2.3361e-01, time/batch = 17.1497s	
25089/26050 (epoch 48.155), train_loss = 0.63948643, grad/param norm = 2.0921e-01, time/batch = 18.1631s	
25090/26050 (epoch 48.157), train_loss = 0.69551375, grad/param norm = 2.3145e-01, time/batch = 16.9703s	
25091/26050 (epoch 48.159), train_loss = 0.75257107, grad/param norm = 2.2866e-01, time/batch = 17.7328s	
25092/26050 (epoch 48.161), train_loss = 0.73132904, grad/param norm = 2.3549e-01, time/batch = 18.4888s	
25093/26050 (epoch 48.163), train_loss = 0.62575139, grad/param norm = 2.2379e-01, time/batch = 17.7368s	
25094/26050 (epoch 48.165), train_loss = 0.56835355, grad/param norm = 1.8766e-01, time/batch = 15.9861s	
25095/26050 (epoch 48.167), train_loss = 0.85633649, grad/param norm = 2.7057e-01, time/batch = 16.8005s	
25096/26050 (epoch 48.169), train_loss = 0.74497617, grad/param norm = 2.5459e-01, time/batch = 18.3206s	
25097/26050 (epoch 48.171), train_loss = 0.67908729, grad/param norm = 2.0291e-01, time/batch = 18.3932s	
25098/26050 (epoch 48.173), train_loss = 0.70883093, grad/param norm = 2.2338e-01, time/batch = 18.3156s	
25099/26050 (epoch 48.175), train_loss = 0.73487983, grad/param norm = 2.2987e-01, time/batch = 15.8015s	
25100/26050 (epoch 48.177), train_loss = 0.79853224, grad/param norm = 2.4204e-01, time/batch = 18.1516s	
25101/26050 (epoch 48.179), train_loss = 0.58269286, grad/param norm = 2.0488e-01, time/batch = 18.8842s	
25102/26050 (epoch 48.180), train_loss = 0.95335902, grad/param norm = 2.4062e-01, time/batch = 28.8643s	
25103/26050 (epoch 48.182), train_loss = 0.89181883, grad/param norm = 2.8290e-01, time/batch = 28.7189s	
25104/26050 (epoch 48.184), train_loss = 0.74287343, grad/param norm = 2.0958e-01, time/batch = 14.6620s	
25105/26050 (epoch 48.186), train_loss = 0.65781255, grad/param norm = 2.1690e-01, time/batch = 18.0546s	
25106/26050 (epoch 48.188), train_loss = 0.80786277, grad/param norm = 2.5640e-01, time/batch = 18.0700s	
25107/26050 (epoch 48.190), train_loss = 0.79411773, grad/param norm = 2.3013e-01, time/batch = 17.1953s	
25108/26050 (epoch 48.192), train_loss = 0.84202986, grad/param norm = 2.1542e-01, time/batch = 18.8151s	
25109/26050 (epoch 48.194), train_loss = 0.76904864, grad/param norm = 2.0262e-01, time/batch = 17.8941s	
25110/26050 (epoch 48.196), train_loss = 0.80853337, grad/param norm = 2.1703e-01, time/batch = 18.4985s	
25111/26050 (epoch 48.198), train_loss = 0.68034302, grad/param norm = 1.8978e-01, time/batch = 18.1329s	
25112/26050 (epoch 48.200), train_loss = 0.68198035, grad/param norm = 2.3979e-01, time/batch = 18.6497s	
25113/26050 (epoch 48.202), train_loss = 0.76635019, grad/param norm = 2.3140e-01, time/batch = 17.8222s	
25114/26050 (epoch 48.203), train_loss = 0.86467791, grad/param norm = 1.9844e-01, time/batch = 15.0473s	
25115/26050 (epoch 48.205), train_loss = 0.71151161, grad/param norm = 2.2867e-01, time/batch = 18.2382s	
25116/26050 (epoch 48.207), train_loss = 0.68092035, grad/param norm = 2.3552e-01, time/batch = 18.0848s	
25117/26050 (epoch 48.209), train_loss = 0.84788170, grad/param norm = 2.4741e-01, time/batch = 17.1612s	
25118/26050 (epoch 48.211), train_loss = 0.64938624, grad/param norm = 1.9229e-01, time/batch = 15.9431s	
25119/26050 (epoch 48.213), train_loss = 0.76452567, grad/param norm = 2.3726e-01, time/batch = 17.9737s	
25120/26050 (epoch 48.215), train_loss = 0.71902715, grad/param norm = 2.1437e-01, time/batch = 15.6424s	
25121/26050 (epoch 48.217), train_loss = 0.71974988, grad/param norm = 1.9752e-01, time/batch = 16.9907s	
25122/26050 (epoch 48.219), train_loss = 0.70535723, grad/param norm = 2.6853e-01, time/batch = 18.4032s	
25123/26050 (epoch 48.221), train_loss = 0.67560406, grad/param norm = 2.7117e-01, time/batch = 18.9003s	
25124/26050 (epoch 48.223), train_loss = 0.82077209, grad/param norm = 2.7020e-01, time/batch = 17.8057s	
25125/26050 (epoch 48.225), train_loss = 0.67431026, grad/param norm = 2.2480e-01, time/batch = 16.2925s	
25126/26050 (epoch 48.226), train_loss = 0.75749196, grad/param norm = 2.6976e-01, time/batch = 14.7229s	
25127/26050 (epoch 48.228), train_loss = 0.84024768, grad/param norm = 2.2645e-01, time/batch = 18.7365s	
25128/26050 (epoch 48.230), train_loss = 0.75277514, grad/param norm = 2.1180e-01, time/batch = 17.7167s	
25129/26050 (epoch 48.232), train_loss = 0.84239403, grad/param norm = 2.7526e-01, time/batch = 17.6435s	
25130/26050 (epoch 48.234), train_loss = 0.65135089, grad/param norm = 2.3312e-01, time/batch = 18.8197s	
25131/26050 (epoch 48.236), train_loss = 0.79631025, grad/param norm = 2.3250e-01, time/batch = 17.0687s	
25132/26050 (epoch 48.238), train_loss = 0.66748594, grad/param norm = 1.9993e-01, time/batch = 18.8089s	
25133/26050 (epoch 48.240), train_loss = 0.75218233, grad/param norm = 2.4028e-01, time/batch = 18.6559s	
25134/26050 (epoch 48.242), train_loss = 0.72855440, grad/param norm = 2.3348e-01, time/batch = 17.3879s	
25135/26050 (epoch 48.244), train_loss = 0.77403318, grad/param norm = 2.3437e-01, time/batch = 17.8039s	
25136/26050 (epoch 48.246), train_loss = 0.71490265, grad/param norm = 2.1972e-01, time/batch = 18.0734s	
25137/26050 (epoch 48.248), train_loss = 0.76739877, grad/param norm = 2.2764e-01, time/batch = 14.8965s	
25138/26050 (epoch 48.250), train_loss = 0.75320294, grad/param norm = 2.3887e-01, time/batch = 16.0673s	
25139/26050 (epoch 48.251), train_loss = 0.72442352, grad/param norm = 2.2250e-01, time/batch = 15.5485s	
25140/26050 (epoch 48.253), train_loss = 0.63516968, grad/param norm = 2.1508e-01, time/batch = 16.4697s	
25141/26050 (epoch 48.255), train_loss = 0.90260767, grad/param norm = 2.4636e-01, time/batch = 18.1580s	
25142/26050 (epoch 48.257), train_loss = 0.78274429, grad/param norm = 2.3774e-01, time/batch = 16.9897s	
25143/26050 (epoch 48.259), train_loss = 0.84444033, grad/param norm = 2.3219e-01, time/batch = 17.6350s	
25144/26050 (epoch 48.261), train_loss = 0.66598827, grad/param norm = 2.1587e-01, time/batch = 17.3300s	
25145/26050 (epoch 48.263), train_loss = 0.81403093, grad/param norm = 2.4659e-01, time/batch = 17.4725s	
25146/26050 (epoch 48.265), train_loss = 0.84519826, grad/param norm = 2.7271e-01, time/batch = 17.0809s	
25147/26050 (epoch 48.267), train_loss = 0.87612372, grad/param norm = 2.4505e-01, time/batch = 15.3134s	
25148/26050 (epoch 48.269), train_loss = 0.85106461, grad/param norm = 2.2739e-01, time/batch = 18.1279s	
25149/26050 (epoch 48.271), train_loss = 0.75080569, grad/param norm = 2.3430e-01, time/batch = 15.3716s	
25150/26050 (epoch 48.273), train_loss = 0.67660269, grad/param norm = 2.2884e-01, time/batch = 18.4118s	
25151/26050 (epoch 48.274), train_loss = 0.71843952, grad/param norm = 1.9575e-01, time/batch = 18.3095s	
25152/26050 (epoch 48.276), train_loss = 0.73149698, grad/param norm = 2.3729e-01, time/batch = 17.4690s	
25153/26050 (epoch 48.278), train_loss = 0.81652764, grad/param norm = 2.1333e-01, time/batch = 18.7132s	
25154/26050 (epoch 48.280), train_loss = 0.72186517, grad/param norm = 1.9221e-01, time/batch = 18.4883s	
25155/26050 (epoch 48.282), train_loss = 0.83815983, grad/param norm = 2.3314e-01, time/batch = 16.6545s	
25156/26050 (epoch 48.284), train_loss = 0.75162814, grad/param norm = 2.2934e-01, time/batch = 18.9038s	
25157/26050 (epoch 48.286), train_loss = 0.79417560, grad/param norm = 2.4458e-01, time/batch = 18.2391s	
25158/26050 (epoch 48.288), train_loss = 0.66333448, grad/param norm = 2.5225e-01, time/batch = 17.7513s	
25159/26050 (epoch 48.290), train_loss = 0.75562983, grad/param norm = 2.1693e-01, time/batch = 18.2173s	
25160/26050 (epoch 48.292), train_loss = 0.68659655, grad/param norm = 2.1816e-01, time/batch = 16.0469s	
25161/26050 (epoch 48.294), train_loss = 0.75299354, grad/param norm = 2.5329e-01, time/batch = 18.5694s	
25162/26050 (epoch 48.296), train_loss = 0.82619760, grad/param norm = 2.1998e-01, time/batch = 17.2354s	
25163/26050 (epoch 48.298), train_loss = 0.80320443, grad/param norm = 2.1167e-01, time/batch = 18.5818s	
25164/26050 (epoch 48.299), train_loss = 0.65642453, grad/param norm = 2.5875e-01, time/batch = 18.4856s	
25165/26050 (epoch 48.301), train_loss = 0.65232769, grad/param norm = 2.3643e-01, time/batch = 15.0502s	
25166/26050 (epoch 48.303), train_loss = 0.75137905, grad/param norm = 2.3001e-01, time/batch = 16.9085s	
25167/26050 (epoch 48.305), train_loss = 0.60983340, grad/param norm = 1.9922e-01, time/batch = 17.8175s	
25168/26050 (epoch 48.307), train_loss = 0.65328598, grad/param norm = 2.0867e-01, time/batch = 17.7295s	
25169/26050 (epoch 48.309), train_loss = 0.79328877, grad/param norm = 2.3901e-01, time/batch = 16.4499s	
25170/26050 (epoch 48.311), train_loss = 0.76392833, grad/param norm = 2.6510e-01, time/batch = 17.1575s	
25171/26050 (epoch 48.313), train_loss = 0.74621217, grad/param norm = 2.5071e-01, time/batch = 15.2277s	
25172/26050 (epoch 48.315), train_loss = 0.80335712, grad/param norm = 2.3897e-01, time/batch = 17.8900s	
25173/26050 (epoch 48.317), train_loss = 0.73198348, grad/param norm = 2.3148e-01, time/batch = 18.0476s	
25174/26050 (epoch 48.319), train_loss = 0.71876808, grad/param norm = 2.2462e-01, time/batch = 18.8946s	
25175/26050 (epoch 48.321), train_loss = 0.76991662, grad/param norm = 2.3322e-01, time/batch = 18.8258s	
25176/26050 (epoch 48.322), train_loss = 0.82132090, grad/param norm = 2.2174e-01, time/batch = 17.9073s	
25177/26050 (epoch 48.324), train_loss = 0.60640654, grad/param norm = 2.1049e-01, time/batch = 17.1490s	
25178/26050 (epoch 48.326), train_loss = 0.87063972, grad/param norm = 2.9182e-01, time/batch = 18.2417s	
25179/26050 (epoch 48.328), train_loss = 0.79486194, grad/param norm = 2.4448e-01, time/batch = 17.4716s	
25180/26050 (epoch 48.330), train_loss = 0.64515964, grad/param norm = 2.5239e-01, time/batch = 15.7200s	
25181/26050 (epoch 48.332), train_loss = 0.81501328, grad/param norm = 2.2980e-01, time/batch = 18.1486s	
25182/26050 (epoch 48.334), train_loss = 0.67256147, grad/param norm = 2.2142e-01, time/batch = 17.3231s	
25183/26050 (epoch 48.336), train_loss = 0.73985410, grad/param norm = 2.2309e-01, time/batch = 18.2301s	
25184/26050 (epoch 48.338), train_loss = 0.65619211, grad/param norm = 1.9629e-01, time/batch = 18.5657s	
25185/26050 (epoch 48.340), train_loss = 0.81272402, grad/param norm = 2.6479e-01, time/batch = 19.1468s	
25186/26050 (epoch 48.342), train_loss = 0.84903678, grad/param norm = 2.3244e-01, time/batch = 17.8911s	
25187/26050 (epoch 48.344), train_loss = 0.70576930, grad/param norm = 2.3226e-01, time/batch = 18.7354s	
25188/26050 (epoch 48.345), train_loss = 0.75262319, grad/param norm = 2.7527e-01, time/batch = 15.0326s	
25189/26050 (epoch 48.347), train_loss = 0.86129133, grad/param norm = 2.3355e-01, time/batch = 14.8878s	
25190/26050 (epoch 48.349), train_loss = 0.79027710, grad/param norm = 2.2947e-01, time/batch = 18.5666s	
25191/26050 (epoch 48.351), train_loss = 0.77411708, grad/param norm = 2.4200e-01, time/batch = 18.4764s	
25192/26050 (epoch 48.353), train_loss = 0.74514271, grad/param norm = 2.8017e-01, time/batch = 18.5605s	
25193/26050 (epoch 48.355), train_loss = 0.78172267, grad/param norm = 4.4463e-01, time/batch = 17.8740s	
25194/26050 (epoch 48.357), train_loss = 0.71044314, grad/param norm = 2.0584e-01, time/batch = 18.2282s	
25195/26050 (epoch 48.359), train_loss = 0.86202311, grad/param norm = 2.7795e-01, time/batch = 18.1526s	
25196/26050 (epoch 48.361), train_loss = 0.67610136, grad/param norm = 1.9156e-01, time/batch = 17.2355s	
25197/26050 (epoch 48.363), train_loss = 0.81463218, grad/param norm = 2.0645e-01, time/batch = 18.6508s	
25198/26050 (epoch 48.365), train_loss = 0.74785154, grad/param norm = 2.2926e-01, time/batch = 18.8128s	
25199/26050 (epoch 48.367), train_loss = 0.80361059, grad/param norm = 2.1338e-01, time/batch = 17.2436s	
25200/26050 (epoch 48.369), train_loss = 0.66464164, grad/param norm = 1.8748e-01, time/batch = 17.9744s	
25201/26050 (epoch 48.370), train_loss = 0.65612667, grad/param norm = 2.1162e-01, time/batch = 18.5662s	
25202/26050 (epoch 48.372), train_loss = 0.74535374, grad/param norm = 2.6945e-01, time/batch = 17.8074s	
25203/26050 (epoch 48.374), train_loss = 0.86774826, grad/param norm = 2.2798e-01, time/batch = 15.3079s	
25204/26050 (epoch 48.376), train_loss = 0.88381012, grad/param norm = 2.8831e-01, time/batch = 18.6056s	
25205/26050 (epoch 48.378), train_loss = 0.73136602, grad/param norm = 2.2165e-01, time/batch = 18.6304s	
25206/26050 (epoch 48.380), train_loss = 0.84807558, grad/param norm = 2.6873e-01, time/batch = 17.5412s	
25207/26050 (epoch 48.382), train_loss = 0.91805049, grad/param norm = 2.9719e-01, time/batch = 18.3107s	
25208/26050 (epoch 48.384), train_loss = 0.72255422, grad/param norm = 2.5310e-01, time/batch = 18.0570s	
25209/26050 (epoch 48.386), train_loss = 0.85385821, grad/param norm = 3.1916e-01, time/batch = 16.3119s	
25210/26050 (epoch 48.388), train_loss = 0.77639735, grad/param norm = 2.5026e-01, time/batch = 17.4653s	
25211/26050 (epoch 48.390), train_loss = 0.70131579, grad/param norm = 2.1010e-01, time/batch = 17.4859s	
25212/26050 (epoch 48.392), train_loss = 0.64086229, grad/param norm = 1.8745e-01, time/batch = 17.6519s	
25213/26050 (epoch 48.393), train_loss = 0.82100889, grad/param norm = 2.3295e-01, time/batch = 18.1492s	
25214/26050 (epoch 48.395), train_loss = 0.81758817, grad/param norm = 2.5144e-01, time/batch = 18.9001s	
25215/26050 (epoch 48.397), train_loss = 0.80351777, grad/param norm = 2.2209e-01, time/batch = 18.5792s	
25216/26050 (epoch 48.399), train_loss = 0.71783306, grad/param norm = 2.7553e-01, time/batch = 17.1392s	
25217/26050 (epoch 48.401), train_loss = 0.76707764, grad/param norm = 2.2180e-01, time/batch = 17.9102s	
25218/26050 (epoch 48.403), train_loss = 0.78628694, grad/param norm = 2.9583e-01, time/batch = 15.9865s	
25219/26050 (epoch 48.405), train_loss = 0.76121574, grad/param norm = 2.2696e-01, time/batch = 17.5416s	
25220/26050 (epoch 48.407), train_loss = 0.88365638, grad/param norm = 2.7091e-01, time/batch = 17.3337s	
25221/26050 (epoch 48.409), train_loss = 0.87162490, grad/param norm = 2.8181e-01, time/batch = 18.0619s	
25222/26050 (epoch 48.411), train_loss = 0.86169484, grad/param norm = 2.5049e-01, time/batch = 17.6632s	
25223/26050 (epoch 48.413), train_loss = 0.94490472, grad/param norm = 2.1909e-01, time/batch = 14.6306s	
25224/26050 (epoch 48.415), train_loss = 0.92769417, grad/param norm = 2.7952e-01, time/batch = 18.5715s	
25225/26050 (epoch 48.417), train_loss = 0.92496528, grad/param norm = 2.7620e-01, time/batch = 18.6481s	
25226/26050 (epoch 48.418), train_loss = 0.81041877, grad/param norm = 2.7485e-01, time/batch = 17.8899s	
25227/26050 (epoch 48.420), train_loss = 0.67256343, grad/param norm = 2.1724e-01, time/batch = 18.2377s	
25228/26050 (epoch 48.422), train_loss = 0.64805635, grad/param norm = 2.0921e-01, time/batch = 17.3719s	
25229/26050 (epoch 48.424), train_loss = 0.87345224, grad/param norm = 3.0352e-01, time/batch = 15.7081s	
25230/26050 (epoch 48.426), train_loss = 0.80621130, grad/param norm = 2.5521e-01, time/batch = 18.3094s	
25231/26050 (epoch 48.428), train_loss = 0.76486239, grad/param norm = 2.5580e-01, time/batch = 18.4834s	
25232/26050 (epoch 48.430), train_loss = 0.92319137, grad/param norm = 2.9416e-01, time/batch = 18.4019s	
25233/26050 (epoch 48.432), train_loss = 0.72355735, grad/param norm = 2.2595e-01, time/batch = 17.0674s	
25234/26050 (epoch 48.434), train_loss = 0.72729084, grad/param norm = 2.3567e-01, time/batch = 18.3223s	
25235/26050 (epoch 48.436), train_loss = 0.83885126, grad/param norm = 2.7005e-01, time/batch = 18.5678s	
25236/26050 (epoch 48.438), train_loss = 0.80344355, grad/param norm = 2.4874e-01, time/batch = 17.6399s	
25237/26050 (epoch 48.440), train_loss = 0.82355260, grad/param norm = 2.3736e-01, time/batch = 17.9636s	
25238/26050 (epoch 48.441), train_loss = 0.79845844, grad/param norm = 2.4604e-01, time/batch = 18.6546s	
25239/26050 (epoch 48.443), train_loss = 0.69397819, grad/param norm = 2.2514e-01, time/batch = 18.0569s	
25240/26050 (epoch 48.445), train_loss = 0.71962991, grad/param norm = 2.6340e-01, time/batch = 14.4755s	
25241/26050 (epoch 48.447), train_loss = 0.88367185, grad/param norm = 2.3099e-01, time/batch = 18.4706s	
25242/26050 (epoch 48.449), train_loss = 0.71542650, grad/param norm = 2.5015e-01, time/batch = 17.3924s	
25243/26050 (epoch 48.451), train_loss = 0.88662452, grad/param norm = 2.3738e-01, time/batch = 17.4610s	
25244/26050 (epoch 48.453), train_loss = 0.74780531, grad/param norm = 2.0127e-01, time/batch = 17.0330s	
25245/26050 (epoch 48.455), train_loss = 0.76872402, grad/param norm = 2.1230e-01, time/batch = 18.1559s	
25246/26050 (epoch 48.457), train_loss = 0.74956092, grad/param norm = 2.2350e-01, time/batch = 17.7292s	
25247/26050 (epoch 48.459), train_loss = 0.82695190, grad/param norm = 2.2200e-01, time/batch = 17.6665s	
25248/26050 (epoch 48.461), train_loss = 0.84070041, grad/param norm = 2.4707e-01, time/batch = 18.7320s	
25249/26050 (epoch 48.463), train_loss = 0.74149777, grad/param norm = 2.2470e-01, time/batch = 18.2395s	
25250/26050 (epoch 48.464), train_loss = 0.79273348, grad/param norm = 2.4492e-01, time/batch = 14.6221s	
25251/26050 (epoch 48.466), train_loss = 0.76001846, grad/param norm = 2.4183e-01, time/batch = 18.2263s	
25252/26050 (epoch 48.468), train_loss = 0.86360624, grad/param norm = 2.1306e-01, time/batch = 16.1249s	
25253/26050 (epoch 48.470), train_loss = 0.84575293, grad/param norm = 2.7604e-01, time/batch = 17.6422s	
25254/26050 (epoch 48.472), train_loss = 0.83886245, grad/param norm = 2.5150e-01, time/batch = 17.8946s	
25255/26050 (epoch 48.474), train_loss = 0.88233274, grad/param norm = 2.8295e-01, time/batch = 16.7176s	
25256/26050 (epoch 48.476), train_loss = 0.84842583, grad/param norm = 2.2170e-01, time/batch = 18.3135s	
25257/26050 (epoch 48.478), train_loss = 0.74696297, grad/param norm = 2.2603e-01, time/batch = 16.3863s	
25258/26050 (epoch 48.480), train_loss = 0.74369922, grad/param norm = 2.0099e-01, time/batch = 18.2270s	
25259/26050 (epoch 48.482), train_loss = 0.74350977, grad/param norm = 2.6134e-01, time/batch = 18.0508s	
25260/26050 (epoch 48.484), train_loss = 0.71114820, grad/param norm = 2.2635e-01, time/batch = 16.2955s	
25261/26050 (epoch 48.486), train_loss = 0.87180706, grad/param norm = 2.2435e-01, time/batch = 18.1428s	
25262/26050 (epoch 48.488), train_loss = 0.91453583, grad/param norm = 2.4505e-01, time/batch = 17.8170s	
25263/26050 (epoch 48.489), train_loss = 0.94097897, grad/param norm = 2.9716e-01, time/batch = 18.3996s	
25264/26050 (epoch 48.491), train_loss = 0.69590243, grad/param norm = 2.1753e-01, time/batch = 17.8236s	
25265/26050 (epoch 48.493), train_loss = 0.78963622, grad/param norm = 2.3025e-01, time/batch = 16.5627s	
25266/26050 (epoch 48.495), train_loss = 0.76562073, grad/param norm = 1.9677e-01, time/batch = 18.1583s	
25267/26050 (epoch 48.497), train_loss = 0.68958722, grad/param norm = 2.1524e-01, time/batch = 15.1312s	
25268/26050 (epoch 48.499), train_loss = 0.70802012, grad/param norm = 2.2340e-01, time/batch = 17.6301s	
25269/26050 (epoch 48.501), train_loss = 0.88118998, grad/param norm = 2.1798e-01, time/batch = 18.1605s	
25270/26050 (epoch 48.503), train_loss = 0.73355801, grad/param norm = 2.1245e-01, time/batch = 17.1507s	
25271/26050 (epoch 48.505), train_loss = 0.86005253, grad/param norm = 2.1980e-01, time/batch = 3.1065s	
25272/26050 (epoch 48.507), train_loss = 0.85205029, grad/param norm = 2.4172e-01, time/batch = 0.6435s	
25273/26050 (epoch 48.509), train_loss = 0.89261936, grad/param norm = 2.2765e-01, time/batch = 0.6436s	
25274/26050 (epoch 48.511), train_loss = 0.77582442, grad/param norm = 1.9742e-01, time/batch = 0.6501s	
25275/26050 (epoch 48.512), train_loss = 0.67645137, grad/param norm = 2.5249e-01, time/batch = 0.6529s	
25276/26050 (epoch 48.514), train_loss = 0.82189513, grad/param norm = 2.4536e-01, time/batch = 0.6424s	
25277/26050 (epoch 48.516), train_loss = 0.91160946, grad/param norm = 2.5104e-01, time/batch = 0.6477s	
25278/26050 (epoch 48.518), train_loss = 0.76938821, grad/param norm = 2.4859e-01, time/batch = 0.6926s	
25279/26050 (epoch 48.520), train_loss = 0.80281705, grad/param norm = 2.5484e-01, time/batch = 0.9438s	
25280/26050 (epoch 48.522), train_loss = 0.61727194, grad/param norm = 2.0846e-01, time/batch = 0.9432s	
25281/26050 (epoch 48.524), train_loss = 0.84971875, grad/param norm = 2.6748e-01, time/batch = 0.9682s	
25282/26050 (epoch 48.526), train_loss = 0.86211454, grad/param norm = 2.2422e-01, time/batch = 0.9883s	
25283/26050 (epoch 48.528), train_loss = 0.80440346, grad/param norm = 2.4442e-01, time/batch = 0.9446s	
25284/26050 (epoch 48.530), train_loss = 0.75901605, grad/param norm = 2.8270e-01, time/batch = 1.7906s	
25285/26050 (epoch 48.532), train_loss = 0.84200268, grad/param norm = 2.1563e-01, time/batch = 1.8519s	
25286/26050 (epoch 48.534), train_loss = 0.79663303, grad/param norm = 2.8700e-01, time/batch = 5.3035s	
25287/26050 (epoch 48.536), train_loss = 0.81035455, grad/param norm = 2.3425e-01, time/batch = 18.6577s	
25288/26050 (epoch 48.537), train_loss = 0.87061505, grad/param norm = 2.3899e-01, time/batch = 17.4037s	
25289/26050 (epoch 48.539), train_loss = 0.82116441, grad/param norm = 2.2512e-01, time/batch = 18.5664s	
25290/26050 (epoch 48.541), train_loss = 0.91759608, grad/param norm = 2.5316e-01, time/batch = 16.2239s	
25291/26050 (epoch 48.543), train_loss = 0.60711520, grad/param norm = 2.0164e-01, time/batch = 18.7266s	
25292/26050 (epoch 48.545), train_loss = 0.76384089, grad/param norm = 2.4482e-01, time/batch = 16.2950s	
25293/26050 (epoch 48.547), train_loss = 0.71729933, grad/param norm = 2.2444e-01, time/batch = 19.0540s	
25294/26050 (epoch 48.549), train_loss = 0.68331731, grad/param norm = 2.3807e-01, time/batch = 18.5001s	
25295/26050 (epoch 48.551), train_loss = 0.83599795, grad/param norm = 2.4659e-01, time/batch = 17.3147s	
25296/26050 (epoch 48.553), train_loss = 0.73582307, grad/param norm = 2.0560e-01, time/batch = 18.0576s	
25297/26050 (epoch 48.555), train_loss = 0.65302303, grad/param norm = 2.1489e-01, time/batch = 18.7247s	
25298/26050 (epoch 48.557), train_loss = 0.79231580, grad/param norm = 2.1031e-01, time/batch = 18.1533s	
25299/26050 (epoch 48.559), train_loss = 0.79281504, grad/param norm = 2.1633e-01, time/batch = 17.7362s	
25300/26050 (epoch 48.560), train_loss = 0.75746613, grad/param norm = 2.4940e-01, time/batch = 14.6437s	
25301/26050 (epoch 48.562), train_loss = 0.78230338, grad/param norm = 2.7358e-01, time/batch = 18.8085s	
25302/26050 (epoch 48.564), train_loss = 0.91730902, grad/param norm = 2.3523e-01, time/batch = 17.4817s	
25303/26050 (epoch 48.566), train_loss = 0.73714399, grad/param norm = 2.3020e-01, time/batch = 18.1328s	
25304/26050 (epoch 48.568), train_loss = 0.80698347, grad/param norm = 2.1954e-01, time/batch = 18.8180s	
25305/26050 (epoch 48.570), train_loss = 0.76317209, grad/param norm = 2.2253e-01, time/batch = 14.6928s	
25306/26050 (epoch 48.572), train_loss = 0.79364605, grad/param norm = 2.6001e-01, time/batch = 18.2268s	
25307/26050 (epoch 48.574), train_loss = 0.80489731, grad/param norm = 2.7107e-01, time/batch = 18.2330s	
25308/26050 (epoch 48.576), train_loss = 0.79931425, grad/param norm = 2.5728e-01, time/batch = 18.4026s	
25309/26050 (epoch 48.578), train_loss = 0.74177207, grad/param norm = 2.5584e-01, time/batch = 17.8214s	
25310/26050 (epoch 48.580), train_loss = 0.70475945, grad/param norm = 2.4210e-01, time/batch = 18.0787s	
25311/26050 (epoch 48.582), train_loss = 0.78885488, grad/param norm = 2.2208e-01, time/batch = 15.7176s	
25312/26050 (epoch 48.583), train_loss = 0.82885361, grad/param norm = 2.4854e-01, time/batch = 17.2996s	
25313/26050 (epoch 48.585), train_loss = 0.69191051, grad/param norm = 2.1605e-01, time/batch = 18.6555s	
25314/26050 (epoch 48.587), train_loss = 0.79437586, grad/param norm = 2.5238e-01, time/batch = 16.9104s	
25315/26050 (epoch 48.589), train_loss = 0.91333565, grad/param norm = 2.3762e-01, time/batch = 17.7545s	
25316/26050 (epoch 48.591), train_loss = 0.81053104, grad/param norm = 2.3791e-01, time/batch = 17.6416s	
25317/26050 (epoch 48.593), train_loss = 0.67145166, grad/param norm = 1.9757e-01, time/batch = 18.3917s	
25318/26050 (epoch 48.595), train_loss = 0.82147690, grad/param norm = 2.5376e-01, time/batch = 15.4860s	
25319/26050 (epoch 48.597), train_loss = 0.81079016, grad/param norm = 2.4844e-01, time/batch = 20.4574s	
25320/26050 (epoch 48.599), train_loss = 0.83679888, grad/param norm = 2.2004e-01, time/batch = 34.1787s	
25321/26050 (epoch 48.601), train_loss = 0.91759326, grad/param norm = 2.2791e-01, time/batch = 18.1757s	
25322/26050 (epoch 48.603), train_loss = 0.83051550, grad/param norm = 2.4839e-01, time/batch = 18.8857s	
25323/26050 (epoch 48.605), train_loss = 0.76924191, grad/param norm = 2.3531e-01, time/batch = 15.3705s	
25324/26050 (epoch 48.607), train_loss = 0.85989685, grad/param norm = 2.6616e-01, time/batch = 17.7174s	
25325/26050 (epoch 48.608), train_loss = 0.73762471, grad/param norm = 2.1296e-01, time/batch = 18.4673s	
25326/26050 (epoch 48.610), train_loss = 0.78347631, grad/param norm = 2.2339e-01, time/batch = 17.9815s	
25327/26050 (epoch 48.612), train_loss = 0.75501950, grad/param norm = 2.2614e-01, time/batch = 18.5748s	
25328/26050 (epoch 48.614), train_loss = 0.79214704, grad/param norm = 2.2897e-01, time/batch = 16.7337s	
25329/26050 (epoch 48.616), train_loss = 0.81273228, grad/param norm = 2.7955e-01, time/batch = 18.4116s	
25330/26050 (epoch 48.618), train_loss = 0.72506973, grad/param norm = 2.4032e-01, time/batch = 14.8182s	
25331/26050 (epoch 48.620), train_loss = 0.83908542, grad/param norm = 2.3062e-01, time/batch = 17.4191s	
25332/26050 (epoch 48.622), train_loss = 0.71460129, grad/param norm = 2.1227e-01, time/batch = 17.2277s	
25333/26050 (epoch 48.624), train_loss = 0.64084798, grad/param norm = 1.9376e-01, time/batch = 18.6342s	
25334/26050 (epoch 48.626), train_loss = 0.81037079, grad/param norm = 2.2055e-01, time/batch = 18.5636s	
25335/26050 (epoch 48.628), train_loss = 0.73996377, grad/param norm = 2.6811e-01, time/batch = 15.4828s	
25336/26050 (epoch 48.630), train_loss = 0.92489784, grad/param norm = 2.1022e-01, time/batch = 17.7230s	
25337/26050 (epoch 48.631), train_loss = 0.89615200, grad/param norm = 2.4445e-01, time/batch = 18.8914s	
25338/26050 (epoch 48.633), train_loss = 0.71918920, grad/param norm = 2.3162e-01, time/batch = 17.4819s	
25339/26050 (epoch 48.635), train_loss = 0.74213296, grad/param norm = 1.9763e-01, time/batch = 18.5736s	
25340/26050 (epoch 48.637), train_loss = 0.69696859, grad/param norm = 2.0864e-01, time/batch = 17.0621s	
25341/26050 (epoch 48.639), train_loss = 0.83216294, grad/param norm = 2.2270e-01, time/batch = 17.4535s	
25342/26050 (epoch 48.641), train_loss = 0.73003228, grad/param norm = 2.2826e-01, time/batch = 15.8790s	
25343/26050 (epoch 48.643), train_loss = 0.72145969, grad/param norm = 1.8554e-01, time/batch = 17.7267s	
25344/26050 (epoch 48.645), train_loss = 0.74393606, grad/param norm = 2.2246e-01, time/batch = 18.6489s	
25345/26050 (epoch 48.647), train_loss = 0.68977254, grad/param norm = 2.6172e-01, time/batch = 17.2236s	
25346/26050 (epoch 48.649), train_loss = 0.74945839, grad/param norm = 2.7218e-01, time/batch = 18.4621s	
25347/26050 (epoch 48.651), train_loss = 0.75850164, grad/param norm = 2.2092e-01, time/batch = 17.8257s	
25348/26050 (epoch 48.653), train_loss = 0.76459067, grad/param norm = 2.4718e-01, time/batch = 18.0849s	
25349/26050 (epoch 48.655), train_loss = 0.70567922, grad/param norm = 2.3910e-01, time/batch = 15.6290s	
25350/26050 (epoch 48.656), train_loss = 0.68724772, grad/param norm = 2.0454e-01, time/batch = 18.8925s	
25351/26050 (epoch 48.658), train_loss = 0.93633401, grad/param norm = 2.5712e-01, time/batch = 18.8134s	
25352/26050 (epoch 48.660), train_loss = 0.65356269, grad/param norm = 2.4724e-01, time/batch = 18.1340s	
25353/26050 (epoch 48.662), train_loss = 0.76558678, grad/param norm = 2.0032e-01, time/batch = 14.8965s	
25354/26050 (epoch 48.664), train_loss = 0.77810887, grad/param norm = 2.1506e-01, time/batch = 17.4829s	
25355/26050 (epoch 48.666), train_loss = 0.73751125, grad/param norm = 2.1529e-01, time/batch = 17.3063s	
25356/26050 (epoch 48.668), train_loss = 0.60512264, grad/param norm = 2.3618e-01, time/batch = 17.0516s	
25357/26050 (epoch 48.670), train_loss = 0.89212141, grad/param norm = 2.6860e-01, time/batch = 18.4998s	
25358/26050 (epoch 48.672), train_loss = 0.75887875, grad/param norm = 2.2300e-01, time/batch = 18.4741s	
25359/26050 (epoch 48.674), train_loss = 0.66946380, grad/param norm = 2.5022e-01, time/batch = 18.4656s	
25360/26050 (epoch 48.676), train_loss = 0.81699880, grad/param norm = 2.4207e-01, time/batch = 17.8152s	
25361/26050 (epoch 48.678), train_loss = 0.84730956, grad/param norm = 2.3388e-01, time/batch = 18.6408s	
25362/26050 (epoch 48.679), train_loss = 0.87774606, grad/param norm = 2.4801e-01, time/batch = 17.6624s	
25363/26050 (epoch 48.681), train_loss = 0.78835557, grad/param norm = 2.3173e-01, time/batch = 18.1544s	
25364/26050 (epoch 48.683), train_loss = 0.68854706, grad/param norm = 2.4162e-01, time/batch = 18.8082s	
25365/26050 (epoch 48.685), train_loss = 0.72643563, grad/param norm = 2.5058e-01, time/batch = 17.7380s	
25366/26050 (epoch 48.687), train_loss = 0.69510228, grad/param norm = 2.3175e-01, time/batch = 14.4812s	
25367/26050 (epoch 48.689), train_loss = 0.72014721, grad/param norm = 2.4295e-01, time/batch = 17.5571s	
25368/26050 (epoch 48.691), train_loss = 0.64226619, grad/param norm = 1.7977e-01, time/batch = 18.2307s	
25369/26050 (epoch 48.693), train_loss = 0.72448291, grad/param norm = 2.9047e-01, time/batch = 16.9787s	
25370/26050 (epoch 48.695), train_loss = 0.76053957, grad/param norm = 2.1479e-01, time/batch = 17.9751s	
25371/26050 (epoch 48.697), train_loss = 0.69616719, grad/param norm = 2.2494e-01, time/batch = 14.8816s	
25372/26050 (epoch 48.699), train_loss = 0.79607085, grad/param norm = 2.3120e-01, time/batch = 17.1395s	
25373/26050 (epoch 48.701), train_loss = 0.68366739, grad/param norm = 1.8572e-01, time/batch = 18.3943s	
25374/26050 (epoch 48.702), train_loss = 0.83822967, grad/param norm = 2.3381e-01, time/batch = 18.1488s	
25375/26050 (epoch 48.704), train_loss = 0.88052841, grad/param norm = 2.1445e-01, time/batch = 18.3314s	
25376/26050 (epoch 48.706), train_loss = 0.72942218, grad/param norm = 2.4532e-01, time/batch = 18.4867s	
25377/26050 (epoch 48.708), train_loss = 0.83659564, grad/param norm = 2.3988e-01, time/batch = 14.9703s	
25378/26050 (epoch 48.710), train_loss = 0.80792295, grad/param norm = 2.9832e-01, time/batch = 18.4852s	
25379/26050 (epoch 48.712), train_loss = 0.77913013, grad/param norm = 2.6387e-01, time/batch = 17.0648s	
25380/26050 (epoch 48.714), train_loss = 0.69433550, grad/param norm = 1.8898e-01, time/batch = 18.2271s	
25381/26050 (epoch 48.716), train_loss = 0.96800287, grad/param norm = 2.6170e-01, time/batch = 18.6395s	
25382/26050 (epoch 48.718), train_loss = 0.82490538, grad/param norm = 2.2727e-01, time/batch = 17.5591s	
25383/26050 (epoch 48.720), train_loss = 0.77688636, grad/param norm = 3.1845e-01, time/batch = 16.8251s	
25384/26050 (epoch 48.722), train_loss = 0.71242424, grad/param norm = 2.3095e-01, time/batch = 17.9759s	
25385/26050 (epoch 48.724), train_loss = 0.72236050, grad/param norm = 2.4511e-01, time/batch = 18.7360s	
25386/26050 (epoch 48.726), train_loss = 0.82954663, grad/param norm = 2.0900e-01, time/batch = 17.9628s	
25387/26050 (epoch 48.727), train_loss = 0.80759766, grad/param norm = 2.3346e-01, time/batch = 18.5586s	
25388/26050 (epoch 48.729), train_loss = 0.82203613, grad/param norm = 2.2393e-01, time/batch = 16.2147s	
25389/26050 (epoch 48.731), train_loss = 0.81068097, grad/param norm = 2.2132e-01, time/batch = 15.2071s	
25390/26050 (epoch 48.733), train_loss = 0.73332382, grad/param norm = 2.4954e-01, time/batch = 17.3979s	
25391/26050 (epoch 48.735), train_loss = 0.87735528, grad/param norm = 2.5253e-01, time/batch = 15.9828s	
25392/26050 (epoch 48.737), train_loss = 0.73572956, grad/param norm = 2.5017e-01, time/batch = 18.5592s	
25393/26050 (epoch 48.739), train_loss = 0.80017050, grad/param norm = 2.3299e-01, time/batch = 18.7133s	
25394/26050 (epoch 48.741), train_loss = 0.70292445, grad/param norm = 2.2093e-01, time/batch = 17.8249s	
25395/26050 (epoch 48.743), train_loss = 0.77918737, grad/param norm = 2.6456e-01, time/batch = 18.2375s	
25396/26050 (epoch 48.745), train_loss = 0.69319660, grad/param norm = 2.0109e-01, time/batch = 14.9597s	
25397/26050 (epoch 48.747), train_loss = 0.73703198, grad/param norm = 2.2810e-01, time/batch = 18.3141s	
25398/26050 (epoch 48.749), train_loss = 0.86773462, grad/param norm = 2.4481e-01, time/batch = 18.7419s	
25399/26050 (epoch 48.750), train_loss = 0.72003792, grad/param norm = 1.9579e-01, time/batch = 17.6593s	
25400/26050 (epoch 48.752), train_loss = 0.71506204, grad/param norm = 2.5037e-01, time/batch = 18.3976s	
25401/26050 (epoch 48.754), train_loss = 0.77877902, grad/param norm = 2.3786e-01, time/batch = 18.6416s	
25402/26050 (epoch 48.756), train_loss = 0.73945698, grad/param norm = 2.5292e-01, time/batch = 18.4606s	
25403/26050 (epoch 48.758), train_loss = 0.76447224, grad/param norm = 2.4011e-01, time/batch = 15.5412s	
25404/26050 (epoch 48.760), train_loss = 0.89185904, grad/param norm = 2.4310e-01, time/batch = 15.7906s	
25405/26050 (epoch 48.762), train_loss = 0.74342051, grad/param norm = 2.1613e-01, time/batch = 16.3109s	
25406/26050 (epoch 48.764), train_loss = 0.74461899, grad/param norm = 2.9154e-01, time/batch = 17.9738s	
25407/26050 (epoch 48.766), train_loss = 0.76107002, grad/param norm = 2.2281e-01, time/batch = 17.8178s	
25408/26050 (epoch 48.768), train_loss = 0.65829621, grad/param norm = 2.1918e-01, time/batch = 16.2329s	
25409/26050 (epoch 48.770), train_loss = 0.76440173, grad/param norm = 2.4598e-01, time/batch = 18.6296s	
25410/26050 (epoch 48.772), train_loss = 0.78682015, grad/param norm = 2.6001e-01, time/batch = 16.9809s	
25411/26050 (epoch 48.774), train_loss = 0.62977302, grad/param norm = 2.1818e-01, time/batch = 18.3108s	
25412/26050 (epoch 48.775), train_loss = 0.55637598, grad/param norm = 2.0523e-01, time/batch = 18.4123s	
25413/26050 (epoch 48.777), train_loss = 0.72765898, grad/param norm = 2.2926e-01, time/batch = 17.2187s	
25414/26050 (epoch 48.779), train_loss = 0.75617323, grad/param norm = 3.4375e-01, time/batch = 18.4052s	
25415/26050 (epoch 48.781), train_loss = 0.69570895, grad/param norm = 2.4121e-01, time/batch = 18.9658s	
25416/26050 (epoch 48.783), train_loss = 0.65798469, grad/param norm = 2.1368e-01, time/batch = 15.1375s	
25417/26050 (epoch 48.785), train_loss = 0.77222304, grad/param norm = 2.5446e-01, time/batch = 18.0588s	
25418/26050 (epoch 48.787), train_loss = 0.66742653, grad/param norm = 2.0695e-01, time/batch = 18.3033s	
25419/26050 (epoch 48.789), train_loss = 0.69577960, grad/param norm = 2.6864e-01, time/batch = 18.5029s	
25420/26050 (epoch 48.791), train_loss = 0.68628185, grad/param norm = 2.8932e-01, time/batch = 17.5607s	
25421/26050 (epoch 48.793), train_loss = 0.76687546, grad/param norm = 2.4347e-01, time/batch = 16.1018s	
25422/26050 (epoch 48.795), train_loss = 0.62687837, grad/param norm = 2.2572e-01, time/batch = 17.9836s	
25423/26050 (epoch 48.797), train_loss = 0.69649256, grad/param norm = 2.4729e-01, time/batch = 14.7993s	
25424/26050 (epoch 48.798), train_loss = 0.78019899, grad/param norm = 2.7284e-01, time/batch = 18.8187s	
25425/26050 (epoch 48.800), train_loss = 0.65896021, grad/param norm = 2.2808e-01, time/batch = 17.7356s	
25426/26050 (epoch 48.802), train_loss = 0.73349681, grad/param norm = 2.2158e-01, time/batch = 18.1558s	
25427/26050 (epoch 48.804), train_loss = 0.75768069, grad/param norm = 2.3709e-01, time/batch = 18.0623s	
25428/26050 (epoch 48.806), train_loss = 0.82285957, grad/param norm = 2.5771e-01, time/batch = 18.4972s	
25429/26050 (epoch 48.808), train_loss = 0.78854006, grad/param norm = 2.5742e-01, time/batch = 18.4718s	
25430/26050 (epoch 48.810), train_loss = 0.78431962, grad/param norm = 2.7373e-01, time/batch = 17.9009s	
25431/26050 (epoch 48.812), train_loss = 0.64029076, grad/param norm = 2.3956e-01, time/batch = 14.8121s	
25432/26050 (epoch 48.814), train_loss = 0.66886436, grad/param norm = 2.7338e-01, time/batch = 18.7357s	
25433/26050 (epoch 48.816), train_loss = 0.78334205, grad/param norm = 2.4269e-01, time/batch = 17.6426s	
25434/26050 (epoch 48.818), train_loss = 0.82327056, grad/param norm = 2.7447e-01, time/batch = 18.0794s	
25435/26050 (epoch 48.820), train_loss = 0.75872146, grad/param norm = 2.3040e-01, time/batch = 18.8090s	
25436/26050 (epoch 48.821), train_loss = 0.84571553, grad/param norm = 2.6544e-01, time/batch = 17.9006s	
25437/26050 (epoch 48.823), train_loss = 0.93477946, grad/param norm = 2.4878e-01, time/batch = 17.8761s	
25438/26050 (epoch 48.825), train_loss = 0.75981401, grad/param norm = 2.2985e-01, time/batch = 18.3937s	
25439/26050 (epoch 48.827), train_loss = 0.75891865, grad/param norm = 2.6720e-01, time/batch = 17.2912s	
25440/26050 (epoch 48.829), train_loss = 0.88353175, grad/param norm = 2.7745e-01, time/batch = 16.9864s	
25441/26050 (epoch 48.831), train_loss = 0.91691597, grad/param norm = 2.8586e-01, time/batch = 18.4148s	
25442/26050 (epoch 48.833), train_loss = 0.82553423, grad/param norm = 2.3953e-01, time/batch = 17.7323s	
25443/26050 (epoch 48.835), train_loss = 0.88274300, grad/param norm = 3.6075e-01, time/batch = 18.3095s	
25444/26050 (epoch 48.837), train_loss = 0.80521773, grad/param norm = 2.5064e-01, time/batch = 14.2313s	
25445/26050 (epoch 48.839), train_loss = 0.76978844, grad/param norm = 3.1599e-01, time/batch = 17.0371s	
25446/26050 (epoch 48.841), train_loss = 0.82007139, grad/param norm = 2.8685e-01, time/batch = 17.3723s	
25447/26050 (epoch 48.843), train_loss = 0.74695441, grad/param norm = 1.9653e-01, time/batch = 17.3965s	
25448/26050 (epoch 48.845), train_loss = 0.75411504, grad/param norm = 2.8339e-01, time/batch = 17.9807s	
25449/26050 (epoch 48.846), train_loss = 0.80724702, grad/param norm = 2.6747e-01, time/batch = 18.6488s	
25450/26050 (epoch 48.848), train_loss = 0.74838172, grad/param norm = 2.3257e-01, time/batch = 18.1557s	
25451/26050 (epoch 48.850), train_loss = 0.66864702, grad/param norm = 1.9107e-01, time/batch = 17.4976s	
25452/26050 (epoch 48.852), train_loss = 0.80051391, grad/param norm = 2.4018e-01, time/batch = 18.1579s	
25453/26050 (epoch 48.854), train_loss = 0.78900809, grad/param norm = 2.6956e-01, time/batch = 18.3878s	
25454/26050 (epoch 48.856), train_loss = 0.72330928, grad/param norm = 2.6853e-01, time/batch = 16.2149s	
25455/26050 (epoch 48.858), train_loss = 0.69541706, grad/param norm = 2.2434e-01, time/batch = 17.0272s	
25456/26050 (epoch 48.860), train_loss = 0.78091065, grad/param norm = 2.7252e-01, time/batch = 18.5611s	
25457/26050 (epoch 48.862), train_loss = 0.84180971, grad/param norm = 2.3368e-01, time/batch = 16.9833s	
25458/26050 (epoch 48.864), train_loss = 0.75848324, grad/param norm = 2.8677e-01, time/batch = 18.2386s	
25459/26050 (epoch 48.866), train_loss = 0.78411175, grad/param norm = 2.1800e-01, time/batch = 17.7337s	
25460/26050 (epoch 48.868), train_loss = 0.83128972, grad/param norm = 2.6173e-01, time/batch = 17.5663s	
25461/26050 (epoch 48.869), train_loss = 0.69856550, grad/param norm = 1.9111e-01, time/batch = 18.8067s	
25462/26050 (epoch 48.871), train_loss = 0.63187006, grad/param norm = 2.1922e-01, time/batch = 17.8968s	
25463/26050 (epoch 48.873), train_loss = 0.82934850, grad/param norm = 2.7275e-01, time/batch = 17.9715s	
25464/26050 (epoch 48.875), train_loss = 0.72400324, grad/param norm = 2.4971e-01, time/batch = 17.4761s	
25465/26050 (epoch 48.877), train_loss = 0.74979715, grad/param norm = 2.4298e-01, time/batch = 15.8761s	
25466/26050 (epoch 48.879), train_loss = 0.85115262, grad/param norm = 2.4291e-01, time/batch = 15.8017s	
25467/26050 (epoch 48.881), train_loss = 0.82876520, grad/param norm = 2.5773e-01, time/batch = 17.8133s	
25468/26050 (epoch 48.883), train_loss = 0.82834252, grad/param norm = 2.1572e-01, time/batch = 18.5643s	
25469/26050 (epoch 48.885), train_loss = 0.60455012, grad/param norm = 1.8721e-01, time/batch = 18.8185s	
25470/26050 (epoch 48.887), train_loss = 0.86708447, grad/param norm = 2.4932e-01, time/batch = 17.7320s	
25471/26050 (epoch 48.889), train_loss = 0.71033824, grad/param norm = 2.0602e-01, time/batch = 18.5597s	
25472/26050 (epoch 48.891), train_loss = 0.63861487, grad/param norm = 2.0779e-01, time/batch = 16.1410s	
25473/26050 (epoch 48.893), train_loss = 0.64131548, grad/param norm = 2.3983e-01, time/batch = 18.6514s	
25474/26050 (epoch 48.894), train_loss = 0.71064757, grad/param norm = 2.2346e-01, time/batch = 17.1474s	
25475/26050 (epoch 48.896), train_loss = 0.83161478, grad/param norm = 2.2610e-01, time/batch = 17.2174s	
25476/26050 (epoch 48.898), train_loss = 0.71265655, grad/param norm = 2.1254e-01, time/batch = 17.3057s	
25477/26050 (epoch 48.900), train_loss = 0.79535205, grad/param norm = 2.5326e-01, time/batch = 18.2269s	
25478/26050 (epoch 48.902), train_loss = 0.72185681, grad/param norm = 2.1487e-01, time/batch = 17.7326s	
25479/26050 (epoch 48.904), train_loss = 0.75409390, grad/param norm = 2.5449e-01, time/batch = 18.4935s	
25480/26050 (epoch 48.906), train_loss = 0.72584851, grad/param norm = 2.9509e-01, time/batch = 18.3089s	
25481/26050 (epoch 48.908), train_loss = 0.80570975, grad/param norm = 2.7180e-01, time/batch = 17.7269s	
25482/26050 (epoch 48.910), train_loss = 0.70308631, grad/param norm = 2.1541e-01, time/batch = 16.5359s	
25483/26050 (epoch 48.912), train_loss = 0.90997356, grad/param norm = 2.5035e-01, time/batch = 17.4058s	
25484/26050 (epoch 48.914), train_loss = 1.03907193, grad/param norm = 2.6156e-01, time/batch = 14.6253s	
25485/26050 (epoch 48.916), train_loss = 0.82982424, grad/param norm = 2.9853e-01, time/batch = 17.9873s	
25486/26050 (epoch 48.917), train_loss = 0.79116940, grad/param norm = 2.3173e-01, time/batch = 18.2820s	
25487/26050 (epoch 48.919), train_loss = 0.80579549, grad/param norm = 2.6442e-01, time/batch = 17.4788s	
25488/26050 (epoch 48.921), train_loss = 0.71457423, grad/param norm = 2.5928e-01, time/batch = 18.1322s	
25489/26050 (epoch 48.923), train_loss = 0.78826999, grad/param norm = 2.3816e-01, time/batch = 18.1516s	
25490/26050 (epoch 48.925), train_loss = 0.77485016, grad/param norm = 2.2948e-01, time/batch = 18.5651s	
25491/26050 (epoch 48.927), train_loss = 0.71522899, grad/param norm = 1.8232e-01, time/batch = 17.3897s	
25492/26050 (epoch 48.929), train_loss = 0.66056762, grad/param norm = 2.2163e-01, time/batch = 18.4879s	
25493/26050 (epoch 48.931), train_loss = 0.90870512, grad/param norm = 3.0713e-01, time/batch = 16.6447s	
25494/26050 (epoch 48.933), train_loss = 0.76666807, grad/param norm = 2.3138e-01, time/batch = 16.6539s	
25495/26050 (epoch 48.935), train_loss = 0.73186201, grad/param norm = 2.1493e-01, time/batch = 16.9570s	
25496/26050 (epoch 48.937), train_loss = 0.84681415, grad/param norm = 2.3438e-01, time/batch = 18.3214s	
25497/26050 (epoch 48.939), train_loss = 0.69660638, grad/param norm = 1.8149e-01, time/batch = 18.0716s	
25498/26050 (epoch 48.940), train_loss = 0.77727789, grad/param norm = 2.1975e-01, time/batch = 18.1387s	
25499/26050 (epoch 48.942), train_loss = 0.68509751, grad/param norm = 2.1892e-01, time/batch = 14.6397s	
25500/26050 (epoch 48.944), train_loss = 0.74087393, grad/param norm = 2.1939e-01, time/batch = 14.9683s	
25501/26050 (epoch 48.946), train_loss = 0.90927273, grad/param norm = 2.3460e-01, time/batch = 17.9761s	
25502/26050 (epoch 48.948), train_loss = 0.65643679, grad/param norm = 2.2878e-01, time/batch = 18.3177s	
25503/26050 (epoch 48.950), train_loss = 0.80412691, grad/param norm = 2.7898e-01, time/batch = 18.8175s	
25504/26050 (epoch 48.952), train_loss = 0.80594326, grad/param norm = 2.4552e-01, time/batch = 17.8848s	
25505/26050 (epoch 48.954), train_loss = 0.82522857, grad/param norm = 2.7144e-01, time/batch = 17.8941s	
25506/26050 (epoch 48.956), train_loss = 0.70871946, grad/param norm = 2.1205e-01, time/batch = 18.2395s	
25507/26050 (epoch 48.958), train_loss = 0.69608010, grad/param norm = 2.1389e-01, time/batch = 15.5647s	
25508/26050 (epoch 48.960), train_loss = 0.79414273, grad/param norm = 2.5248e-01, time/batch = 17.0509s	
25509/26050 (epoch 48.962), train_loss = 0.77231057, grad/param norm = 2.1937e-01, time/batch = 18.8918s	
25510/26050 (epoch 48.964), train_loss = 0.71363043, grad/param norm = 2.1828e-01, time/batch = 18.8957s	
25511/26050 (epoch 48.965), train_loss = 0.67028082, grad/param norm = 2.2527e-01, time/batch = 15.2901s	
25512/26050 (epoch 48.967), train_loss = 0.97779127, grad/param norm = 2.2957e-01, time/batch = 17.7342s	
25513/26050 (epoch 48.969), train_loss = 0.76664791, grad/param norm = 2.1289e-01, time/batch = 18.3925s	
25514/26050 (epoch 48.971), train_loss = 0.77721093, grad/param norm = 2.3604e-01, time/batch = 18.1446s	
25515/26050 (epoch 48.973), train_loss = 0.78172504, grad/param norm = 2.3118e-01, time/batch = 15.6284s	
25516/26050 (epoch 48.975), train_loss = 0.76805982, grad/param norm = 2.2236e-01, time/batch = 17.3901s	
25517/26050 (epoch 48.977), train_loss = 0.75146588, grad/param norm = 2.0670e-01, time/batch = 15.3041s	
25518/26050 (epoch 48.979), train_loss = 0.61592667, grad/param norm = 1.8946e-01, time/batch = 18.0670s	
25519/26050 (epoch 48.981), train_loss = 0.83165701, grad/param norm = 2.0615e-01, time/batch = 17.1346s	
25520/26050 (epoch 48.983), train_loss = 0.77885996, grad/param norm = 2.3076e-01, time/batch = 18.8825s	
25521/26050 (epoch 48.985), train_loss = 0.77930092, grad/param norm = 2.5582e-01, time/batch = 18.4130s	
25522/26050 (epoch 48.987), train_loss = 0.86636038, grad/param norm = 2.4424e-01, time/batch = 28.6895s	
25523/26050 (epoch 48.988), train_loss = 0.80102075, grad/param norm = 2.6320e-01, time/batch = 28.0655s	
25524/26050 (epoch 48.990), train_loss = 0.66094487, grad/param norm = 2.0714e-01, time/batch = 16.5380s	
25525/26050 (epoch 48.992), train_loss = 0.87397192, grad/param norm = 2.6342e-01, time/batch = 16.3785s	
25526/26050 (epoch 48.994), train_loss = 0.70172163, grad/param norm = 2.2882e-01, time/batch = 18.5807s	
25527/26050 (epoch 48.996), train_loss = 0.67822496, grad/param norm = 3.5411e-01, time/batch = 17.7971s	
25528/26050 (epoch 48.998), train_loss = 0.77682654, grad/param norm = 2.5418e-01, time/batch = 18.5634s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
25529/26050 (epoch 49.000), train_loss = 0.70038331, grad/param norm = 2.6427e-01, time/batch = 16.6345s	
25530/26050 (epoch 49.002), train_loss = 0.83767459, grad/param norm = 2.5685e-01, time/batch = 17.5469s	
25531/26050 (epoch 49.004), train_loss = 0.66740213, grad/param norm = 2.3563e-01, time/batch = 18.4758s	
25532/26050 (epoch 49.006), train_loss = 0.71239528, grad/param norm = 2.3322e-01, time/batch = 18.0676s	
25533/26050 (epoch 49.008), train_loss = 0.70483686, grad/param norm = 2.4411e-01, time/batch = 15.3140s	
25534/26050 (epoch 49.010), train_loss = 0.69148036, grad/param norm = 2.3849e-01, time/batch = 16.8102s	
25535/26050 (epoch 49.012), train_loss = 0.75408299, grad/param norm = 2.4687e-01, time/batch = 14.8942s	
25536/26050 (epoch 49.013), train_loss = 0.99256061, grad/param norm = 2.9690e-01, time/batch = 17.8944s	
25537/26050 (epoch 49.015), train_loss = 0.75233960, grad/param norm = 2.1057e-01, time/batch = 18.1593s	
25538/26050 (epoch 49.017), train_loss = 0.79359377, grad/param norm = 2.0662e-01, time/batch = 17.6271s	
25539/26050 (epoch 49.019), train_loss = 0.66621172, grad/param norm = 1.8660e-01, time/batch = 18.0754s	
25540/26050 (epoch 49.021), train_loss = 0.81693324, grad/param norm = 2.2724e-01, time/batch = 18.0791s	
25541/26050 (epoch 49.023), train_loss = 0.63702333, grad/param norm = 2.3383e-01, time/batch = 17.3041s	
25542/26050 (epoch 49.025), train_loss = 0.76318916, grad/param norm = 2.2311e-01, time/batch = 18.1587s	
25543/26050 (epoch 49.027), train_loss = 0.59912339, grad/param norm = 2.0269e-01, time/batch = 16.8793s	
25544/26050 (epoch 49.029), train_loss = 0.82633290, grad/param norm = 2.1333e-01, time/batch = 17.7384s	
25545/26050 (epoch 49.031), train_loss = 0.86780060, grad/param norm = 2.6032e-01, time/batch = 16.8836s	
25546/26050 (epoch 49.033), train_loss = 0.74154554, grad/param norm = 2.1326e-01, time/batch = 16.4728s	
25547/26050 (epoch 49.035), train_loss = 0.80555916, grad/param norm = 2.0465e-01, time/batch = 16.8184s	
25548/26050 (epoch 49.036), train_loss = 0.67595346, grad/param norm = 2.4568e-01, time/batch = 16.7154s	
25549/26050 (epoch 49.038), train_loss = 0.60505831, grad/param norm = 1.8903e-01, time/batch = 18.2452s	
25550/26050 (epoch 49.040), train_loss = 0.74360979, grad/param norm = 2.0788e-01, time/batch = 18.9933s	
25551/26050 (epoch 49.042), train_loss = 0.65482950, grad/param norm = 2.5015e-01, time/batch = 17.3963s	
25552/26050 (epoch 49.044), train_loss = 0.82423439, grad/param norm = 2.3006e-01, time/batch = 17.8995s	
25553/26050 (epoch 49.046), train_loss = 0.64600755, grad/param norm = 1.7951e-01, time/batch = 17.4170s	
25554/26050 (epoch 49.048), train_loss = 0.76666092, grad/param norm = 2.3089e-01, time/batch = 18.1550s	
25555/26050 (epoch 49.050), train_loss = 0.73536839, grad/param norm = 2.1636e-01, time/batch = 18.3007s	
25556/26050 (epoch 49.052), train_loss = 0.71236704, grad/param norm = 2.3504e-01, time/batch = 18.6499s	
25557/26050 (epoch 49.054), train_loss = 0.64288850, grad/param norm = 2.1413e-01, time/batch = 18.7312s	
25558/26050 (epoch 49.056), train_loss = 0.64563676, grad/param norm = 1.7124e-01, time/batch = 16.2071s	
25559/26050 (epoch 49.058), train_loss = 0.73403515, grad/param norm = 2.2358e-01, time/batch = 18.1580s	
25560/26050 (epoch 49.060), train_loss = 0.81122724, grad/param norm = 2.2811e-01, time/batch = 18.8165s	
25561/26050 (epoch 49.061), train_loss = 0.64955611, grad/param norm = 2.1671e-01, time/batch = 15.8762s	
25562/26050 (epoch 49.063), train_loss = 0.73751979, grad/param norm = 2.0698e-01, time/batch = 18.9748s	
25563/26050 (epoch 49.065), train_loss = 0.61888509, grad/param norm = 1.6382e-01, time/batch = 14.3990s	
25564/26050 (epoch 49.067), train_loss = 0.74874524, grad/param norm = 2.5598e-01, time/batch = 14.5960s	
25565/26050 (epoch 49.069), train_loss = 0.78068671, grad/param norm = 2.2968e-01, time/batch = 14.3721s	
25566/26050 (epoch 49.071), train_loss = 0.75321693, grad/param norm = 2.7027e-01, time/batch = 15.8045s	
25567/26050 (epoch 49.073), train_loss = 0.90869628, grad/param norm = 2.2149e-01, time/batch = 14.2075s	
25568/26050 (epoch 49.075), train_loss = 0.71736866, grad/param norm = 2.2124e-01, time/batch = 14.9630s	
25569/26050 (epoch 49.077), train_loss = 0.73134064, grad/param norm = 2.4787e-01, time/batch = 15.9642s	
25570/26050 (epoch 49.079), train_loss = 0.73677165, grad/param norm = 2.3703e-01, time/batch = 18.0579s	
25571/26050 (epoch 49.081), train_loss = 0.72974275, grad/param norm = 2.4502e-01, time/batch = 18.0826s	
25572/26050 (epoch 49.083), train_loss = 0.84555561, grad/param norm = 2.2168e-01, time/batch = 17.4053s	
25573/26050 (epoch 49.084), train_loss = 0.78558750, grad/param norm = 3.3614e-01, time/batch = 17.7229s	
25574/26050 (epoch 49.086), train_loss = 0.87928400, grad/param norm = 2.6205e-01, time/batch = 17.5472s	
25575/26050 (epoch 49.088), train_loss = 0.76204703, grad/param norm = 2.2407e-01, time/batch = 17.3171s	
25576/26050 (epoch 49.090), train_loss = 0.78446233, grad/param norm = 2.4065e-01, time/batch = 15.7820s	
25577/26050 (epoch 49.092), train_loss = 0.80948379, grad/param norm = 2.0963e-01, time/batch = 16.7965s	
25578/26050 (epoch 49.094), train_loss = 0.64285999, grad/param norm = 2.3148e-01, time/batch = 17.4516s	
25579/26050 (epoch 49.096), train_loss = 0.78212229, grad/param norm = 2.1974e-01, time/batch = 17.4044s	
25580/26050 (epoch 49.098), train_loss = 0.76481983, grad/param norm = 2.3002e-01, time/batch = 18.6482s	
25581/26050 (epoch 49.100), train_loss = 0.67260513, grad/param norm = 2.4017e-01, time/batch = 18.1648s	
25582/26050 (epoch 49.102), train_loss = 0.76434196, grad/param norm = 2.4855e-01, time/batch = 18.6509s	
25583/26050 (epoch 49.104), train_loss = 0.72746740, grad/param norm = 2.3191e-01, time/batch = 18.4575s	
25584/26050 (epoch 49.106), train_loss = 0.79184579, grad/param norm = 2.5688e-01, time/batch = 18.2275s	
25585/26050 (epoch 49.107), train_loss = 0.64179821, grad/param norm = 2.1169e-01, time/batch = 17.9024s	
25586/26050 (epoch 49.109), train_loss = 0.70942508, grad/param norm = 2.3712e-01, time/batch = 17.1475s	
25587/26050 (epoch 49.111), train_loss = 0.88356766, grad/param norm = 2.7448e-01, time/batch = 17.6568s	
25588/26050 (epoch 49.113), train_loss = 0.74887060, grad/param norm = 2.2684e-01, time/batch = 16.8025s	
25589/26050 (epoch 49.115), train_loss = 0.81824420, grad/param norm = 2.1766e-01, time/batch = 17.4726s	
25590/26050 (epoch 49.117), train_loss = 0.78812201, grad/param norm = 2.6654e-01, time/batch = 15.5519s	
25591/26050 (epoch 49.119), train_loss = 0.65117984, grad/param norm = 1.8493e-01, time/batch = 19.0695s	
25592/26050 (epoch 49.121), train_loss = 0.75128458, grad/param norm = 2.0959e-01, time/batch = 17.7423s	
25593/26050 (epoch 49.123), train_loss = 0.70160382, grad/param norm = 2.4108e-01, time/batch = 17.3069s	
25594/26050 (epoch 49.125), train_loss = 0.64597116, grad/param norm = 2.1720e-01, time/batch = 17.4794s	
25595/26050 (epoch 49.127), train_loss = 0.63699774, grad/param norm = 2.0411e-01, time/batch = 15.1472s	
25596/26050 (epoch 49.129), train_loss = 0.57656841, grad/param norm = 2.0018e-01, time/batch = 18.1449s	
25597/26050 (epoch 49.131), train_loss = 0.74520423, grad/param norm = 2.3193e-01, time/batch = 18.1392s	
25598/26050 (epoch 49.132), train_loss = 0.78203221, grad/param norm = 2.3573e-01, time/batch = 17.0769s	
25599/26050 (epoch 49.134), train_loss = 0.76683599, grad/param norm = 2.6441e-01, time/batch = 17.5489s	
25600/26050 (epoch 49.136), train_loss = 0.71460061, grad/param norm = 2.2416e-01, time/batch = 18.7330s	
25601/26050 (epoch 49.138), train_loss = 0.54152526, grad/param norm = 2.2858e-01, time/batch = 18.6369s	
25602/26050 (epoch 49.140), train_loss = 0.60334409, grad/param norm = 1.9484e-01, time/batch = 17.6226s	
25603/26050 (epoch 49.142), train_loss = 0.62819972, grad/param norm = 2.1857e-01, time/batch = 17.3901s	
25604/26050 (epoch 49.144), train_loss = 0.60957917, grad/param norm = 2.5713e-01, time/batch = 18.4875s	
25605/26050 (epoch 49.146), train_loss = 0.55564838, grad/param norm = 1.9289e-01, time/batch = 18.3332s	
25606/26050 (epoch 49.148), train_loss = 0.59603779, grad/param norm = 1.7896e-01, time/batch = 19.0875s	
25607/26050 (epoch 49.150), train_loss = 0.66724904, grad/param norm = 2.3165e-01, time/batch = 18.4513s	
25608/26050 (epoch 49.152), train_loss = 0.80960440, grad/param norm = 2.7935e-01, time/batch = 22.7726s	
25609/26050 (epoch 49.154), train_loss = 0.58759544, grad/param norm = 2.4522e-01, time/batch = 20.5433s	
25610/26050 (epoch 49.155), train_loss = 0.63550616, grad/param norm = 2.1428e-01, time/batch = 24.1968s	
25611/26050 (epoch 49.157), train_loss = 0.69715161, grad/param norm = 2.4587e-01, time/batch = 23.3091s	
25612/26050 (epoch 49.159), train_loss = 0.75676488, grad/param norm = 2.4626e-01, time/batch = 23.3031s	
25613/26050 (epoch 49.161), train_loss = 0.72648544, grad/param norm = 2.6071e-01, time/batch = 23.0614s	
25614/26050 (epoch 49.163), train_loss = 0.62368257, grad/param norm = 2.2591e-01, time/batch = 21.7512s	
25615/26050 (epoch 49.165), train_loss = 0.56192573, grad/param norm = 1.8914e-01, time/batch = 20.2874s	
25616/26050 (epoch 49.167), train_loss = 0.85864273, grad/param norm = 2.6772e-01, time/batch = 23.7374s	
25617/26050 (epoch 49.169), train_loss = 0.72944852, grad/param norm = 2.2977e-01, time/batch = 20.8612s	
25618/26050 (epoch 49.171), train_loss = 0.67682225, grad/param norm = 1.9390e-01, time/batch = 22.7300s	
25619/26050 (epoch 49.173), train_loss = 0.70395823, grad/param norm = 2.2767e-01, time/batch = 22.8018s	
25620/26050 (epoch 49.175), train_loss = 0.72352075, grad/param norm = 2.3913e-01, time/batch = 22.2672s	
25621/26050 (epoch 49.177), train_loss = 0.78735746, grad/param norm = 2.2764e-01, time/batch = 21.6665s	
25622/26050 (epoch 49.179), train_loss = 0.56184298, grad/param norm = 1.9435e-01, time/batch = 21.0594s	
25623/26050 (epoch 49.180), train_loss = 0.94846272, grad/param norm = 2.3201e-01, time/batch = 23.8861s	
25624/26050 (epoch 49.182), train_loss = 0.86827566, grad/param norm = 2.5091e-01, time/batch = 26.2592s	
25625/26050 (epoch 49.184), train_loss = 0.75375719, grad/param norm = 2.1035e-01, time/batch = 17.1552s	
25626/26050 (epoch 49.186), train_loss = 0.67294312, grad/param norm = 2.6476e-01, time/batch = 18.8885s	
25627/26050 (epoch 49.188), train_loss = 0.79429912, grad/param norm = 2.4090e-01, time/batch = 17.9899s	
25628/26050 (epoch 49.190), train_loss = 0.79470296, grad/param norm = 2.5166e-01, time/batch = 17.4863s	
25629/26050 (epoch 49.192), train_loss = 0.83782778, grad/param norm = 2.2697e-01, time/batch = 14.9623s	
25630/26050 (epoch 49.194), train_loss = 0.75343106, grad/param norm = 2.0766e-01, time/batch = 18.3092s	
25631/26050 (epoch 49.196), train_loss = 0.80539251, grad/param norm = 2.2731e-01, time/batch = 19.1610s	
25632/26050 (epoch 49.198), train_loss = 0.68137689, grad/param norm = 1.9161e-01, time/batch = 17.7240s	
25633/26050 (epoch 49.200), train_loss = 0.68236986, grad/param norm = 2.3327e-01, time/batch = 15.9810s	
25634/26050 (epoch 49.202), train_loss = 0.75015803, grad/param norm = 2.0209e-01, time/batch = 18.5466s	
25635/26050 (epoch 49.203), train_loss = 0.85985257, grad/param norm = 2.2906e-01, time/batch = 17.3064s	
25636/26050 (epoch 49.205), train_loss = 0.70654797, grad/param norm = 2.3169e-01, time/batch = 18.4081s	
25637/26050 (epoch 49.207), train_loss = 0.66886044, grad/param norm = 2.0262e-01, time/batch = 17.9862s	
25638/26050 (epoch 49.209), train_loss = 0.82910115, grad/param norm = 2.1638e-01, time/batch = 17.8158s	
25639/26050 (epoch 49.211), train_loss = 0.64764182, grad/param norm = 1.8830e-01, time/batch = 18.0714s	
25640/26050 (epoch 49.213), train_loss = 0.74565730, grad/param norm = 2.1118e-01, time/batch = 15.1413s	
25641/26050 (epoch 49.215), train_loss = 0.72874264, grad/param norm = 2.4000e-01, time/batch = 17.8001s	
25642/26050 (epoch 49.217), train_loss = 0.71516613, grad/param norm = 1.9052e-01, time/batch = 14.3622s	
25643/26050 (epoch 49.219), train_loss = 0.69156412, grad/param norm = 2.0871e-01, time/batch = 18.6344s	
25644/26050 (epoch 49.221), train_loss = 0.65554186, grad/param norm = 2.3031e-01, time/batch = 18.1556s	
25645/26050 (epoch 49.223), train_loss = 0.80639724, grad/param norm = 2.3413e-01, time/batch = 17.6484s	
25646/26050 (epoch 49.225), train_loss = 0.66720184, grad/param norm = 2.2188e-01, time/batch = 18.3025s	
25647/26050 (epoch 49.226), train_loss = 0.75869432, grad/param norm = 2.6478e-01, time/batch = 18.2343s	
25648/26050 (epoch 49.228), train_loss = 0.83234785, grad/param norm = 2.3910e-01, time/batch = 18.8256s	
25649/26050 (epoch 49.230), train_loss = 0.74704534, grad/param norm = 1.9331e-01, time/batch = 17.4779s	
25650/26050 (epoch 49.232), train_loss = 0.84205855, grad/param norm = 2.6950e-01, time/batch = 18.2275s	
25651/26050 (epoch 49.234), train_loss = 0.65212968, grad/param norm = 2.4057e-01, time/batch = 17.8066s	
25652/26050 (epoch 49.236), train_loss = 0.77745270, grad/param norm = 2.2619e-01, time/batch = 15.3862s	
25653/26050 (epoch 49.238), train_loss = 0.65662731, grad/param norm = 1.9592e-01, time/batch = 18.3238s	
25654/26050 (epoch 49.240), train_loss = 0.75386153, grad/param norm = 2.7528e-01, time/batch = 17.6524s	
25655/26050 (epoch 49.242), train_loss = 0.71552886, grad/param norm = 2.2417e-01, time/batch = 17.1201s	
25656/26050 (epoch 49.244), train_loss = 0.77655855, grad/param norm = 2.5022e-01, time/batch = 17.8062s	
25657/26050 (epoch 49.246), train_loss = 0.71774898, grad/param norm = 2.1484e-01, time/batch = 14.9686s	
25658/26050 (epoch 49.248), train_loss = 0.75906708, grad/param norm = 2.2729e-01, time/batch = 18.7240s	
25659/26050 (epoch 49.250), train_loss = 0.74756490, grad/param norm = 2.2308e-01, time/batch = 15.9033s	
25660/26050 (epoch 49.251), train_loss = 0.71487907, grad/param norm = 2.1514e-01, time/batch = 18.0558s	
25661/26050 (epoch 49.253), train_loss = 0.62250664, grad/param norm = 1.7845e-01, time/batch = 16.8028s	
25662/26050 (epoch 49.255), train_loss = 0.87937721, grad/param norm = 2.7232e-01, time/batch = 16.4541s	
25663/26050 (epoch 49.257), train_loss = 0.76753173, grad/param norm = 2.4104e-01, time/batch = 18.0668s	
25664/26050 (epoch 49.259), train_loss = 0.82513385, grad/param norm = 2.2289e-01, time/batch = 18.3290s	
25665/26050 (epoch 49.261), train_loss = 0.68136598, grad/param norm = 2.6511e-01, time/batch = 18.5600s	
25666/26050 (epoch 49.263), train_loss = 0.82211366, grad/param norm = 2.6063e-01, time/batch = 17.3177s	
25667/26050 (epoch 49.265), train_loss = 0.85077566, grad/param norm = 2.5837e-01, time/batch = 17.7414s	
25668/26050 (epoch 49.267), train_loss = 0.87348320, grad/param norm = 2.2375e-01, time/batch = 18.8281s	
25669/26050 (epoch 49.269), train_loss = 0.83654970, grad/param norm = 2.4092e-01, time/batch = 18.3895s	
25670/26050 (epoch 49.271), train_loss = 0.73634489, grad/param norm = 2.1569e-01, time/batch = 18.2273s	
25671/26050 (epoch 49.273), train_loss = 0.67478778, grad/param norm = 2.5679e-01, time/batch = 18.0527s	
25672/26050 (epoch 49.274), train_loss = 0.71855623, grad/param norm = 2.1369e-01, time/batch = 16.2968s	
25673/26050 (epoch 49.276), train_loss = 0.71937702, grad/param norm = 2.3775e-01, time/batch = 16.7718s	
25674/26050 (epoch 49.278), train_loss = 0.82589625, grad/param norm = 2.2068e-01, time/batch = 18.1558s	
25675/26050 (epoch 49.280), train_loss = 0.72129014, grad/param norm = 2.0657e-01, time/batch = 15.1365s	
25676/26050 (epoch 49.282), train_loss = 0.82520974, grad/param norm = 2.2517e-01, time/batch = 17.0551s	
25677/26050 (epoch 49.284), train_loss = 0.74966689, grad/param norm = 2.6218e-01, time/batch = 18.4855s	
25678/26050 (epoch 49.286), train_loss = 0.79611524, grad/param norm = 2.3345e-01, time/batch = 16.6355s	
25679/26050 (epoch 49.288), train_loss = 0.65950370, grad/param norm = 2.1025e-01, time/batch = 18.0609s	
25680/26050 (epoch 49.290), train_loss = 0.74979817, grad/param norm = 2.6409e-01, time/batch = 16.3152s	
25681/26050 (epoch 49.292), train_loss = 0.70338874, grad/param norm = 2.3279e-01, time/batch = 17.3894s	
25682/26050 (epoch 49.294), train_loss = 0.77211523, grad/param norm = 2.5787e-01, time/batch = 18.8946s	
25683/26050 (epoch 49.296), train_loss = 0.82679774, grad/param norm = 2.3252e-01, time/batch = 16.7343s	
25684/26050 (epoch 49.298), train_loss = 0.81755235, grad/param norm = 2.1381e-01, time/batch = 17.7435s	
25685/26050 (epoch 49.299), train_loss = 0.64603815, grad/param norm = 1.9714e-01, time/batch = 15.6450s	
25686/26050 (epoch 49.301), train_loss = 0.64191483, grad/param norm = 2.0448e-01, time/batch = 16.7190s	
25687/26050 (epoch 49.303), train_loss = 0.74428302, grad/param norm = 2.6387e-01, time/batch = 17.8141s	
25688/26050 (epoch 49.305), train_loss = 0.60396678, grad/param norm = 2.1160e-01, time/batch = 18.7365s	
25689/26050 (epoch 49.307), train_loss = 0.67095282, grad/param norm = 2.5971e-01, time/batch = 17.8173s	
25690/26050 (epoch 49.309), train_loss = 0.78581465, grad/param norm = 2.2108e-01, time/batch = 16.6542s	
25691/26050 (epoch 49.311), train_loss = 0.74891089, grad/param norm = 3.0949e-01, time/batch = 17.5686s	
25692/26050 (epoch 49.313), train_loss = 0.73816981, grad/param norm = 2.6711e-01, time/batch = 15.3958s	
25693/26050 (epoch 49.315), train_loss = 0.79688095, grad/param norm = 2.2676e-01, time/batch = 18.4039s	
25694/26050 (epoch 49.317), train_loss = 0.73937504, grad/param norm = 2.2199e-01, time/batch = 17.5670s	
25695/26050 (epoch 49.319), train_loss = 0.71013117, grad/param norm = 2.3519e-01, time/batch = 18.4158s	
25696/26050 (epoch 49.321), train_loss = 0.75483823, grad/param norm = 2.3409e-01, time/batch = 16.8991s	
25697/26050 (epoch 49.322), train_loss = 0.81776235, grad/param norm = 2.3130e-01, time/batch = 17.6007s	
25698/26050 (epoch 49.324), train_loss = 0.60404680, grad/param norm = 2.1530e-01, time/batch = 18.2413s	
25699/26050 (epoch 49.326), train_loss = 0.88321454, grad/param norm = 3.1385e-01, time/batch = 17.6356s	
25700/26050 (epoch 49.328), train_loss = 0.79561108, grad/param norm = 2.5759e-01, time/batch = 16.0484s	
25701/26050 (epoch 49.330), train_loss = 0.64582220, grad/param norm = 2.1563e-01, time/batch = 18.6417s	
25702/26050 (epoch 49.332), train_loss = 0.79902113, grad/param norm = 2.3116e-01, time/batch = 18.5701s	
25703/26050 (epoch 49.334), train_loss = 0.68085233, grad/param norm = 2.6228e-01, time/batch = 17.8105s	
25704/26050 (epoch 49.336), train_loss = 0.75516142, grad/param norm = 2.4453e-01, time/batch = 17.7458s	
25705/26050 (epoch 49.338), train_loss = 0.66132421, grad/param norm = 1.9790e-01, time/batch = 17.7323s	
25706/26050 (epoch 49.340), train_loss = 0.79086532, grad/param norm = 2.2961e-01, time/batch = 18.4496s	
25707/26050 (epoch 49.342), train_loss = 0.84308419, grad/param norm = 2.3297e-01, time/batch = 16.8168s	
25708/26050 (epoch 49.344), train_loss = 0.68738039, grad/param norm = 2.3579e-01, time/batch = 14.8353s	
25709/26050 (epoch 49.345), train_loss = 0.74377011, grad/param norm = 2.5771e-01, time/batch = 17.2227s	
25710/26050 (epoch 49.347), train_loss = 0.85135804, grad/param norm = 2.2657e-01, time/batch = 14.5773s	
25711/26050 (epoch 49.349), train_loss = 0.78593434, grad/param norm = 2.2419e-01, time/batch = 15.4507s	
25712/26050 (epoch 49.351), train_loss = 0.76130288, grad/param norm = 2.4172e-01, time/batch = 14.5376s	
25713/26050 (epoch 49.353), train_loss = 0.73147705, grad/param norm = 2.2393e-01, time/batch = 14.0651s	
25714/26050 (epoch 49.355), train_loss = 0.75555071, grad/param norm = 2.6148e-01, time/batch = 15.2224s	
25715/26050 (epoch 49.357), train_loss = 0.69786866, grad/param norm = 1.9072e-01, time/batch = 16.5798s	
25716/26050 (epoch 49.359), train_loss = 0.84773320, grad/param norm = 2.4479e-01, time/batch = 17.9782s	
25717/26050 (epoch 49.361), train_loss = 0.67793075, grad/param norm = 2.0924e-01, time/batch = 16.5454s	
25718/26050 (epoch 49.363), train_loss = 0.81755774, grad/param norm = 2.1998e-01, time/batch = 17.8165s	
25719/26050 (epoch 49.365), train_loss = 0.73140031, grad/param norm = 2.1859e-01, time/batch = 16.2345s	
25720/26050 (epoch 49.367), train_loss = 0.79562294, grad/param norm = 2.3789e-01, time/batch = 18.3136s	
25721/26050 (epoch 49.369), train_loss = 0.65294198, grad/param norm = 2.0166e-01, time/batch = 18.7276s	
25722/26050 (epoch 49.370), train_loss = 0.65927986, grad/param norm = 2.0257e-01, time/batch = 30.8763s	
25723/26050 (epoch 49.372), train_loss = 0.71909660, grad/param norm = 2.1159e-01, time/batch = 25.8257s	
25724/26050 (epoch 49.374), train_loss = 0.85347725, grad/param norm = 2.1266e-01, time/batch = 16.2645s	
25725/26050 (epoch 49.376), train_loss = 0.86256483, grad/param norm = 2.5162e-01, time/batch = 18.1986s	
25726/26050 (epoch 49.378), train_loss = 0.72305040, grad/param norm = 2.2357e-01, time/batch = 18.3225s	
25727/26050 (epoch 49.380), train_loss = 0.85209961, grad/param norm = 2.5890e-01, time/batch = 17.2268s	
25728/26050 (epoch 49.382), train_loss = 0.89991760, grad/param norm = 2.8721e-01, time/batch = 18.8223s	
25729/26050 (epoch 49.384), train_loss = 0.71723613, grad/param norm = 2.7199e-01, time/batch = 18.3248s	
25730/26050 (epoch 49.386), train_loss = 0.82166491, grad/param norm = 3.3901e-01, time/batch = 14.3606s	
25731/26050 (epoch 49.388), train_loss = 0.77286727, grad/param norm = 2.3084e-01, time/batch = 17.2139s	
25732/26050 (epoch 49.390), train_loss = 0.69324042, grad/param norm = 2.0092e-01, time/batch = 18.2383s	
25733/26050 (epoch 49.392), train_loss = 0.63762741, grad/param norm = 1.9573e-01, time/batch = 18.8076s	
25734/26050 (epoch 49.393), train_loss = 0.82132304, grad/param norm = 2.5211e-01, time/batch = 17.6451s	
25735/26050 (epoch 49.395), train_loss = 0.80949689, grad/param norm = 2.4206e-01, time/batch = 18.1626s	
25736/26050 (epoch 49.397), train_loss = 0.81224798, grad/param norm = 2.3923e-01, time/batch = 17.5658s	
25737/26050 (epoch 49.399), train_loss = 0.71493032, grad/param norm = 2.3838e-01, time/batch = 18.0599s	
25738/26050 (epoch 49.401), train_loss = 0.75981309, grad/param norm = 2.4718e-01, time/batch = 17.9047s	
25739/26050 (epoch 49.403), train_loss = 0.75051301, grad/param norm = 2.5145e-01, time/batch = 15.1428s	
25740/26050 (epoch 49.405), train_loss = 0.77390998, grad/param norm = 2.9386e-01, time/batch = 18.4109s	
25741/26050 (epoch 49.407), train_loss = 0.88328943, grad/param norm = 2.6677e-01, time/batch = 17.8873s	
25742/26050 (epoch 49.409), train_loss = 0.84744583, grad/param norm = 2.4770e-01, time/batch = 18.4612s	
25743/26050 (epoch 49.411), train_loss = 0.84675709, grad/param norm = 2.5424e-01, time/batch = 18.8169s	
25744/26050 (epoch 49.413), train_loss = 0.94844378, grad/param norm = 2.2205e-01, time/batch = 17.6516s	
25745/26050 (epoch 49.415), train_loss = 0.91954463, grad/param norm = 2.3792e-01, time/batch = 18.0638s	
25746/26050 (epoch 49.417), train_loss = 0.91498666, grad/param norm = 2.7674e-01, time/batch = 18.2380s	
25747/26050 (epoch 49.418), train_loss = 0.81237750, grad/param norm = 2.6717e-01, time/batch = 17.5683s	
25748/26050 (epoch 49.420), train_loss = 0.65078673, grad/param norm = 2.0924e-01, time/batch = 18.7255s	
25749/26050 (epoch 49.422), train_loss = 0.65069764, grad/param norm = 2.3171e-01, time/batch = 17.6332s	
25750/26050 (epoch 49.424), train_loss = 0.85099132, grad/param norm = 2.4490e-01, time/batch = 18.0727s	
25751/26050 (epoch 49.426), train_loss = 0.80503410, grad/param norm = 2.5666e-01, time/batch = 17.4554s	
25752/26050 (epoch 49.428), train_loss = 0.75523112, grad/param norm = 2.4963e-01, time/batch = 16.2186s	
25753/26050 (epoch 49.430), train_loss = 0.91422949, grad/param norm = 2.5194e-01, time/batch = 17.1619s	
25754/26050 (epoch 49.432), train_loss = 0.72843002, grad/param norm = 2.1550e-01, time/batch = 16.6167s	
25755/26050 (epoch 49.434), train_loss = 0.73312286, grad/param norm = 2.5571e-01, time/batch = 18.2183s	
25756/26050 (epoch 49.436), train_loss = 0.84544963, grad/param norm = 2.3658e-01, time/batch = 18.3230s	
25757/26050 (epoch 49.438), train_loss = 0.79586017, grad/param norm = 2.4532e-01, time/batch = 17.6336s	
25758/26050 (epoch 49.440), train_loss = 0.82261177, grad/param norm = 2.3280e-01, time/batch = 17.4072s	
25759/26050 (epoch 49.441), train_loss = 0.79032811, grad/param norm = 2.4035e-01, time/batch = 18.4146s	
25760/26050 (epoch 49.443), train_loss = 0.66307308, grad/param norm = 1.8256e-01, time/batch = 18.3078s	
25761/26050 (epoch 49.445), train_loss = 0.69656255, grad/param norm = 2.3393e-01, time/batch = 17.9795s	
25762/26050 (epoch 49.447), train_loss = 0.87705100, grad/param norm = 2.1990e-01, time/batch = 18.1544s	
25763/26050 (epoch 49.449), train_loss = 0.68832676, grad/param norm = 2.2004e-01, time/batch = 17.3925s	
25764/26050 (epoch 49.451), train_loss = 0.87655025, grad/param norm = 2.3919e-01, time/batch = 15.0930s	
25765/26050 (epoch 49.453), train_loss = 0.74416400, grad/param norm = 2.0105e-01, time/batch = 18.3242s	
25766/26050 (epoch 49.455), train_loss = 0.77040652, grad/param norm = 2.2550e-01, time/batch = 16.4750s	
25767/26050 (epoch 49.457), train_loss = 0.74020952, grad/param norm = 2.4189e-01, time/batch = 18.0694s	
25768/26050 (epoch 49.459), train_loss = 0.82760529, grad/param norm = 2.3458e-01, time/batch = 18.4827s	
25769/26050 (epoch 49.461), train_loss = 0.84714576, grad/param norm = 2.7066e-01, time/batch = 17.9931s	
25770/26050 (epoch 49.463), train_loss = 0.72863037, grad/param norm = 2.0548e-01, time/batch = 15.8994s	
25771/26050 (epoch 49.464), train_loss = 0.80291340, grad/param norm = 2.3822e-01, time/batch = 16.9832s	
25772/26050 (epoch 49.466), train_loss = 0.75389539, grad/param norm = 2.3321e-01, time/batch = 18.0620s	
25773/26050 (epoch 49.468), train_loss = 0.85355775, grad/param norm = 2.2241e-01, time/batch = 19.2217s	
25774/26050 (epoch 49.470), train_loss = 0.85723188, grad/param norm = 2.5396e-01, time/batch = 17.2241s	
25775/26050 (epoch 49.472), train_loss = 0.84724393, grad/param norm = 2.5357e-01, time/batch = 17.9035s	
25776/26050 (epoch 49.474), train_loss = 0.88874457, grad/param norm = 2.8061e-01, time/batch = 17.9009s	
25777/26050 (epoch 49.476), train_loss = 0.83278953, grad/param norm = 2.3173e-01, time/batch = 18.8114s	
25778/26050 (epoch 49.478), train_loss = 0.74764087, grad/param norm = 2.1132e-01, time/batch = 17.7229s	
25779/26050 (epoch 49.480), train_loss = 0.73790978, grad/param norm = 2.0485e-01, time/batch = 16.2303s	
25780/26050 (epoch 49.482), train_loss = 0.74322071, grad/param norm = 2.1833e-01, time/batch = 18.5623s	
25781/26050 (epoch 49.484), train_loss = 0.71896457, grad/param norm = 2.4066e-01, time/batch = 17.0348s	
25782/26050 (epoch 49.486), train_loss = 0.86207623, grad/param norm = 2.3321e-01, time/batch = 18.4797s	
25783/26050 (epoch 49.488), train_loss = 0.91512237, grad/param norm = 3.0223e-01, time/batch = 18.4790s	
25784/26050 (epoch 49.489), train_loss = 0.92154856, grad/param norm = 3.0477e-01, time/batch = 17.6422s	
25785/26050 (epoch 49.491), train_loss = 0.71061392, grad/param norm = 2.5803e-01, time/batch = 17.6492s	
25786/26050 (epoch 49.493), train_loss = 0.79161056, grad/param norm = 2.3613e-01, time/batch = 15.0463s	
25787/26050 (epoch 49.495), train_loss = 0.77011383, grad/param norm = 2.0119e-01, time/batch = 17.1263s	
25788/26050 (epoch 49.497), train_loss = 0.69291615, grad/param norm = 2.2310e-01, time/batch = 17.4813s	
25789/26050 (epoch 49.499), train_loss = 0.70143426, grad/param norm = 2.3506e-01, time/batch = 18.4850s	
25790/26050 (epoch 49.501), train_loss = 0.87144469, grad/param norm = 2.2254e-01, time/batch = 17.8773s	
25791/26050 (epoch 49.503), train_loss = 0.73097523, grad/param norm = 2.2514e-01, time/batch = 17.2175s	
25792/26050 (epoch 49.505), train_loss = 0.85299656, grad/param norm = 2.2506e-01, time/batch = 18.2962s	
25793/26050 (epoch 49.507), train_loss = 0.84937788, grad/param norm = 2.5896e-01, time/batch = 18.1487s	
25794/26050 (epoch 49.509), train_loss = 0.88777701, grad/param norm = 2.1548e-01, time/batch = 17.7355s	
25795/26050 (epoch 49.511), train_loss = 0.78069479, grad/param norm = 2.1769e-01, time/batch = 18.6356s	
25796/26050 (epoch 49.512), train_loss = 0.67080066, grad/param norm = 2.4949e-01, time/batch = 18.1519s	
25797/26050 (epoch 49.514), train_loss = 0.80895289, grad/param norm = 2.3080e-01, time/batch = 16.4767s	
25798/26050 (epoch 49.516), train_loss = 0.88584006, grad/param norm = 2.3942e-01, time/batch = 16.3027s	
25799/26050 (epoch 49.518), train_loss = 0.75176562, grad/param norm = 2.1191e-01, time/batch = 17.6588s	
25800/26050 (epoch 49.520), train_loss = 0.77815561, grad/param norm = 2.2491e-01, time/batch = 18.9002s	
25801/26050 (epoch 49.522), train_loss = 0.61925582, grad/param norm = 2.1630e-01, time/batch = 17.7376s	
25802/26050 (epoch 49.524), train_loss = 0.83459757, grad/param norm = 2.8183e-01, time/batch = 18.4616s	
25803/26050 (epoch 49.526), train_loss = 0.86620907, grad/param norm = 2.9201e-01, time/batch = 15.1438s	
25804/26050 (epoch 49.528), train_loss = 0.80139471, grad/param norm = 2.4339e-01, time/batch = 18.9887s	
25805/26050 (epoch 49.530), train_loss = 0.73429606, grad/param norm = 2.7129e-01, time/batch = 18.2953s	
25806/26050 (epoch 49.532), train_loss = 0.84585462, grad/param norm = 2.2675e-01, time/batch = 18.8154s	
25807/26050 (epoch 49.534), train_loss = 0.80200691, grad/param norm = 3.4800e-01, time/batch = 18.8002s	
25808/26050 (epoch 49.536), train_loss = 0.79222268, grad/param norm = 2.3786e-01, time/batch = 17.0600s	
25809/26050 (epoch 49.537), train_loss = 0.85995404, grad/param norm = 2.3212e-01, time/batch = 18.4902s	
25810/26050 (epoch 49.539), train_loss = 0.80370569, grad/param norm = 2.2678e-01, time/batch = 18.9836s	
25811/26050 (epoch 49.541), train_loss = 0.91724828, grad/param norm = 2.8638e-01, time/batch = 14.7036s	
25812/26050 (epoch 49.543), train_loss = 0.61119798, grad/param norm = 2.0011e-01, time/batch = 17.8871s	
25813/26050 (epoch 49.545), train_loss = 0.74774577, grad/param norm = 2.2057e-01, time/batch = 15.9769s	
25814/26050 (epoch 49.547), train_loss = 0.70484076, grad/param norm = 2.1867e-01, time/batch = 17.4758s	
25815/26050 (epoch 49.549), train_loss = 0.67267731, grad/param norm = 2.2034e-01, time/batch = 17.6546s	
25816/26050 (epoch 49.551), train_loss = 0.83149668, grad/param norm = 2.3604e-01, time/batch = 17.9808s	
25817/26050 (epoch 49.553), train_loss = 0.73190332, grad/param norm = 2.2806e-01, time/batch = 18.8986s	
25818/26050 (epoch 49.555), train_loss = 0.65792943, grad/param norm = 2.2779e-01, time/batch = 17.5685s	
25819/26050 (epoch 49.557), train_loss = 0.79015853, grad/param norm = 2.1347e-01, time/batch = 18.0746s	
25820/26050 (epoch 49.559), train_loss = 0.78374934, grad/param norm = 2.1027e-01, time/batch = 18.1502s	
25821/26050 (epoch 49.560), train_loss = 0.74858764, grad/param norm = 2.3778e-01, time/batch = 17.7309s	
25822/26050 (epoch 49.562), train_loss = 0.76953255, grad/param norm = 2.3955e-01, time/batch = 17.9650s	
25823/26050 (epoch 49.564), train_loss = 0.92230096, grad/param norm = 2.4266e-01, time/batch = 17.7427s	
25824/26050 (epoch 49.566), train_loss = 0.72250289, grad/param norm = 2.2328e-01, time/batch = 18.6489s	
25825/26050 (epoch 49.568), train_loss = 0.81392510, grad/param norm = 2.3784e-01, time/batch = 16.1249s	
25826/26050 (epoch 49.570), train_loss = 0.76963552, grad/param norm = 2.3463e-01, time/batch = 17.4687s	
25827/26050 (epoch 49.572), train_loss = 0.79394744, grad/param norm = 2.8663e-01, time/batch = 17.4698s	
25828/26050 (epoch 49.574), train_loss = 0.81274153, grad/param norm = 2.8522e-01, time/batch = 18.0585s	
25829/26050 (epoch 49.576), train_loss = 0.79340870, grad/param norm = 2.6755e-01, time/batch = 18.6399s	
25830/26050 (epoch 49.578), train_loss = 0.74391663, grad/param norm = 2.5520e-01, time/batch = 18.1592s	
25831/26050 (epoch 49.580), train_loss = 0.69308933, grad/param norm = 2.5666e-01, time/batch = 15.3882s	
25832/26050 (epoch 49.582), train_loss = 0.79898177, grad/param norm = 2.3069e-01, time/batch = 15.1776s	
25833/26050 (epoch 49.583), train_loss = 0.80996340, grad/param norm = 2.1984e-01, time/batch = 15.1136s	
25834/26050 (epoch 49.585), train_loss = 0.69641329, grad/param norm = 2.1561e-01, time/batch = 18.0865s	
25835/26050 (epoch 49.587), train_loss = 0.78326723, grad/param norm = 2.6445e-01, time/batch = 14.5561s	
25836/26050 (epoch 49.589), train_loss = 0.91774098, grad/param norm = 2.3659e-01, time/batch = 15.0400s	
25837/26050 (epoch 49.591), train_loss = 0.81474913, grad/param norm = 2.4549e-01, time/batch = 14.3850s	
25838/26050 (epoch 49.593), train_loss = 0.67552480, grad/param norm = 2.0545e-01, time/batch = 14.3796s	
25839/26050 (epoch 49.595), train_loss = 0.80424149, grad/param norm = 2.4618e-01, time/batch = 16.4149s	
25840/26050 (epoch 49.597), train_loss = 0.79255597, grad/param norm = 2.3205e-01, time/batch = 16.5645s	
25841/26050 (epoch 49.599), train_loss = 0.83040261, grad/param norm = 2.2745e-01, time/batch = 18.4648s	
25842/26050 (epoch 49.601), train_loss = 0.91030338, grad/param norm = 2.3897e-01, time/batch = 18.4064s	
25843/26050 (epoch 49.603), train_loss = 0.82156595, grad/param norm = 2.4959e-01, time/batch = 17.5475s	
25844/26050 (epoch 49.605), train_loss = 0.76087126, grad/param norm = 2.6743e-01, time/batch = 18.2348s	
25845/26050 (epoch 49.607), train_loss = 0.84924014, grad/param norm = 2.6553e-01, time/batch = 17.2900s	
25846/26050 (epoch 49.608), train_loss = 0.73860133, grad/param norm = 2.1642e-01, time/batch = 17.4026s	
25847/26050 (epoch 49.610), train_loss = 0.77297857, grad/param norm = 2.4269e-01, time/batch = 18.6511s	
25848/26050 (epoch 49.612), train_loss = 0.74772043, grad/param norm = 2.4480e-01, time/batch = 18.3270s	
25849/26050 (epoch 49.614), train_loss = 0.78192627, grad/param norm = 2.2300e-01, time/batch = 16.6383s	
25850/26050 (epoch 49.616), train_loss = 0.81221547, grad/param norm = 2.4748e-01, time/batch = 14.8029s	
25851/26050 (epoch 49.618), train_loss = 0.71622321, grad/param norm = 2.3391e-01, time/batch = 18.8082s	
25852/26050 (epoch 49.620), train_loss = 0.84560903, grad/param norm = 2.4122e-01, time/batch = 18.9693s	
25853/26050 (epoch 49.622), train_loss = 0.71140494, grad/param norm = 2.1279e-01, time/batch = 17.7238s	
25854/26050 (epoch 49.624), train_loss = 0.64160841, grad/param norm = 2.1698e-01, time/batch = 17.8916s	
25855/26050 (epoch 49.626), train_loss = 0.80634379, grad/param norm = 2.3027e-01, time/batch = 18.9821s	
25856/26050 (epoch 49.628), train_loss = 0.72857809, grad/param norm = 2.4963e-01, time/batch = 17.7383s	
25857/26050 (epoch 49.630), train_loss = 0.92534183, grad/param norm = 2.4254e-01, time/batch = 18.3982s	
25858/26050 (epoch 49.631), train_loss = 0.88389343, grad/param norm = 2.7014e-01, time/batch = 15.7393s	
25859/26050 (epoch 49.633), train_loss = 0.72607216, grad/param norm = 2.5335e-01, time/batch = 18.7250s	
25860/26050 (epoch 49.635), train_loss = 0.73282291, grad/param norm = 1.9615e-01, time/batch = 14.6272s	
25861/26050 (epoch 49.637), train_loss = 0.68332081, grad/param norm = 1.9985e-01, time/batch = 14.5651s	
25862/26050 (epoch 49.639), train_loss = 0.81379052, grad/param norm = 2.2428e-01, time/batch = 18.9813s	
25863/26050 (epoch 49.641), train_loss = 0.70909632, grad/param norm = 2.1219e-01, time/batch = 16.8583s	
25864/26050 (epoch 49.643), train_loss = 0.71827469, grad/param norm = 1.8950e-01, time/batch = 18.6503s	
25865/26050 (epoch 49.645), train_loss = 0.74024713, grad/param norm = 2.2351e-01, time/batch = 17.8318s	
25866/26050 (epoch 49.647), train_loss = 0.67015284, grad/param norm = 2.0488e-01, time/batch = 18.3923s	
25867/26050 (epoch 49.649), train_loss = 0.73490497, grad/param norm = 2.9927e-01, time/batch = 16.7328s	
25868/26050 (epoch 49.651), train_loss = 0.74571651, grad/param norm = 2.0755e-01, time/batch = 18.3832s	
25869/26050 (epoch 49.653), train_loss = 0.76911390, grad/param norm = 2.5123e-01, time/batch = 17.9173s	
25870/26050 (epoch 49.655), train_loss = 0.70838512, grad/param norm = 2.3452e-01, time/batch = 17.5735s	
25871/26050 (epoch 49.656), train_loss = 0.67864762, grad/param norm = 2.0559e-01, time/batch = 18.6450s	
25872/26050 (epoch 49.658), train_loss = 0.91765514, grad/param norm = 2.4855e-01, time/batch = 19.3228s	
25873/26050 (epoch 49.660), train_loss = 0.62289097, grad/param norm = 2.3044e-01, time/batch = 16.9823s	
25874/26050 (epoch 49.662), train_loss = 0.74929587, grad/param norm = 1.9404e-01, time/batch = 14.9039s	
25875/26050 (epoch 49.664), train_loss = 0.77369562, grad/param norm = 2.1599e-01, time/batch = 16.3125s	
25876/26050 (epoch 49.666), train_loss = 0.73291315, grad/param norm = 2.2271e-01, time/batch = 17.4753s	
25877/26050 (epoch 49.668), train_loss = 0.60496846, grad/param norm = 2.3782e-01, time/batch = 16.6556s	
25878/26050 (epoch 49.670), train_loss = 0.88854249, grad/param norm = 3.0436e-01, time/batch = 17.0022s	
25879/26050 (epoch 49.672), train_loss = 0.75087649, grad/param norm = 2.4875e-01, time/batch = 15.3917s	
25880/26050 (epoch 49.674), train_loss = 0.66326966, grad/param norm = 2.2454e-01, time/batch = 18.2276s	
25881/26050 (epoch 49.676), train_loss = 0.80617852, grad/param norm = 2.3984e-01, time/batch = 18.1359s	
25882/26050 (epoch 49.678), train_loss = 0.84092877, grad/param norm = 2.4220e-01, time/batch = 17.8929s	
25883/26050 (epoch 49.679), train_loss = 0.86495057, grad/param norm = 2.7504e-01, time/batch = 18.2139s	
25884/26050 (epoch 49.681), train_loss = 0.78747192, grad/param norm = 2.3324e-01, time/batch = 17.3865s	
25885/26050 (epoch 49.683), train_loss = 0.68922752, grad/param norm = 3.0649e-01, time/batch = 18.1535s	
25886/26050 (epoch 49.685), train_loss = 0.72552560, grad/param norm = 2.3339e-01, time/batch = 18.3237s	
25887/26050 (epoch 49.687), train_loss = 0.68957555, grad/param norm = 2.2548e-01, time/batch = 15.7228s	
25888/26050 (epoch 49.689), train_loss = 0.72333168, grad/param norm = 2.1475e-01, time/batch = 18.0601s	
25889/26050 (epoch 49.691), train_loss = 0.63374817, grad/param norm = 2.0588e-01, time/batch = 18.4879s	
25890/26050 (epoch 49.693), train_loss = 0.72123179, grad/param norm = 2.3565e-01, time/batch = 17.7992s	
25891/26050 (epoch 49.695), train_loss = 0.74601033, grad/param norm = 2.2850e-01, time/batch = 18.1464s	
25892/26050 (epoch 49.697), train_loss = 0.68610478, grad/param norm = 2.0509e-01, time/batch = 18.1515s	
25893/26050 (epoch 49.699), train_loss = 0.79525672, grad/param norm = 2.4031e-01, time/batch = 18.9824s	
25894/26050 (epoch 49.701), train_loss = 0.68415472, grad/param norm = 1.9553e-01, time/batch = 16.0360s	
25895/26050 (epoch 49.702), train_loss = 0.83206079, grad/param norm = 2.1685e-01, time/batch = 17.5725s	
25896/26050 (epoch 49.704), train_loss = 0.87322867, grad/param norm = 2.1691e-01, time/batch = 17.8047s	
25897/26050 (epoch 49.706), train_loss = 0.70677606, grad/param norm = 2.1526e-01, time/batch = 17.0459s	
25898/26050 (epoch 49.708), train_loss = 0.82487896, grad/param norm = 2.2801e-01, time/batch = 18.8151s	
25899/26050 (epoch 49.710), train_loss = 0.77838626, grad/param norm = 2.3076e-01, time/batch = 17.6664s	
25900/26050 (epoch 49.712), train_loss = 0.75789874, grad/param norm = 2.5716e-01, time/batch = 17.0749s	
25901/26050 (epoch 49.714), train_loss = 0.69151575, grad/param norm = 2.0660e-01, time/batch = 17.3605s	
25902/26050 (epoch 49.716), train_loss = 0.96269337, grad/param norm = 2.5497e-01, time/batch = 18.0702s	
25903/26050 (epoch 49.718), train_loss = 0.82893737, grad/param norm = 2.4508e-01, time/batch = 18.8170s	
25904/26050 (epoch 49.720), train_loss = 0.73128050, grad/param norm = 2.0951e-01, time/batch = 17.3825s	
25905/26050 (epoch 49.722), train_loss = 0.69634174, grad/param norm = 2.2912e-01, time/batch = 17.9851s	
25906/26050 (epoch 49.724), train_loss = 0.71885700, grad/param norm = 2.2332e-01, time/batch = 15.0735s	
25907/26050 (epoch 49.726), train_loss = 0.81874561, grad/param norm = 2.1488e-01, time/batch = 18.2340s	
25908/26050 (epoch 49.727), train_loss = 0.80135610, grad/param norm = 2.3251e-01, time/batch = 2.8939s	
25909/26050 (epoch 49.729), train_loss = 0.82308331, grad/param norm = 2.1403e-01, time/batch = 0.6409s	
25910/26050 (epoch 49.731), train_loss = 0.81025376, grad/param norm = 2.3489e-01, time/batch = 0.6793s	
25911/26050 (epoch 49.733), train_loss = 0.73538160, grad/param norm = 2.3070e-01, time/batch = 0.6633s	
25912/26050 (epoch 49.735), train_loss = 0.83873769, grad/param norm = 2.0008e-01, time/batch = 0.6412s	
25913/26050 (epoch 49.737), train_loss = 0.72600221, grad/param norm = 2.5167e-01, time/batch = 0.6531s	
25914/26050 (epoch 49.739), train_loss = 0.78265891, grad/param norm = 1.9829e-01, time/batch = 0.6510s	
25915/26050 (epoch 49.741), train_loss = 0.69290259, grad/param norm = 2.1112e-01, time/batch = 0.7196s	
25916/26050 (epoch 49.743), train_loss = 0.75290724, grad/param norm = 2.4156e-01, time/batch = 0.9438s	
25917/26050 (epoch 49.745), train_loss = 0.67723078, grad/param norm = 2.1096e-01, time/batch = 0.9442s	
25918/26050 (epoch 49.747), train_loss = 0.73343159, grad/param norm = 2.3687e-01, time/batch = 0.9431s	
25919/26050 (epoch 49.749), train_loss = 0.87395000, grad/param norm = 2.5227e-01, time/batch = 0.9414s	
25920/26050 (epoch 49.750), train_loss = 0.72918439, grad/param norm = 2.2069e-01, time/batch = 0.9652s	
25921/26050 (epoch 49.752), train_loss = 0.71305894, grad/param norm = 2.4899e-01, time/batch = 1.8103s	
25922/26050 (epoch 49.754), train_loss = 0.76369864, grad/param norm = 2.3775e-01, time/batch = 1.7993s	
25923/26050 (epoch 49.756), train_loss = 0.73453793, grad/param norm = 2.4378e-01, time/batch = 5.8418s	
25924/26050 (epoch 49.758), train_loss = 0.75108753, grad/param norm = 2.4421e-01, time/batch = 18.6518s	
25925/26050 (epoch 49.760), train_loss = 0.88797460, grad/param norm = 2.8977e-01, time/batch = 18.1531s	
25926/26050 (epoch 49.762), train_loss = 0.73362277, grad/param norm = 2.3130e-01, time/batch = 17.6479s	
25927/26050 (epoch 49.764), train_loss = 0.75026076, grad/param norm = 2.4357e-01, time/batch = 15.8175s	
25928/26050 (epoch 49.766), train_loss = 0.75997383, grad/param norm = 2.7720e-01, time/batch = 18.4794s	
25929/26050 (epoch 49.768), train_loss = 0.66227109, grad/param norm = 2.1416e-01, time/batch = 17.5571s	
25930/26050 (epoch 49.770), train_loss = 0.74702527, grad/param norm = 2.6057e-01, time/batch = 18.1514s	
25931/26050 (epoch 49.772), train_loss = 0.77807112, grad/param norm = 2.5016e-01, time/batch = 18.0854s	
25932/26050 (epoch 49.774), train_loss = 0.62937503, grad/param norm = 2.1740e-01, time/batch = 16.5538s	
25933/26050 (epoch 49.775), train_loss = 0.53595645, grad/param norm = 1.9611e-01, time/batch = 18.3039s	
25934/26050 (epoch 49.777), train_loss = 0.72398378, grad/param norm = 2.0077e-01, time/batch = 17.8935s	
25935/26050 (epoch 49.779), train_loss = 0.73791859, grad/param norm = 2.2334e-01, time/batch = 18.6375s	
25936/26050 (epoch 49.781), train_loss = 0.68059491, grad/param norm = 1.9828e-01, time/batch = 17.9781s	
25937/26050 (epoch 49.783), train_loss = 0.64255893, grad/param norm = 2.2554e-01, time/batch = 18.0526s	
25938/26050 (epoch 49.785), train_loss = 0.75444961, grad/param norm = 2.3477e-01, time/batch = 17.2965s	
25939/26050 (epoch 49.787), train_loss = 0.68057869, grad/param norm = 2.1789e-01, time/batch = 20.0873s	
25940/26050 (epoch 49.789), train_loss = 0.68345700, grad/param norm = 2.5951e-01, time/batch = 32.7015s	
25941/26050 (epoch 49.791), train_loss = 0.67962581, grad/param norm = 2.5053e-01, time/batch = 17.3115s	
25942/26050 (epoch 49.793), train_loss = 0.76191214, grad/param norm = 2.2718e-01, time/batch = 18.7273s	
25943/26050 (epoch 49.795), train_loss = 0.60981404, grad/param norm = 2.0722e-01, time/batch = 17.8216s	
25944/26050 (epoch 49.797), train_loss = 0.69302252, grad/param norm = 2.2588e-01, time/batch = 18.7257s	
25945/26050 (epoch 49.798), train_loss = 0.76030886, grad/param norm = 2.8734e-01, time/batch = 18.3816s	
25946/26050 (epoch 49.800), train_loss = 0.63957569, grad/param norm = 1.8741e-01, time/batch = 17.9892s	
25947/26050 (epoch 49.802), train_loss = 0.71561707, grad/param norm = 2.1231e-01, time/batch = 14.8111s	
25948/26050 (epoch 49.804), train_loss = 0.75394023, grad/param norm = 2.5061e-01, time/batch = 17.1158s	
25949/26050 (epoch 49.806), train_loss = 0.81341491, grad/param norm = 2.2969e-01, time/batch = 18.0518s	
25950/26050 (epoch 49.808), train_loss = 0.75651866, grad/param norm = 1.9977e-01, time/batch = 18.1599s	
25951/26050 (epoch 49.810), train_loss = 0.77309099, grad/param norm = 2.2341e-01, time/batch = 17.6535s	
25952/26050 (epoch 49.812), train_loss = 0.62196307, grad/param norm = 2.1964e-01, time/batch = 18.4039s	
25953/26050 (epoch 49.814), train_loss = 0.66028261, grad/param norm = 2.6914e-01, time/batch = 18.5631s	
25954/26050 (epoch 49.816), train_loss = 0.76924585, grad/param norm = 2.3015e-01, time/batch = 15.4730s	
25955/26050 (epoch 49.818), train_loss = 0.81785346, grad/param norm = 2.7034e-01, time/batch = 15.6422s	
25956/26050 (epoch 49.820), train_loss = 0.76304648, grad/param norm = 2.4424e-01, time/batch = 16.7970s	
25957/26050 (epoch 49.821), train_loss = 0.82524133, grad/param norm = 2.3720e-01, time/batch = 17.3024s	
25958/26050 (epoch 49.823), train_loss = 0.92860103, grad/param norm = 2.3263e-01, time/batch = 17.3906s	
25959/26050 (epoch 49.825), train_loss = 0.75319688, grad/param norm = 2.4993e-01, time/batch = 18.2291s	
25960/26050 (epoch 49.827), train_loss = 0.75127745, grad/param norm = 2.6687e-01, time/batch = 18.7266s	
25961/26050 (epoch 49.829), train_loss = 0.86834848, grad/param norm = 2.9676e-01, time/batch = 18.6516s	
25962/26050 (epoch 49.831), train_loss = 0.90977727, grad/param norm = 2.4724e-01, time/batch = 17.6291s	
25963/26050 (epoch 49.833), train_loss = 0.83654005, grad/param norm = 2.6438e-01, time/batch = 18.8153s	
25964/26050 (epoch 49.835), train_loss = 0.87839468, grad/param norm = 2.6078e-01, time/batch = 16.7041s	
25965/26050 (epoch 49.837), train_loss = 0.76999621, grad/param norm = 2.1831e-01, time/batch = 17.0376s	
25966/26050 (epoch 49.839), train_loss = 0.74843734, grad/param norm = 2.2689e-01, time/batch = 17.3667s	
25967/26050 (epoch 49.841), train_loss = 0.81772908, grad/param norm = 2.8577e-01, time/batch = 18.4933s	
25968/26050 (epoch 49.843), train_loss = 0.73599366, grad/param norm = 1.9318e-01, time/batch = 17.9010s	
25969/26050 (epoch 49.845), train_loss = 0.74352819, grad/param norm = 2.8517e-01, time/batch = 17.4102s	
25970/26050 (epoch 49.846), train_loss = 0.78297986, grad/param norm = 2.3596e-01, time/batch = 18.7494s	
25971/26050 (epoch 49.848), train_loss = 0.75004731, grad/param norm = 2.6004e-01, time/batch = 18.7201s	
25972/26050 (epoch 49.850), train_loss = 0.67018630, grad/param norm = 2.0051e-01, time/batch = 17.1238s	
25973/26050 (epoch 49.852), train_loss = 0.78001143, grad/param norm = 2.2154e-01, time/batch = 18.8159s	
25974/26050 (epoch 49.854), train_loss = 0.75356001, grad/param norm = 2.4750e-01, time/batch = 18.6520s	
25975/26050 (epoch 49.856), train_loss = 0.72790915, grad/param norm = 2.6971e-01, time/batch = 17.2387s	
25976/26050 (epoch 49.858), train_loss = 0.69839822, grad/param norm = 2.3260e-01, time/batch = 18.0824s	
25977/26050 (epoch 49.860), train_loss = 0.76570509, grad/param norm = 2.6884e-01, time/batch = 15.3940s	
25978/26050 (epoch 49.862), train_loss = 0.82875642, grad/param norm = 2.4232e-01, time/batch = 15.4735s	
25979/26050 (epoch 49.864), train_loss = 0.75036042, grad/param norm = 2.8387e-01, time/batch = 16.4569s	
25980/26050 (epoch 49.866), train_loss = 0.78307431, grad/param norm = 2.3948e-01, time/batch = 17.4943s	
25981/26050 (epoch 49.868), train_loss = 0.81886800, grad/param norm = 2.6924e-01, time/batch = 18.5540s	
25982/26050 (epoch 49.869), train_loss = 0.70269882, grad/param norm = 2.2118e-01, time/batch = 17.7991s	
25983/26050 (epoch 49.871), train_loss = 0.64504354, grad/param norm = 2.2166e-01, time/batch = 18.7243s	
25984/26050 (epoch 49.873), train_loss = 0.81000067, grad/param norm = 2.2256e-01, time/batch = 17.4051s	
25985/26050 (epoch 49.875), train_loss = 0.74362110, grad/param norm = 2.5763e-01, time/batch = 15.9496s	
25986/26050 (epoch 49.877), train_loss = 0.73601003, grad/param norm = 2.3797e-01, time/batch = 18.5413s	
25987/26050 (epoch 49.879), train_loss = 0.83394538, grad/param norm = 2.1903e-01, time/batch = 15.2282s	
25988/26050 (epoch 49.881), train_loss = 0.83255846, grad/param norm = 2.8473e-01, time/batch = 18.1486s	
25989/26050 (epoch 49.883), train_loss = 0.84610184, grad/param norm = 2.8712e-01, time/batch = 17.6364s	
25990/26050 (epoch 49.885), train_loss = 0.60976801, grad/param norm = 1.9456e-01, time/batch = 18.4814s	
25991/26050 (epoch 49.887), train_loss = 0.87557071, grad/param norm = 2.5133e-01, time/batch = 16.9985s	
25992/26050 (epoch 49.889), train_loss = 0.71831074, grad/param norm = 2.2579e-01, time/batch = 17.2285s	
25993/26050 (epoch 49.891), train_loss = 0.63397723, grad/param norm = 2.0673e-01, time/batch = 16.6244s	
25994/26050 (epoch 49.893), train_loss = 0.63646676, grad/param norm = 2.4697e-01, time/batch = 17.2003s	
25995/26050 (epoch 49.894), train_loss = 0.71427080, grad/param norm = 2.3582e-01, time/batch = 17.8194s	
25996/26050 (epoch 49.896), train_loss = 0.81957090, grad/param norm = 2.4331e-01, time/batch = 18.3936s	
25997/26050 (epoch 49.898), train_loss = 0.70117426, grad/param norm = 2.3623e-01, time/batch = 18.2394s	
25998/26050 (epoch 49.900), train_loss = 0.80598065, grad/param norm = 2.5909e-01, time/batch = 18.0701s	
25999/26050 (epoch 49.902), train_loss = 0.73274954, grad/param norm = 2.3955e-01, time/batch = 17.6562s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch49.90_2.0385.t7	
26000/26050 (epoch 49.904), train_loss = 0.75765247, grad/param norm = 2.8292e-01, time/batch = 16.8044s	
26001/26050 (epoch 49.906), train_loss = 1.22872773, grad/param norm = 3.9091e-01, time/batch = 18.2263s	
26002/26050 (epoch 49.908), train_loss = 0.81340860, grad/param norm = 2.5428e-01, time/batch = 18.5650s	
26003/26050 (epoch 49.910), train_loss = 0.71076245, grad/param norm = 2.4636e-01, time/batch = 16.6511s	
26004/26050 (epoch 49.912), train_loss = 0.91945563, grad/param norm = 2.8339e-01, time/batch = 16.3766s	
26005/26050 (epoch 49.914), train_loss = 1.02981572, grad/param norm = 2.7790e-01, time/batch = 15.5490s	
26006/26050 (epoch 49.916), train_loss = 0.81783714, grad/param norm = 3.1225e-01, time/batch = 17.4747s	
26007/26050 (epoch 49.917), train_loss = 0.77956883, grad/param norm = 2.4234e-01, time/batch = 18.3840s	
26008/26050 (epoch 49.919), train_loss = 0.77997455, grad/param norm = 2.5946e-01, time/batch = 18.7203s	
26009/26050 (epoch 49.921), train_loss = 0.68970593, grad/param norm = 2.4166e-01, time/batch = 18.7411s	
26010/26050 (epoch 49.923), train_loss = 0.77488414, grad/param norm = 2.2596e-01, time/batch = 18.5526s	
26011/26050 (epoch 49.925), train_loss = 0.77634897, grad/param norm = 2.8002e-01, time/batch = 18.1596s	
26012/26050 (epoch 49.927), train_loss = 0.70953718, grad/param norm = 1.9583e-01, time/batch = 18.8208s	
26013/26050 (epoch 49.929), train_loss = 0.63756444, grad/param norm = 2.0731e-01, time/batch = 17.3113s	
26014/26050 (epoch 49.931), train_loss = 0.89223929, grad/param norm = 2.5466e-01, time/batch = 18.3214s	
26015/26050 (epoch 49.933), train_loss = 0.77995565, grad/param norm = 2.4391e-01, time/batch = 18.3184s	
26016/26050 (epoch 49.935), train_loss = 0.74254442, grad/param norm = 2.4163e-01, time/batch = 17.9791s	
26017/26050 (epoch 49.937), train_loss = 0.83477523, grad/param norm = 2.2348e-01, time/batch = 18.6398s	
26018/26050 (epoch 49.939), train_loss = 0.71231786, grad/param norm = 2.3261e-01, time/batch = 14.6448s	
26019/26050 (epoch 49.940), train_loss = 0.76651171, grad/param norm = 2.2808e-01, time/batch = 18.3127s	
26020/26050 (epoch 49.942), train_loss = 0.68869404, grad/param norm = 2.2542e-01, time/batch = 17.2216s	
26021/26050 (epoch 49.944), train_loss = 0.74254165, grad/param norm = 2.3655e-01, time/batch = 18.4083s	
26022/26050 (epoch 49.946), train_loss = 0.91710233, grad/param norm = 2.5571e-01, time/batch = 17.4116s	
26023/26050 (epoch 49.948), train_loss = 0.64473745, grad/param norm = 2.2403e-01, time/batch = 15.6408s	
26024/26050 (epoch 49.950), train_loss = 0.80344582, grad/param norm = 2.3595e-01, time/batch = 18.3930s	
26025/26050 (epoch 49.952), train_loss = 0.79910668, grad/param norm = 2.4277e-01, time/batch = 17.9105s	
26026/26050 (epoch 49.954), train_loss = 0.81627559, grad/param norm = 2.3522e-01, time/batch = 17.6515s	
26027/26050 (epoch 49.956), train_loss = 0.71405386, grad/param norm = 2.2795e-01, time/batch = 15.3100s	
26028/26050 (epoch 49.958), train_loss = 0.68418882, grad/param norm = 2.2161e-01, time/batch = 16.5563s	
26029/26050 (epoch 49.960), train_loss = 0.79051592, grad/param norm = 2.0784e-01, time/batch = 15.7862s	
26030/26050 (epoch 49.962), train_loss = 0.74517988, grad/param norm = 1.9008e-01, time/batch = 17.6580s	
26031/26050 (epoch 49.964), train_loss = 0.69661701, grad/param norm = 2.0120e-01, time/batch = 17.8164s	
26032/26050 (epoch 49.965), train_loss = 0.66700780, grad/param norm = 3.1053e-01, time/batch = 18.1438s	
26033/26050 (epoch 49.967), train_loss = 0.99677699, grad/param norm = 2.3110e-01, time/batch = 18.0536s	
26034/26050 (epoch 49.969), train_loss = 0.75209418, grad/param norm = 2.2241e-01, time/batch = 17.9888s	
26035/26050 (epoch 49.971), train_loss = 0.78215684, grad/param norm = 2.6631e-01, time/batch = 19.3129s	
26036/26050 (epoch 49.973), train_loss = 0.77691605, grad/param norm = 2.3863e-01, time/batch = 16.5690s	
26037/26050 (epoch 49.975), train_loss = 0.77181781, grad/param norm = 2.1804e-01, time/batch = 16.0331s	
26038/26050 (epoch 49.977), train_loss = 0.73282002, grad/param norm = 1.9178e-01, time/batch = 18.7251s	
26039/26050 (epoch 49.979), train_loss = 0.61353404, grad/param norm = 2.0127e-01, time/batch = 18.4731s	
26040/26050 (epoch 49.981), train_loss = 0.82023456, grad/param norm = 2.0647e-01, time/batch = 16.7140s	
26041/26050 (epoch 49.983), train_loss = 0.77493915, grad/param norm = 2.1708e-01, time/batch = 18.6289s	
26042/26050 (epoch 49.985), train_loss = 0.77095626, grad/param norm = 2.4132e-01, time/batch = 17.0709s	
26043/26050 (epoch 49.987), train_loss = 0.85290021, grad/param norm = 2.4773e-01, time/batch = 18.1625s	
26044/26050 (epoch 49.988), train_loss = 0.78489846, grad/param norm = 2.4218e-01, time/batch = 18.2304s	
26045/26050 (epoch 49.990), train_loss = 0.66385237, grad/param norm = 2.3258e-01, time/batch = 17.9762s	
26046/26050 (epoch 49.992), train_loss = 0.88306313, grad/param norm = 2.6035e-01, time/batch = 17.9864s	
26047/26050 (epoch 49.994), train_loss = 0.70990916, grad/param norm = 2.4761e-01, time/batch = 16.9610s	
26048/26050 (epoch 49.996), train_loss = 0.69404463, grad/param norm = 3.2299e-01, time/batch = 17.2383s	
26049/26050 (epoch 49.998), train_loss = 0.77562799, grad/param norm = 2.3905e-01, time/batch = 18.3981s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch50.00_2.0088.t7	
26050/26050 (epoch 50.000), train_loss = 0.68735053, grad/param norm = 2.5502e-01, time/batch = 15.1286s	

real	5586m48.406s
user	5544m5.572s
sys	5m5.476s
