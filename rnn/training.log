tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 570, val: 30, test: 0	
vocab size: 144	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 290960	
cloning rnn	
cloning criterion	
1/28500 (epoch 0.002), train_loss = 4.97659627, grad/param norm = 5.6992e-01, time/batch = 0.7243s	
2/28500 (epoch 0.004), train_loss = 4.73031704, grad/param norm = 1.4875e+00, time/batch = 0.6859s	
3/28500 (epoch 0.005), train_loss = 3.85942993, grad/param norm = 1.6025e+00, time/batch = 0.6829s	
4/28500 (epoch 0.007), train_loss = 3.39351314, grad/param norm = 9.9938e-01, time/batch = 0.6815s	
5/28500 (epoch 0.009), train_loss = 3.51547386, grad/param norm = 7.1065e-01, time/batch = 0.6816s	
6/28500 (epoch 0.011), train_loss = 3.69060927, grad/param norm = 8.5438e-01, time/batch = 0.6782s	
7/28500 (epoch 0.012), train_loss = 3.54524334, grad/param norm = 6.6374e-01, time/batch = 0.6753s	
8/28500 (epoch 0.014), train_loss = 3.61503980, grad/param norm = 8.0610e-01, time/batch = 0.6772s	
9/28500 (epoch 0.016), train_loss = 3.61040502, grad/param norm = 6.8455e-01, time/batch = 0.6768s	
10/28500 (epoch 0.018), train_loss = 3.53022901, grad/param norm = 8.3092e-01, time/batch = 0.6751s	
11/28500 (epoch 0.019), train_loss = 3.53975355, grad/param norm = 7.1217e-01, time/batch = 0.6751s	
12/28500 (epoch 0.021), train_loss = 3.35527989, grad/param norm = 6.7907e-01, time/batch = 0.6751s	
13/28500 (epoch 0.023), train_loss = 3.43773733, grad/param norm = 5.8377e-01, time/batch = 0.6760s	
14/28500 (epoch 0.025), train_loss = 3.30774363, grad/param norm = 6.7490e-01, time/batch = 0.6744s	
15/28500 (epoch 0.026), train_loss = 3.49532604, grad/param norm = 7.6345e-01, time/batch = 0.6745s	
16/28500 (epoch 0.028), train_loss = 3.41780409, grad/param norm = 7.3376e-01, time/batch = 0.6749s	
17/28500 (epoch 0.030), train_loss = 3.33483958, grad/param norm = 9.3560e-01, time/batch = 0.6748s	
18/28500 (epoch 0.032), train_loss = 3.31170722, grad/param norm = 5.9258e-01, time/batch = 0.6745s	
19/28500 (epoch 0.033), train_loss = 3.62498398, grad/param norm = 9.4371e-01, time/batch = 0.6747s	
20/28500 (epoch 0.035), train_loss = 3.63471495, grad/param norm = 8.1136e-01, time/batch = 0.6767s	
21/28500 (epoch 0.037), train_loss = 3.47687610, grad/param norm = 7.1475e-01, time/batch = 0.6765s	
22/28500 (epoch 0.039), train_loss = 3.45486239, grad/param norm = 5.5371e-01, time/batch = 0.6769s	
23/28500 (epoch 0.040), train_loss = 3.43728679, grad/param norm = 5.4841e-01, time/batch = 0.6759s	
24/28500 (epoch 0.042), train_loss = 3.48444686, grad/param norm = 6.7819e-01, time/batch = 0.6801s	
25/28500 (epoch 0.044), train_loss = 3.52724017, grad/param norm = 8.0759e-01, time/batch = 0.6925s	
26/28500 (epoch 0.046), train_loss = 3.36108430, grad/param norm = 5.7876e-01, time/batch = 0.6830s	
27/28500 (epoch 0.047), train_loss = 3.42281461, grad/param norm = 6.4730e-01, time/batch = 0.6816s	
28/28500 (epoch 0.049), train_loss = 3.46918898, grad/param norm = 5.9253e-01, time/batch = 0.6802s	
29/28500 (epoch 0.051), train_loss = 3.39295855, grad/param norm = 5.9747e-01, time/batch = 0.6877s	
30/28500 (epoch 0.053), train_loss = 3.43570854, grad/param norm = 6.4981e-01, time/batch = 0.6760s	
31/28500 (epoch 0.054), train_loss = 3.28906669, grad/param norm = 6.9690e-01, time/batch = 0.6790s	
32/28500 (epoch 0.056), train_loss = 3.43806397, grad/param norm = 6.9348e-01, time/batch = 0.6779s	
33/28500 (epoch 0.058), train_loss = 3.40625593, grad/param norm = 5.2224e-01, time/batch = 0.6764s	
34/28500 (epoch 0.060), train_loss = 3.31085159, grad/param norm = 7.6409e-01, time/batch = 0.6743s	
35/28500 (epoch 0.061), train_loss = 3.46855626, grad/param norm = 7.5748e-01, time/batch = 0.6748s	
36/28500 (epoch 0.063), train_loss = 3.41477321, grad/param norm = 4.7219e-01, time/batch = 0.6747s	
37/28500 (epoch 0.065), train_loss = 3.53812493, grad/param norm = 5.6581e-01, time/batch = 0.6751s	
38/28500 (epoch 0.067), train_loss = 3.30436374, grad/param norm = 7.2330e-01, time/batch = 0.6747s	
39/28500 (epoch 0.068), train_loss = 3.38066403, grad/param norm = 6.7952e-01, time/batch = 0.6744s	
40/28500 (epoch 0.070), train_loss = 3.37570453, grad/param norm = 5.8712e-01, time/batch = 0.6745s	
41/28500 (epoch 0.072), train_loss = 3.32348756, grad/param norm = 6.4873e-01, time/batch = 0.6784s	
42/28500 (epoch 0.074), train_loss = 3.59900373, grad/param norm = 9.2456e-01, time/batch = 0.6780s	
43/28500 (epoch 0.075), train_loss = 3.46385792, grad/param norm = 5.7312e-01, time/batch = 0.6757s	
44/28500 (epoch 0.077), train_loss = 3.30054279, grad/param norm = 6.5499e-01, time/batch = 0.6744s	
45/28500 (epoch 0.079), train_loss = 3.34873514, grad/param norm = 7.3685e-01, time/batch = 0.6743s	
46/28500 (epoch 0.081), train_loss = 3.30133065, grad/param norm = 6.1288e-01, time/batch = 0.6741s	
47/28500 (epoch 0.082), train_loss = 3.37626951, grad/param norm = 5.7592e-01, time/batch = 0.6739s	
48/28500 (epoch 0.084), train_loss = 3.36080964, grad/param norm = 5.0673e-01, time/batch = 0.6738s	
49/28500 (epoch 0.086), train_loss = 3.31115326, grad/param norm = 7.3302e-01, time/batch = 0.6742s	
50/28500 (epoch 0.088), train_loss = 3.28749552, grad/param norm = 6.2968e-01, time/batch = 0.6742s	
51/28500 (epoch 0.089), train_loss = 3.49497609, grad/param norm = 6.4878e-01, time/batch = 0.6801s	
52/28500 (epoch 0.091), train_loss = 3.34875290, grad/param norm = 9.1288e-01, time/batch = 0.6751s	
53/28500 (epoch 0.093), train_loss = 3.30200556, grad/param norm = 7.1274e-01, time/batch = 0.6743s	
54/28500 (epoch 0.095), train_loss = 3.38540824, grad/param norm = 5.8519e-01, time/batch = 0.6763s	
55/28500 (epoch 0.096), train_loss = 3.47000151, grad/param norm = 6.5213e-01, time/batch = 0.6755s	
56/28500 (epoch 0.098), train_loss = 3.48047260, grad/param norm = 6.5812e-01, time/batch = 0.6781s	
57/28500 (epoch 0.100), train_loss = 3.42424132, grad/param norm = 5.9109e-01, time/batch = 0.6778s	
58/28500 (epoch 0.102), train_loss = 3.39742979, grad/param norm = 4.8906e-01, time/batch = 0.6806s	
59/28500 (epoch 0.104), train_loss = 3.33609594, grad/param norm = 5.0560e-01, time/batch = 0.6797s	
60/28500 (epoch 0.105), train_loss = 3.21929523, grad/param norm = 7.9650e-01, time/batch = 0.6792s	
61/28500 (epoch 0.107), train_loss = 3.40651120, grad/param norm = 5.9553e-01, time/batch = 0.6819s	
62/28500 (epoch 0.109), train_loss = 3.32650875, grad/param norm = 6.7482e-01, time/batch = 0.6801s	
63/28500 (epoch 0.111), train_loss = 3.39104237, grad/param norm = 6.0046e-01, time/batch = 0.6784s	
64/28500 (epoch 0.112), train_loss = 3.36905075, grad/param norm = 6.1765e-01, time/batch = 0.6768s	
65/28500 (epoch 0.114), train_loss = 3.31246534, grad/param norm = 4.5326e-01, time/batch = 0.6742s	
66/28500 (epoch 0.116), train_loss = 3.24534331, grad/param norm = 6.9609e-01, time/batch = 0.6745s	
67/28500 (epoch 0.118), train_loss = 3.30056000, grad/param norm = 5.5344e-01, time/batch = 0.6748s	
68/28500 (epoch 0.119), train_loss = 3.48006190, grad/param norm = 5.4310e-01, time/batch = 0.6758s	
69/28500 (epoch 0.121), train_loss = 3.42256268, grad/param norm = 5.6741e-01, time/batch = 0.6753s	
70/28500 (epoch 0.123), train_loss = 3.26833660, grad/param norm = 6.6734e-01, time/batch = 0.6752s	
71/28500 (epoch 0.125), train_loss = 3.38915806, grad/param norm = 6.3240e-01, time/batch = 0.6813s	
72/28500 (epoch 0.126), train_loss = 3.42607712, grad/param norm = 5.9277e-01, time/batch = 0.6867s	
73/28500 (epoch 0.128), train_loss = 3.58239584, grad/param norm = 7.1977e-01, time/batch = 0.6806s	
74/28500 (epoch 0.130), train_loss = 3.55642978, grad/param norm = 5.2668e-01, time/batch = 0.6759s	
75/28500 (epoch 0.132), train_loss = 3.49208728, grad/param norm = 5.3064e-01, time/batch = 0.6754s	
76/28500 (epoch 0.133), train_loss = 3.48762566, grad/param norm = 5.1013e-01, time/batch = 0.6753s	
77/28500 (epoch 0.135), train_loss = 3.34455989, grad/param norm = 5.7594e-01, time/batch = 0.6754s	
78/28500 (epoch 0.137), train_loss = 3.60153400, grad/param norm = 7.8282e-01, time/batch = 0.6769s	
79/28500 (epoch 0.139), train_loss = 3.37714640, grad/param norm = 5.8459e-01, time/batch = 0.6794s	
80/28500 (epoch 0.140), train_loss = 3.30301688, grad/param norm = 4.9517e-01, time/batch = 0.6795s	
81/28500 (epoch 0.142), train_loss = 3.45170090, grad/param norm = 6.7271e-01, time/batch = 0.6854s	
82/28500 (epoch 0.144), train_loss = 3.38427369, grad/param norm = 4.8423e-01, time/batch = 0.6815s	
83/28500 (epoch 0.146), train_loss = 3.25973715, grad/param norm = 5.3472e-01, time/batch = 0.6793s	
84/28500 (epoch 0.147), train_loss = 3.43705443, grad/param norm = 4.9601e-01, time/batch = 0.6788s	
85/28500 (epoch 0.149), train_loss = 3.32463081, grad/param norm = 5.8317e-01, time/batch = 0.6933s	
86/28500 (epoch 0.151), train_loss = 3.49926628, grad/param norm = 4.5149e-01, time/batch = 0.6906s	
87/28500 (epoch 0.153), train_loss = 3.46488970, grad/param norm = 5.9412e-01, time/batch = 0.6800s	
88/28500 (epoch 0.154), train_loss = 3.43647844, grad/param norm = 5.5796e-01, time/batch = 0.6855s	
89/28500 (epoch 0.156), train_loss = 3.39603794, grad/param norm = 4.7995e-01, time/batch = 0.6830s	
90/28500 (epoch 0.158), train_loss = 3.41503915, grad/param norm = 4.8536e-01, time/batch = 0.6780s	
91/28500 (epoch 0.160), train_loss = 3.34376785, grad/param norm = 4.6218e-01, time/batch = 0.6846s	
92/28500 (epoch 0.161), train_loss = 3.36217672, grad/param norm = 6.3012e-01, time/batch = 0.6819s	
93/28500 (epoch 0.163), train_loss = 3.45783243, grad/param norm = 7.1481e-01, time/batch = 0.6855s	
94/28500 (epoch 0.165), train_loss = 3.32088403, grad/param norm = 5.3500e-01, time/batch = 0.6799s	
95/28500 (epoch 0.167), train_loss = 3.29705046, grad/param norm = 5.5511e-01, time/batch = 0.6794s	
96/28500 (epoch 0.168), train_loss = 3.34390107, grad/param norm = 5.8490e-01, time/batch = 0.6792s	
97/28500 (epoch 0.170), train_loss = 3.36869358, grad/param norm = 6.1304e-01, time/batch = 0.6778s	
98/28500 (epoch 0.172), train_loss = 3.39337492, grad/param norm = 5.4607e-01, time/batch = 0.6789s	
99/28500 (epoch 0.174), train_loss = 3.50618861, grad/param norm = 6.3868e-01, time/batch = 0.6788s	
100/28500 (epoch 0.175), train_loss = 3.37411357, grad/param norm = 5.2004e-01, time/batch = 0.6802s	
101/28500 (epoch 0.177), train_loss = 3.44492884, grad/param norm = 4.7668e-01, time/batch = 0.6839s	
102/28500 (epoch 0.179), train_loss = 3.30839690, grad/param norm = 4.5720e-01, time/batch = 0.6795s	
103/28500 (epoch 0.181), train_loss = 3.45814365, grad/param norm = 5.9038e-01, time/batch = 0.6802s	
104/28500 (epoch 0.182), train_loss = 3.36388202, grad/param norm = 8.4054e-01, time/batch = 0.6781s	
105/28500 (epoch 0.184), train_loss = 3.31903931, grad/param norm = 7.4799e-01, time/batch = 0.6796s	
106/28500 (epoch 0.186), train_loss = 3.24670448, grad/param norm = 3.8110e-01, time/batch = 0.6801s	
107/28500 (epoch 0.188), train_loss = 3.55586446, grad/param norm = 4.0748e-01, time/batch = 0.7008s	
108/28500 (epoch 0.189), train_loss = 3.29613900, grad/param norm = 7.1337e-01, time/batch = 0.6820s	
109/28500 (epoch 0.191), train_loss = 3.33809002, grad/param norm = 4.9708e-01, time/batch = 0.6786s	
110/28500 (epoch 0.193), train_loss = 3.29680748, grad/param norm = 4.3254e-01, time/batch = 0.6801s	
111/28500 (epoch 0.195), train_loss = 3.47681362, grad/param norm = 5.4228e-01, time/batch = 0.6810s	
112/28500 (epoch 0.196), train_loss = 3.45091488, grad/param norm = 5.2463e-01, time/batch = 0.6794s	
113/28500 (epoch 0.198), train_loss = 3.25183924, grad/param norm = 4.7961e-01, time/batch = 0.6794s	
114/28500 (epoch 0.200), train_loss = 3.37839697, grad/param norm = 8.3593e-01, time/batch = 0.6782s	
115/28500 (epoch 0.202), train_loss = 3.47812398, grad/param norm = 8.4653e-01, time/batch = 0.6801s	
116/28500 (epoch 0.204), train_loss = 3.20384216, grad/param norm = 4.7808e-01, time/batch = 0.6799s	
117/28500 (epoch 0.205), train_loss = 3.32253695, grad/param norm = 4.1223e-01, time/batch = 0.6802s	
118/28500 (epoch 0.207), train_loss = 3.37251433, grad/param norm = 4.8537e-01, time/batch = 0.6804s	
119/28500 (epoch 0.209), train_loss = 3.33486991, grad/param norm = 3.6764e-01, time/batch = 0.6780s	
120/28500 (epoch 0.211), train_loss = 3.44676729, grad/param norm = 3.8321e-01, time/batch = 0.6812s	
121/28500 (epoch 0.212), train_loss = 3.23289959, grad/param norm = 5.1843e-01, time/batch = 0.6820s	
122/28500 (epoch 0.214), train_loss = 3.30980110, grad/param norm = 7.9125e-01, time/batch = 0.6807s	
123/28500 (epoch 0.216), train_loss = 3.34062287, grad/param norm = 1.0327e+00, time/batch = 0.6797s	
124/28500 (epoch 0.218), train_loss = 3.30208043, grad/param norm = 9.0310e-01, time/batch = 0.6801s	
125/28500 (epoch 0.219), train_loss = 3.30873210, grad/param norm = 6.9709e-01, time/batch = 0.6829s	
126/28500 (epoch 0.221), train_loss = 3.26616912, grad/param norm = 4.1859e-01, time/batch = 0.6813s	
127/28500 (epoch 0.223), train_loss = 3.26345251, grad/param norm = 4.4642e-01, time/batch = 0.6794s	
128/28500 (epoch 0.225), train_loss = 3.37604041, grad/param norm = 5.1346e-01, time/batch = 0.6778s	
129/28500 (epoch 0.226), train_loss = 3.26687380, grad/param norm = 4.2760e-01, time/batch = 0.6754s	
130/28500 (epoch 0.228), train_loss = 3.32324273, grad/param norm = 6.2257e-01, time/batch = 0.6771s	
131/28500 (epoch 0.230), train_loss = 3.25972029, grad/param norm = 1.1443e+00, time/batch = 0.6829s	
132/28500 (epoch 0.232), train_loss = 3.27297709, grad/param norm = 1.2936e+00, time/batch = 0.6799s	
133/28500 (epoch 0.233), train_loss = 3.23605190, grad/param norm = 5.6380e-01, time/batch = 0.6790s	
134/28500 (epoch 0.235), train_loss = 3.17592101, grad/param norm = 4.0999e-01, time/batch = 0.6772s	
135/28500 (epoch 0.237), train_loss = 3.26470217, grad/param norm = 3.4578e-01, time/batch = 0.6802s	
136/28500 (epoch 0.239), train_loss = 3.17285131, grad/param norm = 4.8789e-01, time/batch = 0.6790s	
137/28500 (epoch 0.240), train_loss = 3.14459479, grad/param norm = 6.2748e-01, time/batch = 0.6763s	
138/28500 (epoch 0.242), train_loss = 3.18572568, grad/param norm = 6.5978e-01, time/batch = 0.6799s	
139/28500 (epoch 0.244), train_loss = 3.09938843, grad/param norm = 6.9805e-01, time/batch = 0.6850s	
140/28500 (epoch 0.246), train_loss = 3.16190117, grad/param norm = 7.2894e-01, time/batch = 0.6786s	
141/28500 (epoch 0.247), train_loss = 3.22742734, grad/param norm = 1.1377e+00, time/batch = 0.6817s	
142/28500 (epoch 0.249), train_loss = 3.26249764, grad/param norm = 1.1331e+00, time/batch = 0.6777s	
143/28500 (epoch 0.251), train_loss = 3.16636432, grad/param norm = 8.0904e-01, time/batch = 0.6837s	
144/28500 (epoch 0.253), train_loss = 3.07517215, grad/param norm = 7.2265e-01, time/batch = 0.6832s	
145/28500 (epoch 0.254), train_loss = 3.12653811, grad/param norm = 6.4361e-01, time/batch = 0.6823s	
146/28500 (epoch 0.256), train_loss = 3.10652593, grad/param norm = 5.4059e-01, time/batch = 0.6783s	
147/28500 (epoch 0.258), train_loss = 3.21345161, grad/param norm = 5.7212e-01, time/batch = 0.6771s	
148/28500 (epoch 0.260), train_loss = 3.07305363, grad/param norm = 8.1992e-01, time/batch = 0.6788s	
149/28500 (epoch 0.261), train_loss = 3.07421840, grad/param norm = 9.8495e-01, time/batch = 0.6772s	
150/28500 (epoch 0.263), train_loss = 3.09165853, grad/param norm = 6.7922e-01, time/batch = 0.6816s	
151/28500 (epoch 0.265), train_loss = 3.19058019, grad/param norm = 3.3962e-01, time/batch = 0.6816s	
152/28500 (epoch 0.267), train_loss = 3.07870941, grad/param norm = 4.0585e-01, time/batch = 0.6810s	
153/28500 (epoch 0.268), train_loss = 3.03519012, grad/param norm = 4.7876e-01, time/batch = 0.6766s	
154/28500 (epoch 0.270), train_loss = 3.10189126, grad/param norm = 7.8268e-01, time/batch = 0.6772s	
155/28500 (epoch 0.272), train_loss = 2.97907366, grad/param norm = 1.0732e+00, time/batch = 0.6796s	
156/28500 (epoch 0.274), train_loss = 3.17474728, grad/param norm = 1.0549e+00, time/batch = 0.6783s	
157/28500 (epoch 0.275), train_loss = 3.05833555, grad/param norm = 9.2039e-01, time/batch = 0.6757s	
158/28500 (epoch 0.277), train_loss = 3.07483673, grad/param norm = 6.7265e-01, time/batch = 0.6771s	
159/28500 (epoch 0.279), train_loss = 3.00574273, grad/param norm = 6.0340e-01, time/batch = 0.6792s	
160/28500 (epoch 0.281), train_loss = 2.96499312, grad/param norm = 8.9133e-01, time/batch = 0.6967s	
161/28500 (epoch 0.282), train_loss = 2.93457243, grad/param norm = 1.0918e+00, time/batch = 0.6883s	
162/28500 (epoch 0.284), train_loss = 2.99687412, grad/param norm = 7.8203e-01, time/batch = 0.6779s	
163/28500 (epoch 0.286), train_loss = 3.14439091, grad/param norm = 6.0055e-01, time/batch = 0.6879s	
164/28500 (epoch 0.288), train_loss = 3.04229621, grad/param norm = 5.5255e-01, time/batch = 0.6881s	
165/28500 (epoch 0.289), train_loss = 3.14223806, grad/param norm = 4.2736e-01, time/batch = 0.6822s	
166/28500 (epoch 0.291), train_loss = 2.85537492, grad/param norm = 4.4143e-01, time/batch = 0.6792s	
167/28500 (epoch 0.293), train_loss = 2.91797713, grad/param norm = 6.1940e-01, time/batch = 0.6794s	
168/28500 (epoch 0.295), train_loss = 2.96756192, grad/param norm = 5.6483e-01, time/batch = 0.6765s	
169/28500 (epoch 0.296), train_loss = 2.98642264, grad/param norm = 7.6196e-01, time/batch = 0.6789s	
170/28500 (epoch 0.298), train_loss = 2.96352656, grad/param norm = 8.8678e-01, time/batch = 0.6792s	
171/28500 (epoch 0.300), train_loss = 2.91086343, grad/param norm = 8.7365e-01, time/batch = 0.6816s	
172/28500 (epoch 0.302), train_loss = 2.93283333, grad/param norm = 8.9803e-01, time/batch = 0.6764s	
173/28500 (epoch 0.304), train_loss = 2.99239784, grad/param norm = 8.5390e-01, time/batch = 0.6798s	
174/28500 (epoch 0.305), train_loss = 2.93598630, grad/param norm = 8.9119e-01, time/batch = 0.6819s	
175/28500 (epoch 0.307), train_loss = 3.00918046, grad/param norm = 9.3094e-01, time/batch = 0.6762s	
176/28500 (epoch 0.309), train_loss = 3.05881875, grad/param norm = 9.3099e-01, time/batch = 0.6756s	
177/28500 (epoch 0.311), train_loss = 2.96140154, grad/param norm = 1.0615e+00, time/batch = 0.6758s	
178/28500 (epoch 0.312), train_loss = 2.79899549, grad/param norm = 8.4864e-01, time/batch = 0.6781s	
179/28500 (epoch 0.314), train_loss = 2.88548370, grad/param norm = 7.2745e-01, time/batch = 0.7007s	
180/28500 (epoch 0.316), train_loss = 2.86206083, grad/param norm = 5.1377e-01, time/batch = 0.6847s	
181/28500 (epoch 0.318), train_loss = 2.76501616, grad/param norm = 5.2578e-01, time/batch = 0.6788s	
182/28500 (epoch 0.319), train_loss = 2.87661841, grad/param norm = 7.2084e-01, time/batch = 0.6823s	
183/28500 (epoch 0.321), train_loss = 3.00570335, grad/param norm = 5.7690e-01, time/batch = 0.6792s	
184/28500 (epoch 0.323), train_loss = 2.87623622, grad/param norm = 5.0191e-01, time/batch = 0.6772s	
185/28500 (epoch 0.325), train_loss = 3.00809936, grad/param norm = 6.5176e-01, time/batch = 0.6811s	
186/28500 (epoch 0.326), train_loss = 2.95927234, grad/param norm = 6.4712e-01, time/batch = 0.6790s	
187/28500 (epoch 0.328), train_loss = 3.08862448, grad/param norm = 5.5180e-01, time/batch = 0.6811s	
188/28500 (epoch 0.330), train_loss = 2.87912882, grad/param norm = 9.3928e-01, time/batch = 0.6838s	
189/28500 (epoch 0.332), train_loss = 2.87004376, grad/param norm = 8.7418e-01, time/batch = 0.6836s	
190/28500 (epoch 0.333), train_loss = 2.91270652, grad/param norm = 6.8564e-01, time/batch = 0.6846s	
191/28500 (epoch 0.335), train_loss = 2.83801293, grad/param norm = 5.0344e-01, time/batch = 0.6979s	
192/28500 (epoch 0.337), train_loss = 2.94548869, grad/param norm = 3.7148e-01, time/batch = 0.6872s	
193/28500 (epoch 0.339), train_loss = 2.93246083, grad/param norm = 4.2712e-01, time/batch = 0.6854s	
194/28500 (epoch 0.340), train_loss = 2.88098904, grad/param norm = 6.2341e-01, time/batch = 0.6791s	
195/28500 (epoch 0.342), train_loss = 2.81683520, grad/param norm = 8.3002e-01, time/batch = 0.6796s	
196/28500 (epoch 0.344), train_loss = 2.88490696, grad/param norm = 1.0519e+00, time/batch = 0.6766s	
197/28500 (epoch 0.346), train_loss = 2.78896891, grad/param norm = 9.5825e-01, time/batch = 0.6947s	
198/28500 (epoch 0.347), train_loss = 2.84669480, grad/param norm = 5.9616e-01, time/batch = 0.7009s	
199/28500 (epoch 0.349), train_loss = 2.88411800, grad/param norm = 5.5763e-01, time/batch = 0.6862s	
200/28500 (epoch 0.351), train_loss = 2.77833418, grad/param norm = 6.2865e-01, time/batch = 0.6849s	
201/28500 (epoch 0.353), train_loss = 2.87386332, grad/param norm = 7.4834e-01, time/batch = 0.6783s	
202/28500 (epoch 0.354), train_loss = 2.94480318, grad/param norm = 1.0261e+00, time/batch = 0.6765s	
203/28500 (epoch 0.356), train_loss = 2.99657304, grad/param norm = 1.5118e+00, time/batch = 0.6767s	
204/28500 (epoch 0.358), train_loss = 2.93795462, grad/param norm = 8.5958e-01, time/batch = 0.6794s	
205/28500 (epoch 0.360), train_loss = 3.00429803, grad/param norm = 4.9819e-01, time/batch = 0.6809s	
206/28500 (epoch 0.361), train_loss = 2.93931757, grad/param norm = 6.1810e-01, time/batch = 0.6793s	
207/28500 (epoch 0.363), train_loss = 2.94919675, grad/param norm = 7.8802e-01, time/batch = 0.6837s	
208/28500 (epoch 0.365), train_loss = 2.79913781, grad/param norm = 6.3998e-01, time/batch = 0.6796s	
209/28500 (epoch 0.367), train_loss = 2.81440999, grad/param norm = 6.7870e-01, time/batch = 0.6820s	
210/28500 (epoch 0.368), train_loss = 2.74034000, grad/param norm = 8.1522e-01, time/batch = 0.6810s	
211/28500 (epoch 0.370), train_loss = 2.89837945, grad/param norm = 1.0067e+00, time/batch = 0.6858s	
212/28500 (epoch 0.372), train_loss = 2.77695309, grad/param norm = 5.3967e-01, time/batch = 0.6799s	
213/28500 (epoch 0.374), train_loss = 2.86113884, grad/param norm = 3.8251e-01, time/batch = 0.6834s	
214/28500 (epoch 0.375), train_loss = 2.84604375, grad/param norm = 4.9954e-01, time/batch = 0.6848s	
215/28500 (epoch 0.377), train_loss = 3.13365256, grad/param norm = 6.6615e-01, time/batch = 0.6811s	
216/28500 (epoch 0.379), train_loss = 2.78345894, grad/param norm = 1.5179e+00, time/batch = 0.6800s	
217/28500 (epoch 0.381), train_loss = 2.88149703, grad/param norm = 7.2815e-01, time/batch = 0.6830s	
218/28500 (epoch 0.382), train_loss = 2.92571160, grad/param norm = 6.6485e-01, time/batch = 0.6817s	
219/28500 (epoch 0.384), train_loss = 2.99361479, grad/param norm = 5.8683e-01, time/batch = 0.6807s	
220/28500 (epoch 0.386), train_loss = 2.75788611, grad/param norm = 4.6840e-01, time/batch = 0.6815s	
221/28500 (epoch 0.388), train_loss = 2.88882612, grad/param norm = 4.8477e-01, time/batch = 0.6851s	
222/28500 (epoch 0.389), train_loss = 2.83308080, grad/param norm = 4.1014e-01, time/batch = 0.6811s	
223/28500 (epoch 0.391), train_loss = 2.87456289, grad/param norm = 2.9993e-01, time/batch = 0.6812s	
224/28500 (epoch 0.393), train_loss = 2.64578375, grad/param norm = 4.4857e-01, time/batch = 0.6790s	
225/28500 (epoch 0.395), train_loss = 2.98113547, grad/param norm = 6.2166e-01, time/batch = 0.6819s	
226/28500 (epoch 0.396), train_loss = 2.94909818, grad/param norm = 7.7994e-01, time/batch = 0.6791s	
227/28500 (epoch 0.398), train_loss = 3.21338140, grad/param norm = 1.0075e+00, time/batch = 0.6796s	
228/28500 (epoch 0.400), train_loss = 3.13507319, grad/param norm = 1.9615e+00, time/batch = 0.6787s	
229/28500 (epoch 0.402), train_loss = 2.94095298, grad/param norm = 1.0564e+00, time/batch = 0.6796s	
230/28500 (epoch 0.404), train_loss = 2.90836186, grad/param norm = 5.5077e-01, time/batch = 0.6779s	
231/28500 (epoch 0.405), train_loss = 2.78528024, grad/param norm = 4.2174e-01, time/batch = 0.6890s	
232/28500 (epoch 0.407), train_loss = 2.85891918, grad/param norm = 4.4076e-01, time/batch = 0.6810s	
233/28500 (epoch 0.409), train_loss = 2.82786538, grad/param norm = 4.0528e-01, time/batch = 0.6844s	
234/28500 (epoch 0.411), train_loss = 2.80585665, grad/param norm = 5.1438e-01, time/batch = 0.6805s	
235/28500 (epoch 0.412), train_loss = 2.77203185, grad/param norm = 6.5912e-01, time/batch = 0.6862s	
236/28500 (epoch 0.414), train_loss = 2.91804934, grad/param norm = 7.8220e-01, time/batch = 0.6901s	
237/28500 (epoch 0.416), train_loss = 2.73618867, grad/param norm = 8.2209e-01, time/batch = 0.6912s	
238/28500 (epoch 0.418), train_loss = 2.86202426, grad/param norm = 6.6436e-01, time/batch = 0.6887s	
239/28500 (epoch 0.419), train_loss = 2.73002530, grad/param norm = 6.8478e-01, time/batch = 0.6871s	
240/28500 (epoch 0.421), train_loss = 2.70856484, grad/param norm = 6.7746e-01, time/batch = 0.6869s	
241/28500 (epoch 0.423), train_loss = 2.95143759, grad/param norm = 8.7125e-01, time/batch = 0.6860s	
242/28500 (epoch 0.425), train_loss = 2.83818360, grad/param norm = 7.1883e-01, time/batch = 0.6809s	
243/28500 (epoch 0.426), train_loss = 2.77947941, grad/param norm = 4.7606e-01, time/batch = 0.6784s	
244/28500 (epoch 0.428), train_loss = 2.85973649, grad/param norm = 6.1292e-01, time/batch = 0.6799s	
245/28500 (epoch 0.430), train_loss = 2.79060766, grad/param norm = 4.9410e-01, time/batch = 0.6802s	
246/28500 (epoch 0.432), train_loss = 2.96983164, grad/param norm = 4.5917e-01, time/batch = 0.6817s	
247/28500 (epoch 0.433), train_loss = 2.74247452, grad/param norm = 7.7155e-01, time/batch = 0.6887s	
248/28500 (epoch 0.435), train_loss = 2.75996202, grad/param norm = 9.0481e-01, time/batch = 0.6898s	
249/28500 (epoch 0.437), train_loss = 2.68461160, grad/param norm = 7.8772e-01, time/batch = 0.6823s	
250/28500 (epoch 0.439), train_loss = 2.77564649, grad/param norm = 7.4624e-01, time/batch = 0.6824s	
251/28500 (epoch 0.440), train_loss = 2.73285878, grad/param norm = 6.3986e-01, time/batch = 0.6849s	
252/28500 (epoch 0.442), train_loss = 2.70739335, grad/param norm = 5.0696e-01, time/batch = 0.6864s	
253/28500 (epoch 0.444), train_loss = 2.81679623, grad/param norm = 5.1396e-01, time/batch = 0.7022s	
254/28500 (epoch 0.446), train_loss = 2.67006222, grad/param norm = 7.7407e-01, time/batch = 0.6807s	
255/28500 (epoch 0.447), train_loss = 2.78817934, grad/param norm = 7.4317e-01, time/batch = 0.6823s	
256/28500 (epoch 0.449), train_loss = 2.75403758, grad/param norm = 6.9248e-01, time/batch = 0.6837s	
257/28500 (epoch 0.451), train_loss = 2.75762832, grad/param norm = 5.1237e-01, time/batch = 0.6819s	
258/28500 (epoch 0.453), train_loss = 2.73827349, grad/param norm = 3.0473e-01, time/batch = 0.6843s	
259/28500 (epoch 0.454), train_loss = 2.64272207, grad/param norm = 4.5090e-01, time/batch = 0.6808s	
260/28500 (epoch 0.456), train_loss = 2.98467914, grad/param norm = 8.4397e-01, time/batch = 0.6808s	
261/28500 (epoch 0.458), train_loss = 2.79325636, grad/param norm = 1.0567e+00, time/batch = 0.6838s	
262/28500 (epoch 0.460), train_loss = 2.89777376, grad/param norm = 8.6103e-01, time/batch = 0.6807s	
263/28500 (epoch 0.461), train_loss = 2.73369287, grad/param norm = 1.0512e+00, time/batch = 0.6821s	
264/28500 (epoch 0.463), train_loss = 2.67487684, grad/param norm = 8.2777e-01, time/batch = 0.6820s	
265/28500 (epoch 0.465), train_loss = 2.65921121, grad/param norm = 6.5869e-01, time/batch = 0.6810s	
266/28500 (epoch 0.467), train_loss = 2.80207749, grad/param norm = 6.1564e-01, time/batch = 0.6790s	
267/28500 (epoch 0.468), train_loss = 2.69426350, grad/param norm = 4.5212e-01, time/batch = 0.6803s	
268/28500 (epoch 0.470), train_loss = 2.69294761, grad/param norm = 5.6803e-01, time/batch = 0.6818s	
269/28500 (epoch 0.472), train_loss = 2.68815853, grad/param norm = 6.6545e-01, time/batch = 0.6801s	
270/28500 (epoch 0.474), train_loss = 2.81264620, grad/param norm = 6.1929e-01, time/batch = 0.6800s	
271/28500 (epoch 0.475), train_loss = 2.69870245, grad/param norm = 5.3064e-01, time/batch = 0.6822s	
272/28500 (epoch 0.477), train_loss = 2.61305224, grad/param norm = 4.2794e-01, time/batch = 0.6807s	
273/28500 (epoch 0.479), train_loss = 2.74886498, grad/param norm = 4.7770e-01, time/batch = 0.6789s	
274/28500 (epoch 0.481), train_loss = 2.70485291, grad/param norm = 4.5611e-01, time/batch = 0.6804s	
275/28500 (epoch 0.482), train_loss = 2.72246861, grad/param norm = 4.6407e-01, time/batch = 0.6795s	
276/28500 (epoch 0.484), train_loss = 2.66748292, grad/param norm = 8.3930e-01, time/batch = 0.6803s	
277/28500 (epoch 0.486), train_loss = 2.82499049, grad/param norm = 9.6319e-01, time/batch = 0.6806s	
278/28500 (epoch 0.488), train_loss = 2.66619020, grad/param norm = 9.4688e-01, time/batch = 0.6799s	
279/28500 (epoch 0.489), train_loss = 2.75629674, grad/param norm = 8.3786e-01, time/batch = 0.6866s	
280/28500 (epoch 0.491), train_loss = 2.60677907, grad/param norm = 5.4834e-01, time/batch = 0.6801s	
281/28500 (epoch 0.493), train_loss = 2.69093131, grad/param norm = 3.5415e-01, time/batch = 0.6852s	
282/28500 (epoch 0.495), train_loss = 2.65850815, grad/param norm = 4.3072e-01, time/batch = 0.6813s	
283/28500 (epoch 0.496), train_loss = 2.89031043, grad/param norm = 7.2405e-01, time/batch = 0.6802s	
284/28500 (epoch 0.498), train_loss = 2.72507379, grad/param norm = 8.1978e-01, time/batch = 0.6807s	
285/28500 (epoch 0.500), train_loss = 2.70223940, grad/param norm = 4.4213e-01, time/batch = 0.6780s	
286/28500 (epoch 0.502), train_loss = 2.62467687, grad/param norm = 4.1816e-01, time/batch = 0.6758s	
287/28500 (epoch 0.504), train_loss = 2.62209725, grad/param norm = 3.6298e-01, time/batch = 0.6755s	
288/28500 (epoch 0.505), train_loss = 2.69414361, grad/param norm = 4.5518e-01, time/batch = 0.6758s	
289/28500 (epoch 0.507), train_loss = 2.85971991, grad/param norm = 4.4030e-01, time/batch = 0.6830s	
290/28500 (epoch 0.509), train_loss = 2.73153520, grad/param norm = 6.3891e-01, time/batch = 0.6935s	
291/28500 (epoch 0.511), train_loss = 2.86761250, grad/param norm = 7.9644e-01, time/batch = 0.6793s	
292/28500 (epoch 0.512), train_loss = 2.75748628, grad/param norm = 8.5566e-01, time/batch = 0.6856s	
293/28500 (epoch 0.514), train_loss = 2.70112100, grad/param norm = 6.0319e-01, time/batch = 0.6829s	
294/28500 (epoch 0.516), train_loss = 2.73033491, grad/param norm = 4.4322e-01, time/batch = 0.6811s	
295/28500 (epoch 0.518), train_loss = 2.64554067, grad/param norm = 3.4624e-01, time/batch = 0.6797s	
296/28500 (epoch 0.519), train_loss = 2.82606046, grad/param norm = 4.3803e-01, time/batch = 0.6824s	
297/28500 (epoch 0.521), train_loss = 2.74735605, grad/param norm = 4.8554e-01, time/batch = 0.6866s	
298/28500 (epoch 0.523), train_loss = 2.66212236, grad/param norm = 5.3349e-01, time/batch = 0.6932s	
299/28500 (epoch 0.525), train_loss = 2.66754318, grad/param norm = 7.2872e-01, time/batch = 0.6928s	
300/28500 (epoch 0.526), train_loss = 2.60120475, grad/param norm = 6.2490e-01, time/batch = 0.6935s	
301/28500 (epoch 0.528), train_loss = 2.81561138, grad/param norm = 6.0292e-01, time/batch = 0.6949s	
302/28500 (epoch 0.530), train_loss = 2.72070586, grad/param norm = 7.4588e-01, time/batch = 0.6954s	
303/28500 (epoch 0.532), train_loss = 2.70055960, grad/param norm = 8.4016e-01, time/batch = 0.6929s	
304/28500 (epoch 0.533), train_loss = 2.68407834, grad/param norm = 6.5367e-01, time/batch = 0.6924s	
305/28500 (epoch 0.535), train_loss = 2.55833133, grad/param norm = 5.4187e-01, time/batch = 0.6933s	
306/28500 (epoch 0.537), train_loss = 2.63437495, grad/param norm = 6.8565e-01, time/batch = 0.6939s	
307/28500 (epoch 0.539), train_loss = 2.73247383, grad/param norm = 7.8940e-01, time/batch = 0.6923s	
308/28500 (epoch 0.540), train_loss = 2.61855124, grad/param norm = 9.2101e-01, time/batch = 0.6921s	
309/28500 (epoch 0.542), train_loss = 2.92062090, grad/param norm = 1.0183e+00, time/batch = 0.6923s	
310/28500 (epoch 0.544), train_loss = 2.80341444, grad/param norm = 7.2129e-01, time/batch = 0.6926s	
311/28500 (epoch 0.546), train_loss = 2.65702386, grad/param norm = 4.2318e-01, time/batch = 0.6934s	
312/28500 (epoch 0.547), train_loss = 2.69848215, grad/param norm = 3.5690e-01, time/batch = 0.6940s	
313/28500 (epoch 0.549), train_loss = 2.69106890, grad/param norm = 3.6020e-01, time/batch = 0.6946s	
314/28500 (epoch 0.551), train_loss = 2.94255117, grad/param norm = 5.7773e-01, time/batch = 0.6944s	
315/28500 (epoch 0.553), train_loss = 2.80910308, grad/param norm = 7.9017e-01, time/batch = 0.6929s	
316/28500 (epoch 0.554), train_loss = 2.71676109, grad/param norm = 6.2990e-01, time/batch = 0.6932s	
317/28500 (epoch 0.556), train_loss = 2.76289796, grad/param norm = 3.2189e-01, time/batch = 0.6941s	
318/28500 (epoch 0.558), train_loss = 2.68720758, grad/param norm = 3.6971e-01, time/batch = 0.6910s	
319/28500 (epoch 0.560), train_loss = 2.63351613, grad/param norm = 4.9304e-01, time/batch = 0.6932s	
320/28500 (epoch 0.561), train_loss = 2.68500250, grad/param norm = 4.5640e-01, time/batch = 0.6914s	
321/28500 (epoch 0.563), train_loss = 2.61509211, grad/param norm = 4.4500e-01, time/batch = 0.6947s	
322/28500 (epoch 0.565), train_loss = 2.67935362, grad/param norm = 4.5558e-01, time/batch = 0.6947s	
323/28500 (epoch 0.567), train_loss = 2.59530775, grad/param norm = 6.3699e-01, time/batch = 0.6927s	
324/28500 (epoch 0.568), train_loss = 2.78588212, grad/param norm = 5.3979e-01, time/batch = 0.6934s	
325/28500 (epoch 0.570), train_loss = 2.74114754, grad/param norm = 6.4421e-01, time/batch = 0.6928s	
326/28500 (epoch 0.572), train_loss = 2.66462657, grad/param norm = 7.3310e-01, time/batch = 0.6936s	
327/28500 (epoch 0.574), train_loss = 2.78089170, grad/param norm = 5.2277e-01, time/batch = 0.6924s	
328/28500 (epoch 0.575), train_loss = 2.53971368, grad/param norm = 7.2769e-01, time/batch = 0.6949s	
329/28500 (epoch 0.577), train_loss = 2.55879381, grad/param norm = 8.1897e-01, time/batch = 0.6947s	
330/28500 (epoch 0.579), train_loss = 2.92996296, grad/param norm = 7.0129e-01, time/batch = 0.6922s	
331/28500 (epoch 0.581), train_loss = 2.67436951, grad/param norm = 6.6999e-01, time/batch = 0.6953s	
332/28500 (epoch 0.582), train_loss = 2.63698051, grad/param norm = 5.9990e-01, time/batch = 0.6952s	
333/28500 (epoch 0.584), train_loss = 2.51482438, grad/param norm = 3.9337e-01, time/batch = 0.6948s	
334/28500 (epoch 0.586), train_loss = 2.49308596, grad/param norm = 4.1887e-01, time/batch = 0.6957s	
335/28500 (epoch 0.588), train_loss = 2.65415225, grad/param norm = 4.1917e-01, time/batch = 0.7094s	
336/28500 (epoch 0.589), train_loss = 2.88549833, grad/param norm = 5.1786e-01, time/batch = 0.6988s	
337/28500 (epoch 0.591), train_loss = 2.70340261, grad/param norm = 3.9698e-01, time/batch = 0.7084s	
338/28500 (epoch 0.593), train_loss = 2.50970312, grad/param norm = 3.2683e-01, time/batch = 0.7013s	
339/28500 (epoch 0.595), train_loss = 2.66594829, grad/param norm = 4.3190e-01, time/batch = 0.7033s	
340/28500 (epoch 0.596), train_loss = 2.59402157, grad/param norm = 5.6299e-01, time/batch = 0.6940s	
341/28500 (epoch 0.598), train_loss = 2.63277258, grad/param norm = 4.6026e-01, time/batch = 0.6909s	
342/28500 (epoch 0.600), train_loss = 2.69957504, grad/param norm = 4.5850e-01, time/batch = 0.6908s	
343/28500 (epoch 0.602), train_loss = 2.70615847, grad/param norm = 4.9829e-01, time/batch = 0.6896s	
344/28500 (epoch 0.604), train_loss = 2.58559334, grad/param norm = 6.3077e-01, time/batch = 0.6901s	
345/28500 (epoch 0.605), train_loss = 2.59311399, grad/param norm = 6.1880e-01, time/batch = 0.7016s	
346/28500 (epoch 0.607), train_loss = 2.57462510, grad/param norm = 7.4527e-01, time/batch = 0.7000s	
347/28500 (epoch 0.609), train_loss = 2.64501014, grad/param norm = 5.8106e-01, time/batch = 0.6898s	
348/28500 (epoch 0.611), train_loss = 2.70152322, grad/param norm = 3.7053e-01, time/batch = 0.6921s	
349/28500 (epoch 0.612), train_loss = 2.73936667, grad/param norm = 3.9707e-01, time/batch = 0.6908s	
350/28500 (epoch 0.614), train_loss = 2.57825323, grad/param norm = 3.7345e-01, time/batch = 0.6891s	
351/28500 (epoch 0.616), train_loss = 2.52481022, grad/param norm = 3.7841e-01, time/batch = 0.6921s	
352/28500 (epoch 0.618), train_loss = 2.42858412, grad/param norm = 4.0597e-01, time/batch = 0.6899s	
353/28500 (epoch 0.619), train_loss = 2.59637676, grad/param norm = 4.7129e-01, time/batch = 0.6904s	
354/28500 (epoch 0.621), train_loss = 2.52251082, grad/param norm = 6.6321e-01, time/batch = 0.6907s	
355/28500 (epoch 0.623), train_loss = 2.66051478, grad/param norm = 9.4802e-01, time/batch = 0.6901s	
356/28500 (epoch 0.625), train_loss = 2.60306581, grad/param norm = 8.3230e-01, time/batch = 0.6892s	
357/28500 (epoch 0.626), train_loss = 2.46961077, grad/param norm = 5.8675e-01, time/batch = 0.6894s	
358/28500 (epoch 0.628), train_loss = 2.51864933, grad/param norm = 4.8849e-01, time/batch = 0.6980s	
359/28500 (epoch 0.630), train_loss = 2.52636232, grad/param norm = 3.5189e-01, time/batch = 0.7043s	
360/28500 (epoch 0.632), train_loss = 2.64347439, grad/param norm = 3.5399e-01, time/batch = 0.6976s	
361/28500 (epoch 0.633), train_loss = 2.51043307, grad/param norm = 3.5147e-01, time/batch = 0.6992s	
362/28500 (epoch 0.635), train_loss = 2.76543924, grad/param norm = 4.9531e-01, time/batch = 0.6933s	
363/28500 (epoch 0.637), train_loss = 2.63505312, grad/param norm = 6.7707e-01, time/batch = 0.6902s	
364/28500 (epoch 0.639), train_loss = 2.50677142, grad/param norm = 4.9160e-01, time/batch = 0.6914s	
365/28500 (epoch 0.640), train_loss = 2.58700903, grad/param norm = 4.6683e-01, time/batch = 0.6934s	
366/28500 (epoch 0.642), train_loss = 2.69570981, grad/param norm = 4.6431e-01, time/batch = 0.6917s	
367/28500 (epoch 0.644), train_loss = 2.86410431, grad/param norm = 4.8936e-01, time/batch = 0.6921s	
368/28500 (epoch 0.646), train_loss = 2.60390524, grad/param norm = 6.0177e-01, time/batch = 0.6910s	
369/28500 (epoch 0.647), train_loss = 2.62193239, grad/param norm = 5.4747e-01, time/batch = 0.6923s	
370/28500 (epoch 0.649), train_loss = 2.61793206, grad/param norm = 4.5143e-01, time/batch = 0.6926s	
371/28500 (epoch 0.651), train_loss = 2.62623595, grad/param norm = 5.7807e-01, time/batch = 0.6941s	
372/28500 (epoch 0.653), train_loss = 2.60494693, grad/param norm = 5.3747e-01, time/batch = 0.6787s	
373/28500 (epoch 0.654), train_loss = 2.67495494, grad/param norm = 3.4720e-01, time/batch = 0.6789s	
374/28500 (epoch 0.656), train_loss = 2.61778348, grad/param norm = 3.3996e-01, time/batch = 0.6838s	
375/28500 (epoch 0.658), train_loss = 2.62784150, grad/param norm = 3.6325e-01, time/batch = 0.6833s	
376/28500 (epoch 0.660), train_loss = 2.68273077, grad/param norm = 4.5928e-01, time/batch = 0.7006s	
377/28500 (epoch 0.661), train_loss = 2.63266001, grad/param norm = 4.2711e-01, time/batch = 0.6957s	
378/28500 (epoch 0.663), train_loss = 2.61495657, grad/param norm = 3.5689e-01, time/batch = 0.6966s	
379/28500 (epoch 0.665), train_loss = 2.60330072, grad/param norm = 4.3162e-01, time/batch = 0.6960s	
380/28500 (epoch 0.667), train_loss = 2.43317967, grad/param norm = 6.6360e-01, time/batch = 0.6937s	
381/28500 (epoch 0.668), train_loss = 2.51578568, grad/param norm = 6.2872e-01, time/batch = 0.6965s	
382/28500 (epoch 0.670), train_loss = 2.48391927, grad/param norm = 4.7821e-01, time/batch = 0.6970s	
383/28500 (epoch 0.672), train_loss = 2.50909801, grad/param norm = 4.8986e-01, time/batch = 0.6947s	
384/28500 (epoch 0.674), train_loss = 2.53158775, grad/param norm = 3.8302e-01, time/batch = 0.6928s	
385/28500 (epoch 0.675), train_loss = 2.38285506, grad/param norm = 2.9516e-01, time/batch = 0.6799s	
386/28500 (epoch 0.677), train_loss = 2.55861555, grad/param norm = 3.5722e-01, time/batch = 0.6860s	
387/28500 (epoch 0.679), train_loss = 2.55588566, grad/param norm = 3.4996e-01, time/batch = 0.7014s	
388/28500 (epoch 0.681), train_loss = 2.66736031, grad/param norm = 4.7535e-01, time/batch = 0.6916s	
389/28500 (epoch 0.682), train_loss = 2.48234977, grad/param norm = 4.9445e-01, time/batch = 0.6915s	
390/28500 (epoch 0.684), train_loss = 2.60852206, grad/param norm = 6.7046e-01, time/batch = 0.6926s	
391/28500 (epoch 0.686), train_loss = 2.51539919, grad/param norm = 9.8678e-01, time/batch = 0.6954s	
392/28500 (epoch 0.688), train_loss = 2.48024731, grad/param norm = 7.3939e-01, time/batch = 0.6913s	
393/28500 (epoch 0.689), train_loss = 2.61283275, grad/param norm = 4.8766e-01, time/batch = 0.6914s	
394/28500 (epoch 0.691), train_loss = 2.48252140, grad/param norm = 4.0022e-01, time/batch = 0.6908s	
395/28500 (epoch 0.693), train_loss = 2.49565190, grad/param norm = 5.0409e-01, time/batch = 0.6910s	
396/28500 (epoch 0.695), train_loss = 2.58304625, grad/param norm = 4.4644e-01, time/batch = 0.6923s	
397/28500 (epoch 0.696), train_loss = 2.59380757, grad/param norm = 3.5032e-01, time/batch = 0.6890s	
398/28500 (epoch 0.698), train_loss = 2.47098389, grad/param norm = 3.2315e-01, time/batch = 0.6903s	
399/28500 (epoch 0.700), train_loss = 2.42383042, grad/param norm = 3.4917e-01, time/batch = 0.6901s	
400/28500 (epoch 0.702), train_loss = 2.50423155, grad/param norm = 3.4198e-01, time/batch = 0.6895s	
401/28500 (epoch 0.704), train_loss = 2.37241307, grad/param norm = 4.5406e-01, time/batch = 0.6951s	
402/28500 (epoch 0.705), train_loss = 2.48548471, grad/param norm = 5.0735e-01, time/batch = 0.6948s	
403/28500 (epoch 0.707), train_loss = 2.64758290, grad/param norm = 5.0516e-01, time/batch = 0.6929s	
404/28500 (epoch 0.709), train_loss = 2.55168470, grad/param norm = 5.7720e-01, time/batch = 0.6892s	
405/28500 (epoch 0.711), train_loss = 2.42931599, grad/param norm = 5.6880e-01, time/batch = 0.6956s	
406/28500 (epoch 0.712), train_loss = 2.40112035, grad/param norm = 5.6622e-01, time/batch = 0.7063s	
407/28500 (epoch 0.714), train_loss = 2.48955750, grad/param norm = 4.7958e-01, time/batch = 0.6972s	
408/28500 (epoch 0.716), train_loss = 2.58556517, grad/param norm = 3.4700e-01, time/batch = 0.6897s	
409/28500 (epoch 0.718), train_loss = 2.47351350, grad/param norm = 3.3152e-01, time/batch = 0.6905s	
410/28500 (epoch 0.719), train_loss = 2.49024090, grad/param norm = 3.7668e-01, time/batch = 0.6895s	
411/28500 (epoch 0.721), train_loss = 2.44904010, grad/param norm = 4.5845e-01, time/batch = 0.6919s	
412/28500 (epoch 0.723), train_loss = 2.48719879, grad/param norm = 4.1685e-01, time/batch = 0.6917s	
413/28500 (epoch 0.725), train_loss = 2.63397084, grad/param norm = 3.5153e-01, time/batch = 0.6911s	
414/28500 (epoch 0.726), train_loss = 2.51099625, grad/param norm = 3.7775e-01, time/batch = 0.6894s	
415/28500 (epoch 0.728), train_loss = 2.46640653, grad/param norm = 3.7795e-01, time/batch = 0.6906s	
416/28500 (epoch 0.730), train_loss = 2.54745697, grad/param norm = 3.2815e-01, time/batch = 0.6905s	
417/28500 (epoch 0.732), train_loss = 2.42707984, grad/param norm = 3.5244e-01, time/batch = 0.6894s	
418/28500 (epoch 0.733), train_loss = 2.48472197, grad/param norm = 5.9341e-01, time/batch = 0.6895s	
419/28500 (epoch 0.735), train_loss = 2.58481303, grad/param norm = 7.6319e-01, time/batch = 0.6949s	
420/28500 (epoch 0.737), train_loss = 2.48707351, grad/param norm = 7.7277e-01, time/batch = 0.7001s	
421/28500 (epoch 0.739), train_loss = 2.47986400, grad/param norm = 6.5972e-01, time/batch = 0.7217s	
422/28500 (epoch 0.740), train_loss = 2.52723456, grad/param norm = 4.6356e-01, time/batch = 0.7124s	
423/28500 (epoch 0.742), train_loss = 2.49099912, grad/param norm = 3.3752e-01, time/batch = 0.7001s	
424/28500 (epoch 0.744), train_loss = 2.46638382, grad/param norm = 2.9492e-01, time/batch = 0.7021s	
425/28500 (epoch 0.746), train_loss = 2.40958741, grad/param norm = 3.9130e-01, time/batch = 0.7026s	
426/28500 (epoch 0.747), train_loss = 2.45988387, grad/param norm = 3.8431e-01, time/batch = 0.7040s	
427/28500 (epoch 0.749), train_loss = 2.71064200, grad/param norm = 5.0372e-01, time/batch = 0.7124s	
428/28500 (epoch 0.751), train_loss = 2.45921277, grad/param norm = 4.4424e-01, time/batch = 0.7076s	
429/28500 (epoch 0.753), train_loss = 2.32778659, grad/param norm = 5.7352e-01, time/batch = 0.7006s	
430/28500 (epoch 0.754), train_loss = 2.50744202, grad/param norm = 5.5961e-01, time/batch = 0.6942s	
431/28500 (epoch 0.756), train_loss = 2.64413814, grad/param norm = 4.8254e-01, time/batch = 0.6959s	
432/28500 (epoch 0.758), train_loss = 2.49108188, grad/param norm = 4.2215e-01, time/batch = 0.7026s	
433/28500 (epoch 0.760), train_loss = 2.50289557, grad/param norm = 4.6651e-01, time/batch = 0.7009s	
434/28500 (epoch 0.761), train_loss = 2.58590568, grad/param norm = 5.1205e-01, time/batch = 0.6939s	
435/28500 (epoch 0.763), train_loss = 2.42383251, grad/param norm = 6.5093e-01, time/batch = 0.6957s	
436/28500 (epoch 0.765), train_loss = 2.42398923, grad/param norm = 4.2667e-01, time/batch = 0.6974s	
437/28500 (epoch 0.767), train_loss = 2.44629226, grad/param norm = 3.5235e-01, time/batch = 0.6967s	
438/28500 (epoch 0.768), train_loss = 2.50391027, grad/param norm = 4.7238e-01, time/batch = 0.6928s	
439/28500 (epoch 0.770), train_loss = 2.46675669, grad/param norm = 4.4144e-01, time/batch = 0.6927s	
440/28500 (epoch 0.772), train_loss = 2.39831456, grad/param norm = 3.8668e-01, time/batch = 0.6944s	
441/28500 (epoch 0.774), train_loss = 2.40132659, grad/param norm = 3.5948e-01, time/batch = 0.7029s	
442/28500 (epoch 0.775), train_loss = 2.54312846, grad/param norm = 3.4709e-01, time/batch = 0.6986s	
443/28500 (epoch 0.777), train_loss = 2.39517412, grad/param norm = 3.7354e-01, time/batch = 0.6940s	
444/28500 (epoch 0.779), train_loss = 2.54603878, grad/param norm = 5.4490e-01, time/batch = 0.6981s	
445/28500 (epoch 0.781), train_loss = 2.54289109, grad/param norm = 5.2849e-01, time/batch = 0.6959s	
446/28500 (epoch 0.782), train_loss = 2.53849547, grad/param norm = 4.6157e-01, time/batch = 0.6942s	
447/28500 (epoch 0.784), train_loss = 2.42784189, grad/param norm = 4.0161e-01, time/batch = 0.6980s	
448/28500 (epoch 0.786), train_loss = 2.50667029, grad/param norm = 3.9590e-01, time/batch = 0.6964s	
449/28500 (epoch 0.788), train_loss = 2.68100645, grad/param norm = 3.0870e-01, time/batch = 0.6997s	
450/28500 (epoch 0.789), train_loss = 2.46294818, grad/param norm = 5.8342e-01, time/batch = 0.6932s	
451/28500 (epoch 0.791), train_loss = 2.43552643, grad/param norm = 6.1578e-01, time/batch = 0.6987s	
452/28500 (epoch 0.793), train_loss = 2.26012175, grad/param norm = 5.5747e-01, time/batch = 0.6970s	
453/28500 (epoch 0.795), train_loss = 2.49618551, grad/param norm = 5.1213e-01, time/batch = 0.6977s	
454/28500 (epoch 0.796), train_loss = 2.37434950, grad/param norm = 4.9283e-01, time/batch = 0.7035s	
455/28500 (epoch 0.798), train_loss = 2.47437925, grad/param norm = 4.8705e-01, time/batch = 0.6976s	
456/28500 (epoch 0.800), train_loss = 2.44563429, grad/param norm = 4.4980e-01, time/batch = 0.6986s	
457/28500 (epoch 0.802), train_loss = 2.56826940, grad/param norm = 3.8025e-01, time/batch = 0.6935s	
458/28500 (epoch 0.804), train_loss = 2.42528101, grad/param norm = 3.8566e-01, time/batch = 0.6958s	
459/28500 (epoch 0.805), train_loss = 2.50326746, grad/param norm = 3.4393e-01, time/batch = 0.6956s	
460/28500 (epoch 0.807), train_loss = 2.62990907, grad/param norm = 3.6660e-01, time/batch = 0.7023s	
461/28500 (epoch 0.809), train_loss = 2.47306691, grad/param norm = 3.9465e-01, time/batch = 0.6947s	
462/28500 (epoch 0.811), train_loss = 2.55672055, grad/param norm = 3.4126e-01, time/batch = 0.6945s	
463/28500 (epoch 0.812), train_loss = 2.55682912, grad/param norm = 3.5025e-01, time/batch = 0.7031s	
464/28500 (epoch 0.814), train_loss = 2.48346953, grad/param norm = 4.2691e-01, time/batch = 0.7002s	
465/28500 (epoch 0.816), train_loss = 2.51899521, grad/param norm = 4.2797e-01, time/batch = 0.6964s	
466/28500 (epoch 0.818), train_loss = 2.41564434, grad/param norm = 5.5494e-01, time/batch = 0.6955s	
467/28500 (epoch 0.819), train_loss = 2.48797749, grad/param norm = 6.1505e-01, time/batch = 0.6963s	
468/28500 (epoch 0.821), train_loss = 2.46989712, grad/param norm = 5.9317e-01, time/batch = 0.6951s	
469/28500 (epoch 0.823), train_loss = 2.61152971, grad/param norm = 4.4314e-01, time/batch = 0.6968s	
470/28500 (epoch 0.825), train_loss = 2.40734943, grad/param norm = 3.8013e-01, time/batch = 0.6958s	
471/28500 (epoch 0.826), train_loss = 2.44917725, grad/param norm = 3.4874e-01, time/batch = 0.7024s	
472/28500 (epoch 0.828), train_loss = 2.31310300, grad/param norm = 2.6148e-01, time/batch = 0.7020s	
473/28500 (epoch 0.830), train_loss = 2.38517707, grad/param norm = 3.0434e-01, time/batch = 0.7004s	
474/28500 (epoch 0.832), train_loss = 2.50325040, grad/param norm = 3.5008e-01, time/batch = 0.6985s	
475/28500 (epoch 0.833), train_loss = 2.51520144, grad/param norm = 4.1893e-01, time/batch = 0.6991s	
476/28500 (epoch 0.835), train_loss = 2.38214512, grad/param norm = 4.5905e-01, time/batch = 0.6990s	
477/28500 (epoch 0.837), train_loss = 2.44805990, grad/param norm = 4.8502e-01, time/batch = 0.6989s	
478/28500 (epoch 0.839), train_loss = 2.49857705, grad/param norm = 4.0328e-01, time/batch = 0.6978s	
479/28500 (epoch 0.840), train_loss = 2.51525946, grad/param norm = 4.6219e-01, time/batch = 0.6964s	
480/28500 (epoch 0.842), train_loss = 2.58045985, grad/param norm = 4.6529e-01, time/batch = 0.6976s	
481/28500 (epoch 0.844), train_loss = 2.48588568, grad/param norm = 3.5323e-01, time/batch = 0.6986s	
482/28500 (epoch 0.846), train_loss = 2.47516509, grad/param norm = 3.2782e-01, time/batch = 0.6954s	
483/28500 (epoch 0.847), train_loss = 2.36500984, grad/param norm = 3.0231e-01, time/batch = 0.6966s	
484/28500 (epoch 0.849), train_loss = 2.40340264, grad/param norm = 3.3437e-01, time/batch = 0.6951s	
485/28500 (epoch 0.851), train_loss = 2.30928980, grad/param norm = 3.7483e-01, time/batch = 0.6996s	
486/28500 (epoch 0.853), train_loss = 2.47269970, grad/param norm = 3.6422e-01, time/batch = 0.6987s	
487/28500 (epoch 0.854), train_loss = 2.36740009, grad/param norm = 3.6353e-01, time/batch = 0.6995s	
488/28500 (epoch 0.856), train_loss = 2.55146200, grad/param norm = 4.3584e-01, time/batch = 0.7008s	
489/28500 (epoch 0.858), train_loss = 2.34277086, grad/param norm = 3.8519e-01, time/batch = 0.7068s	
490/28500 (epoch 0.860), train_loss = 2.41632123, grad/param norm = 3.0464e-01, time/batch = 0.7123s	
491/28500 (epoch 0.861), train_loss = 2.35545210, grad/param norm = 3.9889e-01, time/batch = 0.7158s	
492/28500 (epoch 0.863), train_loss = 2.53502893, grad/param norm = 3.5553e-01, time/batch = 0.6995s	
493/28500 (epoch 0.865), train_loss = 2.39856167, grad/param norm = 4.5864e-01, time/batch = 0.6966s	
494/28500 (epoch 0.867), train_loss = 2.47047136, grad/param norm = 5.4341e-01, time/batch = 0.6936s	
495/28500 (epoch 0.868), train_loss = 2.17179805, grad/param norm = 3.7308e-01, time/batch = 0.6960s	
496/28500 (epoch 0.870), train_loss = 2.31515647, grad/param norm = 3.4731e-01, time/batch = 0.7044s	
497/28500 (epoch 0.872), train_loss = 2.59544333, grad/param norm = 3.5703e-01, time/batch = 0.7073s	
498/28500 (epoch 0.874), train_loss = 2.40422248, grad/param norm = 3.1533e-01, time/batch = 0.6980s	
499/28500 (epoch 0.875), train_loss = 2.42795984, grad/param norm = 3.5620e-01, time/batch = 0.6933s	
500/28500 (epoch 0.877), train_loss = 2.39003389, grad/param norm = 3.7489e-01, time/batch = 0.6941s	
501/28500 (epoch 0.879), train_loss = 2.38796752, grad/param norm = 3.6178e-01, time/batch = 0.7027s	
502/28500 (epoch 0.881), train_loss = 2.46416338, grad/param norm = 3.5155e-01, time/batch = 0.6950s	
503/28500 (epoch 0.882), train_loss = 2.31756670, grad/param norm = 4.2114e-01, time/batch = 0.6942s	
504/28500 (epoch 0.884), train_loss = 2.42172444, grad/param norm = 5.2602e-01, time/batch = 0.6972s	
505/28500 (epoch 0.886), train_loss = 2.30597228, grad/param norm = 5.9018e-01, time/batch = 0.6995s	
506/28500 (epoch 0.888), train_loss = 2.27899006, grad/param norm = 5.2035e-01, time/batch = 0.7119s	
507/28500 (epoch 0.889), train_loss = 2.22751247, grad/param norm = 4.5459e-01, time/batch = 0.6986s	
508/28500 (epoch 0.891), train_loss = 2.43018784, grad/param norm = 5.5239e-01, time/batch = 0.6950s	
509/28500 (epoch 0.893), train_loss = 2.61099417, grad/param norm = 4.2323e-01, time/batch = 0.6945s	
510/28500 (epoch 0.895), train_loss = 2.50146794, grad/param norm = 3.6740e-01, time/batch = 0.6939s	
511/28500 (epoch 0.896), train_loss = 2.44858752, grad/param norm = 3.5455e-01, time/batch = 0.6994s	
512/28500 (epoch 0.898), train_loss = 2.29484366, grad/param norm = 2.7807e-01, time/batch = 0.7009s	
513/28500 (epoch 0.900), train_loss = 2.31066960, grad/param norm = 3.2063e-01, time/batch = 0.6993s	
514/28500 (epoch 0.902), train_loss = 2.36857005, grad/param norm = 3.0924e-01, time/batch = 0.6969s	
515/28500 (epoch 0.904), train_loss = 2.31909058, grad/param norm = 3.0148e-01, time/batch = 0.7035s	
516/28500 (epoch 0.905), train_loss = 2.51458656, grad/param norm = 3.8406e-01, time/batch = 0.6937s	
517/28500 (epoch 0.907), train_loss = 2.56885418, grad/param norm = 3.8532e-01, time/batch = 0.6937s	
518/28500 (epoch 0.909), train_loss = 2.50442098, grad/param norm = 4.3929e-01, time/batch = 0.6943s	
519/28500 (epoch 0.911), train_loss = 2.35675582, grad/param norm = 3.4390e-01, time/batch = 0.6959s	
520/28500 (epoch 0.912), train_loss = 2.14772161, grad/param norm = 3.3127e-01, time/batch = 0.6940s	
521/28500 (epoch 0.914), train_loss = 2.50288860, grad/param norm = 5.0835e-01, time/batch = 0.7215s	
522/28500 (epoch 0.916), train_loss = 2.39688333, grad/param norm = 5.9766e-01, time/batch = 0.7058s	
523/28500 (epoch 0.918), train_loss = 2.50208820, grad/param norm = 4.4847e-01, time/batch = 0.7010s	
524/28500 (epoch 0.919), train_loss = 2.26365766, grad/param norm = 3.2876e-01, time/batch = 0.6985s	
525/28500 (epoch 0.921), train_loss = 2.46544741, grad/param norm = 4.0142e-01, time/batch = 0.6979s	
526/28500 (epoch 0.923), train_loss = 2.57923428, grad/param norm = 5.0099e-01, time/batch = 0.6980s	
527/28500 (epoch 0.925), train_loss = 2.34079174, grad/param norm = 4.3795e-01, time/batch = 0.6951s	
528/28500 (epoch 0.926), train_loss = 2.46446974, grad/param norm = 4.3531e-01, time/batch = 0.7028s	
529/28500 (epoch 0.928), train_loss = 2.33273867, grad/param norm = 3.5453e-01, time/batch = 0.6935s	
530/28500 (epoch 0.930), train_loss = 2.14678792, grad/param norm = 3.2252e-01, time/batch = 0.6934s	
531/28500 (epoch 0.932), train_loss = 2.23427166, grad/param norm = 3.9831e-01, time/batch = 0.6950s	
532/28500 (epoch 0.933), train_loss = 2.37029719, grad/param norm = 4.7539e-01, time/batch = 0.6941s	
533/28500 (epoch 0.935), train_loss = 2.29678294, grad/param norm = 3.9154e-01, time/batch = 0.6941s	
534/28500 (epoch 0.937), train_loss = 2.43242610, grad/param norm = 4.1467e-01, time/batch = 0.6933s	
535/28500 (epoch 0.939), train_loss = 2.49511845, grad/param norm = 4.7294e-01, time/batch = 0.6983s	
536/28500 (epoch 0.940), train_loss = 2.44712881, grad/param norm = 4.8915e-01, time/batch = 0.6929s	
537/28500 (epoch 0.942), train_loss = 2.50221997, grad/param norm = 5.0772e-01, time/batch = 0.6924s	
538/28500 (epoch 0.944), train_loss = 2.38969203, grad/param norm = 5.2228e-01, time/batch = 0.6925s	
539/28500 (epoch 0.946), train_loss = 2.47286507, grad/param norm = 4.2057e-01, time/batch = 0.6944s	
540/28500 (epoch 0.947), train_loss = 2.54914473, grad/param norm = 3.4395e-01, time/batch = 0.6970s	
541/28500 (epoch 0.949), train_loss = 2.31952074, grad/param norm = 3.5208e-01, time/batch = 0.6976s	
542/28500 (epoch 0.951), train_loss = 2.42602336, grad/param norm = 3.1872e-01, time/batch = 0.6973s	
543/28500 (epoch 0.953), train_loss = 2.35398467, grad/param norm = 3.4479e-01, time/batch = 0.6966s	
544/28500 (epoch 0.954), train_loss = 2.35984527, grad/param norm = 2.9618e-01, time/batch = 0.6974s	
545/28500 (epoch 0.956), train_loss = 2.40120981, grad/param norm = 3.4448e-01, time/batch = 0.6967s	
546/28500 (epoch 0.958), train_loss = 2.27572088, grad/param norm = 3.2075e-01, time/batch = 0.6961s	
547/28500 (epoch 0.960), train_loss = 2.37652581, grad/param norm = 4.6953e-01, time/batch = 0.6944s	
548/28500 (epoch 0.961), train_loss = 2.48440771, grad/param norm = 4.9992e-01, time/batch = 0.6939s	
549/28500 (epoch 0.963), train_loss = 2.53028881, grad/param norm = 4.2102e-01, time/batch = 0.6932s	
550/28500 (epoch 0.965), train_loss = 2.42632304, grad/param norm = 8.1391e-01, time/batch = 0.7033s	
551/28500 (epoch 0.967), train_loss = 2.21759485, grad/param norm = 2.9462e-01, time/batch = 0.7090s	
552/28500 (epoch 0.968), train_loss = 2.23601245, grad/param norm = 2.9669e-01, time/batch = 0.6946s	
553/28500 (epoch 0.970), train_loss = 2.70361275, grad/param norm = 6.0619e-01, time/batch = 0.6981s	
554/28500 (epoch 0.972), train_loss = 2.71768358, grad/param norm = 4.8536e-01, time/batch = 0.7012s	
555/28500 (epoch 0.974), train_loss = 2.49942987, grad/param norm = 3.7289e-01, time/batch = 0.6934s	
556/28500 (epoch 0.975), train_loss = 2.33601120, grad/param norm = 4.2905e-01, time/batch = 0.6945s	
557/28500 (epoch 0.977), train_loss = 2.63423391, grad/param norm = 7.9043e-01, time/batch = 0.6968s	
558/28500 (epoch 0.979), train_loss = 2.35370404, grad/param norm = 5.4370e-01, time/batch = 0.6988s	
559/28500 (epoch 0.981), train_loss = 2.30899769, grad/param norm = 3.3972e-01, time/batch = 0.6948s	
560/28500 (epoch 0.982), train_loss = 2.19798620, grad/param norm = 3.1476e-01, time/batch = 0.6938s	
561/28500 (epoch 0.984), train_loss = 2.40367872, grad/param norm = 2.8025e-01, time/batch = 0.6968s	
562/28500 (epoch 0.986), train_loss = 2.33581500, grad/param norm = 2.6249e-01, time/batch = 0.6977s	
563/28500 (epoch 0.988), train_loss = 2.20267053, grad/param norm = 3.1377e-01, time/batch = 0.6975s	
564/28500 (epoch 0.989), train_loss = 2.38578817, grad/param norm = 3.5700e-01, time/batch = 0.6939s	
565/28500 (epoch 0.991), train_loss = 2.42758038, grad/param norm = 3.5471e-01, time/batch = 0.6932s	
566/28500 (epoch 0.993), train_loss = 2.48236350, grad/param norm = 3.3134e-01, time/batch = 0.6933s	
567/28500 (epoch 0.995), train_loss = 2.22238775, grad/param norm = 3.1449e-01, time/batch = 0.6930s	
568/28500 (epoch 0.996), train_loss = 2.31132835, grad/param norm = 3.6476e-01, time/batch = 0.6958s	
569/28500 (epoch 0.998), train_loss = 2.40817197, grad/param norm = 3.6764e-01, time/batch = 0.6961s	
570/28500 (epoch 1.000), train_loss = 2.27893997, grad/param norm = 3.0149e-01, time/batch = 0.6947s	
571/28500 (epoch 1.002), train_loss = 2.36529799, grad/param norm = 2.7590e-01, time/batch = 0.6951s	
572/28500 (epoch 1.004), train_loss = 2.31511300, grad/param norm = 3.4451e-01, time/batch = 0.6940s	
573/28500 (epoch 1.005), train_loss = 2.31175308, grad/param norm = 3.4416e-01, time/batch = 0.6937s	
574/28500 (epoch 1.007), train_loss = 2.19334990, grad/param norm = 3.1636e-01, time/batch = 0.6929s	
575/28500 (epoch 1.009), train_loss = 2.40191013, grad/param norm = 3.7101e-01, time/batch = 0.6953s	
576/28500 (epoch 1.011), train_loss = 2.39415323, grad/param norm = 4.6376e-01, time/batch = 0.6936s	
577/28500 (epoch 1.012), train_loss = 2.31321598, grad/param norm = 3.5970e-01, time/batch = 0.6943s	
578/28500 (epoch 1.014), train_loss = 2.28960407, grad/param norm = 3.2320e-01, time/batch = 0.6954s	
579/28500 (epoch 1.016), train_loss = 2.28884256, grad/param norm = 3.2277e-01, time/batch = 0.6935s	
580/28500 (epoch 1.018), train_loss = 2.28718485, grad/param norm = 4.1595e-01, time/batch = 0.6931s	
581/28500 (epoch 1.019), train_loss = 2.29016426, grad/param norm = 4.6749e-01, time/batch = 0.6983s	
582/28500 (epoch 1.021), train_loss = 2.19677228, grad/param norm = 4.9661e-01, time/batch = 0.6935s	
583/28500 (epoch 1.023), train_loss = 2.24608606, grad/param norm = 3.8727e-01, time/batch = 0.6934s	
584/28500 (epoch 1.025), train_loss = 2.10377686, grad/param norm = 3.3003e-01, time/batch = 0.6926s	
585/28500 (epoch 1.026), train_loss = 2.40683615, grad/param norm = 4.0641e-01, time/batch = 0.6922s	
586/28500 (epoch 1.028), train_loss = 2.31398087, grad/param norm = 4.0752e-01, time/batch = 0.6936s	
587/28500 (epoch 1.030), train_loss = 2.33963264, grad/param norm = 5.5521e-01, time/batch = 0.6944s	
588/28500 (epoch 1.032), train_loss = 2.39076458, grad/param norm = 7.7847e-01, time/batch = 0.6923s	
589/28500 (epoch 1.033), train_loss = 2.49502651, grad/param norm = 4.9114e-01, time/batch = 0.6921s	
590/28500 (epoch 1.035), train_loss = 2.31396007, grad/param norm = 3.1209e-01, time/batch = 0.6950s	
591/28500 (epoch 1.037), train_loss = 2.36116514, grad/param norm = 2.9245e-01, time/batch = 0.6981s	
592/28500 (epoch 1.039), train_loss = 2.41759865, grad/param norm = 3.0822e-01, time/batch = 0.7121s	
593/28500 (epoch 1.040), train_loss = 2.29229615, grad/param norm = 3.0147e-01, time/batch = 0.6974s	
594/28500 (epoch 1.042), train_loss = 2.49906577, grad/param norm = 3.4844e-01, time/batch = 0.6974s	
595/28500 (epoch 1.044), train_loss = 2.33300173, grad/param norm = 3.9364e-01, time/batch = 0.6955s	
596/28500 (epoch 1.046), train_loss = 2.39709176, grad/param norm = 3.2238e-01, time/batch = 0.6955s	
597/28500 (epoch 1.047), train_loss = 2.38612931, grad/param norm = 2.9729e-01, time/batch = 0.7177s	
598/28500 (epoch 1.049), train_loss = 2.31955342, grad/param norm = 3.3825e-01, time/batch = 0.7080s	
599/28500 (epoch 1.051), train_loss = 2.33292519, grad/param norm = 3.8046e-01, time/batch = 0.7012s	
600/28500 (epoch 1.053), train_loss = 2.43052538, grad/param norm = 4.4819e-01, time/batch = 0.7051s	
601/28500 (epoch 1.054), train_loss = 2.27735784, grad/param norm = 3.7945e-01, time/batch = 0.6968s	
602/28500 (epoch 1.056), train_loss = 2.29658006, grad/param norm = 3.2641e-01, time/batch = 0.6929s	
603/28500 (epoch 1.058), train_loss = 2.30280191, grad/param norm = 3.0633e-01, time/batch = 0.6960s	
604/28500 (epoch 1.060), train_loss = 2.21300226, grad/param norm = 3.3720e-01, time/batch = 0.6949s	
605/28500 (epoch 1.061), train_loss = 2.45557425, grad/param norm = 4.2360e-01, time/batch = 0.6947s	
606/28500 (epoch 1.063), train_loss = 2.48573858, grad/param norm = 3.5287e-01, time/batch = 0.6921s	
607/28500 (epoch 1.065), train_loss = 2.52709554, grad/param norm = 3.7395e-01, time/batch = 0.6929s	
608/28500 (epoch 1.067), train_loss = 2.30322333, grad/param norm = 5.0010e-01, time/batch = 0.7047s	
609/28500 (epoch 1.068), train_loss = 2.21600625, grad/param norm = 3.4554e-01, time/batch = 0.6955s	
610/28500 (epoch 1.070), train_loss = 2.38252050, grad/param norm = 3.4666e-01, time/batch = 0.6925s	
611/28500 (epoch 1.072), train_loss = 2.53169080, grad/param norm = 3.7561e-01, time/batch = 0.6967s	
612/28500 (epoch 1.074), train_loss = 2.36190355, grad/param norm = 3.4349e-01, time/batch = 0.6955s	
613/28500 (epoch 1.075), train_loss = 2.27196835, grad/param norm = 3.1977e-01, time/batch = 0.6928s	
614/28500 (epoch 1.077), train_loss = 2.32105269, grad/param norm = 3.2538e-01, time/batch = 0.6992s	
615/28500 (epoch 1.079), train_loss = 2.24418206, grad/param norm = 3.2070e-01, time/batch = 0.6970s	
616/28500 (epoch 1.081), train_loss = 2.35917275, grad/param norm = 2.9976e-01, time/batch = 0.6994s	
617/28500 (epoch 1.082), train_loss = 2.37471108, grad/param norm = 3.8657e-01, time/batch = 0.6925s	
618/28500 (epoch 1.084), train_loss = 2.38676213, grad/param norm = 3.3676e-01, time/batch = 0.6984s	
619/28500 (epoch 1.086), train_loss = 2.16758513, grad/param norm = 2.8855e-01, time/batch = 0.6966s	
620/28500 (epoch 1.088), train_loss = 2.18424696, grad/param norm = 3.1454e-01, time/batch = 0.6994s	
621/28500 (epoch 1.089), train_loss = 2.45591400, grad/param norm = 3.1981e-01, time/batch = 0.7006s	
622/28500 (epoch 1.091), train_loss = 2.25430768, grad/param norm = 3.9657e-01, time/batch = 0.6979s	
623/28500 (epoch 1.093), train_loss = 2.29852733, grad/param norm = 5.4665e-01, time/batch = 0.6962s	
624/28500 (epoch 1.095), train_loss = 2.41080476, grad/param norm = 5.7840e-01, time/batch = 0.6973s	
625/28500 (epoch 1.096), train_loss = 2.33287962, grad/param norm = 3.9223e-01, time/batch = 0.6968s	
626/28500 (epoch 1.098), train_loss = 2.47168503, grad/param norm = 2.9738e-01, time/batch = 0.6983s	
627/28500 (epoch 1.100), train_loss = 2.28411979, grad/param norm = 3.1810e-01, time/batch = 0.6989s	
628/28500 (epoch 1.102), train_loss = 2.40446294, grad/param norm = 2.5797e-01, time/batch = 0.6977s	
629/28500 (epoch 1.104), train_loss = 2.29006369, grad/param norm = 2.8928e-01, time/batch = 0.6968s	
630/28500 (epoch 1.105), train_loss = 2.25437640, grad/param norm = 4.2725e-01, time/batch = 0.6990s	
631/28500 (epoch 1.107), train_loss = 2.19526628, grad/param norm = 4.3065e-01, time/batch = 0.6996s	
632/28500 (epoch 1.109), train_loss = 2.24123585, grad/param norm = 3.3039e-01, time/batch = 0.6975s	
633/28500 (epoch 1.111), train_loss = 2.32780315, grad/param norm = 3.1175e-01, time/batch = 0.6976s	
634/28500 (epoch 1.112), train_loss = 2.36262628, grad/param norm = 2.7914e-01, time/batch = 0.6984s	
635/28500 (epoch 1.114), train_loss = 2.14678329, grad/param norm = 3.4256e-01, time/batch = 0.6967s	
636/28500 (epoch 1.116), train_loss = 2.37055999, grad/param norm = 4.0716e-01, time/batch = 0.6980s	
637/28500 (epoch 1.118), train_loss = 2.23107162, grad/param norm = 3.9944e-01, time/batch = 0.6954s	
638/28500 (epoch 1.119), train_loss = 2.39039720, grad/param norm = 3.8849e-01, time/batch = 0.6958s	
639/28500 (epoch 1.121), train_loss = 2.47999320, grad/param norm = 2.9390e-01, time/batch = 0.6955s	
640/28500 (epoch 1.123), train_loss = 2.25864451, grad/param norm = 3.8496e-01, time/batch = 0.6968s	
641/28500 (epoch 1.125), train_loss = 2.48118675, grad/param norm = 3.4035e-01, time/batch = 0.7006s	
642/28500 (epoch 1.126), train_loss = 2.29436970, grad/param norm = 3.4358e-01, time/batch = 0.6981s	
643/28500 (epoch 1.128), train_loss = 2.38198263, grad/param norm = 3.7550e-01, time/batch = 0.6974s	
644/28500 (epoch 1.130), train_loss = 2.40942489, grad/param norm = 3.2231e-01, time/batch = 0.6972s	
645/28500 (epoch 1.132), train_loss = 2.41506189, grad/param norm = 4.3488e-01, time/batch = 0.6989s	
646/28500 (epoch 1.133), train_loss = 2.27524011, grad/param norm = 2.9164e-01, time/batch = 0.6966s	
647/28500 (epoch 1.135), train_loss = 2.25621810, grad/param norm = 3.0765e-01, time/batch = 0.6975s	
648/28500 (epoch 1.137), train_loss = 2.21346459, grad/param norm = 3.6129e-01, time/batch = 0.6979s	
649/28500 (epoch 1.139), train_loss = 2.26780691, grad/param norm = 3.6147e-01, time/batch = 0.6969s	
650/28500 (epoch 1.140), train_loss = 2.25854118, grad/param norm = 3.8893e-01, time/batch = 0.6970s	
651/28500 (epoch 1.142), train_loss = 2.37882388, grad/param norm = 3.4521e-01, time/batch = 0.7065s	
652/28500 (epoch 1.144), train_loss = 2.24201241, grad/param norm = 3.4357e-01, time/batch = 0.6966s	
653/28500 (epoch 1.146), train_loss = 2.20679580, grad/param norm = 3.8793e-01, time/batch = 0.6977s	
654/28500 (epoch 1.147), train_loss = 2.17799851, grad/param norm = 2.6974e-01, time/batch = 0.6981s	
655/28500 (epoch 1.149), train_loss = 2.19609899, grad/param norm = 2.6865e-01, time/batch = 0.6973s	
656/28500 (epoch 1.151), train_loss = 2.19999388, grad/param norm = 2.9231e-01, time/batch = 0.6959s	
657/28500 (epoch 1.153), train_loss = 2.27221050, grad/param norm = 3.7438e-01, time/batch = 0.7006s	
658/28500 (epoch 1.154), train_loss = 2.25825243, grad/param norm = 3.1871e-01, time/batch = 0.6969s	
659/28500 (epoch 1.156), train_loss = 2.46198675, grad/param norm = 2.7296e-01, time/batch = 0.7002s	
660/28500 (epoch 1.158), train_loss = 2.26672700, grad/param norm = 2.8729e-01, time/batch = 0.7000s	
661/28500 (epoch 1.160), train_loss = 2.15479864, grad/param norm = 3.1899e-01, time/batch = 0.7067s	
662/28500 (epoch 1.161), train_loss = 2.32340343, grad/param norm = 3.5270e-01, time/batch = 0.7072s	
663/28500 (epoch 1.163), train_loss = 2.20661723, grad/param norm = 3.6989e-01, time/batch = 0.7026s	
664/28500 (epoch 1.165), train_loss = 2.35853548, grad/param norm = 3.0044e-01, time/batch = 0.6960s	
665/28500 (epoch 1.167), train_loss = 2.34937318, grad/param norm = 2.9405e-01, time/batch = 0.6950s	
666/28500 (epoch 1.168), train_loss = 2.33537573, grad/param norm = 3.0729e-01, time/batch = 0.6962s	
667/28500 (epoch 1.170), train_loss = 2.43223677, grad/param norm = 3.2537e-01, time/batch = 0.6938s	
668/28500 (epoch 1.172), train_loss = 2.28594293, grad/param norm = 2.9700e-01, time/batch = 0.6938s	
669/28500 (epoch 1.174), train_loss = 2.36604143, grad/param norm = 2.8518e-01, time/batch = 0.6926s	
670/28500 (epoch 1.175), train_loss = 2.27405091, grad/param norm = 2.7032e-01, time/batch = 0.6923s	
671/28500 (epoch 1.177), train_loss = 2.34006069, grad/param norm = 2.7206e-01, time/batch = 0.6994s	
672/28500 (epoch 1.179), train_loss = 2.23499191, grad/param norm = 3.3013e-01, time/batch = 0.6933s	
673/28500 (epoch 1.181), train_loss = 2.37399233, grad/param norm = 3.5060e-01, time/batch = 0.6923s	
674/28500 (epoch 1.182), train_loss = 2.28841361, grad/param norm = 4.1383e-01, time/batch = 0.6931s	
675/28500 (epoch 1.184), train_loss = 2.29370042, grad/param norm = 4.4482e-01, time/batch = 0.6934s	
676/28500 (epoch 1.186), train_loss = 2.30878967, grad/param norm = 4.1899e-01, time/batch = 0.6975s	
677/28500 (epoch 1.188), train_loss = 2.26951117, grad/param norm = 3.3161e-01, time/batch = 0.7019s	
678/28500 (epoch 1.189), train_loss = 2.41324404, grad/param norm = 3.4532e-01, time/batch = 0.6984s	
679/28500 (epoch 1.191), train_loss = 2.38739724, grad/param norm = 3.1061e-01, time/batch = 0.6943s	
680/28500 (epoch 1.193), train_loss = 2.25354711, grad/param norm = 2.6500e-01, time/batch = 0.6995s	
681/28500 (epoch 1.195), train_loss = 2.31946966, grad/param norm = 3.3502e-01, time/batch = 0.6960s	
682/28500 (epoch 1.196), train_loss = 2.27849641, grad/param norm = 3.7056e-01, time/batch = 0.6949s	
683/28500 (epoch 1.198), train_loss = 2.20855958, grad/param norm = 4.6690e-01, time/batch = 0.6931s	
684/28500 (epoch 1.200), train_loss = 2.29414196, grad/param norm = 3.7562e-01, time/batch = 0.6928s	
685/28500 (epoch 1.202), train_loss = 2.33830032, grad/param norm = 3.2138e-01, time/batch = 0.6937s	
686/28500 (epoch 1.204), train_loss = 2.07848012, grad/param norm = 2.8492e-01, time/batch = 0.6951s	
687/28500 (epoch 1.205), train_loss = 2.17493936, grad/param norm = 2.9121e-01, time/batch = 0.7016s	
688/28500 (epoch 1.207), train_loss = 2.30237642, grad/param norm = 2.6914e-01, time/batch = 0.7061s	
689/28500 (epoch 1.209), train_loss = 2.20272808, grad/param norm = 2.8192e-01, time/batch = 0.6957s	
690/28500 (epoch 1.211), train_loss = 2.27543512, grad/param norm = 2.6477e-01, time/batch = 0.6937s	
691/28500 (epoch 1.212), train_loss = 2.14819135, grad/param norm = 3.0042e-01, time/batch = 0.6982s	
692/28500 (epoch 1.214), train_loss = 2.32718452, grad/param norm = 3.0708e-01, time/batch = 0.6956s	
693/28500 (epoch 1.216), train_loss = 2.20187432, grad/param norm = 2.8554e-01, time/batch = 0.6944s	
694/28500 (epoch 1.218), train_loss = 2.18995037, grad/param norm = 3.0565e-01, time/batch = 0.6934s	
695/28500 (epoch 1.219), train_loss = 2.19230086, grad/param norm = 3.1461e-01, time/batch = 0.7033s	
696/28500 (epoch 1.221), train_loss = 2.15090017, grad/param norm = 2.7165e-01, time/batch = 0.6965s	
697/28500 (epoch 1.223), train_loss = 2.30931058, grad/param norm = 3.3827e-01, time/batch = 0.6971s	
698/28500 (epoch 1.225), train_loss = 2.40206507, grad/param norm = 3.8931e-01, time/batch = 0.6975s	
699/28500 (epoch 1.226), train_loss = 2.32313893, grad/param norm = 3.0699e-01, time/batch = 0.6970s	
700/28500 (epoch 1.228), train_loss = 2.32928434, grad/param norm = 3.1507e-01, time/batch = 0.6960s	
701/28500 (epoch 1.230), train_loss = 2.20634632, grad/param norm = 3.4050e-01, time/batch = 0.6988s	
702/28500 (epoch 1.232), train_loss = 2.28532135, grad/param norm = 3.9441e-01, time/batch = 0.6963s	
703/28500 (epoch 1.233), train_loss = 2.28017093, grad/param norm = 5.2951e-01, time/batch = 0.6957s	
704/28500 (epoch 1.235), train_loss = 2.21871858, grad/param norm = 4.2654e-01, time/batch = 0.6961s	
705/28500 (epoch 1.237), train_loss = 2.15959660, grad/param norm = 2.9170e-01, time/batch = 0.6968s	
706/28500 (epoch 1.239), train_loss = 2.18163256, grad/param norm = 3.2089e-01, time/batch = 0.6958s	
707/28500 (epoch 1.240), train_loss = 2.22581712, grad/param norm = 3.0316e-01, time/batch = 0.6970s	
708/28500 (epoch 1.242), train_loss = 2.29685861, grad/param norm = 3.3048e-01, time/batch = 0.6963s	
709/28500 (epoch 1.244), train_loss = 2.28665298, grad/param norm = 3.4197e-01, time/batch = 0.6996s	
710/28500 (epoch 1.246), train_loss = 2.21420367, grad/param norm = 3.7317e-01, time/batch = 0.6971s	
711/28500 (epoch 1.247), train_loss = 2.34867382, grad/param norm = 4.0731e-01, time/batch = 0.6989s	
712/28500 (epoch 1.249), train_loss = 2.26352658, grad/param norm = 3.7978e-01, time/batch = 0.7001s	
713/28500 (epoch 1.251), train_loss = 2.06255949, grad/param norm = 3.6021e-01, time/batch = 0.6981s	
714/28500 (epoch 1.253), train_loss = 2.27236213, grad/param norm = 3.6977e-01, time/batch = 0.6979s	
715/28500 (epoch 1.254), train_loss = 2.27021110, grad/param norm = 3.2146e-01, time/batch = 0.6963s	
716/28500 (epoch 1.256), train_loss = 2.24958986, grad/param norm = 3.4672e-01, time/batch = 0.6968s	
717/28500 (epoch 1.258), train_loss = 2.23776634, grad/param norm = 3.4386e-01, time/batch = 0.7056s	
718/28500 (epoch 1.260), train_loss = 2.19323486, grad/param norm = 2.7847e-01, time/batch = 0.7181s	
719/28500 (epoch 1.261), train_loss = 2.17999655, grad/param norm = 2.8525e-01, time/batch = 0.7035s	
720/28500 (epoch 1.263), train_loss = 2.31243519, grad/param norm = 3.0552e-01, time/batch = 0.6995s	
721/28500 (epoch 1.265), train_loss = 2.38226766, grad/param norm = 3.0620e-01, time/batch = 0.7024s	
722/28500 (epoch 1.267), train_loss = 2.32019006, grad/param norm = 3.0693e-01, time/batch = 0.6981s	
723/28500 (epoch 1.268), train_loss = 2.23680538, grad/param norm = 2.8329e-01, time/batch = 0.6984s	
724/28500 (epoch 1.270), train_loss = 2.17902764, grad/param norm = 2.6947e-01, time/batch = 0.7138s	
725/28500 (epoch 1.272), train_loss = 2.19755570, grad/param norm = 3.0256e-01, time/batch = 0.6983s	
726/28500 (epoch 1.274), train_loss = 2.28929538, grad/param norm = 2.8344e-01, time/batch = 0.6983s	
727/28500 (epoch 1.275), train_loss = 2.22681632, grad/param norm = 2.5362e-01, time/batch = 0.6959s	
728/28500 (epoch 1.277), train_loss = 2.26025614, grad/param norm = 2.8604e-01, time/batch = 0.6970s	
729/28500 (epoch 1.279), train_loss = 2.21887350, grad/param norm = 3.1074e-01, time/batch = 0.6964s	
730/28500 (epoch 1.281), train_loss = 2.21405155, grad/param norm = 3.9979e-01, time/batch = 0.6970s	
731/28500 (epoch 1.282), train_loss = 2.13909156, grad/param norm = 3.7968e-01, time/batch = 0.6998s	
732/28500 (epoch 1.284), train_loss = 2.26457314, grad/param norm = 3.4171e-01, time/batch = 0.6980s	
733/28500 (epoch 1.286), train_loss = 2.34643841, grad/param norm = 3.5747e-01, time/batch = 0.6964s	
734/28500 (epoch 1.288), train_loss = 2.16088143, grad/param norm = 3.0232e-01, time/batch = 0.6970s	
735/28500 (epoch 1.289), train_loss = 2.43036267, grad/param norm = 2.7870e-01, time/batch = 0.6966s	
736/28500 (epoch 1.291), train_loss = 2.06641258, grad/param norm = 3.0212e-01, time/batch = 0.6960s	
737/28500 (epoch 1.293), train_loss = 2.16624477, grad/param norm = 3.0371e-01, time/batch = 0.6963s	
738/28500 (epoch 1.295), train_loss = 2.18920198, grad/param norm = 3.3479e-01, time/batch = 0.6961s	
739/28500 (epoch 1.296), train_loss = 2.18336812, grad/param norm = 4.0034e-01, time/batch = 0.6970s	
740/28500 (epoch 1.298), train_loss = 2.17542974, grad/param norm = 4.3131e-01, time/batch = 0.6965s	
741/28500 (epoch 1.300), train_loss = 2.11095644, grad/param norm = 4.0567e-01, time/batch = 0.7012s	
742/28500 (epoch 1.302), train_loss = 2.18168778, grad/param norm = 3.7329e-01, time/batch = 0.6997s	
743/28500 (epoch 1.304), train_loss = 2.08576096, grad/param norm = 2.7669e-01, time/batch = 0.6981s	
744/28500 (epoch 1.305), train_loss = 2.22842166, grad/param norm = 2.6491e-01, time/batch = 0.6966s	
745/28500 (epoch 1.307), train_loss = 2.28943961, grad/param norm = 3.4737e-01, time/batch = 0.7004s	
746/28500 (epoch 1.309), train_loss = 2.29615717, grad/param norm = 3.3777e-01, time/batch = 0.6967s	
747/28500 (epoch 1.311), train_loss = 2.12983340, grad/param norm = 3.2048e-01, time/batch = 0.6975s	
748/28500 (epoch 1.312), train_loss = 1.98979549, grad/param norm = 2.7892e-01, time/batch = 0.6939s	
749/28500 (epoch 1.314), train_loss = 2.12006604, grad/param norm = 3.2534e-01, time/batch = 0.6928s	
750/28500 (epoch 1.316), train_loss = 2.16238927, grad/param norm = 2.9859e-01, time/batch = 0.6930s	
751/28500 (epoch 1.318), train_loss = 2.17332217, grad/param norm = 3.2270e-01, time/batch = 0.6966s	
752/28500 (epoch 1.319), train_loss = 2.19288287, grad/param norm = 3.5244e-01, time/batch = 0.6935s	
753/28500 (epoch 1.321), train_loss = 2.29195602, grad/param norm = 2.9939e-01, time/batch = 0.6929s	
754/28500 (epoch 1.323), train_loss = 2.22253732, grad/param norm = 2.7380e-01, time/batch = 0.6931s	
755/28500 (epoch 1.325), train_loss = 2.37114564, grad/param norm = 3.2135e-01, time/batch = 0.6953s	
756/28500 (epoch 1.326), train_loss = 2.39555701, grad/param norm = 3.7473e-01, time/batch = 0.6936s	
757/28500 (epoch 1.328), train_loss = 2.10070539, grad/param norm = 3.6313e-01, time/batch = 0.6948s	
758/28500 (epoch 1.330), train_loss = 2.13530916, grad/param norm = 2.9908e-01, time/batch = 0.6948s	
759/28500 (epoch 1.332), train_loss = 2.12235494, grad/param norm = 2.7231e-01, time/batch = 0.6924s	
760/28500 (epoch 1.333), train_loss = 2.06991005, grad/param norm = 2.9913e-01, time/batch = 0.6928s	
761/28500 (epoch 1.335), train_loss = 2.02643150, grad/param norm = 2.9974e-01, time/batch = 0.6968s	
762/28500 (epoch 1.337), train_loss = 2.22953906, grad/param norm = 3.6172e-01, time/batch = 0.6986s	
763/28500 (epoch 1.339), train_loss = 2.20249475, grad/param norm = 3.3132e-01, time/batch = 0.7116s	
764/28500 (epoch 1.340), train_loss = 2.21488287, grad/param norm = 3.6876e-01, time/batch = 0.6932s	
765/28500 (epoch 1.342), train_loss = 2.08716249, grad/param norm = 4.7581e-01, time/batch = 0.6962s	
766/28500 (epoch 1.344), train_loss = 2.15145540, grad/param norm = 4.7045e-01, time/batch = 0.6969s	
767/28500 (epoch 1.346), train_loss = 1.99680852, grad/param norm = 5.5206e-01, time/batch = 0.7002s	
768/28500 (epoch 1.347), train_loss = 2.18456904, grad/param norm = 3.1193e-01, time/batch = 0.7000s	
769/28500 (epoch 1.349), train_loss = 2.08861783, grad/param norm = 2.7406e-01, time/batch = 0.6930s	
770/28500 (epoch 1.351), train_loss = 2.04503591, grad/param norm = 2.6010e-01, time/batch = 0.6940s	
771/28500 (epoch 1.353), train_loss = 2.22306004, grad/param norm = 2.5439e-01, time/batch = 0.6976s	
772/28500 (epoch 1.354), train_loss = 2.15339447, grad/param norm = 2.6225e-01, time/batch = 0.6970s	
773/28500 (epoch 1.356), train_loss = 2.11227008, grad/param norm = 3.0106e-01, time/batch = 0.6965s	
774/28500 (epoch 1.358), train_loss = 2.20653086, grad/param norm = 2.8024e-01, time/batch = 0.6965s	
775/28500 (epoch 1.360), train_loss = 2.22973230, grad/param norm = 2.9303e-01, time/batch = 0.6951s	
776/28500 (epoch 1.361), train_loss = 2.20393563, grad/param norm = 3.0331e-01, time/batch = 0.6947s	
777/28500 (epoch 1.363), train_loss = 2.02512253, grad/param norm = 3.0624e-01, time/batch = 0.6966s	
778/28500 (epoch 1.365), train_loss = 2.10264372, grad/param norm = 2.4402e-01, time/batch = 0.6957s	
779/28500 (epoch 1.367), train_loss = 2.18132981, grad/param norm = 3.3397e-01, time/batch = 0.6960s	
780/28500 (epoch 1.368), train_loss = 2.10631775, grad/param norm = 3.2458e-01, time/batch = 0.6974s	
781/28500 (epoch 1.370), train_loss = 2.17645084, grad/param norm = 2.9256e-01, time/batch = 0.7037s	
782/28500 (epoch 1.372), train_loss = 2.12597400, grad/param norm = 2.8696e-01, time/batch = 0.6902s	
783/28500 (epoch 1.374), train_loss = 2.22484971, grad/param norm = 3.2808e-01, time/batch = 0.7032s	
784/28500 (epoch 1.375), train_loss = 2.21662409, grad/param norm = 3.2813e-01, time/batch = 0.7071s	
785/28500 (epoch 1.377), train_loss = 2.20594444, grad/param norm = 3.0835e-01, time/batch = 0.6857s	
786/28500 (epoch 1.379), train_loss = 1.96399245, grad/param norm = 2.9088e-01, time/batch = 0.6802s	
787/28500 (epoch 1.381), train_loss = 2.09035385, grad/param norm = 2.9855e-01, time/batch = 0.6827s	
788/28500 (epoch 1.382), train_loss = 2.15593320, grad/param norm = 3.0178e-01, time/batch = 0.6782s	
789/28500 (epoch 1.384), train_loss = 2.20739989, grad/param norm = 3.4656e-01, time/batch = 0.6936s	
790/28500 (epoch 1.386), train_loss = 1.99839935, grad/param norm = 2.7954e-01, time/batch = 0.6964s	
791/28500 (epoch 1.388), train_loss = 2.21582231, grad/param norm = 3.2890e-01, time/batch = 0.6851s	
792/28500 (epoch 1.389), train_loss = 2.14377121, grad/param norm = 3.5426e-01, time/batch = 0.6791s	
793/28500 (epoch 1.391), train_loss = 2.14654849, grad/param norm = 3.5948e-01, time/batch = 0.6847s	
794/28500 (epoch 1.393), train_loss = 1.98235815, grad/param norm = 3.7261e-01, time/batch = 0.6807s	
795/28500 (epoch 1.395), train_loss = 2.33377404, grad/param norm = 3.4624e-01, time/batch = 0.6827s	
796/28500 (epoch 1.396), train_loss = 2.28226073, grad/param norm = 3.3839e-01, time/batch = 0.6789s	
797/28500 (epoch 1.398), train_loss = 2.13643446, grad/param norm = 3.5123e-01, time/batch = 0.6777s	
798/28500 (epoch 1.400), train_loss = 2.19984412, grad/param norm = 2.6224e-01, time/batch = 0.6864s	
799/28500 (epoch 1.402), train_loss = 2.14505945, grad/param norm = 2.6613e-01, time/batch = 0.6867s	
800/28500 (epoch 1.404), train_loss = 2.27395580, grad/param norm = 2.9549e-01, time/batch = 0.6815s	
801/28500 (epoch 1.405), train_loss = 2.21236257, grad/param norm = 3.2010e-01, time/batch = 0.6807s	
802/28500 (epoch 1.407), train_loss = 2.18509022, grad/param norm = 2.6448e-01, time/batch = 0.6799s	
803/28500 (epoch 1.409), train_loss = 2.19594704, grad/param norm = 2.7466e-01, time/batch = 0.6774s	
804/28500 (epoch 1.411), train_loss = 2.19435908, grad/param norm = 2.7714e-01, time/batch = 0.6778s	
805/28500 (epoch 1.412), train_loss = 2.25513659, grad/param norm = 3.2596e-01, time/batch = 0.6815s	
806/28500 (epoch 1.414), train_loss = 2.24247786, grad/param norm = 3.5561e-01, time/batch = 0.6799s	
807/28500 (epoch 1.416), train_loss = 2.07059575, grad/param norm = 4.2362e-01, time/batch = 0.6804s	
808/28500 (epoch 1.418), train_loss = 2.20494936, grad/param norm = 3.7306e-01, time/batch = 0.6781s	
809/28500 (epoch 1.419), train_loss = 2.22240890, grad/param norm = 3.0433e-01, time/batch = 0.6891s	
810/28500 (epoch 1.421), train_loss = 2.14906677, grad/param norm = 2.8012e-01, time/batch = 0.6928s	
811/28500 (epoch 1.423), train_loss = 2.29009904, grad/param norm = 3.1213e-01, time/batch = 0.6805s	
812/28500 (epoch 1.425), train_loss = 2.22322651, grad/param norm = 2.8958e-01, time/batch = 0.6797s	
813/28500 (epoch 1.426), train_loss = 2.22433436, grad/param norm = 3.2169e-01, time/batch = 0.6801s	
814/28500 (epoch 1.428), train_loss = 2.29601880, grad/param norm = 3.0012e-01, time/batch = 0.6770s	
815/28500 (epoch 1.430), train_loss = 2.16454646, grad/param norm = 3.0274e-01, time/batch = 0.6770s	
816/28500 (epoch 1.432), train_loss = 2.30297253, grad/param norm = 3.3306e-01, time/batch = 0.6776s	
817/28500 (epoch 1.433), train_loss = 2.09859151, grad/param norm = 3.5177e-01, time/batch = 0.6789s	
818/28500 (epoch 1.435), train_loss = 2.07041802, grad/param norm = 3.3264e-01, time/batch = 0.6768s	
819/28500 (epoch 1.437), train_loss = 2.01963954, grad/param norm = 3.5324e-01, time/batch = 0.6774s	
820/28500 (epoch 1.439), train_loss = 2.10783459, grad/param norm = 3.5907e-01, time/batch = 0.6779s	
821/28500 (epoch 1.440), train_loss = 2.13814805, grad/param norm = 2.9345e-01, time/batch = 0.6793s	
822/28500 (epoch 1.442), train_loss = 2.08577125, grad/param norm = 3.0607e-01, time/batch = 0.6783s	
823/28500 (epoch 1.444), train_loss = 2.10438637, grad/param norm = 2.9590e-01, time/batch = 0.6789s	
824/28500 (epoch 1.446), train_loss = 1.98072758, grad/param norm = 3.2411e-01, time/batch = 0.6786s	
825/28500 (epoch 1.447), train_loss = 2.02214493, grad/param norm = 2.6001e-01, time/batch = 0.6770s	
826/28500 (epoch 1.449), train_loss = 2.14253979, grad/param norm = 3.7672e-01, time/batch = 0.6766s	
827/28500 (epoch 1.451), train_loss = 2.19934205, grad/param norm = 3.5924e-01, time/batch = 0.6776s	
828/28500 (epoch 1.453), train_loss = 2.15109413, grad/param norm = 3.0363e-01, time/batch = 0.6775s	
829/28500 (epoch 1.454), train_loss = 2.04677389, grad/param norm = 3.1520e-01, time/batch = 0.6823s	
830/28500 (epoch 1.456), train_loss = 2.31101052, grad/param norm = 3.9740e-01, time/batch = 0.6783s	
831/28500 (epoch 1.458), train_loss = 2.13737604, grad/param norm = 3.7473e-01, time/batch = 0.6781s	
832/28500 (epoch 1.460), train_loss = 2.23028651, grad/param norm = 3.1327e-01, time/batch = 0.6762s	
833/28500 (epoch 1.461), train_loss = 2.17064284, grad/param norm = 2.8538e-01, time/batch = 0.6858s	
834/28500 (epoch 1.463), train_loss = 2.07036703, grad/param norm = 2.7839e-01, time/batch = 0.6913s	
835/28500 (epoch 1.465), train_loss = 1.99954994, grad/param norm = 2.9859e-01, time/batch = 0.6821s	
836/28500 (epoch 1.467), train_loss = 2.27620898, grad/param norm = 3.0546e-01, time/batch = 0.6813s	
837/28500 (epoch 1.468), train_loss = 2.01493499, grad/param norm = 2.6269e-01, time/batch = 0.6774s	
838/28500 (epoch 1.470), train_loss = 2.18674676, grad/param norm = 2.8681e-01, time/batch = 0.6764s	
839/28500 (epoch 1.472), train_loss = 2.07320706, grad/param norm = 3.4593e-01, time/batch = 0.6768s	
840/28500 (epoch 1.474), train_loss = 2.30635941, grad/param norm = 4.4077e-01, time/batch = 0.6794s	
841/28500 (epoch 1.475), train_loss = 2.15020507, grad/param norm = 4.5980e-01, time/batch = 0.6826s	
842/28500 (epoch 1.477), train_loss = 2.10340892, grad/param norm = 4.1174e-01, time/batch = 0.6787s	
843/28500 (epoch 1.479), train_loss = 2.18197242, grad/param norm = 2.9148e-01, time/batch = 0.6765s	
844/28500 (epoch 1.481), train_loss = 2.15122154, grad/param norm = 2.4907e-01, time/batch = 0.6773s	
845/28500 (epoch 1.482), train_loss = 2.15870030, grad/param norm = 2.8295e-01, time/batch = 0.6815s	
846/28500 (epoch 1.484), train_loss = 2.01678380, grad/param norm = 3.6706e-01, time/batch = 0.6784s	
847/28500 (epoch 1.486), train_loss = 2.13474536, grad/param norm = 3.4796e-01, time/batch = 0.6755s	
848/28500 (epoch 1.488), train_loss = 2.04978755, grad/param norm = 3.9640e-01, time/batch = 0.6793s	
849/28500 (epoch 1.489), train_loss = 2.18758499, grad/param norm = 4.2802e-01, time/batch = 0.6888s	
850/28500 (epoch 1.491), train_loss = 2.07595264, grad/param norm = 3.9122e-01, time/batch = 0.6970s	
851/28500 (epoch 1.493), train_loss = 2.04125314, grad/param norm = 2.7246e-01, time/batch = 0.6962s	
852/28500 (epoch 1.495), train_loss = 2.06899446, grad/param norm = 2.4739e-01, time/batch = 0.6919s	
853/28500 (epoch 1.496), train_loss = 2.23957544, grad/param norm = 2.8774e-01, time/batch = 0.6985s	
854/28500 (epoch 1.498), train_loss = 2.15001449, grad/param norm = 3.0339e-01, time/batch = 0.6904s	
855/28500 (epoch 1.500), train_loss = 2.12977219, grad/param norm = 2.6517e-01, time/batch = 0.7062s	
856/28500 (epoch 1.502), train_loss = 2.15506529, grad/param norm = 2.7430e-01, time/batch = 0.7137s	
857/28500 (epoch 1.504), train_loss = 2.09603840, grad/param norm = 2.6188e-01, time/batch = 0.7080s	
858/28500 (epoch 1.505), train_loss = 2.08875981, grad/param norm = 2.8523e-01, time/batch = 0.6945s	
859/28500 (epoch 1.507), train_loss = 2.36657894, grad/param norm = 3.0561e-01, time/batch = 0.6947s	
860/28500 (epoch 1.509), train_loss = 2.09955842, grad/param norm = 3.3903e-01, time/batch = 0.6945s	
861/28500 (epoch 1.511), train_loss = 2.31172760, grad/param norm = 3.5351e-01, time/batch = 0.6978s	
862/28500 (epoch 1.512), train_loss = 2.12873663, grad/param norm = 3.3276e-01, time/batch = 0.6984s	
863/28500 (epoch 1.514), train_loss = 2.05508127, grad/param norm = 2.5043e-01, time/batch = 0.6936s	
864/28500 (epoch 1.516), train_loss = 2.09544213, grad/param norm = 2.7114e-01, time/batch = 0.6959s	
865/28500 (epoch 1.518), train_loss = 2.04631697, grad/param norm = 2.4859e-01, time/batch = 0.6922s	
866/28500 (epoch 1.519), train_loss = 2.27236691, grad/param norm = 3.3633e-01, time/batch = 0.6939s	
867/28500 (epoch 1.521), train_loss = 2.25469274, grad/param norm = 3.4851e-01, time/batch = 0.6931s	
868/28500 (epoch 1.523), train_loss = 2.13493603, grad/param norm = 3.3994e-01, time/batch = 0.6947s	
869/28500 (epoch 1.525), train_loss = 2.17167884, grad/param norm = 2.8295e-01, time/batch = 0.6941s	
870/28500 (epoch 1.526), train_loss = 2.03235305, grad/param norm = 2.8130e-01, time/batch = 0.6936s	
871/28500 (epoch 1.528), train_loss = 2.24520642, grad/param norm = 3.4445e-01, time/batch = 0.6966s	
872/28500 (epoch 1.530), train_loss = 2.12212006, grad/param norm = 2.9014e-01, time/batch = 0.7066s	
873/28500 (epoch 1.532), train_loss = 2.06399738, grad/param norm = 3.5370e-01, time/batch = 0.7054s	
874/28500 (epoch 1.533), train_loss = 2.23478470, grad/param norm = 3.0733e-01, time/batch = 0.6934s	
875/28500 (epoch 1.535), train_loss = 1.97378675, grad/param norm = 2.4650e-01, time/batch = 0.6941s	
876/28500 (epoch 1.537), train_loss = 1.90458249, grad/param norm = 2.6303e-01, time/batch = 0.6953s	
877/28500 (epoch 1.539), train_loss = 2.08414226, grad/param norm = 2.5191e-01, time/batch = 0.6939s	
878/28500 (epoch 1.540), train_loss = 2.08116434, grad/param norm = 3.0974e-01, time/batch = 0.6952s	
879/28500 (epoch 1.542), train_loss = 2.39946973, grad/param norm = 4.1594e-01, time/batch = 0.6942s	
880/28500 (epoch 1.544), train_loss = 2.23067704, grad/param norm = 4.7217e-01, time/batch = 0.6964s	
881/28500 (epoch 1.546), train_loss = 2.22947536, grad/param norm = 3.7740e-01, time/batch = 0.7149s	
882/28500 (epoch 1.547), train_loss = 2.17932723, grad/param norm = 3.0522e-01, time/batch = 0.6981s	
883/28500 (epoch 1.549), train_loss = 2.04672303, grad/param norm = 2.6226e-01, time/batch = 0.6971s	
884/28500 (epoch 1.551), train_loss = 2.32293674, grad/param norm = 2.9704e-01, time/batch = 0.6946s	
885/28500 (epoch 1.553), train_loss = 2.28612678, grad/param norm = 2.6393e-01, time/batch = 0.7032s	
886/28500 (epoch 1.554), train_loss = 2.13842933, grad/param norm = 2.5775e-01, time/batch = 0.6934s	
887/28500 (epoch 1.556), train_loss = 2.18840442, grad/param norm = 2.7741e-01, time/batch = 0.6934s	
888/28500 (epoch 1.558), train_loss = 2.16754517, grad/param norm = 2.7777e-01, time/batch = 0.6940s	
889/28500 (epoch 1.560), train_loss = 2.13738098, grad/param norm = 2.6562e-01, time/batch = 0.6938s	
890/28500 (epoch 1.561), train_loss = 2.18957261, grad/param norm = 2.6294e-01, time/batch = 0.7055s	
891/28500 (epoch 1.563), train_loss = 2.14273064, grad/param norm = 2.7298e-01, time/batch = 0.7072s	
892/28500 (epoch 1.565), train_loss = 2.12895548, grad/param norm = 3.3114e-01, time/batch = 0.6968s	
893/28500 (epoch 1.567), train_loss = 2.02613146, grad/param norm = 3.5105e-01, time/batch = 0.6991s	
894/28500 (epoch 1.568), train_loss = 2.22250569, grad/param norm = 2.9140e-01, time/batch = 0.6959s	
895/28500 (epoch 1.570), train_loss = 2.11036568, grad/param norm = 3.9613e-01, time/batch = 0.6931s	
896/28500 (epoch 1.572), train_loss = 2.12845730, grad/param norm = 3.5374e-01, time/batch = 0.6941s	
897/28500 (epoch 1.574), train_loss = 2.20326853, grad/param norm = 2.8502e-01, time/batch = 0.6899s	
898/28500 (epoch 1.575), train_loss = 1.99117318, grad/param norm = 2.8617e-01, time/batch = 0.6817s	
899/28500 (epoch 1.577), train_loss = 2.01453332, grad/param norm = 3.3838e-01, time/batch = 0.6819s	
900/28500 (epoch 1.579), train_loss = 2.35888368, grad/param norm = 3.5859e-01, time/batch = 0.6996s	
901/28500 (epoch 1.581), train_loss = 2.04201380, grad/param norm = 3.3042e-01, time/batch = 0.6896s	
902/28500 (epoch 1.582), train_loss = 2.15708611, grad/param norm = 3.3089e-01, time/batch = 0.6863s	
903/28500 (epoch 1.584), train_loss = 2.03660053, grad/param norm = 2.7802e-01, time/batch = 0.6830s	
904/28500 (epoch 1.586), train_loss = 1.87250256, grad/param norm = 2.6280e-01, time/batch = 0.6820s	
905/28500 (epoch 1.588), train_loss = 2.04274917, grad/param norm = 3.2983e-01, time/batch = 0.6829s	
906/28500 (epoch 1.589), train_loss = 2.45566124, grad/param norm = 3.1652e-01, time/batch = 0.6849s	
907/28500 (epoch 1.591), train_loss = 2.16757009, grad/param norm = 2.5968e-01, time/batch = 0.6811s	
908/28500 (epoch 1.593), train_loss = 2.03394327, grad/param norm = 2.9316e-01, time/batch = 0.6817s	
909/28500 (epoch 1.595), train_loss = 2.29245609, grad/param norm = 3.3190e-01, time/batch = 0.6964s	
910/28500 (epoch 1.596), train_loss = 2.16495744, grad/param norm = 4.1138e-01, time/batch = 0.6940s	
911/28500 (epoch 1.598), train_loss = 2.11013254, grad/param norm = 3.1877e-01, time/batch = 0.6849s	
912/28500 (epoch 1.600), train_loss = 2.12335028, grad/param norm = 2.6744e-01, time/batch = 0.6837s	
913/28500 (epoch 1.602), train_loss = 2.25654842, grad/param norm = 2.9692e-01, time/batch = 0.6960s	
914/28500 (epoch 1.604), train_loss = 2.09993780, grad/param norm = 3.2660e-01, time/batch = 0.6962s	
915/28500 (epoch 1.605), train_loss = 2.10256818, grad/param norm = 2.6848e-01, time/batch = 0.7034s	
916/28500 (epoch 1.607), train_loss = 2.03552100, grad/param norm = 2.3867e-01, time/batch = 0.6985s	
917/28500 (epoch 1.609), train_loss = 2.08206565, grad/param norm = 3.0187e-01, time/batch = 0.6965s	
918/28500 (epoch 1.611), train_loss = 2.09360300, grad/param norm = 3.2320e-01, time/batch = 0.7066s	
919/28500 (epoch 1.612), train_loss = 2.13439336, grad/param norm = 2.7878e-01, time/batch = 0.7068s	
920/28500 (epoch 1.614), train_loss = 2.03339529, grad/param norm = 3.0642e-01, time/batch = 0.7031s	
921/28500 (epoch 1.616), train_loss = 2.01643658, grad/param norm = 3.4778e-01, time/batch = 0.6946s	
922/28500 (epoch 1.618), train_loss = 1.85616905, grad/param norm = 2.9978e-01, time/batch = 0.6958s	
923/28500 (epoch 1.619), train_loss = 2.15166298, grad/param norm = 3.4293e-01, time/batch = 0.6976s	
924/28500 (epoch 1.621), train_loss = 1.88672494, grad/param norm = 3.2600e-01, time/batch = 0.6974s	
925/28500 (epoch 1.623), train_loss = 2.09883444, grad/param norm = 2.9166e-01, time/batch = 0.6913s	
926/28500 (epoch 1.625), train_loss = 2.04104906, grad/param norm = 2.8871e-01, time/batch = 0.6892s	
927/28500 (epoch 1.626), train_loss = 1.90484783, grad/param norm = 2.9995e-01, time/batch = 0.6896s	
928/28500 (epoch 1.628), train_loss = 1.95097657, grad/param norm = 3.0330e-01, time/batch = 0.6903s	
929/28500 (epoch 1.630), train_loss = 1.99779039, grad/param norm = 3.1279e-01, time/batch = 0.6898s	
930/28500 (epoch 1.632), train_loss = 2.15751453, grad/param norm = 3.7164e-01, time/batch = 0.6897s	
931/28500 (epoch 1.633), train_loss = 2.07068277, grad/param norm = 3.0669e-01, time/batch = 0.6930s	
932/28500 (epoch 1.635), train_loss = 2.21178338, grad/param norm = 3.1436e-01, time/batch = 0.6920s	
933/28500 (epoch 1.637), train_loss = 2.04973486, grad/param norm = 2.8332e-01, time/batch = 0.6915s	
934/28500 (epoch 1.639), train_loss = 1.85539517, grad/param norm = 3.0593e-01, time/batch = 0.6918s	
935/28500 (epoch 1.640), train_loss = 2.05755738, grad/param norm = 2.6995e-01, time/batch = 0.6983s	
936/28500 (epoch 1.642), train_loss = 2.18176183, grad/param norm = 2.8904e-01, time/batch = 0.7116s	
937/28500 (epoch 1.644), train_loss = 2.12974289, grad/param norm = 2.6556e-01, time/batch = 0.6949s	
938/28500 (epoch 1.646), train_loss = 2.08445534, grad/param norm = 2.9176e-01, time/batch = 0.6937s	
939/28500 (epoch 1.647), train_loss = 2.04588367, grad/param norm = 2.8456e-01, time/batch = 0.6941s	
940/28500 (epoch 1.649), train_loss = 2.03942397, grad/param norm = 2.5892e-01, time/batch = 0.7050s	
941/28500 (epoch 1.651), train_loss = 2.00431257, grad/param norm = 2.9267e-01, time/batch = 0.7062s	
942/28500 (epoch 1.653), train_loss = 2.01496241, grad/param norm = 3.3848e-01, time/batch = 0.7003s	
943/28500 (epoch 1.654), train_loss = 2.06385461, grad/param norm = 3.6715e-01, time/batch = 0.6965s	
944/28500 (epoch 1.656), train_loss = 2.12547874, grad/param norm = 3.7041e-01, time/batch = 0.6988s	
945/28500 (epoch 1.658), train_loss = 2.10531991, grad/param norm = 2.8693e-01, time/batch = 0.6960s	
946/28500 (epoch 1.660), train_loss = 2.03403888, grad/param norm = 2.6307e-01, time/batch = 0.6972s	
947/28500 (epoch 1.661), train_loss = 2.14278157, grad/param norm = 2.3783e-01, time/batch = 0.6984s	
948/28500 (epoch 1.663), train_loss = 2.14386492, grad/param norm = 2.6570e-01, time/batch = 0.6989s	
949/28500 (epoch 1.665), train_loss = 2.10023966, grad/param norm = 3.1236e-01, time/batch = 0.7005s	
950/28500 (epoch 1.667), train_loss = 1.99211408, grad/param norm = 3.0484e-01, time/batch = 0.6988s	
951/28500 (epoch 1.668), train_loss = 2.02744625, grad/param norm = 2.7626e-01, time/batch = 0.7002s	
952/28500 (epoch 1.670), train_loss = 1.98015415, grad/param norm = 3.0362e-01, time/batch = 0.6994s	
953/28500 (epoch 1.672), train_loss = 2.01681714, grad/param norm = 2.8859e-01, time/batch = 0.6988s	
954/28500 (epoch 1.674), train_loss = 1.95606501, grad/param norm = 2.8674e-01, time/batch = 0.7004s	
955/28500 (epoch 1.675), train_loss = 1.89237469, grad/param norm = 2.9112e-01, time/batch = 0.6964s	
956/28500 (epoch 1.677), train_loss = 1.98348489, grad/param norm = 2.9743e-01, time/batch = 0.6984s	
957/28500 (epoch 1.679), train_loss = 2.05572031, grad/param norm = 2.3440e-01, time/batch = 0.6976s	
958/28500 (epoch 1.681), train_loss = 2.17778600, grad/param norm = 2.9417e-01, time/batch = 0.7021s	
959/28500 (epoch 1.682), train_loss = 1.93004291, grad/param norm = 2.8972e-01, time/batch = 0.6914s	
960/28500 (epoch 1.684), train_loss = 2.07026102, grad/param norm = 2.4086e-01, time/batch = 0.6928s	
961/28500 (epoch 1.686), train_loss = 1.97256610, grad/param norm = 2.7234e-01, time/batch = 0.6940s	
962/28500 (epoch 1.688), train_loss = 1.99183723, grad/param norm = 3.1438e-01, time/batch = 0.6971s	
963/28500 (epoch 1.689), train_loss = 2.20441576, grad/param norm = 3.7558e-01, time/batch = 0.6940s	
964/28500 (epoch 1.691), train_loss = 2.01370738, grad/param norm = 2.9236e-01, time/batch = 0.6934s	
965/28500 (epoch 1.693), train_loss = 2.07132324, grad/param norm = 2.9377e-01, time/batch = 0.6929s	
966/28500 (epoch 1.695), train_loss = 2.08931258, grad/param norm = 2.7637e-01, time/batch = 0.6956s	
967/28500 (epoch 1.696), train_loss = 2.13407616, grad/param norm = 3.6984e-01, time/batch = 0.6973s	
968/28500 (epoch 1.698), train_loss = 1.97055277, grad/param norm = 2.9294e-01, time/batch = 0.6946s	
969/28500 (epoch 1.700), train_loss = 1.97773198, grad/param norm = 2.6438e-01, time/batch = 0.6937s	
970/28500 (epoch 1.702), train_loss = 2.13343944, grad/param norm = 2.7001e-01, time/batch = 0.6944s	
971/28500 (epoch 1.704), train_loss = 1.97108350, grad/param norm = 2.8574e-01, time/batch = 0.6937s	
972/28500 (epoch 1.705), train_loss = 2.04341608, grad/param norm = 3.0733e-01, time/batch = 0.6961s	
973/28500 (epoch 1.707), train_loss = 2.10597558, grad/param norm = 3.1874e-01, time/batch = 0.7020s	
974/28500 (epoch 1.709), train_loss = 2.10625905, grad/param norm = 2.7834e-01, time/batch = 0.7012s	
975/28500 (epoch 1.711), train_loss = 1.90047958, grad/param norm = 2.9355e-01, time/batch = 0.6937s	
976/28500 (epoch 1.712), train_loss = 2.01293817, grad/param norm = 3.0253e-01, time/batch = 0.6904s	
977/28500 (epoch 1.714), train_loss = 2.04519144, grad/param norm = 2.8646e-01, time/batch = 0.6896s	
978/28500 (epoch 1.716), train_loss = 2.13132907, grad/param norm = 2.6267e-01, time/batch = 0.6919s	
979/28500 (epoch 1.718), train_loss = 1.94879094, grad/param norm = 2.5418e-01, time/batch = 0.6898s	
980/28500 (epoch 1.719), train_loss = 1.95414936, grad/param norm = 2.4917e-01, time/batch = 0.6903s	
981/28500 (epoch 1.721), train_loss = 1.82998514, grad/param norm = 2.7800e-01, time/batch = 0.6941s	
982/28500 (epoch 1.723), train_loss = 2.04245768, grad/param norm = 2.8542e-01, time/batch = 0.6921s	
983/28500 (epoch 1.725), train_loss = 2.09756087, grad/param norm = 2.8573e-01, time/batch = 0.6902s	
984/28500 (epoch 1.726), train_loss = 2.01928662, grad/param norm = 2.7504e-01, time/batch = 0.6895s	
985/28500 (epoch 1.728), train_loss = 1.92942082, grad/param norm = 2.5368e-01, time/batch = 0.6899s	
986/28500 (epoch 1.730), train_loss = 2.12320874, grad/param norm = 3.3120e-01, time/batch = 0.6899s	
987/28500 (epoch 1.732), train_loss = 1.91812573, grad/param norm = 4.6190e-01, time/batch = 0.6924s	
988/28500 (epoch 1.733), train_loss = 2.00068985, grad/param norm = 4.1274e-01, time/batch = 0.6947s	
989/28500 (epoch 1.735), train_loss = 1.92545513, grad/param norm = 3.1182e-01, time/batch = 0.6915s	
990/28500 (epoch 1.737), train_loss = 1.92384064, grad/param norm = 2.6382e-01, time/batch = 0.6926s	
991/28500 (epoch 1.739), train_loss = 2.05146762, grad/param norm = 2.5928e-01, time/batch = 0.6954s	
992/28500 (epoch 1.740), train_loss = 1.96318781, grad/param norm = 2.7573e-01, time/batch = 0.6974s	
993/28500 (epoch 1.742), train_loss = 2.02720695, grad/param norm = 2.4534e-01, time/batch = 0.6942s	
994/28500 (epoch 1.744), train_loss = 2.04933443, grad/param norm = 2.7842e-01, time/batch = 0.6937s	
995/28500 (epoch 1.746), train_loss = 1.90310463, grad/param norm = 2.9415e-01, time/batch = 0.6963s	
996/28500 (epoch 1.747), train_loss = 1.87353791, grad/param norm = 3.0801e-01, time/batch = 0.6923s	
997/28500 (epoch 1.749), train_loss = 2.27797018, grad/param norm = 3.3523e-01, time/batch = 0.6930s	
998/28500 (epoch 1.751), train_loss = 1.95761698, grad/param norm = 2.6696e-01, time/batch = 0.6936s	
999/28500 (epoch 1.753), train_loss = 1.80889810, grad/param norm = 2.3430e-01, time/batch = 0.7111s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch1.75_2.0663.t7	
1000/28500 (epoch 1.754), train_loss = 1.90517108, grad/param norm = 2.5138e-01, time/batch = 0.6999s	
1001/28500 (epoch 1.756), train_loss = 2.16762270, grad/param norm = 2.5890e-01, time/batch = 0.7059s	
1002/28500 (epoch 1.758), train_loss = 2.00095698, grad/param norm = 2.3825e-01, time/batch = 0.6951s	
1003/28500 (epoch 1.760), train_loss = 1.94437323, grad/param norm = 3.1386e-01, time/batch = 0.6949s	
1004/28500 (epoch 1.761), train_loss = 2.06604328, grad/param norm = 3.4788e-01, time/batch = 0.7013s	
1005/28500 (epoch 1.763), train_loss = 1.87909806, grad/param norm = 3.3947e-01, time/batch = 0.6970s	
1006/28500 (epoch 1.765), train_loss = 1.90502338, grad/param norm = 2.8086e-01, time/batch = 0.7015s	
1007/28500 (epoch 1.767), train_loss = 1.81740042, grad/param norm = 2.6415e-01, time/batch = 0.6999s	
1008/28500 (epoch 1.768), train_loss = 2.11476654, grad/param norm = 2.7077e-01, time/batch = 0.6985s	
1009/28500 (epoch 1.770), train_loss = 1.95134782, grad/param norm = 2.7709e-01, time/batch = 0.6924s	
1010/28500 (epoch 1.772), train_loss = 1.89255984, grad/param norm = 3.1573e-01, time/batch = 0.6934s	
1011/28500 (epoch 1.774), train_loss = 1.95703125, grad/param norm = 3.1465e-01, time/batch = 0.6957s	
1012/28500 (epoch 1.775), train_loss = 2.13131607, grad/param norm = 2.6408e-01, time/batch = 0.6961s	
1013/28500 (epoch 1.777), train_loss = 1.95955184, grad/param norm = 2.5239e-01, time/batch = 0.6956s	
1014/28500 (epoch 1.779), train_loss = 2.00452179, grad/param norm = 3.0715e-01, time/batch = 0.7051s	
1015/28500 (epoch 1.781), train_loss = 2.03980564, grad/param norm = 3.3295e-01, time/batch = 0.6883s	
1016/28500 (epoch 1.782), train_loss = 2.13573212, grad/param norm = 3.2904e-01, time/batch = 0.6900s	
1017/28500 (epoch 1.784), train_loss = 1.88198887, grad/param norm = 2.4044e-01, time/batch = 0.6883s	
1018/28500 (epoch 1.786), train_loss = 2.02740587, grad/param norm = 2.4935e-01, time/batch = 0.6949s	
1019/28500 (epoch 1.788), train_loss = 2.13396463, grad/param norm = 2.9040e-01, time/batch = 0.6948s	
1020/28500 (epoch 1.789), train_loss = 1.96619868, grad/param norm = 4.2318e-01, time/batch = 0.6927s	
1021/28500 (epoch 1.791), train_loss = 1.98593430, grad/param norm = 3.8300e-01, time/batch = 0.6915s	
1022/28500 (epoch 1.793), train_loss = 1.89492371, grad/param norm = 3.0716e-01, time/batch = 0.6929s	
1023/28500 (epoch 1.795), train_loss = 2.04501045, grad/param norm = 3.1831e-01, time/batch = 0.6949s	
1024/28500 (epoch 1.796), train_loss = 1.92172992, grad/param norm = 3.0560e-01, time/batch = 0.6942s	
1025/28500 (epoch 1.798), train_loss = 1.96248652, grad/param norm = 3.2563e-01, time/batch = 0.7126s	
1026/28500 (epoch 1.800), train_loss = 1.96327178, grad/param norm = 3.2440e-01, time/batch = 0.6957s	
1027/28500 (epoch 1.802), train_loss = 2.09553872, grad/param norm = 3.3743e-01, time/batch = 0.7036s	
1028/28500 (epoch 1.804), train_loss = 1.96665785, grad/param norm = 2.8368e-01, time/batch = 0.6967s	
1029/28500 (epoch 1.805), train_loss = 2.03881778, grad/param norm = 2.6978e-01, time/batch = 0.7014s	
1030/28500 (epoch 1.807), train_loss = 2.15624983, grad/param norm = 2.4197e-01, time/batch = 0.6901s	
1031/28500 (epoch 1.809), train_loss = 1.89873892, grad/param norm = 2.4618e-01, time/batch = 0.6910s	
1032/28500 (epoch 1.811), train_loss = 2.15943931, grad/param norm = 2.7817e-01, time/batch = 0.6898s	
1033/28500 (epoch 1.812), train_loss = 2.05786164, grad/param norm = 2.8277e-01, time/batch = 0.6897s	
1034/28500 (epoch 1.814), train_loss = 2.00103317, grad/param norm = 3.0395e-01, time/batch = 0.6933s	
1035/28500 (epoch 1.816), train_loss = 2.06263425, grad/param norm = 2.3936e-01, time/batch = 0.6957s	
1036/28500 (epoch 1.818), train_loss = 1.94699670, grad/param norm = 2.5206e-01, time/batch = 0.6935s	
1037/28500 (epoch 1.819), train_loss = 1.96991670, grad/param norm = 2.9551e-01, time/batch = 0.6914s	
1038/28500 (epoch 1.821), train_loss = 2.01492921, grad/param norm = 3.3642e-01, time/batch = 0.7020s	
1039/28500 (epoch 1.823), train_loss = 2.22480138, grad/param norm = 3.1915e-01, time/batch = 0.7044s	
1040/28500 (epoch 1.825), train_loss = 1.93391454, grad/param norm = 2.6926e-01, time/batch = 0.6945s	
1041/28500 (epoch 1.826), train_loss = 2.02232980, grad/param norm = 3.0418e-01, time/batch = 0.6942s	
1042/28500 (epoch 1.828), train_loss = 1.85632937, grad/param norm = 2.6269e-01, time/batch = 0.6915s	
1043/28500 (epoch 1.830), train_loss = 1.90323189, grad/param norm = 2.6137e-01, time/batch = 0.6914s	
1044/28500 (epoch 1.832), train_loss = 2.07399717, grad/param norm = 2.8445e-01, time/batch = 0.6911s	
1045/28500 (epoch 1.833), train_loss = 2.09739192, grad/param norm = 2.8685e-01, time/batch = 0.6894s	
1046/28500 (epoch 1.835), train_loss = 1.97481153, grad/param norm = 3.4432e-01, time/batch = 0.6895s	
1047/28500 (epoch 1.837), train_loss = 1.93281569, grad/param norm = 2.9733e-01, time/batch = 0.6901s	
1048/28500 (epoch 1.839), train_loss = 2.09142721, grad/param norm = 2.6913e-01, time/batch = 0.6890s	
1049/28500 (epoch 1.840), train_loss = 2.07689661, grad/param norm = 2.6993e-01, time/batch = 0.6888s	
1050/28500 (epoch 1.842), train_loss = 1.98695224, grad/param norm = 2.7644e-01, time/batch = 0.6887s	
1051/28500 (epoch 1.844), train_loss = 2.00653737, grad/param norm = 2.8316e-01, time/batch = 0.6905s	
1052/28500 (epoch 1.846), train_loss = 2.08486826, grad/param norm = 2.8094e-01, time/batch = 0.6888s	
1053/28500 (epoch 1.847), train_loss = 1.94634822, grad/param norm = 2.4555e-01, time/batch = 0.6894s	
1054/28500 (epoch 1.849), train_loss = 1.89064433, grad/param norm = 2.3819e-01, time/batch = 0.6889s	
1055/28500 (epoch 1.851), train_loss = 1.84681464, grad/param norm = 2.4058e-01, time/batch = 0.6894s	
1056/28500 (epoch 1.853), train_loss = 2.06839684, grad/param norm = 2.5295e-01, time/batch = 0.6921s	
1057/28500 (epoch 1.854), train_loss = 1.91121265, grad/param norm = 2.3250e-01, time/batch = 0.6922s	
1058/28500 (epoch 1.856), train_loss = 2.08218293, grad/param norm = 3.1031e-01, time/batch = 0.6895s	
1059/28500 (epoch 1.858), train_loss = 1.84319086, grad/param norm = 2.4243e-01, time/batch = 0.6889s	
1060/28500 (epoch 1.860), train_loss = 2.01802933, grad/param norm = 2.4765e-01, time/batch = 0.6908s	
1061/28500 (epoch 1.861), train_loss = 1.89949013, grad/param norm = 2.3690e-01, time/batch = 0.6924s	
1062/28500 (epoch 1.863), train_loss = 2.12653981, grad/param norm = 2.7834e-01, time/batch = 0.6923s	
1063/28500 (epoch 1.865), train_loss = 1.97072165, grad/param norm = 2.7245e-01, time/batch = 0.6927s	
1064/28500 (epoch 1.867), train_loss = 2.04360478, grad/param norm = 2.4352e-01, time/batch = 0.7065s	
1065/28500 (epoch 1.868), train_loss = 1.78309495, grad/param norm = 2.9691e-01, time/batch = 0.6926s	
1066/28500 (epoch 1.870), train_loss = 1.78983253, grad/param norm = 2.9070e-01, time/batch = 0.6936s	
1067/28500 (epoch 1.872), train_loss = 2.15199529, grad/param norm = 3.4878e-01, time/batch = 0.6931s	
1068/28500 (epoch 1.874), train_loss = 1.96957099, grad/param norm = 3.3603e-01, time/batch = 0.6923s	
1069/28500 (epoch 1.875), train_loss = 2.04705708, grad/param norm = 3.2322e-01, time/batch = 0.7140s	
1070/28500 (epoch 1.877), train_loss = 1.97383050, grad/param norm = 2.7703e-01, time/batch = 0.6982s	
1071/28500 (epoch 1.879), train_loss = 1.97219269, grad/param norm = 2.4454e-01, time/batch = 0.7191s	
1072/28500 (epoch 1.881), train_loss = 2.02948225, grad/param norm = 2.5511e-01, time/batch = 0.7223s	
1073/28500 (epoch 1.882), train_loss = 1.92744637, grad/param norm = 2.8798e-01, time/batch = 0.7257s	
1074/28500 (epoch 1.884), train_loss = 2.04286768, grad/param norm = 3.1864e-01, time/batch = 0.7152s	
1075/28500 (epoch 1.886), train_loss = 1.83809271, grad/param norm = 3.3063e-01, time/batch = 0.7020s	
1076/28500 (epoch 1.888), train_loss = 1.80149160, grad/param norm = 2.5658e-01, time/batch = 0.7012s	
1077/28500 (epoch 1.889), train_loss = 1.80963862, grad/param norm = 2.3890e-01, time/batch = 0.6955s	
1078/28500 (epoch 1.891), train_loss = 1.98564411, grad/param norm = 2.6813e-01, time/batch = 0.6972s	
1079/28500 (epoch 1.893), train_loss = 1.98890518, grad/param norm = 2.5554e-01, time/batch = 0.7009s	
1080/28500 (epoch 1.895), train_loss = 2.12862772, grad/param norm = 3.2541e-01, time/batch = 0.6942s	
1081/28500 (epoch 1.896), train_loss = 2.10821633, grad/param norm = 2.8885e-01, time/batch = 0.6987s	
1082/28500 (epoch 1.898), train_loss = 1.86182507, grad/param norm = 2.3982e-01, time/batch = 0.6946s	
1083/28500 (epoch 1.900), train_loss = 1.85357778, grad/param norm = 2.4561e-01, time/batch = 0.6950s	
1084/28500 (epoch 1.902), train_loss = 1.90676712, grad/param norm = 2.6428e-01, time/batch = 0.6987s	
1085/28500 (epoch 1.904), train_loss = 1.88310162, grad/param norm = 2.4706e-01, time/batch = 0.6939s	
1086/28500 (epoch 1.905), train_loss = 2.05663030, grad/param norm = 2.6015e-01, time/batch = 0.6892s	
1087/28500 (epoch 1.907), train_loss = 2.19428380, grad/param norm = 2.8769e-01, time/batch = 0.6923s	
1088/28500 (epoch 1.909), train_loss = 1.90266353, grad/param norm = 3.0420e-01, time/batch = 0.6883s	
1089/28500 (epoch 1.911), train_loss = 1.94879075, grad/param norm = 2.8123e-01, time/batch = 0.6881s	
1090/28500 (epoch 1.912), train_loss = 1.73875772, grad/param norm = 3.0456e-01, time/batch = 0.6883s	
1091/28500 (epoch 1.914), train_loss = 2.11448966, grad/param norm = 3.7884e-01, time/batch = 0.6909s	
1092/28500 (epoch 1.916), train_loss = 2.01404817, grad/param norm = 3.2751e-01, time/batch = 0.6897s	
1093/28500 (epoch 1.918), train_loss = 2.14185110, grad/param norm = 2.7578e-01, time/batch = 0.6896s	
1094/28500 (epoch 1.919), train_loss = 1.83564738, grad/param norm = 2.4891e-01, time/batch = 0.6899s	
1095/28500 (epoch 1.921), train_loss = 2.11339105, grad/param norm = 2.6781e-01, time/batch = 0.6911s	
1096/28500 (epoch 1.923), train_loss = 2.09883070, grad/param norm = 2.9470e-01, time/batch = 0.6906s	
1097/28500 (epoch 1.925), train_loss = 1.89135528, grad/param norm = 2.5838e-01, time/batch = 0.6915s	
1098/28500 (epoch 1.926), train_loss = 2.03677338, grad/param norm = 2.9176e-01, time/batch = 0.6973s	
1099/28500 (epoch 1.928), train_loss = 1.87306967, grad/param norm = 2.5175e-01, time/batch = 0.7005s	
1100/28500 (epoch 1.930), train_loss = 1.68101544, grad/param norm = 2.3970e-01, time/batch = 0.7092s	
1101/28500 (epoch 1.932), train_loss = 1.83108815, grad/param norm = 2.3908e-01, time/batch = 0.7097s	
1102/28500 (epoch 1.933), train_loss = 1.97031597, grad/param norm = 2.5970e-01, time/batch = 0.7074s	
1103/28500 (epoch 1.935), train_loss = 1.88671099, grad/param norm = 2.5097e-01, time/batch = 0.7026s	
1104/28500 (epoch 1.937), train_loss = 2.04119306, grad/param norm = 2.5465e-01, time/batch = 0.6979s	
1105/28500 (epoch 1.939), train_loss = 2.19743688, grad/param norm = 2.8113e-01, time/batch = 0.6979s	
1106/28500 (epoch 1.940), train_loss = 2.01001473, grad/param norm = 2.7142e-01, time/batch = 0.6990s	
1107/28500 (epoch 1.942), train_loss = 2.05586214, grad/param norm = 3.6097e-01, time/batch = 0.7013s	
1108/28500 (epoch 1.944), train_loss = 2.00247545, grad/param norm = 2.9730e-01, time/batch = 0.6972s	
1109/28500 (epoch 1.946), train_loss = 2.08861857, grad/param norm = 3.0382e-01, time/batch = 0.6994s	
1110/28500 (epoch 1.947), train_loss = 2.27338305, grad/param norm = 2.9960e-01, time/batch = 0.6987s	
1111/28500 (epoch 1.949), train_loss = 1.84579796, grad/param norm = 3.1534e-01, time/batch = 0.7005s	
1112/28500 (epoch 1.951), train_loss = 2.11868656, grad/param norm = 2.6551e-01, time/batch = 0.6985s	
1113/28500 (epoch 1.953), train_loss = 2.02720498, grad/param norm = 2.8744e-01, time/batch = 0.6977s	
1114/28500 (epoch 1.954), train_loss = 2.01160650, grad/param norm = 2.7676e-01, time/batch = 0.7009s	
1115/28500 (epoch 1.956), train_loss = 2.01227593, grad/param norm = 2.9652e-01, time/batch = 0.6970s	
1116/28500 (epoch 1.958), train_loss = 1.96368675, grad/param norm = 2.6577e-01, time/batch = 0.6981s	
1117/28500 (epoch 1.960), train_loss = 1.87113645, grad/param norm = 3.1231e-01, time/batch = 0.6962s	
1118/28500 (epoch 1.961), train_loss = 2.10286304, grad/param norm = 3.1064e-01, time/batch = 0.6975s	
1119/28500 (epoch 1.963), train_loss = 2.00743181, grad/param norm = 2.4669e-01, time/batch = 0.6976s	
1120/28500 (epoch 1.965), train_loss = 1.89983929, grad/param norm = 2.4654e-01, time/batch = 0.6993s	
1121/28500 (epoch 1.967), train_loss = 1.76784944, grad/param norm = 2.3448e-01, time/batch = 0.7023s	
1122/28500 (epoch 1.968), train_loss = 1.79888460, grad/param norm = 2.5552e-01, time/batch = 0.6965s	
1123/28500 (epoch 1.970), train_loss = 2.11394170, grad/param norm = 3.2916e-01, time/batch = 0.6978s	
1124/28500 (epoch 1.972), train_loss = 2.24956990, grad/param norm = 3.1539e-01, time/batch = 0.6990s	
1125/28500 (epoch 1.974), train_loss = 2.13993224, grad/param norm = 2.8354e-01, time/batch = 0.6973s	
1126/28500 (epoch 1.975), train_loss = 1.95593769, grad/param norm = 2.3848e-01, time/batch = 0.6979s	
1127/28500 (epoch 1.977), train_loss = 2.14737189, grad/param norm = 2.7746e-01, time/batch = 0.6974s	
1128/28500 (epoch 1.979), train_loss = 1.95311048, grad/param norm = 2.5815e-01, time/batch = 0.6978s	
1129/28500 (epoch 1.981), train_loss = 1.90191077, grad/param norm = 2.5916e-01, time/batch = 0.6990s	
1130/28500 (epoch 1.982), train_loss = 1.78712532, grad/param norm = 2.4790e-01, time/batch = 0.7000s	
1131/28500 (epoch 1.984), train_loss = 2.01740088, grad/param norm = 2.4892e-01, time/batch = 0.7011s	
1132/28500 (epoch 1.986), train_loss = 2.03026754, grad/param norm = 2.3223e-01, time/batch = 0.7016s	
1133/28500 (epoch 1.988), train_loss = 1.77069950, grad/param norm = 2.2513e-01, time/batch = 0.6999s	
1134/28500 (epoch 1.989), train_loss = 1.97205203, grad/param norm = 2.7001e-01, time/batch = 0.6979s	
1135/28500 (epoch 1.991), train_loss = 1.94317675, grad/param norm = 2.9305e-01, time/batch = 0.6973s	
1136/28500 (epoch 1.993), train_loss = 2.00976079, grad/param norm = 3.1051e-01, time/batch = 0.6963s	
1137/28500 (epoch 1.995), train_loss = 1.84605119, grad/param norm = 2.4734e-01, time/batch = 0.6974s	
1138/28500 (epoch 1.996), train_loss = 1.86445325, grad/param norm = 2.8854e-01, time/batch = 0.6987s	
1139/28500 (epoch 1.998), train_loss = 2.02884137, grad/param norm = 3.0286e-01, time/batch = 0.6987s	
1140/28500 (epoch 2.000), train_loss = 1.93078620, grad/param norm = 2.6956e-01, time/batch = 0.6974s	
1141/28500 (epoch 2.002), train_loss = 1.98143257, grad/param norm = 2.4971e-01, time/batch = 0.7011s	
1142/28500 (epoch 2.004), train_loss = 1.86434693, grad/param norm = 3.0379e-01, time/batch = 0.6983s	
1143/28500 (epoch 2.005), train_loss = 1.96392416, grad/param norm = 2.5411e-01, time/batch = 0.6971s	
1144/28500 (epoch 2.007), train_loss = 1.76806995, grad/param norm = 2.3772e-01, time/batch = 0.6990s	
1145/28500 (epoch 2.009), train_loss = 2.06594244, grad/param norm = 2.9686e-01, time/batch = 0.6976s	
1146/28500 (epoch 2.011), train_loss = 1.92408678, grad/param norm = 3.0993e-01, time/batch = 0.6993s	
1147/28500 (epoch 2.012), train_loss = 1.80330458, grad/param norm = 2.6000e-01, time/batch = 0.6971s	
1148/28500 (epoch 2.014), train_loss = 1.82038914, grad/param norm = 2.5087e-01, time/batch = 0.6978s	
1149/28500 (epoch 2.016), train_loss = 1.86884986, grad/param norm = 2.5495e-01, time/batch = 0.6984s	
1150/28500 (epoch 2.018), train_loss = 1.91132163, grad/param norm = 3.5272e-01, time/batch = 0.6979s	
1151/28500 (epoch 2.019), train_loss = 1.89465644, grad/param norm = 2.8350e-01, time/batch = 0.7028s	
1152/28500 (epoch 2.021), train_loss = 1.83738166, grad/param norm = 2.5236e-01, time/batch = 0.7048s	
1153/28500 (epoch 2.023), train_loss = 1.92439726, grad/param norm = 2.7430e-01, time/batch = 0.7095s	
1154/28500 (epoch 2.025), train_loss = 1.77703828, grad/param norm = 2.2568e-01, time/batch = 0.6964s	
1155/28500 (epoch 2.026), train_loss = 2.00430239, grad/param norm = 3.2897e-01, time/batch = 0.6983s	
1156/28500 (epoch 2.028), train_loss = 1.98332558, grad/param norm = 3.4414e-01, time/batch = 0.6987s	
1157/28500 (epoch 2.030), train_loss = 2.02019562, grad/param norm = 2.7955e-01, time/batch = 0.6988s	
1158/28500 (epoch 2.032), train_loss = 2.01975643, grad/param norm = 2.9601e-01, time/batch = 0.7003s	
1159/28500 (epoch 2.033), train_loss = 2.12259280, grad/param norm = 2.8462e-01, time/batch = 0.7072s	
1160/28500 (epoch 2.035), train_loss = 1.98121266, grad/param norm = 3.0469e-01, time/batch = 0.7132s	
1161/28500 (epoch 2.037), train_loss = 2.02827855, grad/param norm = 2.9769e-01, time/batch = 0.6967s	
1162/28500 (epoch 2.039), train_loss = 2.08338976, grad/param norm = 2.7184e-01, time/batch = 0.6938s	
1163/28500 (epoch 2.040), train_loss = 2.01142608, grad/param norm = 2.6220e-01, time/batch = 0.6935s	
1164/28500 (epoch 2.042), train_loss = 2.13958364, grad/param norm = 2.9406e-01, time/batch = 0.6950s	
1165/28500 (epoch 2.044), train_loss = 1.95739571, grad/param norm = 2.9675e-01, time/batch = 0.6954s	
1166/28500 (epoch 2.046), train_loss = 2.06792487, grad/param norm = 2.6635e-01, time/batch = 0.6950s	
1167/28500 (epoch 2.047), train_loss = 2.08024007, grad/param norm = 2.6557e-01, time/batch = 0.6934s	
1168/28500 (epoch 2.049), train_loss = 2.01173319, grad/param norm = 2.9778e-01, time/batch = 0.6950s	
1169/28500 (epoch 2.051), train_loss = 1.95311396, grad/param norm = 2.3750e-01, time/batch = 0.6931s	
1170/28500 (epoch 2.053), train_loss = 2.07739757, grad/param norm = 2.7089e-01, time/batch = 0.6930s	
1171/28500 (epoch 2.054), train_loss = 2.00266473, grad/param norm = 2.5903e-01, time/batch = 0.6951s	
1172/28500 (epoch 2.056), train_loss = 1.84611173, grad/param norm = 2.2502e-01, time/batch = 0.6939s	
1173/28500 (epoch 2.058), train_loss = 1.89905931, grad/param norm = 2.5146e-01, time/batch = 0.6936s	
1174/28500 (epoch 2.060), train_loss = 1.92148437, grad/param norm = 2.9540e-01, time/batch = 0.6948s	
1175/28500 (epoch 2.061), train_loss = 2.09231912, grad/param norm = 3.1583e-01, time/batch = 0.6942s	
1176/28500 (epoch 2.063), train_loss = 2.14139252, grad/param norm = 2.3844e-01, time/batch = 0.6938s	
1177/28500 (epoch 2.065), train_loss = 2.21689880, grad/param norm = 2.6798e-01, time/batch = 0.6932s	
1178/28500 (epoch 2.067), train_loss = 1.96178388, grad/param norm = 3.0212e-01, time/batch = 0.6951s	
1179/28500 (epoch 2.068), train_loss = 1.82393028, grad/param norm = 2.3939e-01, time/batch = 0.6963s	
1180/28500 (epoch 2.070), train_loss = 2.05345006, grad/param norm = 2.6176e-01, time/batch = 0.6942s	
1181/28500 (epoch 2.072), train_loss = 2.19263975, grad/param norm = 2.7471e-01, time/batch = 0.6965s	
1182/28500 (epoch 2.074), train_loss = 2.01745441, grad/param norm = 2.8870e-01, time/batch = 0.6946s	
1183/28500 (epoch 2.075), train_loss = 1.91423293, grad/param norm = 2.8934e-01, time/batch = 0.6947s	
1184/28500 (epoch 2.077), train_loss = 2.00984983, grad/param norm = 2.5936e-01, time/batch = 0.6974s	
1185/28500 (epoch 2.079), train_loss = 1.93276815, grad/param norm = 2.4413e-01, time/batch = 0.7141s	
1186/28500 (epoch 2.081), train_loss = 2.07178265, grad/param norm = 2.6157e-01, time/batch = 0.6945s	
1187/28500 (epoch 2.082), train_loss = 2.06494747, grad/param norm = 3.1923e-01, time/batch = 0.6937s	
1188/28500 (epoch 2.084), train_loss = 2.06439404, grad/param norm = 2.6817e-01, time/batch = 0.6934s	
1189/28500 (epoch 2.086), train_loss = 1.83535399, grad/param norm = 2.4083e-01, time/batch = 0.6973s	
1190/28500 (epoch 2.088), train_loss = 1.82564092, grad/param norm = 2.4660e-01, time/batch = 0.6969s	
1191/28500 (epoch 2.089), train_loss = 2.10319064, grad/param norm = 2.4631e-01, time/batch = 0.6990s	
1192/28500 (epoch 2.091), train_loss = 1.83073942, grad/param norm = 2.3073e-01, time/batch = 0.7010s	
1193/28500 (epoch 2.093), train_loss = 1.94696783, grad/param norm = 2.4569e-01, time/batch = 0.6972s	
1194/28500 (epoch 2.095), train_loss = 2.00312990, grad/param norm = 2.5348e-01, time/batch = 0.6974s	
1195/28500 (epoch 2.096), train_loss = 2.01753255, grad/param norm = 2.4537e-01, time/batch = 0.6969s	
1196/28500 (epoch 2.098), train_loss = 2.11698264, grad/param norm = 2.6248e-01, time/batch = 0.7014s	
1197/28500 (epoch 2.100), train_loss = 1.88932663, grad/param norm = 2.7070e-01, time/batch = 0.6973s	
1198/28500 (epoch 2.102), train_loss = 2.08831199, grad/param norm = 2.2831e-01, time/batch = 0.6972s	
1199/28500 (epoch 2.104), train_loss = 1.96318812, grad/param norm = 2.5498e-01, time/batch = 0.7003s	
1200/28500 (epoch 2.105), train_loss = 1.99896001, grad/param norm = 3.1825e-01, time/batch = 0.7000s	
1201/28500 (epoch 2.107), train_loss = 1.88119876, grad/param norm = 3.6996e-01, time/batch = 0.7023s	
1202/28500 (epoch 2.109), train_loss = 1.89604335, grad/param norm = 2.7278e-01, time/batch = 0.6987s	
1203/28500 (epoch 2.111), train_loss = 1.97084970, grad/param norm = 2.5920e-01, time/batch = 0.7006s	
1204/28500 (epoch 2.112), train_loss = 2.01892137, grad/param norm = 2.4989e-01, time/batch = 0.6940s	
1205/28500 (epoch 2.114), train_loss = 1.86519868, grad/param norm = 2.5182e-01, time/batch = 0.6937s	
1206/28500 (epoch 2.116), train_loss = 2.08793669, grad/param norm = 2.7978e-01, time/batch = 0.6946s	
1207/28500 (epoch 2.118), train_loss = 1.84138938, grad/param norm = 3.1302e-01, time/batch = 0.6935s	
1208/28500 (epoch 2.119), train_loss = 2.05421869, grad/param norm = 3.0559e-01, time/batch = 0.6931s	
1209/28500 (epoch 2.121), train_loss = 2.16439010, grad/param norm = 2.6772e-01, time/batch = 0.6943s	
1210/28500 (epoch 2.123), train_loss = 1.97481375, grad/param norm = 2.8125e-01, time/batch = 0.6940s	
1211/28500 (epoch 2.125), train_loss = 2.11708095, grad/param norm = 2.5192e-01, time/batch = 0.6950s	
1212/28500 (epoch 2.126), train_loss = 1.99645243, grad/param norm = 2.5341e-01, time/batch = 0.6941s	
1213/28500 (epoch 2.128), train_loss = 1.94670059, grad/param norm = 3.0376e-01, time/batch = 0.6936s	
1214/28500 (epoch 2.130), train_loss = 2.01074536, grad/param norm = 2.4910e-01, time/batch = 0.6929s	
1215/28500 (epoch 2.132), train_loss = 2.03937339, grad/param norm = 2.8144e-01, time/batch = 0.6947s	
1216/28500 (epoch 2.133), train_loss = 1.88051560, grad/param norm = 2.2501e-01, time/batch = 0.6951s	
1217/28500 (epoch 2.135), train_loss = 1.92672439, grad/param norm = 2.2161e-01, time/batch = 0.6944s	
1218/28500 (epoch 2.137), train_loss = 1.84997289, grad/param norm = 2.7772e-01, time/batch = 0.6924s	
1219/28500 (epoch 2.139), train_loss = 1.90134010, grad/param norm = 2.6279e-01, time/batch = 0.6929s	
1220/28500 (epoch 2.140), train_loss = 1.93229591, grad/param norm = 2.4116e-01, time/batch = 0.6995s	
1221/28500 (epoch 2.142), train_loss = 1.98146307, grad/param norm = 2.5456e-01, time/batch = 0.6955s	
1222/28500 (epoch 2.144), train_loss = 1.86641869, grad/param norm = 2.8343e-01, time/batch = 0.6941s	
1223/28500 (epoch 2.146), train_loss = 1.87614023, grad/param norm = 3.2721e-01, time/batch = 0.6925s	
1224/28500 (epoch 2.147), train_loss = 1.79017453, grad/param norm = 2.3244e-01, time/batch = 0.6924s	
1225/28500 (epoch 2.149), train_loss = 1.88158557, grad/param norm = 2.4286e-01, time/batch = 0.6926s	
1226/28500 (epoch 2.151), train_loss = 1.83983920, grad/param norm = 2.3983e-01, time/batch = 0.6924s	
1227/28500 (epoch 2.153), train_loss = 1.87344893, grad/param norm = 2.7617e-01, time/batch = 0.6933s	
1228/28500 (epoch 2.154), train_loss = 1.88052322, grad/param norm = 2.5252e-01, time/batch = 0.6928s	
1229/28500 (epoch 2.156), train_loss = 2.15272556, grad/param norm = 2.6872e-01, time/batch = 0.6930s	
1230/28500 (epoch 2.158), train_loss = 1.89201687, grad/param norm = 2.5567e-01, time/batch = 0.6947s	
1231/28500 (epoch 2.160), train_loss = 1.83502696, grad/param norm = 2.9412e-01, time/batch = 0.6953s	
1232/28500 (epoch 2.161), train_loss = 2.02045305, grad/param norm = 3.1826e-01, time/batch = 0.6938s	
1233/28500 (epoch 2.163), train_loss = 1.87410327, grad/param norm = 3.1024e-01, time/batch = 0.6958s	
1234/28500 (epoch 2.165), train_loss = 2.06115747, grad/param norm = 2.3225e-01, time/batch = 0.6947s	
1235/28500 (epoch 2.167), train_loss = 2.08007719, grad/param norm = 2.3489e-01, time/batch = 0.6956s	
1236/28500 (epoch 2.168), train_loss = 2.02071997, grad/param norm = 3.1536e-01, time/batch = 0.6940s	
1237/28500 (epoch 2.170), train_loss = 2.12149350, grad/param norm = 2.9531e-01, time/batch = 0.6932s	
1238/28500 (epoch 2.172), train_loss = 1.95224744, grad/param norm = 3.2743e-01, time/batch = 0.6945s	
1239/28500 (epoch 2.174), train_loss = 2.12331457, grad/param norm = 2.4352e-01, time/batch = 0.6927s	
1240/28500 (epoch 2.175), train_loss = 1.92558857, grad/param norm = 2.4726e-01, time/batch = 0.6928s	
1241/28500 (epoch 2.177), train_loss = 2.05319192, grad/param norm = 2.5070e-01, time/batch = 0.6955s	
1242/28500 (epoch 2.179), train_loss = 1.88804439, grad/param norm = 2.7640e-01, time/batch = 0.6944s	
1243/28500 (epoch 2.181), train_loss = 2.06507567, grad/param norm = 2.5454e-01, time/batch = 0.6947s	
1244/28500 (epoch 2.182), train_loss = 1.98339486, grad/param norm = 3.0995e-01, time/batch = 0.6978s	
1245/28500 (epoch 2.184), train_loss = 2.08647884, grad/param norm = 2.9323e-01, time/batch = 0.6996s	
1246/28500 (epoch 2.186), train_loss = 2.05386699, grad/param norm = 2.7702e-01, time/batch = 0.7110s	
1247/28500 (epoch 2.188), train_loss = 1.92162885, grad/param norm = 2.5461e-01, time/batch = 0.7018s	
1248/28500 (epoch 2.189), train_loss = 2.09009003, grad/param norm = 2.7942e-01, time/batch = 0.6959s	
1249/28500 (epoch 2.191), train_loss = 2.12765328, grad/param norm = 2.5049e-01, time/batch = 0.6965s	
1250/28500 (epoch 2.193), train_loss = 1.97536798, grad/param norm = 2.7904e-01, time/batch = 0.6955s	
1251/28500 (epoch 2.195), train_loss = 2.03748917, grad/param norm = 2.9338e-01, time/batch = 0.6987s	
1252/28500 (epoch 2.196), train_loss = 1.93426015, grad/param norm = 2.5750e-01, time/batch = 0.6955s	
1253/28500 (epoch 2.198), train_loss = 1.91882075, grad/param norm = 2.6216e-01, time/batch = 0.6975s	
1254/28500 (epoch 2.200), train_loss = 1.93392644, grad/param norm = 2.2536e-01, time/batch = 0.6934s	
1255/28500 (epoch 2.202), train_loss = 2.02159145, grad/param norm = 2.6075e-01, time/batch = 0.6933s	
1256/28500 (epoch 2.204), train_loss = 1.77059880, grad/param norm = 2.3481e-01, time/batch = 0.6936s	
1257/28500 (epoch 2.205), train_loss = 1.82051907, grad/param norm = 2.2995e-01, time/batch = 0.6928s	
1258/28500 (epoch 2.207), train_loss = 2.00597831, grad/param norm = 2.5865e-01, time/batch = 0.6937s	
1259/28500 (epoch 2.209), train_loss = 1.88915412, grad/param norm = 2.6677e-01, time/batch = 0.6940s	
1260/28500 (epoch 2.211), train_loss = 1.85895235, grad/param norm = 2.2247e-01, time/batch = 0.6940s	
1261/28500 (epoch 2.212), train_loss = 1.82481319, grad/param norm = 2.4239e-01, time/batch = 0.6956s	
1262/28500 (epoch 2.214), train_loss = 2.05837527, grad/param norm = 2.4951e-01, time/batch = 0.6978s	
1263/28500 (epoch 2.216), train_loss = 1.84197204, grad/param norm = 2.1878e-01, time/batch = 0.7102s	
1264/28500 (epoch 2.218), train_loss = 1.91907709, grad/param norm = 2.2486e-01, time/batch = 0.6994s	
1265/28500 (epoch 2.219), train_loss = 1.84652512, grad/param norm = 2.2478e-01, time/batch = 0.6962s	
1266/28500 (epoch 2.221), train_loss = 1.81185259, grad/param norm = 2.2023e-01, time/batch = 0.6968s	
1267/28500 (epoch 2.223), train_loss = 2.01785497, grad/param norm = 2.4866e-01, time/batch = 0.6952s	
1268/28500 (epoch 2.225), train_loss = 2.08785160, grad/param norm = 2.7939e-01, time/batch = 0.6928s	
1269/28500 (epoch 2.226), train_loss = 2.00122403, grad/param norm = 2.7421e-01, time/batch = 0.7025s	
1270/28500 (epoch 2.228), train_loss = 1.94179822, grad/param norm = 2.8377e-01, time/batch = 0.7087s	
1271/28500 (epoch 2.230), train_loss = 1.90901089, grad/param norm = 2.4428e-01, time/batch = 0.7344s	
1272/28500 (epoch 2.232), train_loss = 1.98504747, grad/param norm = 2.5867e-01, time/batch = 0.7158s	
1273/28500 (epoch 2.233), train_loss = 1.96445292, grad/param norm = 3.3192e-01, time/batch = 0.7046s	
1274/28500 (epoch 2.235), train_loss = 1.85742781, grad/param norm = 3.1334e-01, time/batch = 0.7032s	
1275/28500 (epoch 2.237), train_loss = 1.79791930, grad/param norm = 2.2728e-01, time/batch = 0.6996s	
1276/28500 (epoch 2.239), train_loss = 1.85767721, grad/param norm = 2.6024e-01, time/batch = 0.7017s	
1277/28500 (epoch 2.240), train_loss = 1.84124778, grad/param norm = 2.6937e-01, time/batch = 0.6941s	
1278/28500 (epoch 2.242), train_loss = 1.98171513, grad/param norm = 2.7635e-01, time/batch = 0.6974s	
1279/28500 (epoch 2.244), train_loss = 2.03381833, grad/param norm = 2.4811e-01, time/batch = 0.6992s	
1280/28500 (epoch 2.246), train_loss = 1.90303937, grad/param norm = 2.4119e-01, time/batch = 0.7123s	
1281/28500 (epoch 2.247), train_loss = 2.07008673, grad/param norm = 2.4129e-01, time/batch = 0.7064s	
1282/28500 (epoch 2.249), train_loss = 1.94836928, grad/param norm = 2.5131e-01, time/batch = 0.7012s	
1283/28500 (epoch 2.251), train_loss = 1.67079470, grad/param norm = 2.1540e-01, time/batch = 0.6982s	
1284/28500 (epoch 2.253), train_loss = 1.98448125, grad/param norm = 2.4557e-01, time/batch = 0.6963s	
1285/28500 (epoch 2.254), train_loss = 1.96391879, grad/param norm = 2.3268e-01, time/batch = 0.6964s	
1286/28500 (epoch 2.256), train_loss = 1.88509794, grad/param norm = 2.3017e-01, time/batch = 0.6932s	
1287/28500 (epoch 2.258), train_loss = 1.90268913, grad/param norm = 2.7370e-01, time/batch = 0.6995s	
1288/28500 (epoch 2.260), train_loss = 1.91385999, grad/param norm = 2.6302e-01, time/batch = 0.6986s	
1289/28500 (epoch 2.261), train_loss = 1.86893988, grad/param norm = 2.7841e-01, time/batch = 0.7003s	
1290/28500 (epoch 2.263), train_loss = 2.09667450, grad/param norm = 2.8174e-01, time/batch = 0.6929s	
1291/28500 (epoch 2.265), train_loss = 2.02012690, grad/param norm = 2.5042e-01, time/batch = 0.6950s	
1292/28500 (epoch 2.267), train_loss = 2.05891205, grad/param norm = 2.6102e-01, time/batch = 0.7013s	
1293/28500 (epoch 2.268), train_loss = 1.97912893, grad/param norm = 2.5961e-01, time/batch = 0.7065s	
1294/28500 (epoch 2.270), train_loss = 1.82962435, grad/param norm = 2.2647e-01, time/batch = 0.6920s	
1295/28500 (epoch 2.272), train_loss = 1.90480616, grad/param norm = 2.9754e-01, time/batch = 0.6917s	
1296/28500 (epoch 2.274), train_loss = 2.06384351, grad/param norm = 2.8824e-01, time/batch = 0.6920s	
1297/28500 (epoch 2.275), train_loss = 1.98011688, grad/param norm = 2.7037e-01, time/batch = 0.6921s	
1298/28500 (epoch 2.277), train_loss = 1.89540577, grad/param norm = 2.6768e-01, time/batch = 0.6923s	
1299/28500 (epoch 2.279), train_loss = 1.92244961, grad/param norm = 2.6419e-01, time/batch = 0.6929s	
1300/28500 (epoch 2.281), train_loss = 1.92841441, grad/param norm = 2.6648e-01, time/batch = 0.7042s	
1301/28500 (epoch 2.282), train_loss = 1.84431144, grad/param norm = 2.4349e-01, time/batch = 0.7058s	
1302/28500 (epoch 2.284), train_loss = 1.95724287, grad/param norm = 2.4908e-01, time/batch = 0.6934s	
1303/28500 (epoch 2.286), train_loss = 2.05302349, grad/param norm = 2.6763e-01, time/batch = 0.6924s	
1304/28500 (epoch 2.288), train_loss = 1.90864886, grad/param norm = 2.5838e-01, time/batch = 0.6931s	
1305/28500 (epoch 2.289), train_loss = 2.12937721, grad/param norm = 2.5099e-01, time/batch = 0.6922s	
1306/28500 (epoch 2.291), train_loss = 1.78855671, grad/param norm = 2.4643e-01, time/batch = 0.6924s	
1307/28500 (epoch 2.293), train_loss = 1.86934124, grad/param norm = 2.5192e-01, time/batch = 0.6933s	
1308/28500 (epoch 2.295), train_loss = 1.84764343, grad/param norm = 2.3845e-01, time/batch = 0.7087s	
1309/28500 (epoch 2.296), train_loss = 1.78725089, grad/param norm = 2.2964e-01, time/batch = 0.7007s	
1310/28500 (epoch 2.298), train_loss = 1.88275440, grad/param norm = 2.3654e-01, time/batch = 0.6919s	
1311/28500 (epoch 2.300), train_loss = 1.78259922, grad/param norm = 2.5231e-01, time/batch = 0.6972s	
1312/28500 (epoch 2.302), train_loss = 1.81066423, grad/param norm = 2.5595e-01, time/batch = 0.6970s	
1313/28500 (epoch 2.304), train_loss = 1.77815151, grad/param norm = 2.0972e-01, time/batch = 0.6970s	
1314/28500 (epoch 2.305), train_loss = 1.94125645, grad/param norm = 2.3754e-01, time/batch = 0.6952s	
1315/28500 (epoch 2.307), train_loss = 2.00804339, grad/param norm = 3.1364e-01, time/batch = 0.6969s	
1316/28500 (epoch 2.309), train_loss = 2.03220544, grad/param norm = 2.9557e-01, time/batch = 0.7084s	
1317/28500 (epoch 2.311), train_loss = 1.87390093, grad/param norm = 2.8940e-01, time/batch = 0.6951s	
1318/28500 (epoch 2.312), train_loss = 1.72760808, grad/param norm = 2.5308e-01, time/batch = 0.6919s	
1319/28500 (epoch 2.314), train_loss = 1.89914560, grad/param norm = 2.7318e-01, time/batch = 0.6964s	
1320/28500 (epoch 2.316), train_loss = 1.89579806, grad/param norm = 2.3483e-01, time/batch = 0.6965s	
1321/28500 (epoch 2.318), train_loss = 1.91583193, grad/param norm = 2.6045e-01, time/batch = 0.6976s	
1322/28500 (epoch 2.319), train_loss = 1.88495872, grad/param norm = 2.6316e-01, time/batch = 0.6934s	
1323/28500 (epoch 2.321), train_loss = 1.99246758, grad/param norm = 2.5917e-01, time/batch = 0.6939s	
1324/28500 (epoch 2.323), train_loss = 1.91880561, grad/param norm = 2.5854e-01, time/batch = 0.6944s	
1325/28500 (epoch 2.325), train_loss = 2.11005678, grad/param norm = 2.8183e-01, time/batch = 0.7056s	
1326/28500 (epoch 2.326), train_loss = 2.10325851, grad/param norm = 2.9838e-01, time/batch = 0.7087s	
1327/28500 (epoch 2.328), train_loss = 1.72505397, grad/param norm = 2.8591e-01, time/batch = 0.6958s	
1328/28500 (epoch 2.330), train_loss = 1.85131808, grad/param norm = 2.6371e-01, time/batch = 0.6930s	
1329/28500 (epoch 2.332), train_loss = 1.81831058, grad/param norm = 2.2496e-01, time/batch = 0.6963s	
1330/28500 (epoch 2.333), train_loss = 1.73980418, grad/param norm = 2.2128e-01, time/batch = 0.6982s	
1331/28500 (epoch 2.335), train_loss = 1.71927216, grad/param norm = 2.4942e-01, time/batch = 0.6987s	
1332/28500 (epoch 2.337), train_loss = 1.94417339, grad/param norm = 2.8262e-01, time/batch = 0.6978s	
1333/28500 (epoch 2.339), train_loss = 1.87336875, grad/param norm = 2.4620e-01, time/batch = 0.6964s	
1334/28500 (epoch 2.340), train_loss = 1.98037868, grad/param norm = 2.7759e-01, time/batch = 0.6981s	
1335/28500 (epoch 2.342), train_loss = 1.78888750, grad/param norm = 2.9375e-01, time/batch = 0.6965s	
1336/28500 (epoch 2.344), train_loss = 1.86539905, grad/param norm = 3.0943e-01, time/batch = 0.6994s	
1337/28500 (epoch 2.346), train_loss = 1.61398855, grad/param norm = 2.7171e-01, time/batch = 0.6979s	
1338/28500 (epoch 2.347), train_loss = 1.89675209, grad/param norm = 2.6792e-01, time/batch = 0.6983s	
1339/28500 (epoch 2.349), train_loss = 1.77794432, grad/param norm = 2.2190e-01, time/batch = 0.6992s	
1340/28500 (epoch 2.351), train_loss = 1.71035301, grad/param norm = 2.3988e-01, time/batch = 0.6997s	
1341/28500 (epoch 2.353), train_loss = 1.94525702, grad/param norm = 2.3268e-01, time/batch = 0.7056s	
1342/28500 (epoch 2.354), train_loss = 1.81244786, grad/param norm = 2.5002e-01, time/batch = 0.7009s	
1343/28500 (epoch 2.356), train_loss = 1.78549198, grad/param norm = 2.3359e-01, time/batch = 0.7028s	
1344/28500 (epoch 2.358), train_loss = 1.91995589, grad/param norm = 2.3255e-01, time/batch = 0.7003s	
1345/28500 (epoch 2.360), train_loss = 1.87923106, grad/param norm = 2.4740e-01, time/batch = 0.6971s	
1346/28500 (epoch 2.361), train_loss = 1.88991917, grad/param norm = 2.5566e-01, time/batch = 0.6971s	
1347/28500 (epoch 2.363), train_loss = 1.77111617, grad/param norm = 2.2808e-01, time/batch = 0.6956s	
1348/28500 (epoch 2.365), train_loss = 1.80158949, grad/param norm = 2.3926e-01, time/batch = 0.7035s	
1349/28500 (epoch 2.367), train_loss = 1.89298457, grad/param norm = 3.1163e-01, time/batch = 0.7020s	
1350/28500 (epoch 2.368), train_loss = 1.85145768, grad/param norm = 2.6209e-01, time/batch = 0.6999s	
1351/28500 (epoch 2.370), train_loss = 1.87402287, grad/param norm = 2.4230e-01, time/batch = 0.7051s	
1352/28500 (epoch 2.372), train_loss = 1.82646174, grad/param norm = 2.4975e-01, time/batch = 0.6981s	
1353/28500 (epoch 2.374), train_loss = 1.96607085, grad/param norm = 2.6560e-01, time/batch = 0.6930s	
1354/28500 (epoch 2.375), train_loss = 1.97371265, grad/param norm = 2.7621e-01, time/batch = 0.6940s	
1355/28500 (epoch 2.377), train_loss = 1.86496220, grad/param norm = 2.8432e-01, time/batch = 0.6961s	
1356/28500 (epoch 2.379), train_loss = 1.70314632, grad/param norm = 2.9104e-01, time/batch = 0.6989s	
1357/28500 (epoch 2.381), train_loss = 1.79554646, grad/param norm = 2.4424e-01, time/batch = 0.7034s	
1358/28500 (epoch 2.382), train_loss = 1.85529166, grad/param norm = 2.2881e-01, time/batch = 0.6948s	
1359/28500 (epoch 2.384), train_loss = 1.79629144, grad/param norm = 2.3641e-01, time/batch = 0.6945s	
1360/28500 (epoch 2.386), train_loss = 1.70800786, grad/param norm = 2.6096e-01, time/batch = 0.6929s	
1361/28500 (epoch 2.388), train_loss = 1.94614007, grad/param norm = 2.6059e-01, time/batch = 0.7024s	
1362/28500 (epoch 2.389), train_loss = 1.82975088, grad/param norm = 2.3947e-01, time/batch = 0.7089s	
1363/28500 (epoch 2.391), train_loss = 1.79351768, grad/param norm = 2.2723e-01, time/batch = 0.6998s	
1364/28500 (epoch 2.393), train_loss = 1.69910770, grad/param norm = 2.3414e-01, time/batch = 0.6950s	
1365/28500 (epoch 2.395), train_loss = 2.06133212, grad/param norm = 2.2560e-01, time/batch = 0.6974s	
1366/28500 (epoch 2.396), train_loss = 1.95842370, grad/param norm = 2.3902e-01, time/batch = 0.7014s	
1367/28500 (epoch 2.398), train_loss = 1.78518367, grad/param norm = 2.7505e-01, time/batch = 0.7018s	
1368/28500 (epoch 2.400), train_loss = 1.95120948, grad/param norm = 2.3149e-01, time/batch = 0.7082s	
1369/28500 (epoch 2.402), train_loss = 1.84417615, grad/param norm = 2.5868e-01, time/batch = 0.7046s	
1370/28500 (epoch 2.404), train_loss = 1.98120484, grad/param norm = 2.4277e-01, time/batch = 0.7143s	
1371/28500 (epoch 2.405), train_loss = 1.92255373, grad/param norm = 2.2919e-01, time/batch = 0.7037s	
1372/28500 (epoch 2.407), train_loss = 1.91940114, grad/param norm = 2.2379e-01, time/batch = 0.7035s	
1373/28500 (epoch 2.409), train_loss = 1.91314357, grad/param norm = 2.6314e-01, time/batch = 0.6968s	
1374/28500 (epoch 2.411), train_loss = 1.91534642, grad/param norm = 2.5399e-01, time/batch = 0.6986s	
1375/28500 (epoch 2.412), train_loss = 2.01958250, grad/param norm = 2.6081e-01, time/batch = 0.7019s	
1376/28500 (epoch 2.414), train_loss = 1.90184676, grad/param norm = 2.2855e-01, time/batch = 0.7049s	
1377/28500 (epoch 2.416), train_loss = 1.78212305, grad/param norm = 2.6950e-01, time/batch = 0.7002s	
1378/28500 (epoch 2.418), train_loss = 1.93429466, grad/param norm = 2.6664e-01, time/batch = 0.6966s	
1379/28500 (epoch 2.419), train_loss = 1.97742440, grad/param norm = 2.5768e-01, time/batch = 0.6969s	
1380/28500 (epoch 2.421), train_loss = 1.94315560, grad/param norm = 2.8105e-01, time/batch = 0.6958s	
1381/28500 (epoch 2.423), train_loss = 2.06583896, grad/param norm = 2.8337e-01, time/batch = 0.7005s	
1382/28500 (epoch 2.425), train_loss = 1.97503203, grad/param norm = 2.8606e-01, time/batch = 0.7005s	
1383/28500 (epoch 2.426), train_loss = 1.94533700, grad/param norm = 2.8043e-01, time/batch = 0.6984s	
1384/28500 (epoch 2.428), train_loss = 2.06795825, grad/param norm = 2.5652e-01, time/batch = 0.7040s	
1385/28500 (epoch 2.430), train_loss = 1.88665518, grad/param norm = 2.4177e-01, time/batch = 0.6974s	
1386/28500 (epoch 2.432), train_loss = 1.99763476, grad/param norm = 3.2233e-01, time/batch = 0.6982s	
1387/28500 (epoch 2.433), train_loss = 1.85602440, grad/param norm = 2.5820e-01, time/batch = 0.6987s	
1388/28500 (epoch 2.435), train_loss = 1.79978640, grad/param norm = 2.3740e-01, time/batch = 0.6985s	
1389/28500 (epoch 2.437), train_loss = 1.70084235, grad/param norm = 2.3195e-01, time/batch = 0.6972s	
1390/28500 (epoch 2.439), train_loss = 1.77995222, grad/param norm = 2.4924e-01, time/batch = 0.6959s	
1391/28500 (epoch 2.440), train_loss = 1.88290869, grad/param norm = 2.3269e-01, time/batch = 0.7008s	
1392/28500 (epoch 2.442), train_loss = 1.79870315, grad/param norm = 2.4910e-01, time/batch = 0.6976s	
1393/28500 (epoch 2.444), train_loss = 1.76053529, grad/param norm = 2.4470e-01, time/batch = 0.6968s	
1394/28500 (epoch 2.446), train_loss = 1.67758977, grad/param norm = 2.8706e-01, time/batch = 0.6997s	
1395/28500 (epoch 2.447), train_loss = 1.76634025, grad/param norm = 2.6339e-01, time/batch = 0.6970s	
1396/28500 (epoch 2.449), train_loss = 1.84202194, grad/param norm = 3.0107e-01, time/batch = 0.6972s	
1397/28500 (epoch 2.451), train_loss = 1.90108280, grad/param norm = 2.9246e-01, time/batch = 0.6987s	
1398/28500 (epoch 2.453), train_loss = 1.88743262, grad/param norm = 2.5816e-01, time/batch = 0.6993s	
1399/28500 (epoch 2.454), train_loss = 1.74624455, grad/param norm = 2.7165e-01, time/batch = 0.6969s	
1400/28500 (epoch 2.456), train_loss = 1.99117632, grad/param norm = 2.9467e-01, time/batch = 0.6981s	
1401/28500 (epoch 2.458), train_loss = 1.80710042, grad/param norm = 2.6691e-01, time/batch = 0.6999s	
1402/28500 (epoch 2.460), train_loss = 1.95790735, grad/param norm = 2.3601e-01, time/batch = 0.6995s	
1403/28500 (epoch 2.461), train_loss = 1.85762438, grad/param norm = 2.5009e-01, time/batch = 0.6993s	
1404/28500 (epoch 2.463), train_loss = 1.75006093, grad/param norm = 2.5927e-01, time/batch = 0.6973s	
1405/28500 (epoch 2.465), train_loss = 1.67400540, grad/param norm = 2.7778e-01, time/batch = 0.6974s	
1406/28500 (epoch 2.467), train_loss = 1.97480886, grad/param norm = 2.6177e-01, time/batch = 0.6970s	
1407/28500 (epoch 2.468), train_loss = 1.67778815, grad/param norm = 2.1967e-01, time/batch = 0.6976s	
1408/28500 (epoch 2.470), train_loss = 1.93164612, grad/param norm = 2.5884e-01, time/batch = 0.6975s	
1409/28500 (epoch 2.472), train_loss = 1.80991089, grad/param norm = 2.2521e-01, time/batch = 0.6980s	
1410/28500 (epoch 2.474), train_loss = 2.02857803, grad/param norm = 2.4755e-01, time/batch = 0.6971s	
1411/28500 (epoch 2.475), train_loss = 1.83773383, grad/param norm = 2.6363e-01, time/batch = 0.7002s	
1412/28500 (epoch 2.477), train_loss = 1.81054631, grad/param norm = 2.7231e-01, time/batch = 0.6992s	
1413/28500 (epoch 2.479), train_loss = 1.88509218, grad/param norm = 2.3257e-01, time/batch = 0.6974s	
1414/28500 (epoch 2.481), train_loss = 1.89002565, grad/param norm = 2.5310e-01, time/batch = 0.6996s	
1415/28500 (epoch 2.482), train_loss = 1.83701993, grad/param norm = 2.8902e-01, time/batch = 0.7027s	
1416/28500 (epoch 2.484), train_loss = 1.75620625, grad/param norm = 2.6823e-01, time/batch = 0.6959s	
1417/28500 (epoch 2.486), train_loss = 1.80413698, grad/param norm = 2.5283e-01, time/batch = 0.6974s	
1418/28500 (epoch 2.488), train_loss = 1.75959149, grad/param norm = 3.1237e-01, time/batch = 0.6970s	
1419/28500 (epoch 2.489), train_loss = 1.93260542, grad/param norm = 3.1507e-01, time/batch = 0.6967s	
1420/28500 (epoch 2.491), train_loss = 1.78429392, grad/param norm = 2.6203e-01, time/batch = 0.7148s	
1421/28500 (epoch 2.493), train_loss = 1.74415385, grad/param norm = 2.2712e-01, time/batch = 0.6959s	
1422/28500 (epoch 2.495), train_loss = 1.80491683, grad/param norm = 2.2690e-01, time/batch = 0.6968s	
1423/28500 (epoch 2.496), train_loss = 1.94965330, grad/param norm = 2.4368e-01, time/batch = 0.6961s	
1424/28500 (epoch 2.498), train_loss = 1.85524095, grad/param norm = 2.4946e-01, time/batch = 0.6946s	
1425/28500 (epoch 2.500), train_loss = 1.89000196, grad/param norm = 2.5674e-01, time/batch = 0.6941s	
1426/28500 (epoch 2.502), train_loss = 1.90050684, grad/param norm = 2.3015e-01, time/batch = 0.6964s	
1427/28500 (epoch 2.504), train_loss = 1.86029336, grad/param norm = 2.2345e-01, time/batch = 0.7060s	
1428/28500 (epoch 2.505), train_loss = 1.80089874, grad/param norm = 2.1517e-01, time/batch = 0.6969s	
1429/28500 (epoch 2.507), train_loss = 2.06520603, grad/param norm = 2.4390e-01, time/batch = 0.6971s	
1430/28500 (epoch 2.509), train_loss = 1.79179943, grad/param norm = 2.5474e-01, time/batch = 0.6930s	
1431/28500 (epoch 2.511), train_loss = 1.95268308, grad/param norm = 2.5251e-01, time/batch = 0.6953s	
1432/28500 (epoch 2.512), train_loss = 1.79695571, grad/param norm = 2.2685e-01, time/batch = 0.6990s	
1433/28500 (epoch 2.514), train_loss = 1.73703381, grad/param norm = 2.4339e-01, time/batch = 0.6972s	
1434/28500 (epoch 2.516), train_loss = 1.76564842, grad/param norm = 2.2590e-01, time/batch = 0.6939s	
1435/28500 (epoch 2.518), train_loss = 1.77660760, grad/param norm = 2.0966e-01, time/batch = 0.6950s	
1436/28500 (epoch 2.519), train_loss = 1.98138769, grad/param norm = 2.5529e-01, time/batch = 0.6984s	
1437/28500 (epoch 2.521), train_loss = 2.00839440, grad/param norm = 2.5884e-01, time/batch = 0.6935s	
1438/28500 (epoch 2.523), train_loss = 1.89326452, grad/param norm = 2.7601e-01, time/batch = 0.6934s	
1439/28500 (epoch 2.525), train_loss = 1.96056913, grad/param norm = 2.6475e-01, time/batch = 0.6928s	
1440/28500 (epoch 2.526), train_loss = 1.82037671, grad/param norm = 2.5511e-01, time/batch = 0.6982s	
1441/28500 (epoch 2.528), train_loss = 1.94734901, grad/param norm = 2.6317e-01, time/batch = 0.7017s	
1442/28500 (epoch 2.530), train_loss = 1.91424205, grad/param norm = 2.4072e-01, time/batch = 0.7163s	
1443/28500 (epoch 2.532), train_loss = 1.79130114, grad/param norm = 2.5898e-01, time/batch = 0.7014s	
1444/28500 (epoch 2.533), train_loss = 1.97577624, grad/param norm = 2.6275e-01, time/batch = 0.6932s	
1445/28500 (epoch 2.535), train_loss = 1.70059826, grad/param norm = 2.5264e-01, time/batch = 0.6927s	
1446/28500 (epoch 2.537), train_loss = 1.60777248, grad/param norm = 2.3287e-01, time/batch = 0.6989s	
1447/28500 (epoch 2.539), train_loss = 1.76466987, grad/param norm = 2.3250e-01, time/batch = 0.7039s	
1448/28500 (epoch 2.540), train_loss = 1.86338953, grad/param norm = 2.5700e-01, time/batch = 0.6984s	
1449/28500 (epoch 2.542), train_loss = 2.14825299, grad/param norm = 3.2153e-01, time/batch = 0.6960s	
1450/28500 (epoch 2.544), train_loss = 1.95460864, grad/param norm = 2.9554e-01, time/batch = 0.6931s	
1451/28500 (epoch 2.546), train_loss = 1.94298893, grad/param norm = 2.6468e-01, time/batch = 0.6991s	
1452/28500 (epoch 2.547), train_loss = 1.87342373, grad/param norm = 2.3571e-01, time/batch = 0.7012s	
1453/28500 (epoch 2.549), train_loss = 1.71629174, grad/param norm = 2.2947e-01, time/batch = 0.7125s	
1454/28500 (epoch 2.551), train_loss = 2.06879132, grad/param norm = 2.6201e-01, time/batch = 0.6820s	
1455/28500 (epoch 2.553), train_loss = 2.07770533, grad/param norm = 2.4300e-01, time/batch = 0.6840s	
1456/28500 (epoch 2.554), train_loss = 1.84684659, grad/param norm = 2.3182e-01, time/batch = 0.6809s	
1457/28500 (epoch 2.556), train_loss = 1.89944286, grad/param norm = 2.6808e-01, time/batch = 0.6775s	
1458/28500 (epoch 2.558), train_loss = 1.89638962, grad/param norm = 2.4194e-01, time/batch = 0.6891s	
1459/28500 (epoch 2.560), train_loss = 1.90129670, grad/param norm = 2.4889e-01, time/batch = 0.6768s	
1460/28500 (epoch 2.561), train_loss = 1.95159957, grad/param norm = 2.6431e-01, time/batch = 0.6755s	
1461/28500 (epoch 2.563), train_loss = 1.92585432, grad/param norm = 2.4439e-01, time/batch = 0.6825s	
1462/28500 (epoch 2.565), train_loss = 1.82158131, grad/param norm = 2.5950e-01, time/batch = 0.6766s	
1463/28500 (epoch 2.567), train_loss = 1.76263483, grad/param norm = 2.4071e-01, time/batch = 0.6765s	
1464/28500 (epoch 2.568), train_loss = 1.92191377, grad/param norm = 2.4881e-01, time/batch = 0.6769s	
1465/28500 (epoch 2.570), train_loss = 1.77194209, grad/param norm = 3.0135e-01, time/batch = 0.6768s	
1466/28500 (epoch 2.572), train_loss = 1.86455694, grad/param norm = 2.8511e-01, time/batch = 0.6759s	
1467/28500 (epoch 2.574), train_loss = 1.92559595, grad/param norm = 2.4203e-01, time/batch = 0.6764s	
1468/28500 (epoch 2.575), train_loss = 1.76024184, grad/param norm = 2.3750e-01, time/batch = 0.6762s	
1469/28500 (epoch 2.577), train_loss = 1.75198189, grad/param norm = 2.3600e-01, time/batch = 0.6756s	
1470/28500 (epoch 2.579), train_loss = 2.05896809, grad/param norm = 2.6786e-01, time/batch = 0.6757s	
1471/28500 (epoch 2.581), train_loss = 1.77289302, grad/param norm = 2.5623e-01, time/batch = 0.6780s	
1472/28500 (epoch 2.582), train_loss = 1.89786043, grad/param norm = 2.7157e-01, time/batch = 0.6761s	
1473/28500 (epoch 2.584), train_loss = 1.78323730, grad/param norm = 2.3872e-01, time/batch = 0.6779s	
1474/28500 (epoch 2.586), train_loss = 1.62013453, grad/param norm = 2.1747e-01, time/batch = 0.6758s	
1475/28500 (epoch 2.588), train_loss = 1.76007653, grad/param norm = 2.6406e-01, time/batch = 0.6770s	
1476/28500 (epoch 2.589), train_loss = 2.17676111, grad/param norm = 2.6245e-01, time/batch = 0.6758s	
1477/28500 (epoch 2.591), train_loss = 1.91636368, grad/param norm = 2.2273e-01, time/batch = 0.6774s	
1478/28500 (epoch 2.593), train_loss = 1.78674533, grad/param norm = 2.4821e-01, time/batch = 0.6788s	
1479/28500 (epoch 2.595), train_loss = 2.08564412, grad/param norm = 2.9169e-01, time/batch = 0.6815s	
1480/28500 (epoch 2.596), train_loss = 1.95688196, grad/param norm = 3.3265e-01, time/batch = 0.6775s	
1481/28500 (epoch 2.598), train_loss = 1.84049511, grad/param norm = 2.4789e-01, time/batch = 0.6786s	
1482/28500 (epoch 2.600), train_loss = 1.88169115, grad/param norm = 2.2308e-01, time/batch = 0.6792s	
1483/28500 (epoch 2.602), train_loss = 2.03072836, grad/param norm = 2.6933e-01, time/batch = 0.6853s	
1484/28500 (epoch 2.604), train_loss = 1.88319939, grad/param norm = 2.5297e-01, time/batch = 0.6771s	
1485/28500 (epoch 2.605), train_loss = 1.85384450, grad/param norm = 2.3271e-01, time/batch = 0.6764s	
1486/28500 (epoch 2.607), train_loss = 1.80523041, grad/param norm = 2.1911e-01, time/batch = 0.6761s	
1487/28500 (epoch 2.609), train_loss = 1.82563417, grad/param norm = 2.4837e-01, time/batch = 0.6794s	
1488/28500 (epoch 2.611), train_loss = 1.82977926, grad/param norm = 2.2974e-01, time/batch = 0.6792s	
1489/28500 (epoch 2.612), train_loss = 1.87371287, grad/param norm = 2.3919e-01, time/batch = 0.6756s	
1490/28500 (epoch 2.614), train_loss = 1.79781235, grad/param norm = 2.4564e-01, time/batch = 0.6756s	
1491/28500 (epoch 2.616), train_loss = 1.79930701, grad/param norm = 2.5628e-01, time/batch = 0.6775s	
1492/28500 (epoch 2.618), train_loss = 1.66265597, grad/param norm = 2.3435e-01, time/batch = 0.6764s	
1493/28500 (epoch 2.619), train_loss = 1.94403380, grad/param norm = 2.5357e-01, time/batch = 0.6791s	
1494/28500 (epoch 2.621), train_loss = 1.58467883, grad/param norm = 2.1578e-01, time/batch = 0.6792s	
1495/28500 (epoch 2.623), train_loss = 1.84916824, grad/param norm = 2.3283e-01, time/batch = 0.6784s	
1496/28500 (epoch 2.625), train_loss = 1.76180656, grad/param norm = 2.5524e-01, time/batch = 0.6762s	
1497/28500 (epoch 2.626), train_loss = 1.60490914, grad/param norm = 2.3820e-01, time/batch = 0.6790s	
1498/28500 (epoch 2.628), train_loss = 1.69601429, grad/param norm = 2.4649e-01, time/batch = 0.6817s	
1499/28500 (epoch 2.630), train_loss = 1.72512256, grad/param norm = 2.6510e-01, time/batch = 0.6820s	
1500/28500 (epoch 2.632), train_loss = 1.91515727, grad/param norm = 2.9175e-01, time/batch = 0.6814s	
1501/28500 (epoch 2.633), train_loss = 1.81108686, grad/param norm = 2.1112e-01, time/batch = 0.6874s	
1502/28500 (epoch 2.635), train_loss = 1.94187274, grad/param norm = 2.5296e-01, time/batch = 0.6839s	
1503/28500 (epoch 2.637), train_loss = 1.80870432, grad/param norm = 2.5762e-01, time/batch = 0.6768s	
1504/28500 (epoch 2.639), train_loss = 1.57789930, grad/param norm = 2.4717e-01, time/batch = 0.6803s	
1505/28500 (epoch 2.640), train_loss = 1.81384657, grad/param norm = 2.3700e-01, time/batch = 0.6790s	
1506/28500 (epoch 2.642), train_loss = 1.89205318, grad/param norm = 2.2261e-01, time/batch = 0.6810s	
1507/28500 (epoch 2.644), train_loss = 1.85407124, grad/param norm = 2.1184e-01, time/batch = 0.6801s	
1508/28500 (epoch 2.646), train_loss = 1.77150162, grad/param norm = 2.2577e-01, time/batch = 0.6774s	
1509/28500 (epoch 2.647), train_loss = 1.74351076, grad/param norm = 2.5715e-01, time/batch = 0.6771s	
1510/28500 (epoch 2.649), train_loss = 1.75143228, grad/param norm = 2.1511e-01, time/batch = 0.6766s	
1511/28500 (epoch 2.651), train_loss = 1.75365192, grad/param norm = 2.4175e-01, time/batch = 0.6779s	
1512/28500 (epoch 2.653), train_loss = 1.71407795, grad/param norm = 2.3492e-01, time/batch = 0.6782s	
1513/28500 (epoch 2.654), train_loss = 1.73488793, grad/param norm = 2.5033e-01, time/batch = 0.6859s	
1514/28500 (epoch 2.656), train_loss = 1.84920370, grad/param norm = 2.2851e-01, time/batch = 0.6766s	
1515/28500 (epoch 2.658), train_loss = 1.85973281, grad/param norm = 2.3816e-01, time/batch = 0.6759s	
1516/28500 (epoch 2.660), train_loss = 1.76831121, grad/param norm = 1.9766e-01, time/batch = 0.6759s	
1517/28500 (epoch 2.661), train_loss = 1.93895338, grad/param norm = 2.1894e-01, time/batch = 0.6759s	
1518/28500 (epoch 2.663), train_loss = 1.95079835, grad/param norm = 2.4312e-01, time/batch = 0.6757s	
1519/28500 (epoch 2.665), train_loss = 1.80122451, grad/param norm = 2.4344e-01, time/batch = 0.6767s	
1520/28500 (epoch 2.667), train_loss = 1.80538687, grad/param norm = 2.4941e-01, time/batch = 0.6759s	
1521/28500 (epoch 2.668), train_loss = 1.79161558, grad/param norm = 2.5540e-01, time/batch = 0.6817s	
1522/28500 (epoch 2.670), train_loss = 1.76095425, grad/param norm = 2.5776e-01, time/batch = 0.6765s	
1523/28500 (epoch 2.672), train_loss = 1.78638238, grad/param norm = 2.4212e-01, time/batch = 0.6761s	
1524/28500 (epoch 2.674), train_loss = 1.68383957, grad/param norm = 2.6121e-01, time/batch = 0.6757s	
1525/28500 (epoch 2.675), train_loss = 1.65514834, grad/param norm = 2.4562e-01, time/batch = 0.6752s	
1526/28500 (epoch 2.677), train_loss = 1.71210221, grad/param norm = 2.4586e-01, time/batch = 0.6757s	
1527/28500 (epoch 2.679), train_loss = 1.84180121, grad/param norm = 2.1794e-01, time/batch = 0.6756s	
1528/28500 (epoch 2.681), train_loss = 1.91808371, grad/param norm = 2.6319e-01, time/batch = 0.6791s	
1529/28500 (epoch 2.682), train_loss = 1.66845371, grad/param norm = 2.1592e-01, time/batch = 0.6831s	
1530/28500 (epoch 2.684), train_loss = 1.83441378, grad/param norm = 2.2764e-01, time/batch = 0.6908s	
1531/28500 (epoch 2.686), train_loss = 1.73131235, grad/param norm = 2.4118e-01, time/batch = 0.6840s	
1532/28500 (epoch 2.688), train_loss = 1.77923135, grad/param norm = 2.4262e-01, time/batch = 0.6849s	
1533/28500 (epoch 2.689), train_loss = 1.92938395, grad/param norm = 2.9583e-01, time/batch = 0.6821s	
1534/28500 (epoch 2.691), train_loss = 1.80872581, grad/param norm = 2.6360e-01, time/batch = 0.6802s	
1535/28500 (epoch 2.693), train_loss = 1.83028498, grad/param norm = 2.4256e-01, time/batch = 0.6804s	
1536/28500 (epoch 2.695), train_loss = 1.83298722, grad/param norm = 2.6022e-01, time/batch = 0.6800s	
1537/28500 (epoch 2.696), train_loss = 1.90211263, grad/param norm = 3.1189e-01, time/batch = 0.6848s	
1538/28500 (epoch 2.698), train_loss = 1.74070963, grad/param norm = 2.2852e-01, time/batch = 0.6816s	
1539/28500 (epoch 2.700), train_loss = 1.76024254, grad/param norm = 2.4580e-01, time/batch = 0.6822s	
1540/28500 (epoch 2.702), train_loss = 1.92596364, grad/param norm = 2.3817e-01, time/batch = 0.6793s	
1541/28500 (epoch 2.704), train_loss = 1.79446438, grad/param norm = 2.4478e-01, time/batch = 0.6826s	
1542/28500 (epoch 2.705), train_loss = 1.83295850, grad/param norm = 2.5894e-01, time/batch = 0.6805s	
1543/28500 (epoch 2.707), train_loss = 1.81133585, grad/param norm = 2.8703e-01, time/batch = 0.6808s	
1544/28500 (epoch 2.709), train_loss = 1.89933058, grad/param norm = 2.7168e-01, time/batch = 0.6855s	
1545/28500 (epoch 2.711), train_loss = 1.68727132, grad/param norm = 2.4815e-01, time/batch = 0.6894s	
1546/28500 (epoch 2.712), train_loss = 1.84006483, grad/param norm = 2.5140e-01, time/batch = 0.6827s	
1547/28500 (epoch 2.714), train_loss = 1.84874491, grad/param norm = 2.4405e-01, time/batch = 0.6802s	
1548/28500 (epoch 2.716), train_loss = 1.86612884, grad/param norm = 2.3080e-01, time/batch = 0.6803s	
1549/28500 (epoch 2.718), train_loss = 1.67821890, grad/param norm = 2.3087e-01, time/batch = 0.6810s	
1550/28500 (epoch 2.719), train_loss = 1.69357646, grad/param norm = 2.3179e-01, time/batch = 0.6803s	
1551/28500 (epoch 2.721), train_loss = 1.56308669, grad/param norm = 2.3467e-01, time/batch = 0.6830s	
1552/28500 (epoch 2.723), train_loss = 1.80205668, grad/param norm = 2.2560e-01, time/batch = 0.6807s	
1553/28500 (epoch 2.725), train_loss = 1.88554924, grad/param norm = 2.4233e-01, time/batch = 0.6806s	
1554/28500 (epoch 2.726), train_loss = 1.79905403, grad/param norm = 2.4260e-01, time/batch = 0.6799s	
1555/28500 (epoch 2.728), train_loss = 1.66779630, grad/param norm = 2.1204e-01, time/batch = 0.6801s	
1556/28500 (epoch 2.730), train_loss = 1.87007730, grad/param norm = 2.4177e-01, time/batch = 0.6819s	
1557/28500 (epoch 2.732), train_loss = 1.60021399, grad/param norm = 2.5391e-01, time/batch = 0.6806s	
1558/28500 (epoch 2.733), train_loss = 1.71609200, grad/param norm = 2.6625e-01, time/batch = 0.6786s	
1559/28500 (epoch 2.735), train_loss = 1.65180599, grad/param norm = 2.4670e-01, time/batch = 0.6804s	
1560/28500 (epoch 2.737), train_loss = 1.64926521, grad/param norm = 2.1618e-01, time/batch = 0.6789s	
1561/28500 (epoch 2.739), train_loss = 1.83428197, grad/param norm = 2.3420e-01, time/batch = 0.6842s	
1562/28500 (epoch 2.740), train_loss = 1.73954363, grad/param norm = 2.3200e-01, time/batch = 0.6811s	
1563/28500 (epoch 2.742), train_loss = 1.78819334, grad/param norm = 2.3436e-01, time/batch = 0.6839s	
1564/28500 (epoch 2.744), train_loss = 1.86363726, grad/param norm = 2.3700e-01, time/batch = 0.6820s	
1565/28500 (epoch 2.746), train_loss = 1.69047641, grad/param norm = 2.2986e-01, time/batch = 0.6821s	
1566/28500 (epoch 2.747), train_loss = 1.67027785, grad/param norm = 2.4200e-01, time/batch = 0.6817s	
1567/28500 (epoch 2.749), train_loss = 2.06041284, grad/param norm = 2.6773e-01, time/batch = 0.6803s	
1568/28500 (epoch 2.751), train_loss = 1.70267130, grad/param norm = 2.2697e-01, time/batch = 0.6801s	
1569/28500 (epoch 2.753), train_loss = 1.60659838, grad/param norm = 2.0132e-01, time/batch = 0.6807s	
1570/28500 (epoch 2.754), train_loss = 1.61221632, grad/param norm = 2.1569e-01, time/batch = 0.6800s	
1571/28500 (epoch 2.756), train_loss = 1.86159871, grad/param norm = 2.3096e-01, time/batch = 0.6837s	
1572/28500 (epoch 2.758), train_loss = 1.74111633, grad/param norm = 2.1583e-01, time/batch = 0.6824s	
1573/28500 (epoch 2.760), train_loss = 1.69978133, grad/param norm = 2.7535e-01, time/batch = 0.6807s	
1574/28500 (epoch 2.761), train_loss = 1.81170327, grad/param norm = 2.3729e-01, time/batch = 0.6790s	
1575/28500 (epoch 2.763), train_loss = 1.56447735, grad/param norm = 2.3582e-01, time/batch = 0.6798s	
1576/28500 (epoch 2.765), train_loss = 1.67391213, grad/param norm = 2.2202e-01, time/batch = 0.6788s	
1577/28500 (epoch 2.767), train_loss = 1.53822434, grad/param norm = 2.3389e-01, time/batch = 0.6801s	
1578/28500 (epoch 2.768), train_loss = 1.94118990, grad/param norm = 2.7259e-01, time/batch = 0.6895s	
1579/28500 (epoch 2.770), train_loss = 1.66049973, grad/param norm = 2.3878e-01, time/batch = 0.6849s	
1580/28500 (epoch 2.772), train_loss = 1.61891186, grad/param norm = 2.6369e-01, time/batch = 0.6811s	
1581/28500 (epoch 2.774), train_loss = 1.74872521, grad/param norm = 2.4290e-01, time/batch = 0.6835s	
1582/28500 (epoch 2.775), train_loss = 1.86515734, grad/param norm = 2.1763e-01, time/batch = 0.6807s	
1583/28500 (epoch 2.777), train_loss = 1.75563787, grad/param norm = 2.1620e-01, time/batch = 0.6820s	
1584/28500 (epoch 2.779), train_loss = 1.72145416, grad/param norm = 2.4136e-01, time/batch = 0.6935s	
1585/28500 (epoch 2.781), train_loss = 1.83201363, grad/param norm = 2.6509e-01, time/batch = 0.6803s	
1586/28500 (epoch 2.782), train_loss = 1.94394951, grad/param norm = 2.6053e-01, time/batch = 0.6790s	
1587/28500 (epoch 2.784), train_loss = 1.60449326, grad/param norm = 2.0848e-01, time/batch = 0.6806s	
1588/28500 (epoch 2.786), train_loss = 1.79539791, grad/param norm = 2.3326e-01, time/batch = 0.6789s	
1589/28500 (epoch 2.788), train_loss = 1.87564272, grad/param norm = 2.2264e-01, time/batch = 0.6799s	
1590/28500 (epoch 2.789), train_loss = 1.63371534, grad/param norm = 2.5595e-01, time/batch = 0.6832s	
1591/28500 (epoch 2.791), train_loss = 1.74217766, grad/param norm = 2.3752e-01, time/batch = 0.6810s	
1592/28500 (epoch 2.793), train_loss = 1.66890829, grad/param norm = 2.5508e-01, time/batch = 0.6807s	
1593/28500 (epoch 2.795), train_loss = 1.77951025, grad/param norm = 2.4999e-01, time/batch = 0.6790s	
1594/28500 (epoch 2.796), train_loss = 1.66123836, grad/param norm = 2.1654e-01, time/batch = 0.6803s	
1595/28500 (epoch 2.798), train_loss = 1.68968478, grad/param norm = 2.4461e-01, time/batch = 0.6802s	
1596/28500 (epoch 2.800), train_loss = 1.71404684, grad/param norm = 2.3932e-01, time/batch = 0.6811s	
1597/28500 (epoch 2.802), train_loss = 1.82415065, grad/param norm = 2.7024e-01, time/batch = 0.6792s	
1598/28500 (epoch 2.804), train_loss = 1.75898676, grad/param norm = 2.2437e-01, time/batch = 0.6801s	
1599/28500 (epoch 2.805), train_loss = 1.81258740, grad/param norm = 2.4078e-01, time/batch = 0.6804s	
1600/28500 (epoch 2.807), train_loss = 1.93448435, grad/param norm = 2.3051e-01, time/batch = 0.6792s	
1601/28500 (epoch 2.809), train_loss = 1.71328789, grad/param norm = 2.3530e-01, time/batch = 0.6812s	
1602/28500 (epoch 2.811), train_loss = 1.93393108, grad/param norm = 2.5040e-01, time/batch = 0.6807s	
1603/28500 (epoch 2.812), train_loss = 1.82737262, grad/param norm = 2.3013e-01, time/batch = 0.6788s	
1604/28500 (epoch 2.814), train_loss = 1.73601665, grad/param norm = 2.4361e-01, time/batch = 0.6804s	
1605/28500 (epoch 2.816), train_loss = 1.85273802, grad/param norm = 2.3482e-01, time/batch = 0.6804s	
1606/28500 (epoch 2.818), train_loss = 1.73452119, grad/param norm = 2.3738e-01, time/batch = 0.6795s	
1607/28500 (epoch 2.819), train_loss = 1.74811000, grad/param norm = 2.5796e-01, time/batch = 0.6789s	
1608/28500 (epoch 2.821), train_loss = 1.73677885, grad/param norm = 2.5413e-01, time/batch = 0.6788s	
1609/28500 (epoch 2.823), train_loss = 2.03963204, grad/param norm = 2.8363e-01, time/batch = 0.6791s	
1610/28500 (epoch 2.825), train_loss = 1.73183199, grad/param norm = 2.4492e-01, time/batch = 0.6800s	
1611/28500 (epoch 2.826), train_loss = 1.81838859, grad/param norm = 2.6333e-01, time/batch = 0.6824s	
1612/28500 (epoch 2.828), train_loss = 1.62667973, grad/param norm = 2.3310e-01, time/batch = 0.6809s	
1613/28500 (epoch 2.830), train_loss = 1.68568949, grad/param norm = 2.2166e-01, time/batch = 0.6782s	
1614/28500 (epoch 2.832), train_loss = 1.84296236, grad/param norm = 2.5716e-01, time/batch = 0.6792s	
1615/28500 (epoch 2.833), train_loss = 1.90207892, grad/param norm = 2.4373e-01, time/batch = 0.6829s	
1616/28500 (epoch 2.835), train_loss = 1.74879141, grad/param norm = 2.5446e-01, time/batch = 0.6851s	
1617/28500 (epoch 2.837), train_loss = 1.67627456, grad/param norm = 2.2836e-01, time/batch = 0.7082s	
1618/28500 (epoch 2.839), train_loss = 1.92061497, grad/param norm = 2.5041e-01, time/batch = 0.6862s	
1619/28500 (epoch 2.840), train_loss = 1.88071123, grad/param norm = 2.3524e-01, time/batch = 0.6847s	
1620/28500 (epoch 2.842), train_loss = 1.76079812, grad/param norm = 2.3084e-01, time/batch = 0.6949s	
1621/28500 (epoch 2.844), train_loss = 1.77040431, grad/param norm = 2.3314e-01, time/batch = 0.7163s	
1622/28500 (epoch 2.846), train_loss = 1.88301213, grad/param norm = 2.3753e-01, time/batch = 0.7184s	
1623/28500 (epoch 2.847), train_loss = 1.72635988, grad/param norm = 2.1386e-01, time/batch = 0.7027s	
1624/28500 (epoch 2.849), train_loss = 1.66420160, grad/param norm = 1.9960e-01, time/batch = 0.6938s	
1625/28500 (epoch 2.851), train_loss = 1.62326436, grad/param norm = 2.2522e-01, time/batch = 0.6934s	
1626/28500 (epoch 2.853), train_loss = 1.83597677, grad/param norm = 2.3242e-01, time/batch = 0.7043s	
1627/28500 (epoch 2.854), train_loss = 1.70927457, grad/param norm = 2.1876e-01, time/batch = 0.7085s	
1628/28500 (epoch 2.856), train_loss = 1.83089409, grad/param norm = 2.5364e-01, time/batch = 0.7015s	
1629/28500 (epoch 2.858), train_loss = 1.63059374, grad/param norm = 2.3026e-01, time/batch = 0.6952s	
1630/28500 (epoch 2.860), train_loss = 1.85453350, grad/param norm = 2.5918e-01, time/batch = 0.6946s	
1631/28500 (epoch 2.861), train_loss = 1.70796912, grad/param norm = 2.2003e-01, time/batch = 0.6999s	
1632/28500 (epoch 2.863), train_loss = 1.90315499, grad/param norm = 2.3761e-01, time/batch = 0.6959s	
1633/28500 (epoch 2.865), train_loss = 1.77487096, grad/param norm = 2.4466e-01, time/batch = 0.6948s	
1634/28500 (epoch 2.867), train_loss = 1.86411737, grad/param norm = 2.3916e-01, time/batch = 0.6978s	
1635/28500 (epoch 2.868), train_loss = 1.60688346, grad/param norm = 2.7057e-01, time/batch = 0.6962s	
1636/28500 (epoch 2.870), train_loss = 1.54167575, grad/param norm = 2.2622e-01, time/batch = 0.7017s	
1637/28500 (epoch 2.872), train_loss = 1.89413608, grad/param norm = 2.7115e-01, time/batch = 0.6983s	
1638/28500 (epoch 2.874), train_loss = 1.76167090, grad/param norm = 2.6340e-01, time/batch = 0.6981s	
1639/28500 (epoch 2.875), train_loss = 1.83458357, grad/param norm = 2.5301e-01, time/batch = 0.7035s	
1640/28500 (epoch 2.877), train_loss = 1.77111894, grad/param norm = 2.3305e-01, time/batch = 0.7054s	
1641/28500 (epoch 2.879), train_loss = 1.75015272, grad/param norm = 2.1649e-01, time/batch = 0.7021s	
1642/28500 (epoch 2.881), train_loss = 1.82609939, grad/param norm = 2.3923e-01, time/batch = 0.6975s	
1643/28500 (epoch 2.882), train_loss = 1.72505404, grad/param norm = 2.4289e-01, time/batch = 0.6992s	
1644/28500 (epoch 2.884), train_loss = 1.81687447, grad/param norm = 2.5065e-01, time/batch = 0.6984s	
1645/28500 (epoch 2.886), train_loss = 1.63050648, grad/param norm = 2.6620e-01, time/batch = 0.6981s	
1646/28500 (epoch 2.888), train_loss = 1.58162673, grad/param norm = 2.2416e-01, time/batch = 0.6976s	
1647/28500 (epoch 2.889), train_loss = 1.61762189, grad/param norm = 2.0431e-01, time/batch = 0.6975s	
1648/28500 (epoch 2.891), train_loss = 1.76005507, grad/param norm = 2.1405e-01, time/batch = 0.6995s	
1649/28500 (epoch 2.893), train_loss = 1.75073950, grad/param norm = 2.2412e-01, time/batch = 0.6978s	
1650/28500 (epoch 2.895), train_loss = 1.94171530, grad/param norm = 2.5577e-01, time/batch = 0.6999s	
1651/28500 (epoch 2.896), train_loss = 1.90474701, grad/param norm = 2.5265e-01, time/batch = 0.7043s	
1652/28500 (epoch 2.898), train_loss = 1.64250657, grad/param norm = 2.0497e-01, time/batch = 0.6983s	
1653/28500 (epoch 2.900), train_loss = 1.61913687, grad/param norm = 2.3602e-01, time/batch = 0.6982s	
1654/28500 (epoch 2.902), train_loss = 1.65952491, grad/param norm = 2.2589e-01, time/batch = 0.6995s	
1655/28500 (epoch 2.904), train_loss = 1.65659948, grad/param norm = 2.1632e-01, time/batch = 0.6985s	
1656/28500 (epoch 2.905), train_loss = 1.81059666, grad/param norm = 2.0936e-01, time/batch = 0.6968s	
1657/28500 (epoch 2.907), train_loss = 1.96376417, grad/param norm = 2.6586e-01, time/batch = 0.6966s	
1658/28500 (epoch 2.909), train_loss = 1.67058078, grad/param norm = 2.2092e-01, time/batch = 0.6999s	
1659/28500 (epoch 2.911), train_loss = 1.71936716, grad/param norm = 2.2277e-01, time/batch = 0.6980s	
1660/28500 (epoch 2.912), train_loss = 1.49094052, grad/param norm = 2.5241e-01, time/batch = 0.6979s	
1661/28500 (epoch 2.914), train_loss = 1.88542517, grad/param norm = 2.7500e-01, time/batch = 0.7007s	
1662/28500 (epoch 2.916), train_loss = 1.80413460, grad/param norm = 2.5585e-01, time/batch = 0.6999s	
1663/28500 (epoch 2.918), train_loss = 1.88804681, grad/param norm = 2.4448e-01, time/batch = 0.7052s	
1664/28500 (epoch 2.919), train_loss = 1.63973900, grad/param norm = 2.0412e-01, time/batch = 0.7050s	
1665/28500 (epoch 2.921), train_loss = 1.93049261, grad/param norm = 2.4343e-01, time/batch = 0.7063s	
1666/28500 (epoch 2.923), train_loss = 1.90478359, grad/param norm = 2.7260e-01, time/batch = 0.6970s	
1667/28500 (epoch 2.925), train_loss = 1.69225743, grad/param norm = 2.3811e-01, time/batch = 0.7039s	
1668/28500 (epoch 2.926), train_loss = 1.81242925, grad/param norm = 2.4954e-01, time/batch = 0.6929s	
1669/28500 (epoch 2.928), train_loss = 1.63556631, grad/param norm = 2.2476e-01, time/batch = 0.7018s	
1670/28500 (epoch 2.930), train_loss = 1.43885914, grad/param norm = 2.0246e-01, time/batch = 0.6956s	
1671/28500 (epoch 2.932), train_loss = 1.59553135, grad/param norm = 1.9307e-01, time/batch = 0.7010s	
1672/28500 (epoch 2.933), train_loss = 1.76616064, grad/param norm = 1.9989e-01, time/batch = 0.6952s	
1673/28500 (epoch 2.935), train_loss = 1.69396897, grad/param norm = 2.4404e-01, time/batch = 0.7084s	
1674/28500 (epoch 2.937), train_loss = 1.86210108, grad/param norm = 2.3231e-01, time/batch = 0.6935s	
1675/28500 (epoch 2.939), train_loss = 2.01261728, grad/param norm = 2.6826e-01, time/batch = 0.6859s	
1676/28500 (epoch 2.940), train_loss = 1.75008528, grad/param norm = 2.2216e-01, time/batch = 0.6824s	
1677/28500 (epoch 2.942), train_loss = 1.82688896, grad/param norm = 2.4653e-01, time/batch = 0.6851s	
1678/28500 (epoch 2.944), train_loss = 1.78950516, grad/param norm = 2.1548e-01, time/batch = 0.6779s	
1679/28500 (epoch 2.946), train_loss = 1.86206389, grad/param norm = 2.0538e-01, time/batch = 0.6769s	
1680/28500 (epoch 2.947), train_loss = 2.10718195, grad/param norm = 2.4806e-01, time/batch = 0.6812s	
1681/28500 (epoch 2.949), train_loss = 1.64079934, grad/param norm = 2.4349e-01, time/batch = 0.6837s	
1682/28500 (epoch 2.951), train_loss = 1.93111465, grad/param norm = 2.2363e-01, time/batch = 0.6884s	
1683/28500 (epoch 2.953), train_loss = 1.85653945, grad/param norm = 2.6329e-01, time/batch = 0.6799s	
1684/28500 (epoch 2.954), train_loss = 1.83179862, grad/param norm = 2.3724e-01, time/batch = 0.6770s	
1685/28500 (epoch 2.956), train_loss = 1.81687765, grad/param norm = 2.6068e-01, time/batch = 0.6774s	
1686/28500 (epoch 2.958), train_loss = 1.78965384, grad/param norm = 2.4965e-01, time/batch = 0.6793s	
1687/28500 (epoch 2.960), train_loss = 1.66228417, grad/param norm = 2.7962e-01, time/batch = 0.6765s	
1688/28500 (epoch 2.961), train_loss = 1.94929721, grad/param norm = 2.7237e-01, time/batch = 0.6816s	
1689/28500 (epoch 2.963), train_loss = 1.81093707, grad/param norm = 2.0715e-01, time/batch = 0.6796s	
1690/28500 (epoch 2.965), train_loss = 1.67197106, grad/param norm = 2.1161e-01, time/batch = 0.6802s	
1691/28500 (epoch 2.967), train_loss = 1.57491200, grad/param norm = 2.1123e-01, time/batch = 0.6791s	
1692/28500 (epoch 2.968), train_loss = 1.54744313, grad/param norm = 2.1025e-01, time/batch = 0.6800s	
1693/28500 (epoch 2.970), train_loss = 1.85915729, grad/param norm = 2.4127e-01, time/batch = 0.6806s	
1694/28500 (epoch 2.972), train_loss = 2.01633066, grad/param norm = 2.5964e-01, time/batch = 0.6840s	
1695/28500 (epoch 2.974), train_loss = 1.98838430, grad/param norm = 2.4485e-01, time/batch = 0.6809s	
1696/28500 (epoch 2.975), train_loss = 1.75028290, grad/param norm = 2.1242e-01, time/batch = 0.6805s	
1697/28500 (epoch 2.977), train_loss = 1.94609558, grad/param norm = 2.2447e-01, time/batch = 0.6786s	
1698/28500 (epoch 2.979), train_loss = 1.71395701, grad/param norm = 2.2257e-01, time/batch = 0.6775s	
1699/28500 (epoch 2.981), train_loss = 1.71081551, grad/param norm = 2.2241e-01, time/batch = 0.6769s	
1700/28500 (epoch 2.982), train_loss = 1.60247085, grad/param norm = 2.1848e-01, time/batch = 0.6771s	
1701/28500 (epoch 2.984), train_loss = 1.80782701, grad/param norm = 2.2622e-01, time/batch = 0.6832s	
1702/28500 (epoch 2.986), train_loss = 1.87465974, grad/param norm = 2.2445e-01, time/batch = 0.6870s	
1703/28500 (epoch 2.988), train_loss = 1.54802198, grad/param norm = 2.0705e-01, time/batch = 0.7000s	
1704/28500 (epoch 2.989), train_loss = 1.76138802, grad/param norm = 2.3966e-01, time/batch = 0.7047s	
1705/28500 (epoch 2.991), train_loss = 1.71131233, grad/param norm = 2.5685e-01, time/batch = 0.6982s	
1706/28500 (epoch 2.993), train_loss = 1.75535942, grad/param norm = 2.5041e-01, time/batch = 0.7048s	
1707/28500 (epoch 2.995), train_loss = 1.67431781, grad/param norm = 2.0909e-01, time/batch = 0.6865s	
1708/28500 (epoch 2.996), train_loss = 1.63045200, grad/param norm = 2.2785e-01, time/batch = 0.7018s	
1709/28500 (epoch 2.998), train_loss = 1.81732698, grad/param norm = 2.6379e-01, time/batch = 0.6929s	
1710/28500 (epoch 3.000), train_loss = 1.69834074, grad/param norm = 2.1381e-01, time/batch = 0.6871s	
1711/28500 (epoch 3.002), train_loss = 1.79085038, grad/param norm = 2.3075e-01, time/batch = 0.7012s	
1712/28500 (epoch 3.004), train_loss = 1.64918207, grad/param norm = 2.7511e-01, time/batch = 0.6979s	
1713/28500 (epoch 3.005), train_loss = 1.77095661, grad/param norm = 2.2297e-01, time/batch = 0.6952s	
1714/28500 (epoch 3.007), train_loss = 1.54813254, grad/param norm = 2.0775e-01, time/batch = 0.6933s	
1715/28500 (epoch 3.009), train_loss = 1.86310569, grad/param norm = 2.5334e-01, time/batch = 0.6777s	
1716/28500 (epoch 3.011), train_loss = 1.72770800, grad/param norm = 2.6344e-01, time/batch = 0.6772s	
1717/28500 (epoch 3.012), train_loss = 1.55820801, grad/param norm = 2.1008e-01, time/batch = 0.6797s	
1718/28500 (epoch 3.014), train_loss = 1.61371843, grad/param norm = 2.2983e-01, time/batch = 0.6822s	
1719/28500 (epoch 3.016), train_loss = 1.65987712, grad/param norm = 2.3953e-01, time/batch = 0.6802s	
1720/28500 (epoch 3.018), train_loss = 1.71189736, grad/param norm = 2.7439e-01, time/batch = 0.6777s	
1721/28500 (epoch 3.019), train_loss = 1.72281835, grad/param norm = 2.3138e-01, time/batch = 0.6818s	
1722/28500 (epoch 3.021), train_loss = 1.67411083, grad/param norm = 2.1713e-01, time/batch = 0.6815s	
1723/28500 (epoch 3.023), train_loss = 1.75664709, grad/param norm = 2.3190e-01, time/batch = 0.6810s	
1724/28500 (epoch 3.025), train_loss = 1.65271109, grad/param norm = 2.1665e-01, time/batch = 0.6789s	
1725/28500 (epoch 3.026), train_loss = 1.77164360, grad/param norm = 2.6845e-01, time/batch = 0.6908s	
1726/28500 (epoch 3.028), train_loss = 1.79677888, grad/param norm = 2.7488e-01, time/batch = 0.6828s	
1727/28500 (epoch 3.030), train_loss = 1.83944113, grad/param norm = 2.6060e-01, time/batch = 0.6807s	
1728/28500 (epoch 3.032), train_loss = 1.83394982, grad/param norm = 2.4943e-01, time/batch = 0.6799s	
1729/28500 (epoch 3.033), train_loss = 1.94344402, grad/param norm = 2.5475e-01, time/batch = 0.6776s	
1730/28500 (epoch 3.035), train_loss = 1.78022607, grad/param norm = 2.3991e-01, time/batch = 0.6777s	
1731/28500 (epoch 3.037), train_loss = 1.81891288, grad/param norm = 2.3894e-01, time/batch = 0.6803s	
1732/28500 (epoch 3.039), train_loss = 1.88273664, grad/param norm = 2.2650e-01, time/batch = 0.6801s	
1733/28500 (epoch 3.040), train_loss = 1.87581470, grad/param norm = 2.2521e-01, time/batch = 0.6805s	
1734/28500 (epoch 3.042), train_loss = 1.93830372, grad/param norm = 2.5221e-01, time/batch = 0.6805s	
1735/28500 (epoch 3.044), train_loss = 1.79496355, grad/param norm = 2.5184e-01, time/batch = 0.6791s	
1736/28500 (epoch 3.046), train_loss = 1.89097243, grad/param norm = 2.2169e-01, time/batch = 0.6772s	
1737/28500 (epoch 3.047), train_loss = 1.89686319, grad/param norm = 2.2961e-01, time/batch = 0.6778s	
1738/28500 (epoch 3.049), train_loss = 1.82344105, grad/param norm = 2.5594e-01, time/batch = 0.6769s	
1739/28500 (epoch 3.051), train_loss = 1.76584276, grad/param norm = 2.0680e-01, time/batch = 0.6793s	
1740/28500 (epoch 3.053), train_loss = 1.86928181, grad/param norm = 2.3706e-01, time/batch = 0.6901s	
1741/28500 (epoch 3.054), train_loss = 1.86615528, grad/param norm = 2.2929e-01, time/batch = 0.6787s	
1742/28500 (epoch 3.056), train_loss = 1.61982877, grad/param norm = 2.0358e-01, time/batch = 0.6777s	
1743/28500 (epoch 3.058), train_loss = 1.68303601, grad/param norm = 2.4317e-01, time/batch = 0.6775s	
1744/28500 (epoch 3.060), train_loss = 1.76376727, grad/param norm = 2.5955e-01, time/batch = 0.6773s	
1745/28500 (epoch 3.061), train_loss = 1.85973039, grad/param norm = 2.4829e-01, time/batch = 0.6774s	
1746/28500 (epoch 3.063), train_loss = 1.91828191, grad/param norm = 2.2123e-01, time/batch = 0.6776s	
1747/28500 (epoch 3.065), train_loss = 2.01016536, grad/param norm = 2.3666e-01, time/batch = 0.6771s	
1748/28500 (epoch 3.067), train_loss = 1.73907849, grad/param norm = 2.5157e-01, time/batch = 0.6775s	
1749/28500 (epoch 3.068), train_loss = 1.62375293, grad/param norm = 2.0939e-01, time/batch = 0.6893s	
1750/28500 (epoch 3.070), train_loss = 1.83355097, grad/param norm = 2.2942e-01, time/batch = 0.6785s	
1751/28500 (epoch 3.072), train_loss = 2.01938391, grad/param norm = 2.3861e-01, time/batch = 0.6879s	
1752/28500 (epoch 3.074), train_loss = 1.82398383, grad/param norm = 2.3991e-01, time/batch = 0.6893s	
1753/28500 (epoch 3.075), train_loss = 1.69823212, grad/param norm = 2.1691e-01, time/batch = 0.6777s	
1754/28500 (epoch 3.077), train_loss = 1.80791326, grad/param norm = 2.0941e-01, time/batch = 0.6852s	
1755/28500 (epoch 3.079), train_loss = 1.78152575, grad/param norm = 2.3022e-01, time/batch = 0.6809s	
1756/28500 (epoch 3.081), train_loss = 1.90834945, grad/param norm = 2.3835e-01, time/batch = 0.6769s	
1757/28500 (epoch 3.082), train_loss = 1.85567038, grad/param norm = 2.6664e-01, time/batch = 0.6925s	
1758/28500 (epoch 3.084), train_loss = 1.85134200, grad/param norm = 2.1921e-01, time/batch = 0.6826s	
1759/28500 (epoch 3.086), train_loss = 1.65917899, grad/param norm = 2.2625e-01, time/batch = 0.6781s	
1760/28500 (epoch 3.088), train_loss = 1.64954654, grad/param norm = 2.3040e-01, time/batch = 0.6779s	
1761/28500 (epoch 3.089), train_loss = 1.92169675, grad/param norm = 2.1680e-01, time/batch = 0.6782s	
1762/28500 (epoch 3.091), train_loss = 1.59219157, grad/param norm = 2.0809e-01, time/batch = 0.6770s	
1763/28500 (epoch 3.093), train_loss = 1.75954971, grad/param norm = 2.1502e-01, time/batch = 0.6765s	
1764/28500 (epoch 3.095), train_loss = 1.76268388, grad/param norm = 2.3579e-01, time/batch = 0.6764s	
1765/28500 (epoch 3.096), train_loss = 1.87316923, grad/param norm = 2.2816e-01, time/batch = 0.6803s	
1766/28500 (epoch 3.098), train_loss = 1.94936957, grad/param norm = 2.4906e-01, time/batch = 0.6896s	
1767/28500 (epoch 3.100), train_loss = 1.66266645, grad/param norm = 2.4116e-01, time/batch = 0.6767s	
1768/28500 (epoch 3.102), train_loss = 1.93332107, grad/param norm = 2.1593e-01, time/batch = 0.6762s	
1769/28500 (epoch 3.104), train_loss = 1.77649141, grad/param norm = 2.2937e-01, time/batch = 0.6762s	
1770/28500 (epoch 3.105), train_loss = 1.79460798, grad/param norm = 2.3532e-01, time/batch = 0.6762s	
1771/28500 (epoch 3.107), train_loss = 1.69603062, grad/param norm = 2.5761e-01, time/batch = 0.6781s	
1772/28500 (epoch 3.109), train_loss = 1.66100449, grad/param norm = 2.1967e-01, time/batch = 0.6783s	
1773/28500 (epoch 3.111), train_loss = 1.76061098, grad/param norm = 2.2406e-01, time/batch = 0.6766s	
1774/28500 (epoch 3.112), train_loss = 1.84078758, grad/param norm = 2.1912e-01, time/batch = 0.6766s	
1775/28500 (epoch 3.114), train_loss = 1.71459254, grad/param norm = 2.1779e-01, time/batch = 0.6772s	
1776/28500 (epoch 3.116), train_loss = 1.91655929, grad/param norm = 2.4316e-01, time/batch = 0.6766s	
1777/28500 (epoch 3.118), train_loss = 1.61597659, grad/param norm = 2.2582e-01, time/batch = 0.6763s	
1778/28500 (epoch 3.119), train_loss = 1.83110264, grad/param norm = 2.4274e-01, time/batch = 0.6849s	
1779/28500 (epoch 3.121), train_loss = 1.96410713, grad/param norm = 2.2646e-01, time/batch = 0.6851s	
1780/28500 (epoch 3.123), train_loss = 1.83404961, grad/param norm = 2.6408e-01, time/batch = 0.6798s	
1781/28500 (epoch 3.125), train_loss = 1.88426165, grad/param norm = 2.2125e-01, time/batch = 0.6801s	
1782/28500 (epoch 3.126), train_loss = 1.79367353, grad/param norm = 2.2680e-01, time/batch = 0.6791s	
1783/28500 (epoch 3.128), train_loss = 1.70785054, grad/param norm = 2.7927e-01, time/batch = 0.6784s	
1784/28500 (epoch 3.130), train_loss = 1.78595001, grad/param norm = 2.3676e-01, time/batch = 0.6783s	
1785/28500 (epoch 3.132), train_loss = 1.84213623, grad/param norm = 2.4353e-01, time/batch = 0.6782s	
1786/28500 (epoch 3.133), train_loss = 1.70261099, grad/param norm = 2.1487e-01, time/batch = 0.6789s	
1787/28500 (epoch 3.135), train_loss = 1.75652306, grad/param norm = 2.0998e-01, time/batch = 0.6838s	
1788/28500 (epoch 3.137), train_loss = 1.67770710, grad/param norm = 2.3762e-01, time/batch = 0.6878s	
1789/28500 (epoch 3.139), train_loss = 1.69852452, grad/param norm = 2.0614e-01, time/batch = 0.6884s	
1790/28500 (epoch 3.140), train_loss = 1.73736048, grad/param norm = 2.1594e-01, time/batch = 0.6893s	
1791/28500 (epoch 3.142), train_loss = 1.80999698, grad/param norm = 2.4371e-01, time/batch = 0.6873s	
1792/28500 (epoch 3.144), train_loss = 1.65170933, grad/param norm = 2.2603e-01, time/batch = 0.6863s	
1793/28500 (epoch 3.146), train_loss = 1.66390870, grad/param norm = 2.3395e-01, time/batch = 0.6821s	
1794/28500 (epoch 3.147), train_loss = 1.57500038, grad/param norm = 2.0071e-01, time/batch = 0.6796s	
1795/28500 (epoch 3.149), train_loss = 1.66712017, grad/param norm = 2.1213e-01, time/batch = 0.6788s	
1796/28500 (epoch 3.151), train_loss = 1.61864323, grad/param norm = 2.2601e-01, time/batch = 0.6800s	
1797/28500 (epoch 3.153), train_loss = 1.68231750, grad/param norm = 2.4728e-01, time/batch = 0.6807s	
1798/28500 (epoch 3.154), train_loss = 1.66040033, grad/param norm = 2.1068e-01, time/batch = 0.6807s	
1799/28500 (epoch 3.156), train_loss = 1.95112852, grad/param norm = 2.4034e-01, time/batch = 0.6841s	
1800/28500 (epoch 3.158), train_loss = 1.68268324, grad/param norm = 2.1643e-01, time/batch = 0.6855s	
1801/28500 (epoch 3.160), train_loss = 1.64319630, grad/param norm = 2.4209e-01, time/batch = 0.6875s	
1802/28500 (epoch 3.161), train_loss = 1.82419648, grad/param norm = 2.6483e-01, time/batch = 0.6831s	
1803/28500 (epoch 3.163), train_loss = 1.68853271, grad/param norm = 2.6247e-01, time/batch = 0.6798s	
1804/28500 (epoch 3.165), train_loss = 1.92958485, grad/param norm = 2.3111e-01, time/batch = 0.6804s	
1805/28500 (epoch 3.167), train_loss = 1.96757698, grad/param norm = 2.2194e-01, time/batch = 0.6864s	
1806/28500 (epoch 3.168), train_loss = 1.83403219, grad/param norm = 2.6319e-01, time/batch = 0.6958s	
1807/28500 (epoch 3.170), train_loss = 1.90763697, grad/param norm = 2.6538e-01, time/batch = 0.6867s	
1808/28500 (epoch 3.172), train_loss = 1.73799295, grad/param norm = 3.1062e-01, time/batch = 0.6840s	
1809/28500 (epoch 3.174), train_loss = 1.94887684, grad/param norm = 2.1496e-01, time/batch = 0.7792s	
1810/28500 (epoch 3.175), train_loss = 1.70897744, grad/param norm = 2.0196e-01, time/batch = 0.6809s	
1811/28500 (epoch 3.177), train_loss = 1.84436160, grad/param norm = 2.1858e-01, time/batch = 0.6838s	
1812/28500 (epoch 3.179), train_loss = 1.70113687, grad/param norm = 2.3733e-01, time/batch = 0.6832s	
1813/28500 (epoch 3.181), train_loss = 1.89086487, grad/param norm = 2.4841e-01, time/batch = 0.6899s	
1814/28500 (epoch 3.182), train_loss = 1.77657089, grad/param norm = 2.5535e-01, time/batch = 0.6755s	
1815/28500 (epoch 3.184), train_loss = 1.95697386, grad/param norm = 2.4339e-01, time/batch = 0.6765s	
1816/28500 (epoch 3.186), train_loss = 1.89407143, grad/param norm = 2.5562e-01, time/batch = 0.6782s	
1817/28500 (epoch 3.188), train_loss = 1.72043381, grad/param norm = 2.2564e-01, time/batch = 0.6756s	
1818/28500 (epoch 3.189), train_loss = 1.87865926, grad/param norm = 2.3256e-01, time/batch = 0.6758s	
1819/28500 (epoch 3.191), train_loss = 1.99592609, grad/param norm = 2.3589e-01, time/batch = 0.6779s	
1820/28500 (epoch 3.193), train_loss = 1.82286517, grad/param norm = 2.4338e-01, time/batch = 0.6762s	
1821/28500 (epoch 3.195), train_loss = 1.85953304, grad/param norm = 2.4414e-01, time/batch = 0.6789s	
1822/28500 (epoch 3.196), train_loss = 1.77796498, grad/param norm = 2.4096e-01, time/batch = 0.6768s	
1823/28500 (epoch 3.198), train_loss = 1.76016360, grad/param norm = 2.2896e-01, time/batch = 0.6764s	
1824/28500 (epoch 3.200), train_loss = 1.72707646, grad/param norm = 1.9675e-01, time/batch = 0.6759s	
1825/28500 (epoch 3.202), train_loss = 1.82208869, grad/param norm = 2.4355e-01, time/batch = 0.6763s	
1826/28500 (epoch 3.204), train_loss = 1.58176118, grad/param norm = 1.9558e-01, time/batch = 0.6758s	
1827/28500 (epoch 3.205), train_loss = 1.65534878, grad/param norm = 2.1308e-01, time/batch = 0.6767s	
1828/28500 (epoch 3.207), train_loss = 1.80626932, grad/param norm = 2.4180e-01, time/batch = 0.6775s	
1829/28500 (epoch 3.209), train_loss = 1.72954130, grad/param norm = 2.4969e-01, time/batch = 0.6761s	
1830/28500 (epoch 3.211), train_loss = 1.61695072, grad/param norm = 2.0969e-01, time/batch = 0.6752s	
1831/28500 (epoch 3.212), train_loss = 1.63562874, grad/param norm = 2.2250e-01, time/batch = 0.6802s	
1832/28500 (epoch 3.214), train_loss = 1.85265543, grad/param norm = 2.4406e-01, time/batch = 0.6767s	
1833/28500 (epoch 3.216), train_loss = 1.61698366, grad/param norm = 1.9670e-01, time/batch = 0.6769s	
1834/28500 (epoch 3.218), train_loss = 1.76272829, grad/param norm = 1.9886e-01, time/batch = 0.6782s	
1835/28500 (epoch 3.219), train_loss = 1.69823258, grad/param norm = 2.0944e-01, time/batch = 0.6813s	
1836/28500 (epoch 3.221), train_loss = 1.64158597, grad/param norm = 2.0774e-01, time/batch = 0.6792s	
1837/28500 (epoch 3.223), train_loss = 1.87139695, grad/param norm = 2.5478e-01, time/batch = 0.6798s	
1838/28500 (epoch 3.225), train_loss = 1.92152258, grad/param norm = 2.4535e-01, time/batch = 0.6798s	
1839/28500 (epoch 3.226), train_loss = 1.79318618, grad/param norm = 2.4920e-01, time/batch = 0.6797s	
1840/28500 (epoch 3.228), train_loss = 1.76109743, grad/param norm = 2.2624e-01, time/batch = 0.6804s	
1841/28500 (epoch 3.230), train_loss = 1.74149392, grad/param norm = 2.1602e-01, time/batch = 0.6823s	
1842/28500 (epoch 3.232), train_loss = 1.81607414, grad/param norm = 2.2376e-01, time/batch = 0.6791s	
1843/28500 (epoch 3.233), train_loss = 1.78556429, grad/param norm = 2.4085e-01, time/batch = 0.6818s	
1844/28500 (epoch 3.235), train_loss = 1.63774907, grad/param norm = 2.1305e-01, time/batch = 0.6863s	
1845/28500 (epoch 3.237), train_loss = 1.58498357, grad/param norm = 1.9250e-01, time/batch = 0.6808s	
1846/28500 (epoch 3.239), train_loss = 1.66206161, grad/param norm = 2.1098e-01, time/batch = 0.6823s	
1847/28500 (epoch 3.240), train_loss = 1.60310391, grad/param norm = 2.0505e-01, time/batch = 0.6825s	
1848/28500 (epoch 3.242), train_loss = 1.79878936, grad/param norm = 2.1791e-01, time/batch = 0.6826s	
1849/28500 (epoch 3.244), train_loss = 1.85109353, grad/param norm = 2.1831e-01, time/batch = 0.6804s	
1850/28500 (epoch 3.246), train_loss = 1.76251528, grad/param norm = 2.1649e-01, time/batch = 0.6802s	
1851/28500 (epoch 3.247), train_loss = 1.92168931, grad/param norm = 2.2733e-01, time/batch = 0.6822s	
1852/28500 (epoch 3.249), train_loss = 1.78373952, grad/param norm = 2.5967e-01, time/batch = 0.6797s	
1853/28500 (epoch 3.251), train_loss = 1.50685080, grad/param norm = 2.0317e-01, time/batch = 0.6806s	
1854/28500 (epoch 3.253), train_loss = 1.82546537, grad/param norm = 2.1596e-01, time/batch = 0.6797s	
1855/28500 (epoch 3.254), train_loss = 1.80163756, grad/param norm = 2.1382e-01, time/batch = 0.6815s	
1856/28500 (epoch 3.256), train_loss = 1.68255140, grad/param norm = 2.2005e-01, time/batch = 0.6810s	
1857/28500 (epoch 3.258), train_loss = 1.72210090, grad/param norm = 2.5104e-01, time/batch = 0.6799s	
1858/28500 (epoch 3.260), train_loss = 1.70818194, grad/param norm = 2.2220e-01, time/batch = 0.6795s	
1859/28500 (epoch 3.261), train_loss = 1.67414349, grad/param norm = 2.1820e-01, time/batch = 0.6796s	
1860/28500 (epoch 3.263), train_loss = 1.92033586, grad/param norm = 2.4668e-01, time/batch = 0.6799s	
1861/28500 (epoch 3.265), train_loss = 1.82609446, grad/param norm = 2.4243e-01, time/batch = 0.6836s	
1862/28500 (epoch 3.267), train_loss = 1.89043711, grad/param norm = 2.3661e-01, time/batch = 0.6827s	
1863/28500 (epoch 3.268), train_loss = 1.83288314, grad/param norm = 2.5311e-01, time/batch = 0.6805s	
1864/28500 (epoch 3.270), train_loss = 1.66115004, grad/param norm = 1.9753e-01, time/batch = 0.6804s	
1865/28500 (epoch 3.272), train_loss = 1.72751159, grad/param norm = 2.6199e-01, time/batch = 0.6797s	
1866/28500 (epoch 3.274), train_loss = 1.93155374, grad/param norm = 2.5563e-01, time/batch = 0.6812s	
1867/28500 (epoch 3.275), train_loss = 1.81483493, grad/param norm = 2.1494e-01, time/batch = 0.6794s	
1868/28500 (epoch 3.277), train_loss = 1.67953583, grad/param norm = 2.1908e-01, time/batch = 0.6809s	
1869/28500 (epoch 3.279), train_loss = 1.75951137, grad/param norm = 2.2763e-01, time/batch = 0.6813s	
1870/28500 (epoch 3.281), train_loss = 1.76384572, grad/param norm = 2.1972e-01, time/batch = 0.6800s	
1871/28500 (epoch 3.282), train_loss = 1.64788643, grad/param norm = 2.1614e-01, time/batch = 0.6822s	
1872/28500 (epoch 3.284), train_loss = 1.76146617, grad/param norm = 2.2424e-01, time/batch = 0.6822s	
1873/28500 (epoch 3.286), train_loss = 1.89583399, grad/param norm = 2.5184e-01, time/batch = 0.6801s	
1874/28500 (epoch 3.288), train_loss = 1.74613904, grad/param norm = 2.2873e-01, time/batch = 0.6797s	
1875/28500 (epoch 3.289), train_loss = 1.91590671, grad/param norm = 2.2326e-01, time/batch = 0.6805s	
1876/28500 (epoch 3.291), train_loss = 1.64773447, grad/param norm = 2.3121e-01, time/batch = 0.6813s	
1877/28500 (epoch 3.293), train_loss = 1.67098010, grad/param norm = 2.2991e-01, time/batch = 0.6831s	
1878/28500 (epoch 3.295), train_loss = 1.66065124, grad/param norm = 2.1909e-01, time/batch = 0.6923s	
1879/28500 (epoch 3.296), train_loss = 1.59264721, grad/param norm = 1.9708e-01, time/batch = 0.6891s	
1880/28500 (epoch 3.298), train_loss = 1.74111324, grad/param norm = 2.2350e-01, time/batch = 0.6813s	
1881/28500 (epoch 3.300), train_loss = 1.60579883, grad/param norm = 2.1144e-01, time/batch = 0.6825s	
1882/28500 (epoch 3.302), train_loss = 1.59913009, grad/param norm = 2.1272e-01, time/batch = 0.6821s	
1883/28500 (epoch 3.304), train_loss = 1.63679148, grad/param norm = 1.8885e-01, time/batch = 0.6831s	
1884/28500 (epoch 3.305), train_loss = 1.78587666, grad/param norm = 2.1669e-01, time/batch = 0.6828s	
1885/28500 (epoch 3.307), train_loss = 1.83512359, grad/param norm = 2.8268e-01, time/batch = 0.6848s	
1886/28500 (epoch 3.309), train_loss = 1.84521180, grad/param norm = 2.4928e-01, time/batch = 0.6827s	
1887/28500 (epoch 3.311), train_loss = 1.72873960, grad/param norm = 2.8397e-01, time/batch = 0.6831s	
1888/28500 (epoch 3.312), train_loss = 1.57900263, grad/param norm = 2.1605e-01, time/batch = 0.6869s	
1889/28500 (epoch 3.314), train_loss = 1.75874014, grad/param norm = 2.4763e-01, time/batch = 0.6799s	
1890/28500 (epoch 3.316), train_loss = 1.71803065, grad/param norm = 1.9722e-01, time/batch = 0.6803s	
1891/28500 (epoch 3.318), train_loss = 1.75682162, grad/param norm = 2.4142e-01, time/batch = 0.6842s	
1892/28500 (epoch 3.319), train_loss = 1.69277111, grad/param norm = 2.3624e-01, time/batch = 0.6853s	
1893/28500 (epoch 3.321), train_loss = 1.80229474, grad/param norm = 2.1514e-01, time/batch = 0.6800s	
1894/28500 (epoch 3.323), train_loss = 1.70753484, grad/param norm = 2.2016e-01, time/batch = 0.6791s	
1895/28500 (epoch 3.325), train_loss = 1.93797533, grad/param norm = 2.1976e-01, time/batch = 0.6806s	
1896/28500 (epoch 3.326), train_loss = 1.89146589, grad/param norm = 2.5635e-01, time/batch = 0.6790s	
1897/28500 (epoch 3.328), train_loss = 1.51921749, grad/param norm = 2.3451e-01, time/batch = 0.6872s	
1898/28500 (epoch 3.330), train_loss = 1.65756120, grad/param norm = 2.1766e-01, time/batch = 0.6818s	
1899/28500 (epoch 3.332), train_loss = 1.65931486, grad/param norm = 2.0467e-01, time/batch = 0.6822s	
1900/28500 (epoch 3.333), train_loss = 1.55507337, grad/param norm = 2.0792e-01, time/batch = 0.6785s	
1901/28500 (epoch 3.335), train_loss = 1.56403309, grad/param norm = 2.1048e-01, time/batch = 0.6826s	
1902/28500 (epoch 3.337), train_loss = 1.74669484, grad/param norm = 2.4818e-01, time/batch = 0.6809s	
1903/28500 (epoch 3.339), train_loss = 1.69893214, grad/param norm = 2.3794e-01, time/batch = 0.6802s	
1904/28500 (epoch 3.340), train_loss = 1.83853835, grad/param norm = 2.6150e-01, time/batch = 0.6832s	
1905/28500 (epoch 3.342), train_loss = 1.65174691, grad/param norm = 2.7034e-01, time/batch = 0.6813s	
1906/28500 (epoch 3.344), train_loss = 1.65956172, grad/param norm = 2.5739e-01, time/batch = 0.6806s	
1907/28500 (epoch 3.346), train_loss = 1.40655364, grad/param norm = 2.2193e-01, time/batch = 0.6761s	
1908/28500 (epoch 3.347), train_loss = 1.71128564, grad/param norm = 2.3785e-01, time/batch = 0.6766s	
1909/28500 (epoch 3.349), train_loss = 1.59596249, grad/param norm = 1.9769e-01, time/batch = 0.6762s	
1910/28500 (epoch 3.351), train_loss = 1.53391418, grad/param norm = 1.9434e-01, time/batch = 0.6759s	
1911/28500 (epoch 3.353), train_loss = 1.79794817, grad/param norm = 2.1505e-01, time/batch = 0.6780s	
1912/28500 (epoch 3.354), train_loss = 1.61737827, grad/param norm = 2.3214e-01, time/batch = 0.6773s	
1913/28500 (epoch 3.356), train_loss = 1.60682729, grad/param norm = 2.0833e-01, time/batch = 0.6804s	
1914/28500 (epoch 3.358), train_loss = 1.76551615, grad/param norm = 1.9515e-01, time/batch = 0.6794s	
1915/28500 (epoch 3.360), train_loss = 1.72199310, grad/param norm = 2.3015e-01, time/batch = 0.6782s	
1916/28500 (epoch 3.361), train_loss = 1.69974543, grad/param norm = 2.1851e-01, time/batch = 0.6798s	
1917/28500 (epoch 3.363), train_loss = 1.60386892, grad/param norm = 2.0946e-01, time/batch = 0.6801s	
1918/28500 (epoch 3.365), train_loss = 1.65034881, grad/param norm = 2.2326e-01, time/batch = 0.6826s	
1919/28500 (epoch 3.367), train_loss = 1.70655354, grad/param norm = 2.3438e-01, time/batch = 0.6802s	
1920/28500 (epoch 3.368), train_loss = 1.67130684, grad/param norm = 2.1754e-01, time/batch = 0.6773s	
1921/28500 (epoch 3.370), train_loss = 1.72986616, grad/param norm = 2.1962e-01, time/batch = 0.6826s	
1922/28500 (epoch 3.372), train_loss = 1.61031637, grad/param norm = 2.2751e-01, time/batch = 0.6816s	
1923/28500 (epoch 3.374), train_loss = 1.80980982, grad/param norm = 2.4200e-01, time/batch = 0.6806s	
1924/28500 (epoch 3.375), train_loss = 1.85472252, grad/param norm = 2.3999e-01, time/batch = 0.6778s	
1925/28500 (epoch 3.377), train_loss = 1.69047832, grad/param norm = 2.4061e-01, time/batch = 0.6768s	
1926/28500 (epoch 3.379), train_loss = 1.52139468, grad/param norm = 2.3546e-01, time/batch = 0.6762s	
1927/28500 (epoch 3.381), train_loss = 1.61800102, grad/param norm = 2.0013e-01, time/batch = 0.6781s	
1928/28500 (epoch 3.382), train_loss = 1.69193182, grad/param norm = 2.3651e-01, time/batch = 0.6814s	
1929/28500 (epoch 3.384), train_loss = 1.59047390, grad/param norm = 2.1173e-01, time/batch = 0.6798s	
1930/28500 (epoch 3.386), train_loss = 1.55807114, grad/param norm = 2.2614e-01, time/batch = 0.6793s	
1931/28500 (epoch 3.388), train_loss = 1.81397276, grad/param norm = 2.2760e-01, time/batch = 0.6782s	
1932/28500 (epoch 3.389), train_loss = 1.67081933, grad/param norm = 2.0902e-01, time/batch = 0.6769s	
1933/28500 (epoch 3.391), train_loss = 1.62080829, grad/param norm = 2.0098e-01, time/batch = 0.6790s	
1934/28500 (epoch 3.393), train_loss = 1.55175037, grad/param norm = 2.1345e-01, time/batch = 0.6796s	
1935/28500 (epoch 3.395), train_loss = 1.89744164, grad/param norm = 2.2001e-01, time/batch = 0.6803s	
1936/28500 (epoch 3.396), train_loss = 1.79377568, grad/param norm = 2.1553e-01, time/batch = 0.6767s	
1937/28500 (epoch 3.398), train_loss = 1.59817863, grad/param norm = 2.3727e-01, time/batch = 0.6763s	
1938/28500 (epoch 3.400), train_loss = 1.81437611, grad/param norm = 2.3640e-01, time/batch = 0.6763s	
1939/28500 (epoch 3.402), train_loss = 1.68364158, grad/param norm = 2.4598e-01, time/batch = 0.6779s	
1940/28500 (epoch 3.404), train_loss = 1.80666183, grad/param norm = 2.1879e-01, time/batch = 0.6762s	
1941/28500 (epoch 3.405), train_loss = 1.75590978, grad/param norm = 2.0573e-01, time/batch = 0.6778s	
1942/28500 (epoch 3.407), train_loss = 1.75235819, grad/param norm = 2.0774e-01, time/batch = 0.6766s	
1943/28500 (epoch 3.409), train_loss = 1.73261359, grad/param norm = 2.2764e-01, time/batch = 0.6761s	
1944/28500 (epoch 3.411), train_loss = 1.75537791, grad/param norm = 2.2951e-01, time/batch = 0.6761s	
1945/28500 (epoch 3.412), train_loss = 1.86420125, grad/param norm = 2.2803e-01, time/batch = 0.6760s	
1946/28500 (epoch 3.414), train_loss = 1.70622394, grad/param norm = 2.0754e-01, time/batch = 0.6758s	
1947/28500 (epoch 3.416), train_loss = 1.61629824, grad/param norm = 2.1619e-01, time/batch = 0.6757s	
1948/28500 (epoch 3.418), train_loss = 1.75547138, grad/param norm = 2.2320e-01, time/batch = 0.6763s	
1949/28500 (epoch 3.419), train_loss = 1.82573941, grad/param norm = 2.3118e-01, time/batch = 0.6776s	
1950/28500 (epoch 3.421), train_loss = 1.79265486, grad/param norm = 2.3432e-01, time/batch = 0.6821s	
1951/28500 (epoch 3.423), train_loss = 1.95213049, grad/param norm = 2.6655e-01, time/batch = 0.6837s	
1952/28500 (epoch 3.425), train_loss = 1.79774825, grad/param norm = 2.6056e-01, time/batch = 0.6819s	
1953/28500 (epoch 3.426), train_loss = 1.77184948, grad/param norm = 2.5579e-01, time/batch = 0.6774s	
1954/28500 (epoch 3.428), train_loss = 1.95381988, grad/param norm = 2.5024e-01, time/batch = 0.6764s	
1955/28500 (epoch 3.430), train_loss = 1.75977062, grad/param norm = 2.2923e-01, time/batch = 0.6780s	
1956/28500 (epoch 3.432), train_loss = 1.82058949, grad/param norm = 2.6441e-01, time/batch = 0.6772s	
1957/28500 (epoch 3.433), train_loss = 1.72312154, grad/param norm = 2.2958e-01, time/batch = 0.6773s	
1958/28500 (epoch 3.435), train_loss = 1.67141641, grad/param norm = 2.3306e-01, time/batch = 0.6774s	
1959/28500 (epoch 3.437), train_loss = 1.52633642, grad/param norm = 1.9529e-01, time/batch = 0.6807s	
1960/28500 (epoch 3.439), train_loss = 1.59859780, grad/param norm = 2.1163e-01, time/batch = 0.6818s	
1961/28500 (epoch 3.440), train_loss = 1.73481419, grad/param norm = 1.9764e-01, time/batch = 0.6908s	
1962/28500 (epoch 3.442), train_loss = 1.62297240, grad/param norm = 2.1954e-01, time/batch = 0.6766s	
1963/28500 (epoch 3.444), train_loss = 1.55577127, grad/param norm = 2.1383e-01, time/batch = 0.6783s	
1964/28500 (epoch 3.446), train_loss = 1.48752727, grad/param norm = 2.2165e-01, time/batch = 0.6817s	
1965/28500 (epoch 3.447), train_loss = 1.61101768, grad/param norm = 2.1092e-01, time/batch = 0.6835s	
1966/28500 (epoch 3.449), train_loss = 1.65139731, grad/param norm = 2.3700e-01, time/batch = 0.6930s	
1967/28500 (epoch 3.451), train_loss = 1.69431200, grad/param norm = 2.1565e-01, time/batch = 0.6924s	
1968/28500 (epoch 3.453), train_loss = 1.70802035, grad/param norm = 2.1782e-01, time/batch = 0.6934s	
1969/28500 (epoch 3.454), train_loss = 1.58461424, grad/param norm = 2.2662e-01, time/batch = 0.6860s	
1970/28500 (epoch 3.456), train_loss = 1.78067545, grad/param norm = 2.4995e-01, time/batch = 0.6797s	
1971/28500 (epoch 3.458), train_loss = 1.65324327, grad/param norm = 2.4086e-01, time/batch = 0.6830s	
1972/28500 (epoch 3.460), train_loss = 1.78905734, grad/param norm = 2.1003e-01, time/batch = 0.6863s	
1973/28500 (epoch 3.461), train_loss = 1.66421947, grad/param norm = 2.1744e-01, time/batch = 0.6799s	
1974/28500 (epoch 3.463), train_loss = 1.56511156, grad/param norm = 1.9739e-01, time/batch = 0.6787s	
1975/28500 (epoch 3.465), train_loss = 1.49147418, grad/param norm = 2.2828e-01, time/batch = 0.6872s	
1976/28500 (epoch 3.467), train_loss = 1.78292529, grad/param norm = 2.3261e-01, time/batch = 0.6860s	
1977/28500 (epoch 3.468), train_loss = 1.49328391, grad/param norm = 1.7845e-01, time/batch = 0.6826s	
1978/28500 (epoch 3.470), train_loss = 1.73092468, grad/param norm = 2.4375e-01, time/batch = 0.6950s	
1979/28500 (epoch 3.472), train_loss = 1.64334690, grad/param norm = 2.1576e-01, time/batch = 0.6806s	
1980/28500 (epoch 3.474), train_loss = 1.88482064, grad/param norm = 2.3174e-01, time/batch = 0.6790s	
1981/28500 (epoch 3.475), train_loss = 1.65974856, grad/param norm = 2.2968e-01, time/batch = 0.6888s	
1982/28500 (epoch 3.477), train_loss = 1.63633031, grad/param norm = 2.2776e-01, time/batch = 0.6783s	
1983/28500 (epoch 3.479), train_loss = 1.70972171, grad/param norm = 2.1148e-01, time/batch = 0.6853s	
1984/28500 (epoch 3.481), train_loss = 1.71718943, grad/param norm = 2.4708e-01, time/batch = 0.6759s	
1985/28500 (epoch 3.482), train_loss = 1.61802374, grad/param norm = 2.3021e-01, time/batch = 0.6819s	
1986/28500 (epoch 3.484), train_loss = 1.59793029, grad/param norm = 2.4128e-01, time/batch = 0.6878s	
1987/28500 (epoch 3.486), train_loss = 1.61359981, grad/param norm = 2.2920e-01, time/batch = 0.6818s	
1988/28500 (epoch 3.488), train_loss = 1.62650124, grad/param norm = 2.5460e-01, time/batch = 0.6775s	
1989/28500 (epoch 3.489), train_loss = 1.78510140, grad/param norm = 2.6452e-01, time/batch = 0.6786s	
1990/28500 (epoch 3.491), train_loss = 1.63185282, grad/param norm = 2.3717e-01, time/batch = 0.6766s	
1991/28500 (epoch 3.493), train_loss = 1.57356926, grad/param norm = 2.0232e-01, time/batch = 0.6775s	
1992/28500 (epoch 3.495), train_loss = 1.65713487, grad/param norm = 2.0988e-01, time/batch = 0.6765s	
1993/28500 (epoch 3.496), train_loss = 1.74527027, grad/param norm = 2.2317e-01, time/batch = 0.6767s	
1994/28500 (epoch 3.498), train_loss = 1.72919929, grad/param norm = 2.2445e-01, time/batch = 0.6768s	
1995/28500 (epoch 3.500), train_loss = 1.72056978, grad/param norm = 2.2977e-01, time/batch = 0.6784s	
1996/28500 (epoch 3.502), train_loss = 1.75098133, grad/param norm = 2.2566e-01, time/batch = 0.6773s	
1997/28500 (epoch 3.504), train_loss = 1.72381122, grad/param norm = 2.0381e-01, time/batch = 0.6759s	
1998/28500 (epoch 3.505), train_loss = 1.61684318, grad/param norm = 1.9828e-01, time/batch = 0.6757s	
1999/28500 (epoch 3.507), train_loss = 1.89704530, grad/param norm = 2.4232e-01, time/batch = 0.6755s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch3.51_1.7862.t7	
2000/28500 (epoch 3.509), train_loss = 1.65340210, grad/param norm = 2.3805e-01, time/batch = 0.6755s	
2001/28500 (epoch 3.511), train_loss = 1.86142190, grad/param norm = 2.2377e-01, time/batch = 0.6861s	
2002/28500 (epoch 3.512), train_loss = 1.62563573, grad/param norm = 1.9307e-01, time/batch = 0.6768s	
2003/28500 (epoch 3.514), train_loss = 1.54594583, grad/param norm = 2.1438e-01, time/batch = 0.6770s	
2004/28500 (epoch 3.516), train_loss = 1.57402103, grad/param norm = 2.0192e-01, time/batch = 0.6861s	
2005/28500 (epoch 3.518), train_loss = 1.63162846, grad/param norm = 1.9449e-01, time/batch = 0.6795s	
2006/28500 (epoch 3.519), train_loss = 1.78407071, grad/param norm = 2.2988e-01, time/batch = 0.6827s	
2007/28500 (epoch 3.521), train_loss = 1.85866699, grad/param norm = 2.2988e-01, time/batch = 0.6839s	
2008/28500 (epoch 3.523), train_loss = 1.75634294, grad/param norm = 2.3742e-01, time/batch = 0.6804s	
2009/28500 (epoch 3.525), train_loss = 1.82456974, grad/param norm = 2.3098e-01, time/batch = 0.6757s	
2010/28500 (epoch 3.526), train_loss = 1.67233449, grad/param norm = 2.0692e-01, time/batch = 0.6763s	
2011/28500 (epoch 3.528), train_loss = 1.78149049, grad/param norm = 2.3459e-01, time/batch = 0.6767s	
2012/28500 (epoch 3.530), train_loss = 1.79846538, grad/param norm = 2.2198e-01, time/batch = 0.6774s	
2013/28500 (epoch 3.532), train_loss = 1.62664719, grad/param norm = 2.1238e-01, time/batch = 0.6772s	
2014/28500 (epoch 3.533), train_loss = 1.82592303, grad/param norm = 2.2522e-01, time/batch = 0.6763s	
2015/28500 (epoch 3.535), train_loss = 1.52580868, grad/param norm = 2.1919e-01, time/batch = 0.6764s	
2016/28500 (epoch 3.537), train_loss = 1.45449050, grad/param norm = 1.9996e-01, time/batch = 0.6766s	
2017/28500 (epoch 3.539), train_loss = 1.59688288, grad/param norm = 2.0932e-01, time/batch = 0.6752s	
2018/28500 (epoch 3.540), train_loss = 1.72109434, grad/param norm = 2.2384e-01, time/batch = 0.6753s	
2019/28500 (epoch 3.542), train_loss = 1.96919291, grad/param norm = 2.7312e-01, time/batch = 0.6756s	
2020/28500 (epoch 3.544), train_loss = 1.80021902, grad/param norm = 2.1971e-01, time/batch = 0.6763s	
2021/28500 (epoch 3.546), train_loss = 1.75306826, grad/param norm = 2.2566e-01, time/batch = 0.6859s	
2022/28500 (epoch 3.547), train_loss = 1.72005941, grad/param norm = 2.1412e-01, time/batch = 0.6853s	
2023/28500 (epoch 3.549), train_loss = 1.52572324, grad/param norm = 2.0335e-01, time/batch = 0.6875s	
2024/28500 (epoch 3.551), train_loss = 1.89270894, grad/param norm = 2.3184e-01, time/batch = 0.6757s	
2025/28500 (epoch 3.553), train_loss = 1.92000145, grad/param norm = 2.2128e-01, time/batch = 0.6795s	
2026/28500 (epoch 3.554), train_loss = 1.66672740, grad/param norm = 2.1539e-01, time/batch = 0.6779s	
2027/28500 (epoch 3.556), train_loss = 1.73191885, grad/param norm = 2.2125e-01, time/batch = 0.6776s	
2028/28500 (epoch 3.558), train_loss = 1.71416635, grad/param norm = 2.1228e-01, time/batch = 0.6797s	
2029/28500 (epoch 3.560), train_loss = 1.74950419, grad/param norm = 2.3541e-01, time/batch = 0.6793s	
2030/28500 (epoch 3.561), train_loss = 1.78852281, grad/param norm = 2.5643e-01, time/batch = 0.6804s	
2031/28500 (epoch 3.563), train_loss = 1.79070546, grad/param norm = 2.3972e-01, time/batch = 0.6818s	
2032/28500 (epoch 3.565), train_loss = 1.66159143, grad/param norm = 2.4873e-01, time/batch = 0.6818s	
2033/28500 (epoch 3.567), train_loss = 1.59580523, grad/param norm = 2.1871e-01, time/batch = 0.6798s	
2034/28500 (epoch 3.568), train_loss = 1.76080163, grad/param norm = 2.2348e-01, time/batch = 0.6791s	
2035/28500 (epoch 3.570), train_loss = 1.58488492, grad/param norm = 2.4375e-01, time/batch = 0.6788s	
2036/28500 (epoch 3.572), train_loss = 1.68928177, grad/param norm = 2.3602e-01, time/batch = 0.6791s	
2037/28500 (epoch 3.574), train_loss = 1.73840098, grad/param norm = 2.1634e-01, time/batch = 0.6790s	
2038/28500 (epoch 3.575), train_loss = 1.59883729, grad/param norm = 2.2368e-01, time/batch = 0.6787s	
2039/28500 (epoch 3.577), train_loss = 1.62085689, grad/param norm = 1.9888e-01, time/batch = 0.6788s	
2040/28500 (epoch 3.579), train_loss = 1.88161369, grad/param norm = 2.4890e-01, time/batch = 0.6782s	
2041/28500 (epoch 3.581), train_loss = 1.61182312, grad/param norm = 2.0757e-01, time/batch = 0.6819s	
2042/28500 (epoch 3.582), train_loss = 1.75070051, grad/param norm = 2.1860e-01, time/batch = 0.6795s	
2043/28500 (epoch 3.584), train_loss = 1.61752667, grad/param norm = 1.9292e-01, time/batch = 0.6799s	
2044/28500 (epoch 3.586), train_loss = 1.48778155, grad/param norm = 1.7896e-01, time/batch = 0.6790s	
2045/28500 (epoch 3.588), train_loss = 1.59364292, grad/param norm = 2.1481e-01, time/batch = 0.6927s	
2046/28500 (epoch 3.589), train_loss = 1.99324787, grad/param norm = 2.3005e-01, time/batch = 0.6842s	
2047/28500 (epoch 3.591), train_loss = 1.75484624, grad/param norm = 2.0696e-01, time/batch = 0.6773s	
2048/28500 (epoch 3.593), train_loss = 1.62202095, grad/param norm = 2.0706e-01, time/batch = 0.6802s	
2049/28500 (epoch 3.595), train_loss = 1.94334494, grad/param norm = 2.6539e-01, time/batch = 0.6798s	
2050/28500 (epoch 3.596), train_loss = 1.82581282, grad/param norm = 2.7810e-01, time/batch = 0.6788s	
2051/28500 (epoch 3.598), train_loss = 1.67244535, grad/param norm = 2.0909e-01, time/batch = 0.6833s	
2052/28500 (epoch 3.600), train_loss = 1.72392791, grad/param norm = 2.1346e-01, time/batch = 0.6802s	
2053/28500 (epoch 3.602), train_loss = 1.87579446, grad/param norm = 2.2160e-01, time/batch = 0.6801s	
2054/28500 (epoch 3.604), train_loss = 1.73569734, grad/param norm = 2.2246e-01, time/batch = 0.6791s	
2055/28500 (epoch 3.605), train_loss = 1.69185130, grad/param norm = 2.2175e-01, time/batch = 0.6801s	
2056/28500 (epoch 3.607), train_loss = 1.67915593, grad/param norm = 2.1198e-01, time/batch = 0.6789s	
2057/28500 (epoch 3.609), train_loss = 1.68461290, grad/param norm = 2.2267e-01, time/batch = 0.6821s	
2058/28500 (epoch 3.611), train_loss = 1.69803893, grad/param norm = 2.1038e-01, time/batch = 0.6815s	
2059/28500 (epoch 3.612), train_loss = 1.72082924, grad/param norm = 2.1191e-01, time/batch = 0.6799s	
2060/28500 (epoch 3.614), train_loss = 1.65968727, grad/param norm = 2.0692e-01, time/batch = 0.6834s	
2061/28500 (epoch 3.616), train_loss = 1.65393600, grad/param norm = 2.1464e-01, time/batch = 0.6835s	
2062/28500 (epoch 3.618), train_loss = 1.55263382, grad/param norm = 2.0871e-01, time/batch = 0.6811s	
2063/28500 (epoch 3.619), train_loss = 1.83015227, grad/param norm = 2.2900e-01, time/batch = 0.6811s	
2064/28500 (epoch 3.621), train_loss = 1.41715964, grad/param norm = 1.9603e-01, time/batch = 0.6849s	
2065/28500 (epoch 3.623), train_loss = 1.70368594, grad/param norm = 2.0890e-01, time/batch = 0.6809s	
2066/28500 (epoch 3.625), train_loss = 1.56547986, grad/param norm = 2.2769e-01, time/batch = 0.6810s	
2067/28500 (epoch 3.626), train_loss = 1.42905816, grad/param norm = 1.9977e-01, time/batch = 0.6788s	
2068/28500 (epoch 3.628), train_loss = 1.55039126, grad/param norm = 2.1247e-01, time/batch = 0.6847s	
2069/28500 (epoch 3.630), train_loss = 1.54977460, grad/param norm = 2.1416e-01, time/batch = 0.6796s	
2070/28500 (epoch 3.632), train_loss = 1.76365578, grad/param norm = 2.4020e-01, time/batch = 0.6789s	
2071/28500 (epoch 3.633), train_loss = 1.67896113, grad/param norm = 1.9031e-01, time/batch = 0.6814s	
2072/28500 (epoch 3.635), train_loss = 1.79882119, grad/param norm = 2.2793e-01, time/batch = 0.6787s	
2073/28500 (epoch 3.637), train_loss = 1.66607830, grad/param norm = 2.2351e-01, time/batch = 0.6801s	
2074/28500 (epoch 3.639), train_loss = 1.43943695, grad/param norm = 2.2107e-01, time/batch = 0.6792s	
2075/28500 (epoch 3.640), train_loss = 1.62674441, grad/param norm = 2.1940e-01, time/batch = 0.6794s	
2076/28500 (epoch 3.642), train_loss = 1.71845054, grad/param norm = 1.9321e-01, time/batch = 0.6791s	
2077/28500 (epoch 3.644), train_loss = 1.71049848, grad/param norm = 2.0386e-01, time/batch = 0.6801s	
2078/28500 (epoch 3.646), train_loss = 1.59053222, grad/param norm = 1.8577e-01, time/batch = 0.6792s	
2079/28500 (epoch 3.647), train_loss = 1.55919203, grad/param norm = 2.1986e-01, time/batch = 0.6789s	
2080/28500 (epoch 3.649), train_loss = 1.60399255, grad/param norm = 2.0606e-01, time/batch = 0.6793s	
2081/28500 (epoch 3.651), train_loss = 1.59332707, grad/param norm = 2.0981e-01, time/batch = 0.6829s	
2082/28500 (epoch 3.653), train_loss = 1.54382086, grad/param norm = 2.0676e-01, time/batch = 0.6803s	
2083/28500 (epoch 3.654), train_loss = 1.58226696, grad/param norm = 2.2588e-01, time/batch = 0.6786s	
2084/28500 (epoch 3.656), train_loss = 1.67780248, grad/param norm = 2.0609e-01, time/batch = 0.6814s	
2085/28500 (epoch 3.658), train_loss = 1.70112713, grad/param norm = 2.2334e-01, time/batch = 0.6791s	
2086/28500 (epoch 3.660), train_loss = 1.60965019, grad/param norm = 1.8568e-01, time/batch = 0.6802s	
2087/28500 (epoch 3.661), train_loss = 1.79158727, grad/param norm = 2.1539e-01, time/batch = 0.6940s	
2088/28500 (epoch 3.663), train_loss = 1.82907449, grad/param norm = 2.2030e-01, time/batch = 0.6881s	
2089/28500 (epoch 3.665), train_loss = 1.64022347, grad/param norm = 2.1798e-01, time/batch = 0.6837s	
2090/28500 (epoch 3.667), train_loss = 1.69634086, grad/param norm = 2.2054e-01, time/batch = 0.6811s	
2091/28500 (epoch 3.668), train_loss = 1.63091616, grad/param norm = 2.1764e-01, time/batch = 0.6823s	
2092/28500 (epoch 3.670), train_loss = 1.61198813, grad/param norm = 2.2083e-01, time/batch = 0.6803s	
2093/28500 (epoch 3.672), train_loss = 1.63933320, grad/param norm = 2.0824e-01, time/batch = 0.6811s	
2094/28500 (epoch 3.674), train_loss = 1.52421588, grad/param norm = 2.2044e-01, time/batch = 0.6923s	
2095/28500 (epoch 3.675), train_loss = 1.49393597, grad/param norm = 2.0580e-01, time/batch = 0.6812s	
2096/28500 (epoch 3.677), train_loss = 1.57792011, grad/param norm = 2.1489e-01, time/batch = 0.6800s	
2097/28500 (epoch 3.679), train_loss = 1.70970199, grad/param norm = 2.2594e-01, time/batch = 0.6795s	
2098/28500 (epoch 3.681), train_loss = 1.76567037, grad/param norm = 2.4216e-01, time/batch = 0.6799s	
2099/28500 (epoch 3.682), train_loss = 1.54019031, grad/param norm = 1.9180e-01, time/batch = 0.6799s	
2100/28500 (epoch 3.684), train_loss = 1.67866216, grad/param norm = 2.0721e-01, time/batch = 0.6822s	
2101/28500 (epoch 3.686), train_loss = 1.57297805, grad/param norm = 2.2070e-01, time/batch = 0.6839s	
2102/28500 (epoch 3.688), train_loss = 1.63379342, grad/param norm = 2.1766e-01, time/batch = 0.6800s	
2103/28500 (epoch 3.689), train_loss = 1.74063701, grad/param norm = 2.4426e-01, time/batch = 0.6807s	
2104/28500 (epoch 3.691), train_loss = 1.65719260, grad/param norm = 2.2548e-01, time/batch = 0.6804s	
2105/28500 (epoch 3.693), train_loss = 1.66893637, grad/param norm = 2.1312e-01, time/batch = 0.6797s	
2106/28500 (epoch 3.695), train_loss = 1.65625466, grad/param norm = 2.4195e-01, time/batch = 0.6784s	
2107/28500 (epoch 3.696), train_loss = 1.72345981, grad/param norm = 2.8067e-01, time/batch = 0.6792s	
2108/28500 (epoch 3.698), train_loss = 1.61619576, grad/param norm = 2.0120e-01, time/batch = 0.6788s	
2109/28500 (epoch 3.700), train_loss = 1.62380469, grad/param norm = 2.1965e-01, time/batch = 0.6792s	
2110/28500 (epoch 3.702), train_loss = 1.82141431, grad/param norm = 2.2046e-01, time/batch = 0.6782s	
2111/28500 (epoch 3.704), train_loss = 1.68869368, grad/param norm = 2.2881e-01, time/batch = 0.6817s	
2112/28500 (epoch 3.705), train_loss = 1.71206245, grad/param norm = 2.0749e-01, time/batch = 0.6789s	
2113/28500 (epoch 3.707), train_loss = 1.64566821, grad/param norm = 2.4818e-01, time/batch = 0.6803s	
2114/28500 (epoch 3.709), train_loss = 1.75765617, grad/param norm = 2.3470e-01, time/batch = 0.6780s	
2115/28500 (epoch 3.711), train_loss = 1.57044379, grad/param norm = 2.3125e-01, time/batch = 0.6803s	
2116/28500 (epoch 3.712), train_loss = 1.73336532, grad/param norm = 2.3454e-01, time/batch = 0.6797s	
2117/28500 (epoch 3.714), train_loss = 1.72449262, grad/param norm = 2.2451e-01, time/batch = 0.6842s	
2118/28500 (epoch 3.716), train_loss = 1.67727579, grad/param norm = 2.1197e-01, time/batch = 0.6793s	
2119/28500 (epoch 3.718), train_loss = 1.54721365, grad/param norm = 2.1128e-01, time/batch = 0.6815s	
2120/28500 (epoch 3.719), train_loss = 1.55792168, grad/param norm = 2.0576e-01, time/batch = 0.6806s	
2121/28500 (epoch 3.721), train_loss = 1.40189680, grad/param norm = 2.1008e-01, time/batch = 0.6826s	
2122/28500 (epoch 3.723), train_loss = 1.65137113, grad/param norm = 2.0564e-01, time/batch = 0.6805s	
2123/28500 (epoch 3.725), train_loss = 1.73623101, grad/param norm = 2.1397e-01, time/batch = 0.6810s	
2124/28500 (epoch 3.726), train_loss = 1.65684546, grad/param norm = 2.2363e-01, time/batch = 0.6801s	
2125/28500 (epoch 3.728), train_loss = 1.52241465, grad/param norm = 1.9941e-01, time/batch = 0.6813s	
2126/28500 (epoch 3.730), train_loss = 1.69701751, grad/param norm = 2.2256e-01, time/batch = 0.6806s	
2127/28500 (epoch 3.732), train_loss = 1.44831930, grad/param norm = 2.1170e-01, time/batch = 0.6800s	
2128/28500 (epoch 3.733), train_loss = 1.53456159, grad/param norm = 2.2792e-01, time/batch = 0.6811s	
2129/28500 (epoch 3.735), train_loss = 1.48943966, grad/param norm = 1.9343e-01, time/batch = 0.6819s	
2130/28500 (epoch 3.737), train_loss = 1.46517931, grad/param norm = 1.9192e-01, time/batch = 0.6802s	
2131/28500 (epoch 3.739), train_loss = 1.68918060, grad/param norm = 2.1938e-01, time/batch = 0.6858s	
2132/28500 (epoch 3.740), train_loss = 1.61212524, grad/param norm = 2.0229e-01, time/batch = 0.6905s	
2133/28500 (epoch 3.742), train_loss = 1.63625989, grad/param norm = 2.1339e-01, time/batch = 0.7060s	
2134/28500 (epoch 3.744), train_loss = 1.75146976, grad/param norm = 2.1270e-01, time/batch = 0.6828s	
2135/28500 (epoch 3.746), train_loss = 1.54728536, grad/param norm = 1.9590e-01, time/batch = 0.6822s	
2136/28500 (epoch 3.747), train_loss = 1.53542987, grad/param norm = 2.1116e-01, time/batch = 0.6851s	
2137/28500 (epoch 3.749), train_loss = 1.90604397, grad/param norm = 2.2768e-01, time/batch = 0.6793s	
2138/28500 (epoch 3.751), train_loss = 1.56846335, grad/param norm = 2.0350e-01, time/batch = 0.6883s	
2139/28500 (epoch 3.753), train_loss = 1.47122389, grad/param norm = 1.8486e-01, time/batch = 0.6869s	
2140/28500 (epoch 3.754), train_loss = 1.45972905, grad/param norm = 1.9347e-01, time/batch = 0.6766s	
2141/28500 (epoch 3.756), train_loss = 1.72602478, grad/param norm = 2.0612e-01, time/batch = 0.6784s	
2142/28500 (epoch 3.758), train_loss = 1.61950271, grad/param norm = 2.0595e-01, time/batch = 0.6780s	
2143/28500 (epoch 3.760), train_loss = 1.54201872, grad/param norm = 2.2200e-01, time/batch = 0.6819s	
2144/28500 (epoch 3.761), train_loss = 1.63135244, grad/param norm = 2.1289e-01, time/batch = 0.7004s	
2145/28500 (epoch 3.763), train_loss = 1.39639636, grad/param norm = 1.9300e-01, time/batch = 0.6898s	
2146/28500 (epoch 3.765), train_loss = 1.54305923, grad/param norm = 1.9311e-01, time/batch = 0.6875s	
2147/28500 (epoch 3.767), train_loss = 1.38827681, grad/param norm = 2.1244e-01, time/batch = 0.6809s	
2148/28500 (epoch 3.768), train_loss = 1.79719860, grad/param norm = 2.5203e-01, time/batch = 0.6963s	
2149/28500 (epoch 3.770), train_loss = 1.49334647, grad/param norm = 2.1717e-01, time/batch = 0.6907s	
2150/28500 (epoch 3.772), train_loss = 1.44564420, grad/param norm = 2.3540e-01, time/batch = 0.6822s	
2151/28500 (epoch 3.774), train_loss = 1.63348439, grad/param norm = 2.2057e-01, time/batch = 0.6799s	
2152/28500 (epoch 3.775), train_loss = 1.73254323, grad/param norm = 2.1839e-01, time/batch = 0.6802s	
2153/28500 (epoch 3.777), train_loss = 1.62975875, grad/param norm = 2.0593e-01, time/batch = 0.6926s	
2154/28500 (epoch 3.779), train_loss = 1.55025275, grad/param norm = 2.0761e-01, time/batch = 0.6912s	
2155/28500 (epoch 3.781), train_loss = 1.68145733, grad/param norm = 2.3046e-01, time/batch = 0.6797s	
2156/28500 (epoch 3.782), train_loss = 1.81242256, grad/param norm = 2.3438e-01, time/batch = 0.6770s	
2157/28500 (epoch 3.784), train_loss = 1.43476596, grad/param norm = 1.9033e-01, time/batch = 0.6832s	
2158/28500 (epoch 3.786), train_loss = 1.61528061, grad/param norm = 2.0280e-01, time/batch = 0.6798s	
2159/28500 (epoch 3.788), train_loss = 1.72929311, grad/param norm = 2.1135e-01, time/batch = 0.6796s	
2160/28500 (epoch 3.789), train_loss = 1.44663518, grad/param norm = 2.2221e-01, time/batch = 0.6777s	
2161/28500 (epoch 3.791), train_loss = 1.61424731, grad/param norm = 2.2204e-01, time/batch = 0.6926s	
2162/28500 (epoch 3.793), train_loss = 1.50339111, grad/param norm = 2.1895e-01, time/batch = 0.6955s	
2163/28500 (epoch 3.795), train_loss = 1.63594630, grad/param norm = 2.4937e-01, time/batch = 0.6799s	
2164/28500 (epoch 3.796), train_loss = 1.51929616, grad/param norm = 2.0145e-01, time/batch = 0.6758s	
2165/28500 (epoch 3.798), train_loss = 1.53062231, grad/param norm = 2.1401e-01, time/batch = 0.6756s	
2166/28500 (epoch 3.800), train_loss = 1.56793462, grad/param norm = 2.0920e-01, time/batch = 0.6799s	
2167/28500 (epoch 3.802), train_loss = 1.67012657, grad/param norm = 2.2770e-01, time/batch = 0.6785s	
2168/28500 (epoch 3.804), train_loss = 1.63913090, grad/param norm = 1.9666e-01, time/batch = 0.6754s	
2169/28500 (epoch 3.805), train_loss = 1.67770003, grad/param norm = 2.1643e-01, time/batch = 0.6756s	
2170/28500 (epoch 3.807), train_loss = 1.79415715, grad/param norm = 2.1201e-01, time/batch = 0.6756s	
2171/28500 (epoch 3.809), train_loss = 1.56380167, grad/param norm = 1.9569e-01, time/batch = 0.6776s	
2172/28500 (epoch 3.811), train_loss = 1.78185285, grad/param norm = 2.3721e-01, time/batch = 0.6794s	
2173/28500 (epoch 3.812), train_loss = 1.69037662, grad/param norm = 2.1108e-01, time/batch = 0.6989s	
2174/28500 (epoch 3.814), train_loss = 1.56380438, grad/param norm = 2.0585e-01, time/batch = 0.6874s	
2175/28500 (epoch 3.816), train_loss = 1.73870501, grad/param norm = 2.1854e-01, time/batch = 0.6765s	
2176/28500 (epoch 3.818), train_loss = 1.62340744, grad/param norm = 2.1990e-01, time/batch = 0.6771s	
2177/28500 (epoch 3.819), train_loss = 1.60920232, grad/param norm = 2.1252e-01, time/batch = 0.6820s	
2178/28500 (epoch 3.821), train_loss = 1.56020807, grad/param norm = 1.9996e-01, time/batch = 0.6801s	
2179/28500 (epoch 3.823), train_loss = 1.91632278, grad/param norm = 2.7277e-01, time/batch = 0.6791s	
2180/28500 (epoch 3.825), train_loss = 1.60967593, grad/param norm = 2.3298e-01, time/batch = 0.6771s	
2181/28500 (epoch 3.826), train_loss = 1.69574965, grad/param norm = 2.3822e-01, time/batch = 0.6786s	
2182/28500 (epoch 3.828), train_loss = 1.48727058, grad/param norm = 2.1462e-01, time/batch = 0.6765s	
2183/28500 (epoch 3.830), train_loss = 1.55258975, grad/param norm = 1.9920e-01, time/batch = 0.6762s	
2184/28500 (epoch 3.832), train_loss = 1.68851596, grad/param norm = 2.3073e-01, time/batch = 0.6765s	
2185/28500 (epoch 3.833), train_loss = 1.78013430, grad/param norm = 2.0772e-01, time/batch = 0.6759s	
2186/28500 (epoch 3.835), train_loss = 1.60192906, grad/param norm = 2.1272e-01, time/batch = 0.6780s	
2187/28500 (epoch 3.837), train_loss = 1.52585926, grad/param norm = 2.0801e-01, time/batch = 0.6778s	
2188/28500 (epoch 3.839), train_loss = 1.77501133, grad/param norm = 2.1938e-01, time/batch = 0.6909s	
2189/28500 (epoch 3.840), train_loss = 1.74037703, grad/param norm = 2.1136e-01, time/batch = 0.6759s	
2190/28500 (epoch 3.842), train_loss = 1.65217611, grad/param norm = 2.0884e-01, time/batch = 0.6758s	
2191/28500 (epoch 3.844), train_loss = 1.64642588, grad/param norm = 2.0572e-01, time/batch = 0.6776s	
2192/28500 (epoch 3.846), train_loss = 1.74309793, grad/param norm = 2.1468e-01, time/batch = 0.6760s	
2193/28500 (epoch 3.847), train_loss = 1.57676388, grad/param norm = 2.0158e-01, time/batch = 0.6774s	
2194/28500 (epoch 3.849), train_loss = 1.53132351, grad/param norm = 1.8701e-01, time/batch = 0.6761s	
2195/28500 (epoch 3.851), train_loss = 1.47850841, grad/param norm = 2.0202e-01, time/batch = 0.6752s	
2196/28500 (epoch 3.853), train_loss = 1.67145247, grad/param norm = 2.1662e-01, time/batch = 0.6759s	
2197/28500 (epoch 3.854), train_loss = 1.59306584, grad/param norm = 2.1035e-01, time/batch = 0.6888s	
2198/28500 (epoch 3.856), train_loss = 1.68225202, grad/param norm = 2.1656e-01, time/batch = 0.6872s	
2199/28500 (epoch 3.858), train_loss = 1.47133499, grad/param norm = 2.0106e-01, time/batch = 0.6752s	
2200/28500 (epoch 3.860), train_loss = 1.73425466, grad/param norm = 2.2375e-01, time/batch = 0.6757s	
2201/28500 (epoch 3.861), train_loss = 1.58514935, grad/param norm = 2.0728e-01, time/batch = 0.6810s	
2202/28500 (epoch 3.863), train_loss = 1.75628263, grad/param norm = 2.1355e-01, time/batch = 0.6764s	
2203/28500 (epoch 3.865), train_loss = 1.64121513, grad/param norm = 2.3342e-01, time/batch = 0.6760s	
2204/28500 (epoch 3.867), train_loss = 1.72071950, grad/param norm = 2.1466e-01, time/batch = 0.6801s	
2205/28500 (epoch 3.868), train_loss = 1.49168250, grad/param norm = 2.4946e-01, time/batch = 0.6777s	
2206/28500 (epoch 3.870), train_loss = 1.39103478, grad/param norm = 1.9945e-01, time/batch = 0.6882s	
2207/28500 (epoch 3.872), train_loss = 1.73328562, grad/param norm = 2.2557e-01, time/batch = 0.6877s	
2208/28500 (epoch 3.874), train_loss = 1.62067004, grad/param norm = 2.3105e-01, time/batch = 0.6778s	
2209/28500 (epoch 3.875), train_loss = 1.70476436, grad/param norm = 2.2060e-01, time/batch = 0.6756s	
2210/28500 (epoch 3.877), train_loss = 1.62621034, grad/param norm = 2.2230e-01, time/batch = 0.6747s	
2211/28500 (epoch 3.879), train_loss = 1.59496387, grad/param norm = 2.0367e-01, time/batch = 0.6770s	
2212/28500 (epoch 3.881), train_loss = 1.67892301, grad/param norm = 2.0798e-01, time/batch = 0.6780s	
2213/28500 (epoch 3.882), train_loss = 1.58507235, grad/param norm = 1.9986e-01, time/batch = 0.6791s	
2214/28500 (epoch 3.884), train_loss = 1.68439962, grad/param norm = 2.2026e-01, time/batch = 0.6795s	
2215/28500 (epoch 3.886), train_loss = 1.49412473, grad/param norm = 2.1350e-01, time/batch = 0.6765s	
2216/28500 (epoch 3.888), train_loss = 1.45035393, grad/param norm = 1.9614e-01, time/batch = 0.6918s	
2217/28500 (epoch 3.889), train_loss = 1.50042903, grad/param norm = 1.8541e-01, time/batch = 0.6756s	
2218/28500 (epoch 3.891), train_loss = 1.62915776, grad/param norm = 1.9392e-01, time/batch = 0.6759s	
2219/28500 (epoch 3.893), train_loss = 1.59939885, grad/param norm = 2.0899e-01, time/batch = 0.6947s	
2220/28500 (epoch 3.895), train_loss = 1.82973372, grad/param norm = 2.4038e-01, time/batch = 0.7152s	
2221/28500 (epoch 3.896), train_loss = 1.76279789, grad/param norm = 2.2039e-01, time/batch = 0.7151s	
2222/28500 (epoch 3.898), train_loss = 1.53548164, grad/param norm = 1.9756e-01, time/batch = 0.6916s	
2223/28500 (epoch 3.900), train_loss = 1.46474331, grad/param norm = 2.0749e-01, time/batch = 0.6910s	
2224/28500 (epoch 3.902), train_loss = 1.51217126, grad/param norm = 2.0582e-01, time/batch = 0.6915s	
2225/28500 (epoch 3.904), train_loss = 1.50021046, grad/param norm = 1.9567e-01, time/batch = 0.7069s	
2226/28500 (epoch 3.905), train_loss = 1.64377324, grad/param norm = 1.9257e-01, time/batch = 0.7081s	
2227/28500 (epoch 3.907), train_loss = 1.79089507, grad/param norm = 2.4032e-01, time/batch = 0.6944s	
2228/28500 (epoch 3.909), train_loss = 1.53892123, grad/param norm = 1.9895e-01, time/batch = 0.6909s	
2229/28500 (epoch 3.911), train_loss = 1.56237709, grad/param norm = 2.0656e-01, time/batch = 0.6904s	
2230/28500 (epoch 3.912), train_loss = 1.32420086, grad/param norm = 2.1579e-01, time/batch = 0.6887s	
2231/28500 (epoch 3.914), train_loss = 1.73702764, grad/param norm = 2.2272e-01, time/batch = 0.6920s	
2232/28500 (epoch 3.916), train_loss = 1.66795235, grad/param norm = 2.2013e-01, time/batch = 0.7001s	
2233/28500 (epoch 3.918), train_loss = 1.69680842, grad/param norm = 2.2589e-01, time/batch = 0.6988s	
2234/28500 (epoch 3.919), train_loss = 1.51626355, grad/param norm = 1.8967e-01, time/batch = 0.7121s	
2235/28500 (epoch 3.921), train_loss = 1.80937400, grad/param norm = 2.2784e-01, time/batch = 0.7116s	
2236/28500 (epoch 3.923), train_loss = 1.74566650, grad/param norm = 2.5364e-01, time/batch = 0.7057s	
2237/28500 (epoch 3.925), train_loss = 1.53209114, grad/param norm = 2.1705e-01, time/batch = 0.6951s	
2238/28500 (epoch 3.926), train_loss = 1.66265881, grad/param norm = 2.1455e-01, time/batch = 0.6946s	
2239/28500 (epoch 3.928), train_loss = 1.49890148, grad/param norm = 2.1063e-01, time/batch = 0.6945s	
2240/28500 (epoch 3.930), train_loss = 1.28706116, grad/param norm = 1.9048e-01, time/batch = 0.6933s	
2241/28500 (epoch 3.932), train_loss = 1.44517183, grad/param norm = 1.7436e-01, time/batch = 0.7019s	
2242/28500 (epoch 3.933), train_loss = 1.64283740, grad/param norm = 1.8757e-01, time/batch = 0.6967s	
2243/28500 (epoch 3.935), train_loss = 1.57741423, grad/param norm = 2.2450e-01, time/batch = 0.7065s	
2244/28500 (epoch 3.937), train_loss = 1.75712074, grad/param norm = 2.1736e-01, time/batch = 0.7011s	
2245/28500 (epoch 3.939), train_loss = 1.87766208, grad/param norm = 2.3382e-01, time/batch = 0.6965s	
2246/28500 (epoch 3.940), train_loss = 1.56376964, grad/param norm = 1.9466e-01, time/batch = 0.6928s	
2247/28500 (epoch 3.942), train_loss = 1.68390682, grad/param norm = 2.0483e-01, time/batch = 0.6932s	
2248/28500 (epoch 3.944), train_loss = 1.65509891, grad/param norm = 2.0223e-01, time/batch = 0.6939s	
2249/28500 (epoch 3.946), train_loss = 1.72766235, grad/param norm = 1.9493e-01, time/batch = 0.6920s	
2250/28500 (epoch 3.947), train_loss = 1.99960765, grad/param norm = 2.3715e-01, time/batch = 0.6941s	
2251/28500 (epoch 3.949), train_loss = 1.51351275, grad/param norm = 2.2854e-01, time/batch = 0.7023s	
2252/28500 (epoch 3.951), train_loss = 1.80860070, grad/param norm = 2.1732e-01, time/batch = 0.6967s	
2253/28500 (epoch 3.953), train_loss = 1.76986807, grad/param norm = 2.4745e-01, time/batch = 0.6934s	
2254/28500 (epoch 3.954), train_loss = 1.69100851, grad/param norm = 2.1044e-01, time/batch = 0.6980s	
2255/28500 (epoch 3.956), train_loss = 1.69753514, grad/param norm = 2.4885e-01, time/batch = 0.6927s	
2256/28500 (epoch 3.958), train_loss = 1.67329978, grad/param norm = 2.3309e-01, time/batch = 0.6981s	
2257/28500 (epoch 3.960), train_loss = 1.52999925, grad/param norm = 2.2825e-01, time/batch = 0.6952s	
2258/28500 (epoch 3.961), train_loss = 1.84101620, grad/param norm = 2.3035e-01, time/batch = 0.6990s	
2259/28500 (epoch 3.963), train_loss = 1.68369126, grad/param norm = 1.8604e-01, time/batch = 0.6987s	
2260/28500 (epoch 3.965), train_loss = 1.51453583, grad/param norm = 1.9311e-01, time/batch = 0.7140s	
2261/28500 (epoch 3.967), train_loss = 1.44771245, grad/param norm = 1.9629e-01, time/batch = 0.7016s	
2262/28500 (epoch 3.968), train_loss = 1.40255845, grad/param norm = 1.8934e-01, time/batch = 0.6980s	
2263/28500 (epoch 3.970), train_loss = 1.71599106, grad/param norm = 2.1953e-01, time/batch = 0.6964s	
2264/28500 (epoch 3.972), train_loss = 1.88468068, grad/param norm = 2.3711e-01, time/batch = 0.6975s	
2265/28500 (epoch 3.974), train_loss = 1.87566866, grad/param norm = 2.1471e-01, time/batch = 0.6907s	
2266/28500 (epoch 3.975), train_loss = 1.59302542, grad/param norm = 2.0805e-01, time/batch = 0.7124s	
2267/28500 (epoch 3.977), train_loss = 1.83265832, grad/param norm = 2.1465e-01, time/batch = 0.7093s	
2268/28500 (epoch 3.979), train_loss = 1.55758618, grad/param norm = 1.9943e-01, time/batch = 0.6943s	
2269/28500 (epoch 3.981), train_loss = 1.58544122, grad/param norm = 2.0918e-01, time/batch = 0.6969s	
2270/28500 (epoch 3.982), train_loss = 1.47517371, grad/param norm = 1.9429e-01, time/batch = 0.6931s	
2271/28500 (epoch 3.984), train_loss = 1.67706966, grad/param norm = 2.0477e-01, time/batch = 0.6963s	
2272/28500 (epoch 3.986), train_loss = 1.77926291, grad/param norm = 2.1927e-01, time/batch = 0.6945s	
2273/28500 (epoch 3.988), train_loss = 1.40229948, grad/param norm = 1.9870e-01, time/batch = 0.6944s	
2274/28500 (epoch 3.989), train_loss = 1.64607227, grad/param norm = 2.1489e-01, time/batch = 0.6970s	
2275/28500 (epoch 3.991), train_loss = 1.56959911, grad/param norm = 2.2396e-01, time/batch = 0.7062s	
2276/28500 (epoch 3.993), train_loss = 1.59513711, grad/param norm = 2.2122e-01, time/batch = 0.7043s	
2277/28500 (epoch 3.995), train_loss = 1.55821291, grad/param norm = 1.9383e-01, time/batch = 0.7004s	
2278/28500 (epoch 3.996), train_loss = 1.49358376, grad/param norm = 1.9845e-01, time/batch = 0.6945s	
2279/28500 (epoch 3.998), train_loss = 1.69659942, grad/param norm = 2.2717e-01, time/batch = 0.6959s	
2280/28500 (epoch 4.000), train_loss = 1.56243207, grad/param norm = 2.0050e-01, time/batch = 0.6942s	
2281/28500 (epoch 4.002), train_loss = 1.68671296, grad/param norm = 2.1425e-01, time/batch = 0.6974s	
2282/28500 (epoch 4.004), train_loss = 1.52004846, grad/param norm = 2.3036e-01, time/batch = 0.6942s	
2283/28500 (epoch 4.005), train_loss = 1.66121633, grad/param norm = 2.0783e-01, time/batch = 0.6985s	
2284/28500 (epoch 4.007), train_loss = 1.40397598, grad/param norm = 1.8273e-01, time/batch = 0.6984s	
2285/28500 (epoch 4.009), train_loss = 1.70994404, grad/param norm = 2.2379e-01, time/batch = 0.6944s	
2286/28500 (epoch 4.011), train_loss = 1.61098570, grad/param norm = 2.3546e-01, time/batch = 0.6961s	
2287/28500 (epoch 4.012), train_loss = 1.40922364, grad/param norm = 1.8205e-01, time/batch = 0.6939s	
2288/28500 (epoch 4.014), train_loss = 1.47837020, grad/param norm = 1.9782e-01, time/batch = 0.6947s	
2289/28500 (epoch 4.016), train_loss = 1.52835794, grad/param norm = 2.0284e-01, time/batch = 0.6928s	
2290/28500 (epoch 4.018), train_loss = 1.57053413, grad/param norm = 2.1986e-01, time/batch = 0.6985s	
2291/28500 (epoch 4.019), train_loss = 1.62470496, grad/param norm = 2.2765e-01, time/batch = 0.6972s	
2292/28500 (epoch 4.021), train_loss = 1.56188470, grad/param norm = 1.9179e-01, time/batch = 0.6955s	
2293/28500 (epoch 4.023), train_loss = 1.63873228, grad/param norm = 2.1214e-01, time/batch = 0.6953s	
2294/28500 (epoch 4.025), train_loss = 1.55400790, grad/param norm = 1.9617e-01, time/batch = 0.6952s	
2295/28500 (epoch 4.026), train_loss = 1.63731381, grad/param norm = 2.2014e-01, time/batch = 0.6943s	
2296/28500 (epoch 4.028), train_loss = 1.68027227, grad/param norm = 2.3018e-01, time/batch = 0.6921s	
2297/28500 (epoch 4.030), train_loss = 1.73380132, grad/param norm = 2.6167e-01, time/batch = 0.6935s	
2298/28500 (epoch 4.032), train_loss = 1.69466397, grad/param norm = 2.2643e-01, time/batch = 0.6923s	
2299/28500 (epoch 4.033), train_loss = 1.80007916, grad/param norm = 2.2422e-01, time/batch = 0.6934s	
2300/28500 (epoch 4.035), train_loss = 1.66224459, grad/param norm = 2.1856e-01, time/batch = 0.6942s	
2301/28500 (epoch 4.037), train_loss = 1.68480646, grad/param norm = 2.1259e-01, time/batch = 0.6952s	
2302/28500 (epoch 4.039), train_loss = 1.77259924, grad/param norm = 2.3086e-01, time/batch = 0.6959s	
2303/28500 (epoch 4.040), train_loss = 1.76476521, grad/param norm = 2.1213e-01, time/batch = 0.6953s	
2304/28500 (epoch 4.042), train_loss = 1.78848864, grad/param norm = 2.1950e-01, time/batch = 0.6983s	
2305/28500 (epoch 4.044), train_loss = 1.66205056, grad/param norm = 2.2559e-01, time/batch = 0.6958s	
2306/28500 (epoch 4.046), train_loss = 1.77499245, grad/param norm = 1.9701e-01, time/batch = 0.7014s	
2307/28500 (epoch 4.047), train_loss = 1.76257207, grad/param norm = 2.0940e-01, time/batch = 0.6990s	
2308/28500 (epoch 4.049), train_loss = 1.68634782, grad/param norm = 2.2610e-01, time/batch = 0.6921s	
2309/28500 (epoch 4.051), train_loss = 1.63111003, grad/param norm = 1.9203e-01, time/batch = 0.6958s	
2310/28500 (epoch 4.053), train_loss = 1.72306080, grad/param norm = 2.1133e-01, time/batch = 0.6935s	
2311/28500 (epoch 4.054), train_loss = 1.73065547, grad/param norm = 2.0066e-01, time/batch = 0.7037s	
2312/28500 (epoch 4.056), train_loss = 1.47699207, grad/param norm = 1.8999e-01, time/batch = 0.6938s	
2313/28500 (epoch 4.058), train_loss = 1.52383372, grad/param norm = 2.1370e-01, time/batch = 0.6938s	
2314/28500 (epoch 4.060), train_loss = 1.64354469, grad/param norm = 2.2671e-01, time/batch = 0.7001s	
2315/28500 (epoch 4.061), train_loss = 1.71055212, grad/param norm = 2.1813e-01, time/batch = 0.6936s	
2316/28500 (epoch 4.063), train_loss = 1.76692756, grad/param norm = 2.0266e-01, time/batch = 0.6935s	
2317/28500 (epoch 4.065), train_loss = 1.85973137, grad/param norm = 2.1285e-01, time/batch = 0.6929s	
2318/28500 (epoch 4.067), train_loss = 1.57168285, grad/param norm = 2.1424e-01, time/batch = 0.7048s	
2319/28500 (epoch 4.068), train_loss = 1.50280881, grad/param norm = 1.9045e-01, time/batch = 0.6988s	
2320/28500 (epoch 4.070), train_loss = 1.68899527, grad/param norm = 2.0431e-01, time/batch = 0.6979s	
2321/28500 (epoch 4.072), train_loss = 1.86781500, grad/param norm = 2.2117e-01, time/batch = 0.7033s	
2322/28500 (epoch 4.074), train_loss = 1.69186439, grad/param norm = 2.2143e-01, time/batch = 0.7048s	
2323/28500 (epoch 4.075), train_loss = 1.56433181, grad/param norm = 1.8619e-01, time/batch = 0.6960s	
2324/28500 (epoch 4.077), train_loss = 1.68214659, grad/param norm = 1.9738e-01, time/batch = 0.6952s	
2325/28500 (epoch 4.079), train_loss = 1.64350199, grad/param norm = 2.1779e-01, time/batch = 0.6956s	
2326/28500 (epoch 4.081), train_loss = 1.80185900, grad/param norm = 2.3455e-01, time/batch = 0.6905s	
2327/28500 (epoch 4.082), train_loss = 1.70085123, grad/param norm = 2.2195e-01, time/batch = 0.6898s	
2328/28500 (epoch 4.084), train_loss = 1.70758508, grad/param norm = 1.9495e-01, time/batch = 0.6934s	
2329/28500 (epoch 4.086), train_loss = 1.56059926, grad/param norm = 2.1737e-01, time/batch = 0.6947s	
2330/28500 (epoch 4.088), train_loss = 1.51278365, grad/param norm = 2.0542e-01, time/batch = 0.6898s	
2331/28500 (epoch 4.089), train_loss = 1.79546184, grad/param norm = 1.9696e-01, time/batch = 0.6911s	
2332/28500 (epoch 4.091), train_loss = 1.43911903, grad/param norm = 1.9940e-01, time/batch = 0.6899s	
2333/28500 (epoch 4.093), train_loss = 1.63054663, grad/param norm = 1.9522e-01, time/batch = 0.6947s	
2334/28500 (epoch 4.095), train_loss = 1.59312040, grad/param norm = 2.1335e-01, time/batch = 0.6937s	
2335/28500 (epoch 4.096), train_loss = 1.77569204, grad/param norm = 2.1244e-01, time/batch = 0.6897s	
2336/28500 (epoch 4.098), train_loss = 1.81980887, grad/param norm = 2.3077e-01, time/batch = 0.6904s	
2337/28500 (epoch 4.100), train_loss = 1.52152017, grad/param norm = 2.0685e-01, time/batch = 0.6893s	
2338/28500 (epoch 4.102), train_loss = 1.81123590, grad/param norm = 1.9939e-01, time/batch = 0.6896s	
2339/28500 (epoch 4.104), train_loss = 1.63695205, grad/param norm = 2.0847e-01, time/batch = 0.6965s	
2340/28500 (epoch 4.105), train_loss = 1.64858815, grad/param norm = 2.1937e-01, time/batch = 0.6986s	
2341/28500 (epoch 4.107), train_loss = 1.56528692, grad/param norm = 2.3719e-01, time/batch = 0.6972s	
2342/28500 (epoch 4.109), train_loss = 1.51129206, grad/param norm = 2.0466e-01, time/batch = 0.6922s	
2343/28500 (epoch 4.111), train_loss = 1.62239215, grad/param norm = 2.0897e-01, time/batch = 0.6940s	
2344/28500 (epoch 4.112), train_loss = 1.71248423, grad/param norm = 2.0132e-01, time/batch = 0.6912s	
2345/28500 (epoch 4.114), train_loss = 1.60772524, grad/param norm = 2.1297e-01, time/batch = 0.6961s	
2346/28500 (epoch 4.116), train_loss = 1.81348784, grad/param norm = 2.2282e-01, time/batch = 0.6939s	
2347/28500 (epoch 4.118), train_loss = 1.47630884, grad/param norm = 1.9945e-01, time/batch = 0.6927s	
2348/28500 (epoch 4.119), train_loss = 1.69942569, grad/param norm = 2.1851e-01, time/batch = 0.6890s	
2349/28500 (epoch 4.121), train_loss = 1.83276571, grad/param norm = 2.1560e-01, time/batch = 0.6890s	
2350/28500 (epoch 4.123), train_loss = 1.72049187, grad/param norm = 2.4762e-01, time/batch = 0.6908s	
2351/28500 (epoch 4.125), train_loss = 1.72239746, grad/param norm = 2.1295e-01, time/batch = 0.6924s	
2352/28500 (epoch 4.126), train_loss = 1.64898419, grad/param norm = 2.0616e-01, time/batch = 0.6896s	
2353/28500 (epoch 4.128), train_loss = 1.55953009, grad/param norm = 2.4219e-01, time/batch = 0.6896s	
2354/28500 (epoch 4.130), train_loss = 1.62685707, grad/param norm = 2.1567e-01, time/batch = 0.6892s	
2355/28500 (epoch 4.132), train_loss = 1.70569257, grad/param norm = 2.2142e-01, time/batch = 0.6912s	
2356/28500 (epoch 4.133), train_loss = 1.58668112, grad/param norm = 1.9787e-01, time/batch = 0.6905s	
2357/28500 (epoch 4.135), train_loss = 1.63525049, grad/param norm = 1.8957e-01, time/batch = 0.6897s	
2358/28500 (epoch 4.137), train_loss = 1.57720673, grad/param norm = 2.1827e-01, time/batch = 0.6891s	
2359/28500 (epoch 4.139), train_loss = 1.57218712, grad/param norm = 1.7850e-01, time/batch = 0.6906s	
2360/28500 (epoch 4.140), train_loss = 1.60102305, grad/param norm = 1.9220e-01, time/batch = 0.6913s	
2361/28500 (epoch 4.142), train_loss = 1.67497826, grad/param norm = 2.1462e-01, time/batch = 0.6918s	
2362/28500 (epoch 4.144), train_loss = 1.51252502, grad/param norm = 1.9661e-01, time/batch = 0.6917s	
2363/28500 (epoch 4.146), train_loss = 1.52115852, grad/param norm = 2.0087e-01, time/batch = 0.6906s	
2364/28500 (epoch 4.147), train_loss = 1.44551224, grad/param norm = 1.9350e-01, time/batch = 0.6900s	
2365/28500 (epoch 4.149), train_loss = 1.49672405, grad/param norm = 1.9587e-01, time/batch = 0.6898s	
2366/28500 (epoch 4.151), train_loss = 1.48162785, grad/param norm = 2.1166e-01, time/batch = 0.6916s	
2367/28500 (epoch 4.153), train_loss = 1.55634914, grad/param norm = 2.1247e-01, time/batch = 0.6965s	
2368/28500 (epoch 4.154), train_loss = 1.52405072, grad/param norm = 2.0809e-01, time/batch = 0.6988s	
2369/28500 (epoch 4.156), train_loss = 1.82896318, grad/param norm = 2.2409e-01, time/batch = 0.6933s	
2370/28500 (epoch 4.158), train_loss = 1.55532143, grad/param norm = 1.9966e-01, time/batch = 0.6955s	
2371/28500 (epoch 4.160), train_loss = 1.50373672, grad/param norm = 2.0715e-01, time/batch = 0.6945s	
2372/28500 (epoch 4.161), train_loss = 1.70840241, grad/param norm = 2.4101e-01, time/batch = 0.6926s	
2373/28500 (epoch 4.163), train_loss = 1.53399735, grad/param norm = 2.2263e-01, time/batch = 0.6907s	
2374/28500 (epoch 4.165), train_loss = 1.82882593, grad/param norm = 2.1158e-01, time/batch = 0.6958s	
2375/28500 (epoch 4.167), train_loss = 1.88357283, grad/param norm = 2.1701e-01, time/batch = 0.6916s	
2376/28500 (epoch 4.168), train_loss = 1.70713611, grad/param norm = 2.2461e-01, time/batch = 0.6916s	
2377/28500 (epoch 4.170), train_loss = 1.76660586, grad/param norm = 2.2668e-01, time/batch = 0.6925s	
2378/28500 (epoch 4.172), train_loss = 1.59151990, grad/param norm = 2.3319e-01, time/batch = 0.6892s	
2379/28500 (epoch 4.174), train_loss = 1.84487289, grad/param norm = 2.0696e-01, time/batch = 0.6924s	
2380/28500 (epoch 4.175), train_loss = 1.56571239, grad/param norm = 1.9397e-01, time/batch = 0.6919s	
2381/28500 (epoch 4.177), train_loss = 1.71366307, grad/param norm = 2.1010e-01, time/batch = 0.6908s	
2382/28500 (epoch 4.179), train_loss = 1.57623190, grad/param norm = 2.1576e-01, time/batch = 0.6895s	
2383/28500 (epoch 4.181), train_loss = 1.73369084, grad/param norm = 2.1395e-01, time/batch = 0.6895s	
2384/28500 (epoch 4.182), train_loss = 1.62730173, grad/param norm = 2.2818e-01, time/batch = 0.6892s	
2385/28500 (epoch 4.184), train_loss = 1.85409486, grad/param norm = 2.2667e-01, time/batch = 0.6911s	
2386/28500 (epoch 4.186), train_loss = 1.77348357, grad/param norm = 2.4073e-01, time/batch = 0.6981s	
2387/28500 (epoch 4.188), train_loss = 1.58568458, grad/param norm = 2.0078e-01, time/batch = 0.6954s	
2388/28500 (epoch 4.189), train_loss = 1.72856759, grad/param norm = 2.1025e-01, time/batch = 0.6894s	
2389/28500 (epoch 4.191), train_loss = 1.91231843, grad/param norm = 2.1772e-01, time/batch = 0.6937s	
2390/28500 (epoch 4.193), train_loss = 1.71886141, grad/param norm = 2.1651e-01, time/batch = 0.6943s	
2391/28500 (epoch 4.195), train_loss = 1.73521761, grad/param norm = 2.2039e-01, time/batch = 0.7014s	
2392/28500 (epoch 4.196), train_loss = 1.66562514, grad/param norm = 2.1662e-01, time/batch = 0.7054s	
2393/28500 (epoch 4.198), train_loss = 1.64060337, grad/param norm = 2.2378e-01, time/batch = 0.6976s	
2394/28500 (epoch 4.200), train_loss = 1.59545966, grad/param norm = 1.7945e-01, time/batch = 0.6999s	
2395/28500 (epoch 4.202), train_loss = 1.68833663, grad/param norm = 2.2576e-01, time/batch = 0.6946s	
2396/28500 (epoch 4.204), train_loss = 1.45205952, grad/param norm = 1.7925e-01, time/batch = 0.6929s	
2397/28500 (epoch 4.205), train_loss = 1.54823671, grad/param norm = 2.0129e-01, time/batch = 0.6981s	
2398/28500 (epoch 4.207), train_loss = 1.65558882, grad/param norm = 2.2203e-01, time/batch = 0.7085s	
2399/28500 (epoch 4.209), train_loss = 1.62216273, grad/param norm = 2.2591e-01, time/batch = 0.6945s	
2400/28500 (epoch 4.211), train_loss = 1.47211718, grad/param norm = 1.9373e-01, time/batch = 0.6940s	
2401/28500 (epoch 4.212), train_loss = 1.48964139, grad/param norm = 1.9819e-01, time/batch = 0.6997s	
2402/28500 (epoch 4.214), train_loss = 1.70080192, grad/param norm = 2.2392e-01, time/batch = 0.6937s	
2403/28500 (epoch 4.216), train_loss = 1.47608825, grad/param norm = 1.8559e-01, time/batch = 0.7107s	
2404/28500 (epoch 4.218), train_loss = 1.65277113, grad/param norm = 1.8809e-01, time/batch = 0.7090s	
2405/28500 (epoch 4.219), train_loss = 1.59655872, grad/param norm = 2.0174e-01, time/batch = 0.6971s	
2406/28500 (epoch 4.221), train_loss = 1.51382213, grad/param norm = 1.9704e-01, time/batch = 0.6945s	
2407/28500 (epoch 4.223), train_loss = 1.76239033, grad/param norm = 2.4155e-01, time/batch = 0.6925s	
2408/28500 (epoch 4.225), train_loss = 1.80393007, grad/param norm = 2.3385e-01, time/batch = 0.6923s	
2409/28500 (epoch 4.226), train_loss = 1.64970357, grad/param norm = 2.2377e-01, time/batch = 0.6926s	
2410/28500 (epoch 4.228), train_loss = 1.63560653, grad/param norm = 2.0458e-01, time/batch = 0.6925s	
2411/28500 (epoch 4.230), train_loss = 1.63966664, grad/param norm = 2.0438e-01, time/batch = 0.6948s	
2412/28500 (epoch 4.232), train_loss = 1.68059528, grad/param norm = 1.9835e-01, time/batch = 0.6934s	
2413/28500 (epoch 4.233), train_loss = 1.65747022, grad/param norm = 2.1128e-01, time/batch = 0.6916s	
2414/28500 (epoch 4.235), train_loss = 1.52088745, grad/param norm = 1.9116e-01, time/batch = 0.6937s	
2415/28500 (epoch 4.237), train_loss = 1.44386876, grad/param norm = 1.7182e-01, time/batch = 0.6914s	
2416/28500 (epoch 4.239), train_loss = 1.53305054, grad/param norm = 1.9378e-01, time/batch = 0.6917s	
2417/28500 (epoch 4.240), train_loss = 1.45698141, grad/param norm = 1.9117e-01, time/batch = 0.6908s	
2418/28500 (epoch 4.242), train_loss = 1.67592188, grad/param norm = 2.0608e-01, time/batch = 0.6919s	
2419/28500 (epoch 4.244), train_loss = 1.72634568, grad/param norm = 2.0739e-01, time/batch = 0.6921s	
2420/28500 (epoch 4.246), train_loss = 1.67386883, grad/param norm = 2.0530e-01, time/batch = 0.6927s	
2421/28500 (epoch 4.247), train_loss = 1.81344629, grad/param norm = 2.1198e-01, time/batch = 0.6973s	
2422/28500 (epoch 4.249), train_loss = 1.66022837, grad/param norm = 2.4084e-01, time/batch = 0.6944s	
2423/28500 (epoch 4.251), train_loss = 1.40563789, grad/param norm = 1.8337e-01, time/batch = 0.6936s	
2424/28500 (epoch 4.253), train_loss = 1.73752305, grad/param norm = 2.0365e-01, time/batch = 0.6910s	
2425/28500 (epoch 4.254), train_loss = 1.70228315, grad/param norm = 2.0823e-01, time/batch = 0.6937s	
2426/28500 (epoch 4.256), train_loss = 1.53826396, grad/param norm = 1.9939e-01, time/batch = 0.6927s	
2427/28500 (epoch 4.258), train_loss = 1.59467903, grad/param norm = 2.2048e-01, time/batch = 0.6932s	
2428/28500 (epoch 4.260), train_loss = 1.57317943, grad/param norm = 1.9554e-01, time/batch = 0.6927s	
2429/28500 (epoch 4.261), train_loss = 1.54106244, grad/param norm = 2.0068e-01, time/batch = 0.6927s	
2430/28500 (epoch 4.263), train_loss = 1.80074217, grad/param norm = 2.3032e-01, time/batch = 0.6952s	
2431/28500 (epoch 4.265), train_loss = 1.68254971, grad/param norm = 2.2159e-01, time/batch = 0.7026s	
2432/28500 (epoch 4.267), train_loss = 1.77020430, grad/param norm = 2.3019e-01, time/batch = 0.6937s	
2433/28500 (epoch 4.268), train_loss = 1.70308784, grad/param norm = 2.1988e-01, time/batch = 0.6915s	
2434/28500 (epoch 4.270), train_loss = 1.57462239, grad/param norm = 1.9536e-01, time/batch = 0.6948s	
2435/28500 (epoch 4.272), train_loss = 1.60754582, grad/param norm = 2.2583e-01, time/batch = 0.6940s	
2436/28500 (epoch 4.274), train_loss = 1.81028581, grad/param norm = 2.1924e-01, time/batch = 0.6943s	
2437/28500 (epoch 4.275), train_loss = 1.69960657, grad/param norm = 1.9502e-01, time/batch = 0.6978s	
2438/28500 (epoch 4.277), train_loss = 1.54595937, grad/param norm = 1.9629e-01, time/batch = 0.6928s	
2439/28500 (epoch 4.279), train_loss = 1.66041171, grad/param norm = 2.1331e-01, time/batch = 0.6924s	
2440/28500 (epoch 4.281), train_loss = 1.66442515, grad/param norm = 2.0134e-01, time/batch = 0.6923s	
2441/28500 (epoch 4.282), train_loss = 1.51208708, grad/param norm = 2.0005e-01, time/batch = 0.6950s	
2442/28500 (epoch 4.284), train_loss = 1.64745188, grad/param norm = 2.0308e-01, time/batch = 0.6932s	
2443/28500 (epoch 4.286), train_loss = 1.76384167, grad/param norm = 2.2855e-01, time/batch = 0.6933s	
2444/28500 (epoch 4.288), train_loss = 1.64770661, grad/param norm = 2.0688e-01, time/batch = 0.6913s	
2445/28500 (epoch 4.289), train_loss = 1.77634005, grad/param norm = 1.9925e-01, time/batch = 0.6924s	
2446/28500 (epoch 4.291), train_loss = 1.55066378, grad/param norm = 1.9989e-01, time/batch = 0.6922s	
2447/28500 (epoch 4.293), train_loss = 1.54373841, grad/param norm = 2.0803e-01, time/batch = 0.6922s	
2448/28500 (epoch 4.295), train_loss = 1.53321709, grad/param norm = 1.9996e-01, time/batch = 0.6939s	
2449/28500 (epoch 4.296), train_loss = 1.47522542, grad/param norm = 1.8900e-01, time/batch = 0.6945s	
2450/28500 (epoch 4.298), train_loss = 1.64962923, grad/param norm = 2.1119e-01, time/batch = 0.6946s	
2451/28500 (epoch 4.300), train_loss = 1.50390661, grad/param norm = 1.8980e-01, time/batch = 0.6979s	
2452/28500 (epoch 4.302), train_loss = 1.46483035, grad/param norm = 1.9258e-01, time/batch = 0.6893s	
2453/28500 (epoch 4.304), train_loss = 1.55873891, grad/param norm = 1.7430e-01, time/batch = 0.6910s	
2454/28500 (epoch 4.305), train_loss = 1.68452958, grad/param norm = 2.0509e-01, time/batch = 0.6932s	
2455/28500 (epoch 4.307), train_loss = 1.70204236, grad/param norm = 2.4696e-01, time/batch = 0.6929s	
2456/28500 (epoch 4.309), train_loss = 1.71589943, grad/param norm = 2.2913e-01, time/batch = 0.6937s	
2457/28500 (epoch 4.311), train_loss = 1.62279782, grad/param norm = 2.5584e-01, time/batch = 0.6940s	
2458/28500 (epoch 4.312), train_loss = 1.48797853, grad/param norm = 1.8801e-01, time/batch = 0.6935s	
2459/28500 (epoch 4.314), train_loss = 1.65744250, grad/param norm = 2.2411e-01, time/batch = 0.6918s	
2460/28500 (epoch 4.316), train_loss = 1.61035148, grad/param norm = 1.9029e-01, time/batch = 0.6936s	
2461/28500 (epoch 4.318), train_loss = 1.65633671, grad/param norm = 2.3379e-01, time/batch = 0.6956s	
2462/28500 (epoch 4.319), train_loss = 1.57889260, grad/param norm = 2.1746e-01, time/batch = 0.6919s	
2463/28500 (epoch 4.321), train_loss = 1.68653499, grad/param norm = 2.0813e-01, time/batch = 0.6933s	
2464/28500 (epoch 4.323), train_loss = 1.58369030, grad/param norm = 2.0603e-01, time/batch = 0.6911s	
2465/28500 (epoch 4.325), train_loss = 1.81529290, grad/param norm = 1.9896e-01, time/batch = 0.6932s	
2466/28500 (epoch 4.326), train_loss = 1.73922760, grad/param norm = 2.3564e-01, time/batch = 0.6948s	
2467/28500 (epoch 4.328), train_loss = 1.38826289, grad/param norm = 2.0534e-01, time/batch = 0.6929s	
2468/28500 (epoch 4.330), train_loss = 1.53866144, grad/param norm = 1.9716e-01, time/batch = 0.6929s	
2469/28500 (epoch 4.332), train_loss = 1.54638856, grad/param norm = 1.8742e-01, time/batch = 0.6894s	
2470/28500 (epoch 4.333), train_loss = 1.43382642, grad/param norm = 1.9435e-01, time/batch = 0.6886s	
2471/28500 (epoch 4.335), train_loss = 1.45983302, grad/param norm = 1.8868e-01, time/batch = 0.6929s	
2472/28500 (epoch 4.337), train_loss = 1.61302567, grad/param norm = 2.1233e-01, time/batch = 0.6915s	
2473/28500 (epoch 4.339), train_loss = 1.55478450, grad/param norm = 2.1081e-01, time/batch = 0.6892s	
2474/28500 (epoch 4.340), train_loss = 1.70942619, grad/param norm = 2.2412e-01, time/batch = 0.6889s	
2475/28500 (epoch 4.342), train_loss = 1.54965054, grad/param norm = 2.2851e-01, time/batch = 0.6890s	
2476/28500 (epoch 4.344), train_loss = 1.53465476, grad/param norm = 2.2554e-01, time/batch = 0.6912s	
2477/28500 (epoch 4.346), train_loss = 1.27861675, grad/param norm = 1.9772e-01, time/batch = 0.6922s	
2478/28500 (epoch 4.347), train_loss = 1.60355582, grad/param norm = 2.1214e-01, time/batch = 0.6947s	
2479/28500 (epoch 4.349), train_loss = 1.48017513, grad/param norm = 1.7963e-01, time/batch = 0.7006s	
2480/28500 (epoch 4.351), train_loss = 1.44480098, grad/param norm = 1.8065e-01, time/batch = 0.6890s	
2481/28500 (epoch 4.353), train_loss = 1.69127132, grad/param norm = 2.0216e-01, time/batch = 0.6922s	
2482/28500 (epoch 4.354), train_loss = 1.49194059, grad/param norm = 2.0904e-01, time/batch = 0.6927s	
2483/28500 (epoch 4.356), train_loss = 1.49334687, grad/param norm = 1.7946e-01, time/batch = 0.6886s	
2484/28500 (epoch 4.358), train_loss = 1.64534799, grad/param norm = 1.7999e-01, time/batch = 0.6888s	
2485/28500 (epoch 4.360), train_loss = 1.61005007, grad/param norm = 2.1968e-01, time/batch = 0.6938s	
2486/28500 (epoch 4.361), train_loss = 1.56494630, grad/param norm = 1.9568e-01, time/batch = 0.7046s	
2487/28500 (epoch 4.363), train_loss = 1.47964050, grad/param norm = 1.9370e-01, time/batch = 0.6898s	
2488/28500 (epoch 4.365), train_loss = 1.53921772, grad/param norm = 2.0398e-01, time/batch = 0.6906s	
2489/28500 (epoch 4.367), train_loss = 1.59344072, grad/param norm = 2.1221e-01, time/batch = 0.6911s	
2490/28500 (epoch 4.368), train_loss = 1.54976043, grad/param norm = 1.9248e-01, time/batch = 0.6889s	
2491/28500 (epoch 4.370), train_loss = 1.63662633, grad/param norm = 2.1082e-01, time/batch = 0.6923s	
2492/28500 (epoch 4.372), train_loss = 1.47216733, grad/param norm = 2.1063e-01, time/batch = 0.6946s	
2493/28500 (epoch 4.374), train_loss = 1.69717105, grad/param norm = 2.2285e-01, time/batch = 0.6927s	
2494/28500 (epoch 4.375), train_loss = 1.76241583, grad/param norm = 2.1746e-01, time/batch = 0.6893s	
2495/28500 (epoch 4.377), train_loss = 1.55904605, grad/param norm = 2.0375e-01, time/batch = 0.6893s	
2496/28500 (epoch 4.379), train_loss = 1.37585982, grad/param norm = 1.9913e-01, time/batch = 0.6886s	
2497/28500 (epoch 4.381), train_loss = 1.51129117, grad/param norm = 1.8319e-01, time/batch = 0.6898s	
2498/28500 (epoch 4.382), train_loss = 1.56790928, grad/param norm = 2.1954e-01, time/batch = 0.6893s	
2499/28500 (epoch 4.384), train_loss = 1.46353791, grad/param norm = 1.9454e-01, time/batch = 0.6889s	
2500/28500 (epoch 4.386), train_loss = 1.45223423, grad/param norm = 2.1227e-01, time/batch = 0.6888s	
2501/28500 (epoch 4.388), train_loss = 1.72836776, grad/param norm = 2.0767e-01, time/batch = 0.6918s	
2502/28500 (epoch 4.389), train_loss = 1.55426724, grad/param norm = 1.9371e-01, time/batch = 0.6916s	
2503/28500 (epoch 4.391), train_loss = 1.50806936, grad/param norm = 1.8561e-01, time/batch = 0.6906s	
2504/28500 (epoch 4.393), train_loss = 1.42746152, grad/param norm = 1.9173e-01, time/batch = 0.6919s	
2505/28500 (epoch 4.395), train_loss = 1.79364346, grad/param norm = 2.0814e-01, time/batch = 0.6891s	
2506/28500 (epoch 4.396), train_loss = 1.67232510, grad/param norm = 2.0519e-01, time/batch = 0.6894s	
2507/28500 (epoch 4.398), train_loss = 1.47073185, grad/param norm = 2.1638e-01, time/batch = 0.6889s	
2508/28500 (epoch 4.400), train_loss = 1.69972741, grad/param norm = 2.3894e-01, time/batch = 0.6902s	
2509/28500 (epoch 4.402), train_loss = 1.56534081, grad/param norm = 2.2337e-01, time/batch = 0.7053s	
2510/28500 (epoch 4.404), train_loss = 1.69891570, grad/param norm = 2.0773e-01, time/batch = 0.6946s	
2511/28500 (epoch 4.405), train_loss = 1.64889766, grad/param norm = 1.9304e-01, time/batch = 0.6952s	
2512/28500 (epoch 4.407), train_loss = 1.63682354, grad/param norm = 1.9917e-01, time/batch = 0.6960s	
2513/28500 (epoch 4.409), train_loss = 1.62862414, grad/param norm = 2.0481e-01, time/batch = 0.6910s	
2514/28500 (epoch 4.411), train_loss = 1.64554880, grad/param norm = 1.9048e-01, time/batch = 0.6944s	
2515/28500 (epoch 4.412), train_loss = 1.76024503, grad/param norm = 2.1267e-01, time/batch = 0.6930s	
2516/28500 (epoch 4.414), train_loss = 1.58801685, grad/param norm = 1.9415e-01, time/batch = 0.6970s	
2517/28500 (epoch 4.416), train_loss = 1.51599954, grad/param norm = 2.0291e-01, time/batch = 0.6924s	
2518/28500 (epoch 4.418), train_loss = 1.63892213, grad/param norm = 1.9662e-01, time/batch = 0.6928s	
2519/28500 (epoch 4.419), train_loss = 1.74330854, grad/param norm = 2.2075e-01, time/batch = 0.6932s	
2520/28500 (epoch 4.421), train_loss = 1.69239848, grad/param norm = 2.0789e-01, time/batch = 0.6943s	
2521/28500 (epoch 4.423), train_loss = 1.83867523, grad/param norm = 2.3704e-01, time/batch = 0.6957s	
2522/28500 (epoch 4.425), train_loss = 1.67046403, grad/param norm = 2.2312e-01, time/batch = 0.6932s	
2523/28500 (epoch 4.426), train_loss = 1.64516482, grad/param norm = 2.1847e-01, time/batch = 0.6938s	
2524/28500 (epoch 4.428), train_loss = 1.85820063, grad/param norm = 2.2860e-01, time/batch = 0.6910s	
2525/28500 (epoch 4.430), train_loss = 1.65961837, grad/param norm = 2.0161e-01, time/batch = 0.6927s	
2526/28500 (epoch 4.432), train_loss = 1.70430979, grad/param norm = 2.4296e-01, time/batch = 0.6928s	
2527/28500 (epoch 4.433), train_loss = 1.64414167, grad/param norm = 2.1057e-01, time/batch = 0.6935s	
2528/28500 (epoch 4.435), train_loss = 1.57151512, grad/param norm = 2.1231e-01, time/batch = 0.6958s	
2529/28500 (epoch 4.437), train_loss = 1.41864051, grad/param norm = 1.7166e-01, time/batch = 0.6931s	
2530/28500 (epoch 4.439), train_loss = 1.47265283, grad/param norm = 1.8743e-01, time/batch = 0.6929s	
2531/28500 (epoch 4.440), train_loss = 1.63753120, grad/param norm = 1.8578e-01, time/batch = 0.6962s	
2532/28500 (epoch 4.442), train_loss = 1.50457641, grad/param norm = 2.0711e-01, time/batch = 0.6935s	
2533/28500 (epoch 4.444), train_loss = 1.43419509, grad/param norm = 1.9559e-01, time/batch = 0.6930s	
2534/28500 (epoch 4.446), train_loss = 1.36989825, grad/param norm = 1.9955e-01, time/batch = 0.6939s	
2535/28500 (epoch 4.447), train_loss = 1.49660420, grad/param norm = 1.9218e-01, time/batch = 0.6955s	
2536/28500 (epoch 4.449), train_loss = 1.50977350, grad/param norm = 2.0159e-01, time/batch = 0.7013s	
2537/28500 (epoch 4.451), train_loss = 1.56948849, grad/param norm = 1.9369e-01, time/batch = 0.6926s	
2538/28500 (epoch 4.453), train_loss = 1.59726799, grad/param norm = 2.1188e-01, time/batch = 0.6928s	
2539/28500 (epoch 4.454), train_loss = 1.48811591, grad/param norm = 2.0636e-01, time/batch = 0.6932s	
2540/28500 (epoch 4.456), train_loss = 1.66241550, grad/param norm = 2.2294e-01, time/batch = 0.6938s	
2541/28500 (epoch 4.458), train_loss = 1.52434062, grad/param norm = 2.0840e-01, time/batch = 0.6911s	
2542/28500 (epoch 4.460), train_loss = 1.68153666, grad/param norm = 1.9656e-01, time/batch = 0.6896s	
2543/28500 (epoch 4.461), train_loss = 1.55017798, grad/param norm = 2.1150e-01, time/batch = 0.6896s	
2544/28500 (epoch 4.463), train_loss = 1.44419462, grad/param norm = 1.8447e-01, time/batch = 0.6888s	
2545/28500 (epoch 4.465), train_loss = 1.38511556, grad/param norm = 2.0550e-01, time/batch = 0.6893s	
2546/28500 (epoch 4.467), train_loss = 1.66046172, grad/param norm = 2.1023e-01, time/batch = 0.6886s	
2547/28500 (epoch 4.468), train_loss = 1.37376054, grad/param norm = 1.6063e-01, time/batch = 0.6896s	
2548/28500 (epoch 4.470), train_loss = 1.60772098, grad/param norm = 2.2012e-01, time/batch = 0.6897s	
2549/28500 (epoch 4.472), train_loss = 1.51444016, grad/param norm = 1.8650e-01, time/batch = 0.6885s	
2550/28500 (epoch 4.474), train_loss = 1.80303020, grad/param norm = 2.2446e-01, time/batch = 0.6893s	
2551/28500 (epoch 4.475), train_loss = 1.54266734, grad/param norm = 2.1976e-01, time/batch = 0.6908s	
2552/28500 (epoch 4.477), train_loss = 1.53164516, grad/param norm = 1.9963e-01, time/batch = 0.6907s	
2553/28500 (epoch 4.479), train_loss = 1.57715757, grad/param norm = 1.9259e-01, time/batch = 0.6954s	
2554/28500 (epoch 4.481), train_loss = 1.58935511, grad/param norm = 2.2259e-01, time/batch = 0.6969s	
2555/28500 (epoch 4.482), train_loss = 1.48414853, grad/param norm = 2.0353e-01, time/batch = 0.7100s	
2556/28500 (epoch 4.484), train_loss = 1.48823831, grad/param norm = 2.2175e-01, time/batch = 0.7104s	
2557/28500 (epoch 4.486), train_loss = 1.48485655, grad/param norm = 2.0382e-01, time/batch = 0.6986s	
2558/28500 (epoch 4.488), train_loss = 1.53425224, grad/param norm = 2.0486e-01, time/batch = 0.7002s	
2559/28500 (epoch 4.489), train_loss = 1.65282979, grad/param norm = 2.2063e-01, time/batch = 0.6969s	
2560/28500 (epoch 4.491), train_loss = 1.51771182, grad/param norm = 2.0983e-01, time/batch = 0.6943s	
2561/28500 (epoch 4.493), train_loss = 1.45633355, grad/param norm = 1.7719e-01, time/batch = 0.6968s	
2562/28500 (epoch 4.495), train_loss = 1.54662287, grad/param norm = 2.0168e-01, time/batch = 0.6943s	
2563/28500 (epoch 4.496), train_loss = 1.61566827, grad/param norm = 2.1850e-01, time/batch = 0.6980s	
2564/28500 (epoch 4.498), train_loss = 1.63734342, grad/param norm = 2.1800e-01, time/batch = 0.7559s	
2565/28500 (epoch 4.500), train_loss = 1.59509788, grad/param norm = 2.1097e-01, time/batch = 1.4171s	
2566/28500 (epoch 4.502), train_loss = 1.63636796, grad/param norm = 2.0354e-01, time/batch = 0.7105s	
2567/28500 (epoch 4.504), train_loss = 1.63242744, grad/param norm = 1.9121e-01, time/batch = 0.7049s	
2568/28500 (epoch 4.505), train_loss = 1.49680720, grad/param norm = 1.8426e-01, time/batch = 0.7020s	
2569/28500 (epoch 4.507), train_loss = 1.77424477, grad/param norm = 2.2939e-01, time/batch = 0.7011s	
2570/28500 (epoch 4.509), train_loss = 1.56791200, grad/param norm = 2.2587e-01, time/batch = 0.7008s	
2571/28500 (epoch 4.511), train_loss = 1.62933394, grad/param norm = 2.0527e-01, time/batch = 0.7437s	
2572/28500 (epoch 4.512), train_loss = 1.53223836, grad/param norm = 1.8879e-01, time/batch = 0.6910s	
2573/28500 (epoch 4.514), train_loss = 1.42498119, grad/param norm = 1.9335e-01, time/batch = 0.6957s	
2574/28500 (epoch 4.516), train_loss = 1.45545704, grad/param norm = 1.8172e-01, time/batch = 0.6975s	
2575/28500 (epoch 4.518), train_loss = 1.52571350, grad/param norm = 1.8683e-01, time/batch = 0.6927s	
2576/28500 (epoch 4.519), train_loss = 1.64839204, grad/param norm = 2.1409e-01, time/batch = 0.7190s	
2577/28500 (epoch 4.521), train_loss = 1.76168376, grad/param norm = 2.0940e-01, time/batch = 0.7119s	
2578/28500 (epoch 4.523), train_loss = 1.67163505, grad/param norm = 2.2226e-01, time/batch = 0.6936s	
2579/28500 (epoch 4.525), train_loss = 1.72612126, grad/param norm = 2.0705e-01, time/batch = 0.6887s	
2580/28500 (epoch 4.526), train_loss = 1.58468901, grad/param norm = 1.9224e-01, time/batch = 0.7030s	
2581/28500 (epoch 4.528), train_loss = 1.68059951, grad/param norm = 2.2459e-01, time/batch = 0.7100s	
2582/28500 (epoch 4.530), train_loss = 1.69765636, grad/param norm = 1.9447e-01, time/batch = 0.6934s	
2583/28500 (epoch 4.532), train_loss = 1.51600681, grad/param norm = 1.9273e-01, time/batch = 0.6907s	
2584/28500 (epoch 4.533), train_loss = 1.71713234, grad/param norm = 2.0411e-01, time/batch = 0.6904s	
2585/28500 (epoch 4.535), train_loss = 1.41017542, grad/param norm = 1.8961e-01, time/batch = 0.6903s	
2586/28500 (epoch 4.537), train_loss = 1.35227286, grad/param norm = 1.8103e-01, time/batch = 0.6887s	
2587/28500 (epoch 4.539), train_loss = 1.47391209, grad/param norm = 1.9300e-01, time/batch = 0.6886s	
2588/28500 (epoch 4.540), train_loss = 1.60400904, grad/param norm = 2.0583e-01, time/batch = 0.6883s	
2589/28500 (epoch 4.542), train_loss = 1.82571443, grad/param norm = 2.4510e-01, time/batch = 0.6891s	
2590/28500 (epoch 4.544), train_loss = 1.70361985, grad/param norm = 1.9976e-01, time/batch = 0.7031s	
2591/28500 (epoch 4.546), train_loss = 1.62943157, grad/param norm = 2.1932e-01, time/batch = 0.6932s	
2592/28500 (epoch 4.547), train_loss = 1.61565956, grad/param norm = 2.0165e-01, time/batch = 0.6888s	
2593/28500 (epoch 4.549), train_loss = 1.40834933, grad/param norm = 1.8170e-01, time/batch = 0.6892s	
2594/28500 (epoch 4.551), train_loss = 1.75991410, grad/param norm = 2.1940e-01, time/batch = 0.6924s	
2595/28500 (epoch 4.553), train_loss = 1.80610019, grad/param norm = 2.0805e-01, time/batch = 0.6882s	
2596/28500 (epoch 4.554), train_loss = 1.53889115, grad/param norm = 1.8598e-01, time/batch = 0.6886s	
2597/28500 (epoch 4.556), train_loss = 1.61743025, grad/param norm = 2.0325e-01, time/batch = 0.6890s	
2598/28500 (epoch 4.558), train_loss = 1.60386157, grad/param norm = 1.9419e-01, time/batch = 0.6902s	
2599/28500 (epoch 4.560), train_loss = 1.63717519, grad/param norm = 2.1913e-01, time/batch = 0.6897s	
2600/28500 (epoch 4.561), train_loss = 1.69014150, grad/param norm = 2.3566e-01, time/batch = 0.6897s	
2601/28500 (epoch 4.563), train_loss = 1.68449494, grad/param norm = 2.1128e-01, time/batch = 0.6922s	
2602/28500 (epoch 4.565), train_loss = 1.55202639, grad/param norm = 2.2037e-01, time/batch = 0.7046s	
2603/28500 (epoch 4.567), train_loss = 1.48374487, grad/param norm = 2.1121e-01, time/batch = 0.7048s	
2604/28500 (epoch 4.568), train_loss = 1.64540865, grad/param norm = 2.1338e-01, time/batch = 0.7066s	
2605/28500 (epoch 4.570), train_loss = 1.47881682, grad/param norm = 2.1620e-01, time/batch = 0.6925s	
2606/28500 (epoch 4.572), train_loss = 1.56599242, grad/param norm = 2.0980e-01, time/batch = 0.6955s	
2607/28500 (epoch 4.574), train_loss = 1.61793976, grad/param norm = 2.0598e-01, time/batch = 0.7034s	
2608/28500 (epoch 4.575), train_loss = 1.48192332, grad/param norm = 1.9956e-01, time/batch = 0.6923s	
2609/28500 (epoch 4.577), train_loss = 1.53503646, grad/param norm = 1.8575e-01, time/batch = 0.6915s	
2610/28500 (epoch 4.579), train_loss = 1.76256280, grad/param norm = 2.4194e-01, time/batch = 0.7126s	
2611/28500 (epoch 4.581), train_loss = 1.51537641, grad/param norm = 1.9049e-01, time/batch = 0.6956s	
2612/28500 (epoch 4.582), train_loss = 1.64966487, grad/param norm = 2.0447e-01, time/batch = 0.6940s	
2613/28500 (epoch 4.584), train_loss = 1.49862876, grad/param norm = 1.7812e-01, time/batch = 0.7021s	
2614/28500 (epoch 4.586), train_loss = 1.39056857, grad/param norm = 1.6270e-01, time/batch = 0.6892s	
2615/28500 (epoch 4.588), train_loss = 1.48398036, grad/param norm = 1.8815e-01, time/batch = 0.6939s	
2616/28500 (epoch 4.589), train_loss = 1.83713507, grad/param norm = 2.1149e-01, time/batch = 0.7290s	
2617/28500 (epoch 4.591), train_loss = 1.63713178, grad/param norm = 1.8803e-01, time/batch = 0.6898s	
2618/28500 (epoch 4.593), train_loss = 1.49882289, grad/param norm = 1.8718e-01, time/batch = 0.6888s	
2619/28500 (epoch 4.595), train_loss = 1.83000777, grad/param norm = 2.5420e-01, time/batch = 0.7042s	
2620/28500 (epoch 4.596), train_loss = 1.73094444, grad/param norm = 2.3864e-01, time/batch = 0.6931s	
2621/28500 (epoch 4.598), train_loss = 1.55858416, grad/param norm = 1.8747e-01, time/batch = 0.6968s	
2622/28500 (epoch 4.600), train_loss = 1.61751556, grad/param norm = 2.0039e-01, time/batch = 0.6960s	
2623/28500 (epoch 4.602), train_loss = 1.77803180, grad/param norm = 2.0448e-01, time/batch = 0.6911s	
2624/28500 (epoch 4.604), train_loss = 1.62824036, grad/param norm = 2.0124e-01, time/batch = 0.6887s	
2625/28500 (epoch 4.605), train_loss = 1.58522588, grad/param norm = 2.0748e-01, time/batch = 0.6891s	
2626/28500 (epoch 4.607), train_loss = 1.58956356, grad/param norm = 1.9871e-01, time/batch = 0.6900s	
2627/28500 (epoch 4.609), train_loss = 1.59377246, grad/param norm = 2.0815e-01, time/batch = 0.6901s	
2628/28500 (epoch 4.611), train_loss = 1.60924713, grad/param norm = 2.0663e-01, time/batch = 0.6894s	
2629/28500 (epoch 4.612), train_loss = 1.61256347, grad/param norm = 1.9005e-01, time/batch = 0.6896s	
2630/28500 (epoch 4.614), train_loss = 1.56310751, grad/param norm = 1.9575e-01, time/batch = 0.7053s	
2631/28500 (epoch 4.616), train_loss = 1.56584859, grad/param norm = 2.0703e-01, time/batch = 0.6971s	
2632/28500 (epoch 4.618), train_loss = 1.46474487, grad/param norm = 1.8879e-01, time/batch = 0.6902s	
2633/28500 (epoch 4.619), train_loss = 1.75313580, grad/param norm = 2.2072e-01, time/batch = 0.6896s	
2634/28500 (epoch 4.621), train_loss = 1.31156014, grad/param norm = 1.7922e-01, time/batch = 0.6910s	
2635/28500 (epoch 4.623), train_loss = 1.60349274, grad/param norm = 2.0075e-01, time/batch = 0.6902s	
2636/28500 (epoch 4.625), train_loss = 1.43541669, grad/param norm = 1.9967e-01, time/batch = 0.6888s	
2637/28500 (epoch 4.626), train_loss = 1.30532148, grad/param norm = 1.7790e-01, time/batch = 0.6902s	
2638/28500 (epoch 4.628), train_loss = 1.45470033, grad/param norm = 1.9952e-01, time/batch = 0.6901s	
2639/28500 (epoch 4.630), train_loss = 1.42458149, grad/param norm = 1.8388e-01, time/batch = 0.6888s	
2640/28500 (epoch 4.632), train_loss = 1.65265759, grad/param norm = 2.0357e-01, time/batch = 0.7104s	
2641/28500 (epoch 4.633), train_loss = 1.59249770, grad/param norm = 1.8077e-01, time/batch = 0.6946s	
2642/28500 (epoch 4.635), train_loss = 1.70601656, grad/param norm = 2.0563e-01, time/batch = 0.6902s	
2643/28500 (epoch 4.637), train_loss = 1.56422571, grad/param norm = 1.9517e-01, time/batch = 0.6899s	
2644/28500 (epoch 4.639), train_loss = 1.34281560, grad/param norm = 1.9155e-01, time/batch = 0.6885s	
2645/28500 (epoch 4.640), train_loss = 1.49265098, grad/param norm = 2.0354e-01, time/batch = 0.6887s	
2646/28500 (epoch 4.642), train_loss = 1.61653194, grad/param norm = 1.8276e-01, time/batch = 0.6893s	
2647/28500 (epoch 4.644), train_loss = 1.62433437, grad/param norm = 1.9698e-01, time/batch = 0.6896s	
2648/28500 (epoch 4.646), train_loss = 1.47321247, grad/param norm = 1.7425e-01, time/batch = 0.6912s	
2649/28500 (epoch 4.647), train_loss = 1.45258218, grad/param norm = 1.9847e-01, time/batch = 0.7033s	
2650/28500 (epoch 4.649), train_loss = 1.48205027, grad/param norm = 1.8039e-01, time/batch = 0.7114s	
2651/28500 (epoch 4.651), train_loss = 1.45392600, grad/param norm = 1.9553e-01, time/batch = 0.7034s	
2652/28500 (epoch 4.653), train_loss = 1.43546828, grad/param norm = 1.8666e-01, time/batch = 0.6926s	
2653/28500 (epoch 4.654), train_loss = 1.48273922, grad/param norm = 1.9948e-01, time/batch = 0.6913s	
2654/28500 (epoch 4.656), train_loss = 1.55292930, grad/param norm = 1.9237e-01, time/batch = 0.6891s	
2655/28500 (epoch 4.658), train_loss = 1.59752406, grad/param norm = 2.0668e-01, time/batch = 0.6891s	
2656/28500 (epoch 4.660), train_loss = 1.51024330, grad/param norm = 1.7037e-01, time/batch = 0.6912s	
2657/28500 (epoch 4.661), train_loss = 1.67851784, grad/param norm = 2.0913e-01, time/batch = 0.6903s	
2658/28500 (epoch 4.663), train_loss = 1.74574857, grad/param norm = 2.0875e-01, time/batch = 0.6956s	
2659/28500 (epoch 4.665), train_loss = 1.52722857, grad/param norm = 1.9174e-01, time/batch = 0.7083s	
2660/28500 (epoch 4.667), train_loss = 1.60395155, grad/param norm = 2.0145e-01, time/batch = 0.7069s	
2661/28500 (epoch 4.668), train_loss = 1.52532647, grad/param norm = 1.8830e-01, time/batch = 0.6985s	
2662/28500 (epoch 4.670), train_loss = 1.50999231, grad/param norm = 1.9958e-01, time/batch = 0.6932s	
2663/28500 (epoch 4.672), train_loss = 1.54251265, grad/param norm = 1.8666e-01, time/batch = 0.7116s	
2664/28500 (epoch 4.674), train_loss = 1.40915761, grad/param norm = 2.0307e-01, time/batch = 0.7010s	
2665/28500 (epoch 4.675), train_loss = 1.38989840, grad/param norm = 1.8493e-01, time/batch = 0.7020s	
2666/28500 (epoch 4.677), train_loss = 1.49661783, grad/param norm = 2.0287e-01, time/batch = 0.6945s	
2667/28500 (epoch 4.679), train_loss = 1.59170256, grad/param norm = 2.1141e-01, time/batch = 0.7050s	
2668/28500 (epoch 4.681), train_loss = 1.65691602, grad/param norm = 2.2101e-01, time/batch = 0.6949s	
2669/28500 (epoch 4.682), train_loss = 1.45211104, grad/param norm = 1.8488e-01, time/batch = 0.6970s	
2670/28500 (epoch 4.684), train_loss = 1.57901980, grad/param norm = 1.9189e-01, time/batch = 0.6977s	
2671/28500 (epoch 4.686), train_loss = 1.47961091, grad/param norm = 2.1613e-01, time/batch = 0.7140s	
2672/28500 (epoch 4.688), train_loss = 1.52371272, grad/param norm = 1.9637e-01, time/batch = 0.7019s	
2673/28500 (epoch 4.689), train_loss = 1.60387448, grad/param norm = 2.2155e-01, time/batch = 0.6935s	
2674/28500 (epoch 4.691), train_loss = 1.55709373, grad/param norm = 2.0654e-01, time/batch = 0.6999s	
2675/28500 (epoch 4.693), train_loss = 1.55486979, grad/param norm = 2.1067e-01, time/batch = 0.7070s	
2676/28500 (epoch 4.695), train_loss = 1.53676537, grad/param norm = 2.2539e-01, time/batch = 0.6920s	
2677/28500 (epoch 4.696), train_loss = 1.58372931, grad/param norm = 2.3449e-01, time/batch = 0.6903s	
2678/28500 (epoch 4.698), train_loss = 1.52715105, grad/param norm = 1.8618e-01, time/batch = 0.6903s	
2679/28500 (epoch 4.700), train_loss = 1.53061072, grad/param norm = 2.0427e-01, time/batch = 0.6894s	
2680/28500 (epoch 4.702), train_loss = 1.73162225, grad/param norm = 2.0428e-01, time/batch = 0.6884s	
2681/28500 (epoch 4.704), train_loss = 1.59755880, grad/param norm = 2.1566e-01, time/batch = 0.6909s	
2682/28500 (epoch 4.705), train_loss = 1.62285665, grad/param norm = 1.9490e-01, time/batch = 0.6925s	
2683/28500 (epoch 4.707), train_loss = 1.54402522, grad/param norm = 2.1872e-01, time/batch = 0.7044s	
2684/28500 (epoch 4.709), train_loss = 1.65166981, grad/param norm = 2.0747e-01, time/batch = 0.6891s	
2685/28500 (epoch 4.711), train_loss = 1.47287933, grad/param norm = 2.1716e-01, time/batch = 0.6901s	
2686/28500 (epoch 4.712), train_loss = 1.63941610, grad/param norm = 2.2563e-01, time/batch = 0.6894s	
2687/28500 (epoch 4.714), train_loss = 1.61769732, grad/param norm = 1.9832e-01, time/batch = 0.6884s	
2688/28500 (epoch 4.716), train_loss = 1.54743021, grad/param norm = 1.9573e-01, time/batch = 0.6886s	
2689/28500 (epoch 4.718), train_loss = 1.45025967, grad/param norm = 1.9970e-01, time/batch = 0.6892s	
2690/28500 (epoch 4.719), train_loss = 1.46230146, grad/param norm = 1.8841e-01, time/batch = 0.6886s	
2691/28500 (epoch 4.721), train_loss = 1.29534043, grad/param norm = 1.9726e-01, time/batch = 0.6913s	
2692/28500 (epoch 4.723), train_loss = 1.54606882, grad/param norm = 1.9019e-01, time/batch = 0.6895s	
2693/28500 (epoch 4.725), train_loss = 1.63249121, grad/param norm = 1.8713e-01, time/batch = 0.6981s	
2694/28500 (epoch 4.726), train_loss = 1.54792798, grad/param norm = 1.9970e-01, time/batch = 0.6990s	
2695/28500 (epoch 4.728), train_loss = 1.40669257, grad/param norm = 1.7744e-01, time/batch = 0.6914s	
2696/28500 (epoch 4.730), train_loss = 1.56188891, grad/param norm = 1.9660e-01, time/batch = 0.6897s	
2697/28500 (epoch 4.732), train_loss = 1.35785170, grad/param norm = 1.9657e-01, time/batch = 0.6928s	
2698/28500 (epoch 4.733), train_loss = 1.39692777, grad/param norm = 1.9521e-01, time/batch = 0.6890s	
2699/28500 (epoch 4.735), train_loss = 1.38038950, grad/param norm = 1.7100e-01, time/batch = 0.6920s	
2700/28500 (epoch 4.737), train_loss = 1.34502143, grad/param norm = 1.8121e-01, time/batch = 0.6918s	
2701/28500 (epoch 4.739), train_loss = 1.56568739, grad/param norm = 1.9870e-01, time/batch = 0.6968s	
2702/28500 (epoch 4.740), train_loss = 1.52240473, grad/param norm = 1.9249e-01, time/batch = 0.7036s	
2703/28500 (epoch 4.742), train_loss = 1.51454050, grad/param norm = 2.0635e-01, time/batch = 0.7040s	
2704/28500 (epoch 4.744), train_loss = 1.64990085, grad/param norm = 1.9446e-01, time/batch = 0.6935s	
2705/28500 (epoch 4.746), train_loss = 1.43412985, grad/param norm = 1.7600e-01, time/batch = 0.6925s	
2706/28500 (epoch 4.747), train_loss = 1.42876249, grad/param norm = 1.8972e-01, time/batch = 0.6937s	
2707/28500 (epoch 4.749), train_loss = 1.77176639, grad/param norm = 2.0683e-01, time/batch = 0.6928s	
2708/28500 (epoch 4.751), train_loss = 1.46586072, grad/param norm = 1.9115e-01, time/batch = 0.6930s	
2709/28500 (epoch 4.753), train_loss = 1.38246149, grad/param norm = 1.7275e-01, time/batch = 0.6921s	
2710/28500 (epoch 4.754), train_loss = 1.35688494, grad/param norm = 1.7938e-01, time/batch = 0.6927s	
2711/28500 (epoch 4.756), train_loss = 1.64190157, grad/param norm = 1.9666e-01, time/batch = 0.6962s	
2712/28500 (epoch 4.758), train_loss = 1.54514431, grad/param norm = 1.9821e-01, time/batch = 0.6960s	
2713/28500 (epoch 4.760), train_loss = 1.43335521, grad/param norm = 2.0535e-01, time/batch = 0.6986s	
2714/28500 (epoch 4.761), train_loss = 1.49718953, grad/param norm = 1.9690e-01, time/batch = 0.6991s	
2715/28500 (epoch 4.763), train_loss = 1.29139150, grad/param norm = 1.7986e-01, time/batch = 0.6968s	
2716/28500 (epoch 4.765), train_loss = 1.44984249, grad/param norm = 1.7638e-01, time/batch = 0.6936s	
2717/28500 (epoch 4.767), train_loss = 1.29169687, grad/param norm = 1.9157e-01, time/batch = 0.6932s	
2718/28500 (epoch 4.768), train_loss = 1.68224694, grad/param norm = 2.2084e-01, time/batch = 0.6941s	
2719/28500 (epoch 4.770), train_loss = 1.37421149, grad/param norm = 2.0676e-01, time/batch = 0.6939s	
2720/28500 (epoch 4.772), train_loss = 1.32614077, grad/param norm = 2.1644e-01, time/batch = 0.6929s	
2721/28500 (epoch 4.774), train_loss = 1.56037437, grad/param norm = 2.0498e-01, time/batch = 0.6969s	
2722/28500 (epoch 4.775), train_loss = 1.62647187, grad/param norm = 1.9128e-01, time/batch = 0.6963s	
2723/28500 (epoch 4.777), train_loss = 1.54459367, grad/param norm = 1.9870e-01, time/batch = 0.6970s	
2724/28500 (epoch 4.779), train_loss = 1.41773314, grad/param norm = 1.8229e-01, time/batch = 0.6963s	
2725/28500 (epoch 4.781), train_loss = 1.59058496, grad/param norm = 2.1427e-01, time/batch = 0.6958s	
2726/28500 (epoch 4.782), train_loss = 1.69579249, grad/param norm = 2.0943e-01, time/batch = 0.6956s	
2727/28500 (epoch 4.784), train_loss = 1.31422951, grad/param norm = 1.7240e-01, time/batch = 0.6934s	
2728/28500 (epoch 4.786), train_loss = 1.49725925, grad/param norm = 1.9170e-01, time/batch = 0.6965s	
2729/28500 (epoch 4.788), train_loss = 1.62818783, grad/param norm = 2.0428e-01, time/batch = 0.6947s	
2730/28500 (epoch 4.789), train_loss = 1.31195129, grad/param norm = 1.9938e-01, time/batch = 0.6935s	
2731/28500 (epoch 4.791), train_loss = 1.50594212, grad/param norm = 2.0459e-01, time/batch = 0.6954s	
2732/28500 (epoch 4.793), train_loss = 1.39915050, grad/param norm = 2.0673e-01, time/batch = 0.6940s	
2733/28500 (epoch 4.795), train_loss = 1.53234497, grad/param norm = 2.0947e-01, time/batch = 0.6948s	
2734/28500 (epoch 4.796), train_loss = 1.41732023, grad/param norm = 1.7574e-01, time/batch = 0.6992s	
2735/28500 (epoch 4.798), train_loss = 1.41252898, grad/param norm = 1.8505e-01, time/batch = 0.7027s	
2736/28500 (epoch 4.800), train_loss = 1.45832825, grad/param norm = 1.9714e-01, time/batch = 0.7091s	
2737/28500 (epoch 4.802), train_loss = 1.55888771, grad/param norm = 2.1116e-01, time/batch = 0.6947s	
2738/28500 (epoch 4.804), train_loss = 1.54512486, grad/param norm = 1.9281e-01, time/batch = 0.6925s	
2739/28500 (epoch 4.805), train_loss = 1.58038785, grad/param norm = 2.0053e-01, time/batch = 0.6935s	
2740/28500 (epoch 4.807), train_loss = 1.68972755, grad/param norm = 2.0971e-01, time/batch = 0.6961s	
2741/28500 (epoch 4.809), train_loss = 1.46230011, grad/param norm = 1.8013e-01, time/batch = 0.7016s	
2742/28500 (epoch 4.811), train_loss = 1.67490666, grad/param norm = 2.2905e-01, time/batch = 0.6944s	
2743/28500 (epoch 4.812), train_loss = 1.58876392, grad/param norm = 1.9053e-01, time/batch = 0.6940s	
2744/28500 (epoch 4.814), train_loss = 1.47098099, grad/param norm = 1.9074e-01, time/batch = 0.6941s	
2745/28500 (epoch 4.816), train_loss = 1.66744419, grad/param norm = 2.0257e-01, time/batch = 0.6958s	
2746/28500 (epoch 4.818), train_loss = 1.54081649, grad/param norm = 1.9566e-01, time/batch = 0.6933s	
2747/28500 (epoch 4.819), train_loss = 1.51117464, grad/param norm = 1.9232e-01, time/batch = 0.6932s	
2748/28500 (epoch 4.821), train_loss = 1.44428901, grad/param norm = 1.7975e-01, time/batch = 0.6920s	
2749/28500 (epoch 4.823), train_loss = 1.80508035, grad/param norm = 2.4521e-01, time/batch = 0.6952s	
2750/28500 (epoch 4.825), train_loss = 1.50671169, grad/param norm = 2.1478e-01, time/batch = 0.6951s	
2751/28500 (epoch 4.826), train_loss = 1.59441532, grad/param norm = 2.1970e-01, time/batch = 0.6959s	
2752/28500 (epoch 4.828), train_loss = 1.40383192, grad/param norm = 2.0240e-01, time/batch = 0.6949s	
2753/28500 (epoch 4.830), train_loss = 1.44463644, grad/param norm = 1.7033e-01, time/batch = 0.6944s	
2754/28500 (epoch 4.832), train_loss = 1.55610762, grad/param norm = 1.9975e-01, time/batch = 0.6967s	
2755/28500 (epoch 4.833), train_loss = 1.69255266, grad/param norm = 1.8789e-01, time/batch = 0.6955s	
2756/28500 (epoch 4.835), train_loss = 1.49677201, grad/param norm = 1.9981e-01, time/batch = 0.6934s	
2757/28500 (epoch 4.837), train_loss = 1.39821355, grad/param norm = 1.8622e-01, time/batch = 0.6939s	
2758/28500 (epoch 4.839), train_loss = 1.67038880, grad/param norm = 2.0423e-01, time/batch = 0.6940s	
2759/28500 (epoch 4.840), train_loss = 1.63810168, grad/param norm = 1.9398e-01, time/batch = 0.6955s	
2760/28500 (epoch 4.842), train_loss = 1.55890659, grad/param norm = 1.9222e-01, time/batch = 0.6940s	
2761/28500 (epoch 4.844), train_loss = 1.56366112, grad/param norm = 1.9856e-01, time/batch = 0.6968s	
2762/28500 (epoch 4.846), train_loss = 1.63885350, grad/param norm = 1.9019e-01, time/batch = 0.6951s	
2763/28500 (epoch 4.847), train_loss = 1.48241448, grad/param norm = 1.8381e-01, time/batch = 0.6942s	
2764/28500 (epoch 4.849), train_loss = 1.44288531, grad/param norm = 1.7162e-01, time/batch = 0.6935s	
2765/28500 (epoch 4.851), train_loss = 1.36459099, grad/param norm = 1.8215e-01, time/batch = 0.6942s	
2766/28500 (epoch 4.853), train_loss = 1.54837809, grad/param norm = 1.9230e-01, time/batch = 0.6942s	
2767/28500 (epoch 4.854), train_loss = 1.50204798, grad/param norm = 2.0201e-01, time/batch = 0.6929s	
2768/28500 (epoch 4.856), train_loss = 1.59127405, grad/param norm = 1.9908e-01, time/batch = 0.6947s	
2769/28500 (epoch 4.858), train_loss = 1.35894003, grad/param norm = 1.8373e-01, time/batch = 0.6927s	
2770/28500 (epoch 4.860), train_loss = 1.63310736, grad/param norm = 2.0768e-01, time/batch = 0.6928s	
2771/28500 (epoch 4.861), train_loss = 1.48924822, grad/param norm = 1.9921e-01, time/batch = 0.6962s	
2772/28500 (epoch 4.863), train_loss = 1.65789258, grad/param norm = 2.1141e-01, time/batch = 0.6942s	
2773/28500 (epoch 4.865), train_loss = 1.53435805, grad/param norm = 2.1604e-01, time/batch = 0.6955s	
2774/28500 (epoch 4.867), train_loss = 1.60884432, grad/param norm = 1.9682e-01, time/batch = 0.6949s	
2775/28500 (epoch 4.868), train_loss = 1.39138640, grad/param norm = 2.1418e-01, time/batch = 0.6948s	
2776/28500 (epoch 4.870), train_loss = 1.28354649, grad/param norm = 1.7290e-01, time/batch = 0.6923s	
2777/28500 (epoch 4.872), train_loss = 1.61791321, grad/param norm = 1.9945e-01, time/batch = 0.6947s	
2778/28500 (epoch 4.874), train_loss = 1.52401431, grad/param norm = 2.1510e-01, time/batch = 0.6930s	
2779/28500 (epoch 4.875), train_loss = 1.61138117, grad/param norm = 2.0156e-01, time/batch = 0.6948s	
2780/28500 (epoch 4.877), train_loss = 1.51906527, grad/param norm = 2.1241e-01, time/batch = 0.6929s	
2781/28500 (epoch 4.879), train_loss = 1.48067592, grad/param norm = 1.9282e-01, time/batch = 0.6968s	
2782/28500 (epoch 4.881), train_loss = 1.58426239, grad/param norm = 1.9095e-01, time/batch = 0.6986s	
2783/28500 (epoch 4.882), train_loss = 1.49847154, grad/param norm = 1.8759e-01, time/batch = 0.6934s	
2784/28500 (epoch 4.884), train_loss = 1.58401020, grad/param norm = 2.0644e-01, time/batch = 0.6937s	
2785/28500 (epoch 4.886), train_loss = 1.40084143, grad/param norm = 1.8482e-01, time/batch = 0.6935s	
2786/28500 (epoch 4.888), train_loss = 1.36851398, grad/param norm = 1.7523e-01, time/batch = 0.6938s	
2787/28500 (epoch 4.889), train_loss = 1.41879863, grad/param norm = 1.7176e-01, time/batch = 0.6937s	
2788/28500 (epoch 4.891), train_loss = 1.53534622, grad/param norm = 1.8144e-01, time/batch = 0.6937s	
2789/28500 (epoch 4.893), train_loss = 1.47979646, grad/param norm = 2.1724e-01, time/batch = 0.6942s	
2790/28500 (epoch 4.895), train_loss = 1.72592994, grad/param norm = 2.2458e-01, time/batch = 0.6955s	
2791/28500 (epoch 4.896), train_loss = 1.65703239, grad/param norm = 2.1029e-01, time/batch = 0.6915s	
2792/28500 (epoch 4.898), train_loss = 1.45680167, grad/param norm = 1.8519e-01, time/batch = 0.6919s	
2793/28500 (epoch 4.900), train_loss = 1.37016685, grad/param norm = 1.9639e-01, time/batch = 0.7048s	
2794/28500 (epoch 4.902), train_loss = 1.40000949, grad/param norm = 1.8730e-01, time/batch = 0.7025s	
2795/28500 (epoch 4.904), train_loss = 1.38113149, grad/param norm = 1.7225e-01, time/batch = 0.6955s	
2796/28500 (epoch 4.905), train_loss = 1.53257244, grad/param norm = 1.8522e-01, time/batch = 0.6931s	
2797/28500 (epoch 4.907), train_loss = 1.66537033, grad/param norm = 2.1979e-01, time/batch = 0.6951s	
2798/28500 (epoch 4.909), train_loss = 1.44225382, grad/param norm = 1.8200e-01, time/batch = 0.6945s	
2799/28500 (epoch 4.911), train_loss = 1.44336183, grad/param norm = 1.9505e-01, time/batch = 0.6915s	
2800/28500 (epoch 4.912), train_loss = 1.22257639, grad/param norm = 1.9788e-01, time/batch = 0.6943s	
2801/28500 (epoch 4.914), train_loss = 1.63599582, grad/param norm = 2.0076e-01, time/batch = 0.6967s	
2802/28500 (epoch 4.916), train_loss = 1.57957236, grad/param norm = 1.9940e-01, time/batch = 0.6970s	
2803/28500 (epoch 4.918), train_loss = 1.55837043, grad/param norm = 2.0241e-01, time/batch = 0.6908s	
2804/28500 (epoch 4.919), train_loss = 1.43580062, grad/param norm = 1.7670e-01, time/batch = 0.6904s	
2805/28500 (epoch 4.921), train_loss = 1.73502398, grad/param norm = 2.2728e-01, time/batch = 0.6985s	
2806/28500 (epoch 4.923), train_loss = 1.61573564, grad/param norm = 2.3324e-01, time/batch = 0.6966s	
2807/28500 (epoch 4.925), train_loss = 1.41592644, grad/param norm = 1.9442e-01, time/batch = 0.6980s	
2808/28500 (epoch 4.926), train_loss = 1.55533684, grad/param norm = 2.1235e-01, time/batch = 0.6915s	
2809/28500 (epoch 4.928), train_loss = 1.40932290, grad/param norm = 1.9640e-01, time/batch = 0.6914s	
2810/28500 (epoch 4.930), train_loss = 1.18476280, grad/param norm = 1.7872e-01, time/batch = 0.7060s	
2811/28500 (epoch 4.932), train_loss = 1.34174474, grad/param norm = 1.6484e-01, time/batch = 0.7013s	
2812/28500 (epoch 4.933), train_loss = 1.54678142, grad/param norm = 1.8718e-01, time/batch = 0.7044s	
2813/28500 (epoch 4.935), train_loss = 1.50384834, grad/param norm = 2.1854e-01, time/batch = 0.7011s	
2814/28500 (epoch 4.937), train_loss = 1.67697447, grad/param norm = 2.1039e-01, time/batch = 0.6947s	
2815/28500 (epoch 4.939), train_loss = 1.76095629, grad/param norm = 2.0287e-01, time/batch = 0.6940s	
2816/28500 (epoch 4.940), train_loss = 1.44541456, grad/param norm = 1.8370e-01, time/batch = 0.6900s	
2817/28500 (epoch 4.942), train_loss = 1.60210014, grad/param norm = 1.8633e-01, time/batch = 0.6914s	
2818/28500 (epoch 4.944), train_loss = 1.55569947, grad/param norm = 1.8855e-01, time/batch = 0.6932s	
2819/28500 (epoch 4.946), train_loss = 1.64144605, grad/param norm = 1.9034e-01, time/batch = 0.6908s	
2820/28500 (epoch 4.947), train_loss = 1.91150264, grad/param norm = 2.2906e-01, time/batch = 0.6936s	
2821/28500 (epoch 4.949), train_loss = 1.41417888, grad/param norm = 2.1201e-01, time/batch = 0.7091s	
2822/28500 (epoch 4.951), train_loss = 1.71856336, grad/param norm = 2.1407e-01, time/batch = 0.6906s	
2823/28500 (epoch 4.953), train_loss = 1.70246499, grad/param norm = 2.3387e-01, time/batch = 0.6911s	
2824/28500 (epoch 4.954), train_loss = 1.60626165, grad/param norm = 2.0523e-01, time/batch = 0.6891s	
2825/28500 (epoch 4.956), train_loss = 1.61444817, grad/param norm = 2.3696e-01, time/batch = 0.6904s	
2826/28500 (epoch 4.958), train_loss = 1.59693998, grad/param norm = 2.1391e-01, time/batch = 0.6897s	
2827/28500 (epoch 4.960), train_loss = 1.43450172, grad/param norm = 1.9701e-01, time/batch = 0.6898s	
2828/28500 (epoch 4.961), train_loss = 1.76021545, grad/param norm = 2.0845e-01, time/batch = 0.6908s	
2829/28500 (epoch 4.963), train_loss = 1.59302108, grad/param norm = 1.6684e-01, time/batch = 0.6906s	
2830/28500 (epoch 4.965), train_loss = 1.40464489, grad/param norm = 1.7935e-01, time/batch = 0.6895s	
2831/28500 (epoch 4.967), train_loss = 1.35681810, grad/param norm = 1.7775e-01, time/batch = 0.6971s	
2832/28500 (epoch 4.968), train_loss = 1.30823231, grad/param norm = 1.7311e-01, time/batch = 0.6967s	
2833/28500 (epoch 4.970), train_loss = 1.59473168, grad/param norm = 1.9998e-01, time/batch = 0.6898s	
2834/28500 (epoch 4.972), train_loss = 1.78421436, grad/param norm = 2.1052e-01, time/batch = 0.6937s	
2835/28500 (epoch 4.974), train_loss = 1.79310748, grad/param norm = 2.0242e-01, time/batch = 0.6902s	
2836/28500 (epoch 4.975), train_loss = 1.48813098, grad/param norm = 1.9929e-01, time/batch = 0.6892s	
2837/28500 (epoch 4.977), train_loss = 1.75056955, grad/param norm = 2.0804e-01, time/batch = 0.6906s	
2838/28500 (epoch 4.979), train_loss = 1.44046152, grad/param norm = 1.8182e-01, time/batch = 0.6916s	
2839/28500 (epoch 4.981), train_loss = 1.48735057, grad/param norm = 1.9136e-01, time/batch = 0.6953s	
2840/28500 (epoch 4.982), train_loss = 1.38349773, grad/param norm = 1.7925e-01, time/batch = 0.6899s	
2841/28500 (epoch 4.984), train_loss = 1.58569415, grad/param norm = 1.8708e-01, time/batch = 0.6927s	
2842/28500 (epoch 4.986), train_loss = 1.69453185, grad/param norm = 2.0147e-01, time/batch = 0.6925s	
2843/28500 (epoch 4.988), train_loss = 1.30993740, grad/param norm = 1.8741e-01, time/batch = 0.6952s	
2844/28500 (epoch 4.989), train_loss = 1.57186278, grad/param norm = 2.0198e-01, time/batch = 0.6939s	
2845/28500 (epoch 4.991), train_loss = 1.47120755, grad/param norm = 2.0956e-01, time/batch = 0.6937s	
2846/28500 (epoch 4.993), train_loss = 1.47674043, grad/param norm = 2.0261e-01, time/batch = 0.6918s	
2847/28500 (epoch 4.995), train_loss = 1.47676778, grad/param norm = 1.9313e-01, time/batch = 0.6925s	
2848/28500 (epoch 4.996), train_loss = 1.40857872, grad/param norm = 1.7850e-01, time/batch = 0.6929s	
2849/28500 (epoch 4.998), train_loss = 1.60824649, grad/param norm = 2.0315e-01, time/batch = 0.6934s	
2850/28500 (epoch 5.000), train_loss = 1.46899274, grad/param norm = 1.8916e-01, time/batch = 0.6974s	
2851/28500 (epoch 5.002), train_loss = 1.61094985, grad/param norm = 1.9045e-01, time/batch = 0.7062s	
2852/28500 (epoch 5.004), train_loss = 1.43075848, grad/param norm = 2.0196e-01, time/batch = 0.7105s	
2853/28500 (epoch 5.005), train_loss = 1.58675517, grad/param norm = 2.0188e-01, time/batch = 0.7048s	
2854/28500 (epoch 5.007), train_loss = 1.32327335, grad/param norm = 1.7488e-01, time/batch = 0.6973s	
2855/28500 (epoch 5.009), train_loss = 1.62591463, grad/param norm = 2.1089e-01, time/batch = 0.6914s	
2856/28500 (epoch 5.011), train_loss = 1.51944699, grad/param norm = 2.1649e-01, time/batch = 0.6916s	
2857/28500 (epoch 5.012), train_loss = 1.31777141, grad/param norm = 1.6502e-01, time/batch = 0.6917s	
2858/28500 (epoch 5.014), train_loss = 1.38408713, grad/param norm = 1.7780e-01, time/batch = 0.7118s	
2859/28500 (epoch 5.016), train_loss = 1.44020591, grad/param norm = 1.8489e-01, time/batch = 0.7105s	
2860/28500 (epoch 5.018), train_loss = 1.48066645, grad/param norm = 1.9141e-01, time/batch = 0.7013s	
2861/28500 (epoch 5.019), train_loss = 1.55351484, grad/param norm = 2.1125e-01, time/batch = 0.6930s	
2862/28500 (epoch 5.021), train_loss = 1.49302598, grad/param norm = 1.8215e-01, time/batch = 0.6967s	
2863/28500 (epoch 5.023), train_loss = 1.52617213, grad/param norm = 1.9821e-01, time/batch = 0.6967s	
2864/28500 (epoch 5.025), train_loss = 1.47635947, grad/param norm = 1.8728e-01, time/batch = 0.6975s	
2865/28500 (epoch 5.026), train_loss = 1.55322178, grad/param norm = 2.0074e-01, time/batch = 0.6921s	
2866/28500 (epoch 5.028), train_loss = 1.59396005, grad/param norm = 2.0412e-01, time/batch = 0.6916s	
2867/28500 (epoch 5.030), train_loss = 1.63167984, grad/param norm = 2.3658e-01, time/batch = 0.6896s	
2868/28500 (epoch 5.032), train_loss = 1.60021877, grad/param norm = 2.0128e-01, time/batch = 0.6907s	
2869/28500 (epoch 5.033), train_loss = 1.69996152, grad/param norm = 2.0897e-01, time/batch = 0.6955s	
2870/28500 (epoch 5.035), train_loss = 1.58192024, grad/param norm = 2.1510e-01, time/batch = 0.6923s	
2871/28500 (epoch 5.037), train_loss = 1.58588272, grad/param norm = 1.9049e-01, time/batch = 0.6943s	
2872/28500 (epoch 5.039), train_loss = 1.68862309, grad/param norm = 2.1364e-01, time/batch = 0.6921s	
2873/28500 (epoch 5.040), train_loss = 1.66569598, grad/param norm = 1.9566e-01, time/batch = 0.6902s	
2874/28500 (epoch 5.042), train_loss = 1.67084789, grad/param norm = 2.0240e-01, time/batch = 0.6896s	
2875/28500 (epoch 5.044), train_loss = 1.56571185, grad/param norm = 2.1995e-01, time/batch = 0.6907s	
2876/28500 (epoch 5.046), train_loss = 1.70319500, grad/param norm = 1.9262e-01, time/batch = 0.7051s	
2877/28500 (epoch 5.047), train_loss = 1.66349195, grad/param norm = 2.1205e-01, time/batch = 0.6999s	
2878/28500 (epoch 5.049), train_loss = 1.59657451, grad/param norm = 2.1227e-01, time/batch = 0.6966s	
2879/28500 (epoch 5.051), train_loss = 1.51620184, grad/param norm = 1.7930e-01, time/batch = 0.6939s	
2880/28500 (epoch 5.053), train_loss = 1.62857896, grad/param norm = 1.9595e-01, time/batch = 0.6920s	
2881/28500 (epoch 5.054), train_loss = 1.63803781, grad/param norm = 1.8859e-01, time/batch = 0.6915s	
2882/28500 (epoch 5.056), train_loss = 1.38287201, grad/param norm = 1.7606e-01, time/batch = 0.6915s	
2883/28500 (epoch 5.058), train_loss = 1.41186562, grad/param norm = 2.0147e-01, time/batch = 0.6992s	
2884/28500 (epoch 5.060), train_loss = 1.55787654, grad/param norm = 1.9825e-01, time/batch = 0.6898s	
2885/28500 (epoch 5.061), train_loss = 1.61754721, grad/param norm = 2.0751e-01, time/batch = 0.6901s	
2886/28500 (epoch 5.063), train_loss = 1.65912134, grad/param norm = 1.8977e-01, time/batch = 0.6916s	
2887/28500 (epoch 5.065), train_loss = 1.74652930, grad/param norm = 1.9687e-01, time/batch = 0.6909s	
2888/28500 (epoch 5.067), train_loss = 1.45231280, grad/param norm = 1.9405e-01, time/batch = 0.6895s	
2889/28500 (epoch 5.068), train_loss = 1.42025804, grad/param norm = 1.8527e-01, time/batch = 0.6895s	
2890/28500 (epoch 5.070), train_loss = 1.58773492, grad/param norm = 1.9198e-01, time/batch = 0.6891s	
2891/28500 (epoch 5.072), train_loss = 1.75280561, grad/param norm = 2.0797e-01, time/batch = 0.6915s	
2892/28500 (epoch 5.074), train_loss = 1.58320992, grad/param norm = 2.0544e-01, time/batch = 0.6902s	
2893/28500 (epoch 5.075), train_loss = 1.47235350, grad/param norm = 1.7408e-01, time/batch = 0.6900s	
2894/28500 (epoch 5.077), train_loss = 1.59150921, grad/param norm = 1.9437e-01, time/batch = 0.6897s	
2895/28500 (epoch 5.079), train_loss = 1.53757363, grad/param norm = 1.9921e-01, time/batch = 0.6897s	
2896/28500 (epoch 5.081), train_loss = 1.69723573, grad/param norm = 2.0892e-01, time/batch = 0.6905s	
2897/28500 (epoch 5.082), train_loss = 1.60303821, grad/param norm = 2.0424e-01, time/batch = 0.6911s	
2898/28500 (epoch 5.084), train_loss = 1.60580801, grad/param norm = 1.8619e-01, time/batch = 0.6901s	
2899/28500 (epoch 5.086), train_loss = 1.47476988, grad/param norm = 2.1148e-01, time/batch = 0.6908s	
2900/28500 (epoch 5.088), train_loss = 1.41951974, grad/param norm = 1.9814e-01, time/batch = 0.6918s	
2901/28500 (epoch 5.089), train_loss = 1.70078042, grad/param norm = 1.8076e-01, time/batch = 0.6932s	
2902/28500 (epoch 5.091), train_loss = 1.34122993, grad/param norm = 1.8610e-01, time/batch = 0.6932s	
2903/28500 (epoch 5.093), train_loss = 1.53349398, grad/param norm = 1.8908e-01, time/batch = 0.6894s	
2904/28500 (epoch 5.095), train_loss = 1.47409464, grad/param norm = 1.9445e-01, time/batch = 0.6897s	
2905/28500 (epoch 5.096), train_loss = 1.69472292, grad/param norm = 1.9949e-01, time/batch = 0.6913s	
2906/28500 (epoch 5.098), train_loss = 1.70826850, grad/param norm = 2.1379e-01, time/batch = 0.6945s	
2907/28500 (epoch 5.100), train_loss = 1.43929281, grad/param norm = 1.8957e-01, time/batch = 0.7085s	
2908/28500 (epoch 5.102), train_loss = 1.72138585, grad/param norm = 1.9203e-01, time/batch = 0.6981s	
2909/28500 (epoch 5.104), train_loss = 1.53376616, grad/param norm = 1.9035e-01, time/batch = 0.7151s	
2910/28500 (epoch 5.105), train_loss = 1.55284874, grad/param norm = 2.0010e-01, time/batch = 0.6994s	
2911/28500 (epoch 5.107), train_loss = 1.45925396, grad/param norm = 2.1002e-01, time/batch = 0.7044s	
2912/28500 (epoch 5.109), train_loss = 1.40614998, grad/param norm = 1.8745e-01, time/batch = 0.6998s	
2913/28500 (epoch 5.111), train_loss = 1.51626149, grad/param norm = 1.9144e-01, time/batch = 0.7033s	
2914/28500 (epoch 5.112), train_loss = 1.61866118, grad/param norm = 1.9986e-01, time/batch = 0.7083s	
2915/28500 (epoch 5.114), train_loss = 1.52294233, grad/param norm = 2.1043e-01, time/batch = 0.6992s	
2916/28500 (epoch 5.116), train_loss = 1.74366702, grad/param norm = 2.1262e-01, time/batch = 0.6946s	
2917/28500 (epoch 5.118), train_loss = 1.38688204, grad/param norm = 1.8319e-01, time/batch = 0.6914s	
2918/28500 (epoch 5.119), train_loss = 1.60401109, grad/param norm = 1.9847e-01, time/batch = 0.6925s	
2919/28500 (epoch 5.121), train_loss = 1.74467050, grad/param norm = 2.1536e-01, time/batch = 0.6998s	
2920/28500 (epoch 5.123), train_loss = 1.62910585, grad/param norm = 2.3249e-01, time/batch = 0.6891s	
2921/28500 (epoch 5.125), train_loss = 1.60751393, grad/param norm = 2.0136e-01, time/batch = 0.6943s	
2922/28500 (epoch 5.126), train_loss = 1.55209537, grad/param norm = 1.9078e-01, time/batch = 0.6902s	
2923/28500 (epoch 5.128), train_loss = 1.45689272, grad/param norm = 2.0941e-01, time/batch = 0.6896s	
2924/28500 (epoch 5.130), train_loss = 1.50718657, grad/param norm = 1.9868e-01, time/batch = 0.6900s	
2925/28500 (epoch 5.132), train_loss = 1.61103384, grad/param norm = 2.0659e-01, time/batch = 0.6900s	
2926/28500 (epoch 5.133), train_loss = 1.50126873, grad/param norm = 1.8159e-01, time/batch = 0.6917s	
2927/28500 (epoch 5.135), train_loss = 1.53667477, grad/param norm = 1.7998e-01, time/batch = 0.6904s	
2928/28500 (epoch 5.137), train_loss = 1.50321240, grad/param norm = 2.0653e-01, time/batch = 0.6893s	
2929/28500 (epoch 5.139), train_loss = 1.49572640, grad/param norm = 1.7329e-01, time/batch = 0.6897s	
2930/28500 (epoch 5.140), train_loss = 1.52151991, grad/param norm = 1.8422e-01, time/batch = 0.6919s	
2931/28500 (epoch 5.142), train_loss = 1.58362491, grad/param norm = 1.9903e-01, time/batch = 0.6957s	
2932/28500 (epoch 5.144), train_loss = 1.40849149, grad/param norm = 1.8364e-01, time/batch = 0.6910s	
2933/28500 (epoch 5.146), train_loss = 1.42554490, grad/param norm = 1.8793e-01, time/batch = 0.6906s	
2934/28500 (epoch 5.147), train_loss = 1.35032620, grad/param norm = 1.8165e-01, time/batch = 0.6918s	
2935/28500 (epoch 5.149), train_loss = 1.37643698, grad/param norm = 1.7755e-01, time/batch = 0.6899s	
2936/28500 (epoch 5.151), train_loss = 1.37791202, grad/param norm = 1.9048e-01, time/batch = 0.6894s	
2937/28500 (epoch 5.153), train_loss = 1.46950633, grad/param norm = 1.8383e-01, time/batch = 0.6897s	
2938/28500 (epoch 5.154), train_loss = 1.41949135, grad/param norm = 2.0118e-01, time/batch = 0.6914s	
2939/28500 (epoch 5.156), train_loss = 1.74097635, grad/param norm = 2.1463e-01, time/batch = 0.6946s	
2940/28500 (epoch 5.158), train_loss = 1.45969095, grad/param norm = 1.7934e-01, time/batch = 0.6943s	
2941/28500 (epoch 5.160), train_loss = 1.39930468, grad/param norm = 1.8164e-01, time/batch = 0.6958s	
2942/28500 (epoch 5.161), train_loss = 1.60974802, grad/param norm = 2.1986e-01, time/batch = 0.6947s	
2943/28500 (epoch 5.163), train_loss = 1.42348724, grad/param norm = 2.0267e-01, time/batch = 0.6937s	
2944/28500 (epoch 5.165), train_loss = 1.74302110, grad/param norm = 1.9072e-01, time/batch = 0.6896s	
2945/28500 (epoch 5.167), train_loss = 1.80764598, grad/param norm = 2.1022e-01, time/batch = 0.6915s	
2946/28500 (epoch 5.168), train_loss = 1.61517764, grad/param norm = 2.0642e-01, time/batch = 0.6937s	
2947/28500 (epoch 5.170), train_loss = 1.67547207, grad/param norm = 2.1681e-01, time/batch = 0.6912s	
2948/28500 (epoch 5.172), train_loss = 1.48765399, grad/param norm = 1.9378e-01, time/batch = 0.6903s	
2949/28500 (epoch 5.174), train_loss = 1.77717097, grad/param norm = 2.0828e-01, time/batch = 0.6909s	
2950/28500 (epoch 5.175), train_loss = 1.47275055, grad/param norm = 1.8607e-01, time/batch = 0.6900s	
2951/28500 (epoch 5.177), train_loss = 1.61168521, grad/param norm = 1.9679e-01, time/batch = 0.6970s	
2952/28500 (epoch 5.179), train_loss = 1.48964221, grad/param norm = 2.0059e-01, time/batch = 0.6907s	
2953/28500 (epoch 5.181), train_loss = 1.61583020, grad/param norm = 1.9059e-01, time/batch = 0.6917s	
2954/28500 (epoch 5.182), train_loss = 1.51413795, grad/param norm = 1.9858e-01, time/batch = 0.6893s	
2955/28500 (epoch 5.184), train_loss = 1.76881512, grad/param norm = 2.1508e-01, time/batch = 0.6898s	
2956/28500 (epoch 5.186), train_loss = 1.66732105, grad/param norm = 2.1597e-01, time/batch = 0.6892s	
2957/28500 (epoch 5.188), train_loss = 1.50256175, grad/param norm = 1.8975e-01, time/batch = 0.6897s	
2958/28500 (epoch 5.189), train_loss = 1.60560261, grad/param norm = 1.9960e-01, time/batch = 0.6900s	
2959/28500 (epoch 5.191), train_loss = 1.81782325, grad/param norm = 2.0129e-01, time/batch = 0.6895s	
2960/28500 (epoch 5.193), train_loss = 1.65429668, grad/param norm = 2.0817e-01, time/batch = 0.6895s	
2961/28500 (epoch 5.195), train_loss = 1.64270464, grad/param norm = 2.0701e-01, time/batch = 0.6919s	
2962/28500 (epoch 5.196), train_loss = 1.59071078, grad/param norm = 1.9310e-01, time/batch = 0.6911s	
2963/28500 (epoch 5.198), train_loss = 1.55324907, grad/param norm = 2.0465e-01, time/batch = 0.6900s	
2964/28500 (epoch 5.200), train_loss = 1.50922674, grad/param norm = 1.6633e-01, time/batch = 0.6900s	
2965/28500 (epoch 5.202), train_loss = 1.59285300, grad/param norm = 2.1808e-01, time/batch = 0.6907s	
2966/28500 (epoch 5.204), train_loss = 1.36619217, grad/param norm = 1.7451e-01, time/batch = 0.6915s	
2967/28500 (epoch 5.205), train_loss = 1.47238260, grad/param norm = 1.8980e-01, time/batch = 0.6921s	
2968/28500 (epoch 5.207), train_loss = 1.54617677, grad/param norm = 2.0493e-01, time/batch = 0.6897s	
2969/28500 (epoch 5.209), train_loss = 1.53966103, grad/param norm = 2.1040e-01, time/batch = 0.6904s	
2970/28500 (epoch 5.211), train_loss = 1.35986991, grad/param norm = 1.7715e-01, time/batch = 0.6929s	
2971/28500 (epoch 5.212), train_loss = 1.38800157, grad/param norm = 1.8120e-01, time/batch = 0.6915s	
2972/28500 (epoch 5.214), train_loss = 1.59129277, grad/param norm = 2.1335e-01, time/batch = 0.6910s	
2973/28500 (epoch 5.216), train_loss = 1.38679008, grad/param norm = 1.7419e-01, time/batch = 0.6902s	
2974/28500 (epoch 5.218), train_loss = 1.58324619, grad/param norm = 1.7827e-01, time/batch = 0.6903s	
2975/28500 (epoch 5.219), train_loss = 1.53202884, grad/param norm = 1.9240e-01, time/batch = 0.6939s	
2976/28500 (epoch 5.221), train_loss = 1.42824438, grad/param norm = 1.9231e-01, time/batch = 0.6914s	
2977/28500 (epoch 5.223), train_loss = 1.67369564, grad/param norm = 2.2697e-01, time/batch = 0.6902s	
2978/28500 (epoch 5.225), train_loss = 1.70645688, grad/param norm = 2.1575e-01, time/batch = 0.6939s	
2979/28500 (epoch 5.226), train_loss = 1.53444387, grad/param norm = 1.9475e-01, time/batch = 0.6900s	
2980/28500 (epoch 5.228), train_loss = 1.54505700, grad/param norm = 1.8805e-01, time/batch = 0.6927s	
2981/28500 (epoch 5.230), train_loss = 1.57960607, grad/param norm = 1.9296e-01, time/batch = 0.6956s	
2982/28500 (epoch 5.232), train_loss = 1.58636211, grad/param norm = 1.8351e-01, time/batch = 0.6926s	
2983/28500 (epoch 5.233), train_loss = 1.56903228, grad/param norm = 2.0312e-01, time/batch = 0.6913s	
2984/28500 (epoch 5.235), train_loss = 1.44802204, grad/param norm = 1.7979e-01, time/batch = 0.6900s	
2985/28500 (epoch 5.237), train_loss = 1.34870081, grad/param norm = 1.5792e-01, time/batch = 0.6902s	
2986/28500 (epoch 5.239), train_loss = 1.43852932, grad/param norm = 1.8866e-01, time/batch = 0.6906s	
2987/28500 (epoch 5.240), train_loss = 1.36611589, grad/param norm = 1.8130e-01, time/batch = 0.6900s	
2988/28500 (epoch 5.242), train_loss = 1.57188758, grad/param norm = 1.8270e-01, time/batch = 0.6898s	
2989/28500 (epoch 5.244), train_loss = 1.62972000, grad/param norm = 1.9699e-01, time/batch = 0.6893s	
2990/28500 (epoch 5.246), train_loss = 1.59491943, grad/param norm = 1.9237e-01, time/batch = 0.6900s	
2991/28500 (epoch 5.247), train_loss = 1.73265607, grad/param norm = 1.9890e-01, time/batch = 0.7022s	
2992/28500 (epoch 5.249), train_loss = 1.57200114, grad/param norm = 2.1549e-01, time/batch = 0.6982s	
2993/28500 (epoch 5.251), train_loss = 1.33418271, grad/param norm = 1.7513e-01, time/batch = 0.6927s	
2994/28500 (epoch 5.253), train_loss = 1.68574947, grad/param norm = 2.0738e-01, time/batch = 0.7156s	
2995/28500 (epoch 5.254), train_loss = 1.61479300, grad/param norm = 1.9800e-01, time/batch = 0.6877s	
2996/28500 (epoch 5.256), train_loss = 1.44670821, grad/param norm = 1.8618e-01, time/batch = 0.6776s	
2997/28500 (epoch 5.258), train_loss = 1.51792330, grad/param norm = 1.9795e-01, time/batch = 0.6839s	
2998/28500 (epoch 5.260), train_loss = 1.47310379, grad/param norm = 1.8522e-01, time/batch = 0.6861s	
2999/28500 (epoch 5.261), train_loss = 1.44524489, grad/param norm = 1.8900e-01, time/batch = 0.6843s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch5.26_1.6743.t7	
3000/28500 (epoch 5.263), train_loss = 1.70387219, grad/param norm = 2.1274e-01, time/batch = 0.6822s	
3001/28500 (epoch 5.265), train_loss = 1.77617642, grad/param norm = 2.2146e-01, time/batch = 0.6864s	
3002/28500 (epoch 5.267), train_loss = 1.70184799, grad/param norm = 2.2579e-01, time/batch = 0.6783s	
3003/28500 (epoch 5.268), train_loss = 1.61155561, grad/param norm = 1.9252e-01, time/batch = 0.6877s	
3004/28500 (epoch 5.270), train_loss = 1.51830095, grad/param norm = 1.9095e-01, time/batch = 0.6851s	
3005/28500 (epoch 5.272), train_loss = 1.51579859, grad/param norm = 1.9868e-01, time/batch = 0.6976s	
3006/28500 (epoch 5.274), train_loss = 1.71727548, grad/param norm = 2.0599e-01, time/batch = 0.6826s	
3007/28500 (epoch 5.275), train_loss = 1.60379247, grad/param norm = 1.8260e-01, time/batch = 0.6799s	
3008/28500 (epoch 5.277), train_loss = 1.46245899, grad/param norm = 1.8573e-01, time/batch = 0.6791s	
3009/28500 (epoch 5.279), train_loss = 1.57505611, grad/param norm = 1.9836e-01, time/batch = 0.6761s	
3010/28500 (epoch 5.281), train_loss = 1.58770814, grad/param norm = 1.9097e-01, time/batch = 0.6757s	
3011/28500 (epoch 5.282), train_loss = 1.41873172, grad/param norm = 1.8073e-01, time/batch = 0.6770s	
3012/28500 (epoch 5.284), train_loss = 1.57069348, grad/param norm = 1.9223e-01, time/batch = 0.6768s	
3013/28500 (epoch 5.286), train_loss = 1.66574747, grad/param norm = 2.1377e-01, time/batch = 0.6760s	
3014/28500 (epoch 5.288), train_loss = 1.57014455, grad/param norm = 1.9231e-01, time/batch = 0.6871s	
3015/28500 (epoch 5.289), train_loss = 1.68109632, grad/param norm = 1.9109e-01, time/batch = 0.6856s	
3016/28500 (epoch 5.291), train_loss = 1.48522079, grad/param norm = 1.8610e-01, time/batch = 0.6762s	
3017/28500 (epoch 5.293), train_loss = 1.46560928, grad/param norm = 1.9373e-01, time/batch = 0.6775s	
3018/28500 (epoch 5.295), train_loss = 1.43876129, grad/param norm = 1.8452e-01, time/batch = 0.6813s	
3019/28500 (epoch 5.296), train_loss = 1.40493618, grad/param norm = 1.7770e-01, time/batch = 0.6755s	
3020/28500 (epoch 5.298), train_loss = 1.56148253, grad/param norm = 1.9549e-01, time/batch = 0.6807s	
3021/28500 (epoch 5.300), train_loss = 1.41486095, grad/param norm = 1.7956e-01, time/batch = 0.6928s	
3022/28500 (epoch 5.302), train_loss = 1.38961362, grad/param norm = 1.8728e-01, time/batch = 0.6959s	
3023/28500 (epoch 5.304), train_loss = 1.50223664, grad/param norm = 1.7623e-01, time/batch = 0.6796s	
3024/28500 (epoch 5.305), train_loss = 1.60310544, grad/param norm = 1.9686e-01, time/batch = 0.6772s	
3025/28500 (epoch 5.307), train_loss = 1.61131625, grad/param norm = 2.2770e-01, time/batch = 0.6757s	
3026/28500 (epoch 5.309), train_loss = 1.60269150, grad/param norm = 2.1332e-01, time/batch = 0.6760s	
3027/28500 (epoch 5.311), train_loss = 1.54186185, grad/param norm = 2.2600e-01, time/batch = 0.6802s	
3028/28500 (epoch 5.312), train_loss = 1.42610699, grad/param norm = 1.7420e-01, time/batch = 0.6809s	
3029/28500 (epoch 5.314), train_loss = 1.58686659, grad/param norm = 2.0957e-01, time/batch = 0.6811s	
3030/28500 (epoch 5.316), train_loss = 1.53010169, grad/param norm = 1.7682e-01, time/batch = 0.6970s	
3031/28500 (epoch 5.318), train_loss = 1.57534475, grad/param norm = 2.1676e-01, time/batch = 0.6977s	
3032/28500 (epoch 5.319), train_loss = 1.49247129, grad/param norm = 1.9751e-01, time/batch = 0.6931s	
3033/28500 (epoch 5.321), train_loss = 1.60574460, grad/param norm = 2.0893e-01, time/batch = 0.7027s	
3034/28500 (epoch 5.323), train_loss = 1.51174586, grad/param norm = 1.9897e-01, time/batch = 0.7048s	
3035/28500 (epoch 5.325), train_loss = 1.72786423, grad/param norm = 1.8617e-01, time/batch = 0.7153s	
3036/28500 (epoch 5.326), train_loss = 1.61827046, grad/param norm = 2.2392e-01, time/batch = 0.7071s	
3037/28500 (epoch 5.328), train_loss = 1.28827679, grad/param norm = 1.8240e-01, time/batch = 0.6937s	
3038/28500 (epoch 5.330), train_loss = 1.44393782, grad/param norm = 1.8302e-01, time/batch = 0.6972s	
3039/28500 (epoch 5.332), train_loss = 1.47521042, grad/param norm = 1.7395e-01, time/batch = 0.7422s	
3040/28500 (epoch 5.333), train_loss = 1.34670285, grad/param norm = 1.8104e-01, time/batch = 0.6935s	
3041/28500 (epoch 5.335), train_loss = 1.38008334, grad/param norm = 1.7190e-01, time/batch = 0.6991s	
3042/28500 (epoch 5.337), train_loss = 1.51717741, grad/param norm = 1.9363e-01, time/batch = 0.6963s	
3043/28500 (epoch 5.339), train_loss = 1.44960374, grad/param norm = 1.9051e-01, time/batch = 0.6929s	
3044/28500 (epoch 5.340), train_loss = 1.62599668, grad/param norm = 2.0554e-01, time/batch = 0.6939s	
3045/28500 (epoch 5.342), train_loss = 1.47358630, grad/param norm = 2.1779e-01, time/batch = 0.6959s	
3046/28500 (epoch 5.344), train_loss = 1.45176811, grad/param norm = 2.1060e-01, time/batch = 0.6993s	
3047/28500 (epoch 5.346), train_loss = 1.19288993, grad/param norm = 1.6871e-01, time/batch = 0.6960s	
3048/28500 (epoch 5.347), train_loss = 1.52863236, grad/param norm = 1.9534e-01, time/batch = 0.6951s	
3049/28500 (epoch 5.349), train_loss = 1.40703373, grad/param norm = 1.7403e-01, time/batch = 0.6936s	
3050/28500 (epoch 5.351), train_loss = 1.37353325, grad/param norm = 1.7056e-01, time/batch = 0.6937s	
3051/28500 (epoch 5.353), train_loss = 1.60227408, grad/param norm = 1.9239e-01, time/batch = 0.6945s	
3052/28500 (epoch 5.354), train_loss = 1.39730211, grad/param norm = 1.9224e-01, time/batch = 0.6956s	
3053/28500 (epoch 5.356), train_loss = 1.41213725, grad/param norm = 1.6715e-01, time/batch = 0.6959s	
3054/28500 (epoch 5.358), train_loss = 1.56216032, grad/param norm = 1.7157e-01, time/batch = 0.6963s	
3055/28500 (epoch 5.360), train_loss = 1.52293479, grad/param norm = 2.0519e-01, time/batch = 0.6945s	
3056/28500 (epoch 5.361), train_loss = 1.46251461, grad/param norm = 1.7950e-01, time/batch = 0.6941s	
3057/28500 (epoch 5.363), train_loss = 1.38439757, grad/param norm = 1.7596e-01, time/batch = 0.7076s	
3058/28500 (epoch 5.365), train_loss = 1.44930898, grad/param norm = 1.8960e-01, time/batch = 0.6996s	
3059/28500 (epoch 5.367), train_loss = 1.50649814, grad/param norm = 1.9677e-01, time/batch = 0.6975s	
3060/28500 (epoch 5.368), train_loss = 1.45499108, grad/param norm = 1.7833e-01, time/batch = 0.6938s	
3061/28500 (epoch 5.370), train_loss = 1.55208837, grad/param norm = 1.9811e-01, time/batch = 0.6961s	
3062/28500 (epoch 5.372), train_loss = 1.37057675, grad/param norm = 1.8960e-01, time/batch = 0.6947s	
3063/28500 (epoch 5.374), train_loss = 1.58945577, grad/param norm = 2.0850e-01, time/batch = 0.6935s	
3064/28500 (epoch 5.375), train_loss = 1.68134628, grad/param norm = 2.0602e-01, time/batch = 0.6929s	
3065/28500 (epoch 5.377), train_loss = 1.46753061, grad/param norm = 1.8570e-01, time/batch = 0.6929s	
3066/28500 (epoch 5.379), train_loss = 1.26334552, grad/param norm = 1.7431e-01, time/batch = 0.6927s	
3067/28500 (epoch 5.381), train_loss = 1.43630139, grad/param norm = 1.7013e-01, time/batch = 0.6928s	
3068/28500 (epoch 5.382), train_loss = 1.46586873, grad/param norm = 2.0012e-01, time/batch = 0.6922s	
3069/28500 (epoch 5.384), train_loss = 1.37126175, grad/param norm = 1.7897e-01, time/batch = 0.6923s	
3070/28500 (epoch 5.386), train_loss = 1.36614744, grad/param norm = 1.9620e-01, time/batch = 0.6933s	
3071/28500 (epoch 5.388), train_loss = 1.63784352, grad/param norm = 1.9163e-01, time/batch = 0.7105s	
3072/28500 (epoch 5.389), train_loss = 1.45097758, grad/param norm = 1.8955e-01, time/batch = 0.6965s	
3073/28500 (epoch 5.391), train_loss = 1.42284926, grad/param norm = 1.7787e-01, time/batch = 0.6942s	
3074/28500 (epoch 5.393), train_loss = 1.33426696, grad/param norm = 1.7583e-01, time/batch = 0.6938s	
3075/28500 (epoch 5.395), train_loss = 1.72125694, grad/param norm = 1.9916e-01, time/batch = 0.6925s	
3076/28500 (epoch 5.396), train_loss = 1.58162614, grad/param norm = 1.9275e-01, time/batch = 0.6921s	
3077/28500 (epoch 5.398), train_loss = 1.37445546, grad/param norm = 2.0202e-01, time/batch = 0.6929s	
3078/28500 (epoch 5.400), train_loss = 1.60247917, grad/param norm = 2.2157e-01, time/batch = 0.6953s	
3079/28500 (epoch 5.402), train_loss = 1.47701802, grad/param norm = 1.9737e-01, time/batch = 0.6998s	
3080/28500 (epoch 5.404), train_loss = 1.61948083, grad/param norm = 2.0415e-01, time/batch = 0.6952s	
3081/28500 (epoch 5.405), train_loss = 1.57526447, grad/param norm = 1.8143e-01, time/batch = 0.7123s	
3082/28500 (epoch 5.407), train_loss = 1.54406446, grad/param norm = 1.8245e-01, time/batch = 0.7040s	
3083/28500 (epoch 5.409), train_loss = 1.55509930, grad/param norm = 1.9722e-01, time/batch = 0.6974s	
3084/28500 (epoch 5.411), train_loss = 1.57265814, grad/param norm = 1.7704e-01, time/batch = 0.6961s	
3085/28500 (epoch 5.412), train_loss = 1.68797962, grad/param norm = 2.0114e-01, time/batch = 0.6963s	
3086/28500 (epoch 5.414), train_loss = 1.50706414, grad/param norm = 1.8733e-01, time/batch = 0.6923s	
3087/28500 (epoch 5.416), train_loss = 1.44448991, grad/param norm = 1.9186e-01, time/batch = 0.6961s	
3088/28500 (epoch 5.418), train_loss = 1.55725972, grad/param norm = 1.7942e-01, time/batch = 0.6976s	
3089/28500 (epoch 5.419), train_loss = 1.66970682, grad/param norm = 2.1429e-01, time/batch = 0.6931s	
3090/28500 (epoch 5.421), train_loss = 1.60091346, grad/param norm = 1.8612e-01, time/batch = 0.7093s	
3091/28500 (epoch 5.423), train_loss = 1.74713688, grad/param norm = 2.1545e-01, time/batch = 0.6964s	
3092/28500 (epoch 5.425), train_loss = 1.57200156, grad/param norm = 2.1320e-01, time/batch = 0.6984s	
3093/28500 (epoch 5.426), train_loss = 1.53671570, grad/param norm = 1.9528e-01, time/batch = 0.6973s	
3094/28500 (epoch 5.428), train_loss = 1.77758225, grad/param norm = 2.1596e-01, time/batch = 0.6958s	
3095/28500 (epoch 5.430), train_loss = 1.58248429, grad/param norm = 1.8066e-01, time/batch = 0.6945s	
3096/28500 (epoch 5.432), train_loss = 1.61484030, grad/param norm = 2.2623e-01, time/batch = 0.6946s	
3097/28500 (epoch 5.433), train_loss = 1.59836574, grad/param norm = 2.0114e-01, time/batch = 0.6944s	
3098/28500 (epoch 5.435), train_loss = 1.49212455, grad/param norm = 1.9629e-01, time/batch = 0.6943s	
3099/28500 (epoch 5.437), train_loss = 1.34209887, grad/param norm = 1.5980e-01, time/batch = 0.6956s	
3100/28500 (epoch 5.439), train_loss = 1.38787290, grad/param norm = 1.7335e-01, time/batch = 0.6966s	
3101/28500 (epoch 5.440), train_loss = 1.58060288, grad/param norm = 1.8183e-01, time/batch = 0.6950s	
3102/28500 (epoch 5.442), train_loss = 1.41109931, grad/param norm = 1.9741e-01, time/batch = 0.6956s	
3103/28500 (epoch 5.444), train_loss = 1.35686782, grad/param norm = 1.7156e-01, time/batch = 0.6966s	
3104/28500 (epoch 5.446), train_loss = 1.28853665, grad/param norm = 1.8172e-01, time/batch = 0.6968s	
3105/28500 (epoch 5.447), train_loss = 1.41405487, grad/param norm = 1.7587e-01, time/batch = 0.6959s	
3106/28500 (epoch 5.449), train_loss = 1.39981261, grad/param norm = 1.8243e-01, time/batch = 0.6970s	
3107/28500 (epoch 5.451), train_loss = 1.48896167, grad/param norm = 1.8335e-01, time/batch = 0.6956s	
3108/28500 (epoch 5.453), train_loss = 1.50129628, grad/param norm = 2.0151e-01, time/batch = 0.6991s	
3109/28500 (epoch 5.454), train_loss = 1.42018079, grad/param norm = 2.0089e-01, time/batch = 0.6962s	
3110/28500 (epoch 5.456), train_loss = 1.57249120, grad/param norm = 2.0202e-01, time/batch = 0.6962s	
3111/28500 (epoch 5.458), train_loss = 1.43643480, grad/param norm = 1.8820e-01, time/batch = 0.6975s	
3112/28500 (epoch 5.460), train_loss = 1.60067487, grad/param norm = 1.8782e-01, time/batch = 0.7006s	
3113/28500 (epoch 5.461), train_loss = 1.46471175, grad/param norm = 1.9361e-01, time/batch = 0.6972s	
3114/28500 (epoch 5.463), train_loss = 1.35845851, grad/param norm = 1.6314e-01, time/batch = 0.7045s	
3115/28500 (epoch 5.465), train_loss = 1.30599076, grad/param norm = 1.7498e-01, time/batch = 0.6981s	
3116/28500 (epoch 5.467), train_loss = 1.57671040, grad/param norm = 1.9912e-01, time/batch = 0.6967s	
3117/28500 (epoch 5.468), train_loss = 1.29922587, grad/param norm = 1.5513e-01, time/batch = 0.6962s	
3118/28500 (epoch 5.470), train_loss = 1.51442835, grad/param norm = 2.0461e-01, time/batch = 0.6962s	
3119/28500 (epoch 5.472), train_loss = 1.41701924, grad/param norm = 1.7079e-01, time/batch = 0.6956s	
3120/28500 (epoch 5.474), train_loss = 1.74149471, grad/param norm = 2.1558e-01, time/batch = 0.6962s	
3121/28500 (epoch 5.475), train_loss = 1.45486264, grad/param norm = 1.9319e-01, time/batch = 0.6983s	
3122/28500 (epoch 5.477), train_loss = 1.45931987, grad/param norm = 1.8776e-01, time/batch = 0.6986s	
3123/28500 (epoch 5.479), train_loss = 1.48294467, grad/param norm = 1.8368e-01, time/batch = 0.7031s	
3124/28500 (epoch 5.481), train_loss = 1.48973346, grad/param norm = 1.9951e-01, time/batch = 0.6970s	
3125/28500 (epoch 5.482), train_loss = 1.39125849, grad/param norm = 1.9572e-01, time/batch = 0.6981s	
3126/28500 (epoch 5.484), train_loss = 1.40483171, grad/param norm = 2.1262e-01, time/batch = 0.6949s	
3127/28500 (epoch 5.486), train_loss = 1.38182280, grad/param norm = 1.8907e-01, time/batch = 0.6961s	
3128/28500 (epoch 5.488), train_loss = 1.45787939, grad/param norm = 1.8569e-01, time/batch = 0.6997s	
3129/28500 (epoch 5.489), train_loss = 1.57289028, grad/param norm = 2.0375e-01, time/batch = 0.7068s	
3130/28500 (epoch 5.491), train_loss = 1.42640202, grad/param norm = 1.8779e-01, time/batch = 0.7001s	
3131/28500 (epoch 5.493), train_loss = 1.37649731, grad/param norm = 1.6713e-01, time/batch = 0.7009s	
3132/28500 (epoch 5.495), train_loss = 1.45243202, grad/param norm = 1.9143e-01, time/batch = 0.6972s	
3133/28500 (epoch 5.496), train_loss = 1.51421061, grad/param norm = 1.9244e-01, time/batch = 0.6986s	
3134/28500 (epoch 5.498), train_loss = 1.55504994, grad/param norm = 1.9484e-01, time/batch = 0.7019s	
3135/28500 (epoch 5.500), train_loss = 1.50670819, grad/param norm = 1.9570e-01, time/batch = 0.6969s	
3136/28500 (epoch 5.502), train_loss = 1.55623806, grad/param norm = 1.9126e-01, time/batch = 0.6965s	
3137/28500 (epoch 5.504), train_loss = 1.56414546, grad/param norm = 1.8462e-01, time/batch = 0.6970s	
3138/28500 (epoch 5.505), train_loss = 1.40872983, grad/param norm = 1.7548e-01, time/batch = 0.6974s	
3139/28500 (epoch 5.507), train_loss = 1.67624378, grad/param norm = 2.1464e-01, time/batch = 0.7122s	
3140/28500 (epoch 5.509), train_loss = 1.50753868, grad/param norm = 2.1046e-01, time/batch = 0.7287s	
3141/28500 (epoch 5.511), train_loss = 1.52943747, grad/param norm = 1.8980e-01, time/batch = 0.7116s	
3142/28500 (epoch 5.512), train_loss = 1.46897807, grad/param norm = 1.8294e-01, time/batch = 0.7037s	
3143/28500 (epoch 5.514), train_loss = 1.34358821, grad/param norm = 1.8034e-01, time/batch = 0.7022s	
3144/28500 (epoch 5.516), train_loss = 1.37845477, grad/param norm = 1.6805e-01, time/batch = 0.7021s	
3145/28500 (epoch 5.518), train_loss = 1.44640288, grad/param norm = 1.7212e-01, time/batch = 0.6979s	
3146/28500 (epoch 5.519), train_loss = 1.54935093, grad/param norm = 1.9004e-01, time/batch = 0.7008s	
3147/28500 (epoch 5.521), train_loss = 1.67823593, grad/param norm = 1.9501e-01, time/batch = 0.7031s	
3148/28500 (epoch 5.523), train_loss = 1.59080301, grad/param norm = 2.0299e-01, time/batch = 0.7058s	
3149/28500 (epoch 5.525), train_loss = 1.64475508, grad/param norm = 1.9051e-01, time/batch = 0.7007s	
3150/28500 (epoch 5.526), train_loss = 1.52252995, grad/param norm = 1.8781e-01, time/batch = 0.6964s	
3151/28500 (epoch 5.528), train_loss = 1.61256011, grad/param norm = 2.1157e-01, time/batch = 0.6987s	
3152/28500 (epoch 5.530), train_loss = 1.61302806, grad/param norm = 1.7595e-01, time/batch = 0.7015s	
3153/28500 (epoch 5.532), train_loss = 1.44057222, grad/param norm = 1.8584e-01, time/batch = 0.6971s	
3154/28500 (epoch 5.533), train_loss = 1.63769006, grad/param norm = 2.0797e-01, time/batch = 0.6956s	
3155/28500 (epoch 5.535), train_loss = 1.32714800, grad/param norm = 1.7367e-01, time/batch = 0.7016s	
3156/28500 (epoch 5.537), train_loss = 1.27957997, grad/param norm = 1.7591e-01, time/batch = 0.7011s	
3157/28500 (epoch 5.539), train_loss = 1.38538084, grad/param norm = 1.7951e-01, time/batch = 0.7074s	
3158/28500 (epoch 5.540), train_loss = 1.50789812, grad/param norm = 1.8227e-01, time/batch = 0.6993s	
3159/28500 (epoch 5.542), train_loss = 1.72118422, grad/param norm = 2.2251e-01, time/batch = 0.6980s	
3160/28500 (epoch 5.544), train_loss = 1.63653152, grad/param norm = 1.8572e-01, time/batch = 0.6981s	
3161/28500 (epoch 5.546), train_loss = 1.53864848, grad/param norm = 2.0787e-01, time/batch = 0.7003s	
3162/28500 (epoch 5.547), train_loss = 1.52121047, grad/param norm = 1.8376e-01, time/batch = 0.7001s	
3163/28500 (epoch 5.549), train_loss = 1.31925454, grad/param norm = 1.6764e-01, time/batch = 0.6965s	
3164/28500 (epoch 5.551), train_loss = 1.64929475, grad/param norm = 2.0348e-01, time/batch = 0.6989s	
3165/28500 (epoch 5.553), train_loss = 1.73472673, grad/param norm = 2.0025e-01, time/batch = 0.7215s	
3166/28500 (epoch 5.554), train_loss = 1.44624378, grad/param norm = 1.6794e-01, time/batch = 0.6993s	
3167/28500 (epoch 5.556), train_loss = 1.53360950, grad/param norm = 1.9966e-01, time/batch = 0.6970s	
3168/28500 (epoch 5.558), train_loss = 1.53024674, grad/param norm = 1.8239e-01, time/batch = 0.6966s	
3169/28500 (epoch 5.560), train_loss = 1.54996827, grad/param norm = 2.0662e-01, time/batch = 0.6963s	
3170/28500 (epoch 5.561), train_loss = 1.60642878, grad/param norm = 2.2508e-01, time/batch = 0.6972s	
3171/28500 (epoch 5.563), train_loss = 1.62204718, grad/param norm = 2.0484e-01, time/batch = 0.7000s	
3172/28500 (epoch 5.565), train_loss = 1.47023234, grad/param norm = 1.9428e-01, time/batch = 0.6961s	
3173/28500 (epoch 5.567), train_loss = 1.39370541, grad/param norm = 1.9615e-01, time/batch = 0.6962s	
3174/28500 (epoch 5.568), train_loss = 1.55191898, grad/param norm = 2.0196e-01, time/batch = 0.6953s	
3175/28500 (epoch 5.570), train_loss = 1.41032187, grad/param norm = 2.0016e-01, time/batch = 0.6957s	
3176/28500 (epoch 5.572), train_loss = 1.47356975, grad/param norm = 1.9603e-01, time/batch = 0.6965s	
3177/28500 (epoch 5.574), train_loss = 1.53178762, grad/param norm = 1.9640e-01, time/batch = 0.6965s	
3178/28500 (epoch 5.575), train_loss = 1.41074261, grad/param norm = 1.8580e-01, time/batch = 0.6955s	
3179/28500 (epoch 5.577), train_loss = 1.46758579, grad/param norm = 1.7737e-01, time/batch = 0.6972s	
3180/28500 (epoch 5.579), train_loss = 1.65934725, grad/param norm = 2.2606e-01, time/batch = 0.6952s	
3181/28500 (epoch 5.581), train_loss = 1.45409902, grad/param norm = 1.8275e-01, time/batch = 0.6989s	
3182/28500 (epoch 5.582), train_loss = 1.56410035, grad/param norm = 1.9649e-01, time/batch = 0.6984s	
3183/28500 (epoch 5.584), train_loss = 1.41350889, grad/param norm = 1.7093e-01, time/batch = 0.6981s	
3184/28500 (epoch 5.586), train_loss = 1.32385983, grad/param norm = 1.5990e-01, time/batch = 0.6981s	
3185/28500 (epoch 5.588), train_loss = 1.38965816, grad/param norm = 1.7692e-01, time/batch = 0.6970s	
3186/28500 (epoch 5.589), train_loss = 1.71751824, grad/param norm = 1.9603e-01, time/batch = 0.6965s	
3187/28500 (epoch 5.591), train_loss = 1.55043180, grad/param norm = 1.7311e-01, time/batch = 0.6975s	
3188/28500 (epoch 5.593), train_loss = 1.41879947, grad/param norm = 1.7837e-01, time/batch = 0.6964s	
3189/28500 (epoch 5.595), train_loss = 1.74941306, grad/param norm = 2.3765e-01, time/batch = 0.6961s	
3190/28500 (epoch 5.596), train_loss = 1.66840209, grad/param norm = 2.1123e-01, time/batch = 0.6947s	
3191/28500 (epoch 5.598), train_loss = 1.48344926, grad/param norm = 1.7242e-01, time/batch = 0.7007s	
3192/28500 (epoch 5.600), train_loss = 1.54572040, grad/param norm = 1.9864e-01, time/batch = 0.7007s	
3193/28500 (epoch 5.602), train_loss = 1.70304401, grad/param norm = 1.9390e-01, time/batch = 0.7013s	
3194/28500 (epoch 5.604), train_loss = 1.55799970, grad/param norm = 1.8420e-01, time/batch = 0.6973s	
3195/28500 (epoch 5.605), train_loss = 1.51409762, grad/param norm = 1.9458e-01, time/batch = 0.6958s	
3196/28500 (epoch 5.607), train_loss = 1.52631786, grad/param norm = 1.8018e-01, time/batch = 0.7083s	
3197/28500 (epoch 5.609), train_loss = 1.51642107, grad/param norm = 1.9587e-01, time/batch = 0.6960s	
3198/28500 (epoch 5.611), train_loss = 1.52913836, grad/param norm = 1.9568e-01, time/batch = 0.6942s	
3199/28500 (epoch 5.612), train_loss = 1.53349033, grad/param norm = 1.7745e-01, time/batch = 0.6958s	
3200/28500 (epoch 5.614), train_loss = 1.49704843, grad/param norm = 1.9110e-01, time/batch = 0.6946s	
3201/28500 (epoch 5.616), train_loss = 1.49363480, grad/param norm = 2.0071e-01, time/batch = 0.7036s	
3202/28500 (epoch 5.618), train_loss = 1.40313433, grad/param norm = 1.7737e-01, time/batch = 0.7115s	
3203/28500 (epoch 5.619), train_loss = 1.69582162, grad/param norm = 2.0813e-01, time/batch = 0.6952s	
3204/28500 (epoch 5.621), train_loss = 1.23618219, grad/param norm = 1.6080e-01, time/batch = 0.6970s	
3205/28500 (epoch 5.623), train_loss = 1.52902745, grad/param norm = 1.9158e-01, time/batch = 0.6960s	
3206/28500 (epoch 5.625), train_loss = 1.34200111, grad/param norm = 1.8685e-01, time/batch = 0.6938s	
3207/28500 (epoch 5.626), train_loss = 1.22818995, grad/param norm = 1.6647e-01, time/batch = 0.6931s	
3208/28500 (epoch 5.628), train_loss = 1.37967679, grad/param norm = 1.8789e-01, time/batch = 0.6973s	
3209/28500 (epoch 5.630), train_loss = 1.33506623, grad/param norm = 1.6714e-01, time/batch = 0.6959s	
3210/28500 (epoch 5.632), train_loss = 1.56861430, grad/param norm = 1.8693e-01, time/batch = 0.6945s	
3211/28500 (epoch 5.633), train_loss = 1.53533212, grad/param norm = 1.7764e-01, time/batch = 0.6946s	
3212/28500 (epoch 5.635), train_loss = 1.63858036, grad/param norm = 1.8988e-01, time/batch = 0.6937s	
3213/28500 (epoch 5.637), train_loss = 1.49936958, grad/param norm = 1.8010e-01, time/batch = 0.6986s	
3214/28500 (epoch 5.639), train_loss = 1.27216875, grad/param norm = 1.7167e-01, time/batch = 0.6964s	
3215/28500 (epoch 5.640), train_loss = 1.39430431, grad/param norm = 1.8337e-01, time/batch = 0.6930s	
3216/28500 (epoch 5.642), train_loss = 1.54372068, grad/param norm = 1.7972e-01, time/batch = 0.6938s	
3217/28500 (epoch 5.644), train_loss = 1.56033196, grad/param norm = 1.8192e-01, time/batch = 0.6954s	
3218/28500 (epoch 5.646), train_loss = 1.38946938, grad/param norm = 1.6493e-01, time/batch = 0.6947s	
3219/28500 (epoch 5.647), train_loss = 1.37270824, grad/param norm = 1.8638e-01, time/batch = 0.6960s	
3220/28500 (epoch 5.649), train_loss = 1.39667063, grad/param norm = 1.7316e-01, time/batch = 0.6976s	
3221/28500 (epoch 5.651), train_loss = 1.36312657, grad/param norm = 1.8085e-01, time/batch = 0.7038s	
3222/28500 (epoch 5.653), train_loss = 1.36247787, grad/param norm = 1.7074e-01, time/batch = 0.6941s	
3223/28500 (epoch 5.654), train_loss = 1.41301419, grad/param norm = 1.8448e-01, time/batch = 0.7027s	
3224/28500 (epoch 5.656), train_loss = 1.46363274, grad/param norm = 1.8482e-01, time/batch = 0.7114s	
3225/28500 (epoch 5.658), train_loss = 1.52049466, grad/param norm = 1.9085e-01, time/batch = 0.6936s	
3226/28500 (epoch 5.660), train_loss = 1.44021930, grad/param norm = 1.5902e-01, time/batch = 0.7009s	
3227/28500 (epoch 5.661), train_loss = 1.60466497, grad/param norm = 1.9841e-01, time/batch = 0.7001s	
3228/28500 (epoch 5.663), train_loss = 1.68391028, grad/param norm = 1.9560e-01, time/batch = 0.6926s	
3229/28500 (epoch 5.665), train_loss = 1.45215290, grad/param norm = 1.8003e-01, time/batch = 0.6928s	
3230/28500 (epoch 5.667), train_loss = 1.53822887, grad/param norm = 1.8906e-01, time/batch = 0.6924s	
3231/28500 (epoch 5.668), train_loss = 1.45557820, grad/param norm = 1.7728e-01, time/batch = 0.6948s	
3232/28500 (epoch 5.670), train_loss = 1.44585061, grad/param norm = 1.8903e-01, time/batch = 0.6946s	
3233/28500 (epoch 5.672), train_loss = 1.46493102, grad/param norm = 1.7244e-01, time/batch = 0.6951s	
3234/28500 (epoch 5.674), train_loss = 1.33381366, grad/param norm = 2.0081e-01, time/batch = 0.6946s	
3235/28500 (epoch 5.675), train_loss = 1.31780710, grad/param norm = 1.7511e-01, time/batch = 0.6926s	
3236/28500 (epoch 5.677), train_loss = 1.42850390, grad/param norm = 1.8688e-01, time/batch = 0.6938s	
3237/28500 (epoch 5.679), train_loss = 1.49209779, grad/param norm = 1.9393e-01, time/batch = 0.6944s	
3238/28500 (epoch 5.681), train_loss = 1.57998179, grad/param norm = 1.9932e-01, time/batch = 0.6922s	
3239/28500 (epoch 5.682), train_loss = 1.39156579, grad/param norm = 1.8635e-01, time/batch = 0.6936s	
3240/28500 (epoch 5.684), train_loss = 1.50687254, grad/param norm = 1.8181e-01, time/batch = 0.6925s	
3241/28500 (epoch 5.686), train_loss = 1.41467416, grad/param norm = 2.0377e-01, time/batch = 0.6968s	
3242/28500 (epoch 5.688), train_loss = 1.43889738, grad/param norm = 1.7549e-01, time/batch = 0.6975s	
3243/28500 (epoch 5.689), train_loss = 1.51547134, grad/param norm = 2.0107e-01, time/batch = 0.6977s	
3244/28500 (epoch 5.691), train_loss = 1.47819395, grad/param norm = 1.9052e-01, time/batch = 0.6954s	
3245/28500 (epoch 5.693), train_loss = 1.46977946, grad/param norm = 1.9682e-01, time/batch = 0.6948s	
3246/28500 (epoch 5.695), train_loss = 1.43038359, grad/param norm = 2.0630e-01, time/batch = 0.7092s	
3247/28500 (epoch 5.696), train_loss = 1.49397523, grad/param norm = 2.1449e-01, time/batch = 0.6994s	
3248/28500 (epoch 5.698), train_loss = 1.46526383, grad/param norm = 1.7653e-01, time/batch = 0.6953s	
3249/28500 (epoch 5.700), train_loss = 1.46485818, grad/param norm = 1.9127e-01, time/batch = 0.7001s	
3250/28500 (epoch 5.702), train_loss = 1.65091390, grad/param norm = 1.9302e-01, time/batch = 0.6986s	
3251/28500 (epoch 5.704), train_loss = 1.52536573, grad/param norm = 2.0043e-01, time/batch = 0.7014s	
3252/28500 (epoch 5.705), train_loss = 1.55209562, grad/param norm = 1.8840e-01, time/batch = 0.6944s	
3253/28500 (epoch 5.707), train_loss = 1.47195604, grad/param norm = 2.0087e-01, time/batch = 0.6962s	
3254/28500 (epoch 5.709), train_loss = 1.56068751, grad/param norm = 1.9047e-01, time/batch = 0.6982s	
3255/28500 (epoch 5.711), train_loss = 1.41271173, grad/param norm = 2.0485e-01, time/batch = 0.6961s	
3256/28500 (epoch 5.712), train_loss = 1.56378515, grad/param norm = 2.1176e-01, time/batch = 0.6938s	
3257/28500 (epoch 5.714), train_loss = 1.52582295, grad/param norm = 1.8041e-01, time/batch = 0.6928s	
3258/28500 (epoch 5.716), train_loss = 1.45625359, grad/param norm = 1.8973e-01, time/batch = 0.6937s	
3259/28500 (epoch 5.718), train_loss = 1.37805832, grad/param norm = 1.9002e-01, time/batch = 0.6974s	
3260/28500 (epoch 5.719), train_loss = 1.39089685, grad/param norm = 1.7604e-01, time/batch = 0.6964s	
3261/28500 (epoch 5.721), train_loss = 1.22188906, grad/param norm = 1.7700e-01, time/batch = 0.6957s	
3262/28500 (epoch 5.723), train_loss = 1.47100188, grad/param norm = 1.7452e-01, time/batch = 0.6932s	
3263/28500 (epoch 5.725), train_loss = 1.56195859, grad/param norm = 1.7376e-01, time/batch = 0.6937s	
3264/28500 (epoch 5.726), train_loss = 1.47606726, grad/param norm = 1.8644e-01, time/batch = 0.6930s	
3265/28500 (epoch 5.728), train_loss = 1.31557827, grad/param norm = 1.6727e-01, time/batch = 0.6959s	
3266/28500 (epoch 5.730), train_loss = 1.47650395, grad/param norm = 1.9026e-01, time/batch = 0.6965s	
3267/28500 (epoch 5.732), train_loss = 1.29118843, grad/param norm = 1.9172e-01, time/batch = 0.6973s	
3268/28500 (epoch 5.733), train_loss = 1.29874229, grad/param norm = 1.8206e-01, time/batch = 0.6945s	
3269/28500 (epoch 5.735), train_loss = 1.29409608, grad/param norm = 1.5814e-01, time/batch = 0.6972s	
3270/28500 (epoch 5.737), train_loss = 1.25738001, grad/param norm = 1.6989e-01, time/batch = 0.6972s	
3271/28500 (epoch 5.739), train_loss = 1.47716550, grad/param norm = 1.8534e-01, time/batch = 0.6994s	
3272/28500 (epoch 5.740), train_loss = 1.45719319, grad/param norm = 1.8777e-01, time/batch = 0.6980s	
3273/28500 (epoch 5.742), train_loss = 1.41700117, grad/param norm = 1.8704e-01, time/batch = 0.6972s	
3274/28500 (epoch 5.744), train_loss = 1.55072286, grad/param norm = 1.8321e-01, time/batch = 0.6965s	
3275/28500 (epoch 5.746), train_loss = 1.34762914, grad/param norm = 1.6275e-01, time/batch = 0.6968s	
3276/28500 (epoch 5.747), train_loss = 1.35249948, grad/param norm = 1.7462e-01, time/batch = 0.6955s	
3277/28500 (epoch 5.749), train_loss = 1.67006818, grad/param norm = 1.9829e-01, time/batch = 0.6969s	
3278/28500 (epoch 5.751), train_loss = 1.38475927, grad/param norm = 1.8140e-01, time/batch = 0.6954s	
3279/28500 (epoch 5.753), train_loss = 1.32091210, grad/param norm = 1.6362e-01, time/batch = 0.6976s	
3280/28500 (epoch 5.754), train_loss = 1.27642788, grad/param norm = 1.6278e-01, time/batch = 0.6967s	
3281/28500 (epoch 5.756), train_loss = 1.56979920, grad/param norm = 1.8215e-01, time/batch = 0.7004s	
3282/28500 (epoch 5.758), train_loss = 1.48095480, grad/param norm = 1.9000e-01, time/batch = 0.6980s	
3283/28500 (epoch 5.760), train_loss = 1.36095664, grad/param norm = 1.8715e-01, time/batch = 0.6959s	
3284/28500 (epoch 5.761), train_loss = 1.39302547, grad/param norm = 1.8827e-01, time/batch = 0.6969s	
3285/28500 (epoch 5.763), train_loss = 1.21389463, grad/param norm = 1.7578e-01, time/batch = 0.6986s	
3286/28500 (epoch 5.765), train_loss = 1.37214451, grad/param norm = 1.6557e-01, time/batch = 0.6990s	
3287/28500 (epoch 5.767), train_loss = 1.21534159, grad/param norm = 1.6901e-01, time/batch = 0.7002s	
3288/28500 (epoch 5.768), train_loss = 1.59515438, grad/param norm = 2.0693e-01, time/batch = 0.6979s	
3289/28500 (epoch 5.770), train_loss = 1.28483370, grad/param norm = 1.8976e-01, time/batch = 0.6985s	
3290/28500 (epoch 5.772), train_loss = 1.22733149, grad/param norm = 1.8538e-01, time/batch = 0.6979s	
3291/28500 (epoch 5.774), train_loss = 1.49047105, grad/param norm = 1.8971e-01, time/batch = 0.6991s	
3292/28500 (epoch 5.775), train_loss = 1.53456133, grad/param norm = 1.7420e-01, time/batch = 0.7227s	
3293/28500 (epoch 5.777), train_loss = 1.46684458, grad/param norm = 1.8658e-01, time/batch = 0.6973s	
3294/28500 (epoch 5.779), train_loss = 1.32015552, grad/param norm = 1.7031e-01, time/batch = 0.7006s	
3295/28500 (epoch 5.781), train_loss = 1.52701411, grad/param norm = 2.0230e-01, time/batch = 0.7006s	
3296/28500 (epoch 5.782), train_loss = 1.61408012, grad/param norm = 2.0019e-01, time/batch = 0.7026s	
3297/28500 (epoch 5.784), train_loss = 1.23690639, grad/param norm = 1.7011e-01, time/batch = 0.6998s	
3298/28500 (epoch 5.786), train_loss = 1.41578163, grad/param norm = 1.7636e-01, time/batch = 0.6985s	
3299/28500 (epoch 5.788), train_loss = 1.54323111, grad/param norm = 1.9893e-01, time/batch = 0.7069s	
3300/28500 (epoch 5.789), train_loss = 1.21084859, grad/param norm = 1.7401e-01, time/batch = 0.6957s	
3301/28500 (epoch 5.791), train_loss = 1.43504610, grad/param norm = 1.9171e-01, time/batch = 0.7001s	
3302/28500 (epoch 5.793), train_loss = 1.32644997, grad/param norm = 1.9739e-01, time/batch = 0.6972s	
3303/28500 (epoch 5.795), train_loss = 1.46188785, grad/param norm = 1.8278e-01, time/batch = 0.6982s	
3304/28500 (epoch 5.796), train_loss = 1.34080035, grad/param norm = 1.6704e-01, time/batch = 0.6987s	
3305/28500 (epoch 5.798), train_loss = 1.31295489, grad/param norm = 1.6888e-01, time/batch = 0.6971s	
3306/28500 (epoch 5.800), train_loss = 1.36682171, grad/param norm = 1.8439e-01, time/batch = 0.6976s	
3307/28500 (epoch 5.802), train_loss = 1.47827099, grad/param norm = 2.0249e-01, time/batch = 0.6983s	
3308/28500 (epoch 5.804), train_loss = 1.45620379, grad/param norm = 1.8407e-01, time/batch = 0.6998s	
3309/28500 (epoch 5.805), train_loss = 1.48877715, grad/param norm = 1.8480e-01, time/batch = 0.6975s	
3310/28500 (epoch 5.807), train_loss = 1.59459353, grad/param norm = 1.9693e-01, time/batch = 0.6968s	
3311/28500 (epoch 5.809), train_loss = 1.39216833, grad/param norm = 1.7321e-01, time/batch = 0.6994s	
3312/28500 (epoch 5.811), train_loss = 1.58041678, grad/param norm = 2.0982e-01, time/batch = 0.7019s	
3313/28500 (epoch 5.812), train_loss = 1.51945385, grad/param norm = 1.8203e-01, time/batch = 0.6961s	
3314/28500 (epoch 5.814), train_loss = 1.41602411, grad/param norm = 1.8660e-01, time/batch = 0.6971s	
3315/28500 (epoch 5.816), train_loss = 1.60969242, grad/param norm = 1.9617e-01, time/batch = 0.6955s	
3316/28500 (epoch 5.818), train_loss = 1.48402170, grad/param norm = 1.8269e-01, time/batch = 0.6965s	
3317/28500 (epoch 5.819), train_loss = 1.43694675, grad/param norm = 1.8477e-01, time/batch = 0.6952s	
3318/28500 (epoch 5.821), train_loss = 1.36436501, grad/param norm = 1.6887e-01, time/batch = 0.6969s	
3319/28500 (epoch 5.823), train_loss = 1.70780066, grad/param norm = 2.1708e-01, time/batch = 0.7014s	
3320/28500 (epoch 5.825), train_loss = 1.43235282, grad/param norm = 1.9624e-01, time/batch = 0.7019s	
3321/28500 (epoch 5.826), train_loss = 1.51417064, grad/param norm = 2.0877e-01, time/batch = 0.7035s	
3322/28500 (epoch 5.828), train_loss = 1.33230719, grad/param norm = 2.0383e-01, time/batch = 0.7012s	
3323/28500 (epoch 5.830), train_loss = 1.36557884, grad/param norm = 1.5678e-01, time/batch = 0.6994s	
3324/28500 (epoch 5.832), train_loss = 1.46341101, grad/param norm = 1.8481e-01, time/batch = 0.6989s	
3325/28500 (epoch 5.833), train_loss = 1.61600409, grad/param norm = 1.7833e-01, time/batch = 0.6987s	
3326/28500 (epoch 5.835), train_loss = 1.40975107, grad/param norm = 1.9134e-01, time/batch = 0.6980s	
3327/28500 (epoch 5.837), train_loss = 1.30328499, grad/param norm = 1.7145e-01, time/batch = 0.7000s	
3328/28500 (epoch 5.839), train_loss = 1.59439121, grad/param norm = 1.9377e-01, time/batch = 0.7107s	
3329/28500 (epoch 5.840), train_loss = 1.57583885, grad/param norm = 2.0153e-01, time/batch = 0.6967s	
3330/28500 (epoch 5.842), train_loss = 1.48332257, grad/param norm = 1.7271e-01, time/batch = 0.7170s	
3331/28500 (epoch 5.844), train_loss = 1.48126035, grad/param norm = 1.8642e-01, time/batch = 0.7138s	
3332/28500 (epoch 5.846), train_loss = 1.58116503, grad/param norm = 1.8074e-01, time/batch = 0.7046s	
3333/28500 (epoch 5.847), train_loss = 1.41056899, grad/param norm = 1.7689e-01, time/batch = 0.6975s	
3334/28500 (epoch 5.849), train_loss = 1.37234478, grad/param norm = 1.6254e-01, time/batch = 0.6972s	
3335/28500 (epoch 5.851), train_loss = 1.27247154, grad/param norm = 1.7074e-01, time/batch = 0.7043s	
3336/28500 (epoch 5.853), train_loss = 1.46417417, grad/param norm = 1.8365e-01, time/batch = 0.6979s	
3337/28500 (epoch 5.854), train_loss = 1.43816795, grad/param norm = 1.8980e-01, time/batch = 0.6969s	
3338/28500 (epoch 5.856), train_loss = 1.52399300, grad/param norm = 1.8453e-01, time/batch = 0.6960s	
3339/28500 (epoch 5.858), train_loss = 1.27455783, grad/param norm = 1.6329e-01, time/batch = 0.6980s	
3340/28500 (epoch 5.860), train_loss = 1.54168227, grad/param norm = 1.9082e-01, time/batch = 0.6990s	
3341/28500 (epoch 5.861), train_loss = 1.42458171, grad/param norm = 1.9099e-01, time/batch = 0.7010s	
3342/28500 (epoch 5.863), train_loss = 1.57787743, grad/param norm = 1.9236e-01, time/batch = 0.7019s	
3343/28500 (epoch 5.865), train_loss = 1.44408461, grad/param norm = 1.9330e-01, time/batch = 0.6976s	
3344/28500 (epoch 5.867), train_loss = 1.52391466, grad/param norm = 1.9235e-01, time/batch = 0.6968s	
3345/28500 (epoch 5.868), train_loss = 1.32030136, grad/param norm = 1.9052e-01, time/batch = 0.6966s	
3346/28500 (epoch 5.870), train_loss = 1.20703262, grad/param norm = 1.5422e-01, time/batch = 0.6975s	
3347/28500 (epoch 5.872), train_loss = 1.53940664, grad/param norm = 1.9102e-01, time/batch = 0.6969s	
3348/28500 (epoch 5.874), train_loss = 1.44824226, grad/param norm = 1.8965e-01, time/batch = 0.6966s	
3349/28500 (epoch 5.875), train_loss = 1.53950029, grad/param norm = 1.8799e-01, time/batch = 0.6973s	
3350/28500 (epoch 5.877), train_loss = 1.44181811, grad/param norm = 2.0061e-01, time/batch = 0.6975s	
3351/28500 (epoch 5.879), train_loss = 1.41107479, grad/param norm = 1.8123e-01, time/batch = 0.7050s	
3352/28500 (epoch 5.881), train_loss = 1.51109422, grad/param norm = 1.8075e-01, time/batch = 0.7001s	
3353/28500 (epoch 5.882), train_loss = 1.42230560, grad/param norm = 1.8110e-01, time/batch = 0.6976s	
3354/28500 (epoch 5.884), train_loss = 1.50867951, grad/param norm = 1.9829e-01, time/batch = 0.6993s	
3355/28500 (epoch 5.886), train_loss = 1.32983336, grad/param norm = 1.7680e-01, time/batch = 0.7021s	
3356/28500 (epoch 5.888), train_loss = 1.30705659, grad/param norm = 1.6696e-01, time/batch = 0.6996s	
3357/28500 (epoch 5.889), train_loss = 1.36350157, grad/param norm = 1.6652e-01, time/batch = 0.6972s	
3358/28500 (epoch 5.891), train_loss = 1.45552530, grad/param norm = 1.7039e-01, time/batch = 0.6983s	
3359/28500 (epoch 5.893), train_loss = 1.40455131, grad/param norm = 2.0528e-01, time/batch = 0.6974s	
3360/28500 (epoch 5.895), train_loss = 1.64559375, grad/param norm = 2.0260e-01, time/batch = 0.6957s	
3361/28500 (epoch 5.896), train_loss = 1.57292840, grad/param norm = 2.0279e-01, time/batch = 0.6987s	
3362/28500 (epoch 5.898), train_loss = 1.40427753, grad/param norm = 1.7572e-01, time/batch = 0.6972s	
3363/28500 (epoch 5.900), train_loss = 1.29674734, grad/param norm = 1.7886e-01, time/batch = 0.7038s	
3364/28500 (epoch 5.902), train_loss = 1.32558101, grad/param norm = 1.6908e-01, time/batch = 0.6982s	
3365/28500 (epoch 5.904), train_loss = 1.30364155, grad/param norm = 1.6135e-01, time/batch = 0.6992s	
3366/28500 (epoch 5.905), train_loss = 1.45660753, grad/param norm = 1.7175e-01, time/batch = 0.6964s	
3367/28500 (epoch 5.907), train_loss = 1.57336025, grad/param norm = 2.0227e-01, time/batch = 0.6970s	
3368/28500 (epoch 5.909), train_loss = 1.35534146, grad/param norm = 1.8194e-01, time/batch = 0.6966s	
3369/28500 (epoch 5.911), train_loss = 1.35252963, grad/param norm = 1.7753e-01, time/batch = 0.6963s	
3370/28500 (epoch 5.912), train_loss = 1.15174055, grad/param norm = 1.8199e-01, time/batch = 0.6971s	
3371/28500 (epoch 5.914), train_loss = 1.56275677, grad/param norm = 1.8757e-01, time/batch = 0.6981s	
3372/28500 (epoch 5.916), train_loss = 1.50244909, grad/param norm = 1.8512e-01, time/batch = 0.6979s	
3373/28500 (epoch 5.918), train_loss = 1.45899550, grad/param norm = 1.9008e-01, time/batch = 0.6987s	
3374/28500 (epoch 5.919), train_loss = 1.36592111, grad/param norm = 1.6704e-01, time/batch = 0.7005s	
3375/28500 (epoch 5.921), train_loss = 1.65547345, grad/param norm = 2.2041e-01, time/batch = 0.6973s	
3376/28500 (epoch 5.923), train_loss = 1.52670492, grad/param norm = 2.2230e-01, time/batch = 0.6965s	
3377/28500 (epoch 5.925), train_loss = 1.33480150, grad/param norm = 1.9014e-01, time/batch = 0.6965s	
3378/28500 (epoch 5.926), train_loss = 1.47004337, grad/param norm = 2.0216e-01, time/batch = 0.6952s	
3379/28500 (epoch 5.928), train_loss = 1.34681630, grad/param norm = 1.7904e-01, time/batch = 0.6978s	
3380/28500 (epoch 5.930), train_loss = 1.11734259, grad/param norm = 1.6164e-01, time/batch = 0.6968s	
3381/28500 (epoch 5.932), train_loss = 1.25721997, grad/param norm = 1.5598e-01, time/batch = 0.6997s	
3382/28500 (epoch 5.933), train_loss = 1.45860790, grad/param norm = 1.7623e-01, time/batch = 0.6995s	
3383/28500 (epoch 5.935), train_loss = 1.46240410, grad/param norm = 2.0978e-01, time/batch = 0.6989s	
3384/28500 (epoch 5.937), train_loss = 1.60439448, grad/param norm = 1.9534e-01, time/batch = 0.6979s	
3385/28500 (epoch 5.939), train_loss = 1.67222961, grad/param norm = 1.8370e-01, time/batch = 0.6969s	
3386/28500 (epoch 5.940), train_loss = 1.35928568, grad/param norm = 1.7348e-01, time/batch = 0.6992s	
3387/28500 (epoch 5.942), train_loss = 1.54554363, grad/param norm = 1.8393e-01, time/batch = 0.7012s	
3388/28500 (epoch 5.944), train_loss = 1.47644015, grad/param norm = 1.8035e-01, time/batch = 0.6971s	
3389/28500 (epoch 5.946), train_loss = 1.57553138, grad/param norm = 1.7964e-01, time/batch = 0.6968s	
3390/28500 (epoch 5.947), train_loss = 1.82489757, grad/param norm = 2.1594e-01, time/batch = 0.6981s	
3391/28500 (epoch 5.949), train_loss = 1.32934647, grad/param norm = 1.9617e-01, time/batch = 0.7005s	
3392/28500 (epoch 5.951), train_loss = 1.64331550, grad/param norm = 2.0573e-01, time/batch = 0.6975s	
3393/28500 (epoch 5.953), train_loss = 1.66630612, grad/param norm = 2.2868e-01, time/batch = 0.6972s	
3394/28500 (epoch 5.954), train_loss = 1.54616665, grad/param norm = 1.9822e-01, time/batch = 0.6971s	
3395/28500 (epoch 5.956), train_loss = 1.53661543, grad/param norm = 2.1775e-01, time/batch = 0.6970s	
3396/28500 (epoch 5.958), train_loss = 1.55120403, grad/param norm = 1.9780e-01, time/batch = 0.6987s	
3397/28500 (epoch 5.960), train_loss = 1.36415651, grad/param norm = 1.8831e-01, time/batch = 0.6986s	
3398/28500 (epoch 5.961), train_loss = 1.69471684, grad/param norm = 2.0156e-01, time/batch = 0.6975s	
3399/28500 (epoch 5.963), train_loss = 1.52688952, grad/param norm = 1.5753e-01, time/batch = 0.6984s	
3400/28500 (epoch 5.965), train_loss = 1.32039678, grad/param norm = 1.6553e-01, time/batch = 0.6977s	
3401/28500 (epoch 5.967), train_loss = 1.29355209, grad/param norm = 1.7421e-01, time/batch = 0.7036s	
3402/28500 (epoch 5.968), train_loss = 1.24286701, grad/param norm = 1.6097e-01, time/batch = 0.6990s	
3403/28500 (epoch 5.970), train_loss = 1.50830139, grad/param norm = 1.9069e-01, time/batch = 0.6990s	
3404/28500 (epoch 5.972), train_loss = 1.69303916, grad/param norm = 2.0816e-01, time/batch = 0.6987s	
3405/28500 (epoch 5.974), train_loss = 1.72013001, grad/param norm = 1.9341e-01, time/batch = 0.7002s	
3406/28500 (epoch 5.975), train_loss = 1.41046336, grad/param norm = 1.8769e-01, time/batch = 0.6981s	
3407/28500 (epoch 5.977), train_loss = 1.66492173, grad/param norm = 1.8756e-01, time/batch = 0.7024s	
3408/28500 (epoch 5.979), train_loss = 1.35690842, grad/param norm = 1.7291e-01, time/batch = 0.7002s	
3409/28500 (epoch 5.981), train_loss = 1.40637204, grad/param norm = 1.8187e-01, time/batch = 0.6997s	
3410/28500 (epoch 5.982), train_loss = 1.31704088, grad/param norm = 1.7067e-01, time/batch = 0.6974s	
3411/28500 (epoch 5.984), train_loss = 1.51148378, grad/param norm = 1.7720e-01, time/batch = 0.7027s	
3412/28500 (epoch 5.986), train_loss = 1.63231814, grad/param norm = 1.9658e-01, time/batch = 0.7095s	
3413/28500 (epoch 5.988), train_loss = 1.25148141, grad/param norm = 1.8067e-01, time/batch = 0.7072s	
3414/28500 (epoch 5.989), train_loss = 1.50823351, grad/param norm = 1.8772e-01, time/batch = 0.7150s	
3415/28500 (epoch 5.991), train_loss = 1.38004631, grad/param norm = 1.9130e-01, time/batch = 0.7051s	
3416/28500 (epoch 5.993), train_loss = 1.39243317, grad/param norm = 1.8826e-01, time/batch = 0.7133s	
3417/28500 (epoch 5.995), train_loss = 1.40369833, grad/param norm = 1.8704e-01, time/batch = 0.6965s	
3418/28500 (epoch 5.996), train_loss = 1.33760321, grad/param norm = 1.6559e-01, time/batch = 0.6999s	
3419/28500 (epoch 5.998), train_loss = 1.54849561, grad/param norm = 1.8655e-01, time/batch = 0.7095s	
3420/28500 (epoch 6.000), train_loss = 1.38468228, grad/param norm = 1.7132e-01, time/batch = 0.6973s	
3421/28500 (epoch 6.002), train_loss = 1.55428195, grad/param norm = 1.8280e-01, time/batch = 0.6982s	
3422/28500 (epoch 6.004), train_loss = 1.36601945, grad/param norm = 1.8334e-01, time/batch = 0.6970s	
3423/28500 (epoch 6.005), train_loss = 1.51966887, grad/param norm = 1.9170e-01, time/batch = 0.7024s	
3424/28500 (epoch 6.007), train_loss = 1.26434579, grad/param norm = 1.6662e-01, time/batch = 0.6958s	
3425/28500 (epoch 6.009), train_loss = 1.55466740, grad/param norm = 1.9749e-01, time/batch = 0.6825s	
3426/28500 (epoch 6.011), train_loss = 1.43714418, grad/param norm = 2.0177e-01, time/batch = 0.6826s	
3427/28500 (epoch 6.012), train_loss = 1.25290987, grad/param norm = 1.5495e-01, time/batch = 0.6899s	
3428/28500 (epoch 6.014), train_loss = 1.31289826, grad/param norm = 1.6552e-01, time/batch = 0.6851s	
3429/28500 (epoch 6.016), train_loss = 1.36695934, grad/param norm = 1.6261e-01, time/batch = 0.6874s	
3430/28500 (epoch 6.018), train_loss = 1.43595624, grad/param norm = 1.8015e-01, time/batch = 0.6841s	
3431/28500 (epoch 6.019), train_loss = 1.49668217, grad/param norm = 1.9297e-01, time/batch = 0.6876s	
3432/28500 (epoch 6.021), train_loss = 1.44243086, grad/param norm = 1.8244e-01, time/batch = 0.6904s	
3433/28500 (epoch 6.023), train_loss = 1.43124857, grad/param norm = 1.8734e-01, time/batch = 0.6918s	
3434/28500 (epoch 6.025), train_loss = 1.41551368, grad/param norm = 1.8056e-01, time/batch = 0.7046s	
3435/28500 (epoch 6.026), train_loss = 1.48429110, grad/param norm = 1.8884e-01, time/batch = 0.6959s	
3436/28500 (epoch 6.028), train_loss = 1.52516006, grad/param norm = 1.9327e-01, time/batch = 0.6950s	
3437/28500 (epoch 6.030), train_loss = 1.55237604, grad/param norm = 2.1443e-01, time/batch = 0.6908s	
3438/28500 (epoch 6.032), train_loss = 1.53432816, grad/param norm = 1.9076e-01, time/batch = 0.6932s	
3439/28500 (epoch 6.033), train_loss = 1.63401968, grad/param norm = 1.9257e-01, time/batch = 0.6831s	
3440/28500 (epoch 6.035), train_loss = 1.51052601, grad/param norm = 2.0383e-01, time/batch = 0.6837s	
3441/28500 (epoch 6.037), train_loss = 1.51732624, grad/param norm = 1.7691e-01, time/batch = 0.6816s	
3442/28500 (epoch 6.039), train_loss = 1.63060876, grad/param norm = 2.1505e-01, time/batch = 0.6816s	
3443/28500 (epoch 6.040), train_loss = 1.59789735, grad/param norm = 1.8416e-01, time/batch = 0.6878s	
3444/28500 (epoch 6.042), train_loss = 1.57697775, grad/param norm = 1.8971e-01, time/batch = 0.6877s	
3445/28500 (epoch 6.044), train_loss = 1.48493544, grad/param norm = 2.0659e-01, time/batch = 0.7001s	
3446/28500 (epoch 6.046), train_loss = 1.64359353, grad/param norm = 1.8950e-01, time/batch = 0.6855s	
3447/28500 (epoch 6.047), train_loss = 1.58932528, grad/param norm = 2.0374e-01, time/batch = 0.6829s	
3448/28500 (epoch 6.049), train_loss = 1.51261175, grad/param norm = 2.0212e-01, time/batch = 0.6858s	
3449/28500 (epoch 6.051), train_loss = 1.42851184, grad/param norm = 1.6821e-01, time/batch = 0.6860s	
3450/28500 (epoch 6.053), train_loss = 1.54329049, grad/param norm = 1.8308e-01, time/batch = 0.6804s	
3451/28500 (epoch 6.054), train_loss = 1.56217591, grad/param norm = 1.8056e-01, time/batch = 0.6815s	
3452/28500 (epoch 6.056), train_loss = 1.30994598, grad/param norm = 1.6606e-01, time/batch = 0.6866s	
3453/28500 (epoch 6.058), train_loss = 1.32769073, grad/param norm = 1.8450e-01, time/batch = 0.6816s	
3454/28500 (epoch 6.060), train_loss = 1.50031455, grad/param norm = 1.8721e-01, time/batch = 0.6822s	
3455/28500 (epoch 6.061), train_loss = 1.55490872, grad/param norm = 2.1237e-01, time/batch = 0.6826s	
3456/28500 (epoch 6.063), train_loss = 1.57056212, grad/param norm = 1.7831e-01, time/batch = 0.6857s	
3457/28500 (epoch 6.065), train_loss = 1.66123758, grad/param norm = 1.8382e-01, time/batch = 0.6814s	
3458/28500 (epoch 6.067), train_loss = 1.36516910, grad/param norm = 1.7508e-01, time/batch = 0.6777s	
3459/28500 (epoch 6.068), train_loss = 1.35970874, grad/param norm = 1.7557e-01, time/batch = 0.6821s	
3460/28500 (epoch 6.070), train_loss = 1.51142674, grad/param norm = 1.8311e-01, time/batch = 0.6944s	
3461/28500 (epoch 6.072), train_loss = 1.66340031, grad/param norm = 1.9226e-01, time/batch = 0.6859s	
3462/28500 (epoch 6.074), train_loss = 1.50938693, grad/param norm = 1.9485e-01, time/batch = 0.6825s	
3463/28500 (epoch 6.075), train_loss = 1.40667257, grad/param norm = 1.6059e-01, time/batch = 0.6788s	
3464/28500 (epoch 6.077), train_loss = 1.51427481, grad/param norm = 1.9213e-01, time/batch = 0.6773s	
3465/28500 (epoch 6.079), train_loss = 1.46211390, grad/param norm = 1.7969e-01, time/batch = 0.6794s	
3466/28500 (epoch 6.081), train_loss = 1.61231368, grad/param norm = 1.9582e-01, time/batch = 0.7305s	
3467/28500 (epoch 6.082), train_loss = 1.53124725, grad/param norm = 1.9254e-01, time/batch = 0.6794s	
3468/28500 (epoch 6.084), train_loss = 1.52565573, grad/param norm = 1.7909e-01, time/batch = 0.6784s	
3469/28500 (epoch 6.086), train_loss = 1.40449103, grad/param norm = 1.9854e-01, time/batch = 0.6782s	
3470/28500 (epoch 6.088), train_loss = 1.34358488, grad/param norm = 1.8507e-01, time/batch = 0.6787s	
3471/28500 (epoch 6.089), train_loss = 1.62015248, grad/param norm = 1.6746e-01, time/batch = 0.6834s	
3472/28500 (epoch 6.091), train_loss = 1.27832605, grad/param norm = 1.7295e-01, time/batch = 0.6785s	
3473/28500 (epoch 6.093), train_loss = 1.46658501, grad/param norm = 1.8198e-01, time/batch = 0.6795s	
3474/28500 (epoch 6.095), train_loss = 1.39693375, grad/param norm = 1.8111e-01, time/batch = 0.6780s	
3475/28500 (epoch 6.096), train_loss = 1.62064634, grad/param norm = 1.8994e-01, time/batch = 0.6774s	
3476/28500 (epoch 6.098), train_loss = 1.61505046, grad/param norm = 1.9750e-01, time/batch = 0.6771s	
3477/28500 (epoch 6.100), train_loss = 1.37475449, grad/param norm = 1.7631e-01, time/batch = 0.6784s	
3478/28500 (epoch 6.102), train_loss = 1.65001965, grad/param norm = 1.8759e-01, time/batch = 0.6793s	
3479/28500 (epoch 6.104), train_loss = 1.45774248, grad/param norm = 1.8707e-01, time/batch = 0.6775s	
3480/28500 (epoch 6.105), train_loss = 1.48805291, grad/param norm = 1.8063e-01, time/batch = 0.6782s	
3481/28500 (epoch 6.107), train_loss = 1.37922238, grad/param norm = 1.8806e-01, time/batch = 0.6808s	
3482/28500 (epoch 6.109), train_loss = 1.33903093, grad/param norm = 1.8687e-01, time/batch = 0.6785s	
3483/28500 (epoch 6.111), train_loss = 1.42954074, grad/param norm = 1.7864e-01, time/batch = 0.6787s	
3484/28500 (epoch 6.112), train_loss = 1.54153115, grad/param norm = 1.9458e-01, time/batch = 0.6818s	
3485/28500 (epoch 6.114), train_loss = 1.45060824, grad/param norm = 2.0006e-01, time/batch = 0.6827s	
3486/28500 (epoch 6.116), train_loss = 1.67406334, grad/param norm = 1.9617e-01, time/batch = 0.6825s	
3487/28500 (epoch 6.118), train_loss = 1.31652884, grad/param norm = 1.7559e-01, time/batch = 0.6799s	
3488/28500 (epoch 6.119), train_loss = 1.53392510, grad/param norm = 1.9034e-01, time/batch = 0.6771s	
3489/28500 (epoch 6.121), train_loss = 1.67220285, grad/param norm = 2.0180e-01, time/batch = 0.6814s	
3490/28500 (epoch 6.123), train_loss = 1.53890761, grad/param norm = 2.1032e-01, time/batch = 0.6795s	
3491/28500 (epoch 6.125), train_loss = 1.51873030, grad/param norm = 1.9057e-01, time/batch = 0.6801s	
3492/28500 (epoch 6.126), train_loss = 1.47206587, grad/param norm = 1.8125e-01, time/batch = 0.6797s	
3493/28500 (epoch 6.128), train_loss = 1.37572930, grad/param norm = 1.8866e-01, time/batch = 0.6797s	
3494/28500 (epoch 6.130), train_loss = 1.41119513, grad/param norm = 1.8109e-01, time/batch = 0.6797s	
3495/28500 (epoch 6.132), train_loss = 1.52362184, grad/param norm = 1.8564e-01, time/batch = 0.6807s	
3496/28500 (epoch 6.133), train_loss = 1.43200166, grad/param norm = 1.7192e-01, time/batch = 0.6783s	
3497/28500 (epoch 6.135), train_loss = 1.45359606, grad/param norm = 1.7276e-01, time/batch = 0.6777s	
3498/28500 (epoch 6.137), train_loss = 1.44172819, grad/param norm = 1.9214e-01, time/batch = 0.6776s	
3499/28500 (epoch 6.139), train_loss = 1.42941805, grad/param norm = 1.6722e-01, time/batch = 0.6795s	
3500/28500 (epoch 6.140), train_loss = 1.47310548, grad/param norm = 1.8259e-01, time/batch = 0.6862s	
3501/28500 (epoch 6.142), train_loss = 1.51264750, grad/param norm = 1.8601e-01, time/batch = 0.6856s	
3502/28500 (epoch 6.144), train_loss = 1.32734984, grad/param norm = 1.6933e-01, time/batch = 0.6801s	
3503/28500 (epoch 6.146), train_loss = 1.34802570, grad/param norm = 1.7347e-01, time/batch = 0.6778s	
3504/28500 (epoch 6.147), train_loss = 1.27846451, grad/param norm = 1.7131e-01, time/batch = 0.6787s	
3505/28500 (epoch 6.149), train_loss = 1.29490999, grad/param norm = 1.6728e-01, time/batch = 0.6782s	
3506/28500 (epoch 6.151), train_loss = 1.29245386, grad/param norm = 1.7098e-01, time/batch = 0.6779s	
3507/28500 (epoch 6.153), train_loss = 1.41407917, grad/param norm = 1.7120e-01, time/batch = 0.6791s	
3508/28500 (epoch 6.154), train_loss = 1.34565811, grad/param norm = 1.9217e-01, time/batch = 0.6773s	
3509/28500 (epoch 6.156), train_loss = 1.65826843, grad/param norm = 2.0612e-01, time/batch = 0.6789s	
3510/28500 (epoch 6.158), train_loss = 1.39847436, grad/param norm = 1.7364e-01, time/batch = 0.6791s	
3511/28500 (epoch 6.160), train_loss = 1.32492925, grad/param norm = 1.6746e-01, time/batch = 0.6948s	
3512/28500 (epoch 6.161), train_loss = 1.52169828, grad/param norm = 2.0101e-01, time/batch = 0.6921s	
3513/28500 (epoch 6.163), train_loss = 1.34684755, grad/param norm = 1.9134e-01, time/batch = 0.6816s	
3514/28500 (epoch 6.165), train_loss = 1.66312549, grad/param norm = 1.8087e-01, time/batch = 0.6814s	
3515/28500 (epoch 6.167), train_loss = 1.75104118, grad/param norm = 2.0461e-01, time/batch = 0.6819s	
3516/28500 (epoch 6.168), train_loss = 1.55650017, grad/param norm = 2.0814e-01, time/batch = 0.6832s	
3517/28500 (epoch 6.170), train_loss = 1.61038802, grad/param norm = 2.0855e-01, time/batch = 0.6819s	
3518/28500 (epoch 6.172), train_loss = 1.42023356, grad/param norm = 1.8646e-01, time/batch = 0.6814s	
3519/28500 (epoch 6.174), train_loss = 1.70692409, grad/param norm = 2.0286e-01, time/batch = 0.6805s	
3520/28500 (epoch 6.175), train_loss = 1.39561425, grad/param norm = 1.7492e-01, time/batch = 0.6828s	
3521/28500 (epoch 6.177), train_loss = 1.54089590, grad/param norm = 1.8991e-01, time/batch = 0.6853s	
3522/28500 (epoch 6.179), train_loss = 1.42204111, grad/param norm = 1.8855e-01, time/batch = 0.6828s	
3523/28500 (epoch 6.181), train_loss = 1.52096911, grad/param norm = 1.8035e-01, time/batch = 0.6805s	
3524/28500 (epoch 6.182), train_loss = 1.43890537, grad/param norm = 1.8498e-01, time/batch = 0.6820s	
3525/28500 (epoch 6.184), train_loss = 1.69024670, grad/param norm = 2.0778e-01, time/batch = 0.6801s	
3526/28500 (epoch 6.186), train_loss = 1.58680868, grad/param norm = 1.9812e-01, time/batch = 0.6834s	
3527/28500 (epoch 6.188), train_loss = 1.44525082, grad/param norm = 1.7699e-01, time/batch = 0.6875s	
3528/28500 (epoch 6.189), train_loss = 1.51393786, grad/param norm = 1.8956e-01, time/batch = 0.6884s	
3529/28500 (epoch 6.191), train_loss = 1.73352802, grad/param norm = 1.8842e-01, time/batch = 0.6895s	
3530/28500 (epoch 6.193), train_loss = 1.59174907, grad/param norm = 2.0326e-01, time/batch = 0.6863s	
3531/28500 (epoch 6.195), train_loss = 1.57675342, grad/param norm = 1.9458e-01, time/batch = 0.6887s	
3532/28500 (epoch 6.196), train_loss = 1.52488018, grad/param norm = 1.8043e-01, time/batch = 0.6851s	
3533/28500 (epoch 6.198), train_loss = 1.48700403, grad/param norm = 1.8823e-01, time/batch = 0.6811s	
3534/28500 (epoch 6.200), train_loss = 1.44396883, grad/param norm = 1.5920e-01, time/batch = 0.6798s	
3535/28500 (epoch 6.202), train_loss = 1.50848360, grad/param norm = 2.0006e-01, time/batch = 0.6806s	
3536/28500 (epoch 6.204), train_loss = 1.30907403, grad/param norm = 1.6685e-01, time/batch = 0.6795s	
3537/28500 (epoch 6.205), train_loss = 1.40937681, grad/param norm = 1.8110e-01, time/batch = 0.6793s	
3538/28500 (epoch 6.207), train_loss = 1.46493161, grad/param norm = 1.9331e-01, time/batch = 0.6789s	
3539/28500 (epoch 6.209), train_loss = 1.45941887, grad/param norm = 1.9076e-01, time/batch = 0.6780s	
3540/28500 (epoch 6.211), train_loss = 1.29033517, grad/param norm = 1.6269e-01, time/batch = 0.6777s	
3541/28500 (epoch 6.212), train_loss = 1.31474411, grad/param norm = 1.7005e-01, time/batch = 0.6809s	
3542/28500 (epoch 6.214), train_loss = 1.51345647, grad/param norm = 1.9815e-01, time/batch = 0.6783s	
3543/28500 (epoch 6.216), train_loss = 1.32310606, grad/param norm = 1.6821e-01, time/batch = 0.6806s	
3544/28500 (epoch 6.218), train_loss = 1.53240864, grad/param norm = 1.7115e-01, time/batch = 0.6797s	
3545/28500 (epoch 6.219), train_loss = 1.47931265, grad/param norm = 1.8672e-01, time/batch = 0.6793s	
3546/28500 (epoch 6.221), train_loss = 1.35829291, grad/param norm = 1.8538e-01, time/batch = 0.6774s	
3547/28500 (epoch 6.223), train_loss = 1.59728703, grad/param norm = 2.0819e-01, time/batch = 0.6791s	
3548/28500 (epoch 6.225), train_loss = 1.62747599, grad/param norm = 1.9255e-01, time/batch = 0.6792s	
3549/28500 (epoch 6.226), train_loss = 1.45389966, grad/param norm = 1.8045e-01, time/batch = 0.6879s	
3550/28500 (epoch 6.228), train_loss = 1.48137672, grad/param norm = 1.7438e-01, time/batch = 0.6964s	
3551/28500 (epoch 6.230), train_loss = 1.51835303, grad/param norm = 1.7534e-01, time/batch = 0.6877s	
3552/28500 (epoch 6.232), train_loss = 1.51896904, grad/param norm = 1.7575e-01, time/batch = 0.6808s	
3553/28500 (epoch 6.233), train_loss = 1.49781982, grad/param norm = 1.9408e-01, time/batch = 0.6808s	
3554/28500 (epoch 6.235), train_loss = 1.39246153, grad/param norm = 1.7459e-01, time/batch = 0.6785s	
3555/28500 (epoch 6.237), train_loss = 1.27352926, grad/param norm = 1.5197e-01, time/batch = 0.6820s	
3556/28500 (epoch 6.239), train_loss = 1.36535470, grad/param norm = 1.7835e-01, time/batch = 0.6780s	
3557/28500 (epoch 6.240), train_loss = 1.29645824, grad/param norm = 1.7224e-01, time/batch = 0.6819s	
3558/28500 (epoch 6.242), train_loss = 1.49706928, grad/param norm = 1.7645e-01, time/batch = 0.6774s	
3559/28500 (epoch 6.244), train_loss = 1.54709112, grad/param norm = 1.8850e-01, time/batch = 0.6795s	
3560/28500 (epoch 6.246), train_loss = 1.52217376, grad/param norm = 1.8205e-01, time/batch = 0.6794s	
3561/28500 (epoch 6.247), train_loss = 1.67206451, grad/param norm = 1.9173e-01, time/batch = 0.6800s	
3562/28500 (epoch 6.249), train_loss = 1.50556947, grad/param norm = 2.0029e-01, time/batch = 0.6780s	
3563/28500 (epoch 6.251), train_loss = 1.28056485, grad/param norm = 1.6576e-01, time/batch = 0.6778s	
3564/28500 (epoch 6.253), train_loss = 1.64209587, grad/param norm = 2.0751e-01, time/batch = 0.6778s	
3565/28500 (epoch 6.254), train_loss = 1.55331994, grad/param norm = 1.8338e-01, time/batch = 0.6781s	
3566/28500 (epoch 6.256), train_loss = 1.37110700, grad/param norm = 1.6852e-01, time/batch = 0.6776s	
3567/28500 (epoch 6.258), train_loss = 1.45052588, grad/param norm = 1.8480e-01, time/batch = 0.6779s	
3568/28500 (epoch 6.260), train_loss = 1.39908102, grad/param norm = 1.7189e-01, time/batch = 0.6777s	
3569/28500 (epoch 6.261), train_loss = 1.38271024, grad/param norm = 1.7864e-01, time/batch = 0.6772s	
3570/28500 (epoch 6.263), train_loss = 1.63365400, grad/param norm = 2.0367e-01, time/batch = 0.6769s	
3571/28500 (epoch 6.265), train_loss = 1.51176724, grad/param norm = 2.0054e-01, time/batch = 0.6794s	
3572/28500 (epoch 6.267), train_loss = 1.62935637, grad/param norm = 2.0239e-01, time/batch = 0.6795s	
3573/28500 (epoch 6.268), train_loss = 1.54702491, grad/param norm = 1.6940e-01, time/batch = 0.6779s	
3574/28500 (epoch 6.270), train_loss = 1.47292767, grad/param norm = 1.9193e-01, time/batch = 0.6780s	
3575/28500 (epoch 6.272), train_loss = 1.45109355, grad/param norm = 1.8809e-01, time/batch = 0.6776s	
3576/28500 (epoch 6.274), train_loss = 1.63765139, grad/param norm = 2.0620e-01, time/batch = 0.6780s	
3577/28500 (epoch 6.275), train_loss = 1.52917977, grad/param norm = 1.7349e-01, time/batch = 0.6792s	
3578/28500 (epoch 6.277), train_loss = 1.41005758, grad/param norm = 1.7993e-01, time/batch = 0.6781s	
3579/28500 (epoch 6.279), train_loss = 1.50509979, grad/param norm = 1.8793e-01, time/batch = 0.6776s	
3580/28500 (epoch 6.281), train_loss = 1.52221509, grad/param norm = 1.8364e-01, time/batch = 0.6785s	
3581/28500 (epoch 6.282), train_loss = 1.34307100, grad/param norm = 1.6534e-01, time/batch = 0.6794s	
3582/28500 (epoch 6.284), train_loss = 1.50690670, grad/param norm = 1.8284e-01, time/batch = 0.6787s	
3583/28500 (epoch 6.286), train_loss = 1.58875188, grad/param norm = 2.0114e-01, time/batch = 0.6777s	
3584/28500 (epoch 6.288), train_loss = 1.50106958, grad/param norm = 1.8136e-01, time/batch = 0.6775s	
3585/28500 (epoch 6.289), train_loss = 1.60571421, grad/param norm = 1.8257e-01, time/batch = 0.6778s	
3586/28500 (epoch 6.291), train_loss = 1.43482851, grad/param norm = 1.7972e-01, time/batch = 0.6796s	
3587/28500 (epoch 6.293), train_loss = 1.40248612, grad/param norm = 1.8259e-01, time/batch = 0.6806s	
3588/28500 (epoch 6.295), train_loss = 1.36165585, grad/param norm = 1.7369e-01, time/batch = 0.6949s	
3589/28500 (epoch 6.296), train_loss = 1.34456455, grad/param norm = 1.6782e-01, time/batch = 0.6789s	
3590/28500 (epoch 6.298), train_loss = 1.48848686, grad/param norm = 1.8904e-01, time/batch = 0.6771s	
3591/28500 (epoch 6.300), train_loss = 1.35584109, grad/param norm = 1.7081e-01, time/batch = 0.6813s	
3592/28500 (epoch 6.302), train_loss = 1.32445509, grad/param norm = 1.7648e-01, time/batch = 0.6819s	
3593/28500 (epoch 6.304), train_loss = 1.45140815, grad/param norm = 1.7274e-01, time/batch = 0.6802s	
3594/28500 (epoch 6.305), train_loss = 1.53740623, grad/param norm = 1.9362e-01, time/batch = 0.6815s	
3595/28500 (epoch 6.307), train_loss = 1.53603007, grad/param norm = 2.0962e-01, time/batch = 0.6789s	
3596/28500 (epoch 6.309), train_loss = 1.52282341, grad/param norm = 2.0180e-01, time/batch = 0.6968s	
3597/28500 (epoch 6.311), train_loss = 1.48058472, grad/param norm = 2.1048e-01, time/batch = 0.6892s	
3598/28500 (epoch 6.312), train_loss = 1.37013753, grad/param norm = 1.6818e-01, time/batch = 0.6826s	
3599/28500 (epoch 6.314), train_loss = 1.52157195, grad/param norm = 1.9306e-01, time/batch = 0.6853s	
3600/28500 (epoch 6.316), train_loss = 1.47325402, grad/param norm = 1.6840e-01, time/batch = 0.6783s	
3601/28500 (epoch 6.318), train_loss = 1.51086872, grad/param norm = 2.0856e-01, time/batch = 0.6815s	
3602/28500 (epoch 6.319), train_loss = 1.42742995, grad/param norm = 1.8690e-01, time/batch = 0.6843s	
3603/28500 (epoch 6.321), train_loss = 1.52549508, grad/param norm = 2.0353e-01, time/batch = 0.6859s	
3604/28500 (epoch 6.323), train_loss = 1.43934379, grad/param norm = 1.9383e-01, time/batch = 0.6776s	
3605/28500 (epoch 6.325), train_loss = 1.65358300, grad/param norm = 1.8356e-01, time/batch = 0.6772s	
3606/28500 (epoch 6.326), train_loss = 1.53926299, grad/param norm = 2.0635e-01, time/batch = 0.6769s	
3607/28500 (epoch 6.328), train_loss = 1.21887003, grad/param norm = 1.6791e-01, time/batch = 0.6837s	
3608/28500 (epoch 6.330), train_loss = 1.36231349, grad/param norm = 1.7174e-01, time/batch = 0.6794s	
3609/28500 (epoch 6.332), train_loss = 1.42321647, grad/param norm = 1.6807e-01, time/batch = 0.6801s	
3610/28500 (epoch 6.333), train_loss = 1.27893514, grad/param norm = 1.7514e-01, time/batch = 0.6791s	
3611/28500 (epoch 6.335), train_loss = 1.31863753, grad/param norm = 1.6073e-01, time/batch = 0.6799s	
3612/28500 (epoch 6.337), train_loss = 1.43309858, grad/param norm = 1.8357e-01, time/batch = 0.6792s	
3613/28500 (epoch 6.339), train_loss = 1.36351535, grad/param norm = 1.7119e-01, time/batch = 0.6796s	
3614/28500 (epoch 6.340), train_loss = 1.55728959, grad/param norm = 1.8842e-01, time/batch = 0.6785s	
3615/28500 (epoch 6.342), train_loss = 1.41590129, grad/param norm = 2.0174e-01, time/batch = 0.6776s	
3616/28500 (epoch 6.344), train_loss = 1.38006130, grad/param norm = 1.9637e-01, time/batch = 0.6770s	
3617/28500 (epoch 6.346), train_loss = 1.14244155, grad/param norm = 1.5961e-01, time/batch = 0.6772s	
3618/28500 (epoch 6.347), train_loss = 1.47044186, grad/param norm = 1.8715e-01, time/batch = 0.6786s	
3619/28500 (epoch 6.349), train_loss = 1.34516210, grad/param norm = 1.6093e-01, time/batch = 0.6774s	
3620/28500 (epoch 6.351), train_loss = 1.31409637, grad/param norm = 1.6161e-01, time/batch = 0.6770s	
3621/28500 (epoch 6.353), train_loss = 1.52815628, grad/param norm = 1.8814e-01, time/batch = 0.6795s	
3622/28500 (epoch 6.354), train_loss = 1.32110393, grad/param norm = 1.8019e-01, time/batch = 0.6802s	
3623/28500 (epoch 6.356), train_loss = 1.34580089, grad/param norm = 1.5726e-01, time/batch = 0.6814s	
3624/28500 (epoch 6.358), train_loss = 1.49352864, grad/param norm = 1.6286e-01, time/batch = 0.6813s	
3625/28500 (epoch 6.360), train_loss = 1.45897428, grad/param norm = 1.9635e-01, time/batch = 0.6829s	
3626/28500 (epoch 6.361), train_loss = 1.39156347, grad/param norm = 1.6955e-01, time/batch = 0.6812s	
3627/28500 (epoch 6.363), train_loss = 1.31182832, grad/param norm = 1.6421e-01, time/batch = 0.6802s	
3628/28500 (epoch 6.365), train_loss = 1.38710618, grad/param norm = 1.8318e-01, time/batch = 0.6788s	
3629/28500 (epoch 6.367), train_loss = 1.43008265, grad/param norm = 1.7371e-01, time/batch = 0.6808s	
3630/28500 (epoch 6.368), train_loss = 1.38146067, grad/param norm = 1.6817e-01, time/batch = 0.6795s	
3631/28500 (epoch 6.370), train_loss = 1.47857467, grad/param norm = 1.8734e-01, time/batch = 0.6839s	
3632/28500 (epoch 6.372), train_loss = 1.29104894, grad/param norm = 1.7117e-01, time/batch = 0.6814s	
3633/28500 (epoch 6.374), train_loss = 1.49765532, grad/param norm = 1.9822e-01, time/batch = 0.6808s	
3634/28500 (epoch 6.375), train_loss = 1.62064322, grad/param norm = 1.9313e-01, time/batch = 0.6806s	
3635/28500 (epoch 6.377), train_loss = 1.38840244, grad/param norm = 1.7183e-01, time/batch = 0.6803s	
3636/28500 (epoch 6.379), train_loss = 1.18591498, grad/param norm = 1.6016e-01, time/batch = 0.6801s	
3637/28500 (epoch 6.381), train_loss = 1.37635899, grad/param norm = 1.6142e-01, time/batch = 0.6849s	
3638/28500 (epoch 6.382), train_loss = 1.38420669, grad/param norm = 1.8067e-01, time/batch = 0.6805s	
3639/28500 (epoch 6.384), train_loss = 1.29999045, grad/param norm = 1.6604e-01, time/batch = 0.6805s	
3640/28500 (epoch 6.386), train_loss = 1.30223843, grad/param norm = 1.8535e-01, time/batch = 0.6803s	
3641/28500 (epoch 6.388), train_loss = 1.55592041, grad/param norm = 1.7666e-01, time/batch = 0.6830s	
3642/28500 (epoch 6.389), train_loss = 1.36610347, grad/param norm = 1.7940e-01, time/batch = 0.6822s	
3643/28500 (epoch 6.391), train_loss = 1.36435484, grad/param norm = 1.7413e-01, time/batch = 0.6844s	
3644/28500 (epoch 6.393), train_loss = 1.26362241, grad/param norm = 1.6362e-01, time/batch = 0.6821s	
3645/28500 (epoch 6.395), train_loss = 1.65879285, grad/param norm = 1.9914e-01, time/batch = 0.6813s	
3646/28500 (epoch 6.396), train_loss = 1.51733877, grad/param norm = 1.8630e-01, time/batch = 0.6815s	
3647/28500 (epoch 6.398), train_loss = 1.29570260, grad/param norm = 1.9867e-01, time/batch = 0.6809s	
3648/28500 (epoch 6.400), train_loss = 1.51421885, grad/param norm = 2.1766e-01, time/batch = 0.6802s	
3649/28500 (epoch 6.402), train_loss = 1.40952677, grad/param norm = 1.7472e-01, time/batch = 0.6797s	
3650/28500 (epoch 6.404), train_loss = 1.54962837, grad/param norm = 2.1551e-01, time/batch = 0.6801s	
3651/28500 (epoch 6.405), train_loss = 1.51195914, grad/param norm = 1.7363e-01, time/batch = 0.6849s	
3652/28500 (epoch 6.407), train_loss = 1.47038313, grad/param norm = 1.7166e-01, time/batch = 0.6823s	
3653/28500 (epoch 6.409), train_loss = 1.48121712, grad/param norm = 1.8259e-01, time/batch = 0.6802s	
3654/28500 (epoch 6.411), train_loss = 1.51565832, grad/param norm = 1.6220e-01, time/batch = 0.6808s	
3655/28500 (epoch 6.412), train_loss = 1.63695343, grad/param norm = 1.9171e-01, time/batch = 0.6810s	
3656/28500 (epoch 6.414), train_loss = 1.46731273, grad/param norm = 1.9654e-01, time/batch = 0.6820s	
3657/28500 (epoch 6.416), train_loss = 1.39091316, grad/param norm = 1.9150e-01, time/batch = 0.6816s	
3658/28500 (epoch 6.418), train_loss = 1.48306261, grad/param norm = 1.6768e-01, time/batch = 0.6823s	
3659/28500 (epoch 6.419), train_loss = 1.59721524, grad/param norm = 2.0163e-01, time/batch = 0.6831s	
3660/28500 (epoch 6.421), train_loss = 1.52972305, grad/param norm = 1.7564e-01, time/batch = 0.6857s	
3661/28500 (epoch 6.423), train_loss = 1.65251454, grad/param norm = 2.0070e-01, time/batch = 0.6828s	
3662/28500 (epoch 6.425), train_loss = 1.49687039, grad/param norm = 2.0374e-01, time/batch = 0.6814s	
3663/28500 (epoch 6.426), train_loss = 1.46465471, grad/param norm = 1.8070e-01, time/batch = 0.6797s	
3664/28500 (epoch 6.428), train_loss = 1.69987817, grad/param norm = 2.0093e-01, time/batch = 0.6804s	
3665/28500 (epoch 6.430), train_loss = 1.53069915, grad/param norm = 1.7392e-01, time/batch = 0.6811s	
3666/28500 (epoch 6.432), train_loss = 1.53996492, grad/param norm = 2.0440e-01, time/batch = 0.6798s	
3667/28500 (epoch 6.433), train_loss = 1.55998494, grad/param norm = 1.9845e-01, time/batch = 0.6800s	
3668/28500 (epoch 6.435), train_loss = 1.43155228, grad/param norm = 1.8800e-01, time/batch = 0.6792s	
3669/28500 (epoch 6.437), train_loss = 1.27887760, grad/param norm = 1.5319e-01, time/batch = 0.6807s	
3670/28500 (epoch 6.439), train_loss = 1.32889148, grad/param norm = 1.6206e-01, time/batch = 0.6783s	
3671/28500 (epoch 6.440), train_loss = 1.53997561, grad/param norm = 1.7909e-01, time/batch = 0.6824s	
3672/28500 (epoch 6.442), train_loss = 1.34281868, grad/param norm = 1.8723e-01, time/batch = 0.6803s	
3673/28500 (epoch 6.444), train_loss = 1.29917023, grad/param norm = 1.5806e-01, time/batch = 0.6805s	
3674/28500 (epoch 6.446), train_loss = 1.23150554, grad/param norm = 1.7031e-01, time/batch = 0.6804s	
3675/28500 (epoch 6.447), train_loss = 1.33911067, grad/param norm = 1.6435e-01, time/batch = 0.6822s	
3676/28500 (epoch 6.449), train_loss = 1.31931265, grad/param norm = 1.6855e-01, time/batch = 0.6885s	
3677/28500 (epoch 6.451), train_loss = 1.42167472, grad/param norm = 1.7680e-01, time/batch = 0.6824s	
3678/28500 (epoch 6.453), train_loss = 1.43504381, grad/param norm = 1.9667e-01, time/batch = 0.6856s	
3679/28500 (epoch 6.454), train_loss = 1.36414330, grad/param norm = 1.8870e-01, time/batch = 0.6897s	
3680/28500 (epoch 6.456), train_loss = 1.50561629, grad/param norm = 1.8919e-01, time/batch = 0.6853s	
3681/28500 (epoch 6.458), train_loss = 1.37555391, grad/param norm = 1.7871e-01, time/batch = 0.6844s	
3682/28500 (epoch 6.460), train_loss = 1.53377649, grad/param norm = 1.8315e-01, time/batch = 0.6815s	
3683/28500 (epoch 6.461), train_loss = 1.39423976, grad/param norm = 1.8080e-01, time/batch = 0.6779s	
3684/28500 (epoch 6.463), train_loss = 1.30200330, grad/param norm = 1.5657e-01, time/batch = 0.6802s	
3685/28500 (epoch 6.465), train_loss = 1.24959208, grad/param norm = 1.6880e-01, time/batch = 0.6844s	
3686/28500 (epoch 6.467), train_loss = 1.50456010, grad/param norm = 1.8649e-01, time/batch = 0.6785s	
3687/28500 (epoch 6.468), train_loss = 1.24010397, grad/param norm = 1.4926e-01, time/batch = 0.6793s	
3688/28500 (epoch 6.470), train_loss = 1.43955156, grad/param norm = 1.9833e-01, time/batch = 0.6768s	
3689/28500 (epoch 6.472), train_loss = 1.34411740, grad/param norm = 1.6105e-01, time/batch = 0.6819s	
3690/28500 (epoch 6.474), train_loss = 1.69531297, grad/param norm = 2.0757e-01, time/batch = 0.6860s	
3691/28500 (epoch 6.475), train_loss = 1.37678927, grad/param norm = 1.7702e-01, time/batch = 0.6828s	
3692/28500 (epoch 6.477), train_loss = 1.40424982, grad/param norm = 1.8092e-01, time/batch = 0.6792s	
3693/28500 (epoch 6.479), train_loss = 1.42357416, grad/param norm = 1.7236e-01, time/batch = 0.6773s	
3694/28500 (epoch 6.481), train_loss = 1.40999296, grad/param norm = 1.8662e-01, time/batch = 0.6769s	
3695/28500 (epoch 6.482), train_loss = 1.32666364, grad/param norm = 1.8189e-01, time/batch = 0.6787s	
3696/28500 (epoch 6.484), train_loss = 1.33706578, grad/param norm = 1.9363e-01, time/batch = 0.6822s	
3697/28500 (epoch 6.486), train_loss = 1.29537672, grad/param norm = 1.8025e-01, time/batch = 0.6829s	
3698/28500 (epoch 6.488), train_loss = 1.40780011, grad/param norm = 1.7955e-01, time/batch = 0.6785s	
3699/28500 (epoch 6.489), train_loss = 1.51062573, grad/param norm = 1.9221e-01, time/batch = 0.6784s	
3700/28500 (epoch 6.491), train_loss = 1.35992702, grad/param norm = 1.7329e-01, time/batch = 0.6774s	
3701/28500 (epoch 6.493), train_loss = 1.32289344, grad/param norm = 1.6287e-01, time/batch = 0.6803s	
3702/28500 (epoch 6.495), train_loss = 1.36764191, grad/param norm = 1.7946e-01, time/batch = 0.6821s	
3703/28500 (epoch 6.496), train_loss = 1.43999316, grad/param norm = 1.7335e-01, time/batch = 0.6811s	
3704/28500 (epoch 6.498), train_loss = 1.48760241, grad/param norm = 1.7905e-01, time/batch = 0.6775s	
3705/28500 (epoch 6.500), train_loss = 1.43447572, grad/param norm = 1.8274e-01, time/batch = 0.6772s	
3706/28500 (epoch 6.502), train_loss = 1.49449785, grad/param norm = 1.7964e-01, time/batch = 0.6771s	
3707/28500 (epoch 6.504), train_loss = 1.50096107, grad/param norm = 1.7255e-01, time/batch = 0.6776s	
3708/28500 (epoch 6.505), train_loss = 1.33524595, grad/param norm = 1.6196e-01, time/batch = 0.6772s	
3709/28500 (epoch 6.507), train_loss = 1.59424372, grad/param norm = 2.0446e-01, time/batch = 0.6805s	
3710/28500 (epoch 6.509), train_loss = 1.44984164, grad/param norm = 2.0165e-01, time/batch = 0.6786s	
3711/28500 (epoch 6.511), train_loss = 1.44700779, grad/param norm = 1.7857e-01, time/batch = 0.6797s	
3712/28500 (epoch 6.512), train_loss = 1.42247429, grad/param norm = 1.7473e-01, time/batch = 0.6780s	
3713/28500 (epoch 6.514), train_loss = 1.28450255, grad/param norm = 1.7173e-01, time/batch = 0.6783s	
3714/28500 (epoch 6.516), train_loss = 1.32597613, grad/param norm = 1.6082e-01, time/batch = 0.6784s	
3715/28500 (epoch 6.518), train_loss = 1.37957141, grad/param norm = 1.6052e-01, time/batch = 0.6778s	
3716/28500 (epoch 6.519), train_loss = 1.47374857, grad/param norm = 1.7621e-01, time/batch = 0.6804s	
3717/28500 (epoch 6.521), train_loss = 1.60926160, grad/param norm = 1.9063e-01, time/batch = 0.6860s	
3718/28500 (epoch 6.523), train_loss = 1.52546996, grad/param norm = 1.9292e-01, time/batch = 0.6782s	
3719/28500 (epoch 6.525), train_loss = 1.56937655, grad/param norm = 1.8416e-01, time/batch = 0.6803s	
3720/28500 (epoch 6.526), train_loss = 1.46679689, grad/param norm = 1.7941e-01, time/batch = 0.6779s	
3721/28500 (epoch 6.528), train_loss = 1.56093454, grad/param norm = 2.0506e-01, time/batch = 0.6804s	
3722/28500 (epoch 6.530), train_loss = 1.54461065, grad/param norm = 1.6578e-01, time/batch = 0.6815s	
3723/28500 (epoch 6.532), train_loss = 1.37589670, grad/param norm = 1.8524e-01, time/batch = 0.6771s	
3724/28500 (epoch 6.533), train_loss = 1.57750224, grad/param norm = 2.0175e-01, time/batch = 0.6794s	
3725/28500 (epoch 6.535), train_loss = 1.25964239, grad/param norm = 1.6489e-01, time/batch = 0.6784s	
3726/28500 (epoch 6.537), train_loss = 1.22468190, grad/param norm = 1.6824e-01, time/batch = 0.6779s	
3727/28500 (epoch 6.539), train_loss = 1.31875177, grad/param norm = 1.7107e-01, time/batch = 0.6803s	
3728/28500 (epoch 6.540), train_loss = 1.43116034, grad/param norm = 1.7152e-01, time/batch = 0.6794s	
3729/28500 (epoch 6.542), train_loss = 1.64316860, grad/param norm = 2.1202e-01, time/batch = 0.6783s	
3730/28500 (epoch 6.544), train_loss = 1.58771461, grad/param norm = 1.8247e-01, time/batch = 0.6772s	
3731/28500 (epoch 6.546), train_loss = 1.46627523, grad/param norm = 1.9377e-01, time/batch = 0.6836s	
3732/28500 (epoch 6.547), train_loss = 1.43323439, grad/param norm = 1.6603e-01, time/batch = 0.6805s	
3733/28500 (epoch 6.549), train_loss = 1.25110489, grad/param norm = 1.5435e-01, time/batch = 0.6796s	
3734/28500 (epoch 6.551), train_loss = 1.56687524, grad/param norm = 1.8861e-01, time/batch = 0.6791s	
3735/28500 (epoch 6.553), train_loss = 1.67857912, grad/param norm = 1.9193e-01, time/batch = 0.6840s	
3736/28500 (epoch 6.554), train_loss = 1.38199076, grad/param norm = 1.6682e-01, time/batch = 0.6993s	
3737/28500 (epoch 6.556), train_loss = 1.47128191, grad/param norm = 1.9441e-01, time/batch = 0.6954s	
3738/28500 (epoch 6.558), train_loss = 1.46835378, grad/param norm = 1.7624e-01, time/batch = 0.7002s	
3739/28500 (epoch 6.560), train_loss = 1.48520498, grad/param norm = 1.9149e-01, time/batch = 0.6993s	
3740/28500 (epoch 6.561), train_loss = 1.53605936, grad/param norm = 2.0062e-01, time/batch = 0.6929s	
3741/28500 (epoch 6.563), train_loss = 1.55701078, grad/param norm = 1.9441e-01, time/batch = 0.6982s	
3742/28500 (epoch 6.565), train_loss = 1.40389564, grad/param norm = 1.7773e-01, time/batch = 0.6970s	
3743/28500 (epoch 6.567), train_loss = 1.32064173, grad/param norm = 1.8429e-01, time/batch = 0.7113s	
3744/28500 (epoch 6.568), train_loss = 1.48073416, grad/param norm = 1.9185e-01, time/batch = 0.7040s	
3745/28500 (epoch 6.570), train_loss = 1.35564925, grad/param norm = 1.8863e-01, time/batch = 0.6998s	
3746/28500 (epoch 6.572), train_loss = 1.39540689, grad/param norm = 1.8136e-01, time/batch = 0.6925s	
3747/28500 (epoch 6.574), train_loss = 1.45740379, grad/param norm = 1.8054e-01, time/batch = 0.6988s	
3748/28500 (epoch 6.575), train_loss = 1.36003605, grad/param norm = 1.7709e-01, time/batch = 0.6895s	
3749/28500 (epoch 6.577), train_loss = 1.41181258, grad/param norm = 1.7280e-01, time/batch = 0.6892s	
3750/28500 (epoch 6.579), train_loss = 1.58143615, grad/param norm = 2.1498e-01, time/batch = 0.6934s	
3751/28500 (epoch 6.581), train_loss = 1.39642266, grad/param norm = 1.7414e-01, time/batch = 0.6937s	
3752/28500 (epoch 6.582), train_loss = 1.49445430, grad/param norm = 1.8516e-01, time/batch = 0.6898s	
3753/28500 (epoch 6.584), train_loss = 1.35526084, grad/param norm = 1.6628e-01, time/batch = 0.6903s	
3754/28500 (epoch 6.586), train_loss = 1.26708982, grad/param norm = 1.5403e-01, time/batch = 0.6891s	
3755/28500 (epoch 6.588), train_loss = 1.32166007, grad/param norm = 1.7268e-01, time/batch = 0.6961s	
3756/28500 (epoch 6.589), train_loss = 1.62116207, grad/param norm = 1.8326e-01, time/batch = 0.6919s	
3757/28500 (epoch 6.591), train_loss = 1.48218181, grad/param norm = 1.6304e-01, time/batch = 0.6926s	
3758/28500 (epoch 6.593), train_loss = 1.35935285, grad/param norm = 1.6807e-01, time/batch = 0.6930s	
3759/28500 (epoch 6.595), train_loss = 1.68705287, grad/param norm = 2.2180e-01, time/batch = 0.6886s	
3760/28500 (epoch 6.596), train_loss = 1.63051086, grad/param norm = 2.0232e-01, time/batch = 0.6887s	
3761/28500 (epoch 6.598), train_loss = 1.42531249, grad/param norm = 1.6123e-01, time/batch = 0.6916s	
3762/28500 (epoch 6.600), train_loss = 1.49411201, grad/param norm = 1.9487e-01, time/batch = 0.6948s	
3763/28500 (epoch 6.602), train_loss = 1.64876584, grad/param norm = 1.8610e-01, time/batch = 0.7080s	
3764/28500 (epoch 6.604), train_loss = 1.49555597, grad/param norm = 1.7461e-01, time/batch = 0.6937s	
3765/28500 (epoch 6.605), train_loss = 1.44886765, grad/param norm = 1.7919e-01, time/batch = 0.7029s	
3766/28500 (epoch 6.607), train_loss = 1.47498642, grad/param norm = 1.6790e-01, time/batch = 0.6972s	
3767/28500 (epoch 6.609), train_loss = 1.44730090, grad/param norm = 1.8433e-01, time/batch = 0.6913s	
3768/28500 (epoch 6.611), train_loss = 1.45989715, grad/param norm = 1.8368e-01, time/batch = 0.6928s	
3769/28500 (epoch 6.612), train_loss = 1.46674631, grad/param norm = 1.6618e-01, time/batch = 0.6908s	
3770/28500 (epoch 6.614), train_loss = 1.45082705, grad/param norm = 1.7877e-01, time/batch = 0.6921s	
3771/28500 (epoch 6.616), train_loss = 1.42412950, grad/param norm = 1.9343e-01, time/batch = 0.6938s	
3772/28500 (epoch 6.618), train_loss = 1.35063068, grad/param norm = 1.6815e-01, time/batch = 0.6947s	
3773/28500 (epoch 6.619), train_loss = 1.63349067, grad/param norm = 1.9254e-01, time/batch = 0.6923s	
3774/28500 (epoch 6.621), train_loss = 1.17684433, grad/param norm = 1.4977e-01, time/batch = 0.6942s	
3775/28500 (epoch 6.623), train_loss = 1.46975529, grad/param norm = 1.8178e-01, time/batch = 0.6927s	
3776/28500 (epoch 6.625), train_loss = 1.26602131, grad/param norm = 1.7305e-01, time/batch = 0.6924s	
3777/28500 (epoch 6.626), train_loss = 1.15981767, grad/param norm = 1.5543e-01, time/batch = 0.6954s	
3778/28500 (epoch 6.628), train_loss = 1.32136164, grad/param norm = 1.8053e-01, time/batch = 0.6931s	
3779/28500 (epoch 6.630), train_loss = 1.26840126, grad/param norm = 1.6064e-01, time/batch = 0.6921s	
3780/28500 (epoch 6.632), train_loss = 1.50121227, grad/param norm = 1.7769e-01, time/batch = 0.6942s	
3781/28500 (epoch 6.633), train_loss = 1.48583370, grad/param norm = 1.7403e-01, time/batch = 0.6947s	
3782/28500 (epoch 6.635), train_loss = 1.58992607, grad/param norm = 1.8223e-01, time/batch = 0.6951s	
3783/28500 (epoch 6.637), train_loss = 1.44146429, grad/param norm = 1.6922e-01, time/batch = 0.6945s	
3784/28500 (epoch 6.639), train_loss = 1.22874445, grad/param norm = 1.6127e-01, time/batch = 0.6917s	
3785/28500 (epoch 6.640), train_loss = 1.32569987, grad/param norm = 1.7355e-01, time/batch = 0.6928s	
3786/28500 (epoch 6.642), train_loss = 1.47910135, grad/param norm = 1.7182e-01, time/batch = 0.6918s	
3787/28500 (epoch 6.644), train_loss = 1.50173152, grad/param norm = 1.6784e-01, time/batch = 0.7167s	
3788/28500 (epoch 6.646), train_loss = 1.32354353, grad/param norm = 1.6418e-01, time/batch = 0.6952s	
3789/28500 (epoch 6.647), train_loss = 1.31166027, grad/param norm = 1.7584e-01, time/batch = 0.6955s	
3790/28500 (epoch 6.649), train_loss = 1.32921630, grad/param norm = 1.6540e-01, time/batch = 0.6940s	
3791/28500 (epoch 6.651), train_loss = 1.29505418, grad/param norm = 1.7018e-01, time/batch = 0.6940s	
3792/28500 (epoch 6.653), train_loss = 1.30324600, grad/param norm = 1.7172e-01, time/batch = 0.6909s	
3793/28500 (epoch 6.654), train_loss = 1.36075432, grad/param norm = 1.7563e-01, time/batch = 0.6897s	
3794/28500 (epoch 6.656), train_loss = 1.39980558, grad/param norm = 1.8180e-01, time/batch = 0.6998s	
3795/28500 (epoch 6.658), train_loss = 1.45567590, grad/param norm = 1.8453e-01, time/batch = 0.6889s	
3796/28500 (epoch 6.660), train_loss = 1.38399030, grad/param norm = 1.5429e-01, time/batch = 0.6886s	
3797/28500 (epoch 6.661), train_loss = 1.54569981, grad/param norm = 1.9145e-01, time/batch = 0.6891s	
3798/28500 (epoch 6.663), train_loss = 1.62218300, grad/param norm = 1.9032e-01, time/batch = 0.6889s	
3799/28500 (epoch 6.665), train_loss = 1.38979058, grad/param norm = 1.7662e-01, time/batch = 0.6886s	
3800/28500 (epoch 6.667), train_loss = 1.48058740, grad/param norm = 1.7940e-01, time/batch = 0.6888s	
3801/28500 (epoch 6.668), train_loss = 1.40445260, grad/param norm = 1.7374e-01, time/batch = 0.6953s	
3802/28500 (epoch 6.670), train_loss = 1.39494850, grad/param norm = 1.8100e-01, time/batch = 0.6898s	
3803/28500 (epoch 6.672), train_loss = 1.39236935, grad/param norm = 1.6518e-01, time/batch = 0.6895s	
3804/28500 (epoch 6.674), train_loss = 1.26884949, grad/param norm = 1.9754e-01, time/batch = 0.6901s	
3805/28500 (epoch 6.675), train_loss = 1.26620246, grad/param norm = 1.6997e-01, time/batch = 0.6904s	
3806/28500 (epoch 6.677), train_loss = 1.37600345, grad/param norm = 1.8334e-01, time/batch = 0.6944s	
3807/28500 (epoch 6.679), train_loss = 1.41443564, grad/param norm = 1.8346e-01, time/batch = 0.6931s	
3808/28500 (epoch 6.681), train_loss = 1.52130028, grad/param norm = 1.8456e-01, time/batch = 0.6932s	
3809/28500 (epoch 6.682), train_loss = 1.34494673, grad/param norm = 1.8931e-01, time/batch = 0.6941s	
3810/28500 (epoch 6.684), train_loss = 1.46239864, grad/param norm = 1.7745e-01, time/batch = 0.6937s	
3811/28500 (epoch 6.686), train_loss = 1.35147750, grad/param norm = 1.8220e-01, time/batch = 0.6950s	
3812/28500 (epoch 6.688), train_loss = 1.35525602, grad/param norm = 1.5803e-01, time/batch = 0.6920s	
3813/28500 (epoch 6.689), train_loss = 1.44557508, grad/param norm = 1.8334e-01, time/batch = 0.6928s	
3814/28500 (epoch 6.691), train_loss = 1.43191651, grad/param norm = 1.8769e-01, time/batch = 0.6926s	
3815/28500 (epoch 6.693), train_loss = 1.40022325, grad/param norm = 1.8197e-01, time/batch = 0.6944s	
3816/28500 (epoch 6.695), train_loss = 1.34539178, grad/param norm = 1.9776e-01, time/batch = 0.6926s	
3817/28500 (epoch 6.696), train_loss = 1.42114719, grad/param norm = 1.9522e-01, time/batch = 0.6927s	
3818/28500 (epoch 6.698), train_loss = 1.40630593, grad/param norm = 1.6910e-01, time/batch = 0.6912s	
3819/28500 (epoch 6.700), train_loss = 1.41462664, grad/param norm = 1.7741e-01, time/batch = 0.6937s	
3820/28500 (epoch 6.702), train_loss = 1.58502339, grad/param norm = 1.8483e-01, time/batch = 0.6919s	
3821/28500 (epoch 6.704), train_loss = 1.46157334, grad/param norm = 1.8338e-01, time/batch = 0.6962s	
3822/28500 (epoch 6.705), train_loss = 1.50711291, grad/param norm = 1.8866e-01, time/batch = 0.6937s	
3823/28500 (epoch 6.707), train_loss = 1.41963346, grad/param norm = 1.8579e-01, time/batch = 0.6924s	
3824/28500 (epoch 6.709), train_loss = 1.49474067, grad/param norm = 1.8116e-01, time/batch = 0.6931s	
3825/28500 (epoch 6.711), train_loss = 1.36544871, grad/param norm = 2.0571e-01, time/batch = 0.6934s	
3826/28500 (epoch 6.712), train_loss = 1.51372012, grad/param norm = 2.0019e-01, time/batch = 0.6938s	
3827/28500 (epoch 6.714), train_loss = 1.46442294, grad/param norm = 1.7392e-01, time/batch = 0.6922s	
3828/28500 (epoch 6.716), train_loss = 1.38072233, grad/param norm = 1.7789e-01, time/batch = 0.6925s	
3829/28500 (epoch 6.718), train_loss = 1.32008643, grad/param norm = 1.7538e-01, time/batch = 0.6927s	
3830/28500 (epoch 6.719), train_loss = 1.33205623, grad/param norm = 1.6513e-01, time/batch = 0.6924s	
3831/28500 (epoch 6.721), train_loss = 1.16656456, grad/param norm = 1.6621e-01, time/batch = 0.6930s	
3832/28500 (epoch 6.723), train_loss = 1.41008318, grad/param norm = 1.7405e-01, time/batch = 0.6930s	
3833/28500 (epoch 6.725), train_loss = 1.50725053, grad/param norm = 1.6996e-01, time/batch = 0.6916s	
3834/28500 (epoch 6.726), train_loss = 1.41885849, grad/param norm = 1.8005e-01, time/batch = 0.6931s	
3835/28500 (epoch 6.728), train_loss = 1.24933436, grad/param norm = 1.6284e-01, time/batch = 0.6929s	
3836/28500 (epoch 6.730), train_loss = 1.41948847, grad/param norm = 1.8553e-01, time/batch = 0.6942s	
3837/28500 (epoch 6.732), train_loss = 1.23723855, grad/param norm = 1.7981e-01, time/batch = 0.6924s	
3838/28500 (epoch 6.733), train_loss = 1.22409768, grad/param norm = 1.6857e-01, time/batch = 0.6944s	
3839/28500 (epoch 6.735), train_loss = 1.22157303, grad/param norm = 1.5212e-01, time/batch = 0.6940s	
3840/28500 (epoch 6.737), train_loss = 1.19871464, grad/param norm = 1.5991e-01, time/batch = 0.6926s	
3841/28500 (epoch 6.739), train_loss = 1.39437102, grad/param norm = 1.7960e-01, time/batch = 0.6966s	
3842/28500 (epoch 6.740), train_loss = 1.40636263, grad/param norm = 1.7942e-01, time/batch = 0.6944s	
3843/28500 (epoch 6.742), train_loss = 1.34606875, grad/param norm = 1.7476e-01, time/batch = 0.6931s	
3844/28500 (epoch 6.744), train_loss = 1.46407629, grad/param norm = 1.7715e-01, time/batch = 0.6930s	
3845/28500 (epoch 6.746), train_loss = 1.27826303, grad/param norm = 1.5471e-01, time/batch = 0.6939s	
3846/28500 (epoch 6.747), train_loss = 1.29331968, grad/param norm = 1.7214e-01, time/batch = 0.6928s	
3847/28500 (epoch 6.749), train_loss = 1.61037639, grad/param norm = 1.9380e-01, time/batch = 0.6981s	
3848/28500 (epoch 6.751), train_loss = 1.31193831, grad/param norm = 1.7518e-01, time/batch = 0.7012s	
3849/28500 (epoch 6.753), train_loss = 1.27268934, grad/param norm = 1.5930e-01, time/batch = 0.7172s	
3850/28500 (epoch 6.754), train_loss = 1.21427198, grad/param norm = 1.5992e-01, time/batch = 0.7147s	
3851/28500 (epoch 6.756), train_loss = 1.50485403, grad/param norm = 1.7273e-01, time/batch = 0.7139s	
3852/28500 (epoch 6.758), train_loss = 1.43412559, grad/param norm = 1.7993e-01, time/batch = 0.7005s	
3853/28500 (epoch 6.760), train_loss = 1.28360518, grad/param norm = 1.8436e-01, time/batch = 0.7000s	
3854/28500 (epoch 6.761), train_loss = 1.30574698, grad/param norm = 1.7466e-01, time/batch = 0.6945s	
3855/28500 (epoch 6.763), train_loss = 1.15000549, grad/param norm = 1.6783e-01, time/batch = 0.6974s	
3856/28500 (epoch 6.765), train_loss = 1.31266424, grad/param norm = 1.5904e-01, time/batch = 0.6909s	
3857/28500 (epoch 6.767), train_loss = 1.15832373, grad/param norm = 1.5381e-01, time/batch = 0.7040s	
3858/28500 (epoch 6.768), train_loss = 1.51716281, grad/param norm = 1.9081e-01, time/batch = 0.6987s	
3859/28500 (epoch 6.770), train_loss = 1.21833670, grad/param norm = 1.7887e-01, time/batch = 0.6942s	
3860/28500 (epoch 6.772), train_loss = 1.15074501, grad/param norm = 1.7148e-01, time/batch = 0.7000s	
3861/28500 (epoch 6.774), train_loss = 1.43590184, grad/param norm = 1.8230e-01, time/batch = 0.6944s	
3862/28500 (epoch 6.775), train_loss = 1.46802606, grad/param norm = 1.6557e-01, time/batch = 0.6934s	
3863/28500 (epoch 6.777), train_loss = 1.40496400, grad/param norm = 1.7392e-01, time/batch = 0.6935s	
3864/28500 (epoch 6.779), train_loss = 1.24281328, grad/param norm = 1.6227e-01, time/batch = 0.7009s	
3865/28500 (epoch 6.781), train_loss = 1.47335814, grad/param norm = 1.9241e-01, time/batch = 0.6927s	
3866/28500 (epoch 6.782), train_loss = 1.53382146, grad/param norm = 1.9081e-01, time/batch = 0.6922s	
3867/28500 (epoch 6.784), train_loss = 1.17912245, grad/param norm = 1.6579e-01, time/batch = 0.6910s	
3868/28500 (epoch 6.786), train_loss = 1.34446065, grad/param norm = 1.6482e-01, time/batch = 0.6941s	
3869/28500 (epoch 6.788), train_loss = 1.47883507, grad/param norm = 1.9486e-01, time/batch = 0.6912s	
3870/28500 (epoch 6.789), train_loss = 1.14519865, grad/param norm = 1.6754e-01, time/batch = 0.6939s	
3871/28500 (epoch 6.791), train_loss = 1.37186726, grad/param norm = 1.8084e-01, time/batch = 0.6946s	
3872/28500 (epoch 6.793), train_loss = 1.27189958, grad/param norm = 1.8606e-01, time/batch = 0.6936s	
3873/28500 (epoch 6.795), train_loss = 1.39256663, grad/param norm = 1.6749e-01, time/batch = 0.6927s	
3874/28500 (epoch 6.796), train_loss = 1.28371190, grad/param norm = 1.6322e-01, time/batch = 0.6954s	
3875/28500 (epoch 6.798), train_loss = 1.24508845, grad/param norm = 1.5976e-01, time/batch = 0.6922s	
3876/28500 (epoch 6.800), train_loss = 1.29060561, grad/param norm = 1.7021e-01, time/batch = 0.6923s	
3877/28500 (epoch 6.802), train_loss = 1.41191998, grad/param norm = 1.9947e-01, time/batch = 0.6919s	
3878/28500 (epoch 6.804), train_loss = 1.38710685, grad/param norm = 1.7824e-01, time/batch = 0.6923s	
3879/28500 (epoch 6.805), train_loss = 1.41890141, grad/param norm = 1.8264e-01, time/batch = 0.6932s	
3880/28500 (epoch 6.807), train_loss = 1.51145719, grad/param norm = 1.8856e-01, time/batch = 0.6930s	
3881/28500 (epoch 6.809), train_loss = 1.33796172, grad/param norm = 1.6607e-01, time/batch = 0.6948s	
3882/28500 (epoch 6.811), train_loss = 1.49086335, grad/param norm = 1.9212e-01, time/batch = 0.6924s	
3883/28500 (epoch 6.812), train_loss = 1.46075797, grad/param norm = 1.8083e-01, time/batch = 0.6922s	
3884/28500 (epoch 6.814), train_loss = 1.36069849, grad/param norm = 1.7582e-01, time/batch = 0.6957s	
3885/28500 (epoch 6.816), train_loss = 1.55723755, grad/param norm = 1.8847e-01, time/batch = 0.6939s	
3886/28500 (epoch 6.818), train_loss = 1.43588968, grad/param norm = 1.7320e-01, time/batch = 0.6925s	
3887/28500 (epoch 6.819), train_loss = 1.37794461, grad/param norm = 1.7534e-01, time/batch = 0.6928s	
3888/28500 (epoch 6.821), train_loss = 1.30439767, grad/param norm = 1.6181e-01, time/batch = 0.6920s	
3889/28500 (epoch 6.823), train_loss = 1.63000432, grad/param norm = 1.9856e-01, time/batch = 0.6925s	
3890/28500 (epoch 6.825), train_loss = 1.37373740, grad/param norm = 1.9158e-01, time/batch = 0.6925s	
3891/28500 (epoch 6.826), train_loss = 1.45452744, grad/param norm = 2.1370e-01, time/batch = 0.6951s	
3892/28500 (epoch 6.828), train_loss = 1.26147805, grad/param norm = 1.8822e-01, time/batch = 0.6938s	
3893/28500 (epoch 6.830), train_loss = 1.31099862, grad/param norm = 1.5265e-01, time/batch = 0.6935s	
3894/28500 (epoch 6.832), train_loss = 1.38858106, grad/param norm = 1.7770e-01, time/batch = 0.6932s	
3895/28500 (epoch 6.833), train_loss = 1.55467837, grad/param norm = 1.7005e-01, time/batch = 0.6952s	
3896/28500 (epoch 6.835), train_loss = 1.33405933, grad/param norm = 1.8535e-01, time/batch = 0.6919s	
3897/28500 (epoch 6.837), train_loss = 1.23549136, grad/param norm = 1.6696e-01, time/batch = 0.6919s	
3898/28500 (epoch 6.839), train_loss = 1.53130174, grad/param norm = 1.9450e-01, time/batch = 0.6925s	
3899/28500 (epoch 6.840), train_loss = 1.52729629, grad/param norm = 1.8748e-01, time/batch = 0.6921s	
3900/28500 (epoch 6.842), train_loss = 1.43693015, grad/param norm = 1.6707e-01, time/batch = 0.6925s	
3901/28500 (epoch 6.844), train_loss = 1.41011236, grad/param norm = 1.7524e-01, time/batch = 0.6965s	
3902/28500 (epoch 6.846), train_loss = 1.53753879, grad/param norm = 1.7580e-01, time/batch = 0.6988s	
3903/28500 (epoch 6.847), train_loss = 1.35447996, grad/param norm = 1.6756e-01, time/batch = 0.6925s	
3904/28500 (epoch 6.849), train_loss = 1.31520505, grad/param norm = 1.5619e-01, time/batch = 0.6943s	
3905/28500 (epoch 6.851), train_loss = 1.20349611, grad/param norm = 1.6278e-01, time/batch = 0.6936s	
3906/28500 (epoch 6.853), train_loss = 1.40800595, grad/param norm = 1.7993e-01, time/batch = 0.6939s	
3907/28500 (epoch 6.854), train_loss = 1.38463306, grad/param norm = 1.7616e-01, time/batch = 0.6955s	
3908/28500 (epoch 6.856), train_loss = 1.47870493, grad/param norm = 1.7823e-01, time/batch = 0.6935s	
3909/28500 (epoch 6.858), train_loss = 1.21029231, grad/param norm = 1.5088e-01, time/batch = 0.6915s	
3910/28500 (epoch 6.860), train_loss = 1.47396699, grad/param norm = 1.8544e-01, time/batch = 0.6921s	
3911/28500 (epoch 6.861), train_loss = 1.38381467, grad/param norm = 1.8885e-01, time/batch = 0.6962s	
3912/28500 (epoch 6.863), train_loss = 1.51939761, grad/param norm = 1.7645e-01, time/batch = 0.6931s	
3913/28500 (epoch 6.865), train_loss = 1.37486795, grad/param norm = 1.7604e-01, time/batch = 0.6941s	
3914/28500 (epoch 6.867), train_loss = 1.45307240, grad/param norm = 1.8755e-01, time/batch = 0.6916s	
3915/28500 (epoch 6.868), train_loss = 1.26241643, grad/param norm = 1.7140e-01, time/batch = 0.6926s	
3916/28500 (epoch 6.870), train_loss = 1.15344208, grad/param norm = 1.4697e-01, time/batch = 0.6920s	
3917/28500 (epoch 6.872), train_loss = 1.46435361, grad/param norm = 1.8884e-01, time/batch = 0.6924s	
3918/28500 (epoch 6.874), train_loss = 1.39944048, grad/param norm = 1.8348e-01, time/batch = 0.6918s	
3919/28500 (epoch 6.875), train_loss = 1.48417320, grad/param norm = 1.7671e-01, time/batch = 0.6932s	
3920/28500 (epoch 6.877), train_loss = 1.38520938, grad/param norm = 1.9086e-01, time/batch = 0.6937s	
3921/28500 (epoch 6.879), train_loss = 1.36501743, grad/param norm = 1.7801e-01, time/batch = 0.6937s	
3922/28500 (epoch 6.881), train_loss = 1.45184526, grad/param norm = 1.7079e-01, time/batch = 0.6935s	
3923/28500 (epoch 6.882), train_loss = 1.35877871, grad/param norm = 1.7219e-01, time/batch = 0.6913s	
3924/28500 (epoch 6.884), train_loss = 1.44200537, grad/param norm = 1.8775e-01, time/batch = 0.6912s	
3925/28500 (epoch 6.886), train_loss = 1.27472558, grad/param norm = 1.6774e-01, time/batch = 0.6884s	
3926/28500 (epoch 6.888), train_loss = 1.24742044, grad/param norm = 1.6295e-01, time/batch = 0.6889s	
3927/28500 (epoch 6.889), train_loss = 1.32320888, grad/param norm = 1.6245e-01, time/batch = 0.6913s	
3928/28500 (epoch 6.891), train_loss = 1.39603305, grad/param norm = 1.6239e-01, time/batch = 0.6888s	
3929/28500 (epoch 6.893), train_loss = 1.34116111, grad/param norm = 1.9061e-01, time/batch = 0.6929s	
3930/28500 (epoch 6.895), train_loss = 1.59225579, grad/param norm = 1.9543e-01, time/batch = 0.6956s	
3931/28500 (epoch 6.896), train_loss = 1.49382273, grad/param norm = 1.9022e-01, time/batch = 0.6941s	
3932/28500 (epoch 6.898), train_loss = 1.35905487, grad/param norm = 1.7637e-01, time/batch = 0.6901s	
3933/28500 (epoch 6.900), train_loss = 1.24585403, grad/param norm = 1.6747e-01, time/batch = 0.6898s	
3934/28500 (epoch 6.902), train_loss = 1.26511399, grad/param norm = 1.5812e-01, time/batch = 0.6955s	
3935/28500 (epoch 6.904), train_loss = 1.24573894, grad/param norm = 1.5779e-01, time/batch = 0.7002s	
3936/28500 (epoch 6.905), train_loss = 1.40997061, grad/param norm = 1.7481e-01, time/batch = 0.6996s	
3937/28500 (epoch 6.907), train_loss = 1.49602972, grad/param norm = 1.8759e-01, time/batch = 0.6906s	
3938/28500 (epoch 6.909), train_loss = 1.28087545, grad/param norm = 1.7891e-01, time/batch = 0.6903s	
3939/28500 (epoch 6.911), train_loss = 1.29589602, grad/param norm = 1.6919e-01, time/batch = 0.6913s	
3940/28500 (epoch 6.912), train_loss = 1.09700820, grad/param norm = 1.7260e-01, time/batch = 0.6927s	
3941/28500 (epoch 6.914), train_loss = 1.50366971, grad/param norm = 1.7978e-01, time/batch = 0.6944s	
3942/28500 (epoch 6.916), train_loss = 1.44806841, grad/param norm = 1.7798e-01, time/batch = 0.6903s	
3943/28500 (epoch 6.918), train_loss = 1.38461092, grad/param norm = 1.8570e-01, time/batch = 0.6902s	
3944/28500 (epoch 6.919), train_loss = 1.31414020, grad/param norm = 1.6112e-01, time/batch = 0.6894s	
3945/28500 (epoch 6.921), train_loss = 1.58275472, grad/param norm = 2.1291e-01, time/batch = 0.6901s	
3946/28500 (epoch 6.923), train_loss = 1.44488068, grad/param norm = 2.0437e-01, time/batch = 0.6949s	
3947/28500 (epoch 6.925), train_loss = 1.26189307, grad/param norm = 1.7678e-01, time/batch = 0.6912s	
3948/28500 (epoch 6.926), train_loss = 1.40031957, grad/param norm = 1.8877e-01, time/batch = 0.6919s	
3949/28500 (epoch 6.928), train_loss = 1.29555931, grad/param norm = 1.6311e-01, time/batch = 0.7088s	
3950/28500 (epoch 6.930), train_loss = 1.06857962, grad/param norm = 1.6172e-01, time/batch = 0.7128s	
3951/28500 (epoch 6.932), train_loss = 1.18527426, grad/param norm = 1.5084e-01, time/batch = 0.7098s	
3952/28500 (epoch 6.933), train_loss = 1.39781480, grad/param norm = 1.7062e-01, time/batch = 0.6975s	
3953/28500 (epoch 6.935), train_loss = 1.42897744, grad/param norm = 1.9824e-01, time/batch = 0.7106s	
3954/28500 (epoch 6.937), train_loss = 1.53202781, grad/param norm = 1.8852e-01, time/batch = 0.7002s	
3955/28500 (epoch 6.939), train_loss = 1.61084235, grad/param norm = 1.8043e-01, time/batch = 0.6984s	
3956/28500 (epoch 6.940), train_loss = 1.28988542, grad/param norm = 1.6729e-01, time/batch = 0.6978s	
3957/28500 (epoch 6.942), train_loss = 1.48871036, grad/param norm = 1.7869e-01, time/batch = 0.7066s	
3958/28500 (epoch 6.944), train_loss = 1.41102201, grad/param norm = 1.7525e-01, time/batch = 0.6932s	
3959/28500 (epoch 6.946), train_loss = 1.52139690, grad/param norm = 1.7151e-01, time/batch = 0.6910s	
3960/28500 (epoch 6.947), train_loss = 1.75698824, grad/param norm = 2.0134e-01, time/batch = 0.6907s	
3961/28500 (epoch 6.949), train_loss = 1.26410080, grad/param norm = 1.7889e-01, time/batch = 0.7011s	
3962/28500 (epoch 6.951), train_loss = 1.57988971, grad/param norm = 2.0264e-01, time/batch = 0.6895s	
3963/28500 (epoch 6.953), train_loss = 1.63046884, grad/param norm = 2.2390e-01, time/batch = 0.6897s	
3964/28500 (epoch 6.954), train_loss = 1.50401110, grad/param norm = 1.8704e-01, time/batch = 0.6891s	
3965/28500 (epoch 6.956), train_loss = 1.47197620, grad/param norm = 2.0558e-01, time/batch = 0.6892s	
3966/28500 (epoch 6.958), train_loss = 1.51356135, grad/param norm = 1.8417e-01, time/batch = 0.6888s	
3967/28500 (epoch 6.960), train_loss = 1.30463083, grad/param norm = 1.7832e-01, time/batch = 0.6903s	
3968/28500 (epoch 6.961), train_loss = 1.62694654, grad/param norm = 1.9571e-01, time/batch = 0.6904s	
3969/28500 (epoch 6.963), train_loss = 1.47212004, grad/param norm = 1.5623e-01, time/batch = 0.6898s	
3970/28500 (epoch 6.965), train_loss = 1.25588852, grad/param norm = 1.5313e-01, time/batch = 0.6892s	
3971/28500 (epoch 6.967), train_loss = 1.23965981, grad/param norm = 1.6793e-01, time/batch = 0.6936s	
3972/28500 (epoch 6.968), train_loss = 1.19007230, grad/param norm = 1.5293e-01, time/batch = 0.6927s	
3973/28500 (epoch 6.970), train_loss = 1.43038204, grad/param norm = 1.8158e-01, time/batch = 0.7076s	
3974/28500 (epoch 6.972), train_loss = 1.59817904, grad/param norm = 1.9430e-01, time/batch = 0.6920s	
3975/28500 (epoch 6.974), train_loss = 1.65795040, grad/param norm = 1.9044e-01, time/batch = 0.6942s	
3976/28500 (epoch 6.975), train_loss = 1.35140538, grad/param norm = 1.8037e-01, time/batch = 0.6968s	
3977/28500 (epoch 6.977), train_loss = 1.59593135, grad/param norm = 1.8108e-01, time/batch = 0.6941s	
3978/28500 (epoch 6.979), train_loss = 1.30298216, grad/param norm = 1.6815e-01, time/batch = 0.6921s	
3979/28500 (epoch 6.981), train_loss = 1.34381300, grad/param norm = 1.7966e-01, time/batch = 0.6918s	
3980/28500 (epoch 6.982), train_loss = 1.26728406, grad/param norm = 1.5905e-01, time/batch = 0.6975s	
3981/28500 (epoch 6.984), train_loss = 1.45863930, grad/param norm = 1.7464e-01, time/batch = 0.6967s	
3982/28500 (epoch 6.986), train_loss = 1.58737280, grad/param norm = 1.9101e-01, time/batch = 0.6923s	
3983/28500 (epoch 6.988), train_loss = 1.19730583, grad/param norm = 1.7318e-01, time/batch = 0.6894s	
3984/28500 (epoch 6.989), train_loss = 1.45736961, grad/param norm = 1.8021e-01, time/batch = 0.6896s	
3985/28500 (epoch 6.991), train_loss = 1.30847023, grad/param norm = 1.7789e-01, time/batch = 0.6942s	
3986/28500 (epoch 6.993), train_loss = 1.32349144, grad/param norm = 1.7574e-01, time/batch = 0.6934s	
3987/28500 (epoch 6.995), train_loss = 1.34178922, grad/param norm = 1.8095e-01, time/batch = 0.6903s	
3988/28500 (epoch 6.996), train_loss = 1.27743233, grad/param norm = 1.5935e-01, time/batch = 0.6905s	
3989/28500 (epoch 6.998), train_loss = 1.50687166, grad/param norm = 1.8366e-01, time/batch = 0.6892s	
3990/28500 (epoch 7.000), train_loss = 1.31307657, grad/param norm = 1.6212e-01, time/batch = 0.6888s	
3991/28500 (epoch 7.002), train_loss = 1.51841505, grad/param norm = 1.8092e-01, time/batch = 0.6946s	
3992/28500 (epoch 7.004), train_loss = 1.31537354, grad/param norm = 1.7342e-01, time/batch = 0.6939s	
3993/28500 (epoch 7.005), train_loss = 1.46395043, grad/param norm = 1.8336e-01, time/batch = 0.6940s	
3994/28500 (epoch 7.007), train_loss = 1.21598294, grad/param norm = 1.5569e-01, time/batch = 0.6902s	
3995/28500 (epoch 7.009), train_loss = 1.49004345, grad/param norm = 1.8303e-01, time/batch = 0.6895s	
3996/28500 (epoch 7.011), train_loss = 1.37559383, grad/param norm = 1.9092e-01, time/batch = 0.6931s	
3997/28500 (epoch 7.012), train_loss = 1.19692965, grad/param norm = 1.4578e-01, time/batch = 0.6925s	
3998/28500 (epoch 7.014), train_loss = 1.25103846, grad/param norm = 1.5433e-01, time/batch = 0.6927s	
3999/28500 (epoch 7.016), train_loss = 1.30788073, grad/param norm = 1.4880e-01, time/batch = 0.6944s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch7.02_1.6088.t7	
4000/28500 (epoch 7.018), train_loss = 1.39680302, grad/param norm = 1.7549e-01, time/batch = 0.6908s	
4001/28500 (epoch 7.019), train_loss = 1.62978729, grad/param norm = 1.9926e-01, time/batch = 0.6911s	
4002/28500 (epoch 7.021), train_loss = 1.40547928, grad/param norm = 1.7507e-01, time/batch = 0.6821s	
4003/28500 (epoch 7.023), train_loss = 1.36035437, grad/param norm = 1.7345e-01, time/batch = 0.6774s	
4004/28500 (epoch 7.025), train_loss = 1.35930657, grad/param norm = 1.7180e-01, time/batch = 0.6858s	
4005/28500 (epoch 7.026), train_loss = 1.42664354, grad/param norm = 1.8437e-01, time/batch = 0.6881s	
4006/28500 (epoch 7.028), train_loss = 1.46632574, grad/param norm = 1.7773e-01, time/batch = 0.6845s	
4007/28500 (epoch 7.030), train_loss = 1.48823246, grad/param norm = 2.0245e-01, time/batch = 0.6803s	
4008/28500 (epoch 7.032), train_loss = 1.48225088, grad/param norm = 1.8450e-01, time/batch = 0.6844s	
4009/28500 (epoch 7.033), train_loss = 1.57655033, grad/param norm = 1.8017e-01, time/batch = 0.6782s	
4010/28500 (epoch 7.035), train_loss = 1.44369560, grad/param norm = 1.9344e-01, time/batch = 0.6765s	
4011/28500 (epoch 7.037), train_loss = 1.46535837, grad/param norm = 1.7004e-01, time/batch = 0.6791s	
4012/28500 (epoch 7.039), train_loss = 1.57932343, grad/param norm = 1.9398e-01, time/batch = 0.6823s	
4013/28500 (epoch 7.040), train_loss = 1.54240627, grad/param norm = 1.7323e-01, time/batch = 0.6952s	
4014/28500 (epoch 7.042), train_loss = 1.49426729, grad/param norm = 1.8012e-01, time/batch = 0.6850s	
4015/28500 (epoch 7.044), train_loss = 1.41100526, grad/param norm = 1.9414e-01, time/batch = 0.6827s	
4016/28500 (epoch 7.046), train_loss = 1.58534500, grad/param norm = 1.8485e-01, time/batch = 0.6758s	
4017/28500 (epoch 7.047), train_loss = 1.52130916, grad/param norm = 1.8746e-01, time/batch = 0.6762s	
4018/28500 (epoch 7.049), train_loss = 1.43095127, grad/param norm = 1.8915e-01, time/batch = 0.6778s	
4019/28500 (epoch 7.051), train_loss = 1.36541542, grad/param norm = 1.6704e-01, time/batch = 0.6803s	
4020/28500 (epoch 7.053), train_loss = 1.46324812, grad/param norm = 1.7305e-01, time/batch = 0.6768s	
4021/28500 (epoch 7.054), train_loss = 1.50674798, grad/param norm = 1.7717e-01, time/batch = 0.6789s	
4022/28500 (epoch 7.056), train_loss = 1.24259387, grad/param norm = 1.5780e-01, time/batch = 0.6825s	
4023/28500 (epoch 7.058), train_loss = 1.26769194, grad/param norm = 1.7612e-01, time/batch = 0.6824s	
4024/28500 (epoch 7.060), train_loss = 1.45709594, grad/param norm = 1.8560e-01, time/batch = 0.6823s	
4025/28500 (epoch 7.061), train_loss = 1.50868672, grad/param norm = 2.1024e-01, time/batch = 0.6920s	
4026/28500 (epoch 7.063), train_loss = 1.50009616, grad/param norm = 1.7594e-01, time/batch = 0.6905s	
4027/28500 (epoch 7.065), train_loss = 1.59069650, grad/param norm = 1.7609e-01, time/batch = 0.6926s	
4028/28500 (epoch 7.067), train_loss = 1.29644863, grad/param norm = 1.6103e-01, time/batch = 0.6979s	
4029/28500 (epoch 7.068), train_loss = 1.32459415, grad/param norm = 1.7071e-01, time/batch = 0.6872s	
4030/28500 (epoch 7.070), train_loss = 1.45756775, grad/param norm = 1.8033e-01, time/batch = 0.6875s	
4031/28500 (epoch 7.072), train_loss = 1.59973771, grad/param norm = 1.8435e-01, time/batch = 0.6805s	
4032/28500 (epoch 7.074), train_loss = 1.44781957, grad/param norm = 1.8605e-01, time/batch = 0.6958s	
4033/28500 (epoch 7.075), train_loss = 1.35997074, grad/param norm = 1.5504e-01, time/batch = 0.6890s	
4034/28500 (epoch 7.077), train_loss = 1.44978825, grad/param norm = 1.8290e-01, time/batch = 0.6822s	
4035/28500 (epoch 7.079), train_loss = 1.40513381, grad/param norm = 1.6581e-01, time/batch = 0.6778s	
4036/28500 (epoch 7.081), train_loss = 1.53902827, grad/param norm = 1.9042e-01, time/batch = 0.6800s	
4037/28500 (epoch 7.082), train_loss = 1.46880025, grad/param norm = 1.7988e-01, time/batch = 0.6796s	
4038/28500 (epoch 7.084), train_loss = 1.46371509, grad/param norm = 1.7788e-01, time/batch = 0.6822s	
4039/28500 (epoch 7.086), train_loss = 1.35363677, grad/param norm = 1.8881e-01, time/batch = 0.6816s	
4040/28500 (epoch 7.088), train_loss = 1.28702519, grad/param norm = 1.7958e-01, time/batch = 0.6794s	
4041/28500 (epoch 7.089), train_loss = 1.54416718, grad/param norm = 1.5519e-01, time/batch = 0.6825s	
4042/28500 (epoch 7.091), train_loss = 1.23029702, grad/param norm = 1.6217e-01, time/batch = 0.6805s	
4043/28500 (epoch 7.093), train_loss = 1.40989757, grad/param norm = 1.7275e-01, time/batch = 0.7002s	
4044/28500 (epoch 7.095), train_loss = 1.32784657, grad/param norm = 1.7047e-01, time/batch = 0.6868s	
4045/28500 (epoch 7.096), train_loss = 1.55183711, grad/param norm = 1.8064e-01, time/batch = 0.6846s	
4046/28500 (epoch 7.098), train_loss = 1.54280752, grad/param norm = 1.8624e-01, time/batch = 0.6832s	
4047/28500 (epoch 7.100), train_loss = 1.31923357, grad/param norm = 1.6488e-01, time/batch = 0.6826s	
4048/28500 (epoch 7.102), train_loss = 1.58721154, grad/param norm = 1.7734e-01, time/batch = 0.6804s	
4049/28500 (epoch 7.104), train_loss = 1.39751110, grad/param norm = 1.8114e-01, time/batch = 0.6823s	
4050/28500 (epoch 7.105), train_loss = 1.43481681, grad/param norm = 1.6937e-01, time/batch = 0.6811s	
4051/28500 (epoch 7.107), train_loss = 1.31304185, grad/param norm = 1.7571e-01, time/batch = 0.6865s	
4052/28500 (epoch 7.109), train_loss = 1.28315005, grad/param norm = 1.8444e-01, time/batch = 0.6812s	
4053/28500 (epoch 7.111), train_loss = 1.35641114, grad/param norm = 1.7494e-01, time/batch = 0.6811s	
4054/28500 (epoch 7.112), train_loss = 1.47929377, grad/param norm = 1.8929e-01, time/batch = 0.6802s	
4055/28500 (epoch 7.114), train_loss = 1.38884386, grad/param norm = 1.8067e-01, time/batch = 0.6805s	
4056/28500 (epoch 7.116), train_loss = 1.59021979, grad/param norm = 1.8531e-01, time/batch = 0.6800s	
4057/28500 (epoch 7.118), train_loss = 1.26805919, grad/param norm = 1.7925e-01, time/batch = 0.6803s	
4058/28500 (epoch 7.119), train_loss = 1.47320664, grad/param norm = 1.8023e-01, time/batch = 0.6800s	
4059/28500 (epoch 7.121), train_loss = 1.60974652, grad/param norm = 2.0096e-01, time/batch = 0.6805s	
4060/28500 (epoch 7.123), train_loss = 1.46703695, grad/param norm = 2.0128e-01, time/batch = 0.6833s	
4061/28500 (epoch 7.125), train_loss = 1.45630354, grad/param norm = 1.8401e-01, time/batch = 0.6831s	
4062/28500 (epoch 7.126), train_loss = 1.40861702, grad/param norm = 1.7150e-01, time/batch = 0.6812s	
4063/28500 (epoch 7.128), train_loss = 1.31233514, grad/param norm = 1.7440e-01, time/batch = 0.6822s	
4064/28500 (epoch 7.130), train_loss = 1.34594371, grad/param norm = 1.8029e-01, time/batch = 0.6824s	
4065/28500 (epoch 7.132), train_loss = 1.46277993, grad/param norm = 1.8050e-01, time/batch = 0.6817s	
4066/28500 (epoch 7.133), train_loss = 1.38891508, grad/param norm = 1.6879e-01, time/batch = 0.6807s	
4067/28500 (epoch 7.135), train_loss = 1.38878738, grad/param norm = 1.6499e-01, time/batch = 0.6819s	
4068/28500 (epoch 7.137), train_loss = 1.38395853, grad/param norm = 1.8377e-01, time/batch = 0.6797s	
4069/28500 (epoch 7.139), train_loss = 1.37275731, grad/param norm = 1.5678e-01, time/batch = 0.6802s	
4070/28500 (epoch 7.140), train_loss = 1.43028059, grad/param norm = 1.7754e-01, time/batch = 0.6808s	
4071/28500 (epoch 7.142), train_loss = 1.44621444, grad/param norm = 1.7829e-01, time/batch = 0.6830s	
4072/28500 (epoch 7.144), train_loss = 1.27091015, grad/param norm = 1.6041e-01, time/batch = 0.6825s	
4073/28500 (epoch 7.146), train_loss = 1.29631235, grad/param norm = 1.6744e-01, time/batch = 0.6831s	
4074/28500 (epoch 7.147), train_loss = 1.22001344, grad/param norm = 1.6420e-01, time/batch = 0.6802s	
4075/28500 (epoch 7.149), train_loss = 1.24122957, grad/param norm = 1.5909e-01, time/batch = 0.6805s	
4076/28500 (epoch 7.151), train_loss = 1.23006794, grad/param norm = 1.6196e-01, time/batch = 0.6811s	
4077/28500 (epoch 7.153), train_loss = 1.36883495, grad/param norm = 1.6739e-01, time/batch = 0.6802s	
4078/28500 (epoch 7.154), train_loss = 1.29232266, grad/param norm = 1.7999e-01, time/batch = 0.6813s	
4079/28500 (epoch 7.156), train_loss = 1.58395575, grad/param norm = 1.9694e-01, time/batch = 0.6824s	
4080/28500 (epoch 7.158), train_loss = 1.34639734, grad/param norm = 1.6168e-01, time/batch = 0.6827s	
4081/28500 (epoch 7.160), train_loss = 1.26342269, grad/param norm = 1.5276e-01, time/batch = 0.6825s	
4082/28500 (epoch 7.161), train_loss = 1.44746533, grad/param norm = 1.8796e-01, time/batch = 0.6830s	
4083/28500 (epoch 7.163), train_loss = 1.29101621, grad/param norm = 1.8406e-01, time/batch = 0.6824s	
4084/28500 (epoch 7.165), train_loss = 1.59822049, grad/param norm = 1.7508e-01, time/batch = 0.6825s	
4085/28500 (epoch 7.167), train_loss = 1.69248660, grad/param norm = 1.9771e-01, time/batch = 0.6798s	
4086/28500 (epoch 7.168), train_loss = 1.49604177, grad/param norm = 1.9927e-01, time/batch = 0.6759s	
4087/28500 (epoch 7.170), train_loss = 1.55135459, grad/param norm = 2.0939e-01, time/batch = 0.6764s	
4088/28500 (epoch 7.172), train_loss = 1.37007277, grad/param norm = 1.8033e-01, time/batch = 0.6937s	
4089/28500 (epoch 7.174), train_loss = 1.63491087, grad/param norm = 1.9465e-01, time/batch = 0.6857s	
4090/28500 (epoch 7.175), train_loss = 1.34278336, grad/param norm = 1.6724e-01, time/batch = 0.6754s	
4091/28500 (epoch 7.177), train_loss = 1.48307143, grad/param norm = 1.8192e-01, time/batch = 0.6807s	
4092/28500 (epoch 7.179), train_loss = 1.36989351, grad/param norm = 1.8218e-01, time/batch = 0.6797s	
4093/28500 (epoch 7.181), train_loss = 1.44438800, grad/param norm = 1.6817e-01, time/batch = 0.6761s	
4094/28500 (epoch 7.182), train_loss = 1.39441317, grad/param norm = 1.8174e-01, time/batch = 0.6770s	
4095/28500 (epoch 7.184), train_loss = 1.63154445, grad/param norm = 1.9953e-01, time/batch = 0.6778s	
4096/28500 (epoch 7.186), train_loss = 1.52258434, grad/param norm = 1.8083e-01, time/batch = 0.6782s	
4097/28500 (epoch 7.188), train_loss = 1.39312825, grad/param norm = 1.6633e-01, time/batch = 0.6764s	
4098/28500 (epoch 7.189), train_loss = 1.44047444, grad/param norm = 1.7737e-01, time/batch = 0.6772s	
4099/28500 (epoch 7.191), train_loss = 1.66820661, grad/param norm = 1.8314e-01, time/batch = 0.6788s	
4100/28500 (epoch 7.193), train_loss = 1.53601126, grad/param norm = 1.9754e-01, time/batch = 0.6824s	
4101/28500 (epoch 7.195), train_loss = 1.52512233, grad/param norm = 1.8972e-01, time/batch = 0.6966s	
4102/28500 (epoch 7.196), train_loss = 1.47281087, grad/param norm = 1.7360e-01, time/batch = 0.6787s	
4103/28500 (epoch 7.198), train_loss = 1.44202987, grad/param norm = 1.8331e-01, time/batch = 0.6773s	
4104/28500 (epoch 7.200), train_loss = 1.39031069, grad/param norm = 1.5479e-01, time/batch = 0.6760s	
4105/28500 (epoch 7.202), train_loss = 1.43078158, grad/param norm = 1.8738e-01, time/batch = 0.6766s	
4106/28500 (epoch 7.204), train_loss = 1.26883982, grad/param norm = 1.6375e-01, time/batch = 0.6800s	
4107/28500 (epoch 7.205), train_loss = 1.35285656, grad/param norm = 1.7016e-01, time/batch = 0.6813s	
4108/28500 (epoch 7.207), train_loss = 1.40027525, grad/param norm = 1.8109e-01, time/batch = 0.6988s	
4109/28500 (epoch 7.209), train_loss = 1.40153956, grad/param norm = 1.8595e-01, time/batch = 0.6828s	
4110/28500 (epoch 7.211), train_loss = 1.23615394, grad/param norm = 1.5652e-01, time/batch = 0.6836s	
4111/28500 (epoch 7.212), train_loss = 1.25356942, grad/param norm = 1.6637e-01, time/batch = 0.6933s	
4112/28500 (epoch 7.214), train_loss = 1.45254216, grad/param norm = 1.9180e-01, time/batch = 0.6850s	
4113/28500 (epoch 7.216), train_loss = 1.26503740, grad/param norm = 1.6096e-01, time/batch = 0.6826s	
4114/28500 (epoch 7.218), train_loss = 1.48276953, grad/param norm = 1.6553e-01, time/batch = 0.6796s	
4115/28500 (epoch 7.219), train_loss = 1.43214469, grad/param norm = 1.8423e-01, time/batch = 0.6792s	
4116/28500 (epoch 7.221), train_loss = 1.29188833, grad/param norm = 1.7732e-01, time/batch = 0.6780s	
4117/28500 (epoch 7.223), train_loss = 1.53727202, grad/param norm = 1.9557e-01, time/batch = 0.6760s	
4118/28500 (epoch 7.225), train_loss = 1.56680055, grad/param norm = 1.8041e-01, time/batch = 0.6763s	
4119/28500 (epoch 7.226), train_loss = 1.39708381, grad/param norm = 1.7733e-01, time/batch = 0.6760s	
4120/28500 (epoch 7.228), train_loss = 1.43227001, grad/param norm = 1.6306e-01, time/batch = 0.6783s	
4121/28500 (epoch 7.230), train_loss = 1.47733459, grad/param norm = 1.7283e-01, time/batch = 0.6823s	
4122/28500 (epoch 7.232), train_loss = 1.46694505, grad/param norm = 1.7521e-01, time/batch = 0.6819s	
4123/28500 (epoch 7.233), train_loss = 1.44152723, grad/param norm = 1.8293e-01, time/batch = 0.6763s	
4124/28500 (epoch 7.235), train_loss = 1.33952938, grad/param norm = 1.7104e-01, time/batch = 0.6760s	
4125/28500 (epoch 7.237), train_loss = 1.22069242, grad/param norm = 1.4629e-01, time/batch = 0.6756s	
4126/28500 (epoch 7.239), train_loss = 1.31450999, grad/param norm = 1.7286e-01, time/batch = 0.6777s	
4127/28500 (epoch 7.240), train_loss = 1.23886304, grad/param norm = 1.6322e-01, time/batch = 0.6762s	
4128/28500 (epoch 7.242), train_loss = 1.44515674, grad/param norm = 1.7645e-01, time/batch = 0.6759s	
4129/28500 (epoch 7.244), train_loss = 1.48110110, grad/param norm = 1.8233e-01, time/batch = 0.6772s	
4130/28500 (epoch 7.246), train_loss = 1.48244966, grad/param norm = 1.7787e-01, time/batch = 0.6765s	
4131/28500 (epoch 7.247), train_loss = 1.62232262, grad/param norm = 1.8853e-01, time/batch = 0.6787s	
4132/28500 (epoch 7.249), train_loss = 1.45022623, grad/param norm = 1.8800e-01, time/batch = 0.6770s	
4133/28500 (epoch 7.251), train_loss = 1.24311159, grad/param norm = 1.5970e-01, time/batch = 0.6785s	
4134/28500 (epoch 7.253), train_loss = 1.59845234, grad/param norm = 2.0068e-01, time/batch = 0.6801s	
4135/28500 (epoch 7.254), train_loss = 1.51251922, grad/param norm = 1.7709e-01, time/batch = 0.6923s	
4136/28500 (epoch 7.256), train_loss = 1.31795974, grad/param norm = 1.6289e-01, time/batch = 0.6839s	
4137/28500 (epoch 7.258), train_loss = 1.39437709, grad/param norm = 1.7826e-01, time/batch = 0.6775s	
4138/28500 (epoch 7.260), train_loss = 1.34116252, grad/param norm = 1.6376e-01, time/batch = 0.6791s	
4139/28500 (epoch 7.261), train_loss = 1.33134618, grad/param norm = 1.7102e-01, time/batch = 0.6797s	
4140/28500 (epoch 7.263), train_loss = 1.57738692, grad/param norm = 1.9577e-01, time/batch = 0.6759s	
4141/28500 (epoch 7.265), train_loss = 1.44479294, grad/param norm = 1.8860e-01, time/batch = 0.6828s	
4142/28500 (epoch 7.267), train_loss = 1.57678953, grad/param norm = 1.9394e-01, time/batch = 0.6822s	
4143/28500 (epoch 7.268), train_loss = 1.49079650, grad/param norm = 1.6275e-01, time/batch = 0.6811s	
4144/28500 (epoch 7.270), train_loss = 1.42786893, grad/param norm = 1.9283e-01, time/batch = 0.6790s	
4145/28500 (epoch 7.272), train_loss = 1.38874758, grad/param norm = 1.8072e-01, time/batch = 0.6761s	
4146/28500 (epoch 7.274), train_loss = 1.57073362, grad/param norm = 1.9710e-01, time/batch = 0.6774s	
4147/28500 (epoch 7.275), train_loss = 1.47221410, grad/param norm = 1.6955e-01, time/batch = 0.6797s	
4148/28500 (epoch 7.277), train_loss = 1.37519645, grad/param norm = 1.7824e-01, time/batch = 0.6787s	
4149/28500 (epoch 7.279), train_loss = 1.44364336, grad/param norm = 1.8252e-01, time/batch = 0.6772s	
4150/28500 (epoch 7.281), train_loss = 1.46141721, grad/param norm = 1.7558e-01, time/batch = 0.6775s	
4151/28500 (epoch 7.282), train_loss = 1.28628383, grad/param norm = 1.5940e-01, time/batch = 0.6786s	
4152/28500 (epoch 7.284), train_loss = 1.45057275, grad/param norm = 1.7290e-01, time/batch = 0.6774s	
4153/28500 (epoch 7.286), train_loss = 1.52343830, grad/param norm = 1.8575e-01, time/batch = 0.6810s	
4154/28500 (epoch 7.288), train_loss = 1.44908676, grad/param norm = 1.7742e-01, time/batch = 0.6803s	
4155/28500 (epoch 7.289), train_loss = 1.54891285, grad/param norm = 1.7620e-01, time/batch = 0.6966s	
4156/28500 (epoch 7.291), train_loss = 1.38618728, grad/param norm = 1.7097e-01, time/batch = 0.6764s	
4157/28500 (epoch 7.293), train_loss = 1.34537283, grad/param norm = 1.7273e-01, time/batch = 0.6821s	
4158/28500 (epoch 7.295), train_loss = 1.29743389, grad/param norm = 1.6511e-01, time/batch = 0.6819s	
4159/28500 (epoch 7.296), train_loss = 1.29245670, grad/param norm = 1.6242e-01, time/batch = 0.6797s	
4160/28500 (epoch 7.298), train_loss = 1.41634806, grad/param norm = 1.7605e-01, time/batch = 0.6816s	
4161/28500 (epoch 7.300), train_loss = 1.31077069, grad/param norm = 1.6743e-01, time/batch = 0.6863s	
4162/28500 (epoch 7.302), train_loss = 1.27096610, grad/param norm = 1.6656e-01, time/batch = 0.6812s	
4163/28500 (epoch 7.304), train_loss = 1.39855055, grad/param norm = 1.6681e-01, time/batch = 0.6786s	
4164/28500 (epoch 7.305), train_loss = 1.47677006, grad/param norm = 1.8450e-01, time/batch = 0.6793s	
4165/28500 (epoch 7.307), train_loss = 1.46799391, grad/param norm = 1.9547e-01, time/batch = 0.6781s	
4166/28500 (epoch 7.309), train_loss = 1.45956350, grad/param norm = 1.9307e-01, time/batch = 0.6813s	
4167/28500 (epoch 7.311), train_loss = 1.42030045, grad/param norm = 1.9136e-01, time/batch = 0.6830s	
4168/28500 (epoch 7.312), train_loss = 1.32690934, grad/param norm = 1.6841e-01, time/batch = 0.6808s	
4169/28500 (epoch 7.314), train_loss = 1.47380152, grad/param norm = 1.8451e-01, time/batch = 0.6869s	
4170/28500 (epoch 7.316), train_loss = 1.43711234, grad/param norm = 1.6353e-01, time/batch = 0.6818s	
4171/28500 (epoch 7.318), train_loss = 1.45977250, grad/param norm = 1.9757e-01, time/batch = 0.6816s	
4172/28500 (epoch 7.319), train_loss = 1.37852130, grad/param norm = 1.7146e-01, time/batch = 0.6850s	
4173/28500 (epoch 7.321), train_loss = 1.45869618, grad/param norm = 1.9518e-01, time/batch = 0.6794s	
4174/28500 (epoch 7.323), train_loss = 1.37568269, grad/param norm = 1.7784e-01, time/batch = 0.6802s	
4175/28500 (epoch 7.325), train_loss = 1.59299552, grad/param norm = 1.8190e-01, time/batch = 0.6792s	
4176/28500 (epoch 7.326), train_loss = 1.47061256, grad/param norm = 1.9002e-01, time/batch = 0.6826s	
4177/28500 (epoch 7.328), train_loss = 1.16338192, grad/param norm = 1.5812e-01, time/batch = 0.6801s	
4178/28500 (epoch 7.330), train_loss = 1.30751971, grad/param norm = 1.6555e-01, time/batch = 0.6808s	
4179/28500 (epoch 7.332), train_loss = 1.37649737, grad/param norm = 1.6222e-01, time/batch = 0.6781s	
4180/28500 (epoch 7.333), train_loss = 1.22509523, grad/param norm = 1.6784e-01, time/batch = 0.6797s	
4181/28500 (epoch 7.335), train_loss = 1.27115212, grad/param norm = 1.5603e-01, time/batch = 0.6819s	
4182/28500 (epoch 7.337), train_loss = 1.37218386, grad/param norm = 1.7209e-01, time/batch = 0.6816s	
4183/28500 (epoch 7.339), train_loss = 1.29729222, grad/param norm = 1.6078e-01, time/batch = 0.6800s	
4184/28500 (epoch 7.340), train_loss = 1.49336815, grad/param norm = 1.7945e-01, time/batch = 0.6808s	
4185/28500 (epoch 7.342), train_loss = 1.36002613, grad/param norm = 1.8724e-01, time/batch = 0.6790s	
4186/28500 (epoch 7.344), train_loss = 1.32602093, grad/param norm = 1.8491e-01, time/batch = 0.6795s	
4187/28500 (epoch 7.346), train_loss = 1.09812814, grad/param norm = 1.4867e-01, time/batch = 0.6819s	
4188/28500 (epoch 7.347), train_loss = 1.40593254, grad/param norm = 1.8040e-01, time/batch = 0.6848s	
4189/28500 (epoch 7.349), train_loss = 1.29513567, grad/param norm = 1.5620e-01, time/batch = 0.6886s	
4190/28500 (epoch 7.351), train_loss = 1.27122712, grad/param norm = 1.5684e-01, time/batch = 0.6828s	
4191/28500 (epoch 7.353), train_loss = 1.46535281, grad/param norm = 1.8148e-01, time/batch = 0.6817s	
4192/28500 (epoch 7.354), train_loss = 1.26177000, grad/param norm = 1.7350e-01, time/batch = 0.6831s	
4193/28500 (epoch 7.356), train_loss = 1.29580544, grad/param norm = 1.5029e-01, time/batch = 0.6807s	
4194/28500 (epoch 7.358), train_loss = 1.42827367, grad/param norm = 1.5848e-01, time/batch = 0.6850s	
4195/28500 (epoch 7.360), train_loss = 1.41097591, grad/param norm = 1.8155e-01, time/batch = 0.6796s	
4196/28500 (epoch 7.361), train_loss = 1.32890039, grad/param norm = 1.6031e-01, time/batch = 0.6794s	
4197/28500 (epoch 7.363), train_loss = 1.26324614, grad/param norm = 1.5811e-01, time/batch = 0.6798s	
4198/28500 (epoch 7.365), train_loss = 1.33227073, grad/param norm = 1.7612e-01, time/batch = 0.6793s	
4199/28500 (epoch 7.367), train_loss = 1.37406558, grad/param norm = 1.6387e-01, time/batch = 0.6797s	
4200/28500 (epoch 7.368), train_loss = 1.32893181, grad/param norm = 1.6074e-01, time/batch = 0.6828s	
4201/28500 (epoch 7.370), train_loss = 1.42054920, grad/param norm = 1.7502e-01, time/batch = 0.6832s	
4202/28500 (epoch 7.372), train_loss = 1.23239904, grad/param norm = 1.6185e-01, time/batch = 0.6854s	
4203/28500 (epoch 7.374), train_loss = 1.42225129, grad/param norm = 1.8558e-01, time/batch = 0.6889s	
4204/28500 (epoch 7.375), train_loss = 1.56425717, grad/param norm = 1.8415e-01, time/batch = 0.6817s	
4205/28500 (epoch 7.377), train_loss = 1.32387032, grad/param norm = 1.6844e-01, time/batch = 0.6799s	
4206/28500 (epoch 7.379), train_loss = 1.13008169, grad/param norm = 1.5098e-01, time/batch = 0.6800s	
4207/28500 (epoch 7.381), train_loss = 1.32326324, grad/param norm = 1.6054e-01, time/batch = 0.6795s	
4208/28500 (epoch 7.382), train_loss = 1.31588706, grad/param norm = 1.6921e-01, time/batch = 0.6814s	
4209/28500 (epoch 7.384), train_loss = 1.23739787, grad/param norm = 1.5640e-01, time/batch = 0.6800s	
4210/28500 (epoch 7.386), train_loss = 1.25386705, grad/param norm = 1.7961e-01, time/batch = 0.6867s	
4211/28500 (epoch 7.388), train_loss = 1.49857086, grad/param norm = 1.7312e-01, time/batch = 0.6830s	
4212/28500 (epoch 7.389), train_loss = 1.30000298, grad/param norm = 1.6752e-01, time/batch = 0.6815s	
4213/28500 (epoch 7.391), train_loss = 1.31173707, grad/param norm = 1.7011e-01, time/batch = 0.6792s	
4214/28500 (epoch 7.393), train_loss = 1.20933129, grad/param norm = 1.5879e-01, time/batch = 0.6955s	
4215/28500 (epoch 7.395), train_loss = 1.59803632, grad/param norm = 1.9590e-01, time/batch = 0.6943s	
4216/28500 (epoch 7.396), train_loss = 1.46604655, grad/param norm = 1.7780e-01, time/batch = 0.6889s	
4217/28500 (epoch 7.398), train_loss = 1.23263223, grad/param norm = 2.1285e-01, time/batch = 0.6831s	
4218/28500 (epoch 7.400), train_loss = 1.45010593, grad/param norm = 2.1740e-01, time/batch = 0.6822s	
4219/28500 (epoch 7.402), train_loss = 1.36164106, grad/param norm = 1.6945e-01, time/batch = 0.6800s	
4220/28500 (epoch 7.404), train_loss = 1.49267486, grad/param norm = 2.0325e-01, time/batch = 0.6824s	
4221/28500 (epoch 7.405), train_loss = 1.46816069, grad/param norm = 1.6923e-01, time/batch = 0.6846s	
4222/28500 (epoch 7.407), train_loss = 1.41687241, grad/param norm = 1.6636e-01, time/batch = 0.6843s	
4223/28500 (epoch 7.409), train_loss = 1.42535611, grad/param norm = 1.7866e-01, time/batch = 0.6806s	
4224/28500 (epoch 7.411), train_loss = 1.46864864, grad/param norm = 1.5723e-01, time/batch = 0.6813s	
4225/28500 (epoch 7.412), train_loss = 1.60012669, grad/param norm = 1.9389e-01, time/batch = 0.6801s	
4226/28500 (epoch 7.414), train_loss = 1.42874331, grad/param norm = 1.9419e-01, time/batch = 0.6813s	
4227/28500 (epoch 7.416), train_loss = 1.33445374, grad/param norm = 1.8633e-01, time/batch = 0.6797s	
4228/28500 (epoch 7.418), train_loss = 1.42343221, grad/param norm = 1.6525e-01, time/batch = 0.6823s	
4229/28500 (epoch 7.419), train_loss = 1.53078804, grad/param norm = 1.9222e-01, time/batch = 0.6797s	
4230/28500 (epoch 7.421), train_loss = 1.47222194, grad/param norm = 1.7278e-01, time/batch = 0.6794s	
4231/28500 (epoch 7.423), train_loss = 1.58122111, grad/param norm = 1.9358e-01, time/batch = 0.6836s	
4232/28500 (epoch 7.425), train_loss = 1.43986160, grad/param norm = 1.9653e-01, time/batch = 0.6805s	
4233/28500 (epoch 7.426), train_loss = 1.41254906, grad/param norm = 1.7319e-01, time/batch = 0.6766s	
4234/28500 (epoch 7.428), train_loss = 1.63037430, grad/param norm = 1.8350e-01, time/batch = 0.6772s	
4235/28500 (epoch 7.430), train_loss = 1.49014068, grad/param norm = 1.6695e-01, time/batch = 0.6779s	
4236/28500 (epoch 7.432), train_loss = 1.46995861, grad/param norm = 1.8933e-01, time/batch = 0.6764s	
4237/28500 (epoch 7.433), train_loss = 1.51496756, grad/param norm = 1.9446e-01, time/batch = 0.6761s	
4238/28500 (epoch 7.435), train_loss = 1.38279115, grad/param norm = 1.7329e-01, time/batch = 0.6785s	
4239/28500 (epoch 7.437), train_loss = 1.22481215, grad/param norm = 1.4732e-01, time/batch = 0.6797s	
4240/28500 (epoch 7.439), train_loss = 1.27894263, grad/param norm = 1.5366e-01, time/batch = 0.6802s	
4241/28500 (epoch 7.440), train_loss = 1.50628946, grad/param norm = 1.7421e-01, time/batch = 0.6827s	
4242/28500 (epoch 7.442), train_loss = 1.28524428, grad/param norm = 1.7729e-01, time/batch = 0.6822s	
4243/28500 (epoch 7.444), train_loss = 1.24904286, grad/param norm = 1.5498e-01, time/batch = 0.6806s	
4244/28500 (epoch 7.446), train_loss = 1.18154583, grad/param norm = 1.6218e-01, time/batch = 0.6826s	
4245/28500 (epoch 7.447), train_loss = 1.26699394, grad/param norm = 1.5735e-01, time/batch = 0.6811s	
4246/28500 (epoch 7.449), train_loss = 1.26996087, grad/param norm = 1.6044e-01, time/batch = 0.6868s	
4247/28500 (epoch 7.451), train_loss = 1.36409941, grad/param norm = 1.7176e-01, time/batch = 0.6834s	
4248/28500 (epoch 7.453), train_loss = 1.39649520, grad/param norm = 1.9677e-01, time/batch = 0.6794s	
4249/28500 (epoch 7.454), train_loss = 1.31470284, grad/param norm = 1.7609e-01, time/batch = 0.6790s	
4250/28500 (epoch 7.456), train_loss = 1.44398640, grad/param norm = 1.7930e-01, time/batch = 0.6815s	
4251/28500 (epoch 7.458), train_loss = 1.32304225, grad/param norm = 1.7238e-01, time/batch = 0.6838s	
4252/28500 (epoch 7.460), train_loss = 1.47597149, grad/param norm = 1.7388e-01, time/batch = 0.6812s	
4253/28500 (epoch 7.461), train_loss = 1.33790716, grad/param norm = 1.7226e-01, time/batch = 0.6810s	
4254/28500 (epoch 7.463), train_loss = 1.25162300, grad/param norm = 1.5518e-01, time/batch = 0.6814s	
4255/28500 (epoch 7.465), train_loss = 1.20479859, grad/param norm = 1.6745e-01, time/batch = 0.6815s	
4256/28500 (epoch 7.467), train_loss = 1.43932998, grad/param norm = 1.7342e-01, time/batch = 0.6809s	
4257/28500 (epoch 7.468), train_loss = 1.19237671, grad/param norm = 1.4612e-01, time/batch = 0.6807s	
4258/28500 (epoch 7.470), train_loss = 1.37848842, grad/param norm = 1.8974e-01, time/batch = 0.6857s	
4259/28500 (epoch 7.472), train_loss = 1.28865985, grad/param norm = 1.5715e-01, time/batch = 0.6825s	
4260/28500 (epoch 7.474), train_loss = 1.66194417, grad/param norm = 2.0186e-01, time/batch = 0.6791s	
4261/28500 (epoch 7.475), train_loss = 1.30056148, grad/param norm = 1.5860e-01, time/batch = 0.6830s	
4262/28500 (epoch 7.477), train_loss = 1.35692003, grad/param norm = 1.7319e-01, time/batch = 0.6800s	
4263/28500 (epoch 7.479), train_loss = 1.38717416, grad/param norm = 1.6670e-01, time/batch = 0.6795s	
4264/28500 (epoch 7.481), train_loss = 1.34963459, grad/param norm = 1.7249e-01, time/batch = 0.6794s	
4265/28500 (epoch 7.482), train_loss = 1.27034729, grad/param norm = 1.7441e-01, time/batch = 0.6793s	
4266/28500 (epoch 7.484), train_loss = 1.28249429, grad/param norm = 1.7788e-01, time/batch = 0.6780s	
4267/28500 (epoch 7.486), train_loss = 1.23408834, grad/param norm = 1.7317e-01, time/batch = 0.6805s	
4268/28500 (epoch 7.488), train_loss = 1.37058226, grad/param norm = 1.7898e-01, time/batch = 0.6810s	
4269/28500 (epoch 7.489), train_loss = 1.46661629, grad/param norm = 1.8082e-01, time/batch = 0.6817s	
4270/28500 (epoch 7.491), train_loss = 1.31104965, grad/param norm = 1.6837e-01, time/batch = 0.6808s	
4271/28500 (epoch 7.493), train_loss = 1.27447392, grad/param norm = 1.5917e-01, time/batch = 0.6841s	
4272/28500 (epoch 7.495), train_loss = 1.29973455, grad/param norm = 1.6613e-01, time/batch = 0.6801s	
4273/28500 (epoch 7.496), train_loss = 1.38365579, grad/param norm = 1.7069e-01, time/batch = 0.6814s	
4274/28500 (epoch 7.498), train_loss = 1.43146941, grad/param norm = 1.7374e-01, time/batch = 0.6818s	
4275/28500 (epoch 7.500), train_loss = 1.37689656, grad/param norm = 1.7130e-01, time/batch = 0.6858s	
4276/28500 (epoch 7.502), train_loss = 1.44764290, grad/param norm = 1.6761e-01, time/batch = 0.7065s	
4277/28500 (epoch 7.504), train_loss = 1.43908829, grad/param norm = 1.6318e-01, time/batch = 0.6855s	
4278/28500 (epoch 7.505), train_loss = 1.27889677, grad/param norm = 1.5827e-01, time/batch = 0.6823s	
4279/28500 (epoch 7.507), train_loss = 1.52400266, grad/param norm = 1.9842e-01, time/batch = 0.6869s	
4280/28500 (epoch 7.509), train_loss = 1.39472501, grad/param norm = 1.8662e-01, time/batch = 0.6833s	
4281/28500 (epoch 7.511), train_loss = 1.38282260, grad/param norm = 1.7101e-01, time/batch = 0.6856s	
4282/28500 (epoch 7.512), train_loss = 1.38235399, grad/param norm = 1.7012e-01, time/batch = 0.6982s	
4283/28500 (epoch 7.514), train_loss = 1.23911592, grad/param norm = 1.6221e-01, time/batch = 0.6965s	
4284/28500 (epoch 7.516), train_loss = 1.27616113, grad/param norm = 1.5346e-01, time/batch = 0.6986s	
4285/28500 (epoch 7.518), train_loss = 1.32691676, grad/param norm = 1.4646e-01, time/batch = 0.6978s	
4286/28500 (epoch 7.519), train_loss = 1.41258757, grad/param norm = 1.6520e-01, time/batch = 0.6986s	
4287/28500 (epoch 7.521), train_loss = 1.55299817, grad/param norm = 1.8435e-01, time/batch = 0.6976s	
4288/28500 (epoch 7.523), train_loss = 1.45780075, grad/param norm = 1.8798e-01, time/batch = 0.6988s	
4289/28500 (epoch 7.525), train_loss = 1.50108075, grad/param norm = 1.8042e-01, time/batch = 0.6999s	
4290/28500 (epoch 7.526), train_loss = 1.42403646, grad/param norm = 1.7301e-01, time/batch = 0.7189s	
4291/28500 (epoch 7.528), train_loss = 1.50544554, grad/param norm = 2.0358e-01, time/batch = 0.7020s	
4292/28500 (epoch 7.530), train_loss = 1.48887507, grad/param norm = 1.6272e-01, time/batch = 0.6960s	
4293/28500 (epoch 7.532), train_loss = 1.32947310, grad/param norm = 1.8109e-01, time/batch = 0.6939s	
4294/28500 (epoch 7.533), train_loss = 1.52033499, grad/param norm = 1.8477e-01, time/batch = 0.6936s	
4295/28500 (epoch 7.535), train_loss = 1.20722425, grad/param norm = 1.6175e-01, time/batch = 0.6943s	
4296/28500 (epoch 7.537), train_loss = 1.19320126, grad/param norm = 1.6516e-01, time/batch = 0.6932s	
4297/28500 (epoch 7.539), train_loss = 1.26561464, grad/param norm = 1.6189e-01, time/batch = 0.6933s	
4298/28500 (epoch 7.540), train_loss = 1.36778943, grad/param norm = 1.6263e-01, time/batch = 0.6925s	
4299/28500 (epoch 7.542), train_loss = 1.57407316, grad/param norm = 1.9450e-01, time/batch = 0.6928s	
4300/28500 (epoch 7.544), train_loss = 1.54331597, grad/param norm = 1.7515e-01, time/batch = 0.6930s	
4301/28500 (epoch 7.546), train_loss = 1.39789630, grad/param norm = 1.7530e-01, time/batch = 0.6975s	
4302/28500 (epoch 7.547), train_loss = 1.36853659, grad/param norm = 1.5775e-01, time/batch = 0.6981s	
4303/28500 (epoch 7.549), train_loss = 1.19483592, grad/param norm = 1.4562e-01, time/batch = 0.6990s	
4304/28500 (epoch 7.551), train_loss = 1.50058095, grad/param norm = 1.8432e-01, time/batch = 0.6994s	
4305/28500 (epoch 7.553), train_loss = 1.62631157, grad/param norm = 1.8940e-01, time/batch = 0.6855s	
4306/28500 (epoch 7.554), train_loss = 1.32084464, grad/param norm = 1.6393e-01, time/batch = 0.6809s	
4307/28500 (epoch 7.556), train_loss = 1.41451400, grad/param norm = 1.9216e-01, time/batch = 0.6807s	
4308/28500 (epoch 7.558), train_loss = 1.42473483, grad/param norm = 1.7355e-01, time/batch = 0.6819s	
4309/28500 (epoch 7.560), train_loss = 1.43154797, grad/param norm = 1.8302e-01, time/batch = 0.6997s	
4310/28500 (epoch 7.561), train_loss = 1.48060237, grad/param norm = 1.9004e-01, time/batch = 0.6867s	
4311/28500 (epoch 7.563), train_loss = 1.50429034, grad/param norm = 1.8398e-01, time/batch = 0.6863s	
4312/28500 (epoch 7.565), train_loss = 1.34811836, grad/param norm = 1.7116e-01, time/batch = 0.6849s	
4313/28500 (epoch 7.567), train_loss = 1.26086521, grad/param norm = 1.7807e-01, time/batch = 0.6841s	
4314/28500 (epoch 7.568), train_loss = 1.42678894, grad/param norm = 1.8011e-01, time/batch = 0.6834s	
4315/28500 (epoch 7.570), train_loss = 1.30794650, grad/param norm = 1.7657e-01, time/batch = 0.6794s	
4316/28500 (epoch 7.572), train_loss = 1.33604468, grad/param norm = 1.6947e-01, time/batch = 0.6918s	
4317/28500 (epoch 7.574), train_loss = 1.39541683, grad/param norm = 1.6889e-01, time/batch = 0.6800s	
4318/28500 (epoch 7.575), train_loss = 1.31541141, grad/param norm = 1.6878e-01, time/batch = 0.6817s	
4319/28500 (epoch 7.577), train_loss = 1.35979663, grad/param norm = 1.7078e-01, time/batch = 0.6814s	
4320/28500 (epoch 7.579), train_loss = 1.50927375, grad/param norm = 2.0026e-01, time/batch = 0.6830s	
4321/28500 (epoch 7.581), train_loss = 1.34364750, grad/param norm = 1.6851e-01, time/batch = 0.6860s	
4322/28500 (epoch 7.582), train_loss = 1.44533074, grad/param norm = 1.7461e-01, time/batch = 0.6843s	
4323/28500 (epoch 7.584), train_loss = 1.30932516, grad/param norm = 1.6440e-01, time/batch = 0.6867s	
4324/28500 (epoch 7.586), train_loss = 1.22706977, grad/param norm = 1.4854e-01, time/batch = 0.6878s	
4325/28500 (epoch 7.588), train_loss = 1.26606800, grad/param norm = 1.6170e-01, time/batch = 0.7012s	
4326/28500 (epoch 7.589), train_loss = 1.54304700, grad/param norm = 1.7709e-01, time/batch = 0.7020s	
4327/28500 (epoch 7.591), train_loss = 1.42593112, grad/param norm = 1.5909e-01, time/batch = 0.7038s	
4328/28500 (epoch 7.593), train_loss = 1.30915986, grad/param norm = 1.5916e-01, time/batch = 0.7104s	
4329/28500 (epoch 7.595), train_loss = 1.63626309, grad/param norm = 2.1388e-01, time/batch = 0.7330s	
4330/28500 (epoch 7.596), train_loss = 1.58836212, grad/param norm = 1.9670e-01, time/batch = 0.6823s	
4331/28500 (epoch 7.598), train_loss = 1.38187510, grad/param norm = 1.5727e-01, time/batch = 0.6835s	
4332/28500 (epoch 7.600), train_loss = 1.43216692, grad/param norm = 1.8615e-01, time/batch = 0.6940s	
4333/28500 (epoch 7.602), train_loss = 1.59567442, grad/param norm = 1.8795e-01, time/batch = 0.6917s	
4334/28500 (epoch 7.604), train_loss = 1.44226678, grad/param norm = 1.6615e-01, time/batch = 0.6885s	
4335/28500 (epoch 7.605), train_loss = 1.38779388, grad/param norm = 1.6556e-01, time/batch = 0.6817s	
4336/28500 (epoch 7.607), train_loss = 1.42708718, grad/param norm = 1.6072e-01, time/batch = 0.6792s	
4337/28500 (epoch 7.609), train_loss = 1.39084689, grad/param norm = 1.7899e-01, time/batch = 0.6785s	
4338/28500 (epoch 7.611), train_loss = 1.41864757, grad/param norm = 1.7485e-01, time/batch = 0.6802s	
4339/28500 (epoch 7.612), train_loss = 1.41888709, grad/param norm = 1.6182e-01, time/batch = 0.6819s	
4340/28500 (epoch 7.614), train_loss = 1.41224892, grad/param norm = 1.6865e-01, time/batch = 0.6800s	
4341/28500 (epoch 7.616), train_loss = 1.36086289, grad/param norm = 1.8286e-01, time/batch = 0.6843s	
4342/28500 (epoch 7.618), train_loss = 1.30803306, grad/param norm = 1.6818e-01, time/batch = 0.6775s	
4343/28500 (epoch 7.619), train_loss = 1.58736534, grad/param norm = 1.9012e-01, time/batch = 0.6760s	
4344/28500 (epoch 7.621), train_loss = 1.13678781, grad/param norm = 1.4767e-01, time/batch = 0.6811s	
4345/28500 (epoch 7.623), train_loss = 1.43580683, grad/param norm = 1.7303e-01, time/batch = 0.6800s	
4346/28500 (epoch 7.625), train_loss = 1.21549198, grad/param norm = 1.6613e-01, time/batch = 0.6809s	
4347/28500 (epoch 7.626), train_loss = 1.10440285, grad/param norm = 1.4852e-01, time/batch = 0.6812s	
4348/28500 (epoch 7.628), train_loss = 1.26074751, grad/param norm = 1.7154e-01, time/batch = 0.6787s	
4349/28500 (epoch 7.630), train_loss = 1.21154359, grad/param norm = 1.5958e-01, time/batch = 0.6780s	
4350/28500 (epoch 7.632), train_loss = 1.45009334, grad/param norm = 1.6838e-01, time/batch = 0.6756s	
4351/28500 (epoch 7.633), train_loss = 1.44435881, grad/param norm = 1.6545e-01, time/batch = 0.6793s	
4352/28500 (epoch 7.635), train_loss = 1.54934024, grad/param norm = 1.8012e-01, time/batch = 0.6904s	
4353/28500 (epoch 7.637), train_loss = 1.39249227, grad/param norm = 1.6656e-01, time/batch = 0.6820s	
4354/28500 (epoch 7.639), train_loss = 1.19543362, grad/param norm = 1.5549e-01, time/batch = 0.6785s	
4355/28500 (epoch 7.640), train_loss = 1.26683789, grad/param norm = 1.6658e-01, time/batch = 0.6767s	
4356/28500 (epoch 7.642), train_loss = 1.42727095, grad/param norm = 1.6534e-01, time/batch = 0.6754s	
4357/28500 (epoch 7.644), train_loss = 1.45246398, grad/param norm = 1.6658e-01, time/batch = 0.6762s	
4358/28500 (epoch 7.646), train_loss = 1.26115712, grad/param norm = 1.5273e-01, time/batch = 0.6754s	
4359/28500 (epoch 7.647), train_loss = 1.26038831, grad/param norm = 1.6579e-01, time/batch = 0.6755s	
4360/28500 (epoch 7.649), train_loss = 1.26677883, grad/param norm = 1.6606e-01, time/batch = 0.6768s	
4361/28500 (epoch 7.651), train_loss = 1.23048810, grad/param norm = 1.5701e-01, time/batch = 0.6789s	
4362/28500 (epoch 7.653), train_loss = 1.25263336, grad/param norm = 1.6782e-01, time/batch = 0.6783s	
4363/28500 (epoch 7.654), train_loss = 1.30801321, grad/param norm = 1.6310e-01, time/batch = 0.6830s	
4364/28500 (epoch 7.656), train_loss = 1.33526985, grad/param norm = 1.7606e-01, time/batch = 0.6763s	
4365/28500 (epoch 7.658), train_loss = 1.40673060, grad/param norm = 1.8064e-01, time/batch = 0.6759s	
4366/28500 (epoch 7.660), train_loss = 1.33631757, grad/param norm = 1.5067e-01, time/batch = 0.6812s	
4367/28500 (epoch 7.661), train_loss = 1.50137994, grad/param norm = 1.8412e-01, time/batch = 0.6937s	
4368/28500 (epoch 7.663), train_loss = 1.57518803, grad/param norm = 1.9090e-01, time/batch = 0.6806s	
4369/28500 (epoch 7.665), train_loss = 1.33919454, grad/param norm = 1.7300e-01, time/batch = 0.6763s	
4370/28500 (epoch 7.667), train_loss = 1.41964425, grad/param norm = 1.6963e-01, time/batch = 0.6771s	
4371/28500 (epoch 7.668), train_loss = 1.35511546, grad/param norm = 1.6783e-01, time/batch = 0.6796s	
4372/28500 (epoch 7.670), train_loss = 1.34971542, grad/param norm = 1.6835e-01, time/batch = 0.6841s	
4373/28500 (epoch 7.672), train_loss = 1.33639175, grad/param norm = 1.6203e-01, time/batch = 0.6780s	
4374/28500 (epoch 7.674), train_loss = 1.21110505, grad/param norm = 1.7783e-01, time/batch = 0.6836s	
4375/28500 (epoch 7.675), train_loss = 1.21844955, grad/param norm = 1.6251e-01, time/batch = 0.6911s	
4376/28500 (epoch 7.677), train_loss = 1.33039826, grad/param norm = 1.7598e-01, time/batch = 0.6850s	
4377/28500 (epoch 7.679), train_loss = 1.34893916, grad/param norm = 1.7252e-01, time/batch = 0.6767s	
4378/28500 (epoch 7.681), train_loss = 1.47408903, grad/param norm = 1.7275e-01, time/batch = 0.6781s	
4379/28500 (epoch 7.682), train_loss = 1.30499165, grad/param norm = 1.8327e-01, time/batch = 0.6780s	
4380/28500 (epoch 7.684), train_loss = 1.42407794, grad/param norm = 1.7058e-01, time/batch = 0.6757s	
4381/28500 (epoch 7.686), train_loss = 1.29114068, grad/param norm = 1.6774e-01, time/batch = 0.6812s	
4382/28500 (epoch 7.688), train_loss = 1.28392762, grad/param norm = 1.4999e-01, time/batch = 0.6821s	
4383/28500 (epoch 7.689), train_loss = 1.39143884, grad/param norm = 1.7440e-01, time/batch = 0.6771s	
4384/28500 (epoch 7.691), train_loss = 1.39411181, grad/param norm = 1.8851e-01, time/batch = 0.6761s	
4385/28500 (epoch 7.693), train_loss = 1.34348322, grad/param norm = 1.7230e-01, time/batch = 0.6760s	
4386/28500 (epoch 7.695), train_loss = 1.26608750, grad/param norm = 1.9289e-01, time/batch = 0.6794s	
4387/28500 (epoch 7.696), train_loss = 1.36356539, grad/param norm = 1.8619e-01, time/batch = 0.6790s	
4388/28500 (epoch 7.698), train_loss = 1.35775015, grad/param norm = 1.5739e-01, time/batch = 0.6774s	
4389/28500 (epoch 7.700), train_loss = 1.36556625, grad/param norm = 1.6704e-01, time/batch = 0.6777s	
4390/28500 (epoch 7.702), train_loss = 1.52337948, grad/param norm = 1.7854e-01, time/batch = 0.6802s	
4391/28500 (epoch 7.704), train_loss = 1.41359625, grad/param norm = 1.7568e-01, time/batch = 0.6778s	
4392/28500 (epoch 7.705), train_loss = 1.46045625, grad/param norm = 1.7645e-01, time/batch = 0.6763s	
4393/28500 (epoch 7.707), train_loss = 1.36453963, grad/param norm = 1.8063e-01, time/batch = 0.6801s	
4394/28500 (epoch 7.709), train_loss = 1.45275337, grad/param norm = 1.8504e-01, time/batch = 0.6795s	
4395/28500 (epoch 7.711), train_loss = 1.32487188, grad/param norm = 2.0715e-01, time/batch = 0.6781s	
4396/28500 (epoch 7.712), train_loss = 1.46800536, grad/param norm = 1.8898e-01, time/batch = 0.6806s	
4397/28500 (epoch 7.714), train_loss = 1.42664742, grad/param norm = 1.7499e-01, time/batch = 0.6780s	
4398/28500 (epoch 7.716), train_loss = 1.32347067, grad/param norm = 1.7067e-01, time/batch = 0.6759s	
4399/28500 (epoch 7.718), train_loss = 1.27592837, grad/param norm = 1.6488e-01, time/batch = 0.6755s	
4400/28500 (epoch 7.719), train_loss = 1.29440911, grad/param norm = 1.5957e-01, time/batch = 0.6758s	
4401/28500 (epoch 7.721), train_loss = 1.12955688, grad/param norm = 1.6103e-01, time/batch = 0.6878s	
4402/28500 (epoch 7.723), train_loss = 1.35536147, grad/param norm = 1.6798e-01, time/batch = 0.6759s	
4403/28500 (epoch 7.725), train_loss = 1.45768635, grad/param norm = 1.6235e-01, time/batch = 0.6758s	
4404/28500 (epoch 7.726), train_loss = 1.36843318, grad/param norm = 1.7034e-01, time/batch = 0.6762s	
4405/28500 (epoch 7.728), train_loss = 1.20215378, grad/param norm = 1.5537e-01, time/batch = 0.6757s	
4406/28500 (epoch 7.730), train_loss = 1.38249394, grad/param norm = 1.7603e-01, time/batch = 0.6762s	
4407/28500 (epoch 7.732), train_loss = 1.18459599, grad/param norm = 1.6740e-01, time/batch = 0.6770s	
4408/28500 (epoch 7.733), train_loss = 1.16364865, grad/param norm = 1.5358e-01, time/batch = 0.6773s	
4409/28500 (epoch 7.735), train_loss = 1.16593677, grad/param norm = 1.5018e-01, time/batch = 0.6758s	
4410/28500 (epoch 7.737), train_loss = 1.15179147, grad/param norm = 1.5247e-01, time/batch = 0.6767s	
4411/28500 (epoch 7.739), train_loss = 1.32510515, grad/param norm = 1.7161e-01, time/batch = 0.6797s	
4412/28500 (epoch 7.740), train_loss = 1.35781926, grad/param norm = 1.7311e-01, time/batch = 0.6805s	
4413/28500 (epoch 7.742), train_loss = 1.28344486, grad/param norm = 1.6659e-01, time/batch = 0.6777s	
4414/28500 (epoch 7.744), train_loss = 1.40246206, grad/param norm = 1.7224e-01, time/batch = 0.6783s	
4415/28500 (epoch 7.746), train_loss = 1.22236373, grad/param norm = 1.4734e-01, time/batch = 0.6784s	
4416/28500 (epoch 7.747), train_loss = 1.24495775, grad/param norm = 1.7338e-01, time/batch = 0.6798s	
4417/28500 (epoch 7.749), train_loss = 1.56352926, grad/param norm = 1.9120e-01, time/batch = 0.6799s	
4418/28500 (epoch 7.751), train_loss = 1.26220087, grad/param norm = 1.6965e-01, time/batch = 0.6780s	
4419/28500 (epoch 7.753), train_loss = 1.23627267, grad/param norm = 1.5523e-01, time/batch = 0.6766s	
4420/28500 (epoch 7.754), train_loss = 1.16273960, grad/param norm = 1.5622e-01, time/batch = 0.6776s	
4421/28500 (epoch 7.756), train_loss = 1.45454941, grad/param norm = 1.7183e-01, time/batch = 0.6778s	
4422/28500 (epoch 7.758), train_loss = 1.39290120, grad/param norm = 1.7014e-01, time/batch = 0.6780s	
4423/28500 (epoch 7.760), train_loss = 1.21588022, grad/param norm = 1.7813e-01, time/batch = 0.6779s	
4424/28500 (epoch 7.761), train_loss = 1.24322545, grad/param norm = 1.7310e-01, time/batch = 0.6803s	
4425/28500 (epoch 7.763), train_loss = 1.09920684, grad/param norm = 1.6215e-01, time/batch = 0.6767s	
4426/28500 (epoch 7.765), train_loss = 1.26968987, grad/param norm = 1.5348e-01, time/batch = 0.6756s	
4427/28500 (epoch 7.767), train_loss = 1.11808837, grad/param norm = 1.4703e-01, time/batch = 0.6759s	
4428/28500 (epoch 7.768), train_loss = 1.46844969, grad/param norm = 1.8462e-01, time/batch = 0.6757s	
4429/28500 (epoch 7.770), train_loss = 1.16969261, grad/param norm = 1.7395e-01, time/batch = 0.6757s	
4430/28500 (epoch 7.772), train_loss = 1.08458840, grad/param norm = 1.6561e-01, time/batch = 0.6761s	
4431/28500 (epoch 7.774), train_loss = 1.39149805, grad/param norm = 1.7625e-01, time/batch = 0.6769s	
4432/28500 (epoch 7.775), train_loss = 1.41563431, grad/param norm = 1.6173e-01, time/batch = 0.6755s	
4433/28500 (epoch 7.777), train_loss = 1.36000979, grad/param norm = 1.6403e-01, time/batch = 0.6760s	
4434/28500 (epoch 7.779), train_loss = 1.18326286, grad/param norm = 1.5986e-01, time/batch = 0.6770s	
4435/28500 (epoch 7.781), train_loss = 1.42258232, grad/param norm = 1.8534e-01, time/batch = 0.6771s	
4436/28500 (epoch 7.782), train_loss = 1.46085802, grad/param norm = 1.8226e-01, time/batch = 0.6756s	
4437/28500 (epoch 7.784), train_loss = 1.13186800, grad/param norm = 1.5275e-01, time/batch = 0.6756s	
4438/28500 (epoch 7.786), train_loss = 1.28620492, grad/param norm = 1.5601e-01, time/batch = 0.6758s	
4439/28500 (epoch 7.788), train_loss = 1.42490973, grad/param norm = 1.9387e-01, time/batch = 0.6756s	
4440/28500 (epoch 7.789), train_loss = 1.09514963, grad/param norm = 1.6447e-01, time/batch = 0.6761s	
4441/28500 (epoch 7.791), train_loss = 1.32258604, grad/param norm = 1.7748e-01, time/batch = 0.6780s	
4442/28500 (epoch 7.793), train_loss = 1.23665097, grad/param norm = 1.7673e-01, time/batch = 0.6781s	
4443/28500 (epoch 7.795), train_loss = 1.33511035, grad/param norm = 1.5774e-01, time/batch = 0.6783s	
4444/28500 (epoch 7.796), train_loss = 1.23749446, grad/param norm = 1.6048e-01, time/batch = 0.6768s	
4445/28500 (epoch 7.798), train_loss = 1.19834708, grad/param norm = 1.5750e-01, time/batch = 0.6765s	
4446/28500 (epoch 7.800), train_loss = 1.22625902, grad/param norm = 1.6283e-01, time/batch = 0.6774s	
4447/28500 (epoch 7.802), train_loss = 1.36387784, grad/param norm = 1.9221e-01, time/batch = 0.6755s	
4448/28500 (epoch 7.804), train_loss = 1.33146740, grad/param norm = 1.6467e-01, time/batch = 0.6759s	
4449/28500 (epoch 7.805), train_loss = 1.35004446, grad/param norm = 1.7931e-01, time/batch = 0.6782s	
4450/28500 (epoch 7.807), train_loss = 1.44417402, grad/param norm = 1.8700e-01, time/batch = 0.6838s	
4451/28500 (epoch 7.809), train_loss = 1.29290675, grad/param norm = 1.5954e-01, time/batch = 0.6864s	
4452/28500 (epoch 7.811), train_loss = 1.42469733, grad/param norm = 1.8166e-01, time/batch = 0.6837s	
4453/28500 (epoch 7.812), train_loss = 1.40215672, grad/param norm = 1.7873e-01, time/batch = 0.6863s	
4454/28500 (epoch 7.814), train_loss = 1.31463729, grad/param norm = 1.7815e-01, time/batch = 0.6791s	
4455/28500 (epoch 7.816), train_loss = 1.50649163, grad/param norm = 1.7450e-01, time/batch = 0.6809s	
4456/28500 (epoch 7.818), train_loss = 1.39609888, grad/param norm = 1.6870e-01, time/batch = 0.6797s	
4457/28500 (epoch 7.819), train_loss = 1.33296625, grad/param norm = 1.7030e-01, time/batch = 0.6859s	
4458/28500 (epoch 7.821), train_loss = 1.25350097, grad/param norm = 1.5707e-01, time/batch = 0.6839s	
4459/28500 (epoch 7.823), train_loss = 1.57255192, grad/param norm = 1.8729e-01, time/batch = 0.6824s	
4460/28500 (epoch 7.825), train_loss = 1.31569604, grad/param norm = 1.8182e-01, time/batch = 0.6812s	
4461/28500 (epoch 7.826), train_loss = 1.40459284, grad/param norm = 2.0349e-01, time/batch = 0.6833s	
4462/28500 (epoch 7.828), train_loss = 1.21308405, grad/param norm = 1.7741e-01, time/batch = 0.6794s	
4463/28500 (epoch 7.830), train_loss = 1.27017242, grad/param norm = 1.5275e-01, time/batch = 0.6801s	
4464/28500 (epoch 7.832), train_loss = 1.33376835, grad/param norm = 1.7117e-01, time/batch = 0.6788s	
4465/28500 (epoch 7.833), train_loss = 1.50845918, grad/param norm = 1.6693e-01, time/batch = 0.6820s	
4466/28500 (epoch 7.835), train_loss = 1.27420088, grad/param norm = 1.7415e-01, time/batch = 0.6784s	
4467/28500 (epoch 7.837), train_loss = 1.18399564, grad/param norm = 1.6044e-01, time/batch = 0.6827s	
4468/28500 (epoch 7.839), train_loss = 1.46631459, grad/param norm = 1.8486e-01, time/batch = 0.6793s	
4469/28500 (epoch 7.840), train_loss = 1.47866256, grad/param norm = 1.8813e-01, time/batch = 0.6816s	
4470/28500 (epoch 7.842), train_loss = 1.40470484, grad/param norm = 1.6873e-01, time/batch = 0.6856s	
4471/28500 (epoch 7.844), train_loss = 1.35701333, grad/param norm = 1.6522e-01, time/batch = 0.6831s	
4472/28500 (epoch 7.846), train_loss = 1.49506078, grad/param norm = 1.7357e-01, time/batch = 0.6816s	
4473/28500 (epoch 7.847), train_loss = 1.30462954, grad/param norm = 1.6025e-01, time/batch = 0.6850s	
4474/28500 (epoch 7.849), train_loss = 1.27197495, grad/param norm = 1.5486e-01, time/batch = 0.6895s	
4475/28500 (epoch 7.851), train_loss = 1.15482760, grad/param norm = 1.5951e-01, time/batch = 0.6834s	
4476/28500 (epoch 7.853), train_loss = 1.35939326, grad/param norm = 1.7983e-01, time/batch = 0.6829s	
4477/28500 (epoch 7.854), train_loss = 1.34673636, grad/param norm = 1.7063e-01, time/batch = 0.6881s	
4478/28500 (epoch 7.856), train_loss = 1.43137245, grad/param norm = 1.7543e-01, time/batch = 0.6828s	
4479/28500 (epoch 7.858), train_loss = 1.16889896, grad/param norm = 1.4492e-01, time/batch = 0.6889s	
4480/28500 (epoch 7.860), train_loss = 1.42067041, grad/param norm = 1.8350e-01, time/batch = 0.6820s	
4481/28500 (epoch 7.861), train_loss = 1.34062647, grad/param norm = 1.8305e-01, time/batch = 0.6917s	
4482/28500 (epoch 7.863), train_loss = 1.47547492, grad/param norm = 1.7069e-01, time/batch = 0.6826s	
4483/28500 (epoch 7.865), train_loss = 1.32600966, grad/param norm = 1.6915e-01, time/batch = 0.6814s	
4484/28500 (epoch 7.867), train_loss = 1.40684628, grad/param norm = 1.8627e-01, time/batch = 0.6792s	
4485/28500 (epoch 7.868), train_loss = 1.20842480, grad/param norm = 1.5923e-01, time/batch = 0.6798s	
4486/28500 (epoch 7.870), train_loss = 1.11544267, grad/param norm = 1.4911e-01, time/batch = 0.6797s	
4487/28500 (epoch 7.872), train_loss = 1.40658843, grad/param norm = 1.8261e-01, time/batch = 0.6816s	
4488/28500 (epoch 7.874), train_loss = 1.34843606, grad/param norm = 1.7625e-01, time/batch = 0.6801s	
4489/28500 (epoch 7.875), train_loss = 1.44475379, grad/param norm = 1.7531e-01, time/batch = 0.6797s	
4490/28500 (epoch 7.877), train_loss = 1.34164707, grad/param norm = 1.8435e-01, time/batch = 0.6795s	
4491/28500 (epoch 7.879), train_loss = 1.32689090, grad/param norm = 1.7438e-01, time/batch = 0.6816s	
4492/28500 (epoch 7.881), train_loss = 1.40036107, grad/param norm = 1.6346e-01, time/batch = 0.6815s	
4493/28500 (epoch 7.882), train_loss = 1.30355348, grad/param norm = 1.6214e-01, time/batch = 0.6822s	
4494/28500 (epoch 7.884), train_loss = 1.37831108, grad/param norm = 1.7821e-01, time/batch = 0.6831s	
4495/28500 (epoch 7.886), train_loss = 1.23006294, grad/param norm = 1.5125e-01, time/batch = 0.6821s	
4496/28500 (epoch 7.888), train_loss = 1.20542858, grad/param norm = 1.6106e-01, time/batch = 0.6805s	
4497/28500 (epoch 7.889), train_loss = 1.28743598, grad/param norm = 1.5370e-01, time/batch = 0.6789s	
4498/28500 (epoch 7.891), train_loss = 1.35520446, grad/param norm = 1.6194e-01, time/batch = 0.6797s	
4499/28500 (epoch 7.893), train_loss = 1.29176063, grad/param norm = 1.8525e-01, time/batch = 0.6782s	
4500/28500 (epoch 7.895), train_loss = 1.54647062, grad/param norm = 1.9324e-01, time/batch = 0.6796s	
4501/28500 (epoch 7.896), train_loss = 1.42803802, grad/param norm = 1.8053e-01, time/batch = 0.6817s	
4502/28500 (epoch 7.898), train_loss = 1.31227108, grad/param norm = 1.7125e-01, time/batch = 0.6800s	
4503/28500 (epoch 7.900), train_loss = 1.20976808, grad/param norm = 1.6424e-01, time/batch = 0.6792s	
4504/28500 (epoch 7.902), train_loss = 1.21448806, grad/param norm = 1.5276e-01, time/batch = 0.6795s	
4505/28500 (epoch 7.904), train_loss = 1.20992870, grad/param norm = 1.5845e-01, time/batch = 0.6780s	
4506/28500 (epoch 7.905), train_loss = 1.37151695, grad/param norm = 1.7663e-01, time/batch = 0.6791s	
4507/28500 (epoch 7.907), train_loss = 1.42862188, grad/param norm = 1.8043e-01, time/batch = 0.6818s	
4508/28500 (epoch 7.909), train_loss = 1.22935262, grad/param norm = 1.8850e-01, time/batch = 0.6799s	
4509/28500 (epoch 7.911), train_loss = 1.24492965, grad/param norm = 1.6270e-01, time/batch = 0.6824s	
4510/28500 (epoch 7.912), train_loss = 1.04789673, grad/param norm = 1.5857e-01, time/batch = 0.6797s	
4511/28500 (epoch 7.914), train_loss = 1.45655681, grad/param norm = 1.6876e-01, time/batch = 0.6814s	
4512/28500 (epoch 7.916), train_loss = 1.40230809, grad/param norm = 1.7893e-01, time/batch = 0.6813s	
4513/28500 (epoch 7.918), train_loss = 1.32959818, grad/param norm = 1.8516e-01, time/batch = 0.6805s	
4514/28500 (epoch 7.919), train_loss = 1.27606611, grad/param norm = 1.5650e-01, time/batch = 0.6814s	
4515/28500 (epoch 7.921), train_loss = 1.53517777, grad/param norm = 2.1434e-01, time/batch = 0.6792s	
4516/28500 (epoch 7.923), train_loss = 1.38485566, grad/param norm = 1.9257e-01, time/batch = 0.6811s	
4517/28500 (epoch 7.925), train_loss = 1.20530577, grad/param norm = 1.6308e-01, time/batch = 0.6802s	
4518/28500 (epoch 7.926), train_loss = 1.33962291, grad/param norm = 1.7570e-01, time/batch = 0.6803s	
4519/28500 (epoch 7.928), train_loss = 1.25076856, grad/param norm = 1.5496e-01, time/batch = 0.6786s	
4520/28500 (epoch 7.930), train_loss = 1.03574676, grad/param norm = 1.6490e-01, time/batch = 0.6795s	
4521/28500 (epoch 7.932), train_loss = 1.13353072, grad/param norm = 1.4496e-01, time/batch = 0.6834s	
4522/28500 (epoch 7.933), train_loss = 1.34788799, grad/param norm = 1.6328e-01, time/batch = 0.6884s	
4523/28500 (epoch 7.935), train_loss = 1.39555480, grad/param norm = 1.8640e-01, time/batch = 0.6854s	
4524/28500 (epoch 7.937), train_loss = 1.47168131, grad/param norm = 1.9080e-01, time/batch = 0.6797s	
4525/28500 (epoch 7.939), train_loss = 1.55176700, grad/param norm = 1.8290e-01, time/batch = 0.6804s	
4526/28500 (epoch 7.940), train_loss = 1.23750384, grad/param norm = 1.6533e-01, time/batch = 0.6796s	
4527/28500 (epoch 7.942), train_loss = 1.43540625, grad/param norm = 1.7011e-01, time/batch = 0.6796s	
4528/28500 (epoch 7.944), train_loss = 1.35421832, grad/param norm = 1.7047e-01, time/batch = 0.6808s	
4529/28500 (epoch 7.946), train_loss = 1.47703137, grad/param norm = 1.6575e-01, time/batch = 0.6810s	
4530/28500 (epoch 7.947), train_loss = 1.70949555, grad/param norm = 1.9423e-01, time/batch = 0.6819s	
4531/28500 (epoch 7.949), train_loss = 1.21397518, grad/param norm = 1.6687e-01, time/batch = 0.6822s	
4532/28500 (epoch 7.951), train_loss = 1.52405541, grad/param norm = 1.9998e-01, time/batch = 0.6798s	
4533/28500 (epoch 7.953), train_loss = 1.58032307, grad/param norm = 2.0461e-01, time/batch = 0.6802s	
4534/28500 (epoch 7.954), train_loss = 1.46548755, grad/param norm = 1.7984e-01, time/batch = 0.6786s	
4535/28500 (epoch 7.956), train_loss = 1.42888333, grad/param norm = 1.9988e-01, time/batch = 0.6798s	
4536/28500 (epoch 7.958), train_loss = 1.47743270, grad/param norm = 1.6836e-01, time/batch = 0.6796s	
4537/28500 (epoch 7.960), train_loss = 1.25448315, grad/param norm = 1.7278e-01, time/batch = 0.6852s	
4538/28500 (epoch 7.961), train_loss = 1.57803006, grad/param norm = 1.9168e-01, time/batch = 0.6907s	
4539/28500 (epoch 7.963), train_loss = 1.42502573, grad/param norm = 1.5338e-01, time/batch = 0.6876s	
4540/28500 (epoch 7.965), train_loss = 1.21421456, grad/param norm = 1.4845e-01, time/batch = 0.6797s	
4541/28500 (epoch 7.967), train_loss = 1.19021508, grad/param norm = 1.5984e-01, time/batch = 0.6829s	
4542/28500 (epoch 7.968), train_loss = 1.14668260, grad/param norm = 1.4701e-01, time/batch = 0.6801s	
4543/28500 (epoch 7.970), train_loss = 1.35595102, grad/param norm = 1.7040e-01, time/batch = 0.6787s	
4544/28500 (epoch 7.972), train_loss = 1.51013551, grad/param norm = 1.9152e-01, time/batch = 0.6794s	
4545/28500 (epoch 7.974), train_loss = 1.60645248, grad/param norm = 1.8369e-01, time/batch = 0.6800s	
4546/28500 (epoch 7.975), train_loss = 1.30703253, grad/param norm = 1.7783e-01, time/batch = 0.6799s	
4547/28500 (epoch 7.977), train_loss = 1.54233112, grad/param norm = 1.7543e-01, time/batch = 0.6818s	
4548/28500 (epoch 7.979), train_loss = 1.25855517, grad/param norm = 1.6258e-01, time/batch = 0.6817s	
4549/28500 (epoch 7.981), train_loss = 1.28941363, grad/param norm = 1.7334e-01, time/batch = 0.6808s	
4550/28500 (epoch 7.982), train_loss = 1.21789750, grad/param norm = 1.5016e-01, time/batch = 0.6808s	
4551/28500 (epoch 7.984), train_loss = 1.41355885, grad/param norm = 1.7161e-01, time/batch = 0.7050s	
4552/28500 (epoch 7.986), train_loss = 1.55301107, grad/param norm = 1.8466e-01, time/batch = 0.6842s	
4553/28500 (epoch 7.988), train_loss = 1.14972906, grad/param norm = 1.6329e-01, time/batch = 0.6804s	
4554/28500 (epoch 7.989), train_loss = 1.40499644, grad/param norm = 1.8526e-01, time/batch = 0.6815s	
4555/28500 (epoch 7.991), train_loss = 1.25119201, grad/param norm = 1.7089e-01, time/batch = 0.6797s	
4556/28500 (epoch 7.993), train_loss = 1.26830105, grad/param norm = 1.6725e-01, time/batch = 0.6807s	
4557/28500 (epoch 7.995), train_loss = 1.27575281, grad/param norm = 1.7089e-01, time/batch = 0.6817s	
4558/28500 (epoch 7.996), train_loss = 1.22161829, grad/param norm = 1.5560e-01, time/batch = 0.6824s	
4559/28500 (epoch 7.998), train_loss = 1.46352435, grad/param norm = 1.7799e-01, time/batch = 0.6797s	
4560/28500 (epoch 8.000), train_loss = 1.25095940, grad/param norm = 1.4846e-01, time/batch = 0.6800s	
4561/28500 (epoch 8.002), train_loss = 1.48147375, grad/param norm = 1.7812e-01, time/batch = 0.6826s	
4562/28500 (epoch 8.004), train_loss = 1.27760701, grad/param norm = 1.6692e-01, time/batch = 0.6803s	
4563/28500 (epoch 8.005), train_loss = 1.42032097, grad/param norm = 1.7596e-01, time/batch = 0.6818s	
4564/28500 (epoch 8.007), train_loss = 1.17211262, grad/param norm = 1.4626e-01, time/batch = 0.6808s	
4565/28500 (epoch 8.009), train_loss = 1.43977602, grad/param norm = 1.7328e-01, time/batch = 0.6844s	
4566/28500 (epoch 8.011), train_loss = 1.32766822, grad/param norm = 1.8584e-01, time/batch = 0.6786s	
4567/28500 (epoch 8.012), train_loss = 1.15059336, grad/param norm = 1.4275e-01, time/batch = 0.6783s	
4568/28500 (epoch 8.014), train_loss = 1.20655040, grad/param norm = 1.5224e-01, time/batch = 0.6765s	
4569/28500 (epoch 8.016), train_loss = 1.26844174, grad/param norm = 1.4735e-01, time/batch = 0.6768s	
4570/28500 (epoch 8.018), train_loss = 1.36375607, grad/param norm = 1.7207e-01, time/batch = 0.6931s	
4571/28500 (epoch 8.019), train_loss = 1.42912479, grad/param norm = 1.8969e-01, time/batch = 0.6848s	
4572/28500 (epoch 8.021), train_loss = 1.36021387, grad/param norm = 1.5880e-01, time/batch = 0.6762s	
4573/28500 (epoch 8.023), train_loss = 1.29942442, grad/param norm = 1.6314e-01, time/batch = 0.6788s	
4574/28500 (epoch 8.025), train_loss = 1.31478878, grad/param norm = 1.6881e-01, time/batch = 0.6790s	
4575/28500 (epoch 8.026), train_loss = 1.38385458, grad/param norm = 1.7589e-01, time/batch = 0.6758s	
4576/28500 (epoch 8.028), train_loss = 1.41228627, grad/param norm = 1.6609e-01, time/batch = 0.6805s	
4577/28500 (epoch 8.030), train_loss = 1.43876691, grad/param norm = 1.9350e-01, time/batch = 0.6776s	
4578/28500 (epoch 8.032), train_loss = 1.43685646, grad/param norm = 1.8121e-01, time/batch = 0.6757s	
4579/28500 (epoch 8.033), train_loss = 1.51886249, grad/param norm = 1.7229e-01, time/batch = 0.6754s	
4580/28500 (epoch 8.035), train_loss = 1.38777708, grad/param norm = 1.7729e-01, time/batch = 0.6759s	
4581/28500 (epoch 8.037), train_loss = 1.42586678, grad/param norm = 1.6509e-01, time/batch = 0.6810s	
4582/28500 (epoch 8.039), train_loss = 1.52071959, grad/param norm = 1.8468e-01, time/batch = 0.6822s	
4583/28500 (epoch 8.040), train_loss = 1.50503124, grad/param norm = 1.7643e-01, time/batch = 0.6768s	
4584/28500 (epoch 8.042), train_loss = 1.42700547, grad/param norm = 1.7573e-01, time/batch = 0.6757s	
4585/28500 (epoch 8.044), train_loss = 1.34877683, grad/param norm = 1.8754e-01, time/batch = 0.6767s	
4586/28500 (epoch 8.046), train_loss = 1.55343625, grad/param norm = 1.8335e-01, time/batch = 0.6759s	
4587/28500 (epoch 8.047), train_loss = 1.46749705, grad/param norm = 1.7948e-01, time/batch = 0.6754s	
4588/28500 (epoch 8.049), train_loss = 1.37141916, grad/param norm = 1.8133e-01, time/batch = 0.6786s	
4589/28500 (epoch 8.051), train_loss = 1.30843497, grad/param norm = 1.6280e-01, time/batch = 0.6790s	
4590/28500 (epoch 8.053), train_loss = 1.39920797, grad/param norm = 1.6294e-01, time/batch = 0.6792s	
4591/28500 (epoch 8.054), train_loss = 1.45660864, grad/param norm = 1.7329e-01, time/batch = 0.6794s	
4592/28500 (epoch 8.056), train_loss = 1.19497602, grad/param norm = 1.5918e-01, time/batch = 0.6776s	
4593/28500 (epoch 8.058), train_loss = 1.22589089, grad/param norm = 1.7423e-01, time/batch = 0.6823s	
4594/28500 (epoch 8.060), train_loss = 1.42099798, grad/param norm = 1.8286e-01, time/batch = 0.6803s	
4595/28500 (epoch 8.061), train_loss = 1.45349978, grad/param norm = 2.0443e-01, time/batch = 0.6975s	
4596/28500 (epoch 8.063), train_loss = 1.44051962, grad/param norm = 1.7197e-01, time/batch = 0.6840s	
4597/28500 (epoch 8.065), train_loss = 1.52761121, grad/param norm = 1.7338e-01, time/batch = 0.6802s	
4598/28500 (epoch 8.067), train_loss = 1.24668109, grad/param norm = 1.5381e-01, time/batch = 0.6793s	
4599/28500 (epoch 8.068), train_loss = 1.29068438, grad/param norm = 1.6313e-01, time/batch = 0.6793s	
4600/28500 (epoch 8.070), train_loss = 1.40291569, grad/param norm = 1.7803e-01, time/batch = 0.6759s	
4601/28500 (epoch 8.072), train_loss = 1.55150709, grad/param norm = 1.7773e-01, time/batch = 0.6804s	
4602/28500 (epoch 8.074), train_loss = 1.39234524, grad/param norm = 1.7889e-01, time/batch = 0.6839s	
4603/28500 (epoch 8.075), train_loss = 1.32369877, grad/param norm = 1.5149e-01, time/batch = 0.6782s	
4604/28500 (epoch 8.077), train_loss = 1.39210517, grad/param norm = 1.7333e-01, time/batch = 0.6798s	
4605/28500 (epoch 8.079), train_loss = 1.35630905, grad/param norm = 1.6007e-01, time/batch = 0.6816s	
4606/28500 (epoch 8.081), train_loss = 1.48145686, grad/param norm = 1.8394e-01, time/batch = 0.6826s	
4607/28500 (epoch 8.082), train_loss = 1.41593223, grad/param norm = 1.7928e-01, time/batch = 0.6818s	
4608/28500 (epoch 8.084), train_loss = 1.41651825, grad/param norm = 1.7504e-01, time/batch = 0.6813s	
4609/28500 (epoch 8.086), train_loss = 1.31288499, grad/param norm = 1.8351e-01, time/batch = 0.6800s	
4610/28500 (epoch 8.088), train_loss = 1.23678357, grad/param norm = 1.7741e-01, time/batch = 0.6809s	
4611/28500 (epoch 8.089), train_loss = 1.48787718, grad/param norm = 1.5008e-01, time/batch = 0.6851s	
4612/28500 (epoch 8.091), train_loss = 1.19236412, grad/param norm = 1.5564e-01, time/batch = 0.6781s	
4613/28500 (epoch 8.093), train_loss = 1.37702221, grad/param norm = 1.7240e-01, time/batch = 0.6787s	
4614/28500 (epoch 8.095), train_loss = 1.27454370, grad/param norm = 1.6376e-01, time/batch = 0.6819s	
4615/28500 (epoch 8.096), train_loss = 1.49845100, grad/param norm = 1.7648e-01, time/batch = 0.6780s	
4616/28500 (epoch 8.098), train_loss = 1.48999738, grad/param norm = 1.8076e-01, time/batch = 0.6803s	
4617/28500 (epoch 8.100), train_loss = 1.27306208, grad/param norm = 1.5914e-01, time/batch = 0.6795s	
4618/28500 (epoch 8.102), train_loss = 1.52893210, grad/param norm = 1.6850e-01, time/batch = 0.6802s	
4619/28500 (epoch 8.104), train_loss = 1.34148325, grad/param norm = 1.7148e-01, time/batch = 0.6800s	
4620/28500 (epoch 8.105), train_loss = 1.39408225, grad/param norm = 1.6517e-01, time/batch = 0.6840s	
4621/28500 (epoch 8.107), train_loss = 1.25641877, grad/param norm = 1.6768e-01, time/batch = 0.6846s	
4622/28500 (epoch 8.109), train_loss = 1.23232719, grad/param norm = 1.7591e-01, time/batch = 0.6783s	
4623/28500 (epoch 8.111), train_loss = 1.28975072, grad/param norm = 1.6466e-01, time/batch = 0.6830s	
4624/28500 (epoch 8.112), train_loss = 1.44001864, grad/param norm = 1.8501e-01, time/batch = 0.6836s	
4625/28500 (epoch 8.114), train_loss = 1.33977203, grad/param norm = 1.6891e-01, time/batch = 0.6866s	
4626/28500 (epoch 8.116), train_loss = 1.52568690, grad/param norm = 1.7880e-01, time/batch = 0.6977s	
4627/28500 (epoch 8.118), train_loss = 1.22757363, grad/param norm = 1.7895e-01, time/batch = 0.6988s	
4628/28500 (epoch 8.119), train_loss = 1.42638666, grad/param norm = 1.7767e-01, time/batch = 0.6850s	
4629/28500 (epoch 8.121), train_loss = 1.56530936, grad/param norm = 1.9831e-01, time/batch = 0.6929s	
4630/28500 (epoch 8.123), train_loss = 1.40784487, grad/param norm = 1.9189e-01, time/batch = 0.6898s	
4631/28500 (epoch 8.125), train_loss = 1.39863393, grad/param norm = 1.7717e-01, time/batch = 0.6836s	
4632/28500 (epoch 8.126), train_loss = 1.35428093, grad/param norm = 1.6712e-01, time/batch = 0.6852s	
4633/28500 (epoch 8.128), train_loss = 1.26033593, grad/param norm = 1.6336e-01, time/batch = 0.6845s	
4634/28500 (epoch 8.130), train_loss = 1.27404697, grad/param norm = 1.6702e-01, time/batch = 0.6958s	
4635/28500 (epoch 8.132), train_loss = 1.42155970, grad/param norm = 1.7555e-01, time/batch = 0.6909s	
4636/28500 (epoch 8.133), train_loss = 1.35272767, grad/param norm = 1.6743e-01, time/batch = 0.6861s	
4637/28500 (epoch 8.135), train_loss = 1.33967232, grad/param norm = 1.6133e-01, time/batch = 0.6842s	
4638/28500 (epoch 8.137), train_loss = 1.32253490, grad/param norm = 1.7337e-01, time/batch = 0.6825s	
4639/28500 (epoch 8.139), train_loss = 1.32750065, grad/param norm = 1.5537e-01, time/batch = 0.6841s	
4640/28500 (epoch 8.140), train_loss = 1.38991788, grad/param norm = 1.7134e-01, time/batch = 0.7018s	
4641/28500 (epoch 8.142), train_loss = 1.39139972, grad/param norm = 1.7413e-01, time/batch = 0.6845s	
4642/28500 (epoch 8.144), train_loss = 1.22614302, grad/param norm = 1.5316e-01, time/batch = 0.6797s	
4643/28500 (epoch 8.146), train_loss = 1.25448420, grad/param norm = 1.6312e-01, time/batch = 0.6793s	
4644/28500 (epoch 8.147), train_loss = 1.17210416, grad/param norm = 1.5729e-01, time/batch = 0.6783s	
4645/28500 (epoch 8.149), train_loss = 1.19443889, grad/param norm = 1.5127e-01, time/batch = 0.6805s	
4646/28500 (epoch 8.151), train_loss = 1.17859295, grad/param norm = 1.5603e-01, time/batch = 0.6826s	
4647/28500 (epoch 8.153), train_loss = 1.33501155, grad/param norm = 1.6442e-01, time/batch = 0.6812s	
4648/28500 (epoch 8.154), train_loss = 1.24569518, grad/param norm = 1.7318e-01, time/batch = 0.6778s	
4649/28500 (epoch 8.156), train_loss = 1.51765029, grad/param norm = 1.8279e-01, time/batch = 0.6828s	
4650/28500 (epoch 8.158), train_loss = 1.30345659, grad/param norm = 1.5508e-01, time/batch = 0.6795s	
4651/28500 (epoch 8.160), train_loss = 1.22472835, grad/param norm = 1.5681e-01, time/batch = 0.6805s	
4652/28500 (epoch 8.161), train_loss = 1.37991228, grad/param norm = 1.7222e-01, time/batch = 0.6801s	
4653/28500 (epoch 8.163), train_loss = 1.23630302, grad/param norm = 1.7840e-01, time/batch = 0.6795s	
4654/28500 (epoch 8.165), train_loss = 1.54722483, grad/param norm = 1.7063e-01, time/batch = 0.6795s	
4655/28500 (epoch 8.167), train_loss = 1.63928099, grad/param norm = 1.9192e-01, time/batch = 0.6798s	
4656/28500 (epoch 8.168), train_loss = 1.45300887, grad/param norm = 1.9207e-01, time/batch = 0.6792s	
4657/28500 (epoch 8.170), train_loss = 1.49265763, grad/param norm = 2.0189e-01, time/batch = 0.6779s	
4658/28500 (epoch 8.172), train_loss = 1.33577931, grad/param norm = 1.8199e-01, time/batch = 0.6781s	
4659/28500 (epoch 8.174), train_loss = 1.57265993, grad/param norm = 1.9159e-01, time/batch = 0.6774s	
4660/28500 (epoch 8.175), train_loss = 1.29895553, grad/param norm = 1.6218e-01, time/batch = 0.6771s	
4661/28500 (epoch 8.177), train_loss = 1.43127545, grad/param norm = 1.7343e-01, time/batch = 0.6810s	
4662/28500 (epoch 8.179), train_loss = 1.32806759, grad/param norm = 1.7913e-01, time/batch = 0.6812s	
4663/28500 (epoch 8.181), train_loss = 1.38462187, grad/param norm = 1.5731e-01, time/batch = 0.6777s	
4664/28500 (epoch 8.182), train_loss = 1.35401932, grad/param norm = 1.7533e-01, time/batch = 0.6777s	
4665/28500 (epoch 8.184), train_loss = 1.58217716, grad/param norm = 1.9122e-01, time/batch = 0.6786s	
4666/28500 (epoch 8.186), train_loss = 1.47433108, grad/param norm = 1.7806e-01, time/batch = 0.6771s	
4667/28500 (epoch 8.188), train_loss = 1.34659006, grad/param norm = 1.6031e-01, time/batch = 0.6774s	
4668/28500 (epoch 8.189), train_loss = 1.38829038, grad/param norm = 1.7026e-01, time/batch = 0.6800s	
4669/28500 (epoch 8.191), train_loss = 1.60640264, grad/param norm = 1.8217e-01, time/batch = 0.6799s	
4670/28500 (epoch 8.193), train_loss = 1.48606765, grad/param norm = 1.9101e-01, time/batch = 0.6817s	
4671/28500 (epoch 8.195), train_loss = 1.48549793, grad/param norm = 1.8617e-01, time/batch = 0.6842s	
4672/28500 (epoch 8.196), train_loss = 1.43526475, grad/param norm = 1.7337e-01, time/batch = 0.6849s	
4673/28500 (epoch 8.198), train_loss = 1.39821730, grad/param norm = 1.8297e-01, time/batch = 0.6852s	
4674/28500 (epoch 8.200), train_loss = 1.33750956, grad/param norm = 1.4977e-01, time/batch = 0.6801s	
4675/28500 (epoch 8.202), train_loss = 1.37412783, grad/param norm = 1.7569e-01, time/batch = 0.6830s	
4676/28500 (epoch 8.204), train_loss = 1.23409623, grad/param norm = 1.5994e-01, time/batch = 0.6833s	
4677/28500 (epoch 8.205), train_loss = 1.30044919, grad/param norm = 1.6192e-01, time/batch = 0.6840s	
4678/28500 (epoch 8.207), train_loss = 1.34061120, grad/param norm = 1.7297e-01, time/batch = 0.6801s	
4679/28500 (epoch 8.209), train_loss = 1.35394033, grad/param norm = 1.7657e-01, time/batch = 0.6811s	
4680/28500 (epoch 8.211), train_loss = 1.19766511, grad/param norm = 1.5862e-01, time/batch = 0.6805s	
4681/28500 (epoch 8.212), train_loss = 1.21195147, grad/param norm = 1.6641e-01, time/batch = 0.6841s	
4682/28500 (epoch 8.214), train_loss = 1.40172896, grad/param norm = 1.8500e-01, time/batch = 0.6812s	
4683/28500 (epoch 8.216), train_loss = 1.21816549, grad/param norm = 1.5586e-01, time/batch = 0.6828s	
4684/28500 (epoch 8.218), train_loss = 1.44400674, grad/param norm = 1.6202e-01, time/batch = 0.6807s	
4685/28500 (epoch 8.219), train_loss = 1.39068203, grad/param norm = 1.7625e-01, time/batch = 0.6814s	
4686/28500 (epoch 8.221), train_loss = 1.24657843, grad/param norm = 1.7078e-01, time/batch = 0.6818s	
4687/28500 (epoch 8.223), train_loss = 1.48615830, grad/param norm = 1.9090e-01, time/batch = 0.6819s	
4688/28500 (epoch 8.225), train_loss = 1.50926737, grad/param norm = 1.6946e-01, time/batch = 0.6808s	
4689/28500 (epoch 8.226), train_loss = 1.34272741, grad/param norm = 1.7833e-01, time/batch = 0.6809s	
4690/28500 (epoch 8.228), train_loss = 1.39841146, grad/param norm = 1.5777e-01, time/batch = 0.6824s	
4691/28500 (epoch 8.230), train_loss = 1.43989537, grad/param norm = 1.7078e-01, time/batch = 0.6836s	
4692/28500 (epoch 8.232), train_loss = 1.41266600, grad/param norm = 1.7325e-01, time/batch = 0.6817s	
4693/28500 (epoch 8.233), train_loss = 1.39814578, grad/param norm = 1.7767e-01, time/batch = 0.6842s	
4694/28500 (epoch 8.235), train_loss = 1.29478899, grad/param norm = 1.6302e-01, time/batch = 0.6806s	
4695/28500 (epoch 8.237), train_loss = 1.17781848, grad/param norm = 1.4495e-01, time/batch = 0.6854s	
4696/28500 (epoch 8.239), train_loss = 1.26780372, grad/param norm = 1.6857e-01, time/batch = 0.6846s	
4697/28500 (epoch 8.240), train_loss = 1.19608107, grad/param norm = 1.5680e-01, time/batch = 0.6823s	
4698/28500 (epoch 8.242), train_loss = 1.40082841, grad/param norm = 1.7765e-01, time/batch = 0.6812s	
4699/28500 (epoch 8.244), train_loss = 1.42097346, grad/param norm = 1.6926e-01, time/batch = 0.6806s	
4700/28500 (epoch 8.246), train_loss = 1.45163821, grad/param norm = 1.7534e-01, time/batch = 0.6813s	
4701/28500 (epoch 8.247), train_loss = 1.56915287, grad/param norm = 1.8082e-01, time/batch = 0.6826s	
4702/28500 (epoch 8.249), train_loss = 1.40506492, grad/param norm = 1.7881e-01, time/batch = 0.6833s	
4703/28500 (epoch 8.251), train_loss = 1.21706790, grad/param norm = 1.5393e-01, time/batch = 0.6834s	
4704/28500 (epoch 8.253), train_loss = 1.54344264, grad/param norm = 1.8788e-01, time/batch = 0.6815s	
4705/28500 (epoch 8.254), train_loss = 1.48865652, grad/param norm = 1.8030e-01, time/batch = 0.6830s	
4706/28500 (epoch 8.256), train_loss = 1.27668904, grad/param norm = 1.5640e-01, time/batch = 0.6809s	
4707/28500 (epoch 8.258), train_loss = 1.34034947, grad/param norm = 1.7237e-01, time/batch = 0.6799s	
4708/28500 (epoch 8.260), train_loss = 1.29207890, grad/param norm = 1.5846e-01, time/batch = 0.6809s	
4709/28500 (epoch 8.261), train_loss = 1.28679063, grad/param norm = 1.7097e-01, time/batch = 0.6796s	
4710/28500 (epoch 8.263), train_loss = 1.52586710, grad/param norm = 1.9095e-01, time/batch = 0.6801s	
4711/28500 (epoch 8.265), train_loss = 1.39621134, grad/param norm = 1.8629e-01, time/batch = 0.6826s	
4712/28500 (epoch 8.267), train_loss = 1.52680956, grad/param norm = 1.8171e-01, time/batch = 0.6882s	
4713/28500 (epoch 8.268), train_loss = 1.43939284, grad/param norm = 1.5720e-01, time/batch = 0.6857s	
4714/28500 (epoch 8.270), train_loss = 1.38011260, grad/param norm = 1.8435e-01, time/batch = 0.7050s	
4715/28500 (epoch 8.272), train_loss = 1.33536380, grad/param norm = 1.7439e-01, time/batch = 0.6840s	
4716/28500 (epoch 8.274), train_loss = 1.51214224, grad/param norm = 1.8621e-01, time/batch = 0.6835s	
4717/28500 (epoch 8.275), train_loss = 1.42343700, grad/param norm = 1.6554e-01, time/batch = 0.6889s	
4718/28500 (epoch 8.277), train_loss = 1.34629823, grad/param norm = 1.7328e-01, time/batch = 0.6929s	
4719/28500 (epoch 8.279), train_loss = 1.40272202, grad/param norm = 1.8086e-01, time/batch = 0.6875s	
4720/28500 (epoch 8.281), train_loss = 1.41639946, grad/param norm = 1.7214e-01, time/batch = 0.6811s	
4721/28500 (epoch 8.282), train_loss = 1.24198509, grad/param norm = 1.5172e-01, time/batch = 0.6873s	
4722/28500 (epoch 8.284), train_loss = 1.40613367, grad/param norm = 1.6725e-01, time/batch = 0.6828s	
4723/28500 (epoch 8.286), train_loss = 1.47126789, grad/param norm = 1.6922e-01, time/batch = 0.6819s	
4724/28500 (epoch 8.288), train_loss = 1.39779327, grad/param norm = 1.6967e-01, time/batch = 0.6830s	
4725/28500 (epoch 8.289), train_loss = 1.50855873, grad/param norm = 1.7471e-01, time/batch = 0.6851s	
4726/28500 (epoch 8.291), train_loss = 1.34562562, grad/param norm = 1.6482e-01, time/batch = 0.6827s	
4727/28500 (epoch 8.293), train_loss = 1.30534989, grad/param norm = 1.6946e-01, time/batch = 0.6825s	
4728/28500 (epoch 8.295), train_loss = 1.25278972, grad/param norm = 1.6104e-01, time/batch = 0.6817s	
4729/28500 (epoch 8.296), train_loss = 1.24438504, grad/param norm = 1.5857e-01, time/batch = 0.6817s	
4730/28500 (epoch 8.298), train_loss = 1.36249840, grad/param norm = 1.6861e-01, time/batch = 0.6824s	
4731/28500 (epoch 8.300), train_loss = 1.27660287, grad/param norm = 1.6712e-01, time/batch = 0.6856s	
4732/28500 (epoch 8.302), train_loss = 1.23755066, grad/param norm = 1.6316e-01, time/batch = 0.6810s	
4733/28500 (epoch 8.304), train_loss = 1.34812184, grad/param norm = 1.5924e-01, time/batch = 0.6864s	
4734/28500 (epoch 8.305), train_loss = 1.42852922, grad/param norm = 1.7107e-01, time/batch = 0.6844s	
4735/28500 (epoch 8.307), train_loss = 1.41310453, grad/param norm = 1.8710e-01, time/batch = 0.6827s	
4736/28500 (epoch 8.309), train_loss = 1.40099037, grad/param norm = 1.8882e-01, time/batch = 0.6796s	
4737/28500 (epoch 8.311), train_loss = 1.36682209, grad/param norm = 1.7775e-01, time/batch = 0.6790s	
4738/28500 (epoch 8.312), train_loss = 1.28684948, grad/param norm = 1.6411e-01, time/batch = 0.6803s	
4739/28500 (epoch 8.314), train_loss = 1.43581541, grad/param norm = 1.7665e-01, time/batch = 0.6887s	
4740/28500 (epoch 8.316), train_loss = 1.39929634, grad/param norm = 1.5408e-01, time/batch = 0.6773s	
4741/28500 (epoch 8.318), train_loss = 1.41587699, grad/param norm = 1.8505e-01, time/batch = 0.6798s	
4742/28500 (epoch 8.319), train_loss = 1.34407311, grad/param norm = 1.6700e-01, time/batch = 0.6778s	
4743/28500 (epoch 8.321), train_loss = 1.41891707, grad/param norm = 1.9458e-01, time/batch = 0.6788s	
4744/28500 (epoch 8.323), train_loss = 1.33168278, grad/param norm = 1.9054e-01, time/batch = 0.6778s	
4745/28500 (epoch 8.325), train_loss = 1.53526791, grad/param norm = 1.7749e-01, time/batch = 0.6792s	
4746/28500 (epoch 8.326), train_loss = 1.40968013, grad/param norm = 1.8446e-01, time/batch = 0.6804s	
4747/28500 (epoch 8.328), train_loss = 1.12853386, grad/param norm = 1.6016e-01, time/batch = 0.6808s	
4748/28500 (epoch 8.330), train_loss = 1.26310400, grad/param norm = 1.6599e-01, time/batch = 0.6798s	
4749/28500 (epoch 8.332), train_loss = 1.33278620, grad/param norm = 1.5745e-01, time/batch = 0.6808s	
4750/28500 (epoch 8.333), train_loss = 1.17951474, grad/param norm = 1.5792e-01, time/batch = 0.6819s	
4751/28500 (epoch 8.335), train_loss = 1.23303102, grad/param norm = 1.4802e-01, time/batch = 0.6841s	
4752/28500 (epoch 8.337), train_loss = 1.33155616, grad/param norm = 1.6972e-01, time/batch = 0.6827s	
4753/28500 (epoch 8.339), train_loss = 1.24894824, grad/param norm = 1.5727e-01, time/batch = 0.6820s	
4754/28500 (epoch 8.340), train_loss = 1.43489700, grad/param norm = 1.7489e-01, time/batch = 0.6813s	
4755/28500 (epoch 8.342), train_loss = 1.32074375, grad/param norm = 1.7683e-01, time/batch = 0.6819s	
4756/28500 (epoch 8.344), train_loss = 1.28123341, grad/param norm = 1.7300e-01, time/batch = 0.6823s	
4757/28500 (epoch 8.346), train_loss = 1.05858332, grad/param norm = 1.3592e-01, time/batch = 0.6888s	
4758/28500 (epoch 8.347), train_loss = 1.35014326, grad/param norm = 1.7166e-01, time/batch = 0.6831s	
4759/28500 (epoch 8.349), train_loss = 1.25696691, grad/param norm = 1.5344e-01, time/batch = 0.6804s	
4760/28500 (epoch 8.351), train_loss = 1.23444567, grad/param norm = 1.5562e-01, time/batch = 0.6822s	
4761/28500 (epoch 8.353), train_loss = 1.41407460, grad/param norm = 1.7590e-01, time/batch = 0.6863s	
4762/28500 (epoch 8.354), train_loss = 1.20955083, grad/param norm = 1.6391e-01, time/batch = 0.6823s	
4763/28500 (epoch 8.356), train_loss = 1.25350934, grad/param norm = 1.4851e-01, time/batch = 0.6806s	
4764/28500 (epoch 8.358), train_loss = 1.36174646, grad/param norm = 1.5030e-01, time/batch = 0.6814s	
4765/28500 (epoch 8.360), train_loss = 1.36908431, grad/param norm = 1.7520e-01, time/batch = 0.6813s	
4766/28500 (epoch 8.361), train_loss = 1.27267687, grad/param norm = 1.5481e-01, time/batch = 0.6830s	
4767/28500 (epoch 8.363), train_loss = 1.22074041, grad/param norm = 1.4886e-01, time/batch = 0.7361s	
4768/28500 (epoch 8.365), train_loss = 1.28487855, grad/param norm = 1.6611e-01, time/batch = 0.6828s	
4769/28500 (epoch 8.367), train_loss = 1.32390661, grad/param norm = 1.6032e-01, time/batch = 0.6814s	
4770/28500 (epoch 8.368), train_loss = 1.28458757, grad/param norm = 1.5400e-01, time/batch = 0.6817s	
4771/28500 (epoch 8.370), train_loss = 1.36817078, grad/param norm = 1.6304e-01, time/batch = 0.6837s	
4772/28500 (epoch 8.372), train_loss = 1.18690198, grad/param norm = 1.6068e-01, time/batch = 0.6824s	
4773/28500 (epoch 8.374), train_loss = 1.35749752, grad/param norm = 1.6807e-01, time/batch = 0.6840s	
4774/28500 (epoch 8.375), train_loss = 1.50626367, grad/param norm = 1.8092e-01, time/batch = 0.6823s	
4775/28500 (epoch 8.377), train_loss = 1.27510085, grad/param norm = 1.6967e-01, time/batch = 0.6814s	
4776/28500 (epoch 8.379), train_loss = 1.08957451, grad/param norm = 1.4471e-01, time/batch = 0.6813s	
4777/28500 (epoch 8.381), train_loss = 1.28015582, grad/param norm = 1.5187e-01, time/batch = 0.6806s	
4778/28500 (epoch 8.382), train_loss = 1.25918454, grad/param norm = 1.6212e-01, time/batch = 0.6823s	
4779/28500 (epoch 8.384), train_loss = 1.18676539, grad/param norm = 1.4874e-01, time/batch = 0.6849s	
4780/28500 (epoch 8.386), train_loss = 1.21782969, grad/param norm = 1.7930e-01, time/batch = 0.6800s	
4781/28500 (epoch 8.388), train_loss = 1.44518276, grad/param norm = 1.6480e-01, time/batch = 0.6834s	
4782/28500 (epoch 8.389), train_loss = 1.24843517, grad/param norm = 1.6239e-01, time/batch = 0.6812s	
4783/28500 (epoch 8.391), train_loss = 1.26016644, grad/param norm = 1.6495e-01, time/batch = 0.6810s	
4784/28500 (epoch 8.393), train_loss = 1.16702546, grad/param norm = 1.6121e-01, time/batch = 0.6806s	
4785/28500 (epoch 8.395), train_loss = 1.54175428, grad/param norm = 1.8956e-01, time/batch = 0.6826s	
4786/28500 (epoch 8.396), train_loss = 1.42371918, grad/param norm = 1.7308e-01, time/batch = 0.6803s	
4787/28500 (epoch 8.398), train_loss = 1.16064221, grad/param norm = 1.9364e-01, time/batch = 0.6851s	
4788/28500 (epoch 8.400), train_loss = 1.38221918, grad/param norm = 2.0399e-01, time/batch = 0.6806s	
4789/28500 (epoch 8.402), train_loss = 1.32378633, grad/param norm = 1.6482e-01, time/batch = 0.6853s	
4790/28500 (epoch 8.404), train_loss = 1.45109152, grad/param norm = 1.9999e-01, time/batch = 0.6804s	
4791/28500 (epoch 8.405), train_loss = 1.43187231, grad/param norm = 1.7083e-01, time/batch = 0.6852s	
4792/28500 (epoch 8.407), train_loss = 1.37333419, grad/param norm = 1.6967e-01, time/batch = 0.6827s	
4793/28500 (epoch 8.409), train_loss = 1.37887113, grad/param norm = 1.7802e-01, time/batch = 0.6835s	
4794/28500 (epoch 8.411), train_loss = 1.42722769, grad/param norm = 1.6232e-01, time/batch = 0.6800s	
4795/28500 (epoch 8.412), train_loss = 1.55875892, grad/param norm = 1.9566e-01, time/batch = 0.6824s	
4796/28500 (epoch 8.414), train_loss = 1.37985925, grad/param norm = 1.8354e-01, time/batch = 0.6819s	
4797/28500 (epoch 8.416), train_loss = 1.29296320, grad/param norm = 1.8477e-01, time/batch = 0.6808s	
4798/28500 (epoch 8.418), train_loss = 1.37061305, grad/param norm = 1.6241e-01, time/batch = 0.6800s	
4799/28500 (epoch 8.419), train_loss = 1.48295916, grad/param norm = 1.8755e-01, time/batch = 0.6840s	
4800/28500 (epoch 8.421), train_loss = 1.42593209, grad/param norm = 1.6752e-01, time/batch = 0.6838s	
4801/28500 (epoch 8.423), train_loss = 1.51896089, grad/param norm = 1.8048e-01, time/batch = 0.6929s	
4802/28500 (epoch 8.425), train_loss = 1.40418273, grad/param norm = 1.9241e-01, time/batch = 0.6862s	
4803/28500 (epoch 8.426), train_loss = 1.37347899, grad/param norm = 1.7422e-01, time/batch = 0.6806s	
4804/28500 (epoch 8.428), train_loss = 1.58104043, grad/param norm = 1.7529e-01, time/batch = 0.6816s	
4805/28500 (epoch 8.430), train_loss = 1.46073599, grad/param norm = 1.6746e-01, time/batch = 0.6804s	
4806/28500 (epoch 8.432), train_loss = 1.41735604, grad/param norm = 1.8148e-01, time/batch = 0.6813s	
4807/28500 (epoch 8.433), train_loss = 1.46613655, grad/param norm = 1.8694e-01, time/batch = 0.6813s	
4808/28500 (epoch 8.435), train_loss = 1.33951361, grad/param norm = 1.6443e-01, time/batch = 0.6815s	
4809/28500 (epoch 8.437), train_loss = 1.18940612, grad/param norm = 1.4364e-01, time/batch = 0.6813s	
4810/28500 (epoch 8.439), train_loss = 1.24326661, grad/param norm = 1.5115e-01, time/batch = 0.6834s	
4811/28500 (epoch 8.440), train_loss = 1.48379743, grad/param norm = 1.7539e-01, time/batch = 0.6878s	
4812/28500 (epoch 8.442), train_loss = 1.24403775, grad/param norm = 1.7262e-01, time/batch = 0.6847s	
4813/28500 (epoch 8.444), train_loss = 1.19853746, grad/param norm = 1.5182e-01, time/batch = 0.6816s	
4814/28500 (epoch 8.446), train_loss = 1.13854884, grad/param norm = 1.5642e-01, time/batch = 0.6837s	
4815/28500 (epoch 8.447), train_loss = 1.20486524, grad/param norm = 1.5550e-01, time/batch = 0.6810s	
4816/28500 (epoch 8.449), train_loss = 1.23450654, grad/param norm = 1.5481e-01, time/batch = 0.6811s	
4817/28500 (epoch 8.451), train_loss = 1.30384524, grad/param norm = 1.6657e-01, time/batch = 0.6803s	
4818/28500 (epoch 8.453), train_loss = 1.35818578, grad/param norm = 1.9567e-01, time/batch = 0.6801s	
4819/28500 (epoch 8.454), train_loss = 1.26900460, grad/param norm = 1.6621e-01, time/batch = 0.6772s	
4820/28500 (epoch 8.456), train_loss = 1.39558106, grad/param norm = 1.6139e-01, time/batch = 0.6774s	
4821/28500 (epoch 8.458), train_loss = 1.27958722, grad/param norm = 1.6519e-01, time/batch = 0.6847s	
4822/28500 (epoch 8.460), train_loss = 1.42350927, grad/param norm = 1.6641e-01, time/batch = 0.6941s	
4823/28500 (epoch 8.461), train_loss = 1.28823916, grad/param norm = 1.6673e-01, time/batch = 0.6815s	
4824/28500 (epoch 8.463), train_loss = 1.20680871, grad/param norm = 1.4967e-01, time/batch = 0.6981s	
4825/28500 (epoch 8.465), train_loss = 1.17137216, grad/param norm = 1.7222e-01, time/batch = 0.6887s	
4826/28500 (epoch 8.467), train_loss = 1.38745771, grad/param norm = 1.6884e-01, time/batch = 0.6874s	
4827/28500 (epoch 8.468), train_loss = 1.15743851, grad/param norm = 1.4542e-01, time/batch = 0.6940s	
4828/28500 (epoch 8.470), train_loss = 1.31861971, grad/param norm = 1.7956e-01, time/batch = 0.6957s	
4829/28500 (epoch 8.472), train_loss = 1.24723730, grad/param norm = 1.5323e-01, time/batch = 0.6937s	
4830/28500 (epoch 8.474), train_loss = 1.61889165, grad/param norm = 2.0053e-01, time/batch = 0.6928s	
4831/28500 (epoch 8.475), train_loss = 1.24304254, grad/param norm = 1.4830e-01, time/batch = 0.7014s	
4832/28500 (epoch 8.477), train_loss = 1.31335523, grad/param norm = 1.6827e-01, time/batch = 0.6905s	
4833/28500 (epoch 8.479), train_loss = 1.35600175, grad/param norm = 1.6381e-01, time/batch = 0.6932s	
4834/28500 (epoch 8.481), train_loss = 1.30761083, grad/param norm = 1.6989e-01, time/batch = 0.6924s	
4835/28500 (epoch 8.482), train_loss = 1.22834364, grad/param norm = 1.7312e-01, time/batch = 0.6895s	
4836/28500 (epoch 8.484), train_loss = 1.22940782, grad/param norm = 1.6226e-01, time/batch = 0.6911s	
4837/28500 (epoch 8.486), train_loss = 1.18085913, grad/param norm = 1.7008e-01, time/batch = 0.6911s	
4838/28500 (epoch 8.488), train_loss = 1.34419461, grad/param norm = 1.7611e-01, time/batch = 0.6900s	
4839/28500 (epoch 8.489), train_loss = 1.42957318, grad/param norm = 1.7328e-01, time/batch = 0.6896s	
4840/28500 (epoch 8.491), train_loss = 1.27160518, grad/param norm = 1.6293e-01, time/batch = 0.6921s	
4841/28500 (epoch 8.493), train_loss = 1.23570365, grad/param norm = 1.5651e-01, time/batch = 0.6945s	
4842/28500 (epoch 8.495), train_loss = 1.24560009, grad/param norm = 1.5567e-01, time/batch = 0.6929s	
4843/28500 (epoch 8.496), train_loss = 1.32846684, grad/param norm = 1.7579e-01, time/batch = 0.6899s	
4844/28500 (epoch 8.498), train_loss = 1.38603102, grad/param norm = 1.6550e-01, time/batch = 0.6900s	
4845/28500 (epoch 8.500), train_loss = 1.32477526, grad/param norm = 1.6739e-01, time/batch = 0.6925s	
4846/28500 (epoch 8.502), train_loss = 1.41229762, grad/param norm = 1.6221e-01, time/batch = 0.6915s	
4847/28500 (epoch 8.504), train_loss = 1.38941523, grad/param norm = 1.5739e-01, time/batch = 0.6936s	
4848/28500 (epoch 8.505), train_loss = 1.23119826, grad/param norm = 1.5265e-01, time/batch = 0.6894s	
4849/28500 (epoch 8.507), train_loss = 1.46558938, grad/param norm = 1.8520e-01, time/batch = 0.6890s	
4850/28500 (epoch 8.509), train_loss = 1.34970396, grad/param norm = 1.7516e-01, time/batch = 0.6891s	
4851/28500 (epoch 8.511), train_loss = 1.33393051, grad/param norm = 1.6623e-01, time/batch = 0.6913s	
4852/28500 (epoch 8.512), train_loss = 1.34282486, grad/param norm = 1.6659e-01, time/batch = 0.6894s	
4853/28500 (epoch 8.514), train_loss = 1.19761919, grad/param norm = 1.5436e-01, time/batch = 0.6893s	
4854/28500 (epoch 8.516), train_loss = 1.23104803, grad/param norm = 1.4839e-01, time/batch = 0.6930s	
4855/28500 (epoch 8.518), train_loss = 1.28245433, grad/param norm = 1.4076e-01, time/batch = 0.6899s	
4856/28500 (epoch 8.519), train_loss = 1.36865524, grad/param norm = 1.6238e-01, time/batch = 0.6888s	
4857/28500 (epoch 8.521), train_loss = 1.50086273, grad/param norm = 1.7815e-01, time/batch = 0.7019s	
4858/28500 (epoch 8.523), train_loss = 1.39803600, grad/param norm = 1.8091e-01, time/batch = 0.6909s	
4859/28500 (epoch 8.525), train_loss = 1.44412136, grad/param norm = 1.7129e-01, time/batch = 0.6914s	
4860/28500 (epoch 8.526), train_loss = 1.38027912, grad/param norm = 1.7163e-01, time/batch = 0.6916s	
4861/28500 (epoch 8.528), train_loss = 1.45170079, grad/param norm = 1.8943e-01, time/batch = 0.6944s	
4862/28500 (epoch 8.530), train_loss = 1.44383314, grad/param norm = 1.5579e-01, time/batch = 0.6924s	
4863/28500 (epoch 8.532), train_loss = 1.28898644, grad/param norm = 1.7817e-01, time/batch = 0.6911s	
4864/28500 (epoch 8.533), train_loss = 1.46858768, grad/param norm = 1.7578e-01, time/batch = 0.6929s	
4865/28500 (epoch 8.535), train_loss = 1.15762755, grad/param norm = 1.5812e-01, time/batch = 0.6903s	
4866/28500 (epoch 8.537), train_loss = 1.15711783, grad/param norm = 1.6147e-01, time/batch = 0.6889s	
4867/28500 (epoch 8.539), train_loss = 1.21098863, grad/param norm = 1.5657e-01, time/batch = 0.6897s	
4868/28500 (epoch 8.540), train_loss = 1.31654993, grad/param norm = 1.5717e-01, time/batch = 0.6889s	
4869/28500 (epoch 8.542), train_loss = 1.52099848, grad/param norm = 1.8592e-01, time/batch = 0.6907s	
4870/28500 (epoch 8.544), train_loss = 1.50241498, grad/param norm = 1.6748e-01, time/batch = 0.6934s	
4871/28500 (epoch 8.546), train_loss = 1.34761022, grad/param norm = 1.6935e-01, time/batch = 0.6955s	
4872/28500 (epoch 8.547), train_loss = 1.32128500, grad/param norm = 1.5160e-01, time/batch = 0.6904s	
4873/28500 (epoch 8.549), train_loss = 1.15169413, grad/param norm = 1.4286e-01, time/batch = 0.6912s	
4874/28500 (epoch 8.551), train_loss = 1.45373610, grad/param norm = 1.8420e-01, time/batch = 0.6933s	
4875/28500 (epoch 8.553), train_loss = 1.57427020, grad/param norm = 1.8768e-01, time/batch = 0.6912s	
4876/28500 (epoch 8.554), train_loss = 1.27135748, grad/param norm = 1.5840e-01, time/batch = 0.6909s	
4877/28500 (epoch 8.556), train_loss = 1.35786203, grad/param norm = 1.7813e-01, time/batch = 0.6891s	
4878/28500 (epoch 8.558), train_loss = 1.38186500, grad/param norm = 1.6818e-01, time/batch = 0.6894s	
4879/28500 (epoch 8.560), train_loss = 1.37944908, grad/param norm = 1.7675e-01, time/batch = 0.6915s	
4880/28500 (epoch 8.561), train_loss = 1.43093414, grad/param norm = 1.8623e-01, time/batch = 0.6906s	
4881/28500 (epoch 8.563), train_loss = 1.46754680, grad/param norm = 1.8247e-01, time/batch = 0.6906s	
4882/28500 (epoch 8.565), train_loss = 1.30322236, grad/param norm = 1.6638e-01, time/batch = 0.6889s	
4883/28500 (epoch 8.567), train_loss = 1.20265648, grad/param norm = 1.7737e-01, time/batch = 0.6886s	
4884/28500 (epoch 8.568), train_loss = 1.38192526, grad/param norm = 1.8043e-01, time/batch = 0.6892s	
4885/28500 (epoch 8.570), train_loss = 1.27062250, grad/param norm = 1.7567e-01, time/batch = 0.6912s	
4886/28500 (epoch 8.572), train_loss = 1.29614456, grad/param norm = 1.6732e-01, time/batch = 0.6941s	
4887/28500 (epoch 8.574), train_loss = 1.34433807, grad/param norm = 1.5920e-01, time/batch = 0.6992s	
4888/28500 (epoch 8.575), train_loss = 1.27642248, grad/param norm = 1.6581e-01, time/batch = 0.6936s	
4889/28500 (epoch 8.577), train_loss = 1.30842758, grad/param norm = 1.6186e-01, time/batch = 0.6898s	
4890/28500 (epoch 8.579), train_loss = 1.44803976, grad/param norm = 1.8656e-01, time/batch = 0.6906s	
4891/28500 (epoch 8.581), train_loss = 1.29732693, grad/param norm = 1.6783e-01, time/batch = 0.6914s	
4892/28500 (epoch 8.582), train_loss = 1.41292804, grad/param norm = 1.6724e-01, time/batch = 0.7058s	
4893/28500 (epoch 8.584), train_loss = 1.26934765, grad/param norm = 1.5839e-01, time/batch = 0.6923s	
4894/28500 (epoch 8.586), train_loss = 1.19384789, grad/param norm = 1.4450e-01, time/batch = 0.6929s	
4895/28500 (epoch 8.588), train_loss = 1.21740656, grad/param norm = 1.5032e-01, time/batch = 0.6948s	
4896/28500 (epoch 8.589), train_loss = 1.47249301, grad/param norm = 1.7020e-01, time/batch = 0.6959s	
4897/28500 (epoch 8.591), train_loss = 1.37841327, grad/param norm = 1.5474e-01, time/batch = 0.6937s	
4898/28500 (epoch 8.593), train_loss = 1.26412342, grad/param norm = 1.5794e-01, time/batch = 0.6952s	
4899/28500 (epoch 8.595), train_loss = 1.58661229, grad/param norm = 2.0381e-01, time/batch = 0.6942s	
4900/28500 (epoch 8.596), train_loss = 1.54609717, grad/param norm = 1.8998e-01, time/batch = 0.6967s	
4901/28500 (epoch 8.598), train_loss = 1.34749394, grad/param norm = 1.5395e-01, time/batch = 0.6988s	
4902/28500 (epoch 8.600), train_loss = 1.37544996, grad/param norm = 1.8226e-01, time/batch = 0.6970s	
4903/28500 (epoch 8.602), train_loss = 1.53979294, grad/param norm = 1.8751e-01, time/batch = 0.6938s	
4904/28500 (epoch 8.604), train_loss = 1.40348878, grad/param norm = 1.6189e-01, time/batch = 0.6940s	
4905/28500 (epoch 8.605), train_loss = 1.34022038, grad/param norm = 1.6323e-01, time/batch = 0.6950s	
4906/28500 (epoch 8.607), train_loss = 1.39022037, grad/param norm = 1.5768e-01, time/batch = 0.6952s	
4907/28500 (epoch 8.609), train_loss = 1.35106434, grad/param norm = 1.7721e-01, time/batch = 0.6972s	
4908/28500 (epoch 8.611), train_loss = 1.38255805, grad/param norm = 1.7590e-01, time/batch = 0.7038s	
4909/28500 (epoch 8.612), train_loss = 1.38379420, grad/param norm = 1.6041e-01, time/batch = 0.6929s	
4910/28500 (epoch 8.614), train_loss = 1.36911603, grad/param norm = 1.6335e-01, time/batch = 0.6948s	
4911/28500 (epoch 8.616), train_loss = 1.30263834, grad/param norm = 1.7369e-01, time/batch = 0.6954s	
4912/28500 (epoch 8.618), train_loss = 1.27348342, grad/param norm = 1.6054e-01, time/batch = 0.6938s	
4913/28500 (epoch 8.619), train_loss = 1.54954614, grad/param norm = 1.8510e-01, time/batch = 0.6928s	
4914/28500 (epoch 8.621), train_loss = 1.10556839, grad/param norm = 1.4330e-01, time/batch = 0.6929s	
4915/28500 (epoch 8.623), train_loss = 1.41318136, grad/param norm = 1.7017e-01, time/batch = 0.6928s	
4916/28500 (epoch 8.625), train_loss = 1.17756947, grad/param norm = 1.5642e-01, time/batch = 0.6925s	
4917/28500 (epoch 8.626), train_loss = 1.05524839, grad/param norm = 1.4250e-01, time/batch = 0.6925s	
4918/28500 (epoch 8.628), train_loss = 1.21732901, grad/param norm = 1.6593e-01, time/batch = 0.6931s	
4919/28500 (epoch 8.630), train_loss = 1.15646527, grad/param norm = 1.5248e-01, time/batch = 0.6954s	
4920/28500 (epoch 8.632), train_loss = 1.41487694, grad/param norm = 1.6233e-01, time/batch = 0.6921s	
4921/28500 (epoch 8.633), train_loss = 1.41802507, grad/param norm = 1.6360e-01, time/batch = 0.6968s	
4922/28500 (epoch 8.635), train_loss = 1.51930292, grad/param norm = 1.7799e-01, time/batch = 0.6940s	
4923/28500 (epoch 8.637), train_loss = 1.34580688, grad/param norm = 1.6281e-01, time/batch = 0.6933s	
4924/28500 (epoch 8.639), train_loss = 1.16932588, grad/param norm = 1.4972e-01, time/batch = 0.6946s	
4925/28500 (epoch 8.640), train_loss = 1.21665626, grad/param norm = 1.5678e-01, time/batch = 0.6968s	
4926/28500 (epoch 8.642), train_loss = 1.38134498, grad/param norm = 1.5869e-01, time/batch = 0.6992s	
4927/28500 (epoch 8.644), train_loss = 1.40859494, grad/param norm = 1.6282e-01, time/batch = 0.7116s	
4928/28500 (epoch 8.646), train_loss = 1.21320345, grad/param norm = 1.4595e-01, time/batch = 0.7014s	
4929/28500 (epoch 8.647), train_loss = 1.21656936, grad/param norm = 1.5922e-01, time/batch = 0.6937s	
4930/28500 (epoch 8.649), train_loss = 1.21189784, grad/param norm = 1.5855e-01, time/batch = 0.6848s	
4931/28500 (epoch 8.651), train_loss = 1.17830614, grad/param norm = 1.4899e-01, time/batch = 0.6900s	
4932/28500 (epoch 8.653), train_loss = 1.20612959, grad/param norm = 1.6039e-01, time/batch = 0.6822s	
4933/28500 (epoch 8.654), train_loss = 1.26762996, grad/param norm = 1.5646e-01, time/batch = 0.6841s	
4934/28500 (epoch 8.656), train_loss = 1.27992236, grad/param norm = 1.7089e-01, time/batch = 0.6995s	
4935/28500 (epoch 8.658), train_loss = 1.36338153, grad/param norm = 1.8559e-01, time/batch = 0.6890s	
4936/28500 (epoch 8.660), train_loss = 1.29450292, grad/param norm = 1.4973e-01, time/batch = 0.6860s	
4937/28500 (epoch 8.661), train_loss = 1.46140986, grad/param norm = 1.7766e-01, time/batch = 0.6859s	
4938/28500 (epoch 8.663), train_loss = 1.52996457, grad/param norm = 1.8403e-01, time/batch = 0.6799s	
4939/28500 (epoch 8.665), train_loss = 1.29060891, grad/param norm = 1.6829e-01, time/batch = 0.6806s	
4940/28500 (epoch 8.667), train_loss = 1.37073755, grad/param norm = 1.6497e-01, time/batch = 0.6795s	
4941/28500 (epoch 8.668), train_loss = 1.30413000, grad/param norm = 1.5888e-01, time/batch = 0.6822s	
4942/28500 (epoch 8.670), train_loss = 1.31667335, grad/param norm = 1.5924e-01, time/batch = 0.6822s	
4943/28500 (epoch 8.672), train_loss = 1.29429607, grad/param norm = 1.6054e-01, time/batch = 0.6796s	
4944/28500 (epoch 8.674), train_loss = 1.15569349, grad/param norm = 1.6334e-01, time/batch = 0.6839s	
4945/28500 (epoch 8.675), train_loss = 1.16905813, grad/param norm = 1.5709e-01, time/batch = 0.6820s	
4946/28500 (epoch 8.677), train_loss = 1.28783109, grad/param norm = 1.5954e-01, time/batch = 0.6863s	
4947/28500 (epoch 8.679), train_loss = 1.30125905, grad/param norm = 1.6676e-01, time/batch = 0.6811s	
4948/28500 (epoch 8.681), train_loss = 1.42642424, grad/param norm = 1.6613e-01, time/batch = 0.6795s	
4949/28500 (epoch 8.682), train_loss = 1.27895330, grad/param norm = 1.7509e-01, time/batch = 0.6795s	
4950/28500 (epoch 8.684), train_loss = 1.38468977, grad/param norm = 1.6144e-01, time/batch = 0.6834s	
4951/28500 (epoch 8.686), train_loss = 1.24624476, grad/param norm = 1.6172e-01, time/batch = 0.6791s	
4952/28500 (epoch 8.688), train_loss = 1.22459547, grad/param norm = 1.4501e-01, time/batch = 0.6769s	
4953/28500 (epoch 8.689), train_loss = 1.34828585, grad/param norm = 1.6880e-01, time/batch = 0.6797s	
4954/28500 (epoch 8.691), train_loss = 1.36255259, grad/param norm = 1.8964e-01, time/batch = 0.6821s	
4955/28500 (epoch 8.693), train_loss = 1.29758507, grad/param norm = 1.6869e-01, time/batch = 0.6767s	
4956/28500 (epoch 8.695), train_loss = 1.19422048, grad/param norm = 1.8384e-01, time/batch = 0.6817s	
4957/28500 (epoch 8.696), train_loss = 1.31122512, grad/param norm = 1.7665e-01, time/batch = 0.6813s	
4958/28500 (epoch 8.698), train_loss = 1.32144451, grad/param norm = 1.5386e-01, time/batch = 0.6870s	
4959/28500 (epoch 8.700), train_loss = 1.32245381, grad/param norm = 1.5499e-01, time/batch = 0.6825s	
4960/28500 (epoch 8.702), train_loss = 1.46964015, grad/param norm = 1.7469e-01, time/batch = 0.6805s	
4961/28500 (epoch 8.704), train_loss = 1.36529743, grad/param norm = 1.6928e-01, time/batch = 0.6834s	
4962/28500 (epoch 8.705), train_loss = 1.42288248, grad/param norm = 1.7475e-01, time/batch = 0.6820s	
4963/28500 (epoch 8.707), train_loss = 1.31721475, grad/param norm = 1.8283e-01, time/batch = 0.6862s	
4964/28500 (epoch 8.709), train_loss = 1.41637648, grad/param norm = 1.8120e-01, time/batch = 0.6808s	
4965/28500 (epoch 8.711), train_loss = 1.27556177, grad/param norm = 1.9136e-01, time/batch = 0.6819s	
4966/28500 (epoch 8.712), train_loss = 1.42868571, grad/param norm = 1.8087e-01, time/batch = 0.6794s	
4967/28500 (epoch 8.714), train_loss = 1.39519324, grad/param norm = 1.7463e-01, time/batch = 0.6797s	
4968/28500 (epoch 8.716), train_loss = 1.27758138, grad/param norm = 1.7017e-01, time/batch = 0.6779s	
4969/28500 (epoch 8.718), train_loss = 1.23995427, grad/param norm = 1.5741e-01, time/batch = 0.6789s	
4970/28500 (epoch 8.719), train_loss = 1.26461508, grad/param norm = 1.5554e-01, time/batch = 0.6784s	
4971/28500 (epoch 8.721), train_loss = 1.09786398, grad/param norm = 1.4735e-01, time/batch = 0.6821s	
4972/28500 (epoch 8.723), train_loss = 1.30947903, grad/param norm = 1.6731e-01, time/batch = 0.6790s	
4973/28500 (epoch 8.725), train_loss = 1.41056728, grad/param norm = 1.5071e-01, time/batch = 0.6836s	
4974/28500 (epoch 8.726), train_loss = 1.33139884, grad/param norm = 1.6748e-01, time/batch = 0.6907s	
4975/28500 (epoch 8.728), train_loss = 1.16048429, grad/param norm = 1.4624e-01, time/batch = 0.6852s	
4976/28500 (epoch 8.730), train_loss = 1.35586924, grad/param norm = 1.7895e-01, time/batch = 0.6812s	
4977/28500 (epoch 8.732), train_loss = 1.14390961, grad/param norm = 1.6051e-01, time/batch = 0.6812s	
4978/28500 (epoch 8.733), train_loss = 1.11565778, grad/param norm = 1.4593e-01, time/batch = 0.6819s	
4979/28500 (epoch 8.735), train_loss = 1.12892044, grad/param norm = 1.4715e-01, time/batch = 0.6782s	
4980/28500 (epoch 8.737), train_loss = 1.10837171, grad/param norm = 1.4488e-01, time/batch = 0.6925s	
4981/28500 (epoch 8.739), train_loss = 1.27941464, grad/param norm = 1.6756e-01, time/batch = 0.6871s	
4982/28500 (epoch 8.740), train_loss = 1.30419724, grad/param norm = 1.6556e-01, time/batch = 0.6847s	
4983/28500 (epoch 8.742), train_loss = 1.23225192, grad/param norm = 1.5630e-01, time/batch = 0.6811s	
4984/28500 (epoch 8.744), train_loss = 1.36095307, grad/param norm = 1.7133e-01, time/batch = 0.6828s	
4985/28500 (epoch 8.746), train_loss = 1.18080769, grad/param norm = 1.4146e-01, time/batch = 0.6789s	
4986/28500 (epoch 8.747), train_loss = 1.20768081, grad/param norm = 1.6954e-01, time/batch = 0.6996s	
4987/28500 (epoch 8.749), train_loss = 1.51523299, grad/param norm = 1.8866e-01, time/batch = 0.6822s	
4988/28500 (epoch 8.751), train_loss = 1.21562494, grad/param norm = 1.6949e-01, time/batch = 0.6775s	
4989/28500 (epoch 8.753), train_loss = 1.20254708, grad/param norm = 1.5122e-01, time/batch = 0.6759s	
4990/28500 (epoch 8.754), train_loss = 1.11826578, grad/param norm = 1.5328e-01, time/batch = 0.6900s	
4991/28500 (epoch 8.756), train_loss = 1.41178940, grad/param norm = 1.6702e-01, time/batch = 0.6953s	
4992/28500 (epoch 8.758), train_loss = 1.35334516, grad/param norm = 1.6096e-01, time/batch = 0.6802s	
4993/28500 (epoch 8.760), train_loss = 1.16192369, grad/param norm = 1.6675e-01, time/batch = 0.6792s	
4994/28500 (epoch 8.761), train_loss = 1.19565685, grad/param norm = 1.6730e-01, time/batch = 0.6803s	
4995/28500 (epoch 8.763), train_loss = 1.05712834, grad/param norm = 1.5592e-01, time/batch = 0.6761s	
4996/28500 (epoch 8.765), train_loss = 1.22857258, grad/param norm = 1.5243e-01, time/batch = 0.6766s	
4997/28500 (epoch 8.767), train_loss = 1.08933934, grad/param norm = 1.4741e-01, time/batch = 0.6797s	
4998/28500 (epoch 8.768), train_loss = 1.42440434, grad/param norm = 1.8064e-01, time/batch = 0.6785s	
4999/28500 (epoch 8.770), train_loss = 1.13276939, grad/param norm = 1.6938e-01, time/batch = 0.6773s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch8.77_1.6097.t7	
5000/28500 (epoch 8.772), train_loss = 1.03738734, grad/param norm = 1.6176e-01, time/batch = 0.6758s	
5001/28500 (epoch 8.774), train_loss = 1.50453075, grad/param norm = 1.8328e-01, time/batch = 0.6879s	
5002/28500 (epoch 8.775), train_loss = 1.36934929, grad/param norm = 1.5771e-01, time/batch = 0.6807s	
5003/28500 (epoch 8.777), train_loss = 1.32813364, grad/param norm = 1.5921e-01, time/batch = 0.6779s	
5004/28500 (epoch 8.779), train_loss = 1.13540567, grad/param norm = 1.5337e-01, time/batch = 0.6837s	
5005/28500 (epoch 8.781), train_loss = 1.37092023, grad/param norm = 1.7585e-01, time/batch = 0.7013s	
5006/28500 (epoch 8.782), train_loss = 1.39671621, grad/param norm = 1.7257e-01, time/batch = 0.6867s	
5007/28500 (epoch 8.784), train_loss = 1.09669597, grad/param norm = 1.4573e-01, time/batch = 0.6848s	
5008/28500 (epoch 8.786), train_loss = 1.22942381, grad/param norm = 1.4828e-01, time/batch = 0.6804s	
5009/28500 (epoch 8.788), train_loss = 1.36594082, grad/param norm = 1.8044e-01, time/batch = 0.6779s	
5010/28500 (epoch 8.789), train_loss = 1.04975119, grad/param norm = 1.6188e-01, time/batch = 0.6775s	
5011/28500 (epoch 8.791), train_loss = 1.28578868, grad/param norm = 1.7874e-01, time/batch = 0.6789s	
5012/28500 (epoch 8.793), train_loss = 1.20993048, grad/param norm = 1.7846e-01, time/batch = 0.6782s	
5013/28500 (epoch 8.795), train_loss = 1.29355465, grad/param norm = 1.5094e-01, time/batch = 0.6811s	
5014/28500 (epoch 8.796), train_loss = 1.19494465, grad/param norm = 1.5220e-01, time/batch = 0.6832s	
5015/28500 (epoch 8.798), train_loss = 1.15079284, grad/param norm = 1.4993e-01, time/batch = 0.6979s	
5016/28500 (epoch 8.800), train_loss = 1.16942759, grad/param norm = 1.5072e-01, time/batch = 0.6988s	
5017/28500 (epoch 8.802), train_loss = 1.31838757, grad/param norm = 1.8623e-01, time/batch = 0.6972s	
5018/28500 (epoch 8.804), train_loss = 1.28552365, grad/param norm = 1.6203e-01, time/batch = 0.6925s	
5019/28500 (epoch 8.805), train_loss = 1.30739673, grad/param norm = 1.8085e-01, time/batch = 0.6926s	
5020/28500 (epoch 8.807), train_loss = 1.38925981, grad/param norm = 1.7643e-01, time/batch = 0.6927s	
5021/28500 (epoch 8.809), train_loss = 1.25680887, grad/param norm = 1.5721e-01, time/batch = 0.6955s	
5022/28500 (epoch 8.811), train_loss = 1.37165085, grad/param norm = 1.6675e-01, time/batch = 0.6956s	
5023/28500 (epoch 8.812), train_loss = 1.35340119, grad/param norm = 1.7213e-01, time/batch = 0.6957s	
5024/28500 (epoch 8.814), train_loss = 1.26832828, grad/param norm = 1.7228e-01, time/batch = 0.6931s	
5025/28500 (epoch 8.816), train_loss = 1.45907986, grad/param norm = 1.6907e-01, time/batch = 0.6932s	
5026/28500 (epoch 8.818), train_loss = 1.36016510, grad/param norm = 1.6506e-01, time/batch = 0.6929s	
5027/28500 (epoch 8.819), train_loss = 1.30087740, grad/param norm = 1.6503e-01, time/batch = 0.6930s	
5028/28500 (epoch 8.821), train_loss = 1.20911293, grad/param norm = 1.5958e-01, time/batch = 0.6936s	
5029/28500 (epoch 8.823), train_loss = 1.52026648, grad/param norm = 1.8713e-01, time/batch = 0.6927s	
5030/28500 (epoch 8.825), train_loss = 1.26474893, grad/param norm = 1.7486e-01, time/batch = 0.6968s	
5031/28500 (epoch 8.826), train_loss = 1.36282558, grad/param norm = 1.8946e-01, time/batch = 0.7031s	
5032/28500 (epoch 8.828), train_loss = 1.17575607, grad/param norm = 1.7549e-01, time/batch = 0.6955s	
5033/28500 (epoch 8.830), train_loss = 1.23757079, grad/param norm = 1.5215e-01, time/batch = 0.6936s	
5034/28500 (epoch 8.832), train_loss = 1.28791084, grad/param norm = 1.6759e-01, time/batch = 0.6953s	
5035/28500 (epoch 8.833), train_loss = 1.47322034, grad/param norm = 1.6635e-01, time/batch = 0.6963s	
5036/28500 (epoch 8.835), train_loss = 1.22939615, grad/param norm = 1.6237e-01, time/batch = 0.6942s	
5037/28500 (epoch 8.837), train_loss = 1.13301577, grad/param norm = 1.5119e-01, time/batch = 0.6929s	
5038/28500 (epoch 8.839), train_loss = 1.41264107, grad/param norm = 1.7702e-01, time/batch = 0.6940s	
5039/28500 (epoch 8.840), train_loss = 1.43342031, grad/param norm = 1.9397e-01, time/batch = 0.6982s	
5040/28500 (epoch 8.842), train_loss = 1.36975396, grad/param norm = 1.6288e-01, time/batch = 0.6981s	
5041/28500 (epoch 8.844), train_loss = 1.30996540, grad/param norm = 1.5980e-01, time/batch = 0.6972s	
5042/28500 (epoch 8.846), train_loss = 1.45151679, grad/param norm = 1.7474e-01, time/batch = 0.6992s	
5043/28500 (epoch 8.847), train_loss = 1.25700341, grad/param norm = 1.5775e-01, time/batch = 0.6943s	
5044/28500 (epoch 8.849), train_loss = 1.23944877, grad/param norm = 1.5258e-01, time/batch = 0.6934s	
5045/28500 (epoch 8.851), train_loss = 1.12969810, grad/param norm = 1.6022e-01, time/batch = 0.6938s	
5046/28500 (epoch 8.853), train_loss = 1.31329254, grad/param norm = 1.7439e-01, time/batch = 0.6970s	
5047/28500 (epoch 8.854), train_loss = 1.30936686, grad/param norm = 1.6657e-01, time/batch = 0.6973s	
5048/28500 (epoch 8.856), train_loss = 1.39412213, grad/param norm = 1.7195e-01, time/batch = 0.6971s	
5049/28500 (epoch 8.858), train_loss = 1.13057802, grad/param norm = 1.4232e-01, time/batch = 0.6951s	
5050/28500 (epoch 8.860), train_loss = 1.37162569, grad/param norm = 1.8215e-01, time/batch = 0.6928s	
5051/28500 (epoch 8.861), train_loss = 1.29789984, grad/param norm = 1.7531e-01, time/batch = 0.6989s	
5052/28500 (epoch 8.863), train_loss = 1.42529550, grad/param norm = 1.6813e-01, time/batch = 0.7037s	
5053/28500 (epoch 8.865), train_loss = 1.28436772, grad/param norm = 1.6264e-01, time/batch = 0.7085s	
5054/28500 (epoch 8.867), train_loss = 1.37263794, grad/param norm = 1.9216e-01, time/batch = 0.6986s	
5055/28500 (epoch 8.868), train_loss = 1.16181463, grad/param norm = 1.5274e-01, time/batch = 0.6968s	
5056/28500 (epoch 8.870), train_loss = 1.08502068, grad/param norm = 1.4673e-01, time/batch = 0.6968s	
5057/28500 (epoch 8.872), train_loss = 1.36068402, grad/param norm = 1.7871e-01, time/batch = 0.6954s	
5058/28500 (epoch 8.874), train_loss = 1.30617752, grad/param norm = 1.7207e-01, time/batch = 0.6960s	
5059/28500 (epoch 8.875), train_loss = 1.39506659, grad/param norm = 1.6743e-01, time/batch = 0.6968s	
5060/28500 (epoch 8.877), train_loss = 1.30215360, grad/param norm = 1.6839e-01, time/batch = 0.6972s	
5061/28500 (epoch 8.879), train_loss = 1.28850705, grad/param norm = 1.6648e-01, time/batch = 0.6987s	
5062/28500 (epoch 8.881), train_loss = 1.36016087, grad/param norm = 1.6056e-01, time/batch = 0.6976s	
5063/28500 (epoch 8.882), train_loss = 1.25371333, grad/param norm = 1.5679e-01, time/batch = 0.6984s	
5064/28500 (epoch 8.884), train_loss = 1.33781076, grad/param norm = 1.7463e-01, time/batch = 0.6970s	
5065/28500 (epoch 8.886), train_loss = 1.19655367, grad/param norm = 1.4607e-01, time/batch = 0.6970s	
5066/28500 (epoch 8.888), train_loss = 1.16455185, grad/param norm = 1.5870e-01, time/batch = 0.6998s	
5067/28500 (epoch 8.889), train_loss = 1.26192609, grad/param norm = 1.4794e-01, time/batch = 0.6969s	
5068/28500 (epoch 8.891), train_loss = 1.32103201, grad/param norm = 1.6130e-01, time/batch = 0.6956s	
5069/28500 (epoch 8.893), train_loss = 1.25659262, grad/param norm = 1.8690e-01, time/batch = 0.6966s	
5070/28500 (epoch 8.895), train_loss = 1.49945088, grad/param norm = 1.9280e-01, time/batch = 0.6965s	
5071/28500 (epoch 8.896), train_loss = 1.38653006, grad/param norm = 1.7160e-01, time/batch = 0.6998s	
5072/28500 (epoch 8.898), train_loss = 1.26667746, grad/param norm = 1.6368e-01, time/batch = 0.6991s	
5073/28500 (epoch 8.900), train_loss = 1.17332661, grad/param norm = 1.6106e-01, time/batch = 0.6963s	
5074/28500 (epoch 8.902), train_loss = 1.16872390, grad/param norm = 1.4875e-01, time/batch = 0.6976s	
5075/28500 (epoch 8.904), train_loss = 1.17480685, grad/param norm = 1.5533e-01, time/batch = 0.6965s	
5076/28500 (epoch 8.905), train_loss = 1.33531734, grad/param norm = 1.6922e-01, time/batch = 0.6961s	
5077/28500 (epoch 8.907), train_loss = 1.36101554, grad/param norm = 1.7861e-01, time/batch = 0.6979s	
5078/28500 (epoch 8.909), train_loss = 1.18291927, grad/param norm = 1.8892e-01, time/batch = 0.6969s	
5079/28500 (epoch 8.911), train_loss = 1.20017787, grad/param norm = 1.5798e-01, time/batch = 0.6960s	
5080/28500 (epoch 8.912), train_loss = 1.01030820, grad/param norm = 1.5098e-01, time/batch = 0.6965s	
5081/28500 (epoch 8.914), train_loss = 1.42076013, grad/param norm = 1.6245e-01, time/batch = 0.6983s	
5082/28500 (epoch 8.916), train_loss = 1.35709362, grad/param norm = 1.7875e-01, time/batch = 0.6977s	
5083/28500 (epoch 8.918), train_loss = 1.28786568, grad/param norm = 1.7890e-01, time/batch = 0.6956s	
5084/28500 (epoch 8.919), train_loss = 1.24310986, grad/param norm = 1.5193e-01, time/batch = 0.6965s	
5085/28500 (epoch 8.921), train_loss = 1.49193819, grad/param norm = 2.0760e-01, time/batch = 0.6995s	
5086/28500 (epoch 8.923), train_loss = 1.33554592, grad/param norm = 1.8889e-01, time/batch = 0.7001s	
5087/28500 (epoch 8.925), train_loss = 1.17944426, grad/param norm = 1.6860e-01, time/batch = 0.6967s	
5088/28500 (epoch 8.926), train_loss = 1.28628812, grad/param norm = 1.6440e-01, time/batch = 0.6953s	
5089/28500 (epoch 8.928), train_loss = 1.21678684, grad/param norm = 1.4987e-01, time/batch = 0.6987s	
5090/28500 (epoch 8.930), train_loss = 1.00453478, grad/param norm = 1.5583e-01, time/batch = 0.6977s	
5091/28500 (epoch 8.932), train_loss = 1.09309868, grad/param norm = 1.4185e-01, time/batch = 0.6984s	
5092/28500 (epoch 8.933), train_loss = 1.30610856, grad/param norm = 1.5612e-01, time/batch = 0.6969s	
5093/28500 (epoch 8.935), train_loss = 1.36153116, grad/param norm = 1.7756e-01, time/batch = 0.6964s	
5094/28500 (epoch 8.937), train_loss = 1.42786727, grad/param norm = 1.8986e-01, time/batch = 0.6965s	
5095/28500 (epoch 8.939), train_loss = 1.50118776, grad/param norm = 1.8249e-01, time/batch = 0.6974s	
5096/28500 (epoch 8.940), train_loss = 1.19759331, grad/param norm = 1.6201e-01, time/batch = 0.6990s	
5097/28500 (epoch 8.942), train_loss = 1.38767832, grad/param norm = 1.6216e-01, time/batch = 0.6961s	
5098/28500 (epoch 8.944), train_loss = 1.30704450, grad/param norm = 1.6790e-01, time/batch = 0.6950s	
5099/28500 (epoch 8.946), train_loss = 1.44209298, grad/param norm = 1.6306e-01, time/batch = 0.6957s	
5100/28500 (epoch 8.947), train_loss = 1.66422719, grad/param norm = 1.9086e-01, time/batch = 0.6956s	
5101/28500 (epoch 8.949), train_loss = 1.17539505, grad/param norm = 1.6208e-01, time/batch = 0.6985s	
5102/28500 (epoch 8.951), train_loss = 1.47088568, grad/param norm = 1.9608e-01, time/batch = 0.6983s	
5103/28500 (epoch 8.953), train_loss = 1.53109091, grad/param norm = 1.9246e-01, time/batch = 0.6970s	
5104/28500 (epoch 8.954), train_loss = 1.42826637, grad/param norm = 1.7110e-01, time/batch = 0.6988s	
5105/28500 (epoch 8.956), train_loss = 1.38643726, grad/param norm = 1.9147e-01, time/batch = 0.6974s	
5106/28500 (epoch 8.958), train_loss = 1.44383515, grad/param norm = 1.6308e-01, time/batch = 0.6964s	
5107/28500 (epoch 8.960), train_loss = 1.20596053, grad/param norm = 1.7066e-01, time/batch = 0.6991s	
5108/28500 (epoch 8.961), train_loss = 1.53996534, grad/param norm = 1.8833e-01, time/batch = 0.7162s	
5109/28500 (epoch 8.963), train_loss = 1.39086437, grad/param norm = 1.5196e-01, time/batch = 0.7045s	
5110/28500 (epoch 8.965), train_loss = 1.18036503, grad/param norm = 1.5139e-01, time/batch = 0.6986s	
5111/28500 (epoch 8.967), train_loss = 1.15929052, grad/param norm = 1.5204e-01, time/batch = 0.7019s	
5112/28500 (epoch 8.968), train_loss = 1.11040760, grad/param norm = 1.4688e-01, time/batch = 0.6981s	
5113/28500 (epoch 8.970), train_loss = 1.28132997, grad/param norm = 1.5870e-01, time/batch = 0.7016s	
5114/28500 (epoch 8.972), train_loss = 1.42109973, grad/param norm = 1.9210e-01, time/batch = 0.6981s	
5115/28500 (epoch 8.974), train_loss = 1.56535867, grad/param norm = 1.8066e-01, time/batch = 0.7038s	
5116/28500 (epoch 8.975), train_loss = 1.26879051, grad/param norm = 1.7380e-01, time/batch = 0.6963s	
5117/28500 (epoch 8.977), train_loss = 1.51015123, grad/param norm = 1.7672e-01, time/batch = 0.6968s	
5118/28500 (epoch 8.979), train_loss = 1.22697286, grad/param norm = 1.6098e-01, time/batch = 0.7011s	
5119/28500 (epoch 8.981), train_loss = 1.24092414, grad/param norm = 1.6975e-01, time/batch = 0.6980s	
5120/28500 (epoch 8.982), train_loss = 1.17339906, grad/param norm = 1.4309e-01, time/batch = 0.6961s	
5121/28500 (epoch 8.984), train_loss = 1.37070528, grad/param norm = 1.6660e-01, time/batch = 0.6972s	
5122/28500 (epoch 8.986), train_loss = 1.51513181, grad/param norm = 1.8242e-01, time/batch = 0.6971s	
5123/28500 (epoch 8.988), train_loss = 1.11015476, grad/param norm = 1.5968e-01, time/batch = 0.6969s	
5124/28500 (epoch 8.989), train_loss = 1.35745574, grad/param norm = 1.8392e-01, time/batch = 0.6968s	
5125/28500 (epoch 8.991), train_loss = 1.20765074, grad/param norm = 1.6136e-01, time/batch = 0.6967s	
5126/28500 (epoch 8.993), train_loss = 1.22119686, grad/param norm = 1.6108e-01, time/batch = 0.6960s	
5127/28500 (epoch 8.995), train_loss = 1.22527218, grad/param norm = 1.6183e-01, time/batch = 0.6968s	
5128/28500 (epoch 8.996), train_loss = 1.17225467, grad/param norm = 1.5621e-01, time/batch = 0.6988s	
5129/28500 (epoch 8.998), train_loss = 1.42812898, grad/param norm = 1.7925e-01, time/batch = 0.6954s	
5130/28500 (epoch 9.000), train_loss = 1.21529130, grad/param norm = 1.4616e-01, time/batch = 0.6963s	
5131/28500 (epoch 9.002), train_loss = 1.45229776, grad/param norm = 1.7747e-01, time/batch = 0.6981s	
5132/28500 (epoch 9.004), train_loss = 1.24822595, grad/param norm = 1.6576e-01, time/batch = 0.6971s	
5133/28500 (epoch 9.005), train_loss = 1.38196026, grad/param norm = 1.6626e-01, time/batch = 0.6967s	
5134/28500 (epoch 9.007), train_loss = 1.13365335, grad/param norm = 1.4295e-01, time/batch = 0.6971s	
5135/28500 (epoch 9.009), train_loss = 1.39470606, grad/param norm = 1.6954e-01, time/batch = 0.7024s	
5136/28500 (epoch 9.011), train_loss = 1.27765393, grad/param norm = 1.8567e-01, time/batch = 0.6992s	
5137/28500 (epoch 9.012), train_loss = 1.11355588, grad/param norm = 1.4461e-01, time/batch = 0.7062s	
5138/28500 (epoch 9.014), train_loss = 1.16953810, grad/param norm = 1.5204e-01, time/batch = 0.7147s	
5139/28500 (epoch 9.016), train_loss = 1.23964904, grad/param norm = 1.4705e-01, time/batch = 0.6996s	
5140/28500 (epoch 9.018), train_loss = 1.33979775, grad/param norm = 1.6819e-01, time/batch = 0.6860s	
5141/28500 (epoch 9.019), train_loss = 1.39127403, grad/param norm = 1.7903e-01, time/batch = 0.7071s	
5142/28500 (epoch 9.021), train_loss = 1.32431633, grad/param norm = 1.5322e-01, time/batch = 0.7055s	
5143/28500 (epoch 9.023), train_loss = 1.25150044, grad/param norm = 1.5743e-01, time/batch = 0.7211s	
5144/28500 (epoch 9.025), train_loss = 1.27491187, grad/param norm = 1.6140e-01, time/batch = 0.7031s	
5145/28500 (epoch 9.026), train_loss = 1.34301620, grad/param norm = 1.6865e-01, time/batch = 0.7030s	
5146/28500 (epoch 9.028), train_loss = 1.36782974, grad/param norm = 1.6476e-01, time/batch = 0.7031s	
5147/28500 (epoch 9.030), train_loss = 1.39276453, grad/param norm = 1.8645e-01, time/batch = 0.7144s	
5148/28500 (epoch 9.032), train_loss = 1.39622792, grad/param norm = 1.7567e-01, time/batch = 0.7124s	
5149/28500 (epoch 9.033), train_loss = 1.47841468, grad/param norm = 1.7133e-01, time/batch = 0.7101s	
5150/28500 (epoch 9.035), train_loss = 1.34731019, grad/param norm = 1.7061e-01, time/batch = 0.7009s	
5151/28500 (epoch 9.037), train_loss = 1.38361867, grad/param norm = 1.6348e-01, time/batch = 0.7002s	
5152/28500 (epoch 9.039), train_loss = 1.46487549, grad/param norm = 1.7842e-01, time/batch = 0.7161s	
5153/28500 (epoch 9.040), train_loss = 1.46392938, grad/param norm = 1.7141e-01, time/batch = 0.6972s	
5154/28500 (epoch 9.042), train_loss = 1.38076557, grad/param norm = 1.7287e-01, time/batch = 0.6937s	
5155/28500 (epoch 9.044), train_loss = 1.30272739, grad/param norm = 1.7819e-01, time/batch = 0.6942s	
5156/28500 (epoch 9.046), train_loss = 1.51357499, grad/param norm = 1.7485e-01, time/batch = 0.6935s	
5157/28500 (epoch 9.047), train_loss = 1.41595775, grad/param norm = 1.6992e-01, time/batch = 0.6929s	
5158/28500 (epoch 9.049), train_loss = 1.33547022, grad/param norm = 1.7680e-01, time/batch = 0.6935s	
5159/28500 (epoch 9.051), train_loss = 1.26779705, grad/param norm = 1.5752e-01, time/batch = 0.6930s	
5160/28500 (epoch 9.053), train_loss = 1.35775551, grad/param norm = 1.6118e-01, time/batch = 0.6924s	
5161/28500 (epoch 9.054), train_loss = 1.41183445, grad/param norm = 1.7540e-01, time/batch = 0.6944s	
5162/28500 (epoch 9.056), train_loss = 1.16129315, grad/param norm = 1.6066e-01, time/batch = 0.6926s	
5163/28500 (epoch 9.058), train_loss = 1.19594832, grad/param norm = 1.7039e-01, time/batch = 0.6956s	
5164/28500 (epoch 9.060), train_loss = 1.38553358, grad/param norm = 1.7697e-01, time/batch = 0.6916s	
5165/28500 (epoch 9.061), train_loss = 1.38768502, grad/param norm = 1.9309e-01, time/batch = 0.6925s	
5166/28500 (epoch 9.063), train_loss = 1.39390832, grad/param norm = 1.6546e-01, time/batch = 0.7020s	
5167/28500 (epoch 9.065), train_loss = 1.46576589, grad/param norm = 1.6912e-01, time/batch = 0.7031s	
5168/28500 (epoch 9.067), train_loss = 1.20920369, grad/param norm = 1.4544e-01, time/batch = 0.6925s	
5169/28500 (epoch 9.068), train_loss = 1.26284778, grad/param norm = 1.6130e-01, time/batch = 0.6940s	
5170/28500 (epoch 9.070), train_loss = 1.36481050, grad/param norm = 1.7782e-01, time/batch = 0.6917s	
5171/28500 (epoch 9.072), train_loss = 1.50974071, grad/param norm = 1.7473e-01, time/batch = 0.6948s	
5172/28500 (epoch 9.074), train_loss = 1.34768059, grad/param norm = 1.6815e-01, time/batch = 0.6931s	
5173/28500 (epoch 9.075), train_loss = 1.29126305, grad/param norm = 1.4629e-01, time/batch = 0.6930s	
5174/28500 (epoch 9.077), train_loss = 1.34589024, grad/param norm = 1.6846e-01, time/batch = 0.6924s	
5175/28500 (epoch 9.079), train_loss = 1.30853193, grad/param norm = 1.5207e-01, time/batch = 0.7092s	
5176/28500 (epoch 9.081), train_loss = 1.43300137, grad/param norm = 1.8252e-01, time/batch = 0.6926s	
5177/28500 (epoch 9.082), train_loss = 1.36216635, grad/param norm = 1.8000e-01, time/batch = 0.6922s	
5178/28500 (epoch 9.084), train_loss = 1.38119087, grad/param norm = 1.7382e-01, time/batch = 0.6912s	
5179/28500 (epoch 9.086), train_loss = 1.27638077, grad/param norm = 1.7469e-01, time/batch = 0.6920s	
5180/28500 (epoch 9.088), train_loss = 1.19978260, grad/param norm = 1.7137e-01, time/batch = 0.6966s	
5181/28500 (epoch 9.089), train_loss = 1.44769980, grad/param norm = 1.5090e-01, time/batch = 0.6964s	
5182/28500 (epoch 9.091), train_loss = 1.15752925, grad/param norm = 1.5219e-01, time/batch = 0.7244s	
5183/28500 (epoch 9.093), train_loss = 1.35457742, grad/param norm = 1.6698e-01, time/batch = 0.7107s	
5184/28500 (epoch 9.095), train_loss = 1.22859348, grad/param norm = 1.5260e-01, time/batch = 0.6968s	
5185/28500 (epoch 9.096), train_loss = 1.45613650, grad/param norm = 1.7170e-01, time/batch = 0.6924s	
5186/28500 (epoch 9.098), train_loss = 1.45189343, grad/param norm = 1.7771e-01, time/batch = 0.6907s	
5187/28500 (epoch 9.100), train_loss = 1.24605324, grad/param norm = 1.5950e-01, time/batch = 0.6896s	
5188/28500 (epoch 9.102), train_loss = 1.48308886, grad/param norm = 1.7063e-01, time/batch = 0.6898s	
5189/28500 (epoch 9.104), train_loss = 1.29009929, grad/param norm = 1.6703e-01, time/batch = 0.7042s	
5190/28500 (epoch 9.105), train_loss = 1.37016584, grad/param norm = 1.6537e-01, time/batch = 0.7053s	
5191/28500 (epoch 9.107), train_loss = 1.20719480, grad/param norm = 1.6133e-01, time/batch = 0.7003s	
5192/28500 (epoch 9.109), train_loss = 1.19608027, grad/param norm = 1.6569e-01, time/batch = 0.6967s	
5193/28500 (epoch 9.111), train_loss = 1.24969952, grad/param norm = 1.6104e-01, time/batch = 0.6932s	
5194/28500 (epoch 9.112), train_loss = 1.40405197, grad/param norm = 1.7629e-01, time/batch = 0.6934s	
5195/28500 (epoch 9.114), train_loss = 1.29918834, grad/param norm = 1.6381e-01, time/batch = 0.6947s	
5196/28500 (epoch 9.116), train_loss = 1.47955609, grad/param norm = 1.7242e-01, time/batch = 0.6986s	
5197/28500 (epoch 9.118), train_loss = 1.18285127, grad/param norm = 1.6595e-01, time/batch = 0.6928s	
5198/28500 (epoch 9.119), train_loss = 1.38511788, grad/param norm = 1.8107e-01, time/batch = 0.6945s	
5199/28500 (epoch 9.121), train_loss = 1.53878077, grad/param norm = 1.9525e-01, time/batch = 0.6965s	
5200/28500 (epoch 9.123), train_loss = 1.35928045, grad/param norm = 1.8309e-01, time/batch = 0.6938s	
5201/28500 (epoch 9.125), train_loss = 1.34002432, grad/param norm = 1.6804e-01, time/batch = 0.6958s	
5202/28500 (epoch 9.126), train_loss = 1.31070935, grad/param norm = 1.5773e-01, time/batch = 0.6941s	
5203/28500 (epoch 9.128), train_loss = 1.22660131, grad/param norm = 1.5574e-01, time/batch = 0.6948s	
5204/28500 (epoch 9.130), train_loss = 1.21383468, grad/param norm = 1.6639e-01, time/batch = 0.6948s	
5205/28500 (epoch 9.132), train_loss = 1.39543525, grad/param norm = 1.7492e-01, time/batch = 0.6953s	
5206/28500 (epoch 9.133), train_loss = 1.31808451, grad/param norm = 1.6280e-01, time/batch = 0.6930s	
5207/28500 (epoch 9.135), train_loss = 1.30200491, grad/param norm = 1.5533e-01, time/batch = 0.6951s	
5208/28500 (epoch 9.137), train_loss = 1.27238826, grad/param norm = 1.6873e-01, time/batch = 0.6929s	
5209/28500 (epoch 9.139), train_loss = 1.28689547, grad/param norm = 1.5460e-01, time/batch = 0.6938s	
5210/28500 (epoch 9.140), train_loss = 1.35164952, grad/param norm = 1.6314e-01, time/batch = 0.6951s	
5211/28500 (epoch 9.142), train_loss = 1.34596230, grad/param norm = 1.6978e-01, time/batch = 0.6979s	
5212/28500 (epoch 9.144), train_loss = 1.19070541, grad/param norm = 1.4902e-01, time/batch = 0.6885s	
5213/28500 (epoch 9.146), train_loss = 1.21969394, grad/param norm = 1.5857e-01, time/batch = 0.6852s	
5214/28500 (epoch 9.147), train_loss = 1.14379763, grad/param norm = 1.5740e-01, time/batch = 0.6871s	
5215/28500 (epoch 9.149), train_loss = 1.15595432, grad/param norm = 1.4624e-01, time/batch = 0.7096s	
5216/28500 (epoch 9.151), train_loss = 1.14237706, grad/param norm = 1.4909e-01, time/batch = 0.6944s	
5217/28500 (epoch 9.153), train_loss = 1.29959458, grad/param norm = 1.6067e-01, time/batch = 0.6956s	
5218/28500 (epoch 9.154), train_loss = 1.20802903, grad/param norm = 1.6808e-01, time/batch = 0.7029s	
5219/28500 (epoch 9.156), train_loss = 1.46436869, grad/param norm = 1.7390e-01, time/batch = 0.6963s	
5220/28500 (epoch 9.158), train_loss = 1.26354874, grad/param norm = 1.4861e-01, time/batch = 0.6825s	
5221/28500 (epoch 9.160), train_loss = 1.19039383, grad/param norm = 1.5892e-01, time/batch = 0.6830s	
5222/28500 (epoch 9.161), train_loss = 1.32887503, grad/param norm = 1.6495e-01, time/batch = 0.6897s	
5223/28500 (epoch 9.163), train_loss = 1.18868568, grad/param norm = 1.7168e-01, time/batch = 0.6880s	
5224/28500 (epoch 9.165), train_loss = 1.49483100, grad/param norm = 1.6146e-01, time/batch = 0.7006s	
5225/28500 (epoch 9.167), train_loss = 1.59103356, grad/param norm = 1.8504e-01, time/batch = 0.6879s	
5226/28500 (epoch 9.168), train_loss = 1.41712578, grad/param norm = 1.8925e-01, time/batch = 0.6784s	
5227/28500 (epoch 9.170), train_loss = 1.43251598, grad/param norm = 1.8805e-01, time/batch = 0.6779s	
5228/28500 (epoch 9.172), train_loss = 1.29679142, grad/param norm = 1.7538e-01, time/batch = 0.6785s	
5229/28500 (epoch 9.174), train_loss = 1.51347129, grad/param norm = 1.9226e-01, time/batch = 0.6776s	
5230/28500 (epoch 9.175), train_loss = 1.25962706, grad/param norm = 1.5769e-01, time/batch = 0.6811s	
5231/28500 (epoch 9.177), train_loss = 1.38509485, grad/param norm = 1.6777e-01, time/batch = 0.6829s	
5232/28500 (epoch 9.179), train_loss = 1.28966467, grad/param norm = 1.7632e-01, time/batch = 0.6818s	
5233/28500 (epoch 9.181), train_loss = 1.34272147, grad/param norm = 1.5147e-01, time/batch = 0.6793s	
5234/28500 (epoch 9.182), train_loss = 1.32184751, grad/param norm = 1.7140e-01, time/batch = 0.6791s	
5235/28500 (epoch 9.184), train_loss = 1.54532629, grad/param norm = 1.8189e-01, time/batch = 0.6818s	
5236/28500 (epoch 9.186), train_loss = 1.43947438, grad/param norm = 1.7738e-01, time/batch = 0.6807s	
5237/28500 (epoch 9.188), train_loss = 1.30150026, grad/param norm = 1.5265e-01, time/batch = 0.6815s	
5238/28500 (epoch 9.189), train_loss = 1.35100344, grad/param norm = 1.6775e-01, time/batch = 0.6852s	
5239/28500 (epoch 9.191), train_loss = 1.55380251, grad/param norm = 1.7763e-01, time/batch = 0.6794s	
5240/28500 (epoch 9.193), train_loss = 1.43570282, grad/param norm = 1.9144e-01, time/batch = 0.6782s	
5241/28500 (epoch 9.195), train_loss = 1.44691073, grad/param norm = 1.8192e-01, time/batch = 0.6807s	
5242/28500 (epoch 9.196), train_loss = 1.38986580, grad/param norm = 1.7080e-01, time/batch = 0.6803s	
5243/28500 (epoch 9.198), train_loss = 1.35963446, grad/param norm = 1.8329e-01, time/batch = 0.6835s	
5244/28500 (epoch 9.200), train_loss = 1.29461637, grad/param norm = 1.4695e-01, time/batch = 0.6800s	
5245/28500 (epoch 9.202), train_loss = 1.32587142, grad/param norm = 1.6883e-01, time/batch = 0.6809s	
5246/28500 (epoch 9.204), train_loss = 1.19818109, grad/param norm = 1.5599e-01, time/batch = 0.6827s	
5247/28500 (epoch 9.205), train_loss = 1.25883422, grad/param norm = 1.5591e-01, time/batch = 0.6855s	
5248/28500 (epoch 9.207), train_loss = 1.28753333, grad/param norm = 1.6337e-01, time/batch = 0.6774s	
5249/28500 (epoch 9.209), train_loss = 1.31404240, grad/param norm = 1.6903e-01, time/batch = 0.6772s	
5250/28500 (epoch 9.211), train_loss = 1.16181548, grad/param norm = 1.5963e-01, time/batch = 0.6812s	
5251/28500 (epoch 9.212), train_loss = 1.17706287, grad/param norm = 1.6069e-01, time/batch = 0.6812s	
5252/28500 (epoch 9.214), train_loss = 1.35216874, grad/param norm = 1.8138e-01, time/batch = 0.6828s	
5253/28500 (epoch 9.216), train_loss = 1.17679204, grad/param norm = 1.5156e-01, time/batch = 0.6780s	
5254/28500 (epoch 9.218), train_loss = 1.41204656, grad/param norm = 1.5811e-01, time/batch = 0.6776s	
5255/28500 (epoch 9.219), train_loss = 1.36423088, grad/param norm = 1.7293e-01, time/batch = 0.6774s	
5256/28500 (epoch 9.221), train_loss = 1.21114063, grad/param norm = 1.6715e-01, time/batch = 0.6776s	
5257/28500 (epoch 9.223), train_loss = 1.43587741, grad/param norm = 1.8321e-01, time/batch = 0.6771s	
5258/28500 (epoch 9.225), train_loss = 1.46921483, grad/param norm = 1.6684e-01, time/batch = 0.6775s	
5259/28500 (epoch 9.226), train_loss = 1.28706530, grad/param norm = 1.6508e-01, time/batch = 0.6775s	
5260/28500 (epoch 9.228), train_loss = 1.37630024, grad/param norm = 1.6172e-01, time/batch = 0.6771s	
5261/28500 (epoch 9.230), train_loss = 1.40528285, grad/param norm = 1.6635e-01, time/batch = 0.6791s	
5262/28500 (epoch 9.232), train_loss = 1.36535620, grad/param norm = 1.7220e-01, time/batch = 0.6788s	
5263/28500 (epoch 9.233), train_loss = 1.36293966, grad/param norm = 1.7550e-01, time/batch = 0.6775s	
5264/28500 (epoch 9.235), train_loss = 1.26022315, grad/param norm = 1.5846e-01, time/batch = 0.6777s	
5265/28500 (epoch 9.237), train_loss = 1.14305868, grad/param norm = 1.4139e-01, time/batch = 0.6773s	
5266/28500 (epoch 9.239), train_loss = 1.21721870, grad/param norm = 1.5599e-01, time/batch = 0.6817s	
5267/28500 (epoch 9.240), train_loss = 1.16336376, grad/param norm = 1.5989e-01, time/batch = 0.6843s	
5268/28500 (epoch 9.242), train_loss = 1.36613379, grad/param norm = 1.8245e-01, time/batch = 0.6805s	
5269/28500 (epoch 9.244), train_loss = 1.37110499, grad/param norm = 1.6563e-01, time/batch = 0.6810s	
5270/28500 (epoch 9.246), train_loss = 1.41848059, grad/param norm = 1.7005e-01, time/batch = 0.6794s	
5271/28500 (epoch 9.247), train_loss = 1.52151003, grad/param norm = 1.7474e-01, time/batch = 0.6822s	
5272/28500 (epoch 9.249), train_loss = 1.35881740, grad/param norm = 1.7367e-01, time/batch = 0.6829s	
5273/28500 (epoch 9.251), train_loss = 1.19175523, grad/param norm = 1.5156e-01, time/batch = 0.6786s	
5274/28500 (epoch 9.253), train_loss = 1.50189600, grad/param norm = 1.8029e-01, time/batch = 0.6782s	
5275/28500 (epoch 9.254), train_loss = 1.46923770, grad/param norm = 1.8008e-01, time/batch = 0.6789s	
5276/28500 (epoch 9.256), train_loss = 1.23779768, grad/param norm = 1.4932e-01, time/batch = 0.6810s	
5277/28500 (epoch 9.258), train_loss = 1.29067294, grad/param norm = 1.6801e-01, time/batch = 0.6790s	
5278/28500 (epoch 9.260), train_loss = 1.24961327, grad/param norm = 1.5501e-01, time/batch = 0.6806s	
5279/28500 (epoch 9.261), train_loss = 1.24611965, grad/param norm = 1.6971e-01, time/batch = 0.7060s	
5280/28500 (epoch 9.263), train_loss = 1.47260383, grad/param norm = 1.8421e-01, time/batch = 0.6813s	
5281/28500 (epoch 9.265), train_loss = 1.34477493, grad/param norm = 1.7918e-01, time/batch = 0.6824s	
5282/28500 (epoch 9.267), train_loss = 1.48059908, grad/param norm = 1.7680e-01, time/batch = 0.6839s	
5283/28500 (epoch 9.268), train_loss = 1.40173853, grad/param norm = 1.5672e-01, time/batch = 0.6814s	
5284/28500 (epoch 9.270), train_loss = 1.34603627, grad/param norm = 1.7854e-01, time/batch = 0.6827s	
5285/28500 (epoch 9.272), train_loss = 1.29229250, grad/param norm = 1.6913e-01, time/batch = 0.6801s	
5286/28500 (epoch 9.274), train_loss = 1.46361745, grad/param norm = 1.8142e-01, time/batch = 0.6932s	
5287/28500 (epoch 9.275), train_loss = 1.38138315, grad/param norm = 1.6126e-01, time/batch = 0.6818s	
5288/28500 (epoch 9.277), train_loss = 1.32063317, grad/param norm = 1.6533e-01, time/batch = 0.6815s	
5289/28500 (epoch 9.279), train_loss = 1.36661922, grad/param norm = 1.7743e-01, time/batch = 0.6880s	
5290/28500 (epoch 9.281), train_loss = 1.38042722, grad/param norm = 1.6746e-01, time/batch = 0.6927s	
5291/28500 (epoch 9.282), train_loss = 1.20345496, grad/param norm = 1.4735e-01, time/batch = 0.6843s	
5292/28500 (epoch 9.284), train_loss = 1.36818292, grad/param norm = 1.6619e-01, time/batch = 0.6831s	
5293/28500 (epoch 9.286), train_loss = 1.43169801, grad/param norm = 1.6546e-01, time/batch = 0.6817s	
5294/28500 (epoch 9.288), train_loss = 1.34496354, grad/param norm = 1.5581e-01, time/batch = 0.6824s	
5295/28500 (epoch 9.289), train_loss = 1.47881093, grad/param norm = 1.7431e-01, time/batch = 0.6838s	
5296/28500 (epoch 9.291), train_loss = 1.30656567, grad/param norm = 1.6287e-01, time/batch = 0.6854s	
5297/28500 (epoch 9.293), train_loss = 1.26932366, grad/param norm = 1.6781e-01, time/batch = 0.6816s	
5298/28500 (epoch 9.295), train_loss = 1.21244353, grad/param norm = 1.5865e-01, time/batch = 0.6814s	
5299/28500 (epoch 9.296), train_loss = 1.21213401, grad/param norm = 1.5631e-01, time/batch = 0.6795s	
5300/28500 (epoch 9.298), train_loss = 1.33356351, grad/param norm = 1.6663e-01, time/batch = 0.6813s	
5301/28500 (epoch 9.300), train_loss = 1.24407125, grad/param norm = 1.6296e-01, time/batch = 0.6828s	
5302/28500 (epoch 9.302), train_loss = 1.21093689, grad/param norm = 1.6041e-01, time/batch = 0.6823s	
5303/28500 (epoch 9.304), train_loss = 1.30515531, grad/param norm = 1.5362e-01, time/batch = 0.6825s	
5304/28500 (epoch 9.305), train_loss = 1.38384714, grad/param norm = 1.6223e-01, time/batch = 0.6803s	
5305/28500 (epoch 9.307), train_loss = 1.36698858, grad/param norm = 1.8196e-01, time/batch = 0.6814s	
5306/28500 (epoch 9.309), train_loss = 1.34337221, grad/param norm = 1.8127e-01, time/batch = 0.6811s	
5307/28500 (epoch 9.311), train_loss = 1.33281099, grad/param norm = 1.7280e-01, time/batch = 0.6810s	
5308/28500 (epoch 9.312), train_loss = 1.25147298, grad/param norm = 1.6059e-01, time/batch = 0.6820s	
5309/28500 (epoch 9.314), train_loss = 1.40638410, grad/param norm = 1.7489e-01, time/batch = 0.6799s	
5310/28500 (epoch 9.316), train_loss = 1.37039889, grad/param norm = 1.5037e-01, time/batch = 0.6794s	
5311/28500 (epoch 9.318), train_loss = 1.38089514, grad/param norm = 1.7985e-01, time/batch = 0.6906s	
5312/28500 (epoch 9.319), train_loss = 1.31107159, grad/param norm = 1.6891e-01, time/batch = 0.7072s	
5313/28500 (epoch 9.321), train_loss = 1.37507344, grad/param norm = 1.8413e-01, time/batch = 0.6784s	
5314/28500 (epoch 9.323), train_loss = 1.29343087, grad/param norm = 1.7763e-01, time/batch = 0.6774s	
5315/28500 (epoch 9.325), train_loss = 1.48699891, grad/param norm = 1.6621e-01, time/batch = 0.6772s	
5316/28500 (epoch 9.326), train_loss = 1.35909925, grad/param norm = 1.7946e-01, time/batch = 0.6790s	
5317/28500 (epoch 9.328), train_loss = 1.09727545, grad/param norm = 1.5472e-01, time/batch = 0.6804s	
5318/28500 (epoch 9.330), train_loss = 1.21967643, grad/param norm = 1.6242e-01, time/batch = 0.6792s	
5319/28500 (epoch 9.332), train_loss = 1.29561099, grad/param norm = 1.5567e-01, time/batch = 0.6794s	
5320/28500 (epoch 9.333), train_loss = 1.14682301, grad/param norm = 1.5820e-01, time/batch = 0.6772s	
5321/28500 (epoch 9.335), train_loss = 1.19718919, grad/param norm = 1.4343e-01, time/batch = 0.6884s	
5322/28500 (epoch 9.337), train_loss = 1.28778587, grad/param norm = 1.7203e-01, time/batch = 0.6783s	
5323/28500 (epoch 9.339), train_loss = 1.19911933, grad/param norm = 1.5273e-01, time/batch = 0.6791s	
5324/28500 (epoch 9.340), train_loss = 1.39057372, grad/param norm = 1.7325e-01, time/batch = 0.6777s	
5325/28500 (epoch 9.342), train_loss = 1.29059101, grad/param norm = 1.7434e-01, time/batch = 0.6791s	
5326/28500 (epoch 9.344), train_loss = 1.24324090, grad/param norm = 1.6330e-01, time/batch = 0.6798s	
5327/28500 (epoch 9.346), train_loss = 1.03156594, grad/param norm = 1.3394e-01, time/batch = 0.6779s	
5328/28500 (epoch 9.347), train_loss = 1.29872350, grad/param norm = 1.6127e-01, time/batch = 0.6777s	
5329/28500 (epoch 9.349), train_loss = 1.22453564, grad/param norm = 1.5028e-01, time/batch = 0.6772s	
5330/28500 (epoch 9.351), train_loss = 1.20396637, grad/param norm = 1.5575e-01, time/batch = 0.6773s	
5331/28500 (epoch 9.353), train_loss = 1.37065214, grad/param norm = 1.7344e-01, time/batch = 0.6829s	
5332/28500 (epoch 9.354), train_loss = 1.16420119, grad/param norm = 1.5492e-01, time/batch = 0.6836s	
5333/28500 (epoch 9.356), train_loss = 1.21535570, grad/param norm = 1.4777e-01, time/batch = 0.6795s	
5334/28500 (epoch 9.358), train_loss = 1.30860076, grad/param norm = 1.4763e-01, time/batch = 0.6780s	
5335/28500 (epoch 9.360), train_loss = 1.33559063, grad/param norm = 1.7070e-01, time/batch = 0.6772s	
5336/28500 (epoch 9.361), train_loss = 1.22241480, grad/param norm = 1.5042e-01, time/batch = 0.6859s	
5337/28500 (epoch 9.363), train_loss = 1.18436301, grad/param norm = 1.4753e-01, time/batch = 0.6790s	
5338/28500 (epoch 9.365), train_loss = 1.24924202, grad/param norm = 1.5971e-01, time/batch = 0.6783s	
5339/28500 (epoch 9.367), train_loss = 1.28555946, grad/param norm = 1.5887e-01, time/batch = 0.6776s	
5340/28500 (epoch 9.368), train_loss = 1.24958373, grad/param norm = 1.5326e-01, time/batch = 0.6792s	
5341/28500 (epoch 9.370), train_loss = 1.32711476, grad/param norm = 1.5823e-01, time/batch = 0.6804s	
5342/28500 (epoch 9.372), train_loss = 1.14825004, grad/param norm = 1.6022e-01, time/batch = 0.6781s	
5343/28500 (epoch 9.374), train_loss = 1.30407954, grad/param norm = 1.5957e-01, time/batch = 0.6796s	
5344/28500 (epoch 9.375), train_loss = 1.44877545, grad/param norm = 1.7407e-01, time/batch = 0.6773s	
5345/28500 (epoch 9.377), train_loss = 1.23254894, grad/param norm = 1.6630e-01, time/batch = 0.6775s	
5346/28500 (epoch 9.379), train_loss = 1.05573900, grad/param norm = 1.4165e-01, time/batch = 0.6821s	
5347/28500 (epoch 9.381), train_loss = 1.24293047, grad/param norm = 1.4610e-01, time/batch = 0.6777s	
5348/28500 (epoch 9.382), train_loss = 1.21963423, grad/param norm = 1.5470e-01, time/batch = 0.6774s	
5349/28500 (epoch 9.384), train_loss = 1.15081631, grad/param norm = 1.4398e-01, time/batch = 0.6790s	
5350/28500 (epoch 9.386), train_loss = 1.18070864, grad/param norm = 1.7626e-01, time/batch = 0.6787s	
5351/28500 (epoch 9.388), train_loss = 1.39879007, grad/param norm = 1.6502e-01, time/batch = 0.6797s	
5352/28500 (epoch 9.389), train_loss = 1.20367855, grad/param norm = 1.5781e-01, time/batch = 0.6810s	
5353/28500 (epoch 9.391), train_loss = 1.21463155, grad/param norm = 1.6204e-01, time/batch = 0.6842s	
5354/28500 (epoch 9.393), train_loss = 1.12686320, grad/param norm = 1.5656e-01, time/batch = 0.6844s	
5355/28500 (epoch 9.395), train_loss = 1.49116019, grad/param norm = 1.8379e-01, time/batch = 0.6799s	
5356/28500 (epoch 9.396), train_loss = 1.39199987, grad/param norm = 1.7023e-01, time/batch = 0.6803s	
5357/28500 (epoch 9.398), train_loss = 1.11852876, grad/param norm = 2.1193e-01, time/batch = 0.6782s	
5358/28500 (epoch 9.400), train_loss = 1.33729468, grad/param norm = 1.9396e-01, time/batch = 0.6793s	
5359/28500 (epoch 9.402), train_loss = 1.28224308, grad/param norm = 1.5791e-01, time/batch = 0.6776s	
5360/28500 (epoch 9.404), train_loss = 1.41400353, grad/param norm = 1.9339e-01, time/batch = 0.6824s	
5361/28500 (epoch 9.405), train_loss = 1.39722217, grad/param norm = 1.6774e-01, time/batch = 0.6801s	
5362/28500 (epoch 9.407), train_loss = 1.33143655, grad/param norm = 1.6579e-01, time/batch = 0.6780s	
5363/28500 (epoch 9.409), train_loss = 1.33027247, grad/param norm = 1.7067e-01, time/batch = 0.6774s	
5364/28500 (epoch 9.411), train_loss = 1.38775318, grad/param norm = 1.6153e-01, time/batch = 0.6846s	
5365/28500 (epoch 9.412), train_loss = 1.50990971, grad/param norm = 1.9835e-01, time/batch = 0.6843s	
5366/28500 (epoch 9.414), train_loss = 1.34066143, grad/param norm = 1.7972e-01, time/batch = 0.6805s	
5367/28500 (epoch 9.416), train_loss = 1.26130530, grad/param norm = 1.8306e-01, time/batch = 0.6796s	
5368/28500 (epoch 9.418), train_loss = 1.32460360, grad/param norm = 1.5469e-01, time/batch = 0.6809s	
5369/28500 (epoch 9.419), train_loss = 1.44753418, grad/param norm = 1.7943e-01, time/batch = 0.6808s	
5370/28500 (epoch 9.421), train_loss = 1.38114407, grad/param norm = 1.6211e-01, time/batch = 0.6812s	
5371/28500 (epoch 9.423), train_loss = 1.46869768, grad/param norm = 1.7990e-01, time/batch = 0.6837s	
5372/28500 (epoch 9.425), train_loss = 1.36378816, grad/param norm = 1.8148e-01, time/batch = 0.6840s	
5373/28500 (epoch 9.426), train_loss = 1.32562690, grad/param norm = 1.7179e-01, time/batch = 0.6823s	
5374/28500 (epoch 9.428), train_loss = 1.54892151, grad/param norm = 1.7748e-01, time/batch = 0.6808s	
5375/28500 (epoch 9.430), train_loss = 1.43430438, grad/param norm = 1.6830e-01, time/batch = 0.6818s	
5376/28500 (epoch 9.432), train_loss = 1.36768904, grad/param norm = 1.6944e-01, time/batch = 0.6804s	
5377/28500 (epoch 9.433), train_loss = 1.41768225, grad/param norm = 1.8364e-01, time/batch = 0.6791s	
5378/28500 (epoch 9.435), train_loss = 1.30332783, grad/param norm = 1.6245e-01, time/batch = 0.6773s	
5379/28500 (epoch 9.437), train_loss = 1.15992111, grad/param norm = 1.3959e-01, time/batch = 0.6770s	
5380/28500 (epoch 9.439), train_loss = 1.21595595, grad/param norm = 1.4987e-01, time/batch = 0.6770s	
5381/28500 (epoch 9.440), train_loss = 1.46410478, grad/param norm = 1.7320e-01, time/batch = 0.6810s	
5382/28500 (epoch 9.442), train_loss = 1.20401429, grad/param norm = 1.6934e-01, time/batch = 0.6788s	
5383/28500 (epoch 9.444), train_loss = 1.15311794, grad/param norm = 1.4273e-01, time/batch = 0.6821s	
5384/28500 (epoch 9.446), train_loss = 1.09897365, grad/param norm = 1.5236e-01, time/batch = 0.6782s	
5385/28500 (epoch 9.447), train_loss = 1.15696852, grad/param norm = 1.5502e-01, time/batch = 0.6804s	
5386/28500 (epoch 9.449), train_loss = 1.20307304, grad/param norm = 1.5225e-01, time/batch = 0.6777s	
5387/28500 (epoch 9.451), train_loss = 1.25400012, grad/param norm = 1.6305e-01, time/batch = 0.6789s	
5388/28500 (epoch 9.453), train_loss = 1.31395543, grad/param norm = 1.8519e-01, time/batch = 0.6878s	
5389/28500 (epoch 9.454), train_loss = 1.22463458, grad/param norm = 1.5723e-01, time/batch = 0.6839s	
5390/28500 (epoch 9.456), train_loss = 1.35688314, grad/param norm = 1.5932e-01, time/batch = 0.6880s	
5391/28500 (epoch 9.458), train_loss = 1.24388811, grad/param norm = 1.6474e-01, time/batch = 0.6886s	
5392/28500 (epoch 9.460), train_loss = 1.38636780, grad/param norm = 1.6871e-01, time/batch = 0.6862s	
5393/28500 (epoch 9.461), train_loss = 1.24653071, grad/param norm = 1.6480e-01, time/batch = 0.6820s	
5394/28500 (epoch 9.463), train_loss = 1.17041381, grad/param norm = 1.4328e-01, time/batch = 0.6776s	
5395/28500 (epoch 9.465), train_loss = 1.14400956, grad/param norm = 1.7565e-01, time/batch = 0.6796s	
5396/28500 (epoch 9.467), train_loss = 1.34142555, grad/param norm = 1.6399e-01, time/batch = 0.6829s	
5397/28500 (epoch 9.468), train_loss = 1.12801275, grad/param norm = 1.3920e-01, time/batch = 0.6833s	
5398/28500 (epoch 9.470), train_loss = 1.26782256, grad/param norm = 1.7428e-01, time/batch = 0.6848s	
5399/28500 (epoch 9.472), train_loss = 1.21315615, grad/param norm = 1.5136e-01, time/batch = 0.7151s	
5400/28500 (epoch 9.474), train_loss = 1.57065600, grad/param norm = 1.9582e-01, time/batch = 0.6978s	
5401/28500 (epoch 9.475), train_loss = 1.19665602, grad/param norm = 1.4301e-01, time/batch = 0.7008s	
5402/28500 (epoch 9.477), train_loss = 1.28023849, grad/param norm = 1.6062e-01, time/batch = 0.6973s	
5403/28500 (epoch 9.479), train_loss = 1.33157164, grad/param norm = 1.6220e-01, time/batch = 0.6922s	
5404/28500 (epoch 9.481), train_loss = 1.27421483, grad/param norm = 1.6645e-01, time/batch = 0.6922s	
5405/28500 (epoch 9.482), train_loss = 1.18688305, grad/param norm = 1.6436e-01, time/batch = 0.7098s	
5406/28500 (epoch 9.484), train_loss = 1.18700399, grad/param norm = 1.5492e-01, time/batch = 0.7057s	
5407/28500 (epoch 9.486), train_loss = 1.12914565, grad/param norm = 1.6506e-01, time/batch = 0.6978s	
5408/28500 (epoch 9.488), train_loss = 1.31324985, grad/param norm = 1.6418e-01, time/batch = 0.6913s	
5409/28500 (epoch 9.489), train_loss = 1.39345359, grad/param norm = 1.6711e-01, time/batch = 0.6917s	
5410/28500 (epoch 9.491), train_loss = 1.23468384, grad/param norm = 1.6233e-01, time/batch = 0.6911s	
5411/28500 (epoch 9.493), train_loss = 1.20964486, grad/param norm = 1.5726e-01, time/batch = 0.6924s	
5412/28500 (epoch 9.495), train_loss = 1.20481025, grad/param norm = 1.5208e-01, time/batch = 0.6912s	
5413/28500 (epoch 9.496), train_loss = 1.27314144, grad/param norm = 1.6827e-01, time/batch = 0.6899s	
5414/28500 (epoch 9.498), train_loss = 1.35125594, grad/param norm = 1.6348e-01, time/batch = 0.6901s	
5415/28500 (epoch 9.500), train_loss = 1.27383117, grad/param norm = 1.6018e-01, time/batch = 0.6924s	
5416/28500 (epoch 9.502), train_loss = 1.37813476, grad/param norm = 1.5554e-01, time/batch = 0.6899s	
5417/28500 (epoch 9.504), train_loss = 1.34895963, grad/param norm = 1.5370e-01, time/batch = 0.6895s	
5418/28500 (epoch 9.505), train_loss = 1.19318737, grad/param norm = 1.4777e-01, time/batch = 0.6922s	
5419/28500 (epoch 9.507), train_loss = 1.41276670, grad/param norm = 1.7748e-01, time/batch = 0.6933s	
5420/28500 (epoch 9.509), train_loss = 1.30605106, grad/param norm = 1.6333e-01, time/batch = 0.6961s	
5421/28500 (epoch 9.511), train_loss = 1.28705486, grad/param norm = 1.6070e-01, time/batch = 0.6976s	
5422/28500 (epoch 9.512), train_loss = 1.30692508, grad/param norm = 1.6568e-01, time/batch = 0.6940s	
5423/28500 (epoch 9.514), train_loss = 1.16379327, grad/param norm = 1.4857e-01, time/batch = 0.6930s	
5424/28500 (epoch 9.516), train_loss = 1.19571608, grad/param norm = 1.4483e-01, time/batch = 0.6916s	
5425/28500 (epoch 9.518), train_loss = 1.24912285, grad/param norm = 1.3957e-01, time/batch = 0.6929s	
5426/28500 (epoch 9.519), train_loss = 1.33197202, grad/param norm = 1.5873e-01, time/batch = 0.6919s	
5427/28500 (epoch 9.521), train_loss = 1.44329151, grad/param norm = 1.6965e-01, time/batch = 0.6932s	
5428/28500 (epoch 9.523), train_loss = 1.34478426, grad/param norm = 1.7480e-01, time/batch = 0.6938s	
5429/28500 (epoch 9.525), train_loss = 1.40380653, grad/param norm = 1.7223e-01, time/batch = 0.6935s	
5430/28500 (epoch 9.526), train_loss = 1.34215158, grad/param norm = 1.6711e-01, time/batch = 0.6923s	
5431/28500 (epoch 9.528), train_loss = 1.41019632, grad/param norm = 1.7974e-01, time/batch = 0.6953s	
5432/28500 (epoch 9.530), train_loss = 1.40463662, grad/param norm = 1.5198e-01, time/batch = 0.6924s	
5433/28500 (epoch 9.532), train_loss = 1.25241787, grad/param norm = 1.7292e-01, time/batch = 0.6928s	
5434/28500 (epoch 9.533), train_loss = 1.41626151, grad/param norm = 1.6512e-01, time/batch = 0.6936s	
5435/28500 (epoch 9.535), train_loss = 1.11634045, grad/param norm = 1.5054e-01, time/batch = 0.6933s	
5436/28500 (epoch 9.537), train_loss = 1.12155066, grad/param norm = 1.5736e-01, time/batch = 0.6934s	
5437/28500 (epoch 9.539), train_loss = 1.16446860, grad/param norm = 1.5447e-01, time/batch = 0.6950s	
5438/28500 (epoch 9.540), train_loss = 1.26683142, grad/param norm = 1.5000e-01, time/batch = 0.6930s	
5439/28500 (epoch 9.542), train_loss = 1.47732220, grad/param norm = 1.8310e-01, time/batch = 0.6937s	
5440/28500 (epoch 9.544), train_loss = 1.46461161, grad/param norm = 1.6656e-01, time/batch = 0.6943s	
5441/28500 (epoch 9.546), train_loss = 1.31123604, grad/param norm = 1.6993e-01, time/batch = 0.6967s	
5442/28500 (epoch 9.547), train_loss = 1.28147808, grad/param norm = 1.4746e-01, time/batch = 0.6958s	
5443/28500 (epoch 9.549), train_loss = 1.11591520, grad/param norm = 1.3853e-01, time/batch = 0.6951s	
5444/28500 (epoch 9.551), train_loss = 1.40874643, grad/param norm = 1.7920e-01, time/batch = 0.6932s	
5445/28500 (epoch 9.553), train_loss = 1.52762946, grad/param norm = 1.8136e-01, time/batch = 0.6941s	
5446/28500 (epoch 9.554), train_loss = 1.23751997, grad/param norm = 1.5453e-01, time/batch = 0.6929s	
5447/28500 (epoch 9.556), train_loss = 1.31540014, grad/param norm = 1.6840e-01, time/batch = 0.6941s	
5448/28500 (epoch 9.558), train_loss = 1.34625378, grad/param norm = 1.7314e-01, time/batch = 0.6943s	
5449/28500 (epoch 9.560), train_loss = 1.33948706, grad/param norm = 1.6935e-01, time/batch = 0.6932s	
5450/28500 (epoch 9.561), train_loss = 1.38887352, grad/param norm = 1.8034e-01, time/batch = 0.6932s	
5451/28500 (epoch 9.563), train_loss = 1.43405919, grad/param norm = 1.7790e-01, time/batch = 0.6951s	
5452/28500 (epoch 9.565), train_loss = 1.27023126, grad/param norm = 1.6493e-01, time/batch = 0.6940s	
5453/28500 (epoch 9.567), train_loss = 1.14756232, grad/param norm = 1.7020e-01, time/batch = 0.6931s	
5454/28500 (epoch 9.568), train_loss = 1.34342774, grad/param norm = 1.7048e-01, time/batch = 0.6941s	
5455/28500 (epoch 9.570), train_loss = 1.23831881, grad/param norm = 1.7244e-01, time/batch = 0.6914s	
5456/28500 (epoch 9.572), train_loss = 1.24661389, grad/param norm = 1.5810e-01, time/batch = 0.6934s	
5457/28500 (epoch 9.574), train_loss = 1.30623394, grad/param norm = 1.6329e-01, time/batch = 0.6910s	
5458/28500 (epoch 9.575), train_loss = 1.23992171, grad/param norm = 1.6153e-01, time/batch = 0.7036s	
5459/28500 (epoch 9.577), train_loss = 1.26935837, grad/param norm = 1.5500e-01, time/batch = 0.7071s	
5460/28500 (epoch 9.579), train_loss = 1.39944884, grad/param norm = 1.7829e-01, time/batch = 0.6938s	
5461/28500 (epoch 9.581), train_loss = 1.26322585, grad/param norm = 1.7548e-01, time/batch = 0.7014s	
5462/28500 (epoch 9.582), train_loss = 1.38260815, grad/param norm = 1.6206e-01, time/batch = 0.6932s	
5463/28500 (epoch 9.584), train_loss = 1.23143340, grad/param norm = 1.4997e-01, time/batch = 0.6909s	
5464/28500 (epoch 9.586), train_loss = 1.17523874, grad/param norm = 1.4845e-01, time/batch = 0.6909s	
5465/28500 (epoch 9.588), train_loss = 1.18199606, grad/param norm = 1.4667e-01, time/batch = 0.6921s	
5466/28500 (epoch 9.589), train_loss = 1.40932854, grad/param norm = 1.6758e-01, time/batch = 0.6901s	
5467/28500 (epoch 9.591), train_loss = 1.34088919, grad/param norm = 1.5271e-01, time/batch = 0.6892s	
5468/28500 (epoch 9.593), train_loss = 1.21572857, grad/param norm = 1.5296e-01, time/batch = 0.6888s	
5469/28500 (epoch 9.595), train_loss = 1.54601356, grad/param norm = 1.9525e-01, time/batch = 0.6917s	
5470/28500 (epoch 9.596), train_loss = 1.51110948, grad/param norm = 1.8588e-01, time/batch = 0.6934s	
5471/28500 (epoch 9.598), train_loss = 1.31761344, grad/param norm = 1.5357e-01, time/batch = 0.6939s	
5472/28500 (epoch 9.600), train_loss = 1.33666950, grad/param norm = 1.8018e-01, time/batch = 0.6917s	
5473/28500 (epoch 9.602), train_loss = 1.48218906, grad/param norm = 1.7821e-01, time/batch = 0.6905s	
5474/28500 (epoch 9.604), train_loss = 1.36635570, grad/param norm = 1.6092e-01, time/batch = 0.6895s	
5475/28500 (epoch 9.605), train_loss = 1.30649544, grad/param norm = 1.5623e-01, time/batch = 0.6928s	
5476/28500 (epoch 9.607), train_loss = 1.36282792, grad/param norm = 1.5732e-01, time/batch = 0.6996s	
5477/28500 (epoch 9.609), train_loss = 1.30798759, grad/param norm = 1.6246e-01, time/batch = 0.6936s	
5478/28500 (epoch 9.611), train_loss = 1.33902158, grad/param norm = 1.7044e-01, time/batch = 0.6956s	
5479/28500 (epoch 9.612), train_loss = 1.33695706, grad/param norm = 1.5854e-01, time/batch = 0.6890s	
5480/28500 (epoch 9.614), train_loss = 1.33543755, grad/param norm = 1.6054e-01, time/batch = 0.6892s	
5481/28500 (epoch 9.616), train_loss = 1.25589756, grad/param norm = 1.7318e-01, time/batch = 0.6953s	
5482/28500 (epoch 9.618), train_loss = 1.23981263, grad/param norm = 1.5383e-01, time/batch = 0.6912s	
5483/28500 (epoch 9.619), train_loss = 1.50249480, grad/param norm = 1.7826e-01, time/batch = 0.6919s	
5484/28500 (epoch 9.621), train_loss = 1.07320805, grad/param norm = 1.3654e-01, time/batch = 0.6941s	
5485/28500 (epoch 9.623), train_loss = 1.38909892, grad/param norm = 1.6786e-01, time/batch = 0.7043s	
5486/28500 (epoch 9.625), train_loss = 1.14116548, grad/param norm = 1.5644e-01, time/batch = 0.6971s	
5487/28500 (epoch 9.626), train_loss = 1.01723558, grad/param norm = 1.4015e-01, time/batch = 0.7044s	
5488/28500 (epoch 9.628), train_loss = 1.19599184, grad/param norm = 1.6433e-01, time/batch = 0.7099s	
5489/28500 (epoch 9.630), train_loss = 1.11316953, grad/param norm = 1.4424e-01, time/batch = 0.6906s	
5490/28500 (epoch 9.632), train_loss = 1.38192894, grad/param norm = 1.6463e-01, time/batch = 0.6900s	
5491/28500 (epoch 9.633), train_loss = 1.39439100, grad/param norm = 1.6519e-01, time/batch = 0.6928s	
5492/28500 (epoch 9.635), train_loss = 1.49267691, grad/param norm = 1.7321e-01, time/batch = 0.6911s	
5493/28500 (epoch 9.637), train_loss = 1.30233287, grad/param norm = 1.6030e-01, time/batch = 0.6905s	
5494/28500 (epoch 9.639), train_loss = 1.14507436, grad/param norm = 1.4647e-01, time/batch = 0.7061s	
5495/28500 (epoch 9.640), train_loss = 1.17130940, grad/param norm = 1.4996e-01, time/batch = 0.7010s	
5496/28500 (epoch 9.642), train_loss = 1.33697881, grad/param norm = 1.5409e-01, time/batch = 0.6929s	
5497/28500 (epoch 9.644), train_loss = 1.37208389, grad/param norm = 1.5530e-01, time/batch = 0.6899s	
5498/28500 (epoch 9.646), train_loss = 1.16505441, grad/param norm = 1.4082e-01, time/batch = 0.6940s	
5499/28500 (epoch 9.647), train_loss = 1.17861999, grad/param norm = 1.5702e-01, time/batch = 0.6973s	
5500/28500 (epoch 9.649), train_loss = 1.16771051, grad/param norm = 1.5741e-01, time/batch = 0.6907s	
5501/28500 (epoch 9.651), train_loss = 1.13450634, grad/param norm = 1.4359e-01, time/batch = 0.6923s	
5502/28500 (epoch 9.653), train_loss = 1.15672367, grad/param norm = 1.5303e-01, time/batch = 0.6954s	
5503/28500 (epoch 9.654), train_loss = 1.23289161, grad/param norm = 1.5325e-01, time/batch = 0.6931s	
5504/28500 (epoch 9.656), train_loss = 1.23361330, grad/param norm = 1.7057e-01, time/batch = 0.6951s	
5505/28500 (epoch 9.658), train_loss = 1.32120406, grad/param norm = 1.8062e-01, time/batch = 0.7025s	
5506/28500 (epoch 9.660), train_loss = 1.25959291, grad/param norm = 1.4671e-01, time/batch = 0.6937s	
5507/28500 (epoch 9.661), train_loss = 1.43106234, grad/param norm = 1.8244e-01, time/batch = 0.7003s	
5508/28500 (epoch 9.663), train_loss = 1.49145505, grad/param norm = 1.8371e-01, time/batch = 0.6986s	
5509/28500 (epoch 9.665), train_loss = 1.25211467, grad/param norm = 1.6807e-01, time/batch = 0.6908s	
5510/28500 (epoch 9.667), train_loss = 1.33335469, grad/param norm = 1.6244e-01, time/batch = 0.6936s	
5511/28500 (epoch 9.668), train_loss = 1.26809039, grad/param norm = 1.5792e-01, time/batch = 0.6983s	
5512/28500 (epoch 9.670), train_loss = 1.28822922, grad/param norm = 1.5616e-01, time/batch = 0.6967s	
5513/28500 (epoch 9.672), train_loss = 1.25877977, grad/param norm = 1.5812e-01, time/batch = 0.7041s	
5514/28500 (epoch 9.674), train_loss = 1.10832280, grad/param norm = 1.5643e-01, time/batch = 0.7104s	
5515/28500 (epoch 9.675), train_loss = 1.12732722, grad/param norm = 1.5290e-01, time/batch = 0.7102s	
5516/28500 (epoch 9.677), train_loss = 1.24810101, grad/param norm = 1.5382e-01, time/batch = 0.7018s	
5517/28500 (epoch 9.679), train_loss = 1.26668973, grad/param norm = 1.6530e-01, time/batch = 0.6938s	
5518/28500 (epoch 9.681), train_loss = 1.37636607, grad/param norm = 1.6142e-01, time/batch = 0.6944s	
5519/28500 (epoch 9.682), train_loss = 1.24975676, grad/param norm = 1.6382e-01, time/batch = 0.7005s	
5520/28500 (epoch 9.684), train_loss = 1.34172177, grad/param norm = 1.5962e-01, time/batch = 0.6962s	
5521/28500 (epoch 9.686), train_loss = 1.21865031, grad/param norm = 1.6112e-01, time/batch = 0.6997s	
5522/28500 (epoch 9.688), train_loss = 1.17176243, grad/param norm = 1.4236e-01, time/batch = 0.7021s	
5523/28500 (epoch 9.689), train_loss = 1.31284540, grad/param norm = 1.6649e-01, time/batch = 0.7004s	
5524/28500 (epoch 9.691), train_loss = 1.33284573, grad/param norm = 1.8525e-01, time/batch = 0.6933s	
5525/28500 (epoch 9.693), train_loss = 1.25335763, grad/param norm = 1.6431e-01, time/batch = 0.6904s	
5526/28500 (epoch 9.695), train_loss = 1.14017104, grad/param norm = 1.7811e-01, time/batch = 0.6936s	
5527/28500 (epoch 9.696), train_loss = 1.25742913, grad/param norm = 1.6984e-01, time/batch = 0.6926s	
5528/28500 (epoch 9.698), train_loss = 1.28973476, grad/param norm = 1.5215e-01, time/batch = 0.6927s	
5529/28500 (epoch 9.700), train_loss = 1.28674929, grad/param norm = 1.4761e-01, time/batch = 0.6924s	
5530/28500 (epoch 9.702), train_loss = 1.42169588, grad/param norm = 1.7450e-01, time/batch = 0.6938s	
5531/28500 (epoch 9.704), train_loss = 1.32505640, grad/param norm = 1.6609e-01, time/batch = 0.6940s	
5532/28500 (epoch 9.705), train_loss = 1.38157174, grad/param norm = 1.6979e-01, time/batch = 0.6897s	
5533/28500 (epoch 9.707), train_loss = 1.26273500, grad/param norm = 1.7613e-01, time/batch = 0.6917s	
5534/28500 (epoch 9.709), train_loss = 1.38630914, grad/param norm = 1.7551e-01, time/batch = 0.6930s	
5535/28500 (epoch 9.711), train_loss = 1.22936674, grad/param norm = 1.8011e-01, time/batch = 0.6942s	
5536/28500 (epoch 9.712), train_loss = 1.38598490, grad/param norm = 1.6962e-01, time/batch = 0.6931s	
5537/28500 (epoch 9.714), train_loss = 1.36610453, grad/param norm = 1.7093e-01, time/batch = 0.6942s	
5538/28500 (epoch 9.716), train_loss = 1.24289331, grad/param norm = 1.6972e-01, time/batch = 0.6923s	
5539/28500 (epoch 9.718), train_loss = 1.21717515, grad/param norm = 1.5214e-01, time/batch = 0.6949s	
5540/28500 (epoch 9.719), train_loss = 1.23931012, grad/param norm = 1.5425e-01, time/batch = 0.6949s	
5541/28500 (epoch 9.721), train_loss = 1.07213463, grad/param norm = 1.4305e-01, time/batch = 0.6978s	
5542/28500 (epoch 9.723), train_loss = 1.27238973, grad/param norm = 1.6999e-01, time/batch = 0.6955s	
5543/28500 (epoch 9.725), train_loss = 1.37564845, grad/param norm = 1.4781e-01, time/batch = 0.6950s	
5544/28500 (epoch 9.726), train_loss = 1.29534413, grad/param norm = 1.5621e-01, time/batch = 0.6936s	
5545/28500 (epoch 9.728), train_loss = 1.12587577, grad/param norm = 1.3915e-01, time/batch = 0.6936s	
5546/28500 (epoch 9.730), train_loss = 1.32980218, grad/param norm = 1.7753e-01, time/batch = 0.6927s	
5547/28500 (epoch 9.732), train_loss = 1.10701104, grad/param norm = 1.5287e-01, time/batch = 0.6944s	
5548/28500 (epoch 9.733), train_loss = 1.07532119, grad/param norm = 1.4242e-01, time/batch = 0.6959s	
5549/28500 (epoch 9.735), train_loss = 1.09597795, grad/param norm = 1.4241e-01, time/batch = 0.6952s	
5550/28500 (epoch 9.737), train_loss = 1.07523451, grad/param norm = 1.4060e-01, time/batch = 0.6929s	
5551/28500 (epoch 9.739), train_loss = 1.23790923, grad/param norm = 1.6298e-01, time/batch = 0.6960s	
5552/28500 (epoch 9.740), train_loss = 1.26695805, grad/param norm = 1.6213e-01, time/batch = 0.6947s	
5553/28500 (epoch 9.742), train_loss = 1.18324098, grad/param norm = 1.5188e-01, time/batch = 0.6925s	
5554/28500 (epoch 9.744), train_loss = 1.32510802, grad/param norm = 1.6851e-01, time/batch = 0.6943s	
5555/28500 (epoch 9.746), train_loss = 1.14739731, grad/param norm = 1.3958e-01, time/batch = 0.6949s	
5556/28500 (epoch 9.747), train_loss = 1.17377929, grad/param norm = 1.6003e-01, time/batch = 0.6963s	
5557/28500 (epoch 9.749), train_loss = 1.45513141, grad/param norm = 1.8217e-01, time/batch = 0.6936s	
5558/28500 (epoch 9.751), train_loss = 1.18673752, grad/param norm = 1.7569e-01, time/batch = 0.6938s	
5559/28500 (epoch 9.753), train_loss = 1.16753582, grad/param norm = 1.4633e-01, time/batch = 0.6924s	
5560/28500 (epoch 9.754), train_loss = 1.08562275, grad/param norm = 1.5010e-01, time/batch = 0.6936s	
5561/28500 (epoch 9.756), train_loss = 1.37162108, grad/param norm = 1.6552e-01, time/batch = 0.6961s	
5562/28500 (epoch 9.758), train_loss = 1.31689397, grad/param norm = 1.5835e-01, time/batch = 0.6936s	
5563/28500 (epoch 9.760), train_loss = 1.11671940, grad/param norm = 1.5608e-01, time/batch = 0.6934s	
5564/28500 (epoch 9.761), train_loss = 1.15005511, grad/param norm = 1.5930e-01, time/batch = 0.6933s	
5565/28500 (epoch 9.763), train_loss = 1.01825720, grad/param norm = 1.5099e-01, time/batch = 0.6941s	
5566/28500 (epoch 9.765), train_loss = 1.18911957, grad/param norm = 1.5418e-01, time/batch = 0.6927s	
5567/28500 (epoch 9.767), train_loss = 1.06256487, grad/param norm = 1.4945e-01, time/batch = 0.6929s	
5568/28500 (epoch 9.768), train_loss = 1.38510260, grad/param norm = 1.7376e-01, time/batch = 0.6934s	
5569/28500 (epoch 9.770), train_loss = 1.09610914, grad/param norm = 1.5793e-01, time/batch = 0.6968s	
5570/28500 (epoch 9.772), train_loss = 1.00031096, grad/param norm = 1.4960e-01, time/batch = 0.6976s	
5571/28500 (epoch 9.774), train_loss = 1.31135975, grad/param norm = 1.6963e-01, time/batch = 0.7140s	
5572/28500 (epoch 9.775), train_loss = 1.32455057, grad/param norm = 1.5620e-01, time/batch = 0.7324s	
5573/28500 (epoch 9.777), train_loss = 1.31110838, grad/param norm = 1.6043e-01, time/batch = 0.7157s	
5574/28500 (epoch 9.779), train_loss = 1.08862081, grad/param norm = 1.4576e-01, time/batch = 0.6959s	
5575/28500 (epoch 9.781), train_loss = 1.32223775, grad/param norm = 1.6780e-01, time/batch = 0.7086s	
5576/28500 (epoch 9.782), train_loss = 1.35370602, grad/param norm = 1.7677e-01, time/batch = 0.7150s	
5577/28500 (epoch 9.784), train_loss = 1.06349752, grad/param norm = 1.3837e-01, time/batch = 0.6930s	
5578/28500 (epoch 9.786), train_loss = 1.18358852, grad/param norm = 1.4474e-01, time/batch = 0.6939s	
5579/28500 (epoch 9.788), train_loss = 1.31396721, grad/param norm = 1.7072e-01, time/batch = 0.6932s	
5580/28500 (epoch 9.789), train_loss = 1.00527946, grad/param norm = 1.5225e-01, time/batch = 0.6940s	
5581/28500 (epoch 9.791), train_loss = 1.25091334, grad/param norm = 1.7262e-01, time/batch = 0.6977s	
5582/28500 (epoch 9.793), train_loss = 1.17913880, grad/param norm = 1.6641e-01, time/batch = 0.6964s	
5583/28500 (epoch 9.795), train_loss = 1.25982418, grad/param norm = 1.5021e-01, time/batch = 0.6948s	
5584/28500 (epoch 9.796), train_loss = 1.16013512, grad/param norm = 1.5340e-01, time/batch = 0.6960s	
5585/28500 (epoch 9.798), train_loss = 1.10756190, grad/param norm = 1.4791e-01, time/batch = 0.7017s	
5586/28500 (epoch 9.800), train_loss = 1.12884672, grad/param norm = 1.4826e-01, time/batch = 0.6944s	
5587/28500 (epoch 9.802), train_loss = 1.28309903, grad/param norm = 1.8402e-01, time/batch = 0.6973s	
5588/28500 (epoch 9.804), train_loss = 1.23892321, grad/param norm = 1.6466e-01, time/batch = 0.6965s	
5589/28500 (epoch 9.805), train_loss = 1.27222861, grad/param norm = 1.7958e-01, time/batch = 0.6953s	
5590/28500 (epoch 9.807), train_loss = 1.34209128, grad/param norm = 1.6917e-01, time/batch = 0.6945s	
5591/28500 (epoch 9.809), train_loss = 1.22644552, grad/param norm = 1.5464e-01, time/batch = 0.7400s	
5592/28500 (epoch 9.811), train_loss = 1.33453335, grad/param norm = 1.6567e-01, time/batch = 0.7036s	
5593/28500 (epoch 9.812), train_loss = 1.30794964, grad/param norm = 1.7081e-01, time/batch = 0.6933s	
5594/28500 (epoch 9.814), train_loss = 1.23518541, grad/param norm = 1.6695e-01, time/batch = 0.6934s	
5595/28500 (epoch 9.816), train_loss = 1.42564829, grad/param norm = 1.7509e-01, time/batch = 0.6932s	
5596/28500 (epoch 9.818), train_loss = 1.32708634, grad/param norm = 1.5957e-01, time/batch = 0.6935s	
5597/28500 (epoch 9.819), train_loss = 1.26054843, grad/param norm = 1.5725e-01, time/batch = 0.6929s	
5598/28500 (epoch 9.821), train_loss = 1.18064060, grad/param norm = 1.6345e-01, time/batch = 0.7122s	
5599/28500 (epoch 9.823), train_loss = 1.47169480, grad/param norm = 1.9003e-01, time/batch = 0.6938s	
5600/28500 (epoch 9.825), train_loss = 1.21869381, grad/param norm = 1.7404e-01, time/batch = 0.6928s	
5601/28500 (epoch 9.826), train_loss = 1.33229920, grad/param norm = 1.8933e-01, time/batch = 0.6952s	
5602/28500 (epoch 9.828), train_loss = 1.14451506, grad/param norm = 1.6975e-01, time/batch = 0.6928s	
5603/28500 (epoch 9.830), train_loss = 1.20083890, grad/param norm = 1.5272e-01, time/batch = 0.6933s	
5604/28500 (epoch 9.832), train_loss = 1.25613145, grad/param norm = 1.6947e-01, time/batch = 0.6925s	
5605/28500 (epoch 9.833), train_loss = 1.43539962, grad/param norm = 1.6752e-01, time/batch = 0.6932s	
5606/28500 (epoch 9.835), train_loss = 1.20086964, grad/param norm = 1.5415e-01, time/batch = 0.7095s	
5607/28500 (epoch 9.837), train_loss = 1.10029967, grad/param norm = 1.4872e-01, time/batch = 0.6933s	
5608/28500 (epoch 9.839), train_loss = 1.36957694, grad/param norm = 1.7290e-01, time/batch = 0.6922s	
5609/28500 (epoch 9.840), train_loss = 1.38743691, grad/param norm = 1.7570e-01, time/batch = 0.6935s	
5610/28500 (epoch 9.842), train_loss = 1.33916789, grad/param norm = 1.6318e-01, time/batch = 0.6941s	
5611/28500 (epoch 9.844), train_loss = 1.28159890, grad/param norm = 1.6167e-01, time/batch = 0.6950s	
5612/28500 (epoch 9.846), train_loss = 1.41369471, grad/param norm = 1.7199e-01, time/batch = 0.6950s	
5613/28500 (epoch 9.847), train_loss = 1.21426877, grad/param norm = 1.5820e-01, time/batch = 0.7074s	
5614/28500 (epoch 9.849), train_loss = 1.21573385, grad/param norm = 1.5518e-01, time/batch = 0.7042s	
5615/28500 (epoch 9.851), train_loss = 1.10087021, grad/param norm = 1.6085e-01, time/batch = 0.6954s	
5616/28500 (epoch 9.853), train_loss = 1.27263712, grad/param norm = 1.6992e-01, time/batch = 0.6940s	
5617/28500 (epoch 9.854), train_loss = 1.27894449, grad/param norm = 1.6469e-01, time/batch = 0.6926s	
5618/28500 (epoch 9.856), train_loss = 1.36162864, grad/param norm = 1.6826e-01, time/batch = 0.6927s	
5619/28500 (epoch 9.858), train_loss = 1.10214204, grad/param norm = 1.4057e-01, time/batch = 0.6934s	
5620/28500 (epoch 9.860), train_loss = 1.32654939, grad/param norm = 1.8117e-01, time/batch = 0.6949s	
5621/28500 (epoch 9.861), train_loss = 1.26119439, grad/param norm = 1.6419e-01, time/batch = 0.7139s	
5622/28500 (epoch 9.863), train_loss = 1.37868970, grad/param norm = 1.6642e-01, time/batch = 0.6951s	
5623/28500 (epoch 9.865), train_loss = 1.24898853, grad/param norm = 1.5873e-01, time/batch = 0.6933s	
5624/28500 (epoch 9.867), train_loss = 1.34111805, grad/param norm = 1.8726e-01, time/batch = 0.6950s	
5625/28500 (epoch 9.868), train_loss = 1.13069901, grad/param norm = 1.4885e-01, time/batch = 0.6938s	
5626/28500 (epoch 9.870), train_loss = 1.05838108, grad/param norm = 1.4284e-01, time/batch = 0.6938s	
5627/28500 (epoch 9.872), train_loss = 1.31606458, grad/param norm = 1.7866e-01, time/batch = 0.6926s	
5628/28500 (epoch 9.874), train_loss = 1.27968228, grad/param norm = 1.7632e-01, time/batch = 0.6939s	
5629/28500 (epoch 9.875), train_loss = 1.35687327, grad/param norm = 1.6436e-01, time/batch = 0.6925s	
5630/28500 (epoch 9.877), train_loss = 1.27357442, grad/param norm = 1.6305e-01, time/batch = 0.7122s	
5631/28500 (epoch 9.879), train_loss = 1.25096254, grad/param norm = 1.6069e-01, time/batch = 0.6961s	
5632/28500 (epoch 9.881), train_loss = 1.31687536, grad/param norm = 1.6095e-01, time/batch = 0.6934s	
5633/28500 (epoch 9.882), train_loss = 1.21842172, grad/param norm = 1.5662e-01, time/batch = 0.6927s	
5634/28500 (epoch 9.884), train_loss = 1.30406658, grad/param norm = 1.7036e-01, time/batch = 0.6932s	
5635/28500 (epoch 9.886), train_loss = 1.17075697, grad/param norm = 1.4372e-01, time/batch = 0.6936s	
5636/28500 (epoch 9.888), train_loss = 1.12694310, grad/param norm = 1.5437e-01, time/batch = 0.6939s	
5637/28500 (epoch 9.889), train_loss = 1.23474760, grad/param norm = 1.4884e-01, time/batch = 0.7094s	
5638/28500 (epoch 9.891), train_loss = 1.27967698, grad/param norm = 1.5837e-01, time/batch = 0.7005s	
5639/28500 (epoch 9.893), train_loss = 1.21601648, grad/param norm = 1.7442e-01, time/batch = 0.6930s	
5640/28500 (epoch 9.895), train_loss = 1.45255610, grad/param norm = 1.8339e-01, time/batch = 0.6954s	
5641/28500 (epoch 9.896), train_loss = 1.35134075, grad/param norm = 1.7192e-01, time/batch = 0.6952s	
5642/28500 (epoch 9.898), train_loss = 1.22268601, grad/param norm = 1.5799e-01, time/batch = 0.6946s	
5643/28500 (epoch 9.900), train_loss = 1.13146341, grad/param norm = 1.5086e-01, time/batch = 0.6931s	
5644/28500 (epoch 9.902), train_loss = 1.12764837, grad/param norm = 1.4788e-01, time/batch = 0.7010s	
5645/28500 (epoch 9.904), train_loss = 1.14371021, grad/param norm = 1.5319e-01, time/batch = 0.7082s	
5646/28500 (epoch 9.905), train_loss = 1.29204199, grad/param norm = 1.6479e-01, time/batch = 0.6931s	
5647/28500 (epoch 9.907), train_loss = 1.31675418, grad/param norm = 1.6129e-01, time/batch = 0.6901s	
5648/28500 (epoch 9.909), train_loss = 1.12079520, grad/param norm = 1.6004e-01, time/batch = 0.6896s	
5649/28500 (epoch 9.911), train_loss = 1.16647225, grad/param norm = 1.5407e-01, time/batch = 0.6901s	
5650/28500 (epoch 9.912), train_loss = 0.98887197, grad/param norm = 1.4247e-01, time/batch = 0.6894s	
5651/28500 (epoch 9.914), train_loss = 1.38573217, grad/param norm = 1.5594e-01, time/batch = 0.6913s	
5652/28500 (epoch 9.916), train_loss = 1.31471533, grad/param norm = 1.7122e-01, time/batch = 0.6900s	
5653/28500 (epoch 9.918), train_loss = 1.25464290, grad/param norm = 1.7326e-01, time/batch = 0.6909s	
5654/28500 (epoch 9.919), train_loss = 1.20302538, grad/param norm = 1.4801e-01, time/batch = 0.6985s	
5655/28500 (epoch 9.921), train_loss = 1.44479404, grad/param norm = 1.9366e-01, time/batch = 0.6937s	
5656/28500 (epoch 9.923), train_loss = 1.29632392, grad/param norm = 1.8605e-01, time/batch = 0.6949s	
5657/28500 (epoch 9.925), train_loss = 1.15562661, grad/param norm = 1.7254e-01, time/batch = 0.7046s	
5658/28500 (epoch 9.926), train_loss = 1.24340945, grad/param norm = 1.5884e-01, time/batch = 0.6912s	
5659/28500 (epoch 9.928), train_loss = 1.19179149, grad/param norm = 1.4690e-01, time/batch = 0.6949s	
5660/28500 (epoch 9.930), train_loss = 0.97316478, grad/param norm = 1.4255e-01, time/batch = 0.6909s	
5661/28500 (epoch 9.932), train_loss = 1.05169387, grad/param norm = 1.3674e-01, time/batch = 0.6924s	
5662/28500 (epoch 9.933), train_loss = 1.27720925, grad/param norm = 1.5688e-01, time/batch = 0.6979s	
5663/28500 (epoch 9.935), train_loss = 1.33449959, grad/param norm = 1.7689e-01, time/batch = 0.7074s	
5664/28500 (epoch 9.937), train_loss = 1.39240349, grad/param norm = 1.8768e-01, time/batch = 0.6937s	
5665/28500 (epoch 9.939), train_loss = 1.45719830, grad/param norm = 1.8059e-01, time/batch = 0.6940s	
5666/28500 (epoch 9.940), train_loss = 1.15542645, grad/param norm = 1.5747e-01, time/batch = 0.7135s	
5667/28500 (epoch 9.942), train_loss = 1.34698530, grad/param norm = 1.5870e-01, time/batch = 0.6943s	
5668/28500 (epoch 9.944), train_loss = 1.25744041, grad/param norm = 1.6472e-01, time/batch = 0.6981s	
5669/28500 (epoch 9.946), train_loss = 1.41526802, grad/param norm = 1.7009e-01, time/batch = 0.6955s	
5670/28500 (epoch 9.947), train_loss = 1.62123942, grad/param norm = 1.9000e-01, time/batch = 0.6922s	
5671/28500 (epoch 9.949), train_loss = 1.13688696, grad/param norm = 1.4878e-01, time/batch = 0.6926s	
5672/28500 (epoch 9.951), train_loss = 1.42175847, grad/param norm = 1.9176e-01, time/batch = 0.6913s	
5673/28500 (epoch 9.953), train_loss = 1.47459674, grad/param norm = 1.8494e-01, time/batch = 0.7043s	
5674/28500 (epoch 9.954), train_loss = 1.39857496, grad/param norm = 1.7670e-01, time/batch = 0.6917s	
5675/28500 (epoch 9.956), train_loss = 1.35833233, grad/param norm = 1.9478e-01, time/batch = 0.6915s	
5676/28500 (epoch 9.958), train_loss = 1.41984277, grad/param norm = 1.6801e-01, time/batch = 0.6896s	
5677/28500 (epoch 9.960), train_loss = 1.17095438, grad/param norm = 1.6702e-01, time/batch = 0.6922s	
5678/28500 (epoch 9.961), train_loss = 1.49997739, grad/param norm = 1.8620e-01, time/batch = 0.6941s	
5679/28500 (epoch 9.963), train_loss = 1.36694357, grad/param norm = 1.5208e-01, time/batch = 0.6938s	
5680/28500 (epoch 9.965), train_loss = 1.14368495, grad/param norm = 1.4793e-01, time/batch = 0.6925s	
5681/28500 (epoch 9.967), train_loss = 1.12927512, grad/param norm = 1.5082e-01, time/batch = 0.6915s	
5682/28500 (epoch 9.968), train_loss = 1.07385235, grad/param norm = 1.4315e-01, time/batch = 0.6901s	
5683/28500 (epoch 9.970), train_loss = 1.21527622, grad/param norm = 1.5254e-01, time/batch = 0.6896s	
5684/28500 (epoch 9.972), train_loss = 1.34587588, grad/param norm = 1.9502e-01, time/batch = 0.6896s	
5685/28500 (epoch 9.974), train_loss = 1.51819246, grad/param norm = 1.7879e-01, time/batch = 0.6900s	
5686/28500 (epoch 9.975), train_loss = 1.22314738, grad/param norm = 1.6680e-01, time/batch = 0.6903s	
5687/28500 (epoch 9.977), train_loss = 1.47778538, grad/param norm = 1.7516e-01, time/batch = 0.6904s	
5688/28500 (epoch 9.979), train_loss = 1.19206001, grad/param norm = 1.5505e-01, time/batch = 0.6900s	
5689/28500 (epoch 9.981), train_loss = 1.19411042, grad/param norm = 1.6087e-01, time/batch = 0.6896s	
5690/28500 (epoch 9.982), train_loss = 1.13001580, grad/param norm = 1.3982e-01, time/batch = 0.6912s	
5691/28500 (epoch 9.984), train_loss = 1.34334640, grad/param norm = 1.6271e-01, time/batch = 0.6959s	
5692/28500 (epoch 9.986), train_loss = 1.49024635, grad/param norm = 1.8665e-01, time/batch = 0.6952s	
5693/28500 (epoch 9.988), train_loss = 1.07570698, grad/param norm = 1.5686e-01, time/batch = 0.6948s	
5694/28500 (epoch 9.989), train_loss = 1.31462237, grad/param norm = 1.8401e-01, time/batch = 0.6945s	
5695/28500 (epoch 9.991), train_loss = 1.18092133, grad/param norm = 1.6530e-01, time/batch = 0.6969s	
5696/28500 (epoch 9.993), train_loss = 1.19059801, grad/param norm = 1.6726e-01, time/batch = 0.6947s	
5697/28500 (epoch 9.995), train_loss = 1.17564004, grad/param norm = 1.5623e-01, time/batch = 0.6919s	
5698/28500 (epoch 9.996), train_loss = 1.12797919, grad/param norm = 1.5273e-01, time/batch = 0.6935s	
5699/28500 (epoch 9.998), train_loss = 1.37460803, grad/param norm = 1.6949e-01, time/batch = 0.6932s	
decayed learning rate by a factor 0.97 to 0.00194	
5700/28500 (epoch 10.000), train_loss = 1.18893235, grad/param norm = 1.5163e-01, time/batch = 0.6932s	
5701/28500 (epoch 10.002), train_loss = 1.42843712, grad/param norm = 1.7693e-01, time/batch = 0.6946s	
5702/28500 (epoch 10.004), train_loss = 1.21692234, grad/param norm = 1.6633e-01, time/batch = 0.6909s	
5703/28500 (epoch 10.005), train_loss = 1.35211698, grad/param norm = 1.6676e-01, time/batch = 0.6896s	
5704/28500 (epoch 10.007), train_loss = 1.10315833, grad/param norm = 1.4231e-01, time/batch = 0.6895s	
5705/28500 (epoch 10.009), train_loss = 1.34879500, grad/param norm = 1.6582e-01, time/batch = 0.6896s	
5706/28500 (epoch 10.011), train_loss = 1.23783354, grad/param norm = 1.9494e-01, time/batch = 0.6901s	
5707/28500 (epoch 10.012), train_loss = 1.08817485, grad/param norm = 1.4959e-01, time/batch = 0.6936s	
5708/28500 (epoch 10.014), train_loss = 1.13412354, grad/param norm = 1.4990e-01, time/batch = 0.6936s	
5709/28500 (epoch 10.016), train_loss = 1.20651037, grad/param norm = 1.4212e-01, time/batch = 0.6914s	
5710/28500 (epoch 10.018), train_loss = 1.29969099, grad/param norm = 1.6500e-01, time/batch = 0.6909s	
5711/28500 (epoch 10.019), train_loss = 1.35037906, grad/param norm = 1.7045e-01, time/batch = 0.6971s	
5712/28500 (epoch 10.021), train_loss = 1.29239468, grad/param norm = 1.4939e-01, time/batch = 0.6920s	
5713/28500 (epoch 10.023), train_loss = 1.22301582, grad/param norm = 1.5592e-01, time/batch = 0.6894s	
5714/28500 (epoch 10.025), train_loss = 1.24317514, grad/param norm = 1.6126e-01, time/batch = 0.6898s	
5715/28500 (epoch 10.026), train_loss = 1.29510229, grad/param norm = 1.6478e-01, time/batch = 0.6959s	
5716/28500 (epoch 10.028), train_loss = 1.31973480, grad/param norm = 1.6423e-01, time/batch = 0.6927s	
5717/28500 (epoch 10.030), train_loss = 1.35210652, grad/param norm = 1.8291e-01, time/batch = 0.6935s	
5718/28500 (epoch 10.032), train_loss = 1.35356935, grad/param norm = 1.7112e-01, time/batch = 0.6889s	
5719/28500 (epoch 10.033), train_loss = 1.44625318, grad/param norm = 1.7397e-01, time/batch = 0.6892s	
5720/28500 (epoch 10.035), train_loss = 1.30887821, grad/param norm = 1.6726e-01, time/batch = 0.6893s	
5721/28500 (epoch 10.037), train_loss = 1.34771342, grad/param norm = 1.5242e-01, time/batch = 0.6919s	
5722/28500 (epoch 10.039), train_loss = 1.42706522, grad/param norm = 1.7797e-01, time/batch = 0.6921s	
5723/28500 (epoch 10.040), train_loss = 1.43727098, grad/param norm = 1.6945e-01, time/batch = 0.6943s	
5724/28500 (epoch 10.042), train_loss = 1.34874847, grad/param norm = 1.8349e-01, time/batch = 0.6955s	
5725/28500 (epoch 10.044), train_loss = 1.26388337, grad/param norm = 1.7150e-01, time/batch = 0.6897s	
5726/28500 (epoch 10.046), train_loss = 1.47913176, grad/param norm = 1.7141e-01, time/batch = 0.6979s	
5727/28500 (epoch 10.047), train_loss = 1.38687498, grad/param norm = 1.6856e-01, time/batch = 0.7101s	
5728/28500 (epoch 10.049), train_loss = 1.29755799, grad/param norm = 1.6765e-01, time/batch = 0.6959s	
5729/28500 (epoch 10.051), train_loss = 1.24032549, grad/param norm = 1.5880e-01, time/batch = 0.6920s	
5730/28500 (epoch 10.053), train_loss = 1.32252130, grad/param norm = 1.6218e-01, time/batch = 0.6933s	
5731/28500 (epoch 10.054), train_loss = 1.37068705, grad/param norm = 1.6569e-01, time/batch = 0.6988s	
5732/28500 (epoch 10.056), train_loss = 1.12936681, grad/param norm = 1.4640e-01, time/batch = 0.6944s	
5733/28500 (epoch 10.058), train_loss = 1.15782473, grad/param norm = 1.6694e-01, time/batch = 0.6958s	
5734/28500 (epoch 10.060), train_loss = 1.34311504, grad/param norm = 1.6491e-01, time/batch = 0.6913s	
5735/28500 (epoch 10.061), train_loss = 1.33322252, grad/param norm = 1.8355e-01, time/batch = 0.6910s	
5736/28500 (epoch 10.063), train_loss = 1.35776760, grad/param norm = 1.6144e-01, time/batch = 0.6903s	
5737/28500 (epoch 10.065), train_loss = 1.41590990, grad/param norm = 1.6952e-01, time/batch = 0.6934s	
5738/28500 (epoch 10.067), train_loss = 1.17954189, grad/param norm = 1.3982e-01, time/batch = 0.6900s	
5739/28500 (epoch 10.068), train_loss = 1.21714381, grad/param norm = 1.6321e-01, time/batch = 0.6887s	
5740/28500 (epoch 10.070), train_loss = 1.33253367, grad/param norm = 1.7242e-01, time/batch = 0.6889s	
5741/28500 (epoch 10.072), train_loss = 1.48312366, grad/param norm = 1.7431e-01, time/batch = 0.6923s	
5742/28500 (epoch 10.074), train_loss = 1.31192311, grad/param norm = 1.6038e-01, time/batch = 0.6930s	
5743/28500 (epoch 10.075), train_loss = 1.25471825, grad/param norm = 1.4036e-01, time/batch = 0.7037s	
5744/28500 (epoch 10.077), train_loss = 1.31522910, grad/param norm = 1.6216e-01, time/batch = 0.6915s	
5745/28500 (epoch 10.079), train_loss = 1.25676526, grad/param norm = 1.4652e-01, time/batch = 0.6914s	
5746/28500 (epoch 10.081), train_loss = 1.39691049, grad/param norm = 1.8369e-01, time/batch = 0.6893s	
5747/28500 (epoch 10.082), train_loss = 1.31939617, grad/param norm = 1.8635e-01, time/batch = 0.6896s	
5748/28500 (epoch 10.084), train_loss = 1.34951540, grad/param norm = 1.7057e-01, time/batch = 0.6948s	
5749/28500 (epoch 10.086), train_loss = 1.24087343, grad/param norm = 1.6892e-01, time/batch = 0.6933s	
5750/28500 (epoch 10.088), train_loss = 1.16350573, grad/param norm = 1.5971e-01, time/batch = 0.6956s	
5751/28500 (epoch 10.089), train_loss = 1.40411165, grad/param norm = 1.5100e-01, time/batch = 0.6923s	
5752/28500 (epoch 10.091), train_loss = 1.12755209, grad/param norm = 1.5293e-01, time/batch = 0.6943s	
5753/28500 (epoch 10.093), train_loss = 1.32458902, grad/param norm = 1.6343e-01, time/batch = 0.6973s	
5754/28500 (epoch 10.095), train_loss = 1.19249541, grad/param norm = 1.4714e-01, time/batch = 0.6930s	
5755/28500 (epoch 10.096), train_loss = 1.42658089, grad/param norm = 1.7145e-01, time/batch = 0.6921s	
5756/28500 (epoch 10.098), train_loss = 1.41585394, grad/param norm = 1.7629e-01, time/batch = 0.7055s	
5757/28500 (epoch 10.100), train_loss = 1.22264633, grad/param norm = 1.5602e-01, time/batch = 0.7076s	
5758/28500 (epoch 10.102), train_loss = 1.43522728, grad/param norm = 1.6370e-01, time/batch = 0.6948s	
5759/28500 (epoch 10.104), train_loss = 1.25208134, grad/param norm = 1.6751e-01, time/batch = 0.6926s	
5760/28500 (epoch 10.105), train_loss = 1.34242678, grad/param norm = 1.6321e-01, time/batch = 0.6924s	
5761/28500 (epoch 10.107), train_loss = 1.16597675, grad/param norm = 1.5891e-01, time/batch = 0.6977s	
5762/28500 (epoch 10.109), train_loss = 1.15959235, grad/param norm = 1.6270e-01, time/batch = 0.6979s	
5763/28500 (epoch 10.111), train_loss = 1.22497015, grad/param norm = 1.6625e-01, time/batch = 0.6961s	
5764/28500 (epoch 10.112), train_loss = 1.36433457, grad/param norm = 1.7200e-01, time/batch = 0.6937s	
5765/28500 (epoch 10.114), train_loss = 1.26677204, grad/param norm = 1.6438e-01, time/batch = 0.6918s	
5766/28500 (epoch 10.116), train_loss = 1.45077122, grad/param norm = 1.6629e-01, time/batch = 0.6932s	
5767/28500 (epoch 10.118), train_loss = 1.14155934, grad/param norm = 1.5848e-01, time/batch = 0.6893s	
5768/28500 (epoch 10.119), train_loss = 1.34258563, grad/param norm = 1.7911e-01, time/batch = 0.6905s	
5769/28500 (epoch 10.121), train_loss = 1.50440613, grad/param norm = 1.8798e-01, time/batch = 0.6922s	
5770/28500 (epoch 10.123), train_loss = 1.32230394, grad/param norm = 1.7035e-01, time/batch = 0.6930s	
5771/28500 (epoch 10.125), train_loss = 1.29834552, grad/param norm = 1.6140e-01, time/batch = 0.6917s	
5772/28500 (epoch 10.126), train_loss = 1.26601761, grad/param norm = 1.5306e-01, time/batch = 0.6916s	
5773/28500 (epoch 10.128), train_loss = 1.19866783, grad/param norm = 1.5263e-01, time/batch = 0.6897s	
5774/28500 (epoch 10.130), train_loss = 1.16999988, grad/param norm = 1.6314e-01, time/batch = 0.6894s	
5775/28500 (epoch 10.132), train_loss = 1.36222591, grad/param norm = 1.7319e-01, time/batch = 0.6893s	
5776/28500 (epoch 10.133), train_loss = 1.28994812, grad/param norm = 1.6170e-01, time/batch = 0.6892s	
5777/28500 (epoch 10.135), train_loss = 1.26074969, grad/param norm = 1.5265e-01, time/batch = 0.6913s	
5778/28500 (epoch 10.137), train_loss = 1.22611081, grad/param norm = 1.6725e-01, time/batch = 0.6927s	
5779/28500 (epoch 10.139), train_loss = 1.25305501, grad/param norm = 1.5201e-01, time/batch = 0.6912s	
5780/28500 (epoch 10.140), train_loss = 1.32083613, grad/param norm = 1.5653e-01, time/batch = 0.6902s	
5781/28500 (epoch 10.142), train_loss = 1.30430707, grad/param norm = 1.6732e-01, time/batch = 0.6916s	
5782/28500 (epoch 10.144), train_loss = 1.16477243, grad/param norm = 1.4911e-01, time/batch = 0.6914s	
5783/28500 (epoch 10.146), train_loss = 1.19702112, grad/param norm = 1.5482e-01, time/batch = 0.6898s	
5784/28500 (epoch 10.147), train_loss = 1.11451808, grad/param norm = 1.5595e-01, time/batch = 0.6897s	
5785/28500 (epoch 10.149), train_loss = 1.11590354, grad/param norm = 1.4122e-01, time/batch = 0.6913s	
5786/28500 (epoch 10.151), train_loss = 1.10251123, grad/param norm = 1.4027e-01, time/batch = 0.6922s	
5787/28500 (epoch 10.153), train_loss = 1.26513201, grad/param norm = 1.5113e-01, time/batch = 0.6939s	
5788/28500 (epoch 10.154), train_loss = 1.17994066, grad/param norm = 1.6715e-01, time/batch = 0.6954s	
5789/28500 (epoch 10.156), train_loss = 1.42857534, grad/param norm = 1.7822e-01, time/batch = 0.6926s	
5790/28500 (epoch 10.158), train_loss = 1.23102309, grad/param norm = 1.5016e-01, time/batch = 0.6967s	
5791/28500 (epoch 10.160), train_loss = 1.15416425, grad/param norm = 1.5216e-01, time/batch = 0.6989s	
5792/28500 (epoch 10.161), train_loss = 1.27382808, grad/param norm = 1.5946e-01, time/batch = 0.6941s	
5793/28500 (epoch 10.163), train_loss = 1.15032592, grad/param norm = 1.6726e-01, time/batch = 0.6984s	
5794/28500 (epoch 10.165), train_loss = 1.45425933, grad/param norm = 1.5593e-01, time/batch = 0.6961s	
5795/28500 (epoch 10.167), train_loss = 1.54118643, grad/param norm = 1.8571e-01, time/batch = 0.6946s	
5796/28500 (epoch 10.168), train_loss = 1.37794329, grad/param norm = 1.9264e-01, time/batch = 0.6931s	
5797/28500 (epoch 10.170), train_loss = 1.37862934, grad/param norm = 1.7370e-01, time/batch = 0.6935s	
5798/28500 (epoch 10.172), train_loss = 1.27088521, grad/param norm = 1.7843e-01, time/batch = 0.6928s	
5799/28500 (epoch 10.174), train_loss = 1.45101063, grad/param norm = 1.8393e-01, time/batch = 0.6940s	
5800/28500 (epoch 10.175), train_loss = 1.22356183, grad/param norm = 1.4866e-01, time/batch = 0.6943s	
5801/28500 (epoch 10.177), train_loss = 1.34065279, grad/param norm = 1.6460e-01, time/batch = 0.6950s	
5802/28500 (epoch 10.179), train_loss = 1.25502597, grad/param norm = 1.7017e-01, time/batch = 0.6940s	
5803/28500 (epoch 10.181), train_loss = 1.30536244, grad/param norm = 1.4973e-01, time/batch = 0.6936s	
5804/28500 (epoch 10.182), train_loss = 1.27902323, grad/param norm = 1.6119e-01, time/batch = 0.6939s	
5805/28500 (epoch 10.184), train_loss = 1.50783696, grad/param norm = 1.8129e-01, time/batch = 0.6947s	
5806/28500 (epoch 10.186), train_loss = 1.39801735, grad/param norm = 1.7749e-01, time/batch = 0.6946s	
5807/28500 (epoch 10.188), train_loss = 1.27199112, grad/param norm = 1.5375e-01, time/batch = 0.6962s	
5808/28500 (epoch 10.189), train_loss = 1.31143376, grad/param norm = 1.6738e-01, time/batch = 0.6978s	
5809/28500 (epoch 10.191), train_loss = 1.51541291, grad/param norm = 1.7679e-01, time/batch = 0.6960s	
5810/28500 (epoch 10.193), train_loss = 1.37721754, grad/param norm = 1.8737e-01, time/batch = 0.6992s	
5811/28500 (epoch 10.195), train_loss = 1.40659685, grad/param norm = 1.7590e-01, time/batch = 0.7152s	
5812/28500 (epoch 10.196), train_loss = 1.33987992, grad/param norm = 1.6856e-01, time/batch = 0.7188s	
5813/28500 (epoch 10.198), train_loss = 1.32659398, grad/param norm = 1.8498e-01, time/batch = 0.7087s	
5814/28500 (epoch 10.200), train_loss = 1.26514357, grad/param norm = 1.4529e-01, time/batch = 0.6977s	
5815/28500 (epoch 10.202), train_loss = 1.28409622, grad/param norm = 1.5964e-01, time/batch = 0.6954s	
5816/28500 (epoch 10.204), train_loss = 1.16955122, grad/param norm = 1.5288e-01, time/batch = 0.6951s	
5817/28500 (epoch 10.205), train_loss = 1.23090291, grad/param norm = 1.5457e-01, time/batch = 0.6957s	
5818/28500 (epoch 10.207), train_loss = 1.24320468, grad/param norm = 1.5902e-01, time/batch = 0.6899s	
5819/28500 (epoch 10.209), train_loss = 1.27569622, grad/param norm = 1.6124e-01, time/batch = 0.6956s	
5820/28500 (epoch 10.211), train_loss = 1.13159399, grad/param norm = 1.5766e-01, time/batch = 0.6914s	
5821/28500 (epoch 10.212), train_loss = 1.13539098, grad/param norm = 1.5141e-01, time/batch = 0.6912s	
5822/28500 (epoch 10.214), train_loss = 1.30857515, grad/param norm = 1.8064e-01, time/batch = 0.6904s	
5823/28500 (epoch 10.216), train_loss = 1.14487992, grad/param norm = 1.4873e-01, time/batch = 0.6899s	
5824/28500 (epoch 10.218), train_loss = 1.38347627, grad/param norm = 1.5443e-01, time/batch = 0.6925s	
5825/28500 (epoch 10.219), train_loss = 1.33779668, grad/param norm = 1.7751e-01, time/batch = 0.6903s	
5826/28500 (epoch 10.221), train_loss = 1.18153505, grad/param norm = 1.7340e-01, time/batch = 0.6911s	
5827/28500 (epoch 10.223), train_loss = 1.39090222, grad/param norm = 1.7663e-01, time/batch = 0.6912s	
5828/28500 (epoch 10.225), train_loss = 1.42509622, grad/param norm = 1.6463e-01, time/batch = 0.6924s	
5829/28500 (epoch 10.226), train_loss = 1.24353835, grad/param norm = 1.5997e-01, time/batch = 0.6997s	
5830/28500 (epoch 10.228), train_loss = 1.34480034, grad/param norm = 1.5354e-01, time/batch = 0.7044s	
5831/28500 (epoch 10.230), train_loss = 1.37452266, grad/param norm = 1.6178e-01, time/batch = 0.7011s	
5832/28500 (epoch 10.232), train_loss = 1.32363348, grad/param norm = 1.6358e-01, time/batch = 0.6957s	
5833/28500 (epoch 10.233), train_loss = 1.33032086, grad/param norm = 1.7005e-01, time/batch = 0.6993s	
5834/28500 (epoch 10.235), train_loss = 1.22383642, grad/param norm = 1.5835e-01, time/batch = 0.7004s	
5835/28500 (epoch 10.237), train_loss = 1.11253079, grad/param norm = 1.4084e-01, time/batch = 0.6939s	
5836/28500 (epoch 10.239), train_loss = 1.17919588, grad/param norm = 1.5023e-01, time/batch = 0.6950s	
5837/28500 (epoch 10.240), train_loss = 1.13787662, grad/param norm = 1.6661e-01, time/batch = 0.7055s	
5838/28500 (epoch 10.242), train_loss = 1.32294212, grad/param norm = 1.8809e-01, time/batch = 0.6971s	
5839/28500 (epoch 10.244), train_loss = 1.33511098, grad/param norm = 1.5923e-01, time/batch = 0.6942s	
5840/28500 (epoch 10.246), train_loss = 1.38684338, grad/param norm = 1.6712e-01, time/batch = 0.6946s	
5841/28500 (epoch 10.247), train_loss = 1.48680454, grad/param norm = 1.7055e-01, time/batch = 0.6957s	
5842/28500 (epoch 10.249), train_loss = 1.31368577, grad/param norm = 1.7110e-01, time/batch = 0.6975s	
5843/28500 (epoch 10.251), train_loss = 1.16511461, grad/param norm = 1.4664e-01, time/batch = 0.7003s	
5844/28500 (epoch 10.253), train_loss = 1.47483175, grad/param norm = 1.7707e-01, time/batch = 0.6956s	
5845/28500 (epoch 10.254), train_loss = 1.43295561, grad/param norm = 1.7618e-01, time/batch = 0.6953s	
5846/28500 (epoch 10.256), train_loss = 1.20205400, grad/param norm = 1.4380e-01, time/batch = 0.6968s	
5847/28500 (epoch 10.258), train_loss = 1.25146115, grad/param norm = 1.6585e-01, time/batch = 0.6964s	
5848/28500 (epoch 10.260), train_loss = 1.21120889, grad/param norm = 1.4933e-01, time/batch = 0.6975s	
5849/28500 (epoch 10.261), train_loss = 1.21074367, grad/param norm = 1.6839e-01, time/batch = 0.6952s	
5850/28500 (epoch 10.263), train_loss = 1.42701185, grad/param norm = 1.7713e-01, time/batch = 0.6942s	
5851/28500 (epoch 10.265), train_loss = 1.29821889, grad/param norm = 1.6776e-01, time/batch = 0.6927s	
5852/28500 (epoch 10.267), train_loss = 1.44485104, grad/param norm = 1.7769e-01, time/batch = 0.6918s	
5853/28500 (epoch 10.268), train_loss = 1.36714952, grad/param norm = 1.5571e-01, time/batch = 0.6897s	
5854/28500 (epoch 10.270), train_loss = 1.31572572, grad/param norm = 1.7433e-01, time/batch = 0.6908s	
5855/28500 (epoch 10.272), train_loss = 1.26078117, grad/param norm = 1.6382e-01, time/batch = 0.6906s	
5856/28500 (epoch 10.274), train_loss = 1.41508548, grad/param norm = 1.7518e-01, time/batch = 0.6898s	
5857/28500 (epoch 10.275), train_loss = 1.33742159, grad/param norm = 1.6129e-01, time/batch = 0.6905s	
5858/28500 (epoch 10.277), train_loss = 1.29085822, grad/param norm = 1.6173e-01, time/batch = 0.6906s	
5859/28500 (epoch 10.279), train_loss = 1.32821765, grad/param norm = 1.7669e-01, time/batch = 0.6900s	
5860/28500 (epoch 10.281), train_loss = 1.33957962, grad/param norm = 1.6419e-01, time/batch = 0.6946s	
5861/28500 (epoch 10.282), train_loss = 1.16716392, grad/param norm = 1.4311e-01, time/batch = 0.6922s	
5862/28500 (epoch 10.284), train_loss = 1.32841810, grad/param norm = 1.6789e-01, time/batch = 0.6906s	
5863/28500 (epoch 10.286), train_loss = 1.38815991, grad/param norm = 1.6306e-01, time/batch = 0.6901s	
5864/28500 (epoch 10.288), train_loss = 1.30158936, grad/param norm = 1.5207e-01, time/batch = 0.6902s	
5865/28500 (epoch 10.289), train_loss = 1.43115629, grad/param norm = 1.6885e-01, time/batch = 0.6913s	
5866/28500 (epoch 10.291), train_loss = 1.26928325, grad/param norm = 1.6254e-01, time/batch = 0.6917s	
5867/28500 (epoch 10.293), train_loss = 1.23885654, grad/param norm = 1.6493e-01, time/batch = 0.6896s	
5868/28500 (epoch 10.295), train_loss = 1.17182755, grad/param norm = 1.5290e-01, time/batch = 0.6914s	
5869/28500 (epoch 10.296), train_loss = 1.17835662, grad/param norm = 1.5237e-01, time/batch = 0.6932s	
5870/28500 (epoch 10.298), train_loss = 1.30543849, grad/param norm = 1.5948e-01, time/batch = 0.6899s	
5871/28500 (epoch 10.300), train_loss = 1.21320510, grad/param norm = 1.5885e-01, time/batch = 0.6924s	
5872/28500 (epoch 10.302), train_loss = 1.17765329, grad/param norm = 1.5442e-01, time/batch = 0.6916s	
5873/28500 (epoch 10.304), train_loss = 1.27164113, grad/param norm = 1.5390e-01, time/batch = 0.6906s	
5874/28500 (epoch 10.305), train_loss = 1.34775027, grad/param norm = 1.5902e-01, time/batch = 0.6935s	
5875/28500 (epoch 10.307), train_loss = 1.32484626, grad/param norm = 1.7964e-01, time/batch = 0.6951s	
5876/28500 (epoch 10.309), train_loss = 1.29303906, grad/param norm = 1.7421e-01, time/batch = 0.6931s	
5877/28500 (epoch 10.311), train_loss = 1.29752410, grad/param norm = 1.6718e-01, time/batch = 0.6921s	
5878/28500 (epoch 10.312), train_loss = 1.21826678, grad/param norm = 1.6104e-01, time/batch = 0.6922s	
5879/28500 (epoch 10.314), train_loss = 1.37584314, grad/param norm = 1.7484e-01, time/batch = 0.6926s	
5880/28500 (epoch 10.316), train_loss = 1.33776812, grad/param norm = 1.5131e-01, time/batch = 0.6944s	
5881/28500 (epoch 10.318), train_loss = 1.35330454, grad/param norm = 1.8203e-01, time/batch = 0.6937s	
5882/28500 (epoch 10.319), train_loss = 1.27479149, grad/param norm = 1.6777e-01, time/batch = 0.6925s	
5883/28500 (epoch 10.321), train_loss = 1.32707660, grad/param norm = 1.8395e-01, time/batch = 0.6902s	
5884/28500 (epoch 10.323), train_loss = 1.25057646, grad/param norm = 1.7441e-01, time/batch = 0.6937s	
5885/28500 (epoch 10.325), train_loss = 1.45283617, grad/param norm = 1.6797e-01, time/batch = 0.6952s	
5886/28500 (epoch 10.326), train_loss = 1.31182770, grad/param norm = 1.7552e-01, time/batch = 0.6897s	
5887/28500 (epoch 10.328), train_loss = 1.06699428, grad/param norm = 1.4572e-01, time/batch = 0.6910s	
5888/28500 (epoch 10.330), train_loss = 1.18063894, grad/param norm = 1.5653e-01, time/batch = 0.6910s	
5889/28500 (epoch 10.332), train_loss = 1.26711674, grad/param norm = 1.5448e-01, time/batch = 0.6891s	
5890/28500 (epoch 10.333), train_loss = 1.11069683, grad/param norm = 1.5560e-01, time/batch = 0.6916s	
5891/28500 (epoch 10.335), train_loss = 1.15662978, grad/param norm = 1.3859e-01, time/batch = 0.6945s	
5892/28500 (epoch 10.337), train_loss = 1.23866047, grad/param norm = 1.6892e-01, time/batch = 0.6927s	
5893/28500 (epoch 10.339), train_loss = 1.14881946, grad/param norm = 1.4842e-01, time/batch = 0.6896s	
5894/28500 (epoch 10.340), train_loss = 1.33946733, grad/param norm = 1.6540e-01, time/batch = 0.6915s	
5895/28500 (epoch 10.342), train_loss = 1.25152176, grad/param norm = 1.7385e-01, time/batch = 0.6901s	
5896/28500 (epoch 10.344), train_loss = 1.20618962, grad/param norm = 1.5848e-01, time/batch = 0.6950s	
5897/28500 (epoch 10.346), train_loss = 1.01102057, grad/param norm = 1.3553e-01, time/batch = 0.6905s	
5898/28500 (epoch 10.347), train_loss = 1.25137933, grad/param norm = 1.5061e-01, time/batch = 0.7435s	
5899/28500 (epoch 10.349), train_loss = 1.19402353, grad/param norm = 1.4770e-01, time/batch = 1.0151s	
5900/28500 (epoch 10.351), train_loss = 1.17364020, grad/param norm = 1.5168e-01, time/batch = 1.0094s	
5901/28500 (epoch 10.353), train_loss = 1.33008544, grad/param norm = 1.7613e-01, time/batch = 1.0143s	
5902/28500 (epoch 10.354), train_loss = 1.12407689, grad/param norm = 1.4861e-01, time/batch = 1.0062s	
5903/28500 (epoch 10.356), train_loss = 1.17988490, grad/param norm = 1.4679e-01, time/batch = 1.2369s	
5904/28500 (epoch 10.358), train_loss = 1.26691056, grad/param norm = 1.4789e-01, time/batch = 1.8913s	
5905/28500 (epoch 10.360), train_loss = 1.30418326, grad/param norm = 1.7453e-01, time/batch = 1.8942s	
5906/28500 (epoch 10.361), train_loss = 1.18703804, grad/param norm = 1.5545e-01, time/batch = 10.3478s	
5907/28500 (epoch 10.363), train_loss = 1.15458312, grad/param norm = 1.4998e-01, time/batch = 15.3810s	
5908/28500 (epoch 10.365), train_loss = 1.21275734, grad/param norm = 1.5964e-01, time/batch = 15.1425s	
5909/28500 (epoch 10.367), train_loss = 1.24925370, grad/param norm = 1.5424e-01, time/batch = 15.5004s	
5910/28500 (epoch 10.368), train_loss = 1.21415990, grad/param norm = 1.4780e-01, time/batch = 15.5962s	
5911/28500 (epoch 10.370), train_loss = 1.28913153, grad/param norm = 1.5871e-01, time/batch = 15.4693s	
5912/28500 (epoch 10.372), train_loss = 1.11216453, grad/param norm = 1.5558e-01, time/batch = 14.9830s	
5913/28500 (epoch 10.374), train_loss = 1.25958717, grad/param norm = 1.5520e-01, time/batch = 15.5189s	
5914/28500 (epoch 10.375), train_loss = 1.40355753, grad/param norm = 1.6907e-01, time/batch = 15.5065s	
5915/28500 (epoch 10.377), train_loss = 1.18514684, grad/param norm = 1.5758e-01, time/batch = 15.4853s	
5916/28500 (epoch 10.379), train_loss = 1.02072319, grad/param norm = 1.3941e-01, time/batch = 15.3748s	
5917/28500 (epoch 10.381), train_loss = 1.21340582, grad/param norm = 1.4270e-01, time/batch = 15.3713s	
5918/28500 (epoch 10.382), train_loss = 1.19099525, grad/param norm = 1.5357e-01, time/batch = 15.3866s	
5919/28500 (epoch 10.384), train_loss = 1.12235960, grad/param norm = 1.4255e-01, time/batch = 15.4651s	
5920/28500 (epoch 10.386), train_loss = 1.14342767, grad/param norm = 1.7077e-01, time/batch = 15.3846s	
5921/28500 (epoch 10.388), train_loss = 1.34834276, grad/param norm = 1.6003e-01, time/batch = 15.6277s	
5922/28500 (epoch 10.389), train_loss = 1.16859823, grad/param norm = 1.5971e-01, time/batch = 15.5293s	
5923/28500 (epoch 10.391), train_loss = 1.17300426, grad/param norm = 1.6007e-01, time/batch = 15.3004s	
5924/28500 (epoch 10.393), train_loss = 1.10162972, grad/param norm = 1.5413e-01, time/batch = 15.1595s	
5925/28500 (epoch 10.395), train_loss = 1.44434728, grad/param norm = 1.7325e-01, time/batch = 15.2969s	
5926/28500 (epoch 10.396), train_loss = 1.35575427, grad/param norm = 1.6482e-01, time/batch = 15.3714s	
5927/28500 (epoch 10.398), train_loss = 1.08441161, grad/param norm = 2.1586e-01, time/batch = 15.1474s	
5928/28500 (epoch 10.400), train_loss = 1.31165781, grad/param norm = 1.8461e-01, time/batch = 15.4042s	
5929/28500 (epoch 10.402), train_loss = 1.24808706, grad/param norm = 1.5363e-01, time/batch = 15.5613s	
5930/28500 (epoch 10.404), train_loss = 1.38048288, grad/param norm = 1.9367e-01, time/batch = 15.2895s	
5931/28500 (epoch 10.405), train_loss = 1.37179041, grad/param norm = 1.6699e-01, time/batch = 15.5897s	
5932/28500 (epoch 10.407), train_loss = 1.29057994, grad/param norm = 1.6250e-01, time/batch = 15.3105s	
5933/28500 (epoch 10.409), train_loss = 1.28990096, grad/param norm = 1.6251e-01, time/batch = 15.4610s	
5934/28500 (epoch 10.411), train_loss = 1.35901070, grad/param norm = 1.6248e-01, time/batch = 15.6320s	
5935/28500 (epoch 10.412), train_loss = 1.45651525, grad/param norm = 1.9619e-01, time/batch = 15.5465s	
5936/28500 (epoch 10.414), train_loss = 1.29926475, grad/param norm = 1.7932e-01, time/batch = 15.4385s	
5937/28500 (epoch 10.416), train_loss = 1.23174678, grad/param norm = 1.8115e-01, time/batch = 15.4148s	
5938/28500 (epoch 10.418), train_loss = 1.27190685, grad/param norm = 1.4477e-01, time/batch = 15.5257s	
5939/28500 (epoch 10.419), train_loss = 1.41289033, grad/param norm = 1.6906e-01, time/batch = 15.4341s	
5940/28500 (epoch 10.421), train_loss = 1.34418238, grad/param norm = 1.5724e-01, time/batch = 15.5509s	
5941/28500 (epoch 10.423), train_loss = 1.41356895, grad/param norm = 1.7227e-01, time/batch = 15.6602s	
5942/28500 (epoch 10.425), train_loss = 1.32360371, grad/param norm = 1.7405e-01, time/batch = 15.1835s	
5943/28500 (epoch 10.426), train_loss = 1.28649269, grad/param norm = 1.7508e-01, time/batch = 15.2147s	
5944/28500 (epoch 10.428), train_loss = 1.51089874, grad/param norm = 1.7800e-01, time/batch = 15.2725s	
5945/28500 (epoch 10.430), train_loss = 1.39805894, grad/param norm = 1.6401e-01, time/batch = 15.5274s	
5946/28500 (epoch 10.432), train_loss = 1.32988631, grad/param norm = 1.7045e-01, time/batch = 15.3612s	
5947/28500 (epoch 10.433), train_loss = 1.36771109, grad/param norm = 1.8375e-01, time/batch = 15.4322s	
5948/28500 (epoch 10.435), train_loss = 1.26846420, grad/param norm = 1.6431e-01, time/batch = 15.3839s	
5949/28500 (epoch 10.437), train_loss = 1.13460172, grad/param norm = 1.4533e-01, time/batch = 15.3653s	
5950/28500 (epoch 10.439), train_loss = 1.18538908, grad/param norm = 1.4830e-01, time/batch = 15.4708s	
5951/28500 (epoch 10.440), train_loss = 1.44294590, grad/param norm = 1.7357e-01, time/batch = 15.3724s	
5952/28500 (epoch 10.442), train_loss = 1.16925483, grad/param norm = 1.6469e-01, time/batch = 15.2960s	
5953/28500 (epoch 10.444), train_loss = 1.11778407, grad/param norm = 1.3779e-01, time/batch = 15.3656s	
5954/28500 (epoch 10.446), train_loss = 1.06852421, grad/param norm = 1.5223e-01, time/batch = 15.4479s	
5955/28500 (epoch 10.447), train_loss = 1.11822082, grad/param norm = 1.4866e-01, time/batch = 15.2339s	
5956/28500 (epoch 10.449), train_loss = 1.17692261, grad/param norm = 1.5250e-01, time/batch = 15.1240s	
5957/28500 (epoch 10.451), train_loss = 1.21243307, grad/param norm = 1.5791e-01, time/batch = 15.4399s	
5958/28500 (epoch 10.453), train_loss = 1.25987013, grad/param norm = 1.7600e-01, time/batch = 15.5280s	
5959/28500 (epoch 10.454), train_loss = 1.18840486, grad/param norm = 1.5190e-01, time/batch = 15.2750s	
5960/28500 (epoch 10.456), train_loss = 1.32223766, grad/param norm = 1.5942e-01, time/batch = 15.3790s	
5961/28500 (epoch 10.458), train_loss = 1.21096001, grad/param norm = 1.6197e-01, time/batch = 15.3770s	
5962/28500 (epoch 10.460), train_loss = 1.34625734, grad/param norm = 1.7521e-01, time/batch = 15.6254s	
5963/28500 (epoch 10.461), train_loss = 1.20682837, grad/param norm = 1.5891e-01, time/batch = 15.5464s	
5964/28500 (epoch 10.463), train_loss = 1.13310077, grad/param norm = 1.3741e-01, time/batch = 15.4416s	
5965/28500 (epoch 10.465), train_loss = 1.11102203, grad/param norm = 1.7262e-01, time/batch = 15.3934s	
5966/28500 (epoch 10.467), train_loss = 1.29838006, grad/param norm = 1.6054e-01, time/batch = 15.3611s	
5967/28500 (epoch 10.468), train_loss = 1.09948033, grad/param norm = 1.3108e-01, time/batch = 15.3765s	
5968/28500 (epoch 10.470), train_loss = 1.21925687, grad/param norm = 1.7125e-01, time/batch = 15.5646s	
5969/28500 (epoch 10.472), train_loss = 1.19075319, grad/param norm = 1.5093e-01, time/batch = 15.1186s	
5970/28500 (epoch 10.474), train_loss = 1.52240714, grad/param norm = 1.9636e-01, time/batch = 15.1438s	
5971/28500 (epoch 10.475), train_loss = 1.16082359, grad/param norm = 1.4199e-01, time/batch = 15.3821s	
5972/28500 (epoch 10.477), train_loss = 1.25304692, grad/param norm = 1.5371e-01, time/batch = 15.2878s	
5973/28500 (epoch 10.479), train_loss = 1.30440149, grad/param norm = 1.5972e-01, time/batch = 15.2959s	
5974/28500 (epoch 10.481), train_loss = 1.24664128, grad/param norm = 1.6684e-01, time/batch = 15.2814s	
5975/28500 (epoch 10.482), train_loss = 1.14822314, grad/param norm = 1.6545e-01, time/batch = 15.5381s	
5976/28500 (epoch 10.484), train_loss = 1.14908712, grad/param norm = 1.5176e-01, time/batch = 15.2773s	
5977/28500 (epoch 10.486), train_loss = 1.07625087, grad/param norm = 1.6164e-01, time/batch = 15.1906s	
5978/28500 (epoch 10.488), train_loss = 1.27331301, grad/param norm = 1.5324e-01, time/batch = 14.9838s	
5979/28500 (epoch 10.489), train_loss = 1.35582636, grad/param norm = 1.6199e-01, time/batch = 15.0454s	
5980/28500 (epoch 10.491), train_loss = 1.19669253, grad/param norm = 1.5428e-01, time/batch = 15.2434s	
5981/28500 (epoch 10.493), train_loss = 1.18318456, grad/param norm = 1.5101e-01, time/batch = 15.2728s	
5982/28500 (epoch 10.495), train_loss = 1.17039226, grad/param norm = 1.5045e-01, time/batch = 15.3284s	
5983/28500 (epoch 10.496), train_loss = 1.22111916, grad/param norm = 1.6515e-01, time/batch = 15.2864s	
5984/28500 (epoch 10.498), train_loss = 1.31490168, grad/param norm = 1.6179e-01, time/batch = 15.5142s	
5985/28500 (epoch 10.500), train_loss = 1.23104984, grad/param norm = 1.5869e-01, time/batch = 15.3854s	
5986/28500 (epoch 10.502), train_loss = 1.34421035, grad/param norm = 1.5079e-01, time/batch = 15.2980s	
5987/28500 (epoch 10.504), train_loss = 1.31126367, grad/param norm = 1.5317e-01, time/batch = 15.9514s	
5988/28500 (epoch 10.505), train_loss = 1.15405947, grad/param norm = 1.4304e-01, time/batch = 26.9818s	
5989/28500 (epoch 10.507), train_loss = 1.36884934, grad/param norm = 1.7571e-01, time/batch = 15.3049s	
5990/28500 (epoch 10.509), train_loss = 1.26276562, grad/param norm = 1.5660e-01, time/batch = 15.3046s	
5991/28500 (epoch 10.511), train_loss = 1.24121307, grad/param norm = 1.5838e-01, time/batch = 15.3790s	
5992/28500 (epoch 10.512), train_loss = 1.26663447, grad/param norm = 1.6265e-01, time/batch = 15.2250s	
5993/28500 (epoch 10.514), train_loss = 1.12775322, grad/param norm = 1.4390e-01, time/batch = 15.1451s	
5994/28500 (epoch 10.516), train_loss = 1.16896720, grad/param norm = 1.4284e-01, time/batch = 15.2297s	
5995/28500 (epoch 10.518), train_loss = 1.22557161, grad/param norm = 1.4225e-01, time/batch = 15.2658s	
5996/28500 (epoch 10.519), train_loss = 1.29944787, grad/param norm = 1.5368e-01, time/batch = 15.1221s	
5997/28500 (epoch 10.521), train_loss = 1.41127701, grad/param norm = 1.6538e-01, time/batch = 15.1211s	
5998/28500 (epoch 10.523), train_loss = 1.30468172, grad/param norm = 1.8157e-01, time/batch = 15.4347s	
5999/28500 (epoch 10.525), train_loss = 1.36651277, grad/param norm = 1.7244e-01, time/batch = 15.4602s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch10.53_1.6016.t7	
6000/28500 (epoch 10.526), train_loss = 1.30609430, grad/param norm = 1.6757e-01, time/batch = 15.5493s	
6001/28500 (epoch 10.528), train_loss = 1.53511192, grad/param norm = 1.8354e-01, time/batch = 15.7852s	
6002/28500 (epoch 10.530), train_loss = 1.37214611, grad/param norm = 1.5250e-01, time/batch = 15.3762s	
6003/28500 (epoch 10.532), train_loss = 1.22255363, grad/param norm = 1.7212e-01, time/batch = 15.3819s	
6004/28500 (epoch 10.533), train_loss = 1.36448039, grad/param norm = 1.5383e-01, time/batch = 15.8060s	
6005/28500 (epoch 10.535), train_loss = 1.07851310, grad/param norm = 1.4603e-01, time/batch = 15.6347s	
6006/28500 (epoch 10.537), train_loss = 1.08627244, grad/param norm = 1.5492e-01, time/batch = 15.7041s	
6007/28500 (epoch 10.539), train_loss = 1.11922611, grad/param norm = 1.5130e-01, time/batch = 15.7172s	
6008/28500 (epoch 10.540), train_loss = 1.23011446, grad/param norm = 1.4264e-01, time/batch = 15.4383s	
6009/28500 (epoch 10.542), train_loss = 1.43573680, grad/param norm = 1.7871e-01, time/batch = 15.2213s	
6010/28500 (epoch 10.544), train_loss = 1.42894544, grad/param norm = 1.6564e-01, time/batch = 15.1307s	
6011/28500 (epoch 10.546), train_loss = 1.26343367, grad/param norm = 1.6568e-01, time/batch = 15.3079s	
6012/28500 (epoch 10.547), train_loss = 1.23972257, grad/param norm = 1.4311e-01, time/batch = 15.1390s	
6013/28500 (epoch 10.549), train_loss = 1.08727642, grad/param norm = 1.3639e-01, time/batch = 15.1699s	
6014/28500 (epoch 10.551), train_loss = 1.35446716, grad/param norm = 1.7666e-01, time/batch = 15.3617s	
6015/28500 (epoch 10.553), train_loss = 1.48172323, grad/param norm = 1.7782e-01, time/batch = 15.6124s	
6016/28500 (epoch 10.554), train_loss = 1.20054557, grad/param norm = 1.4896e-01, time/batch = 15.2894s	
6017/28500 (epoch 10.556), train_loss = 1.26566279, grad/param norm = 1.6590e-01, time/batch = 15.2241s	
6018/28500 (epoch 10.558), train_loss = 1.29961352, grad/param norm = 1.6728e-01, time/batch = 15.3462s	
6019/28500 (epoch 10.560), train_loss = 1.30504267, grad/param norm = 1.6628e-01, time/batch = 15.5570s	
6020/28500 (epoch 10.561), train_loss = 1.35908657, grad/param norm = 1.7945e-01, time/batch = 15.6400s	
6021/28500 (epoch 10.563), train_loss = 1.40003297, grad/param norm = 1.7192e-01, time/batch = 15.5522s	
6022/28500 (epoch 10.565), train_loss = 1.23410911, grad/param norm = 1.6053e-01, time/batch = 15.4686s	
6023/28500 (epoch 10.567), train_loss = 1.10526398, grad/param norm = 1.6287e-01, time/batch = 15.3007s	
6024/28500 (epoch 10.568), train_loss = 1.29831446, grad/param norm = 1.6421e-01, time/batch = 15.1628s	
6025/28500 (epoch 10.570), train_loss = 1.20633529, grad/param norm = 1.6743e-01, time/batch = 15.2091s	
6026/28500 (epoch 10.572), train_loss = 1.21159193, grad/param norm = 1.7015e-01, time/batch = 15.5149s	
6027/28500 (epoch 10.574), train_loss = 1.26080090, grad/param norm = 1.6340e-01, time/batch = 15.3380s	
6028/28500 (epoch 10.575), train_loss = 1.21251918, grad/param norm = 1.6224e-01, time/batch = 15.1349s	
6029/28500 (epoch 10.577), train_loss = 1.23733616, grad/param norm = 1.4885e-01, time/batch = 15.0810s	
6030/28500 (epoch 10.579), train_loss = 1.34761679, grad/param norm = 1.6890e-01, time/batch = 15.4629s	
6031/28500 (epoch 10.581), train_loss = 1.21712652, grad/param norm = 1.6983e-01, time/batch = 15.6128s	
6032/28500 (epoch 10.582), train_loss = 1.35070343, grad/param norm = 1.6232e-01, time/batch = 15.0605s	
6033/28500 (epoch 10.584), train_loss = 1.20229769, grad/param norm = 1.4719e-01, time/batch = 15.2602s	
6034/28500 (epoch 10.586), train_loss = 1.14963953, grad/param norm = 1.4516e-01, time/batch = 15.2935s	
6035/28500 (epoch 10.588), train_loss = 1.15630501, grad/param norm = 1.4770e-01, time/batch = 15.3580s	
6036/28500 (epoch 10.589), train_loss = 1.34845743, grad/param norm = 1.5677e-01, time/batch = 15.2261s	
6037/28500 (epoch 10.591), train_loss = 1.31036558, grad/param norm = 1.5560e-01, time/batch = 15.3427s	
6038/28500 (epoch 10.593), train_loss = 1.17461735, grad/param norm = 1.4771e-01, time/batch = 15.1228s	
6039/28500 (epoch 10.595), train_loss = 1.50339241, grad/param norm = 1.9121e-01, time/batch = 15.2808s	
6040/28500 (epoch 10.596), train_loss = 1.47988437, grad/param norm = 1.8522e-01, time/batch = 15.1722s	
6041/28500 (epoch 10.598), train_loss = 1.28547201, grad/param norm = 1.5530e-01, time/batch = 15.2500s	
6042/28500 (epoch 10.600), train_loss = 1.30512042, grad/param norm = 1.8085e-01, time/batch = 14.9897s	
6043/28500 (epoch 10.602), train_loss = 1.42888208, grad/param norm = 1.7165e-01, time/batch = 15.1411s	
6044/28500 (epoch 10.604), train_loss = 1.33190320, grad/param norm = 1.5690e-01, time/batch = 15.3895s	
6045/28500 (epoch 10.605), train_loss = 1.27327692, grad/param norm = 1.5338e-01, time/batch = 15.4563s	
6046/28500 (epoch 10.607), train_loss = 1.32477386, grad/param norm = 1.5188e-01, time/batch = 15.3113s	
6047/28500 (epoch 10.609), train_loss = 1.26146452, grad/param norm = 1.6868e-01, time/batch = 15.2046s	
6048/28500 (epoch 10.611), train_loss = 1.28417801, grad/param norm = 1.6139e-01, time/batch = 15.1636s	
6049/28500 (epoch 10.612), train_loss = 1.30599973, grad/param norm = 1.6093e-01, time/batch = 15.1167s	
6050/28500 (epoch 10.614), train_loss = 1.30238250, grad/param norm = 1.6148e-01, time/batch = 14.9840s	
6051/28500 (epoch 10.616), train_loss = 1.21050178, grad/param norm = 1.6528e-01, time/batch = 15.2056s	
6052/28500 (epoch 10.618), train_loss = 1.20583871, grad/param norm = 1.5279e-01, time/batch = 15.0540s	
6053/28500 (epoch 10.619), train_loss = 1.45619955, grad/param norm = 1.6997e-01, time/batch = 15.4833s	
6054/28500 (epoch 10.621), train_loss = 1.04417372, grad/param norm = 1.3305e-01, time/batch = 15.5300s	
6055/28500 (epoch 10.623), train_loss = 1.36755171, grad/param norm = 1.6481e-01, time/batch = 15.5694s	
6056/28500 (epoch 10.625), train_loss = 1.10871019, grad/param norm = 1.4830e-01, time/batch = 15.0398s	
6057/28500 (epoch 10.626), train_loss = 0.98905855, grad/param norm = 1.3959e-01, time/batch = 15.1869s	
6058/28500 (epoch 10.628), train_loss = 1.17398643, grad/param norm = 1.6176e-01, time/batch = 14.9640s	
6059/28500 (epoch 10.630), train_loss = 1.08153731, grad/param norm = 1.4272e-01, time/batch = 15.0705s	
6060/28500 (epoch 10.632), train_loss = 1.35235141, grad/param norm = 1.6581e-01, time/batch = 15.2205s	
6061/28500 (epoch 10.633), train_loss = 1.37326100, grad/param norm = 1.5904e-01, time/batch = 15.4624s	
6062/28500 (epoch 10.635), train_loss = 1.45898427, grad/param norm = 1.7099e-01, time/batch = 15.4597s	
6063/28500 (epoch 10.637), train_loss = 1.26389918, grad/param norm = 1.5777e-01, time/batch = 15.3840s	
6064/28500 (epoch 10.639), train_loss = 1.11911047, grad/param norm = 1.4628e-01, time/batch = 15.1202s	
6065/28500 (epoch 10.640), train_loss = 1.13332046, grad/param norm = 1.4746e-01, time/batch = 15.3466s	
6066/28500 (epoch 10.642), train_loss = 1.29468571, grad/param norm = 1.5019e-01, time/batch = 15.2975s	
6067/28500 (epoch 10.644), train_loss = 1.33178101, grad/param norm = 1.5309e-01, time/batch = 15.4008s	
6068/28500 (epoch 10.646), train_loss = 1.12767624, grad/param norm = 1.3471e-01, time/batch = 15.2132s	
6069/28500 (epoch 10.647), train_loss = 1.14144217, grad/param norm = 1.5696e-01, time/batch = 15.1169s	
6070/28500 (epoch 10.649), train_loss = 1.13244844, grad/param norm = 1.5533e-01, time/batch = 15.3909s	
6071/28500 (epoch 10.651), train_loss = 1.09478840, grad/param norm = 1.4124e-01, time/batch = 15.6330s	
6072/28500 (epoch 10.653), train_loss = 1.12096289, grad/param norm = 1.5023e-01, time/batch = 15.4564s	
6073/28500 (epoch 10.654), train_loss = 1.20867845, grad/param norm = 1.5112e-01, time/batch = 15.5441s	
6074/28500 (epoch 10.656), train_loss = 1.18765625, grad/param norm = 1.5875e-01, time/batch = 15.4573s	
6075/28500 (epoch 10.658), train_loss = 1.27445041, grad/param norm = 1.6812e-01, time/batch = 15.3609s	
6076/28500 (epoch 10.660), train_loss = 1.22911444, grad/param norm = 1.3956e-01, time/batch = 15.4026s	
6077/28500 (epoch 10.661), train_loss = 1.39214449, grad/param norm = 1.7276e-01, time/batch = 14.9577s	
6078/28500 (epoch 10.663), train_loss = 1.44718422, grad/param norm = 1.7325e-01, time/batch = 15.1874s	
6079/28500 (epoch 10.665), train_loss = 1.21514802, grad/param norm = 1.6705e-01, time/batch = 15.1054s	
6080/28500 (epoch 10.667), train_loss = 1.28904066, grad/param norm = 1.6072e-01, time/batch = 15.4790s	
6081/28500 (epoch 10.668), train_loss = 1.23277171, grad/param norm = 1.5329e-01, time/batch = 15.2099s	
6082/28500 (epoch 10.670), train_loss = 1.25665693, grad/param norm = 1.5374e-01, time/batch = 15.2146s	
6083/28500 (epoch 10.672), train_loss = 1.22351751, grad/param norm = 1.5882e-01, time/batch = 15.3887s	
6084/28500 (epoch 10.674), train_loss = 1.06386811, grad/param norm = 1.5511e-01, time/batch = 15.2554s	
6085/28500 (epoch 10.675), train_loss = 1.08788479, grad/param norm = 1.4931e-01, time/batch = 15.4593s	
6086/28500 (epoch 10.677), train_loss = 1.21098012, grad/param norm = 1.5354e-01, time/batch = 15.5468s	
6087/28500 (epoch 10.679), train_loss = 1.22055521, grad/param norm = 1.6302e-01, time/batch = 15.4639s	
6088/28500 (epoch 10.681), train_loss = 1.33443436, grad/param norm = 1.5998e-01, time/batch = 15.2149s	
6089/28500 (epoch 10.682), train_loss = 1.20920926, grad/param norm = 1.5551e-01, time/batch = 15.0504s	
6090/28500 (epoch 10.684), train_loss = 1.30533268, grad/param norm = 1.5904e-01, time/batch = 14.9818s	
6091/28500 (epoch 10.686), train_loss = 1.18577445, grad/param norm = 1.5967e-01, time/batch = 15.5337s	
6092/28500 (epoch 10.688), train_loss = 1.13462090, grad/param norm = 1.4245e-01, time/batch = 15.5453s	
6093/28500 (epoch 10.689), train_loss = 1.27662094, grad/param norm = 1.6762e-01, time/batch = 15.2239s	
6094/28500 (epoch 10.691), train_loss = 1.29482319, grad/param norm = 1.8097e-01, time/batch = 15.2704s	
6095/28500 (epoch 10.693), train_loss = 1.21079801, grad/param norm = 1.6233e-01, time/batch = 15.2965s	
6096/28500 (epoch 10.695), train_loss = 1.08248546, grad/param norm = 1.6960e-01, time/batch = 15.6019s	
6097/28500 (epoch 10.696), train_loss = 1.20397573, grad/param norm = 1.6268e-01, time/batch = 15.5306s	
6098/28500 (epoch 10.698), train_loss = 1.25623656, grad/param norm = 1.5366e-01, time/batch = 15.1961s	
6099/28500 (epoch 10.700), train_loss = 1.26198150, grad/param norm = 1.5039e-01, time/batch = 15.1543s	
6100/28500 (epoch 10.702), train_loss = 1.37728413, grad/param norm = 1.7791e-01, time/batch = 15.6252s	
6101/28500 (epoch 10.704), train_loss = 1.29460398, grad/param norm = 1.6412e-01, time/batch = 15.4607s	
6102/28500 (epoch 10.705), train_loss = 1.33907931, grad/param norm = 1.6455e-01, time/batch = 15.2298s	
6103/28500 (epoch 10.707), train_loss = 1.22459298, grad/param norm = 1.7471e-01, time/batch = 15.3219s	
6104/28500 (epoch 10.709), train_loss = 1.35178824, grad/param norm = 1.7033e-01, time/batch = 15.3718s	
6105/28500 (epoch 10.711), train_loss = 1.19182797, grad/param norm = 1.7900e-01, time/batch = 15.1723s	
6106/28500 (epoch 10.712), train_loss = 1.34516660, grad/param norm = 1.6629e-01, time/batch = 15.1265s	
6107/28500 (epoch 10.714), train_loss = 1.33933393, grad/param norm = 1.6837e-01, time/batch = 15.3786s	
6108/28500 (epoch 10.716), train_loss = 1.20923053, grad/param norm = 1.6078e-01, time/batch = 15.4307s	
6109/28500 (epoch 10.718), train_loss = 1.19259846, grad/param norm = 1.4813e-01, time/batch = 14.9838s	
6110/28500 (epoch 10.719), train_loss = 1.22171789, grad/param norm = 1.5602e-01, time/batch = 15.1829s	
6111/28500 (epoch 10.721), train_loss = 1.04690437, grad/param norm = 1.4503e-01, time/batch = 15.3605s	
6112/28500 (epoch 10.723), train_loss = 1.23359126, grad/param norm = 1.6881e-01, time/batch = 15.3717s	
6113/28500 (epoch 10.725), train_loss = 1.34707520, grad/param norm = 1.4756e-01, time/batch = 15.3632s	
6114/28500 (epoch 10.726), train_loss = 1.25636145, grad/param norm = 1.4946e-01, time/batch = 15.2944s	
6115/28500 (epoch 10.728), train_loss = 1.09296420, grad/param norm = 1.3548e-01, time/batch = 15.5626s	
6116/28500 (epoch 10.730), train_loss = 1.29822230, grad/param norm = 1.8147e-01, time/batch = 15.2952s	
6117/28500 (epoch 10.732), train_loss = 1.07364254, grad/param norm = 1.4987e-01, time/batch = 15.3938s	
6118/28500 (epoch 10.733), train_loss = 1.04682582, grad/param norm = 1.3907e-01, time/batch = 15.1930s	
6119/28500 (epoch 10.735), train_loss = 1.06642887, grad/param norm = 1.3797e-01, time/batch = 15.4530s	
6120/28500 (epoch 10.737), train_loss = 1.03724662, grad/param norm = 1.3450e-01, time/batch = 15.4782s	
6121/28500 (epoch 10.739), train_loss = 1.20174202, grad/param norm = 1.6408e-01, time/batch = 15.6085s	
6122/28500 (epoch 10.740), train_loss = 1.23717745, grad/param norm = 1.6052e-01, time/batch = 15.4079s	
6123/28500 (epoch 10.742), train_loss = 1.14607280, grad/param norm = 1.5124e-01, time/batch = 15.4002s	
6124/28500 (epoch 10.744), train_loss = 1.28962626, grad/param norm = 1.6819e-01, time/batch = 15.3211s	
6125/28500 (epoch 10.746), train_loss = 1.12062039, grad/param norm = 1.4219e-01, time/batch = 15.1778s	
6126/28500 (epoch 10.747), train_loss = 1.14045056, grad/param norm = 1.5323e-01, time/batch = 15.1546s	
6127/28500 (epoch 10.749), train_loss = 1.40538537, grad/param norm = 1.8113e-01, time/batch = 15.2851s	
6128/28500 (epoch 10.751), train_loss = 1.15282070, grad/param norm = 1.7721e-01, time/batch = 15.5469s	
6129/28500 (epoch 10.753), train_loss = 1.13015652, grad/param norm = 1.4039e-01, time/batch = 15.3650s	
6130/28500 (epoch 10.754), train_loss = 1.06807101, grad/param norm = 1.5522e-01, time/batch = 15.3015s	
6131/28500 (epoch 10.756), train_loss = 1.33525941, grad/param norm = 1.5866e-01, time/batch = 15.6005s	
6132/28500 (epoch 10.758), train_loss = 1.27900499, grad/param norm = 1.5483e-01, time/batch = 15.3511s	
6133/28500 (epoch 10.760), train_loss = 1.07852975, grad/param norm = 1.5054e-01, time/batch = 15.5310s	
6134/28500 (epoch 10.761), train_loss = 1.11729922, grad/param norm = 1.6722e-01, time/batch = 15.4111s	
6135/28500 (epoch 10.763), train_loss = 0.98912004, grad/param norm = 1.4567e-01, time/batch = 15.3001s	
6136/28500 (epoch 10.765), train_loss = 1.15563791, grad/param norm = 1.5325e-01, time/batch = 15.1618s	
6137/28500 (epoch 10.767), train_loss = 1.02633290, grad/param norm = 1.3833e-01, time/batch = 15.1381s	
6138/28500 (epoch 10.768), train_loss = 1.34465760, grad/param norm = 1.6948e-01, time/batch = 15.0558s	
6139/28500 (epoch 10.770), train_loss = 1.06255707, grad/param norm = 1.5653e-01, time/batch = 15.4301s	
6140/28500 (epoch 10.772), train_loss = 0.96443301, grad/param norm = 1.4119e-01, time/batch = 15.5279s	
6141/28500 (epoch 10.774), train_loss = 1.26244929, grad/param norm = 1.6202e-01, time/batch = 15.4575s	
6142/28500 (epoch 10.775), train_loss = 1.29108978, grad/param norm = 1.5515e-01, time/batch = 15.2226s	
6143/28500 (epoch 10.777), train_loss = 1.27911504, grad/param norm = 1.5482e-01, time/batch = 15.5312s	
6144/28500 (epoch 10.779), train_loss = 1.04748871, grad/param norm = 1.3809e-01, time/batch = 15.3744s	
6145/28500 (epoch 10.781), train_loss = 1.27549293, grad/param norm = 1.6859e-01, time/batch = 15.2243s	
6146/28500 (epoch 10.782), train_loss = 1.32060950, grad/param norm = 1.7832e-01, time/batch = 15.2319s	
6147/28500 (epoch 10.784), train_loss = 1.03041136, grad/param norm = 1.3641e-01, time/batch = 15.2297s	
6148/28500 (epoch 10.786), train_loss = 1.13813663, grad/param norm = 1.3728e-01, time/batch = 15.0516s	
6149/28500 (epoch 10.788), train_loss = 1.26737048, grad/param norm = 1.6407e-01, time/batch = 15.3623s	
6150/28500 (epoch 10.789), train_loss = 0.96748355, grad/param norm = 1.5183e-01, time/batch = 15.0811s	
6151/28500 (epoch 10.791), train_loss = 1.21375391, grad/param norm = 1.6999e-01, time/batch = 15.4495s	
6152/28500 (epoch 10.793), train_loss = 1.15354278, grad/param norm = 1.6351e-01, time/batch = 15.3212s	
6153/28500 (epoch 10.795), train_loss = 1.22548238, grad/param norm = 1.4999e-01, time/batch = 15.3194s	
6154/28500 (epoch 10.796), train_loss = 1.11413926, grad/param norm = 1.5281e-01, time/batch = 15.6054s	
6155/28500 (epoch 10.798), train_loss = 1.07836277, grad/param norm = 1.9252e-01, time/batch = 15.2798s	
6156/28500 (epoch 10.800), train_loss = 1.10921627, grad/param norm = 1.5065e-01, time/batch = 15.3853s	
6157/28500 (epoch 10.802), train_loss = 1.22563022, grad/param norm = 1.7813e-01, time/batch = 15.5951s	
6158/28500 (epoch 10.804), train_loss = 1.20601429, grad/param norm = 1.6108e-01, time/batch = 15.3586s	
6159/28500 (epoch 10.805), train_loss = 1.23576887, grad/param norm = 1.8041e-01, time/batch = 15.2174s	
6160/28500 (epoch 10.807), train_loss = 1.30453551, grad/param norm = 1.6727e-01, time/batch = 15.2475s	
6161/28500 (epoch 10.809), train_loss = 1.20010702, grad/param norm = 1.6608e-01, time/batch = 15.2570s	
6162/28500 (epoch 10.811), train_loss = 1.29754636, grad/param norm = 1.7157e-01, time/batch = 15.6416s	
6163/28500 (epoch 10.812), train_loss = 1.26440839, grad/param norm = 1.6325e-01, time/batch = 15.4340s	
6164/28500 (epoch 10.814), train_loss = 1.20411225, grad/param norm = 1.6699e-01, time/batch = 15.2366s	
6165/28500 (epoch 10.816), train_loss = 1.36116375, grad/param norm = 1.6800e-01, time/batch = 15.3889s	
6166/28500 (epoch 10.818), train_loss = 1.29094035, grad/param norm = 1.5210e-01, time/batch = 15.5352s	
6167/28500 (epoch 10.819), train_loss = 1.22179987, grad/param norm = 1.5185e-01, time/batch = 15.2836s	
6168/28500 (epoch 10.821), train_loss = 1.15340149, grad/param norm = 1.6109e-01, time/batch = 15.2161s	
6169/28500 (epoch 10.823), train_loss = 1.42207369, grad/param norm = 1.8704e-01, time/batch = 15.2034s	
6170/28500 (epoch 10.825), train_loss = 1.18818144, grad/param norm = 1.6713e-01, time/batch = 15.2228s	
6171/28500 (epoch 10.826), train_loss = 1.29044711, grad/param norm = 1.7101e-01, time/batch = 15.4537s	
6172/28500 (epoch 10.828), train_loss = 1.10319469, grad/param norm = 1.6400e-01, time/batch = 15.3908s	
6173/28500 (epoch 10.830), train_loss = 1.17045096, grad/param norm = 1.5632e-01, time/batch = 15.3484s	
6174/28500 (epoch 10.832), train_loss = 1.22122465, grad/param norm = 1.6592e-01, time/batch = 15.4936s	
6175/28500 (epoch 10.833), train_loss = 1.39460691, grad/param norm = 1.6144e-01, time/batch = 14.9848s	
6176/28500 (epoch 10.835), train_loss = 1.17120667, grad/param norm = 1.5122e-01, time/batch = 15.2914s	
6177/28500 (epoch 10.837), train_loss = 1.07694216, grad/param norm = 1.5395e-01, time/batch = 15.2908s	
6178/28500 (epoch 10.839), train_loss = 1.33661020, grad/param norm = 1.8155e-01, time/batch = 15.2085s	
6179/28500 (epoch 10.840), train_loss = 1.34200682, grad/param norm = 1.6613e-01, time/batch = 15.0522s	
6180/28500 (epoch 10.842), train_loss = 1.30139750, grad/param norm = 1.7092e-01, time/batch = 15.2778s	
6181/28500 (epoch 10.844), train_loss = 1.25053315, grad/param norm = 1.6262e-01, time/batch = 15.2136s	
6182/28500 (epoch 10.846), train_loss = 1.37733749, grad/param norm = 1.7326e-01, time/batch = 15.2081s	
6183/28500 (epoch 10.847), train_loss = 1.17068751, grad/param norm = 1.5121e-01, time/batch = 15.0599s	
6184/28500 (epoch 10.849), train_loss = 1.18464873, grad/param norm = 1.5460e-01, time/batch = 15.1984s	
6185/28500 (epoch 10.851), train_loss = 1.06535063, grad/param norm = 1.5208e-01, time/batch = 15.3784s	
6186/28500 (epoch 10.853), train_loss = 1.23690084, grad/param norm = 1.6288e-01, time/batch = 15.2592s	
6187/28500 (epoch 10.854), train_loss = 1.24654351, grad/param norm = 1.6247e-01, time/batch = 15.3345s	
6188/28500 (epoch 10.856), train_loss = 1.33393809, grad/param norm = 1.7427e-01, time/batch = 15.1692s	
6189/28500 (epoch 10.858), train_loss = 1.07739739, grad/param norm = 1.4337e-01, time/batch = 15.2664s	
6190/28500 (epoch 10.860), train_loss = 1.27628286, grad/param norm = 1.7412e-01, time/batch = 15.3620s	
6191/28500 (epoch 10.861), train_loss = 1.23987097, grad/param norm = 1.6968e-01, time/batch = 14.9880s	
6192/28500 (epoch 10.863), train_loss = 1.34265512, grad/param norm = 1.6401e-01, time/batch = 14.9058s	
6193/28500 (epoch 10.865), train_loss = 1.21555313, grad/param norm = 1.5617e-01, time/batch = 15.2870s	
6194/28500 (epoch 10.867), train_loss = 1.29810765, grad/param norm = 1.8325e-01, time/batch = 15.2169s	
6195/28500 (epoch 10.868), train_loss = 1.09734580, grad/param norm = 1.4508e-01, time/batch = 15.3971s	
6196/28500 (epoch 10.870), train_loss = 1.03178376, grad/param norm = 1.4089e-01, time/batch = 15.3987s	
6197/28500 (epoch 10.872), train_loss = 1.27505814, grad/param norm = 1.7750e-01, time/batch = 15.5485s	
6198/28500 (epoch 10.874), train_loss = 1.24883379, grad/param norm = 1.8096e-01, time/batch = 15.2735s	
6199/28500 (epoch 10.875), train_loss = 1.32843888, grad/param norm = 1.6514e-01, time/batch = 15.2926s	
6200/28500 (epoch 10.877), train_loss = 1.24841979, grad/param norm = 1.6269e-01, time/batch = 15.2607s	
6201/28500 (epoch 10.879), train_loss = 1.21502487, grad/param norm = 1.5529e-01, time/batch = 15.4785s	
6202/28500 (epoch 10.881), train_loss = 1.26180367, grad/param norm = 1.5730e-01, time/batch = 15.4576s	
6203/28500 (epoch 10.882), train_loss = 1.18592427, grad/param norm = 1.5247e-01, time/batch = 15.3830s	
6204/28500 (epoch 10.884), train_loss = 1.25895381, grad/param norm = 1.6535e-01, time/batch = 15.3058s	
6205/28500 (epoch 10.886), train_loss = 1.14799290, grad/param norm = 1.4131e-01, time/batch = 15.3700s	
6206/28500 (epoch 10.888), train_loss = 1.09119475, grad/param norm = 1.4948e-01, time/batch = 15.4729s	
6207/28500 (epoch 10.889), train_loss = 1.21149073, grad/param norm = 1.5399e-01, time/batch = 15.3630s	
6208/28500 (epoch 10.891), train_loss = 1.24575363, grad/param norm = 1.5642e-01, time/batch = 15.1412s	
6209/28500 (epoch 10.893), train_loss = 1.16839928, grad/param norm = 1.6922e-01, time/batch = 15.2923s	
6210/28500 (epoch 10.895), train_loss = 1.40905758, grad/param norm = 1.7967e-01, time/batch = 15.2303s	
6211/28500 (epoch 10.896), train_loss = 1.32366809, grad/param norm = 1.7395e-01, time/batch = 15.1306s	
6212/28500 (epoch 10.898), train_loss = 1.19254211, grad/param norm = 1.5418e-01, time/batch = 20.7563s	
6213/28500 (epoch 10.900), train_loss = 1.08619994, grad/param norm = 1.4838e-01, time/batch = 22.5468s	
6214/28500 (epoch 10.902), train_loss = 1.09458368, grad/param norm = 1.4860e-01, time/batch = 15.0377s	
6215/28500 (epoch 10.904), train_loss = 1.11253619, grad/param norm = 1.4742e-01, time/batch = 15.2134s	
6216/28500 (epoch 10.905), train_loss = 1.24451225, grad/param norm = 1.5801e-01, time/batch = 15.3652s	
6217/28500 (epoch 10.907), train_loss = 1.27587589, grad/param norm = 1.6921e-01, time/batch = 15.0707s	
6218/28500 (epoch 10.909), train_loss = 1.08397758, grad/param norm = 1.6867e-01, time/batch = 15.0320s	
6219/28500 (epoch 10.911), train_loss = 1.13311433, grad/param norm = 1.4785e-01, time/batch = 15.2953s	
6220/28500 (epoch 10.912), train_loss = 0.96759875, grad/param norm = 1.3330e-01, time/batch = 15.4558s	
6221/28500 (epoch 10.914), train_loss = 1.34818581, grad/param norm = 1.5192e-01, time/batch = 15.3971s	
6222/28500 (epoch 10.916), train_loss = 1.27540303, grad/param norm = 1.7027e-01, time/batch = 15.2375s	
6223/28500 (epoch 10.918), train_loss = 1.23039963, grad/param norm = 1.7226e-01, time/batch = 15.3125s	
6224/28500 (epoch 10.919), train_loss = 1.17687766, grad/param norm = 1.4765e-01, time/batch = 15.2976s	
6225/28500 (epoch 10.921), train_loss = 1.39999446, grad/param norm = 1.8656e-01, time/batch = 15.3072s	
6226/28500 (epoch 10.923), train_loss = 1.24891542, grad/param norm = 1.8234e-01, time/batch = 15.3925s	
6227/28500 (epoch 10.925), train_loss = 1.12229747, grad/param norm = 1.6445e-01, time/batch = 15.4865s	
6228/28500 (epoch 10.926), train_loss = 1.20785773, grad/param norm = 1.5415e-01, time/batch = 15.4368s	
6229/28500 (epoch 10.928), train_loss = 1.15790100, grad/param norm = 1.4477e-01, time/batch = 15.2997s	
6230/28500 (epoch 10.930), train_loss = 0.94577628, grad/param norm = 1.3421e-01, time/batch = 15.3813s	
6231/28500 (epoch 10.932), train_loss = 1.00727713, grad/param norm = 1.3309e-01, time/batch = 15.6021s	
6232/28500 (epoch 10.933), train_loss = 1.24626800, grad/param norm = 1.5811e-01, time/batch = 15.2358s	
6233/28500 (epoch 10.935), train_loss = 1.29828594, grad/param norm = 1.7248e-01, time/batch = 15.1900s	
6234/28500 (epoch 10.937), train_loss = 1.34971973, grad/param norm = 1.8341e-01, time/batch = 15.3281s	
6235/28500 (epoch 10.939), train_loss = 1.41712804, grad/param norm = 1.8102e-01, time/batch = 15.2745s	
6236/28500 (epoch 10.940), train_loss = 1.12066510, grad/param norm = 1.5854e-01, time/batch = 15.1166s	
6237/28500 (epoch 10.942), train_loss = 1.30737395, grad/param norm = 1.6103e-01, time/batch = 15.2484s	
6238/28500 (epoch 10.944), train_loss = 1.21774526, grad/param norm = 1.6472e-01, time/batch = 15.1323s	
6239/28500 (epoch 10.946), train_loss = 1.37260311, grad/param norm = 1.6281e-01, time/batch = 15.2713s	
6240/28500 (epoch 10.947), train_loss = 1.58162991, grad/param norm = 1.8600e-01, time/batch = 15.1767s	
6241/28500 (epoch 10.949), train_loss = 1.10649636, grad/param norm = 1.4942e-01, time/batch = 15.4285s	
6242/28500 (epoch 10.951), train_loss = 1.37476994, grad/param norm = 1.8707e-01, time/batch = 15.3107s	
6243/28500 (epoch 10.953), train_loss = 1.42594181, grad/param norm = 1.7940e-01, time/batch = 15.3808s	
6244/28500 (epoch 10.954), train_loss = 1.36158487, grad/param norm = 1.7039e-01, time/batch = 15.5594s	
6245/28500 (epoch 10.956), train_loss = 1.32127245, grad/param norm = 1.8479e-01, time/batch = 14.9899s	
6246/28500 (epoch 10.958), train_loss = 1.40462192, grad/param norm = 1.7147e-01, time/batch = 15.1045s	
6247/28500 (epoch 10.960), train_loss = 1.13140602, grad/param norm = 1.6634e-01, time/batch = 15.3858s	
6248/28500 (epoch 10.961), train_loss = 1.45914848, grad/param norm = 1.7480e-01, time/batch = 15.4022s	
6249/28500 (epoch 10.963), train_loss = 1.35046024, grad/param norm = 1.6071e-01, time/batch = 15.2135s	
6250/28500 (epoch 10.965), train_loss = 1.10969006, grad/param norm = 1.5173e-01, time/batch = 15.0487s	
6251/28500 (epoch 10.967), train_loss = 1.08839912, grad/param norm = 1.4583e-01, time/batch = 15.6810s	
6252/28500 (epoch 10.968), train_loss = 1.04445509, grad/param norm = 1.4302e-01, time/batch = 15.4612s	
6253/28500 (epoch 10.970), train_loss = 1.17165934, grad/param norm = 1.5357e-01, time/batch = 15.3638s	
6254/28500 (epoch 10.972), train_loss = 1.27994292, grad/param norm = 1.7388e-01, time/batch = 15.3554s	
6255/28500 (epoch 10.974), train_loss = 1.47437194, grad/param norm = 1.8565e-01, time/batch = 15.4308s	
6256/28500 (epoch 10.975), train_loss = 1.18375456, grad/param norm = 1.5880e-01, time/batch = 15.2659s	
6257/28500 (epoch 10.977), train_loss = 1.44649609, grad/param norm = 1.7035e-01, time/batch = 15.1393s	
6258/28500 (epoch 10.979), train_loss = 1.16523273, grad/param norm = 1.5108e-01, time/batch = 15.1890s	
6259/28500 (epoch 10.981), train_loss = 1.15119008, grad/param norm = 1.5642e-01, time/batch = 15.3765s	
6260/28500 (epoch 10.982), train_loss = 1.10395298, grad/param norm = 1.4312e-01, time/batch = 15.1545s	
6261/28500 (epoch 10.984), train_loss = 1.32708799, grad/param norm = 1.6137e-01, time/batch = 15.3144s	
6262/28500 (epoch 10.986), train_loss = 1.46823328, grad/param norm = 1.8341e-01, time/batch = 15.3801s	
6263/28500 (epoch 10.988), train_loss = 1.04345377, grad/param norm = 1.6021e-01, time/batch = 15.5533s	
6264/28500 (epoch 10.989), train_loss = 1.27701880, grad/param norm = 1.8033e-01, time/batch = 15.2952s	
6265/28500 (epoch 10.991), train_loss = 1.14861123, grad/param norm = 1.5997e-01, time/batch = 15.6412s	
6266/28500 (epoch 10.993), train_loss = 1.15191715, grad/param norm = 1.5640e-01, time/batch = 15.3056s	
6267/28500 (epoch 10.995), train_loss = 1.14573077, grad/param norm = 1.5487e-01, time/batch = 15.3979s	
6268/28500 (epoch 10.996), train_loss = 1.08706756, grad/param norm = 1.4943e-01, time/batch = 15.3857s	
6269/28500 (epoch 10.998), train_loss = 1.33349867, grad/param norm = 1.6446e-01, time/batch = 15.3723s	
decayed learning rate by a factor 0.97 to 0.0018818	
6270/28500 (epoch 11.000), train_loss = 1.15272844, grad/param norm = 1.4829e-01, time/batch = 15.5976s	
6271/28500 (epoch 11.002), train_loss = 1.39386848, grad/param norm = 1.7668e-01, time/batch = 15.6311s	
6272/28500 (epoch 11.004), train_loss = 1.18800701, grad/param norm = 1.6298e-01, time/batch = 15.4647s	
6273/28500 (epoch 11.005), train_loss = 1.31324842, grad/param norm = 1.6390e-01, time/batch = 15.3827s	
6274/28500 (epoch 11.007), train_loss = 1.08053021, grad/param norm = 1.4265e-01, time/batch = 15.3735s	
6275/28500 (epoch 11.009), train_loss = 1.31049438, grad/param norm = 1.6962e-01, time/batch = 15.5455s	
6276/28500 (epoch 11.011), train_loss = 1.19502526, grad/param norm = 1.8855e-01, time/batch = 15.2765s	
6277/28500 (epoch 11.012), train_loss = 1.05577799, grad/param norm = 1.3605e-01, time/batch = 15.1118s	
6278/28500 (epoch 11.014), train_loss = 1.10442418, grad/param norm = 1.4882e-01, time/batch = 15.2547s	
6279/28500 (epoch 11.016), train_loss = 1.18464051, grad/param norm = 1.4911e-01, time/batch = 15.0467s	
6280/28500 (epoch 11.018), train_loss = 1.26967930, grad/param norm = 1.6169e-01, time/batch = 15.2366s	
6281/28500 (epoch 11.019), train_loss = 1.32103436, grad/param norm = 1.6924e-01, time/batch = 15.5493s	
6282/28500 (epoch 11.021), train_loss = 1.26780828, grad/param norm = 1.4683e-01, time/batch = 15.2094s	
6283/28500 (epoch 11.023), train_loss = 1.19148210, grad/param norm = 1.5382e-01, time/batch = 15.3910s	
6284/28500 (epoch 11.025), train_loss = 1.21545844, grad/param norm = 1.5970e-01, time/batch = 15.2844s	
6285/28500 (epoch 11.026), train_loss = 1.25502262, grad/param norm = 1.6277e-01, time/batch = 15.2918s	
6286/28500 (epoch 11.028), train_loss = 1.28049811, grad/param norm = 1.6024e-01, time/batch = 15.3616s	
6287/28500 (epoch 11.030), train_loss = 1.31757001, grad/param norm = 1.8189e-01, time/batch = 15.3887s	
6288/28500 (epoch 11.032), train_loss = 1.31659610, grad/param norm = 1.6905e-01, time/batch = 15.3783s	
6289/28500 (epoch 11.033), train_loss = 1.41489811, grad/param norm = 1.7741e-01, time/batch = 15.5230s	
6290/28500 (epoch 11.035), train_loss = 1.27070648, grad/param norm = 1.6660e-01, time/batch = 15.4764s	
6291/28500 (epoch 11.037), train_loss = 1.31286099, grad/param norm = 1.4947e-01, time/batch = 15.4568s	
6292/28500 (epoch 11.039), train_loss = 1.38791541, grad/param norm = 1.7617e-01, time/batch = 15.4710s	
6293/28500 (epoch 11.040), train_loss = 1.39893192, grad/param norm = 1.6932e-01, time/batch = 15.5500s	
6294/28500 (epoch 11.042), train_loss = 1.31370250, grad/param norm = 1.8161e-01, time/batch = 15.5144s	
6295/28500 (epoch 11.044), train_loss = 1.23666159, grad/param norm = 1.6805e-01, time/batch = 15.4383s	
6296/28500 (epoch 11.046), train_loss = 1.45210227, grad/param norm = 1.6895e-01, time/batch = 15.2914s	
6297/28500 (epoch 11.047), train_loss = 1.35639425, grad/param norm = 1.7171e-01, time/batch = 15.1188s	
6298/28500 (epoch 11.049), train_loss = 1.26137498, grad/param norm = 1.6441e-01, time/batch = 15.1311s	
6299/28500 (epoch 11.051), train_loss = 1.20760485, grad/param norm = 1.5296e-01, time/batch = 15.1793s	
6300/28500 (epoch 11.053), train_loss = 1.29181226, grad/param norm = 1.6854e-01, time/batch = 15.4126s	
6301/28500 (epoch 11.054), train_loss = 1.33905119, grad/param norm = 1.6770e-01, time/batch = 15.3544s	
6302/28500 (epoch 11.056), train_loss = 1.09679087, grad/param norm = 1.3916e-01, time/batch = 15.1557s	
6303/28500 (epoch 11.058), train_loss = 1.12435944, grad/param norm = 1.6322e-01, time/batch = 15.0692s	
6304/28500 (epoch 11.060), train_loss = 1.31295341, grad/param norm = 1.6201e-01, time/batch = 15.2392s	
6305/28500 (epoch 11.061), train_loss = 1.28606773, grad/param norm = 1.7548e-01, time/batch = 15.2304s	
6306/28500 (epoch 11.063), train_loss = 1.33605737, grad/param norm = 1.6712e-01, time/batch = 15.1369s	
6307/28500 (epoch 11.065), train_loss = 1.36574734, grad/param norm = 1.6188e-01, time/batch = 15.1528s	
6308/28500 (epoch 11.067), train_loss = 1.16062091, grad/param norm = 1.4062e-01, time/batch = 14.9650s	
6309/28500 (epoch 11.068), train_loss = 1.18861156, grad/param norm = 1.5949e-01, time/batch = 15.7572s	
6310/28500 (epoch 11.070), train_loss = 1.30285837, grad/param norm = 1.7090e-01, time/batch = 15.3830s	
6311/28500 (epoch 11.072), train_loss = 1.44459366, grad/param norm = 1.7017e-01, time/batch = 15.2817s	
6312/28500 (epoch 11.074), train_loss = 1.28286070, grad/param norm = 1.5969e-01, time/batch = 15.2511s	
6313/28500 (epoch 11.075), train_loss = 1.22571851, grad/param norm = 1.3789e-01, time/batch = 15.4656s	
6314/28500 (epoch 11.077), train_loss = 1.28173658, grad/param norm = 1.5691e-01, time/batch = 15.4537s	
6315/28500 (epoch 11.079), train_loss = 1.21689706, grad/param norm = 1.4574e-01, time/batch = 15.4658s	
6316/28500 (epoch 11.081), train_loss = 1.35463930, grad/param norm = 1.8305e-01, time/batch = 15.5540s	
6317/28500 (epoch 11.082), train_loss = 1.28314428, grad/param norm = 1.8364e-01, time/batch = 15.3807s	
6318/28500 (epoch 11.084), train_loss = 1.31089157, grad/param norm = 1.5733e-01, time/batch = 14.9724s	
6319/28500 (epoch 11.086), train_loss = 1.20861636, grad/param norm = 1.6308e-01, time/batch = 15.1372s	
6320/28500 (epoch 11.088), train_loss = 1.12103802, grad/param norm = 1.5417e-01, time/batch = 15.1769s	
6321/28500 (epoch 11.089), train_loss = 1.36771012, grad/param norm = 1.5283e-01, time/batch = 15.1169s	
6322/28500 (epoch 11.091), train_loss = 1.10618406, grad/param norm = 1.5633e-01, time/batch = 15.0604s	
6323/28500 (epoch 11.093), train_loss = 1.29450995, grad/param norm = 1.6093e-01, time/batch = 15.2967s	
6324/28500 (epoch 11.095), train_loss = 1.16104312, grad/param norm = 1.4459e-01, time/batch = 15.4659s	
6325/28500 (epoch 11.096), train_loss = 1.39932277, grad/param norm = 1.7146e-01, time/batch = 15.3717s	
6326/28500 (epoch 11.098), train_loss = 1.37808156, grad/param norm = 1.7247e-01, time/batch = 15.2529s	
6327/28500 (epoch 11.100), train_loss = 1.19286475, grad/param norm = 1.5395e-01, time/batch = 15.1169s	
6328/28500 (epoch 11.102), train_loss = 1.39801850, grad/param norm = 1.6104e-01, time/batch = 15.4187s	
6329/28500 (epoch 11.104), train_loss = 1.22884015, grad/param norm = 1.7193e-01, time/batch = 15.1838s	
6330/28500 (epoch 11.105), train_loss = 1.31538278, grad/param norm = 1.6216e-01, time/batch = 15.4123s	
6331/28500 (epoch 11.107), train_loss = 1.12644725, grad/param norm = 1.5453e-01, time/batch = 15.5814s	
6332/28500 (epoch 11.109), train_loss = 1.12935950, grad/param norm = 1.6077e-01, time/batch = 15.2448s	
6333/28500 (epoch 11.111), train_loss = 1.20007994, grad/param norm = 1.5789e-01, time/batch = 15.2387s	
6334/28500 (epoch 11.112), train_loss = 1.32947179, grad/param norm = 1.7490e-01, time/batch = 15.2926s	
6335/28500 (epoch 11.114), train_loss = 1.23606028, grad/param norm = 1.6120e-01, time/batch = 15.0619s	
6336/28500 (epoch 11.116), train_loss = 1.42120848, grad/param norm = 1.6001e-01, time/batch = 15.1262s	
6337/28500 (epoch 11.118), train_loss = 1.10562467, grad/param norm = 1.5381e-01, time/batch = 15.2523s	
6338/28500 (epoch 11.119), train_loss = 1.30279426, grad/param norm = 1.8168e-01, time/batch = 15.0478s	
6339/28500 (epoch 11.121), train_loss = 1.47251216, grad/param norm = 1.8364e-01, time/batch = 15.4348s	
6340/28500 (epoch 11.123), train_loss = 1.30700970, grad/param norm = 1.7419e-01, time/batch = 15.4604s	
6341/28500 (epoch 11.125), train_loss = 1.27096369, grad/param norm = 1.5736e-01, time/batch = 15.6278s	
6342/28500 (epoch 11.126), train_loss = 1.22868162, grad/param norm = 1.5228e-01, time/batch = 15.5480s	
6343/28500 (epoch 11.128), train_loss = 1.17762364, grad/param norm = 1.5486e-01, time/batch = 15.5447s	
6344/28500 (epoch 11.130), train_loss = 1.13166657, grad/param norm = 1.5658e-01, time/batch = 15.5527s	
6345/28500 (epoch 11.132), train_loss = 1.32859033, grad/param norm = 1.7243e-01, time/batch = 15.4061s	
6346/28500 (epoch 11.133), train_loss = 1.27598104, grad/param norm = 1.6592e-01, time/batch = 15.5396s	
6347/28500 (epoch 11.135), train_loss = 1.22686355, grad/param norm = 1.4976e-01, time/batch = 15.5844s	
6348/28500 (epoch 11.137), train_loss = 1.18838009, grad/param norm = 1.6484e-01, time/batch = 15.6388s	
6349/28500 (epoch 11.139), train_loss = 1.21979125, grad/param norm = 1.5144e-01, time/batch = 15.1349s	
6350/28500 (epoch 11.140), train_loss = 1.29071624, grad/param norm = 1.5423e-01, time/batch = 14.9821s	
6351/28500 (epoch 11.142), train_loss = 1.26471984, grad/param norm = 1.6716e-01, time/batch = 15.1361s	
6352/28500 (epoch 11.144), train_loss = 1.13168630, grad/param norm = 1.4453e-01, time/batch = 15.1473s	
6353/28500 (epoch 11.146), train_loss = 1.17002873, grad/param norm = 1.5108e-01, time/batch = 15.0689s	
6354/28500 (epoch 11.147), train_loss = 1.07600292, grad/param norm = 1.5116e-01, time/batch = 14.9726s	
6355/28500 (epoch 11.149), train_loss = 1.07900921, grad/param norm = 1.4104e-01, time/batch = 15.0587s	
6356/28500 (epoch 11.151), train_loss = 1.07398840, grad/param norm = 1.3483e-01, time/batch = 15.1615s	
6357/28500 (epoch 11.153), train_loss = 1.24116004, grad/param norm = 1.5152e-01, time/batch = 15.2430s	
6358/28500 (epoch 11.154), train_loss = 1.15075943, grad/param norm = 1.6299e-01, time/batch = 15.1996s	
6359/28500 (epoch 11.156), train_loss = 1.39020324, grad/param norm = 1.7129e-01, time/batch = 15.1230s	
6360/28500 (epoch 11.158), train_loss = 1.19552973, grad/param norm = 1.4597e-01, time/batch = 15.2555s	
6361/28500 (epoch 11.160), train_loss = 1.12550859, grad/param norm = 1.4588e-01, time/batch = 15.2521s	
6362/28500 (epoch 11.161), train_loss = 1.22297142, grad/param norm = 1.5802e-01, time/batch = 15.1420s	
6363/28500 (epoch 11.163), train_loss = 1.10961859, grad/param norm = 1.6055e-01, time/batch = 15.2810s	
6364/28500 (epoch 11.165), train_loss = 1.42702186, grad/param norm = 1.5320e-01, time/batch = 15.5165s	
6365/28500 (epoch 11.167), train_loss = 1.50315686, grad/param norm = 1.8164e-01, time/batch = 15.4536s	
6366/28500 (epoch 11.168), train_loss = 1.34205082, grad/param norm = 1.8921e-01, time/batch = 15.4850s	
6367/28500 (epoch 11.170), train_loss = 1.33832457, grad/param norm = 1.6943e-01, time/batch = 15.3664s	
6368/28500 (epoch 11.172), train_loss = 1.23803377, grad/param norm = 1.7480e-01, time/batch = 15.5177s	
6369/28500 (epoch 11.174), train_loss = 1.39753702, grad/param norm = 1.7997e-01, time/batch = 15.4595s	
6370/28500 (epoch 11.175), train_loss = 1.20175599, grad/param norm = 1.4459e-01, time/batch = 15.2028s	
6371/28500 (epoch 11.177), train_loss = 1.30914244, grad/param norm = 1.6258e-01, time/batch = 15.5226s	
6372/28500 (epoch 11.179), train_loss = 1.21620054, grad/param norm = 1.7514e-01, time/batch = 15.2204s	
6373/28500 (epoch 11.181), train_loss = 1.27680228, grad/param norm = 1.5613e-01, time/batch = 15.3852s	
6374/28500 (epoch 11.182), train_loss = 1.23907519, grad/param norm = 1.5502e-01, time/batch = 15.4822s	
6375/28500 (epoch 11.184), train_loss = 1.47026689, grad/param norm = 1.8398e-01, time/batch = 15.5197s	
6376/28500 (epoch 11.186), train_loss = 1.35259818, grad/param norm = 1.7047e-01, time/batch = 15.3929s	
6377/28500 (epoch 11.188), train_loss = 1.24433942, grad/param norm = 1.5819e-01, time/batch = 15.3696s	
6378/28500 (epoch 11.189), train_loss = 1.28808233, grad/param norm = 1.6996e-01, time/batch = 15.3030s	
6379/28500 (epoch 11.191), train_loss = 1.48283382, grad/param norm = 1.8186e-01, time/batch = 15.5147s	
6380/28500 (epoch 11.193), train_loss = 1.33332708, grad/param norm = 1.8164e-01, time/batch = 15.5483s	
6381/28500 (epoch 11.195), train_loss = 1.37482719, grad/param norm = 1.7323e-01, time/batch = 15.4630s	
6382/28500 (epoch 11.196), train_loss = 1.30889900, grad/param norm = 1.6958e-01, time/batch = 15.0739s	
6383/28500 (epoch 11.198), train_loss = 1.29006665, grad/param norm = 1.8430e-01, time/batch = 15.1348s	
6384/28500 (epoch 11.200), train_loss = 1.24534303, grad/param norm = 1.4994e-01, time/batch = 15.3549s	
6385/28500 (epoch 11.202), train_loss = 1.24857810, grad/param norm = 1.5836e-01, time/batch = 15.5386s	
6386/28500 (epoch 11.204), train_loss = 1.14582279, grad/param norm = 1.5357e-01, time/batch = 15.6289s	
6387/28500 (epoch 11.205), train_loss = 1.20930446, grad/param norm = 1.5798e-01, time/batch = 15.5827s	
6388/28500 (epoch 11.207), train_loss = 1.19852112, grad/param norm = 1.5546e-01, time/batch = 15.3408s	
6389/28500 (epoch 11.209), train_loss = 1.24356758, grad/param norm = 1.6110e-01, time/batch = 14.8994s	
6390/28500 (epoch 11.211), train_loss = 1.10822952, grad/param norm = 1.5691e-01, time/batch = 15.0237s	
6391/28500 (epoch 11.212), train_loss = 1.10202543, grad/param norm = 1.5163e-01, time/batch = 15.5551s	
6392/28500 (epoch 11.214), train_loss = 1.27041184, grad/param norm = 1.7967e-01, time/batch = 15.2213s	
6393/28500 (epoch 11.216), train_loss = 1.11813840, grad/param norm = 1.4535e-01, time/batch = 15.2103s	
6394/28500 (epoch 11.218), train_loss = 1.35571946, grad/param norm = 1.5341e-01, time/batch = 15.3663s	
6395/28500 (epoch 11.219), train_loss = 1.30238380, grad/param norm = 1.7744e-01, time/batch = 14.9767s	
6396/28500 (epoch 11.221), train_loss = 1.14829554, grad/param norm = 1.7324e-01, time/batch = 14.9812s	
6397/28500 (epoch 11.223), train_loss = 1.36021781, grad/param norm = 1.7205e-01, time/batch = 14.9020s	
6398/28500 (epoch 11.225), train_loss = 1.38626209, grad/param norm = 1.5985e-01, time/batch = 15.0418s	
6399/28500 (epoch 11.226), train_loss = 1.20268558, grad/param norm = 1.5416e-01, time/batch = 15.2200s	
6400/28500 (epoch 11.228), train_loss = 1.30782273, grad/param norm = 1.4611e-01, time/batch = 15.3009s	
6401/28500 (epoch 11.230), train_loss = 1.34294370, grad/param norm = 1.6095e-01, time/batch = 15.5760s	
6402/28500 (epoch 11.232), train_loss = 1.30115545, grad/param norm = 1.5827e-01, time/batch = 15.5091s	
6403/28500 (epoch 11.233), train_loss = 1.29142088, grad/param norm = 1.6593e-01, time/batch = 15.5037s	
6404/28500 (epoch 11.235), train_loss = 1.18898587, grad/param norm = 1.5620e-01, time/batch = 15.3819s	
6405/28500 (epoch 11.237), train_loss = 1.08803880, grad/param norm = 1.3710e-01, time/batch = 15.6136s	
6406/28500 (epoch 11.239), train_loss = 1.15750594, grad/param norm = 1.4861e-01, time/batch = 15.6147s	
6407/28500 (epoch 11.240), train_loss = 1.10810032, grad/param norm = 1.6205e-01, time/batch = 14.9928s	
6408/28500 (epoch 11.242), train_loss = 1.28987562, grad/param norm = 1.8745e-01, time/batch = 14.9812s	
6409/28500 (epoch 11.244), train_loss = 1.30693361, grad/param norm = 1.5607e-01, time/batch = 15.0416s	
6410/28500 (epoch 11.246), train_loss = 1.35775852, grad/param norm = 1.6330e-01, time/batch = 15.1187s	
6411/28500 (epoch 11.247), train_loss = 1.45209975, grad/param norm = 1.7010e-01, time/batch = 15.3120s	
6412/28500 (epoch 11.249), train_loss = 1.26706453, grad/param norm = 1.6580e-01, time/batch = 15.5094s	
6413/28500 (epoch 11.251), train_loss = 1.14319525, grad/param norm = 1.4730e-01, time/batch = 15.6239s	
6414/28500 (epoch 11.253), train_loss = 1.44166813, grad/param norm = 1.7327e-01, time/batch = 15.4126s	
6415/28500 (epoch 11.254), train_loss = 1.39306903, grad/param norm = 1.7544e-01, time/batch = 15.2840s	
6416/28500 (epoch 11.256), train_loss = 1.17363231, grad/param norm = 1.4012e-01, time/batch = 15.3164s	
6417/28500 (epoch 11.258), train_loss = 1.22705302, grad/param norm = 1.6593e-01, time/batch = 15.2934s	
6418/28500 (epoch 11.260), train_loss = 1.18046369, grad/param norm = 1.4653e-01, time/batch = 15.2909s	
6419/28500 (epoch 11.261), train_loss = 1.17613894, grad/param norm = 1.5954e-01, time/batch = 15.1305s	
6420/28500 (epoch 11.263), train_loss = 1.38900478, grad/param norm = 1.7773e-01, time/batch = 15.1489s	
6421/28500 (epoch 11.265), train_loss = 1.25514351, grad/param norm = 1.5997e-01, time/batch = 15.3937s	
6422/28500 (epoch 11.267), train_loss = 1.42326562, grad/param norm = 1.7910e-01, time/batch = 15.7037s	
6423/28500 (epoch 11.268), train_loss = 1.33713925, grad/param norm = 1.5511e-01, time/batch = 15.5661s	
6424/28500 (epoch 11.270), train_loss = 1.28533280, grad/param norm = 1.6954e-01, time/batch = 15.4826s	
6425/28500 (epoch 11.272), train_loss = 1.22831731, grad/param norm = 1.6055e-01, time/batch = 15.4462s	
6426/28500 (epoch 11.274), train_loss = 1.37222723, grad/param norm = 1.7198e-01, time/batch = 15.2601s	
6427/28500 (epoch 11.275), train_loss = 1.30213198, grad/param norm = 1.6045e-01, time/batch = 15.2814s	
6428/28500 (epoch 11.277), train_loss = 1.25918673, grad/param norm = 1.6164e-01, time/batch = 15.0981s	
6429/28500 (epoch 11.279), train_loss = 1.28892914, grad/param norm = 1.7361e-01, time/batch = 15.2002s	
6430/28500 (epoch 11.281), train_loss = 1.31474615, grad/param norm = 1.7248e-01, time/batch = 15.3404s	
6431/28500 (epoch 11.282), train_loss = 1.13624979, grad/param norm = 1.4280e-01, time/batch = 15.5356s	
6432/28500 (epoch 11.284), train_loss = 1.28383953, grad/param norm = 1.6509e-01, time/batch = 15.6165s	
6433/28500 (epoch 11.286), train_loss = 1.34686149, grad/param norm = 1.5981e-01, time/batch = 15.4869s	
6434/28500 (epoch 11.288), train_loss = 1.27175760, grad/param norm = 1.5381e-01, time/batch = 15.3083s	
6435/28500 (epoch 11.289), train_loss = 1.39210470, grad/param norm = 1.6961e-01, time/batch = 15.3199s	
6436/28500 (epoch 11.291), train_loss = 1.22998356, grad/param norm = 1.5605e-01, time/batch = 15.3923s	
6437/28500 (epoch 11.293), train_loss = 1.20728299, grad/param norm = 1.6194e-01, time/batch = 15.0484s	
6438/28500 (epoch 11.295), train_loss = 1.12554988, grad/param norm = 1.4920e-01, time/batch = 15.1897s	
6439/28500 (epoch 11.296), train_loss = 1.14632203, grad/param norm = 1.5047e-01, time/batch = 15.3833s	
6440/28500 (epoch 11.298), train_loss = 1.28179879, grad/param norm = 1.5913e-01, time/batch = 15.3737s	
6441/28500 (epoch 11.300), train_loss = 1.17757939, grad/param norm = 1.5516e-01, time/batch = 15.5795s	
6442/28500 (epoch 11.302), train_loss = 1.14946693, grad/param norm = 1.4869e-01, time/batch = 15.6483s	
6443/28500 (epoch 11.304), train_loss = 1.23951157, grad/param norm = 1.4893e-01, time/batch = 15.5365s	
6444/28500 (epoch 11.305), train_loss = 1.32084233, grad/param norm = 1.5640e-01, time/batch = 15.3002s	
6445/28500 (epoch 11.307), train_loss = 1.28698616, grad/param norm = 1.7352e-01, time/batch = 26.9374s	
6446/28500 (epoch 11.309), train_loss = 1.24700046, grad/param norm = 1.6850e-01, time/batch = 15.6393s	
6447/28500 (epoch 11.311), train_loss = 1.26808499, grad/param norm = 1.6819e-01, time/batch = 15.4373s	
6448/28500 (epoch 11.312), train_loss = 1.19470197, grad/param norm = 1.6623e-01, time/batch = 15.3406s	
6449/28500 (epoch 11.314), train_loss = 1.33552104, grad/param norm = 1.7276e-01, time/batch = 15.2665s	
6450/28500 (epoch 11.316), train_loss = 1.29906406, grad/param norm = 1.5071e-01, time/batch = 15.2795s	
6451/28500 (epoch 11.318), train_loss = 1.32941684, grad/param norm = 1.7415e-01, time/batch = 15.2039s	
6452/28500 (epoch 11.319), train_loss = 1.23470391, grad/param norm = 1.6365e-01, time/batch = 15.3300s	
6453/28500 (epoch 11.321), train_loss = 1.28003785, grad/param norm = 1.8232e-01, time/batch = 15.2225s	
6454/28500 (epoch 11.323), train_loss = 1.21789868, grad/param norm = 1.7478e-01, time/batch = 15.5555s	
6455/28500 (epoch 11.325), train_loss = 1.41117353, grad/param norm = 1.6845e-01, time/batch = 15.5437s	
6456/28500 (epoch 11.326), train_loss = 1.26636237, grad/param norm = 1.7143e-01, time/batch = 15.3493s	
6457/28500 (epoch 11.328), train_loss = 1.03670083, grad/param norm = 1.4458e-01, time/batch = 14.8874s	
6458/28500 (epoch 11.330), train_loss = 1.14928763, grad/param norm = 1.5261e-01, time/batch = 15.1023s	
6459/28500 (epoch 11.332), train_loss = 1.23589269, grad/param norm = 1.5173e-01, time/batch = 15.1950s	
6460/28500 (epoch 11.333), train_loss = 1.07724777, grad/param norm = 1.5285e-01, time/batch = 15.2344s	
6461/28500 (epoch 11.335), train_loss = 1.11472385, grad/param norm = 1.3979e-01, time/batch = 15.3929s	
6462/28500 (epoch 11.337), train_loss = 1.19118813, grad/param norm = 1.5740e-01, time/batch = 15.5191s	
6463/28500 (epoch 11.339), train_loss = 1.11325524, grad/param norm = 1.4478e-01, time/batch = 15.6260s	
6464/28500 (epoch 11.340), train_loss = 1.30285439, grad/param norm = 1.6194e-01, time/batch = 15.5683s	
6465/28500 (epoch 11.342), train_loss = 1.21862177, grad/param norm = 1.7234e-01, time/batch = 15.5562s	
6466/28500 (epoch 11.344), train_loss = 1.17637038, grad/param norm = 1.5839e-01, time/batch = 15.5457s	
6467/28500 (epoch 11.346), train_loss = 0.98925725, grad/param norm = 1.3762e-01, time/batch = 15.4717s	
6468/28500 (epoch 11.347), train_loss = 1.21255732, grad/param norm = 1.4591e-01, time/batch = 15.2103s	
6469/28500 (epoch 11.349), train_loss = 1.16588418, grad/param norm = 1.4407e-01, time/batch = 15.1280s	
6470/28500 (epoch 11.351), train_loss = 1.14430850, grad/param norm = 1.4874e-01, time/batch = 15.5439s	
6471/28500 (epoch 11.353), train_loss = 1.29183003, grad/param norm = 1.7502e-01, time/batch = 15.5365s	
6472/28500 (epoch 11.354), train_loss = 1.09405798, grad/param norm = 1.4764e-01, time/batch = 15.2890s	
6473/28500 (epoch 11.356), train_loss = 1.13854636, grad/param norm = 1.4272e-01, time/batch = 15.3134s	
6474/28500 (epoch 11.358), train_loss = 1.23067821, grad/param norm = 1.4733e-01, time/batch = 15.2185s	
6475/28500 (epoch 11.360), train_loss = 1.26387527, grad/param norm = 1.7872e-01, time/batch = 15.1366s	
6476/28500 (epoch 11.361), train_loss = 1.15897532, grad/param norm = 1.5791e-01, time/batch = 15.1336s	
6477/28500 (epoch 11.363), train_loss = 1.12171254, grad/param norm = 1.4879e-01, time/batch = 15.4639s	
6478/28500 (epoch 11.365), train_loss = 1.18276302, grad/param norm = 1.5999e-01, time/batch = 15.2701s	
6479/28500 (epoch 11.367), train_loss = 1.21434667, grad/param norm = 1.4999e-01, time/batch = 15.2065s	
6480/28500 (epoch 11.368), train_loss = 1.18003329, grad/param norm = 1.4590e-01, time/batch = 15.2506s	
6481/28500 (epoch 11.370), train_loss = 1.24750835, grad/param norm = 1.5685e-01, time/batch = 15.4552s	
6482/28500 (epoch 11.372), train_loss = 1.07930299, grad/param norm = 1.5152e-01, time/batch = 15.3169s	
6483/28500 (epoch 11.374), train_loss = 1.21494937, grad/param norm = 1.5140e-01, time/batch = 15.5168s	
6484/28500 (epoch 11.375), train_loss = 1.36161499, grad/param norm = 1.6461e-01, time/batch = 15.5433s	
6485/28500 (epoch 11.377), train_loss = 1.14305619, grad/param norm = 1.5197e-01, time/batch = 15.5607s	
6486/28500 (epoch 11.379), train_loss = 0.98330231, grad/param norm = 1.3660e-01, time/batch = 15.5615s	
6487/28500 (epoch 11.381), train_loss = 1.18941506, grad/param norm = 1.4517e-01, time/batch = 15.6233s	
6488/28500 (epoch 11.382), train_loss = 1.16376831, grad/param norm = 1.5465e-01, time/batch = 15.3687s	
6489/28500 (epoch 11.384), train_loss = 1.09258350, grad/param norm = 1.4113e-01, time/batch = 15.4381s	
6490/28500 (epoch 11.386), train_loss = 1.10409744, grad/param norm = 1.6510e-01, time/batch = 15.0668s	
6491/28500 (epoch 11.388), train_loss = 1.30292996, grad/param norm = 1.5768e-01, time/batch = 15.6014s	
6492/28500 (epoch 11.389), train_loss = 1.13360896, grad/param norm = 1.5792e-01, time/batch = 15.3841s	
6493/28500 (epoch 11.391), train_loss = 1.14104635, grad/param norm = 1.5776e-01, time/batch = 15.4918s	
6494/28500 (epoch 11.393), train_loss = 1.07757115, grad/param norm = 1.5100e-01, time/batch = 15.1899s	
6495/28500 (epoch 11.395), train_loss = 1.40524429, grad/param norm = 1.6750e-01, time/batch = 15.1373s	
6496/28500 (epoch 11.396), train_loss = 1.32087664, grad/param norm = 1.5890e-01, time/batch = 15.2940s	
6497/28500 (epoch 11.398), train_loss = 1.05193859, grad/param norm = 2.5815e-01, time/batch = 14.9598s	
6498/28500 (epoch 11.400), train_loss = 1.28117232, grad/param norm = 2.5649e-01, time/batch = 15.2884s	
6499/28500 (epoch 11.402), train_loss = 1.23630658, grad/param norm = 1.6483e-01, time/batch = 15.5455s	
6500/28500 (epoch 11.404), train_loss = 1.35030376, grad/param norm = 1.9232e-01, time/batch = 15.5493s	
6501/28500 (epoch 11.405), train_loss = 1.34868492, grad/param norm = 1.6570e-01, time/batch = 15.6316s	
6502/28500 (epoch 11.407), train_loss = 1.25962156, grad/param norm = 1.5813e-01, time/batch = 15.6146s	
6503/28500 (epoch 11.409), train_loss = 1.25234907, grad/param norm = 1.5812e-01, time/batch = 15.6160s	
6504/28500 (epoch 11.411), train_loss = 1.33312134, grad/param norm = 1.5812e-01, time/batch = 15.5548s	
6505/28500 (epoch 11.412), train_loss = 1.41137186, grad/param norm = 1.8922e-01, time/batch = 15.4734s	
6506/28500 (epoch 11.414), train_loss = 1.25072394, grad/param norm = 1.6661e-01, time/batch = 15.4867s	
6507/28500 (epoch 11.416), train_loss = 1.19614713, grad/param norm = 1.7049e-01, time/batch = 15.4941s	
6508/28500 (epoch 11.418), train_loss = 1.23208428, grad/param norm = 1.4171e-01, time/batch = 15.4663s	
6509/28500 (epoch 11.419), train_loss = 1.38044148, grad/param norm = 1.6738e-01, time/batch = 15.4474s	
6510/28500 (epoch 11.421), train_loss = 1.32372821, grad/param norm = 1.5796e-01, time/batch = 15.3656s	
6511/28500 (epoch 11.423), train_loss = 1.36989187, grad/param norm = 1.7331e-01, time/batch = 15.2105s	
6512/28500 (epoch 11.425), train_loss = 1.28255481, grad/param norm = 1.7350e-01, time/batch = 15.5148s	
6513/28500 (epoch 11.426), train_loss = 1.24223146, grad/param norm = 1.7369e-01, time/batch = 15.5689s	
6514/28500 (epoch 11.428), train_loss = 1.46420417, grad/param norm = 1.7509e-01, time/batch = 15.3789s	
6515/28500 (epoch 11.430), train_loss = 1.36411702, grad/param norm = 1.5861e-01, time/batch = 15.2848s	
6516/28500 (epoch 11.432), train_loss = 1.29688781, grad/param norm = 1.6413e-01, time/batch = 15.3870s	
6517/28500 (epoch 11.433), train_loss = 1.32657127, grad/param norm = 1.7443e-01, time/batch = 15.0898s	
6518/28500 (epoch 11.435), train_loss = 1.23296511, grad/param norm = 1.6222e-01, time/batch = 15.1992s	
6519/28500 (epoch 11.437), train_loss = 1.10304596, grad/param norm = 1.4384e-01, time/batch = 14.9672s	
6520/28500 (epoch 11.439), train_loss = 1.15993193, grad/param norm = 1.4972e-01, time/batch = 15.2385s	
6521/28500 (epoch 11.440), train_loss = 1.41316732, grad/param norm = 1.7292e-01, time/batch = 15.5295s	
6522/28500 (epoch 11.442), train_loss = 1.14576300, grad/param norm = 1.6692e-01, time/batch = 15.5264s	
6523/28500 (epoch 11.444), train_loss = 1.08579450, grad/param norm = 1.3739e-01, time/batch = 15.5369s	
6524/28500 (epoch 11.446), train_loss = 1.02991745, grad/param norm = 1.4434e-01, time/batch = 15.7119s	
6525/28500 (epoch 11.447), train_loss = 1.07966263, grad/param norm = 1.3957e-01, time/batch = 15.5391s	
6526/28500 (epoch 11.449), train_loss = 1.15260623, grad/param norm = 1.4822e-01, time/batch = 15.4636s	
6527/28500 (epoch 11.451), train_loss = 1.17943642, grad/param norm = 1.5219e-01, time/batch = 15.4865s	
6528/28500 (epoch 11.453), train_loss = 1.22324633, grad/param norm = 1.6880e-01, time/batch = 15.7203s	
6529/28500 (epoch 11.454), train_loss = 1.15762757, grad/param norm = 1.4838e-01, time/batch = 15.2837s	
6530/28500 (epoch 11.456), train_loss = 1.28791434, grad/param norm = 1.6688e-01, time/batch = 15.0725s	
6531/28500 (epoch 11.458), train_loss = 1.17995941, grad/param norm = 1.5941e-01, time/batch = 15.2616s	
6532/28500 (epoch 11.460), train_loss = 1.30015495, grad/param norm = 1.7025e-01, time/batch = 15.3491s	
6533/28500 (epoch 11.461), train_loss = 1.17575730, grad/param norm = 1.5736e-01, time/batch = 15.4240s	
6534/28500 (epoch 11.463), train_loss = 1.10342767, grad/param norm = 1.3615e-01, time/batch = 15.6079s	
6535/28500 (epoch 11.465), train_loss = 1.08086363, grad/param norm = 1.6826e-01, time/batch = 15.5510s	
6536/28500 (epoch 11.467), train_loss = 1.25998677, grad/param norm = 1.5924e-01, time/batch = 15.3663s	
6537/28500 (epoch 11.468), train_loss = 1.07503655, grad/param norm = 1.2516e-01, time/batch = 15.1417s	
6538/28500 (epoch 11.470), train_loss = 1.17579073, grad/param norm = 1.6386e-01, time/batch = 15.2960s	
6539/28500 (epoch 11.472), train_loss = 1.16755358, grad/param norm = 1.5398e-01, time/batch = 15.2153s	
6540/28500 (epoch 11.474), train_loss = 1.48355335, grad/param norm = 1.8895e-01, time/batch = 15.3083s	
6541/28500 (epoch 11.475), train_loss = 1.12758392, grad/param norm = 1.4281e-01, time/batch = 15.4610s	
6542/28500 (epoch 11.477), train_loss = 1.22158949, grad/param norm = 1.5185e-01, time/batch = 15.3073s	
6543/28500 (epoch 11.479), train_loss = 1.27065037, grad/param norm = 1.5514e-01, time/batch = 15.2203s	
6544/28500 (epoch 11.481), train_loss = 1.22242824, grad/param norm = 1.6463e-01, time/batch = 15.2678s	
6545/28500 (epoch 11.482), train_loss = 1.11174391, grad/param norm = 1.5550e-01, time/batch = 15.1945s	
6546/28500 (epoch 11.484), train_loss = 1.11204273, grad/param norm = 1.4936e-01, time/batch = 15.1693s	
6547/28500 (epoch 11.486), train_loss = 1.03796068, grad/param norm = 1.6381e-01, time/batch = 15.2205s	
6548/28500 (epoch 11.488), train_loss = 1.24518629, grad/param norm = 1.4951e-01, time/batch = 14.9767s	
6549/28500 (epoch 11.489), train_loss = 1.31898357, grad/param norm = 1.5619e-01, time/batch = 15.2874s	
6550/28500 (epoch 11.491), train_loss = 1.17096664, grad/param norm = 1.5322e-01, time/batch = 15.1455s	
6551/28500 (epoch 11.493), train_loss = 1.16096295, grad/param norm = 1.5189e-01, time/batch = 15.3664s	
6552/28500 (epoch 11.495), train_loss = 1.14679969, grad/param norm = 1.4783e-01, time/batch = 15.0747s	
6553/28500 (epoch 11.496), train_loss = 1.18381650, grad/param norm = 1.6511e-01, time/batch = 15.2344s	
6554/28500 (epoch 11.498), train_loss = 1.28059209, grad/param norm = 1.6427e-01, time/batch = 14.9021s	
6555/28500 (epoch 11.500), train_loss = 1.19091301, grad/param norm = 1.5310e-01, time/batch = 15.0751s	
6556/28500 (epoch 11.502), train_loss = 1.31788734, grad/param norm = 1.5039e-01, time/batch = 15.3973s	
6557/28500 (epoch 11.504), train_loss = 1.27094566, grad/param norm = 1.5407e-01, time/batch = 15.5428s	
6558/28500 (epoch 11.505), train_loss = 1.11972133, grad/param norm = 1.4733e-01, time/batch = 15.3011s	
6559/28500 (epoch 11.507), train_loss = 1.33535656, grad/param norm = 1.7208e-01, time/batch = 15.3005s	
6560/28500 (epoch 11.509), train_loss = 1.22175665, grad/param norm = 1.5535e-01, time/batch = 15.4909s	
6561/28500 (epoch 11.511), train_loss = 1.20095016, grad/param norm = 1.5496e-01, time/batch = 15.6014s	
6562/28500 (epoch 11.512), train_loss = 1.22909943, grad/param norm = 1.5695e-01, time/batch = 15.3000s	
6563/28500 (epoch 11.514), train_loss = 1.09887706, grad/param norm = 1.4355e-01, time/batch = 15.2246s	
6564/28500 (epoch 11.516), train_loss = 1.14372530, grad/param norm = 1.4455e-01, time/batch = 15.0546s	
6565/28500 (epoch 11.518), train_loss = 1.20664281, grad/param norm = 1.4859e-01, time/batch = 15.1113s	
6566/28500 (epoch 11.519), train_loss = 1.27140189, grad/param norm = 1.5476e-01, time/batch = 15.1487s	
6567/28500 (epoch 11.521), train_loss = 1.38393167, grad/param norm = 1.6548e-01, time/batch = 15.0537s	
6568/28500 (epoch 11.523), train_loss = 1.27284168, grad/param norm = 1.7012e-01, time/batch = 14.9896s	
6569/28500 (epoch 11.525), train_loss = 1.32608355, grad/param norm = 1.6331e-01, time/batch = 15.1891s	
6570/28500 (epoch 11.526), train_loss = 1.28304767, grad/param norm = 1.7000e-01, time/batch = 14.9641s	
6571/28500 (epoch 11.528), train_loss = 1.32993904, grad/param norm = 1.6654e-01, time/batch = 15.1909s	
6572/28500 (epoch 11.530), train_loss = 1.34668581, grad/param norm = 1.5425e-01, time/batch = 15.4070s	
6573/28500 (epoch 11.532), train_loss = 1.18402170, grad/param norm = 1.6803e-01, time/batch = 15.5418s	
6574/28500 (epoch 11.533), train_loss = 1.31611942, grad/param norm = 1.4594e-01, time/batch = 15.4952s	
6575/28500 (epoch 11.535), train_loss = 1.05382559, grad/param norm = 1.4399e-01, time/batch = 15.3005s	
6576/28500 (epoch 11.537), train_loss = 1.05225168, grad/param norm = 1.5134e-01, time/batch = 15.2954s	
6577/28500 (epoch 11.539), train_loss = 1.08431275, grad/param norm = 1.5131e-01, time/batch = 15.4627s	
6578/28500 (epoch 11.540), train_loss = 1.19631608, grad/param norm = 1.4014e-01, time/batch = 15.3977s	
6579/28500 (epoch 11.542), train_loss = 1.39230197, grad/param norm = 1.8396e-01, time/batch = 15.2963s	
6580/28500 (epoch 11.544), train_loss = 1.39173464, grad/param norm = 1.6005e-01, time/batch = 15.5334s	
6581/28500 (epoch 11.546), train_loss = 1.23245449, grad/param norm = 1.6821e-01, time/batch = 15.3237s	
6582/28500 (epoch 11.547), train_loss = 1.20612238, grad/param norm = 1.4196e-01, time/batch = 15.5498s	
6583/28500 (epoch 11.549), train_loss = 1.05602682, grad/param norm = 1.3770e-01, time/batch = 15.5615s	
6584/28500 (epoch 11.551), train_loss = 1.30570462, grad/param norm = 1.7317e-01, time/batch = 15.4699s	
6585/28500 (epoch 11.553), train_loss = 1.44980106, grad/param norm = 1.8326e-01, time/batch = 15.3133s	
6586/28500 (epoch 11.554), train_loss = 1.17676122, grad/param norm = 1.4181e-01, time/batch = 15.3785s	
6587/28500 (epoch 11.556), train_loss = 1.22902580, grad/param norm = 1.6770e-01, time/batch = 15.4183s	
6588/28500 (epoch 11.558), train_loss = 1.26429603, grad/param norm = 1.7146e-01, time/batch = 15.4375s	
6589/28500 (epoch 11.560), train_loss = 1.27019184, grad/param norm = 1.6876e-01, time/batch = 15.2191s	
6590/28500 (epoch 11.561), train_loss = 1.32776944, grad/param norm = 1.8011e-01, time/batch = 15.4635s	
6591/28500 (epoch 11.563), train_loss = 1.37990418, grad/param norm = 1.6863e-01, time/batch = 15.5578s	
6592/28500 (epoch 11.565), train_loss = 1.20476269, grad/param norm = 1.5461e-01, time/batch = 15.5469s	
6593/28500 (epoch 11.567), train_loss = 1.07588006, grad/param norm = 1.5594e-01, time/batch = 15.3157s	
6594/28500 (epoch 11.568), train_loss = 1.26086275, grad/param norm = 1.6688e-01, time/batch = 15.4521s	
6595/28500 (epoch 11.570), train_loss = 1.17003050, grad/param norm = 1.6177e-01, time/batch = 15.2675s	
6596/28500 (epoch 11.572), train_loss = 1.18980128, grad/param norm = 1.7549e-01, time/batch = 15.5541s	
6597/28500 (epoch 11.574), train_loss = 1.21210565, grad/param norm = 1.5815e-01, time/batch = 15.4745s	
6598/28500 (epoch 11.575), train_loss = 1.18288958, grad/param norm = 1.6014e-01, time/batch = 15.3688s	
6599/28500 (epoch 11.577), train_loss = 1.20490915, grad/param norm = 1.4774e-01, time/batch = 15.3559s	
6600/28500 (epoch 11.579), train_loss = 1.31935046, grad/param norm = 1.6724e-01, time/batch = 15.5741s	
6601/28500 (epoch 11.581), train_loss = 1.19516181, grad/param norm = 1.7717e-01, time/batch = 15.3521s	
6602/28500 (epoch 11.582), train_loss = 1.32271260, grad/param norm = 1.6051e-01, time/batch = 15.6147s	
6603/28500 (epoch 11.584), train_loss = 1.16845461, grad/param norm = 1.4616e-01, time/batch = 15.1389s	
6604/28500 (epoch 11.586), train_loss = 1.11279426, grad/param norm = 1.4134e-01, time/batch = 15.2221s	
6605/28500 (epoch 11.588), train_loss = 1.12711434, grad/param norm = 1.4326e-01, time/batch = 15.3595s	
6606/28500 (epoch 11.589), train_loss = 1.29474634, grad/param norm = 1.5536e-01, time/batch = 15.2322s	
6607/28500 (epoch 11.591), train_loss = 1.27425979, grad/param norm = 1.5194e-01, time/batch = 15.3761s	
6608/28500 (epoch 11.593), train_loss = 1.15399412, grad/param norm = 1.4922e-01, time/batch = 15.2074s	
6609/28500 (epoch 11.595), train_loss = 1.46395574, grad/param norm = 1.8972e-01, time/batch = 15.1152s	
6610/28500 (epoch 11.596), train_loss = 1.44881267, grad/param norm = 1.8606e-01, time/batch = 14.8994s	
6611/28500 (epoch 11.598), train_loss = 1.25106547, grad/param norm = 1.5662e-01, time/batch = 15.3595s	
6612/28500 (epoch 11.600), train_loss = 1.26734426, grad/param norm = 1.7911e-01, time/batch = 15.3142s	
6613/28500 (epoch 11.602), train_loss = 1.37851687, grad/param norm = 1.6949e-01, time/batch = 15.2950s	
6614/28500 (epoch 11.604), train_loss = 1.30398247, grad/param norm = 1.5385e-01, time/batch = 15.5747s	
6615/28500 (epoch 11.605), train_loss = 1.24400832, grad/param norm = 1.5371e-01, time/batch = 15.5399s	
6616/28500 (epoch 11.607), train_loss = 1.29299219, grad/param norm = 1.5020e-01, time/batch = 15.6076s	
6617/28500 (epoch 11.609), train_loss = 1.21873317, grad/param norm = 1.5224e-01, time/batch = 15.2198s	
6618/28500 (epoch 11.611), train_loss = 1.24441196, grad/param norm = 1.5607e-01, time/batch = 15.2221s	
6619/28500 (epoch 11.612), train_loss = 1.27890279, grad/param norm = 1.6635e-01, time/batch = 15.4945s	
6620/28500 (epoch 11.614), train_loss = 1.26564047, grad/param norm = 1.6111e-01, time/batch = 15.4578s	
6621/28500 (epoch 11.616), train_loss = 1.17300865, grad/param norm = 1.5927e-01, time/batch = 15.3891s	
6622/28500 (epoch 11.618), train_loss = 1.17413803, grad/param norm = 1.5231e-01, time/batch = 15.4461s	
6623/28500 (epoch 11.619), train_loss = 1.41593930, grad/param norm = 1.7380e-01, time/batch = 15.3636s	
6624/28500 (epoch 11.621), train_loss = 1.02274071, grad/param norm = 1.3602e-01, time/batch = 15.7103s	
6625/28500 (epoch 11.623), train_loss = 1.34509461, grad/param norm = 1.6428e-01, time/batch = 15.4444s	
6626/28500 (epoch 11.625), train_loss = 1.08649946, grad/param norm = 1.5000e-01, time/batch = 15.5387s	
6627/28500 (epoch 11.626), train_loss = 0.95558715, grad/param norm = 1.3917e-01, time/batch = 15.3119s	
6628/28500 (epoch 11.628), train_loss = 1.15410736, grad/param norm = 1.6147e-01, time/batch = 15.1749s	
6629/28500 (epoch 11.630), train_loss = 1.05667168, grad/param norm = 1.4656e-01, time/batch = 15.2801s	
6630/28500 (epoch 11.632), train_loss = 1.31869313, grad/param norm = 1.6208e-01, time/batch = 15.6375s	
6631/28500 (epoch 11.633), train_loss = 1.34969372, grad/param norm = 1.5768e-01, time/batch = 15.2095s	
6632/28500 (epoch 11.635), train_loss = 1.42559209, grad/param norm = 1.7000e-01, time/batch = 15.2036s	
6633/28500 (epoch 11.637), train_loss = 1.22653050, grad/param norm = 1.5047e-01, time/batch = 15.2243s	
6634/28500 (epoch 11.639), train_loss = 1.09737491, grad/param norm = 1.4746e-01, time/batch = 15.2961s	
6635/28500 (epoch 11.640), train_loss = 1.10632199, grad/param norm = 1.5052e-01, time/batch = 15.2860s	
6636/28500 (epoch 11.642), train_loss = 1.25238341, grad/param norm = 1.5000e-01, time/batch = 15.4736s	
6637/28500 (epoch 11.644), train_loss = 1.30098523, grad/param norm = 1.4716e-01, time/batch = 15.4674s	
6638/28500 (epoch 11.646), train_loss = 1.10285435, grad/param norm = 1.3964e-01, time/batch = 15.4139s	
6639/28500 (epoch 11.647), train_loss = 1.11426545, grad/param norm = 1.5478e-01, time/batch = 15.1097s	
6640/28500 (epoch 11.649), train_loss = 1.09773256, grad/param norm = 1.5122e-01, time/batch = 15.2231s	
6641/28500 (epoch 11.651), train_loss = 1.06681754, grad/param norm = 1.4124e-01, time/batch = 15.2590s	
6642/28500 (epoch 11.653), train_loss = 1.09362800, grad/param norm = 1.4914e-01, time/batch = 15.2292s	
6643/28500 (epoch 11.654), train_loss = 1.18090705, grad/param norm = 1.5289e-01, time/batch = 15.1241s	
6644/28500 (epoch 11.656), train_loss = 1.14457245, grad/param norm = 1.5420e-01, time/batch = 15.1136s	
6645/28500 (epoch 11.658), train_loss = 1.23949234, grad/param norm = 1.6319e-01, time/batch = 15.2107s	
6646/28500 (epoch 11.660), train_loss = 1.20317586, grad/param norm = 1.4405e-01, time/batch = 15.4186s	
6647/28500 (epoch 11.661), train_loss = 1.37034102, grad/param norm = 1.7106e-01, time/batch = 15.3406s	
6648/28500 (epoch 11.663), train_loss = 1.40937468, grad/param norm = 1.6928e-01, time/batch = 15.0415s	
6649/28500 (epoch 11.665), train_loss = 1.17561276, grad/param norm = 1.5848e-01, time/batch = 15.1035s	
6650/28500 (epoch 11.667), train_loss = 1.25013217, grad/param norm = 1.6365e-01, time/batch = 15.1906s	
6651/28500 (epoch 11.668), train_loss = 1.19933422, grad/param norm = 1.5182e-01, time/batch = 15.2880s	
6652/28500 (epoch 11.670), train_loss = 1.22774728, grad/param norm = 1.5250e-01, time/batch = 15.3820s	
6653/28500 (epoch 11.672), train_loss = 1.18578864, grad/param norm = 1.5888e-01, time/batch = 15.4184s	
6654/28500 (epoch 11.674), train_loss = 1.02525928, grad/param norm = 1.6359e-01, time/batch = 15.4764s	
6655/28500 (epoch 11.675), train_loss = 1.06068574, grad/param norm = 1.5327e-01, time/batch = 15.2979s	
6656/28500 (epoch 11.677), train_loss = 1.18776329, grad/param norm = 1.5317e-01, time/batch = 15.2284s	
6657/28500 (epoch 11.679), train_loss = 1.16869695, grad/param norm = 1.5365e-01, time/batch = 15.4346s	
6658/28500 (epoch 11.681), train_loss = 1.29798171, grad/param norm = 1.5631e-01, time/batch = 15.6065s	
6659/28500 (epoch 11.682), train_loss = 1.17334710, grad/param norm = 1.4934e-01, time/batch = 15.3472s	
6660/28500 (epoch 11.684), train_loss = 1.27732527, grad/param norm = 1.6034e-01, time/batch = 15.2021s	
6661/28500 (epoch 11.686), train_loss = 1.14728714, grad/param norm = 1.6091e-01, time/batch = 15.6112s	
6662/28500 (epoch 11.688), train_loss = 1.09758455, grad/param norm = 1.4014e-01, time/batch = 15.4464s	
6663/28500 (epoch 11.689), train_loss = 1.24169295, grad/param norm = 1.6562e-01, time/batch = 15.3012s	
6664/28500 (epoch 11.691), train_loss = 1.26836327, grad/param norm = 1.7704e-01, time/batch = 15.2949s	
6665/28500 (epoch 11.693), train_loss = 1.17523829, grad/param norm = 1.6299e-01, time/batch = 15.2974s	
6666/28500 (epoch 11.695), train_loss = 1.03168103, grad/param norm = 1.6831e-01, time/batch = 15.2250s	
6667/28500 (epoch 11.696), train_loss = 1.17614546, grad/param norm = 1.6534e-01, time/batch = 15.4039s	
6668/28500 (epoch 11.698), train_loss = 1.21888355, grad/param norm = 1.5548e-01, time/batch = 15.3524s	
6669/28500 (epoch 11.700), train_loss = 1.23484678, grad/param norm = 1.5045e-01, time/batch = 15.2150s	
6670/28500 (epoch 11.702), train_loss = 1.34541963, grad/param norm = 1.8257e-01, time/batch = 15.2854s	
6671/28500 (epoch 11.704), train_loss = 1.26135382, grad/param norm = 1.6641e-01, time/batch = 15.0514s	
6672/28500 (epoch 11.705), train_loss = 1.30704159, grad/param norm = 1.6147e-01, time/batch = 15.2351s	
6673/28500 (epoch 11.707), train_loss = 1.17079331, grad/param norm = 1.6165e-01, time/batch = 15.5511s	
6674/28500 (epoch 11.709), train_loss = 1.33260793, grad/param norm = 1.7434e-01, time/batch = 15.2033s	
6675/28500 (epoch 11.711), train_loss = 1.15453201, grad/param norm = 1.7568e-01, time/batch = 14.9057s	
6676/28500 (epoch 11.712), train_loss = 1.29828383, grad/param norm = 1.5722e-01, time/batch = 15.2240s	
6677/28500 (epoch 11.714), train_loss = 1.31305152, grad/param norm = 1.6533e-01, time/batch = 20.3881s	
6678/28500 (epoch 11.716), train_loss = 1.18024530, grad/param norm = 1.6035e-01, time/batch = 22.6144s	
6679/28500 (epoch 11.718), train_loss = 1.16466949, grad/param norm = 1.5224e-01, time/batch = 14.9692s	
6680/28500 (epoch 11.719), train_loss = 1.19503782, grad/param norm = 1.5206e-01, time/batch = 15.2535s	
6681/28500 (epoch 11.721), train_loss = 1.01318354, grad/param norm = 1.4640e-01, time/batch = 15.5079s	
6682/28500 (epoch 11.723), train_loss = 1.20445458, grad/param norm = 1.7041e-01, time/batch = 15.2102s	
6683/28500 (epoch 11.725), train_loss = 1.31761491, grad/param norm = 1.5038e-01, time/batch = 15.0555s	
6684/28500 (epoch 11.726), train_loss = 1.22591079, grad/param norm = 1.4580e-01, time/batch = 15.1314s	
6685/28500 (epoch 11.728), train_loss = 1.06742508, grad/param norm = 1.3466e-01, time/batch = 15.1375s	
6686/28500 (epoch 11.730), train_loss = 1.25874079, grad/param norm = 1.6915e-01, time/batch = 15.3000s	
6687/28500 (epoch 11.732), train_loss = 1.04026096, grad/param norm = 1.4962e-01, time/batch = 15.4702s	
6688/28500 (epoch 11.733), train_loss = 1.01943822, grad/param norm = 1.3818e-01, time/batch = 15.4455s	
6689/28500 (epoch 11.735), train_loss = 1.04400519, grad/param norm = 1.4140e-01, time/batch = 15.3667s	
6690/28500 (epoch 11.737), train_loss = 1.00135127, grad/param norm = 1.3507e-01, time/batch = 14.9852s	
6691/28500 (epoch 11.739), train_loss = 1.17312226, grad/param norm = 1.6236e-01, time/batch = 15.5257s	
6692/28500 (epoch 11.740), train_loss = 1.20693590, grad/param norm = 1.5710e-01, time/batch = 15.2183s	
6693/28500 (epoch 11.742), train_loss = 1.10568407, grad/param norm = 1.4653e-01, time/batch = 15.3491s	
6694/28500 (epoch 11.744), train_loss = 1.25769370, grad/param norm = 1.6945e-01, time/batch = 15.1973s	
6695/28500 (epoch 11.746), train_loss = 1.08864628, grad/param norm = 1.4067e-01, time/batch = 15.2779s	
6696/28500 (epoch 11.747), train_loss = 1.11143079, grad/param norm = 1.4966e-01, time/batch = 15.4074s	
6697/28500 (epoch 11.749), train_loss = 1.36755590, grad/param norm = 1.8129e-01, time/batch = 15.0477s	
6698/28500 (epoch 11.751), train_loss = 1.11813891, grad/param norm = 1.7606e-01, time/batch = 15.1105s	
6699/28500 (epoch 11.753), train_loss = 1.10258491, grad/param norm = 1.3823e-01, time/batch = 15.0209s	
6700/28500 (epoch 11.754), train_loss = 1.04281645, grad/param norm = 1.4926e-01, time/batch = 15.2240s	
6701/28500 (epoch 11.756), train_loss = 1.30931588, grad/param norm = 1.5828e-01, time/batch = 15.2080s	
6702/28500 (epoch 11.758), train_loss = 1.25562606, grad/param norm = 1.5483e-01, time/batch = 15.3957s	
6703/28500 (epoch 11.760), train_loss = 1.04898986, grad/param norm = 1.4788e-01, time/batch = 15.3143s	
6704/28500 (epoch 11.761), train_loss = 1.08666397, grad/param norm = 1.6125e-01, time/batch = 15.2341s	
6705/28500 (epoch 11.763), train_loss = 0.96634224, grad/param norm = 1.4772e-01, time/batch = 15.2346s	
6706/28500 (epoch 11.765), train_loss = 1.12840585, grad/param norm = 1.4765e-01, time/batch = 15.4722s	
6707/28500 (epoch 11.767), train_loss = 0.99440358, grad/param norm = 1.3432e-01, time/batch = 15.4776s	
6708/28500 (epoch 11.768), train_loss = 1.30725239, grad/param norm = 1.7455e-01, time/batch = 15.2901s	
6709/28500 (epoch 11.770), train_loss = 1.02787989, grad/param norm = 1.4857e-01, time/batch = 15.2898s	
6710/28500 (epoch 11.772), train_loss = 0.93363734, grad/param norm = 1.3985e-01, time/batch = 15.4847s	
6711/28500 (epoch 11.774), train_loss = 1.21447862, grad/param norm = 1.5574e-01, time/batch = 15.5344s	
6712/28500 (epoch 11.775), train_loss = 1.25845516, grad/param norm = 1.5217e-01, time/batch = 15.2997s	
6713/28500 (epoch 11.777), train_loss = 1.24488845, grad/param norm = 1.5230e-01, time/batch = 15.5457s	
6714/28500 (epoch 11.779), train_loss = 1.01444853, grad/param norm = 1.3616e-01, time/batch = 15.3175s	
6715/28500 (epoch 11.781), train_loss = 1.23827709, grad/param norm = 1.5968e-01, time/batch = 15.2227s	
6716/28500 (epoch 11.782), train_loss = 1.27790837, grad/param norm = 1.7999e-01, time/batch = 15.4607s	
6717/28500 (epoch 11.784), train_loss = 0.99686480, grad/param norm = 1.3173e-01, time/batch = 15.6011s	
6718/28500 (epoch 11.786), train_loss = 1.10065909, grad/param norm = 1.3734e-01, time/batch = 15.2030s	
6719/28500 (epoch 11.788), train_loss = 1.21736315, grad/param norm = 1.5507e-01, time/batch = 15.0403s	
6720/28500 (epoch 11.789), train_loss = 0.93380257, grad/param norm = 1.5798e-01, time/batch = 15.1793s	
6721/28500 (epoch 11.791), train_loss = 1.18215124, grad/param norm = 1.6916e-01, time/batch = 15.3262s	
6722/28500 (epoch 11.793), train_loss = 1.12057359, grad/param norm = 1.5556e-01, time/batch = 15.1339s	
6723/28500 (epoch 11.795), train_loss = 1.19618932, grad/param norm = 1.5276e-01, time/batch = 15.2582s	
6724/28500 (epoch 11.796), train_loss = 1.08264165, grad/param norm = 1.5271e-01, time/batch = 15.4665s	
6725/28500 (epoch 11.798), train_loss = 1.04843753, grad/param norm = 1.4989e-01, time/batch = 15.3085s	
6726/28500 (epoch 11.800), train_loss = 1.06632685, grad/param norm = 1.5778e-01, time/batch = 15.2315s	
6727/28500 (epoch 11.802), train_loss = 1.18964271, grad/param norm = 1.8558e-01, time/batch = 15.1391s	
6728/28500 (epoch 11.804), train_loss = 1.18568081, grad/param norm = 1.5016e-01, time/batch = 15.1231s	
6729/28500 (epoch 11.805), train_loss = 1.20171152, grad/param norm = 1.7366e-01, time/batch = 15.0546s	
6730/28500 (epoch 11.807), train_loss = 1.26669314, grad/param norm = 1.6174e-01, time/batch = 15.0420s	
6731/28500 (epoch 11.809), train_loss = 1.17833908, grad/param norm = 1.5943e-01, time/batch = 15.1250s	
6732/28500 (epoch 11.811), train_loss = 1.26625238, grad/param norm = 1.7029e-01, time/batch = 15.2913s	
6733/28500 (epoch 11.812), train_loss = 1.22936235, grad/param norm = 1.6882e-01, time/batch = 15.2137s	
6734/28500 (epoch 11.814), train_loss = 1.16674925, grad/param norm = 1.5731e-01, time/batch = 15.5020s	
6735/28500 (epoch 11.816), train_loss = 1.33948101, grad/param norm = 1.7721e-01, time/batch = 15.6861s	
6736/28500 (epoch 11.818), train_loss = 1.28001009, grad/param norm = 1.5712e-01, time/batch = 15.5503s	
6737/28500 (epoch 11.819), train_loss = 1.18540599, grad/param norm = 1.4880e-01, time/batch = 15.2911s	
6738/28500 (epoch 11.821), train_loss = 1.12089333, grad/param norm = 1.5576e-01, time/batch = 15.2292s	
6739/28500 (epoch 11.823), train_loss = 1.36190846, grad/param norm = 1.7961e-01, time/batch = 15.2487s	
6740/28500 (epoch 11.825), train_loss = 1.16084222, grad/param norm = 1.5982e-01, time/batch = 15.6155s	
6741/28500 (epoch 11.826), train_loss = 1.23819174, grad/param norm = 1.6530e-01, time/batch = 15.7108s	
6742/28500 (epoch 11.828), train_loss = 1.06352370, grad/param norm = 1.6095e-01, time/batch = 15.4801s	
6743/28500 (epoch 11.830), train_loss = 1.14067288, grad/param norm = 1.5595e-01, time/batch = 15.4530s	
6744/28500 (epoch 11.832), train_loss = 1.19491338, grad/param norm = 1.7279e-01, time/batch = 15.4200s	
6745/28500 (epoch 11.833), train_loss = 1.35817415, grad/param norm = 1.6216e-01, time/batch = 15.1894s	
6746/28500 (epoch 11.835), train_loss = 1.14352177, grad/param norm = 1.5737e-01, time/batch = 15.4545s	
6747/28500 (epoch 11.837), train_loss = 1.04167239, grad/param norm = 1.5806e-01, time/batch = 15.3201s	
6748/28500 (epoch 11.839), train_loss = 1.30371929, grad/param norm = 1.8829e-01, time/batch = 15.2904s	
6749/28500 (epoch 11.840), train_loss = 1.32439312, grad/param norm = 1.8521e-01, time/batch = 15.2671s	
6750/28500 (epoch 11.842), train_loss = 1.27423903, grad/param norm = 1.6321e-01, time/batch = 15.4643s	
6751/28500 (epoch 11.844), train_loss = 1.21809110, grad/param norm = 1.5946e-01, time/batch = 15.1469s	
6752/28500 (epoch 11.846), train_loss = 1.34226979, grad/param norm = 1.7060e-01, time/batch = 14.9909s	
6753/28500 (epoch 11.847), train_loss = 1.14219741, grad/param norm = 1.5508e-01, time/batch = 15.3923s	
6754/28500 (epoch 11.849), train_loss = 1.14540751, grad/param norm = 1.5231e-01, time/batch = 15.5342s	
6755/28500 (epoch 11.851), train_loss = 1.03406947, grad/param norm = 1.4563e-01, time/batch = 15.4496s	
6756/28500 (epoch 11.853), train_loss = 1.20662418, grad/param norm = 1.6337e-01, time/batch = 15.2399s	
6757/28500 (epoch 11.854), train_loss = 1.21536961, grad/param norm = 1.6579e-01, time/batch = 15.5399s	
6758/28500 (epoch 11.856), train_loss = 1.29320080, grad/param norm = 1.8499e-01, time/batch = 15.2822s	
6759/28500 (epoch 11.858), train_loss = 1.06122963, grad/param norm = 1.4721e-01, time/batch = 15.3616s	
6760/28500 (epoch 11.860), train_loss = 1.24141021, grad/param norm = 1.7826e-01, time/batch = 15.5074s	
6761/28500 (epoch 11.861), train_loss = 1.21646187, grad/param norm = 1.7064e-01, time/batch = 15.4443s	
6762/28500 (epoch 11.863), train_loss = 1.31319432, grad/param norm = 1.7197e-01, time/batch = 15.4667s	
6763/28500 (epoch 11.865), train_loss = 1.18551538, grad/param norm = 1.5409e-01, time/batch = 15.3167s	
6764/28500 (epoch 11.867), train_loss = 1.26007841, grad/param norm = 1.7697e-01, time/batch = 15.2280s	
6765/28500 (epoch 11.868), train_loss = 1.07302114, grad/param norm = 1.4532e-01, time/batch = 15.2152s	
6766/28500 (epoch 11.870), train_loss = 0.99937003, grad/param norm = 1.4091e-01, time/batch = 15.1299s	
6767/28500 (epoch 11.872), train_loss = 1.24194924, grad/param norm = 1.7086e-01, time/batch = 15.4754s	
6768/28500 (epoch 11.874), train_loss = 1.20786770, grad/param norm = 1.7217e-01, time/batch = 15.4826s	
6769/28500 (epoch 11.875), train_loss = 1.30061607, grad/param norm = 1.7206e-01, time/batch = 15.2489s	
6770/28500 (epoch 11.877), train_loss = 1.22020475, grad/param norm = 1.5454e-01, time/batch = 15.3728s	
6771/28500 (epoch 11.879), train_loss = 1.18525065, grad/param norm = 1.4910e-01, time/batch = 15.4555s	
6772/28500 (epoch 11.881), train_loss = 1.22075047, grad/param norm = 1.5745e-01, time/batch = 15.4720s	
6773/28500 (epoch 11.882), train_loss = 1.15453073, grad/param norm = 1.5059e-01, time/batch = 15.1591s	
6774/28500 (epoch 11.884), train_loss = 1.22449601, grad/param norm = 1.6415e-01, time/batch = 15.6245s	
6775/28500 (epoch 11.886), train_loss = 1.11673820, grad/param norm = 1.4071e-01, time/batch = 15.3146s	
6776/28500 (epoch 11.888), train_loss = 1.06259870, grad/param norm = 1.4738e-01, time/batch = 15.3775s	
6777/28500 (epoch 11.889), train_loss = 1.18869144, grad/param norm = 1.5469e-01, time/batch = 15.2889s	
6778/28500 (epoch 11.891), train_loss = 1.21786910, grad/param norm = 1.5696e-01, time/batch = 15.2078s	
6779/28500 (epoch 11.893), train_loss = 1.13123969, grad/param norm = 1.6871e-01, time/batch = 15.2197s	
6780/28500 (epoch 11.895), train_loss = 1.37168773, grad/param norm = 1.7788e-01, time/batch = 15.1276s	
6781/28500 (epoch 11.896), train_loss = 1.27569311, grad/param norm = 1.6428e-01, time/batch = 15.3136s	
6782/28500 (epoch 11.898), train_loss = 1.16563398, grad/param norm = 1.5104e-01, time/batch = 15.5506s	
6783/28500 (epoch 11.900), train_loss = 1.05093983, grad/param norm = 1.5082e-01, time/batch = 15.5568s	
6784/28500 (epoch 11.902), train_loss = 1.06787694, grad/param norm = 1.4857e-01, time/batch = 15.2838s	
6785/28500 (epoch 11.904), train_loss = 1.09027816, grad/param norm = 1.4687e-01, time/batch = 15.3056s	
6786/28500 (epoch 11.905), train_loss = 1.21729212, grad/param norm = 1.6089e-01, time/batch = 15.2121s	
6787/28500 (epoch 11.907), train_loss = 1.22366909, grad/param norm = 1.6428e-01, time/batch = 15.3298s	
6788/28500 (epoch 11.909), train_loss = 1.06520295, grad/param norm = 1.7126e-01, time/batch = 15.2928s	
6789/28500 (epoch 11.911), train_loss = 1.08891321, grad/param norm = 1.4049e-01, time/batch = 15.2853s	
6790/28500 (epoch 11.912), train_loss = 0.94227654, grad/param norm = 1.3227e-01, time/batch = 15.4715s	
6791/28500 (epoch 11.914), train_loss = 1.30949468, grad/param norm = 1.5162e-01, time/batch = 15.4755s	
6792/28500 (epoch 11.916), train_loss = 1.24970211, grad/param norm = 1.7032e-01, time/batch = 15.1495s	
6793/28500 (epoch 11.918), train_loss = 1.20737575, grad/param norm = 1.7231e-01, time/batch = 15.3683s	
6794/28500 (epoch 11.919), train_loss = 1.15772156, grad/param norm = 1.4987e-01, time/batch = 15.5596s	
6795/28500 (epoch 11.921), train_loss = 1.36017511, grad/param norm = 1.8052e-01, time/batch = 15.2994s	
6796/28500 (epoch 11.923), train_loss = 1.20844508, grad/param norm = 1.7905e-01, time/batch = 15.3692s	
6797/28500 (epoch 11.925), train_loss = 1.09425435, grad/param norm = 1.6475e-01, time/batch = 15.3607s	
6798/28500 (epoch 11.926), train_loss = 1.17899115, grad/param norm = 1.5711e-01, time/batch = 15.3401s	
6799/28500 (epoch 11.928), train_loss = 1.13021726, grad/param norm = 1.5090e-01, time/batch = 15.3510s	
6800/28500 (epoch 11.930), train_loss = 0.91877924, grad/param norm = 1.3271e-01, time/batch = 15.3984s	
6801/28500 (epoch 11.932), train_loss = 0.96827434, grad/param norm = 1.3154e-01, time/batch = 15.4694s	
6802/28500 (epoch 11.933), train_loss = 1.21519365, grad/param norm = 1.5677e-01, time/batch = 15.4642s	
6803/28500 (epoch 11.935), train_loss = 1.27308252, grad/param norm = 1.7096e-01, time/batch = 15.2081s	
6804/28500 (epoch 11.937), train_loss = 1.31880898, grad/param norm = 1.8211e-01, time/batch = 15.2228s	
6805/28500 (epoch 11.939), train_loss = 1.37156763, grad/param norm = 1.7470e-01, time/batch = 15.2138s	
6806/28500 (epoch 11.940), train_loss = 1.08313451, grad/param norm = 1.6148e-01, time/batch = 15.2379s	
6807/28500 (epoch 11.942), train_loss = 1.27245445, grad/param norm = 1.6463e-01, time/batch = 15.5422s	
6808/28500 (epoch 11.944), train_loss = 1.18614177, grad/param norm = 1.6186e-01, time/batch = 15.5382s	
6809/28500 (epoch 11.946), train_loss = 1.32177342, grad/param norm = 1.5659e-01, time/batch = 15.6022s	
6810/28500 (epoch 11.947), train_loss = 1.55430862, grad/param norm = 2.3783e-01, time/batch = 15.4001s	
6811/28500 (epoch 11.949), train_loss = 1.08719581, grad/param norm = 1.5359e-01, time/batch = 15.4585s	
6812/28500 (epoch 11.951), train_loss = 1.32508228, grad/param norm = 1.7762e-01, time/batch = 15.4783s	
6813/28500 (epoch 11.953), train_loss = 1.39536833, grad/param norm = 1.8010e-01, time/batch = 15.1906s	
6814/28500 (epoch 11.954), train_loss = 1.32824845, grad/param norm = 1.8091e-01, time/batch = 15.3187s	
6815/28500 (epoch 11.956), train_loss = 1.29940272, grad/param norm = 1.9859e-01, time/batch = 15.4672s	
6816/28500 (epoch 11.958), train_loss = 1.38705883, grad/param norm = 1.6610e-01, time/batch = 15.4823s	
6817/28500 (epoch 11.960), train_loss = 1.10302438, grad/param norm = 1.6427e-01, time/batch = 15.3635s	
6818/28500 (epoch 11.961), train_loss = 1.43341235, grad/param norm = 1.7584e-01, time/batch = 15.0528s	
6819/28500 (epoch 11.963), train_loss = 1.32630565, grad/param norm = 1.6258e-01, time/batch = 15.1221s	
6820/28500 (epoch 11.965), train_loss = 1.08283206, grad/param norm = 1.5037e-01, time/batch = 15.1340s	
6821/28500 (epoch 11.967), train_loss = 1.06758790, grad/param norm = 1.4594e-01, time/batch = 15.6989s	
6822/28500 (epoch 11.968), train_loss = 1.01887180, grad/param norm = 1.4069e-01, time/batch = 15.4740s	
6823/28500 (epoch 11.970), train_loss = 1.13120804, grad/param norm = 1.5018e-01, time/batch = 15.2915s	
6824/28500 (epoch 11.972), train_loss = 1.22871781, grad/param norm = 1.5946e-01, time/batch = 15.1158s	
6825/28500 (epoch 11.974), train_loss = 1.43734492, grad/param norm = 1.8951e-01, time/batch = 15.0883s	
6826/28500 (epoch 11.975), train_loss = 1.15856835, grad/param norm = 1.6589e-01, time/batch = 15.2570s	
6827/28500 (epoch 11.977), train_loss = 1.40444037, grad/param norm = 1.6801e-01, time/batch = 15.4496s	
6828/28500 (epoch 11.979), train_loss = 1.14002438, grad/param norm = 1.5797e-01, time/batch = 15.3327s	
6829/28500 (epoch 11.981), train_loss = 1.11077242, grad/param norm = 1.5037e-01, time/batch = 15.2788s	
6830/28500 (epoch 11.982), train_loss = 1.08584387, grad/param norm = 1.4719e-01, time/batch = 15.2078s	
6831/28500 (epoch 11.984), train_loss = 1.31540969, grad/param norm = 1.6716e-01, time/batch = 15.1270s	
6832/28500 (epoch 11.986), train_loss = 1.45191628, grad/param norm = 1.8166e-01, time/batch = 15.3636s	
6833/28500 (epoch 11.988), train_loss = 1.02671985, grad/param norm = 1.5951e-01, time/batch = 15.6112s	
6834/28500 (epoch 11.989), train_loss = 1.22836096, grad/param norm = 1.6663e-01, time/batch = 15.5540s	
6835/28500 (epoch 11.991), train_loss = 1.11777987, grad/param norm = 1.6685e-01, time/batch = 15.5582s	
6836/28500 (epoch 11.993), train_loss = 1.12148379, grad/param norm = 1.5723e-01, time/batch = 15.4046s	
6837/28500 (epoch 11.995), train_loss = 1.11277935, grad/param norm = 1.5634e-01, time/batch = 15.3787s	
6838/28500 (epoch 11.996), train_loss = 1.06507822, grad/param norm = 1.5132e-01, time/batch = 15.3721s	
6839/28500 (epoch 11.998), train_loss = 1.29421149, grad/param norm = 1.6047e-01, time/batch = 15.3900s	
decayed learning rate by a factor 0.97 to 0.001825346	
6840/28500 (epoch 12.000), train_loss = 1.12633658, grad/param norm = 1.4882e-01, time/batch = 15.4119s	
6841/28500 (epoch 12.002), train_loss = 1.36578988, grad/param norm = 1.7285e-01, time/batch = 15.5722s	
6842/28500 (epoch 12.004), train_loss = 1.16168837, grad/param norm = 1.5906e-01, time/batch = 15.2065s	
6843/28500 (epoch 12.005), train_loss = 1.28845768, grad/param norm = 1.6972e-01, time/batch = 15.0743s	
6844/28500 (epoch 12.007), train_loss = 1.05448278, grad/param norm = 1.4360e-01, time/batch = 15.2969s	
6845/28500 (epoch 12.009), train_loss = 1.26931746, grad/param norm = 1.6037e-01, time/batch = 15.2774s	
6846/28500 (epoch 12.011), train_loss = 1.15751773, grad/param norm = 1.8591e-01, time/batch = 15.5691s	
6847/28500 (epoch 12.012), train_loss = 1.03419423, grad/param norm = 1.3728e-01, time/batch = 15.5425s	
6848/28500 (epoch 12.014), train_loss = 1.06902028, grad/param norm = 1.4153e-01, time/batch = 15.5339s	
6849/28500 (epoch 12.016), train_loss = 1.15209653, grad/param norm = 1.4232e-01, time/batch = 15.4514s	
6850/28500 (epoch 12.018), train_loss = 1.24183572, grad/param norm = 1.6553e-01, time/batch = 15.2121s	
6851/28500 (epoch 12.019), train_loss = 1.28425811, grad/param norm = 1.6556e-01, time/batch = 15.2977s	
6852/28500 (epoch 12.021), train_loss = 1.24544253, grad/param norm = 1.4643e-01, time/batch = 15.5844s	
6853/28500 (epoch 12.023), train_loss = 1.15682961, grad/param norm = 1.5363e-01, time/batch = 15.5704s	
6854/28500 (epoch 12.025), train_loss = 1.18388975, grad/param norm = 1.5626e-01, time/batch = 15.4082s	
6855/28500 (epoch 12.026), train_loss = 1.21618008, grad/param norm = 1.6149e-01, time/batch = 15.3544s	
6856/28500 (epoch 12.028), train_loss = 1.25790219, grad/param norm = 1.6473e-01, time/batch = 15.2909s	
6857/28500 (epoch 12.030), train_loss = 1.28520149, grad/param norm = 1.8122e-01, time/batch = 15.2648s	
6858/28500 (epoch 12.032), train_loss = 1.27566922, grad/param norm = 1.6708e-01, time/batch = 15.2183s	
6859/28500 (epoch 12.033), train_loss = 1.38214699, grad/param norm = 1.7599e-01, time/batch = 15.1758s	
6860/28500 (epoch 12.035), train_loss = 1.22294341, grad/param norm = 1.6061e-01, time/batch = 15.2103s	
6861/28500 (epoch 12.037), train_loss = 1.28025484, grad/param norm = 1.4803e-01, time/batch = 15.4009s	
6862/28500 (epoch 12.039), train_loss = 1.33476464, grad/param norm = 1.7192e-01, time/batch = 15.5462s	
6863/28500 (epoch 12.040), train_loss = 1.36709157, grad/param norm = 1.6552e-01, time/batch = 15.3871s	
6864/28500 (epoch 12.042), train_loss = 1.28578835, grad/param norm = 1.7811e-01, time/batch = 15.2868s	
6865/28500 (epoch 12.044), train_loss = 1.20099478, grad/param norm = 1.6064e-01, time/batch = 15.3076s	
6866/28500 (epoch 12.046), train_loss = 1.41648094, grad/param norm = 1.6378e-01, time/batch = 15.2256s	
6867/28500 (epoch 12.047), train_loss = 1.32551199, grad/param norm = 1.7676e-01, time/batch = 15.2429s	
6868/28500 (epoch 12.049), train_loss = 1.22725102, grad/param norm = 1.6128e-01, time/batch = 15.1665s	
6869/28500 (epoch 12.051), train_loss = 1.17610394, grad/param norm = 1.5252e-01, time/batch = 15.2310s	
6870/28500 (epoch 12.053), train_loss = 1.24869170, grad/param norm = 1.6832e-01, time/batch = 15.1272s	
6871/28500 (epoch 12.054), train_loss = 1.30690567, grad/param norm = 1.6940e-01, time/batch = 15.5374s	
6872/28500 (epoch 12.056), train_loss = 1.07644525, grad/param norm = 1.4093e-01, time/batch = 15.2201s	
6873/28500 (epoch 12.058), train_loss = 1.09144047, grad/param norm = 1.6198e-01, time/batch = 15.0798s	
6874/28500 (epoch 12.060), train_loss = 1.27933848, grad/param norm = 1.6235e-01, time/batch = 15.3684s	
6875/28500 (epoch 12.061), train_loss = 1.24120611, grad/param norm = 1.7091e-01, time/batch = 15.4448s	
6876/28500 (epoch 12.063), train_loss = 1.30764004, grad/param norm = 1.6544e-01, time/batch = 15.2365s	
6877/28500 (epoch 12.065), train_loss = 1.33860044, grad/param norm = 1.6678e-01, time/batch = 15.1325s	
6878/28500 (epoch 12.067), train_loss = 1.13426276, grad/param norm = 1.4325e-01, time/batch = 15.1081s	
6879/28500 (epoch 12.068), train_loss = 1.17143357, grad/param norm = 1.5924e-01, time/batch = 15.0942s	
6880/28500 (epoch 12.070), train_loss = 1.27162640, grad/param norm = 1.7191e-01, time/batch = 15.3698s	
6881/28500 (epoch 12.072), train_loss = 1.41734706, grad/param norm = 1.7326e-01, time/batch = 15.3240s	
6882/28500 (epoch 12.074), train_loss = 1.24729535, grad/param norm = 1.5713e-01, time/batch = 15.3027s	
6883/28500 (epoch 12.075), train_loss = 1.19435177, grad/param norm = 1.3632e-01, time/batch = 15.5264s	
6884/28500 (epoch 12.077), train_loss = 1.25713260, grad/param norm = 1.5839e-01, time/batch = 15.2389s	
6885/28500 (epoch 12.079), train_loss = 1.17935019, grad/param norm = 1.4074e-01, time/batch = 15.2262s	
6886/28500 (epoch 12.081), train_loss = 1.32668813, grad/param norm = 1.8023e-01, time/batch = 15.2791s	
6887/28500 (epoch 12.082), train_loss = 1.24740003, grad/param norm = 1.7634e-01, time/batch = 15.4750s	
6888/28500 (epoch 12.084), train_loss = 1.27899920, grad/param norm = 1.5564e-01, time/batch = 15.5541s	
6889/28500 (epoch 12.086), train_loss = 1.18223412, grad/param norm = 1.6115e-01, time/batch = 15.3879s	
6890/28500 (epoch 12.088), train_loss = 1.08010075, grad/param norm = 1.5109e-01, time/batch = 15.4426s	
6891/28500 (epoch 12.089), train_loss = 1.32605516, grad/param norm = 1.5020e-01, time/batch = 15.5582s	
6892/28500 (epoch 12.091), train_loss = 1.08581076, grad/param norm = 1.5864e-01, time/batch = 15.4182s	
6893/28500 (epoch 12.093), train_loss = 1.26809340, grad/param norm = 1.6422e-01, time/batch = 15.4704s	
6894/28500 (epoch 12.095), train_loss = 1.13222982, grad/param norm = 1.4378e-01, time/batch = 15.2355s	
6895/28500 (epoch 12.096), train_loss = 1.36715541, grad/param norm = 1.6642e-01, time/batch = 15.2016s	
6896/28500 (epoch 12.098), train_loss = 1.34155887, grad/param norm = 1.7660e-01, time/batch = 15.2976s	
6897/28500 (epoch 12.100), train_loss = 1.15855789, grad/param norm = 1.4916e-01, time/batch = 15.3445s	
6898/28500 (epoch 12.102), train_loss = 1.36583747, grad/param norm = 1.6657e-01, time/batch = 15.2026s	
6899/28500 (epoch 12.104), train_loss = 1.20068435, grad/param norm = 1.7474e-01, time/batch = 15.0281s	
6900/28500 (epoch 12.105), train_loss = 1.29363975, grad/param norm = 1.6319e-01, time/batch = 15.2080s	
6901/28500 (epoch 12.107), train_loss = 1.09719595, grad/param norm = 1.5496e-01, time/batch = 15.3198s	
6902/28500 (epoch 12.109), train_loss = 1.09478019, grad/param norm = 1.5794e-01, time/batch = 15.4487s	
6903/28500 (epoch 12.111), train_loss = 1.17195558, grad/param norm = 1.5709e-01, time/batch = 15.3252s	
6904/28500 (epoch 12.112), train_loss = 1.29932522, grad/param norm = 1.7409e-01, time/batch = 15.5239s	
6905/28500 (epoch 12.114), train_loss = 1.19524522, grad/param norm = 1.6119e-01, time/batch = 15.6163s	
6906/28500 (epoch 12.116), train_loss = 1.38815069, grad/param norm = 1.5976e-01, time/batch = 15.5516s	
6907/28500 (epoch 12.118), train_loss = 1.06983231, grad/param norm = 1.5196e-01, time/batch = 15.3832s	
6908/28500 (epoch 12.119), train_loss = 1.27343271, grad/param norm = 1.8977e-01, time/batch = 15.4162s	
6909/28500 (epoch 12.121), train_loss = 1.42819508, grad/param norm = 1.8381e-01, time/batch = 15.0832s	
6910/28500 (epoch 12.123), train_loss = 1.27935792, grad/param norm = 1.6477e-01, time/batch = 26.8664s	
6911/28500 (epoch 12.125), train_loss = 1.24366004, grad/param norm = 1.5546e-01, time/batch = 15.2198s	
6912/28500 (epoch 12.126), train_loss = 1.19339264, grad/param norm = 1.5125e-01, time/batch = 15.1286s	
6913/28500 (epoch 12.128), train_loss = 1.15687234, grad/param norm = 1.5535e-01, time/batch = 15.4312s	
6914/28500 (epoch 12.130), train_loss = 1.09321635, grad/param norm = 1.5480e-01, time/batch = 15.3854s	
6915/28500 (epoch 12.132), train_loss = 1.29387523, grad/param norm = 1.7099e-01, time/batch = 15.3023s	
6916/28500 (epoch 12.133), train_loss = 1.25349477, grad/param norm = 1.6527e-01, time/batch = 15.4564s	
6917/28500 (epoch 12.135), train_loss = 1.19221396, grad/param norm = 1.4524e-01, time/batch = 15.6334s	
6918/28500 (epoch 12.137), train_loss = 1.15334940, grad/param norm = 1.5997e-01, time/batch = 15.2895s	
6919/28500 (epoch 12.139), train_loss = 1.18437818, grad/param norm = 1.4891e-01, time/batch = 15.1214s	
6920/28500 (epoch 12.140), train_loss = 1.25557964, grad/param norm = 1.4748e-01, time/batch = 15.3282s	
6921/28500 (epoch 12.142), train_loss = 1.21644682, grad/param norm = 1.6535e-01, time/batch = 15.5337s	
6922/28500 (epoch 12.144), train_loss = 1.10772681, grad/param norm = 1.4721e-01, time/batch = 15.2893s	
6923/28500 (epoch 12.146), train_loss = 1.14068486, grad/param norm = 1.4823e-01, time/batch = 15.1083s	
6924/28500 (epoch 12.147), train_loss = 1.04713214, grad/param norm = 1.4723e-01, time/batch = 15.0429s	
6925/28500 (epoch 12.149), train_loss = 1.04917320, grad/param norm = 1.4141e-01, time/batch = 15.2095s	
6926/28500 (epoch 12.151), train_loss = 1.05764223, grad/param norm = 1.3721e-01, time/batch = 15.0662s	
6927/28500 (epoch 12.153), train_loss = 1.21752963, grad/param norm = 1.5394e-01, time/batch = 15.3004s	
6928/28500 (epoch 12.154), train_loss = 1.12074774, grad/param norm = 1.5810e-01, time/batch = 15.4476s	
6929/28500 (epoch 12.156), train_loss = 1.35714155, grad/param norm = 1.7506e-01, time/batch = 15.1809s	
6930/28500 (epoch 12.158), train_loss = 1.17860867, grad/param norm = 1.5799e-01, time/batch = 15.2358s	
6931/28500 (epoch 12.160), train_loss = 1.09634357, grad/param norm = 1.4472e-01, time/batch = 15.3688s	
6932/28500 (epoch 12.161), train_loss = 1.18148046, grad/param norm = 1.5807e-01, time/batch = 15.3549s	
6933/28500 (epoch 12.163), train_loss = 1.06586668, grad/param norm = 1.6653e-01, time/batch = 15.1704s	
6934/28500 (epoch 12.165), train_loss = 1.39255312, grad/param norm = 1.5200e-01, time/batch = 15.2272s	
6935/28500 (epoch 12.167), train_loss = 1.46259249, grad/param norm = 1.7904e-01, time/batch = 15.4792s	
6936/28500 (epoch 12.168), train_loss = 1.30989215, grad/param norm = 1.8928e-01, time/batch = 15.3704s	
6937/28500 (epoch 12.170), train_loss = 1.31608925, grad/param norm = 1.7485e-01, time/batch = 15.3656s	
6938/28500 (epoch 12.172), train_loss = 1.20527453, grad/param norm = 1.7375e-01, time/batch = 15.3125s	
6939/28500 (epoch 12.174), train_loss = 1.35343388, grad/param norm = 1.7006e-01, time/batch = 15.4417s	
6940/28500 (epoch 12.175), train_loss = 1.18258162, grad/param norm = 1.4354e-01, time/batch = 15.6169s	
6941/28500 (epoch 12.177), train_loss = 1.27577716, grad/param norm = 1.6068e-01, time/batch = 15.6421s	
6942/28500 (epoch 12.179), train_loss = 1.18731604, grad/param norm = 1.7953e-01, time/batch = 15.5511s	
6943/28500 (epoch 12.181), train_loss = 1.25517415, grad/param norm = 1.5818e-01, time/batch = 15.6357s	
6944/28500 (epoch 12.182), train_loss = 1.20722691, grad/param norm = 1.5080e-01, time/batch = 15.5545s	
6945/28500 (epoch 12.184), train_loss = 1.43746166, grad/param norm = 1.8331e-01, time/batch = 15.5641s	
6946/28500 (epoch 12.186), train_loss = 1.31418269, grad/param norm = 1.6636e-01, time/batch = 15.7771s	
6947/28500 (epoch 12.188), train_loss = 1.21294141, grad/param norm = 1.5328e-01, time/batch = 15.5660s	
6948/28500 (epoch 12.189), train_loss = 1.26791683, grad/param norm = 1.7231e-01, time/batch = 15.3624s	
6949/28500 (epoch 12.191), train_loss = 1.43996492, grad/param norm = 1.7461e-01, time/batch = 15.3577s	
6950/28500 (epoch 12.193), train_loss = 1.29455711, grad/param norm = 1.8002e-01, time/batch = 15.4082s	
6951/28500 (epoch 12.195), train_loss = 1.34645852, grad/param norm = 1.6746e-01, time/batch = 15.2456s	
6952/28500 (epoch 12.196), train_loss = 1.28014482, grad/param norm = 1.6549e-01, time/batch = 15.2003s	
6953/28500 (epoch 12.198), train_loss = 1.25224103, grad/param norm = 1.7619e-01, time/batch = 14.9871s	
6954/28500 (epoch 12.200), train_loss = 1.22938964, grad/param norm = 1.5501e-01, time/batch = 15.2131s	
6955/28500 (epoch 12.202), train_loss = 1.21723916, grad/param norm = 1.6507e-01, time/batch = 15.1331s	
6956/28500 (epoch 12.204), train_loss = 1.13098039, grad/param norm = 1.5278e-01, time/batch = 15.3781s	
6957/28500 (epoch 12.205), train_loss = 1.18846300, grad/param norm = 1.6410e-01, time/batch = 15.4641s	
6958/28500 (epoch 12.207), train_loss = 1.15877035, grad/param norm = 1.6103e-01, time/batch = 15.1859s	
6959/28500 (epoch 12.209), train_loss = 1.21606244, grad/param norm = 1.6297e-01, time/batch = 15.3090s	
6960/28500 (epoch 12.211), train_loss = 1.07780399, grad/param norm = 1.5292e-01, time/batch = 15.6580s	
6961/28500 (epoch 12.212), train_loss = 1.07362122, grad/param norm = 1.4927e-01, time/batch = 15.5268s	
6962/28500 (epoch 12.214), train_loss = 1.23019455, grad/param norm = 1.7032e-01, time/batch = 15.6437s	
6963/28500 (epoch 12.216), train_loss = 1.08705145, grad/param norm = 1.4715e-01, time/batch = 15.5527s	
6964/28500 (epoch 12.218), train_loss = 1.33692247, grad/param norm = 1.5722e-01, time/batch = 15.6289s	
6965/28500 (epoch 12.219), train_loss = 1.27108856, grad/param norm = 1.7719e-01, time/batch = 15.5712s	
6966/28500 (epoch 12.221), train_loss = 1.11701186, grad/param norm = 1.7353e-01, time/batch = 15.2968s	
6967/28500 (epoch 12.223), train_loss = 1.32639531, grad/param norm = 1.6645e-01, time/batch = 15.4263s	
6968/28500 (epoch 12.225), train_loss = 1.35335039, grad/param norm = 1.5594e-01, time/batch = 15.3598s	
6969/28500 (epoch 12.226), train_loss = 1.17000117, grad/param norm = 1.4560e-01, time/batch = 15.1625s	
6970/28500 (epoch 12.228), train_loss = 1.27879869, grad/param norm = 1.4474e-01, time/batch = 15.2788s	
6971/28500 (epoch 12.230), train_loss = 1.31635671, grad/param norm = 1.6277e-01, time/batch = 15.3316s	
6972/28500 (epoch 12.232), train_loss = 1.27211401, grad/param norm = 1.5453e-01, time/batch = 15.4242s	
6973/28500 (epoch 12.233), train_loss = 1.26313464, grad/param norm = 1.7170e-01, time/batch = 15.4762s	
6974/28500 (epoch 12.235), train_loss = 1.16172732, grad/param norm = 1.5168e-01, time/batch = 15.5049s	
6975/28500 (epoch 12.237), train_loss = 1.06206973, grad/param norm = 1.3368e-01, time/batch = 15.4365s	
6976/28500 (epoch 12.239), train_loss = 1.13151329, grad/param norm = 1.4461e-01, time/batch = 15.2090s	
6977/28500 (epoch 12.240), train_loss = 1.08381025, grad/param norm = 1.5973e-01, time/batch = 15.0506s	
6978/28500 (epoch 12.242), train_loss = 1.25240977, grad/param norm = 1.7932e-01, time/batch = 15.0960s	
6979/28500 (epoch 12.244), train_loss = 1.28647374, grad/param norm = 1.5835e-01, time/batch = 15.2439s	
6980/28500 (epoch 12.246), train_loss = 1.33218736, grad/param norm = 1.6551e-01, time/batch = 15.3095s	
6981/28500 (epoch 12.247), train_loss = 1.42083944, grad/param norm = 1.7036e-01, time/batch = 15.4537s	
6982/28500 (epoch 12.249), train_loss = 1.22920981, grad/param norm = 1.6238e-01, time/batch = 15.3977s	
6983/28500 (epoch 12.251), train_loss = 1.11803803, grad/param norm = 1.4768e-01, time/batch = 15.5234s	
6984/28500 (epoch 12.253), train_loss = 1.41029726, grad/param norm = 1.7411e-01, time/batch = 15.4701s	
6985/28500 (epoch 12.254), train_loss = 1.36050831, grad/param norm = 1.7304e-01, time/batch = 15.3955s	
6986/28500 (epoch 12.256), train_loss = 1.15041379, grad/param norm = 1.4131e-01, time/batch = 15.3719s	
6987/28500 (epoch 12.258), train_loss = 1.21040825, grad/param norm = 1.6538e-01, time/batch = 15.3070s	
6988/28500 (epoch 12.260), train_loss = 1.15254301, grad/param norm = 1.4417e-01, time/batch = 15.1952s	
6989/28500 (epoch 12.261), train_loss = 1.15464906, grad/param norm = 1.6107e-01, time/batch = 15.4332s	
6990/28500 (epoch 12.263), train_loss = 1.35851476, grad/param norm = 1.8108e-01, time/batch = 15.1326s	
6991/28500 (epoch 12.265), train_loss = 1.22587555, grad/param norm = 1.5887e-01, time/batch = 15.2760s	
6992/28500 (epoch 12.267), train_loss = 1.39756355, grad/param norm = 1.7709e-01, time/batch = 14.8926s	
6993/28500 (epoch 12.268), train_loss = 1.30239152, grad/param norm = 1.4972e-01, time/batch = 15.0822s	
6994/28500 (epoch 12.270), train_loss = 1.25947585, grad/param norm = 1.7051e-01, time/batch = 15.4641s	
6995/28500 (epoch 12.272), train_loss = 1.20171507, grad/param norm = 1.6286e-01, time/batch = 15.3123s	
6996/28500 (epoch 12.274), train_loss = 1.33964687, grad/param norm = 1.6701e-01, time/batch = 15.3743s	
6997/28500 (epoch 12.275), train_loss = 1.26737765, grad/param norm = 1.6044e-01, time/batch = 15.2839s	
6998/28500 (epoch 12.277), train_loss = 1.23186607, grad/param norm = 1.5814e-01, time/batch = 15.5135s	
6999/28500 (epoch 12.279), train_loss = 1.27183547, grad/param norm = 1.7676e-01, time/batch = 15.5322s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch12.28_1.6011.t7	
7000/28500 (epoch 12.281), train_loss = 1.29252373, grad/param norm = 1.7772e-01, time/batch = 15.5783s	
7001/28500 (epoch 12.282), train_loss = 1.24446224, grad/param norm = 1.5670e-01, time/batch = 15.3665s	
7002/28500 (epoch 12.284), train_loss = 1.25256107, grad/param norm = 1.6781e-01, time/batch = 15.2097s	
7003/28500 (epoch 12.286), train_loss = 1.32575194, grad/param norm = 1.6518e-01, time/batch = 15.4356s	
7004/28500 (epoch 12.288), train_loss = 1.24995482, grad/param norm = 1.5508e-01, time/batch = 15.5375s	
7005/28500 (epoch 12.289), train_loss = 1.35455541, grad/param norm = 1.7276e-01, time/batch = 15.4354s	
7006/28500 (epoch 12.291), train_loss = 1.21165658, grad/param norm = 1.5630e-01, time/batch = 15.3326s	
7007/28500 (epoch 12.293), train_loss = 1.17497287, grad/param norm = 1.5524e-01, time/batch = 15.7122s	
7008/28500 (epoch 12.295), train_loss = 1.09573216, grad/param norm = 1.4786e-01, time/batch = 15.4954s	
7009/28500 (epoch 12.296), train_loss = 1.11309506, grad/param norm = 1.4962e-01, time/batch = 15.3025s	
7010/28500 (epoch 12.298), train_loss = 1.26388942, grad/param norm = 1.5713e-01, time/batch = 15.5048s	
7011/28500 (epoch 12.300), train_loss = 1.14963588, grad/param norm = 1.5491e-01, time/batch = 15.1397s	
7012/28500 (epoch 12.302), train_loss = 1.11869187, grad/param norm = 1.4800e-01, time/batch = 15.0521s	
7013/28500 (epoch 12.304), train_loss = 1.21197979, grad/param norm = 1.4631e-01, time/batch = 15.0486s	
7014/28500 (epoch 12.305), train_loss = 1.29151148, grad/param norm = 1.5927e-01, time/batch = 15.4433s	
7015/28500 (epoch 12.307), train_loss = 1.25660169, grad/param norm = 1.7158e-01, time/batch = 15.6003s	
7016/28500 (epoch 12.309), train_loss = 1.20593333, grad/param norm = 1.6193e-01, time/batch = 15.5636s	
7017/28500 (epoch 12.311), train_loss = 1.24115831, grad/param norm = 1.6295e-01, time/batch = 15.5094s	
7018/28500 (epoch 12.312), train_loss = 1.16603866, grad/param norm = 1.5977e-01, time/batch = 15.5322s	
7019/28500 (epoch 12.314), train_loss = 1.29966222, grad/param norm = 1.6896e-01, time/batch = 15.3132s	
7020/28500 (epoch 12.316), train_loss = 1.26015981, grad/param norm = 1.5108e-01, time/batch = 15.1271s	
7021/28500 (epoch 12.318), train_loss = 1.30647254, grad/param norm = 1.6758e-01, time/batch = 15.2027s	
7022/28500 (epoch 12.319), train_loss = 1.20348945, grad/param norm = 1.6715e-01, time/batch = 15.2271s	
7023/28500 (epoch 12.321), train_loss = 1.22922714, grad/param norm = 1.8184e-01, time/batch = 15.4266s	
7024/28500 (epoch 12.323), train_loss = 1.18223884, grad/param norm = 1.6690e-01, time/batch = 15.2842s	
7025/28500 (epoch 12.325), train_loss = 1.37217349, grad/param norm = 1.6373e-01, time/batch = 15.2869s	
7026/28500 (epoch 12.326), train_loss = 1.23311610, grad/param norm = 1.7068e-01, time/batch = 15.2716s	
7027/28500 (epoch 12.328), train_loss = 1.01731417, grad/param norm = 1.4676e-01, time/batch = 15.3982s	
7028/28500 (epoch 12.330), train_loss = 1.12135597, grad/param norm = 1.5153e-01, time/batch = 15.2266s	
7029/28500 (epoch 12.332), train_loss = 1.21110781, grad/param norm = 1.4906e-01, time/batch = 15.2226s	
7030/28500 (epoch 12.333), train_loss = 1.04243101, grad/param norm = 1.4541e-01, time/batch = 15.2261s	
7031/28500 (epoch 12.335), train_loss = 1.08228209, grad/param norm = 1.4081e-01, time/batch = 15.0521s	
7032/28500 (epoch 12.337), train_loss = 1.15575926, grad/param norm = 1.5509e-01, time/batch = 15.3407s	
7033/28500 (epoch 12.339), train_loss = 1.07530414, grad/param norm = 1.4206e-01, time/batch = 15.5116s	
7034/28500 (epoch 12.340), train_loss = 1.27670135, grad/param norm = 1.7154e-01, time/batch = 15.2382s	
7035/28500 (epoch 12.342), train_loss = 1.18786644, grad/param norm = 1.7340e-01, time/batch = 15.4083s	
7036/28500 (epoch 12.344), train_loss = 1.15014722, grad/param norm = 1.6364e-01, time/batch = 15.2103s	
7037/28500 (epoch 12.346), train_loss = 0.96935586, grad/param norm = 1.3695e-01, time/batch = 15.3610s	
7038/28500 (epoch 12.347), train_loss = 1.18742178, grad/param norm = 1.4590e-01, time/batch = 15.3631s	
7039/28500 (epoch 12.349), train_loss = 1.14639454, grad/param norm = 1.4893e-01, time/batch = 15.3896s	
7040/28500 (epoch 12.351), train_loss = 1.11751340, grad/param norm = 1.4892e-01, time/batch = 15.2900s	
7041/28500 (epoch 12.353), train_loss = 1.26726232, grad/param norm = 1.7335e-01, time/batch = 15.2808s	
7042/28500 (epoch 12.354), train_loss = 1.06848250, grad/param norm = 1.4575e-01, time/batch = 15.0387s	
7043/28500 (epoch 12.356), train_loss = 1.10063687, grad/param norm = 1.4054e-01, time/batch = 15.2876s	
7044/28500 (epoch 12.358), train_loss = 1.20545236, grad/param norm = 1.4804e-01, time/batch = 15.4306s	
7045/28500 (epoch 12.360), train_loss = 1.22788434, grad/param norm = 1.7275e-01, time/batch = 15.2802s	
7046/28500 (epoch 12.361), train_loss = 1.13054294, grad/param norm = 1.5766e-01, time/batch = 15.1711s	
7047/28500 (epoch 12.363), train_loss = 1.08504128, grad/param norm = 1.4475e-01, time/batch = 15.2364s	
7048/28500 (epoch 12.365), train_loss = 1.16168254, grad/param norm = 1.5967e-01, time/batch = 15.4037s	
7049/28500 (epoch 12.367), train_loss = 1.18063238, grad/param norm = 1.4989e-01, time/batch = 15.4402s	
7050/28500 (epoch 12.368), train_loss = 1.15401765, grad/param norm = 1.4362e-01, time/batch = 15.4382s	
7051/28500 (epoch 12.370), train_loss = 1.20846064, grad/param norm = 1.5483e-01, time/batch = 15.1915s	
7052/28500 (epoch 12.372), train_loss = 1.05288511, grad/param norm = 1.4869e-01, time/batch = 15.0279s	
7053/28500 (epoch 12.374), train_loss = 1.17768210, grad/param norm = 1.5006e-01, time/batch = 15.3784s	
7054/28500 (epoch 12.375), train_loss = 1.32518557, grad/param norm = 1.6295e-01, time/batch = 15.1824s	
7055/28500 (epoch 12.377), train_loss = 1.11323148, grad/param norm = 1.5333e-01, time/batch = 15.2269s	
7056/28500 (epoch 12.379), train_loss = 0.94644275, grad/param norm = 1.3188e-01, time/batch = 15.4729s	
7057/28500 (epoch 12.381), train_loss = 1.15592460, grad/param norm = 1.4248e-01, time/batch = 15.4393s	
7058/28500 (epoch 12.382), train_loss = 1.13361322, grad/param norm = 1.5771e-01, time/batch = 15.2130s	
7059/28500 (epoch 12.384), train_loss = 1.06466955, grad/param norm = 1.4533e-01, time/batch = 15.2600s	
7060/28500 (epoch 12.386), train_loss = 1.06966301, grad/param norm = 1.6303e-01, time/batch = 15.1757s	
7061/28500 (epoch 12.388), train_loss = 1.26939823, grad/param norm = 1.5871e-01, time/batch = 15.4624s	
7062/28500 (epoch 12.389), train_loss = 1.10190316, grad/param norm = 1.5543e-01, time/batch = 15.3009s	
7063/28500 (epoch 12.391), train_loss = 1.10577874, grad/param norm = 1.5091e-01, time/batch = 15.3780s	
7064/28500 (epoch 12.393), train_loss = 1.04548115, grad/param norm = 1.4772e-01, time/batch = 15.0626s	
7065/28500 (epoch 12.395), train_loss = 1.36525049, grad/param norm = 1.6237e-01, time/batch = 15.0586s	
7066/28500 (epoch 12.396), train_loss = 1.30005677, grad/param norm = 1.6517e-01, time/batch = 14.9748s	
7067/28500 (epoch 12.398), train_loss = 1.00048309, grad/param norm = 1.7764e-01, time/batch = 15.0678s	
7068/28500 (epoch 12.400), train_loss = 1.22355161, grad/param norm = 1.7517e-01, time/batch = 14.9714s	
7069/28500 (epoch 12.402), train_loss = 1.21360417, grad/param norm = 1.5698e-01, time/batch = 15.3610s	
7070/28500 (epoch 12.404), train_loss = 1.30846515, grad/param norm = 1.8153e-01, time/batch = 15.4131s	
7071/28500 (epoch 12.405), train_loss = 1.31606487, grad/param norm = 1.6695e-01, time/batch = 15.1249s	
7072/28500 (epoch 12.407), train_loss = 1.22495210, grad/param norm = 1.5605e-01, time/batch = 15.1079s	
7073/28500 (epoch 12.409), train_loss = 1.23199243, grad/param norm = 1.6350e-01, time/batch = 15.1759s	
7074/28500 (epoch 12.411), train_loss = 1.31374192, grad/param norm = 1.5197e-01, time/batch = 14.9861s	
7075/28500 (epoch 12.412), train_loss = 1.36712140, grad/param norm = 1.8634e-01, time/batch = 15.1390s	
7076/28500 (epoch 12.414), train_loss = 1.22372020, grad/param norm = 1.6758e-01, time/batch = 15.1916s	
7077/28500 (epoch 12.416), train_loss = 1.15749216, grad/param norm = 1.6906e-01, time/batch = 15.4689s	
7078/28500 (epoch 12.418), train_loss = 1.20212265, grad/param norm = 1.4310e-01, time/batch = 15.4955s	
7079/28500 (epoch 12.419), train_loss = 1.34920097, grad/param norm = 1.6647e-01, time/batch = 15.2238s	
7080/28500 (epoch 12.421), train_loss = 1.29464117, grad/param norm = 1.5886e-01, time/batch = 15.1067s	
7081/28500 (epoch 12.423), train_loss = 1.33234131, grad/param norm = 1.7079e-01, time/batch = 15.2109s	
7082/28500 (epoch 12.425), train_loss = 1.25151505, grad/param norm = 1.6558e-01, time/batch = 15.1411s	
7083/28500 (epoch 12.426), train_loss = 1.20111823, grad/param norm = 1.6741e-01, time/batch = 15.3040s	
7084/28500 (epoch 12.428), train_loss = 1.41897996, grad/param norm = 1.7317e-01, time/batch = 15.3699s	
7085/28500 (epoch 12.430), train_loss = 1.33773853, grad/param norm = 1.5790e-01, time/batch = 15.4225s	
7086/28500 (epoch 12.432), train_loss = 1.26848446, grad/param norm = 1.6372e-01, time/batch = 15.4875s	
7087/28500 (epoch 12.433), train_loss = 1.28603884, grad/param norm = 1.7460e-01, time/batch = 15.4663s	
7088/28500 (epoch 12.435), train_loss = 1.20749374, grad/param norm = 1.6963e-01, time/batch = 15.6087s	
7089/28500 (epoch 12.437), train_loss = 1.08055110, grad/param norm = 1.4218e-01, time/batch = 15.3705s	
7090/28500 (epoch 12.439), train_loss = 1.13388381, grad/param norm = 1.4566e-01, time/batch = 15.2297s	
7091/28500 (epoch 12.440), train_loss = 1.39120949, grad/param norm = 1.6836e-01, time/batch = 15.1304s	
7092/28500 (epoch 12.442), train_loss = 1.12543640, grad/param norm = 1.6564e-01, time/batch = 15.5271s	
7093/28500 (epoch 12.444), train_loss = 1.05378175, grad/param norm = 1.4014e-01, time/batch = 15.5657s	
7094/28500 (epoch 12.446), train_loss = 0.99477249, grad/param norm = 1.3809e-01, time/batch = 15.5421s	
7095/28500 (epoch 12.447), train_loss = 1.04929263, grad/param norm = 1.3649e-01, time/batch = 15.6146s	
7096/28500 (epoch 12.449), train_loss = 1.11843352, grad/param norm = 1.4205e-01, time/batch = 15.5138s	
7097/28500 (epoch 12.451), train_loss = 1.15609815, grad/param norm = 1.5025e-01, time/batch = 15.2194s	
7098/28500 (epoch 12.453), train_loss = 1.18178755, grad/param norm = 1.5916e-01, time/batch = 15.1421s	
7099/28500 (epoch 12.454), train_loss = 1.12542756, grad/param norm = 1.4462e-01, time/batch = 15.4203s	
7100/28500 (epoch 12.456), train_loss = 1.24414396, grad/param norm = 1.5516e-01, time/batch = 15.4861s	
7101/28500 (epoch 12.458), train_loss = 1.15515477, grad/param norm = 1.5631e-01, time/batch = 15.0727s	
7102/28500 (epoch 12.460), train_loss = 1.26365938, grad/param norm = 1.6138e-01, time/batch = 15.4478s	
7103/28500 (epoch 12.461), train_loss = 1.14142165, grad/param norm = 1.5615e-01, time/batch = 15.3581s	
7104/28500 (epoch 12.463), train_loss = 1.07824215, grad/param norm = 1.3585e-01, time/batch = 15.3747s	
7105/28500 (epoch 12.465), train_loss = 1.05981392, grad/param norm = 1.7008e-01, time/batch = 15.3089s	
7106/28500 (epoch 12.467), train_loss = 1.23472434, grad/param norm = 1.5706e-01, time/batch = 15.4640s	
7107/28500 (epoch 12.468), train_loss = 1.04886167, grad/param norm = 1.2383e-01, time/batch = 15.2980s	
7108/28500 (epoch 12.470), train_loss = 1.13656876, grad/param norm = 1.6091e-01, time/batch = 15.4593s	
7109/28500 (epoch 12.472), train_loss = 1.14534315, grad/param norm = 1.5690e-01, time/batch = 15.3622s	
7110/28500 (epoch 12.474), train_loss = 1.45264754, grad/param norm = 1.9189e-01, time/batch = 15.1949s	
7111/28500 (epoch 12.475), train_loss = 1.09901318, grad/param norm = 1.3948e-01, time/batch = 15.1321s	
7112/28500 (epoch 12.477), train_loss = 1.18596075, grad/param norm = 1.4789e-01, time/batch = 15.2829s	
7113/28500 (epoch 12.479), train_loss = 1.24385962, grad/param norm = 1.5593e-01, time/batch = 15.4848s	
7114/28500 (epoch 12.481), train_loss = 1.19289337, grad/param norm = 1.6641e-01, time/batch = 15.5473s	
7115/28500 (epoch 12.482), train_loss = 1.08548048, grad/param norm = 1.5512e-01, time/batch = 15.6806s	
7116/28500 (epoch 12.484), train_loss = 1.08563521, grad/param norm = 1.4902e-01, time/batch = 15.5528s	
7117/28500 (epoch 12.486), train_loss = 1.00099036, grad/param norm = 1.6420e-01, time/batch = 15.5441s	
7118/28500 (epoch 12.488), train_loss = 1.21651620, grad/param norm = 1.4973e-01, time/batch = 15.0736s	
7119/28500 (epoch 12.489), train_loss = 1.27900249, grad/param norm = 1.5240e-01, time/batch = 15.4703s	
7120/28500 (epoch 12.491), train_loss = 1.14643561, grad/param norm = 1.5454e-01, time/batch = 15.4650s	
7121/28500 (epoch 12.493), train_loss = 1.13670749, grad/param norm = 1.5076e-01, time/batch = 15.6219s	
7122/28500 (epoch 12.495), train_loss = 1.12496685, grad/param norm = 1.5013e-01, time/batch = 15.0553s	
7123/28500 (epoch 12.496), train_loss = 1.15866952, grad/param norm = 1.6973e-01, time/batch = 15.3749s	
7124/28500 (epoch 12.498), train_loss = 1.24957466, grad/param norm = 1.6863e-01, time/batch = 15.2913s	
7125/28500 (epoch 12.500), train_loss = 1.15973531, grad/param norm = 1.5525e-01, time/batch = 15.2999s	
7126/28500 (epoch 12.502), train_loss = 1.28501769, grad/param norm = 1.5166e-01, time/batch = 15.4092s	
7127/28500 (epoch 12.504), train_loss = 1.23363189, grad/param norm = 1.5612e-01, time/batch = 15.5365s	
7128/28500 (epoch 12.505), train_loss = 1.09374694, grad/param norm = 1.4755e-01, time/batch = 15.3861s	
7129/28500 (epoch 12.507), train_loss = 1.32511704, grad/param norm = 2.6553e-01, time/batch = 15.4426s	
7130/28500 (epoch 12.509), train_loss = 1.18219233, grad/param norm = 1.5198e-01, time/batch = 14.9706s	
7131/28500 (epoch 12.511), train_loss = 1.17790645, grad/param norm = 1.5412e-01, time/batch = 15.1975s	
7132/28500 (epoch 12.512), train_loss = 1.19306434, grad/param norm = 1.5221e-01, time/batch = 15.0548s	
7133/28500 (epoch 12.514), train_loss = 1.09054580, grad/param norm = 1.5216e-01, time/batch = 15.0630s	
7134/28500 (epoch 12.516), train_loss = 1.11781656, grad/param norm = 1.4892e-01, time/batch = 16.3658s	
7135/28500 (epoch 12.518), train_loss = 1.18880374, grad/param norm = 1.5314e-01, time/batch = 26.1196s	
7136/28500 (epoch 12.519), train_loss = 1.24848409, grad/param norm = 1.5739e-01, time/batch = 15.2781s	
7137/28500 (epoch 12.521), train_loss = 1.35502363, grad/param norm = 1.6804e-01, time/batch = 15.2145s	
7138/28500 (epoch 12.523), train_loss = 1.25461590, grad/param norm = 1.8645e-01, time/batch = 15.4700s	
7139/28500 (epoch 12.525), train_loss = 1.28124937, grad/param norm = 1.6110e-01, time/batch = 15.5511s	
7140/28500 (epoch 12.526), train_loss = 1.26372030, grad/param norm = 1.7111e-01, time/batch = 15.4187s	
7141/28500 (epoch 12.528), train_loss = 1.28400102, grad/param norm = 1.6215e-01, time/batch = 15.4189s	
7142/28500 (epoch 12.530), train_loss = 1.31828817, grad/param norm = 1.5039e-01, time/batch = 15.3551s	
7143/28500 (epoch 12.532), train_loss = 1.14785835, grad/param norm = 1.6047e-01, time/batch = 15.2756s	
7144/28500 (epoch 12.533), train_loss = 1.28321452, grad/param norm = 1.4525e-01, time/batch = 15.1447s	
7145/28500 (epoch 12.535), train_loss = 1.02968658, grad/param norm = 1.4352e-01, time/batch = 15.2833s	
7146/28500 (epoch 12.537), train_loss = 1.01905671, grad/param norm = 1.4649e-01, time/batch = 15.3662s	
7147/28500 (epoch 12.539), train_loss = 1.05491121, grad/param norm = 1.5694e-01, time/batch = 15.3672s	
7148/28500 (epoch 12.540), train_loss = 1.17959869, grad/param norm = 1.4547e-01, time/batch = 15.4791s	
7149/28500 (epoch 12.542), train_loss = 1.34672235, grad/param norm = 1.7292e-01, time/batch = 15.6040s	
7150/28500 (epoch 12.544), train_loss = 1.36304510, grad/param norm = 1.6272e-01, time/batch = 15.6139s	
7151/28500 (epoch 12.546), train_loss = 1.21108347, grad/param norm = 1.6696e-01, time/batch = 15.3771s	
7152/28500 (epoch 12.547), train_loss = 1.18802814, grad/param norm = 1.4669e-01, time/batch = 15.4768s	
7153/28500 (epoch 12.549), train_loss = 1.02285520, grad/param norm = 1.3497e-01, time/batch = 15.4107s	
7154/28500 (epoch 12.551), train_loss = 1.25632156, grad/param norm = 1.7531e-01, time/batch = 14.9685s	
7155/28500 (epoch 12.553), train_loss = 1.41761136, grad/param norm = 1.8009e-01, time/batch = 15.0430s	
7156/28500 (epoch 12.554), train_loss = 1.14854992, grad/param norm = 1.3874e-01, time/batch = 15.2570s	
7157/28500 (epoch 12.556), train_loss = 1.19786588, grad/param norm = 1.6490e-01, time/batch = 15.4557s	
7158/28500 (epoch 12.558), train_loss = 1.22945560, grad/param norm = 1.5865e-01, time/batch = 15.0624s	
7159/28500 (epoch 12.560), train_loss = 1.23439987, grad/param norm = 1.6670e-01, time/batch = 15.0971s	
7160/28500 (epoch 12.561), train_loss = 1.29315208, grad/param norm = 1.7507e-01, time/batch = 15.3222s	
7161/28500 (epoch 12.563), train_loss = 1.36611627, grad/param norm = 1.7246e-01, time/batch = 15.3481s	
7162/28500 (epoch 12.565), train_loss = 1.17780746, grad/param norm = 1.5111e-01, time/batch = 15.1458s	
7163/28500 (epoch 12.567), train_loss = 1.05676550, grad/param norm = 1.5938e-01, time/batch = 15.0947s	
7164/28500 (epoch 12.568), train_loss = 1.22723432, grad/param norm = 1.5642e-01, time/batch = 15.1274s	
7165/28500 (epoch 12.570), train_loss = 1.14675116, grad/param norm = 1.6081e-01, time/batch = 15.4595s	
7166/28500 (epoch 12.572), train_loss = 1.15216588, grad/param norm = 1.6594e-01, time/batch = 15.4621s	
7167/28500 (epoch 12.574), train_loss = 1.17700782, grad/param norm = 1.6163e-01, time/batch = 15.2189s	
7168/28500 (epoch 12.575), train_loss = 1.15409489, grad/param norm = 1.5321e-01, time/batch = 15.0941s	
7169/28500 (epoch 12.577), train_loss = 1.19877937, grad/param norm = 1.5450e-01, time/batch = 15.1008s	
7170/28500 (epoch 12.579), train_loss = 1.28495856, grad/param norm = 1.6757e-01, time/batch = 15.0414s	
7171/28500 (epoch 12.581), train_loss = 1.16789420, grad/param norm = 1.7092e-01, time/batch = 15.1997s	
7172/28500 (epoch 12.582), train_loss = 1.29611249, grad/param norm = 1.5988e-01, time/batch = 15.0555s	
7173/28500 (epoch 12.584), train_loss = 1.13846502, grad/param norm = 1.4811e-01, time/batch = 15.2835s	
7174/28500 (epoch 12.586), train_loss = 1.08424431, grad/param norm = 1.3964e-01, time/batch = 15.4871s	
7175/28500 (epoch 12.588), train_loss = 1.09523530, grad/param norm = 1.3957e-01, time/batch = 15.2123s	
7176/28500 (epoch 12.589), train_loss = 1.25461773, grad/param norm = 1.6828e-01, time/batch = 15.2785s	
7177/28500 (epoch 12.591), train_loss = 1.24982572, grad/param norm = 1.5349e-01, time/batch = 15.0748s	
7178/28500 (epoch 12.593), train_loss = 1.13393352, grad/param norm = 1.4942e-01, time/batch = 15.3689s	
7179/28500 (epoch 12.595), train_loss = 1.42352867, grad/param norm = 1.8272e-01, time/batch = 15.4859s	
7180/28500 (epoch 12.596), train_loss = 1.42315901, grad/param norm = 1.8742e-01, time/batch = 15.1905s	
7181/28500 (epoch 12.598), train_loss = 1.21538755, grad/param norm = 1.5831e-01, time/batch = 15.4324s	
7182/28500 (epoch 12.600), train_loss = 1.22700168, grad/param norm = 1.7285e-01, time/batch = 15.3720s	
7183/28500 (epoch 12.602), train_loss = 1.33555420, grad/param norm = 1.6446e-01, time/batch = 15.3133s	
7184/28500 (epoch 12.604), train_loss = 1.27048648, grad/param norm = 1.5314e-01, time/batch = 15.7148s	
7185/28500 (epoch 12.605), train_loss = 1.21823200, grad/param norm = 1.5960e-01, time/batch = 15.3090s	
7186/28500 (epoch 12.607), train_loss = 1.27162903, grad/param norm = 1.4791e-01, time/batch = 15.2296s	
7187/28500 (epoch 12.609), train_loss = 1.18859247, grad/param norm = 1.5687e-01, time/batch = 15.3757s	
7188/28500 (epoch 12.611), train_loss = 1.21582691, grad/param norm = 1.6225e-01, time/batch = 15.3622s	
7189/28500 (epoch 12.612), train_loss = 1.25932332, grad/param norm = 1.7746e-01, time/batch = 15.2271s	
7190/28500 (epoch 12.614), train_loss = 1.23584749, grad/param norm = 1.6420e-01, time/batch = 15.1999s	
7191/28500 (epoch 12.616), train_loss = 1.14035983, grad/param norm = 1.5167e-01, time/batch = 15.0526s	
7192/28500 (epoch 12.618), train_loss = 1.15251911, grad/param norm = 1.6096e-01, time/batch = 15.4026s	
7193/28500 (epoch 12.619), train_loss = 1.38638914, grad/param norm = 1.7469e-01, time/batch = 15.1049s	
7194/28500 (epoch 12.621), train_loss = 0.99505908, grad/param norm = 1.3646e-01, time/batch = 15.1440s	
7195/28500 (epoch 12.623), train_loss = 1.31303918, grad/param norm = 1.6262e-01, time/batch = 14.9549s	
7196/28500 (epoch 12.625), train_loss = 1.06203612, grad/param norm = 1.5651e-01, time/batch = 15.1341s	
7197/28500 (epoch 12.626), train_loss = 0.92701660, grad/param norm = 1.3365e-01, time/batch = 14.9724s	
7198/28500 (epoch 12.628), train_loss = 1.12691914, grad/param norm = 1.5347e-01, time/batch = 15.1401s	
7199/28500 (epoch 12.630), train_loss = 1.03098624, grad/param norm = 1.4151e-01, time/batch = 14.9813s	
7200/28500 (epoch 12.632), train_loss = 1.28355342, grad/param norm = 1.6380e-01, time/batch = 15.4150s	
7201/28500 (epoch 12.633), train_loss = 1.32666600, grad/param norm = 1.5390e-01, time/batch = 15.4415s	
7202/28500 (epoch 12.635), train_loss = 1.38937755, grad/param norm = 1.7390e-01, time/batch = 15.1409s	
7203/28500 (epoch 12.637), train_loss = 1.19853369, grad/param norm = 1.4634e-01, time/batch = 15.2025s	
7204/28500 (epoch 12.639), train_loss = 1.07126802, grad/param norm = 1.4521e-01, time/batch = 15.3728s	
7205/28500 (epoch 12.640), train_loss = 1.07985202, grad/param norm = 1.4416e-01, time/batch = 15.4560s	
7206/28500 (epoch 12.642), train_loss = 1.21438439, grad/param norm = 1.5191e-01, time/batch = 15.4140s	
7207/28500 (epoch 12.644), train_loss = 1.26232817, grad/param norm = 1.4413e-01, time/batch = 15.2262s	
7208/28500 (epoch 12.646), train_loss = 1.07750423, grad/param norm = 1.3816e-01, time/batch = 15.3179s	
7209/28500 (epoch 12.647), train_loss = 1.07984615, grad/param norm = 1.4563e-01, time/batch = 15.2261s	
7210/28500 (epoch 12.649), train_loss = 1.06565216, grad/param norm = 1.4601e-01, time/batch = 15.2324s	
7211/28500 (epoch 12.651), train_loss = 1.03783565, grad/param norm = 1.4149e-01, time/batch = 15.1396s	
7212/28500 (epoch 12.653), train_loss = 1.06943988, grad/param norm = 1.4663e-01, time/batch = 15.3292s	
7213/28500 (epoch 12.654), train_loss = 1.15420735, grad/param norm = 1.5004e-01, time/batch = 15.2517s	
7214/28500 (epoch 12.656), train_loss = 1.10860690, grad/param norm = 1.5173e-01, time/batch = 15.3842s	
7215/28500 (epoch 12.658), train_loss = 1.19698427, grad/param norm = 1.5655e-01, time/batch = 15.2096s	
7216/28500 (epoch 12.660), train_loss = 1.16613377, grad/param norm = 1.3805e-01, time/batch = 15.6239s	
7217/28500 (epoch 12.661), train_loss = 1.34556272, grad/param norm = 1.7186e-01, time/batch = 15.0640s	
7218/28500 (epoch 12.663), train_loss = 1.38350733, grad/param norm = 1.7234e-01, time/batch = 15.0686s	
7219/28500 (epoch 12.665), train_loss = 1.15168702, grad/param norm = 1.5350e-01, time/batch = 15.3480s	
7220/28500 (epoch 12.667), train_loss = 1.21267075, grad/param norm = 1.6628e-01, time/batch = 15.1877s	
7221/28500 (epoch 12.668), train_loss = 1.17099341, grad/param norm = 1.4969e-01, time/batch = 15.1338s	
7222/28500 (epoch 12.670), train_loss = 1.19602606, grad/param norm = 1.5249e-01, time/batch = 15.1092s	
7223/28500 (epoch 12.672), train_loss = 1.15337939, grad/param norm = 1.5496e-01, time/batch = 15.6104s	
7224/28500 (epoch 12.674), train_loss = 0.99529099, grad/param norm = 1.4886e-01, time/batch = 15.5080s	
7225/28500 (epoch 12.675), train_loss = 1.02922200, grad/param norm = 1.5160e-01, time/batch = 14.9071s	
7226/28500 (epoch 12.677), train_loss = 1.15774236, grad/param norm = 1.4929e-01, time/batch = 15.2131s	
7227/28500 (epoch 12.679), train_loss = 1.12440363, grad/param norm = 1.4867e-01, time/batch = 15.2670s	
7228/28500 (epoch 12.681), train_loss = 1.27631323, grad/param norm = 1.5948e-01, time/batch = 15.1203s	
7229/28500 (epoch 12.682), train_loss = 1.14424103, grad/param norm = 1.4783e-01, time/batch = 14.9926s	
7230/28500 (epoch 12.684), train_loss = 1.25108138, grad/param norm = 1.6180e-01, time/batch = 15.3745s	
7231/28500 (epoch 12.686), train_loss = 1.11957417, grad/param norm = 1.6918e-01, time/batch = 15.4394s	
7232/28500 (epoch 12.688), train_loss = 1.06684684, grad/param norm = 1.3846e-01, time/batch = 15.1206s	
7233/28500 (epoch 12.689), train_loss = 1.19543617, grad/param norm = 1.5377e-01, time/batch = 15.0898s	
7234/28500 (epoch 12.691), train_loss = 1.24497350, grad/param norm = 1.7386e-01, time/batch = 15.0712s	
7235/28500 (epoch 12.693), train_loss = 1.14240768, grad/param norm = 1.6296e-01, time/batch = 15.2094s	
7236/28500 (epoch 12.695), train_loss = 0.99624861, grad/param norm = 1.6140e-01, time/batch = 15.5447s	
7237/28500 (epoch 12.696), train_loss = 1.14128958, grad/param norm = 1.6108e-01, time/batch = 15.2114s	
7238/28500 (epoch 12.698), train_loss = 1.17607528, grad/param norm = 1.5153e-01, time/batch = 15.2275s	
7239/28500 (epoch 12.700), train_loss = 1.21214111, grad/param norm = 1.5071e-01, time/batch = 15.2178s	
7240/28500 (epoch 12.702), train_loss = 1.29441718, grad/param norm = 1.7784e-01, time/batch = 15.4279s	
7241/28500 (epoch 12.704), train_loss = 1.22872133, grad/param norm = 1.6839e-01, time/batch = 15.0632s	
7242/28500 (epoch 12.705), train_loss = 1.28689487, grad/param norm = 1.6886e-01, time/batch = 15.2254s	
7243/28500 (epoch 12.707), train_loss = 1.13894269, grad/param norm = 1.5994e-01, time/batch = 15.4599s	
7244/28500 (epoch 12.709), train_loss = 1.30471028, grad/param norm = 1.6883e-01, time/batch = 15.5462s	
7245/28500 (epoch 12.711), train_loss = 1.12088905, grad/param norm = 1.7119e-01, time/batch = 15.4655s	
7246/28500 (epoch 12.712), train_loss = 1.26549017, grad/param norm = 1.5992e-01, time/batch = 15.4241s	
7247/28500 (epoch 12.714), train_loss = 1.29288433, grad/param norm = 1.6352e-01, time/batch = 15.2818s	
7248/28500 (epoch 12.716), train_loss = 1.15447331, grad/param norm = 1.6008e-01, time/batch = 15.6723s	
7249/28500 (epoch 12.718), train_loss = 1.14497954, grad/param norm = 1.5649e-01, time/batch = 15.2942s	
7250/28500 (epoch 12.719), train_loss = 1.17266304, grad/param norm = 1.5396e-01, time/batch = 14.8301s	
7251/28500 (epoch 12.721), train_loss = 0.98277414, grad/param norm = 1.5125e-01, time/batch = 15.6001s	
7252/28500 (epoch 12.723), train_loss = 1.17492053, grad/param norm = 1.6917e-01, time/batch = 15.2866s	
7253/28500 (epoch 12.725), train_loss = 1.28629131, grad/param norm = 1.4937e-01, time/batch = 15.3028s	
7254/28500 (epoch 12.726), train_loss = 1.20962113, grad/param norm = 1.5795e-01, time/batch = 15.0705s	
7255/28500 (epoch 12.728), train_loss = 1.04009124, grad/param norm = 1.3339e-01, time/batch = 15.2134s	
7256/28500 (epoch 12.730), train_loss = 1.22337794, grad/param norm = 1.6689e-01, time/batch = 15.1544s	
7257/28500 (epoch 12.732), train_loss = 1.00237058, grad/param norm = 1.4779e-01, time/batch = 15.3819s	
7258/28500 (epoch 12.733), train_loss = 0.99713315, grad/param norm = 1.3567e-01, time/batch = 15.4572s	
7259/28500 (epoch 12.735), train_loss = 1.02338922, grad/param norm = 1.4642e-01, time/batch = 15.4380s	
7260/28500 (epoch 12.737), train_loss = 0.96324258, grad/param norm = 1.3077e-01, time/batch = 15.6656s	
7261/28500 (epoch 12.739), train_loss = 1.14553694, grad/param norm = 1.6495e-01, time/batch = 15.4771s	
7262/28500 (epoch 12.740), train_loss = 1.17322331, grad/param norm = 1.5314e-01, time/batch = 15.3661s	
7263/28500 (epoch 12.742), train_loss = 1.07897008, grad/param norm = 1.4395e-01, time/batch = 15.3781s	
7264/28500 (epoch 12.744), train_loss = 1.21741694, grad/param norm = 1.6629e-01, time/batch = 15.4564s	
7265/28500 (epoch 12.746), train_loss = 1.06369865, grad/param norm = 1.3989e-01, time/batch = 15.3255s	
7266/28500 (epoch 12.747), train_loss = 1.08045477, grad/param norm = 1.4595e-01, time/batch = 15.4500s	
7267/28500 (epoch 12.749), train_loss = 1.32777813, grad/param norm = 1.8061e-01, time/batch = 15.6338s	
7268/28500 (epoch 12.751), train_loss = 1.07739567, grad/param norm = 1.7371e-01, time/batch = 15.5475s	
7269/28500 (epoch 12.753), train_loss = 1.08206666, grad/param norm = 1.4059e-01, time/batch = 15.6427s	
7270/28500 (epoch 12.754), train_loss = 1.01800093, grad/param norm = 1.5958e-01, time/batch = 15.5982s	
7271/28500 (epoch 12.756), train_loss = 1.28123601, grad/param norm = 1.6097e-01, time/batch = 15.2809s	
7272/28500 (epoch 12.758), train_loss = 1.23831732, grad/param norm = 1.5746e-01, time/batch = 15.1291s	
7273/28500 (epoch 12.760), train_loss = 1.02347986, grad/param norm = 1.4274e-01, time/batch = 15.1644s	
7274/28500 (epoch 12.761), train_loss = 1.05719822, grad/param norm = 1.7027e-01, time/batch = 15.5387s	
7275/28500 (epoch 12.763), train_loss = 0.94950585, grad/param norm = 1.4549e-01, time/batch = 15.3808s	
7276/28500 (epoch 12.765), train_loss = 1.10453658, grad/param norm = 1.4527e-01, time/batch = 15.2356s	
7277/28500 (epoch 12.767), train_loss = 0.97239347, grad/param norm = 1.3384e-01, time/batch = 15.4757s	
7278/28500 (epoch 12.768), train_loss = 1.27170114, grad/param norm = 1.7287e-01, time/batch = 15.5408s	
7279/28500 (epoch 12.770), train_loss = 1.00596565, grad/param norm = 1.4716e-01, time/batch = 15.3804s	
7280/28500 (epoch 12.772), train_loss = 0.90567920, grad/param norm = 1.3523e-01, time/batch = 15.3139s	
7281/28500 (epoch 12.774), train_loss = 1.18916058, grad/param norm = 1.5839e-01, time/batch = 15.2118s	
7282/28500 (epoch 12.775), train_loss = 1.23411084, grad/param norm = 1.5007e-01, time/batch = 15.4520s	
7283/28500 (epoch 12.777), train_loss = 1.22092570, grad/param norm = 1.5040e-01, time/batch = 15.3895s	
7284/28500 (epoch 12.779), train_loss = 0.98303712, grad/param norm = 1.3279e-01, time/batch = 15.1390s	
7285/28500 (epoch 12.781), train_loss = 1.20423585, grad/param norm = 1.5635e-01, time/batch = 15.1618s	
7286/28500 (epoch 12.782), train_loss = 1.24376012, grad/param norm = 1.6446e-01, time/batch = 15.3289s	
7287/28500 (epoch 12.784), train_loss = 0.97921846, grad/param norm = 1.6262e-01, time/batch = 15.5751s	
7288/28500 (epoch 12.786), train_loss = 1.06317610, grad/param norm = 1.4097e-01, time/batch = 15.5502s	
7289/28500 (epoch 12.788), train_loss = 1.17361003, grad/param norm = 1.5934e-01, time/batch = 15.1129s	
7290/28500 (epoch 12.789), train_loss = 0.90213059, grad/param norm = 1.5830e-01, time/batch = 15.2907s	
7291/28500 (epoch 12.791), train_loss = 1.14764303, grad/param norm = 1.5012e-01, time/batch = 15.3654s	
7292/28500 (epoch 12.793), train_loss = 1.09663100, grad/param norm = 1.6024e-01, time/batch = 15.5603s	
7293/28500 (epoch 12.795), train_loss = 1.18003985, grad/param norm = 1.5020e-01, time/batch = 15.2180s	
7294/28500 (epoch 12.796), train_loss = 1.05479818, grad/param norm = 1.5362e-01, time/batch = 15.3867s	
7295/28500 (epoch 12.798), train_loss = 1.01081293, grad/param norm = 1.5022e-01, time/batch = 15.5474s	
7296/28500 (epoch 12.800), train_loss = 1.03646372, grad/param norm = 1.5002e-01, time/batch = 15.6081s	
7297/28500 (epoch 12.802), train_loss = 1.14521181, grad/param norm = 1.7247e-01, time/batch = 15.5233s	
7298/28500 (epoch 12.804), train_loss = 1.16262216, grad/param norm = 1.4706e-01, time/batch = 15.6334s	
7299/28500 (epoch 12.805), train_loss = 1.16753320, grad/param norm = 1.6862e-01, time/batch = 15.5114s	
7300/28500 (epoch 12.807), train_loss = 1.23143780, grad/param norm = 1.5986e-01, time/batch = 15.0235s	
7301/28500 (epoch 12.809), train_loss = 1.14378506, grad/param norm = 1.5790e-01, time/batch = 14.9735s	
7302/28500 (epoch 12.811), train_loss = 1.23213748, grad/param norm = 1.6697e-01, time/batch = 15.2734s	
7303/28500 (epoch 12.812), train_loss = 1.20231018, grad/param norm = 1.7207e-01, time/batch = 15.4709s	
7304/28500 (epoch 12.814), train_loss = 1.14299586, grad/param norm = 1.6228e-01, time/batch = 15.3763s	
7305/28500 (epoch 12.816), train_loss = 1.29660679, grad/param norm = 1.7792e-01, time/batch = 15.5025s	
7306/28500 (epoch 12.818), train_loss = 1.24583634, grad/param norm = 1.5434e-01, time/batch = 15.4840s	
7307/28500 (epoch 12.819), train_loss = 1.16376349, grad/param norm = 1.5119e-01, time/batch = 15.5353s	
7308/28500 (epoch 12.821), train_loss = 1.09883855, grad/param norm = 1.5029e-01, time/batch = 15.5586s	
7309/28500 (epoch 12.823), train_loss = 1.32463067, grad/param norm = 1.7932e-01, time/batch = 15.5481s	
7310/28500 (epoch 12.825), train_loss = 1.13017354, grad/param norm = 1.5768e-01, time/batch = 15.4333s	
7311/28500 (epoch 12.826), train_loss = 1.19591147, grad/param norm = 1.6554e-01, time/batch = 15.1869s	
7312/28500 (epoch 12.828), train_loss = 1.03439180, grad/param norm = 1.5983e-01, time/batch = 15.2021s	
7313/28500 (epoch 12.830), train_loss = 1.10873122, grad/param norm = 1.5170e-01, time/batch = 15.3336s	
7314/28500 (epoch 12.832), train_loss = 1.16903437, grad/param norm = 1.7822e-01, time/batch = 15.1756s	
7315/28500 (epoch 12.833), train_loss = 1.31815176, grad/param norm = 1.5940e-01, time/batch = 15.0631s	
7316/28500 (epoch 12.835), train_loss = 1.11675004, grad/param norm = 1.5885e-01, time/batch = 15.2723s	
7317/28500 (epoch 12.837), train_loss = 1.00413374, grad/param norm = 1.4908e-01, time/batch = 15.3196s	
7318/28500 (epoch 12.839), train_loss = 1.27830853, grad/param norm = 1.8046e-01, time/batch = 15.3589s	
7319/28500 (epoch 12.840), train_loss = 1.27924131, grad/param norm = 1.6041e-01, time/batch = 15.5227s	
7320/28500 (epoch 12.842), train_loss = 1.25433597, grad/param norm = 1.6830e-01, time/batch = 15.4680s	
7321/28500 (epoch 12.844), train_loss = 1.17848156, grad/param norm = 1.5476e-01, time/batch = 15.6219s	
7322/28500 (epoch 12.846), train_loss = 1.31463243, grad/param norm = 1.6959e-01, time/batch = 15.3770s	
7323/28500 (epoch 12.847), train_loss = 1.11257390, grad/param norm = 1.5047e-01, time/batch = 15.1422s	
7324/28500 (epoch 12.849), train_loss = 1.11309422, grad/param norm = 1.5116e-01, time/batch = 15.2706s	
7325/28500 (epoch 12.851), train_loss = 0.99681557, grad/param norm = 1.4263e-01, time/batch = 15.1704s	
7326/28500 (epoch 12.853), train_loss = 1.17776868, grad/param norm = 1.5822e-01, time/batch = 15.1693s	
7327/28500 (epoch 12.854), train_loss = 1.19475622, grad/param norm = 1.6507e-01, time/batch = 15.1787s	
7328/28500 (epoch 12.856), train_loss = 1.28496497, grad/param norm = 1.7922e-01, time/batch = 15.3497s	
7329/28500 (epoch 12.858), train_loss = 1.04013775, grad/param norm = 1.4061e-01, time/batch = 15.4342s	
7330/28500 (epoch 12.860), train_loss = 1.19281634, grad/param norm = 1.7531e-01, time/batch = 15.3579s	
7331/28500 (epoch 12.861), train_loss = 1.19129448, grad/param norm = 1.7191e-01, time/batch = 15.4626s	
7332/28500 (epoch 12.863), train_loss = 1.27623880, grad/param norm = 1.6602e-01, time/batch = 15.3780s	
7333/28500 (epoch 12.865), train_loss = 1.15602344, grad/param norm = 1.5362e-01, time/batch = 15.3033s	
7334/28500 (epoch 12.867), train_loss = 1.22889649, grad/param norm = 1.6892e-01, time/batch = 15.2101s	
7335/28500 (epoch 12.868), train_loss = 1.04314574, grad/param norm = 1.4330e-01, time/batch = 15.2896s	
7336/28500 (epoch 12.870), train_loss = 0.96646403, grad/param norm = 1.3844e-01, time/batch = 15.2986s	
7337/28500 (epoch 12.872), train_loss = 1.21192765, grad/param norm = 1.7267e-01, time/batch = 15.2020s	
7338/28500 (epoch 12.874), train_loss = 1.17789225, grad/param norm = 1.6934e-01, time/batch = 15.3712s	
7339/28500 (epoch 12.875), train_loss = 1.27427634, grad/param norm = 1.8574e-01, time/batch = 15.4232s	
7340/28500 (epoch 12.877), train_loss = 1.19773385, grad/param norm = 1.5342e-01, time/batch = 15.5678s	
7341/28500 (epoch 12.879), train_loss = 1.16514844, grad/param norm = 1.4969e-01, time/batch = 15.3013s	
7342/28500 (epoch 12.881), train_loss = 1.17365314, grad/param norm = 1.5265e-01, time/batch = 15.3593s	
7343/28500 (epoch 12.882), train_loss = 1.12424890, grad/param norm = 1.4598e-01, time/batch = 15.3062s	
7344/28500 (epoch 12.884), train_loss = 1.19205910, grad/param norm = 1.6626e-01, time/batch = 15.2879s	
7345/28500 (epoch 12.886), train_loss = 1.09585736, grad/param norm = 1.4224e-01, time/batch = 15.2890s	
7346/28500 (epoch 12.888), train_loss = 1.03442966, grad/param norm = 1.4893e-01, time/batch = 15.3073s	
7347/28500 (epoch 12.889), train_loss = 1.16147082, grad/param norm = 1.5300e-01, time/batch = 15.1907s	
7348/28500 (epoch 12.891), train_loss = 1.18158486, grad/param norm = 1.5243e-01, time/batch = 15.6073s	
7349/28500 (epoch 12.893), train_loss = 1.10045050, grad/param norm = 1.6311e-01, time/batch = 15.3878s	
7350/28500 (epoch 12.895), train_loss = 1.34868193, grad/param norm = 1.8821e-01, time/batch = 15.3583s	
7351/28500 (epoch 12.896), train_loss = 1.23099861, grad/param norm = 1.5891e-01, time/batch = 15.3828s	
7352/28500 (epoch 12.898), train_loss = 1.14061722, grad/param norm = 1.5247e-01, time/batch = 15.5135s	
7353/28500 (epoch 12.900), train_loss = 1.02903258, grad/param norm = 1.5466e-01, time/batch = 15.4923s	
7354/28500 (epoch 12.902), train_loss = 1.04427597, grad/param norm = 1.5482e-01, time/batch = 15.3846s	
7355/28500 (epoch 12.904), train_loss = 1.07296637, grad/param norm = 1.4410e-01, time/batch = 15.5254s	
7356/28500 (epoch 12.905), train_loss = 1.19647195, grad/param norm = 1.5987e-01, time/batch = 15.3813s	
7357/28500 (epoch 12.907), train_loss = 1.17446051, grad/param norm = 1.6758e-01, time/batch = 15.3852s	
7358/28500 (epoch 12.909), train_loss = 1.03858328, grad/param norm = 1.6528e-01, time/batch = 15.3079s	
7359/28500 (epoch 12.911), train_loss = 1.05751568, grad/param norm = 1.3810e-01, time/batch = 15.0508s	
7360/28500 (epoch 12.912), train_loss = 0.92559704, grad/param norm = 1.2939e-01, time/batch = 15.2564s	
7361/28500 (epoch 12.914), train_loss = 1.27873164, grad/param norm = 1.5292e-01, time/batch = 15.2521s	
7362/28500 (epoch 12.916), train_loss = 1.22171285, grad/param norm = 1.7062e-01, time/batch = 15.0378s	
7363/28500 (epoch 12.918), train_loss = 1.17727701, grad/param norm = 1.6983e-01, time/batch = 15.0600s	
7364/28500 (epoch 12.919), train_loss = 1.13554574, grad/param norm = 1.4179e-01, time/batch = 15.2571s	
7365/28500 (epoch 12.921), train_loss = 1.31794626, grad/param norm = 1.8081e-01, time/batch = 15.2953s	
7366/28500 (epoch 12.923), train_loss = 1.16279978, grad/param norm = 1.7433e-01, time/batch = 15.4606s	
7367/28500 (epoch 12.925), train_loss = 1.06331734, grad/param norm = 1.5960e-01, time/batch = 20.4350s	
7368/28500 (epoch 12.926), train_loss = 1.13823164, grad/param norm = 1.4925e-01, time/batch = 22.6928s	
7369/28500 (epoch 12.928), train_loss = 1.09011918, grad/param norm = 1.4803e-01, time/batch = 15.4475s	
7370/28500 (epoch 12.930), train_loss = 0.90040069, grad/param norm = 1.3198e-01, time/batch = 15.2948s	
7371/28500 (epoch 12.932), train_loss = 0.93528991, grad/param norm = 1.3378e-01, time/batch = 15.3005s	
7372/28500 (epoch 12.933), train_loss = 1.20715429, grad/param norm = 1.6899e-01, time/batch = 15.3211s	
7373/28500 (epoch 12.935), train_loss = 1.24869224, grad/param norm = 1.7076e-01, time/batch = 15.5446s	
7374/28500 (epoch 12.937), train_loss = 1.29348644, grad/param norm = 1.8416e-01, time/batch = 15.5405s	
7375/28500 (epoch 12.939), train_loss = 1.33893941, grad/param norm = 1.7574e-01, time/batch = 15.5468s	
7376/28500 (epoch 12.940), train_loss = 1.04992978, grad/param norm = 1.5774e-01, time/batch = 15.6367s	
7377/28500 (epoch 12.942), train_loss = 1.23517792, grad/param norm = 1.6728e-01, time/batch = 15.5596s	
7378/28500 (epoch 12.944), train_loss = 1.14769263, grad/param norm = 1.5737e-01, time/batch = 15.2072s	
7379/28500 (epoch 12.946), train_loss = 1.28645795, grad/param norm = 1.5337e-01, time/batch = 15.3071s	
7380/28500 (epoch 12.947), train_loss = 1.51567700, grad/param norm = 1.9401e-01, time/batch = 15.1173s	
7381/28500 (epoch 12.949), train_loss = 1.06462172, grad/param norm = 1.5411e-01, time/batch = 15.4593s	
7382/28500 (epoch 12.951), train_loss = 1.29430643, grad/param norm = 1.7676e-01, time/batch = 15.4133s	
7383/28500 (epoch 12.953), train_loss = 1.36379328, grad/param norm = 1.8148e-01, time/batch = 15.2201s	
7384/28500 (epoch 12.954), train_loss = 1.29692497, grad/param norm = 1.8042e-01, time/batch = 15.3001s	
7385/28500 (epoch 12.956), train_loss = 1.26853685, grad/param norm = 1.9566e-01, time/batch = 15.4120s	
7386/28500 (epoch 12.958), train_loss = 1.35340844, grad/param norm = 1.6007e-01, time/batch = 15.4260s	
7387/28500 (epoch 12.960), train_loss = 1.06059075, grad/param norm = 1.5728e-01, time/batch = 14.9945s	
7388/28500 (epoch 12.961), train_loss = 1.41536851, grad/param norm = 1.9124e-01, time/batch = 15.1335s	
7389/28500 (epoch 12.963), train_loss = 1.29720069, grad/param norm = 1.7958e-01, time/batch = 15.3206s	
7390/28500 (epoch 12.965), train_loss = 1.06009249, grad/param norm = 1.4933e-01, time/batch = 15.4215s	
7391/28500 (epoch 12.967), train_loss = 1.05352936, grad/param norm = 1.5261e-01, time/batch = 15.1574s	
7392/28500 (epoch 12.968), train_loss = 0.99040940, grad/param norm = 1.3501e-01, time/batch = 15.3190s	
7393/28500 (epoch 12.970), train_loss = 1.10171660, grad/param norm = 1.5171e-01, time/batch = 15.1994s	
7394/28500 (epoch 12.972), train_loss = 1.19598270, grad/param norm = 1.6973e-01, time/batch = 15.3374s	
7395/28500 (epoch 12.974), train_loss = 1.40393515, grad/param norm = 1.8666e-01, time/batch = 15.3786s	
7396/28500 (epoch 12.975), train_loss = 1.12000772, grad/param norm = 1.6077e-01, time/batch = 15.3292s	
7397/28500 (epoch 12.977), train_loss = 1.35132966, grad/param norm = 1.6960e-01, time/batch = 15.3528s	
7398/28500 (epoch 12.979), train_loss = 1.11386357, grad/param norm = 1.5875e-01, time/batch = 15.5302s	
7399/28500 (epoch 12.981), train_loss = 1.08317616, grad/param norm = 1.5127e-01, time/batch = 15.5844s	
7400/28500 (epoch 12.982), train_loss = 1.07356243, grad/param norm = 1.4882e-01, time/batch = 15.5339s	
7401/28500 (epoch 12.984), train_loss = 1.29043751, grad/param norm = 1.6441e-01, time/batch = 15.5098s	
7402/28500 (epoch 12.986), train_loss = 1.42878088, grad/param norm = 1.7932e-01, time/batch = 15.4304s	
7403/28500 (epoch 12.988), train_loss = 1.01072855, grad/param norm = 1.6151e-01, time/batch = 15.3301s	
7404/28500 (epoch 12.989), train_loss = 1.19974880, grad/param norm = 1.6723e-01, time/batch = 15.5211s	
7405/28500 (epoch 12.991), train_loss = 1.09201235, grad/param norm = 1.6141e-01, time/batch = 15.5321s	
7406/28500 (epoch 12.993), train_loss = 1.09525712, grad/param norm = 1.5935e-01, time/batch = 15.4011s	
7407/28500 (epoch 12.995), train_loss = 1.08216557, grad/param norm = 1.5836e-01, time/batch = 15.3037s	
7408/28500 (epoch 12.996), train_loss = 1.04645804, grad/param norm = 1.5065e-01, time/batch = 15.3091s	
7409/28500 (epoch 12.998), train_loss = 1.26610548, grad/param norm = 1.6182e-01, time/batch = 15.2891s	
decayed learning rate by a factor 0.97 to 0.00177058562	
7410/28500 (epoch 13.000), train_loss = 1.10928930, grad/param norm = 1.5009e-01, time/batch = 15.1268s	
7411/28500 (epoch 13.002), train_loss = 1.34676670, grad/param norm = 1.8108e-01, time/batch = 15.2484s	
7412/28500 (epoch 13.004), train_loss = 1.13800283, grad/param norm = 1.5752e-01, time/batch = 15.3321s	
7413/28500 (epoch 13.005), train_loss = 1.25542844, grad/param norm = 1.6998e-01, time/batch = 15.2770s	
7414/28500 (epoch 13.007), train_loss = 1.03260300, grad/param norm = 1.4452e-01, time/batch = 15.2320s	
7415/28500 (epoch 13.009), train_loss = 1.23049354, grad/param norm = 1.6346e-01, time/batch = 15.5528s	
7416/28500 (epoch 13.011), train_loss = 1.12169968, grad/param norm = 1.9363e-01, time/batch = 15.5502s	
7417/28500 (epoch 13.012), train_loss = 1.01595119, grad/param norm = 1.3837e-01, time/batch = 15.5513s	
7418/28500 (epoch 13.014), train_loss = 1.04087532, grad/param norm = 1.4465e-01, time/batch = 15.5411s	
7419/28500 (epoch 13.016), train_loss = 1.12060863, grad/param norm = 1.4215e-01, time/batch = 15.4805s	
7420/28500 (epoch 13.018), train_loss = 1.20955726, grad/param norm = 1.5764e-01, time/batch = 15.2831s	
7421/28500 (epoch 13.019), train_loss = 1.25632428, grad/param norm = 1.6536e-01, time/batch = 15.3821s	
7422/28500 (epoch 13.021), train_loss = 1.21997174, grad/param norm = 1.4364e-01, time/batch = 15.4077s	
7423/28500 (epoch 13.023), train_loss = 1.12592931, grad/param norm = 1.5221e-01, time/batch = 15.3581s	
7424/28500 (epoch 13.025), train_loss = 1.16271610, grad/param norm = 1.5611e-01, time/batch = 15.2298s	
7425/28500 (epoch 13.026), train_loss = 1.18401761, grad/param norm = 1.6326e-01, time/batch = 15.4630s	
7426/28500 (epoch 13.028), train_loss = 1.22488045, grad/param norm = 1.5970e-01, time/batch = 15.2673s	
7427/28500 (epoch 13.030), train_loss = 1.25791183, grad/param norm = 1.8762e-01, time/batch = 14.9690s	
7428/28500 (epoch 13.032), train_loss = 1.23781927, grad/param norm = 1.6675e-01, time/batch = 15.4607s	
7429/28500 (epoch 13.033), train_loss = 1.34794019, grad/param norm = 1.7523e-01, time/batch = 15.4682s	
7430/28500 (epoch 13.035), train_loss = 1.18441015, grad/param norm = 1.5932e-01, time/batch = 15.4348s	
7431/28500 (epoch 13.037), train_loss = 1.24437982, grad/param norm = 1.4825e-01, time/batch = 15.0633s	
7432/28500 (epoch 13.039), train_loss = 1.29044545, grad/param norm = 1.7461e-01, time/batch = 15.2617s	
7433/28500 (epoch 13.040), train_loss = 1.33143317, grad/param norm = 1.6010e-01, time/batch = 15.4240s	
7434/28500 (epoch 13.042), train_loss = 1.25461029, grad/param norm = 1.7238e-01, time/batch = 15.2256s	
7435/28500 (epoch 13.044), train_loss = 1.18523289, grad/param norm = 1.6589e-01, time/batch = 15.4394s	
7436/28500 (epoch 13.046), train_loss = 1.39115371, grad/param norm = 1.6347e-01, time/batch = 15.5282s	
7437/28500 (epoch 13.047), train_loss = 1.29681214, grad/param norm = 1.7444e-01, time/batch = 15.6362s	
7438/28500 (epoch 13.049), train_loss = 1.19568102, grad/param norm = 1.6577e-01, time/batch = 15.3917s	
7439/28500 (epoch 13.051), train_loss = 1.14601494, grad/param norm = 1.6103e-01, time/batch = 15.2292s	
7440/28500 (epoch 13.053), train_loss = 1.21038903, grad/param norm = 1.6974e-01, time/batch = 15.2069s	
7441/28500 (epoch 13.054), train_loss = 1.28389271, grad/param norm = 1.7367e-01, time/batch = 15.1313s	
7442/28500 (epoch 13.056), train_loss = 1.04720163, grad/param norm = 1.3724e-01, time/batch = 15.0540s	
7443/28500 (epoch 13.058), train_loss = 1.05309212, grad/param norm = 1.5225e-01, time/batch = 15.0507s	
7444/28500 (epoch 13.060), train_loss = 1.25658898, grad/param norm = 1.6702e-01, time/batch = 15.3645s	
7445/28500 (epoch 13.061), train_loss = 1.20371088, grad/param norm = 1.7006e-01, time/batch = 15.2177s	
7446/28500 (epoch 13.063), train_loss = 1.27426435, grad/param norm = 1.6341e-01, time/batch = 15.4871s	
7447/28500 (epoch 13.065), train_loss = 1.31162964, grad/param norm = 1.6765e-01, time/batch = 15.3917s	
7448/28500 (epoch 13.067), train_loss = 1.11559001, grad/param norm = 1.4280e-01, time/batch = 15.1263s	
7449/28500 (epoch 13.068), train_loss = 1.14109153, grad/param norm = 1.5552e-01, time/batch = 15.3605s	
7450/28500 (epoch 13.070), train_loss = 1.22789709, grad/param norm = 1.7054e-01, time/batch = 15.3205s	
7451/28500 (epoch 13.072), train_loss = 1.39512051, grad/param norm = 1.7768e-01, time/batch = 15.3011s	
7452/28500 (epoch 13.074), train_loss = 1.21577184, grad/param norm = 1.5314e-01, time/batch = 15.5461s	
7453/28500 (epoch 13.075), train_loss = 1.17209207, grad/param norm = 1.3806e-01, time/batch = 15.5609s	
7454/28500 (epoch 13.077), train_loss = 1.23807327, grad/param norm = 1.6101e-01, time/batch = 15.2790s	
7455/28500 (epoch 13.079), train_loss = 1.15947321, grad/param norm = 1.4206e-01, time/batch = 15.3510s	
7456/28500 (epoch 13.081), train_loss = 1.30424643, grad/param norm = 1.7626e-01, time/batch = 15.3086s	
7457/28500 (epoch 13.082), train_loss = 1.21972050, grad/param norm = 1.7910e-01, time/batch = 15.0837s	
7458/28500 (epoch 13.084), train_loss = 1.24733099, grad/param norm = 1.5555e-01, time/batch = 14.8212s	
7459/28500 (epoch 13.086), train_loss = 1.15656386, grad/param norm = 1.6250e-01, time/batch = 15.5166s	
7460/28500 (epoch 13.088), train_loss = 1.04780307, grad/param norm = 1.4938e-01, time/batch = 15.6721s	
7461/28500 (epoch 13.089), train_loss = 1.29969378, grad/param norm = 1.5023e-01, time/batch = 15.2980s	
7462/28500 (epoch 13.091), train_loss = 1.06671596, grad/param norm = 1.5856e-01, time/batch = 15.2187s	
7463/28500 (epoch 13.093), train_loss = 1.23383340, grad/param norm = 1.5950e-01, time/batch = 15.5338s	
7464/28500 (epoch 13.095), train_loss = 1.10801788, grad/param norm = 1.4174e-01, time/batch = 15.7004s	
7465/28500 (epoch 13.096), train_loss = 1.32830130, grad/param norm = 1.6350e-01, time/batch = 15.6129s	
7466/28500 (epoch 13.098), train_loss = 1.29930807, grad/param norm = 1.7324e-01, time/batch = 15.7168s	
7467/28500 (epoch 13.100), train_loss = 1.13289952, grad/param norm = 1.4730e-01, time/batch = 15.5036s	
7468/28500 (epoch 13.102), train_loss = 1.33286228, grad/param norm = 1.6776e-01, time/batch = 15.6267s	
7469/28500 (epoch 13.104), train_loss = 1.16281849, grad/param norm = 1.6236e-01, time/batch = 15.6283s	
7470/28500 (epoch 13.105), train_loss = 1.26690137, grad/param norm = 1.5885e-01, time/batch = 15.2736s	
7471/28500 (epoch 13.107), train_loss = 1.06330322, grad/param norm = 1.5098e-01, time/batch = 15.4356s	
7472/28500 (epoch 13.109), train_loss = 1.05703158, grad/param norm = 1.5147e-01, time/batch = 15.4308s	
7473/28500 (epoch 13.111), train_loss = 1.15020415, grad/param norm = 1.7020e-01, time/batch = 15.5909s	
7474/28500 (epoch 13.112), train_loss = 1.27697935, grad/param norm = 1.7326e-01, time/batch = 15.5547s	
7475/28500 (epoch 13.114), train_loss = 1.15976052, grad/param norm = 1.6410e-01, time/batch = 15.4272s	
7476/28500 (epoch 13.116), train_loss = 1.36246300, grad/param norm = 1.5910e-01, time/batch = 15.4365s	
7477/28500 (epoch 13.118), train_loss = 1.04370826, grad/param norm = 1.5421e-01, time/batch = 15.2614s	
7478/28500 (epoch 13.119), train_loss = 1.24128600, grad/param norm = 1.8965e-01, time/batch = 15.5565s	
7479/28500 (epoch 13.121), train_loss = 1.39680585, grad/param norm = 1.8274e-01, time/batch = 15.6342s	
7480/28500 (epoch 13.123), train_loss = 1.25201973, grad/param norm = 1.6458e-01, time/batch = 15.5903s	
7481/28500 (epoch 13.125), train_loss = 1.21539649, grad/param norm = 1.6358e-01, time/batch = 15.4665s	
7482/28500 (epoch 13.126), train_loss = 1.16926026, grad/param norm = 1.5250e-01, time/batch = 15.3881s	
7483/28500 (epoch 13.128), train_loss = 1.13825569, grad/param norm = 1.5227e-01, time/batch = 15.5034s	
7484/28500 (epoch 13.130), train_loss = 1.07123230, grad/param norm = 1.6005e-01, time/batch = 15.3595s	
7485/28500 (epoch 13.132), train_loss = 1.26638071, grad/param norm = 1.7613e-01, time/batch = 15.5079s	
7486/28500 (epoch 13.133), train_loss = 1.23586392, grad/param norm = 1.7026e-01, time/batch = 15.4188s	
7487/28500 (epoch 13.135), train_loss = 1.16833988, grad/param norm = 1.4449e-01, time/batch = 15.4383s	
7488/28500 (epoch 13.137), train_loss = 1.13409824, grad/param norm = 1.6116e-01, time/batch = 15.2120s	
7489/28500 (epoch 13.139), train_loss = 1.15036738, grad/param norm = 1.4497e-01, time/batch = 15.2755s	
7490/28500 (epoch 13.140), train_loss = 1.22633467, grad/param norm = 1.4255e-01, time/batch = 15.3830s	
7491/28500 (epoch 13.142), train_loss = 1.17209850, grad/param norm = 1.5667e-01, time/batch = 15.5163s	
7492/28500 (epoch 13.144), train_loss = 1.08709887, grad/param norm = 1.5083e-01, time/batch = 15.4706s	
7493/28500 (epoch 13.146), train_loss = 1.11429104, grad/param norm = 1.5218e-01, time/batch = 15.3042s	
7494/28500 (epoch 13.147), train_loss = 1.01865986, grad/param norm = 1.4768e-01, time/batch = 15.4080s	
7495/28500 (epoch 13.149), train_loss = 1.02070673, grad/param norm = 1.3681e-01, time/batch = 15.1529s	
7496/28500 (epoch 13.151), train_loss = 1.04148589, grad/param norm = 1.3444e-01, time/batch = 15.3098s	
7497/28500 (epoch 13.153), train_loss = 1.18692979, grad/param norm = 1.5226e-01, time/batch = 15.2881s	
7498/28500 (epoch 13.154), train_loss = 1.08478458, grad/param norm = 1.5649e-01, time/batch = 15.5257s	
7499/28500 (epoch 13.156), train_loss = 1.32523847, grad/param norm = 1.7255e-01, time/batch = 15.3285s	
7500/28500 (epoch 13.158), train_loss = 1.15279873, grad/param norm = 1.5990e-01, time/batch = 15.2661s	
7501/28500 (epoch 13.160), train_loss = 1.07187082, grad/param norm = 1.4292e-01, time/batch = 15.4603s	
7502/28500 (epoch 13.161), train_loss = 1.14532491, grad/param norm = 1.6872e-01, time/batch = 15.5866s	
7503/28500 (epoch 13.163), train_loss = 1.02745685, grad/param norm = 1.5821e-01, time/batch = 15.4457s	
7504/28500 (epoch 13.165), train_loss = 1.36294545, grad/param norm = 1.5637e-01, time/batch = 15.5425s	
7505/28500 (epoch 13.167), train_loss = 1.42300883, grad/param norm = 1.7846e-01, time/batch = 15.5223s	
7506/28500 (epoch 13.168), train_loss = 1.28489952, grad/param norm = 1.8366e-01, time/batch = 15.4579s	
7507/28500 (epoch 13.170), train_loss = 1.29468695, grad/param norm = 1.7870e-01, time/batch = 15.3175s	
7508/28500 (epoch 13.172), train_loss = 1.16989326, grad/param norm = 1.6096e-01, time/batch = 15.2946s	
7509/28500 (epoch 13.174), train_loss = 1.32409405, grad/param norm = 1.7326e-01, time/batch = 15.2826s	
7510/28500 (epoch 13.175), train_loss = 1.16289748, grad/param norm = 1.4540e-01, time/batch = 15.5233s	
7511/28500 (epoch 13.177), train_loss = 1.24982228, grad/param norm = 1.5996e-01, time/batch = 15.2803s	
7512/28500 (epoch 13.179), train_loss = 1.16113832, grad/param norm = 1.7340e-01, time/batch = 15.1750s	
7513/28500 (epoch 13.181), train_loss = 1.22409210, grad/param norm = 1.5514e-01, time/batch = 15.3551s	
7514/28500 (epoch 13.182), train_loss = 1.17618594, grad/param norm = 1.5107e-01, time/batch = 15.5304s	
7515/28500 (epoch 13.184), train_loss = 1.39986862, grad/param norm = 1.8405e-01, time/batch = 15.6027s	
7516/28500 (epoch 13.186), train_loss = 1.29009626, grad/param norm = 1.6709e-01, time/batch = 15.6313s	
7517/28500 (epoch 13.188), train_loss = 1.19115940, grad/param norm = 1.5357e-01, time/batch = 15.4712s	
7518/28500 (epoch 13.189), train_loss = 1.23794866, grad/param norm = 1.6697e-01, time/batch = 15.4565s	
7519/28500 (epoch 13.191), train_loss = 1.41266956, grad/param norm = 1.7408e-01, time/batch = 15.6292s	
7520/28500 (epoch 13.193), train_loss = 1.25706874, grad/param norm = 1.7004e-01, time/batch = 15.6140s	
7521/28500 (epoch 13.195), train_loss = 1.32562195, grad/param norm = 1.6676e-01, time/batch = 15.5113s	
7522/28500 (epoch 13.196), train_loss = 1.25569578, grad/param norm = 1.6295e-01, time/batch = 15.4618s	
7523/28500 (epoch 13.198), train_loss = 1.21672101, grad/param norm = 1.7103e-01, time/batch = 15.2180s	
7524/28500 (epoch 13.200), train_loss = 1.21397726, grad/param norm = 1.5359e-01, time/batch = 15.3789s	
7525/28500 (epoch 13.202), train_loss = 1.19591492, grad/param norm = 1.6751e-01, time/batch = 15.1633s	
7526/28500 (epoch 13.204), train_loss = 1.11736172, grad/param norm = 1.5275e-01, time/batch = 15.4998s	
7527/28500 (epoch 13.205), train_loss = 1.16246226, grad/param norm = 1.6374e-01, time/batch = 15.4432s	
7528/28500 (epoch 13.207), train_loss = 1.11656366, grad/param norm = 1.6586e-01, time/batch = 15.5048s	
7529/28500 (epoch 13.209), train_loss = 1.17992097, grad/param norm = 1.5410e-01, time/batch = 15.4287s	
7530/28500 (epoch 13.211), train_loss = 1.05776312, grad/param norm = 1.5650e-01, time/batch = 15.3663s	
7531/28500 (epoch 13.212), train_loss = 1.04643529, grad/param norm = 1.5024e-01, time/batch = 15.6128s	
7532/28500 (epoch 13.214), train_loss = 1.19232008, grad/param norm = 1.7082e-01, time/batch = 15.0668s	
7533/28500 (epoch 13.216), train_loss = 1.05578607, grad/param norm = 1.4508e-01, time/batch = 15.1328s	
7534/28500 (epoch 13.218), train_loss = 1.32134417, grad/param norm = 1.6210e-01, time/batch = 15.2205s	
7535/28500 (epoch 13.219), train_loss = 1.23629717, grad/param norm = 1.7296e-01, time/batch = 15.5422s	
7536/28500 (epoch 13.221), train_loss = 1.08156875, grad/param norm = 1.7267e-01, time/batch = 15.5495s	
7537/28500 (epoch 13.223), train_loss = 1.31056329, grad/param norm = 1.6802e-01, time/batch = 15.2844s	
7538/28500 (epoch 13.225), train_loss = 1.32142945, grad/param norm = 1.5808e-01, time/batch = 15.1908s	
7539/28500 (epoch 13.226), train_loss = 1.14937402, grad/param norm = 1.4949e-01, time/batch = 15.4101s	
7540/28500 (epoch 13.228), train_loss = 1.24846342, grad/param norm = 1.4098e-01, time/batch = 15.3604s	
7541/28500 (epoch 13.230), train_loss = 1.29366901, grad/param norm = 1.6520e-01, time/batch = 15.6728s	
7542/28500 (epoch 13.232), train_loss = 1.24459569, grad/param norm = 1.5291e-01, time/batch = 15.2501s	
7543/28500 (epoch 13.233), train_loss = 1.22528654, grad/param norm = 1.6669e-01, time/batch = 15.4618s	
7544/28500 (epoch 13.235), train_loss = 1.15354081, grad/param norm = 1.5180e-01, time/batch = 15.3683s	
7545/28500 (epoch 13.237), train_loss = 1.03778235, grad/param norm = 1.3643e-01, time/batch = 15.1155s	
7546/28500 (epoch 13.239), train_loss = 1.10468883, grad/param norm = 1.3988e-01, time/batch = 15.2234s	
7547/28500 (epoch 13.240), train_loss = 1.06104393, grad/param norm = 1.6211e-01, time/batch = 15.1919s	
7548/28500 (epoch 13.242), train_loss = 1.22470744, grad/param norm = 1.7241e-01, time/batch = 15.3720s	
7549/28500 (epoch 13.244), train_loss = 1.25270090, grad/param norm = 1.6066e-01, time/batch = 15.5409s	
7550/28500 (epoch 13.246), train_loss = 1.30537174, grad/param norm = 1.6982e-01, time/batch = 15.3712s	
7551/28500 (epoch 13.247), train_loss = 1.39773964, grad/param norm = 1.7584e-01, time/batch = 15.5393s	
7552/28500 (epoch 13.249), train_loss = 1.19927933, grad/param norm = 1.6330e-01, time/batch = 15.5096s	
7553/28500 (epoch 13.251), train_loss = 1.08784350, grad/param norm = 1.4853e-01, time/batch = 15.5237s	
7554/28500 (epoch 13.253), train_loss = 1.38817218, grad/param norm = 1.8204e-01, time/batch = 15.3895s	
7555/28500 (epoch 13.254), train_loss = 1.32549785, grad/param norm = 1.6738e-01, time/batch = 15.3664s	
7556/28500 (epoch 13.256), train_loss = 1.12497998, grad/param norm = 1.4367e-01, time/batch = 15.2907s	
7557/28500 (epoch 13.258), train_loss = 1.18743294, grad/param norm = 1.6512e-01, time/batch = 15.3110s	
7558/28500 (epoch 13.260), train_loss = 1.13498217, grad/param norm = 1.4669e-01, time/batch = 15.3882s	
7559/28500 (epoch 13.261), train_loss = 1.13442660, grad/param norm = 1.5552e-01, time/batch = 15.3855s	
7560/28500 (epoch 13.263), train_loss = 1.32437607, grad/param norm = 1.8235e-01, time/batch = 15.2871s	
7561/28500 (epoch 13.265), train_loss = 1.20103951, grad/param norm = 1.5478e-01, time/batch = 15.6222s	
7562/28500 (epoch 13.267), train_loss = 1.36748271, grad/param norm = 1.7111e-01, time/batch = 15.3840s	
7563/28500 (epoch 13.268), train_loss = 1.27408984, grad/param norm = 1.4834e-01, time/batch = 15.3802s	
7564/28500 (epoch 13.270), train_loss = 1.22948552, grad/param norm = 1.7442e-01, time/batch = 15.4396s	
7565/28500 (epoch 13.272), train_loss = 1.17529825, grad/param norm = 1.6017e-01, time/batch = 15.5282s	
7566/28500 (epoch 13.274), train_loss = 1.31531727, grad/param norm = 1.6914e-01, time/batch = 15.5855s	
7567/28500 (epoch 13.275), train_loss = 1.23644292, grad/param norm = 1.5767e-01, time/batch = 15.5265s	
7568/28500 (epoch 13.277), train_loss = 1.20130435, grad/param norm = 1.5465e-01, time/batch = 15.5973s	
7569/28500 (epoch 13.279), train_loss = 1.25503967, grad/param norm = 1.8375e-01, time/batch = 15.4458s	
7570/28500 (epoch 13.281), train_loss = 1.27096476, grad/param norm = 1.7536e-01, time/batch = 15.3868s	
7571/28500 (epoch 13.282), train_loss = 1.10122830, grad/param norm = 1.4356e-01, time/batch = 15.3583s	
7572/28500 (epoch 13.284), train_loss = 1.22090149, grad/param norm = 1.6863e-01, time/batch = 15.3835s	
7573/28500 (epoch 13.286), train_loss = 1.29474312, grad/param norm = 1.6667e-01, time/batch = 15.4494s	
7574/28500 (epoch 13.288), train_loss = 1.22906047, grad/param norm = 1.5769e-01, time/batch = 15.3109s	
7575/28500 (epoch 13.289), train_loss = 1.31634503, grad/param norm = 1.7602e-01, time/batch = 15.1536s	
7576/28500 (epoch 13.291), train_loss = 1.18463782, grad/param norm = 1.4974e-01, time/batch = 15.7193s	
7577/28500 (epoch 13.293), train_loss = 1.14595132, grad/param norm = 1.5384e-01, time/batch = 15.6298s	
7578/28500 (epoch 13.295), train_loss = 1.06677907, grad/param norm = 1.5295e-01, time/batch = 15.3914s	
7579/28500 (epoch 13.296), train_loss = 1.09175064, grad/param norm = 1.4674e-01, time/batch = 15.1553s	
7580/28500 (epoch 13.298), train_loss = 1.23788963, grad/param norm = 1.5705e-01, time/batch = 15.4206s	
7581/28500 (epoch 13.300), train_loss = 1.11950227, grad/param norm = 1.5623e-01, time/batch = 15.2859s	
7582/28500 (epoch 13.302), train_loss = 1.08683350, grad/param norm = 1.4446e-01, time/batch = 15.2512s	
7583/28500 (epoch 13.304), train_loss = 1.18471418, grad/param norm = 1.4494e-01, time/batch = 15.4676s	
7584/28500 (epoch 13.305), train_loss = 1.26445504, grad/param norm = 1.6329e-01, time/batch = 15.2930s	
7585/28500 (epoch 13.307), train_loss = 1.21260633, grad/param norm = 1.6945e-01, time/batch = 15.5107s	
7586/28500 (epoch 13.309), train_loss = 1.18179883, grad/param norm = 1.6137e-01, time/batch = 15.5396s	
7587/28500 (epoch 13.311), train_loss = 1.21977059, grad/param norm = 1.5822e-01, time/batch = 15.5326s	
7588/28500 (epoch 13.312), train_loss = 1.13846794, grad/param norm = 1.5109e-01, time/batch = 15.4490s	
7589/28500 (epoch 13.314), train_loss = 1.27560879, grad/param norm = 1.7001e-01, time/batch = 15.3118s	
7590/28500 (epoch 13.316), train_loss = 1.22253288, grad/param norm = 1.5220e-01, time/batch = 15.3648s	
7591/28500 (epoch 13.318), train_loss = 1.27136942, grad/param norm = 1.6506e-01, time/batch = 15.5184s	
7592/28500 (epoch 13.319), train_loss = 1.17878971, grad/param norm = 1.6439e-01, time/batch = 15.3993s	
7593/28500 (epoch 13.321), train_loss = 1.19622839, grad/param norm = 1.9280e-01, time/batch = 15.4225s	
7594/28500 (epoch 13.323), train_loss = 1.16004920, grad/param norm = 1.7256e-01, time/batch = 15.4735s	
7595/28500 (epoch 13.325), train_loss = 1.33668926, grad/param norm = 1.6965e-01, time/batch = 15.5922s	
7596/28500 (epoch 13.326), train_loss = 1.19607857, grad/param norm = 1.6477e-01, time/batch = 15.5564s	
7597/28500 (epoch 13.328), train_loss = 0.99947254, grad/param norm = 1.4969e-01, time/batch = 15.5308s	
7598/28500 (epoch 13.330), train_loss = 1.10295002, grad/param norm = 1.5855e-01, time/batch = 15.4839s	
7599/28500 (epoch 13.332), train_loss = 1.18296574, grad/param norm = 1.4947e-01, time/batch = 26.8514s	
7600/28500 (epoch 13.333), train_loss = 1.01264652, grad/param norm = 1.4891e-01, time/batch = 16.4474s	
7601/28500 (epoch 13.335), train_loss = 1.05252627, grad/param norm = 1.4108e-01, time/batch = 15.2872s	
7602/28500 (epoch 13.337), train_loss = 1.12587236, grad/param norm = 1.5431e-01, time/batch = 15.1960s	
7603/28500 (epoch 13.339), train_loss = 1.03952496, grad/param norm = 1.4096e-01, time/batch = 15.3125s	
7604/28500 (epoch 13.340), train_loss = 1.24147019, grad/param norm = 1.6116e-01, time/batch = 15.3054s	
7605/28500 (epoch 13.342), train_loss = 1.16103875, grad/param norm = 1.7492e-01, time/batch = 15.5518s	
7606/28500 (epoch 13.344), train_loss = 1.12924637, grad/param norm = 1.7447e-01, time/batch = 15.5322s	
7607/28500 (epoch 13.346), train_loss = 0.94626031, grad/param norm = 1.3474e-01, time/batch = 15.5504s	
7608/28500 (epoch 13.347), train_loss = 1.15943750, grad/param norm = 1.4611e-01, time/batch = 15.5104s	
7609/28500 (epoch 13.349), train_loss = 1.11786313, grad/param norm = 1.4608e-01, time/batch = 15.3762s	
7610/28500 (epoch 13.351), train_loss = 1.09152463, grad/param norm = 1.5111e-01, time/batch = 15.5916s	
7611/28500 (epoch 13.353), train_loss = 1.24663415, grad/param norm = 1.7365e-01, time/batch = 15.1306s	
7612/28500 (epoch 13.354), train_loss = 1.04127598, grad/param norm = 1.4492e-01, time/batch = 15.0677s	
7613/28500 (epoch 13.356), train_loss = 1.07094857, grad/param norm = 1.3963e-01, time/batch = 14.9772s	
7614/28500 (epoch 13.358), train_loss = 1.18207474, grad/param norm = 1.5105e-01, time/batch = 15.4859s	
7615/28500 (epoch 13.360), train_loss = 1.19975969, grad/param norm = 1.6909e-01, time/batch = 15.2968s	
7616/28500 (epoch 13.361), train_loss = 1.10108680, grad/param norm = 1.5497e-01, time/batch = 15.2987s	
7617/28500 (epoch 13.363), train_loss = 1.05190131, grad/param norm = 1.3948e-01, time/batch = 15.5172s	
7618/28500 (epoch 13.365), train_loss = 1.13924170, grad/param norm = 1.6262e-01, time/batch = 15.5610s	
7619/28500 (epoch 13.367), train_loss = 1.16025432, grad/param norm = 1.5507e-01, time/batch = 15.4388s	
7620/28500 (epoch 13.368), train_loss = 1.13432289, grad/param norm = 1.4479e-01, time/batch = 15.4544s	
7621/28500 (epoch 13.370), train_loss = 1.17694375, grad/param norm = 1.5323e-01, time/batch = 15.4500s	
7622/28500 (epoch 13.372), train_loss = 1.03239095, grad/param norm = 1.5157e-01, time/batch = 15.4195s	
7623/28500 (epoch 13.374), train_loss = 1.14177949, grad/param norm = 1.5506e-01, time/batch = 15.2161s	
7624/28500 (epoch 13.375), train_loss = 1.30439912, grad/param norm = 1.5989e-01, time/batch = 15.2216s	
7625/28500 (epoch 13.377), train_loss = 1.08764930, grad/param norm = 1.5966e-01, time/batch = 15.2143s	
7626/28500 (epoch 13.379), train_loss = 0.91931755, grad/param norm = 1.3496e-01, time/batch = 15.5559s	
7627/28500 (epoch 13.381), train_loss = 1.12187972, grad/param norm = 1.4081e-01, time/batch = 15.2119s	
7628/28500 (epoch 13.382), train_loss = 1.10515157, grad/param norm = 1.5353e-01, time/batch = 15.2840s	
7629/28500 (epoch 13.384), train_loss = 1.04625811, grad/param norm = 1.5327e-01, time/batch = 15.3567s	
7630/28500 (epoch 13.386), train_loss = 1.03430142, grad/param norm = 1.5670e-01, time/batch = 15.5441s	
7631/28500 (epoch 13.388), train_loss = 1.24369436, grad/param norm = 1.5884e-01, time/batch = 15.6772s	
7632/28500 (epoch 13.389), train_loss = 1.07268397, grad/param norm = 1.5157e-01, time/batch = 15.4337s	
7633/28500 (epoch 13.391), train_loss = 1.07140622, grad/param norm = 1.4555e-01, time/batch = 15.4622s	
7634/28500 (epoch 13.393), train_loss = 1.02526335, grad/param norm = 1.5227e-01, time/batch = 15.5520s	
7635/28500 (epoch 13.395), train_loss = 1.33643028, grad/param norm = 1.6327e-01, time/batch = 15.5562s	
7636/28500 (epoch 13.396), train_loss = 1.27599276, grad/param norm = 1.6837e-01, time/batch = 15.5443s	
7637/28500 (epoch 13.398), train_loss = 0.97130460, grad/param norm = 1.6838e-01, time/batch = 15.4414s	
7638/28500 (epoch 13.400), train_loss = 1.18774138, grad/param norm = 1.7700e-01, time/batch = 15.2826s	
7639/28500 (epoch 13.402), train_loss = 1.19183255, grad/param norm = 1.5425e-01, time/batch = 15.2860s	
7640/28500 (epoch 13.404), train_loss = 1.29184117, grad/param norm = 1.8941e-01, time/batch = 15.2657s	
7641/28500 (epoch 13.405), train_loss = 1.28774044, grad/param norm = 1.6372e-01, time/batch = 15.4674s	
7642/28500 (epoch 13.407), train_loss = 1.19091847, grad/param norm = 1.5080e-01, time/batch = 15.5203s	
7643/28500 (epoch 13.409), train_loss = 1.20396899, grad/param norm = 1.6707e-01, time/batch = 15.5326s	
7644/28500 (epoch 13.411), train_loss = 1.29933522, grad/param norm = 1.5950e-01, time/batch = 15.6164s	
7645/28500 (epoch 13.412), train_loss = 1.32403729, grad/param norm = 1.8122e-01, time/batch = 15.3111s	
7646/28500 (epoch 13.414), train_loss = 1.19482951, grad/param norm = 1.6692e-01, time/batch = 15.2222s	
7647/28500 (epoch 13.416), train_loss = 1.12269952, grad/param norm = 1.6415e-01, time/batch = 15.5404s	
7648/28500 (epoch 13.418), train_loss = 1.18319118, grad/param norm = 1.4618e-01, time/batch = 15.4424s	
7649/28500 (epoch 13.419), train_loss = 1.32196586, grad/param norm = 1.6940e-01, time/batch = 15.4663s	
7650/28500 (epoch 13.421), train_loss = 1.26258024, grad/param norm = 1.6244e-01, time/batch = 15.2131s	
7651/28500 (epoch 13.423), train_loss = 1.29741478, grad/param norm = 1.7674e-01, time/batch = 15.6344s	
7652/28500 (epoch 13.425), train_loss = 1.22242785, grad/param norm = 1.6571e-01, time/batch = 15.2805s	
7653/28500 (epoch 13.426), train_loss = 1.16662839, grad/param norm = 1.6648e-01, time/batch = 15.2566s	
7654/28500 (epoch 13.428), train_loss = 1.38886004, grad/param norm = 1.6934e-01, time/batch = 15.1647s	
7655/28500 (epoch 13.430), train_loss = 1.31338202, grad/param norm = 1.6045e-01, time/batch = 15.1437s	
7656/28500 (epoch 13.432), train_loss = 1.23649334, grad/param norm = 1.6064e-01, time/batch = 15.4805s	
7657/28500 (epoch 13.433), train_loss = 1.25219924, grad/param norm = 1.6958e-01, time/batch = 15.5737s	
7658/28500 (epoch 13.435), train_loss = 1.17950743, grad/param norm = 1.7440e-01, time/batch = 15.5786s	
7659/28500 (epoch 13.437), train_loss = 1.05168737, grad/param norm = 1.4326e-01, time/batch = 15.4321s	
7660/28500 (epoch 13.439), train_loss = 1.10973835, grad/param norm = 1.4602e-01, time/batch = 15.3535s	
7661/28500 (epoch 13.440), train_loss = 1.37123684, grad/param norm = 1.6657e-01, time/batch = 15.2052s	
7662/28500 (epoch 13.442), train_loss = 1.10547613, grad/param norm = 1.6611e-01, time/batch = 15.0900s	
7663/28500 (epoch 13.444), train_loss = 1.02897459, grad/param norm = 1.4197e-01, time/batch = 15.2331s	
7664/28500 (epoch 13.446), train_loss = 0.97257847, grad/param norm = 1.4023e-01, time/batch = 15.5792s	
7665/28500 (epoch 13.447), train_loss = 1.01243433, grad/param norm = 1.3835e-01, time/batch = 15.4666s	
7666/28500 (epoch 13.449), train_loss = 1.09730740, grad/param norm = 1.4596e-01, time/batch = 15.2236s	
7667/28500 (epoch 13.451), train_loss = 1.13852017, grad/param norm = 1.5304e-01, time/batch = 15.2963s	
7668/28500 (epoch 13.453), train_loss = 1.15130836, grad/param norm = 1.5516e-01, time/batch = 15.4399s	
7669/28500 (epoch 13.454), train_loss = 1.09787471, grad/param norm = 1.4369e-01, time/batch = 15.2061s	
7670/28500 (epoch 13.456), train_loss = 1.21583272, grad/param norm = 1.6100e-01, time/batch = 15.4374s	
7671/28500 (epoch 13.458), train_loss = 1.13770972, grad/param norm = 1.5823e-01, time/batch = 15.4962s	
7672/28500 (epoch 13.460), train_loss = 1.23397328, grad/param norm = 1.6653e-01, time/batch = 15.3289s	
7673/28500 (epoch 13.461), train_loss = 1.11783270, grad/param norm = 1.6069e-01, time/batch = 15.0515s	
7674/28500 (epoch 13.463), train_loss = 1.05333447, grad/param norm = 1.3571e-01, time/batch = 15.4786s	
7675/28500 (epoch 13.465), train_loss = 1.02718545, grad/param norm = 1.7091e-01, time/batch = 15.6218s	
7676/28500 (epoch 13.467), train_loss = 1.19528839, grad/param norm = 1.5227e-01, time/batch = 15.2817s	
7677/28500 (epoch 13.468), train_loss = 1.02909738, grad/param norm = 1.2691e-01, time/batch = 15.6733s	
7678/28500 (epoch 13.470), train_loss = 1.10316235, grad/param norm = 1.5990e-01, time/batch = 15.6208s	
7679/28500 (epoch 13.472), train_loss = 1.12401980, grad/param norm = 1.5994e-01, time/batch = 15.3848s	
7680/28500 (epoch 13.474), train_loss = 1.42108925, grad/param norm = 1.9746e-01, time/batch = 15.5391s	
7681/28500 (epoch 13.475), train_loss = 1.07142448, grad/param norm = 1.4035e-01, time/batch = 15.4561s	
7682/28500 (epoch 13.477), train_loss = 1.15688427, grad/param norm = 1.4757e-01, time/batch = 15.2563s	
7683/28500 (epoch 13.479), train_loss = 1.22331602, grad/param norm = 1.5675e-01, time/batch = 15.4125s	
7684/28500 (epoch 13.481), train_loss = 1.16277878, grad/param norm = 1.7445e-01, time/batch = 15.5192s	
7685/28500 (epoch 13.482), train_loss = 1.06221117, grad/param norm = 1.5201e-01, time/batch = 15.5698s	
7686/28500 (epoch 13.484), train_loss = 1.06103843, grad/param norm = 1.4739e-01, time/batch = 15.6479s	
7687/28500 (epoch 13.486), train_loss = 0.97384394, grad/param norm = 1.7346e-01, time/batch = 15.5263s	
7688/28500 (epoch 13.488), train_loss = 1.18778725, grad/param norm = 1.4739e-01, time/batch = 15.4335s	
7689/28500 (epoch 13.489), train_loss = 1.24753376, grad/param norm = 1.5253e-01, time/batch = 15.3843s	
7690/28500 (epoch 13.491), train_loss = 1.12012074, grad/param norm = 1.5302e-01, time/batch = 15.5290s	
7691/28500 (epoch 13.493), train_loss = 1.10740962, grad/param norm = 1.5224e-01, time/batch = 15.7003s	
7692/28500 (epoch 13.495), train_loss = 1.10123044, grad/param norm = 1.4585e-01, time/batch = 15.5409s	
7693/28500 (epoch 13.496), train_loss = 1.13296246, grad/param norm = 1.6848e-01, time/batch = 15.3087s	
7694/28500 (epoch 13.498), train_loss = 1.21424468, grad/param norm = 1.6465e-01, time/batch = 15.2932s	
7695/28500 (epoch 13.500), train_loss = 1.13208725, grad/param norm = 1.5312e-01, time/batch = 15.6640s	
7696/28500 (epoch 13.502), train_loss = 1.25441806, grad/param norm = 1.5308e-01, time/batch = 15.3751s	
7697/28500 (epoch 13.504), train_loss = 1.21026147, grad/param norm = 1.6267e-01, time/batch = 15.4728s	
7698/28500 (epoch 13.505), train_loss = 1.07070311, grad/param norm = 1.4351e-01, time/batch = 15.5749s	
7699/28500 (epoch 13.507), train_loss = 1.29710668, grad/param norm = 1.8493e-01, time/batch = 15.4223s	
7700/28500 (epoch 13.509), train_loss = 1.16380373, grad/param norm = 1.5836e-01, time/batch = 15.2955s	
7701/28500 (epoch 13.511), train_loss = 1.14983710, grad/param norm = 1.5961e-01, time/batch = 15.3357s	
7702/28500 (epoch 13.512), train_loss = 1.16363480, grad/param norm = 1.4607e-01, time/batch = 15.3630s	
7703/28500 (epoch 13.514), train_loss = 1.05464381, grad/param norm = 1.4505e-01, time/batch = 15.3778s	
7704/28500 (epoch 13.516), train_loss = 1.08179678, grad/param norm = 1.4293e-01, time/batch = 15.3092s	
7705/28500 (epoch 13.518), train_loss = 1.17059534, grad/param norm = 1.5702e-01, time/batch = 15.3945s	
7706/28500 (epoch 13.519), train_loss = 1.22774046, grad/param norm = 1.5720e-01, time/batch = 15.2938s	
7707/28500 (epoch 13.521), train_loss = 1.32386713, grad/param norm = 1.7208e-01, time/batch = 15.0517s	
7708/28500 (epoch 13.523), train_loss = 1.21860968, grad/param norm = 1.6523e-01, time/batch = 15.3782s	
7709/28500 (epoch 13.525), train_loss = 1.26033819, grad/param norm = 1.6498e-01, time/batch = 15.1165s	
7710/28500 (epoch 13.526), train_loss = 1.23882324, grad/param norm = 1.6968e-01, time/batch = 15.2057s	
7711/28500 (epoch 13.528), train_loss = 1.24498795, grad/param norm = 1.5936e-01, time/batch = 15.5789s	
7712/28500 (epoch 13.530), train_loss = 1.28847098, grad/param norm = 1.5527e-01, time/batch = 15.5106s	
7713/28500 (epoch 13.532), train_loss = 1.11381101, grad/param norm = 1.6006e-01, time/batch = 15.3067s	
7714/28500 (epoch 13.533), train_loss = 1.25180599, grad/param norm = 1.4408e-01, time/batch = 15.4189s	
7715/28500 (epoch 13.535), train_loss = 0.99295382, grad/param norm = 1.4036e-01, time/batch = 15.6295s	
7716/28500 (epoch 13.537), train_loss = 1.00234743, grad/param norm = 1.4951e-01, time/batch = 15.3748s	
7717/28500 (epoch 13.539), train_loss = 1.02535630, grad/param norm = 1.5758e-01, time/batch = 15.5537s	
7718/28500 (epoch 13.540), train_loss = 1.16282500, grad/param norm = 1.4568e-01, time/batch = 15.6263s	
7719/28500 (epoch 13.542), train_loss = 1.30018755, grad/param norm = 1.6860e-01, time/batch = 15.6106s	
7720/28500 (epoch 13.544), train_loss = 1.32388695, grad/param norm = 1.6055e-01, time/batch = 15.3739s	
7721/28500 (epoch 13.546), train_loss = 1.17140840, grad/param norm = 1.6269e-01, time/batch = 15.4541s	
7722/28500 (epoch 13.547), train_loss = 1.16811637, grad/param norm = 1.4835e-01, time/batch = 15.2669s	
7723/28500 (epoch 13.549), train_loss = 1.00074895, grad/param norm = 1.3053e-01, time/batch = 15.1196s	
7724/28500 (epoch 13.551), train_loss = 1.22549272, grad/param norm = 1.7390e-01, time/batch = 15.0366s	
7725/28500 (epoch 13.553), train_loss = 1.38684909, grad/param norm = 1.8813e-01, time/batch = 15.3350s	
7726/28500 (epoch 13.554), train_loss = 1.12661397, grad/param norm = 1.4248e-01, time/batch = 15.4118s	
7727/28500 (epoch 13.556), train_loss = 1.17152875, grad/param norm = 1.6410e-01, time/batch = 15.3649s	
7728/28500 (epoch 13.558), train_loss = 1.19348529, grad/param norm = 1.4994e-01, time/batch = 15.2834s	
7729/28500 (epoch 13.560), train_loss = 1.19562993, grad/param norm = 1.6469e-01, time/batch = 15.3017s	
7730/28500 (epoch 13.561), train_loss = 1.25740437, grad/param norm = 1.7704e-01, time/batch = 15.2317s	
7731/28500 (epoch 13.563), train_loss = 1.35565642, grad/param norm = 1.7164e-01, time/batch = 15.3791s	
7732/28500 (epoch 13.565), train_loss = 1.15224749, grad/param norm = 1.5149e-01, time/batch = 15.2995s	
7733/28500 (epoch 13.567), train_loss = 1.03007553, grad/param norm = 1.5319e-01, time/batch = 15.3132s	
7734/28500 (epoch 13.568), train_loss = 1.19821876, grad/param norm = 1.5187e-01, time/batch = 15.5846s	
7735/28500 (epoch 13.570), train_loss = 1.12505536, grad/param norm = 1.5726e-01, time/batch = 15.2151s	
7736/28500 (epoch 13.572), train_loss = 1.11930708, grad/param norm = 1.5545e-01, time/batch = 15.3003s	
7737/28500 (epoch 13.574), train_loss = 1.13088769, grad/param norm = 1.5637e-01, time/batch = 15.2499s	
7738/28500 (epoch 13.575), train_loss = 1.12588616, grad/param norm = 1.4896e-01, time/batch = 15.2379s	
7739/28500 (epoch 13.577), train_loss = 1.18354957, grad/param norm = 1.4920e-01, time/batch = 15.1140s	
7740/28500 (epoch 13.579), train_loss = 1.24715816, grad/param norm = 1.6243e-01, time/batch = 15.1202s	
7741/28500 (epoch 13.581), train_loss = 1.13250135, grad/param norm = 1.6909e-01, time/batch = 15.3426s	
7742/28500 (epoch 13.582), train_loss = 1.27044636, grad/param norm = 1.5840e-01, time/batch = 15.3026s	
7743/28500 (epoch 13.584), train_loss = 1.11346436, grad/param norm = 1.5266e-01, time/batch = 15.3404s	
7744/28500 (epoch 13.586), train_loss = 1.06620709, grad/param norm = 1.3830e-01, time/batch = 15.1975s	
7745/28500 (epoch 13.588), train_loss = 1.06975396, grad/param norm = 1.3926e-01, time/batch = 15.2968s	
7746/28500 (epoch 13.589), train_loss = 1.21492559, grad/param norm = 1.5962e-01, time/batch = 15.2219s	
7747/28500 (epoch 13.591), train_loss = 1.20991702, grad/param norm = 1.4674e-01, time/batch = 15.1368s	
7748/28500 (epoch 13.593), train_loss = 1.10968696, grad/param norm = 1.4904e-01, time/batch = 15.1184s	
7749/28500 (epoch 13.595), train_loss = 1.39979095, grad/param norm = 1.8342e-01, time/batch = 15.1060s	
7750/28500 (epoch 13.596), train_loss = 1.39369858, grad/param norm = 1.8558e-01, time/batch = 15.1284s	
7751/28500 (epoch 13.598), train_loss = 1.18535488, grad/param norm = 1.5038e-01, time/batch = 15.5040s	
7752/28500 (epoch 13.600), train_loss = 1.19293212, grad/param norm = 1.7340e-01, time/batch = 15.3872s	
7753/28500 (epoch 13.602), train_loss = 1.29629859, grad/param norm = 1.6103e-01, time/batch = 15.5745s	
7754/28500 (epoch 13.604), train_loss = 1.25276685, grad/param norm = 1.5896e-01, time/batch = 15.2075s	
7755/28500 (epoch 13.605), train_loss = 1.20059234, grad/param norm = 1.6587e-01, time/batch = 15.3854s	
7756/28500 (epoch 13.607), train_loss = 1.24510368, grad/param norm = 1.4625e-01, time/batch = 15.3572s	
7757/28500 (epoch 13.609), train_loss = 1.17116318, grad/param norm = 1.6223e-01, time/batch = 15.3664s	
7758/28500 (epoch 13.611), train_loss = 1.18947878, grad/param norm = 1.5428e-01, time/batch = 15.3766s	
7759/28500 (epoch 13.612), train_loss = 1.22509172, grad/param norm = 1.6805e-01, time/batch = 15.5231s	
7760/28500 (epoch 13.614), train_loss = 1.21279794, grad/param norm = 1.6526e-01, time/batch = 15.1752s	
7761/28500 (epoch 13.616), train_loss = 1.11545349, grad/param norm = 1.5203e-01, time/batch = 15.2734s	
7762/28500 (epoch 13.618), train_loss = 1.12530126, grad/param norm = 1.5528e-01, time/batch = 15.2105s	
7763/28500 (epoch 13.619), train_loss = 1.36359859, grad/param norm = 1.7410e-01, time/batch = 15.2110s	
7764/28500 (epoch 13.621), train_loss = 0.96893848, grad/param norm = 1.3543e-01, time/batch = 15.5329s	
7765/28500 (epoch 13.623), train_loss = 1.28208154, grad/param norm = 1.6007e-01, time/batch = 15.5665s	
7766/28500 (epoch 13.625), train_loss = 1.03532218, grad/param norm = 1.5422e-01, time/batch = 15.4770s	
7767/28500 (epoch 13.626), train_loss = 0.89307689, grad/param norm = 1.2720e-01, time/batch = 15.6444s	
7768/28500 (epoch 13.628), train_loss = 1.09349257, grad/param norm = 1.4826e-01, time/batch = 15.4449s	
7769/28500 (epoch 13.630), train_loss = 1.00934602, grad/param norm = 1.4681e-01, time/batch = 15.3595s	
7770/28500 (epoch 13.632), train_loss = 1.25214215, grad/param norm = 1.6416e-01, time/batch = 15.1299s	
7771/28500 (epoch 13.633), train_loss = 1.31076412, grad/param norm = 1.6106e-01, time/batch = 15.3530s	
7772/28500 (epoch 13.635), train_loss = 1.35279966, grad/param norm = 1.7631e-01, time/batch = 15.3784s	
7773/28500 (epoch 13.637), train_loss = 1.16800703, grad/param norm = 1.4322e-01, time/batch = 15.3893s	
7774/28500 (epoch 13.639), train_loss = 1.04434348, grad/param norm = 1.4656e-01, time/batch = 15.2945s	
7775/28500 (epoch 13.640), train_loss = 1.05892120, grad/param norm = 1.4400e-01, time/batch = 15.3032s	
7776/28500 (epoch 13.642), train_loss = 1.17751301, grad/param norm = 1.4938e-01, time/batch = 15.2233s	
7777/28500 (epoch 13.644), train_loss = 1.23515429, grad/param norm = 1.4794e-01, time/batch = 15.3768s	
7778/28500 (epoch 13.646), train_loss = 1.05498455, grad/param norm = 1.3866e-01, time/batch = 15.3148s	
7779/28500 (epoch 13.647), train_loss = 1.05484747, grad/param norm = 1.4816e-01, time/batch = 15.4160s	
7780/28500 (epoch 13.649), train_loss = 1.04309310, grad/param norm = 1.4953e-01, time/batch = 15.1216s	
7781/28500 (epoch 13.651), train_loss = 1.01595254, grad/param norm = 1.4471e-01, time/batch = 15.6041s	
7782/28500 (epoch 13.653), train_loss = 1.04055002, grad/param norm = 1.4815e-01, time/batch = 15.4748s	
7783/28500 (epoch 13.654), train_loss = 1.14224512, grad/param norm = 1.5587e-01, time/batch = 15.4803s	
7784/28500 (epoch 13.656), train_loss = 1.07822945, grad/param norm = 1.5626e-01, time/batch = 15.5325s	
7785/28500 (epoch 13.658), train_loss = 1.17413470, grad/param norm = 1.6179e-01, time/batch = 15.3950s	
7786/28500 (epoch 13.660), train_loss = 1.14530686, grad/param norm = 1.3697e-01, time/batch = 15.4866s	
7787/28500 (epoch 13.661), train_loss = 1.31890197, grad/param norm = 1.7111e-01, time/batch = 15.4797s	
7788/28500 (epoch 13.663), train_loss = 1.35496224, grad/param norm = 1.7253e-01, time/batch = 15.2843s	
7789/28500 (epoch 13.665), train_loss = 1.13721889, grad/param norm = 1.5109e-01, time/batch = 15.0486s	
7790/28500 (epoch 13.667), train_loss = 1.16761964, grad/param norm = 1.6237e-01, time/batch = 15.0362s	
7791/28500 (epoch 13.668), train_loss = 1.14626857, grad/param norm = 1.4761e-01, time/batch = 15.2744s	
7792/28500 (epoch 13.670), train_loss = 1.17003325, grad/param norm = 1.5555e-01, time/batch = 15.4170s	
7793/28500 (epoch 13.672), train_loss = 1.11714130, grad/param norm = 1.5799e-01, time/batch = 15.4697s	
7794/28500 (epoch 13.674), train_loss = 0.96977522, grad/param norm = 1.4695e-01, time/batch = 15.3893s	
7795/28500 (epoch 13.675), train_loss = 1.01783369, grad/param norm = 1.5765e-01, time/batch = 15.5422s	
7796/28500 (epoch 13.677), train_loss = 1.13368368, grad/param norm = 1.4513e-01, time/batch = 15.2767s	
7797/28500 (epoch 13.679), train_loss = 1.10161772, grad/param norm = 1.5177e-01, time/batch = 15.0705s	
7798/28500 (epoch 13.681), train_loss = 1.24273022, grad/param norm = 1.6088e-01, time/batch = 15.2332s	
7799/28500 (epoch 13.682), train_loss = 1.12248923, grad/param norm = 1.5309e-01, time/batch = 15.3049s	
7800/28500 (epoch 13.684), train_loss = 1.22956363, grad/param norm = 1.5841e-01, time/batch = 15.1699s	
7801/28500 (epoch 13.686), train_loss = 1.09349063, grad/param norm = 1.6402e-01, time/batch = 15.3643s	
7802/28500 (epoch 13.688), train_loss = 1.03909439, grad/param norm = 1.3621e-01, time/batch = 15.4623s	
7803/28500 (epoch 13.689), train_loss = 1.15731702, grad/param norm = 1.4653e-01, time/batch = 15.6272s	
7804/28500 (epoch 13.691), train_loss = 1.22505221, grad/param norm = 1.7871e-01, time/batch = 15.4445s	
7805/28500 (epoch 13.693), train_loss = 1.11054915, grad/param norm = 1.5727e-01, time/batch = 15.3284s	
7806/28500 (epoch 13.695), train_loss = 0.96678262, grad/param norm = 1.6837e-01, time/batch = 15.3059s	
7807/28500 (epoch 13.696), train_loss = 1.11897845, grad/param norm = 1.6000e-01, time/batch = 15.3614s	
7808/28500 (epoch 13.698), train_loss = 1.13658908, grad/param norm = 1.4982e-01, time/batch = 15.3670s	
7809/28500 (epoch 13.700), train_loss = 1.19227085, grad/param norm = 1.5328e-01, time/batch = 15.0601s	
7810/28500 (epoch 13.702), train_loss = 1.25398317, grad/param norm = 1.7053e-01, time/batch = 15.1790s	
7811/28500 (epoch 13.704), train_loss = 1.20050628, grad/param norm = 1.6667e-01, time/batch = 15.3914s	
7812/28500 (epoch 13.705), train_loss = 1.27177267, grad/param norm = 1.7179e-01, time/batch = 15.5323s	
7813/28500 (epoch 13.707), train_loss = 1.11264528, grad/param norm = 1.6234e-01, time/batch = 15.4408s	
7814/28500 (epoch 13.709), train_loss = 1.27207259, grad/param norm = 1.6297e-01, time/batch = 15.4919s	
7815/28500 (epoch 13.711), train_loss = 1.08328219, grad/param norm = 1.6848e-01, time/batch = 15.5423s	
7816/28500 (epoch 13.712), train_loss = 1.22393384, grad/param norm = 1.7348e-01, time/batch = 15.5499s	
7817/28500 (epoch 13.714), train_loss = 1.26609742, grad/param norm = 1.6913e-01, time/batch = 15.2894s	
7818/28500 (epoch 13.716), train_loss = 1.14213667, grad/param norm = 1.8365e-01, time/batch = 15.3447s	
7819/28500 (epoch 13.718), train_loss = 1.12540204, grad/param norm = 1.5759e-01, time/batch = 15.4183s	
7820/28500 (epoch 13.719), train_loss = 1.16078353, grad/param norm = 1.5620e-01, time/batch = 15.3659s	
7821/28500 (epoch 13.721), train_loss = 0.96341527, grad/param norm = 1.5755e-01, time/batch = 15.4581s	
7822/28500 (epoch 13.723), train_loss = 1.16215613, grad/param norm = 1.7027e-01, time/batch = 15.5385s	
7823/28500 (epoch 13.725), train_loss = 1.25904326, grad/param norm = 1.4769e-01, time/batch = 15.2306s	
7824/28500 (epoch 13.726), train_loss = 1.19648570, grad/param norm = 1.6775e-01, time/batch = 15.3917s	
7825/28500 (epoch 13.728), train_loss = 1.02322525, grad/param norm = 1.3587e-01, time/batch = 15.3200s	
7826/28500 (epoch 13.730), train_loss = 1.18874173, grad/param norm = 1.7030e-01, time/batch = 15.2953s	
7827/28500 (epoch 13.732), train_loss = 0.97421498, grad/param norm = 1.4199e-01, time/batch = 15.1992s	
7828/28500 (epoch 13.733), train_loss = 0.97619737, grad/param norm = 1.3587e-01, time/batch = 15.3029s	
7829/28500 (epoch 13.735), train_loss = 0.99751493, grad/param norm = 1.4264e-01, time/batch = 15.1259s	
7830/28500 (epoch 13.737), train_loss = 0.93168575, grad/param norm = 1.2681e-01, time/batch = 15.3663s	
7831/28500 (epoch 13.739), train_loss = 1.12699965, grad/param norm = 1.6676e-01, time/batch = 27.7151s	
7832/28500 (epoch 13.740), train_loss = 1.14940577, grad/param norm = 1.5464e-01, time/batch = 15.1439s	
7833/28500 (epoch 13.742), train_loss = 1.04779038, grad/param norm = 1.3909e-01, time/batch = 15.0296s	
7834/28500 (epoch 13.744), train_loss = 1.19484108, grad/param norm = 1.6504e-01, time/batch = 15.5186s	
7835/28500 (epoch 13.746), train_loss = 1.03772222, grad/param norm = 1.3926e-01, time/batch = 15.2973s	
7836/28500 (epoch 13.747), train_loss = 1.05480649, grad/param norm = 1.4799e-01, time/batch = 15.3761s	
7837/28500 (epoch 13.749), train_loss = 1.28618363, grad/param norm = 1.7673e-01, time/batch = 15.5502s	
7838/28500 (epoch 13.751), train_loss = 1.04821927, grad/param norm = 1.7133e-01, time/batch = 15.3663s	
7839/28500 (epoch 13.753), train_loss = 1.05079131, grad/param norm = 1.3586e-01, time/batch = 15.2817s	
7840/28500 (epoch 13.754), train_loss = 1.00316292, grad/param norm = 1.6609e-01, time/batch = 15.3205s	
7841/28500 (epoch 13.756), train_loss = 1.25779254, grad/param norm = 1.6320e-01, time/batch = 15.5760s	
7842/28500 (epoch 13.758), train_loss = 1.21805266, grad/param norm = 1.6276e-01, time/batch = 15.5155s	
7843/28500 (epoch 13.760), train_loss = 1.01061447, grad/param norm = 1.4566e-01, time/batch = 15.3725s	
7844/28500 (epoch 13.761), train_loss = 1.03046740, grad/param norm = 1.6956e-01, time/batch = 15.4058s	
7845/28500 (epoch 13.763), train_loss = 0.92194773, grad/param norm = 1.4446e-01, time/batch = 15.5850s	
7846/28500 (epoch 13.765), train_loss = 1.07754854, grad/param norm = 1.4270e-01, time/batch = 15.4731s	
7847/28500 (epoch 13.767), train_loss = 0.95466485, grad/param norm = 1.3577e-01, time/batch = 15.4224s	
7848/28500 (epoch 13.768), train_loss = 1.23664275, grad/param norm = 1.6840e-01, time/batch = 15.3816s	
7849/28500 (epoch 13.770), train_loss = 0.97269088, grad/param norm = 1.4074e-01, time/batch = 15.2164s	
7850/28500 (epoch 13.772), train_loss = 0.87922720, grad/param norm = 1.3164e-01, time/batch = 15.3720s	
7851/28500 (epoch 13.774), train_loss = 1.15704654, grad/param norm = 1.6065e-01, time/batch = 15.6374s	
7852/28500 (epoch 13.775), train_loss = 1.21275350, grad/param norm = 1.4664e-01, time/batch = 15.6213s	
7853/28500 (epoch 13.777), train_loss = 1.19295822, grad/param norm = 1.5257e-01, time/batch = 15.3583s	
7854/28500 (epoch 13.779), train_loss = 0.96220922, grad/param norm = 1.3045e-01, time/batch = 15.2935s	
7855/28500 (epoch 13.781), train_loss = 1.16781625, grad/param norm = 1.5942e-01, time/batch = 15.3670s	
7856/28500 (epoch 13.782), train_loss = 1.20899311, grad/param norm = 1.5963e-01, time/batch = 15.1492s	
7857/28500 (epoch 13.784), train_loss = 0.95404755, grad/param norm = 1.3222e-01, time/batch = 15.3608s	
7858/28500 (epoch 13.786), train_loss = 1.02543847, grad/param norm = 1.4242e-01, time/batch = 15.2930s	
7859/28500 (epoch 13.788), train_loss = 1.12491015, grad/param norm = 1.4719e-01, time/batch = 15.1700s	
7860/28500 (epoch 13.789), train_loss = 0.88601386, grad/param norm = 1.6548e-01, time/batch = 15.4942s	
7861/28500 (epoch 13.791), train_loss = 1.12371670, grad/param norm = 1.4760e-01, time/batch = 15.4553s	
7862/28500 (epoch 13.793), train_loss = 1.08754573, grad/param norm = 1.6075e-01, time/batch = 15.1384s	
7863/28500 (epoch 13.795), train_loss = 1.14557055, grad/param norm = 1.4284e-01, time/batch = 15.1675s	
7864/28500 (epoch 13.796), train_loss = 1.03144810, grad/param norm = 1.5164e-01, time/batch = 15.5266s	
7865/28500 (epoch 13.798), train_loss = 0.97538289, grad/param norm = 1.4782e-01, time/batch = 15.4724s	
7866/28500 (epoch 13.800), train_loss = 1.01657901, grad/param norm = 1.5943e-01, time/batch = 15.2931s	
7867/28500 (epoch 13.802), train_loss = 1.12440459, grad/param norm = 1.8583e-01, time/batch = 15.1442s	
7868/28500 (epoch 13.804), train_loss = 1.15018822, grad/param norm = 1.4882e-01, time/batch = 15.2187s	
7869/28500 (epoch 13.805), train_loss = 1.13084942, grad/param norm = 1.6774e-01, time/batch = 15.5639s	
7870/28500 (epoch 13.807), train_loss = 1.20509227, grad/param norm = 1.6780e-01, time/batch = 15.5027s	
7871/28500 (epoch 13.809), train_loss = 1.11052498, grad/param norm = 1.5053e-01, time/batch = 15.5724s	
7872/28500 (epoch 13.811), train_loss = 1.19742659, grad/param norm = 1.6467e-01, time/batch = 15.2006s	
7873/28500 (epoch 13.812), train_loss = 1.17648524, grad/param norm = 1.8024e-01, time/batch = 15.3600s	
7874/28500 (epoch 13.814), train_loss = 1.10395663, grad/param norm = 1.5330e-01, time/batch = 15.4020s	
7875/28500 (epoch 13.816), train_loss = 1.24496979, grad/param norm = 1.7046e-01, time/batch = 15.2219s	
7876/28500 (epoch 13.818), train_loss = 1.21881470, grad/param norm = 1.5469e-01, time/batch = 15.3756s	
7877/28500 (epoch 13.819), train_loss = 1.13510013, grad/param norm = 1.4862e-01, time/batch = 15.2822s	
7878/28500 (epoch 13.821), train_loss = 1.07802685, grad/param norm = 1.5629e-01, time/batch = 15.4891s	
7879/28500 (epoch 13.823), train_loss = 1.28788701, grad/param norm = 1.7461e-01, time/batch = 15.4462s	
7880/28500 (epoch 13.825), train_loss = 1.10943635, grad/param norm = 1.6002e-01, time/batch = 15.2940s	
7881/28500 (epoch 13.826), train_loss = 1.16425109, grad/param norm = 1.6666e-01, time/batch = 15.6054s	
7882/28500 (epoch 13.828), train_loss = 1.01411950, grad/param norm = 1.6138e-01, time/batch = 15.2093s	
7883/28500 (epoch 13.830), train_loss = 1.07625217, grad/param norm = 1.5227e-01, time/batch = 14.9807s	
7884/28500 (epoch 13.832), train_loss = 1.14014157, grad/param norm = 1.7101e-01, time/batch = 15.4109s	
7885/28500 (epoch 13.833), train_loss = 1.29223558, grad/param norm = 1.6444e-01, time/batch = 15.5382s	
7886/28500 (epoch 13.835), train_loss = 1.09343432, grad/param norm = 1.6474e-01, time/batch = 15.4463s	
7887/28500 (epoch 13.837), train_loss = 0.98835977, grad/param norm = 1.5129e-01, time/batch = 15.4910s	
7888/28500 (epoch 13.839), train_loss = 1.25053515, grad/param norm = 1.6893e-01, time/batch = 15.7008s	
7889/28500 (epoch 13.840), train_loss = 1.25489485, grad/param norm = 1.5990e-01, time/batch = 15.5993s	
7890/28500 (epoch 13.842), train_loss = 1.22607534, grad/param norm = 1.7216e-01, time/batch = 15.3889s	
7891/28500 (epoch 13.844), train_loss = 1.15932247, grad/param norm = 1.6075e-01, time/batch = 15.6444s	
7892/28500 (epoch 13.846), train_loss = 1.28095734, grad/param norm = 1.6312e-01, time/batch = 15.5610s	
7893/28500 (epoch 13.847), train_loss = 1.08743231, grad/param norm = 1.4600e-01, time/batch = 15.5183s	
7894/28500 (epoch 13.849), train_loss = 1.08318789, grad/param norm = 1.5124e-01, time/batch = 15.3811s	
7895/28500 (epoch 13.851), train_loss = 0.96979641, grad/param norm = 1.3766e-01, time/batch = 15.3684s	
7896/28500 (epoch 13.853), train_loss = 1.14748682, grad/param norm = 1.6332e-01, time/batch = 15.3682s	
7897/28500 (epoch 13.854), train_loss = 1.17393162, grad/param norm = 1.6589e-01, time/batch = 15.5358s	
7898/28500 (epoch 13.856), train_loss = 1.26420041, grad/param norm = 1.8422e-01, time/batch = 15.4270s	
7899/28500 (epoch 13.858), train_loss = 1.01734757, grad/param norm = 1.4016e-01, time/batch = 15.3411s	
7900/28500 (epoch 13.860), train_loss = 1.15123745, grad/param norm = 1.6665e-01, time/batch = 15.3719s	
7901/28500 (epoch 13.861), train_loss = 1.17492889, grad/param norm = 1.6499e-01, time/batch = 15.3865s	
7902/28500 (epoch 13.863), train_loss = 1.23775965, grad/param norm = 1.6970e-01, time/batch = 15.3140s	
7903/28500 (epoch 13.865), train_loss = 1.12820312, grad/param norm = 1.5783e-01, time/batch = 15.3610s	
7904/28500 (epoch 13.867), train_loss = 1.19502793, grad/param norm = 1.6560e-01, time/batch = 15.4561s	
7905/28500 (epoch 13.868), train_loss = 1.01770142, grad/param norm = 1.4608e-01, time/batch = 15.6161s	
7906/28500 (epoch 13.870), train_loss = 0.94215278, grad/param norm = 1.3468e-01, time/batch = 15.5623s	
7907/28500 (epoch 13.872), train_loss = 1.18950073, grad/param norm = 1.7328e-01, time/batch = 15.6245s	
7908/28500 (epoch 13.874), train_loss = 1.14608157, grad/param norm = 1.7389e-01, time/batch = 15.2134s	
7909/28500 (epoch 13.875), train_loss = 1.24309525, grad/param norm = 1.7007e-01, time/batch = 15.3116s	
7910/28500 (epoch 13.877), train_loss = 1.17324856, grad/param norm = 1.5112e-01, time/batch = 15.2139s	
7911/28500 (epoch 13.879), train_loss = 1.14945487, grad/param norm = 1.5633e-01, time/batch = 15.4814s	
7912/28500 (epoch 13.881), train_loss = 1.14755540, grad/param norm = 1.5620e-01, time/batch = 15.1301s	
7913/28500 (epoch 13.882), train_loss = 1.07942987, grad/param norm = 1.3975e-01, time/batch = 15.2066s	
7914/28500 (epoch 13.884), train_loss = 1.17756080, grad/param norm = 1.7043e-01, time/batch = 15.2115s	
7915/28500 (epoch 13.886), train_loss = 1.08124772, grad/param norm = 1.4901e-01, time/batch = 15.3540s	
7916/28500 (epoch 13.888), train_loss = 1.01661223, grad/param norm = 1.4848e-01, time/batch = 15.5147s	
7917/28500 (epoch 13.889), train_loss = 1.14478342, grad/param norm = 1.5776e-01, time/batch = 15.3800s	
7918/28500 (epoch 13.891), train_loss = 1.16005088, grad/param norm = 1.5515e-01, time/batch = 15.1246s	
7919/28500 (epoch 13.893), train_loss = 1.06808927, grad/param norm = 1.5252e-01, time/batch = 15.2603s	
7920/28500 (epoch 13.895), train_loss = 1.32137422, grad/param norm = 1.8884e-01, time/batch = 15.0702s	
7921/28500 (epoch 13.896), train_loss = 1.19525632, grad/param norm = 1.5796e-01, time/batch = 15.4066s	
7922/28500 (epoch 13.898), train_loss = 1.12034329, grad/param norm = 1.5265e-01, time/batch = 15.4427s	
7923/28500 (epoch 13.900), train_loss = 0.99404721, grad/param norm = 1.5312e-01, time/batch = 15.2714s	
7924/28500 (epoch 13.902), train_loss = 1.01439459, grad/param norm = 1.5375e-01, time/batch = 15.4082s	
7925/28500 (epoch 13.904), train_loss = 1.05278919, grad/param norm = 1.4441e-01, time/batch = 15.0372s	
7926/28500 (epoch 13.905), train_loss = 1.16979930, grad/param norm = 1.5898e-01, time/batch = 14.9812s	
7927/28500 (epoch 13.907), train_loss = 1.13528198, grad/param norm = 1.5940e-01, time/batch = 15.2033s	
7928/28500 (epoch 13.909), train_loss = 1.01238191, grad/param norm = 1.6459e-01, time/batch = 15.6259s	
7929/28500 (epoch 13.911), train_loss = 1.02711592, grad/param norm = 1.3580e-01, time/batch = 15.4760s	
7930/28500 (epoch 13.912), train_loss = 0.90462406, grad/param norm = 1.3409e-01, time/batch = 15.3012s	
7931/28500 (epoch 13.914), train_loss = 1.24848352, grad/param norm = 1.4849e-01, time/batch = 15.5344s	
7932/28500 (epoch 13.916), train_loss = 1.19094253, grad/param norm = 1.7733e-01, time/batch = 15.4772s	
7933/28500 (epoch 13.918), train_loss = 1.15225237, grad/param norm = 1.7244e-01, time/batch = 15.3730s	
7934/28500 (epoch 13.919), train_loss = 1.12386934, grad/param norm = 1.4597e-01, time/batch = 15.1402s	
7935/28500 (epoch 13.921), train_loss = 1.28129082, grad/param norm = 1.7977e-01, time/batch = 15.1077s	
7936/28500 (epoch 13.923), train_loss = 1.14015162, grad/param norm = 1.7725e-01, time/batch = 15.4161s	
7937/28500 (epoch 13.925), train_loss = 1.04048482, grad/param norm = 1.6078e-01, time/batch = 15.5300s	
7938/28500 (epoch 13.926), train_loss = 1.10128394, grad/param norm = 1.4740e-01, time/batch = 15.4986s	
7939/28500 (epoch 13.928), train_loss = 1.06430562, grad/param norm = 1.4658e-01, time/batch = 15.6104s	
7940/28500 (epoch 13.930), train_loss = 0.88177084, grad/param norm = 1.3233e-01, time/batch = 15.4652s	
7941/28500 (epoch 13.932), train_loss = 0.90630167, grad/param norm = 1.3244e-01, time/batch = 15.4465s	
7942/28500 (epoch 13.933), train_loss = 1.19063559, grad/param norm = 1.6327e-01, time/batch = 14.9652s	
7943/28500 (epoch 13.935), train_loss = 1.23235687, grad/param norm = 1.7379e-01, time/batch = 15.1144s	
7944/28500 (epoch 13.937), train_loss = 1.26198555, grad/param norm = 1.7830e-01, time/batch = 15.1335s	
7945/28500 (epoch 13.939), train_loss = 1.31437957, grad/param norm = 1.6972e-01, time/batch = 15.4421s	
7946/28500 (epoch 13.940), train_loss = 1.01298195, grad/param norm = 1.4773e-01, time/batch = 15.4419s	
7947/28500 (epoch 13.942), train_loss = 1.20539206, grad/param norm = 1.7501e-01, time/batch = 15.4680s	
7948/28500 (epoch 13.944), train_loss = 1.12329974, grad/param norm = 1.6105e-01, time/batch = 15.3050s	
7949/28500 (epoch 13.946), train_loss = 1.25048422, grad/param norm = 1.5246e-01, time/batch = 15.2978s	
7950/28500 (epoch 13.947), train_loss = 1.47041401, grad/param norm = 1.9574e-01, time/batch = 15.4326s	
7951/28500 (epoch 13.949), train_loss = 1.03591116, grad/param norm = 1.5263e-01, time/batch = 15.3996s	
7952/28500 (epoch 13.951), train_loss = 1.27350826, grad/param norm = 1.8353e-01, time/batch = 15.2138s	
7953/28500 (epoch 13.953), train_loss = 1.32659205, grad/param norm = 1.8002e-01, time/batch = 15.0608s	
7954/28500 (epoch 13.954), train_loss = 1.27740537, grad/param norm = 1.9325e-01, time/batch = 15.2835s	
7955/28500 (epoch 13.956), train_loss = 1.24285696, grad/param norm = 2.0834e-01, time/batch = 15.5251s	
7956/28500 (epoch 13.958), train_loss = 1.33335024, grad/param norm = 1.6344e-01, time/batch = 15.4347s	
7957/28500 (epoch 13.960), train_loss = 1.02852616, grad/param norm = 1.6551e-01, time/batch = 15.4613s	
7958/28500 (epoch 13.961), train_loss = 1.37514713, grad/param norm = 1.8284e-01, time/batch = 15.2383s	
7959/28500 (epoch 13.963), train_loss = 1.26631600, grad/param norm = 1.5969e-01, time/batch = 15.3141s	
7960/28500 (epoch 13.965), train_loss = 1.04026642, grad/param norm = 1.5177e-01, time/batch = 15.1309s	
7961/28500 (epoch 13.967), train_loss = 1.03631310, grad/param norm = 1.6173e-01, time/batch = 15.3917s	
7962/28500 (epoch 13.968), train_loss = 0.96574969, grad/param norm = 1.3442e-01, time/batch = 15.3645s	
7963/28500 (epoch 13.970), train_loss = 1.07894348, grad/param norm = 1.5304e-01, time/batch = 15.3718s	
7964/28500 (epoch 13.972), train_loss = 1.18393683, grad/param norm = 1.6924e-01, time/batch = 15.4056s	
7965/28500 (epoch 13.974), train_loss = 1.36792296, grad/param norm = 1.8392e-01, time/batch = 15.3439s	
7966/28500 (epoch 13.975), train_loss = 1.09439175, grad/param norm = 1.6281e-01, time/batch = 15.4007s	
7967/28500 (epoch 13.977), train_loss = 1.30370246, grad/param norm = 1.7260e-01, time/batch = 15.2635s	
7968/28500 (epoch 13.979), train_loss = 1.09904396, grad/param norm = 1.6238e-01, time/batch = 15.3214s	
7969/28500 (epoch 13.981), train_loss = 1.05141114, grad/param norm = 1.5021e-01, time/batch = 15.1492s	
7970/28500 (epoch 13.982), train_loss = 1.06573584, grad/param norm = 1.4853e-01, time/batch = 15.2092s	
7971/28500 (epoch 13.984), train_loss = 1.26122358, grad/param norm = 1.6513e-01, time/batch = 15.6354s	
7972/28500 (epoch 13.986), train_loss = 1.40893082, grad/param norm = 1.8298e-01, time/batch = 15.2290s	
7973/28500 (epoch 13.988), train_loss = 0.98185629, grad/param norm = 1.6210e-01, time/batch = 15.2094s	
7974/28500 (epoch 13.989), train_loss = 1.17464458, grad/param norm = 1.5966e-01, time/batch = 15.3783s	
7975/28500 (epoch 13.991), train_loss = 1.07352848, grad/param norm = 1.6548e-01, time/batch = 15.4582s	
7976/28500 (epoch 13.993), train_loss = 1.08258228, grad/param norm = 1.6847e-01, time/batch = 15.5934s	
7977/28500 (epoch 13.995), train_loss = 1.04861984, grad/param norm = 1.5088e-01, time/batch = 15.8351s	
7978/28500 (epoch 13.996), train_loss = 1.02916567, grad/param norm = 1.4759e-01, time/batch = 15.7220s	
7979/28500 (epoch 13.998), train_loss = 1.23975135, grad/param norm = 1.5975e-01, time/batch = 15.7034s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
7980/28500 (epoch 14.000), train_loss = 1.08192066, grad/param norm = 1.5020e-01, time/batch = 15.4613s	
7981/28500 (epoch 14.002), train_loss = 1.30168194, grad/param norm = 1.7179e-01, time/batch = 15.3626s	
7982/28500 (epoch 14.004), train_loss = 1.10021553, grad/param norm = 1.5288e-01, time/batch = 15.3766s	
7983/28500 (epoch 14.005), train_loss = 1.24531686, grad/param norm = 1.6893e-01, time/batch = 15.3834s	
7984/28500 (epoch 14.007), train_loss = 1.00994894, grad/param norm = 1.4691e-01, time/batch = 15.2698s	
7985/28500 (epoch 14.009), train_loss = 1.20583844, grad/param norm = 1.7245e-01, time/batch = 15.1613s	
7986/28500 (epoch 14.011), train_loss = 1.09394048, grad/param norm = 2.0074e-01, time/batch = 15.2223s	
7987/28500 (epoch 14.012), train_loss = 0.98966961, grad/param norm = 1.3761e-01, time/batch = 15.3035s	
7988/28500 (epoch 14.014), train_loss = 1.02288911, grad/param norm = 1.4771e-01, time/batch = 15.4621s	
7989/28500 (epoch 14.016), train_loss = 1.09231260, grad/param norm = 1.3799e-01, time/batch = 15.6162s	
7990/28500 (epoch 14.018), train_loss = 1.17192525, grad/param norm = 1.5625e-01, time/batch = 15.5412s	
7991/28500 (epoch 14.019), train_loss = 1.23393944, grad/param norm = 1.6573e-01, time/batch = 15.6584s	
7992/28500 (epoch 14.021), train_loss = 1.19880620, grad/param norm = 1.4044e-01, time/batch = 15.4435s	
7993/28500 (epoch 14.023), train_loss = 1.10566882, grad/param norm = 1.5632e-01, time/batch = 15.3526s	
7994/28500 (epoch 14.025), train_loss = 1.13678145, grad/param norm = 1.5297e-01, time/batch = 15.4335s	
7995/28500 (epoch 14.026), train_loss = 1.14927639, grad/param norm = 1.6318e-01, time/batch = 15.2275s	
7996/28500 (epoch 14.028), train_loss = 1.19196054, grad/param norm = 1.6462e-01, time/batch = 14.9864s	
7997/28500 (epoch 14.030), train_loss = 1.23259639, grad/param norm = 1.8124e-01, time/batch = 15.4681s	
7998/28500 (epoch 14.032), train_loss = 1.21045254, grad/param norm = 1.7086e-01, time/batch = 15.4284s	
7999/28500 (epoch 14.033), train_loss = 1.31184727, grad/param norm = 1.7558e-01, time/batch = 15.3988s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch14.04_1.6097.t7	
8000/28500 (epoch 14.035), train_loss = 1.14887100, grad/param norm = 1.5882e-01, time/batch = 15.5522s	
8001/28500 (epoch 14.037), train_loss = 1.43729570, grad/param norm = 1.6040e-01, time/batch = 15.6970s	
8002/28500 (epoch 14.039), train_loss = 1.26007576, grad/param norm = 1.7463e-01, time/batch = 15.2794s	
8003/28500 (epoch 14.040), train_loss = 1.29511556, grad/param norm = 1.5577e-01, time/batch = 15.4618s	
8004/28500 (epoch 14.042), train_loss = 1.22322526, grad/param norm = 1.6030e-01, time/batch = 15.6863s	
8005/28500 (epoch 14.044), train_loss = 1.15179542, grad/param norm = 1.7017e-01, time/batch = 15.4297s	
8006/28500 (epoch 14.046), train_loss = 1.36799857, grad/param norm = 1.6831e-01, time/batch = 15.3511s	
8007/28500 (epoch 14.047), train_loss = 1.27125149, grad/param norm = 1.7468e-01, time/batch = 15.2784s	
8008/28500 (epoch 14.049), train_loss = 1.17065843, grad/param norm = 1.6703e-01, time/batch = 15.5169s	
8009/28500 (epoch 14.051), train_loss = 1.11805576, grad/param norm = 1.6865e-01, time/batch = 15.5517s	
8010/28500 (epoch 14.053), train_loss = 1.17537889, grad/param norm = 1.7326e-01, time/batch = 15.3080s	
8011/28500 (epoch 14.054), train_loss = 1.26496754, grad/param norm = 1.7676e-01, time/batch = 15.3824s	
8012/28500 (epoch 14.056), train_loss = 1.02671964, grad/param norm = 1.3482e-01, time/batch = 15.3486s	
8013/28500 (epoch 14.058), train_loss = 1.03032563, grad/param norm = 1.4562e-01, time/batch = 15.1960s	
8014/28500 (epoch 14.060), train_loss = 1.24444957, grad/param norm = 1.6913e-01, time/batch = 15.2780s	
8015/28500 (epoch 14.061), train_loss = 1.16926595, grad/param norm = 1.7150e-01, time/batch = 15.4442s	
8016/28500 (epoch 14.063), train_loss = 1.24518256, grad/param norm = 1.6532e-01, time/batch = 15.4953s	
8017/28500 (epoch 14.065), train_loss = 1.28475724, grad/param norm = 1.7287e-01, time/batch = 15.6304s	
8018/28500 (epoch 14.067), train_loss = 1.09537159, grad/param norm = 1.3956e-01, time/batch = 15.3825s	
8019/28500 (epoch 14.068), train_loss = 1.12018619, grad/param norm = 1.5407e-01, time/batch = 15.2404s	
8020/28500 (epoch 14.070), train_loss = 1.20072955, grad/param norm = 1.6781e-01, time/batch = 15.2959s	
8021/28500 (epoch 14.072), train_loss = 1.37511302, grad/param norm = 1.8315e-01, time/batch = 15.0586s	
8022/28500 (epoch 14.074), train_loss = 1.19060964, grad/param norm = 1.5040e-01, time/batch = 15.3636s	
8023/28500 (epoch 14.075), train_loss = 1.15362965, grad/param norm = 1.4272e-01, time/batch = 15.5651s	
8024/28500 (epoch 14.077), train_loss = 1.21522234, grad/param norm = 1.5968e-01, time/batch = 15.3552s	
8025/28500 (epoch 14.079), train_loss = 1.13604077, grad/param norm = 1.4560e-01, time/batch = 15.2859s	
8026/28500 (epoch 14.081), train_loss = 1.28666190, grad/param norm = 1.7350e-01, time/batch = 15.3742s	
8027/28500 (epoch 14.082), train_loss = 1.20121661, grad/param norm = 1.7722e-01, time/batch = 15.3086s	
8028/28500 (epoch 14.084), train_loss = 1.21456913, grad/param norm = 1.6423e-01, time/batch = 15.4519s	
8029/28500 (epoch 14.086), train_loss = 1.13711432, grad/param norm = 1.6864e-01, time/batch = 15.5280s	
8030/28500 (epoch 14.088), train_loss = 1.03129993, grad/param norm = 1.5874e-01, time/batch = 15.5335s	
8031/28500 (epoch 14.089), train_loss = 1.27174636, grad/param norm = 1.5268e-01, time/batch = 15.6334s	
8032/28500 (epoch 14.091), train_loss = 1.05289079, grad/param norm = 1.5970e-01, time/batch = 15.3861s	
8033/28500 (epoch 14.093), train_loss = 1.20831144, grad/param norm = 1.5709e-01, time/batch = 15.3778s	
8034/28500 (epoch 14.095), train_loss = 1.09406153, grad/param norm = 1.4795e-01, time/batch = 15.3654s	
8035/28500 (epoch 14.096), train_loss = 1.29953036, grad/param norm = 1.6236e-01, time/batch = 15.3719s	
8036/28500 (epoch 14.098), train_loss = 1.25972649, grad/param norm = 1.7263e-01, time/batch = 15.4894s	
8037/28500 (epoch 14.100), train_loss = 1.11340736, grad/param norm = 1.4889e-01, time/batch = 15.2303s	
8038/28500 (epoch 14.102), train_loss = 1.29476585, grad/param norm = 1.6437e-01, time/batch = 15.2675s	
8039/28500 (epoch 14.104), train_loss = 1.14739291, grad/param norm = 1.7195e-01, time/batch = 15.5112s	
8040/28500 (epoch 14.105), train_loss = 1.25766282, grad/param norm = 1.6164e-01, time/batch = 15.4481s	
8041/28500 (epoch 14.107), train_loss = 1.05074272, grad/param norm = 1.5935e-01, time/batch = 15.5335s	
8042/28500 (epoch 14.109), train_loss = 1.02931849, grad/param norm = 1.5208e-01, time/batch = 15.7108s	
8043/28500 (epoch 14.111), train_loss = 1.13218366, grad/param norm = 1.6655e-01, time/batch = 15.5338s	
8044/28500 (epoch 14.112), train_loss = 1.24751796, grad/param norm = 1.7346e-01, time/batch = 15.5394s	
8045/28500 (epoch 14.114), train_loss = 1.13335770, grad/param norm = 1.5768e-01, time/batch = 15.1336s	
8046/28500 (epoch 14.116), train_loss = 1.32868001, grad/param norm = 1.5823e-01, time/batch = 15.3087s	
8047/28500 (epoch 14.118), train_loss = 1.00994616, grad/param norm = 1.5712e-01, time/batch = 15.4293s	
8048/28500 (epoch 14.119), train_loss = 1.20550340, grad/param norm = 1.7639e-01, time/batch = 15.6053s	
8049/28500 (epoch 14.121), train_loss = 1.36217488, grad/param norm = 1.8264e-01, time/batch = 15.2050s	
8050/28500 (epoch 14.123), train_loss = 1.22818094, grad/param norm = 1.6298e-01, time/batch = 15.5610s	
8051/28500 (epoch 14.125), train_loss = 1.18837594, grad/param norm = 1.6412e-01, time/batch = 15.5421s	
8052/28500 (epoch 14.126), train_loss = 1.14476175, grad/param norm = 1.4904e-01, time/batch = 15.3519s	
8053/28500 (epoch 14.128), train_loss = 1.12617686, grad/param norm = 1.5689e-01, time/batch = 15.1975s	
8054/28500 (epoch 14.130), train_loss = 1.03778082, grad/param norm = 1.5781e-01, time/batch = 15.3111s	
8055/28500 (epoch 14.132), train_loss = 1.22757832, grad/param norm = 1.6910e-01, time/batch = 27.6579s	
8056/28500 (epoch 14.133), train_loss = 1.21067415, grad/param norm = 1.6813e-01, time/batch = 15.2148s	
8057/28500 (epoch 14.135), train_loss = 1.14105947, grad/param norm = 1.4728e-01, time/batch = 15.1577s	
8058/28500 (epoch 14.137), train_loss = 1.10684944, grad/param norm = 1.5473e-01, time/batch = 15.4513s	
8059/28500 (epoch 14.139), train_loss = 1.12185105, grad/param norm = 1.4408e-01, time/batch = 15.2960s	
8060/28500 (epoch 14.140), train_loss = 1.20548452, grad/param norm = 1.4613e-01, time/batch = 15.2993s	
8061/28500 (epoch 14.142), train_loss = 1.15547483, grad/param norm = 1.6552e-01, time/batch = 15.2128s	
8062/28500 (epoch 14.144), train_loss = 1.07571511, grad/param norm = 1.5118e-01, time/batch = 15.6602s	
8063/28500 (epoch 14.146), train_loss = 1.09123085, grad/param norm = 1.4963e-01, time/batch = 15.5841s	
8064/28500 (epoch 14.147), train_loss = 0.99391634, grad/param norm = 1.4646e-01, time/batch = 15.3856s	
8065/28500 (epoch 14.149), train_loss = 0.99178851, grad/param norm = 1.3707e-01, time/batch = 15.4391s	
8066/28500 (epoch 14.151), train_loss = 1.02881720, grad/param norm = 1.3522e-01, time/batch = 15.3723s	
8067/28500 (epoch 14.153), train_loss = 1.16015731, grad/param norm = 1.5880e-01, time/batch = 15.4202s	
8068/28500 (epoch 14.154), train_loss = 1.05130505, grad/param norm = 1.5604e-01, time/batch = 15.5527s	
8069/28500 (epoch 14.156), train_loss = 1.27891005, grad/param norm = 1.5857e-01, time/batch = 15.3085s	
8070/28500 (epoch 14.158), train_loss = 1.12196317, grad/param norm = 1.5084e-01, time/batch = 15.2132s	
8071/28500 (epoch 14.160), train_loss = 1.05134408, grad/param norm = 1.5685e-01, time/batch = 15.1542s	
8072/28500 (epoch 14.161), train_loss = 1.12574251, grad/param norm = 1.7157e-01, time/batch = 15.2469s	
8073/28500 (epoch 14.163), train_loss = 0.99706173, grad/param norm = 1.6100e-01, time/batch = 15.6455s	
8074/28500 (epoch 14.165), train_loss = 1.33933937, grad/param norm = 1.5485e-01, time/batch = 15.3724s	
8075/28500 (epoch 14.167), train_loss = 1.40281692, grad/param norm = 1.8376e-01, time/batch = 15.4442s	
8076/28500 (epoch 14.168), train_loss = 1.26187671, grad/param norm = 1.8268e-01, time/batch = 15.5605s	
8077/28500 (epoch 14.170), train_loss = 1.27786884, grad/param norm = 2.0084e-01, time/batch = 15.4827s	
8078/28500 (epoch 14.172), train_loss = 1.15243860, grad/param norm = 1.6832e-01, time/batch = 15.2909s	
8079/28500 (epoch 14.174), train_loss = 1.29453363, grad/param norm = 1.8616e-01, time/batch = 15.3785s	
8080/28500 (epoch 14.175), train_loss = 1.14385577, grad/param norm = 1.4930e-01, time/batch = 15.3025s	
8081/28500 (epoch 14.177), train_loss = 1.23574449, grad/param norm = 1.8443e-01, time/batch = 15.3794s	
8082/28500 (epoch 14.179), train_loss = 1.13588903, grad/param norm = 1.7008e-01, time/batch = 15.3045s	
8083/28500 (epoch 14.181), train_loss = 1.20759324, grad/param norm = 1.6027e-01, time/batch = 15.2319s	
8084/28500 (epoch 14.182), train_loss = 1.15111463, grad/param norm = 1.5293e-01, time/batch = 15.5362s	
8085/28500 (epoch 14.184), train_loss = 1.37425593, grad/param norm = 1.9213e-01, time/batch = 15.5826s	
8086/28500 (epoch 14.186), train_loss = 1.26926856, grad/param norm = 1.7158e-01, time/batch = 15.4536s	
8087/28500 (epoch 14.188), train_loss = 1.17394601, grad/param norm = 1.5371e-01, time/batch = 15.2850s	
8088/28500 (epoch 14.189), train_loss = 1.20850492, grad/param norm = 1.6490e-01, time/batch = 15.2637s	
8089/28500 (epoch 14.191), train_loss = 1.38364820, grad/param norm = 1.7159e-01, time/batch = 15.2363s	
8090/28500 (epoch 14.193), train_loss = 1.23775831, grad/param norm = 1.8713e-01, time/batch = 15.0514s	
8091/28500 (epoch 14.195), train_loss = 1.31131664, grad/param norm = 1.7024e-01, time/batch = 15.1426s	
8092/28500 (epoch 14.196), train_loss = 1.23934690, grad/param norm = 1.6884e-01, time/batch = 15.0434s	
8093/28500 (epoch 14.198), train_loss = 1.17980129, grad/param norm = 1.6853e-01, time/batch = 15.2862s	
8094/28500 (epoch 14.200), train_loss = 1.19005257, grad/param norm = 1.5280e-01, time/batch = 15.0362s	
8095/28500 (epoch 14.202), train_loss = 1.17105085, grad/param norm = 1.6081e-01, time/batch = 15.5362s	
8096/28500 (epoch 14.204), train_loss = 1.10396608, grad/param norm = 1.4789e-01, time/batch = 15.2846s	
8097/28500 (epoch 14.205), train_loss = 1.13191259, grad/param norm = 1.6590e-01, time/batch = 15.3845s	
8098/28500 (epoch 14.207), train_loss = 1.08357996, grad/param norm = 1.6383e-01, time/batch = 15.2255s	
8099/28500 (epoch 14.209), train_loss = 1.16265186, grad/param norm = 1.5275e-01, time/batch = 15.4441s	
8100/28500 (epoch 14.211), train_loss = 1.03433632, grad/param norm = 1.6439e-01, time/batch = 15.2272s	
8101/28500 (epoch 14.212), train_loss = 1.02459830, grad/param norm = 1.4371e-01, time/batch = 15.5476s	
8102/28500 (epoch 14.214), train_loss = 1.18509683, grad/param norm = 1.7459e-01, time/batch = 15.3924s	
8103/28500 (epoch 14.216), train_loss = 1.03360131, grad/param norm = 1.4514e-01, time/batch = 15.1618s	
8104/28500 (epoch 14.218), train_loss = 1.30234584, grad/param norm = 1.6241e-01, time/batch = 15.3821s	
8105/28500 (epoch 14.219), train_loss = 1.21073511, grad/param norm = 1.8201e-01, time/batch = 15.5139s	
8106/28500 (epoch 14.221), train_loss = 1.05466874, grad/param norm = 1.6691e-01, time/batch = 15.4218s	
8107/28500 (epoch 14.223), train_loss = 1.27965550, grad/param norm = 1.6024e-01, time/batch = 15.6387s	
8108/28500 (epoch 14.225), train_loss = 1.29595287, grad/param norm = 1.6203e-01, time/batch = 15.6111s	
8109/28500 (epoch 14.226), train_loss = 1.12241163, grad/param norm = 1.4969e-01, time/batch = 15.5535s	
8110/28500 (epoch 14.228), train_loss = 1.22344825, grad/param norm = 1.4313e-01, time/batch = 15.4729s	
8111/28500 (epoch 14.230), train_loss = 1.27449817, grad/param norm = 1.5917e-01, time/batch = 15.3708s	
8112/28500 (epoch 14.232), train_loss = 1.22693760, grad/param norm = 1.5131e-01, time/batch = 15.3649s	
8113/28500 (epoch 14.233), train_loss = 1.20476081, grad/param norm = 1.6539e-01, time/batch = 15.1168s	
8114/28500 (epoch 14.235), train_loss = 1.12692870, grad/param norm = 1.5181e-01, time/batch = 15.0370s	
8115/28500 (epoch 14.237), train_loss = 1.01614961, grad/param norm = 1.4065e-01, time/batch = 15.2021s	
8116/28500 (epoch 14.239), train_loss = 1.08610626, grad/param norm = 1.3613e-01, time/batch = 15.3177s	
8117/28500 (epoch 14.240), train_loss = 1.03837330, grad/param norm = 1.5768e-01, time/batch = 15.4532s	
8118/28500 (epoch 14.242), train_loss = 1.21283777, grad/param norm = 1.6958e-01, time/batch = 15.2218s	
8119/28500 (epoch 14.244), train_loss = 1.22359458, grad/param norm = 1.5174e-01, time/batch = 15.3242s	
8120/28500 (epoch 14.246), train_loss = 1.27949079, grad/param norm = 1.7019e-01, time/batch = 15.6894s	
8121/28500 (epoch 14.247), train_loss = 1.36954900, grad/param norm = 1.7520e-01, time/batch = 15.3961s	
8122/28500 (epoch 14.249), train_loss = 1.17264924, grad/param norm = 1.5628e-01, time/batch = 15.4021s	
8123/28500 (epoch 14.251), train_loss = 1.06901828, grad/param norm = 1.4496e-01, time/batch = 15.6281s	
8124/28500 (epoch 14.253), train_loss = 1.36490252, grad/param norm = 1.9418e-01, time/batch = 15.2833s	
8125/28500 (epoch 14.254), train_loss = 1.30243888, grad/param norm = 1.6497e-01, time/batch = 15.1913s	
8126/28500 (epoch 14.256), train_loss = 1.11349030, grad/param norm = 1.5036e-01, time/batch = 15.0428s	
8127/28500 (epoch 14.258), train_loss = 1.16499880, grad/param norm = 1.6570e-01, time/batch = 15.1343s	
8128/28500 (epoch 14.260), train_loss = 1.10875521, grad/param norm = 1.4318e-01, time/batch = 15.4924s	
8129/28500 (epoch 14.261), train_loss = 1.11554898, grad/param norm = 1.4994e-01, time/batch = 15.5565s	
8130/28500 (epoch 14.263), train_loss = 1.29609942, grad/param norm = 1.8395e-01, time/batch = 15.5223s	
8131/28500 (epoch 14.265), train_loss = 1.17849399, grad/param norm = 1.5396e-01, time/batch = 15.5340s	
8132/28500 (epoch 14.267), train_loss = 1.33369696, grad/param norm = 1.6474e-01, time/batch = 15.2823s	
8133/28500 (epoch 14.268), train_loss = 1.24279418, grad/param norm = 1.4968e-01, time/batch = 15.1326s	
8134/28500 (epoch 14.270), train_loss = 1.19881394, grad/param norm = 1.7172e-01, time/batch = 15.3599s	
8135/28500 (epoch 14.272), train_loss = 1.14545923, grad/param norm = 1.5727e-01, time/batch = 15.2387s	
8136/28500 (epoch 14.274), train_loss = 1.28984151, grad/param norm = 1.6143e-01, time/batch = 15.3763s	
8137/28500 (epoch 14.275), train_loss = 1.21210607, grad/param norm = 1.5465e-01, time/batch = 15.4764s	
8138/28500 (epoch 14.277), train_loss = 1.16782851, grad/param norm = 1.5565e-01, time/batch = 15.4659s	
8139/28500 (epoch 14.279), train_loss = 1.23051224, grad/param norm = 1.8348e-01, time/batch = 15.4448s	
8140/28500 (epoch 14.281), train_loss = 1.25596531, grad/param norm = 1.7884e-01, time/batch = 15.5334s	
8141/28500 (epoch 14.282), train_loss = 1.07753294, grad/param norm = 1.4384e-01, time/batch = 15.3895s	
8142/28500 (epoch 14.284), train_loss = 1.19720697, grad/param norm = 1.6807e-01, time/batch = 15.3021s	
8143/28500 (epoch 14.286), train_loss = 1.27988629, grad/param norm = 1.7174e-01, time/batch = 15.4165s	
8144/28500 (epoch 14.288), train_loss = 1.20946379, grad/param norm = 1.5993e-01, time/batch = 15.3981s	
8145/28500 (epoch 14.289), train_loss = 1.27527012, grad/param norm = 1.8012e-01, time/batch = 15.0394s	
8146/28500 (epoch 14.291), train_loss = 1.16097238, grad/param norm = 1.4680e-01, time/batch = 15.3183s	
8147/28500 (epoch 14.293), train_loss = 1.12495025, grad/param norm = 1.5445e-01, time/batch = 15.5332s	
8148/28500 (epoch 14.295), train_loss = 1.04593824, grad/param norm = 1.4620e-01, time/batch = 15.2216s	
8149/28500 (epoch 14.296), train_loss = 1.06928927, grad/param norm = 1.4532e-01, time/batch = 15.3094s	
8150/28500 (epoch 14.298), train_loss = 1.22164562, grad/param norm = 1.5370e-01, time/batch = 15.3972s	
8151/28500 (epoch 14.300), train_loss = 1.08105645, grad/param norm = 1.4626e-01, time/batch = 15.7400s	
8152/28500 (epoch 14.302), train_loss = 1.06921052, grad/param norm = 1.5098e-01, time/batch = 15.3042s	
8153/28500 (epoch 14.304), train_loss = 1.16284582, grad/param norm = 1.4858e-01, time/batch = 15.4418s	
8154/28500 (epoch 14.305), train_loss = 1.23668179, grad/param norm = 1.6277e-01, time/batch = 15.3065s	
8155/28500 (epoch 14.307), train_loss = 1.18738612, grad/param norm = 1.7189e-01, time/batch = 15.4045s	
8156/28500 (epoch 14.309), train_loss = 1.15559205, grad/param norm = 1.6145e-01, time/batch = 15.2424s	
8157/28500 (epoch 14.311), train_loss = 1.20350854, grad/param norm = 1.5852e-01, time/batch = 15.3858s	
8158/28500 (epoch 14.312), train_loss = 1.11977693, grad/param norm = 1.4660e-01, time/batch = 15.5165s	
8159/28500 (epoch 14.314), train_loss = 1.24985193, grad/param norm = 1.7454e-01, time/batch = 15.5416s	
8160/28500 (epoch 14.316), train_loss = 1.18865963, grad/param norm = 1.5182e-01, time/batch = 15.3797s	
8161/28500 (epoch 14.318), train_loss = 1.24540029, grad/param norm = 1.6362e-01, time/batch = 15.2210s	
8162/28500 (epoch 14.319), train_loss = 1.14144045, grad/param norm = 1.5877e-01, time/batch = 15.2214s	
8163/28500 (epoch 14.321), train_loss = 1.14735426, grad/param norm = 1.8242e-01, time/batch = 15.3696s	
8164/28500 (epoch 14.323), train_loss = 1.13119019, grad/param norm = 1.6359e-01, time/batch = 15.1987s	
8165/28500 (epoch 14.325), train_loss = 1.31064827, grad/param norm = 1.7310e-01, time/batch = 14.8954s	
8166/28500 (epoch 14.326), train_loss = 1.16285937, grad/param norm = 1.6121e-01, time/batch = 15.1251s	
8167/28500 (epoch 14.328), train_loss = 0.97786801, grad/param norm = 1.5084e-01, time/batch = 15.1879s	
8168/28500 (epoch 14.330), train_loss = 1.08306509, grad/param norm = 1.5402e-01, time/batch = 15.1590s	
8169/28500 (epoch 14.332), train_loss = 1.15597006, grad/param norm = 1.4403e-01, time/batch = 15.2557s	
8170/28500 (epoch 14.333), train_loss = 0.98415438, grad/param norm = 1.4651e-01, time/batch = 15.4302s	
8171/28500 (epoch 14.335), train_loss = 1.03243850, grad/param norm = 1.4352e-01, time/batch = 15.6550s	
8172/28500 (epoch 14.337), train_loss = 1.08881003, grad/param norm = 1.4914e-01, time/batch = 15.3668s	
8173/28500 (epoch 14.339), train_loss = 1.01134246, grad/param norm = 1.4364e-01, time/batch = 15.3157s	
8174/28500 (epoch 14.340), train_loss = 1.20654825, grad/param norm = 1.6394e-01, time/batch = 15.3515s	
8175/28500 (epoch 14.342), train_loss = 1.13574403, grad/param norm = 1.6631e-01, time/batch = 15.3293s	
8176/28500 (epoch 14.344), train_loss = 1.10385018, grad/param norm = 1.6597e-01, time/batch = 15.5004s	
8177/28500 (epoch 14.346), train_loss = 0.92886279, grad/param norm = 1.2991e-01, time/batch = 15.7669s	
8178/28500 (epoch 14.347), train_loss = 1.13876941, grad/param norm = 1.4625e-01, time/batch = 15.3304s	
8179/28500 (epoch 14.349), train_loss = 1.09285451, grad/param norm = 1.4786e-01, time/batch = 15.4663s	
8180/28500 (epoch 14.351), train_loss = 1.06366428, grad/param norm = 1.4989e-01, time/batch = 15.4625s	
8181/28500 (epoch 14.353), train_loss = 1.21514524, grad/param norm = 1.7209e-01, time/batch = 15.3791s	
8182/28500 (epoch 14.354), train_loss = 1.02088463, grad/param norm = 1.5477e-01, time/batch = 15.3901s	
8183/28500 (epoch 14.356), train_loss = 1.04383514, grad/param norm = 1.4369e-01, time/batch = 15.3259s	
8184/28500 (epoch 14.358), train_loss = 1.15334310, grad/param norm = 1.4674e-01, time/batch = 15.3524s	
8185/28500 (epoch 14.360), train_loss = 1.16532194, grad/param norm = 1.6820e-01, time/batch = 15.1873s	
8186/28500 (epoch 14.361), train_loss = 1.07536580, grad/param norm = 1.5106e-01, time/batch = 15.4946s	
8187/28500 (epoch 14.363), train_loss = 1.02566079, grad/param norm = 1.3848e-01, time/batch = 15.4469s	
8188/28500 (epoch 14.365), train_loss = 1.11574816, grad/param norm = 1.6379e-01, time/batch = 15.3923s	
8189/28500 (epoch 14.367), train_loss = 1.13975029, grad/param norm = 1.6009e-01, time/batch = 15.4685s	
8190/28500 (epoch 14.368), train_loss = 1.11176089, grad/param norm = 1.5170e-01, time/batch = 15.4222s	
8191/28500 (epoch 14.370), train_loss = 1.14496700, grad/param norm = 1.5175e-01, time/batch = 15.2018s	
8192/28500 (epoch 14.372), train_loss = 1.00058524, grad/param norm = 1.5043e-01, time/batch = 15.5216s	
8193/28500 (epoch 14.374), train_loss = 1.12067464, grad/param norm = 1.5460e-01, time/batch = 15.4244s	
8194/28500 (epoch 14.375), train_loss = 1.29436271, grad/param norm = 1.6589e-01, time/batch = 15.3702s	
8195/28500 (epoch 14.377), train_loss = 1.05587658, grad/param norm = 1.5554e-01, time/batch = 15.4014s	
8196/28500 (epoch 14.379), train_loss = 0.89672877, grad/param norm = 1.3942e-01, time/batch = 15.4141s	
8197/28500 (epoch 14.381), train_loss = 1.09773491, grad/param norm = 1.3755e-01, time/batch = 15.2063s	
8198/28500 (epoch 14.382), train_loss = 1.08119816, grad/param norm = 1.5704e-01, time/batch = 15.2868s	
8199/28500 (epoch 14.384), train_loss = 1.02108635, grad/param norm = 1.4426e-01, time/batch = 15.3045s	
8200/28500 (epoch 14.386), train_loss = 1.00849250, grad/param norm = 1.5409e-01, time/batch = 15.3529s	
8201/28500 (epoch 14.388), train_loss = 1.21988568, grad/param norm = 1.5976e-01, time/batch = 15.6198s	
8202/28500 (epoch 14.389), train_loss = 1.04390260, grad/param norm = 1.5049e-01, time/batch = 15.5444s	
8203/28500 (epoch 14.391), train_loss = 1.04850884, grad/param norm = 1.4653e-01, time/batch = 15.5456s	
8204/28500 (epoch 14.393), train_loss = 1.01336734, grad/param norm = 1.5813e-01, time/batch = 15.4141s	
8205/28500 (epoch 14.395), train_loss = 1.30885277, grad/param norm = 1.6323e-01, time/batch = 15.3614s	
8206/28500 (epoch 14.396), train_loss = 1.26253186, grad/param norm = 1.7541e-01, time/batch = 15.3458s	
8207/28500 (epoch 14.398), train_loss = 0.94364526, grad/param norm = 1.7341e-01, time/batch = 15.4219s	
8208/28500 (epoch 14.400), train_loss = 1.15962960, grad/param norm = 1.7284e-01, time/batch = 15.1178s	
8209/28500 (epoch 14.402), train_loss = 1.17407971, grad/param norm = 1.6092e-01, time/batch = 15.3137s	
8210/28500 (epoch 14.404), train_loss = 1.25900793, grad/param norm = 1.8043e-01, time/batch = 15.4945s	
8211/28500 (epoch 14.405), train_loss = 1.26525551, grad/param norm = 1.6238e-01, time/batch = 15.5178s	
8212/28500 (epoch 14.407), train_loss = 1.15943892, grad/param norm = 1.5206e-01, time/batch = 15.1757s	
8213/28500 (epoch 14.409), train_loss = 1.17560215, grad/param norm = 1.6172e-01, time/batch = 15.2482s	
8214/28500 (epoch 14.411), train_loss = 1.28077541, grad/param norm = 1.6169e-01, time/batch = 15.1961s	
8215/28500 (epoch 14.412), train_loss = 1.28404405, grad/param norm = 1.7631e-01, time/batch = 15.5504s	
8216/28500 (epoch 14.414), train_loss = 1.17956671, grad/param norm = 1.6949e-01, time/batch = 15.6175s	
8217/28500 (epoch 14.416), train_loss = 1.08627027, grad/param norm = 1.6176e-01, time/batch = 15.5973s	
8218/28500 (epoch 14.418), train_loss = 1.15603624, grad/param norm = 1.4655e-01, time/batch = 15.0907s	
8219/28500 (epoch 14.419), train_loss = 1.29965988, grad/param norm = 1.7657e-01, time/batch = 15.4603s	
8220/28500 (epoch 14.421), train_loss = 1.22994631, grad/param norm = 1.5975e-01, time/batch = 15.0694s	
8221/28500 (epoch 14.423), train_loss = 1.26519839, grad/param norm = 1.7310e-01, time/batch = 15.2673s	
8222/28500 (epoch 14.425), train_loss = 1.19789789, grad/param norm = 1.6290e-01, time/batch = 15.2577s	
8223/28500 (epoch 14.426), train_loss = 1.14200675, grad/param norm = 1.6653e-01, time/batch = 15.4211s	
8224/28500 (epoch 14.428), train_loss = 1.37115581, grad/param norm = 1.7198e-01, time/batch = 15.1249s	
8225/28500 (epoch 14.430), train_loss = 1.28984669, grad/param norm = 1.6109e-01, time/batch = 15.2675s	
8226/28500 (epoch 14.432), train_loss = 1.20654397, grad/param norm = 1.5222e-01, time/batch = 15.1785s	
8227/28500 (epoch 14.433), train_loss = 1.22402662, grad/param norm = 1.7261e-01, time/batch = 15.2910s	
8228/28500 (epoch 14.435), train_loss = 1.16179998, grad/param norm = 1.7407e-01, time/batch = 15.4958s	
8229/28500 (epoch 14.437), train_loss = 1.02924407, grad/param norm = 1.3715e-01, time/batch = 15.6671s	
8230/28500 (epoch 14.439), train_loss = 1.08343287, grad/param norm = 1.4194e-01, time/batch = 15.6283s	
8231/28500 (epoch 14.440), train_loss = 1.34875430, grad/param norm = 1.6551e-01, time/batch = 15.6174s	
8232/28500 (epoch 14.442), train_loss = 1.07788255, grad/param norm = 1.6135e-01, time/batch = 15.5252s	
8233/28500 (epoch 14.444), train_loss = 1.00426616, grad/param norm = 1.4214e-01, time/batch = 15.2687s	
8234/28500 (epoch 14.446), train_loss = 0.94895656, grad/param norm = 1.4421e-01, time/batch = 15.3878s	
8235/28500 (epoch 14.447), train_loss = 0.98665659, grad/param norm = 1.4783e-01, time/batch = 15.2887s	
8236/28500 (epoch 14.449), train_loss = 1.07441374, grad/param norm = 1.4574e-01, time/batch = 15.4859s	
8237/28500 (epoch 14.451), train_loss = 1.12452385, grad/param norm = 1.5571e-01, time/batch = 15.3587s	
8238/28500 (epoch 14.453), train_loss = 1.12687611, grad/param norm = 1.5229e-01, time/batch = 15.2966s	
8239/28500 (epoch 14.454), train_loss = 1.08466035, grad/param norm = 1.4442e-01, time/batch = 15.4700s	
8240/28500 (epoch 14.456), train_loss = 1.19557703, grad/param norm = 1.6427e-01, time/batch = 15.5249s	
8241/28500 (epoch 14.458), train_loss = 1.10090988, grad/param norm = 1.5594e-01, time/batch = 15.4637s	
8242/28500 (epoch 14.460), train_loss = 1.19512685, grad/param norm = 1.5415e-01, time/batch = 15.3775s	
8243/28500 (epoch 14.461), train_loss = 1.09136678, grad/param norm = 1.5890e-01, time/batch = 15.2261s	
8244/28500 (epoch 14.463), train_loss = 1.02622963, grad/param norm = 1.3424e-01, time/batch = 15.4941s	
8245/28500 (epoch 14.465), train_loss = 0.99593859, grad/param norm = 1.7061e-01, time/batch = 15.4538s	
8246/28500 (epoch 14.467), train_loss = 1.15513414, grad/param norm = 1.5111e-01, time/batch = 15.3606s	
8247/28500 (epoch 14.468), train_loss = 1.01424245, grad/param norm = 1.2949e-01, time/batch = 15.4451s	
8248/28500 (epoch 14.470), train_loss = 1.07666763, grad/param norm = 1.5239e-01, time/batch = 15.5873s	
8249/28500 (epoch 14.472), train_loss = 1.10413493, grad/param norm = 1.5930e-01, time/batch = 15.4849s	
8250/28500 (epoch 14.474), train_loss = 1.36936955, grad/param norm = 1.8011e-01, time/batch = 15.6111s	
8251/28500 (epoch 14.475), train_loss = 1.04176429, grad/param norm = 1.4159e-01, time/batch = 15.6203s	
8252/28500 (epoch 14.477), train_loss = 1.12449952, grad/param norm = 1.4926e-01, time/batch = 15.2739s	
8253/28500 (epoch 14.479), train_loss = 1.19837323, grad/param norm = 1.5586e-01, time/batch = 15.1358s	
8254/28500 (epoch 14.481), train_loss = 1.12932410, grad/param norm = 1.5947e-01, time/batch = 15.1185s	
8255/28500 (epoch 14.482), train_loss = 1.03747363, grad/param norm = 1.5015e-01, time/batch = 15.3644s	
8256/28500 (epoch 14.484), train_loss = 1.03193452, grad/param norm = 1.4763e-01, time/batch = 15.2740s	
8257/28500 (epoch 14.486), train_loss = 0.94893176, grad/param norm = 1.7108e-01, time/batch = 15.5677s	
8258/28500 (epoch 14.488), train_loss = 1.16664072, grad/param norm = 1.5102e-01, time/batch = 15.1491s	
8259/28500 (epoch 14.489), train_loss = 1.22533729, grad/param norm = 1.5543e-01, time/batch = 15.2294s	
8260/28500 (epoch 14.491), train_loss = 1.09603304, grad/param norm = 1.5552e-01, time/batch = 15.0453s	
8261/28500 (epoch 14.493), train_loss = 1.08053283, grad/param norm = 1.5425e-01, time/batch = 15.4270s	
8262/28500 (epoch 14.495), train_loss = 1.09155036, grad/param norm = 1.4525e-01, time/batch = 15.4357s	
8263/28500 (epoch 14.496), train_loss = 1.09889357, grad/param norm = 1.6292e-01, time/batch = 15.3343s	
8264/28500 (epoch 14.498), train_loss = 1.18989430, grad/param norm = 1.6353e-01, time/batch = 15.2253s	
8265/28500 (epoch 14.500), train_loss = 1.09769390, grad/param norm = 1.5105e-01, time/batch = 15.1146s	
8266/28500 (epoch 14.502), train_loss = 1.22690089, grad/param norm = 1.5659e-01, time/batch = 15.1851s	
8267/28500 (epoch 14.504), train_loss = 1.18189729, grad/param norm = 1.6361e-01, time/batch = 15.5861s	
8268/28500 (epoch 14.505), train_loss = 1.04654104, grad/param norm = 1.4447e-01, time/batch = 15.6168s	
8269/28500 (epoch 14.507), train_loss = 1.26320128, grad/param norm = 1.7532e-01, time/batch = 14.9832s	
8270/28500 (epoch 14.509), train_loss = 1.13561322, grad/param norm = 1.5409e-01, time/batch = 15.1498s	
8271/28500 (epoch 14.511), train_loss = 1.13054210, grad/param norm = 1.6066e-01, time/batch = 15.3734s	
8272/28500 (epoch 14.512), train_loss = 1.13640495, grad/param norm = 1.4589e-01, time/batch = 15.5330s	
8273/28500 (epoch 14.514), train_loss = 1.03870830, grad/param norm = 1.4916e-01, time/batch = 15.5990s	
8274/28500 (epoch 14.516), train_loss = 1.05989619, grad/param norm = 1.4050e-01, time/batch = 15.5357s	
8275/28500 (epoch 14.518), train_loss = 1.16692145, grad/param norm = 1.6096e-01, time/batch = 15.3697s	
8276/28500 (epoch 14.519), train_loss = 1.20743509, grad/param norm = 1.5437e-01, time/batch = 15.5512s	
8277/28500 (epoch 14.521), train_loss = 1.29543649, grad/param norm = 1.7418e-01, time/batch = 15.5812s	
8278/28500 (epoch 14.523), train_loss = 1.19429080, grad/param norm = 1.7113e-01, time/batch = 15.6448s	
8279/28500 (epoch 14.525), train_loss = 1.23532364, grad/param norm = 1.6693e-01, time/batch = 15.3659s	
8280/28500 (epoch 14.526), train_loss = 1.20528921, grad/param norm = 1.6530e-01, time/batch = 15.4398s	
8281/28500 (epoch 14.528), train_loss = 1.22241563, grad/param norm = 1.6217e-01, time/batch = 15.3774s	
8282/28500 (epoch 14.530), train_loss = 1.26032175, grad/param norm = 1.5613e-01, time/batch = 15.3925s	
8283/28500 (epoch 14.532), train_loss = 1.09082246, grad/param norm = 1.5401e-01, time/batch = 15.3154s	
8284/28500 (epoch 14.533), train_loss = 1.21875496, grad/param norm = 1.4712e-01, time/batch = 15.1834s	
8285/28500 (epoch 14.535), train_loss = 0.97260279, grad/param norm = 1.4457e-01, time/batch = 15.0391s	
8286/28500 (epoch 14.537), train_loss = 0.98498444, grad/param norm = 1.4818e-01, time/batch = 15.3858s	
8287/28500 (epoch 14.539), train_loss = 1.00039727, grad/param norm = 1.5512e-01, time/batch = 27.2732s	
8288/28500 (epoch 14.540), train_loss = 1.14793217, grad/param norm = 1.4995e-01, time/batch = 15.4884s	
8289/28500 (epoch 14.542), train_loss = 1.26152147, grad/param norm = 1.6850e-01, time/batch = 15.2609s	
8290/28500 (epoch 14.544), train_loss = 1.29945763, grad/param norm = 1.6678e-01, time/batch = 15.3741s	
8291/28500 (epoch 14.546), train_loss = 1.13929229, grad/param norm = 1.6180e-01, time/batch = 15.4594s	
8292/28500 (epoch 14.547), train_loss = 1.14934953, grad/param norm = 1.5858e-01, time/batch = 15.6158s	
8293/28500 (epoch 14.549), train_loss = 0.97455967, grad/param norm = 1.3315e-01, time/batch = 15.4554s	
8294/28500 (epoch 14.551), train_loss = 1.18847014, grad/param norm = 1.8192e-01, time/batch = 15.4430s	
8295/28500 (epoch 14.553), train_loss = 1.34937820, grad/param norm = 1.8767e-01, time/batch = 15.3996s	
8296/28500 (epoch 14.554), train_loss = 1.11000220, grad/param norm = 1.5138e-01, time/batch = 15.5263s	
8297/28500 (epoch 14.556), train_loss = 1.16870906, grad/param norm = 1.6885e-01, time/batch = 15.5123s	
8298/28500 (epoch 14.558), train_loss = 1.17258957, grad/param norm = 1.4754e-01, time/batch = 15.4635s	
8299/28500 (epoch 14.560), train_loss = 1.17466311, grad/param norm = 1.6650e-01, time/batch = 15.2279s	
8300/28500 (epoch 14.561), train_loss = 1.22692865, grad/param norm = 1.7437e-01, time/batch = 15.2302s	
8301/28500 (epoch 14.563), train_loss = 1.34557441, grad/param norm = 1.7725e-01, time/batch = 15.5135s	
8302/28500 (epoch 14.565), train_loss = 1.12465220, grad/param norm = 1.5685e-01, time/batch = 15.4149s	
8303/28500 (epoch 14.567), train_loss = 1.01175934, grad/param norm = 1.5155e-01, time/batch = 15.4629s	
8304/28500 (epoch 14.568), train_loss = 1.17703681, grad/param norm = 1.5819e-01, time/batch = 15.1241s	
8305/28500 (epoch 14.570), train_loss = 1.10644912, grad/param norm = 1.5369e-01, time/batch = 15.4347s	
8306/28500 (epoch 14.572), train_loss = 1.08751765, grad/param norm = 1.5026e-01, time/batch = 15.5375s	
8307/28500 (epoch 14.574), train_loss = 1.09464154, grad/param norm = 1.5569e-01, time/batch = 15.3076s	
8308/28500 (epoch 14.575), train_loss = 1.10433307, grad/param norm = 1.4753e-01, time/batch = 15.2958s	
8309/28500 (epoch 14.577), train_loss = 1.16768384, grad/param norm = 1.4764e-01, time/batch = 15.4289s	
8310/28500 (epoch 14.579), train_loss = 1.21437569, grad/param norm = 1.6398e-01, time/batch = 15.3633s	
8311/28500 (epoch 14.581), train_loss = 1.09452428, grad/param norm = 1.7227e-01, time/batch = 15.4713s	
8312/28500 (epoch 14.582), train_loss = 1.24447450, grad/param norm = 1.5994e-01, time/batch = 15.3780s	
8313/28500 (epoch 14.584), train_loss = 1.10054498, grad/param norm = 1.5860e-01, time/batch = 15.4321s	
8314/28500 (epoch 14.586), train_loss = 1.04839770, grad/param norm = 1.3991e-01, time/batch = 15.1279s	
8315/28500 (epoch 14.588), train_loss = 1.04188941, grad/param norm = 1.4302e-01, time/batch = 15.2248s	
8316/28500 (epoch 14.589), train_loss = 1.18829998, grad/param norm = 1.6728e-01, time/batch = 14.9778s	
8317/28500 (epoch 14.591), train_loss = 1.18489132, grad/param norm = 1.4687e-01, time/batch = 15.3728s	
8318/28500 (epoch 14.593), train_loss = 1.08424933, grad/param norm = 1.3977e-01, time/batch = 15.5999s	
8319/28500 (epoch 14.595), train_loss = 1.37769629, grad/param norm = 1.8556e-01, time/batch = 15.3972s	
8320/28500 (epoch 14.596), train_loss = 1.36505294, grad/param norm = 1.8654e-01, time/batch = 15.3069s	
8321/28500 (epoch 14.598), train_loss = 1.16038354, grad/param norm = 1.5304e-01, time/batch = 15.3699s	
8322/28500 (epoch 14.600), train_loss = 1.16904355, grad/param norm = 1.7510e-01, time/batch = 15.4254s	
8323/28500 (epoch 14.602), train_loss = 1.26804474, grad/param norm = 1.6537e-01, time/batch = 15.3056s	
8324/28500 (epoch 14.604), train_loss = 1.24014811, grad/param norm = 1.6613e-01, time/batch = 15.3480s	
8325/28500 (epoch 14.605), train_loss = 1.18121821, grad/param norm = 1.6536e-01, time/batch = 15.6691s	
8326/28500 (epoch 14.607), train_loss = 1.23410017, grad/param norm = 1.4853e-01, time/batch = 15.4460s	
8327/28500 (epoch 14.609), train_loss = 1.15165048, grad/param norm = 1.6078e-01, time/batch = 15.6257s	
8328/28500 (epoch 14.611), train_loss = 1.15985567, grad/param norm = 1.5444e-01, time/batch = 15.5901s	
8329/28500 (epoch 14.612), train_loss = 1.20275349, grad/param norm = 1.6538e-01, time/batch = 15.4614s	
8330/28500 (epoch 14.614), train_loss = 1.18207652, grad/param norm = 1.6208e-01, time/batch = 15.0593s	
8331/28500 (epoch 14.616), train_loss = 1.09063117, grad/param norm = 1.5766e-01, time/batch = 15.6046s	
8332/28500 (epoch 14.618), train_loss = 1.09752262, grad/param norm = 1.4995e-01, time/batch = 15.4506s	
8333/28500 (epoch 14.619), train_loss = 1.33992875, grad/param norm = 1.7360e-01, time/batch = 15.1284s	
8334/28500 (epoch 14.621), train_loss = 0.95079305, grad/param norm = 1.3633e-01, time/batch = 15.2387s	
8335/28500 (epoch 14.623), train_loss = 1.25474390, grad/param norm = 1.6526e-01, time/batch = 15.2143s	
8336/28500 (epoch 14.625), train_loss = 1.00720728, grad/param norm = 1.5321e-01, time/batch = 15.4606s	
8337/28500 (epoch 14.626), train_loss = 0.88277027, grad/param norm = 1.2869e-01, time/batch = 15.4527s	
8338/28500 (epoch 14.628), train_loss = 1.06897185, grad/param norm = 1.4930e-01, time/batch = 15.4620s	
8339/28500 (epoch 14.630), train_loss = 0.98836008, grad/param norm = 1.4196e-01, time/batch = 15.2729s	
8340/28500 (epoch 14.632), train_loss = 1.21872199, grad/param norm = 1.5625e-01, time/batch = 15.0499s	
8341/28500 (epoch 14.633), train_loss = 1.27930631, grad/param norm = 1.5575e-01, time/batch = 15.5532s	
8342/28500 (epoch 14.635), train_loss = 1.31295466, grad/param norm = 1.7242e-01, time/batch = 15.2448s	
8343/28500 (epoch 14.637), train_loss = 1.14975787, grad/param norm = 1.5087e-01, time/batch = 15.3778s	
8344/28500 (epoch 14.639), train_loss = 1.01348264, grad/param norm = 1.4061e-01, time/batch = 15.3503s	
8345/28500 (epoch 14.640), train_loss = 1.04526969, grad/param norm = 1.4445e-01, time/batch = 15.5209s	
8346/28500 (epoch 14.642), train_loss = 1.15074725, grad/param norm = 1.4935e-01, time/batch = 15.1368s	
8347/28500 (epoch 14.644), train_loss = 1.21347691, grad/param norm = 1.4452e-01, time/batch = 15.1016s	
8348/28500 (epoch 14.646), train_loss = 1.02345877, grad/param norm = 1.3675e-01, time/batch = 15.4993s	
8349/28500 (epoch 14.647), train_loss = 1.03920460, grad/param norm = 1.4714e-01, time/batch = 15.4863s	
8350/28500 (epoch 14.649), train_loss = 1.02519064, grad/param norm = 1.5479e-01, time/batch = 15.3411s	
8351/28500 (epoch 14.651), train_loss = 0.99353296, grad/param norm = 1.4375e-01, time/batch = 15.3341s	
8352/28500 (epoch 14.653), train_loss = 1.01232543, grad/param norm = 1.4255e-01, time/batch = 15.6536s	
8353/28500 (epoch 14.654), train_loss = 1.12323557, grad/param norm = 1.5431e-01, time/batch = 15.4268s	
8354/28500 (epoch 14.656), train_loss = 1.05707103, grad/param norm = 1.6238e-01, time/batch = 15.2899s	
8355/28500 (epoch 14.658), train_loss = 1.14257706, grad/param norm = 1.6086e-01, time/batch = 15.3193s	
8356/28500 (epoch 14.660), train_loss = 1.12588376, grad/param norm = 1.4172e-01, time/batch = 15.4354s	
8357/28500 (epoch 14.661), train_loss = 1.29085007, grad/param norm = 1.6844e-01, time/batch = 15.2961s	
8358/28500 (epoch 14.663), train_loss = 1.32715979, grad/param norm = 1.6882e-01, time/batch = 15.2906s	
8359/28500 (epoch 14.665), train_loss = 1.11436465, grad/param norm = 1.4523e-01, time/batch = 15.2682s	
8360/28500 (epoch 14.667), train_loss = 1.14046359, grad/param norm = 1.6101e-01, time/batch = 15.2809s	
8361/28500 (epoch 14.668), train_loss = 1.11837871, grad/param norm = 1.4895e-01, time/batch = 15.6374s	
8362/28500 (epoch 14.670), train_loss = 1.14704343, grad/param norm = 1.6115e-01, time/batch = 15.4752s	
8363/28500 (epoch 14.672), train_loss = 1.09107201, grad/param norm = 1.4923e-01, time/batch = 15.3508s	
8364/28500 (epoch 14.674), train_loss = 0.93801367, grad/param norm = 1.4270e-01, time/batch = 15.4343s	
8365/28500 (epoch 14.675), train_loss = 0.99212316, grad/param norm = 1.5257e-01, time/batch = 15.2892s	
8366/28500 (epoch 14.677), train_loss = 1.11348493, grad/param norm = 1.4830e-01, time/batch = 15.2627s	
8367/28500 (epoch 14.679), train_loss = 1.08583303, grad/param norm = 1.5482e-01, time/batch = 15.1868s	
8368/28500 (epoch 14.681), train_loss = 1.21172140, grad/param norm = 1.5698e-01, time/batch = 15.7153s	
8369/28500 (epoch 14.682), train_loss = 1.09230393, grad/param norm = 1.5287e-01, time/batch = 15.5208s	
8370/28500 (epoch 14.684), train_loss = 1.19665818, grad/param norm = 1.6358e-01, time/batch = 15.5407s	
8371/28500 (epoch 14.686), train_loss = 1.07047178, grad/param norm = 1.6014e-01, time/batch = 15.3650s	
8372/28500 (epoch 14.688), train_loss = 1.00630022, grad/param norm = 1.2988e-01, time/batch = 15.2993s	
8373/28500 (epoch 14.689), train_loss = 1.12909041, grad/param norm = 1.4792e-01, time/batch = 15.3031s	
8374/28500 (epoch 14.691), train_loss = 1.20430540, grad/param norm = 1.8210e-01, time/batch = 15.1691s	
8375/28500 (epoch 14.693), train_loss = 1.08728319, grad/param norm = 1.5585e-01, time/batch = 15.3861s	
8376/28500 (epoch 14.695), train_loss = 0.93921655, grad/param norm = 1.7003e-01, time/batch = 15.3824s	
8377/28500 (epoch 14.696), train_loss = 1.09911640, grad/param norm = 1.6056e-01, time/batch = 15.0978s	
8378/28500 (epoch 14.698), train_loss = 1.11141896, grad/param norm = 1.5287e-01, time/batch = 15.1435s	
8379/28500 (epoch 14.700), train_loss = 1.17267756, grad/param norm = 1.5916e-01, time/batch = 15.0543s	
8380/28500 (epoch 14.702), train_loss = 1.21380002, grad/param norm = 1.6892e-01, time/batch = 15.6170s	
8381/28500 (epoch 14.704), train_loss = 1.17909955, grad/param norm = 1.6158e-01, time/batch = 15.6864s	
8382/28500 (epoch 14.705), train_loss = 1.25107683, grad/param norm = 1.9056e-01, time/batch = 15.2534s	
8383/28500 (epoch 14.707), train_loss = 1.08895440, grad/param norm = 1.5822e-01, time/batch = 15.5292s	
8384/28500 (epoch 14.709), train_loss = 1.25211763, grad/param norm = 1.6327e-01, time/batch = 15.2873s	
8385/28500 (epoch 14.711), train_loss = 1.05169780, grad/param norm = 1.6631e-01, time/batch = 15.1180s	
8386/28500 (epoch 14.712), train_loss = 1.18801719, grad/param norm = 1.6755e-01, time/batch = 15.0537s	
8387/28500 (epoch 14.714), train_loss = 1.24510497, grad/param norm = 1.6948e-01, time/batch = 15.4899s	
8388/28500 (epoch 14.716), train_loss = 1.11616299, grad/param norm = 1.6104e-01, time/batch = 15.5270s	
8389/28500 (epoch 14.718), train_loss = 1.10959740, grad/param norm = 1.5534e-01, time/batch = 15.4597s	
8390/28500 (epoch 14.719), train_loss = 1.14104602, grad/param norm = 1.5612e-01, time/batch = 15.4081s	
8391/28500 (epoch 14.721), train_loss = 0.93721687, grad/param norm = 1.3896e-01, time/batch = 15.1885s	
8392/28500 (epoch 14.723), train_loss = 1.13399832, grad/param norm = 1.5997e-01, time/batch = 15.1237s	
8393/28500 (epoch 14.725), train_loss = 1.23462732, grad/param norm = 1.4775e-01, time/batch = 15.5065s	
8394/28500 (epoch 14.726), train_loss = 1.15520951, grad/param norm = 1.6111e-01, time/batch = 15.4221s	
8395/28500 (epoch 14.728), train_loss = 0.99683261, grad/param norm = 1.3521e-01, time/batch = 15.4025s	
8396/28500 (epoch 14.730), train_loss = 1.14713015, grad/param norm = 1.6447e-01, time/batch = 15.3477s	
8397/28500 (epoch 14.732), train_loss = 0.93971502, grad/param norm = 1.3435e-01, time/batch = 15.5526s	
8398/28500 (epoch 14.733), train_loss = 0.95646354, grad/param norm = 1.3526e-01, time/batch = 15.4519s	
8399/28500 (epoch 14.735), train_loss = 0.97685133, grad/param norm = 1.3987e-01, time/batch = 15.2944s	
8400/28500 (epoch 14.737), train_loss = 0.90285814, grad/param norm = 1.2401e-01, time/batch = 15.2275s	
8401/28500 (epoch 14.739), train_loss = 1.10322236, grad/param norm = 1.6642e-01, time/batch = 15.5480s	
8402/28500 (epoch 14.740), train_loss = 1.13002826, grad/param norm = 1.5308e-01, time/batch = 15.4481s	
8403/28500 (epoch 14.742), train_loss = 1.03109908, grad/param norm = 1.4380e-01, time/batch = 15.3805s	
8404/28500 (epoch 14.744), train_loss = 1.17400995, grad/param norm = 1.6636e-01, time/batch = 15.1179s	
8405/28500 (epoch 14.746), train_loss = 1.01677448, grad/param norm = 1.4044e-01, time/batch = 14.9772s	
8406/28500 (epoch 14.747), train_loss = 1.02979657, grad/param norm = 1.4621e-01, time/batch = 15.2800s	
8407/28500 (epoch 14.749), train_loss = 1.25843709, grad/param norm = 1.8099e-01, time/batch = 15.2917s	
8408/28500 (epoch 14.751), train_loss = 1.02419734, grad/param norm = 1.7194e-01, time/batch = 15.2274s	
8409/28500 (epoch 14.753), train_loss = 1.04175987, grad/param norm = 1.4055e-01, time/batch = 15.1833s	
8410/28500 (epoch 14.754), train_loss = 0.98663511, grad/param norm = 1.5851e-01, time/batch = 15.2864s	
8411/28500 (epoch 14.756), train_loss = 1.24339357, grad/param norm = 1.7064e-01, time/batch = 15.3663s	
8412/28500 (epoch 14.758), train_loss = 1.19757620, grad/param norm = 1.6358e-01, time/batch = 15.1341s	
8413/28500 (epoch 14.760), train_loss = 0.98779047, grad/param norm = 1.4296e-01, time/batch = 15.2852s	
8414/28500 (epoch 14.761), train_loss = 1.00311818, grad/param norm = 1.4897e-01, time/batch = 15.2467s	
8415/28500 (epoch 14.763), train_loss = 0.89882306, grad/param norm = 1.4878e-01, time/batch = 15.2883s	
8416/28500 (epoch 14.765), train_loss = 1.05984386, grad/param norm = 1.4237e-01, time/batch = 15.2825s	
8417/28500 (epoch 14.767), train_loss = 0.92980685, grad/param norm = 1.3382e-01, time/batch = 15.3979s	
8418/28500 (epoch 14.768), train_loss = 1.20549536, grad/param norm = 1.6401e-01, time/batch = 15.4247s	
8419/28500 (epoch 14.770), train_loss = 0.95556066, grad/param norm = 1.3733e-01, time/batch = 15.2989s	
8420/28500 (epoch 14.772), train_loss = 0.86038418, grad/param norm = 1.3157e-01, time/batch = 15.5520s	
8421/28500 (epoch 14.774), train_loss = 1.12968827, grad/param norm = 1.5868e-01, time/batch = 15.4418s	
8422/28500 (epoch 14.775), train_loss = 1.18570972, grad/param norm = 1.4453e-01, time/batch = 15.6375s	
8423/28500 (epoch 14.777), train_loss = 1.17000148, grad/param norm = 1.6069e-01, time/batch = 15.4491s	
8424/28500 (epoch 14.779), train_loss = 0.93816875, grad/param norm = 1.2730e-01, time/batch = 15.4433s	
8425/28500 (epoch 14.781), train_loss = 1.13944053, grad/param norm = 1.6229e-01, time/batch = 15.3721s	
8426/28500 (epoch 14.782), train_loss = 1.17876653, grad/param norm = 1.5744e-01, time/batch = 15.2828s	
8427/28500 (epoch 14.784), train_loss = 0.93051834, grad/param norm = 1.3218e-01, time/batch = 15.2828s	
8428/28500 (epoch 14.786), train_loss = 0.99827534, grad/param norm = 1.4810e-01, time/batch = 15.4716s	
8429/28500 (epoch 14.788), train_loss = 1.08991325, grad/param norm = 1.4783e-01, time/batch = 15.4666s	
8430/28500 (epoch 14.789), train_loss = 0.86267617, grad/param norm = 1.5575e-01, time/batch = 15.2223s	
8431/28500 (epoch 14.791), train_loss = 1.10365939, grad/param norm = 1.5021e-01, time/batch = 15.3099s	
8432/28500 (epoch 14.793), train_loss = 1.07356606, grad/param norm = 1.5414e-01, time/batch = 15.1277s	
8433/28500 (epoch 14.795), train_loss = 1.12756390, grad/param norm = 1.4311e-01, time/batch = 15.1782s	
8434/28500 (epoch 14.796), train_loss = 1.00396806, grad/param norm = 1.4786e-01, time/batch = 15.1362s	
8435/28500 (epoch 14.798), train_loss = 0.94748166, grad/param norm = 1.4849e-01, time/batch = 15.4223s	
8436/28500 (epoch 14.800), train_loss = 0.99219254, grad/param norm = 1.5356e-01, time/batch = 15.2089s	
8437/28500 (epoch 14.802), train_loss = 1.09177553, grad/param norm = 1.8165e-01, time/batch = 15.2267s	
8438/28500 (epoch 14.804), train_loss = 1.13990458, grad/param norm = 1.4862e-01, time/batch = 15.2745s	
8439/28500 (epoch 14.805), train_loss = 1.09671139, grad/param norm = 1.5726e-01, time/batch = 15.4599s	
8440/28500 (epoch 14.807), train_loss = 1.17502208, grad/param norm = 1.6783e-01, time/batch = 15.5495s	
8441/28500 (epoch 14.809), train_loss = 1.06810592, grad/param norm = 1.4706e-01, time/batch = 15.5271s	
8442/28500 (epoch 14.811), train_loss = 1.16976959, grad/param norm = 1.7183e-01, time/batch = 15.6398s	
8443/28500 (epoch 14.812), train_loss = 1.14500756, grad/param norm = 1.8127e-01, time/batch = 15.5505s	
8444/28500 (epoch 14.814), train_loss = 1.09319825, grad/param norm = 1.7190e-01, time/batch = 15.4227s	
8445/28500 (epoch 14.816), train_loss = 1.21126613, grad/param norm = 1.7312e-01, time/batch = 15.1827s	
8446/28500 (epoch 14.818), train_loss = 1.19332222, grad/param norm = 1.5159e-01, time/batch = 15.1931s	
8447/28500 (epoch 14.819), train_loss = 1.11268096, grad/param norm = 1.4990e-01, time/batch = 15.2909s	
8448/28500 (epoch 14.821), train_loss = 1.06239541, grad/param norm = 1.6114e-01, time/batch = 15.4392s	
8449/28500 (epoch 14.823), train_loss = 1.25888959, grad/param norm = 1.7900e-01, time/batch = 15.2338s	
8450/28500 (epoch 14.825), train_loss = 1.09000552, grad/param norm = 1.6078e-01, time/batch = 15.4684s	
8451/28500 (epoch 14.826), train_loss = 1.13634094, grad/param norm = 1.7776e-01, time/batch = 15.2875s	
8452/28500 (epoch 14.828), train_loss = 1.00629360, grad/param norm = 1.7698e-01, time/batch = 15.4415s	
8453/28500 (epoch 14.830), train_loss = 1.05219258, grad/param norm = 1.4947e-01, time/batch = 15.4433s	
8454/28500 (epoch 14.832), train_loss = 1.12842738, grad/param norm = 1.8720e-01, time/batch = 15.5884s	
8455/28500 (epoch 14.833), train_loss = 1.25995957, grad/param norm = 1.6269e-01, time/batch = 15.3765s	
8456/28500 (epoch 14.835), train_loss = 1.06287288, grad/param norm = 1.5719e-01, time/batch = 15.3846s	
8457/28500 (epoch 14.837), train_loss = 0.97605884, grad/param norm = 1.5837e-01, time/batch = 15.2955s	
8458/28500 (epoch 14.839), train_loss = 1.22985788, grad/param norm = 1.7169e-01, time/batch = 15.2239s	
8459/28500 (epoch 14.840), train_loss = 1.24351484, grad/param norm = 1.6374e-01, time/batch = 15.2778s	
8460/28500 (epoch 14.842), train_loss = 1.19829689, grad/param norm = 1.8880e-01, time/batch = 15.0414s	
8461/28500 (epoch 14.844), train_loss = 1.14602299, grad/param norm = 1.8993e-01, time/batch = 15.6143s	
8462/28500 (epoch 14.846), train_loss = 1.26287427, grad/param norm = 1.6746e-01, time/batch = 15.6430s	
8463/28500 (epoch 14.847), train_loss = 1.06214481, grad/param norm = 1.4542e-01, time/batch = 15.5318s	
8464/28500 (epoch 14.849), train_loss = 1.06002442, grad/param norm = 1.4553e-01, time/batch = 15.3551s	
8465/28500 (epoch 14.851), train_loss = 0.94120611, grad/param norm = 1.3420e-01, time/batch = 15.3017s	
8466/28500 (epoch 14.853), train_loss = 1.12629858, grad/param norm = 1.5180e-01, time/batch = 15.5547s	
8467/28500 (epoch 14.854), train_loss = 1.14980289, grad/param norm = 1.6634e-01, time/batch = 15.7919s	
8468/28500 (epoch 14.856), train_loss = 1.23814243, grad/param norm = 1.8127e-01, time/batch = 15.5973s	
8469/28500 (epoch 14.858), train_loss = 0.99496063, grad/param norm = 1.3527e-01, time/batch = 15.4671s	
8470/28500 (epoch 14.860), train_loss = 1.11705689, grad/param norm = 1.6774e-01, time/batch = 15.2209s	
8471/28500 (epoch 14.861), train_loss = 1.15872692, grad/param norm = 1.6643e-01, time/batch = 15.4541s	
8472/28500 (epoch 14.863), train_loss = 1.20519581, grad/param norm = 1.7009e-01, time/batch = 15.6776s	
8473/28500 (epoch 14.865), train_loss = 1.10615760, grad/param norm = 1.6057e-01, time/batch = 15.4547s	
8474/28500 (epoch 14.867), train_loss = 1.17004302, grad/param norm = 1.6834e-01, time/batch = 15.4573s	
8475/28500 (epoch 14.868), train_loss = 0.99768904, grad/param norm = 1.5168e-01, time/batch = 15.5000s	
8476/28500 (epoch 14.870), train_loss = 0.92527577, grad/param norm = 1.3798e-01, time/batch = 15.4332s	
8477/28500 (epoch 14.872), train_loss = 1.16889484, grad/param norm = 1.7677e-01, time/batch = 15.3875s	
8478/28500 (epoch 14.874), train_loss = 1.10669018, grad/param norm = 1.7003e-01, time/batch = 15.3955s	
8479/28500 (epoch 14.875), train_loss = 1.21951931, grad/param norm = 1.7539e-01, time/batch = 15.3738s	
8480/28500 (epoch 14.877), train_loss = 1.14690508, grad/param norm = 1.4784e-01, time/batch = 15.3582s	
8481/28500 (epoch 14.879), train_loss = 1.12314032, grad/param norm = 1.5119e-01, time/batch = 15.7041s	
8482/28500 (epoch 14.881), train_loss = 1.12046507, grad/param norm = 1.5915e-01, time/batch = 15.4666s	
8483/28500 (epoch 14.882), train_loss = 1.04992456, grad/param norm = 1.3983e-01, time/batch = 15.4693s	
8484/28500 (epoch 14.884), train_loss = 1.14453056, grad/param norm = 1.7198e-01, time/batch = 15.4263s	
8485/28500 (epoch 14.886), train_loss = 1.06064088, grad/param norm = 1.4169e-01, time/batch = 15.1363s	
8486/28500 (epoch 14.888), train_loss = 0.99736578, grad/param norm = 1.4877e-01, time/batch = 15.0395s	
8487/28500 (epoch 14.889), train_loss = 1.12614130, grad/param norm = 1.5832e-01, time/batch = 15.0503s	
8488/28500 (epoch 14.891), train_loss = 1.13735834, grad/param norm = 1.5555e-01, time/batch = 15.3350s	
8489/28500 (epoch 14.893), train_loss = 1.05171761, grad/param norm = 1.5190e-01, time/batch = 15.2705s	
8490/28500 (epoch 14.895), train_loss = 1.29551205, grad/param norm = 1.7862e-01, time/batch = 15.3740s	
8491/28500 (epoch 14.896), train_loss = 1.18745326, grad/param norm = 1.6436e-01, time/batch = 15.6723s	
8492/28500 (epoch 14.898), train_loss = 1.09473086, grad/param norm = 1.4889e-01, time/batch = 15.2882s	
8493/28500 (epoch 14.900), train_loss = 0.96579752, grad/param norm = 1.4399e-01, time/batch = 15.1352s	
8494/28500 (epoch 14.902), train_loss = 0.98421373, grad/param norm = 1.5526e-01, time/batch = 15.0465s	
8495/28500 (epoch 14.904), train_loss = 1.03119840, grad/param norm = 1.4325e-01, time/batch = 15.0519s	
8496/28500 (epoch 14.905), train_loss = 1.14276919, grad/param norm = 1.5876e-01, time/batch = 15.1377s	
8497/28500 (epoch 14.907), train_loss = 1.10132660, grad/param norm = 1.5141e-01, time/batch = 15.3129s	
8498/28500 (epoch 14.909), train_loss = 0.98824860, grad/param norm = 1.6889e-01, time/batch = 15.5488s	
8499/28500 (epoch 14.911), train_loss = 1.00597357, grad/param norm = 1.4216e-01, time/batch = 15.6181s	
8500/28500 (epoch 14.912), train_loss = 0.87850602, grad/param norm = 1.3047e-01, time/batch = 15.4513s	
8501/28500 (epoch 14.914), train_loss = 1.21622212, grad/param norm = 1.5019e-01, time/batch = 15.4472s	
8502/28500 (epoch 14.916), train_loss = 1.16304703, grad/param norm = 1.7972e-01, time/batch = 15.5643s	
8503/28500 (epoch 14.918), train_loss = 1.13585772, grad/param norm = 1.7284e-01, time/batch = 15.4573s	
8504/28500 (epoch 14.919), train_loss = 1.09665636, grad/param norm = 1.4732e-01, time/batch = 15.5953s	
8505/28500 (epoch 14.921), train_loss = 1.24656659, grad/param norm = 1.8296e-01, time/batch = 15.5056s	
8506/28500 (epoch 14.923), train_loss = 1.11350245, grad/param norm = 1.7143e-01, time/batch = 15.4670s	
8507/28500 (epoch 14.925), train_loss = 1.02741759, grad/param norm = 1.6298e-01, time/batch = 15.3068s	
8508/28500 (epoch 14.926), train_loss = 1.08044324, grad/param norm = 1.5223e-01, time/batch = 15.2915s	
8509/28500 (epoch 14.928), train_loss = 1.04241972, grad/param norm = 1.5189e-01, time/batch = 15.2075s	
8510/28500 (epoch 14.930), train_loss = 0.86222506, grad/param norm = 1.3855e-01, time/batch = 15.2875s	
8511/28500 (epoch 14.932), train_loss = 0.88028570, grad/param norm = 1.2869e-01, time/batch = 15.3949s	
8512/28500 (epoch 14.933), train_loss = 1.17327568, grad/param norm = 1.5923e-01, time/batch = 15.4810s	
8513/28500 (epoch 14.935), train_loss = 1.20229293, grad/param norm = 1.7184e-01, time/batch = 15.2818s	
8514/28500 (epoch 14.937), train_loss = 1.23234365, grad/param norm = 1.7471e-01, time/batch = 15.3841s	
8515/28500 (epoch 14.939), train_loss = 1.28745937, grad/param norm = 1.6905e-01, time/batch = 15.6536s	
8516/28500 (epoch 14.940), train_loss = 0.98463038, grad/param norm = 1.4301e-01, time/batch = 15.5499s	
8517/28500 (epoch 14.942), train_loss = 1.17664679, grad/param norm = 1.7768e-01, time/batch = 15.5542s	
8518/28500 (epoch 14.944), train_loss = 1.08852925, grad/param norm = 1.5636e-01, time/batch = 15.3031s	
8519/28500 (epoch 14.946), train_loss = 1.22128268, grad/param norm = 1.5539e-01, time/batch = 27.7781s	
8520/28500 (epoch 14.947), train_loss = 1.43092218, grad/param norm = 1.8669e-01, time/batch = 15.6417s	
8521/28500 (epoch 14.949), train_loss = 1.02743764, grad/param norm = 1.6189e-01, time/batch = 15.6121s	
8522/28500 (epoch 14.951), train_loss = 1.25748442, grad/param norm = 1.8378e-01, time/batch = 15.5141s	
8523/28500 (epoch 14.953), train_loss = 1.30447514, grad/param norm = 1.7983e-01, time/batch = 15.4263s	
8524/28500 (epoch 14.954), train_loss = 1.25553084, grad/param norm = 1.7828e-01, time/batch = 15.1150s	
8525/28500 (epoch 14.956), train_loss = 1.20864034, grad/param norm = 2.0130e-01, time/batch = 15.4430s	
8526/28500 (epoch 14.958), train_loss = 1.30585013, grad/param norm = 1.6027e-01, time/batch = 15.4419s	
8527/28500 (epoch 14.960), train_loss = 1.00029044, grad/param norm = 1.5602e-01, time/batch = 15.4732s	
8528/28500 (epoch 14.961), train_loss = 1.35185779, grad/param norm = 1.8436e-01, time/batch = 15.3133s	
8529/28500 (epoch 14.963), train_loss = 1.23400254, grad/param norm = 1.5507e-01, time/batch = 15.4296s	
8530/28500 (epoch 14.965), train_loss = 1.02015113, grad/param norm = 1.5296e-01, time/batch = 15.3556s	
8531/28500 (epoch 14.967), train_loss = 1.01023691, grad/param norm = 1.4699e-01, time/batch = 15.2727s	
8532/28500 (epoch 14.968), train_loss = 0.94256151, grad/param norm = 1.3001e-01, time/batch = 15.3923s	
8533/28500 (epoch 14.970), train_loss = 1.05108594, grad/param norm = 1.4663e-01, time/batch = 15.2498s	
8534/28500 (epoch 14.972), train_loss = 1.14476826, grad/param norm = 1.5713e-01, time/batch = 15.4501s	
8535/28500 (epoch 14.974), train_loss = 1.33200147, grad/param norm = 1.7583e-01, time/batch = 15.1712s	
8536/28500 (epoch 14.975), train_loss = 1.07687677, grad/param norm = 1.6736e-01, time/batch = 15.2442s	
8537/28500 (epoch 14.977), train_loss = 1.26063006, grad/param norm = 1.6722e-01, time/batch = 15.2091s	
8538/28500 (epoch 14.979), train_loss = 1.06147177, grad/param norm = 1.5971e-01, time/batch = 15.4663s	
8539/28500 (epoch 14.981), train_loss = 1.02520604, grad/param norm = 1.5094e-01, time/batch = 15.2588s	
8540/28500 (epoch 14.982), train_loss = 1.05716598, grad/param norm = 1.5195e-01, time/batch = 15.2645s	
8541/28500 (epoch 14.984), train_loss = 1.23073588, grad/param norm = 1.6471e-01, time/batch = 15.3262s	
8542/28500 (epoch 14.986), train_loss = 1.38240843, grad/param norm = 1.8054e-01, time/batch = 15.1678s	
8543/28500 (epoch 14.988), train_loss = 0.95470172, grad/param norm = 1.5788e-01, time/batch = 15.1263s	
8544/28500 (epoch 14.989), train_loss = 1.15538873, grad/param norm = 1.6170e-01, time/batch = 15.5116s	
8545/28500 (epoch 14.991), train_loss = 1.04986459, grad/param norm = 1.5983e-01, time/batch = 15.5951s	
8546/28500 (epoch 14.993), train_loss = 1.06131648, grad/param norm = 1.6544e-01, time/batch = 15.5496s	
8547/28500 (epoch 14.995), train_loss = 1.03081619, grad/param norm = 1.5564e-01, time/batch = 15.6176s	
8548/28500 (epoch 14.996), train_loss = 1.00879897, grad/param norm = 1.4999e-01, time/batch = 15.5479s	
8549/28500 (epoch 14.998), train_loss = 1.22186415, grad/param norm = 1.6837e-01, time/batch = 15.5307s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
8550/28500 (epoch 15.000), train_loss = 1.05538968, grad/param norm = 1.4352e-01, time/batch = 15.4429s	
8551/28500 (epoch 15.002), train_loss = 1.26910800, grad/param norm = 1.7749e-01, time/batch = 15.5421s	
8552/28500 (epoch 15.004), train_loss = 1.07293906, grad/param norm = 1.6331e-01, time/batch = 15.1916s	
8553/28500 (epoch 15.005), train_loss = 1.22140546, grad/param norm = 1.6667e-01, time/batch = 15.3603s	
8554/28500 (epoch 15.007), train_loss = 0.98545750, grad/param norm = 1.4436e-01, time/batch = 15.4087s	
8555/28500 (epoch 15.009), train_loss = 1.17114246, grad/param norm = 1.6787e-01, time/batch = 15.5795s	
8556/28500 (epoch 15.011), train_loss = 1.06226013, grad/param norm = 1.9542e-01, time/batch = 15.5255s	
8557/28500 (epoch 15.012), train_loss = 0.97268738, grad/param norm = 1.3606e-01, time/batch = 15.5214s	
8558/28500 (epoch 15.014), train_loss = 1.00326220, grad/param norm = 1.5051e-01, time/batch = 15.3857s	
8559/28500 (epoch 15.016), train_loss = 1.06582641, grad/param norm = 1.3713e-01, time/batch = 15.4620s	
8560/28500 (epoch 15.018), train_loss = 1.14249430, grad/param norm = 1.6434e-01, time/batch = 15.2852s	
8561/28500 (epoch 15.019), train_loss = 1.22478965, grad/param norm = 1.6661e-01, time/batch = 15.4472s	
8562/28500 (epoch 15.021), train_loss = 1.18314678, grad/param norm = 1.3775e-01, time/batch = 15.6208s	
8563/28500 (epoch 15.023), train_loss = 1.07707092, grad/param norm = 1.5898e-01, time/batch = 15.5260s	
8564/28500 (epoch 15.025), train_loss = 1.11690651, grad/param norm = 1.5391e-01, time/batch = 15.6094s	
8565/28500 (epoch 15.026), train_loss = 1.11693591, grad/param norm = 1.5759e-01, time/batch = 15.5211s	
8566/28500 (epoch 15.028), train_loss = 1.16362731, grad/param norm = 1.5880e-01, time/batch = 15.4884s	
8567/28500 (epoch 15.030), train_loss = 1.19877348, grad/param norm = 1.7975e-01, time/batch = 15.5109s	
8568/28500 (epoch 15.032), train_loss = 1.18162035, grad/param norm = 1.6598e-01, time/batch = 15.2483s	
8569/28500 (epoch 15.033), train_loss = 1.27446199, grad/param norm = 1.6818e-01, time/batch = 15.4288s	
8570/28500 (epoch 15.035), train_loss = 1.12837374, grad/param norm = 1.6560e-01, time/batch = 15.6096s	
8571/28500 (epoch 15.037), train_loss = 1.19669555, grad/param norm = 1.4681e-01, time/batch = 15.5431s	
8572/28500 (epoch 15.039), train_loss = 1.23345619, grad/param norm = 1.7211e-01, time/batch = 15.4510s	
8573/28500 (epoch 15.040), train_loss = 1.27572548, grad/param norm = 1.6353e-01, time/batch = 15.2000s	
8574/28500 (epoch 15.042), train_loss = 1.20613501, grad/param norm = 1.6206e-01, time/batch = 15.4655s	
8575/28500 (epoch 15.044), train_loss = 1.11430945, grad/param norm = 1.6479e-01, time/batch = 15.2278s	
8576/28500 (epoch 15.046), train_loss = 1.34980722, grad/param norm = 1.7174e-01, time/batch = 15.4115s	
8577/28500 (epoch 15.047), train_loss = 1.25070420, grad/param norm = 1.7114e-01, time/batch = 15.6259s	
8578/28500 (epoch 15.049), train_loss = 1.15085082, grad/param norm = 1.6728e-01, time/batch = 15.4750s	
8579/28500 (epoch 15.051), train_loss = 1.08745623, grad/param norm = 1.6902e-01, time/batch = 15.3744s	
8580/28500 (epoch 15.053), train_loss = 1.13668816, grad/param norm = 1.6491e-01, time/batch = 15.5247s	
8581/28500 (epoch 15.054), train_loss = 1.23316496, grad/param norm = 1.7545e-01, time/batch = 15.4830s	
8582/28500 (epoch 15.056), train_loss = 1.00200913, grad/param norm = 1.4047e-01, time/batch = 15.2718s	
8583/28500 (epoch 15.058), train_loss = 1.01506112, grad/param norm = 1.5388e-01, time/batch = 15.2137s	
8584/28500 (epoch 15.060), train_loss = 1.22030943, grad/param norm = 1.6767e-01, time/batch = 15.2820s	
8585/28500 (epoch 15.061), train_loss = 1.14466873, grad/param norm = 1.7511e-01, time/batch = 15.3814s	
8586/28500 (epoch 15.063), train_loss = 1.20888703, grad/param norm = 1.6362e-01, time/batch = 15.3570s	
8587/28500 (epoch 15.065), train_loss = 1.25289585, grad/param norm = 1.7234e-01, time/batch = 15.3619s	
8588/28500 (epoch 15.067), train_loss = 1.08445472, grad/param norm = 1.4155e-01, time/batch = 15.6006s	
8589/28500 (epoch 15.068), train_loss = 1.10076009, grad/param norm = 1.5548e-01, time/batch = 15.5959s	
8590/28500 (epoch 15.070), train_loss = 1.16829386, grad/param norm = 1.6428e-01, time/batch = 15.6319s	
8591/28500 (epoch 15.072), train_loss = 1.34627296, grad/param norm = 1.8616e-01, time/batch = 15.6865s	
8592/28500 (epoch 15.074), train_loss = 1.17019096, grad/param norm = 1.5091e-01, time/batch = 15.5062s	
8593/28500 (epoch 15.075), train_loss = 1.12870259, grad/param norm = 1.4701e-01, time/batch = 15.3015s	
8594/28500 (epoch 15.077), train_loss = 1.19322577, grad/param norm = 1.6476e-01, time/batch = 15.4247s	
8595/28500 (epoch 15.079), train_loss = 1.11820992, grad/param norm = 1.5066e-01, time/batch = 15.1828s	
8596/28500 (epoch 15.081), train_loss = 1.27228657, grad/param norm = 1.7623e-01, time/batch = 15.2790s	
8597/28500 (epoch 15.082), train_loss = 1.17048248, grad/param norm = 1.7453e-01, time/batch = 15.2875s	
8598/28500 (epoch 15.084), train_loss = 1.18076594, grad/param norm = 1.5734e-01, time/batch = 14.9522s	
8599/28500 (epoch 15.086), train_loss = 1.11745266, grad/param norm = 1.6815e-01, time/batch = 15.1216s	
8600/28500 (epoch 15.088), train_loss = 1.01266567, grad/param norm = 1.5714e-01, time/batch = 15.2755s	
8601/28500 (epoch 15.089), train_loss = 1.24353277, grad/param norm = 1.4650e-01, time/batch = 15.5324s	
8602/28500 (epoch 15.091), train_loss = 1.02655963, grad/param norm = 1.5401e-01, time/batch = 15.1239s	
8603/28500 (epoch 15.093), train_loss = 1.17728139, grad/param norm = 1.5397e-01, time/batch = 15.0315s	
8604/28500 (epoch 15.095), train_loss = 1.07588653, grad/param norm = 1.4389e-01, time/batch = 15.3663s	
8605/28500 (epoch 15.096), train_loss = 1.26690104, grad/param norm = 1.6287e-01, time/batch = 15.3619s	
8606/28500 (epoch 15.098), train_loss = 1.23145849, grad/param norm = 1.7203e-01, time/batch = 15.1359s	
8607/28500 (epoch 15.100), train_loss = 1.09635506, grad/param norm = 1.5907e-01, time/batch = 15.3361s	
8608/28500 (epoch 15.102), train_loss = 1.27115173, grad/param norm = 1.6739e-01, time/batch = 15.4917s	
8609/28500 (epoch 15.104), train_loss = 1.11866904, grad/param norm = 1.6527e-01, time/batch = 15.3836s	
8610/28500 (epoch 15.105), train_loss = 1.23650792, grad/param norm = 1.5858e-01, time/batch = 15.2846s	
8611/28500 (epoch 15.107), train_loss = 1.02782764, grad/param norm = 1.6958e-01, time/batch = 15.5912s	
8612/28500 (epoch 15.109), train_loss = 1.01183188, grad/param norm = 1.5663e-01, time/batch = 15.4501s	
8613/28500 (epoch 15.111), train_loss = 1.11533304, grad/param norm = 1.7109e-01, time/batch = 15.4394s	
8614/28500 (epoch 15.112), train_loss = 1.20992961, grad/param norm = 1.6731e-01, time/batch = 15.2208s	
8615/28500 (epoch 15.114), train_loss = 1.11521642, grad/param norm = 1.5350e-01, time/batch = 15.5379s	
8616/28500 (epoch 15.116), train_loss = 1.31746892, grad/param norm = 1.7068e-01, time/batch = 15.3866s	
8617/28500 (epoch 15.118), train_loss = 0.99401102, grad/param norm = 1.5871e-01, time/batch = 15.3713s	
8618/28500 (epoch 15.119), train_loss = 1.18124117, grad/param norm = 1.6899e-01, time/batch = 15.3767s	
8619/28500 (epoch 15.121), train_loss = 1.33256824, grad/param norm = 1.8765e-01, time/batch = 15.5686s	
8620/28500 (epoch 15.123), train_loss = 1.20055644, grad/param norm = 1.6099e-01, time/batch = 15.3000s	
8621/28500 (epoch 15.125), train_loss = 1.15661657, grad/param norm = 1.5867e-01, time/batch = 15.5583s	
8622/28500 (epoch 15.126), train_loss = 1.12481252, grad/param norm = 1.5236e-01, time/batch = 15.1037s	
8623/28500 (epoch 15.128), train_loss = 1.10204287, grad/param norm = 1.5447e-01, time/batch = 15.0460s	
8624/28500 (epoch 15.130), train_loss = 1.01765976, grad/param norm = 1.5361e-01, time/batch = 15.3469s	
8625/28500 (epoch 15.132), train_loss = 1.19284282, grad/param norm = 1.6730e-01, time/batch = 15.3890s	
8626/28500 (epoch 15.133), train_loss = 1.19612500, grad/param norm = 1.7801e-01, time/batch = 15.5180s	
8627/28500 (epoch 15.135), train_loss = 1.11221403, grad/param norm = 1.4897e-01, time/batch = 15.4655s	
8628/28500 (epoch 15.137), train_loss = 1.09811718, grad/param norm = 1.6321e-01, time/batch = 15.3793s	
8629/28500 (epoch 15.139), train_loss = 1.10202218, grad/param norm = 1.4522e-01, time/batch = 15.6163s	
8630/28500 (epoch 15.140), train_loss = 1.17569695, grad/param norm = 1.4491e-01, time/batch = 15.4871s	
8631/28500 (epoch 15.142), train_loss = 1.12420559, grad/param norm = 1.6167e-01, time/batch = 15.4517s	
8632/28500 (epoch 15.144), train_loss = 1.05519853, grad/param norm = 1.5248e-01, time/batch = 15.1956s	
8633/28500 (epoch 15.146), train_loss = 1.06691892, grad/param norm = 1.4741e-01, time/batch = 15.3626s	
8634/28500 (epoch 15.147), train_loss = 0.97757743, grad/param norm = 1.5050e-01, time/batch = 15.3195s	
8635/28500 (epoch 15.149), train_loss = 0.97415908, grad/param norm = 1.3479e-01, time/batch = 15.4688s	
8636/28500 (epoch 15.151), train_loss = 1.01369802, grad/param norm = 1.3805e-01, time/batch = 15.4621s	
8637/28500 (epoch 15.153), train_loss = 1.14088820, grad/param norm = 1.5698e-01, time/batch = 15.5190s	
8638/28500 (epoch 15.154), train_loss = 1.01226099, grad/param norm = 1.4481e-01, time/batch = 15.2058s	
8639/28500 (epoch 15.156), train_loss = 1.25302801, grad/param norm = 1.6324e-01, time/batch = 15.3665s	
8640/28500 (epoch 15.158), train_loss = 1.10266401, grad/param norm = 1.4828e-01, time/batch = 15.5013s	
8641/28500 (epoch 15.160), train_loss = 1.02481827, grad/param norm = 1.4432e-01, time/batch = 15.4501s	
8642/28500 (epoch 15.161), train_loss = 1.10444567, grad/param norm = 1.9142e-01, time/batch = 15.3419s	
8643/28500 (epoch 15.163), train_loss = 0.97855534, grad/param norm = 1.5813e-01, time/batch = 15.4325s	
8644/28500 (epoch 15.165), train_loss = 1.32762986, grad/param norm = 1.6251e-01, time/batch = 15.3758s	
8645/28500 (epoch 15.167), train_loss = 1.38126539, grad/param norm = 1.8266e-01, time/batch = 15.3680s	
8646/28500 (epoch 15.168), train_loss = 1.24479097, grad/param norm = 1.7289e-01, time/batch = 15.6526s	
8647/28500 (epoch 15.170), train_loss = 1.25042923, grad/param norm = 1.9061e-01, time/batch = 15.6925s	
8648/28500 (epoch 15.172), train_loss = 1.11949036, grad/param norm = 1.5157e-01, time/batch = 15.4831s	
8649/28500 (epoch 15.174), train_loss = 1.28029216, grad/param norm = 1.8370e-01, time/batch = 15.3656s	
8650/28500 (epoch 15.175), train_loss = 1.12258372, grad/param norm = 1.4982e-01, time/batch = 15.6134s	
8651/28500 (epoch 15.177), train_loss = 1.19849266, grad/param norm = 1.7120e-01, time/batch = 15.2790s	
8652/28500 (epoch 15.179), train_loss = 1.11851264, grad/param norm = 1.7459e-01, time/batch = 15.3014s	
8653/28500 (epoch 15.181), train_loss = 1.18713913, grad/param norm = 1.6694e-01, time/batch = 15.5908s	
8654/28500 (epoch 15.182), train_loss = 1.11946991, grad/param norm = 1.4850e-01, time/batch = 15.2712s	
8655/28500 (epoch 15.184), train_loss = 1.33061511, grad/param norm = 1.8543e-01, time/batch = 15.0632s	
8656/28500 (epoch 15.186), train_loss = 1.24698582, grad/param norm = 1.7012e-01, time/batch = 15.0741s	
8657/28500 (epoch 15.188), train_loss = 1.14427955, grad/param norm = 1.4694e-01, time/batch = 15.0988s	
8658/28500 (epoch 15.189), train_loss = 1.18885639, grad/param norm = 1.6772e-01, time/batch = 15.4567s	
8659/28500 (epoch 15.191), train_loss = 1.36329589, grad/param norm = 1.7034e-01, time/batch = 15.5605s	
8660/28500 (epoch 15.193), train_loss = 1.21350352, grad/param norm = 1.8473e-01, time/batch = 15.4373s	
8661/28500 (epoch 15.195), train_loss = 1.29397402, grad/param norm = 1.7368e-01, time/batch = 15.3220s	
8662/28500 (epoch 15.196), train_loss = 1.20632623, grad/param norm = 1.6613e-01, time/batch = 15.1825s	
8663/28500 (epoch 15.198), train_loss = 1.15813725, grad/param norm = 1.7879e-01, time/batch = 15.2852s	
8664/28500 (epoch 15.200), train_loss = 1.17712922, grad/param norm = 1.5447e-01, time/batch = 15.4972s	
8665/28500 (epoch 15.202), train_loss = 1.14594733, grad/param norm = 1.6022e-01, time/batch = 15.2984s	
8666/28500 (epoch 15.204), train_loss = 1.07987605, grad/param norm = 1.4707e-01, time/batch = 15.2018s	
8667/28500 (epoch 15.205), train_loss = 1.11131698, grad/param norm = 1.6649e-01, time/batch = 15.3691s	
8668/28500 (epoch 15.207), train_loss = 1.05541751, grad/param norm = 1.6330e-01, time/batch = 15.5507s	
8669/28500 (epoch 15.209), train_loss = 1.14582311, grad/param norm = 1.5286e-01, time/batch = 15.3577s	
8670/28500 (epoch 15.211), train_loss = 1.01720917, grad/param norm = 1.6011e-01, time/batch = 15.2941s	
8671/28500 (epoch 15.212), train_loss = 0.99434002, grad/param norm = 1.4068e-01, time/batch = 15.3896s	
8672/28500 (epoch 15.214), train_loss = 1.16339624, grad/param norm = 1.7233e-01, time/batch = 15.2615s	
8673/28500 (epoch 15.216), train_loss = 1.01765469, grad/param norm = 1.4795e-01, time/batch = 15.2803s	
8674/28500 (epoch 15.218), train_loss = 1.27306590, grad/param norm = 1.5730e-01, time/batch = 15.1853s	
8675/28500 (epoch 15.219), train_loss = 1.19158013, grad/param norm = 1.7786e-01, time/batch = 15.1450s	
8676/28500 (epoch 15.221), train_loss = 1.02053159, grad/param norm = 1.6118e-01, time/batch = 15.0613s	
8677/28500 (epoch 15.223), train_loss = 1.26504366, grad/param norm = 1.6275e-01, time/batch = 15.3528s	
8678/28500 (epoch 15.225), train_loss = 1.27175738, grad/param norm = 1.6006e-01, time/batch = 15.3741s	
8679/28500 (epoch 15.226), train_loss = 1.09707234, grad/param norm = 1.4907e-01, time/batch = 15.4392s	
8680/28500 (epoch 15.228), train_loss = 1.21068445, grad/param norm = 1.5065e-01, time/batch = 15.3689s	
8681/28500 (epoch 15.230), train_loss = 1.24821517, grad/param norm = 1.5983e-01, time/batch = 15.4438s	
8682/28500 (epoch 15.232), train_loss = 1.20798203, grad/param norm = 1.4968e-01, time/batch = 15.1754s	
8683/28500 (epoch 15.233), train_loss = 1.17827713, grad/param norm = 1.6589e-01, time/batch = 15.1144s	
8684/28500 (epoch 15.235), train_loss = 1.11188474, grad/param norm = 1.4874e-01, time/batch = 15.1246s	
8685/28500 (epoch 15.237), train_loss = 0.99129972, grad/param norm = 1.3706e-01, time/batch = 15.3696s	
8686/28500 (epoch 15.239), train_loss = 1.06667719, grad/param norm = 1.3923e-01, time/batch = 15.2972s	
8687/28500 (epoch 15.240), train_loss = 1.02317694, grad/param norm = 1.6907e-01, time/batch = 15.5931s	
8688/28500 (epoch 15.242), train_loss = 1.19396318, grad/param norm = 1.7496e-01, time/batch = 15.4862s	
8689/28500 (epoch 15.244), train_loss = 1.19443677, grad/param norm = 1.4939e-01, time/batch = 15.4014s	
8690/28500 (epoch 15.246), train_loss = 1.25975103, grad/param norm = 1.6451e-01, time/batch = 15.4748s	
8691/28500 (epoch 15.247), train_loss = 1.33916708, grad/param norm = 1.7666e-01, time/batch = 15.6034s	
8692/28500 (epoch 15.249), train_loss = 1.14977023, grad/param norm = 1.5748e-01, time/batch = 15.6101s	
8693/28500 (epoch 15.251), train_loss = 1.04918242, grad/param norm = 1.4306e-01, time/batch = 15.5127s	
8694/28500 (epoch 15.253), train_loss = 1.33157521, grad/param norm = 1.9046e-01, time/batch = 15.5695s	
8695/28500 (epoch 15.254), train_loss = 1.28249029, grad/param norm = 1.6659e-01, time/batch = 15.5284s	
8696/28500 (epoch 15.256), train_loss = 1.08829872, grad/param norm = 1.5072e-01, time/batch = 15.4537s	
8697/28500 (epoch 15.258), train_loss = 1.14608463, grad/param norm = 1.7184e-01, time/batch = 15.3491s	
8698/28500 (epoch 15.260), train_loss = 1.08753346, grad/param norm = 1.4540e-01, time/batch = 15.3308s	
8699/28500 (epoch 15.261), train_loss = 1.08865652, grad/param norm = 1.5557e-01, time/batch = 15.1045s	
8700/28500 (epoch 15.263), train_loss = 1.27841621, grad/param norm = 1.8837e-01, time/batch = 15.3428s	
8701/28500 (epoch 15.265), train_loss = 1.15499940, grad/param norm = 1.5658e-01, time/batch = 15.4619s	
8702/28500 (epoch 15.267), train_loss = 1.30593184, grad/param norm = 1.6304e-01, time/batch = 15.1729s	
8703/28500 (epoch 15.268), train_loss = 1.20553646, grad/param norm = 1.5265e-01, time/batch = 15.1485s	
8704/28500 (epoch 15.270), train_loss = 1.17811504, grad/param norm = 1.7776e-01, time/batch = 15.4953s	
8705/28500 (epoch 15.272), train_loss = 1.11485125, grad/param norm = 1.5273e-01, time/batch = 15.3673s	
8706/28500 (epoch 15.274), train_loss = 1.26264592, grad/param norm = 1.5899e-01, time/batch = 15.5259s	
8707/28500 (epoch 15.275), train_loss = 1.18736814, grad/param norm = 1.4980e-01, time/batch = 15.5102s	
8708/28500 (epoch 15.277), train_loss = 1.14324553, grad/param norm = 1.5567e-01, time/batch = 15.5501s	
8709/28500 (epoch 15.279), train_loss = 1.20388123, grad/param norm = 1.8413e-01, time/batch = 15.5490s	
8710/28500 (epoch 15.281), train_loss = 1.23579991, grad/param norm = 1.8305e-01, time/batch = 15.4512s	
8711/28500 (epoch 15.282), train_loss = 1.06003574, grad/param norm = 1.4813e-01, time/batch = 15.4422s	
8712/28500 (epoch 15.284), train_loss = 1.16864312, grad/param norm = 1.6634e-01, time/batch = 15.5778s	
8713/28500 (epoch 15.286), train_loss = 1.26598920, grad/param norm = 1.6615e-01, time/batch = 15.3694s	
8714/28500 (epoch 15.288), train_loss = 1.19939161, grad/param norm = 1.7454e-01, time/batch = 15.5020s	
8715/28500 (epoch 15.289), train_loss = 1.23082015, grad/param norm = 1.8204e-01, time/batch = 15.2959s	
8716/28500 (epoch 15.291), train_loss = 1.13372660, grad/param norm = 1.4886e-01, time/batch = 15.3608s	
8717/28500 (epoch 15.293), train_loss = 1.10600284, grad/param norm = 1.5752e-01, time/batch = 15.2878s	
8718/28500 (epoch 15.295), train_loss = 1.02914236, grad/param norm = 1.5119e-01, time/batch = 15.3716s	
8719/28500 (epoch 15.296), train_loss = 1.04483047, grad/param norm = 1.4590e-01, time/batch = 15.2882s	
8720/28500 (epoch 15.298), train_loss = 1.20819438, grad/param norm = 1.5204e-01, time/batch = 15.3814s	
8721/28500 (epoch 15.300), train_loss = 1.05388372, grad/param norm = 1.4636e-01, time/batch = 15.6881s	
8722/28500 (epoch 15.302), train_loss = 1.04011928, grad/param norm = 1.4967e-01, time/batch = 15.5366s	
8723/28500 (epoch 15.304), train_loss = 1.13561912, grad/param norm = 1.4844e-01, time/batch = 15.6045s	
8724/28500 (epoch 15.305), train_loss = 1.21681881, grad/param norm = 1.6104e-01, time/batch = 15.4450s	
8725/28500 (epoch 15.307), train_loss = 1.15142261, grad/param norm = 1.6586e-01, time/batch = 15.3449s	
8726/28500 (epoch 15.309), train_loss = 1.14543604, grad/param norm = 1.6047e-01, time/batch = 15.5110s	
8727/28500 (epoch 15.311), train_loss = 1.18707598, grad/param norm = 1.5415e-01, time/batch = 15.5435s	
8728/28500 (epoch 15.312), train_loss = 1.10747617, grad/param norm = 1.4785e-01, time/batch = 15.5682s	
8729/28500 (epoch 15.314), train_loss = 1.22947573, grad/param norm = 1.7254e-01, time/batch = 15.3611s	
8730/28500 (epoch 15.316), train_loss = 1.17070836, grad/param norm = 1.5396e-01, time/batch = 15.2922s	
8731/28500 (epoch 15.318), train_loss = 1.22260112, grad/param norm = 1.6025e-01, time/batch = 15.6830s	
8732/28500 (epoch 15.319), train_loss = 1.11579990, grad/param norm = 1.5860e-01, time/batch = 15.4414s	
8733/28500 (epoch 15.321), train_loss = 1.11815578, grad/param norm = 1.7440e-01, time/batch = 15.3285s	
8734/28500 (epoch 15.323), train_loss = 1.10947912, grad/param norm = 1.7012e-01, time/batch = 15.4344s	
8735/28500 (epoch 15.325), train_loss = 1.29849020, grad/param norm = 1.7609e-01, time/batch = 15.4978s	
8736/28500 (epoch 15.326), train_loss = 1.14393886, grad/param norm = 1.6373e-01, time/batch = 15.3052s	
8737/28500 (epoch 15.328), train_loss = 0.95590119, grad/param norm = 1.4778e-01, time/batch = 15.5410s	
8738/28500 (epoch 15.330), train_loss = 1.06046212, grad/param norm = 1.5659e-01, time/batch = 15.5193s	
8739/28500 (epoch 15.332), train_loss = 1.12842953, grad/param norm = 1.4171e-01, time/batch = 15.2765s	
8740/28500 (epoch 15.333), train_loss = 0.95977965, grad/param norm = 1.4261e-01, time/batch = 15.5187s	
8741/28500 (epoch 15.335), train_loss = 1.00952559, grad/param norm = 1.4557e-01, time/batch = 15.6699s	
8742/28500 (epoch 15.337), train_loss = 1.06443794, grad/param norm = 1.4990e-01, time/batch = 15.2526s	
8743/28500 (epoch 15.339), train_loss = 0.98175968, grad/param norm = 1.3929e-01, time/batch = 15.1226s	
8744/28500 (epoch 15.340), train_loss = 1.17831286, grad/param norm = 1.7049e-01, time/batch = 15.1874s	
8745/28500 (epoch 15.342), train_loss = 1.12518116, grad/param norm = 1.6749e-01, time/batch = 15.0554s	
8746/28500 (epoch 15.344), train_loss = 1.09287627, grad/param norm = 1.7987e-01, time/batch = 15.1822s	
8747/28500 (epoch 15.346), train_loss = 0.91974464, grad/param norm = 1.3303e-01, time/batch = 15.4528s	
8748/28500 (epoch 15.347), train_loss = 1.12066571, grad/param norm = 1.4964e-01, time/batch = 15.2316s	
8749/28500 (epoch 15.349), train_loss = 1.08041937, grad/param norm = 1.4392e-01, time/batch = 15.3037s	
8750/28500 (epoch 15.351), train_loss = 1.03488565, grad/param norm = 1.4826e-01, time/batch = 20.0220s	
8751/28500 (epoch 15.353), train_loss = 1.18350256, grad/param norm = 1.6606e-01, time/batch = 22.3355s	
8752/28500 (epoch 15.354), train_loss = 1.00054664, grad/param norm = 1.5459e-01, time/batch = 15.1987s	
8753/28500 (epoch 15.356), train_loss = 1.02358783, grad/param norm = 1.4649e-01, time/batch = 15.1989s	
8754/28500 (epoch 15.358), train_loss = 1.13565649, grad/param norm = 1.5229e-01, time/batch = 15.3226s	
8755/28500 (epoch 15.360), train_loss = 1.14121377, grad/param norm = 1.6448e-01, time/batch = 15.3775s	
8756/28500 (epoch 15.361), train_loss = 1.05806531, grad/param norm = 1.5528e-01, time/batch = 15.5493s	
8757/28500 (epoch 15.363), train_loss = 1.00255700, grad/param norm = 1.4115e-01, time/batch = 15.5500s	
8758/28500 (epoch 15.365), train_loss = 1.10026577, grad/param norm = 1.6339e-01, time/batch = 15.0739s	
8759/28500 (epoch 15.367), train_loss = 1.12731303, grad/param norm = 1.6318e-01, time/batch = 15.0510s	
8760/28500 (epoch 15.368), train_loss = 1.09023032, grad/param norm = 1.5091e-01, time/batch = 15.3637s	
8761/28500 (epoch 15.370), train_loss = 1.11634211, grad/param norm = 1.5062e-01, time/batch = 15.5210s	
8762/28500 (epoch 15.372), train_loss = 0.97216281, grad/param norm = 1.4539e-01, time/batch = 15.4533s	
8763/28500 (epoch 15.374), train_loss = 1.10051900, grad/param norm = 1.6173e-01, time/batch = 15.2842s	
8764/28500 (epoch 15.375), train_loss = 1.26686178, grad/param norm = 1.6053e-01, time/batch = 15.3841s	
8765/28500 (epoch 15.377), train_loss = 1.02587377, grad/param norm = 1.4922e-01, time/batch = 15.2452s	
8766/28500 (epoch 15.379), train_loss = 0.88061767, grad/param norm = 1.3964e-01, time/batch = 15.2805s	
8767/28500 (epoch 15.381), train_loss = 1.06757653, grad/param norm = 1.3302e-01, time/batch = 15.5066s	
8768/28500 (epoch 15.382), train_loss = 1.06458905, grad/param norm = 1.5992e-01, time/batch = 15.4496s	
8769/28500 (epoch 15.384), train_loss = 0.99855204, grad/param norm = 1.4319e-01, time/batch = 15.5380s	
8770/28500 (epoch 15.386), train_loss = 0.98423990, grad/param norm = 1.5053e-01, time/batch = 15.3696s	
8771/28500 (epoch 15.388), train_loss = 1.20719226, grad/param norm = 1.6133e-01, time/batch = 15.3731s	
8772/28500 (epoch 15.389), train_loss = 1.01557224, grad/param norm = 1.4776e-01, time/batch = 15.4972s	
8773/28500 (epoch 15.391), train_loss = 1.02040505, grad/param norm = 1.4884e-01, time/batch = 15.5081s	
8774/28500 (epoch 15.393), train_loss = 0.99510312, grad/param norm = 1.5972e-01, time/batch = 15.4354s	
8775/28500 (epoch 15.395), train_loss = 1.28170438, grad/param norm = 1.6255e-01, time/batch = 15.4633s	
8776/28500 (epoch 15.396), train_loss = 1.23269089, grad/param norm = 1.7510e-01, time/batch = 15.1456s	
8777/28500 (epoch 15.398), train_loss = 0.92252023, grad/param norm = 1.6838e-01, time/batch = 15.4283s	
8778/28500 (epoch 15.400), train_loss = 1.12820148, grad/param norm = 1.8234e-01, time/batch = 15.2474s	
8779/28500 (epoch 15.402), train_loss = 1.15055388, grad/param norm = 1.6341e-01, time/batch = 15.2297s	
8780/28500 (epoch 15.404), train_loss = 1.23789845, grad/param norm = 1.7701e-01, time/batch = 15.3620s	
8781/28500 (epoch 15.405), train_loss = 1.23678307, grad/param norm = 1.6367e-01, time/batch = 15.4090s	
8782/28500 (epoch 15.407), train_loss = 1.13197654, grad/param norm = 1.5301e-01, time/batch = 15.0728s	
8783/28500 (epoch 15.409), train_loss = 1.13807629, grad/param norm = 1.5605e-01, time/batch = 15.1250s	
8784/28500 (epoch 15.411), train_loss = 1.24545769, grad/param norm = 1.5982e-01, time/batch = 15.0324s	
8785/28500 (epoch 15.412), train_loss = 1.25369098, grad/param norm = 1.8041e-01, time/batch = 15.3822s	
8786/28500 (epoch 15.414), train_loss = 1.16160412, grad/param norm = 1.6650e-01, time/batch = 15.4788s	
8787/28500 (epoch 15.416), train_loss = 1.05896992, grad/param norm = 1.6500e-01, time/batch = 15.5466s	
8788/28500 (epoch 15.418), train_loss = 1.13909364, grad/param norm = 1.5069e-01, time/batch = 15.5354s	
8789/28500 (epoch 15.419), train_loss = 1.27248441, grad/param norm = 1.6903e-01, time/batch = 15.6151s	
8790/28500 (epoch 15.421), train_loss = 1.20237345, grad/param norm = 1.5991e-01, time/batch = 15.3699s	
8791/28500 (epoch 15.423), train_loss = 1.23655701, grad/param norm = 1.7192e-01, time/batch = 15.6221s	
8792/28500 (epoch 15.425), train_loss = 1.18282892, grad/param norm = 2.0439e-01, time/batch = 15.2730s	
8793/28500 (epoch 15.426), train_loss = 1.13714419, grad/param norm = 1.7261e-01, time/batch = 15.4421s	
8794/28500 (epoch 15.428), train_loss = 1.35166093, grad/param norm = 1.7453e-01, time/batch = 15.5633s	
8795/28500 (epoch 15.430), train_loss = 1.25922857, grad/param norm = 1.5880e-01, time/batch = 15.4447s	
8796/28500 (epoch 15.432), train_loss = 1.19328938, grad/param norm = 1.6189e-01, time/batch = 15.5143s	
8797/28500 (epoch 15.433), train_loss = 1.19406682, grad/param norm = 1.7493e-01, time/batch = 15.3011s	
8798/28500 (epoch 15.435), train_loss = 1.13387524, grad/param norm = 1.7462e-01, time/batch = 15.2996s	
8799/28500 (epoch 15.437), train_loss = 1.01234936, grad/param norm = 1.4246e-01, time/batch = 15.3728s	
8800/28500 (epoch 15.439), train_loss = 1.07327168, grad/param norm = 1.4204e-01, time/batch = 15.4328s	
8801/28500 (epoch 15.440), train_loss = 1.33858859, grad/param norm = 1.7212e-01, time/batch = 15.2302s	
8802/28500 (epoch 15.442), train_loss = 1.06607583, grad/param norm = 1.7153e-01, time/batch = 15.2707s	
8803/28500 (epoch 15.444), train_loss = 0.98294667, grad/param norm = 1.4031e-01, time/batch = 15.4201s	
8804/28500 (epoch 15.446), train_loss = 0.93806810, grad/param norm = 1.4043e-01, time/batch = 15.5007s	
8805/28500 (epoch 15.447), train_loss = 0.96977480, grad/param norm = 1.4306e-01, time/batch = 15.3663s	
8806/28500 (epoch 15.449), train_loss = 1.06104491, grad/param norm = 1.4671e-01, time/batch = 15.2730s	
8807/28500 (epoch 15.451), train_loss = 1.10557255, grad/param norm = 1.5536e-01, time/batch = 15.3343s	
8808/28500 (epoch 15.453), train_loss = 1.09450074, grad/param norm = 1.4796e-01, time/batch = 15.6021s	
8809/28500 (epoch 15.454), train_loss = 1.06184345, grad/param norm = 1.4230e-01, time/batch = 15.5445s	
8810/28500 (epoch 15.456), train_loss = 1.17579498, grad/param norm = 1.6156e-01, time/batch = 15.5310s	
8811/28500 (epoch 15.458), train_loss = 1.09902828, grad/param norm = 1.6783e-01, time/batch = 15.3723s	
8812/28500 (epoch 15.460), train_loss = 1.16024597, grad/param norm = 1.5621e-01, time/batch = 15.2838s	
8813/28500 (epoch 15.461), train_loss = 1.07255587, grad/param norm = 1.6507e-01, time/batch = 15.3298s	
8814/28500 (epoch 15.463), train_loss = 1.00147712, grad/param norm = 1.3432e-01, time/batch = 15.3916s	
8815/28500 (epoch 15.465), train_loss = 0.96371083, grad/param norm = 1.6684e-01, time/batch = 15.6098s	
8816/28500 (epoch 15.467), train_loss = 1.12646845, grad/param norm = 1.5834e-01, time/batch = 15.6211s	
8817/28500 (epoch 15.468), train_loss = 0.99663977, grad/param norm = 1.2984e-01, time/batch = 15.4648s	
8818/28500 (epoch 15.470), train_loss = 1.04759662, grad/param norm = 1.4642e-01, time/batch = 15.4535s	
8819/28500 (epoch 15.472), train_loss = 1.08280438, grad/param norm = 1.5764e-01, time/batch = 15.5071s	
8820/28500 (epoch 15.474), train_loss = 1.34611978, grad/param norm = 1.7745e-01, time/batch = 15.5256s	
8821/28500 (epoch 15.475), train_loss = 1.03679907, grad/param norm = 1.5193e-01, time/batch = 15.5800s	
8822/28500 (epoch 15.477), train_loss = 1.10112684, grad/param norm = 1.5366e-01, time/batch = 15.4593s	
8823/28500 (epoch 15.479), train_loss = 1.17717032, grad/param norm = 1.5429e-01, time/batch = 15.1827s	
8824/28500 (epoch 15.481), train_loss = 1.10643694, grad/param norm = 1.6074e-01, time/batch = 15.6007s	
8825/28500 (epoch 15.482), train_loss = 1.01474368, grad/param norm = 1.5299e-01, time/batch = 15.4874s	
8826/28500 (epoch 15.484), train_loss = 1.00299087, grad/param norm = 1.4800e-01, time/batch = 15.6330s	
8827/28500 (epoch 15.486), train_loss = 0.92792086, grad/param norm = 1.5949e-01, time/batch = 15.5043s	
8828/28500 (epoch 15.488), train_loss = 1.13724998, grad/param norm = 1.4560e-01, time/batch = 15.5532s	
8829/28500 (epoch 15.489), train_loss = 1.20363857, grad/param norm = 1.5283e-01, time/batch = 15.4799s	
8830/28500 (epoch 15.491), train_loss = 1.07085153, grad/param norm = 1.5613e-01, time/batch = 15.3537s	
8831/28500 (epoch 15.493), train_loss = 1.05666703, grad/param norm = 1.5151e-01, time/batch = 15.3667s	
8832/28500 (epoch 15.495), train_loss = 1.06534528, grad/param norm = 1.4524e-01, time/batch = 15.2963s	
8833/28500 (epoch 15.496), train_loss = 1.07135681, grad/param norm = 1.6144e-01, time/batch = 15.3684s	
8834/28500 (epoch 15.498), train_loss = 1.15986162, grad/param norm = 1.5816e-01, time/batch = 15.4861s	
8835/28500 (epoch 15.500), train_loss = 1.07387789, grad/param norm = 1.5208e-01, time/batch = 15.5079s	
8836/28500 (epoch 15.502), train_loss = 1.20732456, grad/param norm = 1.5963e-01, time/batch = 15.5512s	
8837/28500 (epoch 15.504), train_loss = 1.14550729, grad/param norm = 1.5327e-01, time/batch = 15.5540s	
8838/28500 (epoch 15.505), train_loss = 1.02548809, grad/param norm = 1.4296e-01, time/batch = 15.5916s	
8839/28500 (epoch 15.507), train_loss = 1.24617332, grad/param norm = 1.8389e-01, time/batch = 15.5913s	
8840/28500 (epoch 15.509), train_loss = 1.11180320, grad/param norm = 1.5018e-01, time/batch = 15.5831s	
8841/28500 (epoch 15.511), train_loss = 1.10702047, grad/param norm = 1.6307e-01, time/batch = 15.6073s	
8842/28500 (epoch 15.512), train_loss = 1.11627744, grad/param norm = 1.4594e-01, time/batch = 15.3652s	
8843/28500 (epoch 15.514), train_loss = 1.02093696, grad/param norm = 1.5137e-01, time/batch = 15.3586s	
8844/28500 (epoch 15.516), train_loss = 1.03851197, grad/param norm = 1.3938e-01, time/batch = 15.2885s	
8845/28500 (epoch 15.518), train_loss = 1.14766169, grad/param norm = 1.5717e-01, time/batch = 15.0634s	
8846/28500 (epoch 15.519), train_loss = 1.17670772, grad/param norm = 1.5383e-01, time/batch = 15.3502s	
8847/28500 (epoch 15.521), train_loss = 1.26999409, grad/param norm = 1.7394e-01, time/batch = 15.2621s	
8848/28500 (epoch 15.523), train_loss = 1.16970397, grad/param norm = 1.6558e-01, time/batch = 15.4800s	
8849/28500 (epoch 15.525), train_loss = 1.21474747, grad/param norm = 1.6853e-01, time/batch = 15.1969s	
8850/28500 (epoch 15.526), train_loss = 1.17945513, grad/param norm = 1.6601e-01, time/batch = 15.3496s	
8851/28500 (epoch 15.528), train_loss = 1.19678200, grad/param norm = 1.6307e-01, time/batch = 15.5478s	
8852/28500 (epoch 15.530), train_loss = 1.23277705, grad/param norm = 1.5706e-01, time/batch = 15.5276s	
8853/28500 (epoch 15.532), train_loss = 1.06911687, grad/param norm = 1.4909e-01, time/batch = 15.2830s	
8854/28500 (epoch 15.533), train_loss = 1.20163692, grad/param norm = 1.7155e-01, time/batch = 15.4367s	
8855/28500 (epoch 15.535), train_loss = 0.94788300, grad/param norm = 1.4089e-01, time/batch = 15.5477s	
8856/28500 (epoch 15.537), train_loss = 0.96429560, grad/param norm = 1.5183e-01, time/batch = 15.5177s	
8857/28500 (epoch 15.539), train_loss = 0.97466245, grad/param norm = 1.6515e-01, time/batch = 15.2934s	
8858/28500 (epoch 15.540), train_loss = 1.13194613, grad/param norm = 1.5427e-01, time/batch = 15.1986s	
8859/28500 (epoch 15.542), train_loss = 1.22564223, grad/param norm = 1.6944e-01, time/batch = 15.2145s	
8860/28500 (epoch 15.544), train_loss = 1.27016643, grad/param norm = 1.6273e-01, time/batch = 15.3510s	
8861/28500 (epoch 15.546), train_loss = 1.11341490, grad/param norm = 1.6223e-01, time/batch = 15.5006s	
8862/28500 (epoch 15.547), train_loss = 1.11428368, grad/param norm = 1.6034e-01, time/batch = 15.5470s	
8863/28500 (epoch 15.549), train_loss = 0.95741392, grad/param norm = 1.3619e-01, time/batch = 15.4553s	
8864/28500 (epoch 15.551), train_loss = 1.14979760, grad/param norm = 1.7172e-01, time/batch = 15.3619s	
8865/28500 (epoch 15.553), train_loss = 1.32241511, grad/param norm = 1.8025e-01, time/batch = 15.4573s	
8866/28500 (epoch 15.554), train_loss = 1.09125875, grad/param norm = 1.5283e-01, time/batch = 15.3154s	
8867/28500 (epoch 15.556), train_loss = 1.15814288, grad/param norm = 1.7579e-01, time/batch = 15.5453s	
8868/28500 (epoch 15.558), train_loss = 1.14993688, grad/param norm = 1.4983e-01, time/batch = 15.2797s	
8869/28500 (epoch 15.560), train_loss = 1.15707651, grad/param norm = 1.6989e-01, time/batch = 15.2930s	
8870/28500 (epoch 15.561), train_loss = 1.20020448, grad/param norm = 1.7423e-01, time/batch = 15.4353s	
8871/28500 (epoch 15.563), train_loss = 1.32880312, grad/param norm = 1.8132e-01, time/batch = 15.5137s	
8872/28500 (epoch 15.565), train_loss = 1.10713607, grad/param norm = 1.5670e-01, time/batch = 15.3262s	
8873/28500 (epoch 15.567), train_loss = 0.99184720, grad/param norm = 1.4621e-01, time/batch = 15.1808s	
8874/28500 (epoch 15.568), train_loss = 1.15150104, grad/param norm = 1.6833e-01, time/batch = 15.3229s	
8875/28500 (epoch 15.570), train_loss = 1.08265775, grad/param norm = 1.5147e-01, time/batch = 15.5741s	
8876/28500 (epoch 15.572), train_loss = 1.07849921, grad/param norm = 1.5488e-01, time/batch = 15.4949s	
8877/28500 (epoch 15.574), train_loss = 1.07515129, grad/param norm = 1.5936e-01, time/batch = 15.2703s	
8878/28500 (epoch 15.575), train_loss = 1.07911962, grad/param norm = 1.4424e-01, time/batch = 15.3006s	
8879/28500 (epoch 15.577), train_loss = 1.15013295, grad/param norm = 1.4969e-01, time/batch = 15.5105s	
8880/28500 (epoch 15.579), train_loss = 1.19561791, grad/param norm = 1.6901e-01, time/batch = 15.5382s	
8881/28500 (epoch 15.581), train_loss = 1.06215598, grad/param norm = 1.6835e-01, time/batch = 15.3675s	
8882/28500 (epoch 15.582), train_loss = 1.21341250, grad/param norm = 1.5928e-01, time/batch = 15.6013s	
8883/28500 (epoch 15.584), train_loss = 1.08133599, grad/param norm = 1.7183e-01, time/batch = 15.2978s	
8884/28500 (epoch 15.586), train_loss = 1.02615818, grad/param norm = 1.3942e-01, time/batch = 15.1401s	
8885/28500 (epoch 15.588), train_loss = 1.02670248, grad/param norm = 1.4002e-01, time/batch = 15.6004s	
8886/28500 (epoch 15.589), train_loss = 1.16689212, grad/param norm = 1.6808e-01, time/batch = 15.3770s	
8887/28500 (epoch 15.591), train_loss = 1.15480145, grad/param norm = 1.4896e-01, time/batch = 15.4965s	
8888/28500 (epoch 15.593), train_loss = 1.05668430, grad/param norm = 1.3632e-01, time/batch = 15.6207s	
8889/28500 (epoch 15.595), train_loss = 1.34648838, grad/param norm = 1.7992e-01, time/batch = 15.4487s	
8890/28500 (epoch 15.596), train_loss = 1.33765598, grad/param norm = 1.7919e-01, time/batch = 15.3551s	
8891/28500 (epoch 15.598), train_loss = 1.14800603, grad/param norm = 1.5681e-01, time/batch = 15.2257s	
8892/28500 (epoch 15.600), train_loss = 1.13926273, grad/param norm = 1.7420e-01, time/batch = 15.5158s	
8893/28500 (epoch 15.602), train_loss = 1.23010756, grad/param norm = 1.6797e-01, time/batch = 15.3533s	
8894/28500 (epoch 15.604), train_loss = 1.22495149, grad/param norm = 1.6699e-01, time/batch = 15.6125s	
8895/28500 (epoch 15.605), train_loss = 1.16821552, grad/param norm = 1.7788e-01, time/batch = 15.4514s	
8896/28500 (epoch 15.607), train_loss = 1.21963008, grad/param norm = 1.5309e-01, time/batch = 15.5154s	
8897/28500 (epoch 15.609), train_loss = 1.13364998, grad/param norm = 1.6376e-01, time/batch = 15.6260s	
8898/28500 (epoch 15.611), train_loss = 1.12060260, grad/param norm = 1.5433e-01, time/batch = 15.4694s	
8899/28500 (epoch 15.612), train_loss = 1.18173359, grad/param norm = 1.6460e-01, time/batch = 15.5912s	
8900/28500 (epoch 15.614), train_loss = 1.17196286, grad/param norm = 1.5925e-01, time/batch = 15.5765s	
8901/28500 (epoch 15.616), train_loss = 1.07110043, grad/param norm = 1.5327e-01, time/batch = 15.5880s	
8902/28500 (epoch 15.618), train_loss = 1.07798368, grad/param norm = 1.5143e-01, time/batch = 15.4658s	
8903/28500 (epoch 15.619), train_loss = 1.31121207, grad/param norm = 1.7362e-01, time/batch = 15.5150s	
8904/28500 (epoch 15.621), train_loss = 0.92832110, grad/param norm = 1.3664e-01, time/batch = 15.6301s	
8905/28500 (epoch 15.623), train_loss = 1.23924412, grad/param norm = 1.6702e-01, time/batch = 15.6797s	
8906/28500 (epoch 15.625), train_loss = 0.99408731, grad/param norm = 1.5164e-01, time/batch = 15.4913s	
8907/28500 (epoch 15.626), train_loss = 0.87057379, grad/param norm = 1.2967e-01, time/batch = 15.4757s	
8908/28500 (epoch 15.628), train_loss = 1.05095575, grad/param norm = 1.5082e-01, time/batch = 15.5535s	
8909/28500 (epoch 15.630), train_loss = 0.97491023, grad/param norm = 1.4176e-01, time/batch = 15.5462s	
8910/28500 (epoch 15.632), train_loss = 1.19235581, grad/param norm = 1.5732e-01, time/batch = 15.5316s	
8911/28500 (epoch 15.633), train_loss = 1.25791737, grad/param norm = 1.5104e-01, time/batch = 15.5968s	
8912/28500 (epoch 15.635), train_loss = 1.26796085, grad/param norm = 1.7287e-01, time/batch = 15.5257s	
8913/28500 (epoch 15.637), train_loss = 1.14050386, grad/param norm = 1.5177e-01, time/batch = 15.4310s	
8914/28500 (epoch 15.639), train_loss = 0.99209276, grad/param norm = 1.3702e-01, time/batch = 15.5870s	
8915/28500 (epoch 15.640), train_loss = 1.02996834, grad/param norm = 1.4442e-01, time/batch = 15.5392s	
8916/28500 (epoch 15.642), train_loss = 1.11582106, grad/param norm = 1.4163e-01, time/batch = 15.2925s	
8917/28500 (epoch 15.644), train_loss = 1.19536683, grad/param norm = 1.4746e-01, time/batch = 15.4624s	
8918/28500 (epoch 15.646), train_loss = 1.00710282, grad/param norm = 1.4060e-01, time/batch = 15.4671s	
8919/28500 (epoch 15.647), train_loss = 1.02120046, grad/param norm = 1.4638e-01, time/batch = 15.6136s	
8920/28500 (epoch 15.649), train_loss = 0.99453597, grad/param norm = 1.4893e-01, time/batch = 15.6335s	
8921/28500 (epoch 15.651), train_loss = 0.97212141, grad/param norm = 1.3572e-01, time/batch = 15.6305s	
8922/28500 (epoch 15.653), train_loss = 0.99577392, grad/param norm = 1.4109e-01, time/batch = 15.5818s	
8923/28500 (epoch 15.654), train_loss = 1.11056351, grad/param norm = 1.6009e-01, time/batch = 15.3716s	
8924/28500 (epoch 15.656), train_loss = 1.02949551, grad/param norm = 1.5713e-01, time/batch = 15.4383s	
8925/28500 (epoch 15.658), train_loss = 1.11934937, grad/param norm = 1.6066e-01, time/batch = 15.5373s	
8926/28500 (epoch 15.660), train_loss = 1.11517299, grad/param norm = 1.4421e-01, time/batch = 15.6243s	
8927/28500 (epoch 15.661), train_loss = 1.27492225, grad/param norm = 1.6957e-01, time/batch = 15.4793s	
8928/28500 (epoch 15.663), train_loss = 1.29538419, grad/param norm = 1.6219e-01, time/batch = 15.4674s	
8929/28500 (epoch 15.665), train_loss = 1.10247267, grad/param norm = 1.5043e-01, time/batch = 15.3000s	
8930/28500 (epoch 15.667), train_loss = 1.11929145, grad/param norm = 1.6213e-01, time/batch = 15.2150s	
8931/28500 (epoch 15.668), train_loss = 1.09748783, grad/param norm = 1.4784e-01, time/batch = 15.2096s	
8932/28500 (epoch 15.670), train_loss = 1.12481215, grad/param norm = 1.5754e-01, time/batch = 15.2775s	
8933/28500 (epoch 15.672), train_loss = 1.06297072, grad/param norm = 1.5092e-01, time/batch = 15.2234s	
8934/28500 (epoch 15.674), train_loss = 0.90919628, grad/param norm = 1.4377e-01, time/batch = 15.2450s	
8935/28500 (epoch 15.675), train_loss = 0.97636000, grad/param norm = 1.4742e-01, time/batch = 15.5182s	
8936/28500 (epoch 15.677), train_loss = 1.07897051, grad/param norm = 1.4588e-01, time/batch = 15.2174s	
8937/28500 (epoch 15.679), train_loss = 1.06255686, grad/param norm = 1.5348e-01, time/batch = 15.2744s	
8938/28500 (epoch 15.681), train_loss = 1.17750630, grad/param norm = 1.5223e-01, time/batch = 15.4018s	
8939/28500 (epoch 15.682), train_loss = 1.06750986, grad/param norm = 1.5526e-01, time/batch = 15.5245s	
8940/28500 (epoch 15.684), train_loss = 1.17902946, grad/param norm = 1.7383e-01, time/batch = 15.3390s	
8941/28500 (epoch 15.686), train_loss = 1.04814281, grad/param norm = 1.6151e-01, time/batch = 15.4525s	
8942/28500 (epoch 15.688), train_loss = 0.98879302, grad/param norm = 1.3519e-01, time/batch = 15.3873s	
8943/28500 (epoch 15.689), train_loss = 1.09525930, grad/param norm = 1.5431e-01, time/batch = 15.5448s	
8944/28500 (epoch 15.691), train_loss = 1.18058613, grad/param norm = 1.8123e-01, time/batch = 15.3030s	
8945/28500 (epoch 15.693), train_loss = 1.05926839, grad/param norm = 1.5356e-01, time/batch = 15.2688s	
8946/28500 (epoch 15.695), train_loss = 0.90411578, grad/param norm = 1.7108e-01, time/batch = 15.0475s	
8947/28500 (epoch 15.696), train_loss = 1.08655932, grad/param norm = 1.6157e-01, time/batch = 15.6869s	
8948/28500 (epoch 15.698), train_loss = 1.08819591, grad/param norm = 1.5252e-01, time/batch = 15.5593s	
8949/28500 (epoch 15.700), train_loss = 1.14770789, grad/param norm = 1.5578e-01, time/batch = 15.5040s	
8950/28500 (epoch 15.702), train_loss = 1.18884248, grad/param norm = 1.7141e-01, time/batch = 15.3119s	
8951/28500 (epoch 15.704), train_loss = 1.15300322, grad/param norm = 1.5873e-01, time/batch = 15.4400s	
8952/28500 (epoch 15.705), train_loss = 1.22733248, grad/param norm = 1.7670e-01, time/batch = 15.2218s	
8953/28500 (epoch 15.707), train_loss = 1.07108292, grad/param norm = 1.6947e-01, time/batch = 15.4367s	
8954/28500 (epoch 15.709), train_loss = 1.24293323, grad/param norm = 1.7105e-01, time/batch = 15.2645s	
8955/28500 (epoch 15.711), train_loss = 1.03000263, grad/param norm = 1.7297e-01, time/batch = 15.2979s	
8956/28500 (epoch 15.712), train_loss = 1.16839238, grad/param norm = 1.6346e-01, time/batch = 15.1334s	
8957/28500 (epoch 15.714), train_loss = 1.22017512, grad/param norm = 1.6467e-01, time/batch = 15.5422s	
8958/28500 (epoch 15.716), train_loss = 1.09286722, grad/param norm = 1.6093e-01, time/batch = 15.4281s	
8959/28500 (epoch 15.718), train_loss = 1.09341771, grad/param norm = 1.5215e-01, time/batch = 15.2972s	
8960/28500 (epoch 15.719), train_loss = 1.13315457, grad/param norm = 1.6070e-01, time/batch = 15.3198s	
8961/28500 (epoch 15.721), train_loss = 0.92076678, grad/param norm = 1.4253e-01, time/batch = 15.5589s	
8962/28500 (epoch 15.723), train_loss = 1.11208413, grad/param norm = 1.6524e-01, time/batch = 15.3545s	
8963/28500 (epoch 15.725), train_loss = 1.20866726, grad/param norm = 1.4459e-01, time/batch = 15.3033s	
8964/28500 (epoch 15.726), train_loss = 1.13100851, grad/param norm = 1.6243e-01, time/batch = 15.3701s	
8965/28500 (epoch 15.728), train_loss = 0.98040977, grad/param norm = 1.3451e-01, time/batch = 15.3943s	
8966/28500 (epoch 15.730), train_loss = 1.11944574, grad/param norm = 1.6437e-01, time/batch = 15.4023s	
8967/28500 (epoch 15.732), train_loss = 0.91675835, grad/param norm = 1.3497e-01, time/batch = 15.3280s	
8968/28500 (epoch 15.733), train_loss = 0.93335440, grad/param norm = 1.3441e-01, time/batch = 15.2678s	
8969/28500 (epoch 15.735), train_loss = 0.95808687, grad/param norm = 1.4298e-01, time/batch = 15.5021s	
8970/28500 (epoch 15.737), train_loss = 0.88508042, grad/param norm = 1.2633e-01, time/batch = 15.4831s	
8971/28500 (epoch 15.739), train_loss = 1.07844636, grad/param norm = 1.6396e-01, time/batch = 15.3024s	
8972/28500 (epoch 15.740), train_loss = 1.10962126, grad/param norm = 1.4867e-01, time/batch = 15.6014s	
8973/28500 (epoch 15.742), train_loss = 1.01522356, grad/param norm = 1.4720e-01, time/batch = 15.3176s	
8974/28500 (epoch 15.744), train_loss = 1.15214044, grad/param norm = 1.6898e-01, time/batch = 15.6334s	
8975/28500 (epoch 15.746), train_loss = 0.99764117, grad/param norm = 1.4703e-01, time/batch = 15.5419s	
8976/28500 (epoch 15.747), train_loss = 1.01576483, grad/param norm = 1.4686e-01, time/batch = 15.6814s	
8977/28500 (epoch 15.749), train_loss = 1.23455407, grad/param norm = 1.8322e-01, time/batch = 15.2912s	
8978/28500 (epoch 15.751), train_loss = 1.00520621, grad/param norm = 1.7251e-01, time/batch = 15.4727s	
8979/28500 (epoch 15.753), train_loss = 1.02167217, grad/param norm = 1.4273e-01, time/batch = 15.4344s	
8980/28500 (epoch 15.754), train_loss = 0.95208590, grad/param norm = 1.4376e-01, time/batch = 15.5023s	
8981/28500 (epoch 15.756), train_loss = 1.22710659, grad/param norm = 1.6997e-01, time/batch = 18.3105s	
8982/28500 (epoch 15.758), train_loss = 1.17462371, grad/param norm = 1.6634e-01, time/batch = 25.2565s	
8983/28500 (epoch 15.760), train_loss = 0.96771647, grad/param norm = 1.4725e-01, time/batch = 15.1990s	
8984/28500 (epoch 15.761), train_loss = 0.98544152, grad/param norm = 1.8387e-01, time/batch = 15.2145s	
8985/28500 (epoch 15.763), train_loss = 0.88586547, grad/param norm = 1.4486e-01, time/batch = 15.2206s	
8986/28500 (epoch 15.765), train_loss = 1.03902295, grad/param norm = 1.4409e-01, time/batch = 15.4545s	
8987/28500 (epoch 15.767), train_loss = 0.92069183, grad/param norm = 1.3714e-01, time/batch = 15.5276s	
8988/28500 (epoch 15.768), train_loss = 1.18281694, grad/param norm = 1.6773e-01, time/batch = 15.5398s	
8989/28500 (epoch 15.770), train_loss = 0.94099339, grad/param norm = 1.4159e-01, time/batch = 15.3052s	
8990/28500 (epoch 15.772), train_loss = 0.83834029, grad/param norm = 1.3001e-01, time/batch = 15.2904s	
8991/28500 (epoch 15.774), train_loss = 1.09719487, grad/param norm = 1.5969e-01, time/batch = 15.6172s	
8992/28500 (epoch 15.775), train_loss = 1.16155550, grad/param norm = 1.4391e-01, time/batch = 15.3338s	
8993/28500 (epoch 15.777), train_loss = 1.15555235, grad/param norm = 1.6368e-01, time/batch = 15.3502s	
8994/28500 (epoch 15.779), train_loss = 0.92269387, grad/param norm = 1.2924e-01, time/batch = 15.0631s	
8995/28500 (epoch 15.781), train_loss = 1.10106620, grad/param norm = 1.6244e-01, time/batch = 15.1748s	
8996/28500 (epoch 15.782), train_loss = 1.15754186, grad/param norm = 1.6392e-01, time/batch = 15.5132s	
8997/28500 (epoch 15.784), train_loss = 0.91284065, grad/param norm = 1.3156e-01, time/batch = 15.6213s	
8998/28500 (epoch 15.786), train_loss = 0.97198355, grad/param norm = 1.4399e-01, time/batch = 15.5627s	
8999/28500 (epoch 15.788), train_loss = 1.06512661, grad/param norm = 1.4712e-01, time/batch = 15.2920s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch15.79_1.6458.t7	
9000/28500 (epoch 15.789), train_loss = 0.84651110, grad/param norm = 1.7465e-01, time/batch = 15.4528s	
9001/28500 (epoch 15.791), train_loss = 1.29027539, grad/param norm = 1.7222e-01, time/batch = 15.7277s	
9002/28500 (epoch 15.793), train_loss = 1.06222125, grad/param norm = 1.5370e-01, time/batch = 15.4414s	
9003/28500 (epoch 15.795), train_loss = 1.11060714, grad/param norm = 1.4724e-01, time/batch = 15.3001s	
9004/28500 (epoch 15.796), train_loss = 0.97892588, grad/param norm = 1.5075e-01, time/batch = 15.4030s	
9005/28500 (epoch 15.798), train_loss = 0.93238667, grad/param norm = 1.5037e-01, time/batch = 15.5401s	
9006/28500 (epoch 15.800), train_loss = 0.98392958, grad/param norm = 1.7769e-01, time/batch = 15.6242s	
9007/28500 (epoch 15.802), train_loss = 1.07224512, grad/param norm = 1.8796e-01, time/batch = 15.6838s	
9008/28500 (epoch 15.804), train_loss = 1.12173933, grad/param norm = 1.4516e-01, time/batch = 15.6302s	
9009/28500 (epoch 15.805), train_loss = 1.07643112, grad/param norm = 1.5214e-01, time/batch = 15.6139s	
9010/28500 (epoch 15.807), train_loss = 1.13531327, grad/param norm = 1.5915e-01, time/batch = 15.3755s	
9011/28500 (epoch 15.809), train_loss = 1.03865712, grad/param norm = 1.5209e-01, time/batch = 15.4267s	
9012/28500 (epoch 15.811), train_loss = 1.12886305, grad/param norm = 1.6134e-01, time/batch = 15.3482s	
9013/28500 (epoch 15.812), train_loss = 1.11766646, grad/param norm = 1.7086e-01, time/batch = 15.4327s	
9014/28500 (epoch 15.814), train_loss = 1.06592591, grad/param norm = 1.5562e-01, time/batch = 15.5216s	
9015/28500 (epoch 15.816), train_loss = 1.20896530, grad/param norm = 1.9072e-01, time/batch = 15.4609s	
9016/28500 (epoch 15.818), train_loss = 1.17274347, grad/param norm = 1.4851e-01, time/batch = 15.4592s	
9017/28500 (epoch 15.819), train_loss = 1.07791871, grad/param norm = 1.4598e-01, time/batch = 15.5768s	
9018/28500 (epoch 15.821), train_loss = 1.04567560, grad/param norm = 1.5565e-01, time/batch = 15.5520s	
9019/28500 (epoch 15.823), train_loss = 1.24987766, grad/param norm = 1.8815e-01, time/batch = 15.2328s	
9020/28500 (epoch 15.825), train_loss = 1.06043105, grad/param norm = 1.6096e-01, time/batch = 15.3521s	
9021/28500 (epoch 15.826), train_loss = 1.11121213, grad/param norm = 1.7268e-01, time/batch = 15.6234s	
9022/28500 (epoch 15.828), train_loss = 0.96565821, grad/param norm = 1.5749e-01, time/batch = 15.6593s	
9023/28500 (epoch 15.830), train_loss = 1.03080885, grad/param norm = 1.5161e-01, time/batch = 15.5429s	
9024/28500 (epoch 15.832), train_loss = 1.11340348, grad/param norm = 1.8177e-01, time/batch = 15.6097s	
9025/28500 (epoch 15.833), train_loss = 1.23324865, grad/param norm = 1.6225e-01, time/batch = 15.4855s	
9026/28500 (epoch 15.835), train_loss = 1.04294567, grad/param norm = 1.5835e-01, time/batch = 15.3096s	
9027/28500 (epoch 15.837), train_loss = 0.94587045, grad/param norm = 1.5019e-01, time/batch = 15.5202s	
9028/28500 (epoch 15.839), train_loss = 1.21007402, grad/param norm = 1.5942e-01, time/batch = 15.2289s	
9029/28500 (epoch 15.840), train_loss = 1.23110822, grad/param norm = 1.6694e-01, time/batch = 15.4739s	
9030/28500 (epoch 15.842), train_loss = 1.17964826, grad/param norm = 1.6637e-01, time/batch = 15.5436s	
9031/28500 (epoch 15.844), train_loss = 1.11405662, grad/param norm = 1.6190e-01, time/batch = 15.8473s	
9032/28500 (epoch 15.846), train_loss = 1.24162309, grad/param norm = 1.6960e-01, time/batch = 15.5768s	
9033/28500 (epoch 15.847), train_loss = 1.04176402, grad/param norm = 1.6114e-01, time/batch = 15.4863s	
9034/28500 (epoch 15.849), train_loss = 1.03985916, grad/param norm = 1.5387e-01, time/batch = 15.5047s	
9035/28500 (epoch 15.851), train_loss = 0.92145049, grad/param norm = 1.3734e-01, time/batch = 15.3414s	
9036/28500 (epoch 15.853), train_loss = 1.10537050, grad/param norm = 1.5374e-01, time/batch = 15.4380s	
9037/28500 (epoch 15.854), train_loss = 1.11774395, grad/param norm = 1.6122e-01, time/batch = 15.4339s	
9038/28500 (epoch 15.856), train_loss = 1.22287717, grad/param norm = 1.9798e-01, time/batch = 15.4043s	
9039/28500 (epoch 15.858), train_loss = 0.98514686, grad/param norm = 1.4226e-01, time/batch = 15.5686s	
9040/28500 (epoch 15.860), train_loss = 1.08908691, grad/param norm = 1.6833e-01, time/batch = 15.2673s	
9041/28500 (epoch 15.861), train_loss = 1.13756675, grad/param norm = 1.7121e-01, time/batch = 15.3885s	
9042/28500 (epoch 15.863), train_loss = 1.18277311, grad/param norm = 1.7959e-01, time/batch = 15.3067s	
9043/28500 (epoch 15.865), train_loss = 1.08343479, grad/param norm = 1.6745e-01, time/batch = 15.3573s	
9044/28500 (epoch 15.867), train_loss = 1.14582851, grad/param norm = 1.6916e-01, time/batch = 15.4316s	
9045/28500 (epoch 15.868), train_loss = 0.97168983, grad/param norm = 1.4585e-01, time/batch = 15.4618s	
9046/28500 (epoch 15.870), train_loss = 0.91804974, grad/param norm = 1.4752e-01, time/batch = 15.4190s	
9047/28500 (epoch 15.872), train_loss = 1.14060104, grad/param norm = 1.7151e-01, time/batch = 15.3444s	
9048/28500 (epoch 15.874), train_loss = 1.07092717, grad/param norm = 1.7290e-01, time/batch = 15.0447s	
9049/28500 (epoch 15.875), train_loss = 1.19361854, grad/param norm = 1.6707e-01, time/batch = 15.0283s	
9050/28500 (epoch 15.877), train_loss = 1.12936652, grad/param norm = 1.5225e-01, time/batch = 15.3999s	
9051/28500 (epoch 15.879), train_loss = 1.10126779, grad/param norm = 1.4526e-01, time/batch = 15.4134s	
9052/28500 (epoch 15.881), train_loss = 1.09464297, grad/param norm = 1.6635e-01, time/batch = 15.4391s	
9053/28500 (epoch 15.882), train_loss = 1.02089184, grad/param norm = 1.4122e-01, time/batch = 15.5637s	
9054/28500 (epoch 15.884), train_loss = 1.10841755, grad/param norm = 1.6480e-01, time/batch = 15.2841s	
9055/28500 (epoch 15.886), train_loss = 1.05552320, grad/param norm = 1.4908e-01, time/batch = 15.4713s	
9056/28500 (epoch 15.888), train_loss = 0.97890846, grad/param norm = 1.5462e-01, time/batch = 15.3819s	
9057/28500 (epoch 15.889), train_loss = 1.10789672, grad/param norm = 1.6241e-01, time/batch = 15.2044s	
9058/28500 (epoch 15.891), train_loss = 1.10932434, grad/param norm = 1.5696e-01, time/batch = 15.3487s	
9059/28500 (epoch 15.893), train_loss = 1.03296474, grad/param norm = 1.5815e-01, time/batch = 15.5940s	
9060/28500 (epoch 15.895), train_loss = 1.27634919, grad/param norm = 1.7848e-01, time/batch = 15.3635s	
9061/28500 (epoch 15.896), train_loss = 1.16776754, grad/param norm = 1.6739e-01, time/batch = 15.3551s	
9062/28500 (epoch 15.898), train_loss = 1.07490641, grad/param norm = 1.5288e-01, time/batch = 15.1223s	
9063/28500 (epoch 15.900), train_loss = 0.93844137, grad/param norm = 1.5751e-01, time/batch = 15.2225s	
9064/28500 (epoch 15.902), train_loss = 0.95583710, grad/param norm = 1.5955e-01, time/batch = 15.3648s	
9065/28500 (epoch 15.904), train_loss = 1.00976867, grad/param norm = 1.4465e-01, time/batch = 15.3275s	
9066/28500 (epoch 15.905), train_loss = 1.11625828, grad/param norm = 1.6333e-01, time/batch = 15.1980s	
9067/28500 (epoch 15.907), train_loss = 1.07005312, grad/param norm = 1.5196e-01, time/batch = 15.2711s	
9068/28500 (epoch 15.909), train_loss = 0.98428467, grad/param norm = 1.6895e-01, time/batch = 15.1299s	
9069/28500 (epoch 15.911), train_loss = 0.99619354, grad/param norm = 1.4200e-01, time/batch = 15.4521s	
9070/28500 (epoch 15.912), train_loss = 0.86992463, grad/param norm = 1.3583e-01, time/batch = 15.4047s	
9071/28500 (epoch 15.914), train_loss = 1.18212854, grad/param norm = 1.4724e-01, time/batch = 15.4757s	
9072/28500 (epoch 15.916), train_loss = 1.12627496, grad/param norm = 1.7916e-01, time/batch = 15.5248s	
9073/28500 (epoch 15.918), train_loss = 1.10074989, grad/param norm = 1.6017e-01, time/batch = 15.4474s	
9074/28500 (epoch 15.919), train_loss = 1.07538107, grad/param norm = 1.4425e-01, time/batch = 15.4731s	
9075/28500 (epoch 15.921), train_loss = 1.22244493, grad/param norm = 1.9264e-01, time/batch = 15.3617s	
9076/28500 (epoch 15.923), train_loss = 1.10247407, grad/param norm = 1.7970e-01, time/batch = 15.3687s	
9077/28500 (epoch 15.925), train_loss = 1.01178920, grad/param norm = 1.6866e-01, time/batch = 15.2026s	
9078/28500 (epoch 15.926), train_loss = 1.05203110, grad/param norm = 1.4592e-01, time/batch = 15.3241s	
9079/28500 (epoch 15.928), train_loss = 1.02527979, grad/param norm = 1.5455e-01, time/batch = 15.3549s	
9080/28500 (epoch 15.930), train_loss = 0.84120782, grad/param norm = 1.3258e-01, time/batch = 15.2222s	
9081/28500 (epoch 15.932), train_loss = 0.86368268, grad/param norm = 1.2911e-01, time/batch = 15.3717s	
9082/28500 (epoch 15.933), train_loss = 1.16420509, grad/param norm = 1.6192e-01, time/batch = 15.3801s	
9083/28500 (epoch 15.935), train_loss = 1.17673078, grad/param norm = 1.6904e-01, time/batch = 15.2893s	
9084/28500 (epoch 15.937), train_loss = 1.20813973, grad/param norm = 1.7890e-01, time/batch = 15.4473s	
9085/28500 (epoch 15.939), train_loss = 1.26875540, grad/param norm = 1.7486e-01, time/batch = 15.4125s	
9086/28500 (epoch 15.940), train_loss = 0.95999018, grad/param norm = 1.4429e-01, time/batch = 15.5246s	
9087/28500 (epoch 15.942), train_loss = 1.13302152, grad/param norm = 1.6560e-01, time/batch = 15.2908s	
9088/28500 (epoch 15.944), train_loss = 1.06978263, grad/param norm = 1.6258e-01, time/batch = 15.2247s	
9089/28500 (epoch 15.946), train_loss = 1.19442274, grad/param norm = 1.5587e-01, time/batch = 15.2672s	
9090/28500 (epoch 15.947), train_loss = 1.39090146, grad/param norm = 1.8300e-01, time/batch = 15.1333s	
9091/28500 (epoch 15.949), train_loss = 1.00712614, grad/param norm = 1.5082e-01, time/batch = 15.6020s	
9092/28500 (epoch 15.951), train_loss = 1.25148037, grad/param norm = 1.8920e-01, time/batch = 15.4325s	
9093/28500 (epoch 15.953), train_loss = 1.27173533, grad/param norm = 1.8348e-01, time/batch = 15.6092s	
9094/28500 (epoch 15.954), train_loss = 1.23457468, grad/param norm = 1.7530e-01, time/batch = 15.4470s	
9095/28500 (epoch 15.956), train_loss = 1.16621274, grad/param norm = 1.9083e-01, time/batch = 15.4498s	
9096/28500 (epoch 15.958), train_loss = 1.28047283, grad/param norm = 1.6031e-01, time/batch = 15.1391s	
9097/28500 (epoch 15.960), train_loss = 0.98284007, grad/param norm = 1.4978e-01, time/batch = 15.4136s	
9098/28500 (epoch 15.961), train_loss = 1.32326334, grad/param norm = 1.8273e-01, time/batch = 15.3840s	
9099/28500 (epoch 15.963), train_loss = 1.20355510, grad/param norm = 1.6123e-01, time/batch = 15.5589s	
9100/28500 (epoch 15.965), train_loss = 1.01535766, grad/param norm = 1.6124e-01, time/batch = 15.3042s	
9101/28500 (epoch 15.967), train_loss = 0.99893111, grad/param norm = 1.5722e-01, time/batch = 15.3731s	
9102/28500 (epoch 15.968), train_loss = 0.92013775, grad/param norm = 1.3139e-01, time/batch = 15.5358s	
9103/28500 (epoch 15.970), train_loss = 1.02774171, grad/param norm = 1.4975e-01, time/batch = 15.6248s	
9104/28500 (epoch 15.972), train_loss = 1.11969018, grad/param norm = 1.5583e-01, time/batch = 15.3578s	
9105/28500 (epoch 15.974), train_loss = 1.29879119, grad/param norm = 1.7767e-01, time/batch = 15.4782s	
9106/28500 (epoch 15.975), train_loss = 1.06599062, grad/param norm = 1.6532e-01, time/batch = 15.1858s	
9107/28500 (epoch 15.977), train_loss = 1.23612096, grad/param norm = 1.7494e-01, time/batch = 15.4603s	
9108/28500 (epoch 15.979), train_loss = 1.04909660, grad/param norm = 1.6352e-01, time/batch = 15.6150s	
9109/28500 (epoch 15.981), train_loss = 0.99872785, grad/param norm = 1.5074e-01, time/batch = 15.5323s	
9110/28500 (epoch 15.982), train_loss = 1.04800379, grad/param norm = 1.5018e-01, time/batch = 15.4432s	
9111/28500 (epoch 15.984), train_loss = 1.20552062, grad/param norm = 1.7160e-01, time/batch = 15.4498s	
9112/28500 (epoch 15.986), train_loss = 1.34390350, grad/param norm = 1.7302e-01, time/batch = 15.4648s	
9113/28500 (epoch 15.988), train_loss = 0.92220397, grad/param norm = 1.5106e-01, time/batch = 15.4498s	
9114/28500 (epoch 15.989), train_loss = 1.13724318, grad/param norm = 1.6688e-01, time/batch = 15.4561s	
9115/28500 (epoch 15.991), train_loss = 1.04289190, grad/param norm = 1.7334e-01, time/batch = 15.6392s	
9116/28500 (epoch 15.993), train_loss = 1.03677831, grad/param norm = 1.6441e-01, time/batch = 15.6126s	
9117/28500 (epoch 15.995), train_loss = 1.01219180, grad/param norm = 1.5879e-01, time/batch = 15.2739s	
9118/28500 (epoch 15.996), train_loss = 0.99138718, grad/param norm = 1.4868e-01, time/batch = 15.4747s	
9119/28500 (epoch 15.998), train_loss = 1.20556776, grad/param norm = 1.6858e-01, time/batch = 15.1926s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
9120/28500 (epoch 16.000), train_loss = 1.04062592, grad/param norm = 1.4806e-01, time/batch = 15.3611s	
9121/28500 (epoch 16.002), train_loss = 1.22934895, grad/param norm = 1.6868e-01, time/batch = 15.2739s	
9122/28500 (epoch 16.004), train_loss = 1.04781435, grad/param norm = 1.6274e-01, time/batch = 15.3176s	
9123/28500 (epoch 16.005), train_loss = 1.20567609, grad/param norm = 1.6527e-01, time/batch = 15.1390s	
9124/28500 (epoch 16.007), train_loss = 0.95837674, grad/param norm = 1.4246e-01, time/batch = 15.2910s	
9125/28500 (epoch 16.009), train_loss = 1.15434613, grad/param norm = 1.7362e-01, time/batch = 15.1526s	
9126/28500 (epoch 16.011), train_loss = 1.03287131, grad/param norm = 1.8377e-01, time/batch = 15.1220s	
9127/28500 (epoch 16.012), train_loss = 0.95190585, grad/param norm = 1.3486e-01, time/batch = 15.2940s	
9128/28500 (epoch 16.014), train_loss = 0.98302640, grad/param norm = 1.4813e-01, time/batch = 15.5352s	
9129/28500 (epoch 16.016), train_loss = 1.05531268, grad/param norm = 1.4393e-01, time/batch = 15.4617s	
9130/28500 (epoch 16.018), train_loss = 1.11782431, grad/param norm = 1.6356e-01, time/batch = 15.4627s	
9131/28500 (epoch 16.019), train_loss = 1.19525111, grad/param norm = 1.6607e-01, time/batch = 15.4340s	
9132/28500 (epoch 16.021), train_loss = 1.16485356, grad/param norm = 1.4085e-01, time/batch = 15.5787s	
9133/28500 (epoch 16.023), train_loss = 1.05935866, grad/param norm = 1.5720e-01, time/batch = 15.3236s	
9134/28500 (epoch 16.025), train_loss = 1.09063447, grad/param norm = 1.4986e-01, time/batch = 15.3616s	
9135/28500 (epoch 16.026), train_loss = 1.08552008, grad/param norm = 1.5385e-01, time/batch = 15.4474s	
9136/28500 (epoch 16.028), train_loss = 1.14345770, grad/param norm = 1.6022e-01, time/batch = 15.5295s	
9137/28500 (epoch 16.030), train_loss = 1.17377814, grad/param norm = 1.8206e-01, time/batch = 15.4613s	
9138/28500 (epoch 16.032), train_loss = 1.16570522, grad/param norm = 1.6838e-01, time/batch = 15.2336s	
9139/28500 (epoch 16.033), train_loss = 1.23862711, grad/param norm = 1.6463e-01, time/batch = 15.1313s	
9140/28500 (epoch 16.035), train_loss = 1.11058620, grad/param norm = 1.7288e-01, time/batch = 15.1555s	
9141/28500 (epoch 16.037), train_loss = 1.17746358, grad/param norm = 1.4384e-01, time/batch = 15.4666s	
9142/28500 (epoch 16.039), train_loss = 1.20788252, grad/param norm = 1.6490e-01, time/batch = 15.2123s	
9143/28500 (epoch 16.040), train_loss = 1.25352899, grad/param norm = 1.6255e-01, time/batch = 15.3799s	
9144/28500 (epoch 16.042), train_loss = 1.18317528, grad/param norm = 1.6214e-01, time/batch = 15.6237s	
9145/28500 (epoch 16.044), train_loss = 1.09496462, grad/param norm = 1.6008e-01, time/batch = 15.5706s	
9146/28500 (epoch 16.046), train_loss = 1.33091893, grad/param norm = 1.7374e-01, time/batch = 15.3661s	
9147/28500 (epoch 16.047), train_loss = 1.23331685, grad/param norm = 1.6613e-01, time/batch = 15.5937s	
9148/28500 (epoch 16.049), train_loss = 1.15059191, grad/param norm = 1.7694e-01, time/batch = 15.2647s	
9149/28500 (epoch 16.051), train_loss = 1.06754191, grad/param norm = 1.5851e-01, time/batch = 15.1275s	
9150/28500 (epoch 16.053), train_loss = 1.11988113, grad/param norm = 1.7603e-01, time/batch = 15.1267s	
9151/28500 (epoch 16.054), train_loss = 1.20150345, grad/param norm = 1.7472e-01, time/batch = 15.4545s	
9152/28500 (epoch 16.056), train_loss = 0.97819839, grad/param norm = 1.3784e-01, time/batch = 15.4837s	
9153/28500 (epoch 16.058), train_loss = 0.98816016, grad/param norm = 1.5371e-01, time/batch = 15.6220s	
9154/28500 (epoch 16.060), train_loss = 1.18571891, grad/param norm = 1.6404e-01, time/batch = 15.6419s	
9155/28500 (epoch 16.061), train_loss = 1.13277340, grad/param norm = 1.7765e-01, time/batch = 15.3557s	
9156/28500 (epoch 16.063), train_loss = 1.17948729, grad/param norm = 1.5461e-01, time/batch = 15.3778s	
9157/28500 (epoch 16.065), train_loss = 1.21548139, grad/param norm = 1.7177e-01, time/batch = 15.3866s	
9158/28500 (epoch 16.067), train_loss = 1.06362722, grad/param norm = 1.4358e-01, time/batch = 15.4848s	
9159/28500 (epoch 16.068), train_loss = 1.08469640, grad/param norm = 1.5250e-01, time/batch = 15.3035s	
9160/28500 (epoch 16.070), train_loss = 1.15743458, grad/param norm = 1.7768e-01, time/batch = 15.4626s	
9161/28500 (epoch 16.072), train_loss = 1.30757802, grad/param norm = 1.7784e-01, time/batch = 15.5071s	
9162/28500 (epoch 16.074), train_loss = 1.15156554, grad/param norm = 1.5143e-01, time/batch = 15.2976s	
9163/28500 (epoch 16.075), train_loss = 1.09701125, grad/param norm = 1.4436e-01, time/batch = 15.2954s	
9164/28500 (epoch 16.077), train_loss = 1.17237737, grad/param norm = 1.6918e-01, time/batch = 15.0680s	
9165/28500 (epoch 16.079), train_loss = 1.10203188, grad/param norm = 1.5044e-01, time/batch = 15.3826s	
9166/28500 (epoch 16.081), train_loss = 1.24719722, grad/param norm = 1.7219e-01, time/batch = 15.2979s	
9167/28500 (epoch 16.082), train_loss = 1.14928943, grad/param norm = 1.7490e-01, time/batch = 15.5949s	
9168/28500 (epoch 16.084), train_loss = 1.15651736, grad/param norm = 1.5508e-01, time/batch = 15.3999s	
9169/28500 (epoch 16.086), train_loss = 1.09654103, grad/param norm = 1.7404e-01, time/batch = 15.2001s	
9170/28500 (epoch 16.088), train_loss = 0.99705565, grad/param norm = 1.6217e-01, time/batch = 15.3130s	
9171/28500 (epoch 16.089), train_loss = 1.22232087, grad/param norm = 1.4367e-01, time/batch = 15.3828s	
9172/28500 (epoch 16.091), train_loss = 1.00622774, grad/param norm = 1.5371e-01, time/batch = 15.3429s	
9173/28500 (epoch 16.093), train_loss = 1.14990468, grad/param norm = 1.5077e-01, time/batch = 15.2800s	
9174/28500 (epoch 16.095), train_loss = 1.05471872, grad/param norm = 1.4497e-01, time/batch = 15.2518s	
9175/28500 (epoch 16.096), train_loss = 1.24987208, grad/param norm = 1.6400e-01, time/batch = 15.5462s	
9176/28500 (epoch 16.098), train_loss = 1.18819256, grad/param norm = 1.7687e-01, time/batch = 15.3691s	
9177/28500 (epoch 16.100), train_loss = 1.07800483, grad/param norm = 1.6013e-01, time/batch = 15.5387s	
9178/28500 (epoch 16.102), train_loss = 1.23654444, grad/param norm = 1.6656e-01, time/batch = 15.1344s	
9179/28500 (epoch 16.104), train_loss = 1.09132813, grad/param norm = 1.6051e-01, time/batch = 26.7477s	
9180/28500 (epoch 16.105), train_loss = 1.21755741, grad/param norm = 1.6119e-01, time/batch = 27.7053s	
9181/28500 (epoch 16.107), train_loss = 0.99916607, grad/param norm = 1.6200e-01, time/batch = 31.9944s	
9182/28500 (epoch 16.109), train_loss = 0.98142071, grad/param norm = 1.6021e-01, time/batch = 30.9218s	
9183/28500 (epoch 16.111), train_loss = 1.09567622, grad/param norm = 1.7746e-01, time/batch = 29.1819s	
9184/28500 (epoch 16.112), train_loss = 1.17881553, grad/param norm = 1.5416e-01, time/batch = 30.7515s	
9185/28500 (epoch 16.114), train_loss = 1.09611294, grad/param norm = 1.5907e-01, time/batch = 29.6210s	
9186/28500 (epoch 16.116), train_loss = 1.29733008, grad/param norm = 1.7197e-01, time/batch = 30.7625s	
9187/28500 (epoch 16.118), train_loss = 0.96468339, grad/param norm = 1.5617e-01, time/batch = 31.1737s	
9188/28500 (epoch 16.119), train_loss = 1.14175408, grad/param norm = 1.6521e-01, time/batch = 30.9862s	
9189/28500 (epoch 16.121), train_loss = 1.30078781, grad/param norm = 1.9208e-01, time/batch = 15.6348s	
9190/28500 (epoch 16.123), train_loss = 1.18195803, grad/param norm = 1.6341e-01, time/batch = 15.1480s	
9191/28500 (epoch 16.125), train_loss = 1.13689239, grad/param norm = 1.5901e-01, time/batch = 15.3057s	
9192/28500 (epoch 16.126), train_loss = 1.10737395, grad/param norm = 1.5606e-01, time/batch = 15.2933s	
9193/28500 (epoch 16.128), train_loss = 1.08905643, grad/param norm = 1.5187e-01, time/batch = 15.1434s	
9194/28500 (epoch 16.130), train_loss = 1.00130054, grad/param norm = 1.5765e-01, time/batch = 15.3122s	
9195/28500 (epoch 16.132), train_loss = 1.17211782, grad/param norm = 1.7462e-01, time/batch = 15.2410s	
9196/28500 (epoch 16.133), train_loss = 1.17804111, grad/param norm = 1.7776e-01, time/batch = 25.1255s	
9197/28500 (epoch 16.135), train_loss = 1.08442098, grad/param norm = 1.4449e-01, time/batch = 18.9506s	
9198/28500 (epoch 16.137), train_loss = 1.07834104, grad/param norm = 1.6159e-01, time/batch = 15.1723s	
9199/28500 (epoch 16.139), train_loss = 1.09358966, grad/param norm = 1.4660e-01, time/batch = 15.4684s	
9200/28500 (epoch 16.140), train_loss = 1.14763203, grad/param norm = 1.4928e-01, time/batch = 15.5787s	
9201/28500 (epoch 16.142), train_loss = 1.10188312, grad/param norm = 1.7518e-01, time/batch = 15.5713s	
9202/28500 (epoch 16.144), train_loss = 1.03998881, grad/param norm = 1.5834e-01, time/batch = 15.4057s	
9203/28500 (epoch 16.146), train_loss = 1.05424274, grad/param norm = 1.4761e-01, time/batch = 15.6218s	
9204/28500 (epoch 16.147), train_loss = 0.96603262, grad/param norm = 1.4966e-01, time/batch = 15.4064s	
9205/28500 (epoch 16.149), train_loss = 0.95475218, grad/param norm = 1.3259e-01, time/batch = 15.4286s	
9206/28500 (epoch 16.151), train_loss = 1.00035346, grad/param norm = 1.3648e-01, time/batch = 15.3259s	
9207/28500 (epoch 16.153), train_loss = 1.12310026, grad/param norm = 1.6565e-01, time/batch = 15.1336s	
9208/28500 (epoch 16.154), train_loss = 0.98973553, grad/param norm = 1.4568e-01, time/batch = 15.3971s	
9209/28500 (epoch 16.156), train_loss = 1.23576601, grad/param norm = 1.6414e-01, time/batch = 15.5193s	
9210/28500 (epoch 16.158), train_loss = 1.08362989, grad/param norm = 1.4810e-01, time/batch = 15.4480s	
9211/28500 (epoch 16.160), train_loss = 0.99421788, grad/param norm = 1.4175e-01, time/batch = 15.3775s	
9212/28500 (epoch 16.161), train_loss = 1.06673874, grad/param norm = 1.5366e-01, time/batch = 15.1438s	
9213/28500 (epoch 16.163), train_loss = 0.95584044, grad/param norm = 1.6144e-01, time/batch = 15.3716s	
9214/28500 (epoch 16.165), train_loss = 1.30623856, grad/param norm = 1.6230e-01, time/batch = 15.6605s	
9215/28500 (epoch 16.167), train_loss = 1.36188928, grad/param norm = 1.8637e-01, time/batch = 15.3916s	
9216/28500 (epoch 16.168), train_loss = 1.22075444, grad/param norm = 1.7614e-01, time/batch = 15.2860s	
9217/28500 (epoch 16.170), train_loss = 1.22322001, grad/param norm = 1.8509e-01, time/batch = 15.1885s	
9218/28500 (epoch 16.172), train_loss = 1.09943819, grad/param norm = 1.5174e-01, time/batch = 15.2899s	
9219/28500 (epoch 16.174), train_loss = 1.25696384, grad/param norm = 1.7390e-01, time/batch = 15.2153s	
9220/28500 (epoch 16.175), train_loss = 1.10485372, grad/param norm = 1.5317e-01, time/batch = 15.1524s	
9221/28500 (epoch 16.177), train_loss = 1.18652345, grad/param norm = 1.8447e-01, time/batch = 15.1937s	
9222/28500 (epoch 16.179), train_loss = 1.10666375, grad/param norm = 1.7464e-01, time/batch = 15.1906s	
9223/28500 (epoch 16.181), train_loss = 1.17261689, grad/param norm = 1.6588e-01, time/batch = 15.2999s	
9224/28500 (epoch 16.182), train_loss = 1.09994741, grad/param norm = 1.4500e-01, time/batch = 15.2970s	
9225/28500 (epoch 16.184), train_loss = 1.30579393, grad/param norm = 1.8471e-01, time/batch = 15.0517s	
9226/28500 (epoch 16.186), train_loss = 1.22305139, grad/param norm = 1.6925e-01, time/batch = 15.2079s	
9227/28500 (epoch 16.188), train_loss = 1.12739840, grad/param norm = 1.4883e-01, time/batch = 15.3989s	
9228/28500 (epoch 16.189), train_loss = 1.15262350, grad/param norm = 1.6316e-01, time/batch = 15.4951s	
9229/28500 (epoch 16.191), train_loss = 1.33709088, grad/param norm = 1.7108e-01, time/batch = 15.3597s	
9230/28500 (epoch 16.193), train_loss = 1.18409071, grad/param norm = 1.7818e-01, time/batch = 15.2659s	
9231/28500 (epoch 16.195), train_loss = 1.27531344, grad/param norm = 1.7059e-01, time/batch = 15.5244s	
9232/28500 (epoch 16.196), train_loss = 1.17125221, grad/param norm = 1.6477e-01, time/batch = 15.5147s	
9233/28500 (epoch 16.198), train_loss = 1.13205157, grad/param norm = 1.7819e-01, time/batch = 15.4650s	
9234/28500 (epoch 16.200), train_loss = 1.16180470, grad/param norm = 1.5286e-01, time/batch = 15.6353s	
9235/28500 (epoch 16.202), train_loss = 1.13512086, grad/param norm = 1.5554e-01, time/batch = 15.4718s	
9236/28500 (epoch 16.204), train_loss = 1.06295959, grad/param norm = 1.4248e-01, time/batch = 15.4598s	
9237/28500 (epoch 16.205), train_loss = 1.09570836, grad/param norm = 1.6475e-01, time/batch = 15.4479s	
9238/28500 (epoch 16.207), train_loss = 1.03338734, grad/param norm = 1.6298e-01, time/batch = 15.0541s	
9239/28500 (epoch 16.209), train_loss = 1.12912884, grad/param norm = 1.5201e-01, time/batch = 15.0362s	
9240/28500 (epoch 16.211), train_loss = 0.98818969, grad/param norm = 1.5327e-01, time/batch = 15.1512s	
9241/28500 (epoch 16.212), train_loss = 0.97344184, grad/param norm = 1.3894e-01, time/batch = 15.6334s	
9242/28500 (epoch 16.214), train_loss = 1.14002104, grad/param norm = 1.7472e-01, time/batch = 15.5886s	
9243/28500 (epoch 16.216), train_loss = 1.01464260, grad/param norm = 1.5143e-01, time/batch = 15.5244s	
9244/28500 (epoch 16.218), train_loss = 1.24525049, grad/param norm = 1.5467e-01, time/batch = 15.2716s	
9245/28500 (epoch 16.219), train_loss = 1.17244592, grad/param norm = 1.7347e-01, time/batch = 15.2726s	
9246/28500 (epoch 16.221), train_loss = 0.98055442, grad/param norm = 1.4944e-01, time/batch = 15.2854s	
9247/28500 (epoch 16.223), train_loss = 1.23637609, grad/param norm = 1.6178e-01, time/batch = 15.2382s	
9248/28500 (epoch 16.225), train_loss = 1.24819233, grad/param norm = 1.6440e-01, time/batch = 15.3838s	
9249/28500 (epoch 16.226), train_loss = 1.07938156, grad/param norm = 1.5108e-01, time/batch = 15.3881s	
9250/28500 (epoch 16.228), train_loss = 1.19368500, grad/param norm = 1.5146e-01, time/batch = 15.3781s	
9251/28500 (epoch 16.230), train_loss = 1.22465719, grad/param norm = 1.5847e-01, time/batch = 15.4411s	
9252/28500 (epoch 16.232), train_loss = 1.18303300, grad/param norm = 1.4935e-01, time/batch = 15.2722s	
9253/28500 (epoch 16.233), train_loss = 1.16099923, grad/param norm = 1.6807e-01, time/batch = 15.5514s	
9254/28500 (epoch 16.235), train_loss = 1.09426382, grad/param norm = 1.4479e-01, time/batch = 15.5483s	
9255/28500 (epoch 16.237), train_loss = 0.97526397, grad/param norm = 1.3669e-01, time/batch = 15.3835s	
9256/28500 (epoch 16.239), train_loss = 1.04436368, grad/param norm = 1.3834e-01, time/batch = 15.3287s	
9257/28500 (epoch 16.240), train_loss = 1.00466270, grad/param norm = 1.6013e-01, time/batch = 15.5689s	
9258/28500 (epoch 16.242), train_loss = 1.17017285, grad/param norm = 1.7356e-01, time/batch = 15.4061s	
9259/28500 (epoch 16.244), train_loss = 1.17162879, grad/param norm = 1.5055e-01, time/batch = 15.3207s	
9260/28500 (epoch 16.246), train_loss = 1.22891669, grad/param norm = 1.6647e-01, time/batch = 15.5591s	
9261/28500 (epoch 16.247), train_loss = 1.31230304, grad/param norm = 1.7801e-01, time/batch = 15.4837s	
9262/28500 (epoch 16.249), train_loss = 1.12980095, grad/param norm = 1.5916e-01, time/batch = 15.3311s	
9263/28500 (epoch 16.251), train_loss = 1.03836861, grad/param norm = 1.3974e-01, time/batch = 15.2012s	
9264/28500 (epoch 16.253), train_loss = 1.29942122, grad/param norm = 1.8479e-01, time/batch = 15.0641s	
9265/28500 (epoch 16.254), train_loss = 1.25834194, grad/param norm = 1.6317e-01, time/batch = 15.2746s	
9266/28500 (epoch 16.256), train_loss = 1.05570085, grad/param norm = 1.5103e-01, time/batch = 15.2924s	
9267/28500 (epoch 16.258), train_loss = 1.12735566, grad/param norm = 1.6909e-01, time/batch = 15.4736s	
9268/28500 (epoch 16.260), train_loss = 1.06035913, grad/param norm = 1.5124e-01, time/batch = 15.2587s	
9269/28500 (epoch 16.261), train_loss = 1.06604534, grad/param norm = 1.5834e-01, time/batch = 15.2540s	
9270/28500 (epoch 16.263), train_loss = 1.25555821, grad/param norm = 1.8001e-01, time/batch = 15.0492s	
9271/28500 (epoch 16.265), train_loss = 1.12719791, grad/param norm = 1.5339e-01, time/batch = 15.4509s	
9272/28500 (epoch 16.267), train_loss = 1.27372402, grad/param norm = 1.6809e-01, time/batch = 15.3511s	
9273/28500 (epoch 16.268), train_loss = 1.17311764, grad/param norm = 1.5268e-01, time/batch = 15.6281s	
9274/28500 (epoch 16.270), train_loss = 1.16017578, grad/param norm = 1.8238e-01, time/batch = 15.1323s	
9275/28500 (epoch 16.272), train_loss = 1.09387665, grad/param norm = 1.5698e-01, time/batch = 14.9029s	
9276/28500 (epoch 16.274), train_loss = 1.24104563, grad/param norm = 1.5930e-01, time/batch = 15.0564s	
9277/28500 (epoch 16.275), train_loss = 1.15369643, grad/param norm = 1.4536e-01, time/batch = 15.5465s	
9278/28500 (epoch 16.277), train_loss = 1.13036415, grad/param norm = 1.5306e-01, time/batch = 15.5404s	
9279/28500 (epoch 16.279), train_loss = 1.17774507, grad/param norm = 1.6896e-01, time/batch = 15.3442s	
9280/28500 (epoch 16.281), train_loss = 1.21259215, grad/param norm = 1.8011e-01, time/batch = 15.3573s	
9281/28500 (epoch 16.282), train_loss = 1.03953726, grad/param norm = 1.4943e-01, time/batch = 15.4407s	
9282/28500 (epoch 16.284), train_loss = 1.14683885, grad/param norm = 1.6539e-01, time/batch = 15.4086s	
9283/28500 (epoch 16.286), train_loss = 1.24238462, grad/param norm = 1.5950e-01, time/batch = 15.2257s	
9284/28500 (epoch 16.288), train_loss = 1.17708799, grad/param norm = 1.7151e-01, time/batch = 15.1993s	
9285/28500 (epoch 16.289), train_loss = 1.19669966, grad/param norm = 1.7548e-01, time/batch = 15.4493s	
9286/28500 (epoch 16.291), train_loss = 1.12122063, grad/param norm = 1.4958e-01, time/batch = 15.0741s	
9287/28500 (epoch 16.293), train_loss = 1.08525094, grad/param norm = 1.5818e-01, time/batch = 15.2287s	
9288/28500 (epoch 16.295), train_loss = 1.00778503, grad/param norm = 1.5681e-01, time/batch = 15.3102s	
9289/28500 (epoch 16.296), train_loss = 1.02431918, grad/param norm = 1.4413e-01, time/batch = 15.2315s	
9290/28500 (epoch 16.298), train_loss = 1.20016341, grad/param norm = 1.5270e-01, time/batch = 15.3715s	
9291/28500 (epoch 16.300), train_loss = 1.03736126, grad/param norm = 1.4975e-01, time/batch = 15.3007s	
9292/28500 (epoch 16.302), train_loss = 1.01584155, grad/param norm = 1.5226e-01, time/batch = 15.5129s	
9293/28500 (epoch 16.304), train_loss = 1.10554447, grad/param norm = 1.4667e-01, time/batch = 15.5360s	
9294/28500 (epoch 16.305), train_loss = 1.18765891, grad/param norm = 1.5497e-01, time/batch = 15.5140s	
9295/28500 (epoch 16.307), train_loss = 1.12866165, grad/param norm = 1.6878e-01, time/batch = 15.4718s	
9296/28500 (epoch 16.309), train_loss = 1.11626969, grad/param norm = 1.5726e-01, time/batch = 15.4386s	
9297/28500 (epoch 16.311), train_loss = 1.17060783, grad/param norm = 1.5372e-01, time/batch = 14.9794s	
9298/28500 (epoch 16.312), train_loss = 1.08904028, grad/param norm = 1.5525e-01, time/batch = 14.9494s	
9299/28500 (epoch 16.314), train_loss = 1.20274533, grad/param norm = 1.7488e-01, time/batch = 15.0413s	
9300/28500 (epoch 16.316), train_loss = 1.14755342, grad/param norm = 1.4891e-01, time/batch = 15.1903s	
9301/28500 (epoch 16.318), train_loss = 1.20258182, grad/param norm = 1.6163e-01, time/batch = 15.3010s	
9302/28500 (epoch 16.319), train_loss = 1.08834659, grad/param norm = 1.6033e-01, time/batch = 15.2909s	
9303/28500 (epoch 16.321), train_loss = 1.09447411, grad/param norm = 1.6880e-01, time/batch = 15.3100s	
9304/28500 (epoch 16.323), train_loss = 1.09804216, grad/param norm = 1.7477e-01, time/batch = 15.5322s	
9305/28500 (epoch 16.325), train_loss = 1.28053850, grad/param norm = 1.7046e-01, time/batch = 15.2153s	
9306/28500 (epoch 16.326), train_loss = 1.12287007, grad/param norm = 1.5695e-01, time/batch = 15.2996s	
9307/28500 (epoch 16.328), train_loss = 0.93410714, grad/param norm = 1.5216e-01, time/batch = 15.1045s	
9308/28500 (epoch 16.330), train_loss = 1.04146770, grad/param norm = 1.5752e-01, time/batch = 15.4746s	
9309/28500 (epoch 16.332), train_loss = 1.12215435, grad/param norm = 1.4743e-01, time/batch = 15.3495s	
9310/28500 (epoch 16.333), train_loss = 0.93913280, grad/param norm = 1.4447e-01, time/batch = 15.3081s	
9311/28500 (epoch 16.335), train_loss = 0.99069263, grad/param norm = 1.4459e-01, time/batch = 15.5623s	
9312/28500 (epoch 16.337), train_loss = 1.03864952, grad/param norm = 1.4694e-01, time/batch = 15.5828s	
9313/28500 (epoch 16.339), train_loss = 0.95987553, grad/param norm = 1.3897e-01, time/batch = 15.5772s	
9314/28500 (epoch 16.340), train_loss = 1.15777900, grad/param norm = 1.7786e-01, time/batch = 15.4991s	
9315/28500 (epoch 16.342), train_loss = 1.10498665, grad/param norm = 1.5965e-01, time/batch = 15.3412s	
9316/28500 (epoch 16.344), train_loss = 1.06332296, grad/param norm = 1.7097e-01, time/batch = 15.5742s	
9317/28500 (epoch 16.346), train_loss = 0.90322297, grad/param norm = 1.3218e-01, time/batch = 15.7017s	
9318/28500 (epoch 16.347), train_loss = 1.09152081, grad/param norm = 1.5562e-01, time/batch = 15.6264s	
9319/28500 (epoch 16.349), train_loss = 1.06412906, grad/param norm = 1.4412e-01, time/batch = 15.6074s	
9320/28500 (epoch 16.351), train_loss = 1.00958132, grad/param norm = 1.4536e-01, time/batch = 15.3807s	
9321/28500 (epoch 16.353), train_loss = 1.15293866, grad/param norm = 1.6505e-01, time/batch = 15.5118s	
9322/28500 (epoch 16.354), train_loss = 0.99007174, grad/param norm = 1.5069e-01, time/batch = 15.5119s	
9323/28500 (epoch 16.356), train_loss = 1.00111967, grad/param norm = 1.4217e-01, time/batch = 15.5251s	
9324/28500 (epoch 16.358), train_loss = 1.11501983, grad/param norm = 1.4659e-01, time/batch = 15.5294s	
9325/28500 (epoch 16.360), train_loss = 1.13360513, grad/param norm = 1.6503e-01, time/batch = 15.7055s	
9326/28500 (epoch 16.361), train_loss = 1.03783887, grad/param norm = 1.5356e-01, time/batch = 15.6155s	
9327/28500 (epoch 16.363), train_loss = 0.97991130, grad/param norm = 1.4117e-01, time/batch = 15.2760s	
9328/28500 (epoch 16.365), train_loss = 1.08257775, grad/param norm = 1.7366e-01, time/batch = 15.1445s	
9329/28500 (epoch 16.367), train_loss = 1.11156394, grad/param norm = 1.6418e-01, time/batch = 15.4653s	
9330/28500 (epoch 16.368), train_loss = 1.06869349, grad/param norm = 1.5539e-01, time/batch = 15.3613s	
9331/28500 (epoch 16.370), train_loss = 1.10180921, grad/param norm = 1.5576e-01, time/batch = 15.5095s	
9332/28500 (epoch 16.372), train_loss = 0.94736586, grad/param norm = 1.4576e-01, time/batch = 15.1279s	
9333/28500 (epoch 16.374), train_loss = 1.07550959, grad/param norm = 1.5668e-01, time/batch = 15.2271s	
9334/28500 (epoch 16.375), train_loss = 1.25055578, grad/param norm = 1.6217e-01, time/batch = 15.3000s	
9335/28500 (epoch 16.377), train_loss = 1.00174996, grad/param norm = 1.6077e-01, time/batch = 15.2503s	
9336/28500 (epoch 16.379), train_loss = 0.86984836, grad/param norm = 1.4476e-01, time/batch = 15.0551s	
9337/28500 (epoch 16.381), train_loss = 1.05101946, grad/param norm = 1.3686e-01, time/batch = 15.2183s	
9338/28500 (epoch 16.382), train_loss = 1.04263836, grad/param norm = 1.5654e-01, time/batch = 15.1842s	
9339/28500 (epoch 16.384), train_loss = 0.97418579, grad/param norm = 1.4290e-01, time/batch = 15.2670s	
9340/28500 (epoch 16.386), train_loss = 0.95253860, grad/param norm = 1.4677e-01, time/batch = 15.1172s	
9341/28500 (epoch 16.388), train_loss = 1.18813297, grad/param norm = 1.6882e-01, time/batch = 15.3088s	
9342/28500 (epoch 16.389), train_loss = 0.99994783, grad/param norm = 1.5241e-01, time/batch = 15.3794s	
9343/28500 (epoch 16.391), train_loss = 0.99016580, grad/param norm = 1.4690e-01, time/batch = 15.3021s	
9344/28500 (epoch 16.393), train_loss = 0.97441800, grad/param norm = 1.5762e-01, time/batch = 15.3891s	
9345/28500 (epoch 16.395), train_loss = 1.25223368, grad/param norm = 1.5843e-01, time/batch = 15.5679s	
9346/28500 (epoch 16.396), train_loss = 1.19806572, grad/param norm = 1.7303e-01, time/batch = 15.4366s	
9347/28500 (epoch 16.398), train_loss = 0.89971733, grad/param norm = 1.6807e-01, time/batch = 15.2999s	
9348/28500 (epoch 16.400), train_loss = 1.09986603, grad/param norm = 1.7602e-01, time/batch = 15.3889s	
9349/28500 (epoch 16.402), train_loss = 1.13139518, grad/param norm = 1.6604e-01, time/batch = 15.0335s	
9350/28500 (epoch 16.404), train_loss = 1.21218896, grad/param norm = 1.8209e-01, time/batch = 15.0373s	
9351/28500 (epoch 16.405), train_loss = 1.21396356, grad/param norm = 1.6293e-01, time/batch = 15.4571s	
9352/28500 (epoch 16.407), train_loss = 1.12233205, grad/param norm = 1.5573e-01, time/batch = 15.5492s	
9353/28500 (epoch 16.409), train_loss = 1.11706376, grad/param norm = 1.6714e-01, time/batch = 15.2262s	
9354/28500 (epoch 16.411), train_loss = 1.22397835, grad/param norm = 1.6409e-01, time/batch = 15.2587s	
9355/28500 (epoch 16.412), train_loss = 1.23653014, grad/param norm = 1.8371e-01, time/batch = 15.4728s	
9356/28500 (epoch 16.414), train_loss = 1.13884985, grad/param norm = 1.6456e-01, time/batch = 15.3032s	
9357/28500 (epoch 16.416), train_loss = 1.03725057, grad/param norm = 1.6163e-01, time/batch = 15.2129s	
9358/28500 (epoch 16.418), train_loss = 1.11694041, grad/param norm = 1.5466e-01, time/batch = 15.4084s	
9359/28500 (epoch 16.419), train_loss = 1.25010231, grad/param norm = 1.6908e-01, time/batch = 15.4466s	
9360/28500 (epoch 16.421), train_loss = 1.18381590, grad/param norm = 1.6156e-01, time/batch = 15.2056s	
9361/28500 (epoch 16.423), train_loss = 1.21759074, grad/param norm = 1.7787e-01, time/batch = 15.4283s	
9362/28500 (epoch 16.425), train_loss = 1.16187257, grad/param norm = 1.6560e-01, time/batch = 15.4234s	
9363/28500 (epoch 16.426), train_loss = 1.10527155, grad/param norm = 1.6834e-01, time/batch = 15.2087s	
9364/28500 (epoch 16.428), train_loss = 1.32231487, grad/param norm = 1.7146e-01, time/batch = 15.3971s	
9365/28500 (epoch 16.430), train_loss = 1.23867780, grad/param norm = 1.5751e-01, time/batch = 15.5571s	
9366/28500 (epoch 16.432), train_loss = 1.17680506, grad/param norm = 1.8069e-01, time/batch = 15.1866s	
9367/28500 (epoch 16.433), train_loss = 1.16891979, grad/param norm = 1.7891e-01, time/batch = 15.1301s	
9368/28500 (epoch 16.435), train_loss = 1.11504322, grad/param norm = 1.5587e-01, time/batch = 15.0573s	
9369/28500 (epoch 16.437), train_loss = 0.99919468, grad/param norm = 1.4064e-01, time/batch = 14.9704s	
9370/28500 (epoch 16.439), train_loss = 1.05309025, grad/param norm = 1.4835e-01, time/batch = 15.5821s	
9371/28500 (epoch 16.440), train_loss = 1.32940806, grad/param norm = 1.7830e-01, time/batch = 15.6033s	
9372/28500 (epoch 16.442), train_loss = 1.04634335, grad/param norm = 1.6289e-01, time/batch = 15.4251s	
9373/28500 (epoch 16.444), train_loss = 0.95921182, grad/param norm = 1.4273e-01, time/batch = 15.3273s	
9374/28500 (epoch 16.446), train_loss = 0.92515033, grad/param norm = 1.4742e-01, time/batch = 15.6279s	
9375/28500 (epoch 16.447), train_loss = 0.94794907, grad/param norm = 1.4247e-01, time/batch = 15.3147s	
9376/28500 (epoch 16.449), train_loss = 1.04210381, grad/param norm = 1.4544e-01, time/batch = 15.1087s	
9377/28500 (epoch 16.451), train_loss = 1.08819581, grad/param norm = 1.5431e-01, time/batch = 15.2121s	
9378/28500 (epoch 16.453), train_loss = 1.06947201, grad/param norm = 1.4512e-01, time/batch = 15.4080s	
9379/28500 (epoch 16.454), train_loss = 1.04341675, grad/param norm = 1.4216e-01, time/batch = 15.4475s	
9380/28500 (epoch 16.456), train_loss = 1.17316729, grad/param norm = 1.9920e-01, time/batch = 15.4265s	
9381/28500 (epoch 16.458), train_loss = 1.09335571, grad/param norm = 1.8937e-01, time/batch = 15.3781s	
9382/28500 (epoch 16.460), train_loss = 1.13822586, grad/param norm = 1.5458e-01, time/batch = 15.3309s	
9383/28500 (epoch 16.461), train_loss = 1.05821615, grad/param norm = 1.7255e-01, time/batch = 14.9835s	
9384/28500 (epoch 16.463), train_loss = 0.97739641, grad/param norm = 1.3310e-01, time/batch = 15.2284s	
9385/28500 (epoch 16.465), train_loss = 0.94595217, grad/param norm = 1.7139e-01, time/batch = 15.3605s	
9386/28500 (epoch 16.467), train_loss = 1.10731868, grad/param norm = 1.5505e-01, time/batch = 15.2818s	
9387/28500 (epoch 16.468), train_loss = 0.98769580, grad/param norm = 1.3289e-01, time/batch = 15.2745s	
9388/28500 (epoch 16.470), train_loss = 1.02973303, grad/param norm = 1.5263e-01, time/batch = 15.3172s	
9389/28500 (epoch 16.472), train_loss = 1.05694241, grad/param norm = 1.5615e-01, time/batch = 15.3792s	
9390/28500 (epoch 16.474), train_loss = 1.31515535, grad/param norm = 1.7727e-01, time/batch = 15.2694s	
9391/28500 (epoch 16.475), train_loss = 1.01913679, grad/param norm = 1.5073e-01, time/batch = 15.5764s	
9392/28500 (epoch 16.477), train_loss = 1.08252685, grad/param norm = 1.5737e-01, time/batch = 15.5253s	
9393/28500 (epoch 16.479), train_loss = 1.15535243, grad/param norm = 1.5496e-01, time/batch = 15.5193s	
9394/28500 (epoch 16.481), train_loss = 1.09826562, grad/param norm = 1.7476e-01, time/batch = 15.2913s	
9395/28500 (epoch 16.482), train_loss = 0.99758489, grad/param norm = 1.4781e-01, time/batch = 15.2185s	
9396/28500 (epoch 16.484), train_loss = 0.98884875, grad/param norm = 1.5057e-01, time/batch = 15.0734s	
9397/28500 (epoch 16.486), train_loss = 0.90726890, grad/param norm = 1.5801e-01, time/batch = 15.3624s	
9398/28500 (epoch 16.488), train_loss = 1.12110317, grad/param norm = 1.4620e-01, time/batch = 15.4642s	
9399/28500 (epoch 16.489), train_loss = 1.19613811, grad/param norm = 1.6931e-01, time/batch = 15.2077s	
9400/28500 (epoch 16.491), train_loss = 1.05610636, grad/param norm = 1.5314e-01, time/batch = 15.1230s	
9401/28500 (epoch 16.493), train_loss = 1.04228425, grad/param norm = 1.5451e-01, time/batch = 15.5718s	
9402/28500 (epoch 16.495), train_loss = 1.04641288, grad/param norm = 1.4326e-01, time/batch = 15.4887s	
9403/28500 (epoch 16.496), train_loss = 1.03438584, grad/param norm = 1.5843e-01, time/batch = 15.3791s	
9404/28500 (epoch 16.498), train_loss = 1.13557700, grad/param norm = 1.5896e-01, time/batch = 15.3609s	
9405/28500 (epoch 16.500), train_loss = 1.05339907, grad/param norm = 1.5407e-01, time/batch = 15.3793s	
9406/28500 (epoch 16.502), train_loss = 1.17877206, grad/param norm = 1.5658e-01, time/batch = 15.3653s	
9407/28500 (epoch 16.504), train_loss = 1.12496251, grad/param norm = 1.5294e-01, time/batch = 15.1502s	
9408/28500 (epoch 16.505), train_loss = 1.00825958, grad/param norm = 1.4304e-01, time/batch = 15.2843s	
9409/28500 (epoch 16.507), train_loss = 1.21933705, grad/param norm = 1.8584e-01, time/batch = 15.3339s	
9410/28500 (epoch 16.509), train_loss = 1.10205729, grad/param norm = 1.5525e-01, time/batch = 15.3372s	
9411/28500 (epoch 16.511), train_loss = 1.09464210, grad/param norm = 1.7423e-01, time/batch = 15.2063s	
9412/28500 (epoch 16.512), train_loss = 1.09472935, grad/param norm = 1.4780e-01, time/batch = 15.1414s	
9413/28500 (epoch 16.514), train_loss = 1.01196678, grad/param norm = 1.5330e-01, time/batch = 15.4316s	
9414/28500 (epoch 16.516), train_loss = 1.02549941, grad/param norm = 1.3872e-01, time/batch = 15.4703s	
9415/28500 (epoch 16.518), train_loss = 1.12023679, grad/param norm = 1.5343e-01, time/batch = 15.4730s	
9416/28500 (epoch 16.519), train_loss = 1.15708946, grad/param norm = 1.5435e-01, time/batch = 15.3395s	
9417/28500 (epoch 16.521), train_loss = 1.24434494, grad/param norm = 1.7297e-01, time/batch = 15.3069s	
9418/28500 (epoch 16.523), train_loss = 1.15640531, grad/param norm = 1.6930e-01, time/batch = 15.3697s	
9419/28500 (epoch 16.525), train_loss = 1.18941007, grad/param norm = 1.5969e-01, time/batch = 15.3700s	
9420/28500 (epoch 16.526), train_loss = 1.16811577, grad/param norm = 1.6722e-01, time/batch = 15.4433s	
9421/28500 (epoch 16.528), train_loss = 1.17273300, grad/param norm = 1.6414e-01, time/batch = 15.5403s	
9422/28500 (epoch 16.530), train_loss = 1.20593854, grad/param norm = 1.5521e-01, time/batch = 15.3886s	
9423/28500 (epoch 16.532), train_loss = 1.05515448, grad/param norm = 1.5267e-01, time/batch = 15.5445s	
9424/28500 (epoch 16.533), train_loss = 1.17427230, grad/param norm = 1.4790e-01, time/batch = 15.3368s	
9425/28500 (epoch 16.535), train_loss = 0.93545694, grad/param norm = 1.4167e-01, time/batch = 15.5400s	
9426/28500 (epoch 16.537), train_loss = 0.94922154, grad/param norm = 1.5186e-01, time/batch = 15.6274s	
9427/28500 (epoch 16.539), train_loss = 0.95606760, grad/param norm = 1.6155e-01, time/batch = 15.4608s	
9428/28500 (epoch 16.540), train_loss = 1.10815721, grad/param norm = 1.5305e-01, time/batch = 26.9700s	
9429/28500 (epoch 16.542), train_loss = 1.18424012, grad/param norm = 1.6846e-01, time/batch = 15.8695s	
9430/28500 (epoch 16.544), train_loss = 1.25756921, grad/param norm = 1.6834e-01, time/batch = 15.2409s	
9431/28500 (epoch 16.546), train_loss = 1.07910315, grad/param norm = 1.5627e-01, time/batch = 15.2914s	
9432/28500 (epoch 16.547), train_loss = 1.08933341, grad/param norm = 1.5446e-01, time/batch = 15.1101s	
9433/28500 (epoch 16.549), train_loss = 0.93096822, grad/param norm = 1.2971e-01, time/batch = 15.3615s	
9434/28500 (epoch 16.551), train_loss = 1.12892394, grad/param norm = 1.7852e-01, time/batch = 15.4798s	
9435/28500 (epoch 16.553), train_loss = 1.29805718, grad/param norm = 1.9031e-01, time/batch = 15.4450s	
9436/28500 (epoch 16.554), train_loss = 1.06918839, grad/param norm = 1.5072e-01, time/batch = 15.3873s	
9437/28500 (epoch 16.556), train_loss = 1.13756895, grad/param norm = 1.9075e-01, time/batch = 15.3142s	
9438/28500 (epoch 16.558), train_loss = 1.13013179, grad/param norm = 1.5074e-01, time/batch = 15.3769s	
9439/28500 (epoch 16.560), train_loss = 1.14244999, grad/param norm = 1.7504e-01, time/batch = 15.3714s	
9440/28500 (epoch 16.561), train_loss = 1.16701041, grad/param norm = 1.6732e-01, time/batch = 15.1854s	
9441/28500 (epoch 16.563), train_loss = 1.30606667, grad/param norm = 1.7676e-01, time/batch = 15.4178s	
9442/28500 (epoch 16.565), train_loss = 1.09861339, grad/param norm = 1.6509e-01, time/batch = 15.2873s	
9443/28500 (epoch 16.567), train_loss = 0.98041509, grad/param norm = 1.4888e-01, time/batch = 15.5170s	
9444/28500 (epoch 16.568), train_loss = 1.13053696, grad/param norm = 1.6160e-01, time/batch = 15.4495s	
9445/28500 (epoch 16.570), train_loss = 1.05600142, grad/param norm = 1.5446e-01, time/batch = 15.5317s	
9446/28500 (epoch 16.572), train_loss = 1.05912399, grad/param norm = 1.4888e-01, time/batch = 15.4506s	
9447/28500 (epoch 16.574), train_loss = 1.06257679, grad/param norm = 1.6575e-01, time/batch = 15.3677s	
9448/28500 (epoch 16.575), train_loss = 1.05982217, grad/param norm = 1.4282e-01, time/batch = 15.5422s	
9449/28500 (epoch 16.577), train_loss = 1.14266202, grad/param norm = 1.6247e-01, time/batch = 15.4097s	
9450/28500 (epoch 16.579), train_loss = 1.18595380, grad/param norm = 1.7357e-01, time/batch = 15.2741s	
9451/28500 (epoch 16.581), train_loss = 1.03501926, grad/param norm = 1.6623e-01, time/batch = 15.2695s	
9452/28500 (epoch 16.582), train_loss = 1.19774391, grad/param norm = 1.5701e-01, time/batch = 15.2125s	
9453/28500 (epoch 16.584), train_loss = 1.05685140, grad/param norm = 1.5741e-01, time/batch = 15.1735s	
9454/28500 (epoch 16.586), train_loss = 1.00725976, grad/param norm = 1.3565e-01, time/batch = 15.4038s	
9455/28500 (epoch 16.588), train_loss = 1.00228865, grad/param norm = 1.3673e-01, time/batch = 15.1890s	
9456/28500 (epoch 16.589), train_loss = 1.13647350, grad/param norm = 1.6738e-01, time/batch = 15.1176s	
9457/28500 (epoch 16.591), train_loss = 1.12498012, grad/param norm = 1.4493e-01, time/batch = 15.3655s	
9458/28500 (epoch 16.593), train_loss = 1.04318797, grad/param norm = 1.3970e-01, time/batch = 15.4285s	
9459/28500 (epoch 16.595), train_loss = 1.30534754, grad/param norm = 1.8098e-01, time/batch = 15.3792s	
9460/28500 (epoch 16.596), train_loss = 1.32287347, grad/param norm = 1.8242e-01, time/batch = 15.5196s	
9461/28500 (epoch 16.598), train_loss = 1.12566679, grad/param norm = 1.5900e-01, time/batch = 15.7925s	
9462/28500 (epoch 16.600), train_loss = 1.10458167, grad/param norm = 1.6680e-01, time/batch = 15.5394s	
9463/28500 (epoch 16.602), train_loss = 1.20509266, grad/param norm = 1.6549e-01, time/batch = 15.3013s	
9464/28500 (epoch 16.604), train_loss = 1.20249768, grad/param norm = 1.6099e-01, time/batch = 15.5384s	
9465/28500 (epoch 16.605), train_loss = 1.14794764, grad/param norm = 1.6783e-01, time/batch = 15.5458s	
9466/28500 (epoch 16.607), train_loss = 1.20582866, grad/param norm = 1.5100e-01, time/batch = 15.6014s	
9467/28500 (epoch 16.609), train_loss = 1.11917241, grad/param norm = 1.7023e-01, time/batch = 15.6534s	
9468/28500 (epoch 16.611), train_loss = 1.09450406, grad/param norm = 1.4860e-01, time/batch = 15.4820s	
9469/28500 (epoch 16.612), train_loss = 1.16593883, grad/param norm = 1.7720e-01, time/batch = 15.3856s	
9470/28500 (epoch 16.614), train_loss = 1.15507976, grad/param norm = 1.6871e-01, time/batch = 15.4423s	
9471/28500 (epoch 16.616), train_loss = 1.05625943, grad/param norm = 1.5904e-01, time/batch = 15.6111s	
9472/28500 (epoch 16.618), train_loss = 1.05316859, grad/param norm = 1.5164e-01, time/batch = 15.6067s	
9473/28500 (epoch 16.619), train_loss = 1.28143702, grad/param norm = 1.7651e-01, time/batch = 15.5389s	
9474/28500 (epoch 16.621), train_loss = 0.90323423, grad/param norm = 1.3446e-01, time/batch = 15.3955s	
9475/28500 (epoch 16.623), train_loss = 1.21220157, grad/param norm = 1.6450e-01, time/batch = 15.3105s	
9476/28500 (epoch 16.625), train_loss = 0.97729824, grad/param norm = 1.5463e-01, time/batch = 15.1308s	
9477/28500 (epoch 16.626), train_loss = 0.86073155, grad/param norm = 1.3384e-01, time/batch = 15.1181s	
9478/28500 (epoch 16.628), train_loss = 1.03274080, grad/param norm = 1.4849e-01, time/batch = 15.3415s	
9479/28500 (epoch 16.630), train_loss = 0.94536385, grad/param norm = 1.3021e-01, time/batch = 15.5208s	
9480/28500 (epoch 16.632), train_loss = 1.17727937, grad/param norm = 1.5916e-01, time/batch = 15.4660s	
9481/28500 (epoch 16.633), train_loss = 1.24641060, grad/param norm = 1.5307e-01, time/batch = 15.6601s	
9482/28500 (epoch 16.635), train_loss = 1.23228516, grad/param norm = 1.7173e-01, time/batch = 15.2824s	
9483/28500 (epoch 16.637), train_loss = 1.12166793, grad/param norm = 1.4936e-01, time/batch = 15.0595s	
9484/28500 (epoch 16.639), train_loss = 0.98911672, grad/param norm = 1.4246e-01, time/batch = 15.4802s	
9485/28500 (epoch 16.640), train_loss = 1.01258771, grad/param norm = 1.4664e-01, time/batch = 15.5738s	
9486/28500 (epoch 16.642), train_loss = 1.09060057, grad/param norm = 1.4107e-01, time/batch = 15.2157s	
9487/28500 (epoch 16.644), train_loss = 1.16933250, grad/param norm = 1.4339e-01, time/batch = 15.4692s	
9488/28500 (epoch 16.646), train_loss = 0.98654404, grad/param norm = 1.4127e-01, time/batch = 15.6196s	
9489/28500 (epoch 16.647), train_loss = 1.00674094, grad/param norm = 1.5208e-01, time/batch = 15.3544s	
9490/28500 (epoch 16.649), train_loss = 0.96512249, grad/param norm = 1.4608e-01, time/batch = 15.3755s	
9491/28500 (epoch 16.651), train_loss = 0.95018154, grad/param norm = 1.3386e-01, time/batch = 15.4451s	
9492/28500 (epoch 16.653), train_loss = 0.98459507, grad/param norm = 1.4543e-01, time/batch = 15.2831s	
9493/28500 (epoch 16.654), train_loss = 1.09078871, grad/param norm = 1.5985e-01, time/batch = 15.2628s	
9494/28500 (epoch 16.656), train_loss = 1.00936124, grad/param norm = 1.6167e-01, time/batch = 15.2310s	
9495/28500 (epoch 16.658), train_loss = 1.09590501, grad/param norm = 1.5935e-01, time/batch = 15.3432s	
9496/28500 (epoch 16.660), train_loss = 1.09271066, grad/param norm = 1.4271e-01, time/batch = 15.5238s	
9497/28500 (epoch 16.661), train_loss = 1.24626213, grad/param norm = 1.7276e-01, time/batch = 15.4367s	
9498/28500 (epoch 16.663), train_loss = 1.26567592, grad/param norm = 1.6502e-01, time/batch = 15.0511s	
9499/28500 (epoch 16.665), train_loss = 1.08433160, grad/param norm = 1.5084e-01, time/batch = 15.1027s	
9500/28500 (epoch 16.667), train_loss = 1.09071476, grad/param norm = 1.6129e-01, time/batch = 15.1956s	
9501/28500 (epoch 16.668), train_loss = 1.08063801, grad/param norm = 1.4920e-01, time/batch = 15.6109s	
9502/28500 (epoch 16.670), train_loss = 1.09747361, grad/param norm = 1.5052e-01, time/batch = 15.5321s	
9503/28500 (epoch 16.672), train_loss = 1.03726102, grad/param norm = 1.5249e-01, time/batch = 15.1274s	
9504/28500 (epoch 16.674), train_loss = 0.90485778, grad/param norm = 1.4714e-01, time/batch = 15.0430s	
9505/28500 (epoch 16.675), train_loss = 0.96419805, grad/param norm = 1.4868e-01, time/batch = 15.4792s	
9506/28500 (epoch 16.677), train_loss = 1.06475017, grad/param norm = 1.4802e-01, time/batch = 15.1711s	
9507/28500 (epoch 16.679), train_loss = 1.04439417, grad/param norm = 1.5940e-01, time/batch = 15.2105s	
9508/28500 (epoch 16.681), train_loss = 1.15012715, grad/param norm = 1.4810e-01, time/batch = 15.2322s	
9509/28500 (epoch 16.682), train_loss = 1.05116460, grad/param norm = 1.5503e-01, time/batch = 15.1328s	
9510/28500 (epoch 16.684), train_loss = 1.14747362, grad/param norm = 1.6852e-01, time/batch = 15.1303s	
9511/28500 (epoch 16.686), train_loss = 1.04279407, grad/param norm = 1.7770e-01, time/batch = 15.4119s	
9512/28500 (epoch 16.688), train_loss = 0.97404309, grad/param norm = 1.3926e-01, time/batch = 15.1364s	
9513/28500 (epoch 16.689), train_loss = 1.07097874, grad/param norm = 1.5192e-01, time/batch = 15.3129s	
9514/28500 (epoch 16.691), train_loss = 1.15950379, grad/param norm = 1.8395e-01, time/batch = 15.3057s	
9515/28500 (epoch 16.693), train_loss = 1.04339720, grad/param norm = 1.5369e-01, time/batch = 15.0445s	
9516/28500 (epoch 16.695), train_loss = 0.87423159, grad/param norm = 1.6392e-01, time/batch = 15.1368s	
9517/28500 (epoch 16.696), train_loss = 1.06526424, grad/param norm = 1.5867e-01, time/batch = 15.3087s	
9518/28500 (epoch 16.698), train_loss = 1.05881776, grad/param norm = 1.5289e-01, time/batch = 15.3793s	
9519/28500 (epoch 16.700), train_loss = 1.12920220, grad/param norm = 1.5769e-01, time/batch = 15.2577s	
9520/28500 (epoch 16.702), train_loss = 1.16124705, grad/param norm = 1.7171e-01, time/batch = 15.0501s	
9521/28500 (epoch 16.704), train_loss = 1.12747349, grad/param norm = 1.6190e-01, time/batch = 15.4182s	
9522/28500 (epoch 16.705), train_loss = 1.20431216, grad/param norm = 1.8829e-01, time/batch = 15.6019s	
9523/28500 (epoch 16.707), train_loss = 1.04092024, grad/param norm = 1.6274e-01, time/batch = 15.5440s	
9524/28500 (epoch 16.709), train_loss = 1.23382866, grad/param norm = 1.6737e-01, time/batch = 15.5243s	
9525/28500 (epoch 16.711), train_loss = 1.00623522, grad/param norm = 1.6957e-01, time/batch = 15.3174s	
9526/28500 (epoch 16.712), train_loss = 1.15009344, grad/param norm = 1.5991e-01, time/batch = 15.5346s	
9527/28500 (epoch 16.714), train_loss = 1.20539029, grad/param norm = 1.6212e-01, time/batch = 15.3863s	
9528/28500 (epoch 16.716), train_loss = 1.07181208, grad/param norm = 1.5570e-01, time/batch = 15.3663s	
9529/28500 (epoch 16.718), train_loss = 1.07308453, grad/param norm = 1.5474e-01, time/batch = 15.1244s	
9530/28500 (epoch 16.719), train_loss = 1.11448925, grad/param norm = 1.6287e-01, time/batch = 15.1193s	
9531/28500 (epoch 16.721), train_loss = 0.90601845, grad/param norm = 1.4262e-01, time/batch = 15.2740s	
9532/28500 (epoch 16.723), train_loss = 1.09219802, grad/param norm = 1.6957e-01, time/batch = 15.2792s	
9533/28500 (epoch 16.725), train_loss = 1.18435784, grad/param norm = 1.4535e-01, time/batch = 15.3024s	
9534/28500 (epoch 16.726), train_loss = 1.11601027, grad/param norm = 1.7547e-01, time/batch = 15.4636s	
9535/28500 (epoch 16.728), train_loss = 0.96551843, grad/param norm = 1.3342e-01, time/batch = 15.1610s	
9536/28500 (epoch 16.730), train_loss = 1.10841009, grad/param norm = 1.6860e-01, time/batch = 15.2304s	
9537/28500 (epoch 16.732), train_loss = 0.89985163, grad/param norm = 1.3752e-01, time/batch = 15.2293s	
9538/28500 (epoch 16.733), train_loss = 0.91177705, grad/param norm = 1.3197e-01, time/batch = 15.1233s	
9539/28500 (epoch 16.735), train_loss = 0.94109876, grad/param norm = 1.4601e-01, time/batch = 15.0648s	
9540/28500 (epoch 16.737), train_loss = 0.86461849, grad/param norm = 1.2896e-01, time/batch = 15.3712s	
9541/28500 (epoch 16.739), train_loss = 1.04110434, grad/param norm = 1.6069e-01, time/batch = 15.6253s	
9542/28500 (epoch 16.740), train_loss = 1.07324748, grad/param norm = 1.4693e-01, time/batch = 15.5656s	
9543/28500 (epoch 16.742), train_loss = 0.99902166, grad/param norm = 1.4970e-01, time/batch = 15.2955s	
9544/28500 (epoch 16.744), train_loss = 1.13802173, grad/param norm = 1.7174e-01, time/batch = 15.5223s	
9545/28500 (epoch 16.746), train_loss = 0.98159256, grad/param norm = 1.4759e-01, time/batch = 15.3276s	
9546/28500 (epoch 16.747), train_loss = 0.98848259, grad/param norm = 1.4322e-01, time/batch = 15.3256s	
9547/28500 (epoch 16.749), train_loss = 1.20417030, grad/param norm = 1.8138e-01, time/batch = 15.1615s	
9548/28500 (epoch 16.751), train_loss = 0.97548511, grad/param norm = 1.5741e-01, time/batch = 15.4741s	
9549/28500 (epoch 16.753), train_loss = 1.01300649, grad/param norm = 1.4158e-01, time/batch = 15.1458s	
9550/28500 (epoch 16.754), train_loss = 0.93556230, grad/param norm = 1.4634e-01, time/batch = 15.4894s	
9551/28500 (epoch 16.756), train_loss = 1.19029139, grad/param norm = 1.6639e-01, time/batch = 15.6287s	
9552/28500 (epoch 16.758), train_loss = 1.15251279, grad/param norm = 1.6829e-01, time/batch = 15.3255s	
9553/28500 (epoch 16.760), train_loss = 0.95164114, grad/param norm = 1.4914e-01, time/batch = 15.5127s	
9554/28500 (epoch 16.761), train_loss = 0.97776390, grad/param norm = 1.5797e-01, time/batch = 15.3152s	
9555/28500 (epoch 16.763), train_loss = 0.85905428, grad/param norm = 1.3556e-01, time/batch = 15.1868s	
9556/28500 (epoch 16.765), train_loss = 1.02109954, grad/param norm = 1.4168e-01, time/batch = 15.2025s	
9557/28500 (epoch 16.767), train_loss = 0.89913652, grad/param norm = 1.3862e-01, time/batch = 15.1261s	
9558/28500 (epoch 16.768), train_loss = 1.15863337, grad/param norm = 1.6020e-01, time/batch = 15.2060s	
9559/28500 (epoch 16.770), train_loss = 0.93026983, grad/param norm = 1.4858e-01, time/batch = 15.1734s	
9560/28500 (epoch 16.772), train_loss = 0.81987402, grad/param norm = 1.3428e-01, time/batch = 15.2003s	
9561/28500 (epoch 16.774), train_loss = 1.07103503, grad/param norm = 1.6269e-01, time/batch = 15.4141s	
9562/28500 (epoch 16.775), train_loss = 1.13903265, grad/param norm = 1.4196e-01, time/batch = 15.3544s	
9563/28500 (epoch 16.777), train_loss = 1.12885017, grad/param norm = 1.6163e-01, time/batch = 15.5176s	
9564/28500 (epoch 16.779), train_loss = 0.91495867, grad/param norm = 1.3843e-01, time/batch = 15.2816s	
9565/28500 (epoch 16.781), train_loss = 1.07934893, grad/param norm = 1.6532e-01, time/batch = 15.2867s	
9566/28500 (epoch 16.782), train_loss = 1.13675115, grad/param norm = 1.6691e-01, time/batch = 15.4379s	
9567/28500 (epoch 16.784), train_loss = 0.89348542, grad/param norm = 1.3797e-01, time/batch = 15.5159s	
9568/28500 (epoch 16.786), train_loss = 0.96415827, grad/param norm = 1.4879e-01, time/batch = 15.6811s	
9569/28500 (epoch 16.788), train_loss = 1.04293839, grad/param norm = 1.6932e-01, time/batch = 15.4364s	
9570/28500 (epoch 16.789), train_loss = 0.82447182, grad/param norm = 1.5798e-01, time/batch = 15.0307s	
9571/28500 (epoch 16.791), train_loss = 1.07794724, grad/param norm = 1.5823e-01, time/batch = 15.6699s	
9572/28500 (epoch 16.793), train_loss = 1.04644764, grad/param norm = 1.5278e-01, time/batch = 15.3614s	
9573/28500 (epoch 16.795), train_loss = 1.08222649, grad/param norm = 1.4001e-01, time/batch = 15.4409s	
9574/28500 (epoch 16.796), train_loss = 0.95371616, grad/param norm = 1.4627e-01, time/batch = 15.4281s	
9575/28500 (epoch 16.798), train_loss = 0.89759504, grad/param norm = 1.4712e-01, time/batch = 15.3985s	
9576/28500 (epoch 16.800), train_loss = 0.95620877, grad/param norm = 1.8312e-01, time/batch = 15.0513s	
9577/28500 (epoch 16.802), train_loss = 1.04593990, grad/param norm = 1.8682e-01, time/batch = 15.1053s	
9578/28500 (epoch 16.804), train_loss = 1.09606568, grad/param norm = 1.4852e-01, time/batch = 15.0083s	
9579/28500 (epoch 16.805), train_loss = 1.06070832, grad/param norm = 1.5310e-01, time/batch = 15.3722s	
9580/28500 (epoch 16.807), train_loss = 1.10407715, grad/param norm = 1.5580e-01, time/batch = 15.4150s	
9581/28500 (epoch 16.809), train_loss = 1.02041452, grad/param norm = 1.4562e-01, time/batch = 15.1483s	
9582/28500 (epoch 16.811), train_loss = 1.10490295, grad/param norm = 1.6631e-01, time/batch = 15.1277s	
9583/28500 (epoch 16.812), train_loss = 1.08971711, grad/param norm = 1.6134e-01, time/batch = 15.3448s	
9584/28500 (epoch 16.814), train_loss = 1.03698713, grad/param norm = 1.5573e-01, time/batch = 15.6010s	
9585/28500 (epoch 16.816), train_loss = 1.18143509, grad/param norm = 1.9788e-01, time/batch = 15.4448s	
9586/28500 (epoch 16.818), train_loss = 1.16059130, grad/param norm = 1.5716e-01, time/batch = 15.3524s	
9587/28500 (epoch 16.819), train_loss = 1.06075011, grad/param norm = 1.4590e-01, time/batch = 15.5942s	
9588/28500 (epoch 16.821), train_loss = 1.03853875, grad/param norm = 1.6873e-01, time/batch = 15.4853s	
9589/28500 (epoch 16.823), train_loss = 1.21955349, grad/param norm = 1.8494e-01, time/batch = 15.3680s	
9590/28500 (epoch 16.825), train_loss = 1.03026021, grad/param norm = 1.6290e-01, time/batch = 15.1911s	
9591/28500 (epoch 16.826), train_loss = 1.06726264, grad/param norm = 1.6338e-01, time/batch = 15.5255s	
9592/28500 (epoch 16.828), train_loss = 0.95142247, grad/param norm = 1.7527e-01, time/batch = 15.4037s	
9593/28500 (epoch 16.830), train_loss = 1.01874541, grad/param norm = 1.4812e-01, time/batch = 15.3107s	
9594/28500 (epoch 16.832), train_loss = 1.09109194, grad/param norm = 1.7905e-01, time/batch = 15.3216s	
9595/28500 (epoch 16.833), train_loss = 1.20007243, grad/param norm = 1.6340e-01, time/batch = 15.3817s	
9596/28500 (epoch 16.835), train_loss = 1.01265959, grad/param norm = 1.5399e-01, time/batch = 15.4642s	
9597/28500 (epoch 16.837), train_loss = 0.92615870, grad/param norm = 1.4992e-01, time/batch = 15.5123s	
9598/28500 (epoch 16.839), train_loss = 1.19206135, grad/param norm = 1.9577e-01, time/batch = 15.1328s	
9599/28500 (epoch 16.840), train_loss = 1.22708252, grad/param norm = 1.8350e-01, time/batch = 15.3519s	
9600/28500 (epoch 16.842), train_loss = 1.16881317, grad/param norm = 1.6955e-01, time/batch = 15.1969s	
9601/28500 (epoch 16.844), train_loss = 1.08732817, grad/param norm = 1.6846e-01, time/batch = 15.4998s	
9602/28500 (epoch 16.846), train_loss = 1.22561421, grad/param norm = 1.7238e-01, time/batch = 15.3299s	
9603/28500 (epoch 16.847), train_loss = 1.01102868, grad/param norm = 1.4780e-01, time/batch = 15.4597s	
9604/28500 (epoch 16.849), train_loss = 1.03304494, grad/param norm = 1.6487e-01, time/batch = 15.6298s	
9605/28500 (epoch 16.851), train_loss = 0.89777979, grad/param norm = 1.3738e-01, time/batch = 15.6304s	
9606/28500 (epoch 16.853), train_loss = 1.07983157, grad/param norm = 1.5105e-01, time/batch = 15.3720s	
9607/28500 (epoch 16.854), train_loss = 1.09685857, grad/param norm = 1.5990e-01, time/batch = 15.2979s	
9608/28500 (epoch 16.856), train_loss = 1.20395203, grad/param norm = 1.8607e-01, time/batch = 15.2223s	
9609/28500 (epoch 16.858), train_loss = 0.96137738, grad/param norm = 1.3731e-01, time/batch = 15.1271s	
9610/28500 (epoch 16.860), train_loss = 1.05640156, grad/param norm = 1.5431e-01, time/batch = 15.4971s	
9611/28500 (epoch 16.861), train_loss = 1.12954918, grad/param norm = 1.7467e-01, time/batch = 15.5376s	
9612/28500 (epoch 16.863), train_loss = 1.15657257, grad/param norm = 1.7152e-01, time/batch = 15.4540s	
9613/28500 (epoch 16.865), train_loss = 1.06182604, grad/param norm = 1.6401e-01, time/batch = 15.3790s	
9614/28500 (epoch 16.867), train_loss = 1.12193789, grad/param norm = 1.6454e-01, time/batch = 15.2669s	
9615/28500 (epoch 16.868), train_loss = 0.94377046, grad/param norm = 1.4681e-01, time/batch = 15.5787s	
9616/28500 (epoch 16.870), train_loss = 0.90135062, grad/param norm = 1.3861e-01, time/batch = 15.5508s	
9617/28500 (epoch 16.872), train_loss = 1.12072878, grad/param norm = 1.8014e-01, time/batch = 15.6116s	
9618/28500 (epoch 16.874), train_loss = 1.05529481, grad/param norm = 1.8206e-01, time/batch = 15.2083s	
9619/28500 (epoch 16.875), train_loss = 1.17968380, grad/param norm = 1.7422e-01, time/batch = 15.3750s	
9620/28500 (epoch 16.877), train_loss = 1.10504014, grad/param norm = 1.5037e-01, time/batch = 15.3847s	
9621/28500 (epoch 16.879), train_loss = 1.08856096, grad/param norm = 1.5054e-01, time/batch = 15.5206s	
9622/28500 (epoch 16.881), train_loss = 1.09026650, grad/param norm = 1.6684e-01, time/batch = 15.4588s	
9623/28500 (epoch 16.882), train_loss = 0.99689271, grad/param norm = 1.4369e-01, time/batch = 15.3783s	
9624/28500 (epoch 16.884), train_loss = 1.09035347, grad/param norm = 1.6805e-01, time/batch = 15.3915s	
9625/28500 (epoch 16.886), train_loss = 1.03672473, grad/param norm = 1.4640e-01, time/batch = 15.2750s	
9626/28500 (epoch 16.888), train_loss = 0.96153641, grad/param norm = 1.5877e-01, time/batch = 15.2749s	
9627/28500 (epoch 16.889), train_loss = 1.07620215, grad/param norm = 1.5287e-01, time/batch = 15.4655s	
9628/28500 (epoch 16.891), train_loss = 1.07797568, grad/param norm = 1.5420e-01, time/batch = 15.4216s	
9629/28500 (epoch 16.893), train_loss = 1.01209937, grad/param norm = 1.5769e-01, time/batch = 15.1102s	
9630/28500 (epoch 16.895), train_loss = 1.25771442, grad/param norm = 1.8396e-01, time/batch = 15.2307s	
9631/28500 (epoch 16.896), train_loss = 1.15237765, grad/param norm = 1.6687e-01, time/batch = 15.1465s	
9632/28500 (epoch 16.898), train_loss = 1.05694589, grad/param norm = 1.5826e-01, time/batch = 15.4280s	
9633/28500 (epoch 16.900), train_loss = 0.91775575, grad/param norm = 1.5236e-01, time/batch = 15.5452s	
9634/28500 (epoch 16.902), train_loss = 0.94409521, grad/param norm = 1.5772e-01, time/batch = 15.2854s	
9635/28500 (epoch 16.904), train_loss = 0.98971290, grad/param norm = 1.4447e-01, time/batch = 15.2987s	
9636/28500 (epoch 16.905), train_loss = 1.08675995, grad/param norm = 1.5927e-01, time/batch = 15.3076s	
9637/28500 (epoch 16.907), train_loss = 1.04383928, grad/param norm = 1.5013e-01, time/batch = 15.5468s	
9638/28500 (epoch 16.909), train_loss = 0.95996440, grad/param norm = 1.5626e-01, time/batch = 15.4715s	
9639/28500 (epoch 16.911), train_loss = 0.97761594, grad/param norm = 1.4172e-01, time/batch = 15.1270s	
9640/28500 (epoch 16.912), train_loss = 0.85540900, grad/param norm = 1.4760e-01, time/batch = 14.9669s	
9641/28500 (epoch 16.914), train_loss = 1.15632105, grad/param norm = 1.4993e-01, time/batch = 15.4038s	
9642/28500 (epoch 16.916), train_loss = 1.08729960, grad/param norm = 1.6927e-01, time/batch = 15.1878s	
9643/28500 (epoch 16.918), train_loss = 1.08040630, grad/param norm = 1.7294e-01, time/batch = 15.1339s	
9644/28500 (epoch 16.919), train_loss = 1.05939341, grad/param norm = 1.5284e-01, time/batch = 15.3278s	
9645/28500 (epoch 16.921), train_loss = 1.18809808, grad/param norm = 1.8616e-01, time/batch = 15.2110s	
9646/28500 (epoch 16.923), train_loss = 1.07062678, grad/param norm = 1.8226e-01, time/batch = 15.2305s	
9647/28500 (epoch 16.925), train_loss = 0.99471494, grad/param norm = 1.6922e-01, time/batch = 15.3074s	
9648/28500 (epoch 16.926), train_loss = 1.04213369, grad/param norm = 1.5284e-01, time/batch = 15.2221s	
9649/28500 (epoch 16.928), train_loss = 1.01178378, grad/param norm = 1.5733e-01, time/batch = 15.4541s	
9650/28500 (epoch 16.930), train_loss = 0.82771725, grad/param norm = 1.2953e-01, time/batch = 15.2025s	
9651/28500 (epoch 16.932), train_loss = 0.84633825, grad/param norm = 1.2645e-01, time/batch = 15.3030s	
9652/28500 (epoch 16.933), train_loss = 1.13750313, grad/param norm = 1.6422e-01, time/batch = 15.2015s	
9653/28500 (epoch 16.935), train_loss = 1.15286608, grad/param norm = 1.6035e-01, time/batch = 15.2386s	
9654/28500 (epoch 16.937), train_loss = 1.16593921, grad/param norm = 1.6702e-01, time/batch = 15.3605s	
9655/28500 (epoch 16.939), train_loss = 1.25179809, grad/param norm = 1.7877e-01, time/batch = 15.3105s	
9656/28500 (epoch 16.940), train_loss = 0.95840204, grad/param norm = 1.5371e-01, time/batch = 15.2778s	
9657/28500 (epoch 16.942), train_loss = 1.10617931, grad/param norm = 1.6170e-01, time/batch = 15.4832s	
9658/28500 (epoch 16.944), train_loss = 1.04003136, grad/param norm = 1.5140e-01, time/batch = 15.1856s	
9659/28500 (epoch 16.946), train_loss = 1.17217770, grad/param norm = 1.5848e-01, time/batch = 15.1432s	
9660/28500 (epoch 16.947), train_loss = 1.36215035, grad/param norm = 1.8357e-01, time/batch = 21.9932s	
9661/28500 (epoch 16.949), train_loss = 0.99438189, grad/param norm = 1.4693e-01, time/batch = 20.3745s	
9662/28500 (epoch 16.951), train_loss = 1.24231082, grad/param norm = 1.9766e-01, time/batch = 15.6263s	
9663/28500 (epoch 16.953), train_loss = 1.23504616, grad/param norm = 1.7923e-01, time/batch = 15.3771s	
9664/28500 (epoch 16.954), train_loss = 1.21532079, grad/param norm = 1.7613e-01, time/batch = 15.2762s	
9665/28500 (epoch 16.956), train_loss = 1.13502020, grad/param norm = 1.8965e-01, time/batch = 15.3087s	
9666/28500 (epoch 16.958), train_loss = 1.26378673, grad/param norm = 1.6109e-01, time/batch = 15.1107s	
9667/28500 (epoch 16.960), train_loss = 0.96935005, grad/param norm = 1.5358e-01, time/batch = 15.3480s	
9668/28500 (epoch 16.961), train_loss = 1.30281946, grad/param norm = 1.8869e-01, time/batch = 15.4964s	
9669/28500 (epoch 16.963), train_loss = 1.18485016, grad/param norm = 1.8272e-01, time/batch = 15.4564s	
9670/28500 (epoch 16.965), train_loss = 0.99656661, grad/param norm = 1.6436e-01, time/batch = 15.2857s	
9671/28500 (epoch 16.967), train_loss = 0.97554449, grad/param norm = 1.5703e-01, time/batch = 15.5329s	
9672/28500 (epoch 16.968), train_loss = 0.91100106, grad/param norm = 1.2692e-01, time/batch = 15.8027s	
9673/28500 (epoch 16.970), train_loss = 1.00330774, grad/param norm = 1.5533e-01, time/batch = 15.3842s	
9674/28500 (epoch 16.972), train_loss = 1.09669684, grad/param norm = 1.6324e-01, time/batch = 15.2151s	
9675/28500 (epoch 16.974), train_loss = 1.28200825, grad/param norm = 1.7963e-01, time/batch = 15.4939s	
9676/28500 (epoch 16.975), train_loss = 1.04415197, grad/param norm = 1.6654e-01, time/batch = 15.5446s	
9677/28500 (epoch 16.977), train_loss = 1.20886546, grad/param norm = 1.5755e-01, time/batch = 15.4318s	
9678/28500 (epoch 16.979), train_loss = 1.02603531, grad/param norm = 1.6511e-01, time/batch = 15.4632s	
9679/28500 (epoch 16.981), train_loss = 0.98561686, grad/param norm = 1.4855e-01, time/batch = 15.5956s	
9680/28500 (epoch 16.982), train_loss = 1.02376253, grad/param norm = 1.4866e-01, time/batch = 15.2034s	
9681/28500 (epoch 16.984), train_loss = 1.17376635, grad/param norm = 1.6533e-01, time/batch = 15.3161s	
9682/28500 (epoch 16.986), train_loss = 1.32062339, grad/param norm = 1.7947e-01, time/batch = 15.4701s	
9683/28500 (epoch 16.988), train_loss = 0.90517597, grad/param norm = 1.5270e-01, time/batch = 15.5158s	
9684/28500 (epoch 16.989), train_loss = 1.13021226, grad/param norm = 1.7545e-01, time/batch = 15.2908s	
9685/28500 (epoch 16.991), train_loss = 1.01001808, grad/param norm = 1.5457e-01, time/batch = 15.2137s	
9686/28500 (epoch 16.993), train_loss = 1.01250503, grad/param norm = 1.6940e-01, time/batch = 15.2177s	
9687/28500 (epoch 16.995), train_loss = 1.00062231, grad/param norm = 1.6638e-01, time/batch = 15.2955s	
9688/28500 (epoch 16.996), train_loss = 0.96927415, grad/param norm = 1.5631e-01, time/batch = 15.0474s	
9689/28500 (epoch 16.998), train_loss = 1.18402964, grad/param norm = 1.7538e-01, time/batch = 15.4231s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
9690/28500 (epoch 17.000), train_loss = 1.03038009, grad/param norm = 1.5052e-01, time/batch = 15.2807s	
9691/28500 (epoch 17.002), train_loss = 1.21817026, grad/param norm = 1.8107e-01, time/batch = 15.2098s	
9692/28500 (epoch 17.004), train_loss = 1.02524099, grad/param norm = 1.5044e-01, time/batch = 15.2055s	
9693/28500 (epoch 17.005), train_loss = 1.20451846, grad/param norm = 1.7012e-01, time/batch = 15.5893s	
9694/28500 (epoch 17.007), train_loss = 0.95263526, grad/param norm = 1.4601e-01, time/batch = 15.3316s	
9695/28500 (epoch 17.009), train_loss = 1.13718321, grad/param norm = 1.7714e-01, time/batch = 15.3523s	
9696/28500 (epoch 17.011), train_loss = 1.02472094, grad/param norm = 2.0533e-01, time/batch = 15.4671s	
9697/28500 (epoch 17.012), train_loss = 0.93642457, grad/param norm = 1.3523e-01, time/batch = 15.5297s	
9698/28500 (epoch 17.014), train_loss = 0.96897391, grad/param norm = 1.5227e-01, time/batch = 15.3560s	
9699/28500 (epoch 17.016), train_loss = 1.03209270, grad/param norm = 1.4856e-01, time/batch = 15.4538s	
9700/28500 (epoch 17.018), train_loss = 1.08396913, grad/param norm = 1.6212e-01, time/batch = 15.3779s	
9701/28500 (epoch 17.019), train_loss = 1.16065505, grad/param norm = 1.6855e-01, time/batch = 15.7136s	
9702/28500 (epoch 17.021), train_loss = 1.14902315, grad/param norm = 1.4507e-01, time/batch = 15.6226s	
9703/28500 (epoch 17.023), train_loss = 1.04871842, grad/param norm = 1.5750e-01, time/batch = 15.4469s	
9704/28500 (epoch 17.025), train_loss = 1.07291641, grad/param norm = 1.5201e-01, time/batch = 15.2125s	
9705/28500 (epoch 17.026), train_loss = 1.06410315, grad/param norm = 1.5721e-01, time/batch = 15.1952s	
9706/28500 (epoch 17.028), train_loss = 1.13434459, grad/param norm = 1.6827e-01, time/batch = 15.4251s	
9707/28500 (epoch 17.030), train_loss = 1.15555333, grad/param norm = 1.8748e-01, time/batch = 15.6307s	
9708/28500 (epoch 17.032), train_loss = 1.15770544, grad/param norm = 1.6061e-01, time/batch = 15.4975s	
9709/28500 (epoch 17.033), train_loss = 1.23084590, grad/param norm = 1.7162e-01, time/batch = 15.3673s	
9710/28500 (epoch 17.035), train_loss = 1.09155920, grad/param norm = 1.7333e-01, time/batch = 15.5134s	
9711/28500 (epoch 17.037), train_loss = 1.16260396, grad/param norm = 1.4795e-01, time/batch = 15.2081s	
9712/28500 (epoch 17.039), train_loss = 1.18774943, grad/param norm = 1.6781e-01, time/batch = 15.2035s	
9713/28500 (epoch 17.040), train_loss = 1.24235845, grad/param norm = 1.6379e-01, time/batch = 15.5416s	
9714/28500 (epoch 17.042), train_loss = 1.16483082, grad/param norm = 1.6724e-01, time/batch = 15.3030s	
9715/28500 (epoch 17.044), train_loss = 1.08011946, grad/param norm = 1.6181e-01, time/batch = 15.3885s	
9716/28500 (epoch 17.046), train_loss = 1.31323061, grad/param norm = 1.6594e-01, time/batch = 15.3879s	
9717/28500 (epoch 17.047), train_loss = 1.20890405, grad/param norm = 1.6507e-01, time/batch = 15.3691s	
9718/28500 (epoch 17.049), train_loss = 1.11633509, grad/param norm = 1.7255e-01, time/batch = 15.5116s	
9719/28500 (epoch 17.051), train_loss = 1.04826825, grad/param norm = 1.5389e-01, time/batch = 15.3576s	
9720/28500 (epoch 17.053), train_loss = 1.08890208, grad/param norm = 1.7173e-01, time/batch = 15.4971s	
9721/28500 (epoch 17.054), train_loss = 1.16161331, grad/param norm = 1.6147e-01, time/batch = 15.4749s	
9722/28500 (epoch 17.056), train_loss = 0.96902863, grad/param norm = 1.4477e-01, time/batch = 15.4678s	
9723/28500 (epoch 17.058), train_loss = 0.97059410, grad/param norm = 1.4766e-01, time/batch = 15.5839s	
9724/28500 (epoch 17.060), train_loss = 1.16904001, grad/param norm = 1.6398e-01, time/batch = 15.5252s	
9725/28500 (epoch 17.061), train_loss = 1.10868474, grad/param norm = 1.8014e-01, time/batch = 15.5155s	
9726/28500 (epoch 17.063), train_loss = 1.15350687, grad/param norm = 1.5135e-01, time/batch = 15.5134s	
9727/28500 (epoch 17.065), train_loss = 1.19424980, grad/param norm = 1.7445e-01, time/batch = 15.3424s	
9728/28500 (epoch 17.067), train_loss = 1.04636790, grad/param norm = 1.4315e-01, time/batch = 15.3695s	
9729/28500 (epoch 17.068), train_loss = 1.07762874, grad/param norm = 1.5801e-01, time/batch = 15.5755s	
9730/28500 (epoch 17.070), train_loss = 1.13493719, grad/param norm = 1.7455e-01, time/batch = 15.3690s	
9731/28500 (epoch 17.072), train_loss = 1.27990191, grad/param norm = 1.7624e-01, time/batch = 15.3637s	
9732/28500 (epoch 17.074), train_loss = 1.12786291, grad/param norm = 1.4867e-01, time/batch = 15.3345s	
9733/28500 (epoch 17.075), train_loss = 1.07429968, grad/param norm = 1.4040e-01, time/batch = 15.4321s	
9734/28500 (epoch 17.077), train_loss = 1.14964127, grad/param norm = 1.6841e-01, time/batch = 15.4108s	
9735/28500 (epoch 17.079), train_loss = 1.09309620, grad/param norm = 1.5290e-01, time/batch = 15.5169s	
9736/28500 (epoch 17.081), train_loss = 1.21337743, grad/param norm = 1.6871e-01, time/batch = 15.3602s	
9737/28500 (epoch 17.082), train_loss = 1.11913118, grad/param norm = 1.8168e-01, time/batch = 15.4109s	
9738/28500 (epoch 17.084), train_loss = 1.13142679, grad/param norm = 1.5598e-01, time/batch = 15.4301s	
9739/28500 (epoch 17.086), train_loss = 1.08043294, grad/param norm = 1.7025e-01, time/batch = 15.1876s	
9740/28500 (epoch 17.088), train_loss = 0.99498750, grad/param norm = 1.6527e-01, time/batch = 15.1975s	
9741/28500 (epoch 17.089), train_loss = 1.19386736, grad/param norm = 1.4361e-01, time/batch = 15.4395s	
9742/28500 (epoch 17.091), train_loss = 0.98992815, grad/param norm = 1.5712e-01, time/batch = 15.6899s	
9743/28500 (epoch 17.093), train_loss = 1.13609962, grad/param norm = 1.5295e-01, time/batch = 15.4637s	
9744/28500 (epoch 17.095), train_loss = 1.03896566, grad/param norm = 1.4545e-01, time/batch = 15.6018s	
9745/28500 (epoch 17.096), train_loss = 1.21854782, grad/param norm = 1.6059e-01, time/batch = 15.6561s	
9746/28500 (epoch 17.098), train_loss = 1.16769490, grad/param norm = 1.9224e-01, time/batch = 15.5584s	
9747/28500 (epoch 17.100), train_loss = 1.05003286, grad/param norm = 1.6014e-01, time/batch = 15.3607s	
9748/28500 (epoch 17.102), train_loss = 1.21227571, grad/param norm = 1.6810e-01, time/batch = 15.4775s	
9749/28500 (epoch 17.104), train_loss = 1.08126468, grad/param norm = 1.7213e-01, time/batch = 15.3648s	
9750/28500 (epoch 17.105), train_loss = 1.20541767, grad/param norm = 1.6181e-01, time/batch = 15.1842s	
9751/28500 (epoch 17.107), train_loss = 0.98432414, grad/param norm = 1.5819e-01, time/batch = 15.2066s	
9752/28500 (epoch 17.109), train_loss = 0.97017258, grad/param norm = 1.7184e-01, time/batch = 15.3868s	
9753/28500 (epoch 17.111), train_loss = 1.06099655, grad/param norm = 1.6657e-01, time/batch = 15.2784s	
9754/28500 (epoch 17.112), train_loss = 1.15557281, grad/param norm = 1.6025e-01, time/batch = 15.2864s	
9755/28500 (epoch 17.114), train_loss = 1.06844425, grad/param norm = 1.5917e-01, time/batch = 15.2971s	
9756/28500 (epoch 17.116), train_loss = 1.28050535, grad/param norm = 1.7354e-01, time/batch = 15.4496s	
9757/28500 (epoch 17.118), train_loss = 0.95536596, grad/param norm = 1.5823e-01, time/batch = 15.3234s	
9758/28500 (epoch 17.119), train_loss = 1.12548391, grad/param norm = 1.7402e-01, time/batch = 15.4553s	
9759/28500 (epoch 17.121), train_loss = 1.25891865, grad/param norm = 1.8613e-01, time/batch = 15.2119s	
9760/28500 (epoch 17.123), train_loss = 1.15738081, grad/param norm = 1.6021e-01, time/batch = 15.1306s	
9761/28500 (epoch 17.125), train_loss = 1.10293260, grad/param norm = 1.5430e-01, time/batch = 15.3126s	
9762/28500 (epoch 17.126), train_loss = 1.09278940, grad/param norm = 1.5923e-01, time/batch = 15.0488s	
9763/28500 (epoch 17.128), train_loss = 1.07709697, grad/param norm = 1.5197e-01, time/batch = 15.2166s	
9764/28500 (epoch 17.130), train_loss = 0.98517341, grad/param norm = 1.5699e-01, time/batch = 15.4564s	
9765/28500 (epoch 17.132), train_loss = 1.15436358, grad/param norm = 1.7371e-01, time/batch = 15.4546s	
9766/28500 (epoch 17.133), train_loss = 1.16644061, grad/param norm = 1.8069e-01, time/batch = 15.3020s	
9767/28500 (epoch 17.135), train_loss = 1.05950013, grad/param norm = 1.4272e-01, time/batch = 15.4495s	
9768/28500 (epoch 17.137), train_loss = 1.08015470, grad/param norm = 1.6700e-01, time/batch = 15.5142s	
9769/28500 (epoch 17.139), train_loss = 1.06840407, grad/param norm = 1.4451e-01, time/batch = 15.4454s	
9770/28500 (epoch 17.140), train_loss = 1.13131665, grad/param norm = 1.5025e-01, time/batch = 15.1204s	
9771/28500 (epoch 17.142), train_loss = 1.08553974, grad/param norm = 1.7530e-01, time/batch = 15.0666s	
9772/28500 (epoch 17.144), train_loss = 1.02673523, grad/param norm = 1.5514e-01, time/batch = 15.2010s	
9773/28500 (epoch 17.146), train_loss = 1.04266509, grad/param norm = 1.5456e-01, time/batch = 15.6097s	
9774/28500 (epoch 17.147), train_loss = 0.95376023, grad/param norm = 1.4894e-01, time/batch = 15.4033s	
9775/28500 (epoch 17.149), train_loss = 0.94562805, grad/param norm = 1.3752e-01, time/batch = 15.0440s	
9776/28500 (epoch 17.151), train_loss = 0.99677741, grad/param norm = 1.4253e-01, time/batch = 15.4999s	
9777/28500 (epoch 17.153), train_loss = 1.10537298, grad/param norm = 1.6859e-01, time/batch = 15.4387s	
9778/28500 (epoch 17.154), train_loss = 0.97789788, grad/param norm = 1.4875e-01, time/batch = 15.2867s	
9779/28500 (epoch 17.156), train_loss = 1.21585782, grad/param norm = 1.7550e-01, time/batch = 15.3598s	
9780/28500 (epoch 17.158), train_loss = 1.07733232, grad/param norm = 1.5395e-01, time/batch = 15.3704s	
9781/28500 (epoch 17.160), train_loss = 0.97614849, grad/param norm = 1.5428e-01, time/batch = 15.3888s	
9782/28500 (epoch 17.161), train_loss = 1.04208028, grad/param norm = 1.5181e-01, time/batch = 15.3636s	
9783/28500 (epoch 17.163), train_loss = 0.93531611, grad/param norm = 1.5078e-01, time/batch = 15.2958s	
9784/28500 (epoch 17.165), train_loss = 1.28969041, grad/param norm = 1.6658e-01, time/batch = 15.5047s	
9785/28500 (epoch 17.167), train_loss = 1.33656112, grad/param norm = 1.8372e-01, time/batch = 15.2805s	
9786/28500 (epoch 17.168), train_loss = 1.20873756, grad/param norm = 1.9451e-01, time/batch = 15.3012s	
9787/28500 (epoch 17.170), train_loss = 1.21428881, grad/param norm = 2.0378e-01, time/batch = 15.5494s	
9788/28500 (epoch 17.172), train_loss = 1.07467448, grad/param norm = 1.4719e-01, time/batch = 15.4674s	
9789/28500 (epoch 17.174), train_loss = 1.23860484, grad/param norm = 1.8786e-01, time/batch = 15.3190s	
9790/28500 (epoch 17.175), train_loss = 1.08536594, grad/param norm = 1.4783e-01, time/batch = 15.3609s	
9791/28500 (epoch 17.177), train_loss = 1.16374935, grad/param norm = 1.7504e-01, time/batch = 15.5393s	
9792/28500 (epoch 17.179), train_loss = 1.08488815, grad/param norm = 1.7012e-01, time/batch = 15.3513s	
9793/28500 (epoch 17.181), train_loss = 1.16935465, grad/param norm = 1.6234e-01, time/batch = 15.3867s	
9794/28500 (epoch 17.182), train_loss = 1.07219132, grad/param norm = 1.4269e-01, time/batch = 15.1383s	
9795/28500 (epoch 17.184), train_loss = 1.27364734, grad/param norm = 1.7607e-01, time/batch = 15.2568s	
9796/28500 (epoch 17.186), train_loss = 1.20470237, grad/param norm = 1.6532e-01, time/batch = 15.4403s	
9797/28500 (epoch 17.188), train_loss = 1.11742636, grad/param norm = 1.5940e-01, time/batch = 15.3788s	
9798/28500 (epoch 17.189), train_loss = 1.12929918, grad/param norm = 1.6661e-01, time/batch = 15.4884s	
9799/28500 (epoch 17.191), train_loss = 1.32437199, grad/param norm = 1.8222e-01, time/batch = 15.5980s	
9800/28500 (epoch 17.193), train_loss = 1.17477414, grad/param norm = 1.7637e-01, time/batch = 15.1329s	
9801/28500 (epoch 17.195), train_loss = 1.24173089, grad/param norm = 1.6250e-01, time/batch = 15.3226s	
9802/28500 (epoch 17.196), train_loss = 1.15386959, grad/param norm = 1.8966e-01, time/batch = 15.3654s	
9803/28500 (epoch 17.198), train_loss = 1.12558627, grad/param norm = 1.8339e-01, time/batch = 15.3253s	
9804/28500 (epoch 17.200), train_loss = 1.14118273, grad/param norm = 1.6277e-01, time/batch = 15.5491s	
9805/28500 (epoch 17.202), train_loss = 1.12685356, grad/param norm = 1.7056e-01, time/batch = 15.5341s	
9806/28500 (epoch 17.204), train_loss = 1.04348835, grad/param norm = 1.4496e-01, time/batch = 15.1452s	
9807/28500 (epoch 17.205), train_loss = 1.07283074, grad/param norm = 1.7131e-01, time/batch = 15.4972s	
9808/28500 (epoch 17.207), train_loss = 1.01195047, grad/param norm = 1.5664e-01, time/batch = 15.2171s	
9809/28500 (epoch 17.209), train_loss = 1.11162076, grad/param norm = 1.5028e-01, time/batch = 15.4795s	
9810/28500 (epoch 17.211), train_loss = 0.96708509, grad/param norm = 1.4954e-01, time/batch = 15.1993s	
9811/28500 (epoch 17.212), train_loss = 0.94226977, grad/param norm = 1.3773e-01, time/batch = 15.4661s	
9812/28500 (epoch 17.214), train_loss = 1.10858082, grad/param norm = 1.7527e-01, time/batch = 15.4381s	
9813/28500 (epoch 17.216), train_loss = 0.99665019, grad/param norm = 1.4941e-01, time/batch = 15.6161s	
9814/28500 (epoch 17.218), train_loss = 1.22816026, grad/param norm = 1.5606e-01, time/batch = 15.2495s	
9815/28500 (epoch 17.219), train_loss = 1.14934455, grad/param norm = 1.7029e-01, time/batch = 15.5127s	
9816/28500 (epoch 17.221), train_loss = 0.96247442, grad/param norm = 1.5401e-01, time/batch = 15.2053s	
9817/28500 (epoch 17.223), train_loss = 1.22590782, grad/param norm = 1.6893e-01, time/batch = 15.1842s	
9818/28500 (epoch 17.225), train_loss = 1.23422749, grad/param norm = 1.8051e-01, time/batch = 15.3519s	
9819/28500 (epoch 17.226), train_loss = 1.05444776, grad/param norm = 1.5327e-01, time/batch = 15.4564s	
9820/28500 (epoch 17.228), train_loss = 1.18025412, grad/param norm = 1.4569e-01, time/batch = 15.5374s	
9821/28500 (epoch 17.230), train_loss = 1.19024582, grad/param norm = 1.5815e-01, time/batch = 15.6352s	
9822/28500 (epoch 17.232), train_loss = 1.15445908, grad/param norm = 1.4977e-01, time/batch = 15.3825s	
9823/28500 (epoch 17.233), train_loss = 1.13111226, grad/param norm = 1.6767e-01, time/batch = 15.2354s	
9824/28500 (epoch 17.235), train_loss = 1.07266880, grad/param norm = 1.4241e-01, time/batch = 15.2164s	
9825/28500 (epoch 17.237), train_loss = 0.96381563, grad/param norm = 1.3613e-01, time/batch = 15.3991s	
9826/28500 (epoch 17.239), train_loss = 1.02151847, grad/param norm = 1.4465e-01, time/batch = 15.6245s	
9827/28500 (epoch 17.240), train_loss = 0.98514295, grad/param norm = 1.6265e-01, time/batch = 15.5546s	
9828/28500 (epoch 17.242), train_loss = 1.14711709, grad/param norm = 1.8024e-01, time/batch = 15.4150s	
9829/28500 (epoch 17.244), train_loss = 1.15084964, grad/param norm = 1.4839e-01, time/batch = 15.2906s	
9830/28500 (epoch 17.246), train_loss = 1.19915563, grad/param norm = 1.6162e-01, time/batch = 15.2705s	
9831/28500 (epoch 17.247), train_loss = 1.27072673, grad/param norm = 1.7456e-01, time/batch = 15.7053s	
9832/28500 (epoch 17.249), train_loss = 1.09914417, grad/param norm = 1.6012e-01, time/batch = 15.7062s	
9833/28500 (epoch 17.251), train_loss = 1.02686308, grad/param norm = 1.4273e-01, time/batch = 15.5571s	
9834/28500 (epoch 17.253), train_loss = 1.27258169, grad/param norm = 1.8536e-01, time/batch = 15.3775s	
9835/28500 (epoch 17.254), train_loss = 1.23508768, grad/param norm = 1.6310e-01, time/batch = 15.0716s	
9836/28500 (epoch 17.256), train_loss = 1.04475627, grad/param norm = 1.5394e-01, time/batch = 15.3029s	
9837/28500 (epoch 17.258), train_loss = 1.10850726, grad/param norm = 1.7495e-01, time/batch = 15.1414s	
9838/28500 (epoch 17.260), train_loss = 1.03131733, grad/param norm = 1.5463e-01, time/batch = 15.4384s	
9839/28500 (epoch 17.261), train_loss = 1.04702482, grad/param norm = 1.6260e-01, time/batch = 15.2905s	
9840/28500 (epoch 17.263), train_loss = 1.22166530, grad/param norm = 1.7887e-01, time/batch = 15.3724s	
9841/28500 (epoch 17.265), train_loss = 1.11140541, grad/param norm = 1.6452e-01, time/batch = 15.4799s	
9842/28500 (epoch 17.267), train_loss = 1.25063803, grad/param norm = 1.7819e-01, time/batch = 15.6101s	
9843/28500 (epoch 17.268), train_loss = 1.15601140, grad/param norm = 1.5941e-01, time/batch = 15.4562s	
9844/28500 (epoch 17.270), train_loss = 1.14817792, grad/param norm = 1.8281e-01, time/batch = 15.5468s	
9845/28500 (epoch 17.272), train_loss = 1.08302672, grad/param norm = 1.5899e-01, time/batch = 15.2972s	
9846/28500 (epoch 17.274), train_loss = 1.22549433, grad/param norm = 1.6414e-01, time/batch = 15.2025s	
9847/28500 (epoch 17.275), train_loss = 1.13246523, grad/param norm = 1.4464e-01, time/batch = 15.4511s	
9848/28500 (epoch 17.277), train_loss = 1.11099087, grad/param norm = 1.6086e-01, time/batch = 15.3974s	
9849/28500 (epoch 17.279), train_loss = 1.15857959, grad/param norm = 1.6944e-01, time/batch = 15.5522s	
9850/28500 (epoch 17.281), train_loss = 1.18803827, grad/param norm = 1.7579e-01, time/batch = 15.5112s	
9851/28500 (epoch 17.282), train_loss = 1.02646011, grad/param norm = 1.4967e-01, time/batch = 15.5351s	
9852/28500 (epoch 17.284), train_loss = 1.12952704, grad/param norm = 1.7289e-01, time/batch = 15.4624s	
9853/28500 (epoch 17.286), train_loss = 1.21112848, grad/param norm = 1.6366e-01, time/batch = 15.4505s	
9854/28500 (epoch 17.288), train_loss = 1.16407564, grad/param norm = 1.6666e-01, time/batch = 15.5830s	
9855/28500 (epoch 17.289), train_loss = 1.17049858, grad/param norm = 1.7736e-01, time/batch = 15.5357s	
9856/28500 (epoch 17.291), train_loss = 1.10941198, grad/param norm = 1.5996e-01, time/batch = 15.3032s	
9857/28500 (epoch 17.293), train_loss = 1.07983987, grad/param norm = 1.6239e-01, time/batch = 15.4435s	
9858/28500 (epoch 17.295), train_loss = 0.98458169, grad/param norm = 1.6536e-01, time/batch = 15.3006s	
9859/28500 (epoch 17.296), train_loss = 0.99984006, grad/param norm = 1.4510e-01, time/batch = 15.1252s	
9860/28500 (epoch 17.298), train_loss = 1.18370021, grad/param norm = 1.5461e-01, time/batch = 15.4521s	
9861/28500 (epoch 17.300), train_loss = 1.01271595, grad/param norm = 1.5207e-01, time/batch = 15.4555s	
9862/28500 (epoch 17.302), train_loss = 0.99277521, grad/param norm = 1.4551e-01, time/batch = 15.3046s	
9863/28500 (epoch 17.304), train_loss = 1.07437128, grad/param norm = 1.4917e-01, time/batch = 15.3825s	
9864/28500 (epoch 17.305), train_loss = 1.16251021, grad/param norm = 1.5372e-01, time/batch = 15.2819s	
9865/28500 (epoch 17.307), train_loss = 1.10196272, grad/param norm = 1.6490e-01, time/batch = 15.3790s	
9866/28500 (epoch 17.309), train_loss = 1.09003841, grad/param norm = 1.5124e-01, time/batch = 15.3753s	
9867/28500 (epoch 17.311), train_loss = 1.15777831, grad/param norm = 1.5610e-01, time/batch = 15.3465s	
9868/28500 (epoch 17.312), train_loss = 1.09313391, grad/param norm = 1.6570e-01, time/batch = 15.4173s	
9869/28500 (epoch 17.314), train_loss = 1.18566882, grad/param norm = 1.8079e-01, time/batch = 15.5391s	
9870/28500 (epoch 17.316), train_loss = 1.13126485, grad/param norm = 1.5575e-01, time/batch = 15.4409s	
9871/28500 (epoch 17.318), train_loss = 1.17153165, grad/param norm = 1.5652e-01, time/batch = 15.4043s	
9872/28500 (epoch 17.319), train_loss = 1.07498635, grad/param norm = 1.6402e-01, time/batch = 15.7894s	
9873/28500 (epoch 17.321), train_loss = 1.06652284, grad/param norm = 1.6249e-01, time/batch = 15.5355s	
9874/28500 (epoch 17.323), train_loss = 1.07152936, grad/param norm = 2.1189e-01, time/batch = 15.4737s	
9875/28500 (epoch 17.325), train_loss = 1.25622341, grad/param norm = 1.8026e-01, time/batch = 15.1476s	
9876/28500 (epoch 17.326), train_loss = 1.10703488, grad/param norm = 1.5851e-01, time/batch = 15.3024s	
9877/28500 (epoch 17.328), train_loss = 0.91528581, grad/param norm = 1.5582e-01, time/batch = 15.3939s	
9878/28500 (epoch 17.330), train_loss = 1.02783694, grad/param norm = 1.7040e-01, time/batch = 15.3731s	
9879/28500 (epoch 17.332), train_loss = 1.09708097, grad/param norm = 1.5320e-01, time/batch = 15.5291s	
9880/28500 (epoch 17.333), train_loss = 0.92341898, grad/param norm = 1.4693e-01, time/batch = 15.4421s	
9881/28500 (epoch 17.335), train_loss = 0.98578918, grad/param norm = 1.5542e-01, time/batch = 15.4655s	
9882/28500 (epoch 17.337), train_loss = 1.01499078, grad/param norm = 1.4723e-01, time/batch = 15.2081s	
9883/28500 (epoch 17.339), train_loss = 0.93932729, grad/param norm = 1.3932e-01, time/batch = 15.1380s	
9884/28500 (epoch 17.340), train_loss = 1.14055484, grad/param norm = 1.8985e-01, time/batch = 15.3373s	
9885/28500 (epoch 17.342), train_loss = 1.09622531, grad/param norm = 1.6481e-01, time/batch = 15.4680s	
9886/28500 (epoch 17.344), train_loss = 1.04630234, grad/param norm = 1.8519e-01, time/batch = 15.4777s	
9887/28500 (epoch 17.346), train_loss = 0.89268182, grad/param norm = 1.2935e-01, time/batch = 15.6195s	
9888/28500 (epoch 17.347), train_loss = 1.07438361, grad/param norm = 1.5788e-01, time/batch = 15.4639s	
9889/28500 (epoch 17.349), train_loss = 1.04729009, grad/param norm = 1.4019e-01, time/batch = 15.5159s	
9890/28500 (epoch 17.351), train_loss = 0.99293118, grad/param norm = 1.4562e-01, time/batch = 15.4513s	
9891/28500 (epoch 17.353), train_loss = 1.12570776, grad/param norm = 1.6129e-01, time/batch = 15.4624s	
9892/28500 (epoch 17.354), train_loss = 0.96316272, grad/param norm = 1.4541e-01, time/batch = 27.6099s	
9893/28500 (epoch 17.356), train_loss = 0.98673477, grad/param norm = 1.3869e-01, time/batch = 15.3035s	
9894/28500 (epoch 17.358), train_loss = 1.10247903, grad/param norm = 1.5750e-01, time/batch = 15.5163s	
9895/28500 (epoch 17.360), train_loss = 1.11767048, grad/param norm = 1.6114e-01, time/batch = 15.4815s	
9896/28500 (epoch 17.361), train_loss = 1.01697583, grad/param norm = 1.5345e-01, time/batch = 15.3412s	
9897/28500 (epoch 17.363), train_loss = 0.95553710, grad/param norm = 1.3888e-01, time/batch = 15.2412s	
9898/28500 (epoch 17.365), train_loss = 1.06275100, grad/param norm = 1.6230e-01, time/batch = 15.2146s	
9899/28500 (epoch 17.367), train_loss = 1.08842978, grad/param norm = 1.6043e-01, time/batch = 15.5648s	
9900/28500 (epoch 17.368), train_loss = 1.05146495, grad/param norm = 1.5059e-01, time/batch = 15.4393s	
9901/28500 (epoch 17.370), train_loss = 1.08068811, grad/param norm = 1.5696e-01, time/batch = 15.5890s	
9902/28500 (epoch 17.372), train_loss = 0.93974757, grad/param norm = 1.4976e-01, time/batch = 15.5807s	
9903/28500 (epoch 17.374), train_loss = 1.05111617, grad/param norm = 1.6509e-01, time/batch = 15.4782s	
9904/28500 (epoch 17.375), train_loss = 1.21822608, grad/param norm = 1.5973e-01, time/batch = 15.4701s	
9905/28500 (epoch 17.377), train_loss = 0.97141577, grad/param norm = 1.6398e-01, time/batch = 15.4301s	
9906/28500 (epoch 17.379), train_loss = 0.84958018, grad/param norm = 1.5670e-01, time/batch = 15.2543s	
9907/28500 (epoch 17.381), train_loss = 1.04231242, grad/param norm = 1.4487e-01, time/batch = 15.5724s	
9908/28500 (epoch 17.382), train_loss = 1.03986783, grad/param norm = 1.7401e-01, time/batch = 15.4596s	
9909/28500 (epoch 17.384), train_loss = 0.96408797, grad/param norm = 1.4496e-01, time/batch = 15.4680s	
9910/28500 (epoch 17.386), train_loss = 0.93292066, grad/param norm = 1.4614e-01, time/batch = 15.5208s	
9911/28500 (epoch 17.388), train_loss = 1.17602384, grad/param norm = 1.6706e-01, time/batch = 15.6297s	
9912/28500 (epoch 17.389), train_loss = 0.97493985, grad/param norm = 1.5347e-01, time/batch = 15.3036s	
9913/28500 (epoch 17.391), train_loss = 0.97055964, grad/param norm = 1.4953e-01, time/batch = 15.5441s	
9914/28500 (epoch 17.393), train_loss = 0.96253297, grad/param norm = 1.6169e-01, time/batch = 15.4822s	
9915/28500 (epoch 17.395), train_loss = 1.22237490, grad/param norm = 1.6211e-01, time/batch = 15.2201s	
9916/28500 (epoch 17.396), train_loss = 1.17743955, grad/param norm = 1.7947e-01, time/batch = 15.5321s	
9917/28500 (epoch 17.398), train_loss = 0.87215569, grad/param norm = 1.6357e-01, time/batch = 15.7131s	
9918/28500 (epoch 17.400), train_loss = 1.06422435, grad/param norm = 1.6621e-01, time/batch = 15.4420s	
9919/28500 (epoch 17.402), train_loss = 1.11287535, grad/param norm = 1.6204e-01, time/batch = 15.1976s	
9920/28500 (epoch 17.404), train_loss = 1.17199326, grad/param norm = 1.7317e-01, time/batch = 15.3986s	
9921/28500 (epoch 17.405), train_loss = 1.19111584, grad/param norm = 1.5945e-01, time/batch = 15.5660s	
9922/28500 (epoch 17.407), train_loss = 1.09214745, grad/param norm = 1.5439e-01, time/batch = 15.5533s	
9923/28500 (epoch 17.409), train_loss = 1.09250951, grad/param norm = 1.6105e-01, time/batch = 15.4535s	
9924/28500 (epoch 17.411), train_loss = 1.19508898, grad/param norm = 1.6309e-01, time/batch = 15.3117s	
9925/28500 (epoch 17.412), train_loss = 1.21621574, grad/param norm = 1.7905e-01, time/batch = 15.4602s	
9926/28500 (epoch 17.414), train_loss = 1.11582048, grad/param norm = 1.6262e-01, time/batch = 15.3626s	
9927/28500 (epoch 17.416), train_loss = 1.02074053, grad/param norm = 1.7310e-01, time/batch = 15.3065s	
9928/28500 (epoch 17.418), train_loss = 1.09062188, grad/param norm = 1.4711e-01, time/batch = 15.2992s	
9929/28500 (epoch 17.419), train_loss = 1.23896078, grad/param norm = 1.7582e-01, time/batch = 15.2780s	
9930/28500 (epoch 17.421), train_loss = 1.17660531, grad/param norm = 1.6976e-01, time/batch = 15.4367s	
9931/28500 (epoch 17.423), train_loss = 1.19323588, grad/param norm = 1.8337e-01, time/batch = 15.4355s	
9932/28500 (epoch 17.425), train_loss = 1.12863726, grad/param norm = 1.6013e-01, time/batch = 15.3769s	
9933/28500 (epoch 17.426), train_loss = 1.08608519, grad/param norm = 1.7334e-01, time/batch = 15.3318s	
9934/28500 (epoch 17.428), train_loss = 1.29189953, grad/param norm = 1.6580e-01, time/batch = 15.4379s	
9935/28500 (epoch 17.430), train_loss = 1.22245606, grad/param norm = 1.5650e-01, time/batch = 15.4458s	
9936/28500 (epoch 17.432), train_loss = 1.14837213, grad/param norm = 1.8268e-01, time/batch = 15.4417s	
9937/28500 (epoch 17.433), train_loss = 1.15638184, grad/param norm = 1.7733e-01, time/batch = 15.2919s	
9938/28500 (epoch 17.435), train_loss = 1.09307980, grad/param norm = 1.6112e-01, time/batch = 15.2165s	
9939/28500 (epoch 17.437), train_loss = 0.98255022, grad/param norm = 1.4046e-01, time/batch = 15.3045s	
9940/28500 (epoch 17.439), train_loss = 1.04212334, grad/param norm = 1.4581e-01, time/batch = 15.5658s	
9941/28500 (epoch 17.440), train_loss = 1.31008651, grad/param norm = 1.7574e-01, time/batch = 15.6228s	
9942/28500 (epoch 17.442), train_loss = 1.02870054, grad/param norm = 1.6700e-01, time/batch = 15.4765s	
9943/28500 (epoch 17.444), train_loss = 0.92277042, grad/param norm = 1.3769e-01, time/batch = 15.4774s	
9944/28500 (epoch 17.446), train_loss = 0.90166609, grad/param norm = 1.3317e-01, time/batch = 15.5525s	
9945/28500 (epoch 17.447), train_loss = 0.93356358, grad/param norm = 1.5125e-01, time/batch = 15.5369s	
9946/28500 (epoch 17.449), train_loss = 1.02688091, grad/param norm = 1.4472e-01, time/batch = 15.5830s	
9947/28500 (epoch 17.451), train_loss = 1.07434018, grad/param norm = 1.5451e-01, time/batch = 15.4263s	
9948/28500 (epoch 17.453), train_loss = 1.05045349, grad/param norm = 1.4745e-01, time/batch = 15.2223s	
9949/28500 (epoch 17.454), train_loss = 1.03406834, grad/param norm = 1.4639e-01, time/batch = 15.4278s	
9950/28500 (epoch 17.456), train_loss = 1.14051940, grad/param norm = 1.6535e-01, time/batch = 15.4681s	
9951/28500 (epoch 17.458), train_loss = 1.06215218, grad/param norm = 1.6233e-01, time/batch = 15.4692s	
9952/28500 (epoch 17.460), train_loss = 1.11711429, grad/param norm = 1.5691e-01, time/batch = 15.3048s	
9953/28500 (epoch 17.461), train_loss = 1.02988894, grad/param norm = 1.6357e-01, time/batch = 15.1941s	
9954/28500 (epoch 17.463), train_loss = 0.95514152, grad/param norm = 1.3559e-01, time/batch = 15.3731s	
9955/28500 (epoch 17.465), train_loss = 0.92128277, grad/param norm = 1.7019e-01, time/batch = 15.2252s	
9956/28500 (epoch 17.467), train_loss = 1.08041671, grad/param norm = 1.5373e-01, time/batch = 15.3949s	
9957/28500 (epoch 17.468), train_loss = 0.98056448, grad/param norm = 1.3480e-01, time/batch = 15.3668s	
9958/28500 (epoch 17.470), train_loss = 1.00585967, grad/param norm = 1.4862e-01, time/batch = 15.2102s	
9959/28500 (epoch 17.472), train_loss = 1.03192613, grad/param norm = 1.4929e-01, time/batch = 15.1070s	
9960/28500 (epoch 17.474), train_loss = 1.28948257, grad/param norm = 1.7986e-01, time/batch = 15.4173s	
9961/28500 (epoch 17.475), train_loss = 0.99801762, grad/param norm = 1.4720e-01, time/batch = 15.2898s	
9962/28500 (epoch 17.477), train_loss = 1.05152222, grad/param norm = 1.5978e-01, time/batch = 15.6376s	
9963/28500 (epoch 17.479), train_loss = 1.12813422, grad/param norm = 1.5327e-01, time/batch = 15.5313s	
9964/28500 (epoch 17.481), train_loss = 1.06819984, grad/param norm = 1.7010e-01, time/batch = 15.5361s	
9965/28500 (epoch 17.482), train_loss = 0.97442881, grad/param norm = 1.4865e-01, time/batch = 15.4442s	
9966/28500 (epoch 17.484), train_loss = 0.95837869, grad/param norm = 1.4585e-01, time/batch = 15.5642s	
9967/28500 (epoch 17.486), train_loss = 0.88634434, grad/param norm = 1.5584e-01, time/batch = 15.5529s	
9968/28500 (epoch 17.488), train_loss = 1.10510924, grad/param norm = 1.4825e-01, time/batch = 15.2017s	
9969/28500 (epoch 17.489), train_loss = 1.18627613, grad/param norm = 1.6504e-01, time/batch = 15.1147s	
9970/28500 (epoch 17.491), train_loss = 1.03551303, grad/param norm = 1.5407e-01, time/batch = 15.1393s	
9971/28500 (epoch 17.493), train_loss = 1.02976904, grad/param norm = 1.5021e-01, time/batch = 15.2909s	
9972/28500 (epoch 17.495), train_loss = 1.02609103, grad/param norm = 1.3971e-01, time/batch = 15.4790s	
9973/28500 (epoch 17.496), train_loss = 1.00908230, grad/param norm = 1.7438e-01, time/batch = 15.6360s	
9974/28500 (epoch 17.498), train_loss = 1.10685249, grad/param norm = 1.5566e-01, time/batch = 15.4135s	
9975/28500 (epoch 17.500), train_loss = 1.02940580, grad/param norm = 1.5590e-01, time/batch = 15.5359s	
9976/28500 (epoch 17.502), train_loss = 1.16471568, grad/param norm = 1.5947e-01, time/batch = 15.5025s	
9977/28500 (epoch 17.504), train_loss = 1.10261504, grad/param norm = 1.5451e-01, time/batch = 15.2232s	
9978/28500 (epoch 17.505), train_loss = 0.98644955, grad/param norm = 1.5034e-01, time/batch = 15.5036s	
9979/28500 (epoch 17.507), train_loss = 1.19972558, grad/param norm = 1.8802e-01, time/batch = 15.3183s	
9980/28500 (epoch 17.509), train_loss = 1.06594660, grad/param norm = 1.4913e-01, time/batch = 15.2999s	
9981/28500 (epoch 17.511), train_loss = 1.07020603, grad/param norm = 1.5167e-01, time/batch = 15.7848s	
9982/28500 (epoch 17.512), train_loss = 1.07766748, grad/param norm = 1.5364e-01, time/batch = 15.4247s	
9983/28500 (epoch 17.514), train_loss = 0.99382116, grad/param norm = 1.5086e-01, time/batch = 15.2253s	
9984/28500 (epoch 17.516), train_loss = 1.01278059, grad/param norm = 1.3723e-01, time/batch = 15.3030s	
9985/28500 (epoch 17.518), train_loss = 1.09838611, grad/param norm = 1.4835e-01, time/batch = 15.3883s	
9986/28500 (epoch 17.519), train_loss = 1.13896961, grad/param norm = 1.5507e-01, time/batch = 15.5257s	
9987/28500 (epoch 17.521), train_loss = 1.22435500, grad/param norm = 1.6780e-01, time/batch = 15.2575s	
9988/28500 (epoch 17.523), train_loss = 1.14090495, grad/param norm = 1.8588e-01, time/batch = 19.2427s	
9989/28500 (epoch 17.525), train_loss = 1.17897602, grad/param norm = 1.7072e-01, time/batch = 17.5355s	
9990/28500 (epoch 17.526), train_loss = 1.15046317, grad/param norm = 1.6098e-01, time/batch = 18.0600s	
9991/28500 (epoch 17.528), train_loss = 1.15814082, grad/param norm = 1.6356e-01, time/batch = 18.2191s	
9992/28500 (epoch 17.530), train_loss = 1.17654293, grad/param norm = 1.5715e-01, time/batch = 17.8858s	
9993/28500 (epoch 17.532), train_loss = 1.02446316, grad/param norm = 1.4887e-01, time/batch = 17.8884s	
9994/28500 (epoch 17.533), train_loss = 1.16374173, grad/param norm = 1.4957e-01, time/batch = 17.9617s	
9995/28500 (epoch 17.535), train_loss = 0.92246798, grad/param norm = 1.4437e-01, time/batch = 17.5664s	
9996/28500 (epoch 17.537), train_loss = 0.93506172, grad/param norm = 1.4234e-01, time/batch = 17.6376s	
9997/28500 (epoch 17.539), train_loss = 0.92631527, grad/param norm = 1.5587e-01, time/batch = 17.8695s	
9998/28500 (epoch 17.540), train_loss = 1.09647590, grad/param norm = 1.5583e-01, time/batch = 23.4372s	
9999/28500 (epoch 17.542), train_loss = 1.15444874, grad/param norm = 1.7857e-01, time/batch = 16.9305s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch17.54_1.6579.t7	
10000/28500 (epoch 17.544), train_loss = 1.23787859, grad/param norm = 1.6943e-01, time/batch = 15.4638s	
10001/28500 (epoch 17.546), train_loss = 1.31697521, grad/param norm = 1.7268e-01, time/batch = 15.6203s	
10002/28500 (epoch 17.547), train_loss = 1.07081515, grad/param norm = 1.5260e-01, time/batch = 15.6118s	
10003/28500 (epoch 17.549), train_loss = 0.91532446, grad/param norm = 1.3080e-01, time/batch = 15.5751s	
10004/28500 (epoch 17.551), train_loss = 1.10164721, grad/param norm = 1.7891e-01, time/batch = 15.5364s	
10005/28500 (epoch 17.553), train_loss = 1.27376189, grad/param norm = 1.8325e-01, time/batch = 15.4640s	
10006/28500 (epoch 17.554), train_loss = 1.06042187, grad/param norm = 1.5914e-01, time/batch = 15.3474s	
10007/28500 (epoch 17.556), train_loss = 1.11597827, grad/param norm = 1.7040e-01, time/batch = 15.4427s	
10008/28500 (epoch 17.558), train_loss = 1.11440896, grad/param norm = 1.6130e-01, time/batch = 15.4416s	
10009/28500 (epoch 17.560), train_loss = 1.13183310, grad/param norm = 1.7865e-01, time/batch = 15.2207s	
10010/28500 (epoch 17.561), train_loss = 1.14693426, grad/param norm = 1.6166e-01, time/batch = 15.1516s	
10011/28500 (epoch 17.563), train_loss = 1.28463672, grad/param norm = 1.8217e-01, time/batch = 15.4744s	
10012/28500 (epoch 17.565), train_loss = 1.07614541, grad/param norm = 1.6113e-01, time/batch = 15.5251s	
10013/28500 (epoch 17.567), train_loss = 0.95893794, grad/param norm = 1.3943e-01, time/batch = 15.2138s	
10014/28500 (epoch 17.568), train_loss = 1.10348661, grad/param norm = 1.5964e-01, time/batch = 15.2126s	
10015/28500 (epoch 17.570), train_loss = 1.04072503, grad/param norm = 1.5026e-01, time/batch = 15.4688s	
10016/28500 (epoch 17.572), train_loss = 1.04600475, grad/param norm = 1.5929e-01, time/batch = 15.7120s	
10017/28500 (epoch 17.574), train_loss = 1.04240071, grad/param norm = 1.5924e-01, time/batch = 15.5104s	
10018/28500 (epoch 17.575), train_loss = 1.03555381, grad/param norm = 1.4961e-01, time/batch = 15.5092s	
10019/28500 (epoch 17.577), train_loss = 1.11228137, grad/param norm = 1.5746e-01, time/batch = 15.4570s	
10020/28500 (epoch 17.579), train_loss = 1.15803877, grad/param norm = 1.6957e-01, time/batch = 15.6970s	
10021/28500 (epoch 17.581), train_loss = 1.00931819, grad/param norm = 1.6271e-01, time/batch = 15.7815s	
10022/28500 (epoch 17.582), train_loss = 1.15691387, grad/param norm = 1.4791e-01, time/batch = 15.6482s	
10023/28500 (epoch 17.584), train_loss = 1.04504694, grad/param norm = 1.6932e-01, time/batch = 15.6470s	
10024/28500 (epoch 17.586), train_loss = 0.99376175, grad/param norm = 1.4015e-01, time/batch = 15.3760s	
10025/28500 (epoch 17.588), train_loss = 0.98664384, grad/param norm = 1.4017e-01, time/batch = 15.3940s	
10026/28500 (epoch 17.589), train_loss = 1.12205565, grad/param norm = 1.6107e-01, time/batch = 15.1443s	
10027/28500 (epoch 17.591), train_loss = 1.09561819, grad/param norm = 1.4754e-01, time/batch = 15.2692s	
10028/28500 (epoch 17.593), train_loss = 1.03241351, grad/param norm = 1.4097e-01, time/batch = 15.1313s	
10029/28500 (epoch 17.595), train_loss = 1.28311890, grad/param norm = 1.8239e-01, time/batch = 15.2468s	
10030/28500 (epoch 17.596), train_loss = 1.30420903, grad/param norm = 1.8539e-01, time/batch = 15.4260s	
10031/28500 (epoch 17.598), train_loss = 1.10886071, grad/param norm = 1.6330e-01, time/batch = 15.5218s	
10032/28500 (epoch 17.600), train_loss = 1.08948980, grad/param norm = 1.7111e-01, time/batch = 15.6325s	
10033/28500 (epoch 17.602), train_loss = 1.17758720, grad/param norm = 1.6366e-01, time/batch = 15.5309s	
10034/28500 (epoch 17.604), train_loss = 1.18597945, grad/param norm = 1.6237e-01, time/batch = 15.2126s	
10035/28500 (epoch 17.605), train_loss = 1.12623225, grad/param norm = 1.6760e-01, time/batch = 15.2916s	
10036/28500 (epoch 17.607), train_loss = 1.19414913, grad/param norm = 1.4863e-01, time/batch = 15.6145s	
10037/28500 (epoch 17.609), train_loss = 1.09059121, grad/param norm = 1.5786e-01, time/batch = 15.3649s	
10038/28500 (epoch 17.611), train_loss = 1.07732744, grad/param norm = 1.6536e-01, time/batch = 15.2731s	
10039/28500 (epoch 17.612), train_loss = 1.12701578, grad/param norm = 1.6362e-01, time/batch = 15.5310s	
10040/28500 (epoch 17.614), train_loss = 1.11726315, grad/param norm = 1.5565e-01, time/batch = 15.5012s	
10041/28500 (epoch 17.616), train_loss = 1.02986889, grad/param norm = 1.5684e-01, time/batch = 15.4608s	
10042/28500 (epoch 17.618), train_loss = 1.03228833, grad/param norm = 1.4632e-01, time/batch = 15.6130s	
10043/28500 (epoch 17.619), train_loss = 1.26268275, grad/param norm = 1.7995e-01, time/batch = 15.4714s	
10044/28500 (epoch 17.621), train_loss = 0.89329666, grad/param norm = 1.3633e-01, time/batch = 15.5609s	
10045/28500 (epoch 17.623), train_loss = 1.20363024, grad/param norm = 1.8781e-01, time/batch = 15.4077s	
10046/28500 (epoch 17.625), train_loss = 0.96862564, grad/param norm = 1.5631e-01, time/batch = 15.3742s	
10047/28500 (epoch 17.626), train_loss = 0.84679501, grad/param norm = 1.3288e-01, time/batch = 15.4467s	
10048/28500 (epoch 17.628), train_loss = 1.01776227, grad/param norm = 1.5411e-01, time/batch = 15.3511s	
10049/28500 (epoch 17.630), train_loss = 0.93687951, grad/param norm = 1.3886e-01, time/batch = 15.5167s	
10050/28500 (epoch 17.632), train_loss = 1.16280318, grad/param norm = 1.5769e-01, time/batch = 15.2927s	
10051/28500 (epoch 17.633), train_loss = 1.22769800, grad/param norm = 1.4935e-01, time/batch = 15.5081s	
10052/28500 (epoch 17.635), train_loss = 1.20291173, grad/param norm = 1.6869e-01, time/batch = 15.3144s	
10053/28500 (epoch 17.637), train_loss = 1.11159008, grad/param norm = 1.5199e-01, time/batch = 15.5430s	
10054/28500 (epoch 17.639), train_loss = 0.96817852, grad/param norm = 1.4025e-01, time/batch = 15.5402s	
10055/28500 (epoch 17.640), train_loss = 1.00823407, grad/param norm = 1.4924e-01, time/batch = 15.4332s	
10056/28500 (epoch 17.642), train_loss = 1.06950431, grad/param norm = 1.4409e-01, time/batch = 15.3977s	
10057/28500 (epoch 17.644), train_loss = 1.15664779, grad/param norm = 1.4841e-01, time/batch = 15.3327s	
10058/28500 (epoch 17.646), train_loss = 0.96479713, grad/param norm = 1.3930e-01, time/batch = 15.3509s	
10059/28500 (epoch 17.647), train_loss = 0.99136632, grad/param norm = 1.5371e-01, time/batch = 15.4977s	
10060/28500 (epoch 17.649), train_loss = 0.95517814, grad/param norm = 1.4697e-01, time/batch = 15.5119s	
10061/28500 (epoch 17.651), train_loss = 0.92936077, grad/param norm = 1.3269e-01, time/batch = 15.4152s	
10062/28500 (epoch 17.653), train_loss = 0.96715308, grad/param norm = 1.5521e-01, time/batch = 15.2702s	
10063/28500 (epoch 17.654), train_loss = 1.06241034, grad/param norm = 1.5806e-01, time/batch = 15.6370s	
10064/28500 (epoch 17.656), train_loss = 0.99542141, grad/param norm = 1.5727e-01, time/batch = 15.2671s	
10065/28500 (epoch 17.658), train_loss = 1.07771650, grad/param norm = 1.6116e-01, time/batch = 15.6316s	
10066/28500 (epoch 17.660), train_loss = 1.06609313, grad/param norm = 1.4197e-01, time/batch = 15.3984s	
10067/28500 (epoch 17.661), train_loss = 1.23487229, grad/param norm = 1.7980e-01, time/batch = 15.5869s	
10068/28500 (epoch 17.663), train_loss = 1.23846940, grad/param norm = 1.6123e-01, time/batch = 15.6156s	
10069/28500 (epoch 17.665), train_loss = 1.06655283, grad/param norm = 1.5172e-01, time/batch = 15.3416s	
10070/28500 (epoch 17.667), train_loss = 1.08101936, grad/param norm = 1.6041e-01, time/batch = 15.5587s	
10071/28500 (epoch 17.668), train_loss = 1.06115092, grad/param norm = 1.5636e-01, time/batch = 15.6278s	
10072/28500 (epoch 17.670), train_loss = 1.09159701, grad/param norm = 1.5791e-01, time/batch = 15.6286s	
10073/28500 (epoch 17.672), train_loss = 1.02077473, grad/param norm = 1.6792e-01, time/batch = 15.2890s	
10074/28500 (epoch 17.674), train_loss = 0.90307790, grad/param norm = 1.5556e-01, time/batch = 15.3354s	
10075/28500 (epoch 17.675), train_loss = 0.94827690, grad/param norm = 1.4709e-01, time/batch = 15.4632s	
10076/28500 (epoch 17.677), train_loss = 1.05054615, grad/param norm = 1.5063e-01, time/batch = 15.3721s	
10077/28500 (epoch 17.679), train_loss = 1.02535737, grad/param norm = 1.6172e-01, time/batch = 15.0610s	
10078/28500 (epoch 17.681), train_loss = 1.12808666, grad/param norm = 1.5453e-01, time/batch = 15.4223s	
10079/28500 (epoch 17.682), train_loss = 1.03321702, grad/param norm = 1.5692e-01, time/batch = 15.3030s	
10080/28500 (epoch 17.684), train_loss = 1.12305126, grad/param norm = 1.6859e-01, time/batch = 15.4378s	
10081/28500 (epoch 17.686), train_loss = 1.01635086, grad/param norm = 1.6980e-01, time/batch = 15.2924s	
10082/28500 (epoch 17.688), train_loss = 0.95861304, grad/param norm = 1.3492e-01, time/batch = 15.5036s	
10083/28500 (epoch 17.689), train_loss = 1.05496809, grad/param norm = 1.5460e-01, time/batch = 15.4123s	
10084/28500 (epoch 17.691), train_loss = 1.13193730, grad/param norm = 1.8994e-01, time/batch = 15.1865s	
10085/28500 (epoch 17.693), train_loss = 1.03158049, grad/param norm = 1.6793e-01, time/batch = 15.2538s	
10086/28500 (epoch 17.695), train_loss = 0.84644204, grad/param norm = 1.6382e-01, time/batch = 15.5169s	
10087/28500 (epoch 17.696), train_loss = 1.04586911, grad/param norm = 1.6146e-01, time/batch = 15.3843s	
10088/28500 (epoch 17.698), train_loss = 1.03674076, grad/param norm = 1.5280e-01, time/batch = 15.2068s	
10089/28500 (epoch 17.700), train_loss = 1.09822668, grad/param norm = 1.5624e-01, time/batch = 15.3183s	
10090/28500 (epoch 17.702), train_loss = 1.14089365, grad/param norm = 1.7028e-01, time/batch = 15.5853s	
10091/28500 (epoch 17.704), train_loss = 1.11167153, grad/param norm = 1.6545e-01, time/batch = 15.6322s	
10092/28500 (epoch 17.705), train_loss = 1.17855164, grad/param norm = 1.7357e-01, time/batch = 15.4710s	
10093/28500 (epoch 17.707), train_loss = 1.01544619, grad/param norm = 1.6380e-01, time/batch = 15.5251s	
10094/28500 (epoch 17.709), train_loss = 1.22230466, grad/param norm = 1.7236e-01, time/batch = 15.3525s	
10095/28500 (epoch 17.711), train_loss = 0.98365331, grad/param norm = 1.6337e-01, time/batch = 15.5711s	
10096/28500 (epoch 17.712), train_loss = 1.12260241, grad/param norm = 1.5910e-01, time/batch = 15.3121s	
10097/28500 (epoch 17.714), train_loss = 1.18493212, grad/param norm = 1.5283e-01, time/batch = 15.3491s	
10098/28500 (epoch 17.716), train_loss = 1.06018654, grad/param norm = 1.6681e-01, time/batch = 15.4494s	
10099/28500 (epoch 17.718), train_loss = 1.06485704, grad/param norm = 1.5229e-01, time/batch = 15.3697s	
10100/28500 (epoch 17.719), train_loss = 1.10283804, grad/param norm = 1.6809e-01, time/batch = 15.4412s	
10101/28500 (epoch 17.721), train_loss = 0.88201461, grad/param norm = 1.4080e-01, time/batch = 15.6915s	
10102/28500 (epoch 17.723), train_loss = 1.06696274, grad/param norm = 1.6459e-01, time/batch = 15.6246s	
10103/28500 (epoch 17.725), train_loss = 1.15983196, grad/param norm = 1.3850e-01, time/batch = 15.3937s	
10104/28500 (epoch 17.726), train_loss = 1.10130383, grad/param norm = 1.6772e-01, time/batch = 15.3416s	
10105/28500 (epoch 17.728), train_loss = 0.95273595, grad/param norm = 1.3409e-01, time/batch = 15.2711s	
10106/28500 (epoch 17.730), train_loss = 1.08897322, grad/param norm = 1.7017e-01, time/batch = 15.3604s	
10107/28500 (epoch 17.732), train_loss = 0.88747647, grad/param norm = 1.3786e-01, time/batch = 15.1893s	
10108/28500 (epoch 17.733), train_loss = 0.89698749, grad/param norm = 1.3800e-01, time/batch = 15.3783s	
10109/28500 (epoch 17.735), train_loss = 0.92161980, grad/param norm = 1.4343e-01, time/batch = 15.4039s	
10110/28500 (epoch 17.737), train_loss = 0.85130876, grad/param norm = 1.3448e-01, time/batch = 15.1857s	
10111/28500 (epoch 17.739), train_loss = 1.01807744, grad/param norm = 1.6031e-01, time/batch = 15.3670s	
10112/28500 (epoch 17.740), train_loss = 1.06509197, grad/param norm = 1.5308e-01, time/batch = 15.2262s	
10113/28500 (epoch 17.742), train_loss = 0.98439618, grad/param norm = 1.5376e-01, time/batch = 20.9886s	
10114/28500 (epoch 17.744), train_loss = 1.10994141, grad/param norm = 1.6552e-01, time/batch = 23.9885s	
10115/28500 (epoch 17.746), train_loss = 0.96481151, grad/param norm = 1.5360e-01, time/batch = 15.6085s	
10116/28500 (epoch 17.747), train_loss = 0.96869709, grad/param norm = 1.4235e-01, time/batch = 15.6156s	
10117/28500 (epoch 17.749), train_loss = 1.18249092, grad/param norm = 1.8339e-01, time/batch = 15.3726s	
10118/28500 (epoch 17.751), train_loss = 0.97211810, grad/param norm = 1.8732e-01, time/batch = 15.3168s	
10119/28500 (epoch 17.753), train_loss = 1.00435644, grad/param norm = 1.4277e-01, time/batch = 15.3683s	
10120/28500 (epoch 17.754), train_loss = 0.91407748, grad/param norm = 1.4000e-01, time/batch = 15.5608s	
10121/28500 (epoch 17.756), train_loss = 1.17320455, grad/param norm = 1.6965e-01, time/batch = 15.4323s	
10122/28500 (epoch 17.758), train_loss = 1.14077173, grad/param norm = 1.6798e-01, time/batch = 15.3988s	
10123/28500 (epoch 17.760), train_loss = 0.92967839, grad/param norm = 1.4716e-01, time/batch = 15.3152s	
10124/28500 (epoch 17.761), train_loss = 0.97283820, grad/param norm = 1.8741e-01, time/batch = 15.3779s	
10125/28500 (epoch 17.763), train_loss = 0.84835222, grad/param norm = 1.4133e-01, time/batch = 15.4614s	
10126/28500 (epoch 17.765), train_loss = 1.00801135, grad/param norm = 1.4733e-01, time/batch = 15.4680s	
10127/28500 (epoch 17.767), train_loss = 0.88233751, grad/param norm = 1.4105e-01, time/batch = 15.4454s	
10128/28500 (epoch 17.768), train_loss = 1.13070106, grad/param norm = 1.6234e-01, time/batch = 15.4570s	
10129/28500 (epoch 17.770), train_loss = 0.92775008, grad/param norm = 1.5579e-01, time/batch = 15.6462s	
10130/28500 (epoch 17.772), train_loss = 0.80191733, grad/param norm = 1.3159e-01, time/batch = 15.6261s	
10131/28500 (epoch 17.774), train_loss = 1.06939813, grad/param norm = 1.6847e-01, time/batch = 15.6181s	
10132/28500 (epoch 17.775), train_loss = 1.12140391, grad/param norm = 1.4363e-01, time/batch = 15.4563s	
10133/28500 (epoch 17.777), train_loss = 1.12264436, grad/param norm = 1.6204e-01, time/batch = 15.3167s	
10134/28500 (epoch 17.779), train_loss = 0.89002896, grad/param norm = 1.3444e-01, time/batch = 15.3403s	
10135/28500 (epoch 17.781), train_loss = 1.05600885, grad/param norm = 1.5806e-01, time/batch = 15.5705s	
10136/28500 (epoch 17.782), train_loss = 1.12064132, grad/param norm = 1.7390e-01, time/batch = 15.3715s	
10137/28500 (epoch 17.784), train_loss = 0.87254298, grad/param norm = 1.3278e-01, time/batch = 15.3804s	
10138/28500 (epoch 17.786), train_loss = 0.94835804, grad/param norm = 1.5380e-01, time/batch = 15.5509s	
10139/28500 (epoch 17.788), train_loss = 1.02790912, grad/param norm = 1.5073e-01, time/batch = 15.3623s	
10140/28500 (epoch 17.789), train_loss = 0.81875830, grad/param norm = 1.6658e-01, time/batch = 15.3049s	
10141/28500 (epoch 17.791), train_loss = 1.06391587, grad/param norm = 1.4878e-01, time/batch = 15.5496s	
10142/28500 (epoch 17.793), train_loss = 1.02336530, grad/param norm = 1.5526e-01, time/batch = 15.3082s	
10143/28500 (epoch 17.795), train_loss = 1.07293625, grad/param norm = 1.5041e-01, time/batch = 15.2936s	
10144/28500 (epoch 17.796), train_loss = 0.93569680, grad/param norm = 1.4868e-01, time/batch = 15.5471s	
10145/28500 (epoch 17.798), train_loss = 0.87822628, grad/param norm = 1.5062e-01, time/batch = 15.5450s	
10146/28500 (epoch 17.800), train_loss = 0.93411407, grad/param norm = 1.5750e-01, time/batch = 15.2025s	
10147/28500 (epoch 17.802), train_loss = 1.02923582, grad/param norm = 1.9126e-01, time/batch = 15.1985s	
10148/28500 (epoch 17.804), train_loss = 1.06872827, grad/param norm = 1.4835e-01, time/batch = 15.4705s	
10149/28500 (epoch 17.805), train_loss = 1.04559123, grad/param norm = 1.6129e-01, time/batch = 15.4432s	
10150/28500 (epoch 17.807), train_loss = 1.07470969, grad/param norm = 1.4828e-01, time/batch = 15.2871s	
10151/28500 (epoch 17.809), train_loss = 0.99066755, grad/param norm = 1.4748e-01, time/batch = 15.4885s	
10152/28500 (epoch 17.811), train_loss = 1.08286633, grad/param norm = 1.6377e-01, time/batch = 15.5208s	
10153/28500 (epoch 17.812), train_loss = 1.05961366, grad/param norm = 1.6182e-01, time/batch = 15.3692s	
10154/28500 (epoch 17.814), train_loss = 1.02163349, grad/param norm = 1.5770e-01, time/batch = 15.3032s	
10155/28500 (epoch 17.816), train_loss = 1.13997103, grad/param norm = 1.9334e-01, time/batch = 15.3811s	
10156/28500 (epoch 17.818), train_loss = 1.13832164, grad/param norm = 1.7199e-01, time/batch = 15.3184s	
10157/28500 (epoch 17.819), train_loss = 1.03715914, grad/param norm = 1.5109e-01, time/batch = 15.4445s	
10158/28500 (epoch 17.821), train_loss = 1.01987830, grad/param norm = 1.6897e-01, time/batch = 15.4544s	
10159/28500 (epoch 17.823), train_loss = 1.19864691, grad/param norm = 1.8075e-01, time/batch = 15.4577s	
10160/28500 (epoch 17.825), train_loss = 1.01152694, grad/param norm = 1.6892e-01, time/batch = 15.1302s	
10161/28500 (epoch 17.826), train_loss = 1.06382924, grad/param norm = 1.7019e-01, time/batch = 15.6056s	
10162/28500 (epoch 17.828), train_loss = 0.92587912, grad/param norm = 1.7279e-01, time/batch = 15.3299s	
10163/28500 (epoch 17.830), train_loss = 0.99725875, grad/param norm = 1.4522e-01, time/batch = 15.3248s	
10164/28500 (epoch 17.832), train_loss = 1.06580233, grad/param norm = 1.7747e-01, time/batch = 15.5841s	
10165/28500 (epoch 17.833), train_loss = 1.16301629, grad/param norm = 1.5688e-01, time/batch = 15.3620s	
10166/28500 (epoch 17.835), train_loss = 0.98800427, grad/param norm = 1.5278e-01, time/batch = 15.2761s	
10167/28500 (epoch 17.837), train_loss = 0.91983722, grad/param norm = 1.7983e-01, time/batch = 15.2886s	
10168/28500 (epoch 17.839), train_loss = 1.18102706, grad/param norm = 1.7713e-01, time/batch = 15.2278s	
10169/28500 (epoch 17.840), train_loss = 1.19258477, grad/param norm = 1.7142e-01, time/batch = 15.1441s	
10170/28500 (epoch 17.842), train_loss = 1.15173541, grad/param norm = 1.7400e-01, time/batch = 15.3690s	
10171/28500 (epoch 17.844), train_loss = 1.08351762, grad/param norm = 1.6312e-01, time/batch = 15.3921s	
10172/28500 (epoch 17.846), train_loss = 1.19861151, grad/param norm = 1.7771e-01, time/batch = 15.2304s	
10173/28500 (epoch 17.847), train_loss = 0.99989261, grad/param norm = 1.5472e-01, time/batch = 15.1245s	
10174/28500 (epoch 17.849), train_loss = 0.99913899, grad/param norm = 1.5792e-01, time/batch = 15.3795s	
10175/28500 (epoch 17.851), train_loss = 0.87386151, grad/param norm = 1.3757e-01, time/batch = 15.4699s	
10176/28500 (epoch 17.853), train_loss = 1.05137684, grad/param norm = 1.5044e-01, time/batch = 15.1133s	
10177/28500 (epoch 17.854), train_loss = 1.08184085, grad/param norm = 1.6483e-01, time/batch = 15.0475s	
10178/28500 (epoch 17.856), train_loss = 1.18102940, grad/param norm = 1.9052e-01, time/batch = 15.4213s	
10179/28500 (epoch 17.858), train_loss = 0.95087833, grad/param norm = 1.4340e-01, time/batch = 15.1483s	
10180/28500 (epoch 17.860), train_loss = 1.03830579, grad/param norm = 1.6198e-01, time/batch = 15.2008s	
10181/28500 (epoch 17.861), train_loss = 1.11067683, grad/param norm = 1.7968e-01, time/batch = 15.2008s	
10182/28500 (epoch 17.863), train_loss = 1.13991408, grad/param norm = 1.8030e-01, time/batch = 15.2084s	
10183/28500 (epoch 17.865), train_loss = 1.04878635, grad/param norm = 1.6543e-01, time/batch = 15.0676s	
10184/28500 (epoch 17.867), train_loss = 1.11515925, grad/param norm = 1.7126e-01, time/batch = 15.2936s	
10185/28500 (epoch 17.868), train_loss = 0.93175660, grad/param norm = 1.4322e-01, time/batch = 15.3868s	
10186/28500 (epoch 17.870), train_loss = 0.88897753, grad/param norm = 1.4135e-01, time/batch = 15.5857s	
10187/28500 (epoch 17.872), train_loss = 1.08966971, grad/param norm = 1.7719e-01, time/batch = 15.2966s	
10188/28500 (epoch 17.874), train_loss = 1.03322552, grad/param norm = 1.7530e-01, time/batch = 15.4158s	
10189/28500 (epoch 17.875), train_loss = 1.16452055, grad/param norm = 1.8756e-01, time/batch = 15.4995s	
10190/28500 (epoch 17.877), train_loss = 1.08761218, grad/param norm = 1.5371e-01, time/batch = 15.5279s	
10191/28500 (epoch 17.879), train_loss = 1.07079304, grad/param norm = 1.4388e-01, time/batch = 15.5131s	
10192/28500 (epoch 17.881), train_loss = 1.08006172, grad/param norm = 1.6269e-01, time/batch = 15.4640s	
10193/28500 (epoch 17.882), train_loss = 0.97793935, grad/param norm = 1.4402e-01, time/batch = 15.3560s	
10194/28500 (epoch 17.884), train_loss = 1.05938078, grad/param norm = 1.7067e-01, time/batch = 15.3601s	
10195/28500 (epoch 17.886), train_loss = 1.02219928, grad/param norm = 1.4921e-01, time/batch = 15.3626s	
10196/28500 (epoch 17.888), train_loss = 0.94751675, grad/param norm = 1.6633e-01, time/batch = 15.0550s	
10197/28500 (epoch 17.889), train_loss = 1.05535640, grad/param norm = 1.6515e-01, time/batch = 15.5163s	
10198/28500 (epoch 17.891), train_loss = 1.06119845, grad/param norm = 1.6016e-01, time/batch = 15.3625s	
10199/28500 (epoch 17.893), train_loss = 0.98595667, grad/param norm = 1.5820e-01, time/batch = 15.2018s	
10200/28500 (epoch 17.895), train_loss = 1.24428095, grad/param norm = 1.8359e-01, time/batch = 15.2220s	
10201/28500 (epoch 17.896), train_loss = 1.14390369, grad/param norm = 1.7707e-01, time/batch = 15.2513s	
10202/28500 (epoch 17.898), train_loss = 1.06011278, grad/param norm = 1.6596e-01, time/batch = 15.3343s	
10203/28500 (epoch 17.900), train_loss = 0.89935460, grad/param norm = 1.4344e-01, time/batch = 15.1383s	
10204/28500 (epoch 17.902), train_loss = 0.93331890, grad/param norm = 1.5729e-01, time/batch = 15.2551s	
10205/28500 (epoch 17.904), train_loss = 0.95158411, grad/param norm = 1.3843e-01, time/batch = 15.3283s	
10206/28500 (epoch 17.905), train_loss = 1.06108328, grad/param norm = 1.5518e-01, time/batch = 15.2020s	
10207/28500 (epoch 17.907), train_loss = 1.02055937, grad/param norm = 1.4955e-01, time/batch = 15.1928s	
10208/28500 (epoch 17.909), train_loss = 0.93781450, grad/param norm = 1.6174e-01, time/batch = 15.2269s	
10209/28500 (epoch 17.911), train_loss = 0.95889842, grad/param norm = 1.4463e-01, time/batch = 15.3645s	
10210/28500 (epoch 17.912), train_loss = 0.83918331, grad/param norm = 1.3868e-01, time/batch = 15.3850s	
10211/28500 (epoch 17.914), train_loss = 1.14341902, grad/param norm = 1.4946e-01, time/batch = 15.6045s	
10212/28500 (epoch 17.916), train_loss = 1.07113556, grad/param norm = 1.7426e-01, time/batch = 15.6413s	
10213/28500 (epoch 17.918), train_loss = 1.05753960, grad/param norm = 1.6806e-01, time/batch = 15.5316s	
10214/28500 (epoch 17.919), train_loss = 1.03589545, grad/param norm = 1.4817e-01, time/batch = 15.4728s	
10215/28500 (epoch 17.921), train_loss = 1.15647059, grad/param norm = 1.9358e-01, time/batch = 15.5640s	
10216/28500 (epoch 17.923), train_loss = 1.05029517, grad/param norm = 1.9243e-01, time/batch = 15.2792s	
10217/28500 (epoch 17.925), train_loss = 0.98450547, grad/param norm = 1.7071e-01, time/batch = 15.2966s	
10218/28500 (epoch 17.926), train_loss = 1.02253425, grad/param norm = 1.4983e-01, time/batch = 15.0971s	
10219/28500 (epoch 17.928), train_loss = 0.99917447, grad/param norm = 1.5864e-01, time/batch = 15.4043s	
10220/28500 (epoch 17.930), train_loss = 0.80616277, grad/param norm = 1.2471e-01, time/batch = 15.4970s	
10221/28500 (epoch 17.932), train_loss = 0.82970518, grad/param norm = 1.2827e-01, time/batch = 15.3904s	
10222/28500 (epoch 17.933), train_loss = 1.10677896, grad/param norm = 1.6164e-01, time/batch = 15.3860s	
10223/28500 (epoch 17.935), train_loss = 1.13097664, grad/param norm = 1.6461e-01, time/batch = 15.5547s	
10224/28500 (epoch 17.937), train_loss = 1.15379718, grad/param norm = 1.8278e-01, time/batch = 15.3774s	
10225/28500 (epoch 17.939), train_loss = 1.23192223, grad/param norm = 1.7585e-01, time/batch = 15.5836s	
10226/28500 (epoch 17.940), train_loss = 0.93740784, grad/param norm = 1.5378e-01, time/batch = 15.3685s	
10227/28500 (epoch 17.942), train_loss = 1.08374658, grad/param norm = 1.5343e-01, time/batch = 15.0362s	
10228/28500 (epoch 17.944), train_loss = 1.01627859, grad/param norm = 1.5556e-01, time/batch = 15.4276s	
10229/28500 (epoch 17.946), train_loss = 1.15140212, grad/param norm = 1.6166e-01, time/batch = 15.5114s	
10230/28500 (epoch 17.947), train_loss = 1.34312884, grad/param norm = 1.8752e-01, time/batch = 15.2105s	
10231/28500 (epoch 17.949), train_loss = 0.98805360, grad/param norm = 1.5567e-01, time/batch = 15.2915s	
10232/28500 (epoch 17.951), train_loss = 1.24295874, grad/param norm = 2.0440e-01, time/batch = 15.2228s	
10233/28500 (epoch 17.953), train_loss = 1.21590522, grad/param norm = 1.7514e-01, time/batch = 15.3855s	
10234/28500 (epoch 17.954), train_loss = 1.18864925, grad/param norm = 1.6942e-01, time/batch = 15.3864s	
10235/28500 (epoch 17.956), train_loss = 1.11703014, grad/param norm = 1.8873e-01, time/batch = 15.4207s	
10236/28500 (epoch 17.958), train_loss = 1.23931811, grad/param norm = 1.6556e-01, time/batch = 15.1372s	
10237/28500 (epoch 17.960), train_loss = 0.95497254, grad/param norm = 1.5246e-01, time/batch = 15.0657s	
10238/28500 (epoch 17.961), train_loss = 1.27478536, grad/param norm = 1.8587e-01, time/batch = 15.4108s	
10239/28500 (epoch 17.963), train_loss = 1.16255571, grad/param norm = 1.7659e-01, time/batch = 15.3717s	
10240/28500 (epoch 17.965), train_loss = 0.97615639, grad/param norm = 1.7272e-01, time/batch = 15.4260s	
10241/28500 (epoch 17.967), train_loss = 0.95131725, grad/param norm = 1.5297e-01, time/batch = 15.5471s	
10242/28500 (epoch 17.968), train_loss = 0.90357343, grad/param norm = 1.3192e-01, time/batch = 15.4970s	
10243/28500 (epoch 17.970), train_loss = 0.99298379, grad/param norm = 1.6315e-01, time/batch = 15.2070s	
10244/28500 (epoch 17.972), train_loss = 1.06348751, grad/param norm = 1.5591e-01, time/batch = 15.4586s	
10245/28500 (epoch 17.974), train_loss = 1.24876100, grad/param norm = 1.8440e-01, time/batch = 15.1901s	
10246/28500 (epoch 17.975), train_loss = 1.01790550, grad/param norm = 1.7050e-01, time/batch = 15.2175s	
10247/28500 (epoch 17.977), train_loss = 1.19270656, grad/param norm = 1.7363e-01, time/batch = 15.3656s	
10248/28500 (epoch 17.979), train_loss = 1.01478999, grad/param norm = 1.6570e-01, time/batch = 15.6854s	
10249/28500 (epoch 17.981), train_loss = 0.96858282, grad/param norm = 1.6347e-01, time/batch = 15.5385s	
10250/28500 (epoch 17.982), train_loss = 1.01937782, grad/param norm = 1.4655e-01, time/batch = 15.6395s	
10251/28500 (epoch 17.984), train_loss = 1.14406917, grad/param norm = 1.6286e-01, time/batch = 15.6242s	
10252/28500 (epoch 17.986), train_loss = 1.29745617, grad/param norm = 1.8515e-01, time/batch = 15.5599s	
10253/28500 (epoch 17.988), train_loss = 0.89040555, grad/param norm = 1.4958e-01, time/batch = 15.2232s	
10254/28500 (epoch 17.989), train_loss = 1.09718198, grad/param norm = 1.6717e-01, time/batch = 15.1957s	
10255/28500 (epoch 17.991), train_loss = 0.99346762, grad/param norm = 1.6023e-01, time/batch = 15.1953s	
10256/28500 (epoch 17.993), train_loss = 0.99619649, grad/param norm = 1.6901e-01, time/batch = 15.2750s	
10257/28500 (epoch 17.995), train_loss = 0.99496833, grad/param norm = 1.7140e-01, time/batch = 15.4574s	
10258/28500 (epoch 17.996), train_loss = 0.94819267, grad/param norm = 1.5584e-01, time/batch = 15.5613s	
10259/28500 (epoch 17.998), train_loss = 1.17287678, grad/param norm = 1.8563e-01, time/batch = 15.5500s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
10260/28500 (epoch 18.000), train_loss = 1.01712529, grad/param norm = 1.5633e-01, time/batch = 15.6217s	
10261/28500 (epoch 18.002), train_loss = 1.20160996, grad/param norm = 1.7513e-01, time/batch = 15.7161s	
10262/28500 (epoch 18.004), train_loss = 1.00744735, grad/param norm = 1.5043e-01, time/batch = 15.5599s	
10263/28500 (epoch 18.005), train_loss = 1.18505767, grad/param norm = 1.7251e-01, time/batch = 15.5202s	
10264/28500 (epoch 18.007), train_loss = 0.93596639, grad/param norm = 1.4564e-01, time/batch = 15.1286s	
10265/28500 (epoch 18.009), train_loss = 1.11558029, grad/param norm = 1.7215e-01, time/batch = 15.2194s	
10266/28500 (epoch 18.011), train_loss = 0.99759241, grad/param norm = 1.9347e-01, time/batch = 15.2023s	
10267/28500 (epoch 18.012), train_loss = 0.91550771, grad/param norm = 1.3978e-01, time/batch = 15.3399s	
10268/28500 (epoch 18.014), train_loss = 0.94881341, grad/param norm = 1.5163e-01, time/batch = 15.3207s	
10269/28500 (epoch 18.016), train_loss = 1.02125506, grad/param norm = 1.6838e-01, time/batch = 15.6061s	
10270/28500 (epoch 18.018), train_loss = 1.06902184, grad/param norm = 1.6194e-01, time/batch = 15.1277s	
10271/28500 (epoch 18.019), train_loss = 1.11991326, grad/param norm = 1.6595e-01, time/batch = 15.2743s	
10272/28500 (epoch 18.021), train_loss = 1.12863376, grad/param norm = 1.4773e-01, time/batch = 15.1422s	
10273/28500 (epoch 18.023), train_loss = 1.03508778, grad/param norm = 1.6211e-01, time/batch = 15.2781s	
10274/28500 (epoch 18.025), train_loss = 1.05941215, grad/param norm = 1.4825e-01, time/batch = 15.3633s	
10275/28500 (epoch 18.026), train_loss = 1.03953395, grad/param norm = 1.5811e-01, time/batch = 15.5310s	
10276/28500 (epoch 18.028), train_loss = 1.10941027, grad/param norm = 1.6660e-01, time/batch = 15.2307s	
10277/28500 (epoch 18.030), train_loss = 1.11826709, grad/param norm = 1.8374e-01, time/batch = 15.1473s	
10278/28500 (epoch 18.032), train_loss = 1.14333998, grad/param norm = 1.6160e-01, time/batch = 15.0530s	
10279/28500 (epoch 18.033), train_loss = 1.21685869, grad/param norm = 1.7719e-01, time/batch = 15.2813s	
10280/28500 (epoch 18.035), train_loss = 1.06786795, grad/param norm = 1.7260e-01, time/batch = 15.2094s	
10281/28500 (epoch 18.037), train_loss = 1.13867242, grad/param norm = 1.4971e-01, time/batch = 15.5255s	
10282/28500 (epoch 18.039), train_loss = 1.16967390, grad/param norm = 1.6568e-01, time/batch = 15.3127s	
10283/28500 (epoch 18.040), train_loss = 1.20263225, grad/param norm = 1.6029e-01, time/batch = 15.6075s	
10284/28500 (epoch 18.042), train_loss = 1.15005173, grad/param norm = 1.6872e-01, time/batch = 15.3713s	
10285/28500 (epoch 18.044), train_loss = 1.05851944, grad/param norm = 1.6140e-01, time/batch = 15.4063s	
10286/28500 (epoch 18.046), train_loss = 1.30173050, grad/param norm = 1.7080e-01, time/batch = 15.5076s	
10287/28500 (epoch 18.047), train_loss = 1.19335623, grad/param norm = 1.6954e-01, time/batch = 15.4987s	
10288/28500 (epoch 18.049), train_loss = 1.07622840, grad/param norm = 1.6434e-01, time/batch = 15.5020s	
10289/28500 (epoch 18.051), train_loss = 1.02604057, grad/param norm = 1.4788e-01, time/batch = 15.6419s	
10290/28500 (epoch 18.053), train_loss = 1.06673639, grad/param norm = 1.7145e-01, time/batch = 15.4963s	
10291/28500 (epoch 18.054), train_loss = 1.13553051, grad/param norm = 1.6241e-01, time/batch = 15.3764s	
10292/28500 (epoch 18.056), train_loss = 0.94974570, grad/param norm = 1.4305e-01, time/batch = 15.5117s	
10293/28500 (epoch 18.058), train_loss = 0.96017846, grad/param norm = 1.4579e-01, time/batch = 15.4508s	
10294/28500 (epoch 18.060), train_loss = 1.15260228, grad/param norm = 1.6384e-01, time/batch = 15.3730s	
10295/28500 (epoch 18.061), train_loss = 1.08275690, grad/param norm = 1.7746e-01, time/batch = 15.5630s	
10296/28500 (epoch 18.063), train_loss = 1.13943974, grad/param norm = 1.6003e-01, time/batch = 15.0613s	
10297/28500 (epoch 18.065), train_loss = 1.16304786, grad/param norm = 1.6842e-01, time/batch = 15.4030s	
10298/28500 (epoch 18.067), train_loss = 1.02759274, grad/param norm = 1.4450e-01, time/batch = 15.4521s	
10299/28500 (epoch 18.068), train_loss = 1.06657059, grad/param norm = 1.6191e-01, time/batch = 15.4768s	
10300/28500 (epoch 18.070), train_loss = 1.12141245, grad/param norm = 1.7632e-01, time/batch = 15.2222s	
10301/28500 (epoch 18.072), train_loss = 1.25788535, grad/param norm = 1.8737e-01, time/batch = 15.3479s	
10302/28500 (epoch 18.074), train_loss = 1.11133458, grad/param norm = 1.5319e-01, time/batch = 15.1322s	
10303/28500 (epoch 18.075), train_loss = 1.04633036, grad/param norm = 1.4038e-01, time/batch = 15.4317s	
10304/28500 (epoch 18.077), train_loss = 1.13477546, grad/param norm = 1.6677e-01, time/batch = 15.4962s	
10305/28500 (epoch 18.079), train_loss = 1.08802923, grad/param norm = 1.5513e-01, time/batch = 15.4041s	
10306/28500 (epoch 18.081), train_loss = 1.19234031, grad/param norm = 1.7195e-01, time/batch = 15.4293s	
10307/28500 (epoch 18.082), train_loss = 1.08973825, grad/param norm = 1.7452e-01, time/batch = 15.5586s	
10308/28500 (epoch 18.084), train_loss = 1.11262011, grad/param norm = 1.5623e-01, time/batch = 15.6652s	
10309/28500 (epoch 18.086), train_loss = 1.05237675, grad/param norm = 1.6619e-01, time/batch = 15.5054s	
10310/28500 (epoch 18.088), train_loss = 0.98022894, grad/param norm = 1.6586e-01, time/batch = 15.5221s	
10311/28500 (epoch 18.089), train_loss = 1.17549519, grad/param norm = 1.4312e-01, time/batch = 15.5404s	
10312/28500 (epoch 18.091), train_loss = 0.95429218, grad/param norm = 1.5102e-01, time/batch = 15.4463s	
10313/28500 (epoch 18.093), train_loss = 1.12685906, grad/param norm = 1.5644e-01, time/batch = 15.3546s	
10314/28500 (epoch 18.095), train_loss = 1.01426029, grad/param norm = 1.4174e-01, time/batch = 15.2603s	
10315/28500 (epoch 18.096), train_loss = 1.19623704, grad/param norm = 1.6976e-01, time/batch = 15.5384s	
10316/28500 (epoch 18.098), train_loss = 1.12706146, grad/param norm = 1.8210e-01, time/batch = 15.2957s	
10317/28500 (epoch 18.100), train_loss = 1.03640720, grad/param norm = 1.5860e-01, time/batch = 15.0158s	
10318/28500 (epoch 18.102), train_loss = 1.18354670, grad/param norm = 1.7852e-01, time/batch = 15.2440s	
10319/28500 (epoch 18.104), train_loss = 1.05927427, grad/param norm = 1.9337e-01, time/batch = 15.1476s	
10320/28500 (epoch 18.105), train_loss = 1.19384284, grad/param norm = 1.6570e-01, time/batch = 15.3600s	
10321/28500 (epoch 18.107), train_loss = 0.95990320, grad/param norm = 1.4680e-01, time/batch = 15.2573s	
10322/28500 (epoch 18.109), train_loss = 0.94801755, grad/param norm = 1.7662e-01, time/batch = 15.3989s	
10323/28500 (epoch 18.111), train_loss = 1.03863041, grad/param norm = 1.6215e-01, time/batch = 15.2211s	
10324/28500 (epoch 18.112), train_loss = 1.12282642, grad/param norm = 1.5939e-01, time/batch = 15.3734s	
10325/28500 (epoch 18.114), train_loss = 1.04830352, grad/param norm = 1.6234e-01, time/batch = 15.3047s	
10326/28500 (epoch 18.116), train_loss = 1.26055930, grad/param norm = 1.8890e-01, time/batch = 15.0571s	
10327/28500 (epoch 18.118), train_loss = 0.93514122, grad/param norm = 1.6272e-01, time/batch = 14.8147s	
10328/28500 (epoch 18.119), train_loss = 1.09372505, grad/param norm = 1.6647e-01, time/batch = 14.9785s	
10329/28500 (epoch 18.121), train_loss = 1.23091231, grad/param norm = 1.8517e-01, time/batch = 14.9684s	
10330/28500 (epoch 18.123), train_loss = 1.14509752, grad/param norm = 1.6352e-01, time/batch = 15.1320s	
10331/28500 (epoch 18.125), train_loss = 1.08636778, grad/param norm = 1.5936e-01, time/batch = 15.3143s	
10332/28500 (epoch 18.126), train_loss = 1.07350843, grad/param norm = 1.6169e-01, time/batch = 15.2247s	
10333/28500 (epoch 18.128), train_loss = 1.06716252, grad/param norm = 1.5552e-01, time/batch = 15.2013s	
10334/28500 (epoch 18.130), train_loss = 0.96677664, grad/param norm = 1.5341e-01, time/batch = 15.2311s	
10335/28500 (epoch 18.132), train_loss = 1.12330666, grad/param norm = 1.9530e-01, time/batch = 15.5010s	
10336/28500 (epoch 18.133), train_loss = 1.14566193, grad/param norm = 1.7136e-01, time/batch = 15.6851s	
10337/28500 (epoch 18.135), train_loss = 1.04120324, grad/param norm = 1.4347e-01, time/batch = 15.5241s	
10338/28500 (epoch 18.137), train_loss = 1.06894853, grad/param norm = 1.7069e-01, time/batch = 15.2959s	
10339/28500 (epoch 18.139), train_loss = 1.04581167, grad/param norm = 1.3975e-01, time/batch = 15.2174s	
10340/28500 (epoch 18.140), train_loss = 1.10613082, grad/param norm = 1.4737e-01, time/batch = 15.2916s	
10341/28500 (epoch 18.142), train_loss = 1.06035373, grad/param norm = 1.6513e-01, time/batch = 15.3449s	
10342/28500 (epoch 18.144), train_loss = 0.99644641, grad/param norm = 1.4527e-01, time/batch = 15.3011s	
10343/28500 (epoch 18.146), train_loss = 1.02987539, grad/param norm = 1.5135e-01, time/batch = 15.4688s	
10344/28500 (epoch 18.147), train_loss = 0.94493198, grad/param norm = 1.4878e-01, time/batch = 15.4520s	
10345/28500 (epoch 18.149), train_loss = 0.93465724, grad/param norm = 1.4455e-01, time/batch = 27.3881s	
10346/28500 (epoch 18.151), train_loss = 0.99796503, grad/param norm = 1.5261e-01, time/batch = 15.2121s	
10347/28500 (epoch 18.153), train_loss = 1.08547427, grad/param norm = 1.6693e-01, time/batch = 15.1853s	
10348/28500 (epoch 18.154), train_loss = 0.97212261, grad/param norm = 1.5604e-01, time/batch = 15.2514s	
10349/28500 (epoch 18.156), train_loss = 1.19337005, grad/param norm = 1.7458e-01, time/batch = 15.2037s	
10350/28500 (epoch 18.158), train_loss = 1.06310543, grad/param norm = 1.5577e-01, time/batch = 15.3988s	
10351/28500 (epoch 18.160), train_loss = 0.94912402, grad/param norm = 1.3828e-01, time/batch = 15.7006s	
10352/28500 (epoch 18.161), train_loss = 1.04111543, grad/param norm = 1.9129e-01, time/batch = 15.5229s	
10353/28500 (epoch 18.163), train_loss = 0.93811467, grad/param norm = 1.5077e-01, time/batch = 15.4431s	
10354/28500 (epoch 18.165), train_loss = 1.27575697, grad/param norm = 1.7059e-01, time/batch = 15.1528s	
10355/28500 (epoch 18.167), train_loss = 1.30344554, grad/param norm = 1.9042e-01, time/batch = 15.2815s	
10356/28500 (epoch 18.168), train_loss = 1.18320789, grad/param norm = 1.8507e-01, time/batch = 15.3370s	
10357/28500 (epoch 18.170), train_loss = 1.17589626, grad/param norm = 1.8959e-01, time/batch = 15.4938s	
10358/28500 (epoch 18.172), train_loss = 1.06680934, grad/param norm = 1.5699e-01, time/batch = 15.5491s	
10359/28500 (epoch 18.174), train_loss = 1.23183571, grad/param norm = 2.5602e-01, time/batch = 15.3744s	
10360/28500 (epoch 18.175), train_loss = 1.08096615, grad/param norm = 1.5368e-01, time/batch = 15.5394s	
10361/28500 (epoch 18.177), train_loss = 1.13238271, grad/param norm = 1.8230e-01, time/batch = 15.5759s	
10362/28500 (epoch 18.179), train_loss = 1.09304015, grad/param norm = 1.8259e-01, time/batch = 15.6042s	
10363/28500 (epoch 18.181), train_loss = 1.15808555, grad/param norm = 1.6848e-01, time/batch = 15.3797s	
10364/28500 (epoch 18.182), train_loss = 1.06168866, grad/param norm = 1.5115e-01, time/batch = 15.3491s	
10365/28500 (epoch 18.184), train_loss = 1.24731343, grad/param norm = 1.7950e-01, time/batch = 15.3947s	
10366/28500 (epoch 18.186), train_loss = 1.19533092, grad/param norm = 1.7015e-01, time/batch = 15.3150s	
10367/28500 (epoch 18.188), train_loss = 1.09791436, grad/param norm = 1.5804e-01, time/batch = 15.5946s	
10368/28500 (epoch 18.189), train_loss = 1.10601087, grad/param norm = 1.6611e-01, time/batch = 15.3554s	
10369/28500 (epoch 18.191), train_loss = 1.30344068, grad/param norm = 1.8354e-01, time/batch = 15.3294s	
10370/28500 (epoch 18.193), train_loss = 1.14461032, grad/param norm = 1.6944e-01, time/batch = 15.5426s	
10371/28500 (epoch 18.195), train_loss = 1.24170819, grad/param norm = 1.7399e-01, time/batch = 15.5400s	
10372/28500 (epoch 18.196), train_loss = 1.13467184, grad/param norm = 1.6802e-01, time/batch = 15.2473s	
10373/28500 (epoch 18.198), train_loss = 1.09601695, grad/param norm = 1.6924e-01, time/batch = 15.1240s	
10374/28500 (epoch 18.200), train_loss = 1.13666810, grad/param norm = 1.6819e-01, time/batch = 15.4977s	
10375/28500 (epoch 18.202), train_loss = 1.10423077, grad/param norm = 1.5542e-01, time/batch = 15.1070s	
10376/28500 (epoch 18.204), train_loss = 1.02611103, grad/param norm = 1.4101e-01, time/batch = 15.0652s	
10377/28500 (epoch 18.205), train_loss = 1.04986749, grad/param norm = 1.6739e-01, time/batch = 15.0445s	
10378/28500 (epoch 18.207), train_loss = 1.00478313, grad/param norm = 1.6687e-01, time/batch = 14.9848s	
10379/28500 (epoch 18.209), train_loss = 1.09186358, grad/param norm = 1.4997e-01, time/batch = 15.4323s	
10380/28500 (epoch 18.211), train_loss = 0.95184456, grad/param norm = 1.6502e-01, time/batch = 14.9936s	
10381/28500 (epoch 18.212), train_loss = 0.93492316, grad/param norm = 1.4333e-01, time/batch = 15.3922s	
10382/28500 (epoch 18.214), train_loss = 1.08759977, grad/param norm = 1.7383e-01, time/batch = 15.4532s	
10383/28500 (epoch 18.216), train_loss = 0.98141290, grad/param norm = 1.4780e-01, time/batch = 15.4213s	
10384/28500 (epoch 18.218), train_loss = 1.19548803, grad/param norm = 1.5297e-01, time/batch = 15.0666s	
10385/28500 (epoch 18.219), train_loss = 1.12953221, grad/param norm = 1.6930e-01, time/batch = 15.0428s	
10386/28500 (epoch 18.221), train_loss = 0.95514080, grad/param norm = 1.6220e-01, time/batch = 15.3094s	
10387/28500 (epoch 18.223), train_loss = 1.19897593, grad/param norm = 1.6287e-01, time/batch = 15.4961s	
10388/28500 (epoch 18.225), train_loss = 1.21476039, grad/param norm = 1.7548e-01, time/batch = 15.5665s	
10389/28500 (epoch 18.226), train_loss = 1.03438044, grad/param norm = 1.5243e-01, time/batch = 15.5132s	
10390/28500 (epoch 18.228), train_loss = 1.17190626, grad/param norm = 1.5226e-01, time/batch = 15.1328s	
10391/28500 (epoch 18.230), train_loss = 1.17457158, grad/param norm = 1.5968e-01, time/batch = 15.2703s	
10392/28500 (epoch 18.232), train_loss = 1.13294861, grad/param norm = 1.5235e-01, time/batch = 15.0642s	
10393/28500 (epoch 18.233), train_loss = 1.11565244, grad/param norm = 1.7825e-01, time/batch = 15.1931s	
10394/28500 (epoch 18.235), train_loss = 1.05199776, grad/param norm = 1.4252e-01, time/batch = 15.4730s	
10395/28500 (epoch 18.237), train_loss = 0.94054923, grad/param norm = 1.3058e-01, time/batch = 15.3694s	
10396/28500 (epoch 18.239), train_loss = 1.00127180, grad/param norm = 1.4017e-01, time/batch = 15.3024s	
10397/28500 (epoch 18.240), train_loss = 0.97382068, grad/param norm = 1.6414e-01, time/batch = 15.3944s	
10398/28500 (epoch 18.242), train_loss = 1.13193931, grad/param norm = 1.8210e-01, time/batch = 15.5459s	
10399/28500 (epoch 18.244), train_loss = 1.12932370, grad/param norm = 1.4966e-01, time/batch = 15.6314s	
10400/28500 (epoch 18.246), train_loss = 1.17900820, grad/param norm = 1.7289e-01, time/batch = 15.4692s	
10401/28500 (epoch 18.247), train_loss = 1.24926972, grad/param norm = 1.7624e-01, time/batch = 15.5730s	
10402/28500 (epoch 18.249), train_loss = 1.09531022, grad/param norm = 1.6522e-01, time/batch = 15.5930s	
10403/28500 (epoch 18.251), train_loss = 1.01638559, grad/param norm = 1.4745e-01, time/batch = 15.2837s	
10404/28500 (epoch 18.253), train_loss = 1.24580647, grad/param norm = 1.8855e-01, time/batch = 15.1309s	
10405/28500 (epoch 18.254), train_loss = 1.22333500, grad/param norm = 1.6769e-01, time/batch = 15.4334s	
10406/28500 (epoch 18.256), train_loss = 1.02570741, grad/param norm = 1.5752e-01, time/batch = 15.1112s	
10407/28500 (epoch 18.258), train_loss = 1.07686380, grad/param norm = 1.6794e-01, time/batch = 15.2823s	
10408/28500 (epoch 18.260), train_loss = 1.01311548, grad/param norm = 1.5251e-01, time/batch = 15.3019s	
10409/28500 (epoch 18.261), train_loss = 1.03320783, grad/param norm = 1.6246e-01, time/batch = 15.2771s	
10410/28500 (epoch 18.263), train_loss = 1.19674412, grad/param norm = 1.7869e-01, time/batch = 15.6300s	
10411/28500 (epoch 18.265), train_loss = 1.09494469, grad/param norm = 1.6376e-01, time/batch = 15.6239s	
10412/28500 (epoch 18.267), train_loss = 1.23845754, grad/param norm = 1.7883e-01, time/batch = 15.1155s	
10413/28500 (epoch 18.268), train_loss = 1.13589929, grad/param norm = 1.5744e-01, time/batch = 15.3057s	
10414/28500 (epoch 18.270), train_loss = 1.12448452, grad/param norm = 1.7395e-01, time/batch = 15.4198s	
10415/28500 (epoch 18.272), train_loss = 1.05588655, grad/param norm = 1.6488e-01, time/batch = 15.4353s	
10416/28500 (epoch 18.274), train_loss = 1.21084986, grad/param norm = 1.6427e-01, time/batch = 15.2295s	
10417/28500 (epoch 18.275), train_loss = 1.11885925, grad/param norm = 1.4979e-01, time/batch = 15.2546s	
10418/28500 (epoch 18.277), train_loss = 1.11218641, grad/param norm = 1.7417e-01, time/batch = 15.4325s	
10419/28500 (epoch 18.279), train_loss = 1.13984636, grad/param norm = 1.6935e-01, time/batch = 15.5366s	
10420/28500 (epoch 18.281), train_loss = 1.17497999, grad/param norm = 1.7941e-01, time/batch = 15.4565s	
10421/28500 (epoch 18.282), train_loss = 1.00794714, grad/param norm = 1.4947e-01, time/batch = 15.3869s	
10422/28500 (epoch 18.284), train_loss = 1.11137695, grad/param norm = 1.6818e-01, time/batch = 15.2994s	
10423/28500 (epoch 18.286), train_loss = 1.19816246, grad/param norm = 1.6687e-01, time/batch = 15.2099s	
10424/28500 (epoch 18.288), train_loss = 1.13659796, grad/param norm = 1.6725e-01, time/batch = 15.3686s	
10425/28500 (epoch 18.289), train_loss = 1.14966515, grad/param norm = 1.7878e-01, time/batch = 15.1077s	
10426/28500 (epoch 18.291), train_loss = 1.09242907, grad/param norm = 1.4807e-01, time/batch = 15.2864s	
10427/28500 (epoch 18.293), train_loss = 1.06078677, grad/param norm = 1.6359e-01, time/batch = 15.5306s	
10428/28500 (epoch 18.295), train_loss = 0.96519994, grad/param norm = 1.5499e-01, time/batch = 15.5615s	
10429/28500 (epoch 18.296), train_loss = 0.98316052, grad/param norm = 1.4873e-01, time/batch = 15.5272s	
10430/28500 (epoch 18.298), train_loss = 1.16633599, grad/param norm = 1.5806e-01, time/batch = 15.4903s	
10431/28500 (epoch 18.300), train_loss = 0.99396728, grad/param norm = 1.5176e-01, time/batch = 15.2833s	
10432/28500 (epoch 18.302), train_loss = 0.97251790, grad/param norm = 1.5041e-01, time/batch = 15.1469s	
10433/28500 (epoch 18.304), train_loss = 1.04907005, grad/param norm = 1.4468e-01, time/batch = 15.4489s	
10434/28500 (epoch 18.305), train_loss = 1.13882310, grad/param norm = 1.5412e-01, time/batch = 15.3730s	
10435/28500 (epoch 18.307), train_loss = 1.08046602, grad/param norm = 1.6680e-01, time/batch = 15.3020s	
10436/28500 (epoch 18.309), train_loss = 1.07370255, grad/param norm = 1.5785e-01, time/batch = 15.5395s	
10437/28500 (epoch 18.311), train_loss = 1.14269112, grad/param norm = 1.5713e-01, time/batch = 15.5400s	
10438/28500 (epoch 18.312), train_loss = 1.06938103, grad/param norm = 1.5770e-01, time/batch = 15.3878s	
10439/28500 (epoch 18.314), train_loss = 1.16765182, grad/param norm = 1.7594e-01, time/batch = 15.2971s	
10440/28500 (epoch 18.316), train_loss = 1.10770986, grad/param norm = 1.5560e-01, time/batch = 15.5465s	
10441/28500 (epoch 18.318), train_loss = 1.15658491, grad/param norm = 1.5622e-01, time/batch = 15.5572s	
10442/28500 (epoch 18.319), train_loss = 1.03692657, grad/param norm = 1.5246e-01, time/batch = 15.1216s	
10443/28500 (epoch 18.321), train_loss = 1.03984407, grad/param norm = 1.6645e-01, time/batch = 15.1350s	
10444/28500 (epoch 18.323), train_loss = 1.06608426, grad/param norm = 1.7493e-01, time/batch = 15.0599s	
10445/28500 (epoch 18.325), train_loss = 1.24168328, grad/param norm = 1.8274e-01, time/batch = 15.4351s	
10446/28500 (epoch 18.326), train_loss = 1.09486591, grad/param norm = 1.6331e-01, time/batch = 15.3138s	
10447/28500 (epoch 18.328), train_loss = 0.89144973, grad/param norm = 1.4615e-01, time/batch = 15.2186s	
10448/28500 (epoch 18.330), train_loss = 0.99828770, grad/param norm = 1.5470e-01, time/batch = 15.2974s	
10449/28500 (epoch 18.332), train_loss = 1.07901651, grad/param norm = 1.4772e-01, time/batch = 15.4413s	
10450/28500 (epoch 18.333), train_loss = 0.90795787, grad/param norm = 1.5244e-01, time/batch = 15.4798s	
10451/28500 (epoch 18.335), train_loss = 0.96230676, grad/param norm = 1.4543e-01, time/batch = 15.6436s	
10452/28500 (epoch 18.337), train_loss = 0.98826626, grad/param norm = 1.4368e-01, time/batch = 15.3699s	
10453/28500 (epoch 18.339), train_loss = 0.92348053, grad/param norm = 1.3336e-01, time/batch = 15.2977s	
10454/28500 (epoch 18.340), train_loss = 1.13094252, grad/param norm = 1.7538e-01, time/batch = 15.5017s	
10455/28500 (epoch 18.342), train_loss = 1.06940235, grad/param norm = 1.5807e-01, time/batch = 15.2915s	
10456/28500 (epoch 18.344), train_loss = 1.01639997, grad/param norm = 1.6842e-01, time/batch = 15.1442s	
10457/28500 (epoch 18.346), train_loss = 0.88801628, grad/param norm = 1.3388e-01, time/batch = 15.3091s	
10458/28500 (epoch 18.347), train_loss = 1.05613936, grad/param norm = 1.5575e-01, time/batch = 15.2263s	
10459/28500 (epoch 18.349), train_loss = 1.03049962, grad/param norm = 1.4365e-01, time/batch = 15.4675s	
10460/28500 (epoch 18.351), train_loss = 0.98294103, grad/param norm = 1.5160e-01, time/batch = 15.3848s	
10461/28500 (epoch 18.353), train_loss = 1.10888522, grad/param norm = 1.6669e-01, time/batch = 15.4473s	
10462/28500 (epoch 18.354), train_loss = 0.95992624, grad/param norm = 1.6085e-01, time/batch = 15.3766s	
10463/28500 (epoch 18.356), train_loss = 0.97242737, grad/param norm = 1.3979e-01, time/batch = 15.3784s	
10464/28500 (epoch 18.358), train_loss = 1.09131687, grad/param norm = 1.5302e-01, time/batch = 15.2959s	
10465/28500 (epoch 18.360), train_loss = 1.09342554, grad/param norm = 1.6176e-01, time/batch = 15.3728s	
10466/28500 (epoch 18.361), train_loss = 1.00533218, grad/param norm = 1.5693e-01, time/batch = 15.5497s	
10467/28500 (epoch 18.363), train_loss = 0.94587312, grad/param norm = 1.4066e-01, time/batch = 15.3671s	
10468/28500 (epoch 18.365), train_loss = 1.03547201, grad/param norm = 1.6265e-01, time/batch = 15.4732s	
10469/28500 (epoch 18.367), train_loss = 1.07178781, grad/param norm = 1.6506e-01, time/batch = 15.6386s	
10470/28500 (epoch 18.368), train_loss = 1.02617100, grad/param norm = 1.5003e-01, time/batch = 15.2204s	
10471/28500 (epoch 18.370), train_loss = 1.06268843, grad/param norm = 1.6296e-01, time/batch = 15.6232s	
10472/28500 (epoch 18.372), train_loss = 0.91522100, grad/param norm = 1.4902e-01, time/batch = 15.2824s	
10473/28500 (epoch 18.374), train_loss = 1.03288491, grad/param norm = 1.6076e-01, time/batch = 15.3906s	
10474/28500 (epoch 18.375), train_loss = 1.19228074, grad/param norm = 1.5502e-01, time/batch = 15.3888s	
10475/28500 (epoch 18.377), train_loss = 0.94085609, grad/param norm = 1.5428e-01, time/batch = 15.2279s	
10476/28500 (epoch 18.379), train_loss = 0.83804495, grad/param norm = 1.5001e-01, time/batch = 15.4425s	
10477/28500 (epoch 18.381), train_loss = 1.01535781, grad/param norm = 1.3762e-01, time/batch = 15.0678s	
10478/28500 (epoch 18.382), train_loss = 1.01204291, grad/param norm = 1.5709e-01, time/batch = 15.2185s	
10479/28500 (epoch 18.384), train_loss = 0.93840800, grad/param norm = 1.4625e-01, time/batch = 15.6407s	
10480/28500 (epoch 18.386), train_loss = 0.91336702, grad/param norm = 1.4518e-01, time/batch = 15.4557s	
10481/28500 (epoch 18.388), train_loss = 1.14935741, grad/param norm = 1.6165e-01, time/batch = 15.4784s	
10482/28500 (epoch 18.389), train_loss = 0.95428374, grad/param norm = 1.5667e-01, time/batch = 15.3619s	
10483/28500 (epoch 18.391), train_loss = 0.94979287, grad/param norm = 1.4640e-01, time/batch = 15.1318s	
10484/28500 (epoch 18.393), train_loss = 0.94055615, grad/param norm = 1.6095e-01, time/batch = 15.2449s	
10485/28500 (epoch 18.395), train_loss = 1.20450344, grad/param norm = 1.6462e-01, time/batch = 15.4593s	
10486/28500 (epoch 18.396), train_loss = 1.13723106, grad/param norm = 1.6914e-01, time/batch = 15.5009s	
10487/28500 (epoch 18.398), train_loss = 0.84877892, grad/param norm = 1.6390e-01, time/batch = 15.4694s	
10488/28500 (epoch 18.400), train_loss = 1.04916656, grad/param norm = 1.6560e-01, time/batch = 15.6193s	
10489/28500 (epoch 18.402), train_loss = 1.10530762, grad/param norm = 1.6724e-01, time/batch = 15.4779s	
10490/28500 (epoch 18.404), train_loss = 1.15778004, grad/param norm = 1.8078e-01, time/batch = 15.3866s	
10491/28500 (epoch 18.405), train_loss = 1.16542131, grad/param norm = 1.5701e-01, time/batch = 15.5424s	
10492/28500 (epoch 18.407), train_loss = 1.07655292, grad/param norm = 1.5097e-01, time/batch = 15.3658s	
10493/28500 (epoch 18.409), train_loss = 1.08030175, grad/param norm = 1.6981e-01, time/batch = 15.3772s	
10494/28500 (epoch 18.411), train_loss = 1.18084447, grad/param norm = 1.6419e-01, time/batch = 15.2566s	
10495/28500 (epoch 18.412), train_loss = 1.18602437, grad/param norm = 1.7380e-01, time/batch = 15.0281s	
10496/28500 (epoch 18.414), train_loss = 1.08856020, grad/param norm = 1.6107e-01, time/batch = 15.1317s	
10497/28500 (epoch 18.416), train_loss = 0.98072293, grad/param norm = 1.5512e-01, time/batch = 15.1463s	
10498/28500 (epoch 18.418), train_loss = 1.07100251, grad/param norm = 1.4537e-01, time/batch = 15.4467s	
10499/28500 (epoch 18.419), train_loss = 1.19807236, grad/param norm = 1.8305e-01, time/batch = 15.5946s	
10500/28500 (epoch 18.421), train_loss = 1.15219584, grad/param norm = 1.6218e-01, time/batch = 15.6806s	
10501/28500 (epoch 18.423), train_loss = 1.16364045, grad/param norm = 1.9624e-01, time/batch = 15.6243s	
10502/28500 (epoch 18.425), train_loss = 1.10754310, grad/param norm = 1.6480e-01, time/batch = 15.2991s	
10503/28500 (epoch 18.426), train_loss = 1.05833730, grad/param norm = 1.7602e-01, time/batch = 15.4566s	
10504/28500 (epoch 18.428), train_loss = 1.28097165, grad/param norm = 1.7284e-01, time/batch = 15.3882s	
10505/28500 (epoch 18.430), train_loss = 1.19996600, grad/param norm = 1.5211e-01, time/batch = 15.5212s	
10506/28500 (epoch 18.432), train_loss = 1.13109767, grad/param norm = 1.8124e-01, time/batch = 15.3006s	
10507/28500 (epoch 18.433), train_loss = 1.14488022, grad/param norm = 1.7792e-01, time/batch = 15.3836s	
10508/28500 (epoch 18.435), train_loss = 1.08163387, grad/param norm = 1.7270e-01, time/batch = 15.4959s	
10509/28500 (epoch 18.437), train_loss = 0.97384061, grad/param norm = 1.4798e-01, time/batch = 15.6155s	
10510/28500 (epoch 18.439), train_loss = 1.02210719, grad/param norm = 1.4215e-01, time/batch = 15.4681s	
10511/28500 (epoch 18.440), train_loss = 1.29514078, grad/param norm = 1.7582e-01, time/batch = 15.4598s	
10512/28500 (epoch 18.442), train_loss = 1.00415428, grad/param norm = 1.5527e-01, time/batch = 15.3942s	
10513/28500 (epoch 18.444), train_loss = 0.90764839, grad/param norm = 1.4825e-01, time/batch = 15.3753s	
10514/28500 (epoch 18.446), train_loss = 0.89906132, grad/param norm = 1.4347e-01, time/batch = 15.3641s	
10515/28500 (epoch 18.447), train_loss = 0.90586296, grad/param norm = 1.3625e-01, time/batch = 15.5151s	
10516/28500 (epoch 18.449), train_loss = 1.00955726, grad/param norm = 1.4214e-01, time/batch = 15.5564s	
10517/28500 (epoch 18.451), train_loss = 1.04301035, grad/param norm = 1.5578e-01, time/batch = 15.4811s	
10518/28500 (epoch 18.453), train_loss = 1.03886925, grad/param norm = 1.5081e-01, time/batch = 15.6871s	
10519/28500 (epoch 18.454), train_loss = 1.01687981, grad/param norm = 1.4364e-01, time/batch = 15.5727s	
10520/28500 (epoch 18.456), train_loss = 1.13262273, grad/param norm = 1.7320e-01, time/batch = 15.4536s	
10521/28500 (epoch 18.458), train_loss = 1.02945592, grad/param norm = 1.5505e-01, time/batch = 15.6398s	
10522/28500 (epoch 18.460), train_loss = 1.10055304, grad/param norm = 1.5651e-01, time/batch = 15.4532s	
10523/28500 (epoch 18.461), train_loss = 1.02165879, grad/param norm = 1.7098e-01, time/batch = 20.2132s	
10524/28500 (epoch 18.463), train_loss = 0.92957467, grad/param norm = 1.3205e-01, time/batch = 17.1172s	
10525/28500 (epoch 18.465), train_loss = 0.90076939, grad/param norm = 1.6729e-01, time/batch = 15.6384s	
10526/28500 (epoch 18.467), train_loss = 1.05756547, grad/param norm = 1.5140e-01, time/batch = 15.6958s	
10527/28500 (epoch 18.468), train_loss = 0.96796667, grad/param norm = 1.3615e-01, time/batch = 15.5278s	
10528/28500 (epoch 18.470), train_loss = 0.99529820, grad/param norm = 1.6034e-01, time/batch = 15.3157s	
10529/28500 (epoch 18.472), train_loss = 1.00668086, grad/param norm = 1.4655e-01, time/batch = 15.2901s	
10530/28500 (epoch 18.474), train_loss = 1.26064929, grad/param norm = 1.8161e-01, time/batch = 15.2665s	
10531/28500 (epoch 18.475), train_loss = 0.97537095, grad/param norm = 1.4399e-01, time/batch = 15.2118s	
10532/28500 (epoch 18.477), train_loss = 1.02415254, grad/param norm = 1.6376e-01, time/batch = 15.1307s	
10533/28500 (epoch 18.479), train_loss = 1.11057763, grad/param norm = 1.5680e-01, time/batch = 15.3722s	
10534/28500 (epoch 18.481), train_loss = 1.04705925, grad/param norm = 1.6008e-01, time/batch = 15.5698s	
10535/28500 (epoch 18.482), train_loss = 0.96208774, grad/param norm = 1.5407e-01, time/batch = 15.5450s	
10536/28500 (epoch 18.484), train_loss = 0.94548790, grad/param norm = 1.4614e-01, time/batch = 15.4693s	
10537/28500 (epoch 18.486), train_loss = 0.86726056, grad/param norm = 1.5561e-01, time/batch = 15.1223s	
10538/28500 (epoch 18.488), train_loss = 1.08338415, grad/param norm = 1.4198e-01, time/batch = 15.1049s	
10539/28500 (epoch 18.489), train_loss = 1.15899994, grad/param norm = 1.6676e-01, time/batch = 15.1564s	
10540/28500 (epoch 18.491), train_loss = 1.02251305, grad/param norm = 1.6486e-01, time/batch = 15.4653s	
10541/28500 (epoch 18.493), train_loss = 1.01643870, grad/param norm = 1.4942e-01, time/batch = 15.4890s	
10542/28500 (epoch 18.495), train_loss = 1.01128280, grad/param norm = 1.4270e-01, time/batch = 15.2135s	
10543/28500 (epoch 18.496), train_loss = 0.98229757, grad/param norm = 1.6235e-01, time/batch = 15.3727s	
10544/28500 (epoch 18.498), train_loss = 1.08606750, grad/param norm = 1.5824e-01, time/batch = 15.2824s	
10545/28500 (epoch 18.500), train_loss = 1.00943865, grad/param norm = 1.4843e-01, time/batch = 15.5153s	
10546/28500 (epoch 18.502), train_loss = 1.14491934, grad/param norm = 1.5606e-01, time/batch = 15.6162s	
10547/28500 (epoch 18.504), train_loss = 1.08147982, grad/param norm = 1.5921e-01, time/batch = 15.5524s	
10548/28500 (epoch 18.505), train_loss = 0.97023274, grad/param norm = 1.4902e-01, time/batch = 15.6226s	
10549/28500 (epoch 18.507), train_loss = 1.17452233, grad/param norm = 1.8172e-01, time/batch = 15.4424s	
10550/28500 (epoch 18.509), train_loss = 1.06109845, grad/param norm = 1.5741e-01, time/batch = 15.5394s	
10551/28500 (epoch 18.511), train_loss = 1.05181045, grad/param norm = 1.7275e-01, time/batch = 15.3945s	
10552/28500 (epoch 18.512), train_loss = 1.06049090, grad/param norm = 1.4856e-01, time/batch = 15.1912s	
10553/28500 (epoch 18.514), train_loss = 0.97287342, grad/param norm = 1.4766e-01, time/batch = 15.3119s	
10554/28500 (epoch 18.516), train_loss = 1.00016570, grad/param norm = 1.3849e-01, time/batch = 15.3013s	
10555/28500 (epoch 18.518), train_loss = 1.07854419, grad/param norm = 1.4839e-01, time/batch = 15.2191s	
10556/28500 (epoch 18.519), train_loss = 1.12073082, grad/param norm = 1.5264e-01, time/batch = 15.3748s	
10557/28500 (epoch 18.521), train_loss = 1.20522082, grad/param norm = 1.7275e-01, time/batch = 15.5148s	
10558/28500 (epoch 18.523), train_loss = 1.12431254, grad/param norm = 1.7501e-01, time/batch = 15.5572s	
10559/28500 (epoch 18.525), train_loss = 1.16722800, grad/param norm = 1.6447e-01, time/batch = 15.4667s	
10560/28500 (epoch 18.526), train_loss = 1.12437388, grad/param norm = 1.6254e-01, time/batch = 15.4773s	
10561/28500 (epoch 18.528), train_loss = 1.13890423, grad/param norm = 1.6708e-01, time/batch = 15.5717s	
10562/28500 (epoch 18.530), train_loss = 1.15717233, grad/param norm = 1.5605e-01, time/batch = 15.3005s	
10563/28500 (epoch 18.532), train_loss = 1.00492343, grad/param norm = 1.5225e-01, time/batch = 15.4517s	
10564/28500 (epoch 18.533), train_loss = 1.15185093, grad/param norm = 1.6208e-01, time/batch = 15.2072s	
10565/28500 (epoch 18.535), train_loss = 0.90430338, grad/param norm = 1.4196e-01, time/batch = 15.1363s	
10566/28500 (epoch 18.537), train_loss = 0.93048389, grad/param norm = 1.4704e-01, time/batch = 15.1547s	
10567/28500 (epoch 18.539), train_loss = 0.90252384, grad/param norm = 1.5016e-01, time/batch = 15.4458s	
10568/28500 (epoch 18.540), train_loss = 1.08027888, grad/param norm = 1.6415e-01, time/batch = 15.4503s	
10569/28500 (epoch 18.542), train_loss = 1.13334161, grad/param norm = 1.9909e-01, time/batch = 15.4522s	
10570/28500 (epoch 18.544), train_loss = 1.22332623, grad/param norm = 1.7548e-01, time/batch = 15.2229s	
10571/28500 (epoch 18.546), train_loss = 1.05367242, grad/param norm = 1.6577e-01, time/batch = 15.4475s	
10572/28500 (epoch 18.547), train_loss = 1.04725606, grad/param norm = 1.5132e-01, time/batch = 15.3715s	
10573/28500 (epoch 18.549), train_loss = 0.89288212, grad/param norm = 1.2549e-01, time/batch = 15.2853s	
10574/28500 (epoch 18.551), train_loss = 1.08779634, grad/param norm = 1.9021e-01, time/batch = 15.2444s	
10575/28500 (epoch 18.553), train_loss = 1.25074923, grad/param norm = 1.9948e-01, time/batch = 15.0574s	
10576/28500 (epoch 18.554), train_loss = 1.04704026, grad/param norm = 1.5508e-01, time/batch = 22.3355s	
10577/28500 (epoch 18.556), train_loss = 1.09356616, grad/param norm = 1.6439e-01, time/batch = 20.4844s	
10578/28500 (epoch 18.558), train_loss = 1.10311262, grad/param norm = 1.5878e-01, time/batch = 15.2282s	
10579/28500 (epoch 18.560), train_loss = 1.10778938, grad/param norm = 1.7715e-01, time/batch = 15.4459s	
10580/28500 (epoch 18.561), train_loss = 1.12469868, grad/param norm = 1.5620e-01, time/batch = 15.3050s	
10581/28500 (epoch 18.563), train_loss = 1.24957909, grad/param norm = 1.7979e-01, time/batch = 15.5593s	
10582/28500 (epoch 18.565), train_loss = 1.05551209, grad/param norm = 1.6324e-01, time/batch = 15.4291s	
10583/28500 (epoch 18.567), train_loss = 0.94192590, grad/param norm = 1.4189e-01, time/batch = 15.2122s	
10584/28500 (epoch 18.568), train_loss = 1.09641933, grad/param norm = 1.6263e-01, time/batch = 15.4353s	
10585/28500 (epoch 18.570), train_loss = 1.02323484, grad/param norm = 1.4971e-01, time/batch = 15.4622s	
10586/28500 (epoch 18.572), train_loss = 1.02762043, grad/param norm = 1.6581e-01, time/batch = 15.4728s	
10587/28500 (epoch 18.574), train_loss = 1.02450801, grad/param norm = 1.6053e-01, time/batch = 15.3463s	
10588/28500 (epoch 18.575), train_loss = 1.02302975, grad/param norm = 1.4719e-01, time/batch = 15.3883s	
10589/28500 (epoch 18.577), train_loss = 1.08628820, grad/param norm = 1.5166e-01, time/batch = 15.1280s	
10590/28500 (epoch 18.579), train_loss = 1.14155258, grad/param norm = 1.7130e-01, time/batch = 15.0446s	
10591/28500 (epoch 18.581), train_loss = 0.98504283, grad/param norm = 1.5974e-01, time/batch = 15.2817s	
10592/28500 (epoch 18.582), train_loss = 1.13858620, grad/param norm = 1.4990e-01, time/batch = 15.2615s	
10593/28500 (epoch 18.584), train_loss = 1.01721862, grad/param norm = 1.6148e-01, time/batch = 15.0630s	
10594/28500 (epoch 18.586), train_loss = 0.97934798, grad/param norm = 1.4448e-01, time/batch = 15.1699s	
10595/28500 (epoch 18.588), train_loss = 0.96535515, grad/param norm = 1.4805e-01, time/batch = 15.5265s	
10596/28500 (epoch 18.589), train_loss = 1.10013924, grad/param norm = 1.6742e-01, time/batch = 15.4343s	
10597/28500 (epoch 18.591), train_loss = 1.09273274, grad/param norm = 1.7177e-01, time/batch = 15.4769s	
10598/28500 (epoch 18.593), train_loss = 1.01144234, grad/param norm = 1.4276e-01, time/batch = 15.4576s	
10599/28500 (epoch 18.595), train_loss = 1.27275328, grad/param norm = 1.9794e-01, time/batch = 15.4420s	
10600/28500 (epoch 18.596), train_loss = 1.27395524, grad/param norm = 1.8181e-01, time/batch = 15.4895s	
10601/28500 (epoch 18.598), train_loss = 1.08918005, grad/param norm = 1.6860e-01, time/batch = 15.3818s	
10602/28500 (epoch 18.600), train_loss = 1.07239771, grad/param norm = 1.6625e-01, time/batch = 15.3673s	
10603/28500 (epoch 18.602), train_loss = 1.15904033, grad/param norm = 1.6554e-01, time/batch = 15.4488s	
10604/28500 (epoch 18.604), train_loss = 1.16002288, grad/param norm = 1.6511e-01, time/batch = 15.4008s	
10605/28500 (epoch 18.605), train_loss = 1.10501547, grad/param norm = 1.6419e-01, time/batch = 15.3684s	
10606/28500 (epoch 18.607), train_loss = 1.18003152, grad/param norm = 1.5505e-01, time/batch = 15.4379s	
10607/28500 (epoch 18.609), train_loss = 1.07112232, grad/param norm = 1.5736e-01, time/batch = 15.5493s	
10608/28500 (epoch 18.611), train_loss = 1.04477081, grad/param norm = 1.5390e-01, time/batch = 15.2917s	
10609/28500 (epoch 18.612), train_loss = 1.11335536, grad/param norm = 1.6681e-01, time/batch = 15.1075s	
10610/28500 (epoch 18.614), train_loss = 1.10246421, grad/param norm = 1.5298e-01, time/batch = 15.2123s	
10611/28500 (epoch 18.616), train_loss = 1.00215348, grad/param norm = 1.5347e-01, time/batch = 15.2063s	
10612/28500 (epoch 18.618), train_loss = 1.02400275, grad/param norm = 1.5357e-01, time/batch = 15.2982s	
10613/28500 (epoch 18.619), train_loss = 1.24432653, grad/param norm = 1.8530e-01, time/batch = 15.4912s	
10614/28500 (epoch 18.621), train_loss = 0.87675985, grad/param norm = 1.4014e-01, time/batch = 15.1836s	
10615/28500 (epoch 18.623), train_loss = 1.17880218, grad/param norm = 1.6411e-01, time/batch = 15.2223s	
10616/28500 (epoch 18.625), train_loss = 0.94789513, grad/param norm = 1.6130e-01, time/batch = 15.0513s	
10617/28500 (epoch 18.626), train_loss = 0.83946661, grad/param norm = 1.3631e-01, time/batch = 15.0688s	
10618/28500 (epoch 18.628), train_loss = 1.01152054, grad/param norm = 1.6082e-01, time/batch = 15.2876s	
10619/28500 (epoch 18.630), train_loss = 0.92113262, grad/param norm = 1.4286e-01, time/batch = 15.3852s	
10620/28500 (epoch 18.632), train_loss = 1.14820796, grad/param norm = 1.5986e-01, time/batch = 15.3993s	
10621/28500 (epoch 18.633), train_loss = 1.21449298, grad/param norm = 1.5704e-01, time/batch = 15.4649s	
10622/28500 (epoch 18.635), train_loss = 1.17129654, grad/param norm = 1.7474e-01, time/batch = 15.1874s	
10623/28500 (epoch 18.637), train_loss = 1.09194179, grad/param norm = 1.5720e-01, time/batch = 15.0647s	
10624/28500 (epoch 18.639), train_loss = 0.96331823, grad/param norm = 1.4628e-01, time/batch = 15.3259s	
10625/28500 (epoch 18.640), train_loss = 0.98843730, grad/param norm = 1.5251e-01, time/batch = 15.4495s	
10626/28500 (epoch 18.642), train_loss = 1.02688810, grad/param norm = 1.4859e-01, time/batch = 15.1848s	
10627/28500 (epoch 18.644), train_loss = 1.14410051, grad/param norm = 1.5372e-01, time/batch = 15.5690s	
10628/28500 (epoch 18.646), train_loss = 0.96067737, grad/param norm = 1.4755e-01, time/batch = 15.5372s	
10629/28500 (epoch 18.647), train_loss = 0.97566983, grad/param norm = 1.6316e-01, time/batch = 15.5327s	
10630/28500 (epoch 18.649), train_loss = 0.93769209, grad/param norm = 1.4441e-01, time/batch = 15.5144s	
10631/28500 (epoch 18.651), train_loss = 0.93021659, grad/param norm = 1.4555e-01, time/batch = 15.5425s	
10632/28500 (epoch 18.653), train_loss = 0.95072413, grad/param norm = 1.5762e-01, time/batch = 15.3851s	
10633/28500 (epoch 18.654), train_loss = 1.03681044, grad/param norm = 1.5256e-01, time/batch = 15.3069s	
10634/28500 (epoch 18.656), train_loss = 0.96993968, grad/param norm = 1.5808e-01, time/batch = 15.5333s	
10635/28500 (epoch 18.658), train_loss = 1.05327752, grad/param norm = 1.5476e-01, time/batch = 15.2307s	
10636/28500 (epoch 18.660), train_loss = 1.04635303, grad/param norm = 1.3787e-01, time/batch = 15.3807s	
10637/28500 (epoch 18.661), train_loss = 1.21533842, grad/param norm = 1.8310e-01, time/batch = 15.4542s	
10638/28500 (epoch 18.663), train_loss = 1.21165325, grad/param norm = 1.6066e-01, time/batch = 15.3028s	
10639/28500 (epoch 18.665), train_loss = 1.04342002, grad/param norm = 1.5001e-01, time/batch = 15.4446s	
10640/28500 (epoch 18.667), train_loss = 1.05586954, grad/param norm = 1.6154e-01, time/batch = 15.1656s	
10641/28500 (epoch 18.668), train_loss = 1.04583899, grad/param norm = 1.5525e-01, time/batch = 15.3444s	
10642/28500 (epoch 18.670), train_loss = 1.06286365, grad/param norm = 1.5229e-01, time/batch = 15.5289s	
10643/28500 (epoch 18.672), train_loss = 0.99984733, grad/param norm = 1.5249e-01, time/batch = 15.3032s	
10644/28500 (epoch 18.674), train_loss = 0.88605092, grad/param norm = 1.5398e-01, time/batch = 15.0800s	
10645/28500 (epoch 18.675), train_loss = 0.92688888, grad/param norm = 1.4611e-01, time/batch = 15.2315s	
10646/28500 (epoch 18.677), train_loss = 1.03630870, grad/param norm = 1.5149e-01, time/batch = 15.0948s	
10647/28500 (epoch 18.679), train_loss = 1.00612111, grad/param norm = 1.6611e-01, time/batch = 15.4661s	
10648/28500 (epoch 18.681), train_loss = 1.11511053, grad/param norm = 1.5591e-01, time/batch = 15.3820s	
10649/28500 (epoch 18.682), train_loss = 1.00628409, grad/param norm = 1.4587e-01, time/batch = 15.2191s	
10650/28500 (epoch 18.684), train_loss = 1.09590741, grad/param norm = 1.6154e-01, time/batch = 15.2231s	
10651/28500 (epoch 18.686), train_loss = 0.98978805, grad/param norm = 1.6147e-01, time/batch = 15.2911s	
10652/28500 (epoch 18.688), train_loss = 0.94510381, grad/param norm = 1.3414e-01, time/batch = 15.0516s	
10653/28500 (epoch 18.689), train_loss = 1.03703218, grad/param norm = 1.6190e-01, time/batch = 15.4970s	
10654/28500 (epoch 18.691), train_loss = 1.10094264, grad/param norm = 1.7709e-01, time/batch = 15.3495s	
10655/28500 (epoch 18.693), train_loss = 1.00649530, grad/param norm = 1.5914e-01, time/batch = 15.2340s	
10656/28500 (epoch 18.695), train_loss = 0.82565281, grad/param norm = 1.6466e-01, time/batch = 15.2331s	
10657/28500 (epoch 18.696), train_loss = 1.03799183, grad/param norm = 1.6032e-01, time/batch = 15.2102s	
10658/28500 (epoch 18.698), train_loss = 1.01564756, grad/param norm = 1.5184e-01, time/batch = 15.1953s	
10659/28500 (epoch 18.700), train_loss = 1.07209968, grad/param norm = 1.5940e-01, time/batch = 15.4752s	
10660/28500 (epoch 18.702), train_loss = 1.10631850, grad/param norm = 1.7034e-01, time/batch = 15.3127s	
10661/28500 (epoch 18.704), train_loss = 1.09186659, grad/param norm = 1.5246e-01, time/batch = 15.3696s	
10662/28500 (epoch 18.705), train_loss = 1.16532605, grad/param norm = 1.9844e-01, time/batch = 15.1252s	
10663/28500 (epoch 18.707), train_loss = 0.99561127, grad/param norm = 1.6913e-01, time/batch = 15.1957s	
10664/28500 (epoch 18.709), train_loss = 1.19419870, grad/param norm = 1.6614e-01, time/batch = 15.0196s	
10665/28500 (epoch 18.711), train_loss = 0.97047051, grad/param norm = 1.6154e-01, time/batch = 15.4418s	
10666/28500 (epoch 18.712), train_loss = 1.09396473, grad/param norm = 1.6262e-01, time/batch = 15.2963s	
10667/28500 (epoch 18.714), train_loss = 1.17930129, grad/param norm = 1.6072e-01, time/batch = 15.4709s	
10668/28500 (epoch 18.716), train_loss = 1.03752054, grad/param norm = 1.7185e-01, time/batch = 15.4421s	
10669/28500 (epoch 18.718), train_loss = 1.04508790, grad/param norm = 1.5113e-01, time/batch = 15.2817s	
10670/28500 (epoch 18.719), train_loss = 1.08424623, grad/param norm = 1.6545e-01, time/batch = 15.1301s	
10671/28500 (epoch 18.721), train_loss = 0.86443163, grad/param norm = 1.4574e-01, time/batch = 15.1401s	
10672/28500 (epoch 18.723), train_loss = 1.05248743, grad/param norm = 1.6718e-01, time/batch = 15.3578s	
10673/28500 (epoch 18.725), train_loss = 1.14168824, grad/param norm = 1.4442e-01, time/batch = 15.5010s	
10674/28500 (epoch 18.726), train_loss = 1.06790985, grad/param norm = 1.5934e-01, time/batch = 15.6271s	
10675/28500 (epoch 18.728), train_loss = 0.94004535, grad/param norm = 1.4344e-01, time/batch = 15.4365s	
10676/28500 (epoch 18.730), train_loss = 1.05185445, grad/param norm = 1.6497e-01, time/batch = 15.1319s	
10677/28500 (epoch 18.732), train_loss = 0.86700521, grad/param norm = 1.3421e-01, time/batch = 15.2210s	
10678/28500 (epoch 18.733), train_loss = 0.87658306, grad/param norm = 1.3806e-01, time/batch = 15.3097s	
10679/28500 (epoch 18.735), train_loss = 0.90245343, grad/param norm = 1.3961e-01, time/batch = 15.6232s	
10680/28500 (epoch 18.737), train_loss = 0.83141269, grad/param norm = 1.3182e-01, time/batch = 15.4879s	
10681/28500 (epoch 18.739), train_loss = 0.99184721, grad/param norm = 1.5866e-01, time/batch = 15.5070s	
10682/28500 (epoch 18.740), train_loss = 1.04072181, grad/param norm = 1.6902e-01, time/batch = 15.3672s	
10683/28500 (epoch 18.742), train_loss = 0.96344369, grad/param norm = 1.5040e-01, time/batch = 15.2128s	
10684/28500 (epoch 18.744), train_loss = 1.07613407, grad/param norm = 1.5838e-01, time/batch = 15.1257s	
10685/28500 (epoch 18.746), train_loss = 0.93622987, grad/param norm = 1.3964e-01, time/batch = 15.4352s	
10686/28500 (epoch 18.747), train_loss = 0.94756715, grad/param norm = 1.4450e-01, time/batch = 15.3847s	
10687/28500 (epoch 18.749), train_loss = 1.15588757, grad/param norm = 1.8174e-01, time/batch = 15.1038s	
10688/28500 (epoch 18.751), train_loss = 0.94051665, grad/param norm = 1.6897e-01, time/batch = 15.2986s	
10689/28500 (epoch 18.753), train_loss = 0.99098200, grad/param norm = 1.5506e-01, time/batch = 15.1434s	
10690/28500 (epoch 18.754), train_loss = 0.90882503, grad/param norm = 1.3912e-01, time/batch = 15.1771s	
10691/28500 (epoch 18.756), train_loss = 1.15300892, grad/param norm = 1.6541e-01, time/batch = 15.1978s	
10692/28500 (epoch 18.758), train_loss = 1.12021744, grad/param norm = 1.7089e-01, time/batch = 15.4551s	
10693/28500 (epoch 18.760), train_loss = 0.91327489, grad/param norm = 1.4442e-01, time/batch = 15.5072s	
10694/28500 (epoch 18.761), train_loss = 0.95238648, grad/param norm = 1.6774e-01, time/batch = 15.4292s	
10695/28500 (epoch 18.763), train_loss = 0.84086209, grad/param norm = 1.4778e-01, time/batch = 15.3488s	
10696/28500 (epoch 18.765), train_loss = 0.99849165, grad/param norm = 1.4598e-01, time/batch = 15.5775s	
10697/28500 (epoch 18.767), train_loss = 0.87967333, grad/param norm = 1.4106e-01, time/batch = 15.2061s	
10698/28500 (epoch 18.768), train_loss = 1.10631667, grad/param norm = 1.6040e-01, time/batch = 15.1401s	
10699/28500 (epoch 18.770), train_loss = 0.91143114, grad/param norm = 1.4653e-01, time/batch = 15.3134s	
10700/28500 (epoch 18.772), train_loss = 0.78600679, grad/param norm = 1.3873e-01, time/batch = 15.3051s	
10701/28500 (epoch 18.774), train_loss = 1.04491509, grad/param norm = 1.6776e-01, time/batch = 15.1449s	
10702/28500 (epoch 18.775), train_loss = 1.10208969, grad/param norm = 1.4536e-01, time/batch = 15.2973s	
10703/28500 (epoch 18.777), train_loss = 1.10547778, grad/param norm = 1.5352e-01, time/batch = 15.3073s	
10704/28500 (epoch 18.779), train_loss = 0.86669486, grad/param norm = 1.3930e-01, time/batch = 15.1200s	
10705/28500 (epoch 18.781), train_loss = 1.02604766, grad/param norm = 1.5692e-01, time/batch = 15.3560s	
10706/28500 (epoch 18.782), train_loss = 1.09815219, grad/param norm = 1.6178e-01, time/batch = 15.3095s	
10707/28500 (epoch 18.784), train_loss = 0.85698749, grad/param norm = 1.3868e-01, time/batch = 15.2472s	
10708/28500 (epoch 18.786), train_loss = 0.92099175, grad/param norm = 1.5360e-01, time/batch = 15.5048s	
10709/28500 (epoch 18.788), train_loss = 1.01870177, grad/param norm = 1.5450e-01, time/batch = 15.3934s	
10710/28500 (epoch 18.789), train_loss = 0.78239359, grad/param norm = 1.5460e-01, time/batch = 15.3687s	
10711/28500 (epoch 18.791), train_loss = 1.04342272, grad/param norm = 1.4741e-01, time/batch = 15.3023s	
10712/28500 (epoch 18.793), train_loss = 1.00913958, grad/param norm = 1.6674e-01, time/batch = 15.4235s	
10713/28500 (epoch 18.795), train_loss = 1.05153644, grad/param norm = 1.4452e-01, time/batch = 15.3863s	
10714/28500 (epoch 18.796), train_loss = 0.91712901, grad/param norm = 1.4704e-01, time/batch = 15.4545s	
10715/28500 (epoch 18.798), train_loss = 0.87591989, grad/param norm = 1.5125e-01, time/batch = 15.4724s	
10716/28500 (epoch 18.800), train_loss = 0.90803594, grad/param norm = 1.5056e-01, time/batch = 15.3158s	
10717/28500 (epoch 18.802), train_loss = 0.99953709, grad/param norm = 1.6934e-01, time/batch = 15.0572s	
10718/28500 (epoch 18.804), train_loss = 1.04607227, grad/param norm = 1.4630e-01, time/batch = 15.0756s	
10719/28500 (epoch 18.805), train_loss = 1.02461885, grad/param norm = 1.5840e-01, time/batch = 15.0522s	
10720/28500 (epoch 18.807), train_loss = 1.05056703, grad/param norm = 1.5151e-01, time/batch = 15.3435s	
10721/28500 (epoch 18.809), train_loss = 0.97552483, grad/param norm = 1.4946e-01, time/batch = 15.5144s	
10722/28500 (epoch 18.811), train_loss = 1.07318791, grad/param norm = 1.6961e-01, time/batch = 15.1318s	
10723/28500 (epoch 18.812), train_loss = 1.05342513, grad/param norm = 1.7330e-01, time/batch = 15.5159s	
10724/28500 (epoch 18.814), train_loss = 0.99367199, grad/param norm = 1.4789e-01, time/batch = 15.5638s	
10725/28500 (epoch 18.816), train_loss = 1.12474283, grad/param norm = 1.8404e-01, time/batch = 15.5300s	
10726/28500 (epoch 18.818), train_loss = 1.13217613, grad/param norm = 1.8819e-01, time/batch = 15.3148s	
10727/28500 (epoch 18.819), train_loss = 1.01581885, grad/param norm = 1.4181e-01, time/batch = 15.1841s	
10728/28500 (epoch 18.821), train_loss = 0.99667712, grad/param norm = 1.5619e-01, time/batch = 15.1973s	
10729/28500 (epoch 18.823), train_loss = 1.17514595, grad/param norm = 1.8484e-01, time/batch = 15.1347s	
10730/28500 (epoch 18.825), train_loss = 0.99066042, grad/param norm = 1.6186e-01, time/batch = 15.5341s	
10731/28500 (epoch 18.826), train_loss = 1.04286865, grad/param norm = 1.6717e-01, time/batch = 15.5117s	
10732/28500 (epoch 18.828), train_loss = 0.89914041, grad/param norm = 1.6937e-01, time/batch = 15.3061s	
10733/28500 (epoch 18.830), train_loss = 0.98468188, grad/param norm = 1.4821e-01, time/batch = 15.3546s	
10734/28500 (epoch 18.832), train_loss = 1.04521100, grad/param norm = 1.8105e-01, time/batch = 15.2515s	
10735/28500 (epoch 18.833), train_loss = 1.14725335, grad/param norm = 1.6322e-01, time/batch = 15.1004s	
10736/28500 (epoch 18.835), train_loss = 0.96701402, grad/param norm = 1.5245e-01, time/batch = 15.2283s	
10737/28500 (epoch 18.837), train_loss = 0.89521213, grad/param norm = 1.5227e-01, time/batch = 15.3729s	
10738/28500 (epoch 18.839), train_loss = 1.16075596, grad/param norm = 1.8105e-01, time/batch = 15.3070s	
10739/28500 (epoch 18.840), train_loss = 1.17858915, grad/param norm = 1.7315e-01, time/batch = 15.6140s	
10740/28500 (epoch 18.842), train_loss = 1.11710606, grad/param norm = 1.7032e-01, time/batch = 15.3977s	
10741/28500 (epoch 18.844), train_loss = 1.07248014, grad/param norm = 1.8107e-01, time/batch = 15.6355s	
10742/28500 (epoch 18.846), train_loss = 1.18041470, grad/param norm = 1.7638e-01, time/batch = 15.6099s	
10743/28500 (epoch 18.847), train_loss = 0.98200811, grad/param norm = 1.5674e-01, time/batch = 15.4658s	
10744/28500 (epoch 18.849), train_loss = 0.99357322, grad/param norm = 1.6501e-01, time/batch = 15.4642s	
10745/28500 (epoch 18.851), train_loss = 0.85755516, grad/param norm = 1.4251e-01, time/batch = 15.2580s	
10746/28500 (epoch 18.853), train_loss = 1.03355018, grad/param norm = 1.6813e-01, time/batch = 15.2987s	
10747/28500 (epoch 18.854), train_loss = 1.06374449, grad/param norm = 1.6440e-01, time/batch = 15.5659s	
10748/28500 (epoch 18.856), train_loss = 1.15591208, grad/param norm = 1.7671e-01, time/batch = 15.4685s	
10749/28500 (epoch 18.858), train_loss = 0.94475244, grad/param norm = 1.3849e-01, time/batch = 15.4034s	
10750/28500 (epoch 18.860), train_loss = 1.02092653, grad/param norm = 1.5983e-01, time/batch = 15.5982s	
10751/28500 (epoch 18.861), train_loss = 1.08801218, grad/param norm = 1.7471e-01, time/batch = 15.2958s	
10752/28500 (epoch 18.863), train_loss = 1.11256381, grad/param norm = 1.8484e-01, time/batch = 15.4389s	
10753/28500 (epoch 18.865), train_loss = 1.01486549, grad/param norm = 1.5711e-01, time/batch = 15.4730s	
10754/28500 (epoch 18.867), train_loss = 1.09486959, grad/param norm = 1.7245e-01, time/batch = 15.2442s	
10755/28500 (epoch 18.868), train_loss = 0.91107208, grad/param norm = 1.4993e-01, time/batch = 15.3697s	
10756/28500 (epoch 18.870), train_loss = 0.88059619, grad/param norm = 1.4090e-01, time/batch = 15.3846s	
10757/28500 (epoch 18.872), train_loss = 1.07398879, grad/param norm = 1.8145e-01, time/batch = 15.4715s	
10758/28500 (epoch 18.874), train_loss = 0.99517616, grad/param norm = 1.6983e-01, time/batch = 15.3776s	
10759/28500 (epoch 18.875), train_loss = 1.14515314, grad/param norm = 1.7098e-01, time/batch = 15.4688s	
10760/28500 (epoch 18.877), train_loss = 1.07455721, grad/param norm = 1.5973e-01, time/batch = 15.5131s	
10761/28500 (epoch 18.879), train_loss = 1.07782124, grad/param norm = 1.4818e-01, time/batch = 15.5123s	
10762/28500 (epoch 18.881), train_loss = 1.06386753, grad/param norm = 1.7112e-01, time/batch = 15.2148s	
10763/28500 (epoch 18.882), train_loss = 0.96531511, grad/param norm = 1.5045e-01, time/batch = 15.2630s	
10764/28500 (epoch 18.884), train_loss = 1.04771349, grad/param norm = 1.7794e-01, time/batch = 15.3420s	
10765/28500 (epoch 18.886), train_loss = 1.00781791, grad/param norm = 1.5579e-01, time/batch = 15.5277s	
10766/28500 (epoch 18.888), train_loss = 0.93631883, grad/param norm = 1.6228e-01, time/batch = 15.5122s	
10767/28500 (epoch 18.889), train_loss = 1.03881178, grad/param norm = 1.5744e-01, time/batch = 15.4754s	
10768/28500 (epoch 18.891), train_loss = 1.03029092, grad/param norm = 1.5567e-01, time/batch = 15.2961s	
10769/28500 (epoch 18.893), train_loss = 0.97513348, grad/param norm = 1.5765e-01, time/batch = 15.3556s	
10770/28500 (epoch 18.895), train_loss = 1.22357125, grad/param norm = 1.8552e-01, time/batch = 15.6016s	
10771/28500 (epoch 18.896), train_loss = 1.12995045, grad/param norm = 1.7698e-01, time/batch = 15.4522s	
10772/28500 (epoch 18.898), train_loss = 1.04120750, grad/param norm = 1.6488e-01, time/batch = 15.0584s	
10773/28500 (epoch 18.900), train_loss = 0.89077897, grad/param norm = 1.4429e-01, time/batch = 15.1226s	
10774/28500 (epoch 18.902), train_loss = 0.92596289, grad/param norm = 1.7099e-01, time/batch = 15.4051s	
10775/28500 (epoch 18.904), train_loss = 0.93956593, grad/param norm = 1.4517e-01, time/batch = 15.6272s	
10776/28500 (epoch 18.905), train_loss = 1.03606236, grad/param norm = 1.5614e-01, time/batch = 15.6166s	
10777/28500 (epoch 18.907), train_loss = 1.00622173, grad/param norm = 1.5306e-01, time/batch = 15.5611s	
10778/28500 (epoch 18.909), train_loss = 0.92907802, grad/param norm = 1.7016e-01, time/batch = 15.5418s	
10779/28500 (epoch 18.911), train_loss = 0.94785489, grad/param norm = 1.5119e-01, time/batch = 15.4411s	
10780/28500 (epoch 18.912), train_loss = 0.82178199, grad/param norm = 1.3479e-01, time/batch = 15.4633s	
10781/28500 (epoch 18.914), train_loss = 1.11455590, grad/param norm = 1.5469e-01, time/batch = 15.6529s	
10782/28500 (epoch 18.916), train_loss = 1.04721880, grad/param norm = 1.7335e-01, time/batch = 15.4411s	
10783/28500 (epoch 18.918), train_loss = 1.04927817, grad/param norm = 1.6956e-01, time/batch = 15.1228s	
10784/28500 (epoch 18.919), train_loss = 1.02004574, grad/param norm = 1.5291e-01, time/batch = 15.1245s	
10785/28500 (epoch 18.921), train_loss = 1.12371416, grad/param norm = 1.8908e-01, time/batch = 15.2083s	
10786/28500 (epoch 18.923), train_loss = 1.02506763, grad/param norm = 1.8571e-01, time/batch = 15.4626s	
10787/28500 (epoch 18.925), train_loss = 0.98687547, grad/param norm = 1.7684e-01, time/batch = 15.1596s	
10788/28500 (epoch 18.926), train_loss = 1.01617694, grad/param norm = 1.5671e-01, time/batch = 14.9844s	
10789/28500 (epoch 18.928), train_loss = 0.99230904, grad/param norm = 1.6501e-01, time/batch = 15.2644s	
10790/28500 (epoch 18.930), train_loss = 0.80072460, grad/param norm = 1.3398e-01, time/batch = 15.1855s	
10791/28500 (epoch 18.932), train_loss = 0.82036459, grad/param norm = 1.2563e-01, time/batch = 15.2061s	
10792/28500 (epoch 18.933), train_loss = 1.08646529, grad/param norm = 1.5978e-01, time/batch = 15.2078s	
10793/28500 (epoch 18.935), train_loss = 1.11268097, grad/param norm = 1.6209e-01, time/batch = 15.5878s	
10794/28500 (epoch 18.937), train_loss = 1.13257837, grad/param norm = 1.8455e-01, time/batch = 15.3872s	
10795/28500 (epoch 18.939), train_loss = 1.21840692, grad/param norm = 1.8578e-01, time/batch = 15.2012s	
10796/28500 (epoch 18.940), train_loss = 0.91803208, grad/param norm = 1.5170e-01, time/batch = 15.2262s	
10797/28500 (epoch 18.942), train_loss = 1.05213570, grad/param norm = 1.5151e-01, time/batch = 15.2805s	
10798/28500 (epoch 18.944), train_loss = 0.98698435, grad/param norm = 1.5972e-01, time/batch = 15.1533s	
10799/28500 (epoch 18.946), train_loss = 1.12765536, grad/param norm = 1.5930e-01, time/batch = 15.3086s	
10800/28500 (epoch 18.947), train_loss = 1.32384858, grad/param norm = 1.9684e-01, time/batch = 15.3495s	
10801/28500 (epoch 18.949), train_loss = 0.97881990, grad/param norm = 1.6066e-01, time/batch = 15.4200s	
10802/28500 (epoch 18.951), train_loss = 1.21878102, grad/param norm = 2.1209e-01, time/batch = 15.0410s	
10803/28500 (epoch 18.953), train_loss = 1.18958945, grad/param norm = 1.8355e-01, time/batch = 15.0421s	
10804/28500 (epoch 18.954), train_loss = 1.16226739, grad/param norm = 1.8051e-01, time/batch = 15.4530s	
10805/28500 (epoch 18.956), train_loss = 1.08349053, grad/param norm = 2.0558e-01, time/batch = 15.3556s	
10806/28500 (epoch 18.958), train_loss = 1.23351542, grad/param norm = 1.6412e-01, time/batch = 15.3814s	
10807/28500 (epoch 18.960), train_loss = 0.95029209, grad/param norm = 1.6652e-01, time/batch = 15.5497s	
10808/28500 (epoch 18.961), train_loss = 1.26266762, grad/param norm = 1.8842e-01, time/batch = 16.6005s	
10809/28500 (epoch 18.963), train_loss = 1.14931210, grad/param norm = 1.6876e-01, time/batch = 26.4022s	
10810/28500 (epoch 18.965), train_loss = 0.96215707, grad/param norm = 1.6128e-01, time/batch = 15.3671s	
10811/28500 (epoch 18.967), train_loss = 0.93345156, grad/param norm = 1.5014e-01, time/batch = 15.5211s	
10812/28500 (epoch 18.968), train_loss = 0.89334833, grad/param norm = 1.3423e-01, time/batch = 15.1174s	
10813/28500 (epoch 18.970), train_loss = 0.97806799, grad/param norm = 1.5652e-01, time/batch = 15.4790s	
10814/28500 (epoch 18.972), train_loss = 1.03412652, grad/param norm = 1.5293e-01, time/batch = 15.4471s	
10815/28500 (epoch 18.974), train_loss = 1.22456715, grad/param norm = 1.7843e-01, time/batch = 15.5153s	
10816/28500 (epoch 18.975), train_loss = 0.99507748, grad/param norm = 1.8408e-01, time/batch = 15.6153s	
10817/28500 (epoch 18.977), train_loss = 1.17087489, grad/param norm = 1.8781e-01, time/batch = 15.3740s	
10818/28500 (epoch 18.979), train_loss = 0.99789266, grad/param norm = 1.6176e-01, time/batch = 15.4920s	
10819/28500 (epoch 18.981), train_loss = 0.94554712, grad/param norm = 1.5679e-01, time/batch = 15.5317s	
10820/28500 (epoch 18.982), train_loss = 1.02150179, grad/param norm = 1.4924e-01, time/batch = 15.5047s	
10821/28500 (epoch 18.984), train_loss = 1.11775825, grad/param norm = 1.6199e-01, time/batch = 15.3307s	
10822/28500 (epoch 18.986), train_loss = 1.27530813, grad/param norm = 1.8144e-01, time/batch = 15.3765s	
10823/28500 (epoch 18.988), train_loss = 0.87940932, grad/param norm = 1.4860e-01, time/batch = 15.5089s	
10824/28500 (epoch 18.989), train_loss = 1.08098835, grad/param norm = 1.7284e-01, time/batch = 15.2937s	
10825/28500 (epoch 18.991), train_loss = 0.96326710, grad/param norm = 1.6605e-01, time/batch = 15.5122s	
10826/28500 (epoch 18.993), train_loss = 0.97387003, grad/param norm = 1.5848e-01, time/batch = 15.5091s	
10827/28500 (epoch 18.995), train_loss = 0.97151446, grad/param norm = 1.6295e-01, time/batch = 15.4316s	
10828/28500 (epoch 18.996), train_loss = 0.92245752, grad/param norm = 1.5295e-01, time/batch = 15.2246s	
10829/28500 (epoch 18.998), train_loss = 1.15655888, grad/param norm = 1.8795e-01, time/batch = 15.1253s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
10830/28500 (epoch 19.000), train_loss = 1.00706334, grad/param norm = 1.5130e-01, time/batch = 15.0630s	
10831/28500 (epoch 19.002), train_loss = 1.18625637, grad/param norm = 1.7385e-01, time/batch = 15.2001s	
10832/28500 (epoch 19.004), train_loss = 0.98961410, grad/param norm = 1.5096e-01, time/batch = 15.2735s	
10833/28500 (epoch 19.005), train_loss = 1.16726289, grad/param norm = 1.7139e-01, time/batch = 15.0588s	
10834/28500 (epoch 19.007), train_loss = 0.91691026, grad/param norm = 1.4383e-01, time/batch = 15.0633s	
10835/28500 (epoch 19.009), train_loss = 1.09357665, grad/param norm = 1.7530e-01, time/batch = 15.1924s	
10836/28500 (epoch 19.011), train_loss = 0.95942994, grad/param norm = 1.7840e-01, time/batch = 15.0693s	
10837/28500 (epoch 19.012), train_loss = 0.91102321, grad/param norm = 1.3813e-01, time/batch = 14.9794s	
10838/28500 (epoch 19.014), train_loss = 0.94445950, grad/param norm = 1.5293e-01, time/batch = 15.3882s	
10839/28500 (epoch 19.016), train_loss = 0.99636606, grad/param norm = 1.4684e-01, time/batch = 15.4411s	
10840/28500 (epoch 19.018), train_loss = 1.04666962, grad/param norm = 1.6022e-01, time/batch = 15.2323s	
10841/28500 (epoch 19.019), train_loss = 1.10015118, grad/param norm = 1.8152e-01, time/batch = 15.3240s	
10842/28500 (epoch 19.021), train_loss = 1.10979722, grad/param norm = 1.4569e-01, time/batch = 15.4466s	
10843/28500 (epoch 19.023), train_loss = 1.00998991, grad/param norm = 1.4994e-01, time/batch = 15.3456s	
10844/28500 (epoch 19.025), train_loss = 1.06033308, grad/param norm = 1.5529e-01, time/batch = 15.4760s	
10845/28500 (epoch 19.026), train_loss = 1.01813300, grad/param norm = 1.5222e-01, time/batch = 15.3974s	
10846/28500 (epoch 19.028), train_loss = 1.07281849, grad/param norm = 1.6032e-01, time/batch = 15.3024s	
10847/28500 (epoch 19.030), train_loss = 1.09457155, grad/param norm = 1.7877e-01, time/batch = 15.3644s	
10848/28500 (epoch 19.032), train_loss = 1.12265369, grad/param norm = 1.6042e-01, time/batch = 15.4566s	
10849/28500 (epoch 19.033), train_loss = 1.20720522, grad/param norm = 1.8403e-01, time/batch = 15.3899s	
10850/28500 (epoch 19.035), train_loss = 1.05004444, grad/param norm = 1.8683e-01, time/batch = 15.3782s	
10851/28500 (epoch 19.037), train_loss = 1.12877729, grad/param norm = 1.6487e-01, time/batch = 15.4465s	
10852/28500 (epoch 19.039), train_loss = 1.14854041, grad/param norm = 1.7206e-01, time/batch = 15.2147s	
10853/28500 (epoch 19.040), train_loss = 1.18290241, grad/param norm = 1.6463e-01, time/batch = 15.4034s	
10854/28500 (epoch 19.042), train_loss = 1.11666867, grad/param norm = 1.6653e-01, time/batch = 15.4647s	
10855/28500 (epoch 19.044), train_loss = 1.04456276, grad/param norm = 1.6083e-01, time/batch = 15.6838s	
10856/28500 (epoch 19.046), train_loss = 1.28626700, grad/param norm = 1.7925e-01, time/batch = 15.4680s	
10857/28500 (epoch 19.047), train_loss = 1.17355495, grad/param norm = 1.7299e-01, time/batch = 15.7115s	
10858/28500 (epoch 19.049), train_loss = 1.08000548, grad/param norm = 1.7359e-01, time/batch = 15.6169s	
10859/28500 (epoch 19.051), train_loss = 1.02079620, grad/param norm = 1.5376e-01, time/batch = 15.4735s	
10860/28500 (epoch 19.053), train_loss = 1.04442280, grad/param norm = 1.6427e-01, time/batch = 15.0608s	
10861/28500 (epoch 19.054), train_loss = 1.11820380, grad/param norm = 1.5944e-01, time/batch = 15.2212s	
10862/28500 (epoch 19.056), train_loss = 0.94593362, grad/param norm = 1.5169e-01, time/batch = 15.1845s	
10863/28500 (epoch 19.058), train_loss = 0.93943562, grad/param norm = 1.4448e-01, time/batch = 15.1939s	
10864/28500 (epoch 19.060), train_loss = 1.14241860, grad/param norm = 1.6802e-01, time/batch = 15.3606s	
10865/28500 (epoch 19.061), train_loss = 1.05663619, grad/param norm = 1.7507e-01, time/batch = 15.4548s	
10866/28500 (epoch 19.063), train_loss = 1.11877970, grad/param norm = 1.6375e-01, time/batch = 15.4132s	
10867/28500 (epoch 19.065), train_loss = 1.15189879, grad/param norm = 1.8026e-01, time/batch = 15.5686s	
10868/28500 (epoch 19.067), train_loss = 1.01135347, grad/param norm = 1.4289e-01, time/batch = 15.4637s	
10869/28500 (epoch 19.068), train_loss = 1.03258308, grad/param norm = 1.5312e-01, time/batch = 15.4196s	
10870/28500 (epoch 19.070), train_loss = 1.10727631, grad/param norm = 1.7412e-01, time/batch = 15.2900s	
10871/28500 (epoch 19.072), train_loss = 1.21825378, grad/param norm = 1.7015e-01, time/batch = 15.1288s	
10872/28500 (epoch 19.074), train_loss = 1.07640552, grad/param norm = 1.4688e-01, time/batch = 15.2443s	
10873/28500 (epoch 19.075), train_loss = 1.02971589, grad/param norm = 1.4137e-01, time/batch = 15.3879s	
10874/28500 (epoch 19.077), train_loss = 1.11377529, grad/param norm = 1.6323e-01, time/batch = 15.4647s	
10875/28500 (epoch 19.079), train_loss = 1.07291631, grad/param norm = 1.6277e-01, time/batch = 15.2713s	
10876/28500 (epoch 19.081), train_loss = 1.17661743, grad/param norm = 1.7408e-01, time/batch = 15.6407s	
10877/28500 (epoch 19.082), train_loss = 1.07034115, grad/param norm = 1.7448e-01, time/batch = 15.7093s	
10878/28500 (epoch 19.084), train_loss = 1.09808141, grad/param norm = 1.6027e-01, time/batch = 15.2316s	
10879/28500 (epoch 19.086), train_loss = 1.02949499, grad/param norm = 1.6846e-01, time/batch = 15.3880s	
10880/28500 (epoch 19.088), train_loss = 0.97408432, grad/param norm = 1.6961e-01, time/batch = 15.4830s	
10881/28500 (epoch 19.089), train_loss = 1.14439532, grad/param norm = 1.3856e-01, time/batch = 15.5210s	
10882/28500 (epoch 19.091), train_loss = 0.93347045, grad/param norm = 1.4791e-01, time/batch = 15.5137s	
10883/28500 (epoch 19.093), train_loss = 1.10878002, grad/param norm = 1.5090e-01, time/batch = 15.1403s	
10884/28500 (epoch 19.095), train_loss = 0.99616373, grad/param norm = 1.3926e-01, time/batch = 15.3077s	
10885/28500 (epoch 19.096), train_loss = 1.17036968, grad/param norm = 1.6222e-01, time/batch = 15.4380s	
10886/28500 (epoch 19.098), train_loss = 1.09263969, grad/param norm = 1.7944e-01, time/batch = 15.4946s	
10887/28500 (epoch 19.100), train_loss = 1.01477715, grad/param norm = 1.5874e-01, time/batch = 15.2310s	
10888/28500 (epoch 19.102), train_loss = 1.15634228, grad/param norm = 1.7367e-01, time/batch = 15.3906s	
10889/28500 (epoch 19.104), train_loss = 1.03368446, grad/param norm = 1.7592e-01, time/batch = 15.1917s	
10890/28500 (epoch 19.105), train_loss = 1.18717415, grad/param norm = 1.6745e-01, time/batch = 15.1199s	
10891/28500 (epoch 19.107), train_loss = 0.94717955, grad/param norm = 1.5124e-01, time/batch = 15.2802s	
10892/28500 (epoch 19.109), train_loss = 0.92312956, grad/param norm = 1.5690e-01, time/batch = 15.3736s	
10893/28500 (epoch 19.111), train_loss = 1.00957486, grad/param norm = 1.8723e-01, time/batch = 15.4881s	
10894/28500 (epoch 19.112), train_loss = 1.10201809, grad/param norm = 1.6223e-01, time/batch = 15.4432s	
10895/28500 (epoch 19.114), train_loss = 1.03801595, grad/param norm = 1.6892e-01, time/batch = 15.2391s	
10896/28500 (epoch 19.116), train_loss = 1.23941962, grad/param norm = 1.8556e-01, time/batch = 15.4823s	
10897/28500 (epoch 19.118), train_loss = 0.93063564, grad/param norm = 1.7156e-01, time/batch = 15.2960s	
10898/28500 (epoch 19.119), train_loss = 1.07599970, grad/param norm = 1.6808e-01, time/batch = 15.2990s	
10899/28500 (epoch 19.121), train_loss = 1.20556657, grad/param norm = 1.9084e-01, time/batch = 15.3778s	
10900/28500 (epoch 19.123), train_loss = 1.12288093, grad/param norm = 1.6251e-01, time/batch = 15.3111s	
10901/28500 (epoch 19.125), train_loss = 1.07302768, grad/param norm = 1.6490e-01, time/batch = 15.5291s	
10902/28500 (epoch 19.126), train_loss = 1.06327349, grad/param norm = 1.6735e-01, time/batch = 15.4370s	
10903/28500 (epoch 19.128), train_loss = 1.05129600, grad/param norm = 1.5713e-01, time/batch = 15.0529s	
10904/28500 (epoch 19.130), train_loss = 0.93918513, grad/param norm = 1.5106e-01, time/batch = 15.2031s	
10905/28500 (epoch 19.132), train_loss = 1.11354945, grad/param norm = 2.0887e-01, time/batch = 15.3463s	
10906/28500 (epoch 19.133), train_loss = 1.12543278, grad/param norm = 1.7337e-01, time/batch = 15.1071s	
10907/28500 (epoch 19.135), train_loss = 1.01503329, grad/param norm = 1.4434e-01, time/batch = 15.1070s	
10908/28500 (epoch 19.137), train_loss = 1.06321661, grad/param norm = 1.7690e-01, time/batch = 15.1385s	
10909/28500 (epoch 19.139), train_loss = 1.02706506, grad/param norm = 1.3988e-01, time/batch = 15.2429s	
10910/28500 (epoch 19.140), train_loss = 1.08884771, grad/param norm = 1.4970e-01, time/batch = 15.2053s	
10911/28500 (epoch 19.142), train_loss = 1.04539503, grad/param norm = 1.7950e-01, time/batch = 15.2942s	
10912/28500 (epoch 19.144), train_loss = 0.98704243, grad/param norm = 1.3885e-01, time/batch = 15.1228s	
10913/28500 (epoch 19.146), train_loss = 1.01231202, grad/param norm = 1.6003e-01, time/batch = 15.2133s	
10914/28500 (epoch 19.147), train_loss = 0.92693711, grad/param norm = 1.5000e-01, time/batch = 15.2220s	
10915/28500 (epoch 19.149), train_loss = 0.91313384, grad/param norm = 1.4304e-01, time/batch = 15.2399s	
10916/28500 (epoch 19.151), train_loss = 0.98058271, grad/param norm = 1.4900e-01, time/batch = 15.3737s	
10917/28500 (epoch 19.153), train_loss = 1.07136101, grad/param norm = 1.7565e-01, time/batch = 15.2154s	
10918/28500 (epoch 19.154), train_loss = 0.96466066, grad/param norm = 1.6339e-01, time/batch = 15.2195s	
10919/28500 (epoch 19.156), train_loss = 1.16472974, grad/param norm = 1.5976e-01, time/batch = 15.4590s	
10920/28500 (epoch 19.158), train_loss = 1.04867943, grad/param norm = 1.5228e-01, time/batch = 15.4860s	
10921/28500 (epoch 19.160), train_loss = 0.93811079, grad/param norm = 1.3649e-01, time/batch = 15.3849s	
10922/28500 (epoch 19.161), train_loss = 1.01703684, grad/param norm = 1.6262e-01, time/batch = 15.3642s	
10923/28500 (epoch 19.163), train_loss = 0.91130412, grad/param norm = 1.5310e-01, time/batch = 15.3986s	
10924/28500 (epoch 19.165), train_loss = 1.24747452, grad/param norm = 1.6047e-01, time/batch = 15.6393s	
10925/28500 (epoch 19.167), train_loss = 1.28234232, grad/param norm = 1.8506e-01, time/batch = 15.7109s	
10926/28500 (epoch 19.168), train_loss = 1.18077030, grad/param norm = 1.8475e-01, time/batch = 15.6377s	
10927/28500 (epoch 19.170), train_loss = 1.15213332, grad/param norm = 1.9245e-01, time/batch = 15.3858s	
10928/28500 (epoch 19.172), train_loss = 1.03864592, grad/param norm = 1.4792e-01, time/batch = 15.3604s	
10929/28500 (epoch 19.174), train_loss = 1.23873501, grad/param norm = 2.0630e-01, time/batch = 15.6101s	
10930/28500 (epoch 19.175), train_loss = 1.05923329, grad/param norm = 1.5380e-01, time/batch = 15.5930s	
10931/28500 (epoch 19.177), train_loss = 1.12374217, grad/param norm = 1.7611e-01, time/batch = 15.5287s	
10932/28500 (epoch 19.179), train_loss = 1.07073360, grad/param norm = 1.7450e-01, time/batch = 15.3618s	
10933/28500 (epoch 19.181), train_loss = 1.13166974, grad/param norm = 1.6317e-01, time/batch = 15.4981s	
10934/28500 (epoch 19.182), train_loss = 1.03709222, grad/param norm = 1.4527e-01, time/batch = 15.5206s	
10935/28500 (epoch 19.184), train_loss = 1.21819228, grad/param norm = 1.7527e-01, time/batch = 15.3076s	
10936/28500 (epoch 19.186), train_loss = 1.15952391, grad/param norm = 1.6899e-01, time/batch = 15.5309s	
10937/28500 (epoch 19.188), train_loss = 1.08069117, grad/param norm = 1.5506e-01, time/batch = 15.3966s	
10938/28500 (epoch 19.189), train_loss = 1.08115125, grad/param norm = 1.6432e-01, time/batch = 15.4814s	
10939/28500 (epoch 19.191), train_loss = 1.29002136, grad/param norm = 1.7560e-01, time/batch = 15.5506s	
10940/28500 (epoch 19.193), train_loss = 1.14098124, grad/param norm = 1.9309e-01, time/batch = 15.3814s	
10941/28500 (epoch 19.195), train_loss = 1.20897020, grad/param norm = 1.6753e-01, time/batch = 15.5398s	
10942/28500 (epoch 19.196), train_loss = 1.11980888, grad/param norm = 1.6904e-01, time/batch = 15.2732s	
10943/28500 (epoch 19.198), train_loss = 1.09125972, grad/param norm = 1.7997e-01, time/batch = 15.2876s	
10944/28500 (epoch 19.200), train_loss = 1.11717648, grad/param norm = 1.6805e-01, time/batch = 15.2651s	
10945/28500 (epoch 19.202), train_loss = 1.09069751, grad/param norm = 1.5874e-01, time/batch = 15.2086s	
10946/28500 (epoch 19.204), train_loss = 1.00369569, grad/param norm = 1.3896e-01, time/batch = 15.3341s	
10947/28500 (epoch 19.205), train_loss = 1.03872533, grad/param norm = 1.7272e-01, time/batch = 15.4804s	
10948/28500 (epoch 19.207), train_loss = 0.97660315, grad/param norm = 1.6457e-01, time/batch = 15.3896s	
10949/28500 (epoch 19.209), train_loss = 1.07218241, grad/param norm = 1.5001e-01, time/batch = 15.3420s	
10950/28500 (epoch 19.211), train_loss = 0.93126855, grad/param norm = 1.6328e-01, time/batch = 15.3850s	
10951/28500 (epoch 19.212), train_loss = 0.91386524, grad/param norm = 1.4965e-01, time/batch = 15.3691s	
10952/28500 (epoch 19.214), train_loss = 1.06532538, grad/param norm = 1.7013e-01, time/batch = 15.3101s	
10953/28500 (epoch 19.216), train_loss = 0.96503328, grad/param norm = 1.4507e-01, time/batch = 15.1389s	
10954/28500 (epoch 19.218), train_loss = 1.17999023, grad/param norm = 1.5601e-01, time/batch = 15.4600s	
10955/28500 (epoch 19.219), train_loss = 1.11117198, grad/param norm = 1.7180e-01, time/batch = 15.5241s	
10956/28500 (epoch 19.221), train_loss = 0.93358287, grad/param norm = 1.5746e-01, time/batch = 15.5552s	
10957/28500 (epoch 19.223), train_loss = 1.18587639, grad/param norm = 1.6342e-01, time/batch = 15.4730s	
10958/28500 (epoch 19.225), train_loss = 1.19091650, grad/param norm = 1.7223e-01, time/batch = 15.2973s	
10959/28500 (epoch 19.226), train_loss = 1.01265718, grad/param norm = 1.4959e-01, time/batch = 15.3541s	
10960/28500 (epoch 19.228), train_loss = 1.15896957, grad/param norm = 1.5910e-01, time/batch = 15.2494s	
10961/28500 (epoch 19.230), train_loss = 1.16097956, grad/param norm = 1.6295e-01, time/batch = 15.2250s	
10962/28500 (epoch 19.232), train_loss = 1.09750031, grad/param norm = 1.4581e-01, time/batch = 15.3553s	
10963/28500 (epoch 19.233), train_loss = 1.08391986, grad/param norm = 1.8875e-01, time/batch = 15.2927s	
10964/28500 (epoch 19.235), train_loss = 1.03839043, grad/param norm = 1.4588e-01, time/batch = 15.2192s	
10965/28500 (epoch 19.237), train_loss = 0.93683269, grad/param norm = 1.3829e-01, time/batch = 15.2088s	
10966/28500 (epoch 19.239), train_loss = 0.98781720, grad/param norm = 1.4041e-01, time/batch = 15.4635s	
10967/28500 (epoch 19.240), train_loss = 0.95711654, grad/param norm = 1.6263e-01, time/batch = 15.5331s	
10968/28500 (epoch 19.242), train_loss = 1.10161299, grad/param norm = 1.7889e-01, time/batch = 15.7140s	
10969/28500 (epoch 19.244), train_loss = 1.10664006, grad/param norm = 1.4543e-01, time/batch = 15.5604s	
10970/28500 (epoch 19.246), train_loss = 1.15711364, grad/param norm = 1.6589e-01, time/batch = 15.5500s	
10971/28500 (epoch 19.247), train_loss = 1.22188778, grad/param norm = 1.7782e-01, time/batch = 15.5963s	
10972/28500 (epoch 19.249), train_loss = 1.06279112, grad/param norm = 1.4971e-01, time/batch = 15.4455s	
10973/28500 (epoch 19.251), train_loss = 1.00849842, grad/param norm = 1.5000e-01, time/batch = 15.2200s	
10974/28500 (epoch 19.253), train_loss = 1.21180513, grad/param norm = 1.7058e-01, time/batch = 15.1789s	
10975/28500 (epoch 19.254), train_loss = 1.21113934, grad/param norm = 1.6587e-01, time/batch = 15.2289s	
10976/28500 (epoch 19.256), train_loss = 1.00355742, grad/param norm = 1.6651e-01, time/batch = 15.6349s	
10977/28500 (epoch 19.258), train_loss = 1.06694189, grad/param norm = 1.8296e-01, time/batch = 15.5555s	
10978/28500 (epoch 19.260), train_loss = 1.00047351, grad/param norm = 1.5190e-01, time/batch = 15.6345s	
10979/28500 (epoch 19.261), train_loss = 0.99786022, grad/param norm = 1.5610e-01, time/batch = 15.6278s	
10980/28500 (epoch 19.263), train_loss = 1.17603065, grad/param norm = 1.7278e-01, time/batch = 15.4784s	
10981/28500 (epoch 19.265), train_loss = 1.08052582, grad/param norm = 1.6876e-01, time/batch = 15.3440s	
10982/28500 (epoch 19.267), train_loss = 1.20974157, grad/param norm = 1.8522e-01, time/batch = 15.5219s	
10983/28500 (epoch 19.268), train_loss = 1.12210110, grad/param norm = 1.6506e-01, time/batch = 15.4686s	
10984/28500 (epoch 19.270), train_loss = 1.11577304, grad/param norm = 1.8753e-01, time/batch = 15.2909s	
10985/28500 (epoch 19.272), train_loss = 1.03706302, grad/param norm = 1.5933e-01, time/batch = 15.4730s	
10986/28500 (epoch 19.274), train_loss = 1.20478793, grad/param norm = 1.7897e-01, time/batch = 15.4235s	
10987/28500 (epoch 19.275), train_loss = 1.09910881, grad/param norm = 1.5075e-01, time/batch = 15.3728s	
10988/28500 (epoch 19.277), train_loss = 1.08433761, grad/param norm = 1.5987e-01, time/batch = 15.3354s	
10989/28500 (epoch 19.279), train_loss = 1.12795161, grad/param norm = 1.7934e-01, time/batch = 15.2766s	
10990/28500 (epoch 19.281), train_loss = 1.15389477, grad/param norm = 1.8657e-01, time/batch = 15.1232s	
10991/28500 (epoch 19.282), train_loss = 0.99455877, grad/param norm = 1.4530e-01, time/batch = 15.3731s	
10992/28500 (epoch 19.284), train_loss = 1.09325344, grad/param norm = 1.8009e-01, time/batch = 15.2149s	
10993/28500 (epoch 19.286), train_loss = 1.17343259, grad/param norm = 1.6628e-01, time/batch = 15.2978s	
10994/28500 (epoch 19.288), train_loss = 1.12643147, grad/param norm = 1.7944e-01, time/batch = 15.5268s	
10995/28500 (epoch 19.289), train_loss = 1.11743990, grad/param norm = 1.8125e-01, time/batch = 15.4749s	
10996/28500 (epoch 19.291), train_loss = 1.10219037, grad/param norm = 1.6080e-01, time/batch = 15.4746s	
10997/28500 (epoch 19.293), train_loss = 1.05456904, grad/param norm = 1.6336e-01, time/batch = 15.4670s	
10998/28500 (epoch 19.295), train_loss = 0.95205994, grad/param norm = 1.6129e-01, time/batch = 15.5311s	
10999/28500 (epoch 19.296), train_loss = 0.96052958, grad/param norm = 1.5550e-01, time/batch = 15.3821s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch19.30_1.6737.t7	
11000/28500 (epoch 19.298), train_loss = 1.14383378, grad/param norm = 1.5713e-01, time/batch = 15.2371s	
11001/28500 (epoch 19.300), train_loss = 1.33984806, grad/param norm = 1.8073e-01, time/batch = 15.5420s	
11002/28500 (epoch 19.302), train_loss = 0.94786185, grad/param norm = 1.4324e-01, time/batch = 15.5351s	
11003/28500 (epoch 19.304), train_loss = 1.04199534, grad/param norm = 1.5028e-01, time/batch = 15.3753s	
11004/28500 (epoch 19.305), train_loss = 1.11047420, grad/param norm = 1.5665e-01, time/batch = 15.3647s	
11005/28500 (epoch 19.307), train_loss = 1.06722612, grad/param norm = 1.7428e-01, time/batch = 15.6521s	
11006/28500 (epoch 19.309), train_loss = 1.05712096, grad/param norm = 1.5124e-01, time/batch = 15.6095s	
11007/28500 (epoch 19.311), train_loss = 1.12633941, grad/param norm = 1.5073e-01, time/batch = 15.2251s	
11008/28500 (epoch 19.312), train_loss = 1.06618422, grad/param norm = 1.5930e-01, time/batch = 15.2321s	
11009/28500 (epoch 19.314), train_loss = 1.15434889, grad/param norm = 1.8019e-01, time/batch = 15.1973s	
11010/28500 (epoch 19.316), train_loss = 1.08741884, grad/param norm = 1.5355e-01, time/batch = 15.2977s	
11011/28500 (epoch 19.318), train_loss = 1.14213499, grad/param norm = 1.6776e-01, time/batch = 15.5433s	
11012/28500 (epoch 19.319), train_loss = 1.02184169, grad/param norm = 1.5122e-01, time/batch = 15.5413s	
11013/28500 (epoch 19.321), train_loss = 1.01410927, grad/param norm = 1.7017e-01, time/batch = 15.3069s	
11014/28500 (epoch 19.323), train_loss = 1.03473117, grad/param norm = 1.6848e-01, time/batch = 15.0978s	
11015/28500 (epoch 19.325), train_loss = 1.21347466, grad/param norm = 1.7609e-01, time/batch = 15.0579s	
11016/28500 (epoch 19.326), train_loss = 1.08376648, grad/param norm = 1.6384e-01, time/batch = 14.9658s	
11017/28500 (epoch 19.328), train_loss = 0.87718039, grad/param norm = 1.4801e-01, time/batch = 15.1396s	
11018/28500 (epoch 19.330), train_loss = 0.97569916, grad/param norm = 1.5762e-01, time/batch = 15.1189s	
11019/28500 (epoch 19.332), train_loss = 1.06770452, grad/param norm = 1.4470e-01, time/batch = 15.4069s	
11020/28500 (epoch 19.333), train_loss = 0.89812232, grad/param norm = 1.6432e-01, time/batch = 15.5371s	
11021/28500 (epoch 19.335), train_loss = 0.95012290, grad/param norm = 1.4608e-01, time/batch = 15.5950s	
11022/28500 (epoch 19.337), train_loss = 0.96914232, grad/param norm = 1.5181e-01, time/batch = 15.4406s	
11023/28500 (epoch 19.339), train_loss = 0.90382971, grad/param norm = 1.3695e-01, time/batch = 15.1287s	
11024/28500 (epoch 19.340), train_loss = 1.09898156, grad/param norm = 1.7515e-01, time/batch = 15.1317s	
11025/28500 (epoch 19.342), train_loss = 1.05891420, grad/param norm = 1.5597e-01, time/batch = 15.2691s	
11026/28500 (epoch 19.344), train_loss = 0.99247324, grad/param norm = 1.7249e-01, time/batch = 15.0525s	
11027/28500 (epoch 19.346), train_loss = 0.87510867, grad/param norm = 1.3575e-01, time/batch = 15.1263s	
11028/28500 (epoch 19.347), train_loss = 1.04660971, grad/param norm = 1.6674e-01, time/batch = 15.0628s	
11029/28500 (epoch 19.349), train_loss = 1.01966585, grad/param norm = 1.4506e-01, time/batch = 15.3993s	
11030/28500 (epoch 19.351), train_loss = 0.96633311, grad/param norm = 1.4701e-01, time/batch = 15.2230s	
11031/28500 (epoch 19.353), train_loss = 1.08487693, grad/param norm = 1.6661e-01, time/batch = 15.5198s	
11032/28500 (epoch 19.354), train_loss = 0.94180022, grad/param norm = 1.5622e-01, time/batch = 15.2494s	
11033/28500 (epoch 19.356), train_loss = 0.95459616, grad/param norm = 1.4044e-01, time/batch = 27.3596s	
11034/28500 (epoch 19.358), train_loss = 1.07012733, grad/param norm = 1.6039e-01, time/batch = 15.5427s	
11035/28500 (epoch 19.360), train_loss = 1.08035996, grad/param norm = 1.6604e-01, time/batch = 15.3131s	
11036/28500 (epoch 19.361), train_loss = 0.98009443, grad/param norm = 1.5036e-01, time/batch = 15.3743s	
11037/28500 (epoch 19.363), train_loss = 0.92566771, grad/param norm = 1.4057e-01, time/batch = 15.3691s	
11038/28500 (epoch 19.365), train_loss = 1.01463544, grad/param norm = 1.6132e-01, time/batch = 15.3914s	
11039/28500 (epoch 19.367), train_loss = 1.05998753, grad/param norm = 1.6935e-01, time/batch = 15.3899s	
11040/28500 (epoch 19.368), train_loss = 1.01983900, grad/param norm = 1.6738e-01, time/batch = 15.6162s	
11041/28500 (epoch 19.370), train_loss = 1.05415335, grad/param norm = 1.8301e-01, time/batch = 15.5737s	
11042/28500 (epoch 19.372), train_loss = 0.91280581, grad/param norm = 1.6571e-01, time/batch = 15.2920s	
11043/28500 (epoch 19.374), train_loss = 1.01969686, grad/param norm = 1.6360e-01, time/batch = 15.4659s	
11044/28500 (epoch 19.375), train_loss = 1.16794319, grad/param norm = 1.5501e-01, time/batch = 15.3547s	
11045/28500 (epoch 19.377), train_loss = 0.92995846, grad/param norm = 2.0270e-01, time/batch = 15.4317s	
11046/28500 (epoch 19.379), train_loss = 0.82608558, grad/param norm = 1.5983e-01, time/batch = 15.3867s	
11047/28500 (epoch 19.381), train_loss = 1.00942499, grad/param norm = 1.5351e-01, time/batch = 15.4756s	
11048/28500 (epoch 19.382), train_loss = 0.99296489, grad/param norm = 1.6044e-01, time/batch = 15.5474s	
11049/28500 (epoch 19.384), train_loss = 0.91450997, grad/param norm = 1.5022e-01, time/batch = 15.5584s	
11050/28500 (epoch 19.386), train_loss = 0.90007202, grad/param norm = 1.4307e-01, time/batch = 15.5474s	
11051/28500 (epoch 19.388), train_loss = 1.13748315, grad/param norm = 1.6638e-01, time/batch = 15.6970s	
11052/28500 (epoch 19.389), train_loss = 0.95514160, grad/param norm = 1.7468e-01, time/batch = 15.5313s	
11053/28500 (epoch 19.391), train_loss = 0.93625433, grad/param norm = 1.4323e-01, time/batch = 15.3742s	
11054/28500 (epoch 19.393), train_loss = 0.93193079, grad/param norm = 1.6364e-01, time/batch = 15.0330s	
11055/28500 (epoch 19.395), train_loss = 1.18827217, grad/param norm = 1.6262e-01, time/batch = 15.1234s	
11056/28500 (epoch 19.396), train_loss = 1.11612295, grad/param norm = 1.6283e-01, time/batch = 15.2683s	
11057/28500 (epoch 19.398), train_loss = 0.84027231, grad/param norm = 1.7025e-01, time/batch = 15.6275s	
11058/28500 (epoch 19.400), train_loss = 1.03290943, grad/param norm = 1.6293e-01, time/batch = 15.5744s	
11059/28500 (epoch 19.402), train_loss = 1.08208521, grad/param norm = 1.7618e-01, time/batch = 15.3681s	
11060/28500 (epoch 19.404), train_loss = 1.12932304, grad/param norm = 1.7920e-01, time/batch = 15.4310s	
11061/28500 (epoch 19.405), train_loss = 1.13957311, grad/param norm = 1.5539e-01, time/batch = 15.5367s	
11062/28500 (epoch 19.407), train_loss = 1.06053895, grad/param norm = 1.5552e-01, time/batch = 15.1600s	
11063/28500 (epoch 19.409), train_loss = 1.06130067, grad/param norm = 1.6047e-01, time/batch = 15.1855s	
11064/28500 (epoch 19.411), train_loss = 1.16319228, grad/param norm = 1.7432e-01, time/batch = 15.1910s	
11065/28500 (epoch 19.412), train_loss = 1.16581391, grad/param norm = 1.7799e-01, time/batch = 15.2158s	
11066/28500 (epoch 19.414), train_loss = 1.07338172, grad/param norm = 1.6363e-01, time/batch = 15.0722s	
11067/28500 (epoch 19.416), train_loss = 0.96829037, grad/param norm = 1.5874e-01, time/batch = 15.2188s	
11068/28500 (epoch 19.418), train_loss = 1.05782968, grad/param norm = 1.4367e-01, time/batch = 15.2143s	
11069/28500 (epoch 19.419), train_loss = 1.17573013, grad/param norm = 1.7715e-01, time/batch = 15.4854s	
11070/28500 (epoch 19.421), train_loss = 1.13388687, grad/param norm = 1.6632e-01, time/batch = 15.4776s	
11071/28500 (epoch 19.423), train_loss = 1.13913597, grad/param norm = 1.8412e-01, time/batch = 15.7375s	
11072/28500 (epoch 19.425), train_loss = 1.10141281, grad/param norm = 1.7495e-01, time/batch = 15.4283s	
11073/28500 (epoch 19.426), train_loss = 1.05382580, grad/param norm = 1.7640e-01, time/batch = 15.3812s	
11074/28500 (epoch 19.428), train_loss = 1.24884734, grad/param norm = 1.6602e-01, time/batch = 15.3455s	
11075/28500 (epoch 19.430), train_loss = 1.18371748, grad/param norm = 1.5852e-01, time/batch = 15.2169s	
11076/28500 (epoch 19.432), train_loss = 1.11979319, grad/param norm = 1.7847e-01, time/batch = 15.3679s	
11077/28500 (epoch 19.433), train_loss = 1.12408259, grad/param norm = 1.7924e-01, time/batch = 15.2424s	
11078/28500 (epoch 19.435), train_loss = 1.07317851, grad/param norm = 1.7816e-01, time/batch = 15.3010s	
11079/28500 (epoch 19.437), train_loss = 0.97417329, grad/param norm = 1.5268e-01, time/batch = 15.6250s	
11080/28500 (epoch 19.439), train_loss = 1.01842275, grad/param norm = 1.4716e-01, time/batch = 15.5685s	
11081/28500 (epoch 19.440), train_loss = 1.27516341, grad/param norm = 1.7132e-01, time/batch = 15.6370s	
11082/28500 (epoch 19.442), train_loss = 1.00207422, grad/param norm = 1.6626e-01, time/batch = 15.4558s	
11083/28500 (epoch 19.444), train_loss = 0.89009468, grad/param norm = 1.3041e-01, time/batch = 15.5416s	
11084/28500 (epoch 19.446), train_loss = 0.88457930, grad/param norm = 1.3777e-01, time/batch = 15.4379s	
11085/28500 (epoch 19.447), train_loss = 0.89028127, grad/param norm = 1.3410e-01, time/batch = 15.4312s	
11086/28500 (epoch 19.449), train_loss = 1.00025484, grad/param norm = 1.4412e-01, time/batch = 15.3749s	
11087/28500 (epoch 19.451), train_loss = 1.03225923, grad/param norm = 1.5336e-01, time/batch = 15.5991s	
11088/28500 (epoch 19.453), train_loss = 1.01023234, grad/param norm = 1.5178e-01, time/batch = 15.3861s	
11089/28500 (epoch 19.454), train_loss = 1.01024888, grad/param norm = 1.4639e-01, time/batch = 15.3028s	
11090/28500 (epoch 19.456), train_loss = 1.12347612, grad/param norm = 1.6287e-01, time/batch = 15.5393s	
11091/28500 (epoch 19.458), train_loss = 1.02978746, grad/param norm = 1.5962e-01, time/batch = 15.6967s	
11092/28500 (epoch 19.460), train_loss = 1.09136470, grad/param norm = 1.7015e-01, time/batch = 15.5275s	
11093/28500 (epoch 19.461), train_loss = 1.00716562, grad/param norm = 1.9026e-01, time/batch = 15.3656s	
11094/28500 (epoch 19.463), train_loss = 0.91031004, grad/param norm = 1.2887e-01, time/batch = 15.5226s	
11095/28500 (epoch 19.465), train_loss = 0.89524750, grad/param norm = 1.7491e-01, time/batch = 15.6029s	
11096/28500 (epoch 19.467), train_loss = 1.03916860, grad/param norm = 1.4613e-01, time/batch = 15.1431s	
11097/28500 (epoch 19.468), train_loss = 0.94867971, grad/param norm = 1.3974e-01, time/batch = 15.1970s	
11098/28500 (epoch 19.470), train_loss = 0.97023460, grad/param norm = 1.6248e-01, time/batch = 15.3908s	
11099/28500 (epoch 19.472), train_loss = 0.99192021, grad/param norm = 1.5316e-01, time/batch = 15.1203s	
11100/28500 (epoch 19.474), train_loss = 1.21438035, grad/param norm = 1.7114e-01, time/batch = 14.9812s	
11101/28500 (epoch 19.475), train_loss = 0.94908361, grad/param norm = 1.4378e-01, time/batch = 15.3541s	
11102/28500 (epoch 19.477), train_loss = 1.01751683, grad/param norm = 1.6514e-01, time/batch = 15.2717s	
11103/28500 (epoch 19.479), train_loss = 1.08906559, grad/param norm = 1.5883e-01, time/batch = 15.3656s	
11104/28500 (epoch 19.481), train_loss = 1.04310966, grad/param norm = 1.7847e-01, time/batch = 15.2099s	
11105/28500 (epoch 19.482), train_loss = 0.94286980, grad/param norm = 1.5620e-01, time/batch = 15.3841s	
11106/28500 (epoch 19.484), train_loss = 0.93406484, grad/param norm = 1.5015e-01, time/batch = 15.5997s	
11107/28500 (epoch 19.486), train_loss = 0.85013189, grad/param norm = 1.5470e-01, time/batch = 15.4651s	
11108/28500 (epoch 19.488), train_loss = 1.06688328, grad/param norm = 1.4376e-01, time/batch = 14.9750s	
11109/28500 (epoch 19.489), train_loss = 1.13930956, grad/param norm = 1.5698e-01, time/batch = 15.0783s	
11110/28500 (epoch 19.491), train_loss = 0.98631144, grad/param norm = 1.5069e-01, time/batch = 15.2257s	
11111/28500 (epoch 19.493), train_loss = 1.00459888, grad/param norm = 1.4730e-01, time/batch = 15.3029s	
11112/28500 (epoch 19.495), train_loss = 1.00525456, grad/param norm = 1.4511e-01, time/batch = 15.1789s	
11113/28500 (epoch 19.496), train_loss = 0.96006002, grad/param norm = 1.7423e-01, time/batch = 15.1214s	
11114/28500 (epoch 19.498), train_loss = 1.05760759, grad/param norm = 1.4844e-01, time/batch = 15.4988s	
11115/28500 (epoch 19.500), train_loss = 0.99509957, grad/param norm = 1.4778e-01, time/batch = 15.5489s	
11116/28500 (epoch 19.502), train_loss = 1.10886425, grad/param norm = 1.5194e-01, time/batch = 15.2269s	
11117/28500 (epoch 19.504), train_loss = 1.05885667, grad/param norm = 1.5407e-01, time/batch = 15.3875s	
11118/28500 (epoch 19.505), train_loss = 0.95825673, grad/param norm = 1.4780e-01, time/batch = 15.1533s	
11119/28500 (epoch 19.507), train_loss = 1.15145100, grad/param norm = 1.7293e-01, time/batch = 15.2094s	
11120/28500 (epoch 19.509), train_loss = 1.03090057, grad/param norm = 1.5631e-01, time/batch = 15.2834s	
11121/28500 (epoch 19.511), train_loss = 1.02177653, grad/param norm = 1.4959e-01, time/batch = 15.4800s	
11122/28500 (epoch 19.512), train_loss = 1.05237271, grad/param norm = 1.5927e-01, time/batch = 15.4313s	
11123/28500 (epoch 19.514), train_loss = 0.96997546, grad/param norm = 1.5021e-01, time/batch = 15.2431s	
11124/28500 (epoch 19.516), train_loss = 0.99223130, grad/param norm = 1.3786e-01, time/batch = 15.2661s	
11125/28500 (epoch 19.518), train_loss = 1.06257387, grad/param norm = 1.4891e-01, time/batch = 15.1669s	
11126/28500 (epoch 19.519), train_loss = 1.11058111, grad/param norm = 1.6027e-01, time/batch = 15.2172s	
11127/28500 (epoch 19.521), train_loss = 1.18967827, grad/param norm = 1.8164e-01, time/batch = 15.3612s	
11128/28500 (epoch 19.523), train_loss = 1.10516521, grad/param norm = 1.7133e-01, time/batch = 15.2323s	
11129/28500 (epoch 19.525), train_loss = 1.13125695, grad/param norm = 1.6195e-01, time/batch = 15.2793s	
11130/28500 (epoch 19.526), train_loss = 1.10497990, grad/param norm = 1.5510e-01, time/batch = 15.2028s	
11131/28500 (epoch 19.528), train_loss = 1.12548748, grad/param norm = 1.6893e-01, time/batch = 15.5410s	
11132/28500 (epoch 19.530), train_loss = 1.13591594, grad/param norm = 1.5091e-01, time/batch = 15.3156s	
11133/28500 (epoch 19.532), train_loss = 0.99263471, grad/param norm = 1.4862e-01, time/batch = 15.5125s	
11134/28500 (epoch 19.533), train_loss = 1.12906691, grad/param norm = 1.6506e-01, time/batch = 15.2965s	
11135/28500 (epoch 19.535), train_loss = 0.88446491, grad/param norm = 1.4017e-01, time/batch = 15.0542s	
11136/28500 (epoch 19.537), train_loss = 0.91605065, grad/param norm = 1.4940e-01, time/batch = 15.2648s	
11137/28500 (epoch 19.539), train_loss = 0.89020215, grad/param norm = 1.5576e-01, time/batch = 15.2614s	
11138/28500 (epoch 19.540), train_loss = 1.06218202, grad/param norm = 1.7448e-01, time/batch = 15.4812s	
11139/28500 (epoch 19.542), train_loss = 1.10020830, grad/param norm = 1.6978e-01, time/batch = 15.3732s	
11140/28500 (epoch 19.544), train_loss = 1.19861120, grad/param norm = 1.6772e-01, time/batch = 15.3886s	
11141/28500 (epoch 19.546), train_loss = 1.03462089, grad/param norm = 1.6582e-01, time/batch = 15.4484s	
11142/28500 (epoch 19.547), train_loss = 1.03497602, grad/param norm = 1.4859e-01, time/batch = 15.3804s	
11143/28500 (epoch 19.549), train_loss = 0.87878387, grad/param norm = 1.2250e-01, time/batch = 15.2115s	
11144/28500 (epoch 19.551), train_loss = 1.05461914, grad/param norm = 1.8498e-01, time/batch = 15.5381s	
11145/28500 (epoch 19.553), train_loss = 1.25093961, grad/param norm = 1.9748e-01, time/batch = 15.4625s	
11146/28500 (epoch 19.554), train_loss = 1.03345632, grad/param norm = 1.5374e-01, time/batch = 15.4675s	
11147/28500 (epoch 19.556), train_loss = 1.08312414, grad/param norm = 1.6534e-01, time/batch = 15.4888s	
11148/28500 (epoch 19.558), train_loss = 1.07511751, grad/param norm = 1.5206e-01, time/batch = 15.6282s	
11149/28500 (epoch 19.560), train_loss = 1.09112136, grad/param norm = 1.7358e-01, time/batch = 15.6443s	
11150/28500 (epoch 19.561), train_loss = 1.12275836, grad/param norm = 1.6757e-01, time/batch = 15.6249s	
11151/28500 (epoch 19.563), train_loss = 1.22326536, grad/param norm = 1.7907e-01, time/batch = 15.5721s	
11152/28500 (epoch 19.565), train_loss = 1.03500115, grad/param norm = 1.6818e-01, time/batch = 15.3453s	
11153/28500 (epoch 19.567), train_loss = 0.92462805, grad/param norm = 1.4367e-01, time/batch = 15.3078s	
11154/28500 (epoch 19.568), train_loss = 1.08510897, grad/param norm = 1.6702e-01, time/batch = 15.4516s	
11155/28500 (epoch 19.570), train_loss = 1.01313215, grad/param norm = 1.4683e-01, time/batch = 15.5573s	
11156/28500 (epoch 19.572), train_loss = 1.01650042, grad/param norm = 1.5208e-01, time/batch = 15.5474s	
11157/28500 (epoch 19.574), train_loss = 1.02055127, grad/param norm = 1.6764e-01, time/batch = 15.4642s	
11158/28500 (epoch 19.575), train_loss = 1.01027243, grad/param norm = 1.6347e-01, time/batch = 15.1981s	
11159/28500 (epoch 19.577), train_loss = 1.07511744, grad/param norm = 1.6276e-01, time/batch = 15.5409s	
11160/28500 (epoch 19.579), train_loss = 1.13205242, grad/param norm = 1.7454e-01, time/batch = 15.2406s	
11161/28500 (epoch 19.581), train_loss = 0.97398626, grad/param norm = 1.5386e-01, time/batch = 15.6243s	
11162/28500 (epoch 19.582), train_loss = 1.11583683, grad/param norm = 1.4518e-01, time/batch = 15.1998s	
11163/28500 (epoch 19.584), train_loss = 0.99226538, grad/param norm = 1.6020e-01, time/batch = 15.1405s	
11164/28500 (epoch 19.586), train_loss = 0.95862603, grad/param norm = 1.3926e-01, time/batch = 15.3288s	
11165/28500 (epoch 19.588), train_loss = 0.95217195, grad/param norm = 1.4272e-01, time/batch = 15.1628s	
11166/28500 (epoch 19.589), train_loss = 1.07415096, grad/param norm = 1.5524e-01, time/batch = 15.0746s	
11167/28500 (epoch 19.591), train_loss = 1.04664957, grad/param norm = 1.5134e-01, time/batch = 15.3079s	
11168/28500 (epoch 19.593), train_loss = 0.99882833, grad/param norm = 1.4912e-01, time/batch = 15.4557s	
11169/28500 (epoch 19.595), train_loss = 1.23155319, grad/param norm = 1.7788e-01, time/batch = 15.0536s	
11170/28500 (epoch 19.596), train_loss = 1.25918629, grad/param norm = 1.7534e-01, time/batch = 15.3095s	
11171/28500 (epoch 19.598), train_loss = 1.06684120, grad/param norm = 1.7464e-01, time/batch = 15.6185s	
11172/28500 (epoch 19.600), train_loss = 1.04924969, grad/param norm = 1.6072e-01, time/batch = 15.6240s	
11173/28500 (epoch 19.602), train_loss = 1.14444027, grad/param norm = 1.6830e-01, time/batch = 15.3749s	
11174/28500 (epoch 19.604), train_loss = 1.13846693, grad/param norm = 1.6113e-01, time/batch = 15.3021s	
11175/28500 (epoch 19.605), train_loss = 1.08804530, grad/param norm = 1.7011e-01, time/batch = 15.2028s	
11176/28500 (epoch 19.607), train_loss = 1.15522423, grad/param norm = 1.4813e-01, time/batch = 15.3664s	
11177/28500 (epoch 19.609), train_loss = 1.04958467, grad/param norm = 1.5542e-01, time/batch = 15.5420s	
11178/28500 (epoch 19.611), train_loss = 1.02878476, grad/param norm = 1.6087e-01, time/batch = 15.5755s	
11179/28500 (epoch 19.612), train_loss = 1.09406404, grad/param norm = 1.6916e-01, time/batch = 15.6186s	
11180/28500 (epoch 19.614), train_loss = 1.08462926, grad/param norm = 1.5608e-01, time/batch = 15.4520s	
11181/28500 (epoch 19.616), train_loss = 0.98344526, grad/param norm = 1.8063e-01, time/batch = 15.4477s	
11182/28500 (epoch 19.618), train_loss = 1.02564261, grad/param norm = 1.6338e-01, time/batch = 15.3981s	
11183/28500 (epoch 19.619), train_loss = 1.22921576, grad/param norm = 1.8308e-01, time/batch = 15.4294s	
11184/28500 (epoch 19.621), train_loss = 0.86418583, grad/param norm = 1.4776e-01, time/batch = 15.2959s	
11185/28500 (epoch 19.623), train_loss = 1.17058962, grad/param norm = 1.7150e-01, time/batch = 15.1376s	
11186/28500 (epoch 19.625), train_loss = 0.93791981, grad/param norm = 1.5591e-01, time/batch = 15.3614s	
11187/28500 (epoch 19.626), train_loss = 0.81685295, grad/param norm = 1.3070e-01, time/batch = 10.8831s	
11188/28500 (epoch 19.628), train_loss = 0.97887161, grad/param norm = 1.4964e-01, time/batch = 0.6922s	
11189/28500 (epoch 19.630), train_loss = 0.90302889, grad/param norm = 1.3769e-01, time/batch = 0.6814s	
11190/28500 (epoch 19.632), train_loss = 1.13516512, grad/param norm = 1.6041e-01, time/batch = 0.6838s	
11191/28500 (epoch 19.633), train_loss = 1.19266839, grad/param norm = 1.5268e-01, time/batch = 0.6839s	
11192/28500 (epoch 19.635), train_loss = 1.15412111, grad/param norm = 1.7141e-01, time/batch = 0.6859s	
11193/28500 (epoch 19.637), train_loss = 1.08040091, grad/param norm = 1.5494e-01, time/batch = 0.6839s	
11194/28500 (epoch 19.639), train_loss = 0.94299009, grad/param norm = 1.5314e-01, time/batch = 0.6850s	
11195/28500 (epoch 19.640), train_loss = 0.97908953, grad/param norm = 1.5377e-01, time/batch = 0.6890s	
11196/28500 (epoch 19.642), train_loss = 1.00068334, grad/param norm = 1.4615e-01, time/batch = 0.6935s	
11197/28500 (epoch 19.644), train_loss = 1.10880420, grad/param norm = 1.4130e-01, time/batch = 0.6897s	
11198/28500 (epoch 19.646), train_loss = 0.92914458, grad/param norm = 1.4214e-01, time/batch = 0.6938s	
11199/28500 (epoch 19.647), train_loss = 0.95436369, grad/param norm = 1.5265e-01, time/batch = 0.6961s	
11200/28500 (epoch 19.649), train_loss = 0.92298756, grad/param norm = 1.4202e-01, time/batch = 0.6963s	
11201/28500 (epoch 19.651), train_loss = 0.90411591, grad/param norm = 1.4083e-01, time/batch = 0.7020s	
11202/28500 (epoch 19.653), train_loss = 0.92496001, grad/param norm = 1.5731e-01, time/batch = 0.6913s	
11203/28500 (epoch 19.654), train_loss = 1.01663881, grad/param norm = 1.5660e-01, time/batch = 0.6971s	
11204/28500 (epoch 19.656), train_loss = 0.95634630, grad/param norm = 1.6283e-01, time/batch = 0.6853s	
11205/28500 (epoch 19.658), train_loss = 1.03623886, grad/param norm = 1.6342e-01, time/batch = 0.6945s	
11206/28500 (epoch 19.660), train_loss = 1.02757218, grad/param norm = 1.4901e-01, time/batch = 0.6928s	
11207/28500 (epoch 19.661), train_loss = 1.19477512, grad/param norm = 1.8351e-01, time/batch = 0.6873s	
11208/28500 (epoch 19.663), train_loss = 1.19135008, grad/param norm = 1.7095e-01, time/batch = 0.6928s	
11209/28500 (epoch 19.665), train_loss = 1.02222411, grad/param norm = 1.5415e-01, time/batch = 0.6897s	
11210/28500 (epoch 19.667), train_loss = 1.03974170, grad/param norm = 1.6267e-01, time/batch = 0.6939s	
11211/28500 (epoch 19.668), train_loss = 1.03471941, grad/param norm = 1.6134e-01, time/batch = 0.6895s	
11212/28500 (epoch 19.670), train_loss = 1.05292665, grad/param norm = 1.6574e-01, time/batch = 0.6935s	
11213/28500 (epoch 19.672), train_loss = 0.99467564, grad/param norm = 1.7099e-01, time/batch = 0.6864s	
11214/28500 (epoch 19.674), train_loss = 0.87225448, grad/param norm = 1.6571e-01, time/batch = 0.6986s	
11215/28500 (epoch 19.675), train_loss = 0.91464739, grad/param norm = 1.4874e-01, time/batch = 0.6869s	
11216/28500 (epoch 19.677), train_loss = 1.02272192, grad/param norm = 1.5922e-01, time/batch = 0.6836s	
11217/28500 (epoch 19.679), train_loss = 0.98701821, grad/param norm = 1.6606e-01, time/batch = 0.6815s	
11218/28500 (epoch 19.681), train_loss = 1.08513914, grad/param norm = 1.5318e-01, time/batch = 0.6813s	
11219/28500 (epoch 19.682), train_loss = 0.98880133, grad/param norm = 1.4595e-01, time/batch = 0.6807s	
11220/28500 (epoch 19.684), train_loss = 1.08698496, grad/param norm = 1.7614e-01, time/batch = 0.6826s	
11221/28500 (epoch 19.686), train_loss = 0.97230370, grad/param norm = 1.6593e-01, time/batch = 0.6904s	
11222/28500 (epoch 19.688), train_loss = 0.93039903, grad/param norm = 1.3260e-01, time/batch = 0.6838s	
11223/28500 (epoch 19.689), train_loss = 1.00403160, grad/param norm = 1.5559e-01, time/batch = 0.6816s	
11224/28500 (epoch 19.691), train_loss = 1.08872752, grad/param norm = 1.8698e-01, time/batch = 0.6803s	
11225/28500 (epoch 19.693), train_loss = 0.99534052, grad/param norm = 1.6918e-01, time/batch = 0.6914s	
11226/28500 (epoch 19.695), train_loss = 0.80826171, grad/param norm = 1.6702e-01, time/batch = 0.6850s	
11227/28500 (epoch 19.696), train_loss = 1.02600207, grad/param norm = 1.6267e-01, time/batch = 0.6831s	
11228/28500 (epoch 19.698), train_loss = 1.00804646, grad/param norm = 1.5112e-01, time/batch = 0.6845s	
11229/28500 (epoch 19.700), train_loss = 1.04388018, grad/param norm = 1.5873e-01, time/batch = 0.6814s	
11230/28500 (epoch 19.702), train_loss = 1.09389217, grad/param norm = 1.7356e-01, time/batch = 0.6806s	
11231/28500 (epoch 19.704), train_loss = 1.07119375, grad/param norm = 1.5711e-01, time/batch = 0.6902s	
11232/28500 (epoch 19.705), train_loss = 1.13742293, grad/param norm = 1.7500e-01, time/batch = 0.6822s	
11233/28500 (epoch 19.707), train_loss = 0.97924197, grad/param norm = 1.7337e-01, time/batch = 0.6821s	
11234/28500 (epoch 19.709), train_loss = 1.17570384, grad/param norm = 1.7073e-01, time/batch = 0.6821s	
11235/28500 (epoch 19.711), train_loss = 0.94865721, grad/param norm = 1.6019e-01, time/batch = 0.6876s	
11236/28500 (epoch 19.712), train_loss = 1.08180204, grad/param norm = 1.5338e-01, time/batch = 0.6828s	
11237/28500 (epoch 19.714), train_loss = 1.16016727, grad/param norm = 1.5631e-01, time/batch = 0.6861s	
11238/28500 (epoch 19.716), train_loss = 1.02082469, grad/param norm = 1.6915e-01, time/batch = 0.6815s	
11239/28500 (epoch 19.718), train_loss = 1.03886000, grad/param norm = 1.5819e-01, time/batch = 0.6809s	
11240/28500 (epoch 19.719), train_loss = 1.05940354, grad/param norm = 1.5670e-01, time/batch = 0.6823s	
11241/28500 (epoch 19.721), train_loss = 0.84959595, grad/param norm = 1.4530e-01, time/batch = 0.6836s	
11242/28500 (epoch 19.723), train_loss = 1.04116441, grad/param norm = 1.7248e-01, time/batch = 0.6821s	
11243/28500 (epoch 19.725), train_loss = 1.11642598, grad/param norm = 1.4517e-01, time/batch = 0.6811s	
11244/28500 (epoch 19.726), train_loss = 1.04027030, grad/param norm = 1.6249e-01, time/batch = 0.6840s	
11245/28500 (epoch 19.728), train_loss = 0.92828870, grad/param norm = 1.3933e-01, time/batch = 0.6825s	
11246/28500 (epoch 19.730), train_loss = 1.04163663, grad/param norm = 1.8223e-01, time/batch = 0.6857s	
11247/28500 (epoch 19.732), train_loss = 0.85604132, grad/param norm = 1.3421e-01, time/batch = 0.6804s	
11248/28500 (epoch 19.733), train_loss = 0.86691580, grad/param norm = 1.3697e-01, time/batch = 0.6846s	
11249/28500 (epoch 19.735), train_loss = 0.89295008, grad/param norm = 1.4264e-01, time/batch = 0.6802s	
11250/28500 (epoch 19.737), train_loss = 0.81350462, grad/param norm = 1.3239e-01, time/batch = 0.6833s	
11251/28500 (epoch 19.739), train_loss = 0.96766946, grad/param norm = 1.6129e-01, time/batch = 0.6822s	
11252/28500 (epoch 19.740), train_loss = 1.03132612, grad/param norm = 1.6844e-01, time/batch = 0.6850s	
11253/28500 (epoch 19.742), train_loss = 0.94913167, grad/param norm = 1.4145e-01, time/batch = 0.6803s	
11254/28500 (epoch 19.744), train_loss = 1.05945485, grad/param norm = 1.7064e-01, time/batch = 0.6831s	
11255/28500 (epoch 19.746), train_loss = 0.93668644, grad/param norm = 1.4950e-01, time/batch = 0.6810s	
11256/28500 (epoch 19.747), train_loss = 0.93397398, grad/param norm = 1.4526e-01, time/batch = 0.6834s	
11257/28500 (epoch 19.749), train_loss = 1.13857364, grad/param norm = 1.8856e-01, time/batch = 0.6819s	
11258/28500 (epoch 19.751), train_loss = 0.93579180, grad/param norm = 2.0685e-01, time/batch = 0.6826s	
11259/28500 (epoch 19.753), train_loss = 0.98001844, grad/param norm = 1.4470e-01, time/batch = 0.6819s	
11260/28500 (epoch 19.754), train_loss = 0.89963476, grad/param norm = 1.4301e-01, time/batch = 0.6815s	
11261/28500 (epoch 19.756), train_loss = 1.13191340, grad/param norm = 1.6303e-01, time/batch = 0.6845s	
11262/28500 (epoch 19.758), train_loss = 1.11591969, grad/param norm = 1.7616e-01, time/batch = 0.6849s	
11263/28500 (epoch 19.760), train_loss = 0.90616446, grad/param norm = 1.5776e-01, time/batch = 0.6854s	
11264/28500 (epoch 19.761), train_loss = 0.94350335, grad/param norm = 1.8415e-01, time/batch = 0.6930s	
11265/28500 (epoch 19.763), train_loss = 0.83533354, grad/param norm = 1.4694e-01, time/batch = 0.6834s	
11266/28500 (epoch 19.765), train_loss = 0.98854932, grad/param norm = 1.5608e-01, time/batch = 0.6833s	
11267/28500 (epoch 19.767), train_loss = 0.86713265, grad/param norm = 1.4339e-01, time/batch = 0.6906s	
11268/28500 (epoch 19.768), train_loss = 1.09394816, grad/param norm = 1.6879e-01, time/batch = 0.6902s	
11269/28500 (epoch 19.770), train_loss = 0.88761389, grad/param norm = 1.4162e-01, time/batch = 0.7011s	
11270/28500 (epoch 19.772), train_loss = 0.77725336, grad/param norm = 1.3752e-01, time/batch = 0.6963s	
11271/28500 (epoch 19.774), train_loss = 1.03901932, grad/param norm = 1.8023e-01, time/batch = 0.7098s	
11272/28500 (epoch 19.775), train_loss = 1.09443495, grad/param norm = 1.4930e-01, time/batch = 0.6974s	
11273/28500 (epoch 19.777), train_loss = 1.07993680, grad/param norm = 1.5303e-01, time/batch = 0.6879s	
11274/28500 (epoch 19.779), train_loss = 0.85299279, grad/param norm = 1.3927e-01, time/batch = 0.6853s	
11275/28500 (epoch 19.781), train_loss = 1.00452911, grad/param norm = 1.6651e-01, time/batch = 0.6930s	
11276/28500 (epoch 19.782), train_loss = 1.08044705, grad/param norm = 1.6752e-01, time/batch = 0.6898s	
11277/28500 (epoch 19.784), train_loss = 0.84344769, grad/param norm = 1.4027e-01, time/batch = 0.6936s	
11278/28500 (epoch 19.786), train_loss = 0.91248843, grad/param norm = 1.5489e-01, time/batch = 0.6976s	
11279/28500 (epoch 19.788), train_loss = 0.99699584, grad/param norm = 1.6632e-01, time/batch = 0.6899s	
11280/28500 (epoch 19.789), train_loss = 0.76042107, grad/param norm = 1.6362e-01, time/batch = 0.6840s	
11281/28500 (epoch 19.791), train_loss = 1.03369473, grad/param norm = 1.5870e-01, time/batch = 0.6878s	
11282/28500 (epoch 19.793), train_loss = 1.00138483, grad/param norm = 1.7469e-01, time/batch = 0.6802s	
11283/28500 (epoch 19.795), train_loss = 1.03678434, grad/param norm = 1.5185e-01, time/batch = 0.6847s	
11284/28500 (epoch 19.796), train_loss = 0.90651709, grad/param norm = 1.5967e-01, time/batch = 0.6892s	
11285/28500 (epoch 19.798), train_loss = 0.85462136, grad/param norm = 1.4472e-01, time/batch = 0.6809s	
11286/28500 (epoch 19.800), train_loss = 0.88928974, grad/param norm = 1.5347e-01, time/batch = 0.6777s	
11287/28500 (epoch 19.802), train_loss = 0.99352965, grad/param norm = 1.7013e-01, time/batch = 0.6778s	
11288/28500 (epoch 19.804), train_loss = 1.03013810, grad/param norm = 1.5226e-01, time/batch = 0.6783s	
11289/28500 (epoch 19.805), train_loss = 1.01190354, grad/param norm = 1.6399e-01, time/batch = 0.6841s	
11290/28500 (epoch 19.807), train_loss = 1.04360874, grad/param norm = 1.6455e-01, time/batch = 0.6797s	
11291/28500 (epoch 19.809), train_loss = 0.96167457, grad/param norm = 1.4510e-01, time/batch = 0.6823s	
11292/28500 (epoch 19.811), train_loss = 1.05599520, grad/param norm = 1.6144e-01, time/batch = 0.6792s	
11293/28500 (epoch 19.812), train_loss = 1.03540071, grad/param norm = 1.6319e-01, time/batch = 0.6879s	
11294/28500 (epoch 19.814), train_loss = 0.97434392, grad/param norm = 1.4875e-01, time/batch = 0.6779s	
11295/28500 (epoch 19.816), train_loss = 1.10181479, grad/param norm = 1.8397e-01, time/batch = 0.6825s	
11296/28500 (epoch 19.818), train_loss = 1.10793166, grad/param norm = 1.6926e-01, time/batch = 0.6836s	
11297/28500 (epoch 19.819), train_loss = 1.00628532, grad/param norm = 1.4417e-01, time/batch = 0.6817s	
11298/28500 (epoch 19.821), train_loss = 0.98016355, grad/param norm = 1.5380e-01, time/batch = 0.6825s	
11299/28500 (epoch 19.823), train_loss = 1.16759193, grad/param norm = 1.7664e-01, time/batch = 0.6791s	
11300/28500 (epoch 19.825), train_loss = 0.97741397, grad/param norm = 1.6965e-01, time/batch = 0.6786s	
11301/28500 (epoch 19.826), train_loss = 1.00690704, grad/param norm = 1.5824e-01, time/batch = 0.6827s	
11302/28500 (epoch 19.828), train_loss = 0.89171429, grad/param norm = 1.8159e-01, time/batch = 0.6780s	
11303/28500 (epoch 19.830), train_loss = 0.96755265, grad/param norm = 1.5297e-01, time/batch = 0.6781s	
11304/28500 (epoch 19.832), train_loss = 1.01391069, grad/param norm = 1.8145e-01, time/batch = 0.6824s	
11305/28500 (epoch 19.833), train_loss = 1.11676137, grad/param norm = 1.5882e-01, time/batch = 0.6792s	
11306/28500 (epoch 19.835), train_loss = 0.94414888, grad/param norm = 1.6096e-01, time/batch = 0.6805s	
11307/28500 (epoch 19.837), train_loss = 0.87005470, grad/param norm = 1.4990e-01, time/batch = 0.6789s	
11308/28500 (epoch 19.839), train_loss = 1.14159914, grad/param norm = 1.8412e-01, time/batch = 0.6805s	
11309/28500 (epoch 19.840), train_loss = 1.17526399, grad/param norm = 1.7747e-01, time/batch = 0.6773s	
11310/28500 (epoch 19.842), train_loss = 1.11630427, grad/param norm = 1.7562e-01, time/batch = 0.6773s	
11311/28500 (epoch 19.844), train_loss = 1.05627811, grad/param norm = 1.7492e-01, time/batch = 0.6808s	
11312/28500 (epoch 19.846), train_loss = 1.17324746, grad/param norm = 1.9683e-01, time/batch = 0.6785s	
11313/28500 (epoch 19.847), train_loss = 0.97357433, grad/param norm = 1.7557e-01, time/batch = 0.6878s	
11314/28500 (epoch 19.849), train_loss = 0.97378628, grad/param norm = 1.6683e-01, time/batch = 0.6804s	
11315/28500 (epoch 19.851), train_loss = 0.84006876, grad/param norm = 1.3742e-01, time/batch = 0.6822s	
11316/28500 (epoch 19.853), train_loss = 1.03031252, grad/param norm = 1.7425e-01, time/batch = 0.6784s	
11317/28500 (epoch 19.854), train_loss = 1.04723488, grad/param norm = 1.6151e-01, time/batch = 0.6817s	
11318/28500 (epoch 19.856), train_loss = 1.15237507, grad/param norm = 1.8732e-01, time/batch = 0.6860s	
11319/28500 (epoch 19.858), train_loss = 0.92578598, grad/param norm = 1.5350e-01, time/batch = 0.6799s	
11320/28500 (epoch 19.860), train_loss = 1.00410202, grad/param norm = 1.7176e-01, time/batch = 0.6779s	
11321/28500 (epoch 19.861), train_loss = 1.05955320, grad/param norm = 1.7318e-01, time/batch = 0.6815s	
11322/28500 (epoch 19.863), train_loss = 1.10393963, grad/param norm = 1.9431e-01, time/batch = 0.6792s	
11323/28500 (epoch 19.865), train_loss = 0.98229814, grad/param norm = 1.5479e-01, time/batch = 0.6794s	
11324/28500 (epoch 19.867), train_loss = 1.08773247, grad/param norm = 1.8007e-01, time/batch = 0.6802s	
11325/28500 (epoch 19.868), train_loss = 0.90146140, grad/param norm = 1.5271e-01, time/batch = 0.6829s	
11326/28500 (epoch 19.870), train_loss = 0.87202078, grad/param norm = 1.3982e-01, time/batch = 0.6840s	
11327/28500 (epoch 19.872), train_loss = 1.06288122, grad/param norm = 1.8327e-01, time/batch = 0.6802s	
11328/28500 (epoch 19.874), train_loss = 0.96931206, grad/param norm = 1.5856e-01, time/batch = 0.6776s	
11329/28500 (epoch 19.875), train_loss = 1.13501788, grad/param norm = 1.9467e-01, time/batch = 0.6825s	
11330/28500 (epoch 19.877), train_loss = 1.05318088, grad/param norm = 1.6300e-01, time/batch = 0.6805s	
11331/28500 (epoch 19.879), train_loss = 1.06106515, grad/param norm = 1.4780e-01, time/batch = 0.6827s	
11332/28500 (epoch 19.881), train_loss = 1.04635748, grad/param norm = 1.6740e-01, time/batch = 0.6821s	
11333/28500 (epoch 19.882), train_loss = 0.95612486, grad/param norm = 1.5226e-01, time/batch = 0.6791s	
11334/28500 (epoch 19.884), train_loss = 1.02558709, grad/param norm = 1.6712e-01, time/batch = 0.6807s	
11335/28500 (epoch 19.886), train_loss = 0.99171119, grad/param norm = 1.5313e-01, time/batch = 0.6822s	
11336/28500 (epoch 19.888), train_loss = 0.91754016, grad/param norm = 1.5170e-01, time/batch = 0.6780s	
11337/28500 (epoch 19.889), train_loss = 1.02650307, grad/param norm = 1.7070e-01, time/batch = 0.6801s	
11338/28500 (epoch 19.891), train_loss = 0.99869233, grad/param norm = 1.4757e-01, time/batch = 0.6801s	
11339/28500 (epoch 19.893), train_loss = 0.96762873, grad/param norm = 1.6989e-01, time/batch = 0.6789s	
11340/28500 (epoch 19.895), train_loss = 1.20961429, grad/param norm = 1.8621e-01, time/batch = 0.6806s	
11341/28500 (epoch 19.896), train_loss = 1.13859430, grad/param norm = 1.8742e-01, time/batch = 0.6839s	
11342/28500 (epoch 19.898), train_loss = 1.03576527, grad/param norm = 1.6683e-01, time/batch = 0.6847s	
11343/28500 (epoch 19.900), train_loss = 0.87549141, grad/param norm = 1.5239e-01, time/batch = 0.6773s	
11344/28500 (epoch 19.902), train_loss = 0.90442583, grad/param norm = 1.5887e-01, time/batch = 0.6819s	
11345/28500 (epoch 19.904), train_loss = 0.91253967, grad/param norm = 1.4270e-01, time/batch = 0.6835s	
11346/28500 (epoch 19.905), train_loss = 1.00518934, grad/param norm = 1.5523e-01, time/batch = 0.6812s	
11347/28500 (epoch 19.907), train_loss = 0.99342334, grad/param norm = 1.7234e-01, time/batch = 0.6821s	
11348/28500 (epoch 19.909), train_loss = 0.90933559, grad/param norm = 1.6966e-01, time/batch = 0.6830s	
11349/28500 (epoch 19.911), train_loss = 0.92962293, grad/param norm = 1.4279e-01, time/batch = 0.6812s	
11350/28500 (epoch 19.912), train_loss = 0.81273071, grad/param norm = 1.3827e-01, time/batch = 0.6843s	
11351/28500 (epoch 19.914), train_loss = 1.09179352, grad/param norm = 1.5168e-01, time/batch = 0.6833s	
11352/28500 (epoch 19.916), train_loss = 1.01776951, grad/param norm = 1.7016e-01, time/batch = 0.6868s	
11353/28500 (epoch 19.918), train_loss = 1.02178770, grad/param norm = 1.7938e-01, time/batch = 0.6821s	
11354/28500 (epoch 19.919), train_loss = 1.00269736, grad/param norm = 1.4983e-01, time/batch = 0.6856s	
11355/28500 (epoch 19.921), train_loss = 1.11782784, grad/param norm = 2.3909e-01, time/batch = 0.6846s	
11356/28500 (epoch 19.923), train_loss = 1.01197415, grad/param norm = 1.9515e-01, time/batch = 0.6886s	
11357/28500 (epoch 19.925), train_loss = 0.96794685, grad/param norm = 1.8105e-01, time/batch = 0.6975s	
11358/28500 (epoch 19.926), train_loss = 1.00964948, grad/param norm = 1.5755e-01, time/batch = 0.6810s	
11359/28500 (epoch 19.928), train_loss = 0.97117895, grad/param norm = 1.5162e-01, time/batch = 0.6777s	
11360/28500 (epoch 19.930), train_loss = 0.80440292, grad/param norm = 1.3570e-01, time/batch = 0.6778s	
11361/28500 (epoch 19.932), train_loss = 0.79640297, grad/param norm = 1.2100e-01, time/batch = 0.6825s	
11362/28500 (epoch 19.933), train_loss = 1.07616292, grad/param norm = 1.5908e-01, time/batch = 0.6956s	
11363/28500 (epoch 19.935), train_loss = 1.09739901, grad/param norm = 1.6395e-01, time/batch = 0.6864s	
11364/28500 (epoch 19.937), train_loss = 1.12983882, grad/param norm = 1.9482e-01, time/batch = 0.6813s	
11365/28500 (epoch 19.939), train_loss = 1.19384373, grad/param norm = 1.8920e-01, time/batch = 0.6802s	
11366/28500 (epoch 19.940), train_loss = 0.90515182, grad/param norm = 1.5779e-01, time/batch = 0.6817s	
11367/28500 (epoch 19.942), train_loss = 1.03475581, grad/param norm = 1.6057e-01, time/batch = 0.6779s	
11368/28500 (epoch 19.944), train_loss = 0.96273483, grad/param norm = 1.6623e-01, time/batch = 0.6791s	
11369/28500 (epoch 19.946), train_loss = 1.10764043, grad/param norm = 1.7376e-01, time/batch = 0.6790s	
11370/28500 (epoch 19.947), train_loss = 1.30850589, grad/param norm = 2.0937e-01, time/batch = 0.6819s	
11371/28500 (epoch 19.949), train_loss = 0.97047216, grad/param norm = 1.7387e-01, time/batch = 0.6821s	
11372/28500 (epoch 19.951), train_loss = 1.20684257, grad/param norm = 2.0523e-01, time/batch = 0.6855s	
11373/28500 (epoch 19.953), train_loss = 1.18711723, grad/param norm = 2.1034e-01, time/batch = 0.6776s	
11374/28500 (epoch 19.954), train_loss = 1.15091015, grad/param norm = 2.0431e-01, time/batch = 0.6797s	
11375/28500 (epoch 19.956), train_loss = 1.08481423, grad/param norm = 2.3315e-01, time/batch = 0.6794s	
11376/28500 (epoch 19.958), train_loss = 1.21393132, grad/param norm = 1.6152e-01, time/batch = 0.6809s	
11377/28500 (epoch 19.960), train_loss = 0.92938198, grad/param norm = 1.5503e-01, time/batch = 0.6771s	
11378/28500 (epoch 19.961), train_loss = 1.22941956, grad/param norm = 1.8949e-01, time/batch = 0.6793s	
11379/28500 (epoch 19.963), train_loss = 1.13876569, grad/param norm = 1.6966e-01, time/batch = 0.6777s	
11380/28500 (epoch 19.965), train_loss = 0.95270607, grad/param norm = 1.7576e-01, time/batch = 0.6792s	
11381/28500 (epoch 19.967), train_loss = 0.91194191, grad/param norm = 1.4481e-01, time/batch = 0.6790s	
11382/28500 (epoch 19.968), train_loss = 0.89104558, grad/param norm = 1.3582e-01, time/batch = 0.6796s	
11383/28500 (epoch 19.970), train_loss = 0.94787981, grad/param norm = 1.6151e-01, time/batch = 0.6776s	
11384/28500 (epoch 19.972), train_loss = 1.03250146, grad/param norm = 1.6277e-01, time/batch = 0.6789s	
11385/28500 (epoch 19.974), train_loss = 1.21194507, grad/param norm = 1.8174e-01, time/batch = 0.6773s	
11386/28500 (epoch 19.975), train_loss = 0.96231006, grad/param norm = 1.7085e-01, time/batch = 0.6803s	
11387/28500 (epoch 19.977), train_loss = 1.15388702, grad/param norm = 1.8545e-01, time/batch = 0.6804s	
11388/28500 (epoch 19.979), train_loss = 0.99212827, grad/param norm = 1.6735e-01, time/batch = 0.6779s	
11389/28500 (epoch 19.981), train_loss = 0.93450182, grad/param norm = 1.6517e-01, time/batch = 0.6794s	
11390/28500 (epoch 19.982), train_loss = 1.00980864, grad/param norm = 1.5346e-01, time/batch = 0.6784s	
11391/28500 (epoch 19.984), train_loss = 1.10287804, grad/param norm = 1.6796e-01, time/batch = 0.6820s	
11392/28500 (epoch 19.986), train_loss = 1.25386437, grad/param norm = 1.8171e-01, time/batch = 0.6823s	
11393/28500 (epoch 19.988), train_loss = 0.87720997, grad/param norm = 1.4874e-01, time/batch = 0.6784s	
11394/28500 (epoch 19.989), train_loss = 1.06810997, grad/param norm = 1.6420e-01, time/batch = 0.6806s	
11395/28500 (epoch 19.991), train_loss = 0.94295745, grad/param norm = 1.6986e-01, time/batch = 0.6803s	
11396/28500 (epoch 19.993), train_loss = 0.96601239, grad/param norm = 1.6747e-01, time/batch = 0.6917s	
11397/28500 (epoch 19.995), train_loss = 0.95304476, grad/param norm = 1.5425e-01, time/batch = 0.6854s	
11398/28500 (epoch 19.996), train_loss = 0.91396400, grad/param norm = 1.5322e-01, time/batch = 0.6843s	
11399/28500 (epoch 19.998), train_loss = 1.13384012, grad/param norm = 2.1322e-01, time/batch = 0.6845s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
11400/28500 (epoch 20.000), train_loss = 0.98910661, grad/param norm = 1.5096e-01, time/batch = 0.6832s	
11401/28500 (epoch 20.002), train_loss = 1.16459019, grad/param norm = 1.7973e-01, time/batch = 0.6862s	
11402/28500 (epoch 20.004), train_loss = 0.98059793, grad/param norm = 1.5253e-01, time/batch = 0.6835s	
11403/28500 (epoch 20.005), train_loss = 1.15190112, grad/param norm = 1.7539e-01, time/batch = 0.6778s	
11404/28500 (epoch 20.007), train_loss = 0.90919893, grad/param norm = 1.3833e-01, time/batch = 0.6774s	
11405/28500 (epoch 20.009), train_loss = 1.08760825, grad/param norm = 1.9186e-01, time/batch = 0.6792s	
11406/28500 (epoch 20.011), train_loss = 0.94167402, grad/param norm = 1.6986e-01, time/batch = 0.6779s	
11407/28500 (epoch 20.012), train_loss = 0.90343977, grad/param norm = 1.4302e-01, time/batch = 0.6804s	
11408/28500 (epoch 20.014), train_loss = 0.92551058, grad/param norm = 1.5405e-01, time/batch = 0.6780s	
11409/28500 (epoch 20.016), train_loss = 0.97031913, grad/param norm = 1.4119e-01, time/batch = 0.6793s	
11410/28500 (epoch 20.018), train_loss = 1.02948664, grad/param norm = 1.6387e-01, time/batch = 0.6776s	
11411/28500 (epoch 20.019), train_loss = 1.08288327, grad/param norm = 1.6197e-01, time/batch = 0.6834s	
11412/28500 (epoch 20.021), train_loss = 1.09541236, grad/param norm = 1.4904e-01, time/batch = 0.6779s	
11413/28500 (epoch 20.023), train_loss = 1.00458646, grad/param norm = 1.6717e-01, time/batch = 0.6786s	
11414/28500 (epoch 20.025), train_loss = 1.05023485, grad/param norm = 1.5843e-01, time/batch = 0.6777s	
11415/28500 (epoch 20.026), train_loss = 1.00342347, grad/param norm = 1.5155e-01, time/batch = 0.8963s	
11416/28500 (epoch 20.028), train_loss = 1.07623566, grad/param norm = 1.9590e-01, time/batch = 0.9837s	
11417/28500 (epoch 20.030), train_loss = 1.08611728, grad/param norm = 1.8336e-01, time/batch = 1.0006s	
11418/28500 (epoch 20.032), train_loss = 1.09645016, grad/param norm = 1.6824e-01, time/batch = 1.0226s	
11419/28500 (epoch 20.033), train_loss = 1.19959106, grad/param norm = 1.9232e-01, time/batch = 1.0124s	
11420/28500 (epoch 20.035), train_loss = 1.04103024, grad/param norm = 1.7722e-01, time/batch = 1.0078s	
11421/28500 (epoch 20.037), train_loss = 1.10092696, grad/param norm = 1.5432e-01, time/batch = 1.0150s	
11422/28500 (epoch 20.039), train_loss = 1.14007446, grad/param norm = 1.7706e-01, time/batch = 1.0196s	
11423/28500 (epoch 20.040), train_loss = 1.15233036, grad/param norm = 1.5382e-01, time/batch = 1.0163s	
11424/28500 (epoch 20.042), train_loss = 1.09974934, grad/param norm = 1.6429e-01, time/batch = 1.0255s	
11425/28500 (epoch 20.044), train_loss = 1.03789108, grad/param norm = 1.7522e-01, time/batch = 1.0142s	
11426/28500 (epoch 20.046), train_loss = 1.26133947, grad/param norm = 1.8014e-01, time/batch = 1.7970s	
11427/28500 (epoch 20.047), train_loss = 1.15987608, grad/param norm = 1.8287e-01, time/batch = 1.8776s	
11428/28500 (epoch 20.049), train_loss = 1.04861408, grad/param norm = 1.7015e-01, time/batch = 1.8731s	
11429/28500 (epoch 20.051), train_loss = 1.01753245, grad/param norm = 1.5468e-01, time/batch = 1.8485s	
11430/28500 (epoch 20.053), train_loss = 1.03194408, grad/param norm = 1.9181e-01, time/batch = 1.9078s	
11431/28500 (epoch 20.054), train_loss = 1.10783858, grad/param norm = 1.6085e-01, time/batch = 1.8923s	
11432/28500 (epoch 20.056), train_loss = 0.94755975, grad/param norm = 1.5889e-01, time/batch = 13.4922s	
11433/28500 (epoch 20.058), train_loss = 0.93056948, grad/param norm = 1.5369e-01, time/batch = 15.1113s	
11434/28500 (epoch 20.060), train_loss = 1.12281928, grad/param norm = 1.7477e-01, time/batch = 15.3094s	
11435/28500 (epoch 20.061), train_loss = 1.03975956, grad/param norm = 1.7113e-01, time/batch = 15.4448s	
11436/28500 (epoch 20.063), train_loss = 1.11138194, grad/param norm = 1.7343e-01, time/batch = 15.2088s	
11437/28500 (epoch 20.065), train_loss = 1.11420562, grad/param norm = 1.7401e-01, time/batch = 15.4309s	
11438/28500 (epoch 20.067), train_loss = 0.99468791, grad/param norm = 1.4128e-01, time/batch = 15.5229s	
11439/28500 (epoch 20.068), train_loss = 1.00699185, grad/param norm = 1.4748e-01, time/batch = 12.7014s	
11440/28500 (epoch 20.070), train_loss = 1.09179518, grad/param norm = 1.7688e-01, time/batch = 0.6949s	
11441/28500 (epoch 20.072), train_loss = 1.19463829, grad/param norm = 1.7535e-01, time/batch = 0.6877s	
11442/28500 (epoch 20.074), train_loss = 1.06426640, grad/param norm = 1.5855e-01, time/batch = 0.6842s	
11443/28500 (epoch 20.075), train_loss = 1.00402586, grad/param norm = 1.3911e-01, time/batch = 0.6881s	
11444/28500 (epoch 20.077), train_loss = 1.09224580, grad/param norm = 1.5852e-01, time/batch = 0.6883s	
11445/28500 (epoch 20.079), train_loss = 1.06240495, grad/param norm = 1.6603e-01, time/batch = 0.6871s	
11446/28500 (epoch 20.081), train_loss = 1.16711171, grad/param norm = 1.8881e-01, time/batch = 0.6829s	
11447/28500 (epoch 20.082), train_loss = 1.05878435, grad/param norm = 1.7955e-01, time/batch = 0.6861s	
11448/28500 (epoch 20.084), train_loss = 1.07581820, grad/param norm = 1.5631e-01, time/batch = 0.6851s	
11449/28500 (epoch 20.086), train_loss = 1.02149103, grad/param norm = 1.9200e-01, time/batch = 0.6809s	
11450/28500 (epoch 20.088), train_loss = 0.95867771, grad/param norm = 1.6475e-01, time/batch = 0.6839s	
11451/28500 (epoch 20.089), train_loss = 1.12645228, grad/param norm = 1.4198e-01, time/batch = 0.6827s	
11452/28500 (epoch 20.091), train_loss = 0.91998734, grad/param norm = 1.5300e-01, time/batch = 0.6854s	
11453/28500 (epoch 20.093), train_loss = 1.08908927, grad/param norm = 1.5728e-01, time/batch = 0.6852s	
11454/28500 (epoch 20.095), train_loss = 0.98564529, grad/param norm = 1.4450e-01, time/batch = 0.6848s	
11455/28500 (epoch 20.096), train_loss = 1.16259568, grad/param norm = 1.6774e-01, time/batch = 0.6804s	
11456/28500 (epoch 20.098), train_loss = 1.05638127, grad/param norm = 1.6837e-01, time/batch = 0.6842s	
11457/28500 (epoch 20.100), train_loss = 0.99798231, grad/param norm = 1.5444e-01, time/batch = 0.6811s	
11458/28500 (epoch 20.102), train_loss = 1.12553623, grad/param norm = 1.7517e-01, time/batch = 0.6830s	
11459/28500 (epoch 20.104), train_loss = 1.02006176, grad/param norm = 1.8334e-01, time/batch = 0.6837s	
11460/28500 (epoch 20.105), train_loss = 1.17710307, grad/param norm = 1.6406e-01, time/batch = 0.6826s	
11461/28500 (epoch 20.107), train_loss = 0.92360631, grad/param norm = 1.5152e-01, time/batch = 0.6898s	
11462/28500 (epoch 20.109), train_loss = 0.91499194, grad/param norm = 1.6516e-01, time/batch = 0.6842s	
11463/28500 (epoch 20.111), train_loss = 0.98574244, grad/param norm = 1.5944e-01, time/batch = 0.6846s	
11464/28500 (epoch 20.112), train_loss = 1.09444832, grad/param norm = 1.6045e-01, time/batch = 0.6816s	
11465/28500 (epoch 20.114), train_loss = 1.01342876, grad/param norm = 1.6854e-01, time/batch = 0.6838s	
11466/28500 (epoch 20.116), train_loss = 1.20033950, grad/param norm = 1.7848e-01, time/batch = 0.6812s	
11467/28500 (epoch 20.118), train_loss = 0.91595435, grad/param norm = 1.7179e-01, time/batch = 0.6821s	
11468/28500 (epoch 20.119), train_loss = 1.05148430, grad/param norm = 1.7108e-01, time/batch = 0.6810s	
11469/28500 (epoch 20.121), train_loss = 1.19397140, grad/param norm = 1.9548e-01, time/batch = 0.6865s	
11470/28500 (epoch 20.123), train_loss = 1.11655678, grad/param norm = 1.7153e-01, time/batch = 0.6818s	
11471/28500 (epoch 20.125), train_loss = 1.05225814, grad/param norm = 1.7409e-01, time/batch = 0.6828s	
11472/28500 (epoch 20.126), train_loss = 1.04049380, grad/param norm = 1.6240e-01, time/batch = 0.6830s	
11473/28500 (epoch 20.128), train_loss = 1.03512378, grad/param norm = 1.5739e-01, time/batch = 0.6827s	
11474/28500 (epoch 20.130), train_loss = 0.93800773, grad/param norm = 1.6936e-01, time/batch = 0.6829s	
11475/28500 (epoch 20.132), train_loss = 1.07293561, grad/param norm = 1.9264e-01, time/batch = 0.6855s	
11476/28500 (epoch 20.133), train_loss = 1.11842953, grad/param norm = 1.7788e-01, time/batch = 0.6826s	
11477/28500 (epoch 20.135), train_loss = 1.00470985, grad/param norm = 1.5016e-01, time/batch = 0.6801s	
11478/28500 (epoch 20.137), train_loss = 1.04972696, grad/param norm = 1.7749e-01, time/batch = 0.6827s	
11479/28500 (epoch 20.139), train_loss = 1.01243204, grad/param norm = 1.4218e-01, time/batch = 0.6816s	
11480/28500 (epoch 20.140), train_loss = 1.06600736, grad/param norm = 1.4993e-01, time/batch = 0.6833s	
11481/28500 (epoch 20.142), train_loss = 1.01782317, grad/param norm = 1.6442e-01, time/batch = 0.6918s	
11482/28500 (epoch 20.144), train_loss = 0.97591621, grad/param norm = 1.4115e-01, time/batch = 0.6828s	
11483/28500 (epoch 20.146), train_loss = 0.98949518, grad/param norm = 1.5283e-01, time/batch = 0.6853s	
11484/28500 (epoch 20.147), train_loss = 0.90499761, grad/param norm = 1.4742e-01, time/batch = 0.6824s	
11485/28500 (epoch 20.149), train_loss = 0.90207452, grad/param norm = 1.5055e-01, time/batch = 0.6923s	
11486/28500 (epoch 20.151), train_loss = 0.97652593, grad/param norm = 1.5543e-01, time/batch = 0.6807s	
11487/28500 (epoch 20.153), train_loss = 1.04513948, grad/param norm = 1.7751e-01, time/batch = 0.6841s	
11488/28500 (epoch 20.154), train_loss = 0.93654084, grad/param norm = 1.5558e-01, time/batch = 0.6802s	
11489/28500 (epoch 20.156), train_loss = 1.14265902, grad/param norm = 1.7326e-01, time/batch = 0.6812s	
11490/28500 (epoch 20.158), train_loss = 1.03780273, grad/param norm = 1.5989e-01, time/batch = 0.6832s	
11491/28500 (epoch 20.160), train_loss = 0.91361472, grad/param norm = 1.2843e-01, time/batch = 0.6859s	
11492/28500 (epoch 20.161), train_loss = 0.99515862, grad/param norm = 1.6381e-01, time/batch = 0.6852s	
11493/28500 (epoch 20.163), train_loss = 0.89633412, grad/param norm = 1.5301e-01, time/batch = 0.6808s	
11494/28500 (epoch 20.165), train_loss = 1.23729637, grad/param norm = 1.7028e-01, time/batch = 0.6857s	
11495/28500 (epoch 20.167), train_loss = 1.25703535, grad/param norm = 1.8576e-01, time/batch = 0.6805s	
11496/28500 (epoch 20.168), train_loss = 1.16080723, grad/param norm = 1.7593e-01, time/batch = 0.6838s	
11497/28500 (epoch 20.170), train_loss = 1.13012131, grad/param norm = 1.8218e-01, time/batch = 0.6802s	
11498/28500 (epoch 20.172), train_loss = 1.01893711, grad/param norm = 1.5272e-01, time/batch = 0.6811s	
11499/28500 (epoch 20.174), train_loss = 1.21364258, grad/param norm = 1.9842e-01, time/batch = 0.6823s	
11500/28500 (epoch 20.175), train_loss = 1.04192699, grad/param norm = 1.5515e-01, time/batch = 0.6824s	
11501/28500 (epoch 20.177), train_loss = 1.11020085, grad/param norm = 1.7513e-01, time/batch = 0.6859s	
11502/28500 (epoch 20.179), train_loss = 1.05973246, grad/param norm = 1.8614e-01, time/batch = 0.6829s	
11503/28500 (epoch 20.181), train_loss = 1.10896777, grad/param norm = 1.6424e-01, time/batch = 0.6821s	
11504/28500 (epoch 20.182), train_loss = 1.01665705, grad/param norm = 1.5980e-01, time/batch = 0.6810s	
11505/28500 (epoch 20.184), train_loss = 1.19031698, grad/param norm = 1.7817e-01, time/batch = 0.6836s	
11506/28500 (epoch 20.186), train_loss = 1.15580066, grad/param norm = 1.6780e-01, time/batch = 0.6822s	
11507/28500 (epoch 20.188), train_loss = 1.07696049, grad/param norm = 1.6925e-01, time/batch = 0.6818s	
11508/28500 (epoch 20.189), train_loss = 1.05192265, grad/param norm = 1.5772e-01, time/batch = 0.6817s	
11509/28500 (epoch 20.191), train_loss = 1.26915916, grad/param norm = 1.8455e-01, time/batch = 0.6829s	
11510/28500 (epoch 20.193), train_loss = 1.12028689, grad/param norm = 1.7906e-01, time/batch = 0.6814s	
11511/28500 (epoch 20.195), train_loss = 1.18889896, grad/param norm = 1.7080e-01, time/batch = 0.6848s	
11512/28500 (epoch 20.196), train_loss = 1.10915776, grad/param norm = 1.8305e-01, time/batch = 0.6846s	
11513/28500 (epoch 20.198), train_loss = 1.07290158, grad/param norm = 1.7261e-01, time/batch = 0.6822s	
11514/28500 (epoch 20.200), train_loss = 1.11050552, grad/param norm = 1.7112e-01, time/batch = 0.6812s	
11515/28500 (epoch 20.202), train_loss = 1.07165344, grad/param norm = 1.5740e-01, time/batch = 0.6812s	
11516/28500 (epoch 20.204), train_loss = 0.99619453, grad/param norm = 1.3866e-01, time/batch = 0.6874s	
11517/28500 (epoch 20.205), train_loss = 1.00827077, grad/param norm = 1.6477e-01, time/batch = 0.6813s	
11518/28500 (epoch 20.207), train_loss = 0.97809671, grad/param norm = 1.7112e-01, time/batch = 0.6800s	
11519/28500 (epoch 20.209), train_loss = 1.05383346, grad/param norm = 1.7793e-01, time/batch = 0.6809s	
11520/28500 (epoch 20.211), train_loss = 0.91459618, grad/param norm = 1.5057e-01, time/batch = 0.6834s	
11521/28500 (epoch 20.212), train_loss = 0.89791064, grad/param norm = 1.4671e-01, time/batch = 0.6833s	
11522/28500 (epoch 20.214), train_loss = 1.04502154, grad/param norm = 1.7286e-01, time/batch = 0.6835s	
11523/28500 (epoch 20.216), train_loss = 0.95730172, grad/param norm = 1.5476e-01, time/batch = 0.6829s	
11524/28500 (epoch 20.218), train_loss = 1.16590777, grad/param norm = 1.5043e-01, time/batch = 0.6824s	
11525/28500 (epoch 20.219), train_loss = 1.07537900, grad/param norm = 1.6467e-01, time/batch = 0.6871s	
11526/28500 (epoch 20.221), train_loss = 0.93707604, grad/param norm = 1.7512e-01, time/batch = 0.6937s	
11527/28500 (epoch 20.223), train_loss = 1.16983438, grad/param norm = 1.6327e-01, time/batch = 0.6881s	
11528/28500 (epoch 20.225), train_loss = 1.17030962, grad/param norm = 1.7339e-01, time/batch = 0.6794s	
11529/28500 (epoch 20.226), train_loss = 0.99277339, grad/param norm = 1.5037e-01, time/batch = 0.6826s	
11530/28500 (epoch 20.228), train_loss = 1.15544830, grad/param norm = 1.6110e-01, time/batch = 0.6797s	
11531/28500 (epoch 20.230), train_loss = 1.13585777, grad/param norm = 1.6737e-01, time/batch = 0.6884s	
11532/28500 (epoch 20.232), train_loss = 1.07385681, grad/param norm = 1.4884e-01, time/batch = 0.6828s	
11533/28500 (epoch 20.233), train_loss = 1.07168142, grad/param norm = 1.7649e-01, time/batch = 0.6842s	
11534/28500 (epoch 20.235), train_loss = 1.01533258, grad/param norm = 1.3645e-01, time/batch = 0.6983s	
11535/28500 (epoch 20.237), train_loss = 0.92842379, grad/param norm = 1.4171e-01, time/batch = 0.6878s	
11536/28500 (epoch 20.239), train_loss = 0.97161193, grad/param norm = 1.4304e-01, time/batch = 0.6836s	
11537/28500 (epoch 20.240), train_loss = 0.93413589, grad/param norm = 1.5828e-01, time/batch = 0.6835s	
11538/28500 (epoch 20.242), train_loss = 1.08737751, grad/param norm = 1.8156e-01, time/batch = 0.6858s	
11539/28500 (epoch 20.244), train_loss = 1.09225657, grad/param norm = 1.4484e-01, time/batch = 0.6897s	
11540/28500 (epoch 20.246), train_loss = 1.14976684, grad/param norm = 1.7463e-01, time/batch = 0.6854s	
11541/28500 (epoch 20.247), train_loss = 1.19003787, grad/param norm = 1.6985e-01, time/batch = 0.6852s	
11542/28500 (epoch 20.249), train_loss = 1.05350284, grad/param norm = 1.5203e-01, time/batch = 0.6842s	
11543/28500 (epoch 20.251), train_loss = 1.00168462, grad/param norm = 1.5092e-01, time/batch = 0.6800s	
11544/28500 (epoch 20.253), train_loss = 1.18533056, grad/param norm = 1.8188e-01, time/batch = 0.6854s	
11545/28500 (epoch 20.254), train_loss = 1.18426873, grad/param norm = 1.6305e-01, time/batch = 0.6809s	
11546/28500 (epoch 20.256), train_loss = 0.97635777, grad/param norm = 1.5309e-01, time/batch = 0.6861s	
11547/28500 (epoch 20.258), train_loss = 1.04123381, grad/param norm = 1.7878e-01, time/batch = 0.6808s	
11548/28500 (epoch 20.260), train_loss = 0.98376120, grad/param norm = 1.5344e-01, time/batch = 0.6825s	
11549/28500 (epoch 20.261), train_loss = 0.97731482, grad/param norm = 1.5070e-01, time/batch = 0.6816s	
11550/28500 (epoch 20.263), train_loss = 1.15338357, grad/param norm = 1.7025e-01, time/batch = 0.6833s	
11551/28500 (epoch 20.265), train_loss = 1.05881714, grad/param norm = 1.6595e-01, time/batch = 0.6826s	
11552/28500 (epoch 20.267), train_loss = 1.18790271, grad/param norm = 1.7057e-01, time/batch = 0.6816s	
11553/28500 (epoch 20.268), train_loss = 1.09826047, grad/param norm = 1.5470e-01, time/batch = 0.6814s	
11554/28500 (epoch 20.270), train_loss = 1.09562765, grad/param norm = 1.7816e-01, time/batch = 0.6868s	
11555/28500 (epoch 20.272), train_loss = 1.01207776, grad/param norm = 1.5827e-01, time/batch = 0.6832s	
11556/28500 (epoch 20.274), train_loss = 1.16899302, grad/param norm = 1.7833e-01, time/batch = 0.6857s	
11557/28500 (epoch 20.275), train_loss = 1.07312246, grad/param norm = 1.5066e-01, time/batch = 0.6825s	
11558/28500 (epoch 20.277), train_loss = 1.06946736, grad/param norm = 1.5985e-01, time/batch = 0.6856s	
11559/28500 (epoch 20.279), train_loss = 1.10411261, grad/param norm = 1.7013e-01, time/batch = 0.6871s	
11560/28500 (epoch 20.281), train_loss = 1.14242499, grad/param norm = 1.8744e-01, time/batch = 0.6828s	
11561/28500 (epoch 20.282), train_loss = 0.98019145, grad/param norm = 1.4361e-01, time/batch = 0.6909s	
11562/28500 (epoch 20.284), train_loss = 1.06340076, grad/param norm = 1.7147e-01, time/batch = 0.6854s	
11563/28500 (epoch 20.286), train_loss = 1.16966305, grad/param norm = 1.6149e-01, time/batch = 0.6862s	
11564/28500 (epoch 20.288), train_loss = 1.09927275, grad/param norm = 1.7493e-01, time/batch = 0.6836s	
11565/28500 (epoch 20.289), train_loss = 1.10729262, grad/param norm = 2.0023e-01, time/batch = 0.6839s	
11566/28500 (epoch 20.291), train_loss = 1.07062005, grad/param norm = 1.5272e-01, time/batch = 0.6820s	
11567/28500 (epoch 20.293), train_loss = 1.04182185, grad/param norm = 1.6221e-01, time/batch = 0.6815s	
11568/28500 (epoch 20.295), train_loss = 0.94017290, grad/param norm = 1.6421e-01, time/batch = 0.6817s	
11569/28500 (epoch 20.296), train_loss = 0.94142340, grad/param norm = 1.6256e-01, time/batch = 0.6815s	
11570/28500 (epoch 20.298), train_loss = 1.12984124, grad/param norm = 1.6313e-01, time/batch = 0.6851s	
11571/28500 (epoch 20.300), train_loss = 0.98005223, grad/param norm = 1.5402e-01, time/batch = 0.6863s	
11572/28500 (epoch 20.302), train_loss = 0.93328715, grad/param norm = 1.5057e-01, time/batch = 0.6841s	
11573/28500 (epoch 20.304), train_loss = 1.02414676, grad/param norm = 1.6011e-01, time/batch = 0.6819s	
11574/28500 (epoch 20.305), train_loss = 1.08381080, grad/param norm = 1.5730e-01, time/batch = 0.6820s	
11575/28500 (epoch 20.307), train_loss = 1.04435618, grad/param norm = 1.6877e-01, time/batch = 0.6848s	
11576/28500 (epoch 20.309), train_loss = 1.05378156, grad/param norm = 1.8078e-01, time/batch = 0.6848s	
11577/28500 (epoch 20.311), train_loss = 1.10997044, grad/param norm = 1.5618e-01, time/batch = 0.6808s	
11578/28500 (epoch 20.312), train_loss = 1.06794987, grad/param norm = 1.8156e-01, time/batch = 0.6870s	
11579/28500 (epoch 20.314), train_loss = 1.13840990, grad/param norm = 1.8780e-01, time/batch = 0.6844s	
11580/28500 (epoch 20.316), train_loss = 1.06570665, grad/param norm = 1.5227e-01, time/batch = 0.6818s	
11581/28500 (epoch 20.318), train_loss = 1.13526415, grad/param norm = 1.6866e-01, time/batch = 0.6834s	
11582/28500 (epoch 20.319), train_loss = 1.00749532, grad/param norm = 1.6683e-01, time/batch = 0.6895s	
11583/28500 (epoch 20.321), train_loss = 1.00088054, grad/param norm = 1.6954e-01, time/batch = 0.6803s	
11584/28500 (epoch 20.323), train_loss = 1.02335429, grad/param norm = 1.9691e-01, time/batch = 0.6776s	
11585/28500 (epoch 20.325), train_loss = 1.19202645, grad/param norm = 1.6962e-01, time/batch = 0.6882s	
11586/28500 (epoch 20.326), train_loss = 1.07048129, grad/param norm = 1.6416e-01, time/batch = 0.6954s	
11587/28500 (epoch 20.328), train_loss = 0.86334962, grad/param norm = 1.4642e-01, time/batch = 0.6834s	
11588/28500 (epoch 20.330), train_loss = 0.97771138, grad/param norm = 1.7844e-01, time/batch = 0.6832s	
11589/28500 (epoch 20.332), train_loss = 1.05259381, grad/param norm = 1.5117e-01, time/batch = 0.6822s	
11590/28500 (epoch 20.333), train_loss = 0.87782409, grad/param norm = 1.6274e-01, time/batch = 0.6914s	
11591/28500 (epoch 20.335), train_loss = 0.94419664, grad/param norm = 1.5101e-01, time/batch = 0.6819s	
11592/28500 (epoch 20.337), train_loss = 0.93351505, grad/param norm = 1.4580e-01, time/batch = 0.6848s	
11593/28500 (epoch 20.339), train_loss = 0.88259699, grad/param norm = 1.3528e-01, time/batch = 0.6818s	
11594/28500 (epoch 20.340), train_loss = 1.08423502, grad/param norm = 1.8468e-01, time/batch = 0.6787s	
11595/28500 (epoch 20.342), train_loss = 1.03696267, grad/param norm = 1.5829e-01, time/batch = 0.6786s	
11596/28500 (epoch 20.344), train_loss = 0.97751099, grad/param norm = 1.7056e-01, time/batch = 0.6818s	
11597/28500 (epoch 20.346), train_loss = 0.85443984, grad/param norm = 1.3218e-01, time/batch = 0.6845s	
11598/28500 (epoch 20.347), train_loss = 1.03694471, grad/param norm = 1.7574e-01, time/batch = 0.6804s	
11599/28500 (epoch 20.349), train_loss = 1.00528526, grad/param norm = 1.4538e-01, time/batch = 0.6784s	
11600/28500 (epoch 20.351), train_loss = 0.94664176, grad/param norm = 1.5023e-01, time/batch = 0.6837s	
11601/28500 (epoch 20.353), train_loss = 1.06012882, grad/param norm = 1.7187e-01, time/batch = 0.6956s	
11602/28500 (epoch 20.354), train_loss = 0.92239444, grad/param norm = 1.4726e-01, time/batch = 0.6963s	
11603/28500 (epoch 20.356), train_loss = 0.95058212, grad/param norm = 1.4242e-01, time/batch = 0.6969s	
11604/28500 (epoch 20.358), train_loss = 1.05554256, grad/param norm = 1.5579e-01, time/batch = 0.6966s	
11605/28500 (epoch 20.360), train_loss = 1.06334107, grad/param norm = 1.7433e-01, time/batch = 0.6990s	
11606/28500 (epoch 20.361), train_loss = 0.96866486, grad/param norm = 1.4785e-01, time/batch = 0.6918s	
11607/28500 (epoch 20.363), train_loss = 0.90773734, grad/param norm = 1.3943e-01, time/batch = 0.7011s	
11608/28500 (epoch 20.365), train_loss = 0.99996974, grad/param norm = 1.6170e-01, time/batch = 0.7119s	
11609/28500 (epoch 20.367), train_loss = 1.04100427, grad/param norm = 1.6556e-01, time/batch = 0.6929s	
11610/28500 (epoch 20.368), train_loss = 0.99617361, grad/param norm = 1.4812e-01, time/batch = 0.6926s	
11611/28500 (epoch 20.370), train_loss = 1.03598330, grad/param norm = 1.6867e-01, time/batch = 0.6945s	
11612/28500 (epoch 20.372), train_loss = 0.88607086, grad/param norm = 1.6344e-01, time/batch = 0.6916s	
11613/28500 (epoch 20.374), train_loss = 0.99827316, grad/param norm = 1.6814e-01, time/batch = 0.7027s	
11614/28500 (epoch 20.375), train_loss = 1.14637309, grad/param norm = 1.5668e-01, time/batch = 0.7018s	
11615/28500 (epoch 20.377), train_loss = 0.89366579, grad/param norm = 1.4415e-01, time/batch = 0.6969s	
11616/28500 (epoch 20.379), train_loss = 0.80290602, grad/param norm = 1.5584e-01, time/batch = 0.6912s	
11617/28500 (epoch 20.381), train_loss = 0.98855556, grad/param norm = 1.5315e-01, time/batch = 0.6918s	
11618/28500 (epoch 20.382), train_loss = 0.97734283, grad/param norm = 1.6764e-01, time/batch = 0.6915s	
11619/28500 (epoch 20.384), train_loss = 0.89275788, grad/param norm = 1.5202e-01, time/batch = 0.6935s	
11620/28500 (epoch 20.386), train_loss = 0.89258695, grad/param norm = 1.5516e-01, time/batch = 0.6947s	
11621/28500 (epoch 20.388), train_loss = 1.11109878, grad/param norm = 1.6444e-01, time/batch = 0.6982s	
11622/28500 (epoch 20.389), train_loss = 0.94335372, grad/param norm = 1.6784e-01, time/batch = 0.6934s	
11623/28500 (epoch 20.391), train_loss = 0.92001000, grad/param norm = 1.4789e-01, time/batch = 0.6928s	
11624/28500 (epoch 20.393), train_loss = 0.92043701, grad/param norm = 1.5811e-01, time/batch = 0.6933s	
11625/28500 (epoch 20.395), train_loss = 1.17505629, grad/param norm = 1.6747e-01, time/batch = 0.6933s	
11626/28500 (epoch 20.396), train_loss = 1.10740451, grad/param norm = 1.7007e-01, time/batch = 0.6925s	
11627/28500 (epoch 20.398), train_loss = 0.81238137, grad/param norm = 1.6016e-01, time/batch = 0.6986s	
11628/28500 (epoch 20.400), train_loss = 1.02819213, grad/param norm = 1.8458e-01, time/batch = 0.6916s	
11629/28500 (epoch 20.402), train_loss = 1.06677355, grad/param norm = 1.7927e-01, time/batch = 0.6945s	
11630/28500 (epoch 20.404), train_loss = 1.10385917, grad/param norm = 1.7659e-01, time/batch = 0.7010s	
11631/28500 (epoch 20.405), train_loss = 1.11572500, grad/param norm = 1.5823e-01, time/batch = 0.7061s	
11632/28500 (epoch 20.407), train_loss = 1.04840417, grad/param norm = 1.5332e-01, time/batch = 0.7091s	
11633/28500 (epoch 20.409), train_loss = 1.05398393, grad/param norm = 1.5981e-01, time/batch = 0.6958s	
11634/28500 (epoch 20.411), train_loss = 1.15283625, grad/param norm = 1.7118e-01, time/batch = 0.6920s	
11635/28500 (epoch 20.412), train_loss = 1.14832716, grad/param norm = 1.7545e-01, time/batch = 0.6938s	
11636/28500 (epoch 20.414), train_loss = 1.06002630, grad/param norm = 1.6785e-01, time/batch = 0.6937s	
11637/28500 (epoch 20.416), train_loss = 0.95214808, grad/param norm = 1.5948e-01, time/batch = 0.7203s	
11638/28500 (epoch 20.418), train_loss = 1.04131584, grad/param norm = 1.4645e-01, time/batch = 0.7071s	
11639/28500 (epoch 20.419), train_loss = 1.14097911, grad/param norm = 1.7101e-01, time/batch = 0.7079s	
11640/28500 (epoch 20.421), train_loss = 1.11607726, grad/param norm = 1.6859e-01, time/batch = 0.6923s	
11641/28500 (epoch 20.423), train_loss = 1.12408294, grad/param norm = 1.8138e-01, time/batch = 0.6929s	
11642/28500 (epoch 20.425), train_loss = 1.06615369, grad/param norm = 1.7072e-01, time/batch = 0.6895s	
11643/28500 (epoch 20.426), train_loss = 1.02469269, grad/param norm = 1.7183e-01, time/batch = 0.7051s	
11644/28500 (epoch 20.428), train_loss = 1.22537937, grad/param norm = 1.7446e-01, time/batch = 0.6953s	
11645/28500 (epoch 20.430), train_loss = 1.15788265, grad/param norm = 1.5534e-01, time/batch = 0.6929s	
11646/28500 (epoch 20.432), train_loss = 1.08811407, grad/param norm = 1.6771e-01, time/batch = 0.6913s	
11647/28500 (epoch 20.433), train_loss = 1.09815582, grad/param norm = 1.7679e-01, time/batch = 0.6896s	
11648/28500 (epoch 20.435), train_loss = 1.06374175, grad/param norm = 1.7702e-01, time/batch = 0.6915s	
11649/28500 (epoch 20.437), train_loss = 0.96718786, grad/param norm = 1.6485e-01, time/batch = 0.6935s	
11650/28500 (epoch 20.439), train_loss = 1.00379315, grad/param norm = 1.4396e-01, time/batch = 0.6922s	
11651/28500 (epoch 20.440), train_loss = 1.26480501, grad/param norm = 1.7836e-01, time/batch = 0.6984s	
11652/28500 (epoch 20.442), train_loss = 0.96985931, grad/param norm = 1.6265e-01, time/batch = 0.6922s	
11653/28500 (epoch 20.444), train_loss = 0.89434977, grad/param norm = 1.4493e-01, time/batch = 0.7005s	
11654/28500 (epoch 20.446), train_loss = 0.87189432, grad/param norm = 1.4175e-01, time/batch = 0.6930s	
11655/28500 (epoch 20.447), train_loss = 0.87827078, grad/param norm = 1.3245e-01, time/batch = 0.6941s	
11656/28500 (epoch 20.449), train_loss = 0.98553636, grad/param norm = 1.4679e-01, time/batch = 0.6941s	
11657/28500 (epoch 20.451), train_loss = 1.01363138, grad/param norm = 1.5288e-01, time/batch = 0.6997s	
11658/28500 (epoch 20.453), train_loss = 1.00041358, grad/param norm = 1.5021e-01, time/batch = 0.6920s	
11659/28500 (epoch 20.454), train_loss = 0.98902690, grad/param norm = 1.5308e-01, time/batch = 0.6939s	
11660/28500 (epoch 20.456), train_loss = 1.10281348, grad/param norm = 1.7151e-01, time/batch = 0.6948s	
11661/28500 (epoch 20.458), train_loss = 1.01084204, grad/param norm = 1.6017e-01, time/batch = 0.6969s	
11662/28500 (epoch 20.460), train_loss = 1.07320779, grad/param norm = 1.6773e-01, time/batch = 0.6996s	
11663/28500 (epoch 20.461), train_loss = 0.99009060, grad/param norm = 1.8134e-01, time/batch = 0.6931s	
11664/28500 (epoch 20.463), train_loss = 0.89366549, grad/param norm = 1.3298e-01, time/batch = 0.6948s	
11665/28500 (epoch 20.465), train_loss = 0.87598983, grad/param norm = 1.6970e-01, time/batch = 0.6918s	
11666/28500 (epoch 20.467), train_loss = 1.01855195, grad/param norm = 1.5111e-01, time/batch = 0.6903s	
11667/28500 (epoch 20.468), train_loss = 0.94219099, grad/param norm = 1.4436e-01, time/batch = 0.6926s	
11668/28500 (epoch 20.470), train_loss = 0.94640624, grad/param norm = 1.4891e-01, time/batch = 0.6926s	
11669/28500 (epoch 20.472), train_loss = 0.97455628, grad/param norm = 1.5305e-01, time/batch = 0.6956s	
11670/28500 (epoch 20.474), train_loss = 1.18766998, grad/param norm = 1.7437e-01, time/batch = 0.6924s	
11671/28500 (epoch 20.475), train_loss = 0.93119461, grad/param norm = 1.3576e-01, time/batch = 0.6991s	
11672/28500 (epoch 20.477), train_loss = 0.99509766, grad/param norm = 1.6131e-01, time/batch = 0.6956s	
11673/28500 (epoch 20.479), train_loss = 1.06429614, grad/param norm = 1.5641e-01, time/batch = 0.6990s	
11674/28500 (epoch 20.481), train_loss = 1.02152557, grad/param norm = 1.9273e-01, time/batch = 0.6957s	
11675/28500 (epoch 20.482), train_loss = 0.93286779, grad/param norm = 1.5255e-01, time/batch = 0.6924s	
11676/28500 (epoch 20.484), train_loss = 0.92140666, grad/param norm = 1.4535e-01, time/batch = 0.6938s	
11677/28500 (epoch 20.486), train_loss = 0.83761743, grad/param norm = 1.6541e-01, time/batch = 0.6924s	
11678/28500 (epoch 20.488), train_loss = 1.05016569, grad/param norm = 1.4216e-01, time/batch = 0.6940s	
11679/28500 (epoch 20.489), train_loss = 1.12129385, grad/param norm = 1.6480e-01, time/batch = 0.6902s	
11680/28500 (epoch 20.491), train_loss = 0.97096666, grad/param norm = 1.4905e-01, time/batch = 0.6923s	
11681/28500 (epoch 20.493), train_loss = 0.98774301, grad/param norm = 1.4917e-01, time/batch = 0.6937s	
11682/28500 (epoch 20.495), train_loss = 0.99769045, grad/param norm = 1.4259e-01, time/batch = 0.6971s	
11683/28500 (epoch 20.496), train_loss = 0.93822525, grad/param norm = 1.7531e-01, time/batch = 0.6985s	
11684/28500 (epoch 20.498), train_loss = 1.03953474, grad/param norm = 1.5585e-01, time/batch = 0.6985s	
11685/28500 (epoch 20.500), train_loss = 0.97269171, grad/param norm = 1.4729e-01, time/batch = 0.6942s	
11686/28500 (epoch 20.502), train_loss = 1.09738635, grad/param norm = 1.5247e-01, time/batch = 0.6985s	
11687/28500 (epoch 20.504), train_loss = 1.02924972, grad/param norm = 1.5213e-01, time/batch = 0.6959s	
11688/28500 (epoch 20.505), train_loss = 0.94127711, grad/param norm = 1.4532e-01, time/batch = 0.6984s	
11689/28500 (epoch 20.507), train_loss = 1.13652360, grad/param norm = 1.8060e-01, time/batch = 0.7034s	
11690/28500 (epoch 20.509), train_loss = 1.02393151, grad/param norm = 1.6461e-01, time/batch = 0.7127s	
11691/28500 (epoch 20.511), train_loss = 1.00957573, grad/param norm = 1.5635e-01, time/batch = 0.7198s	
11692/28500 (epoch 20.512), train_loss = 1.03570397, grad/param norm = 1.5366e-01, time/batch = 0.6993s	
11693/28500 (epoch 20.514), train_loss = 0.95335901, grad/param norm = 1.4639e-01, time/batch = 0.7047s	
11694/28500 (epoch 20.516), train_loss = 0.97518548, grad/param norm = 1.3454e-01, time/batch = 0.6899s	
11695/28500 (epoch 20.518), train_loss = 1.05325958, grad/param norm = 1.4352e-01, time/batch = 0.6903s	
11696/28500 (epoch 20.519), train_loss = 1.08993299, grad/param norm = 1.5451e-01, time/batch = 0.6837s	
11697/28500 (epoch 20.521), train_loss = 1.17887221, grad/param norm = 1.8486e-01, time/batch = 0.6862s	
11698/28500 (epoch 20.523), train_loss = 1.08418115, grad/param norm = 1.6548e-01, time/batch = 0.6902s	
11699/28500 (epoch 20.525), train_loss = 1.11519367, grad/param norm = 1.6423e-01, time/batch = 0.6956s	
11700/28500 (epoch 20.526), train_loss = 1.09833797, grad/param norm = 1.6593e-01, time/batch = 0.7004s	
11701/28500 (epoch 20.528), train_loss = 1.10399679, grad/param norm = 1.5918e-01, time/batch = 0.6928s	
11702/28500 (epoch 20.530), train_loss = 1.12568613, grad/param norm = 1.5763e-01, time/batch = 0.6858s	
11703/28500 (epoch 20.532), train_loss = 0.98273634, grad/param norm = 1.4343e-01, time/batch = 0.6847s	
11704/28500 (epoch 20.533), train_loss = 1.12418683, grad/param norm = 1.6767e-01, time/batch = 0.6851s	
11705/28500 (epoch 20.535), train_loss = 0.87476251, grad/param norm = 1.3565e-01, time/batch = 0.6844s	
11706/28500 (epoch 20.537), train_loss = 0.92136530, grad/param norm = 1.4612e-01, time/batch = 0.6819s	
11707/28500 (epoch 20.539), train_loss = 0.87357977, grad/param norm = 1.4854e-01, time/batch = 0.6974s	
11708/28500 (epoch 20.540), train_loss = 1.04117507, grad/param norm = 1.6566e-01, time/batch = 0.6869s	
11709/28500 (epoch 20.542), train_loss = 1.08399053, grad/param norm = 1.8571e-01, time/batch = 0.6828s	
11710/28500 (epoch 20.544), train_loss = 1.18869598, grad/param norm = 1.7415e-01, time/batch = 0.6875s	
11711/28500 (epoch 20.546), train_loss = 1.02798618, grad/param norm = 1.7210e-01, time/batch = 0.7026s	
11712/28500 (epoch 20.547), train_loss = 1.03214216, grad/param norm = 1.5225e-01, time/batch = 0.7020s	
11713/28500 (epoch 20.549), train_loss = 0.85425140, grad/param norm = 1.2232e-01, time/batch = 0.6957s	
11714/28500 (epoch 20.551), train_loss = 1.03222730, grad/param norm = 1.8663e-01, time/batch = 0.7095s	
11715/28500 (epoch 20.553), train_loss = 1.21804249, grad/param norm = 1.8971e-01, time/batch = 0.7015s	
11716/28500 (epoch 20.554), train_loss = 1.02014099, grad/param norm = 1.5162e-01, time/batch = 0.7031s	
11717/28500 (epoch 20.556), train_loss = 1.05619402, grad/param norm = 1.6363e-01, time/batch = 0.6985s	
11718/28500 (epoch 20.558), train_loss = 1.06335964, grad/param norm = 1.5508e-01, time/batch = 0.6988s	
11719/28500 (epoch 20.560), train_loss = 1.08818085, grad/param norm = 1.8042e-01, time/batch = 0.6970s	
11720/28500 (epoch 20.561), train_loss = 1.09572986, grad/param norm = 1.6144e-01, time/batch = 0.6989s	
11721/28500 (epoch 20.563), train_loss = 1.19185040, grad/param norm = 1.7774e-01, time/batch = 0.7004s	
11722/28500 (epoch 20.565), train_loss = 1.00898358, grad/param norm = 1.6465e-01, time/batch = 0.6995s	
11723/28500 (epoch 20.567), train_loss = 0.90576519, grad/param norm = 1.3492e-01, time/batch = 0.6968s	
11724/28500 (epoch 20.568), train_loss = 1.06464199, grad/param norm = 1.6787e-01, time/batch = 0.6974s	
11725/28500 (epoch 20.570), train_loss = 1.00593693, grad/param norm = 1.5639e-01, time/batch = 0.7027s	
11726/28500 (epoch 20.572), train_loss = 1.00236401, grad/param norm = 1.5370e-01, time/batch = 0.7271s	
11727/28500 (epoch 20.574), train_loss = 0.99649061, grad/param norm = 1.5922e-01, time/batch = 0.6971s	
11728/28500 (epoch 20.575), train_loss = 0.99812340, grad/param norm = 1.6340e-01, time/batch = 0.6969s	
11729/28500 (epoch 20.577), train_loss = 1.05740959, grad/param norm = 1.6763e-01, time/batch = 0.7006s	
11730/28500 (epoch 20.579), train_loss = 1.11818348, grad/param norm = 1.7294e-01, time/batch = 0.6974s	
11731/28500 (epoch 20.581), train_loss = 0.95378096, grad/param norm = 1.6226e-01, time/batch = 0.7062s	
11732/28500 (epoch 20.582), train_loss = 1.10240853, grad/param norm = 1.4992e-01, time/batch = 0.7104s	
11733/28500 (epoch 20.584), train_loss = 0.98065885, grad/param norm = 1.5576e-01, time/batch = 0.7040s	
11734/28500 (epoch 20.586), train_loss = 0.94495767, grad/param norm = 1.3615e-01, time/batch = 0.6976s	
11735/28500 (epoch 20.588), train_loss = 0.93556304, grad/param norm = 1.4231e-01, time/batch = 0.7004s	
11736/28500 (epoch 20.589), train_loss = 1.05271837, grad/param norm = 1.6590e-01, time/batch = 0.6967s	
11737/28500 (epoch 20.591), train_loss = 1.03749447, grad/param norm = 1.6896e-01, time/batch = 0.7000s	
11738/28500 (epoch 20.593), train_loss = 0.97753947, grad/param norm = 1.5590e-01, time/batch = 0.6968s	
11739/28500 (epoch 20.595), train_loss = 1.22795766, grad/param norm = 1.9108e-01, time/batch = 0.6996s	
11740/28500 (epoch 20.596), train_loss = 1.22573093, grad/param norm = 1.8090e-01, time/batch = 0.6963s	
11741/28500 (epoch 20.598), train_loss = 1.04311098, grad/param norm = 1.5384e-01, time/batch = 0.7015s	
11742/28500 (epoch 20.600), train_loss = 1.03109172, grad/param norm = 1.6338e-01, time/batch = 0.6967s	
11743/28500 (epoch 20.602), train_loss = 1.12379632, grad/param norm = 1.7310e-01, time/batch = 0.7019s	
11744/28500 (epoch 20.604), train_loss = 1.12207186, grad/param norm = 1.6622e-01, time/batch = 0.6961s	
11745/28500 (epoch 20.605), train_loss = 1.06816148, grad/param norm = 1.6206e-01, time/batch = 0.7010s	
11746/28500 (epoch 20.607), train_loss = 1.14481464, grad/param norm = 1.5634e-01, time/batch = 0.6986s	
11747/28500 (epoch 20.609), train_loss = 1.04809138, grad/param norm = 1.5745e-01, time/batch = 0.7019s	
11748/28500 (epoch 20.611), train_loss = 1.01058204, grad/param norm = 1.5903e-01, time/batch = 0.6999s	
11749/28500 (epoch 20.612), train_loss = 1.08093479, grad/param norm = 1.6674e-01, time/batch = 0.6948s	
11750/28500 (epoch 20.614), train_loss = 1.07144081, grad/param norm = 1.5176e-01, time/batch = 0.6950s	
11751/28500 (epoch 20.616), train_loss = 0.97581521, grad/param norm = 1.7844e-01, time/batch = 0.7034s	
11752/28500 (epoch 20.618), train_loss = 1.01513736, grad/param norm = 1.5725e-01, time/batch = 0.6945s	
11753/28500 (epoch 20.619), train_loss = 1.20932625, grad/param norm = 1.8874e-01, time/batch = 0.6969s	
11754/28500 (epoch 20.621), train_loss = 0.84627668, grad/param norm = 1.3638e-01, time/batch = 0.6951s	
11755/28500 (epoch 20.623), train_loss = 1.14240347, grad/param norm = 1.5970e-01, time/batch = 0.6979s	
11756/28500 (epoch 20.625), train_loss = 0.93197141, grad/param norm = 1.5907e-01, time/batch = 0.6936s	
11757/28500 (epoch 20.626), train_loss = 0.80221789, grad/param norm = 1.3486e-01, time/batch = 0.6987s	
11758/28500 (epoch 20.628), train_loss = 0.96041671, grad/param norm = 1.5807e-01, time/batch = 0.6971s	
11759/28500 (epoch 20.630), train_loss = 0.88085159, grad/param norm = 1.3637e-01, time/batch = 0.6955s	
11760/28500 (epoch 20.632), train_loss = 1.12491796, grad/param norm = 1.6157e-01, time/batch = 0.6948s	
11761/28500 (epoch 20.633), train_loss = 1.18877771, grad/param norm = 1.5383e-01, time/batch = 0.6965s	
11762/28500 (epoch 20.635), train_loss = 1.11800658, grad/param norm = 1.6171e-01, time/batch = 0.6954s	
11763/28500 (epoch 20.637), train_loss = 1.05460141, grad/param norm = 1.5055e-01, time/batch = 0.7012s	
11764/28500 (epoch 20.639), train_loss = 0.92648868, grad/param norm = 1.5474e-01, time/batch = 0.6945s	
11765/28500 (epoch 20.640), train_loss = 0.96437537, grad/param norm = 1.4965e-01, time/batch = 0.6964s	
11766/28500 (epoch 20.642), train_loss = 0.97189671, grad/param norm = 1.4532e-01, time/batch = 0.6951s	
11767/28500 (epoch 20.644), train_loss = 1.09964386, grad/param norm = 1.5402e-01, time/batch = 0.6987s	
11768/28500 (epoch 20.646), train_loss = 0.91443765, grad/param norm = 1.4374e-01, time/batch = 0.6953s	
11769/28500 (epoch 20.647), train_loss = 0.94190253, grad/param norm = 1.6667e-01, time/batch = 0.6987s	
11770/28500 (epoch 20.649), train_loss = 0.90744188, grad/param norm = 1.5126e-01, time/batch = 0.6983s	
11771/28500 (epoch 20.651), train_loss = 0.89483096, grad/param norm = 1.5509e-01, time/batch = 0.6963s	
11772/28500 (epoch 20.653), train_loss = 0.90856215, grad/param norm = 1.5528e-01, time/batch = 0.6953s	
11773/28500 (epoch 20.654), train_loss = 0.98696976, grad/param norm = 1.5515e-01, time/batch = 0.7072s	
11774/28500 (epoch 20.656), train_loss = 0.93725940, grad/param norm = 1.6336e-01, time/batch = 0.7020s	
11775/28500 (epoch 20.658), train_loss = 1.00176108, grad/param norm = 1.5843e-01, time/batch = 0.6954s	
11776/28500 (epoch 20.660), train_loss = 1.00209756, grad/param norm = 1.4661e-01, time/batch = 0.6930s	
11777/28500 (epoch 20.661), train_loss = 1.16627311, grad/param norm = 1.8487e-01, time/batch = 0.6935s	
11778/28500 (epoch 20.663), train_loss = 1.16325001, grad/param norm = 1.7218e-01, time/batch = 0.6929s	
11779/28500 (epoch 20.665), train_loss = 1.00818732, grad/param norm = 1.4880e-01, time/batch = 0.6941s	
11780/28500 (epoch 20.667), train_loss = 1.01533563, grad/param norm = 1.6159e-01, time/batch = 0.6928s	
11781/28500 (epoch 20.668), train_loss = 1.01208036, grad/param norm = 1.5752e-01, time/batch = 0.6966s	
11782/28500 (epoch 20.670), train_loss = 1.03518100, grad/param norm = 1.5323e-01, time/batch = 0.6957s	
11783/28500 (epoch 20.672), train_loss = 0.95646320, grad/param norm = 1.5885e-01, time/batch = 0.6962s	
11784/28500 (epoch 20.674), train_loss = 0.86694026, grad/param norm = 1.6427e-01, time/batch = 0.6964s	
11785/28500 (epoch 20.675), train_loss = 0.89654154, grad/param norm = 1.4673e-01, time/batch = 0.7093s	
11786/28500 (epoch 20.677), train_loss = 1.00978003, grad/param norm = 1.5945e-01, time/batch = 0.6941s	
11787/28500 (epoch 20.679), train_loss = 0.97376400, grad/param norm = 1.6498e-01, time/batch = 0.6940s	
11788/28500 (epoch 20.681), train_loss = 1.07359647, grad/param norm = 1.5818e-01, time/batch = 0.7119s	
11789/28500 (epoch 20.682), train_loss = 0.96929191, grad/param norm = 1.4219e-01, time/batch = 0.6991s	
11790/28500 (epoch 20.684), train_loss = 1.06223165, grad/param norm = 1.6419e-01, time/batch = 0.6938s	
11791/28500 (epoch 20.686), train_loss = 0.97156828, grad/param norm = 1.7258e-01, time/batch = 0.7015s	
11792/28500 (epoch 20.688), train_loss = 0.92141380, grad/param norm = 1.4032e-01, time/batch = 0.6942s	
11793/28500 (epoch 20.689), train_loss = 0.99521231, grad/param norm = 1.7037e-01, time/batch = 0.6951s	
11794/28500 (epoch 20.691), train_loss = 1.03922675, grad/param norm = 1.7420e-01, time/batch = 0.6945s	
11795/28500 (epoch 20.693), train_loss = 0.98037500, grad/param norm = 1.7272e-01, time/batch = 0.6985s	
11796/28500 (epoch 20.695), train_loss = 0.78466356, grad/param norm = 1.7332e-01, time/batch = 0.6938s	
11797/28500 (epoch 20.696), train_loss = 1.00790796, grad/param norm = 1.6024e-01, time/batch = 0.6947s	
11798/28500 (epoch 20.698), train_loss = 1.00376482, grad/param norm = 1.5695e-01, time/batch = 0.7022s	
11799/28500 (epoch 20.700), train_loss = 1.03224866, grad/param norm = 1.6705e-01, time/batch = 0.6979s	
11800/28500 (epoch 20.702), train_loss = 1.06923866, grad/param norm = 1.6494e-01, time/batch = 0.7010s	
11801/28500 (epoch 20.704), train_loss = 1.05306442, grad/param norm = 1.6484e-01, time/batch = 0.7014s	
11802/28500 (epoch 20.705), train_loss = 1.12837420, grad/param norm = 1.9964e-01, time/batch = 0.6965s	
11803/28500 (epoch 20.707), train_loss = 0.95010284, grad/param norm = 1.6662e-01, time/batch = 0.6992s	
11804/28500 (epoch 20.709), train_loss = 1.15065320, grad/param norm = 1.6857e-01, time/batch = 0.6989s	
11805/28500 (epoch 20.711), train_loss = 0.93383855, grad/param norm = 1.6319e-01, time/batch = 0.6932s	
11806/28500 (epoch 20.712), train_loss = 1.05196232, grad/param norm = 1.6437e-01, time/batch = 0.6956s	
11807/28500 (epoch 20.714), train_loss = 1.14158954, grad/param norm = 1.6398e-01, time/batch = 0.6930s	
11808/28500 (epoch 20.716), train_loss = 0.99981093, grad/param norm = 1.5954e-01, time/batch = 0.7001s	
11809/28500 (epoch 20.718), train_loss = 1.02302106, grad/param norm = 1.5358e-01, time/batch = 0.6954s	
11810/28500 (epoch 20.719), train_loss = 1.04445137, grad/param norm = 1.6473e-01, time/batch = 0.6940s	
11811/28500 (epoch 20.721), train_loss = 0.84454768, grad/param norm = 1.5828e-01, time/batch = 0.6965s	
11812/28500 (epoch 20.723), train_loss = 1.02104221, grad/param norm = 1.6497e-01, time/batch = 0.6943s	
11813/28500 (epoch 20.725), train_loss = 1.09693682, grad/param norm = 1.5281e-01, time/batch = 0.6958s	
11814/28500 (epoch 20.726), train_loss = 1.01750367, grad/param norm = 1.5880e-01, time/batch = 0.6954s	
11815/28500 (epoch 20.728), train_loss = 0.92241662, grad/param norm = 1.4381e-01, time/batch = 0.7018s	
11816/28500 (epoch 20.730), train_loss = 1.01962572, grad/param norm = 1.6639e-01, time/batch = 0.6969s	
11817/28500 (epoch 20.732), train_loss = 0.85347896, grad/param norm = 1.3595e-01, time/batch = 0.7161s	
11818/28500 (epoch 20.733), train_loss = 0.85254049, grad/param norm = 1.4035e-01, time/batch = 0.6948s	
11819/28500 (epoch 20.735), train_loss = 0.88729323, grad/param norm = 1.5238e-01, time/batch = 0.6990s	
11820/28500 (epoch 20.737), train_loss = 0.80148774, grad/param norm = 1.3966e-01, time/batch = 0.6981s	
11821/28500 (epoch 20.739), train_loss = 0.95703290, grad/param norm = 1.6536e-01, time/batch = 0.6993s	
11822/28500 (epoch 20.740), train_loss = 1.00075368, grad/param norm = 1.5528e-01, time/batch = 0.6956s	
11823/28500 (epoch 20.742), train_loss = 0.93618747, grad/param norm = 1.4489e-01, time/batch = 0.7017s	
11824/28500 (epoch 20.744), train_loss = 1.04839690, grad/param norm = 1.7165e-01, time/batch = 0.6952s	
11825/28500 (epoch 20.746), train_loss = 0.92516445, grad/param norm = 1.4975e-01, time/batch = 0.6988s	
11826/28500 (epoch 20.747), train_loss = 0.93268745, grad/param norm = 1.4873e-01, time/batch = 0.6997s	
11827/28500 (epoch 20.749), train_loss = 1.11635780, grad/param norm = 1.9019e-01, time/batch = 0.6967s	
11828/28500 (epoch 20.751), train_loss = 0.90460143, grad/param norm = 1.6306e-01, time/batch = 0.6986s	
11829/28500 (epoch 20.753), train_loss = 0.96752465, grad/param norm = 1.4175e-01, time/batch = 0.6980s	
11830/28500 (epoch 20.754), train_loss = 0.88881259, grad/param norm = 1.4960e-01, time/batch = 0.6998s	
11831/28500 (epoch 20.756), train_loss = 1.10551333, grad/param norm = 1.5825e-01, time/batch = 0.7018s	
11832/28500 (epoch 20.758), train_loss = 1.08692928, grad/param norm = 1.7764e-01, time/batch = 0.6966s	
11833/28500 (epoch 20.760), train_loss = 0.88976950, grad/param norm = 1.6047e-01, time/batch = 0.6986s	
11834/28500 (epoch 20.761), train_loss = 0.94076290, grad/param norm = 1.7873e-01, time/batch = 0.6985s	
11835/28500 (epoch 20.763), train_loss = 0.82191017, grad/param norm = 1.4571e-01, time/batch = 0.7014s	
11836/28500 (epoch 20.765), train_loss = 0.97234363, grad/param norm = 1.5163e-01, time/batch = 0.6963s	
11837/28500 (epoch 20.767), train_loss = 0.85937491, grad/param norm = 1.3869e-01, time/batch = 0.6998s	
11838/28500 (epoch 20.768), train_loss = 1.06807625, grad/param norm = 1.5823e-01, time/batch = 0.6979s	
11839/28500 (epoch 20.770), train_loss = 0.87318472, grad/param norm = 1.3866e-01, time/batch = 0.6967s	
11840/28500 (epoch 20.772), train_loss = 0.76904973, grad/param norm = 1.3631e-01, time/batch = 0.6981s	
11841/28500 (epoch 20.774), train_loss = 1.00928190, grad/param norm = 1.6442e-01, time/batch = 0.6990s	
11842/28500 (epoch 20.775), train_loss = 1.07898414, grad/param norm = 1.5191e-01, time/batch = 0.6988s	
11843/28500 (epoch 20.777), train_loss = 1.07310706, grad/param norm = 1.5731e-01, time/batch = 0.6972s	
11844/28500 (epoch 20.779), train_loss = 0.83115842, grad/param norm = 1.3741e-01, time/batch = 0.6970s	
11845/28500 (epoch 20.781), train_loss = 0.98305571, grad/param norm = 1.6120e-01, time/batch = 0.6973s	
11846/28500 (epoch 20.782), train_loss = 1.07541802, grad/param norm = 1.7110e-01, time/batch = 0.6969s	
11847/28500 (epoch 20.784), train_loss = 0.82846991, grad/param norm = 1.4538e-01, time/batch = 0.6995s	
11848/28500 (epoch 20.786), train_loss = 0.89641478, grad/param norm = 1.5366e-01, time/batch = 0.6983s	
11849/28500 (epoch 20.788), train_loss = 0.98102408, grad/param norm = 1.5758e-01, time/batch = 0.6974s	
11850/28500 (epoch 20.789), train_loss = 0.74864682, grad/param norm = 1.7302e-01, time/batch = 0.6974s	
11851/28500 (epoch 20.791), train_loss = 1.00549946, grad/param norm = 1.5381e-01, time/batch = 0.7013s	
11852/28500 (epoch 20.793), train_loss = 0.99735881, grad/param norm = 1.7643e-01, time/batch = 0.6980s	
11853/28500 (epoch 20.795), train_loss = 1.02026302, grad/param norm = 1.5600e-01, time/batch = 0.6963s	
11854/28500 (epoch 20.796), train_loss = 0.88909011, grad/param norm = 1.5283e-01, time/batch = 0.6977s	
11855/28500 (epoch 20.798), train_loss = 0.83059639, grad/param norm = 1.4294e-01, time/batch = 0.6993s	
11856/28500 (epoch 20.800), train_loss = 0.88431046, grad/param norm = 1.6169e-01, time/batch = 0.6978s	
11857/28500 (epoch 20.802), train_loss = 0.98933903, grad/param norm = 2.1900e-01, time/batch = 0.6992s	
11858/28500 (epoch 20.804), train_loss = 1.01958302, grad/param norm = 1.5835e-01, time/batch = 0.6975s	
11859/28500 (epoch 20.805), train_loss = 1.00020633, grad/param norm = 1.6713e-01, time/batch = 0.6966s	
11860/28500 (epoch 20.807), train_loss = 1.03413481, grad/param norm = 1.7128e-01, time/batch = 0.6977s	
11861/28500 (epoch 20.809), train_loss = 0.95428176, grad/param norm = 1.5972e-01, time/batch = 0.6993s	
11862/28500 (epoch 20.811), train_loss = 1.04701918, grad/param norm = 1.6751e-01, time/batch = 0.6999s	
11863/28500 (epoch 20.812), train_loss = 1.02728461, grad/param norm = 1.7293e-01, time/batch = 0.6991s	
11864/28500 (epoch 20.814), train_loss = 0.96070802, grad/param norm = 1.6959e-01, time/batch = 0.6982s	
11865/28500 (epoch 20.816), train_loss = 1.08123484, grad/param norm = 1.8414e-01, time/batch = 0.6962s	
11866/28500 (epoch 20.818), train_loss = 1.11467693, grad/param norm = 1.9420e-01, time/batch = 0.6989s	
11867/28500 (epoch 20.819), train_loss = 0.99985576, grad/param norm = 1.4579e-01, time/batch = 0.6962s	
11868/28500 (epoch 20.821), train_loss = 0.97161195, grad/param norm = 1.5574e-01, time/batch = 0.6997s	
11869/28500 (epoch 20.823), train_loss = 1.15892045, grad/param norm = 1.8750e-01, time/batch = 0.7007s	
11870/28500 (epoch 20.825), train_loss = 0.96971076, grad/param norm = 1.7306e-01, time/batch = 0.7033s	
11871/28500 (epoch 20.826), train_loss = 1.00370329, grad/param norm = 1.6967e-01, time/batch = 0.7159s	
11872/28500 (epoch 20.828), train_loss = 0.88638976, grad/param norm = 2.9573e-01, time/batch = 0.7187s	
11873/28500 (epoch 20.830), train_loss = 0.96365740, grad/param norm = 1.5031e-01, time/batch = 0.7132s	
11874/28500 (epoch 20.832), train_loss = 1.00771391, grad/param norm = 2.0516e-01, time/batch = 0.7240s	
11875/28500 (epoch 20.833), train_loss = 1.10660143, grad/param norm = 1.6471e-01, time/batch = 0.7234s	
11876/28500 (epoch 20.835), train_loss = 0.92369447, grad/param norm = 1.5543e-01, time/batch = 0.7205s	
11877/28500 (epoch 20.837), train_loss = 0.87476265, grad/param norm = 1.5769e-01, time/batch = 0.7080s	
11878/28500 (epoch 20.839), train_loss = 1.13860730, grad/param norm = 1.8692e-01, time/batch = 0.7085s	
11879/28500 (epoch 20.840), train_loss = 1.15524611, grad/param norm = 1.8171e-01, time/batch = 0.7085s	
11880/28500 (epoch 20.842), train_loss = 1.09924397, grad/param norm = 1.8672e-01, time/batch = 0.7273s	
11881/28500 (epoch 20.844), train_loss = 1.04104745, grad/param norm = 1.7317e-01, time/batch = 0.7167s	
11882/28500 (epoch 20.846), train_loss = 1.14454260, grad/param norm = 1.8130e-01, time/batch = 0.7248s	
11883/28500 (epoch 20.847), train_loss = 0.95928461, grad/param norm = 1.6659e-01, time/batch = 0.7147s	
11884/28500 (epoch 20.849), train_loss = 0.95980203, grad/param norm = 1.5857e-01, time/batch = 0.6977s	
11885/28500 (epoch 20.851), train_loss = 0.84417085, grad/param norm = 1.4406e-01, time/batch = 0.6991s	
11886/28500 (epoch 20.853), train_loss = 1.01155480, grad/param norm = 1.5709e-01, time/batch = 0.6964s	
11887/28500 (epoch 20.854), train_loss = 1.03467916, grad/param norm = 1.6783e-01, time/batch = 0.6972s	
11888/28500 (epoch 20.856), train_loss = 1.14309520, grad/param norm = 1.8573e-01, time/batch = 0.6977s	
11889/28500 (epoch 20.858), train_loss = 0.91975956, grad/param norm = 1.5548e-01, time/batch = 0.6986s	
11890/28500 (epoch 20.860), train_loss = 0.97774193, grad/param norm = 1.6300e-01, time/batch = 0.6930s	
11891/28500 (epoch 20.861), train_loss = 1.04871227, grad/param norm = 1.7836e-01, time/batch = 0.7038s	
11892/28500 (epoch 20.863), train_loss = 1.07256521, grad/param norm = 1.8945e-01, time/batch = 0.6942s	
11893/28500 (epoch 20.865), train_loss = 0.96837576, grad/param norm = 1.7397e-01, time/batch = 0.6963s	
11894/28500 (epoch 20.867), train_loss = 1.06248506, grad/param norm = 1.7463e-01, time/batch = 0.6932s	
11895/28500 (epoch 20.868), train_loss = 0.88375757, grad/param norm = 1.4873e-01, time/batch = 0.6969s	
11896/28500 (epoch 20.870), train_loss = 0.86199501, grad/param norm = 1.5153e-01, time/batch = 0.6959s	
11897/28500 (epoch 20.872), train_loss = 1.04472065, grad/param norm = 1.9541e-01, time/batch = 0.6939s	
11898/28500 (epoch 20.874), train_loss = 0.96739200, grad/param norm = 1.7392e-01, time/batch = 0.6950s	
11899/28500 (epoch 20.875), train_loss = 1.12906460, grad/param norm = 1.9007e-01, time/batch = 0.6930s	
11900/28500 (epoch 20.877), train_loss = 1.04256787, grad/param norm = 1.6949e-01, time/batch = 0.6950s	
11901/28500 (epoch 20.879), train_loss = 1.04913568, grad/param norm = 1.5100e-01, time/batch = 0.6952s	
11902/28500 (epoch 20.881), train_loss = 1.04298346, grad/param norm = 1.6142e-01, time/batch = 0.6957s	
11903/28500 (epoch 20.882), train_loss = 0.94246689, grad/param norm = 1.5631e-01, time/batch = 0.6933s	
11904/28500 (epoch 20.884), train_loss = 1.01025632, grad/param norm = 1.6882e-01, time/batch = 0.6957s	
11905/28500 (epoch 20.886), train_loss = 0.98436947, grad/param norm = 1.5783e-01, time/batch = 0.6932s	
11906/28500 (epoch 20.888), train_loss = 0.91462239, grad/param norm = 1.5600e-01, time/batch = 0.6953s	
11907/28500 (epoch 20.889), train_loss = 1.00289211, grad/param norm = 1.6243e-01, time/batch = 0.6928s	
11908/28500 (epoch 20.891), train_loss = 0.98622480, grad/param norm = 1.5453e-01, time/batch = 0.7011s	
11909/28500 (epoch 20.893), train_loss = 0.95021867, grad/param norm = 1.5676e-01, time/batch = 0.6938s	
11910/28500 (epoch 20.895), train_loss = 1.19021128, grad/param norm = 1.9103e-01, time/batch = 0.6965s	
11911/28500 (epoch 20.896), train_loss = 1.11478637, grad/param norm = 1.8184e-01, time/batch = 0.6955s	
11912/28500 (epoch 20.898), train_loss = 1.01955991, grad/param norm = 1.6486e-01, time/batch = 0.6964s	
11913/28500 (epoch 20.900), train_loss = 0.87068408, grad/param norm = 1.5588e-01, time/batch = 0.6954s	
11914/28500 (epoch 20.902), train_loss = 0.91110988, grad/param norm = 1.7259e-01, time/batch = 0.6965s	
11915/28500 (epoch 20.904), train_loss = 0.89924711, grad/param norm = 1.6051e-01, time/batch = 0.6936s	
11916/28500 (epoch 20.905), train_loss = 0.98426086, grad/param norm = 1.5843e-01, time/batch = 0.6965s	
11917/28500 (epoch 20.907), train_loss = 0.97245343, grad/param norm = 1.5589e-01, time/batch = 0.6941s	
11918/28500 (epoch 20.909), train_loss = 0.90247306, grad/param norm = 1.9019e-01, time/batch = 0.6949s	
11919/28500 (epoch 20.911), train_loss = 0.90606750, grad/param norm = 1.3985e-01, time/batch = 0.6930s	
11920/28500 (epoch 20.912), train_loss = 0.80311831, grad/param norm = 1.4179e-01, time/batch = 0.7009s	
11921/28500 (epoch 20.914), train_loss = 1.05981398, grad/param norm = 1.5064e-01, time/batch = 0.6975s	
11922/28500 (epoch 20.916), train_loss = 1.02043863, grad/param norm = 1.7180e-01, time/batch = 0.6972s	
11923/28500 (epoch 20.918), train_loss = 1.01179274, grad/param norm = 1.7414e-01, time/batch = 0.6963s	
11924/28500 (epoch 20.919), train_loss = 1.00034642, grad/param norm = 1.5541e-01, time/batch = 0.6972s	
11925/28500 (epoch 20.921), train_loss = 1.10023982, grad/param norm = 1.8566e-01, time/batch = 0.6995s	
11926/28500 (epoch 20.923), train_loss = 0.98925343, grad/param norm = 2.1540e-01, time/batch = 0.6975s	
11927/28500 (epoch 20.925), train_loss = 0.94485285, grad/param norm = 1.6812e-01, time/batch = 0.6991s	
11928/28500 (epoch 20.926), train_loss = 0.99344992, grad/param norm = 1.5873e-01, time/batch = 0.6975s	
11929/28500 (epoch 20.928), train_loss = 0.96666355, grad/param norm = 1.5767e-01, time/batch = 0.7091s	
11930/28500 (epoch 20.930), train_loss = 0.79021474, grad/param norm = 1.3879e-01, time/batch = 0.6998s	
11931/28500 (epoch 20.932), train_loss = 0.78865091, grad/param norm = 1.2705e-01, time/batch = 0.7021s	
11932/28500 (epoch 20.933), train_loss = 1.07092863, grad/param norm = 1.6356e-01, time/batch = 0.6970s	
11933/28500 (epoch 20.935), train_loss = 1.08600114, grad/param norm = 1.6863e-01, time/batch = 0.6991s	
11934/28500 (epoch 20.937), train_loss = 1.09695757, grad/param norm = 1.8983e-01, time/batch = 0.6974s	
11935/28500 (epoch 20.939), train_loss = 1.16788415, grad/param norm = 1.8267e-01, time/batch = 0.6981s	
11936/28500 (epoch 20.940), train_loss = 0.87777633, grad/param norm = 1.5980e-01, time/batch = 0.6964s	
11937/28500 (epoch 20.942), train_loss = 1.00700743, grad/param norm = 1.5007e-01, time/batch = 0.7003s	
11938/28500 (epoch 20.944), train_loss = 0.94747946, grad/param norm = 1.5899e-01, time/batch = 0.6969s	
11939/28500 (epoch 20.946), train_loss = 1.09595650, grad/param norm = 1.6282e-01, time/batch = 0.7037s	
11940/28500 (epoch 20.947), train_loss = 1.29863135, grad/param norm = 2.0284e-01, time/batch = 0.6997s	
11941/28500 (epoch 20.949), train_loss = 0.94188433, grad/param norm = 1.6091e-01, time/batch = 0.7069s	
11942/28500 (epoch 20.951), train_loss = 1.18604376, grad/param norm = 1.9315e-01, time/batch = 0.7016s	
11943/28500 (epoch 20.953), train_loss = 1.15769814, grad/param norm = 2.0218e-01, time/batch = 0.7026s	
11944/28500 (epoch 20.954), train_loss = 1.12860281, grad/param norm = 1.7627e-01, time/batch = 0.6990s	
11945/28500 (epoch 20.956), train_loss = 1.04499958, grad/param norm = 2.1325e-01, time/batch = 0.7012s	
11946/28500 (epoch 20.958), train_loss = 1.20377643, grad/param norm = 1.6988e-01, time/batch = 0.6987s	
11947/28500 (epoch 20.960), train_loss = 0.92547768, grad/param norm = 1.5475e-01, time/batch = 0.6987s	
11948/28500 (epoch 20.961), train_loss = 1.21239458, grad/param norm = 2.0627e-01, time/batch = 0.6975s	
11949/28500 (epoch 20.963), train_loss = 1.14307824, grad/param norm = 2.0866e-01, time/batch = 0.6986s	
11950/28500 (epoch 20.965), train_loss = 0.92844098, grad/param norm = 1.6321e-01, time/batch = 0.6967s	
11951/28500 (epoch 20.967), train_loss = 0.91234681, grad/param norm = 1.4379e-01, time/batch = 0.6993s	
11952/28500 (epoch 20.968), train_loss = 0.87557768, grad/param norm = 1.3503e-01, time/batch = 0.7007s	
11953/28500 (epoch 20.970), train_loss = 0.93940278, grad/param norm = 1.6414e-01, time/batch = 0.6965s	
11954/28500 (epoch 20.972), train_loss = 1.01367018, grad/param norm = 1.7011e-01, time/batch = 0.7033s	
11955/28500 (epoch 20.974), train_loss = 1.19471193, grad/param norm = 1.7757e-01, time/batch = 0.7076s	
11956/28500 (epoch 20.975), train_loss = 0.94592625, grad/param norm = 1.7275e-01, time/batch = 0.6995s	
11957/28500 (epoch 20.977), train_loss = 1.12281551, grad/param norm = 1.7565e-01, time/batch = 0.6944s	
11958/28500 (epoch 20.979), train_loss = 0.98497449, grad/param norm = 1.6990e-01, time/batch = 0.6950s	
11959/28500 (epoch 20.981), train_loss = 0.92124122, grad/param norm = 1.6430e-01, time/batch = 0.6936s	
11960/28500 (epoch 20.982), train_loss = 0.99305067, grad/param norm = 1.5366e-01, time/batch = 0.6953s	
11961/28500 (epoch 20.984), train_loss = 1.07843224, grad/param norm = 1.6234e-01, time/batch = 0.6983s	
11962/28500 (epoch 20.986), train_loss = 1.24090463, grad/param norm = 1.7999e-01, time/batch = 0.7012s	
11963/28500 (epoch 20.988), train_loss = 0.86389485, grad/param norm = 1.4523e-01, time/batch = 0.7015s	
11964/28500 (epoch 20.989), train_loss = 1.05003893, grad/param norm = 1.6801e-01, time/batch = 0.6996s	
11965/28500 (epoch 20.991), train_loss = 0.93775435, grad/param norm = 1.6506e-01, time/batch = 0.6978s	
11966/28500 (epoch 20.993), train_loss = 0.94008362, grad/param norm = 1.5768e-01, time/batch = 0.7008s	
11967/28500 (epoch 20.995), train_loss = 0.94278560, grad/param norm = 1.6056e-01, time/batch = 0.7021s	
11968/28500 (epoch 20.996), train_loss = 0.89865611, grad/param norm = 1.5656e-01, time/batch = 0.6963s	
11969/28500 (epoch 20.998), train_loss = 1.12074310, grad/param norm = 1.9024e-01, time/batch = 0.7024s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
11970/28500 (epoch 21.000), train_loss = 0.96575104, grad/param norm = 1.5855e-01, time/batch = 0.6982s	
11971/28500 (epoch 21.002), train_loss = 1.16242198, grad/param norm = 1.8221e-01, time/batch = 0.6995s	
11972/28500 (epoch 21.004), train_loss = 0.95844519, grad/param norm = 1.5719e-01, time/batch = 0.7213s	
11973/28500 (epoch 21.005), train_loss = 1.13256714, grad/param norm = 1.8899e-01, time/batch = 0.6997s	
11974/28500 (epoch 21.007), train_loss = 0.90085843, grad/param norm = 1.4299e-01, time/batch = 0.7050s	
11975/28500 (epoch 21.009), train_loss = 1.04775786, grad/param norm = 1.7593e-01, time/batch = 0.6995s	
11976/28500 (epoch 21.011), train_loss = 0.93374393, grad/param norm = 1.8236e-01, time/batch = 0.6983s	
11977/28500 (epoch 21.012), train_loss = 0.88885496, grad/param norm = 1.3516e-01, time/batch = 0.7103s	
11978/28500 (epoch 21.014), train_loss = 0.90627981, grad/param norm = 1.5458e-01, time/batch = 0.7127s	
11979/28500 (epoch 21.016), train_loss = 0.95012293, grad/param norm = 1.4253e-01, time/batch = 0.7078s	
11980/28500 (epoch 21.018), train_loss = 1.01073606, grad/param norm = 1.7931e-01, time/batch = 0.7083s	
11981/28500 (epoch 21.019), train_loss = 1.06670490, grad/param norm = 1.7116e-01, time/batch = 0.7014s	
11982/28500 (epoch 21.021), train_loss = 1.08797622, grad/param norm = 1.5554e-01, time/batch = 0.6993s	
11983/28500 (epoch 21.023), train_loss = 0.99474311, grad/param norm = 1.5866e-01, time/batch = 0.7060s	
11984/28500 (epoch 21.025), train_loss = 1.02035623, grad/param norm = 1.5191e-01, time/batch = 0.6963s	
11985/28500 (epoch 21.026), train_loss = 0.98952058, grad/param norm = 1.5540e-01, time/batch = 0.7046s	
11986/28500 (epoch 21.028), train_loss = 1.03788929, grad/param norm = 1.7175e-01, time/batch = 0.7154s	
11987/28500 (epoch 21.030), train_loss = 1.06090263, grad/param norm = 1.7367e-01, time/batch = 0.7214s	
11988/28500 (epoch 21.032), train_loss = 1.09888374, grad/param norm = 1.6001e-01, time/batch = 0.7164s	
11989/28500 (epoch 21.033), train_loss = 1.17834535, grad/param norm = 1.9232e-01, time/batch = 0.7087s	
11990/28500 (epoch 21.035), train_loss = 1.01896536, grad/param norm = 1.7300e-01, time/batch = 0.7026s	
11991/28500 (epoch 21.037), train_loss = 1.08943746, grad/param norm = 1.6202e-01, time/batch = 0.7065s	
11992/28500 (epoch 21.039), train_loss = 1.12567270, grad/param norm = 1.8142e-01, time/batch = 0.7181s	
11993/28500 (epoch 21.040), train_loss = 1.13297807, grad/param norm = 1.6622e-01, time/batch = 0.7182s	
11994/28500 (epoch 21.042), train_loss = 1.08689232, grad/param norm = 1.6670e-01, time/batch = 0.6966s	
11995/28500 (epoch 21.044), train_loss = 1.00481054, grad/param norm = 1.5545e-01, time/batch = 0.7024s	
11996/28500 (epoch 21.046), train_loss = 1.24369336, grad/param norm = 1.8111e-01, time/batch = 0.7126s	
11997/28500 (epoch 21.047), train_loss = 1.15380107, grad/param norm = 1.8742e-01, time/batch = 0.6944s	
11998/28500 (epoch 21.049), train_loss = 1.02545158, grad/param norm = 1.6477e-01, time/batch = 0.6971s	
11999/28500 (epoch 21.051), train_loss = 1.00829877, grad/param norm = 1.5629e-01, time/batch = 0.6984s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch21.05_1.6960.t7	
12000/28500 (epoch 21.053), train_loss = 1.01099695, grad/param norm = 1.6329e-01, time/batch = 0.7049s	
12001/28500 (epoch 21.054), train_loss = 1.37529799, grad/param norm = 2.0243e-01, time/batch = 0.7035s	
12002/28500 (epoch 21.056), train_loss = 0.92908324, grad/param norm = 1.5345e-01, time/batch = 0.7047s	
12003/28500 (epoch 21.058), train_loss = 0.92904091, grad/param norm = 1.7157e-01, time/batch = 0.7129s	
12004/28500 (epoch 21.060), train_loss = 1.11115906, grad/param norm = 1.6786e-01, time/batch = 0.6953s	
12005/28500 (epoch 21.061), train_loss = 1.02751237, grad/param norm = 1.7371e-01, time/batch = 0.6979s	
12006/28500 (epoch 21.063), train_loss = 1.08538104, grad/param norm = 1.6645e-01, time/batch = 0.6956s	
12007/28500 (epoch 21.065), train_loss = 1.10006231, grad/param norm = 1.9073e-01, time/batch = 0.6976s	
12008/28500 (epoch 21.067), train_loss = 0.99446187, grad/param norm = 1.5306e-01, time/batch = 0.6948s	
12009/28500 (epoch 21.068), train_loss = 1.00012808, grad/param norm = 1.5162e-01, time/batch = 0.6926s	
12010/28500 (epoch 21.070), train_loss = 1.07519335, grad/param norm = 1.8192e-01, time/batch = 0.6950s	
12011/28500 (epoch 21.072), train_loss = 1.17803042, grad/param norm = 1.7603e-01, time/batch = 0.6907s	
12012/28500 (epoch 21.074), train_loss = 1.03095037, grad/param norm = 1.4579e-01, time/batch = 0.6934s	
12013/28500 (epoch 21.075), train_loss = 0.98165304, grad/param norm = 1.3925e-01, time/batch = 0.6907s	
12014/28500 (epoch 21.077), train_loss = 1.07993338, grad/param norm = 1.6398e-01, time/batch = 0.6918s	
12015/28500 (epoch 21.079), train_loss = 1.04629421, grad/param norm = 1.6849e-01, time/batch = 0.6894s	
12016/28500 (epoch 21.081), train_loss = 1.14216892, grad/param norm = 1.7662e-01, time/batch = 0.6922s	
12017/28500 (epoch 21.082), train_loss = 1.05749012, grad/param norm = 1.8620e-01, time/batch = 0.6898s	
12018/28500 (epoch 21.084), train_loss = 1.06397356, grad/param norm = 1.6885e-01, time/batch = 0.6922s	
12019/28500 (epoch 21.086), train_loss = 1.00109801, grad/param norm = 1.8317e-01, time/batch = 0.6921s	
12020/28500 (epoch 21.088), train_loss = 0.96919432, grad/param norm = 1.7947e-01, time/batch = 0.6920s	
12021/28500 (epoch 21.089), train_loss = 1.11542307, grad/param norm = 1.5486e-01, time/batch = 0.6928s	
12022/28500 (epoch 21.091), train_loss = 0.90326718, grad/param norm = 1.4937e-01, time/batch = 0.6929s	
12023/28500 (epoch 21.093), train_loss = 1.07176189, grad/param norm = 1.5405e-01, time/batch = 0.6902s	
12024/28500 (epoch 21.095), train_loss = 0.97958161, grad/param norm = 1.5145e-01, time/batch = 0.7054s	
12025/28500 (epoch 21.096), train_loss = 1.14539052, grad/param norm = 1.7629e-01, time/batch = 0.7041s	
12026/28500 (epoch 21.098), train_loss = 1.04512601, grad/param norm = 1.7609e-01, time/batch = 0.6925s	
12027/28500 (epoch 21.100), train_loss = 0.98261542, grad/param norm = 1.6013e-01, time/batch = 0.6923s	
12028/28500 (epoch 21.102), train_loss = 1.10334371, grad/param norm = 1.7036e-01, time/batch = 0.6940s	
12029/28500 (epoch 21.104), train_loss = 1.00456414, grad/param norm = 1.7638e-01, time/batch = 0.6889s	
12030/28500 (epoch 21.105), train_loss = 1.16535789, grad/param norm = 1.6543e-01, time/batch = 0.7002s	
12031/28500 (epoch 21.107), train_loss = 0.90951234, grad/param norm = 1.4766e-01, time/batch = 0.6969s	
12032/28500 (epoch 21.109), train_loss = 0.90768932, grad/param norm = 1.6515e-01, time/batch = 0.6974s	
12033/28500 (epoch 21.111), train_loss = 0.97191126, grad/param norm = 1.7062e-01, time/batch = 0.6966s	
12034/28500 (epoch 21.112), train_loss = 1.07885825, grad/param norm = 1.6042e-01, time/batch = 0.7144s	
12035/28500 (epoch 21.114), train_loss = 1.00246046, grad/param norm = 1.6396e-01, time/batch = 0.7056s	
12036/28500 (epoch 21.116), train_loss = 1.18261346, grad/param norm = 1.8115e-01, time/batch = 0.7020s	
12037/28500 (epoch 21.118), train_loss = 0.89648172, grad/param norm = 1.6595e-01, time/batch = 0.6944s	
12038/28500 (epoch 21.119), train_loss = 1.04013321, grad/param norm = 1.9987e-01, time/batch = 0.6943s	
12039/28500 (epoch 21.121), train_loss = 1.18487017, grad/param norm = 2.0150e-01, time/batch = 0.6922s	
12040/28500 (epoch 21.123), train_loss = 1.10572171, grad/param norm = 1.7492e-01, time/batch = 0.6929s	
12041/28500 (epoch 21.125), train_loss = 1.02647562, grad/param norm = 1.6490e-01, time/batch = 0.6917s	
12042/28500 (epoch 21.126), train_loss = 1.01133791, grad/param norm = 1.5605e-01, time/batch = 0.6975s	
12043/28500 (epoch 21.128), train_loss = 1.01951684, grad/param norm = 1.6731e-01, time/batch = 0.6923s	
12044/28500 (epoch 21.130), train_loss = 0.92763213, grad/param norm = 1.6700e-01, time/batch = 0.6931s	
12045/28500 (epoch 21.132), train_loss = 1.05593167, grad/param norm = 1.7961e-01, time/batch = 0.6905s	
12046/28500 (epoch 21.133), train_loss = 1.09649011, grad/param norm = 1.7585e-01, time/batch = 0.6942s	
12047/28500 (epoch 21.135), train_loss = 0.97452686, grad/param norm = 1.4302e-01, time/batch = 0.6908s	
12048/28500 (epoch 21.137), train_loss = 1.02812994, grad/param norm = 1.7452e-01, time/batch = 0.6910s	
12049/28500 (epoch 21.139), train_loss = 0.99526001, grad/param norm = 1.4489e-01, time/batch = 0.6895s	
12050/28500 (epoch 21.140), train_loss = 1.04930012, grad/param norm = 1.5038e-01, time/batch = 0.6918s	
12051/28500 (epoch 21.142), train_loss = 1.00854820, grad/param norm = 1.7426e-01, time/batch = 0.6970s	
12052/28500 (epoch 21.144), train_loss = 0.96297364, grad/param norm = 1.4176e-01, time/batch = 0.6925s	
12053/28500 (epoch 21.146), train_loss = 0.97268712, grad/param norm = 1.4478e-01, time/batch = 0.6947s	
12054/28500 (epoch 21.147), train_loss = 0.88270518, grad/param norm = 1.4614e-01, time/batch = 0.6895s	
12055/28500 (epoch 21.149), train_loss = 0.88645143, grad/param norm = 1.5588e-01, time/batch = 0.6912s	
12056/28500 (epoch 21.151), train_loss = 0.96866184, grad/param norm = 1.5440e-01, time/batch = 0.6900s	
12057/28500 (epoch 21.153), train_loss = 1.02743482, grad/param norm = 1.7574e-01, time/batch = 0.6903s	
12058/28500 (epoch 21.154), train_loss = 0.92813073, grad/param norm = 1.5624e-01, time/batch = 0.6898s	
12059/28500 (epoch 21.156), train_loss = 1.12914912, grad/param norm = 1.8031e-01, time/batch = 0.6897s	
12060/28500 (epoch 21.158), train_loss = 1.03543985, grad/param norm = 1.5131e-01, time/batch = 0.6883s	
12061/28500 (epoch 21.160), train_loss = 0.91136054, grad/param norm = 1.4092e-01, time/batch = 0.6950s	
12062/28500 (epoch 21.161), train_loss = 0.97203528, grad/param norm = 1.6411e-01, time/batch = 0.6903s	
12063/28500 (epoch 21.163), train_loss = 0.88486941, grad/param norm = 1.5546e-01, time/batch = 0.6904s	
12064/28500 (epoch 21.165), train_loss = 1.22172869, grad/param norm = 1.6464e-01, time/batch = 0.6892s	
12065/28500 (epoch 21.167), train_loss = 1.22352543, grad/param norm = 1.9195e-01, time/batch = 0.6923s	
12066/28500 (epoch 21.168), train_loss = 1.15533777, grad/param norm = 1.8416e-01, time/batch = 0.6890s	
12067/28500 (epoch 21.170), train_loss = 1.13051376, grad/param norm = 2.2502e-01, time/batch = 0.6903s	
12068/28500 (epoch 21.172), train_loss = 1.01391610, grad/param norm = 1.5682e-01, time/batch = 0.6893s	
12069/28500 (epoch 21.174), train_loss = 1.19150706, grad/param norm = 1.9185e-01, time/batch = 0.6962s	
12070/28500 (epoch 21.175), train_loss = 1.03406466, grad/param norm = 1.6647e-01, time/batch = 0.6945s	
12071/28500 (epoch 21.177), train_loss = 1.08853208, grad/param norm = 1.7238e-01, time/batch = 0.6968s	
12072/28500 (epoch 21.179), train_loss = 1.05561463, grad/param norm = 1.7609e-01, time/batch = 0.6945s	
12073/28500 (epoch 21.181), train_loss = 1.09846963, grad/param norm = 1.7289e-01, time/batch = 0.6946s	
12074/28500 (epoch 21.182), train_loss = 1.00228273, grad/param norm = 1.5442e-01, time/batch = 0.6956s	
12075/28500 (epoch 21.184), train_loss = 1.18182752, grad/param norm = 1.7519e-01, time/batch = 0.6935s	
12076/28500 (epoch 21.186), train_loss = 1.13642428, grad/param norm = 1.6562e-01, time/batch = 0.6959s	
12077/28500 (epoch 21.188), train_loss = 1.06788319, grad/param norm = 1.8220e-01, time/batch = 0.6927s	
12078/28500 (epoch 21.189), train_loss = 1.03759620, grad/param norm = 1.5982e-01, time/batch = 0.7014s	
12079/28500 (epoch 21.191), train_loss = 1.25413482, grad/param norm = 1.8087e-01, time/batch = 0.6940s	
12080/28500 (epoch 21.193), train_loss = 1.10214120, grad/param norm = 1.9538e-01, time/batch = 0.6945s	
12081/28500 (epoch 21.195), train_loss = 1.17139703, grad/param norm = 1.7284e-01, time/batch = 0.6964s	
12082/28500 (epoch 21.196), train_loss = 1.09727984, grad/param norm = 1.7273e-01, time/batch = 0.6984s	
12083/28500 (epoch 21.198), train_loss = 1.06509100, grad/param norm = 1.7450e-01, time/batch = 0.6935s	
12084/28500 (epoch 21.200), train_loss = 1.10334302, grad/param norm = 1.6965e-01, time/batch = 0.7028s	
12085/28500 (epoch 21.202), train_loss = 1.05220166, grad/param norm = 1.5630e-01, time/batch = 0.6956s	
12086/28500 (epoch 21.204), train_loss = 0.97755966, grad/param norm = 1.4146e-01, time/batch = 0.6966s	
12087/28500 (epoch 21.205), train_loss = 0.99240896, grad/param norm = 1.6452e-01, time/batch = 0.6937s	
12088/28500 (epoch 21.207), train_loss = 0.95845906, grad/param norm = 1.6897e-01, time/batch = 0.6952s	
12089/28500 (epoch 21.209), train_loss = 1.04002759, grad/param norm = 1.5012e-01, time/batch = 0.6968s	
12090/28500 (epoch 21.211), train_loss = 0.90362889, grad/param norm = 1.6919e-01, time/batch = 0.6974s	
12091/28500 (epoch 21.212), train_loss = 0.87646060, grad/param norm = 1.4499e-01, time/batch = 0.6983s	
12092/28500 (epoch 21.214), train_loss = 1.02647119, grad/param norm = 1.7749e-01, time/batch = 0.6952s	
12093/28500 (epoch 21.216), train_loss = 0.93516389, grad/param norm = 1.4810e-01, time/batch = 0.7074s	
12094/28500 (epoch 21.218), train_loss = 1.13692955, grad/param norm = 1.4579e-01, time/batch = 0.7043s	
12095/28500 (epoch 21.219), train_loss = 1.06782969, grad/param norm = 1.6422e-01, time/batch = 0.7005s	
12096/28500 (epoch 21.221), train_loss = 0.89958261, grad/param norm = 1.6434e-01, time/batch = 0.6943s	
12097/28500 (epoch 21.223), train_loss = 1.16199884, grad/param norm = 1.7271e-01, time/batch = 0.6968s	
12098/28500 (epoch 21.225), train_loss = 1.15690560, grad/param norm = 1.8132e-01, time/batch = 0.6970s	
12099/28500 (epoch 21.226), train_loss = 0.98199414, grad/param norm = 1.5069e-01, time/batch = 0.6940s	
12100/28500 (epoch 21.228), train_loss = 1.14329119, grad/param norm = 1.6396e-01, time/batch = 0.7040s	
12101/28500 (epoch 21.230), train_loss = 1.10447180, grad/param norm = 1.5878e-01, time/batch = 0.6960s	
12102/28500 (epoch 21.232), train_loss = 1.06319616, grad/param norm = 1.5952e-01, time/batch = 0.6982s	
12103/28500 (epoch 21.233), train_loss = 1.06968224, grad/param norm = 1.9217e-01, time/batch = 0.7022s	
12104/28500 (epoch 21.235), train_loss = 1.00789350, grad/param norm = 1.4528e-01, time/batch = 0.6980s	
12105/28500 (epoch 21.237), train_loss = 0.91527725, grad/param norm = 1.4210e-01, time/batch = 0.6936s	
12106/28500 (epoch 21.239), train_loss = 0.96299699, grad/param norm = 1.4446e-01, time/batch = 0.6976s	
12107/28500 (epoch 21.240), train_loss = 0.91948480, grad/param norm = 1.5740e-01, time/batch = 0.6928s	
12108/28500 (epoch 21.242), train_loss = 1.06243019, grad/param norm = 1.7510e-01, time/batch = 0.6929s	
12109/28500 (epoch 21.244), train_loss = 1.07372172, grad/param norm = 1.4984e-01, time/batch = 0.6934s	
12110/28500 (epoch 21.246), train_loss = 1.12292443, grad/param norm = 1.6515e-01, time/batch = 0.6929s	
12111/28500 (epoch 21.247), train_loss = 1.18927404, grad/param norm = 1.7643e-01, time/batch = 0.7044s	
12112/28500 (epoch 21.249), train_loss = 1.04598328, grad/param norm = 1.5856e-01, time/batch = 0.6963s	
12113/28500 (epoch 21.251), train_loss = 0.98034099, grad/param norm = 1.4852e-01, time/batch = 0.6933s	
12114/28500 (epoch 21.253), train_loss = 1.16599484, grad/param norm = 1.7977e-01, time/batch = 0.6947s	
12115/28500 (epoch 21.254), train_loss = 1.16953087, grad/param norm = 1.6600e-01, time/batch = 0.6934s	
12116/28500 (epoch 21.256), train_loss = 0.96387312, grad/param norm = 1.5431e-01, time/batch = 0.6922s	
12117/28500 (epoch 21.258), train_loss = 1.03548015, grad/param norm = 1.8316e-01, time/batch = 0.6986s	
12118/28500 (epoch 21.260), train_loss = 0.98087923, grad/param norm = 1.5495e-01, time/batch = 0.6966s	
12119/28500 (epoch 21.261), train_loss = 0.95881640, grad/param norm = 1.5795e-01, time/batch = 0.7121s	
12120/28500 (epoch 21.263), train_loss = 1.14740878, grad/param norm = 1.8064e-01, time/batch = 0.6924s	
12121/28500 (epoch 21.265), train_loss = 1.04423287, grad/param norm = 1.7272e-01, time/batch = 0.7003s	
12122/28500 (epoch 21.267), train_loss = 1.16967056, grad/param norm = 1.7083e-01, time/batch = 0.6934s	
12123/28500 (epoch 21.268), train_loss = 1.07864247, grad/param norm = 1.5266e-01, time/batch = 0.6966s	
12124/28500 (epoch 21.270), train_loss = 1.07790407, grad/param norm = 1.7273e-01, time/batch = 0.6924s	
12125/28500 (epoch 21.272), train_loss = 1.00649643, grad/param norm = 1.5867e-01, time/batch = 0.6943s	
12126/28500 (epoch 21.274), train_loss = 1.14637566, grad/param norm = 1.6729e-01, time/batch = 0.6923s	
12127/28500 (epoch 21.275), train_loss = 1.06189036, grad/param norm = 1.5325e-01, time/batch = 0.6961s	
12128/28500 (epoch 21.277), train_loss = 1.05620765, grad/param norm = 1.7768e-01, time/batch = 0.6951s	
12129/28500 (epoch 21.279), train_loss = 1.08097484, grad/param norm = 1.7383e-01, time/batch = 0.6920s	
12130/28500 (epoch 21.281), train_loss = 1.11485668, grad/param norm = 1.9989e-01, time/batch = 0.6948s	
12131/28500 (epoch 21.282), train_loss = 0.97563364, grad/param norm = 1.5132e-01, time/batch = 0.7157s	
12132/28500 (epoch 21.284), train_loss = 1.04941315, grad/param norm = 1.7460e-01, time/batch = 0.6972s	
12133/28500 (epoch 21.286), train_loss = 1.16545505, grad/param norm = 1.8370e-01, time/batch = 0.6919s	
12134/28500 (epoch 21.288), train_loss = 1.07980520, grad/param norm = 1.7293e-01, time/batch = 0.6943s	
12135/28500 (epoch 21.289), train_loss = 1.09025318, grad/param norm = 1.9245e-01, time/batch = 0.7050s	
12136/28500 (epoch 21.291), train_loss = 1.06582271, grad/param norm = 1.5286e-01, time/batch = 0.7040s	
12137/28500 (epoch 21.293), train_loss = 1.02377723, grad/param norm = 1.6083e-01, time/batch = 0.6946s	
12138/28500 (epoch 21.295), train_loss = 0.91822702, grad/param norm = 1.6128e-01, time/batch = 0.6962s	
12139/28500 (epoch 21.296), train_loss = 0.92704803, grad/param norm = 1.5757e-01, time/batch = 0.6931s	
12140/28500 (epoch 21.298), train_loss = 1.10884544, grad/param norm = 1.6686e-01, time/batch = 0.6967s	
12141/28500 (epoch 21.300), train_loss = 0.96523571, grad/param norm = 1.6524e-01, time/batch = 0.6959s	
12142/28500 (epoch 21.302), train_loss = 0.91424986, grad/param norm = 1.5048e-01, time/batch = 0.7041s	
12143/28500 (epoch 21.304), train_loss = 1.00482782, grad/param norm = 1.5674e-01, time/batch = 0.6924s	
12144/28500 (epoch 21.305), train_loss = 1.06662109, grad/param norm = 1.5417e-01, time/batch = 0.6891s	
12145/28500 (epoch 21.307), train_loss = 1.02962014, grad/param norm = 1.8017e-01, time/batch = 0.6915s	
12146/28500 (epoch 21.309), train_loss = 1.02533170, grad/param norm = 1.5641e-01, time/batch = 0.6900s	
12147/28500 (epoch 21.311), train_loss = 1.09524819, grad/param norm = 1.5857e-01, time/batch = 0.6896s	
12148/28500 (epoch 21.312), train_loss = 1.05888554, grad/param norm = 1.7115e-01, time/batch = 0.6887s	
12149/28500 (epoch 21.314), train_loss = 1.10918538, grad/param norm = 1.7809e-01, time/batch = 0.6908s	
12150/28500 (epoch 21.316), train_loss = 1.06378020, grad/param norm = 1.6130e-01, time/batch = 0.6891s	
12151/28500 (epoch 21.318), train_loss = 1.10479490, grad/param norm = 1.6031e-01, time/batch = 0.6939s	
12152/28500 (epoch 21.319), train_loss = 0.99689284, grad/param norm = 1.7362e-01, time/batch = 0.6913s	
12153/28500 (epoch 21.321), train_loss = 0.97924154, grad/param norm = 1.7136e-01, time/batch = 0.6915s	
12154/28500 (epoch 21.323), train_loss = 1.00974755, grad/param norm = 1.9002e-01, time/batch = 0.6891s	
12155/28500 (epoch 21.325), train_loss = 1.17211819, grad/param norm = 1.7035e-01, time/batch = 0.6910s	
12156/28500 (epoch 21.326), train_loss = 1.05576945, grad/param norm = 1.6376e-01, time/batch = 0.6891s	
12157/28500 (epoch 21.328), train_loss = 0.84872714, grad/param norm = 1.5404e-01, time/batch = 0.6890s	
12158/28500 (epoch 21.330), train_loss = 0.95962087, grad/param norm = 1.5955e-01, time/batch = 0.6891s	
12159/28500 (epoch 21.332), train_loss = 1.04504364, grad/param norm = 1.5118e-01, time/batch = 0.6913s	
12160/28500 (epoch 21.333), train_loss = 0.86432995, grad/param norm = 1.6183e-01, time/batch = 0.6888s	
12161/28500 (epoch 21.335), train_loss = 0.92886842, grad/param norm = 1.5126e-01, time/batch = 0.6922s	
12162/28500 (epoch 21.337), train_loss = 0.91208309, grad/param norm = 1.5217e-01, time/batch = 0.6900s	
12163/28500 (epoch 21.339), train_loss = 0.86982953, grad/param norm = 1.3767e-01, time/batch = 0.6908s	
12164/28500 (epoch 21.340), train_loss = 1.06987635, grad/param norm = 1.8927e-01, time/batch = 0.6913s	
12165/28500 (epoch 21.342), train_loss = 1.02395381, grad/param norm = 1.6542e-01, time/batch = 0.6912s	
12166/28500 (epoch 21.344), train_loss = 0.96374087, grad/param norm = 1.7361e-01, time/batch = 0.6899s	
12167/28500 (epoch 21.346), train_loss = 0.84972396, grad/param norm = 1.3426e-01, time/batch = 0.6892s	
12168/28500 (epoch 21.347), train_loss = 1.02861585, grad/param norm = 1.7488e-01, time/batch = 0.6940s	
12169/28500 (epoch 21.349), train_loss = 0.98856189, grad/param norm = 1.5144e-01, time/batch = 0.6903s	
12170/28500 (epoch 21.351), train_loss = 0.93922950, grad/param norm = 1.5110e-01, time/batch = 0.6934s	
12171/28500 (epoch 21.353), train_loss = 1.04798014, grad/param norm = 1.8175e-01, time/batch = 0.6930s	
12172/28500 (epoch 21.354), train_loss = 0.91931455, grad/param norm = 1.5625e-01, time/batch = 0.6968s	
12173/28500 (epoch 21.356), train_loss = 0.93891094, grad/param norm = 1.4593e-01, time/batch = 0.6914s	
12174/28500 (epoch 21.358), train_loss = 1.04515273, grad/param norm = 1.6054e-01, time/batch = 0.6932s	
12175/28500 (epoch 21.360), train_loss = 1.05252041, grad/param norm = 1.6973e-01, time/batch = 0.6891s	
12176/28500 (epoch 21.361), train_loss = 0.94980633, grad/param norm = 1.5084e-01, time/batch = 0.6905s	
12177/28500 (epoch 21.363), train_loss = 0.90709419, grad/param norm = 1.4938e-01, time/batch = 0.6896s	
12178/28500 (epoch 21.365), train_loss = 0.98076787, grad/param norm = 1.6011e-01, time/batch = 0.6916s	
12179/28500 (epoch 21.367), train_loss = 1.01132892, grad/param norm = 1.5569e-01, time/batch = 0.6907s	
12180/28500 (epoch 21.368), train_loss = 0.98296298, grad/param norm = 1.4830e-01, time/batch = 0.6912s	
12181/28500 (epoch 21.370), train_loss = 1.00975057, grad/param norm = 1.6085e-01, time/batch = 0.6912s	
12182/28500 (epoch 21.372), train_loss = 0.86056101, grad/param norm = 1.5140e-01, time/batch = 0.6911s	
12183/28500 (epoch 21.374), train_loss = 0.98723540, grad/param norm = 1.6619e-01, time/batch = 0.6903s	
12184/28500 (epoch 21.375), train_loss = 1.12539677, grad/param norm = 1.5691e-01, time/batch = 0.6893s	
12185/28500 (epoch 21.377), train_loss = 0.87827471, grad/param norm = 1.5542e-01, time/batch = 0.6915s	
12186/28500 (epoch 21.379), train_loss = 0.78801737, grad/param norm = 1.6935e-01, time/batch = 0.6923s	
12187/28500 (epoch 21.381), train_loss = 0.98493129, grad/param norm = 1.5622e-01, time/batch = 0.6906s	
12188/28500 (epoch 21.382), train_loss = 0.94923045, grad/param norm = 1.6103e-01, time/batch = 0.6909s	
12189/28500 (epoch 21.384), train_loss = 0.87643532, grad/param norm = 1.5440e-01, time/batch = 0.6923s	
12190/28500 (epoch 21.386), train_loss = 0.87591721, grad/param norm = 1.4579e-01, time/batch = 0.6907s	
12191/28500 (epoch 21.388), train_loss = 1.08627401, grad/param norm = 1.6394e-01, time/batch = 0.6927s	
12192/28500 (epoch 21.389), train_loss = 0.93561073, grad/param norm = 1.6345e-01, time/batch = 0.6911s	
12193/28500 (epoch 21.391), train_loss = 0.91517494, grad/param norm = 1.5549e-01, time/batch = 0.6913s	
12194/28500 (epoch 21.393), train_loss = 0.90915203, grad/param norm = 1.6277e-01, time/batch = 0.6891s	
12195/28500 (epoch 21.395), train_loss = 1.15463622, grad/param norm = 1.6559e-01, time/batch = 0.6915s	
12196/28500 (epoch 21.396), train_loss = 1.08887870, grad/param norm = 1.7181e-01, time/batch = 0.6894s	
12197/28500 (epoch 21.398), train_loss = 0.80122499, grad/param norm = 1.6487e-01, time/batch = 0.6907s	
12198/28500 (epoch 21.400), train_loss = 0.99656359, grad/param norm = 1.7959e-01, time/batch = 0.6892s	
12199/28500 (epoch 21.402), train_loss = 1.04178505, grad/param norm = 1.6661e-01, time/batch = 0.6919s	
12200/28500 (epoch 21.404), train_loss = 1.07895778, grad/param norm = 1.7865e-01, time/batch = 0.6894s	
12201/28500 (epoch 21.405), train_loss = 1.08452182, grad/param norm = 1.5236e-01, time/batch = 0.6917s	
12202/28500 (epoch 21.407), train_loss = 1.04279014, grad/param norm = 1.5999e-01, time/batch = 0.6910s	
12203/28500 (epoch 21.409), train_loss = 1.03860321, grad/param norm = 1.5957e-01, time/batch = 0.6937s	
12204/28500 (epoch 21.411), train_loss = 1.12029112, grad/param norm = 1.6021e-01, time/batch = 0.7032s	
12205/28500 (epoch 21.412), train_loss = 1.11859272, grad/param norm = 1.7866e-01, time/batch = 0.6963s	
12206/28500 (epoch 21.414), train_loss = 1.04135806, grad/param norm = 1.7357e-01, time/batch = 0.6952s	
12207/28500 (epoch 21.416), train_loss = 0.93608432, grad/param norm = 1.7277e-01, time/batch = 0.6902s	
12208/28500 (epoch 21.418), train_loss = 1.02040834, grad/param norm = 1.4148e-01, time/batch = 0.6940s	
12209/28500 (epoch 21.419), train_loss = 1.13870188, grad/param norm = 1.8955e-01, time/batch = 0.6951s	
12210/28500 (epoch 21.421), train_loss = 1.10860367, grad/param norm = 1.8395e-01, time/batch = 0.6936s	
12211/28500 (epoch 21.423), train_loss = 1.11643284, grad/param norm = 1.9127e-01, time/batch = 0.6995s	
12212/28500 (epoch 21.425), train_loss = 1.06648169, grad/param norm = 2.0548e-01, time/batch = 0.6934s	
12213/28500 (epoch 21.426), train_loss = 1.00551025, grad/param norm = 1.7123e-01, time/batch = 0.6920s	
12214/28500 (epoch 21.428), train_loss = 1.20217505, grad/param norm = 1.7087e-01, time/batch = 0.6908s	
12215/28500 (epoch 21.430), train_loss = 1.13897746, grad/param norm = 1.5915e-01, time/batch = 0.7032s	
12216/28500 (epoch 21.432), train_loss = 1.07154198, grad/param norm = 1.8497e-01, time/batch = 0.7056s	
12217/28500 (epoch 21.433), train_loss = 1.07985703, grad/param norm = 1.7316e-01, time/batch = 0.6934s	
12218/28500 (epoch 21.435), train_loss = 1.05448283, grad/param norm = 1.8157e-01, time/batch = 0.6963s	
12219/28500 (epoch 21.437), train_loss = 0.95478314, grad/param norm = 1.6585e-01, time/batch = 0.6961s	
12220/28500 (epoch 21.439), train_loss = 1.00230163, grad/param norm = 1.4784e-01, time/batch = 0.6944s	
12221/28500 (epoch 21.440), train_loss = 1.24138534, grad/param norm = 1.7355e-01, time/batch = 0.7023s	
12222/28500 (epoch 21.442), train_loss = 0.95696582, grad/param norm = 1.6236e-01, time/batch = 0.6981s	
12223/28500 (epoch 21.444), train_loss = 0.88120040, grad/param norm = 1.4958e-01, time/batch = 0.6934s	
12224/28500 (epoch 21.446), train_loss = 0.86012306, grad/param norm = 1.4917e-01, time/batch = 0.6961s	
12225/28500 (epoch 21.447), train_loss = 0.86699928, grad/param norm = 1.2977e-01, time/batch = 0.6895s	
12226/28500 (epoch 21.449), train_loss = 0.96690674, grad/param norm = 1.4467e-01, time/batch = 0.6892s	
12227/28500 (epoch 21.451), train_loss = 0.99669528, grad/param norm = 1.4867e-01, time/batch = 0.6971s	
12228/28500 (epoch 21.453), train_loss = 0.97783197, grad/param norm = 1.5306e-01, time/batch = 0.6904s	
12229/28500 (epoch 21.454), train_loss = 0.96403165, grad/param norm = 1.5143e-01, time/batch = 0.6899s	
12230/28500 (epoch 21.456), train_loss = 1.09139494, grad/param norm = 1.6993e-01, time/batch = 0.6888s	
12231/28500 (epoch 21.458), train_loss = 0.98448674, grad/param norm = 1.5472e-01, time/batch = 0.6907s	
12232/28500 (epoch 21.460), train_loss = 1.06863481, grad/param norm = 1.7276e-01, time/batch = 0.6922s	
12233/28500 (epoch 21.461), train_loss = 0.97092720, grad/param norm = 1.7439e-01, time/batch = 0.6935s	
12234/28500 (epoch 21.463), train_loss = 0.88035130, grad/param norm = 1.3531e-01, time/batch = 0.6961s	
12235/28500 (epoch 21.465), train_loss = 0.85977832, grad/param norm = 1.7506e-01, time/batch = 0.6901s	
12236/28500 (epoch 21.467), train_loss = 1.00210461, grad/param norm = 1.5005e-01, time/batch = 0.6978s	
12237/28500 (epoch 21.468), train_loss = 0.92656254, grad/param norm = 1.5332e-01, time/batch = 0.7034s	
12238/28500 (epoch 21.470), train_loss = 0.94545913, grad/param norm = 1.7751e-01, time/batch = 0.7047s	
12239/28500 (epoch 21.472), train_loss = 0.95016356, grad/param norm = 1.5107e-01, time/batch = 0.6986s	
12240/28500 (epoch 21.474), train_loss = 1.16451821, grad/param norm = 1.7370e-01, time/batch = 0.6921s	
12241/28500 (epoch 21.475), train_loss = 0.91702994, grad/param norm = 1.3822e-01, time/batch = 0.6920s	
12242/28500 (epoch 21.477), train_loss = 0.98154302, grad/param norm = 1.6182e-01, time/batch = 0.6908s	
12243/28500 (epoch 21.479), train_loss = 1.05860702, grad/param norm = 1.6796e-01, time/batch = 0.6895s	
12244/28500 (epoch 21.481), train_loss = 1.01540000, grad/param norm = 1.7561e-01, time/batch = 0.6899s	
12245/28500 (epoch 21.482), train_loss = 0.91516351, grad/param norm = 1.5749e-01, time/batch = 0.6918s	
12246/28500 (epoch 21.484), train_loss = 0.90843218, grad/param norm = 1.4840e-01, time/batch = 0.6918s	
12247/28500 (epoch 21.486), train_loss = 0.84315343, grad/param norm = 1.7801e-01, time/batch = 0.6900s	
12248/28500 (epoch 21.488), train_loss = 1.04396206, grad/param norm = 1.4822e-01, time/batch = 0.6895s	
12249/28500 (epoch 21.489), train_loss = 1.10492161, grad/param norm = 1.5734e-01, time/batch = 0.6892s	
12250/28500 (epoch 21.491), train_loss = 0.96363638, grad/param norm = 1.5833e-01, time/batch = 0.6917s	
12251/28500 (epoch 21.493), train_loss = 0.98404130, grad/param norm = 1.5644e-01, time/batch = 0.6915s	
12252/28500 (epoch 21.495), train_loss = 0.97096637, grad/param norm = 1.4036e-01, time/batch = 0.6944s	
12253/28500 (epoch 21.496), train_loss = 0.92384818, grad/param norm = 1.7319e-01, time/batch = 0.6923s	
12254/28500 (epoch 21.498), train_loss = 1.02239234, grad/param norm = 1.5392e-01, time/batch = 0.6966s	
12255/28500 (epoch 21.500), train_loss = 0.95465019, grad/param norm = 1.5012e-01, time/batch = 0.6922s	
12256/28500 (epoch 21.502), train_loss = 1.09351976, grad/param norm = 1.5624e-01, time/batch = 0.6904s	
12257/28500 (epoch 21.504), train_loss = 1.00952612, grad/param norm = 1.4640e-01, time/batch = 0.6924s	
12258/28500 (epoch 21.505), train_loss = 0.92471030, grad/param norm = 1.5375e-01, time/batch = 0.6947s	
12259/28500 (epoch 21.507), train_loss = 1.10610713, grad/param norm = 1.8521e-01, time/batch = 0.6898s	
12260/28500 (epoch 21.509), train_loss = 1.00337956, grad/param norm = 1.6520e-01, time/batch = 0.6893s	
12261/28500 (epoch 21.511), train_loss = 0.98976138, grad/param norm = 1.5378e-01, time/batch = 0.7009s	
12262/28500 (epoch 21.512), train_loss = 1.03672693, grad/param norm = 1.5752e-01, time/batch = 0.7071s	
12263/28500 (epoch 21.514), train_loss = 0.95571778, grad/param norm = 1.5586e-01, time/batch = 0.6972s	
12264/28500 (epoch 21.516), train_loss = 0.96252217, grad/param norm = 1.3363e-01, time/batch = 0.6917s	
12265/28500 (epoch 21.518), train_loss = 1.03092802, grad/param norm = 1.4604e-01, time/batch = 0.6931s	
12266/28500 (epoch 21.519), train_loss = 1.07700871, grad/param norm = 1.5559e-01, time/batch = 0.6902s	
12267/28500 (epoch 21.521), train_loss = 1.16564896, grad/param norm = 1.7739e-01, time/batch = 0.6928s	
12268/28500 (epoch 21.523), train_loss = 1.07759414, grad/param norm = 1.7423e-01, time/batch = 0.6958s	
12269/28500 (epoch 21.525), train_loss = 1.08517724, grad/param norm = 1.5925e-01, time/batch = 0.6962s	
12270/28500 (epoch 21.526), train_loss = 1.07617388, grad/param norm = 1.6897e-01, time/batch = 0.6978s	
12271/28500 (epoch 21.528), train_loss = 1.09387662, grad/param norm = 1.6580e-01, time/batch = 0.6995s	
12272/28500 (epoch 21.530), train_loss = 1.10208936, grad/param norm = 1.5559e-01, time/batch = 0.7066s	
12273/28500 (epoch 21.532), train_loss = 0.96308013, grad/param norm = 1.4509e-01, time/batch = 0.7280s	
12274/28500 (epoch 21.533), train_loss = 1.09761321, grad/param norm = 1.6558e-01, time/batch = 0.7024s	
12275/28500 (epoch 21.535), train_loss = 0.85988452, grad/param norm = 1.4071e-01, time/batch = 0.7012s	
12276/28500 (epoch 21.537), train_loss = 0.89344213, grad/param norm = 1.4682e-01, time/batch = 0.6923s	
12277/28500 (epoch 21.539), train_loss = 0.85981354, grad/param norm = 1.4821e-01, time/batch = 0.6955s	
12278/28500 (epoch 21.540), train_loss = 1.03336350, grad/param norm = 1.6937e-01, time/batch = 0.6931s	
12279/28500 (epoch 21.542), train_loss = 1.05973151, grad/param norm = 1.8269e-01, time/batch = 0.7002s	
12280/28500 (epoch 21.544), train_loss = 1.18357801, grad/param norm = 1.8498e-01, time/batch = 0.7054s	
12281/28500 (epoch 21.546), train_loss = 0.99297984, grad/param norm = 1.6035e-01, time/batch = 0.7048s	
12282/28500 (epoch 21.547), train_loss = 1.01639999, grad/param norm = 1.4669e-01, time/batch = 0.6967s	
12283/28500 (epoch 21.549), train_loss = 0.84652227, grad/param norm = 1.2701e-01, time/batch = 0.6967s	
12284/28500 (epoch 21.551), train_loss = 0.99247124, grad/param norm = 1.7617e-01, time/batch = 0.6927s	
12285/28500 (epoch 21.553), train_loss = 1.19704372, grad/param norm = 1.9806e-01, time/batch = 0.6964s	
12286/28500 (epoch 21.554), train_loss = 1.01609770, grad/param norm = 1.5921e-01, time/batch = 0.6935s	
12287/28500 (epoch 21.556), train_loss = 1.04616199, grad/param norm = 1.6366e-01, time/batch = 0.6991s	
12288/28500 (epoch 21.558), train_loss = 1.03892559, grad/param norm = 1.5196e-01, time/batch = 0.6938s	
12289/28500 (epoch 21.560), train_loss = 1.05694708, grad/param norm = 1.7322e-01, time/batch = 0.7009s	
12290/28500 (epoch 21.561), train_loss = 1.09402454, grad/param norm = 1.7454e-01, time/batch = 0.6975s	
12291/28500 (epoch 21.563), train_loss = 1.17821590, grad/param norm = 1.9015e-01, time/batch = 0.7220s	
12292/28500 (epoch 21.565), train_loss = 0.99544937, grad/param norm = 1.7332e-01, time/batch = 0.7096s	
12293/28500 (epoch 21.567), train_loss = 0.88409115, grad/param norm = 1.4087e-01, time/batch = 0.7143s	
12294/28500 (epoch 21.568), train_loss = 1.06754393, grad/param norm = 1.7983e-01, time/batch = 0.7123s	
12295/28500 (epoch 21.570), train_loss = 0.98099667, grad/param norm = 1.4983e-01, time/batch = 0.6964s	
12296/28500 (epoch 21.572), train_loss = 0.99197454, grad/param norm = 1.5963e-01, time/batch = 0.7017s	
12297/28500 (epoch 21.574), train_loss = 0.97734727, grad/param norm = 1.5458e-01, time/batch = 0.6965s	
12298/28500 (epoch 21.575), train_loss = 0.98935885, grad/param norm = 1.5872e-01, time/batch = 0.6929s	
12299/28500 (epoch 21.577), train_loss = 1.02161113, grad/param norm = 1.5566e-01, time/batch = 0.7061s	
12300/28500 (epoch 21.579), train_loss = 1.09483317, grad/param norm = 1.6557e-01, time/batch = 0.7102s	
12301/28500 (epoch 21.581), train_loss = 0.93100546, grad/param norm = 1.6476e-01, time/batch = 0.6932s	
12302/28500 (epoch 21.582), train_loss = 1.08258012, grad/param norm = 1.5021e-01, time/batch = 0.6970s	
12303/28500 (epoch 21.584), train_loss = 0.95517670, grad/param norm = 1.6077e-01, time/batch = 0.6906s	
12304/28500 (epoch 21.586), train_loss = 0.92536805, grad/param norm = 1.4065e-01, time/batch = 0.6985s	
12305/28500 (epoch 21.588), train_loss = 0.92544292, grad/param norm = 1.4875e-01, time/batch = 0.6964s	
12306/28500 (epoch 21.589), train_loss = 1.03646248, grad/param norm = 1.6040e-01, time/batch = 0.6974s	
12307/28500 (epoch 21.591), train_loss = 1.01623852, grad/param norm = 1.7206e-01, time/batch = 0.7069s	
12308/28500 (epoch 21.593), train_loss = 0.95549041, grad/param norm = 1.5608e-01, time/batch = 0.7048s	
12309/28500 (epoch 21.595), train_loss = 1.21263460, grad/param norm = 1.8156e-01, time/batch = 0.6946s	
12310/28500 (epoch 21.596), train_loss = 1.20777047, grad/param norm = 1.7888e-01, time/batch = 0.6945s	
12311/28500 (epoch 21.598), train_loss = 1.02568888, grad/param norm = 1.5264e-01, time/batch = 0.7028s	
12312/28500 (epoch 21.600), train_loss = 1.02428357, grad/param norm = 1.7655e-01, time/batch = 0.6952s	
12313/28500 (epoch 21.602), train_loss = 1.10893525, grad/param norm = 1.8237e-01, time/batch = 0.7163s	
12314/28500 (epoch 21.604), train_loss = 1.10561586, grad/param norm = 1.6090e-01, time/batch = 0.6971s	
12315/28500 (epoch 21.605), train_loss = 1.06589246, grad/param norm = 1.6896e-01, time/batch = 0.7134s	
12316/28500 (epoch 21.607), train_loss = 1.11457243, grad/param norm = 1.4914e-01, time/batch = 0.7012s	
12317/28500 (epoch 21.609), train_loss = 1.04125846, grad/param norm = 1.7085e-01, time/batch = 0.6950s	
12318/28500 (epoch 21.611), train_loss = 0.99839794, grad/param norm = 1.6874e-01, time/batch = 0.6924s	
12319/28500 (epoch 21.612), train_loss = 1.07367234, grad/param norm = 1.7939e-01, time/batch = 0.6947s	
12320/28500 (epoch 21.614), train_loss = 1.03833803, grad/param norm = 1.4937e-01, time/batch = 0.6927s	
12321/28500 (epoch 21.616), train_loss = 0.95783008, grad/param norm = 1.6332e-01, time/batch = 0.6978s	
12322/28500 (epoch 21.618), train_loss = 0.99912654, grad/param norm = 1.6308e-01, time/batch = 0.6937s	
12323/28500 (epoch 21.619), train_loss = 1.15982018, grad/param norm = 1.8095e-01, time/batch = 0.6987s	
12324/28500 (epoch 21.621), train_loss = 0.84782430, grad/param norm = 1.3927e-01, time/batch = 0.6991s	
12325/28500 (epoch 21.623), train_loss = 1.13354927, grad/param norm = 2.0668e-01, time/batch = 0.6929s	
12326/28500 (epoch 21.625), train_loss = 0.92529511, grad/param norm = 1.6891e-01, time/batch = 0.7000s	
12327/28500 (epoch 21.626), train_loss = 0.78805428, grad/param norm = 1.3897e-01, time/batch = 0.6942s	
12328/28500 (epoch 21.628), train_loss = 0.94932413, grad/param norm = 1.5924e-01, time/batch = 0.6962s	
12329/28500 (epoch 21.630), train_loss = 0.89074579, grad/param norm = 1.4729e-01, time/batch = 0.6930s	
12330/28500 (epoch 21.632), train_loss = 1.10067562, grad/param norm = 1.6745e-01, time/batch = 0.6949s	
12331/28500 (epoch 21.633), train_loss = 1.17976569, grad/param norm = 1.5274e-01, time/batch = 0.6988s	
12332/28500 (epoch 21.635), train_loss = 1.10559681, grad/param norm = 1.6757e-01, time/batch = 0.6949s	
12333/28500 (epoch 21.637), train_loss = 1.05015360, grad/param norm = 1.5861e-01, time/batch = 0.7021s	
12334/28500 (epoch 21.639), train_loss = 0.90249111, grad/param norm = 1.5286e-01, time/batch = 0.6976s	
12335/28500 (epoch 21.640), train_loss = 0.96045269, grad/param norm = 1.5964e-01, time/batch = 0.6933s	
12336/28500 (epoch 21.642), train_loss = 0.95729795, grad/param norm = 1.5485e-01, time/batch = 0.6962s	
12337/28500 (epoch 21.644), train_loss = 1.08491228, grad/param norm = 1.4752e-01, time/batch = 0.6924s	
12338/28500 (epoch 21.646), train_loss = 0.88906629, grad/param norm = 1.3792e-01, time/batch = 0.6952s	
12339/28500 (epoch 21.647), train_loss = 0.91332932, grad/param norm = 1.5254e-01, time/batch = 0.6929s	
12340/28500 (epoch 21.649), train_loss = 0.89384136, grad/param norm = 1.5826e-01, time/batch = 0.6957s	
12341/28500 (epoch 21.651), train_loss = 0.87586291, grad/param norm = 1.4330e-01, time/batch = 0.6945s	
12342/28500 (epoch 21.653), train_loss = 0.88289178, grad/param norm = 1.4524e-01, time/batch = 0.6928s	
12343/28500 (epoch 21.654), train_loss = 0.96985549, grad/param norm = 1.5788e-01, time/batch = 0.6889s	
12344/28500 (epoch 21.656), train_loss = 0.91643425, grad/param norm = 1.5862e-01, time/batch = 0.6911s	
12345/28500 (epoch 21.658), train_loss = 0.98647248, grad/param norm = 1.6864e-01, time/batch = 0.6895s	
12346/28500 (epoch 21.660), train_loss = 0.99054519, grad/param norm = 1.5409e-01, time/batch = 0.7020s	
12347/28500 (epoch 21.661), train_loss = 1.15472210, grad/param norm = 1.8269e-01, time/batch = 0.6904s	
12348/28500 (epoch 21.663), train_loss = 1.13713226, grad/param norm = 1.7456e-01, time/batch = 0.6934s	
12349/28500 (epoch 21.665), train_loss = 0.97754711, grad/param norm = 1.4261e-01, time/batch = 0.6895s	
12350/28500 (epoch 21.667), train_loss = 1.00736943, grad/param norm = 1.7618e-01, time/batch = 0.6990s	
12351/28500 (epoch 21.668), train_loss = 0.98934377, grad/param norm = 1.5194e-01, time/batch = 0.6962s	
12352/28500 (epoch 21.670), train_loss = 1.02632444, grad/param norm = 1.7257e-01, time/batch = 0.6908s	
12353/28500 (epoch 21.672), train_loss = 0.95778909, grad/param norm = 1.7595e-01, time/batch = 0.6918s	
12354/28500 (epoch 21.674), train_loss = 0.83664235, grad/param norm = 1.6018e-01, time/batch = 0.6895s	
12355/28500 (epoch 21.675), train_loss = 0.88761659, grad/param norm = 1.5745e-01, time/batch = 0.6927s	
12356/28500 (epoch 21.677), train_loss = 0.96996942, grad/param norm = 1.5065e-01, time/batch = 0.6924s	
12357/28500 (epoch 21.679), train_loss = 0.95782378, grad/param norm = 1.7054e-01, time/batch = 0.6938s	
12358/28500 (epoch 21.681), train_loss = 1.05431103, grad/param norm = 1.6172e-01, time/batch = 0.6929s	
12359/28500 (epoch 21.682), train_loss = 0.96594996, grad/param norm = 1.5247e-01, time/batch = 0.6933s	
12360/28500 (epoch 21.684), train_loss = 1.03773336, grad/param norm = 1.5637e-01, time/batch = 0.7015s	
12361/28500 (epoch 21.686), train_loss = 0.95486570, grad/param norm = 1.6682e-01, time/batch = 0.6974s	
12362/28500 (epoch 21.688), train_loss = 0.90471127, grad/param norm = 1.3425e-01, time/batch = 0.6981s	
12363/28500 (epoch 21.689), train_loss = 0.96609013, grad/param norm = 1.5834e-01, time/batch = 0.6940s	
12364/28500 (epoch 21.691), train_loss = 1.01961589, grad/param norm = 1.7569e-01, time/batch = 0.6975s	
12365/28500 (epoch 21.693), train_loss = 0.95632666, grad/param norm = 1.6032e-01, time/batch = 0.6934s	
12366/28500 (epoch 21.695), train_loss = 0.77446248, grad/param norm = 1.7679e-01, time/batch = 0.6977s	
12367/28500 (epoch 21.696), train_loss = 0.98149551, grad/param norm = 1.5664e-01, time/batch = 0.6960s	
12368/28500 (epoch 21.698), train_loss = 0.98526377, grad/param norm = 1.5804e-01, time/batch = 0.6988s	
12369/28500 (epoch 21.700), train_loss = 1.00776248, grad/param norm = 1.6254e-01, time/batch = 0.6979s	
12370/28500 (epoch 21.702), train_loss = 1.04787457, grad/param norm = 1.6344e-01, time/batch = 0.6950s	
12371/28500 (epoch 21.704), train_loss = 1.03053292, grad/param norm = 1.5801e-01, time/batch = 0.6996s	
12372/28500 (epoch 21.705), train_loss = 1.10654469, grad/param norm = 2.0098e-01, time/batch = 0.6924s	
12373/28500 (epoch 21.707), train_loss = 0.93572512, grad/param norm = 1.7225e-01, time/batch = 0.6898s	
12374/28500 (epoch 21.709), train_loss = 1.13574385, grad/param norm = 1.7280e-01, time/batch = 0.6897s	
12375/28500 (epoch 21.711), train_loss = 0.91770455, grad/param norm = 1.5585e-01, time/batch = 0.6954s	
12376/28500 (epoch 21.712), train_loss = 1.04205042, grad/param norm = 1.7540e-01, time/batch = 0.6957s	
12377/28500 (epoch 21.714), train_loss = 1.12635586, grad/param norm = 1.6305e-01, time/batch = 0.7005s	
12378/28500 (epoch 21.716), train_loss = 0.98179134, grad/param norm = 1.6397e-01, time/batch = 0.6890s	
12379/28500 (epoch 21.718), train_loss = 1.01051679, grad/param norm = 1.5775e-01, time/batch = 0.6926s	
12380/28500 (epoch 21.719), train_loss = 1.02222417, grad/param norm = 1.6300e-01, time/batch = 0.6893s	
12381/28500 (epoch 21.721), train_loss = 0.84300417, grad/param norm = 1.5481e-01, time/batch = 0.6921s	
12382/28500 (epoch 21.723), train_loss = 1.00664136, grad/param norm = 1.6322e-01, time/batch = 0.6949s	
12383/28500 (epoch 21.725), train_loss = 1.07661825, grad/param norm = 1.5394e-01, time/batch = 0.6924s	
12384/28500 (epoch 21.726), train_loss = 0.99442720, grad/param norm = 1.5880e-01, time/batch = 0.6914s	
12385/28500 (epoch 21.728), train_loss = 0.91045421, grad/param norm = 1.5303e-01, time/batch = 0.6902s	
12386/28500 (epoch 21.730), train_loss = 1.01027373, grad/param norm = 1.7183e-01, time/batch = 0.6911s	
12387/28500 (epoch 21.732), train_loss = 0.83577178, grad/param norm = 1.4426e-01, time/batch = 0.6960s	
12388/28500 (epoch 21.733), train_loss = 0.84432046, grad/param norm = 1.3998e-01, time/batch = 0.6904s	
12389/28500 (epoch 21.735), train_loss = 0.86821201, grad/param norm = 1.4654e-01, time/batch = 0.6926s	
12390/28500 (epoch 21.737), train_loss = 0.79184040, grad/param norm = 1.3703e-01, time/batch = 0.6892s	
12391/28500 (epoch 21.739), train_loss = 0.94351010, grad/param norm = 1.6373e-01, time/batch = 0.6936s	
12392/28500 (epoch 21.740), train_loss = 0.98367268, grad/param norm = 1.5299e-01, time/batch = 0.6897s	
12393/28500 (epoch 21.742), train_loss = 0.92531928, grad/param norm = 1.5005e-01, time/batch = 0.6926s	
12394/28500 (epoch 21.744), train_loss = 1.02052564, grad/param norm = 1.6366e-01, time/batch = 0.6898s	
12395/28500 (epoch 21.746), train_loss = 0.91020896, grad/param norm = 1.4847e-01, time/batch = 0.6936s	
12396/28500 (epoch 21.747), train_loss = 0.91308608, grad/param norm = 1.4896e-01, time/batch = 0.6905s	
12397/28500 (epoch 21.749), train_loss = 1.08270398, grad/param norm = 1.8504e-01, time/batch = 0.6914s	
12398/28500 (epoch 21.751), train_loss = 0.90137504, grad/param norm = 1.8908e-01, time/batch = 0.6890s	
12399/28500 (epoch 21.753), train_loss = 0.95512773, grad/param norm = 1.5015e-01, time/batch = 0.6920s	
12400/28500 (epoch 21.754), train_loss = 0.87474249, grad/param norm = 1.4462e-01, time/batch = 0.6891s	
12401/28500 (epoch 21.756), train_loss = 1.10458230, grad/param norm = 1.7979e-01, time/batch = 0.6960s	
12402/28500 (epoch 21.758), train_loss = 1.08012167, grad/param norm = 1.9983e-01, time/batch = 0.7049s	
12403/28500 (epoch 21.760), train_loss = 0.89070880, grad/param norm = 1.7474e-01, time/batch = 0.6960s	
12404/28500 (epoch 21.761), train_loss = 0.92743127, grad/param norm = 1.7191e-01, time/batch = 0.6908s	
12405/28500 (epoch 21.763), train_loss = 0.79716969, grad/param norm = 1.3207e-01, time/batch = 0.6927s	
12406/28500 (epoch 21.765), train_loss = 0.95516202, grad/param norm = 1.5945e-01, time/batch = 0.6914s	
12407/28500 (epoch 21.767), train_loss = 0.83870707, grad/param norm = 1.4201e-01, time/batch = 0.6932s	
12408/28500 (epoch 21.768), train_loss = 1.05417358, grad/param norm = 1.6409e-01, time/batch = 0.6918s	
12409/28500 (epoch 21.770), train_loss = 0.86867097, grad/param norm = 1.5601e-01, time/batch = 0.6917s	
12410/28500 (epoch 21.772), train_loss = 0.75297234, grad/param norm = 1.3391e-01, time/batch = 0.6898s	
12411/28500 (epoch 21.774), train_loss = 0.97688414, grad/param norm = 1.6820e-01, time/batch = 0.6913s	
12412/28500 (epoch 21.775), train_loss = 1.07228988, grad/param norm = 1.5456e-01, time/batch = 0.6904s	
12413/28500 (epoch 21.777), train_loss = 1.06790984, grad/param norm = 1.5576e-01, time/batch = 0.6899s	
12414/28500 (epoch 21.779), train_loss = 0.81868137, grad/param norm = 1.4898e-01, time/batch = 0.6900s	
12415/28500 (epoch 21.781), train_loss = 0.97244452, grad/param norm = 1.7072e-01, time/batch = 0.6893s	
12416/28500 (epoch 21.782), train_loss = 1.04405395, grad/param norm = 1.6578e-01, time/batch = 0.6928s	
12417/28500 (epoch 21.784), train_loss = 0.82090981, grad/param norm = 1.4825e-01, time/batch = 0.6891s	
12418/28500 (epoch 21.786), train_loss = 0.87934702, grad/param norm = 1.4120e-01, time/batch = 0.6937s	
12419/28500 (epoch 21.788), train_loss = 0.97353315, grad/param norm = 1.7431e-01, time/batch = 0.6898s	
12420/28500 (epoch 21.789), train_loss = 0.73140558, grad/param norm = 2.0471e-01, time/batch = 0.6935s	
12421/28500 (epoch 21.791), train_loss = 0.99919020, grad/param norm = 1.6004e-01, time/batch = 0.6932s	
12422/28500 (epoch 21.793), train_loss = 0.96907999, grad/param norm = 1.7040e-01, time/batch = 0.6905s	
12423/28500 (epoch 21.795), train_loss = 1.00111801, grad/param norm = 1.5294e-01, time/batch = 0.6916s	
12424/28500 (epoch 21.796), train_loss = 0.88160061, grad/param norm = 1.4913e-01, time/batch = 0.6903s	
12425/28500 (epoch 21.798), train_loss = 0.82489278, grad/param norm = 1.7312e-01, time/batch = 0.6925s	
12426/28500 (epoch 21.800), train_loss = 0.86280748, grad/param norm = 1.6015e-01, time/batch = 0.6902s	
12427/28500 (epoch 21.802), train_loss = 0.96686338, grad/param norm = 1.8143e-01, time/batch = 0.6953s	
12428/28500 (epoch 21.804), train_loss = 1.00767735, grad/param norm = 1.5347e-01, time/batch = 0.6892s	
12429/28500 (epoch 21.805), train_loss = 0.98908018, grad/param norm = 1.7178e-01, time/batch = 0.6953s	
12430/28500 (epoch 21.807), train_loss = 1.01116510, grad/param norm = 1.6389e-01, time/batch = 0.6915s	
12431/28500 (epoch 21.809), train_loss = 0.95158638, grad/param norm = 1.6492e-01, time/batch = 0.6944s	
12432/28500 (epoch 21.811), train_loss = 1.03167805, grad/param norm = 1.7062e-01, time/batch = 0.6897s	
12433/28500 (epoch 21.812), train_loss = 1.01679173, grad/param norm = 1.8205e-01, time/batch = 0.6912s	
12434/28500 (epoch 21.814), train_loss = 0.92495535, grad/param norm = 1.5902e-01, time/batch = 0.6917s	
12435/28500 (epoch 21.816), train_loss = 1.05746499, grad/param norm = 1.8129e-01, time/batch = 0.6899s	
12436/28500 (epoch 21.818), train_loss = 1.09291465, grad/param norm = 1.7242e-01, time/batch = 0.6904s	
12437/28500 (epoch 21.819), train_loss = 0.99014220, grad/param norm = 1.5379e-01, time/batch = 0.6899s	
12438/28500 (epoch 21.821), train_loss = 0.95090495, grad/param norm = 1.5624e-01, time/batch = 0.6928s	
12439/28500 (epoch 21.823), train_loss = 1.13522318, grad/param norm = 1.7820e-01, time/batch = 0.7117s	
12440/28500 (epoch 21.825), train_loss = 0.95003824, grad/param norm = 1.5916e-01, time/batch = 0.7002s	
12441/28500 (epoch 21.826), train_loss = 0.99113111, grad/param norm = 1.6806e-01, time/batch = 0.6969s	
12442/28500 (epoch 21.828), train_loss = 0.85786792, grad/param norm = 1.5763e-01, time/batch = 0.6944s	
12443/28500 (epoch 21.830), train_loss = 0.95008213, grad/param norm = 1.6286e-01, time/batch = 0.6908s	
12444/28500 (epoch 21.832), train_loss = 0.97963358, grad/param norm = 1.6887e-01, time/batch = 0.6921s	
12445/28500 (epoch 21.833), train_loss = 1.09079116, grad/param norm = 1.5530e-01, time/batch = 0.6900s	
12446/28500 (epoch 21.835), train_loss = 0.90694709, grad/param norm = 1.4780e-01, time/batch = 0.6970s	
12447/28500 (epoch 21.837), train_loss = 0.84483419, grad/param norm = 1.5752e-01, time/batch = 0.6922s	
12448/28500 (epoch 21.839), train_loss = 1.11914353, grad/param norm = 2.3659e-01, time/batch = 0.6919s	
12449/28500 (epoch 21.840), train_loss = 1.15152106, grad/param norm = 1.9588e-01, time/batch = 0.6900s	
12450/28500 (epoch 21.842), train_loss = 1.07225039, grad/param norm = 1.7295e-01, time/batch = 0.6908s	
12451/28500 (epoch 21.844), train_loss = 1.02272792, grad/param norm = 1.8191e-01, time/batch = 0.6919s	
12452/28500 (epoch 21.846), train_loss = 1.12741278, grad/param norm = 1.8934e-01, time/batch = 0.6918s	
12453/28500 (epoch 21.847), train_loss = 0.94253502, grad/param norm = 1.5759e-01, time/batch = 0.6911s	
12454/28500 (epoch 21.849), train_loss = 0.94884746, grad/param norm = 1.6289e-01, time/batch = 0.6919s	
12455/28500 (epoch 21.851), train_loss = 0.82315699, grad/param norm = 1.3944e-01, time/batch = 0.6913s	
12456/28500 (epoch 21.853), train_loss = 1.00760896, grad/param norm = 1.6322e-01, time/batch = 0.6906s	
12457/28500 (epoch 21.854), train_loss = 1.00680541, grad/param norm = 1.6812e-01, time/batch = 0.6899s	
12458/28500 (epoch 21.856), train_loss = 1.12148500, grad/param norm = 1.9030e-01, time/batch = 0.6911s	
12459/28500 (epoch 21.858), train_loss = 0.90639635, grad/param norm = 1.5062e-01, time/batch = 0.6914s	
12460/28500 (epoch 21.860), train_loss = 0.96462385, grad/param norm = 1.6119e-01, time/batch = 0.6916s	
12461/28500 (epoch 21.861), train_loss = 1.04010421, grad/param norm = 1.7743e-01, time/batch = 0.6947s	
12462/28500 (epoch 21.863), train_loss = 1.04616272, grad/param norm = 1.8431e-01, time/batch = 0.6987s	
12463/28500 (epoch 21.865), train_loss = 0.93185438, grad/param norm = 1.5987e-01, time/batch = 0.7108s	
12464/28500 (epoch 21.867), train_loss = 1.04086518, grad/param norm = 1.8337e-01, time/batch = 0.7041s	
12465/28500 (epoch 21.868), train_loss = 0.86312193, grad/param norm = 1.4378e-01, time/batch = 0.6976s	
12466/28500 (epoch 21.870), train_loss = 0.84695679, grad/param norm = 1.5457e-01, time/batch = 0.6937s	
12467/28500 (epoch 21.872), train_loss = 1.02311332, grad/param norm = 1.9017e-01, time/batch = 0.6927s	
12468/28500 (epoch 21.874), train_loss = 0.93724421, grad/param norm = 1.7306e-01, time/batch = 0.6951s	
12469/28500 (epoch 21.875), train_loss = 1.12114444, grad/param norm = 1.9564e-01, time/batch = 0.6934s	
12470/28500 (epoch 21.877), train_loss = 1.00631453, grad/param norm = 1.6150e-01, time/batch = 0.6943s	
12471/28500 (epoch 21.879), train_loss = 1.04258009, grad/param norm = 1.4752e-01, time/batch = 0.6970s	
12472/28500 (epoch 21.881), train_loss = 1.02923930, grad/param norm = 1.7127e-01, time/batch = 0.6936s	
12473/28500 (epoch 21.882), train_loss = 0.91632176, grad/param norm = 1.4252e-01, time/batch = 0.6920s	
12474/28500 (epoch 21.884), train_loss = 1.00002518, grad/param norm = 1.6874e-01, time/batch = 0.6998s	
12475/28500 (epoch 21.886), train_loss = 0.96614018, grad/param norm = 1.6043e-01, time/batch = 0.6986s	
12476/28500 (epoch 21.888), train_loss = 0.89322348, grad/param norm = 1.4984e-01, time/batch = 0.6988s	
12477/28500 (epoch 21.889), train_loss = 0.99330609, grad/param norm = 1.6122e-01, time/batch = 0.6960s	
12478/28500 (epoch 21.891), train_loss = 0.97505902, grad/param norm = 1.5455e-01, time/batch = 0.6944s	
12479/28500 (epoch 21.893), train_loss = 0.95664060, grad/param norm = 1.6768e-01, time/batch = 0.6948s	
12480/28500 (epoch 21.895), train_loss = 1.15980058, grad/param norm = 1.7957e-01, time/batch = 0.6936s	
12481/28500 (epoch 21.896), train_loss = 1.09242832, grad/param norm = 1.7467e-01, time/batch = 0.6973s	
12482/28500 (epoch 21.898), train_loss = 1.01410590, grad/param norm = 1.6582e-01, time/batch = 0.6957s	
12483/28500 (epoch 21.900), train_loss = 0.84944132, grad/param norm = 1.5565e-01, time/batch = 0.6913s	
12484/28500 (epoch 21.902), train_loss = 0.89242146, grad/param norm = 1.6269e-01, time/batch = 0.6917s	
12485/28500 (epoch 21.904), train_loss = 0.88745540, grad/param norm = 1.6197e-01, time/batch = 0.6903s	
12486/28500 (epoch 21.905), train_loss = 0.96415657, grad/param norm = 1.5292e-01, time/batch = 0.7061s	
12487/28500 (epoch 21.907), train_loss = 0.97347393, grad/param norm = 1.6446e-01, time/batch = 0.7031s	
12488/28500 (epoch 21.909), train_loss = 0.88670173, grad/param norm = 1.9237e-01, time/batch = 0.6906s	
12489/28500 (epoch 21.911), train_loss = 0.89909924, grad/param norm = 1.4730e-01, time/batch = 0.6909s	
12490/28500 (epoch 21.912), train_loss = 0.79589719, grad/param norm = 1.4430e-01, time/batch = 0.6900s	
12491/28500 (epoch 21.914), train_loss = 1.04286079, grad/param norm = 1.5989e-01, time/batch = 0.6937s	
12492/28500 (epoch 21.916), train_loss = 0.99245897, grad/param norm = 1.6103e-01, time/batch = 0.6915s	
12493/28500 (epoch 21.918), train_loss = 0.98683637, grad/param norm = 1.8268e-01, time/batch = 0.6894s	
12494/28500 (epoch 21.919), train_loss = 0.97460524, grad/param norm = 1.4980e-01, time/batch = 0.6902s	
12495/28500 (epoch 21.921), train_loss = 1.07116716, grad/param norm = 1.8561e-01, time/batch = 0.6892s	
12496/28500 (epoch 21.923), train_loss = 0.95534036, grad/param norm = 1.8524e-01, time/batch = 0.6894s	
12497/28500 (epoch 21.925), train_loss = 0.92578477, grad/param norm = 1.7494e-01, time/batch = 0.6908s	
12498/28500 (epoch 21.926), train_loss = 0.98138395, grad/param norm = 1.5118e-01, time/batch = 0.6907s	
12499/28500 (epoch 21.928), train_loss = 0.95128119, grad/param norm = 1.5732e-01, time/batch = 0.6893s	
12500/28500 (epoch 21.930), train_loss = 0.77508775, grad/param norm = 1.3648e-01, time/batch = 0.6905s	
12501/28500 (epoch 21.932), train_loss = 0.77099872, grad/param norm = 1.2241e-01, time/batch = 0.6915s	
12502/28500 (epoch 21.933), train_loss = 1.05587228, grad/param norm = 1.5837e-01, time/batch = 0.6898s	
12503/28500 (epoch 21.935), train_loss = 1.07590428, grad/param norm = 1.7175e-01, time/batch = 0.6899s	
12504/28500 (epoch 21.937), train_loss = 1.09190706, grad/param norm = 1.8823e-01, time/batch = 0.6907s	
12505/28500 (epoch 21.939), train_loss = 1.14286198, grad/param norm = 1.8213e-01, time/batch = 0.6900s	
12506/28500 (epoch 21.940), train_loss = 0.87003867, grad/param norm = 1.6327e-01, time/batch = 0.6897s	
12507/28500 (epoch 21.942), train_loss = 0.98997094, grad/param norm = 1.5557e-01, time/batch = 0.6894s	
12508/28500 (epoch 21.944), train_loss = 0.93347259, grad/param norm = 1.6960e-01, time/batch = 0.6904s	
12509/28500 (epoch 21.946), train_loss = 1.07441131, grad/param norm = 1.5985e-01, time/batch = 0.6914s	
12510/28500 (epoch 21.947), train_loss = 1.26727971, grad/param norm = 2.1802e-01, time/batch = 0.6889s	
12511/28500 (epoch 21.949), train_loss = 0.94418979, grad/param norm = 1.7909e-01, time/batch = 0.6943s	
12512/28500 (epoch 21.951), train_loss = 1.17086136, grad/param norm = 1.9939e-01, time/batch = 0.6930s	
12513/28500 (epoch 21.953), train_loss = 1.14179904, grad/param norm = 1.9454e-01, time/batch = 0.6956s	
12514/28500 (epoch 21.954), train_loss = 1.10867191, grad/param norm = 1.9767e-01, time/batch = 0.6914s	
12515/28500 (epoch 21.956), train_loss = 1.03819271, grad/param norm = 2.6024e-01, time/batch = 0.6972s	
12516/28500 (epoch 21.958), train_loss = 1.19857429, grad/param norm = 1.6821e-01, time/batch = 0.6969s	
12517/28500 (epoch 21.960), train_loss = 0.91528534, grad/param norm = 1.7287e-01, time/batch = 0.6912s	
12518/28500 (epoch 21.961), train_loss = 1.18917287, grad/param norm = 1.9115e-01, time/batch = 0.6915s	
12519/28500 (epoch 21.963), train_loss = 1.13645602, grad/param norm = 1.8325e-01, time/batch = 0.6902s	
12520/28500 (epoch 21.965), train_loss = 0.91656960, grad/param norm = 1.6127e-01, time/batch = 0.6905s	
12521/28500 (epoch 21.967), train_loss = 0.89646426, grad/param norm = 1.4695e-01, time/batch = 0.6952s	
12522/28500 (epoch 21.968), train_loss = 0.86009118, grad/param norm = 1.3304e-01, time/batch = 0.6947s	
12523/28500 (epoch 21.970), train_loss = 0.91508221, grad/param norm = 1.5918e-01, time/batch = 0.6901s	
12524/28500 (epoch 21.972), train_loss = 1.01315235, grad/param norm = 2.2866e-01, time/batch = 0.6904s	
12525/28500 (epoch 21.974), train_loss = 1.18753797, grad/param norm = 1.9409e-01, time/batch = 0.6905s	
12526/28500 (epoch 21.975), train_loss = 0.91014590, grad/param norm = 1.6338e-01, time/batch = 0.6887s	
12527/28500 (epoch 21.977), train_loss = 1.10679228, grad/param norm = 1.8823e-01, time/batch = 0.6930s	
12528/28500 (epoch 21.979), train_loss = 0.97799676, grad/param norm = 1.7069e-01, time/batch = 0.6943s	
12529/28500 (epoch 21.981), train_loss = 0.91004866, grad/param norm = 1.6985e-01, time/batch = 0.6931s	
12530/28500 (epoch 21.982), train_loss = 0.97353285, grad/param norm = 1.5896e-01, time/batch = 0.6903s	
12531/28500 (epoch 21.984), train_loss = 1.05571250, grad/param norm = 1.6258e-01, time/batch = 0.6959s	
12532/28500 (epoch 21.986), train_loss = 1.22410305, grad/param norm = 1.8165e-01, time/batch = 0.6944s	
12533/28500 (epoch 21.988), train_loss = 0.86044317, grad/param norm = 1.5101e-01, time/batch = 0.6987s	
12534/28500 (epoch 21.989), train_loss = 1.02762027, grad/param norm = 1.6216e-01, time/batch = 0.6941s	
12535/28500 (epoch 21.991), train_loss = 0.91186456, grad/param norm = 1.6086e-01, time/batch = 0.6939s	
12536/28500 (epoch 21.993), train_loss = 0.93796819, grad/param norm = 1.7142e-01, time/batch = 0.6916s	
12537/28500 (epoch 21.995), train_loss = 0.92388006, grad/param norm = 1.6197e-01, time/batch = 0.6922s	
12538/28500 (epoch 21.996), train_loss = 0.89903340, grad/param norm = 1.8715e-01, time/batch = 0.6927s	
12539/28500 (epoch 21.998), train_loss = 1.09944611, grad/param norm = 1.8870e-01, time/batch = 0.6934s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
12540/28500 (epoch 22.000), train_loss = 0.95399020, grad/param norm = 1.5502e-01, time/batch = 0.6919s	
12541/28500 (epoch 22.002), train_loss = 1.14507384, grad/param norm = 1.8330e-01, time/batch = 0.6954s	
12542/28500 (epoch 22.004), train_loss = 0.94636402, grad/param norm = 1.5960e-01, time/batch = 0.6928s	
12543/28500 (epoch 22.005), train_loss = 1.13531188, grad/param norm = 1.8915e-01, time/batch = 0.6937s	
12544/28500 (epoch 22.007), train_loss = 0.88376411, grad/param norm = 1.3892e-01, time/batch = 0.6919s	
12545/28500 (epoch 22.009), train_loss = 1.05044347, grad/param norm = 1.9477e-01, time/batch = 0.6934s	
12546/28500 (epoch 22.011), train_loss = 0.91533648, grad/param norm = 1.8235e-01, time/batch = 0.6933s	
12547/28500 (epoch 22.012), train_loss = 0.87111571, grad/param norm = 1.4455e-01, time/batch = 0.6989s	
12548/28500 (epoch 22.014), train_loss = 0.90753272, grad/param norm = 1.6487e-01, time/batch = 0.6990s	
12549/28500 (epoch 22.016), train_loss = 0.93893756, grad/param norm = 1.5807e-01, time/batch = 0.7180s	
12550/28500 (epoch 22.018), train_loss = 0.98709909, grad/param norm = 1.6247e-01, time/batch = 0.7189s	
12551/28500 (epoch 22.019), train_loss = 1.06091677, grad/param norm = 1.7572e-01, time/batch = 0.7032s	
12552/28500 (epoch 22.021), train_loss = 1.07151775, grad/param norm = 1.5787e-01, time/batch = 0.6976s	
12553/28500 (epoch 22.023), train_loss = 0.98508002, grad/param norm = 1.8601e-01, time/batch = 0.7040s	
12554/28500 (epoch 22.025), train_loss = 1.02658556, grad/param norm = 1.5813e-01, time/batch = 0.6984s	
12555/28500 (epoch 22.026), train_loss = 0.96625315, grad/param norm = 1.5145e-01, time/batch = 0.6997s	
12556/28500 (epoch 22.028), train_loss = 1.03112856, grad/param norm = 1.8904e-01, time/batch = 0.6979s	
12557/28500 (epoch 22.030), train_loss = 1.05173112, grad/param norm = 1.8731e-01, time/batch = 0.7026s	
12558/28500 (epoch 22.032), train_loss = 1.07780163, grad/param norm = 1.7520e-01, time/batch = 0.6971s	
12559/28500 (epoch 22.033), train_loss = 1.15536590, grad/param norm = 1.8197e-01, time/batch = 0.6996s	
12560/28500 (epoch 22.035), train_loss = 1.00703541, grad/param norm = 1.7616e-01, time/batch = 0.6996s	
12561/28500 (epoch 22.037), train_loss = 1.06744035, grad/param norm = 1.5629e-01, time/batch = 0.7082s	
12562/28500 (epoch 22.039), train_loss = 1.10558233, grad/param norm = 1.7957e-01, time/batch = 0.6998s	
12563/28500 (epoch 22.040), train_loss = 1.13091980, grad/param norm = 1.7017e-01, time/batch = 0.6974s	
12564/28500 (epoch 22.042), train_loss = 1.06895408, grad/param norm = 1.6885e-01, time/batch = 0.7075s	
12565/28500 (epoch 22.044), train_loss = 0.98855927, grad/param norm = 1.6040e-01, time/batch = 0.7031s	
12566/28500 (epoch 22.046), train_loss = 1.22205659, grad/param norm = 1.7382e-01, time/batch = 0.7068s	
12567/28500 (epoch 22.047), train_loss = 1.13683913, grad/param norm = 1.8048e-01, time/batch = 0.7028s	
12568/28500 (epoch 22.049), train_loss = 1.01488380, grad/param norm = 1.6470e-01, time/batch = 0.7081s	
12569/28500 (epoch 22.051), train_loss = 1.01058270, grad/param norm = 1.6306e-01, time/batch = 0.7168s	
12570/28500 (epoch 22.053), train_loss = 1.00443203, grad/param norm = 2.0631e-01, time/batch = 0.7065s	
12571/28500 (epoch 22.054), train_loss = 1.07862006, grad/param norm = 1.6669e-01, time/batch = 0.7020s	
12572/28500 (epoch 22.056), train_loss = 0.92740749, grad/param norm = 1.5936e-01, time/batch = 0.7015s	
12573/28500 (epoch 22.058), train_loss = 0.90922235, grad/param norm = 1.5188e-01, time/batch = 0.7011s	
12574/28500 (epoch 22.060), train_loss = 1.09039604, grad/param norm = 1.7529e-01, time/batch = 0.6971s	
12575/28500 (epoch 22.061), train_loss = 1.00509011, grad/param norm = 1.7156e-01, time/batch = 0.7006s	
12576/28500 (epoch 22.063), train_loss = 1.07742877, grad/param norm = 1.7295e-01, time/batch = 0.7000s	
12577/28500 (epoch 22.065), train_loss = 1.06775455, grad/param norm = 1.7415e-01, time/batch = 0.7028s	
12578/28500 (epoch 22.067), train_loss = 0.97815319, grad/param norm = 1.5179e-01, time/batch = 0.6976s	
12579/28500 (epoch 22.068), train_loss = 0.98692745, grad/param norm = 1.4734e-01, time/batch = 0.6988s	
12580/28500 (epoch 22.070), train_loss = 1.04869274, grad/param norm = 1.7301e-01, time/batch = 0.6994s	
12581/28500 (epoch 22.072), train_loss = 1.15820053, grad/param norm = 1.7325e-01, time/batch = 0.7007s	
12582/28500 (epoch 22.074), train_loss = 1.02853212, grad/param norm = 1.5602e-01, time/batch = 0.6997s	
12583/28500 (epoch 22.075), train_loss = 0.98003252, grad/param norm = 1.4276e-01, time/batch = 0.6968s	
12584/28500 (epoch 22.077), train_loss = 1.06821192, grad/param norm = 1.5845e-01, time/batch = 0.6995s	
12585/28500 (epoch 22.079), train_loss = 1.03546805, grad/param norm = 1.7682e-01, time/batch = 0.6983s	
12586/28500 (epoch 22.081), train_loss = 1.12689243, grad/param norm = 1.7899e-01, time/batch = 0.7083s	
12587/28500 (epoch 22.082), train_loss = 1.03086002, grad/param norm = 2.1690e-01, time/batch = 0.7139s	
12588/28500 (epoch 22.084), train_loss = 1.04687889, grad/param norm = 1.5910e-01, time/batch = 0.7070s	
12589/28500 (epoch 22.086), train_loss = 0.98454613, grad/param norm = 1.9498e-01, time/batch = 0.7000s	
12590/28500 (epoch 22.088), train_loss = 0.94723275, grad/param norm = 1.8006e-01, time/batch = 0.6987s	
12591/28500 (epoch 22.089), train_loss = 1.09940248, grad/param norm = 1.5585e-01, time/batch = 0.7014s	
12592/28500 (epoch 22.091), train_loss = 0.88940037, grad/param norm = 1.4923e-01, time/batch = 0.7006s	
12593/28500 (epoch 22.093), train_loss = 1.06183091, grad/param norm = 1.5572e-01, time/batch = 0.7089s	
12594/28500 (epoch 22.095), train_loss = 0.96145592, grad/param norm = 1.5190e-01, time/batch = 0.6978s	
12595/28500 (epoch 22.096), train_loss = 1.12979444, grad/param norm = 1.8492e-01, time/batch = 0.6987s	
12596/28500 (epoch 22.098), train_loss = 1.01454830, grad/param norm = 1.7145e-01, time/batch = 0.6968s	
12597/28500 (epoch 22.100), train_loss = 0.97000005, grad/param norm = 1.6258e-01, time/batch = 0.6993s	
12598/28500 (epoch 22.102), train_loss = 1.08246372, grad/param norm = 1.8693e-01, time/batch = 0.6975s	
12599/28500 (epoch 22.104), train_loss = 0.99460609, grad/param norm = 1.7940e-01, time/batch = 0.6977s	
12600/28500 (epoch 22.105), train_loss = 1.13473715, grad/param norm = 1.5792e-01, time/batch = 0.6931s	
12601/28500 (epoch 22.107), train_loss = 0.90063557, grad/param norm = 1.4826e-01, time/batch = 0.6972s	
12602/28500 (epoch 22.109), train_loss = 0.89451990, grad/param norm = 1.5657e-01, time/batch = 0.6976s	
12603/28500 (epoch 22.111), train_loss = 0.96414050, grad/param norm = 1.6814e-01, time/batch = 0.6934s	
12604/28500 (epoch 22.112), train_loss = 1.06687214, grad/param norm = 1.6168e-01, time/batch = 0.6957s	
12605/28500 (epoch 22.114), train_loss = 0.98926816, grad/param norm = 1.6470e-01, time/batch = 0.6936s	
12606/28500 (epoch 22.116), train_loss = 1.17344161, grad/param norm = 1.8315e-01, time/batch = 0.6945s	
12607/28500 (epoch 22.118), train_loss = 0.88909163, grad/param norm = 1.6740e-01, time/batch = 0.6951s	
12608/28500 (epoch 22.119), train_loss = 1.03064443, grad/param norm = 1.7626e-01, time/batch = 0.6951s	
12609/28500 (epoch 22.121), train_loss = 1.16107077, grad/param norm = 1.9477e-01, time/batch = 0.6979s	
12610/28500 (epoch 22.123), train_loss = 1.09736447, grad/param norm = 1.8194e-01, time/batch = 0.6945s	
12611/28500 (epoch 22.125), train_loss = 1.01587850, grad/param norm = 1.7211e-01, time/batch = 0.6978s	
12612/28500 (epoch 22.126), train_loss = 1.01174361, grad/param norm = 1.6353e-01, time/batch = 0.6940s	
12613/28500 (epoch 22.128), train_loss = 1.02275059, grad/param norm = 1.6549e-01, time/batch = 0.6948s	
12614/28500 (epoch 22.130), train_loss = 0.93886364, grad/param norm = 1.8272e-01, time/batch = 0.6940s	
12615/28500 (epoch 22.132), train_loss = 1.03092516, grad/param norm = 1.7983e-01, time/batch = 0.6941s	
12616/28500 (epoch 22.133), train_loss = 1.09427343, grad/param norm = 1.8718e-01, time/batch = 0.6940s	
12617/28500 (epoch 22.135), train_loss = 0.95872714, grad/param norm = 1.5130e-01, time/batch = 0.6951s	
12618/28500 (epoch 22.137), train_loss = 1.00671695, grad/param norm = 1.7008e-01, time/batch = 0.6941s	
12619/28500 (epoch 22.139), train_loss = 1.00152451, grad/param norm = 1.5997e-01, time/batch = 0.6938s	
12620/28500 (epoch 22.140), train_loss = 1.03501403, grad/param norm = 1.4997e-01, time/batch = 0.6950s	
12621/28500 (epoch 22.142), train_loss = 0.98720874, grad/param norm = 1.7545e-01, time/batch = 0.6956s	
12622/28500 (epoch 22.144), train_loss = 0.94773201, grad/param norm = 1.4818e-01, time/batch = 0.6972s	
12623/28500 (epoch 22.146), train_loss = 0.96526407, grad/param norm = 1.5041e-01, time/batch = 0.6945s	
12624/28500 (epoch 22.147), train_loss = 0.87818377, grad/param norm = 1.5275e-01, time/batch = 0.6954s	
12625/28500 (epoch 22.149), train_loss = 0.88260042, grad/param norm = 1.6041e-01, time/batch = 0.6933s	
12626/28500 (epoch 22.151), train_loss = 0.95830714, grad/param norm = 1.5652e-01, time/batch = 0.6947s	
12627/28500 (epoch 22.153), train_loss = 1.01333943, grad/param norm = 1.7513e-01, time/batch = 0.6932s	
12628/28500 (epoch 22.154), train_loss = 0.89964480, grad/param norm = 1.5114e-01, time/batch = 0.6946s	
12629/28500 (epoch 22.156), train_loss = 1.11160807, grad/param norm = 1.7189e-01, time/batch = 0.7055s	
12630/28500 (epoch 22.158), train_loss = 1.02590344, grad/param norm = 1.6694e-01, time/batch = 0.7107s	
12631/28500 (epoch 22.160), train_loss = 0.89891418, grad/param norm = 1.4054e-01, time/batch = 0.7080s	
12632/28500 (epoch 22.161), train_loss = 0.96222275, grad/param norm = 2.0366e-01, time/batch = 0.6992s	
12633/28500 (epoch 22.163), train_loss = 0.87133143, grad/param norm = 1.5531e-01, time/batch = 0.6980s	
12634/28500 (epoch 22.165), train_loss = 1.20306478, grad/param norm = 1.6424e-01, time/batch = 0.7010s	
12635/28500 (epoch 22.167), train_loss = 1.19984673, grad/param norm = 1.8759e-01, time/batch = 0.7006s	
12636/28500 (epoch 22.168), train_loss = 1.13115677, grad/param norm = 1.8611e-01, time/batch = 0.6993s	
12637/28500 (epoch 22.170), train_loss = 1.11079204, grad/param norm = 1.8011e-01, time/batch = 0.6953s	
12638/28500 (epoch 22.172), train_loss = 1.00846572, grad/param norm = 1.6306e-01, time/batch = 0.6949s	
12639/28500 (epoch 22.174), train_loss = 1.18559807, grad/param norm = 2.0794e-01, time/batch = 0.6944s	
12640/28500 (epoch 22.175), train_loss = 1.00481654, grad/param norm = 1.5972e-01, time/batch = 0.7033s	
12641/28500 (epoch 22.177), train_loss = 1.07276584, grad/param norm = 1.7212e-01, time/batch = 0.6992s	
12642/28500 (epoch 22.179), train_loss = 1.04603321, grad/param norm = 1.8355e-01, time/batch = 0.6955s	
12643/28500 (epoch 22.181), train_loss = 1.07577336, grad/param norm = 1.7448e-01, time/batch = 0.7158s	
12644/28500 (epoch 22.182), train_loss = 0.97682594, grad/param norm = 1.5495e-01, time/batch = 0.6951s	
12645/28500 (epoch 22.184), train_loss = 1.15924203, grad/param norm = 1.7967e-01, time/batch = 0.6940s	
12646/28500 (epoch 22.186), train_loss = 1.13553138, grad/param norm = 1.6982e-01, time/batch = 0.7004s	
12647/28500 (epoch 22.188), train_loss = 1.04458471, grad/param norm = 1.6947e-01, time/batch = 0.6951s	
12648/28500 (epoch 22.189), train_loss = 1.02883933, grad/param norm = 1.5654e-01, time/batch = 0.7009s	
12649/28500 (epoch 22.191), train_loss = 1.23798894, grad/param norm = 1.8293e-01, time/batch = 0.6938s	
12650/28500 (epoch 22.193), train_loss = 1.06181691, grad/param norm = 1.6899e-01, time/batch = 0.7028s	
12651/28500 (epoch 22.195), train_loss = 1.16578813, grad/param norm = 1.7786e-01, time/batch = 0.7103s	
12652/28500 (epoch 22.196), train_loss = 1.09030511, grad/param norm = 1.9616e-01, time/batch = 0.6973s	
12653/28500 (epoch 22.198), train_loss = 1.04079399, grad/param norm = 1.6867e-01, time/batch = 0.6989s	
12654/28500 (epoch 22.200), train_loss = 1.08572793, grad/param norm = 1.7737e-01, time/batch = 0.7004s	
12655/28500 (epoch 22.202), train_loss = 1.04516597, grad/param norm = 1.5571e-01, time/batch = 0.6938s	
12656/28500 (epoch 22.204), train_loss = 0.97071335, grad/param norm = 1.4064e-01, time/batch = 0.6948s	
12657/28500 (epoch 22.205), train_loss = 0.97669742, grad/param norm = 1.7443e-01, time/batch = 0.6938s	
12658/28500 (epoch 22.207), train_loss = 0.93812791, grad/param norm = 1.6527e-01, time/batch = 0.6996s	
12659/28500 (epoch 22.209), train_loss = 1.01915984, grad/param norm = 1.4801e-01, time/batch = 0.6936s	
12660/28500 (epoch 22.211), train_loss = 0.87423035, grad/param norm = 1.6042e-01, time/batch = 0.6960s	
12661/28500 (epoch 22.212), train_loss = 0.85470971, grad/param norm = 1.4438e-01, time/batch = 0.6960s	
12662/28500 (epoch 22.214), train_loss = 1.00058432, grad/param norm = 1.7138e-01, time/batch = 0.6972s	
12663/28500 (epoch 22.216), train_loss = 0.93507876, grad/param norm = 1.5799e-01, time/batch = 0.6962s	
12664/28500 (epoch 22.218), train_loss = 1.13183478, grad/param norm = 1.5276e-01, time/batch = 0.6951s	
12665/28500 (epoch 22.219), train_loss = 1.04138001, grad/param norm = 1.6227e-01, time/batch = 0.6953s	
12666/28500 (epoch 22.221), train_loss = 0.89348891, grad/param norm = 1.8224e-01, time/batch = 0.6942s	
12667/28500 (epoch 22.223), train_loss = 1.14276693, grad/param norm = 1.7536e-01, time/batch = 0.6974s	
12668/28500 (epoch 22.225), train_loss = 1.12771858, grad/param norm = 1.6848e-01, time/batch = 0.6942s	
12669/28500 (epoch 22.226), train_loss = 0.95949205, grad/param norm = 1.4047e-01, time/batch = 0.6951s	
12670/28500 (epoch 22.228), train_loss = 1.11103687, grad/param norm = 1.4883e-01, time/batch = 0.6952s	
12671/28500 (epoch 22.230), train_loss = 1.09673447, grad/param norm = 1.6493e-01, time/batch = 0.6972s	
12672/28500 (epoch 22.232), train_loss = 1.04461726, grad/param norm = 1.6082e-01, time/batch = 0.6952s	
12673/28500 (epoch 22.233), train_loss = 1.03867464, grad/param norm = 1.7145e-01, time/batch = 0.6976s	
12674/28500 (epoch 22.235), train_loss = 0.98091330, grad/param norm = 1.4827e-01, time/batch = 0.6949s	
12675/28500 (epoch 22.237), train_loss = 0.90388936, grad/param norm = 1.5181e-01, time/batch = 0.7006s	
12676/28500 (epoch 22.239), train_loss = 0.95183278, grad/param norm = 1.4133e-01, time/batch = 0.6962s	
12677/28500 (epoch 22.240), train_loss = 0.90061482, grad/param norm = 1.5429e-01, time/batch = 0.7088s	
12678/28500 (epoch 22.242), train_loss = 1.05111193, grad/param norm = 1.9175e-01, time/batch = 0.6978s	
12679/28500 (epoch 22.244), train_loss = 1.05978217, grad/param norm = 1.4755e-01, time/batch = 0.6980s	
12680/28500 (epoch 22.246), train_loss = 1.10024817, grad/param norm = 1.7038e-01, time/batch = 0.6947s	
12681/28500 (epoch 22.247), train_loss = 1.16949817, grad/param norm = 1.8232e-01, time/batch = 0.6998s	
12682/28500 (epoch 22.249), train_loss = 1.03466706, grad/param norm = 1.6636e-01, time/batch = 0.7024s	
12683/28500 (epoch 22.251), train_loss = 0.97651592, grad/param norm = 1.4926e-01, time/batch = 0.6973s	
12684/28500 (epoch 22.253), train_loss = 1.14165746, grad/param norm = 1.7590e-01, time/batch = 0.6950s	
12685/28500 (epoch 22.254), train_loss = 1.16291998, grad/param norm = 1.6238e-01, time/batch = 0.6984s	
12686/28500 (epoch 22.256), train_loss = 0.95013491, grad/param norm = 1.5371e-01, time/batch = 0.7010s	
12687/28500 (epoch 22.258), train_loss = 1.00714100, grad/param norm = 1.7594e-01, time/batch = 0.6944s	
12688/28500 (epoch 22.260), train_loss = 0.96000483, grad/param norm = 1.5705e-01, time/batch = 0.6950s	
12689/28500 (epoch 22.261), train_loss = 0.94048638, grad/param norm = 1.6711e-01, time/batch = 0.6959s	
12690/28500 (epoch 22.263), train_loss = 1.12464820, grad/param norm = 1.8805e-01, time/batch = 0.6929s	
12691/28500 (epoch 22.265), train_loss = 1.03098515, grad/param norm = 1.7171e-01, time/batch = 0.6960s	
12692/28500 (epoch 22.267), train_loss = 1.16333917, grad/param norm = 1.8134e-01, time/batch = 0.6976s	
12693/28500 (epoch 22.268), train_loss = 1.05882850, grad/param norm = 1.5091e-01, time/batch = 0.6960s	
12694/28500 (epoch 22.270), train_loss = 1.06041150, grad/param norm = 1.7717e-01, time/batch = 0.6985s	
12695/28500 (epoch 22.272), train_loss = 0.99689812, grad/param norm = 1.6366e-01, time/batch = 0.6946s	
12696/28500 (epoch 22.274), train_loss = 1.13741177, grad/param norm = 1.7984e-01, time/batch = 0.7027s	
12697/28500 (epoch 22.275), train_loss = 1.04632337, grad/param norm = 1.4689e-01, time/batch = 0.6966s	
12698/28500 (epoch 22.277), train_loss = 1.02822429, grad/param norm = 1.6788e-01, time/batch = 0.7028s	
12699/28500 (epoch 22.279), train_loss = 1.06424550, grad/param norm = 1.6701e-01, time/batch = 0.6978s	
12700/28500 (epoch 22.281), train_loss = 1.10619276, grad/param norm = 1.8069e-01, time/batch = 0.6968s	
12701/28500 (epoch 22.282), train_loss = 0.95475320, grad/param norm = 1.4486e-01, time/batch = 0.7023s	
12702/28500 (epoch 22.284), train_loss = 1.02971721, grad/param norm = 1.7253e-01, time/batch = 0.6988s	
12703/28500 (epoch 22.286), train_loss = 1.16019255, grad/param norm = 1.7099e-01, time/batch = 0.7022s	
12704/28500 (epoch 22.288), train_loss = 1.06932112, grad/param norm = 1.8246e-01, time/batch = 0.6973s	
12705/28500 (epoch 22.289), train_loss = 1.07411007, grad/param norm = 1.9785e-01, time/batch = 0.7016s	
12706/28500 (epoch 22.291), train_loss = 1.04928551, grad/param norm = 1.5550e-01, time/batch = 0.6979s	
12707/28500 (epoch 22.293), train_loss = 1.01692715, grad/param norm = 1.5309e-01, time/batch = 0.6997s	
12708/28500 (epoch 22.295), train_loss = 0.90454281, grad/param norm = 1.6419e-01, time/batch = 0.6970s	
12709/28500 (epoch 22.296), train_loss = 0.90298097, grad/param norm = 1.5589e-01, time/batch = 0.6995s	
12710/28500 (epoch 22.298), train_loss = 1.08733120, grad/param norm = 1.5658e-01, time/batch = 0.6959s	
12711/28500 (epoch 22.300), train_loss = 0.94986526, grad/param norm = 1.5948e-01, time/batch = 0.7005s	
12712/28500 (epoch 22.302), train_loss = 0.90260305, grad/param norm = 1.5128e-01, time/batch = 0.7005s	
12713/28500 (epoch 22.304), train_loss = 0.98666571, grad/param norm = 1.6092e-01, time/batch = 0.6971s	
12714/28500 (epoch 22.305), train_loss = 1.05025740, grad/param norm = 1.5784e-01, time/batch = 0.6984s	
12715/28500 (epoch 22.307), train_loss = 1.01479593, grad/param norm = 1.6894e-01, time/batch = 0.6960s	
12716/28500 (epoch 22.309), train_loss = 1.02710848, grad/param norm = 1.6829e-01, time/batch = 0.7017s	
12717/28500 (epoch 22.311), train_loss = 1.06874860, grad/param norm = 1.4900e-01, time/batch = 0.6989s	
12718/28500 (epoch 22.312), train_loss = 1.04098343, grad/param norm = 1.7132e-01, time/batch = 0.7127s	
12719/28500 (epoch 22.314), train_loss = 1.09624601, grad/param norm = 1.9199e-01, time/batch = 0.7165s	
12720/28500 (epoch 22.316), train_loss = 1.03164903, grad/param norm = 1.6162e-01, time/batch = 1.4299s	
12721/28500 (epoch 22.318), train_loss = 1.09850192, grad/param norm = 1.6658e-01, time/batch = 0.7232s	
12722/28500 (epoch 22.319), train_loss = 0.98781694, grad/param norm = 1.7397e-01, time/batch = 0.7074s	
12723/28500 (epoch 22.321), train_loss = 0.96942517, grad/param norm = 1.7139e-01, time/batch = 0.7003s	
12724/28500 (epoch 22.323), train_loss = 0.98638872, grad/param norm = 1.7806e-01, time/batch = 0.7067s	
12725/28500 (epoch 22.325), train_loss = 1.15511138, grad/param norm = 1.6314e-01, time/batch = 0.7021s	
12726/28500 (epoch 22.326), train_loss = 1.03812068, grad/param norm = 1.5996e-01, time/batch = 0.8227s	
12727/28500 (epoch 22.328), train_loss = 0.83420966, grad/param norm = 1.5024e-01, time/batch = 0.6975s	
12728/28500 (epoch 22.330), train_loss = 0.93800638, grad/param norm = 1.5719e-01, time/batch = 0.7012s	
12729/28500 (epoch 22.332), train_loss = 1.02551525, grad/param norm = 1.5669e-01, time/batch = 0.6973s	
12730/28500 (epoch 22.333), train_loss = 0.85359360, grad/param norm = 1.6174e-01, time/batch = 0.7010s	
12731/28500 (epoch 22.335), train_loss = 0.91754211, grad/param norm = 1.5430e-01, time/batch = 0.7031s	
12732/28500 (epoch 22.337), train_loss = 0.89097145, grad/param norm = 1.4504e-01, time/batch = 0.7107s	
12733/28500 (epoch 22.339), train_loss = 0.84103582, grad/param norm = 1.2945e-01, time/batch = 0.7087s	
12734/28500 (epoch 22.340), train_loss = 1.03580658, grad/param norm = 1.8231e-01, time/batch = 0.6979s	
12735/28500 (epoch 22.342), train_loss = 1.00044464, grad/param norm = 1.7483e-01, time/batch = 0.6966s	
12736/28500 (epoch 22.344), train_loss = 0.94478151, grad/param norm = 1.6769e-01, time/batch = 0.7004s	
12737/28500 (epoch 22.346), train_loss = 0.83796849, grad/param norm = 1.3527e-01, time/batch = 0.6969s	
12738/28500 (epoch 22.347), train_loss = 1.01460052, grad/param norm = 1.7859e-01, time/batch = 0.6978s	
12739/28500 (epoch 22.349), train_loss = 0.98290697, grad/param norm = 1.5042e-01, time/batch = 0.6967s	
12740/28500 (epoch 22.351), train_loss = 0.91667330, grad/param norm = 1.4686e-01, time/batch = 0.7160s	
12741/28500 (epoch 22.353), train_loss = 1.02944616, grad/param norm = 1.8379e-01, time/batch = 0.7023s	
12742/28500 (epoch 22.354), train_loss = 0.90585672, grad/param norm = 1.5530e-01, time/batch = 0.6991s	
12743/28500 (epoch 22.356), train_loss = 0.92130138, grad/param norm = 1.5333e-01, time/batch = 0.6991s	
12744/28500 (epoch 22.358), train_loss = 1.03887584, grad/param norm = 1.6688e-01, time/batch = 0.7005s	
12745/28500 (epoch 22.360), train_loss = 1.04510831, grad/param norm = 1.7263e-01, time/batch = 0.7023s	
12746/28500 (epoch 22.361), train_loss = 0.94076983, grad/param norm = 1.4637e-01, time/batch = 0.6970s	
12747/28500 (epoch 22.363), train_loss = 0.89394306, grad/param norm = 1.4657e-01, time/batch = 0.7140s	
12748/28500 (epoch 22.365), train_loss = 0.96722054, grad/param norm = 1.5884e-01, time/batch = 0.7044s	
12749/28500 (epoch 22.367), train_loss = 0.99217900, grad/param norm = 1.5625e-01, time/batch = 0.6968s	
12750/28500 (epoch 22.368), train_loss = 0.95626023, grad/param norm = 1.4985e-01, time/batch = 0.7002s	
12751/28500 (epoch 22.370), train_loss = 1.00115792, grad/param norm = 1.6005e-01, time/batch = 0.6986s	
12752/28500 (epoch 22.372), train_loss = 0.84687405, grad/param norm = 1.5558e-01, time/batch = 0.7000s	
12753/28500 (epoch 22.374), train_loss = 0.97571566, grad/param norm = 1.6123e-01, time/batch = 0.6970s	
12754/28500 (epoch 22.375), train_loss = 1.10912461, grad/param norm = 1.5633e-01, time/batch = 0.7063s	
12755/28500 (epoch 22.377), train_loss = 0.85646957, grad/param norm = 1.5772e-01, time/batch = 0.7177s	
12756/28500 (epoch 22.379), train_loss = 0.78259185, grad/param norm = 1.6513e-01, time/batch = 0.7024s	
12757/28500 (epoch 22.381), train_loss = 0.96471573, grad/param norm = 1.6383e-01, time/batch = 0.6973s	
12758/28500 (epoch 22.382), train_loss = 0.94243192, grad/param norm = 1.7614e-01, time/batch = 0.7122s	
12759/28500 (epoch 22.384), train_loss = 0.84406926, grad/param norm = 1.4643e-01, time/batch = 0.6972s	
12760/28500 (epoch 22.386), train_loss = 0.87655280, grad/param norm = 1.6119e-01, time/batch = 0.6998s	
12761/28500 (epoch 22.388), train_loss = 1.07293123, grad/param norm = 1.6162e-01, time/batch = 0.7006s	
12762/28500 (epoch 22.389), train_loss = 0.92405948, grad/param norm = 1.5873e-01, time/batch = 0.7138s	
12763/28500 (epoch 22.391), train_loss = 0.89467147, grad/param norm = 1.5137e-01, time/batch = 0.7055s	
12764/28500 (epoch 22.393), train_loss = 0.89557481, grad/param norm = 1.6073e-01, time/batch = 0.6965s	
12765/28500 (epoch 22.395), train_loss = 1.15114949, grad/param norm = 1.7389e-01, time/batch = 0.6998s	
12766/28500 (epoch 22.396), train_loss = 1.06507509, grad/param norm = 1.7235e-01, time/batch = 0.6967s	
12767/28500 (epoch 22.398), train_loss = 0.76624580, grad/param norm = 1.5664e-01, time/batch = 0.6970s	
12768/28500 (epoch 22.400), train_loss = 0.97940184, grad/param norm = 1.7480e-01, time/batch = 0.6993s	
12769/28500 (epoch 22.402), train_loss = 1.01819605, grad/param norm = 1.9486e-01, time/batch = 0.7121s	
12770/28500 (epoch 22.404), train_loss = 1.06993267, grad/param norm = 1.7161e-01, time/batch = 0.7089s	
12771/28500 (epoch 22.405), train_loss = 1.06528768, grad/param norm = 1.5363e-01, time/batch = 0.7034s	
12772/28500 (epoch 22.407), train_loss = 1.02389375, grad/param norm = 1.6598e-01, time/batch = 0.6986s	
12773/28500 (epoch 22.409), train_loss = 1.02660655, grad/param norm = 1.7029e-01, time/batch = 0.7000s	
12774/28500 (epoch 22.411), train_loss = 1.10032602, grad/param norm = 1.6777e-01, time/batch = 0.6977s	
12775/28500 (epoch 22.412), train_loss = 1.11047201, grad/param norm = 1.9063e-01, time/batch = 0.7012s	
12776/28500 (epoch 22.414), train_loss = 1.02641842, grad/param norm = 1.6731e-01, time/batch = 0.6973s	
12777/28500 (epoch 22.416), train_loss = 0.92648587, grad/param norm = 1.5462e-01, time/batch = 0.7021s	
12778/28500 (epoch 22.418), train_loss = 1.01058669, grad/param norm = 1.4469e-01, time/batch = 0.7023s	
12779/28500 (epoch 22.419), train_loss = 1.12543050, grad/param norm = 1.8512e-01, time/batch = 0.7040s	
12780/28500 (epoch 22.421), train_loss = 1.08300776, grad/param norm = 1.6294e-01, time/batch = 0.6977s	
12781/28500 (epoch 22.423), train_loss = 1.09690048, grad/param norm = 1.8738e-01, time/batch = 0.7052s	
12782/28500 (epoch 22.425), train_loss = 1.04853311, grad/param norm = 1.8195e-01, time/batch = 0.7025s	
12783/28500 (epoch 22.426), train_loss = 1.01069864, grad/param norm = 1.9764e-01, time/batch = 0.6997s	
12784/28500 (epoch 22.428), train_loss = 1.18798343, grad/param norm = 1.9536e-01, time/batch = 0.7033s	
12785/28500 (epoch 22.430), train_loss = 1.13322329, grad/param norm = 1.5689e-01, time/batch = 0.6984s	
12786/28500 (epoch 22.432), train_loss = 1.04688052, grad/param norm = 1.8217e-01, time/batch = 0.6981s	
12787/28500 (epoch 22.433), train_loss = 1.06637344, grad/param norm = 1.8488e-01, time/batch = 0.6999s	
12788/28500 (epoch 22.435), train_loss = 1.04565269, grad/param norm = 1.7937e-01, time/batch = 0.6994s	
12789/28500 (epoch 22.437), train_loss = 0.94400544, grad/param norm = 1.4974e-01, time/batch = 0.7006s	
12790/28500 (epoch 22.439), train_loss = 0.97401966, grad/param norm = 1.4777e-01, time/batch = 0.7045s	
12791/28500 (epoch 22.440), train_loss = 1.22331252, grad/param norm = 1.8635e-01, time/batch = 0.7005s	
12792/28500 (epoch 22.442), train_loss = 0.95488802, grad/param norm = 1.7036e-01, time/batch = 0.7018s	
12793/28500 (epoch 22.444), train_loss = 0.86158078, grad/param norm = 1.4172e-01, time/batch = 0.7001s	
12794/28500 (epoch 22.446), train_loss = 0.84276885, grad/param norm = 1.5358e-01, time/batch = 0.7043s	
12795/28500 (epoch 22.447), train_loss = 0.86360465, grad/param norm = 1.4386e-01, time/batch = 0.7005s	
12796/28500 (epoch 22.449), train_loss = 0.94869583, grad/param norm = 1.4217e-01, time/batch = 0.7010s	
12797/28500 (epoch 22.451), train_loss = 0.97756218, grad/param norm = 1.4418e-01, time/batch = 0.7026s	
12798/28500 (epoch 22.453), train_loss = 0.98370901, grad/param norm = 1.6106e-01, time/batch = 0.7009s	
12799/28500 (epoch 22.454), train_loss = 0.94602746, grad/param norm = 1.5220e-01, time/batch = 0.7004s	
12800/28500 (epoch 22.456), train_loss = 1.07443856, grad/param norm = 1.9230e-01, time/batch = 0.7017s	
12801/28500 (epoch 22.458), train_loss = 0.97826212, grad/param norm = 1.5649e-01, time/batch = 0.7017s	
12802/28500 (epoch 22.460), train_loss = 1.05709096, grad/param norm = 1.7155e-01, time/batch = 0.7067s	
12803/28500 (epoch 22.461), train_loss = 0.95793720, grad/param norm = 1.8358e-01, time/batch = 0.7077s	
12804/28500 (epoch 22.463), train_loss = 0.86735887, grad/param norm = 1.4292e-01, time/batch = 0.7041s	
12805/28500 (epoch 22.465), train_loss = 0.84414368, grad/param norm = 1.6090e-01, time/batch = 0.6922s	
12806/28500 (epoch 22.467), train_loss = 0.98315066, grad/param norm = 1.4780e-01, time/batch = 0.6922s	
12807/28500 (epoch 22.468), train_loss = 0.90489335, grad/param norm = 1.4073e-01, time/batch = 0.7175s	
12808/28500 (epoch 22.470), train_loss = 0.91918587, grad/param norm = 1.5173e-01, time/batch = 0.6918s	
12809/28500 (epoch 22.472), train_loss = 0.94114837, grad/param norm = 1.5447e-01, time/batch = 0.7016s	
12810/28500 (epoch 22.474), train_loss = 1.14262585, grad/param norm = 1.6978e-01, time/batch = 0.6931s	
12811/28500 (epoch 22.475), train_loss = 0.90659771, grad/param norm = 1.4885e-01, time/batch = 0.6972s	
12812/28500 (epoch 22.477), train_loss = 0.96838443, grad/param norm = 1.6601e-01, time/batch = 0.6960s	
12813/28500 (epoch 22.479), train_loss = 1.04380429, grad/param norm = 1.6586e-01, time/batch = 0.6910s	
12814/28500 (epoch 22.481), train_loss = 1.01300861, grad/param norm = 1.9859e-01, time/batch = 0.6936s	
12815/28500 (epoch 22.482), train_loss = 0.89480877, grad/param norm = 1.5024e-01, time/batch = 0.6945s	
12816/28500 (epoch 22.484), train_loss = 0.89147559, grad/param norm = 1.4762e-01, time/batch = 0.6962s	
12817/28500 (epoch 22.486), train_loss = 0.81400098, grad/param norm = 1.6643e-01, time/batch = 0.6915s	
12818/28500 (epoch 22.488), train_loss = 1.01002849, grad/param norm = 1.4684e-01, time/batch = 0.6899s	
12819/28500 (epoch 22.489), train_loss = 1.08988965, grad/param norm = 1.6156e-01, time/batch = 0.7041s	
12820/28500 (epoch 22.491), train_loss = 0.95704458, grad/param norm = 1.6503e-01, time/batch = 0.6907s	
12821/28500 (epoch 22.493), train_loss = 0.96844077, grad/param norm = 1.6411e-01, time/batch = 0.6928s	
12822/28500 (epoch 22.495), train_loss = 0.97484379, grad/param norm = 1.4642e-01, time/batch = 0.6954s	
12823/28500 (epoch 22.496), train_loss = 0.89950898, grad/param norm = 1.6141e-01, time/batch = 0.6914s	
12824/28500 (epoch 22.498), train_loss = 0.99624185, grad/param norm = 1.5736e-01, time/batch = 0.6938s	
12825/28500 (epoch 22.500), train_loss = 0.93122140, grad/param norm = 1.4118e-01, time/batch = 0.7008s	
12826/28500 (epoch 22.502), train_loss = 1.07679766, grad/param norm = 1.5684e-01, time/batch = 0.6984s	
12827/28500 (epoch 22.504), train_loss = 1.00716030, grad/param norm = 1.5827e-01, time/batch = 0.6930s	
12828/28500 (epoch 22.505), train_loss = 0.92130437, grad/param norm = 1.6060e-01, time/batch = 0.6894s	
12829/28500 (epoch 22.507), train_loss = 1.10116120, grad/param norm = 2.0055e-01, time/batch = 0.6931s	
12830/28500 (epoch 22.509), train_loss = 0.98555710, grad/param norm = 1.6677e-01, time/batch = 0.6949s	
12831/28500 (epoch 22.511), train_loss = 0.98147750, grad/param norm = 1.6853e-01, time/batch = 0.6938s	
12832/28500 (epoch 22.512), train_loss = 1.02878084, grad/param norm = 1.6189e-01, time/batch = 0.6908s	
12833/28500 (epoch 22.514), train_loss = 0.94673131, grad/param norm = 1.5357e-01, time/batch = 0.6920s	
12834/28500 (epoch 22.516), train_loss = 0.96100588, grad/param norm = 1.4491e-01, time/batch = 0.6901s	
12835/28500 (epoch 22.518), train_loss = 1.03134086, grad/param norm = 1.5991e-01, time/batch = 0.6917s	
12836/28500 (epoch 22.519), train_loss = 1.06353084, grad/param norm = 1.5494e-01, time/batch = 0.6954s	
12837/28500 (epoch 22.521), train_loss = 1.14665941, grad/param norm = 1.7126e-01, time/batch = 0.7069s	
12838/28500 (epoch 22.523), train_loss = 1.06223866, grad/param norm = 1.9893e-01, time/batch = 0.6947s	
12839/28500 (epoch 22.525), train_loss = 1.07727411, grad/param norm = 1.6426e-01, time/batch = 0.6962s	
12840/28500 (epoch 22.526), train_loss = 1.06791432, grad/param norm = 1.6707e-01, time/batch = 0.6947s	
12841/28500 (epoch 22.528), train_loss = 1.07960906, grad/param norm = 1.7305e-01, time/batch = 0.7054s	
12842/28500 (epoch 22.530), train_loss = 1.08168678, grad/param norm = 1.5471e-01, time/batch = 0.6947s	
12843/28500 (epoch 22.532), train_loss = 0.96459593, grad/param norm = 1.5056e-01, time/batch = 0.7010s	
12844/28500 (epoch 22.533), train_loss = 1.08960975, grad/param norm = 1.7077e-01, time/batch = 0.6951s	
12845/28500 (epoch 22.535), train_loss = 0.84270645, grad/param norm = 1.3411e-01, time/batch = 0.7003s	
12846/28500 (epoch 22.537), train_loss = 0.88491112, grad/param norm = 1.5172e-01, time/batch = 0.6916s	
12847/28500 (epoch 22.539), train_loss = 0.84071491, grad/param norm = 1.5389e-01, time/batch = 0.6926s	
12848/28500 (epoch 22.540), train_loss = 1.01544028, grad/param norm = 1.7327e-01, time/batch = 0.6915s	
12849/28500 (epoch 22.542), train_loss = 1.04855940, grad/param norm = 1.8100e-01, time/batch = 0.6901s	
12850/28500 (epoch 22.544), train_loss = 1.14816304, grad/param norm = 1.6833e-01, time/batch = 0.6919s	
12851/28500 (epoch 22.546), train_loss = 0.97693128, grad/param norm = 1.6328e-01, time/batch = 0.6927s	
12852/28500 (epoch 22.547), train_loss = 1.00929611, grad/param norm = 1.6372e-01, time/batch = 0.6978s	
12853/28500 (epoch 22.549), train_loss = 0.83397758, grad/param norm = 1.2540e-01, time/batch = 0.6904s	
12854/28500 (epoch 22.551), train_loss = 0.98104029, grad/param norm = 1.9433e-01, time/batch = 0.6966s	
12855/28500 (epoch 22.553), train_loss = 1.18153238, grad/param norm = 2.0132e-01, time/batch = 0.6903s	
12856/28500 (epoch 22.554), train_loss = 1.01187909, grad/param norm = 1.6192e-01, time/batch = 0.6980s	
12857/28500 (epoch 22.556), train_loss = 1.03352275, grad/param norm = 1.7263e-01, time/batch = 0.6962s	
12858/28500 (epoch 22.558), train_loss = 1.02956389, grad/param norm = 1.5669e-01, time/batch = 0.7005s	
12859/28500 (epoch 22.560), train_loss = 1.04159614, grad/param norm = 1.6987e-01, time/batch = 0.7127s	
12860/28500 (epoch 22.561), train_loss = 1.07895157, grad/param norm = 1.7498e-01, time/batch = 0.7283s	
12861/28500 (epoch 22.563), train_loss = 1.13466732, grad/param norm = 1.8328e-01, time/batch = 0.7079s	
12862/28500 (epoch 22.565), train_loss = 0.96044793, grad/param norm = 1.5898e-01, time/batch = 0.7076s	
12863/28500 (epoch 22.567), train_loss = 0.88435743, grad/param norm = 1.5327e-01, time/batch = 0.6953s	
12864/28500 (epoch 22.568), train_loss = 1.04778532, grad/param norm = 1.7622e-01, time/batch = 0.7046s	
12865/28500 (epoch 22.570), train_loss = 0.97847435, grad/param norm = 1.6371e-01, time/batch = 0.6970s	
12866/28500 (epoch 22.572), train_loss = 0.95819723, grad/param norm = 1.5586e-01, time/batch = 0.6940s	
12867/28500 (epoch 22.574), train_loss = 0.96889306, grad/param norm = 1.6073e-01, time/batch = 0.7022s	
12868/28500 (epoch 22.575), train_loss = 0.97174909, grad/param norm = 1.5905e-01, time/batch = 0.6998s	
12869/28500 (epoch 22.577), train_loss = 1.01592747, grad/param norm = 1.5690e-01, time/batch = 0.7028s	
12870/28500 (epoch 22.579), train_loss = 1.07639778, grad/param norm = 1.6250e-01, time/batch = 0.6944s	
12871/28500 (epoch 22.581), train_loss = 0.91972312, grad/param norm = 1.6561e-01, time/batch = 0.6943s	
12872/28500 (epoch 22.582), train_loss = 1.07273205, grad/param norm = 1.4954e-01, time/batch = 0.6986s	
12873/28500 (epoch 22.584), train_loss = 0.95445038, grad/param norm = 1.6428e-01, time/batch = 0.6927s	
12874/28500 (epoch 22.586), train_loss = 0.91210983, grad/param norm = 1.3520e-01, time/batch = 0.6981s	
12875/28500 (epoch 22.588), train_loss = 0.92607667, grad/param norm = 1.5483e-01, time/batch = 0.6970s	
12876/28500 (epoch 22.589), train_loss = 1.02093796, grad/param norm = 1.6554e-01, time/batch = 0.6914s	
12877/28500 (epoch 22.591), train_loss = 0.99680812, grad/param norm = 1.5710e-01, time/batch = 0.6923s	
12878/28500 (epoch 22.593), train_loss = 0.93990668, grad/param norm = 1.5283e-01, time/batch = 0.6965s	
12879/28500 (epoch 22.595), train_loss = 1.18708773, grad/param norm = 1.8596e-01, time/batch = 0.6916s	
12880/28500 (epoch 22.596), train_loss = 1.17534202, grad/param norm = 1.7016e-01, time/batch = 0.6962s	
12881/28500 (epoch 22.598), train_loss = 1.01611731, grad/param norm = 1.7050e-01, time/batch = 0.6953s	
12882/28500 (epoch 22.600), train_loss = 1.00276248, grad/param norm = 1.6828e-01, time/batch = 0.6995s	
12883/28500 (epoch 22.602), train_loss = 1.09929937, grad/param norm = 1.8199e-01, time/batch = 0.6910s	
12884/28500 (epoch 22.604), train_loss = 1.07858580, grad/param norm = 1.6168e-01, time/batch = 0.6923s	
12885/28500 (epoch 22.605), train_loss = 1.04631599, grad/param norm = 1.6686e-01, time/batch = 0.6955s	
12886/28500 (epoch 22.607), train_loss = 1.10307240, grad/param norm = 1.4931e-01, time/batch = 0.6977s	
12887/28500 (epoch 22.609), train_loss = 1.03503062, grad/param norm = 2.0422e-01, time/batch = 0.6938s	
12888/28500 (epoch 22.611), train_loss = 0.98430373, grad/param norm = 1.6145e-01, time/batch = 0.6977s	
12889/28500 (epoch 22.612), train_loss = 1.05195136, grad/param norm = 1.7389e-01, time/batch = 0.7107s	
12890/28500 (epoch 22.614), train_loss = 1.05556716, grad/param norm = 1.6555e-01, time/batch = 0.7031s	
12891/28500 (epoch 22.616), train_loss = 0.95471730, grad/param norm = 1.7520e-01, time/batch = 0.7005s	
12892/28500 (epoch 22.618), train_loss = 0.98827241, grad/param norm = 1.6136e-01, time/batch = 0.6970s	
12893/28500 (epoch 22.619), train_loss = 1.15178831, grad/param norm = 1.9383e-01, time/batch = 0.7080s	
12894/28500 (epoch 22.621), train_loss = 0.83428691, grad/param norm = 1.4773e-01, time/batch = 0.7094s	
12895/28500 (epoch 22.623), train_loss = 1.11581962, grad/param norm = 1.7797e-01, time/batch = 0.6936s	
12896/28500 (epoch 22.625), train_loss = 0.90000734, grad/param norm = 1.5520e-01, time/batch = 0.7037s	
12897/28500 (epoch 22.626), train_loss = 0.78455409, grad/param norm = 1.3550e-01, time/batch = 0.6969s	
12898/28500 (epoch 22.628), train_loss = 0.93574119, grad/param norm = 1.6137e-01, time/batch = 0.6965s	
12899/28500 (epoch 22.630), train_loss = 0.86688613, grad/param norm = 1.4188e-01, time/batch = 0.6997s	
12900/28500 (epoch 22.632), train_loss = 1.10441439, grad/param norm = 1.7200e-01, time/batch = 0.6995s	
12901/28500 (epoch 22.633), train_loss = 1.15590074, grad/param norm = 1.5711e-01, time/batch = 0.7031s	
12902/28500 (epoch 22.635), train_loss = 1.08316822, grad/param norm = 1.7298e-01, time/batch = 0.6994s	
12903/28500 (epoch 22.637), train_loss = 1.03476028, grad/param norm = 1.5640e-01, time/batch = 0.7020s	
12904/28500 (epoch 22.639), train_loss = 0.89872021, grad/param norm = 1.5653e-01, time/batch = 0.6966s	
12905/28500 (epoch 22.640), train_loss = 0.93463692, grad/param norm = 1.4866e-01, time/batch = 0.6975s	
12906/28500 (epoch 22.642), train_loss = 0.94630819, grad/param norm = 1.6003e-01, time/batch = 0.6934s	
12907/28500 (epoch 22.644), train_loss = 1.07895158, grad/param norm = 1.7507e-01, time/batch = 0.6981s	
12908/28500 (epoch 22.646), train_loss = 0.87830761, grad/param norm = 1.4341e-01, time/batch = 0.7096s	
12909/28500 (epoch 22.647), train_loss = 0.91441624, grad/param norm = 1.5607e-01, time/batch = 0.7056s	
12910/28500 (epoch 22.649), train_loss = 0.87202537, grad/param norm = 1.5626e-01, time/batch = 0.6943s	
12911/28500 (epoch 22.651), train_loss = 0.87026908, grad/param norm = 1.5177e-01, time/batch = 0.7014s	
12912/28500 (epoch 22.653), train_loss = 0.86124626, grad/param norm = 1.4034e-01, time/batch = 0.6943s	
12913/28500 (epoch 22.654), train_loss = 0.95588909, grad/param norm = 1.6658e-01, time/batch = 0.6966s	
12914/28500 (epoch 22.656), train_loss = 0.91130698, grad/param norm = 1.6851e-01, time/batch = 0.6965s	
12915/28500 (epoch 22.658), train_loss = 0.97011966, grad/param norm = 1.6104e-01, time/batch = 0.6976s	
12916/28500 (epoch 22.660), train_loss = 0.97622213, grad/param norm = 1.5556e-01, time/batch = 0.6927s	
12917/28500 (epoch 22.661), train_loss = 1.13920519, grad/param norm = 1.8599e-01, time/batch = 0.6966s	
12918/28500 (epoch 22.663), train_loss = 1.12246502, grad/param norm = 1.7848e-01, time/batch = 0.6926s	
12919/28500 (epoch 22.665), train_loss = 0.97051359, grad/param norm = 1.4550e-01, time/batch = 0.6986s	
12920/28500 (epoch 22.667), train_loss = 0.98803315, grad/param norm = 1.7348e-01, time/batch = 0.6985s	
12921/28500 (epoch 22.668), train_loss = 0.97981455, grad/param norm = 1.5396e-01, time/batch = 0.6967s	
12922/28500 (epoch 22.670), train_loss = 1.00536833, grad/param norm = 1.6273e-01, time/batch = 0.6929s	
12923/28500 (epoch 22.672), train_loss = 0.94492873, grad/param norm = 1.7331e-01, time/batch = 0.6947s	
12924/28500 (epoch 22.674), train_loss = 0.83426877, grad/param norm = 1.5999e-01, time/batch = 0.6943s	
12925/28500 (epoch 22.675), train_loss = 0.86393398, grad/param norm = 1.4652e-01, time/batch = 0.7112s	
12926/28500 (epoch 22.677), train_loss = 0.95935144, grad/param norm = 1.5368e-01, time/batch = 0.7040s	
12927/28500 (epoch 22.679), train_loss = 0.94508788, grad/param norm = 1.6196e-01, time/batch = 0.7110s	
12928/28500 (epoch 22.681), train_loss = 1.03266149, grad/param norm = 1.6680e-01, time/batch = 0.6937s	
12929/28500 (epoch 22.682), train_loss = 0.95558454, grad/param norm = 1.5053e-01, time/batch = 0.7023s	
12930/28500 (epoch 22.684), train_loss = 1.02007908, grad/param norm = 1.5774e-01, time/batch = 0.6982s	
12931/28500 (epoch 22.686), train_loss = 0.94888514, grad/param norm = 1.6781e-01, time/batch = 0.7008s	
12932/28500 (epoch 22.688), train_loss = 0.89765405, grad/param norm = 1.4091e-01, time/batch = 0.6996s	
12933/28500 (epoch 22.689), train_loss = 0.96910807, grad/param norm = 1.9092e-01, time/batch = 0.6970s	
12934/28500 (epoch 22.691), train_loss = 0.99796666, grad/param norm = 1.6537e-01, time/batch = 0.6966s	
12935/28500 (epoch 22.693), train_loss = 0.93344980, grad/param norm = 1.5783e-01, time/batch = 0.6939s	
12936/28500 (epoch 22.695), train_loss = 0.75088731, grad/param norm = 1.7340e-01, time/batch = 0.6949s	
12937/28500 (epoch 22.696), train_loss = 0.96902771, grad/param norm = 1.6295e-01, time/batch = 0.6927s	
12938/28500 (epoch 22.698), train_loss = 0.96686241, grad/param norm = 1.5676e-01, time/batch = 0.6950s	
12939/28500 (epoch 22.700), train_loss = 0.99134786, grad/param norm = 1.6334e-01, time/batch = 0.6932s	
12940/28500 (epoch 22.702), train_loss = 1.03107548, grad/param norm = 1.7435e-01, time/batch = 0.6994s	
12941/28500 (epoch 22.704), train_loss = 1.00434209, grad/param norm = 1.5392e-01, time/batch = 0.6980s	
12942/28500 (epoch 22.705), train_loss = 1.10324893, grad/param norm = 2.0097e-01, time/batch = 0.6958s	
12943/28500 (epoch 22.707), train_loss = 0.91877149, grad/param norm = 1.6619e-01, time/batch = 0.7014s	
12944/28500 (epoch 22.709), train_loss = 1.12648439, grad/param norm = 1.7952e-01, time/batch = 0.7023s	
12945/28500 (epoch 22.711), train_loss = 0.91149741, grad/param norm = 1.5427e-01, time/batch = 0.6947s	
12946/28500 (epoch 22.712), train_loss = 1.02723537, grad/param norm = 1.8987e-01, time/batch = 0.6991s	
12947/28500 (epoch 22.714), train_loss = 1.10909912, grad/param norm = 1.7007e-01, time/batch = 0.6942s	
12948/28500 (epoch 22.716), train_loss = 0.97325927, grad/param norm = 1.6638e-01, time/batch = 0.6944s	
12949/28500 (epoch 22.718), train_loss = 1.00565868, grad/param norm = 1.6121e-01, time/batch = 0.6932s	
12950/28500 (epoch 22.719), train_loss = 0.98916254, grad/param norm = 1.5514e-01, time/batch = 0.7046s	
12951/28500 (epoch 22.721), train_loss = 0.81780656, grad/param norm = 1.5524e-01, time/batch = 0.6949s	
12952/28500 (epoch 22.723), train_loss = 0.98705135, grad/param norm = 1.6863e-01, time/batch = 0.6945s	
12953/28500 (epoch 22.725), train_loss = 1.06986217, grad/param norm = 1.5724e-01, time/batch = 0.6931s	
12954/28500 (epoch 22.726), train_loss = 0.98020252, grad/param norm = 1.5651e-01, time/batch = 0.6968s	
12955/28500 (epoch 22.728), train_loss = 0.90340719, grad/param norm = 1.5398e-01, time/batch = 0.6944s	
12956/28500 (epoch 22.730), train_loss = 0.98965270, grad/param norm = 1.6508e-01, time/batch = 0.6939s	
12957/28500 (epoch 22.732), train_loss = 0.81841501, grad/param norm = 1.3955e-01, time/batch = 0.6951s	
12958/28500 (epoch 22.733), train_loss = 0.84676468, grad/param norm = 1.4505e-01, time/batch = 0.6984s	
12959/28500 (epoch 22.735), train_loss = 0.84712186, grad/param norm = 1.5027e-01, time/batch = 0.7000s	
12960/28500 (epoch 22.737), train_loss = 0.77724931, grad/param norm = 1.3647e-01, time/batch = 0.7035s	
12961/28500 (epoch 22.739), train_loss = 0.93154779, grad/param norm = 1.7218e-01, time/batch = 0.7018s	
12962/28500 (epoch 22.740), train_loss = 0.97002379, grad/param norm = 1.5078e-01, time/batch = 0.6946s	
12963/28500 (epoch 22.742), train_loss = 0.91317452, grad/param norm = 1.5510e-01, time/batch = 0.6970s	
12964/28500 (epoch 22.744), train_loss = 1.01426608, grad/param norm = 1.7564e-01, time/batch = 0.7077s	
12965/28500 (epoch 22.746), train_loss = 0.90520198, grad/param norm = 1.5077e-01, time/batch = 0.6995s	
12966/28500 (epoch 22.747), train_loss = 0.90629393, grad/param norm = 1.5087e-01, time/batch = 0.7038s	
12967/28500 (epoch 22.749), train_loss = 1.06932397, grad/param norm = 1.9177e-01, time/batch = 0.6990s	
12968/28500 (epoch 22.751), train_loss = 0.87231107, grad/param norm = 1.7247e-01, time/batch = 0.7008s	
12969/28500 (epoch 22.753), train_loss = 0.94247535, grad/param norm = 1.4410e-01, time/batch = 0.6930s	
12970/28500 (epoch 22.754), train_loss = 0.87258522, grad/param norm = 1.4597e-01, time/batch = 0.6959s	
12971/28500 (epoch 22.756), train_loss = 1.07871236, grad/param norm = 1.6652e-01, time/batch = 0.6959s	
12972/28500 (epoch 22.758), train_loss = 1.04056974, grad/param norm = 1.7034e-01, time/batch = 0.6978s	
12973/28500 (epoch 22.760), train_loss = 0.88097802, grad/param norm = 1.6947e-01, time/batch = 0.6988s	
12974/28500 (epoch 22.761), train_loss = 0.90897822, grad/param norm = 1.6391e-01, time/batch = 0.7016s	
12975/28500 (epoch 22.763), train_loss = 0.80341336, grad/param norm = 1.5177e-01, time/batch = 0.7045s	
12976/28500 (epoch 22.765), train_loss = 0.94468837, grad/param norm = 1.5242e-01, time/batch = 0.6951s	
12977/28500 (epoch 22.767), train_loss = 0.83191173, grad/param norm = 1.4243e-01, time/batch = 0.6934s	
12978/28500 (epoch 22.768), train_loss = 1.03712227, grad/param norm = 1.6379e-01, time/batch = 0.6981s	
12979/28500 (epoch 22.770), train_loss = 0.84904801, grad/param norm = 1.5009e-01, time/batch = 0.6951s	
12980/28500 (epoch 22.772), train_loss = 0.75212638, grad/param norm = 1.3530e-01, time/batch = 0.6948s	
12981/28500 (epoch 22.774), train_loss = 0.97679171, grad/param norm = 1.6691e-01, time/batch = 0.6954s	
12982/28500 (epoch 22.775), train_loss = 1.05483442, grad/param norm = 1.5170e-01, time/batch = 0.6932s	
12983/28500 (epoch 22.777), train_loss = 1.06592957, grad/param norm = 1.7603e-01, time/batch = 0.6944s	
12984/28500 (epoch 22.779), train_loss = 0.80802513, grad/param norm = 1.4364e-01, time/batch = 0.6954s	
12985/28500 (epoch 22.781), train_loss = 0.95432327, grad/param norm = 1.8686e-01, time/batch = 0.6941s	
12986/28500 (epoch 22.782), train_loss = 1.03168721, grad/param norm = 1.7184e-01, time/batch = 0.6933s	
12987/28500 (epoch 22.784), train_loss = 0.80200401, grad/param norm = 1.4298e-01, time/batch = 0.6938s	
12988/28500 (epoch 22.786), train_loss = 0.86640649, grad/param norm = 1.4198e-01, time/batch = 0.6956s	
12989/28500 (epoch 22.788), train_loss = 0.95567539, grad/param norm = 1.8003e-01, time/batch = 0.6946s	
12990/28500 (epoch 22.789), train_loss = 0.71508178, grad/param norm = 1.6624e-01, time/batch = 0.6970s	
12991/28500 (epoch 22.791), train_loss = 0.97600721, grad/param norm = 1.5310e-01, time/batch = 0.6972s	
12992/28500 (epoch 22.793), train_loss = 0.96519308, grad/param norm = 1.5393e-01, time/batch = 0.6970s	
12993/28500 (epoch 22.795), train_loss = 0.99860548, grad/param norm = 1.5540e-01, time/batch = 0.6948s	
12994/28500 (epoch 22.796), train_loss = 0.85875150, grad/param norm = 1.5124e-01, time/batch = 0.6950s	
12995/28500 (epoch 22.798), train_loss = 0.81555205, grad/param norm = 1.5235e-01, time/batch = 0.6929s	
12996/28500 (epoch 22.800), train_loss = 0.85803383, grad/param norm = 1.6522e-01, time/batch = 0.6931s	
12997/28500 (epoch 22.802), train_loss = 0.95017298, grad/param norm = 1.8771e-01, time/batch = 0.7010s	
12998/28500 (epoch 22.804), train_loss = 0.98010482, grad/param norm = 1.4737e-01, time/batch = 0.6969s	
12999/28500 (epoch 22.805), train_loss = 0.96834714, grad/param norm = 1.7563e-01, time/batch = 0.6951s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch22.81_1.7397.t7	
13000/28500 (epoch 22.807), train_loss = 0.98964578, grad/param norm = 1.5729e-01, time/batch = 0.6930s	
13001/28500 (epoch 22.809), train_loss = 1.37919859, grad/param norm = 1.9503e-01, time/batch = 0.7096s	
13002/28500 (epoch 22.811), train_loss = 1.03220405, grad/param norm = 1.7727e-01, time/batch = 0.6974s	
13003/28500 (epoch 22.812), train_loss = 1.00027813, grad/param norm = 1.7155e-01, time/batch = 0.6996s	
13004/28500 (epoch 22.814), train_loss = 0.90400979, grad/param norm = 1.5428e-01, time/batch = 0.6965s	
13005/28500 (epoch 22.816), train_loss = 1.03517293, grad/param norm = 2.0545e-01, time/batch = 0.7060s	
13006/28500 (epoch 22.818), train_loss = 1.07423979, grad/param norm = 1.7050e-01, time/batch = 0.7002s	
13007/28500 (epoch 22.819), train_loss = 0.97034879, grad/param norm = 1.4942e-01, time/batch = 0.7046s	
13008/28500 (epoch 22.821), train_loss = 0.93861329, grad/param norm = 1.4793e-01, time/batch = 0.7017s	
13009/28500 (epoch 22.823), train_loss = 1.12479089, grad/param norm = 1.8793e-01, time/batch = 0.7028s	
13010/28500 (epoch 22.825), train_loss = 0.93459990, grad/param norm = 1.6069e-01, time/batch = 0.7002s	
13011/28500 (epoch 22.826), train_loss = 0.98342999, grad/param norm = 1.7669e-01, time/batch = 0.6996s	
13012/28500 (epoch 22.828), train_loss = 0.86694875, grad/param norm = 1.7118e-01, time/batch = 0.6971s	
13013/28500 (epoch 22.830), train_loss = 0.94016607, grad/param norm = 1.5855e-01, time/batch = 0.7002s	
13014/28500 (epoch 22.832), train_loss = 0.98666635, grad/param norm = 1.8278e-01, time/batch = 0.6980s	
13015/28500 (epoch 22.833), train_loss = 1.07664173, grad/param norm = 1.5821e-01, time/batch = 0.6959s	
13016/28500 (epoch 22.835), train_loss = 0.89652561, grad/param norm = 1.5719e-01, time/batch = 0.6970s	
13017/28500 (epoch 22.837), train_loss = 0.83296717, grad/param norm = 1.5108e-01, time/batch = 0.7018s	
13018/28500 (epoch 22.839), train_loss = 1.10105144, grad/param norm = 1.8205e-01, time/batch = 0.7001s	
13019/28500 (epoch 22.840), train_loss = 1.13544910, grad/param norm = 1.8168e-01, time/batch = 0.6960s	
13020/28500 (epoch 22.842), train_loss = 1.04921623, grad/param norm = 1.9732e-01, time/batch = 0.6978s	
13021/28500 (epoch 22.844), train_loss = 1.02985173, grad/param norm = 1.8273e-01, time/batch = 0.7001s	
13022/28500 (epoch 22.846), train_loss = 1.10923580, grad/param norm = 1.9074e-01, time/batch = 0.6989s	
13023/28500 (epoch 22.847), train_loss = 0.94978906, grad/param norm = 1.8382e-01, time/batch = 0.7005s	
13024/28500 (epoch 22.849), train_loss = 0.92757744, grad/param norm = 1.5510e-01, time/batch = 0.6958s	
13025/28500 (epoch 22.851), train_loss = 0.81174252, grad/param norm = 1.5008e-01, time/batch = 0.6964s	
13026/28500 (epoch 22.853), train_loss = 0.99405834, grad/param norm = 1.6892e-01, time/batch = 0.6977s	
13027/28500 (epoch 22.854), train_loss = 0.99922574, grad/param norm = 1.8143e-01, time/batch = 0.6959s	
13028/28500 (epoch 22.856), train_loss = 1.10774801, grad/param norm = 1.9526e-01, time/batch = 0.7004s	
13029/28500 (epoch 22.858), train_loss = 0.89070284, grad/param norm = 1.5163e-01, time/batch = 0.6969s	
13030/28500 (epoch 22.860), train_loss = 0.94084690, grad/param norm = 1.6736e-01, time/batch = 0.6972s	
13031/28500 (epoch 22.861), train_loss = 1.02573336, grad/param norm = 1.7432e-01, time/batch = 0.6995s	
13032/28500 (epoch 22.863), train_loss = 1.03361487, grad/param norm = 1.8684e-01, time/batch = 0.6972s	
13033/28500 (epoch 22.865), train_loss = 0.92064299, grad/param norm = 1.7303e-01, time/batch = 0.6989s	
13034/28500 (epoch 22.867), train_loss = 1.04079104, grad/param norm = 1.7932e-01, time/batch = 0.6987s	
13035/28500 (epoch 22.868), train_loss = 0.85132495, grad/param norm = 1.4661e-01, time/batch = 0.7007s	
13036/28500 (epoch 22.870), train_loss = 0.82870468, grad/param norm = 1.4940e-01, time/batch = 0.6970s	
13037/28500 (epoch 22.872), train_loss = 1.01583359, grad/param norm = 1.9390e-01, time/batch = 0.6969s	
13038/28500 (epoch 22.874), train_loss = 0.92268719, grad/param norm = 1.7245e-01, time/batch = 0.6960s	
13039/28500 (epoch 22.875), train_loss = 1.10343158, grad/param norm = 1.9014e-01, time/batch = 0.6957s	
13040/28500 (epoch 22.877), train_loss = 0.99180011, grad/param norm = 1.6196e-01, time/batch = 0.6985s	
13041/28500 (epoch 22.879), train_loss = 1.04551338, grad/param norm = 1.4871e-01, time/batch = 0.6994s	
13042/28500 (epoch 22.881), train_loss = 1.02096653, grad/param norm = 1.7675e-01, time/batch = 0.6970s	
13043/28500 (epoch 22.882), train_loss = 0.90537154, grad/param norm = 1.4772e-01, time/batch = 0.7002s	
13044/28500 (epoch 22.884), train_loss = 0.98289944, grad/param norm = 1.6834e-01, time/batch = 0.6969s	
13045/28500 (epoch 22.886), train_loss = 0.94874642, grad/param norm = 1.6189e-01, time/batch = 0.6998s	
13046/28500 (epoch 22.888), train_loss = 0.88902891, grad/param norm = 1.5891e-01, time/batch = 0.6982s	
13047/28500 (epoch 22.889), train_loss = 0.97520158, grad/param norm = 1.6231e-01, time/batch = 0.6988s	
13048/28500 (epoch 22.891), train_loss = 0.95918087, grad/param norm = 1.5704e-01, time/batch = 0.6970s	
13049/28500 (epoch 22.893), train_loss = 0.94828011, grad/param norm = 1.7188e-01, time/batch = 0.7004s	
13050/28500 (epoch 22.895), train_loss = 1.14950295, grad/param norm = 1.8173e-01, time/batch = 0.7010s	
13051/28500 (epoch 22.896), train_loss = 1.08225793, grad/param norm = 1.7365e-01, time/batch = 0.7073s	
13052/28500 (epoch 22.898), train_loss = 0.99745062, grad/param norm = 1.6580e-01, time/batch = 0.7071s	
13053/28500 (epoch 22.900), train_loss = 0.83646157, grad/param norm = 1.5223e-01, time/batch = 0.7200s	
13054/28500 (epoch 22.902), train_loss = 0.87594896, grad/param norm = 1.6604e-01, time/batch = 0.6973s	
13055/28500 (epoch 22.904), train_loss = 0.86872577, grad/param norm = 1.5296e-01, time/batch = 0.7015s	
13056/28500 (epoch 22.905), train_loss = 0.96122365, grad/param norm = 1.6563e-01, time/batch = 0.7170s	
13057/28500 (epoch 22.907), train_loss = 0.94882543, grad/param norm = 1.6091e-01, time/batch = 0.7090s	
13058/28500 (epoch 22.909), train_loss = 0.88195386, grad/param norm = 2.0614e-01, time/batch = 0.6959s	
13059/28500 (epoch 22.911), train_loss = 0.88613221, grad/param norm = 1.4531e-01, time/batch = 0.6980s	
13060/28500 (epoch 22.912), train_loss = 0.77550211, grad/param norm = 1.4741e-01, time/batch = 0.6966s	
13061/28500 (epoch 22.914), train_loss = 1.01962370, grad/param norm = 1.4958e-01, time/batch = 0.7043s	
13062/28500 (epoch 22.916), train_loss = 0.97202055, grad/param norm = 1.7707e-01, time/batch = 0.7011s	
13063/28500 (epoch 22.918), train_loss = 0.97456622, grad/param norm = 1.8907e-01, time/batch = 0.6981s	
13064/28500 (epoch 22.919), train_loss = 0.97464136, grad/param norm = 1.6563e-01, time/batch = 0.7005s	
13065/28500 (epoch 22.921), train_loss = 1.07602933, grad/param norm = 2.0648e-01, time/batch = 0.6970s	
13066/28500 (epoch 22.923), train_loss = 0.94308377, grad/param norm = 1.8079e-01, time/batch = 0.7012s	
13067/28500 (epoch 22.925), train_loss = 0.91056827, grad/param norm = 1.6697e-01, time/batch = 0.6990s	
13068/28500 (epoch 22.926), train_loss = 0.95345163, grad/param norm = 1.5410e-01, time/batch = 0.7028s	
13069/28500 (epoch 22.928), train_loss = 0.95109803, grad/param norm = 1.6903e-01, time/batch = 0.7007s	
13070/28500 (epoch 22.930), train_loss = 0.76147159, grad/param norm = 1.4349e-01, time/batch = 0.6955s	
13071/28500 (epoch 22.932), train_loss = 0.77314336, grad/param norm = 1.2076e-01, time/batch = 0.7007s	
13072/28500 (epoch 22.933), train_loss = 1.03975323, grad/param norm = 1.6686e-01, time/batch = 0.6961s	
13073/28500 (epoch 22.935), train_loss = 1.06421464, grad/param norm = 1.7946e-01, time/batch = 0.7003s	
13074/28500 (epoch 22.937), train_loss = 1.07147582, grad/param norm = 1.9762e-01, time/batch = 0.6951s	
13075/28500 (epoch 22.939), train_loss = 1.11942254, grad/param norm = 1.8256e-01, time/batch = 0.6976s	
13076/28500 (epoch 22.940), train_loss = 0.85772195, grad/param norm = 1.6300e-01, time/batch = 0.6970s	
13077/28500 (epoch 22.942), train_loss = 0.97272191, grad/param norm = 1.5486e-01, time/batch = 0.7006s	
13078/28500 (epoch 22.944), train_loss = 0.91293215, grad/param norm = 1.5199e-01, time/batch = 0.7005s	
13079/28500 (epoch 22.946), train_loss = 1.05998361, grad/param norm = 1.6127e-01, time/batch = 0.6977s	
13080/28500 (epoch 22.947), train_loss = 1.26835689, grad/param norm = 2.0602e-01, time/batch = 0.6974s	
13081/28500 (epoch 22.949), train_loss = 0.91978911, grad/param norm = 1.6611e-01, time/batch = 0.6991s	
13082/28500 (epoch 22.951), train_loss = 1.16873311, grad/param norm = 2.0045e-01, time/batch = 0.6998s	
13083/28500 (epoch 22.953), train_loss = 1.12085854, grad/param norm = 1.8956e-01, time/batch = 0.6968s	
13084/28500 (epoch 22.954), train_loss = 1.09931586, grad/param norm = 1.9490e-01, time/batch = 0.6968s	
13085/28500 (epoch 22.956), train_loss = 1.02426241, grad/param norm = 2.8468e-01, time/batch = 0.6966s	
13086/28500 (epoch 22.958), train_loss = 1.19102864, grad/param norm = 1.7115e-01, time/batch = 0.6953s	
13087/28500 (epoch 22.960), train_loss = 0.91061240, grad/param norm = 1.7799e-01, time/batch = 0.6942s	
13088/28500 (epoch 22.961), train_loss = 1.16091869, grad/param norm = 2.0240e-01, time/batch = 0.6940s	
13089/28500 (epoch 22.963), train_loss = 1.11041265, grad/param norm = 1.6312e-01, time/batch = 0.6984s	
13090/28500 (epoch 22.965), train_loss = 0.89553021, grad/param norm = 1.6999e-01, time/batch = 0.7126s	
13091/28500 (epoch 22.967), train_loss = 0.89319286, grad/param norm = 1.5152e-01, time/batch = 0.7020s	
13092/28500 (epoch 22.968), train_loss = 0.84640445, grad/param norm = 1.3819e-01, time/batch = 0.6967s	
13093/28500 (epoch 22.970), train_loss = 0.88972660, grad/param norm = 1.6240e-01, time/batch = 0.7001s	
13094/28500 (epoch 22.972), train_loss = 0.99186875, grad/param norm = 1.6788e-01, time/batch = 0.6956s	
13095/28500 (epoch 22.974), train_loss = 1.17626880, grad/param norm = 1.8741e-01, time/batch = 0.6947s	
13096/28500 (epoch 22.975), train_loss = 0.89769423, grad/param norm = 1.7348e-01, time/batch = 0.6997s	
13097/28500 (epoch 22.977), train_loss = 1.08683276, grad/param norm = 1.9591e-01, time/batch = 0.6944s	
13098/28500 (epoch 22.979), train_loss = 0.96682850, grad/param norm = 1.8128e-01, time/batch = 0.6938s	
13099/28500 (epoch 22.981), train_loss = 0.90079565, grad/param norm = 1.7780e-01, time/batch = 0.6926s	
13100/28500 (epoch 22.982), train_loss = 0.96742446, grad/param norm = 1.6343e-01, time/batch = 0.6946s	
13101/28500 (epoch 22.984), train_loss = 1.05369948, grad/param norm = 1.7452e-01, time/batch = 0.6983s	
13102/28500 (epoch 22.986), train_loss = 1.21679079, grad/param norm = 1.8027e-01, time/batch = 0.6942s	
13103/28500 (epoch 22.988), train_loss = 0.85100805, grad/param norm = 1.4850e-01, time/batch = 0.6934s	
13104/28500 (epoch 22.989), train_loss = 1.01502929, grad/param norm = 1.7148e-01, time/batch = 0.6940s	
13105/28500 (epoch 22.991), train_loss = 0.89683198, grad/param norm = 1.6260e-01, time/batch = 0.6924s	
13106/28500 (epoch 22.993), train_loss = 0.91236230, grad/param norm = 1.6367e-01, time/batch = 0.6921s	
13107/28500 (epoch 22.995), train_loss = 0.91729368, grad/param norm = 1.6595e-01, time/batch = 0.7003s	
13108/28500 (epoch 22.996), train_loss = 0.87540123, grad/param norm = 1.6664e-01, time/batch = 0.6953s	
13109/28500 (epoch 22.998), train_loss = 1.09809775, grad/param norm = 2.1814e-01, time/batch = 0.6979s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
13110/28500 (epoch 23.000), train_loss = 0.95295037, grad/param norm = 1.5919e-01, time/batch = 0.6927s	
13111/28500 (epoch 23.002), train_loss = 1.12735309, grad/param norm = 1.8055e-01, time/batch = 0.7154s	
13112/28500 (epoch 23.004), train_loss = 0.93875174, grad/param norm = 1.5298e-01, time/batch = 0.7073s	
13113/28500 (epoch 23.005), train_loss = 1.10682049, grad/param norm = 1.9670e-01, time/batch = 0.6953s	
13114/28500 (epoch 23.007), train_loss = 0.87693386, grad/param norm = 1.4408e-01, time/batch = 0.6995s	
13115/28500 (epoch 23.009), train_loss = 1.03317068, grad/param norm = 1.8850e-01, time/batch = 0.6953s	
13116/28500 (epoch 23.011), train_loss = 0.92025149, grad/param norm = 1.9820e-01, time/batch = 0.6927s	
13117/28500 (epoch 23.012), train_loss = 0.86400716, grad/param norm = 1.3610e-01, time/batch = 0.6964s	
13118/28500 (epoch 23.014), train_loss = 0.89085569, grad/param norm = 1.5929e-01, time/batch = 0.6926s	
13119/28500 (epoch 23.016), train_loss = 0.92857042, grad/param norm = 1.5420e-01, time/batch = 0.6948s	
13120/28500 (epoch 23.018), train_loss = 0.99905013, grad/param norm = 1.7127e-01, time/batch = 0.6944s	
13121/28500 (epoch 23.019), train_loss = 1.04535987, grad/param norm = 1.6829e-01, time/batch = 0.6980s	
13122/28500 (epoch 23.021), train_loss = 1.05773127, grad/param norm = 1.5523e-01, time/batch = 0.6933s	
13123/28500 (epoch 23.023), train_loss = 0.96468647, grad/param norm = 1.7135e-01, time/batch = 0.6947s	
13124/28500 (epoch 23.025), train_loss = 1.00929820, grad/param norm = 1.5594e-01, time/batch = 0.6931s	
13125/28500 (epoch 23.026), train_loss = 0.95496154, grad/param norm = 1.6005e-01, time/batch = 0.6950s	
13126/28500 (epoch 23.028), train_loss = 1.00505479, grad/param norm = 1.8022e-01, time/batch = 0.6970s	
13127/28500 (epoch 23.030), train_loss = 1.02445592, grad/param norm = 1.7623e-01, time/batch = 0.6986s	
13128/28500 (epoch 23.032), train_loss = 1.06656409, grad/param norm = 1.6461e-01, time/batch = 0.6927s	
13129/28500 (epoch 23.033), train_loss = 1.15183396, grad/param norm = 1.9892e-01, time/batch = 0.6976s	
13130/28500 (epoch 23.035), train_loss = 0.98790573, grad/param norm = 1.8055e-01, time/batch = 0.6932s	
13131/28500 (epoch 23.037), train_loss = 1.04514268, grad/param norm = 1.5812e-01, time/batch = 0.6972s	
13132/28500 (epoch 23.039), train_loss = 1.08915448, grad/param norm = 1.7189e-01, time/batch = 0.6929s	
13133/28500 (epoch 23.040), train_loss = 1.11027142, grad/param norm = 1.7159e-01, time/batch = 0.6953s	
13134/28500 (epoch 23.042), train_loss = 1.06028695, grad/param norm = 1.7129e-01, time/batch = 0.6929s	
13135/28500 (epoch 23.044), train_loss = 0.98297482, grad/param norm = 1.6718e-01, time/batch = 0.6994s	
13136/28500 (epoch 23.046), train_loss = 1.19891877, grad/param norm = 1.7391e-01, time/batch = 0.7154s	
13137/28500 (epoch 23.047), train_loss = 1.13395475, grad/param norm = 1.8263e-01, time/batch = 0.7076s	
13138/28500 (epoch 23.049), train_loss = 0.99667603, grad/param norm = 1.6804e-01, time/batch = 0.7209s	
13139/28500 (epoch 23.051), train_loss = 1.00491410, grad/param norm = 1.6395e-01, time/batch = 0.7041s	
13140/28500 (epoch 23.053), train_loss = 0.96376004, grad/param norm = 1.6150e-01, time/batch = 0.7224s	
13141/28500 (epoch 23.054), train_loss = 1.06788461, grad/param norm = 1.6856e-01, time/batch = 0.7087s	
13142/28500 (epoch 23.056), train_loss = 0.90846379, grad/param norm = 1.4894e-01, time/batch = 0.7094s	
13143/28500 (epoch 23.058), train_loss = 0.89426141, grad/param norm = 1.4987e-01, time/batch = 0.7122s	
13144/28500 (epoch 23.060), train_loss = 1.06877706, grad/param norm = 1.6846e-01, time/batch = 0.7012s	
13145/28500 (epoch 23.061), train_loss = 0.98279398, grad/param norm = 1.6622e-01, time/batch = 0.7025s	
13146/28500 (epoch 23.063), train_loss = 1.05628624, grad/param norm = 1.7206e-01, time/batch = 0.7159s	
13147/28500 (epoch 23.065), train_loss = 1.05889819, grad/param norm = 1.9377e-01, time/batch = 0.7163s	
13148/28500 (epoch 23.067), train_loss = 0.96474803, grad/param norm = 1.5454e-01, time/batch = 0.7037s	
13149/28500 (epoch 23.068), train_loss = 0.96952430, grad/param norm = 1.5524e-01, time/batch = 0.6981s	
13150/28500 (epoch 23.070), train_loss = 1.03629920, grad/param norm = 1.7455e-01, time/batch = 0.6966s	
13151/28500 (epoch 23.072), train_loss = 1.13726626, grad/param norm = 1.7280e-01, time/batch = 0.7018s	
13152/28500 (epoch 23.074), train_loss = 1.00664779, grad/param norm = 1.5214e-01, time/batch = 0.6989s	
13153/28500 (epoch 23.075), train_loss = 0.96407476, grad/param norm = 1.4183e-01, time/batch = 0.7210s	
13154/28500 (epoch 23.077), train_loss = 1.05523107, grad/param norm = 1.5808e-01, time/batch = 0.7099s	
13155/28500 (epoch 23.079), train_loss = 1.00583031, grad/param norm = 1.7113e-01, time/batch = 0.7139s	
13156/28500 (epoch 23.081), train_loss = 1.11650059, grad/param norm = 1.7752e-01, time/batch = 0.7034s	
13157/28500 (epoch 23.082), train_loss = 1.00537722, grad/param norm = 1.9851e-01, time/batch = 0.6957s	
13158/28500 (epoch 23.084), train_loss = 1.02374869, grad/param norm = 1.6939e-01, time/batch = 0.7014s	
13159/28500 (epoch 23.086), train_loss = 0.96099119, grad/param norm = 1.7230e-01, time/batch = 0.6947s	
13160/28500 (epoch 23.088), train_loss = 0.92489294, grad/param norm = 1.6999e-01, time/batch = 0.7044s	
13161/28500 (epoch 23.089), train_loss = 1.10333703, grad/param norm = 1.6032e-01, time/batch = 0.6979s	
13162/28500 (epoch 23.091), train_loss = 0.87322993, grad/param norm = 1.4797e-01, time/batch = 0.7072s	
13163/28500 (epoch 23.093), train_loss = 1.03443578, grad/param norm = 1.4818e-01, time/batch = 0.6927s	
13164/28500 (epoch 23.095), train_loss = 0.94603876, grad/param norm = 1.4929e-01, time/batch = 0.6949s	
13165/28500 (epoch 23.096), train_loss = 1.10958724, grad/param norm = 1.7449e-01, time/batch = 0.6934s	
13166/28500 (epoch 23.098), train_loss = 1.01853671, grad/param norm = 1.7621e-01, time/batch = 0.6944s	
13167/28500 (epoch 23.100), train_loss = 0.95063949, grad/param norm = 1.5427e-01, time/batch = 0.6926s	
13168/28500 (epoch 23.102), train_loss = 1.07054591, grad/param norm = 1.8769e-01, time/batch = 0.6939s	
13169/28500 (epoch 23.104), train_loss = 0.99973855, grad/param norm = 2.0017e-01, time/batch = 0.7080s	
13170/28500 (epoch 23.105), train_loss = 1.11638494, grad/param norm = 1.5703e-01, time/batch = 0.6977s	
13171/28500 (epoch 23.107), train_loss = 0.87825743, grad/param norm = 1.3886e-01, time/batch = 0.6993s	
13172/28500 (epoch 23.109), train_loss = 0.90754047, grad/param norm = 1.9097e-01, time/batch = 0.6989s	
13173/28500 (epoch 23.111), train_loss = 0.94441144, grad/param norm = 1.5906e-01, time/batch = 0.6961s	
13174/28500 (epoch 23.112), train_loss = 1.04621296, grad/param norm = 1.6464e-01, time/batch = 0.6977s	
13175/28500 (epoch 23.114), train_loss = 0.97577994, grad/param norm = 1.6064e-01, time/batch = 0.7020s	
13176/28500 (epoch 23.116), train_loss = 1.15612890, grad/param norm = 1.8217e-01, time/batch = 0.7049s	
13177/28500 (epoch 23.118), train_loss = 0.87229314, grad/param norm = 1.7612e-01, time/batch = 0.7132s	
13178/28500 (epoch 23.119), train_loss = 1.01209691, grad/param norm = 1.6273e-01, time/batch = 0.6968s	
13179/28500 (epoch 23.121), train_loss = 1.15146909, grad/param norm = 2.1175e-01, time/batch = 0.6991s	
13180/28500 (epoch 23.123), train_loss = 1.08255784, grad/param norm = 1.7497e-01, time/batch = 0.6967s	
13181/28500 (epoch 23.125), train_loss = 1.00203014, grad/param norm = 1.7503e-01, time/batch = 0.6996s	
13182/28500 (epoch 23.126), train_loss = 0.98651962, grad/param norm = 1.7058e-01, time/batch = 0.6973s	
13183/28500 (epoch 23.128), train_loss = 0.99841884, grad/param norm = 1.5957e-01, time/batch = 0.6969s	
13184/28500 (epoch 23.130), train_loss = 0.92246702, grad/param norm = 1.7749e-01, time/batch = 0.7174s	
13185/28500 (epoch 23.132), train_loss = 1.03176604, grad/param norm = 2.1328e-01, time/batch = 0.7021s	
13186/28500 (epoch 23.133), train_loss = 1.08146226, grad/param norm = 1.9296e-01, time/batch = 0.6996s	
13187/28500 (epoch 23.135), train_loss = 0.95420792, grad/param norm = 1.4876e-01, time/batch = 0.6977s	
13188/28500 (epoch 23.137), train_loss = 0.98741139, grad/param norm = 1.5985e-01, time/batch = 0.7010s	
13189/28500 (epoch 23.139), train_loss = 0.99257506, grad/param norm = 1.6016e-01, time/batch = 0.6964s	
13190/28500 (epoch 23.140), train_loss = 1.00903258, grad/param norm = 1.5799e-01, time/batch = 0.6986s	
13191/28500 (epoch 23.142), train_loss = 0.97685614, grad/param norm = 1.7616e-01, time/batch = 0.6995s	
13192/28500 (epoch 23.144), train_loss = 0.93180144, grad/param norm = 1.5066e-01, time/batch = 0.7152s	
13193/28500 (epoch 23.146), train_loss = 0.96062371, grad/param norm = 1.5451e-01, time/batch = 0.7124s	
13194/28500 (epoch 23.147), train_loss = 0.86690831, grad/param norm = 1.5106e-01, time/batch = 0.6997s	
13195/28500 (epoch 23.149), train_loss = 0.85616529, grad/param norm = 1.4600e-01, time/batch = 0.6975s	
13196/28500 (epoch 23.151), train_loss = 0.94559500, grad/param norm = 1.5532e-01, time/batch = 0.7070s	
13197/28500 (epoch 23.153), train_loss = 1.00901166, grad/param norm = 1.7731e-01, time/batch = 0.7111s	
13198/28500 (epoch 23.154), train_loss = 0.89536747, grad/param norm = 1.5996e-01, time/batch = 0.7052s	
13199/28500 (epoch 23.156), train_loss = 1.10014345, grad/param norm = 1.6953e-01, time/batch = 0.6988s	
13200/28500 (epoch 23.158), train_loss = 1.02230468, grad/param norm = 1.5951e-01, time/batch = 0.7142s	
13201/28500 (epoch 23.160), train_loss = 0.87994916, grad/param norm = 1.3689e-01, time/batch = 0.7019s	
13202/28500 (epoch 23.161), train_loss = 0.94685732, grad/param norm = 1.6488e-01, time/batch = 0.6982s	
13203/28500 (epoch 23.163), train_loss = 0.86433990, grad/param norm = 1.6871e-01, time/batch = 0.6975s	
13204/28500 (epoch 23.165), train_loss = 1.18979184, grad/param norm = 1.6772e-01, time/batch = 0.6967s	
13205/28500 (epoch 23.167), train_loss = 1.18590409, grad/param norm = 1.9634e-01, time/batch = 0.6974s	
13206/28500 (epoch 23.168), train_loss = 1.11265138, grad/param norm = 1.8117e-01, time/batch = 0.7030s	
13207/28500 (epoch 23.170), train_loss = 1.08551690, grad/param norm = 1.8090e-01, time/batch = 0.6975s	
13208/28500 (epoch 23.172), train_loss = 0.99397564, grad/param norm = 1.5461e-01, time/batch = 0.7098s	
13209/28500 (epoch 23.174), train_loss = 1.16042396, grad/param norm = 1.9137e-01, time/batch = 0.7079s	
13210/28500 (epoch 23.175), train_loss = 0.98357294, grad/param norm = 1.5796e-01, time/batch = 0.6959s	
13211/28500 (epoch 23.177), train_loss = 1.04231128, grad/param norm = 1.6899e-01, time/batch = 0.7010s	
13212/28500 (epoch 23.179), train_loss = 1.02432299, grad/param norm = 1.8258e-01, time/batch = 0.6996s	
13213/28500 (epoch 23.181), train_loss = 1.05207238, grad/param norm = 1.6354e-01, time/batch = 0.7031s	
13214/28500 (epoch 23.182), train_loss = 0.97307671, grad/param norm = 1.5734e-01, time/batch = 0.7002s	
13215/28500 (epoch 23.184), train_loss = 1.15346104, grad/param norm = 2.0595e-01, time/batch = 0.7023s	
13216/28500 (epoch 23.186), train_loss = 1.12310852, grad/param norm = 1.7750e-01, time/batch = 0.7193s	
13217/28500 (epoch 23.188), train_loss = 1.02714248, grad/param norm = 1.7233e-01, time/batch = 0.6973s	
13218/28500 (epoch 23.189), train_loss = 1.01238200, grad/param norm = 1.6540e-01, time/batch = 0.6963s	
13219/28500 (epoch 23.191), train_loss = 1.23075972, grad/param norm = 1.8659e-01, time/batch = 0.7007s	
13220/28500 (epoch 23.193), train_loss = 1.05286374, grad/param norm = 1.9255e-01, time/batch = 0.7013s	
13221/28500 (epoch 23.195), train_loss = 1.15642924, grad/param norm = 1.8784e-01, time/batch = 0.7098s	
13222/28500 (epoch 23.196), train_loss = 1.06817625, grad/param norm = 1.9135e-01, time/batch = 0.7053s	
13223/28500 (epoch 23.198), train_loss = 1.04448219, grad/param norm = 1.8382e-01, time/batch = 0.7347s	
13224/28500 (epoch 23.200), train_loss = 1.06409853, grad/param norm = 1.6883e-01, time/batch = 0.7100s	
13225/28500 (epoch 23.202), train_loss = 1.02982548, grad/param norm = 1.6073e-01, time/batch = 0.6982s	
13226/28500 (epoch 23.204), train_loss = 0.95667030, grad/param norm = 1.4645e-01, time/batch = 0.6908s	
13227/28500 (epoch 23.205), train_loss = 0.97250507, grad/param norm = 1.7386e-01, time/batch = 0.6893s	
13228/28500 (epoch 23.207), train_loss = 0.92548315, grad/param norm = 1.6287e-01, time/batch = 0.6898s	
13229/28500 (epoch 23.209), train_loss = 1.01764094, grad/param norm = 1.5012e-01, time/batch = 0.6911s	
13230/28500 (epoch 23.211), train_loss = 0.86640844, grad/param norm = 1.6747e-01, time/batch = 0.6904s	
13231/28500 (epoch 23.212), train_loss = 0.85462425, grad/param norm = 1.4878e-01, time/batch = 0.7130s	
13232/28500 (epoch 23.214), train_loss = 0.98938545, grad/param norm = 1.8442e-01, time/batch = 0.6892s	
13233/28500 (epoch 23.216), train_loss = 0.91783399, grad/param norm = 1.5154e-01, time/batch = 0.6930s	
13234/28500 (epoch 23.218), train_loss = 1.11618126, grad/param norm = 1.5757e-01, time/batch = 0.6888s	
13235/28500 (epoch 23.219), train_loss = 1.02624312, grad/param norm = 1.6741e-01, time/batch = 0.6904s	
13236/28500 (epoch 23.221), train_loss = 0.87932444, grad/param norm = 1.7674e-01, time/batch = 0.6932s	
13237/28500 (epoch 23.223), train_loss = 1.10448631, grad/param norm = 1.6722e-01, time/batch = 0.7063s	
13238/28500 (epoch 23.225), train_loss = 1.12563333, grad/param norm = 1.7271e-01, time/batch = 0.7069s	
13239/28500 (epoch 23.226), train_loss = 0.95605138, grad/param norm = 1.4713e-01, time/batch = 0.6982s	
13240/28500 (epoch 23.228), train_loss = 1.10263682, grad/param norm = 1.5439e-01, time/batch = 0.6882s	
13241/28500 (epoch 23.230), train_loss = 1.07776026, grad/param norm = 1.6568e-01, time/batch = 0.6924s	
13242/28500 (epoch 23.232), train_loss = 1.03824875, grad/param norm = 1.5620e-01, time/batch = 0.6913s	
13243/28500 (epoch 23.233), train_loss = 1.04232084, grad/param norm = 1.8121e-01, time/batch = 0.6929s	
13244/28500 (epoch 23.235), train_loss = 0.96988306, grad/param norm = 1.5246e-01, time/batch = 0.6894s	
13245/28500 (epoch 23.237), train_loss = 0.89533960, grad/param norm = 1.5309e-01, time/batch = 0.6912s	
13246/28500 (epoch 23.239), train_loss = 0.95471975, grad/param norm = 1.4753e-01, time/batch = 0.7070s	
13247/28500 (epoch 23.240), train_loss = 0.88538017, grad/param norm = 1.4661e-01, time/batch = 0.7049s	
13248/28500 (epoch 23.242), train_loss = 1.01609381, grad/param norm = 1.7407e-01, time/batch = 0.6933s	
13249/28500 (epoch 23.244), train_loss = 1.04134173, grad/param norm = 1.4623e-01, time/batch = 0.6947s	
13250/28500 (epoch 23.246), train_loss = 1.08745565, grad/param norm = 1.7897e-01, time/batch = 0.6921s	
13251/28500 (epoch 23.247), train_loss = 1.15951471, grad/param norm = 1.7378e-01, time/batch = 0.6990s	
13252/28500 (epoch 23.249), train_loss = 1.01028369, grad/param norm = 1.6578e-01, time/batch = 0.6993s	
13253/28500 (epoch 23.251), train_loss = 0.95704029, grad/param norm = 1.4929e-01, time/batch = 0.6931s	
13254/28500 (epoch 23.253), train_loss = 1.12845032, grad/param norm = 1.7311e-01, time/batch = 0.7015s	
13255/28500 (epoch 23.254), train_loss = 1.14298854, grad/param norm = 1.6449e-01, time/batch = 0.6976s	
13256/28500 (epoch 23.256), train_loss = 0.93902987, grad/param norm = 1.5020e-01, time/batch = 0.6941s	
13257/28500 (epoch 23.258), train_loss = 0.98243225, grad/param norm = 1.7392e-01, time/batch = 0.6906s	
13258/28500 (epoch 23.260), train_loss = 0.95103053, grad/param norm = 1.5036e-01, time/batch = 0.6883s	
13259/28500 (epoch 23.261), train_loss = 0.91851963, grad/param norm = 1.4845e-01, time/batch = 0.6926s	
13260/28500 (epoch 23.263), train_loss = 1.10259016, grad/param norm = 1.8259e-01, time/batch = 0.6881s	
13261/28500 (epoch 23.265), train_loss = 1.01176456, grad/param norm = 1.7060e-01, time/batch = 0.6919s	
13262/28500 (epoch 23.267), train_loss = 1.15044062, grad/param norm = 1.8012e-01, time/batch = 0.6886s	
13263/28500 (epoch 23.268), train_loss = 1.04785091, grad/param norm = 1.5705e-01, time/batch = 0.6918s	
13264/28500 (epoch 23.270), train_loss = 1.04958975, grad/param norm = 1.8877e-01, time/batch = 0.6958s	
13265/28500 (epoch 23.272), train_loss = 0.98938942, grad/param norm = 1.6196e-01, time/batch = 0.7097s	
13266/28500 (epoch 23.274), train_loss = 1.10947501, grad/param norm = 1.6629e-01, time/batch = 0.7187s	
13267/28500 (epoch 23.275), train_loss = 1.04059366, grad/param norm = 1.6080e-01, time/batch = 0.7051s	
13268/28500 (epoch 23.277), train_loss = 1.01170391, grad/param norm = 1.6834e-01, time/batch = 0.6898s	
13269/28500 (epoch 23.279), train_loss = 1.04574729, grad/param norm = 1.8475e-01, time/batch = 0.6929s	
13270/28500 (epoch 23.281), train_loss = 1.09549501, grad/param norm = 1.9337e-01, time/batch = 0.6899s	
13271/28500 (epoch 23.282), train_loss = 0.95255903, grad/param norm = 1.4793e-01, time/batch = 0.6972s	
13272/28500 (epoch 23.284), train_loss = 1.01727628, grad/param norm = 1.7747e-01, time/batch = 0.6928s	
13273/28500 (epoch 23.286), train_loss = 1.14294423, grad/param norm = 1.8035e-01, time/batch = 0.6989s	
13274/28500 (epoch 23.288), train_loss = 1.04616046, grad/param norm = 1.8264e-01, time/batch = 0.6972s	
13275/28500 (epoch 23.289), train_loss = 1.06155613, grad/param norm = 1.9492e-01, time/batch = 0.6938s	
13276/28500 (epoch 23.291), train_loss = 1.04259630, grad/param norm = 1.6024e-01, time/batch = 0.6967s	
13277/28500 (epoch 23.293), train_loss = 1.00485855, grad/param norm = 1.5827e-01, time/batch = 0.6947s	
13278/28500 (epoch 23.295), train_loss = 0.89914855, grad/param norm = 1.6491e-01, time/batch = 0.6948s	
13279/28500 (epoch 23.296), train_loss = 0.88970620, grad/param norm = 1.6041e-01, time/batch = 0.6969s	
13280/28500 (epoch 23.298), train_loss = 1.08069693, grad/param norm = 1.5987e-01, time/batch = 0.6951s	
13281/28500 (epoch 23.300), train_loss = 0.93751831, grad/param norm = 1.7179e-01, time/batch = 0.6988s	
13282/28500 (epoch 23.302), train_loss = 0.89010689, grad/param norm = 1.6125e-01, time/batch = 0.6954s	
13283/28500 (epoch 23.304), train_loss = 0.97150312, grad/param norm = 1.6154e-01, time/batch = 0.6960s	
13284/28500 (epoch 23.305), train_loss = 1.04721452, grad/param norm = 1.6482e-01, time/batch = 0.6949s	
13285/28500 (epoch 23.307), train_loss = 0.99222833, grad/param norm = 1.6759e-01, time/batch = 0.7008s	
13286/28500 (epoch 23.309), train_loss = 1.01014508, grad/param norm = 1.6733e-01, time/batch = 0.6975s	
13287/28500 (epoch 23.311), train_loss = 1.05667744, grad/param norm = 1.5604e-01, time/batch = 0.6945s	
13288/28500 (epoch 23.312), train_loss = 1.03150450, grad/param norm = 1.6895e-01, time/batch = 0.6951s	
13289/28500 (epoch 23.314), train_loss = 1.09774954, grad/param norm = 2.1195e-01, time/batch = 0.6967s	
13290/28500 (epoch 23.316), train_loss = 1.01804081, grad/param norm = 1.6593e-01, time/batch = 0.6936s	
13291/28500 (epoch 23.318), train_loss = 1.08954363, grad/param norm = 1.6722e-01, time/batch = 0.6963s	
13292/28500 (epoch 23.319), train_loss = 0.97147177, grad/param norm = 1.7796e-01, time/batch = 0.6945s	
13293/28500 (epoch 23.321), train_loss = 0.94749707, grad/param norm = 1.6185e-01, time/batch = 0.6944s	
13294/28500 (epoch 23.323), train_loss = 0.96561224, grad/param norm = 1.8303e-01, time/batch = 0.6952s	
13295/28500 (epoch 23.325), train_loss = 1.15288340, grad/param norm = 1.7733e-01, time/batch = 0.6958s	
13296/28500 (epoch 23.326), train_loss = 1.03216086, grad/param norm = 1.6774e-01, time/batch = 0.6953s	
13297/28500 (epoch 23.328), train_loss = 0.82212121, grad/param norm = 1.4865e-01, time/batch = 0.6938s	
13298/28500 (epoch 23.330), train_loss = 0.93592210, grad/param norm = 1.7744e-01, time/batch = 0.6934s	
13299/28500 (epoch 23.332), train_loss = 1.00808618, grad/param norm = 1.5471e-01, time/batch = 0.6939s	
13300/28500 (epoch 23.333), train_loss = 0.83782138, grad/param norm = 1.5973e-01, time/batch = 0.6936s	
13301/28500 (epoch 23.335), train_loss = 0.88860840, grad/param norm = 1.4640e-01, time/batch = 0.6966s	
13302/28500 (epoch 23.337), train_loss = 0.88256127, grad/param norm = 1.5307e-01, time/batch = 0.6948s	
13303/28500 (epoch 23.339), train_loss = 0.84013336, grad/param norm = 1.3592e-01, time/batch = 0.6944s	
13304/28500 (epoch 23.340), train_loss = 1.00925221, grad/param norm = 1.8613e-01, time/batch = 0.6938s	
13305/28500 (epoch 23.342), train_loss = 0.98555175, grad/param norm = 1.5966e-01, time/batch = 0.6934s	
13306/28500 (epoch 23.344), train_loss = 0.93418535, grad/param norm = 1.7033e-01, time/batch = 0.6949s	
13307/28500 (epoch 23.346), train_loss = 0.81798938, grad/param norm = 1.3673e-01, time/batch = 0.6976s	
13308/28500 (epoch 23.347), train_loss = 0.98922242, grad/param norm = 1.6278e-01, time/batch = 0.7087s	
13309/28500 (epoch 23.349), train_loss = 0.97287335, grad/param norm = 1.5620e-01, time/batch = 0.6943s	
13310/28500 (epoch 23.351), train_loss = 0.91044970, grad/param norm = 1.4860e-01, time/batch = 0.6938s	
13311/28500 (epoch 23.353), train_loss = 1.01037964, grad/param norm = 1.6759e-01, time/batch = 0.6961s	
13312/28500 (epoch 23.354), train_loss = 0.89565691, grad/param norm = 1.4731e-01, time/batch = 0.6960s	
13313/28500 (epoch 23.356), train_loss = 0.91231047, grad/param norm = 1.4593e-01, time/batch = 0.6967s	
13314/28500 (epoch 23.358), train_loss = 1.01899703, grad/param norm = 1.5894e-01, time/batch = 0.6957s	
13315/28500 (epoch 23.360), train_loss = 1.03433125, grad/param norm = 1.7768e-01, time/batch = 0.6904s	
13316/28500 (epoch 23.361), train_loss = 0.91736133, grad/param norm = 1.4676e-01, time/batch = 0.6916s	
13317/28500 (epoch 23.363), train_loss = 0.89331198, grad/param norm = 1.4689e-01, time/batch = 0.6916s	
13318/28500 (epoch 23.365), train_loss = 0.95113447, grad/param norm = 1.6373e-01, time/batch = 0.6969s	
13319/28500 (epoch 23.367), train_loss = 0.98586406, grad/param norm = 1.6151e-01, time/batch = 0.6951s	
13320/28500 (epoch 23.368), train_loss = 0.94014295, grad/param norm = 1.4499e-01, time/batch = 0.7079s	
13321/28500 (epoch 23.370), train_loss = 0.97597751, grad/param norm = 1.5349e-01, time/batch = 0.6933s	
13322/28500 (epoch 23.372), train_loss = 0.82011041, grad/param norm = 1.5328e-01, time/batch = 0.6957s	
13323/28500 (epoch 23.374), train_loss = 0.95017266, grad/param norm = 1.6629e-01, time/batch = 0.6947s	
13324/28500 (epoch 23.375), train_loss = 1.10124130, grad/param norm = 1.6585e-01, time/batch = 0.6903s	
13325/28500 (epoch 23.377), train_loss = 0.84819423, grad/param norm = 1.5933e-01, time/batch = 0.6916s	
13326/28500 (epoch 23.379), train_loss = 0.76799155, grad/param norm = 1.5620e-01, time/batch = 0.6910s	
13327/28500 (epoch 23.381), train_loss = 0.95584060, grad/param norm = 1.6373e-01, time/batch = 0.6907s	
13328/28500 (epoch 23.382), train_loss = 0.92010019, grad/param norm = 1.6625e-01, time/batch = 0.6902s	
13329/28500 (epoch 23.384), train_loss = 0.84589195, grad/param norm = 1.5533e-01, time/batch = 0.6898s	
13330/28500 (epoch 23.386), train_loss = 0.85830438, grad/param norm = 1.5243e-01, time/batch = 0.6897s	
13331/28500 (epoch 23.388), train_loss = 1.06666000, grad/param norm = 1.6961e-01, time/batch = 0.6948s	
13332/28500 (epoch 23.389), train_loss = 0.91224453, grad/param norm = 1.7276e-01, time/batch = 0.6921s	
13333/28500 (epoch 23.391), train_loss = 0.88143565, grad/param norm = 1.5309e-01, time/batch = 0.6906s	
13334/28500 (epoch 23.393), train_loss = 0.88506081, grad/param norm = 1.6135e-01, time/batch = 0.6897s	
13335/28500 (epoch 23.395), train_loss = 1.12975390, grad/param norm = 1.6820e-01, time/batch = 0.6937s	
13336/28500 (epoch 23.396), train_loss = 1.05926407, grad/param norm = 1.8115e-01, time/batch = 0.7088s	
13337/28500 (epoch 23.398), train_loss = 0.76423647, grad/param norm = 1.6606e-01, time/batch = 0.6939s	
13338/28500 (epoch 23.400), train_loss = 0.96597768, grad/param norm = 1.8048e-01, time/batch = 0.6936s	
13339/28500 (epoch 23.402), train_loss = 0.99879797, grad/param norm = 1.7070e-01, time/batch = 0.6927s	
13340/28500 (epoch 23.404), train_loss = 1.05677242, grad/param norm = 1.8457e-01, time/batch = 0.6896s	
13341/28500 (epoch 23.405), train_loss = 1.03637809, grad/param norm = 1.5200e-01, time/batch = 0.6911s	
13342/28500 (epoch 23.407), train_loss = 1.01936535, grad/param norm = 1.7217e-01, time/batch = 0.6952s	
13343/28500 (epoch 23.409), train_loss = 1.01527635, grad/param norm = 1.6742e-01, time/batch = 0.6908s	
13344/28500 (epoch 23.411), train_loss = 1.06904872, grad/param norm = 1.5851e-01, time/batch = 0.6917s	
13345/28500 (epoch 23.412), train_loss = 1.08710840, grad/param norm = 1.7503e-01, time/batch = 0.6894s	
13346/28500 (epoch 23.414), train_loss = 1.00560522, grad/param norm = 1.7277e-01, time/batch = 0.6898s	
13347/28500 (epoch 23.416), train_loss = 0.90864207, grad/param norm = 1.6268e-01, time/batch = 0.6981s	
13348/28500 (epoch 23.418), train_loss = 1.00547541, grad/param norm = 1.5254e-01, time/batch = 0.6931s	
13349/28500 (epoch 23.419), train_loss = 1.11278715, grad/param norm = 1.8706e-01, time/batch = 0.6893s	
13350/28500 (epoch 23.421), train_loss = 1.07170866, grad/param norm = 1.6679e-01, time/batch = 0.6915s	
13351/28500 (epoch 23.423), train_loss = 1.09317123, grad/param norm = 2.0339e-01, time/batch = 0.6931s	
13352/28500 (epoch 23.425), train_loss = 1.03600418, grad/param norm = 1.9179e-01, time/batch = 0.6908s	
13353/28500 (epoch 23.426), train_loss = 0.99430190, grad/param norm = 2.1621e-01, time/batch = 0.6948s	
13354/28500 (epoch 23.428), train_loss = 1.17409855, grad/param norm = 2.0427e-01, time/batch = 0.6937s	
13355/28500 (epoch 23.430), train_loss = 1.11300614, grad/param norm = 1.5817e-01, time/batch = 0.6911s	
13356/28500 (epoch 23.432), train_loss = 1.03084826, grad/param norm = 1.9515e-01, time/batch = 0.6912s	
13357/28500 (epoch 23.433), train_loss = 1.05860602, grad/param norm = 1.8834e-01, time/batch = 0.6945s	
13358/28500 (epoch 23.435), train_loss = 1.02337149, grad/param norm = 1.7821e-01, time/batch = 0.6907s	
13359/28500 (epoch 23.437), train_loss = 0.94135289, grad/param norm = 1.6214e-01, time/batch = 0.6933s	
13360/28500 (epoch 23.439), train_loss = 0.95900935, grad/param norm = 1.4360e-01, time/batch = 0.6901s	
13361/28500 (epoch 23.440), train_loss = 1.20556711, grad/param norm = 1.8567e-01, time/batch = 0.6906s	
13362/28500 (epoch 23.442), train_loss = 0.93591852, grad/param norm = 1.6580e-01, time/batch = 0.6900s	
13363/28500 (epoch 23.444), train_loss = 0.86239711, grad/param norm = 1.5054e-01, time/batch = 0.6890s	
13364/28500 (epoch 23.446), train_loss = 0.84536877, grad/param norm = 1.6619e-01, time/batch = 0.6904s	
13365/28500 (epoch 23.447), train_loss = 0.85138591, grad/param norm = 1.4222e-01, time/batch = 0.6897s	
13366/28500 (epoch 23.449), train_loss = 0.92807788, grad/param norm = 1.4628e-01, time/batch = 0.7125s	
13367/28500 (epoch 23.451), train_loss = 0.98081023, grad/param norm = 1.6313e-01, time/batch = 0.6910s	
13368/28500 (epoch 23.453), train_loss = 0.95521361, grad/param norm = 1.5896e-01, time/batch = 0.6918s	
13369/28500 (epoch 23.454), train_loss = 0.94248501, grad/param norm = 1.6029e-01, time/batch = 0.6926s	
13370/28500 (epoch 23.456), train_loss = 1.05728394, grad/param norm = 1.8604e-01, time/batch = 0.6890s	
13371/28500 (epoch 23.458), train_loss = 0.94527582, grad/param norm = 1.5088e-01, time/batch = 0.6936s	
13372/28500 (epoch 23.460), train_loss = 1.05125537, grad/param norm = 1.7347e-01, time/batch = 0.6955s	
13373/28500 (epoch 23.461), train_loss = 0.93236118, grad/param norm = 1.7234e-01, time/batch = 0.6891s	
13374/28500 (epoch 23.463), train_loss = 0.84683431, grad/param norm = 1.4597e-01, time/batch = 0.6903s	
13375/28500 (epoch 23.465), train_loss = 0.84250324, grad/param norm = 1.6726e-01, time/batch = 0.6893s	
13376/28500 (epoch 23.467), train_loss = 0.97676455, grad/param norm = 1.5707e-01, time/batch = 0.6898s	
13377/28500 (epoch 23.468), train_loss = 0.89799626, grad/param norm = 1.5369e-01, time/batch = 0.6892s	
13378/28500 (epoch 23.470), train_loss = 0.91594148, grad/param norm = 1.5674e-01, time/batch = 0.6905s	
13379/28500 (epoch 23.472), train_loss = 0.93194520, grad/param norm = 1.6273e-01, time/batch = 0.6940s	
13380/28500 (epoch 23.474), train_loss = 1.12274644, grad/param norm = 1.8397e-01, time/batch = 0.6889s	
13381/28500 (epoch 23.475), train_loss = 0.88196945, grad/param norm = 1.5066e-01, time/batch = 0.6938s	
13382/28500 (epoch 23.477), train_loss = 0.94238796, grad/param norm = 1.6709e-01, time/batch = 0.7107s	
13383/28500 (epoch 23.479), train_loss = 1.03525195, grad/param norm = 1.6257e-01, time/batch = 0.6938s	
13384/28500 (epoch 23.481), train_loss = 1.00216424, grad/param norm = 1.6913e-01, time/batch = 0.6960s	
13385/28500 (epoch 23.482), train_loss = 0.88739198, grad/param norm = 1.5242e-01, time/batch = 0.6951s	
13386/28500 (epoch 23.484), train_loss = 0.89632629, grad/param norm = 1.7230e-01, time/batch = 0.6898s	
13387/28500 (epoch 23.486), train_loss = 0.82732230, grad/param norm = 1.9841e-01, time/batch = 0.6918s	
13388/28500 (epoch 23.488), train_loss = 1.00702305, grad/param norm = 1.5214e-01, time/batch = 0.6923s	
13389/28500 (epoch 23.489), train_loss = 1.08114089, grad/param norm = 1.5785e-01, time/batch = 0.6943s	
13390/28500 (epoch 23.491), train_loss = 0.94435894, grad/param norm = 1.5757e-01, time/batch = 0.6903s	
13391/28500 (epoch 23.493), train_loss = 0.96955700, grad/param norm = 1.5409e-01, time/batch = 0.6930s	
13392/28500 (epoch 23.495), train_loss = 0.96719506, grad/param norm = 1.5104e-01, time/batch = 0.6912s	
13393/28500 (epoch 23.496), train_loss = 0.89798046, grad/param norm = 1.8210e-01, time/batch = 0.6932s	
13394/28500 (epoch 23.498), train_loss = 0.97881398, grad/param norm = 1.5449e-01, time/batch = 0.6984s	
13395/28500 (epoch 23.500), train_loss = 0.92044770, grad/param norm = 1.4952e-01, time/batch = 0.6982s	
13396/28500 (epoch 23.502), train_loss = 1.06438190, grad/param norm = 1.5682e-01, time/batch = 0.6904s	
13397/28500 (epoch 23.504), train_loss = 0.98445624, grad/param norm = 1.4823e-01, time/batch = 0.6897s	
13398/28500 (epoch 23.505), train_loss = 0.90869054, grad/param norm = 1.5348e-01, time/batch = 0.6914s	
13399/28500 (epoch 23.507), train_loss = 1.10583102, grad/param norm = 4.8999e-01, time/batch = 0.6912s	
13400/28500 (epoch 23.509), train_loss = 0.98411305, grad/param norm = 1.8052e-01, time/batch = 0.6948s	
13401/28500 (epoch 23.511), train_loss = 0.98592236, grad/param norm = 1.8130e-01, time/batch = 0.6970s	
13402/28500 (epoch 23.512), train_loss = 1.01893577, grad/param norm = 1.6295e-01, time/batch = 0.6890s	
13403/28500 (epoch 23.514), train_loss = 0.95612240, grad/param norm = 1.6488e-01, time/batch = 0.6908s	
13404/28500 (epoch 23.516), train_loss = 0.94313019, grad/param norm = 1.4526e-01, time/batch = 0.6898s	
13405/28500 (epoch 23.518), train_loss = 1.02282141, grad/param norm = 1.6751e-01, time/batch = 0.6902s	
13406/28500 (epoch 23.519), train_loss = 1.04862086, grad/param norm = 1.5430e-01, time/batch = 0.6936s	
13407/28500 (epoch 23.521), train_loss = 1.11110397, grad/param norm = 1.7027e-01, time/batch = 0.7078s	
13408/28500 (epoch 23.523), train_loss = 1.05655326, grad/param norm = 1.8501e-01, time/batch = 0.7158s	
13409/28500 (epoch 23.525), train_loss = 1.08768931, grad/param norm = 1.8892e-01, time/batch = 0.6964s	
13410/28500 (epoch 23.526), train_loss = 1.05447408, grad/param norm = 1.6693e-01, time/batch = 0.6964s	
13411/28500 (epoch 23.528), train_loss = 1.07280681, grad/param norm = 1.9915e-01, time/batch = 0.7038s	
13412/28500 (epoch 23.530), train_loss = 1.07869473, grad/param norm = 1.5798e-01, time/batch = 0.6991s	
13413/28500 (epoch 23.532), train_loss = 0.95648558, grad/param norm = 1.5440e-01, time/batch = 0.6935s	
13414/28500 (epoch 23.533), train_loss = 1.06919741, grad/param norm = 1.6944e-01, time/batch = 0.6918s	
13415/28500 (epoch 23.535), train_loss = 0.84809974, grad/param norm = 1.4304e-01, time/batch = 0.6967s	
13416/28500 (epoch 23.537), train_loss = 0.85951457, grad/param norm = 1.6377e-01, time/batch = 0.6935s	
13417/28500 (epoch 23.539), train_loss = 0.83623327, grad/param norm = 1.8044e-01, time/batch = 0.6894s	
13418/28500 (epoch 23.540), train_loss = 1.00440875, grad/param norm = 1.6436e-01, time/batch = 0.6893s	
13419/28500 (epoch 23.542), train_loss = 1.04477676, grad/param norm = 2.1713e-01, time/batch = 0.6908s	
13420/28500 (epoch 23.544), train_loss = 1.12660971, grad/param norm = 1.7308e-01, time/batch = 0.6890s	
13421/28500 (epoch 23.546), train_loss = 0.95627776, grad/param norm = 1.6348e-01, time/batch = 0.6940s	
13422/28500 (epoch 23.547), train_loss = 0.99149003, grad/param norm = 1.5383e-01, time/batch = 0.6933s	
13423/28500 (epoch 23.549), train_loss = 0.82315134, grad/param norm = 1.2636e-01, time/batch = 0.6891s	
13424/28500 (epoch 23.551), train_loss = 0.96685027, grad/param norm = 1.9103e-01, time/batch = 0.6933s	
13425/28500 (epoch 23.553), train_loss = 1.16744889, grad/param norm = 1.9097e-01, time/batch = 0.6933s	
13426/28500 (epoch 23.554), train_loss = 1.01705990, grad/param norm = 1.8256e-01, time/batch = 0.6898s	
13427/28500 (epoch 23.556), train_loss = 1.01311517, grad/param norm = 1.6623e-01, time/batch = 0.6909s	
13428/28500 (epoch 23.558), train_loss = 1.02972547, grad/param norm = 1.6314e-01, time/batch = 0.6891s	
13429/28500 (epoch 23.560), train_loss = 1.03390057, grad/param norm = 1.7173e-01, time/batch = 0.6910s	
13430/28500 (epoch 23.561), train_loss = 1.07812791, grad/param norm = 1.7365e-01, time/batch = 0.6889s	
13431/28500 (epoch 23.563), train_loss = 1.12563890, grad/param norm = 1.8315e-01, time/batch = 0.6928s	
13432/28500 (epoch 23.565), train_loss = 0.94480081, grad/param norm = 1.5036e-01, time/batch = 0.6895s	
13433/28500 (epoch 23.567), train_loss = 0.86242774, grad/param norm = 1.4366e-01, time/batch = 0.6904s	
13434/28500 (epoch 23.568), train_loss = 1.03587665, grad/param norm = 1.9639e-01, time/batch = 0.6932s	
13435/28500 (epoch 23.570), train_loss = 0.96755011, grad/param norm = 1.6078e-01, time/batch = 0.6924s	
13436/28500 (epoch 23.572), train_loss = 0.96255674, grad/param norm = 1.6869e-01, time/batch = 0.6922s	
13437/28500 (epoch 23.574), train_loss = 0.95330752, grad/param norm = 1.6251e-01, time/batch = 0.6947s	
13438/28500 (epoch 23.575), train_loss = 0.97129489, grad/param norm = 1.5718e-01, time/batch = 0.6987s	
13439/28500 (epoch 23.577), train_loss = 1.01347578, grad/param norm = 1.6580e-01, time/batch = 0.6983s	
13440/28500 (epoch 23.579), train_loss = 1.07045124, grad/param norm = 1.6375e-01, time/batch = 0.6977s	
13441/28500 (epoch 23.581), train_loss = 0.92065316, grad/param norm = 1.7877e-01, time/batch = 0.7096s	
13442/28500 (epoch 23.582), train_loss = 1.05894611, grad/param norm = 1.5105e-01, time/batch = 0.7164s	
13443/28500 (epoch 23.584), train_loss = 0.95126172, grad/param norm = 1.8273e-01, time/batch = 0.7026s	
13444/28500 (epoch 23.586), train_loss = 0.90333115, grad/param norm = 1.3470e-01, time/batch = 0.7059s	
13445/28500 (epoch 23.588), train_loss = 0.90551352, grad/param norm = 1.5318e-01, time/batch = 0.6943s	
13446/28500 (epoch 23.589), train_loss = 0.99774010, grad/param norm = 1.6942e-01, time/batch = 0.6950s	
13447/28500 (epoch 23.591), train_loss = 0.98783307, grad/param norm = 1.5734e-01, time/batch = 0.6929s	
13448/28500 (epoch 23.593), train_loss = 0.92637839, grad/param norm = 1.5911e-01, time/batch = 0.7110s	
13449/28500 (epoch 23.595), train_loss = 1.18124387, grad/param norm = 1.9404e-01, time/batch = 0.7068s	
13450/28500 (epoch 23.596), train_loss = 1.15076633, grad/param norm = 1.7214e-01, time/batch = 0.6985s	
13451/28500 (epoch 23.598), train_loss = 1.00151101, grad/param norm = 1.6243e-01, time/batch = 0.6976s	
13452/28500 (epoch 23.600), train_loss = 1.01003958, grad/param norm = 1.8541e-01, time/batch = 0.6904s	
13453/28500 (epoch 23.602), train_loss = 1.06776054, grad/param norm = 1.7406e-01, time/batch = 0.6939s	
13454/28500 (epoch 23.604), train_loss = 1.07220676, grad/param norm = 1.7233e-01, time/batch = 0.6953s	
13455/28500 (epoch 23.605), train_loss = 1.03346865, grad/param norm = 1.8138e-01, time/batch = 0.6912s	
13456/28500 (epoch 23.607), train_loss = 1.08878030, grad/param norm = 1.4668e-01, time/batch = 0.6898s	
13457/28500 (epoch 23.609), train_loss = 1.01683195, grad/param norm = 1.7790e-01, time/batch = 0.6903s	
13458/28500 (epoch 23.611), train_loss = 0.97281312, grad/param norm = 1.6881e-01, time/batch = 0.6899s	
13459/28500 (epoch 23.612), train_loss = 1.03679370, grad/param norm = 1.8987e-01, time/batch = 0.6933s	
13460/28500 (epoch 23.614), train_loss = 1.04058817, grad/param norm = 1.7225e-01, time/batch = 0.6931s	
13461/28500 (epoch 23.616), train_loss = 0.94497912, grad/param norm = 1.8150e-01, time/batch = 0.6925s	
13462/28500 (epoch 23.618), train_loss = 0.98064248, grad/param norm = 1.6114e-01, time/batch = 0.6907s	
13463/28500 (epoch 23.619), train_loss = 1.11836631, grad/param norm = 1.7979e-01, time/batch = 0.6923s	
13464/28500 (epoch 23.621), train_loss = 0.82501714, grad/param norm = 1.4338e-01, time/batch = 0.6906s	
13465/28500 (epoch 23.623), train_loss = 1.08132279, grad/param norm = 1.6332e-01, time/batch = 0.6939s	
13466/28500 (epoch 23.625), train_loss = 0.89538151, grad/param norm = 1.6492e-01, time/batch = 0.6911s	
13467/28500 (epoch 23.626), train_loss = 0.77269334, grad/param norm = 1.4053e-01, time/batch = 0.7008s	
13468/28500 (epoch 23.628), train_loss = 0.91494512, grad/param norm = 1.5080e-01, time/batch = 0.6933s	
13469/28500 (epoch 23.630), train_loss = 0.86187076, grad/param norm = 1.4632e-01, time/batch = 0.6960s	
13470/28500 (epoch 23.632), train_loss = 1.07984973, grad/param norm = 1.7445e-01, time/batch = 0.6959s	
13471/28500 (epoch 23.633), train_loss = 1.14659306, grad/param norm = 1.5551e-01, time/batch = 0.6945s	
13472/28500 (epoch 23.635), train_loss = 1.07271621, grad/param norm = 1.7803e-01, time/batch = 0.6963s	
13473/28500 (epoch 23.637), train_loss = 1.00846567, grad/param norm = 1.5665e-01, time/batch = 0.6918s	
13474/28500 (epoch 23.639), train_loss = 0.88004221, grad/param norm = 1.5301e-01, time/batch = 0.6915s	
13475/28500 (epoch 23.640), train_loss = 0.92728516, grad/param norm = 1.7162e-01, time/batch = 0.6908s	
13476/28500 (epoch 23.642), train_loss = 0.93178699, grad/param norm = 1.6404e-01, time/batch = 0.6943s	
13477/28500 (epoch 23.644), train_loss = 1.05870140, grad/param norm = 1.5494e-01, time/batch = 0.6893s	
13478/28500 (epoch 23.646), train_loss = 0.86092361, grad/param norm = 1.3694e-01, time/batch = 0.6942s	
13479/28500 (epoch 23.647), train_loss = 0.88318252, grad/param norm = 1.4507e-01, time/batch = 0.6924s	
13480/28500 (epoch 23.649), train_loss = 0.84663178, grad/param norm = 1.4763e-01, time/batch = 0.7001s	
13481/28500 (epoch 23.651), train_loss = 0.85242204, grad/param norm = 1.3328e-01, time/batch = 0.7014s	
13482/28500 (epoch 23.653), train_loss = 0.85112470, grad/param norm = 1.5266e-01, time/batch = 0.6941s	
13483/28500 (epoch 23.654), train_loss = 0.94060583, grad/param norm = 1.6458e-01, time/batch = 0.6956s	
13484/28500 (epoch 23.656), train_loss = 0.89861177, grad/param norm = 1.9074e-01, time/batch = 0.6943s	
13485/28500 (epoch 23.658), train_loss = 0.96035790, grad/param norm = 1.8313e-01, time/batch = 0.6966s	
13486/28500 (epoch 23.660), train_loss = 0.96812733, grad/param norm = 1.5817e-01, time/batch = 0.6924s	
13487/28500 (epoch 23.661), train_loss = 1.12083193, grad/param norm = 1.9280e-01, time/batch = 0.6978s	
13488/28500 (epoch 23.663), train_loss = 1.10057953, grad/param norm = 1.6737e-01, time/batch = 0.6942s	
13489/28500 (epoch 23.665), train_loss = 0.95931879, grad/param norm = 1.4694e-01, time/batch = 0.6932s	
13490/28500 (epoch 23.667), train_loss = 0.97407697, grad/param norm = 1.7688e-01, time/batch = 0.7020s	
13491/28500 (epoch 23.668), train_loss = 0.96277285, grad/param norm = 1.5426e-01, time/batch = 0.6938s	
13492/28500 (epoch 23.670), train_loss = 0.97989015, grad/param norm = 1.6370e-01, time/batch = 0.6976s	
13493/28500 (epoch 23.672), train_loss = 0.92359499, grad/param norm = 1.7068e-01, time/batch = 0.6933s	
13494/28500 (epoch 23.674), train_loss = 0.81528458, grad/param norm = 1.6685e-01, time/batch = 0.6969s	
13495/28500 (epoch 23.675), train_loss = 0.85240112, grad/param norm = 1.4728e-01, time/batch = 0.6936s	
13496/28500 (epoch 23.677), train_loss = 0.93441310, grad/param norm = 1.4909e-01, time/batch = 0.6967s	
13497/28500 (epoch 23.679), train_loss = 0.92392071, grad/param norm = 1.5610e-01, time/batch = 0.7112s	
13498/28500 (epoch 23.681), train_loss = 1.01707646, grad/param norm = 1.6488e-01, time/batch = 0.6994s	
13499/28500 (epoch 23.682), train_loss = 0.93854099, grad/param norm = 1.5309e-01, time/batch = 0.7012s	
13500/28500 (epoch 23.684), train_loss = 1.00074703, grad/param norm = 1.5724e-01, time/batch = 0.6955s	
13501/28500 (epoch 23.686), train_loss = 0.95512753, grad/param norm = 1.7606e-01, time/batch = 0.6952s	
13502/28500 (epoch 23.688), train_loss = 0.88356759, grad/param norm = 1.3394e-01, time/batch = 0.6926s	
13503/28500 (epoch 23.689), train_loss = 0.94932326, grad/param norm = 1.7303e-01, time/batch = 0.7132s	
13504/28500 (epoch 23.691), train_loss = 0.98628404, grad/param norm = 1.6102e-01, time/batch = 0.7068s	
13505/28500 (epoch 23.693), train_loss = 0.92620428, grad/param norm = 1.5988e-01, time/batch = 0.6904s	
13506/28500 (epoch 23.695), train_loss = 0.74430155, grad/param norm = 1.5819e-01, time/batch = 0.6941s	
13507/28500 (epoch 23.696), train_loss = 0.96031257, grad/param norm = 1.7101e-01, time/batch = 0.6914s	
13508/28500 (epoch 23.698), train_loss = 0.96054245, grad/param norm = 1.5254e-01, time/batch = 0.6916s	
13509/28500 (epoch 23.700), train_loss = 0.98124522, grad/param norm = 1.7003e-01, time/batch = 0.6949s	
13510/28500 (epoch 23.702), train_loss = 1.01205815, grad/param norm = 1.6472e-01, time/batch = 0.6968s	
13511/28500 (epoch 23.704), train_loss = 1.00062969, grad/param norm = 1.6907e-01, time/batch = 0.6937s	
13512/28500 (epoch 23.705), train_loss = 1.07142817, grad/param norm = 1.8721e-01, time/batch = 0.6936s	
13513/28500 (epoch 23.707), train_loss = 0.91400974, grad/param norm = 1.8392e-01, time/batch = 0.6896s	
13514/28500 (epoch 23.709), train_loss = 1.11063642, grad/param norm = 1.7464e-01, time/batch = 0.6948s	
13515/28500 (epoch 23.711), train_loss = 0.90083690, grad/param norm = 1.5905e-01, time/batch = 0.6933s	
13516/28500 (epoch 23.712), train_loss = 1.01536094, grad/param norm = 1.9402e-01, time/batch = 0.6945s	
13517/28500 (epoch 23.714), train_loss = 1.09552582, grad/param norm = 1.7277e-01, time/batch = 0.6903s	
13518/28500 (epoch 23.716), train_loss = 0.94288030, grad/param norm = 1.5214e-01, time/batch = 0.6900s	
13519/28500 (epoch 23.718), train_loss = 0.98673181, grad/param norm = 1.6616e-01, time/batch = 0.6889s	
13520/28500 (epoch 23.719), train_loss = 0.99600479, grad/param norm = 1.5893e-01, time/batch = 0.6951s	
13521/28500 (epoch 23.721), train_loss = 0.82440654, grad/param norm = 1.6934e-01, time/batch = 0.6953s	
13522/28500 (epoch 23.723), train_loss = 0.98009317, grad/param norm = 1.6727e-01, time/batch = 0.6945s	
13523/28500 (epoch 23.725), train_loss = 1.04750331, grad/param norm = 1.4945e-01, time/batch = 0.6889s	
13524/28500 (epoch 23.726), train_loss = 0.96535453, grad/param norm = 1.7503e-01, time/batch = 0.6978s	
13525/28500 (epoch 23.728), train_loss = 0.89830423, grad/param norm = 1.6174e-01, time/batch = 0.7037s	
13526/28500 (epoch 23.730), train_loss = 0.98479590, grad/param norm = 1.7693e-01, time/batch = 0.6972s	
13527/28500 (epoch 23.732), train_loss = 0.80022850, grad/param norm = 1.3805e-01, time/batch = 0.6909s	
13528/28500 (epoch 23.733), train_loss = 0.83145722, grad/param norm = 1.4475e-01, time/batch = 0.6937s	
13529/28500 (epoch 23.735), train_loss = 0.83441560, grad/param norm = 1.5750e-01, time/batch = 0.6889s	
13530/28500 (epoch 23.737), train_loss = 0.76038343, grad/param norm = 1.3599e-01, time/batch = 0.6897s	
13531/28500 (epoch 23.739), train_loss = 0.91569181, grad/param norm = 1.6981e-01, time/batch = 0.6922s	
13532/28500 (epoch 23.740), train_loss = 0.95941949, grad/param norm = 1.4414e-01, time/batch = 0.6921s	
13533/28500 (epoch 23.742), train_loss = 0.89825956, grad/param norm = 1.6724e-01, time/batch = 0.6899s	
13534/28500 (epoch 23.744), train_loss = 0.98501864, grad/param norm = 1.6703e-01, time/batch = 0.6901s	
13535/28500 (epoch 23.746), train_loss = 0.89246923, grad/param norm = 1.4978e-01, time/batch = 0.6902s	
13536/28500 (epoch 23.747), train_loss = 0.89004201, grad/param norm = 1.4815e-01, time/batch = 0.6894s	
13537/28500 (epoch 23.749), train_loss = 1.04621690, grad/param norm = 1.9747e-01, time/batch = 0.6892s	
13538/28500 (epoch 23.751), train_loss = 0.87068079, grad/param norm = 2.2247e-01, time/batch = 0.6888s	
13539/28500 (epoch 23.753), train_loss = 0.92637311, grad/param norm = 1.4636e-01, time/batch = 0.6907s	
13540/28500 (epoch 23.754), train_loss = 0.85332087, grad/param norm = 1.4546e-01, time/batch = 0.6910s	
13541/28500 (epoch 23.756), train_loss = 1.08731095, grad/param norm = 1.7535e-01, time/batch = 0.6940s	
13542/28500 (epoch 23.758), train_loss = 1.02237375, grad/param norm = 1.7900e-01, time/batch = 0.6895s	
13543/28500 (epoch 23.760), train_loss = 0.85625176, grad/param norm = 1.6205e-01, time/batch = 0.6904s	
13544/28500 (epoch 23.761), train_loss = 0.89516483, grad/param norm = 1.5514e-01, time/batch = 0.6888s	
13545/28500 (epoch 23.763), train_loss = 0.78500609, grad/param norm = 1.3875e-01, time/batch = 0.6905s	
13546/28500 (epoch 23.765), train_loss = 0.93225626, grad/param norm = 1.4913e-01, time/batch = 0.6913s	
13547/28500 (epoch 23.767), train_loss = 0.81475113, grad/param norm = 1.5098e-01, time/batch = 0.6914s	
13548/28500 (epoch 23.768), train_loss = 1.02861495, grad/param norm = 1.7178e-01, time/batch = 0.6889s	
13549/28500 (epoch 23.770), train_loss = 0.83828067, grad/param norm = 1.6096e-01, time/batch = 0.7035s	
13550/28500 (epoch 23.772), train_loss = 0.74498577, grad/param norm = 1.3613e-01, time/batch = 0.7003s	
13551/28500 (epoch 23.774), train_loss = 0.97031354, grad/param norm = 1.8936e-01, time/batch = 0.6978s	
13552/28500 (epoch 23.775), train_loss = 1.04611345, grad/param norm = 1.5404e-01, time/batch = 0.6942s	
13553/28500 (epoch 23.777), train_loss = 1.04574273, grad/param norm = 1.6205e-01, time/batch = 0.6963s	
13554/28500 (epoch 23.779), train_loss = 0.78816790, grad/param norm = 1.4310e-01, time/batch = 0.6892s	
13555/28500 (epoch 23.781), train_loss = 0.94806833, grad/param norm = 1.6987e-01, time/batch = 0.6938s	
13556/28500 (epoch 23.782), train_loss = 1.01357615, grad/param norm = 1.7376e-01, time/batch = 0.6925s	
13557/28500 (epoch 23.784), train_loss = 0.79820532, grad/param norm = 1.3459e-01, time/batch = 0.6934s	
13558/28500 (epoch 23.786), train_loss = 0.84167327, grad/param norm = 1.4737e-01, time/batch = 0.6887s	
13559/28500 (epoch 23.788), train_loss = 0.93677927, grad/param norm = 1.7760e-01, time/batch = 0.6902s	
13560/28500 (epoch 23.789), train_loss = 0.70777222, grad/param norm = 1.9767e-01, time/batch = 0.6912s	
13561/28500 (epoch 23.791), train_loss = 0.97600651, grad/param norm = 1.5890e-01, time/batch = 0.6951s	
13562/28500 (epoch 23.793), train_loss = 0.95363048, grad/param norm = 1.6282e-01, time/batch = 0.6897s	
13563/28500 (epoch 23.795), train_loss = 0.97451171, grad/param norm = 1.5776e-01, time/batch = 0.6910s	
13564/28500 (epoch 23.796), train_loss = 0.85142043, grad/param norm = 1.5178e-01, time/batch = 0.6930s	
13565/28500 (epoch 23.798), train_loss = 0.79284716, grad/param norm = 1.5522e-01, time/batch = 0.6971s	
13566/28500 (epoch 23.800), train_loss = 0.83310411, grad/param norm = 1.9626e-01, time/batch = 0.7168s	
13567/28500 (epoch 23.802), train_loss = 0.92804155, grad/param norm = 1.9094e-01, time/batch = 0.7037s	
13568/28500 (epoch 23.804), train_loss = 0.97705757, grad/param norm = 1.5318e-01, time/batch = 0.6941s	
13569/28500 (epoch 23.805), train_loss = 0.96602947, grad/param norm = 1.8172e-01, time/batch = 0.6953s	
13570/28500 (epoch 23.807), train_loss = 0.97993917, grad/param norm = 1.7431e-01, time/batch = 0.6968s	
13571/28500 (epoch 23.809), train_loss = 0.95483506, grad/param norm = 1.6572e-01, time/batch = 0.7106s	
13572/28500 (epoch 23.811), train_loss = 1.01573582, grad/param norm = 1.7986e-01, time/batch = 0.7280s	
13573/28500 (epoch 23.812), train_loss = 0.98379555, grad/param norm = 1.8555e-01, time/batch = 0.7106s	
13574/28500 (epoch 23.814), train_loss = 0.90915627, grad/param norm = 1.6896e-01, time/batch = 0.7109s	
13575/28500 (epoch 23.816), train_loss = 1.02630237, grad/param norm = 2.0306e-01, time/batch = 0.7158s	
13576/28500 (epoch 23.818), train_loss = 1.09289207, grad/param norm = 2.3658e-01, time/batch = 0.7246s	
13577/28500 (epoch 23.819), train_loss = 0.96467051, grad/param norm = 1.6161e-01, time/batch = 0.7231s	
13578/28500 (epoch 23.821), train_loss = 0.92565226, grad/param norm = 1.5030e-01, time/batch = 0.7273s	
13579/28500 (epoch 23.823), train_loss = 1.08719644, grad/param norm = 1.7888e-01, time/batch = 0.7169s	
13580/28500 (epoch 23.825), train_loss = 0.92110762, grad/param norm = 1.6480e-01, time/batch = 0.6961s	
13581/28500 (epoch 23.826), train_loss = 0.97197633, grad/param norm = 1.7228e-01, time/batch = 0.6964s	
13582/28500 (epoch 23.828), train_loss = 0.85323884, grad/param norm = 1.6390e-01, time/batch = 0.6961s	
13583/28500 (epoch 23.830), train_loss = 0.92732905, grad/param norm = 1.5687e-01, time/batch = 0.6965s	
13584/28500 (epoch 23.832), train_loss = 0.97419384, grad/param norm = 1.8392e-01, time/batch = 0.6926s	
13585/28500 (epoch 23.833), train_loss = 1.06597270, grad/param norm = 1.7217e-01, time/batch = 0.6987s	
13586/28500 (epoch 23.835), train_loss = 0.89002680, grad/param norm = 1.5598e-01, time/batch = 0.6927s	
13587/28500 (epoch 23.837), train_loss = 0.82522440, grad/param norm = 1.4545e-01, time/batch = 0.6945s	
13588/28500 (epoch 23.839), train_loss = 1.07807149, grad/param norm = 1.8714e-01, time/batch = 0.6921s	
13589/28500 (epoch 23.840), train_loss = 1.12192132, grad/param norm = 1.8581e-01, time/batch = 0.6951s	
13590/28500 (epoch 23.842), train_loss = 1.02504653, grad/param norm = 1.6656e-01, time/batch = 0.6920s	
13591/28500 (epoch 23.844), train_loss = 1.00507442, grad/param norm = 1.7921e-01, time/batch = 0.6959s	
13592/28500 (epoch 23.846), train_loss = 1.07895942, grad/param norm = 1.8055e-01, time/batch = 0.6936s	
13593/28500 (epoch 23.847), train_loss = 0.91754345, grad/param norm = 1.6707e-01, time/batch = 0.7108s	
13594/28500 (epoch 23.849), train_loss = 0.92328302, grad/param norm = 1.6157e-01, time/batch = 0.6928s	
13595/28500 (epoch 23.851), train_loss = 0.80982265, grad/param norm = 1.4246e-01, time/batch = 0.6949s	
13596/28500 (epoch 23.853), train_loss = 0.97141510, grad/param norm = 1.8630e-01, time/batch = 0.6923s	
13597/28500 (epoch 23.854), train_loss = 0.97510038, grad/param norm = 1.6855e-01, time/batch = 0.6953s	
13598/28500 (epoch 23.856), train_loss = 1.08536190, grad/param norm = 1.9947e-01, time/batch = 0.6913s	
13599/28500 (epoch 23.858), train_loss = 0.88891995, grad/param norm = 1.4588e-01, time/batch = 0.6942s	
13600/28500 (epoch 23.860), train_loss = 0.92165460, grad/param norm = 1.6415e-01, time/batch = 0.6916s	
13601/28500 (epoch 23.861), train_loss = 1.02354981, grad/param norm = 1.9882e-01, time/batch = 0.7049s	
13602/28500 (epoch 23.863), train_loss = 1.00685554, grad/param norm = 1.8681e-01, time/batch = 0.7039s	
13603/28500 (epoch 23.865), train_loss = 0.91033450, grad/param norm = 1.8225e-01, time/batch = 0.6922s	
13604/28500 (epoch 23.867), train_loss = 1.00188380, grad/param norm = 1.7217e-01, time/batch = 0.6940s	
13605/28500 (epoch 23.868), train_loss = 0.84175049, grad/param norm = 1.4860e-01, time/batch = 0.6914s	
13606/28500 (epoch 23.870), train_loss = 0.82440675, grad/param norm = 1.5009e-01, time/batch = 0.6940s	
13607/28500 (epoch 23.872), train_loss = 1.00505766, grad/param norm = 1.9078e-01, time/batch = 0.6918s	
13608/28500 (epoch 23.874), train_loss = 0.90481236, grad/param norm = 1.8584e-01, time/batch = 0.6936s	
13609/28500 (epoch 23.875), train_loss = 1.09043909, grad/param norm = 1.9190e-01, time/batch = 0.7128s	
13610/28500 (epoch 23.877), train_loss = 0.97646639, grad/param norm = 1.6359e-01, time/batch = 0.6928s	
13611/28500 (epoch 23.879), train_loss = 1.01133501, grad/param norm = 1.4481e-01, time/batch = 0.6941s	
13612/28500 (epoch 23.881), train_loss = 0.99160142, grad/param norm = 1.6167e-01, time/batch = 0.6926s	
13613/28500 (epoch 23.882), train_loss = 0.87740820, grad/param norm = 1.4506e-01, time/batch = 0.6918s	
13614/28500 (epoch 23.884), train_loss = 0.96169893, grad/param norm = 1.7055e-01, time/batch = 0.7007s	
13615/28500 (epoch 23.886), train_loss = 0.93214743, grad/param norm = 1.5350e-01, time/batch = 0.6920s	
13616/28500 (epoch 23.888), train_loss = 0.87307280, grad/param norm = 1.5069e-01, time/batch = 0.7119s	
13617/28500 (epoch 23.889), train_loss = 0.97143031, grad/param norm = 1.6381e-01, time/batch = 0.6940s	
13618/28500 (epoch 23.891), train_loss = 0.95063866, grad/param norm = 1.5652e-01, time/batch = 0.6937s	
13619/28500 (epoch 23.893), train_loss = 0.92843883, grad/param norm = 1.6091e-01, time/batch = 0.6915s	
13620/28500 (epoch 23.895), train_loss = 1.13523933, grad/param norm = 1.8701e-01, time/batch = 0.6933s	
13621/28500 (epoch 23.896), train_loss = 1.06139837, grad/param norm = 1.7197e-01, time/batch = 0.6947s	
13622/28500 (epoch 23.898), train_loss = 0.99146417, grad/param norm = 1.6674e-01, time/batch = 0.6980s	
13623/28500 (epoch 23.900), train_loss = 0.83528336, grad/param norm = 1.7933e-01, time/batch = 0.7004s	
13624/28500 (epoch 23.902), train_loss = 0.87182048, grad/param norm = 1.7862e-01, time/batch = 0.7087s	
13625/28500 (epoch 23.904), train_loss = 0.84991057, grad/param norm = 1.5490e-01, time/batch = 0.6934s	
13626/28500 (epoch 23.905), train_loss = 0.92969988, grad/param norm = 1.6778e-01, time/batch = 0.6939s	
13627/28500 (epoch 23.907), train_loss = 0.94048472, grad/param norm = 1.6654e-01, time/batch = 0.6926s	
13628/28500 (epoch 23.909), train_loss = 0.86716742, grad/param norm = 1.8380e-01, time/batch = 0.6937s	
13629/28500 (epoch 23.911), train_loss = 0.86686335, grad/param norm = 1.4758e-01, time/batch = 0.6920s	
13630/28500 (epoch 23.912), train_loss = 0.76056161, grad/param norm = 1.4822e-01, time/batch = 0.6933s	
13631/28500 (epoch 23.914), train_loss = 0.99704286, grad/param norm = 1.5852e-01, time/batch = 0.7137s	
13632/28500 (epoch 23.916), train_loss = 0.95083342, grad/param norm = 1.5880e-01, time/batch = 0.6950s	
13633/28500 (epoch 23.918), train_loss = 0.96764038, grad/param norm = 1.8772e-01, time/batch = 0.6924s	
13634/28500 (epoch 23.919), train_loss = 0.94667757, grad/param norm = 1.5969e-01, time/batch = 0.6935s	
13635/28500 (epoch 23.921), train_loss = 1.06439884, grad/param norm = 1.9885e-01, time/batch = 0.6923s	
13636/28500 (epoch 23.923), train_loss = 0.92639749, grad/param norm = 2.0582e-01, time/batch = 0.6966s	
13637/28500 (epoch 23.925), train_loss = 0.89560044, grad/param norm = 1.7678e-01, time/batch = 0.6925s	
13638/28500 (epoch 23.926), train_loss = 0.94586707, grad/param norm = 1.5134e-01, time/batch = 0.6959s	
13639/28500 (epoch 23.928), train_loss = 0.93046050, grad/param norm = 1.5991e-01, time/batch = 0.7066s	
13640/28500 (epoch 23.930), train_loss = 0.75072268, grad/param norm = 1.3929e-01, time/batch = 0.6939s	
13641/28500 (epoch 23.932), train_loss = 0.75384549, grad/param norm = 1.1981e-01, time/batch = 0.6942s	
13642/28500 (epoch 23.933), train_loss = 1.02929277, grad/param norm = 1.6191e-01, time/batch = 0.6953s	
13643/28500 (epoch 23.935), train_loss = 1.04777161, grad/param norm = 1.7505e-01, time/batch = 0.6918s	
13644/28500 (epoch 23.937), train_loss = 1.05260264, grad/param norm = 1.8830e-01, time/batch = 0.6937s	
13645/28500 (epoch 23.939), train_loss = 1.11188312, grad/param norm = 1.9565e-01, time/batch = 0.6916s	
13646/28500 (epoch 23.940), train_loss = 0.85585291, grad/param norm = 1.7079e-01, time/batch = 0.7143s	
13647/28500 (epoch 23.942), train_loss = 0.96507332, grad/param norm = 1.6695e-01, time/batch = 0.6964s	
13648/28500 (epoch 23.944), train_loss = 0.89643119, grad/param norm = 1.4850e-01, time/batch = 0.6922s	
13649/28500 (epoch 23.946), train_loss = 1.03442987, grad/param norm = 1.8235e-01, time/batch = 0.6921s	
13650/28500 (epoch 23.947), train_loss = 1.24149223, grad/param norm = 2.1624e-01, time/batch = 0.6937s	
13651/28500 (epoch 23.949), train_loss = 0.92753838, grad/param norm = 1.8085e-01, time/batch = 0.6946s	
13652/28500 (epoch 23.951), train_loss = 1.14365618, grad/param norm = 1.8850e-01, time/batch = 0.6826s	
13653/28500 (epoch 23.953), train_loss = 1.09943979, grad/param norm = 1.8512e-01, time/batch = 0.6986s	
13654/28500 (epoch 23.954), train_loss = 1.06712070, grad/param norm = 1.9427e-01, time/batch = 0.6874s	
13655/28500 (epoch 23.956), train_loss = 0.99855835, grad/param norm = 2.6674e-01, time/batch = 0.6767s	
13656/28500 (epoch 23.958), train_loss = 1.18023234, grad/param norm = 1.7637e-01, time/batch = 0.6806s	
13657/28500 (epoch 23.960), train_loss = 0.89089063, grad/param norm = 1.8080e-01, time/batch = 0.6798s	
13658/28500 (epoch 23.961), train_loss = 1.14417795, grad/param norm = 2.0145e-01, time/batch = 0.6761s	
13659/28500 (epoch 23.963), train_loss = 1.10156004, grad/param norm = 1.7278e-01, time/batch = 0.6786s	
13660/28500 (epoch 23.965), train_loss = 0.88640229, grad/param norm = 1.7121e-01, time/batch = 0.6778s	
13661/28500 (epoch 23.967), train_loss = 0.88096384, grad/param norm = 1.4415e-01, time/batch = 0.7042s	
13662/28500 (epoch 23.968), train_loss = 0.83610629, grad/param norm = 1.3711e-01, time/batch = 0.6865s	
13663/28500 (epoch 23.970), train_loss = 0.88867347, grad/param norm = 1.7447e-01, time/batch = 0.6799s	
13664/28500 (epoch 23.972), train_loss = 0.97652953, grad/param norm = 1.7854e-01, time/batch = 0.6762s	
13665/28500 (epoch 23.974), train_loss = 1.15234341, grad/param norm = 1.9295e-01, time/batch = 0.6788s	
13666/28500 (epoch 23.975), train_loss = 0.87964107, grad/param norm = 1.6491e-01, time/batch = 0.6879s	
13667/28500 (epoch 23.977), train_loss = 1.06331811, grad/param norm = 1.8192e-01, time/batch = 0.6758s	
13668/28500 (epoch 23.979), train_loss = 0.95613039, grad/param norm = 1.8696e-01, time/batch = 0.6783s	
13669/28500 (epoch 23.981), train_loss = 0.86895878, grad/param norm = 1.6534e-01, time/batch = 0.6887s	
13670/28500 (epoch 23.982), train_loss = 0.93818333, grad/param norm = 1.5729e-01, time/batch = 0.6793s	
13671/28500 (epoch 23.984), train_loss = 1.04065484, grad/param norm = 1.6809e-01, time/batch = 0.6776s	
13672/28500 (epoch 23.986), train_loss = 1.20037469, grad/param norm = 1.7977e-01, time/batch = 0.6779s	
13673/28500 (epoch 23.988), train_loss = 0.84096216, grad/param norm = 1.4734e-01, time/batch = 0.6761s	
13674/28500 (epoch 23.989), train_loss = 1.00452105, grad/param norm = 1.7083e-01, time/batch = 0.6774s	
13675/28500 (epoch 23.991), train_loss = 0.87939153, grad/param norm = 1.5101e-01, time/batch = 0.6758s	
13676/28500 (epoch 23.993), train_loss = 0.91961771, grad/param norm = 1.8638e-01, time/batch = 0.6856s	
13677/28500 (epoch 23.995), train_loss = 0.89989707, grad/param norm = 1.7054e-01, time/batch = 0.6858s	
13678/28500 (epoch 23.996), train_loss = 0.86785234, grad/param norm = 1.6164e-01, time/batch = 0.6756s	
13679/28500 (epoch 23.998), train_loss = 1.07721658, grad/param norm = 2.0307e-01, time/batch = 0.6760s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
13680/28500 (epoch 24.000), train_loss = 0.94701373, grad/param norm = 1.8611e-01, time/batch = 0.6757s	
13681/28500 (epoch 24.002), train_loss = 1.12890825, grad/param norm = 1.7984e-01, time/batch = 0.6787s	
13682/28500 (epoch 24.004), train_loss = 0.93630922, grad/param norm = 1.5931e-01, time/batch = 0.6762s	
13683/28500 (epoch 24.005), train_loss = 1.09034217, grad/param norm = 2.0509e-01, time/batch = 0.6781s	
13684/28500 (epoch 24.007), train_loss = 0.85811349, grad/param norm = 1.3555e-01, time/batch = 0.6871s	
13685/28500 (epoch 24.009), train_loss = 0.99954750, grad/param norm = 1.7817e-01, time/batch = 0.6805s	
13686/28500 (epoch 24.011), train_loss = 0.87878505, grad/param norm = 1.7494e-01, time/batch = 0.6790s	
13687/28500 (epoch 24.012), train_loss = 0.84834063, grad/param norm = 1.4079e-01, time/batch = 0.6754s	
13688/28500 (epoch 24.014), train_loss = 0.88501265, grad/param norm = 1.7663e-01, time/batch = 0.6775s	
13689/28500 (epoch 24.016), train_loss = 0.91154865, grad/param norm = 1.5441e-01, time/batch = 0.6753s	
13690/28500 (epoch 24.018), train_loss = 0.98122373, grad/param norm = 1.7655e-01, time/batch = 0.6769s	
13691/28500 (epoch 24.019), train_loss = 1.04130498, grad/param norm = 1.5832e-01, time/batch = 0.6773s	
13692/28500 (epoch 24.021), train_loss = 1.05183708, grad/param norm = 1.6227e-01, time/batch = 0.6794s	
13693/28500 (epoch 24.023), train_loss = 0.96426833, grad/param norm = 1.7349e-01, time/batch = 0.6785s	
13694/28500 (epoch 24.025), train_loss = 1.01444047, grad/param norm = 1.6668e-01, time/batch = 0.6829s	
13695/28500 (epoch 24.026), train_loss = 0.94086678, grad/param norm = 1.5163e-01, time/batch = 0.6801s	
13696/28500 (epoch 24.028), train_loss = 0.99335463, grad/param norm = 2.0812e-01, time/batch = 0.6786s	
13697/28500 (epoch 24.030), train_loss = 1.01839549, grad/param norm = 1.8082e-01, time/batch = 0.6759s	
13698/28500 (epoch 24.032), train_loss = 1.06646143, grad/param norm = 1.7203e-01, time/batch = 0.6753s	
13699/28500 (epoch 24.033), train_loss = 1.14245247, grad/param norm = 1.8055e-01, time/batch = 0.6768s	
13700/28500 (epoch 24.035), train_loss = 0.96190659, grad/param norm = 1.7201e-01, time/batch = 0.6754s	
13701/28500 (epoch 24.037), train_loss = 1.03121868, grad/param norm = 1.6410e-01, time/batch = 0.6800s	
13702/28500 (epoch 24.039), train_loss = 1.07337662, grad/param norm = 1.7430e-01, time/batch = 0.6765s	
13703/28500 (epoch 24.040), train_loss = 1.09958494, grad/param norm = 1.8804e-01, time/batch = 0.6773s	
13704/28500 (epoch 24.042), train_loss = 1.04162846, grad/param norm = 1.8240e-01, time/batch = 0.6762s	
13705/28500 (epoch 24.044), train_loss = 0.96908362, grad/param norm = 1.7246e-01, time/batch = 0.6920s	
13706/28500 (epoch 24.046), train_loss = 1.18556594, grad/param norm = 1.7039e-01, time/batch = 0.6885s	
13707/28500 (epoch 24.047), train_loss = 1.10518893, grad/param norm = 1.7896e-01, time/batch = 0.6820s	
13708/28500 (epoch 24.049), train_loss = 0.99102698, grad/param norm = 1.7080e-01, time/batch = 0.6786s	
13709/28500 (epoch 24.051), train_loss = 0.97445649, grad/param norm = 1.7036e-01, time/batch = 0.6797s	
13710/28500 (epoch 24.053), train_loss = 0.98224503, grad/param norm = 2.1664e-01, time/batch = 0.6798s	
13711/28500 (epoch 24.054), train_loss = 1.05612461, grad/param norm = 1.6490e-01, time/batch = 0.6814s	
13712/28500 (epoch 24.056), train_loss = 0.89239252, grad/param norm = 1.5411e-01, time/batch = 0.6790s	
13713/28500 (epoch 24.058), train_loss = 0.88598183, grad/param norm = 1.4950e-01, time/batch = 0.6863s	
13714/28500 (epoch 24.060), train_loss = 1.04826214, grad/param norm = 1.7393e-01, time/batch = 0.6786s	
13715/28500 (epoch 24.061), train_loss = 0.96931185, grad/param norm = 1.7013e-01, time/batch = 0.6777s	
13716/28500 (epoch 24.063), train_loss = 1.05790833, grad/param norm = 1.8721e-01, time/batch = 0.6769s	
13717/28500 (epoch 24.065), train_loss = 1.04442307, grad/param norm = 2.0267e-01, time/batch = 0.6755s	
13718/28500 (epoch 24.067), train_loss = 0.95854251, grad/param norm = 1.4928e-01, time/batch = 0.6796s	
13719/28500 (epoch 24.068), train_loss = 0.95022842, grad/param norm = 1.5130e-01, time/batch = 0.6770s	
13720/28500 (epoch 24.070), train_loss = 1.02543102, grad/param norm = 1.7832e-01, time/batch = 0.6812s	
13721/28500 (epoch 24.072), train_loss = 1.12472273, grad/param norm = 1.8035e-01, time/batch = 0.6819s	
13722/28500 (epoch 24.074), train_loss = 1.00651435, grad/param norm = 1.7103e-01, time/batch = 0.6899s	
13723/28500 (epoch 24.075), train_loss = 0.95534169, grad/param norm = 1.5154e-01, time/batch = 0.6848s	
13724/28500 (epoch 24.077), train_loss = 1.04811922, grad/param norm = 1.6040e-01, time/batch = 0.6813s	
13725/28500 (epoch 24.079), train_loss = 0.98851797, grad/param norm = 1.7568e-01, time/batch = 0.6790s	
13726/28500 (epoch 24.081), train_loss = 1.08683057, grad/param norm = 1.7012e-01, time/batch = 0.6781s	
13727/28500 (epoch 24.082), train_loss = 0.98909388, grad/param norm = 1.8825e-01, time/batch = 0.6841s	
13728/28500 (epoch 24.084), train_loss = 1.02779439, grad/param norm = 1.6641e-01, time/batch = 0.6787s	
13729/28500 (epoch 24.086), train_loss = 0.94756769, grad/param norm = 1.7132e-01, time/batch = 0.6878s	
13730/28500 (epoch 24.088), train_loss = 0.90075022, grad/param norm = 1.6065e-01, time/batch = 0.6766s	
13731/28500 (epoch 24.089), train_loss = 1.08368257, grad/param norm = 1.6664e-01, time/batch = 0.6810s	
13732/28500 (epoch 24.091), train_loss = 0.86059201, grad/param norm = 1.5474e-01, time/batch = 0.6775s	
13733/28500 (epoch 24.093), train_loss = 1.02558701, grad/param norm = 1.5556e-01, time/batch = 0.6758s	
13734/28500 (epoch 24.095), train_loss = 0.93759692, grad/param norm = 1.5385e-01, time/batch = 0.6766s	
13735/28500 (epoch 24.096), train_loss = 1.08070130, grad/param norm = 1.7169e-01, time/batch = 0.6862s	
13736/28500 (epoch 24.098), train_loss = 0.99891786, grad/param norm = 1.9960e-01, time/batch = 0.6805s	
13737/28500 (epoch 24.100), train_loss = 0.94003270, grad/param norm = 1.5627e-01, time/batch = 0.6862s	
13738/28500 (epoch 24.102), train_loss = 1.05947112, grad/param norm = 1.7957e-01, time/batch = 0.6959s	
13739/28500 (epoch 24.104), train_loss = 0.99514675, grad/param norm = 1.9235e-01, time/batch = 0.7053s	
13740/28500 (epoch 24.105), train_loss = 1.10438409, grad/param norm = 1.6556e-01, time/batch = 0.7222s	
13741/28500 (epoch 24.107), train_loss = 0.87697994, grad/param norm = 1.5490e-01, time/batch = 0.7025s	
13742/28500 (epoch 24.109), train_loss = 0.89660405, grad/param norm = 1.8242e-01, time/batch = 0.7088s	
13743/28500 (epoch 24.111), train_loss = 0.93509723, grad/param norm = 1.7128e-01, time/batch = 0.6959s	
13744/28500 (epoch 24.112), train_loss = 1.03832629, grad/param norm = 1.5855e-01, time/batch = 0.6988s	
13745/28500 (epoch 24.114), train_loss = 0.95847583, grad/param norm = 1.6836e-01, time/batch = 0.6991s	
13746/28500 (epoch 24.116), train_loss = 1.12847117, grad/param norm = 1.8951e-01, time/batch = 0.6920s	
13747/28500 (epoch 24.118), train_loss = 0.86589157, grad/param norm = 1.6927e-01, time/batch = 0.7008s	
13748/28500 (epoch 24.119), train_loss = 1.00523644, grad/param norm = 1.7332e-01, time/batch = 0.6929s	
13749/28500 (epoch 24.121), train_loss = 1.13490287, grad/param norm = 1.9555e-01, time/batch = 0.7141s	
13750/28500 (epoch 24.123), train_loss = 1.06934914, grad/param norm = 1.7742e-01, time/batch = 0.6927s	
13751/28500 (epoch 24.125), train_loss = 0.99088927, grad/param norm = 1.7856e-01, time/batch = 0.6945s	
13752/28500 (epoch 24.126), train_loss = 0.98366304, grad/param norm = 1.6560e-01, time/batch = 0.6931s	
13753/28500 (epoch 24.128), train_loss = 1.00058551, grad/param norm = 1.6299e-01, time/batch = 0.6978s	
13754/28500 (epoch 24.130), train_loss = 0.91618597, grad/param norm = 1.9054e-01, time/batch = 0.6978s	
13755/28500 (epoch 24.132), train_loss = 0.99363661, grad/param norm = 1.7078e-01, time/batch = 0.6979s	
13756/28500 (epoch 24.133), train_loss = 1.05992905, grad/param norm = 1.8359e-01, time/batch = 0.6975s	
13757/28500 (epoch 24.135), train_loss = 0.93840844, grad/param norm = 1.5196e-01, time/batch = 0.6891s	
13758/28500 (epoch 24.137), train_loss = 0.97174948, grad/param norm = 1.5517e-01, time/batch = 0.6988s	
13759/28500 (epoch 24.139), train_loss = 0.98361274, grad/param norm = 1.5717e-01, time/batch = 0.6948s	
13760/28500 (epoch 24.140), train_loss = 1.00478617, grad/param norm = 1.6110e-01, time/batch = 0.6907s	
13761/28500 (epoch 24.142), train_loss = 0.96461921, grad/param norm = 1.7385e-01, time/batch = 0.6933s	
13762/28500 (epoch 24.144), train_loss = 0.91293026, grad/param norm = 1.6596e-01, time/batch = 0.6943s	
13763/28500 (epoch 24.146), train_loss = 0.94429159, grad/param norm = 1.5113e-01, time/batch = 0.6891s	
13764/28500 (epoch 24.147), train_loss = 0.85414616, grad/param norm = 1.5437e-01, time/batch = 0.7065s	
13765/28500 (epoch 24.149), train_loss = 0.85447798, grad/param norm = 1.5724e-01, time/batch = 0.7033s	
13766/28500 (epoch 24.151), train_loss = 0.94607045, grad/param norm = 1.5376e-01, time/batch = 0.6902s	
13767/28500 (epoch 24.153), train_loss = 0.99206689, grad/param norm = 1.6872e-01, time/batch = 0.6900s	
13768/28500 (epoch 24.154), train_loss = 0.88134388, grad/param norm = 1.4970e-01, time/batch = 0.6919s	
13769/28500 (epoch 24.156), train_loss = 1.08156010, grad/param norm = 1.7452e-01, time/batch = 0.6898s	
13770/28500 (epoch 24.158), train_loss = 0.99810443, grad/param norm = 1.6073e-01, time/batch = 0.6905s	
13771/28500 (epoch 24.160), train_loss = 0.87489400, grad/param norm = 1.4667e-01, time/batch = 0.6918s	
13772/28500 (epoch 24.161), train_loss = 0.94197150, grad/param norm = 1.9967e-01, time/batch = 0.6924s	
13773/28500 (epoch 24.163), train_loss = 0.85533753, grad/param norm = 1.7238e-01, time/batch = 0.6895s	
13774/28500 (epoch 24.165), train_loss = 1.15862352, grad/param norm = 1.6530e-01, time/batch = 0.6908s	
13775/28500 (epoch 24.167), train_loss = 1.17888976, grad/param norm = 1.8627e-01, time/batch = 0.6906s	
13776/28500 (epoch 24.168), train_loss = 1.10776814, grad/param norm = 2.0351e-01, time/batch = 0.6902s	
13777/28500 (epoch 24.170), train_loss = 1.06518602, grad/param norm = 1.8120e-01, time/batch = 0.6910s	
13778/28500 (epoch 24.172), train_loss = 0.98710510, grad/param norm = 1.6770e-01, time/batch = 0.6893s	
13779/28500 (epoch 24.174), train_loss = 1.14409578, grad/param norm = 1.8768e-01, time/batch = 0.6896s	
13780/28500 (epoch 24.175), train_loss = 0.96919722, grad/param norm = 1.6252e-01, time/batch = 0.6907s	
13781/28500 (epoch 24.177), train_loss = 1.03754088, grad/param norm = 1.7523e-01, time/batch = 0.6927s	
13782/28500 (epoch 24.179), train_loss = 1.00939873, grad/param norm = 1.8034e-01, time/batch = 0.6909s	
13783/28500 (epoch 24.181), train_loss = 1.04133838, grad/param norm = 1.8804e-01, time/batch = 0.6891s	
13784/28500 (epoch 24.182), train_loss = 0.95450979, grad/param norm = 1.6165e-01, time/batch = 0.6908s	
13785/28500 (epoch 24.184), train_loss = 1.13513042, grad/param norm = 1.7088e-01, time/batch = 0.6914s	
13786/28500 (epoch 24.186), train_loss = 1.11184262, grad/param norm = 1.7685e-01, time/batch = 0.6924s	
13787/28500 (epoch 24.188), train_loss = 1.02722117, grad/param norm = 1.7106e-01, time/batch = 0.7067s	
13788/28500 (epoch 24.189), train_loss = 1.00117943, grad/param norm = 1.6308e-01, time/batch = 0.6965s	
13789/28500 (epoch 24.191), train_loss = 1.21270413, grad/param norm = 1.7729e-01, time/batch = 0.6906s	
13790/28500 (epoch 24.193), train_loss = 1.03482803, grad/param norm = 1.7785e-01, time/batch = 0.6951s	
13791/28500 (epoch 24.195), train_loss = 1.13130387, grad/param norm = 1.9427e-01, time/batch = 0.6917s	
13792/28500 (epoch 24.196), train_loss = 1.04429124, grad/param norm = 1.7380e-01, time/batch = 0.6903s	
13793/28500 (epoch 24.198), train_loss = 1.00341959, grad/param norm = 1.6509e-01, time/batch = 0.6949s	
13794/28500 (epoch 24.200), train_loss = 1.06312122, grad/param norm = 1.7782e-01, time/batch = 0.6901s	
13795/28500 (epoch 24.202), train_loss = 1.02269921, grad/param norm = 1.6859e-01, time/batch = 0.6897s	
13796/28500 (epoch 24.204), train_loss = 0.95554861, grad/param norm = 1.4813e-01, time/batch = 0.6888s	
13797/28500 (epoch 24.205), train_loss = 0.96064286, grad/param norm = 1.7539e-01, time/batch = 0.6922s	
13798/28500 (epoch 24.207), train_loss = 0.90321067, grad/param norm = 1.6979e-01, time/batch = 0.6927s	
13799/28500 (epoch 24.209), train_loss = 1.01402200, grad/param norm = 1.5860e-01, time/batch = 0.6900s	
13800/28500 (epoch 24.211), train_loss = 0.86201231, grad/param norm = 1.6975e-01, time/batch = 0.6915s	
13801/28500 (epoch 24.212), train_loss = 0.83379390, grad/param norm = 1.4913e-01, time/batch = 0.6919s	
13802/28500 (epoch 24.214), train_loss = 0.97874326, grad/param norm = 1.7731e-01, time/batch = 0.6919s	
13803/28500 (epoch 24.216), train_loss = 0.90005583, grad/param norm = 1.5798e-01, time/batch = 0.6890s	
13804/28500 (epoch 24.218), train_loss = 1.09865858, grad/param norm = 1.5855e-01, time/batch = 0.6965s	
13805/28500 (epoch 24.219), train_loss = 1.01978739, grad/param norm = 1.7200e-01, time/batch = 0.6935s	
13806/28500 (epoch 24.221), train_loss = 0.86475009, grad/param norm = 1.7252e-01, time/batch = 0.6963s	
13807/28500 (epoch 24.223), train_loss = 1.10320763, grad/param norm = 1.7393e-01, time/batch = 0.6896s	
13808/28500 (epoch 24.225), train_loss = 1.12292091, grad/param norm = 1.8355e-01, time/batch = 0.6942s	
13809/28500 (epoch 24.226), train_loss = 0.93977964, grad/param norm = 1.5901e-01, time/batch = 0.7003s	
13810/28500 (epoch 24.228), train_loss = 1.09346701, grad/param norm = 1.5570e-01, time/batch = 0.6980s	
13811/28500 (epoch 24.230), train_loss = 1.06031437, grad/param norm = 1.6354e-01, time/batch = 0.6968s	
13812/28500 (epoch 24.232), train_loss = 1.02266750, grad/param norm = 1.7176e-01, time/batch = 0.6992s	
13813/28500 (epoch 24.233), train_loss = 1.01371487, grad/param norm = 1.7731e-01, time/batch = 0.6958s	
13814/28500 (epoch 24.235), train_loss = 0.95979236, grad/param norm = 1.5709e-01, time/batch = 0.6991s	
13815/28500 (epoch 24.237), train_loss = 0.88090483, grad/param norm = 1.5073e-01, time/batch = 0.6963s	
13816/28500 (epoch 24.239), train_loss = 0.93206734, grad/param norm = 1.4681e-01, time/batch = 0.6948s	
13817/28500 (epoch 24.240), train_loss = 0.87254851, grad/param norm = 1.5539e-01, time/batch = 0.6923s	
13818/28500 (epoch 24.242), train_loss = 1.01080022, grad/param norm = 1.8339e-01, time/batch = 0.6941s	
13819/28500 (epoch 24.244), train_loss = 1.02221579, grad/param norm = 1.5128e-01, time/batch = 0.6980s	
13820/28500 (epoch 24.246), train_loss = 1.07416131, grad/param norm = 1.8054e-01, time/batch = 0.6966s	
13821/28500 (epoch 24.247), train_loss = 1.13051085, grad/param norm = 1.8250e-01, time/batch = 0.6966s	
13822/28500 (epoch 24.249), train_loss = 1.00695092, grad/param norm = 1.6346e-01, time/batch = 0.6946s	
13823/28500 (epoch 24.251), train_loss = 0.93777207, grad/param norm = 1.4784e-01, time/batch = 0.6957s	
13824/28500 (epoch 24.253), train_loss = 1.11117889, grad/param norm = 1.7778e-01, time/batch = 0.6946s	
13825/28500 (epoch 24.254), train_loss = 1.14602254, grad/param norm = 1.6501e-01, time/batch = 0.6991s	
13826/28500 (epoch 24.256), train_loss = 0.93916775, grad/param norm = 1.5675e-01, time/batch = 0.7006s	
13827/28500 (epoch 24.258), train_loss = 0.97184204, grad/param norm = 1.6887e-01, time/batch = 0.6929s	
13828/28500 (epoch 24.260), train_loss = 0.94101247, grad/param norm = 1.5353e-01, time/batch = 0.6937s	
13829/28500 (epoch 24.261), train_loss = 0.90988745, grad/param norm = 1.6090e-01, time/batch = 0.6920s	
13830/28500 (epoch 24.263), train_loss = 1.09024476, grad/param norm = 1.8893e-01, time/batch = 0.6958s	
13831/28500 (epoch 24.265), train_loss = 0.98821269, grad/param norm = 1.5265e-01, time/batch = 0.6948s	
13832/28500 (epoch 24.267), train_loss = 1.13405892, grad/param norm = 1.7690e-01, time/batch = 0.6947s	
13833/28500 (epoch 24.268), train_loss = 1.03379028, grad/param norm = 1.5529e-01, time/batch = 0.6936s	
13834/28500 (epoch 24.270), train_loss = 1.02378762, grad/param norm = 1.7976e-01, time/batch = 0.6941s	
13835/28500 (epoch 24.272), train_loss = 0.96921551, grad/param norm = 1.5960e-01, time/batch = 0.6938s	
13836/28500 (epoch 24.274), train_loss = 1.09185640, grad/param norm = 1.7850e-01, time/batch = 0.6970s	
13837/28500 (epoch 24.275), train_loss = 1.02692682, grad/param norm = 1.4893e-01, time/batch = 0.6960s	
13838/28500 (epoch 24.277), train_loss = 1.00690678, grad/param norm = 1.6034e-01, time/batch = 0.6986s	
13839/28500 (epoch 24.279), train_loss = 1.02821716, grad/param norm = 1.8961e-01, time/batch = 0.6947s	
13840/28500 (epoch 24.281), train_loss = 1.08171821, grad/param norm = 1.8856e-01, time/batch = 0.7027s	
13841/28500 (epoch 24.282), train_loss = 0.93977880, grad/param norm = 1.4487e-01, time/batch = 0.6960s	
13842/28500 (epoch 24.284), train_loss = 0.99792822, grad/param norm = 1.6883e-01, time/batch = 0.6941s	
13843/28500 (epoch 24.286), train_loss = 1.13895573, grad/param norm = 1.7898e-01, time/batch = 0.6925s	
13844/28500 (epoch 24.288), train_loss = 1.02299504, grad/param norm = 1.8084e-01, time/batch = 0.6969s	
13845/28500 (epoch 24.289), train_loss = 1.03638227, grad/param norm = 1.8750e-01, time/batch = 0.6940s	
13846/28500 (epoch 24.291), train_loss = 1.03051613, grad/param norm = 1.6452e-01, time/batch = 0.6928s	
13847/28500 (epoch 24.293), train_loss = 0.99368725, grad/param norm = 1.6400e-01, time/batch = 0.6952s	
13848/28500 (epoch 24.295), train_loss = 0.88024078, grad/param norm = 1.6035e-01, time/batch = 0.6921s	
13849/28500 (epoch 24.296), train_loss = 0.87857208, grad/param norm = 1.5822e-01, time/batch = 0.6932s	
13850/28500 (epoch 24.298), train_loss = 1.06437762, grad/param norm = 1.6549e-01, time/batch = 0.6950s	
13851/28500 (epoch 24.300), train_loss = 0.90830159, grad/param norm = 1.5726e-01, time/batch = 0.6953s	
13852/28500 (epoch 24.302), train_loss = 0.87480820, grad/param norm = 1.5876e-01, time/batch = 0.6952s	
13853/28500 (epoch 24.304), train_loss = 0.95406731, grad/param norm = 1.5982e-01, time/batch = 0.6959s	
13854/28500 (epoch 24.305), train_loss = 1.03460452, grad/param norm = 1.6985e-01, time/batch = 0.6940s	
13855/28500 (epoch 24.307), train_loss = 0.98446651, grad/param norm = 1.7786e-01, time/batch = 0.6946s	
13856/28500 (epoch 24.309), train_loss = 0.99695406, grad/param norm = 1.7022e-01, time/batch = 0.6922s	
13857/28500 (epoch 24.311), train_loss = 1.04427909, grad/param norm = 1.6960e-01, time/batch = 0.6947s	
13858/28500 (epoch 24.312), train_loss = 1.02082242, grad/param norm = 1.6909e-01, time/batch = 0.6925s	
13859/28500 (epoch 24.314), train_loss = 1.08578071, grad/param norm = 2.1091e-01, time/batch = 0.6938s	
13860/28500 (epoch 24.316), train_loss = 1.00475237, grad/param norm = 1.7076e-01, time/batch = 0.6922s	
13861/28500 (epoch 24.318), train_loss = 1.06655598, grad/param norm = 1.6366e-01, time/batch = 0.6967s	
13862/28500 (epoch 24.319), train_loss = 0.97509926, grad/param norm = 1.8083e-01, time/batch = 0.6927s	
13863/28500 (epoch 24.321), train_loss = 0.94475394, grad/param norm = 1.6939e-01, time/batch = 0.6944s	
13864/28500 (epoch 24.323), train_loss = 0.94526578, grad/param norm = 1.8081e-01, time/batch = 0.6909s	
13865/28500 (epoch 24.325), train_loss = 1.13282016, grad/param norm = 1.7488e-01, time/batch = 0.6920s	
13866/28500 (epoch 24.326), train_loss = 1.01631638, grad/param norm = 1.6436e-01, time/batch = 0.6928s	
13867/28500 (epoch 24.328), train_loss = 0.82460514, grad/param norm = 1.6893e-01, time/batch = 0.6929s	
13868/28500 (epoch 24.330), train_loss = 0.92133318, grad/param norm = 1.5529e-01, time/batch = 0.6934s	
13869/28500 (epoch 24.332), train_loss = 0.99249671, grad/param norm = 1.4862e-01, time/batch = 0.6921s	
13870/28500 (epoch 24.333), train_loss = 0.80826321, grad/param norm = 1.5013e-01, time/batch = 0.6935s	
13871/28500 (epoch 24.335), train_loss = 0.87756549, grad/param norm = 1.4777e-01, time/batch = 0.6961s	
13872/28500 (epoch 24.337), train_loss = 0.87693596, grad/param norm = 1.5429e-01, time/batch = 0.6927s	
13873/28500 (epoch 24.339), train_loss = 0.83129860, grad/param norm = 1.4085e-01, time/batch = 0.6948s	
13874/28500 (epoch 24.340), train_loss = 0.99353043, grad/param norm = 2.0838e-01, time/batch = 0.6937s	
13875/28500 (epoch 24.342), train_loss = 0.96524528, grad/param norm = 1.6230e-01, time/batch = 0.6932s	
13876/28500 (epoch 24.344), train_loss = 0.91967843, grad/param norm = 1.9123e-01, time/batch = 0.6924s	
13877/28500 (epoch 24.346), train_loss = 0.79934646, grad/param norm = 1.3520e-01, time/batch = 0.6938s	
13878/28500 (epoch 24.347), train_loss = 0.98112196, grad/param norm = 1.6903e-01, time/batch = 0.6919s	
13879/28500 (epoch 24.349), train_loss = 0.95092266, grad/param norm = 1.5536e-01, time/batch = 0.6950s	
13880/28500 (epoch 24.351), train_loss = 0.89805628, grad/param norm = 1.4527e-01, time/batch = 0.6933s	
13881/28500 (epoch 24.353), train_loss = 1.00652728, grad/param norm = 2.7305e-01, time/batch = 0.6950s	
13882/28500 (epoch 24.354), train_loss = 0.89386898, grad/param norm = 1.6831e-01, time/batch = 0.6948s	
13883/28500 (epoch 24.356), train_loss = 0.90711671, grad/param norm = 1.4664e-01, time/batch = 0.6930s	
13884/28500 (epoch 24.358), train_loss = 1.01950767, grad/param norm = 1.8404e-01, time/batch = 0.6940s	
13885/28500 (epoch 24.360), train_loss = 1.00328192, grad/param norm = 1.7769e-01, time/batch = 0.6935s	
13886/28500 (epoch 24.361), train_loss = 0.90665078, grad/param norm = 1.5148e-01, time/batch = 0.6944s	
13887/28500 (epoch 24.363), train_loss = 0.87214335, grad/param norm = 1.4129e-01, time/batch = 0.6944s	
13888/28500 (epoch 24.365), train_loss = 0.94252653, grad/param norm = 1.5581e-01, time/batch = 0.6921s	
13889/28500 (epoch 24.367), train_loss = 0.98504371, grad/param norm = 1.5665e-01, time/batch = 0.6947s	
13890/28500 (epoch 24.368), train_loss = 0.92456378, grad/param norm = 1.4991e-01, time/batch = 0.6947s	
13891/28500 (epoch 24.370), train_loss = 0.97211621, grad/param norm = 1.6534e-01, time/batch = 0.6942s	
13892/28500 (epoch 24.372), train_loss = 0.80421222, grad/param norm = 1.5265e-01, time/batch = 0.6955s	
13893/28500 (epoch 24.374), train_loss = 0.93963875, grad/param norm = 1.6975e-01, time/batch = 0.6925s	
13894/28500 (epoch 24.375), train_loss = 1.08634292, grad/param norm = 1.7572e-01, time/batch = 0.6941s	
13895/28500 (epoch 24.377), train_loss = 0.83550782, grad/param norm = 1.8430e-01, time/batch = 0.6911s	
13896/28500 (epoch 24.379), train_loss = 0.75806297, grad/param norm = 1.6578e-01, time/batch = 0.6936s	
13897/28500 (epoch 24.381), train_loss = 0.92939445, grad/param norm = 1.5663e-01, time/batch = 0.6914s	
13898/28500 (epoch 24.382), train_loss = 0.90627998, grad/param norm = 1.7186e-01, time/batch = 0.6939s	
13899/28500 (epoch 24.384), train_loss = 0.82721432, grad/param norm = 1.4973e-01, time/batch = 0.6911s	
13900/28500 (epoch 24.386), train_loss = 0.86004843, grad/param norm = 1.5839e-01, time/batch = 0.6995s	
13901/28500 (epoch 24.388), train_loss = 1.05449262, grad/param norm = 1.7356e-01, time/batch = 0.6948s	
13902/28500 (epoch 24.389), train_loss = 0.90935497, grad/param norm = 1.7549e-01, time/batch = 0.6934s	
13903/28500 (epoch 24.391), train_loss = 0.85393419, grad/param norm = 1.5147e-01, time/batch = 0.6948s	
13904/28500 (epoch 24.393), train_loss = 0.87486492, grad/param norm = 1.6532e-01, time/batch = 0.6963s	
13905/28500 (epoch 24.395), train_loss = 1.12254266, grad/param norm = 1.8228e-01, time/batch = 0.6932s	
13906/28500 (epoch 24.396), train_loss = 1.04960407, grad/param norm = 1.8936e-01, time/batch = 0.6934s	
13907/28500 (epoch 24.398), train_loss = 0.73417578, grad/param norm = 1.5690e-01, time/batch = 0.6943s	
13908/28500 (epoch 24.400), train_loss = 0.94402380, grad/param norm = 1.7625e-01, time/batch = 0.6937s	
13909/28500 (epoch 24.402), train_loss = 0.98224815, grad/param norm = 1.7389e-01, time/batch = 0.6938s	
13910/28500 (epoch 24.404), train_loss = 1.03604920, grad/param norm = 1.8016e-01, time/batch = 0.6969s	
13911/28500 (epoch 24.405), train_loss = 1.03660216, grad/param norm = 1.6652e-01, time/batch = 0.7033s	
13912/28500 (epoch 24.407), train_loss = 1.00069483, grad/param norm = 1.6736e-01, time/batch = 0.7004s	
13913/28500 (epoch 24.409), train_loss = 1.01002775, grad/param norm = 1.6648e-01, time/batch = 0.6976s	
13914/28500 (epoch 24.411), train_loss = 1.05919878, grad/param norm = 1.6892e-01, time/batch = 0.6928s	
13915/28500 (epoch 24.412), train_loss = 1.07875516, grad/param norm = 1.7897e-01, time/batch = 0.6954s	
13916/28500 (epoch 24.414), train_loss = 0.99119191, grad/param norm = 1.6959e-01, time/batch = 0.6910s	
13917/28500 (epoch 24.416), train_loss = 0.90492458, grad/param norm = 1.6529e-01, time/batch = 0.6961s	
13918/28500 (epoch 24.418), train_loss = 0.99209350, grad/param norm = 1.5354e-01, time/batch = 0.7137s	
13919/28500 (epoch 24.419), train_loss = 1.10692237, grad/param norm = 2.0026e-01, time/batch = 0.6957s	
13920/28500 (epoch 24.421), train_loss = 1.04836271, grad/param norm = 1.6089e-01, time/batch = 0.6955s	
13921/28500 (epoch 24.423), train_loss = 1.08768899, grad/param norm = 1.9860e-01, time/batch = 0.6951s	
13922/28500 (epoch 24.425), train_loss = 1.00675218, grad/param norm = 1.6750e-01, time/batch = 0.6950s	
13923/28500 (epoch 24.426), train_loss = 0.97682865, grad/param norm = 1.7932e-01, time/batch = 0.6932s	
13924/28500 (epoch 24.428), train_loss = 1.14078877, grad/param norm = 1.9247e-01, time/batch = 0.6932s	
13925/28500 (epoch 24.430), train_loss = 1.10756072, grad/param norm = 1.6889e-01, time/batch = 0.6959s	
13926/28500 (epoch 24.432), train_loss = 1.00210189, grad/param norm = 1.8157e-01, time/batch = 0.6924s	
13927/28500 (epoch 24.433), train_loss = 1.02567921, grad/param norm = 1.6753e-01, time/batch = 0.6934s	
13928/28500 (epoch 24.435), train_loss = 1.00969199, grad/param norm = 1.8034e-01, time/batch = 0.6947s	
13929/28500 (epoch 24.437), train_loss = 0.91145672, grad/param norm = 1.4917e-01, time/batch = 0.6940s	
13930/28500 (epoch 24.439), train_loss = 0.94347843, grad/param norm = 1.3931e-01, time/batch = 0.6923s	
13931/28500 (epoch 24.440), train_loss = 1.18085432, grad/param norm = 1.8440e-01, time/batch = 0.6969s	
13932/28500 (epoch 24.442), train_loss = 0.92565209, grad/param norm = 1.7086e-01, time/batch = 0.6942s	
13933/28500 (epoch 24.444), train_loss = 0.84850430, grad/param norm = 1.4458e-01, time/batch = 0.6916s	
13934/28500 (epoch 24.446), train_loss = 0.83122527, grad/param norm = 1.5787e-01, time/batch = 0.6947s	
13935/28500 (epoch 24.447), train_loss = 0.83945340, grad/param norm = 1.3434e-01, time/batch = 0.6920s	
13936/28500 (epoch 24.449), train_loss = 0.91285639, grad/param norm = 1.4848e-01, time/batch = 0.6942s	
13937/28500 (epoch 24.451), train_loss = 0.95930706, grad/param norm = 1.5085e-01, time/batch = 0.6951s	
13938/28500 (epoch 24.453), train_loss = 0.94863044, grad/param norm = 1.5826e-01, time/batch = 0.6945s	
13939/28500 (epoch 24.454), train_loss = 0.92326498, grad/param norm = 1.5277e-01, time/batch = 0.6942s	
13940/28500 (epoch 24.456), train_loss = 1.03896415, grad/param norm = 1.9000e-01, time/batch = 0.6929s	
13941/28500 (epoch 24.458), train_loss = 0.94392973, grad/param norm = 1.6309e-01, time/batch = 0.6989s	
13942/28500 (epoch 24.460), train_loss = 1.03376068, grad/param norm = 1.6574e-01, time/batch = 0.6937s	
13943/28500 (epoch 24.461), train_loss = 0.91489493, grad/param norm = 1.7557e-01, time/batch = 0.6931s	
13944/28500 (epoch 24.463), train_loss = 0.82735391, grad/param norm = 1.3805e-01, time/batch = 0.6929s	
13945/28500 (epoch 24.465), train_loss = 0.83014401, grad/param norm = 1.5995e-01, time/batch = 0.6946s	
13946/28500 (epoch 24.467), train_loss = 0.97032798, grad/param norm = 1.5768e-01, time/batch = 0.6943s	
13947/28500 (epoch 24.468), train_loss = 0.88077239, grad/param norm = 1.4571e-01, time/batch = 0.6941s	
13948/28500 (epoch 24.470), train_loss = 0.89723982, grad/param norm = 1.5990e-01, time/batch = 0.6952s	
13949/28500 (epoch 24.472), train_loss = 0.91102386, grad/param norm = 1.5751e-01, time/batch = 0.6927s	
13950/28500 (epoch 24.474), train_loss = 1.11899857, grad/param norm = 1.8485e-01, time/batch = 0.6944s	
13951/28500 (epoch 24.475), train_loss = 0.88551548, grad/param norm = 1.5853e-01, time/batch = 0.7179s	
13952/28500 (epoch 24.477), train_loss = 0.93277149, grad/param norm = 1.6602e-01, time/batch = 0.6944s	
13953/28500 (epoch 24.479), train_loss = 1.00943565, grad/param norm = 1.6644e-01, time/batch = 0.6970s	
13954/28500 (epoch 24.481), train_loss = 0.99795037, grad/param norm = 1.8079e-01, time/batch = 0.6948s	
13955/28500 (epoch 24.482), train_loss = 0.87846521, grad/param norm = 1.5516e-01, time/batch = 0.6933s	
13956/28500 (epoch 24.484), train_loss = 0.88155094, grad/param norm = 1.5821e-01, time/batch = 0.6955s	
13957/28500 (epoch 24.486), train_loss = 0.79385076, grad/param norm = 1.6372e-01, time/batch = 0.6994s	
13958/28500 (epoch 24.488), train_loss = 0.99306443, grad/param norm = 1.5315e-01, time/batch = 0.6940s	
13959/28500 (epoch 24.489), train_loss = 1.07771186, grad/param norm = 1.6465e-01, time/batch = 0.6951s	
13960/28500 (epoch 24.491), train_loss = 0.92497202, grad/param norm = 1.6881e-01, time/batch = 0.6933s	
13961/28500 (epoch 24.493), train_loss = 0.94457493, grad/param norm = 1.4994e-01, time/batch = 0.7003s	
13962/28500 (epoch 24.495), train_loss = 0.96343052, grad/param norm = 1.5521e-01, time/batch = 0.6933s	
13963/28500 (epoch 24.496), train_loss = 0.87507441, grad/param norm = 1.7502e-01, time/batch = 0.6945s	
13964/28500 (epoch 24.498), train_loss = 0.96296439, grad/param norm = 1.7180e-01, time/batch = 0.6927s	
13965/28500 (epoch 24.500), train_loss = 0.90179121, grad/param norm = 1.5507e-01, time/batch = 0.6941s	
13966/28500 (epoch 24.502), train_loss = 1.05003890, grad/param norm = 1.6240e-01, time/batch = 0.6929s	
13967/28500 (epoch 24.504), train_loss = 0.98003237, grad/param norm = 1.5519e-01, time/batch = 0.6950s	
13968/28500 (epoch 24.505), train_loss = 0.89494160, grad/param norm = 1.5058e-01, time/batch = 0.6955s	
13969/28500 (epoch 24.507), train_loss = 1.08815203, grad/param norm = 1.9137e-01, time/batch = 0.6941s	
13970/28500 (epoch 24.509), train_loss = 0.95733549, grad/param norm = 1.6596e-01, time/batch = 0.6942s	
13971/28500 (epoch 24.511), train_loss = 0.96854971, grad/param norm = 1.6720e-01, time/batch = 0.6977s	
13972/28500 (epoch 24.512), train_loss = 1.00828649, grad/param norm = 1.5501e-01, time/batch = 0.6967s	
13973/28500 (epoch 24.514), train_loss = 0.94028319, grad/param norm = 1.5556e-01, time/batch = 0.6929s	
13974/28500 (epoch 24.516), train_loss = 0.93359789, grad/param norm = 1.5012e-01, time/batch = 0.6929s	
13975/28500 (epoch 24.518), train_loss = 1.01528329, grad/param norm = 1.7714e-01, time/batch = 0.6899s	
13976/28500 (epoch 24.519), train_loss = 1.04123061, grad/param norm = 1.6175e-01, time/batch = 0.6893s	
13977/28500 (epoch 24.521), train_loss = 1.12127903, grad/param norm = 1.8792e-01, time/batch = 0.6907s	
13978/28500 (epoch 24.523), train_loss = 1.03009330, grad/param norm = 1.8723e-01, time/batch = 0.7060s	
13979/28500 (epoch 24.525), train_loss = 1.05720703, grad/param norm = 1.7170e-01, time/batch = 0.6942s	
13980/28500 (epoch 24.526), train_loss = 1.03442687, grad/param norm = 1.6167e-01, time/batch = 0.6942s	
13981/28500 (epoch 24.528), train_loss = 1.03486572, grad/param norm = 1.7298e-01, time/batch = 0.6964s	
13982/28500 (epoch 24.530), train_loss = 1.05756900, grad/param norm = 1.6542e-01, time/batch = 0.6904s	
13983/28500 (epoch 24.532), train_loss = 0.93387768, grad/param norm = 1.4621e-01, time/batch = 0.6909s	
13984/28500 (epoch 24.533), train_loss = 1.04880925, grad/param norm = 1.6349e-01, time/batch = 0.6928s	
13985/28500 (epoch 24.535), train_loss = 0.83760798, grad/param norm = 1.4325e-01, time/batch = 0.6925s	
13986/28500 (epoch 24.537), train_loss = 0.85741654, grad/param norm = 1.5340e-01, time/batch = 0.6915s	
13987/28500 (epoch 24.539), train_loss = 0.81754523, grad/param norm = 1.4521e-01, time/batch = 0.6921s	
13988/28500 (epoch 24.540), train_loss = 1.00313092, grad/param norm = 1.8421e-01, time/batch = 0.6913s	
13989/28500 (epoch 24.542), train_loss = 1.03387820, grad/param norm = 1.8730e-01, time/batch = 0.6931s	
13990/28500 (epoch 24.544), train_loss = 1.12862263, grad/param norm = 1.7719e-01, time/batch = 0.6912s	
13991/28500 (epoch 24.546), train_loss = 0.95310692, grad/param norm = 1.6236e-01, time/batch = 0.6916s	
13992/28500 (epoch 24.547), train_loss = 0.98295406, grad/param norm = 1.6270e-01, time/batch = 0.6894s	
13993/28500 (epoch 24.549), train_loss = 0.81595166, grad/param norm = 1.3654e-01, time/batch = 0.6897s	
13994/28500 (epoch 24.551), train_loss = 0.95981856, grad/param norm = 1.9565e-01, time/batch = 0.6896s	
13995/28500 (epoch 24.553), train_loss = 1.15945149, grad/param norm = 2.0042e-01, time/batch = 0.6931s	
13996/28500 (epoch 24.554), train_loss = 1.00172407, grad/param norm = 1.6908e-01, time/batch = 0.6951s	
13997/28500 (epoch 24.556), train_loss = 1.01928043, grad/param norm = 1.7360e-01, time/batch = 0.7125s	
13998/28500 (epoch 24.558), train_loss = 1.01128662, grad/param norm = 1.5823e-01, time/batch = 0.7019s	
13999/28500 (epoch 24.560), train_loss = 1.00430034, grad/param norm = 1.6840e-01, time/batch = 0.6980s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch24.56_1.7415.t7	
14000/28500 (epoch 24.561), train_loss = 1.05079343, grad/param norm = 1.7633e-01, time/batch = 0.7041s	
14001/28500 (epoch 24.563), train_loss = 1.35589823, grad/param norm = 2.1584e-01, time/batch = 0.6973s	
14002/28500 (epoch 24.565), train_loss = 0.92948299, grad/param norm = 1.6202e-01, time/batch = 0.6907s	
14003/28500 (epoch 24.567), train_loss = 0.86919286, grad/param norm = 1.4746e-01, time/batch = 0.6905s	
14004/28500 (epoch 24.568), train_loss = 1.02137231, grad/param norm = 2.0481e-01, time/batch = 0.6906s	
14005/28500 (epoch 24.570), train_loss = 0.94683949, grad/param norm = 1.5352e-01, time/batch = 0.6993s	
14006/28500 (epoch 24.572), train_loss = 0.94384547, grad/param norm = 1.7284e-01, time/batch = 0.6957s	
14007/28500 (epoch 24.574), train_loss = 0.93920185, grad/param norm = 1.6376e-01, time/batch = 0.6943s	
14008/28500 (epoch 24.575), train_loss = 0.95507612, grad/param norm = 1.6288e-01, time/batch = 0.6960s	
14009/28500 (epoch 24.577), train_loss = 1.00721962, grad/param norm = 1.8690e-01, time/batch = 0.6940s	
14010/28500 (epoch 24.579), train_loss = 1.07111093, grad/param norm = 1.7656e-01, time/batch = 0.6918s	
14011/28500 (epoch 24.581), train_loss = 0.89903866, grad/param norm = 1.8181e-01, time/batch = 0.6946s	
14012/28500 (epoch 24.582), train_loss = 1.04526259, grad/param norm = 1.5489e-01, time/batch = 0.6939s	
14013/28500 (epoch 24.584), train_loss = 0.92481364, grad/param norm = 1.6960e-01, time/batch = 0.6897s	
14014/28500 (epoch 24.586), train_loss = 0.89097449, grad/param norm = 1.4871e-01, time/batch = 0.6889s	
14015/28500 (epoch 24.588), train_loss = 0.90289051, grad/param norm = 1.6102e-01, time/batch = 0.6959s	
14016/28500 (epoch 24.589), train_loss = 0.99707020, grad/param norm = 2.0169e-01, time/batch = 0.7027s	
14017/28500 (epoch 24.591), train_loss = 0.98833661, grad/param norm = 1.7616e-01, time/batch = 0.6941s	
14018/28500 (epoch 24.593), train_loss = 0.91438168, grad/param norm = 1.6174e-01, time/batch = 0.6944s	
14019/28500 (epoch 24.595), train_loss = 1.17022161, grad/param norm = 1.8724e-01, time/batch = 0.6918s	
14020/28500 (epoch 24.596), train_loss = 1.15783032, grad/param norm = 1.9308e-01, time/batch = 0.6896s	
14021/28500 (epoch 24.598), train_loss = 0.96753740, grad/param norm = 1.6170e-01, time/batch = 0.6935s	
14022/28500 (epoch 24.600), train_loss = 0.99386505, grad/param norm = 1.9308e-01, time/batch = 0.6936s	
14023/28500 (epoch 24.602), train_loss = 1.06491463, grad/param norm = 1.7941e-01, time/batch = 0.6920s	
14024/28500 (epoch 24.604), train_loss = 1.05964322, grad/param norm = 1.6462e-01, time/batch = 0.6935s	
14025/28500 (epoch 24.605), train_loss = 1.02893966, grad/param norm = 1.7108e-01, time/batch = 0.6945s	
14026/28500 (epoch 24.607), train_loss = 1.07455243, grad/param norm = 1.5483e-01, time/batch = 0.6952s	
14027/28500 (epoch 24.609), train_loss = 1.00617526, grad/param norm = 1.8093e-01, time/batch = 0.7003s	
14028/28500 (epoch 24.611), train_loss = 0.95380902, grad/param norm = 1.8118e-01, time/batch = 0.7028s	
14029/28500 (epoch 24.612), train_loss = 1.03555796, grad/param norm = 1.8798e-01, time/batch = 0.6950s	
14030/28500 (epoch 24.614), train_loss = 1.01243905, grad/param norm = 1.5750e-01, time/batch = 0.6928s	
14031/28500 (epoch 24.616), train_loss = 0.92151840, grad/param norm = 1.5816e-01, time/batch = 0.6957s	
14032/28500 (epoch 24.618), train_loss = 0.96654649, grad/param norm = 1.7776e-01, time/batch = 0.6927s	
14033/28500 (epoch 24.619), train_loss = 1.10970411, grad/param norm = 2.0531e-01, time/batch = 0.6954s	
14034/28500 (epoch 24.621), train_loss = 0.80939942, grad/param norm = 1.3870e-01, time/batch = 0.6917s	
14035/28500 (epoch 24.623), train_loss = 1.08827405, grad/param norm = 2.1383e-01, time/batch = 0.6959s	
14036/28500 (epoch 24.625), train_loss = 0.86629128, grad/param norm = 1.5838e-01, time/batch = 0.6940s	
14037/28500 (epoch 24.626), train_loss = 0.76554668, grad/param norm = 1.3944e-01, time/batch = 0.6891s	
14038/28500 (epoch 24.628), train_loss = 0.90241566, grad/param norm = 1.5481e-01, time/batch = 0.6914s	
14039/28500 (epoch 24.630), train_loss = 0.84738214, grad/param norm = 1.5461e-01, time/batch = 0.6904s	
14040/28500 (epoch 24.632), train_loss = 1.05899328, grad/param norm = 1.6754e-01, time/batch = 0.6949s	
14041/28500 (epoch 24.633), train_loss = 1.12411351, grad/param norm = 1.5320e-01, time/batch = 0.6930s	
14042/28500 (epoch 24.635), train_loss = 1.05208802, grad/param norm = 1.8469e-01, time/batch = 0.6903s	
14043/28500 (epoch 24.637), train_loss = 1.01086589, grad/param norm = 1.6514e-01, time/batch = 0.6937s	
14044/28500 (epoch 24.639), train_loss = 0.87223519, grad/param norm = 1.6317e-01, time/batch = 0.6928s	
14045/28500 (epoch 24.640), train_loss = 0.91567019, grad/param norm = 1.5990e-01, time/batch = 0.6917s	
14046/28500 (epoch 24.642), train_loss = 0.91257870, grad/param norm = 1.5380e-01, time/batch = 0.6934s	
14047/28500 (epoch 24.644), train_loss = 1.06821660, grad/param norm = 1.8607e-01, time/batch = 0.6895s	
14048/28500 (epoch 24.646), train_loss = 0.84582219, grad/param norm = 1.3942e-01, time/batch = 0.6909s	
14049/28500 (epoch 24.647), train_loss = 0.88097489, grad/param norm = 1.6335e-01, time/batch = 0.6896s	
14050/28500 (epoch 24.649), train_loss = 0.84625160, grad/param norm = 1.5797e-01, time/batch = 0.6887s	
14051/28500 (epoch 24.651), train_loss = 0.85489770, grad/param norm = 1.4872e-01, time/batch = 0.6915s	
14052/28500 (epoch 24.653), train_loss = 0.84537081, grad/param norm = 1.5832e-01, time/batch = 0.7100s	
14053/28500 (epoch 24.654), train_loss = 0.91074521, grad/param norm = 1.5984e-01, time/batch = 0.6960s	
14054/28500 (epoch 24.656), train_loss = 0.88637108, grad/param norm = 1.6419e-01, time/batch = 0.6921s	
14055/28500 (epoch 24.658), train_loss = 0.94034991, grad/param norm = 1.5919e-01, time/batch = 0.6908s	
14056/28500 (epoch 24.660), train_loss = 0.95638585, grad/param norm = 1.5972e-01, time/batch = 0.6899s	
14057/28500 (epoch 24.661), train_loss = 1.10948441, grad/param norm = 1.8159e-01, time/batch = 0.6906s	
14058/28500 (epoch 24.663), train_loss = 1.07627169, grad/param norm = 1.6375e-01, time/batch = 0.6905s	
14059/28500 (epoch 24.665), train_loss = 0.94993770, grad/param norm = 1.5770e-01, time/batch = 0.6928s	
14060/28500 (epoch 24.667), train_loss = 0.96122570, grad/param norm = 1.7521e-01, time/batch = 0.6893s	
14061/28500 (epoch 24.668), train_loss = 0.94499331, grad/param norm = 1.4713e-01, time/batch = 0.6924s	
14062/28500 (epoch 24.670), train_loss = 0.96916090, grad/param norm = 1.6534e-01, time/batch = 0.6930s	
14063/28500 (epoch 24.672), train_loss = 0.89692143, grad/param norm = 1.6011e-01, time/batch = 0.6914s	
14064/28500 (epoch 24.674), train_loss = 0.79490647, grad/param norm = 1.7080e-01, time/batch = 0.6897s	
14065/28500 (epoch 24.675), train_loss = 0.84297629, grad/param norm = 1.5412e-01, time/batch = 0.6907s	
14066/28500 (epoch 24.677), train_loss = 0.92123303, grad/param norm = 1.5916e-01, time/batch = 0.6909s	
14067/28500 (epoch 24.679), train_loss = 0.91438551, grad/param norm = 1.6340e-01, time/batch = 0.6896s	
14068/28500 (epoch 24.681), train_loss = 1.00570632, grad/param norm = 1.6447e-01, time/batch = 0.6892s	
14069/28500 (epoch 24.682), train_loss = 0.91354566, grad/param norm = 1.5495e-01, time/batch = 0.6889s	
14070/28500 (epoch 24.684), train_loss = 0.98346034, grad/param norm = 1.5931e-01, time/batch = 0.6889s	
14071/28500 (epoch 24.686), train_loss = 0.92675840, grad/param norm = 1.6793e-01, time/batch = 0.6936s	
14072/28500 (epoch 24.688), train_loss = 0.87103450, grad/param norm = 1.4225e-01, time/batch = 0.6967s	
14073/28500 (epoch 24.689), train_loss = 0.92216572, grad/param norm = 1.7991e-01, time/batch = 0.6943s	
14074/28500 (epoch 24.691), train_loss = 0.98472536, grad/param norm = 1.7509e-01, time/batch = 0.6964s	
14075/28500 (epoch 24.693), train_loss = 0.90708131, grad/param norm = 1.5992e-01, time/batch = 0.7062s	
14076/28500 (epoch 24.695), train_loss = 0.73140971, grad/param norm = 1.7149e-01, time/batch = 0.6974s	
14077/28500 (epoch 24.696), train_loss = 0.94422515, grad/param norm = 1.5923e-01, time/batch = 0.6929s	
14078/28500 (epoch 24.698), train_loss = 0.95056816, grad/param norm = 1.5699e-01, time/batch = 0.6961s	
14079/28500 (epoch 24.700), train_loss = 0.97227125, grad/param norm = 1.7101e-01, time/batch = 0.6944s	
14080/28500 (epoch 24.702), train_loss = 0.97940193, grad/param norm = 1.7074e-01, time/batch = 0.6927s	
14081/28500 (epoch 24.704), train_loss = 0.97018985, grad/param norm = 1.6516e-01, time/batch = 0.6959s	
14082/28500 (epoch 24.705), train_loss = 1.05197356, grad/param norm = 1.8932e-01, time/batch = 0.6949s	
14083/28500 (epoch 24.707), train_loss = 0.88983484, grad/param norm = 1.7534e-01, time/batch = 0.6929s	
14084/28500 (epoch 24.709), train_loss = 1.09034680, grad/param norm = 1.6855e-01, time/batch = 0.6930s	
14085/28500 (epoch 24.711), train_loss = 0.89516319, grad/param norm = 1.5785e-01, time/batch = 0.6950s	
14086/28500 (epoch 24.712), train_loss = 0.98713705, grad/param norm = 1.6515e-01, time/batch = 0.6941s	
14087/28500 (epoch 24.714), train_loss = 1.07713665, grad/param norm = 1.6999e-01, time/batch = 0.6922s	
14088/28500 (epoch 24.716), train_loss = 0.94611362, grad/param norm = 1.5610e-01, time/batch = 0.6943s	
14089/28500 (epoch 24.718), train_loss = 0.97571079, grad/param norm = 1.5847e-01, time/batch = 0.7046s	
14090/28500 (epoch 24.719), train_loss = 0.97485254, grad/param norm = 1.6427e-01, time/batch = 0.7045s	
14091/28500 (epoch 24.721), train_loss = 0.81008112, grad/param norm = 1.6174e-01, time/batch = 0.7012s	
14092/28500 (epoch 24.723), train_loss = 0.96320136, grad/param norm = 1.7697e-01, time/batch = 0.6982s	
14093/28500 (epoch 24.725), train_loss = 1.03276208, grad/param norm = 1.5692e-01, time/batch = 0.6963s	
14094/28500 (epoch 24.726), train_loss = 0.94427198, grad/param norm = 1.5688e-01, time/batch = 0.6945s	
14095/28500 (epoch 24.728), train_loss = 0.88763381, grad/param norm = 1.6254e-01, time/batch = 0.6946s	
14096/28500 (epoch 24.730), train_loss = 0.97367903, grad/param norm = 1.8879e-01, time/batch = 0.7030s	
14097/28500 (epoch 24.732), train_loss = 0.78486355, grad/param norm = 1.4080e-01, time/batch = 0.7036s	
14098/28500 (epoch 24.733), train_loss = 0.81770368, grad/param norm = 1.4045e-01, time/batch = 0.6951s	
14099/28500 (epoch 24.735), train_loss = 0.81967369, grad/param norm = 1.4885e-01, time/batch = 0.6892s	
14100/28500 (epoch 24.737), train_loss = 0.75396507, grad/param norm = 1.4969e-01, time/batch = 0.6883s	
14101/28500 (epoch 24.739), train_loss = 0.89556082, grad/param norm = 1.6408e-01, time/batch = 0.6905s	
14102/28500 (epoch 24.740), train_loss = 0.94028688, grad/param norm = 1.5408e-01, time/batch = 0.6888s	
14103/28500 (epoch 24.742), train_loss = 0.88189116, grad/param norm = 1.5357e-01, time/batch = 0.6883s	
14104/28500 (epoch 24.744), train_loss = 0.98032141, grad/param norm = 1.7345e-01, time/batch = 0.6886s	
14105/28500 (epoch 24.746), train_loss = 0.87753804, grad/param norm = 1.5645e-01, time/batch = 0.6894s	
14106/28500 (epoch 24.747), train_loss = 0.88232205, grad/param norm = 1.5501e-01, time/batch = 0.6885s	
14107/28500 (epoch 24.749), train_loss = 1.03501463, grad/param norm = 2.0686e-01, time/batch = 0.6880s	
14108/28500 (epoch 24.751), train_loss = 0.86050783, grad/param norm = 1.9697e-01, time/batch = 0.6882s	
14109/28500 (epoch 24.753), train_loss = 0.92119751, grad/param norm = 1.5445e-01, time/batch = 0.6882s	
14110/28500 (epoch 24.754), train_loss = 0.85168678, grad/param norm = 1.4049e-01, time/batch = 0.6903s	
14111/28500 (epoch 24.756), train_loss = 1.06067460, grad/param norm = 1.6424e-01, time/batch = 0.6929s	
14112/28500 (epoch 24.758), train_loss = 1.00618207, grad/param norm = 1.8085e-01, time/batch = 0.6972s	
14113/28500 (epoch 24.760), train_loss = 0.85625238, grad/param norm = 1.7852e-01, time/batch = 0.6960s	
14114/28500 (epoch 24.761), train_loss = 0.88986583, grad/param norm = 1.7001e-01, time/batch = 0.6951s	
14115/28500 (epoch 24.763), train_loss = 0.77192972, grad/param norm = 1.5106e-01, time/batch = 0.6951s	
14116/28500 (epoch 24.765), train_loss = 0.92586737, grad/param norm = 1.4928e-01, time/batch = 0.7081s	
14117/28500 (epoch 24.767), train_loss = 0.79892888, grad/param norm = 1.3414e-01, time/batch = 0.6980s	
14118/28500 (epoch 24.768), train_loss = 1.01128252, grad/param norm = 1.6980e-01, time/batch = 0.6907s	
14119/28500 (epoch 24.770), train_loss = 0.82983636, grad/param norm = 1.5550e-01, time/batch = 0.6886s	
14120/28500 (epoch 24.772), train_loss = 0.72875644, grad/param norm = 1.3433e-01, time/batch = 0.6882s	
14121/28500 (epoch 24.774), train_loss = 0.94686694, grad/param norm = 1.6864e-01, time/batch = 0.6929s	
14122/28500 (epoch 24.775), train_loss = 1.03381518, grad/param norm = 1.5928e-01, time/batch = 0.6992s	
14123/28500 (epoch 24.777), train_loss = 1.03192047, grad/param norm = 1.6485e-01, time/batch = 0.6931s	
14124/28500 (epoch 24.779), train_loss = 0.77600854, grad/param norm = 1.4278e-01, time/batch = 0.6927s	
14125/28500 (epoch 24.781), train_loss = 0.92809866, grad/param norm = 1.7233e-01, time/batch = 0.6922s	
14126/28500 (epoch 24.782), train_loss = 1.00423550, grad/param norm = 1.7360e-01, time/batch = 0.6982s	
14127/28500 (epoch 24.784), train_loss = 0.78402505, grad/param norm = 1.4272e-01, time/batch = 0.6927s	
14128/28500 (epoch 24.786), train_loss = 0.82932231, grad/param norm = 1.4004e-01, time/batch = 0.6970s	
14129/28500 (epoch 24.788), train_loss = 0.92870757, grad/param norm = 1.8532e-01, time/batch = 0.6971s	
14130/28500 (epoch 24.789), train_loss = 0.71528115, grad/param norm = 2.1177e-01, time/batch = 0.6965s	
14131/28500 (epoch 24.791), train_loss = 0.97758221, grad/param norm = 1.6581e-01, time/batch = 0.6987s	
14132/28500 (epoch 24.793), train_loss = 0.94780972, grad/param norm = 1.9806e-01, time/batch = 0.6967s	
14133/28500 (epoch 24.795), train_loss = 0.98162882, grad/param norm = 1.6880e-01, time/batch = 0.6936s	
14134/28500 (epoch 24.796), train_loss = 0.85281413, grad/param norm = 1.6460e-01, time/batch = 0.6959s	
14135/28500 (epoch 24.798), train_loss = 0.78020963, grad/param norm = 1.4860e-01, time/batch = 0.6933s	
14136/28500 (epoch 24.800), train_loss = 0.82712991, grad/param norm = 1.8505e-01, time/batch = 0.6924s	
14137/28500 (epoch 24.802), train_loss = 0.90970696, grad/param norm = 1.9850e-01, time/batch = 0.6985s	
14138/28500 (epoch 24.804), train_loss = 0.95676320, grad/param norm = 1.4954e-01, time/batch = 0.6996s	
14139/28500 (epoch 24.805), train_loss = 0.94030199, grad/param norm = 1.6362e-01, time/batch = 0.6963s	
14140/28500 (epoch 24.807), train_loss = 0.96847618, grad/param norm = 1.7894e-01, time/batch = 0.6932s	
14141/28500 (epoch 24.809), train_loss = 0.94388193, grad/param norm = 1.7774e-01, time/batch = 0.6977s	
14142/28500 (epoch 24.811), train_loss = 1.00567989, grad/param norm = 1.8251e-01, time/batch = 0.6945s	
14143/28500 (epoch 24.812), train_loss = 0.97914238, grad/param norm = 1.8567e-01, time/batch = 0.6955s	
14144/28500 (epoch 24.814), train_loss = 0.89022508, grad/param norm = 1.6924e-01, time/batch = 0.6931s	
14145/28500 (epoch 24.816), train_loss = 0.99221358, grad/param norm = 1.9354e-01, time/batch = 0.6970s	
14146/28500 (epoch 24.818), train_loss = 1.05016825, grad/param norm = 1.7168e-01, time/batch = 0.6926s	
14147/28500 (epoch 24.819), train_loss = 0.95525583, grad/param norm = 1.6181e-01, time/batch = 0.6931s	
14148/28500 (epoch 24.821), train_loss = 0.91485620, grad/param norm = 1.4572e-01, time/batch = 0.6923s	
14149/28500 (epoch 24.823), train_loss = 1.07806013, grad/param norm = 1.8483e-01, time/batch = 0.6935s	
14150/28500 (epoch 24.825), train_loss = 0.90628206, grad/param norm = 1.5674e-01, time/batch = 0.6919s	
14151/28500 (epoch 24.826), train_loss = 0.97209187, grad/param norm = 1.9644e-01, time/batch = 0.6960s	
14152/28500 (epoch 24.828), train_loss = 0.83655681, grad/param norm = 1.6228e-01, time/batch = 0.6937s	
14153/28500 (epoch 24.830), train_loss = 0.91139152, grad/param norm = 1.5003e-01, time/batch = 0.6925s	
14154/28500 (epoch 24.832), train_loss = 0.96358251, grad/param norm = 2.0703e-01, time/batch = 0.6926s	
14155/28500 (epoch 24.833), train_loss = 1.04584881, grad/param norm = 1.6493e-01, time/batch = 0.6912s	
14156/28500 (epoch 24.835), train_loss = 0.89220518, grad/param norm = 1.7676e-01, time/batch = 0.6924s	
14157/28500 (epoch 24.837), train_loss = 0.82273734, grad/param norm = 1.5689e-01, time/batch = 0.6912s	
14158/28500 (epoch 24.839), train_loss = 1.07474507, grad/param norm = 1.7788e-01, time/batch = 0.6924s	
14159/28500 (epoch 24.840), train_loss = 1.10903125, grad/param norm = 1.9007e-01, time/batch = 0.6916s	
14160/28500 (epoch 24.842), train_loss = 1.02105013, grad/param norm = 1.9534e-01, time/batch = 0.6970s	
14161/28500 (epoch 24.844), train_loss = 0.98642465, grad/param norm = 1.6724e-01, time/batch = 0.7153s	
14162/28500 (epoch 24.846), train_loss = 1.08002946, grad/param norm = 1.9434e-01, time/batch = 0.7070s	
14163/28500 (epoch 24.847), train_loss = 0.92152169, grad/param norm = 1.9167e-01, time/batch = 0.6937s	
14164/28500 (epoch 24.849), train_loss = 0.90991790, grad/param norm = 1.6679e-01, time/batch = 0.6958s	
14165/28500 (epoch 24.851), train_loss = 0.80043213, grad/param norm = 1.4822e-01, time/batch = 0.6919s	
14166/28500 (epoch 24.853), train_loss = 0.95607728, grad/param norm = 1.9391e-01, time/batch = 0.6943s	
14167/28500 (epoch 24.854), train_loss = 0.96089020, grad/param norm = 1.7423e-01, time/batch = 0.6945s	
14168/28500 (epoch 24.856), train_loss = 1.07098031, grad/param norm = 1.9083e-01, time/batch = 0.6936s	
14169/28500 (epoch 24.858), train_loss = 0.87955844, grad/param norm = 1.5711e-01, time/batch = 0.6931s	
14170/28500 (epoch 24.860), train_loss = 0.90533481, grad/param norm = 1.6373e-01, time/batch = 0.6925s	
14171/28500 (epoch 24.861), train_loss = 0.98735443, grad/param norm = 1.8468e-01, time/batch = 0.7041s	
14172/28500 (epoch 24.863), train_loss = 0.98914724, grad/param norm = 1.8620e-01, time/batch = 0.7077s	
14173/28500 (epoch 24.865), train_loss = 0.87124325, grad/param norm = 1.4550e-01, time/batch = 0.6991s	
14174/28500 (epoch 24.867), train_loss = 0.99365315, grad/param norm = 1.7062e-01, time/batch = 0.6942s	
14175/28500 (epoch 24.868), train_loss = 0.83809621, grad/param norm = 1.5468e-01, time/batch = 0.6953s	
14176/28500 (epoch 24.870), train_loss = 0.81425553, grad/param norm = 1.4962e-01, time/batch = 0.6933s	
14177/28500 (epoch 24.872), train_loss = 0.98206960, grad/param norm = 1.8227e-01, time/batch = 0.6941s	
14178/28500 (epoch 24.874), train_loss = 0.88748581, grad/param norm = 1.9974e-01, time/batch = 0.6941s	
14179/28500 (epoch 24.875), train_loss = 1.08488763, grad/param norm = 1.8700e-01, time/batch = 0.6951s	
14180/28500 (epoch 24.877), train_loss = 0.96028936, grad/param norm = 1.6896e-01, time/batch = 0.6944s	
14181/28500 (epoch 24.879), train_loss = 1.00865318, grad/param norm = 1.4966e-01, time/batch = 0.6945s	
14182/28500 (epoch 24.881), train_loss = 0.98063992, grad/param norm = 1.6593e-01, time/batch = 0.6938s	
14183/28500 (epoch 24.882), train_loss = 0.86884036, grad/param norm = 1.4888e-01, time/batch = 0.6917s	
14184/28500 (epoch 24.884), train_loss = 0.94618254, grad/param norm = 1.7889e-01, time/batch = 0.6930s	
14185/28500 (epoch 24.886), train_loss = 0.92372492, grad/param norm = 1.5473e-01, time/batch = 0.6916s	
14186/28500 (epoch 24.888), train_loss = 0.87900103, grad/param norm = 1.6102e-01, time/batch = 0.6926s	
14187/28500 (epoch 24.889), train_loss = 0.95585557, grad/param norm = 1.6660e-01, time/batch = 0.6924s	
14188/28500 (epoch 24.891), train_loss = 0.93246362, grad/param norm = 1.6264e-01, time/batch = 0.6926s	
14189/28500 (epoch 24.893), train_loss = 0.91514222, grad/param norm = 1.6688e-01, time/batch = 0.6921s	
14190/28500 (epoch 24.895), train_loss = 1.12952326, grad/param norm = 2.0304e-01, time/batch = 0.6923s	
14191/28500 (epoch 24.896), train_loss = 1.05588500, grad/param norm = 1.8746e-01, time/batch = 0.6953s	
14192/28500 (epoch 24.898), train_loss = 0.98408791, grad/param norm = 1.6686e-01, time/batch = 0.6940s	
14193/28500 (epoch 24.900), train_loss = 0.82128617, grad/param norm = 1.5504e-01, time/batch = 0.6940s	
14194/28500 (epoch 24.902), train_loss = 0.83244577, grad/param norm = 1.5708e-01, time/batch = 0.6919s	
14195/28500 (epoch 24.904), train_loss = 0.85368639, grad/param norm = 1.5194e-01, time/batch = 0.6930s	
14196/28500 (epoch 24.905), train_loss = 0.92557465, grad/param norm = 1.7232e-01, time/batch = 0.6925s	
14197/28500 (epoch 24.907), train_loss = 0.91945332, grad/param norm = 1.6290e-01, time/batch = 0.6953s	
14198/28500 (epoch 24.909), train_loss = 0.84461204, grad/param norm = 1.8241e-01, time/batch = 0.6944s	
14199/28500 (epoch 24.911), train_loss = 0.85453255, grad/param norm = 1.5224e-01, time/batch = 0.6910s	
14200/28500 (epoch 24.912), train_loss = 0.75033956, grad/param norm = 1.4235e-01, time/batch = 0.6917s	
14201/28500 (epoch 24.914), train_loss = 0.97817703, grad/param norm = 1.6703e-01, time/batch = 0.7064s	
14202/28500 (epoch 24.916), train_loss = 0.94036304, grad/param norm = 1.6825e-01, time/batch = 0.6973s	
14203/28500 (epoch 24.918), train_loss = 0.94260184, grad/param norm = 1.7761e-01, time/batch = 0.6963s	
14204/28500 (epoch 24.919), train_loss = 0.92878024, grad/param norm = 1.5510e-01, time/batch = 0.6933s	
14205/28500 (epoch 24.921), train_loss = 1.04615843, grad/param norm = 1.9482e-01, time/batch = 0.6953s	
14206/28500 (epoch 24.923), train_loss = 0.90516919, grad/param norm = 1.8470e-01, time/batch = 0.6943s	
14207/28500 (epoch 24.925), train_loss = 0.87771395, grad/param norm = 1.7033e-01, time/batch = 0.7010s	
14208/28500 (epoch 24.926), train_loss = 0.92138220, grad/param norm = 1.4868e-01, time/batch = 0.6986s	
14209/28500 (epoch 24.928), train_loss = 0.91493686, grad/param norm = 1.7241e-01, time/batch = 0.6892s	
14210/28500 (epoch 24.930), train_loss = 0.74396680, grad/param norm = 1.3943e-01, time/batch = 0.6887s	
14211/28500 (epoch 24.932), train_loss = 0.75180611, grad/param norm = 1.2604e-01, time/batch = 0.6928s	
14212/28500 (epoch 24.933), train_loss = 1.00670342, grad/param norm = 1.6520e-01, time/batch = 0.6905s	
14213/28500 (epoch 24.935), train_loss = 1.04261998, grad/param norm = 1.8133e-01, time/batch = 0.6908s	
14214/28500 (epoch 24.937), train_loss = 1.04587364, grad/param norm = 1.9730e-01, time/batch = 0.6911s	
14215/28500 (epoch 24.939), train_loss = 1.09752986, grad/param norm = 1.9314e-01, time/batch = 0.6890s	
14216/28500 (epoch 24.940), train_loss = 0.83805261, grad/param norm = 1.6972e-01, time/batch = 0.6891s	
14217/28500 (epoch 24.942), train_loss = 0.94459374, grad/param norm = 1.5961e-01, time/batch = 0.6898s	
14218/28500 (epoch 24.944), train_loss = 0.88493773, grad/param norm = 1.6705e-01, time/batch = 0.6891s	
14219/28500 (epoch 24.946), train_loss = 1.01343254, grad/param norm = 1.5835e-01, time/batch = 0.6919s	
14220/28500 (epoch 24.947), train_loss = 1.23650547, grad/param norm = 2.2551e-01, time/batch = 0.6941s	
14221/28500 (epoch 24.949), train_loss = 0.92198234, grad/param norm = 1.9313e-01, time/batch = 0.6946s	
14222/28500 (epoch 24.951), train_loss = 1.12741929, grad/param norm = 1.9286e-01, time/batch = 0.6893s	
14223/28500 (epoch 24.953), train_loss = 1.09691003, grad/param norm = 1.9547e-01, time/batch = 0.6883s	
14224/28500 (epoch 24.954), train_loss = 1.05852941, grad/param norm = 2.1809e-01, time/batch = 0.6932s	
14225/28500 (epoch 24.956), train_loss = 0.97819765, grad/param norm = 2.4400e-01, time/batch = 0.6904s	
14226/28500 (epoch 24.958), train_loss = 1.15001688, grad/param norm = 1.6502e-01, time/batch = 0.6885s	
14227/28500 (epoch 24.960), train_loss = 0.87981788, grad/param norm = 1.6441e-01, time/batch = 0.6885s	
14228/28500 (epoch 24.961), train_loss = 1.12159189, grad/param norm = 2.0587e-01, time/batch = 0.6890s	
14229/28500 (epoch 24.963), train_loss = 1.09395461, grad/param norm = 1.9700e-01, time/batch = 0.6904s	
14230/28500 (epoch 24.965), train_loss = 0.88227582, grad/param norm = 1.8510e-01, time/batch = 0.6909s	
14231/28500 (epoch 24.967), train_loss = 0.86488407, grad/param norm = 1.5834e-01, time/batch = 0.6945s	
14232/28500 (epoch 24.968), train_loss = 0.82596835, grad/param norm = 1.3962e-01, time/batch = 0.6932s	
14233/28500 (epoch 24.970), train_loss = 0.89659507, grad/param norm = 1.9581e-01, time/batch = 0.6886s	
14234/28500 (epoch 24.972), train_loss = 0.97651957, grad/param norm = 1.7922e-01, time/batch = 0.6899s	
14235/28500 (epoch 24.974), train_loss = 1.13422479, grad/param norm = 1.9633e-01, time/batch = 0.6928s	
14236/28500 (epoch 24.975), train_loss = 0.87585143, grad/param norm = 1.6398e-01, time/batch = 0.6905s	
14237/28500 (epoch 24.977), train_loss = 1.03388549, grad/param norm = 1.7210e-01, time/batch = 0.6910s	
14238/28500 (epoch 24.979), train_loss = 0.93857894, grad/param norm = 1.8288e-01, time/batch = 0.6880s	
14239/28500 (epoch 24.981), train_loss = 0.85438066, grad/param norm = 1.7479e-01, time/batch = 0.6890s	
14240/28500 (epoch 24.982), train_loss = 0.92882803, grad/param norm = 1.7225e-01, time/batch = 0.6916s	
14241/28500 (epoch 24.984), train_loss = 1.02433425, grad/param norm = 1.6372e-01, time/batch = 0.6914s	
14242/28500 (epoch 24.986), train_loss = 1.19271999, grad/param norm = 1.9132e-01, time/batch = 0.6896s	
14243/28500 (epoch 24.988), train_loss = 0.82918153, grad/param norm = 1.5226e-01, time/batch = 0.6884s	
14244/28500 (epoch 24.989), train_loss = 0.99755040, grad/param norm = 1.7313e-01, time/batch = 0.6880s	
14245/28500 (epoch 24.991), train_loss = 0.87050982, grad/param norm = 1.7662e-01, time/batch = 0.6886s	
14246/28500 (epoch 24.993), train_loss = 0.89118565, grad/param norm = 1.5910e-01, time/batch = 0.6924s	
14247/28500 (epoch 24.995), train_loss = 0.88327400, grad/param norm = 1.5954e-01, time/batch = 0.7004s	
14248/28500 (epoch 24.996), train_loss = 0.85341415, grad/param norm = 1.5648e-01, time/batch = 0.6963s	
14249/28500 (epoch 24.998), train_loss = 1.07340256, grad/param norm = 2.2397e-01, time/batch = 0.6976s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
14250/28500 (epoch 25.000), train_loss = 0.95131687, grad/param norm = 1.6912e-01, time/batch = 0.7139s	
14251/28500 (epoch 25.002), train_loss = 1.12688312, grad/param norm = 1.8594e-01, time/batch = 0.6936s	
14252/28500 (epoch 25.004), train_loss = 0.92265012, grad/param norm = 1.5814e-01, time/batch = 0.6928s	
14253/28500 (epoch 25.005), train_loss = 1.08622575, grad/param norm = 2.0187e-01, time/batch = 0.6903s	
14254/28500 (epoch 25.007), train_loss = 0.84791371, grad/param norm = 1.4228e-01, time/batch = 0.6896s	
14255/28500 (epoch 25.009), train_loss = 1.00180810, grad/param norm = 1.9619e-01, time/batch = 0.6893s	
14256/28500 (epoch 25.011), train_loss = 0.88634667, grad/param norm = 1.8449e-01, time/batch = 0.6899s	
14257/28500 (epoch 25.012), train_loss = 0.84936903, grad/param norm = 1.4531e-01, time/batch = 0.6904s	
14258/28500 (epoch 25.014), train_loss = 0.86811950, grad/param norm = 1.6475e-01, time/batch = 0.6890s	
14259/28500 (epoch 25.016), train_loss = 0.89630020, grad/param norm = 1.5302e-01, time/batch = 0.6894s	
14260/28500 (epoch 25.018), train_loss = 0.96364434, grad/param norm = 1.7460e-01, time/batch = 0.6890s	
14261/28500 (epoch 25.019), train_loss = 1.01325713, grad/param norm = 1.6290e-01, time/batch = 0.6911s	
14262/28500 (epoch 25.021), train_loss = 1.02705152, grad/param norm = 1.6043e-01, time/batch = 0.6902s	
14263/28500 (epoch 25.023), train_loss = 0.95570156, grad/param norm = 1.6506e-01, time/batch = 0.6903s	
14264/28500 (epoch 25.025), train_loss = 0.98114502, grad/param norm = 1.6585e-01, time/batch = 0.7051s	
14265/28500 (epoch 25.026), train_loss = 0.93601754, grad/param norm = 1.6333e-01, time/batch = 0.7032s	
14266/28500 (epoch 25.028), train_loss = 0.97321652, grad/param norm = 1.8615e-01, time/batch = 0.6954s	
14267/28500 (epoch 25.030), train_loss = 1.00750591, grad/param norm = 1.7223e-01, time/batch = 0.6931s	
14268/28500 (epoch 25.032), train_loss = 1.04364283, grad/param norm = 1.6782e-01, time/batch = 0.6921s	
14269/28500 (epoch 25.033), train_loss = 1.13529568, grad/param norm = 1.9928e-01, time/batch = 0.6890s	
14270/28500 (epoch 25.035), train_loss = 0.97010389, grad/param norm = 1.8036e-01, time/batch = 0.6924s	
14271/28500 (epoch 25.037), train_loss = 1.01768220, grad/param norm = 1.5716e-01, time/batch = 0.6943s	
14272/28500 (epoch 25.039), train_loss = 1.06033634, grad/param norm = 1.7595e-01, time/batch = 0.6903s	
14273/28500 (epoch 25.040), train_loss = 1.07782086, grad/param norm = 1.7780e-01, time/batch = 0.6910s	
14274/28500 (epoch 25.042), train_loss = 1.03284281, grad/param norm = 1.7600e-01, time/batch = 0.6918s	
14275/28500 (epoch 25.044), train_loss = 0.95933118, grad/param norm = 1.7173e-01, time/batch = 0.6917s	
14276/28500 (epoch 25.046), train_loss = 1.17083790, grad/param norm = 1.6789e-01, time/batch = 0.6915s	
14277/28500 (epoch 25.047), train_loss = 1.10306512, grad/param norm = 1.8805e-01, time/batch = 0.6893s	
14278/28500 (epoch 25.049), train_loss = 0.97250780, grad/param norm = 1.6816e-01, time/batch = 0.6886s	
14279/28500 (epoch 25.051), train_loss = 0.96207878, grad/param norm = 1.7022e-01, time/batch = 0.6897s	
14280/28500 (epoch 25.053), train_loss = 0.96463007, grad/param norm = 1.8846e-01, time/batch = 0.6905s	
14281/28500 (epoch 25.054), train_loss = 1.03897067, grad/param norm = 1.7331e-01, time/batch = 0.6978s	
14282/28500 (epoch 25.056), train_loss = 0.90181911, grad/param norm = 1.6583e-01, time/batch = 0.6943s	
14283/28500 (epoch 25.058), train_loss = 0.87675562, grad/param norm = 1.5331e-01, time/batch = 0.6947s	
14284/28500 (epoch 25.060), train_loss = 1.02367585, grad/param norm = 1.6370e-01, time/batch = 0.6898s	
14285/28500 (epoch 25.061), train_loss = 0.94707549, grad/param norm = 1.7462e-01, time/batch = 0.6895s	
14286/28500 (epoch 25.063), train_loss = 1.04337437, grad/param norm = 1.8177e-01, time/batch = 0.6901s	
14287/28500 (epoch 25.065), train_loss = 1.03503144, grad/param norm = 1.8974e-01, time/batch = 0.6889s	
14288/28500 (epoch 25.067), train_loss = 0.95101402, grad/param norm = 1.6390e-01, time/batch = 0.6896s	
14289/28500 (epoch 25.068), train_loss = 0.95283133, grad/param norm = 1.7273e-01, time/batch = 0.6892s	
14290/28500 (epoch 25.070), train_loss = 1.00388194, grad/param norm = 1.8032e-01, time/batch = 0.6892s	
14291/28500 (epoch 25.072), train_loss = 1.10039959, grad/param norm = 1.8528e-01, time/batch = 0.6916s	
14292/28500 (epoch 25.074), train_loss = 0.96711631, grad/param norm = 1.5408e-01, time/batch = 0.6902s	
14293/28500 (epoch 25.075), train_loss = 0.94633638, grad/param norm = 1.5497e-01, time/batch = 0.6900s	
14294/28500 (epoch 25.077), train_loss = 1.03959939, grad/param norm = 1.5523e-01, time/batch = 0.6897s	
14295/28500 (epoch 25.079), train_loss = 0.97274733, grad/param norm = 1.7248e-01, time/batch = 0.6896s	
14296/28500 (epoch 25.081), train_loss = 1.08204809, grad/param norm = 1.8526e-01, time/batch = 0.6895s	
14297/28500 (epoch 25.082), train_loss = 0.97882640, grad/param norm = 2.0302e-01, time/batch = 0.6906s	
14298/28500 (epoch 25.084), train_loss = 1.00705312, grad/param norm = 1.8010e-01, time/batch = 0.6919s	
14299/28500 (epoch 25.086), train_loss = 0.95480204, grad/param norm = 1.8202e-01, time/batch = 0.6907s	
14300/28500 (epoch 25.088), train_loss = 0.88805717, grad/param norm = 1.6505e-01, time/batch = 0.6901s	
14301/28500 (epoch 25.089), train_loss = 1.08913843, grad/param norm = 1.7177e-01, time/batch = 0.6971s	
14302/28500 (epoch 25.091), train_loss = 0.84553054, grad/param norm = 1.5383e-01, time/batch = 0.6949s	
14303/28500 (epoch 25.093), train_loss = 1.01303009, grad/param norm = 1.4750e-01, time/batch = 0.6939s	
14304/28500 (epoch 25.095), train_loss = 0.93736658, grad/param norm = 1.5398e-01, time/batch = 0.6970s	
14305/28500 (epoch 25.096), train_loss = 1.06949244, grad/param norm = 1.7525e-01, time/batch = 0.6932s	
14306/28500 (epoch 25.098), train_loss = 0.98438044, grad/param norm = 1.7845e-01, time/batch = 0.6955s	
14307/28500 (epoch 25.100), train_loss = 0.93070104, grad/param norm = 1.6362e-01, time/batch = 0.6969s	
14308/28500 (epoch 25.102), train_loss = 1.03875332, grad/param norm = 1.9165e-01, time/batch = 0.6984s	
14309/28500 (epoch 25.104), train_loss = 0.96815936, grad/param norm = 1.8441e-01, time/batch = 0.7095s	
14310/28500 (epoch 25.105), train_loss = 1.08810264, grad/param norm = 1.5978e-01, time/batch = 0.6941s	
14311/28500 (epoch 25.107), train_loss = 0.87014164, grad/param norm = 1.6419e-01, time/batch = 0.6974s	
14312/28500 (epoch 25.109), train_loss = 0.88961427, grad/param norm = 1.8135e-01, time/batch = 0.6947s	
14313/28500 (epoch 25.111), train_loss = 0.91608935, grad/param norm = 1.6273e-01, time/batch = 0.6943s	
14314/28500 (epoch 25.112), train_loss = 1.03554704, grad/param norm = 1.6421e-01, time/batch = 0.6952s	
14315/28500 (epoch 25.114), train_loss = 0.94078053, grad/param norm = 1.5530e-01, time/batch = 0.7075s	
14316/28500 (epoch 25.116), train_loss = 1.10812483, grad/param norm = 1.7465e-01, time/batch = 0.6919s	
14317/28500 (epoch 25.118), train_loss = 0.85668636, grad/param norm = 1.8048e-01, time/batch = 0.6946s	
14318/28500 (epoch 25.119), train_loss = 1.00408626, grad/param norm = 1.7219e-01, time/batch = 0.6918s	
14319/28500 (epoch 25.121), train_loss = 1.12352517, grad/param norm = 1.9717e-01, time/batch = 0.6949s	
14320/28500 (epoch 25.123), train_loss = 1.04981186, grad/param norm = 1.6419e-01, time/batch = 0.6958s	
14321/28500 (epoch 25.125), train_loss = 0.99077220, grad/param norm = 1.9962e-01, time/batch = 0.7003s	
14322/28500 (epoch 25.126), train_loss = 0.96397659, grad/param norm = 1.5891e-01, time/batch = 0.6978s	
14323/28500 (epoch 25.128), train_loss = 0.98763485, grad/param norm = 1.6195e-01, time/batch = 0.7063s	
14324/28500 (epoch 25.130), train_loss = 0.90649723, grad/param norm = 1.8994e-01, time/batch = 0.6981s	
14325/28500 (epoch 25.132), train_loss = 0.97686682, grad/param norm = 1.8138e-01, time/batch = 0.6986s	
14326/28500 (epoch 25.133), train_loss = 1.04583583, grad/param norm = 1.9170e-01, time/batch = 0.6943s	
14327/28500 (epoch 25.135), train_loss = 0.92780600, grad/param norm = 1.5573e-01, time/batch = 0.6975s	
14328/28500 (epoch 25.137), train_loss = 0.96817726, grad/param norm = 1.5127e-01, time/batch = 0.6932s	
14329/28500 (epoch 25.139), train_loss = 0.97646058, grad/param norm = 1.5361e-01, time/batch = 0.6933s	
14330/28500 (epoch 25.140), train_loss = 0.99379006, grad/param norm = 1.6597e-01, time/batch = 0.6936s	
14331/28500 (epoch 25.142), train_loss = 0.95357925, grad/param norm = 1.7373e-01, time/batch = 0.6997s	
14332/28500 (epoch 25.144), train_loss = 0.89503587, grad/param norm = 1.5454e-01, time/batch = 0.6998s	
14333/28500 (epoch 25.146), train_loss = 0.94299857, grad/param norm = 1.5520e-01, time/batch = 0.6983s	
14334/28500 (epoch 25.147), train_loss = 0.83174206, grad/param norm = 1.4978e-01, time/batch = 0.7042s	
14335/28500 (epoch 25.149), train_loss = 0.84398208, grad/param norm = 1.5942e-01, time/batch = 0.6950s	
14336/28500 (epoch 25.151), train_loss = 0.92326700, grad/param norm = 1.5705e-01, time/batch = 0.7027s	
14337/28500 (epoch 25.153), train_loss = 0.98487295, grad/param norm = 1.7532e-01, time/batch = 0.6983s	
14338/28500 (epoch 25.154), train_loss = 0.87046740, grad/param norm = 1.6268e-01, time/batch = 0.7147s	
14339/28500 (epoch 25.156), train_loss = 1.06146991, grad/param norm = 1.8082e-01, time/batch = 0.6975s	
14340/28500 (epoch 25.158), train_loss = 0.98826105, grad/param norm = 1.5811e-01, time/batch = 0.7095s	
14341/28500 (epoch 25.160), train_loss = 0.87925103, grad/param norm = 1.4776e-01, time/batch = 0.6981s	
14342/28500 (epoch 25.161), train_loss = 0.92672832, grad/param norm = 2.0754e-01, time/batch = 0.6945s	
14343/28500 (epoch 25.163), train_loss = 0.84613734, grad/param norm = 1.6987e-01, time/batch = 0.6913s	
14344/28500 (epoch 25.165), train_loss = 1.16025269, grad/param norm = 1.7371e-01, time/batch = 0.6937s	
14345/28500 (epoch 25.167), train_loss = 1.15558290, grad/param norm = 1.8223e-01, time/batch = 0.6930s	
14346/28500 (epoch 25.168), train_loss = 1.08079095, grad/param norm = 1.8409e-01, time/batch = 0.6938s	
14347/28500 (epoch 25.170), train_loss = 1.05307201, grad/param norm = 1.9890e-01, time/batch = 0.6921s	
14348/28500 (epoch 25.172), train_loss = 0.97112548, grad/param norm = 1.6684e-01, time/batch = 0.6904s	
14349/28500 (epoch 25.174), train_loss = 1.13432170, grad/param norm = 1.9443e-01, time/batch = 0.6913s	
14350/28500 (epoch 25.175), train_loss = 0.95336073, grad/param norm = 1.7034e-01, time/batch = 0.6898s	
14351/28500 (epoch 25.177), train_loss = 1.02220360, grad/param norm = 1.7736e-01, time/batch = 0.6908s	
14352/28500 (epoch 25.179), train_loss = 1.01363397, grad/param norm = 1.9097e-01, time/batch = 0.6901s	
14353/28500 (epoch 25.181), train_loss = 1.02589324, grad/param norm = 1.6428e-01, time/batch = 0.6894s	
14354/28500 (epoch 25.182), train_loss = 0.93658253, grad/param norm = 1.5058e-01, time/batch = 0.6886s	
14355/28500 (epoch 25.184), train_loss = 1.12998433, grad/param norm = 1.9690e-01, time/batch = 0.6883s	
14356/28500 (epoch 25.186), train_loss = 1.09315026, grad/param norm = 1.6682e-01, time/batch = 0.6878s	
14357/28500 (epoch 25.188), train_loss = 1.00142348, grad/param norm = 1.6975e-01, time/batch = 0.6880s	
14358/28500 (epoch 25.189), train_loss = 0.97058253, grad/param norm = 1.5610e-01, time/batch = 0.6884s	
14359/28500 (epoch 25.191), train_loss = 1.21188439, grad/param norm = 1.9654e-01, time/batch = 0.6888s	
14360/28500 (epoch 25.193), train_loss = 1.02370715, grad/param norm = 1.8138e-01, time/batch = 0.6891s	
14361/28500 (epoch 25.195), train_loss = 1.12731503, grad/param norm = 1.9536e-01, time/batch = 0.6903s	
14362/28500 (epoch 25.196), train_loss = 1.02326171, grad/param norm = 1.7599e-01, time/batch = 0.6896s	
14363/28500 (epoch 25.198), train_loss = 1.00161610, grad/param norm = 1.7545e-01, time/batch = 0.6894s	
14364/28500 (epoch 25.200), train_loss = 1.03412385, grad/param norm = 1.6578e-01, time/batch = 0.6888s	
14365/28500 (epoch 25.202), train_loss = 1.00468678, grad/param norm = 1.5822e-01, time/batch = 0.6902s	
14366/28500 (epoch 25.204), train_loss = 0.94772916, grad/param norm = 1.5494e-01, time/batch = 0.6957s	
14367/28500 (epoch 25.205), train_loss = 0.93943495, grad/param norm = 1.7062e-01, time/batch = 0.6896s	
14368/28500 (epoch 25.207), train_loss = 0.89236898, grad/param norm = 1.9361e-01, time/batch = 0.6896s	
14369/28500 (epoch 25.209), train_loss = 1.00231026, grad/param norm = 1.5854e-01, time/batch = 0.6891s	
14370/28500 (epoch 25.211), train_loss = 0.85464945, grad/param norm = 1.7753e-01, time/batch = 0.6884s	
14371/28500 (epoch 25.212), train_loss = 0.83451362, grad/param norm = 1.6193e-01, time/batch = 0.6909s	
14372/28500 (epoch 25.214), train_loss = 0.95792961, grad/param norm = 1.7332e-01, time/batch = 0.6914s	
14373/28500 (epoch 25.216), train_loss = 0.89590574, grad/param norm = 1.6068e-01, time/batch = 0.6927s	
14374/28500 (epoch 25.218), train_loss = 1.07905396, grad/param norm = 1.6178e-01, time/batch = 0.6934s	
14375/28500 (epoch 25.219), train_loss = 1.00454331, grad/param norm = 1.6871e-01, time/batch = 0.6973s	
14376/28500 (epoch 25.221), train_loss = 0.85714264, grad/param norm = 1.7378e-01, time/batch = 0.6915s	
14377/28500 (epoch 25.223), train_loss = 1.09254570, grad/param norm = 1.8602e-01, time/batch = 0.6926s	
14378/28500 (epoch 25.225), train_loss = 1.10882438, grad/param norm = 1.8164e-01, time/batch = 0.6930s	
14379/28500 (epoch 25.226), train_loss = 0.93118415, grad/param norm = 1.6123e-01, time/batch = 0.6919s	
14380/28500 (epoch 25.228), train_loss = 1.07660408, grad/param norm = 1.6196e-01, time/batch = 0.6924s	
14381/28500 (epoch 25.230), train_loss = 1.06061783, grad/param norm = 1.7671e-01, time/batch = 0.6954s	
14382/28500 (epoch 25.232), train_loss = 1.02803164, grad/param norm = 1.6824e-01, time/batch = 0.6919s	
14383/28500 (epoch 25.233), train_loss = 1.01428959, grad/param norm = 2.0907e-01, time/batch = 0.6901s	
14384/28500 (epoch 25.235), train_loss = 0.95479011, grad/param norm = 1.5482e-01, time/batch = 0.6887s	
14385/28500 (epoch 25.237), train_loss = 0.87156470, grad/param norm = 1.5718e-01, time/batch = 0.6888s	
14386/28500 (epoch 25.239), train_loss = 0.92288021, grad/param norm = 1.4525e-01, time/batch = 0.6893s	
14387/28500 (epoch 25.240), train_loss = 0.85698185, grad/param norm = 1.4943e-01, time/batch = 0.6907s	
14388/28500 (epoch 25.242), train_loss = 0.98923029, grad/param norm = 1.8023e-01, time/batch = 0.6912s	
14389/28500 (epoch 25.244), train_loss = 1.00479898, grad/param norm = 1.4517e-01, time/batch = 0.6905s	
14390/28500 (epoch 25.246), train_loss = 1.05600205, grad/param norm = 1.7783e-01, time/batch = 0.6903s	
14391/28500 (epoch 25.247), train_loss = 1.13011085, grad/param norm = 1.8960e-01, time/batch = 0.6937s	
14392/28500 (epoch 25.249), train_loss = 0.98812136, grad/param norm = 1.6859e-01, time/batch = 0.6899s	
14393/28500 (epoch 25.251), train_loss = 0.93134622, grad/param norm = 1.5658e-01, time/batch = 0.6881s	
14394/28500 (epoch 25.253), train_loss = 1.08945976, grad/param norm = 1.7580e-01, time/batch = 0.6885s	
14395/28500 (epoch 25.254), train_loss = 1.12437942, grad/param norm = 1.6291e-01, time/batch = 0.6889s	
14396/28500 (epoch 25.256), train_loss = 0.92392978, grad/param norm = 1.6670e-01, time/batch = 0.6925s	
14397/28500 (epoch 25.258), train_loss = 0.95271888, grad/param norm = 1.7172e-01, time/batch = 0.6973s	
14398/28500 (epoch 25.260), train_loss = 0.92892160, grad/param norm = 1.5403e-01, time/batch = 0.7057s	
14399/28500 (epoch 25.261), train_loss = 0.89050835, grad/param norm = 1.5799e-01, time/batch = 0.7071s	
14400/28500 (epoch 25.263), train_loss = 1.06664809, grad/param norm = 1.8470e-01, time/batch = 0.6954s	
14401/28500 (epoch 25.265), train_loss = 0.96732577, grad/param norm = 1.6784e-01, time/batch = 0.6929s	
14402/28500 (epoch 25.267), train_loss = 1.12109874, grad/param norm = 2.0383e-01, time/batch = 0.6972s	
14403/28500 (epoch 25.268), train_loss = 1.02478203, grad/param norm = 1.5383e-01, time/batch = 0.6936s	
14404/28500 (epoch 25.270), train_loss = 1.00630765, grad/param norm = 1.7489e-01, time/batch = 0.6936s	
14405/28500 (epoch 25.272), train_loss = 0.96541900, grad/param norm = 1.6230e-01, time/batch = 0.7002s	
14406/28500 (epoch 25.274), train_loss = 1.07364430, grad/param norm = 1.7251e-01, time/batch = 0.7062s	
14407/28500 (epoch 25.275), train_loss = 1.02576124, grad/param norm = 1.5862e-01, time/batch = 0.7006s	
14408/28500 (epoch 25.277), train_loss = 0.98595238, grad/param norm = 1.5936e-01, time/batch = 0.6930s	
14409/28500 (epoch 25.279), train_loss = 0.99992770, grad/param norm = 1.6801e-01, time/batch = 0.6904s	
14410/28500 (epoch 25.281), train_loss = 1.07770944, grad/param norm = 1.9670e-01, time/batch = 0.6881s	
14411/28500 (epoch 25.282), train_loss = 0.92985448, grad/param norm = 1.4604e-01, time/batch = 0.6906s	
14412/28500 (epoch 25.284), train_loss = 0.99805100, grad/param norm = 2.0146e-01, time/batch = 0.6891s	
14413/28500 (epoch 25.286), train_loss = 1.12154432, grad/param norm = 1.7675e-01, time/batch = 0.6883s	
14414/28500 (epoch 25.288), train_loss = 1.01108999, grad/param norm = 1.7862e-01, time/batch = 0.6887s	
14415/28500 (epoch 25.289), train_loss = 1.02061331, grad/param norm = 1.8872e-01, time/batch = 0.6884s	
14416/28500 (epoch 25.291), train_loss = 1.02313965, grad/param norm = 1.7512e-01, time/batch = 0.6897s	
14417/28500 (epoch 25.293), train_loss = 0.96620767, grad/param norm = 1.4960e-01, time/batch = 0.6904s	
14418/28500 (epoch 25.295), train_loss = 0.86663717, grad/param norm = 1.5085e-01, time/batch = 0.6918s	
14419/28500 (epoch 25.296), train_loss = 0.85752981, grad/param norm = 1.5594e-01, time/batch = 0.6908s	
14420/28500 (epoch 25.298), train_loss = 1.04054377, grad/param norm = 1.6070e-01, time/batch = 0.7081s	
14421/28500 (epoch 25.300), train_loss = 0.89996474, grad/param norm = 1.6814e-01, time/batch = 0.7112s	
14422/28500 (epoch 25.302), train_loss = 0.87162152, grad/param norm = 1.5663e-01, time/batch = 0.6978s	
14423/28500 (epoch 25.304), train_loss = 0.94121549, grad/param norm = 1.6152e-01, time/batch = 0.6897s	
14424/28500 (epoch 25.305), train_loss = 1.01481724, grad/param norm = 1.6896e-01, time/batch = 0.7021s	
14425/28500 (epoch 25.307), train_loss = 0.96741463, grad/param norm = 1.7336e-01, time/batch = 0.6891s	
14426/28500 (epoch 25.309), train_loss = 0.98193644, grad/param norm = 1.6679e-01, time/batch = 0.6918s	
14427/28500 (epoch 25.311), train_loss = 1.02739797, grad/param norm = 1.4799e-01, time/batch = 0.7078s	
14428/28500 (epoch 25.312), train_loss = 0.99773230, grad/param norm = 1.6508e-01, time/batch = 0.6887s	
14429/28500 (epoch 25.314), train_loss = 1.05005867, grad/param norm = 1.9647e-01, time/batch = 0.6908s	
14430/28500 (epoch 25.316), train_loss = 0.98426893, grad/param norm = 1.6974e-01, time/batch = 0.6904s	
14431/28500 (epoch 25.318), train_loss = 1.06953421, grad/param norm = 1.6924e-01, time/batch = 0.7086s	
14432/28500 (epoch 25.319), train_loss = 0.95898678, grad/param norm = 1.7084e-01, time/batch = 0.6981s	
14433/28500 (epoch 25.321), train_loss = 0.93177807, grad/param norm = 1.7543e-01, time/batch = 0.6941s	
14434/28500 (epoch 25.323), train_loss = 0.93344634, grad/param norm = 1.7818e-01, time/batch = 0.6937s	
14435/28500 (epoch 25.325), train_loss = 1.12615206, grad/param norm = 1.7575e-01, time/batch = 0.6909s	
14436/28500 (epoch 25.326), train_loss = 1.01438835, grad/param norm = 1.6843e-01, time/batch = 0.6914s	
14437/28500 (epoch 25.328), train_loss = 0.79937799, grad/param norm = 1.5385e-01, time/batch = 0.6915s	
14438/28500 (epoch 25.330), train_loss = 0.90955490, grad/param norm = 1.5649e-01, time/batch = 0.6900s	
14439/28500 (epoch 25.332), train_loss = 0.98267373, grad/param norm = 1.6060e-01, time/batch = 0.6895s	
14440/28500 (epoch 25.333), train_loss = 0.79587948, grad/param norm = 1.5207e-01, time/batch = 0.6876s	
14441/28500 (epoch 25.335), train_loss = 0.86511005, grad/param norm = 1.4666e-01, time/batch = 0.6928s	
14442/28500 (epoch 25.337), train_loss = 0.85331765, grad/param norm = 1.5039e-01, time/batch = 0.7011s	
14443/28500 (epoch 25.339), train_loss = 0.82041276, grad/param norm = 1.4476e-01, time/batch = 0.6935s	
14444/28500 (epoch 25.340), train_loss = 0.98417892, grad/param norm = 2.1336e-01, time/batch = 0.6885s	
14445/28500 (epoch 25.342), train_loss = 0.95167529, grad/param norm = 1.5593e-01, time/batch = 0.6893s	
14446/28500 (epoch 25.344), train_loss = 0.90052678, grad/param norm = 1.7673e-01, time/batch = 0.6888s	
14447/28500 (epoch 25.346), train_loss = 0.79404818, grad/param norm = 1.5076e-01, time/batch = 0.6888s	
14448/28500 (epoch 25.347), train_loss = 0.96091275, grad/param norm = 1.6228e-01, time/batch = 0.6937s	
14449/28500 (epoch 25.349), train_loss = 0.94373328, grad/param norm = 1.5517e-01, time/batch = 0.6935s	
14450/28500 (epoch 25.351), train_loss = 0.89006895, grad/param norm = 1.5520e-01, time/batch = 0.6924s	
14451/28500 (epoch 25.353), train_loss = 0.98980127, grad/param norm = 1.7799e-01, time/batch = 0.6934s	
14452/28500 (epoch 25.354), train_loss = 0.88132209, grad/param norm = 1.5575e-01, time/batch = 0.7058s	
14453/28500 (epoch 25.356), train_loss = 0.89084127, grad/param norm = 1.4299e-01, time/batch = 0.7049s	
14454/28500 (epoch 25.358), train_loss = 0.99769859, grad/param norm = 1.6546e-01, time/batch = 0.6960s	
14455/28500 (epoch 25.360), train_loss = 0.99629227, grad/param norm = 1.7191e-01, time/batch = 0.6930s	
14456/28500 (epoch 25.361), train_loss = 0.88798695, grad/param norm = 1.4538e-01, time/batch = 0.6919s	
14457/28500 (epoch 25.363), train_loss = 0.86274739, grad/param norm = 1.4131e-01, time/batch = 0.6928s	
14458/28500 (epoch 25.365), train_loss = 0.93873511, grad/param norm = 1.7339e-01, time/batch = 0.6912s	
14459/28500 (epoch 25.367), train_loss = 0.97620803, grad/param norm = 1.6718e-01, time/batch = 0.7048s	
14460/28500 (epoch 25.368), train_loss = 0.91514882, grad/param norm = 1.5266e-01, time/batch = 0.6908s	
14461/28500 (epoch 25.370), train_loss = 0.95295890, grad/param norm = 1.6097e-01, time/batch = 0.6965s	
14462/28500 (epoch 25.372), train_loss = 0.80654649, grad/param norm = 1.4770e-01, time/batch = 0.6920s	
14463/28500 (epoch 25.374), train_loss = 0.92625990, grad/param norm = 1.6552e-01, time/batch = 0.6930s	
14464/28500 (epoch 25.375), train_loss = 1.07178862, grad/param norm = 1.6344e-01, time/batch = 0.6924s	
14465/28500 (epoch 25.377), train_loss = 0.82954452, grad/param norm = 1.7599e-01, time/batch = 0.6924s	
14466/28500 (epoch 25.379), train_loss = 0.75056627, grad/param norm = 1.5263e-01, time/batch = 0.6936s	
14467/28500 (epoch 25.381), train_loss = 0.94079805, grad/param norm = 1.7004e-01, time/batch = 0.6927s	
14468/28500 (epoch 25.382), train_loss = 0.90524157, grad/param norm = 1.8463e-01, time/batch = 0.6937s	
14469/28500 (epoch 25.384), train_loss = 0.81307374, grad/param norm = 1.4792e-01, time/batch = 0.6930s	
14470/28500 (epoch 25.386), train_loss = 0.85555086, grad/param norm = 1.5972e-01, time/batch = 0.6941s	
14471/28500 (epoch 25.388), train_loss = 1.04492594, grad/param norm = 1.6489e-01, time/batch = 0.6941s	
14472/28500 (epoch 25.389), train_loss = 0.90923494, grad/param norm = 1.9048e-01, time/batch = 0.6928s	
14473/28500 (epoch 25.391), train_loss = 0.85279595, grad/param norm = 1.6106e-01, time/batch = 0.6927s	
14474/28500 (epoch 25.393), train_loss = 0.88065396, grad/param norm = 1.7304e-01, time/batch = 0.6912s	
14475/28500 (epoch 25.395), train_loss = 1.08974757, grad/param norm = 1.6726e-01, time/batch = 0.6934s	
14476/28500 (epoch 25.396), train_loss = 1.03058513, grad/param norm = 1.7931e-01, time/batch = 0.6943s	
14477/28500 (epoch 25.398), train_loss = 0.73215573, grad/param norm = 1.7002e-01, time/batch = 0.6927s	
14478/28500 (epoch 25.400), train_loss = 0.93247328, grad/param norm = 1.7681e-01, time/batch = 0.6927s	
14479/28500 (epoch 25.402), train_loss = 0.97328984, grad/param norm = 2.1102e-01, time/batch = 0.6909s	
14480/28500 (epoch 25.404), train_loss = 1.02021156, grad/param norm = 1.9459e-01, time/batch = 0.6925s	
14481/28500 (epoch 25.405), train_loss = 1.01658144, grad/param norm = 1.5530e-01, time/batch = 0.6938s	
14482/28500 (epoch 25.407), train_loss = 1.00802277, grad/param norm = 1.7332e-01, time/batch = 0.6933s	
14483/28500 (epoch 25.409), train_loss = 1.00445625, grad/param norm = 1.6686e-01, time/batch = 0.6927s	
14484/28500 (epoch 25.411), train_loss = 1.03634805, grad/param norm = 1.6973e-01, time/batch = 0.6914s	
14485/28500 (epoch 25.412), train_loss = 1.07602873, grad/param norm = 1.9668e-01, time/batch = 0.6928s	
14486/28500 (epoch 25.414), train_loss = 0.98336488, grad/param norm = 1.7535e-01, time/batch = 0.6908s	
14487/28500 (epoch 25.416), train_loss = 0.88399821, grad/param norm = 1.5846e-01, time/batch = 0.6919s	
14488/28500 (epoch 25.418), train_loss = 0.99034207, grad/param norm = 1.5915e-01, time/batch = 0.6916s	
14489/28500 (epoch 25.419), train_loss = 1.09130684, grad/param norm = 2.1716e-01, time/batch = 0.6886s	
14490/28500 (epoch 25.421), train_loss = 1.04384737, grad/param norm = 1.7284e-01, time/batch = 0.6883s	
14491/28500 (epoch 25.423), train_loss = 1.09741243, grad/param norm = 2.1899e-01, time/batch = 0.6906s	
14492/28500 (epoch 25.425), train_loss = 0.99918209, grad/param norm = 2.0114e-01, time/batch = 0.6906s	
14493/28500 (epoch 25.426), train_loss = 0.96476441, grad/param norm = 1.6962e-01, time/batch = 0.6917s	
14494/28500 (epoch 25.428), train_loss = 1.12015825, grad/param norm = 1.9003e-01, time/batch = 0.6893s	
14495/28500 (epoch 25.430), train_loss = 1.08699369, grad/param norm = 1.5858e-01, time/batch = 0.6910s	
14496/28500 (epoch 25.432), train_loss = 0.98731324, grad/param norm = 1.8434e-01, time/batch = 0.6900s	
14497/28500 (epoch 25.433), train_loss = 1.03209454, grad/param norm = 1.7941e-01, time/batch = 0.6888s	
14498/28500 (epoch 25.435), train_loss = 1.00238295, grad/param norm = 1.7842e-01, time/batch = 0.6886s	
14499/28500 (epoch 25.437), train_loss = 0.90508714, grad/param norm = 1.5739e-01, time/batch = 0.6882s	
14500/28500 (epoch 25.439), train_loss = 0.92218308, grad/param norm = 1.4274e-01, time/batch = 0.6884s	
14501/28500 (epoch 25.440), train_loss = 1.16568830, grad/param norm = 1.8889e-01, time/batch = 0.6917s	
14502/28500 (epoch 25.442), train_loss = 0.91619231, grad/param norm = 1.8027e-01, time/batch = 0.6887s	
14503/28500 (epoch 25.444), train_loss = 0.84874953, grad/param norm = 1.5656e-01, time/batch = 0.6888s	
14504/28500 (epoch 25.446), train_loss = 0.82733951, grad/param norm = 1.6135e-01, time/batch = 0.6948s	
14505/28500 (epoch 25.447), train_loss = 0.82869194, grad/param norm = 1.5439e-01, time/batch = 0.6961s	
14506/28500 (epoch 25.449), train_loss = 0.89350813, grad/param norm = 1.4448e-01, time/batch = 0.7028s	
14507/28500 (epoch 25.451), train_loss = 0.96219527, grad/param norm = 1.5291e-01, time/batch = 0.6959s	
14508/28500 (epoch 25.453), train_loss = 0.93865286, grad/param norm = 1.6067e-01, time/batch = 0.6929s	
14509/28500 (epoch 25.454), train_loss = 0.91768489, grad/param norm = 1.4756e-01, time/batch = 0.6911s	
14510/28500 (epoch 25.456), train_loss = 1.02586931, grad/param norm = 2.0155e-01, time/batch = 0.6937s	
14511/28500 (epoch 25.458), train_loss = 0.93032216, grad/param norm = 1.7951e-01, time/batch = 0.6939s	
14512/28500 (epoch 25.460), train_loss = 1.02661875, grad/param norm = 1.6615e-01, time/batch = 0.6955s	
14513/28500 (epoch 25.461), train_loss = 0.88494178, grad/param norm = 1.6672e-01, time/batch = 0.6943s	
14514/28500 (epoch 25.463), train_loss = 0.81251137, grad/param norm = 1.4630e-01, time/batch = 0.6922s	
14515/28500 (epoch 25.465), train_loss = 0.82355798, grad/param norm = 1.6555e-01, time/batch = 0.6926s	
14516/28500 (epoch 25.467), train_loss = 0.96971711, grad/param norm = 1.6803e-01, time/batch = 0.6922s	
14517/28500 (epoch 25.468), train_loss = 0.87746222, grad/param norm = 1.5272e-01, time/batch = 0.6922s	
14518/28500 (epoch 25.470), train_loss = 0.90433120, grad/param norm = 1.5549e-01, time/batch = 0.6925s	
14519/28500 (epoch 25.472), train_loss = 0.89274243, grad/param norm = 1.5949e-01, time/batch = 0.6908s	
14520/28500 (epoch 25.474), train_loss = 1.09948616, grad/param norm = 1.8468e-01, time/batch = 0.6929s	
14521/28500 (epoch 25.475), train_loss = 0.87522981, grad/param norm = 1.6854e-01, time/batch = 0.6938s	
14522/28500 (epoch 25.477), train_loss = 0.91905283, grad/param norm = 1.6287e-01, time/batch = 0.6945s	
14523/28500 (epoch 25.479), train_loss = 0.99889393, grad/param norm = 1.6334e-01, time/batch = 0.6945s	
14524/28500 (epoch 25.481), train_loss = 0.99020475, grad/param norm = 1.8136e-01, time/batch = 0.6930s	
14525/28500 (epoch 25.482), train_loss = 0.84756411, grad/param norm = 1.4355e-01, time/batch = 0.6933s	
14526/28500 (epoch 25.484), train_loss = 0.87164614, grad/param norm = 1.6551e-01, time/batch = 0.6952s	
14527/28500 (epoch 25.486), train_loss = 0.78680679, grad/param norm = 1.8377e-01, time/batch = 0.7168s	
14528/28500 (epoch 25.488), train_loss = 0.98732978, grad/param norm = 1.5400e-01, time/batch = 0.7040s	
14529/28500 (epoch 25.489), train_loss = 1.06223533, grad/param norm = 1.6035e-01, time/batch = 0.6978s	
14530/28500 (epoch 25.491), train_loss = 0.91827104, grad/param norm = 1.5836e-01, time/batch = 0.6989s	
14531/28500 (epoch 25.493), train_loss = 0.94028846, grad/param norm = 1.5508e-01, time/batch = 0.7011s	
14532/28500 (epoch 25.495), train_loss = 0.96136262, grad/param norm = 1.5759e-01, time/batch = 0.6973s	
14533/28500 (epoch 25.496), train_loss = 0.85493787, grad/param norm = 1.7054e-01, time/batch = 0.6949s	
14534/28500 (epoch 25.498), train_loss = 0.93570446, grad/param norm = 1.5438e-01, time/batch = 0.7051s	
14535/28500 (epoch 25.500), train_loss = 0.88972200, grad/param norm = 1.5249e-01, time/batch = 0.6928s	
14536/28500 (epoch 25.502), train_loss = 1.02962091, grad/param norm = 1.6268e-01, time/batch = 0.6958s	
14537/28500 (epoch 25.504), train_loss = 0.98116502, grad/param norm = 1.5754e-01, time/batch = 0.6937s	
14538/28500 (epoch 25.505), train_loss = 0.88309317, grad/param norm = 1.5607e-01, time/batch = 0.6944s	
14539/28500 (epoch 25.507), train_loss = 1.05243476, grad/param norm = 2.2679e-01, time/batch = 0.6946s	
14540/28500 (epoch 25.509), train_loss = 0.95008496, grad/param norm = 1.7105e-01, time/batch = 0.6909s	
14541/28500 (epoch 25.511), train_loss = 0.95809884, grad/param norm = 1.6517e-01, time/batch = 0.6951s	
14542/28500 (epoch 25.512), train_loss = 0.99604196, grad/param norm = 1.6244e-01, time/batch = 0.6918s	
14543/28500 (epoch 25.514), train_loss = 0.93065026, grad/param norm = 1.5826e-01, time/batch = 0.6944s	
14544/28500 (epoch 25.516), train_loss = 0.91752612, grad/param norm = 1.4738e-01, time/batch = 0.6945s	
14545/28500 (epoch 25.518), train_loss = 0.99311393, grad/param norm = 1.5759e-01, time/batch = 0.6966s	
14546/28500 (epoch 25.519), train_loss = 1.02831814, grad/param norm = 1.5768e-01, time/batch = 0.6950s	
14547/28500 (epoch 25.521), train_loss = 1.09736952, grad/param norm = 1.7317e-01, time/batch = 0.6888s	
14548/28500 (epoch 25.523), train_loss = 0.99665702, grad/param norm = 1.7042e-01, time/batch = 0.6923s	
14549/28500 (epoch 25.525), train_loss = 1.06015509, grad/param norm = 1.8458e-01, time/batch = 0.6945s	
14550/28500 (epoch 25.526), train_loss = 1.02613181, grad/param norm = 1.6078e-01, time/batch = 0.6920s	
14551/28500 (epoch 25.528), train_loss = 1.03804482, grad/param norm = 2.3148e-01, time/batch = 0.6937s	
14552/28500 (epoch 25.530), train_loss = 1.04302316, grad/param norm = 1.5643e-01, time/batch = 0.6900s	
14553/28500 (epoch 25.532), train_loss = 0.94249754, grad/param norm = 1.5582e-01, time/batch = 0.6891s	
14554/28500 (epoch 25.533), train_loss = 1.02591620, grad/param norm = 1.7685e-01, time/batch = 0.6898s	
14555/28500 (epoch 25.535), train_loss = 0.82933633, grad/param norm = 1.4634e-01, time/batch = 0.6936s	
14556/28500 (epoch 25.537), train_loss = 0.84559423, grad/param norm = 1.4975e-01, time/batch = 0.6893s	
14557/28500 (epoch 25.539), train_loss = 0.81092367, grad/param norm = 1.5774e-01, time/batch = 0.6902s	
14558/28500 (epoch 25.540), train_loss = 0.97486073, grad/param norm = 1.6750e-01, time/batch = 0.6894s	
14559/28500 (epoch 25.542), train_loss = 1.02333448, grad/param norm = 2.2943e-01, time/batch = 0.6883s	
14560/28500 (epoch 25.544), train_loss = 1.10700330, grad/param norm = 1.7639e-01, time/batch = 0.6887s	
14561/28500 (epoch 25.546), train_loss = 0.94843953, grad/param norm = 1.5803e-01, time/batch = 0.6907s	
14562/28500 (epoch 25.547), train_loss = 0.97408253, grad/param norm = 1.5422e-01, time/batch = 0.6893s	
14563/28500 (epoch 25.549), train_loss = 0.79336981, grad/param norm = 1.2955e-01, time/batch = 0.6901s	
14564/28500 (epoch 25.551), train_loss = 0.94231856, grad/param norm = 2.0097e-01, time/batch = 0.6890s	
14565/28500 (epoch 25.553), train_loss = 1.14534633, grad/param norm = 1.9061e-01, time/batch = 0.6921s	
14566/28500 (epoch 25.554), train_loss = 0.99807050, grad/param norm = 1.7024e-01, time/batch = 0.6914s	
14567/28500 (epoch 25.556), train_loss = 0.99578931, grad/param norm = 1.7858e-01, time/batch = 0.6927s	
14568/28500 (epoch 25.558), train_loss = 1.01508776, grad/param norm = 1.7094e-01, time/batch = 0.6934s	
14569/28500 (epoch 25.560), train_loss = 0.98251967, grad/param norm = 1.6477e-01, time/batch = 0.6930s	
14570/28500 (epoch 25.561), train_loss = 1.05431736, grad/param norm = 1.7092e-01, time/batch = 0.6937s	
14571/28500 (epoch 25.563), train_loss = 1.10065139, grad/param norm = 1.9175e-01, time/batch = 0.6935s	
14572/28500 (epoch 25.565), train_loss = 0.91953007, grad/param norm = 1.6372e-01, time/batch = 0.6937s	
14573/28500 (epoch 25.567), train_loss = 0.85355333, grad/param norm = 1.5466e-01, time/batch = 0.6923s	
14574/28500 (epoch 25.568), train_loss = 0.99953010, grad/param norm = 1.8807e-01, time/batch = 0.6923s	
14575/28500 (epoch 25.570), train_loss = 0.93438476, grad/param norm = 1.5514e-01, time/batch = 0.6931s	
14576/28500 (epoch 25.572), train_loss = 0.93051225, grad/param norm = 1.6597e-01, time/batch = 0.6915s	
14577/28500 (epoch 25.574), train_loss = 0.93734639, grad/param norm = 1.6914e-01, time/batch = 0.6929s	
14578/28500 (epoch 25.575), train_loss = 0.94435456, grad/param norm = 1.8566e-01, time/batch = 0.6939s	
14579/28500 (epoch 25.577), train_loss = 0.99696228, grad/param norm = 1.6300e-01, time/batch = 0.6923s	
14580/28500 (epoch 25.579), train_loss = 1.05070508, grad/param norm = 1.6857e-01, time/batch = 0.6936s	
14581/28500 (epoch 25.581), train_loss = 0.87583322, grad/param norm = 1.6244e-01, time/batch = 0.6942s	
14582/28500 (epoch 25.582), train_loss = 1.03996219, grad/param norm = 1.6066e-01, time/batch = 0.6944s	
14583/28500 (epoch 25.584), train_loss = 0.91428781, grad/param norm = 1.7818e-01, time/batch = 0.6948s	
14584/28500 (epoch 25.586), train_loss = 0.88098781, grad/param norm = 1.3791e-01, time/batch = 0.6931s	
14585/28500 (epoch 25.588), train_loss = 0.89220985, grad/param norm = 1.6755e-01, time/batch = 0.6932s	
14586/28500 (epoch 25.589), train_loss = 0.97158091, grad/param norm = 1.6952e-01, time/batch = 0.6937s	
14587/28500 (epoch 25.591), train_loss = 0.97753636, grad/param norm = 1.6931e-01, time/batch = 0.6928s	
14588/28500 (epoch 25.593), train_loss = 0.90882507, grad/param norm = 1.7772e-01, time/batch = 0.6924s	
14589/28500 (epoch 25.595), train_loss = 1.15886882, grad/param norm = 1.9713e-01, time/batch = 0.6926s	
14590/28500 (epoch 25.596), train_loss = 1.11349939, grad/param norm = 1.7395e-01, time/batch = 0.6931s	
14591/28500 (epoch 25.598), train_loss = 0.96851185, grad/param norm = 1.6639e-01, time/batch = 0.6985s	
14592/28500 (epoch 25.600), train_loss = 0.98466868, grad/param norm = 1.8725e-01, time/batch = 0.7003s	
14593/28500 (epoch 25.602), train_loss = 1.03984018, grad/param norm = 1.8211e-01, time/batch = 0.6935s	
14594/28500 (epoch 25.604), train_loss = 1.05163657, grad/param norm = 1.6166e-01, time/batch = 0.6934s	
14595/28500 (epoch 25.605), train_loss = 1.02064272, grad/param norm = 1.6710e-01, time/batch = 0.6912s	
14596/28500 (epoch 25.607), train_loss = 1.06242436, grad/param norm = 1.5267e-01, time/batch = 0.6928s	
14597/28500 (epoch 25.609), train_loss = 0.97923850, grad/param norm = 1.6793e-01, time/batch = 0.6948s	
14598/28500 (epoch 25.611), train_loss = 0.92981933, grad/param norm = 1.6780e-01, time/batch = 0.6937s	
14599/28500 (epoch 25.612), train_loss = 1.01321076, grad/param norm = 1.7589e-01, time/batch = 0.6958s	
14600/28500 (epoch 25.614), train_loss = 1.00356644, grad/param norm = 1.7876e-01, time/batch = 0.6950s	
14601/28500 (epoch 25.616), train_loss = 0.92001751, grad/param norm = 1.6942e-01, time/batch = 0.6992s	
14602/28500 (epoch 25.618), train_loss = 0.95678252, grad/param norm = 1.7352e-01, time/batch = 0.6994s	
14603/28500 (epoch 25.619), train_loss = 1.08292235, grad/param norm = 1.8985e-01, time/batch = 0.6933s	
14604/28500 (epoch 25.621), train_loss = 0.80421521, grad/param norm = 1.4887e-01, time/batch = 0.7060s	
14605/28500 (epoch 25.623), train_loss = 1.06535574, grad/param norm = 1.7718e-01, time/batch = 0.6932s	
14606/28500 (epoch 25.625), train_loss = 0.85073770, grad/param norm = 1.4846e-01, time/batch = 0.6963s	
14607/28500 (epoch 25.626), train_loss = 0.75571628, grad/param norm = 1.4517e-01, time/batch = 0.6927s	
14608/28500 (epoch 25.628), train_loss = 0.89065406, grad/param norm = 1.6038e-01, time/batch = 0.6915s	
14609/28500 (epoch 25.630), train_loss = 0.82542556, grad/param norm = 1.3756e-01, time/batch = 0.6932s	
14610/28500 (epoch 25.632), train_loss = 1.05553511, grad/param norm = 1.7032e-01, time/batch = 0.6911s	
14611/28500 (epoch 25.633), train_loss = 1.10808253, grad/param norm = 1.6750e-01, time/batch = 0.6963s	
14612/28500 (epoch 25.635), train_loss = 1.03218740, grad/param norm = 1.9580e-01, time/batch = 0.6936s	
14613/28500 (epoch 25.637), train_loss = 0.98614340, grad/param norm = 1.6573e-01, time/batch = 0.6986s	
14614/28500 (epoch 25.639), train_loss = 0.87792933, grad/param norm = 1.6982e-01, time/batch = 0.6925s	
14615/28500 (epoch 25.640), train_loss = 0.90185144, grad/param norm = 1.6904e-01, time/batch = 0.6942s	
14616/28500 (epoch 25.642), train_loss = 0.90866292, grad/param norm = 1.5422e-01, time/batch = 0.6957s	
14617/28500 (epoch 25.644), train_loss = 1.04301487, grad/param norm = 1.6538e-01, time/batch = 0.6997s	
14618/28500 (epoch 25.646), train_loss = 0.82998578, grad/param norm = 1.3628e-01, time/batch = 0.7007s	
14619/28500 (epoch 25.647), train_loss = 0.86666502, grad/param norm = 1.5230e-01, time/batch = 0.7080s	
14620/28500 (epoch 25.649), train_loss = 0.82055906, grad/param norm = 1.5216e-01, time/batch = 0.6972s	
14621/28500 (epoch 25.651), train_loss = 0.84220676, grad/param norm = 1.4145e-01, time/batch = 0.7148s	
14622/28500 (epoch 25.653), train_loss = 0.82069946, grad/param norm = 1.4226e-01, time/batch = 0.7113s	
14623/28500 (epoch 25.654), train_loss = 0.90131431, grad/param norm = 1.6556e-01, time/batch = 0.6990s	
14624/28500 (epoch 25.656), train_loss = 0.86548038, grad/param norm = 1.6596e-01, time/batch = 0.6922s	
14625/28500 (epoch 25.658), train_loss = 0.92934426, grad/param norm = 1.5914e-01, time/batch = 0.6929s	
14626/28500 (epoch 25.660), train_loss = 0.96199983, grad/param norm = 1.6566e-01, time/batch = 0.6963s	
14627/28500 (epoch 25.661), train_loss = 1.09467215, grad/param norm = 1.9421e-01, time/batch = 0.6971s	
14628/28500 (epoch 25.663), train_loss = 1.07115573, grad/param norm = 1.6789e-01, time/batch = 0.7023s	
14629/28500 (epoch 25.665), train_loss = 0.93865827, grad/param norm = 1.5930e-01, time/batch = 0.6920s	
14630/28500 (epoch 25.667), train_loss = 0.94210658, grad/param norm = 1.7676e-01, time/batch = 0.6895s	
14631/28500 (epoch 25.668), train_loss = 0.93905536, grad/param norm = 1.5570e-01, time/batch = 0.6958s	
14632/28500 (epoch 25.670), train_loss = 0.96897385, grad/param norm = 1.7264e-01, time/batch = 0.6984s	
14633/28500 (epoch 25.672), train_loss = 0.88489775, grad/param norm = 1.6948e-01, time/batch = 0.6948s	
14634/28500 (epoch 25.674), train_loss = 0.78763288, grad/param norm = 1.6031e-01, time/batch = 0.6924s	
14635/28500 (epoch 25.675), train_loss = 0.82446757, grad/param norm = 1.4957e-01, time/batch = 0.6898s	
14636/28500 (epoch 25.677), train_loss = 0.91314618, grad/param norm = 1.5135e-01, time/batch = 0.6898s	
14637/28500 (epoch 25.679), train_loss = 0.91033941, grad/param norm = 1.6118e-01, time/batch = 0.6964s	
14638/28500 (epoch 25.681), train_loss = 0.98443606, grad/param norm = 1.6819e-01, time/batch = 0.6926s	
14639/28500 (epoch 25.682), train_loss = 0.90098297, grad/param norm = 1.5371e-01, time/batch = 0.6915s	
14640/28500 (epoch 25.684), train_loss = 0.96764437, grad/param norm = 1.7787e-01, time/batch = 0.6939s	
14641/28500 (epoch 25.686), train_loss = 0.91623120, grad/param norm = 1.6629e-01, time/batch = 0.6966s	
14642/28500 (epoch 25.688), train_loss = 0.85498170, grad/param norm = 1.3869e-01, time/batch = 0.6920s	
14643/28500 (epoch 25.689), train_loss = 0.91276050, grad/param norm = 1.9393e-01, time/batch = 0.6992s	
14644/28500 (epoch 25.691), train_loss = 0.96449016, grad/param norm = 1.6579e-01, time/batch = 0.7033s	
14645/28500 (epoch 25.693), train_loss = 0.89354848, grad/param norm = 1.5572e-01, time/batch = 0.6969s	
14646/28500 (epoch 25.695), train_loss = 0.70208962, grad/param norm = 1.5646e-01, time/batch = 0.6925s	
14647/28500 (epoch 25.696), train_loss = 0.92593096, grad/param norm = 1.6580e-01, time/batch = 0.6937s	
14648/28500 (epoch 25.698), train_loss = 0.94468066, grad/param norm = 1.5251e-01, time/batch = 0.6906s	
14649/28500 (epoch 25.700), train_loss = 0.96004802, grad/param norm = 1.7417e-01, time/batch = 0.6909s	
14650/28500 (epoch 25.702), train_loss = 0.97053769, grad/param norm = 1.8826e-01, time/batch = 0.6895s	
14651/28500 (epoch 25.704), train_loss = 0.96086115, grad/param norm = 1.7003e-01, time/batch = 0.6919s	
14652/28500 (epoch 25.705), train_loss = 1.05607615, grad/param norm = 1.9404e-01, time/batch = 0.6913s	
14653/28500 (epoch 25.707), train_loss = 0.87988561, grad/param norm = 1.7735e-01, time/batch = 0.6899s	
14654/28500 (epoch 25.709), train_loss = 1.07859539, grad/param norm = 1.7711e-01, time/batch = 0.6899s	
14655/28500 (epoch 25.711), train_loss = 0.86902954, grad/param norm = 1.6090e-01, time/batch = 0.6898s	
14656/28500 (epoch 25.712), train_loss = 0.96646834, grad/param norm = 1.7313e-01, time/batch = 0.6903s	
14657/28500 (epoch 25.714), train_loss = 1.07521554, grad/param norm = 1.8198e-01, time/batch = 0.6915s	
14658/28500 (epoch 25.716), train_loss = 0.92975815, grad/param norm = 1.6348e-01, time/batch = 0.6900s	
14659/28500 (epoch 25.718), train_loss = 0.96049861, grad/param norm = 1.5128e-01, time/batch = 0.6898s	
14660/28500 (epoch 25.719), train_loss = 0.96467637, grad/param norm = 1.6156e-01, time/batch = 0.6895s	
14661/28500 (epoch 25.721), train_loss = 0.79267033, grad/param norm = 1.6294e-01, time/batch = 0.6919s	
14662/28500 (epoch 25.723), train_loss = 0.94336949, grad/param norm = 1.6541e-01, time/batch = 0.6973s	
14663/28500 (epoch 25.725), train_loss = 1.01504928, grad/param norm = 1.6463e-01, time/batch = 0.6922s	
14664/28500 (epoch 25.726), train_loss = 0.93007647, grad/param norm = 1.6570e-01, time/batch = 0.6912s	
14665/28500 (epoch 25.728), train_loss = 0.88097200, grad/param norm = 1.6511e-01, time/batch = 0.6903s	
14666/28500 (epoch 25.730), train_loss = 0.95618984, grad/param norm = 1.8200e-01, time/batch = 0.6901s	
14667/28500 (epoch 25.732), train_loss = 0.77701085, grad/param norm = 1.4772e-01, time/batch = 0.6901s	
14668/28500 (epoch 25.733), train_loss = 0.81383003, grad/param norm = 1.5339e-01, time/batch = 0.6921s	
14669/28500 (epoch 25.735), train_loss = 0.81226642, grad/param norm = 1.6011e-01, time/batch = 0.6946s	
14670/28500 (epoch 25.737), train_loss = 0.74307171, grad/param norm = 1.4679e-01, time/batch = 0.6935s	
14671/28500 (epoch 25.739), train_loss = 0.87359331, grad/param norm = 1.6760e-01, time/batch = 0.6947s	
14672/28500 (epoch 25.740), train_loss = 0.93495224, grad/param norm = 1.5292e-01, time/batch = 0.6906s	
14673/28500 (epoch 25.742), train_loss = 0.86846721, grad/param norm = 1.5712e-01, time/batch = 0.6932s	
14674/28500 (epoch 25.744), train_loss = 0.95465517, grad/param norm = 1.8237e-01, time/batch = 0.6909s	
14675/28500 (epoch 25.746), train_loss = 0.88060037, grad/param norm = 1.5932e-01, time/batch = 0.6908s	
14676/28500 (epoch 25.747), train_loss = 0.87184722, grad/param norm = 1.5790e-01, time/batch = 0.6919s	
14677/28500 (epoch 25.749), train_loss = 1.00945870, grad/param norm = 2.1031e-01, time/batch = 0.6997s	
14678/28500 (epoch 25.751), train_loss = 0.85444750, grad/param norm = 2.2265e-01, time/batch = 0.6968s	
14679/28500 (epoch 25.753), train_loss = 0.92171196, grad/param norm = 1.5489e-01, time/batch = 0.6927s	
14680/28500 (epoch 25.754), train_loss = 0.84236107, grad/param norm = 1.5829e-01, time/batch = 0.6918s	
14681/28500 (epoch 25.756), train_loss = 1.04729730, grad/param norm = 1.7190e-01, time/batch = 0.6919s	
14682/28500 (epoch 25.758), train_loss = 0.98849146, grad/param norm = 1.8506e-01, time/batch = 0.6937s	
14683/28500 (epoch 25.760), train_loss = 0.83657046, grad/param norm = 1.7415e-01, time/batch = 0.6922s	
14684/28500 (epoch 25.761), train_loss = 0.88186992, grad/param norm = 1.8108e-01, time/batch = 0.6916s	
14685/28500 (epoch 25.763), train_loss = 0.75736623, grad/param norm = 1.4350e-01, time/batch = 0.6957s	
14686/28500 (epoch 25.765), train_loss = 0.90920228, grad/param norm = 1.4982e-01, time/batch = 0.6958s	
14687/28500 (epoch 25.767), train_loss = 0.79242754, grad/param norm = 1.4627e-01, time/batch = 0.6905s	
14688/28500 (epoch 25.768), train_loss = 0.99829687, grad/param norm = 1.6777e-01, time/batch = 0.6923s	
14689/28500 (epoch 25.770), train_loss = 0.83067898, grad/param norm = 1.6165e-01, time/batch = 0.6936s	
14690/28500 (epoch 25.772), train_loss = 0.73120476, grad/param norm = 1.3951e-01, time/batch = 0.6899s	
14691/28500 (epoch 25.774), train_loss = 0.93807333, grad/param norm = 1.7808e-01, time/batch = 0.6918s	
14692/28500 (epoch 25.775), train_loss = 1.02127094, grad/param norm = 1.6032e-01, time/batch = 0.6908s	
14693/28500 (epoch 25.777), train_loss = 1.01363208, grad/param norm = 1.6919e-01, time/batch = 0.6900s	
14694/28500 (epoch 25.779), train_loss = 0.77383536, grad/param norm = 1.5234e-01, time/batch = 0.6912s	
14695/28500 (epoch 25.781), train_loss = 0.92698037, grad/param norm = 1.7162e-01, time/batch = 0.6956s	
14696/28500 (epoch 25.782), train_loss = 0.98535305, grad/param norm = 1.9470e-01, time/batch = 0.6906s	
14697/28500 (epoch 25.784), train_loss = 0.77469575, grad/param norm = 1.6310e-01, time/batch = 0.6912s	
14698/28500 (epoch 25.786), train_loss = 0.81655991, grad/param norm = 1.4182e-01, time/batch = 0.6933s	
14699/28500 (epoch 25.788), train_loss = 0.92301488, grad/param norm = 1.7710e-01, time/batch = 0.6903s	
14700/28500 (epoch 25.789), train_loss = 0.69908574, grad/param norm = 2.3155e-01, time/batch = 0.6899s	
14701/28500 (epoch 25.791), train_loss = 0.97052502, grad/param norm = 1.7428e-01, time/batch = 0.6923s	
14702/28500 (epoch 25.793), train_loss = 0.93652987, grad/param norm = 2.0553e-01, time/batch = 0.6910s	
14703/28500 (epoch 25.795), train_loss = 0.94555929, grad/param norm = 1.5478e-01, time/batch = 0.6905s	
14704/28500 (epoch 25.796), train_loss = 0.84016771, grad/param norm = 1.6825e-01, time/batch = 0.6901s	
14705/28500 (epoch 25.798), train_loss = 0.77638178, grad/param norm = 1.7051e-01, time/batch = 0.6914s	
14706/28500 (epoch 25.800), train_loss = 0.80470630, grad/param norm = 1.7612e-01, time/batch = 0.6904s	
14707/28500 (epoch 25.802), train_loss = 0.91374832, grad/param norm = 2.2690e-01, time/batch = 0.6891s	
14708/28500 (epoch 25.804), train_loss = 0.95270605, grad/param norm = 1.4961e-01, time/batch = 0.6896s	
14709/28500 (epoch 25.805), train_loss = 0.94449729, grad/param norm = 1.7553e-01, time/batch = 0.6899s	
14710/28500 (epoch 25.807), train_loss = 0.95622717, grad/param norm = 1.7071e-01, time/batch = 0.6916s	
14711/28500 (epoch 25.809), train_loss = 0.94125195, grad/param norm = 1.6571e-01, time/batch = 0.6935s	
14712/28500 (epoch 25.811), train_loss = 0.97955457, grad/param norm = 1.8276e-01, time/batch = 0.6942s	
14713/28500 (epoch 25.812), train_loss = 0.95000528, grad/param norm = 1.8080e-01, time/batch = 0.6909s	
14714/28500 (epoch 25.814), train_loss = 0.86851509, grad/param norm = 1.6614e-01, time/batch = 0.6908s	
14715/28500 (epoch 25.816), train_loss = 0.97714905, grad/param norm = 1.8459e-01, time/batch = 0.6919s	
14716/28500 (epoch 25.818), train_loss = 1.05015565, grad/param norm = 1.7809e-01, time/batch = 0.6905s	
14717/28500 (epoch 25.819), train_loss = 0.93618186, grad/param norm = 1.5395e-01, time/batch = 0.6897s	
14718/28500 (epoch 25.821), train_loss = 0.89557498, grad/param norm = 1.4259e-01, time/batch = 0.6900s	
14719/28500 (epoch 25.823), train_loss = 1.05973687, grad/param norm = 1.8699e-01, time/batch = 0.6922s	
14720/28500 (epoch 25.825), train_loss = 0.90693207, grad/param norm = 1.7967e-01, time/batch = 0.6906s	
14721/28500 (epoch 25.826), train_loss = 0.96452161, grad/param norm = 1.9585e-01, time/batch = 0.6932s	
14722/28500 (epoch 25.828), train_loss = 0.84714230, grad/param norm = 2.0073e-01, time/batch = 0.6911s	
14723/28500 (epoch 25.830), train_loss = 0.91493656, grad/param norm = 1.6921e-01, time/batch = 0.6902s	
14724/28500 (epoch 25.832), train_loss = 0.95137793, grad/param norm = 2.0705e-01, time/batch = 0.6910s	
14725/28500 (epoch 25.833), train_loss = 1.02974613, grad/param norm = 1.6137e-01, time/batch = 0.6900s	
14726/28500 (epoch 25.835), train_loss = 0.86738382, grad/param norm = 1.6301e-01, time/batch = 0.6923s	
14727/28500 (epoch 25.837), train_loss = 0.81770455, grad/param norm = 1.6022e-01, time/batch = 0.6921s	
14728/28500 (epoch 25.839), train_loss = 1.07782674, grad/param norm = 2.0826e-01, time/batch = 0.6913s	
14729/28500 (epoch 25.840), train_loss = 1.10372928, grad/param norm = 1.9166e-01, time/batch = 0.6894s	
14730/28500 (epoch 25.842), train_loss = 1.00012774, grad/param norm = 1.8046e-01, time/batch = 0.6895s	
14731/28500 (epoch 25.844), train_loss = 0.97771163, grad/param norm = 1.7806e-01, time/batch = 0.7020s	
14732/28500 (epoch 25.846), train_loss = 1.07286371, grad/param norm = 2.0203e-01, time/batch = 0.7060s	
14733/28500 (epoch 25.847), train_loss = 0.89535563, grad/param norm = 1.6132e-01, time/batch = 0.6966s	
14734/28500 (epoch 25.849), train_loss = 0.90404998, grad/param norm = 1.6382e-01, time/batch = 0.6947s	
14735/28500 (epoch 25.851), train_loss = 0.80693403, grad/param norm = 1.4961e-01, time/batch = 0.6943s	
14736/28500 (epoch 25.853), train_loss = 0.96155063, grad/param norm = 1.9897e-01, time/batch = 0.6900s	
14737/28500 (epoch 25.854), train_loss = 0.95817715, grad/param norm = 1.7386e-01, time/batch = 0.6902s	
14738/28500 (epoch 25.856), train_loss = 1.06442670, grad/param norm = 2.2486e-01, time/batch = 0.7008s	
14739/28500 (epoch 25.858), train_loss = 0.88013977, grad/param norm = 1.6287e-01, time/batch = 0.6897s	
14740/28500 (epoch 25.860), train_loss = 0.90324397, grad/param norm = 1.6717e-01, time/batch = 0.6906s	
14741/28500 (epoch 25.861), train_loss = 0.98042084, grad/param norm = 2.0376e-01, time/batch = 0.6931s	
14742/28500 (epoch 25.863), train_loss = 0.97072930, grad/param norm = 1.8344e-01, time/batch = 0.6916s	
14743/28500 (epoch 25.865), train_loss = 0.87214002, grad/param norm = 1.6622e-01, time/batch = 0.6920s	
14744/28500 (epoch 25.867), train_loss = 1.00889621, grad/param norm = 2.0146e-01, time/batch = 0.6921s	
14745/28500 (epoch 25.868), train_loss = 0.83712583, grad/param norm = 1.6367e-01, time/batch = 0.6905s	
14746/28500 (epoch 25.870), train_loss = 0.80276612, grad/param norm = 1.5142e-01, time/batch = 0.6917s	
14747/28500 (epoch 25.872), train_loss = 0.98078927, grad/param norm = 1.9958e-01, time/batch = 0.6907s	
14748/28500 (epoch 25.874), train_loss = 0.87158362, grad/param norm = 1.8603e-01, time/batch = 0.6909s	
14749/28500 (epoch 25.875), train_loss = 1.05904951, grad/param norm = 1.7306e-01, time/batch = 0.6907s	
14750/28500 (epoch 25.877), train_loss = 0.95054997, grad/param norm = 1.6650e-01, time/batch = 0.6908s	
14751/28500 (epoch 25.879), train_loss = 0.99785475, grad/param norm = 1.4921e-01, time/batch = 0.6930s	
14752/28500 (epoch 25.881), train_loss = 0.95627335, grad/param norm = 1.6261e-01, time/batch = 0.6965s	
14753/28500 (epoch 25.882), train_loss = 0.85323994, grad/param norm = 1.4015e-01, time/batch = 0.6943s	
14754/28500 (epoch 25.884), train_loss = 0.93423100, grad/param norm = 1.5715e-01, time/batch = 0.6940s	
14755/28500 (epoch 25.886), train_loss = 0.90249799, grad/param norm = 1.6592e-01, time/batch = 0.6932s	
14756/28500 (epoch 25.888), train_loss = 0.86719590, grad/param norm = 1.5238e-01, time/batch = 0.6934s	
14757/28500 (epoch 25.889), train_loss = 0.94521020, grad/param norm = 1.5427e-01, time/batch = 0.6942s	
14758/28500 (epoch 25.891), train_loss = 0.91893307, grad/param norm = 1.5434e-01, time/batch = 0.6953s	
14759/28500 (epoch 25.893), train_loss = 0.90435873, grad/param norm = 1.6932e-01, time/batch = 0.6936s	
14760/28500 (epoch 25.895), train_loss = 1.10821554, grad/param norm = 2.0068e-01, time/batch = 0.6940s	
14761/28500 (epoch 25.896), train_loss = 1.02679864, grad/param norm = 1.7891e-01, time/batch = 0.6945s	
14762/28500 (epoch 25.898), train_loss = 0.94805812, grad/param norm = 1.6248e-01, time/batch = 0.6957s	
14763/28500 (epoch 25.900), train_loss = 0.81221946, grad/param norm = 1.6743e-01, time/batch = 0.7076s	
14764/28500 (epoch 25.902), train_loss = 0.82891467, grad/param norm = 1.7838e-01, time/batch = 0.7225s	
14765/28500 (epoch 25.904), train_loss = 0.84549832, grad/param norm = 1.5639e-01, time/batch = 0.7052s	
14766/28500 (epoch 25.905), train_loss = 0.91520683, grad/param norm = 1.7734e-01, time/batch = 0.7019s	
14767/28500 (epoch 25.907), train_loss = 0.91856732, grad/param norm = 1.7356e-01, time/batch = 0.6940s	
14768/28500 (epoch 25.909), train_loss = 0.83886910, grad/param norm = 1.9699e-01, time/batch = 0.6929s	
14769/28500 (epoch 25.911), train_loss = 0.84451607, grad/param norm = 1.5252e-01, time/batch = 0.6925s	
14770/28500 (epoch 25.912), train_loss = 0.74065875, grad/param norm = 1.5226e-01, time/batch = 0.6931s	
14771/28500 (epoch 25.914), train_loss = 0.96168810, grad/param norm = 1.7378e-01, time/batch = 0.6961s	
14772/28500 (epoch 25.916), train_loss = 0.92872975, grad/param norm = 1.6528e-01, time/batch = 0.6997s	
14773/28500 (epoch 25.918), train_loss = 0.91561251, grad/param norm = 1.7362e-01, time/batch = 0.7064s	
14774/28500 (epoch 25.919), train_loss = 0.91913875, grad/param norm = 1.5559e-01, time/batch = 0.7115s	
14775/28500 (epoch 25.921), train_loss = 1.03318418, grad/param norm = 2.0142e-01, time/batch = 0.6980s	
14776/28500 (epoch 25.923), train_loss = 0.88794186, grad/param norm = 2.0192e-01, time/batch = 0.7064s	
14777/28500 (epoch 25.925), train_loss = 0.85616639, grad/param norm = 1.5428e-01, time/batch = 0.7063s	
14778/28500 (epoch 25.926), train_loss = 0.92073472, grad/param norm = 1.6396e-01, time/batch = 0.7127s	
14779/28500 (epoch 25.928), train_loss = 0.89723404, grad/param norm = 1.7740e-01, time/batch = 0.7100s	
14780/28500 (epoch 25.930), train_loss = 0.72834965, grad/param norm = 1.4479e-01, time/batch = 0.6985s	
14781/28500 (epoch 25.932), train_loss = 0.74438274, grad/param norm = 1.3076e-01, time/batch = 0.6981s	
14782/28500 (epoch 25.933), train_loss = 0.99798762, grad/param norm = 1.6980e-01, time/batch = 0.6940s	
14783/28500 (epoch 25.935), train_loss = 1.01206253, grad/param norm = 1.6593e-01, time/batch = 0.6930s	
14784/28500 (epoch 25.937), train_loss = 1.03162053, grad/param norm = 2.0121e-01, time/batch = 0.6945s	
14785/28500 (epoch 25.939), train_loss = 1.09070289, grad/param norm = 1.9386e-01, time/batch = 0.6932s	
14786/28500 (epoch 25.940), train_loss = 0.81548202, grad/param norm = 1.5578e-01, time/batch = 0.6925s	
14787/28500 (epoch 25.942), train_loss = 0.92912365, grad/param norm = 1.6190e-01, time/batch = 0.6930s	
14788/28500 (epoch 25.944), train_loss = 0.86634322, grad/param norm = 1.5615e-01, time/batch = 0.6919s	
14789/28500 (epoch 25.946), train_loss = 1.00604497, grad/param norm = 1.5837e-01, time/batch = 0.6946s	
14790/28500 (epoch 25.947), train_loss = 1.21313907, grad/param norm = 2.2002e-01, time/batch = 0.6940s	
14791/28500 (epoch 25.949), train_loss = 0.89956193, grad/param norm = 1.8688e-01, time/batch = 0.6967s	
14792/28500 (epoch 25.951), train_loss = 1.12093261, grad/param norm = 1.9980e-01, time/batch = 0.6927s	
14793/28500 (epoch 25.953), train_loss = 1.07756501, grad/param norm = 1.9754e-01, time/batch = 0.6939s	
14794/28500 (epoch 25.954), train_loss = 1.04320165, grad/param norm = 1.9402e-01, time/batch = 0.6923s	
14795/28500 (epoch 25.956), train_loss = 0.95736849, grad/param norm = 2.4016e-01, time/batch = 0.6937s	
14796/28500 (epoch 25.958), train_loss = 1.15429079, grad/param norm = 1.7653e-01, time/batch = 0.6918s	
14797/28500 (epoch 25.960), train_loss = 0.87624253, grad/param norm = 1.8423e-01, time/batch = 0.6928s	
14798/28500 (epoch 25.961), train_loss = 1.11158063, grad/param norm = 2.0786e-01, time/batch = 0.6931s	
14799/28500 (epoch 25.963), train_loss = 1.06968901, grad/param norm = 1.7436e-01, time/batch = 0.6926s	
14800/28500 (epoch 25.965), train_loss = 0.86545346, grad/param norm = 1.6969e-01, time/batch = 0.6926s	
14801/28500 (epoch 25.967), train_loss = 0.85404463, grad/param norm = 1.5765e-01, time/batch = 0.6955s	
14802/28500 (epoch 25.968), train_loss = 0.80249180, grad/param norm = 1.3770e-01, time/batch = 0.6938s	
14803/28500 (epoch 25.970), train_loss = 0.85154373, grad/param norm = 1.7071e-01, time/batch = 0.6930s	
14804/28500 (epoch 25.972), train_loss = 0.97049419, grad/param norm = 1.8274e-01, time/batch = 0.6936s	
14805/28500 (epoch 25.974), train_loss = 1.12954853, grad/param norm = 2.0151e-01, time/batch = 0.6932s	
14806/28500 (epoch 25.975), train_loss = 0.87672688, grad/param norm = 1.7383e-01, time/batch = 0.6940s	
14807/28500 (epoch 25.977), train_loss = 1.02076441, grad/param norm = 1.7399e-01, time/batch = 0.6954s	
14808/28500 (epoch 25.979), train_loss = 0.93162615, grad/param norm = 1.8381e-01, time/batch = 0.6931s	
14809/28500 (epoch 25.981), train_loss = 0.83949217, grad/param norm = 1.6493e-01, time/batch = 0.6931s	
14810/28500 (epoch 25.982), train_loss = 0.89914153, grad/param norm = 1.6155e-01, time/batch = 0.6942s	
14811/28500 (epoch 25.984), train_loss = 1.00924287, grad/param norm = 1.6643e-01, time/batch = 0.6937s	
14812/28500 (epoch 25.986), train_loss = 1.19547400, grad/param norm = 1.9357e-01, time/batch = 0.6936s	
14813/28500 (epoch 25.988), train_loss = 0.82937673, grad/param norm = 1.5417e-01, time/batch = 0.6921s	
14814/28500 (epoch 25.989), train_loss = 0.98853840, grad/param norm = 1.7289e-01, time/batch = 0.6956s	
14815/28500 (epoch 25.991), train_loss = 0.84900459, grad/param norm = 1.5622e-01, time/batch = 0.6981s	
14816/28500 (epoch 25.993), train_loss = 0.88752871, grad/param norm = 1.7014e-01, time/batch = 0.6964s	
14817/28500 (epoch 25.995), train_loss = 0.87719359, grad/param norm = 1.7737e-01, time/batch = 0.6930s	
14818/28500 (epoch 25.996), train_loss = 0.84892900, grad/param norm = 1.6624e-01, time/batch = 0.6931s	
14819/28500 (epoch 25.998), train_loss = 1.06218196, grad/param norm = 2.1955e-01, time/batch = 0.6917s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
14820/28500 (epoch 26.000), train_loss = 0.92835968, grad/param norm = 1.7133e-01, time/batch = 0.6936s	
14821/28500 (epoch 26.002), train_loss = 1.11417943, grad/param norm = 1.7930e-01, time/batch = 0.6968s	
14822/28500 (epoch 26.004), train_loss = 0.89882419, grad/param norm = 1.5793e-01, time/batch = 0.6967s	
14823/28500 (epoch 26.005), train_loss = 1.07920337, grad/param norm = 2.0018e-01, time/batch = 0.6926s	
14824/28500 (epoch 26.007), train_loss = 0.83311622, grad/param norm = 1.4187e-01, time/batch = 0.6950s	
14825/28500 (epoch 26.009), train_loss = 0.97907344, grad/param norm = 1.8853e-01, time/batch = 0.6928s	
14826/28500 (epoch 26.011), train_loss = 0.87392988, grad/param norm = 1.9253e-01, time/batch = 0.6932s	
14827/28500 (epoch 26.012), train_loss = 0.83413784, grad/param norm = 1.4655e-01, time/batch = 0.6928s	
14828/28500 (epoch 26.014), train_loss = 0.85875386, grad/param norm = 1.7035e-01, time/batch = 0.6943s	
14829/28500 (epoch 26.016), train_loss = 0.88673769, grad/param norm = 1.6028e-01, time/batch = 0.6923s	
14830/28500 (epoch 26.018), train_loss = 0.96883504, grad/param norm = 1.7946e-01, time/batch = 0.6932s	
14831/28500 (epoch 26.019), train_loss = 1.02407271, grad/param norm = 1.6734e-01, time/batch = 0.6940s	
14832/28500 (epoch 26.021), train_loss = 1.02989201, grad/param norm = 1.6463e-01, time/batch = 0.6933s	
14833/28500 (epoch 26.023), train_loss = 0.95144300, grad/param norm = 2.0124e-01, time/batch = 0.6916s	
14834/28500 (epoch 26.025), train_loss = 0.98083413, grad/param norm = 1.7053e-01, time/batch = 0.6932s	
14835/28500 (epoch 26.026), train_loss = 0.92317911, grad/param norm = 1.6283e-01, time/batch = 0.6920s	
14836/28500 (epoch 26.028), train_loss = 0.95491905, grad/param norm = 1.8503e-01, time/batch = 0.6948s	
14837/28500 (epoch 26.030), train_loss = 1.01587406, grad/param norm = 1.8909e-01, time/batch = 0.6926s	
14838/28500 (epoch 26.032), train_loss = 1.04957500, grad/param norm = 1.9011e-01, time/batch = 0.6946s	
14839/28500 (epoch 26.033), train_loss = 1.10738862, grad/param norm = 1.7905e-01, time/batch = 0.6946s	
14840/28500 (epoch 26.035), train_loss = 0.94049592, grad/param norm = 1.8229e-01, time/batch = 0.6937s	
14841/28500 (epoch 26.037), train_loss = 1.00059706, grad/param norm = 1.6791e-01, time/batch = 0.6960s	
14842/28500 (epoch 26.039), train_loss = 1.04826683, grad/param norm = 1.7359e-01, time/batch = 0.6949s	
14843/28500 (epoch 26.040), train_loss = 1.05835641, grad/param norm = 1.7474e-01, time/batch = 0.6938s	
14844/28500 (epoch 26.042), train_loss = 1.01682301, grad/param norm = 1.7672e-01, time/batch = 0.6923s	
14845/28500 (epoch 26.044), train_loss = 0.95768236, grad/param norm = 1.8710e-01, time/batch = 0.6920s	
14846/28500 (epoch 26.046), train_loss = 1.16151442, grad/param norm = 1.7505e-01, time/batch = 0.6935s	
14847/28500 (epoch 26.047), train_loss = 1.09029906, grad/param norm = 1.8577e-01, time/batch = 0.6933s	
14848/28500 (epoch 26.049), train_loss = 0.98253837, grad/param norm = 1.8199e-01, time/batch = 0.6963s	
14849/28500 (epoch 26.051), train_loss = 0.95297800, grad/param norm = 1.6885e-01, time/batch = 0.6993s	
14850/28500 (epoch 26.053), train_loss = 0.94894104, grad/param norm = 1.9096e-01, time/batch = 0.7139s	
14851/28500 (epoch 26.054), train_loss = 1.03418387, grad/param norm = 1.7253e-01, time/batch = 0.6977s	
14852/28500 (epoch 26.056), train_loss = 0.87619536, grad/param norm = 1.5340e-01, time/batch = 0.6943s	
14853/28500 (epoch 26.058), train_loss = 0.86751597, grad/param norm = 1.4613e-01, time/batch = 0.6958s	
14854/28500 (epoch 26.060), train_loss = 1.02078582, grad/param norm = 1.7582e-01, time/batch = 0.7060s	
14855/28500 (epoch 26.061), train_loss = 0.94487990, grad/param norm = 1.7259e-01, time/batch = 0.6972s	
14856/28500 (epoch 26.063), train_loss = 1.03284433, grad/param norm = 1.8086e-01, time/batch = 0.6939s	
14857/28500 (epoch 26.065), train_loss = 1.01612769, grad/param norm = 1.9526e-01, time/batch = 0.7059s	
14858/28500 (epoch 26.067), train_loss = 0.92845171, grad/param norm = 1.6111e-01, time/batch = 0.7019s	
14859/28500 (epoch 26.068), train_loss = 0.92511916, grad/param norm = 1.5355e-01, time/batch = 0.7066s	
14860/28500 (epoch 26.070), train_loss = 1.00440297, grad/param norm = 1.9178e-01, time/batch = 0.6949s	
14861/28500 (epoch 26.072), train_loss = 1.07937371, grad/param norm = 1.7415e-01, time/batch = 0.6974s	
14862/28500 (epoch 26.074), train_loss = 0.97095354, grad/param norm = 1.7565e-01, time/batch = 0.6917s	
14863/28500 (epoch 26.075), train_loss = 0.93053345, grad/param norm = 1.5527e-01, time/batch = 0.6894s	
14864/28500 (epoch 26.077), train_loss = 1.02316423, grad/param norm = 1.5607e-01, time/batch = 0.6935s	
14865/28500 (epoch 26.079), train_loss = 0.96091890, grad/param norm = 1.7545e-01, time/batch = 0.6928s	
14866/28500 (epoch 26.081), train_loss = 1.07957052, grad/param norm = 1.9300e-01, time/batch = 0.6896s	
14867/28500 (epoch 26.082), train_loss = 0.97407400, grad/param norm = 1.8152e-01, time/batch = 0.6907s	
14868/28500 (epoch 26.084), train_loss = 0.99614439, grad/param norm = 1.7446e-01, time/batch = 0.6941s	
14869/28500 (epoch 26.086), train_loss = 0.93881905, grad/param norm = 1.9260e-01, time/batch = 0.6935s	
14870/28500 (epoch 26.088), train_loss = 0.88790395, grad/param norm = 1.6769e-01, time/batch = 0.6947s	
14871/28500 (epoch 26.089), train_loss = 1.06306592, grad/param norm = 1.6202e-01, time/batch = 0.6929s	
14872/28500 (epoch 26.091), train_loss = 0.82412192, grad/param norm = 1.5296e-01, time/batch = 0.6906s	
14873/28500 (epoch 26.093), train_loss = 1.01586020, grad/param norm = 1.6141e-01, time/batch = 0.6912s	
14874/28500 (epoch 26.095), train_loss = 0.92476787, grad/param norm = 1.5194e-01, time/batch = 0.6897s	
14875/28500 (epoch 26.096), train_loss = 1.05906465, grad/param norm = 1.7994e-01, time/batch = 0.6924s	
14876/28500 (epoch 26.098), train_loss = 0.98158299, grad/param norm = 1.9463e-01, time/batch = 0.6937s	
14877/28500 (epoch 26.100), train_loss = 0.91663388, grad/param norm = 1.7378e-01, time/batch = 0.6944s	
14878/28500 (epoch 26.102), train_loss = 1.03038207, grad/param norm = 1.9220e-01, time/batch = 0.6898s	
14879/28500 (epoch 26.104), train_loss = 0.96714035, grad/param norm = 1.8727e-01, time/batch = 0.6946s	
14880/28500 (epoch 26.105), train_loss = 1.07596578, grad/param norm = 1.5850e-01, time/batch = 0.7066s	
14881/28500 (epoch 26.107), train_loss = 0.86643016, grad/param norm = 1.5306e-01, time/batch = 0.6963s	
14882/28500 (epoch 26.109), train_loss = 0.86971934, grad/param norm = 1.8985e-01, time/batch = 0.6937s	
14883/28500 (epoch 26.111), train_loss = 0.91573929, grad/param norm = 1.7986e-01, time/batch = 0.6900s	
14884/28500 (epoch 26.112), train_loss = 1.02285302, grad/param norm = 1.6499e-01, time/batch = 0.6900s	
14885/28500 (epoch 26.114), train_loss = 0.92469740, grad/param norm = 1.6123e-01, time/batch = 0.6922s	
14886/28500 (epoch 26.116), train_loss = 1.08773888, grad/param norm = 1.8016e-01, time/batch = 0.6910s	
14887/28500 (epoch 26.118), train_loss = 0.84077409, grad/param norm = 1.6598e-01, time/batch = 0.7128s	
14888/28500 (epoch 26.119), train_loss = 0.99245085, grad/param norm = 2.0134e-01, time/batch = 0.6960s	
14889/28500 (epoch 26.121), train_loss = 1.12132196, grad/param norm = 2.0958e-01, time/batch = 0.6916s	
14890/28500 (epoch 26.123), train_loss = 1.03988988, grad/param norm = 1.8321e-01, time/batch = 0.6917s	
14891/28500 (epoch 26.125), train_loss = 0.97949655, grad/param norm = 1.8003e-01, time/batch = 0.6929s	
14892/28500 (epoch 26.126), train_loss = 0.96254049, grad/param norm = 1.7291e-01, time/batch = 0.6936s	
14893/28500 (epoch 26.128), train_loss = 0.98302373, grad/param norm = 1.8032e-01, time/batch = 0.6950s	
14894/28500 (epoch 26.130), train_loss = 0.89769832, grad/param norm = 2.0254e-01, time/batch = 0.6917s	
14895/28500 (epoch 26.132), train_loss = 0.95530533, grad/param norm = 1.8129e-01, time/batch = 0.6895s	
14896/28500 (epoch 26.133), train_loss = 1.03983796, grad/param norm = 1.8736e-01, time/batch = 0.6896s	
14897/28500 (epoch 26.135), train_loss = 0.91723089, grad/param norm = 1.5934e-01, time/batch = 0.6891s	
14898/28500 (epoch 26.137), train_loss = 0.96765919, grad/param norm = 1.7019e-01, time/batch = 0.6940s	
14899/28500 (epoch 26.139), train_loss = 0.96822875, grad/param norm = 1.6449e-01, time/batch = 0.6918s	
14900/28500 (epoch 26.140), train_loss = 0.98868207, grad/param norm = 1.7339e-01, time/batch = 0.6904s	
14901/28500 (epoch 26.142), train_loss = 0.93607821, grad/param norm = 1.8828e-01, time/batch = 0.6931s	
14902/28500 (epoch 26.144), train_loss = 0.87391425, grad/param norm = 1.5400e-01, time/batch = 0.6929s	
14903/28500 (epoch 26.146), train_loss = 0.92830573, grad/param norm = 1.5719e-01, time/batch = 0.6906s	
14904/28500 (epoch 26.147), train_loss = 0.83171126, grad/param norm = 1.6033e-01, time/batch = 0.6912s	
14905/28500 (epoch 26.149), train_loss = 0.83880317, grad/param norm = 1.5857e-01, time/batch = 0.6936s	
14906/28500 (epoch 26.151), train_loss = 0.90768912, grad/param norm = 1.4760e-01, time/batch = 0.6936s	
14907/28500 (epoch 26.153), train_loss = 0.98240378, grad/param norm = 1.7180e-01, time/batch = 0.6963s	
14908/28500 (epoch 26.154), train_loss = 0.85009164, grad/param norm = 1.5186e-01, time/batch = 0.6923s	
14909/28500 (epoch 26.156), train_loss = 1.05677248, grad/param norm = 1.9569e-01, time/batch = 0.6894s	
14910/28500 (epoch 26.158), train_loss = 0.97695774, grad/param norm = 1.6438e-01, time/batch = 0.6956s	
14911/28500 (epoch 26.160), train_loss = 0.86330108, grad/param norm = 1.4460e-01, time/batch = 0.7009s	
14912/28500 (epoch 26.161), train_loss = 0.90642420, grad/param norm = 1.7628e-01, time/batch = 0.6953s	
14913/28500 (epoch 26.163), train_loss = 0.82094671, grad/param norm = 1.6286e-01, time/batch = 0.6949s	
14914/28500 (epoch 26.165), train_loss = 1.14506604, grad/param norm = 1.6897e-01, time/batch = 0.6973s	
14915/28500 (epoch 26.167), train_loss = 1.14744874, grad/param norm = 1.8879e-01, time/batch = 0.7120s	
14916/28500 (epoch 26.168), train_loss = 1.05451246, grad/param norm = 1.7135e-01, time/batch = 0.7132s	
14917/28500 (epoch 26.170), train_loss = 1.05037437, grad/param norm = 2.2550e-01, time/batch = 0.7011s	
14918/28500 (epoch 26.172), train_loss = 0.94966178, grad/param norm = 1.5948e-01, time/batch = 0.6923s	
14919/28500 (epoch 26.174), train_loss = 1.10228115, grad/param norm = 1.8587e-01, time/batch = 0.6963s	
14920/28500 (epoch 26.175), train_loss = 0.93437945, grad/param norm = 1.5148e-01, time/batch = 0.6924s	
14921/28500 (epoch 26.177), train_loss = 1.00735515, grad/param norm = 1.7077e-01, time/batch = 0.6921s	
14922/28500 (epoch 26.179), train_loss = 1.00073557, grad/param norm = 1.8461e-01, time/batch = 0.6915s	
14923/28500 (epoch 26.181), train_loss = 1.01458544, grad/param norm = 1.8281e-01, time/batch = 0.6903s	
14924/28500 (epoch 26.182), train_loss = 0.93566496, grad/param norm = 1.6341e-01, time/batch = 0.6940s	
14925/28500 (epoch 26.184), train_loss = 1.12981435, grad/param norm = 1.9941e-01, time/batch = 0.6916s	
14926/28500 (epoch 26.186), train_loss = 1.08537230, grad/param norm = 1.7811e-01, time/batch = 0.6892s	
14927/28500 (epoch 26.188), train_loss = 1.00278929, grad/param norm = 1.7682e-01, time/batch = 0.6946s	
14928/28500 (epoch 26.189), train_loss = 0.97804413, grad/param norm = 1.8038e-01, time/batch = 0.6912s	
14929/28500 (epoch 26.191), train_loss = 1.19158597, grad/param norm = 1.9873e-01, time/batch = 0.6938s	
14930/28500 (epoch 26.193), train_loss = 1.00025242, grad/param norm = 1.8975e-01, time/batch = 0.6930s	
14931/28500 (epoch 26.195), train_loss = 1.10823372, grad/param norm = 1.9791e-01, time/batch = 0.6966s	
14932/28500 (epoch 26.196), train_loss = 1.01408636, grad/param norm = 1.6616e-01, time/batch = 0.6963s	
14933/28500 (epoch 26.198), train_loss = 0.98266680, grad/param norm = 1.7186e-01, time/batch = 0.7037s	
14934/28500 (epoch 26.200), train_loss = 1.03258061, grad/param norm = 1.6850e-01, time/batch = 0.6994s	
14935/28500 (epoch 26.202), train_loss = 1.00216588, grad/param norm = 1.6136e-01, time/batch = 0.6981s	
14936/28500 (epoch 26.204), train_loss = 0.93298329, grad/param norm = 1.5081e-01, time/batch = 0.7016s	
14937/28500 (epoch 26.205), train_loss = 0.95154600, grad/param norm = 1.7855e-01, time/batch = 0.6948s	
14938/28500 (epoch 26.207), train_loss = 0.87987232, grad/param norm = 1.6740e-01, time/batch = 0.6932s	
14939/28500 (epoch 26.209), train_loss = 0.98802966, grad/param norm = 1.6143e-01, time/batch = 0.6921s	
14940/28500 (epoch 26.211), train_loss = 0.84474451, grad/param norm = 1.6280e-01, time/batch = 0.6934s	
14941/28500 (epoch 26.212), train_loss = 0.82346489, grad/param norm = 1.5601e-01, time/batch = 0.6960s	
14942/28500 (epoch 26.214), train_loss = 0.94556835, grad/param norm = 1.8407e-01, time/batch = 0.7017s	
14943/28500 (epoch 26.216), train_loss = 0.88654289, grad/param norm = 1.6217e-01, time/batch = 0.6976s	
14944/28500 (epoch 26.218), train_loss = 1.06784830, grad/param norm = 1.6294e-01, time/batch = 0.6945s	
14945/28500 (epoch 26.219), train_loss = 1.00853568, grad/param norm = 1.7523e-01, time/batch = 0.6923s	
14946/28500 (epoch 26.221), train_loss = 0.84178817, grad/param norm = 1.7437e-01, time/batch = 0.6938s	
14947/28500 (epoch 26.223), train_loss = 1.07384938, grad/param norm = 1.8639e-01, time/batch = 0.6921s	
14948/28500 (epoch 26.225), train_loss = 1.11156138, grad/param norm = 1.8029e-01, time/batch = 0.6951s	
14949/28500 (epoch 26.226), train_loss = 0.91130910, grad/param norm = 1.5067e-01, time/batch = 0.6972s	
14950/28500 (epoch 26.228), train_loss = 1.06114045, grad/param norm = 1.5549e-01, time/batch = 0.6935s	
14951/28500 (epoch 26.230), train_loss = 1.04946754, grad/param norm = 1.7425e-01, time/batch = 0.6955s	
14952/28500 (epoch 26.232), train_loss = 0.99729875, grad/param norm = 1.8513e-01, time/batch = 0.6941s	
14953/28500 (epoch 26.233), train_loss = 0.99286488, grad/param norm = 2.0428e-01, time/batch = 0.6921s	
14954/28500 (epoch 26.235), train_loss = 0.94047055, grad/param norm = 1.6784e-01, time/batch = 0.6958s	
14955/28500 (epoch 26.237), train_loss = 0.85792626, grad/param norm = 1.4224e-01, time/batch = 0.6979s	
14956/28500 (epoch 26.239), train_loss = 0.91058224, grad/param norm = 1.5202e-01, time/batch = 0.6929s	
14957/28500 (epoch 26.240), train_loss = 0.85443483, grad/param norm = 1.5346e-01, time/batch = 0.6897s	
14958/28500 (epoch 26.242), train_loss = 0.97663834, grad/param norm = 1.7589e-01, time/batch = 0.6893s	
14959/28500 (epoch 26.244), train_loss = 1.00865480, grad/param norm = 1.5552e-01, time/batch = 0.6889s	
14960/28500 (epoch 26.246), train_loss = 1.03862863, grad/param norm = 1.7338e-01, time/batch = 0.6889s	
14961/28500 (epoch 26.247), train_loss = 1.10154706, grad/param norm = 1.8561e-01, time/batch = 0.6909s	
14962/28500 (epoch 26.249), train_loss = 0.96022726, grad/param norm = 1.5839e-01, time/batch = 0.6896s	
14963/28500 (epoch 26.251), train_loss = 0.92688261, grad/param norm = 1.5525e-01, time/batch = 0.6905s	
14964/28500 (epoch 26.253), train_loss = 1.09540339, grad/param norm = 1.9572e-01, time/batch = 0.6897s	
14965/28500 (epoch 26.254), train_loss = 1.11890129, grad/param norm = 1.7133e-01, time/batch = 0.6904s	
14966/28500 (epoch 26.256), train_loss = 0.91808165, grad/param norm = 1.5287e-01, time/batch = 0.6907s	
14967/28500 (epoch 26.258), train_loss = 0.93638649, grad/param norm = 1.6191e-01, time/batch = 0.6895s	
14968/28500 (epoch 26.260), train_loss = 0.92614083, grad/param norm = 1.4764e-01, time/batch = 0.6894s	
14969/28500 (epoch 26.261), train_loss = 0.88519849, grad/param norm = 1.6652e-01, time/batch = 0.6904s	
14970/28500 (epoch 26.263), train_loss = 1.05734603, grad/param norm = 2.0587e-01, time/batch = 0.6888s	
14971/28500 (epoch 26.265), train_loss = 0.96780458, grad/param norm = 1.8842e-01, time/batch = 0.6914s	
14972/28500 (epoch 26.267), train_loss = 1.09893110, grad/param norm = 1.9130e-01, time/batch = 0.6928s	
14973/28500 (epoch 26.268), train_loss = 1.02494457, grad/param norm = 1.6417e-01, time/batch = 0.6933s	
14974/28500 (epoch 26.270), train_loss = 1.00865922, grad/param norm = 1.8727e-01, time/batch = 0.6975s	
14975/28500 (epoch 26.272), train_loss = 0.97084692, grad/param norm = 1.6827e-01, time/batch = 0.6973s	
14976/28500 (epoch 26.274), train_loss = 1.04410220, grad/param norm = 1.6516e-01, time/batch = 0.6938s	
14977/28500 (epoch 26.275), train_loss = 1.00796216, grad/param norm = 1.5170e-01, time/batch = 0.6937s	
14978/28500 (epoch 26.277), train_loss = 0.97927799, grad/param norm = 1.6951e-01, time/batch = 0.6928s	
14979/28500 (epoch 26.279), train_loss = 0.97631347, grad/param norm = 1.8588e-01, time/batch = 0.6918s	
14980/28500 (epoch 26.281), train_loss = 1.04625510, grad/param norm = 1.8427e-01, time/batch = 0.6946s	
14981/28500 (epoch 26.282), train_loss = 0.91261341, grad/param norm = 1.4923e-01, time/batch = 0.6994s	
14982/28500 (epoch 26.284), train_loss = 0.97934899, grad/param norm = 1.7903e-01, time/batch = 0.6956s	
14983/28500 (epoch 26.286), train_loss = 1.10885561, grad/param norm = 1.6961e-01, time/batch = 0.6938s	
14984/28500 (epoch 26.288), train_loss = 0.99213548, grad/param norm = 1.8194e-01, time/batch = 0.6935s	
14985/28500 (epoch 26.289), train_loss = 1.00864576, grad/param norm = 1.8163e-01, time/batch = 0.7033s	
14986/28500 (epoch 26.291), train_loss = 0.98396484, grad/param norm = 1.5525e-01, time/batch = 0.6929s	
14987/28500 (epoch 26.293), train_loss = 0.94584973, grad/param norm = 1.5445e-01, time/batch = 0.6937s	
14988/28500 (epoch 26.295), train_loss = 0.86439539, grad/param norm = 1.5807e-01, time/batch = 0.6912s	
14989/28500 (epoch 26.296), train_loss = 0.85264834, grad/param norm = 1.5673e-01, time/batch = 0.6931s	
14990/28500 (epoch 26.298), train_loss = 1.01787891, grad/param norm = 1.6255e-01, time/batch = 0.6930s	
14991/28500 (epoch 26.300), train_loss = 0.88685109, grad/param norm = 1.7187e-01, time/batch = 0.6952s	
14992/28500 (epoch 26.302), train_loss = 0.86798400, grad/param norm = 1.5685e-01, time/batch = 0.6921s	
14993/28500 (epoch 26.304), train_loss = 0.92499033, grad/param norm = 1.6242e-01, time/batch = 0.6931s	
14994/28500 (epoch 26.305), train_loss = 1.01093558, grad/param norm = 1.7958e-01, time/batch = 0.6920s	
14995/28500 (epoch 26.307), train_loss = 0.96360084, grad/param norm = 1.7047e-01, time/batch = 0.6934s	
14996/28500 (epoch 26.309), train_loss = 0.96510029, grad/param norm = 1.6736e-01, time/batch = 0.6920s	
14997/28500 (epoch 26.311), train_loss = 1.01446033, grad/param norm = 1.5562e-01, time/batch = 0.6935s	
14998/28500 (epoch 26.312), train_loss = 0.99286979, grad/param norm = 1.7235e-01, time/batch = 0.6937s	
14999/28500 (epoch 26.314), train_loss = 1.04450896, grad/param norm = 2.0628e-01, time/batch = 0.6933s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch26.32_1.7826.t7	
15000/28500 (epoch 26.316), train_loss = 0.96945615, grad/param norm = 1.7795e-01, time/batch = 0.6942s	
15001/28500 (epoch 26.318), train_loss = 1.38114454, grad/param norm = 2.0315e-01, time/batch = 0.7021s	
15002/28500 (epoch 26.319), train_loss = 0.95330321, grad/param norm = 1.9564e-01, time/batch = 0.6949s	
15003/28500 (epoch 26.321), train_loss = 0.93528231, grad/param norm = 1.7846e-01, time/batch = 0.6951s	
15004/28500 (epoch 26.323), train_loss = 0.91792644, grad/param norm = 1.7930e-01, time/batch = 0.6952s	
15005/28500 (epoch 26.325), train_loss = 1.10513387, grad/param norm = 1.7585e-01, time/batch = 0.7023s	
15006/28500 (epoch 26.326), train_loss = 1.00628990, grad/param norm = 1.7502e-01, time/batch = 0.6981s	
15007/28500 (epoch 26.328), train_loss = 0.79225179, grad/param norm = 1.6032e-01, time/batch = 0.7108s	
15008/28500 (epoch 26.330), train_loss = 0.89740629, grad/param norm = 1.6558e-01, time/batch = 0.7033s	
15009/28500 (epoch 26.332), train_loss = 0.96463658, grad/param norm = 1.5608e-01, time/batch = 0.7036s	
15010/28500 (epoch 26.333), train_loss = 0.78733099, grad/param norm = 1.7232e-01, time/batch = 0.6974s	
15011/28500 (epoch 26.335), train_loss = 0.85949473, grad/param norm = 1.5189e-01, time/batch = 0.6873s	
15012/28500 (epoch 26.337), train_loss = 0.83774775, grad/param norm = 1.6243e-01, time/batch = 0.7065s	
15013/28500 (epoch 26.339), train_loss = 0.81500150, grad/param norm = 1.4198e-01, time/batch = 0.6845s	
15014/28500 (epoch 26.340), train_loss = 0.97784005, grad/param norm = 2.1273e-01, time/batch = 0.6967s	
15015/28500 (epoch 26.342), train_loss = 0.94465845, grad/param norm = 1.6340e-01, time/batch = 0.6826s	
15016/28500 (epoch 26.344), train_loss = 0.87646401, grad/param norm = 1.8244e-01, time/batch = 0.6803s	
15017/28500 (epoch 26.346), train_loss = 0.78835620, grad/param norm = 1.4600e-01, time/batch = 0.6785s	
15018/28500 (epoch 26.347), train_loss = 0.95555708, grad/param norm = 1.7238e-01, time/batch = 0.6791s	
15019/28500 (epoch 26.349), train_loss = 0.94487155, grad/param norm = 1.6930e-01, time/batch = 0.6806s	
15020/28500 (epoch 26.351), train_loss = 0.87979768, grad/param norm = 1.5037e-01, time/batch = 0.6823s	
15021/28500 (epoch 26.353), train_loss = 0.97591828, grad/param norm = 1.9255e-01, time/batch = 0.6820s	
15022/28500 (epoch 26.354), train_loss = 0.87390606, grad/param norm = 1.5046e-01, time/batch = 0.6801s	
15023/28500 (epoch 26.356), train_loss = 0.88034431, grad/param norm = 1.4860e-01, time/batch = 0.6793s	
15024/28500 (epoch 26.358), train_loss = 0.98433433, grad/param norm = 1.6928e-01, time/batch = 0.6806s	
15025/28500 (epoch 26.360), train_loss = 0.98944103, grad/param norm = 1.8406e-01, time/batch = 0.6815s	
15026/28500 (epoch 26.361), train_loss = 0.88252334, grad/param norm = 1.5313e-01, time/batch = 0.6820s	
15027/28500 (epoch 26.363), train_loss = 0.85181000, grad/param norm = 1.5014e-01, time/batch = 0.6803s	
15028/28500 (epoch 26.365), train_loss = 0.92531455, grad/param norm = 1.6916e-01, time/batch = 0.6869s	
15029/28500 (epoch 26.367), train_loss = 0.96578990, grad/param norm = 1.6337e-01, time/batch = 0.6811s	
15030/28500 (epoch 26.368), train_loss = 0.89905607, grad/param norm = 1.5236e-01, time/batch = 0.6795s	
15031/28500 (epoch 26.370), train_loss = 0.94787599, grad/param norm = 1.6616e-01, time/batch = 0.6851s	
15032/28500 (epoch 26.372), train_loss = 0.78837888, grad/param norm = 1.4711e-01, time/batch = 0.6821s	
15033/28500 (epoch 26.374), train_loss = 0.90859785, grad/param norm = 1.6011e-01, time/batch = 0.6883s	
15034/28500 (epoch 26.375), train_loss = 1.05237953, grad/param norm = 1.7901e-01, time/batch = 0.6837s	
15035/28500 (epoch 26.377), train_loss = 0.81080444, grad/param norm = 1.9019e-01, time/batch = 0.6790s	
15036/28500 (epoch 26.379), train_loss = 0.74464360, grad/param norm = 1.6530e-01, time/batch = 0.6789s	
15037/28500 (epoch 26.381), train_loss = 0.91634663, grad/param norm = 1.6447e-01, time/batch = 0.6817s	
15038/28500 (epoch 26.382), train_loss = 0.90529566, grad/param norm = 1.9150e-01, time/batch = 0.6810s	
15039/28500 (epoch 26.384), train_loss = 0.82553776, grad/param norm = 1.9628e-01, time/batch = 0.6785s	
15040/28500 (epoch 26.386), train_loss = 0.84758624, grad/param norm = 1.5879e-01, time/batch = 0.6810s	
15041/28500 (epoch 26.388), train_loss = 1.03173507, grad/param norm = 1.6445e-01, time/batch = 0.6808s	
15042/28500 (epoch 26.389), train_loss = 0.89535413, grad/param norm = 1.7457e-01, time/batch = 0.6799s	
15043/28500 (epoch 26.391), train_loss = 0.83762412, grad/param norm = 1.6505e-01, time/batch = 0.6791s	
15044/28500 (epoch 26.393), train_loss = 0.86400456, grad/param norm = 1.7094e-01, time/batch = 0.6795s	
15045/28500 (epoch 26.395), train_loss = 1.07250293, grad/param norm = 1.7015e-01, time/batch = 0.6800s	
15046/28500 (epoch 26.396), train_loss = 1.02348786, grad/param norm = 1.8092e-01, time/batch = 0.6776s	
15047/28500 (epoch 26.398), train_loss = 0.72103503, grad/param norm = 1.7660e-01, time/batch = 0.6790s	
15048/28500 (epoch 26.400), train_loss = 0.94110395, grad/param norm = 2.4344e-01, time/batch = 0.6793s	
15049/28500 (epoch 26.402), train_loss = 0.97231869, grad/param norm = 2.0587e-01, time/batch = 0.6791s	
15050/28500 (epoch 26.404), train_loss = 1.00407395, grad/param norm = 1.8715e-01, time/batch = 0.6790s	
15051/28500 (epoch 26.405), train_loss = 1.00646154, grad/param norm = 1.7452e-01, time/batch = 0.6827s	
15052/28500 (epoch 26.407), train_loss = 0.98431827, grad/param norm = 1.6364e-01, time/batch = 0.6801s	
15053/28500 (epoch 26.409), train_loss = 0.98675961, grad/param norm = 1.7094e-01, time/batch = 0.6797s	
15054/28500 (epoch 26.411), train_loss = 1.03885832, grad/param norm = 1.7263e-01, time/batch = 0.6793s	
15055/28500 (epoch 26.412), train_loss = 1.05648626, grad/param norm = 1.7334e-01, time/batch = 0.6797s	
15056/28500 (epoch 26.414), train_loss = 0.96938992, grad/param norm = 1.7556e-01, time/batch = 0.6803s	
15057/28500 (epoch 26.416), train_loss = 0.87151151, grad/param norm = 1.5702e-01, time/batch = 0.6782s	
15058/28500 (epoch 26.418), train_loss = 0.96929414, grad/param norm = 1.5194e-01, time/batch = 0.6798s	
15059/28500 (epoch 26.419), train_loss = 1.07576153, grad/param norm = 1.9755e-01, time/batch = 0.6804s	
15060/28500 (epoch 26.421), train_loss = 1.02674848, grad/param norm = 1.6680e-01, time/batch = 0.6778s	
15061/28500 (epoch 26.423), train_loss = 1.07626196, grad/param norm = 1.9491e-01, time/batch = 0.6819s	
15062/28500 (epoch 26.425), train_loss = 0.97719953, grad/param norm = 1.9402e-01, time/batch = 0.6789s	
15063/28500 (epoch 26.426), train_loss = 0.95769586, grad/param norm = 1.8832e-01, time/batch = 0.6795s	
15064/28500 (epoch 26.428), train_loss = 1.11532175, grad/param norm = 2.0352e-01, time/batch = 0.6790s	
15065/28500 (epoch 26.430), train_loss = 1.08536012, grad/param norm = 1.6875e-01, time/batch = 0.6802s	
15066/28500 (epoch 26.432), train_loss = 0.96735248, grad/param norm = 1.8592e-01, time/batch = 0.6798s	
15067/28500 (epoch 26.433), train_loss = 1.01477667, grad/param norm = 1.8452e-01, time/batch = 0.6792s	
15068/28500 (epoch 26.435), train_loss = 0.98368445, grad/param norm = 1.7655e-01, time/batch = 0.6791s	
15069/28500 (epoch 26.437), train_loss = 0.89083638, grad/param norm = 1.6628e-01, time/batch = 0.6803s	
15070/28500 (epoch 26.439), train_loss = 0.91501720, grad/param norm = 1.4089e-01, time/batch = 0.6810s	
15071/28500 (epoch 26.440), train_loss = 1.13419005, grad/param norm = 1.7984e-01, time/batch = 0.6795s	
15072/28500 (epoch 26.442), train_loss = 0.90156876, grad/param norm = 1.8165e-01, time/batch = 0.6783s	
15073/28500 (epoch 26.444), train_loss = 0.82944392, grad/param norm = 1.4699e-01, time/batch = 0.6767s	
15074/28500 (epoch 26.446), train_loss = 0.82159952, grad/param norm = 1.6424e-01, time/batch = 0.6759s	
15075/28500 (epoch 26.447), train_loss = 0.83637427, grad/param norm = 1.5025e-01, time/batch = 0.6762s	
15076/28500 (epoch 26.449), train_loss = 0.90817954, grad/param norm = 1.5370e-01, time/batch = 0.6875s	
15077/28500 (epoch 26.451), train_loss = 0.93918683, grad/param norm = 1.4890e-01, time/batch = 0.6881s	
15078/28500 (epoch 26.453), train_loss = 0.92801897, grad/param norm = 1.5706e-01, time/batch = 0.6813s	
15079/28500 (epoch 26.454), train_loss = 0.89981097, grad/param norm = 1.5651e-01, time/batch = 0.6786s	
15080/28500 (epoch 26.456), train_loss = 0.99921799, grad/param norm = 1.8727e-01, time/batch = 0.6792s	
15081/28500 (epoch 26.458), train_loss = 0.92522213, grad/param norm = 1.8016e-01, time/batch = 0.6792s	
15082/28500 (epoch 26.460), train_loss = 1.01877630, grad/param norm = 1.6780e-01, time/batch = 0.6772s	
15083/28500 (epoch 26.461), train_loss = 0.87669113, grad/param norm = 1.8853e-01, time/batch = 0.6983s	
15084/28500 (epoch 26.463), train_loss = 0.79912219, grad/param norm = 1.4681e-01, time/batch = 0.6759s	
15085/28500 (epoch 26.465), train_loss = 0.81856827, grad/param norm = 1.7773e-01, time/batch = 0.6822s	
15086/28500 (epoch 26.467), train_loss = 0.95086637, grad/param norm = 1.6064e-01, time/batch = 0.6781s	
15087/28500 (epoch 26.468), train_loss = 0.85733196, grad/param norm = 1.4618e-01, time/batch = 0.6766s	
15088/28500 (epoch 26.470), train_loss = 0.89737564, grad/param norm = 1.6387e-01, time/batch = 0.6773s	
15089/28500 (epoch 26.472), train_loss = 0.86778605, grad/param norm = 1.5213e-01, time/batch = 0.6812s	
15090/28500 (epoch 26.474), train_loss = 1.09200968, grad/param norm = 1.9515e-01, time/batch = 0.6774s	
15091/28500 (epoch 26.475), train_loss = 0.86122500, grad/param norm = 1.5654e-01, time/batch = 0.6793s	
15092/28500 (epoch 26.477), train_loss = 0.91107301, grad/param norm = 1.6804e-01, time/batch = 0.6775s	
15093/28500 (epoch 26.479), train_loss = 0.98311101, grad/param norm = 1.6188e-01, time/batch = 0.6774s	
15094/28500 (epoch 26.481), train_loss = 0.98531572, grad/param norm = 1.7157e-01, time/batch = 0.6764s	
15095/28500 (epoch 26.482), train_loss = 0.84138602, grad/param norm = 1.4879e-01, time/batch = 0.6759s	
15096/28500 (epoch 26.484), train_loss = 0.86297207, grad/param norm = 1.6064e-01, time/batch = 0.6764s	
15097/28500 (epoch 26.486), train_loss = 0.76883503, grad/param norm = 1.8880e-01, time/batch = 0.6772s	
15098/28500 (epoch 26.488), train_loss = 0.97676684, grad/param norm = 1.6572e-01, time/batch = 0.6761s	
15099/28500 (epoch 26.489), train_loss = 1.06048505, grad/param norm = 1.7772e-01, time/batch = 0.6879s	
15100/28500 (epoch 26.491), train_loss = 0.89870706, grad/param norm = 1.7199e-01, time/batch = 0.6794s	
15101/28500 (epoch 26.493), train_loss = 0.93372820, grad/param norm = 1.5714e-01, time/batch = 0.6890s	
15102/28500 (epoch 26.495), train_loss = 0.93656470, grad/param norm = 1.5799e-01, time/batch = 0.6917s	
15103/28500 (epoch 26.496), train_loss = 0.85239960, grad/param norm = 1.7150e-01, time/batch = 0.6806s	
15104/28500 (epoch 26.498), train_loss = 0.92965910, grad/param norm = 1.6910e-01, time/batch = 0.6839s	
15105/28500 (epoch 26.500), train_loss = 0.87896962, grad/param norm = 1.5143e-01, time/batch = 0.6845s	
15106/28500 (epoch 26.502), train_loss = 1.01349487, grad/param norm = 1.5567e-01, time/batch = 0.6898s	
15107/28500 (epoch 26.504), train_loss = 0.97684471, grad/param norm = 1.5122e-01, time/batch = 0.6824s	
15108/28500 (epoch 26.505), train_loss = 0.88531574, grad/param norm = 1.6218e-01, time/batch = 0.6797s	
15109/28500 (epoch 26.507), train_loss = 1.05878556, grad/param norm = 2.1920e-01, time/batch = 0.6793s	
15110/28500 (epoch 26.509), train_loss = 0.94039909, grad/param norm = 1.6501e-01, time/batch = 0.6813s	
15111/28500 (epoch 26.511), train_loss = 0.96280946, grad/param norm = 1.7401e-01, time/batch = 0.6847s	
15112/28500 (epoch 26.512), train_loss = 0.97773817, grad/param norm = 1.6019e-01, time/batch = 0.6863s	
15113/28500 (epoch 26.514), train_loss = 0.91576360, grad/param norm = 1.5316e-01, time/batch = 0.6949s	
15114/28500 (epoch 26.516), train_loss = 0.89973487, grad/param norm = 1.4282e-01, time/batch = 0.6760s	
15115/28500 (epoch 26.518), train_loss = 0.98517641, grad/param norm = 1.5759e-01, time/batch = 0.6759s	
15116/28500 (epoch 26.519), train_loss = 1.01215058, grad/param norm = 1.6247e-01, time/batch = 0.6762s	
15117/28500 (epoch 26.521), train_loss = 1.08389138, grad/param norm = 1.7764e-01, time/batch = 0.6782s	
15118/28500 (epoch 26.523), train_loss = 1.00070331, grad/param norm = 1.9514e-01, time/batch = 0.6840s	
15119/28500 (epoch 26.525), train_loss = 1.05025026, grad/param norm = 1.7401e-01, time/batch = 0.6802s	
15120/28500 (epoch 26.526), train_loss = 1.01198108, grad/param norm = 1.6156e-01, time/batch = 0.6764s	
15121/28500 (epoch 26.528), train_loss = 1.00301934, grad/param norm = 1.8224e-01, time/batch = 0.6878s	
15122/28500 (epoch 26.530), train_loss = 1.02163146, grad/param norm = 1.6039e-01, time/batch = 0.6954s	
15123/28500 (epoch 26.532), train_loss = 0.91554989, grad/param norm = 1.5363e-01, time/batch = 0.6832s	
15124/28500 (epoch 26.533), train_loss = 1.03287763, grad/param norm = 1.8265e-01, time/batch = 0.6789s	
15125/28500 (epoch 26.535), train_loss = 0.82448536, grad/param norm = 1.4740e-01, time/batch = 0.6799s	
15126/28500 (epoch 26.537), train_loss = 0.84828064, grad/param norm = 1.6606e-01, time/batch = 0.6767s	
15127/28500 (epoch 26.539), train_loss = 0.80402753, grad/param norm = 1.6032e-01, time/batch = 0.6757s	
15128/28500 (epoch 26.540), train_loss = 0.96374962, grad/param norm = 1.7155e-01, time/batch = 0.6754s	
15129/28500 (epoch 26.542), train_loss = 0.99799912, grad/param norm = 1.9146e-01, time/batch = 0.6756s	
15130/28500 (epoch 26.544), train_loss = 1.09293483, grad/param norm = 1.8141e-01, time/batch = 0.6765s	
15131/28500 (epoch 26.546), train_loss = 0.93107244, grad/param norm = 1.6711e-01, time/batch = 0.6785s	
15132/28500 (epoch 26.547), train_loss = 0.95405701, grad/param norm = 1.6136e-01, time/batch = 0.6785s	
15133/28500 (epoch 26.549), train_loss = 0.78553753, grad/param norm = 1.4088e-01, time/batch = 0.6774s	
15134/28500 (epoch 26.551), train_loss = 0.92047777, grad/param norm = 2.0480e-01, time/batch = 0.6761s	
15135/28500 (epoch 26.553), train_loss = 1.13913702, grad/param norm = 2.1232e-01, time/batch = 0.6759s	
15136/28500 (epoch 26.554), train_loss = 0.99655782, grad/param norm = 1.8747e-01, time/batch = 0.6754s	
15137/28500 (epoch 26.556), train_loss = 1.00791482, grad/param norm = 1.8679e-01, time/batch = 0.6757s	
15138/28500 (epoch 26.558), train_loss = 0.99044953, grad/param norm = 1.6699e-01, time/batch = 0.6772s	
15139/28500 (epoch 26.560), train_loss = 0.97400736, grad/param norm = 1.7102e-01, time/batch = 0.6775s	
15140/28500 (epoch 26.561), train_loss = 1.02561882, grad/param norm = 1.8733e-01, time/batch = 0.6751s	
15141/28500 (epoch 26.563), train_loss = 1.10773297, grad/param norm = 2.0961e-01, time/batch = 0.6772s	
15142/28500 (epoch 26.565), train_loss = 0.90048487, grad/param norm = 1.6604e-01, time/batch = 0.6761s	
15143/28500 (epoch 26.567), train_loss = 0.85644902, grad/param norm = 1.6127e-01, time/batch = 0.6760s	
15144/28500 (epoch 26.568), train_loss = 0.98909830, grad/param norm = 1.6661e-01, time/batch = 0.6764s	
15145/28500 (epoch 26.570), train_loss = 0.93237202, grad/param norm = 1.6156e-01, time/batch = 0.6759s	
15146/28500 (epoch 26.572), train_loss = 0.93777626, grad/param norm = 1.6538e-01, time/batch = 0.6912s	
15147/28500 (epoch 26.574), train_loss = 0.90745347, grad/param norm = 1.5965e-01, time/batch = 0.6891s	
15148/28500 (epoch 26.575), train_loss = 0.91692436, grad/param norm = 1.6317e-01, time/batch = 0.6759s	
15149/28500 (epoch 26.577), train_loss = 0.99180454, grad/param norm = 1.7663e-01, time/batch = 0.6778s	
15150/28500 (epoch 26.579), train_loss = 1.04243507, grad/param norm = 1.8196e-01, time/batch = 0.6784s	
15151/28500 (epoch 26.581), train_loss = 0.87191103, grad/param norm = 1.8080e-01, time/batch = 0.6773s	
15152/28500 (epoch 26.582), train_loss = 1.03514401, grad/param norm = 1.7353e-01, time/batch = 0.6810s	
15153/28500 (epoch 26.584), train_loss = 0.89912595, grad/param norm = 1.7466e-01, time/batch = 0.6797s	
15154/28500 (epoch 26.586), train_loss = 0.87123691, grad/param norm = 1.5633e-01, time/batch = 0.6786s	
15155/28500 (epoch 26.588), train_loss = 0.88084807, grad/param norm = 1.6586e-01, time/batch = 0.6898s	
15156/28500 (epoch 26.589), train_loss = 0.97326341, grad/param norm = 1.9572e-01, time/batch = 0.6858s	
15157/28500 (epoch 26.591), train_loss = 0.96271491, grad/param norm = 1.7098e-01, time/batch = 0.6855s	
15158/28500 (epoch 26.593), train_loss = 0.89363829, grad/param norm = 1.6209e-01, time/batch = 0.6812s	
15159/28500 (epoch 26.595), train_loss = 1.13314543, grad/param norm = 1.9586e-01, time/batch = 0.6807s	
15160/28500 (epoch 26.596), train_loss = 1.10870553, grad/param norm = 1.7537e-01, time/batch = 0.6791s	
15161/28500 (epoch 26.598), train_loss = 0.95110593, grad/param norm = 1.6479e-01, time/batch = 0.6786s	
15162/28500 (epoch 26.600), train_loss = 0.96663284, grad/param norm = 1.7821e-01, time/batch = 0.6864s	
15163/28500 (epoch 26.602), train_loss = 1.02201521, grad/param norm = 1.9560e-01, time/batch = 0.6781s	
15164/28500 (epoch 26.604), train_loss = 1.03280624, grad/param norm = 1.6418e-01, time/batch = 0.6792s	
15165/28500 (epoch 26.605), train_loss = 1.01078301, grad/param norm = 1.7031e-01, time/batch = 0.6805s	
15166/28500 (epoch 26.607), train_loss = 1.05190894, grad/param norm = 1.5319e-01, time/batch = 0.6765s	
15167/28500 (epoch 26.609), train_loss = 0.96599676, grad/param norm = 1.6002e-01, time/batch = 0.6756s	
15168/28500 (epoch 26.611), train_loss = 0.91178522, grad/param norm = 1.6902e-01, time/batch = 0.6757s	
15169/28500 (epoch 26.612), train_loss = 1.00030843, grad/param norm = 1.8602e-01, time/batch = 0.6761s	
15170/28500 (epoch 26.614), train_loss = 0.98570745, grad/param norm = 1.5219e-01, time/batch = 0.6763s	
15171/28500 (epoch 26.616), train_loss = 0.93024819, grad/param norm = 1.7832e-01, time/batch = 0.6839s	
15172/28500 (epoch 26.618), train_loss = 0.94183968, grad/param norm = 1.7816e-01, time/batch = 0.6785s	
15173/28500 (epoch 26.619), train_loss = 1.06442298, grad/param norm = 1.9620e-01, time/batch = 0.6765s	
15174/28500 (epoch 26.621), train_loss = 0.78494258, grad/param norm = 1.3900e-01, time/batch = 0.6770s	
15175/28500 (epoch 26.623), train_loss = 1.04221567, grad/param norm = 1.8829e-01, time/batch = 0.6773s	
15176/28500 (epoch 26.625), train_loss = 0.84367744, grad/param norm = 1.5206e-01, time/batch = 0.6765s	
15177/28500 (epoch 26.626), train_loss = 0.73473597, grad/param norm = 1.3780e-01, time/batch = 0.6761s	
15178/28500 (epoch 26.628), train_loss = 0.87537616, grad/param norm = 1.7481e-01, time/batch = 0.6756s	
15179/28500 (epoch 26.630), train_loss = 0.81643535, grad/param norm = 1.5342e-01, time/batch = 0.6768s	
15180/28500 (epoch 26.632), train_loss = 1.03523556, grad/param norm = 1.8276e-01, time/batch = 0.6796s	
15181/28500 (epoch 26.633), train_loss = 1.10946616, grad/param norm = 1.6909e-01, time/batch = 0.6814s	
15182/28500 (epoch 26.635), train_loss = 1.01977279, grad/param norm = 1.8077e-01, time/batch = 0.6793s	
15183/28500 (epoch 26.637), train_loss = 0.97166510, grad/param norm = 1.6312e-01, time/batch = 0.6805s	
15184/28500 (epoch 26.639), train_loss = 0.85586916, grad/param norm = 1.7045e-01, time/batch = 0.6806s	
15185/28500 (epoch 26.640), train_loss = 0.89468548, grad/param norm = 1.6680e-01, time/batch = 0.6788s	
15186/28500 (epoch 26.642), train_loss = 0.91043152, grad/param norm = 1.5893e-01, time/batch = 0.6801s	
15187/28500 (epoch 26.644), train_loss = 1.04035369, grad/param norm = 1.7564e-01, time/batch = 0.6800s	
15188/28500 (epoch 26.646), train_loss = 0.81266231, grad/param norm = 1.3411e-01, time/batch = 0.6804s	
15189/28500 (epoch 26.647), train_loss = 0.85523234, grad/param norm = 1.4958e-01, time/batch = 0.6966s	
15190/28500 (epoch 26.649), train_loss = 0.80664757, grad/param norm = 1.4461e-01, time/batch = 0.6811s	
15191/28500 (epoch 26.651), train_loss = 0.82687924, grad/param norm = 1.4379e-01, time/batch = 0.6798s	
15192/28500 (epoch 26.653), train_loss = 0.81659787, grad/param norm = 1.5965e-01, time/batch = 0.6776s	
15193/28500 (epoch 26.654), train_loss = 0.88616545, grad/param norm = 1.8329e-01, time/batch = 0.6766s	
15194/28500 (epoch 26.656), train_loss = 0.86840443, grad/param norm = 1.7756e-01, time/batch = 0.6764s	
15195/28500 (epoch 26.658), train_loss = 0.92012838, grad/param norm = 1.7057e-01, time/batch = 0.6763s	
15196/28500 (epoch 26.660), train_loss = 0.94160710, grad/param norm = 1.6448e-01, time/batch = 0.6762s	
15197/28500 (epoch 26.661), train_loss = 1.06970132, grad/param norm = 1.9307e-01, time/batch = 0.6767s	
15198/28500 (epoch 26.663), train_loss = 1.05887817, grad/param norm = 1.7354e-01, time/batch = 0.6798s	
15199/28500 (epoch 26.665), train_loss = 0.92811252, grad/param norm = 1.5863e-01, time/batch = 0.6832s	
15200/28500 (epoch 26.667), train_loss = 0.91968639, grad/param norm = 1.6813e-01, time/batch = 0.6973s	
15201/28500 (epoch 26.668), train_loss = 0.92893958, grad/param norm = 1.5997e-01, time/batch = 0.6856s	
15202/28500 (epoch 26.670), train_loss = 0.95003906, grad/param norm = 1.7744e-01, time/batch = 0.6794s	
15203/28500 (epoch 26.672), train_loss = 0.86962408, grad/param norm = 1.5252e-01, time/batch = 0.6867s	
15204/28500 (epoch 26.674), train_loss = 0.77942932, grad/param norm = 1.6986e-01, time/batch = 0.6821s	
15205/28500 (epoch 26.675), train_loss = 0.81275479, grad/param norm = 1.5395e-01, time/batch = 0.6970s	
15206/28500 (epoch 26.677), train_loss = 0.90099813, grad/param norm = 1.6173e-01, time/batch = 0.6989s	
15207/28500 (epoch 26.679), train_loss = 0.89682392, grad/param norm = 1.6224e-01, time/batch = 0.6878s	
15208/28500 (epoch 26.681), train_loss = 0.96981938, grad/param norm = 1.6611e-01, time/batch = 0.6895s	
15209/28500 (epoch 26.682), train_loss = 0.87852166, grad/param norm = 1.5686e-01, time/batch = 0.6848s	
15210/28500 (epoch 26.684), train_loss = 0.95499920, grad/param norm = 1.6987e-01, time/batch = 0.6790s	
15211/28500 (epoch 26.686), train_loss = 0.90939240, grad/param norm = 1.8525e-01, time/batch = 0.6868s	
15212/28500 (epoch 26.688), train_loss = 0.84218904, grad/param norm = 1.3615e-01, time/batch = 0.6840s	
15213/28500 (epoch 26.689), train_loss = 0.87567276, grad/param norm = 1.7523e-01, time/batch = 0.6922s	
15214/28500 (epoch 26.691), train_loss = 0.95832960, grad/param norm = 1.6532e-01, time/batch = 0.6816s	
15215/28500 (epoch 26.693), train_loss = 0.90688662, grad/param norm = 1.7301e-01, time/batch = 0.6844s	
15216/28500 (epoch 26.695), train_loss = 0.71246230, grad/param norm = 2.4498e-01, time/batch = 0.6793s	
15217/28500 (epoch 26.696), train_loss = 0.91660520, grad/param norm = 1.7220e-01, time/batch = 0.6797s	
15218/28500 (epoch 26.698), train_loss = 0.92884658, grad/param norm = 1.5571e-01, time/batch = 0.6796s	
15219/28500 (epoch 26.700), train_loss = 0.94320123, grad/param norm = 1.6781e-01, time/batch = 0.6801s	
15220/28500 (epoch 26.702), train_loss = 0.94525189, grad/param norm = 1.7560e-01, time/batch = 0.6796s	
15221/28500 (epoch 26.704), train_loss = 0.96471572, grad/param norm = 1.8122e-01, time/batch = 0.6840s	
15222/28500 (epoch 26.705), train_loss = 1.03945509, grad/param norm = 2.0768e-01, time/batch = 0.6823s	
15223/28500 (epoch 26.707), train_loss = 0.87540260, grad/param norm = 1.7284e-01, time/batch = 0.6820s	
15224/28500 (epoch 26.709), train_loss = 1.05370315, grad/param norm = 1.6605e-01, time/batch = 0.6810s	
15225/28500 (epoch 26.711), train_loss = 0.87080787, grad/param norm = 1.5844e-01, time/batch = 0.6820s	
15226/28500 (epoch 26.712), train_loss = 0.95115320, grad/param norm = 1.6765e-01, time/batch = 0.6804s	
15227/28500 (epoch 26.714), train_loss = 1.06178339, grad/param norm = 1.8117e-01, time/batch = 0.6789s	
15228/28500 (epoch 26.716), train_loss = 0.92161830, grad/param norm = 1.5931e-01, time/batch = 0.6792s	
15229/28500 (epoch 26.718), train_loss = 0.95837570, grad/param norm = 1.6687e-01, time/batch = 0.6794s	
15230/28500 (epoch 26.719), train_loss = 0.94442142, grad/param norm = 1.6776e-01, time/batch = 0.6785s	
15231/28500 (epoch 26.721), train_loss = 0.77032458, grad/param norm = 1.5813e-01, time/batch = 0.6851s	
15232/28500 (epoch 26.723), train_loss = 0.94540683, grad/param norm = 1.7117e-01, time/batch = 0.6819s	
15233/28500 (epoch 26.725), train_loss = 1.00925884, grad/param norm = 1.6621e-01, time/batch = 0.6807s	
15234/28500 (epoch 26.726), train_loss = 0.93465604, grad/param norm = 1.7521e-01, time/batch = 0.6787s	
15235/28500 (epoch 26.728), train_loss = 0.86554947, grad/param norm = 1.6281e-01, time/batch = 0.6792s	
15236/28500 (epoch 26.730), train_loss = 0.94291971, grad/param norm = 1.8780e-01, time/batch = 0.6794s	
15237/28500 (epoch 26.732), train_loss = 0.75236782, grad/param norm = 1.4176e-01, time/batch = 0.6792s	
15238/28500 (epoch 26.733), train_loss = 0.80180007, grad/param norm = 1.5503e-01, time/batch = 0.6829s	
15239/28500 (epoch 26.735), train_loss = 0.80144645, grad/param norm = 1.5066e-01, time/batch = 0.6809s	
15240/28500 (epoch 26.737), train_loss = 0.73057710, grad/param norm = 1.6136e-01, time/batch = 0.6791s	
15241/28500 (epoch 26.739), train_loss = 0.86289331, grad/param norm = 1.6787e-01, time/batch = 0.6807s	
15242/28500 (epoch 26.740), train_loss = 0.92670209, grad/param norm = 1.5471e-01, time/batch = 0.6810s	
15243/28500 (epoch 26.742), train_loss = 0.87309701, grad/param norm = 1.7388e-01, time/batch = 0.6796s	
15244/28500 (epoch 26.744), train_loss = 0.94255243, grad/param norm = 1.6806e-01, time/batch = 0.6790s	
15245/28500 (epoch 26.746), train_loss = 0.86776252, grad/param norm = 1.5096e-01, time/batch = 0.7018s	
15246/28500 (epoch 26.747), train_loss = 0.86972905, grad/param norm = 1.5564e-01, time/batch = 0.6813s	
15247/28500 (epoch 26.749), train_loss = 1.00068065, grad/param norm = 2.0028e-01, time/batch = 0.6803s	
15248/28500 (epoch 26.751), train_loss = 0.83572123, grad/param norm = 1.9136e-01, time/batch = 0.6812s	
15249/28500 (epoch 26.753), train_loss = 0.91131052, grad/param norm = 1.7969e-01, time/batch = 0.6858s	
15250/28500 (epoch 26.754), train_loss = 0.82823737, grad/param norm = 1.5070e-01, time/batch = 0.6825s	
15251/28500 (epoch 26.756), train_loss = 1.04021931, grad/param norm = 1.7572e-01, time/batch = 0.6816s	
15252/28500 (epoch 26.758), train_loss = 1.00132688, grad/param norm = 2.7928e-01, time/batch = 0.6889s	
15253/28500 (epoch 26.760), train_loss = 0.83798881, grad/param norm = 2.0050e-01, time/batch = 0.6804s	
15254/28500 (epoch 26.761), train_loss = 0.86693241, grad/param norm = 1.9246e-01, time/batch = 0.6800s	
15255/28500 (epoch 26.763), train_loss = 0.74829131, grad/param norm = 1.5028e-01, time/batch = 0.6815s	
15256/28500 (epoch 26.765), train_loss = 0.90645608, grad/param norm = 1.6130e-01, time/batch = 0.6812s	
15257/28500 (epoch 26.767), train_loss = 0.79346546, grad/param norm = 1.5208e-01, time/batch = 0.6803s	
15258/28500 (epoch 26.768), train_loss = 0.98256552, grad/param norm = 1.6050e-01, time/batch = 0.6803s	
15259/28500 (epoch 26.770), train_loss = 0.82535436, grad/param norm = 1.7977e-01, time/batch = 0.6802s	
15260/28500 (epoch 26.772), train_loss = 0.73284374, grad/param norm = 1.3891e-01, time/batch = 0.6804s	
15261/28500 (epoch 26.774), train_loss = 0.94065346, grad/param norm = 1.6894e-01, time/batch = 0.6825s	
15262/28500 (epoch 26.775), train_loss = 1.01116974, grad/param norm = 1.7177e-01, time/batch = 0.6808s	
15263/28500 (epoch 26.777), train_loss = 1.00262246, grad/param norm = 1.5061e-01, time/batch = 0.6796s	
15264/28500 (epoch 26.779), train_loss = 0.75275116, grad/param norm = 1.3323e-01, time/batch = 0.6796s	
15265/28500 (epoch 26.781), train_loss = 0.90734982, grad/param norm = 1.6609e-01, time/batch = 0.6792s	
15266/28500 (epoch 26.782), train_loss = 0.96565853, grad/param norm = 1.8143e-01, time/batch = 0.6763s	
15267/28500 (epoch 26.784), train_loss = 0.75211418, grad/param norm = 1.5530e-01, time/batch = 0.6766s	
15268/28500 (epoch 26.786), train_loss = 0.80373635, grad/param norm = 1.4540e-01, time/batch = 0.6758s	
15269/28500 (epoch 26.788), train_loss = 0.92085892, grad/param norm = 2.1511e-01, time/batch = 0.6899s	
15270/28500 (epoch 26.789), train_loss = 0.69471053, grad/param norm = 2.4238e-01, time/batch = 0.6939s	
15271/28500 (epoch 26.791), train_loss = 0.95468202, grad/param norm = 1.7139e-01, time/batch = 0.6823s	
15272/28500 (epoch 26.793), train_loss = 0.91002700, grad/param norm = 1.5893e-01, time/batch = 0.6831s	
15273/28500 (epoch 26.795), train_loss = 0.94574042, grad/param norm = 1.6468e-01, time/batch = 0.6791s	
15274/28500 (epoch 26.796), train_loss = 0.82240749, grad/param norm = 1.5365e-01, time/batch = 0.6768s	
15275/28500 (epoch 26.798), train_loss = 0.75340771, grad/param norm = 1.4724e-01, time/batch = 0.6852s	
15276/28500 (epoch 26.800), train_loss = 0.79057790, grad/param norm = 1.6969e-01, time/batch = 0.6911s	
15277/28500 (epoch 26.802), train_loss = 0.88176921, grad/param norm = 2.0698e-01, time/batch = 0.7086s	
15278/28500 (epoch 26.804), train_loss = 0.93737584, grad/param norm = 1.5978e-01, time/batch = 0.6914s	
15279/28500 (epoch 26.805), train_loss = 0.92973324, grad/param norm = 1.7790e-01, time/batch = 0.6799s	
15280/28500 (epoch 26.807), train_loss = 0.94094857, grad/param norm = 1.7288e-01, time/batch = 0.6860s	
15281/28500 (epoch 26.809), train_loss = 0.93045174, grad/param norm = 1.7345e-01, time/batch = 0.7009s	
15282/28500 (epoch 26.811), train_loss = 0.96751270, grad/param norm = 1.9216e-01, time/batch = 0.6943s	
15283/28500 (epoch 26.812), train_loss = 0.94617379, grad/param norm = 2.0000e-01, time/batch = 0.6862s	
15284/28500 (epoch 26.814), train_loss = 0.86764983, grad/param norm = 1.7485e-01, time/batch = 0.6838s	
15285/28500 (epoch 26.816), train_loss = 0.97589664, grad/param norm = 1.8335e-01, time/batch = 0.6923s	
15286/28500 (epoch 26.818), train_loss = 1.03866962, grad/param norm = 1.7774e-01, time/batch = 0.6849s	
15287/28500 (epoch 26.819), train_loss = 0.92990934, grad/param norm = 1.6545e-01, time/batch = 0.6924s	
15288/28500 (epoch 26.821), train_loss = 0.88812147, grad/param norm = 1.4662e-01, time/batch = 0.6997s	
15289/28500 (epoch 26.823), train_loss = 1.04876830, grad/param norm = 2.0324e-01, time/batch = 0.7035s	
15290/28500 (epoch 26.825), train_loss = 0.89749337, grad/param norm = 2.0649e-01, time/batch = 0.6761s	
15291/28500 (epoch 26.826), train_loss = 0.94016482, grad/param norm = 1.8296e-01, time/batch = 0.6780s	
15292/28500 (epoch 26.828), train_loss = 0.82661534, grad/param norm = 1.6411e-01, time/batch = 0.6785s	
15293/28500 (epoch 26.830), train_loss = 0.88697924, grad/param norm = 1.4823e-01, time/batch = 0.6790s	
15294/28500 (epoch 26.832), train_loss = 0.92596443, grad/param norm = 2.0186e-01, time/batch = 0.6773s	
15295/28500 (epoch 26.833), train_loss = 1.01285250, grad/param norm = 1.7553e-01, time/batch = 0.6788s	
15296/28500 (epoch 26.835), train_loss = 0.85767967, grad/param norm = 1.7039e-01, time/batch = 0.6762s	
15297/28500 (epoch 26.837), train_loss = 0.79610969, grad/param norm = 1.5686e-01, time/batch = 0.6806s	
15298/28500 (epoch 26.839), train_loss = 1.06957271, grad/param norm = 2.0363e-01, time/batch = 0.6774s	
15299/28500 (epoch 26.840), train_loss = 1.07980011, grad/param norm = 1.9433e-01, time/batch = 0.6755s	
15300/28500 (epoch 26.842), train_loss = 0.96712216, grad/param norm = 1.9398e-01, time/batch = 0.6756s	
15301/28500 (epoch 26.844), train_loss = 0.95730692, grad/param norm = 1.8131e-01, time/batch = 0.6779s	
15302/28500 (epoch 26.846), train_loss = 1.07967334, grad/param norm = 2.2305e-01, time/batch = 0.6764s	
15303/28500 (epoch 26.847), train_loss = 0.89944379, grad/param norm = 1.6765e-01, time/batch = 0.6760s	
15304/28500 (epoch 26.849), train_loss = 0.90830400, grad/param norm = 1.7353e-01, time/batch = 0.6910s	
15305/28500 (epoch 26.851), train_loss = 0.79151651, grad/param norm = 1.4948e-01, time/batch = 0.6782s	
15306/28500 (epoch 26.853), train_loss = 0.94941661, grad/param norm = 1.8945e-01, time/batch = 0.6762s	
15307/28500 (epoch 26.854), train_loss = 0.92689146, grad/param norm = 1.6886e-01, time/batch = 0.6754s	
15308/28500 (epoch 26.856), train_loss = 1.06710838, grad/param norm = 2.3644e-01, time/batch = 0.6758s	
15309/28500 (epoch 26.858), train_loss = 0.87346206, grad/param norm = 1.8169e-01, time/batch = 0.6759s	
15310/28500 (epoch 26.860), train_loss = 0.88656110, grad/param norm = 1.8581e-01, time/batch = 0.6872s	
15311/28500 (epoch 26.861), train_loss = 0.97229223, grad/param norm = 1.9010e-01, time/batch = 0.6808s	
15312/28500 (epoch 26.863), train_loss = 0.97052965, grad/param norm = 1.9749e-01, time/batch = 0.6794s	
15313/28500 (epoch 26.865), train_loss = 0.85922080, grad/param norm = 1.7811e-01, time/batch = 0.6759s	
15314/28500 (epoch 26.867), train_loss = 0.97485595, grad/param norm = 1.9875e-01, time/batch = 0.6770s	
15315/28500 (epoch 26.868), train_loss = 0.81022051, grad/param norm = 1.5617e-01, time/batch = 0.6779s	
15316/28500 (epoch 26.870), train_loss = 0.81073116, grad/param norm = 1.6575e-01, time/batch = 0.6885s	
15317/28500 (epoch 26.872), train_loss = 0.95694667, grad/param norm = 2.0589e-01, time/batch = 0.6775s	
15318/28500 (epoch 26.874), train_loss = 0.87328551, grad/param norm = 1.9558e-01, time/batch = 0.6803s	
15319/28500 (epoch 26.875), train_loss = 1.05849077, grad/param norm = 1.9181e-01, time/batch = 0.6794s	
15320/28500 (epoch 26.877), train_loss = 0.93596083, grad/param norm = 1.7461e-01, time/batch = 0.6775s	
15321/28500 (epoch 26.879), train_loss = 0.98264042, grad/param norm = 1.5707e-01, time/batch = 0.6796s	
15322/28500 (epoch 26.881), train_loss = 0.95456130, grad/param norm = 1.8052e-01, time/batch = 0.6857s	
15323/28500 (epoch 26.882), train_loss = 0.85245946, grad/param norm = 1.5184e-01, time/batch = 0.6811s	
15324/28500 (epoch 26.884), train_loss = 0.93134780, grad/param norm = 1.8806e-01, time/batch = 0.6765s	
15325/28500 (epoch 26.886), train_loss = 0.90161327, grad/param norm = 1.6472e-01, time/batch = 0.6762s	
15326/28500 (epoch 26.888), train_loss = 0.86015713, grad/param norm = 1.5336e-01, time/batch = 0.6768s	
15327/28500 (epoch 26.889), train_loss = 0.92822840, grad/param norm = 1.5855e-01, time/batch = 0.6781s	
15328/28500 (epoch 26.891), train_loss = 0.91540036, grad/param norm = 1.6528e-01, time/batch = 0.6780s	
15329/28500 (epoch 26.893), train_loss = 0.89262408, grad/param norm = 1.6614e-01, time/batch = 0.6761s	
15330/28500 (epoch 26.895), train_loss = 1.06634561, grad/param norm = 1.8192e-01, time/batch = 0.6765s	
15331/28500 (epoch 26.896), train_loss = 1.02495985, grad/param norm = 1.8339e-01, time/batch = 0.6804s	
15332/28500 (epoch 26.898), train_loss = 0.95272199, grad/param norm = 1.8727e-01, time/batch = 0.6795s	
15333/28500 (epoch 26.900), train_loss = 0.79534745, grad/param norm = 1.4838e-01, time/batch = 0.6907s	
15334/28500 (epoch 26.902), train_loss = 0.81379544, grad/param norm = 1.7643e-01, time/batch = 0.6804s	
15335/28500 (epoch 26.904), train_loss = 0.82063926, grad/param norm = 1.4797e-01, time/batch = 0.6769s	
15336/28500 (epoch 26.905), train_loss = 0.89732946, grad/param norm = 1.7533e-01, time/batch = 0.6771s	
15337/28500 (epoch 26.907), train_loss = 0.91500216, grad/param norm = 1.9961e-01, time/batch = 0.6789s	
15338/28500 (epoch 26.909), train_loss = 0.82027771, grad/param norm = 1.8945e-01, time/batch = 0.6786s	
15339/28500 (epoch 26.911), train_loss = 0.82058715, grad/param norm = 1.5346e-01, time/batch = 0.6794s	
15340/28500 (epoch 26.912), train_loss = 0.73033889, grad/param norm = 1.6057e-01, time/batch = 0.6759s	
15341/28500 (epoch 26.914), train_loss = 0.95414314, grad/param norm = 1.7301e-01, time/batch = 0.6786s	
15342/28500 (epoch 26.916), train_loss = 0.90709011, grad/param norm = 1.5384e-01, time/batch = 0.6766s	
15343/28500 (epoch 26.918), train_loss = 0.90829772, grad/param norm = 1.7375e-01, time/batch = 0.6761s	
15344/28500 (epoch 26.919), train_loss = 0.90343725, grad/param norm = 1.5616e-01, time/batch = 0.6765s	
15345/28500 (epoch 26.921), train_loss = 1.02544993, grad/param norm = 2.2784e-01, time/batch = 0.6763s	
15346/28500 (epoch 26.923), train_loss = 0.88721086, grad/param norm = 1.9241e-01, time/batch = 0.6761s	
15347/28500 (epoch 26.925), train_loss = 0.85095880, grad/param norm = 1.7324e-01, time/batch = 0.6765s	
15348/28500 (epoch 26.926), train_loss = 0.91901725, grad/param norm = 1.6851e-01, time/batch = 0.6780s	
15349/28500 (epoch 26.928), train_loss = 0.87215977, grad/param norm = 1.6404e-01, time/batch = 0.6759s	
15350/28500 (epoch 26.930), train_loss = 0.72297004, grad/param norm = 1.3139e-01, time/batch = 0.6758s	
15351/28500 (epoch 26.932), train_loss = 0.73222382, grad/param norm = 1.3169e-01, time/batch = 0.6778s	
15352/28500 (epoch 26.933), train_loss = 0.97709694, grad/param norm = 1.6792e-01, time/batch = 0.6774s	
15353/28500 (epoch 26.935), train_loss = 1.00520302, grad/param norm = 1.7333e-01, time/batch = 0.6762s	
15354/28500 (epoch 26.937), train_loss = 1.01399623, grad/param norm = 1.9223e-01, time/batch = 0.6764s	
15355/28500 (epoch 26.939), train_loss = 1.07712697, grad/param norm = 2.0757e-01, time/batch = 0.6770s	
15356/28500 (epoch 26.940), train_loss = 0.80555429, grad/param norm = 1.5321e-01, time/batch = 0.6788s	
15357/28500 (epoch 26.942), train_loss = 0.92469241, grad/param norm = 1.7556e-01, time/batch = 0.6779s	
15358/28500 (epoch 26.944), train_loss = 0.86567289, grad/param norm = 1.9157e-01, time/batch = 0.6765s	
15359/28500 (epoch 26.946), train_loss = 0.99562922, grad/param norm = 1.7502e-01, time/batch = 0.6776s	
15360/28500 (epoch 26.947), train_loss = 1.20439664, grad/param norm = 2.4305e-01, time/batch = 0.6773s	
15361/28500 (epoch 26.949), train_loss = 0.89191919, grad/param norm = 1.9485e-01, time/batch = 0.6781s	
15362/28500 (epoch 26.951), train_loss = 1.10569670, grad/param norm = 1.8533e-01, time/batch = 0.6790s	
15363/28500 (epoch 26.953), train_loss = 1.07910061, grad/param norm = 1.9430e-01, time/batch = 0.6831s	
15364/28500 (epoch 26.954), train_loss = 1.03745389, grad/param norm = 2.0506e-01, time/batch = 0.6859s	
15365/28500 (epoch 26.956), train_loss = 0.92150274, grad/param norm = 2.2552e-01, time/batch = 0.6818s	
15366/28500 (epoch 26.958), train_loss = 1.13562889, grad/param norm = 1.7881e-01, time/batch = 0.6789s	
15367/28500 (epoch 26.960), train_loss = 0.88027373, grad/param norm = 1.8089e-01, time/batch = 0.6768s	
15368/28500 (epoch 26.961), train_loss = 1.08560310, grad/param norm = 2.0923e-01, time/batch = 0.6770s	
15369/28500 (epoch 26.963), train_loss = 1.04558621, grad/param norm = 1.8523e-01, time/batch = 0.6771s	
15370/28500 (epoch 26.965), train_loss = 0.84867451, grad/param norm = 1.6279e-01, time/batch = 0.6783s	
15371/28500 (epoch 26.967), train_loss = 0.85104420, grad/param norm = 1.5878e-01, time/batch = 0.6808s	
15372/28500 (epoch 26.968), train_loss = 0.79652682, grad/param norm = 1.4481e-01, time/batch = 0.6793s	
15373/28500 (epoch 26.970), train_loss = 0.84141374, grad/param norm = 1.8342e-01, time/batch = 0.6797s	
15374/28500 (epoch 26.972), train_loss = 0.93668436, grad/param norm = 1.7627e-01, time/batch = 0.6776s	
15375/28500 (epoch 26.974), train_loss = 1.10397845, grad/param norm = 2.0133e-01, time/batch = 0.6765s	
15376/28500 (epoch 26.975), train_loss = 0.85753144, grad/param norm = 1.8042e-01, time/batch = 0.6767s	
15377/28500 (epoch 26.977), train_loss = 1.01565326, grad/param norm = 1.8046e-01, time/batch = 0.6765s	
15378/28500 (epoch 26.979), train_loss = 0.91155569, grad/param norm = 1.7971e-01, time/batch = 0.6762s	
15379/28500 (epoch 26.981), train_loss = 0.83409219, grad/param norm = 1.7906e-01, time/batch = 0.6809s	
15380/28500 (epoch 26.982), train_loss = 0.89561883, grad/param norm = 1.7374e-01, time/batch = 0.6778s	
15381/28500 (epoch 26.984), train_loss = 0.99053532, grad/param norm = 1.5994e-01, time/batch = 0.6819s	
15382/28500 (epoch 26.986), train_loss = 1.18726374, grad/param norm = 1.9575e-01, time/batch = 0.6793s	
15383/28500 (epoch 26.988), train_loss = 0.81048476, grad/param norm = 1.5150e-01, time/batch = 0.6810s	
15384/28500 (epoch 26.989), train_loss = 0.97375573, grad/param norm = 1.7131e-01, time/batch = 0.6810s	
15385/28500 (epoch 26.991), train_loss = 0.84392741, grad/param norm = 1.8919e-01, time/batch = 0.6836s	
15386/28500 (epoch 26.993), train_loss = 0.87495897, grad/param norm = 1.7907e-01, time/batch = 0.6801s	
15387/28500 (epoch 26.995), train_loss = 0.87468335, grad/param norm = 1.6908e-01, time/batch = 0.6807s	
15388/28500 (epoch 26.996), train_loss = 0.84361728, grad/param norm = 1.6940e-01, time/batch = 0.6796s	
15389/28500 (epoch 26.998), train_loss = 1.05676222, grad/param norm = 2.3282e-01, time/batch = 0.6807s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
15390/28500 (epoch 27.000), train_loss = 0.92225875, grad/param norm = 1.7772e-01, time/batch = 0.6809s	
15391/28500 (epoch 27.002), train_loss = 1.10959986, grad/param norm = 2.0276e-01, time/batch = 0.6838s	
15392/28500 (epoch 27.004), train_loss = 0.89435518, grad/param norm = 1.6239e-01, time/batch = 0.6812s	
15393/28500 (epoch 27.005), train_loss = 1.05370890, grad/param norm = 1.9872e-01, time/batch = 0.6823s	
15394/28500 (epoch 27.007), train_loss = 0.82319202, grad/param norm = 1.4215e-01, time/batch = 0.6807s	
15395/28500 (epoch 27.009), train_loss = 0.95925952, grad/param norm = 1.8548e-01, time/batch = 0.6819s	
15396/28500 (epoch 27.011), train_loss = 0.88413569, grad/param norm = 1.8999e-01, time/batch = 0.6823s	
15397/28500 (epoch 27.012), train_loss = 0.83195910, grad/param norm = 1.4968e-01, time/batch = 0.6795s	
15398/28500 (epoch 27.014), train_loss = 0.84990544, grad/param norm = 1.7642e-01, time/batch = 0.6797s	
15399/28500 (epoch 27.016), train_loss = 0.88304305, grad/param norm = 1.7062e-01, time/batch = 0.6811s	
15400/28500 (epoch 27.018), train_loss = 0.96098253, grad/param norm = 1.9273e-01, time/batch = 0.6792s	
15401/28500 (epoch 27.019), train_loss = 1.01519389, grad/param norm = 1.6966e-01, time/batch = 0.6843s	
15402/28500 (epoch 27.021), train_loss = 1.00790191, grad/param norm = 1.5313e-01, time/batch = 0.6808s	
15403/28500 (epoch 27.023), train_loss = 0.95126785, grad/param norm = 1.8235e-01, time/batch = 0.6794s	
15404/28500 (epoch 27.025), train_loss = 0.95199920, grad/param norm = 1.6878e-01, time/batch = 0.6791s	
15405/28500 (epoch 27.026), train_loss = 0.91837369, grad/param norm = 1.6564e-01, time/batch = 0.6824s	
15406/28500 (epoch 27.028), train_loss = 0.95496658, grad/param norm = 1.8997e-01, time/batch = 0.6806s	
15407/28500 (epoch 27.030), train_loss = 1.00577904, grad/param norm = 1.9972e-01, time/batch = 0.6796s	
15408/28500 (epoch 27.032), train_loss = 1.03743347, grad/param norm = 1.8242e-01, time/batch = 0.6796s	
15409/28500 (epoch 27.033), train_loss = 1.09676925, grad/param norm = 1.8727e-01, time/batch = 0.6794s	
15410/28500 (epoch 27.035), train_loss = 0.93157080, grad/param norm = 1.7332e-01, time/batch = 0.6792s	
15411/28500 (epoch 27.037), train_loss = 0.98968057, grad/param norm = 1.6052e-01, time/batch = 0.6821s	
15412/28500 (epoch 27.039), train_loss = 1.02705420, grad/param norm = 1.7595e-01, time/batch = 0.6799s	
15413/28500 (epoch 27.040), train_loss = 1.04765004, grad/param norm = 1.6444e-01, time/batch = 0.6796s	
15414/28500 (epoch 27.042), train_loss = 1.00708616, grad/param norm = 1.8712e-01, time/batch = 0.6792s	
15415/28500 (epoch 27.044), train_loss = 0.95629643, grad/param norm = 1.8450e-01, time/batch = 0.6794s	
15416/28500 (epoch 27.046), train_loss = 1.14666065, grad/param norm = 1.8461e-01, time/batch = 0.6791s	
15417/28500 (epoch 27.047), train_loss = 1.07903928, grad/param norm = 1.9098e-01, time/batch = 0.6796s	
15418/28500 (epoch 27.049), train_loss = 0.97075630, grad/param norm = 1.7834e-01, time/batch = 0.6813s	
15419/28500 (epoch 27.051), train_loss = 0.94393010, grad/param norm = 1.8008e-01, time/batch = 0.6785s	
15420/28500 (epoch 27.053), train_loss = 0.93503224, grad/param norm = 1.6533e-01, time/batch = 0.6850s	
15421/28500 (epoch 27.054), train_loss = 1.02867416, grad/param norm = 1.8287e-01, time/batch = 0.6824s	
15422/28500 (epoch 27.056), train_loss = 0.87132447, grad/param norm = 1.5620e-01, time/batch = 0.6843s	
15423/28500 (epoch 27.058), train_loss = 0.86393641, grad/param norm = 1.6317e-01, time/batch = 0.6890s	
15424/28500 (epoch 27.060), train_loss = 0.98714017, grad/param norm = 1.6565e-01, time/batch = 0.6943s	
15425/28500 (epoch 27.061), train_loss = 0.92052558, grad/param norm = 1.7265e-01, time/batch = 0.6868s	
15426/28500 (epoch 27.063), train_loss = 1.01286021, grad/param norm = 1.7991e-01, time/batch = 0.6852s	
15427/28500 (epoch 27.065), train_loss = 1.00399898, grad/param norm = 1.9410e-01, time/batch = 0.6853s	
15428/28500 (epoch 27.067), train_loss = 0.91428622, grad/param norm = 1.6258e-01, time/batch = 0.6821s	
15429/28500 (epoch 27.068), train_loss = 0.92841586, grad/param norm = 1.6245e-01, time/batch = 0.6808s	
15430/28500 (epoch 27.070), train_loss = 0.98056923, grad/param norm = 1.7617e-01, time/batch = 0.6898s	
15431/28500 (epoch 27.072), train_loss = 1.07661584, grad/param norm = 1.8940e-01, time/batch = 0.6804s	
15432/28500 (epoch 27.074), train_loss = 0.96074614, grad/param norm = 1.7180e-01, time/batch = 0.6804s	
15433/28500 (epoch 27.075), train_loss = 0.92094422, grad/param norm = 1.5912e-01, time/batch = 0.6786s	
15434/28500 (epoch 27.077), train_loss = 1.01713163, grad/param norm = 1.6787e-01, time/batch = 0.6821s	
15435/28500 (epoch 27.079), train_loss = 0.94729815, grad/param norm = 1.6210e-01, time/batch = 0.6794s	
15436/28500 (epoch 27.081), train_loss = 1.06458159, grad/param norm = 1.8544e-01, time/batch = 0.6801s	
15437/28500 (epoch 27.082), train_loss = 0.96926698, grad/param norm = 2.1264e-01, time/batch = 0.6794s	
15438/28500 (epoch 27.084), train_loss = 0.98588647, grad/param norm = 1.6594e-01, time/batch = 0.6798s	
15439/28500 (epoch 27.086), train_loss = 0.92957761, grad/param norm = 2.4439e-01, time/batch = 0.6790s	
15440/28500 (epoch 27.088), train_loss = 0.86514455, grad/param norm = 1.6312e-01, time/batch = 0.6812s	
15441/28500 (epoch 27.089), train_loss = 1.04749920, grad/param norm = 1.6158e-01, time/batch = 0.6836s	
15442/28500 (epoch 27.091), train_loss = 0.82870187, grad/param norm = 1.6019e-01, time/batch = 0.6805s	
15443/28500 (epoch 27.093), train_loss = 1.01055123, grad/param norm = 1.7030e-01, time/batch = 0.6790s	
15444/28500 (epoch 27.095), train_loss = 0.91002203, grad/param norm = 1.5202e-01, time/batch = 0.6797s	
15445/28500 (epoch 27.096), train_loss = 1.04691451, grad/param norm = 1.7855e-01, time/batch = 0.6797s	
15446/28500 (epoch 27.098), train_loss = 0.95836830, grad/param norm = 1.8120e-01, time/batch = 0.6794s	
15447/28500 (epoch 27.100), train_loss = 0.89596709, grad/param norm = 1.6821e-01, time/batch = 0.6786s	
15448/28500 (epoch 27.102), train_loss = 1.02228974, grad/param norm = 1.8364e-01, time/batch = 0.6795s	
15449/28500 (epoch 27.104), train_loss = 0.94680210, grad/param norm = 1.9471e-01, time/batch = 0.6781s	
15450/28500 (epoch 27.105), train_loss = 1.06447217, grad/param norm = 1.7695e-01, time/batch = 0.6798s	
15451/28500 (epoch 27.107), train_loss = 0.85877222, grad/param norm = 1.5803e-01, time/batch = 0.6843s	
15452/28500 (epoch 27.109), train_loss = 0.86169786, grad/param norm = 1.8082e-01, time/batch = 0.7044s	
15453/28500 (epoch 27.111), train_loss = 0.89705503, grad/param norm = 1.8091e-01, time/batch = 0.6818s	
15454/28500 (epoch 27.112), train_loss = 1.02458154, grad/param norm = 1.7361e-01, time/batch = 0.6797s	
15455/28500 (epoch 27.114), train_loss = 0.91123869, grad/param norm = 1.5797e-01, time/batch = 0.6793s	
15456/28500 (epoch 27.116), train_loss = 1.08585795, grad/param norm = 1.8348e-01, time/batch = 0.6810s	
15457/28500 (epoch 27.118), train_loss = 0.84317152, grad/param norm = 1.8819e-01, time/batch = 0.6817s	
15458/28500 (epoch 27.119), train_loss = 0.98774728, grad/param norm = 1.8296e-01, time/batch = 0.6822s	
15459/28500 (epoch 27.121), train_loss = 1.13271623, grad/param norm = 2.4350e-01, time/batch = 0.6804s	
15460/28500 (epoch 27.123), train_loss = 1.02702523, grad/param norm = 1.8427e-01, time/batch = 0.6814s	
15461/28500 (epoch 27.125), train_loss = 0.98732632, grad/param norm = 2.0275e-01, time/batch = 0.6852s	
15462/28500 (epoch 27.126), train_loss = 0.95170083, grad/param norm = 1.6452e-01, time/batch = 0.6819s	
15463/28500 (epoch 27.128), train_loss = 0.96588827, grad/param norm = 1.7545e-01, time/batch = 0.6822s	
15464/28500 (epoch 27.130), train_loss = 0.87823569, grad/param norm = 1.9672e-01, time/batch = 0.6816s	
15465/28500 (epoch 27.132), train_loss = 0.95153846, grad/param norm = 1.8907e-01, time/batch = 0.6796s	
15466/28500 (epoch 27.133), train_loss = 1.00663980, grad/param norm = 1.9383e-01, time/batch = 0.6848s	
15467/28500 (epoch 27.135), train_loss = 0.90976948, grad/param norm = 1.5864e-01, time/batch = 0.6805s	
15468/28500 (epoch 27.137), train_loss = 0.95995599, grad/param norm = 1.5574e-01, time/batch = 0.6827s	
15469/28500 (epoch 27.139), train_loss = 0.95505495, grad/param norm = 1.6661e-01, time/batch = 0.6835s	
15470/28500 (epoch 27.140), train_loss = 0.96572649, grad/param norm = 1.6523e-01, time/batch = 0.6782s	
15471/28500 (epoch 27.142), train_loss = 0.92233155, grad/param norm = 1.7491e-01, time/batch = 0.6822s	
15472/28500 (epoch 27.144), train_loss = 0.86869305, grad/param norm = 1.6274e-01, time/batch = 0.6809s	
15473/28500 (epoch 27.146), train_loss = 0.91460300, grad/param norm = 1.5013e-01, time/batch = 0.6800s	
15474/28500 (epoch 27.147), train_loss = 0.82160656, grad/param norm = 1.5335e-01, time/batch = 0.6807s	
15475/28500 (epoch 27.149), train_loss = 0.82067182, grad/param norm = 1.5725e-01, time/batch = 0.6810s	
15476/28500 (epoch 27.151), train_loss = 0.90214947, grad/param norm = 1.5897e-01, time/batch = 0.6787s	
15477/28500 (epoch 27.153), train_loss = 0.96653267, grad/param norm = 1.7611e-01, time/batch = 0.6796s	
15478/28500 (epoch 27.154), train_loss = 0.85232860, grad/param norm = 1.6255e-01, time/batch = 0.6799s	
15479/28500 (epoch 27.156), train_loss = 1.03395345, grad/param norm = 1.8689e-01, time/batch = 0.6796s	
15480/28500 (epoch 27.158), train_loss = 0.96155534, grad/param norm = 1.6248e-01, time/batch = 0.6793s	
15481/28500 (epoch 27.160), train_loss = 0.86351697, grad/param norm = 1.6494e-01, time/batch = 0.6827s	
15482/28500 (epoch 27.161), train_loss = 0.89839177, grad/param norm = 1.8223e-01, time/batch = 0.6817s	
15483/28500 (epoch 27.163), train_loss = 0.81143809, grad/param norm = 1.7321e-01, time/batch = 0.6819s	
15484/28500 (epoch 27.165), train_loss = 1.12175402, grad/param norm = 1.6631e-01, time/batch = 0.6805s	
15485/28500 (epoch 27.167), train_loss = 1.12809893, grad/param norm = 1.8662e-01, time/batch = 0.6800s	
15486/28500 (epoch 27.168), train_loss = 1.05591728, grad/param norm = 1.6915e-01, time/batch = 0.6808s	
15487/28500 (epoch 27.170), train_loss = 1.02675967, grad/param norm = 2.1280e-01, time/batch = 0.6904s	
15488/28500 (epoch 27.172), train_loss = 0.95323750, grad/param norm = 1.6512e-01, time/batch = 0.6798s	
15489/28500 (epoch 27.174), train_loss = 1.11572995, grad/param norm = 2.1285e-01, time/batch = 0.6791s	
15490/28500 (epoch 27.175), train_loss = 0.93234780, grad/param norm = 1.5508e-01, time/batch = 0.6799s	
15491/28500 (epoch 27.177), train_loss = 1.01175142, grad/param norm = 1.7313e-01, time/batch = 0.6820s	
15492/28500 (epoch 27.179), train_loss = 1.00107119, grad/param norm = 1.9577e-01, time/batch = 0.6861s	
15493/28500 (epoch 27.181), train_loss = 1.00601969, grad/param norm = 1.9180e-01, time/batch = 0.6836s	
15494/28500 (epoch 27.182), train_loss = 0.91107426, grad/param norm = 1.5975e-01, time/batch = 0.6807s	
15495/28500 (epoch 27.184), train_loss = 1.10970915, grad/param norm = 1.9100e-01, time/batch = 0.6814s	
15496/28500 (epoch 27.186), train_loss = 1.08935905, grad/param norm = 1.8152e-01, time/batch = 0.6812s	
15497/28500 (epoch 27.188), train_loss = 0.98420817, grad/param norm = 1.6419e-01, time/batch = 0.6856s	
15498/28500 (epoch 27.189), train_loss = 0.94981492, grad/param norm = 1.5121e-01, time/batch = 0.6806s	
15499/28500 (epoch 27.191), train_loss = 1.17434458, grad/param norm = 1.8079e-01, time/batch = 0.6792s	
15500/28500 (epoch 27.193), train_loss = 1.00652803, grad/param norm = 1.9798e-01, time/batch = 0.6803s	
15501/28500 (epoch 27.195), train_loss = 1.11903432, grad/param norm = 1.9481e-01, time/batch = 0.6833s	
15502/28500 (epoch 27.196), train_loss = 1.01351393, grad/param norm = 1.7043e-01, time/batch = 0.6824s	
15503/28500 (epoch 27.198), train_loss = 0.97765702, grad/param norm = 1.8028e-01, time/batch = 0.6794s	
15504/28500 (epoch 27.200), train_loss = 1.02030885, grad/param norm = 1.7309e-01, time/batch = 0.6805s	
15505/28500 (epoch 27.202), train_loss = 0.97313916, grad/param norm = 1.5995e-01, time/batch = 0.6847s	
15506/28500 (epoch 27.204), train_loss = 0.92688602, grad/param norm = 1.5669e-01, time/batch = 0.6816s	
15507/28500 (epoch 27.205), train_loss = 0.93146811, grad/param norm = 1.8271e-01, time/batch = 0.6870s	
15508/28500 (epoch 27.207), train_loss = 0.86047318, grad/param norm = 1.7513e-01, time/batch = 0.6955s	
15509/28500 (epoch 27.209), train_loss = 0.99039342, grad/param norm = 1.8868e-01, time/batch = 0.7031s	
15510/28500 (epoch 27.211), train_loss = 0.84086964, grad/param norm = 1.6983e-01, time/batch = 0.6901s	
15511/28500 (epoch 27.212), train_loss = 0.80259890, grad/param norm = 1.6075e-01, time/batch = 0.6973s	
15512/28500 (epoch 27.214), train_loss = 0.95271881, grad/param norm = 1.8889e-01, time/batch = 0.6871s	
15513/28500 (epoch 27.216), train_loss = 0.89980432, grad/param norm = 2.0159e-01, time/batch = 0.6812s	
15514/28500 (epoch 27.218), train_loss = 1.06216837, grad/param norm = 1.7726e-01, time/batch = 0.6844s	
15515/28500 (epoch 27.219), train_loss = 0.98605217, grad/param norm = 1.6955e-01, time/batch = 0.6994s	
15516/28500 (epoch 27.221), train_loss = 0.83306237, grad/param norm = 1.7129e-01, time/batch = 0.6837s	
15517/28500 (epoch 27.223), train_loss = 1.07449111, grad/param norm = 1.8694e-01, time/batch = 0.6890s	
15518/28500 (epoch 27.225), train_loss = 1.09276902, grad/param norm = 1.9629e-01, time/batch = 0.6792s	
15519/28500 (epoch 27.226), train_loss = 0.90346655, grad/param norm = 1.5337e-01, time/batch = 0.6764s	
15520/28500 (epoch 27.228), train_loss = 1.05042275, grad/param norm = 1.5899e-01, time/batch = 0.6767s	
15521/28500 (epoch 27.230), train_loss = 1.02200297, grad/param norm = 1.7317e-01, time/batch = 0.6793s	
15522/28500 (epoch 27.232), train_loss = 0.99815307, grad/param norm = 1.7915e-01, time/batch = 0.6814s	
15523/28500 (epoch 27.233), train_loss = 0.97753463, grad/param norm = 1.9057e-01, time/batch = 0.6861s	
15524/28500 (epoch 27.235), train_loss = 0.93425728, grad/param norm = 1.5989e-01, time/batch = 0.6782s	
15525/28500 (epoch 27.237), train_loss = 0.85486960, grad/param norm = 1.4768e-01, time/batch = 0.6818s	
15526/28500 (epoch 27.239), train_loss = 0.89779891, grad/param norm = 1.4542e-01, time/batch = 0.6794s	
15527/28500 (epoch 27.240), train_loss = 0.84508276, grad/param norm = 1.6047e-01, time/batch = 0.6783s	
15528/28500 (epoch 27.242), train_loss = 0.96438432, grad/param norm = 1.9983e-01, time/batch = 0.6872s	
15529/28500 (epoch 27.244), train_loss = 0.99184286, grad/param norm = 1.5178e-01, time/batch = 0.6929s	
15530/28500 (epoch 27.246), train_loss = 1.03046634, grad/param norm = 1.7905e-01, time/batch = 0.6868s	
15531/28500 (epoch 27.247), train_loss = 1.07948859, grad/param norm = 1.9497e-01, time/batch = 0.6842s	
15532/28500 (epoch 27.249), train_loss = 0.95863627, grad/param norm = 1.6302e-01, time/batch = 0.6812s	
15533/28500 (epoch 27.251), train_loss = 0.92575103, grad/param norm = 1.5931e-01, time/batch = 0.6978s	
15534/28500 (epoch 27.253), train_loss = 1.07323806, grad/param norm = 1.9348e-01, time/batch = 0.6888s	
15535/28500 (epoch 27.254), train_loss = 1.10784644, grad/param norm = 1.7882e-01, time/batch = 0.6862s	
15536/28500 (epoch 27.256), train_loss = 0.91287328, grad/param norm = 1.6422e-01, time/batch = 0.6778s	
15537/28500 (epoch 27.258), train_loss = 0.92763236, grad/param norm = 1.6406e-01, time/batch = 0.6763s	
15538/28500 (epoch 27.260), train_loss = 0.91476201, grad/param norm = 1.5309e-01, time/batch = 0.6775s	
15539/28500 (epoch 27.261), train_loss = 0.87165629, grad/param norm = 1.6752e-01, time/batch = 0.6790s	
15540/28500 (epoch 27.263), train_loss = 1.03558220, grad/param norm = 1.8374e-01, time/batch = 0.6902s	
15541/28500 (epoch 27.265), train_loss = 0.94453231, grad/param norm = 1.7007e-01, time/batch = 0.6816s	
15542/28500 (epoch 27.267), train_loss = 1.08286856, grad/param norm = 1.8261e-01, time/batch = 0.6788s	
15543/28500 (epoch 27.268), train_loss = 1.00959450, grad/param norm = 1.6416e-01, time/batch = 0.6779s	
15544/28500 (epoch 27.270), train_loss = 0.97787839, grad/param norm = 1.9439e-01, time/batch = 0.6783s	
15545/28500 (epoch 27.272), train_loss = 0.95643092, grad/param norm = 1.6770e-01, time/batch = 0.6810s	
15546/28500 (epoch 27.274), train_loss = 1.03917081, grad/param norm = 1.6506e-01, time/batch = 0.6764s	
15547/28500 (epoch 27.275), train_loss = 1.00664418, grad/param norm = 1.6242e-01, time/batch = 0.6758s	
15548/28500 (epoch 27.277), train_loss = 0.94956994, grad/param norm = 1.6200e-01, time/batch = 0.6769s	
15549/28500 (epoch 27.279), train_loss = 0.96172296, grad/param norm = 1.7507e-01, time/batch = 0.6765s	
15550/28500 (epoch 27.281), train_loss = 1.03617157, grad/param norm = 2.1782e-01, time/batch = 0.6757s	
15551/28500 (epoch 27.282), train_loss = 0.90173809, grad/param norm = 1.5449e-01, time/batch = 0.6793s	
15552/28500 (epoch 27.284), train_loss = 0.95916717, grad/param norm = 1.9328e-01, time/batch = 0.6849s	
15553/28500 (epoch 27.286), train_loss = 1.09456354, grad/param norm = 1.7146e-01, time/batch = 0.6860s	
15554/28500 (epoch 27.288), train_loss = 0.97114444, grad/param norm = 1.8639e-01, time/batch = 0.6798s	
15555/28500 (epoch 27.289), train_loss = 0.99566057, grad/param norm = 1.9143e-01, time/batch = 0.6774s	
15556/28500 (epoch 27.291), train_loss = 0.98124761, grad/param norm = 1.7029e-01, time/batch = 0.6767s	
15557/28500 (epoch 27.293), train_loss = 0.93821764, grad/param norm = 1.7060e-01, time/batch = 0.6895s	
15558/28500 (epoch 27.295), train_loss = 0.84938769, grad/param norm = 1.7324e-01, time/batch = 0.6956s	
15559/28500 (epoch 27.296), train_loss = 0.83004774, grad/param norm = 1.5311e-01, time/batch = 0.6929s	
15560/28500 (epoch 27.298), train_loss = 1.02346230, grad/param norm = 1.7270e-01, time/batch = 0.6850s	
15561/28500 (epoch 27.300), train_loss = 0.87661174, grad/param norm = 1.6593e-01, time/batch = 0.6941s	
15562/28500 (epoch 27.302), train_loss = 0.85324555, grad/param norm = 1.7065e-01, time/batch = 0.6855s	
15563/28500 (epoch 27.304), train_loss = 0.91020958, grad/param norm = 1.5397e-01, time/batch = 0.6839s	
15564/28500 (epoch 27.305), train_loss = 0.99937783, grad/param norm = 1.7038e-01, time/batch = 0.6878s	
15565/28500 (epoch 27.307), train_loss = 0.94456344, grad/param norm = 1.6276e-01, time/batch = 0.6827s	
15566/28500 (epoch 27.309), train_loss = 0.95842712, grad/param norm = 1.6816e-01, time/batch = 0.6791s	
15567/28500 (epoch 27.311), train_loss = 1.00374408, grad/param norm = 1.6489e-01, time/batch = 0.6799s	
15568/28500 (epoch 27.312), train_loss = 0.98308766, grad/param norm = 1.6734e-01, time/batch = 0.6753s	
15569/28500 (epoch 27.314), train_loss = 1.01904647, grad/param norm = 1.9336e-01, time/batch = 0.6758s	
15570/28500 (epoch 27.316), train_loss = 0.97050393, grad/param norm = 1.8912e-01, time/batch = 0.6812s	
15571/28500 (epoch 27.318), train_loss = 1.05031932, grad/param norm = 1.6987e-01, time/batch = 0.6833s	
15572/28500 (epoch 27.319), train_loss = 0.93110034, grad/param norm = 1.8129e-01, time/batch = 0.6765s	
15573/28500 (epoch 27.321), train_loss = 0.90469802, grad/param norm = 1.7409e-01, time/batch = 0.6769s	
15574/28500 (epoch 27.323), train_loss = 0.91416184, grad/param norm = 1.7827e-01, time/batch = 0.6810s	
15575/28500 (epoch 27.325), train_loss = 1.07504289, grad/param norm = 1.7072e-01, time/batch = 0.6755s	
15576/28500 (epoch 27.326), train_loss = 0.99379552, grad/param norm = 1.7011e-01, time/batch = 0.6800s	
15577/28500 (epoch 27.328), train_loss = 0.78487184, grad/param norm = 1.7059e-01, time/batch = 0.6823s	
15578/28500 (epoch 27.330), train_loss = 0.88509113, grad/param norm = 1.7591e-01, time/batch = 0.6823s	
15579/28500 (epoch 27.332), train_loss = 0.96534834, grad/param norm = 1.6422e-01, time/batch = 0.6766s	
15580/28500 (epoch 27.333), train_loss = 0.78047347, grad/param norm = 1.6183e-01, time/batch = 0.6805s	
15581/28500 (epoch 27.335), train_loss = 0.84176825, grad/param norm = 1.5302e-01, time/batch = 0.6857s	
15582/28500 (epoch 27.337), train_loss = 0.82076537, grad/param norm = 1.5030e-01, time/batch = 0.6812s	
15583/28500 (epoch 27.339), train_loss = 0.80661362, grad/param norm = 1.4278e-01, time/batch = 0.6811s	
15584/28500 (epoch 27.340), train_loss = 0.94507234, grad/param norm = 1.8629e-01, time/batch = 0.6801s	
15585/28500 (epoch 27.342), train_loss = 0.93193588, grad/param norm = 1.6282e-01, time/batch = 0.6796s	
15586/28500 (epoch 27.344), train_loss = 0.87962041, grad/param norm = 1.8187e-01, time/batch = 0.6812s	
15587/28500 (epoch 27.346), train_loss = 0.77637543, grad/param norm = 1.4216e-01, time/batch = 0.6802s	
15588/28500 (epoch 27.347), train_loss = 0.93876315, grad/param norm = 1.6625e-01, time/batch = 0.6800s	
15589/28500 (epoch 27.349), train_loss = 0.91764851, grad/param norm = 1.6255e-01, time/batch = 0.6800s	
15590/28500 (epoch 27.351), train_loss = 0.85859339, grad/param norm = 1.6509e-01, time/batch = 0.6807s	
15591/28500 (epoch 27.353), train_loss = 0.93985940, grad/param norm = 1.7788e-01, time/batch = 0.6830s	
15592/28500 (epoch 27.354), train_loss = 0.85560604, grad/param norm = 1.4715e-01, time/batch = 0.6822s	
15593/28500 (epoch 27.356), train_loss = 0.87764922, grad/param norm = 1.4873e-01, time/batch = 0.6814s	
15594/28500 (epoch 27.358), train_loss = 0.97126959, grad/param norm = 1.6245e-01, time/batch = 0.6818s	
15595/28500 (epoch 27.360), train_loss = 0.97340063, grad/param norm = 1.8079e-01, time/batch = 0.6827s	
15596/28500 (epoch 27.361), train_loss = 0.86923808, grad/param norm = 1.5012e-01, time/batch = 0.6877s	
15597/28500 (epoch 27.363), train_loss = 0.83846344, grad/param norm = 1.4819e-01, time/batch = 0.6803s	
15598/28500 (epoch 27.365), train_loss = 0.91525626, grad/param norm = 1.7658e-01, time/batch = 0.6839s	
15599/28500 (epoch 27.367), train_loss = 0.95467716, grad/param norm = 1.7672e-01, time/batch = 0.6813s	
15600/28500 (epoch 27.368), train_loss = 0.88206369, grad/param norm = 1.5863e-01, time/batch = 0.6799s	
15601/28500 (epoch 27.370), train_loss = 0.93803607, grad/param norm = 1.6272e-01, time/batch = 0.6824s	
15602/28500 (epoch 27.372), train_loss = 0.78119371, grad/param norm = 1.5091e-01, time/batch = 0.6811s	
15603/28500 (epoch 27.374), train_loss = 0.90458991, grad/param norm = 1.8312e-01, time/batch = 0.6803s	
15604/28500 (epoch 27.375), train_loss = 1.03248062, grad/param norm = 1.6620e-01, time/batch = 0.6818s	
15605/28500 (epoch 27.377), train_loss = 0.79993863, grad/param norm = 1.9382e-01, time/batch = 0.6816s	
15606/28500 (epoch 27.379), train_loss = 0.73417855, grad/param norm = 1.6304e-01, time/batch = 0.6813s	
15607/28500 (epoch 27.381), train_loss = 0.90832120, grad/param norm = 1.6571e-01, time/batch = 0.6805s	
15608/28500 (epoch 27.382), train_loss = 0.88025323, grad/param norm = 1.6987e-01, time/batch = 0.6804s	
15609/28500 (epoch 27.384), train_loss = 0.79900884, grad/param norm = 1.5194e-01, time/batch = 0.6805s	
15610/28500 (epoch 27.386), train_loss = 0.84265054, grad/param norm = 1.5719e-01, time/batch = 0.6806s	
15611/28500 (epoch 27.388), train_loss = 1.03565350, grad/param norm = 1.7083e-01, time/batch = 0.6864s	
15612/28500 (epoch 27.389), train_loss = 0.87768400, grad/param norm = 1.7111e-01, time/batch = 0.6832s	
15613/28500 (epoch 27.391), train_loss = 0.81699551, grad/param norm = 1.6450e-01, time/batch = 0.6800s	
15614/28500 (epoch 27.393), train_loss = 0.85238574, grad/param norm = 1.7531e-01, time/batch = 0.6814s	
15615/28500 (epoch 27.395), train_loss = 1.04657859, grad/param norm = 1.6718e-01, time/batch = 0.6805s	
15616/28500 (epoch 27.396), train_loss = 1.01866432, grad/param norm = 1.8211e-01, time/batch = 0.6797s	
15617/28500 (epoch 27.398), train_loss = 0.72183421, grad/param norm = 2.3410e-01, time/batch = 0.6797s	
15618/28500 (epoch 27.400), train_loss = 0.91861773, grad/param norm = 1.9561e-01, time/batch = 0.6804s	
15619/28500 (epoch 27.402), train_loss = 0.96092958, grad/param norm = 2.4022e-01, time/batch = 0.6793s	
15620/28500 (epoch 27.404), train_loss = 0.98916755, grad/param norm = 1.9095e-01, time/batch = 0.6781s	
15621/28500 (epoch 27.405), train_loss = 0.99533774, grad/param norm = 1.7829e-01, time/batch = 0.6822s	
15622/28500 (epoch 27.407), train_loss = 0.96257377, grad/param norm = 1.7676e-01, time/batch = 0.6791s	
15623/28500 (epoch 27.409), train_loss = 0.97336039, grad/param norm = 1.7037e-01, time/batch = 0.6805s	
15624/28500 (epoch 27.411), train_loss = 1.02007570, grad/param norm = 1.8048e-01, time/batch = 0.6788s	
15625/28500 (epoch 27.412), train_loss = 1.05920868, grad/param norm = 1.8240e-01, time/batch = 0.6813s	
15626/28500 (epoch 27.414), train_loss = 0.96477927, grad/param norm = 1.7859e-01, time/batch = 0.6849s	
15627/28500 (epoch 27.416), train_loss = 0.86148506, grad/param norm = 1.5984e-01, time/batch = 0.6871s	
15628/28500 (epoch 27.418), train_loss = 0.96697307, grad/param norm = 1.6048e-01, time/batch = 0.6852s	
15629/28500 (epoch 27.419), train_loss = 1.05724418, grad/param norm = 1.9746e-01, time/batch = 0.6849s	
15630/28500 (epoch 27.421), train_loss = 1.02116429, grad/param norm = 1.7871e-01, time/batch = 0.6827s	
15631/28500 (epoch 27.423), train_loss = 1.06000420, grad/param norm = 2.1340e-01, time/batch = 0.6930s	
15632/28500 (epoch 27.425), train_loss = 0.97275632, grad/param norm = 1.9223e-01, time/batch = 0.7025s	
15633/28500 (epoch 27.426), train_loss = 0.95206447, grad/param norm = 1.8732e-01, time/batch = 0.6846s	
15634/28500 (epoch 27.428), train_loss = 1.10148472, grad/param norm = 1.9975e-01, time/batch = 0.6813s	
15635/28500 (epoch 27.430), train_loss = 1.07120987, grad/param norm = 1.6960e-01, time/batch = 0.6814s	
15636/28500 (epoch 27.432), train_loss = 0.95557304, grad/param norm = 1.9138e-01, time/batch = 0.6817s	
15637/28500 (epoch 27.433), train_loss = 1.01825759, grad/param norm = 1.8120e-01, time/batch = 0.6818s	
15638/28500 (epoch 27.435), train_loss = 0.98081549, grad/param norm = 1.8039e-01, time/batch = 0.6820s	
15639/28500 (epoch 27.437), train_loss = 0.87380806, grad/param norm = 1.6211e-01, time/batch = 0.6819s	
15640/28500 (epoch 27.439), train_loss = 0.91642541, grad/param norm = 1.5072e-01, time/batch = 0.6808s	
15641/28500 (epoch 27.440), train_loss = 1.11646541, grad/param norm = 1.8503e-01, time/batch = 0.6830s	
15642/28500 (epoch 27.442), train_loss = 0.88318035, grad/param norm = 1.7729e-01, time/batch = 0.6810s	
15643/28500 (epoch 27.444), train_loss = 0.83201656, grad/param norm = 1.4836e-01, time/batch = 0.6796s	
15644/28500 (epoch 27.446), train_loss = 0.80534638, grad/param norm = 1.6732e-01, time/batch = 0.6825s	
15645/28500 (epoch 27.447), train_loss = 0.81267262, grad/param norm = 1.5811e-01, time/batch = 0.6812s	
15646/28500 (epoch 27.449), train_loss = 0.88906969, grad/param norm = 1.5020e-01, time/batch = 0.6828s	
15647/28500 (epoch 27.451), train_loss = 0.94301076, grad/param norm = 1.7260e-01, time/batch = 0.6860s	
15648/28500 (epoch 27.453), train_loss = 0.91619188, grad/param norm = 1.5865e-01, time/batch = 0.6818s	
15649/28500 (epoch 27.454), train_loss = 0.88641663, grad/param norm = 1.5140e-01, time/batch = 0.6809s	
15650/28500 (epoch 27.456), train_loss = 0.99564355, grad/param norm = 2.5033e-01, time/batch = 0.6806s	
15651/28500 (epoch 27.458), train_loss = 0.91313340, grad/param norm = 1.7449e-01, time/batch = 0.6816s	
15652/28500 (epoch 27.460), train_loss = 1.01609801, grad/param norm = 1.8496e-01, time/batch = 0.6815s	
15653/28500 (epoch 27.461), train_loss = 0.86495634, grad/param norm = 1.7877e-01, time/batch = 0.6799s	
15654/28500 (epoch 27.463), train_loss = 0.79603925, grad/param norm = 1.5232e-01, time/batch = 0.6827s	
15655/28500 (epoch 27.465), train_loss = 0.79895629, grad/param norm = 1.8111e-01, time/batch = 0.7002s	
15656/28500 (epoch 27.467), train_loss = 0.93545100, grad/param norm = 1.6131e-01, time/batch = 0.6788s	
15657/28500 (epoch 27.468), train_loss = 0.84482552, grad/param norm = 1.5150e-01, time/batch = 0.6825s	
15658/28500 (epoch 27.470), train_loss = 0.89416047, grad/param norm = 1.8947e-01, time/batch = 0.6812s	
15659/28500 (epoch 27.472), train_loss = 0.86495224, grad/param norm = 1.5258e-01, time/batch = 0.6810s	
15660/28500 (epoch 27.474), train_loss = 1.06521466, grad/param norm = 1.7556e-01, time/batch = 0.6859s	
15661/28500 (epoch 27.475), train_loss = 0.87969713, grad/param norm = 1.7552e-01, time/batch = 0.6876s	
15662/28500 (epoch 27.477), train_loss = 0.88737005, grad/param norm = 1.6932e-01, time/batch = 0.6836s	
15663/28500 (epoch 27.479), train_loss = 0.98146171, grad/param norm = 1.7665e-01, time/batch = 0.6835s	
15664/28500 (epoch 27.481), train_loss = 0.96891472, grad/param norm = 1.9174e-01, time/batch = 0.6809s	
15665/28500 (epoch 27.482), train_loss = 0.83095673, grad/param norm = 1.6696e-01, time/batch = 0.6816s	
15666/28500 (epoch 27.484), train_loss = 0.85256153, grad/param norm = 1.6187e-01, time/batch = 0.6813s	
15667/28500 (epoch 27.486), train_loss = 0.75247087, grad/param norm = 1.6783e-01, time/batch = 0.6818s	
15668/28500 (epoch 27.488), train_loss = 0.96338601, grad/param norm = 1.5375e-01, time/batch = 0.6799s	
15669/28500 (epoch 27.489), train_loss = 1.05395418, grad/param norm = 1.7365e-01, time/batch = 0.6810s	
15670/28500 (epoch 27.491), train_loss = 0.89327047, grad/param norm = 1.7318e-01, time/batch = 0.6793s	
15671/28500 (epoch 27.493), train_loss = 0.93018184, grad/param norm = 1.5861e-01, time/batch = 0.6836s	
15672/28500 (epoch 27.495), train_loss = 0.93462208, grad/param norm = 1.5960e-01, time/batch = 0.6821s	
15673/28500 (epoch 27.496), train_loss = 0.84999809, grad/param norm = 1.8097e-01, time/batch = 0.6822s	
15674/28500 (epoch 27.498), train_loss = 0.91707164, grad/param norm = 1.5776e-01, time/batch = 0.6791s	
15675/28500 (epoch 27.500), train_loss = 0.86746159, grad/param norm = 1.5857e-01, time/batch = 0.6810s	
15676/28500 (epoch 27.502), train_loss = 0.99159851, grad/param norm = 1.6094e-01, time/batch = 0.6795s	
15677/28500 (epoch 27.504), train_loss = 0.95986209, grad/param norm = 1.5867e-01, time/batch = 0.6810s	
15678/28500 (epoch 27.505), train_loss = 0.87529425, grad/param norm = 1.6441e-01, time/batch = 0.6809s	
15679/28500 (epoch 27.507), train_loss = 1.03493057, grad/param norm = 2.4182e-01, time/batch = 0.6824s	
15680/28500 (epoch 27.509), train_loss = 0.92375080, grad/param norm = 1.5575e-01, time/batch = 0.6818s	
15681/28500 (epoch 27.511), train_loss = 0.94037337, grad/param norm = 1.7687e-01, time/batch = 0.6841s	
15682/28500 (epoch 27.512), train_loss = 0.96362345, grad/param norm = 1.7393e-01, time/batch = 0.6812s	
15683/28500 (epoch 27.514), train_loss = 0.92128406, grad/param norm = 1.7386e-01, time/batch = 0.6815s	
15684/28500 (epoch 27.516), train_loss = 0.89828691, grad/param norm = 1.5318e-01, time/batch = 0.6811s	
15685/28500 (epoch 27.518), train_loss = 0.96889050, grad/param norm = 1.5924e-01, time/batch = 0.6814s	
15686/28500 (epoch 27.519), train_loss = 1.01042644, grad/param norm = 1.7007e-01, time/batch = 0.6847s	
15687/28500 (epoch 27.521), train_loss = 1.06406280, grad/param norm = 1.7799e-01, time/batch = 0.6797s	
15688/28500 (epoch 27.523), train_loss = 0.98416549, grad/param norm = 1.7004e-01, time/batch = 0.6797s	
15689/28500 (epoch 27.525), train_loss = 1.05252261, grad/param norm = 1.8786e-01, time/batch = 0.6822s	
15690/28500 (epoch 27.526), train_loss = 1.00450614, grad/param norm = 1.5708e-01, time/batch = 0.6808s	
15691/28500 (epoch 27.528), train_loss = 0.99407607, grad/param norm = 2.1993e-01, time/batch = 0.6822s	
15692/28500 (epoch 27.530), train_loss = 1.00317997, grad/param norm = 1.5676e-01, time/batch = 0.6808s	
15693/28500 (epoch 27.532), train_loss = 0.89864454, grad/param norm = 1.5340e-01, time/batch = 0.6809s	
15694/28500 (epoch 27.533), train_loss = 1.00578472, grad/param norm = 1.6549e-01, time/batch = 0.6803s	
15695/28500 (epoch 27.535), train_loss = 0.81294363, grad/param norm = 1.4485e-01, time/batch = 0.6807s	
15696/28500 (epoch 27.537), train_loss = 0.83680878, grad/param norm = 1.4662e-01, time/batch = 0.6810s	
15697/28500 (epoch 27.539), train_loss = 0.79294267, grad/param norm = 1.7055e-01, time/batch = 0.6814s	
15698/28500 (epoch 27.540), train_loss = 0.95967862, grad/param norm = 1.8547e-01, time/batch = 0.6814s	
15699/28500 (epoch 27.542), train_loss = 0.98530135, grad/param norm = 2.1536e-01, time/batch = 0.6813s	
15700/28500 (epoch 27.544), train_loss = 1.07095698, grad/param norm = 1.6720e-01, time/batch = 0.6804s	
15701/28500 (epoch 27.546), train_loss = 0.91605049, grad/param norm = 1.6942e-01, time/batch = 0.6868s	
15702/28500 (epoch 27.547), train_loss = 0.93469214, grad/param norm = 1.5166e-01, time/batch = 0.6816s	
15703/28500 (epoch 27.549), train_loss = 0.77661550, grad/param norm = 1.3068e-01, time/batch = 0.6813s	
15704/28500 (epoch 27.551), train_loss = 0.92232541, grad/param norm = 2.0052e-01, time/batch = 0.6806s	
15705/28500 (epoch 27.553), train_loss = 1.10926298, grad/param norm = 2.0692e-01, time/batch = 0.6800s	
15706/28500 (epoch 27.554), train_loss = 0.98133548, grad/param norm = 1.7949e-01, time/batch = 0.6799s	
15707/28500 (epoch 27.556), train_loss = 0.97706645, grad/param norm = 1.6734e-01, time/batch = 0.6821s	
15708/28500 (epoch 27.558), train_loss = 0.99495037, grad/param norm = 1.7420e-01, time/batch = 0.6809s	
15709/28500 (epoch 27.560), train_loss = 0.96436542, grad/param norm = 1.7217e-01, time/batch = 0.6808s	
15710/28500 (epoch 27.561), train_loss = 1.01704473, grad/param norm = 1.7498e-01, time/batch = 0.6803s	
15711/28500 (epoch 27.563), train_loss = 1.08514359, grad/param norm = 1.9666e-01, time/batch = 0.6827s	
15712/28500 (epoch 27.565), train_loss = 0.89250038, grad/param norm = 1.7808e-01, time/batch = 0.6813s	
15713/28500 (epoch 27.567), train_loss = 0.83397939, grad/param norm = 1.4965e-01, time/batch = 0.6845s	
15714/28500 (epoch 27.568), train_loss = 0.98026810, grad/param norm = 1.9750e-01, time/batch = 0.6975s	
15715/28500 (epoch 27.570), train_loss = 0.90784452, grad/param norm = 1.5401e-01, time/batch = 0.7033s	
15716/28500 (epoch 27.572), train_loss = 0.92879652, grad/param norm = 1.7793e-01, time/batch = 0.6955s	
15717/28500 (epoch 27.574), train_loss = 0.90224438, grad/param norm = 1.6502e-01, time/batch = 0.6812s	
15718/28500 (epoch 27.575), train_loss = 0.89942388, grad/param norm = 1.6354e-01, time/batch = 0.6803s	
15719/28500 (epoch 27.577), train_loss = 0.96489154, grad/param norm = 1.6266e-01, time/batch = 0.6833s	
15720/28500 (epoch 27.579), train_loss = 1.02490644, grad/param norm = 1.7283e-01, time/batch = 0.6868s	
15721/28500 (epoch 27.581), train_loss = 0.85962036, grad/param norm = 1.7736e-01, time/batch = 0.6824s	
15722/28500 (epoch 27.582), train_loss = 1.02777095, grad/param norm = 1.7395e-01, time/batch = 0.6796s	
15723/28500 (epoch 27.584), train_loss = 0.89903415, grad/param norm = 1.9210e-01, time/batch = 0.6811s	
15724/28500 (epoch 27.586), train_loss = 0.86490852, grad/param norm = 1.5145e-01, time/batch = 0.6891s	
15725/28500 (epoch 27.588), train_loss = 0.88095278, grad/param norm = 1.7927e-01, time/batch = 0.6861s	
15726/28500 (epoch 27.589), train_loss = 0.95306052, grad/param norm = 1.8654e-01, time/batch = 0.6798s	
15727/28500 (epoch 27.591), train_loss = 0.96130924, grad/param norm = 1.8091e-01, time/batch = 0.6796s	
15728/28500 (epoch 27.593), train_loss = 0.88278340, grad/param norm = 1.7131e-01, time/batch = 0.6801s	
15729/28500 (epoch 27.595), train_loss = 1.13898587, grad/param norm = 2.2581e-01, time/batch = 0.6793s	
15730/28500 (epoch 27.596), train_loss = 1.10067109, grad/param norm = 1.7807e-01, time/batch = 0.6809s	
15731/28500 (epoch 27.598), train_loss = 0.94906022, grad/param norm = 1.9100e-01, time/batch = 0.6837s	
15732/28500 (epoch 27.600), train_loss = 0.95068991, grad/param norm = 1.7605e-01, time/batch = 0.6829s	
15733/28500 (epoch 27.602), train_loss = 1.00812870, grad/param norm = 1.8341e-01, time/batch = 0.6828s	
15734/28500 (epoch 27.604), train_loss = 1.02208396, grad/param norm = 1.5817e-01, time/batch = 0.6802s	
15735/28500 (epoch 27.605), train_loss = 1.01384560, grad/param norm = 1.8816e-01, time/batch = 0.6810s	
15736/28500 (epoch 27.607), train_loss = 1.04066410, grad/param norm = 1.6071e-01, time/batch = 0.6818s	
15737/28500 (epoch 27.609), train_loss = 0.96965059, grad/param norm = 1.7914e-01, time/batch = 0.6800s	
15738/28500 (epoch 27.611), train_loss = 0.91930216, grad/param norm = 1.8982e-01, time/batch = 0.6795s	
15739/28500 (epoch 27.612), train_loss = 0.99303249, grad/param norm = 1.8207e-01, time/batch = 0.6795s	
15740/28500 (epoch 27.614), train_loss = 0.99880952, grad/param norm = 1.6161e-01, time/batch = 0.6807s	
15741/28500 (epoch 27.616), train_loss = 0.91270116, grad/param norm = 1.9200e-01, time/batch = 0.6856s	
15742/28500 (epoch 27.618), train_loss = 0.93066105, grad/param norm = 1.7705e-01, time/batch = 0.6830s	
15743/28500 (epoch 27.619), train_loss = 1.04661965, grad/param norm = 1.9184e-01, time/batch = 0.6803s	
15744/28500 (epoch 27.621), train_loss = 0.77791001, grad/param norm = 1.4379e-01, time/batch = 0.6804s	
15745/28500 (epoch 27.623), train_loss = 1.02639337, grad/param norm = 1.7816e-01, time/batch = 0.6801s	
15746/28500 (epoch 27.625), train_loss = 0.84034569, grad/param norm = 1.5488e-01, time/batch = 0.6800s	
15747/28500 (epoch 27.626), train_loss = 0.73544358, grad/param norm = 1.4960e-01, time/batch = 0.6796s	
15748/28500 (epoch 27.628), train_loss = 0.85955603, grad/param norm = 1.5929e-01, time/batch = 0.6807s	
15749/28500 (epoch 27.630), train_loss = 0.81738450, grad/param norm = 1.6452e-01, time/batch = 0.6781s	
15750/28500 (epoch 27.632), train_loss = 1.04058361, grad/param norm = 1.8934e-01, time/batch = 0.6770s	
15751/28500 (epoch 27.633), train_loss = 1.08940226, grad/param norm = 1.6864e-01, time/batch = 0.6790s	
15752/28500 (epoch 27.635), train_loss = 0.99669663, grad/param norm = 1.7691e-01, time/batch = 0.6770s	
15753/28500 (epoch 27.637), train_loss = 0.94997629, grad/param norm = 1.5966e-01, time/batch = 0.6782s	
15754/28500 (epoch 27.639), train_loss = 0.85212407, grad/param norm = 1.6781e-01, time/batch = 0.6797s	
15755/28500 (epoch 27.640), train_loss = 0.88811316, grad/param norm = 1.7149e-01, time/batch = 0.6803s	
15756/28500 (epoch 27.642), train_loss = 0.87685660, grad/param norm = 1.5570e-01, time/batch = 0.6782s	
15757/28500 (epoch 27.644), train_loss = 1.01704236, grad/param norm = 1.6928e-01, time/batch = 0.6756s	
15758/28500 (epoch 27.646), train_loss = 0.80709632, grad/param norm = 1.3804e-01, time/batch = 0.6796s	
15759/28500 (epoch 27.647), train_loss = 0.85114812, grad/param norm = 1.5169e-01, time/batch = 0.6790s	
15760/28500 (epoch 27.649), train_loss = 0.80367124, grad/param norm = 1.6196e-01, time/batch = 0.6754s	
15761/28500 (epoch 27.651), train_loss = 0.82135926, grad/param norm = 1.4592e-01, time/batch = 0.6782s	
15762/28500 (epoch 27.653), train_loss = 0.81285821, grad/param norm = 1.5473e-01, time/batch = 0.6793s	
15763/28500 (epoch 27.654), train_loss = 0.87069497, grad/param norm = 1.7374e-01, time/batch = 0.6802s	
15764/28500 (epoch 27.656), train_loss = 0.87050774, grad/param norm = 2.1600e-01, time/batch = 0.6781s	
15765/28500 (epoch 27.658), train_loss = 0.91200847, grad/param norm = 1.6539e-01, time/batch = 0.6761s	
15766/28500 (epoch 27.660), train_loss = 0.93980013, grad/param norm = 1.7128e-01, time/batch = 0.6796s	
15767/28500 (epoch 27.661), train_loss = 1.04731874, grad/param norm = 1.9811e-01, time/batch = 0.6774s	
15768/28500 (epoch 27.663), train_loss = 1.05368570, grad/param norm = 1.8817e-01, time/batch = 0.6767s	
15769/28500 (epoch 27.665), train_loss = 0.93056071, grad/param norm = 1.7490e-01, time/batch = 0.6789s	
15770/28500 (epoch 27.667), train_loss = 0.92277335, grad/param norm = 1.9272e-01, time/batch = 0.6808s	
15771/28500 (epoch 27.668), train_loss = 0.91924500, grad/param norm = 1.7035e-01, time/batch = 0.6838s	
15772/28500 (epoch 27.670), train_loss = 0.93725197, grad/param norm = 1.6777e-01, time/batch = 0.6836s	
15773/28500 (epoch 27.672), train_loss = 0.84962514, grad/param norm = 1.5965e-01, time/batch = 0.6964s	
15774/28500 (epoch 27.674), train_loss = 0.75797442, grad/param norm = 1.6339e-01, time/batch = 0.7053s	
15775/28500 (epoch 27.675), train_loss = 0.79388732, grad/param norm = 1.4795e-01, time/batch = 0.6845s	
15776/28500 (epoch 27.677), train_loss = 0.90611603, grad/param norm = 1.6037e-01, time/batch = 0.6822s	
15777/28500 (epoch 27.679), train_loss = 0.88362900, grad/param norm = 1.6891e-01, time/batch = 0.6806s	
15778/28500 (epoch 27.681), train_loss = 0.96561826, grad/param norm = 1.7474e-01, time/batch = 0.6856s	
15779/28500 (epoch 27.682), train_loss = 0.86415094, grad/param norm = 1.5990e-01, time/batch = 0.6904s	
15780/28500 (epoch 27.684), train_loss = 0.94460523, grad/param norm = 1.6776e-01, time/batch = 0.7018s	
15781/28500 (epoch 27.686), train_loss = 0.88450469, grad/param norm = 1.7066e-01, time/batch = 0.6844s	
15782/28500 (epoch 27.688), train_loss = 0.83335669, grad/param norm = 1.3977e-01, time/batch = 0.6810s	
15783/28500 (epoch 27.689), train_loss = 0.88307391, grad/param norm = 1.9614e-01, time/batch = 0.6781s	
15784/28500 (epoch 27.691), train_loss = 0.94137009, grad/param norm = 1.5778e-01, time/batch = 0.6787s	
15785/28500 (epoch 27.693), train_loss = 0.87040532, grad/param norm = 1.5235e-01, time/batch = 0.6866s	
15786/28500 (epoch 27.695), train_loss = 0.69395705, grad/param norm = 1.6203e-01, time/batch = 0.6765s	
15787/28500 (epoch 27.696), train_loss = 0.90018193, grad/param norm = 1.6128e-01, time/batch = 0.6761s	
15788/28500 (epoch 27.698), train_loss = 0.93063791, grad/param norm = 1.6419e-01, time/batch = 0.6756s	
15789/28500 (epoch 27.700), train_loss = 0.93413809, grad/param norm = 1.6630e-01, time/batch = 0.6767s	
15790/28500 (epoch 27.702), train_loss = 0.93209690, grad/param norm = 1.7165e-01, time/batch = 0.6763s	
15791/28500 (epoch 27.704), train_loss = 0.93992948, grad/param norm = 1.6417e-01, time/batch = 0.6790s	
15792/28500 (epoch 27.705), train_loss = 1.01568299, grad/param norm = 1.8214e-01, time/batch = 0.6792s	
15793/28500 (epoch 27.707), train_loss = 0.87583911, grad/param norm = 1.9515e-01, time/batch = 0.6796s	
15794/28500 (epoch 27.709), train_loss = 1.06791301, grad/param norm = 1.7924e-01, time/batch = 0.6755s	
15795/28500 (epoch 27.711), train_loss = 0.86467396, grad/param norm = 1.8127e-01, time/batch = 0.6767s	
15796/28500 (epoch 27.712), train_loss = 0.95204044, grad/param norm = 1.8641e-01, time/batch = 0.6800s	
15797/28500 (epoch 27.714), train_loss = 1.04765553, grad/param norm = 1.7661e-01, time/batch = 0.6760s	
15798/28500 (epoch 27.716), train_loss = 0.90562825, grad/param norm = 1.5841e-01, time/batch = 0.6796s	
15799/28500 (epoch 27.718), train_loss = 0.95125890, grad/param norm = 1.6709e-01, time/batch = 0.6951s	
15800/28500 (epoch 27.719), train_loss = 0.94251009, grad/param norm = 1.6876e-01, time/batch = 0.6868s	
15801/28500 (epoch 27.721), train_loss = 0.76127393, grad/param norm = 1.6695e-01, time/batch = 0.6880s	
15802/28500 (epoch 27.723), train_loss = 0.92263107, grad/param norm = 1.6803e-01, time/batch = 0.6883s	
15803/28500 (epoch 27.725), train_loss = 0.99046465, grad/param norm = 1.5485e-01, time/batch = 0.6847s	
15804/28500 (epoch 27.726), train_loss = 0.92635020, grad/param norm = 1.7900e-01, time/batch = 0.6774s	
15805/28500 (epoch 27.728), train_loss = 0.85235734, grad/param norm = 1.6748e-01, time/batch = 0.6826s	
15806/28500 (epoch 27.730), train_loss = 0.92872787, grad/param norm = 1.9582e-01, time/batch = 0.6849s	
15807/28500 (epoch 27.732), train_loss = 0.74820709, grad/param norm = 1.4741e-01, time/batch = 0.6800s	
15808/28500 (epoch 27.733), train_loss = 0.78049179, grad/param norm = 1.4296e-01, time/batch = 0.6955s	
15809/28500 (epoch 27.735), train_loss = 0.79769110, grad/param norm = 1.4338e-01, time/batch = 0.6991s	
15810/28500 (epoch 27.737), train_loss = 0.72519836, grad/param norm = 1.3973e-01, time/batch = 0.6993s	
15811/28500 (epoch 27.739), train_loss = 0.84276668, grad/param norm = 1.6972e-01, time/batch = 0.6909s	
15812/28500 (epoch 27.740), train_loss = 0.92055886, grad/param norm = 1.6864e-01, time/batch = 0.6839s	
15813/28500 (epoch 27.742), train_loss = 0.83874244, grad/param norm = 1.6059e-01, time/batch = 0.6863s	
15814/28500 (epoch 27.744), train_loss = 0.93315468, grad/param norm = 1.6946e-01, time/batch = 0.6810s	
15815/28500 (epoch 27.746), train_loss = 0.85122472, grad/param norm = 1.5026e-01, time/batch = 0.6770s	
15816/28500 (epoch 27.747), train_loss = 0.85274739, grad/param norm = 1.4931e-01, time/batch = 0.6827s	
15817/28500 (epoch 27.749), train_loss = 0.97135068, grad/param norm = 2.0465e-01, time/batch = 0.6867s	
15818/28500 (epoch 27.751), train_loss = 0.81287278, grad/param norm = 1.7160e-01, time/batch = 0.6873s	
15819/28500 (epoch 27.753), train_loss = 0.90085207, grad/param norm = 1.5811e-01, time/batch = 0.6759s	
15820/28500 (epoch 27.754), train_loss = 0.81746232, grad/param norm = 1.5216e-01, time/batch = 0.6797s	
15821/28500 (epoch 27.756), train_loss = 1.02209333, grad/param norm = 1.7424e-01, time/batch = 0.6852s	
15822/28500 (epoch 27.758), train_loss = 0.99071683, grad/param norm = 1.8598e-01, time/batch = 0.6870s	
15823/28500 (epoch 27.760), train_loss = 0.81796114, grad/param norm = 1.7781e-01, time/batch = 0.6789s	
15824/28500 (epoch 27.761), train_loss = 0.85339204, grad/param norm = 1.8486e-01, time/batch = 0.6797s	
15825/28500 (epoch 27.763), train_loss = 0.74176891, grad/param norm = 1.3961e-01, time/batch = 0.6790s	
15826/28500 (epoch 27.765), train_loss = 0.90148012, grad/param norm = 1.5565e-01, time/batch = 0.6956s	
15827/28500 (epoch 27.767), train_loss = 0.77763130, grad/param norm = 1.5623e-01, time/batch = 0.6832s	
15828/28500 (epoch 27.768), train_loss = 0.96930751, grad/param norm = 1.9715e-01, time/batch = 0.6866s	
15829/28500 (epoch 27.770), train_loss = 0.80682385, grad/param norm = 1.5908e-01, time/batch = 0.6877s	
15830/28500 (epoch 27.772), train_loss = 0.73083676, grad/param norm = 1.4078e-01, time/batch = 0.6793s	
15831/28500 (epoch 27.774), train_loss = 0.91416955, grad/param norm = 1.7228e-01, time/batch = 0.6854s	
15832/28500 (epoch 27.775), train_loss = 1.00456736, grad/param norm = 1.5905e-01, time/batch = 0.6803s	
15833/28500 (epoch 27.777), train_loss = 1.00587300, grad/param norm = 1.6403e-01, time/batch = 0.6840s	
15834/28500 (epoch 27.779), train_loss = 0.74777397, grad/param norm = 1.3410e-01, time/batch = 0.6800s	
15835/28500 (epoch 27.781), train_loss = 0.89107076, grad/param norm = 1.8985e-01, time/batch = 0.6806s	
15836/28500 (epoch 27.782), train_loss = 0.95241141, grad/param norm = 2.2128e-01, time/batch = 0.6817s	
15837/28500 (epoch 27.784), train_loss = 0.75948739, grad/param norm = 1.5518e-01, time/batch = 0.6796s	
15838/28500 (epoch 27.786), train_loss = 0.80261046, grad/param norm = 1.4658e-01, time/batch = 0.6822s	
15839/28500 (epoch 27.788), train_loss = 0.92242222, grad/param norm = 2.1071e-01, time/batch = 0.6822s	
15840/28500 (epoch 27.789), train_loss = 0.68446827, grad/param norm = 1.9023e-01, time/batch = 0.6804s	
15841/28500 (epoch 27.791), train_loss = 0.93998634, grad/param norm = 1.7799e-01, time/batch = 0.6836s	
15842/28500 (epoch 27.793), train_loss = 0.90245115, grad/param norm = 1.7531e-01, time/batch = 0.6834s	
15843/28500 (epoch 27.795), train_loss = 0.91866201, grad/param norm = 1.7751e-01, time/batch = 0.6818s	
15844/28500 (epoch 27.796), train_loss = 0.81862530, grad/param norm = 1.5666e-01, time/batch = 0.6825s	
15845/28500 (epoch 27.798), train_loss = 0.73859137, grad/param norm = 1.6324e-01, time/batch = 0.6859s	
15846/28500 (epoch 27.800), train_loss = 0.78201143, grad/param norm = 1.7896e-01, time/batch = 0.6810s	
15847/28500 (epoch 27.802), train_loss = 0.85775096, grad/param norm = 1.8815e-01, time/batch = 0.6804s	
15848/28500 (epoch 27.804), train_loss = 0.91962773, grad/param norm = 1.5595e-01, time/batch = 0.6800s	
15849/28500 (epoch 27.805), train_loss = 0.92275638, grad/param norm = 1.7709e-01, time/batch = 0.6797s	
15850/28500 (epoch 27.807), train_loss = 0.93042930, grad/param norm = 1.8164e-01, time/batch = 0.6822s	
15851/28500 (epoch 27.809), train_loss = 0.91442303, grad/param norm = 1.7161e-01, time/batch = 0.6849s	
15852/28500 (epoch 27.811), train_loss = 0.94742196, grad/param norm = 1.7259e-01, time/batch = 0.6823s	
15853/28500 (epoch 27.812), train_loss = 0.92484665, grad/param norm = 1.9182e-01, time/batch = 0.6814s	
15854/28500 (epoch 27.814), train_loss = 0.84529063, grad/param norm = 1.6769e-01, time/batch = 0.6800s	
15855/28500 (epoch 27.816), train_loss = 0.94947608, grad/param norm = 2.1548e-01, time/batch = 0.6789s	
15856/28500 (epoch 27.818), train_loss = 1.02179905, grad/param norm = 1.8688e-01, time/batch = 0.6798s	
15857/28500 (epoch 27.819), train_loss = 0.90795485, grad/param norm = 1.5626e-01, time/batch = 0.6796s	
15858/28500 (epoch 27.821), train_loss = 0.86501410, grad/param norm = 1.5655e-01, time/batch = 0.6796s	
15859/28500 (epoch 27.823), train_loss = 1.04447269, grad/param norm = 2.0943e-01, time/batch = 0.6788s	
15860/28500 (epoch 27.825), train_loss = 0.87613112, grad/param norm = 1.8444e-01, time/batch = 0.6796s	
15861/28500 (epoch 27.826), train_loss = 0.92191159, grad/param norm = 1.7334e-01, time/batch = 0.6807s	
15862/28500 (epoch 27.828), train_loss = 0.80143204, grad/param norm = 1.6273e-01, time/batch = 0.6810s	
15863/28500 (epoch 27.830), train_loss = 0.87738991, grad/param norm = 1.5309e-01, time/batch = 0.6785s	
15864/28500 (epoch 27.832), train_loss = 0.92159508, grad/param norm = 2.0236e-01, time/batch = 0.6809s	
15865/28500 (epoch 27.833), train_loss = 1.00086346, grad/param norm = 1.6717e-01, time/batch = 0.6794s	
15866/28500 (epoch 27.835), train_loss = 0.85423304, grad/param norm = 1.8836e-01, time/batch = 0.6799s	
15867/28500 (epoch 27.837), train_loss = 0.80057931, grad/param norm = 1.6973e-01, time/batch = 0.6795s	
15868/28500 (epoch 27.839), train_loss = 1.05156666, grad/param norm = 1.9880e-01, time/batch = 0.6791s	
15869/28500 (epoch 27.840), train_loss = 1.07585600, grad/param norm = 1.9070e-01, time/batch = 0.6804s	
15870/28500 (epoch 27.842), train_loss = 0.96603822, grad/param norm = 1.8936e-01, time/batch = 0.6815s	
15871/28500 (epoch 27.844), train_loss = 0.94689458, grad/param norm = 1.7761e-01, time/batch = 0.6822s	
15872/28500 (epoch 27.846), train_loss = 1.05353281, grad/param norm = 2.1577e-01, time/batch = 0.6808s	
15873/28500 (epoch 27.847), train_loss = 0.88665337, grad/param norm = 1.7024e-01, time/batch = 0.6800s	
15874/28500 (epoch 27.849), train_loss = 0.87772025, grad/param norm = 1.6324e-01, time/batch = 0.6805s	
15875/28500 (epoch 27.851), train_loss = 0.78374702, grad/param norm = 1.4655e-01, time/batch = 0.6783s	
15876/28500 (epoch 27.853), train_loss = 0.91376746, grad/param norm = 1.7143e-01, time/batch = 0.6799s	
15877/28500 (epoch 27.854), train_loss = 0.92415084, grad/param norm = 1.7608e-01, time/batch = 0.6782s	
15878/28500 (epoch 27.856), train_loss = 1.04391722, grad/param norm = 2.1665e-01, time/batch = 0.6797s	
15879/28500 (epoch 27.858), train_loss = 0.85266615, grad/param norm = 1.5916e-01, time/batch = 0.6805s	
15880/28500 (epoch 27.860), train_loss = 0.88225688, grad/param norm = 1.7103e-01, time/batch = 0.6790s	
15881/28500 (epoch 27.861), train_loss = 0.96216733, grad/param norm = 2.0077e-01, time/batch = 0.6782s	
15882/28500 (epoch 27.863), train_loss = 0.96857949, grad/param norm = 2.2117e-01, time/batch = 0.6773s	
15883/28500 (epoch 27.865), train_loss = 0.86346966, grad/param norm = 1.8006e-01, time/batch = 0.6762s	
15884/28500 (epoch 27.867), train_loss = 0.96002975, grad/param norm = 1.9005e-01, time/batch = 0.6759s	
15885/28500 (epoch 27.868), train_loss = 0.83029689, grad/param norm = 1.6190e-01, time/batch = 0.6761s	
15886/28500 (epoch 27.870), train_loss = 0.79112165, grad/param norm = 1.6324e-01, time/batch = 0.6757s	
15887/28500 (epoch 27.872), train_loss = 0.95130558, grad/param norm = 1.7999e-01, time/batch = 0.6758s	
15888/28500 (epoch 27.874), train_loss = 0.83982342, grad/param norm = 1.9638e-01, time/batch = 0.6826s	
15889/28500 (epoch 27.875), train_loss = 1.04309222, grad/param norm = 1.8415e-01, time/batch = 0.6893s	
15890/28500 (epoch 27.877), train_loss = 0.93411026, grad/param norm = 1.8085e-01, time/batch = 0.6907s	
15891/28500 (epoch 27.879), train_loss = 0.96120697, grad/param norm = 1.5373e-01, time/batch = 0.6865s	
15892/28500 (epoch 27.881), train_loss = 0.94341985, grad/param norm = 1.7849e-01, time/batch = 0.6817s	
15893/28500 (epoch 27.882), train_loss = 0.83041763, grad/param norm = 1.5640e-01, time/batch = 0.6797s	
15894/28500 (epoch 27.884), train_loss = 0.92237263, grad/param norm = 1.7764e-01, time/batch = 0.6805s	
15895/28500 (epoch 27.886), train_loss = 0.87381732, grad/param norm = 1.6717e-01, time/batch = 0.6833s	
15896/28500 (epoch 27.888), train_loss = 0.85106288, grad/param norm = 1.5685e-01, time/batch = 0.6805s	
15897/28500 (epoch 27.889), train_loss = 0.91482641, grad/param norm = 1.6328e-01, time/batch = 0.6814s	
15898/28500 (epoch 27.891), train_loss = 0.90463283, grad/param norm = 1.7407e-01, time/batch = 0.6814s	
15899/28500 (epoch 27.893), train_loss = 0.88497848, grad/param norm = 1.7026e-01, time/batch = 0.7027s	
15900/28500 (epoch 27.895), train_loss = 1.04749634, grad/param norm = 1.8074e-01, time/batch = 0.6837s	
15901/28500 (epoch 27.896), train_loss = 0.99594728, grad/param norm = 1.8146e-01, time/batch = 0.6832s	
15902/28500 (epoch 27.898), train_loss = 0.92189622, grad/param norm = 1.7956e-01, time/batch = 0.6816s	
15903/28500 (epoch 27.900), train_loss = 0.79537032, grad/param norm = 1.5780e-01, time/batch = 0.6819s	
15904/28500 (epoch 27.902), train_loss = 0.80005892, grad/param norm = 1.6429e-01, time/batch = 0.6852s	
15905/28500 (epoch 27.904), train_loss = 0.81293854, grad/param norm = 1.5371e-01, time/batch = 0.6826s	
15906/28500 (epoch 27.905), train_loss = 0.87642346, grad/param norm = 1.6052e-01, time/batch = 0.6835s	
15907/28500 (epoch 27.907), train_loss = 0.89141111, grad/param norm = 1.6971e-01, time/batch = 0.6826s	
15908/28500 (epoch 27.909), train_loss = 0.79765842, grad/param norm = 1.9828e-01, time/batch = 0.6832s	
15909/28500 (epoch 27.911), train_loss = 0.81924647, grad/param norm = 1.6397e-01, time/batch = 0.6804s	
15910/28500 (epoch 27.912), train_loss = 0.71599392, grad/param norm = 1.5204e-01, time/batch = 0.6829s	
15911/28500 (epoch 27.914), train_loss = 0.92668543, grad/param norm = 1.7464e-01, time/batch = 0.6820s	
15912/28500 (epoch 27.916), train_loss = 0.90340585, grad/param norm = 1.7569e-01, time/batch = 0.6815s	
15913/28500 (epoch 27.918), train_loss = 0.89805273, grad/param norm = 1.8368e-01, time/batch = 0.6801s	
15914/28500 (epoch 27.919), train_loss = 0.90460125, grad/param norm = 1.5434e-01, time/batch = 0.6822s	
15915/28500 (epoch 27.921), train_loss = 1.00920950, grad/param norm = 2.0807e-01, time/batch = 0.6798s	
15916/28500 (epoch 27.923), train_loss = 0.84632059, grad/param norm = 1.9367e-01, time/batch = 0.6816s	
15917/28500 (epoch 27.925), train_loss = 0.83177939, grad/param norm = 1.7177e-01, time/batch = 0.6802s	
15918/28500 (epoch 27.926), train_loss = 0.91375685, grad/param norm = 1.8688e-01, time/batch = 0.6809s	
15919/28500 (epoch 27.928), train_loss = 0.86447618, grad/param norm = 1.6734e-01, time/batch = 0.6784s	
15920/28500 (epoch 27.930), train_loss = 0.71208807, grad/param norm = 1.3788e-01, time/batch = 0.6803s	
15921/28500 (epoch 27.932), train_loss = 0.71050724, grad/param norm = 1.2815e-01, time/batch = 0.6812s	
15922/28500 (epoch 27.933), train_loss = 0.96362466, grad/param norm = 1.7136e-01, time/batch = 0.6810s	
15923/28500 (epoch 27.935), train_loss = 1.00511096, grad/param norm = 1.8002e-01, time/batch = 0.6799s	
15924/28500 (epoch 27.937), train_loss = 1.01139429, grad/param norm = 2.0637e-01, time/batch = 0.6988s	
15925/28500 (epoch 27.939), train_loss = 1.06307149, grad/param norm = 2.1685e-01, time/batch = 0.6785s	
15926/28500 (epoch 27.940), train_loss = 0.78852413, grad/param norm = 1.6307e-01, time/batch = 0.6799s	
15927/28500 (epoch 27.942), train_loss = 0.90722817, grad/param norm = 1.6275e-01, time/batch = 0.6831s	
15928/28500 (epoch 27.944), train_loss = 0.84677331, grad/param norm = 1.7340e-01, time/batch = 0.6763s	
15929/28500 (epoch 27.946), train_loss = 0.98022042, grad/param norm = 1.7611e-01, time/batch = 0.6772s	
15930/28500 (epoch 27.947), train_loss = 1.19590165, grad/param norm = 2.4112e-01, time/batch = 0.6757s	
15931/28500 (epoch 27.949), train_loss = 0.87549115, grad/param norm = 1.8411e-01, time/batch = 0.6825s	
15932/28500 (epoch 27.951), train_loss = 1.08046970, grad/param norm = 1.8870e-01, time/batch = 0.6766s	
15933/28500 (epoch 27.953), train_loss = 1.06177062, grad/param norm = 1.9898e-01, time/batch = 0.6771s	
15934/28500 (epoch 27.954), train_loss = 1.02166787, grad/param norm = 2.3228e-01, time/batch = 0.6765s	
15935/28500 (epoch 27.956), train_loss = 0.91302272, grad/param norm = 2.1472e-01, time/batch = 0.6766s	
15936/28500 (epoch 27.958), train_loss = 1.13504950, grad/param norm = 1.7784e-01, time/batch = 0.6760s	
15937/28500 (epoch 27.960), train_loss = 0.85617613, grad/param norm = 1.8907e-01, time/batch = 0.6770s	
15938/28500 (epoch 27.961), train_loss = 1.07456774, grad/param norm = 2.1378e-01, time/batch = 0.6771s	
15939/28500 (epoch 27.963), train_loss = 1.02857348, grad/param norm = 1.6163e-01, time/batch = 0.6779s	
15940/28500 (epoch 27.965), train_loss = 0.83987504, grad/param norm = 1.6439e-01, time/batch = 0.6769s	
15941/28500 (epoch 27.967), train_loss = 0.83952018, grad/param norm = 1.5942e-01, time/batch = 0.6791s	
15942/28500 (epoch 27.968), train_loss = 0.78555518, grad/param norm = 1.3759e-01, time/batch = 0.6803s	
15943/28500 (epoch 27.970), train_loss = 0.84413636, grad/param norm = 1.8127e-01, time/batch = 0.6791s	
15944/28500 (epoch 27.972), train_loss = 0.92436073, grad/param norm = 1.7122e-01, time/batch = 0.6771s	
15945/28500 (epoch 27.974), train_loss = 1.08902046, grad/param norm = 1.9731e-01, time/batch = 0.6771s	
15946/28500 (epoch 27.975), train_loss = 0.85451528, grad/param norm = 1.8618e-01, time/batch = 0.6765s	
15947/28500 (epoch 27.977), train_loss = 1.00058073, grad/param norm = 1.8734e-01, time/batch = 0.6758s	
15948/28500 (epoch 27.979), train_loss = 0.90904904, grad/param norm = 1.7542e-01, time/batch = 0.6767s	
15949/28500 (epoch 27.981), train_loss = 0.80552325, grad/param norm = 1.6797e-01, time/batch = 0.6770s	
15950/28500 (epoch 27.982), train_loss = 0.88124991, grad/param norm = 1.7617e-01, time/batch = 0.6759s	
15951/28500 (epoch 27.984), train_loss = 0.98450024, grad/param norm = 1.6871e-01, time/batch = 0.6782s	
15952/28500 (epoch 27.986), train_loss = 1.18624763, grad/param norm = 2.1597e-01, time/batch = 0.6783s	
15953/28500 (epoch 27.988), train_loss = 0.81391753, grad/param norm = 1.5679e-01, time/batch = 0.6766s	
15954/28500 (epoch 27.989), train_loss = 0.94720535, grad/param norm = 1.7233e-01, time/batch = 0.6766s	
15955/28500 (epoch 27.991), train_loss = 0.83225232, grad/param norm = 1.7289e-01, time/batch = 0.6765s	
15956/28500 (epoch 27.993), train_loss = 0.85173680, grad/param norm = 1.5608e-01, time/batch = 0.6764s	
15957/28500 (epoch 27.995), train_loss = 0.86008113, grad/param norm = 1.9043e-01, time/batch = 0.6766s	
15958/28500 (epoch 27.996), train_loss = 0.82357656, grad/param norm = 1.8585e-01, time/batch = 0.6810s	
15959/28500 (epoch 27.998), train_loss = 1.03233604, grad/param norm = 1.9753e-01, time/batch = 0.6766s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
15960/28500 (epoch 28.000), train_loss = 0.91202947, grad/param norm = 1.8433e-01, time/batch = 0.6760s	
15961/28500 (epoch 28.002), train_loss = 1.10007475, grad/param norm = 1.7845e-01, time/batch = 0.6825s	
15962/28500 (epoch 28.004), train_loss = 0.87757974, grad/param norm = 1.6288e-01, time/batch = 0.6774s	
15963/28500 (epoch 28.005), train_loss = 1.03885019, grad/param norm = 1.9888e-01, time/batch = 0.6779s	
15964/28500 (epoch 28.007), train_loss = 0.82352584, grad/param norm = 1.4854e-01, time/batch = 0.6769s	
15965/28500 (epoch 28.009), train_loss = 0.95847003, grad/param norm = 1.9867e-01, time/batch = 0.6768s	
15966/28500 (epoch 28.011), train_loss = 0.86188246, grad/param norm = 1.9926e-01, time/batch = 0.6778s	
15967/28500 (epoch 28.012), train_loss = 0.81230407, grad/param norm = 1.4987e-01, time/batch = 0.6766s	
15968/28500 (epoch 28.014), train_loss = 0.84636717, grad/param norm = 1.8878e-01, time/batch = 0.6764s	
15969/28500 (epoch 28.016), train_loss = 0.86701563, grad/param norm = 1.6888e-01, time/batch = 0.6770s	
15970/28500 (epoch 28.018), train_loss = 0.92860298, grad/param norm = 1.6999e-01, time/batch = 0.6769s	
15971/28500 (epoch 28.019), train_loss = 1.00149718, grad/param norm = 1.6873e-01, time/batch = 0.6804s	
15972/28500 (epoch 28.021), train_loss = 1.01037697, grad/param norm = 1.6261e-01, time/batch = 0.6775s	
15973/28500 (epoch 28.023), train_loss = 0.92674897, grad/param norm = 1.6942e-01, time/batch = 0.6764s	
15974/28500 (epoch 28.025), train_loss = 0.95530456, grad/param norm = 1.8252e-01, time/batch = 0.6773s	
15975/28500 (epoch 28.026), train_loss = 0.90974363, grad/param norm = 1.6067e-01, time/batch = 0.6787s	
15976/28500 (epoch 28.028), train_loss = 0.93475124, grad/param norm = 1.9416e-01, time/batch = 0.6805s	
15977/28500 (epoch 28.030), train_loss = 0.99532876, grad/param norm = 2.0289e-01, time/batch = 0.6821s	
15978/28500 (epoch 28.032), train_loss = 1.01450030, grad/param norm = 1.7174e-01, time/batch = 0.6834s	
15979/28500 (epoch 28.033), train_loss = 1.06898100, grad/param norm = 1.7327e-01, time/batch = 0.6825s	
15980/28500 (epoch 28.035), train_loss = 0.92226475, grad/param norm = 1.9043e-01, time/batch = 0.6854s	
15981/28500 (epoch 28.037), train_loss = 0.98171358, grad/param norm = 1.5896e-01, time/batch = 0.6912s	
15982/28500 (epoch 28.039), train_loss = 1.02545871, grad/param norm = 1.8852e-01, time/batch = 0.6974s	
15983/28500 (epoch 28.040), train_loss = 1.04288124, grad/param norm = 1.8447e-01, time/batch = 0.6960s	
15984/28500 (epoch 28.042), train_loss = 0.99480285, grad/param norm = 1.8898e-01, time/batch = 0.6914s	
15985/28500 (epoch 28.044), train_loss = 0.94491573, grad/param norm = 2.0015e-01, time/batch = 0.6955s	
15986/28500 (epoch 28.046), train_loss = 1.13974487, grad/param norm = 1.7831e-01, time/batch = 0.6929s	
15987/28500 (epoch 28.047), train_loss = 1.07847182, grad/param norm = 1.9918e-01, time/batch = 0.6937s	
15988/28500 (epoch 28.049), train_loss = 0.95923758, grad/param norm = 1.8494e-01, time/batch = 0.6898s	
15989/28500 (epoch 28.051), train_loss = 0.92423730, grad/param norm = 1.7471e-01, time/batch = 0.6890s	
15990/28500 (epoch 28.053), train_loss = 0.93878872, grad/param norm = 1.8963e-01, time/batch = 0.6892s	
15991/28500 (epoch 28.054), train_loss = 1.00752852, grad/param norm = 1.7324e-01, time/batch = 0.6909s	
15992/28500 (epoch 28.056), train_loss = 0.86579066, grad/param norm = 1.6651e-01, time/batch = 0.6889s	
15993/28500 (epoch 28.058), train_loss = 0.84170561, grad/param norm = 1.5072e-01, time/batch = 0.6887s	
15994/28500 (epoch 28.060), train_loss = 0.99715261, grad/param norm = 1.9845e-01, time/batch = 0.6923s	
15995/28500 (epoch 28.061), train_loss = 0.91814084, grad/param norm = 1.7151e-01, time/batch = 0.6892s	
15996/28500 (epoch 28.063), train_loss = 1.01820297, grad/param norm = 1.8910e-01, time/batch = 0.6908s	
15997/28500 (epoch 28.065), train_loss = 0.97717888, grad/param norm = 1.6805e-01, time/batch = 0.7114s	
15998/28500 (epoch 28.067), train_loss = 0.89850262, grad/param norm = 1.5901e-01, time/batch = 0.6904s	
15999/28500 (epoch 28.068), train_loss = 0.92427595, grad/param norm = 1.7131e-01, time/batch = 0.6938s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch28.07_1.8059.t7	
16000/28500 (epoch 28.070), train_loss = 0.97655695, grad/param norm = 1.7839e-01, time/batch = 0.6941s	
16001/28500 (epoch 28.072), train_loss = 1.59011515, grad/param norm = 2.6877e-01, time/batch = 0.6878s	
16002/28500 (epoch 28.074), train_loss = 0.96067396, grad/param norm = 1.8284e-01, time/batch = 0.6813s	
16003/28500 (epoch 28.075), train_loss = 0.91013957, grad/param norm = 1.5130e-01, time/batch = 0.6782s	
16004/28500 (epoch 28.077), train_loss = 0.99693644, grad/param norm = 1.6207e-01, time/batch = 0.6786s	
16005/28500 (epoch 28.079), train_loss = 0.93607416, grad/param norm = 1.6414e-01, time/batch = 0.6846s	
16006/28500 (epoch 28.081), train_loss = 1.06396167, grad/param norm = 1.9793e-01, time/batch = 0.6825s	
16007/28500 (epoch 28.082), train_loss = 0.96937315, grad/param norm = 1.9894e-01, time/batch = 0.6851s	
16008/28500 (epoch 28.084), train_loss = 0.97306711, grad/param norm = 1.7336e-01, time/batch = 0.6837s	
16009/28500 (epoch 28.086), train_loss = 0.91986379, grad/param norm = 2.0328e-01, time/batch = 0.6795s	
16010/28500 (epoch 28.088), train_loss = 0.84976491, grad/param norm = 1.6958e-01, time/batch = 0.6787s	
16011/28500 (epoch 28.089), train_loss = 1.03553301, grad/param norm = 1.7079e-01, time/batch = 0.6773s	
16012/28500 (epoch 28.091), train_loss = 0.80003546, grad/param norm = 1.5231e-01, time/batch = 0.6765s	
16013/28500 (epoch 28.093), train_loss = 1.00289954, grad/param norm = 1.6998e-01, time/batch = 0.6808s	
16014/28500 (epoch 28.095), train_loss = 0.90110667, grad/param norm = 1.5204e-01, time/batch = 0.6783s	
16015/28500 (epoch 28.096), train_loss = 1.03355305, grad/param norm = 1.8355e-01, time/batch = 0.6785s	
16016/28500 (epoch 28.098), train_loss = 0.96732839, grad/param norm = 1.9293e-01, time/batch = 0.6801s	
16017/28500 (epoch 28.100), train_loss = 0.89667878, grad/param norm = 1.6411e-01, time/batch = 0.6895s	
16018/28500 (epoch 28.102), train_loss = 1.01516604, grad/param norm = 2.2730e-01, time/batch = 0.6882s	
16019/28500 (epoch 28.104), train_loss = 0.94804716, grad/param norm = 1.9148e-01, time/batch = 0.6765s	
16020/28500 (epoch 28.105), train_loss = 1.06304562, grad/param norm = 1.6366e-01, time/batch = 0.6777s	
16021/28500 (epoch 28.107), train_loss = 0.85918528, grad/param norm = 1.6563e-01, time/batch = 0.6804s	
16022/28500 (epoch 28.109), train_loss = 0.86800744, grad/param norm = 1.9974e-01, time/batch = 0.6773s	
16023/28500 (epoch 28.111), train_loss = 0.90739892, grad/param norm = 1.8691e-01, time/batch = 0.6792s	
16024/28500 (epoch 28.112), train_loss = 1.01049452, grad/param norm = 1.6786e-01, time/batch = 0.6779s	
16025/28500 (epoch 28.114), train_loss = 0.89636214, grad/param norm = 1.6285e-01, time/batch = 0.6764s	
16026/28500 (epoch 28.116), train_loss = 1.08832231, grad/param norm = 1.8419e-01, time/batch = 0.6759s	
16027/28500 (epoch 28.118), train_loss = 0.82785946, grad/param norm = 1.8413e-01, time/batch = 0.6761s	
16028/28500 (epoch 28.119), train_loss = 0.96040013, grad/param norm = 1.7373e-01, time/batch = 0.6768s	
16029/28500 (epoch 28.121), train_loss = 1.10819662, grad/param norm = 2.0819e-01, time/batch = 0.6767s	
16030/28500 (epoch 28.123), train_loss = 1.02021355, grad/param norm = 2.1309e-01, time/batch = 0.6797s	
16031/28500 (epoch 28.125), train_loss = 0.97371264, grad/param norm = 2.0813e-01, time/batch = 0.6780s	
16032/28500 (epoch 28.126), train_loss = 0.93631205, grad/param norm = 1.6400e-01, time/batch = 0.6769s	
16033/28500 (epoch 28.128), train_loss = 0.95427510, grad/param norm = 1.6836e-01, time/batch = 0.6765s	
16034/28500 (epoch 28.130), train_loss = 0.88415715, grad/param norm = 2.0464e-01, time/batch = 0.6763s	
16035/28500 (epoch 28.132), train_loss = 0.93703891, grad/param norm = 1.7572e-01, time/batch = 0.6775s	
16036/28500 (epoch 28.133), train_loss = 0.99975330, grad/param norm = 1.8521e-01, time/batch = 0.6786s	
16037/28500 (epoch 28.135), train_loss = 0.90263100, grad/param norm = 1.6164e-01, time/batch = 0.6773s	
16038/28500 (epoch 28.137), train_loss = 0.96079837, grad/param norm = 1.7037e-01, time/batch = 0.6764s	
16039/28500 (epoch 28.139), train_loss = 0.94314850, grad/param norm = 1.6040e-01, time/batch = 0.6758s	
16040/28500 (epoch 28.140), train_loss = 0.95023882, grad/param norm = 1.8166e-01, time/batch = 0.6770s	
16041/28500 (epoch 28.142), train_loss = 0.92028415, grad/param norm = 1.8305e-01, time/batch = 0.6785s	
16042/28500 (epoch 28.144), train_loss = 0.85017223, grad/param norm = 1.5040e-01, time/batch = 0.6791s	
16043/28500 (epoch 28.146), train_loss = 0.91864996, grad/param norm = 1.6276e-01, time/batch = 0.6775s	
16044/28500 (epoch 28.147), train_loss = 0.81175503, grad/param norm = 1.5535e-01, time/batch = 0.6812s	
16045/28500 (epoch 28.149), train_loss = 0.81055964, grad/param norm = 1.5560e-01, time/batch = 0.6785s	
16046/28500 (epoch 28.151), train_loss = 0.89448569, grad/param norm = 1.7131e-01, time/batch = 0.6776s	
16047/28500 (epoch 28.153), train_loss = 0.96989696, grad/param norm = 1.8291e-01, time/batch = 0.6758s	
16048/28500 (epoch 28.154), train_loss = 0.83902417, grad/param norm = 1.5718e-01, time/batch = 0.6765s	
16049/28500 (epoch 28.156), train_loss = 1.03497224, grad/param norm = 1.8770e-01, time/batch = 0.6783s	
16050/28500 (epoch 28.158), train_loss = 0.94848025, grad/param norm = 1.5745e-01, time/batch = 0.6778s	
16051/28500 (epoch 28.160), train_loss = 0.84844896, grad/param norm = 1.5141e-01, time/batch = 0.6783s	
16052/28500 (epoch 28.161), train_loss = 0.89318453, grad/param norm = 1.9588e-01, time/batch = 0.6771s	
16053/28500 (epoch 28.163), train_loss = 0.80719561, grad/param norm = 1.6479e-01, time/batch = 0.6792s	
16054/28500 (epoch 28.165), train_loss = 1.11832927, grad/param norm = 1.7347e-01, time/batch = 0.6944s	
16055/28500 (epoch 28.167), train_loss = 1.12143184, grad/param norm = 1.9522e-01, time/batch = 0.6898s	
16056/28500 (epoch 28.168), train_loss = 1.03822498, grad/param norm = 1.8215e-01, time/batch = 0.6876s	
16057/28500 (epoch 28.170), train_loss = 1.02078271, grad/param norm = 1.9958e-01, time/batch = 0.6780s	
16058/28500 (epoch 28.172), train_loss = 0.94077026, grad/param norm = 1.5426e-01, time/batch = 0.6895s	
16059/28500 (epoch 28.174), train_loss = 1.10420283, grad/param norm = 2.1550e-01, time/batch = 0.6832s	
16060/28500 (epoch 28.175), train_loss = 0.91075491, grad/param norm = 1.5690e-01, time/batch = 0.6804s	
16061/28500 (epoch 28.177), train_loss = 0.99431404, grad/param norm = 1.8645e-01, time/batch = 0.6905s	
16062/28500 (epoch 28.179), train_loss = 1.00216068, grad/param norm = 1.9220e-01, time/batch = 0.6822s	
16063/28500 (epoch 28.181), train_loss = 0.99060307, grad/param norm = 1.7956e-01, time/batch = 0.6793s	
16064/28500 (epoch 28.182), train_loss = 0.90729975, grad/param norm = 1.6695e-01, time/batch = 0.6830s	
16065/28500 (epoch 28.184), train_loss = 1.09705583, grad/param norm = 2.0285e-01, time/batch = 0.6826s	
16066/28500 (epoch 28.186), train_loss = 1.06053881, grad/param norm = 1.8008e-01, time/batch = 0.6836s	
16067/28500 (epoch 28.188), train_loss = 0.98175367, grad/param norm = 1.7491e-01, time/batch = 0.6896s	
16068/28500 (epoch 28.189), train_loss = 0.94896023, grad/param norm = 1.6412e-01, time/batch = 0.6829s	
16069/28500 (epoch 28.191), train_loss = 1.16285455, grad/param norm = 1.8927e-01, time/batch = 0.6804s	
16070/28500 (epoch 28.193), train_loss = 0.97428366, grad/param norm = 1.8699e-01, time/batch = 0.6804s	
16071/28500 (epoch 28.195), train_loss = 1.09815279, grad/param norm = 2.0859e-01, time/batch = 0.6847s	
16072/28500 (epoch 28.196), train_loss = 0.99819949, grad/param norm = 1.7242e-01, time/batch = 0.6803s	
16073/28500 (epoch 28.198), train_loss = 0.94527149, grad/param norm = 1.6008e-01, time/batch = 0.6793s	
16074/28500 (epoch 28.200), train_loss = 1.00482811, grad/param norm = 1.7033e-01, time/batch = 0.6803s	
16075/28500 (epoch 28.202), train_loss = 0.97889525, grad/param norm = 1.7567e-01, time/batch = 0.6805s	
16076/28500 (epoch 28.204), train_loss = 0.92387434, grad/param norm = 1.6146e-01, time/batch = 0.6801s	
16077/28500 (epoch 28.205), train_loss = 0.90779117, grad/param norm = 1.7776e-01, time/batch = 0.6787s	
16078/28500 (epoch 28.207), train_loss = 0.85038366, grad/param norm = 1.8008e-01, time/batch = 0.6791s	
16079/28500 (epoch 28.209), train_loss = 0.97797327, grad/param norm = 1.7072e-01, time/batch = 0.6784s	
16080/28500 (epoch 28.211), train_loss = 0.85064307, grad/param norm = 1.6450e-01, time/batch = 0.6792s	
16081/28500 (epoch 28.212), train_loss = 0.79999762, grad/param norm = 1.5812e-01, time/batch = 0.6807s	
16082/28500 (epoch 28.214), train_loss = 0.93191016, grad/param norm = 1.9043e-01, time/batch = 0.6826s	
16083/28500 (epoch 28.216), train_loss = 0.87861662, grad/param norm = 1.7938e-01, time/batch = 0.6859s	
16084/28500 (epoch 28.218), train_loss = 1.04063920, grad/param norm = 1.6455e-01, time/batch = 0.6811s	
16085/28500 (epoch 28.219), train_loss = 0.98534560, grad/param norm = 1.7991e-01, time/batch = 0.6826s	
16086/28500 (epoch 28.221), train_loss = 0.82479326, grad/param norm = 1.7624e-01, time/batch = 0.6807s	
16087/28500 (epoch 28.223), train_loss = 1.06087082, grad/param norm = 1.8439e-01, time/batch = 0.6835s	
16088/28500 (epoch 28.225), train_loss = 1.08879539, grad/param norm = 2.0350e-01, time/batch = 0.6803s	
16089/28500 (epoch 28.226), train_loss = 0.89783018, grad/param norm = 1.5867e-01, time/batch = 0.6813s	
16090/28500 (epoch 28.228), train_loss = 1.03770475, grad/param norm = 1.6532e-01, time/batch = 0.6797s	
16091/28500 (epoch 28.230), train_loss = 1.02865483, grad/param norm = 1.8132e-01, time/batch = 0.6869s	
16092/28500 (epoch 28.232), train_loss = 0.98185124, grad/param norm = 1.8684e-01, time/batch = 0.6795s	
16093/28500 (epoch 28.233), train_loss = 0.96222566, grad/param norm = 1.8090e-01, time/batch = 0.6818s	
16094/28500 (epoch 28.235), train_loss = 0.92919330, grad/param norm = 1.7357e-01, time/batch = 0.6804s	
16095/28500 (epoch 28.237), train_loss = 0.84819982, grad/param norm = 1.5496e-01, time/batch = 0.6807s	
16096/28500 (epoch 28.239), train_loss = 0.89251726, grad/param norm = 1.5228e-01, time/batch = 0.6809s	
16097/28500 (epoch 28.240), train_loss = 0.84776912, grad/param norm = 1.6455e-01, time/batch = 0.6807s	
16098/28500 (epoch 28.242), train_loss = 0.94475203, grad/param norm = 1.8340e-01, time/batch = 0.6799s	
16099/28500 (epoch 28.244), train_loss = 0.98176449, grad/param norm = 1.6117e-01, time/batch = 0.6829s	
16100/28500 (epoch 28.246), train_loss = 1.01726017, grad/param norm = 1.8503e-01, time/batch = 0.6860s	
16101/28500 (epoch 28.247), train_loss = 1.06926694, grad/param norm = 1.8610e-01, time/batch = 0.6848s	
16102/28500 (epoch 28.249), train_loss = 0.93003697, grad/param norm = 1.6373e-01, time/batch = 0.6966s	
16103/28500 (epoch 28.251), train_loss = 0.90943132, grad/param norm = 1.5659e-01, time/batch = 0.7072s	
16104/28500 (epoch 28.253), train_loss = 1.05654153, grad/param norm = 1.8948e-01, time/batch = 0.6954s	
16105/28500 (epoch 28.254), train_loss = 1.09051114, grad/param norm = 1.6640e-01, time/batch = 0.6984s	
16106/28500 (epoch 28.256), train_loss = 0.91116985, grad/param norm = 1.6595e-01, time/batch = 0.6835s	
16107/28500 (epoch 28.258), train_loss = 0.91842103, grad/param norm = 1.6948e-01, time/batch = 0.6823s	
16108/28500 (epoch 28.260), train_loss = 0.90624715, grad/param norm = 1.6100e-01, time/batch = 0.6800s	
16109/28500 (epoch 28.261), train_loss = 0.86028984, grad/param norm = 1.6303e-01, time/batch = 0.6810s	
16110/28500 (epoch 28.263), train_loss = 1.01418218, grad/param norm = 1.8571e-01, time/batch = 0.6803s	
16111/28500 (epoch 28.265), train_loss = 0.92858314, grad/param norm = 1.7543e-01, time/batch = 0.6844s	
16112/28500 (epoch 28.267), train_loss = 1.06573623, grad/param norm = 1.8163e-01, time/batch = 0.6826s	
16113/28500 (epoch 28.268), train_loss = 1.00873172, grad/param norm = 1.6773e-01, time/batch = 0.6790s	
16114/28500 (epoch 28.270), train_loss = 0.98757588, grad/param norm = 1.9385e-01, time/batch = 0.6794s	
16115/28500 (epoch 28.272), train_loss = 0.94546841, grad/param norm = 1.6839e-01, time/batch = 0.6793s	
16116/28500 (epoch 28.274), train_loss = 1.02238254, grad/param norm = 1.7159e-01, time/batch = 0.6813s	
16117/28500 (epoch 28.275), train_loss = 0.98351799, grad/param norm = 1.5463e-01, time/batch = 0.6818s	
16118/28500 (epoch 28.277), train_loss = 0.94759613, grad/param norm = 1.8503e-01, time/batch = 0.6808s	
16119/28500 (epoch 28.279), train_loss = 0.95408153, grad/param norm = 1.8495e-01, time/batch = 0.6810s	
16120/28500 (epoch 28.281), train_loss = 1.02947726, grad/param norm = 2.1863e-01, time/batch = 0.6795s	
16121/28500 (epoch 28.282), train_loss = 0.90038812, grad/param norm = 1.5048e-01, time/batch = 0.6835s	
16122/28500 (epoch 28.284), train_loss = 0.94691267, grad/param norm = 1.9237e-01, time/batch = 0.6807s	
16123/28500 (epoch 28.286), train_loss = 1.08381298, grad/param norm = 1.7569e-01, time/batch = 0.6811s	
16124/28500 (epoch 28.288), train_loss = 0.96715757, grad/param norm = 1.9430e-01, time/batch = 0.6802s	
16125/28500 (epoch 28.289), train_loss = 0.98539807, grad/param norm = 1.8788e-01, time/batch = 0.6817s	
16126/28500 (epoch 28.291), train_loss = 0.95703693, grad/param norm = 1.5898e-01, time/batch = 0.6802s	
16127/28500 (epoch 28.293), train_loss = 0.93036359, grad/param norm = 1.5739e-01, time/batch = 0.6805s	
16128/28500 (epoch 28.295), train_loss = 0.85973663, grad/param norm = 1.6003e-01, time/batch = 0.6802s	
16129/28500 (epoch 28.296), train_loss = 0.83387896, grad/param norm = 1.6224e-01, time/batch = 0.6787s	
16130/28500 (epoch 28.298), train_loss = 0.99340740, grad/param norm = 1.4919e-01, time/batch = 0.6804s	
16131/28500 (epoch 28.300), train_loss = 0.87396518, grad/param norm = 1.6466e-01, time/batch = 0.6842s	
16132/28500 (epoch 28.302), train_loss = 0.85494560, grad/param norm = 1.7276e-01, time/batch = 0.6827s	
16133/28500 (epoch 28.304), train_loss = 0.90923053, grad/param norm = 1.6702e-01, time/batch = 0.6802s	
16134/28500 (epoch 28.305), train_loss = 0.97878572, grad/param norm = 1.6476e-01, time/batch = 0.6809s	
16135/28500 (epoch 28.307), train_loss = 0.93631214, grad/param norm = 1.6434e-01, time/batch = 0.6807s	
16136/28500 (epoch 28.309), train_loss = 0.94242573, grad/param norm = 1.7358e-01, time/batch = 0.6801s	
16137/28500 (epoch 28.311), train_loss = 0.99584336, grad/param norm = 1.7406e-01, time/batch = 0.6817s	
16138/28500 (epoch 28.312), train_loss = 0.98091118, grad/param norm = 1.6786e-01, time/batch = 0.6806s	
16139/28500 (epoch 28.314), train_loss = 1.00543611, grad/param norm = 1.8611e-01, time/batch = 0.6796s	
16140/28500 (epoch 28.316), train_loss = 0.95300543, grad/param norm = 1.7864e-01, time/batch = 0.6811s	
16141/28500 (epoch 28.318), train_loss = 1.03961669, grad/param norm = 1.7988e-01, time/batch = 0.6829s	
16142/28500 (epoch 28.319), train_loss = 0.91564520, grad/param norm = 1.7505e-01, time/batch = 0.6842s	
16143/28500 (epoch 28.321), train_loss = 0.92457085, grad/param norm = 1.9151e-01, time/batch = 0.6852s	
16144/28500 (epoch 28.323), train_loss = 0.89100754, grad/param norm = 1.6868e-01, time/batch = 0.7036s	
16145/28500 (epoch 28.325), train_loss = 1.07641775, grad/param norm = 1.7496e-01, time/batch = 0.6846s	
16146/28500 (epoch 28.326), train_loss = 0.98233647, grad/param norm = 1.7897e-01, time/batch = 0.6909s	
16147/28500 (epoch 28.328), train_loss = 0.77946885, grad/param norm = 1.7095e-01, time/batch = 0.6863s	
16148/28500 (epoch 28.330), train_loss = 0.88290739, grad/param norm = 1.9036e-01, time/batch = 0.6859s	
16149/28500 (epoch 28.332), train_loss = 0.94164545, grad/param norm = 1.7572e-01, time/batch = 0.6905s	
16150/28500 (epoch 28.333), train_loss = 0.75201750, grad/param norm = 1.5267e-01, time/batch = 0.6792s	
16151/28500 (epoch 28.335), train_loss = 0.82096281, grad/param norm = 1.4861e-01, time/batch = 0.6806s	
16152/28500 (epoch 28.337), train_loss = 0.80307236, grad/param norm = 1.4578e-01, time/batch = 0.6806s	
16153/28500 (epoch 28.339), train_loss = 0.78613688, grad/param norm = 1.4169e-01, time/batch = 0.6830s	
16154/28500 (epoch 28.340), train_loss = 0.93499187, grad/param norm = 1.9361e-01, time/batch = 0.6811s	
16155/28500 (epoch 28.342), train_loss = 0.92910819, grad/param norm = 1.6729e-01, time/batch = 0.6821s	
16156/28500 (epoch 28.344), train_loss = 0.86215094, grad/param norm = 1.7975e-01, time/batch = 0.6818s	
16157/28500 (epoch 28.346), train_loss = 0.77022598, grad/param norm = 1.4883e-01, time/batch = 0.6857s	
16158/28500 (epoch 28.347), train_loss = 0.92996438, grad/param norm = 1.6278e-01, time/batch = 0.7064s	
16159/28500 (epoch 28.349), train_loss = 0.91095685, grad/param norm = 1.5854e-01, time/batch = 0.6924s	
16160/28500 (epoch 28.351), train_loss = 0.84462247, grad/param norm = 1.5814e-01, time/batch = 0.6790s	
16161/28500 (epoch 28.353), train_loss = 0.93015373, grad/param norm = 1.7517e-01, time/batch = 0.6832s	
16162/28500 (epoch 28.354), train_loss = 0.83932620, grad/param norm = 1.5174e-01, time/batch = 0.6786s	
16163/28500 (epoch 28.356), train_loss = 0.86389458, grad/param norm = 1.5873e-01, time/batch = 0.6854s	
16164/28500 (epoch 28.358), train_loss = 0.96667181, grad/param norm = 1.7566e-01, time/batch = 0.6921s	
16165/28500 (epoch 28.360), train_loss = 0.93993569, grad/param norm = 1.7742e-01, time/batch = 0.6958s	
16166/28500 (epoch 28.361), train_loss = 0.86169232, grad/param norm = 1.5846e-01, time/batch = 0.6833s	
16167/28500 (epoch 28.363), train_loss = 0.83250580, grad/param norm = 1.4896e-01, time/batch = 0.6823s	
16168/28500 (epoch 28.365), train_loss = 0.91287341, grad/param norm = 1.9478e-01, time/batch = 0.6837s	
16169/28500 (epoch 28.367), train_loss = 0.94074653, grad/param norm = 1.6410e-01, time/batch = 0.6845s	
16170/28500 (epoch 28.368), train_loss = 0.86826048, grad/param norm = 1.6627e-01, time/batch = 0.6899s	
16171/28500 (epoch 28.370), train_loss = 0.92775953, grad/param norm = 1.6340e-01, time/batch = 0.6857s	
16172/28500 (epoch 28.372), train_loss = 0.76391710, grad/param norm = 1.4444e-01, time/batch = 0.6961s	
16173/28500 (epoch 28.374), train_loss = 0.89660846, grad/param norm = 1.8503e-01, time/batch = 0.6862s	
16174/28500 (epoch 28.375), train_loss = 1.02707401, grad/param norm = 1.8258e-01, time/batch = 0.6827s	
16175/28500 (epoch 28.377), train_loss = 0.80492206, grad/param norm = 1.9188e-01, time/batch = 0.6786s	
16176/28500 (epoch 28.379), train_loss = 0.72688077, grad/param norm = 1.5449e-01, time/batch = 0.6767s	
16177/28500 (epoch 28.381), train_loss = 0.89998720, grad/param norm = 1.5972e-01, time/batch = 0.6808s	
16178/28500 (epoch 28.382), train_loss = 0.86862654, grad/param norm = 1.8686e-01, time/batch = 0.6810s	
16179/28500 (epoch 28.384), train_loss = 0.78458303, grad/param norm = 1.5363e-01, time/batch = 0.6794s	
16180/28500 (epoch 28.386), train_loss = 0.83133196, grad/param norm = 1.6045e-01, time/batch = 0.6766s	
16181/28500 (epoch 28.388), train_loss = 1.01953606, grad/param norm = 1.7237e-01, time/batch = 0.6812s	
16182/28500 (epoch 28.389), train_loss = 0.86766872, grad/param norm = 1.8272e-01, time/batch = 0.6779s	
16183/28500 (epoch 28.391), train_loss = 0.80408832, grad/param norm = 1.6596e-01, time/batch = 0.6772s	
16184/28500 (epoch 28.393), train_loss = 0.84024007, grad/param norm = 1.7955e-01, time/batch = 0.6828s	
16185/28500 (epoch 28.395), train_loss = 1.03998250, grad/param norm = 1.7666e-01, time/batch = 0.6782s	
16186/28500 (epoch 28.396), train_loss = 0.99356762, grad/param norm = 1.8105e-01, time/batch = 0.6786s	
16187/28500 (epoch 28.398), train_loss = 0.69256861, grad/param norm = 1.5557e-01, time/batch = 0.6816s	
16188/28500 (epoch 28.400), train_loss = 0.89316253, grad/param norm = 1.7182e-01, time/batch = 0.6931s	
16189/28500 (epoch 28.402), train_loss = 0.94585380, grad/param norm = 2.1470e-01, time/batch = 0.6915s	
16190/28500 (epoch 28.404), train_loss = 0.96003194, grad/param norm = 1.9154e-01, time/batch = 0.6777s	
16191/28500 (epoch 28.405), train_loss = 0.97524230, grad/param norm = 1.7374e-01, time/batch = 0.6814s	
16192/28500 (epoch 28.407), train_loss = 0.95113517, grad/param norm = 1.6728e-01, time/batch = 0.6767s	
16193/28500 (epoch 28.409), train_loss = 0.93908009, grad/param norm = 1.6428e-01, time/batch = 0.6767s	
16194/28500 (epoch 28.411), train_loss = 1.01716249, grad/param norm = 1.7582e-01, time/batch = 0.6766s	
16195/28500 (epoch 28.412), train_loss = 1.05530539, grad/param norm = 1.9430e-01, time/batch = 0.6798s	
16196/28500 (epoch 28.414), train_loss = 0.95244809, grad/param norm = 1.8445e-01, time/batch = 0.6780s	
16197/28500 (epoch 28.416), train_loss = 0.85089894, grad/param norm = 1.7542e-01, time/batch = 0.6775s	
16198/28500 (epoch 28.418), train_loss = 0.95383177, grad/param norm = 1.5430e-01, time/batch = 0.6782s	
16199/28500 (epoch 28.419), train_loss = 1.05635845, grad/param norm = 1.9844e-01, time/batch = 0.6764s	
16200/28500 (epoch 28.421), train_loss = 0.99938861, grad/param norm = 1.6421e-01, time/batch = 0.6759s	
16201/28500 (epoch 28.423), train_loss = 1.02868445, grad/param norm = 1.9860e-01, time/batch = 0.6791s	
16202/28500 (epoch 28.425), train_loss = 0.96197801, grad/param norm = 2.1059e-01, time/batch = 0.6769s	
16203/28500 (epoch 28.426), train_loss = 0.94437391, grad/param norm = 2.0501e-01, time/batch = 0.6765s	
16204/28500 (epoch 28.428), train_loss = 1.08089669, grad/param norm = 1.8856e-01, time/batch = 0.6767s	
16205/28500 (epoch 28.430), train_loss = 1.06598168, grad/param norm = 1.7147e-01, time/batch = 0.6811s	
16206/28500 (epoch 28.432), train_loss = 0.95329696, grad/param norm = 2.0398e-01, time/batch = 0.6801s	
16207/28500 (epoch 28.433), train_loss = 0.99171916, grad/param norm = 1.7526e-01, time/batch = 0.6774s	
16208/28500 (epoch 28.435), train_loss = 0.97683292, grad/param norm = 1.8908e-01, time/batch = 0.6765s	
16209/28500 (epoch 28.437), train_loss = 0.87745883, grad/param norm = 1.7508e-01, time/batch = 0.6762s	
16210/28500 (epoch 28.439), train_loss = 0.89411445, grad/param norm = 1.4419e-01, time/batch = 0.6759s	
16211/28500 (epoch 28.440), train_loss = 1.09547910, grad/param norm = 1.9128e-01, time/batch = 0.6793s	
16212/28500 (epoch 28.442), train_loss = 0.87707166, grad/param norm = 1.8919e-01, time/batch = 0.6784s	
16213/28500 (epoch 28.444), train_loss = 0.82746209, grad/param norm = 1.5081e-01, time/batch = 0.6981s	
16214/28500 (epoch 28.446), train_loss = 0.79097641, grad/param norm = 1.7670e-01, time/batch = 0.6913s	
16215/28500 (epoch 28.447), train_loss = 0.80957374, grad/param norm = 1.5006e-01, time/batch = 0.6837s	
16216/28500 (epoch 28.449), train_loss = 0.88289485, grad/param norm = 1.5767e-01, time/batch = 0.6818s	
16217/28500 (epoch 28.451), train_loss = 0.90984743, grad/param norm = 1.5633e-01, time/batch = 0.6800s	
16218/28500 (epoch 28.453), train_loss = 0.90786838, grad/param norm = 1.7666e-01, time/batch = 0.6767s	
16219/28500 (epoch 28.454), train_loss = 0.87189126, grad/param norm = 1.5510e-01, time/batch = 0.6792s	
16220/28500 (epoch 28.456), train_loss = 0.98634427, grad/param norm = 2.0160e-01, time/batch = 0.6794s	
16221/28500 (epoch 28.458), train_loss = 0.91137900, grad/param norm = 1.8977e-01, time/batch = 0.6787s	
16222/28500 (epoch 28.460), train_loss = 0.98516677, grad/param norm = 1.6357e-01, time/batch = 0.6790s	
16223/28500 (epoch 28.461), train_loss = 0.85947015, grad/param norm = 1.7332e-01, time/batch = 0.6767s	
16224/28500 (epoch 28.463), train_loss = 0.79042821, grad/param norm = 1.4584e-01, time/batch = 0.6817s	
16225/28500 (epoch 28.465), train_loss = 0.80522062, grad/param norm = 1.9308e-01, time/batch = 0.6825s	
16226/28500 (epoch 28.467), train_loss = 0.94695597, grad/param norm = 1.8119e-01, time/batch = 0.6795s	
16227/28500 (epoch 28.468), train_loss = 0.83113696, grad/param norm = 1.4928e-01, time/batch = 0.6770s	
16228/28500 (epoch 28.470), train_loss = 0.89045573, grad/param norm = 1.8392e-01, time/batch = 0.6781s	
16229/28500 (epoch 28.472), train_loss = 0.85043892, grad/param norm = 1.4808e-01, time/batch = 0.6780s	
16230/28500 (epoch 28.474), train_loss = 1.06517828, grad/param norm = 1.9891e-01, time/batch = 0.6782s	
16231/28500 (epoch 28.475), train_loss = 0.86974455, grad/param norm = 1.7717e-01, time/batch = 0.6881s	
16232/28500 (epoch 28.477), train_loss = 0.88858719, grad/param norm = 1.6901e-01, time/batch = 0.7068s	
16233/28500 (epoch 28.479), train_loss = 0.96826971, grad/param norm = 1.7249e-01, time/batch = 0.6957s	
16234/28500 (epoch 28.481), train_loss = 0.97044099, grad/param norm = 1.9596e-01, time/batch = 0.7126s	
16235/28500 (epoch 28.482), train_loss = 0.81354823, grad/param norm = 1.5946e-01, time/batch = 0.7039s	
16236/28500 (epoch 28.484), train_loss = 0.84772120, grad/param norm = 1.7376e-01, time/batch = 0.7003s	
16237/28500 (epoch 28.486), train_loss = 0.74306480, grad/param norm = 1.8964e-01, time/batch = 0.6983s	
16238/28500 (epoch 28.488), train_loss = 0.95112733, grad/param norm = 1.5534e-01, time/batch = 0.7109s	
16239/28500 (epoch 28.489), train_loss = 1.03073559, grad/param norm = 1.6357e-01, time/batch = 0.7076s	
16240/28500 (epoch 28.491), train_loss = 0.87270623, grad/param norm = 1.8137e-01, time/batch = 0.7036s	
16241/28500 (epoch 28.493), train_loss = 0.91241146, grad/param norm = 1.5233e-01, time/batch = 0.7089s	
16242/28500 (epoch 28.495), train_loss = 0.93048091, grad/param norm = 1.7528e-01, time/batch = 0.6977s	
16243/28500 (epoch 28.496), train_loss = 0.84455321, grad/param norm = 1.8854e-01, time/batch = 0.6974s	
16244/28500 (epoch 28.498), train_loss = 0.90278667, grad/param norm = 1.5477e-01, time/batch = 0.6978s	
16245/28500 (epoch 28.500), train_loss = 0.85140230, grad/param norm = 1.5561e-01, time/batch = 0.6981s	
16246/28500 (epoch 28.502), train_loss = 0.97988804, grad/param norm = 1.5590e-01, time/batch = 0.6987s	
16247/28500 (epoch 28.504), train_loss = 0.96301691, grad/param norm = 1.6053e-01, time/batch = 0.6982s	
16248/28500 (epoch 28.505), train_loss = 0.86647110, grad/param norm = 1.6462e-01, time/batch = 0.7011s	
16249/28500 (epoch 28.507), train_loss = 1.02687174, grad/param norm = 2.2994e-01, time/batch = 0.7046s	
16250/28500 (epoch 28.509), train_loss = 0.91826731, grad/param norm = 1.6852e-01, time/batch = 0.7043s	
16251/28500 (epoch 28.511), train_loss = 0.93452264, grad/param norm = 1.8115e-01, time/batch = 0.7053s	
16252/28500 (epoch 28.512), train_loss = 0.96185570, grad/param norm = 1.7757e-01, time/batch = 0.7008s	
16253/28500 (epoch 28.514), train_loss = 0.90248136, grad/param norm = 1.5696e-01, time/batch = 0.7001s	
16254/28500 (epoch 28.516), train_loss = 0.88852409, grad/param norm = 1.6085e-01, time/batch = 0.6984s	
16255/28500 (epoch 28.518), train_loss = 0.94922289, grad/param norm = 1.7307e-01, time/batch = 0.6994s	
16256/28500 (epoch 28.519), train_loss = 1.00298130, grad/param norm = 1.7343e-01, time/batch = 0.6975s	
16257/28500 (epoch 28.521), train_loss = 1.05714604, grad/param norm = 2.3342e-01, time/batch = 0.6977s	
16258/28500 (epoch 28.523), train_loss = 0.98964101, grad/param norm = 1.9006e-01, time/batch = 0.6967s	
16259/28500 (epoch 28.525), train_loss = 1.05396473, grad/param norm = 1.7628e-01, time/batch = 0.6975s	
16260/28500 (epoch 28.526), train_loss = 0.99710657, grad/param norm = 1.6279e-01, time/batch = 0.6987s	
16261/28500 (epoch 28.528), train_loss = 0.98383260, grad/param norm = 1.8448e-01, time/batch = 0.7014s	
16262/28500 (epoch 28.530), train_loss = 1.00130500, grad/param norm = 1.7070e-01, time/batch = 0.6983s	
16263/28500 (epoch 28.532), train_loss = 0.89007294, grad/param norm = 1.5392e-01, time/batch = 0.6959s	
16264/28500 (epoch 28.533), train_loss = 0.99675564, grad/param norm = 1.7483e-01, time/batch = 0.6969s	
16265/28500 (epoch 28.535), train_loss = 0.80304510, grad/param norm = 1.4112e-01, time/batch = 0.6954s	
16266/28500 (epoch 28.537), train_loss = 0.82958631, grad/param norm = 1.5703e-01, time/batch = 0.6973s	
16267/28500 (epoch 28.539), train_loss = 0.78134654, grad/param norm = 1.6353e-01, time/batch = 0.6955s	
16268/28500 (epoch 28.540), train_loss = 0.93859637, grad/param norm = 1.7680e-01, time/batch = 0.6964s	
16269/28500 (epoch 28.542), train_loss = 0.96064395, grad/param norm = 1.9026e-01, time/batch = 0.6977s	
16270/28500 (epoch 28.544), train_loss = 1.06327527, grad/param norm = 2.0144e-01, time/batch = 0.6968s	
16271/28500 (epoch 28.546), train_loss = 0.91466890, grad/param norm = 1.6314e-01, time/batch = 0.6986s	
16272/28500 (epoch 28.547), train_loss = 0.93289534, grad/param norm = 1.6805e-01, time/batch = 0.6953s	
16273/28500 (epoch 28.549), train_loss = 0.76643542, grad/param norm = 1.3657e-01, time/batch = 0.6969s	
16274/28500 (epoch 28.551), train_loss = 0.89656364, grad/param norm = 2.0364e-01, time/batch = 0.6957s	
16275/28500 (epoch 28.553), train_loss = 1.10855756, grad/param norm = 2.0841e-01, time/batch = 0.6986s	
16276/28500 (epoch 28.554), train_loss = 0.97030225, grad/param norm = 1.7460e-01, time/batch = 0.6970s	
16277/28500 (epoch 28.556), train_loss = 0.96873000, grad/param norm = 1.8947e-01, time/batch = 0.6981s	
16278/28500 (epoch 28.558), train_loss = 0.97428097, grad/param norm = 1.6550e-01, time/batch = 0.6969s	
16279/28500 (epoch 28.560), train_loss = 0.95160556, grad/param norm = 1.9040e-01, time/batch = 0.6937s	
16280/28500 (epoch 28.561), train_loss = 1.00254377, grad/param norm = 1.9016e-01, time/batch = 0.6934s	
16281/28500 (epoch 28.563), train_loss = 1.06395189, grad/param norm = 2.0252e-01, time/batch = 0.6964s	
16282/28500 (epoch 28.565), train_loss = 0.87664608, grad/param norm = 1.7547e-01, time/batch = 0.6935s	
16283/28500 (epoch 28.567), train_loss = 0.82387125, grad/param norm = 1.5364e-01, time/batch = 0.6939s	
16284/28500 (epoch 28.568), train_loss = 0.96735963, grad/param norm = 1.8460e-01, time/batch = 0.6933s	
16285/28500 (epoch 28.570), train_loss = 0.89892398, grad/param norm = 1.6515e-01, time/batch = 0.6940s	
16286/28500 (epoch 28.572), train_loss = 0.93191902, grad/param norm = 1.6652e-01, time/batch = 0.6950s	
16287/28500 (epoch 28.574), train_loss = 0.87742735, grad/param norm = 1.6389e-01, time/batch = 0.6945s	
16288/28500 (epoch 28.575), train_loss = 0.89594875, grad/param norm = 1.6901e-01, time/batch = 0.6930s	
16289/28500 (epoch 28.577), train_loss = 0.96472937, grad/param norm = 1.6563e-01, time/batch = 0.6928s	
16290/28500 (epoch 28.579), train_loss = 1.00458838, grad/param norm = 1.8216e-01, time/batch = 0.6930s	
16291/28500 (epoch 28.581), train_loss = 0.85718459, grad/param norm = 1.9751e-01, time/batch = 0.6950s	
16292/28500 (epoch 28.582), train_loss = 1.00766590, grad/param norm = 1.8680e-01, time/batch = 0.6954s	
16293/28500 (epoch 28.584), train_loss = 0.88633983, grad/param norm = 1.7979e-01, time/batch = 0.6960s	
16294/28500 (epoch 28.586), train_loss = 0.85502154, grad/param norm = 1.5268e-01, time/batch = 0.6933s	
16295/28500 (epoch 28.588), train_loss = 0.86534249, grad/param norm = 1.6914e-01, time/batch = 0.6930s	
16296/28500 (epoch 28.589), train_loss = 0.93099773, grad/param norm = 2.0529e-01, time/batch = 0.6932s	
16297/28500 (epoch 28.591), train_loss = 0.94331614, grad/param norm = 1.6984e-01, time/batch = 0.6934s	
16298/28500 (epoch 28.593), train_loss = 0.87226225, grad/param norm = 1.6380e-01, time/batch = 0.6934s	
16299/28500 (epoch 28.595), train_loss = 1.12653300, grad/param norm = 2.0527e-01, time/batch = 0.6933s	
16300/28500 (epoch 28.596), train_loss = 1.08066531, grad/param norm = 1.7940e-01, time/batch = 0.6931s	
16301/28500 (epoch 28.598), train_loss = 0.93946041, grad/param norm = 1.8030e-01, time/batch = 0.6954s	
16302/28500 (epoch 28.600), train_loss = 0.95586725, grad/param norm = 2.1117e-01, time/batch = 0.6939s	
16303/28500 (epoch 28.602), train_loss = 0.98788404, grad/param norm = 1.8236e-01, time/batch = 0.6929s	
16304/28500 (epoch 28.604), train_loss = 1.01191164, grad/param norm = 1.5690e-01, time/batch = 0.6929s	
16305/28500 (epoch 28.605), train_loss = 1.00175729, grad/param norm = 1.7465e-01, time/batch = 0.6948s	
16306/28500 (epoch 28.607), train_loss = 1.02936932, grad/param norm = 1.5793e-01, time/batch = 0.6942s	
16307/28500 (epoch 28.609), train_loss = 0.95285559, grad/param norm = 1.6983e-01, time/batch = 0.6947s	
16308/28500 (epoch 28.611), train_loss = 0.90356531, grad/param norm = 1.7382e-01, time/batch = 0.6943s	
16309/28500 (epoch 28.612), train_loss = 0.97936079, grad/param norm = 1.9980e-01, time/batch = 0.6957s	
16310/28500 (epoch 28.614), train_loss = 0.98295651, grad/param norm = 1.7287e-01, time/batch = 0.6947s	
16311/28500 (epoch 28.616), train_loss = 0.91906139, grad/param norm = 1.9054e-01, time/batch = 0.6964s	
16312/28500 (epoch 28.618), train_loss = 0.90947503, grad/param norm = 1.8017e-01, time/batch = 0.6970s	
16313/28500 (epoch 28.619), train_loss = 1.04763863, grad/param norm = 2.2881e-01, time/batch = 0.6946s	
16314/28500 (epoch 28.621), train_loss = 0.77211934, grad/param norm = 1.4840e-01, time/batch = 0.6947s	
16315/28500 (epoch 28.623), train_loss = 1.02849718, grad/param norm = 2.0623e-01, time/batch = 0.6953s	
16316/28500 (epoch 28.625), train_loss = 0.84680088, grad/param norm = 1.7254e-01, time/batch = 0.6984s	
16317/28500 (epoch 28.626), train_loss = 0.71711805, grad/param norm = 1.4097e-01, time/batch = 0.7058s	
16318/28500 (epoch 28.628), train_loss = 0.85633141, grad/param norm = 1.6921e-01, time/batch = 0.6954s	
16319/28500 (epoch 28.630), train_loss = 0.81057189, grad/param norm = 1.5852e-01, time/batch = 0.6933s	
16320/28500 (epoch 28.632), train_loss = 1.02125094, grad/param norm = 1.8035e-01, time/batch = 0.6968s	
16321/28500 (epoch 28.633), train_loss = 1.07495485, grad/param norm = 1.6633e-01, time/batch = 0.6964s	
16322/28500 (epoch 28.635), train_loss = 0.97218237, grad/param norm = 1.7133e-01, time/batch = 0.6977s	
16323/28500 (epoch 28.637), train_loss = 0.94587045, grad/param norm = 1.7028e-01, time/batch = 0.6963s	
16324/28500 (epoch 28.639), train_loss = 0.83240262, grad/param norm = 1.6590e-01, time/batch = 0.7010s	
16325/28500 (epoch 28.640), train_loss = 0.86721056, grad/param norm = 1.8645e-01, time/batch = 0.7104s	
16326/28500 (epoch 28.642), train_loss = 0.88035565, grad/param norm = 1.5935e-01, time/batch = 0.7004s	
16327/28500 (epoch 28.644), train_loss = 1.00638471, grad/param norm = 1.8037e-01, time/batch = 0.6987s	
16328/28500 (epoch 28.646), train_loss = 0.80131058, grad/param norm = 1.4710e-01, time/batch = 0.6992s	
16329/28500 (epoch 28.647), train_loss = 0.84312491, grad/param norm = 1.5589e-01, time/batch = 0.6994s	
16330/28500 (epoch 28.649), train_loss = 0.81388003, grad/param norm = 1.6728e-01, time/batch = 0.6992s	
16331/28500 (epoch 28.651), train_loss = 0.80820537, grad/param norm = 1.4093e-01, time/batch = 0.7032s	
16332/28500 (epoch 28.653), train_loss = 0.80605443, grad/param norm = 1.6924e-01, time/batch = 0.7014s	
16333/28500 (epoch 28.654), train_loss = 0.86164136, grad/param norm = 1.6528e-01, time/batch = 0.6970s	
16334/28500 (epoch 28.656), train_loss = 0.83912029, grad/param norm = 1.7481e-01, time/batch = 0.6973s	
16335/28500 (epoch 28.658), train_loss = 0.90399138, grad/param norm = 1.7385e-01, time/batch = 0.6965s	
16336/28500 (epoch 28.660), train_loss = 0.93947230, grad/param norm = 1.7469e-01, time/batch = 0.6951s	
16337/28500 (epoch 28.661), train_loss = 1.05189943, grad/param norm = 1.9787e-01, time/batch = 0.6965s	
16338/28500 (epoch 28.663), train_loss = 1.03700070, grad/param norm = 1.9128e-01, time/batch = 0.6995s	
16339/28500 (epoch 28.665), train_loss = 0.90469546, grad/param norm = 1.6172e-01, time/batch = 0.6980s	
16340/28500 (epoch 28.667), train_loss = 0.89775755, grad/param norm = 1.7893e-01, time/batch = 0.6979s	
16341/28500 (epoch 28.668), train_loss = 0.91930957, grad/param norm = 1.7805e-01, time/batch = 0.7030s	
16342/28500 (epoch 28.670), train_loss = 0.92412073, grad/param norm = 1.6804e-01, time/batch = 0.7021s	
16343/28500 (epoch 28.672), train_loss = 0.84667179, grad/param norm = 1.7585e-01, time/batch = 0.7057s	
16344/28500 (epoch 28.674), train_loss = 0.75197468, grad/param norm = 1.6442e-01, time/batch = 0.7038s	
16345/28500 (epoch 28.675), train_loss = 0.79428316, grad/param norm = 1.5682e-01, time/batch = 0.7013s	
16346/28500 (epoch 28.677), train_loss = 0.88492938, grad/param norm = 1.5657e-01, time/batch = 0.6989s	
16347/28500 (epoch 28.679), train_loss = 0.87040050, grad/param norm = 1.6622e-01, time/batch = 0.6984s	
16348/28500 (epoch 28.681), train_loss = 0.95445186, grad/param norm = 1.7545e-01, time/batch = 0.7045s	
16349/28500 (epoch 28.682), train_loss = 0.84972855, grad/param norm = 1.5399e-01, time/batch = 0.6968s	
16350/28500 (epoch 28.684), train_loss = 0.92893224, grad/param norm = 1.6789e-01, time/batch = 0.6982s	
16351/28500 (epoch 28.686), train_loss = 0.88811019, grad/param norm = 2.1724e-01, time/batch = 0.6994s	
16352/28500 (epoch 28.688), train_loss = 0.82256918, grad/param norm = 1.3593e-01, time/batch = 0.6975s	
16353/28500 (epoch 28.689), train_loss = 0.85854453, grad/param norm = 1.7886e-01, time/batch = 0.6962s	
16354/28500 (epoch 28.691), train_loss = 0.94016391, grad/param norm = 1.6863e-01, time/batch = 0.6966s	
16355/28500 (epoch 28.693), train_loss = 0.86869474, grad/param norm = 1.6038e-01, time/batch = 0.6963s	
16356/28500 (epoch 28.695), train_loss = 0.69429544, grad/param norm = 1.8236e-01, time/batch = 0.6977s	
16357/28500 (epoch 28.696), train_loss = 0.88961336, grad/param norm = 1.7238e-01, time/batch = 0.6969s	
16358/28500 (epoch 28.698), train_loss = 0.91469410, grad/param norm = 1.5501e-01, time/batch = 0.6984s	
16359/28500 (epoch 28.700), train_loss = 0.92938556, grad/param norm = 1.6548e-01, time/batch = 0.6974s	
16360/28500 (epoch 28.702), train_loss = 0.93792098, grad/param norm = 1.8671e-01, time/batch = 0.6950s	
16361/28500 (epoch 28.704), train_loss = 0.94070472, grad/param norm = 1.7225e-01, time/batch = 0.7015s	
16362/28500 (epoch 28.705), train_loss = 1.01897669, grad/param norm = 1.9307e-01, time/batch = 0.6997s	
16363/28500 (epoch 28.707), train_loss = 0.84439429, grad/param norm = 1.7033e-01, time/batch = 0.6970s	
16364/28500 (epoch 28.709), train_loss = 1.04444779, grad/param norm = 1.8000e-01, time/batch = 0.6973s	
16365/28500 (epoch 28.711), train_loss = 0.84731852, grad/param norm = 1.5945e-01, time/batch = 0.6956s	
16366/28500 (epoch 28.712), train_loss = 0.91545613, grad/param norm = 1.5683e-01, time/batch = 0.6971s	
16367/28500 (epoch 28.714), train_loss = 1.04113952, grad/param norm = 1.9319e-01, time/batch = 0.6967s	
16368/28500 (epoch 28.716), train_loss = 0.89545621, grad/param norm = 1.6214e-01, time/batch = 0.6974s	
16369/28500 (epoch 28.718), train_loss = 0.94145539, grad/param norm = 1.8354e-01, time/batch = 0.6972s	
16370/28500 (epoch 28.719), train_loss = 0.91963062, grad/param norm = 1.6189e-01, time/batch = 0.6961s	
16371/28500 (epoch 28.721), train_loss = 0.74019235, grad/param norm = 1.6802e-01, time/batch = 0.6999s	
16372/28500 (epoch 28.723), train_loss = 0.92709630, grad/param norm = 1.7229e-01, time/batch = 0.6980s	
16373/28500 (epoch 28.725), train_loss = 0.98476067, grad/param norm = 1.6822e-01, time/batch = 0.6986s	
16374/28500 (epoch 28.726), train_loss = 0.91168533, grad/param norm = 1.7883e-01, time/batch = 0.6972s	
16375/28500 (epoch 28.728), train_loss = 0.83627987, grad/param norm = 1.6401e-01, time/batch = 0.6965s	
16376/28500 (epoch 28.730), train_loss = 0.92416115, grad/param norm = 2.0923e-01, time/batch = 0.6982s	
16377/28500 (epoch 28.732), train_loss = 0.73477049, grad/param norm = 1.4616e-01, time/batch = 0.6975s	
16378/28500 (epoch 28.733), train_loss = 0.76191101, grad/param norm = 1.4219e-01, time/batch = 0.6966s	
16379/28500 (epoch 28.735), train_loss = 0.78592783, grad/param norm = 1.5174e-01, time/batch = 0.6972s	
16380/28500 (epoch 28.737), train_loss = 0.71392426, grad/param norm = 1.4275e-01, time/batch = 0.6961s	
16381/28500 (epoch 28.739), train_loss = 0.83752711, grad/param norm = 1.7952e-01, time/batch = 0.7007s	
16382/28500 (epoch 28.740), train_loss = 0.91617800, grad/param norm = 1.6097e-01, time/batch = 0.6985s	
16383/28500 (epoch 28.742), train_loss = 0.83206265, grad/param norm = 1.6455e-01, time/batch = 0.6976s	
16384/28500 (epoch 28.744), train_loss = 0.91741970, grad/param norm = 1.7758e-01, time/batch = 0.6975s	
16385/28500 (epoch 28.746), train_loss = 0.85966421, grad/param norm = 1.5763e-01, time/batch = 0.7002s	
16386/28500 (epoch 28.747), train_loss = 0.83451870, grad/param norm = 1.5507e-01, time/batch = 0.6989s	
16387/28500 (epoch 28.749), train_loss = 0.96720688, grad/param norm = 1.9296e-01, time/batch = 0.7062s	
16388/28500 (epoch 28.751), train_loss = 0.80940620, grad/param norm = 2.3738e-01, time/batch = 0.6991s	
16389/28500 (epoch 28.753), train_loss = 0.88708776, grad/param norm = 1.6787e-01, time/batch = 0.6973s	
16390/28500 (epoch 28.754), train_loss = 0.82028508, grad/param norm = 1.7603e-01, time/batch = 0.6973s	
16391/28500 (epoch 28.756), train_loss = 1.01309801, grad/param norm = 1.7654e-01, time/batch = 0.7006s	
16392/28500 (epoch 28.758), train_loss = 0.96944516, grad/param norm = 1.8432e-01, time/batch = 0.6981s	
16393/28500 (epoch 28.760), train_loss = 0.80817987, grad/param norm = 1.8798e-01, time/batch = 0.6968s	
16394/28500 (epoch 28.761), train_loss = 0.85681850, grad/param norm = 2.1589e-01, time/batch = 0.6969s	
16395/28500 (epoch 28.763), train_loss = 0.72307985, grad/param norm = 1.4203e-01, time/batch = 0.6975s	
16396/28500 (epoch 28.765), train_loss = 0.88295474, grad/param norm = 1.5743e-01, time/batch = 0.7006s	
16397/28500 (epoch 28.767), train_loss = 0.75507146, grad/param norm = 1.4192e-01, time/batch = 0.6990s	
16398/28500 (epoch 28.768), train_loss = 0.96271053, grad/param norm = 1.7461e-01, time/batch = 0.7018s	
16399/28500 (epoch 28.770), train_loss = 0.82069405, grad/param norm = 1.9367e-01, time/batch = 0.7068s	
16400/28500 (epoch 28.772), train_loss = 0.72652469, grad/param norm = 1.4136e-01, time/batch = 0.7063s	
16401/28500 (epoch 28.774), train_loss = 0.91047879, grad/param norm = 1.8158e-01, time/batch = 0.6980s	
16402/28500 (epoch 28.775), train_loss = 0.98386678, grad/param norm = 1.6003e-01, time/batch = 0.6978s	
16403/28500 (epoch 28.777), train_loss = 0.98481908, grad/param norm = 1.5345e-01, time/batch = 0.7107s	
16404/28500 (epoch 28.779), train_loss = 0.74234205, grad/param norm = 1.4508e-01, time/batch = 0.6954s	
16405/28500 (epoch 28.781), train_loss = 0.88392401, grad/param norm = 1.8328e-01, time/batch = 0.6954s	
16406/28500 (epoch 28.782), train_loss = 0.93825338, grad/param norm = 2.1625e-01, time/batch = 0.7026s	
16407/28500 (epoch 28.784), train_loss = 0.73938649, grad/param norm = 1.5034e-01, time/batch = 0.7043s	
16408/28500 (epoch 28.786), train_loss = 0.78495954, grad/param norm = 1.4941e-01, time/batch = 0.6999s	
16409/28500 (epoch 28.788), train_loss = 0.88021922, grad/param norm = 1.9481e-01, time/batch = 0.6892s	
16410/28500 (epoch 28.789), train_loss = 0.68549102, grad/param norm = 1.8085e-01, time/batch = 0.6905s	
16411/28500 (epoch 28.791), train_loss = 0.93103568, grad/param norm = 1.7388e-01, time/batch = 0.6952s	
16412/28500 (epoch 28.793), train_loss = 0.90691954, grad/param norm = 1.8452e-01, time/batch = 0.7143s	
16413/28500 (epoch 28.795), train_loss = 0.92549291, grad/param norm = 1.6447e-01, time/batch = 0.6990s	
16414/28500 (epoch 28.796), train_loss = 0.80315358, grad/param norm = 1.5750e-01, time/batch = 0.6995s	
16415/28500 (epoch 28.798), train_loss = 0.73751223, grad/param norm = 1.5696e-01, time/batch = 0.6928s	
16416/28500 (epoch 28.800), train_loss = 0.77729290, grad/param norm = 2.0365e-01, time/batch = 0.6918s	
16417/28500 (epoch 28.802), train_loss = 0.86479168, grad/param norm = 2.1981e-01, time/batch = 0.6901s	
16418/28500 (epoch 28.804), train_loss = 0.89975441, grad/param norm = 1.5174e-01, time/batch = 0.6894s	
16419/28500 (epoch 28.805), train_loss = 0.90099929, grad/param norm = 1.9416e-01, time/batch = 0.6903s	
16420/28500 (epoch 28.807), train_loss = 0.93025340, grad/param norm = 1.8806e-01, time/batch = 0.6913s	
16421/28500 (epoch 28.809), train_loss = 0.91590420, grad/param norm = 1.9267e-01, time/batch = 0.6952s	
16422/28500 (epoch 28.811), train_loss = 0.92684218, grad/param norm = 1.6884e-01, time/batch = 0.6937s	
16423/28500 (epoch 28.812), train_loss = 0.90414433, grad/param norm = 1.8255e-01, time/batch = 0.6923s	
16424/28500 (epoch 28.814), train_loss = 0.85347228, grad/param norm = 1.6943e-01, time/batch = 0.6887s	
16425/28500 (epoch 28.816), train_loss = 0.94327533, grad/param norm = 1.9465e-01, time/batch = 0.7095s	
16426/28500 (epoch 28.818), train_loss = 1.02606345, grad/param norm = 1.8243e-01, time/batch = 0.6973s	
16427/28500 (epoch 28.819), train_loss = 0.90729001, grad/param norm = 1.7084e-01, time/batch = 0.7091s	
16428/28500 (epoch 28.821), train_loss = 0.86302794, grad/param norm = 1.6664e-01, time/batch = 0.6920s	
16429/28500 (epoch 28.823), train_loss = 1.02554448, grad/param norm = 2.0386e-01, time/batch = 0.6884s	
16430/28500 (epoch 28.825), train_loss = 0.86326147, grad/param norm = 1.8171e-01, time/batch = 0.6908s	
16431/28500 (epoch 28.826), train_loss = 0.92772359, grad/param norm = 1.9079e-01, time/batch = 0.6909s	
16432/28500 (epoch 28.828), train_loss = 0.80886565, grad/param norm = 1.9671e-01, time/batch = 0.6952s	
16433/28500 (epoch 28.830), train_loss = 0.87122802, grad/param norm = 1.5810e-01, time/batch = 0.6885s	
16434/28500 (epoch 28.832), train_loss = 0.90826951, grad/param norm = 2.0361e-01, time/batch = 0.6891s	
16435/28500 (epoch 28.833), train_loss = 0.97602143, grad/param norm = 1.7310e-01, time/batch = 0.6879s	
16436/28500 (epoch 28.835), train_loss = 0.84683943, grad/param norm = 1.6299e-01, time/batch = 0.6889s	
16437/28500 (epoch 28.837), train_loss = 0.77034992, grad/param norm = 1.6200e-01, time/batch = 0.6911s	
16438/28500 (epoch 28.839), train_loss = 1.02880662, grad/param norm = 1.9711e-01, time/batch = 0.6895s	
16439/28500 (epoch 28.840), train_loss = 1.05341146, grad/param norm = 1.9388e-01, time/batch = 0.6907s	
16440/28500 (epoch 28.842), train_loss = 0.95527629, grad/param norm = 1.9772e-01, time/batch = 0.6909s	
16441/28500 (epoch 28.844), train_loss = 0.94936241, grad/param norm = 1.9261e-01, time/batch = 0.6911s	
16442/28500 (epoch 28.846), train_loss = 1.03961772, grad/param norm = 2.1929e-01, time/batch = 0.6889s	
16443/28500 (epoch 28.847), train_loss = 0.87680200, grad/param norm = 1.7653e-01, time/batch = 0.6887s	
16444/28500 (epoch 28.849), train_loss = 0.88570586, grad/param norm = 1.7958e-01, time/batch = 0.6896s	
16445/28500 (epoch 28.851), train_loss = 0.78444214, grad/param norm = 1.6280e-01, time/batch = 0.6902s	
16446/28500 (epoch 28.853), train_loss = 0.90560280, grad/param norm = 2.0104e-01, time/batch = 0.6907s	
16447/28500 (epoch 28.854), train_loss = 0.91371463, grad/param norm = 1.7512e-01, time/batch = 0.6905s	
16448/28500 (epoch 28.856), train_loss = 1.01613048, grad/param norm = 1.8720e-01, time/batch = 0.6907s	
16449/28500 (epoch 28.858), train_loss = 0.83381017, grad/param norm = 1.6318e-01, time/batch = 0.6916s	
16450/28500 (epoch 28.860), train_loss = 0.85594248, grad/param norm = 1.6166e-01, time/batch = 0.6902s	
16451/28500 (epoch 28.861), train_loss = 0.96032986, grad/param norm = 1.8912e-01, time/batch = 0.6943s	
16452/28500 (epoch 28.863), train_loss = 0.94946472, grad/param norm = 1.9649e-01, time/batch = 0.6944s	
16453/28500 (epoch 28.865), train_loss = 0.85997021, grad/param norm = 1.8791e-01, time/batch = 0.6914s	
16454/28500 (epoch 28.867), train_loss = 0.96167700, grad/param norm = 2.0286e-01, time/batch = 0.6907s	
16455/28500 (epoch 28.868), train_loss = 0.81277523, grad/param norm = 1.6461e-01, time/batch = 0.6933s	
16456/28500 (epoch 28.870), train_loss = 0.78589984, grad/param norm = 1.6812e-01, time/batch = 0.6919s	
16457/28500 (epoch 28.872), train_loss = 0.96243683, grad/param norm = 2.1944e-01, time/batch = 0.6890s	
16458/28500 (epoch 28.874), train_loss = 0.84225299, grad/param norm = 2.0927e-01, time/batch = 0.6897s	
16459/28500 (epoch 28.875), train_loss = 1.02805633, grad/param norm = 1.9538e-01, time/batch = 0.6889s	
16460/28500 (epoch 28.877), train_loss = 0.92134931, grad/param norm = 1.7023e-01, time/batch = 0.6963s	
16461/28500 (epoch 28.879), train_loss = 0.95693164, grad/param norm = 1.5971e-01, time/batch = 0.6930s	
16462/28500 (epoch 28.881), train_loss = 0.92046151, grad/param norm = 1.7889e-01, time/batch = 0.6887s	
16463/28500 (epoch 28.882), train_loss = 0.81706759, grad/param norm = 1.4872e-01, time/batch = 0.6887s	
16464/28500 (epoch 28.884), train_loss = 0.90846124, grad/param norm = 1.7069e-01, time/batch = 0.6889s	
16465/28500 (epoch 28.886), train_loss = 0.86788152, grad/param norm = 1.6164e-01, time/batch = 0.6886s	
16466/28500 (epoch 28.888), train_loss = 0.83391068, grad/param norm = 1.5804e-01, time/batch = 0.6919s	
16467/28500 (epoch 28.889), train_loss = 0.88939121, grad/param norm = 1.4955e-01, time/batch = 0.6920s	
16468/28500 (epoch 28.891), train_loss = 0.88878239, grad/param norm = 1.6720e-01, time/batch = 0.6894s	
16469/28500 (epoch 28.893), train_loss = 0.86708564, grad/param norm = 1.7311e-01, time/batch = 0.6895s	
16470/28500 (epoch 28.895), train_loss = 1.04609429, grad/param norm = 1.9730e-01, time/batch = 0.6985s	
16471/28500 (epoch 28.896), train_loss = 0.99204168, grad/param norm = 1.8718e-01, time/batch = 0.6921s	
16472/28500 (epoch 28.898), train_loss = 0.91207374, grad/param norm = 1.7375e-01, time/batch = 0.6903s	
16473/28500 (epoch 28.900), train_loss = 0.78229249, grad/param norm = 1.8913e-01, time/batch = 0.6908s	
16474/28500 (epoch 28.902), train_loss = 0.77877648, grad/param norm = 1.7353e-01, time/batch = 0.6895s	
16475/28500 (epoch 28.904), train_loss = 0.80289184, grad/param norm = 1.5241e-01, time/batch = 0.6887s	
16476/28500 (epoch 28.905), train_loss = 0.87341831, grad/param norm = 1.7365e-01, time/batch = 0.6901s	
16477/28500 (epoch 28.907), train_loss = 0.88079509, grad/param norm = 1.8408e-01, time/batch = 0.6903s	
16478/28500 (epoch 28.909), train_loss = 0.82176160, grad/param norm = 2.3276e-01, time/batch = 0.6904s	
16479/28500 (epoch 28.911), train_loss = 0.80312990, grad/param norm = 1.6178e-01, time/batch = 0.6907s	
16480/28500 (epoch 28.912), train_loss = 0.71218037, grad/param norm = 1.6795e-01, time/batch = 0.6887s	
16481/28500 (epoch 28.914), train_loss = 0.91328054, grad/param norm = 1.7442e-01, time/batch = 0.6936s	
16482/28500 (epoch 28.916), train_loss = 0.90150901, grad/param norm = 1.7791e-01, time/batch = 0.6941s	
16483/28500 (epoch 28.918), train_loss = 0.88294133, grad/param norm = 1.6839e-01, time/batch = 0.6930s	
16484/28500 (epoch 28.919), train_loss = 0.88725043, grad/param norm = 1.6034e-01, time/batch = 0.6944s	
16485/28500 (epoch 28.921), train_loss = 0.99865921, grad/param norm = 2.2170e-01, time/batch = 0.6954s	
16486/28500 (epoch 28.923), train_loss = 0.86765193, grad/param norm = 2.2106e-01, time/batch = 0.6950s	
16487/28500 (epoch 28.925), train_loss = 0.83427631, grad/param norm = 1.8241e-01, time/batch = 0.7007s	
16488/28500 (epoch 28.926), train_loss = 0.90447709, grad/param norm = 1.6895e-01, time/batch = 0.6991s	
16489/28500 (epoch 28.928), train_loss = 0.84834292, grad/param norm = 1.5675e-01, time/batch = 0.6987s	
16490/28500 (epoch 28.930), train_loss = 0.70295409, grad/param norm = 1.4237e-01, time/batch = 0.6964s	
16491/28500 (epoch 28.932), train_loss = 0.71262240, grad/param norm = 1.2956e-01, time/batch = 0.6970s	
16492/28500 (epoch 28.933), train_loss = 0.95056531, grad/param norm = 1.7132e-01, time/batch = 0.6968s	
16493/28500 (epoch 28.935), train_loss = 0.97217795, grad/param norm = 1.6425e-01, time/batch = 0.6974s	
16494/28500 (epoch 28.937), train_loss = 1.01018359, grad/param norm = 2.5511e-01, time/batch = 0.6951s	
16495/28500 (epoch 28.939), train_loss = 1.06093326, grad/param norm = 2.1136e-01, time/batch = 0.6951s	
16496/28500 (epoch 28.940), train_loss = 0.77764604, grad/param norm = 1.6960e-01, time/batch = 0.6936s	
16497/28500 (epoch 28.942), train_loss = 0.91305672, grad/param norm = 1.7799e-01, time/batch = 0.6942s	
16498/28500 (epoch 28.944), train_loss = 0.83709816, grad/param norm = 1.6595e-01, time/batch = 0.6942s	
16499/28500 (epoch 28.946), train_loss = 0.97131597, grad/param norm = 1.6739e-01, time/batch = 0.6931s	
16500/28500 (epoch 28.947), train_loss = 1.17191653, grad/param norm = 2.3048e-01, time/batch = 0.6933s	
16501/28500 (epoch 28.949), train_loss = 0.86636909, grad/param norm = 1.9596e-01, time/batch = 0.6958s	
16502/28500 (epoch 28.951), train_loss = 1.07123078, grad/param norm = 2.1612e-01, time/batch = 0.6944s	
16503/28500 (epoch 28.953), train_loss = 1.03864361, grad/param norm = 1.8737e-01, time/batch = 0.6971s	
16504/28500 (epoch 28.954), train_loss = 1.00262066, grad/param norm = 2.1769e-01, time/batch = 0.6977s	
16505/28500 (epoch 28.956), train_loss = 0.92111787, grad/param norm = 3.0236e-01, time/batch = 0.6999s	
16506/28500 (epoch 28.958), train_loss = 1.11461374, grad/param norm = 1.8919e-01, time/batch = 0.6945s	
16507/28500 (epoch 28.960), train_loss = 0.86422632, grad/param norm = 2.0731e-01, time/batch = 0.6924s	
16508/28500 (epoch 28.961), train_loss = 1.06279463, grad/param norm = 1.9779e-01, time/batch = 0.6947s	
16509/28500 (epoch 28.963), train_loss = 1.01858384, grad/param norm = 1.8977e-01, time/batch = 0.6923s	
16510/28500 (epoch 28.965), train_loss = 0.82741180, grad/param norm = 1.6551e-01, time/batch = 0.6988s	
16511/28500 (epoch 28.967), train_loss = 0.83594778, grad/param norm = 1.6454e-01, time/batch = 0.6999s	
16512/28500 (epoch 28.968), train_loss = 0.77982165, grad/param norm = 1.4507e-01, time/batch = 0.6975s	
16513/28500 (epoch 28.970), train_loss = 0.83652793, grad/param norm = 1.9863e-01, time/batch = 0.6957s	
16514/28500 (epoch 28.972), train_loss = 0.91523484, grad/param norm = 1.8190e-01, time/batch = 0.6936s	
16515/28500 (epoch 28.974), train_loss = 1.07145049, grad/param norm = 1.9087e-01, time/batch = 0.6943s	
16516/28500 (epoch 28.975), train_loss = 0.83997431, grad/param norm = 1.8535e-01, time/batch = 0.6938s	
16517/28500 (epoch 28.977), train_loss = 0.99236185, grad/param norm = 1.8266e-01, time/batch = 0.7016s	
16518/28500 (epoch 28.979), train_loss = 0.91282215, grad/param norm = 1.9212e-01, time/batch = 0.6941s	
16519/28500 (epoch 28.981), train_loss = 0.81186196, grad/param norm = 1.7201e-01, time/batch = 0.6931s	
16520/28500 (epoch 28.982), train_loss = 0.86854767, grad/param norm = 1.7009e-01, time/batch = 0.6927s	
16521/28500 (epoch 28.984), train_loss = 0.96996930, grad/param norm = 1.6113e-01, time/batch = 0.6954s	
16522/28500 (epoch 28.986), train_loss = 1.17586553, grad/param norm = 2.0542e-01, time/batch = 0.6939s	
16523/28500 (epoch 28.988), train_loss = 0.80545952, grad/param norm = 1.5945e-01, time/batch = 0.6927s	
16524/28500 (epoch 28.989), train_loss = 0.93604889, grad/param norm = 1.8643e-01, time/batch = 0.6927s	
16525/28500 (epoch 28.991), train_loss = 0.82031024, grad/param norm = 1.6591e-01, time/batch = 0.6936s	
16526/28500 (epoch 28.993), train_loss = 0.85312520, grad/param norm = 1.8225e-01, time/batch = 0.6925s	
16527/28500 (epoch 28.995), train_loss = 0.84134197, grad/param norm = 1.7224e-01, time/batch = 0.6933s	
16528/28500 (epoch 28.996), train_loss = 0.81400275, grad/param norm = 1.6758e-01, time/batch = 0.6958s	
16529/28500 (epoch 28.998), train_loss = 1.00990500, grad/param norm = 1.9289e-01, time/batch = 0.6929s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
16530/28500 (epoch 29.000), train_loss = 0.88976195, grad/param norm = 1.6569e-01, time/batch = 0.6941s	
16531/28500 (epoch 29.002), train_loss = 1.07385441, grad/param norm = 1.8389e-01, time/batch = 0.6948s	
16532/28500 (epoch 29.004), train_loss = 0.87419350, grad/param norm = 1.5902e-01, time/batch = 0.6901s	
16533/28500 (epoch 29.005), train_loss = 1.03113240, grad/param norm = 2.1172e-01, time/batch = 0.6886s	
16534/28500 (epoch 29.007), train_loss = 0.80882187, grad/param norm = 1.4856e-01, time/batch = 0.6905s	
16535/28500 (epoch 29.009), train_loss = 0.92925964, grad/param norm = 1.7833e-01, time/batch = 0.6898s	
16536/28500 (epoch 29.011), train_loss = 0.84904487, grad/param norm = 1.8606e-01, time/batch = 0.6892s	
16537/28500 (epoch 29.012), train_loss = 0.80462972, grad/param norm = 1.6802e-01, time/batch = 0.6913s	
16538/28500 (epoch 29.014), train_loss = 0.82607410, grad/param norm = 1.7347e-01, time/batch = 0.6899s	
16539/28500 (epoch 29.016), train_loss = 0.86076249, grad/param norm = 1.7464e-01, time/batch = 0.6882s	
16540/28500 (epoch 29.018), train_loss = 0.93979008, grad/param norm = 2.1270e-01, time/batch = 0.6880s	
16541/28500 (epoch 29.019), train_loss = 1.00639949, grad/param norm = 1.8298e-01, time/batch = 0.6908s	
16542/28500 (epoch 29.021), train_loss = 0.98858434, grad/param norm = 1.5995e-01, time/batch = 0.6895s	
16543/28500 (epoch 29.023), train_loss = 0.92751259, grad/param norm = 1.8414e-01, time/batch = 0.6916s	
16544/28500 (epoch 29.025), train_loss = 0.94540382, grad/param norm = 1.8301e-01, time/batch = 0.6909s	
16545/28500 (epoch 29.026), train_loss = 0.89539431, grad/param norm = 1.6409e-01, time/batch = 0.6899s	
16546/28500 (epoch 29.028), train_loss = 0.92172063, grad/param norm = 1.7519e-01, time/batch = 0.6891s	
16547/28500 (epoch 29.030), train_loss = 0.98582978, grad/param norm = 2.0423e-01, time/batch = 0.6886s	
16548/28500 (epoch 29.032), train_loss = 1.00080949, grad/param norm = 1.8765e-01, time/batch = 0.6888s	
16549/28500 (epoch 29.033), train_loss = 1.05599369, grad/param norm = 1.7329e-01, time/batch = 0.6901s	
16550/28500 (epoch 29.035), train_loss = 0.88704393, grad/param norm = 1.7127e-01, time/batch = 0.6954s	
16551/28500 (epoch 29.037), train_loss = 0.95850439, grad/param norm = 1.5819e-01, time/batch = 0.6917s	
16552/28500 (epoch 29.039), train_loss = 1.00677851, grad/param norm = 1.8288e-01, time/batch = 0.6898s	
16553/28500 (epoch 29.040), train_loss = 1.02708382, grad/param norm = 1.7630e-01, time/batch = 0.6892s	
16554/28500 (epoch 29.042), train_loss = 0.97396172, grad/param norm = 1.8008e-01, time/batch = 0.6890s	
16555/28500 (epoch 29.044), train_loss = 0.92820756, grad/param norm = 1.8770e-01, time/batch = 0.6895s	
16556/28500 (epoch 29.046), train_loss = 1.12634563, grad/param norm = 1.9204e-01, time/batch = 0.6897s	
16557/28500 (epoch 29.047), train_loss = 1.05770426, grad/param norm = 2.0024e-01, time/batch = 0.6891s	
16558/28500 (epoch 29.049), train_loss = 0.95021203, grad/param norm = 1.8610e-01, time/batch = 0.6893s	
16559/28500 (epoch 29.051), train_loss = 0.91484532, grad/param norm = 1.7988e-01, time/batch = 0.6892s	
16560/28500 (epoch 29.053), train_loss = 0.92088905, grad/param norm = 1.9572e-01, time/batch = 0.6890s	
16561/28500 (epoch 29.054), train_loss = 1.01042023, grad/param norm = 1.8582e-01, time/batch = 0.6917s	
16562/28500 (epoch 29.056), train_loss = 0.85263828, grad/param norm = 1.6046e-01, time/batch = 0.6901s	
16563/28500 (epoch 29.058), train_loss = 0.83933308, grad/param norm = 1.5400e-01, time/batch = 0.6896s	
16564/28500 (epoch 29.060), train_loss = 0.97127233, grad/param norm = 1.7760e-01, time/batch = 0.6901s	
16565/28500 (epoch 29.061), train_loss = 0.91649068, grad/param norm = 1.8344e-01, time/batch = 0.6892s	
16566/28500 (epoch 29.063), train_loss = 0.99935013, grad/param norm = 1.9472e-01, time/batch = 0.6901s	
16567/28500 (epoch 29.065), train_loss = 0.96931715, grad/param norm = 1.9723e-01, time/batch = 0.6914s	
16568/28500 (epoch 29.067), train_loss = 0.87950698, grad/param norm = 1.6382e-01, time/batch = 0.6896s	
16569/28500 (epoch 29.068), train_loss = 0.90087552, grad/param norm = 1.5624e-01, time/batch = 0.6894s	
16570/28500 (epoch 29.070), train_loss = 0.97130410, grad/param norm = 1.9301e-01, time/batch = 0.6899s	
16571/28500 (epoch 29.072), train_loss = 1.06169145, grad/param norm = 1.8866e-01, time/batch = 0.6913s	
16572/28500 (epoch 29.074), train_loss = 0.92763721, grad/param norm = 1.7265e-01, time/batch = 0.6902s	
16573/28500 (epoch 29.075), train_loss = 0.88965483, grad/param norm = 1.5632e-01, time/batch = 0.6918s	
16574/28500 (epoch 29.077), train_loss = 0.98341561, grad/param norm = 1.6163e-01, time/batch = 0.6932s	
16575/28500 (epoch 29.079), train_loss = 0.93891381, grad/param norm = 1.6843e-01, time/batch = 0.7165s	
16576/28500 (epoch 29.081), train_loss = 1.06006956, grad/param norm = 2.0476e-01, time/batch = 0.7094s	
16577/28500 (epoch 29.082), train_loss = 0.95423701, grad/param norm = 1.9700e-01, time/batch = 0.6931s	
16578/28500 (epoch 29.084), train_loss = 0.95779027, grad/param norm = 1.8275e-01, time/batch = 0.6984s	
16579/28500 (epoch 29.086), train_loss = 0.89404054, grad/param norm = 1.8582e-01, time/batch = 0.7008s	
16580/28500 (epoch 29.088), train_loss = 0.82160620, grad/param norm = 1.6231e-01, time/batch = 0.7004s	
16581/28500 (epoch 29.089), train_loss = 1.01077634, grad/param norm = 1.6743e-01, time/batch = 0.6971s	
16582/28500 (epoch 29.091), train_loss = 0.80124342, grad/param norm = 1.5776e-01, time/batch = 0.6969s	
16583/28500 (epoch 29.093), train_loss = 0.99706862, grad/param norm = 1.6148e-01, time/batch = 0.6955s	
16584/28500 (epoch 29.095), train_loss = 0.89792952, grad/param norm = 1.5324e-01, time/batch = 0.6969s	
16585/28500 (epoch 29.096), train_loss = 1.02744642, grad/param norm = 1.9667e-01, time/batch = 0.6930s	
16586/28500 (epoch 29.098), train_loss = 0.94756190, grad/param norm = 1.8024e-01, time/batch = 0.6941s	
16587/28500 (epoch 29.100), train_loss = 0.88392042, grad/param norm = 1.7448e-01, time/batch = 0.6936s	
16588/28500 (epoch 29.102), train_loss = 1.00150223, grad/param norm = 1.9486e-01, time/batch = 0.6991s	
16589/28500 (epoch 29.104), train_loss = 0.93642404, grad/param norm = 1.9775e-01, time/batch = 0.6968s	
16590/28500 (epoch 29.105), train_loss = 1.04911197, grad/param norm = 1.7496e-01, time/batch = 0.6942s	
16591/28500 (epoch 29.107), train_loss = 0.84208568, grad/param norm = 1.5828e-01, time/batch = 0.6915s	
16592/28500 (epoch 29.109), train_loss = 0.86638514, grad/param norm = 2.1644e-01, time/batch = 0.6962s	
16593/28500 (epoch 29.111), train_loss = 0.90049991, grad/param norm = 1.7681e-01, time/batch = 0.6946s	
16594/28500 (epoch 29.112), train_loss = 0.98537636, grad/param norm = 1.7649e-01, time/batch = 0.6921s	
16595/28500 (epoch 29.114), train_loss = 0.89962139, grad/param norm = 1.6800e-01, time/batch = 0.7345s	
16596/28500 (epoch 29.116), train_loss = 1.06796022, grad/param norm = 1.8381e-01, time/batch = 1.0139s	
16597/28500 (epoch 29.118), train_loss = 0.83763685, grad/param norm = 1.9226e-01, time/batch = 0.9852s	
16598/28500 (epoch 29.119), train_loss = 0.94681236, grad/param norm = 1.6019e-01, time/batch = 0.9950s	
16599/28500 (epoch 29.121), train_loss = 1.12414343, grad/param norm = 2.3923e-01, time/batch = 0.9940s	
16600/28500 (epoch 29.123), train_loss = 1.03436776, grad/param norm = 2.0867e-01, time/batch = 0.9899s	
16601/28500 (epoch 29.125), train_loss = 0.95011530, grad/param norm = 1.8548e-01, time/batch = 1.0023s	
16602/28500 (epoch 29.126), train_loss = 0.92454581, grad/param norm = 1.6989e-01, time/batch = 0.7940s	
16603/28500 (epoch 29.128), train_loss = 0.93771069, grad/param norm = 1.9227e-01, time/batch = 0.6931s	
16604/28500 (epoch 29.130), train_loss = 0.84987897, grad/param norm = 1.9345e-01, time/batch = 0.6883s	
16605/28500 (epoch 29.132), train_loss = 0.93086434, grad/param norm = 2.0860e-01, time/batch = 0.6927s	
16606/28500 (epoch 29.133), train_loss = 0.99548191, grad/param norm = 2.5884e-01, time/batch = 0.6925s	
16607/28500 (epoch 29.135), train_loss = 0.90767305, grad/param norm = 1.8617e-01, time/batch = 0.6854s	
16608/28500 (epoch 29.137), train_loss = 0.94776359, grad/param norm = 1.6513e-01, time/batch = 0.6820s	
16609/28500 (epoch 29.139), train_loss = 0.92664010, grad/param norm = 1.7400e-01, time/batch = 0.6800s	
16610/28500 (epoch 29.140), train_loss = 0.94151850, grad/param norm = 1.7702e-01, time/batch = 0.7021s	
16611/28500 (epoch 29.142), train_loss = 0.89958751, grad/param norm = 1.9948e-01, time/batch = 0.7099s	
16612/28500 (epoch 29.144), train_loss = 0.85047773, grad/param norm = 1.7282e-01, time/batch = 0.6946s	
16613/28500 (epoch 29.146), train_loss = 0.90392935, grad/param norm = 1.6219e-01, time/batch = 0.6936s	
16614/28500 (epoch 29.147), train_loss = 0.80461734, grad/param norm = 1.5848e-01, time/batch = 0.6936s	
16615/28500 (epoch 29.149), train_loss = 0.79448749, grad/param norm = 1.5424e-01, time/batch = 0.6946s	
16616/28500 (epoch 29.151), train_loss = 0.88628633, grad/param norm = 1.6483e-01, time/batch = 0.6940s	
16617/28500 (epoch 29.153), train_loss = 0.97698957, grad/param norm = 1.9881e-01, time/batch = 0.6924s	
16618/28500 (epoch 29.154), train_loss = 0.82386492, grad/param norm = 1.6103e-01, time/batch = 0.7118s	
16619/28500 (epoch 29.156), train_loss = 1.01252160, grad/param norm = 1.8280e-01, time/batch = 0.6976s	
16620/28500 (epoch 29.158), train_loss = 0.92797595, grad/param norm = 1.5856e-01, time/batch = 0.6941s	
16621/28500 (epoch 29.160), train_loss = 0.83841629, grad/param norm = 1.5810e-01, time/batch = 0.6960s	
16622/28500 (epoch 29.161), train_loss = 0.86596828, grad/param norm = 1.7324e-01, time/batch = 0.6967s	
16623/28500 (epoch 29.163), train_loss = 0.79766267, grad/param norm = 1.8682e-01, time/batch = 0.6938s	
16624/28500 (epoch 29.165), train_loss = 1.11287479, grad/param norm = 1.7733e-01, time/batch = 0.6965s	
16625/28500 (epoch 29.167), train_loss = 1.09770361, grad/param norm = 1.8402e-01, time/batch = 0.7019s	
16626/28500 (epoch 29.168), train_loss = 1.04741143, grad/param norm = 2.1455e-01, time/batch = 0.7076s	
16627/28500 (epoch 29.170), train_loss = 1.02465979, grad/param norm = 2.1772e-01, time/batch = 0.6948s	
16628/28500 (epoch 29.172), train_loss = 0.93688456, grad/param norm = 1.6890e-01, time/batch = 0.6954s	
16629/28500 (epoch 29.174), train_loss = 1.09200803, grad/param norm = 2.0114e-01, time/batch = 0.6959s	
16630/28500 (epoch 29.175), train_loss = 0.91398358, grad/param norm = 1.6395e-01, time/batch = 0.6985s	
16631/28500 (epoch 29.177), train_loss = 0.99089512, grad/param norm = 1.8268e-01, time/batch = 0.7021s	
16632/28500 (epoch 29.179), train_loss = 0.99831111, grad/param norm = 1.9085e-01, time/batch = 0.6978s	
16633/28500 (epoch 29.181), train_loss = 0.98073764, grad/param norm = 1.8695e-01, time/batch = 0.7113s	
16634/28500 (epoch 29.182), train_loss = 0.90018058, grad/param norm = 1.5979e-01, time/batch = 0.7130s	
16635/28500 (epoch 29.184), train_loss = 1.09951671, grad/param norm = 2.2439e-01, time/batch = 0.6928s	
16636/28500 (epoch 29.186), train_loss = 1.05404591, grad/param norm = 1.7294e-01, time/batch = 0.6908s	
16637/28500 (epoch 29.188), train_loss = 0.96934899, grad/param norm = 1.6679e-01, time/batch = 0.6912s	
16638/28500 (epoch 29.189), train_loss = 0.93795471, grad/param norm = 1.5753e-01, time/batch = 0.6915s	
16639/28500 (epoch 29.191), train_loss = 1.13234641, grad/param norm = 1.7305e-01, time/batch = 0.6966s	
16640/28500 (epoch 29.193), train_loss = 0.97181639, grad/param norm = 1.9164e-01, time/batch = 0.6936s	
16641/28500 (epoch 29.195), train_loss = 1.08905928, grad/param norm = 1.9897e-01, time/batch = 0.6979s	
16642/28500 (epoch 29.196), train_loss = 0.99414804, grad/param norm = 1.7592e-01, time/batch = 0.7110s	
16643/28500 (epoch 29.198), train_loss = 0.94536122, grad/param norm = 1.7770e-01, time/batch = 0.6970s	
16644/28500 (epoch 29.200), train_loss = 1.00827824, grad/param norm = 1.8361e-01, time/batch = 0.6939s	
16645/28500 (epoch 29.202), train_loss = 0.95554795, grad/param norm = 1.6139e-01, time/batch = 0.6904s	
16646/28500 (epoch 29.204), train_loss = 0.91924523, grad/param norm = 1.6249e-01, time/batch = 0.6901s	
16647/28500 (epoch 29.205), train_loss = 0.88885816, grad/param norm = 1.6366e-01, time/batch = 0.6911s	
16648/28500 (epoch 29.207), train_loss = 0.83189322, grad/param norm = 1.6516e-01, time/batch = 0.6950s	
16649/28500 (epoch 29.209), train_loss = 0.96468062, grad/param norm = 1.6926e-01, time/batch = 0.7117s	
16650/28500 (epoch 29.211), train_loss = 0.83180950, grad/param norm = 1.6647e-01, time/batch = 0.6998s	
16651/28500 (epoch 29.212), train_loss = 0.80037656, grad/param norm = 1.8341e-01, time/batch = 0.6925s	
16652/28500 (epoch 29.214), train_loss = 0.92206645, grad/param norm = 1.8129e-01, time/batch = 0.6926s	
16653/28500 (epoch 29.216), train_loss = 0.87507999, grad/param norm = 1.8391e-01, time/batch = 0.6916s	
16654/28500 (epoch 29.218), train_loss = 1.02260181, grad/param norm = 1.6733e-01, time/batch = 0.6940s	
16655/28500 (epoch 29.219), train_loss = 0.97714028, grad/param norm = 1.8418e-01, time/batch = 0.6940s	
16656/28500 (epoch 29.221), train_loss = 0.79809489, grad/param norm = 1.6430e-01, time/batch = 0.6996s	
16657/28500 (epoch 29.223), train_loss = 1.04378264, grad/param norm = 2.0231e-01, time/batch = 0.6982s	
16658/28500 (epoch 29.225), train_loss = 1.08460539, grad/param norm = 1.9018e-01, time/batch = 0.7256s	
16659/28500 (epoch 29.226), train_loss = 0.89578362, grad/param norm = 1.5695e-01, time/batch = 0.7008s	
16660/28500 (epoch 29.228), train_loss = 1.01853363, grad/param norm = 1.6499e-01, time/batch = 0.6856s	
16661/28500 (epoch 29.230), train_loss = 1.01671399, grad/param norm = 1.8525e-01, time/batch = 0.6890s	
16662/28500 (epoch 29.232), train_loss = 0.96816545, grad/param norm = 1.6892e-01, time/batch = 0.6837s	
16663/28500 (epoch 29.233), train_loss = 0.94684491, grad/param norm = 1.8951e-01, time/batch = 0.7008s	
16664/28500 (epoch 29.235), train_loss = 0.91674276, grad/param norm = 1.5936e-01, time/batch = 0.6874s	
16665/28500 (epoch 29.237), train_loss = 0.84101514, grad/param norm = 1.5807e-01, time/batch = 0.6977s	
16666/28500 (epoch 29.239), train_loss = 0.87594048, grad/param norm = 1.5317e-01, time/batch = 0.6902s	
16667/28500 (epoch 29.240), train_loss = 0.81806501, grad/param norm = 1.5322e-01, time/batch = 0.6783s	
16668/28500 (epoch 29.242), train_loss = 0.93194866, grad/param norm = 1.8740e-01, time/batch = 0.6900s	
16669/28500 (epoch 29.244), train_loss = 0.97072522, grad/param norm = 1.6095e-01, time/batch = 0.6783s	
16670/28500 (epoch 29.246), train_loss = 0.99288881, grad/param norm = 1.8989e-01, time/batch = 0.6841s	
16671/28500 (epoch 29.247), train_loss = 1.06687870, grad/param norm = 1.9908e-01, time/batch = 0.6813s	
16672/28500 (epoch 29.249), train_loss = 0.92146833, grad/param norm = 1.6264e-01, time/batch = 0.6813s	
16673/28500 (epoch 29.251), train_loss = 0.89484099, grad/param norm = 1.5729e-01, time/batch = 0.6991s	
16674/28500 (epoch 29.253), train_loss = 1.05017766, grad/param norm = 1.9042e-01, time/batch = 0.6837s	
16675/28500 (epoch 29.254), train_loss = 1.07086631, grad/param norm = 1.5975e-01, time/batch = 0.6874s	
16676/28500 (epoch 29.256), train_loss = 0.90763763, grad/param norm = 1.6853e-01, time/batch = 0.6803s	
16677/28500 (epoch 29.258), train_loss = 0.90113799, grad/param norm = 1.7151e-01, time/batch = 0.6802s	
16678/28500 (epoch 29.260), train_loss = 0.91522880, grad/param norm = 1.6318e-01, time/batch = 0.6785s	
16679/28500 (epoch 29.261), train_loss = 0.84911587, grad/param norm = 1.6973e-01, time/batch = 0.6773s	
16680/28500 (epoch 29.263), train_loss = 1.00482810, grad/param norm = 1.9566e-01, time/batch = 0.6848s	
16681/28500 (epoch 29.265), train_loss = 0.91651108, grad/param norm = 1.5985e-01, time/batch = 0.6955s	
16682/28500 (epoch 29.267), train_loss = 1.07161762, grad/param norm = 2.0847e-01, time/batch = 0.6788s	
16683/28500 (epoch 29.268), train_loss = 0.98856861, grad/param norm = 1.5588e-01, time/batch = 0.7000s	
16684/28500 (epoch 29.270), train_loss = 0.96505947, grad/param norm = 1.9569e-01, time/batch = 0.6989s	
16685/28500 (epoch 29.272), train_loss = 0.94358796, grad/param norm = 1.6980e-01, time/batch = 0.6810s	
16686/28500 (epoch 29.274), train_loss = 1.00634420, grad/param norm = 1.8710e-01, time/batch = 0.6837s	
16687/28500 (epoch 29.275), train_loss = 0.98945694, grad/param norm = 1.6833e-01, time/batch = 0.6834s	
16688/28500 (epoch 29.277), train_loss = 0.93513762, grad/param norm = 1.7559e-01, time/batch = 0.6928s	
16689/28500 (epoch 29.279), train_loss = 0.94595962, grad/param norm = 2.0070e-01, time/batch = 0.6979s	
16690/28500 (epoch 29.281), train_loss = 1.00373019, grad/param norm = 1.9482e-01, time/batch = 0.6822s	
16691/28500 (epoch 29.282), train_loss = 0.88544261, grad/param norm = 1.4657e-01, time/batch = 0.6903s	
16692/28500 (epoch 29.284), train_loss = 0.95036093, grad/param norm = 1.8439e-01, time/batch = 0.6861s	
16693/28500 (epoch 29.286), train_loss = 1.06490924, grad/param norm = 1.7408e-01, time/batch = 0.6938s	
16694/28500 (epoch 29.288), train_loss = 0.94984475, grad/param norm = 1.8876e-01, time/batch = 0.6899s	
16695/28500 (epoch 29.289), train_loss = 0.96734705, grad/param norm = 1.9755e-01, time/batch = 0.6875s	
16696/28500 (epoch 29.291), train_loss = 0.95366118, grad/param norm = 1.7884e-01, time/batch = 0.6853s	
16697/28500 (epoch 29.293), train_loss = 0.90815666, grad/param norm = 1.7766e-01, time/batch = 0.6959s	
16698/28500 (epoch 29.295), train_loss = 0.83872038, grad/param norm = 1.7223e-01, time/batch = 0.6831s	
16699/28500 (epoch 29.296), train_loss = 0.81186150, grad/param norm = 1.5742e-01, time/batch = 0.7006s	
16700/28500 (epoch 29.298), train_loss = 0.98256065, grad/param norm = 1.6018e-01, time/batch = 0.6924s	
16701/28500 (epoch 29.300), train_loss = 0.86810616, grad/param norm = 1.7445e-01, time/batch = 0.6804s	
16702/28500 (epoch 29.302), train_loss = 0.83394764, grad/param norm = 1.5322e-01, time/batch = 0.6781s	
16703/28500 (epoch 29.304), train_loss = 0.90080001, grad/param norm = 1.6496e-01, time/batch = 0.6802s	
16704/28500 (epoch 29.305), train_loss = 0.98730451, grad/param norm = 1.7975e-01, time/batch = 0.6789s	
16705/28500 (epoch 29.307), train_loss = 0.93711015, grad/param norm = 1.8182e-01, time/batch = 0.6850s	
16706/28500 (epoch 29.309), train_loss = 0.91623434, grad/param norm = 1.6749e-01, time/batch = 0.6782s	
16707/28500 (epoch 29.311), train_loss = 0.98681241, grad/param norm = 1.8337e-01, time/batch = 0.6815s	
16708/28500 (epoch 29.312), train_loss = 0.95115669, grad/param norm = 1.5995e-01, time/batch = 0.6808s	
16709/28500 (epoch 29.314), train_loss = 0.99849076, grad/param norm = 1.9034e-01, time/batch = 0.6811s	
16710/28500 (epoch 29.316), train_loss = 0.95653546, grad/param norm = 2.0159e-01, time/batch = 0.6852s	
16711/28500 (epoch 29.318), train_loss = 1.02220749, grad/param norm = 1.7022e-01, time/batch = 0.6889s	
16712/28500 (epoch 29.319), train_loss = 0.90620394, grad/param norm = 1.6840e-01, time/batch = 0.6872s	
16713/28500 (epoch 29.321), train_loss = 0.90750042, grad/param norm = 2.0968e-01, time/batch = 0.6828s	
16714/28500 (epoch 29.323), train_loss = 0.89726016, grad/param norm = 1.8917e-01, time/batch = 0.6835s	
16715/28500 (epoch 29.325), train_loss = 1.05177801, grad/param norm = 1.7321e-01, time/batch = 0.6812s	
16716/28500 (epoch 29.326), train_loss = 0.96980136, grad/param norm = 1.6597e-01, time/batch = 0.6803s	
16717/28500 (epoch 29.328), train_loss = 0.76618878, grad/param norm = 1.5896e-01, time/batch = 0.6820s	
16718/28500 (epoch 29.330), train_loss = 0.85248109, grad/param norm = 1.6717e-01, time/batch = 0.6801s	
16719/28500 (epoch 29.332), train_loss = 0.93062969, grad/param norm = 1.6765e-01, time/batch = 0.6834s	
16720/28500 (epoch 29.333), train_loss = 0.75190507, grad/param norm = 1.6378e-01, time/batch = 0.6826s	
16721/28500 (epoch 29.335), train_loss = 0.82852401, grad/param norm = 1.6033e-01, time/batch = 0.6842s	
16722/28500 (epoch 29.337), train_loss = 0.79740814, grad/param norm = 1.5089e-01, time/batch = 0.6836s	
16723/28500 (epoch 29.339), train_loss = 0.77454423, grad/param norm = 1.3339e-01, time/batch = 0.6842s	
16724/28500 (epoch 29.340), train_loss = 0.92902008, grad/param norm = 2.1915e-01, time/batch = 0.6826s	
16725/28500 (epoch 29.342), train_loss = 0.92062903, grad/param norm = 1.6812e-01, time/batch = 0.6838s	
16726/28500 (epoch 29.344), train_loss = 0.83536259, grad/param norm = 1.6392e-01, time/batch = 0.6842s	
16727/28500 (epoch 29.346), train_loss = 0.77137827, grad/param norm = 1.5260e-01, time/batch = 0.6823s	
16728/28500 (epoch 29.347), train_loss = 0.92140908, grad/param norm = 1.6383e-01, time/batch = 0.6807s	
16729/28500 (epoch 29.349), train_loss = 0.90423164, grad/param norm = 1.7281e-01, time/batch = 0.6800s	
16730/28500 (epoch 29.351), train_loss = 0.83972458, grad/param norm = 1.6687e-01, time/batch = 0.6795s	
16731/28500 (epoch 29.353), train_loss = 0.91596213, grad/param norm = 1.7846e-01, time/batch = 0.6831s	
16732/28500 (epoch 29.354), train_loss = 0.83106027, grad/param norm = 1.6194e-01, time/batch = 0.6841s	
16733/28500 (epoch 29.356), train_loss = 0.86395740, grad/param norm = 1.6171e-01, time/batch = 0.6814s	
16734/28500 (epoch 29.358), train_loss = 0.95476909, grad/param norm = 1.6770e-01, time/batch = 0.6816s	
16735/28500 (epoch 29.360), train_loss = 0.95145594, grad/param norm = 1.8670e-01, time/batch = 0.6806s	
16736/28500 (epoch 29.361), train_loss = 0.84179542, grad/param norm = 1.5409e-01, time/batch = 0.6809s	
16737/28500 (epoch 29.363), train_loss = 0.83372067, grad/param norm = 1.5037e-01, time/batch = 0.6812s	
16738/28500 (epoch 29.365), train_loss = 0.88501980, grad/param norm = 1.8035e-01, time/batch = 0.6809s	
16739/28500 (epoch 29.367), train_loss = 0.93932973, grad/param norm = 1.8252e-01, time/batch = 0.6808s	
16740/28500 (epoch 29.368), train_loss = 0.87099196, grad/param norm = 1.6378e-01, time/batch = 0.6795s	
16741/28500 (epoch 29.370), train_loss = 0.91106469, grad/param norm = 1.6366e-01, time/batch = 0.6850s	
16742/28500 (epoch 29.372), train_loss = 0.75992011, grad/param norm = 1.6718e-01, time/batch = 0.6827s	
16743/28500 (epoch 29.374), train_loss = 0.88725965, grad/param norm = 1.6768e-01, time/batch = 0.6849s	
16744/28500 (epoch 29.375), train_loss = 1.00008158, grad/param norm = 1.6919e-01, time/batch = 0.6837s	
16745/28500 (epoch 29.377), train_loss = 0.78112000, grad/param norm = 2.0522e-01, time/batch = 0.6972s	
16746/28500 (epoch 29.379), train_loss = 0.72174147, grad/param norm = 1.5603e-01, time/batch = 0.6991s	
16747/28500 (epoch 29.381), train_loss = 0.87686697, grad/param norm = 1.5749e-01, time/batch = 0.6815s	
16748/28500 (epoch 29.382), train_loss = 0.87059575, grad/param norm = 1.9942e-01, time/batch = 0.6813s	
16749/28500 (epoch 29.384), train_loss = 0.78324173, grad/param norm = 1.7126e-01, time/batch = 0.6822s	
16750/28500 (epoch 29.386), train_loss = 0.81413325, grad/param norm = 1.4963e-01, time/batch = 0.6866s	
16751/28500 (epoch 29.388), train_loss = 1.00571494, grad/param norm = 1.7385e-01, time/batch = 0.6843s	
16752/28500 (epoch 29.389), train_loss = 0.85700590, grad/param norm = 1.7255e-01, time/batch = 0.6827s	
16753/28500 (epoch 29.391), train_loss = 0.79798524, grad/param norm = 1.7142e-01, time/batch = 0.6827s	
16754/28500 (epoch 29.393), train_loss = 0.83787286, grad/param norm = 1.7121e-01, time/batch = 0.6803s	
16755/28500 (epoch 29.395), train_loss = 1.02652876, grad/param norm = 1.6878e-01, time/batch = 0.6809s	
16756/28500 (epoch 29.396), train_loss = 0.98775993, grad/param norm = 1.8403e-01, time/batch = 0.6807s	
16757/28500 (epoch 29.398), train_loss = 0.69260435, grad/param norm = 1.5969e-01, time/batch = 0.6813s	
16758/28500 (epoch 29.400), train_loss = 0.89627208, grad/param norm = 1.8532e-01, time/batch = 0.6805s	
16759/28500 (epoch 29.402), train_loss = 0.92697557, grad/param norm = 2.3677e-01, time/batch = 0.6808s	
16760/28500 (epoch 29.404), train_loss = 0.95046927, grad/param norm = 1.9108e-01, time/batch = 0.6796s	
16761/28500 (epoch 29.405), train_loss = 0.96619480, grad/param norm = 1.8216e-01, time/batch = 0.6821s	
16762/28500 (epoch 29.407), train_loss = 0.93794617, grad/param norm = 1.6341e-01, time/batch = 0.6985s	
16763/28500 (epoch 29.409), train_loss = 0.93473345, grad/param norm = 1.7637e-01, time/batch = 0.6829s	
16764/28500 (epoch 29.411), train_loss = 1.00769632, grad/param norm = 1.8301e-01, time/batch = 0.6834s	
16765/28500 (epoch 29.412), train_loss = 1.04627012, grad/param norm = 1.8388e-01, time/batch = 0.6835s	
16766/28500 (epoch 29.414), train_loss = 0.93463719, grad/param norm = 1.7542e-01, time/batch = 0.6833s	
16767/28500 (epoch 29.416), train_loss = 0.84824482, grad/param norm = 1.6041e-01, time/batch = 0.6813s	
16768/28500 (epoch 29.418), train_loss = 0.94132635, grad/param norm = 1.5719e-01, time/batch = 0.6810s	
16769/28500 (epoch 29.419), train_loss = 1.02569246, grad/param norm = 2.0175e-01, time/batch = 0.6911s	
16770/28500 (epoch 29.421), train_loss = 0.99066584, grad/param norm = 1.6623e-01, time/batch = 0.6801s	
16771/28500 (epoch 29.423), train_loss = 1.01171141, grad/param norm = 1.9823e-01, time/batch = 0.6807s	
16772/28500 (epoch 29.425), train_loss = 0.94750819, grad/param norm = 2.1203e-01, time/batch = 0.6800s	
16773/28500 (epoch 29.426), train_loss = 0.93660329, grad/param norm = 2.0768e-01, time/batch = 0.6797s	
16774/28500 (epoch 29.428), train_loss = 1.06393481, grad/param norm = 1.8098e-01, time/batch = 0.6807s	
16775/28500 (epoch 29.430), train_loss = 1.04806921, grad/param norm = 1.6680e-01, time/batch = 0.6858s	
16776/28500 (epoch 29.432), train_loss = 0.93980707, grad/param norm = 1.8133e-01, time/batch = 0.6964s	
16777/28500 (epoch 29.433), train_loss = 0.98730874, grad/param norm = 1.9512e-01, time/batch = 0.6801s	
16778/28500 (epoch 29.435), train_loss = 0.95484540, grad/param norm = 1.7851e-01, time/batch = 0.6799s	
16779/28500 (epoch 29.437), train_loss = 0.86387162, grad/param norm = 1.5582e-01, time/batch = 0.6810s	
16780/28500 (epoch 29.439), train_loss = 0.88953127, grad/param norm = 1.5202e-01, time/batch = 0.6811s	
16781/28500 (epoch 29.440), train_loss = 1.07869574, grad/param norm = 1.7590e-01, time/batch = 0.6837s	
16782/28500 (epoch 29.442), train_loss = 0.85915077, grad/param norm = 1.8668e-01, time/batch = 0.6801s	
16783/28500 (epoch 29.444), train_loss = 0.81171665, grad/param norm = 1.4707e-01, time/batch = 0.6813s	
16784/28500 (epoch 29.446), train_loss = 0.77830727, grad/param norm = 1.5922e-01, time/batch = 0.6801s	
16785/28500 (epoch 29.447), train_loss = 0.79325805, grad/param norm = 1.6202e-01, time/batch = 0.6815s	
16786/28500 (epoch 29.449), train_loss = 0.88283985, grad/param norm = 1.5772e-01, time/batch = 0.6801s	
16787/28500 (epoch 29.451), train_loss = 0.90528150, grad/param norm = 1.6518e-01, time/batch = 0.6818s	
16788/28500 (epoch 29.453), train_loss = 0.89491014, grad/param norm = 1.7196e-01, time/batch = 0.6796s	
16789/28500 (epoch 29.454), train_loss = 0.85997158, grad/param norm = 1.6149e-01, time/batch = 0.6816s	
16790/28500 (epoch 29.456), train_loss = 0.97907841, grad/param norm = 1.8589e-01, time/batch = 0.6807s	
16791/28500 (epoch 29.458), train_loss = 0.89357489, grad/param norm = 1.7043e-01, time/batch = 0.6812s	
16792/28500 (epoch 29.460), train_loss = 0.98337687, grad/param norm = 1.6897e-01, time/batch = 0.6800s	
16793/28500 (epoch 29.461), train_loss = 0.83866764, grad/param norm = 1.8022e-01, time/batch = 0.6794s	
16794/28500 (epoch 29.463), train_loss = 0.77650723, grad/param norm = 1.4315e-01, time/batch = 0.6806s	
16795/28500 (epoch 29.465), train_loss = 0.77729780, grad/param norm = 1.7087e-01, time/batch = 0.6806s	
16796/28500 (epoch 29.467), train_loss = 0.93125724, grad/param norm = 1.6002e-01, time/batch = 0.6823s	
16797/28500 (epoch 29.468), train_loss = 0.81840581, grad/param norm = 1.4543e-01, time/batch = 0.6797s	
16798/28500 (epoch 29.470), train_loss = 0.87420028, grad/param norm = 2.0074e-01, time/batch = 0.6797s	
16799/28500 (epoch 29.472), train_loss = 0.84769423, grad/param norm = 1.6838e-01, time/batch = 0.6784s	
16800/28500 (epoch 29.474), train_loss = 1.05482458, grad/param norm = 1.9457e-01, time/batch = 0.6851s	
16801/28500 (epoch 29.475), train_loss = 0.85605029, grad/param norm = 1.6294e-01, time/batch = 0.6803s	
16802/28500 (epoch 29.477), train_loss = 0.86995961, grad/param norm = 1.6901e-01, time/batch = 0.6803s	
16803/28500 (epoch 29.479), train_loss = 0.95830908, grad/param norm = 1.7346e-01, time/batch = 0.6782s	
16804/28500 (epoch 29.481), train_loss = 0.95447526, grad/param norm = 1.8357e-01, time/batch = 0.6758s	
16805/28500 (epoch 29.482), train_loss = 0.80707211, grad/param norm = 1.8498e-01, time/batch = 0.6768s	
16806/28500 (epoch 29.484), train_loss = 0.83665741, grad/param norm = 1.6900e-01, time/batch = 0.6763s	
16807/28500 (epoch 29.486), train_loss = 0.73867750, grad/param norm = 1.6693e-01, time/batch = 0.6757s	
16808/28500 (epoch 29.488), train_loss = 0.94801431, grad/param norm = 1.5855e-01, time/batch = 0.6758s	
16809/28500 (epoch 29.489), train_loss = 1.01937208, grad/param norm = 1.6713e-01, time/batch = 0.6762s	
16810/28500 (epoch 29.491), train_loss = 0.86182074, grad/param norm = 1.7801e-01, time/batch = 0.6760s	
16811/28500 (epoch 29.493), train_loss = 0.89843346, grad/param norm = 1.5296e-01, time/batch = 0.6779s	
16812/28500 (epoch 29.495), train_loss = 0.92950647, grad/param norm = 1.7339e-01, time/batch = 0.6765s	
16813/28500 (epoch 29.496), train_loss = 0.82091600, grad/param norm = 1.6704e-01, time/batch = 0.6762s	
16814/28500 (epoch 29.498), train_loss = 0.88158105, grad/param norm = 1.6135e-01, time/batch = 0.6773s	
16815/28500 (epoch 29.500), train_loss = 0.82471986, grad/param norm = 1.5536e-01, time/batch = 0.6798s	
16816/28500 (epoch 29.502), train_loss = 0.95755630, grad/param norm = 1.5271e-01, time/batch = 0.6781s	
16817/28500 (epoch 29.504), train_loss = 0.95093818, grad/param norm = 1.6287e-01, time/batch = 0.6804s	
16818/28500 (epoch 29.505), train_loss = 0.85218667, grad/param norm = 1.7022e-01, time/batch = 0.6768s	
16819/28500 (epoch 29.507), train_loss = 1.02109565, grad/param norm = 2.1422e-01, time/batch = 0.6758s	
16820/28500 (epoch 29.509), train_loss = 0.91418531, grad/param norm = 1.6224e-01, time/batch = 0.6758s	
16821/28500 (epoch 29.511), train_loss = 0.92332687, grad/param norm = 1.7140e-01, time/batch = 0.6783s	
16822/28500 (epoch 29.512), train_loss = 0.95824110, grad/param norm = 1.8119e-01, time/batch = 0.6767s	
16823/28500 (epoch 29.514), train_loss = 0.90981134, grad/param norm = 1.6780e-01, time/batch = 0.6776s	
16824/28500 (epoch 29.516), train_loss = 0.88987955, grad/param norm = 1.5961e-01, time/batch = 0.6786s	
16825/28500 (epoch 29.518), train_loss = 0.94997086, grad/param norm = 1.6698e-01, time/batch = 0.6775s	
16826/28500 (epoch 29.519), train_loss = 0.99205899, grad/param norm = 1.8538e-01, time/batch = 0.6757s	
16827/28500 (epoch 29.521), train_loss = 1.04381664, grad/param norm = 1.8766e-01, time/batch = 0.6763s	
16828/28500 (epoch 29.523), train_loss = 0.96866938, grad/param norm = 1.7546e-01, time/batch = 0.6757s	
16829/28500 (epoch 29.525), train_loss = 1.03066479, grad/param norm = 1.8373e-01, time/batch = 0.6759s	
16830/28500 (epoch 29.526), train_loss = 0.96894261, grad/param norm = 1.5628e-01, time/batch = 0.6764s	
16831/28500 (epoch 29.528), train_loss = 0.96945034, grad/param norm = 1.9790e-01, time/batch = 0.6804s	
16832/28500 (epoch 29.530), train_loss = 1.00490774, grad/param norm = 1.7545e-01, time/batch = 0.6827s	
16833/28500 (epoch 29.532), train_loss = 0.87878966, grad/param norm = 1.5843e-01, time/batch = 0.6856s	
16834/28500 (epoch 29.533), train_loss = 0.97821090, grad/param norm = 1.7503e-01, time/batch = 0.6764s	
16835/28500 (epoch 29.535), train_loss = 0.80646459, grad/param norm = 1.5330e-01, time/batch = 0.6827s	
16836/28500 (epoch 29.537), train_loss = 0.82964887, grad/param norm = 1.6731e-01, time/batch = 0.6793s	
16837/28500 (epoch 29.539), train_loss = 0.78246639, grad/param norm = 1.8874e-01, time/batch = 0.6806s	
16838/28500 (epoch 29.540), train_loss = 0.93757428, grad/param norm = 1.7453e-01, time/batch = 0.6915s	
16839/28500 (epoch 29.542), train_loss = 0.97220460, grad/param norm = 2.4456e-01, time/batch = 0.6838s	
16840/28500 (epoch 29.544), train_loss = 1.04149336, grad/param norm = 1.7740e-01, time/batch = 0.6807s	
16841/28500 (epoch 29.546), train_loss = 0.88617398, grad/param norm = 1.5594e-01, time/batch = 0.6781s	
16842/28500 (epoch 29.547), train_loss = 0.91060488, grad/param norm = 1.7211e-01, time/batch = 0.6775s	
16843/28500 (epoch 29.549), train_loss = 0.75880631, grad/param norm = 1.3755e-01, time/batch = 0.6757s	
16844/28500 (epoch 29.551), train_loss = 0.89552178, grad/param norm = 1.9992e-01, time/batch = 0.6759s	
16845/28500 (epoch 29.553), train_loss = 1.08262981, grad/param norm = 2.2076e-01, time/batch = 0.6761s	
16846/28500 (epoch 29.554), train_loss = 0.97249735, grad/param norm = 1.7902e-01, time/batch = 0.6768s	
16847/28500 (epoch 29.556), train_loss = 0.95483421, grad/param norm = 1.7612e-01, time/batch = 0.6763s	
16848/28500 (epoch 29.558), train_loss = 0.97216426, grad/param norm = 1.8229e-01, time/batch = 0.6763s	
16849/28500 (epoch 29.560), train_loss = 0.94806345, grad/param norm = 1.8553e-01, time/batch = 0.6767s	
16850/28500 (epoch 29.561), train_loss = 0.99578270, grad/param norm = 2.0356e-01, time/batch = 0.6768s	
16851/28500 (epoch 29.563), train_loss = 1.06614299, grad/param norm = 2.0758e-01, time/batch = 0.6775s	
16852/28500 (epoch 29.565), train_loss = 0.86641310, grad/param norm = 1.8604e-01, time/batch = 0.6788s	
16853/28500 (epoch 29.567), train_loss = 0.81759798, grad/param norm = 1.5411e-01, time/batch = 0.6766s	
16854/28500 (epoch 29.568), train_loss = 0.95027822, grad/param norm = 1.9728e-01, time/batch = 0.6757s	
16855/28500 (epoch 29.570), train_loss = 0.89381534, grad/param norm = 1.7108e-01, time/batch = 0.6761s	
16856/28500 (epoch 29.572), train_loss = 0.92849034, grad/param norm = 1.9922e-01, time/batch = 0.6761s	
16857/28500 (epoch 29.574), train_loss = 0.87378113, grad/param norm = 1.7952e-01, time/batch = 0.6757s	
16858/28500 (epoch 29.575), train_loss = 0.88766481, grad/param norm = 1.6431e-01, time/batch = 0.6794s	
16859/28500 (epoch 29.577), train_loss = 0.94827785, grad/param norm = 1.6570e-01, time/batch = 0.6770s	
16860/28500 (epoch 29.579), train_loss = 0.98790055, grad/param norm = 1.7555e-01, time/batch = 0.6768s	
16861/28500 (epoch 29.581), train_loss = 0.83983767, grad/param norm = 1.9364e-01, time/batch = 0.6776s	
16862/28500 (epoch 29.582), train_loss = 0.99907738, grad/param norm = 1.6770e-01, time/batch = 0.6788s	
16863/28500 (epoch 29.584), train_loss = 0.87299012, grad/param norm = 1.7978e-01, time/batch = 0.6794s	
16864/28500 (epoch 29.586), train_loss = 0.83935727, grad/param norm = 1.4585e-01, time/batch = 0.6761s	
16865/28500 (epoch 29.588), train_loss = 0.84313595, grad/param norm = 1.7363e-01, time/batch = 0.6787s	
16866/28500 (epoch 29.589), train_loss = 0.92691148, grad/param norm = 1.9966e-01, time/batch = 0.6773s	
16867/28500 (epoch 29.591), train_loss = 0.94395296, grad/param norm = 1.8140e-01, time/batch = 0.6799s	
16868/28500 (epoch 29.593), train_loss = 0.86728436, grad/param norm = 1.6160e-01, time/batch = 0.6800s	
16869/28500 (epoch 29.595), train_loss = 1.11925634, grad/param norm = 2.1544e-01, time/batch = 0.6795s	
16870/28500 (epoch 29.596), train_loss = 1.07462514, grad/param norm = 1.8108e-01, time/batch = 0.6809s	
16871/28500 (epoch 29.598), train_loss = 0.91295064, grad/param norm = 1.7084e-01, time/batch = 0.6813s	
16872/28500 (epoch 29.600), train_loss = 0.92752628, grad/param norm = 2.1001e-01, time/batch = 0.6798s	
16873/28500 (epoch 29.602), train_loss = 0.99724528, grad/param norm = 2.1683e-01, time/batch = 0.6789s	
16874/28500 (epoch 29.604), train_loss = 1.00925321, grad/param norm = 1.6931e-01, time/batch = 0.6834s	
16875/28500 (epoch 29.605), train_loss = 0.98284953, grad/param norm = 1.6932e-01, time/batch = 0.6811s	
16876/28500 (epoch 29.607), train_loss = 1.01984326, grad/param norm = 1.6538e-01, time/batch = 0.6820s	
16877/28500 (epoch 29.609), train_loss = 0.95340864, grad/param norm = 1.7295e-01, time/batch = 0.6793s	
16878/28500 (epoch 29.611), train_loss = 0.90063302, grad/param norm = 1.9735e-01, time/batch = 0.6877s	
16879/28500 (epoch 29.612), train_loss = 0.97774824, grad/param norm = 1.9749e-01, time/batch = 0.6809s	
16880/28500 (epoch 29.614), train_loss = 0.98197825, grad/param norm = 1.7734e-01, time/batch = 0.6909s	
16881/28500 (epoch 29.616), train_loss = 0.90031993, grad/param norm = 1.8142e-01, time/batch = 0.6823s	
16882/28500 (epoch 29.618), train_loss = 0.90224560, grad/param norm = 1.8373e-01, time/batch = 0.6816s	
16883/28500 (epoch 29.619), train_loss = 1.02151727, grad/param norm = 2.0394e-01, time/batch = 0.6818s	
16884/28500 (epoch 29.621), train_loss = 0.76189707, grad/param norm = 1.5873e-01, time/batch = 0.6777s	
16885/28500 (epoch 29.623), train_loss = 1.02662302, grad/param norm = 2.1379e-01, time/batch = 0.6773s	
16886/28500 (epoch 29.625), train_loss = 0.84100121, grad/param norm = 1.6642e-01, time/batch = 0.6770s	
16887/28500 (epoch 29.626), train_loss = 0.71949683, grad/param norm = 1.5305e-01, time/batch = 0.6777s	
16888/28500 (epoch 29.628), train_loss = 0.83852551, grad/param norm = 1.6967e-01, time/batch = 0.6787s	
16889/28500 (epoch 29.630), train_loss = 0.80188877, grad/param norm = 1.6168e-01, time/batch = 0.6814s	
16890/28500 (epoch 29.632), train_loss = 1.00428692, grad/param norm = 1.8048e-01, time/batch = 0.6791s	
16891/28500 (epoch 29.633), train_loss = 1.05528511, grad/param norm = 1.6112e-01, time/batch = 0.6822s	
16892/28500 (epoch 29.635), train_loss = 0.97568943, grad/param norm = 1.8880e-01, time/batch = 0.8540s	
16893/28500 (epoch 29.637), train_loss = 0.93187724, grad/param norm = 1.6395e-01, time/batch = 0.9902s	
16894/28500 (epoch 29.639), train_loss = 0.85093930, grad/param norm = 1.8839e-01, time/batch = 0.9934s	
16895/28500 (epoch 29.640), train_loss = 0.85053888, grad/param norm = 1.7389e-01, time/batch = 0.9911s	
16896/28500 (epoch 29.642), train_loss = 0.86469594, grad/param norm = 1.5966e-01, time/batch = 0.9952s	
16897/28500 (epoch 29.644), train_loss = 0.97883513, grad/param norm = 1.7082e-01, time/batch = 0.9965s	
16898/28500 (epoch 29.646), train_loss = 0.79404810, grad/param norm = 1.4828e-01, time/batch = 0.9918s	
16899/28500 (epoch 29.647), train_loss = 0.83326292, grad/param norm = 1.5866e-01, time/batch = 0.9913s	
16900/28500 (epoch 29.649), train_loss = 0.80285247, grad/param norm = 1.8792e-01, time/batch = 0.9931s	
16901/28500 (epoch 29.651), train_loss = 0.80889947, grad/param norm = 1.8163e-01, time/batch = 1.0137s	
16902/28500 (epoch 29.653), train_loss = 0.80010852, grad/param norm = 1.8365e-01, time/batch = 1.6374s	
16903/28500 (epoch 29.654), train_loss = 0.84928702, grad/param norm = 1.7642e-01, time/batch = 1.9052s	
16904/28500 (epoch 29.656), train_loss = 0.84415486, grad/param norm = 2.0962e-01, time/batch = 1.8338s	
16905/28500 (epoch 29.658), train_loss = 0.90187959, grad/param norm = 1.7877e-01, time/batch = 1.8966s	
16906/28500 (epoch 29.660), train_loss = 0.93563522, grad/param norm = 1.7444e-01, time/batch = 1.9049s	
16907/28500 (epoch 29.661), train_loss = 1.03377275, grad/param norm = 1.8365e-01, time/batch = 8.9026s	
16908/28500 (epoch 29.663), train_loss = 1.03251073, grad/param norm = 1.8933e-01, time/batch = 15.5153s	
16909/28500 (epoch 29.665), train_loss = 0.90149892, grad/param norm = 1.6172e-01, time/batch = 15.1233s	
16910/28500 (epoch 29.667), train_loss = 0.90324235, grad/param norm = 2.0372e-01, time/batch = 15.2753s	
16911/28500 (epoch 29.668), train_loss = 0.89914806, grad/param norm = 1.6774e-01, time/batch = 15.5064s	
16912/28500 (epoch 29.670), train_loss = 0.91834964, grad/param norm = 1.6885e-01, time/batch = 15.2279s	
16913/28500 (epoch 29.672), train_loss = 0.83031241, grad/param norm = 1.6523e-01, time/batch = 15.1195s	
16914/28500 (epoch 29.674), train_loss = 0.73887195, grad/param norm = 1.6800e-01, time/batch = 15.2100s	
16915/28500 (epoch 29.675), train_loss = 0.77719582, grad/param norm = 1.5356e-01, time/batch = 15.1208s	
16916/28500 (epoch 29.677), train_loss = 0.87474058, grad/param norm = 1.6731e-01, time/batch = 15.1938s	
16917/28500 (epoch 29.679), train_loss = 0.87248134, grad/param norm = 1.8109e-01, time/batch = 15.1399s	
16918/28500 (epoch 29.681), train_loss = 0.93243436, grad/param norm = 1.7829e-01, time/batch = 15.2922s	
16919/28500 (epoch 29.682), train_loss = 0.84263744, grad/param norm = 1.6807e-01, time/batch = 15.6078s	
16920/28500 (epoch 29.684), train_loss = 0.92798401, grad/param norm = 1.6029e-01, time/batch = 15.3855s	
16921/28500 (epoch 29.686), train_loss = 0.86221692, grad/param norm = 1.8558e-01, time/batch = 15.1374s	
16922/28500 (epoch 29.688), train_loss = 0.83033693, grad/param norm = 1.4204e-01, time/batch = 15.4701s	
16923/28500 (epoch 29.689), train_loss = 0.84067033, grad/param norm = 1.8395e-01, time/batch = 15.2962s	
16924/28500 (epoch 29.691), train_loss = 0.92649840, grad/param norm = 1.7632e-01, time/batch = 15.2395s	
16925/28500 (epoch 29.693), train_loss = 0.86150229, grad/param norm = 1.5818e-01, time/batch = 15.0476s	
16926/28500 (epoch 29.695), train_loss = 0.67173006, grad/param norm = 1.7210e-01, time/batch = 15.2844s	
16927/28500 (epoch 29.696), train_loss = 0.88770062, grad/param norm = 1.6293e-01, time/batch = 15.1114s	
16928/28500 (epoch 29.698), train_loss = 0.91637854, grad/param norm = 1.7854e-01, time/batch = 14.9819s	
16929/28500 (epoch 29.700), train_loss = 0.92651517, grad/param norm = 1.8430e-01, time/batch = 15.0445s	
16930/28500 (epoch 29.702), train_loss = 0.92012211, grad/param norm = 1.9991e-01, time/batch = 15.0641s	
16931/28500 (epoch 29.704), train_loss = 0.92808897, grad/param norm = 1.8634e-01, time/batch = 15.5853s	
16932/28500 (epoch 29.705), train_loss = 1.00941044, grad/param norm = 2.0532e-01, time/batch = 15.3154s	
16933/28500 (epoch 29.707), train_loss = 0.84865732, grad/param norm = 1.8400e-01, time/batch = 15.3018s	
16934/28500 (epoch 29.709), train_loss = 1.03939391, grad/param norm = 1.7499e-01, time/batch = 15.5018s	
16935/28500 (epoch 29.711), train_loss = 0.84462692, grad/param norm = 1.7126e-01, time/batch = 15.4587s	
16936/28500 (epoch 29.712), train_loss = 0.92822430, grad/param norm = 1.9937e-01, time/batch = 15.4012s	
16937/28500 (epoch 29.714), train_loss = 1.02717124, grad/param norm = 1.8133e-01, time/batch = 15.4212s	
16938/28500 (epoch 29.716), train_loss = 0.88528330, grad/param norm = 1.5582e-01, time/batch = 15.4124s	
16939/28500 (epoch 29.718), train_loss = 0.92819175, grad/param norm = 1.7939e-01, time/batch = 15.3111s	
16940/28500 (epoch 29.719), train_loss = 0.92107302, grad/param norm = 1.7061e-01, time/batch = 15.2836s	
16941/28500 (epoch 29.721), train_loss = 0.73526813, grad/param norm = 1.6720e-01, time/batch = 15.3133s	
16942/28500 (epoch 29.723), train_loss = 0.91527785, grad/param norm = 1.7832e-01, time/batch = 15.3798s	
16943/28500 (epoch 29.725), train_loss = 0.97592707, grad/param norm = 1.6658e-01, time/batch = 15.5506s	
16944/28500 (epoch 29.726), train_loss = 0.91094887, grad/param norm = 1.8262e-01, time/batch = 15.6380s	
16945/28500 (epoch 29.728), train_loss = 0.82334869, grad/param norm = 1.5340e-01, time/batch = 15.6428s	
16946/28500 (epoch 29.730), train_loss = 0.92001804, grad/param norm = 1.9831e-01, time/batch = 15.1998s	
16947/28500 (epoch 29.732), train_loss = 0.72228211, grad/param norm = 1.4175e-01, time/batch = 15.3032s	
16948/28500 (epoch 29.733), train_loss = 0.76692951, grad/param norm = 1.6103e-01, time/batch = 15.1338s	
16949/28500 (epoch 29.735), train_loss = 0.77495569, grad/param norm = 1.5820e-01, time/batch = 15.3853s	
16950/28500 (epoch 29.737), train_loss = 0.71170469, grad/param norm = 1.3905e-01, time/batch = 26.7116s	
16951/28500 (epoch 29.739), train_loss = 0.82290337, grad/param norm = 1.7108e-01, time/batch = 15.6328s	
16952/28500 (epoch 29.740), train_loss = 0.90909116, grad/param norm = 1.6746e-01, time/batch = 15.3211s	
16953/28500 (epoch 29.742), train_loss = 0.82933391, grad/param norm = 1.7023e-01, time/batch = 15.4260s	
16954/28500 (epoch 29.744), train_loss = 0.91251043, grad/param norm = 1.7654e-01, time/batch = 15.3105s	
16955/28500 (epoch 29.746), train_loss = 0.85033007, grad/param norm = 1.7421e-01, time/batch = 15.3656s	
16956/28500 (epoch 29.747), train_loss = 0.83576993, grad/param norm = 1.5059e-01, time/batch = 15.5679s	
16957/28500 (epoch 29.749), train_loss = 0.95746411, grad/param norm = 1.9287e-01, time/batch = 15.4228s	
16958/28500 (epoch 29.751), train_loss = 0.79603528, grad/param norm = 1.8859e-01, time/batch = 15.0672s	
16959/28500 (epoch 29.753), train_loss = 0.87608288, grad/param norm = 1.6875e-01, time/batch = 15.2094s	
16960/28500 (epoch 29.754), train_loss = 0.80822636, grad/param norm = 1.7247e-01, time/batch = 15.2822s	
16961/28500 (epoch 29.756), train_loss = 1.00697600, grad/param norm = 1.7827e-01, time/batch = 15.7085s	
16962/28500 (epoch 29.758), train_loss = 0.94941497, grad/param norm = 1.8412e-01, time/batch = 15.4685s	
16963/28500 (epoch 29.760), train_loss = 0.78354031, grad/param norm = 1.9946e-01, time/batch = 15.5897s	
16964/28500 (epoch 29.761), train_loss = 0.83447158, grad/param norm = 1.8196e-01, time/batch = 15.5203s	
16965/28500 (epoch 29.763), train_loss = 0.72456599, grad/param norm = 1.5966e-01, time/batch = 15.5352s	
16966/28500 (epoch 29.765), train_loss = 0.87018714, grad/param norm = 1.5708e-01, time/batch = 15.5844s	
16967/28500 (epoch 29.767), train_loss = 0.75607013, grad/param norm = 1.4562e-01, time/batch = 15.4868s	
16968/28500 (epoch 29.768), train_loss = 0.95756306, grad/param norm = 1.7827e-01, time/batch = 15.3811s	
16969/28500 (epoch 29.770), train_loss = 0.80345119, grad/param norm = 1.8060e-01, time/batch = 15.5452s	
16970/28500 (epoch 29.772), train_loss = 0.71487169, grad/param norm = 1.4720e-01, time/batch = 15.0891s	
16971/28500 (epoch 29.774), train_loss = 0.90000923, grad/param norm = 1.7472e-01, time/batch = 15.0703s	
16972/28500 (epoch 29.775), train_loss = 0.97282741, grad/param norm = 1.5838e-01, time/batch = 15.1369s	
16973/28500 (epoch 29.777), train_loss = 0.97187740, grad/param norm = 1.6223e-01, time/batch = 15.5283s	
16974/28500 (epoch 29.779), train_loss = 0.73411450, grad/param norm = 1.4363e-01, time/batch = 15.3682s	
16975/28500 (epoch 29.781), train_loss = 0.87873551, grad/param norm = 1.8466e-01, time/batch = 15.3036s	
16976/28500 (epoch 29.782), train_loss = 0.91485666, grad/param norm = 1.9239e-01, time/batch = 15.4353s	
16977/28500 (epoch 29.784), train_loss = 0.73608490, grad/param norm = 1.7180e-01, time/batch = 15.5070s	
16978/28500 (epoch 29.786), train_loss = 0.77149272, grad/param norm = 1.4257e-01, time/batch = 15.2315s	
16979/28500 (epoch 29.788), train_loss = 0.87324072, grad/param norm = 1.7243e-01, time/batch = 15.3496s	
16980/28500 (epoch 29.789), train_loss = 0.67527992, grad/param norm = 1.7326e-01, time/batch = 15.4649s	
16981/28500 (epoch 29.791), train_loss = 0.89937937, grad/param norm = 1.6474e-01, time/batch = 15.4739s	
16982/28500 (epoch 29.793), train_loss = 0.88586094, grad/param norm = 1.5917e-01, time/batch = 15.3160s	
16983/28500 (epoch 29.795), train_loss = 0.89702269, grad/param norm = 1.6101e-01, time/batch = 15.3850s	
16984/28500 (epoch 29.796), train_loss = 0.79059323, grad/param norm = 1.5287e-01, time/batch = 15.1952s	
16985/28500 (epoch 29.798), train_loss = 0.73620826, grad/param norm = 1.6626e-01, time/batch = 15.1912s	
16986/28500 (epoch 29.800), train_loss = 0.76655857, grad/param norm = 1.8038e-01, time/batch = 15.3562s	
16987/28500 (epoch 29.802), train_loss = 0.83917258, grad/param norm = 2.0470e-01, time/batch = 15.3041s	
16988/28500 (epoch 29.804), train_loss = 0.89744565, grad/param norm = 1.5891e-01, time/batch = 15.2773s	
16989/28500 (epoch 29.805), train_loss = 0.89419231, grad/param norm = 1.8904e-01, time/batch = 15.3645s	
16990/28500 (epoch 29.807), train_loss = 0.89945584, grad/param norm = 1.7030e-01, time/batch = 15.2394s	
16991/28500 (epoch 29.809), train_loss = 0.91152444, grad/param norm = 2.3585e-01, time/batch = 15.0548s	
16992/28500 (epoch 29.811), train_loss = 0.93064156, grad/param norm = 1.8211e-01, time/batch = 15.4442s	
16993/28500 (epoch 29.812), train_loss = 0.89278476, grad/param norm = 1.7887e-01, time/batch = 15.6272s	
16994/28500 (epoch 29.814), train_loss = 0.83363090, grad/param norm = 1.6362e-01, time/batch = 15.7105s	
16995/28500 (epoch 29.816), train_loss = 0.94253272, grad/param norm = 2.0312e-01, time/batch = 15.3597s	
16996/28500 (epoch 29.818), train_loss = 1.00988447, grad/param norm = 1.7963e-01, time/batch = 15.3826s	
16997/28500 (epoch 29.819), train_loss = 0.89085549, grad/param norm = 1.6124e-01, time/batch = 15.2853s	
16998/28500 (epoch 29.821), train_loss = 0.85065837, grad/param norm = 1.5947e-01, time/batch = 15.1537s	
16999/28500 (epoch 29.823), train_loss = 1.03549172, grad/param norm = 2.1071e-01, time/batch = 15.2836s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch29.82_1.8368.t7	
17000/28500 (epoch 29.825), train_loss = 0.85448826, grad/param norm = 1.9177e-01, time/batch = 15.4774s	
17001/28500 (epoch 29.826), train_loss = 1.37983170, grad/param norm = 2.3482e-01, time/batch = 15.8149s	
17002/28500 (epoch 29.828), train_loss = 0.81092918, grad/param norm = 1.8786e-01, time/batch = 15.3292s	
17003/28500 (epoch 29.830), train_loss = 0.85864988, grad/param norm = 1.5680e-01, time/batch = 15.5357s	
17004/28500 (epoch 29.832), train_loss = 0.88379829, grad/param norm = 1.9082e-01, time/batch = 15.5626s	
17005/28500 (epoch 29.833), train_loss = 0.97099901, grad/param norm = 1.7075e-01, time/batch = 15.6229s	
17006/28500 (epoch 29.835), train_loss = 0.83237533, grad/param norm = 1.6844e-01, time/batch = 15.7092s	
17007/28500 (epoch 29.837), train_loss = 0.77448638, grad/param norm = 1.7915e-01, time/batch = 15.6709s	
17008/28500 (epoch 29.839), train_loss = 1.04605312, grad/param norm = 2.0777e-01, time/batch = 15.6173s	
17009/28500 (epoch 29.840), train_loss = 1.03907766, grad/param norm = 1.9966e-01, time/batch = 15.5664s	
17010/28500 (epoch 29.842), train_loss = 0.93721650, grad/param norm = 1.9459e-01, time/batch = 15.5441s	
17011/28500 (epoch 29.844), train_loss = 0.93144715, grad/param norm = 1.7545e-01, time/batch = 15.5879s	
17012/28500 (epoch 29.846), train_loss = 1.03190632, grad/param norm = 2.1651e-01, time/batch = 15.4765s	
17013/28500 (epoch 29.847), train_loss = 0.87795374, grad/param norm = 1.8416e-01, time/batch = 15.5542s	
17014/28500 (epoch 29.849), train_loss = 0.88816873, grad/param norm = 1.8080e-01, time/batch = 15.4853s	
17015/28500 (epoch 29.851), train_loss = 0.77388711, grad/param norm = 1.4520e-01, time/batch = 15.5439s	
17016/28500 (epoch 29.853), train_loss = 0.89903890, grad/param norm = 2.0736e-01, time/batch = 15.3233s	
17017/28500 (epoch 29.854), train_loss = 0.91465105, grad/param norm = 2.0719e-01, time/batch = 15.2791s	
17018/28500 (epoch 29.856), train_loss = 1.02525132, grad/param norm = 2.1848e-01, time/batch = 15.3741s	
17019/28500 (epoch 29.858), train_loss = 0.84298351, grad/param norm = 1.6360e-01, time/batch = 15.4411s	
17020/28500 (epoch 29.860), train_loss = 0.86161720, grad/param norm = 1.6508e-01, time/batch = 14.9895s	
17021/28500 (epoch 29.861), train_loss = 0.93374197, grad/param norm = 1.9537e-01, time/batch = 15.2850s	
17022/28500 (epoch 29.863), train_loss = 0.91985328, grad/param norm = 1.8937e-01, time/batch = 15.3210s	
17023/28500 (epoch 29.865), train_loss = 0.83245943, grad/param norm = 1.9472e-01, time/batch = 15.3934s	
17024/28500 (epoch 29.867), train_loss = 0.94398203, grad/param norm = 1.8108e-01, time/batch = 15.5446s	
17025/28500 (epoch 29.868), train_loss = 0.81449564, grad/param norm = 1.7283e-01, time/batch = 15.3617s	
17026/28500 (epoch 29.870), train_loss = 0.77542075, grad/param norm = 1.5715e-01, time/batch = 15.0536s	
17027/28500 (epoch 29.872), train_loss = 0.95178324, grad/param norm = 2.1890e-01, time/batch = 15.1189s	
17028/28500 (epoch 29.874), train_loss = 0.81771049, grad/param norm = 1.7496e-01, time/batch = 15.3077s	
17029/28500 (epoch 29.875), train_loss = 1.05065612, grad/param norm = 2.4562e-01, time/batch = 15.3680s	
17030/28500 (epoch 29.877), train_loss = 0.92266578, grad/param norm = 1.7831e-01, time/batch = 15.1361s	
17031/28500 (epoch 29.879), train_loss = 0.94959408, grad/param norm = 1.5694e-01, time/batch = 15.5611s	
17032/28500 (epoch 29.881), train_loss = 0.92497790, grad/param norm = 1.8075e-01, time/batch = 15.6405s	
17033/28500 (epoch 29.882), train_loss = 0.81503385, grad/param norm = 1.5775e-01, time/batch = 15.5548s	
17034/28500 (epoch 29.884), train_loss = 0.91241624, grad/param norm = 2.1169e-01, time/batch = 15.4463s	
17035/28500 (epoch 29.886), train_loss = 0.86810842, grad/param norm = 1.7624e-01, time/batch = 15.4833s	
17036/28500 (epoch 29.888), train_loss = 0.84596397, grad/param norm = 1.6150e-01, time/batch = 15.2859s	
17037/28500 (epoch 29.889), train_loss = 0.88897570, grad/param norm = 1.6618e-01, time/batch = 15.3062s	
17038/28500 (epoch 29.891), train_loss = 0.87529249, grad/param norm = 1.6210e-01, time/batch = 15.3227s	
17039/28500 (epoch 29.893), train_loss = 0.85708681, grad/param norm = 1.8936e-01, time/batch = 15.2998s	
17040/28500 (epoch 29.895), train_loss = 1.04670924, grad/param norm = 2.0462e-01, time/batch = 15.3866s	
17041/28500 (epoch 29.896), train_loss = 0.97613846, grad/param norm = 1.8313e-01, time/batch = 15.6168s	
17042/28500 (epoch 29.898), train_loss = 0.90470091, grad/param norm = 1.6510e-01, time/batch = 15.5331s	
17043/28500 (epoch 29.900), train_loss = 0.77105764, grad/param norm = 1.5676e-01, time/batch = 15.5509s	
17044/28500 (epoch 29.902), train_loss = 0.76926471, grad/param norm = 1.6580e-01, time/batch = 15.4805s	
17045/28500 (epoch 29.904), train_loss = 0.78971844, grad/param norm = 1.4999e-01, time/batch = 15.5502s	
17046/28500 (epoch 29.905), train_loss = 0.85699817, grad/param norm = 1.6639e-01, time/batch = 15.2786s	
17047/28500 (epoch 29.907), train_loss = 0.88082287, grad/param norm = 1.8297e-01, time/batch = 15.4219s	
17048/28500 (epoch 29.909), train_loss = 0.78153488, grad/param norm = 2.0092e-01, time/batch = 15.1595s	
17049/28500 (epoch 29.911), train_loss = 0.80280759, grad/param norm = 1.6801e-01, time/batch = 15.2212s	
17050/28500 (epoch 29.912), train_loss = 0.69637323, grad/param norm = 1.6349e-01, time/batch = 15.4694s	
17051/28500 (epoch 29.914), train_loss = 0.90806237, grad/param norm = 1.8382e-01, time/batch = 15.3688s	
17052/28500 (epoch 29.916), train_loss = 0.88778507, grad/param norm = 1.7244e-01, time/batch = 15.2431s	
17053/28500 (epoch 29.918), train_loss = 0.88149920, grad/param norm = 1.9599e-01, time/batch = 15.2227s	
17054/28500 (epoch 29.919), train_loss = 0.88033829, grad/param norm = 1.6017e-01, time/batch = 15.1376s	
17055/28500 (epoch 29.921), train_loss = 0.98996870, grad/param norm = 2.0057e-01, time/batch = 15.2127s	
17056/28500 (epoch 29.923), train_loss = 0.83854520, grad/param norm = 1.9990e-01, time/batch = 15.2294s	
17057/28500 (epoch 29.925), train_loss = 0.81573886, grad/param norm = 1.7614e-01, time/batch = 15.1957s	
17058/28500 (epoch 29.926), train_loss = 0.90065639, grad/param norm = 1.9546e-01, time/batch = 15.2776s	
17059/28500 (epoch 29.928), train_loss = 0.83700501, grad/param norm = 1.7524e-01, time/batch = 15.1910s	
17060/28500 (epoch 29.930), train_loss = 0.69652469, grad/param norm = 1.3350e-01, time/batch = 15.1950s	
17061/28500 (epoch 29.932), train_loss = 0.70021441, grad/param norm = 1.3885e-01, time/batch = 15.5951s	
17062/28500 (epoch 29.933), train_loss = 0.93354876, grad/param norm = 1.6750e-01, time/batch = 15.5663s	
17063/28500 (epoch 29.935), train_loss = 0.96727907, grad/param norm = 1.7572e-01, time/batch = 15.3660s	
17064/28500 (epoch 29.937), train_loss = 0.98775298, grad/param norm = 2.0127e-01, time/batch = 15.2230s	
17065/28500 (epoch 29.939), train_loss = 1.03806707, grad/param norm = 2.0677e-01, time/batch = 15.4287s	
17066/28500 (epoch 29.940), train_loss = 0.76259291, grad/param norm = 1.7098e-01, time/batch = 15.3016s	
17067/28500 (epoch 29.942), train_loss = 0.88478104, grad/param norm = 1.6195e-01, time/batch = 15.2942s	
17068/28500 (epoch 29.944), train_loss = 0.83316989, grad/param norm = 1.7816e-01, time/batch = 15.3944s	
17069/28500 (epoch 29.946), train_loss = 0.94595959, grad/param norm = 1.6603e-01, time/batch = 15.1402s	
17070/28500 (epoch 29.947), train_loss = 1.15531610, grad/param norm = 2.4568e-01, time/batch = 15.3678s	
17071/28500 (epoch 29.949), train_loss = 0.85991186, grad/param norm = 1.9211e-01, time/batch = 15.5316s	
17072/28500 (epoch 29.951), train_loss = 1.03369685, grad/param norm = 1.8033e-01, time/batch = 15.4607s	
17073/28500 (epoch 29.953), train_loss = 1.03690799, grad/param norm = 2.0738e-01, time/batch = 15.4691s	
17074/28500 (epoch 29.954), train_loss = 1.00129249, grad/param norm = 2.3053e-01, time/batch = 15.3073s	
17075/28500 (epoch 29.956), train_loss = 0.89972969, grad/param norm = 2.6373e-01, time/batch = 15.2483s	
17076/28500 (epoch 29.958), train_loss = 1.11889394, grad/param norm = 1.8449e-01, time/batch = 15.2763s	
17077/28500 (epoch 29.960), train_loss = 0.84683872, grad/param norm = 2.0186e-01, time/batch = 15.1932s	
17078/28500 (epoch 29.961), train_loss = 1.05968826, grad/param norm = 2.1205e-01, time/batch = 15.1391s	
17079/28500 (epoch 29.963), train_loss = 1.01938642, grad/param norm = 2.0077e-01, time/batch = 15.3874s	
17080/28500 (epoch 29.965), train_loss = 0.82212788, grad/param norm = 1.8690e-01, time/batch = 15.2889s	
17081/28500 (epoch 29.967), train_loss = 0.83761717, grad/param norm = 1.6822e-01, time/batch = 15.2032s	
17082/28500 (epoch 29.968), train_loss = 0.76714236, grad/param norm = 1.4231e-01, time/batch = 15.1239s	
17083/28500 (epoch 29.970), train_loss = 0.84157653, grad/param norm = 1.8745e-01, time/batch = 15.1539s	
17084/28500 (epoch 29.972), train_loss = 0.90487190, grad/param norm = 1.7947e-01, time/batch = 15.1464s	
17085/28500 (epoch 29.974), train_loss = 1.10436094, grad/param norm = 2.7395e-01, time/batch = 15.2096s	
17086/28500 (epoch 29.975), train_loss = 0.84077592, grad/param norm = 2.0134e-01, time/batch = 15.3452s	
17087/28500 (epoch 29.977), train_loss = 0.98056330, grad/param norm = 2.0285e-01, time/batch = 15.4582s	
17088/28500 (epoch 29.979), train_loss = 0.89684116, grad/param norm = 1.7616e-01, time/batch = 15.4909s	
17089/28500 (epoch 29.981), train_loss = 0.79682774, grad/param norm = 1.6978e-01, time/batch = 15.6585s	
17090/28500 (epoch 29.982), train_loss = 0.87017444, grad/param norm = 1.8367e-01, time/batch = 15.6035s	
17091/28500 (epoch 29.984), train_loss = 0.97177273, grad/param norm = 1.6619e-01, time/batch = 15.8008s	
17092/28500 (epoch 29.986), train_loss = 1.16436819, grad/param norm = 2.0429e-01, time/batch = 15.4599s	
17093/28500 (epoch 29.988), train_loss = 0.80164055, grad/param norm = 1.6883e-01, time/batch = 15.3966s	
17094/28500 (epoch 29.989), train_loss = 0.93806644, grad/param norm = 1.8095e-01, time/batch = 15.3185s	
17095/28500 (epoch 29.991), train_loss = 0.82077373, grad/param norm = 1.7699e-01, time/batch = 15.2329s	
17096/28500 (epoch 29.993), train_loss = 0.84435448, grad/param norm = 1.8239e-01, time/batch = 15.3592s	
17097/28500 (epoch 29.995), train_loss = 0.84874237, grad/param norm = 1.7714e-01, time/batch = 15.4204s	
17098/28500 (epoch 29.996), train_loss = 0.80790721, grad/param norm = 1.8820e-01, time/batch = 15.3088s	
17099/28500 (epoch 29.998), train_loss = 0.99059099, grad/param norm = 2.0297e-01, time/batch = 15.3782s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
17100/28500 (epoch 30.000), train_loss = 0.89538205, grad/param norm = 1.8750e-01, time/batch = 15.2624s	
17101/28500 (epoch 30.002), train_loss = 1.06799960, grad/param norm = 1.9377e-01, time/batch = 15.3849s	
17102/28500 (epoch 30.004), train_loss = 0.86251516, grad/param norm = 1.6366e-01, time/batch = 15.5739s	
17103/28500 (epoch 30.005), train_loss = 1.01117678, grad/param norm = 1.9987e-01, time/batch = 15.3820s	
17104/28500 (epoch 30.007), train_loss = 0.80253717, grad/param norm = 1.4470e-01, time/batch = 15.5237s	
17105/28500 (epoch 30.009), train_loss = 0.93728936, grad/param norm = 2.0035e-01, time/batch = 15.4283s	
17106/28500 (epoch 30.011), train_loss = 0.84235098, grad/param norm = 1.8350e-01, time/batch = 15.3840s	
17107/28500 (epoch 30.012), train_loss = 0.79787541, grad/param norm = 1.5841e-01, time/batch = 15.3699s	
17108/28500 (epoch 30.014), train_loss = 0.82114007, grad/param norm = 1.9218e-01, time/batch = 15.3032s	
17109/28500 (epoch 30.016), train_loss = 0.85800829, grad/param norm = 1.9454e-01, time/batch = 15.5453s	
17110/28500 (epoch 30.018), train_loss = 0.93553719, grad/param norm = 1.8178e-01, time/batch = 15.5454s	
17111/28500 (epoch 30.019), train_loss = 0.98601290, grad/param norm = 1.7295e-01, time/batch = 15.6975s	
17112/28500 (epoch 30.021), train_loss = 0.99877687, grad/param norm = 1.6983e-01, time/batch = 15.6211s	
17113/28500 (epoch 30.023), train_loss = 0.92064977, grad/param norm = 1.8105e-01, time/batch = 15.4234s	
17114/28500 (epoch 30.025), train_loss = 0.92919272, grad/param norm = 1.7629e-01, time/batch = 15.1406s	
17115/28500 (epoch 30.026), train_loss = 0.87805046, grad/param norm = 1.6424e-01, time/batch = 15.5049s	
17116/28500 (epoch 30.028), train_loss = 0.92210826, grad/param norm = 2.1276e-01, time/batch = 15.5684s	
17117/28500 (epoch 30.030), train_loss = 0.97869935, grad/param norm = 2.0371e-01, time/batch = 15.3041s	
17118/28500 (epoch 30.032), train_loss = 1.00013960, grad/param norm = 1.8618e-01, time/batch = 15.5729s	
17119/28500 (epoch 30.033), train_loss = 1.05578912, grad/param norm = 1.9659e-01, time/batch = 15.3830s	
17120/28500 (epoch 30.035), train_loss = 0.88339919, grad/param norm = 1.8998e-01, time/batch = 15.4960s	
17121/28500 (epoch 30.037), train_loss = 0.95721859, grad/param norm = 1.7467e-01, time/batch = 15.3989s	
17122/28500 (epoch 30.039), train_loss = 1.00158656, grad/param norm = 1.8360e-01, time/batch = 15.3178s	
17123/28500 (epoch 30.040), train_loss = 1.01989594, grad/param norm = 1.9191e-01, time/batch = 15.3638s	
17124/28500 (epoch 30.042), train_loss = 0.98586587, grad/param norm = 1.9864e-01, time/batch = 15.5439s	
17125/28500 (epoch 30.044), train_loss = 0.92861351, grad/param norm = 1.9711e-01, time/batch = 15.4814s	
17126/28500 (epoch 30.046), train_loss = 1.12327695, grad/param norm = 1.9528e-01, time/batch = 15.2006s	
17127/28500 (epoch 30.047), train_loss = 1.05910231, grad/param norm = 2.0871e-01, time/batch = 15.1284s	
17128/28500 (epoch 30.049), train_loss = 0.91401240, grad/param norm = 1.7070e-01, time/batch = 15.1895s	
17129/28500 (epoch 30.051), train_loss = 0.91159804, grad/param norm = 1.9104e-01, time/batch = 15.4044s	
17130/28500 (epoch 30.053), train_loss = 0.90877468, grad/param norm = 1.9742e-01, time/batch = 15.2159s	
17131/28500 (epoch 30.054), train_loss = 0.99582731, grad/param norm = 1.8384e-01, time/batch = 15.4636s	
17132/28500 (epoch 30.056), train_loss = 0.83024308, grad/param norm = 1.5935e-01, time/batch = 15.5069s	
17133/28500 (epoch 30.058), train_loss = 0.83298725, grad/param norm = 1.5393e-01, time/batch = 15.0618s	
17134/28500 (epoch 30.060), train_loss = 0.95724576, grad/param norm = 1.8090e-01, time/batch = 15.1493s	
17135/28500 (epoch 30.061), train_loss = 0.89602662, grad/param norm = 1.7145e-01, time/batch = 15.3527s	
17136/28500 (epoch 30.063), train_loss = 0.99511464, grad/param norm = 2.0014e-01, time/batch = 14.9898s	
17137/28500 (epoch 30.065), train_loss = 0.94279370, grad/param norm = 1.7235e-01, time/batch = 15.2240s	
17138/28500 (epoch 30.067), train_loss = 0.87525416, grad/param norm = 1.6554e-01, time/batch = 15.3043s	
17139/28500 (epoch 30.068), train_loss = 0.89024510, grad/param norm = 1.6377e-01, time/batch = 15.4450s	
17140/28500 (epoch 30.070), train_loss = 0.96191470, grad/param norm = 1.8144e-01, time/batch = 15.3727s	
17141/28500 (epoch 30.072), train_loss = 1.05684156, grad/param norm = 2.0722e-01, time/batch = 15.4645s	
17142/28500 (epoch 30.074), train_loss = 0.91355173, grad/param norm = 1.7675e-01, time/batch = 15.5676s	
17143/28500 (epoch 30.075), train_loss = 0.89133822, grad/param norm = 1.6848e-01, time/batch = 15.4598s	
17144/28500 (epoch 30.077), train_loss = 0.95275856, grad/param norm = 1.6478e-01, time/batch = 15.4448s	
17145/28500 (epoch 30.079), train_loss = 0.92051752, grad/param norm = 1.6968e-01, time/batch = 15.3589s	
17146/28500 (epoch 30.081), train_loss = 1.03440530, grad/param norm = 2.0971e-01, time/batch = 15.3096s	
17147/28500 (epoch 30.082), train_loss = 0.94605451, grad/param norm = 2.2369e-01, time/batch = 15.3659s	
17148/28500 (epoch 30.084), train_loss = 0.95787422, grad/param norm = 1.9005e-01, time/batch = 15.2948s	
17149/28500 (epoch 30.086), train_loss = 0.89294830, grad/param norm = 1.7363e-01, time/batch = 15.6207s	
17150/28500 (epoch 30.088), train_loss = 0.81296895, grad/param norm = 1.6314e-01, time/batch = 15.4571s	
17151/28500 (epoch 30.089), train_loss = 1.00600960, grad/param norm = 1.8238e-01, time/batch = 15.6901s	
17152/28500 (epoch 30.091), train_loss = 0.79971696, grad/param norm = 1.6695e-01, time/batch = 15.5566s	
17153/28500 (epoch 30.093), train_loss = 0.98280036, grad/param norm = 1.6784e-01, time/batch = 15.4810s	
17154/28500 (epoch 30.095), train_loss = 0.90765052, grad/param norm = 1.6089e-01, time/batch = 15.6340s	
17155/28500 (epoch 30.096), train_loss = 1.00006184, grad/param norm = 1.8070e-01, time/batch = 15.4963s	
17156/28500 (epoch 30.098), train_loss = 0.94083083, grad/param norm = 1.9865e-01, time/batch = 15.3638s	
17157/28500 (epoch 30.100), train_loss = 0.88052575, grad/param norm = 1.7899e-01, time/batch = 15.3037s	
17158/28500 (epoch 30.102), train_loss = 0.98869880, grad/param norm = 2.0200e-01, time/batch = 15.1258s	
17159/28500 (epoch 30.104), train_loss = 0.90930195, grad/param norm = 1.7648e-01, time/batch = 15.3860s	
17160/28500 (epoch 30.105), train_loss = 1.04804896, grad/param norm = 1.7268e-01, time/batch = 15.2954s	
17161/28500 (epoch 30.107), train_loss = 0.82953098, grad/param norm = 1.6247e-01, time/batch = 15.6358s	
17162/28500 (epoch 30.109), train_loss = 0.83543590, grad/param norm = 1.9422e-01, time/batch = 15.5235s	
17163/28500 (epoch 30.111), train_loss = 0.88224510, grad/param norm = 1.9688e-01, time/batch = 15.4855s	
17164/28500 (epoch 30.112), train_loss = 0.99123715, grad/param norm = 1.7586e-01, time/batch = 15.3151s	
17165/28500 (epoch 30.114), train_loss = 0.88934487, grad/param norm = 1.6668e-01, time/batch = 15.3923s	
17166/28500 (epoch 30.116), train_loss = 1.06193508, grad/param norm = 1.9035e-01, time/batch = 15.1198s	
17167/28500 (epoch 30.118), train_loss = 0.80325282, grad/param norm = 1.5614e-01, time/batch = 15.0513s	
17168/28500 (epoch 30.119), train_loss = 0.95050923, grad/param norm = 1.9500e-01, time/batch = 15.1843s	
17169/28500 (epoch 30.121), train_loss = 1.08425540, grad/param norm = 2.0609e-01, time/batch = 15.2523s	
17170/28500 (epoch 30.123), train_loss = 1.01081774, grad/param norm = 1.9518e-01, time/batch = 15.2817s	
17171/28500 (epoch 30.125), train_loss = 0.93311628, grad/param norm = 1.7252e-01, time/batch = 14.9943s	
17172/28500 (epoch 30.126), train_loss = 0.92271701, grad/param norm = 1.7834e-01, time/batch = 15.1425s	
17173/28500 (epoch 30.128), train_loss = 0.93396263, grad/param norm = 1.7643e-01, time/batch = 15.2425s	
17174/28500 (epoch 30.130), train_loss = 0.86527923, grad/param norm = 2.1277e-01, time/batch = 27.5903s	
17175/28500 (epoch 30.132), train_loss = 0.93040487, grad/param norm = 1.9811e-01, time/batch = 15.3030s	
17176/28500 (epoch 30.133), train_loss = 0.98603953, grad/param norm = 1.9256e-01, time/batch = 15.2486s	
17177/28500 (epoch 30.135), train_loss = 0.87442425, grad/param norm = 1.6948e-01, time/batch = 15.4582s	
17178/28500 (epoch 30.137), train_loss = 0.93374006, grad/param norm = 1.7536e-01, time/batch = 15.1384s	
17179/28500 (epoch 30.139), train_loss = 0.91663143, grad/param norm = 1.6688e-01, time/batch = 15.1808s	
17180/28500 (epoch 30.140), train_loss = 0.91881487, grad/param norm = 1.6582e-01, time/batch = 15.3634s	
17181/28500 (epoch 30.142), train_loss = 0.87849097, grad/param norm = 1.8605e-01, time/batch = 15.7228s	
17182/28500 (epoch 30.144), train_loss = 0.84351530, grad/param norm = 1.6634e-01, time/batch = 15.5411s	
17183/28500 (epoch 30.146), train_loss = 0.88873901, grad/param norm = 1.6446e-01, time/batch = 15.5699s	
17184/28500 (epoch 30.147), train_loss = 0.78410916, grad/param norm = 1.5861e-01, time/batch = 15.5376s	
17185/28500 (epoch 30.149), train_loss = 0.79763652, grad/param norm = 1.6221e-01, time/batch = 15.3920s	
17186/28500 (epoch 30.151), train_loss = 0.88999286, grad/param norm = 1.7132e-01, time/batch = 15.3738s	
17187/28500 (epoch 30.153), train_loss = 0.93761046, grad/param norm = 1.7459e-01, time/batch = 15.3141s	
17188/28500 (epoch 30.154), train_loss = 0.79501149, grad/param norm = 1.5613e-01, time/batch = 15.3701s	
17189/28500 (epoch 30.156), train_loss = 1.00042263, grad/param norm = 1.8617e-01, time/batch = 15.2949s	
17190/28500 (epoch 30.158), train_loss = 0.91103352, grad/param norm = 1.5520e-01, time/batch = 15.5325s	
17191/28500 (epoch 30.160), train_loss = 0.81936263, grad/param norm = 1.6043e-01, time/batch = 15.0787s	
17192/28500 (epoch 30.161), train_loss = 0.84918363, grad/param norm = 1.8008e-01, time/batch = 15.2978s	
17193/28500 (epoch 30.163), train_loss = 0.78361790, grad/param norm = 1.6704e-01, time/batch = 15.5388s	
17194/28500 (epoch 30.165), train_loss = 1.08537675, grad/param norm = 1.7663e-01, time/batch = 15.5450s	
17195/28500 (epoch 30.167), train_loss = 1.09263743, grad/param norm = 2.0057e-01, time/batch = 15.3397s	
17196/28500 (epoch 30.168), train_loss = 1.02472322, grad/param norm = 1.7822e-01, time/batch = 15.1161s	
17197/28500 (epoch 30.170), train_loss = 0.99339766, grad/param norm = 1.9314e-01, time/batch = 15.0466s	
17198/28500 (epoch 30.172), train_loss = 0.92075497, grad/param norm = 1.6414e-01, time/batch = 15.4698s	
17199/28500 (epoch 30.174), train_loss = 1.07955601, grad/param norm = 2.0391e-01, time/batch = 15.4557s	
17200/28500 (epoch 30.175), train_loss = 0.88801978, grad/param norm = 1.6389e-01, time/batch = 15.2978s	
17201/28500 (epoch 30.177), train_loss = 0.96791713, grad/param norm = 1.7961e-01, time/batch = 15.7109s	
17202/28500 (epoch 30.179), train_loss = 0.98887204, grad/param norm = 1.8757e-01, time/batch = 15.6353s	
17203/28500 (epoch 30.181), train_loss = 0.96993328, grad/param norm = 1.9331e-01, time/batch = 15.5604s	
17204/28500 (epoch 30.182), train_loss = 0.88963681, grad/param norm = 1.6452e-01, time/batch = 15.2893s	
17205/28500 (epoch 30.184), train_loss = 1.07510877, grad/param norm = 1.9391e-01, time/batch = 15.4449s	
17206/28500 (epoch 30.186), train_loss = 1.04166447, grad/param norm = 1.8351e-01, time/batch = 15.3712s	
17207/28500 (epoch 30.188), train_loss = 0.96010267, grad/param norm = 1.7527e-01, time/batch = 15.3752s	
17208/28500 (epoch 30.189), train_loss = 0.93313990, grad/param norm = 1.7809e-01, time/batch = 15.3897s	
17209/28500 (epoch 30.191), train_loss = 1.12915601, grad/param norm = 1.8934e-01, time/batch = 15.2971s	
17210/28500 (epoch 30.193), train_loss = 0.95017433, grad/param norm = 1.9828e-01, time/batch = 15.2783s	
17211/28500 (epoch 30.195), train_loss = 1.07239755, grad/param norm = 1.8967e-01, time/batch = 15.3365s	
17212/28500 (epoch 30.196), train_loss = 0.97973222, grad/param norm = 1.7454e-01, time/batch = 15.5432s	
17213/28500 (epoch 30.198), train_loss = 0.95686030, grad/param norm = 1.8973e-01, time/batch = 15.4613s	
17214/28500 (epoch 30.200), train_loss = 0.99009902, grad/param norm = 1.6968e-01, time/batch = 15.3051s	
17215/28500 (epoch 30.202), train_loss = 0.95689327, grad/param norm = 1.6270e-01, time/batch = 15.5603s	
17216/28500 (epoch 30.204), train_loss = 0.90768423, grad/param norm = 1.5555e-01, time/batch = 15.5163s	
17217/28500 (epoch 30.205), train_loss = 0.89089333, grad/param norm = 1.7683e-01, time/batch = 15.3812s	
17218/28500 (epoch 30.207), train_loss = 0.82353135, grad/param norm = 1.7457e-01, time/batch = 15.3165s	
17219/28500 (epoch 30.209), train_loss = 0.95486745, grad/param norm = 1.6895e-01, time/batch = 15.1970s	
17220/28500 (epoch 30.211), train_loss = 0.82813564, grad/param norm = 1.7610e-01, time/batch = 15.2858s	
17221/28500 (epoch 30.212), train_loss = 0.78614933, grad/param norm = 1.6677e-01, time/batch = 15.3352s	
17222/28500 (epoch 30.214), train_loss = 0.91796693, grad/param norm = 1.9181e-01, time/batch = 15.5491s	
17223/28500 (epoch 30.216), train_loss = 0.85701328, grad/param norm = 1.7783e-01, time/batch = 15.5473s	
17224/28500 (epoch 30.218), train_loss = 1.00258063, grad/param norm = 1.6318e-01, time/batch = 15.2740s	
17225/28500 (epoch 30.219), train_loss = 0.95225219, grad/param norm = 1.8090e-01, time/batch = 15.2911s	
17226/28500 (epoch 30.221), train_loss = 0.79377248, grad/param norm = 1.6600e-01, time/batch = 15.1077s	
17227/28500 (epoch 30.223), train_loss = 1.04088596, grad/param norm = 2.0721e-01, time/batch = 15.0825s	
17228/28500 (epoch 30.225), train_loss = 1.06915778, grad/param norm = 1.9421e-01, time/batch = 15.1797s	
17229/28500 (epoch 30.226), train_loss = 0.88632385, grad/param norm = 1.6018e-01, time/batch = 15.2806s	
17230/28500 (epoch 30.228), train_loss = 1.00426143, grad/param norm = 1.6116e-01, time/batch = 15.3016s	
17231/28500 (epoch 30.230), train_loss = 0.99936761, grad/param norm = 2.0433e-01, time/batch = 15.7068s	
17232/28500 (epoch 30.232), train_loss = 0.96526455, grad/param norm = 2.3667e-01, time/batch = 15.4586s	
17233/28500 (epoch 30.233), train_loss = 0.93603014, grad/param norm = 1.7272e-01, time/batch = 15.3832s	
17234/28500 (epoch 30.235), train_loss = 0.92189260, grad/param norm = 1.8043e-01, time/batch = 15.3419s	
17235/28500 (epoch 30.237), train_loss = 0.83177748, grad/param norm = 1.5033e-01, time/batch = 15.6428s	
17236/28500 (epoch 30.239), train_loss = 0.86579091, grad/param norm = 1.5444e-01, time/batch = 15.5258s	
17237/28500 (epoch 30.240), train_loss = 0.81090868, grad/param norm = 1.6318e-01, time/batch = 15.5194s	
17238/28500 (epoch 30.242), train_loss = 0.89767944, grad/param norm = 1.7462e-01, time/batch = 15.4229s	
17239/28500 (epoch 30.244), train_loss = 0.96610078, grad/param norm = 1.5348e-01, time/batch = 15.3451s	
17240/28500 (epoch 30.246), train_loss = 0.98579833, grad/param norm = 1.7108e-01, time/batch = 15.3494s	
17241/28500 (epoch 30.247), train_loss = 1.05669715, grad/param norm = 2.0369e-01, time/batch = 15.5533s	
17242/28500 (epoch 30.249), train_loss = 0.91047082, grad/param norm = 1.6995e-01, time/batch = 15.5406s	
17243/28500 (epoch 30.251), train_loss = 0.88681830, grad/param norm = 1.5820e-01, time/batch = 15.5253s	
17244/28500 (epoch 30.253), train_loss = 1.04879236, grad/param norm = 2.2196e-01, time/batch = 15.4570s	
17245/28500 (epoch 30.254), train_loss = 1.06324336, grad/param norm = 1.6882e-01, time/batch = 15.4598s	
17246/28500 (epoch 30.256), train_loss = 0.89795757, grad/param norm = 1.8178e-01, time/batch = 15.3679s	
17247/28500 (epoch 30.258), train_loss = 0.92023507, grad/param norm = 1.8315e-01, time/batch = 15.5867s	
17248/28500 (epoch 30.260), train_loss = 0.91629070, grad/param norm = 1.8125e-01, time/batch = 15.4862s	
17249/28500 (epoch 30.261), train_loss = 0.83792603, grad/param norm = 1.7255e-01, time/batch = 15.4601s	
17250/28500 (epoch 30.263), train_loss = 0.99568830, grad/param norm = 1.9307e-01, time/batch = 15.6000s	
17251/28500 (epoch 30.265), train_loss = 0.90693388, grad/param norm = 1.7597e-01, time/batch = 15.7009s	
17252/28500 (epoch 30.267), train_loss = 1.04698589, grad/param norm = 1.9721e-01, time/batch = 15.5530s	
17253/28500 (epoch 30.268), train_loss = 0.97694020, grad/param norm = 1.6926e-01, time/batch = 15.5479s	
17254/28500 (epoch 30.270), train_loss = 0.96456054, grad/param norm = 1.9656e-01, time/batch = 15.4648s	
17255/28500 (epoch 30.272), train_loss = 0.94250819, grad/param norm = 1.9666e-01, time/batch = 15.3493s	
17256/28500 (epoch 30.274), train_loss = 1.00312339, grad/param norm = 1.9361e-01, time/batch = 15.4247s	
17257/28500 (epoch 30.275), train_loss = 0.96990724, grad/param norm = 1.6441e-01, time/batch = 15.4310s	
17258/28500 (epoch 30.277), train_loss = 0.91588675, grad/param norm = 1.6987e-01, time/batch = 15.2033s	
17259/28500 (epoch 30.279), train_loss = 0.92747629, grad/param norm = 1.7952e-01, time/batch = 15.2148s	
17260/28500 (epoch 30.281), train_loss = 0.99135277, grad/param norm = 2.0759e-01, time/batch = 15.2726s	
17261/28500 (epoch 30.282), train_loss = 0.88842127, grad/param norm = 1.6036e-01, time/batch = 15.5756s	
17262/28500 (epoch 30.284), train_loss = 0.95427237, grad/param norm = 2.0436e-01, time/batch = 15.4332s	
17263/28500 (epoch 30.286), train_loss = 1.05969818, grad/param norm = 1.7284e-01, time/batch = 15.3707s	
17264/28500 (epoch 30.288), train_loss = 0.92853999, grad/param norm = 1.7940e-01, time/batch = 15.3926s	
17265/28500 (epoch 30.289), train_loss = 0.94889993, grad/param norm = 1.8378e-01, time/batch = 15.3668s	
17266/28500 (epoch 30.291), train_loss = 0.94493884, grad/param norm = 1.7194e-01, time/batch = 15.0461s	
17267/28500 (epoch 30.293), train_loss = 0.90676649, grad/param norm = 1.6563e-01, time/batch = 15.4643s	
17268/28500 (epoch 30.295), train_loss = 0.83725113, grad/param norm = 1.7116e-01, time/batch = 15.3894s	
17269/28500 (epoch 30.296), train_loss = 0.80038753, grad/param norm = 1.5355e-01, time/batch = 15.5381s	
17270/28500 (epoch 30.298), train_loss = 0.96796878, grad/param norm = 1.5649e-01, time/batch = 15.2818s	
17271/28500 (epoch 30.300), train_loss = 0.85718091, grad/param norm = 1.7352e-01, time/batch = 15.1418s	
17272/28500 (epoch 30.302), train_loss = 0.82197361, grad/param norm = 1.6779e-01, time/batch = 15.0589s	
17273/28500 (epoch 30.304), train_loss = 0.89228141, grad/param norm = 1.6124e-01, time/batch = 15.0182s	
17274/28500 (epoch 30.305), train_loss = 0.95869034, grad/param norm = 1.6653e-01, time/batch = 15.3256s	
17275/28500 (epoch 30.307), train_loss = 0.91576780, grad/param norm = 1.7321e-01, time/batch = 15.2464s	
17276/28500 (epoch 30.309), train_loss = 0.90474625, grad/param norm = 1.6973e-01, time/batch = 14.9842s	
17277/28500 (epoch 30.311), train_loss = 0.97168367, grad/param norm = 1.6231e-01, time/batch = 15.1143s	
17278/28500 (epoch 30.312), train_loss = 0.95739484, grad/param norm = 1.6037e-01, time/batch = 15.1769s	
17279/28500 (epoch 30.314), train_loss = 0.97478100, grad/param norm = 2.0234e-01, time/batch = 14.9830s	
17280/28500 (epoch 30.316), train_loss = 0.92589455, grad/param norm = 1.8246e-01, time/batch = 15.2092s	
17281/28500 (epoch 30.318), train_loss = 1.01364627, grad/param norm = 1.7677e-01, time/batch = 14.9112s	
17282/28500 (epoch 30.319), train_loss = 0.89682760, grad/param norm = 1.8738e-01, time/batch = 15.2148s	
17283/28500 (epoch 30.321), train_loss = 0.91273549, grad/param norm = 1.9127e-01, time/batch = 15.3852s	
17284/28500 (epoch 30.323), train_loss = 0.88066637, grad/param norm = 1.8010e-01, time/batch = 15.6236s	
17285/28500 (epoch 30.325), train_loss = 1.04463859, grad/param norm = 1.8034e-01, time/batch = 15.5121s	
17286/28500 (epoch 30.326), train_loss = 0.95264055, grad/param norm = 1.7119e-01, time/batch = 15.3647s	
17287/28500 (epoch 30.328), train_loss = 0.76642642, grad/param norm = 1.7187e-01, time/batch = 15.3676s	
17288/28500 (epoch 30.330), train_loss = 0.85666705, grad/param norm = 1.6517e-01, time/batch = 15.6459s	
17289/28500 (epoch 30.332), train_loss = 0.91052299, grad/param norm = 1.6785e-01, time/batch = 15.5618s	
17290/28500 (epoch 30.333), train_loss = 0.74181128, grad/param norm = 1.7930e-01, time/batch = 15.5348s	
17291/28500 (epoch 30.335), train_loss = 0.82073134, grad/param norm = 1.6811e-01, time/batch = 15.5539s	
17292/28500 (epoch 30.337), train_loss = 0.78151354, grad/param norm = 1.6535e-01, time/batch = 15.3109s	
17293/28500 (epoch 30.339), train_loss = 0.76622464, grad/param norm = 1.4734e-01, time/batch = 15.2984s	
17294/28500 (epoch 30.340), train_loss = 0.91621354, grad/param norm = 2.5027e-01, time/batch = 15.5280s	
17295/28500 (epoch 30.342), train_loss = 0.91013272, grad/param norm = 1.7399e-01, time/batch = 15.5656s	
17296/28500 (epoch 30.344), train_loss = 0.83371600, grad/param norm = 1.7726e-01, time/batch = 15.4940s	
17297/28500 (epoch 30.346), train_loss = 0.76876624, grad/param norm = 1.6058e-01, time/batch = 15.5218s	
17298/28500 (epoch 30.347), train_loss = 0.91449317, grad/param norm = 1.6760e-01, time/batch = 15.5298s	
17299/28500 (epoch 30.349), train_loss = 0.89858877, grad/param norm = 1.6162e-01, time/batch = 15.2940s	
17300/28500 (epoch 30.351), train_loss = 0.81896626, grad/param norm = 1.6624e-01, time/batch = 15.3800s	
17301/28500 (epoch 30.353), train_loss = 0.91234567, grad/param norm = 1.9012e-01, time/batch = 15.3364s	
17302/28500 (epoch 30.354), train_loss = 0.82392563, grad/param norm = 1.7367e-01, time/batch = 15.2024s	
17303/28500 (epoch 30.356), train_loss = 0.84623640, grad/param norm = 1.5732e-01, time/batch = 15.1485s	
17304/28500 (epoch 30.358), train_loss = 0.96143817, grad/param norm = 1.7195e-01, time/batch = 15.1295s	
17305/28500 (epoch 30.360), train_loss = 0.92887075, grad/param norm = 1.8157e-01, time/batch = 15.5130s	
17306/28500 (epoch 30.361), train_loss = 0.83446052, grad/param norm = 1.7170e-01, time/batch = 15.4532s	
17307/28500 (epoch 30.363), train_loss = 0.82985236, grad/param norm = 1.5504e-01, time/batch = 15.5280s	
17308/28500 (epoch 30.365), train_loss = 0.86984167, grad/param norm = 1.6397e-01, time/batch = 15.3061s	
17309/28500 (epoch 30.367), train_loss = 0.92842701, grad/param norm = 1.6317e-01, time/batch = 15.3393s	
17310/28500 (epoch 30.368), train_loss = 0.85245605, grad/param norm = 1.5996e-01, time/batch = 15.0709s	
17311/28500 (epoch 30.370), train_loss = 0.90945065, grad/param norm = 1.6324e-01, time/batch = 15.3431s	
17312/28500 (epoch 30.372), train_loss = 0.74272996, grad/param norm = 1.5803e-01, time/batch = 15.0492s	
17313/28500 (epoch 30.374), train_loss = 0.86013067, grad/param norm = 1.5587e-01, time/batch = 15.2960s	
17314/28500 (epoch 30.375), train_loss = 0.97783844, grad/param norm = 1.7259e-01, time/batch = 15.3164s	
17315/28500 (epoch 30.377), train_loss = 0.79335010, grad/param norm = 1.9889e-01, time/batch = 15.2499s	
17316/28500 (epoch 30.379), train_loss = 0.70943771, grad/param norm = 1.5648e-01, time/batch = 15.1331s	
17317/28500 (epoch 30.381), train_loss = 0.88052094, grad/param norm = 1.6627e-01, time/batch = 15.1873s	
17318/28500 (epoch 30.382), train_loss = 0.85302089, grad/param norm = 1.8748e-01, time/batch = 15.3015s	
17319/28500 (epoch 30.384), train_loss = 0.76406665, grad/param norm = 1.5606e-01, time/batch = 15.3873s	
17320/28500 (epoch 30.386), train_loss = 0.81480312, grad/param norm = 1.5329e-01, time/batch = 15.0614s	
17321/28500 (epoch 30.388), train_loss = 1.00317234, grad/param norm = 1.9151e-01, time/batch = 15.5578s	
17322/28500 (epoch 30.389), train_loss = 0.84577071, grad/param norm = 1.8048e-01, time/batch = 15.4645s	
17323/28500 (epoch 30.391), train_loss = 0.78794816, grad/param norm = 1.7549e-01, time/batch = 15.1451s	
17324/28500 (epoch 30.393), train_loss = 0.81446473, grad/param norm = 1.7192e-01, time/batch = 15.1963s	
17325/28500 (epoch 30.395), train_loss = 0.99879002, grad/param norm = 1.5895e-01, time/batch = 15.0993s	
17326/28500 (epoch 30.396), train_loss = 0.97630211, grad/param norm = 1.7781e-01, time/batch = 15.2945s	
17327/28500 (epoch 30.398), train_loss = 0.69306088, grad/param norm = 1.7396e-01, time/batch = 15.3638s	
17328/28500 (epoch 30.400), train_loss = 0.87915863, grad/param norm = 1.7905e-01, time/batch = 15.2378s	
17329/28500 (epoch 30.402), train_loss = 0.90436606, grad/param norm = 1.9480e-01, time/batch = 15.1574s	
17330/28500 (epoch 30.404), train_loss = 0.93694922, grad/param norm = 2.0784e-01, time/batch = 15.5391s	
17331/28500 (epoch 30.405), train_loss = 0.94899006, grad/param norm = 1.6790e-01, time/batch = 15.1401s	
17332/28500 (epoch 30.407), train_loss = 0.92437397, grad/param norm = 1.6377e-01, time/batch = 15.1373s	
17333/28500 (epoch 30.409), train_loss = 0.92807569, grad/param norm = 1.7051e-01, time/batch = 14.9790s	
17334/28500 (epoch 30.411), train_loss = 1.00602157, grad/param norm = 1.9783e-01, time/batch = 15.1581s	
17335/28500 (epoch 30.412), train_loss = 1.03536945, grad/param norm = 2.0240e-01, time/batch = 15.3073s	
17336/28500 (epoch 30.414), train_loss = 0.93666815, grad/param norm = 1.7965e-01, time/batch = 15.3664s	
17337/28500 (epoch 30.416), train_loss = 0.83093219, grad/param norm = 1.9028e-01, time/batch = 15.2872s	
17338/28500 (epoch 30.418), train_loss = 0.92422957, grad/param norm = 1.5783e-01, time/batch = 15.3624s	
17339/28500 (epoch 30.419), train_loss = 1.02227404, grad/param norm = 1.9164e-01, time/batch = 15.4568s	
17340/28500 (epoch 30.421), train_loss = 0.98272541, grad/param norm = 1.7922e-01, time/batch = 15.3032s	
17341/28500 (epoch 30.423), train_loss = 0.99513633, grad/param norm = 1.8922e-01, time/batch = 15.4387s	
17342/28500 (epoch 30.425), train_loss = 0.92936410, grad/param norm = 2.1042e-01, time/batch = 15.1974s	
17343/28500 (epoch 30.426), train_loss = 0.91175466, grad/param norm = 1.9127e-01, time/batch = 15.0690s	
17344/28500 (epoch 30.428), train_loss = 1.04859097, grad/param norm = 1.8460e-01, time/batch = 15.2919s	
17345/28500 (epoch 30.430), train_loss = 1.04090930, grad/param norm = 1.8247e-01, time/batch = 15.1955s	
17346/28500 (epoch 30.432), train_loss = 0.91375002, grad/param norm = 1.9729e-01, time/batch = 15.1321s	
17347/28500 (epoch 30.433), train_loss = 0.98150667, grad/param norm = 2.0384e-01, time/batch = 15.2003s	
17348/28500 (epoch 30.435), train_loss = 0.95749433, grad/param norm = 1.9106e-01, time/batch = 15.3836s	
17349/28500 (epoch 30.437), train_loss = 0.85245901, grad/param norm = 1.5993e-01, time/batch = 15.2748s	
17350/28500 (epoch 30.439), train_loss = 0.87891647, grad/param norm = 1.5443e-01, time/batch = 15.3693s	
17351/28500 (epoch 30.440), train_loss = 1.05807141, grad/param norm = 1.7425e-01, time/batch = 15.3872s	
17352/28500 (epoch 30.442), train_loss = 0.85648977, grad/param norm = 1.8803e-01, time/batch = 15.3074s	
17353/28500 (epoch 30.444), train_loss = 0.80915030, grad/param norm = 1.4306e-01, time/batch = 15.4751s	
17354/28500 (epoch 30.446), train_loss = 0.76570079, grad/param norm = 1.5579e-01, time/batch = 15.5285s	
17355/28500 (epoch 30.447), train_loss = 0.79909345, grad/param norm = 1.6718e-01, time/batch = 15.4885s	
17356/28500 (epoch 30.449), train_loss = 0.86670625, grad/param norm = 1.5556e-01, time/batch = 15.2056s	
17357/28500 (epoch 30.451), train_loss = 0.89362454, grad/param norm = 1.6447e-01, time/batch = 15.0354s	
17358/28500 (epoch 30.453), train_loss = 0.87950533, grad/param norm = 1.7747e-01, time/batch = 15.0566s	
17359/28500 (epoch 30.454), train_loss = 0.84238648, grad/param norm = 1.6216e-01, time/batch = 15.1173s	
17360/28500 (epoch 30.456), train_loss = 0.96702687, grad/param norm = 1.8953e-01, time/batch = 15.1671s	
17361/28500 (epoch 30.458), train_loss = 0.87915786, grad/param norm = 1.6659e-01, time/batch = 15.3208s	
17362/28500 (epoch 30.460), train_loss = 0.96961328, grad/param norm = 1.6127e-01, time/batch = 15.5465s	
17363/28500 (epoch 30.461), train_loss = 0.82059178, grad/param norm = 1.8152e-01, time/batch = 15.5312s	
17364/28500 (epoch 30.463), train_loss = 0.77163541, grad/param norm = 1.4861e-01, time/batch = 15.2863s	
17365/28500 (epoch 30.465), train_loss = 0.77445719, grad/param norm = 1.7992e-01, time/batch = 15.3112s	
17366/28500 (epoch 30.467), train_loss = 0.91101024, grad/param norm = 1.6426e-01, time/batch = 15.3678s	
17367/28500 (epoch 30.468), train_loss = 0.81094044, grad/param norm = 1.5599e-01, time/batch = 15.4405s	
17368/28500 (epoch 30.470), train_loss = 0.86201501, grad/param norm = 1.9323e-01, time/batch = 15.5755s	
17369/28500 (epoch 30.472), train_loss = 0.82686882, grad/param norm = 1.6147e-01, time/batch = 15.4518s	
17370/28500 (epoch 30.474), train_loss = 1.03303224, grad/param norm = 1.8754e-01, time/batch = 15.4003s	
17371/28500 (epoch 30.475), train_loss = 0.84636745, grad/param norm = 1.6523e-01, time/batch = 15.5490s	
17372/28500 (epoch 30.477), train_loss = 0.85946580, grad/param norm = 1.7164e-01, time/batch = 15.2861s	
17373/28500 (epoch 30.479), train_loss = 0.94290744, grad/param norm = 1.7876e-01, time/batch = 15.3122s	
17374/28500 (epoch 30.481), train_loss = 0.96023717, grad/param norm = 2.0070e-01, time/batch = 15.4679s	
17375/28500 (epoch 30.482), train_loss = 0.80346102, grad/param norm = 1.6093e-01, time/batch = 15.4885s	
17376/28500 (epoch 30.484), train_loss = 0.82882384, grad/param norm = 1.7728e-01, time/batch = 15.5464s	
17377/28500 (epoch 30.486), train_loss = 0.73593442, grad/param norm = 1.8421e-01, time/batch = 15.5350s	
17378/28500 (epoch 30.488), train_loss = 0.91496126, grad/param norm = 1.4736e-01, time/batch = 15.2289s	
17379/28500 (epoch 30.489), train_loss = 1.00918798, grad/param norm = 1.7537e-01, time/batch = 15.3649s	
17380/28500 (epoch 30.491), train_loss = 0.84438374, grad/param norm = 1.8275e-01, time/batch = 15.4568s	
17381/28500 (epoch 30.493), train_loss = 0.89197440, grad/param norm = 1.6804e-01, time/batch = 15.5810s	
17382/28500 (epoch 30.495), train_loss = 0.92636510, grad/param norm = 1.8417e-01, time/batch = 15.4478s	
17383/28500 (epoch 30.496), train_loss = 0.82754304, grad/param norm = 1.9092e-01, time/batch = 15.3635s	
17384/28500 (epoch 30.498), train_loss = 0.87334441, grad/param norm = 1.6757e-01, time/batch = 15.3698s	
17385/28500 (epoch 30.500), train_loss = 0.82431285, grad/param norm = 1.5583e-01, time/batch = 15.2325s	
17386/28500 (epoch 30.502), train_loss = 0.94196405, grad/param norm = 1.5104e-01, time/batch = 15.2945s	
17387/28500 (epoch 30.504), train_loss = 0.92428170, grad/param norm = 1.5601e-01, time/batch = 15.5759s	
17388/28500 (epoch 30.505), train_loss = 0.82537475, grad/param norm = 1.5421e-01, time/batch = 15.6239s	
17389/28500 (epoch 30.507), train_loss = 0.98962250, grad/param norm = 1.9470e-01, time/batch = 15.4628s	
17390/28500 (epoch 30.509), train_loss = 0.92199672, grad/param norm = 1.8982e-01, time/batch = 15.3003s	
17391/28500 (epoch 30.511), train_loss = 0.90648037, grad/param norm = 1.8145e-01, time/batch = 15.3286s	
17392/28500 (epoch 30.512), train_loss = 0.94722945, grad/param norm = 1.8090e-01, time/batch = 15.3175s	
17393/28500 (epoch 30.514), train_loss = 0.89197844, grad/param norm = 1.6269e-01, time/batch = 15.6304s	
17394/28500 (epoch 30.516), train_loss = 0.87796410, grad/param norm = 1.5388e-01, time/batch = 15.6040s	
17395/28500 (epoch 30.518), train_loss = 0.92745973, grad/param norm = 1.5717e-01, time/batch = 15.5615s	
17396/28500 (epoch 30.519), train_loss = 0.97554636, grad/param norm = 1.8003e-01, time/batch = 15.0615s	
17397/28500 (epoch 30.521), train_loss = 1.03627606, grad/param norm = 1.9671e-01, time/batch = 15.0426s	
17398/28500 (epoch 30.523), train_loss = 0.97205834, grad/param norm = 2.1057e-01, time/batch = 15.1943s	
17399/28500 (epoch 30.525), train_loss = 1.03576334, grad/param norm = 1.7226e-01, time/batch = 15.3039s	
17400/28500 (epoch 30.526), train_loss = 0.96343075, grad/param norm = 1.6168e-01, time/batch = 15.2081s	
17401/28500 (epoch 30.528), train_loss = 0.94594467, grad/param norm = 1.7925e-01, time/batch = 15.3097s	
17402/28500 (epoch 30.530), train_loss = 0.98077746, grad/param norm = 1.6492e-01, time/batch = 15.3841s	
17403/28500 (epoch 30.532), train_loss = 0.86727404, grad/param norm = 1.5682e-01, time/batch = 15.4685s	
17404/28500 (epoch 30.533), train_loss = 0.96862339, grad/param norm = 1.7071e-01, time/batch = 15.3100s	
17405/28500 (epoch 30.535), train_loss = 0.79133045, grad/param norm = 1.5572e-01, time/batch = 15.2333s	
17406/28500 (epoch 30.537), train_loss = 0.83632789, grad/param norm = 1.6849e-01, time/batch = 24.6990s	
17407/28500 (epoch 30.539), train_loss = 0.76991213, grad/param norm = 1.5897e-01, time/batch = 18.1444s	
17408/28500 (epoch 30.540), train_loss = 0.91222154, grad/param norm = 1.8568e-01, time/batch = 15.4853s	
17409/28500 (epoch 30.542), train_loss = 0.95581990, grad/param norm = 2.5535e-01, time/batch = 15.4033s	
17410/28500 (epoch 30.544), train_loss = 1.04834455, grad/param norm = 2.1248e-01, time/batch = 15.5166s	
17411/28500 (epoch 30.546), train_loss = 0.89460917, grad/param norm = 1.6498e-01, time/batch = 15.6884s	
17412/28500 (epoch 30.547), train_loss = 0.90947617, grad/param norm = 1.6606e-01, time/batch = 15.5368s	
17413/28500 (epoch 30.549), train_loss = 0.74409721, grad/param norm = 1.4710e-01, time/batch = 15.5174s	
17414/28500 (epoch 30.551), train_loss = 0.88321450, grad/param norm = 2.1869e-01, time/batch = 15.4442s	
17415/28500 (epoch 30.553), train_loss = 1.07132855, grad/param norm = 2.4531e-01, time/batch = 15.2770s	
17416/28500 (epoch 30.554), train_loss = 0.98527814, grad/param norm = 2.0195e-01, time/batch = 15.3552s	
17417/28500 (epoch 30.556), train_loss = 0.94943018, grad/param norm = 1.8668e-01, time/batch = 15.5196s	
17418/28500 (epoch 30.558), train_loss = 0.96490318, grad/param norm = 1.8573e-01, time/batch = 15.3568s	
17419/28500 (epoch 30.560), train_loss = 0.96063178, grad/param norm = 1.9259e-01, time/batch = 15.3986s	
17420/28500 (epoch 30.561), train_loss = 0.97203253, grad/param norm = 1.8545e-01, time/batch = 15.2931s	
17421/28500 (epoch 30.563), train_loss = 1.04550715, grad/param norm = 2.7581e-01, time/batch = 15.4693s	
17422/28500 (epoch 30.565), train_loss = 0.84274333, grad/param norm = 1.7677e-01, time/batch = 14.8892s	
17423/28500 (epoch 30.567), train_loss = 0.81342478, grad/param norm = 1.6241e-01, time/batch = 15.0569s	
17424/28500 (epoch 30.568), train_loss = 0.94021859, grad/param norm = 1.8839e-01, time/batch = 15.0373s	
17425/28500 (epoch 30.570), train_loss = 0.88783872, grad/param norm = 1.6835e-01, time/batch = 15.3519s	
17426/28500 (epoch 30.572), train_loss = 0.92847430, grad/param norm = 1.8003e-01, time/batch = 15.2013s	
17427/28500 (epoch 30.574), train_loss = 0.86457628, grad/param norm = 1.7112e-01, time/batch = 15.5030s	
17428/28500 (epoch 30.575), train_loss = 0.86760497, grad/param norm = 1.7327e-01, time/batch = 15.4290s	
17429/28500 (epoch 30.577), train_loss = 0.95100872, grad/param norm = 1.8111e-01, time/batch = 15.4019s	
17430/28500 (epoch 30.579), train_loss = 0.98315183, grad/param norm = 1.8337e-01, time/batch = 15.3775s	
17431/28500 (epoch 30.581), train_loss = 0.83280832, grad/param norm = 1.9833e-01, time/batch = 15.5680s	
17432/28500 (epoch 30.582), train_loss = 0.99716806, grad/param norm = 1.8446e-01, time/batch = 15.6327s	
17433/28500 (epoch 30.584), train_loss = 0.88112242, grad/param norm = 2.1533e-01, time/batch = 15.6073s	
17434/28500 (epoch 30.586), train_loss = 0.83697641, grad/param norm = 1.5449e-01, time/batch = 15.5714s	
17435/28500 (epoch 30.588), train_loss = 0.85337838, grad/param norm = 1.8355e-01, time/batch = 15.4310s	
17436/28500 (epoch 30.589), train_loss = 0.89889095, grad/param norm = 1.8406e-01, time/batch = 15.3656s	
17437/28500 (epoch 30.591), train_loss = 0.92475508, grad/param norm = 1.7029e-01, time/batch = 15.4401s	
17438/28500 (epoch 30.593), train_loss = 0.85728181, grad/param norm = 1.6853e-01, time/batch = 15.3727s	
17439/28500 (epoch 30.595), train_loss = 1.10953947, grad/param norm = 2.0850e-01, time/batch = 15.3168s	
17440/28500 (epoch 30.596), train_loss = 1.05410967, grad/param norm = 1.6110e-01, time/batch = 15.5365s	
17441/28500 (epoch 30.598), train_loss = 0.91327596, grad/param norm = 1.7980e-01, time/batch = 15.7116s	
17442/28500 (epoch 30.600), train_loss = 0.93014023, grad/param norm = 1.9578e-01, time/batch = 15.5522s	
17443/28500 (epoch 30.602), train_loss = 0.97139374, grad/param norm = 1.9813e-01, time/batch = 15.4138s	
17444/28500 (epoch 30.604), train_loss = 0.99438354, grad/param norm = 1.6385e-01, time/batch = 15.5306s	
17445/28500 (epoch 30.605), train_loss = 0.98288795, grad/param norm = 1.9875e-01, time/batch = 15.4446s	
17446/28500 (epoch 30.607), train_loss = 1.01748419, grad/param norm = 1.6041e-01, time/batch = 15.2927s	
17447/28500 (epoch 30.609), train_loss = 0.93882702, grad/param norm = 1.6667e-01, time/batch = 15.2500s	
17448/28500 (epoch 30.611), train_loss = 0.89699542, grad/param norm = 1.8283e-01, time/batch = 15.2706s	
17449/28500 (epoch 30.612), train_loss = 0.97501487, grad/param norm = 2.0344e-01, time/batch = 15.3156s	
17450/28500 (epoch 30.614), train_loss = 0.96198863, grad/param norm = 1.6339e-01, time/batch = 15.5405s	
17451/28500 (epoch 30.616), train_loss = 0.88810297, grad/param norm = 1.8262e-01, time/batch = 15.2946s	
17452/28500 (epoch 30.618), train_loss = 0.89122168, grad/param norm = 1.7937e-01, time/batch = 15.2983s	
17453/28500 (epoch 30.619), train_loss = 0.99185055, grad/param norm = 1.8703e-01, time/batch = 15.2848s	
17454/28500 (epoch 30.621), train_loss = 0.75012667, grad/param norm = 1.5654e-01, time/batch = 15.1851s	
17455/28500 (epoch 30.623), train_loss = 1.01323253, grad/param norm = 1.9887e-01, time/batch = 15.2887s	
17456/28500 (epoch 30.625), train_loss = 0.82748051, grad/param norm = 1.6760e-01, time/batch = 15.5237s	
17457/28500 (epoch 30.626), train_loss = 0.70809545, grad/param norm = 1.5454e-01, time/batch = 15.1352s	
17458/28500 (epoch 30.628), train_loss = 0.84305876, grad/param norm = 1.7323e-01, time/batch = 15.3565s	
17459/28500 (epoch 30.630), train_loss = 0.77893232, grad/param norm = 1.4740e-01, time/batch = 15.3038s	
17460/28500 (epoch 30.632), train_loss = 0.99858081, grad/param norm = 1.9558e-01, time/batch = 15.5243s	
17461/28500 (epoch 30.633), train_loss = 1.06046177, grad/param norm = 1.7020e-01, time/batch = 15.3975s	
17462/28500 (epoch 30.635), train_loss = 0.96354496, grad/param norm = 1.7629e-01, time/batch = 15.2938s	
17463/28500 (epoch 30.637), train_loss = 0.91368475, grad/param norm = 1.5354e-01, time/batch = 15.1945s	
17464/28500 (epoch 30.639), train_loss = 0.83009467, grad/param norm = 1.7743e-01, time/batch = 15.1886s	
17465/28500 (epoch 30.640), train_loss = 0.83647657, grad/param norm = 1.6286e-01, time/batch = 14.9680s	
17466/28500 (epoch 30.642), train_loss = 0.85633010, grad/param norm = 1.6755e-01, time/batch = 15.2737s	
17467/28500 (epoch 30.644), train_loss = 0.96608415, grad/param norm = 1.7243e-01, time/batch = 15.3222s	
17468/28500 (epoch 30.646), train_loss = 0.77494090, grad/param norm = 1.3803e-01, time/batch = 15.2711s	
17469/28500 (epoch 30.647), train_loss = 0.82698834, grad/param norm = 1.5499e-01, time/batch = 15.3205s	
17470/28500 (epoch 30.649), train_loss = 0.80199613, grad/param norm = 1.6696e-01, time/batch = 15.2932s	
17471/28500 (epoch 30.651), train_loss = 0.79433085, grad/param norm = 1.4464e-01, time/batch = 15.5308s	
17472/28500 (epoch 30.653), train_loss = 0.80503133, grad/param norm = 1.6679e-01, time/batch = 15.3094s	
17473/28500 (epoch 30.654), train_loss = 0.84971334, grad/param norm = 1.7755e-01, time/batch = 14.9861s	
17474/28500 (epoch 30.656), train_loss = 0.81823162, grad/param norm = 2.0245e-01, time/batch = 15.1575s	
17475/28500 (epoch 30.658), train_loss = 0.90706313, grad/param norm = 1.7117e-01, time/batch = 15.1971s	
17476/28500 (epoch 30.660), train_loss = 0.91714295, grad/param norm = 1.7059e-01, time/batch = 15.0276s	
17477/28500 (epoch 30.661), train_loss = 1.00554362, grad/param norm = 1.8607e-01, time/batch = 15.0484s	
17478/28500 (epoch 30.663), train_loss = 1.00453721, grad/param norm = 1.8106e-01, time/batch = 14.9755s	
17479/28500 (epoch 30.665), train_loss = 0.89313227, grad/param norm = 1.6412e-01, time/batch = 15.4538s	
17480/28500 (epoch 30.667), train_loss = 0.89604910, grad/param norm = 1.7937e-01, time/batch = 15.4673s	
17481/28500 (epoch 30.668), train_loss = 0.89221027, grad/param norm = 1.6642e-01, time/batch = 15.1453s	
17482/28500 (epoch 30.670), train_loss = 0.91299613, grad/param norm = 1.8919e-01, time/batch = 15.1510s	
17483/28500 (epoch 30.672), train_loss = 0.81451591, grad/param norm = 1.6052e-01, time/batch = 15.1217s	
17484/28500 (epoch 30.674), train_loss = 0.72101710, grad/param norm = 1.6769e-01, time/batch = 15.0590s	
17485/28500 (epoch 30.675), train_loss = 0.77795457, grad/param norm = 2.0360e-01, time/batch = 15.3568s	
17486/28500 (epoch 30.677), train_loss = 0.86032879, grad/param norm = 1.5887e-01, time/batch = 15.3721s	
17487/28500 (epoch 30.679), train_loss = 0.86634415, grad/param norm = 1.6980e-01, time/batch = 15.4214s	
17488/28500 (epoch 30.681), train_loss = 0.94341112, grad/param norm = 1.8245e-01, time/batch = 15.4932s	
17489/28500 (epoch 30.682), train_loss = 0.82380098, grad/param norm = 1.5943e-01, time/batch = 15.6155s	
17490/28500 (epoch 30.684), train_loss = 0.92257895, grad/param norm = 1.6743e-01, time/batch = 15.7138s	
17491/28500 (epoch 30.686), train_loss = 0.85929561, grad/param norm = 1.8336e-01, time/batch = 15.6877s	
17492/28500 (epoch 30.688), train_loss = 0.81482359, grad/param norm = 1.3617e-01, time/batch = 15.5626s	
17493/28500 (epoch 30.689), train_loss = 0.84684514, grad/param norm = 1.8117e-01, time/batch = 15.3258s	
17494/28500 (epoch 30.691), train_loss = 0.91794517, grad/param norm = 1.7925e-01, time/batch = 15.3353s	
17495/28500 (epoch 30.693), train_loss = 0.85228833, grad/param norm = 1.6635e-01, time/batch = 15.2984s	
17496/28500 (epoch 30.695), train_loss = 0.66650295, grad/param norm = 1.8912e-01, time/batch = 15.2181s	
17497/28500 (epoch 30.696), train_loss = 0.87129745, grad/param norm = 1.6638e-01, time/batch = 14.9922s	
17498/28500 (epoch 30.698), train_loss = 0.91055852, grad/param norm = 1.6409e-01, time/batch = 15.1338s	
17499/28500 (epoch 30.700), train_loss = 0.91668785, grad/param norm = 1.7424e-01, time/batch = 15.4416s	
17500/28500 (epoch 30.702), train_loss = 0.91201274, grad/param norm = 2.0922e-01, time/batch = 15.3731s	
17501/28500 (epoch 30.704), train_loss = 0.91476388, grad/param norm = 1.7600e-01, time/batch = 15.6505s	
17502/28500 (epoch 30.705), train_loss = 0.99426928, grad/param norm = 1.9779e-01, time/batch = 15.6069s	
17503/28500 (epoch 30.707), train_loss = 0.83511588, grad/param norm = 1.7611e-01, time/batch = 15.6336s	
17504/28500 (epoch 30.709), train_loss = 1.02355124, grad/param norm = 1.7996e-01, time/batch = 15.4552s	
17505/28500 (epoch 30.711), train_loss = 0.83022634, grad/param norm = 1.6763e-01, time/batch = 15.1505s	
17506/28500 (epoch 30.712), train_loss = 0.91323490, grad/param norm = 1.8417e-01, time/batch = 15.2859s	
17507/28500 (epoch 30.714), train_loss = 1.02952602, grad/param norm = 1.9914e-01, time/batch = 15.4999s	
17508/28500 (epoch 30.716), train_loss = 0.88034600, grad/param norm = 1.7076e-01, time/batch = 15.3926s	
17509/28500 (epoch 30.718), train_loss = 0.91989081, grad/param norm = 1.7049e-01, time/batch = 15.2367s	
17510/28500 (epoch 30.719), train_loss = 0.91454969, grad/param norm = 1.7591e-01, time/batch = 15.5319s	
17511/28500 (epoch 30.721), train_loss = 0.72398221, grad/param norm = 1.6670e-01, time/batch = 15.7181s	
17512/28500 (epoch 30.723), train_loss = 0.91651014, grad/param norm = 1.8567e-01, time/batch = 15.4866s	
17513/28500 (epoch 30.725), train_loss = 0.98293060, grad/param norm = 1.8786e-01, time/batch = 15.2947s	
17514/28500 (epoch 30.726), train_loss = 0.89509036, grad/param norm = 1.8178e-01, time/batch = 15.4938s	
17515/28500 (epoch 30.728), train_loss = 0.81347427, grad/param norm = 1.6013e-01, time/batch = 15.4321s	
17516/28500 (epoch 30.730), train_loss = 0.88914100, grad/param norm = 1.8365e-01, time/batch = 15.0574s	
17517/28500 (epoch 30.732), train_loss = 0.71977743, grad/param norm = 1.4829e-01, time/batch = 15.0203s	
17518/28500 (epoch 30.733), train_loss = 0.76722890, grad/param norm = 1.4646e-01, time/batch = 15.2098s	
17519/28500 (epoch 30.735), train_loss = 0.77363696, grad/param norm = 1.5494e-01, time/batch = 15.2248s	
17520/28500 (epoch 30.737), train_loss = 0.69814715, grad/param norm = 1.4508e-01, time/batch = 15.1482s	
17521/28500 (epoch 30.739), train_loss = 0.82011946, grad/param norm = 1.8241e-01, time/batch = 15.1556s	
17522/28500 (epoch 30.740), train_loss = 0.89479437, grad/param norm = 1.6615e-01, time/batch = 15.4549s	
17523/28500 (epoch 30.742), train_loss = 0.80628950, grad/param norm = 1.6405e-01, time/batch = 15.0585s	
17524/28500 (epoch 30.744), train_loss = 0.91516670, grad/param norm = 2.0809e-01, time/batch = 15.2048s	
17525/28500 (epoch 30.746), train_loss = 0.83988398, grad/param norm = 1.5608e-01, time/batch = 15.2960s	
17526/28500 (epoch 30.747), train_loss = 0.81154023, grad/param norm = 1.4393e-01, time/batch = 15.3884s	
17527/28500 (epoch 30.749), train_loss = 0.95214718, grad/param norm = 2.3848e-01, time/batch = 15.3596s	
17528/28500 (epoch 30.751), train_loss = 0.80658047, grad/param norm = 2.2940e-01, time/batch = 15.4944s	
17529/28500 (epoch 30.753), train_loss = 0.86677607, grad/param norm = 1.5071e-01, time/batch = 15.5496s	
17530/28500 (epoch 30.754), train_loss = 0.78830433, grad/param norm = 1.6102e-01, time/batch = 15.4389s	
17531/28500 (epoch 30.756), train_loss = 0.99113949, grad/param norm = 1.7478e-01, time/batch = 15.3076s	
17532/28500 (epoch 30.758), train_loss = 0.94825171, grad/param norm = 1.8429e-01, time/batch = 15.2995s	
17533/28500 (epoch 30.760), train_loss = 0.77074642, grad/param norm = 1.7479e-01, time/batch = 15.1192s	
17534/28500 (epoch 30.761), train_loss = 0.84202555, grad/param norm = 2.2638e-01, time/batch = 15.5395s	
17535/28500 (epoch 30.763), train_loss = 0.71377274, grad/param norm = 1.5864e-01, time/batch = 15.3907s	
17536/28500 (epoch 30.765), train_loss = 0.88045612, grad/param norm = 1.7732e-01, time/batch = 15.3341s	
17537/28500 (epoch 30.767), train_loss = 0.75721902, grad/param norm = 1.4989e-01, time/batch = 15.2809s	
17538/28500 (epoch 30.768), train_loss = 0.93263227, grad/param norm = 1.6842e-01, time/batch = 15.1312s	
17539/28500 (epoch 30.770), train_loss = 0.78904859, grad/param norm = 1.7538e-01, time/batch = 14.9830s	
17540/28500 (epoch 30.772), train_loss = 0.70736716, grad/param norm = 1.4618e-01, time/batch = 15.2204s	
17541/28500 (epoch 30.774), train_loss = 0.88327099, grad/param norm = 1.8249e-01, time/batch = 15.4894s	
17542/28500 (epoch 30.775), train_loss = 0.97023414, grad/param norm = 1.7222e-01, time/batch = 15.4308s	
17543/28500 (epoch 30.777), train_loss = 0.95919645, grad/param norm = 1.7708e-01, time/batch = 15.2249s	
17544/28500 (epoch 30.779), train_loss = 0.72896651, grad/param norm = 1.3946e-01, time/batch = 15.3666s	
17545/28500 (epoch 30.781), train_loss = 0.87681067, grad/param norm = 1.7255e-01, time/batch = 15.0497s	
17546/28500 (epoch 30.782), train_loss = 0.89810928, grad/param norm = 2.0393e-01, time/batch = 15.1200s	
17547/28500 (epoch 30.784), train_loss = 0.71599536, grad/param norm = 1.5923e-01, time/batch = 15.1405s	
17548/28500 (epoch 30.786), train_loss = 0.76595829, grad/param norm = 1.4994e-01, time/batch = 15.2324s	
17549/28500 (epoch 30.788), train_loss = 0.87031611, grad/param norm = 1.9903e-01, time/batch = 15.4382s	
17550/28500 (epoch 30.789), train_loss = 0.66511457, grad/param norm = 1.8064e-01, time/batch = 15.1589s	
17551/28500 (epoch 30.791), train_loss = 0.90028628, grad/param norm = 1.9487e-01, time/batch = 15.2469s	
17552/28500 (epoch 30.793), train_loss = 0.87337628, grad/param norm = 1.6492e-01, time/batch = 15.3233s	
17553/28500 (epoch 30.795), train_loss = 0.89697639, grad/param norm = 1.6750e-01, time/batch = 15.4350s	
17554/28500 (epoch 30.796), train_loss = 0.77686095, grad/param norm = 1.4625e-01, time/batch = 15.4834s	
17555/28500 (epoch 30.798), train_loss = 0.72427049, grad/param norm = 1.6228e-01, time/batch = 15.2574s	
17556/28500 (epoch 30.800), train_loss = 0.75390938, grad/param norm = 1.8519e-01, time/batch = 15.1449s	
17557/28500 (epoch 30.802), train_loss = 0.83177504, grad/param norm = 1.9919e-01, time/batch = 15.2679s	
17558/28500 (epoch 30.804), train_loss = 0.88645897, grad/param norm = 1.5193e-01, time/batch = 15.4588s	
17559/28500 (epoch 30.805), train_loss = 0.89148605, grad/param norm = 2.2960e-01, time/batch = 15.5440s	
17560/28500 (epoch 30.807), train_loss = 0.90363759, grad/param norm = 1.8026e-01, time/batch = 15.3908s	
17561/28500 (epoch 30.809), train_loss = 0.87757733, grad/param norm = 1.8722e-01, time/batch = 15.4589s	
17562/28500 (epoch 30.811), train_loss = 0.92374701, grad/param norm = 1.7426e-01, time/batch = 15.3103s	
17563/28500 (epoch 30.812), train_loss = 0.88754347, grad/param norm = 1.9915e-01, time/batch = 15.1270s	
17564/28500 (epoch 30.814), train_loss = 0.82026835, grad/param norm = 1.7255e-01, time/batch = 15.3411s	
17565/28500 (epoch 30.816), train_loss = 0.91855793, grad/param norm = 1.9589e-01, time/batch = 15.3836s	
17566/28500 (epoch 30.818), train_loss = 0.99363452, grad/param norm = 1.8081e-01, time/batch = 15.1956s	
17567/28500 (epoch 30.819), train_loss = 0.87235617, grad/param norm = 1.6625e-01, time/batch = 15.0996s	
17568/28500 (epoch 30.821), train_loss = 0.83695485, grad/param norm = 1.5953e-01, time/batch = 15.1646s	
17569/28500 (epoch 30.823), train_loss = 1.02044801, grad/param norm = 2.3925e-01, time/batch = 15.3823s	
17570/28500 (epoch 30.825), train_loss = 0.85468383, grad/param norm = 2.0572e-01, time/batch = 15.5838s	
17571/28500 (epoch 30.826), train_loss = 0.90740354, grad/param norm = 1.7236e-01, time/batch = 15.6470s	
17572/28500 (epoch 30.828), train_loss = 0.80144613, grad/param norm = 1.8078e-01, time/batch = 15.3006s	
17573/28500 (epoch 30.830), train_loss = 0.84653606, grad/param norm = 1.5629e-01, time/batch = 15.4650s	
17574/28500 (epoch 30.832), train_loss = 0.87321222, grad/param norm = 2.2923e-01, time/batch = 15.4725s	
17575/28500 (epoch 30.833), train_loss = 0.95745821, grad/param norm = 1.6681e-01, time/batch = 15.2364s	
17576/28500 (epoch 30.835), train_loss = 0.83757284, grad/param norm = 1.8042e-01, time/batch = 15.2910s	
17577/28500 (epoch 30.837), train_loss = 0.77193738, grad/param norm = 1.8482e-01, time/batch = 15.2889s	
17578/28500 (epoch 30.839), train_loss = 1.03085476, grad/param norm = 2.7662e-01, time/batch = 15.1359s	
17579/28500 (epoch 30.840), train_loss = 1.03918545, grad/param norm = 1.9266e-01, time/batch = 15.2561s	
17580/28500 (epoch 30.842), train_loss = 0.92985223, grad/param norm = 2.3103e-01, time/batch = 15.3755s	
17581/28500 (epoch 30.844), train_loss = 0.93895931, grad/param norm = 2.1569e-01, time/batch = 15.3193s	
17582/28500 (epoch 30.846), train_loss = 1.03267081, grad/param norm = 2.5707e-01, time/batch = 15.4083s	
17583/28500 (epoch 30.847), train_loss = 0.85410419, grad/param norm = 1.8776e-01, time/batch = 15.5993s	
17584/28500 (epoch 30.849), train_loss = 0.86648680, grad/param norm = 1.8907e-01, time/batch = 15.1745s	
17585/28500 (epoch 30.851), train_loss = 0.78024260, grad/param norm = 1.5251e-01, time/batch = 15.4299s	
17586/28500 (epoch 30.853), train_loss = 0.89863701, grad/param norm = 1.9410e-01, time/batch = 15.2861s	
17587/28500 (epoch 30.854), train_loss = 0.91389138, grad/param norm = 1.8888e-01, time/batch = 15.0305s	
17588/28500 (epoch 30.856), train_loss = 0.99143410, grad/param norm = 2.1912e-01, time/batch = 15.3427s	
17589/28500 (epoch 30.858), train_loss = 0.82542672, grad/param norm = 1.7139e-01, time/batch = 15.5361s	
17590/28500 (epoch 30.860), train_loss = 0.84833533, grad/param norm = 1.6341e-01, time/batch = 15.6322s	
17591/28500 (epoch 30.861), train_loss = 0.94265791, grad/param norm = 1.9324e-01, time/batch = 15.7157s	
17592/28500 (epoch 30.863), train_loss = 0.92740408, grad/param norm = 2.0506e-01, time/batch = 15.6643s	
17593/28500 (epoch 30.865), train_loss = 0.83193347, grad/param norm = 1.8273e-01, time/batch = 15.5563s	
17594/28500 (epoch 30.867), train_loss = 0.94085427, grad/param norm = 1.9122e-01, time/batch = 15.5066s	
17595/28500 (epoch 30.868), train_loss = 0.79483945, grad/param norm = 1.6488e-01, time/batch = 15.1666s	
17596/28500 (epoch 30.870), train_loss = 0.76948189, grad/param norm = 1.7352e-01, time/batch = 15.1974s	
17597/28500 (epoch 30.872), train_loss = 0.93364033, grad/param norm = 2.1140e-01, time/batch = 15.1095s	
17598/28500 (epoch 30.874), train_loss = 0.81327593, grad/param norm = 2.0530e-01, time/batch = 15.0490s	
17599/28500 (epoch 30.875), train_loss = 1.01986464, grad/param norm = 1.9422e-01, time/batch = 15.3803s	
17600/28500 (epoch 30.877), train_loss = 0.91170855, grad/param norm = 1.7131e-01, time/batch = 15.3687s	
17601/28500 (epoch 30.879), train_loss = 0.92428003, grad/param norm = 1.4789e-01, time/batch = 15.5577s	
17602/28500 (epoch 30.881), train_loss = 0.91698524, grad/param norm = 1.7446e-01, time/batch = 15.3929s	
17603/28500 (epoch 30.882), train_loss = 0.79629644, grad/param norm = 1.5014e-01, time/batch = 15.4578s	
17604/28500 (epoch 30.884), train_loss = 0.88856626, grad/param norm = 1.7844e-01, time/batch = 15.5331s	
17605/28500 (epoch 30.886), train_loss = 0.85387707, grad/param norm = 1.5254e-01, time/batch = 15.3637s	
17606/28500 (epoch 30.888), train_loss = 0.83209298, grad/param norm = 1.5441e-01, time/batch = 15.1271s	
17607/28500 (epoch 30.889), train_loss = 0.87280146, grad/param norm = 1.4618e-01, time/batch = 15.3471s	
17608/28500 (epoch 30.891), train_loss = 0.86163450, grad/param norm = 1.6703e-01, time/batch = 15.5710s	
17609/28500 (epoch 30.893), train_loss = 0.86430097, grad/param norm = 1.8354e-01, time/batch = 15.4656s	
17610/28500 (epoch 30.895), train_loss = 1.01779044, grad/param norm = 1.9992e-01, time/batch = 15.2363s	
17611/28500 (epoch 30.896), train_loss = 0.98091506, grad/param norm = 1.9095e-01, time/batch = 15.4642s	
17612/28500 (epoch 30.898), train_loss = 0.90237802, grad/param norm = 1.7745e-01, time/batch = 15.6229s	
17613/28500 (epoch 30.900), train_loss = 0.76025378, grad/param norm = 1.9071e-01, time/batch = 15.5265s	
17614/28500 (epoch 30.902), train_loss = 0.76042598, grad/param norm = 1.6968e-01, time/batch = 15.2934s	
17615/28500 (epoch 30.904), train_loss = 0.78094792, grad/param norm = 1.5634e-01, time/batch = 15.4173s	
17616/28500 (epoch 30.905), train_loss = 0.83031146, grad/param norm = 1.8338e-01, time/batch = 15.1789s	
17617/28500 (epoch 30.907), train_loss = 0.86548802, grad/param norm = 1.8612e-01, time/batch = 15.2926s	
17618/28500 (epoch 30.909), train_loss = 0.77140332, grad/param norm = 2.0679e-01, time/batch = 15.2262s	
17619/28500 (epoch 30.911), train_loss = 0.79593610, grad/param norm = 1.9671e-01, time/batch = 15.5783s	
17620/28500 (epoch 30.912), train_loss = 0.68197345, grad/param norm = 1.5266e-01, time/batch = 15.6213s	
17621/28500 (epoch 30.914), train_loss = 0.89441806, grad/param norm = 1.7779e-01, time/batch = 15.3215s	
17622/28500 (epoch 30.916), train_loss = 0.88512058, grad/param norm = 1.8247e-01, time/batch = 15.1426s	
17623/28500 (epoch 30.918), train_loss = 0.85490069, grad/param norm = 1.6862e-01, time/batch = 15.1167s	
17624/28500 (epoch 30.919), train_loss = 0.86865208, grad/param norm = 1.5658e-01, time/batch = 15.1006s	
17625/28500 (epoch 30.921), train_loss = 0.96744190, grad/param norm = 2.1107e-01, time/batch = 15.0633s	
17626/28500 (epoch 30.923), train_loss = 0.82500307, grad/param norm = 1.9774e-01, time/batch = 15.3763s	
17627/28500 (epoch 30.925), train_loss = 0.81394189, grad/param norm = 1.8311e-01, time/batch = 15.5909s	
17628/28500 (epoch 30.926), train_loss = 0.88213706, grad/param norm = 1.7376e-01, time/batch = 15.3990s	
17629/28500 (epoch 30.928), train_loss = 0.82375739, grad/param norm = 1.6675e-01, time/batch = 15.3111s	
17630/28500 (epoch 30.930), train_loss = 0.69518460, grad/param norm = 1.4096e-01, time/batch = 15.3039s	
17631/28500 (epoch 30.932), train_loss = 0.70532854, grad/param norm = 1.3907e-01, time/batch = 15.5389s	
17632/28500 (epoch 30.933), train_loss = 0.92836432, grad/param norm = 1.7676e-01, time/batch = 15.5550s	
17633/28500 (epoch 30.935), train_loss = 0.94878779, grad/param norm = 1.6793e-01, time/batch = 15.6274s	
17634/28500 (epoch 30.937), train_loss = 0.98613269, grad/param norm = 2.2674e-01, time/batch = 15.5907s	
17635/28500 (epoch 30.939), train_loss = 1.03229827, grad/param norm = 2.0565e-01, time/batch = 15.4344s	
17636/28500 (epoch 30.940), train_loss = 0.74659098, grad/param norm = 1.7360e-01, time/batch = 15.3824s	
17637/28500 (epoch 30.942), train_loss = 0.86661032, grad/param norm = 1.8008e-01, time/batch = 15.4375s	
17638/28500 (epoch 30.944), train_loss = 0.82324921, grad/param norm = 1.6358e-01, time/batch = 19.0565s	
17639/28500 (epoch 30.946), train_loss = 0.93947272, grad/param norm = 1.6008e-01, time/batch = 24.1977s	
17640/28500 (epoch 30.947), train_loss = 1.14400507, grad/param norm = 2.4100e-01, time/batch = 15.3080s	
17641/28500 (epoch 30.949), train_loss = 0.84511073, grad/param norm = 1.8253e-01, time/batch = 15.6285s	
17642/28500 (epoch 30.951), train_loss = 1.05783413, grad/param norm = 2.1076e-01, time/batch = 15.5449s	
17643/28500 (epoch 30.953), train_loss = 1.01907404, grad/param norm = 2.0050e-01, time/batch = 15.3569s	
17644/28500 (epoch 30.954), train_loss = 0.97129718, grad/param norm = 2.0518e-01, time/batch = 15.5055s	
17645/28500 (epoch 30.956), train_loss = 0.89619345, grad/param norm = 3.0755e-01, time/batch = 15.3604s	
17646/28500 (epoch 30.958), train_loss = 1.11596144, grad/param norm = 1.9475e-01, time/batch = 15.5458s	
17647/28500 (epoch 30.960), train_loss = 0.83878838, grad/param norm = 1.9572e-01, time/batch = 15.5680s	
17648/28500 (epoch 30.961), train_loss = 1.04735081, grad/param norm = 2.1138e-01, time/batch = 15.3133s	
17649/28500 (epoch 30.963), train_loss = 0.99213406, grad/param norm = 1.7535e-01, time/batch = 15.3809s	
17650/28500 (epoch 30.965), train_loss = 0.80735744, grad/param norm = 1.7712e-01, time/batch = 15.2916s	
17651/28500 (epoch 30.967), train_loss = 0.82269999, grad/param norm = 1.8265e-01, time/batch = 15.3778s	
17652/28500 (epoch 30.968), train_loss = 0.75981664, grad/param norm = 1.5621e-01, time/batch = 15.2974s	
17653/28500 (epoch 30.970), train_loss = 0.82293554, grad/param norm = 1.8224e-01, time/batch = 15.2844s	
17654/28500 (epoch 30.972), train_loss = 0.87778853, grad/param norm = 1.7649e-01, time/batch = 15.1349s	
17655/28500 (epoch 30.974), train_loss = 1.06555828, grad/param norm = 2.0357e-01, time/batch = 15.4591s	
17656/28500 (epoch 30.975), train_loss = 0.83223581, grad/param norm = 1.9167e-01, time/batch = 15.5156s	
17657/28500 (epoch 30.977), train_loss = 0.96396651, grad/param norm = 1.8704e-01, time/batch = 15.5377s	
17658/28500 (epoch 30.979), train_loss = 0.88909706, grad/param norm = 1.7870e-01, time/batch = 15.3739s	
17659/28500 (epoch 30.981), train_loss = 0.77335830, grad/param norm = 1.6669e-01, time/batch = 15.0629s	
17660/28500 (epoch 30.982), train_loss = 0.84244949, grad/param norm = 1.7330e-01, time/batch = 15.2363s	
17661/28500 (epoch 30.984), train_loss = 0.96348011, grad/param norm = 1.7253e-01, time/batch = 15.4194s	
17662/28500 (epoch 30.986), train_loss = 1.15953451, grad/param norm = 2.0589e-01, time/batch = 15.2932s	
17663/28500 (epoch 30.988), train_loss = 0.79436190, grad/param norm = 1.5869e-01, time/batch = 15.2041s	
17664/28500 (epoch 30.989), train_loss = 0.91349792, grad/param norm = 1.8538e-01, time/batch = 15.0431s	
17665/28500 (epoch 30.991), train_loss = 0.82316583, grad/param norm = 2.0428e-01, time/batch = 15.4453s	
17666/28500 (epoch 30.993), train_loss = 0.81857242, grad/param norm = 1.7436e-01, time/batch = 15.3575s	
17667/28500 (epoch 30.995), train_loss = 0.81750116, grad/param norm = 1.6434e-01, time/batch = 15.3153s	
17668/28500 (epoch 30.996), train_loss = 0.81275967, grad/param norm = 1.9341e-01, time/batch = 15.2287s	
17669/28500 (epoch 30.998), train_loss = 0.98793155, grad/param norm = 2.4733e-01, time/batch = 15.4649s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
17670/28500 (epoch 31.000), train_loss = 0.88629531, grad/param norm = 1.7779e-01, time/batch = 15.5298s	
17671/28500 (epoch 31.002), train_loss = 1.06638962, grad/param norm = 1.9000e-01, time/batch = 15.7210s	
17672/28500 (epoch 31.004), train_loss = 0.84947586, grad/param norm = 1.5769e-01, time/batch = 15.4609s	
17673/28500 (epoch 31.005), train_loss = 0.98864798, grad/param norm = 2.0748e-01, time/batch = 15.1989s	
17674/28500 (epoch 31.007), train_loss = 0.78893176, grad/param norm = 1.4603e-01, time/batch = 15.3206s	
17675/28500 (epoch 31.009), train_loss = 0.91519321, grad/param norm = 1.9076e-01, time/batch = 15.3066s	
17676/28500 (epoch 31.011), train_loss = 0.82375791, grad/param norm = 1.8173e-01, time/batch = 15.1904s	
17677/28500 (epoch 31.012), train_loss = 0.78810519, grad/param norm = 1.6073e-01, time/batch = 15.3643s	
17678/28500 (epoch 31.014), train_loss = 0.80482127, grad/param norm = 1.8438e-01, time/batch = 15.0508s	
17679/28500 (epoch 31.016), train_loss = 0.84415963, grad/param norm = 1.7239e-01, time/batch = 15.0710s	
17680/28500 (epoch 31.018), train_loss = 0.92373107, grad/param norm = 1.8279e-01, time/batch = 15.2915s	
17681/28500 (epoch 31.019), train_loss = 0.98009112, grad/param norm = 1.8065e-01, time/batch = 15.5609s	
17682/28500 (epoch 31.021), train_loss = 0.98725696, grad/param norm = 1.6468e-01, time/batch = 15.5043s	
17683/28500 (epoch 31.023), train_loss = 0.90545516, grad/param norm = 1.8758e-01, time/batch = 15.4563s	
17684/28500 (epoch 31.025), train_loss = 0.91900390, grad/param norm = 1.7638e-01, time/batch = 15.4002s	
17685/28500 (epoch 31.026), train_loss = 0.87035855, grad/param norm = 1.6931e-01, time/batch = 15.4532s	
17686/28500 (epoch 31.028), train_loss = 0.90807789, grad/param norm = 1.8045e-01, time/batch = 15.2181s	
17687/28500 (epoch 31.030), train_loss = 0.94327576, grad/param norm = 2.0084e-01, time/batch = 15.2220s	
17688/28500 (epoch 31.032), train_loss = 0.98084435, grad/param norm = 1.7625e-01, time/batch = 15.4658s	
17689/28500 (epoch 31.033), train_loss = 1.03422019, grad/param norm = 1.8192e-01, time/batch = 15.4190s	
17690/28500 (epoch 31.035), train_loss = 0.86783963, grad/param norm = 1.8111e-01, time/batch = 14.9795s	
17691/28500 (epoch 31.037), train_loss = 0.93757242, grad/param norm = 1.6351e-01, time/batch = 15.0762s	
17692/28500 (epoch 31.039), train_loss = 1.00271281, grad/param norm = 1.8949e-01, time/batch = 15.3753s	
17693/28500 (epoch 31.040), train_loss = 1.00517431, grad/param norm = 1.7295e-01, time/batch = 15.1457s	
17694/28500 (epoch 31.042), train_loss = 0.94336493, grad/param norm = 1.7123e-01, time/batch = 15.1914s	
17695/28500 (epoch 31.044), train_loss = 0.91079793, grad/param norm = 1.8807e-01, time/batch = 15.2402s	
17696/28500 (epoch 31.046), train_loss = 1.09359882, grad/param norm = 1.7843e-01, time/batch = 15.2704s	
17697/28500 (epoch 31.047), train_loss = 1.05089234, grad/param norm = 1.9990e-01, time/batch = 15.2338s	
17698/28500 (epoch 31.049), train_loss = 0.90851505, grad/param norm = 1.7561e-01, time/batch = 15.0488s	
17699/28500 (epoch 31.051), train_loss = 0.89867168, grad/param norm = 1.8340e-01, time/batch = 15.1509s	
17700/28500 (epoch 31.053), train_loss = 0.88804118, grad/param norm = 1.9182e-01, time/batch = 15.5516s	
17701/28500 (epoch 31.054), train_loss = 0.98558792, grad/param norm = 1.8297e-01, time/batch = 15.5322s	
17702/28500 (epoch 31.056), train_loss = 0.82455449, grad/param norm = 1.7423e-01, time/batch = 15.5209s	
17703/28500 (epoch 31.058), train_loss = 0.81497025, grad/param norm = 1.6247e-01, time/batch = 15.5283s	
17704/28500 (epoch 31.060), train_loss = 0.93998061, grad/param norm = 1.7955e-01, time/batch = 15.2256s	
17705/28500 (epoch 31.061), train_loss = 0.88929263, grad/param norm = 1.8486e-01, time/batch = 15.1304s	
17706/28500 (epoch 31.063), train_loss = 0.97561995, grad/param norm = 1.9159e-01, time/batch = 14.9634s	
17707/28500 (epoch 31.065), train_loss = 0.94112727, grad/param norm = 2.0036e-01, time/batch = 15.1461s	
17708/28500 (epoch 31.067), train_loss = 0.86082051, grad/param norm = 1.7026e-01, time/batch = 15.4654s	
17709/28500 (epoch 31.068), train_loss = 0.86932793, grad/param norm = 1.6623e-01, time/batch = 15.5161s	
17710/28500 (epoch 31.070), train_loss = 0.93723437, grad/param norm = 1.7738e-01, time/batch = 15.3796s	
17711/28500 (epoch 31.072), train_loss = 1.03874270, grad/param norm = 2.0365e-01, time/batch = 15.2979s	
17712/28500 (epoch 31.074), train_loss = 0.89978499, grad/param norm = 1.7003e-01, time/batch = 15.3745s	
17713/28500 (epoch 31.075), train_loss = 0.88267885, grad/param norm = 1.6070e-01, time/batch = 15.4723s	
17714/28500 (epoch 31.077), train_loss = 0.94155939, grad/param norm = 1.5621e-01, time/batch = 15.4814s	
17715/28500 (epoch 31.079), train_loss = 0.91778033, grad/param norm = 1.8107e-01, time/batch = 15.3864s	
17716/28500 (epoch 31.081), train_loss = 1.02015951, grad/param norm = 2.0329e-01, time/batch = 15.2858s	
17717/28500 (epoch 31.082), train_loss = 0.94680451, grad/param norm = 2.0427e-01, time/batch = 15.0293s	
17718/28500 (epoch 31.084), train_loss = 0.92962428, grad/param norm = 1.7856e-01, time/batch = 14.9034s	
17719/28500 (epoch 31.086), train_loss = 0.89288458, grad/param norm = 2.0098e-01, time/batch = 15.1937s	
17720/28500 (epoch 31.088), train_loss = 0.80965907, grad/param norm = 1.6576e-01, time/batch = 15.3090s	
17721/28500 (epoch 31.089), train_loss = 0.98612884, grad/param norm = 1.7493e-01, time/batch = 15.3185s	
17722/28500 (epoch 31.091), train_loss = 0.78316867, grad/param norm = 1.6225e-01, time/batch = 15.3048s	
17723/28500 (epoch 31.093), train_loss = 0.99301820, grad/param norm = 1.7611e-01, time/batch = 15.1935s	
17724/28500 (epoch 31.095), train_loss = 0.89628203, grad/param norm = 1.5422e-01, time/batch = 15.2573s	
17725/28500 (epoch 31.096), train_loss = 0.99096062, grad/param norm = 1.8012e-01, time/batch = 15.0504s	
17726/28500 (epoch 31.098), train_loss = 0.93011101, grad/param norm = 1.9125e-01, time/batch = 15.0386s	
17727/28500 (epoch 31.100), train_loss = 0.87591465, grad/param norm = 1.6908e-01, time/batch = 15.3269s	
17728/28500 (epoch 31.102), train_loss = 0.97812506, grad/param norm = 1.9612e-01, time/batch = 15.3350s	
17729/28500 (epoch 31.104), train_loss = 0.89740867, grad/param norm = 1.8158e-01, time/batch = 15.1705s	
17730/28500 (epoch 31.105), train_loss = 1.02466340, grad/param norm = 1.8261e-01, time/batch = 14.8258s	
17731/28500 (epoch 31.107), train_loss = 0.83525311, grad/param norm = 1.7863e-01, time/batch = 15.1439s	
17732/28500 (epoch 31.109), train_loss = 0.83665903, grad/param norm = 1.8987e-01, time/batch = 15.1352s	
17733/28500 (epoch 31.111), train_loss = 0.89402118, grad/param norm = 2.0560e-01, time/batch = 15.2055s	
17734/28500 (epoch 31.112), train_loss = 0.97461172, grad/param norm = 1.7465e-01, time/batch = 14.9773s	
17735/28500 (epoch 31.114), train_loss = 0.86997877, grad/param norm = 1.5597e-01, time/batch = 15.3287s	
17736/28500 (epoch 31.116), train_loss = 1.05880493, grad/param norm = 2.0680e-01, time/batch = 15.0431s	
17737/28500 (epoch 31.118), train_loss = 0.80325821, grad/param norm = 1.6789e-01, time/batch = 15.0634s	
17738/28500 (epoch 31.119), train_loss = 0.94257854, grad/param norm = 1.8421e-01, time/batch = 15.3662s	
17739/28500 (epoch 31.121), train_loss = 1.09606894, grad/param norm = 2.2149e-01, time/batch = 15.5434s	
17740/28500 (epoch 31.123), train_loss = 1.00891521, grad/param norm = 1.9356e-01, time/batch = 15.6874s	
17741/28500 (epoch 31.125), train_loss = 0.93077685, grad/param norm = 1.7908e-01, time/batch = 15.5933s	
17742/28500 (epoch 31.126), train_loss = 0.89972081, grad/param norm = 1.7599e-01, time/batch = 15.6125s	
17743/28500 (epoch 31.128), train_loss = 0.91709043, grad/param norm = 1.8779e-01, time/batch = 15.4373s	
17744/28500 (epoch 31.130), train_loss = 0.84474618, grad/param norm = 2.1856e-01, time/batch = 15.3869s	
17745/28500 (epoch 31.132), train_loss = 0.93774923, grad/param norm = 2.1163e-01, time/batch = 15.3061s	
17746/28500 (epoch 31.133), train_loss = 0.96684318, grad/param norm = 2.1819e-01, time/batch = 15.3590s	
17747/28500 (epoch 31.135), train_loss = 0.87124706, grad/param norm = 1.8033e-01, time/batch = 15.5977s	
17748/28500 (epoch 31.137), train_loss = 0.92302312, grad/param norm = 1.6948e-01, time/batch = 15.2953s	
17749/28500 (epoch 31.139), train_loss = 0.89653468, grad/param norm = 1.6964e-01, time/batch = 15.1470s	
17750/28500 (epoch 31.140), train_loss = 0.91441123, grad/param norm = 1.8101e-01, time/batch = 15.2907s	
17751/28500 (epoch 31.142), train_loss = 0.87626107, grad/param norm = 1.8747e-01, time/batch = 15.2995s	
17752/28500 (epoch 31.144), train_loss = 0.82190961, grad/param norm = 1.6780e-01, time/batch = 15.2852s	
17753/28500 (epoch 31.146), train_loss = 0.88149558, grad/param norm = 1.7205e-01, time/batch = 15.5457s	
17754/28500 (epoch 31.147), train_loss = 0.77816953, grad/param norm = 1.6067e-01, time/batch = 15.5466s	
17755/28500 (epoch 31.149), train_loss = 0.77751246, grad/param norm = 1.5639e-01, time/batch = 15.1952s	
17756/28500 (epoch 31.151), train_loss = 0.86994455, grad/param norm = 1.6418e-01, time/batch = 15.5110s	
17757/28500 (epoch 31.153), train_loss = 0.93660095, grad/param norm = 1.8829e-01, time/batch = 15.4168s	
17758/28500 (epoch 31.154), train_loss = 0.79801373, grad/param norm = 1.7047e-01, time/batch = 15.3113s	
17759/28500 (epoch 31.156), train_loss = 0.99798713, grad/param norm = 1.8428e-01, time/batch = 15.4503s	
17760/28500 (epoch 31.158), train_loss = 0.90849728, grad/param norm = 1.6929e-01, time/batch = 15.4986s	
17761/28500 (epoch 31.160), train_loss = 0.80087427, grad/param norm = 1.5531e-01, time/batch = 15.5163s	
17762/28500 (epoch 31.161), train_loss = 0.85527337, grad/param norm = 2.1401e-01, time/batch = 15.5948s	
17763/28500 (epoch 31.163), train_loss = 0.77033122, grad/param norm = 1.7174e-01, time/batch = 15.3128s	
17764/28500 (epoch 31.165), train_loss = 1.07427972, grad/param norm = 1.9532e-01, time/batch = 15.1398s	
17765/28500 (epoch 31.167), train_loss = 1.06987076, grad/param norm = 1.9566e-01, time/batch = 15.4476s	
17766/28500 (epoch 31.168), train_loss = 1.01041680, grad/param norm = 2.1162e-01, time/batch = 15.4914s	
17767/28500 (epoch 31.170), train_loss = 0.99641935, grad/param norm = 2.4494e-01, time/batch = 15.4249s	
17768/28500 (epoch 31.172), train_loss = 0.90530149, grad/param norm = 1.6283e-01, time/batch = 15.5173s	
17769/28500 (epoch 31.174), train_loss = 1.07756877, grad/param norm = 2.5995e-01, time/batch = 15.3030s	
17770/28500 (epoch 31.175), train_loss = 0.88049182, grad/param norm = 1.6740e-01, time/batch = 15.4516s	
17771/28500 (epoch 31.177), train_loss = 0.97247820, grad/param norm = 1.8044e-01, time/batch = 15.5337s	
17772/28500 (epoch 31.179), train_loss = 0.99606628, grad/param norm = 1.9643e-01, time/batch = 15.5165s	
17773/28500 (epoch 31.181), train_loss = 0.95293835, grad/param norm = 2.0546e-01, time/batch = 15.3106s	
17774/28500 (epoch 31.182), train_loss = 0.89512564, grad/param norm = 1.8034e-01, time/batch = 15.4270s	
17775/28500 (epoch 31.184), train_loss = 1.07297475, grad/param norm = 2.0400e-01, time/batch = 15.2958s	
17776/28500 (epoch 31.186), train_loss = 1.03184358, grad/param norm = 1.7578e-01, time/batch = 15.4396s	
17777/28500 (epoch 31.188), train_loss = 0.95198740, grad/param norm = 1.6810e-01, time/batch = 15.0548s	
17778/28500 (epoch 31.189), train_loss = 0.92305180, grad/param norm = 1.6628e-01, time/batch = 15.1277s	
17779/28500 (epoch 31.191), train_loss = 1.13582539, grad/param norm = 2.0462e-01, time/batch = 15.2136s	
17780/28500 (epoch 31.193), train_loss = 0.94079445, grad/param norm = 1.9371e-01, time/batch = 15.3763s	
17781/28500 (epoch 31.195), train_loss = 1.06051814, grad/param norm = 1.9306e-01, time/batch = 15.5658s	
17782/28500 (epoch 31.196), train_loss = 0.97702273, grad/param norm = 1.7741e-01, time/batch = 15.4614s	
17783/28500 (epoch 31.198), train_loss = 0.92590605, grad/param norm = 1.8286e-01, time/batch = 15.5480s	
17784/28500 (epoch 31.200), train_loss = 0.98211992, grad/param norm = 1.7292e-01, time/batch = 15.3070s	
17785/28500 (epoch 31.202), train_loss = 0.94064651, grad/param norm = 1.7337e-01, time/batch = 15.2960s	
17786/28500 (epoch 31.204), train_loss = 0.90143810, grad/param norm = 1.5710e-01, time/batch = 15.4961s	
17787/28500 (epoch 31.205), train_loss = 0.87644396, grad/param norm = 1.7285e-01, time/batch = 15.3679s	
17788/28500 (epoch 31.207), train_loss = 0.81765326, grad/param norm = 1.9347e-01, time/batch = 15.3752s	
17789/28500 (epoch 31.209), train_loss = 0.95993351, grad/param norm = 1.9522e-01, time/batch = 15.4298s	
17790/28500 (epoch 31.211), train_loss = 0.81875725, grad/param norm = 1.6714e-01, time/batch = 15.3573s	
17791/28500 (epoch 31.212), train_loss = 0.77573171, grad/param norm = 1.6976e-01, time/batch = 15.6885s	
17792/28500 (epoch 31.214), train_loss = 0.91472505, grad/param norm = 1.8411e-01, time/batch = 15.5618s	
17793/28500 (epoch 31.216), train_loss = 0.85851069, grad/param norm = 1.8504e-01, time/batch = 15.4856s	
17794/28500 (epoch 31.218), train_loss = 1.00905429, grad/param norm = 1.6953e-01, time/batch = 15.6482s	
17795/28500 (epoch 31.219), train_loss = 0.94156349, grad/param norm = 1.7933e-01, time/batch = 15.4453s	
17796/28500 (epoch 31.221), train_loss = 0.77934712, grad/param norm = 1.7156e-01, time/batch = 15.4509s	
17797/28500 (epoch 31.223), train_loss = 1.02929483, grad/param norm = 1.9601e-01, time/batch = 15.5550s	
17798/28500 (epoch 31.225), train_loss = 1.05697689, grad/param norm = 1.9106e-01, time/batch = 15.2092s	
17799/28500 (epoch 31.226), train_loss = 0.87881646, grad/param norm = 1.6856e-01, time/batch = 15.1128s	
17800/28500 (epoch 31.228), train_loss = 1.00095674, grad/param norm = 1.6517e-01, time/batch = 15.1438s	
17801/28500 (epoch 31.230), train_loss = 0.99144086, grad/param norm = 1.7355e-01, time/batch = 15.5246s	
17802/28500 (epoch 31.232), train_loss = 0.94664558, grad/param norm = 1.7729e-01, time/batch = 15.6360s	
17803/28500 (epoch 31.233), train_loss = 0.91974732, grad/param norm = 1.9336e-01, time/batch = 15.7172s	
17804/28500 (epoch 31.235), train_loss = 0.90504597, grad/param norm = 1.7025e-01, time/batch = 15.4621s	
17805/28500 (epoch 31.237), train_loss = 0.82180883, grad/param norm = 1.6020e-01, time/batch = 15.4461s	
17806/28500 (epoch 31.239), train_loss = 0.85780602, grad/param norm = 1.4531e-01, time/batch = 15.4812s	
17807/28500 (epoch 31.240), train_loss = 0.81030557, grad/param norm = 1.6135e-01, time/batch = 15.3323s	
17808/28500 (epoch 31.242), train_loss = 0.89656432, grad/param norm = 1.9320e-01, time/batch = 15.1762s	
17809/28500 (epoch 31.244), train_loss = 0.95312911, grad/param norm = 1.7860e-01, time/batch = 15.1950s	
17810/28500 (epoch 31.246), train_loss = 0.97670563, grad/param norm = 1.7450e-01, time/batch = 14.9860s	
17811/28500 (epoch 31.247), train_loss = 1.03938466, grad/param norm = 2.0326e-01, time/batch = 14.9763s	
17812/28500 (epoch 31.249), train_loss = 0.90089122, grad/param norm = 1.7672e-01, time/batch = 15.2125s	
17813/28500 (epoch 31.251), train_loss = 0.86314240, grad/param norm = 1.5226e-01, time/batch = 15.2229s	
17814/28500 (epoch 31.253), train_loss = 1.02366045, grad/param norm = 1.9284e-01, time/batch = 15.1377s	
17815/28500 (epoch 31.254), train_loss = 1.06001905, grad/param norm = 1.7575e-01, time/batch = 15.2074s	
17816/28500 (epoch 31.256), train_loss = 0.89829243, grad/param norm = 1.9862e-01, time/batch = 15.1037s	
17817/28500 (epoch 31.258), train_loss = 0.90592351, grad/param norm = 2.0644e-01, time/batch = 15.1282s	
17818/28500 (epoch 31.260), train_loss = 0.90837787, grad/param norm = 1.6453e-01, time/batch = 15.2185s	
17819/28500 (epoch 31.261), train_loss = 0.82549044, grad/param norm = 1.6262e-01, time/batch = 15.1262s	
17820/28500 (epoch 31.263), train_loss = 0.98203793, grad/param norm = 1.9253e-01, time/batch = 15.3562s	
17821/28500 (epoch 31.265), train_loss = 0.89425877, grad/param norm = 1.6229e-01, time/batch = 15.7102s	
17822/28500 (epoch 31.267), train_loss = 1.04704311, grad/param norm = 2.0905e-01, time/batch = 15.2761s	
17823/28500 (epoch 31.268), train_loss = 0.95889742, grad/param norm = 1.6183e-01, time/batch = 15.2775s	
17824/28500 (epoch 31.270), train_loss = 0.94055404, grad/param norm = 1.9818e-01, time/batch = 15.2754s	
17825/28500 (epoch 31.272), train_loss = 0.93359851, grad/param norm = 1.6946e-01, time/batch = 15.3951s	
17826/28500 (epoch 31.274), train_loss = 0.99219495, grad/param norm = 2.0704e-01, time/batch = 15.3013s	
17827/28500 (epoch 31.275), train_loss = 0.97429833, grad/param norm = 1.7073e-01, time/batch = 15.3108s	
17828/28500 (epoch 31.277), train_loss = 0.90069984, grad/param norm = 1.6722e-01, time/batch = 15.2912s	
17829/28500 (epoch 31.279), train_loss = 0.93490259, grad/param norm = 2.1085e-01, time/batch = 15.4218s	
17830/28500 (epoch 31.281), train_loss = 0.97518647, grad/param norm = 2.1482e-01, time/batch = 15.3943s	
17831/28500 (epoch 31.282), train_loss = 0.86685991, grad/param norm = 1.5719e-01, time/batch = 15.1522s	
17832/28500 (epoch 31.284), train_loss = 0.93188810, grad/param norm = 1.9667e-01, time/batch = 15.4493s	
17833/28500 (epoch 31.286), train_loss = 1.04647544, grad/param norm = 1.8547e-01, time/batch = 15.5967s	
17834/28500 (epoch 31.288), train_loss = 0.92066017, grad/param norm = 1.9073e-01, time/batch = 15.4252s	
17835/28500 (epoch 31.289), train_loss = 0.95214688, grad/param norm = 1.9604e-01, time/batch = 15.2783s	
17836/28500 (epoch 31.291), train_loss = 0.93200291, grad/param norm = 1.7499e-01, time/batch = 15.3643s	
17837/28500 (epoch 31.293), train_loss = 0.90335921, grad/param norm = 1.5736e-01, time/batch = 15.3896s	
17838/28500 (epoch 31.295), train_loss = 0.83652949, grad/param norm = 1.6952e-01, time/batch = 15.4803s	
17839/28500 (epoch 31.296), train_loss = 0.79793043, grad/param norm = 1.5279e-01, time/batch = 15.5523s	
17840/28500 (epoch 31.298), train_loss = 0.96239355, grad/param norm = 1.6616e-01, time/batch = 15.5475s	
17841/28500 (epoch 31.300), train_loss = 0.85177055, grad/param norm = 1.6901e-01, time/batch = 15.5362s	
17842/28500 (epoch 31.302), train_loss = 0.80022769, grad/param norm = 1.5720e-01, time/batch = 15.5238s	
17843/28500 (epoch 31.304), train_loss = 0.88729936, grad/param norm = 1.6895e-01, time/batch = 15.5469s	
17844/28500 (epoch 31.305), train_loss = 0.95616143, grad/param norm = 1.7249e-01, time/batch = 15.4622s	
17845/28500 (epoch 31.307), train_loss = 0.90496131, grad/param norm = 1.8340e-01, time/batch = 15.4624s	
17846/28500 (epoch 31.309), train_loss = 0.89329337, grad/param norm = 1.6491e-01, time/batch = 15.2903s	
17847/28500 (epoch 31.311), train_loss = 0.96214294, grad/param norm = 1.6907e-01, time/batch = 15.5015s	
17848/28500 (epoch 31.312), train_loss = 0.93739164, grad/param norm = 1.6246e-01, time/batch = 15.2711s	
17849/28500 (epoch 31.314), train_loss = 0.96969270, grad/param norm = 2.0069e-01, time/batch = 15.3128s	
17850/28500 (epoch 31.316), train_loss = 0.92466210, grad/param norm = 1.9731e-01, time/batch = 15.6349s	
17851/28500 (epoch 31.318), train_loss = 0.99830843, grad/param norm = 1.6707e-01, time/batch = 15.6212s	
17852/28500 (epoch 31.319), train_loss = 0.87592364, grad/param norm = 1.8587e-01, time/batch = 15.6423s	
17853/28500 (epoch 31.321), train_loss = 0.89319980, grad/param norm = 1.8291e-01, time/batch = 15.5526s	
17854/28500 (epoch 31.323), train_loss = 0.89005569, grad/param norm = 1.8120e-01, time/batch = 15.4704s	
17855/28500 (epoch 31.325), train_loss = 1.04119246, grad/param norm = 1.8393e-01, time/batch = 15.5374s	
17856/28500 (epoch 31.326), train_loss = 0.96543800, grad/param norm = 1.8256e-01, time/batch = 15.3792s	
17857/28500 (epoch 31.328), train_loss = 0.75499911, grad/param norm = 1.6104e-01, time/batch = 15.2965s	
17858/28500 (epoch 31.330), train_loss = 0.83354831, grad/param norm = 1.7218e-01, time/batch = 15.2875s	
17859/28500 (epoch 31.332), train_loss = 0.90174732, grad/param norm = 1.6651e-01, time/batch = 15.5071s	
17860/28500 (epoch 31.333), train_loss = 0.73525758, grad/param norm = 2.0725e-01, time/batch = 15.5365s	
17861/28500 (epoch 31.335), train_loss = 0.81318657, grad/param norm = 1.6771e-01, time/batch = 15.5716s	
17862/28500 (epoch 31.337), train_loss = 0.77581347, grad/param norm = 1.6873e-01, time/batch = 15.5452s	
17863/28500 (epoch 31.339), train_loss = 0.75373136, grad/param norm = 1.3875e-01, time/batch = 15.5035s	
17864/28500 (epoch 31.340), train_loss = 0.90747982, grad/param norm = 2.1875e-01, time/batch = 15.1983s	
17865/28500 (epoch 31.342), train_loss = 0.89279608, grad/param norm = 1.7717e-01, time/batch = 15.3091s	
17866/28500 (epoch 31.344), train_loss = 0.81704866, grad/param norm = 2.0107e-01, time/batch = 15.4333s	
17867/28500 (epoch 31.346), train_loss = 0.75133117, grad/param norm = 1.4700e-01, time/batch = 15.2955s	
17868/28500 (epoch 31.347), train_loss = 0.90111968, grad/param norm = 1.6459e-01, time/batch = 15.3027s	
17869/28500 (epoch 31.349), train_loss = 0.88576537, grad/param norm = 1.6719e-01, time/batch = 15.6082s	
17870/28500 (epoch 31.351), train_loss = 0.82309164, grad/param norm = 1.7379e-01, time/batch = 15.7222s	
17871/28500 (epoch 31.353), train_loss = 0.89953910, grad/param norm = 1.7870e-01, time/batch = 26.0096s	
17872/28500 (epoch 31.354), train_loss = 0.79756746, grad/param norm = 1.4633e-01, time/batch = 15.3009s	
17873/28500 (epoch 31.356), train_loss = 0.85723810, grad/param norm = 2.1948e-01, time/batch = 15.3402s	
17874/28500 (epoch 31.358), train_loss = 0.94869291, grad/param norm = 1.6705e-01, time/batch = 15.2761s	
17875/28500 (epoch 31.360), train_loss = 0.92500231, grad/param norm = 1.8423e-01, time/batch = 15.3768s	
17876/28500 (epoch 31.361), train_loss = 0.81942277, grad/param norm = 1.5755e-01, time/batch = 15.3912s	
17877/28500 (epoch 31.363), train_loss = 0.80609754, grad/param norm = 1.4113e-01, time/batch = 15.3483s	
17878/28500 (epoch 31.365), train_loss = 0.88531244, grad/param norm = 1.8645e-01, time/batch = 15.3815s	
17879/28500 (epoch 31.367), train_loss = 0.92449476, grad/param norm = 1.7300e-01, time/batch = 15.2956s	
17880/28500 (epoch 31.368), train_loss = 0.84646621, grad/param norm = 1.6359e-01, time/batch = 15.6091s	
17881/28500 (epoch 31.370), train_loss = 0.89966155, grad/param norm = 1.7552e-01, time/batch = 15.7040s	
17882/28500 (epoch 31.372), train_loss = 0.73318792, grad/param norm = 1.6912e-01, time/batch = 15.5493s	
17883/28500 (epoch 31.374), train_loss = 0.84928344, grad/param norm = 1.6861e-01, time/batch = 15.4154s	
17884/28500 (epoch 31.375), train_loss = 0.97852843, grad/param norm = 1.7725e-01, time/batch = 15.3704s	
17885/28500 (epoch 31.377), train_loss = 0.78392582, grad/param norm = 2.0150e-01, time/batch = 15.4487s	
17886/28500 (epoch 31.379), train_loss = 0.69805852, grad/param norm = 1.5670e-01, time/batch = 15.4356s	
17887/28500 (epoch 31.381), train_loss = 0.86320747, grad/param norm = 1.6504e-01, time/batch = 15.4196s	
17888/28500 (epoch 31.382), train_loss = 0.84138316, grad/param norm = 1.8407e-01, time/batch = 15.4027s	
17889/28500 (epoch 31.384), train_loss = 0.74062427, grad/param norm = 1.6364e-01, time/batch = 15.5291s	
17890/28500 (epoch 31.386), train_loss = 0.79976867, grad/param norm = 1.5653e-01, time/batch = 15.3059s	
17891/28500 (epoch 31.388), train_loss = 0.98330827, grad/param norm = 1.7409e-01, time/batch = 15.2613s	
17892/28500 (epoch 31.389), train_loss = 0.83390506, grad/param norm = 1.7122e-01, time/batch = 14.9881s	
17893/28500 (epoch 31.391), train_loss = 0.77244528, grad/param norm = 1.7077e-01, time/batch = 15.1328s	
17894/28500 (epoch 31.393), train_loss = 0.82976946, grad/param norm = 1.9003e-01, time/batch = 15.1407s	
17895/28500 (epoch 31.395), train_loss = 0.98941747, grad/param norm = 1.6097e-01, time/batch = 15.0426s	
17896/28500 (epoch 31.396), train_loss = 0.96080289, grad/param norm = 1.7881e-01, time/batch = 14.9867s	
17897/28500 (epoch 31.398), train_loss = 0.67946559, grad/param norm = 1.7971e-01, time/batch = 15.0375s	
17898/28500 (epoch 31.400), train_loss = 0.87066473, grad/param norm = 1.9192e-01, time/batch = 15.1350s	
17899/28500 (epoch 31.402), train_loss = 0.91291017, grad/param norm = 2.8728e-01, time/batch = 15.6315s	
17900/28500 (epoch 31.404), train_loss = 0.91125924, grad/param norm = 1.9038e-01, time/batch = 15.1635s	
17901/28500 (epoch 31.405), train_loss = 0.94085129, grad/param norm = 1.7874e-01, time/batch = 15.1819s	
17902/28500 (epoch 31.407), train_loss = 0.89981696, grad/param norm = 1.6541e-01, time/batch = 15.5604s	
17903/28500 (epoch 31.409), train_loss = 0.91286399, grad/param norm = 1.7890e-01, time/batch = 15.3583s	
17904/28500 (epoch 31.411), train_loss = 1.00319939, grad/param norm = 2.0032e-01, time/batch = 15.2230s	
17905/28500 (epoch 31.412), train_loss = 1.03347448, grad/param norm = 1.9619e-01, time/batch = 15.4381s	
17906/28500 (epoch 31.414), train_loss = 0.91286417, grad/param norm = 1.8206e-01, time/batch = 15.5665s	
17907/28500 (epoch 31.416), train_loss = 0.83207169, grad/param norm = 1.7177e-01, time/batch = 15.4763s	
17908/28500 (epoch 31.418), train_loss = 0.92766388, grad/param norm = 1.5684e-01, time/batch = 15.5562s	
17909/28500 (epoch 31.419), train_loss = 1.00063185, grad/param norm = 1.9965e-01, time/batch = 15.4963s	
17910/28500 (epoch 31.421), train_loss = 0.97328559, grad/param norm = 1.7645e-01, time/batch = 15.3100s	
17911/28500 (epoch 31.423), train_loss = 0.97717630, grad/param norm = 1.8079e-01, time/batch = 15.3991s	
17912/28500 (epoch 31.425), train_loss = 0.91072494, grad/param norm = 1.8735e-01, time/batch = 15.2937s	
17913/28500 (epoch 31.426), train_loss = 0.90576811, grad/param norm = 1.9030e-01, time/batch = 15.1797s	
17914/28500 (epoch 31.428), train_loss = 1.05124912, grad/param norm = 2.0014e-01, time/batch = 15.0870s	
17915/28500 (epoch 31.430), train_loss = 1.03524004, grad/param norm = 1.6321e-01, time/batch = 15.3757s	
17916/28500 (epoch 31.432), train_loss = 0.91170800, grad/param norm = 1.9658e-01, time/batch = 15.2833s	
17917/28500 (epoch 31.433), train_loss = 0.95887747, grad/param norm = 1.8356e-01, time/batch = 15.3086s	
17918/28500 (epoch 31.435), train_loss = 0.94086393, grad/param norm = 1.8994e-01, time/batch = 15.0734s	
17919/28500 (epoch 31.437), train_loss = 0.84126718, grad/param norm = 1.6119e-01, time/batch = 15.1704s	
17920/28500 (epoch 31.439), train_loss = 0.87980955, grad/param norm = 1.5482e-01, time/batch = 15.2359s	
17921/28500 (epoch 31.440), train_loss = 1.04623654, grad/param norm = 1.8423e-01, time/batch = 15.3831s	
17922/28500 (epoch 31.442), train_loss = 0.83490716, grad/param norm = 1.7581e-01, time/batch = 15.5688s	
17923/28500 (epoch 31.444), train_loss = 0.78985245, grad/param norm = 1.4377e-01, time/batch = 15.3227s	
17924/28500 (epoch 31.446), train_loss = 0.75638614, grad/param norm = 1.5572e-01, time/batch = 15.4583s	
17925/28500 (epoch 31.447), train_loss = 0.78575711, grad/param norm = 1.6353e-01, time/batch = 15.3883s	
17926/28500 (epoch 31.449), train_loss = 0.87323762, grad/param norm = 1.6484e-01, time/batch = 15.2698s	
17927/28500 (epoch 31.451), train_loss = 0.88931892, grad/param norm = 1.7357e-01, time/batch = 15.2344s	
17928/28500 (epoch 31.453), train_loss = 0.87341177, grad/param norm = 1.7240e-01, time/batch = 15.3649s	
17929/28500 (epoch 31.454), train_loss = 0.82228394, grad/param norm = 1.4884e-01, time/batch = 15.3213s	
17930/28500 (epoch 31.456), train_loss = 0.95163340, grad/param norm = 1.8807e-01, time/batch = 15.2216s	
17931/28500 (epoch 31.458), train_loss = 0.88630092, grad/param norm = 1.8061e-01, time/batch = 15.2008s	
17932/28500 (epoch 31.460), train_loss = 0.95677109, grad/param norm = 1.7429e-01, time/batch = 15.1037s	
17933/28500 (epoch 31.461), train_loss = 0.82402163, grad/param norm = 1.8402e-01, time/batch = 15.1953s	
17934/28500 (epoch 31.463), train_loss = 0.74943908, grad/param norm = 1.4741e-01, time/batch = 15.2769s	
17935/28500 (epoch 31.465), train_loss = 0.76425197, grad/param norm = 1.8388e-01, time/batch = 15.4916s	
17936/28500 (epoch 31.467), train_loss = 0.90608857, grad/param norm = 1.7659e-01, time/batch = 15.5085s	
17937/28500 (epoch 31.468), train_loss = 0.79456214, grad/param norm = 1.5339e-01, time/batch = 15.3839s	
17938/28500 (epoch 31.470), train_loss = 0.86214298, grad/param norm = 2.0105e-01, time/batch = 15.3515s	
17939/28500 (epoch 31.472), train_loss = 0.81737444, grad/param norm = 1.5646e-01, time/batch = 15.3321s	
17940/28500 (epoch 31.474), train_loss = 1.02416086, grad/param norm = 1.9935e-01, time/batch = 15.4760s	
17941/28500 (epoch 31.475), train_loss = 0.82615382, grad/param norm = 1.6774e-01, time/batch = 15.3700s	
17942/28500 (epoch 31.477), train_loss = 0.84921811, grad/param norm = 1.7141e-01, time/batch = 15.0581s	
17943/28500 (epoch 31.479), train_loss = 0.92455578, grad/param norm = 1.6600e-01, time/batch = 15.2759s	
17944/28500 (epoch 31.481), train_loss = 0.95621398, grad/param norm = 1.7165e-01, time/batch = 15.4068s	
17945/28500 (epoch 31.482), train_loss = 0.78273145, grad/param norm = 1.6209e-01, time/batch = 15.1911s	
17946/28500 (epoch 31.484), train_loss = 0.81699447, grad/param norm = 1.8530e-01, time/batch = 15.2952s	
17947/28500 (epoch 31.486), train_loss = 0.72458894, grad/param norm = 1.8212e-01, time/batch = 15.3749s	
17948/28500 (epoch 31.488), train_loss = 0.93682794, grad/param norm = 1.6964e-01, time/batch = 15.6327s	
17949/28500 (epoch 31.489), train_loss = 1.00998585, grad/param norm = 1.6601e-01, time/batch = 15.4760s	
17950/28500 (epoch 31.491), train_loss = 0.82748277, grad/param norm = 1.7821e-01, time/batch = 15.4597s	
17951/28500 (epoch 31.493), train_loss = 0.88028867, grad/param norm = 1.5966e-01, time/batch = 15.3785s	
17952/28500 (epoch 31.495), train_loss = 0.90410259, grad/param norm = 1.7782e-01, time/batch = 15.2522s	
17953/28500 (epoch 31.496), train_loss = 0.81317074, grad/param norm = 1.8452e-01, time/batch = 15.2808s	
17954/28500 (epoch 31.498), train_loss = 0.85517285, grad/param norm = 1.6212e-01, time/batch = 15.0861s	
17955/28500 (epoch 31.500), train_loss = 0.81679829, grad/param norm = 1.6668e-01, time/batch = 15.2789s	
17956/28500 (epoch 31.502), train_loss = 0.93705391, grad/param norm = 1.6305e-01, time/batch = 15.3679s	
17957/28500 (epoch 31.504), train_loss = 0.92253103, grad/param norm = 1.7214e-01, time/batch = 15.3198s	
17958/28500 (epoch 31.505), train_loss = 0.83170497, grad/param norm = 1.7578e-01, time/batch = 15.4654s	
17959/28500 (epoch 31.507), train_loss = 0.99092673, grad/param norm = 2.5638e-01, time/batch = 15.3636s	
17960/28500 (epoch 31.509), train_loss = 0.89907295, grad/param norm = 1.6805e-01, time/batch = 15.3819s	
17961/28500 (epoch 31.511), train_loss = 0.90212823, grad/param norm = 1.8494e-01, time/batch = 15.4711s	
17962/28500 (epoch 31.512), train_loss = 0.93873935, grad/param norm = 1.9546e-01, time/batch = 15.5560s	
17963/28500 (epoch 31.514), train_loss = 0.88992203, grad/param norm = 1.6645e-01, time/batch = 15.5422s	
17964/28500 (epoch 31.516), train_loss = 0.87781921, grad/param norm = 1.6529e-01, time/batch = 15.5389s	
17965/28500 (epoch 31.518), train_loss = 0.92726178, grad/param norm = 1.6316e-01, time/batch = 15.3071s	
17966/28500 (epoch 31.519), train_loss = 0.95957340, grad/param norm = 1.8003e-01, time/batch = 15.5098s	
17967/28500 (epoch 31.521), train_loss = 1.02725319, grad/param norm = 2.0075e-01, time/batch = 15.6535s	
17968/28500 (epoch 31.523), train_loss = 0.95484462, grad/param norm = 1.9606e-01, time/batch = 15.5573s	
17969/28500 (epoch 31.525), train_loss = 1.01380771, grad/param norm = 1.8466e-01, time/batch = 15.3162s	
17970/28500 (epoch 31.526), train_loss = 0.96303554, grad/param norm = 1.7430e-01, time/batch = 15.2958s	
17971/28500 (epoch 31.528), train_loss = 0.94036662, grad/param norm = 1.9130e-01, time/batch = 15.3799s	
17972/28500 (epoch 31.530), train_loss = 0.96302557, grad/param norm = 1.6953e-01, time/batch = 15.5343s	
17973/28500 (epoch 31.532), train_loss = 0.87311859, grad/param norm = 1.6383e-01, time/batch = 15.5683s	
17974/28500 (epoch 31.533), train_loss = 0.95162165, grad/param norm = 1.9554e-01, time/batch = 15.5857s	
17975/28500 (epoch 31.535), train_loss = 0.77966678, grad/param norm = 1.5883e-01, time/batch = 15.4283s	
17976/28500 (epoch 31.537), train_loss = 0.81694371, grad/param norm = 1.6390e-01, time/batch = 15.1992s	
17977/28500 (epoch 31.539), train_loss = 0.75321926, grad/param norm = 1.6818e-01, time/batch = 15.0501s	
17978/28500 (epoch 31.540), train_loss = 0.90706919, grad/param norm = 1.7089e-01, time/batch = 15.1720s	
17979/28500 (epoch 31.542), train_loss = 0.95520000, grad/param norm = 2.0129e-01, time/batch = 15.5077s	
17980/28500 (epoch 31.544), train_loss = 1.03337260, grad/param norm = 2.0327e-01, time/batch = 15.1434s	
17981/28500 (epoch 31.546), train_loss = 0.89463702, grad/param norm = 1.7476e-01, time/batch = 15.1416s	
17982/28500 (epoch 31.547), train_loss = 0.88380478, grad/param norm = 1.6044e-01, time/batch = 15.2126s	
17983/28500 (epoch 31.549), train_loss = 0.72801017, grad/param norm = 1.3445e-01, time/batch = 15.2004s	
17984/28500 (epoch 31.551), train_loss = 0.87244772, grad/param norm = 1.9829e-01, time/batch = 15.3758s	
17985/28500 (epoch 31.553), train_loss = 1.06203679, grad/param norm = 1.9773e-01, time/batch = 15.2848s	
17986/28500 (epoch 31.554), train_loss = 0.94880520, grad/param norm = 1.8266e-01, time/batch = 15.2915s	
17987/28500 (epoch 31.556), train_loss = 0.94469426, grad/param norm = 2.1323e-01, time/batch = 15.7154s	
17988/28500 (epoch 31.558), train_loss = 0.95964989, grad/param norm = 1.7094e-01, time/batch = 15.6288s	
17989/28500 (epoch 31.560), train_loss = 0.93747939, grad/param norm = 1.8744e-01, time/batch = 15.4772s	
17990/28500 (epoch 31.561), train_loss = 0.96595540, grad/param norm = 1.8527e-01, time/batch = 15.3849s	
17991/28500 (epoch 31.563), train_loss = 1.01952149, grad/param norm = 1.9024e-01, time/batch = 15.4732s	
17992/28500 (epoch 31.565), train_loss = 0.82800891, grad/param norm = 1.7790e-01, time/batch = 15.4985s	
17993/28500 (epoch 31.567), train_loss = 0.77906974, grad/param norm = 1.4866e-01, time/batch = 15.3586s	
17994/28500 (epoch 31.568), train_loss = 0.94629382, grad/param norm = 1.9036e-01, time/batch = 15.3380s	
17995/28500 (epoch 31.570), train_loss = 0.87813136, grad/param norm = 1.7414e-01, time/batch = 14.9924s	
17996/28500 (epoch 31.572), train_loss = 0.91504135, grad/param norm = 1.8311e-01, time/batch = 15.0203s	
17997/28500 (epoch 31.574), train_loss = 0.83957169, grad/param norm = 1.6434e-01, time/batch = 15.1438s	
17998/28500 (epoch 31.575), train_loss = 0.85880960, grad/param norm = 1.7153e-01, time/batch = 15.1724s	
17999/28500 (epoch 31.577), train_loss = 0.92764654, grad/param norm = 1.6140e-01, time/batch = 15.1405s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch31.58_1.8467.t7	
18000/28500 (epoch 31.579), train_loss = 0.95903941, grad/param norm = 1.6417e-01, time/batch = 15.2275s	
18001/28500 (epoch 31.581), train_loss = 1.32441287, grad/param norm = 2.5306e-01, time/batch = 15.7275s	
18002/28500 (epoch 31.582), train_loss = 0.99760583, grad/param norm = 1.8664e-01, time/batch = 15.6163s	
18003/28500 (epoch 31.584), train_loss = 0.86287499, grad/param norm = 1.8047e-01, time/batch = 15.5402s	
18004/28500 (epoch 31.586), train_loss = 0.83154019, grad/param norm = 1.5160e-01, time/batch = 15.3930s	
18005/28500 (epoch 31.588), train_loss = 0.84036469, grad/param norm = 1.8106e-01, time/batch = 15.2203s	
18006/28500 (epoch 31.589), train_loss = 0.87983327, grad/param norm = 1.8757e-01, time/batch = 15.8800s	
18007/28500 (epoch 31.591), train_loss = 0.91547222, grad/param norm = 1.6839e-01, time/batch = 15.6410s	
18008/28500 (epoch 31.593), train_loss = 0.86437430, grad/param norm = 1.8334e-01, time/batch = 15.5527s	
18009/28500 (epoch 31.595), train_loss = 1.08946743, grad/param norm = 2.1982e-01, time/batch = 15.3779s	
18010/28500 (epoch 31.596), train_loss = 1.07186931, grad/param norm = 1.7681e-01, time/batch = 15.5200s	
18011/28500 (epoch 31.598), train_loss = 0.88222191, grad/param norm = 1.6403e-01, time/batch = 15.3567s	
18012/28500 (epoch 31.600), train_loss = 0.90584766, grad/param norm = 1.8844e-01, time/batch = 15.2384s	
18013/28500 (epoch 31.602), train_loss = 0.95385605, grad/param norm = 1.8342e-01, time/batch = 15.2637s	
18014/28500 (epoch 31.604), train_loss = 0.98475289, grad/param norm = 1.6347e-01, time/batch = 15.4582s	
18015/28500 (epoch 31.605), train_loss = 0.98145866, grad/param norm = 2.0093e-01, time/batch = 15.2799s	
18016/28500 (epoch 31.607), train_loss = 1.01224017, grad/param norm = 1.7434e-01, time/batch = 15.2864s	
18017/28500 (epoch 31.609), train_loss = 0.94172141, grad/param norm = 2.0882e-01, time/batch = 15.3505s	
18018/28500 (epoch 31.611), train_loss = 0.88816456, grad/param norm = 2.0475e-01, time/batch = 15.2999s	
18019/28500 (epoch 31.612), train_loss = 0.96685483, grad/param norm = 1.9815e-01, time/batch = 15.4994s	
18020/28500 (epoch 31.614), train_loss = 0.96155530, grad/param norm = 1.8108e-01, time/batch = 15.6360s	
18021/28500 (epoch 31.616), train_loss = 0.86927213, grad/param norm = 1.9158e-01, time/batch = 15.5470s	
18022/28500 (epoch 31.618), train_loss = 0.88823870, grad/param norm = 1.8601e-01, time/batch = 15.4904s	
18023/28500 (epoch 31.619), train_loss = 0.98520854, grad/param norm = 1.9100e-01, time/batch = 15.4893s	
18024/28500 (epoch 31.621), train_loss = 0.73799827, grad/param norm = 1.5383e-01, time/batch = 15.3869s	
18025/28500 (epoch 31.623), train_loss = 0.99924070, grad/param norm = 1.8292e-01, time/batch = 15.4752s	
18026/28500 (epoch 31.625), train_loss = 0.82701388, grad/param norm = 1.8176e-01, time/batch = 15.4283s	
18027/28500 (epoch 31.626), train_loss = 0.69677091, grad/param norm = 1.4418e-01, time/batch = 15.1483s	
18028/28500 (epoch 31.628), train_loss = 0.82209988, grad/param norm = 1.6213e-01, time/batch = 15.2085s	
18029/28500 (epoch 31.630), train_loss = 0.76866046, grad/param norm = 1.4743e-01, time/batch = 15.2278s	
18030/28500 (epoch 31.632), train_loss = 0.99526266, grad/param norm = 1.9766e-01, time/batch = 15.1483s	
18031/28500 (epoch 31.633), train_loss = 1.05563387, grad/param norm = 1.7459e-01, time/batch = 15.2258s	
18032/28500 (epoch 31.635), train_loss = 0.95694815, grad/param norm = 1.7977e-01, time/batch = 14.9070s	
18033/28500 (epoch 31.637), train_loss = 0.90670958, grad/param norm = 1.6066e-01, time/batch = 14.9781s	
18034/28500 (epoch 31.639), train_loss = 0.82842757, grad/param norm = 1.9102e-01, time/batch = 15.1367s	
18035/28500 (epoch 31.640), train_loss = 0.83421842, grad/param norm = 1.7439e-01, time/batch = 15.2653s	
18036/28500 (epoch 31.642), train_loss = 0.84375194, grad/param norm = 1.5978e-01, time/batch = 15.2963s	
18037/28500 (epoch 31.644), train_loss = 0.95142782, grad/param norm = 1.7083e-01, time/batch = 15.5337s	
18038/28500 (epoch 31.646), train_loss = 0.75518813, grad/param norm = 1.3665e-01, time/batch = 15.2211s	
18039/28500 (epoch 31.647), train_loss = 0.82412948, grad/param norm = 1.6946e-01, time/batch = 15.4111s	
18040/28500 (epoch 31.649), train_loss = 0.79671786, grad/param norm = 1.6994e-01, time/batch = 15.3392s	
18041/28500 (epoch 31.651), train_loss = 0.78811026, grad/param norm = 1.5770e-01, time/batch = 15.4401s	
18042/28500 (epoch 31.653), train_loss = 0.77221843, grad/param norm = 1.6616e-01, time/batch = 15.2391s	
18043/28500 (epoch 31.654), train_loss = 0.82967509, grad/param norm = 1.8719e-01, time/batch = 15.1663s	
18044/28500 (epoch 31.656), train_loss = 0.80327954, grad/param norm = 1.9735e-01, time/batch = 15.3029s	
18045/28500 (epoch 31.658), train_loss = 0.88238785, grad/param norm = 1.7198e-01, time/batch = 15.2175s	
18046/28500 (epoch 31.660), train_loss = 0.90513672, grad/param norm = 1.6892e-01, time/batch = 14.9738s	
18047/28500 (epoch 31.661), train_loss = 0.99740082, grad/param norm = 1.9092e-01, time/batch = 15.2824s	
18048/28500 (epoch 31.663), train_loss = 0.99868436, grad/param norm = 1.7311e-01, time/batch = 15.0423s	
18049/28500 (epoch 31.665), train_loss = 0.88940194, grad/param norm = 1.6870e-01, time/batch = 15.4625s	
18050/28500 (epoch 31.667), train_loss = 0.87506502, grad/param norm = 1.8595e-01, time/batch = 15.4310s	
18051/28500 (epoch 31.668), train_loss = 0.89572836, grad/param norm = 1.8159e-01, time/batch = 15.5615s	
18052/28500 (epoch 31.670), train_loss = 0.89832220, grad/param norm = 1.7047e-01, time/batch = 15.4066s	
18053/28500 (epoch 31.672), train_loss = 0.81445292, grad/param norm = 1.6335e-01, time/batch = 15.4903s	
18054/28500 (epoch 31.674), train_loss = 0.71483282, grad/param norm = 1.6882e-01, time/batch = 15.3669s	
18055/28500 (epoch 31.675), train_loss = 0.75219208, grad/param norm = 1.5223e-01, time/batch = 15.2050s	
18056/28500 (epoch 31.677), train_loss = 0.85036862, grad/param norm = 1.5720e-01, time/batch = 15.3710s	
18057/28500 (epoch 31.679), train_loss = 0.84739268, grad/param norm = 1.7133e-01, time/batch = 15.2096s	
18058/28500 (epoch 31.681), train_loss = 0.93621076, grad/param norm = 1.7646e-01, time/batch = 15.1313s	
18059/28500 (epoch 31.682), train_loss = 0.82059535, grad/param norm = 1.5477e-01, time/batch = 15.3134s	
18060/28500 (epoch 31.684), train_loss = 0.89615292, grad/param norm = 1.6899e-01, time/batch = 15.4584s	
18061/28500 (epoch 31.686), train_loss = 0.83862406, grad/param norm = 1.8484e-01, time/batch = 15.5663s	
18062/28500 (epoch 31.688), train_loss = 0.81009524, grad/param norm = 1.3679e-01, time/batch = 15.2151s	
18063/28500 (epoch 31.689), train_loss = 0.83626489, grad/param norm = 1.9849e-01, time/batch = 15.5509s	
18064/28500 (epoch 31.691), train_loss = 0.91336864, grad/param norm = 1.6954e-01, time/batch = 15.5129s	
18065/28500 (epoch 31.693), train_loss = 0.84841290, grad/param norm = 1.7319e-01, time/batch = 15.3028s	
18066/28500 (epoch 31.695), train_loss = 0.66811620, grad/param norm = 1.6617e-01, time/batch = 15.3483s	
18067/28500 (epoch 31.696), train_loss = 0.85606178, grad/param norm = 1.5855e-01, time/batch = 15.2246s	
18068/28500 (epoch 31.698), train_loss = 0.90333715, grad/param norm = 1.6407e-01, time/batch = 15.2010s	
18069/28500 (epoch 31.700), train_loss = 0.90871726, grad/param norm = 1.8839e-01, time/batch = 14.9702s	
18070/28500 (epoch 31.702), train_loss = 0.89969819, grad/param norm = 1.9166e-01, time/batch = 15.1324s	
18071/28500 (epoch 31.704), train_loss = 0.92197567, grad/param norm = 2.0526e-01, time/batch = 15.6516s	
18072/28500 (epoch 31.705), train_loss = 0.97716395, grad/param norm = 2.0685e-01, time/batch = 15.6254s	
18073/28500 (epoch 31.707), train_loss = 0.83219895, grad/param norm = 1.8429e-01, time/batch = 15.4729s	
18074/28500 (epoch 31.709), train_loss = 1.01014753, grad/param norm = 1.8677e-01, time/batch = 15.5428s	
18075/28500 (epoch 31.711), train_loss = 0.84064597, grad/param norm = 1.7966e-01, time/batch = 15.6230s	
18076/28500 (epoch 31.712), train_loss = 0.90750543, grad/param norm = 1.7405e-01, time/batch = 15.5088s	
18077/28500 (epoch 31.714), train_loss = 1.02009860, grad/param norm = 2.2849e-01, time/batch = 15.3031s	
18078/28500 (epoch 31.716), train_loss = 0.87166317, grad/param norm = 1.5650e-01, time/batch = 15.3509s	
18079/28500 (epoch 31.718), train_loss = 0.90521533, grad/param norm = 1.7942e-01, time/batch = 15.5635s	
18080/28500 (epoch 31.719), train_loss = 0.90267456, grad/param norm = 1.7809e-01, time/batch = 15.6357s	
18081/28500 (epoch 31.721), train_loss = 0.71706882, grad/param norm = 1.7050e-01, time/batch = 15.7154s	
18082/28500 (epoch 31.723), train_loss = 0.89500821, grad/param norm = 1.6677e-01, time/batch = 15.3146s	
18083/28500 (epoch 31.725), train_loss = 0.95147702, grad/param norm = 1.6716e-01, time/batch = 15.4707s	
18084/28500 (epoch 31.726), train_loss = 0.88800920, grad/param norm = 1.8246e-01, time/batch = 15.4599s	
18085/28500 (epoch 31.728), train_loss = 0.80376065, grad/param norm = 1.6022e-01, time/batch = 15.5394s	
18086/28500 (epoch 31.730), train_loss = 0.88003931, grad/param norm = 1.7280e-01, time/batch = 15.6226s	
18087/28500 (epoch 31.732), train_loss = 0.71035788, grad/param norm = 1.5166e-01, time/batch = 15.5301s	
18088/28500 (epoch 31.733), train_loss = 0.75153506, grad/param norm = 1.5729e-01, time/batch = 15.3139s	
18089/28500 (epoch 31.735), train_loss = 0.75577322, grad/param norm = 1.4506e-01, time/batch = 15.3115s	
18090/28500 (epoch 31.737), train_loss = 0.69398088, grad/param norm = 1.4289e-01, time/batch = 15.4566s	
18091/28500 (epoch 31.739), train_loss = 0.80305959, grad/param norm = 1.7924e-01, time/batch = 15.5444s	
18092/28500 (epoch 31.740), train_loss = 0.87844690, grad/param norm = 1.6147e-01, time/batch = 15.4200s	
18093/28500 (epoch 31.742), train_loss = 0.79716050, grad/param norm = 1.6517e-01, time/batch = 15.2309s	
18094/28500 (epoch 31.744), train_loss = 0.88896449, grad/param norm = 1.7600e-01, time/batch = 15.3202s	
18095/28500 (epoch 31.746), train_loss = 0.82174117, grad/param norm = 1.5929e-01, time/batch = 27.5507s	
18096/28500 (epoch 31.747), train_loss = 0.80675019, grad/param norm = 1.4571e-01, time/batch = 15.1314s	
18097/28500 (epoch 31.749), train_loss = 0.93689067, grad/param norm = 2.0227e-01, time/batch = 15.4501s	
18098/28500 (epoch 31.751), train_loss = 0.77321170, grad/param norm = 1.8166e-01, time/batch = 15.2862s	
18099/28500 (epoch 31.753), train_loss = 0.86028334, grad/param norm = 1.4765e-01, time/batch = 15.3581s	
18100/28500 (epoch 31.754), train_loss = 0.78271470, grad/param norm = 1.5437e-01, time/batch = 15.5033s	
18101/28500 (epoch 31.756), train_loss = 0.99373074, grad/param norm = 2.0323e-01, time/batch = 15.5507s	
18102/28500 (epoch 31.758), train_loss = 0.94023312, grad/param norm = 1.9179e-01, time/batch = 15.6551s	
18103/28500 (epoch 31.760), train_loss = 0.78164880, grad/param norm = 2.0242e-01, time/batch = 15.7092s	
18104/28500 (epoch 31.761), train_loss = 0.81100190, grad/param norm = 1.7323e-01, time/batch = 15.4690s	
18105/28500 (epoch 31.763), train_loss = 0.70099827, grad/param norm = 1.5380e-01, time/batch = 15.1571s	
18106/28500 (epoch 31.765), train_loss = 0.84400978, grad/param norm = 1.5586e-01, time/batch = 15.2175s	
18107/28500 (epoch 31.767), train_loss = 0.74024563, grad/param norm = 1.4048e-01, time/batch = 15.0973s	
18108/28500 (epoch 31.768), train_loss = 0.92035487, grad/param norm = 1.7314e-01, time/batch = 15.2215s	
18109/28500 (epoch 31.770), train_loss = 0.77066250, grad/param norm = 1.6006e-01, time/batch = 15.4419s	
18110/28500 (epoch 31.772), train_loss = 0.70634192, grad/param norm = 1.4838e-01, time/batch = 15.6320s	
18111/28500 (epoch 31.774), train_loss = 0.87168197, grad/param norm = 1.7000e-01, time/batch = 15.2163s	
18112/28500 (epoch 31.775), train_loss = 0.94763033, grad/param norm = 1.6028e-01, time/batch = 15.1573s	
18113/28500 (epoch 31.777), train_loss = 0.94266271, grad/param norm = 1.6825e-01, time/batch = 15.6266s	
18114/28500 (epoch 31.779), train_loss = 0.71112842, grad/param norm = 1.3500e-01, time/batch = 15.5514s	
18115/28500 (epoch 31.781), train_loss = 0.85842368, grad/param norm = 1.8598e-01, time/batch = 15.4231s	
18116/28500 (epoch 31.782), train_loss = 0.88481087, grad/param norm = 1.9934e-01, time/batch = 15.3625s	
18117/28500 (epoch 31.784), train_loss = 0.70135485, grad/param norm = 1.6636e-01, time/batch = 15.3701s	
18118/28500 (epoch 31.786), train_loss = 0.74541400, grad/param norm = 1.5016e-01, time/batch = 15.4816s	
18119/28500 (epoch 31.788), train_loss = 0.85574831, grad/param norm = 1.9926e-01, time/batch = 15.1976s	
18120/28500 (epoch 31.789), train_loss = 0.63774820, grad/param norm = 1.8927e-01, time/batch = 15.0709s	
18121/28500 (epoch 31.791), train_loss = 0.87584006, grad/param norm = 1.6886e-01, time/batch = 15.3845s	
18122/28500 (epoch 31.793), train_loss = 0.85552851, grad/param norm = 1.6909e-01, time/batch = 15.4722s	
18123/28500 (epoch 31.795), train_loss = 0.88776259, grad/param norm = 1.6676e-01, time/batch = 15.4843s	
18124/28500 (epoch 31.796), train_loss = 0.77133025, grad/param norm = 1.6425e-01, time/batch = 15.5569s	
18125/28500 (epoch 31.798), train_loss = 0.72022186, grad/param norm = 1.6747e-01, time/batch = 15.6115s	
18126/28500 (epoch 31.800), train_loss = 0.74606336, grad/param norm = 1.9697e-01, time/batch = 15.6150s	
18127/28500 (epoch 31.802), train_loss = 0.83814648, grad/param norm = 2.3540e-01, time/batch = 15.4597s	
18128/28500 (epoch 31.804), train_loss = 0.89158625, grad/param norm = 1.6004e-01, time/batch = 15.3772s	
18129/28500 (epoch 31.805), train_loss = 0.87231142, grad/param norm = 1.6899e-01, time/batch = 15.0962s	
18130/28500 (epoch 31.807), train_loss = 0.87970263, grad/param norm = 1.7628e-01, time/batch = 15.2262s	
18131/28500 (epoch 31.809), train_loss = 0.88133626, grad/param norm = 2.1466e-01, time/batch = 15.3863s	
18132/28500 (epoch 31.811), train_loss = 0.90561875, grad/param norm = 1.7866e-01, time/batch = 15.4171s	
18133/28500 (epoch 31.812), train_loss = 0.89318220, grad/param norm = 2.0617e-01, time/batch = 15.3498s	
18134/28500 (epoch 31.814), train_loss = 0.82378872, grad/param norm = 1.9142e-01, time/batch = 15.1175s	
18135/28500 (epoch 31.816), train_loss = 0.92451758, grad/param norm = 2.1030e-01, time/batch = 15.2889s	
18136/28500 (epoch 31.818), train_loss = 1.00812721, grad/param norm = 2.0147e-01, time/batch = 15.0485s	
18137/28500 (epoch 31.819), train_loss = 0.86169768, grad/param norm = 1.6474e-01, time/batch = 15.5819s	
18138/28500 (epoch 31.821), train_loss = 0.82184884, grad/param norm = 1.6355e-01, time/batch = 15.6427s	
18139/28500 (epoch 31.823), train_loss = 0.99608390, grad/param norm = 2.0628e-01, time/batch = 15.4664s	
18140/28500 (epoch 31.825), train_loss = 0.83491388, grad/param norm = 2.2380e-01, time/batch = 15.5501s	
18141/28500 (epoch 31.826), train_loss = 0.89707735, grad/param norm = 2.0969e-01, time/batch = 15.4563s	
18142/28500 (epoch 31.828), train_loss = 0.79344086, grad/param norm = 1.8816e-01, time/batch = 15.3933s	
18143/28500 (epoch 31.830), train_loss = 0.83075102, grad/param norm = 1.5451e-01, time/batch = 15.5233s	
18144/28500 (epoch 31.832), train_loss = 0.87120166, grad/param norm = 1.9870e-01, time/batch = 15.5135s	
18145/28500 (epoch 31.833), train_loss = 0.95012902, grad/param norm = 1.7791e-01, time/batch = 15.3418s	
18146/28500 (epoch 31.835), train_loss = 0.81058337, grad/param norm = 1.6584e-01, time/batch = 15.3460s	
18147/28500 (epoch 31.837), train_loss = 0.76233707, grad/param norm = 1.7559e-01, time/batch = 15.4272s	
18148/28500 (epoch 31.839), train_loss = 1.02027005, grad/param norm = 2.1790e-01, time/batch = 15.5490s	
18149/28500 (epoch 31.840), train_loss = 1.01688355, grad/param norm = 2.0445e-01, time/batch = 15.5461s	
18150/28500 (epoch 31.842), train_loss = 0.93097069, grad/param norm = 2.0589e-01, time/batch = 15.5593s	
18151/28500 (epoch 31.844), train_loss = 0.92550796, grad/param norm = 1.7952e-01, time/batch = 15.5578s	
18152/28500 (epoch 31.846), train_loss = 1.02318973, grad/param norm = 2.1257e-01, time/batch = 15.4539s	
18153/28500 (epoch 31.847), train_loss = 0.84141179, grad/param norm = 1.8396e-01, time/batch = 15.2268s	
18154/28500 (epoch 31.849), train_loss = 0.86022570, grad/param norm = 1.7490e-01, time/batch = 15.3918s	
18155/28500 (epoch 31.851), train_loss = 0.75336385, grad/param norm = 1.5785e-01, time/batch = 15.3808s	
18156/28500 (epoch 31.853), train_loss = 0.88750912, grad/param norm = 1.8136e-01, time/batch = 15.1874s	
18157/28500 (epoch 31.854), train_loss = 0.89616394, grad/param norm = 1.9078e-01, time/batch = 15.2771s	
18158/28500 (epoch 31.856), train_loss = 0.99729092, grad/param norm = 2.2094e-01, time/batch = 15.4296s	
18159/28500 (epoch 31.858), train_loss = 0.82877074, grad/param norm = 1.8368e-01, time/batch = 15.3887s	
18160/28500 (epoch 31.860), train_loss = 0.84841996, grad/param norm = 1.8045e-01, time/batch = 15.5165s	
18161/28500 (epoch 31.861), train_loss = 0.92362960, grad/param norm = 1.9293e-01, time/batch = 15.5581s	
18162/28500 (epoch 31.863), train_loss = 0.89996699, grad/param norm = 1.9491e-01, time/batch = 15.4749s	
18163/28500 (epoch 31.865), train_loss = 0.81504782, grad/param norm = 1.6769e-01, time/batch = 15.4773s	
18164/28500 (epoch 31.867), train_loss = 0.91663793, grad/param norm = 2.0051e-01, time/batch = 15.6280s	
18165/28500 (epoch 31.868), train_loss = 0.78496426, grad/param norm = 1.6735e-01, time/batch = 15.2359s	
18166/28500 (epoch 31.870), train_loss = 0.75048462, grad/param norm = 1.6524e-01, time/batch = 15.1139s	
18167/28500 (epoch 31.872), train_loss = 0.92677909, grad/param norm = 1.8932e-01, time/batch = 14.9549s	
18168/28500 (epoch 31.874), train_loss = 0.78913606, grad/param norm = 1.7628e-01, time/batch = 15.4444s	
18169/28500 (epoch 31.875), train_loss = 1.01097030, grad/param norm = 1.9529e-01, time/batch = 15.2347s	
18170/28500 (epoch 31.877), train_loss = 0.90469805, grad/param norm = 1.7904e-01, time/batch = 15.3770s	
18171/28500 (epoch 31.879), train_loss = 0.92905811, grad/param norm = 1.5567e-01, time/batch = 15.6415s	
18172/28500 (epoch 31.881), train_loss = 0.90553929, grad/param norm = 1.8136e-01, time/batch = 15.3786s	
18173/28500 (epoch 31.882), train_loss = 0.80889763, grad/param norm = 1.6422e-01, time/batch = 15.1202s	
18174/28500 (epoch 31.884), train_loss = 0.87835193, grad/param norm = 1.9751e-01, time/batch = 15.2004s	
18175/28500 (epoch 31.886), train_loss = 0.84738809, grad/param norm = 1.8286e-01, time/batch = 15.1355s	
18176/28500 (epoch 31.888), train_loss = 0.81331266, grad/param norm = 1.6000e-01, time/batch = 15.2023s	
18177/28500 (epoch 31.889), train_loss = 0.87053895, grad/param norm = 1.4754e-01, time/batch = 14.9530s	
18178/28500 (epoch 31.891), train_loss = 0.87828861, grad/param norm = 1.6678e-01, time/batch = 15.2052s	
18179/28500 (epoch 31.893), train_loss = 0.85459634, grad/param norm = 2.1499e-01, time/batch = 15.2017s	
18180/28500 (epoch 31.895), train_loss = 1.03259451, grad/param norm = 2.1684e-01, time/batch = 15.2823s	
18181/28500 (epoch 31.896), train_loss = 0.95542455, grad/param norm = 1.9084e-01, time/batch = 15.3807s	
18182/28500 (epoch 31.898), train_loss = 0.89628505, grad/param norm = 1.7771e-01, time/batch = 15.4838s	
18183/28500 (epoch 31.900), train_loss = 0.75200963, grad/param norm = 1.6001e-01, time/batch = 15.4558s	
18184/28500 (epoch 31.902), train_loss = 0.75803993, grad/param norm = 1.7828e-01, time/batch = 15.5928s	
18185/28500 (epoch 31.904), train_loss = 0.77184320, grad/param norm = 1.6208e-01, time/batch = 15.3486s	
18186/28500 (epoch 31.905), train_loss = 0.83294118, grad/param norm = 1.8450e-01, time/batch = 15.3035s	
18187/28500 (epoch 31.907), train_loss = 0.87780281, grad/param norm = 2.2321e-01, time/batch = 15.3399s	
18188/28500 (epoch 31.909), train_loss = 0.75200167, grad/param norm = 1.9035e-01, time/batch = 15.3799s	
18189/28500 (epoch 31.911), train_loss = 0.78782724, grad/param norm = 1.6058e-01, time/batch = 15.4385s	
18190/28500 (epoch 31.912), train_loss = 0.68799637, grad/param norm = 1.7776e-01, time/batch = 15.2911s	
18191/28500 (epoch 31.914), train_loss = 0.89368350, grad/param norm = 1.8625e-01, time/batch = 15.6900s	
18192/28500 (epoch 31.916), train_loss = 0.87303553, grad/param norm = 1.7850e-01, time/batch = 15.4942s	
18193/28500 (epoch 31.918), train_loss = 0.85563653, grad/param norm = 1.7308e-01, time/batch = 15.5538s	
18194/28500 (epoch 31.919), train_loss = 0.85548483, grad/param norm = 1.5249e-01, time/batch = 15.5427s	
18195/28500 (epoch 31.921), train_loss = 0.96844073, grad/param norm = 2.0176e-01, time/batch = 15.4418s	
18196/28500 (epoch 31.923), train_loss = 0.82482528, grad/param norm = 1.9940e-01, time/batch = 15.1498s	
18197/28500 (epoch 31.925), train_loss = 0.80664097, grad/param norm = 1.9892e-01, time/batch = 15.1780s	
18198/28500 (epoch 31.926), train_loss = 0.87095722, grad/param norm = 1.7052e-01, time/batch = 15.0809s	
18199/28500 (epoch 31.928), train_loss = 0.81548584, grad/param norm = 1.6495e-01, time/batch = 15.2198s	
18200/28500 (epoch 31.930), train_loss = 0.68458885, grad/param norm = 1.5364e-01, time/batch = 15.5371s	
18201/28500 (epoch 31.932), train_loss = 0.69025039, grad/param norm = 1.3378e-01, time/batch = 15.4112s	
18202/28500 (epoch 31.933), train_loss = 0.91357946, grad/param norm = 1.8251e-01, time/batch = 15.3869s	
18203/28500 (epoch 31.935), train_loss = 0.95954348, grad/param norm = 1.8886e-01, time/batch = 15.3703s	
18204/28500 (epoch 31.937), train_loss = 0.97612399, grad/param norm = 2.2670e-01, time/batch = 15.1397s	
18205/28500 (epoch 31.939), train_loss = 1.00051822, grad/param norm = 1.9901e-01, time/batch = 15.0374s	
18206/28500 (epoch 31.940), train_loss = 0.75030174, grad/param norm = 1.8190e-01, time/batch = 15.2163s	
18207/28500 (epoch 31.942), train_loss = 0.84994865, grad/param norm = 1.7055e-01, time/batch = 15.1396s	
18208/28500 (epoch 31.944), train_loss = 0.82203666, grad/param norm = 2.0277e-01, time/batch = 15.3655s	
18209/28500 (epoch 31.946), train_loss = 0.93523148, grad/param norm = 1.7186e-01, time/batch = 15.1134s	
18210/28500 (epoch 31.947), train_loss = 1.11010881, grad/param norm = 2.4797e-01, time/batch = 15.2487s	
18211/28500 (epoch 31.949), train_loss = 0.85967741, grad/param norm = 2.0840e-01, time/batch = 15.8215s	
18212/28500 (epoch 31.951), train_loss = 1.01867125, grad/param norm = 1.9737e-01, time/batch = 15.4795s	
18213/28500 (epoch 31.953), train_loss = 1.02283603, grad/param norm = 2.1126e-01, time/batch = 15.1543s	
18214/28500 (epoch 31.954), train_loss = 0.97501423, grad/param norm = 2.0445e-01, time/batch = 15.2827s	
18215/28500 (epoch 31.956), train_loss = 0.87786168, grad/param norm = 2.8256e-01, time/batch = 15.1301s	
18216/28500 (epoch 31.958), train_loss = 1.09517914, grad/param norm = 1.7960e-01, time/batch = 15.1215s	
18217/28500 (epoch 31.960), train_loss = 0.81132414, grad/param norm = 1.8280e-01, time/batch = 15.3033s	
18218/28500 (epoch 31.961), train_loss = 1.03232522, grad/param norm = 2.3322e-01, time/batch = 15.4218s	
18219/28500 (epoch 31.963), train_loss = 0.97141984, grad/param norm = 1.8308e-01, time/batch = 15.5533s	
18220/28500 (epoch 31.965), train_loss = 0.79972129, grad/param norm = 1.8392e-01, time/batch = 15.4012s	
18221/28500 (epoch 31.967), train_loss = 0.81911696, grad/param norm = 1.7850e-01, time/batch = 15.2088s	
18222/28500 (epoch 31.968), train_loss = 0.76017784, grad/param norm = 1.4999e-01, time/batch = 15.1912s	
18223/28500 (epoch 31.970), train_loss = 0.79173030, grad/param norm = 1.6670e-01, time/batch = 15.3847s	
18224/28500 (epoch 31.972), train_loss = 0.88247023, grad/param norm = 1.9457e-01, time/batch = 15.5154s	
18225/28500 (epoch 31.974), train_loss = 1.05342640, grad/param norm = 1.9398e-01, time/batch = 15.5204s	
18226/28500 (epoch 31.975), train_loss = 0.82147649, grad/param norm = 1.7685e-01, time/batch = 15.4569s	
18227/28500 (epoch 31.977), train_loss = 0.94876504, grad/param norm = 1.8285e-01, time/batch = 15.4287s	
18228/28500 (epoch 31.979), train_loss = 0.89603536, grad/param norm = 1.8031e-01, time/batch = 15.4878s	
18229/28500 (epoch 31.981), train_loss = 0.77046183, grad/param norm = 1.7070e-01, time/batch = 15.1587s	
18230/28500 (epoch 31.982), train_loss = 0.85383494, grad/param norm = 1.7732e-01, time/batch = 15.3566s	
18231/28500 (epoch 31.984), train_loss = 0.94912748, grad/param norm = 1.6407e-01, time/batch = 15.3144s	
18232/28500 (epoch 31.986), train_loss = 1.13081865, grad/param norm = 1.9952e-01, time/batch = 15.2368s	
18233/28500 (epoch 31.988), train_loss = 0.79258501, grad/param norm = 1.7131e-01, time/batch = 15.2355s	
18234/28500 (epoch 31.989), train_loss = 0.91945824, grad/param norm = 1.8576e-01, time/batch = 15.2896s	
18235/28500 (epoch 31.991), train_loss = 0.81273959, grad/param norm = 1.9708e-01, time/batch = 15.3794s	
18236/28500 (epoch 31.993), train_loss = 0.79199020, grad/param norm = 1.6753e-01, time/batch = 15.3024s	
18237/28500 (epoch 31.995), train_loss = 0.82179662, grad/param norm = 1.9081e-01, time/batch = 15.4191s	
18238/28500 (epoch 31.996), train_loss = 0.78282649, grad/param norm = 1.7114e-01, time/batch = 15.5501s	
18239/28500 (epoch 31.998), train_loss = 0.96849750, grad/param norm = 2.2307e-01, time/batch = 15.3723s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
18240/28500 (epoch 32.000), train_loss = 0.86366270, grad/param norm = 1.7109e-01, time/batch = 15.2312s	
18241/28500 (epoch 32.002), train_loss = 1.02907460, grad/param norm = 1.8193e-01, time/batch = 15.3837s	
18242/28500 (epoch 32.004), train_loss = 0.84133088, grad/param norm = 1.5036e-01, time/batch = 15.5698s	
18243/28500 (epoch 32.005), train_loss = 0.99256767, grad/param norm = 2.0153e-01, time/batch = 15.5401s	
18244/28500 (epoch 32.007), train_loss = 0.78599229, grad/param norm = 1.6324e-01, time/batch = 15.5422s	
18245/28500 (epoch 32.009), train_loss = 0.89044377, grad/param norm = 1.8429e-01, time/batch = 15.2237s	
18246/28500 (epoch 32.011), train_loss = 0.82722250, grad/param norm = 2.0044e-01, time/batch = 15.2925s	
18247/28500 (epoch 32.012), train_loss = 0.77545034, grad/param norm = 1.5082e-01, time/batch = 15.3533s	
18248/28500 (epoch 32.014), train_loss = 0.78341880, grad/param norm = 1.8358e-01, time/batch = 15.1331s	
18249/28500 (epoch 32.016), train_loss = 0.83718953, grad/param norm = 1.7279e-01, time/batch = 15.2473s	
18250/28500 (epoch 32.018), train_loss = 0.92484585, grad/param norm = 2.0407e-01, time/batch = 15.5267s	
18251/28500 (epoch 32.019), train_loss = 0.95644679, grad/param norm = 1.8604e-01, time/batch = 15.6541s	
18252/28500 (epoch 32.021), train_loss = 0.99059602, grad/param norm = 1.6796e-01, time/batch = 15.5440s	
18253/28500 (epoch 32.023), train_loss = 0.90497550, grad/param norm = 1.8495e-01, time/batch = 15.1877s	
18254/28500 (epoch 32.025), train_loss = 0.92331682, grad/param norm = 1.8510e-01, time/batch = 15.1217s	
18255/28500 (epoch 32.026), train_loss = 0.87005419, grad/param norm = 1.6292e-01, time/batch = 15.2042s	
18256/28500 (epoch 32.028), train_loss = 0.90159856, grad/param norm = 1.8913e-01, time/batch = 15.3670s	
18257/28500 (epoch 32.030), train_loss = 0.94182391, grad/param norm = 1.9602e-01, time/batch = 15.1188s	
18258/28500 (epoch 32.032), train_loss = 0.96694917, grad/param norm = 1.6899e-01, time/batch = 15.3768s	
18259/28500 (epoch 32.033), train_loss = 1.03105333, grad/param norm = 1.9076e-01, time/batch = 15.2671s	
18260/28500 (epoch 32.035), train_loss = 0.86572848, grad/param norm = 1.8060e-01, time/batch = 15.2886s	
18261/28500 (epoch 32.037), train_loss = 0.93400208, grad/param norm = 1.6749e-01, time/batch = 15.4015s	
18262/28500 (epoch 32.039), train_loss = 0.99126283, grad/param norm = 1.9574e-01, time/batch = 15.1379s	
18263/28500 (epoch 32.040), train_loss = 1.00521585, grad/param norm = 1.8308e-01, time/batch = 15.1432s	
18264/28500 (epoch 32.042), train_loss = 0.93818502, grad/param norm = 1.7779e-01, time/batch = 15.4328s	
18265/28500 (epoch 32.044), train_loss = 0.89652243, grad/param norm = 1.9904e-01, time/batch = 15.1799s	
18266/28500 (epoch 32.046), train_loss = 1.09965170, grad/param norm = 1.9186e-01, time/batch = 15.1331s	
18267/28500 (epoch 32.047), train_loss = 1.02840025, grad/param norm = 1.9125e-01, time/batch = 15.1178s	
18268/28500 (epoch 32.049), train_loss = 0.89861527, grad/param norm = 1.7819e-01, time/batch = 15.3194s	
18269/28500 (epoch 32.051), train_loss = 0.90180126, grad/param norm = 2.0295e-01, time/batch = 15.4287s	
18270/28500 (epoch 32.053), train_loss = 0.88423413, grad/param norm = 1.9969e-01, time/batch = 15.2835s	
18271/28500 (epoch 32.054), train_loss = 0.97134144, grad/param norm = 1.9473e-01, time/batch = 15.5958s	
18272/28500 (epoch 32.056), train_loss = 0.81236951, grad/param norm = 1.6934e-01, time/batch = 15.5524s	
18273/28500 (epoch 32.058), train_loss = 0.81698164, grad/param norm = 1.6504e-01, time/batch = 15.1955s	
18274/28500 (epoch 32.060), train_loss = 0.93836308, grad/param norm = 1.7569e-01, time/batch = 15.2820s	
18275/28500 (epoch 32.061), train_loss = 0.86967916, grad/param norm = 1.7762e-01, time/batch = 15.2695s	
18276/28500 (epoch 32.063), train_loss = 0.97183612, grad/param norm = 2.0162e-01, time/batch = 15.1834s	
18277/28500 (epoch 32.065), train_loss = 0.92143440, grad/param norm = 1.7791e-01, time/batch = 15.1828s	
18278/28500 (epoch 32.067), train_loss = 0.84071540, grad/param norm = 1.7318e-01, time/batch = 15.1668s	
18279/28500 (epoch 32.068), train_loss = 0.87260709, grad/param norm = 1.6877e-01, time/batch = 15.1274s	
18280/28500 (epoch 32.070), train_loss = 0.93603543, grad/param norm = 1.9598e-01, time/batch = 14.9666s	
18281/28500 (epoch 32.072), train_loss = 1.02709506, grad/param norm = 1.9430e-01, time/batch = 15.2075s	
18282/28500 (epoch 32.074), train_loss = 0.89714010, grad/param norm = 1.7646e-01, time/batch = 15.2137s	
18283/28500 (epoch 32.075), train_loss = 0.86243327, grad/param norm = 1.6381e-01, time/batch = 15.3044s	
18284/28500 (epoch 32.077), train_loss = 0.92672794, grad/param norm = 1.6166e-01, time/batch = 15.6146s	
18285/28500 (epoch 32.079), train_loss = 0.90711650, grad/param norm = 1.9007e-01, time/batch = 15.6459s	
18286/28500 (epoch 32.081), train_loss = 1.03362817, grad/param norm = 2.1970e-01, time/batch = 15.4602s	
18287/28500 (epoch 32.082), train_loss = 0.90897425, grad/param norm = 2.1879e-01, time/batch = 15.2001s	
18288/28500 (epoch 32.084), train_loss = 0.93035319, grad/param norm = 1.8208e-01, time/batch = 15.1235s	
18289/28500 (epoch 32.086), train_loss = 0.88326087, grad/param norm = 2.1827e-01, time/batch = 15.2706s	
18290/28500 (epoch 32.088), train_loss = 0.78866497, grad/param norm = 1.6512e-01, time/batch = 15.2118s	
18291/28500 (epoch 32.089), train_loss = 0.96726549, grad/param norm = 1.8082e-01, time/batch = 15.4099s	
18292/28500 (epoch 32.091), train_loss = 0.77366313, grad/param norm = 1.6274e-01, time/batch = 15.4023s	
18293/28500 (epoch 32.093), train_loss = 0.98446525, grad/param norm = 1.7668e-01, time/batch = 15.1563s	
18294/28500 (epoch 32.095), train_loss = 0.89033399, grad/param norm = 1.5314e-01, time/batch = 15.1193s	
18295/28500 (epoch 32.096), train_loss = 0.98852941, grad/param norm = 1.9289e-01, time/batch = 14.9734s	
18296/28500 (epoch 32.098), train_loss = 0.90039024, grad/param norm = 1.8196e-01, time/batch = 15.3605s	
18297/28500 (epoch 32.100), train_loss = 0.85699463, grad/param norm = 1.6357e-01, time/batch = 15.5591s	
18298/28500 (epoch 32.102), train_loss = 0.96856661, grad/param norm = 2.1062e-01, time/batch = 15.3021s	
18299/28500 (epoch 32.104), train_loss = 0.89531388, grad/param norm = 1.8634e-01, time/batch = 15.2171s	
18300/28500 (epoch 32.105), train_loss = 1.01546769, grad/param norm = 1.7838e-01, time/batch = 15.1831s	
18301/28500 (epoch 32.107), train_loss = 0.81452760, grad/param norm = 1.8096e-01, time/batch = 15.1320s	
18302/28500 (epoch 32.109), train_loss = 0.83741348, grad/param norm = 1.9755e-01, time/batch = 14.9871s	
18303/28500 (epoch 32.111), train_loss = 0.88132978, grad/param norm = 2.0290e-01, time/batch = 14.9859s	
18304/28500 (epoch 32.112), train_loss = 0.97283284, grad/param norm = 1.9107e-01, time/batch = 15.3614s	
18305/28500 (epoch 32.114), train_loss = 0.87445856, grad/param norm = 1.7596e-01, time/batch = 15.3330s	
18306/28500 (epoch 32.116), train_loss = 1.03786303, grad/param norm = 1.9574e-01, time/batch = 15.2410s	
18307/28500 (epoch 32.118), train_loss = 0.78759371, grad/param norm = 1.6490e-01, time/batch = 15.1158s	
18308/28500 (epoch 32.119), train_loss = 0.92503046, grad/param norm = 1.8241e-01, time/batch = 15.4354s	
18309/28500 (epoch 32.121), train_loss = 1.06508210, grad/param norm = 2.3158e-01, time/batch = 15.4873s	
18310/28500 (epoch 32.123), train_loss = 0.99992631, grad/param norm = 1.8381e-01, time/batch = 15.3950s	
18311/28500 (epoch 32.125), train_loss = 0.92612452, grad/param norm = 1.8554e-01, time/batch = 15.2000s	
18312/28500 (epoch 32.126), train_loss = 0.89608441, grad/param norm = 1.7833e-01, time/batch = 15.3908s	
18313/28500 (epoch 32.128), train_loss = 0.88906462, grad/param norm = 1.6595e-01, time/batch = 15.2137s	
18314/28500 (epoch 32.130), train_loss = 0.83025638, grad/param norm = 1.8758e-01, time/batch = 14.9929s	
18315/28500 (epoch 32.132), train_loss = 0.91094084, grad/param norm = 1.9390e-01, time/batch = 15.0566s	
18316/28500 (epoch 32.133), train_loss = 0.94636833, grad/param norm = 1.9274e-01, time/batch = 15.3606s	
18317/28500 (epoch 32.135), train_loss = 0.85983140, grad/param norm = 1.8171e-01, time/batch = 15.2341s	
18318/28500 (epoch 32.137), train_loss = 0.92504498, grad/param norm = 1.8328e-01, time/batch = 15.4852s	
18319/28500 (epoch 32.139), train_loss = 0.89811408, grad/param norm = 1.6100e-01, time/batch = 15.1675s	
18320/28500 (epoch 32.140), train_loss = 0.90139049, grad/param norm = 1.8140e-01, time/batch = 15.2215s	
18321/28500 (epoch 32.142), train_loss = 0.85842169, grad/param norm = 2.0489e-01, time/batch = 15.4733s	
18322/28500 (epoch 32.144), train_loss = 0.84254491, grad/param norm = 1.7121e-01, time/batch = 15.3816s	
18323/28500 (epoch 32.146), train_loss = 0.87002381, grad/param norm = 1.7118e-01, time/batch = 15.2724s	
18324/28500 (epoch 32.147), train_loss = 0.76966141, grad/param norm = 1.6386e-01, time/batch = 15.3268s	
18325/28500 (epoch 32.149), train_loss = 0.76847034, grad/param norm = 1.6005e-01, time/batch = 15.2940s	
18326/28500 (epoch 32.151), train_loss = 0.87696764, grad/param norm = 1.7037e-01, time/batch = 15.2082s	
18327/28500 (epoch 32.153), train_loss = 0.92076437, grad/param norm = 1.7835e-01, time/batch = 20.1331s	
18328/28500 (epoch 32.154), train_loss = 0.78704044, grad/param norm = 1.6893e-01, time/batch = 22.7815s	
18329/28500 (epoch 32.156), train_loss = 0.97884670, grad/param norm = 1.9223e-01, time/batch = 15.1117s	
18330/28500 (epoch 32.158), train_loss = 0.88683005, grad/param norm = 1.5469e-01, time/batch = 15.3899s	
18331/28500 (epoch 32.160), train_loss = 0.80038553, grad/param norm = 1.6923e-01, time/batch = 15.6260s	
18332/28500 (epoch 32.161), train_loss = 0.82598442, grad/param norm = 1.8962e-01, time/batch = 15.6255s	
18333/28500 (epoch 32.163), train_loss = 0.77826701, grad/param norm = 1.7595e-01, time/batch = 15.2403s	
18334/28500 (epoch 32.165), train_loss = 1.06131896, grad/param norm = 1.8211e-01, time/batch = 15.2161s	
18335/28500 (epoch 32.167), train_loss = 1.05310640, grad/param norm = 1.9113e-01, time/batch = 15.4530s	
18336/28500 (epoch 32.168), train_loss = 1.00151452, grad/param norm = 2.0303e-01, time/batch = 15.1383s	
18337/28500 (epoch 32.170), train_loss = 0.97434365, grad/param norm = 2.0449e-01, time/batch = 15.0654s	
18338/28500 (epoch 32.172), train_loss = 0.89919270, grad/param norm = 1.7480e-01, time/batch = 15.5286s	
18339/28500 (epoch 32.174), train_loss = 1.06704118, grad/param norm = 2.1527e-01, time/batch = 15.5593s	
18340/28500 (epoch 32.175), train_loss = 0.87029234, grad/param norm = 1.6633e-01, time/batch = 15.4050s	
18341/28500 (epoch 32.177), train_loss = 0.93362584, grad/param norm = 1.7553e-01, time/batch = 15.4830s	
18342/28500 (epoch 32.179), train_loss = 0.97002426, grad/param norm = 1.8776e-01, time/batch = 15.5359s	
18343/28500 (epoch 32.181), train_loss = 0.93922033, grad/param norm = 1.9164e-01, time/batch = 15.2974s	
18344/28500 (epoch 32.182), train_loss = 0.87970201, grad/param norm = 1.6916e-01, time/batch = 15.4922s	
18345/28500 (epoch 32.184), train_loss = 1.05177096, grad/param norm = 2.1252e-01, time/batch = 15.1133s	
18346/28500 (epoch 32.186), train_loss = 1.01410302, grad/param norm = 1.7783e-01, time/batch = 15.2975s	
18347/28500 (epoch 32.188), train_loss = 0.93968967, grad/param norm = 1.6429e-01, time/batch = 15.1982s	
18348/28500 (epoch 32.189), train_loss = 0.91160642, grad/param norm = 1.7127e-01, time/batch = 15.3837s	
18349/28500 (epoch 32.191), train_loss = 1.09751218, grad/param norm = 1.9239e-01, time/batch = 15.2173s	
18350/28500 (epoch 32.193), train_loss = 0.93608572, grad/param norm = 1.9626e-01, time/batch = 15.4206s	
18351/28500 (epoch 32.195), train_loss = 1.04652812, grad/param norm = 1.9334e-01, time/batch = 15.4620s	
18352/28500 (epoch 32.196), train_loss = 0.96212489, grad/param norm = 1.7845e-01, time/batch = 15.4163s	
18353/28500 (epoch 32.198), train_loss = 0.94940000, grad/param norm = 2.2837e-01, time/batch = 15.6156s	
18354/28500 (epoch 32.200), train_loss = 0.97661320, grad/param norm = 1.8340e-01, time/batch = 15.3802s	
18355/28500 (epoch 32.202), train_loss = 0.92396341, grad/param norm = 1.6823e-01, time/batch = 15.4570s	
18356/28500 (epoch 32.204), train_loss = 0.89986413, grad/param norm = 1.7069e-01, time/batch = 15.0375s	
18357/28500 (epoch 32.205), train_loss = 0.85316645, grad/param norm = 1.6126e-01, time/batch = 15.3410s	
18358/28500 (epoch 32.207), train_loss = 0.79216734, grad/param norm = 1.6810e-01, time/batch = 15.4318s	
18359/28500 (epoch 32.209), train_loss = 0.93885826, grad/param norm = 1.7021e-01, time/batch = 15.4499s	
18360/28500 (epoch 32.211), train_loss = 0.81576898, grad/param norm = 1.7925e-01, time/batch = 15.5558s	
18361/28500 (epoch 32.212), train_loss = 0.76053769, grad/param norm = 1.7518e-01, time/batch = 15.2652s	
18362/28500 (epoch 32.214), train_loss = 0.91546526, grad/param norm = 1.8604e-01, time/batch = 15.5699s	
18363/28500 (epoch 32.216), train_loss = 0.85989237, grad/param norm = 1.9372e-01, time/batch = 15.5170s	
18364/28500 (epoch 32.218), train_loss = 0.99415957, grad/param norm = 1.7804e-01, time/batch = 15.3355s	
18365/28500 (epoch 32.219), train_loss = 0.93613417, grad/param norm = 1.8614e-01, time/batch = 15.2912s	
18366/28500 (epoch 32.221), train_loss = 0.76839466, grad/param norm = 1.6011e-01, time/batch = 15.3579s	
18367/28500 (epoch 32.223), train_loss = 1.00011557, grad/param norm = 1.9518e-01, time/batch = 15.2202s	
18368/28500 (epoch 32.225), train_loss = 1.04652970, grad/param norm = 1.8887e-01, time/batch = 15.5353s	
18369/28500 (epoch 32.226), train_loss = 0.86794685, grad/param norm = 1.6720e-01, time/batch = 15.6551s	
18370/28500 (epoch 32.228), train_loss = 0.97689948, grad/param norm = 1.7862e-01, time/batch = 15.5828s	
18371/28500 (epoch 32.230), train_loss = 0.97914042, grad/param norm = 1.7889e-01, time/batch = 15.4846s	
18372/28500 (epoch 32.232), train_loss = 0.94735036, grad/param norm = 1.6864e-01, time/batch = 15.4681s	
18373/28500 (epoch 32.233), train_loss = 0.89165175, grad/param norm = 1.8183e-01, time/batch = 15.4347s	
18374/28500 (epoch 32.235), train_loss = 0.89671578, grad/param norm = 1.7541e-01, time/batch = 15.3748s	
18375/28500 (epoch 32.237), train_loss = 0.80560809, grad/param norm = 1.4180e-01, time/batch = 15.3096s	
18376/28500 (epoch 32.239), train_loss = 0.84693755, grad/param norm = 1.4932e-01, time/batch = 15.0729s	
18377/28500 (epoch 32.240), train_loss = 0.79015094, grad/param norm = 1.6507e-01, time/batch = 15.2944s	
18378/28500 (epoch 32.242), train_loss = 0.87243096, grad/param norm = 1.6886e-01, time/batch = 15.2923s	
18379/28500 (epoch 32.244), train_loss = 0.94183294, grad/param norm = 1.6227e-01, time/batch = 15.4776s	
18380/28500 (epoch 32.246), train_loss = 0.95940496, grad/param norm = 1.7492e-01, time/batch = 15.4818s	
18381/28500 (epoch 32.247), train_loss = 1.03635907, grad/param norm = 2.1301e-01, time/batch = 15.4449s	
18382/28500 (epoch 32.249), train_loss = 0.87001215, grad/param norm = 1.6086e-01, time/batch = 15.3898s	
18383/28500 (epoch 32.251), train_loss = 0.87279920, grad/param norm = 1.6039e-01, time/batch = 15.5408s	
18384/28500 (epoch 32.253), train_loss = 1.01900097, grad/param norm = 1.8929e-01, time/batch = 15.4140s	
18385/28500 (epoch 32.254), train_loss = 1.04667638, grad/param norm = 1.7055e-01, time/batch = 15.2004s	
18386/28500 (epoch 32.256), train_loss = 0.88468592, grad/param norm = 1.8866e-01, time/batch = 14.8899s	
18387/28500 (epoch 32.258), train_loss = 0.89746210, grad/param norm = 2.0014e-01, time/batch = 14.9739s	
18388/28500 (epoch 32.260), train_loss = 0.90208402, grad/param norm = 1.7805e-01, time/batch = 14.8939s	
18389/28500 (epoch 32.261), train_loss = 0.79918203, grad/param norm = 1.5321e-01, time/batch = 15.2287s	
18390/28500 (epoch 32.263), train_loss = 0.98417716, grad/param norm = 1.9088e-01, time/batch = 15.2613s	
18391/28500 (epoch 32.265), train_loss = 0.87154627, grad/param norm = 1.6368e-01, time/batch = 15.2181s	
18392/28500 (epoch 32.267), train_loss = 1.03751489, grad/param norm = 2.0382e-01, time/batch = 15.0648s	
18393/28500 (epoch 32.268), train_loss = 0.94713843, grad/param norm = 1.6070e-01, time/batch = 15.1337s	
18394/28500 (epoch 32.270), train_loss = 0.92847675, grad/param norm = 2.0529e-01, time/batch = 15.6272s	
18395/28500 (epoch 32.272), train_loss = 0.94232890, grad/param norm = 1.9293e-01, time/batch = 15.1219s	
18396/28500 (epoch 32.274), train_loss = 0.98050579, grad/param norm = 1.9503e-01, time/batch = 15.0499s	
18397/28500 (epoch 32.275), train_loss = 0.95207814, grad/param norm = 1.6619e-01, time/batch = 15.3187s	
18398/28500 (epoch 32.277), train_loss = 0.88068036, grad/param norm = 1.6228e-01, time/batch = 15.3688s	
18399/28500 (epoch 32.279), train_loss = 0.93928332, grad/param norm = 2.1144e-01, time/batch = 15.3787s	
18400/28500 (epoch 32.281), train_loss = 0.98509192, grad/param norm = 2.2779e-01, time/batch = 15.4503s	
18401/28500 (epoch 32.282), train_loss = 0.87861889, grad/param norm = 1.5742e-01, time/batch = 15.5488s	
18402/28500 (epoch 32.284), train_loss = 0.94154592, grad/param norm = 1.9737e-01, time/batch = 15.4649s	
18403/28500 (epoch 32.286), train_loss = 1.02728500, grad/param norm = 1.7904e-01, time/batch = 15.5570s	
18404/28500 (epoch 32.288), train_loss = 0.90941833, grad/param norm = 1.8930e-01, time/batch = 15.5398s	
18405/28500 (epoch 32.289), train_loss = 0.95850001, grad/param norm = 2.1159e-01, time/batch = 15.5196s	
18406/28500 (epoch 32.291), train_loss = 0.92116554, grad/param norm = 1.7363e-01, time/batch = 15.3664s	
18407/28500 (epoch 32.293), train_loss = 0.90867076, grad/param norm = 1.6394e-01, time/batch = 15.0646s	
18408/28500 (epoch 32.295), train_loss = 0.82796428, grad/param norm = 1.7707e-01, time/batch = 14.9769s	
18409/28500 (epoch 32.296), train_loss = 0.77966392, grad/param norm = 1.5073e-01, time/batch = 15.4607s	
18410/28500 (epoch 32.298), train_loss = 0.95550731, grad/param norm = 1.6048e-01, time/batch = 15.5202s	
18411/28500 (epoch 32.300), train_loss = 0.83978480, grad/param norm = 1.7742e-01, time/batch = 15.4151s	
18412/28500 (epoch 32.302), train_loss = 0.80119978, grad/param norm = 1.6988e-01, time/batch = 15.5392s	
18413/28500 (epoch 32.304), train_loss = 0.88071601, grad/param norm = 1.7036e-01, time/batch = 15.4621s	
18414/28500 (epoch 32.305), train_loss = 0.93689279, grad/param norm = 1.7285e-01, time/batch = 15.4253s	
18415/28500 (epoch 32.307), train_loss = 0.89112352, grad/param norm = 1.6709e-01, time/batch = 15.0634s	
18416/28500 (epoch 32.309), train_loss = 0.89175906, grad/param norm = 1.6287e-01, time/batch = 15.1902s	
18417/28500 (epoch 32.311), train_loss = 0.94762345, grad/param norm = 1.8489e-01, time/batch = 15.2813s	
18418/28500 (epoch 32.312), train_loss = 0.93268520, grad/param norm = 1.6054e-01, time/batch = 15.1151s	
18419/28500 (epoch 32.314), train_loss = 0.95156723, grad/param norm = 1.8491e-01, time/batch = 14.9746s	
18420/28500 (epoch 32.316), train_loss = 0.91312655, grad/param norm = 2.0629e-01, time/batch = 15.2092s	
18421/28500 (epoch 32.318), train_loss = 0.98737253, grad/param norm = 1.6873e-01, time/batch = 15.4128s	
18422/28500 (epoch 32.319), train_loss = 0.87338204, grad/param norm = 1.6918e-01, time/batch = 15.2994s	
18423/28500 (epoch 32.321), train_loss = 0.86237039, grad/param norm = 1.7580e-01, time/batch = 15.3829s	
18424/28500 (epoch 32.323), train_loss = 0.89013286, grad/param norm = 1.9397e-01, time/batch = 15.2249s	
18425/28500 (epoch 32.325), train_loss = 1.03789521, grad/param norm = 1.8464e-01, time/batch = 15.1973s	
18426/28500 (epoch 32.326), train_loss = 0.93965334, grad/param norm = 1.7090e-01, time/batch = 15.0462s	
18427/28500 (epoch 32.328), train_loss = 0.74699902, grad/param norm = 1.6479e-01, time/batch = 15.1968s	
18428/28500 (epoch 32.330), train_loss = 0.84670115, grad/param norm = 1.7062e-01, time/batch = 15.2175s	
18429/28500 (epoch 32.332), train_loss = 0.88121185, grad/param norm = 1.6893e-01, time/batch = 15.0523s	
18430/28500 (epoch 32.333), train_loss = 0.72336802, grad/param norm = 1.7198e-01, time/batch = 15.1110s	
18431/28500 (epoch 32.335), train_loss = 0.80251771, grad/param norm = 1.6362e-01, time/batch = 15.0664s	
18432/28500 (epoch 32.337), train_loss = 0.75146992, grad/param norm = 1.5429e-01, time/batch = 15.6188s	
18433/28500 (epoch 32.339), train_loss = 0.74972983, grad/param norm = 1.5192e-01, time/batch = 15.5647s	
18434/28500 (epoch 32.340), train_loss = 0.90069603, grad/param norm = 2.3593e-01, time/batch = 15.4746s	
18435/28500 (epoch 32.342), train_loss = 0.87996475, grad/param norm = 1.6992e-01, time/batch = 15.1931s	
18436/28500 (epoch 32.344), train_loss = 0.80176591, grad/param norm = 1.8705e-01, time/batch = 15.3536s	
18437/28500 (epoch 32.346), train_loss = 0.75791466, grad/param norm = 1.5149e-01, time/batch = 15.4188s	
18438/28500 (epoch 32.347), train_loss = 0.89423101, grad/param norm = 1.6370e-01, time/batch = 15.5115s	
18439/28500 (epoch 32.349), train_loss = 0.87960271, grad/param norm = 1.7874e-01, time/batch = 15.5308s	
18440/28500 (epoch 32.351), train_loss = 0.79924778, grad/param norm = 1.5526e-01, time/batch = 15.5556s	
18441/28500 (epoch 32.353), train_loss = 0.87878475, grad/param norm = 1.9589e-01, time/batch = 15.6232s	
18442/28500 (epoch 32.354), train_loss = 0.80450548, grad/param norm = 1.7252e-01, time/batch = 15.3845s	
18443/28500 (epoch 32.356), train_loss = 0.83932473, grad/param norm = 1.7243e-01, time/batch = 15.3719s	
18444/28500 (epoch 32.358), train_loss = 0.94458835, grad/param norm = 1.6816e-01, time/batch = 15.3843s	
18445/28500 (epoch 32.360), train_loss = 0.91418786, grad/param norm = 2.0182e-01, time/batch = 15.3695s	
18446/28500 (epoch 32.361), train_loss = 0.81525963, grad/param norm = 1.6743e-01, time/batch = 15.1803s	
18447/28500 (epoch 32.363), train_loss = 0.81348331, grad/param norm = 1.5865e-01, time/batch = 15.5127s	
18448/28500 (epoch 32.365), train_loss = 0.87390278, grad/param norm = 1.9158e-01, time/batch = 15.4445s	
18449/28500 (epoch 32.367), train_loss = 0.91312194, grad/param norm = 1.9393e-01, time/batch = 15.3541s	
18450/28500 (epoch 32.368), train_loss = 0.83659967, grad/param norm = 1.6124e-01, time/batch = 15.5323s	
18451/28500 (epoch 32.370), train_loss = 0.88813318, grad/param norm = 1.6877e-01, time/batch = 15.7026s	
18452/28500 (epoch 32.372), train_loss = 0.72143433, grad/param norm = 1.5839e-01, time/batch = 15.3677s	
18453/28500 (epoch 32.374), train_loss = 0.84730798, grad/param norm = 1.7176e-01, time/batch = 15.3967s	
18454/28500 (epoch 32.375), train_loss = 0.96408385, grad/param norm = 1.7620e-01, time/batch = 15.5119s	
18455/28500 (epoch 32.377), train_loss = 0.78103256, grad/param norm = 2.1745e-01, time/batch = 15.4383s	
18456/28500 (epoch 32.379), train_loss = 0.69189852, grad/param norm = 1.6955e-01, time/batch = 15.2070s	
18457/28500 (epoch 32.381), train_loss = 0.85006952, grad/param norm = 1.5864e-01, time/batch = 15.4965s	
18458/28500 (epoch 32.382), train_loss = 0.84344187, grad/param norm = 2.0858e-01, time/batch = 15.5422s	
18459/28500 (epoch 32.384), train_loss = 0.74168537, grad/param norm = 1.5971e-01, time/batch = 15.1294s	
18460/28500 (epoch 32.386), train_loss = 0.80114267, grad/param norm = 1.5890e-01, time/batch = 15.1454s	
18461/28500 (epoch 32.388), train_loss = 0.97487261, grad/param norm = 1.7678e-01, time/batch = 15.4876s	
18462/28500 (epoch 32.389), train_loss = 0.83080740, grad/param norm = 1.8744e-01, time/batch = 15.4552s	
18463/28500 (epoch 32.391), train_loss = 0.75969816, grad/param norm = 1.8833e-01, time/batch = 15.5924s	
18464/28500 (epoch 32.393), train_loss = 0.79985970, grad/param norm = 1.7339e-01, time/batch = 15.5642s	
18465/28500 (epoch 32.395), train_loss = 0.98257897, grad/param norm = 1.7201e-01, time/batch = 15.4506s	
18466/28500 (epoch 32.396), train_loss = 0.94359724, grad/param norm = 1.8192e-01, time/batch = 15.3718s	
18467/28500 (epoch 32.398), train_loss = 0.67998090, grad/param norm = 1.7235e-01, time/batch = 15.3387s	
18468/28500 (epoch 32.400), train_loss = 0.85988318, grad/param norm = 1.8402e-01, time/batch = 15.0614s	
18469/28500 (epoch 32.402), train_loss = 0.89218456, grad/param norm = 1.7882e-01, time/batch = 15.1496s	
18470/28500 (epoch 32.404), train_loss = 0.91944116, grad/param norm = 2.1267e-01, time/batch = 15.5255s	
18471/28500 (epoch 32.405), train_loss = 0.92932273, grad/param norm = 1.8309e-01, time/batch = 15.3780s	
18472/28500 (epoch 32.407), train_loss = 0.90588351, grad/param norm = 1.7856e-01, time/batch = 15.7881s	
18473/28500 (epoch 32.409), train_loss = 0.90162680, grad/param norm = 1.8460e-01, time/batch = 15.2165s	
18474/28500 (epoch 32.411), train_loss = 0.99291675, grad/param norm = 1.9659e-01, time/batch = 15.1880s	
18475/28500 (epoch 32.412), train_loss = 1.02193716, grad/param norm = 1.9282e-01, time/batch = 15.4400s	
18476/28500 (epoch 32.414), train_loss = 0.90704003, grad/param norm = 1.7972e-01, time/batch = 15.4564s	
18477/28500 (epoch 32.416), train_loss = 0.81496006, grad/param norm = 1.7346e-01, time/batch = 15.4818s	
18478/28500 (epoch 32.418), train_loss = 0.91003963, grad/param norm = 1.5195e-01, time/batch = 15.4888s	
18479/28500 (epoch 32.419), train_loss = 0.99155430, grad/param norm = 2.0419e-01, time/batch = 15.3960s	
18480/28500 (epoch 32.421), train_loss = 0.96695645, grad/param norm = 1.8631e-01, time/batch = 15.6194s	
18481/28500 (epoch 32.423), train_loss = 0.98303789, grad/param norm = 1.9154e-01, time/batch = 15.7251s	
18482/28500 (epoch 32.425), train_loss = 0.89706269, grad/param norm = 1.8794e-01, time/batch = 15.4631s	
18483/28500 (epoch 32.426), train_loss = 0.90865391, grad/param norm = 2.0381e-01, time/batch = 15.2795s	
18484/28500 (epoch 32.428), train_loss = 1.04239905, grad/param norm = 1.8939e-01, time/batch = 15.3053s	
18485/28500 (epoch 32.430), train_loss = 1.03255107, grad/param norm = 1.7272e-01, time/batch = 15.5369s	
18486/28500 (epoch 32.432), train_loss = 0.88347720, grad/param norm = 1.7721e-01, time/batch = 15.4131s	
18487/28500 (epoch 32.433), train_loss = 0.94968123, grad/param norm = 2.0109e-01, time/batch = 15.0645s	
18488/28500 (epoch 32.435), train_loss = 0.91807459, grad/param norm = 1.8116e-01, time/batch = 15.1254s	
18489/28500 (epoch 32.437), train_loss = 0.84302397, grad/param norm = 1.8886e-01, time/batch = 15.4542s	
18490/28500 (epoch 32.439), train_loss = 0.87223890, grad/param norm = 1.5759e-01, time/batch = 15.6652s	
18491/28500 (epoch 32.440), train_loss = 1.04363831, grad/param norm = 1.9008e-01, time/batch = 15.5750s	
18492/28500 (epoch 32.442), train_loss = 0.82919503, grad/param norm = 1.8984e-01, time/batch = 15.1547s	
18493/28500 (epoch 32.444), train_loss = 0.78778117, grad/param norm = 1.5160e-01, time/batch = 15.3684s	
18494/28500 (epoch 32.446), train_loss = 0.75118700, grad/param norm = 1.5402e-01, time/batch = 15.1931s	
18495/28500 (epoch 32.447), train_loss = 0.76834777, grad/param norm = 1.6483e-01, time/batch = 15.1412s	
18496/28500 (epoch 32.449), train_loss = 0.85234945, grad/param norm = 1.6194e-01, time/batch = 15.1214s	
18497/28500 (epoch 32.451), train_loss = 0.86684331, grad/param norm = 1.7103e-01, time/batch = 15.2292s	
18498/28500 (epoch 32.453), train_loss = 0.85938999, grad/param norm = 1.7502e-01, time/batch = 15.2831s	
18499/28500 (epoch 32.454), train_loss = 0.81596284, grad/param norm = 1.5256e-01, time/batch = 15.4318s	
18500/28500 (epoch 32.456), train_loss = 0.94585871, grad/param norm = 1.8203e-01, time/batch = 15.6032s	
18501/28500 (epoch 32.458), train_loss = 0.85951042, grad/param norm = 1.7193e-01, time/batch = 15.7553s	
18502/28500 (epoch 32.460), train_loss = 0.94450222, grad/param norm = 1.7774e-01, time/batch = 15.6665s	
18503/28500 (epoch 32.461), train_loss = 0.79920996, grad/param norm = 1.7053e-01, time/batch = 15.5008s	
18504/28500 (epoch 32.463), train_loss = 0.74064558, grad/param norm = 1.4676e-01, time/batch = 15.5565s	
18505/28500 (epoch 32.465), train_loss = 0.75037835, grad/param norm = 1.7748e-01, time/batch = 15.3089s	
18506/28500 (epoch 32.467), train_loss = 0.90031629, grad/param norm = 1.6978e-01, time/batch = 15.3698s	
18507/28500 (epoch 32.468), train_loss = 0.78347987, grad/param norm = 1.4456e-01, time/batch = 15.3528s	
18508/28500 (epoch 32.470), train_loss = 0.83862426, grad/param norm = 1.7340e-01, time/batch = 15.4667s	
18509/28500 (epoch 32.472), train_loss = 0.80516894, grad/param norm = 1.5246e-01, time/batch = 15.6068s	
18510/28500 (epoch 32.474), train_loss = 1.01202197, grad/param norm = 1.9952e-01, time/batch = 15.2915s	
18511/28500 (epoch 32.475), train_loss = 0.82617759, grad/param norm = 1.7772e-01, time/batch = 15.6907s	
18512/28500 (epoch 32.477), train_loss = 0.84345136, grad/param norm = 1.7002e-01, time/batch = 15.4637s	
18513/28500 (epoch 32.479), train_loss = 0.90970131, grad/param norm = 1.7110e-01, time/batch = 15.2131s	
18514/28500 (epoch 32.481), train_loss = 0.92746554, grad/param norm = 1.8252e-01, time/batch = 15.4947s	
18515/28500 (epoch 32.482), train_loss = 0.77805694, grad/param norm = 1.5957e-01, time/batch = 15.3646s	
18516/28500 (epoch 32.484), train_loss = 0.81664051, grad/param norm = 1.8074e-01, time/batch = 15.3043s	
18517/28500 (epoch 32.486), train_loss = 0.70969867, grad/param norm = 1.8623e-01, time/batch = 15.4875s	
18518/28500 (epoch 32.488), train_loss = 0.91791893, grad/param norm = 1.5530e-01, time/batch = 14.9546s	
18519/28500 (epoch 32.489), train_loss = 1.00117314, grad/param norm = 1.9491e-01, time/batch = 15.5216s	
18520/28500 (epoch 32.491), train_loss = 0.82143824, grad/param norm = 1.8457e-01, time/batch = 15.3026s	
18521/28500 (epoch 32.493), train_loss = 0.86871798, grad/param norm = 1.7521e-01, time/batch = 15.6000s	
18522/28500 (epoch 32.495), train_loss = 0.91169718, grad/param norm = 1.8293e-01, time/batch = 15.6344s	
18523/28500 (epoch 32.496), train_loss = 0.79539641, grad/param norm = 1.7724e-01, time/batch = 15.4822s	
18524/28500 (epoch 32.498), train_loss = 0.84542554, grad/param norm = 1.5340e-01, time/batch = 15.5858s	
18525/28500 (epoch 32.500), train_loss = 0.80428631, grad/param norm = 1.6148e-01, time/batch = 15.5115s	
18526/28500 (epoch 32.502), train_loss = 0.93783327, grad/param norm = 1.7430e-01, time/batch = 15.3639s	
18527/28500 (epoch 32.504), train_loss = 0.91299979, grad/param norm = 1.6296e-01, time/batch = 15.2987s	
18528/28500 (epoch 32.505), train_loss = 0.81125920, grad/param norm = 1.6407e-01, time/batch = 15.3507s	
18529/28500 (epoch 32.507), train_loss = 0.97526950, grad/param norm = 2.0356e-01, time/batch = 15.1947s	
18530/28500 (epoch 32.509), train_loss = 0.89114115, grad/param norm = 1.8609e-01, time/batch = 15.2518s	
18531/28500 (epoch 32.511), train_loss = 0.88252212, grad/param norm = 1.7241e-01, time/batch = 15.6617s	
18532/28500 (epoch 32.512), train_loss = 0.92443246, grad/param norm = 1.7193e-01, time/batch = 15.5217s	
18533/28500 (epoch 32.514), train_loss = 0.89924121, grad/param norm = 1.8697e-01, time/batch = 15.4307s	
18534/28500 (epoch 32.516), train_loss = 0.85023102, grad/param norm = 1.4891e-01, time/batch = 15.4534s	
18535/28500 (epoch 32.518), train_loss = 0.91519050, grad/param norm = 1.7648e-01, time/batch = 15.3941s	
18536/28500 (epoch 32.519), train_loss = 0.94888546, grad/param norm = 1.7868e-01, time/batch = 15.4477s	
18537/28500 (epoch 32.521), train_loss = 1.00499546, grad/param norm = 1.8713e-01, time/batch = 15.6342s	
18538/28500 (epoch 32.523), train_loss = 0.95194357, grad/param norm = 2.0740e-01, time/batch = 15.3856s	
18539/28500 (epoch 32.525), train_loss = 1.00096311, grad/param norm = 1.8071e-01, time/batch = 15.2286s	
18540/28500 (epoch 32.526), train_loss = 0.95142104, grad/param norm = 1.7116e-01, time/batch = 15.4964s	
18541/28500 (epoch 32.528), train_loss = 0.93581014, grad/param norm = 2.0604e-01, time/batch = 15.6464s	
18542/28500 (epoch 32.530), train_loss = 0.94972323, grad/param norm = 1.6680e-01, time/batch = 15.5417s	
18543/28500 (epoch 32.532), train_loss = 0.84437961, grad/param norm = 1.5819e-01, time/batch = 15.2890s	
18544/28500 (epoch 32.533), train_loss = 0.93863776, grad/param norm = 1.7395e-01, time/batch = 15.3111s	
18545/28500 (epoch 32.535), train_loss = 0.78023245, grad/param norm = 1.5343e-01, time/batch = 15.3636s	
18546/28500 (epoch 32.537), train_loss = 0.79976699, grad/param norm = 1.5520e-01, time/batch = 15.2949s	
18547/28500 (epoch 32.539), train_loss = 0.74911586, grad/param norm = 1.6794e-01, time/batch = 15.2180s	
18548/28500 (epoch 32.540), train_loss = 0.88859266, grad/param norm = 1.6573e-01, time/batch = 15.1982s	
18549/28500 (epoch 32.542), train_loss = 0.93000770, grad/param norm = 2.1537e-01, time/batch = 15.4527s	
18550/28500 (epoch 32.544), train_loss = 1.01922983, grad/param norm = 1.9334e-01, time/batch = 15.0727s	
18551/28500 (epoch 32.546), train_loss = 0.87913775, grad/param norm = 1.6089e-01, time/batch = 15.2137s	
18552/28500 (epoch 32.547), train_loss = 0.88205285, grad/param norm = 1.6862e-01, time/batch = 15.5381s	
18553/28500 (epoch 32.549), train_loss = 0.72573814, grad/param norm = 1.3753e-01, time/batch = 15.6071s	
18554/28500 (epoch 32.551), train_loss = 0.85170039, grad/param norm = 2.0393e-01, time/batch = 15.3838s	
18555/28500 (epoch 32.553), train_loss = 1.05612221, grad/param norm = 2.2438e-01, time/batch = 15.1922s	
18556/28500 (epoch 32.554), train_loss = 0.93550246, grad/param norm = 1.7900e-01, time/batch = 15.1393s	
18557/28500 (epoch 32.556), train_loss = 0.92174107, grad/param norm = 1.7626e-01, time/batch = 15.4814s	
18558/28500 (epoch 32.558), train_loss = 0.93787934, grad/param norm = 1.7176e-01, time/batch = 15.4432s	
18559/28500 (epoch 32.560), train_loss = 0.93506780, grad/param norm = 1.7567e-01, time/batch = 21.7855s	
18560/28500 (epoch 32.561), train_loss = 0.95731925, grad/param norm = 1.9876e-01, time/batch = 21.4116s	
18561/28500 (epoch 32.563), train_loss = 1.00479684, grad/param norm = 1.9588e-01, time/batch = 15.6511s	
18562/28500 (epoch 32.565), train_loss = 0.81461167, grad/param norm = 1.7410e-01, time/batch = 15.6159s	
18563/28500 (epoch 32.567), train_loss = 0.76999933, grad/param norm = 1.5215e-01, time/batch = 15.5427s	
18564/28500 (epoch 32.568), train_loss = 0.92015742, grad/param norm = 1.7478e-01, time/batch = 15.5475s	
18565/28500 (epoch 32.570), train_loss = 0.86638716, grad/param norm = 1.7985e-01, time/batch = 15.3738s	
18566/28500 (epoch 32.572), train_loss = 0.89217545, grad/param norm = 1.7142e-01, time/batch = 15.1124s	
18567/28500 (epoch 32.574), train_loss = 0.81974794, grad/param norm = 1.5947e-01, time/batch = 15.4373s	
18568/28500 (epoch 32.575), train_loss = 0.84762828, grad/param norm = 1.6256e-01, time/batch = 15.3503s	
18569/28500 (epoch 32.577), train_loss = 0.91343794, grad/param norm = 1.6373e-01, time/batch = 15.1957s	
18570/28500 (epoch 32.579), train_loss = 0.95919685, grad/param norm = 2.0336e-01, time/batch = 15.4176s	
18571/28500 (epoch 32.581), train_loss = 0.83784608, grad/param norm = 2.1617e-01, time/batch = 15.4632s	
18572/28500 (epoch 32.582), train_loss = 0.97676773, grad/param norm = 1.8565e-01, time/batch = 15.2925s	
18573/28500 (epoch 32.584), train_loss = 0.86349400, grad/param norm = 2.1708e-01, time/batch = 15.4311s	
18574/28500 (epoch 32.586), train_loss = 0.81276528, grad/param norm = 1.5697e-01, time/batch = 15.3825s	
18575/28500 (epoch 32.588), train_loss = 0.83565220, grad/param norm = 1.7869e-01, time/batch = 15.5297s	
18576/28500 (epoch 32.589), train_loss = 0.87042066, grad/param norm = 1.8359e-01, time/batch = 15.3115s	
18577/28500 (epoch 32.591), train_loss = 0.92231123, grad/param norm = 1.8513e-01, time/batch = 15.1269s	
18578/28500 (epoch 32.593), train_loss = 0.84962406, grad/param norm = 1.6286e-01, time/batch = 15.7689s	
18579/28500 (epoch 32.595), train_loss = 1.06617291, grad/param norm = 1.9904e-01, time/batch = 15.3757s	
18580/28500 (epoch 32.596), train_loss = 1.06125108, grad/param norm = 1.8234e-01, time/batch = 15.4494s	
18581/28500 (epoch 32.598), train_loss = 0.88548999, grad/param norm = 1.7781e-01, time/batch = 15.4491s	
18582/28500 (epoch 32.600), train_loss = 0.88722092, grad/param norm = 1.9657e-01, time/batch = 15.2744s	
18583/28500 (epoch 32.602), train_loss = 0.94029476, grad/param norm = 1.7760e-01, time/batch = 15.2469s	
18584/28500 (epoch 32.604), train_loss = 0.97696019, grad/param norm = 1.6811e-01, time/batch = 15.3603s	
18585/28500 (epoch 32.605), train_loss = 0.95328181, grad/param norm = 1.8597e-01, time/batch = 15.2117s	
18586/28500 (epoch 32.607), train_loss = 0.99833783, grad/param norm = 1.5874e-01, time/batch = 15.2129s	
18587/28500 (epoch 32.609), train_loss = 0.92380251, grad/param norm = 1.8364e-01, time/batch = 15.4283s	
18588/28500 (epoch 32.611), train_loss = 0.87097599, grad/param norm = 1.9474e-01, time/batch = 15.2224s	
18589/28500 (epoch 32.612), train_loss = 0.96335588, grad/param norm = 2.3799e-01, time/batch = 15.5496s	
18590/28500 (epoch 32.614), train_loss = 0.94960035, grad/param norm = 1.7747e-01, time/batch = 15.4731s	
18591/28500 (epoch 32.616), train_loss = 0.86152573, grad/param norm = 1.9061e-01, time/batch = 15.4709s	
18592/28500 (epoch 32.618), train_loss = 0.87372361, grad/param norm = 1.6878e-01, time/batch = 15.5539s	
18593/28500 (epoch 32.619), train_loss = 0.96998055, grad/param norm = 2.0353e-01, time/batch = 15.4762s	
18594/28500 (epoch 32.621), train_loss = 0.73671213, grad/param norm = 1.6404e-01, time/batch = 15.3692s	
18595/28500 (epoch 32.623), train_loss = 0.99999764, grad/param norm = 2.1586e-01, time/batch = 15.3608s	
18596/28500 (epoch 32.625), train_loss = 0.82013086, grad/param norm = 1.8231e-01, time/batch = 15.4193s	
18597/28500 (epoch 32.626), train_loss = 0.70252998, grad/param norm = 1.5606e-01, time/batch = 15.3370s	
18598/28500 (epoch 32.628), train_loss = 0.82005356, grad/param norm = 1.7173e-01, time/batch = 15.3354s	
18599/28500 (epoch 32.630), train_loss = 0.77204485, grad/param norm = 1.6904e-01, time/batch = 15.2298s	
18600/28500 (epoch 32.632), train_loss = 0.97476931, grad/param norm = 1.7947e-01, time/batch = 15.3188s	
18601/28500 (epoch 32.633), train_loss = 1.03741909, grad/param norm = 1.7692e-01, time/batch = 15.4496s	
18602/28500 (epoch 32.635), train_loss = 0.92575807, grad/param norm = 1.8350e-01, time/batch = 15.6213s	
18603/28500 (epoch 32.637), train_loss = 0.90142173, grad/param norm = 1.6304e-01, time/batch = 15.5504s	
18604/28500 (epoch 32.639), train_loss = 0.80306427, grad/param norm = 1.8904e-01, time/batch = 15.4723s	
18605/28500 (epoch 32.640), train_loss = 0.81350065, grad/param norm = 1.5551e-01, time/batch = 15.4438s	
18606/28500 (epoch 32.642), train_loss = 0.83972586, grad/param norm = 1.8057e-01, time/batch = 15.3576s	
18607/28500 (epoch 32.644), train_loss = 0.93893482, grad/param norm = 1.6518e-01, time/batch = 15.4473s	
18608/28500 (epoch 32.646), train_loss = 0.75072630, grad/param norm = 1.4887e-01, time/batch = 15.2301s	
18609/28500 (epoch 32.647), train_loss = 0.82028612, grad/param norm = 1.5706e-01, time/batch = 15.1616s	
18610/28500 (epoch 32.649), train_loss = 0.80303256, grad/param norm = 1.8563e-01, time/batch = 15.1658s	
18611/28500 (epoch 32.651), train_loss = 0.77383118, grad/param norm = 1.4571e-01, time/batch = 15.2637s	
18612/28500 (epoch 32.653), train_loss = 0.77371608, grad/param norm = 1.6638e-01, time/batch = 15.3621s	
18613/28500 (epoch 32.654), train_loss = 0.81463518, grad/param norm = 1.7653e-01, time/batch = 15.1307s	
18614/28500 (epoch 32.656), train_loss = 0.78422220, grad/param norm = 1.8677e-01, time/batch = 15.2983s	
18615/28500 (epoch 32.658), train_loss = 0.87808675, grad/param norm = 1.7570e-01, time/batch = 15.3469s	
18616/28500 (epoch 32.660), train_loss = 0.88717845, grad/param norm = 1.6541e-01, time/batch = 15.5469s	
18617/28500 (epoch 32.661), train_loss = 0.98430984, grad/param norm = 2.0876e-01, time/batch = 15.5456s	
18618/28500 (epoch 32.663), train_loss = 0.98467726, grad/param norm = 1.8425e-01, time/batch = 15.1384s	
18619/28500 (epoch 32.665), train_loss = 0.87019880, grad/param norm = 1.6582e-01, time/batch = 15.1214s	
18620/28500 (epoch 32.667), train_loss = 0.88420297, grad/param norm = 2.2485e-01, time/batch = 15.1290s	
18621/28500 (epoch 32.668), train_loss = 0.88810885, grad/param norm = 1.8493e-01, time/batch = 15.4705s	
18622/28500 (epoch 32.670), train_loss = 0.88119205, grad/param norm = 1.6787e-01, time/batch = 15.2612s	
18623/28500 (epoch 32.672), train_loss = 0.78330253, grad/param norm = 1.6785e-01, time/batch = 15.3994s	
18624/28500 (epoch 32.674), train_loss = 0.70531076, grad/param norm = 1.7405e-01, time/batch = 15.3465s	
18625/28500 (epoch 32.675), train_loss = 0.75691771, grad/param norm = 1.6442e-01, time/batch = 15.1040s	
18626/28500 (epoch 32.677), train_loss = 0.83752053, grad/param norm = 1.6910e-01, time/batch = 15.1869s	
18627/28500 (epoch 32.679), train_loss = 0.84281021, grad/param norm = 1.8558e-01, time/batch = 15.0405s	
18628/28500 (epoch 32.681), train_loss = 0.90521626, grad/param norm = 1.8237e-01, time/batch = 15.0581s	
18629/28500 (epoch 32.682), train_loss = 0.82054532, grad/param norm = 1.6784e-01, time/batch = 15.2115s	
18630/28500 (epoch 32.684), train_loss = 0.89647394, grad/param norm = 1.7430e-01, time/batch = 15.5295s	
18631/28500 (epoch 32.686), train_loss = 0.82923983, grad/param norm = 1.8744e-01, time/batch = 15.6077s	
18632/28500 (epoch 32.688), train_loss = 0.80738925, grad/param norm = 1.4118e-01, time/batch = 15.5565s	
18633/28500 (epoch 32.689), train_loss = 0.82569495, grad/param norm = 1.8282e-01, time/batch = 15.3847s	
18634/28500 (epoch 32.691), train_loss = 0.90686324, grad/param norm = 1.8156e-01, time/batch = 15.3753s	
18635/28500 (epoch 32.693), train_loss = 0.84240571, grad/param norm = 1.7222e-01, time/batch = 15.3783s	
18636/28500 (epoch 32.695), train_loss = 0.65627710, grad/param norm = 2.3853e-01, time/batch = 15.4962s	
18637/28500 (epoch 32.696), train_loss = 0.85609777, grad/param norm = 1.7749e-01, time/batch = 15.5939s	
18638/28500 (epoch 32.698), train_loss = 0.90276531, grad/param norm = 1.7505e-01, time/batch = 15.6107s	
18639/28500 (epoch 32.700), train_loss = 0.89205251, grad/param norm = 1.8244e-01, time/batch = 15.5458s	
18640/28500 (epoch 32.702), train_loss = 0.87333198, grad/param norm = 1.8852e-01, time/batch = 15.4658s	
18641/28500 (epoch 32.704), train_loss = 0.90782326, grad/param norm = 1.9346e-01, time/batch = 15.3017s	
18642/28500 (epoch 32.705), train_loss = 0.95691332, grad/param norm = 2.0519e-01, time/batch = 15.3380s	
18643/28500 (epoch 32.707), train_loss = 0.81957164, grad/param norm = 2.0660e-01, time/batch = 15.0562s	
18644/28500 (epoch 32.709), train_loss = 1.02099713, grad/param norm = 1.9284e-01, time/batch = 15.3423s	
18645/28500 (epoch 32.711), train_loss = 0.80052796, grad/param norm = 1.6065e-01, time/batch = 15.0839s	
18646/28500 (epoch 32.712), train_loss = 0.88253507, grad/param norm = 1.7254e-01, time/batch = 15.2999s	
18647/28500 (epoch 32.714), train_loss = 1.00173673, grad/param norm = 1.8072e-01, time/batch = 15.3003s	
18648/28500 (epoch 32.716), train_loss = 0.86227113, grad/param norm = 1.7744e-01, time/batch = 15.5414s	
18649/28500 (epoch 32.718), train_loss = 0.88607028, grad/param norm = 1.6601e-01, time/batch = 15.4217s	
18650/28500 (epoch 32.719), train_loss = 0.89014744, grad/param norm = 1.7840e-01, time/batch = 15.4866s	
18651/28500 (epoch 32.721), train_loss = 0.69768945, grad/param norm = 1.7370e-01, time/batch = 15.4387s	
18652/28500 (epoch 32.723), train_loss = 0.89587883, grad/param norm = 1.7237e-01, time/batch = 15.5366s	
18653/28500 (epoch 32.725), train_loss = 0.95911799, grad/param norm = 1.6999e-01, time/batch = 15.1350s	
18654/28500 (epoch 32.726), train_loss = 0.87372533, grad/param norm = 2.3061e-01, time/batch = 15.2146s	
18655/28500 (epoch 32.728), train_loss = 0.79139142, grad/param norm = 1.6015e-01, time/batch = 15.3568s	
18656/28500 (epoch 32.730), train_loss = 0.89719802, grad/param norm = 2.1875e-01, time/batch = 15.5453s	
18657/28500 (epoch 32.732), train_loss = 0.70990430, grad/param norm = 1.4233e-01, time/batch = 15.5509s	
18658/28500 (epoch 32.733), train_loss = 0.75693466, grad/param norm = 1.5787e-01, time/batch = 15.4709s	
18659/28500 (epoch 32.735), train_loss = 0.75002680, grad/param norm = 1.5377e-01, time/batch = 15.2821s	
18660/28500 (epoch 32.737), train_loss = 0.67383344, grad/param norm = 1.4607e-01, time/batch = 15.1186s	
18661/28500 (epoch 32.739), train_loss = 0.80249861, grad/param norm = 1.8465e-01, time/batch = 15.2246s	
18662/28500 (epoch 32.740), train_loss = 0.86190204, grad/param norm = 1.5934e-01, time/batch = 15.4987s	
18663/28500 (epoch 32.742), train_loss = 0.78171044, grad/param norm = 1.8126e-01, time/batch = 15.3263s	
18664/28500 (epoch 32.744), train_loss = 0.88817110, grad/param norm = 1.7929e-01, time/batch = 15.1907s	
18665/28500 (epoch 32.746), train_loss = 0.81027070, grad/param norm = 1.5043e-01, time/batch = 15.1065s	
18666/28500 (epoch 32.747), train_loss = 0.80958989, grad/param norm = 1.5455e-01, time/batch = 15.4126s	
18667/28500 (epoch 32.749), train_loss = 0.91714222, grad/param norm = 1.8981e-01, time/batch = 15.4689s	
18668/28500 (epoch 32.751), train_loss = 0.77584515, grad/param norm = 2.0333e-01, time/batch = 15.5409s	
18669/28500 (epoch 32.753), train_loss = 0.85006152, grad/param norm = 1.7678e-01, time/batch = 15.3188s	
18670/28500 (epoch 32.754), train_loss = 0.77156273, grad/param norm = 1.6966e-01, time/batch = 15.3973s	
18671/28500 (epoch 32.756), train_loss = 0.96983333, grad/param norm = 1.7790e-01, time/batch = 15.6024s	
18672/28500 (epoch 32.758), train_loss = 0.93263668, grad/param norm = 2.0273e-01, time/batch = 15.7252s	
18673/28500 (epoch 32.760), train_loss = 0.75420723, grad/param norm = 1.6563e-01, time/batch = 15.3023s	
18674/28500 (epoch 32.761), train_loss = 0.80662126, grad/param norm = 1.8583e-01, time/batch = 15.3654s	
18675/28500 (epoch 32.763), train_loss = 0.70213109, grad/param norm = 1.5000e-01, time/batch = 15.6748s	
18676/28500 (epoch 32.765), train_loss = 0.84467843, grad/param norm = 1.7076e-01, time/batch = 15.4970s	
18677/28500 (epoch 32.767), train_loss = 0.73275391, grad/param norm = 1.5122e-01, time/batch = 15.3564s	
18678/28500 (epoch 32.768), train_loss = 0.91251772, grad/param norm = 1.8509e-01, time/batch = 15.3001s	
18679/28500 (epoch 32.770), train_loss = 0.77566177, grad/param norm = 1.7800e-01, time/batch = 15.4440s	
18680/28500 (epoch 32.772), train_loss = 0.68740609, grad/param norm = 1.4596e-01, time/batch = 15.1949s	
18681/28500 (epoch 32.774), train_loss = 0.86336039, grad/param norm = 1.6591e-01, time/batch = 15.2126s	
18682/28500 (epoch 32.775), train_loss = 0.93414186, grad/param norm = 1.6129e-01, time/batch = 15.1997s	
18683/28500 (epoch 32.777), train_loss = 0.93875760, grad/param norm = 1.6670e-01, time/batch = 15.5404s	
18684/28500 (epoch 32.779), train_loss = 0.70957400, grad/param norm = 1.3482e-01, time/batch = 15.0642s	
18685/28500 (epoch 32.781), train_loss = 0.85886724, grad/param norm = 1.9843e-01, time/batch = 15.0341s	
18686/28500 (epoch 32.782), train_loss = 0.88646441, grad/param norm = 1.8124e-01, time/batch = 15.1241s	
18687/28500 (epoch 32.784), train_loss = 0.69291172, grad/param norm = 1.5991e-01, time/batch = 15.5221s	
18688/28500 (epoch 32.786), train_loss = 0.73962409, grad/param norm = 1.7041e-01, time/batch = 15.5577s	
18689/28500 (epoch 32.788), train_loss = 0.83083435, grad/param norm = 1.8831e-01, time/batch = 15.6248s	
18690/28500 (epoch 32.789), train_loss = 0.65559039, grad/param norm = 2.7232e-01, time/batch = 15.6436s	
18691/28500 (epoch 32.791), train_loss = 0.87986369, grad/param norm = 1.8333e-01, time/batch = 15.4702s	
18692/28500 (epoch 32.793), train_loss = 0.88385301, grad/param norm = 2.0933e-01, time/batch = 15.3605s	
18693/28500 (epoch 32.795), train_loss = 0.86479132, grad/param norm = 1.5950e-01, time/batch = 15.2762s	
18694/28500 (epoch 32.796), train_loss = 0.75988530, grad/param norm = 1.5080e-01, time/batch = 15.4607s	
18695/28500 (epoch 32.798), train_loss = 0.69782732, grad/param norm = 1.6569e-01, time/batch = 15.5100s	
18696/28500 (epoch 32.800), train_loss = 0.73003492, grad/param norm = 1.9632e-01, time/batch = 15.4378s	
18697/28500 (epoch 32.802), train_loss = 0.80962881, grad/param norm = 2.0780e-01, time/batch = 15.4937s	
18698/28500 (epoch 32.804), train_loss = 0.88288543, grad/param norm = 1.6040e-01, time/batch = 15.2888s	
18699/28500 (epoch 32.805), train_loss = 0.87107067, grad/param norm = 2.0182e-01, time/batch = 15.2991s	
18700/28500 (epoch 32.807), train_loss = 0.87504538, grad/param norm = 2.0209e-01, time/batch = 15.1915s	
18701/28500 (epoch 32.809), train_loss = 0.86694264, grad/param norm = 2.1327e-01, time/batch = 15.6167s	
18702/28500 (epoch 32.811), train_loss = 0.89576316, grad/param norm = 1.7333e-01, time/batch = 15.6921s	
18703/28500 (epoch 32.812), train_loss = 0.86111971, grad/param norm = 1.7819e-01, time/batch = 15.6537s	
18704/28500 (epoch 32.814), train_loss = 0.78555280, grad/param norm = 1.5622e-01, time/batch = 15.3656s	
18705/28500 (epoch 32.816), train_loss = 0.89347893, grad/param norm = 1.9139e-01, time/batch = 15.3821s	
18706/28500 (epoch 32.818), train_loss = 0.99282547, grad/param norm = 1.8673e-01, time/batch = 15.5309s	
18707/28500 (epoch 32.819), train_loss = 0.85110034, grad/param norm = 1.7196e-01, time/batch = 15.4302s	
18708/28500 (epoch 32.821), train_loss = 0.82274647, grad/param norm = 1.6773e-01, time/batch = 15.4286s	
18709/28500 (epoch 32.823), train_loss = 0.98958984, grad/param norm = 2.3931e-01, time/batch = 15.4576s	
18710/28500 (epoch 32.825), train_loss = 0.81833737, grad/param norm = 1.9034e-01, time/batch = 15.3945s	
18711/28500 (epoch 32.826), train_loss = 0.88435641, grad/param norm = 1.7715e-01, time/batch = 15.5265s	
18712/28500 (epoch 32.828), train_loss = 0.77376189, grad/param norm = 1.7413e-01, time/batch = 15.2946s	
18713/28500 (epoch 32.830), train_loss = 0.81602664, grad/param norm = 1.5186e-01, time/batch = 15.4755s	
18714/28500 (epoch 32.832), train_loss = 0.84824709, grad/param norm = 1.8910e-01, time/batch = 15.6149s	
18715/28500 (epoch 32.833), train_loss = 0.92570034, grad/param norm = 1.6277e-01, time/batch = 15.3915s	
18716/28500 (epoch 32.835), train_loss = 0.80238532, grad/param norm = 1.7337e-01, time/batch = 15.5695s	
18717/28500 (epoch 32.837), train_loss = 0.73810626, grad/param norm = 1.6937e-01, time/batch = 15.5716s	
18718/28500 (epoch 32.839), train_loss = 0.99940272, grad/param norm = 2.0634e-01, time/batch = 15.5269s	
18719/28500 (epoch 32.840), train_loss = 0.99561264, grad/param norm = 1.7652e-01, time/batch = 15.3877s	
18720/28500 (epoch 32.842), train_loss = 0.89820620, grad/param norm = 1.9490e-01, time/batch = 15.0530s	
18721/28500 (epoch 32.844), train_loss = 0.91066252, grad/param norm = 1.8047e-01, time/batch = 15.4657s	
18722/28500 (epoch 32.846), train_loss = 1.00440649, grad/param norm = 2.0929e-01, time/batch = 15.5021s	
18723/28500 (epoch 32.847), train_loss = 0.83155318, grad/param norm = 1.9413e-01, time/batch = 15.4692s	
18724/28500 (epoch 32.849), train_loss = 0.83525674, grad/param norm = 1.6877e-01, time/batch = 15.6483s	
18725/28500 (epoch 32.851), train_loss = 0.75367707, grad/param norm = 1.7084e-01, time/batch = 15.4373s	
18726/28500 (epoch 32.853), train_loss = 0.89470502, grad/param norm = 2.0932e-01, time/batch = 15.3898s	
18727/28500 (epoch 32.854), train_loss = 0.90096515, grad/param norm = 1.9722e-01, time/batch = 15.3448s	
18728/28500 (epoch 32.856), train_loss = 0.97078592, grad/param norm = 2.1164e-01, time/batch = 15.4671s	
18729/28500 (epoch 32.858), train_loss = 0.81741072, grad/param norm = 1.6141e-01, time/batch = 15.5939s	
18730/28500 (epoch 32.860), train_loss = 0.83561420, grad/param norm = 1.9040e-01, time/batch = 15.4990s	
18731/28500 (epoch 32.861), train_loss = 0.92660754, grad/param norm = 2.0742e-01, time/batch = 15.4715s	
18732/28500 (epoch 32.863), train_loss = 0.89477948, grad/param norm = 2.0776e-01, time/batch = 15.3873s	
18733/28500 (epoch 32.865), train_loss = 0.81838225, grad/param norm = 2.0414e-01, time/batch = 15.4416s	
18734/28500 (epoch 32.867), train_loss = 0.90916754, grad/param norm = 2.0056e-01, time/batch = 15.0454s	
18735/28500 (epoch 32.868), train_loss = 0.77849432, grad/param norm = 1.6072e-01, time/batch = 15.0600s	
18736/28500 (epoch 32.870), train_loss = 0.74422255, grad/param norm = 1.6048e-01, time/batch = 15.1441s	
18737/28500 (epoch 32.872), train_loss = 0.91477227, grad/param norm = 2.3139e-01, time/batch = 15.5508s	
18738/28500 (epoch 32.874), train_loss = 0.78563131, grad/param norm = 1.9734e-01, time/batch = 15.6251s	
18739/28500 (epoch 32.875), train_loss = 0.97970439, grad/param norm = 1.9601e-01, time/batch = 15.5518s	
18740/28500 (epoch 32.877), train_loss = 0.89036169, grad/param norm = 1.8927e-01, time/batch = 15.4542s	
18741/28500 (epoch 32.879), train_loss = 0.90890245, grad/param norm = 1.5200e-01, time/batch = 15.6884s	
18742/28500 (epoch 32.881), train_loss = 0.89164144, grad/param norm = 1.8344e-01, time/batch = 15.5461s	
18743/28500 (epoch 32.882), train_loss = 0.78520810, grad/param norm = 1.5241e-01, time/batch = 15.4105s	
18744/28500 (epoch 32.884), train_loss = 0.85878481, grad/param norm = 1.8325e-01, time/batch = 15.4210s	
18745/28500 (epoch 32.886), train_loss = 0.83999600, grad/param norm = 1.7140e-01, time/batch = 15.3729s	
18746/28500 (epoch 32.888), train_loss = 0.81258689, grad/param norm = 1.5492e-01, time/batch = 15.4454s	
18747/28500 (epoch 32.889), train_loss = 0.86167943, grad/param norm = 1.4939e-01, time/batch = 15.3837s	
18748/28500 (epoch 32.891), train_loss = 0.86196752, grad/param norm = 1.6635e-01, time/batch = 15.4356s	
18749/28500 (epoch 32.893), train_loss = 0.83299414, grad/param norm = 1.8726e-01, time/batch = 15.6189s	
18750/28500 (epoch 32.895), train_loss = 1.01408703, grad/param norm = 2.2948e-01, time/batch = 15.6121s	
18751/28500 (epoch 32.896), train_loss = 0.94670182, grad/param norm = 1.8114e-01, time/batch = 15.6976s	
18752/28500 (epoch 32.898), train_loss = 0.88271509, grad/param norm = 1.6542e-01, time/batch = 15.6773s	
18753/28500 (epoch 32.900), train_loss = 0.75151178, grad/param norm = 1.7983e-01, time/batch = 15.4512s	
18754/28500 (epoch 32.902), train_loss = 0.74688662, grad/param norm = 1.7653e-01, time/batch = 15.3780s	
18755/28500 (epoch 32.904), train_loss = 0.76458838, grad/param norm = 1.5924e-01, time/batch = 15.3013s	
18756/28500 (epoch 32.905), train_loss = 0.80809979, grad/param norm = 1.7742e-01, time/batch = 15.2422s	
18757/28500 (epoch 32.907), train_loss = 0.84034391, grad/param norm = 1.7937e-01, time/batch = 15.2276s	
18758/28500 (epoch 32.909), train_loss = 0.73053457, grad/param norm = 1.8474e-01, time/batch = 15.3263s	
18759/28500 (epoch 32.911), train_loss = 0.76497265, grad/param norm = 1.5863e-01, time/batch = 15.5478s	
18760/28500 (epoch 32.912), train_loss = 0.66378164, grad/param norm = 1.5003e-01, time/batch = 15.4388s	
18761/28500 (epoch 32.914), train_loss = 0.87247864, grad/param norm = 1.8361e-01, time/batch = 15.4432s	
18762/28500 (epoch 32.916), train_loss = 0.85048371, grad/param norm = 1.6806e-01, time/batch = 15.3775s	
18763/28500 (epoch 32.918), train_loss = 0.84891030, grad/param norm = 1.9270e-01, time/batch = 15.3724s	
18764/28500 (epoch 32.919), train_loss = 0.84840646, grad/param norm = 1.8717e-01, time/batch = 15.7947s	
18765/28500 (epoch 32.921), train_loss = 0.96119432, grad/param norm = 2.3308e-01, time/batch = 15.3517s	
18766/28500 (epoch 32.923), train_loss = 0.81382830, grad/param norm = 2.4414e-01, time/batch = 15.3174s	
18767/28500 (epoch 32.925), train_loss = 0.79387320, grad/param norm = 1.7889e-01, time/batch = 15.4522s	
18768/28500 (epoch 32.926), train_loss = 0.85023346, grad/param norm = 1.5944e-01, time/batch = 15.5438s	
18769/28500 (epoch 32.928), train_loss = 0.81039236, grad/param norm = 1.7125e-01, time/batch = 15.4648s	
18770/28500 (epoch 32.930), train_loss = 0.67348495, grad/param norm = 1.4534e-01, time/batch = 15.6655s	
18771/28500 (epoch 32.932), train_loss = 0.69448630, grad/param norm = 1.3497e-01, time/batch = 15.6835s	
18772/28500 (epoch 32.933), train_loss = 0.91379390, grad/param norm = 1.7714e-01, time/batch = 15.5232s	
18773/28500 (epoch 32.935), train_loss = 0.94911958, grad/param norm = 1.6570e-01, time/batch = 15.3675s	
18774/28500 (epoch 32.937), train_loss = 0.95023063, grad/param norm = 1.9506e-01, time/batch = 15.4611s	
18775/28500 (epoch 32.939), train_loss = 0.99949370, grad/param norm = 2.1483e-01, time/batch = 15.3561s	
18776/28500 (epoch 32.940), train_loss = 0.73546612, grad/param norm = 1.8430e-01, time/batch = 15.5407s	
18777/28500 (epoch 32.942), train_loss = 0.84136748, grad/param norm = 1.5861e-01, time/batch = 15.1417s	
18778/28500 (epoch 32.944), train_loss = 0.81644738, grad/param norm = 1.8540e-01, time/batch = 15.1626s	
18779/28500 (epoch 32.946), train_loss = 0.91926245, grad/param norm = 1.6638e-01, time/batch = 15.3351s	
18780/28500 (epoch 32.947), train_loss = 1.10809276, grad/param norm = 2.7099e-01, time/batch = 15.2771s	
18781/28500 (epoch 32.949), train_loss = 0.84301749, grad/param norm = 1.9612e-01, time/batch = 15.0660s	
18782/28500 (epoch 32.951), train_loss = 1.01316630, grad/param norm = 1.9883e-01, time/batch = 15.4353s	
18783/28500 (epoch 32.953), train_loss = 1.01228773, grad/param norm = 2.0924e-01, time/batch = 15.4039s	
18784/28500 (epoch 32.954), train_loss = 0.95988526, grad/param norm = 2.2421e-01, time/batch = 15.3058s	
18785/28500 (epoch 32.956), train_loss = 0.89150121, grad/param norm = 2.7273e-01, time/batch = 15.1073s	
18786/28500 (epoch 32.958), train_loss = 1.09387390, grad/param norm = 1.8627e-01, time/batch = 15.2999s	
18787/28500 (epoch 32.960), train_loss = 0.80392656, grad/param norm = 1.8905e-01, time/batch = 15.2106s	
18788/28500 (epoch 32.961), train_loss = 1.01849086, grad/param norm = 2.1571e-01, time/batch = 15.3076s	
18789/28500 (epoch 32.963), train_loss = 0.98468152, grad/param norm = 2.2384e-01, time/batch = 15.2201s	
18790/28500 (epoch 32.965), train_loss = 0.79709357, grad/param norm = 1.8772e-01, time/batch = 15.1515s	
18791/28500 (epoch 32.967), train_loss = 0.81507189, grad/param norm = 1.7933e-01, time/batch = 27.9252s	
18792/28500 (epoch 32.968), train_loss = 0.75138176, grad/param norm = 1.7740e-01, time/batch = 15.5368s	
18793/28500 (epoch 32.970), train_loss = 0.81452209, grad/param norm = 2.1678e-01, time/batch = 15.3569s	
18794/28500 (epoch 32.972), train_loss = 0.85845882, grad/param norm = 1.7916e-01, time/batch = 15.1965s	
18795/28500 (epoch 32.974), train_loss = 1.05956901, grad/param norm = 2.3454e-01, time/batch = 15.4142s	
18796/28500 (epoch 32.975), train_loss = 0.82934195, grad/param norm = 2.8822e-01, time/batch = 15.1656s	
18797/28500 (epoch 32.977), train_loss = 0.95941574, grad/param norm = 2.3020e-01, time/batch = 15.3350s	
18798/28500 (epoch 32.979), train_loss = 0.87907204, grad/param norm = 1.9623e-01, time/batch = 15.5004s	
18799/28500 (epoch 32.981), train_loss = 0.76574563, grad/param norm = 1.7288e-01, time/batch = 15.6546s	
18800/28500 (epoch 32.982), train_loss = 0.83514805, grad/param norm = 1.6554e-01, time/batch = 15.6233s	
18801/28500 (epoch 32.984), train_loss = 0.95052518, grad/param norm = 1.7827e-01, time/batch = 15.6235s	
18802/28500 (epoch 32.986), train_loss = 1.12633294, grad/param norm = 2.1063e-01, time/batch = 15.6213s	
18803/28500 (epoch 32.988), train_loss = 0.79218759, grad/param norm = 1.7528e-01, time/batch = 15.5497s	
18804/28500 (epoch 32.989), train_loss = 0.88901474, grad/param norm = 1.8758e-01, time/batch = 15.3611s	
18805/28500 (epoch 32.991), train_loss = 0.79263339, grad/param norm = 1.9280e-01, time/batch = 15.1788s	
18806/28500 (epoch 32.993), train_loss = 0.77050512, grad/param norm = 1.6549e-01, time/batch = 15.2925s	
18807/28500 (epoch 32.995), train_loss = 0.80373238, grad/param norm = 1.7309e-01, time/batch = 15.2163s	
18808/28500 (epoch 32.996), train_loss = 0.78376971, grad/param norm = 1.9782e-01, time/batch = 15.5185s	
18809/28500 (epoch 32.998), train_loss = 0.95141869, grad/param norm = 2.1769e-01, time/batch = 15.6333s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
18810/28500 (epoch 33.000), train_loss = 0.84977977, grad/param norm = 1.9127e-01, time/batch = 15.6892s	
18811/28500 (epoch 33.002), train_loss = 1.02703559, grad/param norm = 1.8560e-01, time/batch = 15.6240s	
18812/28500 (epoch 33.004), train_loss = 0.85130171, grad/param norm = 1.7226e-01, time/batch = 15.4651s	
18813/28500 (epoch 33.005), train_loss = 0.97780028, grad/param norm = 2.1424e-01, time/batch = 15.4638s	
18814/28500 (epoch 33.007), train_loss = 0.77569446, grad/param norm = 1.4725e-01, time/batch = 15.5088s	
18815/28500 (epoch 33.009), train_loss = 0.90196332, grad/param norm = 1.8959e-01, time/batch = 15.6977s	
18816/28500 (epoch 33.011), train_loss = 0.81968530, grad/param norm = 2.0695e-01, time/batch = 15.6187s	
18817/28500 (epoch 33.012), train_loss = 0.77091121, grad/param norm = 1.5747e-01, time/batch = 15.5467s	
18818/28500 (epoch 33.014), train_loss = 0.77761313, grad/param norm = 1.9567e-01, time/batch = 15.4652s	
18819/28500 (epoch 33.016), train_loss = 0.82616027, grad/param norm = 1.7294e-01, time/batch = 15.4157s	
18820/28500 (epoch 33.018), train_loss = 0.90089233, grad/param norm = 1.8328e-01, time/batch = 15.2240s	
18821/28500 (epoch 33.019), train_loss = 0.95604540, grad/param norm = 1.8381e-01, time/batch = 15.2037s	
18822/28500 (epoch 33.021), train_loss = 0.98675420, grad/param norm = 1.7569e-01, time/batch = 15.3168s	
18823/28500 (epoch 33.023), train_loss = 0.89395283, grad/param norm = 1.7825e-01, time/batch = 15.1326s	
18824/28500 (epoch 33.025), train_loss = 0.89784014, grad/param norm = 1.7691e-01, time/batch = 15.3451s	
18825/28500 (epoch 33.026), train_loss = 0.84663365, grad/param norm = 1.6394e-01, time/batch = 15.4516s	
18826/28500 (epoch 33.028), train_loss = 0.89006277, grad/param norm = 2.0209e-01, time/batch = 15.5465s	
18827/28500 (epoch 33.030), train_loss = 0.93140251, grad/param norm = 2.0802e-01, time/batch = 15.4780s	
18828/28500 (epoch 33.032), train_loss = 0.95950703, grad/param norm = 1.7245e-01, time/batch = 15.2251s	
18829/28500 (epoch 33.033), train_loss = 1.02965553, grad/param norm = 1.9356e-01, time/batch = 15.4656s	
18830/28500 (epoch 33.035), train_loss = 0.85856317, grad/param norm = 1.9035e-01, time/batch = 15.2648s	
18831/28500 (epoch 33.037), train_loss = 0.92725678, grad/param norm = 1.6606e-01, time/batch = 15.1319s	
18832/28500 (epoch 33.039), train_loss = 0.97503821, grad/param norm = 1.8108e-01, time/batch = 15.1322s	
18833/28500 (epoch 33.040), train_loss = 1.01321406, grad/param norm = 1.8405e-01, time/batch = 15.0981s	
18834/28500 (epoch 33.042), train_loss = 0.93658173, grad/param norm = 1.7493e-01, time/batch = 15.0513s	
18835/28500 (epoch 33.044), train_loss = 0.89987126, grad/param norm = 1.9179e-01, time/batch = 15.4886s	
18836/28500 (epoch 33.046), train_loss = 1.08225185, grad/param norm = 1.9172e-01, time/batch = 15.5199s	
18837/28500 (epoch 33.047), train_loss = 1.01812415, grad/param norm = 1.9344e-01, time/batch = 15.5375s	
18838/28500 (epoch 33.049), train_loss = 0.89036523, grad/param norm = 1.7714e-01, time/batch = 15.5380s	
18839/28500 (epoch 33.051), train_loss = 0.88355009, grad/param norm = 1.8352e-01, time/batch = 15.6015s	
18840/28500 (epoch 33.053), train_loss = 0.86523986, grad/param norm = 1.9304e-01, time/batch = 15.5769s	
18841/28500 (epoch 33.054), train_loss = 0.97150331, grad/param norm = 1.9938e-01, time/batch = 15.7102s	
18842/28500 (epoch 33.056), train_loss = 0.80375536, grad/param norm = 1.8087e-01, time/batch = 15.6427s	
18843/28500 (epoch 33.058), train_loss = 0.79888995, grad/param norm = 1.4824e-01, time/batch = 15.3011s	
18844/28500 (epoch 33.060), train_loss = 0.94648119, grad/param norm = 1.9529e-01, time/batch = 15.3581s	
18845/28500 (epoch 33.061), train_loss = 0.85840981, grad/param norm = 1.7502e-01, time/batch = 15.0704s	
18846/28500 (epoch 33.063), train_loss = 0.95114514, grad/param norm = 1.9238e-01, time/batch = 15.1302s	
18847/28500 (epoch 33.065), train_loss = 0.90541173, grad/param norm = 1.7968e-01, time/batch = 15.0576s	
18848/28500 (epoch 33.067), train_loss = 0.81917121, grad/param norm = 1.6897e-01, time/batch = 15.3438s	
18849/28500 (epoch 33.068), train_loss = 0.84550618, grad/param norm = 1.6850e-01, time/batch = 15.2334s	
18850/28500 (epoch 33.070), train_loss = 0.91923194, grad/param norm = 1.9922e-01, time/batch = 15.4499s	
18851/28500 (epoch 33.072), train_loss = 1.00780532, grad/param norm = 1.9307e-01, time/batch = 15.4516s	
18852/28500 (epoch 33.074), train_loss = 0.87893698, grad/param norm = 1.6672e-01, time/batch = 15.4648s	
18853/28500 (epoch 33.075), train_loss = 0.85200988, grad/param norm = 1.5509e-01, time/batch = 15.3795s	
18854/28500 (epoch 33.077), train_loss = 0.92546522, grad/param norm = 1.6546e-01, time/batch = 15.3797s	
18855/28500 (epoch 33.079), train_loss = 0.88970824, grad/param norm = 1.7487e-01, time/batch = 15.3080s	
18856/28500 (epoch 33.081), train_loss = 1.00764814, grad/param norm = 2.1711e-01, time/batch = 15.5401s	
18857/28500 (epoch 33.082), train_loss = 0.89641311, grad/param norm = 2.2826e-01, time/batch = 15.4476s	
18858/28500 (epoch 33.084), train_loss = 0.92872297, grad/param norm = 1.8654e-01, time/batch = 15.4568s	
18859/28500 (epoch 33.086), train_loss = 0.86501617, grad/param norm = 1.9935e-01, time/batch = 15.3057s	
18860/28500 (epoch 33.088), train_loss = 0.79328116, grad/param norm = 1.7004e-01, time/batch = 15.2943s	
18861/28500 (epoch 33.089), train_loss = 0.95931722, grad/param norm = 1.7915e-01, time/batch = 15.6120s	
18862/28500 (epoch 33.091), train_loss = 0.78329689, grad/param norm = 1.7180e-01, time/batch = 15.2306s	
18863/28500 (epoch 33.093), train_loss = 0.97035959, grad/param norm = 1.6825e-01, time/batch = 15.1142s	
18864/28500 (epoch 33.095), train_loss = 0.88486264, grad/param norm = 1.5987e-01, time/batch = 15.4360s	
18865/28500 (epoch 33.096), train_loss = 0.96175418, grad/param norm = 1.7769e-01, time/batch = 15.0503s	
18866/28500 (epoch 33.098), train_loss = 0.90433646, grad/param norm = 2.0786e-01, time/batch = 14.9893s	
18867/28500 (epoch 33.100), train_loss = 0.86003769, grad/param norm = 1.7991e-01, time/batch = 15.1846s	
18868/28500 (epoch 33.102), train_loss = 0.96178227, grad/param norm = 2.1454e-01, time/batch = 15.5394s	
18869/28500 (epoch 33.104), train_loss = 0.89541466, grad/param norm = 1.9209e-01, time/batch = 15.5481s	
18870/28500 (epoch 33.105), train_loss = 0.99451140, grad/param norm = 1.7537e-01, time/batch = 15.4511s	
18871/28500 (epoch 33.107), train_loss = 0.80265844, grad/param norm = 1.7309e-01, time/batch = 15.3098s	
18872/28500 (epoch 33.109), train_loss = 0.83324202, grad/param norm = 2.1348e-01, time/batch = 15.5411s	
18873/28500 (epoch 33.111), train_loss = 0.85241997, grad/param norm = 2.0096e-01, time/batch = 15.2839s	
18874/28500 (epoch 33.112), train_loss = 0.96881264, grad/param norm = 1.8698e-01, time/batch = 15.3015s	
18875/28500 (epoch 33.114), train_loss = 0.85414854, grad/param norm = 1.7072e-01, time/batch = 15.5125s	
18876/28500 (epoch 33.116), train_loss = 1.02510915, grad/param norm = 1.9471e-01, time/batch = 15.3688s	
18877/28500 (epoch 33.118), train_loss = 0.78341344, grad/param norm = 1.8550e-01, time/batch = 15.4411s	
18878/28500 (epoch 33.119), train_loss = 0.90311768, grad/param norm = 1.8720e-01, time/batch = 15.5360s	
18879/28500 (epoch 33.121), train_loss = 1.04684309, grad/param norm = 2.1677e-01, time/batch = 15.2916s	
18880/28500 (epoch 33.123), train_loss = 0.99057618, grad/param norm = 1.8769e-01, time/batch = 15.1304s	
18881/28500 (epoch 33.125), train_loss = 0.90741454, grad/param norm = 1.7784e-01, time/batch = 15.3118s	
18882/28500 (epoch 33.126), train_loss = 0.88097826, grad/param norm = 1.8432e-01, time/batch = 15.1624s	
18883/28500 (epoch 33.128), train_loss = 0.90306737, grad/param norm = 1.8211e-01, time/batch = 15.4605s	
18884/28500 (epoch 33.130), train_loss = 0.84727742, grad/param norm = 2.1183e-01, time/batch = 15.1272s	
18885/28500 (epoch 33.132), train_loss = 0.89154239, grad/param norm = 1.9165e-01, time/batch = 15.2212s	
18886/28500 (epoch 33.133), train_loss = 0.93610301, grad/param norm = 1.9261e-01, time/batch = 15.2785s	
18887/28500 (epoch 33.135), train_loss = 0.84602813, grad/param norm = 1.7794e-01, time/batch = 15.5254s	
18888/28500 (epoch 33.137), train_loss = 0.90325942, grad/param norm = 1.8048e-01, time/batch = 15.3556s	
18889/28500 (epoch 33.139), train_loss = 0.88736314, grad/param norm = 1.6263e-01, time/batch = 15.6484s	
18890/28500 (epoch 33.140), train_loss = 0.88768424, grad/param norm = 1.7388e-01, time/batch = 15.5492s	
18891/28500 (epoch 33.142), train_loss = 0.84994358, grad/param norm = 1.9312e-01, time/batch = 15.4587s	
18892/28500 (epoch 33.144), train_loss = 0.80752242, grad/param norm = 1.6860e-01, time/batch = 15.4524s	
18893/28500 (epoch 33.146), train_loss = 0.86673748, grad/param norm = 1.6859e-01, time/batch = 15.1351s	
18894/28500 (epoch 33.147), train_loss = 0.76609264, grad/param norm = 1.6187e-01, time/batch = 15.3386s	
18895/28500 (epoch 33.149), train_loss = 0.76476490, grad/param norm = 1.5449e-01, time/batch = 15.4605s	
18896/28500 (epoch 33.151), train_loss = 0.86379580, grad/param norm = 1.7456e-01, time/batch = 15.4424s	
18897/28500 (epoch 33.153), train_loss = 0.91673687, grad/param norm = 1.8700e-01, time/batch = 15.4675s	
18898/28500 (epoch 33.154), train_loss = 0.77892188, grad/param norm = 1.5584e-01, time/batch = 15.3612s	
18899/28500 (epoch 33.156), train_loss = 0.96883121, grad/param norm = 1.9250e-01, time/batch = 15.3056s	
18900/28500 (epoch 33.158), train_loss = 0.89817048, grad/param norm = 1.8037e-01, time/batch = 15.2971s	
18901/28500 (epoch 33.160), train_loss = 0.80967261, grad/param norm = 1.8501e-01, time/batch = 15.3041s	
18902/28500 (epoch 33.161), train_loss = 0.83820423, grad/param norm = 2.0713e-01, time/batch = 15.3180s	
18903/28500 (epoch 33.163), train_loss = 0.75037332, grad/param norm = 1.7409e-01, time/batch = 15.1307s	
18904/28500 (epoch 33.165), train_loss = 1.05541648, grad/param norm = 2.0447e-01, time/batch = 15.1237s	
18905/28500 (epoch 33.167), train_loss = 1.05048746, grad/param norm = 1.9150e-01, time/batch = 15.2090s	
18906/28500 (epoch 33.168), train_loss = 0.99065165, grad/param norm = 2.0104e-01, time/batch = 15.2914s	
18907/28500 (epoch 33.170), train_loss = 0.98465292, grad/param norm = 2.2212e-01, time/batch = 15.3817s	
18908/28500 (epoch 33.172), train_loss = 0.88274573, grad/param norm = 1.6547e-01, time/batch = 15.2235s	
18909/28500 (epoch 33.174), train_loss = 1.03945622, grad/param norm = 2.0161e-01, time/batch = 15.4560s	
18910/28500 (epoch 33.175), train_loss = 0.85646674, grad/param norm = 1.6677e-01, time/batch = 15.4887s	
18911/28500 (epoch 33.177), train_loss = 0.94632888, grad/param norm = 2.0398e-01, time/batch = 15.3501s	
18912/28500 (epoch 33.179), train_loss = 0.96624456, grad/param norm = 1.9518e-01, time/batch = 15.5432s	
18913/28500 (epoch 33.181), train_loss = 0.94635357, grad/param norm = 1.9107e-01, time/batch = 15.3534s	
18914/28500 (epoch 33.182), train_loss = 0.83950961, grad/param norm = 1.6701e-01, time/batch = 15.5285s	
18915/28500 (epoch 33.184), train_loss = 1.04802036, grad/param norm = 1.9387e-01, time/batch = 15.4984s	
18916/28500 (epoch 33.186), train_loss = 1.00814392, grad/param norm = 1.8635e-01, time/batch = 15.2646s	
18917/28500 (epoch 33.188), train_loss = 0.93668227, grad/param norm = 1.7091e-01, time/batch = 15.1829s	
18918/28500 (epoch 33.189), train_loss = 0.90706995, grad/param norm = 1.6381e-01, time/batch = 15.4409s	
18919/28500 (epoch 33.191), train_loss = 1.09954044, grad/param norm = 2.2537e-01, time/batch = 15.5415s	
18920/28500 (epoch 33.193), train_loss = 0.92442705, grad/param norm = 2.0517e-01, time/batch = 15.4780s	
18921/28500 (epoch 33.195), train_loss = 1.03753451, grad/param norm = 1.9708e-01, time/batch = 15.6380s	
18922/28500 (epoch 33.196), train_loss = 0.95593738, grad/param norm = 1.8124e-01, time/batch = 15.6159s	
18923/28500 (epoch 33.198), train_loss = 0.92198185, grad/param norm = 1.8476e-01, time/batch = 15.6270s	
18924/28500 (epoch 33.200), train_loss = 0.96170574, grad/param norm = 1.6931e-01, time/batch = 15.3675s	
18925/28500 (epoch 33.202), train_loss = 0.91682260, grad/param norm = 1.7549e-01, time/batch = 15.5288s	
18926/28500 (epoch 33.204), train_loss = 0.88983446, grad/param norm = 1.6206e-01, time/batch = 15.3608s	
18927/28500 (epoch 33.205), train_loss = 0.85131453, grad/param norm = 1.9321e-01, time/batch = 15.0892s	
18928/28500 (epoch 33.207), train_loss = 0.79089730, grad/param norm = 1.8529e-01, time/batch = 15.5739s	
18929/28500 (epoch 33.209), train_loss = 0.93360595, grad/param norm = 1.7233e-01, time/batch = 15.4794s	
18930/28500 (epoch 33.211), train_loss = 0.81462047, grad/param norm = 1.7697e-01, time/batch = 15.5448s	
18931/28500 (epoch 33.212), train_loss = 0.76215523, grad/param norm = 1.7962e-01, time/batch = 15.5843s	
18932/28500 (epoch 33.214), train_loss = 0.88983709, grad/param norm = 1.8388e-01, time/batch = 15.5130s	
18933/28500 (epoch 33.216), train_loss = 0.84449867, grad/param norm = 1.7946e-01, time/batch = 15.5123s	
18934/28500 (epoch 33.218), train_loss = 0.98013424, grad/param norm = 1.7040e-01, time/batch = 15.4470s	
18935/28500 (epoch 33.219), train_loss = 0.94315857, grad/param norm = 2.0252e-01, time/batch = 15.0609s	
18936/28500 (epoch 33.221), train_loss = 0.77370796, grad/param norm = 1.8508e-01, time/batch = 15.0714s	
18937/28500 (epoch 33.223), train_loss = 1.00841435, grad/param norm = 2.0679e-01, time/batch = 15.2061s	
18938/28500 (epoch 33.225), train_loss = 1.03957213, grad/param norm = 1.9199e-01, time/batch = 15.1935s	
18939/28500 (epoch 33.226), train_loss = 0.85593908, grad/param norm = 1.7421e-01, time/batch = 15.2763s	
18940/28500 (epoch 33.228), train_loss = 0.95993401, grad/param norm = 1.6576e-01, time/batch = 15.5462s	
18941/28500 (epoch 33.230), train_loss = 0.97054152, grad/param norm = 1.8027e-01, time/batch = 15.6612s	
18942/28500 (epoch 33.232), train_loss = 0.93446899, grad/param norm = 1.7581e-01, time/batch = 15.4722s	
18943/28500 (epoch 33.233), train_loss = 0.89910663, grad/param norm = 2.2472e-01, time/batch = 15.4433s	
18944/28500 (epoch 33.235), train_loss = 0.88691601, grad/param norm = 1.8114e-01, time/batch = 15.4447s	
18945/28500 (epoch 33.237), train_loss = 0.79961596, grad/param norm = 1.4704e-01, time/batch = 15.4565s	
18946/28500 (epoch 33.239), train_loss = 0.85263381, grad/param norm = 1.6337e-01, time/batch = 15.5399s	
18947/28500 (epoch 33.240), train_loss = 0.78005113, grad/param norm = 1.5346e-01, time/batch = 15.4258s	
18948/28500 (epoch 33.242), train_loss = 0.86139403, grad/param norm = 1.7840e-01, time/batch = 15.3041s	
18949/28500 (epoch 33.244), train_loss = 0.93315451, grad/param norm = 1.6016e-01, time/batch = 15.4588s	
18950/28500 (epoch 33.246), train_loss = 0.94720712, grad/param norm = 1.8101e-01, time/batch = 15.2136s	
18951/28500 (epoch 33.247), train_loss = 1.01821241, grad/param norm = 2.1414e-01, time/batch = 15.3438s	
18952/28500 (epoch 33.249), train_loss = 0.86637897, grad/param norm = 1.6087e-01, time/batch = 15.3826s	
18953/28500 (epoch 33.251), train_loss = 0.86559487, grad/param norm = 1.5553e-01, time/batch = 15.4911s	
18954/28500 (epoch 33.253), train_loss = 0.99706071, grad/param norm = 1.9048e-01, time/batch = 15.4157s	
18955/28500 (epoch 33.254), train_loss = 1.03829739, grad/param norm = 1.7457e-01, time/batch = 15.5565s	
18956/28500 (epoch 33.256), train_loss = 0.87166438, grad/param norm = 1.7080e-01, time/batch = 15.3397s	
18957/28500 (epoch 33.258), train_loss = 0.89072031, grad/param norm = 1.8256e-01, time/batch = 15.5222s	
18958/28500 (epoch 33.260), train_loss = 0.87782812, grad/param norm = 1.6021e-01, time/batch = 15.3207s	
18959/28500 (epoch 33.261), train_loss = 0.79179799, grad/param norm = 1.5792e-01, time/batch = 15.2297s	
18960/28500 (epoch 33.263), train_loss = 0.97312673, grad/param norm = 2.0101e-01, time/batch = 15.1309s	
18961/28500 (epoch 33.265), train_loss = 0.86117765, grad/param norm = 1.6523e-01, time/batch = 15.7044s	
18962/28500 (epoch 33.267), train_loss = 1.01925781, grad/param norm = 1.9274e-01, time/batch = 15.3095s	
18963/28500 (epoch 33.268), train_loss = 0.92869265, grad/param norm = 1.5779e-01, time/batch = 15.3864s	
18964/28500 (epoch 33.270), train_loss = 0.90170137, grad/param norm = 2.0007e-01, time/batch = 15.6022s	
18965/28500 (epoch 33.272), train_loss = 0.93042636, grad/param norm = 1.8081e-01, time/batch = 15.4555s	
18966/28500 (epoch 33.274), train_loss = 0.96611814, grad/param norm = 2.1132e-01, time/batch = 15.5003s	
18967/28500 (epoch 33.275), train_loss = 0.94958539, grad/param norm = 1.6710e-01, time/batch = 15.5493s	
18968/28500 (epoch 33.277), train_loss = 0.87867790, grad/param norm = 1.8142e-01, time/batch = 15.5096s	
18969/28500 (epoch 33.279), train_loss = 0.90338649, grad/param norm = 1.9951e-01, time/batch = 15.2507s	
18970/28500 (epoch 33.281), train_loss = 0.95576235, grad/param norm = 2.2488e-01, time/batch = 15.4324s	
18971/28500 (epoch 33.282), train_loss = 0.85565896, grad/param norm = 1.4664e-01, time/batch = 15.3499s	
18972/28500 (epoch 33.284), train_loss = 0.90686874, grad/param norm = 1.9737e-01, time/batch = 15.3430s	
18973/28500 (epoch 33.286), train_loss = 1.01878240, grad/param norm = 1.7515e-01, time/batch = 15.2788s	
18974/28500 (epoch 33.288), train_loss = 0.90266308, grad/param norm = 1.9120e-01, time/batch = 15.3627s	
18975/28500 (epoch 33.289), train_loss = 0.93674617, grad/param norm = 1.9813e-01, time/batch = 15.3748s	
18976/28500 (epoch 33.291), train_loss = 0.90914150, grad/param norm = 1.7091e-01, time/batch = 15.3635s	
18977/28500 (epoch 33.293), train_loss = 0.89038419, grad/param norm = 1.6304e-01, time/batch = 15.5838s	
18978/28500 (epoch 33.295), train_loss = 0.80951897, grad/param norm = 1.6651e-01, time/batch = 15.5701s	
18979/28500 (epoch 33.296), train_loss = 0.78672001, grad/param norm = 1.5813e-01, time/batch = 15.3902s	
18980/28500 (epoch 33.298), train_loss = 0.94664420, grad/param norm = 1.7950e-01, time/batch = 15.4425s	
18981/28500 (epoch 33.300), train_loss = 0.83162678, grad/param norm = 1.6938e-01, time/batch = 15.3774s	
18982/28500 (epoch 33.302), train_loss = 0.78748636, grad/param norm = 1.6803e-01, time/batch = 15.4822s	
18983/28500 (epoch 33.304), train_loss = 0.88359614, grad/param norm = 1.8919e-01, time/batch = 15.1159s	
18984/28500 (epoch 33.305), train_loss = 0.92337351, grad/param norm = 1.6856e-01, time/batch = 15.5207s	
18985/28500 (epoch 33.307), train_loss = 0.87524029, grad/param norm = 1.7771e-01, time/batch = 15.5079s	
18986/28500 (epoch 33.309), train_loss = 0.87670764, grad/param norm = 1.6815e-01, time/batch = 15.5153s	
18987/28500 (epoch 33.311), train_loss = 0.95008756, grad/param norm = 1.6735e-01, time/batch = 15.6202s	
18988/28500 (epoch 33.312), train_loss = 0.92642264, grad/param norm = 1.6616e-01, time/batch = 15.6104s	
18989/28500 (epoch 33.314), train_loss = 0.95168365, grad/param norm = 2.0485e-01, time/batch = 15.6184s	
18990/28500 (epoch 33.316), train_loss = 0.91531402, grad/param norm = 2.0123e-01, time/batch = 15.3916s	
18991/28500 (epoch 33.318), train_loss = 0.97412817, grad/param norm = 1.6219e-01, time/batch = 15.5200s	
18992/28500 (epoch 33.319), train_loss = 0.84229685, grad/param norm = 1.8141e-01, time/batch = 15.3487s	
18993/28500 (epoch 33.321), train_loss = 0.85633303, grad/param norm = 1.9210e-01, time/batch = 15.1937s	
18994/28500 (epoch 33.323), train_loss = 0.87123693, grad/param norm = 1.9071e-01, time/batch = 14.9543s	
18995/28500 (epoch 33.325), train_loss = 1.03201648, grad/param norm = 1.8916e-01, time/batch = 15.4110s	
18996/28500 (epoch 33.326), train_loss = 0.92684225, grad/param norm = 1.8664e-01, time/batch = 15.4067s	
18997/28500 (epoch 33.328), train_loss = 0.73478678, grad/param norm = 1.5771e-01, time/batch = 15.5343s	
18998/28500 (epoch 33.330), train_loss = 0.82999681, grad/param norm = 1.7294e-01, time/batch = 15.3104s	
18999/28500 (epoch 33.332), train_loss = 0.87319942, grad/param norm = 1.7362e-01, time/batch = 15.3261s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch33.33_1.8808.t7	
19000/28500 (epoch 33.333), train_loss = 0.70741945, grad/param norm = 1.6691e-01, time/batch = 15.5759s	
19001/28500 (epoch 33.335), train_loss = 1.23902722, grad/param norm = 1.9688e-01, time/batch = 15.6685s	
19002/28500 (epoch 33.337), train_loss = 0.75290020, grad/param norm = 1.6680e-01, time/batch = 15.6444s	
19003/28500 (epoch 33.339), train_loss = 0.73888854, grad/param norm = 1.4672e-01, time/batch = 15.2741s	
19004/28500 (epoch 33.340), train_loss = 0.89419456, grad/param norm = 2.4318e-01, time/batch = 15.1383s	
19005/28500 (epoch 33.342), train_loss = 0.88143106, grad/param norm = 1.8430e-01, time/batch = 15.0481s	
19006/28500 (epoch 33.344), train_loss = 0.79977363, grad/param norm = 1.9543e-01, time/batch = 15.4519s	
19007/28500 (epoch 33.346), train_loss = 0.73364153, grad/param norm = 1.4641e-01, time/batch = 15.6389s	
19008/28500 (epoch 33.347), train_loss = 0.88266950, grad/param norm = 1.6707e-01, time/batch = 15.6843s	
19009/28500 (epoch 33.349), train_loss = 0.88987338, grad/param norm = 1.8810e-01, time/batch = 15.6392s	
19010/28500 (epoch 33.351), train_loss = 0.79463588, grad/param norm = 1.6256e-01, time/batch = 15.6223s	
19011/28500 (epoch 33.353), train_loss = 0.89173074, grad/param norm = 1.9659e-01, time/batch = 15.1560s	
19012/28500 (epoch 33.354), train_loss = 0.77433538, grad/param norm = 1.5983e-01, time/batch = 15.1391s	
19013/28500 (epoch 33.356), train_loss = 0.82488516, grad/param norm = 1.5979e-01, time/batch = 15.1801s	
19014/28500 (epoch 33.358), train_loss = 0.93673114, grad/param norm = 1.7634e-01, time/batch = 20.3981s	
19015/28500 (epoch 33.360), train_loss = 0.91567030, grad/param norm = 1.8834e-01, time/batch = 22.6351s	
19016/28500 (epoch 33.361), train_loss = 0.80876373, grad/param norm = 1.7438e-01, time/batch = 15.3977s	
19017/28500 (epoch 33.363), train_loss = 0.80806711, grad/param norm = 1.5510e-01, time/batch = 15.2188s	
19018/28500 (epoch 33.365), train_loss = 0.84922939, grad/param norm = 1.8581e-01, time/batch = 15.2988s	
19019/28500 (epoch 33.367), train_loss = 0.89450118, grad/param norm = 1.7606e-01, time/batch = 15.2355s	
19020/28500 (epoch 33.368), train_loss = 0.82322597, grad/param norm = 1.5947e-01, time/batch = 15.2501s	
19021/28500 (epoch 33.370), train_loss = 0.87341666, grad/param norm = 1.7070e-01, time/batch = 15.3537s	
19022/28500 (epoch 33.372), train_loss = 0.73134207, grad/param norm = 2.1091e-01, time/batch = 15.2087s	
19023/28500 (epoch 33.374), train_loss = 0.82766537, grad/param norm = 1.6382e-01, time/batch = 15.0700s	
19024/28500 (epoch 33.375), train_loss = 0.95517333, grad/param norm = 1.7696e-01, time/batch = 15.2934s	
19025/28500 (epoch 33.377), train_loss = 0.80385102, grad/param norm = 2.3081e-01, time/batch = 15.2006s	
19026/28500 (epoch 33.379), train_loss = 0.69434298, grad/param norm = 1.7068e-01, time/batch = 15.2558s	
19027/28500 (epoch 33.381), train_loss = 0.84463003, grad/param norm = 1.6413e-01, time/batch = 15.4320s	
19028/28500 (epoch 33.382), train_loss = 0.84158200, grad/param norm = 2.0732e-01, time/batch = 15.3580s	
19029/28500 (epoch 33.384), train_loss = 0.73620256, grad/param norm = 1.6870e-01, time/batch = 15.4435s	
19030/28500 (epoch 33.386), train_loss = 0.78434387, grad/param norm = 1.6044e-01, time/batch = 15.4664s	
19031/28500 (epoch 33.388), train_loss = 0.95476939, grad/param norm = 1.6501e-01, time/batch = 15.3830s	
19032/28500 (epoch 33.389), train_loss = 0.82787327, grad/param norm = 1.9155e-01, time/batch = 15.2943s	
19033/28500 (epoch 33.391), train_loss = 0.76127080, grad/param norm = 1.8503e-01, time/batch = 15.3386s	
19034/28500 (epoch 33.393), train_loss = 0.78890080, grad/param norm = 1.7709e-01, time/batch = 15.3140s	
19035/28500 (epoch 33.395), train_loss = 0.97991225, grad/param norm = 1.6461e-01, time/batch = 14.9887s	
19036/28500 (epoch 33.396), train_loss = 0.93298072, grad/param norm = 1.7030e-01, time/batch = 14.9879s	
19037/28500 (epoch 33.398), train_loss = 0.66170717, grad/param norm = 1.6769e-01, time/batch = 15.2709s	
19038/28500 (epoch 33.400), train_loss = 0.84821624, grad/param norm = 1.6881e-01, time/batch = 15.6153s	
19039/28500 (epoch 33.402), train_loss = 0.89286771, grad/param norm = 2.1548e-01, time/batch = 15.5296s	
19040/28500 (epoch 33.404), train_loss = 0.90554672, grad/param norm = 1.9636e-01, time/batch = 15.1587s	
19041/28500 (epoch 33.405), train_loss = 0.91406070, grad/param norm = 1.8244e-01, time/batch = 15.4564s	
19042/28500 (epoch 33.407), train_loss = 0.87639415, grad/param norm = 1.6268e-01, time/batch = 15.2037s	
19043/28500 (epoch 33.409), train_loss = 0.87719133, grad/param norm = 1.7682e-01, time/batch = 14.9833s	
19044/28500 (epoch 33.411), train_loss = 0.98135230, grad/param norm = 2.0045e-01, time/batch = 15.3238s	
19045/28500 (epoch 33.412), train_loss = 1.01294620, grad/param norm = 2.2078e-01, time/batch = 15.4681s	
19046/28500 (epoch 33.414), train_loss = 0.89871251, grad/param norm = 1.9727e-01, time/batch = 15.3828s	
19047/28500 (epoch 33.416), train_loss = 0.80823873, grad/param norm = 1.7689e-01, time/batch = 15.3595s	
19048/28500 (epoch 33.418), train_loss = 0.90377157, grad/param norm = 1.6142e-01, time/batch = 15.2103s	
19049/28500 (epoch 33.419), train_loss = 0.97460824, grad/param norm = 1.8922e-01, time/batch = 15.2871s	
19050/28500 (epoch 33.421), train_loss = 0.96387825, grad/param norm = 1.9696e-01, time/batch = 15.1946s	
19051/28500 (epoch 33.423), train_loss = 0.94776933, grad/param norm = 1.8175e-01, time/batch = 15.2894s	
19052/28500 (epoch 33.425), train_loss = 0.88926232, grad/param norm = 2.2260e-01, time/batch = 15.2925s	
19053/28500 (epoch 33.426), train_loss = 0.92261757, grad/param norm = 2.1920e-01, time/batch = 15.2518s	
19054/28500 (epoch 33.428), train_loss = 1.02342917, grad/param norm = 2.1925e-01, time/batch = 15.1814s	
19055/28500 (epoch 33.430), train_loss = 1.01610994, grad/param norm = 1.6660e-01, time/batch = 15.1414s	
19056/28500 (epoch 33.432), train_loss = 0.87919773, grad/param norm = 1.8302e-01, time/batch = 15.0499s	
19057/28500 (epoch 33.433), train_loss = 0.95133566, grad/param norm = 2.1508e-01, time/batch = 15.4569s	
19058/28500 (epoch 33.435), train_loss = 0.90470754, grad/param norm = 1.8129e-01, time/batch = 15.3282s	
19059/28500 (epoch 33.437), train_loss = 0.82222035, grad/param norm = 1.6179e-01, time/batch = 15.1296s	
19060/28500 (epoch 33.439), train_loss = 0.86646691, grad/param norm = 1.6409e-01, time/batch = 15.2639s	
19061/28500 (epoch 33.440), train_loss = 1.03896408, grad/param norm = 1.8542e-01, time/batch = 15.6435s	
19062/28500 (epoch 33.442), train_loss = 0.82852943, grad/param norm = 1.8261e-01, time/batch = 15.2962s	
19063/28500 (epoch 33.444), train_loss = 0.76851345, grad/param norm = 1.4323e-01, time/batch = 15.2273s	
19064/28500 (epoch 33.446), train_loss = 0.75346703, grad/param norm = 1.7583e-01, time/batch = 15.1181s	
19065/28500 (epoch 33.447), train_loss = 0.77879808, grad/param norm = 2.0165e-01, time/batch = 15.1622s	
19066/28500 (epoch 33.449), train_loss = 0.85469802, grad/param norm = 1.6776e-01, time/batch = 15.2809s	
19067/28500 (epoch 33.451), train_loss = 0.85334341, grad/param norm = 1.7414e-01, time/batch = 15.3329s	
19068/28500 (epoch 33.453), train_loss = 0.84361403, grad/param norm = 1.7039e-01, time/batch = 15.6383s	
19069/28500 (epoch 33.454), train_loss = 0.80132759, grad/param norm = 1.5218e-01, time/batch = 15.4462s	
19070/28500 (epoch 33.456), train_loss = 0.94030067, grad/param norm = 2.0514e-01, time/batch = 15.2996s	
19071/28500 (epoch 33.458), train_loss = 0.85004392, grad/param norm = 1.6100e-01, time/batch = 15.2048s	
19072/28500 (epoch 33.460), train_loss = 0.94560397, grad/param norm = 1.7941e-01, time/batch = 15.1260s	
19073/28500 (epoch 33.461), train_loss = 0.79172596, grad/param norm = 1.8684e-01, time/batch = 15.3030s	
19074/28500 (epoch 33.463), train_loss = 0.73530706, grad/param norm = 1.5208e-01, time/batch = 15.1374s	
19075/28500 (epoch 33.465), train_loss = 0.74522039, grad/param norm = 1.9054e-01, time/batch = 15.3162s	
19076/28500 (epoch 33.467), train_loss = 0.88598997, grad/param norm = 1.7195e-01, time/batch = 15.3891s	
19077/28500 (epoch 33.468), train_loss = 0.78364713, grad/param norm = 1.5110e-01, time/batch = 15.3211s	
19078/28500 (epoch 33.470), train_loss = 0.83283460, grad/param norm = 1.8833e-01, time/batch = 15.2334s	
19079/28500 (epoch 33.472), train_loss = 0.79495446, grad/param norm = 1.5540e-01, time/batch = 15.2880s	
19080/28500 (epoch 33.474), train_loss = 1.00981460, grad/param norm = 2.0007e-01, time/batch = 15.3952s	
19081/28500 (epoch 33.475), train_loss = 0.81820792, grad/param norm = 1.6506e-01, time/batch = 15.2158s	
19082/28500 (epoch 33.477), train_loss = 0.85903993, grad/param norm = 1.8950e-01, time/batch = 15.2077s	
19083/28500 (epoch 33.479), train_loss = 0.90126966, grad/param norm = 1.8716e-01, time/batch = 15.3973s	
19084/28500 (epoch 33.481), train_loss = 0.92499097, grad/param norm = 1.9115e-01, time/batch = 15.5159s	
19085/28500 (epoch 33.482), train_loss = 0.76508702, grad/param norm = 1.6714e-01, time/batch = 15.4865s	
19086/28500 (epoch 33.484), train_loss = 0.80456817, grad/param norm = 1.7894e-01, time/batch = 15.2827s	
19087/28500 (epoch 33.486), train_loss = 0.69246793, grad/param norm = 1.8098e-01, time/batch = 15.2955s	
19088/28500 (epoch 33.488), train_loss = 0.90457380, grad/param norm = 1.5262e-01, time/batch = 15.4296s	
19089/28500 (epoch 33.489), train_loss = 0.99510125, grad/param norm = 1.7847e-01, time/batch = 15.5513s	
19090/28500 (epoch 33.491), train_loss = 0.81915364, grad/param norm = 1.9460e-01, time/batch = 15.5445s	
19091/28500 (epoch 33.493), train_loss = 0.85890966, grad/param norm = 1.7491e-01, time/batch = 15.5213s	
19092/28500 (epoch 33.495), train_loss = 0.89781434, grad/param norm = 1.9121e-01, time/batch = 15.3737s	
19093/28500 (epoch 33.496), train_loss = 0.78769615, grad/param norm = 1.8855e-01, time/batch = 15.5689s	
19094/28500 (epoch 33.498), train_loss = 0.82288666, grad/param norm = 1.6232e-01, time/batch = 15.2598s	
19095/28500 (epoch 33.500), train_loss = 0.80182247, grad/param norm = 1.7773e-01, time/batch = 15.2245s	
19096/28500 (epoch 33.502), train_loss = 0.92816525, grad/param norm = 1.7153e-01, time/batch = 15.2012s	
19097/28500 (epoch 33.504), train_loss = 0.90224803, grad/param norm = 1.5541e-01, time/batch = 15.3869s	
19098/28500 (epoch 33.505), train_loss = 0.80221999, grad/param norm = 1.7795e-01, time/batch = 15.5392s	
19099/28500 (epoch 33.507), train_loss = 0.95438746, grad/param norm = 2.0644e-01, time/batch = 15.3712s	
19100/28500 (epoch 33.509), train_loss = 0.88200377, grad/param norm = 1.8697e-01, time/batch = 15.3179s	
19101/28500 (epoch 33.511), train_loss = 0.89422595, grad/param norm = 1.9375e-01, time/batch = 15.5449s	
19102/28500 (epoch 33.512), train_loss = 0.91901541, grad/param norm = 1.8611e-01, time/batch = 15.3616s	
19103/28500 (epoch 33.514), train_loss = 0.88094151, grad/param norm = 1.8161e-01, time/batch = 15.3722s	
19104/28500 (epoch 33.516), train_loss = 0.84924926, grad/param norm = 1.6520e-01, time/batch = 15.1168s	
19105/28500 (epoch 33.518), train_loss = 0.91072988, grad/param norm = 1.6257e-01, time/batch = 15.2944s	
19106/28500 (epoch 33.519), train_loss = 0.92934430, grad/param norm = 1.8415e-01, time/batch = 15.4401s	
19107/28500 (epoch 33.521), train_loss = 0.98784289, grad/param norm = 1.9597e-01, time/batch = 15.4653s	
19108/28500 (epoch 33.523), train_loss = 0.91537518, grad/param norm = 1.7256e-01, time/batch = 15.2284s	
19109/28500 (epoch 33.525), train_loss = 0.99925686, grad/param norm = 1.7792e-01, time/batch = 15.1108s	
19110/28500 (epoch 33.526), train_loss = 0.93419419, grad/param norm = 1.7152e-01, time/batch = 15.1141s	
19111/28500 (epoch 33.528), train_loss = 0.91601055, grad/param norm = 2.2108e-01, time/batch = 15.2877s	
19112/28500 (epoch 33.530), train_loss = 0.94033155, grad/param norm = 1.6483e-01, time/batch = 15.2982s	
19113/28500 (epoch 33.532), train_loss = 0.85297420, grad/param norm = 1.8025e-01, time/batch = 15.3914s	
19114/28500 (epoch 33.533), train_loss = 0.92397454, grad/param norm = 1.8224e-01, time/batch = 15.3986s	
19115/28500 (epoch 33.535), train_loss = 0.75779243, grad/param norm = 1.5192e-01, time/batch = 15.5469s	
19116/28500 (epoch 33.537), train_loss = 0.79712402, grad/param norm = 1.5429e-01, time/batch = 15.4614s	
19117/28500 (epoch 33.539), train_loss = 0.74233592, grad/param norm = 1.6759e-01, time/batch = 15.6333s	
19118/28500 (epoch 33.540), train_loss = 0.88161675, grad/param norm = 1.9564e-01, time/batch = 15.6262s	
19119/28500 (epoch 33.542), train_loss = 0.93783140, grad/param norm = 2.3934e-01, time/batch = 15.4306s	
19120/28500 (epoch 33.544), train_loss = 1.00708746, grad/param norm = 2.0229e-01, time/batch = 15.3205s	
19121/28500 (epoch 33.546), train_loss = 0.87173706, grad/param norm = 1.7185e-01, time/batch = 15.4753s	
19122/28500 (epoch 33.547), train_loss = 0.86864529, grad/param norm = 1.8197e-01, time/batch = 15.3728s	
19123/28500 (epoch 33.549), train_loss = 0.72553630, grad/param norm = 1.4447e-01, time/batch = 15.3020s	
19124/28500 (epoch 33.551), train_loss = 0.84530543, grad/param norm = 2.3903e-01, time/batch = 15.2207s	
19125/28500 (epoch 33.553), train_loss = 1.07358766, grad/param norm = 2.7704e-01, time/batch = 15.4663s	
19126/28500 (epoch 33.554), train_loss = 0.94531740, grad/param norm = 2.0610e-01, time/batch = 15.3448s	
19127/28500 (epoch 33.556), train_loss = 0.92156019, grad/param norm = 1.8665e-01, time/batch = 15.3065s	
19128/28500 (epoch 33.558), train_loss = 0.93696516, grad/param norm = 1.8153e-01, time/batch = 15.1199s	
19129/28500 (epoch 33.560), train_loss = 0.95032415, grad/param norm = 2.0796e-01, time/batch = 15.2117s	
19130/28500 (epoch 33.561), train_loss = 0.95624239, grad/param norm = 2.1513e-01, time/batch = 15.3896s	
19131/28500 (epoch 33.563), train_loss = 1.00602854, grad/param norm = 2.2130e-01, time/batch = 15.3564s	
19132/28500 (epoch 33.565), train_loss = 0.80019859, grad/param norm = 1.5708e-01, time/batch = 15.1256s	
19133/28500 (epoch 33.567), train_loss = 0.77412061, grad/param norm = 1.6467e-01, time/batch = 15.4961s	
19134/28500 (epoch 33.568), train_loss = 0.90717267, grad/param norm = 2.0264e-01, time/batch = 15.1451s	
19135/28500 (epoch 33.570), train_loss = 0.86472634, grad/param norm = 2.0271e-01, time/batch = 15.2029s	
19136/28500 (epoch 33.572), train_loss = 0.88109544, grad/param norm = 1.6605e-01, time/batch = 15.2775s	
19137/28500 (epoch 33.574), train_loss = 0.81885966, grad/param norm = 1.7816e-01, time/batch = 15.2700s	
19138/28500 (epoch 33.575), train_loss = 0.84620535, grad/param norm = 1.8650e-01, time/batch = 15.2912s	
19139/28500 (epoch 33.577), train_loss = 0.92116433, grad/param norm = 1.7034e-01, time/batch = 15.4932s	
19140/28500 (epoch 33.579), train_loss = 0.93767185, grad/param norm = 1.7215e-01, time/batch = 15.3621s	
19141/28500 (epoch 33.581), train_loss = 0.82675867, grad/param norm = 2.0054e-01, time/batch = 15.3600s	
19142/28500 (epoch 33.582), train_loss = 0.96879302, grad/param norm = 1.7775e-01, time/batch = 15.6001s	
19143/28500 (epoch 33.584), train_loss = 0.83537710, grad/param norm = 1.6781e-01, time/batch = 15.3922s	
19144/28500 (epoch 33.586), train_loss = 0.81174014, grad/param norm = 1.5037e-01, time/batch = 15.2885s	
19145/28500 (epoch 33.588), train_loss = 0.82131205, grad/param norm = 1.8499e-01, time/batch = 15.2324s	
19146/28500 (epoch 33.589), train_loss = 0.86671877, grad/param norm = 1.9114e-01, time/batch = 15.2974s	
19147/28500 (epoch 33.591), train_loss = 0.90611034, grad/param norm = 1.9022e-01, time/batch = 15.6587s	
19148/28500 (epoch 33.593), train_loss = 0.84683970, grad/param norm = 1.8593e-01, time/batch = 15.5367s	
19149/28500 (epoch 33.595), train_loss = 1.06597383, grad/param norm = 2.2157e-01, time/batch = 15.2025s	
19150/28500 (epoch 33.596), train_loss = 1.04530343, grad/param norm = 1.8134e-01, time/batch = 15.2828s	
19151/28500 (epoch 33.598), train_loss = 0.85857126, grad/param norm = 1.7520e-01, time/batch = 15.2928s	
19152/28500 (epoch 33.600), train_loss = 0.88033338, grad/param norm = 2.0203e-01, time/batch = 15.1842s	
19153/28500 (epoch 33.602), train_loss = 0.93360662, grad/param norm = 1.9862e-01, time/batch = 15.4601s	
19154/28500 (epoch 33.604), train_loss = 0.96464705, grad/param norm = 1.7218e-01, time/batch = 15.4903s	
19155/28500 (epoch 33.605), train_loss = 0.97602975, grad/param norm = 2.2942e-01, time/batch = 15.4702s	
19156/28500 (epoch 33.607), train_loss = 0.99999087, grad/param norm = 1.8090e-01, time/batch = 15.1334s	
19157/28500 (epoch 33.609), train_loss = 0.91423704, grad/param norm = 1.7141e-01, time/batch = 15.4485s	
19158/28500 (epoch 33.611), train_loss = 0.86775249, grad/param norm = 2.3678e-01, time/batch = 15.3853s	
19159/28500 (epoch 33.612), train_loss = 0.95273551, grad/param norm = 2.1790e-01, time/batch = 15.0575s	
19160/28500 (epoch 33.614), train_loss = 0.94587228, grad/param norm = 1.7434e-01, time/batch = 15.4575s	
19161/28500 (epoch 33.616), train_loss = 0.83625571, grad/param norm = 1.7488e-01, time/batch = 15.5118s	
19162/28500 (epoch 33.618), train_loss = 0.88341126, grad/param norm = 1.8482e-01, time/batch = 15.3401s	
19163/28500 (epoch 33.619), train_loss = 0.94701099, grad/param norm = 1.8905e-01, time/batch = 15.4592s	
19164/28500 (epoch 33.621), train_loss = 0.72260016, grad/param norm = 1.6115e-01, time/batch = 15.5435s	
19165/28500 (epoch 33.623), train_loss = 1.00444399, grad/param norm = 2.2449e-01, time/batch = 15.3759s	
19166/28500 (epoch 33.625), train_loss = 0.80389330, grad/param norm = 1.7903e-01, time/batch = 15.2658s	
19167/28500 (epoch 33.626), train_loss = 0.69099051, grad/param norm = 1.5237e-01, time/batch = 15.7996s	
19168/28500 (epoch 33.628), train_loss = 0.81498757, grad/param norm = 1.7994e-01, time/batch = 15.5424s	
19169/28500 (epoch 33.630), train_loss = 0.75663822, grad/param norm = 1.5864e-01, time/batch = 15.3655s	
19170/28500 (epoch 33.632), train_loss = 0.97590192, grad/param norm = 1.9734e-01, time/batch = 15.1351s	
19171/28500 (epoch 33.633), train_loss = 1.02556509, grad/param norm = 1.7177e-01, time/batch = 15.5242s	
19172/28500 (epoch 33.635), train_loss = 0.93197798, grad/param norm = 1.8736e-01, time/batch = 15.1533s	
19173/28500 (epoch 33.637), train_loss = 0.88819398, grad/param norm = 1.5633e-01, time/batch = 15.2476s	
19174/28500 (epoch 33.639), train_loss = 0.80773218, grad/param norm = 1.9971e-01, time/batch = 15.4472s	
19175/28500 (epoch 33.640), train_loss = 0.80707780, grad/param norm = 1.6486e-01, time/batch = 15.5476s	
19176/28500 (epoch 33.642), train_loss = 0.82708043, grad/param norm = 1.5969e-01, time/batch = 15.5608s	
19177/28500 (epoch 33.644), train_loss = 0.92463200, grad/param norm = 1.6485e-01, time/batch = 15.2973s	
19178/28500 (epoch 33.646), train_loss = 0.75249232, grad/param norm = 1.5362e-01, time/batch = 15.2771s	
19179/28500 (epoch 33.647), train_loss = 0.81540240, grad/param norm = 1.5289e-01, time/batch = 15.4301s	
19180/28500 (epoch 33.649), train_loss = 0.77183115, grad/param norm = 1.6676e-01, time/batch = 15.4072s	
19181/28500 (epoch 33.651), train_loss = 0.77866305, grad/param norm = 1.6216e-01, time/batch = 15.4642s	
19182/28500 (epoch 33.653), train_loss = 0.75538384, grad/param norm = 1.8425e-01, time/batch = 15.3628s	
19183/28500 (epoch 33.654), train_loss = 0.81204537, grad/param norm = 1.8942e-01, time/batch = 15.1339s	
19184/28500 (epoch 33.656), train_loss = 0.77302236, grad/param norm = 2.1486e-01, time/batch = 15.4319s	
19185/28500 (epoch 33.658), train_loss = 0.86026960, grad/param norm = 1.8874e-01, time/batch = 15.5265s	
19186/28500 (epoch 33.660), train_loss = 0.88584821, grad/param norm = 1.6687e-01, time/batch = 15.5896s	
19187/28500 (epoch 33.661), train_loss = 0.99302085, grad/param norm = 2.2382e-01, time/batch = 15.5734s	
19188/28500 (epoch 33.663), train_loss = 0.98508156, grad/param norm = 2.1641e-01, time/batch = 15.6267s	
19189/28500 (epoch 33.665), train_loss = 0.87359583, grad/param norm = 1.7038e-01, time/batch = 15.5398s	
19190/28500 (epoch 33.667), train_loss = 0.87910991, grad/param norm = 2.0062e-01, time/batch = 15.3902s	
19191/28500 (epoch 33.668), train_loss = 0.87756113, grad/param norm = 1.8012e-01, time/batch = 15.3858s	
19192/28500 (epoch 33.670), train_loss = 0.87102700, grad/param norm = 1.7446e-01, time/batch = 15.2270s	
19193/28500 (epoch 33.672), train_loss = 0.78872376, grad/param norm = 1.7403e-01, time/batch = 15.3384s	
19194/28500 (epoch 33.674), train_loss = 0.70129263, grad/param norm = 1.6718e-01, time/batch = 15.1393s	
19195/28500 (epoch 33.675), train_loss = 0.72989757, grad/param norm = 1.9105e-01, time/batch = 15.5128s	
19196/28500 (epoch 33.677), train_loss = 0.82826284, grad/param norm = 1.6365e-01, time/batch = 15.2763s	
19197/28500 (epoch 33.679), train_loss = 0.82129688, grad/param norm = 1.7856e-01, time/batch = 15.2332s	
19198/28500 (epoch 33.681), train_loss = 0.90561052, grad/param norm = 1.7483e-01, time/batch = 15.2333s	
19199/28500 (epoch 33.682), train_loss = 0.81237117, grad/param norm = 1.6592e-01, time/batch = 15.3021s	
19200/28500 (epoch 33.684), train_loss = 0.86771428, grad/param norm = 1.7865e-01, time/batch = 15.3292s	
19201/28500 (epoch 33.686), train_loss = 0.81061859, grad/param norm = 1.7616e-01, time/batch = 15.3001s	
19202/28500 (epoch 33.688), train_loss = 0.80984852, grad/param norm = 1.5458e-01, time/batch = 15.2011s	
19203/28500 (epoch 33.689), train_loss = 0.82160497, grad/param norm = 1.9710e-01, time/batch = 15.3103s	
19204/28500 (epoch 33.691), train_loss = 0.90644361, grad/param norm = 1.7766e-01, time/batch = 15.4836s	
19205/28500 (epoch 33.693), train_loss = 0.82690056, grad/param norm = 1.6933e-01, time/batch = 15.2804s	
19206/28500 (epoch 33.695), train_loss = 0.67887029, grad/param norm = 2.0390e-01, time/batch = 15.5785s	
19207/28500 (epoch 33.696), train_loss = 0.84436001, grad/param norm = 1.6700e-01, time/batch = 15.6375s	
19208/28500 (epoch 33.698), train_loss = 0.90275802, grad/param norm = 1.8300e-01, time/batch = 15.6193s	
19209/28500 (epoch 33.700), train_loss = 0.89841949, grad/param norm = 1.9517e-01, time/batch = 15.2999s	
19210/28500 (epoch 33.702), train_loss = 0.88651858, grad/param norm = 2.1931e-01, time/batch = 15.3217s	
19211/28500 (epoch 33.704), train_loss = 0.91182842, grad/param norm = 2.0906e-01, time/batch = 15.2815s	
19212/28500 (epoch 33.705), train_loss = 0.96286669, grad/param norm = 2.1645e-01, time/batch = 15.0476s	
19213/28500 (epoch 33.707), train_loss = 0.81121954, grad/param norm = 1.7766e-01, time/batch = 15.4077s	
19214/28500 (epoch 33.709), train_loss = 0.99939961, grad/param norm = 1.9342e-01, time/batch = 15.3386s	
19215/28500 (epoch 33.711), train_loss = 0.81278663, grad/param norm = 1.8807e-01, time/batch = 15.3907s	
19216/28500 (epoch 33.712), train_loss = 0.88973352, grad/param norm = 1.7504e-01, time/batch = 15.4646s	
19217/28500 (epoch 33.714), train_loss = 0.98559518, grad/param norm = 1.8127e-01, time/batch = 15.1391s	
19218/28500 (epoch 33.716), train_loss = 0.86248067, grad/param norm = 1.7501e-01, time/batch = 15.0643s	
19219/28500 (epoch 33.718), train_loss = 0.89216510, grad/param norm = 1.9396e-01, time/batch = 15.0674s	
19220/28500 (epoch 33.719), train_loss = 0.87562523, grad/param norm = 1.6160e-01, time/batch = 15.4445s	
19221/28500 (epoch 33.721), train_loss = 0.69279518, grad/param norm = 1.7220e-01, time/batch = 15.5540s	
19222/28500 (epoch 33.723), train_loss = 0.88169540, grad/param norm = 1.6645e-01, time/batch = 15.3730s	
19223/28500 (epoch 33.725), train_loss = 0.94013007, grad/param norm = 1.7532e-01, time/batch = 15.2949s	
19224/28500 (epoch 33.726), train_loss = 0.88054834, grad/param norm = 2.0258e-01, time/batch = 15.3711s	
19225/28500 (epoch 33.728), train_loss = 0.78612333, grad/param norm = 1.6290e-01, time/batch = 15.4735s	
19226/28500 (epoch 33.730), train_loss = 0.87542150, grad/param norm = 1.9408e-01, time/batch = 15.4721s	
19227/28500 (epoch 33.732), train_loss = 0.69923323, grad/param norm = 1.4074e-01, time/batch = 15.4887s	
19228/28500 (epoch 33.733), train_loss = 0.73508083, grad/param norm = 1.5156e-01, time/batch = 15.5783s	
19229/28500 (epoch 33.735), train_loss = 0.74810109, grad/param norm = 1.6440e-01, time/batch = 15.4184s	
19230/28500 (epoch 33.737), train_loss = 0.66591715, grad/param norm = 1.4931e-01, time/batch = 15.3024s	
19231/28500 (epoch 33.739), train_loss = 0.77877319, grad/param norm = 1.8413e-01, time/batch = 15.3674s	
19232/28500 (epoch 33.740), train_loss = 0.85992458, grad/param norm = 1.7103e-01, time/batch = 15.1856s	
19233/28500 (epoch 33.742), train_loss = 0.75679986, grad/param norm = 1.5488e-01, time/batch = 15.0489s	
19234/28500 (epoch 33.744), train_loss = 0.86454755, grad/param norm = 1.6289e-01, time/batch = 15.2138s	
19235/28500 (epoch 33.746), train_loss = 0.81730175, grad/param norm = 1.5747e-01, time/batch = 15.0835s	
19236/28500 (epoch 33.747), train_loss = 0.80684344, grad/param norm = 1.6262e-01, time/batch = 15.1915s	
19237/28500 (epoch 33.749), train_loss = 0.92071223, grad/param norm = 1.9886e-01, time/batch = 15.2208s	
19238/28500 (epoch 33.751), train_loss = 0.75886357, grad/param norm = 1.8884e-01, time/batch = 15.2149s	
19239/28500 (epoch 33.753), train_loss = 0.84103422, grad/param norm = 1.6567e-01, time/batch = 15.2969s	
19240/28500 (epoch 33.754), train_loss = 0.76160832, grad/param norm = 1.6372e-01, time/batch = 15.1637s	
19241/28500 (epoch 33.756), train_loss = 0.96831703, grad/param norm = 1.7122e-01, time/batch = 15.2008s	
19242/28500 (epoch 33.758), train_loss = 0.92395136, grad/param norm = 1.9874e-01, time/batch = 15.1220s	
19243/28500 (epoch 33.760), train_loss = 0.75101299, grad/param norm = 2.2341e-01, time/batch = 15.1575s	
19244/28500 (epoch 33.761), train_loss = 0.79400381, grad/param norm = 1.7989e-01, time/batch = 15.3029s	
19245/28500 (epoch 33.763), train_loss = 0.69338365, grad/param norm = 1.6781e-01, time/batch = 15.2974s	
19246/28500 (epoch 33.765), train_loss = 0.83593133, grad/param norm = 1.5868e-01, time/batch = 15.2869s	
19247/28500 (epoch 33.767), train_loss = 0.72881829, grad/param norm = 1.4632e-01, time/batch = 27.4631s	
19248/28500 (epoch 33.768), train_loss = 0.90258007, grad/param norm = 1.8322e-01, time/batch = 15.2243s	
19249/28500 (epoch 33.770), train_loss = 0.76044398, grad/param norm = 1.6201e-01, time/batch = 15.6401s	
19250/28500 (epoch 33.772), train_loss = 0.68784052, grad/param norm = 1.4874e-01, time/batch = 15.5244s	
19251/28500 (epoch 33.774), train_loss = 0.85301789, grad/param norm = 1.6835e-01, time/batch = 15.4658s	
19252/28500 (epoch 33.775), train_loss = 0.93738767, grad/param norm = 1.7091e-01, time/batch = 15.4382s	
19253/28500 (epoch 33.777), train_loss = 0.91534168, grad/param norm = 1.5827e-01, time/batch = 15.5517s	
19254/28500 (epoch 33.779), train_loss = 0.70177345, grad/param norm = 1.3384e-01, time/batch = 15.5436s	
19255/28500 (epoch 33.781), train_loss = 0.84001877, grad/param norm = 1.7896e-01, time/batch = 15.2305s	
19256/28500 (epoch 33.782), train_loss = 0.85905485, grad/param norm = 1.9866e-01, time/batch = 15.1600s	
19257/28500 (epoch 33.784), train_loss = 0.68732377, grad/param norm = 1.5569e-01, time/batch = 15.1332s	
19258/28500 (epoch 33.786), train_loss = 0.73241305, grad/param norm = 1.5428e-01, time/batch = 15.5296s	
19259/28500 (epoch 33.788), train_loss = 0.84886639, grad/param norm = 2.0078e-01, time/batch = 15.4763s	
19260/28500 (epoch 33.789), train_loss = 0.63819417, grad/param norm = 2.3083e-01, time/batch = 15.2190s	
19261/28500 (epoch 33.791), train_loss = 0.87705086, grad/param norm = 1.8408e-01, time/batch = 15.4474s	
19262/28500 (epoch 33.793), train_loss = 0.84907462, grad/param norm = 1.7807e-01, time/batch = 15.5403s	
19263/28500 (epoch 33.795), train_loss = 0.87390896, grad/param norm = 1.9196e-01, time/batch = 15.2985s	
19264/28500 (epoch 33.796), train_loss = 0.75775174, grad/param norm = 1.6669e-01, time/batch = 15.4668s	
19265/28500 (epoch 33.798), train_loss = 0.70728111, grad/param norm = 1.7290e-01, time/batch = 15.4955s	
19266/28500 (epoch 33.800), train_loss = 0.71713734, grad/param norm = 1.9176e-01, time/batch = 15.3150s	
19267/28500 (epoch 33.802), train_loss = 0.81276244, grad/param norm = 2.1685e-01, time/batch = 15.1348s	
19268/28500 (epoch 33.804), train_loss = 0.88158960, grad/param norm = 1.6855e-01, time/batch = 15.0448s	
19269/28500 (epoch 33.805), train_loss = 0.87311224, grad/param norm = 2.0572e-01, time/batch = 15.2890s	
19270/28500 (epoch 33.807), train_loss = 0.84752506, grad/param norm = 1.7271e-01, time/batch = 15.0532s	
19271/28500 (epoch 33.809), train_loss = 0.85127833, grad/param norm = 1.9947e-01, time/batch = 15.4569s	
19272/28500 (epoch 33.811), train_loss = 0.87941629, grad/param norm = 1.8065e-01, time/batch = 15.4784s	
19273/28500 (epoch 33.812), train_loss = 0.85038058, grad/param norm = 1.9131e-01, time/batch = 15.3048s	
19274/28500 (epoch 33.814), train_loss = 0.80196022, grad/param norm = 1.7325e-01, time/batch = 15.1343s	
19275/28500 (epoch 33.816), train_loss = 0.87997158, grad/param norm = 1.9759e-01, time/batch = 15.5258s	
19276/28500 (epoch 33.818), train_loss = 0.96978052, grad/param norm = 1.8822e-01, time/batch = 15.2304s	
19277/28500 (epoch 33.819), train_loss = 0.85563966, grad/param norm = 1.7304e-01, time/batch = 15.2839s	
19278/28500 (epoch 33.821), train_loss = 0.80603314, grad/param norm = 1.6192e-01, time/batch = 15.5492s	
19279/28500 (epoch 33.823), train_loss = 0.95111402, grad/param norm = 1.9166e-01, time/batch = 15.3384s	
19280/28500 (epoch 33.825), train_loss = 0.81793545, grad/param norm = 2.0209e-01, time/batch = 15.1803s	
19281/28500 (epoch 33.826), train_loss = 0.86175566, grad/param norm = 2.1629e-01, time/batch = 15.1386s	
19282/28500 (epoch 33.828), train_loss = 0.79588072, grad/param norm = 2.0268e-01, time/batch = 15.1338s	
19283/28500 (epoch 33.830), train_loss = 0.80582119, grad/param norm = 1.6143e-01, time/batch = 15.4586s	
19284/28500 (epoch 33.832), train_loss = 0.84008869, grad/param norm = 1.9955e-01, time/batch = 15.1386s	
19285/28500 (epoch 33.833), train_loss = 0.92207587, grad/param norm = 1.6907e-01, time/batch = 15.5366s	
19286/28500 (epoch 33.835), train_loss = 0.80553723, grad/param norm = 1.7539e-01, time/batch = 15.3071s	
19287/28500 (epoch 33.837), train_loss = 0.72629331, grad/param norm = 1.6754e-01, time/batch = 15.4645s	
19288/28500 (epoch 33.839), train_loss = 0.99012414, grad/param norm = 2.0628e-01, time/batch = 15.3143s	
19289/28500 (epoch 33.840), train_loss = 0.98420226, grad/param norm = 1.8648e-01, time/batch = 15.1402s	
19290/28500 (epoch 33.842), train_loss = 0.90931207, grad/param norm = 2.3856e-01, time/batch = 15.2824s	
19291/28500 (epoch 33.844), train_loss = 0.92359505, grad/param norm = 2.1185e-01, time/batch = 15.4764s	
19292/28500 (epoch 33.846), train_loss = 1.01318767, grad/param norm = 2.4133e-01, time/batch = 15.1974s	
19293/28500 (epoch 33.847), train_loss = 0.82493903, grad/param norm = 1.9297e-01, time/batch = 15.3928s	
19294/28500 (epoch 33.849), train_loss = 0.82960518, grad/param norm = 1.9433e-01, time/batch = 15.3062s	
19295/28500 (epoch 33.851), train_loss = 0.75133643, grad/param norm = 1.6691e-01, time/batch = 15.3199s	
19296/28500 (epoch 33.853), train_loss = 0.88228001, grad/param norm = 1.9400e-01, time/batch = 15.6125s	
19297/28500 (epoch 33.854), train_loss = 0.88595941, grad/param norm = 2.2177e-01, time/batch = 15.3109s	
19298/28500 (epoch 33.856), train_loss = 0.95418329, grad/param norm = 2.3847e-01, time/batch = 15.2285s	
19299/28500 (epoch 33.858), train_loss = 0.81183511, grad/param norm = 1.7887e-01, time/batch = 15.0050s	
19300/28500 (epoch 33.860), train_loss = 0.82674314, grad/param norm = 1.8771e-01, time/batch = 15.0549s	
19301/28500 (epoch 33.861), train_loss = 0.91701591, grad/param norm = 2.1178e-01, time/batch = 15.2160s	
19302/28500 (epoch 33.863), train_loss = 0.88388979, grad/param norm = 2.0630e-01, time/batch = 15.3831s	
19303/28500 (epoch 33.865), train_loss = 0.80005589, grad/param norm = 1.8318e-01, time/batch = 15.3060s	
19304/28500 (epoch 33.867), train_loss = 0.89878206, grad/param norm = 2.0891e-01, time/batch = 15.6003s	
19305/28500 (epoch 33.868), train_loss = 0.77335546, grad/param norm = 1.6652e-01, time/batch = 15.6260s	
19306/28500 (epoch 33.870), train_loss = 0.73625789, grad/param norm = 1.6477e-01, time/batch = 15.3457s	
19307/28500 (epoch 33.872), train_loss = 0.90295535, grad/param norm = 1.9182e-01, time/batch = 15.3600s	
19308/28500 (epoch 33.874), train_loss = 0.76893599, grad/param norm = 2.0187e-01, time/batch = 15.4353s	
19309/28500 (epoch 33.875), train_loss = 0.98953748, grad/param norm = 2.0132e-01, time/batch = 15.1839s	
19310/28500 (epoch 33.877), train_loss = 0.88877377, grad/param norm = 1.8867e-01, time/batch = 15.3284s	
19311/28500 (epoch 33.879), train_loss = 0.92357346, grad/param norm = 1.6489e-01, time/batch = 15.3454s	
19312/28500 (epoch 33.881), train_loss = 0.88790228, grad/param norm = 1.8039e-01, time/batch = 15.3308s	
19313/28500 (epoch 33.882), train_loss = 0.79687586, grad/param norm = 1.5759e-01, time/batch = 15.4658s	
19314/28500 (epoch 33.884), train_loss = 0.85598522, grad/param norm = 1.9080e-01, time/batch = 15.2188s	
19315/28500 (epoch 33.886), train_loss = 0.81374799, grad/param norm = 1.6170e-01, time/batch = 15.3911s	
19316/28500 (epoch 33.888), train_loss = 0.80369398, grad/param norm = 1.5016e-01, time/batch = 15.3731s	
19317/28500 (epoch 33.889), train_loss = 0.86045531, grad/param norm = 1.5729e-01, time/batch = 15.0590s	
19318/28500 (epoch 33.891), train_loss = 0.85505262, grad/param norm = 1.6490e-01, time/batch = 15.1456s	
19319/28500 (epoch 33.893), train_loss = 0.81898719, grad/param norm = 1.7808e-01, time/batch = 15.5855s	
19320/28500 (epoch 33.895), train_loss = 0.99686513, grad/param norm = 2.1780e-01, time/batch = 15.3266s	
19321/28500 (epoch 33.896), train_loss = 0.94626464, grad/param norm = 1.9311e-01, time/batch = 15.3967s	
19322/28500 (epoch 33.898), train_loss = 0.88062554, grad/param norm = 1.7349e-01, time/batch = 15.5382s	
19323/28500 (epoch 33.900), train_loss = 0.73985481, grad/param norm = 1.6179e-01, time/batch = 15.5103s	
19324/28500 (epoch 33.902), train_loss = 0.74062416, grad/param norm = 1.6778e-01, time/batch = 15.6779s	
19325/28500 (epoch 33.904), train_loss = 0.74035448, grad/param norm = 1.5537e-01, time/batch = 15.5405s	
19326/28500 (epoch 33.905), train_loss = 0.81912743, grad/param norm = 2.0213e-01, time/batch = 15.4838s	
19327/28500 (epoch 33.907), train_loss = 0.83658278, grad/param norm = 1.7829e-01, time/batch = 15.5472s	
19328/28500 (epoch 33.909), train_loss = 0.71451223, grad/param norm = 1.7258e-01, time/batch = 15.2965s	
19329/28500 (epoch 33.911), train_loss = 0.76706321, grad/param norm = 1.6707e-01, time/batch = 15.4684s	
19330/28500 (epoch 33.912), train_loss = 0.65103872, grad/param norm = 1.5941e-01, time/batch = 15.0619s	
19331/28500 (epoch 33.914), train_loss = 0.84666427, grad/param norm = 1.7292e-01, time/batch = 15.1965s	
19332/28500 (epoch 33.916), train_loss = 0.85069378, grad/param norm = 1.8652e-01, time/batch = 15.2008s	
19333/28500 (epoch 33.918), train_loss = 0.84164333, grad/param norm = 1.9758e-01, time/batch = 15.4931s	
19334/28500 (epoch 33.919), train_loss = 0.84024663, grad/param norm = 1.5622e-01, time/batch = 15.3976s	
19335/28500 (epoch 33.921), train_loss = 0.93525445, grad/param norm = 2.0905e-01, time/batch = 15.3725s	
19336/28500 (epoch 33.923), train_loss = 0.81861210, grad/param norm = 2.7328e-01, time/batch = 15.3868s	
19337/28500 (epoch 33.925), train_loss = 0.79933074, grad/param norm = 1.9531e-01, time/batch = 14.9714s	
19338/28500 (epoch 33.926), train_loss = 0.86812647, grad/param norm = 1.9315e-01, time/batch = 15.2193s	
19339/28500 (epoch 33.928), train_loss = 0.79808335, grad/param norm = 1.6626e-01, time/batch = 15.4434s	
19340/28500 (epoch 33.930), train_loss = 0.66352295, grad/param norm = 1.3512e-01, time/batch = 15.4611s	
19341/28500 (epoch 33.932), train_loss = 0.68209812, grad/param norm = 1.4228e-01, time/batch = 15.3148s	
19342/28500 (epoch 33.933), train_loss = 0.90465624, grad/param norm = 1.8615e-01, time/batch = 15.4531s	
19343/28500 (epoch 33.935), train_loss = 0.93578798, grad/param norm = 1.7610e-01, time/batch = 15.3808s	
19344/28500 (epoch 33.937), train_loss = 0.93413243, grad/param norm = 2.1279e-01, time/batch = 15.2714s	
19345/28500 (epoch 33.939), train_loss = 0.98528150, grad/param norm = 2.1199e-01, time/batch = 15.1220s	
19346/28500 (epoch 33.940), train_loss = 0.72774696, grad/param norm = 1.8080e-01, time/batch = 15.1905s	
19347/28500 (epoch 33.942), train_loss = 0.84289087, grad/param norm = 1.7290e-01, time/batch = 15.2520s	
19348/28500 (epoch 33.944), train_loss = 0.81367975, grad/param norm = 1.9814e-01, time/batch = 15.0469s	
19349/28500 (epoch 33.946), train_loss = 0.91819206, grad/param norm = 1.8231e-01, time/batch = 15.1905s	
19350/28500 (epoch 33.947), train_loss = 1.07043116, grad/param norm = 2.5563e-01, time/batch = 15.3016s	
19351/28500 (epoch 33.949), train_loss = 0.83990067, grad/param norm = 1.9482e-01, time/batch = 15.3628s	
19352/28500 (epoch 33.951), train_loss = 1.01156701, grad/param norm = 1.9162e-01, time/batch = 22.4323s	
19353/28500 (epoch 33.953), train_loss = 1.00176461, grad/param norm = 2.0839e-01, time/batch = 15.5385s	
19354/28500 (epoch 33.954), train_loss = 0.94817972, grad/param norm = 2.1414e-01, time/batch = 15.4155s	
19355/28500 (epoch 33.956), train_loss = 0.90639731, grad/param norm = 3.1945e-01, time/batch = 15.5212s	
19356/28500 (epoch 33.958), train_loss = 1.10106921, grad/param norm = 2.0183e-01, time/batch = 15.3889s	
19357/28500 (epoch 33.960), train_loss = 0.81190249, grad/param norm = 2.2515e-01, time/batch = 15.4693s	
19358/28500 (epoch 33.961), train_loss = 0.99697021, grad/param norm = 2.0372e-01, time/batch = 15.5389s	
19359/28500 (epoch 33.963), train_loss = 0.96659757, grad/param norm = 2.1108e-01, time/batch = 15.4909s	
19360/28500 (epoch 33.965), train_loss = 0.79057124, grad/param norm = 1.7203e-01, time/batch = 15.3575s	
19361/28500 (epoch 33.967), train_loss = 0.80066861, grad/param norm = 1.7258e-01, time/batch = 15.3789s	
19362/28500 (epoch 33.968), train_loss = 0.74061282, grad/param norm = 1.4849e-01, time/batch = 15.5237s	
19363/28500 (epoch 33.970), train_loss = 0.80650089, grad/param norm = 2.4141e-01, time/batch = 15.3741s	
19364/28500 (epoch 33.972), train_loss = 0.87399195, grad/param norm = 1.8710e-01, time/batch = 15.5553s	
19365/28500 (epoch 33.974), train_loss = 1.04702166, grad/param norm = 2.1002e-01, time/batch = 15.5654s	
19366/28500 (epoch 33.975), train_loss = 0.79943456, grad/param norm = 1.7026e-01, time/batch = 15.5283s	
19367/28500 (epoch 33.977), train_loss = 0.94805436, grad/param norm = 2.0875e-01, time/batch = 14.9909s	
19368/28500 (epoch 33.979), train_loss = 0.86959255, grad/param norm = 1.7564e-01, time/batch = 15.2790s	
19369/28500 (epoch 33.981), train_loss = 0.76272306, grad/param norm = 2.1002e-01, time/batch = 15.3741s	
19370/28500 (epoch 33.982), train_loss = 0.83467031, grad/param norm = 1.8217e-01, time/batch = 15.3706s	
19371/28500 (epoch 33.984), train_loss = 0.94205877, grad/param norm = 1.7571e-01, time/batch = 15.6813s	
19372/28500 (epoch 33.986), train_loss = 1.12951352, grad/param norm = 2.0990e-01, time/batch = 15.4276s	
19373/28500 (epoch 33.988), train_loss = 0.77390674, grad/param norm = 1.6930e-01, time/batch = 15.4228s	
19374/28500 (epoch 33.989), train_loss = 0.89367156, grad/param norm = 1.9798e-01, time/batch = 15.1249s	
19375/28500 (epoch 33.991), train_loss = 0.80213243, grad/param norm = 2.0339e-01, time/batch = 15.1348s	
19376/28500 (epoch 33.993), train_loss = 0.77135391, grad/param norm = 1.8176e-01, time/batch = 15.3139s	
19377/28500 (epoch 33.995), train_loss = 0.79866529, grad/param norm = 1.8273e-01, time/batch = 15.1293s	
19378/28500 (epoch 33.996), train_loss = 0.77549920, grad/param norm = 1.8037e-01, time/batch = 15.4437s	
19379/28500 (epoch 33.998), train_loss = 0.94756476, grad/param norm = 2.1497e-01, time/batch = 15.2872s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
19380/28500 (epoch 34.000), train_loss = 0.83760385, grad/param norm = 1.8747e-01, time/batch = 15.2772s	
19381/28500 (epoch 34.002), train_loss = 1.02008676, grad/param norm = 2.1591e-01, time/batch = 15.5317s	
19382/28500 (epoch 34.004), train_loss = 0.83865665, grad/param norm = 1.6021e-01, time/batch = 15.5454s	
19383/28500 (epoch 34.005), train_loss = 0.96440644, grad/param norm = 2.1434e-01, time/batch = 15.5261s	
19384/28500 (epoch 34.007), train_loss = 0.77855452, grad/param norm = 2.0405e-01, time/batch = 15.4603s	
19385/28500 (epoch 34.009), train_loss = 0.88935847, grad/param norm = 1.9259e-01, time/batch = 15.3782s	
19386/28500 (epoch 34.011), train_loss = 0.79402045, grad/param norm = 1.8394e-01, time/batch = 15.5709s	
19387/28500 (epoch 34.012), train_loss = 0.76105009, grad/param norm = 1.6295e-01, time/batch = 15.2768s	
19388/28500 (epoch 34.014), train_loss = 0.76609028, grad/param norm = 1.8235e-01, time/batch = 15.3579s	
19389/28500 (epoch 34.016), train_loss = 0.82227623, grad/param norm = 1.7212e-01, time/batch = 15.5254s	
19390/28500 (epoch 34.018), train_loss = 0.90906451, grad/param norm = 1.9285e-01, time/batch = 15.2913s	
19391/28500 (epoch 34.019), train_loss = 0.94394549, grad/param norm = 1.8237e-01, time/batch = 15.5331s	
19392/28500 (epoch 34.021), train_loss = 0.96691040, grad/param norm = 1.6324e-01, time/batch = 15.7222s	
19393/28500 (epoch 34.023), train_loss = 0.87620307, grad/param norm = 1.8588e-01, time/batch = 15.5391s	
19394/28500 (epoch 34.025), train_loss = 0.87777500, grad/param norm = 1.6659e-01, time/batch = 15.5279s	
19395/28500 (epoch 34.026), train_loss = 0.83774439, grad/param norm = 1.7528e-01, time/batch = 15.3539s	
19396/28500 (epoch 34.028), train_loss = 0.88204968, grad/param norm = 1.8282e-01, time/batch = 15.3276s	
19397/28500 (epoch 34.030), train_loss = 0.91253562, grad/param norm = 2.0281e-01, time/batch = 15.3868s	
19398/28500 (epoch 34.032), train_loss = 0.95673616, grad/param norm = 1.8530e-01, time/batch = 15.3854s	
19399/28500 (epoch 34.033), train_loss = 1.01124294, grad/param norm = 1.8891e-01, time/batch = 15.5696s	
19400/28500 (epoch 34.035), train_loss = 0.83456346, grad/param norm = 1.9790e-01, time/batch = 15.3634s	
19401/28500 (epoch 34.037), train_loss = 0.92049727, grad/param norm = 1.7372e-01, time/batch = 15.5057s	
19402/28500 (epoch 34.039), train_loss = 0.98293888, grad/param norm = 2.1141e-01, time/batch = 15.1441s	
19403/28500 (epoch 34.040), train_loss = 1.00362934, grad/param norm = 1.9144e-01, time/batch = 15.3588s	
19404/28500 (epoch 34.042), train_loss = 0.94378608, grad/param norm = 1.9910e-01, time/batch = 15.1992s	
19405/28500 (epoch 34.044), train_loss = 0.88295814, grad/param norm = 1.8716e-01, time/batch = 15.2331s	
19406/28500 (epoch 34.046), train_loss = 1.08121297, grad/param norm = 2.0741e-01, time/batch = 15.2174s	
19407/28500 (epoch 34.047), train_loss = 1.01181730, grad/param norm = 2.3928e-01, time/batch = 15.4412s	
19408/28500 (epoch 34.049), train_loss = 0.87494164, grad/param norm = 1.9079e-01, time/batch = 15.4781s	
19409/28500 (epoch 34.051), train_loss = 0.88203726, grad/param norm = 2.0808e-01, time/batch = 15.4498s	
19410/28500 (epoch 34.053), train_loss = 0.85582677, grad/param norm = 2.0902e-01, time/batch = 15.2891s	
19411/28500 (epoch 34.054), train_loss = 0.95420318, grad/param norm = 1.8641e-01, time/batch = 15.4594s	
19412/28500 (epoch 34.056), train_loss = 0.80189897, grad/param norm = 1.6769e-01, time/batch = 15.4338s	
19413/28500 (epoch 34.058), train_loss = 0.79963041, grad/param norm = 1.5946e-01, time/batch = 15.2593s	
19414/28500 (epoch 34.060), train_loss = 0.92040175, grad/param norm = 1.8008e-01, time/batch = 15.3760s	
19415/28500 (epoch 34.061), train_loss = 0.86868404, grad/param norm = 1.9165e-01, time/batch = 15.3648s	
19416/28500 (epoch 34.063), train_loss = 0.93112813, grad/param norm = 1.8854e-01, time/batch = 15.5510s	
19417/28500 (epoch 34.065), train_loss = 0.89184407, grad/param norm = 1.9349e-01, time/batch = 15.6170s	
19418/28500 (epoch 34.067), train_loss = 0.81558948, grad/param norm = 1.8083e-01, time/batch = 15.3070s	
19419/28500 (epoch 34.068), train_loss = 0.84590236, grad/param norm = 1.8037e-01, time/batch = 15.6332s	
19420/28500 (epoch 34.070), train_loss = 0.91884565, grad/param norm = 2.0322e-01, time/batch = 15.4608s	
19421/28500 (epoch 34.072), train_loss = 0.98887853, grad/param norm = 1.9273e-01, time/batch = 15.6164s	
19422/28500 (epoch 34.074), train_loss = 0.87759555, grad/param norm = 1.7384e-01, time/batch = 15.5411s	
19423/28500 (epoch 34.075), train_loss = 0.83436726, grad/param norm = 1.5161e-01, time/batch = 15.4313s	
19424/28500 (epoch 34.077), train_loss = 0.92046915, grad/param norm = 1.6687e-01, time/batch = 15.4333s	
19425/28500 (epoch 34.079), train_loss = 0.86925974, grad/param norm = 1.7911e-01, time/batch = 15.4529s	
19426/28500 (epoch 34.081), train_loss = 0.99062521, grad/param norm = 2.1299e-01, time/batch = 15.4149s	
19427/28500 (epoch 34.082), train_loss = 0.90271165, grad/param norm = 2.3567e-01, time/batch = 15.3090s	
19428/28500 (epoch 34.084), train_loss = 0.91102305, grad/param norm = 2.0632e-01, time/batch = 15.5236s	
19429/28500 (epoch 34.086), train_loss = 0.86221220, grad/param norm = 2.3347e-01, time/batch = 15.3598s	
19430/28500 (epoch 34.088), train_loss = 0.78977374, grad/param norm = 1.8204e-01, time/batch = 15.3801s	
19431/28500 (epoch 34.089), train_loss = 0.94110299, grad/param norm = 1.8286e-01, time/batch = 15.3763s	
19432/28500 (epoch 34.091), train_loss = 0.78277491, grad/param norm = 1.7080e-01, time/batch = 15.2879s	
19433/28500 (epoch 34.093), train_loss = 0.95789004, grad/param norm = 1.7684e-01, time/batch = 15.1521s	
19434/28500 (epoch 34.095), train_loss = 0.88408359, grad/param norm = 1.7010e-01, time/batch = 15.1425s	
19435/28500 (epoch 34.096), train_loss = 0.96392515, grad/param norm = 1.8360e-01, time/batch = 15.1402s	
19436/28500 (epoch 34.098), train_loss = 0.89848691, grad/param norm = 2.2246e-01, time/batch = 15.2092s	
19437/28500 (epoch 34.100), train_loss = 0.84961534, grad/param norm = 1.7023e-01, time/batch = 15.1476s	
19438/28500 (epoch 34.102), train_loss = 0.95601523, grad/param norm = 2.3832e-01, time/batch = 15.2650s	
19439/28500 (epoch 34.104), train_loss = 0.89078277, grad/param norm = 1.8184e-01, time/batch = 15.5126s	
19440/28500 (epoch 34.105), train_loss = 0.99372515, grad/param norm = 1.7287e-01, time/batch = 15.3570s	
19441/28500 (epoch 34.107), train_loss = 0.80193793, grad/param norm = 1.8600e-01, time/batch = 15.1968s	
19442/28500 (epoch 34.109), train_loss = 0.83161639, grad/param norm = 2.2330e-01, time/batch = 15.1246s	
19443/28500 (epoch 34.111), train_loss = 0.85456195, grad/param norm = 2.2155e-01, time/batch = 15.2643s	
19444/28500 (epoch 34.112), train_loss = 0.94448635, grad/param norm = 1.8348e-01, time/batch = 15.3578s	
19445/28500 (epoch 34.114), train_loss = 0.85655353, grad/param norm = 1.7282e-01, time/batch = 15.2228s	
19446/28500 (epoch 34.116), train_loss = 1.01978546, grad/param norm = 1.9248e-01, time/batch = 15.1122s	
19447/28500 (epoch 34.118), train_loss = 0.78116418, grad/param norm = 1.6644e-01, time/batch = 15.3078s	
19448/28500 (epoch 34.119), train_loss = 0.88928520, grad/param norm = 1.8068e-01, time/batch = 15.3753s	
19449/28500 (epoch 34.121), train_loss = 1.05260849, grad/param norm = 2.1384e-01, time/batch = 15.1425s	
19450/28500 (epoch 34.123), train_loss = 0.97693972, grad/param norm = 1.9607e-01, time/batch = 15.1991s	
19451/28500 (epoch 34.125), train_loss = 0.89702562, grad/param norm = 1.7911e-01, time/batch = 15.4780s	
19452/28500 (epoch 34.126), train_loss = 0.88782634, grad/param norm = 2.0983e-01, time/batch = 15.5198s	
19453/28500 (epoch 34.128), train_loss = 0.89675481, grad/param norm = 1.8527e-01, time/batch = 15.5758s	
19454/28500 (epoch 34.130), train_loss = 0.83552309, grad/param norm = 2.1457e-01, time/batch = 15.4690s	
19455/28500 (epoch 34.132), train_loss = 0.87563780, grad/param norm = 2.1295e-01, time/batch = 15.3855s	
19456/28500 (epoch 34.133), train_loss = 0.93612934, grad/param norm = 1.8901e-01, time/batch = 15.4756s	
19457/28500 (epoch 34.135), train_loss = 0.83605420, grad/param norm = 1.7984e-01, time/batch = 15.4736s	
19458/28500 (epoch 34.137), train_loss = 0.89206002, grad/param norm = 1.7345e-01, time/batch = 15.4519s	
19459/28500 (epoch 34.139), train_loss = 0.88792144, grad/param norm = 1.7372e-01, time/batch = 15.4406s	
19460/28500 (epoch 34.140), train_loss = 0.87721352, grad/param norm = 1.7229e-01, time/batch = 15.3824s	
19461/28500 (epoch 34.142), train_loss = 0.83737955, grad/param norm = 1.7936e-01, time/batch = 15.1989s	
19462/28500 (epoch 34.144), train_loss = 0.79820218, grad/param norm = 1.6883e-01, time/batch = 15.3557s	
19463/28500 (epoch 34.146), train_loss = 0.86456022, grad/param norm = 1.9260e-01, time/batch = 15.3537s	
19464/28500 (epoch 34.147), train_loss = 0.75103467, grad/param norm = 1.6142e-01, time/batch = 15.3810s	
19465/28500 (epoch 34.149), train_loss = 0.75770758, grad/param norm = 1.6520e-01, time/batch = 15.3861s	
19466/28500 (epoch 34.151), train_loss = 0.84302036, grad/param norm = 1.6675e-01, time/batch = 15.3218s	
19467/28500 (epoch 34.153), train_loss = 0.89793819, grad/param norm = 1.7510e-01, time/batch = 15.4331s	
19468/28500 (epoch 34.154), train_loss = 0.77229007, grad/param norm = 1.7286e-01, time/batch = 15.2164s	
19469/28500 (epoch 34.156), train_loss = 0.95454359, grad/param norm = 1.9597e-01, time/batch = 15.1257s	
19470/28500 (epoch 34.158), train_loss = 0.87834238, grad/param norm = 1.6153e-01, time/batch = 15.0608s	
19471/28500 (epoch 34.160), train_loss = 0.79971793, grad/param norm = 1.8768e-01, time/batch = 15.1979s	
19472/28500 (epoch 34.161), train_loss = 0.82374996, grad/param norm = 2.0115e-01, time/batch = 15.3174s	
19473/28500 (epoch 34.163), train_loss = 0.75298454, grad/param norm = 1.6606e-01, time/batch = 15.4702s	
19474/28500 (epoch 34.165), train_loss = 1.04078238, grad/param norm = 1.9435e-01, time/batch = 15.2193s	
19475/28500 (epoch 34.167), train_loss = 1.04370813, grad/param norm = 1.9490e-01, time/batch = 15.5509s	
19476/28500 (epoch 34.168), train_loss = 0.98569992, grad/param norm = 2.1341e-01, time/batch = 15.4317s	
19477/28500 (epoch 34.170), train_loss = 0.97006427, grad/param norm = 2.5332e-01, time/batch = 15.5298s	
19478/28500 (epoch 34.172), train_loss = 0.88489340, grad/param norm = 2.6223e-01, time/batch = 17.3975s	
19479/28500 (epoch 34.174), train_loss = 1.04417476, grad/param norm = 2.1989e-01, time/batch = 25.9756s	
19480/28500 (epoch 34.175), train_loss = 0.88148106, grad/param norm = 1.8873e-01, time/batch = 15.3889s	
19481/28500 (epoch 34.177), train_loss = 0.93761782, grad/param norm = 1.9617e-01, time/batch = 15.5376s	
19482/28500 (epoch 34.179), train_loss = 0.95422241, grad/param norm = 1.8024e-01, time/batch = 15.6093s	
19483/28500 (epoch 34.181), train_loss = 0.93876563, grad/param norm = 2.0101e-01, time/batch = 15.4229s	
19484/28500 (epoch 34.182), train_loss = 0.84042802, grad/param norm = 1.7706e-01, time/batch = 15.6016s	
19485/28500 (epoch 34.184), train_loss = 1.04282331, grad/param norm = 2.0294e-01, time/batch = 15.3594s	
19486/28500 (epoch 34.186), train_loss = 1.00182187, grad/param norm = 1.8370e-01, time/batch = 15.5973s	
19487/28500 (epoch 34.188), train_loss = 0.93493586, grad/param norm = 1.8580e-01, time/batch = 15.6035s	
19488/28500 (epoch 34.189), train_loss = 0.88920939, grad/param norm = 1.6622e-01, time/batch = 15.5487s	
19489/28500 (epoch 34.191), train_loss = 1.07844811, grad/param norm = 2.1028e-01, time/batch = 15.4524s	
19490/28500 (epoch 34.193), train_loss = 0.91271221, grad/param norm = 2.2106e-01, time/batch = 15.2857s	
19491/28500 (epoch 34.195), train_loss = 1.02425241, grad/param norm = 2.0258e-01, time/batch = 15.5334s	
19492/28500 (epoch 34.196), train_loss = 0.94951282, grad/param norm = 1.9134e-01, time/batch = 15.4893s	
19493/28500 (epoch 34.198), train_loss = 0.90217201, grad/param norm = 1.9141e-01, time/batch = 15.3549s	
19494/28500 (epoch 34.200), train_loss = 0.96381485, grad/param norm = 2.0231e-01, time/batch = 15.4436s	
19495/28500 (epoch 34.202), train_loss = 0.91709710, grad/param norm = 1.8261e-01, time/batch = 15.3218s	
19496/28500 (epoch 34.204), train_loss = 0.88779712, grad/param norm = 1.6784e-01, time/batch = 15.3143s	
19497/28500 (epoch 34.205), train_loss = 0.83950529, grad/param norm = 1.6646e-01, time/batch = 15.4897s	
19498/28500 (epoch 34.207), train_loss = 0.78245938, grad/param norm = 2.2120e-01, time/batch = 15.4597s	
19499/28500 (epoch 34.209), train_loss = 0.93049073, grad/param norm = 1.8580e-01, time/batch = 15.4656s	
19500/28500 (epoch 34.211), train_loss = 0.80648542, grad/param norm = 2.0288e-01, time/batch = 15.4784s	
19501/28500 (epoch 34.212), train_loss = 0.75806544, grad/param norm = 1.8269e-01, time/batch = 15.4584s	
19502/28500 (epoch 34.214), train_loss = 0.88031233, grad/param norm = 1.6753e-01, time/batch = 15.3687s	
19503/28500 (epoch 34.216), train_loss = 0.83737744, grad/param norm = 1.8408e-01, time/batch = 15.1238s	
19504/28500 (epoch 34.218), train_loss = 0.98462168, grad/param norm = 1.7228e-01, time/batch = 15.3107s	
19505/28500 (epoch 34.219), train_loss = 0.92208409, grad/param norm = 1.9664e-01, time/batch = 15.3138s	
19506/28500 (epoch 34.221), train_loss = 0.75708728, grad/param norm = 1.9367e-01, time/batch = 15.0561s	
19507/28500 (epoch 34.223), train_loss = 1.00523913, grad/param norm = 2.2936e-01, time/batch = 15.2738s	
19508/28500 (epoch 34.225), train_loss = 1.02162230, grad/param norm = 1.9209e-01, time/batch = 15.3009s	
19509/28500 (epoch 34.226), train_loss = 0.84762761, grad/param norm = 1.7415e-01, time/batch = 15.4638s	
19510/28500 (epoch 34.228), train_loss = 0.96623665, grad/param norm = 1.8119e-01, time/batch = 15.6289s	
19511/28500 (epoch 34.230), train_loss = 0.94727366, grad/param norm = 1.7570e-01, time/batch = 15.6883s	
19512/28500 (epoch 34.232), train_loss = 0.93935410, grad/param norm = 1.9647e-01, time/batch = 15.6232s	
19513/28500 (epoch 34.233), train_loss = 0.87997652, grad/param norm = 1.8656e-01, time/batch = 15.2842s	
19514/28500 (epoch 34.235), train_loss = 0.88008909, grad/param norm = 1.7676e-01, time/batch = 15.2735s	
19515/28500 (epoch 34.237), train_loss = 0.79879782, grad/param norm = 1.6202e-01, time/batch = 15.1455s	
19516/28500 (epoch 34.239), train_loss = 0.85089809, grad/param norm = 1.6627e-01, time/batch = 15.2717s	
19517/28500 (epoch 34.240), train_loss = 0.77184441, grad/param norm = 1.5212e-01, time/batch = 15.2965s	
19518/28500 (epoch 34.242), train_loss = 0.84411117, grad/param norm = 1.7780e-01, time/batch = 15.2627s	
19519/28500 (epoch 34.244), train_loss = 0.91361037, grad/param norm = 1.6539e-01, time/batch = 15.2192s	
19520/28500 (epoch 34.246), train_loss = 0.93908191, grad/param norm = 1.7774e-01, time/batch = 15.2289s	
19521/28500 (epoch 34.247), train_loss = 1.00497541, grad/param norm = 2.1330e-01, time/batch = 15.6066s	
19522/28500 (epoch 34.249), train_loss = 0.85784579, grad/param norm = 1.7385e-01, time/batch = 15.5241s	
19523/28500 (epoch 34.251), train_loss = 0.86135729, grad/param norm = 1.6362e-01, time/batch = 15.3737s	
19524/28500 (epoch 34.253), train_loss = 1.00480218, grad/param norm = 1.9697e-01, time/batch = 15.4235s	
19525/28500 (epoch 34.254), train_loss = 1.03284091, grad/param norm = 1.7309e-01, time/batch = 15.3212s	
19526/28500 (epoch 34.256), train_loss = 0.88377840, grad/param norm = 1.8037e-01, time/batch = 15.3027s	
19527/28500 (epoch 34.258), train_loss = 0.87268989, grad/param norm = 1.9236e-01, time/batch = 15.1233s	
19528/28500 (epoch 34.260), train_loss = 0.87382795, grad/param norm = 1.7232e-01, time/batch = 15.3661s	
19529/28500 (epoch 34.261), train_loss = 0.79195277, grad/param norm = 1.7716e-01, time/batch = 15.4652s	
19530/28500 (epoch 34.263), train_loss = 0.95486530, grad/param norm = 2.0687e-01, time/batch = 15.3868s	
19531/28500 (epoch 34.265), train_loss = 0.85968935, grad/param norm = 1.9680e-01, time/batch = 15.2818s	
19532/28500 (epoch 34.267), train_loss = 1.02337320, grad/param norm = 2.4602e-01, time/batch = 15.3137s	
19533/28500 (epoch 34.268), train_loss = 0.92068897, grad/param norm = 1.5485e-01, time/batch = 15.3141s	
19534/28500 (epoch 34.270), train_loss = 0.89181775, grad/param norm = 1.8896e-01, time/batch = 15.4872s	
19535/28500 (epoch 34.272), train_loss = 0.91103380, grad/param norm = 1.7726e-01, time/batch = 15.2317s	
19536/28500 (epoch 34.274), train_loss = 0.95397135, grad/param norm = 1.9718e-01, time/batch = 15.3654s	
19537/28500 (epoch 34.275), train_loss = 0.95121831, grad/param norm = 1.7064e-01, time/batch = 15.1312s	
19538/28500 (epoch 34.277), train_loss = 0.86166944, grad/param norm = 1.6822e-01, time/batch = 15.1425s	
19539/28500 (epoch 34.279), train_loss = 0.92040316, grad/param norm = 2.0894e-01, time/batch = 15.1735s	
19540/28500 (epoch 34.281), train_loss = 0.94946548, grad/param norm = 2.1610e-01, time/batch = 15.5918s	
19541/28500 (epoch 34.282), train_loss = 0.86004488, grad/param norm = 1.6151e-01, time/batch = 15.6343s	
19542/28500 (epoch 34.284), train_loss = 0.90799921, grad/param norm = 1.8828e-01, time/batch = 15.6284s	
19543/28500 (epoch 34.286), train_loss = 1.01829340, grad/param norm = 1.9383e-01, time/batch = 15.5450s	
19544/28500 (epoch 34.288), train_loss = 0.89071439, grad/param norm = 1.8996e-01, time/batch = 15.5198s	
19545/28500 (epoch 34.289), train_loss = 0.93147721, grad/param norm = 2.0631e-01, time/batch = 15.5570s	
19546/28500 (epoch 34.291), train_loss = 0.90800610, grad/param norm = 1.8011e-01, time/batch = 15.3726s	
19547/28500 (epoch 34.293), train_loss = 0.88677737, grad/param norm = 1.7560e-01, time/batch = 15.3094s	
19548/28500 (epoch 34.295), train_loss = 0.81062855, grad/param norm = 1.7279e-01, time/batch = 15.3758s	
19549/28500 (epoch 34.296), train_loss = 0.77803001, grad/param norm = 1.5584e-01, time/batch = 15.2387s	
19550/28500 (epoch 34.298), train_loss = 0.92630685, grad/param norm = 1.6417e-01, time/batch = 15.0511s	
19551/28500 (epoch 34.300), train_loss = 0.83534349, grad/param norm = 1.8195e-01, time/batch = 15.1259s	
19552/28500 (epoch 34.302), train_loss = 0.77099795, grad/param norm = 1.6714e-01, time/batch = 15.3256s	
19553/28500 (epoch 34.304), train_loss = 0.87282367, grad/param norm = 1.8295e-01, time/batch = 15.6410s	
19554/28500 (epoch 34.305), train_loss = 0.90908644, grad/param norm = 1.7171e-01, time/batch = 15.4706s	
19555/28500 (epoch 34.307), train_loss = 0.86314525, grad/param norm = 1.7919e-01, time/batch = 15.5047s	
19556/28500 (epoch 34.309), train_loss = 0.86193214, grad/param norm = 1.6147e-01, time/batch = 15.5792s	
19557/28500 (epoch 34.311), train_loss = 0.92729846, grad/param norm = 1.8114e-01, time/batch = 15.4576s	
19558/28500 (epoch 34.312), train_loss = 0.91977208, grad/param norm = 1.7303e-01, time/batch = 15.5255s	
19559/28500 (epoch 34.314), train_loss = 0.93811469, grad/param norm = 1.9493e-01, time/batch = 15.4065s	
19560/28500 (epoch 34.316), train_loss = 0.90753635, grad/param norm = 2.0537e-01, time/batch = 15.5333s	
19561/28500 (epoch 34.318), train_loss = 0.97165068, grad/param norm = 1.6564e-01, time/batch = 15.8008s	
19562/28500 (epoch 34.319), train_loss = 0.84716003, grad/param norm = 1.8263e-01, time/batch = 15.5587s	
19563/28500 (epoch 34.321), train_loss = 0.86721747, grad/param norm = 1.8931e-01, time/batch = 15.3584s	
19564/28500 (epoch 34.323), train_loss = 0.87721180, grad/param norm = 2.0351e-01, time/batch = 15.2346s	
19565/28500 (epoch 34.325), train_loss = 1.01867600, grad/param norm = 1.9321e-01, time/batch = 15.3140s	
19566/28500 (epoch 34.326), train_loss = 0.91560009, grad/param norm = 1.7587e-01, time/batch = 15.2348s	
19567/28500 (epoch 34.328), train_loss = 0.72212195, grad/param norm = 1.5889e-01, time/batch = 15.1971s	
19568/28500 (epoch 34.330), train_loss = 0.81845425, grad/param norm = 1.7433e-01, time/batch = 15.2055s	
19569/28500 (epoch 34.332), train_loss = 0.85204497, grad/param norm = 1.7888e-01, time/batch = 15.0547s	
19570/28500 (epoch 34.333), train_loss = 0.69863478, grad/param norm = 1.6326e-01, time/batch = 15.4997s	
19571/28500 (epoch 34.335), train_loss = 0.78520391, grad/param norm = 1.6951e-01, time/batch = 15.5858s	
19572/28500 (epoch 34.337), train_loss = 0.73481372, grad/param norm = 1.6622e-01, time/batch = 15.5424s	
19573/28500 (epoch 34.339), train_loss = 0.72342706, grad/param norm = 1.3734e-01, time/batch = 15.6286s	
19574/28500 (epoch 34.340), train_loss = 0.89139209, grad/param norm = 2.9003e-01, time/batch = 15.6098s	
19575/28500 (epoch 34.342), train_loss = 0.85638045, grad/param norm = 1.7524e-01, time/batch = 15.1262s	
19576/28500 (epoch 34.344), train_loss = 0.78396922, grad/param norm = 1.9345e-01, time/batch = 14.9553s	
19577/28500 (epoch 34.346), train_loss = 0.73586308, grad/param norm = 1.5187e-01, time/batch = 15.4630s	
19578/28500 (epoch 34.347), train_loss = 0.88025603, grad/param norm = 1.6632e-01, time/batch = 15.4622s	
19579/28500 (epoch 34.349), train_loss = 0.86914681, grad/param norm = 1.8063e-01, time/batch = 15.2942s	
19580/28500 (epoch 34.351), train_loss = 0.79026530, grad/param norm = 1.7130e-01, time/batch = 15.5162s	
19581/28500 (epoch 34.353), train_loss = 0.87361139, grad/param norm = 2.2915e-01, time/batch = 15.3085s	
19582/28500 (epoch 34.354), train_loss = 0.77278997, grad/param norm = 1.6855e-01, time/batch = 15.4311s	
19583/28500 (epoch 34.356), train_loss = 0.82595451, grad/param norm = 1.7168e-01, time/batch = 15.3768s	
19584/28500 (epoch 34.358), train_loss = 0.93104395, grad/param norm = 1.6381e-01, time/batch = 15.3066s	
19585/28500 (epoch 34.360), train_loss = 0.89770811, grad/param norm = 1.8750e-01, time/batch = 15.2460s	
19586/28500 (epoch 34.361), train_loss = 0.79338004, grad/param norm = 1.6983e-01, time/batch = 15.1966s	
19587/28500 (epoch 34.363), train_loss = 0.78927257, grad/param norm = 1.5130e-01, time/batch = 15.1153s	
19588/28500 (epoch 34.365), train_loss = 0.84490319, grad/param norm = 1.9002e-01, time/batch = 15.0705s	
19589/28500 (epoch 34.367), train_loss = 0.90040571, grad/param norm = 1.9912e-01, time/batch = 15.3898s	
19590/28500 (epoch 34.368), train_loss = 0.81157571, grad/param norm = 1.5819e-01, time/batch = 15.1415s	
19591/28500 (epoch 34.370), train_loss = 0.88508926, grad/param norm = 1.9529e-01, time/batch = 15.2309s	
19592/28500 (epoch 34.372), train_loss = 0.72351773, grad/param norm = 1.8836e-01, time/batch = 15.3770s	
19593/28500 (epoch 34.374), train_loss = 0.83618425, grad/param norm = 1.8204e-01, time/batch = 15.3067s	
19594/28500 (epoch 34.375), train_loss = 0.95600784, grad/param norm = 1.8853e-01, time/batch = 15.4471s	
19595/28500 (epoch 34.377), train_loss = 0.78503557, grad/param norm = 2.2648e-01, time/batch = 15.2913s	
19596/28500 (epoch 34.379), train_loss = 0.66527235, grad/param norm = 1.6930e-01, time/batch = 15.3021s	
19597/28500 (epoch 34.381), train_loss = 0.84030600, grad/param norm = 1.6920e-01, time/batch = 15.5467s	
19598/28500 (epoch 34.382), train_loss = 0.82021108, grad/param norm = 1.9495e-01, time/batch = 15.5818s	
19599/28500 (epoch 34.384), train_loss = 0.72158243, grad/param norm = 1.6405e-01, time/batch = 15.6364s	
19600/28500 (epoch 34.386), train_loss = 0.76205005, grad/param norm = 1.6173e-01, time/batch = 15.4313s	
19601/28500 (epoch 34.388), train_loss = 0.94155008, grad/param norm = 1.8114e-01, time/batch = 15.3845s	
19602/28500 (epoch 34.389), train_loss = 0.82593808, grad/param norm = 2.4830e-01, time/batch = 15.3018s	
19603/28500 (epoch 34.391), train_loss = 0.75887497, grad/param norm = 1.9640e-01, time/batch = 15.3749s	
19604/28500 (epoch 34.393), train_loss = 0.79725680, grad/param norm = 1.8794e-01, time/batch = 15.2377s	
19605/28500 (epoch 34.395), train_loss = 0.96160576, grad/param norm = 1.7336e-01, time/batch = 15.3903s	
19606/28500 (epoch 34.396), train_loss = 0.94479545, grad/param norm = 1.9365e-01, time/batch = 15.1952s	
19607/28500 (epoch 34.398), train_loss = 0.65485626, grad/param norm = 1.6479e-01, time/batch = 15.2851s	
19608/28500 (epoch 34.400), train_loss = 0.82396788, grad/param norm = 1.7345e-01, time/batch = 15.2929s	
19609/28500 (epoch 34.402), train_loss = 0.86675003, grad/param norm = 1.9662e-01, time/batch = 15.2049s	
19610/28500 (epoch 34.404), train_loss = 0.88609898, grad/param norm = 1.8839e-01, time/batch = 15.2253s	
19611/28500 (epoch 34.405), train_loss = 0.91867716, grad/param norm = 1.8283e-01, time/batch = 15.6199s	
19612/28500 (epoch 34.407), train_loss = 0.88262847, grad/param norm = 1.8350e-01, time/batch = 15.5793s	
19613/28500 (epoch 34.409), train_loss = 0.88324701, grad/param norm = 1.8328e-01, time/batch = 15.4014s	
19614/28500 (epoch 34.411), train_loss = 0.98468055, grad/param norm = 2.2102e-01, time/batch = 15.2741s	
19615/28500 (epoch 34.412), train_loss = 0.99495579, grad/param norm = 1.9805e-01, time/batch = 15.3906s	
19616/28500 (epoch 34.414), train_loss = 0.88340884, grad/param norm = 1.8675e-01, time/batch = 15.3257s	
19617/28500 (epoch 34.416), train_loss = 0.80488599, grad/param norm = 2.2823e-01, time/batch = 15.4595s	
19618/28500 (epoch 34.418), train_loss = 0.88788589, grad/param norm = 1.5840e-01, time/batch = 15.4546s	
19619/28500 (epoch 34.419), train_loss = 0.96718678, grad/param norm = 2.0057e-01, time/batch = 15.4758s	
19620/28500 (epoch 34.421), train_loss = 0.94674395, grad/param norm = 1.9768e-01, time/batch = 15.4824s	
19621/28500 (epoch 34.423), train_loss = 0.95011254, grad/param norm = 2.0699e-01, time/batch = 15.6183s	
19622/28500 (epoch 34.425), train_loss = 0.87284024, grad/param norm = 2.0211e-01, time/batch = 15.6334s	
19623/28500 (epoch 34.426), train_loss = 0.90814707, grad/param norm = 2.1460e-01, time/batch = 15.5597s	
19624/28500 (epoch 34.428), train_loss = 1.02742339, grad/param norm = 2.0260e-01, time/batch = 15.3802s	
19625/28500 (epoch 34.430), train_loss = 1.01375477, grad/param norm = 1.7899e-01, time/batch = 15.5698s	
19626/28500 (epoch 34.432), train_loss = 0.88378252, grad/param norm = 1.9291e-01, time/batch = 15.3752s	
19627/28500 (epoch 34.433), train_loss = 0.93361467, grad/param norm = 1.8993e-01, time/batch = 15.4518s	
19628/28500 (epoch 34.435), train_loss = 0.89166598, grad/param norm = 1.8786e-01, time/batch = 15.4007s	
19629/28500 (epoch 34.437), train_loss = 0.82380448, grad/param norm = 1.7114e-01, time/batch = 15.5372s	
19630/28500 (epoch 34.439), train_loss = 0.85839753, grad/param norm = 1.5831e-01, time/batch = 15.4878s	
19631/28500 (epoch 34.440), train_loss = 1.02173551, grad/param norm = 1.8474e-01, time/batch = 15.5377s	
19632/28500 (epoch 34.442), train_loss = 0.81774334, grad/param norm = 1.8062e-01, time/batch = 15.4648s	
19633/28500 (epoch 34.444), train_loss = 0.76887758, grad/param norm = 1.6945e-01, time/batch = 15.4256s	
19634/28500 (epoch 34.446), train_loss = 0.73698241, grad/param norm = 1.6610e-01, time/batch = 15.2927s	
19635/28500 (epoch 34.447), train_loss = 0.76098380, grad/param norm = 1.5818e-01, time/batch = 15.2420s	
19636/28500 (epoch 34.449), train_loss = 0.83236833, grad/param norm = 1.7101e-01, time/batch = 15.0363s	
19637/28500 (epoch 34.451), train_loss = 0.85399095, grad/param norm = 1.6780e-01, time/batch = 14.9808s	
19638/28500 (epoch 34.453), train_loss = 0.82965181, grad/param norm = 1.6697e-01, time/batch = 15.1057s	
19639/28500 (epoch 34.454), train_loss = 0.79058156, grad/param norm = 1.5494e-01, time/batch = 15.2471s	
19640/28500 (epoch 34.456), train_loss = 0.93712808, grad/param norm = 2.6011e-01, time/batch = 15.3842s	
19641/28500 (epoch 34.458), train_loss = 0.85404474, grad/param norm = 2.0143e-01, time/batch = 15.3802s	
19642/28500 (epoch 34.460), train_loss = 0.94858689, grad/param norm = 1.9373e-01, time/batch = 15.2848s	
19643/28500 (epoch 34.461), train_loss = 0.77731310, grad/param norm = 1.7932e-01, time/batch = 15.2167s	
19644/28500 (epoch 34.463), train_loss = 0.72601985, grad/param norm = 1.5143e-01, time/batch = 15.2784s	
19645/28500 (epoch 34.465), train_loss = 0.71422045, grad/param norm = 1.8131e-01, time/batch = 15.5400s	
19646/28500 (epoch 34.467), train_loss = 0.87442395, grad/param norm = 1.8520e-01, time/batch = 15.2130s	
19647/28500 (epoch 34.468), train_loss = 0.77547554, grad/param norm = 1.5445e-01, time/batch = 15.0636s	
19648/28500 (epoch 34.470), train_loss = 0.82422839, grad/param norm = 1.9073e-01, time/batch = 15.4663s	
19649/28500 (epoch 34.472), train_loss = 0.78793194, grad/param norm = 1.5271e-01, time/batch = 15.5377s	
19650/28500 (epoch 34.474), train_loss = 0.99326713, grad/param norm = 2.0749e-01, time/batch = 15.4085s	
19651/28500 (epoch 34.475), train_loss = 0.80653583, grad/param norm = 1.6969e-01, time/batch = 15.5192s	
19652/28500 (epoch 34.477), train_loss = 0.82971886, grad/param norm = 1.7784e-01, time/batch = 15.5436s	
19653/28500 (epoch 34.479), train_loss = 0.89205735, grad/param norm = 1.7682e-01, time/batch = 15.3222s	
19654/28500 (epoch 34.481), train_loss = 0.91312087, grad/param norm = 1.7839e-01, time/batch = 15.4389s	
19655/28500 (epoch 34.482), train_loss = 0.75574675, grad/param norm = 1.5775e-01, time/batch = 15.3836s	
19656/28500 (epoch 34.484), train_loss = 0.80005372, grad/param norm = 1.8757e-01, time/batch = 15.4589s	
19657/28500 (epoch 34.486), train_loss = 0.69230551, grad/param norm = 1.7922e-01, time/batch = 15.5909s	
19658/28500 (epoch 34.488), train_loss = 0.90353809, grad/param norm = 1.6296e-01, time/batch = 15.2883s	
19659/28500 (epoch 34.489), train_loss = 0.99043436, grad/param norm = 2.0420e-01, time/batch = 15.6735s	
19660/28500 (epoch 34.491), train_loss = 0.80632702, grad/param norm = 1.8220e-01, time/batch = 15.5232s	
19661/28500 (epoch 34.493), train_loss = 0.84198105, grad/param norm = 1.6627e-01, time/batch = 15.6915s	
19662/28500 (epoch 34.495), train_loss = 0.89540670, grad/param norm = 2.0870e-01, time/batch = 15.5467s	
19663/28500 (epoch 34.496), train_loss = 0.78856460, grad/param norm = 1.9029e-01, time/batch = 15.4605s	
19664/28500 (epoch 34.498), train_loss = 0.82863951, grad/param norm = 1.5626e-01, time/batch = 15.5445s	
19665/28500 (epoch 34.500), train_loss = 0.80261328, grad/param norm = 1.7888e-01, time/batch = 15.4139s	
19666/28500 (epoch 34.502), train_loss = 0.91397014, grad/param norm = 1.7104e-01, time/batch = 15.3055s	
19667/28500 (epoch 34.504), train_loss = 0.88931572, grad/param norm = 1.6341e-01, time/batch = 15.0553s	
19668/28500 (epoch 34.505), train_loss = 0.79258241, grad/param norm = 1.6423e-01, time/batch = 15.2259s	
19669/28500 (epoch 34.507), train_loss = 0.96654317, grad/param norm = 2.9680e-01, time/batch = 15.4897s	
19670/28500 (epoch 34.509), train_loss = 0.87193812, grad/param norm = 1.8034e-01, time/batch = 15.3202s	
19671/28500 (epoch 34.511), train_loss = 0.85876500, grad/param norm = 1.7716e-01, time/batch = 15.5492s	
19672/28500 (epoch 34.512), train_loss = 0.92030222, grad/param norm = 1.8284e-01, time/batch = 15.5344s	
19673/28500 (epoch 34.514), train_loss = 0.88238868, grad/param norm = 1.8753e-01, time/batch = 15.2261s	
19674/28500 (epoch 34.516), train_loss = 0.85992501, grad/param norm = 1.6529e-01, time/batch = 15.2935s	
19675/28500 (epoch 34.518), train_loss = 0.90823739, grad/param norm = 1.6887e-01, time/batch = 15.3083s	
19676/28500 (epoch 34.519), train_loss = 0.90502547, grad/param norm = 1.7631e-01, time/batch = 15.2055s	
19677/28500 (epoch 34.521), train_loss = 0.98375730, grad/param norm = 1.8575e-01, time/batch = 15.3046s	
19678/28500 (epoch 34.523), train_loss = 0.92840589, grad/param norm = 1.9631e-01, time/batch = 15.1783s	
19679/28500 (epoch 34.525), train_loss = 0.98758197, grad/param norm = 1.8857e-01, time/batch = 15.4061s	
19680/28500 (epoch 34.526), train_loss = 0.93636264, grad/param norm = 1.8065e-01, time/batch = 15.3564s	
19681/28500 (epoch 34.528), train_loss = 0.91996422, grad/param norm = 2.0999e-01, time/batch = 15.4738s	
19682/28500 (epoch 34.530), train_loss = 0.93182191, grad/param norm = 1.8292e-01, time/batch = 15.3884s	
19683/28500 (epoch 34.532), train_loss = 0.84007210, grad/param norm = 1.7053e-01, time/batch = 15.2945s	
19684/28500 (epoch 34.533), train_loss = 0.90085746, grad/param norm = 1.5946e-01, time/batch = 15.2404s	
19685/28500 (epoch 34.535), train_loss = 0.75086324, grad/param norm = 1.4954e-01, time/batch = 15.4024s	
19686/28500 (epoch 34.537), train_loss = 0.79435838, grad/param norm = 1.7275e-01, time/batch = 15.5408s	
19687/28500 (epoch 34.539), train_loss = 0.74598693, grad/param norm = 1.7222e-01, time/batch = 15.4596s	
19688/28500 (epoch 34.540), train_loss = 0.87056547, grad/param norm = 1.6962e-01, time/batch = 15.4028s	
19689/28500 (epoch 34.542), train_loss = 0.92988615, grad/param norm = 2.0014e-01, time/batch = 15.3638s	
19690/28500 (epoch 34.544), train_loss = 1.01252565, grad/param norm = 1.8934e-01, time/batch = 15.5476s	
19691/28500 (epoch 34.546), train_loss = 0.86751852, grad/param norm = 1.6576e-01, time/batch = 15.6990s	
19692/28500 (epoch 34.547), train_loss = 0.84629447, grad/param norm = 1.9005e-01, time/batch = 15.3213s	
19693/28500 (epoch 34.549), train_loss = 0.71129991, grad/param norm = 1.4538e-01, time/batch = 15.1570s	
19694/28500 (epoch 34.551), train_loss = 0.84930255, grad/param norm = 2.1352e-01, time/batch = 15.1373s	
19695/28500 (epoch 34.553), train_loss = 1.02263257, grad/param norm = 1.9684e-01, time/batch = 15.1276s	
19696/28500 (epoch 34.554), train_loss = 0.92298940, grad/param norm = 1.9259e-01, time/batch = 15.0721s	
19697/28500 (epoch 34.556), train_loss = 0.90752551, grad/param norm = 1.7850e-01, time/batch = 15.2241s	
19698/28500 (epoch 34.558), train_loss = 0.91653958, grad/param norm = 1.7174e-01, time/batch = 15.3673s	
19699/28500 (epoch 34.560), train_loss = 0.91785394, grad/param norm = 1.8949e-01, time/batch = 15.3002s	
19700/28500 (epoch 34.561), train_loss = 0.91972588, grad/param norm = 1.9505e-01, time/batch = 15.3115s	
19701/28500 (epoch 34.563), train_loss = 1.00637449, grad/param norm = 2.0371e-01, time/batch = 15.4855s	
19702/28500 (epoch 34.565), train_loss = 0.80004091, grad/param norm = 1.7011e-01, time/batch = 15.6960s	
19703/28500 (epoch 34.567), train_loss = 0.75100291, grad/param norm = 1.5199e-01, time/batch = 15.4725s	
19704/28500 (epoch 34.568), train_loss = 0.91233239, grad/param norm = 2.2025e-01, time/batch = 15.1468s	
19705/28500 (epoch 34.570), train_loss = 0.84740259, grad/param norm = 1.8027e-01, time/batch = 15.2325s	
19706/28500 (epoch 34.572), train_loss = 0.89009401, grad/param norm = 1.8360e-01, time/batch = 15.3695s	
19707/28500 (epoch 34.574), train_loss = 0.81693737, grad/param norm = 1.7755e-01, time/batch = 15.2741s	
19708/28500 (epoch 34.575), train_loss = 0.82298164, grad/param norm = 1.6668e-01, time/batch = 15.0571s	
19709/28500 (epoch 34.577), train_loss = 0.91983004, grad/param norm = 1.6934e-01, time/batch = 15.0655s	
19710/28500 (epoch 34.579), train_loss = 0.95438856, grad/param norm = 1.8412e-01, time/batch = 19.8785s	
19711/28500 (epoch 34.581), train_loss = 0.83526170, grad/param norm = 2.3895e-01, time/batch = 21.7435s	
19712/28500 (epoch 34.582), train_loss = 0.96269184, grad/param norm = 1.8120e-01, time/batch = 15.4949s	
19713/28500 (epoch 34.584), train_loss = 0.83158204, grad/param norm = 1.9044e-01, time/batch = 15.3837s	
19714/28500 (epoch 34.586), train_loss = 0.80610690, grad/param norm = 1.7946e-01, time/batch = 15.4501s	
19715/28500 (epoch 34.588), train_loss = 0.82235142, grad/param norm = 1.9595e-01, time/batch = 15.0503s	
19716/28500 (epoch 34.589), train_loss = 0.84904539, grad/param norm = 1.7355e-01, time/batch = 15.0710s	
19717/28500 (epoch 34.591), train_loss = 0.88502168, grad/param norm = 1.8506e-01, time/batch = 15.1208s	
19718/28500 (epoch 34.593), train_loss = 0.83060646, grad/param norm = 1.6216e-01, time/batch = 15.4076s	
19719/28500 (epoch 34.595), train_loss = 1.04186811, grad/param norm = 2.0816e-01, time/batch = 15.1481s	
19720/28500 (epoch 34.596), train_loss = 1.04234545, grad/param norm = 1.8699e-01, time/batch = 15.0683s	
19721/28500 (epoch 34.598), train_loss = 0.85703338, grad/param norm = 1.9294e-01, time/batch = 15.2909s	
19722/28500 (epoch 34.600), train_loss = 0.85820665, grad/param norm = 1.8752e-01, time/batch = 15.4471s	
19723/28500 (epoch 34.602), train_loss = 0.93258780, grad/param norm = 2.0387e-01, time/batch = 15.2607s	
19724/28500 (epoch 34.604), train_loss = 0.94871710, grad/param norm = 1.7610e-01, time/batch = 15.2428s	
19725/28500 (epoch 34.605), train_loss = 0.96275674, grad/param norm = 1.9312e-01, time/batch = 15.4633s	
19726/28500 (epoch 34.607), train_loss = 0.98813050, grad/param norm = 1.7911e-01, time/batch = 15.4970s	
19727/28500 (epoch 34.609), train_loss = 0.91323967, grad/param norm = 1.8913e-01, time/batch = 15.2349s	
19728/28500 (epoch 34.611), train_loss = 0.87285247, grad/param norm = 1.9337e-01, time/batch = 15.0023s	
19729/28500 (epoch 34.612), train_loss = 0.95088204, grad/param norm = 2.2355e-01, time/batch = 15.2958s	
19730/28500 (epoch 34.614), train_loss = 0.94690159, grad/param norm = 1.8281e-01, time/batch = 15.2892s	
19731/28500 (epoch 34.616), train_loss = 0.84101411, grad/param norm = 1.9414e-01, time/batch = 15.2699s	
19732/28500 (epoch 34.618), train_loss = 0.85927076, grad/param norm = 1.8138e-01, time/batch = 15.2302s	
19733/28500 (epoch 34.619), train_loss = 0.94500768, grad/param norm = 1.9679e-01, time/batch = 15.3758s	
19734/28500 (epoch 34.621), train_loss = 0.72015258, grad/param norm = 1.7146e-01, time/batch = 15.3773s	
19735/28500 (epoch 34.623), train_loss = 0.98871780, grad/param norm = 2.3024e-01, time/batch = 15.4525s	
19736/28500 (epoch 34.625), train_loss = 0.79859972, grad/param norm = 1.9152e-01, time/batch = 15.3930s	
19737/28500 (epoch 34.626), train_loss = 0.68654240, grad/param norm = 1.5809e-01, time/batch = 15.5433s	
19738/28500 (epoch 34.628), train_loss = 0.81459522, grad/param norm = 1.8747e-01, time/batch = 15.5303s	
19739/28500 (epoch 34.630), train_loss = 0.74436353, grad/param norm = 1.6681e-01, time/batch = 15.6040s	
19740/28500 (epoch 34.632), train_loss = 0.95978216, grad/param norm = 2.0338e-01, time/batch = 15.4367s	
19741/28500 (epoch 34.633), train_loss = 1.00807613, grad/param norm = 1.7527e-01, time/batch = 15.3905s	
19742/28500 (epoch 34.635), train_loss = 0.91630918, grad/param norm = 1.7585e-01, time/batch = 15.5660s	
19743/28500 (epoch 34.637), train_loss = 0.88998762, grad/param norm = 1.6944e-01, time/batch = 15.3613s	
19744/28500 (epoch 34.639), train_loss = 0.78530790, grad/param norm = 1.8054e-01, time/batch = 15.2073s	
19745/28500 (epoch 34.640), train_loss = 0.80397616, grad/param norm = 1.6788e-01, time/batch = 15.5620s	
19746/28500 (epoch 34.642), train_loss = 0.84009798, grad/param norm = 1.9178e-01, time/batch = 15.0627s	
19747/28500 (epoch 34.644), train_loss = 0.92208233, grad/param norm = 2.0210e-01, time/batch = 15.2419s	
19748/28500 (epoch 34.646), train_loss = 0.74033773, grad/param norm = 1.5112e-01, time/batch = 15.2820s	
19749/28500 (epoch 34.647), train_loss = 0.81325154, grad/param norm = 1.8288e-01, time/batch = 15.3744s	
19750/28500 (epoch 34.649), train_loss = 0.78549447, grad/param norm = 1.8062e-01, time/batch = 15.3104s	
19751/28500 (epoch 34.651), train_loss = 0.75966090, grad/param norm = 1.4353e-01, time/batch = 15.5430s	
19752/28500 (epoch 34.653), train_loss = 0.74474973, grad/param norm = 1.6103e-01, time/batch = 15.5310s	
19753/28500 (epoch 34.654), train_loss = 0.79449209, grad/param norm = 1.7881e-01, time/batch = 15.5580s	
19754/28500 (epoch 34.656), train_loss = 0.77342268, grad/param norm = 2.0483e-01, time/batch = 15.5638s	
19755/28500 (epoch 34.658), train_loss = 0.87107873, grad/param norm = 1.8723e-01, time/batch = 15.2862s	
19756/28500 (epoch 34.660), train_loss = 0.87119215, grad/param norm = 1.6271e-01, time/batch = 15.3634s	
19757/28500 (epoch 34.661), train_loss = 0.98166983, grad/param norm = 2.0921e-01, time/batch = 15.4465s	
19758/28500 (epoch 34.663), train_loss = 0.97164221, grad/param norm = 2.0443e-01, time/batch = 15.4005s	
19759/28500 (epoch 34.665), train_loss = 0.86051652, grad/param norm = 1.8225e-01, time/batch = 14.9874s	
19760/28500 (epoch 34.667), train_loss = 0.85736250, grad/param norm = 2.0163e-01, time/batch = 15.1899s	
19761/28500 (epoch 34.668), train_loss = 0.85152218, grad/param norm = 1.7376e-01, time/batch = 15.5670s	
19762/28500 (epoch 34.670), train_loss = 0.85787246, grad/param norm = 1.6969e-01, time/batch = 15.3909s	
19763/28500 (epoch 34.672), train_loss = 0.77660003, grad/param norm = 1.7888e-01, time/batch = 15.2330s	
19764/28500 (epoch 34.674), train_loss = 0.68541548, grad/param norm = 1.6130e-01, time/batch = 15.2524s	
19765/28500 (epoch 34.675), train_loss = 0.72034189, grad/param norm = 1.5584e-01, time/batch = 15.2125s	
19766/28500 (epoch 34.677), train_loss = 0.82530229, grad/param norm = 1.7925e-01, time/batch = 15.1851s	
19767/28500 (epoch 34.679), train_loss = 0.82485472, grad/param norm = 1.8634e-01, time/batch = 15.3837s	
19768/28500 (epoch 34.681), train_loss = 0.89205854, grad/param norm = 1.9869e-01, time/batch = 15.5993s	
19769/28500 (epoch 34.682), train_loss = 0.81001137, grad/param norm = 1.8287e-01, time/batch = 15.5424s	
19770/28500 (epoch 34.684), train_loss = 0.85736272, grad/param norm = 1.7150e-01, time/batch = 15.3076s	
19771/28500 (epoch 34.686), train_loss = 0.80389733, grad/param norm = 2.0286e-01, time/batch = 15.4290s	
19772/28500 (epoch 34.688), train_loss = 0.79843245, grad/param norm = 1.4755e-01, time/batch = 15.3141s	
19773/28500 (epoch 34.689), train_loss = 0.80694026, grad/param norm = 1.7737e-01, time/batch = 15.6397s	
19774/28500 (epoch 34.691), train_loss = 0.91021205, grad/param norm = 2.0456e-01, time/batch = 15.4479s	
19775/28500 (epoch 34.693), train_loss = 0.83821955, grad/param norm = 1.8632e-01, time/batch = 15.2278s	
19776/28500 (epoch 34.695), train_loss = 0.65804951, grad/param norm = 1.8005e-01, time/batch = 15.2120s	
19777/28500 (epoch 34.696), train_loss = 0.84886685, grad/param norm = 2.1825e-01, time/batch = 15.3728s	
19778/28500 (epoch 34.698), train_loss = 0.90393121, grad/param norm = 1.8201e-01, time/batch = 15.2270s	
19779/28500 (epoch 34.700), train_loss = 0.86705858, grad/param norm = 1.8632e-01, time/batch = 15.3931s	
19780/28500 (epoch 34.702), train_loss = 0.86970879, grad/param norm = 2.0641e-01, time/batch = 15.2048s	
19781/28500 (epoch 34.704), train_loss = 0.89783462, grad/param norm = 1.9552e-01, time/batch = 15.1995s	
19782/28500 (epoch 34.705), train_loss = 0.93689667, grad/param norm = 2.3122e-01, time/batch = 15.2967s	
19783/28500 (epoch 34.707), train_loss = 0.81095257, grad/param norm = 2.2709e-01, time/batch = 15.4661s	
19784/28500 (epoch 34.709), train_loss = 1.00526995, grad/param norm = 2.1523e-01, time/batch = 15.4170s	
19785/28500 (epoch 34.711), train_loss = 0.81052601, grad/param norm = 1.7657e-01, time/batch = 15.1900s	
19786/28500 (epoch 34.712), train_loss = 0.87767435, grad/param norm = 1.8256e-01, time/batch = 15.1610s	
19787/28500 (epoch 34.714), train_loss = 0.99308524, grad/param norm = 1.9388e-01, time/batch = 15.2088s	
19788/28500 (epoch 34.716), train_loss = 0.84044034, grad/param norm = 1.6276e-01, time/batch = 15.2296s	
19789/28500 (epoch 34.718), train_loss = 0.88672043, grad/param norm = 1.9752e-01, time/batch = 15.5369s	
19790/28500 (epoch 34.719), train_loss = 0.86297008, grad/param norm = 1.6621e-01, time/batch = 15.4649s	
19791/28500 (epoch 34.721), train_loss = 0.67394170, grad/param norm = 1.6548e-01, time/batch = 15.6342s	
19792/28500 (epoch 34.723), train_loss = 0.87209795, grad/param norm = 1.7480e-01, time/batch = 15.5516s	
19793/28500 (epoch 34.725), train_loss = 0.94516994, grad/param norm = 1.9557e-01, time/batch = 15.3263s	
19794/28500 (epoch 34.726), train_loss = 0.85121958, grad/param norm = 1.7260e-01, time/batch = 15.3038s	
19795/28500 (epoch 34.728), train_loss = 0.77214160, grad/param norm = 1.5679e-01, time/batch = 15.3681s	
19796/28500 (epoch 34.730), train_loss = 0.87028977, grad/param norm = 2.0206e-01, time/batch = 15.4538s	
19797/28500 (epoch 34.732), train_loss = 0.68531301, grad/param norm = 1.5250e-01, time/batch = 15.3437s	
19798/28500 (epoch 34.733), train_loss = 0.73459957, grad/param norm = 1.6519e-01, time/batch = 15.4719s	
19799/28500 (epoch 34.735), train_loss = 0.72498089, grad/param norm = 1.5164e-01, time/batch = 15.4851s	
19800/28500 (epoch 34.737), train_loss = 0.66088407, grad/param norm = 1.4925e-01, time/batch = 15.4651s	
19801/28500 (epoch 34.739), train_loss = 0.78219450, grad/param norm = 1.7669e-01, time/batch = 15.6580s	
19802/28500 (epoch 34.740), train_loss = 0.85588111, grad/param norm = 1.6966e-01, time/batch = 15.4836s	
19803/28500 (epoch 34.742), train_loss = 0.76448635, grad/param norm = 1.7678e-01, time/batch = 15.6281s	
19804/28500 (epoch 34.744), train_loss = 0.85924608, grad/param norm = 1.7284e-01, time/batch = 15.6226s	
19805/28500 (epoch 34.746), train_loss = 0.79714717, grad/param norm = 1.6119e-01, time/batch = 15.5543s	
19806/28500 (epoch 34.747), train_loss = 0.78942840, grad/param norm = 1.4969e-01, time/batch = 15.5416s	
19807/28500 (epoch 34.749), train_loss = 0.91222274, grad/param norm = 1.9033e-01, time/batch = 15.2984s	
19808/28500 (epoch 34.751), train_loss = 0.74499089, grad/param norm = 1.8832e-01, time/batch = 15.3501s	
19809/28500 (epoch 34.753), train_loss = 0.84478623, grad/param norm = 1.5776e-01, time/batch = 14.9760s	
19810/28500 (epoch 34.754), train_loss = 0.76662539, grad/param norm = 1.9011e-01, time/batch = 14.9773s	
19811/28500 (epoch 34.756), train_loss = 0.95758861, grad/param norm = 1.7912e-01, time/batch = 15.2462s	
19812/28500 (epoch 34.758), train_loss = 0.89876254, grad/param norm = 1.9705e-01, time/batch = 14.9730s	
19813/28500 (epoch 34.760), train_loss = 0.75331196, grad/param norm = 1.7222e-01, time/batch = 15.2412s	
19814/28500 (epoch 34.761), train_loss = 0.77491289, grad/param norm = 1.7114e-01, time/batch = 15.1107s	
19815/28500 (epoch 34.763), train_loss = 0.67682774, grad/param norm = 1.6002e-01, time/batch = 15.1232s	
19816/28500 (epoch 34.765), train_loss = 0.83503701, grad/param norm = 1.7463e-01, time/batch = 15.2920s	
19817/28500 (epoch 34.767), train_loss = 0.71648228, grad/param norm = 1.4922e-01, time/batch = 15.1376s	
19818/28500 (epoch 34.768), train_loss = 0.89232801, grad/param norm = 1.7593e-01, time/batch = 15.1389s	
19819/28500 (epoch 34.770), train_loss = 0.75139856, grad/param norm = 1.7608e-01, time/batch = 15.4727s	
19820/28500 (epoch 34.772), train_loss = 0.67895979, grad/param norm = 1.4285e-01, time/batch = 15.5620s	
19821/28500 (epoch 34.774), train_loss = 0.84396132, grad/param norm = 1.7123e-01, time/batch = 15.5505s	
19822/28500 (epoch 34.775), train_loss = 0.91263884, grad/param norm = 1.6391e-01, time/batch = 15.3801s	
19823/28500 (epoch 34.777), train_loss = 0.90468170, grad/param norm = 1.6335e-01, time/batch = 15.3067s	
19824/28500 (epoch 34.779), train_loss = 0.69542512, grad/param norm = 1.4179e-01, time/batch = 15.2272s	
19825/28500 (epoch 34.781), train_loss = 0.83362855, grad/param norm = 1.8042e-01, time/batch = 15.5080s	
19826/28500 (epoch 34.782), train_loss = 0.84858765, grad/param norm = 1.7993e-01, time/batch = 15.2142s	
19827/28500 (epoch 34.784), train_loss = 0.68592333, grad/param norm = 1.6342e-01, time/batch = 15.2155s	
19828/28500 (epoch 34.786), train_loss = 0.72495991, grad/param norm = 1.9786e-01, time/batch = 15.1506s	
19829/28500 (epoch 34.788), train_loss = 0.80500576, grad/param norm = 1.7260e-01, time/batch = 15.1969s	
19830/28500 (epoch 34.789), train_loss = 0.62371742, grad/param norm = 1.9524e-01, time/batch = 15.2423s	
19831/28500 (epoch 34.791), train_loss = 0.86065248, grad/param norm = 1.5782e-01, time/batch = 15.5890s	
19832/28500 (epoch 34.793), train_loss = 0.82285068, grad/param norm = 1.6094e-01, time/batch = 15.3568s	
19833/28500 (epoch 34.795), train_loss = 0.84441869, grad/param norm = 1.6267e-01, time/batch = 15.4553s	
19834/28500 (epoch 34.796), train_loss = 0.74900570, grad/param norm = 1.8219e-01, time/batch = 15.6191s	
19835/28500 (epoch 34.798), train_loss = 0.70513264, grad/param norm = 2.5219e-01, time/batch = 15.5858s	
19836/28500 (epoch 34.800), train_loss = 0.71613091, grad/param norm = 2.3121e-01, time/batch = 15.2808s	
19837/28500 (epoch 34.802), train_loss = 0.80340460, grad/param norm = 2.5198e-01, time/batch = 15.2065s	
19838/28500 (epoch 34.804), train_loss = 0.85959592, grad/param norm = 1.6068e-01, time/batch = 15.1733s	
19839/28500 (epoch 34.805), train_loss = 0.84523609, grad/param norm = 1.9007e-01, time/batch = 15.2035s	
19840/28500 (epoch 34.807), train_loss = 0.84636512, grad/param norm = 1.8798e-01, time/batch = 15.2178s	
19841/28500 (epoch 34.809), train_loss = 0.83657498, grad/param norm = 1.8173e-01, time/batch = 15.2854s	
19842/28500 (epoch 34.811), train_loss = 0.87097529, grad/param norm = 1.7524e-01, time/batch = 15.5338s	
19843/28500 (epoch 34.812), train_loss = 0.83222704, grad/param norm = 1.7742e-01, time/batch = 15.4661s	
19844/28500 (epoch 34.814), train_loss = 0.80991012, grad/param norm = 1.7214e-01, time/batch = 15.3859s	
19845/28500 (epoch 34.816), train_loss = 0.88025376, grad/param norm = 1.9722e-01, time/batch = 15.7118s	
19846/28500 (epoch 34.818), train_loss = 0.97200644, grad/param norm = 1.9939e-01, time/batch = 15.4926s	
19847/28500 (epoch 34.819), train_loss = 0.85362952, grad/param norm = 1.9007e-01, time/batch = 15.4528s	
19848/28500 (epoch 34.821), train_loss = 0.81298646, grad/param norm = 1.7036e-01, time/batch = 15.2019s	
19849/28500 (epoch 34.823), train_loss = 0.95974836, grad/param norm = 2.1503e-01, time/batch = 15.4620s	
19850/28500 (epoch 34.825), train_loss = 0.81451750, grad/param norm = 2.5878e-01, time/batch = 15.5160s	
19851/28500 (epoch 34.826), train_loss = 0.85993700, grad/param norm = 1.8607e-01, time/batch = 15.6502s	
19852/28500 (epoch 34.828), train_loss = 0.76707903, grad/param norm = 1.8302e-01, time/batch = 15.6096s	
19853/28500 (epoch 34.830), train_loss = 0.80398911, grad/param norm = 1.5407e-01, time/batch = 15.4388s	
19854/28500 (epoch 34.832), train_loss = 0.82833571, grad/param norm = 2.3976e-01, time/batch = 15.2853s	
19855/28500 (epoch 34.833), train_loss = 0.90150109, grad/param norm = 1.6758e-01, time/batch = 15.1564s	
19856/28500 (epoch 34.835), train_loss = 0.81647003, grad/param norm = 2.0342e-01, time/batch = 15.3499s	
19857/28500 (epoch 34.837), train_loss = 0.72289241, grad/param norm = 1.8092e-01, time/batch = 15.4880s	
19858/28500 (epoch 34.839), train_loss = 0.97292248, grad/param norm = 2.2699e-01, time/batch = 15.5395s	
19859/28500 (epoch 34.840), train_loss = 0.98820380, grad/param norm = 1.8760e-01, time/batch = 15.3038s	
19860/28500 (epoch 34.842), train_loss = 0.90002926, grad/param norm = 2.0822e-01, time/batch = 15.6384s	
19861/28500 (epoch 34.844), train_loss = 0.89702057, grad/param norm = 1.8058e-01, time/batch = 15.5491s	
19862/28500 (epoch 34.846), train_loss = 1.01168992, grad/param norm = 2.3567e-01, time/batch = 15.4802s	
19863/28500 (epoch 34.847), train_loss = 0.80958206, grad/param norm = 1.8683e-01, time/batch = 15.3800s	
19864/28500 (epoch 34.849), train_loss = 0.81592537, grad/param norm = 1.7634e-01, time/batch = 15.2692s	
19865/28500 (epoch 34.851), train_loss = 0.75073325, grad/param norm = 1.6021e-01, time/batch = 15.2401s	
19866/28500 (epoch 34.853), train_loss = 0.87177033, grad/param norm = 2.0650e-01, time/batch = 15.0615s	
19867/28500 (epoch 34.854), train_loss = 0.86732802, grad/param norm = 1.7712e-01, time/batch = 15.1237s	
19868/28500 (epoch 34.856), train_loss = 0.95329650, grad/param norm = 2.2281e-01, time/batch = 15.3130s	
19869/28500 (epoch 34.858), train_loss = 0.79829128, grad/param norm = 1.6810e-01, time/batch = 15.4995s	
19870/28500 (epoch 34.860), train_loss = 0.84290730, grad/param norm = 2.2762e-01, time/batch = 15.5320s	
19871/28500 (epoch 34.861), train_loss = 0.91824387, grad/param norm = 2.3841e-01, time/batch = 15.5719s	
19872/28500 (epoch 34.863), train_loss = 0.88024867, grad/param norm = 2.1527e-01, time/batch = 15.6319s	
19873/28500 (epoch 34.865), train_loss = 0.77985547, grad/param norm = 1.9193e-01, time/batch = 15.3783s	
19874/28500 (epoch 34.867), train_loss = 0.89016954, grad/param norm = 2.1116e-01, time/batch = 15.3237s	
19875/28500 (epoch 34.868), train_loss = 0.77085992, grad/param norm = 1.6826e-01, time/batch = 15.4509s	
19876/28500 (epoch 34.870), train_loss = 0.72987562, grad/param norm = 1.6243e-01, time/batch = 15.4396s	
19877/28500 (epoch 34.872), train_loss = 0.89868388, grad/param norm = 2.1837e-01, time/batch = 15.1470s	
19878/28500 (epoch 34.874), train_loss = 0.77945264, grad/param norm = 1.9878e-01, time/batch = 15.2455s	
19879/28500 (epoch 34.875), train_loss = 0.97873064, grad/param norm = 2.1626e-01, time/batch = 15.3630s	
19880/28500 (epoch 34.877), train_loss = 0.87548628, grad/param norm = 1.7538e-01, time/batch = 15.3929s	
19881/28500 (epoch 34.879), train_loss = 0.91281642, grad/param norm = 1.6388e-01, time/batch = 15.4798s	
19882/28500 (epoch 34.881), train_loss = 0.89502563, grad/param norm = 1.8370e-01, time/batch = 15.3126s	
19883/28500 (epoch 34.882), train_loss = 0.77982744, grad/param norm = 1.5583e-01, time/batch = 15.3139s	
19884/28500 (epoch 34.884), train_loss = 0.84272148, grad/param norm = 1.8701e-01, time/batch = 15.2949s	
19885/28500 (epoch 34.886), train_loss = 0.79936053, grad/param norm = 1.5514e-01, time/batch = 15.2049s	
19886/28500 (epoch 34.888), train_loss = 0.80916637, grad/param norm = 1.6752e-01, time/batch = 15.0559s	
19887/28500 (epoch 34.889), train_loss = 0.86073654, grad/param norm = 1.7232e-01, time/batch = 15.0510s	
19888/28500 (epoch 34.891), train_loss = 0.84385863, grad/param norm = 1.6613e-01, time/batch = 14.9746s	
19889/28500 (epoch 34.893), train_loss = 0.81541772, grad/param norm = 2.0056e-01, time/batch = 15.1976s	
19890/28500 (epoch 34.895), train_loss = 0.99853082, grad/param norm = 2.2555e-01, time/batch = 15.2832s	
19891/28500 (epoch 34.896), train_loss = 0.94925486, grad/param norm = 1.9782e-01, time/batch = 15.3347s	
19892/28500 (epoch 34.898), train_loss = 0.88363407, grad/param norm = 1.7867e-01, time/batch = 15.1942s	
19893/28500 (epoch 34.900), train_loss = 0.74171734, grad/param norm = 1.5605e-01, time/batch = 15.3838s	
19894/28500 (epoch 34.902), train_loss = 0.71518191, grad/param norm = 1.5601e-01, time/batch = 15.3784s	
19895/28500 (epoch 34.904), train_loss = 0.74429753, grad/param norm = 1.6226e-01, time/batch = 15.4007s	
19896/28500 (epoch 34.905), train_loss = 0.80573636, grad/param norm = 1.9135e-01, time/batch = 15.2839s	
19897/28500 (epoch 34.907), train_loss = 0.83879842, grad/param norm = 1.8682e-01, time/batch = 15.1563s	
19898/28500 (epoch 34.909), train_loss = 0.72979362, grad/param norm = 2.2890e-01, time/batch = 15.2242s	
19899/28500 (epoch 34.911), train_loss = 0.75520248, grad/param norm = 1.6564e-01, time/batch = 15.3170s	
19900/28500 (epoch 34.912), train_loss = 0.65257614, grad/param norm = 1.6507e-01, time/batch = 15.4634s	
19901/28500 (epoch 34.914), train_loss = 0.85158653, grad/param norm = 1.8800e-01, time/batch = 15.3249s	
19902/28500 (epoch 34.916), train_loss = 0.84427222, grad/param norm = 1.9512e-01, time/batch = 15.3765s	
19903/28500 (epoch 34.918), train_loss = 0.83482570, grad/param norm = 1.9428e-01, time/batch = 15.3071s	
19904/28500 (epoch 34.919), train_loss = 0.83129004, grad/param norm = 1.5813e-01, time/batch = 15.5566s	
19905/28500 (epoch 34.921), train_loss = 0.93751152, grad/param norm = 1.9688e-01, time/batch = 15.4243s	
19906/28500 (epoch 34.923), train_loss = 0.81336367, grad/param norm = 2.2871e-01, time/batch = 15.2316s	
19907/28500 (epoch 34.925), train_loss = 0.80560055, grad/param norm = 2.2737e-01, time/batch = 15.0403s	
19908/28500 (epoch 34.926), train_loss = 0.85831979, grad/param norm = 1.8398e-01, time/batch = 15.2386s	
19909/28500 (epoch 34.928), train_loss = 0.78391147, grad/param norm = 1.6003e-01, time/batch = 15.2114s	
19910/28500 (epoch 34.930), train_loss = 0.67082190, grad/param norm = 1.5444e-01, time/batch = 15.2619s	
19911/28500 (epoch 34.932), train_loss = 0.68545209, grad/param norm = 1.4706e-01, time/batch = 15.2921s	
19912/28500 (epoch 34.933), train_loss = 0.90630686, grad/param norm = 2.1536e-01, time/batch = 15.3588s	
19913/28500 (epoch 34.935), train_loss = 0.94033438, grad/param norm = 1.8887e-01, time/batch = 15.1819s	
19914/28500 (epoch 34.937), train_loss = 0.94669015, grad/param norm = 2.1852e-01, time/batch = 15.4682s	
19915/28500 (epoch 34.939), train_loss = 0.97503411, grad/param norm = 2.2472e-01, time/batch = 15.4654s	
19916/28500 (epoch 34.940), train_loss = 0.71718319, grad/param norm = 1.8891e-01, time/batch = 15.2049s	
19917/28500 (epoch 34.942), train_loss = 0.84353292, grad/param norm = 1.8824e-01, time/batch = 15.0587s	
19918/28500 (epoch 34.944), train_loss = 0.81218128, grad/param norm = 2.4664e-01, time/batch = 15.4075s	
19919/28500 (epoch 34.946), train_loss = 0.90113120, grad/param norm = 1.6127e-01, time/batch = 15.1424s	
19920/28500 (epoch 34.947), train_loss = 1.09095916, grad/param norm = 2.7419e-01, time/batch = 15.3730s	
19921/28500 (epoch 34.949), train_loss = 0.84469604, grad/param norm = 2.2055e-01, time/batch = 15.3079s	
19922/28500 (epoch 34.951), train_loss = 1.00768731, grad/param norm = 2.0602e-01, time/batch = 15.0619s	
19923/28500 (epoch 34.953), train_loss = 0.99391488, grad/param norm = 2.0716e-01, time/batch = 15.1370s	
19924/28500 (epoch 34.954), train_loss = 0.93968495, grad/param norm = 2.3038e-01, time/batch = 15.1499s	
19925/28500 (epoch 34.956), train_loss = 0.86313574, grad/param norm = 2.4582e-01, time/batch = 15.3625s	
19926/28500 (epoch 34.958), train_loss = 1.08679500, grad/param norm = 2.0989e-01, time/batch = 15.2249s	
19927/28500 (epoch 34.960), train_loss = 0.80886265, grad/param norm = 2.0985e-01, time/batch = 15.0519s	
19928/28500 (epoch 34.961), train_loss = 1.02302559, grad/param norm = 2.2434e-01, time/batch = 15.1408s	
19929/28500 (epoch 34.963), train_loss = 0.93764631, grad/param norm = 1.9552e-01, time/batch = 15.1014s	
19930/28500 (epoch 34.965), train_loss = 0.79099527, grad/param norm = 1.9862e-01, time/batch = 14.9837s	
19931/28500 (epoch 34.967), train_loss = 0.81192502, grad/param norm = 1.7483e-01, time/batch = 15.2953s	
19932/28500 (epoch 34.968), train_loss = 0.73381521, grad/param norm = 1.4761e-01, time/batch = 15.3118s	
19933/28500 (epoch 34.970), train_loss = 0.80687065, grad/param norm = 2.2051e-01, time/batch = 15.6367s	
19934/28500 (epoch 34.972), train_loss = 0.86583031, grad/param norm = 1.7927e-01, time/batch = 15.3746s	
19935/28500 (epoch 34.974), train_loss = 1.04446390, grad/param norm = 2.2386e-01, time/batch = 15.1330s	
19936/28500 (epoch 34.975), train_loss = 0.79132770, grad/param norm = 2.1092e-01, time/batch = 15.1951s	
19937/28500 (epoch 34.977), train_loss = 0.92496880, grad/param norm = 1.8765e-01, time/batch = 15.1187s	
19938/28500 (epoch 34.979), train_loss = 0.85945000, grad/param norm = 1.7470e-01, time/batch = 15.6376s	
19939/28500 (epoch 34.981), train_loss = 0.76142405, grad/param norm = 1.7614e-01, time/batch = 15.3707s	
19940/28500 (epoch 34.982), train_loss = 0.81223550, grad/param norm = 1.6291e-01, time/batch = 15.1358s	
19941/28500 (epoch 34.984), train_loss = 0.94000402, grad/param norm = 1.7476e-01, time/batch = 15.6281s	
19942/28500 (epoch 34.986), train_loss = 1.09490232, grad/param norm = 2.0684e-01, time/batch = 15.5671s	
19943/28500 (epoch 34.988), train_loss = 0.77810233, grad/param norm = 1.7275e-01, time/batch = 27.3828s	
19944/28500 (epoch 34.989), train_loss = 0.86984985, grad/param norm = 1.8974e-01, time/batch = 15.4891s	
19945/28500 (epoch 34.991), train_loss = 0.79298797, grad/param norm = 1.8994e-01, time/batch = 15.3911s	
19946/28500 (epoch 34.993), train_loss = 0.76039079, grad/param norm = 1.8416e-01, time/batch = 15.1261s	
19947/28500 (epoch 34.995), train_loss = 0.79529044, grad/param norm = 1.6928e-01, time/batch = 15.3038s	
19948/28500 (epoch 34.996), train_loss = 0.75547112, grad/param norm = 1.9281e-01, time/batch = 15.1804s	
19949/28500 (epoch 34.998), train_loss = 0.94126653, grad/param norm = 2.4795e-01, time/batch = 15.2082s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
19950/28500 (epoch 35.000), train_loss = 0.82559932, grad/param norm = 1.8723e-01, time/batch = 15.2999s	
19951/28500 (epoch 35.002), train_loss = 1.00485669, grad/param norm = 1.9525e-01, time/batch = 15.3043s	
19952/28500 (epoch 35.004), train_loss = 0.85098549, grad/param norm = 1.6512e-01, time/batch = 15.6098s	
19953/28500 (epoch 35.005), train_loss = 0.95582643, grad/param norm = 2.1707e-01, time/batch = 15.5576s	
19954/28500 (epoch 35.007), train_loss = 0.75592037, grad/param norm = 1.5632e-01, time/batch = 15.4596s	
19955/28500 (epoch 35.009), train_loss = 0.88031755, grad/param norm = 1.8519e-01, time/batch = 15.5360s	
19956/28500 (epoch 35.011), train_loss = 0.80445825, grad/param norm = 1.8788e-01, time/batch = 15.4063s	
19957/28500 (epoch 35.012), train_loss = 0.78090907, grad/param norm = 1.6567e-01, time/batch = 15.4175s	
19958/28500 (epoch 35.014), train_loss = 0.75773110, grad/param norm = 1.8506e-01, time/batch = 15.4633s	
19959/28500 (epoch 35.016), train_loss = 0.83054713, grad/param norm = 1.9008e-01, time/batch = 15.4393s	
19960/28500 (epoch 35.018), train_loss = 0.89227669, grad/param norm = 1.8446e-01, time/batch = 15.1512s	
19961/28500 (epoch 35.019), train_loss = 0.93431863, grad/param norm = 1.8815e-01, time/batch = 15.5481s	
19962/28500 (epoch 35.021), train_loss = 0.95958708, grad/param norm = 1.7248e-01, time/batch = 15.5417s	
19963/28500 (epoch 35.023), train_loss = 0.86402596, grad/param norm = 1.6834e-01, time/batch = 15.3510s	
19964/28500 (epoch 35.025), train_loss = 0.88165873, grad/param norm = 1.8496e-01, time/batch = 15.2151s	
19965/28500 (epoch 35.026), train_loss = 0.83363347, grad/param norm = 1.8010e-01, time/batch = 15.3115s	
19966/28500 (epoch 35.028), train_loss = 0.88322975, grad/param norm = 1.9065e-01, time/batch = 15.2846s	
19967/28500 (epoch 35.030), train_loss = 0.91640753, grad/param norm = 2.3196e-01, time/batch = 15.1589s	
19968/28500 (epoch 35.032), train_loss = 0.95009310, grad/param norm = 1.9444e-01, time/batch = 15.2253s	
19969/28500 (epoch 35.033), train_loss = 1.00563277, grad/param norm = 1.9223e-01, time/batch = 15.2168s	
19970/28500 (epoch 35.035), train_loss = 0.82283250, grad/param norm = 2.0217e-01, time/batch = 15.3536s	
19971/28500 (epoch 35.037), train_loss = 0.91520134, grad/param norm = 1.7654e-01, time/batch = 15.4221s	
19972/28500 (epoch 35.039), train_loss = 0.97494610, grad/param norm = 1.9019e-01, time/batch = 15.3149s	
19973/28500 (epoch 35.040), train_loss = 0.98666108, grad/param norm = 1.9350e-01, time/batch = 15.5016s	
19974/28500 (epoch 35.042), train_loss = 0.92406254, grad/param norm = 1.7725e-01, time/batch = 15.6266s	
19975/28500 (epoch 35.044), train_loss = 0.88798886, grad/param norm = 2.1003e-01, time/batch = 15.2294s	
19976/28500 (epoch 35.046), train_loss = 1.05982202, grad/param norm = 1.9364e-01, time/batch = 15.0661s	
19977/28500 (epoch 35.047), train_loss = 1.01300915, grad/param norm = 2.2977e-01, time/batch = 15.4433s	
19978/28500 (epoch 35.049), train_loss = 0.86305020, grad/param norm = 1.7573e-01, time/batch = 14.9906s	
19979/28500 (epoch 35.051), train_loss = 0.87058111, grad/param norm = 2.0359e-01, time/batch = 15.0358s	
19980/28500 (epoch 35.053), train_loss = 0.84590290, grad/param norm = 2.0431e-01, time/batch = 15.3094s	
19981/28500 (epoch 35.054), train_loss = 0.94098425, grad/param norm = 1.8627e-01, time/batch = 15.4538s	
19982/28500 (epoch 35.056), train_loss = 0.78881767, grad/param norm = 1.7029e-01, time/batch = 15.4770s	
19983/28500 (epoch 35.058), train_loss = 0.78825335, grad/param norm = 1.5898e-01, time/batch = 15.5743s	
19984/28500 (epoch 35.060), train_loss = 0.91176543, grad/param norm = 1.9003e-01, time/batch = 15.4823s	
19985/28500 (epoch 35.061), train_loss = 0.85070127, grad/param norm = 1.8079e-01, time/batch = 15.4533s	
19986/28500 (epoch 35.063), train_loss = 0.92951076, grad/param norm = 1.9632e-01, time/batch = 15.3736s	
19987/28500 (epoch 35.065), train_loss = 0.87669047, grad/param norm = 1.7945e-01, time/batch = 15.3803s	
19988/28500 (epoch 35.067), train_loss = 0.81231912, grad/param norm = 1.8581e-01, time/batch = 15.5531s	
19989/28500 (epoch 35.068), train_loss = 0.83406369, grad/param norm = 1.8658e-01, time/batch = 15.6018s	
19990/28500 (epoch 35.070), train_loss = 0.91795314, grad/param norm = 1.9740e-01, time/batch = 15.5735s	
19991/28500 (epoch 35.072), train_loss = 0.98430444, grad/param norm = 2.0312e-01, time/batch = 15.3142s	
19992/28500 (epoch 35.074), train_loss = 0.87609243, grad/param norm = 1.8565e-01, time/batch = 15.4657s	
19993/28500 (epoch 35.075), train_loss = 0.83398952, grad/param norm = 1.5697e-01, time/batch = 15.4740s	
19994/28500 (epoch 35.077), train_loss = 0.90905310, grad/param norm = 1.7613e-01, time/batch = 15.4563s	
19995/28500 (epoch 35.079), train_loss = 0.86969106, grad/param norm = 1.7216e-01, time/batch = 15.2870s	
19996/28500 (epoch 35.081), train_loss = 0.99380302, grad/param norm = 2.1835e-01, time/batch = 15.2902s	
19997/28500 (epoch 35.082), train_loss = 0.87477886, grad/param norm = 2.2685e-01, time/batch = 15.5699s	
19998/28500 (epoch 35.084), train_loss = 0.88354526, grad/param norm = 1.7613e-01, time/batch = 15.4764s	
19999/28500 (epoch 35.086), train_loss = 0.84026515, grad/param norm = 2.5014e-01, time/batch = 15.4052s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch35.09_1.8930.t7	
20000/28500 (epoch 35.088), train_loss = 0.77526312, grad/param norm = 1.7914e-01, time/batch = 15.5388s	
20001/28500 (epoch 35.089), train_loss = 1.50127629, grad/param norm = 2.5283e-01, time/batch = 15.7839s	
20002/28500 (epoch 35.091), train_loss = 0.76692092, grad/param norm = 1.6638e-01, time/batch = 15.6540s	
20003/28500 (epoch 35.093), train_loss = 0.96938399, grad/param norm = 1.8055e-01, time/batch = 15.3357s	
20004/28500 (epoch 35.095), train_loss = 0.85790230, grad/param norm = 1.6380e-01, time/batch = 15.2143s	
20005/28500 (epoch 35.096), train_loss = 0.96142387, grad/param norm = 1.7804e-01, time/batch = 15.0633s	
20006/28500 (epoch 35.098), train_loss = 0.88507636, grad/param norm = 2.0073e-01, time/batch = 15.3019s	
20007/28500 (epoch 35.100), train_loss = 0.84109732, grad/param norm = 1.7924e-01, time/batch = 15.3060s	
20008/28500 (epoch 35.102), train_loss = 0.94531555, grad/param norm = 1.9871e-01, time/batch = 15.4755s	
20009/28500 (epoch 35.104), train_loss = 0.87327058, grad/param norm = 2.7781e-01, time/batch = 15.5433s	
20010/28500 (epoch 35.105), train_loss = 0.98336450, grad/param norm = 1.9383e-01, time/batch = 15.3159s	
20011/28500 (epoch 35.107), train_loss = 0.80098875, grad/param norm = 1.8208e-01, time/batch = 15.0654s	
20012/28500 (epoch 35.109), train_loss = 0.84302524, grad/param norm = 2.2794e-01, time/batch = 15.2383s	
20013/28500 (epoch 35.111), train_loss = 0.85262852, grad/param norm = 2.2803e-01, time/batch = 15.3965s	
20014/28500 (epoch 35.112), train_loss = 0.94839856, grad/param norm = 1.9049e-01, time/batch = 15.5544s	
20015/28500 (epoch 35.114), train_loss = 0.85033366, grad/param norm = 1.8923e-01, time/batch = 15.6109s	
20016/28500 (epoch 35.116), train_loss = 1.01246728, grad/param norm = 2.0394e-01, time/batch = 15.2543s	
20017/28500 (epoch 35.118), train_loss = 0.78244651, grad/param norm = 1.8274e-01, time/batch = 15.1617s	
20018/28500 (epoch 35.119), train_loss = 0.89800045, grad/param norm = 1.8467e-01, time/batch = 15.1412s	
20019/28500 (epoch 35.121), train_loss = 1.03331703, grad/param norm = 2.2870e-01, time/batch = 15.2140s	
20020/28500 (epoch 35.123), train_loss = 0.96265003, grad/param norm = 1.8919e-01, time/batch = 15.5318s	
20021/28500 (epoch 35.125), train_loss = 0.88210219, grad/param norm = 1.7670e-01, time/batch = 15.6202s	
20022/28500 (epoch 35.126), train_loss = 0.86528639, grad/param norm = 1.9515e-01, time/batch = 15.5631s	
20023/28500 (epoch 35.128), train_loss = 0.87966883, grad/param norm = 1.8201e-01, time/batch = 15.6275s	
20024/28500 (epoch 35.130), train_loss = 0.81606186, grad/param norm = 1.9533e-01, time/batch = 15.5598s	
20025/28500 (epoch 35.132), train_loss = 0.88229648, grad/param norm = 2.0334e-01, time/batch = 15.2752s	
20026/28500 (epoch 35.133), train_loss = 0.92942722, grad/param norm = 2.0594e-01, time/batch = 15.2128s	
20027/28500 (epoch 35.135), train_loss = 0.82369798, grad/param norm = 1.6982e-01, time/batch = 15.3877s	
20028/28500 (epoch 35.137), train_loss = 0.89596439, grad/param norm = 1.8757e-01, time/batch = 15.4693s	
20029/28500 (epoch 35.139), train_loss = 0.89143465, grad/param norm = 2.0224e-01, time/batch = 15.4606s	
20030/28500 (epoch 35.140), train_loss = 0.87815896, grad/param norm = 1.8562e-01, time/batch = 15.5405s	
20031/28500 (epoch 35.142), train_loss = 0.82785762, grad/param norm = 1.7626e-01, time/batch = 15.7691s	
20032/28500 (epoch 35.144), train_loss = 0.79637273, grad/param norm = 1.8310e-01, time/batch = 15.6921s	
20033/28500 (epoch 35.146), train_loss = 0.85340395, grad/param norm = 1.7439e-01, time/batch = 15.5529s	
20034/28500 (epoch 35.147), train_loss = 0.75940135, grad/param norm = 1.5889e-01, time/batch = 15.4831s	
20035/28500 (epoch 35.149), train_loss = 0.74841520, grad/param norm = 1.6022e-01, time/batch = 15.5218s	
20036/28500 (epoch 35.151), train_loss = 0.84597816, grad/param norm = 1.7877e-01, time/batch = 15.4711s	
20037/28500 (epoch 35.153), train_loss = 0.88941253, grad/param norm = 1.7399e-01, time/batch = 15.3799s	
20038/28500 (epoch 35.154), train_loss = 0.76638610, grad/param norm = 1.8236e-01, time/batch = 15.1278s	
20039/28500 (epoch 35.156), train_loss = 0.93970490, grad/param norm = 1.9663e-01, time/batch = 15.3853s	
20040/28500 (epoch 35.158), train_loss = 0.90269140, grad/param norm = 2.0774e-01, time/batch = 15.3841s	
20041/28500 (epoch 35.160), train_loss = 0.77155215, grad/param norm = 1.6383e-01, time/batch = 15.3067s	
20042/28500 (epoch 35.161), train_loss = 0.79970260, grad/param norm = 1.9205e-01, time/batch = 15.3336s	
20043/28500 (epoch 35.163), train_loss = 0.73606304, grad/param norm = 1.6833e-01, time/batch = 15.3773s	
20044/28500 (epoch 35.165), train_loss = 1.02647466, grad/param norm = 1.8655e-01, time/batch = 15.4408s	
20045/28500 (epoch 35.167), train_loss = 1.02688395, grad/param norm = 1.9257e-01, time/batch = 15.2801s	
20046/28500 (epoch 35.168), train_loss = 0.98350125, grad/param norm = 2.3193e-01, time/batch = 15.4651s	
20047/28500 (epoch 35.170), train_loss = 0.97632703, grad/param norm = 2.4761e-01, time/batch = 15.4561s	
20048/28500 (epoch 35.172), train_loss = 0.85265094, grad/param norm = 1.6267e-01, time/batch = 15.4765s	
20049/28500 (epoch 35.174), train_loss = 1.02954635, grad/param norm = 2.1140e-01, time/batch = 15.4505s	
20050/28500 (epoch 35.175), train_loss = 0.84712130, grad/param norm = 1.5983e-01, time/batch = 15.4685s	
20051/28500 (epoch 35.177), train_loss = 0.91345263, grad/param norm = 1.8171e-01, time/batch = 15.6509s	
20052/28500 (epoch 35.179), train_loss = 0.95045259, grad/param norm = 1.8129e-01, time/batch = 15.2075s	
20053/28500 (epoch 35.181), train_loss = 0.90812791, grad/param norm = 1.9914e-01, time/batch = 15.1261s	
20054/28500 (epoch 35.182), train_loss = 0.82988138, grad/param norm = 1.7249e-01, time/batch = 15.1244s	
20055/28500 (epoch 35.184), train_loss = 1.04044939, grad/param norm = 2.1189e-01, time/batch = 15.4422s	
20056/28500 (epoch 35.186), train_loss = 0.98947586, grad/param norm = 1.7983e-01, time/batch = 15.3471s	
20057/28500 (epoch 35.188), train_loss = 0.92661434, grad/param norm = 1.8603e-01, time/batch = 15.3032s	
20058/28500 (epoch 35.189), train_loss = 0.89495473, grad/param norm = 2.0735e-01, time/batch = 15.2569s	
20059/28500 (epoch 35.191), train_loss = 1.06187165, grad/param norm = 2.0389e-01, time/batch = 15.5526s	
20060/28500 (epoch 35.193), train_loss = 0.89895535, grad/param norm = 1.9756e-01, time/batch = 15.4658s	
20061/28500 (epoch 35.195), train_loss = 1.00963543, grad/param norm = 2.0648e-01, time/batch = 15.5442s	
20062/28500 (epoch 35.196), train_loss = 0.93684653, grad/param norm = 1.8267e-01, time/batch = 15.2970s	
20063/28500 (epoch 35.198), train_loss = 0.89669832, grad/param norm = 1.9013e-01, time/batch = 15.2956s	
20064/28500 (epoch 35.200), train_loss = 0.95285108, grad/param norm = 1.8420e-01, time/batch = 15.4010s	
20065/28500 (epoch 35.202), train_loss = 0.91009152, grad/param norm = 1.7208e-01, time/batch = 15.4529s	
20066/28500 (epoch 35.204), train_loss = 0.86376703, grad/param norm = 1.5949e-01, time/batch = 15.5184s	
20067/28500 (epoch 35.205), train_loss = 0.82311488, grad/param norm = 1.6875e-01, time/batch = 15.3104s	
20068/28500 (epoch 35.207), train_loss = 0.77013686, grad/param norm = 1.6612e-01, time/batch = 15.0553s	
20069/28500 (epoch 35.209), train_loss = 0.90833381, grad/param norm = 1.7540e-01, time/batch = 15.4894s	
20070/28500 (epoch 35.211), train_loss = 0.80784082, grad/param norm = 2.0325e-01, time/batch = 15.5343s	
20071/28500 (epoch 35.212), train_loss = 0.74791875, grad/param norm = 1.8518e-01, time/batch = 15.4046s	
20072/28500 (epoch 35.214), train_loss = 0.88005839, grad/param norm = 1.8624e-01, time/batch = 15.3047s	
20073/28500 (epoch 35.216), train_loss = 0.82065588, grad/param norm = 1.7704e-01, time/batch = 15.1345s	
20074/28500 (epoch 35.218), train_loss = 0.97963114, grad/param norm = 1.7077e-01, time/batch = 15.2266s	
20075/28500 (epoch 35.219), train_loss = 0.90973638, grad/param norm = 1.7984e-01, time/batch = 15.1628s	
20076/28500 (epoch 35.221), train_loss = 0.76794448, grad/param norm = 1.8315e-01, time/batch = 15.2852s	
20077/28500 (epoch 35.223), train_loss = 0.98398328, grad/param norm = 1.9571e-01, time/batch = 15.4676s	
20078/28500 (epoch 35.225), train_loss = 1.01881278, grad/param norm = 1.9990e-01, time/batch = 15.8005s	
20079/28500 (epoch 35.226), train_loss = 0.84098519, grad/param norm = 1.6832e-01, time/batch = 15.4798s	
20080/28500 (epoch 35.228), train_loss = 0.96441493, grad/param norm = 1.9054e-01, time/batch = 15.4344s	
20081/28500 (epoch 35.230), train_loss = 0.95063775, grad/param norm = 1.8444e-01, time/batch = 15.6008s	
20082/28500 (epoch 35.232), train_loss = 0.93766065, grad/param norm = 1.7923e-01, time/batch = 15.4244s	
20083/28500 (epoch 35.233), train_loss = 0.87310547, grad/param norm = 1.9303e-01, time/batch = 15.3854s	
20084/28500 (epoch 35.235), train_loss = 0.87612836, grad/param norm = 1.7727e-01, time/batch = 15.3957s	
20085/28500 (epoch 35.237), train_loss = 0.78195448, grad/param norm = 1.4023e-01, time/batch = 15.5166s	
20086/28500 (epoch 35.239), train_loss = 0.84484726, grad/param norm = 1.6057e-01, time/batch = 15.4795s	
20087/28500 (epoch 35.240), train_loss = 0.77294059, grad/param norm = 1.6941e-01, time/batch = 15.4595s	
20088/28500 (epoch 35.242), train_loss = 0.84586477, grad/param norm = 1.8667e-01, time/batch = 15.4055s	
20089/28500 (epoch 35.244), train_loss = 0.90521501, grad/param norm = 1.5353e-01, time/batch = 15.3798s	
20090/28500 (epoch 35.246), train_loss = 0.92804346, grad/param norm = 1.7534e-01, time/batch = 15.4929s	
20091/28500 (epoch 35.247), train_loss = 0.99688894, grad/param norm = 2.1370e-01, time/batch = 15.5506s	
20092/28500 (epoch 35.249), train_loss = 0.84940067, grad/param norm = 1.6078e-01, time/batch = 15.4376s	
20093/28500 (epoch 35.251), train_loss = 0.85096159, grad/param norm = 1.6086e-01, time/batch = 15.5471s	
20094/28500 (epoch 35.253), train_loss = 0.99050483, grad/param norm = 1.8794e-01, time/batch = 15.5294s	
20095/28500 (epoch 35.254), train_loss = 1.01704359, grad/param norm = 1.8545e-01, time/batch = 15.5941s	
20096/28500 (epoch 35.256), train_loss = 0.85044858, grad/param norm = 1.8231e-01, time/batch = 15.3543s	
20097/28500 (epoch 35.258), train_loss = 0.86773155, grad/param norm = 1.7934e-01, time/batch = 15.2233s	
20098/28500 (epoch 35.260), train_loss = 0.87042666, grad/param norm = 1.6878e-01, time/batch = 15.1168s	
20099/28500 (epoch 35.261), train_loss = 0.76707815, grad/param norm = 1.6520e-01, time/batch = 15.3107s	
20100/28500 (epoch 35.263), train_loss = 0.94861810, grad/param norm = 2.0210e-01, time/batch = 15.5404s	
20101/28500 (epoch 35.265), train_loss = 0.84896691, grad/param norm = 1.7612e-01, time/batch = 15.6449s	
20102/28500 (epoch 35.267), train_loss = 1.01152535, grad/param norm = 2.3429e-01, time/batch = 15.5474s	
20103/28500 (epoch 35.268), train_loss = 0.91953170, grad/param norm = 1.8317e-01, time/batch = 15.6411s	
20104/28500 (epoch 35.270), train_loss = 0.87823710, grad/param norm = 1.9883e-01, time/batch = 15.6190s	
20105/28500 (epoch 35.272), train_loss = 0.91558823, grad/param norm = 2.0388e-01, time/batch = 15.4871s	
20106/28500 (epoch 35.274), train_loss = 0.94240479, grad/param norm = 2.0540e-01, time/batch = 15.3878s	
20107/28500 (epoch 35.275), train_loss = 0.93179569, grad/param norm = 1.6287e-01, time/batch = 15.3838s	
20108/28500 (epoch 35.277), train_loss = 0.87082770, grad/param norm = 2.0791e-01, time/batch = 15.4261s	
20109/28500 (epoch 35.279), train_loss = 0.88812539, grad/param norm = 2.0825e-01, time/batch = 15.1794s	
20110/28500 (epoch 35.281), train_loss = 0.94222567, grad/param norm = 2.3300e-01, time/batch = 15.3191s	
20111/28500 (epoch 35.282), train_loss = 0.86748950, grad/param norm = 1.6623e-01, time/batch = 15.2323s	
20112/28500 (epoch 35.284), train_loss = 0.90502595, grad/param norm = 2.0270e-01, time/batch = 15.1273s	
20113/28500 (epoch 35.286), train_loss = 1.00131925, grad/param norm = 1.8780e-01, time/batch = 15.1356s	
20114/28500 (epoch 35.288), train_loss = 0.88637550, grad/param norm = 2.0384e-01, time/batch = 15.1428s	
20115/28500 (epoch 35.289), train_loss = 0.90137315, grad/param norm = 1.8613e-01, time/batch = 15.1364s	
20116/28500 (epoch 35.291), train_loss = 0.89368942, grad/param norm = 1.7985e-01, time/batch = 15.3530s	
20117/28500 (epoch 35.293), train_loss = 0.88764613, grad/param norm = 1.8284e-01, time/batch = 15.4424s	
20118/28500 (epoch 35.295), train_loss = 0.79234963, grad/param norm = 1.6162e-01, time/batch = 15.3140s	
20119/28500 (epoch 35.296), train_loss = 0.76849096, grad/param norm = 1.5702e-01, time/batch = 15.2101s	
20120/28500 (epoch 35.298), train_loss = 0.92833533, grad/param norm = 1.8260e-01, time/batch = 15.0496s	
20121/28500 (epoch 35.300), train_loss = 0.81981958, grad/param norm = 1.7924e-01, time/batch = 15.2298s	
20122/28500 (epoch 35.302), train_loss = 0.76040901, grad/param norm = 1.5910e-01, time/batch = 15.3356s	
20123/28500 (epoch 35.304), train_loss = 0.87059343, grad/param norm = 1.8747e-01, time/batch = 15.1197s	
20124/28500 (epoch 35.305), train_loss = 0.90044374, grad/param norm = 1.7290e-01, time/batch = 15.5057s	
20125/28500 (epoch 35.307), train_loss = 0.85109090, grad/param norm = 1.8575e-01, time/batch = 15.4472s	
20126/28500 (epoch 35.309), train_loss = 0.86685955, grad/param norm = 1.6972e-01, time/batch = 15.3939s	
20127/28500 (epoch 35.311), train_loss = 0.91570590, grad/param norm = 1.7723e-01, time/batch = 15.5349s	
20128/28500 (epoch 35.312), train_loss = 0.92351583, grad/param norm = 1.7437e-01, time/batch = 15.6864s	
20129/28500 (epoch 35.314), train_loss = 0.93678315, grad/param norm = 2.0977e-01, time/batch = 15.3804s	
20130/28500 (epoch 35.316), train_loss = 0.89488142, grad/param norm = 2.0424e-01, time/batch = 15.2891s	
20131/28500 (epoch 35.318), train_loss = 0.95743464, grad/param norm = 1.6622e-01, time/batch = 15.3794s	
20132/28500 (epoch 35.319), train_loss = 0.83788542, grad/param norm = 2.0215e-01, time/batch = 15.1254s	
20133/28500 (epoch 35.321), train_loss = 0.84729402, grad/param norm = 1.9804e-01, time/batch = 15.3613s	
20134/28500 (epoch 35.323), train_loss = 0.86226814, grad/param norm = 2.0526e-01, time/batch = 15.2978s	
20135/28500 (epoch 35.325), train_loss = 1.01770092, grad/param norm = 1.9702e-01, time/batch = 15.5080s	
20136/28500 (epoch 35.326), train_loss = 0.89592860, grad/param norm = 1.7533e-01, time/batch = 15.5201s	
20137/28500 (epoch 35.328), train_loss = 0.71217232, grad/param norm = 1.6196e-01, time/batch = 15.4011s	
20138/28500 (epoch 35.330), train_loss = 0.81779523, grad/param norm = 1.8292e-01, time/batch = 15.4324s	
20139/28500 (epoch 35.332), train_loss = 0.84904076, grad/param norm = 1.8490e-01, time/batch = 15.3971s	
20140/28500 (epoch 35.333), train_loss = 0.70316706, grad/param norm = 1.7800e-01, time/batch = 15.2606s	
20141/28500 (epoch 35.335), train_loss = 0.77885945, grad/param norm = 1.6228e-01, time/batch = 15.6260s	
20142/28500 (epoch 35.337), train_loss = 0.71572646, grad/param norm = 1.6466e-01, time/batch = 15.2941s	
20143/28500 (epoch 35.339), train_loss = 0.70665468, grad/param norm = 1.3813e-01, time/batch = 15.3268s	
20144/28500 (epoch 35.340), train_loss = 0.87398471, grad/param norm = 2.1084e-01, time/batch = 15.5657s	
20145/28500 (epoch 35.342), train_loss = 0.85412055, grad/param norm = 1.6991e-01, time/batch = 15.2242s	
20146/28500 (epoch 35.344), train_loss = 0.76996718, grad/param norm = 1.8732e-01, time/batch = 15.2164s	
20147/28500 (epoch 35.346), train_loss = 0.71718927, grad/param norm = 1.4743e-01, time/batch = 15.2789s	
20148/28500 (epoch 35.347), train_loss = 0.86817191, grad/param norm = 1.6926e-01, time/batch = 15.2055s	
20149/28500 (epoch 35.349), train_loss = 0.86198235, grad/param norm = 1.7433e-01, time/batch = 15.1518s	
20150/28500 (epoch 35.351), train_loss = 0.77202532, grad/param norm = 1.6601e-01, time/batch = 15.3172s	
20151/28500 (epoch 35.353), train_loss = 0.86735558, grad/param norm = 2.0688e-01, time/batch = 15.5415s	
20152/28500 (epoch 35.354), train_loss = 0.75309157, grad/param norm = 1.5863e-01, time/batch = 15.3902s	
20153/28500 (epoch 35.356), train_loss = 0.81930741, grad/param norm = 1.6406e-01, time/batch = 15.2365s	
20154/28500 (epoch 35.358), train_loss = 0.90414862, grad/param norm = 1.6409e-01, time/batch = 15.2053s	
20155/28500 (epoch 35.360), train_loss = 0.89222573, grad/param norm = 1.9235e-01, time/batch = 15.2161s	
20156/28500 (epoch 35.361), train_loss = 0.78123828, grad/param norm = 1.6402e-01, time/batch = 15.2239s	
20157/28500 (epoch 35.363), train_loss = 0.78459759, grad/param norm = 1.5398e-01, time/batch = 15.0322s	
20158/28500 (epoch 35.365), train_loss = 0.83611809, grad/param norm = 2.1577e-01, time/batch = 15.0598s	
20159/28500 (epoch 35.367), train_loss = 0.87331954, grad/param norm = 1.7038e-01, time/batch = 15.1314s	
20160/28500 (epoch 35.368), train_loss = 0.79437117, grad/param norm = 1.6658e-01, time/batch = 15.1373s	
20161/28500 (epoch 35.370), train_loss = 0.86126833, grad/param norm = 1.6843e-01, time/batch = 15.2214s	
20162/28500 (epoch 35.372), train_loss = 0.69531673, grad/param norm = 1.6228e-01, time/batch = 15.3890s	
20163/28500 (epoch 35.374), train_loss = 0.81965695, grad/param norm = 1.7745e-01, time/batch = 15.1907s	
20164/28500 (epoch 35.375), train_loss = 0.93368082, grad/param norm = 1.7852e-01, time/batch = 15.2051s	
20165/28500 (epoch 35.377), train_loss = 0.77751568, grad/param norm = 2.2499e-01, time/batch = 15.3609s	
20166/28500 (epoch 35.379), train_loss = 0.65277077, grad/param norm = 1.5896e-01, time/batch = 15.4661s	
20167/28500 (epoch 35.381), train_loss = 0.83325422, grad/param norm = 1.6389e-01, time/batch = 27.7288s	
20168/28500 (epoch 35.382), train_loss = 0.82158320, grad/param norm = 2.0528e-01, time/batch = 15.1165s	
20169/28500 (epoch 35.384), train_loss = 0.70104739, grad/param norm = 1.6110e-01, time/batch = 15.3550s	
20170/28500 (epoch 35.386), train_loss = 0.77442765, grad/param norm = 1.7181e-01, time/batch = 15.0432s	
20171/28500 (epoch 35.388), train_loss = 0.94152636, grad/param norm = 1.9556e-01, time/batch = 15.3283s	
20172/28500 (epoch 35.389), train_loss = 0.80078610, grad/param norm = 1.8461e-01, time/batch = 15.4284s	
20173/28500 (epoch 35.391), train_loss = 0.75656188, grad/param norm = 1.9810e-01, time/batch = 15.4377s	
20174/28500 (epoch 35.393), train_loss = 0.78843831, grad/param norm = 1.8883e-01, time/batch = 15.5745s	
20175/28500 (epoch 35.395), train_loss = 0.95959534, grad/param norm = 1.8874e-01, time/batch = 15.4157s	
20176/28500 (epoch 35.396), train_loss = 0.92532406, grad/param norm = 1.7776e-01, time/batch = 15.4645s	
20177/28500 (epoch 35.398), train_loss = 0.63890358, grad/param norm = 1.6241e-01, time/batch = 15.2896s	
20178/28500 (epoch 35.400), train_loss = 0.81076732, grad/param norm = 1.6659e-01, time/batch = 15.4618s	
20179/28500 (epoch 35.402), train_loss = 0.87759443, grad/param norm = 1.9538e-01, time/batch = 15.2331s	
20180/28500 (epoch 35.404), train_loss = 0.88954406, grad/param norm = 1.9633e-01, time/batch = 15.5531s	
20181/28500 (epoch 35.405), train_loss = 0.91709990, grad/param norm = 1.8161e-01, time/batch = 15.5369s	
20182/28500 (epoch 35.407), train_loss = 0.84981477, grad/param norm = 1.8022e-01, time/batch = 15.3099s	
20183/28500 (epoch 35.409), train_loss = 0.86310085, grad/param norm = 1.8227e-01, time/batch = 15.2059s	
20184/28500 (epoch 35.411), train_loss = 0.95638576, grad/param norm = 1.9997e-01, time/batch = 15.4089s	
20185/28500 (epoch 35.412), train_loss = 0.99359464, grad/param norm = 2.0765e-01, time/batch = 15.5975s	
20186/28500 (epoch 35.414), train_loss = 0.87822696, grad/param norm = 1.9075e-01, time/batch = 15.5037s	
20187/28500 (epoch 35.416), train_loss = 0.79098865, grad/param norm = 1.8338e-01, time/batch = 15.3820s	
20188/28500 (epoch 35.418), train_loss = 0.87272651, grad/param norm = 1.5855e-01, time/batch = 15.3990s	
20189/28500 (epoch 35.419), train_loss = 0.97185444, grad/param norm = 2.1658e-01, time/batch = 15.3258s	
20190/28500 (epoch 35.421), train_loss = 0.94529506, grad/param norm = 1.9844e-01, time/batch = 15.1445s	
20191/28500 (epoch 35.423), train_loss = 0.93316573, grad/param norm = 2.0425e-01, time/batch = 15.1443s	
20192/28500 (epoch 35.425), train_loss = 0.87172939, grad/param norm = 2.1158e-01, time/batch = 15.3866s	
20193/28500 (epoch 35.426), train_loss = 0.88729261, grad/param norm = 2.1658e-01, time/batch = 15.4387s	
20194/28500 (epoch 35.428), train_loss = 1.01454199, grad/param norm = 2.1799e-01, time/batch = 15.5480s	
20195/28500 (epoch 35.430), train_loss = 1.00417065, grad/param norm = 1.7967e-01, time/batch = 15.1468s	
20196/28500 (epoch 35.432), train_loss = 0.85151398, grad/param norm = 1.8110e-01, time/batch = 15.0659s	
20197/28500 (epoch 35.433), train_loss = 0.93193744, grad/param norm = 1.9753e-01, time/batch = 15.0293s	
20198/28500 (epoch 35.435), train_loss = 0.90621871, grad/param norm = 2.2218e-01, time/batch = 15.0768s	
20199/28500 (epoch 35.437), train_loss = 0.81727869, grad/param norm = 1.7917e-01, time/batch = 15.3622s	
20200/28500 (epoch 35.439), train_loss = 0.85093671, grad/param norm = 1.5907e-01, time/batch = 15.5439s	
20201/28500 (epoch 35.440), train_loss = 1.02131567, grad/param norm = 1.9111e-01, time/batch = 15.4931s	
20202/28500 (epoch 35.442), train_loss = 0.80801603, grad/param norm = 1.8556e-01, time/batch = 15.1294s	
20203/28500 (epoch 35.444), train_loss = 0.77637231, grad/param norm = 1.5186e-01, time/batch = 15.4531s	
20204/28500 (epoch 35.446), train_loss = 0.73003440, grad/param norm = 1.5464e-01, time/batch = 15.3810s	
20205/28500 (epoch 35.447), train_loss = 0.75659414, grad/param norm = 1.6352e-01, time/batch = 15.5325s	
20206/28500 (epoch 35.449), train_loss = 0.82992124, grad/param norm = 1.7005e-01, time/batch = 15.2066s	
20207/28500 (epoch 35.451), train_loss = 0.82696339, grad/param norm = 1.6420e-01, time/batch = 15.4744s	
20208/28500 (epoch 35.453), train_loss = 0.82571588, grad/param norm = 1.8192e-01, time/batch = 15.2029s	
20209/28500 (epoch 35.454), train_loss = 0.77375127, grad/param norm = 1.5223e-01, time/batch = 15.2909s	
20210/28500 (epoch 35.456), train_loss = 0.93250684, grad/param norm = 2.3143e-01, time/batch = 15.2335s	
20211/28500 (epoch 35.458), train_loss = 0.83957359, grad/param norm = 1.8491e-01, time/batch = 15.2971s	
20212/28500 (epoch 35.460), train_loss = 0.93840821, grad/param norm = 1.6838e-01, time/batch = 15.3063s	
20213/28500 (epoch 35.461), train_loss = 0.77216170, grad/param norm = 1.8744e-01, time/batch = 15.6179s	
20214/28500 (epoch 35.463), train_loss = 0.73010955, grad/param norm = 1.5744e-01, time/batch = 15.5192s	
20215/28500 (epoch 35.465), train_loss = 0.72684384, grad/param norm = 1.8722e-01, time/batch = 15.1611s	
20216/28500 (epoch 35.467), train_loss = 0.86367943, grad/param norm = 1.6950e-01, time/batch = 15.1440s	
20217/28500 (epoch 35.468), train_loss = 0.76793601, grad/param norm = 1.5569e-01, time/batch = 15.1890s	
20218/28500 (epoch 35.470), train_loss = 0.80474338, grad/param norm = 1.6859e-01, time/batch = 15.3075s	
20219/28500 (epoch 35.472), train_loss = 0.76562173, grad/param norm = 1.5417e-01, time/batch = 15.3739s	
20220/28500 (epoch 35.474), train_loss = 0.99583783, grad/param norm = 2.1096e-01, time/batch = 15.1385s	
20221/28500 (epoch 35.475), train_loss = 0.80373102, grad/param norm = 1.7867e-01, time/batch = 15.2180s	
20222/28500 (epoch 35.477), train_loss = 0.83579155, grad/param norm = 1.8275e-01, time/batch = 15.0483s	
20223/28500 (epoch 35.479), train_loss = 0.88307672, grad/param norm = 1.8119e-01, time/batch = 15.1246s	
20224/28500 (epoch 35.481), train_loss = 0.90166033, grad/param norm = 1.8137e-01, time/batch = 15.2226s	
20225/28500 (epoch 35.482), train_loss = 0.74812771, grad/param norm = 1.5811e-01, time/batch = 15.2103s	
20226/28500 (epoch 35.484), train_loss = 0.78484109, grad/param norm = 1.8708e-01, time/batch = 15.3413s	
20227/28500 (epoch 35.486), train_loss = 0.69346068, grad/param norm = 1.9029e-01, time/batch = 15.3664s	
20228/28500 (epoch 35.488), train_loss = 0.88927287, grad/param norm = 1.6008e-01, time/batch = 15.2441s	
20229/28500 (epoch 35.489), train_loss = 0.98265351, grad/param norm = 1.8590e-01, time/batch = 14.9731s	
20230/28500 (epoch 35.491), train_loss = 0.80322462, grad/param norm = 1.9510e-01, time/batch = 15.3028s	
20231/28500 (epoch 35.493), train_loss = 0.84898644, grad/param norm = 1.8655e-01, time/batch = 15.3575s	
20232/28500 (epoch 35.495), train_loss = 0.87353658, grad/param norm = 1.9198e-01, time/batch = 15.4505s	
20233/28500 (epoch 35.496), train_loss = 0.77510707, grad/param norm = 1.9037e-01, time/batch = 15.2160s	
20234/28500 (epoch 35.498), train_loss = 0.82347016, grad/param norm = 1.6009e-01, time/batch = 15.2241s	
20235/28500 (epoch 35.500), train_loss = 0.77491944, grad/param norm = 1.5662e-01, time/batch = 15.2165s	
20236/28500 (epoch 35.502), train_loss = 0.90225791, grad/param norm = 1.6848e-01, time/batch = 15.2179s	
20237/28500 (epoch 35.504), train_loss = 0.87964201, grad/param norm = 1.6063e-01, time/batch = 15.0550s	
20238/28500 (epoch 35.505), train_loss = 0.79521280, grad/param norm = 1.8525e-01, time/batch = 15.3819s	
20239/28500 (epoch 35.507), train_loss = 0.95236658, grad/param norm = 2.4453e-01, time/batch = 15.3930s	
20240/28500 (epoch 35.509), train_loss = 0.85902241, grad/param norm = 1.6225e-01, time/batch = 15.4963s	
20241/28500 (epoch 35.511), train_loss = 0.86517884, grad/param norm = 1.8002e-01, time/batch = 15.5168s	
20242/28500 (epoch 35.512), train_loss = 0.89736888, grad/param norm = 1.8234e-01, time/batch = 15.5029s	
20243/28500 (epoch 35.514), train_loss = 0.85898787, grad/param norm = 1.8914e-01, time/batch = 15.2770s	
20244/28500 (epoch 35.516), train_loss = 0.84237376, grad/param norm = 1.7352e-01, time/batch = 15.1993s	
20245/28500 (epoch 35.518), train_loss = 0.90403310, grad/param norm = 1.7814e-01, time/batch = 15.3105s	
20246/28500 (epoch 35.519), train_loss = 0.90469469, grad/param norm = 1.8385e-01, time/batch = 15.2249s	
20247/28500 (epoch 35.521), train_loss = 0.97941568, grad/param norm = 2.1654e-01, time/batch = 15.4793s	
20248/28500 (epoch 35.523), train_loss = 0.90976825, grad/param norm = 1.9216e-01, time/batch = 15.3921s	
20249/28500 (epoch 35.525), train_loss = 0.96798234, grad/param norm = 1.7493e-01, time/batch = 15.3079s	
20250/28500 (epoch 35.526), train_loss = 0.91105439, grad/param norm = 1.7355e-01, time/batch = 15.2793s	
20251/28500 (epoch 35.528), train_loss = 0.90413946, grad/param norm = 2.1901e-01, time/batch = 15.5532s	
20252/28500 (epoch 35.530), train_loss = 0.92515423, grad/param norm = 1.8276e-01, time/batch = 15.5709s	
20253/28500 (epoch 35.532), train_loss = 0.82044671, grad/param norm = 1.6402e-01, time/batch = 15.2349s	
20254/28500 (epoch 35.533), train_loss = 0.90019229, grad/param norm = 1.7240e-01, time/batch = 15.4654s	
20255/28500 (epoch 35.535), train_loss = 0.74995583, grad/param norm = 1.5282e-01, time/batch = 15.3059s	
20256/28500 (epoch 35.537), train_loss = 0.77805289, grad/param norm = 1.6877e-01, time/batch = 15.3410s	
20257/28500 (epoch 35.539), train_loss = 0.74019421, grad/param norm = 1.8239e-01, time/batch = 15.1782s	
20258/28500 (epoch 35.540), train_loss = 0.85598544, grad/param norm = 1.7455e-01, time/batch = 15.5078s	
20259/28500 (epoch 35.542), train_loss = 0.91198455, grad/param norm = 2.6450e-01, time/batch = 15.3985s	
20260/28500 (epoch 35.544), train_loss = 0.99212841, grad/param norm = 1.9346e-01, time/batch = 15.2438s	
20261/28500 (epoch 35.546), train_loss = 0.85723624, grad/param norm = 1.7991e-01, time/batch = 15.3278s	
20262/28500 (epoch 35.547), train_loss = 0.85484731, grad/param norm = 1.9562e-01, time/batch = 15.2936s	
20263/28500 (epoch 35.549), train_loss = 0.70712310, grad/param norm = 1.4064e-01, time/batch = 15.2975s	
20264/28500 (epoch 35.551), train_loss = 0.82835899, grad/param norm = 2.0634e-01, time/batch = 15.1362s	
20265/28500 (epoch 35.553), train_loss = 1.03319810, grad/param norm = 2.3473e-01, time/batch = 15.3070s	
20266/28500 (epoch 35.554), train_loss = 0.91441473, grad/param norm = 1.8531e-01, time/batch = 15.2790s	
20267/28500 (epoch 35.556), train_loss = 0.89173191, grad/param norm = 1.7764e-01, time/batch = 15.2362s	
20268/28500 (epoch 35.558), train_loss = 0.91775608, grad/param norm = 1.7871e-01, time/batch = 15.1715s	
20269/28500 (epoch 35.560), train_loss = 0.91999114, grad/param norm = 1.9115e-01, time/batch = 15.0979s	
20270/28500 (epoch 35.561), train_loss = 0.94739258, grad/param norm = 2.1686e-01, time/batch = 15.3818s	
20271/28500 (epoch 35.563), train_loss = 1.01298559, grad/param norm = 2.3686e-01, time/batch = 15.5018s	
20272/28500 (epoch 35.565), train_loss = 0.80132376, grad/param norm = 2.2165e-01, time/batch = 15.3709s	
20273/28500 (epoch 35.567), train_loss = 0.74489163, grad/param norm = 1.6626e-01, time/batch = 15.2110s	
20274/28500 (epoch 35.568), train_loss = 0.89316828, grad/param norm = 1.9291e-01, time/batch = 15.1460s	
20275/28500 (epoch 35.570), train_loss = 0.83465981, grad/param norm = 1.7850e-01, time/batch = 15.6190s	
20276/28500 (epoch 35.572), train_loss = 0.87999894, grad/param norm = 1.7835e-01, time/batch = 15.6097s	
20277/28500 (epoch 35.574), train_loss = 0.79616803, grad/param norm = 1.6174e-01, time/batch = 15.5532s	
20278/28500 (epoch 35.575), train_loss = 0.81021890, grad/param norm = 1.6580e-01, time/batch = 15.6388s	
20279/28500 (epoch 35.577), train_loss = 0.91485422, grad/param norm = 1.6669e-01, time/batch = 15.4503s	
20280/28500 (epoch 35.579), train_loss = 0.94861611, grad/param norm = 2.2187e-01, time/batch = 15.4623s	
20281/28500 (epoch 35.581), train_loss = 0.81768954, grad/param norm = 2.1145e-01, time/batch = 15.5220s	
20282/28500 (epoch 35.582), train_loss = 0.97130280, grad/param norm = 1.8582e-01, time/batch = 15.5702s	
20283/28500 (epoch 35.584), train_loss = 0.80875200, grad/param norm = 1.7305e-01, time/batch = 15.4630s	
20284/28500 (epoch 35.586), train_loss = 0.79121806, grad/param norm = 1.5540e-01, time/batch = 15.3077s	
20285/28500 (epoch 35.588), train_loss = 0.81170904, grad/param norm = 1.8535e-01, time/batch = 15.3856s	
20286/28500 (epoch 35.589), train_loss = 0.83489123, grad/param norm = 1.6890e-01, time/batch = 15.5144s	
20287/28500 (epoch 35.591), train_loss = 0.86984516, grad/param norm = 1.7618e-01, time/batch = 15.5552s	
20288/28500 (epoch 35.593), train_loss = 0.82890301, grad/param norm = 1.7471e-01, time/batch = 15.4820s	
20289/28500 (epoch 35.595), train_loss = 1.03365006, grad/param norm = 2.1023e-01, time/batch = 15.4652s	
20290/28500 (epoch 35.596), train_loss = 1.03622595, grad/param norm = 1.9514e-01, time/batch = 15.2894s	
20291/28500 (epoch 35.598), train_loss = 0.85788981, grad/param norm = 1.8230e-01, time/batch = 15.3235s	
20292/28500 (epoch 35.600), train_loss = 0.85558232, grad/param norm = 2.0956e-01, time/batch = 15.1239s	
20293/28500 (epoch 35.602), train_loss = 0.92474776, grad/param norm = 2.0730e-01, time/batch = 15.0584s	
20294/28500 (epoch 35.604), train_loss = 0.93866096, grad/param norm = 1.6436e-01, time/batch = 15.5285s	
20295/28500 (epoch 35.605), train_loss = 0.95843387, grad/param norm = 2.3680e-01, time/batch = 15.5788s	
20296/28500 (epoch 35.607), train_loss = 0.97976417, grad/param norm = 1.8232e-01, time/batch = 14.9903s	
20297/28500 (epoch 35.609), train_loss = 0.89155101, grad/param norm = 1.7712e-01, time/batch = 15.1358s	
20298/28500 (epoch 35.611), train_loss = 0.84513491, grad/param norm = 1.7770e-01, time/batch = 15.3491s	
20299/28500 (epoch 35.612), train_loss = 0.93628389, grad/param norm = 2.0071e-01, time/batch = 15.4727s	
20300/28500 (epoch 35.614), train_loss = 0.93674980, grad/param norm = 1.8423e-01, time/batch = 15.4244s	
20301/28500 (epoch 35.616), train_loss = 0.81164952, grad/param norm = 1.8120e-01, time/batch = 15.4333s	
20302/28500 (epoch 35.618), train_loss = 0.84433873, grad/param norm = 1.9618e-01, time/batch = 15.5019s	
20303/28500 (epoch 35.619), train_loss = 0.92332204, grad/param norm = 2.0851e-01, time/batch = 15.0756s	
20304/28500 (epoch 35.621), train_loss = 0.69843301, grad/param norm = 1.6126e-01, time/batch = 15.3142s	
20305/28500 (epoch 35.623), train_loss = 0.97744573, grad/param norm = 2.1406e-01, time/batch = 15.1366s	
20306/28500 (epoch 35.625), train_loss = 0.78455012, grad/param norm = 1.7562e-01, time/batch = 15.1408s	
20307/28500 (epoch 35.626), train_loss = 0.68757098, grad/param norm = 1.5818e-01, time/batch = 15.1048s	
20308/28500 (epoch 35.628), train_loss = 0.79154640, grad/param norm = 1.7044e-01, time/batch = 15.1813s	
20309/28500 (epoch 35.630), train_loss = 0.74484917, grad/param norm = 1.6520e-01, time/batch = 15.0484s	
20310/28500 (epoch 35.632), train_loss = 0.95833831, grad/param norm = 2.1311e-01, time/batch = 15.4436s	
20311/28500 (epoch 35.633), train_loss = 1.00846864, grad/param norm = 1.7568e-01, time/batch = 15.4642s	
20312/28500 (epoch 35.635), train_loss = 0.90373484, grad/param norm = 2.0100e-01, time/batch = 15.5439s	
20313/28500 (epoch 35.637), train_loss = 0.87970654, grad/param norm = 1.6109e-01, time/batch = 15.5385s	
20314/28500 (epoch 35.639), train_loss = 0.77775188, grad/param norm = 1.9555e-01, time/batch = 15.2878s	
20315/28500 (epoch 35.640), train_loss = 0.79120800, grad/param norm = 1.6295e-01, time/batch = 15.0710s	
20316/28500 (epoch 35.642), train_loss = 0.81666400, grad/param norm = 1.8026e-01, time/batch = 15.2318s	
20317/28500 (epoch 35.644), train_loss = 0.90898782, grad/param norm = 1.8948e-01, time/batch = 15.3925s	
20318/28500 (epoch 35.646), train_loss = 0.73825265, grad/param norm = 1.5273e-01, time/batch = 15.2461s	
20319/28500 (epoch 35.647), train_loss = 0.80452142, grad/param norm = 1.6418e-01, time/batch = 15.1182s	
20320/28500 (epoch 35.649), train_loss = 0.76854532, grad/param norm = 1.6654e-01, time/batch = 15.2142s	
20321/28500 (epoch 35.651), train_loss = 0.75548015, grad/param norm = 1.4863e-01, time/batch = 15.3366s	
20322/28500 (epoch 35.653), train_loss = 0.74613862, grad/param norm = 1.7266e-01, time/batch = 15.2661s	
20323/28500 (epoch 35.654), train_loss = 0.78090740, grad/param norm = 1.7982e-01, time/batch = 15.1155s	
20324/28500 (epoch 35.656), train_loss = 0.73471495, grad/param norm = 1.8044e-01, time/batch = 15.1453s	
20325/28500 (epoch 35.658), train_loss = 0.86177737, grad/param norm = 2.1454e-01, time/batch = 15.4874s	
20326/28500 (epoch 35.660), train_loss = 0.86680187, grad/param norm = 1.6393e-01, time/batch = 15.3807s	
20327/28500 (epoch 35.661), train_loss = 0.95452707, grad/param norm = 2.0987e-01, time/batch = 15.2458s	
20328/28500 (epoch 35.663), train_loss = 0.95135046, grad/param norm = 1.7623e-01, time/batch = 15.4786s	
20329/28500 (epoch 35.665), train_loss = 0.86916673, grad/param norm = 1.8970e-01, time/batch = 15.3019s	
20330/28500 (epoch 35.667), train_loss = 0.86193160, grad/param norm = 2.0494e-01, time/batch = 15.1926s	
20331/28500 (epoch 35.668), train_loss = 0.86186086, grad/param norm = 1.7544e-01, time/batch = 15.2238s	
20332/28500 (epoch 35.670), train_loss = 0.84907661, grad/param norm = 1.6840e-01, time/batch = 15.1278s	
20333/28500 (epoch 35.672), train_loss = 0.76429214, grad/param norm = 1.7236e-01, time/batch = 15.4558s	
20334/28500 (epoch 35.674), train_loss = 0.66520763, grad/param norm = 1.5755e-01, time/batch = 15.5522s	
20335/28500 (epoch 35.675), train_loss = 0.71444161, grad/param norm = 1.6167e-01, time/batch = 15.4181s	
20336/28500 (epoch 35.677), train_loss = 0.79529442, grad/param norm = 1.5600e-01, time/batch = 15.2927s	
20337/28500 (epoch 35.679), train_loss = 0.81815692, grad/param norm = 1.8104e-01, time/batch = 15.3820s	
20338/28500 (epoch 35.681), train_loss = 0.87779039, grad/param norm = 1.8563e-01, time/batch = 15.3545s	
20339/28500 (epoch 35.682), train_loss = 0.80361872, grad/param norm = 1.7784e-01, time/batch = 15.0009s	
20340/28500 (epoch 35.684), train_loss = 0.87623010, grad/param norm = 2.2210e-01, time/batch = 15.1299s	
20341/28500 (epoch 35.686), train_loss = 0.79920687, grad/param norm = 1.8555e-01, time/batch = 15.3985s	
20342/28500 (epoch 35.688), train_loss = 0.78689313, grad/param norm = 1.4298e-01, time/batch = 15.2716s	
20343/28500 (epoch 35.689), train_loss = 0.80751002, grad/param norm = 2.0378e-01, time/batch = 14.9823s	
20344/28500 (epoch 35.691), train_loss = 0.89253062, grad/param norm = 1.7470e-01, time/batch = 15.1701s	
20345/28500 (epoch 35.693), train_loss = 0.81840014, grad/param norm = 1.7875e-01, time/batch = 15.3786s	
20346/28500 (epoch 35.695), train_loss = 0.64434228, grad/param norm = 1.7061e-01, time/batch = 15.2901s	
20347/28500 (epoch 35.696), train_loss = 0.82414276, grad/param norm = 1.6747e-01, time/batch = 15.3017s	
20348/28500 (epoch 35.698), train_loss = 0.89756058, grad/param norm = 1.9390e-01, time/batch = 15.2908s	
20349/28500 (epoch 35.700), train_loss = 0.87842608, grad/param norm = 1.9330e-01, time/batch = 15.1784s	
20350/28500 (epoch 35.702), train_loss = 0.85015647, grad/param norm = 2.0847e-01, time/batch = 15.2708s	
20351/28500 (epoch 35.704), train_loss = 0.90665504, grad/param norm = 2.0378e-01, time/batch = 15.4748s	
20352/28500 (epoch 35.705), train_loss = 0.91975335, grad/param norm = 1.9516e-01, time/batch = 15.4487s	
20353/28500 (epoch 35.707), train_loss = 0.79277787, grad/param norm = 1.9493e-01, time/batch = 15.4536s	
20354/28500 (epoch 35.709), train_loss = 0.99062500, grad/param norm = 2.1281e-01, time/batch = 15.3010s	
20355/28500 (epoch 35.711), train_loss = 0.79552954, grad/param norm = 1.8257e-01, time/batch = 15.0630s	
20356/28500 (epoch 35.712), train_loss = 0.88090184, grad/param norm = 1.9203e-01, time/batch = 15.3619s	
20357/28500 (epoch 35.714), train_loss = 0.97923606, grad/param norm = 2.5546e-01, time/batch = 15.5338s	
20358/28500 (epoch 35.716), train_loss = 0.84201347, grad/param norm = 1.7501e-01, time/batch = 15.3255s	
20359/28500 (epoch 35.718), train_loss = 0.86318039, grad/param norm = 1.8638e-01, time/batch = 15.3029s	
20360/28500 (epoch 35.719), train_loss = 0.87209247, grad/param norm = 1.7938e-01, time/batch = 15.4618s	
20361/28500 (epoch 35.721), train_loss = 0.67508332, grad/param norm = 1.7956e-01, time/batch = 15.6749s	
20362/28500 (epoch 35.723), train_loss = 0.85962645, grad/param norm = 1.8160e-01, time/batch = 15.1097s	
20363/28500 (epoch 35.725), train_loss = 0.92137242, grad/param norm = 1.8017e-01, time/batch = 15.1462s	
20364/28500 (epoch 35.726), train_loss = 0.86129908, grad/param norm = 2.0129e-01, time/batch = 15.1372s	
20365/28500 (epoch 35.728), train_loss = 0.76581896, grad/param norm = 1.6993e-01, time/batch = 15.3911s	
20366/28500 (epoch 35.730), train_loss = 0.87506299, grad/param norm = 2.1611e-01, time/batch = 15.3663s	
20367/28500 (epoch 35.732), train_loss = 0.68612842, grad/param norm = 1.5205e-01, time/batch = 15.1335s	
20368/28500 (epoch 35.733), train_loss = 0.71894976, grad/param norm = 1.9329e-01, time/batch = 15.4245s	
20369/28500 (epoch 35.735), train_loss = 0.72636087, grad/param norm = 1.6302e-01, time/batch = 15.3000s	
20370/28500 (epoch 35.737), train_loss = 0.65963737, grad/param norm = 1.5719e-01, time/batch = 15.4367s	
20371/28500 (epoch 35.739), train_loss = 0.77064007, grad/param norm = 1.8685e-01, time/batch = 15.4761s	
20372/28500 (epoch 35.740), train_loss = 0.85011823, grad/param norm = 1.7800e-01, time/batch = 15.3798s	
20373/28500 (epoch 35.742), train_loss = 0.75686801, grad/param norm = 1.7716e-01, time/batch = 15.4601s	
20374/28500 (epoch 35.744), train_loss = 0.84450416, grad/param norm = 1.7158e-01, time/batch = 15.5155s	
20375/28500 (epoch 35.746), train_loss = 0.79267725, grad/param norm = 1.6131e-01, time/batch = 15.4944s	
20376/28500 (epoch 35.747), train_loss = 0.78694052, grad/param norm = 1.5353e-01, time/batch = 15.3405s	
20377/28500 (epoch 35.749), train_loss = 0.93341852, grad/param norm = 2.2350e-01, time/batch = 15.1501s	
20378/28500 (epoch 35.751), train_loss = 0.75812282, grad/param norm = 2.2010e-01, time/batch = 15.1389s	
20379/28500 (epoch 35.753), train_loss = 0.82746580, grad/param norm = 1.4766e-01, time/batch = 14.9890s	
20380/28500 (epoch 35.754), train_loss = 0.74881021, grad/param norm = 1.7274e-01, time/batch = 15.5717s	
20381/28500 (epoch 35.756), train_loss = 0.95158633, grad/param norm = 1.9772e-01, time/batch = 15.6025s	
20382/28500 (epoch 35.758), train_loss = 0.90116833, grad/param norm = 2.1504e-01, time/batch = 15.5797s	
20383/28500 (epoch 35.760), train_loss = 0.74798721, grad/param norm = 1.8486e-01, time/batch = 15.3580s	
20384/28500 (epoch 35.761), train_loss = 0.77094386, grad/param norm = 1.9300e-01, time/batch = 15.4674s	
20385/28500 (epoch 35.763), train_loss = 0.66878037, grad/param norm = 1.5572e-01, time/batch = 15.4069s	
20386/28500 (epoch 35.765), train_loss = 0.82153129, grad/param norm = 1.6771e-01, time/batch = 15.2401s	
20387/28500 (epoch 35.767), train_loss = 0.69224594, grad/param norm = 1.4406e-01, time/batch = 15.2086s	
20388/28500 (epoch 35.768), train_loss = 0.88018589, grad/param norm = 1.8053e-01, time/batch = 15.4076s	
20389/28500 (epoch 35.770), train_loss = 0.73978544, grad/param norm = 1.5832e-01, time/batch = 15.1079s	
20390/28500 (epoch 35.772), train_loss = 0.66838519, grad/param norm = 1.4431e-01, time/batch = 15.1271s	
20391/28500 (epoch 35.774), train_loss = 0.84184317, grad/param norm = 1.6401e-01, time/batch = 15.4498s	
20392/28500 (epoch 35.775), train_loss = 0.88642058, grad/param norm = 1.5679e-01, time/batch = 15.2993s	
20393/28500 (epoch 35.777), train_loss = 0.89287748, grad/param norm = 1.7032e-01, time/batch = 15.6252s	
20394/28500 (epoch 35.779), train_loss = 0.67354477, grad/param norm = 1.2870e-01, time/batch = 15.6444s	
20395/28500 (epoch 35.781), train_loss = 0.83556196, grad/param norm = 2.0812e-01, time/batch = 15.3032s	
20396/28500 (epoch 35.782), train_loss = 0.85968631, grad/param norm = 1.9791e-01, time/batch = 15.2913s	
20397/28500 (epoch 35.784), train_loss = 0.66586542, grad/param norm = 1.5276e-01, time/batch = 15.3001s	
20398/28500 (epoch 35.786), train_loss = 0.69280330, grad/param norm = 1.4904e-01, time/batch = 15.5522s	
20399/28500 (epoch 35.788), train_loss = 0.79161487, grad/param norm = 2.0843e-01, time/batch = 20.5813s	
20400/28500 (epoch 35.789), train_loss = 0.61688328, grad/param norm = 1.7209e-01, time/batch = 22.5531s	
20401/28500 (epoch 35.791), train_loss = 0.85911682, grad/param norm = 1.8869e-01, time/batch = 15.3282s	
20402/28500 (epoch 35.793), train_loss = 0.83610789, grad/param norm = 1.8147e-01, time/batch = 15.2048s	
20403/28500 (epoch 35.795), train_loss = 0.83029121, grad/param norm = 1.7226e-01, time/batch = 15.2731s	
20404/28500 (epoch 35.796), train_loss = 0.73089382, grad/param norm = 1.4852e-01, time/batch = 15.4087s	
20405/28500 (epoch 35.798), train_loss = 0.69203142, grad/param norm = 1.8155e-01, time/batch = 15.1412s	
20406/28500 (epoch 35.800), train_loss = 0.69827451, grad/param norm = 1.9838e-01, time/batch = 14.9773s	
20407/28500 (epoch 35.802), train_loss = 0.78720236, grad/param norm = 2.1966e-01, time/batch = 14.9780s	
20408/28500 (epoch 35.804), train_loss = 0.86156378, grad/param norm = 1.6488e-01, time/batch = 14.9753s	
20409/28500 (epoch 35.805), train_loss = 0.83346399, grad/param norm = 1.8189e-01, time/batch = 14.9571s	
20410/28500 (epoch 35.807), train_loss = 0.85335355, grad/param norm = 1.9736e-01, time/batch = 15.1032s	
20411/28500 (epoch 35.809), train_loss = 0.82844436, grad/param norm = 1.9065e-01, time/batch = 15.3046s	
20412/28500 (epoch 35.811), train_loss = 0.86282883, grad/param norm = 1.8341e-01, time/batch = 15.1387s	
20413/28500 (epoch 35.812), train_loss = 0.83781891, grad/param norm = 1.9689e-01, time/batch = 15.2887s	
20414/28500 (epoch 35.814), train_loss = 0.77208181, grad/param norm = 1.8591e-01, time/batch = 15.2587s	
20415/28500 (epoch 35.816), train_loss = 0.85736904, grad/param norm = 1.8506e-01, time/batch = 15.1884s	
20416/28500 (epoch 35.818), train_loss = 0.95537117, grad/param norm = 1.8297e-01, time/batch = 15.0643s	
20417/28500 (epoch 35.819), train_loss = 0.81955894, grad/param norm = 1.7011e-01, time/batch = 15.2853s	
20418/28500 (epoch 35.821), train_loss = 0.79401594, grad/param norm = 1.6715e-01, time/batch = 15.3063s	
20419/28500 (epoch 35.823), train_loss = 0.93194189, grad/param norm = 2.0569e-01, time/batch = 15.4885s	
20420/28500 (epoch 35.825), train_loss = 0.77594033, grad/param norm = 2.1283e-01, time/batch = 15.5510s	
20421/28500 (epoch 35.826), train_loss = 0.85030801, grad/param norm = 1.8865e-01, time/batch = 15.6816s	
20422/28500 (epoch 35.828), train_loss = 0.76408357, grad/param norm = 1.8977e-01, time/batch = 15.6951s	
20423/28500 (epoch 35.830), train_loss = 0.79620759, grad/param norm = 1.5796e-01, time/batch = 15.6009s	
20424/28500 (epoch 35.832), train_loss = 0.82625420, grad/param norm = 2.1445e-01, time/batch = 15.6301s	
20425/28500 (epoch 35.833), train_loss = 0.88432721, grad/param norm = 1.6891e-01, time/batch = 15.5523s	
20426/28500 (epoch 35.835), train_loss = 0.77736429, grad/param norm = 1.9933e-01, time/batch = 15.2804s	
20427/28500 (epoch 35.837), train_loss = 0.71871854, grad/param norm = 2.0201e-01, time/batch = 15.3718s	
20428/28500 (epoch 35.839), train_loss = 0.96466614, grad/param norm = 2.8667e-01, time/batch = 15.2096s	
20429/28500 (epoch 35.840), train_loss = 0.97773833, grad/param norm = 2.0011e-01, time/batch = 15.2879s	
20430/28500 (epoch 35.842), train_loss = 0.88662920, grad/param norm = 2.2312e-01, time/batch = 15.3865s	
20431/28500 (epoch 35.844), train_loss = 0.90276185, grad/param norm = 2.1274e-01, time/batch = 15.4538s	
20432/28500 (epoch 35.846), train_loss = 1.00109051, grad/param norm = 2.4146e-01, time/batch = 15.3037s	
20433/28500 (epoch 35.847), train_loss = 0.78763476, grad/param norm = 1.9822e-01, time/batch = 15.3636s	
20434/28500 (epoch 35.849), train_loss = 0.79294687, grad/param norm = 1.6136e-01, time/batch = 15.5584s	
20435/28500 (epoch 35.851), train_loss = 0.73803486, grad/param norm = 1.6478e-01, time/batch = 15.5388s	
20436/28500 (epoch 35.853), train_loss = 0.86195006, grad/param norm = 2.0127e-01, time/batch = 15.5496s	
20437/28500 (epoch 35.854), train_loss = 0.85233143, grad/param norm = 1.9538e-01, time/batch = 15.5944s	
20438/28500 (epoch 35.856), train_loss = 0.96370138, grad/param norm = 3.0901e-01, time/batch = 15.5041s	
20439/28500 (epoch 35.858), train_loss = 0.80670825, grad/param norm = 1.8893e-01, time/batch = 15.3749s	
20440/28500 (epoch 35.860), train_loss = 0.82541265, grad/param norm = 1.8481e-01, time/batch = 15.4339s	
20441/28500 (epoch 35.861), train_loss = 0.93130369, grad/param norm = 2.1718e-01, time/batch = 15.5727s	
20442/28500 (epoch 35.863), train_loss = 0.86969277, grad/param norm = 2.3237e-01, time/batch = 15.4639s	
20443/28500 (epoch 35.865), train_loss = 0.77434090, grad/param norm = 1.8500e-01, time/batch = 15.3894s	
20444/28500 (epoch 35.867), train_loss = 0.87551375, grad/param norm = 2.0280e-01, time/batch = 15.4845s	
20445/28500 (epoch 35.868), train_loss = 0.75381849, grad/param norm = 1.6538e-01, time/batch = 15.5348s	
20446/28500 (epoch 35.870), train_loss = 0.72336808, grad/param norm = 1.5587e-01, time/batch = 15.6190s	
20447/28500 (epoch 35.872), train_loss = 0.90260732, grad/param norm = 2.1638e-01, time/batch = 15.2657s	
20448/28500 (epoch 35.874), train_loss = 0.75976633, grad/param norm = 1.8510e-01, time/batch = 15.2005s	
20449/28500 (epoch 35.875), train_loss = 0.97932581, grad/param norm = 2.2218e-01, time/batch = 15.4541s	
20450/28500 (epoch 35.877), train_loss = 0.86899009, grad/param norm = 1.8429e-01, time/batch = 15.3070s	
20451/28500 (epoch 35.879), train_loss = 0.89251126, grad/param norm = 1.6173e-01, time/batch = 15.4782s	
20452/28500 (epoch 35.881), train_loss = 0.88124676, grad/param norm = 1.8397e-01, time/batch = 15.3838s	
20453/28500 (epoch 35.882), train_loss = 0.77850080, grad/param norm = 1.6406e-01, time/batch = 15.4417s	
20454/28500 (epoch 35.884), train_loss = 0.82002211, grad/param norm = 1.8556e-01, time/batch = 15.5093s	
20455/28500 (epoch 35.886), train_loss = 0.79158593, grad/param norm = 1.8173e-01, time/batch = 15.5299s	
20456/28500 (epoch 35.888), train_loss = 0.79994565, grad/param norm = 1.6896e-01, time/batch = 15.7018s	
20457/28500 (epoch 35.889), train_loss = 0.84903958, grad/param norm = 1.6501e-01, time/batch = 15.2867s	
20458/28500 (epoch 35.891), train_loss = 0.84085828, grad/param norm = 1.7102e-01, time/batch = 15.3095s	
20459/28500 (epoch 35.893), train_loss = 0.79407237, grad/param norm = 1.9355e-01, time/batch = 15.3823s	
20460/28500 (epoch 35.895), train_loss = 0.98196623, grad/param norm = 2.4436e-01, time/batch = 15.5810s	
20461/28500 (epoch 35.896), train_loss = 0.92947180, grad/param norm = 1.9694e-01, time/batch = 15.6577s	
20462/28500 (epoch 35.898), train_loss = 0.85810211, grad/param norm = 1.7433e-01, time/batch = 15.4568s	
20463/28500 (epoch 35.900), train_loss = 0.73157112, grad/param norm = 1.9469e-01, time/batch = 15.3434s	
20464/28500 (epoch 35.902), train_loss = 0.71362912, grad/param norm = 1.8073e-01, time/batch = 15.5425s	
20465/28500 (epoch 35.904), train_loss = 0.74137542, grad/param norm = 1.6295e-01, time/batch = 15.4212s	
20466/28500 (epoch 35.905), train_loss = 0.79363163, grad/param norm = 1.8823e-01, time/batch = 15.4834s	
20467/28500 (epoch 35.907), train_loss = 0.83650516, grad/param norm = 1.9633e-01, time/batch = 15.4671s	
20468/28500 (epoch 35.909), train_loss = 0.69605235, grad/param norm = 2.2236e-01, time/batch = 15.3252s	
20469/28500 (epoch 35.911), train_loss = 0.75959357, grad/param norm = 1.5927e-01, time/batch = 15.2284s	
20470/28500 (epoch 35.912), train_loss = 0.64040323, grad/param norm = 1.7085e-01, time/batch = 15.4040s	
20471/28500 (epoch 35.914), train_loss = 0.84142397, grad/param norm = 1.8380e-01, time/batch = 15.5412s	
20472/28500 (epoch 35.916), train_loss = 0.84492968, grad/param norm = 1.7308e-01, time/batch = 15.2499s	
20473/28500 (epoch 35.918), train_loss = 0.82310576, grad/param norm = 1.9773e-01, time/batch = 15.1207s	
20474/28500 (epoch 35.919), train_loss = 0.83253804, grad/param norm = 1.5278e-01, time/batch = 15.4873s	
20475/28500 (epoch 35.921), train_loss = 0.91998688, grad/param norm = 1.9176e-01, time/batch = 15.4937s	
20476/28500 (epoch 35.923), train_loss = 0.79696317, grad/param norm = 2.1039e-01, time/batch = 15.4851s	
20477/28500 (epoch 35.925), train_loss = 0.78582743, grad/param norm = 2.1967e-01, time/batch = 15.1514s	
20478/28500 (epoch 35.926), train_loss = 0.84730917, grad/param norm = 1.8291e-01, time/batch = 15.2773s	
20479/28500 (epoch 35.928), train_loss = 0.78963552, grad/param norm = 1.6362e-01, time/batch = 15.2663s	
20480/28500 (epoch 35.930), train_loss = 0.64886186, grad/param norm = 1.4448e-01, time/batch = 15.4334s	
20481/28500 (epoch 35.932), train_loss = 0.67659352, grad/param norm = 1.4469e-01, time/batch = 15.2445s	
20482/28500 (epoch 35.933), train_loss = 0.89327329, grad/param norm = 1.8834e-01, time/batch = 15.4007s	
20483/28500 (epoch 35.935), train_loss = 0.91095183, grad/param norm = 1.7349e-01, time/batch = 15.2327s	
20484/28500 (epoch 35.937), train_loss = 0.92446205, grad/param norm = 2.2432e-01, time/batch = 15.2935s	
20485/28500 (epoch 35.939), train_loss = 0.95755239, grad/param norm = 2.0984e-01, time/batch = 15.4330s	
20486/28500 (epoch 35.940), train_loss = 0.71582148, grad/param norm = 1.8335e-01, time/batch = 15.4598s	
20487/28500 (epoch 35.942), train_loss = 0.82697250, grad/param norm = 1.8180e-01, time/batch = 15.4630s	
20488/28500 (epoch 35.944), train_loss = 0.80177372, grad/param norm = 1.8422e-01, time/batch = 15.3934s	
20489/28500 (epoch 35.946), train_loss = 0.89507885, grad/param norm = 1.7740e-01, time/batch = 15.0436s	
20490/28500 (epoch 35.947), train_loss = 1.05611786, grad/param norm = 2.3040e-01, time/batch = 15.0516s	
20491/28500 (epoch 35.949), train_loss = 0.81130262, grad/param norm = 1.9735e-01, time/batch = 15.1373s	
20492/28500 (epoch 35.951), train_loss = 0.98169548, grad/param norm = 1.9032e-01, time/batch = 15.3459s	
20493/28500 (epoch 35.953), train_loss = 1.00335883, grad/param norm = 2.3374e-01, time/batch = 15.2412s	
20494/28500 (epoch 35.954), train_loss = 0.93096476, grad/param norm = 2.1547e-01, time/batch = 15.1636s	
20495/28500 (epoch 35.956), train_loss = 0.86022200, grad/param norm = 2.5928e-01, time/batch = 15.5118s	
20496/28500 (epoch 35.958), train_loss = 1.07795194, grad/param norm = 2.0889e-01, time/batch = 15.3552s	
20497/28500 (epoch 35.960), train_loss = 0.77716287, grad/param norm = 1.8966e-01, time/batch = 15.2870s	
20498/28500 (epoch 35.961), train_loss = 0.99832114, grad/param norm = 2.1973e-01, time/batch = 15.1355s	
20499/28500 (epoch 35.963), train_loss = 0.92649413, grad/param norm = 2.0149e-01, time/batch = 15.1634s	
20500/28500 (epoch 35.965), train_loss = 0.78028759, grad/param norm = 1.7644e-01, time/batch = 15.2946s	
20501/28500 (epoch 35.967), train_loss = 0.79340350, grad/param norm = 1.9997e-01, time/batch = 15.3077s	
20502/28500 (epoch 35.968), train_loss = 0.73635181, grad/param norm = 1.7736e-01, time/batch = 15.5996s	
20503/28500 (epoch 35.970), train_loss = 0.79875120, grad/param norm = 2.2219e-01, time/batch = 15.5562s	
20504/28500 (epoch 35.972), train_loss = 0.85641229, grad/param norm = 2.0156e-01, time/batch = 15.5442s	
20505/28500 (epoch 35.974), train_loss = 1.03192667, grad/param norm = 2.2438e-01, time/batch = 15.4283s	
20506/28500 (epoch 35.975), train_loss = 0.80206594, grad/param norm = 2.0879e-01, time/batch = 15.2165s	
20507/28500 (epoch 35.977), train_loss = 0.94819359, grad/param norm = 2.2031e-01, time/batch = 15.4758s	
20508/28500 (epoch 35.979), train_loss = 0.86412398, grad/param norm = 1.7872e-01, time/batch = 15.5002s	
20509/28500 (epoch 35.981), train_loss = 0.73072502, grad/param norm = 1.7600e-01, time/batch = 15.1570s	
20510/28500 (epoch 35.982), train_loss = 0.82501935, grad/param norm = 1.8910e-01, time/batch = 15.2073s	
20511/28500 (epoch 35.984), train_loss = 0.91147201, grad/param norm = 1.7816e-01, time/batch = 15.3946s	
20512/28500 (epoch 35.986), train_loss = 1.08615128, grad/param norm = 2.0589e-01, time/batch = 15.3928s	
20513/28500 (epoch 35.988), train_loss = 0.76297462, grad/param norm = 1.7457e-01, time/batch = 15.6197s	
20514/28500 (epoch 35.989), train_loss = 0.86267434, grad/param norm = 1.9574e-01, time/batch = 15.5582s	
20515/28500 (epoch 35.991), train_loss = 0.77527412, grad/param norm = 1.8332e-01, time/batch = 15.4359s	
20516/28500 (epoch 35.993), train_loss = 0.76000477, grad/param norm = 1.9843e-01, time/batch = 15.3078s	
20517/28500 (epoch 35.995), train_loss = 0.81045361, grad/param norm = 2.0012e-01, time/batch = 15.3667s	
20518/28500 (epoch 35.996), train_loss = 0.74187126, grad/param norm = 1.9502e-01, time/batch = 15.4907s	
20519/28500 (epoch 35.998), train_loss = 0.94277547, grad/param norm = 2.3899e-01, time/batch = 15.2565s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
20520/28500 (epoch 36.000), train_loss = 0.83171440, grad/param norm = 2.0683e-01, time/batch = 15.2692s	
20521/28500 (epoch 36.002), train_loss = 1.00698867, grad/param norm = 1.9252e-01, time/batch = 15.5542s	
20522/28500 (epoch 36.004), train_loss = 0.82547886, grad/param norm = 1.6011e-01, time/batch = 15.3716s	
20523/28500 (epoch 36.005), train_loss = 0.96039270, grad/param norm = 2.1563e-01, time/batch = 15.3861s	
20524/28500 (epoch 36.007), train_loss = 0.74660427, grad/param norm = 1.4563e-01, time/batch = 15.3094s	
20525/28500 (epoch 36.009), train_loss = 0.85926913, grad/param norm = 1.7002e-01, time/batch = 15.3764s	
20526/28500 (epoch 36.011), train_loss = 0.76679112, grad/param norm = 1.7166e-01, time/batch = 15.4745s	
20527/28500 (epoch 36.012), train_loss = 0.76257405, grad/param norm = 1.6972e-01, time/batch = 15.4485s	
20528/28500 (epoch 36.014), train_loss = 0.74049694, grad/param norm = 1.6617e-01, time/batch = 15.5617s	
20529/28500 (epoch 36.016), train_loss = 0.81114740, grad/param norm = 1.8459e-01, time/batch = 15.3885s	
20530/28500 (epoch 36.018), train_loss = 0.88040836, grad/param norm = 1.8283e-01, time/batch = 15.1809s	
20531/28500 (epoch 36.019), train_loss = 0.91635264, grad/param norm = 1.7613e-01, time/batch = 15.4561s	
20532/28500 (epoch 36.021), train_loss = 0.95199866, grad/param norm = 1.7347e-01, time/batch = 15.3989s	
20533/28500 (epoch 36.023), train_loss = 0.87056871, grad/param norm = 1.9238e-01, time/batch = 15.4638s	
20534/28500 (epoch 36.025), train_loss = 0.86179746, grad/param norm = 1.9776e-01, time/batch = 15.4918s	
20535/28500 (epoch 36.026), train_loss = 0.82414361, grad/param norm = 1.8874e-01, time/batch = 15.3870s	
20536/28500 (epoch 36.028), train_loss = 0.85571300, grad/param norm = 1.9261e-01, time/batch = 15.2597s	
20537/28500 (epoch 36.030), train_loss = 0.88974526, grad/param norm = 1.9932e-01, time/batch = 15.1173s	
20538/28500 (epoch 36.032), train_loss = 0.94764640, grad/param norm = 2.1450e-01, time/batch = 15.1333s	
20539/28500 (epoch 36.033), train_loss = 0.99799287, grad/param norm = 2.0295e-01, time/batch = 15.1068s	
20540/28500 (epoch 36.035), train_loss = 0.81752024, grad/param norm = 1.8154e-01, time/batch = 15.2262s	
20541/28500 (epoch 36.037), train_loss = 0.91124549, grad/param norm = 1.7997e-01, time/batch = 15.5461s	
20542/28500 (epoch 36.039), train_loss = 0.96899402, grad/param norm = 2.1733e-01, time/batch = 15.5210s	
20543/28500 (epoch 36.040), train_loss = 0.98823258, grad/param norm = 1.9447e-01, time/batch = 15.4258s	
20544/28500 (epoch 36.042), train_loss = 0.91935970, grad/param norm = 1.9999e-01, time/batch = 15.3128s	
20545/28500 (epoch 36.044), train_loss = 0.85993542, grad/param norm = 1.9326e-01, time/batch = 15.2845s	
20546/28500 (epoch 36.046), train_loss = 1.05487398, grad/param norm = 2.0047e-01, time/batch = 15.5567s	
20547/28500 (epoch 36.047), train_loss = 1.00623436, grad/param norm = 2.2558e-01, time/batch = 15.5532s	
20548/28500 (epoch 36.049), train_loss = 0.85183179, grad/param norm = 1.7390e-01, time/batch = 15.4157s	
20549/28500 (epoch 36.051), train_loss = 0.86969572, grad/param norm = 2.0647e-01, time/batch = 15.2114s	
20550/28500 (epoch 36.053), train_loss = 0.82601449, grad/param norm = 1.8473e-01, time/batch = 15.4369s	
20551/28500 (epoch 36.054), train_loss = 0.93102448, grad/param norm = 1.8023e-01, time/batch = 15.2963s	
20552/28500 (epoch 36.056), train_loss = 0.78690617, grad/param norm = 1.7175e-01, time/batch = 15.4586s	
20553/28500 (epoch 36.058), train_loss = 0.79250206, grad/param norm = 1.7453e-01, time/batch = 15.0544s	
20554/28500 (epoch 36.060), train_loss = 0.90287838, grad/param norm = 1.8343e-01, time/batch = 15.1391s	
20555/28500 (epoch 36.061), train_loss = 0.82936374, grad/param norm = 1.9242e-01, time/batch = 15.2309s	
20556/28500 (epoch 36.063), train_loss = 0.90961109, grad/param norm = 2.0286e-01, time/batch = 15.3196s	
20557/28500 (epoch 36.065), train_loss = 0.87048771, grad/param norm = 2.0198e-01, time/batch = 15.2940s	
20558/28500 (epoch 36.067), train_loss = 0.80793306, grad/param norm = 1.8247e-01, time/batch = 15.5000s	
20559/28500 (epoch 36.068), train_loss = 0.82400639, grad/param norm = 1.7146e-01, time/batch = 15.4372s	
20560/28500 (epoch 36.070), train_loss = 0.90356955, grad/param norm = 2.1028e-01, time/batch = 15.3001s	
20561/28500 (epoch 36.072), train_loss = 0.99269832, grad/param norm = 2.0586e-01, time/batch = 15.5618s	
20562/28500 (epoch 36.074), train_loss = 0.84160108, grad/param norm = 1.6740e-01, time/batch = 15.4848s	
20563/28500 (epoch 36.075), train_loss = 0.83304612, grad/param norm = 1.6215e-01, time/batch = 15.4576s	
20564/28500 (epoch 36.077), train_loss = 0.89688300, grad/param norm = 1.7296e-01, time/batch = 15.5543s	
20565/28500 (epoch 36.079), train_loss = 0.86027453, grad/param norm = 1.6661e-01, time/batch = 15.5331s	
20566/28500 (epoch 36.081), train_loss = 0.96005682, grad/param norm = 2.2032e-01, time/batch = 15.4731s	
20567/28500 (epoch 36.082), train_loss = 0.86786654, grad/param norm = 2.2594e-01, time/batch = 15.2411s	
20568/28500 (epoch 36.084), train_loss = 0.88284069, grad/param norm = 1.8884e-01, time/batch = 15.4033s	
20569/28500 (epoch 36.086), train_loss = 0.84888318, grad/param norm = 2.4040e-01, time/batch = 15.3416s	
20570/28500 (epoch 36.088), train_loss = 0.77679536, grad/param norm = 1.8690e-01, time/batch = 15.2975s	
20571/28500 (epoch 36.089), train_loss = 0.94267219, grad/param norm = 1.9353e-01, time/batch = 15.3983s	
20572/28500 (epoch 36.091), train_loss = 0.76037694, grad/param norm = 1.7234e-01, time/batch = 15.5476s	
20573/28500 (epoch 36.093), train_loss = 0.94549695, grad/param norm = 1.8035e-01, time/batch = 15.4312s	
20574/28500 (epoch 36.095), train_loss = 0.86797348, grad/param norm = 1.8011e-01, time/batch = 15.4938s	
20575/28500 (epoch 36.096), train_loss = 0.93581996, grad/param norm = 1.8562e-01, time/batch = 15.2966s	
20576/28500 (epoch 36.098), train_loss = 0.87317445, grad/param norm = 1.9483e-01, time/batch = 15.3092s	
20577/28500 (epoch 36.100), train_loss = 0.82811409, grad/param norm = 1.6964e-01, time/batch = 15.3568s	
20578/28500 (epoch 36.102), train_loss = 0.94219675, grad/param norm = 2.2961e-01, time/batch = 15.5484s	
20579/28500 (epoch 36.104), train_loss = 0.87622921, grad/param norm = 1.8394e-01, time/batch = 15.3742s	
20580/28500 (epoch 36.105), train_loss = 0.96942337, grad/param norm = 1.7702e-01, time/batch = 15.4355s	
20581/28500 (epoch 36.107), train_loss = 0.78877885, grad/param norm = 1.8511e-01, time/batch = 15.3073s	
20582/28500 (epoch 36.109), train_loss = 0.81772024, grad/param norm = 1.9104e-01, time/batch = 15.2222s	
20583/28500 (epoch 36.111), train_loss = 0.84286510, grad/param norm = 2.1187e-01, time/batch = 15.2328s	
20584/28500 (epoch 36.112), train_loss = 0.93348008, grad/param norm = 1.9763e-01, time/batch = 15.2939s	
20585/28500 (epoch 36.114), train_loss = 0.84019200, grad/param norm = 1.8263e-01, time/batch = 15.3085s	
20586/28500 (epoch 36.116), train_loss = 1.01178127, grad/param norm = 1.9720e-01, time/batch = 15.2808s	
20587/28500 (epoch 36.118), train_loss = 0.77165174, grad/param norm = 1.7816e-01, time/batch = 15.1163s	
20588/28500 (epoch 36.119), train_loss = 0.87225445, grad/param norm = 1.7742e-01, time/batch = 15.2431s	
20589/28500 (epoch 36.121), train_loss = 1.02416543, grad/param norm = 2.2033e-01, time/batch = 15.4551s	
20590/28500 (epoch 36.123), train_loss = 0.96042385, grad/param norm = 1.9021e-01, time/batch = 15.2964s	
20591/28500 (epoch 36.125), train_loss = 0.88878569, grad/param norm = 1.9175e-01, time/batch = 15.4685s	
20592/28500 (epoch 36.126), train_loss = 0.85122881, grad/param norm = 1.8868e-01, time/batch = 15.3805s	
20593/28500 (epoch 36.128), train_loss = 0.87706065, grad/param norm = 1.8999e-01, time/batch = 15.5037s	
20594/28500 (epoch 36.130), train_loss = 0.81531229, grad/param norm = 1.8254e-01, time/batch = 15.2852s	
20595/28500 (epoch 36.132), train_loss = 0.86589106, grad/param norm = 1.9253e-01, time/batch = 15.3097s	
20596/28500 (epoch 36.133), train_loss = 0.91893430, grad/param norm = 2.3509e-01, time/batch = 15.5466s	
20597/28500 (epoch 36.135), train_loss = 0.83329146, grad/param norm = 1.7863e-01, time/batch = 15.6392s	
20598/28500 (epoch 36.137), train_loss = 0.88012599, grad/param norm = 1.8213e-01, time/batch = 15.4488s	
20599/28500 (epoch 36.139), train_loss = 0.88478561, grad/param norm = 1.7928e-01, time/batch = 15.3085s	
20600/28500 (epoch 36.140), train_loss = 0.86619499, grad/param norm = 1.7626e-01, time/batch = 15.3749s	
20601/28500 (epoch 36.142), train_loss = 0.81686059, grad/param norm = 1.8958e-01, time/batch = 15.7129s	
20602/28500 (epoch 36.144), train_loss = 0.79561483, grad/param norm = 1.9693e-01, time/batch = 15.4794s	
20603/28500 (epoch 36.146), train_loss = 0.85042714, grad/param norm = 1.8063e-01, time/batch = 15.1557s	
20604/28500 (epoch 36.147), train_loss = 0.74333471, grad/param norm = 1.6980e-01, time/batch = 15.4865s	
20605/28500 (epoch 36.149), train_loss = 0.74194162, grad/param norm = 1.6310e-01, time/batch = 15.5192s	
20606/28500 (epoch 36.151), train_loss = 0.83525462, grad/param norm = 1.7488e-01, time/batch = 15.5402s	
20607/28500 (epoch 36.153), train_loss = 0.87843943, grad/param norm = 1.7379e-01, time/batch = 15.3807s	
20608/28500 (epoch 36.154), train_loss = 0.73449890, grad/param norm = 1.5408e-01, time/batch = 15.5595s	
20609/28500 (epoch 36.156), train_loss = 0.91770839, grad/param norm = 1.8132e-01, time/batch = 15.3411s	
20610/28500 (epoch 36.158), train_loss = 0.87291380, grad/param norm = 1.7677e-01, time/batch = 15.1321s	
20611/28500 (epoch 36.160), train_loss = 0.76304621, grad/param norm = 1.4927e-01, time/batch = 15.3992s	
20612/28500 (epoch 36.161), train_loss = 0.79821637, grad/param norm = 1.8234e-01, time/batch = 15.5331s	
20613/28500 (epoch 36.163), train_loss = 0.73943857, grad/param norm = 1.8661e-01, time/batch = 15.2948s	
20614/28500 (epoch 36.165), train_loss = 1.02488712, grad/param norm = 1.9270e-01, time/batch = 15.2388s	
20615/28500 (epoch 36.167), train_loss = 1.02142119, grad/param norm = 1.9382e-01, time/batch = 15.3534s	
20616/28500 (epoch 36.168), train_loss = 0.96725461, grad/param norm = 2.1087e-01, time/batch = 15.3965s	
20617/28500 (epoch 36.170), train_loss = 0.93782550, grad/param norm = 2.3675e-01, time/batch = 15.3757s	
20618/28500 (epoch 36.172), train_loss = 0.85560822, grad/param norm = 1.7827e-01, time/batch = 15.4606s	
20619/28500 (epoch 36.174), train_loss = 1.02810015, grad/param norm = 2.3604e-01, time/batch = 15.2887s	
20620/28500 (epoch 36.175), train_loss = 0.85010767, grad/param norm = 1.7010e-01, time/batch = 15.2279s	
20621/28500 (epoch 36.177), train_loss = 0.91736624, grad/param norm = 2.2317e-01, time/batch = 15.5133s	
20622/28500 (epoch 36.179), train_loss = 0.95601560, grad/param norm = 2.1364e-01, time/batch = 15.0745s	
20623/28500 (epoch 36.181), train_loss = 0.91674991, grad/param norm = 2.0667e-01, time/batch = 15.0521s	
20624/28500 (epoch 36.182), train_loss = 0.81633526, grad/param norm = 1.7826e-01, time/batch = 15.2146s	
20625/28500 (epoch 36.184), train_loss = 1.01946598, grad/param norm = 2.0193e-01, time/batch = 15.1694s	
20626/28500 (epoch 36.186), train_loss = 0.98083006, grad/param norm = 1.7870e-01, time/batch = 15.2601s	
20627/28500 (epoch 36.188), train_loss = 0.91683279, grad/param norm = 1.9571e-01, time/batch = 15.2595s	
20628/28500 (epoch 36.189), train_loss = 0.87703172, grad/param norm = 1.6857e-01, time/batch = 15.2582s	
20629/28500 (epoch 36.191), train_loss = 1.05915013, grad/param norm = 2.1371e-01, time/batch = 15.0717s	
20630/28500 (epoch 36.193), train_loss = 0.90301865, grad/param norm = 2.1530e-01, time/batch = 15.3690s	
20631/28500 (epoch 36.195), train_loss = 1.00589394, grad/param norm = 2.0508e-01, time/batch = 21.6241s	
20632/28500 (epoch 36.196), train_loss = 0.92338437, grad/param norm = 1.9596e-01, time/batch = 21.0640s	
20633/28500 (epoch 36.198), train_loss = 0.88232592, grad/param norm = 1.8795e-01, time/batch = 15.4214s	
20634/28500 (epoch 36.200), train_loss = 0.94928824, grad/param norm = 1.9021e-01, time/batch = 15.6319s	
20635/28500 (epoch 36.202), train_loss = 0.88603794, grad/param norm = 1.7380e-01, time/batch = 15.4783s	
20636/28500 (epoch 36.204), train_loss = 0.87705975, grad/param norm = 1.6963e-01, time/batch = 15.4780s	
20637/28500 (epoch 36.205), train_loss = 0.81952320, grad/param norm = 1.7463e-01, time/batch = 15.4182s	
20638/28500 (epoch 36.207), train_loss = 0.75700438, grad/param norm = 1.8397e-01, time/batch = 15.1421s	
20639/28500 (epoch 36.209), train_loss = 0.89766374, grad/param norm = 1.7488e-01, time/batch = 15.0555s	
20640/28500 (epoch 36.211), train_loss = 0.78972253, grad/param norm = 1.7771e-01, time/batch = 15.1800s	
20641/28500 (epoch 36.212), train_loss = 0.74007552, grad/param norm = 1.8417e-01, time/batch = 15.2122s	
20642/28500 (epoch 36.214), train_loss = 0.86139860, grad/param norm = 1.8997e-01, time/batch = 15.4513s	
20643/28500 (epoch 36.216), train_loss = 0.80836979, grad/param norm = 1.8041e-01, time/batch = 15.1344s	
20644/28500 (epoch 36.218), train_loss = 0.98454642, grad/param norm = 1.7630e-01, time/batch = 15.0622s	
20645/28500 (epoch 36.219), train_loss = 0.90209670, grad/param norm = 1.9093e-01, time/batch = 15.1389s	
20646/28500 (epoch 36.221), train_loss = 0.74049128, grad/param norm = 1.7242e-01, time/batch = 15.2955s	
20647/28500 (epoch 36.223), train_loss = 0.96585794, grad/param norm = 2.0419e-01, time/batch = 15.1413s	
20648/28500 (epoch 36.225), train_loss = 1.00347466, grad/param norm = 2.1484e-01, time/batch = 15.3167s	
20649/28500 (epoch 36.226), train_loss = 0.83841915, grad/param norm = 1.7978e-01, time/batch = 15.2299s	
20650/28500 (epoch 36.228), train_loss = 0.95251132, grad/param norm = 1.7595e-01, time/batch = 15.4978s	
20651/28500 (epoch 36.230), train_loss = 0.95529759, grad/param norm = 1.9972e-01, time/batch = 15.2983s	
20652/28500 (epoch 36.232), train_loss = 0.91643385, grad/param norm = 1.8386e-01, time/batch = 15.0683s	
20653/28500 (epoch 36.233), train_loss = 0.86528793, grad/param norm = 1.9120e-01, time/batch = 15.2733s	
20654/28500 (epoch 36.235), train_loss = 0.86396197, grad/param norm = 1.7148e-01, time/batch = 15.4263s	
20655/28500 (epoch 36.237), train_loss = 0.77073614, grad/param norm = 1.5643e-01, time/batch = 15.2341s	
20656/28500 (epoch 36.239), train_loss = 0.82798898, grad/param norm = 1.5869e-01, time/batch = 15.2225s	
20657/28500 (epoch 36.240), train_loss = 0.77631693, grad/param norm = 1.6416e-01, time/batch = 15.3686s	
20658/28500 (epoch 36.242), train_loss = 0.81827517, grad/param norm = 1.8121e-01, time/batch = 15.5266s	
20659/28500 (epoch 36.244), train_loss = 0.89332636, grad/param norm = 1.5277e-01, time/batch = 15.5651s	
20660/28500 (epoch 36.246), train_loss = 0.91952737, grad/param norm = 1.8488e-01, time/batch = 15.5707s	
20661/28500 (epoch 36.247), train_loss = 0.98949986, grad/param norm = 2.2337e-01, time/batch = 15.3581s	
20662/28500 (epoch 36.249), train_loss = 0.83690638, grad/param norm = 1.6645e-01, time/batch = 15.2029s	
20663/28500 (epoch 36.251), train_loss = 0.84442987, grad/param norm = 1.6198e-01, time/batch = 15.3066s	
20664/28500 (epoch 36.253), train_loss = 0.99251156, grad/param norm = 2.1983e-01, time/batch = 15.3891s	
20665/28500 (epoch 36.254), train_loss = 1.02377352, grad/param norm = 1.8475e-01, time/batch = 15.6199s	
20666/28500 (epoch 36.256), train_loss = 0.85374854, grad/param norm = 1.7927e-01, time/batch = 15.5474s	
20667/28500 (epoch 36.258), train_loss = 0.85774743, grad/param norm = 1.8106e-01, time/batch = 15.5622s	
20668/28500 (epoch 36.260), train_loss = 0.85060085, grad/param norm = 1.7417e-01, time/batch = 15.3178s	
20669/28500 (epoch 36.261), train_loss = 0.77491370, grad/param norm = 1.8688e-01, time/batch = 15.3732s	
20670/28500 (epoch 36.263), train_loss = 0.93407299, grad/param norm = 2.0870e-01, time/batch = 15.2183s	
20671/28500 (epoch 36.265), train_loss = 0.83748082, grad/param norm = 1.7101e-01, time/batch = 15.1474s	
20672/28500 (epoch 36.267), train_loss = 0.98944157, grad/param norm = 1.9618e-01, time/batch = 15.2108s	
20673/28500 (epoch 36.268), train_loss = 0.89318628, grad/param norm = 1.6149e-01, time/batch = 15.2153s	
20674/28500 (epoch 36.270), train_loss = 0.86701518, grad/param norm = 1.9787e-01, time/batch = 15.3097s	
20675/28500 (epoch 36.272), train_loss = 0.89569854, grad/param norm = 1.9654e-01, time/batch = 15.2973s	
20676/28500 (epoch 36.274), train_loss = 0.93036171, grad/param norm = 1.8852e-01, time/batch = 15.2918s	
20677/28500 (epoch 36.275), train_loss = 0.93002225, grad/param norm = 1.8257e-01, time/batch = 15.3075s	
20678/28500 (epoch 36.277), train_loss = 0.86145395, grad/param norm = 1.9577e-01, time/batch = 15.0751s	
20679/28500 (epoch 36.279), train_loss = 0.91180303, grad/param norm = 2.2991e-01, time/batch = 15.0706s	
20680/28500 (epoch 36.281), train_loss = 0.92953092, grad/param norm = 2.4814e-01, time/batch = 15.4211s	
20681/28500 (epoch 36.282), train_loss = 0.85690787, grad/param norm = 1.7104e-01, time/batch = 15.4419s	
20682/28500 (epoch 36.284), train_loss = 0.88502872, grad/param norm = 1.9135e-01, time/batch = 15.3673s	
20683/28500 (epoch 36.286), train_loss = 0.98627841, grad/param norm = 2.2215e-01, time/batch = 15.5311s	
20684/28500 (epoch 36.288), train_loss = 0.87771637, grad/param norm = 1.8928e-01, time/batch = 15.4855s	
20685/28500 (epoch 36.289), train_loss = 0.90251892, grad/param norm = 1.9590e-01, time/batch = 15.2795s	
20686/28500 (epoch 36.291), train_loss = 0.89056181, grad/param norm = 1.8638e-01, time/batch = 15.5706s	
20687/28500 (epoch 36.293), train_loss = 0.87867276, grad/param norm = 1.9304e-01, time/batch = 15.4339s	
20688/28500 (epoch 36.295), train_loss = 0.78668986, grad/param norm = 1.7921e-01, time/batch = 15.2377s	
20689/28500 (epoch 36.296), train_loss = 0.77184358, grad/param norm = 1.5594e-01, time/batch = 15.3881s	
20690/28500 (epoch 36.298), train_loss = 0.93106285, grad/param norm = 1.7868e-01, time/batch = 15.2093s	
20691/28500 (epoch 36.300), train_loss = 0.80423880, grad/param norm = 1.7557e-01, time/batch = 15.2608s	
20692/28500 (epoch 36.302), train_loss = 0.75766374, grad/param norm = 1.6365e-01, time/batch = 15.1946s	
20693/28500 (epoch 36.304), train_loss = 0.85849175, grad/param norm = 1.8382e-01, time/batch = 15.5302s	
20694/28500 (epoch 36.305), train_loss = 0.89105000, grad/param norm = 1.7561e-01, time/batch = 15.5734s	
20695/28500 (epoch 36.307), train_loss = 0.84493797, grad/param norm = 1.8835e-01, time/batch = 15.6324s	
20696/28500 (epoch 36.309), train_loss = 0.84994444, grad/param norm = 1.6851e-01, time/batch = 15.6825s	
20697/28500 (epoch 36.311), train_loss = 0.90995843, grad/param norm = 2.2098e-01, time/batch = 15.3606s	
20698/28500 (epoch 36.312), train_loss = 0.90641971, grad/param norm = 1.7137e-01, time/batch = 15.2995s	
20699/28500 (epoch 36.314), train_loss = 0.91250231, grad/param norm = 2.2240e-01, time/batch = 15.4808s	
20700/28500 (epoch 36.316), train_loss = 0.88146810, grad/param norm = 2.0371e-01, time/batch = 15.5279s	
20701/28500 (epoch 36.318), train_loss = 0.95210598, grad/param norm = 1.7216e-01, time/batch = 15.3889s	
20702/28500 (epoch 36.319), train_loss = 0.83119532, grad/param norm = 1.8361e-01, time/batch = 15.2823s	
20703/28500 (epoch 36.321), train_loss = 0.83099482, grad/param norm = 2.0716e-01, time/batch = 15.0549s	
20704/28500 (epoch 36.323), train_loss = 0.85984756, grad/param norm = 1.8314e-01, time/batch = 15.2019s	
20705/28500 (epoch 36.325), train_loss = 1.01356002, grad/param norm = 2.0411e-01, time/batch = 15.2210s	
20706/28500 (epoch 36.326), train_loss = 0.90130276, grad/param norm = 1.8847e-01, time/batch = 15.2032s	
20707/28500 (epoch 36.328), train_loss = 0.70411700, grad/param norm = 1.6274e-01, time/batch = 15.3011s	
20708/28500 (epoch 36.330), train_loss = 0.81219224, grad/param norm = 1.9820e-01, time/batch = 15.4680s	
20709/28500 (epoch 36.332), train_loss = 0.84633620, grad/param norm = 1.9988e-01, time/batch = 15.0324s	
20710/28500 (epoch 36.333), train_loss = 0.69748343, grad/param norm = 1.8111e-01, time/batch = 14.9673s	
20711/28500 (epoch 36.335), train_loss = 0.75675302, grad/param norm = 1.5785e-01, time/batch = 15.4561s	
20712/28500 (epoch 36.337), train_loss = 0.70934467, grad/param norm = 1.6063e-01, time/batch = 15.3559s	
20713/28500 (epoch 36.339), train_loss = 0.71104810, grad/param norm = 1.4638e-01, time/batch = 15.4691s	
20714/28500 (epoch 36.340), train_loss = 0.84594825, grad/param norm = 2.1199e-01, time/batch = 15.5408s	
20715/28500 (epoch 36.342), train_loss = 0.83734551, grad/param norm = 1.6961e-01, time/batch = 15.4740s	
20716/28500 (epoch 36.344), train_loss = 0.75757658, grad/param norm = 1.9096e-01, time/batch = 15.3632s	
20717/28500 (epoch 36.346), train_loss = 0.71976559, grad/param norm = 1.4553e-01, time/batch = 15.0669s	
20718/28500 (epoch 36.347), train_loss = 0.85755650, grad/param norm = 1.6032e-01, time/batch = 15.2355s	
20719/28500 (epoch 36.349), train_loss = 0.86959542, grad/param norm = 1.8035e-01, time/batch = 15.4484s	
20720/28500 (epoch 36.351), train_loss = 0.77132597, grad/param norm = 1.6393e-01, time/batch = 15.4928s	
20721/28500 (epoch 36.353), train_loss = 0.86248788, grad/param norm = 2.1120e-01, time/batch = 15.5271s	
20722/28500 (epoch 36.354), train_loss = 0.74832639, grad/param norm = 1.6015e-01, time/batch = 15.3773s	
20723/28500 (epoch 36.356), train_loss = 0.81405084, grad/param norm = 1.7263e-01, time/batch = 15.4822s	
20724/28500 (epoch 36.358), train_loss = 0.91311188, grad/param norm = 1.7805e-01, time/batch = 15.5839s	
20725/28500 (epoch 36.360), train_loss = 0.87290933, grad/param norm = 1.8729e-01, time/batch = 15.3140s	
20726/28500 (epoch 36.361), train_loss = 0.76952437, grad/param norm = 1.7389e-01, time/batch = 15.3209s	
20727/28500 (epoch 36.363), train_loss = 0.77365423, grad/param norm = 1.5413e-01, time/batch = 15.2260s	
20728/28500 (epoch 36.365), train_loss = 0.82239709, grad/param norm = 1.7730e-01, time/batch = 15.3693s	
20729/28500 (epoch 36.367), train_loss = 0.87666167, grad/param norm = 1.8691e-01, time/batch = 15.4784s	
20730/28500 (epoch 36.368), train_loss = 0.80132312, grad/param norm = 1.7166e-01, time/batch = 15.3213s	
20731/28500 (epoch 36.370), train_loss = 0.86915412, grad/param norm = 1.9819e-01, time/batch = 15.2892s	
20732/28500 (epoch 36.372), train_loss = 0.69709851, grad/param norm = 1.6171e-01, time/batch = 15.1279s	
20733/28500 (epoch 36.374), train_loss = 0.81706735, grad/param norm = 1.8400e-01, time/batch = 15.4292s	
20734/28500 (epoch 36.375), train_loss = 0.93131164, grad/param norm = 1.8699e-01, time/batch = 15.4145s	
20735/28500 (epoch 36.377), train_loss = 0.77895427, grad/param norm = 2.1668e-01, time/batch = 15.4684s	
20736/28500 (epoch 36.379), train_loss = 0.66313265, grad/param norm = 1.7885e-01, time/batch = 15.5489s	
20737/28500 (epoch 36.381), train_loss = 0.84069980, grad/param norm = 2.0410e-01, time/batch = 15.3599s	
20738/28500 (epoch 36.382), train_loss = 0.80755146, grad/param norm = 2.0284e-01, time/batch = 15.3120s	
20739/28500 (epoch 36.384), train_loss = 0.70122008, grad/param norm = 1.7490e-01, time/batch = 15.4633s	
20740/28500 (epoch 36.386), train_loss = 0.73909566, grad/param norm = 1.5914e-01, time/batch = 15.5552s	
20741/28500 (epoch 36.388), train_loss = 0.91428377, grad/param norm = 1.7697e-01, time/batch = 15.5710s	
20742/28500 (epoch 36.389), train_loss = 0.80870204, grad/param norm = 2.0218e-01, time/batch = 15.3714s	
20743/28500 (epoch 36.391), train_loss = 0.74855938, grad/param norm = 1.8588e-01, time/batch = 15.0544s	
20744/28500 (epoch 36.393), train_loss = 0.77315572, grad/param norm = 1.8657e-01, time/batch = 15.1304s	
20745/28500 (epoch 36.395), train_loss = 0.94528984, grad/param norm = 1.8144e-01, time/batch = 15.1461s	
20746/28500 (epoch 36.396), train_loss = 0.90708807, grad/param norm = 1.6378e-01, time/batch = 15.1741s	
20747/28500 (epoch 36.398), train_loss = 0.62018513, grad/param norm = 1.7340e-01, time/batch = 15.3022s	
20748/28500 (epoch 36.400), train_loss = 0.80699415, grad/param norm = 1.9045e-01, time/batch = 15.2944s	
20749/28500 (epoch 36.402), train_loss = 0.86220357, grad/param norm = 1.8420e-01, time/batch = 15.1645s	
20750/28500 (epoch 36.404), train_loss = 0.88021422, grad/param norm = 2.1244e-01, time/batch = 15.0518s	
20751/28500 (epoch 36.405), train_loss = 0.90003012, grad/param norm = 1.7241e-01, time/batch = 15.1550s	
20752/28500 (epoch 36.407), train_loss = 0.86060066, grad/param norm = 1.8898e-01, time/batch = 15.1412s	
20753/28500 (epoch 36.409), train_loss = 0.85602781, grad/param norm = 1.9161e-01, time/batch = 15.4028s	
20754/28500 (epoch 36.411), train_loss = 0.94249302, grad/param norm = 2.0596e-01, time/batch = 15.4756s	
20755/28500 (epoch 36.412), train_loss = 0.97045248, grad/param norm = 2.2139e-01, time/batch = 15.5847s	
20756/28500 (epoch 36.414), train_loss = 0.87174977, grad/param norm = 2.0081e-01, time/batch = 15.6602s	
20757/28500 (epoch 36.416), train_loss = 0.78225366, grad/param norm = 1.8128e-01, time/batch = 15.6175s	
20758/28500 (epoch 36.418), train_loss = 0.86998158, grad/param norm = 1.6129e-01, time/batch = 15.5920s	
20759/28500 (epoch 36.419), train_loss = 0.96076408, grad/param norm = 2.0141e-01, time/batch = 15.5331s	
20760/28500 (epoch 36.421), train_loss = 0.92310581, grad/param norm = 1.8923e-01, time/batch = 15.1706s	
20761/28500 (epoch 36.423), train_loss = 0.92122925, grad/param norm = 1.9903e-01, time/batch = 15.2137s	
20762/28500 (epoch 36.425), train_loss = 0.84017198, grad/param norm = 2.0753e-01, time/batch = 15.0572s	
20763/28500 (epoch 36.426), train_loss = 0.87651830, grad/param norm = 2.0735e-01, time/batch = 15.1399s	
20764/28500 (epoch 36.428), train_loss = 1.02514801, grad/param norm = 2.2253e-01, time/batch = 15.3131s	
20765/28500 (epoch 36.430), train_loss = 0.99631971, grad/param norm = 1.8199e-01, time/batch = 15.2308s	
20766/28500 (epoch 36.432), train_loss = 0.86090941, grad/param norm = 1.9073e-01, time/batch = 15.0666s	
20767/28500 (epoch 36.433), train_loss = 0.91766427, grad/param norm = 1.8730e-01, time/batch = 15.2508s	
20768/28500 (epoch 36.435), train_loss = 0.88604216, grad/param norm = 1.8262e-01, time/batch = 15.2172s	
20769/28500 (epoch 36.437), train_loss = 0.81589823, grad/param norm = 1.9236e-01, time/batch = 15.3287s	
20770/28500 (epoch 36.439), train_loss = 0.84688688, grad/param norm = 1.7536e-01, time/batch = 15.5419s	
20771/28500 (epoch 36.440), train_loss = 1.01182689, grad/param norm = 1.8559e-01, time/batch = 15.5212s	
20772/28500 (epoch 36.442), train_loss = 0.80371307, grad/param norm = 2.1316e-01, time/batch = 15.3907s	
20773/28500 (epoch 36.444), train_loss = 0.76022370, grad/param norm = 1.7031e-01, time/batch = 15.4370s	
20774/28500 (epoch 36.446), train_loss = 0.72825660, grad/param norm = 1.6622e-01, time/batch = 15.4874s	
20775/28500 (epoch 36.447), train_loss = 0.74837570, grad/param norm = 1.8161e-01, time/batch = 15.3184s	
20776/28500 (epoch 36.449), train_loss = 0.81308831, grad/param norm = 1.7267e-01, time/batch = 15.4667s	
20777/28500 (epoch 36.451), train_loss = 0.82544862, grad/param norm = 1.8351e-01, time/batch = 15.4774s	
20778/28500 (epoch 36.453), train_loss = 0.81975821, grad/param norm = 1.7538e-01, time/batch = 15.5476s	
20779/28500 (epoch 36.454), train_loss = 0.77086686, grad/param norm = 1.5655e-01, time/batch = 15.3981s	
20780/28500 (epoch 36.456), train_loss = 0.92459498, grad/param norm = 2.2271e-01, time/batch = 15.3864s	
20781/28500 (epoch 36.458), train_loss = 0.83451908, grad/param norm = 1.8863e-01, time/batch = 15.6128s	
20782/28500 (epoch 36.460), train_loss = 0.92985853, grad/param norm = 1.7870e-01, time/batch = 15.5934s	
20783/28500 (epoch 36.461), train_loss = 0.77585520, grad/param norm = 1.9774e-01, time/batch = 15.3208s	
20784/28500 (epoch 36.463), train_loss = 0.70492242, grad/param norm = 1.5106e-01, time/batch = 15.5513s	
20785/28500 (epoch 36.465), train_loss = 0.70750138, grad/param norm = 2.1278e-01, time/batch = 15.3117s	
20786/28500 (epoch 36.467), train_loss = 0.85683344, grad/param norm = 1.6963e-01, time/batch = 15.2439s	
20787/28500 (epoch 36.468), train_loss = 0.74896345, grad/param norm = 1.5408e-01, time/batch = 15.5630s	
20788/28500 (epoch 36.470), train_loss = 0.80468822, grad/param norm = 1.8613e-01, time/batch = 15.3749s	
20789/28500 (epoch 36.472), train_loss = 0.75589264, grad/param norm = 1.5778e-01, time/batch = 15.2613s	
20790/28500 (epoch 36.474), train_loss = 0.98052287, grad/param norm = 1.9794e-01, time/batch = 15.2059s	
20791/28500 (epoch 36.475), train_loss = 0.79204489, grad/param norm = 1.7323e-01, time/batch = 15.2380s	
20792/28500 (epoch 36.477), train_loss = 0.82178320, grad/param norm = 1.9306e-01, time/batch = 15.1343s	
20793/28500 (epoch 36.479), train_loss = 0.88157079, grad/param norm = 1.7922e-01, time/batch = 15.3997s	
20794/28500 (epoch 36.481), train_loss = 0.89704406, grad/param norm = 1.8661e-01, time/batch = 15.5422s	
20795/28500 (epoch 36.482), train_loss = 0.73417679, grad/param norm = 1.5958e-01, time/batch = 15.4221s	
20796/28500 (epoch 36.484), train_loss = 0.77562676, grad/param norm = 1.8193e-01, time/batch = 15.3964s	
20797/28500 (epoch 36.486), train_loss = 0.67514000, grad/param norm = 1.6978e-01, time/batch = 15.3850s	
20798/28500 (epoch 36.488), train_loss = 0.89048422, grad/param norm = 1.6951e-01, time/batch = 15.6203s	
20799/28500 (epoch 36.489), train_loss = 0.96377562, grad/param norm = 1.7594e-01, time/batch = 15.4234s	
20800/28500 (epoch 36.491), train_loss = 0.78337718, grad/param norm = 1.9930e-01, time/batch = 15.4796s	
20801/28500 (epoch 36.493), train_loss = 0.81143555, grad/param norm = 1.5498e-01, time/batch = 15.4415s	
20802/28500 (epoch 36.495), train_loss = 0.86756505, grad/param norm = 1.9580e-01, time/batch = 15.1304s	
20803/28500 (epoch 36.496), train_loss = 0.77263758, grad/param norm = 1.9309e-01, time/batch = 15.3984s	
20804/28500 (epoch 36.498), train_loss = 0.81818315, grad/param norm = 1.6324e-01, time/batch = 15.3793s	
20805/28500 (epoch 36.500), train_loss = 0.77863152, grad/param norm = 1.6703e-01, time/batch = 15.5817s	
20806/28500 (epoch 36.502), train_loss = 0.90086687, grad/param norm = 1.6891e-01, time/batch = 15.5849s	
20807/28500 (epoch 36.504), train_loss = 0.88688768, grad/param norm = 1.7804e-01, time/batch = 15.4541s	
20808/28500 (epoch 36.505), train_loss = 0.78843442, grad/param norm = 1.8459e-01, time/batch = 15.3256s	
20809/28500 (epoch 36.507), train_loss = 0.93355853, grad/param norm = 2.4302e-01, time/batch = 15.4676s	
20810/28500 (epoch 36.509), train_loss = 0.85851203, grad/param norm = 1.7698e-01, time/batch = 15.4774s	
20811/28500 (epoch 36.511), train_loss = 0.85643085, grad/param norm = 1.7872e-01, time/batch = 15.4604s	
20812/28500 (epoch 36.512), train_loss = 0.90988105, grad/param norm = 2.0125e-01, time/batch = 15.3274s	
20813/28500 (epoch 36.514), train_loss = 0.85864941, grad/param norm = 1.9549e-01, time/batch = 15.1043s	
20814/28500 (epoch 36.516), train_loss = 0.84177105, grad/param norm = 1.6419e-01, time/batch = 15.0970s	
20815/28500 (epoch 36.518), train_loss = 0.88852723, grad/param norm = 1.8289e-01, time/batch = 15.3829s	
20816/28500 (epoch 36.519), train_loss = 0.88869688, grad/param norm = 1.7756e-01, time/batch = 15.1962s	
20817/28500 (epoch 36.521), train_loss = 0.96782670, grad/param norm = 2.0183e-01, time/batch = 15.4789s	
20818/28500 (epoch 36.523), train_loss = 0.88871125, grad/param norm = 1.8826e-01, time/batch = 15.4561s	
20819/28500 (epoch 36.525), train_loss = 0.95599656, grad/param norm = 1.8458e-01, time/batch = 15.4603s	
20820/28500 (epoch 36.526), train_loss = 0.90185414, grad/param norm = 1.8162e-01, time/batch = 15.4748s	
20821/28500 (epoch 36.528), train_loss = 0.89256778, grad/param norm = 2.0266e-01, time/batch = 15.3693s	
20822/28500 (epoch 36.530), train_loss = 0.90154311, grad/param norm = 1.8775e-01, time/batch = 15.2101s	
20823/28500 (epoch 36.532), train_loss = 0.82957041, grad/param norm = 1.8414e-01, time/batch = 15.0633s	
20824/28500 (epoch 36.533), train_loss = 0.89669041, grad/param norm = 1.7666e-01, time/batch = 15.3022s	
20825/28500 (epoch 36.535), train_loss = 0.73657111, grad/param norm = 1.6035e-01, time/batch = 15.6205s	
20826/28500 (epoch 36.537), train_loss = 0.76465017, grad/param norm = 1.9355e-01, time/batch = 15.4401s	
20827/28500 (epoch 36.539), train_loss = 0.73050402, grad/param norm = 1.9782e-01, time/batch = 15.5909s	
20828/28500 (epoch 36.540), train_loss = 0.84023276, grad/param norm = 1.7018e-01, time/batch = 15.5263s	
20829/28500 (epoch 36.542), train_loss = 0.89492381, grad/param norm = 2.1850e-01, time/batch = 15.5443s	
20830/28500 (epoch 36.544), train_loss = 0.97813156, grad/param norm = 1.7771e-01, time/batch = 15.2148s	
20831/28500 (epoch 36.546), train_loss = 0.83737950, grad/param norm = 1.6974e-01, time/batch = 15.2812s	
20832/28500 (epoch 36.547), train_loss = 0.82470921, grad/param norm = 1.7936e-01, time/batch = 15.2085s	
20833/28500 (epoch 36.549), train_loss = 0.70406456, grad/param norm = 1.4394e-01, time/batch = 15.1940s	
20834/28500 (epoch 36.551), train_loss = 0.82262101, grad/param norm = 2.2626e-01, time/batch = 15.2179s	
20835/28500 (epoch 36.553), train_loss = 1.01320259, grad/param norm = 2.1597e-01, time/batch = 15.2856s	
20836/28500 (epoch 36.554), train_loss = 0.90988982, grad/param norm = 1.9194e-01, time/batch = 15.2733s	
20837/28500 (epoch 36.556), train_loss = 0.89866058, grad/param norm = 1.7306e-01, time/batch = 15.2998s	
20838/28500 (epoch 36.558), train_loss = 0.91145185, grad/param norm = 1.7661e-01, time/batch = 15.2297s	
20839/28500 (epoch 36.560), train_loss = 0.90950352, grad/param norm = 1.9339e-01, time/batch = 15.2951s	
20840/28500 (epoch 36.561), train_loss = 0.91161487, grad/param norm = 2.1723e-01, time/batch = 15.3278s	
20841/28500 (epoch 36.563), train_loss = 0.99750906, grad/param norm = 2.0792e-01, time/batch = 15.2859s	
20842/28500 (epoch 36.565), train_loss = 0.78836492, grad/param norm = 1.7154e-01, time/batch = 15.1434s	
20843/28500 (epoch 36.567), train_loss = 0.74091983, grad/param norm = 1.6798e-01, time/batch = 15.2338s	
20844/28500 (epoch 36.568), train_loss = 0.87926695, grad/param norm = 2.1448e-01, time/batch = 15.5375s	
20845/28500 (epoch 36.570), train_loss = 0.83545498, grad/param norm = 1.9596e-01, time/batch = 15.2416s	
20846/28500 (epoch 36.572), train_loss = 0.87629057, grad/param norm = 1.8631e-01, time/batch = 15.3137s	
20847/28500 (epoch 36.574), train_loss = 0.81718419, grad/param norm = 1.8769e-01, time/batch = 15.4684s	
20848/28500 (epoch 36.575), train_loss = 0.81250996, grad/param norm = 1.6894e-01, time/batch = 15.4882s	
20849/28500 (epoch 36.577), train_loss = 0.91349216, grad/param norm = 1.7180e-01, time/batch = 15.5455s	
20850/28500 (epoch 36.579), train_loss = 0.93006696, grad/param norm = 2.0596e-01, time/batch = 15.4555s	
20851/28500 (epoch 36.581), train_loss = 0.77933645, grad/param norm = 2.2198e-01, time/batch = 15.5414s	
20852/28500 (epoch 36.582), train_loss = 0.95276732, grad/param norm = 1.8918e-01, time/batch = 15.4604s	
20853/28500 (epoch 36.584), train_loss = 0.79637797, grad/param norm = 1.7521e-01, time/batch = 15.4064s	
20854/28500 (epoch 36.586), train_loss = 0.79283366, grad/param norm = 1.8827e-01, time/batch = 15.3619s	
20855/28500 (epoch 36.588), train_loss = 0.79827442, grad/param norm = 1.8268e-01, time/batch = 15.3717s	
20856/28500 (epoch 36.589), train_loss = 0.84126197, grad/param norm = 1.9480e-01, time/batch = 15.5251s	
20857/28500 (epoch 36.591), train_loss = 0.85892786, grad/param norm = 1.8060e-01, time/batch = 15.2326s	
20858/28500 (epoch 36.593), train_loss = 0.81172711, grad/param norm = 1.6394e-01, time/batch = 15.2323s	
20859/28500 (epoch 36.595), train_loss = 1.02849958, grad/param norm = 2.2190e-01, time/batch = 15.2865s	
20860/28500 (epoch 36.596), train_loss = 1.02236769, grad/param norm = 1.9950e-01, time/batch = 15.4704s	
20861/28500 (epoch 36.598), train_loss = 0.83692817, grad/param norm = 1.8541e-01, time/batch = 15.7065s	
20862/28500 (epoch 36.600), train_loss = 0.83582833, grad/param norm = 1.8185e-01, time/batch = 15.5317s	
20863/28500 (epoch 36.602), train_loss = 0.91844616, grad/param norm = 1.9424e-01, time/batch = 17.6597s	
20864/28500 (epoch 36.604), train_loss = 0.91596965, grad/param norm = 1.6363e-01, time/batch = 25.2795s	
20865/28500 (epoch 36.605), train_loss = 0.92723874, grad/param norm = 1.8253e-01, time/batch = 15.3690s	
20866/28500 (epoch 36.607), train_loss = 0.96839335, grad/param norm = 1.7692e-01, time/batch = 15.5670s	
20867/28500 (epoch 36.609), train_loss = 0.86575312, grad/param norm = 1.7549e-01, time/batch = 15.3797s	
20868/28500 (epoch 36.611), train_loss = 0.83771161, grad/param norm = 1.8418e-01, time/batch = 15.2031s	
20869/28500 (epoch 36.612), train_loss = 0.91684410, grad/param norm = 2.0992e-01, time/batch = 15.4310s	
20870/28500 (epoch 36.614), train_loss = 0.93907971, grad/param norm = 1.9958e-01, time/batch = 15.3669s	
20871/28500 (epoch 36.616), train_loss = 0.83401164, grad/param norm = 2.2518e-01, time/batch = 15.4668s	
20872/28500 (epoch 36.618), train_loss = 0.84779051, grad/param norm = 1.7615e-01, time/batch = 15.5457s	
20873/28500 (epoch 36.619), train_loss = 0.92553264, grad/param norm = 2.3788e-01, time/batch = 15.4648s	
20874/28500 (epoch 36.621), train_loss = 0.68986439, grad/param norm = 1.7356e-01, time/batch = 15.5380s	
20875/28500 (epoch 36.623), train_loss = 0.97207831, grad/param norm = 1.9527e-01, time/batch = 15.4618s	
20876/28500 (epoch 36.625), train_loss = 0.77811112, grad/param norm = 1.9070e-01, time/batch = 15.4140s	
20877/28500 (epoch 36.626), train_loss = 0.68357829, grad/param norm = 1.5773e-01, time/batch = 15.2221s	
20878/28500 (epoch 36.628), train_loss = 0.79312485, grad/param norm = 1.9678e-01, time/batch = 15.0407s	
20879/28500 (epoch 36.630), train_loss = 0.73391627, grad/param norm = 1.5493e-01, time/batch = 15.3856s	
20880/28500 (epoch 36.632), train_loss = 0.94875163, grad/param norm = 2.0001e-01, time/batch = 15.3804s	
20881/28500 (epoch 36.633), train_loss = 1.00059922, grad/param norm = 1.8303e-01, time/batch = 15.1550s	
20882/28500 (epoch 36.635), train_loss = 0.91223009, grad/param norm = 2.2399e-01, time/batch = 15.5763s	
20883/28500 (epoch 36.637), train_loss = 0.87948657, grad/param norm = 1.7075e-01, time/batch = 15.5193s	
20884/28500 (epoch 36.639), train_loss = 0.78609027, grad/param norm = 2.0530e-01, time/batch = 15.3833s	
20885/28500 (epoch 36.640), train_loss = 0.79943138, grad/param norm = 1.8105e-01, time/batch = 15.4000s	
20886/28500 (epoch 36.642), train_loss = 0.81735631, grad/param norm = 1.7869e-01, time/batch = 15.5426s	
20887/28500 (epoch 36.644), train_loss = 0.91121171, grad/param norm = 2.0131e-01, time/batch = 15.4667s	
20888/28500 (epoch 36.646), train_loss = 0.73752863, grad/param norm = 1.5952e-01, time/batch = 15.2799s	
20889/28500 (epoch 36.647), train_loss = 0.80383282, grad/param norm = 1.6400e-01, time/batch = 15.0807s	
20890/28500 (epoch 36.649), train_loss = 0.77311447, grad/param norm = 2.0278e-01, time/batch = 15.1921s	
20891/28500 (epoch 36.651), train_loss = 0.73679453, grad/param norm = 1.3921e-01, time/batch = 15.6309s	
20892/28500 (epoch 36.653), train_loss = 0.74061736, grad/param norm = 1.9178e-01, time/batch = 15.6663s	
20893/28500 (epoch 36.654), train_loss = 0.78261954, grad/param norm = 1.7937e-01, time/batch = 15.7584s	
20894/28500 (epoch 36.656), train_loss = 0.72537072, grad/param norm = 1.8186e-01, time/batch = 15.2063s	
20895/28500 (epoch 36.658), train_loss = 0.84476171, grad/param norm = 1.7500e-01, time/batch = 15.4647s	
20896/28500 (epoch 36.660), train_loss = 0.85315103, grad/param norm = 1.6534e-01, time/batch = 15.3266s	
20897/28500 (epoch 36.661), train_loss = 0.94907547, grad/param norm = 1.9475e-01, time/batch = 15.1260s	
20898/28500 (epoch 36.663), train_loss = 0.94507686, grad/param norm = 2.5570e-01, time/batch = 15.5074s	
20899/28500 (epoch 36.665), train_loss = 0.84704190, grad/param norm = 1.7667e-01, time/batch = 15.3659s	
20900/28500 (epoch 36.667), train_loss = 0.84870803, grad/param norm = 1.9924e-01, time/batch = 15.4646s	
20901/28500 (epoch 36.668), train_loss = 0.84472924, grad/param norm = 1.8530e-01, time/batch = 15.5880s	
20902/28500 (epoch 36.670), train_loss = 0.85857834, grad/param norm = 1.8220e-01, time/batch = 15.5028s	
20903/28500 (epoch 36.672), train_loss = 0.77258686, grad/param norm = 1.7699e-01, time/batch = 15.5003s	
20904/28500 (epoch 36.674), train_loss = 0.68190420, grad/param norm = 1.8378e-01, time/batch = 15.3997s	
20905/28500 (epoch 36.675), train_loss = 0.70645183, grad/param norm = 1.6379e-01, time/batch = 15.6032s	
20906/28500 (epoch 36.677), train_loss = 0.79806673, grad/param norm = 1.7311e-01, time/batch = 15.2487s	
20907/28500 (epoch 36.679), train_loss = 0.80471458, grad/param norm = 1.7942e-01, time/batch = 15.0727s	
20908/28500 (epoch 36.681), train_loss = 0.88228644, grad/param norm = 1.8941e-01, time/batch = 15.0251s	
20909/28500 (epoch 36.682), train_loss = 0.78746497, grad/param norm = 1.6857e-01, time/batch = 15.2276s	
20910/28500 (epoch 36.684), train_loss = 0.84005597, grad/param norm = 1.7081e-01, time/batch = 15.2863s	
20911/28500 (epoch 36.686), train_loss = 0.79030303, grad/param norm = 2.2580e-01, time/batch = 15.3878s	
20912/28500 (epoch 36.688), train_loss = 0.77237469, grad/param norm = 1.3656e-01, time/batch = 15.2389s	
20913/28500 (epoch 36.689), train_loss = 0.78243737, grad/param norm = 1.8774e-01, time/batch = 15.2530s	
20914/28500 (epoch 36.691), train_loss = 0.89008419, grad/param norm = 1.8712e-01, time/batch = 15.3339s	
20915/28500 (epoch 36.693), train_loss = 0.80900545, grad/param norm = 1.7232e-01, time/batch = 14.9783s	
20916/28500 (epoch 36.695), train_loss = 0.63998564, grad/param norm = 1.8729e-01, time/batch = 14.9817s	
20917/28500 (epoch 36.696), train_loss = 0.83280583, grad/param norm = 2.2381e-01, time/batch = 15.1937s	
20918/28500 (epoch 36.698), train_loss = 0.87536703, grad/param norm = 1.7208e-01, time/batch = 15.0847s	
20919/28500 (epoch 36.700), train_loss = 0.86314168, grad/param norm = 2.0097e-01, time/batch = 15.3260s	
20920/28500 (epoch 36.702), train_loss = 0.84180746, grad/param norm = 2.2568e-01, time/batch = 15.2155s	
20921/28500 (epoch 36.704), train_loss = 0.88427745, grad/param norm = 2.1303e-01, time/batch = 15.7021s	
20922/28500 (epoch 36.705), train_loss = 0.91809191, grad/param norm = 2.4636e-01, time/batch = 15.5461s	
20923/28500 (epoch 36.707), train_loss = 0.78105677, grad/param norm = 2.0728e-01, time/batch = 15.5347s	
20924/28500 (epoch 36.709), train_loss = 0.98150124, grad/param norm = 2.1786e-01, time/batch = 15.5434s	
20925/28500 (epoch 36.711), train_loss = 0.78487351, grad/param norm = 1.7436e-01, time/batch = 15.3728s	
20926/28500 (epoch 36.712), train_loss = 0.87648726, grad/param norm = 1.8782e-01, time/batch = 15.3914s	
20927/28500 (epoch 36.714), train_loss = 0.96014887, grad/param norm = 2.1223e-01, time/batch = 15.3730s	
20928/28500 (epoch 36.716), train_loss = 0.84283475, grad/param norm = 2.1049e-01, time/batch = 15.2856s	
20929/28500 (epoch 36.718), train_loss = 0.86428209, grad/param norm = 1.8452e-01, time/batch = 15.1306s	
20930/28500 (epoch 36.719), train_loss = 0.85973837, grad/param norm = 1.8305e-01, time/batch = 15.1352s	
20931/28500 (epoch 36.721), train_loss = 0.66497079, grad/param norm = 1.6354e-01, time/batch = 15.3175s	
20932/28500 (epoch 36.723), train_loss = 0.86514966, grad/param norm = 2.0469e-01, time/batch = 15.3491s	
20933/28500 (epoch 36.725), train_loss = 0.91961331, grad/param norm = 1.8899e-01, time/batch = 15.5038s	
20934/28500 (epoch 36.726), train_loss = 0.85191866, grad/param norm = 2.3544e-01, time/batch = 15.3204s	
20935/28500 (epoch 36.728), train_loss = 0.76000944, grad/param norm = 1.6896e-01, time/batch = 15.3765s	
20936/28500 (epoch 36.730), train_loss = 0.85338010, grad/param norm = 1.9998e-01, time/batch = 15.3010s	
20937/28500 (epoch 36.732), train_loss = 0.68481958, grad/param norm = 1.5611e-01, time/batch = 15.3776s	
20938/28500 (epoch 36.733), train_loss = 0.71400464, grad/param norm = 1.7044e-01, time/batch = 15.1405s	
20939/28500 (epoch 36.735), train_loss = 0.71407068, grad/param norm = 1.5500e-01, time/batch = 15.2970s	
20940/28500 (epoch 36.737), train_loss = 0.64152937, grad/param norm = 1.5046e-01, time/batch = 15.3613s	
20941/28500 (epoch 36.739), train_loss = 0.75267920, grad/param norm = 1.8474e-01, time/batch = 15.4020s	
20942/28500 (epoch 36.740), train_loss = 0.84737223, grad/param norm = 1.8310e-01, time/batch = 15.5566s	
20943/28500 (epoch 36.742), train_loss = 0.74075476, grad/param norm = 1.8155e-01, time/batch = 15.5657s	
20944/28500 (epoch 36.744), train_loss = 0.83510405, grad/param norm = 1.7180e-01, time/batch = 15.5389s	
20945/28500 (epoch 36.746), train_loss = 0.78213972, grad/param norm = 1.5749e-01, time/batch = 15.5157s	
20946/28500 (epoch 36.747), train_loss = 0.78137934, grad/param norm = 1.6957e-01, time/batch = 15.4078s	
20947/28500 (epoch 36.749), train_loss = 0.89348452, grad/param norm = 1.9214e-01, time/batch = 15.0599s	
20948/28500 (epoch 36.751), train_loss = 0.75684719, grad/param norm = 2.2728e-01, time/batch = 15.2920s	
20949/28500 (epoch 36.753), train_loss = 0.83457309, grad/param norm = 1.6088e-01, time/batch = 15.6177s	
20950/28500 (epoch 36.754), train_loss = 0.74105256, grad/param norm = 1.8020e-01, time/batch = 15.5467s	
20951/28500 (epoch 36.756), train_loss = 0.94998090, grad/param norm = 1.7358e-01, time/batch = 15.6985s	
20952/28500 (epoch 36.758), train_loss = 0.89865771, grad/param norm = 2.2332e-01, time/batch = 15.6293s	
20953/28500 (epoch 36.760), train_loss = 0.74379747, grad/param norm = 1.7537e-01, time/batch = 15.3033s	
20954/28500 (epoch 36.761), train_loss = 0.76772938, grad/param norm = 1.8284e-01, time/batch = 15.3082s	
20955/28500 (epoch 36.763), train_loss = 0.66926157, grad/param norm = 1.6611e-01, time/batch = 15.1478s	
20956/28500 (epoch 36.765), train_loss = 0.81934312, grad/param norm = 1.7552e-01, time/batch = 15.1218s	
20957/28500 (epoch 36.767), train_loss = 0.69821433, grad/param norm = 1.6664e-01, time/batch = 14.9006s	
20958/28500 (epoch 36.768), train_loss = 0.86830229, grad/param norm = 1.6785e-01, time/batch = 14.9067s	
20959/28500 (epoch 36.770), train_loss = 0.73614156, grad/param norm = 1.6407e-01, time/batch = 15.1679s	
20960/28500 (epoch 36.772), train_loss = 0.67202617, grad/param norm = 1.4932e-01, time/batch = 19.3107s	
20961/28500 (epoch 36.774), train_loss = 0.83042604, grad/param norm = 1.6629e-01, time/batch = 17.0582s	
20962/28500 (epoch 36.775), train_loss = 0.88918773, grad/param norm = 1.7101e-01, time/batch = 17.4760s	
20963/28500 (epoch 36.777), train_loss = 0.88637794, grad/param norm = 1.5694e-01, time/batch = 18.0105s	
20964/28500 (epoch 36.779), train_loss = 0.69061610, grad/param norm = 1.4209e-01, time/batch = 17.3395s	
20965/28500 (epoch 36.781), train_loss = 0.81138561, grad/param norm = 1.7527e-01, time/batch = 17.0200s	
20966/28500 (epoch 36.782), train_loss = 0.84102364, grad/param norm = 1.9945e-01, time/batch = 16.7747s	
20967/28500 (epoch 36.784), train_loss = 0.67481051, grad/param norm = 1.6106e-01, time/batch = 16.7264s	
20968/28500 (epoch 36.786), train_loss = 0.69572266, grad/param norm = 1.6221e-01, time/batch = 24.1701s	
20969/28500 (epoch 36.788), train_loss = 0.78831604, grad/param norm = 1.9495e-01, time/batch = 15.2244s	
20970/28500 (epoch 36.789), train_loss = 0.62584136, grad/param norm = 1.9235e-01, time/batch = 15.3038s	
20971/28500 (epoch 36.791), train_loss = 0.84989334, grad/param norm = 1.8208e-01, time/batch = 15.3248s	
20972/28500 (epoch 36.793), train_loss = 0.81122330, grad/param norm = 1.7754e-01, time/batch = 15.4552s	
20973/28500 (epoch 36.795), train_loss = 0.83874513, grad/param norm = 1.7866e-01, time/batch = 15.3462s	
20974/28500 (epoch 36.796), train_loss = 0.73340060, grad/param norm = 2.0234e-01, time/batch = 15.3746s	
20975/28500 (epoch 36.798), train_loss = 0.68449835, grad/param norm = 1.8132e-01, time/batch = 15.3137s	
20976/28500 (epoch 36.800), train_loss = 0.67300789, grad/param norm = 1.7531e-01, time/batch = 15.4648s	
20977/28500 (epoch 36.802), train_loss = 0.77531445, grad/param norm = 2.1626e-01, time/batch = 15.4598s	
20978/28500 (epoch 36.804), train_loss = 0.83806777, grad/param norm = 1.6210e-01, time/batch = 15.6514s	
20979/28500 (epoch 36.805), train_loss = 0.83096072, grad/param norm = 1.8698e-01, time/batch = 15.3710s	
20980/28500 (epoch 36.807), train_loss = 0.83816003, grad/param norm = 2.0701e-01, time/batch = 15.5376s	
20981/28500 (epoch 36.809), train_loss = 0.79847558, grad/param norm = 2.3837e-01, time/batch = 15.4945s	
20982/28500 (epoch 36.811), train_loss = 0.85103002, grad/param norm = 1.8687e-01, time/batch = 15.6250s	
20983/28500 (epoch 36.812), train_loss = 0.80828127, grad/param norm = 1.8433e-01, time/batch = 15.4779s	
20984/28500 (epoch 36.814), train_loss = 0.76686138, grad/param norm = 1.6740e-01, time/batch = 15.4958s	
20985/28500 (epoch 36.816), train_loss = 0.85140764, grad/param norm = 2.1494e-01, time/batch = 15.3650s	
20986/28500 (epoch 36.818), train_loss = 0.95938375, grad/param norm = 1.9075e-01, time/batch = 15.2975s	
20987/28500 (epoch 36.819), train_loss = 0.81877041, grad/param norm = 1.7568e-01, time/batch = 15.1002s	
20988/28500 (epoch 36.821), train_loss = 0.78712506, grad/param norm = 1.7198e-01, time/batch = 15.4701s	
20989/28500 (epoch 36.823), train_loss = 0.94088687, grad/param norm = 2.4128e-01, time/batch = 15.4267s	
20990/28500 (epoch 36.825), train_loss = 0.77347426, grad/param norm = 2.1440e-01, time/batch = 15.1260s	
20991/28500 (epoch 36.826), train_loss = 0.83920522, grad/param norm = 1.7428e-01, time/batch = 15.1678s	
20992/28500 (epoch 36.828), train_loss = 0.75223443, grad/param norm = 2.0596e-01, time/batch = 15.5434s	
20993/28500 (epoch 36.830), train_loss = 0.77325419, grad/param norm = 1.4595e-01, time/batch = 15.4662s	
20994/28500 (epoch 36.832), train_loss = 0.80534649, grad/param norm = 2.1549e-01, time/batch = 15.4732s	
20995/28500 (epoch 36.833), train_loss = 0.87523380, grad/param norm = 1.7389e-01, time/batch = 15.2956s	
20996/28500 (epoch 36.835), train_loss = 0.78512015, grad/param norm = 1.9471e-01, time/batch = 14.9185s	
20997/28500 (epoch 36.837), train_loss = 0.70035203, grad/param norm = 1.8836e-01, time/batch = 15.3933s	
20998/28500 (epoch 36.839), train_loss = 0.99074660, grad/param norm = 2.4079e-01, time/batch = 15.2239s	
20999/28500 (epoch 36.840), train_loss = 0.96904127, grad/param norm = 2.1955e-01, time/batch = 15.2401s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch36.84_1.9341.t7	
21000/28500 (epoch 36.842), train_loss = 0.89665976, grad/param norm = 2.6552e-01, time/batch = 15.0639s	
21001/28500 (epoch 36.844), train_loss = 1.26601688, grad/param norm = 2.6844e-01, time/batch = 15.7193s	
21002/28500 (epoch 36.846), train_loss = 1.01645841, grad/param norm = 2.8404e-01, time/batch = 15.3053s	
21003/28500 (epoch 36.847), train_loss = 0.80875753, grad/param norm = 2.0201e-01, time/batch = 15.3293s	
21004/28500 (epoch 36.849), train_loss = 0.79628818, grad/param norm = 1.7758e-01, time/batch = 15.5278s	
21005/28500 (epoch 36.851), train_loss = 0.76156535, grad/param norm = 1.8011e-01, time/batch = 15.4523s	
21006/28500 (epoch 36.853), train_loss = 0.85426246, grad/param norm = 2.4275e-01, time/batch = 15.5401s	
21007/28500 (epoch 36.854), train_loss = 0.86976748, grad/param norm = 1.9781e-01, time/batch = 15.3096s	
21008/28500 (epoch 36.856), train_loss = 0.92855951, grad/param norm = 2.1678e-01, time/batch = 15.4346s	
21009/28500 (epoch 36.858), train_loss = 0.80017612, grad/param norm = 1.9638e-01, time/batch = 15.4560s	
21010/28500 (epoch 36.860), train_loss = 0.82855408, grad/param norm = 2.1344e-01, time/batch = 15.6166s	
21011/28500 (epoch 36.861), train_loss = 0.89449047, grad/param norm = 1.9196e-01, time/batch = 15.3327s	
21012/28500 (epoch 36.863), train_loss = 0.87275782, grad/param norm = 2.4483e-01, time/batch = 15.4668s	
21013/28500 (epoch 36.865), train_loss = 0.78590144, grad/param norm = 1.9331e-01, time/batch = 15.4669s	
21014/28500 (epoch 36.867), train_loss = 0.87326522, grad/param norm = 2.1292e-01, time/batch = 15.5362s	
21015/28500 (epoch 36.868), train_loss = 0.74543194, grad/param norm = 1.7213e-01, time/batch = 15.3118s	
21016/28500 (epoch 36.870), train_loss = 0.71045793, grad/param norm = 1.7232e-01, time/batch = 15.2457s	
21017/28500 (epoch 36.872), train_loss = 0.87668153, grad/param norm = 1.9468e-01, time/batch = 15.3803s	
21018/28500 (epoch 36.874), train_loss = 0.75628440, grad/param norm = 2.1606e-01, time/batch = 15.2311s	
21019/28500 (epoch 36.875), train_loss = 0.96519412, grad/param norm = 2.2983e-01, time/batch = 15.5544s	
21020/28500 (epoch 36.877), train_loss = 0.85477199, grad/param norm = 1.9788e-01, time/batch = 15.6313s	
21021/28500 (epoch 36.879), train_loss = 0.89653301, grad/param norm = 1.6190e-01, time/batch = 15.6169s	
21022/28500 (epoch 36.881), train_loss = 0.87510263, grad/param norm = 1.8520e-01, time/batch = 15.5541s	
21023/28500 (epoch 36.882), train_loss = 0.76197625, grad/param norm = 1.5494e-01, time/batch = 15.6238s	
21024/28500 (epoch 36.884), train_loss = 0.80877368, grad/param norm = 1.8242e-01, time/batch = 15.2385s	
21025/28500 (epoch 36.886), train_loss = 0.78472014, grad/param norm = 1.7807e-01, time/batch = 15.0782s	
21026/28500 (epoch 36.888), train_loss = 0.77817467, grad/param norm = 1.5257e-01, time/batch = 15.0763s	
21027/28500 (epoch 36.889), train_loss = 0.83528013, grad/param norm = 1.6329e-01, time/batch = 15.0483s	
21028/28500 (epoch 36.891), train_loss = 0.82459370, grad/param norm = 1.6685e-01, time/batch = 15.4436s	
21029/28500 (epoch 36.893), train_loss = 0.79933456, grad/param norm = 1.8904e-01, time/batch = 15.4901s	
21030/28500 (epoch 36.895), train_loss = 0.97528142, grad/param norm = 2.2481e-01, time/batch = 15.4601s	
21031/28500 (epoch 36.896), train_loss = 0.93329022, grad/param norm = 2.1300e-01, time/batch = 15.4627s	
21032/28500 (epoch 36.898), train_loss = 0.88002047, grad/param norm = 1.9556e-01, time/batch = 15.1774s	
21033/28500 (epoch 36.900), train_loss = 0.72841193, grad/param norm = 1.5207e-01, time/batch = 15.4996s	
21034/28500 (epoch 36.902), train_loss = 0.70414845, grad/param norm = 1.9745e-01, time/batch = 15.2849s	
21035/28500 (epoch 36.904), train_loss = 0.72525989, grad/param norm = 1.4585e-01, time/batch = 15.2449s	
21036/28500 (epoch 36.905), train_loss = 0.78996715, grad/param norm = 2.0410e-01, time/batch = 15.3582s	
21037/28500 (epoch 36.907), train_loss = 0.82771202, grad/param norm = 1.7816e-01, time/batch = 15.6164s	
21038/28500 (epoch 36.909), train_loss = 0.71396557, grad/param norm = 2.5277e-01, time/batch = 15.4633s	
21039/28500 (epoch 36.911), train_loss = 0.74278345, grad/param norm = 1.6243e-01, time/batch = 15.1393s	
21040/28500 (epoch 36.912), train_loss = 0.61868555, grad/param norm = 1.5394e-01, time/batch = 15.1935s	
21041/28500 (epoch 36.914), train_loss = 0.84734099, grad/param norm = 1.8944e-01, time/batch = 15.3453s	
21042/28500 (epoch 36.916), train_loss = 0.84171283, grad/param norm = 1.9356e-01, time/batch = 15.5416s	
21043/28500 (epoch 36.918), train_loss = 0.81714847, grad/param norm = 1.9965e-01, time/batch = 15.5469s	
21044/28500 (epoch 36.919), train_loss = 0.83426978, grad/param norm = 1.8016e-01, time/batch = 15.5484s	
21045/28500 (epoch 36.921), train_loss = 0.93450607, grad/param norm = 2.4942e-01, time/batch = 15.5022s	
21046/28500 (epoch 36.923), train_loss = 0.78346753, grad/param norm = 2.0590e-01, time/batch = 15.1357s	
21047/28500 (epoch 36.925), train_loss = 0.77160270, grad/param norm = 2.1372e-01, time/batch = 15.1973s	
21048/28500 (epoch 36.926), train_loss = 0.84511239, grad/param norm = 1.9436e-01, time/batch = 15.6069s	
21049/28500 (epoch 36.928), train_loss = 0.78551513, grad/param norm = 1.8577e-01, time/batch = 15.2206s	
21050/28500 (epoch 36.930), train_loss = 0.65000327, grad/param norm = 1.4856e-01, time/batch = 15.2442s	
21051/28500 (epoch 36.932), train_loss = 0.67138797, grad/param norm = 1.4670e-01, time/batch = 15.4212s	
21052/28500 (epoch 36.933), train_loss = 0.89117253, grad/param norm = 1.9275e-01, time/batch = 15.3052s	
21053/28500 (epoch 36.935), train_loss = 0.91407321, grad/param norm = 1.7671e-01, time/batch = 15.2307s	
21054/28500 (epoch 36.937), train_loss = 0.92016020, grad/param norm = 2.2065e-01, time/batch = 15.2273s	
21055/28500 (epoch 36.939), train_loss = 0.93929830, grad/param norm = 1.9695e-01, time/batch = 15.5424s	
21056/28500 (epoch 36.940), train_loss = 0.68107075, grad/param norm = 1.7327e-01, time/batch = 15.4114s	
21057/28500 (epoch 36.942), train_loss = 0.82625619, grad/param norm = 2.0602e-01, time/batch = 15.1385s	
21058/28500 (epoch 36.944), train_loss = 0.78591412, grad/param norm = 1.8118e-01, time/batch = 15.3628s	
21059/28500 (epoch 36.946), train_loss = 0.88958624, grad/param norm = 1.7072e-01, time/batch = 15.5414s	
21060/28500 (epoch 36.947), train_loss = 1.04864281, grad/param norm = 2.5181e-01, time/batch = 15.5652s	
21061/28500 (epoch 36.949), train_loss = 0.82735568, grad/param norm = 2.2516e-01, time/batch = 15.7207s	
21062/28500 (epoch 36.951), train_loss = 0.98517549, grad/param norm = 2.1291e-01, time/batch = 15.5159s	
21063/28500 (epoch 36.953), train_loss = 0.98887185, grad/param norm = 2.3829e-01, time/batch = 15.6527s	
21064/28500 (epoch 36.954), train_loss = 0.92823052, grad/param norm = 2.1680e-01, time/batch = 15.4695s	
21065/28500 (epoch 36.956), train_loss = 0.85024012, grad/param norm = 2.5465e-01, time/batch = 15.3116s	
21066/28500 (epoch 36.958), train_loss = 1.06905069, grad/param norm = 2.1192e-01, time/batch = 15.3742s	
21067/28500 (epoch 36.960), train_loss = 0.78425858, grad/param norm = 2.1724e-01, time/batch = 15.2056s	
21068/28500 (epoch 36.961), train_loss = 0.97841468, grad/param norm = 2.0679e-01, time/batch = 15.0678s	
21069/28500 (epoch 36.963), train_loss = 0.91202946, grad/param norm = 1.9623e-01, time/batch = 15.2481s	
21070/28500 (epoch 36.965), train_loss = 0.77181951, grad/param norm = 2.0140e-01, time/batch = 15.1723s	
21071/28500 (epoch 36.967), train_loss = 0.80093149, grad/param norm = 1.7282e-01, time/batch = 15.6010s	
21072/28500 (epoch 36.968), train_loss = 0.71863125, grad/param norm = 1.6116e-01, time/batch = 15.3116s	
21073/28500 (epoch 36.970), train_loss = 0.78225752, grad/param norm = 2.3186e-01, time/batch = 15.3266s	
21074/28500 (epoch 36.972), train_loss = 0.84674676, grad/param norm = 1.8626e-01, time/batch = 15.2097s	
21075/28500 (epoch 36.974), train_loss = 1.01995416, grad/param norm = 2.1033e-01, time/batch = 15.2216s	
21076/28500 (epoch 36.975), train_loss = 0.77713532, grad/param norm = 1.7330e-01, time/batch = 15.4450s	
21077/28500 (epoch 36.977), train_loss = 0.91068739, grad/param norm = 1.8763e-01, time/batch = 15.3658s	
21078/28500 (epoch 36.979), train_loss = 0.86073183, grad/param norm = 1.7330e-01, time/batch = 15.1114s	
21079/28500 (epoch 36.981), train_loss = 0.72208655, grad/param norm = 1.7122e-01, time/batch = 14.7386s	
21080/28500 (epoch 36.982), train_loss = 0.81636929, grad/param norm = 1.8967e-01, time/batch = 14.9764s	
21081/28500 (epoch 36.984), train_loss = 0.90806864, grad/param norm = 1.8691e-01, time/batch = 15.3134s	
21082/28500 (epoch 36.986), train_loss = 1.07730236, grad/param norm = 2.1125e-01, time/batch = 15.3998s	
21083/28500 (epoch 36.988), train_loss = 0.75387194, grad/param norm = 1.8084e-01, time/batch = 15.1782s	
21084/28500 (epoch 36.989), train_loss = 0.86411285, grad/param norm = 1.8128e-01, time/batch = 15.4749s	
21085/28500 (epoch 36.991), train_loss = 0.77946768, grad/param norm = 2.0419e-01, time/batch = 15.3624s	
21086/28500 (epoch 36.993), train_loss = 0.74097446, grad/param norm = 1.8376e-01, time/batch = 25.6508s	
21087/28500 (epoch 36.995), train_loss = 0.78430726, grad/param norm = 1.8382e-01, time/batch = 17.3577s	
21088/28500 (epoch 36.996), train_loss = 0.72897452, grad/param norm = 1.8878e-01, time/batch = 15.6248s	
21089/28500 (epoch 36.998), train_loss = 0.94547585, grad/param norm = 2.4471e-01, time/batch = 15.5516s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
21090/28500 (epoch 37.000), train_loss = 0.80566912, grad/param norm = 2.0149e-01, time/batch = 15.7269s	
21091/28500 (epoch 37.002), train_loss = 0.98163915, grad/param norm = 2.0036e-01, time/batch = 15.5575s	
21092/28500 (epoch 37.004), train_loss = 0.83895278, grad/param norm = 1.7162e-01, time/batch = 15.4854s	
21093/28500 (epoch 37.005), train_loss = 0.93870581, grad/param norm = 2.1899e-01, time/batch = 15.5401s	
21094/28500 (epoch 37.007), train_loss = 0.74042393, grad/param norm = 1.6147e-01, time/batch = 15.5336s	
21095/28500 (epoch 37.009), train_loss = 0.87630304, grad/param norm = 2.1005e-01, time/batch = 15.5781s	
21096/28500 (epoch 37.011), train_loss = 0.77323948, grad/param norm = 1.7600e-01, time/batch = 15.3558s	
21097/28500 (epoch 37.012), train_loss = 0.75914687, grad/param norm = 1.6081e-01, time/batch = 15.4651s	
21098/28500 (epoch 37.014), train_loss = 0.74287886, grad/param norm = 2.2802e-01, time/batch = 15.1978s	
21099/28500 (epoch 37.016), train_loss = 0.79560691, grad/param norm = 1.6636e-01, time/batch = 15.4943s	
21100/28500 (epoch 37.018), train_loss = 0.88203978, grad/param norm = 2.0694e-01, time/batch = 15.2198s	
21101/28500 (epoch 37.019), train_loss = 0.91860622, grad/param norm = 1.8291e-01, time/batch = 15.4470s	
21102/28500 (epoch 37.021), train_loss = 0.94847640, grad/param norm = 1.7422e-01, time/batch = 15.1552s	
21103/28500 (epoch 37.023), train_loss = 0.86671268, grad/param norm = 1.9593e-01, time/batch = 15.0637s	
21104/28500 (epoch 37.025), train_loss = 0.85410333, grad/param norm = 1.7712e-01, time/batch = 15.2182s	
21105/28500 (epoch 37.026), train_loss = 0.80765121, grad/param norm = 1.7514e-01, time/batch = 15.0350s	
21106/28500 (epoch 37.028), train_loss = 0.86045692, grad/param norm = 1.8842e-01, time/batch = 15.2166s	
21107/28500 (epoch 37.030), train_loss = 0.87354345, grad/param norm = 1.9986e-01, time/batch = 15.1324s	
21108/28500 (epoch 37.032), train_loss = 0.95869556, grad/param norm = 2.1592e-01, time/batch = 15.1078s	
21109/28500 (epoch 37.033), train_loss = 0.99806668, grad/param norm = 2.1461e-01, time/batch = 15.3984s	
21110/28500 (epoch 37.035), train_loss = 0.83027534, grad/param norm = 1.9965e-01, time/batch = 15.3565s	
21111/28500 (epoch 37.037), train_loss = 0.88896995, grad/param norm = 1.7126e-01, time/batch = 15.5030s	
21112/28500 (epoch 37.039), train_loss = 0.96243169, grad/param norm = 2.1282e-01, time/batch = 15.0506s	
21113/28500 (epoch 37.040), train_loss = 0.98090294, grad/param norm = 1.9947e-01, time/batch = 15.3011s	
21114/28500 (epoch 37.042), train_loss = 0.91133231, grad/param norm = 1.7769e-01, time/batch = 15.2052s	
21115/28500 (epoch 37.044), train_loss = 0.86536367, grad/param norm = 2.3231e-01, time/batch = 15.2234s	
21116/28500 (epoch 37.046), train_loss = 1.04718243, grad/param norm = 1.9278e-01, time/batch = 15.3750s	
21117/28500 (epoch 37.047), train_loss = 0.99580272, grad/param norm = 2.1282e-01, time/batch = 15.3792s	
21118/28500 (epoch 37.049), train_loss = 0.87516273, grad/param norm = 1.9622e-01, time/batch = 15.2931s	
21119/28500 (epoch 37.051), train_loss = 0.86860804, grad/param norm = 2.3139e-01, time/batch = 15.2955s	
21120/28500 (epoch 37.053), train_loss = 0.82679497, grad/param norm = 1.9280e-01, time/batch = 15.2925s	
21121/28500 (epoch 37.054), train_loss = 0.92989109, grad/param norm = 2.0676e-01, time/batch = 15.6053s	
21122/28500 (epoch 37.056), train_loss = 0.79352350, grad/param norm = 1.6591e-01, time/batch = 15.4971s	
21123/28500 (epoch 37.058), train_loss = 0.78806938, grad/param norm = 1.6566e-01, time/batch = 15.6262s	
21124/28500 (epoch 37.060), train_loss = 0.89791991, grad/param norm = 2.0170e-01, time/batch = 15.5446s	
21125/28500 (epoch 37.061), train_loss = 0.82847166, grad/param norm = 1.9801e-01, time/batch = 15.1990s	
21126/28500 (epoch 37.063), train_loss = 0.90794276, grad/param norm = 2.0390e-01, time/batch = 15.2331s	
21127/28500 (epoch 37.065), train_loss = 0.86660557, grad/param norm = 1.9269e-01, time/batch = 15.0204s	
21128/28500 (epoch 37.067), train_loss = 0.79201067, grad/param norm = 1.8120e-01, time/batch = 15.1228s	
21129/28500 (epoch 37.068), train_loss = 0.82381444, grad/param norm = 1.9053e-01, time/batch = 15.2213s	
21130/28500 (epoch 37.070), train_loss = 0.89491998, grad/param norm = 2.0613e-01, time/batch = 15.2167s	
21131/28500 (epoch 37.072), train_loss = 0.97685966, grad/param norm = 2.2748e-01, time/batch = 15.4552s	
21132/28500 (epoch 37.074), train_loss = 0.84950862, grad/param norm = 1.9236e-01, time/batch = 15.4528s	
21133/28500 (epoch 37.075), train_loss = 0.83512487, grad/param norm = 2.0034e-01, time/batch = 15.2337s	
21134/28500 (epoch 37.077), train_loss = 0.91030743, grad/param norm = 1.8518e-01, time/batch = 15.1368s	
21135/28500 (epoch 37.079), train_loss = 0.85902225, grad/param norm = 1.7074e-01, time/batch = 15.4915s	
21136/28500 (epoch 37.081), train_loss = 0.95708261, grad/param norm = 2.1337e-01, time/batch = 15.5075s	
21137/28500 (epoch 37.082), train_loss = 0.84866225, grad/param norm = 2.1750e-01, time/batch = 15.2368s	
21138/28500 (epoch 37.084), train_loss = 0.88347175, grad/param norm = 2.1175e-01, time/batch = 15.4249s	
21139/28500 (epoch 37.086), train_loss = 0.82057145, grad/param norm = 1.8677e-01, time/batch = 15.3933s	
21140/28500 (epoch 37.088), train_loss = 0.76154284, grad/param norm = 1.8455e-01, time/batch = 15.1479s	
21141/28500 (epoch 37.089), train_loss = 0.93696291, grad/param norm = 2.1887e-01, time/batch = 15.4933s	
21142/28500 (epoch 37.091), train_loss = 0.76343565, grad/param norm = 1.7520e-01, time/batch = 15.4679s	
21143/28500 (epoch 37.093), train_loss = 0.93533544, grad/param norm = 1.7842e-01, time/batch = 15.5879s	
21144/28500 (epoch 37.095), train_loss = 0.85151697, grad/param norm = 1.7760e-01, time/batch = 15.6326s	
21145/28500 (epoch 37.096), train_loss = 0.94890105, grad/param norm = 1.8484e-01, time/batch = 15.6346s	
21146/28500 (epoch 37.098), train_loss = 0.88300727, grad/param norm = 2.5197e-01, time/batch = 15.0565s	
21147/28500 (epoch 37.100), train_loss = 0.82059616, grad/param norm = 1.7508e-01, time/batch = 15.1060s	
21148/28500 (epoch 37.102), train_loss = 0.94213476, grad/param norm = 2.2063e-01, time/batch = 15.1152s	
21149/28500 (epoch 37.104), train_loss = 0.86756791, grad/param norm = 1.9565e-01, time/batch = 15.1432s	
21150/28500 (epoch 37.105), train_loss = 0.95931527, grad/param norm = 1.7405e-01, time/batch = 15.0401s	
21151/28500 (epoch 37.107), train_loss = 0.78596082, grad/param norm = 1.9037e-01, time/batch = 15.2065s	
21152/28500 (epoch 37.109), train_loss = 0.82239807, grad/param norm = 2.2431e-01, time/batch = 15.0472s	
21153/28500 (epoch 37.111), train_loss = 0.81452409, grad/param norm = 1.9014e-01, time/batch = 14.8995s	
21154/28500 (epoch 37.112), train_loss = 0.90678735, grad/param norm = 1.8465e-01, time/batch = 15.0573s	
21155/28500 (epoch 37.114), train_loss = 0.84461164, grad/param norm = 1.8970e-01, time/batch = 15.2032s	
21156/28500 (epoch 37.116), train_loss = 0.99533354, grad/param norm = 2.1266e-01, time/batch = 15.3182s	
21157/28500 (epoch 37.118), train_loss = 0.75819770, grad/param norm = 1.6758e-01, time/batch = 15.3010s	
21158/28500 (epoch 37.119), train_loss = 0.87777081, grad/param norm = 2.0097e-01, time/batch = 15.3800s	
21159/28500 (epoch 37.121), train_loss = 1.01886293, grad/param norm = 2.3206e-01, time/batch = 15.2045s	
21160/28500 (epoch 37.123), train_loss = 0.93861225, grad/param norm = 1.8607e-01, time/batch = 15.3771s	
21161/28500 (epoch 37.125), train_loss = 0.87892000, grad/param norm = 1.9597e-01, time/batch = 15.5082s	
21162/28500 (epoch 37.126), train_loss = 0.84764726, grad/param norm = 1.8592e-01, time/batch = 15.3413s	
21163/28500 (epoch 37.128), train_loss = 0.86483235, grad/param norm = 1.8652e-01, time/batch = 15.4253s	
21164/28500 (epoch 37.130), train_loss = 0.81717549, grad/param norm = 2.0326e-01, time/batch = 15.3067s	
21165/28500 (epoch 37.132), train_loss = 0.85884378, grad/param norm = 1.9232e-01, time/batch = 15.0435s	
21166/28500 (epoch 37.133), train_loss = 0.92244426, grad/param norm = 2.2221e-01, time/batch = 15.2991s	
21167/28500 (epoch 37.135), train_loss = 0.82736665, grad/param norm = 1.7729e-01, time/batch = 15.4619s	
21168/28500 (epoch 37.137), train_loss = 0.88054356, grad/param norm = 1.8596e-01, time/batch = 15.3120s	
21169/28500 (epoch 37.139), train_loss = 0.87715559, grad/param norm = 1.8639e-01, time/batch = 15.2289s	
21170/28500 (epoch 37.140), train_loss = 0.85463129, grad/param norm = 1.8338e-01, time/batch = 15.2261s	
21171/28500 (epoch 37.142), train_loss = 0.81501306, grad/param norm = 2.2538e-01, time/batch = 15.4765s	
21172/28500 (epoch 37.144), train_loss = 0.75977257, grad/param norm = 1.6810e-01, time/batch = 15.5291s	
21173/28500 (epoch 37.146), train_loss = 0.83859194, grad/param norm = 1.8783e-01, time/batch = 15.2870s	
21174/28500 (epoch 37.147), train_loss = 0.72831699, grad/param norm = 1.6700e-01, time/batch = 15.3135s	
21175/28500 (epoch 37.149), train_loss = 0.73313599, grad/param norm = 1.6174e-01, time/batch = 15.3035s	
21176/28500 (epoch 37.151), train_loss = 0.82432233, grad/param norm = 1.8314e-01, time/batch = 15.1813s	
21177/28500 (epoch 37.153), train_loss = 0.87988011, grad/param norm = 1.8714e-01, time/batch = 15.0551s	
21178/28500 (epoch 37.154), train_loss = 0.73972462, grad/param norm = 1.7649e-01, time/batch = 15.1228s	
21179/28500 (epoch 37.156), train_loss = 0.92222258, grad/param norm = 2.0074e-01, time/batch = 15.5589s	
21180/28500 (epoch 37.158), train_loss = 0.88256200, grad/param norm = 1.8697e-01, time/batch = 15.4792s	
21181/28500 (epoch 37.160), train_loss = 0.77102682, grad/param norm = 1.7898e-01, time/batch = 15.3751s	
21182/28500 (epoch 37.161), train_loss = 0.80093706, grad/param norm = 2.1707e-01, time/batch = 15.6112s	
21183/28500 (epoch 37.163), train_loss = 0.72849701, grad/param norm = 1.7916e-01, time/batch = 15.3088s	
21184/28500 (epoch 37.165), train_loss = 0.99559267, grad/param norm = 1.7700e-01, time/batch = 15.2330s	
21185/28500 (epoch 37.167), train_loss = 1.00199031, grad/param norm = 1.9325e-01, time/batch = 15.2296s	
21186/28500 (epoch 37.168), train_loss = 0.96056236, grad/param norm = 2.4270e-01, time/batch = 15.1342s	
21187/28500 (epoch 37.170), train_loss = 0.95758503, grad/param norm = 2.3481e-01, time/batch = 15.0539s	
21188/28500 (epoch 37.172), train_loss = 0.83172490, grad/param norm = 1.5643e-01, time/batch = 15.1425s	
21189/28500 (epoch 37.174), train_loss = 0.99892009, grad/param norm = 2.6892e-01, time/batch = 15.4035s	
21190/28500 (epoch 37.175), train_loss = 0.83398395, grad/param norm = 1.7016e-01, time/batch = 15.4827s	
21191/28500 (epoch 37.177), train_loss = 0.92279880, grad/param norm = 2.1845e-01, time/batch = 15.3823s	
21192/28500 (epoch 37.179), train_loss = 0.94513558, grad/param norm = 1.9062e-01, time/batch = 15.3122s	
21193/28500 (epoch 37.181), train_loss = 0.89722625, grad/param norm = 2.0019e-01, time/batch = 15.2945s	
21194/28500 (epoch 37.182), train_loss = 0.81838364, grad/param norm = 1.8714e-01, time/batch = 15.1893s	
21195/28500 (epoch 37.184), train_loss = 1.03049692, grad/param norm = 2.1355e-01, time/batch = 15.4531s	
21196/28500 (epoch 37.186), train_loss = 0.98357589, grad/param norm = 2.1101e-01, time/batch = 15.5219s	
21197/28500 (epoch 37.188), train_loss = 0.91639569, grad/param norm = 2.0545e-01, time/batch = 15.5714s	
21198/28500 (epoch 37.189), train_loss = 0.86659711, grad/param norm = 1.6734e-01, time/batch = 15.4378s	
21199/28500 (epoch 37.191), train_loss = 1.05836993, grad/param norm = 1.9892e-01, time/batch = 15.3118s	
21200/28500 (epoch 37.193), train_loss = 0.90031737, grad/param norm = 2.3216e-01, time/batch = 15.0524s	
21201/28500 (epoch 37.195), train_loss = 0.99825604, grad/param norm = 2.0697e-01, time/batch = 15.4628s	
21202/28500 (epoch 37.196), train_loss = 0.90512095, grad/param norm = 1.9029e-01, time/batch = 15.4085s	
21203/28500 (epoch 37.198), train_loss = 0.87989354, grad/param norm = 2.0674e-01, time/batch = 15.3540s	
21204/28500 (epoch 37.200), train_loss = 0.93535272, grad/param norm = 1.7466e-01, time/batch = 15.5239s	
21205/28500 (epoch 37.202), train_loss = 0.88551352, grad/param norm = 1.7912e-01, time/batch = 15.4328s	
21206/28500 (epoch 37.204), train_loss = 0.85808401, grad/param norm = 1.7119e-01, time/batch = 15.1188s	
21207/28500 (epoch 37.205), train_loss = 0.80695054, grad/param norm = 1.7377e-01, time/batch = 15.0374s	
21208/28500 (epoch 37.207), train_loss = 0.73470306, grad/param norm = 1.6664e-01, time/batch = 15.1962s	
21209/28500 (epoch 37.209), train_loss = 0.89935109, grad/param norm = 1.9510e-01, time/batch = 15.4391s	
21210/28500 (epoch 37.211), train_loss = 0.78653238, grad/param norm = 1.7224e-01, time/batch = 15.5366s	
21211/28500 (epoch 37.212), train_loss = 0.72143973, grad/param norm = 1.7935e-01, time/batch = 15.4203s	
21212/28500 (epoch 37.214), train_loss = 0.86247457, grad/param norm = 1.8106e-01, time/batch = 15.5350s	
21213/28500 (epoch 37.216), train_loss = 0.79416354, grad/param norm = 1.8828e-01, time/batch = 15.4813s	
21214/28500 (epoch 37.218), train_loss = 0.97116509, grad/param norm = 1.8207e-01, time/batch = 15.5414s	
21215/28500 (epoch 37.219), train_loss = 0.89727971, grad/param norm = 2.3139e-01, time/batch = 15.5074s	
21216/28500 (epoch 37.221), train_loss = 0.74104577, grad/param norm = 1.8932e-01, time/batch = 15.3413s	
21217/28500 (epoch 37.223), train_loss = 0.96827155, grad/param norm = 2.0857e-01, time/batch = 15.1315s	
21218/28500 (epoch 37.225), train_loss = 1.00092361, grad/param norm = 2.1031e-01, time/batch = 15.1166s	
21219/28500 (epoch 37.226), train_loss = 0.83420180, grad/param norm = 1.8612e-01, time/batch = 14.9881s	
21220/28500 (epoch 37.228), train_loss = 0.93395178, grad/param norm = 1.7875e-01, time/batch = 15.0546s	
21221/28500 (epoch 37.230), train_loss = 0.92752503, grad/param norm = 1.8318e-01, time/batch = 15.2737s	
21222/28500 (epoch 37.232), train_loss = 0.91952321, grad/param norm = 1.8935e-01, time/batch = 15.4611s	
21223/28500 (epoch 37.233), train_loss = 0.85896052, grad/param norm = 2.0891e-01, time/batch = 15.4523s	
21224/28500 (epoch 37.235), train_loss = 0.85768143, grad/param norm = 1.7614e-01, time/batch = 15.5372s	
21225/28500 (epoch 37.237), train_loss = 0.76845933, grad/param norm = 1.4848e-01, time/batch = 15.4912s	
21226/28500 (epoch 37.239), train_loss = 0.82427398, grad/param norm = 1.8137e-01, time/batch = 15.4541s	
21227/28500 (epoch 37.240), train_loss = 0.75359961, grad/param norm = 1.6050e-01, time/batch = 15.3837s	
21228/28500 (epoch 37.242), train_loss = 0.80624369, grad/param norm = 1.8277e-01, time/batch = 15.2087s	
21229/28500 (epoch 37.244), train_loss = 0.89936441, grad/param norm = 1.8674e-01, time/batch = 15.3183s	
21230/28500 (epoch 37.246), train_loss = 0.90137357, grad/param norm = 1.8038e-01, time/batch = 15.0456s	
21231/28500 (epoch 37.247), train_loss = 0.99059911, grad/param norm = 2.1623e-01, time/batch = 15.1664s	
21232/28500 (epoch 37.249), train_loss = 0.83822334, grad/param norm = 1.6814e-01, time/batch = 15.2695s	
21233/28500 (epoch 37.251), train_loss = 0.84446105, grad/param norm = 1.6885e-01, time/batch = 15.2164s	
21234/28500 (epoch 37.253), train_loss = 1.00509365, grad/param norm = 2.3055e-01, time/batch = 15.3035s	
21235/28500 (epoch 37.254), train_loss = 1.00627064, grad/param norm = 1.7747e-01, time/batch = 15.4784s	
21236/28500 (epoch 37.256), train_loss = 0.84260028, grad/param norm = 1.7805e-01, time/batch = 15.5631s	
21237/28500 (epoch 37.258), train_loss = 0.84531924, grad/param norm = 1.8974e-01, time/batch = 15.5891s	
21238/28500 (epoch 37.260), train_loss = 0.84324811, grad/param norm = 1.6875e-01, time/batch = 15.3831s	
21239/28500 (epoch 37.261), train_loss = 0.75786692, grad/param norm = 1.9222e-01, time/batch = 15.3823s	
21240/28500 (epoch 37.263), train_loss = 0.94689117, grad/param norm = 2.3753e-01, time/batch = 15.1239s	
21241/28500 (epoch 37.265), train_loss = 0.80330941, grad/param norm = 1.6574e-01, time/batch = 15.5311s	
21242/28500 (epoch 37.267), train_loss = 0.98623506, grad/param norm = 1.9806e-01, time/batch = 15.4144s	
21243/28500 (epoch 37.268), train_loss = 0.89836050, grad/param norm = 1.6107e-01, time/batch = 15.4604s	
21244/28500 (epoch 37.270), train_loss = 0.83519992, grad/param norm = 1.7915e-01, time/batch = 15.5378s	
21245/28500 (epoch 37.272), train_loss = 0.87631824, grad/param norm = 1.7695e-01, time/batch = 15.4378s	
21246/28500 (epoch 37.274), train_loss = 0.91035048, grad/param norm = 1.8457e-01, time/batch = 15.3176s	
21247/28500 (epoch 37.275), train_loss = 0.92382914, grad/param norm = 1.7563e-01, time/batch = 15.3872s	
21248/28500 (epoch 37.277), train_loss = 0.85393491, grad/param norm = 1.9494e-01, time/batch = 15.3813s	
21249/28500 (epoch 37.279), train_loss = 0.88125242, grad/param norm = 2.1469e-01, time/batch = 15.5413s	
21250/28500 (epoch 37.281), train_loss = 0.91633695, grad/param norm = 2.1478e-01, time/batch = 15.5532s	
21251/28500 (epoch 37.282), train_loss = 0.83081174, grad/param norm = 1.5837e-01, time/batch = 15.3934s	
21252/28500 (epoch 37.284), train_loss = 0.87606313, grad/param norm = 1.9220e-01, time/batch = 15.2260s	
21253/28500 (epoch 37.286), train_loss = 0.96803234, grad/param norm = 1.9397e-01, time/batch = 15.3252s	
21254/28500 (epoch 37.288), train_loss = 0.86530928, grad/param norm = 1.8049e-01, time/batch = 15.3760s	
21255/28500 (epoch 37.289), train_loss = 0.89361989, grad/param norm = 2.0392e-01, time/batch = 15.3399s	
21256/28500 (epoch 37.291), train_loss = 0.87655912, grad/param norm = 1.8679e-01, time/batch = 15.2411s	
21257/28500 (epoch 37.293), train_loss = 0.87184947, grad/param norm = 1.8074e-01, time/batch = 15.1227s	
21258/28500 (epoch 37.295), train_loss = 0.78010690, grad/param norm = 1.5802e-01, time/batch = 15.1211s	
21259/28500 (epoch 37.296), train_loss = 0.76266473, grad/param norm = 1.5514e-01, time/batch = 15.3720s	
21260/28500 (epoch 37.298), train_loss = 0.93590140, grad/param norm = 1.9811e-01, time/batch = 15.5889s	
21261/28500 (epoch 37.300), train_loss = 0.79347020, grad/param norm = 1.8133e-01, time/batch = 15.6013s	
21262/28500 (epoch 37.302), train_loss = 0.73370109, grad/param norm = 1.5512e-01, time/batch = 15.4410s	
21263/28500 (epoch 37.304), train_loss = 0.85422108, grad/param norm = 1.9783e-01, time/batch = 14.9907s	
21264/28500 (epoch 37.305), train_loss = 0.88533484, grad/param norm = 1.7546e-01, time/batch = 15.0483s	
21265/28500 (epoch 37.307), train_loss = 0.82915838, grad/param norm = 1.9249e-01, time/batch = 15.1204s	
21266/28500 (epoch 37.309), train_loss = 0.84451547, grad/param norm = 1.6810e-01, time/batch = 15.1414s	
21267/28500 (epoch 37.311), train_loss = 0.90420283, grad/param norm = 1.8158e-01, time/batch = 15.2945s	
21268/28500 (epoch 37.312), train_loss = 0.90645551, grad/param norm = 1.7593e-01, time/batch = 15.2059s	
21269/28500 (epoch 37.314), train_loss = 0.91862431, grad/param norm = 1.9847e-01, time/batch = 15.3314s	
21270/28500 (epoch 37.316), train_loss = 0.87381558, grad/param norm = 1.9118e-01, time/batch = 15.2848s	
21271/28500 (epoch 37.318), train_loss = 0.96044585, grad/param norm = 1.8082e-01, time/batch = 15.3097s	
21272/28500 (epoch 37.319), train_loss = 0.81506012, grad/param norm = 1.7499e-01, time/batch = 15.1409s	
21273/28500 (epoch 37.321), train_loss = 0.83612782, grad/param norm = 1.9896e-01, time/batch = 15.3599s	
21274/28500 (epoch 37.323), train_loss = 0.85982824, grad/param norm = 2.2882e-01, time/batch = 15.4743s	
21275/28500 (epoch 37.325), train_loss = 0.99520458, grad/param norm = 1.9736e-01, time/batch = 15.5506s	
21276/28500 (epoch 37.326), train_loss = 0.88413535, grad/param norm = 1.8399e-01, time/batch = 15.6151s	
21277/28500 (epoch 37.328), train_loss = 0.70101974, grad/param norm = 1.5938e-01, time/batch = 15.5472s	
21278/28500 (epoch 37.330), train_loss = 0.79922997, grad/param norm = 1.7951e-01, time/batch = 15.2155s	
21279/28500 (epoch 37.332), train_loss = 0.81915393, grad/param norm = 1.7445e-01, time/batch = 15.2326s	
21280/28500 (epoch 37.333), train_loss = 0.69321464, grad/param norm = 1.8441e-01, time/batch = 15.6726s	
21281/28500 (epoch 37.335), train_loss = 0.75096171, grad/param norm = 1.6791e-01, time/batch = 15.2104s	
21282/28500 (epoch 37.337), train_loss = 0.71384052, grad/param norm = 1.7731e-01, time/batch = 15.4336s	
21283/28500 (epoch 37.339), train_loss = 0.70093231, grad/param norm = 1.4516e-01, time/batch = 15.3609s	
21284/28500 (epoch 37.340), train_loss = 0.85466482, grad/param norm = 2.5174e-01, time/batch = 15.1484s	
21285/28500 (epoch 37.342), train_loss = 0.83471320, grad/param norm = 1.7218e-01, time/batch = 15.4694s	
21286/28500 (epoch 37.344), train_loss = 0.74463331, grad/param norm = 1.7117e-01, time/batch = 15.2247s	
21287/28500 (epoch 37.346), train_loss = 0.72601387, grad/param norm = 1.5893e-01, time/batch = 15.3797s	
21288/28500 (epoch 37.347), train_loss = 0.84122898, grad/param norm = 1.6779e-01, time/batch = 15.2302s	
21289/28500 (epoch 37.349), train_loss = 0.84317671, grad/param norm = 1.7325e-01, time/batch = 15.2682s	
21290/28500 (epoch 37.351), train_loss = 0.75281427, grad/param norm = 1.6963e-01, time/batch = 15.3122s	
21291/28500 (epoch 37.353), train_loss = 0.84136928, grad/param norm = 1.7091e-01, time/batch = 15.3849s	
21292/28500 (epoch 37.354), train_loss = 0.74661255, grad/param norm = 1.7797e-01, time/batch = 15.3953s	
21293/28500 (epoch 37.356), train_loss = 0.80854156, grad/param norm = 1.6986e-01, time/batch = 15.2489s	
21294/28500 (epoch 37.358), train_loss = 0.89412572, grad/param norm = 1.7481e-01, time/batch = 15.3181s	
21295/28500 (epoch 37.360), train_loss = 0.87098252, grad/param norm = 1.8547e-01, time/batch = 15.5870s	
21296/28500 (epoch 37.361), train_loss = 0.76288260, grad/param norm = 1.6279e-01, time/batch = 15.4914s	
21297/28500 (epoch 37.363), train_loss = 0.76217712, grad/param norm = 1.5333e-01, time/batch = 15.0686s	
21298/28500 (epoch 37.365), train_loss = 0.80793424, grad/param norm = 1.8716e-01, time/batch = 15.1090s	
21299/28500 (epoch 37.367), train_loss = 0.84631475, grad/param norm = 1.7501e-01, time/batch = 15.2999s	
21300/28500 (epoch 37.368), train_loss = 0.78399518, grad/param norm = 1.7877e-01, time/batch = 15.5996s	
21301/28500 (epoch 37.370), train_loss = 0.83935443, grad/param norm = 1.8032e-01, time/batch = 15.5564s	
21302/28500 (epoch 37.372), train_loss = 0.68668468, grad/param norm = 1.9499e-01, time/batch = 15.5550s	
21303/28500 (epoch 37.374), train_loss = 0.80451400, grad/param norm = 1.7451e-01, time/batch = 15.5449s	
21304/28500 (epoch 37.375), train_loss = 0.92820756, grad/param norm = 1.9596e-01, time/batch = 15.4834s	
21305/28500 (epoch 37.377), train_loss = 0.76910711, grad/param norm = 2.3372e-01, time/batch = 15.5585s	
21306/28500 (epoch 37.379), train_loss = 0.64579061, grad/param norm = 1.6352e-01, time/batch = 15.4406s	
21307/28500 (epoch 37.381), train_loss = 0.82869849, grad/param norm = 1.7404e-01, time/batch = 15.3831s	
21308/28500 (epoch 37.382), train_loss = 0.79306466, grad/param norm = 1.9433e-01, time/batch = 15.1402s	
21309/28500 (epoch 37.384), train_loss = 0.71090421, grad/param norm = 1.7167e-01, time/batch = 15.2422s	
21310/28500 (epoch 37.386), train_loss = 0.75018281, grad/param norm = 1.7329e-01, time/batch = 15.0469s	
21311/28500 (epoch 37.388), train_loss = 0.91470284, grad/param norm = 1.8171e-01, time/batch = 15.2814s	
21312/28500 (epoch 37.389), train_loss = 0.78108037, grad/param norm = 1.9838e-01, time/batch = 15.0788s	
21313/28500 (epoch 37.391), train_loss = 0.72473343, grad/param norm = 1.7605e-01, time/batch = 15.0632s	
21314/28500 (epoch 37.393), train_loss = 0.75510474, grad/param norm = 1.7889e-01, time/batch = 15.4419s	
21315/28500 (epoch 37.395), train_loss = 0.93027691, grad/param norm = 1.7276e-01, time/batch = 15.6196s	
21316/28500 (epoch 37.396), train_loss = 0.90615042, grad/param norm = 1.8192e-01, time/batch = 15.3999s	
21317/28500 (epoch 37.398), train_loss = 0.62896255, grad/param norm = 1.9461e-01, time/batch = 15.4602s	
21318/28500 (epoch 37.400), train_loss = 0.80623491, grad/param norm = 1.9374e-01, time/batch = 17.4971s	
21319/28500 (epoch 37.402), train_loss = 0.85270295, grad/param norm = 1.9126e-01, time/batch = 25.4870s	
21320/28500 (epoch 37.404), train_loss = 0.84505008, grad/param norm = 1.8280e-01, time/batch = 15.3028s	
21321/28500 (epoch 37.405), train_loss = 0.88859026, grad/param norm = 1.8254e-01, time/batch = 15.5236s	
21322/28500 (epoch 37.407), train_loss = 0.83499173, grad/param norm = 1.7854e-01, time/batch = 15.3386s	
21323/28500 (epoch 37.409), train_loss = 0.84033651, grad/param norm = 1.8569e-01, time/batch = 15.3830s	
21324/28500 (epoch 37.411), train_loss = 0.93741466, grad/param norm = 2.2344e-01, time/batch = 15.5185s	
21325/28500 (epoch 37.412), train_loss = 0.96112553, grad/param norm = 2.0198e-01, time/batch = 15.4759s	
21326/28500 (epoch 37.414), train_loss = 0.85759316, grad/param norm = 1.9887e-01, time/batch = 15.4442s	
21327/28500 (epoch 37.416), train_loss = 0.77770179, grad/param norm = 1.8400e-01, time/batch = 15.3889s	
21328/28500 (epoch 37.418), train_loss = 0.85278363, grad/param norm = 1.6295e-01, time/batch = 15.2208s	
21329/28500 (epoch 37.419), train_loss = 0.94153516, grad/param norm = 2.4067e-01, time/batch = 15.5430s	
21330/28500 (epoch 37.421), train_loss = 0.92434304, grad/param norm = 1.9331e-01, time/batch = 15.3860s	
21331/28500 (epoch 37.423), train_loss = 0.90866634, grad/param norm = 1.9916e-01, time/batch = 15.1217s	
21332/28500 (epoch 37.425), train_loss = 0.83224165, grad/param norm = 2.3812e-01, time/batch = 15.4615s	
21333/28500 (epoch 37.426), train_loss = 0.87058927, grad/param norm = 2.1358e-01, time/batch = 15.3559s	
21334/28500 (epoch 37.428), train_loss = 1.00375232, grad/param norm = 2.2209e-01, time/batch = 15.3358s	
21335/28500 (epoch 37.430), train_loss = 0.97915995, grad/param norm = 1.8181e-01, time/batch = 15.2405s	
21336/28500 (epoch 37.432), train_loss = 0.84638509, grad/param norm = 1.8493e-01, time/batch = 15.0609s	
21337/28500 (epoch 37.433), train_loss = 0.92292264, grad/param norm = 2.3526e-01, time/batch = 15.5501s	
21338/28500 (epoch 37.435), train_loss = 0.87466615, grad/param norm = 1.9317e-01, time/batch = 15.5111s	
21339/28500 (epoch 37.437), train_loss = 0.79898471, grad/param norm = 2.1471e-01, time/batch = 15.5883s	
21340/28500 (epoch 37.439), train_loss = 0.85585324, grad/param norm = 1.6670e-01, time/batch = 15.5612s	
21341/28500 (epoch 37.440), train_loss = 1.01958618, grad/param norm = 2.0226e-01, time/batch = 15.7015s	
21342/28500 (epoch 37.442), train_loss = 0.78666430, grad/param norm = 1.7387e-01, time/batch = 15.3161s	
21343/28500 (epoch 37.444), train_loss = 0.75077967, grad/param norm = 1.5747e-01, time/batch = 15.5160s	
21344/28500 (epoch 37.446), train_loss = 0.72844526, grad/param norm = 1.6584e-01, time/batch = 15.3176s	
21345/28500 (epoch 37.447), train_loss = 0.75109641, grad/param norm = 1.8420e-01, time/batch = 15.5338s	
21346/28500 (epoch 37.449), train_loss = 0.80812936, grad/param norm = 1.7150e-01, time/batch = 15.4319s	
21347/28500 (epoch 37.451), train_loss = 0.81986345, grad/param norm = 1.8076e-01, time/batch = 15.3072s	
21348/28500 (epoch 37.453), train_loss = 0.80654292, grad/param norm = 1.8003e-01, time/batch = 15.5034s	
21349/28500 (epoch 37.454), train_loss = 0.77403074, grad/param norm = 1.6882e-01, time/batch = 15.3809s	
21350/28500 (epoch 37.456), train_loss = 0.91266265, grad/param norm = 2.0916e-01, time/batch = 15.5359s	
21351/28500 (epoch 37.458), train_loss = 0.82116487, grad/param norm = 2.0551e-01, time/batch = 15.6829s	
21352/28500 (epoch 37.460), train_loss = 0.94322014, grad/param norm = 2.1160e-01, time/batch = 15.6243s	
21353/28500 (epoch 37.461), train_loss = 0.76718234, grad/param norm = 2.4577e-01, time/batch = 15.3248s	
21354/28500 (epoch 37.463), train_loss = 0.71299558, grad/param norm = 1.5490e-01, time/batch = 15.2388s	
21355/28500 (epoch 37.465), train_loss = 0.68518237, grad/param norm = 1.8682e-01, time/batch = 15.4009s	
21356/28500 (epoch 37.467), train_loss = 0.84892672, grad/param norm = 1.8374e-01, time/batch = 15.3809s	
21357/28500 (epoch 37.468), train_loss = 0.76259877, grad/param norm = 1.6636e-01, time/batch = 15.2878s	
21358/28500 (epoch 37.470), train_loss = 0.79914534, grad/param norm = 1.8507e-01, time/batch = 15.0442s	
21359/28500 (epoch 37.472), train_loss = 0.76740262, grad/param norm = 1.6981e-01, time/batch = 15.5044s	
21360/28500 (epoch 37.474), train_loss = 0.98010925, grad/param norm = 2.2016e-01, time/batch = 15.4764s	
21361/28500 (epoch 37.475), train_loss = 0.78506486, grad/param norm = 1.6824e-01, time/batch = 15.5079s	
21362/28500 (epoch 37.477), train_loss = 0.82579968, grad/param norm = 1.8581e-01, time/batch = 15.1226s	
21363/28500 (epoch 37.479), train_loss = 0.86937354, grad/param norm = 1.8371e-01, time/batch = 15.2404s	
21364/28500 (epoch 37.481), train_loss = 0.89234309, grad/param norm = 1.7838e-01, time/batch = 15.2950s	
21365/28500 (epoch 37.482), train_loss = 0.73296880, grad/param norm = 2.1404e-01, time/batch = 15.3063s	
21366/28500 (epoch 37.484), train_loss = 0.78346161, grad/param norm = 1.8199e-01, time/batch = 15.2889s	
21367/28500 (epoch 37.486), train_loss = 0.68711947, grad/param norm = 1.7517e-01, time/batch = 15.2398s	
21368/28500 (epoch 37.488), train_loss = 0.87656376, grad/param norm = 1.5903e-01, time/batch = 15.1866s	
21369/28500 (epoch 37.489), train_loss = 0.97485339, grad/param norm = 2.1004e-01, time/batch = 15.3271s	
21370/28500 (epoch 37.491), train_loss = 0.78335850, grad/param norm = 2.0123e-01, time/batch = 15.3654s	
21371/28500 (epoch 37.493), train_loss = 0.81427830, grad/param norm = 2.1649e-01, time/batch = 15.5538s	
21372/28500 (epoch 37.495), train_loss = 0.85671520, grad/param norm = 2.0597e-01, time/batch = 15.6244s	
21373/28500 (epoch 37.496), train_loss = 0.77540231, grad/param norm = 1.9054e-01, time/batch = 15.5595s	
21374/28500 (epoch 37.498), train_loss = 0.79676228, grad/param norm = 1.5308e-01, time/batch = 15.3641s	
21375/28500 (epoch 37.500), train_loss = 0.77121690, grad/param norm = 1.7320e-01, time/batch = 15.4210s	
21376/28500 (epoch 37.502), train_loss = 0.88790582, grad/param norm = 1.6974e-01, time/batch = 15.6411s	
21377/28500 (epoch 37.504), train_loss = 0.89178872, grad/param norm = 1.6668e-01, time/batch = 15.3644s	
21378/28500 (epoch 37.505), train_loss = 0.79047430, grad/param norm = 2.0586e-01, time/batch = 15.4529s	
21379/28500 (epoch 37.507), train_loss = 0.93530991, grad/param norm = 2.4295e-01, time/batch = 15.2920s	
21380/28500 (epoch 37.509), train_loss = 0.84908968, grad/param norm = 1.7103e-01, time/batch = 15.6239s	
21381/28500 (epoch 37.511), train_loss = 0.83195278, grad/param norm = 1.8050e-01, time/batch = 15.5410s	
21382/28500 (epoch 37.512), train_loss = 0.89783056, grad/param norm = 2.1233e-01, time/batch = 15.2932s	
21383/28500 (epoch 37.514), train_loss = 0.82637099, grad/param norm = 1.8189e-01, time/batch = 15.5403s	
21384/28500 (epoch 37.516), train_loss = 0.81578480, grad/param norm = 1.4997e-01, time/batch = 14.9665s	
21385/28500 (epoch 37.518), train_loss = 0.87878553, grad/param norm = 1.7987e-01, time/batch = 15.2965s	
21386/28500 (epoch 37.519), train_loss = 0.87667199, grad/param norm = 1.6970e-01, time/batch = 15.3902s	
21387/28500 (epoch 37.521), train_loss = 0.96374580, grad/param norm = 2.2496e-01, time/batch = 15.3639s	
21388/28500 (epoch 37.523), train_loss = 0.88069911, grad/param norm = 1.9073e-01, time/batch = 15.5630s	
21389/28500 (epoch 37.525), train_loss = 0.95435516, grad/param norm = 1.8857e-01, time/batch = 15.4495s	
21390/28500 (epoch 37.526), train_loss = 0.88908717, grad/param norm = 1.8379e-01, time/batch = 15.2985s	
21391/28500 (epoch 37.528), train_loss = 0.89371883, grad/param norm = 2.0798e-01, time/batch = 15.4560s	
21392/28500 (epoch 37.530), train_loss = 0.89757020, grad/param norm = 1.9078e-01, time/batch = 15.3836s	
21393/28500 (epoch 37.532), train_loss = 0.82265356, grad/param norm = 1.7045e-01, time/batch = 15.0668s	
21394/28500 (epoch 37.533), train_loss = 0.89970861, grad/param norm = 2.3061e-01, time/batch = 15.1525s	
21395/28500 (epoch 37.535), train_loss = 0.71785235, grad/param norm = 1.4038e-01, time/batch = 15.2394s	
21396/28500 (epoch 37.537), train_loss = 0.75782145, grad/param norm = 1.7969e-01, time/batch = 15.1967s	
21397/28500 (epoch 37.539), train_loss = 0.72236569, grad/param norm = 1.7040e-01, time/batch = 15.0499s	
21398/28500 (epoch 37.540), train_loss = 0.83298065, grad/param norm = 1.7408e-01, time/batch = 15.2728s	
21399/28500 (epoch 37.542), train_loss = 0.89350860, grad/param norm = 2.1438e-01, time/batch = 15.3680s	
21400/28500 (epoch 37.544), train_loss = 0.97887722, grad/param norm = 1.9093e-01, time/batch = 14.9039s	
21401/28500 (epoch 37.546), train_loss = 0.83897241, grad/param norm = 1.7286e-01, time/batch = 15.5049s	
21402/28500 (epoch 37.547), train_loss = 0.81916010, grad/param norm = 1.9239e-01, time/batch = 15.4669s	
21403/28500 (epoch 37.549), train_loss = 0.70029085, grad/param norm = 1.4865e-01, time/batch = 15.4584s	
21404/28500 (epoch 37.551), train_loss = 0.79946489, grad/param norm = 2.0239e-01, time/batch = 14.9675s	
21405/28500 (epoch 37.553), train_loss = 1.00015507, grad/param norm = 2.6566e-01, time/batch = 15.4241s	
21406/28500 (epoch 37.554), train_loss = 0.89827212, grad/param norm = 1.9877e-01, time/batch = 15.2866s	
21407/28500 (epoch 37.556), train_loss = 0.88684206, grad/param norm = 1.7432e-01, time/batch = 15.4219s	
21408/28500 (epoch 37.558), train_loss = 0.89331106, grad/param norm = 1.6667e-01, time/batch = 15.3909s	
21409/28500 (epoch 37.560), train_loss = 0.90101966, grad/param norm = 1.9796e-01, time/batch = 15.5430s	
21410/28500 (epoch 37.561), train_loss = 0.90501661, grad/param norm = 1.9888e-01, time/batch = 15.5605s	
21411/28500 (epoch 37.563), train_loss = 0.98487940, grad/param norm = 2.2264e-01, time/batch = 15.7127s	
21412/28500 (epoch 37.565), train_loss = 0.77624711, grad/param norm = 1.7680e-01, time/batch = 15.5606s	
21413/28500 (epoch 37.567), train_loss = 0.73049242, grad/param norm = 2.1735e-01, time/batch = 15.5596s	
21414/28500 (epoch 37.568), train_loss = 0.87362477, grad/param norm = 1.9040e-01, time/batch = 15.7670s	
21415/28500 (epoch 37.570), train_loss = 0.82593634, grad/param norm = 1.9406e-01, time/batch = 15.5022s	
21416/28500 (epoch 37.572), train_loss = 0.86856258, grad/param norm = 1.7736e-01, time/batch = 15.3214s	
21417/28500 (epoch 37.574), train_loss = 0.79872159, grad/param norm = 1.7981e-01, time/batch = 15.4551s	
21418/28500 (epoch 37.575), train_loss = 0.79974950, grad/param norm = 1.7624e-01, time/batch = 15.2882s	
21419/28500 (epoch 37.577), train_loss = 0.91246864, grad/param norm = 1.8609e-01, time/batch = 15.4725s	
21420/28500 (epoch 37.579), train_loss = 0.92205939, grad/param norm = 1.9736e-01, time/batch = 15.4688s	
21421/28500 (epoch 37.581), train_loss = 0.79423046, grad/param norm = 2.0885e-01, time/batch = 15.5516s	
21422/28500 (epoch 37.582), train_loss = 0.95123363, grad/param norm = 2.0808e-01, time/batch = 15.4443s	
21423/28500 (epoch 37.584), train_loss = 0.79358609, grad/param norm = 1.9290e-01, time/batch = 15.3073s	
21424/28500 (epoch 37.586), train_loss = 0.77659335, grad/param norm = 1.6217e-01, time/batch = 15.1289s	
21425/28500 (epoch 37.588), train_loss = 0.79265046, grad/param norm = 1.7686e-01, time/batch = 15.4446s	
21426/28500 (epoch 37.589), train_loss = 0.83201823, grad/param norm = 1.9420e-01, time/batch = 15.0547s	
21427/28500 (epoch 37.591), train_loss = 0.85582334, grad/param norm = 2.0796e-01, time/batch = 15.0386s	
21428/28500 (epoch 37.593), train_loss = 0.81147065, grad/param norm = 1.7574e-01, time/batch = 15.4876s	
21429/28500 (epoch 37.595), train_loss = 1.02664278, grad/param norm = 2.2043e-01, time/batch = 15.4250s	
21430/28500 (epoch 37.596), train_loss = 1.00818556, grad/param norm = 2.0326e-01, time/batch = 15.5997s	
21431/28500 (epoch 37.598), train_loss = 0.82302954, grad/param norm = 1.8387e-01, time/batch = 15.6502s	
21432/28500 (epoch 37.600), train_loss = 0.83948231, grad/param norm = 1.9293e-01, time/batch = 15.5572s	
21433/28500 (epoch 37.602), train_loss = 0.89572006, grad/param norm = 1.6996e-01, time/batch = 15.3856s	
21434/28500 (epoch 37.604), train_loss = 0.92731493, grad/param norm = 1.7465e-01, time/batch = 15.5516s	
21435/28500 (epoch 37.605), train_loss = 0.92238791, grad/param norm = 2.0116e-01, time/batch = 15.5385s	
21436/28500 (epoch 37.607), train_loss = 0.96167128, grad/param norm = 1.7605e-01, time/batch = 15.2980s	
21437/28500 (epoch 37.609), train_loss = 0.87789785, grad/param norm = 1.7226e-01, time/batch = 15.1340s	
21438/28500 (epoch 37.611), train_loss = 0.84236808, grad/param norm = 1.9455e-01, time/batch = 15.4410s	
21439/28500 (epoch 37.612), train_loss = 0.92726950, grad/param norm = 2.1930e-01, time/batch = 15.3357s	
21440/28500 (epoch 37.614), train_loss = 0.92861273, grad/param norm = 1.8203e-01, time/batch = 15.5233s	
21441/28500 (epoch 37.616), train_loss = 0.80369403, grad/param norm = 2.0198e-01, time/batch = 15.6408s	
21442/28500 (epoch 37.618), train_loss = 0.83174758, grad/param norm = 1.8975e-01, time/batch = 15.3582s	
21443/28500 (epoch 37.619), train_loss = 0.91873612, grad/param norm = 2.2297e-01, time/batch = 15.2368s	
21444/28500 (epoch 37.621), train_loss = 0.70166582, grad/param norm = 1.8295e-01, time/batch = 15.1163s	
21445/28500 (epoch 37.623), train_loss = 0.96264763, grad/param norm = 2.0030e-01, time/batch = 15.3140s	
21446/28500 (epoch 37.625), train_loss = 0.77916712, grad/param norm = 1.8988e-01, time/batch = 15.2945s	
21447/28500 (epoch 37.626), train_loss = 0.66444505, grad/param norm = 1.5217e-01, time/batch = 15.2090s	
21448/28500 (epoch 37.628), train_loss = 0.77812056, grad/param norm = 1.6354e-01, time/batch = 14.9852s	
21449/28500 (epoch 37.630), train_loss = 0.73151823, grad/param norm = 1.5992e-01, time/batch = 15.1283s	
21450/28500 (epoch 37.632), train_loss = 0.93908606, grad/param norm = 1.9704e-01, time/batch = 15.2948s	
21451/28500 (epoch 37.633), train_loss = 0.99268452, grad/param norm = 1.7461e-01, time/batch = 15.4639s	
21452/28500 (epoch 37.635), train_loss = 0.88426757, grad/param norm = 2.0800e-01, time/batch = 15.2767s	
21453/28500 (epoch 37.637), train_loss = 0.87957482, grad/param norm = 1.8207e-01, time/batch = 15.3039s	
21454/28500 (epoch 37.639), train_loss = 0.77219614, grad/param norm = 2.0712e-01, time/batch = 15.3529s	
21455/28500 (epoch 37.640), train_loss = 0.78672575, grad/param norm = 1.7983e-01, time/batch = 15.0871s	
21456/28500 (epoch 37.642), train_loss = 0.80086373, grad/param norm = 1.7281e-01, time/batch = 15.3752s	
21457/28500 (epoch 37.644), train_loss = 0.88403847, grad/param norm = 1.7248e-01, time/batch = 15.5086s	
21458/28500 (epoch 37.646), train_loss = 0.72309260, grad/param norm = 1.5589e-01, time/batch = 15.4672s	
21459/28500 (epoch 37.647), train_loss = 0.80594242, grad/param norm = 1.9688e-01, time/batch = 15.1411s	
21460/28500 (epoch 37.649), train_loss = 0.77947719, grad/param norm = 2.1351e-01, time/batch = 15.3970s	
21461/28500 (epoch 37.651), train_loss = 0.74010299, grad/param norm = 1.5289e-01, time/batch = 15.6958s	
21462/28500 (epoch 37.653), train_loss = 0.72327295, grad/param norm = 1.6922e-01, time/batch = 15.6442s	
21463/28500 (epoch 37.654), train_loss = 0.77341713, grad/param norm = 1.8316e-01, time/batch = 15.1456s	
21464/28500 (epoch 37.656), train_loss = 0.72233563, grad/param norm = 1.7473e-01, time/batch = 14.9842s	
21465/28500 (epoch 37.658), train_loss = 0.83699831, grad/param norm = 1.9047e-01, time/batch = 15.4478s	
21466/28500 (epoch 37.660), train_loss = 0.84702997, grad/param norm = 1.6186e-01, time/batch = 15.5341s	
21467/28500 (epoch 37.661), train_loss = 0.93361274, grad/param norm = 2.0633e-01, time/batch = 15.4527s	
21468/28500 (epoch 37.663), train_loss = 0.94202185, grad/param norm = 2.0593e-01, time/batch = 15.4125s	
21469/28500 (epoch 37.665), train_loss = 0.84927806, grad/param norm = 1.8766e-01, time/batch = 15.6148s	
21470/28500 (epoch 37.667), train_loss = 0.83869596, grad/param norm = 1.9370e-01, time/batch = 15.2382s	
21471/28500 (epoch 37.668), train_loss = 0.84621978, grad/param norm = 2.1204e-01, time/batch = 15.4639s	
21472/28500 (epoch 37.670), train_loss = 0.84633538, grad/param norm = 1.7371e-01, time/batch = 15.2329s	
21473/28500 (epoch 37.672), train_loss = 0.77212311, grad/param norm = 1.8879e-01, time/batch = 15.3639s	
21474/28500 (epoch 37.674), train_loss = 0.66405040, grad/param norm = 1.8908e-01, time/batch = 15.5459s	
21475/28500 (epoch 37.675), train_loss = 0.70346319, grad/param norm = 1.6936e-01, time/batch = 15.5626s	
21476/28500 (epoch 37.677), train_loss = 0.78746470, grad/param norm = 1.6090e-01, time/batch = 15.5299s	
21477/28500 (epoch 37.679), train_loss = 0.80055024, grad/param norm = 1.8176e-01, time/batch = 15.2125s	
21478/28500 (epoch 37.681), train_loss = 0.86988574, grad/param norm = 1.9253e-01, time/batch = 15.1464s	
21479/28500 (epoch 37.682), train_loss = 0.79751808, grad/param norm = 1.7488e-01, time/batch = 15.0576s	
21480/28500 (epoch 37.684), train_loss = 0.83316633, grad/param norm = 1.6641e-01, time/batch = 15.0461s	
21481/28500 (epoch 37.686), train_loss = 0.78906928, grad/param norm = 1.8595e-01, time/batch = 15.5639s	
21482/28500 (epoch 37.688), train_loss = 0.76840356, grad/param norm = 1.6431e-01, time/batch = 15.2208s	
21483/28500 (epoch 37.689), train_loss = 0.78284726, grad/param norm = 2.1607e-01, time/batch = 15.2302s	
21484/28500 (epoch 37.691), train_loss = 0.87628675, grad/param norm = 1.7135e-01, time/batch = 15.2854s	
21485/28500 (epoch 37.693), train_loss = 0.80804830, grad/param norm = 1.8063e-01, time/batch = 15.3125s	
21486/28500 (epoch 37.695), train_loss = 0.63763811, grad/param norm = 1.9299e-01, time/batch = 15.0490s	
21487/28500 (epoch 37.696), train_loss = 0.80731962, grad/param norm = 1.7000e-01, time/batch = 15.2095s	
21488/28500 (epoch 37.698), train_loss = 0.87710489, grad/param norm = 1.8129e-01, time/batch = 15.4244s	
21489/28500 (epoch 37.700), train_loss = 0.84166447, grad/param norm = 1.8074e-01, time/batch = 15.3064s	
21490/28500 (epoch 37.702), train_loss = 0.81904051, grad/param norm = 1.9583e-01, time/batch = 15.5321s	
21491/28500 (epoch 37.704), train_loss = 0.88683321, grad/param norm = 2.0669e-01, time/batch = 15.3881s	
21492/28500 (epoch 37.705), train_loss = 0.91859576, grad/param norm = 3.3584e-01, time/batch = 15.5421s	
21493/28500 (epoch 37.707), train_loss = 0.78667199, grad/param norm = 2.1489e-01, time/batch = 15.2823s	
21494/28500 (epoch 37.709), train_loss = 0.99640374, grad/param norm = 2.3832e-01, time/batch = 15.3591s	
21495/28500 (epoch 37.711), train_loss = 0.77224043, grad/param norm = 1.6786e-01, time/batch = 15.3385s	
21496/28500 (epoch 37.712), train_loss = 0.87492345, grad/param norm = 2.0313e-01, time/batch = 15.1253s	
21497/28500 (epoch 37.714), train_loss = 0.95087043, grad/param norm = 2.3659e-01, time/batch = 23.1849s	
21498/28500 (epoch 37.716), train_loss = 0.83864857, grad/param norm = 1.8280e-01, time/batch = 32.5771s	
21499/28500 (epoch 37.718), train_loss = 0.83538504, grad/param norm = 1.8899e-01, time/batch = 27.1528s	
21500/28500 (epoch 37.719), train_loss = 0.84181473, grad/param norm = 1.7781e-01, time/batch = 30.5173s	
21501/28500 (epoch 37.721), train_loss = 0.66226441, grad/param norm = 1.8354e-01, time/batch = 31.3032s	
21502/28500 (epoch 37.723), train_loss = 0.84121412, grad/param norm = 1.7211e-01, time/batch = 29.6446s	
21503/28500 (epoch 37.725), train_loss = 0.90819860, grad/param norm = 1.7686e-01, time/batch = 31.3074s	
21504/28500 (epoch 37.726), train_loss = 0.82919184, grad/param norm = 1.9863e-01, time/batch = 30.3370s	
21505/28500 (epoch 37.728), train_loss = 0.76609060, grad/param norm = 1.8320e-01, time/batch = 30.8370s	
21506/28500 (epoch 37.730), train_loss = 0.85615292, grad/param norm = 2.1596e-01, time/batch = 31.3253s	
21507/28500 (epoch 37.732), train_loss = 0.66969999, grad/param norm = 1.5046e-01, time/batch = 30.5921s	
21508/28500 (epoch 37.733), train_loss = 0.70634436, grad/param norm = 1.7055e-01, time/batch = 30.6668s	
21509/28500 (epoch 37.735), train_loss = 0.71152035, grad/param norm = 1.5202e-01, time/batch = 31.4358s	
21510/28500 (epoch 37.737), train_loss = 0.63379075, grad/param norm = 1.4866e-01, time/batch = 30.9958s	
21511/28500 (epoch 37.739), train_loss = 0.73431620, grad/param norm = 1.8308e-01, time/batch = 31.4160s	
21512/28500 (epoch 37.740), train_loss = 0.83680543, grad/param norm = 1.8745e-01, time/batch = 30.8375s	
21513/28500 (epoch 37.742), train_loss = 0.74593148, grad/param norm = 1.9694e-01, time/batch = 30.7309s	
21514/28500 (epoch 37.744), train_loss = 0.84075244, grad/param norm = 1.8545e-01, time/batch = 31.7542s	
21515/28500 (epoch 37.746), train_loss = 0.77628694, grad/param norm = 1.6506e-01, time/batch = 30.8263s	
21516/28500 (epoch 37.747), train_loss = 0.77963690, grad/param norm = 1.8095e-01, time/batch = 31.2637s	
21517/28500 (epoch 37.749), train_loss = 0.90998266, grad/param norm = 2.2714e-01, time/batch = 31.1092s	
21518/28500 (epoch 37.751), train_loss = 0.73863199, grad/param norm = 2.0696e-01, time/batch = 31.0917s	
21519/28500 (epoch 37.753), train_loss = 0.81697436, grad/param norm = 1.5006e-01, time/batch = 31.1213s	
21520/28500 (epoch 37.754), train_loss = 0.74235759, grad/param norm = 1.8303e-01, time/batch = 31.1949s	
21521/28500 (epoch 37.756), train_loss = 0.94326588, grad/param norm = 1.7620e-01, time/batch = 29.2862s	
21522/28500 (epoch 37.758), train_loss = 0.86727118, grad/param norm = 1.8568e-01, time/batch = 22.8286s	
21523/28500 (epoch 37.760), train_loss = 0.73298634, grad/param norm = 1.8748e-01, time/batch = 26.1015s	
21524/28500 (epoch 37.761), train_loss = 0.76077665, grad/param norm = 1.8852e-01, time/batch = 30.2098s	
21525/28500 (epoch 37.763), train_loss = 0.65856999, grad/param norm = 1.6783e-01, time/batch = 51.3602s	
21526/28500 (epoch 37.765), train_loss = 0.80451571, grad/param norm = 1.8223e-01, time/batch = 36.6471s	
21527/28500 (epoch 37.767), train_loss = 0.67571168, grad/param norm = 1.4203e-01, time/batch = 30.2991s	
21528/28500 (epoch 37.768), train_loss = 0.86883840, grad/param norm = 1.9144e-01, time/batch = 29.1331s	
21529/28500 (epoch 37.770), train_loss = 0.71599250, grad/param norm = 1.6331e-01, time/batch = 19.9807s	
21530/28500 (epoch 37.772), train_loss = 0.66326082, grad/param norm = 1.5099e-01, time/batch = 19.6996s	
21531/28500 (epoch 37.774), train_loss = 0.82677394, grad/param norm = 1.7084e-01, time/batch = 19.9382s	
21532/28500 (epoch 37.775), train_loss = 0.87950850, grad/param norm = 1.7495e-01, time/batch = 19.4646s	
21533/28500 (epoch 37.777), train_loss = 0.88053080, grad/param norm = 1.7060e-01, time/batch = 20.7506s	
21534/28500 (epoch 37.779), train_loss = 0.67718190, grad/param norm = 1.4261e-01, time/batch = 19.8489s	
21535/28500 (epoch 37.781), train_loss = 0.79694597, grad/param norm = 1.9978e-01, time/batch = 21.0847s	
21536/28500 (epoch 37.782), train_loss = 0.83223993, grad/param norm = 1.8781e-01, time/batch = 20.3588s	
21537/28500 (epoch 37.784), train_loss = 0.68101588, grad/param norm = 1.7622e-01, time/batch = 20.1833s	
21538/28500 (epoch 37.786), train_loss = 0.68602820, grad/param norm = 1.7953e-01, time/batch = 19.9443s	
21539/28500 (epoch 37.788), train_loss = 0.76867012, grad/param norm = 2.1879e-01, time/batch = 21.6268s	
21540/28500 (epoch 37.789), train_loss = 0.62301820, grad/param norm = 2.2970e-01, time/batch = 21.8360s	
21541/28500 (epoch 37.791), train_loss = 0.85606806, grad/param norm = 1.9633e-01, time/batch = 21.0785s	
21542/28500 (epoch 37.793), train_loss = 0.82104274, grad/param norm = 1.9844e-01, time/batch = 21.2432s	
21543/28500 (epoch 37.795), train_loss = 0.83407992, grad/param norm = 1.9550e-01, time/batch = 20.1563s	
21544/28500 (epoch 37.796), train_loss = 0.72347929, grad/param norm = 1.6369e-01, time/batch = 24.1719s	
21545/28500 (epoch 37.798), train_loss = 0.66735119, grad/param norm = 1.6277e-01, time/batch = 27.7544s	
21546/28500 (epoch 37.800), train_loss = 0.66851641, grad/param norm = 2.0004e-01, time/batch = 22.3978s	
21547/28500 (epoch 37.802), train_loss = 0.76223792, grad/param norm = 2.5285e-01, time/batch = 19.1488s	
21548/28500 (epoch 37.804), train_loss = 0.83719866, grad/param norm = 1.7082e-01, time/batch = 23.9931s	
21549/28500 (epoch 37.805), train_loss = 0.84214021, grad/param norm = 2.1381e-01, time/batch = 30.8928s	
21550/28500 (epoch 37.807), train_loss = 0.81764219, grad/param norm = 1.7589e-01, time/batch = 30.8070s	
21551/28500 (epoch 37.809), train_loss = 0.81244767, grad/param norm = 2.0029e-01, time/batch = 31.5028s	
21552/28500 (epoch 37.811), train_loss = 0.82594645, grad/param norm = 1.8039e-01, time/batch = 31.4847s	
21553/28500 (epoch 37.812), train_loss = 0.81290933, grad/param norm = 2.1279e-01, time/batch = 31.4018s	
21554/28500 (epoch 37.814), train_loss = 0.76773654, grad/param norm = 2.1838e-01, time/batch = 28.6411s	
21555/28500 (epoch 37.816), train_loss = 0.86218407, grad/param norm = 2.0985e-01, time/batch = 26.6227s	
21556/28500 (epoch 37.818), train_loss = 0.95421816, grad/param norm = 2.0930e-01, time/batch = 29.6858s	
21557/28500 (epoch 37.819), train_loss = 0.81736104, grad/param norm = 1.7942e-01, time/batch = 29.0263s	
21558/28500 (epoch 37.821), train_loss = 0.78619881, grad/param norm = 1.6989e-01, time/batch = 30.6713s	
21559/28500 (epoch 37.823), train_loss = 0.92733007, grad/param norm = 2.0740e-01, time/batch = 31.5928s	
21560/28500 (epoch 37.825), train_loss = 0.74761243, grad/param norm = 1.9204e-01, time/batch = 24.2793s	
21561/28500 (epoch 37.826), train_loss = 0.82163870, grad/param norm = 1.7739e-01, time/batch = 15.2789s	
21562/28500 (epoch 37.828), train_loss = 0.75124611, grad/param norm = 1.7863e-01, time/batch = 15.5718s	
21563/28500 (epoch 37.830), train_loss = 0.77521370, grad/param norm = 1.6083e-01, time/batch = 15.6271s	
21564/28500 (epoch 37.832), train_loss = 0.81161691, grad/param norm = 1.9824e-01, time/batch = 15.2038s	
21565/28500 (epoch 37.833), train_loss = 0.86325381, grad/param norm = 1.7099e-01, time/batch = 15.1224s	
21566/28500 (epoch 37.835), train_loss = 0.76728965, grad/param norm = 2.0725e-01, time/batch = 15.5402s	
21567/28500 (epoch 37.837), train_loss = 0.70040360, grad/param norm = 1.8982e-01, time/batch = 15.5618s	
21568/28500 (epoch 37.839), train_loss = 0.96898811, grad/param norm = 2.2882e-01, time/batch = 15.6388s	
21569/28500 (epoch 37.840), train_loss = 0.94461596, grad/param norm = 1.9064e-01, time/batch = 15.4699s	
21570/28500 (epoch 37.842), train_loss = 0.87678488, grad/param norm = 2.2363e-01, time/batch = 15.7197s	
21571/28500 (epoch 37.844), train_loss = 0.89048282, grad/param norm = 1.8896e-01, time/batch = 15.6399s	
21572/28500 (epoch 37.846), train_loss = 0.98231959, grad/param norm = 2.2763e-01, time/batch = 15.6419s	
21573/28500 (epoch 37.847), train_loss = 0.78831337, grad/param norm = 2.0732e-01, time/batch = 15.4602s	
21574/28500 (epoch 37.849), train_loss = 0.77630671, grad/param norm = 1.7123e-01, time/batch = 15.4540s	
21575/28500 (epoch 37.851), train_loss = 0.72728495, grad/param norm = 1.6388e-01, time/batch = 15.2990s	
21576/28500 (epoch 37.853), train_loss = 0.84159933, grad/param norm = 1.9127e-01, time/batch = 15.3436s	
21577/28500 (epoch 37.854), train_loss = 0.82219123, grad/param norm = 1.7278e-01, time/batch = 15.5108s	
21578/28500 (epoch 37.856), train_loss = 0.92956989, grad/param norm = 2.2917e-01, time/batch = 15.3777s	
21579/28500 (epoch 37.858), train_loss = 0.78667863, grad/param norm = 1.7882e-01, time/batch = 15.4594s	
21580/28500 (epoch 37.860), train_loss = 0.80029454, grad/param norm = 1.8391e-01, time/batch = 15.2133s	
21581/28500 (epoch 37.861), train_loss = 0.90620221, grad/param norm = 1.9657e-01, time/batch = 15.1426s	
21582/28500 (epoch 37.863), train_loss = 0.86567007, grad/param norm = 2.3511e-01, time/batch = 15.3870s	
21583/28500 (epoch 37.865), train_loss = 0.77573385, grad/param norm = 1.9967e-01, time/batch = 15.2279s	
21584/28500 (epoch 37.867), train_loss = 0.87379685, grad/param norm = 2.2299e-01, time/batch = 15.2247s	
21585/28500 (epoch 37.868), train_loss = 0.74399656, grad/param norm = 1.6822e-01, time/batch = 15.5371s	
21586/28500 (epoch 37.870), train_loss = 0.72080878, grad/param norm = 2.0618e-01, time/batch = 15.3818s	
21587/28500 (epoch 37.872), train_loss = 0.89705804, grad/param norm = 2.8765e-01, time/batch = 15.2839s	
21588/28500 (epoch 37.874), train_loss = 0.73926464, grad/param norm = 2.0738e-01, time/batch = 15.3876s	
21589/28500 (epoch 37.875), train_loss = 0.96745279, grad/param norm = 2.2318e-01, time/batch = 15.2267s	
21590/28500 (epoch 37.877), train_loss = 0.86588562, grad/param norm = 1.9957e-01, time/batch = 15.1680s	
21591/28500 (epoch 37.879), train_loss = 0.88115159, grad/param norm = 1.6302e-01, time/batch = 15.0599s	
21592/28500 (epoch 37.881), train_loss = 0.87019384, grad/param norm = 1.8996e-01, time/batch = 15.1910s	
21593/28500 (epoch 37.882), train_loss = 0.76161046, grad/param norm = 1.6202e-01, time/batch = 15.1267s	
21594/28500 (epoch 37.884), train_loss = 0.79904733, grad/param norm = 1.9087e-01, time/batch = 14.9769s	
21595/28500 (epoch 37.886), train_loss = 0.78139263, grad/param norm = 1.8654e-01, time/batch = 15.3792s	
21596/28500 (epoch 37.888), train_loss = 0.78061129, grad/param norm = 1.5278e-01, time/batch = 15.4598s	
21597/28500 (epoch 37.889), train_loss = 0.83959895, grad/param norm = 1.7358e-01, time/batch = 15.3819s	
21598/28500 (epoch 37.891), train_loss = 0.84380550, grad/param norm = 1.8645e-01, time/batch = 15.3025s	
21599/28500 (epoch 37.893), train_loss = 0.77137713, grad/param norm = 1.7517e-01, time/batch = 15.4676s	
21600/28500 (epoch 37.895), train_loss = 0.96514845, grad/param norm = 2.4244e-01, time/batch = 15.5009s	
21601/28500 (epoch 37.896), train_loss = 0.93369727, grad/param norm = 2.1710e-01, time/batch = 15.6446s	
21602/28500 (epoch 37.898), train_loss = 0.85776997, grad/param norm = 1.9131e-01, time/batch = 15.6108s	
21603/28500 (epoch 37.900), train_loss = 0.72579732, grad/param norm = 1.7606e-01, time/batch = 15.6278s	
21604/28500 (epoch 37.902), train_loss = 0.69200108, grad/param norm = 1.8091e-01, time/batch = 15.3534s	
21605/28500 (epoch 37.904), train_loss = 0.73398061, grad/param norm = 1.7425e-01, time/batch = 15.3139s	
21606/28500 (epoch 37.905), train_loss = 0.78359551, grad/param norm = 2.2174e-01, time/batch = 15.3133s	
21607/28500 (epoch 37.907), train_loss = 0.80926403, grad/param norm = 1.7013e-01, time/batch = 15.4650s	
21608/28500 (epoch 37.909), train_loss = 0.69438753, grad/param norm = 1.9663e-01, time/batch = 15.4730s	
21609/28500 (epoch 37.911), train_loss = 0.73179947, grad/param norm = 1.6501e-01, time/batch = 15.4620s	
21610/28500 (epoch 37.912), train_loss = 0.61037286, grad/param norm = 1.7954e-01, time/batch = 15.2211s	
21611/28500 (epoch 37.914), train_loss = 0.83283916, grad/param norm = 1.8701e-01, time/batch = 15.1431s	
21612/28500 (epoch 37.916), train_loss = 0.81525770, grad/param norm = 1.8931e-01, time/batch = 15.4672s	
21613/28500 (epoch 37.918), train_loss = 0.80297216, grad/param norm = 1.7962e-01, time/batch = 15.1492s	
21614/28500 (epoch 37.919), train_loss = 0.83473449, grad/param norm = 1.9160e-01, time/batch = 15.0486s	
21615/28500 (epoch 37.921), train_loss = 0.91931775, grad/param norm = 2.2626e-01, time/batch = 15.4624s	
21616/28500 (epoch 37.923), train_loss = 0.77990778, grad/param norm = 2.3606e-01, time/batch = 15.3344s	
21617/28500 (epoch 37.925), train_loss = 0.79161165, grad/param norm = 2.2861e-01, time/batch = 15.1610s	
21618/28500 (epoch 37.926), train_loss = 0.83463083, grad/param norm = 1.9742e-01, time/batch = 15.0477s	
21619/28500 (epoch 37.928), train_loss = 0.78048969, grad/param norm = 1.6750e-01, time/batch = 15.2061s	
21620/28500 (epoch 37.930), train_loss = 0.65657194, grad/param norm = 1.6460e-01, time/batch = 15.1283s	
21621/28500 (epoch 37.932), train_loss = 0.66808178, grad/param norm = 1.5750e-01, time/batch = 15.2274s	
21622/28500 (epoch 37.933), train_loss = 0.89568518, grad/param norm = 1.9851e-01, time/batch = 15.1920s	
21623/28500 (epoch 37.935), train_loss = 0.89986299, grad/param norm = 1.7242e-01, time/batch = 15.4397s	
21624/28500 (epoch 37.937), train_loss = 0.90883626, grad/param norm = 2.2706e-01, time/batch = 15.4671s	
21625/28500 (epoch 37.939), train_loss = 0.92545360, grad/param norm = 2.0315e-01, time/batch = 15.2942s	
21626/28500 (epoch 37.940), train_loss = 0.68713044, grad/param norm = 1.8382e-01, time/batch = 15.2979s	
21627/28500 (epoch 37.942), train_loss = 0.82129580, grad/param norm = 1.8969e-01, time/batch = 15.5322s	
21628/28500 (epoch 37.944), train_loss = 0.79492336, grad/param norm = 2.0928e-01, time/batch = 15.3974s	
21629/28500 (epoch 37.946), train_loss = 0.87018796, grad/param norm = 1.6654e-01, time/batch = 15.4549s	
21630/28500 (epoch 37.947), train_loss = 1.04592062, grad/param norm = 2.2957e-01, time/batch = 15.3135s	
21631/28500 (epoch 37.949), train_loss = 0.81088173, grad/param norm = 2.1031e-01, time/batch = 15.2891s	
21632/28500 (epoch 37.951), train_loss = 0.97377385, grad/param norm = 1.8710e-01, time/batch = 15.3926s	
21633/28500 (epoch 37.953), train_loss = 0.98402780, grad/param norm = 2.1204e-01, time/batch = 15.1307s	
21634/28500 (epoch 37.954), train_loss = 0.90851041, grad/param norm = 2.0604e-01, time/batch = 15.0657s	
21635/28500 (epoch 37.956), train_loss = 0.83474474, grad/param norm = 2.3723e-01, time/batch = 15.2833s	
21636/28500 (epoch 37.958), train_loss = 1.06112245, grad/param norm = 2.0836e-01, time/batch = 15.5390s	
21637/28500 (epoch 37.960), train_loss = 0.76556390, grad/param norm = 2.1124e-01, time/batch = 15.5533s	
21638/28500 (epoch 37.961), train_loss = 0.97391926, grad/param norm = 2.1800e-01, time/batch = 15.3952s	
21639/28500 (epoch 37.963), train_loss = 0.92550849, grad/param norm = 2.3616e-01, time/batch = 15.3735s	
21640/28500 (epoch 37.965), train_loss = 0.76328019, grad/param norm = 1.8302e-01, time/batch = 15.5606s	
21641/28500 (epoch 37.967), train_loss = 0.77279951, grad/param norm = 1.7731e-01, time/batch = 15.7256s	
21642/28500 (epoch 37.968), train_loss = 0.72595296, grad/param norm = 1.6416e-01, time/batch = 15.5911s	
21643/28500 (epoch 37.970), train_loss = 0.77087720, grad/param norm = 2.1210e-01, time/batch = 15.6479s	
21644/28500 (epoch 37.972), train_loss = 0.84177412, grad/param norm = 1.9566e-01, time/batch = 15.1140s	
21645/28500 (epoch 37.974), train_loss = 1.01328777, grad/param norm = 2.2020e-01, time/batch = 15.1198s	
21646/28500 (epoch 37.975), train_loss = 0.77050731, grad/param norm = 1.7978e-01, time/batch = 15.1241s	
21647/28500 (epoch 37.977), train_loss = 0.91809860, grad/param norm = 2.3680e-01, time/batch = 15.2989s	
21648/28500 (epoch 37.979), train_loss = 0.86003083, grad/param norm = 1.8389e-01, time/batch = 15.3010s	
21649/28500 (epoch 37.981), train_loss = 0.71966332, grad/param norm = 1.7675e-01, time/batch = 15.1285s	
21650/28500 (epoch 37.982), train_loss = 0.79776708, grad/param norm = 1.9102e-01, time/batch = 15.4732s	
21651/28500 (epoch 37.984), train_loss = 0.90163283, grad/param norm = 1.8168e-01, time/batch = 15.3736s	
21652/28500 (epoch 37.986), train_loss = 1.06335476, grad/param norm = 2.1059e-01, time/batch = 15.3054s	
21653/28500 (epoch 37.988), train_loss = 0.75467091, grad/param norm = 1.7939e-01, time/batch = 15.6351s	
21654/28500 (epoch 37.989), train_loss = 0.84419479, grad/param norm = 1.9883e-01, time/batch = 15.6138s	
21655/28500 (epoch 37.991), train_loss = 0.76146796, grad/param norm = 2.1473e-01, time/batch = 15.5958s	
21656/28500 (epoch 37.993), train_loss = 0.76081314, grad/param norm = 2.1641e-01, time/batch = 15.4206s	
21657/28500 (epoch 37.995), train_loss = 0.78469952, grad/param norm = 1.9035e-01, time/batch = 15.4033s	
21658/28500 (epoch 37.996), train_loss = 0.72944438, grad/param norm = 1.8258e-01, time/batch = 15.4981s	
21659/28500 (epoch 37.998), train_loss = 0.92854980, grad/param norm = 2.1136e-01, time/batch = 15.5900s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
21660/28500 (epoch 38.000), train_loss = 0.81936568, grad/param norm = 1.9957e-01, time/batch = 15.5226s	
21661/28500 (epoch 38.002), train_loss = 0.98239474, grad/param norm = 1.9820e-01, time/batch = 15.6654s	
21662/28500 (epoch 38.004), train_loss = 0.82412109, grad/param norm = 1.6937e-01, time/batch = 15.5165s	
21663/28500 (epoch 38.005), train_loss = 0.93685527, grad/param norm = 2.1204e-01, time/batch = 15.3459s	
21664/28500 (epoch 38.007), train_loss = 0.73810963, grad/param norm = 1.5829e-01, time/batch = 15.4982s	
21665/28500 (epoch 38.009), train_loss = 0.85511677, grad/param norm = 1.9608e-01, time/batch = 15.4597s	
21666/28500 (epoch 38.011), train_loss = 0.75799450, grad/param norm = 1.7621e-01, time/batch = 15.4684s	
21667/28500 (epoch 38.012), train_loss = 0.77032822, grad/param norm = 1.7925e-01, time/batch = 15.1457s	
21668/28500 (epoch 38.014), train_loss = 0.74128148, grad/param norm = 1.7061e-01, time/batch = 15.3077s	
21669/28500 (epoch 38.016), train_loss = 0.79996948, grad/param norm = 1.8264e-01, time/batch = 15.2312s	
21670/28500 (epoch 38.018), train_loss = 0.86220534, grad/param norm = 1.8605e-01, time/batch = 15.4734s	
21671/28500 (epoch 38.019), train_loss = 0.90353093, grad/param norm = 1.7203e-01, time/batch = 15.3706s	
21672/28500 (epoch 38.021), train_loss = 0.95027989, grad/param norm = 1.7500e-01, time/batch = 15.2297s	
21673/28500 (epoch 38.023), train_loss = 0.84331944, grad/param norm = 1.8316e-01, time/batch = 15.1225s	
21674/28500 (epoch 38.025), train_loss = 0.85713842, grad/param norm = 1.8892e-01, time/batch = 15.5082s	
21675/28500 (epoch 38.026), train_loss = 0.79983832, grad/param norm = 1.6983e-01, time/batch = 15.1097s	
21676/28500 (epoch 38.028), train_loss = 0.83916488, grad/param norm = 2.0460e-01, time/batch = 15.0600s	
21677/28500 (epoch 38.030), train_loss = 0.86790801, grad/param norm = 1.9536e-01, time/batch = 15.0957s	
21678/28500 (epoch 38.032), train_loss = 0.93852888, grad/param norm = 2.0600e-01, time/batch = 15.1932s	
21679/28500 (epoch 38.033), train_loss = 0.98694128, grad/param norm = 2.1700e-01, time/batch = 14.9824s	
21680/28500 (epoch 38.035), train_loss = 0.81493986, grad/param norm = 1.8717e-01, time/batch = 15.2172s	
21681/28500 (epoch 38.037), train_loss = 0.89330772, grad/param norm = 1.8205e-01, time/batch = 15.6224s	
21682/28500 (epoch 38.039), train_loss = 0.95153430, grad/param norm = 2.0831e-01, time/batch = 15.5071s	
21683/28500 (epoch 38.040), train_loss = 0.96684911, grad/param norm = 2.0088e-01, time/batch = 15.4970s	
21684/28500 (epoch 38.042), train_loss = 0.90527535, grad/param norm = 1.8909e-01, time/batch = 15.4234s	
21685/28500 (epoch 38.044), train_loss = 0.83670764, grad/param norm = 1.9487e-01, time/batch = 15.2299s	
21686/28500 (epoch 38.046), train_loss = 1.03632134, grad/param norm = 2.0736e-01, time/batch = 15.1762s	
21687/28500 (epoch 38.047), train_loss = 0.98599806, grad/param norm = 2.4607e-01, time/batch = 15.5815s	
21688/28500 (epoch 38.049), train_loss = 0.84984151, grad/param norm = 1.9863e-01, time/batch = 15.6425s	
21689/28500 (epoch 38.051), train_loss = 0.86026789, grad/param norm = 2.3522e-01, time/batch = 15.5971s	
21690/28500 (epoch 38.053), train_loss = 0.82059645, grad/param norm = 2.1335e-01, time/batch = 15.5715s	
21691/28500 (epoch 38.054), train_loss = 0.91928419, grad/param norm = 1.9911e-01, time/batch = 15.5168s	
21692/28500 (epoch 38.056), train_loss = 0.80092184, grad/param norm = 1.8039e-01, time/batch = 15.5327s	
21693/28500 (epoch 38.058), train_loss = 0.76897282, grad/param norm = 1.5958e-01, time/batch = 15.4628s	
21694/28500 (epoch 38.060), train_loss = 0.90661454, grad/param norm = 1.8987e-01, time/batch = 15.2013s	
21695/28500 (epoch 38.061), train_loss = 0.82379205, grad/param norm = 1.9107e-01, time/batch = 15.0459s	
21696/28500 (epoch 38.063), train_loss = 0.89743219, grad/param norm = 1.9394e-01, time/batch = 15.2690s	
21697/28500 (epoch 38.065), train_loss = 0.85455155, grad/param norm = 1.8008e-01, time/batch = 15.2498s	
21698/28500 (epoch 38.067), train_loss = 0.79568469, grad/param norm = 1.9239e-01, time/batch = 15.2209s	
21699/28500 (epoch 38.068), train_loss = 0.81193155, grad/param norm = 1.7491e-01, time/batch = 15.3593s	
21700/28500 (epoch 38.070), train_loss = 0.87410556, grad/param norm = 1.9373e-01, time/batch = 15.2313s	
21701/28500 (epoch 38.072), train_loss = 0.96657947, grad/param norm = 2.0854e-01, time/batch = 15.3912s	
21702/28500 (epoch 38.074), train_loss = 0.82942791, grad/param norm = 1.8183e-01, time/batch = 15.3095s	
21703/28500 (epoch 38.075), train_loss = 0.83392551, grad/param norm = 1.7799e-01, time/batch = 15.1885s	
21704/28500 (epoch 38.077), train_loss = 0.88921561, grad/param norm = 1.8356e-01, time/batch = 15.0633s	
21705/28500 (epoch 38.079), train_loss = 0.86244411, grad/param norm = 1.7338e-01, time/batch = 15.1801s	
21706/28500 (epoch 38.081), train_loss = 0.94949314, grad/param norm = 2.1335e-01, time/batch = 15.0400s	
21707/28500 (epoch 38.082), train_loss = 0.84276965, grad/param norm = 2.3337e-01, time/batch = 15.0466s	
21708/28500 (epoch 38.084), train_loss = 0.85626901, grad/param norm = 1.9718e-01, time/batch = 15.1337s	
21709/28500 (epoch 38.086), train_loss = 0.80809581, grad/param norm = 1.9311e-01, time/batch = 15.2790s	
21710/28500 (epoch 38.088), train_loss = 0.75046065, grad/param norm = 1.7052e-01, time/batch = 15.4905s	
21711/28500 (epoch 38.089), train_loss = 0.92014295, grad/param norm = 2.0565e-01, time/batch = 15.3685s	
21712/28500 (epoch 38.091), train_loss = 0.75577874, grad/param norm = 2.0088e-01, time/batch = 15.3146s	
21713/28500 (epoch 38.093), train_loss = 0.94243945, grad/param norm = 1.8780e-01, time/batch = 15.5199s	
21714/28500 (epoch 38.095), train_loss = 0.85371917, grad/param norm = 1.8021e-01, time/batch = 15.2215s	
21715/28500 (epoch 38.096), train_loss = 0.92883422, grad/param norm = 1.7990e-01, time/batch = 15.4642s	
21716/28500 (epoch 38.098), train_loss = 0.85063421, grad/param norm = 2.1398e-01, time/batch = 15.2220s	
21717/28500 (epoch 38.100), train_loss = 0.82219287, grad/param norm = 1.6773e-01, time/batch = 15.6119s	
21718/28500 (epoch 38.102), train_loss = 0.91831563, grad/param norm = 1.8777e-01, time/batch = 15.5631s	
21719/28500 (epoch 38.104), train_loss = 0.86597193, grad/param norm = 2.0556e-01, time/batch = 15.2117s	
21720/28500 (epoch 38.105), train_loss = 0.94535681, grad/param norm = 1.8861e-01, time/batch = 15.5370s	
21721/28500 (epoch 38.107), train_loss = 0.76527018, grad/param norm = 1.7443e-01, time/batch = 15.6472s	
21722/28500 (epoch 38.109), train_loss = 0.81836730, grad/param norm = 2.3334e-01, time/batch = 15.3674s	
21723/28500 (epoch 38.111), train_loss = 0.82547858, grad/param norm = 2.2227e-01, time/batch = 15.3698s	
21724/28500 (epoch 38.112), train_loss = 0.92298063, grad/param norm = 1.9819e-01, time/batch = 15.4919s	
21725/28500 (epoch 38.114), train_loss = 0.82905960, grad/param norm = 1.8336e-01, time/batch = 15.3162s	
21726/28500 (epoch 38.116), train_loss = 1.00426179, grad/param norm = 2.2282e-01, time/batch = 15.3729s	
21727/28500 (epoch 38.118), train_loss = 0.76271181, grad/param norm = 1.8272e-01, time/batch = 15.3183s	
21728/28500 (epoch 38.119), train_loss = 0.87092231, grad/param norm = 1.9598e-01, time/batch = 15.3778s	
21729/28500 (epoch 38.121), train_loss = 1.01300307, grad/param norm = 2.2450e-01, time/batch = 15.4868s	
21730/28500 (epoch 38.123), train_loss = 0.95001916, grad/param norm = 1.8793e-01, time/batch = 15.4619s	
21731/28500 (epoch 38.125), train_loss = 0.86552187, grad/param norm = 1.8050e-01, time/batch = 15.5928s	
21732/28500 (epoch 38.126), train_loss = 0.84042390, grad/param norm = 1.7980e-01, time/batch = 19.0574s	
21733/28500 (epoch 38.128), train_loss = 0.85765543, grad/param norm = 1.9545e-01, time/batch = 25.1373s	
21734/28500 (epoch 38.130), train_loss = 0.81404674, grad/param norm = 2.2002e-01, time/batch = 15.9328s	
21735/28500 (epoch 38.132), train_loss = 0.85654968, grad/param norm = 2.1243e-01, time/batch = 15.2757s	
21736/28500 (epoch 38.133), train_loss = 0.91520077, grad/param norm = 2.7433e-01, time/batch = 15.4868s	
21737/28500 (epoch 38.135), train_loss = 0.82239012, grad/param norm = 1.8354e-01, time/batch = 15.4499s	
21738/28500 (epoch 38.137), train_loss = 0.87571056, grad/param norm = 1.9091e-01, time/batch = 15.3008s	
21739/28500 (epoch 38.139), train_loss = 0.87230076, grad/param norm = 1.8467e-01, time/batch = 15.1219s	
21740/28500 (epoch 38.140), train_loss = 0.85902252, grad/param norm = 1.9081e-01, time/batch = 15.2230s	
21741/28500 (epoch 38.142), train_loss = 0.81930942, grad/param norm = 2.1041e-01, time/batch = 15.6094s	
21742/28500 (epoch 38.144), train_loss = 0.76283250, grad/param norm = 1.8243e-01, time/batch = 15.2894s	
21743/28500 (epoch 38.146), train_loss = 0.83063747, grad/param norm = 1.8239e-01, time/batch = 15.3700s	
21744/28500 (epoch 38.147), train_loss = 0.72787072, grad/param norm = 1.7926e-01, time/batch = 15.4526s	
21745/28500 (epoch 38.149), train_loss = 0.73820514, grad/param norm = 1.6878e-01, time/batch = 15.3795s	
21746/28500 (epoch 38.151), train_loss = 0.81621171, grad/param norm = 1.7571e-01, time/batch = 15.3862s	
21747/28500 (epoch 38.153), train_loss = 0.86040090, grad/param norm = 1.7832e-01, time/batch = 15.4565s	
21748/28500 (epoch 38.154), train_loss = 0.73236982, grad/param norm = 1.6076e-01, time/batch = 15.4726s	
21749/28500 (epoch 38.156), train_loss = 0.90329386, grad/param norm = 1.9985e-01, time/batch = 15.1632s	
21750/28500 (epoch 38.158), train_loss = 0.85776437, grad/param norm = 1.7309e-01, time/batch = 15.5279s	
21751/28500 (epoch 38.160), train_loss = 0.75478242, grad/param norm = 1.5106e-01, time/batch = 15.3682s	
21752/28500 (epoch 38.161), train_loss = 0.77647992, grad/param norm = 1.7904e-01, time/batch = 15.2791s	
21753/28500 (epoch 38.163), train_loss = 0.73620364, grad/param norm = 1.8834e-01, time/batch = 15.2361s	
21754/28500 (epoch 38.165), train_loss = 1.00315521, grad/param norm = 1.9479e-01, time/batch = 15.1102s	
21755/28500 (epoch 38.167), train_loss = 0.99726051, grad/param norm = 1.9448e-01, time/batch = 15.2531s	
21756/28500 (epoch 38.168), train_loss = 0.96023836, grad/param norm = 2.2049e-01, time/batch = 15.2195s	
21757/28500 (epoch 38.170), train_loss = 0.92670123, grad/param norm = 2.1993e-01, time/batch = 15.2236s	
21758/28500 (epoch 38.172), train_loss = 0.83292530, grad/param norm = 1.6160e-01, time/batch = 15.2970s	
21759/28500 (epoch 38.174), train_loss = 0.99539442, grad/param norm = 2.1574e-01, time/batch = 15.0563s	
21760/28500 (epoch 38.175), train_loss = 0.83946140, grad/param norm = 1.7010e-01, time/batch = 15.3165s	
21761/28500 (epoch 38.177), train_loss = 0.88043227, grad/param norm = 1.8704e-01, time/batch = 15.6199s	
21762/28500 (epoch 38.179), train_loss = 0.94111420, grad/param norm = 2.0371e-01, time/batch = 15.3589s	
21763/28500 (epoch 38.181), train_loss = 0.88039362, grad/param norm = 2.0438e-01, time/batch = 15.2661s	
21764/28500 (epoch 38.182), train_loss = 0.80159138, grad/param norm = 1.7734e-01, time/batch = 15.3785s	
21765/28500 (epoch 38.184), train_loss = 1.02068938, grad/param norm = 2.0868e-01, time/batch = 15.3007s	
21766/28500 (epoch 38.186), train_loss = 0.99157533, grad/param norm = 1.9785e-01, time/batch = 15.3937s	
21767/28500 (epoch 38.188), train_loss = 0.89605445, grad/param norm = 1.9170e-01, time/batch = 15.4635s	
21768/28500 (epoch 38.189), train_loss = 0.85628921, grad/param norm = 1.6954e-01, time/batch = 15.4002s	
21769/28500 (epoch 38.191), train_loss = 1.03287732, grad/param norm = 1.9495e-01, time/batch = 15.4830s	
21770/28500 (epoch 38.193), train_loss = 0.86377916, grad/param norm = 2.1508e-01, time/batch = 15.5412s	
21771/28500 (epoch 38.195), train_loss = 0.98615994, grad/param norm = 1.9810e-01, time/batch = 15.3972s	
21772/28500 (epoch 38.196), train_loss = 0.90736630, grad/param norm = 2.0734e-01, time/batch = 15.3767s	
21773/28500 (epoch 38.198), train_loss = 0.87620539, grad/param norm = 2.0388e-01, time/batch = 15.2961s	
21774/28500 (epoch 38.200), train_loss = 0.93418501, grad/param norm = 1.6840e-01, time/batch = 15.3012s	
21775/28500 (epoch 38.202), train_loss = 0.88507615, grad/param norm = 1.8440e-01, time/batch = 15.3011s	
21776/28500 (epoch 38.204), train_loss = 0.85682252, grad/param norm = 1.6712e-01, time/batch = 15.4045s	
21777/28500 (epoch 38.205), train_loss = 0.81069669, grad/param norm = 2.0118e-01, time/batch = 15.3803s	
21778/28500 (epoch 38.207), train_loss = 0.72638491, grad/param norm = 1.7555e-01, time/batch = 15.2161s	
21779/28500 (epoch 38.209), train_loss = 0.88966376, grad/param norm = 1.7623e-01, time/batch = 15.1444s	
21780/28500 (epoch 38.211), train_loss = 0.79506496, grad/param norm = 1.9060e-01, time/batch = 15.3134s	
21781/28500 (epoch 38.212), train_loss = 0.72248835, grad/param norm = 1.8904e-01, time/batch = 15.3749s	
21782/28500 (epoch 38.214), train_loss = 0.84613568, grad/param norm = 1.9141e-01, time/batch = 15.4699s	
21783/28500 (epoch 38.216), train_loss = 0.78468527, grad/param norm = 1.7574e-01, time/batch = 15.3020s	
21784/28500 (epoch 38.218), train_loss = 0.96974157, grad/param norm = 1.9302e-01, time/batch = 15.1373s	
21785/28500 (epoch 38.219), train_loss = 0.89143392, grad/param norm = 1.9540e-01, time/batch = 15.1031s	
21786/28500 (epoch 38.221), train_loss = 0.73722673, grad/param norm = 1.7546e-01, time/batch = 15.0778s	
21787/28500 (epoch 38.223), train_loss = 0.94859313, grad/param norm = 1.8963e-01, time/batch = 15.0158s	
21788/28500 (epoch 38.225), train_loss = 0.99413213, grad/param norm = 2.1098e-01, time/batch = 15.2080s	
21789/28500 (epoch 38.226), train_loss = 0.83115461, grad/param norm = 1.8697e-01, time/batch = 15.3384s	
21790/28500 (epoch 38.228), train_loss = 0.94045541, grad/param norm = 1.7848e-01, time/batch = 15.4121s	
21791/28500 (epoch 38.230), train_loss = 0.92514524, grad/param norm = 2.0406e-01, time/batch = 15.4645s	
21792/28500 (epoch 38.232), train_loss = 0.91250730, grad/param norm = 2.0459e-01, time/batch = 15.2924s	
21793/28500 (epoch 38.233), train_loss = 0.84371842, grad/param norm = 1.9527e-01, time/batch = 15.3839s	
21794/28500 (epoch 38.235), train_loss = 0.84382544, grad/param norm = 1.6742e-01, time/batch = 15.4591s	
21795/28500 (epoch 38.237), train_loss = 0.75606958, grad/param norm = 1.5031e-01, time/batch = 15.2223s	
21796/28500 (epoch 38.239), train_loss = 0.81550423, grad/param norm = 1.8097e-01, time/batch = 15.0275s	
21797/28500 (epoch 38.240), train_loss = 0.75418809, grad/param norm = 1.7718e-01, time/batch = 15.3611s	
21798/28500 (epoch 38.242), train_loss = 0.79790617, grad/param norm = 1.8423e-01, time/batch = 15.3797s	
21799/28500 (epoch 38.244), train_loss = 0.87622446, grad/param norm = 1.6014e-01, time/batch = 15.0633s	
21800/28500 (epoch 38.246), train_loss = 0.90800285, grad/param norm = 1.9021e-01, time/batch = 15.0674s	
21801/28500 (epoch 38.247), train_loss = 0.97860343, grad/param norm = 2.2269e-01, time/batch = 15.6393s	
21802/28500 (epoch 38.249), train_loss = 0.83176425, grad/param norm = 1.6330e-01, time/batch = 15.6684s	
21803/28500 (epoch 38.251), train_loss = 0.84758901, grad/param norm = 1.7445e-01, time/batch = 15.4827s	
21804/28500 (epoch 38.253), train_loss = 0.96992543, grad/param norm = 1.9790e-01, time/batch = 15.5295s	
21805/28500 (epoch 38.254), train_loss = 0.98580682, grad/param norm = 1.7373e-01, time/batch = 15.4912s	
21806/28500 (epoch 38.256), train_loss = 0.83016047, grad/param norm = 1.9847e-01, time/batch = 15.3107s	
21807/28500 (epoch 38.258), train_loss = 0.83478971, grad/param norm = 1.7980e-01, time/batch = 15.3001s	
21808/28500 (epoch 38.260), train_loss = 0.84883464, grad/param norm = 1.8036e-01, time/batch = 15.4057s	
21809/28500 (epoch 38.261), train_loss = 0.74171110, grad/param norm = 1.8447e-01, time/batch = 15.5340s	
21810/28500 (epoch 38.263), train_loss = 0.92731154, grad/param norm = 2.1181e-01, time/batch = 15.5576s	
21811/28500 (epoch 38.265), train_loss = 0.80401765, grad/param norm = 1.6687e-01, time/batch = 15.5634s	
21812/28500 (epoch 38.267), train_loss = 0.97789720, grad/param norm = 2.0031e-01, time/batch = 15.4808s	
21813/28500 (epoch 38.268), train_loss = 0.88127583, grad/param norm = 1.6811e-01, time/batch = 15.4271s	
21814/28500 (epoch 38.270), train_loss = 0.84778381, grad/param norm = 1.9876e-01, time/batch = 15.2982s	
21815/28500 (epoch 38.272), train_loss = 0.84978954, grad/param norm = 1.7814e-01, time/batch = 15.2119s	
21816/28500 (epoch 38.274), train_loss = 0.90977554, grad/param norm = 1.9513e-01, time/batch = 15.2503s	
21817/28500 (epoch 38.275), train_loss = 0.90799122, grad/param norm = 1.8076e-01, time/batch = 15.1476s	
21818/28500 (epoch 38.277), train_loss = 0.84681562, grad/param norm = 1.7285e-01, time/batch = 15.0405s	
21819/28500 (epoch 38.279), train_loss = 0.88276533, grad/param norm = 2.2478e-01, time/batch = 15.1964s	
21820/28500 (epoch 38.281), train_loss = 0.89937949, grad/param norm = 2.0537e-01, time/batch = 14.9786s	
21821/28500 (epoch 38.282), train_loss = 0.83343104, grad/param norm = 1.5452e-01, time/batch = 15.5429s	
21822/28500 (epoch 38.284), train_loss = 0.87681490, grad/param norm = 1.9768e-01, time/batch = 15.3059s	
21823/28500 (epoch 38.286), train_loss = 0.95069442, grad/param norm = 1.8771e-01, time/batch = 15.4729s	
21824/28500 (epoch 38.288), train_loss = 0.85493164, grad/param norm = 1.9217e-01, time/batch = 15.1407s	
21825/28500 (epoch 38.289), train_loss = 0.86887441, grad/param norm = 1.9304e-01, time/batch = 15.0531s	
21826/28500 (epoch 38.291), train_loss = 0.87390855, grad/param norm = 1.9128e-01, time/batch = 15.1540s	
21827/28500 (epoch 38.293), train_loss = 0.86550664, grad/param norm = 1.9060e-01, time/batch = 15.1306s	
21828/28500 (epoch 38.295), train_loss = 0.76077825, grad/param norm = 1.8188e-01, time/batch = 15.3711s	
21829/28500 (epoch 38.296), train_loss = 0.75859955, grad/param norm = 1.6329e-01, time/batch = 15.3633s	
21830/28500 (epoch 38.298), train_loss = 0.91814481, grad/param norm = 1.8550e-01, time/batch = 15.5237s	
21831/28500 (epoch 38.300), train_loss = 0.79749688, grad/param norm = 1.9107e-01, time/batch = 15.6347s	
21832/28500 (epoch 38.302), train_loss = 0.72428932, grad/param norm = 1.6907e-01, time/batch = 15.4453s	
21833/28500 (epoch 38.304), train_loss = 0.83145399, grad/param norm = 1.8706e-01, time/batch = 15.3809s	
21834/28500 (epoch 38.305), train_loss = 0.87626027, grad/param norm = 1.7388e-01, time/batch = 15.3817s	
21835/28500 (epoch 38.307), train_loss = 0.83145565, grad/param norm = 1.9602e-01, time/batch = 15.5438s	
21836/28500 (epoch 38.309), train_loss = 0.83822573, grad/param norm = 1.7107e-01, time/batch = 15.5472s	
21837/28500 (epoch 38.311), train_loss = 0.88811179, grad/param norm = 1.8066e-01, time/batch = 15.7287s	
21838/28500 (epoch 38.312), train_loss = 0.89724761, grad/param norm = 1.8719e-01, time/batch = 15.5498s	
21839/28500 (epoch 38.314), train_loss = 0.88514125, grad/param norm = 1.8420e-01, time/batch = 15.6244s	
21840/28500 (epoch 38.316), train_loss = 0.86811380, grad/param norm = 2.0856e-01, time/batch = 15.5973s	
21841/28500 (epoch 38.318), train_loss = 0.94249955, grad/param norm = 1.8275e-01, time/batch = 15.7235s	
21842/28500 (epoch 38.319), train_loss = 0.80779031, grad/param norm = 1.7666e-01, time/batch = 15.6823s	
21843/28500 (epoch 38.321), train_loss = 0.80955701, grad/param norm = 1.9233e-01, time/batch = 15.5058s	
21844/28500 (epoch 38.323), train_loss = 0.86241744, grad/param norm = 2.0014e-01, time/batch = 15.4619s	
21845/28500 (epoch 38.325), train_loss = 0.98203698, grad/param norm = 1.9671e-01, time/batch = 15.4563s	
21846/28500 (epoch 38.326), train_loss = 0.87162620, grad/param norm = 1.8299e-01, time/batch = 15.3201s	
21847/28500 (epoch 38.328), train_loss = 0.69363886, grad/param norm = 1.5785e-01, time/batch = 15.1439s	
21848/28500 (epoch 38.330), train_loss = 0.79334819, grad/param norm = 1.9599e-01, time/batch = 15.3742s	
21849/28500 (epoch 38.332), train_loss = 0.81291756, grad/param norm = 1.7388e-01, time/batch = 15.3093s	
21850/28500 (epoch 38.333), train_loss = 0.67060001, grad/param norm = 1.9410e-01, time/batch = 15.3500s	
21851/28500 (epoch 38.335), train_loss = 0.73667054, grad/param norm = 1.6361e-01, time/batch = 15.4486s	
21852/28500 (epoch 38.337), train_loss = 0.69681119, grad/param norm = 1.5909e-01, time/batch = 15.4047s	
21853/28500 (epoch 38.339), train_loss = 0.69298844, grad/param norm = 1.4502e-01, time/batch = 15.5310s	
21854/28500 (epoch 38.340), train_loss = 0.84567457, grad/param norm = 2.3256e-01, time/batch = 15.4992s	
21855/28500 (epoch 38.342), train_loss = 0.83880766, grad/param norm = 1.9262e-01, time/batch = 15.3576s	
21856/28500 (epoch 38.344), train_loss = 0.73583895, grad/param norm = 2.3046e-01, time/batch = 15.3877s	
21857/28500 (epoch 38.346), train_loss = 0.70738393, grad/param norm = 1.5830e-01, time/batch = 15.3015s	
21858/28500 (epoch 38.347), train_loss = 0.84824637, grad/param norm = 1.6715e-01, time/batch = 15.3648s	
21859/28500 (epoch 38.349), train_loss = 0.84728034, grad/param norm = 1.8541e-01, time/batch = 15.4630s	
21860/28500 (epoch 38.351), train_loss = 0.74869108, grad/param norm = 1.7525e-01, time/batch = 15.4293s	
21861/28500 (epoch 38.353), train_loss = 0.84125283, grad/param norm = 2.2613e-01, time/batch = 15.6420s	
21862/28500 (epoch 38.354), train_loss = 0.74189289, grad/param norm = 1.7052e-01, time/batch = 15.6259s	
21863/28500 (epoch 38.356), train_loss = 0.80466477, grad/param norm = 1.6630e-01, time/batch = 15.2776s	
21864/28500 (epoch 38.358), train_loss = 0.88372905, grad/param norm = 1.7634e-01, time/batch = 15.1214s	
21865/28500 (epoch 38.360), train_loss = 0.86291160, grad/param norm = 2.0622e-01, time/batch = 15.0588s	
21866/28500 (epoch 38.361), train_loss = 0.75929287, grad/param norm = 1.7993e-01, time/batch = 15.0461s	
21867/28500 (epoch 38.363), train_loss = 0.75345973, grad/param norm = 1.5409e-01, time/batch = 15.6050s	
21868/28500 (epoch 38.365), train_loss = 0.81066567, grad/param norm = 1.9563e-01, time/batch = 15.4318s	
21869/28500 (epoch 38.367), train_loss = 0.84914654, grad/param norm = 1.7174e-01, time/batch = 15.4778s	
21870/28500 (epoch 38.368), train_loss = 0.77609464, grad/param norm = 1.7340e-01, time/batch = 15.4363s	
21871/28500 (epoch 38.370), train_loss = 0.84803801, grad/param norm = 1.8752e-01, time/batch = 15.2926s	
21872/28500 (epoch 38.372), train_loss = 0.68573952, grad/param norm = 1.9321e-01, time/batch = 15.1265s	
21873/28500 (epoch 38.374), train_loss = 0.80321713, grad/param norm = 1.9864e-01, time/batch = 15.4679s	
21874/28500 (epoch 38.375), train_loss = 0.94113545, grad/param norm = 2.2189e-01, time/batch = 15.3098s	
21875/28500 (epoch 38.377), train_loss = 0.77888846, grad/param norm = 2.3970e-01, time/batch = 15.2146s	
21876/28500 (epoch 38.379), train_loss = 0.64622665, grad/param norm = 1.7627e-01, time/batch = 15.3569s	
21877/28500 (epoch 38.381), train_loss = 0.80176909, grad/param norm = 1.6717e-01, time/batch = 15.5589s	
21878/28500 (epoch 38.382), train_loss = 0.79180934, grad/param norm = 1.9800e-01, time/batch = 15.2972s	
21879/28500 (epoch 38.384), train_loss = 0.69345450, grad/param norm = 1.7862e-01, time/batch = 15.3730s	
21880/28500 (epoch 38.386), train_loss = 0.74093968, grad/param norm = 1.7202e-01, time/batch = 15.3140s	
21881/28500 (epoch 38.388), train_loss = 0.90040269, grad/param norm = 1.8357e-01, time/batch = 15.4550s	
21882/28500 (epoch 38.389), train_loss = 0.77026990, grad/param norm = 2.0090e-01, time/batch = 15.5462s	
21883/28500 (epoch 38.391), train_loss = 0.72884458, grad/param norm = 1.8672e-01, time/batch = 15.4997s	
21884/28500 (epoch 38.393), train_loss = 0.74580296, grad/param norm = 1.7589e-01, time/batch = 15.3869s	
21885/28500 (epoch 38.395), train_loss = 0.92806900, grad/param norm = 1.7205e-01, time/batch = 15.2160s	
21886/28500 (epoch 38.396), train_loss = 0.89645386, grad/param norm = 1.8306e-01, time/batch = 15.5172s	
21887/28500 (epoch 38.398), train_loss = 0.61785817, grad/param norm = 1.7565e-01, time/batch = 15.5372s	
21888/28500 (epoch 38.400), train_loss = 0.77565944, grad/param norm = 1.7158e-01, time/batch = 15.3910s	
21889/28500 (epoch 38.402), train_loss = 0.83788251, grad/param norm = 1.8688e-01, time/batch = 15.5653s	
21890/28500 (epoch 38.404), train_loss = 0.83077824, grad/param norm = 1.8596e-01, time/batch = 15.5415s	
21891/28500 (epoch 38.405), train_loss = 0.87187991, grad/param norm = 1.7391e-01, time/batch = 15.7194s	
21892/28500 (epoch 38.407), train_loss = 0.83459468, grad/param norm = 1.8563e-01, time/batch = 15.6386s	
21893/28500 (epoch 38.409), train_loss = 0.82562648, grad/param norm = 1.8208e-01, time/batch = 15.5297s	
21894/28500 (epoch 38.411), train_loss = 0.93652916, grad/param norm = 2.1782e-01, time/batch = 15.4417s	
21895/28500 (epoch 38.412), train_loss = 0.96556821, grad/param norm = 2.3835e-01, time/batch = 15.4539s	
21896/28500 (epoch 38.414), train_loss = 0.85635257, grad/param norm = 2.3569e-01, time/batch = 15.3290s	
21897/28500 (epoch 38.416), train_loss = 0.75662076, grad/param norm = 2.6719e-01, time/batch = 15.2536s	
21898/28500 (epoch 38.418), train_loss = 0.84032108, grad/param norm = 1.7345e-01, time/batch = 15.3000s	
21899/28500 (epoch 38.419), train_loss = 0.93228963, grad/param norm = 2.4009e-01, time/batch = 15.4464s	
21900/28500 (epoch 38.421), train_loss = 0.90668198, grad/param norm = 1.8430e-01, time/batch = 15.4666s	
21901/28500 (epoch 38.423), train_loss = 0.90996711, grad/param norm = 2.1187e-01, time/batch = 15.3536s	
21902/28500 (epoch 38.425), train_loss = 0.85448886, grad/param norm = 2.3876e-01, time/batch = 15.5297s	
21903/28500 (epoch 38.426), train_loss = 0.85038505, grad/param norm = 1.9891e-01, time/batch = 15.5651s	
21904/28500 (epoch 38.428), train_loss = 0.99856015, grad/param norm = 1.9977e-01, time/batch = 15.4674s	
21905/28500 (epoch 38.430), train_loss = 0.98670904, grad/param norm = 1.8849e-01, time/batch = 15.3088s	
21906/28500 (epoch 38.432), train_loss = 0.85495490, grad/param norm = 1.9832e-01, time/batch = 15.6007s	
21907/28500 (epoch 38.433), train_loss = 0.90120571, grad/param norm = 1.9984e-01, time/batch = 15.2315s	
21908/28500 (epoch 38.435), train_loss = 0.87372681, grad/param norm = 2.5183e-01, time/batch = 15.3355s	
21909/28500 (epoch 38.437), train_loss = 0.79659189, grad/param norm = 1.7616e-01, time/batch = 15.2529s	
21910/28500 (epoch 38.439), train_loss = 0.83948974, grad/param norm = 1.6672e-01, time/batch = 15.3629s	
21911/28500 (epoch 38.440), train_loss = 0.99944496, grad/param norm = 2.0396e-01, time/batch = 15.6367s	
21912/28500 (epoch 38.442), train_loss = 0.78199852, grad/param norm = 2.0111e-01, time/batch = 15.3595s	
21913/28500 (epoch 38.444), train_loss = 0.75009318, grad/param norm = 1.6020e-01, time/batch = 14.9883s	
21914/28500 (epoch 38.446), train_loss = 0.72446921, grad/param norm = 1.9509e-01, time/batch = 15.2782s	
21915/28500 (epoch 38.447), train_loss = 0.72962280, grad/param norm = 1.7453e-01, time/batch = 15.3896s	
21916/28500 (epoch 38.449), train_loss = 0.79940823, grad/param norm = 1.7723e-01, time/batch = 15.6231s	
21917/28500 (epoch 38.451), train_loss = 0.80373915, grad/param norm = 1.6951e-01, time/batch = 15.6195s	
21918/28500 (epoch 38.453), train_loss = 0.80118878, grad/param norm = 1.7861e-01, time/batch = 15.5459s	
21919/28500 (epoch 38.454), train_loss = 0.75460861, grad/param norm = 1.7026e-01, time/batch = 15.6156s	
21920/28500 (epoch 38.456), train_loss = 0.91647092, grad/param norm = 2.4637e-01, time/batch = 15.4792s	
21921/28500 (epoch 38.458), train_loss = 0.82781532, grad/param norm = 1.8905e-01, time/batch = 15.3376s	
21922/28500 (epoch 38.460), train_loss = 0.91905158, grad/param norm = 2.1634e-01, time/batch = 15.3041s	
21923/28500 (epoch 38.461), train_loss = 0.77170604, grad/param norm = 1.8215e-01, time/batch = 15.1721s	
21924/28500 (epoch 38.463), train_loss = 0.70965499, grad/param norm = 1.5763e-01, time/batch = 15.2943s	
21925/28500 (epoch 38.465), train_loss = 0.67186096, grad/param norm = 2.0982e-01, time/batch = 15.5038s	
21926/28500 (epoch 38.467), train_loss = 0.83440264, grad/param norm = 1.6724e-01, time/batch = 15.2046s	
21927/28500 (epoch 38.468), train_loss = 0.73195077, grad/param norm = 1.4777e-01, time/batch = 15.2155s	
21928/28500 (epoch 38.470), train_loss = 0.80270904, grad/param norm = 1.9391e-01, time/batch = 15.4645s	
21929/28500 (epoch 38.472), train_loss = 0.74005167, grad/param norm = 1.6551e-01, time/batch = 15.5961s	
21930/28500 (epoch 38.474), train_loss = 0.96753739, grad/param norm = 1.9679e-01, time/batch = 15.5432s	
21931/28500 (epoch 38.475), train_loss = 0.77715552, grad/param norm = 1.7991e-01, time/batch = 15.6392s	
21932/28500 (epoch 38.477), train_loss = 0.81905189, grad/param norm = 1.9540e-01, time/batch = 15.5602s	
21933/28500 (epoch 38.479), train_loss = 0.88289196, grad/param norm = 1.9158e-01, time/batch = 15.5189s	
21934/28500 (epoch 38.481), train_loss = 0.88994046, grad/param norm = 1.8294e-01, time/batch = 15.3112s	
21935/28500 (epoch 38.482), train_loss = 0.73316167, grad/param norm = 1.8807e-01, time/batch = 15.3668s	
21936/28500 (epoch 38.484), train_loss = 0.77472401, grad/param norm = 1.8769e-01, time/batch = 14.9431s	
21937/28500 (epoch 38.486), train_loss = 0.67327283, grad/param norm = 1.8435e-01, time/batch = 15.4410s	
21938/28500 (epoch 38.488), train_loss = 0.88936110, grad/param norm = 1.9696e-01, time/batch = 15.2158s	
21939/28500 (epoch 38.489), train_loss = 0.95429754, grad/param norm = 1.7119e-01, time/batch = 15.4441s	
21940/28500 (epoch 38.491), train_loss = 0.77446241, grad/param norm = 1.9912e-01, time/batch = 15.3896s	
21941/28500 (epoch 38.493), train_loss = 0.82570706, grad/param norm = 1.8915e-01, time/batch = 15.3929s	
21942/28500 (epoch 38.495), train_loss = 0.84038578, grad/param norm = 1.9771e-01, time/batch = 15.2323s	
21943/28500 (epoch 38.496), train_loss = 0.75316525, grad/param norm = 1.9438e-01, time/batch = 15.3157s	
21944/28500 (epoch 38.498), train_loss = 0.80762321, grad/param norm = 1.5843e-01, time/batch = 15.5256s	
21945/28500 (epoch 38.500), train_loss = 0.76340080, grad/param norm = 1.5815e-01, time/batch = 15.4739s	
21946/28500 (epoch 38.502), train_loss = 0.88202584, grad/param norm = 1.6884e-01, time/batch = 15.4571s	
21947/28500 (epoch 38.504), train_loss = 0.88411914, grad/param norm = 1.7308e-01, time/batch = 15.5598s	
21948/28500 (epoch 38.505), train_loss = 0.78095329, grad/param norm = 1.8272e-01, time/batch = 15.3728s	
21949/28500 (epoch 38.507), train_loss = 0.92177080, grad/param norm = 2.2339e-01, time/batch = 15.0040s	
21950/28500 (epoch 38.509), train_loss = 0.83315169, grad/param norm = 1.7184e-01, time/batch = 15.0458s	
21951/28500 (epoch 38.511), train_loss = 0.82178816, grad/param norm = 1.7857e-01, time/batch = 15.5528s	
21952/28500 (epoch 38.512), train_loss = 0.86869382, grad/param norm = 1.7842e-01, time/batch = 15.2884s	
21953/28500 (epoch 38.514), train_loss = 0.84285904, grad/param norm = 1.9671e-01, time/batch = 15.2332s	
21954/28500 (epoch 38.516), train_loss = 0.81904745, grad/param norm = 1.6690e-01, time/batch = 15.4616s	
21955/28500 (epoch 38.518), train_loss = 0.87147632, grad/param norm = 1.8116e-01, time/batch = 15.2659s	
21956/28500 (epoch 38.519), train_loss = 0.87562817, grad/param norm = 1.8711e-01, time/batch = 15.4196s	
21957/28500 (epoch 38.521), train_loss = 0.96109163, grad/param norm = 2.2612e-01, time/batch = 15.2348s	
21958/28500 (epoch 38.523), train_loss = 0.86943658, grad/param norm = 1.9432e-01, time/batch = 15.1492s	
21959/28500 (epoch 38.525), train_loss = 0.95068095, grad/param norm = 1.9695e-01, time/batch = 15.0481s	
21960/28500 (epoch 38.526), train_loss = 0.88249169, grad/param norm = 1.7512e-01, time/batch = 15.1906s	
21961/28500 (epoch 38.528), train_loss = 0.88526101, grad/param norm = 2.2641e-01, time/batch = 15.5500s	
21962/28500 (epoch 38.530), train_loss = 0.89931230, grad/param norm = 1.8999e-01, time/batch = 15.0117s	
21963/28500 (epoch 38.532), train_loss = 0.81423643, grad/param norm = 1.8730e-01, time/batch = 15.1106s	
21964/28500 (epoch 38.533), train_loss = 0.87737960, grad/param norm = 1.8148e-01, time/batch = 25.5361s	
21965/28500 (epoch 38.535), train_loss = 0.73323310, grad/param norm = 1.5546e-01, time/batch = 16.8694s	
21966/28500 (epoch 38.537), train_loss = 0.73938869, grad/param norm = 1.7393e-01, time/batch = 15.2196s	
21967/28500 (epoch 38.539), train_loss = 0.71186397, grad/param norm = 1.7640e-01, time/batch = 15.3065s	
21968/28500 (epoch 38.540), train_loss = 0.82005361, grad/param norm = 1.6781e-01, time/batch = 15.3088s	
21969/28500 (epoch 38.542), train_loss = 0.86943695, grad/param norm = 2.0001e-01, time/batch = 15.2373s	
21970/28500 (epoch 38.544), train_loss = 0.96800451, grad/param norm = 1.8936e-01, time/batch = 15.5390s	
21971/28500 (epoch 38.546), train_loss = 0.82868335, grad/param norm = 1.8312e-01, time/batch = 15.3696s	
21972/28500 (epoch 38.547), train_loss = 0.81505761, grad/param norm = 2.0533e-01, time/batch = 15.1374s	
21973/28500 (epoch 38.549), train_loss = 0.70625737, grad/param norm = 1.5833e-01, time/batch = 15.0640s	
21974/28500 (epoch 38.551), train_loss = 0.78497245, grad/param norm = 2.0953e-01, time/batch = 15.2188s	
21975/28500 (epoch 38.553), train_loss = 0.99451141, grad/param norm = 2.1570e-01, time/batch = 15.1735s	
21976/28500 (epoch 38.554), train_loss = 0.89211079, grad/param norm = 1.9065e-01, time/batch = 15.1885s	
21977/28500 (epoch 38.556), train_loss = 0.88108888, grad/param norm = 1.7749e-01, time/batch = 14.9762s	
21978/28500 (epoch 38.558), train_loss = 0.88640865, grad/param norm = 1.6530e-01, time/batch = 15.1435s	
21979/28500 (epoch 38.560), train_loss = 0.88920767, grad/param norm = 1.8481e-01, time/batch = 15.4608s	
21980/28500 (epoch 38.561), train_loss = 0.89068030, grad/param norm = 2.0910e-01, time/batch = 15.2235s	
21981/28500 (epoch 38.563), train_loss = 0.97327529, grad/param norm = 2.2541e-01, time/batch = 15.3848s	
21982/28500 (epoch 38.565), train_loss = 0.77400800, grad/param norm = 1.7440e-01, time/batch = 15.3930s	
21983/28500 (epoch 38.567), train_loss = 0.73752921, grad/param norm = 2.0263e-01, time/batch = 15.6253s	
21984/28500 (epoch 38.568), train_loss = 0.85674872, grad/param norm = 1.9930e-01, time/batch = 15.3866s	
21985/28500 (epoch 38.570), train_loss = 0.81238432, grad/param norm = 2.0354e-01, time/batch = 15.1534s	
21986/28500 (epoch 38.572), train_loss = 0.86555241, grad/param norm = 1.7948e-01, time/batch = 15.1186s	
21987/28500 (epoch 38.574), train_loss = 0.79456750, grad/param norm = 1.7307e-01, time/batch = 15.1169s	
21988/28500 (epoch 38.575), train_loss = 0.78577845, grad/param norm = 1.6924e-01, time/batch = 15.1698s	
21989/28500 (epoch 38.577), train_loss = 0.89466109, grad/param norm = 1.7579e-01, time/batch = 15.2700s	
21990/28500 (epoch 38.579), train_loss = 0.90356945, grad/param norm = 1.9921e-01, time/batch = 15.3021s	
21991/28500 (epoch 38.581), train_loss = 0.79231644, grad/param norm = 2.1172e-01, time/batch = 15.3665s	
21992/28500 (epoch 38.582), train_loss = 0.94935002, grad/param norm = 2.1832e-01, time/batch = 15.2336s	
21993/28500 (epoch 38.584), train_loss = 0.78549260, grad/param norm = 1.7982e-01, time/batch = 15.3943s	
21994/28500 (epoch 38.586), train_loss = 0.77309403, grad/param norm = 1.7143e-01, time/batch = 15.4235s	
21995/28500 (epoch 38.588), train_loss = 0.78502149, grad/param norm = 1.8152e-01, time/batch = 15.2920s	
21996/28500 (epoch 38.589), train_loss = 0.82371851, grad/param norm = 2.0918e-01, time/batch = 15.3014s	
21997/28500 (epoch 38.591), train_loss = 0.83813362, grad/param norm = 1.7869e-01, time/batch = 15.4503s	
21998/28500 (epoch 38.593), train_loss = 0.80409313, grad/param norm = 1.6577e-01, time/batch = 15.2650s	
21999/28500 (epoch 38.595), train_loss = 1.00311969, grad/param norm = 2.2722e-01, time/batch = 15.1275s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch38.60_1.9237.t7	
22000/28500 (epoch 38.596), train_loss = 0.99702375, grad/param norm = 1.9876e-01, time/batch = 15.0585s	
22001/28500 (epoch 38.598), train_loss = 1.41563185, grad/param norm = 2.8010e-01, time/batch = 15.8100s	
22002/28500 (epoch 38.600), train_loss = 0.83513123, grad/param norm = 2.1562e-01, time/batch = 15.5417s	
22003/28500 (epoch 38.602), train_loss = 0.93667106, grad/param norm = 2.6217e-01, time/batch = 15.3110s	
22004/28500 (epoch 38.604), train_loss = 0.92218494, grad/param norm = 1.9242e-01, time/batch = 15.2311s	
22005/28500 (epoch 38.605), train_loss = 0.91809337, grad/param norm = 2.0311e-01, time/batch = 15.3134s	
22006/28500 (epoch 38.607), train_loss = 0.95356748, grad/param norm = 1.7803e-01, time/batch = 15.3324s	
22007/28500 (epoch 38.609), train_loss = 0.86178331, grad/param norm = 1.9307e-01, time/batch = 15.2520s	
22008/28500 (epoch 38.611), train_loss = 0.82438701, grad/param norm = 2.0016e-01, time/batch = 15.2109s	
22009/28500 (epoch 38.612), train_loss = 0.90237604, grad/param norm = 2.1132e-01, time/batch = 15.1465s	
22010/28500 (epoch 38.614), train_loss = 0.91753005, grad/param norm = 1.7964e-01, time/batch = 15.4967s	
22011/28500 (epoch 38.616), train_loss = 0.80063008, grad/param norm = 1.9183e-01, time/batch = 15.2305s	
22012/28500 (epoch 38.618), train_loss = 0.82120818, grad/param norm = 1.7170e-01, time/batch = 15.3692s	
22013/28500 (epoch 38.619), train_loss = 0.90760673, grad/param norm = 2.2968e-01, time/batch = 15.2887s	
22014/28500 (epoch 38.621), train_loss = 0.68878241, grad/param norm = 1.8375e-01, time/batch = 15.6242s	
22015/28500 (epoch 38.623), train_loss = 0.96356723, grad/param norm = 1.8033e-01, time/batch = 15.2998s	
22016/28500 (epoch 38.625), train_loss = 0.76333294, grad/param norm = 1.8862e-01, time/batch = 15.2173s	
22017/28500 (epoch 38.626), train_loss = 0.66831908, grad/param norm = 1.6765e-01, time/batch = 15.2226s	
22018/28500 (epoch 38.628), train_loss = 0.77822292, grad/param norm = 1.8351e-01, time/batch = 15.2649s	
22019/28500 (epoch 38.630), train_loss = 0.73044493, grad/param norm = 1.6548e-01, time/batch = 15.3652s	
22020/28500 (epoch 38.632), train_loss = 0.91721374, grad/param norm = 2.2251e-01, time/batch = 15.4140s	
22021/28500 (epoch 38.633), train_loss = 0.98103839, grad/param norm = 1.7211e-01, time/batch = 15.4692s	
22022/28500 (epoch 38.635), train_loss = 0.87757743, grad/param norm = 2.0994e-01, time/batch = 15.4651s	
22023/28500 (epoch 38.637), train_loss = 0.86671705, grad/param norm = 1.7758e-01, time/batch = 15.1717s	
22024/28500 (epoch 38.639), train_loss = 0.76622478, grad/param norm = 1.8820e-01, time/batch = 15.2305s	
22025/28500 (epoch 38.640), train_loss = 0.79010691, grad/param norm = 1.7233e-01, time/batch = 15.3838s	
22026/28500 (epoch 38.642), train_loss = 0.80206083, grad/param norm = 1.7820e-01, time/batch = 15.3070s	
22027/28500 (epoch 38.644), train_loss = 0.86986228, grad/param norm = 1.8096e-01, time/batch = 15.2220s	
22028/28500 (epoch 38.646), train_loss = 0.71220517, grad/param norm = 1.5614e-01, time/batch = 15.3927s	
22029/28500 (epoch 38.647), train_loss = 0.77920007, grad/param norm = 1.6573e-01, time/batch = 15.4345s	
22030/28500 (epoch 38.649), train_loss = 0.77081801, grad/param norm = 2.0764e-01, time/batch = 15.0561s	
22031/28500 (epoch 38.651), train_loss = 0.72829660, grad/param norm = 1.4728e-01, time/batch = 15.0572s	
22032/28500 (epoch 38.653), train_loss = 0.72566567, grad/param norm = 1.6958e-01, time/batch = 15.4876s	
22033/28500 (epoch 38.654), train_loss = 0.76153728, grad/param norm = 1.9925e-01, time/batch = 15.4826s	
22034/28500 (epoch 38.656), train_loss = 0.72098306, grad/param norm = 2.1730e-01, time/batch = 15.2545s	
22035/28500 (epoch 38.658), train_loss = 0.81745825, grad/param norm = 1.9351e-01, time/batch = 15.1084s	
22036/28500 (epoch 38.660), train_loss = 0.84547750, grad/param norm = 1.7130e-01, time/batch = 15.4815s	
22037/28500 (epoch 38.661), train_loss = 0.92484938, grad/param norm = 2.0677e-01, time/batch = 15.4335s	
22038/28500 (epoch 38.663), train_loss = 0.93142029, grad/param norm = 1.9505e-01, time/batch = 15.4032s	
22039/28500 (epoch 38.665), train_loss = 0.85545603, grad/param norm = 2.0943e-01, time/batch = 15.4659s	
22040/28500 (epoch 38.667), train_loss = 0.84236429, grad/param norm = 2.0016e-01, time/batch = 15.4850s	
22041/28500 (epoch 38.668), train_loss = 0.83475266, grad/param norm = 1.7959e-01, time/batch = 15.6411s	
22042/28500 (epoch 38.670), train_loss = 0.83669015, grad/param norm = 1.8055e-01, time/batch = 15.6307s	
22043/28500 (epoch 38.672), train_loss = 0.76579391, grad/param norm = 1.7554e-01, time/batch = 15.5625s	
22044/28500 (epoch 38.674), train_loss = 0.66446485, grad/param norm = 1.8902e-01, time/batch = 15.6351s	
22045/28500 (epoch 38.675), train_loss = 0.70295166, grad/param norm = 1.7296e-01, time/batch = 15.5857s	
22046/28500 (epoch 38.677), train_loss = 0.77836636, grad/param norm = 1.6205e-01, time/batch = 15.5498s	
22047/28500 (epoch 38.679), train_loss = 0.79474382, grad/param norm = 1.9848e-01, time/batch = 15.4237s	
22048/28500 (epoch 38.681), train_loss = 0.86218088, grad/param norm = 1.6700e-01, time/batch = 15.3779s	
22049/28500 (epoch 38.682), train_loss = 0.78975220, grad/param norm = 1.8409e-01, time/batch = 15.4509s	
22050/28500 (epoch 38.684), train_loss = 0.82061747, grad/param norm = 1.8469e-01, time/batch = 15.3039s	
22051/28500 (epoch 38.686), train_loss = 0.79283621, grad/param norm = 1.9552e-01, time/batch = 15.4004s	
22052/28500 (epoch 38.688), train_loss = 0.75359081, grad/param norm = 1.3952e-01, time/batch = 15.3796s	
22053/28500 (epoch 38.689), train_loss = 0.77311592, grad/param norm = 2.2492e-01, time/batch = 15.7234s	
22054/28500 (epoch 38.691), train_loss = 0.88254562, grad/param norm = 1.9789e-01, time/batch = 15.5523s	
22055/28500 (epoch 38.693), train_loss = 0.80477062, grad/param norm = 1.9002e-01, time/batch = 15.4004s	
22056/28500 (epoch 38.695), train_loss = 0.62547953, grad/param norm = 1.5820e-01, time/batch = 15.3933s	
22057/28500 (epoch 38.696), train_loss = 0.79933373, grad/param norm = 1.9939e-01, time/batch = 15.3946s	
22058/28500 (epoch 38.698), train_loss = 0.87714274, grad/param norm = 1.8960e-01, time/batch = 15.3676s	
22059/28500 (epoch 38.700), train_loss = 0.84725029, grad/param norm = 1.8505e-01, time/batch = 14.9930s	
22060/28500 (epoch 38.702), train_loss = 0.82801573, grad/param norm = 2.0076e-01, time/batch = 15.3437s	
22061/28500 (epoch 38.704), train_loss = 0.88026849, grad/param norm = 1.9534e-01, time/batch = 15.6076s	
22062/28500 (epoch 38.705), train_loss = 0.90488160, grad/param norm = 2.3753e-01, time/batch = 15.5708s	
22063/28500 (epoch 38.707), train_loss = 0.76370096, grad/param norm = 1.8347e-01, time/batch = 15.4868s	
22064/28500 (epoch 38.709), train_loss = 0.98920334, grad/param norm = 2.2879e-01, time/batch = 15.5266s	
22065/28500 (epoch 38.711), train_loss = 0.79558741, grad/param norm = 2.3173e-01, time/batch = 15.5941s	
22066/28500 (epoch 38.712), train_loss = 0.86169248, grad/param norm = 1.8119e-01, time/batch = 15.6380s	
22067/28500 (epoch 38.714), train_loss = 0.95519615, grad/param norm = 2.0737e-01, time/batch = 15.6521s	
22068/28500 (epoch 38.716), train_loss = 0.81416668, grad/param norm = 1.7615e-01, time/batch = 15.7013s	
22069/28500 (epoch 38.718), train_loss = 0.83876797, grad/param norm = 1.9295e-01, time/batch = 15.5298s	
22070/28500 (epoch 38.719), train_loss = 0.85165242, grad/param norm = 1.8165e-01, time/batch = 15.4867s	
22071/28500 (epoch 38.721), train_loss = 0.65123651, grad/param norm = 1.8219e-01, time/batch = 15.3678s	
22072/28500 (epoch 38.723), train_loss = 0.83953616, grad/param norm = 1.8904e-01, time/batch = 15.6897s	
22073/28500 (epoch 38.725), train_loss = 0.89906184, grad/param norm = 1.8247e-01, time/batch = 15.5226s	
22074/28500 (epoch 38.726), train_loss = 0.82333740, grad/param norm = 1.9539e-01, time/batch = 15.4770s	
22075/28500 (epoch 38.728), train_loss = 0.74815843, grad/param norm = 1.6876e-01, time/batch = 15.5504s	
22076/28500 (epoch 38.730), train_loss = 0.83923514, grad/param norm = 2.1380e-01, time/batch = 15.3736s	
22077/28500 (epoch 38.732), train_loss = 0.67526822, grad/param norm = 1.6181e-01, time/batch = 15.3874s	
22078/28500 (epoch 38.733), train_loss = 0.70005698, grad/param norm = 1.6793e-01, time/batch = 15.3009s	
22079/28500 (epoch 38.735), train_loss = 0.69952110, grad/param norm = 1.5543e-01, time/batch = 15.2059s	
22080/28500 (epoch 38.737), train_loss = 0.63584749, grad/param norm = 1.5338e-01, time/batch = 15.3088s	
22081/28500 (epoch 38.739), train_loss = 0.72572722, grad/param norm = 1.6884e-01, time/batch = 15.0617s	
22082/28500 (epoch 38.740), train_loss = 0.82735235, grad/param norm = 1.8571e-01, time/batch = 15.3286s	
22083/28500 (epoch 38.742), train_loss = 0.73075045, grad/param norm = 1.8660e-01, time/batch = 15.5281s	
22084/28500 (epoch 38.744), train_loss = 0.81616500, grad/param norm = 1.7486e-01, time/batch = 15.3827s	
22085/28500 (epoch 38.746), train_loss = 0.76148743, grad/param norm = 1.5280e-01, time/batch = 15.2918s	
22086/28500 (epoch 38.747), train_loss = 0.77100039, grad/param norm = 1.7055e-01, time/batch = 15.4344s	
22087/28500 (epoch 38.749), train_loss = 0.87911412, grad/param norm = 2.0823e-01, time/batch = 15.3984s	
22088/28500 (epoch 38.751), train_loss = 0.74255567, grad/param norm = 2.0487e-01, time/batch = 15.1269s	
22089/28500 (epoch 38.753), train_loss = 0.81673670, grad/param norm = 1.5466e-01, time/batch = 15.0502s	
22090/28500 (epoch 38.754), train_loss = 0.72830159, grad/param norm = 1.7854e-01, time/batch = 15.5523s	
22091/28500 (epoch 38.756), train_loss = 0.93768259, grad/param norm = 1.8655e-01, time/batch = 15.7049s	
22092/28500 (epoch 38.758), train_loss = 0.86012616, grad/param norm = 2.1170e-01, time/batch = 15.3819s	
22093/28500 (epoch 38.760), train_loss = 0.72332865, grad/param norm = 1.9966e-01, time/batch = 14.9853s	
22094/28500 (epoch 38.761), train_loss = 0.75185404, grad/param norm = 1.8286e-01, time/batch = 15.2439s	
22095/28500 (epoch 38.763), train_loss = 0.64614623, grad/param norm = 1.5606e-01, time/batch = 15.4683s	
22096/28500 (epoch 38.765), train_loss = 0.80346627, grad/param norm = 1.7749e-01, time/batch = 15.3042s	
22097/28500 (epoch 38.767), train_loss = 0.66492117, grad/param norm = 1.4571e-01, time/batch = 15.1490s	
22098/28500 (epoch 38.768), train_loss = 0.85118526, grad/param norm = 1.7213e-01, time/batch = 15.0434s	
22099/28500 (epoch 38.770), train_loss = 0.70851728, grad/param norm = 1.6492e-01, time/batch = 15.0541s	
22100/28500 (epoch 38.772), train_loss = 0.65831480, grad/param norm = 1.5881e-01, time/batch = 15.0788s	
22101/28500 (epoch 38.774), train_loss = 0.81494939, grad/param norm = 1.6868e-01, time/batch = 15.3560s	
22102/28500 (epoch 38.775), train_loss = 0.87470735, grad/param norm = 1.7637e-01, time/batch = 15.2085s	
22103/28500 (epoch 38.777), train_loss = 0.87277925, grad/param norm = 1.6142e-01, time/batch = 15.4947s	
22104/28500 (epoch 38.779), train_loss = 0.67008856, grad/param norm = 1.3689e-01, time/batch = 15.1511s	
22105/28500 (epoch 38.781), train_loss = 0.80391098, grad/param norm = 2.0160e-01, time/batch = 14.9981s	
22106/28500 (epoch 38.782), train_loss = 0.83094853, grad/param norm = 3.0354e-01, time/batch = 15.2786s	
22107/28500 (epoch 38.784), train_loss = 0.66698805, grad/param norm = 1.7003e-01, time/batch = 15.2775s	
22108/28500 (epoch 38.786), train_loss = 0.69407143, grad/param norm = 1.9048e-01, time/batch = 15.5428s	
22109/28500 (epoch 38.788), train_loss = 0.77102185, grad/param norm = 1.9982e-01, time/batch = 15.3019s	
22110/28500 (epoch 38.789), train_loss = 0.61209059, grad/param norm = 1.8385e-01, time/batch = 14.9909s	
22111/28500 (epoch 38.791), train_loss = 0.83180504, grad/param norm = 1.7545e-01, time/batch = 15.4476s	
22112/28500 (epoch 38.793), train_loss = 0.80301039, grad/param norm = 1.8108e-01, time/batch = 15.4597s	
22113/28500 (epoch 38.795), train_loss = 0.82217888, grad/param norm = 2.0563e-01, time/batch = 15.2764s	
22114/28500 (epoch 38.796), train_loss = 0.71906096, grad/param norm = 1.8748e-01, time/batch = 15.0911s	
22115/28500 (epoch 38.798), train_loss = 0.68596673, grad/param norm = 1.9124e-01, time/batch = 15.2479s	
22116/28500 (epoch 38.800), train_loss = 0.65645476, grad/param norm = 1.8656e-01, time/batch = 15.2113s	
22117/28500 (epoch 38.802), train_loss = 0.76217068, grad/param norm = 2.1534e-01, time/batch = 15.2206s	
22118/28500 (epoch 38.804), train_loss = 0.83492670, grad/param norm = 1.6957e-01, time/batch = 15.3053s	
22119/28500 (epoch 38.805), train_loss = 0.81840693, grad/param norm = 1.8806e-01, time/batch = 15.4252s	
22120/28500 (epoch 38.807), train_loss = 0.83422220, grad/param norm = 2.0215e-01, time/batch = 15.3177s	
22121/28500 (epoch 38.809), train_loss = 0.78589307, grad/param norm = 2.0082e-01, time/batch = 15.3241s	
22122/28500 (epoch 38.811), train_loss = 0.82285323, grad/param norm = 1.9322e-01, time/batch = 15.2944s	
22123/28500 (epoch 38.812), train_loss = 0.78773351, grad/param norm = 1.8990e-01, time/batch = 15.3102s	
22124/28500 (epoch 38.814), train_loss = 0.75770172, grad/param norm = 1.7010e-01, time/batch = 15.2473s	
22125/28500 (epoch 38.816), train_loss = 0.82977698, grad/param norm = 1.9400e-01, time/batch = 15.2862s	
22126/28500 (epoch 38.818), train_loss = 0.93238161, grad/param norm = 1.8759e-01, time/batch = 15.3610s	
22127/28500 (epoch 38.819), train_loss = 0.79890195, grad/param norm = 1.8267e-01, time/batch = 15.3275s	
22128/28500 (epoch 38.821), train_loss = 0.76873880, grad/param norm = 1.7603e-01, time/batch = 15.2064s	
22129/28500 (epoch 38.823), train_loss = 0.92727864, grad/param norm = 2.5198e-01, time/batch = 15.2295s	
22130/28500 (epoch 38.825), train_loss = 0.74034344, grad/param norm = 1.8175e-01, time/batch = 15.3670s	
22131/28500 (epoch 38.826), train_loss = 0.82740871, grad/param norm = 1.8408e-01, time/batch = 15.6218s	
22132/28500 (epoch 38.828), train_loss = 0.73456411, grad/param norm = 1.8328e-01, time/batch = 15.4618s	
22133/28500 (epoch 38.830), train_loss = 0.77080052, grad/param norm = 1.5786e-01, time/batch = 15.5749s	
22134/28500 (epoch 38.832), train_loss = 0.79420093, grad/param norm = 2.3360e-01, time/batch = 15.6329s	
22135/28500 (epoch 38.833), train_loss = 0.85311461, grad/param norm = 1.6777e-01, time/batch = 15.6454s	
22136/28500 (epoch 38.835), train_loss = 0.75433674, grad/param norm = 1.7497e-01, time/batch = 15.6397s	
22137/28500 (epoch 38.837), train_loss = 0.68848208, grad/param norm = 1.9707e-01, time/batch = 15.4631s	
22138/28500 (epoch 38.839), train_loss = 0.95707037, grad/param norm = 2.5492e-01, time/batch = 15.4357s	
22139/28500 (epoch 38.840), train_loss = 0.94590890, grad/param norm = 2.3402e-01, time/batch = 15.3827s	
22140/28500 (epoch 38.842), train_loss = 0.86357964, grad/param norm = 1.9579e-01, time/batch = 15.4928s	
22141/28500 (epoch 38.844), train_loss = 0.88983316, grad/param norm = 2.0935e-01, time/batch = 15.8261s	
22142/28500 (epoch 38.846), train_loss = 0.96863825, grad/param norm = 2.1267e-01, time/batch = 15.3650s	
22143/28500 (epoch 38.847), train_loss = 0.79152123, grad/param norm = 2.5248e-01, time/batch = 15.1479s	
22144/28500 (epoch 38.849), train_loss = 0.78921139, grad/param norm = 1.9686e-01, time/batch = 15.3261s	
22145/28500 (epoch 38.851), train_loss = 0.72935125, grad/param norm = 1.5802e-01, time/batch = 15.4663s	
22146/28500 (epoch 38.853), train_loss = 0.85282132, grad/param norm = 2.1092e-01, time/batch = 15.4590s	
22147/28500 (epoch 38.854), train_loss = 0.83963632, grad/param norm = 1.9189e-01, time/batch = 15.4803s	
22148/28500 (epoch 38.856), train_loss = 0.92331216, grad/param norm = 2.4054e-01, time/batch = 15.5359s	
22149/28500 (epoch 38.858), train_loss = 0.77781485, grad/param norm = 1.7786e-01, time/batch = 15.4484s	
22150/28500 (epoch 38.860), train_loss = 0.79144838, grad/param norm = 1.7062e-01, time/batch = 1.5704s	
22151/28500 (epoch 38.861), train_loss = 0.88161998, grad/param norm = 2.1059e-01, time/batch = 0.7026s	
22152/28500 (epoch 38.863), train_loss = 0.84799334, grad/param norm = 2.2172e-01, time/batch = 0.7077s	
22153/28500 (epoch 38.865), train_loss = 0.75826324, grad/param norm = 1.8877e-01, time/batch = 0.7072s	
22154/28500 (epoch 38.867), train_loss = 0.83922002, grad/param norm = 1.9695e-01, time/batch = 0.7136s	
22155/28500 (epoch 38.868), train_loss = 0.73764166, grad/param norm = 1.6980e-01, time/batch = 0.7034s	
22156/28500 (epoch 38.870), train_loss = 0.70558657, grad/param norm = 1.7597e-01, time/batch = 0.7098s	
22157/28500 (epoch 38.872), train_loss = 0.86370043, grad/param norm = 2.0504e-01, time/batch = 0.7201s	
22158/28500 (epoch 38.874), train_loss = 0.73460795, grad/param norm = 2.0064e-01, time/batch = 0.7213s	
22159/28500 (epoch 38.875), train_loss = 0.95403178, grad/param norm = 2.2593e-01, time/batch = 0.7115s	
22160/28500 (epoch 38.877), train_loss = 0.82379585, grad/param norm = 1.7652e-01, time/batch = 0.6937s	
22161/28500 (epoch 38.879), train_loss = 0.88360326, grad/param norm = 1.7338e-01, time/batch = 0.6950s	
22162/28500 (epoch 38.881), train_loss = 0.85977695, grad/param norm = 2.0049e-01, time/batch = 0.6944s	
22163/28500 (epoch 38.882), train_loss = 0.74412177, grad/param norm = 1.6809e-01, time/batch = 0.6961s	
22164/28500 (epoch 38.884), train_loss = 0.78284926, grad/param norm = 1.9582e-01, time/batch = 0.6933s	
22165/28500 (epoch 38.886), train_loss = 0.76260891, grad/param norm = 1.7714e-01, time/batch = 0.6955s	
22166/28500 (epoch 38.888), train_loss = 0.78415519, grad/param norm = 1.6730e-01, time/batch = 0.6980s	
22167/28500 (epoch 38.889), train_loss = 0.82476948, grad/param norm = 1.6257e-01, time/batch = 0.6960s	
22168/28500 (epoch 38.891), train_loss = 0.82875380, grad/param norm = 1.8482e-01, time/batch = 0.6945s	
22169/28500 (epoch 38.893), train_loss = 0.76814232, grad/param norm = 1.7425e-01, time/batch = 0.6924s	
22170/28500 (epoch 38.895), train_loss = 0.96254819, grad/param norm = 2.3411e-01, time/batch = 0.6963s	
22171/28500 (epoch 38.896), train_loss = 0.90779000, grad/param norm = 2.0815e-01, time/batch = 0.6966s	
22172/28500 (epoch 38.898), train_loss = 0.85174619, grad/param norm = 1.7940e-01, time/batch = 0.6980s	
22173/28500 (epoch 38.900), train_loss = 0.72866749, grad/param norm = 1.7058e-01, time/batch = 0.6974s	
22174/28500 (epoch 38.902), train_loss = 0.67978343, grad/param norm = 1.7120e-01, time/batch = 0.7102s	
22175/28500 (epoch 38.904), train_loss = 0.71908190, grad/param norm = 1.6437e-01, time/batch = 0.6998s	
22176/28500 (epoch 38.905), train_loss = 0.77027264, grad/param norm = 1.9534e-01, time/batch = 0.6977s	
22177/28500 (epoch 38.907), train_loss = 0.80467974, grad/param norm = 1.9794e-01, time/batch = 0.6959s	
22178/28500 (epoch 38.909), train_loss = 0.68967414, grad/param norm = 2.5523e-01, time/batch = 0.6968s	
22179/28500 (epoch 38.911), train_loss = 0.73909323, grad/param norm = 1.7867e-01, time/batch = 0.6955s	
22180/28500 (epoch 38.912), train_loss = 0.61365070, grad/param norm = 1.6800e-01, time/batch = 0.6990s	
22181/28500 (epoch 38.914), train_loss = 0.82599282, grad/param norm = 1.9795e-01, time/batch = 0.6948s	
22182/28500 (epoch 38.916), train_loss = 0.81916126, grad/param norm = 1.9311e-01, time/batch = 0.6956s	
22183/28500 (epoch 38.918), train_loss = 0.80774405, grad/param norm = 2.1550e-01, time/batch = 0.7010s	
22184/28500 (epoch 38.919), train_loss = 0.83079353, grad/param norm = 1.7461e-01, time/batch = 0.6970s	
22185/28500 (epoch 38.921), train_loss = 0.91909468, grad/param norm = 2.1547e-01, time/batch = 0.6964s	
22186/28500 (epoch 38.923), train_loss = 0.75423040, grad/param norm = 2.1827e-01, time/batch = 0.6930s	
22187/28500 (epoch 38.925), train_loss = 0.77162913, grad/param norm = 2.5374e-01, time/batch = 0.6954s	
22188/28500 (epoch 38.926), train_loss = 0.83099933, grad/param norm = 1.9779e-01, time/batch = 0.7527s	
22189/28500 (epoch 38.928), train_loss = 0.76000601, grad/param norm = 1.6488e-01, time/batch = 1.0220s	
22190/28500 (epoch 38.930), train_loss = 0.63991961, grad/param norm = 1.5538e-01, time/batch = 1.0162s	
22191/28500 (epoch 38.932), train_loss = 0.66195935, grad/param norm = 1.5630e-01, time/batch = 1.0145s	
22192/28500 (epoch 38.933), train_loss = 0.87804322, grad/param norm = 2.0193e-01, time/batch = 0.9851s	
22193/28500 (epoch 38.935), train_loss = 0.89445862, grad/param norm = 1.8637e-01, time/batch = 0.9929s	
22194/28500 (epoch 38.937), train_loss = 0.90223390, grad/param norm = 2.2732e-01, time/batch = 0.9903s	
22195/28500 (epoch 38.939), train_loss = 0.91999721, grad/param norm = 2.0957e-01, time/batch = 1.0160s	
22196/28500 (epoch 38.940), train_loss = 0.68417135, grad/param norm = 1.8404e-01, time/batch = 1.0156s	
22197/28500 (epoch 38.942), train_loss = 0.81696037, grad/param norm = 2.0018e-01, time/batch = 1.0066s	
22198/28500 (epoch 38.944), train_loss = 0.79728411, grad/param norm = 1.9175e-01, time/batch = 1.0164s	
22199/28500 (epoch 38.946), train_loss = 0.86647817, grad/param norm = 1.9642e-01, time/batch = 1.8020s	
22200/28500 (epoch 38.947), train_loss = 1.03338488, grad/param norm = 2.8219e-01, time/batch = 1.9111s	
22201/28500 (epoch 38.949), train_loss = 0.81938997, grad/param norm = 2.5011e-01, time/batch = 1.9328s	
22202/28500 (epoch 38.951), train_loss = 0.98063649, grad/param norm = 1.9605e-01, time/batch = 1.9280s	
22203/28500 (epoch 38.953), train_loss = 0.97204936, grad/param norm = 2.0952e-01, time/batch = 5.7092s	
22204/28500 (epoch 38.954), train_loss = 0.89961369, grad/param norm = 2.1529e-01, time/batch = 15.4215s	
22205/28500 (epoch 38.956), train_loss = 0.83636014, grad/param norm = 2.7474e-01, time/batch = 15.4192s	
22206/28500 (epoch 38.958), train_loss = 1.05090288, grad/param norm = 2.0508e-01, time/batch = 15.2150s	
22207/28500 (epoch 38.960), train_loss = 0.76252654, grad/param norm = 2.0880e-01, time/batch = 15.1173s	
22208/28500 (epoch 38.961), train_loss = 0.96618086, grad/param norm = 2.2765e-01, time/batch = 15.1296s	
22209/28500 (epoch 38.963), train_loss = 0.89502557, grad/param norm = 2.1134e-01, time/batch = 15.3798s	
22210/28500 (epoch 38.965), train_loss = 0.76260737, grad/param norm = 1.8726e-01, time/batch = 15.2915s	
22211/28500 (epoch 38.967), train_loss = 0.76212385, grad/param norm = 1.8602e-01, time/batch = 15.3129s	
22212/28500 (epoch 38.968), train_loss = 0.71231069, grad/param norm = 1.6451e-01, time/batch = 15.3779s	
22213/28500 (epoch 38.970), train_loss = 0.75823138, grad/param norm = 1.9740e-01, time/batch = 15.2364s	
22214/28500 (epoch 38.972), train_loss = 0.84095294, grad/param norm = 1.9408e-01, time/batch = 15.2456s	
22215/28500 (epoch 38.974), train_loss = 1.00023044, grad/param norm = 2.1521e-01, time/batch = 15.2153s	
22216/28500 (epoch 38.975), train_loss = 0.76165344, grad/param norm = 1.9241e-01, time/batch = 15.4696s	
22217/28500 (epoch 38.977), train_loss = 0.91020174, grad/param norm = 2.1204e-01, time/batch = 15.4529s	
22218/28500 (epoch 38.979), train_loss = 0.85553418, grad/param norm = 1.8302e-01, time/batch = 15.4127s	
22219/28500 (epoch 38.981), train_loss = 0.70219021, grad/param norm = 1.7875e-01, time/batch = 15.3047s	
22220/28500 (epoch 38.982), train_loss = 0.80165373, grad/param norm = 1.9023e-01, time/batch = 2.5095s	
22221/28500 (epoch 38.984), train_loss = 0.88523134, grad/param norm = 1.8544e-01, time/batch = 0.6801s	
22222/28500 (epoch 38.986), train_loss = 1.05751612, grad/param norm = 2.2272e-01, time/batch = 0.6814s	
22223/28500 (epoch 38.988), train_loss = 0.73987676, grad/param norm = 1.9095e-01, time/batch = 0.6815s	
22224/28500 (epoch 38.989), train_loss = 0.84271709, grad/param norm = 1.9293e-01, time/batch = 0.6775s	
22225/28500 (epoch 38.991), train_loss = 0.75339458, grad/param norm = 2.0614e-01, time/batch = 0.6803s	
22226/28500 (epoch 38.993), train_loss = 0.74376198, grad/param norm = 2.0813e-01, time/batch = 0.6809s	
22227/28500 (epoch 38.995), train_loss = 0.78558865, grad/param norm = 1.9457e-01, time/batch = 0.6793s	
22228/28500 (epoch 38.996), train_loss = 0.71027327, grad/param norm = 1.8210e-01, time/batch = 0.6849s	
22229/28500 (epoch 38.998), train_loss = 0.93534941, grad/param norm = 2.3591e-01, time/batch = 0.6831s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
22230/28500 (epoch 39.000), train_loss = 0.79766380, grad/param norm = 1.9602e-01, time/batch = 0.6821s	
22231/28500 (epoch 39.002), train_loss = 0.97288945, grad/param norm = 2.0181e-01, time/batch = 0.6913s	
22232/28500 (epoch 39.004), train_loss = 0.83478399, grad/param norm = 1.8861e-01, time/batch = 0.6863s	
22233/28500 (epoch 39.005), train_loss = 0.91663022, grad/param norm = 2.1092e-01, time/batch = 0.6874s	
22234/28500 (epoch 39.007), train_loss = 0.72874171, grad/param norm = 1.5805e-01, time/batch = 0.6943s	
22235/28500 (epoch 39.009), train_loss = 0.85127650, grad/param norm = 1.8393e-01, time/batch = 0.6907s	
22236/28500 (epoch 39.011), train_loss = 0.74856750, grad/param norm = 1.7345e-01, time/batch = 0.6880s	
22237/28500 (epoch 39.012), train_loss = 0.76483824, grad/param norm = 1.9846e-01, time/batch = 0.6816s	
22238/28500 (epoch 39.014), train_loss = 0.73359004, grad/param norm = 1.7003e-01, time/batch = 0.6811s	
22239/28500 (epoch 39.016), train_loss = 0.78662668, grad/param norm = 1.6236e-01, time/batch = 0.6831s	
22240/28500 (epoch 39.018), train_loss = 0.85688163, grad/param norm = 2.1022e-01, time/batch = 0.6836s	
22241/28500 (epoch 39.019), train_loss = 0.90421574, grad/param norm = 1.8332e-01, time/batch = 0.6797s	
22242/28500 (epoch 39.021), train_loss = 0.94324421, grad/param norm = 1.9004e-01, time/batch = 0.6846s	
22243/28500 (epoch 39.023), train_loss = 0.83666049, grad/param norm = 1.7635e-01, time/batch = 0.6788s	
22244/28500 (epoch 39.025), train_loss = 0.85722703, grad/param norm = 1.9151e-01, time/batch = 0.6791s	
22245/28500 (epoch 39.026), train_loss = 0.78340013, grad/param norm = 1.7945e-01, time/batch = 0.6795s	
22246/28500 (epoch 39.028), train_loss = 0.82538961, grad/param norm = 1.9563e-01, time/batch = 0.6796s	
22247/28500 (epoch 39.030), train_loss = 0.84874916, grad/param norm = 2.0376e-01, time/batch = 0.6978s	
22248/28500 (epoch 39.032), train_loss = 0.94214342, grad/param norm = 1.9947e-01, time/batch = 0.6812s	
22249/28500 (epoch 39.033), train_loss = 0.98614097, grad/param norm = 2.1235e-01, time/batch = 0.6793s	
22250/28500 (epoch 39.035), train_loss = 0.80201324, grad/param norm = 2.1295e-01, time/batch = 0.6842s	
22251/28500 (epoch 39.037), train_loss = 0.89170565, grad/param norm = 1.9287e-01, time/batch = 0.6791s	
22252/28500 (epoch 39.039), train_loss = 0.94337497, grad/param norm = 2.1184e-01, time/batch = 0.6793s	
22253/28500 (epoch 39.040), train_loss = 0.96228279, grad/param norm = 1.9595e-01, time/batch = 0.6779s	
22254/28500 (epoch 39.042), train_loss = 0.89414766, grad/param norm = 1.8499e-01, time/batch = 0.6770s	
22255/28500 (epoch 39.044), train_loss = 0.83719832, grad/param norm = 2.1471e-01, time/batch = 0.6770s	
22256/28500 (epoch 39.046), train_loss = 1.02889007, grad/param norm = 2.2285e-01, time/batch = 0.6789s	
22257/28500 (epoch 39.047), train_loss = 0.97738159, grad/param norm = 2.2014e-01, time/batch = 0.6776s	
22258/28500 (epoch 39.049), train_loss = 0.84241344, grad/param norm = 1.8509e-01, time/batch = 0.6787s	
22259/28500 (epoch 39.051), train_loss = 0.85500004, grad/param norm = 2.3055e-01, time/batch = 0.6797s	
22260/28500 (epoch 39.053), train_loss = 0.81675946, grad/param norm = 2.1267e-01, time/batch = 0.6773s	
22261/28500 (epoch 39.054), train_loss = 0.89415234, grad/param norm = 1.9412e-01, time/batch = 0.6796s	
22262/28500 (epoch 39.056), train_loss = 0.77684587, grad/param norm = 1.7682e-01, time/batch = 0.6804s	
22263/28500 (epoch 39.058), train_loss = 0.77454834, grad/param norm = 1.8108e-01, time/batch = 0.6763s	
22264/28500 (epoch 39.060), train_loss = 0.88602666, grad/param norm = 1.7751e-01, time/batch = 0.6782s	
22265/28500 (epoch 39.061), train_loss = 0.81005352, grad/param norm = 1.8478e-01, time/batch = 0.6765s	
22266/28500 (epoch 39.063), train_loss = 0.87316385, grad/param norm = 2.0028e-01, time/batch = 0.6800s	
22267/28500 (epoch 39.065), train_loss = 0.83351429, grad/param norm = 1.7834e-01, time/batch = 0.6768s	
22268/28500 (epoch 39.067), train_loss = 0.77419187, grad/param norm = 1.6519e-01, time/batch = 0.6789s	
22269/28500 (epoch 39.068), train_loss = 0.82158827, grad/param norm = 1.9126e-01, time/batch = 0.6795s	
22270/28500 (epoch 39.070), train_loss = 0.86357468, grad/param norm = 1.9832e-01, time/batch = 0.6771s	
22271/28500 (epoch 39.072), train_loss = 0.96576797, grad/param norm = 2.2708e-01, time/batch = 0.6809s	
22272/28500 (epoch 39.074), train_loss = 0.81260612, grad/param norm = 1.7468e-01, time/batch = 0.6770s	
22273/28500 (epoch 39.075), train_loss = 0.82726845, grad/param norm = 1.6259e-01, time/batch = 0.6822s	
22274/28500 (epoch 39.077), train_loss = 0.88169755, grad/param norm = 1.7664e-01, time/batch = 0.6864s	
22275/28500 (epoch 39.079), train_loss = 0.86278119, grad/param norm = 1.7679e-01, time/batch = 0.6796s	
22276/28500 (epoch 39.081), train_loss = 0.93283294, grad/param norm = 2.0241e-01, time/batch = 0.6841s	
22277/28500 (epoch 39.082), train_loss = 0.82516827, grad/param norm = 2.2891e-01, time/batch = 0.6815s	
22278/28500 (epoch 39.084), train_loss = 0.84829066, grad/param norm = 2.0692e-01, time/batch = 0.6844s	
22279/28500 (epoch 39.086), train_loss = 0.80378813, grad/param norm = 2.4701e-01, time/batch = 0.6790s	
22280/28500 (epoch 39.088), train_loss = 0.73855596, grad/param norm = 1.7379e-01, time/batch = 0.6820s	
22281/28500 (epoch 39.089), train_loss = 0.90839515, grad/param norm = 1.9953e-01, time/batch = 0.6823s	
22282/28500 (epoch 39.091), train_loss = 0.75598330, grad/param norm = 1.7066e-01, time/batch = 0.6812s	
22283/28500 (epoch 39.093), train_loss = 0.92672798, grad/param norm = 1.8431e-01, time/batch = 0.6826s	
22284/28500 (epoch 39.095), train_loss = 0.83471202, grad/param norm = 1.6958e-01, time/batch = 0.6807s	
22285/28500 (epoch 39.096), train_loss = 0.91909201, grad/param norm = 1.8399e-01, time/batch = 0.6823s	
22286/28500 (epoch 39.098), train_loss = 0.85202265, grad/param norm = 2.1459e-01, time/batch = 0.6827s	
22287/28500 (epoch 39.100), train_loss = 0.80941677, grad/param norm = 1.7364e-01, time/batch = 0.6835s	
22288/28500 (epoch 39.102), train_loss = 0.92234162, grad/param norm = 2.3086e-01, time/batch = 0.6811s	
22289/28500 (epoch 39.104), train_loss = 0.85144890, grad/param norm = 1.9679e-01, time/batch = 0.6856s	
22290/28500 (epoch 39.105), train_loss = 0.93131582, grad/param norm = 1.9432e-01, time/batch = 0.6796s	
22291/28500 (epoch 39.107), train_loss = 0.76888907, grad/param norm = 1.8877e-01, time/batch = 0.6847s	
22292/28500 (epoch 39.109), train_loss = 0.81944233, grad/param norm = 2.3258e-01, time/batch = 0.6825s	
22293/28500 (epoch 39.111), train_loss = 0.82828434, grad/param norm = 2.4367e-01, time/batch = 0.6802s	
22294/28500 (epoch 39.112), train_loss = 0.91775220, grad/param norm = 2.0728e-01, time/batch = 0.6826s	
22295/28500 (epoch 39.114), train_loss = 0.82746792, grad/param norm = 1.8991e-01, time/batch = 0.6821s	
22296/28500 (epoch 39.116), train_loss = 0.99212752, grad/param norm = 2.1973e-01, time/batch = 0.6804s	
22297/28500 (epoch 39.118), train_loss = 0.76683975, grad/param norm = 2.5422e-01, time/batch = 0.6816s	
22298/28500 (epoch 39.119), train_loss = 0.87579958, grad/param norm = 2.2672e-01, time/batch = 0.6801s	
22299/28500 (epoch 39.121), train_loss = 0.99532789, grad/param norm = 2.1555e-01, time/batch = 0.6803s	
22300/28500 (epoch 39.123), train_loss = 0.94406525, grad/param norm = 2.0336e-01, time/batch = 0.6800s	
22301/28500 (epoch 39.125), train_loss = 0.87173401, grad/param norm = 1.9496e-01, time/batch = 0.6894s	
22302/28500 (epoch 39.126), train_loss = 0.85256765, grad/param norm = 1.8845e-01, time/batch = 0.6981s	
22303/28500 (epoch 39.128), train_loss = 0.85703191, grad/param norm = 1.9015e-01, time/batch = 0.6835s	
22304/28500 (epoch 39.130), train_loss = 0.81092921, grad/param norm = 2.0222e-01, time/batch = 0.6830s	
22305/28500 (epoch 39.132), train_loss = 0.83935997, grad/param norm = 1.8012e-01, time/batch = 0.6858s	
22306/28500 (epoch 39.133), train_loss = 0.90294899, grad/param norm = 2.1208e-01, time/batch = 0.6813s	
22307/28500 (epoch 39.135), train_loss = 0.81131638, grad/param norm = 1.9592e-01, time/batch = 0.6814s	
22308/28500 (epoch 39.137), train_loss = 0.86187127, grad/param norm = 2.0621e-01, time/batch = 0.6800s	
22309/28500 (epoch 39.139), train_loss = 0.86235105, grad/param norm = 1.7185e-01, time/batch = 0.6824s	
22310/28500 (epoch 39.140), train_loss = 0.83145290, grad/param norm = 1.7643e-01, time/batch = 0.6794s	
22311/28500 (epoch 39.142), train_loss = 0.80334167, grad/param norm = 2.0032e-01, time/batch = 0.6834s	
22312/28500 (epoch 39.144), train_loss = 0.74980266, grad/param norm = 1.8066e-01, time/batch = 0.6830s	
22313/28500 (epoch 39.146), train_loss = 0.82189777, grad/param norm = 1.7893e-01, time/batch = 0.6793s	
22314/28500 (epoch 39.147), train_loss = 0.71935232, grad/param norm = 1.6133e-01, time/batch = 0.6809s	
22315/28500 (epoch 39.149), train_loss = 0.70910157, grad/param norm = 1.6127e-01, time/batch = 0.6797s	
22316/28500 (epoch 39.151), train_loss = 0.80250182, grad/param norm = 1.8690e-01, time/batch = 0.6822s	
22317/28500 (epoch 39.153), train_loss = 0.86802811, grad/param norm = 2.0429e-01, time/batch = 0.6796s	
22318/28500 (epoch 39.154), train_loss = 0.72566593, grad/param norm = 1.7467e-01, time/batch = 0.6839s	
22319/28500 (epoch 39.156), train_loss = 0.91028915, grad/param norm = 2.0429e-01, time/batch = 0.6857s	
22320/28500 (epoch 39.158), train_loss = 0.86486873, grad/param norm = 1.9747e-01, time/batch = 0.6803s	
22321/28500 (epoch 39.160), train_loss = 0.74380852, grad/param norm = 1.6113e-01, time/batch = 0.6850s	
22322/28500 (epoch 39.161), train_loss = 0.78272098, grad/param norm = 1.8839e-01, time/batch = 0.6816s	
22323/28500 (epoch 39.163), train_loss = 0.74243994, grad/param norm = 1.8655e-01, time/batch = 0.6846s	
22324/28500 (epoch 39.165), train_loss = 0.98218180, grad/param norm = 1.9786e-01, time/batch = 0.6794s	
22325/28500 (epoch 39.167), train_loss = 0.99054451, grad/param norm = 2.2052e-01, time/batch = 0.6833s	
22326/28500 (epoch 39.168), train_loss = 0.93916295, grad/param norm = 2.2582e-01, time/batch = 0.6784s	
22327/28500 (epoch 39.170), train_loss = 0.93336976, grad/param norm = 2.4327e-01, time/batch = 0.6806s	
22328/28500 (epoch 39.172), train_loss = 0.81961699, grad/param norm = 1.7200e-01, time/batch = 0.6830s	
22329/28500 (epoch 39.174), train_loss = 0.99176806, grad/param norm = 2.4112e-01, time/batch = 0.6804s	
22330/28500 (epoch 39.175), train_loss = 0.82909778, grad/param norm = 1.8498e-01, time/batch = 0.6831s	
22331/28500 (epoch 39.177), train_loss = 0.86443334, grad/param norm = 1.9332e-01, time/batch = 0.6824s	
22332/28500 (epoch 39.179), train_loss = 0.92509834, grad/param norm = 1.9657e-01, time/batch = 0.6804s	
22333/28500 (epoch 39.181), train_loss = 0.88262928, grad/param norm = 2.0782e-01, time/batch = 0.6823s	
22334/28500 (epoch 39.182), train_loss = 0.80422390, grad/param norm = 2.2615e-01, time/batch = 0.6812s	
22335/28500 (epoch 39.184), train_loss = 1.02021349, grad/param norm = 2.2562e-01, time/batch = 0.6819s	
22336/28500 (epoch 39.186), train_loss = 0.97812335, grad/param norm = 1.8927e-01, time/batch = 0.6822s	
22337/28500 (epoch 39.188), train_loss = 0.90519220, grad/param norm = 2.1498e-01, time/batch = 0.6798s	
22338/28500 (epoch 39.189), train_loss = 0.84778635, grad/param norm = 1.8186e-01, time/batch = 0.6830s	
22339/28500 (epoch 39.191), train_loss = 1.03323990, grad/param norm = 2.1090e-01, time/batch = 0.6801s	
22340/28500 (epoch 39.193), train_loss = 0.84837384, grad/param norm = 2.0359e-01, time/batch = 0.6805s	
22341/28500 (epoch 39.195), train_loss = 0.97577976, grad/param norm = 2.0050e-01, time/batch = 0.6837s	
22342/28500 (epoch 39.196), train_loss = 0.89284158, grad/param norm = 1.9489e-01, time/batch = 0.6809s	
22343/28500 (epoch 39.198), train_loss = 0.86332721, grad/param norm = 1.9270e-01, time/batch = 0.6813s	
22344/28500 (epoch 39.200), train_loss = 0.93332446, grad/param norm = 1.9355e-01, time/batch = 0.6794s	
22345/28500 (epoch 39.202), train_loss = 0.86982995, grad/param norm = 1.7474e-01, time/batch = 0.6829s	
22346/28500 (epoch 39.204), train_loss = 0.84157586, grad/param norm = 1.7296e-01, time/batch = 0.6792s	
22347/28500 (epoch 39.205), train_loss = 0.79345971, grad/param norm = 1.7376e-01, time/batch = 0.6823s	
22348/28500 (epoch 39.207), train_loss = 0.72113153, grad/param norm = 1.6563e-01, time/batch = 0.6790s	
22349/28500 (epoch 39.209), train_loss = 0.87313298, grad/param norm = 1.7237e-01, time/batch = 0.6801s	
22350/28500 (epoch 39.211), train_loss = 0.76920465, grad/param norm = 1.6861e-01, time/batch = 0.6809s	
22351/28500 (epoch 39.212), train_loss = 0.71233647, grad/param norm = 1.7792e-01, time/batch = 0.6822s	
22352/28500 (epoch 39.214), train_loss = 0.83867614, grad/param norm = 2.0773e-01, time/batch = 0.6830s	
22353/28500 (epoch 39.216), train_loss = 0.77904254, grad/param norm = 1.8830e-01, time/batch = 0.6828s	
22354/28500 (epoch 39.218), train_loss = 0.95129843, grad/param norm = 1.7099e-01, time/batch = 0.6800s	
22355/28500 (epoch 39.219), train_loss = 0.87278011, grad/param norm = 1.9155e-01, time/batch = 0.6822s	
22356/28500 (epoch 39.221), train_loss = 0.73817836, grad/param norm = 2.0827e-01, time/batch = 0.6795s	
22357/28500 (epoch 39.223), train_loss = 0.96219053, grad/param norm = 2.2879e-01, time/batch = 0.6778s	
22358/28500 (epoch 39.225), train_loss = 0.99439945, grad/param norm = 2.2850e-01, time/batch = 0.6758s	
22359/28500 (epoch 39.226), train_loss = 0.81131825, grad/param norm = 1.6319e-01, time/batch = 0.6773s	
22360/28500 (epoch 39.228), train_loss = 0.93162188, grad/param norm = 1.8613e-01, time/batch = 0.6782s	
22361/28500 (epoch 39.230), train_loss = 0.91201826, grad/param norm = 1.9846e-01, time/batch = 0.6810s	
22362/28500 (epoch 39.232), train_loss = 0.89707935, grad/param norm = 1.8634e-01, time/batch = 0.6973s	
22363/28500 (epoch 39.233), train_loss = 0.84626817, grad/param norm = 2.4373e-01, time/batch = 0.6826s	
22364/28500 (epoch 39.235), train_loss = 0.83763120, grad/param norm = 1.7789e-01, time/batch = 0.6818s	
22365/28500 (epoch 39.237), train_loss = 0.76572111, grad/param norm = 1.6396e-01, time/batch = 0.6773s	
22366/28500 (epoch 39.239), train_loss = 0.80543421, grad/param norm = 1.6689e-01, time/batch = 0.6798s	
22367/28500 (epoch 39.240), train_loss = 0.73693046, grad/param norm = 1.6401e-01, time/batch = 0.6769s	
22368/28500 (epoch 39.242), train_loss = 0.79111279, grad/param norm = 1.9331e-01, time/batch = 0.6870s	
22369/28500 (epoch 39.244), train_loss = 0.87283998, grad/param norm = 1.6390e-01, time/batch = 0.6793s	
22370/28500 (epoch 39.246), train_loss = 0.88439781, grad/param norm = 1.8394e-01, time/batch = 0.6776s	
22371/28500 (epoch 39.247), train_loss = 0.96662972, grad/param norm = 2.1394e-01, time/batch = 0.6775s	
22372/28500 (epoch 39.249), train_loss = 0.82722654, grad/param norm = 1.6977e-01, time/batch = 0.6771s	
22373/28500 (epoch 39.251), train_loss = 0.84499723, grad/param norm = 1.7142e-01, time/batch = 0.6774s	
22374/28500 (epoch 39.253), train_loss = 0.98905067, grad/param norm = 2.1851e-01, time/batch = 0.6779s	
22375/28500 (epoch 39.254), train_loss = 0.98650479, grad/param norm = 1.7471e-01, time/batch = 0.6835s	
22376/28500 (epoch 39.256), train_loss = 0.83241014, grad/param norm = 1.7873e-01, time/batch = 0.6797s	
22377/28500 (epoch 39.258), train_loss = 0.83089252, grad/param norm = 2.1218e-01, time/batch = 0.6795s	
22378/28500 (epoch 39.260), train_loss = 0.83597133, grad/param norm = 1.7685e-01, time/batch = 0.6815s	
22379/28500 (epoch 39.261), train_loss = 0.74601852, grad/param norm = 2.1796e-01, time/batch = 0.6792s	
22380/28500 (epoch 39.263), train_loss = 0.91511130, grad/param norm = 2.1048e-01, time/batch = 0.6794s	
22381/28500 (epoch 39.265), train_loss = 0.78334385, grad/param norm = 1.6563e-01, time/batch = 0.6825s	
22382/28500 (epoch 39.267), train_loss = 0.98029265, grad/param norm = 2.1443e-01, time/batch = 0.6826s	
22383/28500 (epoch 39.268), train_loss = 0.88444655, grad/param norm = 1.8167e-01, time/batch = 0.6809s	
22384/28500 (epoch 39.270), train_loss = 0.83481228, grad/param norm = 2.0658e-01, time/batch = 0.6800s	
22385/28500 (epoch 39.272), train_loss = 0.86487875, grad/param norm = 1.8303e-01, time/batch = 0.6823s	
22386/28500 (epoch 39.274), train_loss = 0.90343182, grad/param norm = 2.0877e-01, time/batch = 0.6817s	
22387/28500 (epoch 39.275), train_loss = 0.92627194, grad/param norm = 2.1849e-01, time/batch = 0.6850s	
22388/28500 (epoch 39.277), train_loss = 0.84599430, grad/param norm = 2.1226e-01, time/batch = 0.6826s	
22389/28500 (epoch 39.279), train_loss = 0.86972350, grad/param norm = 2.0020e-01, time/batch = 0.6869s	
22390/28500 (epoch 39.281), train_loss = 0.91416385, grad/param norm = 2.7675e-01, time/batch = 0.6850s	
22391/28500 (epoch 39.282), train_loss = 0.84722592, grad/param norm = 1.7665e-01, time/batch = 0.6828s	
22392/28500 (epoch 39.284), train_loss = 0.88113196, grad/param norm = 1.9971e-01, time/batch = 0.6887s	
22393/28500 (epoch 39.286), train_loss = 0.94322615, grad/param norm = 1.9615e-01, time/batch = 0.6862s	
22394/28500 (epoch 39.288), train_loss = 0.85133108, grad/param norm = 2.0318e-01, time/batch = 0.6821s	
22395/28500 (epoch 39.289), train_loss = 0.86536004, grad/param norm = 1.9527e-01, time/batch = 0.6853s	
22396/28500 (epoch 39.291), train_loss = 0.86800528, grad/param norm = 1.8030e-01, time/batch = 0.6807s	
22397/28500 (epoch 39.293), train_loss = 0.86582815, grad/param norm = 1.7934e-01, time/batch = 0.6789s	
22398/28500 (epoch 39.295), train_loss = 0.75450784, grad/param norm = 1.7259e-01, time/batch = 0.6793s	
22399/28500 (epoch 39.296), train_loss = 0.74376248, grad/param norm = 1.6519e-01, time/batch = 0.6826s	
22400/28500 (epoch 39.298), train_loss = 0.91751992, grad/param norm = 1.9206e-01, time/batch = 0.6807s	
22401/28500 (epoch 39.300), train_loss = 0.78514089, grad/param norm = 1.7984e-01, time/batch = 0.6865s	
22402/28500 (epoch 39.302), train_loss = 0.72379016, grad/param norm = 1.7501e-01, time/batch = 0.6862s	
22403/28500 (epoch 39.304), train_loss = 0.83210391, grad/param norm = 1.8696e-01, time/batch = 0.7015s	
22404/28500 (epoch 39.305), train_loss = 0.87220641, grad/param norm = 1.7907e-01, time/batch = 0.6934s	
22405/28500 (epoch 39.307), train_loss = 0.81869592, grad/param norm = 2.2027e-01, time/batch = 0.6815s	
22406/28500 (epoch 39.309), train_loss = 0.83277808, grad/param norm = 1.7513e-01, time/batch = 0.6858s	
22407/28500 (epoch 39.311), train_loss = 0.88108245, grad/param norm = 1.7720e-01, time/batch = 0.6815s	
22408/28500 (epoch 39.312), train_loss = 0.89121361, grad/param norm = 1.7893e-01, time/batch = 0.6791s	
22409/28500 (epoch 39.314), train_loss = 0.89076801, grad/param norm = 2.1314e-01, time/batch = 0.6769s	
22410/28500 (epoch 39.316), train_loss = 0.86223600, grad/param norm = 1.9257e-01, time/batch = 0.6762s	
22411/28500 (epoch 39.318), train_loss = 0.93668343, grad/param norm = 1.7944e-01, time/batch = 0.6780s	
22412/28500 (epoch 39.319), train_loss = 0.80807671, grad/param norm = 2.0986e-01, time/batch = 0.6824s	
22413/28500 (epoch 39.321), train_loss = 0.80951476, grad/param norm = 2.2700e-01, time/batch = 0.6814s	
22414/28500 (epoch 39.323), train_loss = 0.86197909, grad/param norm = 2.2655e-01, time/batch = 0.6803s	
22415/28500 (epoch 39.325), train_loss = 0.99181831, grad/param norm = 2.3058e-01, time/batch = 0.6817s	
22416/28500 (epoch 39.326), train_loss = 0.85984558, grad/param norm = 1.7479e-01, time/batch = 0.6799s	
22417/28500 (epoch 39.328), train_loss = 0.69192973, grad/param norm = 1.5662e-01, time/batch = 0.6799s	
22418/28500 (epoch 39.330), train_loss = 0.77982255, grad/param norm = 1.8583e-01, time/batch = 0.6860s	
22419/28500 (epoch 39.332), train_loss = 0.80794826, grad/param norm = 1.7799e-01, time/batch = 0.6819s	
22420/28500 (epoch 39.333), train_loss = 0.67417738, grad/param norm = 1.9046e-01, time/batch = 0.6840s	
22421/28500 (epoch 39.335), train_loss = 0.73491867, grad/param norm = 1.6478e-01, time/batch = 0.6888s	
22422/28500 (epoch 39.337), train_loss = 0.68134488, grad/param norm = 1.5858e-01, time/batch = 0.6861s	
22423/28500 (epoch 39.339), train_loss = 0.68704855, grad/param norm = 1.4005e-01, time/batch = 0.6949s	
22424/28500 (epoch 39.340), train_loss = 0.84823256, grad/param norm = 2.3161e-01, time/batch = 0.6807s	
22425/28500 (epoch 39.342), train_loss = 0.81438623, grad/param norm = 1.7338e-01, time/batch = 0.6818s	
22426/28500 (epoch 39.344), train_loss = 0.73164815, grad/param norm = 1.8684e-01, time/batch = 0.6782s	
22427/28500 (epoch 39.346), train_loss = 0.70203693, grad/param norm = 1.5625e-01, time/batch = 0.6808s	
22428/28500 (epoch 39.347), train_loss = 0.83405901, grad/param norm = 1.5861e-01, time/batch = 0.6806s	
22429/28500 (epoch 39.349), train_loss = 0.83885819, grad/param norm = 2.2124e-01, time/batch = 0.6803s	
22430/28500 (epoch 39.351), train_loss = 0.74511805, grad/param norm = 1.7538e-01, time/batch = 0.6758s	
22431/28500 (epoch 39.353), train_loss = 0.83741453, grad/param norm = 1.9839e-01, time/batch = 0.6804s	
22432/28500 (epoch 39.354), train_loss = 0.74104886, grad/param norm = 1.9186e-01, time/batch = 0.6805s	
22433/28500 (epoch 39.356), train_loss = 0.77826225, grad/param norm = 1.7299e-01, time/batch = 0.6783s	
22434/28500 (epoch 39.358), train_loss = 0.86107611, grad/param norm = 1.6849e-01, time/batch = 0.6850s	
22435/28500 (epoch 39.360), train_loss = 0.86830178, grad/param norm = 2.1938e-01, time/batch = 0.6781s	
22436/28500 (epoch 39.361), train_loss = 0.75869920, grad/param norm = 1.8140e-01, time/batch = 0.6774s	
22437/28500 (epoch 39.363), train_loss = 0.74053798, grad/param norm = 1.6725e-01, time/batch = 0.6769s	
22438/28500 (epoch 39.365), train_loss = 0.79503796, grad/param norm = 2.0911e-01, time/batch = 0.6763s	
22439/28500 (epoch 39.367), train_loss = 0.83351553, grad/param norm = 2.0111e-01, time/batch = 0.6821s	
22440/28500 (epoch 39.368), train_loss = 0.76377404, grad/param norm = 1.7411e-01, time/batch = 0.6785s	
22441/28500 (epoch 39.370), train_loss = 0.83849259, grad/param norm = 2.0357e-01, time/batch = 0.6818s	
22442/28500 (epoch 39.372), train_loss = 0.67495331, grad/param norm = 1.7862e-01, time/batch = 0.6763s	
22443/28500 (epoch 39.374), train_loss = 0.80661878, grad/param norm = 2.0166e-01, time/batch = 0.6765s	
22444/28500 (epoch 39.375), train_loss = 0.93702829, grad/param norm = 1.9485e-01, time/batch = 0.6755s	
22445/28500 (epoch 39.377), train_loss = 0.76175982, grad/param norm = 2.2145e-01, time/batch = 0.6773s	
22446/28500 (epoch 39.379), train_loss = 0.65233289, grad/param norm = 1.8616e-01, time/batch = 0.6753s	
22447/28500 (epoch 39.381), train_loss = 0.81854396, grad/param norm = 1.8526e-01, time/batch = 0.6775s	
22448/28500 (epoch 39.382), train_loss = 0.78089114, grad/param norm = 2.2157e-01, time/batch = 0.6778s	
22449/28500 (epoch 39.384), train_loss = 0.68884507, grad/param norm = 1.8672e-01, time/batch = 0.6821s	
22450/28500 (epoch 39.386), train_loss = 0.73982886, grad/param norm = 1.6899e-01, time/batch = 0.6751s	
22451/28500 (epoch 39.388), train_loss = 0.89748433, grad/param norm = 2.1123e-01, time/batch = 0.6860s	
22452/28500 (epoch 39.389), train_loss = 0.75103262, grad/param norm = 1.7844e-01, time/batch = 0.6783s	
22453/28500 (epoch 39.391), train_loss = 0.73161815, grad/param norm = 1.8647e-01, time/batch = 0.6787s	
22454/28500 (epoch 39.393), train_loss = 0.73684121, grad/param norm = 1.7590e-01, time/batch = 0.6762s	
22455/28500 (epoch 39.395), train_loss = 0.92050176, grad/param norm = 1.8218e-01, time/batch = 0.6829s	
22456/28500 (epoch 39.396), train_loss = 0.88912129, grad/param norm = 1.8488e-01, time/batch = 0.6769s	
22457/28500 (epoch 39.398), train_loss = 0.61298729, grad/param norm = 1.8233e-01, time/batch = 0.6781s	
22458/28500 (epoch 39.400), train_loss = 0.77319207, grad/param norm = 1.7801e-01, time/batch = 0.6903s	
22459/28500 (epoch 39.402), train_loss = 0.84646322, grad/param norm = 1.9206e-01, time/batch = 0.6930s	
22460/28500 (epoch 39.404), train_loss = 0.83495644, grad/param norm = 2.1594e-01, time/batch = 0.6856s	
22461/28500 (epoch 39.405), train_loss = 0.87102867, grad/param norm = 1.8187e-01, time/batch = 0.6889s	
22462/28500 (epoch 39.407), train_loss = 0.82953043, grad/param norm = 1.8200e-01, time/batch = 0.6805s	
22463/28500 (epoch 39.409), train_loss = 0.83487288, grad/param norm = 1.9414e-01, time/batch = 0.6792s	
22464/28500 (epoch 39.411), train_loss = 0.91579088, grad/param norm = 2.2897e-01, time/batch = 0.6796s	
22465/28500 (epoch 39.412), train_loss = 0.94593209, grad/param norm = 2.1993e-01, time/batch = 0.6830s	
22466/28500 (epoch 39.414), train_loss = 0.84531853, grad/param norm = 2.0378e-01, time/batch = 0.6837s	
22467/28500 (epoch 39.416), train_loss = 0.75743575, grad/param norm = 2.1101e-01, time/batch = 0.6866s	
22468/28500 (epoch 39.418), train_loss = 0.84143897, grad/param norm = 1.7238e-01, time/batch = 0.6970s	
22469/28500 (epoch 39.419), train_loss = 0.93855631, grad/param norm = 2.0166e-01, time/batch = 0.6905s	
22470/28500 (epoch 39.421), train_loss = 0.91727153, grad/param norm = 2.2900e-01, time/batch = 0.6825s	
22471/28500 (epoch 39.423), train_loss = 0.90472637, grad/param norm = 2.3380e-01, time/batch = 0.6831s	
22472/28500 (epoch 39.425), train_loss = 0.82389444, grad/param norm = 2.4109e-01, time/batch = 0.6854s	
22473/28500 (epoch 39.426), train_loss = 0.84943538, grad/param norm = 1.9721e-01, time/batch = 0.6849s	
22474/28500 (epoch 39.428), train_loss = 0.99801861, grad/param norm = 2.0322e-01, time/batch = 0.6768s	
22475/28500 (epoch 39.430), train_loss = 0.97425967, grad/param norm = 1.8702e-01, time/batch = 0.6788s	
22476/28500 (epoch 39.432), train_loss = 0.85640431, grad/param norm = 1.9321e-01, time/batch = 0.6872s	
22477/28500 (epoch 39.433), train_loss = 0.91888097, grad/param norm = 2.4517e-01, time/batch = 0.6819s	
22478/28500 (epoch 39.435), train_loss = 0.86948883, grad/param norm = 2.2217e-01, time/batch = 0.6900s	
22479/28500 (epoch 39.437), train_loss = 0.78558755, grad/param norm = 1.8386e-01, time/batch = 0.6792s	
22480/28500 (epoch 39.439), train_loss = 0.83581570, grad/param norm = 1.6971e-01, time/batch = 0.6801s	
22481/28500 (epoch 39.440), train_loss = 0.99545381, grad/param norm = 2.0258e-01, time/batch = 0.6922s	
22482/28500 (epoch 39.442), train_loss = 0.78407894, grad/param norm = 1.8293e-01, time/batch = 0.6835s	
22483/28500 (epoch 39.444), train_loss = 0.75109072, grad/param norm = 1.9585e-01, time/batch = 0.6823s	
22484/28500 (epoch 39.446), train_loss = 0.72098116, grad/param norm = 1.7862e-01, time/batch = 0.6816s	
22485/28500 (epoch 39.447), train_loss = 0.74606254, grad/param norm = 1.9074e-01, time/batch = 0.6866s	
22486/28500 (epoch 39.449), train_loss = 0.79049829, grad/param norm = 1.8303e-01, time/batch = 0.6810s	
22487/28500 (epoch 39.451), train_loss = 0.80966607, grad/param norm = 1.8306e-01, time/batch = 0.6820s	
22488/28500 (epoch 39.453), train_loss = 0.78648473, grad/param norm = 1.8230e-01, time/batch = 0.6809s	
22489/28500 (epoch 39.454), train_loss = 0.74629014, grad/param norm = 1.5753e-01, time/batch = 0.6842s	
22490/28500 (epoch 39.456), train_loss = 0.90409998, grad/param norm = 2.2739e-01, time/batch = 0.6795s	
22491/28500 (epoch 39.458), train_loss = 0.80234983, grad/param norm = 1.8673e-01, time/batch = 0.6833s	
22492/28500 (epoch 39.460), train_loss = 0.91228888, grad/param norm = 2.2891e-01, time/batch = 0.6802s	
22493/28500 (epoch 39.461), train_loss = 0.75412935, grad/param norm = 1.8533e-01, time/batch = 0.6807s	
22494/28500 (epoch 39.463), train_loss = 0.69794153, grad/param norm = 1.5938e-01, time/batch = 0.6829s	
22495/28500 (epoch 39.465), train_loss = 0.67089989, grad/param norm = 1.9769e-01, time/batch = 0.6831s	
22496/28500 (epoch 39.467), train_loss = 0.81928942, grad/param norm = 1.7205e-01, time/batch = 0.6812s	
22497/28500 (epoch 39.468), train_loss = 0.74068296, grad/param norm = 1.7955e-01, time/batch = 0.6845s	
22498/28500 (epoch 39.470), train_loss = 0.79846284, grad/param norm = 2.4028e-01, time/batch = 0.6809s	
22499/28500 (epoch 39.472), train_loss = 0.73969645, grad/param norm = 1.6013e-01, time/batch = 0.6815s	
22500/28500 (epoch 39.474), train_loss = 0.97342172, grad/param norm = 2.2821e-01, time/batch = 0.6808s	
22501/28500 (epoch 39.475), train_loss = 0.76882409, grad/param norm = 1.7916e-01, time/batch = 0.6804s	
22502/28500 (epoch 39.477), train_loss = 0.81069317, grad/param norm = 1.8837e-01, time/batch = 0.6796s	
22503/28500 (epoch 39.479), train_loss = 0.85586279, grad/param norm = 1.9176e-01, time/batch = 0.6799s	
22504/28500 (epoch 39.481), train_loss = 0.86558239, grad/param norm = 1.8090e-01, time/batch = 0.6791s	
22505/28500 (epoch 39.482), train_loss = 0.72949293, grad/param norm = 1.7139e-01, time/batch = 0.6764s	
22506/28500 (epoch 39.484), train_loss = 0.75264942, grad/param norm = 1.7474e-01, time/batch = 0.6778s	
22507/28500 (epoch 39.486), train_loss = 0.66160608, grad/param norm = 1.7992e-01, time/batch = 0.6759s	
22508/28500 (epoch 39.488), train_loss = 0.87526201, grad/param norm = 1.7639e-01, time/batch = 0.6979s	
22509/28500 (epoch 39.489), train_loss = 0.95131390, grad/param norm = 1.9035e-01, time/batch = 0.6818s	
22510/28500 (epoch 39.491), train_loss = 0.76998000, grad/param norm = 2.0204e-01, time/batch = 0.6814s	
22511/28500 (epoch 39.493), train_loss = 0.80155842, grad/param norm = 1.9511e-01, time/batch = 0.6811s	
22512/28500 (epoch 39.495), train_loss = 0.84366612, grad/param norm = 1.9428e-01, time/batch = 0.6775s	
22513/28500 (epoch 39.496), train_loss = 0.75912676, grad/param norm = 1.9940e-01, time/batch = 0.6793s	
22514/28500 (epoch 39.498), train_loss = 0.81167995, grad/param norm = 1.7171e-01, time/batch = 0.6794s	
22515/28500 (epoch 39.500), train_loss = 0.75915877, grad/param norm = 1.6651e-01, time/batch = 0.6784s	
22516/28500 (epoch 39.502), train_loss = 0.86159710, grad/param norm = 1.7322e-01, time/batch = 0.6759s	
22517/28500 (epoch 39.504), train_loss = 0.87215412, grad/param norm = 1.7086e-01, time/batch = 0.6789s	
22518/28500 (epoch 39.505), train_loss = 0.75812668, grad/param norm = 1.9259e-01, time/batch = 0.6770s	
22519/28500 (epoch 39.507), train_loss = 0.91633150, grad/param norm = 2.0197e-01, time/batch = 0.6789s	
22520/28500 (epoch 39.509), train_loss = 0.82557860, grad/param norm = 1.8616e-01, time/batch = 0.6765s	
22521/28500 (epoch 39.511), train_loss = 0.80651377, grad/param norm = 1.6722e-01, time/batch = 0.6786s	
22522/28500 (epoch 39.512), train_loss = 0.86040572, grad/param norm = 1.8422e-01, time/batch = 0.6781s	
22523/28500 (epoch 39.514), train_loss = 0.81730098, grad/param norm = 1.8253e-01, time/batch = 0.6764s	
22524/28500 (epoch 39.516), train_loss = 0.81000589, grad/param norm = 1.5506e-01, time/batch = 0.6772s	
22525/28500 (epoch 39.518), train_loss = 0.86207668, grad/param norm = 1.9073e-01, time/batch = 0.6762s	
22526/28500 (epoch 39.519), train_loss = 0.85775420, grad/param norm = 1.7813e-01, time/batch = 0.6777s	
22527/28500 (epoch 39.521), train_loss = 0.93656927, grad/param norm = 2.1405e-01, time/batch = 0.6780s	
22528/28500 (epoch 39.523), train_loss = 0.86054366, grad/param norm = 1.8435e-01, time/batch = 0.6804s	
22529/28500 (epoch 39.525), train_loss = 0.93425132, grad/param norm = 1.8057e-01, time/batch = 0.6765s	
22530/28500 (epoch 39.526), train_loss = 0.86247288, grad/param norm = 1.7716e-01, time/batch = 0.6778s	
22531/28500 (epoch 39.528), train_loss = 0.86834832, grad/param norm = 2.0705e-01, time/batch = 0.6778s	
22532/28500 (epoch 39.530), train_loss = 0.88729766, grad/param norm = 1.9603e-01, time/batch = 0.6769s	
22533/28500 (epoch 39.532), train_loss = 0.80550582, grad/param norm = 1.8760e-01, time/batch = 0.6778s	
22534/28500 (epoch 39.533), train_loss = 0.85997081, grad/param norm = 1.6131e-01, time/batch = 0.6796s	
22535/28500 (epoch 39.535), train_loss = 0.71624241, grad/param norm = 1.5515e-01, time/batch = 0.6776s	
22536/28500 (epoch 39.537), train_loss = 0.72476429, grad/param norm = 2.3534e-01, time/batch = 0.6793s	
22537/28500 (epoch 39.539), train_loss = 0.70415150, grad/param norm = 1.7495e-01, time/batch = 0.6765s	
22538/28500 (epoch 39.540), train_loss = 0.81765137, grad/param norm = 1.7657e-01, time/batch = 0.6797s	
22539/28500 (epoch 39.542), train_loss = 0.87600699, grad/param norm = 2.3622e-01, time/batch = 0.6773s	
22540/28500 (epoch 39.544), train_loss = 0.96528184, grad/param norm = 2.0719e-01, time/batch = 0.6785s	
22541/28500 (epoch 39.546), train_loss = 0.82189301, grad/param norm = 1.8290e-01, time/batch = 0.6909s	
22542/28500 (epoch 39.547), train_loss = 0.80481645, grad/param norm = 1.9061e-01, time/batch = 0.6788s	
22543/28500 (epoch 39.549), train_loss = 0.69814942, grad/param norm = 1.5071e-01, time/batch = 0.6779s	
22544/28500 (epoch 39.551), train_loss = 0.77476132, grad/param norm = 1.9661e-01, time/batch = 0.6765s	
22545/28500 (epoch 39.553), train_loss = 0.97237862, grad/param norm = 2.2430e-01, time/batch = 0.6773s	
22546/28500 (epoch 39.554), train_loss = 0.87910122, grad/param norm = 2.0380e-01, time/batch = 0.6766s	
22547/28500 (epoch 39.556), train_loss = 0.86818805, grad/param norm = 1.7130e-01, time/batch = 0.6766s	
22548/28500 (epoch 39.558), train_loss = 0.89002730, grad/param norm = 1.8631e-01, time/batch = 0.6764s	
22549/28500 (epoch 39.560), train_loss = 0.87922841, grad/param norm = 2.0981e-01, time/batch = 0.6797s	
22550/28500 (epoch 39.561), train_loss = 0.88858101, grad/param norm = 2.0815e-01, time/batch = 0.6800s	
22551/28500 (epoch 39.563), train_loss = 0.97808849, grad/param norm = 2.3719e-01, time/batch = 0.6831s	
22552/28500 (epoch 39.565), train_loss = 0.76847101, grad/param norm = 1.8002e-01, time/batch = 0.6809s	
22553/28500 (epoch 39.567), train_loss = 0.71898730, grad/param norm = 1.8341e-01, time/batch = 0.6821s	
22554/28500 (epoch 39.568), train_loss = 0.85231909, grad/param norm = 2.0958e-01, time/batch = 0.6778s	
22555/28500 (epoch 39.570), train_loss = 0.80515261, grad/param norm = 1.9385e-01, time/batch = 0.6798s	
22556/28500 (epoch 39.572), train_loss = 0.85848479, grad/param norm = 1.9678e-01, time/batch = 0.6868s	
22557/28500 (epoch 39.574), train_loss = 0.78867196, grad/param norm = 1.8311e-01, time/batch = 0.6839s	
22558/28500 (epoch 39.575), train_loss = 0.77824642, grad/param norm = 2.7953e-01, time/batch = 0.6959s	
22559/28500 (epoch 39.577), train_loss = 0.89807552, grad/param norm = 1.8531e-01, time/batch = 0.6816s	
22560/28500 (epoch 39.579), train_loss = 0.90914031, grad/param norm = 2.0400e-01, time/batch = 0.6834s	
22561/28500 (epoch 39.581), train_loss = 0.77579431, grad/param norm = 2.1556e-01, time/batch = 0.6853s	
22562/28500 (epoch 39.582), train_loss = 0.93620051, grad/param norm = 1.8325e-01, time/batch = 0.6810s	
22563/28500 (epoch 39.584), train_loss = 0.77112768, grad/param norm = 2.1531e-01, time/batch = 0.6823s	
22564/28500 (epoch 39.586), train_loss = 0.75574194, grad/param norm = 1.5752e-01, time/batch = 0.6817s	
22565/28500 (epoch 39.588), train_loss = 0.77851681, grad/param norm = 1.9501e-01, time/batch = 0.6926s	
22566/28500 (epoch 39.589), train_loss = 0.82813307, grad/param norm = 2.0634e-01, time/batch = 0.6804s	
22567/28500 (epoch 39.591), train_loss = 0.84355168, grad/param norm = 2.0422e-01, time/batch = 0.6782s	
22568/28500 (epoch 39.593), train_loss = 0.79201040, grad/param norm = 1.8404e-01, time/batch = 0.6779s	
22569/28500 (epoch 39.595), train_loss = 0.99533816, grad/param norm = 2.2592e-01, time/batch = 0.6810s	
22570/28500 (epoch 39.596), train_loss = 1.00015889, grad/param norm = 2.0843e-01, time/batch = 0.6756s	
22571/28500 (epoch 39.598), train_loss = 0.82357493, grad/param norm = 1.8849e-01, time/batch = 0.6804s	
22572/28500 (epoch 39.600), train_loss = 0.83031659, grad/param norm = 1.9471e-01, time/batch = 0.6768s	
22573/28500 (epoch 39.602), train_loss = 0.89763642, grad/param norm = 1.8829e-01, time/batch = 0.6771s	
22574/28500 (epoch 39.604), train_loss = 0.92290577, grad/param norm = 1.8500e-01, time/batch = 0.6842s	
22575/28500 (epoch 39.605), train_loss = 0.93134205, grad/param norm = 2.2671e-01, time/batch = 0.6999s	
22576/28500 (epoch 39.607), train_loss = 0.95386470, grad/param norm = 1.8939e-01, time/batch = 0.6904s	
22577/28500 (epoch 39.609), train_loss = 0.85577554, grad/param norm = 1.8402e-01, time/batch = 0.6853s	
22578/28500 (epoch 39.611), train_loss = 0.83289687, grad/param norm = 2.0433e-01, time/batch = 0.6807s	
22579/28500 (epoch 39.612), train_loss = 0.90252062, grad/param norm = 2.2052e-01, time/batch = 0.6926s	
22580/28500 (epoch 39.614), train_loss = 0.91683408, grad/param norm = 1.9656e-01, time/batch = 0.6832s	
22581/28500 (epoch 39.616), train_loss = 0.79807821, grad/param norm = 1.9075e-01, time/batch = 0.6934s	
22582/28500 (epoch 39.618), train_loss = 0.83493536, grad/param norm = 2.0999e-01, time/batch = 0.6807s	
22583/28500 (epoch 39.619), train_loss = 0.89616446, grad/param norm = 2.0422e-01, time/batch = 0.6840s	
22584/28500 (epoch 39.621), train_loss = 0.67470724, grad/param norm = 1.9000e-01, time/batch = 0.6803s	
22585/28500 (epoch 39.623), train_loss = 0.95311695, grad/param norm = 1.9356e-01, time/batch = 0.6869s	
22586/28500 (epoch 39.625), train_loss = 0.75806550, grad/param norm = 1.8412e-01, time/batch = 0.6848s	
22587/28500 (epoch 39.626), train_loss = 0.65838622, grad/param norm = 1.5443e-01, time/batch = 0.6806s	
22588/28500 (epoch 39.628), train_loss = 0.76151851, grad/param norm = 1.7573e-01, time/batch = 0.6819s	
22589/28500 (epoch 39.630), train_loss = 0.73288430, grad/param norm = 1.6958e-01, time/batch = 0.6807s	
22590/28500 (epoch 39.632), train_loss = 0.93171001, grad/param norm = 2.0961e-01, time/batch = 0.6768s	
22591/28500 (epoch 39.633), train_loss = 0.98011201, grad/param norm = 1.7992e-01, time/batch = 0.6825s	
22592/28500 (epoch 39.635), train_loss = 0.86713672, grad/param norm = 2.2180e-01, time/batch = 0.6772s	
22593/28500 (epoch 39.637), train_loss = 0.85767023, grad/param norm = 1.9032e-01, time/batch = 0.6804s	
22594/28500 (epoch 39.639), train_loss = 0.75385217, grad/param norm = 1.8760e-01, time/batch = 0.6769s	
22595/28500 (epoch 39.640), train_loss = 0.78251128, grad/param norm = 1.7853e-01, time/batch = 0.6796s	
22596/28500 (epoch 39.642), train_loss = 0.80488345, grad/param norm = 1.9441e-01, time/batch = 0.6772s	
22597/28500 (epoch 39.644), train_loss = 0.86969034, grad/param norm = 1.9099e-01, time/batch = 0.6780s	
22598/28500 (epoch 39.646), train_loss = 0.69573858, grad/param norm = 1.4938e-01, time/batch = 0.6784s	
22599/28500 (epoch 39.647), train_loss = 0.78230091, grad/param norm = 1.7629e-01, time/batch = 0.6769s	
22600/28500 (epoch 39.649), train_loss = 0.76713331, grad/param norm = 1.7715e-01, time/batch = 0.6772s	
22601/28500 (epoch 39.651), train_loss = 0.72693919, grad/param norm = 1.5631e-01, time/batch = 0.6808s	
22602/28500 (epoch 39.653), train_loss = 0.70833749, grad/param norm = 1.8268e-01, time/batch = 0.6821s	
22603/28500 (epoch 39.654), train_loss = 0.75562402, grad/param norm = 1.8512e-01, time/batch = 0.6779s	
22604/28500 (epoch 39.656), train_loss = 0.70572926, grad/param norm = 2.4291e-01, time/batch = 0.6799s	
22605/28500 (epoch 39.658), train_loss = 0.82702224, grad/param norm = 1.7609e-01, time/batch = 0.6768s	
22606/28500 (epoch 39.660), train_loss = 0.83663977, grad/param norm = 1.7763e-01, time/batch = 0.6791s	
22607/28500 (epoch 39.661), train_loss = 0.92072517, grad/param norm = 2.0055e-01, time/batch = 0.6770s	
22608/28500 (epoch 39.663), train_loss = 0.92620945, grad/param norm = 2.0763e-01, time/batch = 0.6790s	
22609/28500 (epoch 39.665), train_loss = 0.84391759, grad/param norm = 2.1631e-01, time/batch = 0.6769s	
22610/28500 (epoch 39.667), train_loss = 0.85043004, grad/param norm = 2.3376e-01, time/batch = 0.6799s	
22611/28500 (epoch 39.668), train_loss = 0.83783961, grad/param norm = 2.1278e-01, time/batch = 0.6779s	
22612/28500 (epoch 39.670), train_loss = 0.83296930, grad/param norm = 1.7568e-01, time/batch = 0.6806s	
22613/28500 (epoch 39.672), train_loss = 0.74939346, grad/param norm = 1.7157e-01, time/batch = 0.6842s	
22614/28500 (epoch 39.674), train_loss = 0.66506847, grad/param norm = 2.4242e-01, time/batch = 0.6793s	
22615/28500 (epoch 39.675), train_loss = 0.70796140, grad/param norm = 1.8035e-01, time/batch = 0.6859s	
22616/28500 (epoch 39.677), train_loss = 0.78557010, grad/param norm = 1.7144e-01, time/batch = 0.6805s	
22617/28500 (epoch 39.679), train_loss = 0.80295398, grad/param norm = 2.2154e-01, time/batch = 0.6824s	
22618/28500 (epoch 39.681), train_loss = 0.86417903, grad/param norm = 1.9520e-01, time/batch = 0.6813s	
22619/28500 (epoch 39.682), train_loss = 0.78602505, grad/param norm = 1.7803e-01, time/batch = 0.6812s	
22620/28500 (epoch 39.684), train_loss = 0.81934906, grad/param norm = 1.8170e-01, time/batch = 0.6870s	
22621/28500 (epoch 39.686), train_loss = 0.77445233, grad/param norm = 1.7398e-01, time/batch = 0.6815s	
22622/28500 (epoch 39.688), train_loss = 0.76612555, grad/param norm = 1.5537e-01, time/batch = 0.6839s	
22623/28500 (epoch 39.689), train_loss = 0.75309967, grad/param norm = 1.7695e-01, time/batch = 0.6814s	
22624/28500 (epoch 39.691), train_loss = 0.87775484, grad/param norm = 2.0998e-01, time/batch = 0.6847s	
22625/28500 (epoch 39.693), train_loss = 0.78363420, grad/param norm = 1.7627e-01, time/batch = 0.6807s	
22626/28500 (epoch 39.695), train_loss = 0.61395660, grad/param norm = 1.9768e-01, time/batch = 0.6822s	
22627/28500 (epoch 39.696), train_loss = 0.77796143, grad/param norm = 1.7143e-01, time/batch = 0.6892s	
22628/28500 (epoch 39.698), train_loss = 0.86146533, grad/param norm = 1.7482e-01, time/batch = 0.6822s	
22629/28500 (epoch 39.700), train_loss = 0.82912166, grad/param norm = 1.9838e-01, time/batch = 0.6853s	
22630/28500 (epoch 39.702), train_loss = 0.80948784, grad/param norm = 2.2294e-01, time/batch = 0.6798s	
22631/28500 (epoch 39.704), train_loss = 0.87240652, grad/param norm = 2.0723e-01, time/batch = 0.6847s	
22632/28500 (epoch 39.705), train_loss = 0.88384213, grad/param norm = 2.5746e-01, time/batch = 0.6833s	
22633/28500 (epoch 39.707), train_loss = 0.76891228, grad/param norm = 2.0327e-01, time/batch = 0.6823s	
22634/28500 (epoch 39.709), train_loss = 0.97688085, grad/param norm = 2.0956e-01, time/batch = 0.6940s	
22635/28500 (epoch 39.711), train_loss = 0.76498273, grad/param norm = 1.8509e-01, time/batch = 0.6889s	
22636/28500 (epoch 39.712), train_loss = 0.84962324, grad/param norm = 1.8634e-01, time/batch = 0.6857s	
22637/28500 (epoch 39.714), train_loss = 0.93967618, grad/param norm = 2.0091e-01, time/batch = 0.6882s	
22638/28500 (epoch 39.716), train_loss = 0.81368804, grad/param norm = 1.8881e-01, time/batch = 0.6830s	
22639/28500 (epoch 39.718), train_loss = 0.82573239, grad/param norm = 1.8574e-01, time/batch = 0.6827s	
22640/28500 (epoch 39.719), train_loss = 0.84714413, grad/param norm = 1.8732e-01, time/batch = 0.6825s	
22641/28500 (epoch 39.721), train_loss = 0.64551153, grad/param norm = 1.8214e-01, time/batch = 0.6890s	
22642/28500 (epoch 39.723), train_loss = 0.83155529, grad/param norm = 1.9501e-01, time/batch = 0.6824s	
22643/28500 (epoch 39.725), train_loss = 0.90767382, grad/param norm = 2.3267e-01, time/batch = 0.6820s	
22644/28500 (epoch 39.726), train_loss = 0.82061330, grad/param norm = 2.0597e-01, time/batch = 0.6828s	
22645/28500 (epoch 39.728), train_loss = 0.74078918, grad/param norm = 1.8117e-01, time/batch = 0.6793s	
22646/28500 (epoch 39.730), train_loss = 0.83887660, grad/param norm = 2.2603e-01, time/batch = 0.6780s	
22647/28500 (epoch 39.732), train_loss = 0.66067876, grad/param norm = 1.7832e-01, time/batch = 0.6803s	
22648/28500 (epoch 39.733), train_loss = 0.68947551, grad/param norm = 1.6935e-01, time/batch = 0.6789s	
22649/28500 (epoch 39.735), train_loss = 0.70658478, grad/param norm = 1.6901e-01, time/batch = 0.6825s	
22650/28500 (epoch 39.737), train_loss = 0.62786643, grad/param norm = 1.5315e-01, time/batch = 0.6794s	
22651/28500 (epoch 39.739), train_loss = 0.72122652, grad/param norm = 1.7752e-01, time/batch = 0.6914s	
22652/28500 (epoch 39.740), train_loss = 0.82069763, grad/param norm = 1.9748e-01, time/batch = 0.6872s	
22653/28500 (epoch 39.742), train_loss = 0.73548007, grad/param norm = 1.9203e-01, time/batch = 1.2000s	
22654/28500 (epoch 39.744), train_loss = 0.82045884, grad/param norm = 1.7986e-01, time/batch = 0.7815s	
22655/28500 (epoch 39.746), train_loss = 0.76832599, grad/param norm = 1.6856e-01, time/batch = 0.6790s	
22656/28500 (epoch 39.747), train_loss = 0.76272275, grad/param norm = 1.6899e-01, time/batch = 0.6860s	
22657/28500 (epoch 39.749), train_loss = 0.88660491, grad/param norm = 2.5067e-01, time/batch = 0.6864s	
22658/28500 (epoch 39.751), train_loss = 0.72325869, grad/param norm = 2.0240e-01, time/batch = 0.6786s	
22659/28500 (epoch 39.753), train_loss = 0.81117786, grad/param norm = 1.6480e-01, time/batch = 0.6761s	
22660/28500 (epoch 39.754), train_loss = 0.71992834, grad/param norm = 1.7585e-01, time/batch = 0.6757s	
22661/28500 (epoch 39.756), train_loss = 0.94608016, grad/param norm = 2.1430e-01, time/batch = 0.6844s	
22662/28500 (epoch 39.758), train_loss = 0.85908483, grad/param norm = 2.1151e-01, time/batch = 0.6921s	
22663/28500 (epoch 39.760), train_loss = 0.70261303, grad/param norm = 1.7250e-01, time/batch = 0.6760s	
22664/28500 (epoch 39.761), train_loss = 0.76234584, grad/param norm = 1.8858e-01, time/batch = 0.6825s	
22665/28500 (epoch 39.763), train_loss = 0.63925980, grad/param norm = 1.7409e-01, time/batch = 0.6803s	
22666/28500 (epoch 39.765), train_loss = 0.80115902, grad/param norm = 1.8928e-01, time/batch = 0.6968s	
22667/28500 (epoch 39.767), train_loss = 0.66189875, grad/param norm = 1.4590e-01, time/batch = 0.6929s	
22668/28500 (epoch 39.768), train_loss = 0.84164375, grad/param norm = 1.7864e-01, time/batch = 0.6873s	
22669/28500 (epoch 39.770), train_loss = 0.69820962, grad/param norm = 1.7889e-01, time/batch = 0.6800s	
22670/28500 (epoch 39.772), train_loss = 0.66467915, grad/param norm = 1.4737e-01, time/batch = 0.6781s	
22671/28500 (epoch 39.774), train_loss = 0.80499756, grad/param norm = 1.6267e-01, time/batch = 0.6902s	
22672/28500 (epoch 39.775), train_loss = 0.85804701, grad/param norm = 1.8255e-01, time/batch = 0.6872s	
22673/28500 (epoch 39.777), train_loss = 0.86776481, grad/param norm = 1.6093e-01, time/batch = 0.6854s	
22674/28500 (epoch 39.779), train_loss = 0.68518130, grad/param norm = 1.5385e-01, time/batch = 0.6815s	
22675/28500 (epoch 39.781), train_loss = 0.79304555, grad/param norm = 1.8918e-01, time/batch = 0.6769s	
22676/28500 (epoch 39.782), train_loss = 0.84582436, grad/param norm = 2.2299e-01, time/batch = 0.6759s	
22677/28500 (epoch 39.784), train_loss = 0.65444808, grad/param norm = 1.7759e-01, time/batch = 0.6770s	
22678/28500 (epoch 39.786), train_loss = 0.66460037, grad/param norm = 1.7157e-01, time/batch = 0.6796s	
22679/28500 (epoch 39.788), train_loss = 0.75098879, grad/param norm = 1.7631e-01, time/batch = 0.6829s	
22680/28500 (epoch 39.789), train_loss = 0.61879205, grad/param norm = 2.5000e-01, time/batch = 0.6757s	
22681/28500 (epoch 39.791), train_loss = 0.83757344, grad/param norm = 1.8407e-01, time/batch = 0.6839s	
22682/28500 (epoch 39.793), train_loss = 0.78010376, grad/param norm = 1.8667e-01, time/batch = 0.6777s	
22683/28500 (epoch 39.795), train_loss = 0.80523706, grad/param norm = 1.7738e-01, time/batch = 0.6796s	
22684/28500 (epoch 39.796), train_loss = 0.71510076, grad/param norm = 1.8021e-01, time/batch = 0.6774s	
22685/28500 (epoch 39.798), train_loss = 0.66703293, grad/param norm = 1.7069e-01, time/batch = 0.6770s	
22686/28500 (epoch 39.800), train_loss = 0.64914149, grad/param norm = 1.9306e-01, time/batch = 0.6802s	
22687/28500 (epoch 39.802), train_loss = 0.75765414, grad/param norm = 2.3362e-01, time/batch = 0.6776s	
22688/28500 (epoch 39.804), train_loss = 0.82013462, grad/param norm = 1.6406e-01, time/batch = 0.6767s	
22689/28500 (epoch 39.805), train_loss = 0.82041414, grad/param norm = 1.9714e-01, time/batch = 0.6778s	
22690/28500 (epoch 39.807), train_loss = 0.81347951, grad/param norm = 2.0044e-01, time/batch = 0.6762s	
22691/28500 (epoch 39.809), train_loss = 0.80131983, grad/param norm = 2.0460e-01, time/batch = 0.6785s	
22692/28500 (epoch 39.811), train_loss = 0.80917291, grad/param norm = 1.9665e-01, time/batch = 0.6764s	
22693/28500 (epoch 39.812), train_loss = 0.78555290, grad/param norm = 2.1697e-01, time/batch = 0.6765s	
22694/28500 (epoch 39.814), train_loss = 0.75940200, grad/param norm = 1.7548e-01, time/batch = 0.6776s	
22695/28500 (epoch 39.816), train_loss = 0.81250898, grad/param norm = 1.8897e-01, time/batch = 0.6787s	
22696/28500 (epoch 39.818), train_loss = 0.92349090, grad/param norm = 2.0297e-01, time/batch = 0.6792s	
22697/28500 (epoch 39.819), train_loss = 0.79924855, grad/param norm = 1.8150e-01, time/batch = 0.6763s	
22698/28500 (epoch 39.821), train_loss = 0.76953669, grad/param norm = 1.7868e-01, time/batch = 0.6757s	
22699/28500 (epoch 39.823), train_loss = 0.91231224, grad/param norm = 2.1933e-01, time/batch = 0.6757s	
22700/28500 (epoch 39.825), train_loss = 0.74200127, grad/param norm = 2.5721e-01, time/batch = 0.6761s	
22701/28500 (epoch 39.826), train_loss = 0.81780668, grad/param norm = 1.8867e-01, time/batch = 0.6820s	
22702/28500 (epoch 39.828), train_loss = 0.73670800, grad/param norm = 1.8447e-01, time/batch = 0.6786s	
22703/28500 (epoch 39.830), train_loss = 0.74992606, grad/param norm = 1.4948e-01, time/batch = 0.6780s	
22704/28500 (epoch 39.832), train_loss = 0.80261288, grad/param norm = 2.3385e-01, time/batch = 0.6806s	
22705/28500 (epoch 39.833), train_loss = 0.85273865, grad/param norm = 1.8402e-01, time/batch = 0.6796s	
22706/28500 (epoch 39.835), train_loss = 0.76079222, grad/param norm = 1.9791e-01, time/batch = 0.6772s	
22707/28500 (epoch 39.837), train_loss = 0.67339126, grad/param norm = 1.7435e-01, time/batch = 0.6806s	
22708/28500 (epoch 39.839), train_loss = 0.94048588, grad/param norm = 2.7747e-01, time/batch = 0.6788s	
22709/28500 (epoch 39.840), train_loss = 0.93502461, grad/param norm = 1.9666e-01, time/batch = 0.6758s	
22710/28500 (epoch 39.842), train_loss = 0.87566333, grad/param norm = 2.1784e-01, time/batch = 0.6776s	
22711/28500 (epoch 39.844), train_loss = 0.87531993, grad/param norm = 1.7680e-01, time/batch = 0.6781s	
22712/28500 (epoch 39.846), train_loss = 0.96934943, grad/param norm = 2.2868e-01, time/batch = 0.6760s	
22713/28500 (epoch 39.847), train_loss = 0.77366350, grad/param norm = 1.8712e-01, time/batch = 0.6766s	
22714/28500 (epoch 39.849), train_loss = 0.77307396, grad/param norm = 1.6509e-01, time/batch = 0.6758s	
22715/28500 (epoch 39.851), train_loss = 0.72683882, grad/param norm = 1.7199e-01, time/batch = 0.6775s	
22716/28500 (epoch 39.853), train_loss = 0.84209014, grad/param norm = 2.1013e-01, time/batch = 0.6763s	
22717/28500 (epoch 39.854), train_loss = 0.82062376, grad/param norm = 1.9381e-01, time/batch = 0.6779s	
22718/28500 (epoch 39.856), train_loss = 0.90717368, grad/param norm = 2.2305e-01, time/batch = 0.6806s	
22719/28500 (epoch 39.858), train_loss = 0.76551691, grad/param norm = 1.8461e-01, time/batch = 0.6803s	
22720/28500 (epoch 39.860), train_loss = 0.78194684, grad/param norm = 1.9639e-01, time/batch = 0.6796s	
22721/28500 (epoch 39.861), train_loss = 0.91321553, grad/param norm = 2.9685e-01, time/batch = 0.6796s	
22722/28500 (epoch 39.863), train_loss = 0.83798443, grad/param norm = 2.3487e-01, time/batch = 0.6780s	
22723/28500 (epoch 39.865), train_loss = 0.75806578, grad/param norm = 2.1789e-01, time/batch = 0.6795s	
22724/28500 (epoch 39.867), train_loss = 0.84427189, grad/param norm = 2.3422e-01, time/batch = 0.6802s	
22725/28500 (epoch 39.868), train_loss = 0.72151845, grad/param norm = 1.7566e-01, time/batch = 0.6795s	
22726/28500 (epoch 39.870), train_loss = 0.70680327, grad/param norm = 1.9046e-01, time/batch = 0.6772s	
22727/28500 (epoch 39.872), train_loss = 0.88093659, grad/param norm = 2.6267e-01, time/batch = 0.6777s	
22728/28500 (epoch 39.874), train_loss = 0.73477712, grad/param norm = 2.2820e-01, time/batch = 0.6771s	
22729/28500 (epoch 39.875), train_loss = 0.95362488, grad/param norm = 2.1282e-01, time/batch = 0.6808s	
22730/28500 (epoch 39.877), train_loss = 0.83537918, grad/param norm = 1.9007e-01, time/batch = 0.6768s	
22731/28500 (epoch 39.879), train_loss = 0.87757074, grad/param norm = 1.7725e-01, time/batch = 0.6819s	
22732/28500 (epoch 39.881), train_loss = 0.86439627, grad/param norm = 2.0192e-01, time/batch = 0.6786s	
22733/28500 (epoch 39.882), train_loss = 0.75071746, grad/param norm = 1.8077e-01, time/batch = 0.6813s	
22734/28500 (epoch 39.884), train_loss = 0.77639911, grad/param norm = 1.9721e-01, time/batch = 0.6771s	
22735/28500 (epoch 39.886), train_loss = 0.76543533, grad/param norm = 1.7849e-01, time/batch = 0.6784s	
22736/28500 (epoch 39.888), train_loss = 0.76466217, grad/param norm = 1.5600e-01, time/batch = 0.6801s	
22737/28500 (epoch 39.889), train_loss = 0.81481096, grad/param norm = 1.6167e-01, time/batch = 0.6789s	
22738/28500 (epoch 39.891), train_loss = 0.82380259, grad/param norm = 1.8493e-01, time/batch = 0.6787s	
22739/28500 (epoch 39.893), train_loss = 0.75973006, grad/param norm = 1.8750e-01, time/batch = 0.6826s	
22740/28500 (epoch 39.895), train_loss = 0.96178760, grad/param norm = 2.6141e-01, time/batch = 0.6972s	
22741/28500 (epoch 39.896), train_loss = 0.90756452, grad/param norm = 2.3472e-01, time/batch = 0.7023s	
22742/28500 (epoch 39.898), train_loss = 0.85453930, grad/param norm = 1.8458e-01, time/batch = 0.6957s	
22743/28500 (epoch 39.900), train_loss = 0.71609308, grad/param norm = 1.7691e-01, time/batch = 0.6952s	
22744/28500 (epoch 39.902), train_loss = 0.68360344, grad/param norm = 1.8012e-01, time/batch = 0.6961s	
22745/28500 (epoch 39.904), train_loss = 0.71651810, grad/param norm = 1.5957e-01, time/batch = 0.6943s	
22746/28500 (epoch 39.905), train_loss = 0.76977939, grad/param norm = 2.0514e-01, time/batch = 0.6945s	
22747/28500 (epoch 39.907), train_loss = 0.79385702, grad/param norm = 1.7051e-01, time/batch = 0.6968s	
22748/28500 (epoch 39.909), train_loss = 0.66101242, grad/param norm = 2.0223e-01, time/batch = 0.7059s	
22749/28500 (epoch 39.911), train_loss = 0.71785839, grad/param norm = 1.6688e-01, time/batch = 0.7007s	
22750/28500 (epoch 39.912), train_loss = 0.59583769, grad/param norm = 1.5464e-01, time/batch = 0.6991s	
22751/28500 (epoch 39.914), train_loss = 0.82003878, grad/param norm = 1.7458e-01, time/batch = 0.7016s	
22752/28500 (epoch 39.916), train_loss = 0.80345739, grad/param norm = 1.9009e-01, time/batch = 0.6961s	
22753/28500 (epoch 39.918), train_loss = 0.80553141, grad/param norm = 2.0234e-01, time/batch = 0.7043s	
22754/28500 (epoch 39.919), train_loss = 0.82370068, grad/param norm = 1.6446e-01, time/batch = 0.6984s	
22755/28500 (epoch 39.921), train_loss = 0.89951601, grad/param norm = 1.8880e-01, time/batch = 0.7003s	
22756/28500 (epoch 39.923), train_loss = 0.74859409, grad/param norm = 2.2032e-01, time/batch = 0.6965s	
22757/28500 (epoch 39.925), train_loss = 0.74182919, grad/param norm = 2.0195e-01, time/batch = 0.6957s	
22758/28500 (epoch 39.926), train_loss = 0.80521491, grad/param norm = 1.7325e-01, time/batch = 0.6945s	
22759/28500 (epoch 39.928), train_loss = 0.76422891, grad/param norm = 1.7952e-01, time/batch = 0.6952s	
22760/28500 (epoch 39.930), train_loss = 0.64078090, grad/param norm = 1.5174e-01, time/batch = 0.6946s	
22761/28500 (epoch 39.932), train_loss = 0.65804909, grad/param norm = 1.6262e-01, time/batch = 0.6993s	
22762/28500 (epoch 39.933), train_loss = 0.85601170, grad/param norm = 1.7599e-01, time/batch = 0.7009s	
22763/28500 (epoch 39.935), train_loss = 0.89221717, grad/param norm = 1.7647e-01, time/batch = 0.6977s	
22764/28500 (epoch 39.937), train_loss = 0.88941726, grad/param norm = 2.4430e-01, time/batch = 0.6974s	
22765/28500 (epoch 39.939), train_loss = 0.92353493, grad/param norm = 2.0159e-01, time/batch = 0.6949s	
22766/28500 (epoch 39.940), train_loss = 0.65882494, grad/param norm = 1.7644e-01, time/batch = 0.7052s	
22767/28500 (epoch 39.942), train_loss = 0.80653706, grad/param norm = 1.8861e-01, time/batch = 0.7050s	
22768/28500 (epoch 39.944), train_loss = 0.79075926, grad/param norm = 2.0818e-01, time/batch = 0.7127s	
22769/28500 (epoch 39.946), train_loss = 0.84973261, grad/param norm = 1.7038e-01, time/batch = 0.7122s	
22770/28500 (epoch 39.947), train_loss = 1.04394076, grad/param norm = 3.2062e-01, time/batch = 0.7219s	
22771/28500 (epoch 39.949), train_loss = 0.79320831, grad/param norm = 2.0799e-01, time/batch = 0.7039s	
22772/28500 (epoch 39.951), train_loss = 0.97248472, grad/param norm = 2.0766e-01, time/batch = 0.7031s	
22773/28500 (epoch 39.953), train_loss = 0.96939946, grad/param norm = 2.1646e-01, time/batch = 0.6978s	
22774/28500 (epoch 39.954), train_loss = 0.88644278, grad/param norm = 2.0321e-01, time/batch = 0.7048s	
22775/28500 (epoch 39.956), train_loss = 0.82297042, grad/param norm = 4.3804e-01, time/batch = 0.6944s	
22776/28500 (epoch 39.958), train_loss = 1.04824836, grad/param norm = 2.1429e-01, time/batch = 0.6958s	
22777/28500 (epoch 39.960), train_loss = 0.77081566, grad/param norm = 2.5670e-01, time/batch = 0.6940s	
22778/28500 (epoch 39.961), train_loss = 0.96190657, grad/param norm = 2.3030e-01, time/batch = 0.7024s	
22779/28500 (epoch 39.963), train_loss = 0.92625639, grad/param norm = 2.8863e-01, time/batch = 0.6965s	
22780/28500 (epoch 39.965), train_loss = 0.74699718, grad/param norm = 1.8605e-01, time/batch = 0.6952s	
22781/28500 (epoch 39.967), train_loss = 0.77144601, grad/param norm = 1.8488e-01, time/batch = 0.6994s	
22782/28500 (epoch 39.968), train_loss = 0.71834830, grad/param norm = 1.6556e-01, time/batch = 0.6987s	
22783/28500 (epoch 39.970), train_loss = 0.75640615, grad/param norm = 2.2635e-01, time/batch = 0.6962s	
22784/28500 (epoch 39.972), train_loss = 0.82588138, grad/param norm = 1.9412e-01, time/batch = 0.7072s	
22785/28500 (epoch 39.974), train_loss = 1.04483430, grad/param norm = 2.9925e-01, time/batch = 0.6978s	
22786/28500 (epoch 39.975), train_loss = 0.75645021, grad/param norm = 2.2269e-01, time/batch = 0.6982s	
22787/28500 (epoch 39.977), train_loss = 0.90868105, grad/param norm = 2.3741e-01, time/batch = 0.6977s	
22788/28500 (epoch 39.979), train_loss = 0.83959113, grad/param norm = 1.8574e-01, time/batch = 0.7001s	
22789/28500 (epoch 39.981), train_loss = 0.69656704, grad/param norm = 1.8573e-01, time/batch = 0.6984s	
22790/28500 (epoch 39.982), train_loss = 0.79610008, grad/param norm = 1.9162e-01, time/batch = 0.7007s	
22791/28500 (epoch 39.984), train_loss = 0.89034061, grad/param norm = 1.9079e-01, time/batch = 0.7002s	
22792/28500 (epoch 39.986), train_loss = 1.05565979, grad/param norm = 2.3542e-01, time/batch = 0.7010s	
22793/28500 (epoch 39.988), train_loss = 0.73734600, grad/param norm = 1.7589e-01, time/batch = 0.7013s	
22794/28500 (epoch 39.989), train_loss = 0.82935168, grad/param norm = 2.0832e-01, time/batch = 0.7027s	
22795/28500 (epoch 39.991), train_loss = 0.76127638, grad/param norm = 2.4569e-01, time/batch = 0.7058s	
22796/28500 (epoch 39.993), train_loss = 0.72586353, grad/param norm = 1.9217e-01, time/batch = 0.7045s	
22797/28500 (epoch 39.995), train_loss = 0.77982939, grad/param norm = 1.8813e-01, time/batch = 0.6997s	
22798/28500 (epoch 39.996), train_loss = 0.72464776, grad/param norm = 2.0612e-01, time/batch = 0.7025s	
22799/28500 (epoch 39.998), train_loss = 0.90243040, grad/param norm = 2.0898e-01, time/batch = 0.6982s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
22800/28500 (epoch 40.000), train_loss = 0.78753471, grad/param norm = 1.8709e-01, time/batch = 0.7023s	
22801/28500 (epoch 40.002), train_loss = 0.97362542, grad/param norm = 2.0423e-01, time/batch = 0.7073s	
22802/28500 (epoch 40.004), train_loss = 0.84536892, grad/param norm = 1.8093e-01, time/batch = 0.7037s	
22803/28500 (epoch 40.005), train_loss = 0.90017291, grad/param norm = 1.9141e-01, time/batch = 0.7019s	
22804/28500 (epoch 40.007), train_loss = 0.72935276, grad/param norm = 1.7028e-01, time/batch = 0.7013s	
22805/28500 (epoch 40.009), train_loss = 0.83665247, grad/param norm = 1.9840e-01, time/batch = 0.7012s	
22806/28500 (epoch 40.011), train_loss = 0.73675183, grad/param norm = 1.6532e-01, time/batch = 0.7027s	
22807/28500 (epoch 40.012), train_loss = 0.76129044, grad/param norm = 1.7560e-01, time/batch = 0.6998s	
22808/28500 (epoch 40.014), train_loss = 0.72397159, grad/param norm = 1.7057e-01, time/batch = 0.7019s	
22809/28500 (epoch 40.016), train_loss = 0.78855217, grad/param norm = 1.7378e-01, time/batch = 0.6999s	
22810/28500 (epoch 40.018), train_loss = 0.85412002, grad/param norm = 1.9677e-01, time/batch = 0.6972s	
22811/28500 (epoch 40.019), train_loss = 0.90624255, grad/param norm = 1.9697e-01, time/batch = 0.7021s	
22812/28500 (epoch 40.021), train_loss = 0.92488201, grad/param norm = 1.7497e-01, time/batch = 0.6985s	
22813/28500 (epoch 40.023), train_loss = 0.83865992, grad/param norm = 1.9508e-01, time/batch = 0.7016s	
22814/28500 (epoch 40.025), train_loss = 0.84640926, grad/param norm = 1.8004e-01, time/batch = 0.6988s	
22815/28500 (epoch 40.026), train_loss = 0.76855856, grad/param norm = 1.8078e-01, time/batch = 0.7023s	
22816/28500 (epoch 40.028), train_loss = 0.83256460, grad/param norm = 2.0015e-01, time/batch = 0.6979s	
22817/28500 (epoch 40.030), train_loss = 0.85725210, grad/param norm = 2.0864e-01, time/batch = 0.7007s	
22818/28500 (epoch 40.032), train_loss = 0.93312087, grad/param norm = 1.8524e-01, time/batch = 0.7002s	
22819/28500 (epoch 40.033), train_loss = 0.96779571, grad/param norm = 2.1469e-01, time/batch = 0.7046s	
22820/28500 (epoch 40.035), train_loss = 0.81364784, grad/param norm = 2.1361e-01, time/batch = 0.6996s	
22821/28500 (epoch 40.037), train_loss = 0.89002920, grad/param norm = 1.7541e-01, time/batch = 0.7046s	
22822/28500 (epoch 40.039), train_loss = 0.93966426, grad/param norm = 2.2686e-01, time/batch = 0.7025s	
22823/28500 (epoch 40.040), train_loss = 0.96115442, grad/param norm = 2.0620e-01, time/batch = 0.6998s	
22824/28500 (epoch 40.042), train_loss = 0.89640824, grad/param norm = 2.0681e-01, time/batch = 0.7009s	
22825/28500 (epoch 40.044), train_loss = 0.83022011, grad/param norm = 2.1867e-01, time/batch = 0.7198s	
22826/28500 (epoch 40.046), train_loss = 1.02529541, grad/param norm = 2.0592e-01, time/batch = 0.7136s	
22827/28500 (epoch 40.047), train_loss = 0.97206401, grad/param norm = 2.5186e-01, time/batch = 0.6978s	
22828/28500 (epoch 40.049), train_loss = 0.84074605, grad/param norm = 2.0071e-01, time/batch = 0.7012s	
22829/28500 (epoch 40.051), train_loss = 0.83627557, grad/param norm = 2.1370e-01, time/batch = 0.7051s	
22830/28500 (epoch 40.053), train_loss = 0.80164690, grad/param norm = 2.0472e-01, time/batch = 0.7009s	
22831/28500 (epoch 40.054), train_loss = 0.89267533, grad/param norm = 1.8109e-01, time/batch = 0.7048s	
22832/28500 (epoch 40.056), train_loss = 0.78237647, grad/param norm = 1.7592e-01, time/batch = 0.6981s	
22833/28500 (epoch 40.058), train_loss = 0.76238611, grad/param norm = 1.7448e-01, time/batch = 0.7006s	
22834/28500 (epoch 40.060), train_loss = 0.89626632, grad/param norm = 1.9077e-01, time/batch = 0.6993s	
22835/28500 (epoch 40.061), train_loss = 0.79911062, grad/param norm = 1.9848e-01, time/batch = 0.7026s	
22836/28500 (epoch 40.063), train_loss = 0.88172602, grad/param norm = 1.9623e-01, time/batch = 0.7003s	
22837/28500 (epoch 40.065), train_loss = 0.83523168, grad/param norm = 1.9646e-01, time/batch = 0.6997s	
22838/28500 (epoch 40.067), train_loss = 0.78565816, grad/param norm = 1.8185e-01, time/batch = 0.6965s	
22839/28500 (epoch 40.068), train_loss = 0.80495292, grad/param norm = 1.7441e-01, time/batch = 0.7044s	
22840/28500 (epoch 40.070), train_loss = 0.85566601, grad/param norm = 1.9955e-01, time/batch = 0.7000s	
22841/28500 (epoch 40.072), train_loss = 0.95801676, grad/param norm = 2.2671e-01, time/batch = 0.7013s	
22842/28500 (epoch 40.074), train_loss = 0.81106251, grad/param norm = 1.7857e-01, time/batch = 0.7006s	
22843/28500 (epoch 40.075), train_loss = 0.81946337, grad/param norm = 1.6509e-01, time/batch = 0.7014s	
22844/28500 (epoch 40.077), train_loss = 0.86436092, grad/param norm = 1.6575e-01, time/batch = 0.7054s	
22845/28500 (epoch 40.079), train_loss = 0.84479926, grad/param norm = 1.8069e-01, time/batch = 0.7018s	
22846/28500 (epoch 40.081), train_loss = 0.90926377, grad/param norm = 2.0195e-01, time/batch = 0.7022s	
22847/28500 (epoch 40.082), train_loss = 0.80340137, grad/param norm = 2.6926e-01, time/batch = 0.6985s	
22848/28500 (epoch 40.084), train_loss = 0.84239192, grad/param norm = 2.1005e-01, time/batch = 0.7014s	
22849/28500 (epoch 40.086), train_loss = 0.79511938, grad/param norm = 2.3791e-01, time/batch = 0.6979s	
22850/28500 (epoch 40.088), train_loss = 0.73948659, grad/param norm = 1.9289e-01, time/batch = 0.6977s	
22851/28500 (epoch 40.089), train_loss = 0.89376962, grad/param norm = 2.0265e-01, time/batch = 0.7033s	
22852/28500 (epoch 40.091), train_loss = 0.74330788, grad/param norm = 1.7528e-01, time/batch = 0.7002s	
22853/28500 (epoch 40.093), train_loss = 0.92054973, grad/param norm = 1.9263e-01, time/batch = 0.7031s	
22854/28500 (epoch 40.095), train_loss = 0.83963368, grad/param norm = 1.8751e-01, time/batch = 0.6989s	
22855/28500 (epoch 40.096), train_loss = 0.92167883, grad/param norm = 1.8789e-01, time/batch = 0.7020s	
22856/28500 (epoch 40.098), train_loss = 0.83422195, grad/param norm = 2.3446e-01, time/batch = 0.6992s	
22857/28500 (epoch 40.100), train_loss = 0.79448794, grad/param norm = 1.6239e-01, time/batch = 0.7005s	
22858/28500 (epoch 40.102), train_loss = 0.92289627, grad/param norm = 2.3847e-01, time/batch = 0.6984s	
22859/28500 (epoch 40.104), train_loss = 0.84980961, grad/param norm = 2.0280e-01, time/batch = 0.6990s	
22860/28500 (epoch 40.105), train_loss = 0.92329731, grad/param norm = 1.8115e-01, time/batch = 0.6978s	
22861/28500 (epoch 40.107), train_loss = 0.75249227, grad/param norm = 1.7580e-01, time/batch = 0.7001s	
22862/28500 (epoch 40.109), train_loss = 0.80950548, grad/param norm = 2.0143e-01, time/batch = 0.7236s	
22863/28500 (epoch 40.111), train_loss = 0.80078729, grad/param norm = 1.8904e-01, time/batch = 0.7014s	
22864/28500 (epoch 40.112), train_loss = 0.90785606, grad/param norm = 1.9380e-01, time/batch = 0.7007s	
22865/28500 (epoch 40.114), train_loss = 0.81624178, grad/param norm = 1.8087e-01, time/batch = 0.6995s	
22866/28500 (epoch 40.116), train_loss = 0.97165095, grad/param norm = 2.1477e-01, time/batch = 0.6984s	
22867/28500 (epoch 40.118), train_loss = 0.73936074, grad/param norm = 1.8145e-01, time/batch = 0.7105s	
22868/28500 (epoch 40.119), train_loss = 0.86377344, grad/param norm = 2.0968e-01, time/batch = 0.7017s	
22869/28500 (epoch 40.121), train_loss = 0.98596277, grad/param norm = 2.3690e-01, time/batch = 0.7015s	
22870/28500 (epoch 40.123), train_loss = 0.93419353, grad/param norm = 1.9185e-01, time/batch = 0.6970s	
22871/28500 (epoch 40.125), train_loss = 0.84620468, grad/param norm = 2.1272e-01, time/batch = 0.7007s	
22872/28500 (epoch 40.126), train_loss = 0.84598830, grad/param norm = 2.0535e-01, time/batch = 0.7003s	
22873/28500 (epoch 40.128), train_loss = 0.82998715, grad/param norm = 1.7444e-01, time/batch = 0.6980s	
22874/28500 (epoch 40.130), train_loss = 0.81001431, grad/param norm = 2.1660e-01, time/batch = 0.7010s	
22875/28500 (epoch 40.132), train_loss = 0.84085966, grad/param norm = 1.9623e-01, time/batch = 0.6976s	
22876/28500 (epoch 40.133), train_loss = 0.91484667, grad/param norm = 2.2597e-01, time/batch = 0.7032s	
22877/28500 (epoch 40.135), train_loss = 0.80690720, grad/param norm = 1.8133e-01, time/batch = 0.6971s	
22878/28500 (epoch 40.137), train_loss = 0.87087932, grad/param norm = 2.0217e-01, time/batch = 0.7025s	
22879/28500 (epoch 40.139), train_loss = 0.84145787, grad/param norm = 1.8105e-01, time/batch = 0.6979s	
22880/28500 (epoch 40.140), train_loss = 0.82475723, grad/param norm = 1.7190e-01, time/batch = 0.7002s	
22881/28500 (epoch 40.142), train_loss = 0.79144269, grad/param norm = 1.9024e-01, time/batch = 0.7010s	
22882/28500 (epoch 40.144), train_loss = 0.74576585, grad/param norm = 1.8339e-01, time/batch = 0.7001s	
22883/28500 (epoch 40.146), train_loss = 0.81733313, grad/param norm = 1.8170e-01, time/batch = 0.6984s	
22884/28500 (epoch 40.147), train_loss = 0.70543956, grad/param norm = 1.7320e-01, time/batch = 0.6980s	
22885/28500 (epoch 40.149), train_loss = 0.71760077, grad/param norm = 1.5689e-01, time/batch = 0.7045s	
22886/28500 (epoch 40.151), train_loss = 0.79470404, grad/param norm = 1.8789e-01, time/batch = 0.6994s	
22887/28500 (epoch 40.153), train_loss = 0.85188664, grad/param norm = 1.8095e-01, time/batch = 0.7029s	
22888/28500 (epoch 40.154), train_loss = 0.71565142, grad/param norm = 1.8025e-01, time/batch = 0.7042s	
22889/28500 (epoch 40.156), train_loss = 0.89227045, grad/param norm = 1.9113e-01, time/batch = 0.6984s	
22890/28500 (epoch 40.158), train_loss = 0.85301243, grad/param norm = 1.9131e-01, time/batch = 0.7018s	
22891/28500 (epoch 40.160), train_loss = 0.74280952, grad/param norm = 1.6907e-01, time/batch = 0.7008s	
22892/28500 (epoch 40.161), train_loss = 0.77083764, grad/param norm = 2.0949e-01, time/batch = 0.6994s	
22893/28500 (epoch 40.163), train_loss = 0.72499548, grad/param norm = 1.8403e-01, time/batch = 0.7000s	
22894/28500 (epoch 40.165), train_loss = 0.98140725, grad/param norm = 1.8318e-01, time/batch = 0.7041s	
22895/28500 (epoch 40.167), train_loss = 0.98259469, grad/param norm = 2.1774e-01, time/batch = 0.7061s	
22896/28500 (epoch 40.168), train_loss = 0.93119050, grad/param norm = 2.0653e-01, time/batch = 0.7032s	
22897/28500 (epoch 40.170), train_loss = 0.92807026, grad/param norm = 2.3540e-01, time/batch = 0.6999s	
22898/28500 (epoch 40.172), train_loss = 0.80354115, grad/param norm = 1.7033e-01, time/batch = 0.6997s	
22899/28500 (epoch 40.174), train_loss = 0.98842257, grad/param norm = 2.3720e-01, time/batch = 0.7022s	
22900/28500 (epoch 40.175), train_loss = 0.82605239, grad/param norm = 1.7619e-01, time/batch = 0.7050s	
22901/28500 (epoch 40.177), train_loss = 0.86063364, grad/param norm = 2.1201e-01, time/batch = 0.7165s	
22902/28500 (epoch 40.179), train_loss = 0.92158471, grad/param norm = 2.0801e-01, time/batch = 0.7086s	
22903/28500 (epoch 40.181), train_loss = 0.85902495, grad/param norm = 1.9721e-01, time/batch = 0.7048s	
22904/28500 (epoch 40.182), train_loss = 0.80714659, grad/param norm = 2.0282e-01, time/batch = 0.7071s	
22905/28500 (epoch 40.184), train_loss = 1.00267466, grad/param norm = 2.1999e-01, time/batch = 0.7027s	
22906/28500 (epoch 40.186), train_loss = 0.96680941, grad/param norm = 2.1342e-01, time/batch = 0.7062s	
22907/28500 (epoch 40.188), train_loss = 0.89180497, grad/param norm = 2.6796e-01, time/batch = 0.7002s	
22908/28500 (epoch 40.189), train_loss = 0.83926193, grad/param norm = 1.6389e-01, time/batch = 0.7015s	
22909/28500 (epoch 40.191), train_loss = 1.01308580, grad/param norm = 2.0132e-01, time/batch = 0.7037s	
22910/28500 (epoch 40.193), train_loss = 0.85275090, grad/param norm = 2.3470e-01, time/batch = 0.7015s	
22911/28500 (epoch 40.195), train_loss = 0.97901029, grad/param norm = 2.2389e-01, time/batch = 0.7055s	
22912/28500 (epoch 40.196), train_loss = 0.88558343, grad/param norm = 1.9909e-01, time/batch = 0.6984s	
22913/28500 (epoch 40.198), train_loss = 0.84289636, grad/param norm = 1.7966e-01, time/batch = 0.6987s	
22914/28500 (epoch 40.200), train_loss = 0.92161438, grad/param norm = 1.8939e-01, time/batch = 0.6982s	
22915/28500 (epoch 40.202), train_loss = 0.87506562, grad/param norm = 1.9375e-01, time/batch = 0.6983s	
22916/28500 (epoch 40.204), train_loss = 0.83558222, grad/param norm = 1.6994e-01, time/batch = 0.6978s	
22917/28500 (epoch 40.205), train_loss = 0.79560627, grad/param norm = 2.0455e-01, time/batch = 0.6999s	
22918/28500 (epoch 40.207), train_loss = 0.71214265, grad/param norm = 1.7365e-01, time/batch = 0.6983s	
22919/28500 (epoch 40.209), train_loss = 0.87170903, grad/param norm = 1.9283e-01, time/batch = 0.7002s	
22920/28500 (epoch 40.211), train_loss = 0.76488798, grad/param norm = 1.8483e-01, time/batch = 0.6998s	
22921/28500 (epoch 40.212), train_loss = 0.70868539, grad/param norm = 1.8931e-01, time/batch = 0.7110s	
22922/28500 (epoch 40.214), train_loss = 0.84382008, grad/param norm = 2.2466e-01, time/batch = 0.7120s	
22923/28500 (epoch 40.216), train_loss = 0.76598270, grad/param norm = 1.8332e-01, time/batch = 0.7043s	
22924/28500 (epoch 40.218), train_loss = 0.94783076, grad/param norm = 1.8751e-01, time/batch = 0.7003s	
22925/28500 (epoch 40.219), train_loss = 0.86815826, grad/param norm = 1.9753e-01, time/batch = 0.6988s	
22926/28500 (epoch 40.221), train_loss = 0.72414601, grad/param norm = 1.7448e-01, time/batch = 0.7005s	
22927/28500 (epoch 40.223), train_loss = 0.93211010, grad/param norm = 2.0167e-01, time/batch = 0.7005s	
22928/28500 (epoch 40.225), train_loss = 0.97836680, grad/param norm = 2.1514e-01, time/batch = 0.7039s	
22929/28500 (epoch 40.226), train_loss = 0.81309669, grad/param norm = 1.9217e-01, time/batch = 0.7025s	
22930/28500 (epoch 40.228), train_loss = 0.93081510, grad/param norm = 1.9379e-01, time/batch = 0.7006s	
22931/28500 (epoch 40.230), train_loss = 0.91377820, grad/param norm = 2.1361e-01, time/batch = 0.7122s	
22932/28500 (epoch 40.232), train_loss = 0.90088287, grad/param norm = 1.9419e-01, time/batch = 0.6995s	
22933/28500 (epoch 40.233), train_loss = 0.84126665, grad/param norm = 1.9411e-01, time/batch = 0.6986s	
22934/28500 (epoch 40.235), train_loss = 0.82848728, grad/param norm = 1.6115e-01, time/batch = 0.7018s	
22935/28500 (epoch 40.237), train_loss = 0.75163831, grad/param norm = 1.6698e-01, time/batch = 0.7003s	
22936/28500 (epoch 40.239), train_loss = 0.80335390, grad/param norm = 1.7823e-01, time/batch = 0.7015s	
22937/28500 (epoch 40.240), train_loss = 0.73879703, grad/param norm = 1.7399e-01, time/batch = 0.6999s	
22938/28500 (epoch 40.242), train_loss = 0.77749643, grad/param norm = 1.8675e-01, time/batch = 0.7016s	
22939/28500 (epoch 40.244), train_loss = 0.86452812, grad/param norm = 1.7293e-01, time/batch = 0.6997s	
22940/28500 (epoch 40.246), train_loss = 0.88034439, grad/param norm = 1.8625e-01, time/batch = 0.6990s	
22941/28500 (epoch 40.247), train_loss = 0.97632876, grad/param norm = 2.4551e-01, time/batch = 0.7035s	
22942/28500 (epoch 40.249), train_loss = 0.82993126, grad/param norm = 1.7503e-01, time/batch = 0.6988s	
22943/28500 (epoch 40.251), train_loss = 0.84106808, grad/param norm = 1.8327e-01, time/batch = 0.6983s	
22944/28500 (epoch 40.253), train_loss = 0.98234556, grad/param norm = 2.2808e-01, time/batch = 0.6988s	
22945/28500 (epoch 40.254), train_loss = 0.99393558, grad/param norm = 1.8780e-01, time/batch = 0.6975s	
22946/28500 (epoch 40.256), train_loss = 0.83004950, grad/param norm = 2.0711e-01, time/batch = 0.6996s	
22947/28500 (epoch 40.258), train_loss = 0.82892931, grad/param norm = 2.0592e-01, time/batch = 0.6998s	
22948/28500 (epoch 40.260), train_loss = 0.83329794, grad/param norm = 1.7428e-01, time/batch = 0.6988s	
22949/28500 (epoch 40.261), train_loss = 0.73996826, grad/param norm = 2.1014e-01, time/batch = 0.6977s	
22950/28500 (epoch 40.263), train_loss = 0.91508367, grad/param norm = 2.1674e-01, time/batch = 0.6984s	
22951/28500 (epoch 40.265), train_loss = 0.78635104, grad/param norm = 1.9142e-01, time/batch = 0.7017s	
22952/28500 (epoch 40.267), train_loss = 0.99884992, grad/param norm = 2.0463e-01, time/batch = 0.7019s	
22953/28500 (epoch 40.268), train_loss = 0.87340854, grad/param norm = 1.7444e-01, time/batch = 0.7002s	
22954/28500 (epoch 40.270), train_loss = 0.82960098, grad/param norm = 2.0350e-01, time/batch = 0.6983s	
22955/28500 (epoch 40.272), train_loss = 0.84620350, grad/param norm = 1.9021e-01, time/batch = 0.6994s	
22956/28500 (epoch 40.274), train_loss = 0.89126494, grad/param norm = 1.8676e-01, time/batch = 0.6950s	
22957/28500 (epoch 40.275), train_loss = 0.91035370, grad/param norm = 2.0453e-01, time/batch = 0.6938s	
22958/28500 (epoch 40.277), train_loss = 0.83737135, grad/param norm = 2.1442e-01, time/batch = 0.6962s	
22959/28500 (epoch 40.279), train_loss = 0.88297939, grad/param norm = 2.1862e-01, time/batch = 0.7121s	
22960/28500 (epoch 40.281), train_loss = 0.90586762, grad/param norm = 2.7109e-01, time/batch = 0.6971s	
22961/28500 (epoch 40.282), train_loss = 0.84158842, grad/param norm = 1.6648e-01, time/batch = 0.7021s	
22962/28500 (epoch 40.284), train_loss = 0.87919032, grad/param norm = 2.3026e-01, time/batch = 0.6985s	
22963/28500 (epoch 40.286), train_loss = 0.93490262, grad/param norm = 2.0382e-01, time/batch = 0.6959s	
22964/28500 (epoch 40.288), train_loss = 0.83610808, grad/param norm = 1.8498e-01, time/batch = 0.6962s	
22965/28500 (epoch 40.289), train_loss = 0.86613679, grad/param norm = 1.9606e-01, time/batch = 0.6976s	
22966/28500 (epoch 40.291), train_loss = 0.86311086, grad/param norm = 1.8892e-01, time/batch = 0.6939s	
22967/28500 (epoch 40.293), train_loss = 0.86552010, grad/param norm = 1.8608e-01, time/batch = 0.6948s	
22968/28500 (epoch 40.295), train_loss = 0.75232499, grad/param norm = 2.1498e-01, time/batch = 0.7023s	
22969/28500 (epoch 40.296), train_loss = 0.73684387, grad/param norm = 1.7167e-01, time/batch = 0.7026s	
22970/28500 (epoch 40.298), train_loss = 0.90584197, grad/param norm = 1.9613e-01, time/batch = 0.6944s	
22971/28500 (epoch 40.300), train_loss = 0.77000810, grad/param norm = 1.8942e-01, time/batch = 0.6963s	
22972/28500 (epoch 40.302), train_loss = 0.71224002, grad/param norm = 1.7222e-01, time/batch = 0.6944s	
22973/28500 (epoch 40.304), train_loss = 0.83444661, grad/param norm = 1.9716e-01, time/batch = 0.6946s	
22974/28500 (epoch 40.305), train_loss = 0.88142786, grad/param norm = 1.9219e-01, time/batch = 0.6952s	
22975/28500 (epoch 40.307), train_loss = 0.81191231, grad/param norm = 1.8795e-01, time/batch = 0.6967s	
22976/28500 (epoch 40.309), train_loss = 0.82538206, grad/param norm = 1.7295e-01, time/batch = 0.6948s	
22977/28500 (epoch 40.311), train_loss = 0.88032524, grad/param norm = 1.8467e-01, time/batch = 0.6932s	
22978/28500 (epoch 40.312), train_loss = 0.87834503, grad/param norm = 1.7554e-01, time/batch = 0.7086s	
22979/28500 (epoch 40.314), train_loss = 0.87028537, grad/param norm = 1.9703e-01, time/batch = 0.7079s	
22980/28500 (epoch 40.316), train_loss = 0.86672256, grad/param norm = 2.1170e-01, time/batch = 0.6957s	
22981/28500 (epoch 40.318), train_loss = 0.93055277, grad/param norm = 1.8145e-01, time/batch = 0.7009s	
22982/28500 (epoch 40.319), train_loss = 0.78237938, grad/param norm = 1.8250e-01, time/batch = 0.6948s	
22983/28500 (epoch 40.321), train_loss = 0.81438348, grad/param norm = 2.3263e-01, time/batch = 0.6940s	
22984/28500 (epoch 40.323), train_loss = 0.84016721, grad/param norm = 1.9903e-01, time/batch = 0.6940s	
22985/28500 (epoch 40.325), train_loss = 0.95754759, grad/param norm = 2.0535e-01, time/batch = 0.6948s	
22986/28500 (epoch 40.326), train_loss = 0.86390064, grad/param norm = 2.0530e-01, time/batch = 0.6955s	
22987/28500 (epoch 40.328), train_loss = 0.67872586, grad/param norm = 1.7946e-01, time/batch = 0.6955s	
22988/28500 (epoch 40.330), train_loss = 0.76952869, grad/param norm = 1.6320e-01, time/batch = 0.6943s	
22989/28500 (epoch 40.332), train_loss = 0.80835244, grad/param norm = 2.1221e-01, time/batch = 0.6949s	
22990/28500 (epoch 40.333), train_loss = 0.66325616, grad/param norm = 1.9227e-01, time/batch = 0.6947s	
22991/28500 (epoch 40.335), train_loss = 0.73767420, grad/param norm = 1.8525e-01, time/batch = 0.6965s	
22992/28500 (epoch 40.337), train_loss = 0.68771214, grad/param norm = 1.7907e-01, time/batch = 0.6942s	
22993/28500 (epoch 40.339), train_loss = 0.68443395, grad/param norm = 1.5564e-01, time/batch = 0.6941s	
22994/28500 (epoch 40.340), train_loss = 0.81671774, grad/param norm = 1.9176e-01, time/batch = 0.7017s	
22995/28500 (epoch 40.342), train_loss = 0.81449384, grad/param norm = 1.8141e-01, time/batch = 0.7130s	
22996/28500 (epoch 40.344), train_loss = 0.71239856, grad/param norm = 1.7328e-01, time/batch = 0.6966s	
22997/28500 (epoch 40.346), train_loss = 0.68707753, grad/param norm = 1.4774e-01, time/batch = 0.7109s	
22998/28500 (epoch 40.347), train_loss = 0.83030927, grad/param norm = 1.7785e-01, time/batch = 0.7022s	
22999/28500 (epoch 40.349), train_loss = 0.83316161, grad/param norm = 1.8053e-01, time/batch = 0.6942s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch40.35_1.9707.t7	
23000/28500 (epoch 40.351), train_loss = 0.73492859, grad/param norm = 1.7894e-01, time/batch = 0.6952s	
23001/28500 (epoch 40.353), train_loss = 1.36798624, grad/param norm = 3.0119e-01, time/batch = 0.7055s	
23002/28500 (epoch 40.354), train_loss = 0.74291064, grad/param norm = 2.0726e-01, time/batch = 0.6982s	
23003/28500 (epoch 40.356), train_loss = 0.79058151, grad/param norm = 1.7112e-01, time/batch = 0.6952s	
23004/28500 (epoch 40.358), train_loss = 0.86827402, grad/param norm = 1.7297e-01, time/batch = 0.6950s	
23005/28500 (epoch 40.360), train_loss = 0.84342097, grad/param norm = 1.9869e-01, time/batch = 0.6958s	
23006/28500 (epoch 40.361), train_loss = 0.74720096, grad/param norm = 1.7139e-01, time/batch = 0.7067s	
23007/28500 (epoch 40.363), train_loss = 0.72999203, grad/param norm = 1.5439e-01, time/batch = 0.7043s	
23008/28500 (epoch 40.365), train_loss = 0.77859684, grad/param norm = 1.9192e-01, time/batch = 0.7017s	
23009/28500 (epoch 40.367), train_loss = 0.83016589, grad/param norm = 1.8442e-01, time/batch = 0.6983s	
23010/28500 (epoch 40.368), train_loss = 0.76652114, grad/param norm = 1.8819e-01, time/batch = 0.6985s	
23011/28500 (epoch 40.370), train_loss = 0.84001879, grad/param norm = 1.8899e-01, time/batch = 0.6995s	
23012/28500 (epoch 40.372), train_loss = 0.67096166, grad/param norm = 1.7613e-01, time/batch = 0.7021s	
23013/28500 (epoch 40.374), train_loss = 0.78497121, grad/param norm = 1.8895e-01, time/batch = 0.6980s	
23014/28500 (epoch 40.375), train_loss = 0.91564135, grad/param norm = 2.1199e-01, time/batch = 0.6954s	
23015/28500 (epoch 40.377), train_loss = 0.76192487, grad/param norm = 2.2585e-01, time/batch = 0.6955s	
23016/28500 (epoch 40.379), train_loss = 0.63473467, grad/param norm = 1.6308e-01, time/batch = 0.6939s	
23017/28500 (epoch 40.381), train_loss = 0.79795286, grad/param norm = 1.7408e-01, time/batch = 0.6938s	
23018/28500 (epoch 40.382), train_loss = 0.77680346, grad/param norm = 1.8964e-01, time/batch = 0.6934s	
23019/28500 (epoch 40.384), train_loss = 0.69522518, grad/param norm = 1.7623e-01, time/batch = 0.6935s	
23020/28500 (epoch 40.386), train_loss = 0.74446078, grad/param norm = 1.8130e-01, time/batch = 0.6951s	
23021/28500 (epoch 40.388), train_loss = 0.89712884, grad/param norm = 2.0654e-01, time/batch = 0.6974s	
23022/28500 (epoch 40.389), train_loss = 0.75061430, grad/param norm = 1.8866e-01, time/batch = 0.6948s	
23023/28500 (epoch 40.391), train_loss = 0.73055498, grad/param norm = 2.4523e-01, time/batch = 0.6947s	
23024/28500 (epoch 40.393), train_loss = 0.73132243, grad/param norm = 1.8492e-01, time/batch = 0.6940s	
23025/28500 (epoch 40.395), train_loss = 0.91979541, grad/param norm = 1.9389e-01, time/batch = 0.6959s	
23026/28500 (epoch 40.396), train_loss = 0.87771694, grad/param norm = 1.9688e-01, time/batch = 0.6940s	
23027/28500 (epoch 40.398), train_loss = 0.61868813, grad/param norm = 1.9509e-01, time/batch = 0.6944s	
23028/28500 (epoch 40.400), train_loss = 0.77194968, grad/param norm = 1.9342e-01, time/batch = 0.6937s	
23029/28500 (epoch 40.402), train_loss = 0.82444437, grad/param norm = 1.8559e-01, time/batch = 0.6938s	
23030/28500 (epoch 40.404), train_loss = 0.81070500, grad/param norm = 1.8791e-01, time/batch = 0.6957s	
23031/28500 (epoch 40.405), train_loss = 0.87532280, grad/param norm = 1.8180e-01, time/batch = 0.6983s	
23032/28500 (epoch 40.407), train_loss = 0.83533214, grad/param norm = 1.7709e-01, time/batch = 0.6957s	
23033/28500 (epoch 40.409), train_loss = 0.81248834, grad/param norm = 1.8838e-01, time/batch = 0.7005s	
23034/28500 (epoch 40.411), train_loss = 0.91427293, grad/param norm = 2.3720e-01, time/batch = 0.6998s	
23035/28500 (epoch 40.412), train_loss = 0.92341740, grad/param norm = 2.2243e-01, time/batch = 0.6957s	
23036/28500 (epoch 40.414), train_loss = 0.84045218, grad/param norm = 2.1170e-01, time/batch = 0.6945s	
23037/28500 (epoch 40.416), train_loss = 0.75014589, grad/param norm = 2.0373e-01, time/batch = 0.7113s	
23038/28500 (epoch 40.418), train_loss = 0.83493652, grad/param norm = 1.7711e-01, time/batch = 0.7046s	
23039/28500 (epoch 40.419), train_loss = 0.94036892, grad/param norm = 2.5416e-01, time/batch = 0.6955s	
23040/28500 (epoch 40.421), train_loss = 0.89154176, grad/param norm = 1.9602e-01, time/batch = 0.6955s	
23041/28500 (epoch 40.423), train_loss = 0.88806471, grad/param norm = 2.0628e-01, time/batch = 0.7062s	
23042/28500 (epoch 40.425), train_loss = 0.83726955, grad/param norm = 2.3885e-01, time/batch = 0.6959s	
23043/28500 (epoch 40.426), train_loss = 0.84969328, grad/param norm = 2.0764e-01, time/batch = 0.6954s	
23044/28500 (epoch 40.428), train_loss = 0.98217684, grad/param norm = 2.1046e-01, time/batch = 0.6952s	
23045/28500 (epoch 40.430), train_loss = 0.95867450, grad/param norm = 1.8151e-01, time/batch = 0.6984s	
23046/28500 (epoch 40.432), train_loss = 0.83035159, grad/param norm = 1.9032e-01, time/batch = 0.6977s	
23047/28500 (epoch 40.433), train_loss = 0.90071247, grad/param norm = 2.3446e-01, time/batch = 0.6942s	
23048/28500 (epoch 40.435), train_loss = 0.85168239, grad/param norm = 1.8873e-01, time/batch = 0.6957s	
23049/28500 (epoch 40.437), train_loss = 0.78130159, grad/param norm = 1.7734e-01, time/batch = 0.6955s	
23050/28500 (epoch 40.439), train_loss = 0.83226268, grad/param norm = 1.8002e-01, time/batch = 0.6989s	
23051/28500 (epoch 40.440), train_loss = 0.98060605, grad/param norm = 2.0402e-01, time/batch = 0.7049s	
23052/28500 (epoch 40.442), train_loss = 0.76957229, grad/param norm = 2.0410e-01, time/batch = 0.7027s	
23053/28500 (epoch 40.444), train_loss = 0.73839349, grad/param norm = 1.6812e-01, time/batch = 0.7200s	
23054/28500 (epoch 40.446), train_loss = 0.71291972, grad/param norm = 1.6618e-01, time/batch = 0.7218s	
23055/28500 (epoch 40.447), train_loss = 0.72800303, grad/param norm = 2.0465e-01, time/batch = 0.7031s	
23056/28500 (epoch 40.449), train_loss = 0.78193839, grad/param norm = 1.8253e-01, time/batch = 0.7067s	
23057/28500 (epoch 40.451), train_loss = 0.79389441, grad/param norm = 1.7388e-01, time/batch = 0.6967s	
23058/28500 (epoch 40.453), train_loss = 0.78363960, grad/param norm = 1.8376e-01, time/batch = 0.6996s	
23059/28500 (epoch 40.454), train_loss = 0.74391332, grad/param norm = 1.5663e-01, time/batch = 0.6982s	
23060/28500 (epoch 40.456), train_loss = 0.89278570, grad/param norm = 2.0312e-01, time/batch = 0.7095s	
23061/28500 (epoch 40.458), train_loss = 0.79221155, grad/param norm = 1.8608e-01, time/batch = 0.7211s	
23062/28500 (epoch 40.460), train_loss = 0.90515401, grad/param norm = 1.7634e-01, time/batch = 0.7030s	
23063/28500 (epoch 40.461), train_loss = 0.74508528, grad/param norm = 1.7767e-01, time/batch = 0.7124s	
23064/28500 (epoch 40.463), train_loss = 0.68152920, grad/param norm = 1.5216e-01, time/batch = 0.6952s	
23065/28500 (epoch 40.465), train_loss = 0.66668030, grad/param norm = 1.8803e-01, time/batch = 0.6963s	
23066/28500 (epoch 40.467), train_loss = 0.82041650, grad/param norm = 1.7840e-01, time/batch = 0.6986s	
23067/28500 (epoch 40.468), train_loss = 0.72579358, grad/param norm = 1.5129e-01, time/batch = 0.6956s	
23068/28500 (epoch 40.470), train_loss = 0.78001372, grad/param norm = 1.9820e-01, time/batch = 0.6963s	
23069/28500 (epoch 40.472), train_loss = 0.72242891, grad/param norm = 1.4973e-01, time/batch = 0.6953s	
23070/28500 (epoch 40.474), train_loss = 0.95673281, grad/param norm = 2.0443e-01, time/batch = 0.6963s	
23071/28500 (epoch 40.475), train_loss = 0.76328294, grad/param norm = 1.6998e-01, time/batch = 0.7042s	
23072/28500 (epoch 40.477), train_loss = 0.80302380, grad/param norm = 1.9688e-01, time/batch = 0.7100s	
23073/28500 (epoch 40.479), train_loss = 0.85135132, grad/param norm = 1.8183e-01, time/batch = 0.7253s	
23074/28500 (epoch 40.481), train_loss = 0.86944856, grad/param norm = 1.8146e-01, time/batch = 0.7110s	
23075/28500 (epoch 40.482), train_loss = 0.71731551, grad/param norm = 1.8388e-01, time/batch = 0.6948s	
23076/28500 (epoch 40.484), train_loss = 0.75594188, grad/param norm = 1.8358e-01, time/batch = 0.6978s	
23077/28500 (epoch 40.486), train_loss = 0.65293796, grad/param norm = 1.6996e-01, time/batch = 0.6958s	
23078/28500 (epoch 40.488), train_loss = 0.86949735, grad/param norm = 1.9091e-01, time/batch = 0.6985s	
23079/28500 (epoch 40.489), train_loss = 0.94969639, grad/param norm = 1.8749e-01, time/batch = 0.6959s	
23080/28500 (epoch 40.491), train_loss = 0.75491321, grad/param norm = 1.9514e-01, time/batch = 0.6969s	
23081/28500 (epoch 40.493), train_loss = 0.79680558, grad/param norm = 1.7060e-01, time/batch = 0.6968s	
23082/28500 (epoch 40.495), train_loss = 0.82618508, grad/param norm = 1.9768e-01, time/batch = 0.7206s	
23083/28500 (epoch 40.496), train_loss = 0.75020315, grad/param norm = 2.3425e-01, time/batch = 0.7004s	
23084/28500 (epoch 40.498), train_loss = 0.78414186, grad/param norm = 1.5734e-01, time/batch = 0.6995s	
23085/28500 (epoch 40.500), train_loss = 0.76175885, grad/param norm = 1.7474e-01, time/batch = 0.7003s	
23086/28500 (epoch 40.502), train_loss = 0.85804459, grad/param norm = 1.7468e-01, time/batch = 0.6986s	
23087/28500 (epoch 40.504), train_loss = 0.88336268, grad/param norm = 1.7680e-01, time/batch = 0.7033s	
23088/28500 (epoch 40.505), train_loss = 0.76420425, grad/param norm = 1.8947e-01, time/batch = 0.6980s	
23089/28500 (epoch 40.507), train_loss = 0.89458912, grad/param norm = 2.0173e-01, time/batch = 0.6986s	
23090/28500 (epoch 40.509), train_loss = 0.80421558, grad/param norm = 1.7064e-01, time/batch = 0.7039s	
23091/28500 (epoch 40.511), train_loss = 0.79674438, grad/param norm = 1.6847e-01, time/batch = 0.7031s	
23092/28500 (epoch 40.512), train_loss = 0.85555455, grad/param norm = 1.8898e-01, time/batch = 0.6988s	
23093/28500 (epoch 40.514), train_loss = 0.80964553, grad/param norm = 1.8069e-01, time/batch = 0.6993s	
23094/28500 (epoch 40.516), train_loss = 0.80107920, grad/param norm = 1.4525e-01, time/batch = 0.6952s	
23095/28500 (epoch 40.518), train_loss = 0.85260317, grad/param norm = 1.9889e-01, time/batch = 0.6933s	
23096/28500 (epoch 40.519), train_loss = 0.84439221, grad/param norm = 1.7570e-01, time/batch = 0.6934s	
23097/28500 (epoch 40.521), train_loss = 0.94951239, grad/param norm = 3.3916e-01, time/batch = 0.6945s	
23098/28500 (epoch 40.523), train_loss = 0.85798954, grad/param norm = 2.0018e-01, time/batch = 0.6936s	
23099/28500 (epoch 40.525), train_loss = 0.93438709, grad/param norm = 1.7991e-01, time/batch = 0.6936s	
23100/28500 (epoch 40.526), train_loss = 0.87447305, grad/param norm = 1.9645e-01, time/batch = 0.6938s	
23101/28500 (epoch 40.528), train_loss = 0.85719258, grad/param norm = 2.0413e-01, time/batch = 0.6978s	
23102/28500 (epoch 40.530), train_loss = 0.87292297, grad/param norm = 1.9440e-01, time/batch = 0.6986s	
23103/28500 (epoch 40.532), train_loss = 0.80243838, grad/param norm = 1.8954e-01, time/batch = 0.6944s	
23104/28500 (epoch 40.533), train_loss = 0.85004225, grad/param norm = 1.6964e-01, time/batch = 0.6961s	
23105/28500 (epoch 40.535), train_loss = 0.72183289, grad/param norm = 1.6322e-01, time/batch = 0.6947s	
23106/28500 (epoch 40.537), train_loss = 0.71865922, grad/param norm = 1.9994e-01, time/batch = 0.6941s	
23107/28500 (epoch 40.539), train_loss = 0.70690481, grad/param norm = 1.8483e-01, time/batch = 0.6932s	
23108/28500 (epoch 40.540), train_loss = 0.79987235, grad/param norm = 1.6821e-01, time/batch = 0.6937s	
23109/28500 (epoch 40.542), train_loss = 0.85782258, grad/param norm = 2.2334e-01, time/batch = 0.6945s	
23110/28500 (epoch 40.544), train_loss = 0.94879748, grad/param norm = 2.0394e-01, time/batch = 0.6953s	
23111/28500 (epoch 40.546), train_loss = 0.80905620, grad/param norm = 1.8230e-01, time/batch = 0.7005s	
23112/28500 (epoch 40.547), train_loss = 0.81139682, grad/param norm = 1.8915e-01, time/batch = 0.6954s	
23113/28500 (epoch 40.549), train_loss = 0.69222662, grad/param norm = 1.5925e-01, time/batch = 0.6994s	
23114/28500 (epoch 40.551), train_loss = 0.76634708, grad/param norm = 2.1556e-01, time/batch = 0.7054s	
23115/28500 (epoch 40.553), train_loss = 0.95858356, grad/param norm = 2.4539e-01, time/batch = 0.7020s	
23116/28500 (epoch 40.554), train_loss = 0.86349080, grad/param norm = 2.0328e-01, time/batch = 0.6985s	
23117/28500 (epoch 40.556), train_loss = 0.86380417, grad/param norm = 1.8965e-01, time/batch = 0.6957s	
23118/28500 (epoch 40.558), train_loss = 0.88288023, grad/param norm = 1.8063e-01, time/batch = 0.6968s	
23119/28500 (epoch 40.560), train_loss = 0.87415152, grad/param norm = 1.8939e-01, time/batch = 0.7032s	
23120/28500 (epoch 40.561), train_loss = 0.87542814, grad/param norm = 1.9635e-01, time/batch = 0.6948s	
23121/28500 (epoch 40.563), train_loss = 0.95842521, grad/param norm = 2.1201e-01, time/batch = 0.7004s	
23122/28500 (epoch 40.565), train_loss = 0.75674718, grad/param norm = 1.8949e-01, time/batch = 0.6952s	
23123/28500 (epoch 40.567), train_loss = 0.70405361, grad/param norm = 1.7601e-01, time/batch = 0.6947s	
23124/28500 (epoch 40.568), train_loss = 0.85084803, grad/param norm = 2.2112e-01, time/batch = 0.6939s	
23125/28500 (epoch 40.570), train_loss = 0.79991078, grad/param norm = 2.1289e-01, time/batch = 0.6973s	
23126/28500 (epoch 40.572), train_loss = 0.84199556, grad/param norm = 1.7862e-01, time/batch = 0.6977s	
23127/28500 (epoch 40.574), train_loss = 0.78342965, grad/param norm = 1.7637e-01, time/batch = 0.6930s	
23128/28500 (epoch 40.575), train_loss = 0.77522788, grad/param norm = 1.8000e-01, time/batch = 0.6940s	
23129/28500 (epoch 40.577), train_loss = 0.89122203, grad/param norm = 1.8768e-01, time/batch = 0.6940s	
23130/28500 (epoch 40.579), train_loss = 0.90202606, grad/param norm = 2.0337e-01, time/batch = 0.6942s	
23131/28500 (epoch 40.581), train_loss = 0.77649718, grad/param norm = 2.1021e-01, time/batch = 0.7026s	
23132/28500 (epoch 40.582), train_loss = 0.95393556, grad/param norm = 2.3609e-01, time/batch = 0.7013s	
23133/28500 (epoch 40.584), train_loss = 0.76251122, grad/param norm = 1.8778e-01, time/batch = 0.6942s	
23134/28500 (epoch 40.586), train_loss = 0.74396266, grad/param norm = 1.6613e-01, time/batch = 0.6946s	
23135/28500 (epoch 40.588), train_loss = 0.76475919, grad/param norm = 1.6982e-01, time/batch = 0.6993s	
23136/28500 (epoch 40.589), train_loss = 0.80460625, grad/param norm = 1.9969e-01, time/batch = 0.7030s	
23137/28500 (epoch 40.591), train_loss = 0.81994307, grad/param norm = 1.7403e-01, time/batch = 0.6988s	
23138/28500 (epoch 40.593), train_loss = 0.78460446, grad/param norm = 1.9559e-01, time/batch = 0.7010s	
23139/28500 (epoch 40.595), train_loss = 0.97990509, grad/param norm = 2.0958e-01, time/batch = 0.6982s	
23140/28500 (epoch 40.596), train_loss = 0.99503631, grad/param norm = 2.1137e-01, time/batch = 0.7031s	
23141/28500 (epoch 40.598), train_loss = 0.80251178, grad/param norm = 1.7540e-01, time/batch = 0.7002s	
23142/28500 (epoch 40.600), train_loss = 0.79104367, grad/param norm = 1.8155e-01, time/batch = 0.6989s	
23143/28500 (epoch 40.602), train_loss = 0.88323367, grad/param norm = 2.0488e-01, time/batch = 0.6948s	
23144/28500 (epoch 40.604), train_loss = 0.90114219, grad/param norm = 1.7847e-01, time/batch = 0.6974s	
23145/28500 (epoch 40.605), train_loss = 0.89803138, grad/param norm = 2.1188e-01, time/batch = 0.6966s	
23146/28500 (epoch 40.607), train_loss = 0.93625559, grad/param norm = 1.8198e-01, time/batch = 0.6967s	
23147/28500 (epoch 40.609), train_loss = 0.85518594, grad/param norm = 2.4569e-01, time/batch = 0.6957s	
23148/28500 (epoch 40.611), train_loss = 0.81436307, grad/param norm = 1.9402e-01, time/batch = 0.6942s	
23149/28500 (epoch 40.612), train_loss = 0.87828065, grad/param norm = 2.0738e-01, time/batch = 0.6939s	
23150/28500 (epoch 40.614), train_loss = 0.92979412, grad/param norm = 1.9965e-01, time/batch = 0.6935s	
23151/28500 (epoch 40.616), train_loss = 0.77856697, grad/param norm = 1.9527e-01, time/batch = 0.6969s	
23152/28500 (epoch 40.618), train_loss = 0.81521090, grad/param norm = 1.9050e-01, time/batch = 0.6949s	
23153/28500 (epoch 40.619), train_loss = 0.91272715, grad/param norm = 2.6072e-01, time/batch = 0.6939s	
23154/28500 (epoch 40.621), train_loss = 0.67398494, grad/param norm = 1.9341e-01, time/batch = 0.6977s	
23155/28500 (epoch 40.623), train_loss = 0.94341023, grad/param norm = 2.0185e-01, time/batch = 0.6947s	
23156/28500 (epoch 40.625), train_loss = 0.75083288, grad/param norm = 1.8248e-01, time/batch = 0.6944s	
23157/28500 (epoch 40.626), train_loss = 0.66428865, grad/param norm = 1.5739e-01, time/batch = 0.6955s	
23158/28500 (epoch 40.628), train_loss = 0.76081153, grad/param norm = 1.8922e-01, time/batch = 0.7037s	
23159/28500 (epoch 40.630), train_loss = 0.72232640, grad/param norm = 1.7859e-01, time/batch = 0.7136s	
23160/28500 (epoch 40.632), train_loss = 0.91669118, grad/param norm = 2.3672e-01, time/batch = 0.6910s	
23161/28500 (epoch 40.633), train_loss = 0.95760440, grad/param norm = 1.7926e-01, time/batch = 0.6927s	
23162/28500 (epoch 40.635), train_loss = 0.86093899, grad/param norm = 2.0437e-01, time/batch = 0.6939s	
23163/28500 (epoch 40.637), train_loss = 0.84210601, grad/param norm = 1.7329e-01, time/batch = 0.6948s	
23164/28500 (epoch 40.639), train_loss = 0.74756196, grad/param norm = 1.9627e-01, time/batch = 0.6948s	
23165/28500 (epoch 40.640), train_loss = 0.78543089, grad/param norm = 1.8606e-01, time/batch = 0.6930s	
23166/28500 (epoch 40.642), train_loss = 0.79961987, grad/param norm = 1.9217e-01, time/batch = 0.6956s	
23167/28500 (epoch 40.644), train_loss = 0.85395887, grad/param norm = 1.8643e-01, time/batch = 0.6946s	
23168/28500 (epoch 40.646), train_loss = 0.69297743, grad/param norm = 1.6911e-01, time/batch = 0.6898s	
23169/28500 (epoch 40.647), train_loss = 0.77326567, grad/param norm = 1.7173e-01, time/batch = 0.6892s	
23170/28500 (epoch 40.649), train_loss = 0.76099598, grad/param norm = 2.1242e-01, time/batch = 0.6895s	
23171/28500 (epoch 40.651), train_loss = 0.72552683, grad/param norm = 1.6853e-01, time/batch = 0.6975s	
23172/28500 (epoch 40.653), train_loss = 0.70290663, grad/param norm = 1.7793e-01, time/batch = 0.6934s	
23173/28500 (epoch 40.654), train_loss = 0.75204534, grad/param norm = 1.9240e-01, time/batch = 0.6911s	
23174/28500 (epoch 40.656), train_loss = 0.69799035, grad/param norm = 1.9364e-01, time/batch = 0.6908s	
23175/28500 (epoch 40.658), train_loss = 0.82215280, grad/param norm = 2.1773e-01, time/batch = 0.6917s	
23176/28500 (epoch 40.660), train_loss = 0.81980640, grad/param norm = 1.6809e-01, time/batch = 0.6924s	
23177/28500 (epoch 40.661), train_loss = 0.92499379, grad/param norm = 2.0602e-01, time/batch = 0.7090s	
23178/28500 (epoch 40.663), train_loss = 0.91157533, grad/param norm = 1.9025e-01, time/batch = 0.6937s	
23179/28500 (epoch 40.665), train_loss = 0.82881996, grad/param norm = 2.1881e-01, time/batch = 0.6892s	
23180/28500 (epoch 40.667), train_loss = 0.84711825, grad/param norm = 2.1767e-01, time/batch = 0.6890s	
23181/28500 (epoch 40.668), train_loss = 0.82556469, grad/param norm = 1.9532e-01, time/batch = 0.6920s	
23182/28500 (epoch 40.670), train_loss = 0.82268094, grad/param norm = 1.8385e-01, time/batch = 0.6895s	
23183/28500 (epoch 40.672), train_loss = 0.74682797, grad/param norm = 1.7528e-01, time/batch = 0.6908s	
23184/28500 (epoch 40.674), train_loss = 0.66819346, grad/param norm = 2.0521e-01, time/batch = 0.6892s	
23185/28500 (epoch 40.675), train_loss = 0.70182567, grad/param norm = 1.8993e-01, time/batch = 0.6893s	
23186/28500 (epoch 40.677), train_loss = 0.76642299, grad/param norm = 1.6955e-01, time/batch = 0.6891s	
23187/28500 (epoch 40.679), train_loss = 0.78479894, grad/param norm = 1.9716e-01, time/batch = 0.6889s	
23188/28500 (epoch 40.681), train_loss = 0.85636526, grad/param norm = 1.9525e-01, time/batch = 0.6887s	
23189/28500 (epoch 40.682), train_loss = 0.79396225, grad/param norm = 1.9310e-01, time/batch = 0.6884s	
23190/28500 (epoch 40.684), train_loss = 0.80933610, grad/param norm = 1.9245e-01, time/batch = 0.6902s	
23191/28500 (epoch 40.686), train_loss = 0.77558620, grad/param norm = 1.7568e-01, time/batch = 0.6937s	
23192/28500 (epoch 40.688), train_loss = 0.73872538, grad/param norm = 1.4568e-01, time/batch = 0.6904s	
23193/28500 (epoch 40.689), train_loss = 0.74803326, grad/param norm = 1.9885e-01, time/batch = 0.6913s	
23194/28500 (epoch 40.691), train_loss = 0.86296568, grad/param norm = 1.8849e-01, time/batch = 0.6916s	
23195/28500 (epoch 40.693), train_loss = 0.77301216, grad/param norm = 1.8009e-01, time/batch = 0.6903s	
23196/28500 (epoch 40.695), train_loss = 0.61496333, grad/param norm = 2.1083e-01, time/batch = 0.6902s	
23197/28500 (epoch 40.696), train_loss = 0.78010126, grad/param norm = 1.8099e-01, time/batch = 0.6930s	
23198/28500 (epoch 40.698), train_loss = 0.85287172, grad/param norm = 1.8799e-01, time/batch = 0.6947s	
23199/28500 (epoch 40.700), train_loss = 0.82223413, grad/param norm = 2.1978e-01, time/batch = 0.6889s	
23200/28500 (epoch 40.702), train_loss = 0.81176041, grad/param norm = 2.1468e-01, time/batch = 0.6894s	
23201/28500 (epoch 40.704), train_loss = 0.87240359, grad/param norm = 1.9996e-01, time/batch = 0.6910s	
23202/28500 (epoch 40.705), train_loss = 0.89678904, grad/param norm = 2.4690e-01, time/batch = 0.6913s	
23203/28500 (epoch 40.707), train_loss = 0.74717726, grad/param norm = 1.8037e-01, time/batch = 0.6908s	
23204/28500 (epoch 40.709), train_loss = 0.95399515, grad/param norm = 2.1757e-01, time/batch = 0.6918s	
23205/28500 (epoch 40.711), train_loss = 0.75919194, grad/param norm = 1.8444e-01, time/batch = 0.6896s	
23206/28500 (epoch 40.712), train_loss = 0.84567722, grad/param norm = 1.9230e-01, time/batch = 0.6895s	
23207/28500 (epoch 40.714), train_loss = 0.93428692, grad/param norm = 2.0557e-01, time/batch = 0.6895s	
23208/28500 (epoch 40.716), train_loss = 0.79356981, grad/param norm = 1.7909e-01, time/batch = 0.6913s	
23209/28500 (epoch 40.718), train_loss = 0.83928673, grad/param norm = 1.9708e-01, time/batch = 0.6920s	
23210/28500 (epoch 40.719), train_loss = 0.83631287, grad/param norm = 1.8211e-01, time/batch = 0.6899s	
23211/28500 (epoch 40.721), train_loss = 0.64166350, grad/param norm = 2.0241e-01, time/batch = 0.6918s	
23212/28500 (epoch 40.723), train_loss = 0.82206488, grad/param norm = 1.9612e-01, time/batch = 0.6898s	
23213/28500 (epoch 40.725), train_loss = 0.88148721, grad/param norm = 2.0378e-01, time/batch = 0.6897s	
23214/28500 (epoch 40.726), train_loss = 0.81135896, grad/param norm = 1.9775e-01, time/batch = 0.6914s	
23215/28500 (epoch 40.728), train_loss = 0.74587597, grad/param norm = 1.7761e-01, time/batch = 0.7080s	
23216/28500 (epoch 40.730), train_loss = 0.80465992, grad/param norm = 1.9504e-01, time/batch = 0.6963s	
23217/28500 (epoch 40.732), train_loss = 0.65064712, grad/param norm = 1.5344e-01, time/batch = 0.6925s	
23218/28500 (epoch 40.733), train_loss = 0.69296475, grad/param norm = 1.8303e-01, time/batch = 0.6906s	
23219/28500 (epoch 40.735), train_loss = 0.68467874, grad/param norm = 1.5105e-01, time/batch = 0.6894s	
23220/28500 (epoch 40.737), train_loss = 0.63587459, grad/param norm = 1.6608e-01, time/batch = 0.6978s	
23221/28500 (epoch 40.739), train_loss = 0.71073617, grad/param norm = 1.7613e-01, time/batch = 0.6929s	
23222/28500 (epoch 40.740), train_loss = 0.80570166, grad/param norm = 1.7771e-01, time/batch = 0.6897s	
23223/28500 (epoch 40.742), train_loss = 0.72964567, grad/param norm = 1.9764e-01, time/batch = 0.6893s	
23224/28500 (epoch 40.744), train_loss = 0.80518572, grad/param norm = 1.7871e-01, time/batch = 0.6914s	
23225/28500 (epoch 40.746), train_loss = 0.75401315, grad/param norm = 1.5884e-01, time/batch = 0.6915s	
23226/28500 (epoch 40.747), train_loss = 0.76964144, grad/param norm = 1.9592e-01, time/batch = 0.6905s	
23227/28500 (epoch 40.749), train_loss = 0.86334729, grad/param norm = 2.3190e-01, time/batch = 0.6896s	
23228/28500 (epoch 40.751), train_loss = 0.73185976, grad/param norm = 2.3805e-01, time/batch = 0.6914s	
23229/28500 (epoch 40.753), train_loss = 0.79755251, grad/param norm = 1.5759e-01, time/batch = 0.6902s	
23230/28500 (epoch 40.754), train_loss = 0.71829474, grad/param norm = 1.6531e-01, time/batch = 0.6891s	
23231/28500 (epoch 40.756), train_loss = 0.93341749, grad/param norm = 1.9945e-01, time/batch = 0.6916s	
23232/28500 (epoch 40.758), train_loss = 0.84705336, grad/param norm = 1.9959e-01, time/batch = 0.6908s	
23233/28500 (epoch 40.760), train_loss = 0.70517939, grad/param norm = 1.8082e-01, time/batch = 0.6904s	
23234/28500 (epoch 40.761), train_loss = 0.75948368, grad/param norm = 2.0018e-01, time/batch = 0.6931s	
23235/28500 (epoch 40.763), train_loss = 0.62705068, grad/param norm = 1.6625e-01, time/batch = 0.6904s	
23236/28500 (epoch 40.765), train_loss = 0.78211096, grad/param norm = 1.6696e-01, time/batch = 0.6892s	
23237/28500 (epoch 40.767), train_loss = 0.65686896, grad/param norm = 1.6716e-01, time/batch = 0.6896s	
23238/28500 (epoch 40.768), train_loss = 0.83618333, grad/param norm = 1.8734e-01, time/batch = 0.6898s	
23239/28500 (epoch 40.770), train_loss = 0.69646337, grad/param norm = 1.9651e-01, time/batch = 0.6903s	
23240/28500 (epoch 40.772), train_loss = 0.66367889, grad/param norm = 1.5506e-01, time/batch = 0.6921s	
23241/28500 (epoch 40.774), train_loss = 0.80145455, grad/param norm = 1.7191e-01, time/batch = 0.6921s	
23242/28500 (epoch 40.775), train_loss = 0.84270818, grad/param norm = 1.7503e-01, time/batch = 0.6913s	
23243/28500 (epoch 40.777), train_loss = 0.85929989, grad/param norm = 1.7486e-01, time/batch = 0.6964s	
23244/28500 (epoch 40.779), train_loss = 0.67382464, grad/param norm = 1.4728e-01, time/batch = 0.7040s	
23245/28500 (epoch 40.781), train_loss = 0.78534705, grad/param norm = 2.0036e-01, time/batch = 0.6992s	
23246/28500 (epoch 40.782), train_loss = 0.82503835, grad/param norm = 2.0831e-01, time/batch = 0.6916s	
23247/28500 (epoch 40.784), train_loss = 0.64216923, grad/param norm = 1.7026e-01, time/batch = 0.6919s	
23248/28500 (epoch 40.786), train_loss = 0.66524949, grad/param norm = 1.7241e-01, time/batch = 0.6912s	
23249/28500 (epoch 40.788), train_loss = 0.74462183, grad/param norm = 1.9330e-01, time/batch = 0.6903s	
23250/28500 (epoch 40.789), train_loss = 0.60269647, grad/param norm = 3.0563e-01, time/batch = 0.6925s	
23251/28500 (epoch 40.791), train_loss = 0.83343513, grad/param norm = 2.0343e-01, time/batch = 0.6978s	
23252/28500 (epoch 40.793), train_loss = 0.78465501, grad/param norm = 2.0159e-01, time/batch = 0.7035s	
23253/28500 (epoch 40.795), train_loss = 0.79189194, grad/param norm = 2.0508e-01, time/batch = 0.6962s	
23254/28500 (epoch 40.796), train_loss = 0.71125410, grad/param norm = 1.6366e-01, time/batch = 0.7014s	
23255/28500 (epoch 40.798), train_loss = 0.66635630, grad/param norm = 2.1436e-01, time/batch = 0.6910s	
23256/28500 (epoch 40.800), train_loss = 0.64537429, grad/param norm = 2.3538e-01, time/batch = 0.6917s	
23257/28500 (epoch 40.802), train_loss = 0.76333603, grad/param norm = 2.3037e-01, time/batch = 0.7035s	
23258/28500 (epoch 40.804), train_loss = 0.79660810, grad/param norm = 1.6292e-01, time/batch = 0.6932s	
23259/28500 (epoch 40.805), train_loss = 0.81159649, grad/param norm = 1.8200e-01, time/batch = 0.6919s	
23260/28500 (epoch 40.807), train_loss = 0.81818136, grad/param norm = 2.0499e-01, time/batch = 0.6902s	
23261/28500 (epoch 40.809), train_loss = 0.78966850, grad/param norm = 2.2046e-01, time/batch = 0.6959s	
23262/28500 (epoch 40.811), train_loss = 0.80689609, grad/param norm = 1.8984e-01, time/batch = 0.6907s	
23263/28500 (epoch 40.812), train_loss = 0.77249999, grad/param norm = 2.0054e-01, time/batch = 0.6899s	
23264/28500 (epoch 40.814), train_loss = 0.74168584, grad/param norm = 1.8567e-01, time/batch = 0.6917s	
23265/28500 (epoch 40.816), train_loss = 0.80997590, grad/param norm = 1.9699e-01, time/batch = 0.6914s	
23266/28500 (epoch 40.818), train_loss = 0.93239270, grad/param norm = 2.1753e-01, time/batch = 0.6892s	
23267/28500 (epoch 40.819), train_loss = 0.79711828, grad/param norm = 1.7628e-01, time/batch = 0.6910s	
23268/28500 (epoch 40.821), train_loss = 0.75739199, grad/param norm = 1.9470e-01, time/batch = 0.6910s	
23269/28500 (epoch 40.823), train_loss = 0.90657036, grad/param norm = 1.9485e-01, time/batch = 0.6895s	
23270/28500 (epoch 40.825), train_loss = 0.72663791, grad/param norm = 2.2630e-01, time/batch = 0.6907s	
23271/28500 (epoch 40.826), train_loss = 0.81352853, grad/param norm = 1.9001e-01, time/batch = 0.6931s	
23272/28500 (epoch 40.828), train_loss = 0.71565726, grad/param norm = 2.1222e-01, time/batch = 0.6907s	
23273/28500 (epoch 40.830), train_loss = 0.74665342, grad/param norm = 1.5861e-01, time/batch = 0.6906s	
23274/28500 (epoch 40.832), train_loss = 0.79616677, grad/param norm = 2.3355e-01, time/batch = 0.6902s	
23275/28500 (epoch 40.833), train_loss = 0.84595054, grad/param norm = 1.8102e-01, time/batch = 0.6921s	
23276/28500 (epoch 40.835), train_loss = 0.74498211, grad/param norm = 1.9905e-01, time/batch = 0.6897s	
23277/28500 (epoch 40.837), train_loss = 0.67296915, grad/param norm = 1.8999e-01, time/batch = 0.6920s	
23278/28500 (epoch 40.839), train_loss = 0.93725122, grad/param norm = 2.3225e-01, time/batch = 0.6893s	
23279/28500 (epoch 40.840), train_loss = 0.94350550, grad/param norm = 2.2796e-01, time/batch = 0.6897s	
23280/28500 (epoch 40.842), train_loss = 0.85303897, grad/param norm = 1.8321e-01, time/batch = 0.6895s	
23281/28500 (epoch 40.844), train_loss = 0.87162901, grad/param norm = 1.8730e-01, time/batch = 0.6918s	
23282/28500 (epoch 40.846), train_loss = 0.95503501, grad/param norm = 2.2330e-01, time/batch = 0.6906s	
23283/28500 (epoch 40.847), train_loss = 0.76040573, grad/param norm = 1.8378e-01, time/batch = 0.6910s	
23284/28500 (epoch 40.849), train_loss = 0.76014963, grad/param norm = 1.7431e-01, time/batch = 0.6920s	
23285/28500 (epoch 40.851), train_loss = 0.72497263, grad/param norm = 1.6864e-01, time/batch = 0.6994s	
23286/28500 (epoch 40.853), train_loss = 0.83180670, grad/param norm = 2.1293e-01, time/batch = 0.6946s	
23287/28500 (epoch 40.854), train_loss = 0.82469098, grad/param norm = 2.5108e-01, time/batch = 0.6976s	
23288/28500 (epoch 40.856), train_loss = 0.89896166, grad/param norm = 2.7547e-01, time/batch = 0.6981s	
23289/28500 (epoch 40.858), train_loss = 0.76196471, grad/param norm = 1.8367e-01, time/batch = 0.6931s	
23290/28500 (epoch 40.860), train_loss = 0.79990230, grad/param norm = 2.1056e-01, time/batch = 0.6943s	
23291/28500 (epoch 40.861), train_loss = 0.89246954, grad/param norm = 2.1267e-01, time/batch = 0.7001s	
23292/28500 (epoch 40.863), train_loss = 0.83920530, grad/param norm = 2.4004e-01, time/batch = 0.6946s	
23293/28500 (epoch 40.865), train_loss = 0.75040544, grad/param norm = 1.9381e-01, time/batch = 0.7046s	
23294/28500 (epoch 40.867), train_loss = 0.84175134, grad/param norm = 2.1766e-01, time/batch = 0.6949s	
23295/28500 (epoch 40.868), train_loss = 0.72085099, grad/param norm = 1.8467e-01, time/batch = 0.6944s	
23296/28500 (epoch 40.870), train_loss = 0.69526642, grad/param norm = 1.8536e-01, time/batch = 0.6955s	
23297/28500 (epoch 40.872), train_loss = 0.87230719, grad/param norm = 2.3461e-01, time/batch = 0.6941s	
23298/28500 (epoch 40.874), train_loss = 0.72589378, grad/param norm = 2.1341e-01, time/batch = 0.6944s	
23299/28500 (epoch 40.875), train_loss = 0.95238289, grad/param norm = 2.3082e-01, time/batch = 0.6947s	
23300/28500 (epoch 40.877), train_loss = 0.82417298, grad/param norm = 2.0888e-01, time/batch = 0.6958s	
23301/28500 (epoch 40.879), train_loss = 0.84923059, grad/param norm = 1.6302e-01, time/batch = 0.6980s	
23302/28500 (epoch 40.881), train_loss = 0.82847515, grad/param norm = 1.9308e-01, time/batch = 0.7008s	
23303/28500 (epoch 40.882), train_loss = 0.74372816, grad/param norm = 1.7712e-01, time/batch = 0.6956s	
23304/28500 (epoch 40.884), train_loss = 0.76712832, grad/param norm = 2.0442e-01, time/batch = 0.6955s	
23305/28500 (epoch 40.886), train_loss = 0.74430116, grad/param norm = 1.6943e-01, time/batch = 0.6943s	
23306/28500 (epoch 40.888), train_loss = 0.76819358, grad/param norm = 1.5790e-01, time/batch = 0.6936s	
23307/28500 (epoch 40.889), train_loss = 0.80968849, grad/param norm = 1.5782e-01, time/batch = 0.6944s	
23308/28500 (epoch 40.891), train_loss = 0.80333548, grad/param norm = 1.7416e-01, time/batch = 0.6956s	
23309/28500 (epoch 40.893), train_loss = 0.75225224, grad/param norm = 1.7846e-01, time/batch = 0.6947s	
23310/28500 (epoch 40.895), train_loss = 0.94316978, grad/param norm = 2.2346e-01, time/batch = 0.6944s	
23311/28500 (epoch 40.896), train_loss = 0.92703940, grad/param norm = 2.2928e-01, time/batch = 0.6978s	
23312/28500 (epoch 40.898), train_loss = 0.84424659, grad/param norm = 1.9366e-01, time/batch = 0.6943s	
23313/28500 (epoch 40.900), train_loss = 0.70631692, grad/param norm = 1.5090e-01, time/batch = 0.6943s	
23314/28500 (epoch 40.902), train_loss = 0.67167473, grad/param norm = 1.7964e-01, time/batch = 0.6959s	
23315/28500 (epoch 40.904), train_loss = 0.70427171, grad/param norm = 1.7345e-01, time/batch = 0.6992s	
23316/28500 (epoch 40.905), train_loss = 0.76572270, grad/param norm = 2.2585e-01, time/batch = 0.6926s	
23317/28500 (epoch 40.907), train_loss = 0.77894851, grad/param norm = 1.6824e-01, time/batch = 0.6946s	
23318/28500 (epoch 40.909), train_loss = 0.66527689, grad/param norm = 2.1347e-01, time/batch = 0.6930s	
23319/28500 (epoch 40.911), train_loss = 0.72038709, grad/param norm = 1.7665e-01, time/batch = 0.6952s	
23320/28500 (epoch 40.912), train_loss = 0.59867520, grad/param norm = 1.5707e-01, time/batch = 0.6965s	
23321/28500 (epoch 40.914), train_loss = 0.82153750, grad/param norm = 1.8732e-01, time/batch = 0.6985s	
23322/28500 (epoch 40.916), train_loss = 0.80496586, grad/param norm = 2.0332e-01, time/batch = 0.6938s	
23323/28500 (epoch 40.918), train_loss = 0.78249066, grad/param norm = 1.8409e-01, time/batch = 0.6933s	
23324/28500 (epoch 40.919), train_loss = 0.82523380, grad/param norm = 2.0602e-01, time/batch = 0.6953s	
23325/28500 (epoch 40.921), train_loss = 0.90181903, grad/param norm = 2.4238e-01, time/batch = 0.6930s	
23326/28500 (epoch 40.923), train_loss = 0.73304166, grad/param norm = 2.1502e-01, time/batch = 0.6941s	
23327/28500 (epoch 40.925), train_loss = 0.74182416, grad/param norm = 1.9288e-01, time/batch = 0.6954s	
23328/28500 (epoch 40.926), train_loss = 0.80492768, grad/param norm = 1.8984e-01, time/batch = 0.6937s	
23329/28500 (epoch 40.928), train_loss = 0.74826738, grad/param norm = 1.7938e-01, time/batch = 0.7045s	
23330/28500 (epoch 40.930), train_loss = 0.64148801, grad/param norm = 1.7341e-01, time/batch = 0.6965s	
23331/28500 (epoch 40.932), train_loss = 0.64388356, grad/param norm = 1.6114e-01, time/batch = 0.7070s	
23332/28500 (epoch 40.933), train_loss = 0.86736482, grad/param norm = 2.2193e-01, time/batch = 0.6966s	
23333/28500 (epoch 40.935), train_loss = 0.88740840, grad/param norm = 1.9255e-01, time/batch = 0.6971s	
23334/28500 (epoch 40.937), train_loss = 0.89511472, grad/param norm = 2.5989e-01, time/batch = 0.6952s	
23335/28500 (epoch 40.939), train_loss = 0.90894516, grad/param norm = 2.2929e-01, time/batch = 0.6933s	
23336/28500 (epoch 40.940), train_loss = 0.64798182, grad/param norm = 1.7551e-01, time/batch = 0.6932s	
23337/28500 (epoch 40.942), train_loss = 0.79813146, grad/param norm = 1.9229e-01, time/batch = 0.6923s	
23338/28500 (epoch 40.944), train_loss = 0.77190019, grad/param norm = 1.7993e-01, time/batch = 0.6929s	
23339/28500 (epoch 40.946), train_loss = 0.83242751, grad/param norm = 1.7525e-01, time/batch = 0.6998s	
23340/28500 (epoch 40.947), train_loss = 1.04007348, grad/param norm = 2.9373e-01, time/batch = 0.6941s	
23341/28500 (epoch 40.949), train_loss = 0.79553515, grad/param norm = 2.2503e-01, time/batch = 0.6994s	
23342/28500 (epoch 40.951), train_loss = 0.98874908, grad/param norm = 2.5365e-01, time/batch = 0.6955s	
23343/28500 (epoch 40.953), train_loss = 0.95857292, grad/param norm = 2.0930e-01, time/batch = 0.7003s	
23344/28500 (epoch 40.954), train_loss = 0.89344848, grad/param norm = 2.2072e-01, time/batch = 0.6939s	
23345/28500 (epoch 40.956), train_loss = 0.85115032, grad/param norm = 2.7013e-01, time/batch = 0.7137s	
23346/28500 (epoch 40.958), train_loss = 1.02780097, grad/param norm = 1.9220e-01, time/batch = 0.6938s	
23347/28500 (epoch 40.960), train_loss = 0.74735431, grad/param norm = 2.2788e-01, time/batch = 0.6997s	
23348/28500 (epoch 40.961), train_loss = 0.95405959, grad/param norm = 2.4502e-01, time/batch = 0.7173s	
23349/28500 (epoch 40.963), train_loss = 0.89219788, grad/param norm = 1.9623e-01, time/batch = 0.6926s	
23350/28500 (epoch 40.965), train_loss = 0.73973012, grad/param norm = 1.9266e-01, time/batch = 0.6949s	
23351/28500 (epoch 40.967), train_loss = 0.76929907, grad/param norm = 1.9160e-01, time/batch = 0.6862s	
23352/28500 (epoch 40.968), train_loss = 0.70491378, grad/param norm = 1.5553e-01, time/batch = 0.6836s	
23353/28500 (epoch 40.970), train_loss = 0.77254621, grad/param norm = 2.2392e-01, time/batch = 0.6817s	
23354/28500 (epoch 40.972), train_loss = 0.81443732, grad/param norm = 1.8878e-01, time/batch = 0.6873s	
23355/28500 (epoch 40.974), train_loss = 1.00998182, grad/param norm = 2.3660e-01, time/batch = 0.6963s	
23356/28500 (epoch 40.975), train_loss = 0.74713412, grad/param norm = 2.1949e-01, time/batch = 0.6915s	
23357/28500 (epoch 40.977), train_loss = 0.92746118, grad/param norm = 2.4136e-01, time/batch = 0.6887s	
23358/28500 (epoch 40.979), train_loss = 0.84286391, grad/param norm = 2.0012e-01, time/batch = 0.6903s	
23359/28500 (epoch 40.981), train_loss = 0.70447779, grad/param norm = 1.8498e-01, time/batch = 0.6840s	
23360/28500 (epoch 40.982), train_loss = 0.79404466, grad/param norm = 1.9651e-01, time/batch = 0.6778s	
23361/28500 (epoch 40.984), train_loss = 0.88222913, grad/param norm = 1.9417e-01, time/batch = 0.6801s	
23362/28500 (epoch 40.986), train_loss = 1.03354742, grad/param norm = 2.2254e-01, time/batch = 0.6775s	
23363/28500 (epoch 40.988), train_loss = 0.74043942, grad/param norm = 1.9621e-01, time/batch = 0.6815s	
23364/28500 (epoch 40.989), train_loss = 0.82901638, grad/param norm = 3.0109e-01, time/batch = 0.6784s	
23365/28500 (epoch 40.991), train_loss = 0.73212120, grad/param norm = 1.8890e-01, time/batch = 0.6772s	
23366/28500 (epoch 40.993), train_loss = 0.74148691, grad/param norm = 1.8819e-01, time/batch = 0.6777s	
23367/28500 (epoch 40.995), train_loss = 0.76810455, grad/param norm = 1.9773e-01, time/batch = 0.6761s	
23368/28500 (epoch 40.996), train_loss = 0.71205329, grad/param norm = 1.8965e-01, time/batch = 0.6786s	
23369/28500 (epoch 40.998), train_loss = 0.94188749, grad/param norm = 3.3929e-01, time/batch = 0.6819s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
23370/28500 (epoch 41.000), train_loss = 0.79195221, grad/param norm = 2.6694e-01, time/batch = 0.6779s	
23371/28500 (epoch 41.002), train_loss = 0.95073738, grad/param norm = 1.9167e-01, time/batch = 0.6788s	
23372/28500 (epoch 41.004), train_loss = 0.82810589, grad/param norm = 1.8953e-01, time/batch = 0.6787s	
23373/28500 (epoch 41.005), train_loss = 0.90822885, grad/param norm = 2.2520e-01, time/batch = 0.6927s	
23374/28500 (epoch 41.007), train_loss = 0.71905902, grad/param norm = 1.6583e-01, time/batch = 0.6780s	
23375/28500 (epoch 41.009), train_loss = 0.82585891, grad/param norm = 1.8601e-01, time/batch = 0.6812s	
23376/28500 (epoch 41.011), train_loss = 0.73911347, grad/param norm = 1.8702e-01, time/batch = 0.6755s	
23377/28500 (epoch 41.012), train_loss = 0.76171906, grad/param norm = 1.9346e-01, time/batch = 0.6771s	
23378/28500 (epoch 41.014), train_loss = 0.73479756, grad/param norm = 2.3141e-01, time/batch = 0.6764s	
23379/28500 (epoch 41.016), train_loss = 0.77671712, grad/param norm = 2.0718e-01, time/batch = 0.6753s	
23380/28500 (epoch 41.018), train_loss = 0.84438392, grad/param norm = 2.0999e-01, time/batch = 0.6760s	
23381/28500 (epoch 41.019), train_loss = 0.89366162, grad/param norm = 1.8950e-01, time/batch = 0.6791s	
23382/28500 (epoch 41.021), train_loss = 0.92261935, grad/param norm = 1.6847e-01, time/batch = 0.6789s	
23383/28500 (epoch 41.023), train_loss = 0.83594036, grad/param norm = 1.8851e-01, time/batch = 0.6809s	
23384/28500 (epoch 41.025), train_loss = 0.84745651, grad/param norm = 1.8601e-01, time/batch = 0.6767s	
23385/28500 (epoch 41.026), train_loss = 0.76745272, grad/param norm = 1.7261e-01, time/batch = 0.6785s	
23386/28500 (epoch 41.028), train_loss = 0.82332396, grad/param norm = 2.3351e-01, time/batch = 0.6777s	
23387/28500 (epoch 41.030), train_loss = 0.83937736, grad/param norm = 2.1795e-01, time/batch = 0.6756s	
23388/28500 (epoch 41.032), train_loss = 0.92822106, grad/param norm = 2.0102e-01, time/batch = 0.6768s	
23389/28500 (epoch 41.033), train_loss = 0.96122202, grad/param norm = 1.9669e-01, time/batch = 0.6758s	
23390/28500 (epoch 41.035), train_loss = 0.79067805, grad/param norm = 2.0046e-01, time/batch = 0.6768s	
23391/28500 (epoch 41.037), train_loss = 0.88095900, grad/param norm = 1.9162e-01, time/batch = 0.6787s	
23392/28500 (epoch 41.039), train_loss = 0.94084992, grad/param norm = 2.1907e-01, time/batch = 0.6797s	
23393/28500 (epoch 41.040), train_loss = 0.93504934, grad/param norm = 1.9115e-01, time/batch = 0.6768s	
23394/28500 (epoch 41.042), train_loss = 0.87352335, grad/param norm = 1.8082e-01, time/batch = 0.6803s	
23395/28500 (epoch 41.044), train_loss = 0.82142141, grad/param norm = 2.1719e-01, time/batch = 0.6765s	
23396/28500 (epoch 41.046), train_loss = 1.00557241, grad/param norm = 1.9959e-01, time/batch = 0.6761s	
23397/28500 (epoch 41.047), train_loss = 0.96889186, grad/param norm = 2.2891e-01, time/batch = 0.6774s	
23398/28500 (epoch 41.049), train_loss = 0.83874975, grad/param norm = 1.9378e-01, time/batch = 0.6784s	
23399/28500 (epoch 41.051), train_loss = 0.83294743, grad/param norm = 2.3938e-01, time/batch = 0.6777s	
23400/28500 (epoch 41.053), train_loss = 0.80334344, grad/param norm = 2.2251e-01, time/batch = 0.6782s	
23401/28500 (epoch 41.054), train_loss = 0.88476669, grad/param norm = 1.8431e-01, time/batch = 0.6778s	
23402/28500 (epoch 41.056), train_loss = 0.78746541, grad/param norm = 1.8923e-01, time/batch = 0.6818s	
23403/28500 (epoch 41.058), train_loss = 0.76100618, grad/param norm = 1.9385e-01, time/batch = 0.6763s	
23404/28500 (epoch 41.060), train_loss = 0.88702453, grad/param norm = 2.1346e-01, time/batch = 0.6795s	
23405/28500 (epoch 41.061), train_loss = 0.78843108, grad/param norm = 1.9190e-01, time/batch = 0.6787s	
23406/28500 (epoch 41.063), train_loss = 0.87276333, grad/param norm = 2.0556e-01, time/batch = 0.6795s	
23407/28500 (epoch 41.065), train_loss = 0.84627540, grad/param norm = 2.3328e-01, time/batch = 0.6764s	
23408/28500 (epoch 41.067), train_loss = 0.76954995, grad/param norm = 1.9065e-01, time/batch = 0.6761s	
23409/28500 (epoch 41.068), train_loss = 0.80279053, grad/param norm = 1.9348e-01, time/batch = 0.6805s	
23410/28500 (epoch 41.070), train_loss = 0.84179809, grad/param norm = 1.9809e-01, time/batch = 0.6787s	
23411/28500 (epoch 41.072), train_loss = 0.95949631, grad/param norm = 2.1886e-01, time/batch = 0.6772s	
23412/28500 (epoch 41.074), train_loss = 0.81059405, grad/param norm = 1.8595e-01, time/batch = 0.6782s	
23413/28500 (epoch 41.075), train_loss = 0.81539396, grad/param norm = 1.7246e-01, time/batch = 0.6763s	
23414/28500 (epoch 41.077), train_loss = 0.87912883, grad/param norm = 1.8625e-01, time/batch = 0.6782s	
23415/28500 (epoch 41.079), train_loss = 0.83583440, grad/param norm = 1.7978e-01, time/batch = 0.6820s	
23416/28500 (epoch 41.081), train_loss = 0.90189363, grad/param norm = 2.0411e-01, time/batch = 0.6827s	
23417/28500 (epoch 41.082), train_loss = 0.82557662, grad/param norm = 2.5394e-01, time/batch = 0.6822s	
23418/28500 (epoch 41.084), train_loss = 0.83865984, grad/param norm = 1.9865e-01, time/batch = 0.6859s	
23419/28500 (epoch 41.086), train_loss = 0.78588331, grad/param norm = 2.1306e-01, time/batch = 0.6822s	
23420/28500 (epoch 41.088), train_loss = 0.73470943, grad/param norm = 1.7756e-01, time/batch = 0.6795s	
23421/28500 (epoch 41.089), train_loss = 0.89969237, grad/param norm = 2.3996e-01, time/batch = 0.6820s	
23422/28500 (epoch 41.091), train_loss = 0.74505858, grad/param norm = 2.0185e-01, time/batch = 0.6804s	
23423/28500 (epoch 41.093), train_loss = 0.91065584, grad/param norm = 1.9205e-01, time/batch = 0.6825s	
23424/28500 (epoch 41.095), train_loss = 0.82410769, grad/param norm = 1.8070e-01, time/batch = 0.6854s	
23425/28500 (epoch 41.096), train_loss = 0.90665647, grad/param norm = 1.9075e-01, time/batch = 0.6833s	
23426/28500 (epoch 41.098), train_loss = 0.82159112, grad/param norm = 2.0450e-01, time/batch = 0.6787s	
23427/28500 (epoch 41.100), train_loss = 0.80085208, grad/param norm = 1.6973e-01, time/batch = 0.6796s	
23428/28500 (epoch 41.102), train_loss = 0.91372076, grad/param norm = 2.2812e-01, time/batch = 0.6782s	
23429/28500 (epoch 41.104), train_loss = 0.85921710, grad/param norm = 2.7004e-01, time/batch = 0.6856s	
23430/28500 (epoch 41.105), train_loss = 0.91739105, grad/param norm = 1.8363e-01, time/batch = 0.6798s	
23431/28500 (epoch 41.107), train_loss = 0.75337922, grad/param norm = 1.8592e-01, time/batch = 0.6845s	
23432/28500 (epoch 41.109), train_loss = 0.79427273, grad/param norm = 2.6617e-01, time/batch = 0.6840s	
23433/28500 (epoch 41.111), train_loss = 0.80104832, grad/param norm = 2.2468e-01, time/batch = 0.6809s	
23434/28500 (epoch 41.112), train_loss = 0.89267513, grad/param norm = 1.9324e-01, time/batch = 0.6863s	
23435/28500 (epoch 41.114), train_loss = 0.82418241, grad/param norm = 2.0623e-01, time/batch = 0.6813s	
23436/28500 (epoch 41.116), train_loss = 0.96511518, grad/param norm = 2.0657e-01, time/batch = 0.6793s	
23437/28500 (epoch 41.118), train_loss = 0.75833641, grad/param norm = 2.0343e-01, time/batch = 0.6822s	
23438/28500 (epoch 41.119), train_loss = 0.85981923, grad/param norm = 2.2121e-01, time/batch = 0.6857s	
23439/28500 (epoch 41.121), train_loss = 0.98736598, grad/param norm = 2.3543e-01, time/batch = 0.6788s	
23440/28500 (epoch 41.123), train_loss = 0.92546093, grad/param norm = 1.9129e-01, time/batch = 0.6790s	
23441/28500 (epoch 41.125), train_loss = 0.85256327, grad/param norm = 1.8921e-01, time/batch = 0.6818s	
23442/28500 (epoch 41.126), train_loss = 0.83799256, grad/param norm = 1.9502e-01, time/batch = 0.6799s	
23443/28500 (epoch 41.128), train_loss = 0.84298610, grad/param norm = 1.8170e-01, time/batch = 0.6792s	
23444/28500 (epoch 41.130), train_loss = 0.82733806, grad/param norm = 2.4686e-01, time/batch = 0.6796s	
23445/28500 (epoch 41.132), train_loss = 0.83230790, grad/param norm = 1.8893e-01, time/batch = 0.6809s	
23446/28500 (epoch 41.133), train_loss = 0.87569743, grad/param norm = 1.9626e-01, time/batch = 0.6792s	
23447/28500 (epoch 41.135), train_loss = 0.78624541, grad/param norm = 1.7174e-01, time/batch = 0.6842s	
23448/28500 (epoch 41.137), train_loss = 0.84386270, grad/param norm = 1.7617e-01, time/batch = 0.6807s	
23449/28500 (epoch 41.139), train_loss = 0.83123981, grad/param norm = 1.8399e-01, time/batch = 0.6792s	
23450/28500 (epoch 41.140), train_loss = 0.83007612, grad/param norm = 1.9107e-01, time/batch = 0.6801s	
23451/28500 (epoch 41.142), train_loss = 0.79048964, grad/param norm = 2.2374e-01, time/batch = 0.6819s	
23452/28500 (epoch 41.144), train_loss = 0.74615366, grad/param norm = 1.8018e-01, time/batch = 0.6813s	
23453/28500 (epoch 41.146), train_loss = 0.81215262, grad/param norm = 1.8619e-01, time/batch = 0.6789s	
23454/28500 (epoch 41.147), train_loss = 0.70380282, grad/param norm = 1.7102e-01, time/batch = 0.6816s	
23455/28500 (epoch 41.149), train_loss = 0.72137513, grad/param norm = 1.7938e-01, time/batch = 0.6795s	
23456/28500 (epoch 41.151), train_loss = 0.78679984, grad/param norm = 1.8703e-01, time/batch = 0.6835s	
23457/28500 (epoch 41.153), train_loss = 0.84262471, grad/param norm = 1.8315e-01, time/batch = 0.6800s	
23458/28500 (epoch 41.154), train_loss = 0.71366932, grad/param norm = 2.0834e-01, time/batch = 0.6803s	
23459/28500 (epoch 41.156), train_loss = 0.89090162, grad/param norm = 1.9174e-01, time/batch = 0.6797s	
23460/28500 (epoch 41.158), train_loss = 0.85106294, grad/param norm = 1.7769e-01, time/batch = 0.6791s	
23461/28500 (epoch 41.160), train_loss = 0.74003289, grad/param norm = 1.7039e-01, time/batch = 0.6822s	
23462/28500 (epoch 41.161), train_loss = 0.77541902, grad/param norm = 2.2027e-01, time/batch = 0.6809s	
23463/28500 (epoch 41.163), train_loss = 0.72296877, grad/param norm = 1.9128e-01, time/batch = 0.6824s	
23464/28500 (epoch 41.165), train_loss = 0.94964947, grad/param norm = 1.7896e-01, time/batch = 0.6791s	
23465/28500 (epoch 41.167), train_loss = 0.96338057, grad/param norm = 2.1088e-01, time/batch = 0.6813s	
23466/28500 (epoch 41.168), train_loss = 0.92176979, grad/param norm = 2.0879e-01, time/batch = 0.6790s	
23467/28500 (epoch 41.170), train_loss = 0.91170147, grad/param norm = 2.3645e-01, time/batch = 0.6809s	
23468/28500 (epoch 41.172), train_loss = 0.80137391, grad/param norm = 1.8211e-01, time/batch = 0.6806s	
23469/28500 (epoch 41.174), train_loss = 0.98005818, grad/param norm = 2.1790e-01, time/batch = 0.6788s	
23470/28500 (epoch 41.175), train_loss = 0.80421669, grad/param norm = 1.7898e-01, time/batch = 0.6818s	
23471/28500 (epoch 41.177), train_loss = 0.84473636, grad/param norm = 1.8574e-01, time/batch = 0.6998s	
23472/28500 (epoch 41.179), train_loss = 0.91150638, grad/param norm = 2.1458e-01, time/batch = 0.6849s	
23473/28500 (epoch 41.181), train_loss = 0.86112154, grad/param norm = 2.2378e-01, time/batch = 0.6829s	
23474/28500 (epoch 41.182), train_loss = 0.79441857, grad/param norm = 1.9707e-01, time/batch = 0.6797s	
23475/28500 (epoch 41.184), train_loss = 1.00054414, grad/param norm = 2.2460e-01, time/batch = 0.6807s	
23476/28500 (epoch 41.186), train_loss = 0.95019522, grad/param norm = 1.8521e-01, time/batch = 0.6892s	
23477/28500 (epoch 41.188), train_loss = 0.88818170, grad/param norm = 2.0907e-01, time/batch = 0.6816s	
23478/28500 (epoch 41.189), train_loss = 0.82735938, grad/param norm = 1.7095e-01, time/batch = 0.6828s	
23479/28500 (epoch 41.191), train_loss = 0.98849880, grad/param norm = 1.9824e-01, time/batch = 0.6793s	
23480/28500 (epoch 41.193), train_loss = 0.81461317, grad/param norm = 2.1193e-01, time/batch = 0.6824s	
23481/28500 (epoch 41.195), train_loss = 0.97531865, grad/param norm = 2.2441e-01, time/batch = 0.6819s	
23482/28500 (epoch 41.196), train_loss = 0.89345663, grad/param norm = 2.0324e-01, time/batch = 0.6814s	
23483/28500 (epoch 41.198), train_loss = 0.86456657, grad/param norm = 2.0240e-01, time/batch = 0.6805s	
23484/28500 (epoch 41.200), train_loss = 0.90085934, grad/param norm = 1.9531e-01, time/batch = 0.6820s	
23485/28500 (epoch 41.202), train_loss = 0.86400167, grad/param norm = 1.7933e-01, time/batch = 0.6792s	
23486/28500 (epoch 41.204), train_loss = 0.82900136, grad/param norm = 1.6687e-01, time/batch = 0.6802s	
23487/28500 (epoch 41.205), train_loss = 0.78636776, grad/param norm = 1.8095e-01, time/batch = 0.6799s	
23488/28500 (epoch 41.207), train_loss = 0.71852064, grad/param norm = 2.0627e-01, time/batch = 0.6787s	
23489/28500 (epoch 41.209), train_loss = 0.86330917, grad/param norm = 1.7261e-01, time/batch = 0.6806s	
23490/28500 (epoch 41.211), train_loss = 0.77493528, grad/param norm = 2.2746e-01, time/batch = 0.6804s	
23491/28500 (epoch 41.212), train_loss = 0.70215340, grad/param norm = 1.9559e-01, time/batch = 0.6832s	
23492/28500 (epoch 41.214), train_loss = 0.82074487, grad/param norm = 2.1188e-01, time/batch = 0.6800s	
23493/28500 (epoch 41.216), train_loss = 0.76636151, grad/param norm = 2.1505e-01, time/batch = 0.6801s	
23494/28500 (epoch 41.218), train_loss = 0.93275128, grad/param norm = 1.7726e-01, time/batch = 0.6796s	
23495/28500 (epoch 41.219), train_loss = 0.86298353, grad/param norm = 2.0770e-01, time/batch = 0.6800s	
23496/28500 (epoch 41.221), train_loss = 0.72949737, grad/param norm = 2.0999e-01, time/batch = 0.6838s	
23497/28500 (epoch 41.223), train_loss = 0.92679924, grad/param norm = 2.1118e-01, time/batch = 0.6787s	
23498/28500 (epoch 41.225), train_loss = 0.96386693, grad/param norm = 2.3354e-01, time/batch = 0.6809s	
23499/28500 (epoch 41.226), train_loss = 0.79524414, grad/param norm = 1.8669e-01, time/batch = 0.6791s	
23500/28500 (epoch 41.228), train_loss = 0.92791532, grad/param norm = 1.9060e-01, time/batch = 0.6787s	
23501/28500 (epoch 41.230), train_loss = 0.90533051, grad/param norm = 2.0724e-01, time/batch = 0.6821s	
23502/28500 (epoch 41.232), train_loss = 0.89155782, grad/param norm = 1.9819e-01, time/batch = 0.6820s	
23503/28500 (epoch 41.233), train_loss = 0.83805200, grad/param norm = 1.9209e-01, time/batch = 0.6807s	
23504/28500 (epoch 41.235), train_loss = 0.83720518, grad/param norm = 1.9092e-01, time/batch = 0.6923s	
23505/28500 (epoch 41.237), train_loss = 0.75353349, grad/param norm = 1.5505e-01, time/batch = 0.6927s	
23506/28500 (epoch 41.239), train_loss = 0.79614643, grad/param norm = 1.8760e-01, time/batch = 0.6908s	
23507/28500 (epoch 41.240), train_loss = 0.73439877, grad/param norm = 1.8316e-01, time/batch = 0.6927s	
23508/28500 (epoch 41.242), train_loss = 0.77193980, grad/param norm = 2.0988e-01, time/batch = 0.6989s	
23509/28500 (epoch 41.244), train_loss = 0.85989300, grad/param norm = 1.6577e-01, time/batch = 0.6863s	
23510/28500 (epoch 41.246), train_loss = 0.87271742, grad/param norm = 1.8466e-01, time/batch = 0.6998s	
23511/28500 (epoch 41.247), train_loss = 0.96152980, grad/param norm = 2.6411e-01, time/batch = 0.7091s	
23512/28500 (epoch 41.249), train_loss = 0.82424636, grad/param norm = 1.7942e-01, time/batch = 0.7066s	
23513/28500 (epoch 41.251), train_loss = 0.83095841, grad/param norm = 1.8113e-01, time/batch = 0.6948s	
23514/28500 (epoch 41.253), train_loss = 0.95984146, grad/param norm = 2.0499e-01, time/batch = 0.6878s	
23515/28500 (epoch 41.254), train_loss = 0.97360460, grad/param norm = 1.9279e-01, time/batch = 0.6929s	
23516/28500 (epoch 41.256), train_loss = 0.81644368, grad/param norm = 2.0204e-01, time/batch = 0.6978s	
23517/28500 (epoch 41.258), train_loss = 0.82225150, grad/param norm = 1.9876e-01, time/batch = 0.7003s	
23518/28500 (epoch 41.260), train_loss = 0.81520043, grad/param norm = 1.7595e-01, time/batch = 0.7102s	
23519/28500 (epoch 41.261), train_loss = 0.72721616, grad/param norm = 2.3824e-01, time/batch = 0.6987s	
23520/28500 (epoch 41.263), train_loss = 0.91109046, grad/param norm = 2.2983e-01, time/batch = 0.6876s	
23521/28500 (epoch 41.265), train_loss = 0.76641157, grad/param norm = 1.7077e-01, time/batch = 0.6826s	
23522/28500 (epoch 41.267), train_loss = 0.98533914, grad/param norm = 2.2084e-01, time/batch = 0.6802s	
23523/28500 (epoch 41.268), train_loss = 0.86175407, grad/param norm = 1.6332e-01, time/batch = 0.6814s	
23524/28500 (epoch 41.270), train_loss = 0.82947400, grad/param norm = 2.0460e-01, time/batch = 0.6790s	
23525/28500 (epoch 41.272), train_loss = 0.83101276, grad/param norm = 1.7637e-01, time/batch = 0.6992s	
23526/28500 (epoch 41.274), train_loss = 0.88541425, grad/param norm = 2.0436e-01, time/batch = 0.6782s	
23527/28500 (epoch 41.275), train_loss = 0.89805299, grad/param norm = 1.8355e-01, time/batch = 0.6759s	
23528/28500 (epoch 41.277), train_loss = 0.83170057, grad/param norm = 2.0162e-01, time/batch = 0.6767s	
23529/28500 (epoch 41.279), train_loss = 0.87308194, grad/param norm = 2.0294e-01, time/batch = 0.6758s	
23530/28500 (epoch 41.281), train_loss = 0.88999517, grad/param norm = 2.2399e-01, time/batch = 0.6766s	
23531/28500 (epoch 41.282), train_loss = 0.83640857, grad/param norm = 1.8522e-01, time/batch = 0.6779s	
23532/28500 (epoch 41.284), train_loss = 0.88006120, grad/param norm = 2.0140e-01, time/batch = 0.6869s	
23533/28500 (epoch 41.286), train_loss = 0.92865686, grad/param norm = 2.0228e-01, time/batch = 0.6876s	
23534/28500 (epoch 41.288), train_loss = 0.83179675, grad/param norm = 1.9649e-01, time/batch = 0.6760s	
23535/28500 (epoch 41.289), train_loss = 0.85440642, grad/param norm = 1.9329e-01, time/batch = 0.6781s	
23536/28500 (epoch 41.291), train_loss = 0.84421306, grad/param norm = 1.7125e-01, time/batch = 0.6758s	
23537/28500 (epoch 41.293), train_loss = 0.86599842, grad/param norm = 2.0658e-01, time/batch = 0.6773s	
23538/28500 (epoch 41.295), train_loss = 0.75972485, grad/param norm = 1.8412e-01, time/batch = 0.6762s	
23539/28500 (epoch 41.296), train_loss = 0.73734232, grad/param norm = 1.8035e-01, time/batch = 0.6772s	
23540/28500 (epoch 41.298), train_loss = 0.89610400, grad/param norm = 1.9705e-01, time/batch = 0.6905s	
23541/28500 (epoch 41.300), train_loss = 0.76512873, grad/param norm = 1.8354e-01, time/batch = 0.6856s	
23542/28500 (epoch 41.302), train_loss = 0.70830112, grad/param norm = 1.8291e-01, time/batch = 0.6763s	
23543/28500 (epoch 41.304), train_loss = 0.81756054, grad/param norm = 1.8915e-01, time/batch = 0.6788s	
23544/28500 (epoch 41.305), train_loss = 0.86300532, grad/param norm = 1.8213e-01, time/batch = 0.6764s	
23545/28500 (epoch 41.307), train_loss = 0.80423258, grad/param norm = 1.9226e-01, time/batch = 0.6996s	
23546/28500 (epoch 41.309), train_loss = 0.83258261, grad/param norm = 1.9061e-01, time/batch = 0.6801s	
23547/28500 (epoch 41.311), train_loss = 0.87567056, grad/param norm = 1.9494e-01, time/batch = 0.6855s	
23548/28500 (epoch 41.312), train_loss = 0.87032083, grad/param norm = 1.8933e-01, time/batch = 0.6998s	
23549/28500 (epoch 41.314), train_loss = 0.86143008, grad/param norm = 1.8211e-01, time/batch = 0.6825s	
23550/28500 (epoch 41.316), train_loss = 0.85018276, grad/param norm = 1.9526e-01, time/batch = 0.6776s	
23551/28500 (epoch 41.318), train_loss = 0.91304832, grad/param norm = 1.7934e-01, time/batch = 0.6791s	
23552/28500 (epoch 41.319), train_loss = 0.78789408, grad/param norm = 1.8898e-01, time/batch = 0.6784s	
23553/28500 (epoch 41.321), train_loss = 0.80242275, grad/param norm = 2.2245e-01, time/batch = 0.6780s	
23554/28500 (epoch 41.323), train_loss = 0.84589178, grad/param norm = 2.2178e-01, time/batch = 0.6808s	
23555/28500 (epoch 41.325), train_loss = 0.94676174, grad/param norm = 1.9505e-01, time/batch = 0.7020s	
23556/28500 (epoch 41.326), train_loss = 0.84704586, grad/param norm = 1.7218e-01, time/batch = 0.6895s	
23557/28500 (epoch 41.328), train_loss = 0.67902911, grad/param norm = 1.6590e-01, time/batch = 0.6796s	
23558/28500 (epoch 41.330), train_loss = 0.77164935, grad/param norm = 1.8177e-01, time/batch = 0.6778s	
23559/28500 (epoch 41.332), train_loss = 0.80093164, grad/param norm = 1.8297e-01, time/batch = 0.6813s	
23560/28500 (epoch 41.333), train_loss = 0.65135967, grad/param norm = 1.7737e-01, time/batch = 0.6770s	
23561/28500 (epoch 41.335), train_loss = 0.72701350, grad/param norm = 1.7714e-01, time/batch = 0.6798s	
23562/28500 (epoch 41.337), train_loss = 0.68154081, grad/param norm = 1.6944e-01, time/batch = 0.6795s	
23563/28500 (epoch 41.339), train_loss = 0.67668233, grad/param norm = 1.4512e-01, time/batch = 0.6898s	
23564/28500 (epoch 41.340), train_loss = 0.81406862, grad/param norm = 2.2418e-01, time/batch = 0.6762s	
23565/28500 (epoch 41.342), train_loss = 0.81110481, grad/param norm = 1.8171e-01, time/batch = 0.6765s	
23566/28500 (epoch 41.344), train_loss = 0.70907315, grad/param norm = 2.0645e-01, time/batch = 0.6755s	
23567/28500 (epoch 41.346), train_loss = 0.69359254, grad/param norm = 1.5856e-01, time/batch = 0.6800s	
23568/28500 (epoch 41.347), train_loss = 0.82213876, grad/param norm = 1.5919e-01, time/batch = 0.6753s	
23569/28500 (epoch 41.349), train_loss = 0.82880707, grad/param norm = 1.8025e-01, time/batch = 0.6773s	
23570/28500 (epoch 41.351), train_loss = 0.73196081, grad/param norm = 1.7185e-01, time/batch = 0.6851s	
23571/28500 (epoch 41.353), train_loss = 0.84347079, grad/param norm = 1.9036e-01, time/batch = 0.6923s	
23572/28500 (epoch 41.354), train_loss = 0.72582603, grad/param norm = 1.8268e-01, time/batch = 0.6763s	
23573/28500 (epoch 41.356), train_loss = 0.77565227, grad/param norm = 1.6859e-01, time/batch = 0.6778s	
23574/28500 (epoch 41.358), train_loss = 0.85928938, grad/param norm = 1.8047e-01, time/batch = 0.6757s	
23575/28500 (epoch 41.360), train_loss = 0.83109049, grad/param norm = 1.9157e-01, time/batch = 0.6761s	
23576/28500 (epoch 41.361), train_loss = 0.73830301, grad/param norm = 1.7314e-01, time/batch = 0.6771s	
23577/28500 (epoch 41.363), train_loss = 0.71913557, grad/param norm = 1.6000e-01, time/batch = 0.6758s	
23578/28500 (epoch 41.365), train_loss = 0.76617429, grad/param norm = 1.7989e-01, time/batch = 0.6910s	
23579/28500 (epoch 41.367), train_loss = 0.82131026, grad/param norm = 1.9700e-01, time/batch = 0.6811s	
23580/28500 (epoch 41.368), train_loss = 0.76291468, grad/param norm = 1.9905e-01, time/batch = 0.6753s	
23581/28500 (epoch 41.370), train_loss = 0.83416437, grad/param norm = 2.2396e-01, time/batch = 0.6796s	
23582/28500 (epoch 41.372), train_loss = 0.66362704, grad/param norm = 2.0190e-01, time/batch = 0.6771s	
23583/28500 (epoch 41.374), train_loss = 0.78569099, grad/param norm = 2.0043e-01, time/batch = 0.6784s	
23584/28500 (epoch 41.375), train_loss = 0.90795431, grad/param norm = 2.0055e-01, time/batch = 0.6761s	
23585/28500 (epoch 41.377), train_loss = 0.75194390, grad/param norm = 2.3622e-01, time/batch = 0.6776s	
23586/28500 (epoch 41.379), train_loss = 0.63851055, grad/param norm = 1.6626e-01, time/batch = 0.6902s	
23587/28500 (epoch 41.381), train_loss = 0.79737363, grad/param norm = 1.8038e-01, time/batch = 0.6776s	
23588/28500 (epoch 41.382), train_loss = 0.77730898, grad/param norm = 2.0393e-01, time/batch = 0.6753s	
23589/28500 (epoch 41.384), train_loss = 0.68386598, grad/param norm = 1.7405e-01, time/batch = 0.6789s	
23590/28500 (epoch 41.386), train_loss = 0.72539935, grad/param norm = 1.7529e-01, time/batch = 0.6755s	
23591/28500 (epoch 41.388), train_loss = 0.89634822, grad/param norm = 2.1065e-01, time/batch = 0.6823s	
23592/28500 (epoch 41.389), train_loss = 0.73366102, grad/param norm = 2.1501e-01, time/batch = 0.6788s	
23593/28500 (epoch 41.391), train_loss = 0.71669555, grad/param norm = 1.9482e-01, time/batch = 0.7102s	
23594/28500 (epoch 41.393), train_loss = 0.71275574, grad/param norm = 1.7356e-01, time/batch = 0.6856s	
23595/28500 (epoch 41.395), train_loss = 0.89905195, grad/param norm = 1.8772e-01, time/batch = 0.6801s	
23596/28500 (epoch 41.396), train_loss = 0.88280237, grad/param norm = 2.0888e-01, time/batch = 0.6823s	
23597/28500 (epoch 41.398), train_loss = 0.60016141, grad/param norm = 1.7242e-01, time/batch = 0.6840s	
23598/28500 (epoch 41.400), train_loss = 0.76859331, grad/param norm = 1.9795e-01, time/batch = 0.6756s	
23599/28500 (epoch 41.402), train_loss = 0.81936317, grad/param norm = 1.9473e-01, time/batch = 0.6786s	
23600/28500 (epoch 41.404), train_loss = 0.82157107, grad/param norm = 2.1783e-01, time/batch = 0.6781s	
23601/28500 (epoch 41.405), train_loss = 0.87123312, grad/param norm = 2.0149e-01, time/batch = 0.6960s	
23602/28500 (epoch 41.407), train_loss = 0.81712364, grad/param norm = 1.8960e-01, time/batch = 0.6781s	
23603/28500 (epoch 41.409), train_loss = 0.81939004, grad/param norm = 2.0161e-01, time/batch = 0.6794s	
23604/28500 (epoch 41.411), train_loss = 0.89689102, grad/param norm = 2.0145e-01, time/batch = 0.6792s	
23605/28500 (epoch 41.412), train_loss = 0.91194196, grad/param norm = 2.0673e-01, time/batch = 0.6781s	
23606/28500 (epoch 41.414), train_loss = 0.82443726, grad/param norm = 1.9845e-01, time/batch = 0.6756s	
23607/28500 (epoch 41.416), train_loss = 0.73589412, grad/param norm = 1.6930e-01, time/batch = 0.6766s	
23608/28500 (epoch 41.418), train_loss = 0.82937308, grad/param norm = 1.7053e-01, time/batch = 0.6785s	
23609/28500 (epoch 41.419), train_loss = 0.92273213, grad/param norm = 2.2734e-01, time/batch = 0.6927s	
23610/28500 (epoch 41.421), train_loss = 0.87420715, grad/param norm = 1.8374e-01, time/batch = 0.6852s	
23611/28500 (epoch 41.423), train_loss = 0.87619303, grad/param norm = 2.2378e-01, time/batch = 0.6854s	
23612/28500 (epoch 41.425), train_loss = 0.77895143, grad/param norm = 2.2203e-01, time/batch = 0.6832s	
23613/28500 (epoch 41.426), train_loss = 0.84913798, grad/param norm = 2.2842e-01, time/batch = 0.6784s	
23614/28500 (epoch 41.428), train_loss = 0.99112326, grad/param norm = 2.2344e-01, time/batch = 0.6820s	
23615/28500 (epoch 41.430), train_loss = 0.95272984, grad/param norm = 2.0691e-01, time/batch = 0.6763s	
23616/28500 (epoch 41.432), train_loss = 0.83692715, grad/param norm = 1.8638e-01, time/batch = 0.6878s	
23617/28500 (epoch 41.433), train_loss = 0.88775647, grad/param norm = 2.0045e-01, time/batch = 0.6883s	
23618/28500 (epoch 41.435), train_loss = 0.83135945, grad/param norm = 1.9839e-01, time/batch = 0.6765s	
23619/28500 (epoch 41.437), train_loss = 0.76803388, grad/param norm = 1.7358e-01, time/batch = 0.6783s	
23620/28500 (epoch 41.439), train_loss = 0.82604147, grad/param norm = 1.7408e-01, time/batch = 0.6763s	
23621/28500 (epoch 41.440), train_loss = 0.97292278, grad/param norm = 1.9378e-01, time/batch = 0.6787s	
23622/28500 (epoch 41.442), train_loss = 0.76779081, grad/param norm = 1.9690e-01, time/batch = 0.6758s	
23623/28500 (epoch 41.444), train_loss = 0.72765788, grad/param norm = 1.5550e-01, time/batch = 0.6783s	
23624/28500 (epoch 41.446), train_loss = 0.69228486, grad/param norm = 1.6587e-01, time/batch = 0.6774s	
23625/28500 (epoch 41.447), train_loss = 0.70860249, grad/param norm = 1.7233e-01, time/batch = 0.6860s	
23626/28500 (epoch 41.449), train_loss = 0.77441091, grad/param norm = 1.7785e-01, time/batch = 0.6790s	
23627/28500 (epoch 41.451), train_loss = 0.79215734, grad/param norm = 1.7463e-01, time/batch = 0.6820s	
23628/28500 (epoch 41.453), train_loss = 0.77184583, grad/param norm = 1.7360e-01, time/batch = 0.6756s	
23629/28500 (epoch 41.454), train_loss = 0.72247492, grad/param norm = 1.5905e-01, time/batch = 0.6757s	
23630/28500 (epoch 41.456), train_loss = 0.87952084, grad/param norm = 2.0497e-01, time/batch = 0.6770s	
23631/28500 (epoch 41.458), train_loss = 0.78093425, grad/param norm = 1.9084e-01, time/batch = 0.6898s	
23632/28500 (epoch 41.460), train_loss = 0.89139860, grad/param norm = 1.9396e-01, time/batch = 0.6773s	
23633/28500 (epoch 41.461), train_loss = 0.74438436, grad/param norm = 1.7899e-01, time/batch = 0.6784s	
23634/28500 (epoch 41.463), train_loss = 0.68635282, grad/param norm = 1.5115e-01, time/batch = 0.6802s	
23635/28500 (epoch 41.465), train_loss = 0.65628774, grad/param norm = 2.2403e-01, time/batch = 0.6852s	
23636/28500 (epoch 41.467), train_loss = 0.80602405, grad/param norm = 1.6875e-01, time/batch = 0.6817s	
23637/28500 (epoch 41.468), train_loss = 0.72419813, grad/param norm = 1.6675e-01, time/batch = 0.6774s	
23638/28500 (epoch 41.470), train_loss = 0.77060026, grad/param norm = 2.0268e-01, time/batch = 0.6755s	
23639/28500 (epoch 41.472), train_loss = 0.72048753, grad/param norm = 1.6051e-01, time/batch = 0.6762s	
23640/28500 (epoch 41.474), train_loss = 0.95943000, grad/param norm = 1.9967e-01, time/batch = 0.6794s	
23641/28500 (epoch 41.475), train_loss = 0.75668812, grad/param norm = 1.9809e-01, time/batch = 0.6940s	
23642/28500 (epoch 41.477), train_loss = 0.79676124, grad/param norm = 1.8630e-01, time/batch = 0.6925s	
23643/28500 (epoch 41.479), train_loss = 0.84905636, grad/param norm = 1.9159e-01, time/batch = 0.6834s	
23644/28500 (epoch 41.481), train_loss = 0.85984243, grad/param norm = 2.2255e-01, time/batch = 0.6784s	
23645/28500 (epoch 41.482), train_loss = 0.70688606, grad/param norm = 1.7003e-01, time/batch = 0.6759s	
23646/28500 (epoch 41.484), train_loss = 0.75412073, grad/param norm = 2.0699e-01, time/batch = 0.6793s	
23647/28500 (epoch 41.486), train_loss = 0.64425085, grad/param norm = 1.7860e-01, time/batch = 0.7003s	
23648/28500 (epoch 41.488), train_loss = 0.84372826, grad/param norm = 1.7388e-01, time/batch = 0.7157s	
23649/28500 (epoch 41.489), train_loss = 0.93561467, grad/param norm = 1.9274e-01, time/batch = 0.7098s	
23650/28500 (epoch 41.491), train_loss = 0.74102976, grad/param norm = 1.8047e-01, time/batch = 0.7046s	
23651/28500 (epoch 41.493), train_loss = 0.79810403, grad/param norm = 2.0310e-01, time/batch = 0.7146s	
23652/28500 (epoch 41.495), train_loss = 0.81389957, grad/param norm = 2.0816e-01, time/batch = 0.7066s	
23653/28500 (epoch 41.496), train_loss = 0.73062008, grad/param norm = 2.1700e-01, time/batch = 0.7101s	
23654/28500 (epoch 41.498), train_loss = 0.78853101, grad/param norm = 1.7987e-01, time/batch = 0.7004s	
23655/28500 (epoch 41.500), train_loss = 0.74860579, grad/param norm = 1.7615e-01, time/batch = 0.7026s	
23656/28500 (epoch 41.502), train_loss = 0.84663765, grad/param norm = 1.6750e-01, time/batch = 0.6946s	
23657/28500 (epoch 41.504), train_loss = 0.86912556, grad/param norm = 1.7903e-01, time/batch = 0.6993s	
23658/28500 (epoch 41.505), train_loss = 0.75736289, grad/param norm = 1.7659e-01, time/batch = 0.7024s	
23659/28500 (epoch 41.507), train_loss = 0.89562262, grad/param norm = 2.3835e-01, time/batch = 0.6966s	
23660/28500 (epoch 41.509), train_loss = 0.79898876, grad/param norm = 1.6929e-01, time/batch = 0.6922s	
23661/28500 (epoch 41.511), train_loss = 0.80335135, grad/param norm = 1.9468e-01, time/batch = 0.7046s	
23662/28500 (epoch 41.512), train_loss = 0.84729086, grad/param norm = 1.8211e-01, time/batch = 0.6935s	
23663/28500 (epoch 41.514), train_loss = 0.79144409, grad/param norm = 1.7471e-01, time/batch = 0.6992s	
23664/28500 (epoch 41.516), train_loss = 0.79244865, grad/param norm = 1.6576e-01, time/batch = 0.6968s	
23665/28500 (epoch 41.518), train_loss = 0.85589078, grad/param norm = 1.9825e-01, time/batch = 0.6950s	
23666/28500 (epoch 41.519), train_loss = 0.84053153, grad/param norm = 1.8407e-01, time/batch = 0.6938s	
23667/28500 (epoch 41.521), train_loss = 0.92687265, grad/param norm = 2.1730e-01, time/batch = 0.6953s	
23668/28500 (epoch 41.523), train_loss = 0.85868731, grad/param norm = 1.9813e-01, time/batch = 0.6955s	
23669/28500 (epoch 41.525), train_loss = 0.94024578, grad/param norm = 2.0631e-01, time/batch = 0.6972s	
23670/28500 (epoch 41.526), train_loss = 0.86224265, grad/param norm = 1.9706e-01, time/batch = 0.6953s	
23671/28500 (epoch 41.528), train_loss = 0.85885886, grad/param norm = 2.1200e-01, time/batch = 0.6942s	
23672/28500 (epoch 41.530), train_loss = 0.86973568, grad/param norm = 1.8435e-01, time/batch = 0.6983s	
23673/28500 (epoch 41.532), train_loss = 0.79461151, grad/param norm = 1.7969e-01, time/batch = 0.6917s	
23674/28500 (epoch 41.533), train_loss = 0.84947863, grad/param norm = 1.9120e-01, time/batch = 0.6956s	
23675/28500 (epoch 41.535), train_loss = 0.70379726, grad/param norm = 1.4836e-01, time/batch = 0.6931s	
23676/28500 (epoch 41.537), train_loss = 0.70290494, grad/param norm = 1.7399e-01, time/batch = 0.6950s	
23677/28500 (epoch 41.539), train_loss = 0.68961022, grad/param norm = 1.5847e-01, time/batch = 0.6942s	
23678/28500 (epoch 41.540), train_loss = 0.79383780, grad/param norm = 1.7089e-01, time/batch = 0.6960s	
23679/28500 (epoch 41.542), train_loss = 0.84069721, grad/param norm = 1.9247e-01, time/batch = 0.6986s	
23680/28500 (epoch 41.544), train_loss = 0.95307414, grad/param norm = 1.9935e-01, time/batch = 0.7001s	
23681/28500 (epoch 41.546), train_loss = 0.80904752, grad/param norm = 1.9401e-01, time/batch = 0.6989s	
23682/28500 (epoch 41.547), train_loss = 0.80406559, grad/param norm = 1.8322e-01, time/batch = 0.6981s	
23683/28500 (epoch 41.549), train_loss = 0.68825230, grad/param norm = 1.6189e-01, time/batch = 0.6945s	
23684/28500 (epoch 41.551), train_loss = 0.75428350, grad/param norm = 1.9481e-01, time/batch = 0.6951s	
23685/28500 (epoch 41.553), train_loss = 0.94883429, grad/param norm = 2.1370e-01, time/batch = 0.6977s	
23686/28500 (epoch 41.554), train_loss = 0.85351915, grad/param norm = 1.9314e-01, time/batch = 0.6981s	
23687/28500 (epoch 41.556), train_loss = 0.84384809, grad/param norm = 1.8503e-01, time/batch = 0.6980s	
23688/28500 (epoch 41.558), train_loss = 0.87765579, grad/param norm = 1.8073e-01, time/batch = 0.6927s	
23689/28500 (epoch 41.560), train_loss = 0.86436035, grad/param norm = 1.9192e-01, time/batch = 0.6982s	
23690/28500 (epoch 41.561), train_loss = 0.88038725, grad/param norm = 1.9593e-01, time/batch = 0.6973s	
23691/28500 (epoch 41.563), train_loss = 0.95257379, grad/param norm = 2.2999e-01, time/batch = 0.6981s	
23692/28500 (epoch 41.565), train_loss = 0.75700308, grad/param norm = 2.1865e-01, time/batch = 0.6976s	
23693/28500 (epoch 41.567), train_loss = 0.69941251, grad/param norm = 1.6875e-01, time/batch = 0.6952s	
23694/28500 (epoch 41.568), train_loss = 0.83742801, grad/param norm = 1.9091e-01, time/batch = 0.6979s	
23695/28500 (epoch 41.570), train_loss = 0.78794399, grad/param norm = 1.9981e-01, time/batch = 0.6963s	
23696/28500 (epoch 41.572), train_loss = 0.83604249, grad/param norm = 1.8304e-01, time/batch = 0.6959s	
23697/28500 (epoch 41.574), train_loss = 0.76271352, grad/param norm = 1.8227e-01, time/batch = 0.6982s	
23698/28500 (epoch 41.575), train_loss = 0.76426365, grad/param norm = 1.7365e-01, time/batch = 0.6945s	
23699/28500 (epoch 41.577), train_loss = 0.88562787, grad/param norm = 2.0260e-01, time/batch = 0.6955s	
23700/28500 (epoch 41.579), train_loss = 0.89531483, grad/param norm = 2.0947e-01, time/batch = 0.6980s	
23701/28500 (epoch 41.581), train_loss = 0.75348118, grad/param norm = 2.1855e-01, time/batch = 0.7044s	
23702/28500 (epoch 41.582), train_loss = 0.92192301, grad/param norm = 2.0216e-01, time/batch = 0.6964s	
23703/28500 (epoch 41.584), train_loss = 0.75611404, grad/param norm = 1.8928e-01, time/batch = 0.6997s	
23704/28500 (epoch 41.586), train_loss = 0.74224424, grad/param norm = 1.7113e-01, time/batch = 0.6992s	
23705/28500 (epoch 41.588), train_loss = 0.76079404, grad/param norm = 2.0563e-01, time/batch = 0.6984s	
23706/28500 (epoch 41.589), train_loss = 0.79872125, grad/param norm = 1.8210e-01, time/batch = 0.6958s	
23707/28500 (epoch 41.591), train_loss = 0.83772389, grad/param norm = 2.6267e-01, time/batch = 0.7082s	
23708/28500 (epoch 41.593), train_loss = 0.76652570, grad/param norm = 1.7149e-01, time/batch = 0.6986s	
23709/28500 (epoch 41.595), train_loss = 0.97323192, grad/param norm = 2.2650e-01, time/batch = 0.7014s	
23710/28500 (epoch 41.596), train_loss = 0.98185470, grad/param norm = 1.9331e-01, time/batch = 0.6979s	
23711/28500 (epoch 41.598), train_loss = 0.81143986, grad/param norm = 2.0345e-01, time/batch = 0.7048s	
23712/28500 (epoch 41.600), train_loss = 0.79002121, grad/param norm = 1.9272e-01, time/batch = 0.6979s	
23713/28500 (epoch 41.602), train_loss = 0.89001010, grad/param norm = 2.4428e-01, time/batch = 0.7009s	
23714/28500 (epoch 41.604), train_loss = 0.89760062, grad/param norm = 1.7323e-01, time/batch = 0.7005s	
23715/28500 (epoch 41.605), train_loss = 0.89941455, grad/param norm = 1.8940e-01, time/batch = 0.6980s	
23716/28500 (epoch 41.607), train_loss = 0.93199175, grad/param norm = 1.8369e-01, time/batch = 0.6989s	
23717/28500 (epoch 41.609), train_loss = 0.84107924, grad/param norm = 1.7755e-01, time/batch = 0.7007s	
23718/28500 (epoch 41.611), train_loss = 0.83190984, grad/param norm = 2.0988e-01, time/batch = 0.6980s	
23719/28500 (epoch 41.612), train_loss = 0.87763061, grad/param norm = 2.2246e-01, time/batch = 0.6986s	
23720/28500 (epoch 41.614), train_loss = 0.90430676, grad/param norm = 1.9233e-01, time/batch = 0.6979s	
23721/28500 (epoch 41.616), train_loss = 0.78109487, grad/param norm = 1.8629e-01, time/batch = 0.7021s	
23722/28500 (epoch 41.618), train_loss = 0.80769379, grad/param norm = 1.9885e-01, time/batch = 0.6983s	
23723/28500 (epoch 41.619), train_loss = 0.89673554, grad/param norm = 2.2737e-01, time/batch = 0.7036s	
23724/28500 (epoch 41.621), train_loss = 0.66440101, grad/param norm = 1.6971e-01, time/batch = 0.6992s	
23725/28500 (epoch 41.623), train_loss = 0.95208990, grad/param norm = 2.1031e-01, time/batch = 0.6979s	
23726/28500 (epoch 41.625), train_loss = 0.74693605, grad/param norm = 1.8749e-01, time/batch = 0.7003s	
23727/28500 (epoch 41.626), train_loss = 0.66149213, grad/param norm = 1.6478e-01, time/batch = 0.6961s	
23728/28500 (epoch 41.628), train_loss = 0.75584909, grad/param norm = 1.8034e-01, time/batch = 0.6977s	
23729/28500 (epoch 41.630), train_loss = 0.72185973, grad/param norm = 1.6961e-01, time/batch = 0.7016s	
23730/28500 (epoch 41.632), train_loss = 0.91251550, grad/param norm = 2.0392e-01, time/batch = 0.6997s	
23731/28500 (epoch 41.633), train_loss = 0.95872617, grad/param norm = 1.7839e-01, time/batch = 0.7027s	
23732/28500 (epoch 41.635), train_loss = 0.85440303, grad/param norm = 2.1213e-01, time/batch = 0.6997s	
23733/28500 (epoch 41.637), train_loss = 0.84024453, grad/param norm = 1.8289e-01, time/batch = 0.7011s	
23734/28500 (epoch 41.639), train_loss = 0.73754616, grad/param norm = 1.9821e-01, time/batch = 0.6966s	
23735/28500 (epoch 41.640), train_loss = 0.77077664, grad/param norm = 1.7241e-01, time/batch = 0.7016s	
23736/28500 (epoch 41.642), train_loss = 0.77300650, grad/param norm = 1.7718e-01, time/batch = 0.6977s	
23737/28500 (epoch 41.644), train_loss = 0.84502061, grad/param norm = 1.9723e-01, time/batch = 0.6995s	
23738/28500 (epoch 41.646), train_loss = 0.68307548, grad/param norm = 1.5404e-01, time/batch = 0.6975s	
23739/28500 (epoch 41.647), train_loss = 0.77152015, grad/param norm = 1.8898e-01, time/batch = 0.6962s	
23740/28500 (epoch 41.649), train_loss = 0.75896823, grad/param norm = 1.8989e-01, time/batch = 0.6984s	
23741/28500 (epoch 41.651), train_loss = 0.70997354, grad/param norm = 1.4511e-01, time/batch = 0.6989s	
23742/28500 (epoch 41.653), train_loss = 0.69921769, grad/param norm = 1.7343e-01, time/batch = 0.7006s	
23743/28500 (epoch 41.654), train_loss = 0.74445208, grad/param norm = 1.9114e-01, time/batch = 0.6982s	
23744/28500 (epoch 41.656), train_loss = 0.69504474, grad/param norm = 1.9679e-01, time/batch = 0.6981s	
23745/28500 (epoch 41.658), train_loss = 0.81922328, grad/param norm = 1.9595e-01, time/batch = 0.7005s	
23746/28500 (epoch 41.660), train_loss = 0.81303958, grad/param norm = 1.6723e-01, time/batch = 0.6996s	
23747/28500 (epoch 41.661), train_loss = 0.90015369, grad/param norm = 2.1591e-01, time/batch = 0.7017s	
23748/28500 (epoch 41.663), train_loss = 0.90784252, grad/param norm = 2.0642e-01, time/batch = 0.6994s	
23749/28500 (epoch 41.665), train_loss = 0.82797215, grad/param norm = 2.0421e-01, time/batch = 0.7045s	
23750/28500 (epoch 41.667), train_loss = 0.83496821, grad/param norm = 2.1174e-01, time/batch = 0.7014s	
23751/28500 (epoch 41.668), train_loss = 0.81824893, grad/param norm = 1.9079e-01, time/batch = 0.7005s	
23752/28500 (epoch 41.670), train_loss = 0.82278610, grad/param norm = 1.8387e-01, time/batch = 0.6987s	
23753/28500 (epoch 41.672), train_loss = 0.74717077, grad/param norm = 1.7654e-01, time/batch = 0.7005s	
23754/28500 (epoch 41.674), train_loss = 0.64149997, grad/param norm = 1.7581e-01, time/batch = 0.6976s	
23755/28500 (epoch 41.675), train_loss = 0.69080367, grad/param norm = 1.9682e-01, time/batch = 0.7006s	
23756/28500 (epoch 41.677), train_loss = 0.76541376, grad/param norm = 1.7227e-01, time/batch = 0.6993s	
23757/28500 (epoch 41.679), train_loss = 0.77747762, grad/param norm = 1.8872e-01, time/batch = 0.6986s	
23758/28500 (epoch 41.681), train_loss = 0.85462187, grad/param norm = 1.9203e-01, time/batch = 0.6990s	
23759/28500 (epoch 41.682), train_loss = 0.77836044, grad/param norm = 1.9498e-01, time/batch = 0.6975s	
23760/28500 (epoch 41.684), train_loss = 0.80543029, grad/param norm = 1.8120e-01, time/batch = 0.6978s	
23761/28500 (epoch 41.686), train_loss = 0.77392633, grad/param norm = 1.7890e-01, time/batch = 0.7004s	
23762/28500 (epoch 41.688), train_loss = 0.72965176, grad/param norm = 1.5226e-01, time/batch = 0.7025s	
23763/28500 (epoch 41.689), train_loss = 0.75246015, grad/param norm = 2.0598e-01, time/batch = 0.7020s	
23764/28500 (epoch 41.691), train_loss = 0.83843354, grad/param norm = 1.8501e-01, time/batch = 0.7010s	
23765/28500 (epoch 41.693), train_loss = 0.77321311, grad/param norm = 1.7793e-01, time/batch = 0.7063s	
23766/28500 (epoch 41.695), train_loss = 0.60395037, grad/param norm = 1.8922e-01, time/batch = 0.6953s	
23767/28500 (epoch 41.696), train_loss = 0.77187338, grad/param norm = 1.9506e-01, time/batch = 0.6931s	
23768/28500 (epoch 41.698), train_loss = 0.84415343, grad/param norm = 1.8435e-01, time/batch = 0.7014s	
23769/28500 (epoch 41.700), train_loss = 0.82280186, grad/param norm = 2.0299e-01, time/batch = 0.6949s	
23770/28500 (epoch 41.702), train_loss = 0.78022359, grad/param norm = 1.9549e-01, time/batch = 0.6956s	
23771/28500 (epoch 41.704), train_loss = 0.86374422, grad/param norm = 1.9916e-01, time/batch = 0.6951s	
23772/28500 (epoch 41.705), train_loss = 0.86539051, grad/param norm = 2.2568e-01, time/batch = 0.6956s	
23773/28500 (epoch 41.707), train_loss = 0.74872756, grad/param norm = 2.1000e-01, time/batch = 0.6944s	
23774/28500 (epoch 41.709), train_loss = 0.94930461, grad/param norm = 2.0143e-01, time/batch = 0.7140s	
23775/28500 (epoch 41.711), train_loss = 0.75425235, grad/param norm = 1.9157e-01, time/batch = 0.7019s	
23776/28500 (epoch 41.712), train_loss = 0.83488450, grad/param norm = 1.7461e-01, time/batch = 0.6964s	
23777/28500 (epoch 41.714), train_loss = 0.90744325, grad/param norm = 1.9748e-01, time/batch = 0.6939s	
23778/28500 (epoch 41.716), train_loss = 0.78498334, grad/param norm = 1.8085e-01, time/batch = 0.6961s	
23779/28500 (epoch 41.718), train_loss = 0.81899175, grad/param norm = 1.7683e-01, time/batch = 0.6982s	
23780/28500 (epoch 41.719), train_loss = 0.83478470, grad/param norm = 1.8593e-01, time/batch = 0.6957s	
23781/28500 (epoch 41.721), train_loss = 0.61624981, grad/param norm = 1.5664e-01, time/batch = 0.6996s	
23782/28500 (epoch 41.723), train_loss = 0.79490756, grad/param norm = 1.8271e-01, time/batch = 0.6964s	
23783/28500 (epoch 41.725), train_loss = 0.87447472, grad/param norm = 2.0499e-01, time/batch = 0.6953s	
23784/28500 (epoch 41.726), train_loss = 0.80017346, grad/param norm = 1.9498e-01, time/batch = 0.6975s	
23785/28500 (epoch 41.728), train_loss = 0.72842997, grad/param norm = 1.7326e-01, time/batch = 0.6946s	
23786/28500 (epoch 41.730), train_loss = 0.81043233, grad/param norm = 2.1152e-01, time/batch = 0.6940s	
23787/28500 (epoch 41.732), train_loss = 0.64935297, grad/param norm = 1.6172e-01, time/batch = 0.6944s	
23788/28500 (epoch 41.733), train_loss = 0.68201150, grad/param norm = 1.7892e-01, time/batch = 0.6945s	
23789/28500 (epoch 41.735), train_loss = 0.69153271, grad/param norm = 1.7840e-01, time/batch = 0.6952s	
23790/28500 (epoch 41.737), train_loss = 0.62846724, grad/param norm = 1.7623e-01, time/batch = 0.6940s	
23791/28500 (epoch 41.739), train_loss = 0.70176287, grad/param norm = 1.9970e-01, time/batch = 0.6973s	
23792/28500 (epoch 41.740), train_loss = 0.80366499, grad/param norm = 1.7926e-01, time/batch = 0.6999s	
23793/28500 (epoch 41.742), train_loss = 0.72403618, grad/param norm = 2.0927e-01, time/batch = 0.6995s	
23794/28500 (epoch 41.744), train_loss = 0.79544166, grad/param norm = 1.7611e-01, time/batch = 0.6947s	
23795/28500 (epoch 41.746), train_loss = 0.75277339, grad/param norm = 1.7234e-01, time/batch = 0.6993s	
23796/28500 (epoch 41.747), train_loss = 0.76351882, grad/param norm = 1.8485e-01, time/batch = 0.6975s	
23797/28500 (epoch 41.749), train_loss = 0.85919952, grad/param norm = 2.8061e-01, time/batch = 0.6946s	
23798/28500 (epoch 41.751), train_loss = 0.72272819, grad/param norm = 2.1967e-01, time/batch = 0.6946s	
23799/28500 (epoch 41.753), train_loss = 0.79605850, grad/param norm = 1.6608e-01, time/batch = 0.6936s	
23800/28500 (epoch 41.754), train_loss = 0.71543890, grad/param norm = 2.1827e-01, time/batch = 0.6954s	
23801/28500 (epoch 41.756), train_loss = 0.93920406, grad/param norm = 2.0550e-01, time/batch = 0.6973s	
23802/28500 (epoch 41.758), train_loss = 0.83888524, grad/param norm = 2.2349e-01, time/batch = 0.6955s	
23803/28500 (epoch 41.760), train_loss = 0.69771158, grad/param norm = 1.6773e-01, time/batch = 0.6932s	
23804/28500 (epoch 41.761), train_loss = 0.74646525, grad/param norm = 1.9006e-01, time/batch = 0.6946s	
23805/28500 (epoch 41.763), train_loss = 0.62268660, grad/param norm = 1.5894e-01, time/batch = 0.6931s	
23806/28500 (epoch 41.765), train_loss = 0.76951524, grad/param norm = 1.6599e-01, time/batch = 0.6942s	
23807/28500 (epoch 41.767), train_loss = 0.64392933, grad/param norm = 1.4921e-01, time/batch = 0.6933s	
23808/28500 (epoch 41.768), train_loss = 0.83291757, grad/param norm = 1.8269e-01, time/batch = 0.6942s	
23809/28500 (epoch 41.770), train_loss = 0.68835191, grad/param norm = 1.6883e-01, time/batch = 0.6946s	
23810/28500 (epoch 41.772), train_loss = 0.63908512, grad/param norm = 1.4719e-01, time/batch = 0.6931s	
23811/28500 (epoch 41.774), train_loss = 0.78525094, grad/param norm = 1.6837e-01, time/batch = 0.6976s	
23812/28500 (epoch 41.775), train_loss = 0.83705649, grad/param norm = 1.8458e-01, time/batch = 0.6997s	
23813/28500 (epoch 41.777), train_loss = 0.85576651, grad/param norm = 1.6392e-01, time/batch = 0.6968s	
23814/28500 (epoch 41.779), train_loss = 0.66621091, grad/param norm = 1.4997e-01, time/batch = 0.6969s	
23815/28500 (epoch 41.781), train_loss = 0.77992709, grad/param norm = 2.1236e-01, time/batch = 0.6943s	
23816/28500 (epoch 41.782), train_loss = 0.83676285, grad/param norm = 2.0882e-01, time/batch = 0.6960s	
23817/28500 (epoch 41.784), train_loss = 0.63742682, grad/param norm = 1.7330e-01, time/batch = 0.6943s	
23818/28500 (epoch 41.786), train_loss = 0.65033086, grad/param norm = 1.5617e-01, time/batch = 0.6940s	
23819/28500 (epoch 41.788), train_loss = 0.74642419, grad/param norm = 2.1232e-01, time/batch = 0.6939s	
23820/28500 (epoch 41.789), train_loss = 0.59381881, grad/param norm = 2.0796e-01, time/batch = 0.6934s	
23821/28500 (epoch 41.791), train_loss = 0.80201928, grad/param norm = 1.7047e-01, time/batch = 0.6999s	
23822/28500 (epoch 41.793), train_loss = 0.76204597, grad/param norm = 1.7583e-01, time/batch = 0.6965s	
23823/28500 (epoch 41.795), train_loss = 0.78274468, grad/param norm = 1.7439e-01, time/batch = 0.6943s	
23824/28500 (epoch 41.796), train_loss = 0.70813724, grad/param norm = 2.0629e-01, time/batch = 0.6946s	
23825/28500 (epoch 41.798), train_loss = 0.66418971, grad/param norm = 1.8507e-01, time/batch = 0.6939s	
23826/28500 (epoch 41.800), train_loss = 0.64796007, grad/param norm = 2.1575e-01, time/batch = 0.6935s	
23827/28500 (epoch 41.802), train_loss = 0.74484346, grad/param norm = 2.2551e-01, time/batch = 0.6948s	
23828/28500 (epoch 41.804), train_loss = 0.81777472, grad/param norm = 1.6894e-01, time/batch = 0.6957s	
23829/28500 (epoch 41.805), train_loss = 0.81784193, grad/param norm = 2.0000e-01, time/batch = 0.6957s	
23830/28500 (epoch 41.807), train_loss = 0.80639811, grad/param norm = 1.9711e-01, time/batch = 0.6946s	
23831/28500 (epoch 41.809), train_loss = 0.78119392, grad/param norm = 3.4079e-01, time/batch = 0.6957s	
23832/28500 (epoch 41.811), train_loss = 0.81760750, grad/param norm = 2.1969e-01, time/batch = 0.6955s	
23833/28500 (epoch 41.812), train_loss = 0.77206936, grad/param norm = 2.0148e-01, time/batch = 0.6949s	
23834/28500 (epoch 41.814), train_loss = 0.74377146, grad/param norm = 1.9367e-01, time/batch = 0.6956s	
23835/28500 (epoch 41.816), train_loss = 0.81476060, grad/param norm = 2.2624e-01, time/batch = 0.6981s	
23836/28500 (epoch 41.818), train_loss = 0.90930258, grad/param norm = 1.9125e-01, time/batch = 0.6978s	
23837/28500 (epoch 41.819), train_loss = 0.81119494, grad/param norm = 1.9388e-01, time/batch = 0.6993s	
23838/28500 (epoch 41.821), train_loss = 0.75541465, grad/param norm = 1.8607e-01, time/batch = 0.6958s	
23839/28500 (epoch 41.823), train_loss = 0.90725181, grad/param norm = 2.3264e-01, time/batch = 0.7002s	
23840/28500 (epoch 41.825), train_loss = 0.70455809, grad/param norm = 1.7741e-01, time/batch = 0.6972s	
23841/28500 (epoch 41.826), train_loss = 0.80180907, grad/param norm = 1.8739e-01, time/batch = 0.7035s	
23842/28500 (epoch 41.828), train_loss = 0.71815684, grad/param norm = 1.9702e-01, time/batch = 0.7013s	
23843/28500 (epoch 41.830), train_loss = 0.73278678, grad/param norm = 1.4522e-01, time/batch = 0.7036s	
23844/28500 (epoch 41.832), train_loss = 0.75987562, grad/param norm = 2.0421e-01, time/batch = 0.7001s	
23845/28500 (epoch 41.833), train_loss = 0.81583332, grad/param norm = 1.7551e-01, time/batch = 0.6976s	
23846/28500 (epoch 41.835), train_loss = 0.73507491, grad/param norm = 2.1433e-01, time/batch = 0.6975s	
23847/28500 (epoch 41.837), train_loss = 0.68530558, grad/param norm = 2.0975e-01, time/batch = 0.6991s	
23848/28500 (epoch 41.839), train_loss = 0.94024326, grad/param norm = 2.5206e-01, time/batch = 0.7050s	
23849/28500 (epoch 41.840), train_loss = 0.93712867, grad/param norm = 2.4781e-01, time/batch = 0.6985s	
23850/28500 (epoch 41.842), train_loss = 0.85621633, grad/param norm = 2.1008e-01, time/batch = 0.7077s	
23851/28500 (epoch 41.844), train_loss = 0.86839600, grad/param norm = 1.8452e-01, time/batch = 0.7165s	
23852/28500 (epoch 41.846), train_loss = 0.94435591, grad/param norm = 2.3190e-01, time/batch = 0.6944s	
23853/28500 (epoch 41.847), train_loss = 0.74435449, grad/param norm = 2.1553e-01, time/batch = 0.6964s	
23854/28500 (epoch 41.849), train_loss = 0.76539219, grad/param norm = 1.8509e-01, time/batch = 0.6939s	
23855/28500 (epoch 41.851), train_loss = 0.72141623, grad/param norm = 1.8182e-01, time/batch = 0.6982s	
23856/28500 (epoch 41.853), train_loss = 0.83858179, grad/param norm = 2.3828e-01, time/batch = 0.6979s	
23857/28500 (epoch 41.854), train_loss = 0.80842897, grad/param norm = 1.9272e-01, time/batch = 0.7086s	
23858/28500 (epoch 41.856), train_loss = 0.90412263, grad/param norm = 2.7869e-01, time/batch = 0.7000s	
23859/28500 (epoch 41.858), train_loss = 0.74694484, grad/param norm = 1.7570e-01, time/batch = 0.6941s	
23860/28500 (epoch 41.860), train_loss = 0.79546996, grad/param norm = 2.1087e-01, time/batch = 0.7142s	
23861/28500 (epoch 41.861), train_loss = 0.89426054, grad/param norm = 2.2053e-01, time/batch = 0.7066s	
23862/28500 (epoch 41.863), train_loss = 0.82977762, grad/param norm = 2.2083e-01, time/batch = 0.7001s	
23863/28500 (epoch 41.865), train_loss = 0.74186330, grad/param norm = 2.0282e-01, time/batch = 0.6953s	
23864/28500 (epoch 41.867), train_loss = 0.80421138, grad/param norm = 2.0160e-01, time/batch = 0.6957s	
23865/28500 (epoch 41.868), train_loss = 0.71683228, grad/param norm = 1.8642e-01, time/batch = 0.6938s	
23866/28500 (epoch 41.870), train_loss = 0.67658170, grad/param norm = 1.8480e-01, time/batch = 0.6949s	
23867/28500 (epoch 41.872), train_loss = 0.87058688, grad/param norm = 2.2632e-01, time/batch = 0.6938s	
23868/28500 (epoch 41.874), train_loss = 0.72332194, grad/param norm = 2.6280e-01, time/batch = 0.6941s	
23869/28500 (epoch 41.875), train_loss = 0.96022839, grad/param norm = 2.9980e-01, time/batch = 0.6933s	
23870/28500 (epoch 41.877), train_loss = 0.82520876, grad/param norm = 1.9303e-01, time/batch = 0.6949s	
23871/28500 (epoch 41.879), train_loss = 0.86304083, grad/param norm = 1.7930e-01, time/batch = 0.6951s	
23872/28500 (epoch 41.881), train_loss = 0.83645273, grad/param norm = 1.9594e-01, time/batch = 0.6950s	
23873/28500 (epoch 41.882), train_loss = 0.72987046, grad/param norm = 1.8371e-01, time/batch = 0.6940s	
23874/28500 (epoch 41.884), train_loss = 0.76761269, grad/param norm = 2.0387e-01, time/batch = 0.6939s	
23875/28500 (epoch 41.886), train_loss = 0.75383201, grad/param norm = 1.9194e-01, time/batch = 0.6934s	
23876/28500 (epoch 41.888), train_loss = 0.76307781, grad/param norm = 1.6373e-01, time/batch = 0.6935s	
23877/28500 (epoch 41.889), train_loss = 0.81543315, grad/param norm = 1.6382e-01, time/batch = 0.6959s	
23878/28500 (epoch 41.891), train_loss = 0.80925535, grad/param norm = 2.0074e-01, time/batch = 0.6939s	
23879/28500 (epoch 41.893), train_loss = 0.75985228, grad/param norm = 1.7653e-01, time/batch = 0.6976s	
23880/28500 (epoch 41.895), train_loss = 0.95142032, grad/param norm = 2.2108e-01, time/batch = 0.6949s	
23881/28500 (epoch 41.896), train_loss = 0.91032424, grad/param norm = 2.2022e-01, time/batch = 0.6982s	
23882/28500 (epoch 41.898), train_loss = 0.85174805, grad/param norm = 1.8206e-01, time/batch = 0.6963s	
23883/28500 (epoch 41.900), train_loss = 0.70031985, grad/param norm = 1.6467e-01, time/batch = 0.6975s	
23884/28500 (epoch 41.902), train_loss = 0.66528314, grad/param norm = 1.7192e-01, time/batch = 0.6956s	
23885/28500 (epoch 41.904), train_loss = 0.71305116, grad/param norm = 1.7575e-01, time/batch = 0.6966s	
23886/28500 (epoch 41.905), train_loss = 0.75228768, grad/param norm = 1.9484e-01, time/batch = 0.7124s	
23887/28500 (epoch 41.907), train_loss = 0.77608919, grad/param norm = 1.7763e-01, time/batch = 0.6973s	
23888/28500 (epoch 41.909), train_loss = 0.65511346, grad/param norm = 1.9490e-01, time/batch = 0.6974s	
23889/28500 (epoch 41.911), train_loss = 0.70592728, grad/param norm = 1.7412e-01, time/batch = 0.6971s	
23890/28500 (epoch 41.912), train_loss = 0.59086844, grad/param norm = 1.6021e-01, time/batch = 0.6980s	
23891/28500 (epoch 41.914), train_loss = 0.80985415, grad/param norm = 1.7251e-01, time/batch = 0.7044s	
23892/28500 (epoch 41.916), train_loss = 0.79377465, grad/param norm = 1.8584e-01, time/batch = 0.6986s	
23893/28500 (epoch 41.918), train_loss = 0.76845344, grad/param norm = 1.8680e-01, time/batch = 0.6974s	
23894/28500 (epoch 41.919), train_loss = 0.81409000, grad/param norm = 1.8177e-01, time/batch = 0.6958s	
23895/28500 (epoch 41.921), train_loss = 0.88685431, grad/param norm = 2.3390e-01, time/batch = 0.6998s	
23896/28500 (epoch 41.923), train_loss = 0.72250423, grad/param norm = 2.0223e-01, time/batch = 0.6984s	
23897/28500 (epoch 41.925), train_loss = 0.73717469, grad/param norm = 2.0660e-01, time/batch = 0.7001s	
23898/28500 (epoch 41.926), train_loss = 0.79543057, grad/param norm = 1.9629e-01, time/batch = 0.6942s	
23899/28500 (epoch 41.928), train_loss = 0.74992763, grad/param norm = 1.8683e-01, time/batch = 0.6960s	
23900/28500 (epoch 41.930), train_loss = 0.63492032, grad/param norm = 1.5616e-01, time/batch = 0.6940s	
23901/28500 (epoch 41.932), train_loss = 0.64773166, grad/param norm = 1.6516e-01, time/batch = 0.6981s	
23902/28500 (epoch 41.933), train_loss = 0.84947785, grad/param norm = 1.8302e-01, time/batch = 0.6985s	
23903/28500 (epoch 41.935), train_loss = 0.87773088, grad/param norm = 1.9138e-01, time/batch = 0.7031s	
23904/28500 (epoch 41.937), train_loss = 0.83882539, grad/param norm = 2.0581e-01, time/batch = 0.6949s	
23905/28500 (epoch 41.939), train_loss = 0.90429981, grad/param norm = 2.0736e-01, time/batch = 0.6965s	
23906/28500 (epoch 41.940), train_loss = 0.64499784, grad/param norm = 1.7514e-01, time/batch = 0.6939s	
23907/28500 (epoch 41.942), train_loss = 0.79095620, grad/param norm = 2.0336e-01, time/batch = 0.7052s	
23908/28500 (epoch 41.944), train_loss = 0.76535251, grad/param norm = 2.0193e-01, time/batch = 0.6937s	
23909/28500 (epoch 41.946), train_loss = 0.85304548, grad/param norm = 2.0205e-01, time/batch = 0.6938s	
23910/28500 (epoch 41.947), train_loss = 1.00370566, grad/param norm = 2.6409e-01, time/batch = 0.6958s	
23911/28500 (epoch 41.949), train_loss = 0.76898320, grad/param norm = 1.9737e-01, time/batch = 0.6977s	
23912/28500 (epoch 41.951), train_loss = 0.95934857, grad/param norm = 2.0441e-01, time/batch = 0.6988s	
23913/28500 (epoch 41.953), train_loss = 0.96011284, grad/param norm = 2.3722e-01, time/batch = 0.6988s	
23914/28500 (epoch 41.954), train_loss = 0.86814383, grad/param norm = 1.9610e-01, time/batch = 0.6966s	
23915/28500 (epoch 41.956), train_loss = 0.81837465, grad/param norm = 2.9137e-01, time/batch = 0.6999s	
23916/28500 (epoch 41.958), train_loss = 1.02671202, grad/param norm = 2.0947e-01, time/batch = 0.6977s	
23917/28500 (epoch 41.960), train_loss = 0.75006649, grad/param norm = 2.1994e-01, time/batch = 0.7008s	
23918/28500 (epoch 41.961), train_loss = 0.94792351, grad/param norm = 2.1146e-01, time/batch = 0.6969s	
23919/28500 (epoch 41.963), train_loss = 0.87108495, grad/param norm = 1.8673e-01, time/batch = 0.6981s	
23920/28500 (epoch 41.965), train_loss = 0.72734766, grad/param norm = 1.8214e-01, time/batch = 0.6981s	
23921/28500 (epoch 41.967), train_loss = 0.75728790, grad/param norm = 1.9096e-01, time/batch = 0.7031s	
23922/28500 (epoch 41.968), train_loss = 0.70409402, grad/param norm = 1.6470e-01, time/batch = 0.7022s	
23923/28500 (epoch 41.970), train_loss = 0.74793778, grad/param norm = 2.4085e-01, time/batch = 0.6983s	
23924/28500 (epoch 41.972), train_loss = 0.79132057, grad/param norm = 2.0271e-01, time/batch = 0.7032s	
23925/28500 (epoch 41.974), train_loss = 0.98034327, grad/param norm = 2.2244e-01, time/batch = 0.6993s	
23926/28500 (epoch 41.975), train_loss = 0.74615340, grad/param norm = 2.1151e-01, time/batch = 0.7009s	
23927/28500 (epoch 41.977), train_loss = 0.88192169, grad/param norm = 2.0439e-01, time/batch = 0.7016s	
23928/28500 (epoch 41.979), train_loss = 0.84889622, grad/param norm = 1.9556e-01, time/batch = 0.7010s	
23929/28500 (epoch 41.981), train_loss = 0.69683353, grad/param norm = 1.9637e-01, time/batch = 0.7034s	
23930/28500 (epoch 41.982), train_loss = 0.77778977, grad/param norm = 1.9073e-01, time/batch = 0.6973s	
23931/28500 (epoch 41.984), train_loss = 0.86321228, grad/param norm = 1.9123e-01, time/batch = 0.7013s	
23932/28500 (epoch 41.986), train_loss = 1.03410731, grad/param norm = 2.4463e-01, time/batch = 0.6981s	
23933/28500 (epoch 41.988), train_loss = 0.72802390, grad/param norm = 1.8347e-01, time/batch = 0.7014s	
23934/28500 (epoch 41.989), train_loss = 0.81738731, grad/param norm = 2.0542e-01, time/batch = 0.7001s	
23935/28500 (epoch 41.991), train_loss = 0.72883721, grad/param norm = 2.0048e-01, time/batch = 0.7134s	
23936/28500 (epoch 41.993), train_loss = 0.72404540, grad/param norm = 2.2114e-01, time/batch = 0.7072s	
23937/28500 (epoch 41.995), train_loss = 0.75797612, grad/param norm = 1.8250e-01, time/batch = 0.7110s	
23938/28500 (epoch 41.996), train_loss = 0.69394194, grad/param norm = 2.0061e-01, time/batch = 0.7150s	
23939/28500 (epoch 41.998), train_loss = 0.92229378, grad/param norm = 2.8073e-01, time/batch = 0.7057s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
23940/28500 (epoch 42.000), train_loss = 0.77617197, grad/param norm = 1.9216e-01, time/batch = 0.7004s	
23941/28500 (epoch 42.002), train_loss = 0.97212449, grad/param norm = 2.2196e-01, time/batch = 0.7128s	
23942/28500 (epoch 42.004), train_loss = 0.81113942, grad/param norm = 1.8231e-01, time/batch = 0.7277s	
23943/28500 (epoch 42.005), train_loss = 0.88697370, grad/param norm = 1.9533e-01, time/batch = 0.7198s	
23944/28500 (epoch 42.007), train_loss = 0.71568424, grad/param norm = 1.7474e-01, time/batch = 0.7167s	
23945/28500 (epoch 42.009), train_loss = 0.82554022, grad/param norm = 2.0786e-01, time/batch = 0.7115s	
23946/28500 (epoch 42.011), train_loss = 0.73716765, grad/param norm = 1.7183e-01, time/batch = 0.7010s	
23947/28500 (epoch 42.012), train_loss = 0.74460479, grad/param norm = 1.7292e-01, time/batch = 0.6995s	
23948/28500 (epoch 42.014), train_loss = 0.71463897, grad/param norm = 2.2360e-01, time/batch = 0.6972s	
23949/28500 (epoch 42.016), train_loss = 0.78225366, grad/param norm = 1.7463e-01, time/batch = 0.7148s	
23950/28500 (epoch 42.018), train_loss = 0.83512901, grad/param norm = 2.0058e-01, time/batch = 0.7333s	
23951/28500 (epoch 42.019), train_loss = 0.89188738, grad/param norm = 1.9282e-01, time/batch = 0.7029s	
23952/28500 (epoch 42.021), train_loss = 0.90856614, grad/param norm = 1.7508e-01, time/batch = 0.7050s	
23953/28500 (epoch 42.023), train_loss = 0.82118561, grad/param norm = 1.9850e-01, time/batch = 0.6955s	
23954/28500 (epoch 42.025), train_loss = 0.83473694, grad/param norm = 1.9426e-01, time/batch = 0.6989s	
23955/28500 (epoch 42.026), train_loss = 0.77089675, grad/param norm = 1.8628e-01, time/batch = 0.6955s	
23956/28500 (epoch 42.028), train_loss = 0.82069621, grad/param norm = 2.1712e-01, time/batch = 0.7036s	
23957/28500 (epoch 42.030), train_loss = 0.82885847, grad/param norm = 1.9738e-01, time/batch = 0.7116s	
23958/28500 (epoch 42.032), train_loss = 0.91025114, grad/param norm = 1.7961e-01, time/batch = 0.6965s	
23959/28500 (epoch 42.033), train_loss = 0.96065341, grad/param norm = 2.1791e-01, time/batch = 0.6944s	
23960/28500 (epoch 42.035), train_loss = 0.79061204, grad/param norm = 1.9741e-01, time/batch = 0.6951s	
23961/28500 (epoch 42.037), train_loss = 0.87061800, grad/param norm = 1.8098e-01, time/batch = 0.7002s	
23962/28500 (epoch 42.039), train_loss = 0.92080130, grad/param norm = 2.0311e-01, time/batch = 0.6997s	
23963/28500 (epoch 42.040), train_loss = 0.93526419, grad/param norm = 1.9182e-01, time/batch = 0.6941s	
23964/28500 (epoch 42.042), train_loss = 0.87401003, grad/param norm = 1.9084e-01, time/batch = 0.6990s	
23965/28500 (epoch 42.044), train_loss = 0.80915476, grad/param norm = 1.9561e-01, time/batch = 0.7106s	
23966/28500 (epoch 42.046), train_loss = 0.99954585, grad/param norm = 2.0238e-01, time/batch = 0.6965s	
23967/28500 (epoch 42.047), train_loss = 0.95750440, grad/param norm = 2.4443e-01, time/batch = 0.6938s	
23968/28500 (epoch 42.049), train_loss = 0.84417790, grad/param norm = 2.1389e-01, time/batch = 0.6956s	
23969/28500 (epoch 42.051), train_loss = 0.83325143, grad/param norm = 2.1173e-01, time/batch = 0.6941s	
23970/28500 (epoch 42.053), train_loss = 0.79128313, grad/param norm = 1.9421e-01, time/batch = 0.6945s	
23971/28500 (epoch 42.054), train_loss = 0.88008404, grad/param norm = 1.9610e-01, time/batch = 0.6960s	
23972/28500 (epoch 42.056), train_loss = 0.76803036, grad/param norm = 1.6817e-01, time/batch = 0.7134s	
23973/28500 (epoch 42.058), train_loss = 0.74498986, grad/param norm = 1.6968e-01, time/batch = 0.7002s	
23974/28500 (epoch 42.060), train_loss = 0.87917944, grad/param norm = 2.0406e-01, time/batch = 0.6942s	
23975/28500 (epoch 42.061), train_loss = 0.79444811, grad/param norm = 1.9874e-01, time/batch = 0.7030s	
23976/28500 (epoch 42.063), train_loss = 0.85725688, grad/param norm = 1.9833e-01, time/batch = 0.6978s	
23977/28500 (epoch 42.065), train_loss = 0.83608009, grad/param norm = 1.9977e-01, time/batch = 0.6948s	
23978/28500 (epoch 42.067), train_loss = 0.76338226, grad/param norm = 1.8499e-01, time/batch = 0.6982s	
23979/28500 (epoch 42.068), train_loss = 0.79952001, grad/param norm = 1.9255e-01, time/batch = 0.6994s	
23980/28500 (epoch 42.070), train_loss = 0.84174339, grad/param norm = 2.0147e-01, time/batch = 0.7099s	
23981/28500 (epoch 42.072), train_loss = 0.95165332, grad/param norm = 2.4136e-01, time/batch = 0.6950s	
23982/28500 (epoch 42.074), train_loss = 0.78591191, grad/param norm = 1.7369e-01, time/batch = 0.6957s	
23983/28500 (epoch 42.075), train_loss = 0.81695042, grad/param norm = 2.0372e-01, time/batch = 0.6933s	
23984/28500 (epoch 42.077), train_loss = 0.87697293, grad/param norm = 1.9441e-01, time/batch = 0.6943s	
23985/28500 (epoch 42.079), train_loss = 0.84079531, grad/param norm = 2.0139e-01, time/batch = 0.6953s	
23986/28500 (epoch 42.081), train_loss = 0.90243984, grad/param norm = 2.1731e-01, time/batch = 0.6944s	
23987/28500 (epoch 42.082), train_loss = 0.79072756, grad/param norm = 2.3734e-01, time/batch = 0.7125s	
23988/28500 (epoch 42.084), train_loss = 0.82403590, grad/param norm = 1.8977e-01, time/batch = 0.6938s	
23989/28500 (epoch 42.086), train_loss = 0.77938780, grad/param norm = 1.9352e-01, time/batch = 0.6936s	
23990/28500 (epoch 42.088), train_loss = 0.72405704, grad/param norm = 1.8011e-01, time/batch = 0.6954s	
23991/28500 (epoch 42.089), train_loss = 0.87434053, grad/param norm = 1.8868e-01, time/batch = 0.6958s	
23992/28500 (epoch 42.091), train_loss = 0.73714827, grad/param norm = 1.6902e-01, time/batch = 0.6958s	
23993/28500 (epoch 42.093), train_loss = 0.91572388, grad/param norm = 1.9942e-01, time/batch = 0.6935s	
23994/28500 (epoch 42.095), train_loss = 0.83048962, grad/param norm = 1.8462e-01, time/batch = 0.7075s	
23995/28500 (epoch 42.096), train_loss = 0.90232697, grad/param norm = 1.8703e-01, time/batch = 0.6981s	
23996/28500 (epoch 42.098), train_loss = 0.80937693, grad/param norm = 2.1771e-01, time/batch = 0.6951s	
23997/28500 (epoch 42.100), train_loss = 0.78457496, grad/param norm = 1.8493e-01, time/batch = 0.6930s	
23998/28500 (epoch 42.102), train_loss = 0.90352440, grad/param norm = 2.2928e-01, time/batch = 0.6957s	
23999/28500 (epoch 42.104), train_loss = 0.86576171, grad/param norm = 3.0923e-01, time/batch = 0.6933s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch42.11_1.9789.t7	
24000/28500 (epoch 42.105), train_loss = 0.90990854, grad/param norm = 1.9592e-01, time/batch = 0.6941s	
24001/28500 (epoch 42.107), train_loss = 1.30446720, grad/param norm = 2.5000e-01, time/batch = 0.7270s	
24002/28500 (epoch 42.109), train_loss = 0.80560306, grad/param norm = 2.8333e-01, time/batch = 0.6970s	
24003/28500 (epoch 42.111), train_loss = 0.81286447, grad/param norm = 2.5733e-01, time/batch = 0.6960s	
24004/28500 (epoch 42.112), train_loss = 0.91852062, grad/param norm = 2.0877e-01, time/batch = 0.6963s	
24005/28500 (epoch 42.114), train_loss = 0.83008710, grad/param norm = 2.0395e-01, time/batch = 0.6961s	
24006/28500 (epoch 42.116), train_loss = 0.97244194, grad/param norm = 2.3175e-01, time/batch = 0.7089s	
24007/28500 (epoch 42.118), train_loss = 0.76478510, grad/param norm = 2.1547e-01, time/batch = 0.6980s	
24008/28500 (epoch 42.119), train_loss = 0.86445579, grad/param norm = 2.4041e-01, time/batch = 0.7162s	
24009/28500 (epoch 42.121), train_loss = 0.98048883, grad/param norm = 2.4215e-01, time/batch = 0.6979s	
24010/28500 (epoch 42.123), train_loss = 0.93002737, grad/param norm = 1.9806e-01, time/batch = 0.6994s	
24011/28500 (epoch 42.125), train_loss = 0.84070010, grad/param norm = 1.8362e-01, time/batch = 0.6966s	
24012/28500 (epoch 42.126), train_loss = 0.83969967, grad/param norm = 1.8943e-01, time/batch = 0.7039s	
24013/28500 (epoch 42.128), train_loss = 0.83508068, grad/param norm = 1.8185e-01, time/batch = 0.7100s	
24014/28500 (epoch 42.130), train_loss = 0.79279924, grad/param norm = 1.9864e-01, time/batch = 0.6946s	
24015/28500 (epoch 42.132), train_loss = 0.83033789, grad/param norm = 2.1236e-01, time/batch = 0.7223s	
24016/28500 (epoch 42.133), train_loss = 0.88348741, grad/param norm = 2.1237e-01, time/batch = 0.7118s	
24017/28500 (epoch 42.135), train_loss = 0.78432253, grad/param norm = 1.8290e-01, time/batch = 0.6951s	
24018/28500 (epoch 42.137), train_loss = 0.83807347, grad/param norm = 1.9802e-01, time/batch = 0.6962s	
24019/28500 (epoch 42.139), train_loss = 0.83199726, grad/param norm = 1.6638e-01, time/batch = 0.6939s	
24020/28500 (epoch 42.140), train_loss = 0.82585544, grad/param norm = 1.9446e-01, time/batch = 0.6945s	
24021/28500 (epoch 42.142), train_loss = 0.79125141, grad/param norm = 2.0734e-01, time/batch = 0.6976s	
24022/28500 (epoch 42.144), train_loss = 0.72792477, grad/param norm = 1.8745e-01, time/batch = 0.7041s	
24023/28500 (epoch 42.146), train_loss = 0.80251933, grad/param norm = 1.8114e-01, time/batch = 0.7064s	
24024/28500 (epoch 42.147), train_loss = 0.70700108, grad/param norm = 2.1966e-01, time/batch = 0.6963s	
24025/28500 (epoch 42.149), train_loss = 0.72571070, grad/param norm = 1.7264e-01, time/batch = 0.6944s	
24026/28500 (epoch 42.151), train_loss = 0.77446824, grad/param norm = 1.8227e-01, time/batch = 0.6932s	
24027/28500 (epoch 42.153), train_loss = 0.85234324, grad/param norm = 1.9917e-01, time/batch = 0.6961s	
24028/28500 (epoch 42.154), train_loss = 0.71149147, grad/param norm = 1.9373e-01, time/batch = 0.6932s	
24029/28500 (epoch 42.156), train_loss = 0.88163941, grad/param norm = 1.9296e-01, time/batch = 0.6935s	
24030/28500 (epoch 42.158), train_loss = 0.84716665, grad/param norm = 1.8706e-01, time/batch = 0.7134s	
24031/28500 (epoch 42.160), train_loss = 0.73848272, grad/param norm = 1.8627e-01, time/batch = 0.6958s	
24032/28500 (epoch 42.161), train_loss = 0.75709995, grad/param norm = 1.9414e-01, time/batch = 0.6994s	
24033/28500 (epoch 42.163), train_loss = 0.72478116, grad/param norm = 1.9541e-01, time/batch = 0.6938s	
24034/28500 (epoch 42.165), train_loss = 0.95393112, grad/param norm = 1.8304e-01, time/batch = 0.6936s	
24035/28500 (epoch 42.167), train_loss = 0.94988644, grad/param norm = 2.2406e-01, time/batch = 0.6952s	
24036/28500 (epoch 42.168), train_loss = 0.91882663, grad/param norm = 2.1613e-01, time/batch = 0.6934s	
24037/28500 (epoch 42.170), train_loss = 0.91349200, grad/param norm = 2.1346e-01, time/batch = 0.7102s	
24038/28500 (epoch 42.172), train_loss = 0.79878646, grad/param norm = 1.7673e-01, time/batch = 0.6991s	
24039/28500 (epoch 42.174), train_loss = 0.95014432, grad/param norm = 2.0523e-01, time/batch = 0.6935s	
24040/28500 (epoch 42.175), train_loss = 0.81573417, grad/param norm = 1.7993e-01, time/batch = 0.6938s	
24041/28500 (epoch 42.177), train_loss = 0.84151824, grad/param norm = 1.8713e-01, time/batch = 0.6975s	
24042/28500 (epoch 42.179), train_loss = 0.89132663, grad/param norm = 1.9404e-01, time/batch = 0.7093s	
24043/28500 (epoch 42.181), train_loss = 0.85571700, grad/param norm = 2.5069e-01, time/batch = 0.6942s	
24044/28500 (epoch 42.182), train_loss = 0.79083603, grad/param norm = 1.8732e-01, time/batch = 0.6984s	
24045/28500 (epoch 42.184), train_loss = 0.98614904, grad/param norm = 2.1475e-01, time/batch = 0.7104s	
24046/28500 (epoch 42.186), train_loss = 0.94396410, grad/param norm = 2.0071e-01, time/batch = 0.6936s	
24047/28500 (epoch 42.188), train_loss = 0.89386618, grad/param norm = 2.0836e-01, time/batch = 0.6976s	
24048/28500 (epoch 42.189), train_loss = 0.83243209, grad/param norm = 1.7433e-01, time/batch = 0.6938s	
24049/28500 (epoch 42.191), train_loss = 0.98648178, grad/param norm = 1.8680e-01, time/batch = 0.6973s	
24050/28500 (epoch 42.193), train_loss = 0.81156754, grad/param norm = 2.1447e-01, time/batch = 0.6936s	
24051/28500 (epoch 42.195), train_loss = 0.96078405, grad/param norm = 2.0981e-01, time/batch = 0.6985s	
24052/28500 (epoch 42.196), train_loss = 0.87203256, grad/param norm = 2.0205e-01, time/batch = 0.7146s	
24053/28500 (epoch 42.198), train_loss = 0.84418113, grad/param norm = 2.1205e-01, time/batch = 0.6974s	
24054/28500 (epoch 42.200), train_loss = 0.90295507, grad/param norm = 1.9756e-01, time/batch = 0.6944s	
24055/28500 (epoch 42.202), train_loss = 0.85786305, grad/param norm = 1.7076e-01, time/batch = 0.6931s	
24056/28500 (epoch 42.204), train_loss = 0.81605796, grad/param norm = 1.7271e-01, time/batch = 0.6959s	
24057/28500 (epoch 42.205), train_loss = 0.77790292, grad/param norm = 2.1125e-01, time/batch = 0.6964s	
24058/28500 (epoch 42.207), train_loss = 0.70537293, grad/param norm = 1.9995e-01, time/batch = 0.6995s	
24059/28500 (epoch 42.209), train_loss = 0.85256990, grad/param norm = 2.2570e-01, time/batch = 0.6997s	
24060/28500 (epoch 42.211), train_loss = 0.76663877, grad/param norm = 1.7720e-01, time/batch = 0.7081s	
24061/28500 (epoch 42.212), train_loss = 0.69698025, grad/param norm = 1.9762e-01, time/batch = 0.6973s	
24062/28500 (epoch 42.214), train_loss = 0.81849625, grad/param norm = 1.9353e-01, time/batch = 0.6960s	
24063/28500 (epoch 42.216), train_loss = 0.76999337, grad/param norm = 1.9637e-01, time/batch = 0.6939s	
24064/28500 (epoch 42.218), train_loss = 0.93768775, grad/param norm = 1.9649e-01, time/batch = 0.6939s	
24065/28500 (epoch 42.219), train_loss = 0.84615320, grad/param norm = 1.9254e-01, time/batch = 0.6952s	
24066/28500 (epoch 42.221), train_loss = 0.72031696, grad/param norm = 1.9953e-01, time/batch = 0.6956s	
24067/28500 (epoch 42.223), train_loss = 0.90931537, grad/param norm = 2.0067e-01, time/batch = 0.7133s	
24068/28500 (epoch 42.225), train_loss = 0.96579425, grad/param norm = 2.2941e-01, time/batch = 0.7151s	
24069/28500 (epoch 42.226), train_loss = 0.79682633, grad/param norm = 1.7031e-01, time/batch = 0.6985s	
24070/28500 (epoch 42.228), train_loss = 0.91397185, grad/param norm = 1.8191e-01, time/batch = 0.6980s	
24071/28500 (epoch 42.230), train_loss = 0.90164502, grad/param norm = 2.2308e-01, time/batch = 0.7037s	
24072/28500 (epoch 42.232), train_loss = 0.88874983, grad/param norm = 1.9449e-01, time/batch = 0.7044s	
24073/28500 (epoch 42.233), train_loss = 0.83077371, grad/param norm = 1.9358e-01, time/batch = 0.7215s	
24074/28500 (epoch 42.235), train_loss = 0.83843068, grad/param norm = 2.0270e-01, time/batch = 0.7063s	
24075/28500 (epoch 42.237), train_loss = 0.75870536, grad/param norm = 1.7439e-01, time/batch = 0.7099s	
24076/28500 (epoch 42.239), train_loss = 0.78768870, grad/param norm = 1.7472e-01, time/batch = 0.7058s	
24077/28500 (epoch 42.240), train_loss = 0.72474424, grad/param norm = 1.9657e-01, time/batch = 0.7035s	
24078/28500 (epoch 42.242), train_loss = 0.75824951, grad/param norm = 2.0193e-01, time/batch = 0.7127s	
24079/28500 (epoch 42.244), train_loss = 0.85373487, grad/param norm = 1.7241e-01, time/batch = 0.6965s	
24080/28500 (epoch 42.246), train_loss = 0.86709795, grad/param norm = 1.8427e-01, time/batch = 0.6972s	
24081/28500 (epoch 42.247), train_loss = 0.94867917, grad/param norm = 2.1899e-01, time/batch = 0.7023s	
24082/28500 (epoch 42.249), train_loss = 0.80385937, grad/param norm = 1.7642e-01, time/batch = 0.6973s	
24083/28500 (epoch 42.251), train_loss = 0.82527193, grad/param norm = 1.7590e-01, time/batch = 0.6989s	
24084/28500 (epoch 42.253), train_loss = 0.97680120, grad/param norm = 2.5500e-01, time/batch = 0.6987s	
24085/28500 (epoch 42.254), train_loss = 0.96980663, grad/param norm = 1.8759e-01, time/batch = 0.6970s	
24086/28500 (epoch 42.256), train_loss = 0.79943828, grad/param norm = 2.1061e-01, time/batch = 0.6993s	
24087/28500 (epoch 42.258), train_loss = 0.81419988, grad/param norm = 2.0680e-01, time/batch = 0.6985s	
24088/28500 (epoch 42.260), train_loss = 0.83893416, grad/param norm = 1.9876e-01, time/batch = 0.6977s	
24089/28500 (epoch 42.261), train_loss = 0.70479985, grad/param norm = 1.6478e-01, time/batch = 0.6980s	
24090/28500 (epoch 42.263), train_loss = 0.90429548, grad/param norm = 2.4075e-01, time/batch = 0.6982s	
24091/28500 (epoch 42.265), train_loss = 0.76605998, grad/param norm = 1.9557e-01, time/batch = 0.7010s	
24092/28500 (epoch 42.267), train_loss = 0.99963878, grad/param norm = 2.7478e-01, time/batch = 0.6975s	
24093/28500 (epoch 42.268), train_loss = 0.86415847, grad/param norm = 1.7627e-01, time/batch = 0.6971s	
24094/28500 (epoch 42.270), train_loss = 0.83038834, grad/param norm = 2.3645e-01, time/batch = 0.6974s	
24095/28500 (epoch 42.272), train_loss = 0.83340085, grad/param norm = 1.8548e-01, time/batch = 0.6995s	
24096/28500 (epoch 42.274), train_loss = 0.89115647, grad/param norm = 2.2303e-01, time/batch = 0.7000s	
24097/28500 (epoch 42.275), train_loss = 0.88874989, grad/param norm = 1.7921e-01, time/batch = 0.7018s	
24098/28500 (epoch 42.277), train_loss = 0.82525540, grad/param norm = 1.9980e-01, time/batch = 0.7026s	
24099/28500 (epoch 42.279), train_loss = 0.86933876, grad/param norm = 2.1761e-01, time/batch = 0.7230s	
24100/28500 (epoch 42.281), train_loss = 0.86825429, grad/param norm = 2.0047e-01, time/batch = 0.7016s	
24101/28500 (epoch 42.282), train_loss = 0.82602661, grad/param norm = 1.6682e-01, time/batch = 0.7025s	
24102/28500 (epoch 42.284), train_loss = 0.86215473, grad/param norm = 1.9950e-01, time/batch = 0.7000s	
24103/28500 (epoch 42.286), train_loss = 0.93047950, grad/param norm = 2.1352e-01, time/batch = 0.6987s	
24104/28500 (epoch 42.288), train_loss = 0.82775969, grad/param norm = 2.0286e-01, time/batch = 0.6993s	
24105/28500 (epoch 42.289), train_loss = 0.85182603, grad/param norm = 2.0222e-01, time/batch = 0.6991s	
24106/28500 (epoch 42.291), train_loss = 0.84393148, grad/param norm = 1.7308e-01, time/batch = 0.6989s	
24107/28500 (epoch 42.293), train_loss = 0.83910094, grad/param norm = 1.9113e-01, time/batch = 0.6976s	
24108/28500 (epoch 42.295), train_loss = 0.74316126, grad/param norm = 1.7958e-01, time/batch = 0.6995s	
24109/28500 (epoch 42.296), train_loss = 0.73326295, grad/param norm = 1.8632e-01, time/batch = 0.7002s	
24110/28500 (epoch 42.298), train_loss = 0.88685343, grad/param norm = 1.7811e-01, time/batch = 0.7025s	
24111/28500 (epoch 42.300), train_loss = 0.75947080, grad/param norm = 1.9439e-01, time/batch = 0.7037s	
24112/28500 (epoch 42.302), train_loss = 0.70279175, grad/param norm = 1.7521e-01, time/batch = 0.7045s	
24113/28500 (epoch 42.304), train_loss = 0.81050005, grad/param norm = 1.8540e-01, time/batch = 0.6949s	
24114/28500 (epoch 42.305), train_loss = 0.86997107, grad/param norm = 2.0044e-01, time/batch = 0.6944s	
24115/28500 (epoch 42.307), train_loss = 0.80442124, grad/param norm = 2.0624e-01, time/batch = 0.6940s	
24116/28500 (epoch 42.309), train_loss = 0.81193767, grad/param norm = 1.7403e-01, time/batch = 0.6952s	
24117/28500 (epoch 42.311), train_loss = 0.86604752, grad/param norm = 1.8638e-01, time/batch = 0.6964s	
24118/28500 (epoch 42.312), train_loss = 0.87703715, grad/param norm = 1.8973e-01, time/batch = 0.6962s	
24119/28500 (epoch 42.314), train_loss = 0.85268382, grad/param norm = 1.8844e-01, time/batch = 0.6962s	
24120/28500 (epoch 42.316), train_loss = 0.84533350, grad/param norm = 2.0409e-01, time/batch = 0.6950s	
24121/28500 (epoch 42.318), train_loss = 0.91000490, grad/param norm = 1.9434e-01, time/batch = 0.6978s	
24122/28500 (epoch 42.319), train_loss = 0.76779878, grad/param norm = 1.8828e-01, time/batch = 0.6969s	
24123/28500 (epoch 42.321), train_loss = 0.78350834, grad/param norm = 1.9777e-01, time/batch = 0.6956s	
24124/28500 (epoch 42.323), train_loss = 0.84082274, grad/param norm = 2.3024e-01, time/batch = 0.6949s	
24125/28500 (epoch 42.325), train_loss = 0.94374334, grad/param norm = 1.8875e-01, time/batch = 0.6947s	
24126/28500 (epoch 42.326), train_loss = 0.85014240, grad/param norm = 2.0198e-01, time/batch = 0.6956s	
24127/28500 (epoch 42.328), train_loss = 0.67293560, grad/param norm = 1.5608e-01, time/batch = 0.6971s	
24128/28500 (epoch 42.330), train_loss = 0.75699998, grad/param norm = 1.6919e-01, time/batch = 0.6968s	
24129/28500 (epoch 42.332), train_loss = 0.77696585, grad/param norm = 1.8742e-01, time/batch = 0.6952s	
24130/28500 (epoch 42.333), train_loss = 0.64958163, grad/param norm = 1.9440e-01, time/batch = 0.6950s	
24131/28500 (epoch 42.335), train_loss = 0.72641103, grad/param norm = 1.7410e-01, time/batch = 0.6960s	
24132/28500 (epoch 42.337), train_loss = 0.67496029, grad/param norm = 1.6984e-01, time/batch = 0.6952s	
24133/28500 (epoch 42.339), train_loss = 0.66695527, grad/param norm = 1.4507e-01, time/batch = 0.6971s	
24134/28500 (epoch 42.340), train_loss = 0.80509002, grad/param norm = 1.8017e-01, time/batch = 0.6975s	
24135/28500 (epoch 42.342), train_loss = 0.80283739, grad/param norm = 1.9011e-01, time/batch = 0.6958s	
24136/28500 (epoch 42.344), train_loss = 0.69624309, grad/param norm = 1.7517e-01, time/batch = 0.6948s	
24137/28500 (epoch 42.346), train_loss = 0.68299427, grad/param norm = 1.5644e-01, time/batch = 0.6954s	
24138/28500 (epoch 42.347), train_loss = 0.81138891, grad/param norm = 1.5991e-01, time/batch = 0.6954s	
24139/28500 (epoch 42.349), train_loss = 0.83210712, grad/param norm = 2.0463e-01, time/batch = 0.6958s	
24140/28500 (epoch 42.351), train_loss = 0.72608476, grad/param norm = 1.8820e-01, time/batch = 0.6953s	
24141/28500 (epoch 42.353), train_loss = 0.83825557, grad/param norm = 2.3313e-01, time/batch = 0.6991s	
24142/28500 (epoch 42.354), train_loss = 0.71560311, grad/param norm = 1.8267e-01, time/batch = 0.6977s	
24143/28500 (epoch 42.356), train_loss = 0.77728877, grad/param norm = 1.9091e-01, time/batch = 0.6941s	
24144/28500 (epoch 42.358), train_loss = 0.83413961, grad/param norm = 1.7362e-01, time/batch = 0.6972s	
24145/28500 (epoch 42.360), train_loss = 0.83420689, grad/param norm = 2.1563e-01, time/batch = 0.6978s	
24146/28500 (epoch 42.361), train_loss = 0.73368040, grad/param norm = 1.8214e-01, time/batch = 0.6979s	
24147/28500 (epoch 42.363), train_loss = 0.71518431, grad/param norm = 1.6188e-01, time/batch = 0.6973s	
24148/28500 (epoch 42.365), train_loss = 0.76280368, grad/param norm = 2.0524e-01, time/batch = 0.6995s	
24149/28500 (epoch 42.367), train_loss = 0.80775499, grad/param norm = 1.8285e-01, time/batch = 0.6974s	
24150/28500 (epoch 42.368), train_loss = 0.75048654, grad/param norm = 1.9168e-01, time/batch = 0.6992s	
24151/28500 (epoch 42.370), train_loss = 0.82066825, grad/param norm = 2.0667e-01, time/batch = 0.7023s	
24152/28500 (epoch 42.372), train_loss = 0.64710451, grad/param norm = 1.7614e-01, time/batch = 0.7016s	
24153/28500 (epoch 42.374), train_loss = 0.77813705, grad/param norm = 2.0097e-01, time/batch = 0.7012s	
24154/28500 (epoch 42.375), train_loss = 0.90293334, grad/param norm = 2.0570e-01, time/batch = 0.6999s	
24155/28500 (epoch 42.377), train_loss = 0.75430896, grad/param norm = 2.4478e-01, time/batch = 0.6996s	
24156/28500 (epoch 42.379), train_loss = 0.62715866, grad/param norm = 1.6679e-01, time/batch = 0.6974s	
24157/28500 (epoch 42.381), train_loss = 0.80001811, grad/param norm = 1.9790e-01, time/batch = 0.6976s	
24158/28500 (epoch 42.382), train_loss = 0.76637356, grad/param norm = 2.2284e-01, time/batch = 0.6981s	
24159/28500 (epoch 42.384), train_loss = 0.67077287, grad/param norm = 1.7564e-01, time/batch = 0.6990s	
24160/28500 (epoch 42.386), train_loss = 0.72793316, grad/param norm = 1.8543e-01, time/batch = 0.6977s	
24161/28500 (epoch 42.388), train_loss = 0.86666276, grad/param norm = 1.9377e-01, time/batch = 0.6999s	
24162/28500 (epoch 42.389), train_loss = 0.73172405, grad/param norm = 1.8847e-01, time/batch = 0.6985s	
24163/28500 (epoch 42.391), train_loss = 0.71046353, grad/param norm = 2.0480e-01, time/batch = 0.6983s	
24164/28500 (epoch 42.393), train_loss = 0.72305010, grad/param norm = 1.8640e-01, time/batch = 0.6995s	
24165/28500 (epoch 42.395), train_loss = 0.89991561, grad/param norm = 2.1796e-01, time/batch = 0.7009s	
24166/28500 (epoch 42.396), train_loss = 0.87123683, grad/param norm = 1.9131e-01, time/batch = 0.6992s	
24167/28500 (epoch 42.398), train_loss = 0.59699022, grad/param norm = 2.1443e-01, time/batch = 0.7100s	
24168/28500 (epoch 42.400), train_loss = 0.76471027, grad/param norm = 1.9510e-01, time/batch = 0.7048s	
24169/28500 (epoch 42.402), train_loss = 0.80413658, grad/param norm = 1.9497e-01, time/batch = 0.6991s	
24170/28500 (epoch 42.404), train_loss = 0.80941254, grad/param norm = 2.0645e-01, time/batch = 0.6984s	
24171/28500 (epoch 42.405), train_loss = 0.87147689, grad/param norm = 1.8659e-01, time/batch = 0.7024s	
24172/28500 (epoch 42.407), train_loss = 0.80250456, grad/param norm = 1.8293e-01, time/batch = 0.6983s	
24173/28500 (epoch 42.409), train_loss = 0.80241820, grad/param norm = 2.1315e-01, time/batch = 0.7005s	
24174/28500 (epoch 42.411), train_loss = 0.89825467, grad/param norm = 3.1212e-01, time/batch = 0.6968s	
24175/28500 (epoch 42.412), train_loss = 0.91626533, grad/param norm = 2.1432e-01, time/batch = 0.6992s	
24176/28500 (epoch 42.414), train_loss = 0.83443703, grad/param norm = 2.2463e-01, time/batch = 0.6960s	
24177/28500 (epoch 42.416), train_loss = 0.74596036, grad/param norm = 2.1829e-01, time/batch = 0.6938s	
24178/28500 (epoch 42.418), train_loss = 0.84610106, grad/param norm = 2.0431e-01, time/batch = 0.6796s	
24179/28500 (epoch 42.419), train_loss = 0.91705649, grad/param norm = 2.9785e-01, time/batch = 0.6810s	
24180/28500 (epoch 42.421), train_loss = 0.86438678, grad/param norm = 1.9589e-01, time/batch = 0.6785s	
24181/28500 (epoch 42.423), train_loss = 0.86782420, grad/param norm = 2.1440e-01, time/batch = 0.6830s	
24182/28500 (epoch 42.425), train_loss = 0.78941574, grad/param norm = 2.2259e-01, time/batch = 0.6843s	
24183/28500 (epoch 42.426), train_loss = 0.81519595, grad/param norm = 1.8801e-01, time/batch = 0.6846s	
24184/28500 (epoch 42.428), train_loss = 0.98559439, grad/param norm = 2.2975e-01, time/batch = 0.6890s	
24185/28500 (epoch 42.430), train_loss = 0.94865707, grad/param norm = 1.9777e-01, time/batch = 0.6841s	
24186/28500 (epoch 42.432), train_loss = 0.83861681, grad/param norm = 1.9078e-01, time/batch = 0.6806s	
24187/28500 (epoch 42.433), train_loss = 0.88011363, grad/param norm = 2.0311e-01, time/batch = 0.6825s	
24188/28500 (epoch 42.435), train_loss = 0.84417951, grad/param norm = 2.0213e-01, time/batch = 0.6802s	
24189/28500 (epoch 42.437), train_loss = 0.76723265, grad/param norm = 1.6835e-01, time/batch = 0.6819s	
24190/28500 (epoch 42.439), train_loss = 0.81172445, grad/param norm = 1.8167e-01, time/batch = 0.6799s	
24191/28500 (epoch 42.440), train_loss = 0.96425693, grad/param norm = 2.0284e-01, time/batch = 0.6921s	
24192/28500 (epoch 42.442), train_loss = 0.75649176, grad/param norm = 1.9111e-01, time/batch = 0.6927s	
24193/28500 (epoch 42.444), train_loss = 0.72729634, grad/param norm = 1.6533e-01, time/batch = 0.6805s	
24194/28500 (epoch 42.446), train_loss = 0.70262499, grad/param norm = 1.7664e-01, time/batch = 0.6824s	
24195/28500 (epoch 42.447), train_loss = 0.71350604, grad/param norm = 1.6738e-01, time/batch = 0.6801s	
24196/28500 (epoch 42.449), train_loss = 0.76574969, grad/param norm = 1.8067e-01, time/batch = 0.6819s	
24197/28500 (epoch 42.451), train_loss = 0.78111924, grad/param norm = 1.7370e-01, time/batch = 0.6811s	
24198/28500 (epoch 42.453), train_loss = 0.76622368, grad/param norm = 1.7419e-01, time/batch = 0.6818s	
24199/28500 (epoch 42.454), train_loss = 0.73046748, grad/param norm = 1.6755e-01, time/batch = 0.6827s	
24200/28500 (epoch 42.456), train_loss = 0.87995467, grad/param norm = 2.5923e-01, time/batch = 0.6818s	
24201/28500 (epoch 42.458), train_loss = 0.78446919, grad/param norm = 2.2586e-01, time/batch = 0.6834s	
24202/28500 (epoch 42.460), train_loss = 0.90437720, grad/param norm = 1.9544e-01, time/batch = 0.6826s	
24203/28500 (epoch 42.461), train_loss = 0.72524969, grad/param norm = 1.8122e-01, time/batch = 0.6865s	
24204/28500 (epoch 42.463), train_loss = 0.67678130, grad/param norm = 1.5213e-01, time/batch = 0.6791s	
24205/28500 (epoch 42.465), train_loss = 0.64851443, grad/param norm = 1.9424e-01, time/batch = 0.6759s	
24206/28500 (epoch 42.467), train_loss = 0.81319952, grad/param norm = 1.8387e-01, time/batch = 0.6799s	
24207/28500 (epoch 42.468), train_loss = 0.72387438, grad/param norm = 1.6463e-01, time/batch = 0.6753s	
24208/28500 (epoch 42.470), train_loss = 0.75753807, grad/param norm = 2.0746e-01, time/batch = 0.6775s	
24209/28500 (epoch 42.472), train_loss = 0.71179286, grad/param norm = 1.6696e-01, time/batch = 0.6754s	
24210/28500 (epoch 42.474), train_loss = 0.93814924, grad/param norm = 2.0414e-01, time/batch = 0.6797s	
24211/28500 (epoch 42.475), train_loss = 0.76453875, grad/param norm = 1.8060e-01, time/batch = 0.6812s	
24212/28500 (epoch 42.477), train_loss = 0.79925188, grad/param norm = 1.8445e-01, time/batch = 0.6817s	
24213/28500 (epoch 42.479), train_loss = 0.83839602, grad/param norm = 1.8822e-01, time/batch = 0.6849s	
24214/28500 (epoch 42.481), train_loss = 0.84185277, grad/param norm = 1.8017e-01, time/batch = 0.6840s	
24215/28500 (epoch 42.482), train_loss = 0.69592699, grad/param norm = 1.8195e-01, time/batch = 0.6817s	
24216/28500 (epoch 42.484), train_loss = 0.73782465, grad/param norm = 1.7820e-01, time/batch = 0.6814s	
24217/28500 (epoch 42.486), train_loss = 0.63981200, grad/param norm = 1.7522e-01, time/batch = 0.6795s	
24218/28500 (epoch 42.488), train_loss = 0.83895695, grad/param norm = 1.8995e-01, time/batch = 0.6805s	
24219/28500 (epoch 42.489), train_loss = 0.92776047, grad/param norm = 1.7246e-01, time/batch = 0.6805s	
24220/28500 (epoch 42.491), train_loss = 0.74828687, grad/param norm = 2.2215e-01, time/batch = 0.6819s	
24221/28500 (epoch 42.493), train_loss = 0.78053779, grad/param norm = 1.7083e-01, time/batch = 0.6824s	
24222/28500 (epoch 42.495), train_loss = 0.82650497, grad/param norm = 2.2435e-01, time/batch = 0.6810s	
24223/28500 (epoch 42.496), train_loss = 0.73388098, grad/param norm = 2.1211e-01, time/batch = 0.6803s	
24224/28500 (epoch 42.498), train_loss = 0.78910124, grad/param norm = 1.7502e-01, time/batch = 0.6808s	
24225/28500 (epoch 42.500), train_loss = 0.74106963, grad/param norm = 1.7491e-01, time/batch = 0.6841s	
24226/28500 (epoch 42.502), train_loss = 0.83474045, grad/param norm = 1.7906e-01, time/batch = 0.6806s	
24227/28500 (epoch 42.504), train_loss = 0.87158887, grad/param norm = 1.9152e-01, time/batch = 0.6839s	
24228/28500 (epoch 42.505), train_loss = 0.76333342, grad/param norm = 2.0476e-01, time/batch = 0.6850s	
24229/28500 (epoch 42.507), train_loss = 0.87634886, grad/param norm = 2.3405e-01, time/batch = 0.6950s	
24230/28500 (epoch 42.509), train_loss = 0.79116412, grad/param norm = 1.7566e-01, time/batch = 0.6992s	
24231/28500 (epoch 42.511), train_loss = 0.79850307, grad/param norm = 1.7844e-01, time/batch = 0.6899s	
24232/28500 (epoch 42.512), train_loss = 0.84814613, grad/param norm = 1.7658e-01, time/batch = 0.6938s	
24233/28500 (epoch 42.514), train_loss = 0.78908992, grad/param norm = 1.7682e-01, time/batch = 0.6876s	
24234/28500 (epoch 42.516), train_loss = 0.79764271, grad/param norm = 1.6951e-01, time/batch = 0.6812s	
24235/28500 (epoch 42.518), train_loss = 0.84285865, grad/param norm = 1.8922e-01, time/batch = 0.6837s	
24236/28500 (epoch 42.519), train_loss = 0.81728483, grad/param norm = 1.7160e-01, time/batch = 0.6787s	
24237/28500 (epoch 42.521), train_loss = 0.92285811, grad/param norm = 2.7158e-01, time/batch = 0.6889s	
24238/28500 (epoch 42.523), train_loss = 0.85284654, grad/param norm = 2.1697e-01, time/batch = 0.6933s	
24239/28500 (epoch 42.525), train_loss = 0.91721617, grad/param norm = 1.8538e-01, time/batch = 0.6820s	
24240/28500 (epoch 42.526), train_loss = 0.85413294, grad/param norm = 1.8955e-01, time/batch = 0.6754s	
24241/28500 (epoch 42.528), train_loss = 0.86167469, grad/param norm = 2.2676e-01, time/batch = 0.6808s	
24242/28500 (epoch 42.530), train_loss = 0.84371304, grad/param norm = 1.8519e-01, time/batch = 0.6851s	
24243/28500 (epoch 42.532), train_loss = 0.79732494, grad/param norm = 2.0228e-01, time/batch = 0.6804s	
24244/28500 (epoch 42.533), train_loss = 0.84694042, grad/param norm = 1.9925e-01, time/batch = 0.6789s	
24245/28500 (epoch 42.535), train_loss = 0.71451780, grad/param norm = 1.7139e-01, time/batch = 0.6788s	
24246/28500 (epoch 42.537), train_loss = 0.69626849, grad/param norm = 1.7631e-01, time/batch = 0.6757s	
24247/28500 (epoch 42.539), train_loss = 0.69163097, grad/param norm = 1.7472e-01, time/batch = 0.6767s	
24248/28500 (epoch 42.540), train_loss = 0.78534912, grad/param norm = 1.7130e-01, time/batch = 0.6845s	
24249/28500 (epoch 42.542), train_loss = 0.82886598, grad/param norm = 2.0762e-01, time/batch = 0.6808s	
24250/28500 (epoch 42.544), train_loss = 0.93204011, grad/param norm = 2.0289e-01, time/batch = 0.6803s	
24251/28500 (epoch 42.546), train_loss = 0.79045770, grad/param norm = 1.8456e-01, time/batch = 0.6789s	
24252/28500 (epoch 42.547), train_loss = 0.77860902, grad/param norm = 1.8209e-01, time/batch = 0.6809s	
24253/28500 (epoch 42.549), train_loss = 0.68041853, grad/param norm = 1.4929e-01, time/batch = 0.6761s	
24254/28500 (epoch 42.551), train_loss = 0.74606666, grad/param norm = 2.1724e-01, time/batch = 0.6799s	
24255/28500 (epoch 42.553), train_loss = 0.94987127, grad/param norm = 2.3583e-01, time/batch = 0.6763s	
24256/28500 (epoch 42.554), train_loss = 0.84308913, grad/param norm = 2.0238e-01, time/batch = 0.6777s	
24257/28500 (epoch 42.556), train_loss = 0.84995831, grad/param norm = 1.8113e-01, time/batch = 0.6781s	
24258/28500 (epoch 42.558), train_loss = 0.86992486, grad/param norm = 1.7961e-01, time/batch = 0.6791s	
24259/28500 (epoch 42.560), train_loss = 0.84359665, grad/param norm = 1.9431e-01, time/batch = 0.6756s	
24260/28500 (epoch 42.561), train_loss = 0.87625146, grad/param norm = 2.2222e-01, time/batch = 0.6775s	
24261/28500 (epoch 42.563), train_loss = 0.94614671, grad/param norm = 2.1801e-01, time/batch = 0.6782s	
24262/28500 (epoch 42.565), train_loss = 0.75567059, grad/param norm = 1.8241e-01, time/batch = 0.6764s	
24263/28500 (epoch 42.567), train_loss = 0.69641466, grad/param norm = 1.8812e-01, time/batch = 0.6797s	
24264/28500 (epoch 42.568), train_loss = 0.82112517, grad/param norm = 2.0562e-01, time/batch = 0.6780s	
24265/28500 (epoch 42.570), train_loss = 0.79588285, grad/param norm = 2.1339e-01, time/batch = 0.6773s	
24266/28500 (epoch 42.572), train_loss = 0.82628419, grad/param norm = 1.9052e-01, time/batch = 0.6759s	
24267/28500 (epoch 42.574), train_loss = 0.76071046, grad/param norm = 1.7441e-01, time/batch = 0.6776s	
24268/28500 (epoch 42.575), train_loss = 0.76171131, grad/param norm = 2.0944e-01, time/batch = 0.6759s	
24269/28500 (epoch 42.577), train_loss = 0.88309393, grad/param norm = 2.0182e-01, time/batch = 0.6763s	
24270/28500 (epoch 42.579), train_loss = 0.88569206, grad/param norm = 2.1037e-01, time/batch = 0.6813s	
24271/28500 (epoch 42.581), train_loss = 0.75400979, grad/param norm = 2.0233e-01, time/batch = 0.6841s	
24272/28500 (epoch 42.582), train_loss = 0.92842932, grad/param norm = 2.2452e-01, time/batch = 0.6877s	
24273/28500 (epoch 42.584), train_loss = 0.74991646, grad/param norm = 1.7208e-01, time/batch = 0.6761s	
24274/28500 (epoch 42.586), train_loss = 0.73354686, grad/param norm = 1.7642e-01, time/batch = 0.6776s	
24275/28500 (epoch 42.588), train_loss = 0.75323401, grad/param norm = 1.7676e-01, time/batch = 0.6752s	
24276/28500 (epoch 42.589), train_loss = 0.77518691, grad/param norm = 1.7630e-01, time/batch = 0.6798s	
24277/28500 (epoch 42.591), train_loss = 0.81746186, grad/param norm = 2.0689e-01, time/batch = 0.6759s	
24278/28500 (epoch 42.593), train_loss = 0.75447607, grad/param norm = 1.6787e-01, time/batch = 0.6820s	
24279/28500 (epoch 42.595), train_loss = 0.95292182, grad/param norm = 2.1188e-01, time/batch = 0.6901s	
24280/28500 (epoch 42.596), train_loss = 0.97082976, grad/param norm = 2.1572e-01, time/batch = 0.6878s	
24281/28500 (epoch 42.598), train_loss = 0.80030162, grad/param norm = 1.9032e-01, time/batch = 0.6935s	
24282/28500 (epoch 42.600), train_loss = 0.78594053, grad/param norm = 1.8973e-01, time/batch = 0.6872s	
24283/28500 (epoch 42.602), train_loss = 0.86300403, grad/param norm = 2.0165e-01, time/batch = 0.6796s	
24284/28500 (epoch 42.604), train_loss = 0.88942976, grad/param norm = 1.9112e-01, time/batch = 0.6814s	
24285/28500 (epoch 42.605), train_loss = 0.88596808, grad/param norm = 1.9951e-01, time/batch = 0.6831s	
24286/28500 (epoch 42.607), train_loss = 0.92426772, grad/param norm = 1.8473e-01, time/batch = 0.6828s	
24287/28500 (epoch 42.609), train_loss = 0.84044034, grad/param norm = 2.1585e-01, time/batch = 0.6865s	
24288/28500 (epoch 42.611), train_loss = 0.80829175, grad/param norm = 2.0259e-01, time/batch = 0.6843s	
24289/28500 (epoch 42.612), train_loss = 0.86734299, grad/param norm = 2.0469e-01, time/batch = 0.6818s	
24290/28500 (epoch 42.614), train_loss = 0.90158507, grad/param norm = 2.0506e-01, time/batch = 0.6813s	
24291/28500 (epoch 42.616), train_loss = 0.77443049, grad/param norm = 1.9689e-01, time/batch = 0.6792s	
24292/28500 (epoch 42.618), train_loss = 0.79298030, grad/param norm = 1.8990e-01, time/batch = 0.6871s	
24293/28500 (epoch 42.619), train_loss = 0.87928545, grad/param norm = 2.1926e-01, time/batch = 0.6773s	
24294/28500 (epoch 42.621), train_loss = 0.66554161, grad/param norm = 1.9490e-01, time/batch = 0.6791s	
24295/28500 (epoch 42.623), train_loss = 0.92530261, grad/param norm = 1.8344e-01, time/batch = 0.6790s	
24296/28500 (epoch 42.625), train_loss = 0.72948066, grad/param norm = 1.6515e-01, time/batch = 0.6823s	
24297/28500 (epoch 42.626), train_loss = 0.66094390, grad/param norm = 1.7604e-01, time/batch = 0.6775s	
24298/28500 (epoch 42.628), train_loss = 0.74836920, grad/param norm = 1.8609e-01, time/batch = 0.6795s	
24299/28500 (epoch 42.630), train_loss = 0.71390988, grad/param norm = 1.6130e-01, time/batch = 0.6797s	
24300/28500 (epoch 42.632), train_loss = 0.89985689, grad/param norm = 2.1230e-01, time/batch = 0.6830s	
24301/28500 (epoch 42.633), train_loss = 0.94070875, grad/param norm = 1.7287e-01, time/batch = 0.6806s	
24302/28500 (epoch 42.635), train_loss = 0.85784699, grad/param norm = 2.2873e-01, time/batch = 0.6845s	
24303/28500 (epoch 42.637), train_loss = 0.82146471, grad/param norm = 1.7157e-01, time/batch = 0.6787s	
24304/28500 (epoch 42.639), train_loss = 0.72322255, grad/param norm = 2.0011e-01, time/batch = 0.6825s	
24305/28500 (epoch 42.640), train_loss = 0.77060914, grad/param norm = 1.9465e-01, time/batch = 0.6783s	
24306/28500 (epoch 42.642), train_loss = 0.77067025, grad/param norm = 1.8562e-01, time/batch = 0.6814s	
24307/28500 (epoch 42.644), train_loss = 0.83980661, grad/param norm = 2.0316e-01, time/batch = 0.6780s	
24308/28500 (epoch 42.646), train_loss = 0.66079818, grad/param norm = 1.4848e-01, time/batch = 0.6798s	
24309/28500 (epoch 42.647), train_loss = 0.75858437, grad/param norm = 1.7428e-01, time/batch = 0.6797s	
24310/28500 (epoch 42.649), train_loss = 0.75779293, grad/param norm = 2.0588e-01, time/batch = 0.6792s	
24311/28500 (epoch 42.651), train_loss = 0.70266091, grad/param norm = 1.3722e-01, time/batch = 0.6877s	
24312/28500 (epoch 42.653), train_loss = 0.68847115, grad/param norm = 1.8351e-01, time/batch = 0.6825s	
24313/28500 (epoch 42.654), train_loss = 0.73509962, grad/param norm = 1.8649e-01, time/batch = 0.6841s	
24314/28500 (epoch 42.656), train_loss = 0.68158463, grad/param norm = 1.8350e-01, time/batch = 0.6809s	
24315/28500 (epoch 42.658), train_loss = 0.80602749, grad/param norm = 1.9797e-01, time/batch = 0.6829s	
24316/28500 (epoch 42.660), train_loss = 0.80808652, grad/param norm = 1.7377e-01, time/batch = 0.6797s	
24317/28500 (epoch 42.661), train_loss = 0.90066203, grad/param norm = 2.4529e-01, time/batch = 0.6835s	
24318/28500 (epoch 42.663), train_loss = 0.89416842, grad/param norm = 1.9873e-01, time/batch = 0.6815s	
24319/28500 (epoch 42.665), train_loss = 0.81138791, grad/param norm = 2.1900e-01, time/batch = 0.6838s	
24320/28500 (epoch 42.667), train_loss = 0.83912897, grad/param norm = 2.1143e-01, time/batch = 0.6790s	
24321/28500 (epoch 42.668), train_loss = 0.80876827, grad/param norm = 1.8980e-01, time/batch = 0.6841s	
24322/28500 (epoch 42.670), train_loss = 0.82248490, grad/param norm = 2.1264e-01, time/batch = 0.6819s	
24323/28500 (epoch 42.672), train_loss = 0.74363016, grad/param norm = 2.0437e-01, time/batch = 0.6839s	
24324/28500 (epoch 42.674), train_loss = 0.64199946, grad/param norm = 1.8344e-01, time/batch = 0.6803s	
24325/28500 (epoch 42.675), train_loss = 0.67765119, grad/param norm = 1.6563e-01, time/batch = 0.6821s	
24326/28500 (epoch 42.677), train_loss = 0.75386174, grad/param norm = 1.7109e-01, time/batch = 0.6826s	
24327/28500 (epoch 42.679), train_loss = 0.76841231, grad/param norm = 1.8311e-01, time/batch = 0.6815s	
24328/28500 (epoch 42.681), train_loss = 0.84087441, grad/param norm = 1.8873e-01, time/batch = 0.6794s	
24329/28500 (epoch 42.682), train_loss = 0.76691025, grad/param norm = 2.0253e-01, time/batch = 0.6848s	
24330/28500 (epoch 42.684), train_loss = 0.81000017, grad/param norm = 2.0632e-01, time/batch = 0.6798s	
24331/28500 (epoch 42.686), train_loss = 0.75473899, grad/param norm = 1.7615e-01, time/batch = 0.6855s	
24332/28500 (epoch 42.688), train_loss = 0.73710524, grad/param norm = 1.5315e-01, time/batch = 0.6797s	
24333/28500 (epoch 42.689), train_loss = 0.73431370, grad/param norm = 2.0160e-01, time/batch = 0.6798s	
24334/28500 (epoch 42.691), train_loss = 0.85131486, grad/param norm = 1.8796e-01, time/batch = 0.6793s	
24335/28500 (epoch 42.693), train_loss = 0.76861638, grad/param norm = 1.7832e-01, time/batch = 0.6821s	
24336/28500 (epoch 42.695), train_loss = 0.59304152, grad/param norm = 1.7275e-01, time/batch = 0.6793s	
24337/28500 (epoch 42.696), train_loss = 0.76206392, grad/param norm = 2.1053e-01, time/batch = 0.6836s	
24338/28500 (epoch 42.698), train_loss = 0.83883368, grad/param norm = 1.8150e-01, time/batch = 0.6791s	
24339/28500 (epoch 42.700), train_loss = 0.80908592, grad/param norm = 1.8923e-01, time/batch = 0.6808s	
24340/28500 (epoch 42.702), train_loss = 0.79585571, grad/param norm = 2.1671e-01, time/batch = 0.6797s	
24341/28500 (epoch 42.704), train_loss = 0.85380756, grad/param norm = 2.0637e-01, time/batch = 0.6811s	
24342/28500 (epoch 42.705), train_loss = 0.85910420, grad/param norm = 2.3803e-01, time/batch = 0.6799s	
24343/28500 (epoch 42.707), train_loss = 0.73930289, grad/param norm = 1.9538e-01, time/batch = 0.6811s	
24344/28500 (epoch 42.709), train_loss = 0.93614233, grad/param norm = 2.0482e-01, time/batch = 0.6803s	
24345/28500 (epoch 42.711), train_loss = 0.75712180, grad/param norm = 2.3300e-01, time/batch = 0.6826s	
24346/28500 (epoch 42.712), train_loss = 0.82572907, grad/param norm = 2.0111e-01, time/batch = 0.6794s	
24347/28500 (epoch 42.714), train_loss = 0.91767944, grad/param norm = 2.1789e-01, time/batch = 0.6835s	
24348/28500 (epoch 42.716), train_loss = 0.78347973, grad/param norm = 1.7767e-01, time/batch = 0.6808s	
24349/28500 (epoch 42.718), train_loss = 0.82561779, grad/param norm = 1.9805e-01, time/batch = 0.6825s	
24350/28500 (epoch 42.719), train_loss = 0.81983837, grad/param norm = 1.8555e-01, time/batch = 0.6797s	
24351/28500 (epoch 42.721), train_loss = 0.61949290, grad/param norm = 1.7460e-01, time/batch = 0.6850s	
24352/28500 (epoch 42.723), train_loss = 0.79022131, grad/param norm = 1.8155e-01, time/batch = 0.6812s	
24353/28500 (epoch 42.725), train_loss = 0.86685373, grad/param norm = 2.1127e-01, time/batch = 0.6798s	
24354/28500 (epoch 42.726), train_loss = 0.77745169, grad/param norm = 1.8019e-01, time/batch = 0.6810s	
24355/28500 (epoch 42.728), train_loss = 0.72287500, grad/param norm = 1.9619e-01, time/batch = 0.6798s	
24356/28500 (epoch 42.730), train_loss = 0.79401707, grad/param norm = 2.4344e-01, time/batch = 0.6820s	
24357/28500 (epoch 42.732), train_loss = 0.64544232, grad/param norm = 1.6317e-01, time/batch = 0.6859s	
24358/28500 (epoch 42.733), train_loss = 0.68672392, grad/param norm = 1.7223e-01, time/batch = 0.6932s	
24359/28500 (epoch 42.735), train_loss = 0.69714439, grad/param norm = 1.7494e-01, time/batch = 0.6899s	
24360/28500 (epoch 42.737), train_loss = 0.61339534, grad/param norm = 1.5688e-01, time/batch = 0.7044s	
24361/28500 (epoch 42.739), train_loss = 0.69695969, grad/param norm = 1.8127e-01, time/batch = 0.6982s	
24362/28500 (epoch 42.740), train_loss = 0.78463602, grad/param norm = 1.8611e-01, time/batch = 0.6870s	
24363/28500 (epoch 42.742), train_loss = 0.71269964, grad/param norm = 1.9920e-01, time/batch = 0.6784s	
24364/28500 (epoch 42.744), train_loss = 0.79587528, grad/param norm = 1.8000e-01, time/batch = 0.6880s	
24365/28500 (epoch 42.746), train_loss = 0.74310124, grad/param norm = 1.5504e-01, time/batch = 0.6829s	
24366/28500 (epoch 42.747), train_loss = 0.76654939, grad/param norm = 1.8613e-01, time/batch = 0.6774s	
24367/28500 (epoch 42.749), train_loss = 0.85891456, grad/param norm = 2.4357e-01, time/batch = 0.6770s	
24368/28500 (epoch 42.751), train_loss = 0.71119228, grad/param norm = 2.3225e-01, time/batch = 0.6791s	
24369/28500 (epoch 42.753), train_loss = 0.80104786, grad/param norm = 1.6427e-01, time/batch = 0.6756s	
24370/28500 (epoch 42.754), train_loss = 0.70957031, grad/param norm = 2.0372e-01, time/batch = 0.6763s	
24371/28500 (epoch 42.756), train_loss = 0.91958589, grad/param norm = 1.9652e-01, time/batch = 0.6787s	
24372/28500 (epoch 42.758), train_loss = 0.83692197, grad/param norm = 2.2946e-01, time/batch = 0.6778s	
24373/28500 (epoch 42.760), train_loss = 0.69211640, grad/param norm = 1.7314e-01, time/batch = 0.6757s	
24374/28500 (epoch 42.761), train_loss = 0.75752067, grad/param norm = 1.9422e-01, time/batch = 0.6761s	
24375/28500 (epoch 42.763), train_loss = 0.61836681, grad/param norm = 1.6981e-01, time/batch = 0.6762s	
24376/28500 (epoch 42.765), train_loss = 0.77622146, grad/param norm = 1.8348e-01, time/batch = 0.6761s	
24377/28500 (epoch 42.767), train_loss = 0.64289655, grad/param norm = 1.6784e-01, time/batch = 0.6776s	
24378/28500 (epoch 42.768), train_loss = 0.81459908, grad/param norm = 1.9472e-01, time/batch = 0.6779s	
24379/28500 (epoch 42.770), train_loss = 0.69838569, grad/param norm = 1.8269e-01, time/batch = 0.7080s	
24380/28500 (epoch 42.772), train_loss = 0.65242680, grad/param norm = 1.4981e-01, time/batch = 0.6775s	
24381/28500 (epoch 42.774), train_loss = 0.77023376, grad/param norm = 1.6431e-01, time/batch = 0.6800s	
24382/28500 (epoch 42.775), train_loss = 0.82660401, grad/param norm = 1.8325e-01, time/batch = 0.6804s	
24383/28500 (epoch 42.777), train_loss = 0.85076361, grad/param norm = 1.7073e-01, time/batch = 0.6770s	
24384/28500 (epoch 42.779), train_loss = 0.66568228, grad/param norm = 1.4931e-01, time/batch = 0.6818s	
24385/28500 (epoch 42.781), train_loss = 0.77907655, grad/param norm = 2.0302e-01, time/batch = 0.6801s	
24386/28500 (epoch 42.782), train_loss = 0.81354571, grad/param norm = 2.5588e-01, time/batch = 0.6984s	
24387/28500 (epoch 42.784), train_loss = 0.63088023, grad/param norm = 1.6400e-01, time/batch = 0.6880s	
24388/28500 (epoch 42.786), train_loss = 0.65023805, grad/param norm = 1.8359e-01, time/batch = 0.6791s	
24389/28500 (epoch 42.788), train_loss = 0.73430597, grad/param norm = 2.0122e-01, time/batch = 0.6792s	
24390/28500 (epoch 42.789), train_loss = 0.58886581, grad/param norm = 2.1330e-01, time/batch = 0.6786s	
24391/28500 (epoch 42.791), train_loss = 0.80807244, grad/param norm = 1.8714e-01, time/batch = 0.6853s	
24392/28500 (epoch 42.793), train_loss = 0.77611845, grad/param norm = 2.0850e-01, time/batch = 0.6789s	
24393/28500 (epoch 42.795), train_loss = 0.77220862, grad/param norm = 1.7871e-01, time/batch = 0.6833s	
24394/28500 (epoch 42.796), train_loss = 0.70614397, grad/param norm = 1.7631e-01, time/batch = 0.6948s	
24395/28500 (epoch 42.798), train_loss = 0.66694952, grad/param norm = 1.9245e-01, time/batch = 0.6804s	
24396/28500 (epoch 42.800), train_loss = 0.65124837, grad/param norm = 2.5242e-01, time/batch = 0.6791s	
24397/28500 (epoch 42.802), train_loss = 0.75094255, grad/param norm = 2.4473e-01, time/batch = 0.6806s	
24398/28500 (epoch 42.804), train_loss = 0.78974284, grad/param norm = 1.6206e-01, time/batch = 0.6782s	
24399/28500 (epoch 42.805), train_loss = 0.81158535, grad/param norm = 2.2984e-01, time/batch = 0.6810s	
24400/28500 (epoch 42.807), train_loss = 0.79196712, grad/param norm = 1.9813e-01, time/batch = 0.6807s	
24401/28500 (epoch 42.809), train_loss = 0.78923168, grad/param norm = 2.2011e-01, time/batch = 0.6980s	
24402/28500 (epoch 42.811), train_loss = 0.79586313, grad/param norm = 1.9667e-01, time/batch = 0.6919s	
24403/28500 (epoch 42.812), train_loss = 0.76870271, grad/param norm = 2.0931e-01, time/batch = 0.6814s	
24404/28500 (epoch 42.814), train_loss = 0.73210471, grad/param norm = 1.8951e-01, time/batch = 0.6796s	
24405/28500 (epoch 42.816), train_loss = 0.81612046, grad/param norm = 2.2522e-01, time/batch = 0.6829s	
24406/28500 (epoch 42.818), train_loss = 0.90395422, grad/param norm = 2.1866e-01, time/batch = 0.6816s	
24407/28500 (epoch 42.819), train_loss = 0.78121520, grad/param norm = 1.9114e-01, time/batch = 0.6793s	
24408/28500 (epoch 42.821), train_loss = 0.75028999, grad/param norm = 1.8539e-01, time/batch = 0.6825s	
24409/28500 (epoch 42.823), train_loss = 0.90538380, grad/param norm = 2.8906e-01, time/batch = 0.7002s	
24410/28500 (epoch 42.825), train_loss = 0.69958282, grad/param norm = 1.9359e-01, time/batch = 0.6850s	
24411/28500 (epoch 42.826), train_loss = 0.78907543, grad/param norm = 1.9449e-01, time/batch = 0.6838s	
24412/28500 (epoch 42.828), train_loss = 0.71013027, grad/param norm = 1.9544e-01, time/batch = 0.6823s	
24413/28500 (epoch 42.830), train_loss = 0.73448194, grad/param norm = 1.6787e-01, time/batch = 0.6765s	
24414/28500 (epoch 42.832), train_loss = 0.76751545, grad/param norm = 2.4026e-01, time/batch = 0.6786s	
24415/28500 (epoch 42.833), train_loss = 0.81973374, grad/param norm = 1.8426e-01, time/batch = 0.6871s	
24416/28500 (epoch 42.835), train_loss = 0.73367529, grad/param norm = 1.8394e-01, time/batch = 0.6830s	
24417/28500 (epoch 42.837), train_loss = 0.68142471, grad/param norm = 1.9971e-01, time/batch = 0.6925s	
24418/28500 (epoch 42.839), train_loss = 0.93820624, grad/param norm = 2.7422e-01, time/batch = 0.6754s	
24419/28500 (epoch 42.840), train_loss = 0.93250261, grad/param norm = 2.2843e-01, time/batch = 0.6770s	
24420/28500 (epoch 42.842), train_loss = 0.86316132, grad/param norm = 2.9676e-01, time/batch = 0.6758s	
24421/28500 (epoch 42.844), train_loss = 0.86404364, grad/param norm = 2.0003e-01, time/batch = 0.6798s	
24422/28500 (epoch 42.846), train_loss = 0.94616654, grad/param norm = 2.3220e-01, time/batch = 0.6768s	
24423/28500 (epoch 42.847), train_loss = 0.75840981, grad/param norm = 1.9977e-01, time/batch = 0.6769s	
24424/28500 (epoch 42.849), train_loss = 0.74230072, grad/param norm = 1.7005e-01, time/batch = 0.6913s	
24425/28500 (epoch 42.851), train_loss = 0.71999083, grad/param norm = 1.6064e-01, time/batch = 0.6828s	
24426/28500 (epoch 42.853), train_loss = 0.83043325, grad/param norm = 2.1107e-01, time/batch = 0.6758s	
24427/28500 (epoch 42.854), train_loss = 0.80711773, grad/param norm = 2.0664e-01, time/batch = 0.6778s	
24428/28500 (epoch 42.856), train_loss = 0.88595058, grad/param norm = 2.5121e-01, time/batch = 0.6756s	
24429/28500 (epoch 42.858), train_loss = 0.75487233, grad/param norm = 1.8359e-01, time/batch = 0.6777s	
24430/28500 (epoch 42.860), train_loss = 0.78703001, grad/param norm = 1.9265e-01, time/batch = 0.6755s	
24431/28500 (epoch 42.861), train_loss = 0.87365981, grad/param norm = 2.2197e-01, time/batch = 0.6795s	
24432/28500 (epoch 42.863), train_loss = 0.82665206, grad/param norm = 2.4567e-01, time/batch = 0.6873s	
24433/28500 (epoch 42.865), train_loss = 0.75008887, grad/param norm = 2.1179e-01, time/batch = 0.6855s	
24434/28500 (epoch 42.867), train_loss = 0.80984633, grad/param norm = 2.0225e-01, time/batch = 0.6761s	
24435/28500 (epoch 42.868), train_loss = 0.70548303, grad/param norm = 1.8893e-01, time/batch = 0.6762s	
24436/28500 (epoch 42.870), train_loss = 0.67608511, grad/param norm = 2.0212e-01, time/batch = 0.6772s	
24437/28500 (epoch 42.872), train_loss = 0.84760907, grad/param norm = 2.0632e-01, time/batch = 0.6756s	
24438/28500 (epoch 42.874), train_loss = 0.71364031, grad/param norm = 2.0595e-01, time/batch = 0.6776s	
24439/28500 (epoch 42.875), train_loss = 0.95109777, grad/param norm = 3.2257e-01, time/batch = 0.6760s	
24440/28500 (epoch 42.877), train_loss = 0.82137424, grad/param norm = 2.1275e-01, time/batch = 0.6799s	
24441/28500 (epoch 42.879), train_loss = 0.84017604, grad/param norm = 1.6991e-01, time/batch = 0.6850s	
24442/28500 (epoch 42.881), train_loss = 0.82201673, grad/param norm = 1.8404e-01, time/batch = 0.6812s	
24443/28500 (epoch 42.882), train_loss = 0.71737702, grad/param norm = 1.6852e-01, time/batch = 0.6808s	
24444/28500 (epoch 42.884), train_loss = 0.76029687, grad/param norm = 1.8900e-01, time/batch = 0.6763s	
24445/28500 (epoch 42.886), train_loss = 0.73122925, grad/param norm = 1.7986e-01, time/batch = 0.6819s	
24446/28500 (epoch 42.888), train_loss = 0.75746104, grad/param norm = 1.8982e-01, time/batch = 0.6833s	
24447/28500 (epoch 42.889), train_loss = 0.80911288, grad/param norm = 1.6686e-01, time/batch = 0.6890s	
24448/28500 (epoch 42.891), train_loss = 0.80182041, grad/param norm = 1.7970e-01, time/batch = 0.6766s	
24449/28500 (epoch 42.893), train_loss = 0.74981674, grad/param norm = 1.8492e-01, time/batch = 0.6874s	
24450/28500 (epoch 42.895), train_loss = 0.94640210, grad/param norm = 2.4245e-01, time/batch = 0.6831s	
24451/28500 (epoch 42.896), train_loss = 0.89504059, grad/param norm = 2.1155e-01, time/batch = 0.6820s	
24452/28500 (epoch 42.898), train_loss = 0.86422387, grad/param norm = 1.9823e-01, time/batch = 0.6832s	
24453/28500 (epoch 42.900), train_loss = 0.69664113, grad/param norm = 1.8387e-01, time/batch = 0.6770s	
24454/28500 (epoch 42.902), train_loss = 0.67925082, grad/param norm = 1.9000e-01, time/batch = 0.6766s	
24455/28500 (epoch 42.904), train_loss = 0.70926861, grad/param norm = 1.8481e-01, time/batch = 0.6802s	
24456/28500 (epoch 42.905), train_loss = 0.76092747, grad/param norm = 2.1275e-01, time/batch = 0.6761s	
24457/28500 (epoch 42.907), train_loss = 0.76157021, grad/param norm = 1.6791e-01, time/batch = 0.6768s	
24458/28500 (epoch 42.909), train_loss = 0.65639378, grad/param norm = 2.0306e-01, time/batch = 0.6766s	
24459/28500 (epoch 42.911), train_loss = 0.70114249, grad/param norm = 1.6685e-01, time/batch = 0.6756s	
24460/28500 (epoch 42.912), train_loss = 0.58432639, grad/param norm = 1.5205e-01, time/batch = 0.6754s	
24461/28500 (epoch 42.914), train_loss = 0.80148684, grad/param norm = 1.7683e-01, time/batch = 0.6820s	
24462/28500 (epoch 42.916), train_loss = 0.79379823, grad/param norm = 1.9210e-01, time/batch = 0.6766s	
24463/28500 (epoch 42.918), train_loss = 0.78023086, grad/param norm = 2.1345e-01, time/batch = 0.6780s	
24464/28500 (epoch 42.919), train_loss = 0.80745706, grad/param norm = 1.7246e-01, time/batch = 0.6760s	
24465/28500 (epoch 42.921), train_loss = 0.88203242, grad/param norm = 2.2657e-01, time/batch = 0.6779s	
24466/28500 (epoch 42.923), train_loss = 0.71065487, grad/param norm = 2.0855e-01, time/batch = 0.6783s	
24467/28500 (epoch 42.925), train_loss = 0.73482056, grad/param norm = 2.1970e-01, time/batch = 0.6803s	
24468/28500 (epoch 42.926), train_loss = 0.78513455, grad/param norm = 1.8308e-01, time/batch = 0.6763s	
24469/28500 (epoch 42.928), train_loss = 0.75208818, grad/param norm = 1.8994e-01, time/batch = 0.6782s	
24470/28500 (epoch 42.930), train_loss = 0.63086442, grad/param norm = 1.6436e-01, time/batch = 0.6771s	
24471/28500 (epoch 42.932), train_loss = 0.64339017, grad/param norm = 1.6322e-01, time/batch = 0.6801s	
24472/28500 (epoch 42.933), train_loss = 0.84564475, grad/param norm = 1.8412e-01, time/batch = 0.6759s	
24473/28500 (epoch 42.935), train_loss = 0.85960158, grad/param norm = 1.7101e-01, time/batch = 0.6841s	
24474/28500 (epoch 42.937), train_loss = 0.83939719, grad/param norm = 2.3929e-01, time/batch = 0.6880s	
24475/28500 (epoch 42.939), train_loss = 0.89506938, grad/param norm = 2.4322e-01, time/batch = 0.6820s	
24476/28500 (epoch 42.940), train_loss = 0.63078653, grad/param norm = 1.6804e-01, time/batch = 0.6805s	
24477/28500 (epoch 42.942), train_loss = 0.78426708, grad/param norm = 1.8295e-01, time/batch = 0.6795s	
24478/28500 (epoch 42.944), train_loss = 0.75632435, grad/param norm = 1.9752e-01, time/batch = 0.6755s	
24479/28500 (epoch 42.946), train_loss = 0.83622000, grad/param norm = 1.9260e-01, time/batch = 0.6812s	
24480/28500 (epoch 42.947), train_loss = 0.98668524, grad/param norm = 2.4622e-01, time/batch = 0.6803s	
24481/28500 (epoch 42.949), train_loss = 0.77088278, grad/param norm = 2.0937e-01, time/batch = 0.6775s	
24482/28500 (epoch 42.951), train_loss = 0.93688105, grad/param norm = 1.7895e-01, time/batch = 0.6783s	
24483/28500 (epoch 42.953), train_loss = 0.94676971, grad/param norm = 2.1263e-01, time/batch = 0.6781s	
24484/28500 (epoch 42.954), train_loss = 0.87883030, grad/param norm = 1.9559e-01, time/batch = 0.6813s	
24485/28500 (epoch 42.956), train_loss = 0.79229883, grad/param norm = 2.5843e-01, time/batch = 0.6759s	
24486/28500 (epoch 42.958), train_loss = 1.02327008, grad/param norm = 1.9214e-01, time/batch = 0.6761s	
24487/28500 (epoch 42.960), train_loss = 0.72574566, grad/param norm = 2.0912e-01, time/batch = 0.6766s	
24488/28500 (epoch 42.961), train_loss = 0.93842888, grad/param norm = 2.2836e-01, time/batch = 0.6755s	
24489/28500 (epoch 42.963), train_loss = 0.87297324, grad/param norm = 2.0805e-01, time/batch = 0.6865s	
24490/28500 (epoch 42.965), train_loss = 0.71998145, grad/param norm = 1.8591e-01, time/batch = 0.6783s	
24491/28500 (epoch 42.967), train_loss = 0.74564005, grad/param norm = 1.8623e-01, time/batch = 0.6876s	
24492/28500 (epoch 42.968), train_loss = 0.69770233, grad/param norm = 1.5746e-01, time/batch = 0.6770s	
24493/28500 (epoch 42.970), train_loss = 0.71382293, grad/param norm = 1.9617e-01, time/batch = 0.6947s	
24494/28500 (epoch 42.972), train_loss = 0.79087464, grad/param norm = 1.9577e-01, time/batch = 0.6855s	
24495/28500 (epoch 42.974), train_loss = 0.99253847, grad/param norm = 2.4848e-01, time/batch = 0.6804s	
24496/28500 (epoch 42.975), train_loss = 0.74266010, grad/param norm = 1.9499e-01, time/batch = 0.6792s	
24497/28500 (epoch 42.977), train_loss = 0.89556813, grad/param norm = 2.3032e-01, time/batch = 0.6765s	
24498/28500 (epoch 42.979), train_loss = 0.83282749, grad/param norm = 1.8667e-01, time/batch = 0.6816s	
24499/28500 (epoch 42.981), train_loss = 0.68732576, grad/param norm = 1.8873e-01, time/batch = 0.6811s	
24500/28500 (epoch 42.982), train_loss = 0.79343409, grad/param norm = 2.1336e-01, time/batch = 0.6783s	
24501/28500 (epoch 42.984), train_loss = 0.86599749, grad/param norm = 1.7882e-01, time/batch = 0.6831s	
24502/28500 (epoch 42.986), train_loss = 1.01951222, grad/param norm = 2.2623e-01, time/batch = 0.6772s	
24503/28500 (epoch 42.988), train_loss = 0.71523892, grad/param norm = 1.8845e-01, time/batch = 0.6878s	
24504/28500 (epoch 42.989), train_loss = 0.80314548, grad/param norm = 1.9612e-01, time/batch = 0.6774s	
24505/28500 (epoch 42.991), train_loss = 0.70718558, grad/param norm = 1.7577e-01, time/batch = 0.6764s	
24506/28500 (epoch 42.993), train_loss = 0.72073455, grad/param norm = 2.1304e-01, time/batch = 0.6764s	
24507/28500 (epoch 42.995), train_loss = 0.75908730, grad/param norm = 2.0463e-01, time/batch = 0.6781s	
24508/28500 (epoch 42.996), train_loss = 0.69293831, grad/param norm = 1.9804e-01, time/batch = 0.6791s	
24509/28500 (epoch 42.998), train_loss = 0.90149839, grad/param norm = 2.3189e-01, time/batch = 0.6781s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
24510/28500 (epoch 43.000), train_loss = 0.77377800, grad/param norm = 1.9097e-01, time/batch = 0.6794s	
24511/28500 (epoch 43.002), train_loss = 0.94892332, grad/param norm = 2.1889e-01, time/batch = 0.6816s	
24512/28500 (epoch 43.004), train_loss = 0.81153189, grad/param norm = 1.7504e-01, time/batch = 0.6894s	
24513/28500 (epoch 43.005), train_loss = 0.88563952, grad/param norm = 2.0045e-01, time/batch = 0.6778s	
24514/28500 (epoch 43.007), train_loss = 0.70354607, grad/param norm = 1.6623e-01, time/batch = 0.6877s	
24515/28500 (epoch 43.009), train_loss = 0.80152480, grad/param norm = 1.7744e-01, time/batch = 0.6803s	
24516/28500 (epoch 43.011), train_loss = 0.72316151, grad/param norm = 1.8362e-01, time/batch = 0.6811s	
24517/28500 (epoch 43.012), train_loss = 0.73385918, grad/param norm = 1.7528e-01, time/batch = 0.6787s	
24518/28500 (epoch 43.014), train_loss = 0.70884733, grad/param norm = 1.7777e-01, time/batch = 0.6805s	
24519/28500 (epoch 43.016), train_loss = 0.76373732, grad/param norm = 1.6700e-01, time/batch = 0.6761s	
24520/28500 (epoch 43.018), train_loss = 0.82521275, grad/param norm = 1.9731e-01, time/batch = 0.6798s	
24521/28500 (epoch 43.019), train_loss = 0.88894935, grad/param norm = 2.1096e-01, time/batch = 0.6804s	
24522/28500 (epoch 43.021), train_loss = 0.90061138, grad/param norm = 1.7972e-01, time/batch = 0.6824s	
24523/28500 (epoch 43.023), train_loss = 0.81675074, grad/param norm = 1.8729e-01, time/batch = 0.6809s	
24524/28500 (epoch 43.025), train_loss = 0.83386185, grad/param norm = 1.8427e-01, time/batch = 0.6772s	
24525/28500 (epoch 43.026), train_loss = 0.75691313, grad/param norm = 1.8443e-01, time/batch = 0.6790s	
24526/28500 (epoch 43.028), train_loss = 0.80680988, grad/param norm = 2.2548e-01, time/batch = 0.6788s	
24527/28500 (epoch 43.030), train_loss = 0.84510206, grad/param norm = 2.2992e-01, time/batch = 0.6804s	
24528/28500 (epoch 43.032), train_loss = 0.90954419, grad/param norm = 1.9514e-01, time/batch = 0.6806s	
24529/28500 (epoch 43.033), train_loss = 0.95215919, grad/param norm = 2.1144e-01, time/batch = 0.6815s	
24530/28500 (epoch 43.035), train_loss = 0.77909312, grad/param norm = 1.9118e-01, time/batch = 0.6860s	
24531/28500 (epoch 43.037), train_loss = 0.87240993, grad/param norm = 2.2577e-01, time/batch = 0.7012s	
24532/28500 (epoch 43.039), train_loss = 0.90815400, grad/param norm = 2.0161e-01, time/batch = 0.6945s	
24533/28500 (epoch 43.040), train_loss = 0.91960424, grad/param norm = 1.9057e-01, time/batch = 0.6824s	
24534/28500 (epoch 43.042), train_loss = 0.86443131, grad/param norm = 1.9785e-01, time/batch = 0.6881s	
24535/28500 (epoch 43.044), train_loss = 0.78992092, grad/param norm = 2.1258e-01, time/batch = 0.6954s	
24536/28500 (epoch 43.046), train_loss = 0.98755694, grad/param norm = 1.9830e-01, time/batch = 0.6860s	
24537/28500 (epoch 43.047), train_loss = 0.95439958, grad/param norm = 2.4125e-01, time/batch = 0.6824s	
24538/28500 (epoch 43.049), train_loss = 0.80466976, grad/param norm = 1.9318e-01, time/batch = 0.6932s	
24539/28500 (epoch 43.051), train_loss = 0.82462346, grad/param norm = 2.0986e-01, time/batch = 0.6782s	
24540/28500 (epoch 43.053), train_loss = 0.77687257, grad/param norm = 2.1149e-01, time/batch = 0.6833s	
24541/28500 (epoch 43.054), train_loss = 0.86707915, grad/param norm = 1.8386e-01, time/batch = 0.6825s	
24542/28500 (epoch 43.056), train_loss = 0.77431226, grad/param norm = 1.9036e-01, time/batch = 0.6807s	
24543/28500 (epoch 43.058), train_loss = 0.73421221, grad/param norm = 1.6843e-01, time/batch = 0.6813s	
24544/28500 (epoch 43.060), train_loss = 0.87300615, grad/param norm = 2.2137e-01, time/batch = 0.6849s	
24545/28500 (epoch 43.061), train_loss = 0.78102127, grad/param norm = 1.8979e-01, time/batch = 0.6814s	
24546/28500 (epoch 43.063), train_loss = 0.86381834, grad/param norm = 2.4745e-01, time/batch = 0.6797s	
24547/28500 (epoch 43.065), train_loss = 0.82400986, grad/param norm = 2.0926e-01, time/batch = 0.6843s	
24548/28500 (epoch 43.067), train_loss = 0.76291832, grad/param norm = 1.9968e-01, time/batch = 0.6811s	
24549/28500 (epoch 43.068), train_loss = 0.78605064, grad/param norm = 1.8249e-01, time/batch = 0.6797s	
24550/28500 (epoch 43.070), train_loss = 0.81519921, grad/param norm = 1.9165e-01, time/batch = 0.6850s	
24551/28500 (epoch 43.072), train_loss = 0.93266542, grad/param norm = 2.1687e-01, time/batch = 0.6855s	
24552/28500 (epoch 43.074), train_loss = 0.79188679, grad/param norm = 1.8370e-01, time/batch = 0.6842s	
24553/28500 (epoch 43.075), train_loss = 0.82205245, grad/param norm = 1.8817e-01, time/batch = 0.6886s	
24554/28500 (epoch 43.077), train_loss = 0.86019166, grad/param norm = 1.7384e-01, time/batch = 0.6845s	
24555/28500 (epoch 43.079), train_loss = 0.82665432, grad/param norm = 1.8478e-01, time/batch = 0.6808s	
24556/28500 (epoch 43.081), train_loss = 0.87984606, grad/param norm = 2.0956e-01, time/batch = 0.6825s	
24557/28500 (epoch 43.082), train_loss = 0.78682571, grad/param norm = 2.3615e-01, time/batch = 0.6954s	
24558/28500 (epoch 43.084), train_loss = 0.81487389, grad/param norm = 2.0659e-01, time/batch = 0.6927s	
24559/28500 (epoch 43.086), train_loss = 0.75151244, grad/param norm = 2.1483e-01, time/batch = 0.6935s	
24560/28500 (epoch 43.088), train_loss = 0.72352273, grad/param norm = 1.7886e-01, time/batch = 0.6907s	
24561/28500 (epoch 43.089), train_loss = 0.87332329, grad/param norm = 2.0979e-01, time/batch = 0.6981s	
24562/28500 (epoch 43.091), train_loss = 0.72829087, grad/param norm = 1.7150e-01, time/batch = 0.6929s	
24563/28500 (epoch 43.093), train_loss = 0.89889256, grad/param norm = 1.9839e-01, time/batch = 0.6953s	
24564/28500 (epoch 43.095), train_loss = 0.81534697, grad/param norm = 1.8109e-01, time/batch = 0.6937s	
24565/28500 (epoch 43.096), train_loss = 0.89971343, grad/param norm = 1.9475e-01, time/batch = 0.6925s	
24566/28500 (epoch 43.098), train_loss = 0.78623333, grad/param norm = 2.4468e-01, time/batch = 0.6983s	
24567/28500 (epoch 43.100), train_loss = 0.78341283, grad/param norm = 1.8316e-01, time/batch = 0.6937s	
24568/28500 (epoch 43.102), train_loss = 0.89734355, grad/param norm = 2.3863e-01, time/batch = 0.6949s	
24569/28500 (epoch 43.104), train_loss = 0.83073598, grad/param norm = 2.0260e-01, time/batch = 0.6967s	
24570/28500 (epoch 43.105), train_loss = 0.89774411, grad/param norm = 2.0278e-01, time/batch = 0.6929s	
24571/28500 (epoch 43.107), train_loss = 0.75177326, grad/param norm = 1.9265e-01, time/batch = 0.6981s	
24572/28500 (epoch 43.109), train_loss = 0.79517775, grad/param norm = 2.5043e-01, time/batch = 0.6938s	
24573/28500 (epoch 43.111), train_loss = 0.79278560, grad/param norm = 2.2878e-01, time/batch = 0.6958s	
24574/28500 (epoch 43.112), train_loss = 0.88809329, grad/param norm = 2.1179e-01, time/batch = 0.6922s	
24575/28500 (epoch 43.114), train_loss = 0.80238468, grad/param norm = 2.1168e-01, time/batch = 0.7159s	
24576/28500 (epoch 43.116), train_loss = 0.95111036, grad/param norm = 2.4364e-01, time/batch = 0.6945s	
24577/28500 (epoch 43.118), train_loss = 0.73216656, grad/param norm = 2.1882e-01, time/batch = 0.6989s	
24578/28500 (epoch 43.119), train_loss = 0.85406245, grad/param norm = 2.2389e-01, time/batch = 0.6944s	
24579/28500 (epoch 43.121), train_loss = 0.98743757, grad/param norm = 2.5311e-01, time/batch = 0.6937s	
24580/28500 (epoch 43.123), train_loss = 0.92268721, grad/param norm = 1.9936e-01, time/batch = 0.6981s	
24581/28500 (epoch 43.125), train_loss = 0.84188062, grad/param norm = 2.0223e-01, time/batch = 0.6963s	
24582/28500 (epoch 43.126), train_loss = 0.82043343, grad/param norm = 1.9510e-01, time/batch = 0.6933s	
24583/28500 (epoch 43.128), train_loss = 0.83385445, grad/param norm = 2.1252e-01, time/batch = 0.6940s	
24584/28500 (epoch 43.130), train_loss = 0.79626445, grad/param norm = 2.1647e-01, time/batch = 0.6918s	
24585/28500 (epoch 43.132), train_loss = 0.81276249, grad/param norm = 1.9194e-01, time/batch = 0.6913s	
24586/28500 (epoch 43.133), train_loss = 0.88464881, grad/param norm = 2.2418e-01, time/batch = 0.6891s	
24587/28500 (epoch 43.135), train_loss = 0.77570619, grad/param norm = 1.8580e-01, time/batch = 0.6902s	
24588/28500 (epoch 43.137), train_loss = 0.83175807, grad/param norm = 1.9740e-01, time/batch = 0.6885s	
24589/28500 (epoch 43.139), train_loss = 0.81405862, grad/param norm = 1.7230e-01, time/batch = 0.6907s	
24590/28500 (epoch 43.140), train_loss = 0.80924077, grad/param norm = 2.0242e-01, time/batch = 0.6888s	
24591/28500 (epoch 43.142), train_loss = 0.78826593, grad/param norm = 2.3776e-01, time/batch = 0.6929s	
24592/28500 (epoch 43.144), train_loss = 0.74058477, grad/param norm = 2.0061e-01, time/batch = 0.6890s	
24593/28500 (epoch 43.146), train_loss = 0.79032593, grad/param norm = 1.8753e-01, time/batch = 0.6905s	
24594/28500 (epoch 43.147), train_loss = 0.69697168, grad/param norm = 1.7284e-01, time/batch = 0.6882s	
24595/28500 (epoch 43.149), train_loss = 0.71821729, grad/param norm = 1.7837e-01, time/batch = 0.6889s	
24596/28500 (epoch 43.151), train_loss = 0.76492975, grad/param norm = 1.9341e-01, time/batch = 0.6887s	
24597/28500 (epoch 43.153), train_loss = 0.83235712, grad/param norm = 1.9134e-01, time/batch = 0.6907s	
24598/28500 (epoch 43.154), train_loss = 0.69319853, grad/param norm = 2.1585e-01, time/batch = 0.6882s	
24599/28500 (epoch 43.156), train_loss = 0.87049100, grad/param norm = 1.9161e-01, time/batch = 0.6895s	
24600/28500 (epoch 43.158), train_loss = 0.83658355, grad/param norm = 2.0004e-01, time/batch = 0.6917s	
24601/28500 (epoch 43.160), train_loss = 0.73320526, grad/param norm = 1.6139e-01, time/batch = 0.6916s	
24602/28500 (epoch 43.161), train_loss = 0.75170200, grad/param norm = 2.0088e-01, time/batch = 0.6947s	
24603/28500 (epoch 43.163), train_loss = 0.71060776, grad/param norm = 1.9158e-01, time/batch = 0.6899s	
24604/28500 (epoch 43.165), train_loss = 0.93828891, grad/param norm = 1.8070e-01, time/batch = 0.6897s	
24605/28500 (epoch 43.167), train_loss = 0.93680606, grad/param norm = 2.1875e-01, time/batch = 0.6960s	
24606/28500 (epoch 43.168), train_loss = 0.91449748, grad/param norm = 2.0722e-01, time/batch = 0.6915s	
24607/28500 (epoch 43.170), train_loss = 0.91280442, grad/param norm = 2.3130e-01, time/batch = 0.6885s	
24608/28500 (epoch 43.172), train_loss = 0.79115742, grad/param norm = 1.8456e-01, time/batch = 0.6903s	
24609/28500 (epoch 43.174), train_loss = 0.93945231, grad/param norm = 2.0872e-01, time/batch = 0.6897s	
24610/28500 (epoch 43.175), train_loss = 0.79482657, grad/param norm = 1.7976e-01, time/batch = 0.6885s	
24611/28500 (epoch 43.177), train_loss = 0.83612977, grad/param norm = 2.1186e-01, time/batch = 0.6959s	
24612/28500 (epoch 43.179), train_loss = 0.89051840, grad/param norm = 2.2407e-01, time/batch = 0.6902s	
24613/28500 (epoch 43.181), train_loss = 0.83242202, grad/param norm = 2.1030e-01, time/batch = 0.6897s	
24614/28500 (epoch 43.182), train_loss = 0.77150641, grad/param norm = 1.8826e-01, time/batch = 0.6897s	
24615/28500 (epoch 43.184), train_loss = 0.96874150, grad/param norm = 2.0789e-01, time/batch = 0.6887s	
24616/28500 (epoch 43.186), train_loss = 0.93146240, grad/param norm = 1.9423e-01, time/batch = 0.6902s	
24617/28500 (epoch 43.188), train_loss = 0.86902889, grad/param norm = 1.8876e-01, time/batch = 0.6898s	
24618/28500 (epoch 43.189), train_loss = 0.82529504, grad/param norm = 1.6873e-01, time/batch = 0.6921s	
24619/28500 (epoch 43.191), train_loss = 0.96337392, grad/param norm = 2.0840e-01, time/batch = 0.6918s	
24620/28500 (epoch 43.193), train_loss = 0.80992503, grad/param norm = 2.2821e-01, time/batch = 0.6956s	
24621/28500 (epoch 43.195), train_loss = 0.96449797, grad/param norm = 2.3698e-01, time/batch = 0.6925s	
24622/28500 (epoch 43.196), train_loss = 0.85791811, grad/param norm = 1.9866e-01, time/batch = 0.6977s	
24623/28500 (epoch 43.198), train_loss = 0.82833541, grad/param norm = 2.0414e-01, time/batch = 0.6948s	
24624/28500 (epoch 43.200), train_loss = 0.89876362, grad/param norm = 1.9975e-01, time/batch = 0.7035s	
24625/28500 (epoch 43.202), train_loss = 0.84487989, grad/param norm = 1.7099e-01, time/batch = 0.6965s	
24626/28500 (epoch 43.204), train_loss = 0.81990186, grad/param norm = 1.8597e-01, time/batch = 0.6890s	
24627/28500 (epoch 43.205), train_loss = 0.76832052, grad/param norm = 1.9216e-01, time/batch = 0.6911s	
24628/28500 (epoch 43.207), train_loss = 0.68237596, grad/param norm = 1.6994e-01, time/batch = 0.6884s	
24629/28500 (epoch 43.209), train_loss = 0.83834709, grad/param norm = 1.8709e-01, time/batch = 0.6919s	
24630/28500 (epoch 43.211), train_loss = 0.75636517, grad/param norm = 1.8311e-01, time/batch = 0.6892s	
24631/28500 (epoch 43.212), train_loss = 0.69973683, grad/param norm = 2.0625e-01, time/batch = 0.6908s	
24632/28500 (epoch 43.214), train_loss = 0.81540210, grad/param norm = 2.1266e-01, time/batch = 0.6896s	
24633/28500 (epoch 43.216), train_loss = 0.75902524, grad/param norm = 2.0389e-01, time/batch = 0.6892s	
24634/28500 (epoch 43.218), train_loss = 0.92916359, grad/param norm = 2.0174e-01, time/batch = 0.6886s	
24635/28500 (epoch 43.219), train_loss = 0.83375424, grad/param norm = 1.8741e-01, time/batch = 0.6906s	
24636/28500 (epoch 43.221), train_loss = 0.70986872, grad/param norm = 1.8493e-01, time/batch = 0.6905s	
24637/28500 (epoch 43.223), train_loss = 0.91079021, grad/param norm = 2.0866e-01, time/batch = 0.6908s	
24638/28500 (epoch 43.225), train_loss = 0.95487308, grad/param norm = 2.1332e-01, time/batch = 0.6919s	
24639/28500 (epoch 43.226), train_loss = 0.78050148, grad/param norm = 1.8138e-01, time/batch = 0.6938s	
24640/28500 (epoch 43.228), train_loss = 0.92712861, grad/param norm = 2.1549e-01, time/batch = 0.6951s	
24641/28500 (epoch 43.230), train_loss = 0.88034666, grad/param norm = 2.0277e-01, time/batch = 0.7017s	
24642/28500 (epoch 43.232), train_loss = 0.87042493, grad/param norm = 1.7966e-01, time/batch = 0.7036s	
24643/28500 (epoch 43.233), train_loss = 0.81210634, grad/param norm = 1.8649e-01, time/batch = 0.6928s	
24644/28500 (epoch 43.235), train_loss = 0.81643212, grad/param norm = 1.8564e-01, time/batch = 0.6962s	
24645/28500 (epoch 43.237), train_loss = 0.74036330, grad/param norm = 1.4785e-01, time/batch = 0.7015s	
24646/28500 (epoch 43.239), train_loss = 0.78864465, grad/param norm = 2.0285e-01, time/batch = 0.6944s	
24647/28500 (epoch 43.240), train_loss = 0.72097647, grad/param norm = 1.6987e-01, time/batch = 0.6929s	
24648/28500 (epoch 43.242), train_loss = 0.75882240, grad/param norm = 2.0386e-01, time/batch = 0.7112s	
24649/28500 (epoch 43.244), train_loss = 0.83551275, grad/param norm = 1.6757e-01, time/batch = 0.6959s	
24650/28500 (epoch 43.246), train_loss = 0.84675690, grad/param norm = 1.8049e-01, time/batch = 0.6975s	
24651/28500 (epoch 43.247), train_loss = 0.92444228, grad/param norm = 2.1239e-01, time/batch = 0.6969s	
24652/28500 (epoch 43.249), train_loss = 0.80524555, grad/param norm = 1.7640e-01, time/batch = 0.6936s	
24653/28500 (epoch 43.251), train_loss = 0.81734870, grad/param norm = 1.7410e-01, time/batch = 0.6922s	
24654/28500 (epoch 43.253), train_loss = 0.96289639, grad/param norm = 2.1179e-01, time/batch = 0.6896s	
24655/28500 (epoch 43.254), train_loss = 0.95539490, grad/param norm = 1.8290e-01, time/batch = 0.6890s	
24656/28500 (epoch 43.256), train_loss = 0.81308409, grad/param norm = 2.2104e-01, time/batch = 0.6887s	
24657/28500 (epoch 43.258), train_loss = 0.81327773, grad/param norm = 1.8788e-01, time/batch = 0.6891s	
24658/28500 (epoch 43.260), train_loss = 0.82152134, grad/param norm = 1.7716e-01, time/batch = 0.6893s	
24659/28500 (epoch 43.261), train_loss = 0.70328402, grad/param norm = 1.7461e-01, time/batch = 0.6894s	
24660/28500 (epoch 43.263), train_loss = 0.89357257, grad/param norm = 2.2915e-01, time/batch = 0.6884s	
24661/28500 (epoch 43.265), train_loss = 0.75551806, grad/param norm = 1.8245e-01, time/batch = 0.6923s	
24662/28500 (epoch 43.267), train_loss = 0.97052116, grad/param norm = 2.2816e-01, time/batch = 0.6899s	
24663/28500 (epoch 43.268), train_loss = 0.84798546, grad/param norm = 1.7961e-01, time/batch = 0.6927s	
24664/28500 (epoch 43.270), train_loss = 0.81405195, grad/param norm = 1.8542e-01, time/batch = 0.6899s	
24665/28500 (epoch 43.272), train_loss = 0.81973414, grad/param norm = 1.7448e-01, time/batch = 0.6887s	
24666/28500 (epoch 43.274), train_loss = 0.86682150, grad/param norm = 1.9936e-01, time/batch = 0.6925s	
24667/28500 (epoch 43.275), train_loss = 0.88518426, grad/param norm = 1.8718e-01, time/batch = 0.6885s	
24668/28500 (epoch 43.277), train_loss = 0.81440117, grad/param norm = 2.0983e-01, time/batch = 0.6916s	
24669/28500 (epoch 43.279), train_loss = 0.85566492, grad/param norm = 2.0949e-01, time/batch = 0.6901s	
24670/28500 (epoch 43.281), train_loss = 0.87654203, grad/param norm = 2.3372e-01, time/batch = 0.6965s	
24671/28500 (epoch 43.282), train_loss = 0.82438368, grad/param norm = 1.6707e-01, time/batch = 0.6906s	
24672/28500 (epoch 43.284), train_loss = 0.86733934, grad/param norm = 2.2978e-01, time/batch = 0.6933s	
24673/28500 (epoch 43.286), train_loss = 0.89780715, grad/param norm = 1.8992e-01, time/batch = 0.6898s	
24674/28500 (epoch 43.288), train_loss = 0.81943971, grad/param norm = 1.9812e-01, time/batch = 0.6897s	
24675/28500 (epoch 43.289), train_loss = 0.83612845, grad/param norm = 2.0063e-01, time/batch = 0.6891s	
24676/28500 (epoch 43.291), train_loss = 0.83573812, grad/param norm = 1.7785e-01, time/batch = 0.6902s	
24677/28500 (epoch 43.293), train_loss = 0.83503053, grad/param norm = 1.9645e-01, time/batch = 0.6885s	
24678/28500 (epoch 43.295), train_loss = 0.73616841, grad/param norm = 1.8952e-01, time/batch = 0.6929s	
24679/28500 (epoch 43.296), train_loss = 0.72057935, grad/param norm = 1.7203e-01, time/batch = 0.6900s	
24680/28500 (epoch 43.298), train_loss = 0.88389306, grad/param norm = 1.8920e-01, time/batch = 0.6914s	
24681/28500 (epoch 43.300), train_loss = 0.75080234, grad/param norm = 1.8494e-01, time/batch = 0.6907s	
24682/28500 (epoch 43.302), train_loss = 0.69404210, grad/param norm = 1.7338e-01, time/batch = 0.6905s	
24683/28500 (epoch 43.304), train_loss = 0.80337961, grad/param norm = 1.8938e-01, time/batch = 0.6885s	
24684/28500 (epoch 43.305), train_loss = 0.86114022, grad/param norm = 1.9290e-01, time/batch = 0.6897s	
24685/28500 (epoch 43.307), train_loss = 0.80123922, grad/param norm = 2.0106e-01, time/batch = 0.6917s	
24686/28500 (epoch 43.309), train_loss = 0.80035712, grad/param norm = 1.7079e-01, time/batch = 0.6902s	
24687/28500 (epoch 43.311), train_loss = 0.87147425, grad/param norm = 2.1054e-01, time/batch = 0.6902s	
24688/28500 (epoch 43.312), train_loss = 0.85704940, grad/param norm = 1.8507e-01, time/batch = 0.6886s	
24689/28500 (epoch 43.314), train_loss = 0.83272018, grad/param norm = 1.9085e-01, time/batch = 0.6883s	
24690/28500 (epoch 43.316), train_loss = 0.84157572, grad/param norm = 1.9915e-01, time/batch = 0.6889s	
24691/28500 (epoch 43.318), train_loss = 0.89546506, grad/param norm = 1.8815e-01, time/batch = 0.6913s	
24692/28500 (epoch 43.319), train_loss = 0.76796446, grad/param norm = 1.9343e-01, time/batch = 0.6898s	
24693/28500 (epoch 43.321), train_loss = 0.78248345, grad/param norm = 2.5470e-01, time/batch = 0.6883s	
24694/28500 (epoch 43.323), train_loss = 0.82297554, grad/param norm = 2.0288e-01, time/batch = 0.6900s	
24695/28500 (epoch 43.325), train_loss = 0.92501772, grad/param norm = 1.9048e-01, time/batch = 0.6879s	
24696/28500 (epoch 43.326), train_loss = 0.84044297, grad/param norm = 1.7427e-01, time/batch = 0.6892s	
24697/28500 (epoch 43.328), train_loss = 0.66127636, grad/param norm = 1.5548e-01, time/batch = 0.6963s	
24698/28500 (epoch 43.330), train_loss = 0.75488502, grad/param norm = 1.9022e-01, time/batch = 0.7053s	
24699/28500 (epoch 43.332), train_loss = 0.77675085, grad/param norm = 1.8461e-01, time/batch = 0.6998s	
24700/28500 (epoch 43.333), train_loss = 0.63659072, grad/param norm = 1.8848e-01, time/batch = 0.6959s	
24701/28500 (epoch 43.335), train_loss = 0.71764533, grad/param norm = 1.8573e-01, time/batch = 0.6907s	
24702/28500 (epoch 43.337), train_loss = 0.66499484, grad/param norm = 1.6724e-01, time/batch = 0.6891s	
24703/28500 (epoch 43.339), train_loss = 0.66949064, grad/param norm = 1.6086e-01, time/batch = 0.6924s	
24704/28500 (epoch 43.340), train_loss = 0.80587097, grad/param norm = 2.1058e-01, time/batch = 0.6902s	
24705/28500 (epoch 43.342), train_loss = 0.79183574, grad/param norm = 1.7261e-01, time/batch = 0.6910s	
24706/28500 (epoch 43.344), train_loss = 0.69425972, grad/param norm = 1.8020e-01, time/batch = 0.6932s	
24707/28500 (epoch 43.346), train_loss = 0.69126303, grad/param norm = 1.6040e-01, time/batch = 0.7090s	
24708/28500 (epoch 43.347), train_loss = 0.80134240, grad/param norm = 1.6721e-01, time/batch = 0.6893s	
24709/28500 (epoch 43.349), train_loss = 0.81953361, grad/param norm = 2.0235e-01, time/batch = 0.6896s	
24710/28500 (epoch 43.351), train_loss = 0.72173158, grad/param norm = 1.9580e-01, time/batch = 0.6883s	
24711/28500 (epoch 43.353), train_loss = 0.82528442, grad/param norm = 2.0841e-01, time/batch = 0.6933s	
24712/28500 (epoch 43.354), train_loss = 0.70855136, grad/param norm = 2.0077e-01, time/batch = 0.6955s	
24713/28500 (epoch 43.356), train_loss = 0.76374247, grad/param norm = 1.6766e-01, time/batch = 0.6945s	
24714/28500 (epoch 43.358), train_loss = 0.84837101, grad/param norm = 1.8594e-01, time/batch = 0.6932s	
24715/28500 (epoch 43.360), train_loss = 0.82754601, grad/param norm = 2.2212e-01, time/batch = 0.6931s	
24716/28500 (epoch 43.361), train_loss = 0.72467497, grad/param norm = 1.7638e-01, time/batch = 0.7139s	
24717/28500 (epoch 43.363), train_loss = 0.70489832, grad/param norm = 1.5463e-01, time/batch = 0.6972s	
24718/28500 (epoch 43.365), train_loss = 0.74811821, grad/param norm = 1.7627e-01, time/batch = 0.6938s	
24719/28500 (epoch 43.367), train_loss = 0.79982094, grad/param norm = 2.1892e-01, time/batch = 0.6949s	
24720/28500 (epoch 43.368), train_loss = 0.73177565, grad/param norm = 1.6940e-01, time/batch = 0.6895s	
24721/28500 (epoch 43.370), train_loss = 0.81960289, grad/param norm = 1.9827e-01, time/batch = 0.6953s	
24722/28500 (epoch 43.372), train_loss = 0.65074214, grad/param norm = 1.8980e-01, time/batch = 0.6892s	
24723/28500 (epoch 43.374), train_loss = 0.77676494, grad/param norm = 2.0116e-01, time/batch = 0.6911s	
24724/28500 (epoch 43.375), train_loss = 0.90124020, grad/param norm = 1.9977e-01, time/batch = 0.6919s	
24725/28500 (epoch 43.377), train_loss = 0.73607397, grad/param norm = 2.0126e-01, time/batch = 0.6975s	
24726/28500 (epoch 43.379), train_loss = 0.63124092, grad/param norm = 1.8287e-01, time/batch = 0.6916s	
24727/28500 (epoch 43.381), train_loss = 0.77537898, grad/param norm = 1.7899e-01, time/batch = 0.6878s	
24728/28500 (epoch 43.382), train_loss = 0.75342981, grad/param norm = 2.0292e-01, time/batch = 0.6931s	
24729/28500 (epoch 43.384), train_loss = 0.66679842, grad/param norm = 1.8272e-01, time/batch = 0.6891s	
24730/28500 (epoch 43.386), train_loss = 0.72012534, grad/param norm = 1.7729e-01, time/batch = 0.6900s	
24731/28500 (epoch 43.388), train_loss = 0.85540147, grad/param norm = 1.8928e-01, time/batch = 0.6901s	
24732/28500 (epoch 43.389), train_loss = 0.72342317, grad/param norm = 1.9637e-01, time/batch = 0.6902s	
24733/28500 (epoch 43.391), train_loss = 0.70075489, grad/param norm = 1.8690e-01, time/batch = 0.6918s	
24734/28500 (epoch 43.393), train_loss = 0.70574935, grad/param norm = 1.7311e-01, time/batch = 0.6927s	
24735/28500 (epoch 43.395), train_loss = 0.88297255, grad/param norm = 1.8817e-01, time/batch = 0.6879s	
24736/28500 (epoch 43.396), train_loss = 0.87945078, grad/param norm = 2.1370e-01, time/batch = 0.6912s	
24737/28500 (epoch 43.398), train_loss = 0.59632630, grad/param norm = 1.9444e-01, time/batch = 0.6899s	
24738/28500 (epoch 43.400), train_loss = 0.75254415, grad/param norm = 1.8503e-01, time/batch = 0.6927s	
24739/28500 (epoch 43.402), train_loss = 0.80804949, grad/param norm = 2.0126e-01, time/batch = 0.7126s	
24740/28500 (epoch 43.404), train_loss = 0.81894543, grad/param norm = 2.2332e-01, time/batch = 0.6997s	
24741/28500 (epoch 43.405), train_loss = 0.85600187, grad/param norm = 1.8864e-01, time/batch = 0.6932s	
24742/28500 (epoch 43.407), train_loss = 0.80071287, grad/param norm = 1.8348e-01, time/batch = 0.7037s	
24743/28500 (epoch 43.409), train_loss = 0.78293906, grad/param norm = 2.1903e-01, time/batch = 0.7024s	
24744/28500 (epoch 43.411), train_loss = 0.89756209, grad/param norm = 2.2745e-01, time/batch = 0.6971s	
24745/28500 (epoch 43.412), train_loss = 0.91543897, grad/param norm = 2.7032e-01, time/batch = 0.6913s	
24746/28500 (epoch 43.414), train_loss = 0.81604635, grad/param norm = 2.0417e-01, time/batch = 0.6907s	
24747/28500 (epoch 43.416), train_loss = 0.72106257, grad/param norm = 1.9774e-01, time/batch = 0.6891s	
24748/28500 (epoch 43.418), train_loss = 0.82722572, grad/param norm = 1.8442e-01, time/batch = 0.6879s	
24749/28500 (epoch 43.419), train_loss = 0.91580507, grad/param norm = 2.2871e-01, time/batch = 0.6901s	
24750/28500 (epoch 43.421), train_loss = 0.87447638, grad/param norm = 2.1969e-01, time/batch = 0.6917s	
24751/28500 (epoch 43.423), train_loss = 0.87594830, grad/param norm = 2.4131e-01, time/batch = 0.6943s	
24752/28500 (epoch 43.425), train_loss = 0.78439448, grad/param norm = 2.2488e-01, time/batch = 0.6901s	
24753/28500 (epoch 43.426), train_loss = 0.80987671, grad/param norm = 2.0236e-01, time/batch = 0.6914s	
24754/28500 (epoch 43.428), train_loss = 0.97177069, grad/param norm = 2.8253e-01, time/batch = 0.6899s	
24755/28500 (epoch 43.430), train_loss = 0.94104473, grad/param norm = 2.0454e-01, time/batch = 0.6924s	
24756/28500 (epoch 43.432), train_loss = 0.83344510, grad/param norm = 1.9764e-01, time/batch = 0.6912s	
24757/28500 (epoch 43.433), train_loss = 0.90011410, grad/param norm = 2.7730e-01, time/batch = 0.6914s	
24758/28500 (epoch 43.435), train_loss = 0.83507953, grad/param norm = 2.0796e-01, time/batch = 0.6890s	
24759/28500 (epoch 43.437), train_loss = 0.76051879, grad/param norm = 1.9040e-01, time/batch = 0.6919s	
24760/28500 (epoch 43.439), train_loss = 0.81258764, grad/param norm = 1.7847e-01, time/batch = 0.6905s	
24761/28500 (epoch 43.440), train_loss = 0.96474292, grad/param norm = 1.9804e-01, time/batch = 0.6929s	
24762/28500 (epoch 43.442), train_loss = 0.76706836, grad/param norm = 2.5960e-01, time/batch = 0.6904s	
24763/28500 (epoch 43.444), train_loss = 0.72394803, grad/param norm = 1.5886e-01, time/batch = 0.6910s	
24764/28500 (epoch 43.446), train_loss = 0.69158988, grad/param norm = 1.7245e-01, time/batch = 0.6889s	
24765/28500 (epoch 43.447), train_loss = 0.69430214, grad/param norm = 1.7333e-01, time/batch = 0.6895s	
24766/28500 (epoch 43.449), train_loss = 0.76468270, grad/param norm = 1.8137e-01, time/batch = 0.6893s	
24767/28500 (epoch 43.451), train_loss = 0.78910080, grad/param norm = 1.9187e-01, time/batch = 0.6890s	
24768/28500 (epoch 43.453), train_loss = 0.76455446, grad/param norm = 1.8291e-01, time/batch = 0.6886s	
24769/28500 (epoch 43.454), train_loss = 0.71411422, grad/param norm = 1.5407e-01, time/batch = 0.6909s	
24770/28500 (epoch 43.456), train_loss = 0.86303336, grad/param norm = 2.3241e-01, time/batch = 0.6927s	
24771/28500 (epoch 43.458), train_loss = 0.75965990, grad/param norm = 2.0182e-01, time/batch = 0.6991s	
24772/28500 (epoch 43.460), train_loss = 0.87865906, grad/param norm = 1.8972e-01, time/batch = 0.6938s	
24773/28500 (epoch 43.461), train_loss = 0.72266203, grad/param norm = 1.8636e-01, time/batch = 0.6910s	
24774/28500 (epoch 43.463), train_loss = 0.66507883, grad/param norm = 1.6133e-01, time/batch = 0.6952s	
24775/28500 (epoch 43.465), train_loss = 0.63212165, grad/param norm = 1.9135e-01, time/batch = 0.6934s	
24776/28500 (epoch 43.467), train_loss = 0.79483850, grad/param norm = 1.8445e-01, time/batch = 0.6896s	
24777/28500 (epoch 43.468), train_loss = 0.71951210, grad/param norm = 1.7530e-01, time/batch = 0.6900s	
24778/28500 (epoch 43.470), train_loss = 0.75665879, grad/param norm = 2.1482e-01, time/batch = 0.6900s	
24779/28500 (epoch 43.472), train_loss = 0.71665029, grad/param norm = 1.6814e-01, time/batch = 0.6931s	
24780/28500 (epoch 43.474), train_loss = 0.94204220, grad/param norm = 1.9975e-01, time/batch = 0.6954s	
24781/28500 (epoch 43.475), train_loss = 0.74123001, grad/param norm = 1.7224e-01, time/batch = 0.6924s	
24782/28500 (epoch 43.477), train_loss = 0.78801279, grad/param norm = 1.9011e-01, time/batch = 0.7098s	
24783/28500 (epoch 43.479), train_loss = 0.83425055, grad/param norm = 1.9704e-01, time/batch = 0.6896s	
24784/28500 (epoch 43.481), train_loss = 0.85288864, grad/param norm = 2.2048e-01, time/batch = 0.6925s	
24785/28500 (epoch 43.482), train_loss = 0.68246817, grad/param norm = 1.7127e-01, time/batch = 0.6910s	
24786/28500 (epoch 43.484), train_loss = 0.73042238, grad/param norm = 2.0303e-01, time/batch = 0.6935s	
24787/28500 (epoch 43.486), train_loss = 0.65857073, grad/param norm = 2.0664e-01, time/batch = 0.6892s	
24788/28500 (epoch 43.488), train_loss = 0.84345930, grad/param norm = 1.8942e-01, time/batch = 0.6886s	
24789/28500 (epoch 43.489), train_loss = 0.93967522, grad/param norm = 2.0188e-01, time/batch = 0.6908s	
24790/28500 (epoch 43.491), train_loss = 0.74845867, grad/param norm = 2.0329e-01, time/batch = 0.6910s	
24791/28500 (epoch 43.493), train_loss = 0.77436532, grad/param norm = 2.0031e-01, time/batch = 0.6963s	
24792/28500 (epoch 43.495), train_loss = 0.79504672, grad/param norm = 2.0642e-01, time/batch = 0.6998s	
24793/28500 (epoch 43.496), train_loss = 0.72422901, grad/param norm = 2.2616e-01, time/batch = 0.6991s	
24794/28500 (epoch 43.498), train_loss = 0.78301078, grad/param norm = 2.0517e-01, time/batch = 0.7120s	
24795/28500 (epoch 43.500), train_loss = 0.73852175, grad/param norm = 1.7687e-01, time/batch = 0.6887s	
24796/28500 (epoch 43.502), train_loss = 0.82238797, grad/param norm = 1.7697e-01, time/batch = 0.6949s	
24797/28500 (epoch 43.504), train_loss = 0.85755143, grad/param norm = 1.7943e-01, time/batch = 0.6936s	
24798/28500 (epoch 43.505), train_loss = 0.74030461, grad/param norm = 2.1018e-01, time/batch = 0.6932s	
24799/28500 (epoch 43.507), train_loss = 0.88005403, grad/param norm = 2.1794e-01, time/batch = 0.6948s	
24800/28500 (epoch 43.509), train_loss = 0.77239683, grad/param norm = 1.6886e-01, time/batch = 0.6901s	
24801/28500 (epoch 43.511), train_loss = 0.79439530, grad/param norm = 1.8485e-01, time/batch = 0.6903s	
24802/28500 (epoch 43.512), train_loss = 0.83987865, grad/param norm = 1.8753e-01, time/batch = 0.7146s	
24803/28500 (epoch 43.514), train_loss = 0.78619007, grad/param norm = 1.8158e-01, time/batch = 0.6920s	
24804/28500 (epoch 43.516), train_loss = 0.80159533, grad/param norm = 1.6567e-01, time/batch = 0.6962s	
24805/28500 (epoch 43.518), train_loss = 0.84441771, grad/param norm = 2.0039e-01, time/batch = 0.6938s	
24806/28500 (epoch 43.519), train_loss = 0.81178595, grad/param norm = 1.6155e-01, time/batch = 0.6949s	
24807/28500 (epoch 43.521), train_loss = 0.90785520, grad/param norm = 2.1969e-01, time/batch = 0.6918s	
24808/28500 (epoch 43.523), train_loss = 0.84531902, grad/param norm = 2.0330e-01, time/batch = 0.6942s	
24809/28500 (epoch 43.525), train_loss = 0.90274130, grad/param norm = 1.9065e-01, time/batch = 0.6923s	
24810/28500 (epoch 43.526), train_loss = 0.83634138, grad/param norm = 2.0579e-01, time/batch = 0.6938s	
24811/28500 (epoch 43.528), train_loss = 0.84625957, grad/param norm = 2.4164e-01, time/batch = 0.7002s	
24812/28500 (epoch 43.530), train_loss = 0.83914678, grad/param norm = 1.8547e-01, time/batch = 0.6982s	
24813/28500 (epoch 43.532), train_loss = 0.79368802, grad/param norm = 1.9482e-01, time/batch = 0.6956s	
24814/28500 (epoch 43.533), train_loss = 0.82694122, grad/param norm = 1.9766e-01, time/batch = 0.6980s	
24815/28500 (epoch 43.535), train_loss = 0.71278342, grad/param norm = 1.7967e-01, time/batch = 0.7079s	
24816/28500 (epoch 43.537), train_loss = 0.69208240, grad/param norm = 1.7987e-01, time/batch = 0.6914s	
24817/28500 (epoch 43.539), train_loss = 0.69142410, grad/param norm = 1.7131e-01, time/batch = 0.6921s	
24818/28500 (epoch 43.540), train_loss = 0.78286657, grad/param norm = 1.7891e-01, time/batch = 0.6892s	
24819/28500 (epoch 43.542), train_loss = 0.82701259, grad/param norm = 2.2291e-01, time/batch = 0.6907s	
24820/28500 (epoch 43.544), train_loss = 0.93415829, grad/param norm = 2.3637e-01, time/batch = 0.6929s	
24821/28500 (epoch 43.546), train_loss = 0.78160524, grad/param norm = 1.7229e-01, time/batch = 0.6998s	
24822/28500 (epoch 43.547), train_loss = 0.79118122, grad/param norm = 1.9307e-01, time/batch = 0.6917s	
24823/28500 (epoch 43.549), train_loss = 0.67498468, grad/param norm = 1.5780e-01, time/batch = 0.6929s	
24824/28500 (epoch 43.551), train_loss = 0.73666129, grad/param norm = 2.0093e-01, time/batch = 0.6911s	
24825/28500 (epoch 43.553), train_loss = 0.94857231, grad/param norm = 2.5498e-01, time/batch = 0.6995s	
24826/28500 (epoch 43.554), train_loss = 0.84304063, grad/param norm = 2.0908e-01, time/batch = 0.6957s	
24827/28500 (epoch 43.556), train_loss = 0.82643455, grad/param norm = 1.8489e-01, time/batch = 0.7033s	
24828/28500 (epoch 43.558), train_loss = 0.85249124, grad/param norm = 1.8179e-01, time/batch = 0.7038s	
24829/28500 (epoch 43.560), train_loss = 0.83138297, grad/param norm = 2.1548e-01, time/batch = 0.6996s	
24830/28500 (epoch 43.561), train_loss = 0.85530079, grad/param norm = 1.9697e-01, time/batch = 0.6967s	
24831/28500 (epoch 43.563), train_loss = 0.93656701, grad/param norm = 2.2055e-01, time/batch = 0.6975s	
24832/28500 (epoch 43.565), train_loss = 0.75751303, grad/param norm = 1.9246e-01, time/batch = 0.6991s	
24833/28500 (epoch 43.567), train_loss = 0.68061883, grad/param norm = 1.7585e-01, time/batch = 0.6963s	
24834/28500 (epoch 43.568), train_loss = 0.82518092, grad/param norm = 2.2229e-01, time/batch = 0.6961s	
24835/28500 (epoch 43.570), train_loss = 0.76972209, grad/param norm = 2.0483e-01, time/batch = 0.6933s	
24836/28500 (epoch 43.572), train_loss = 0.81864673, grad/param norm = 1.8419e-01, time/batch = 0.7038s	
24837/28500 (epoch 43.574), train_loss = 0.75966854, grad/param norm = 1.8051e-01, time/batch = 0.6929s	
24838/28500 (epoch 43.575), train_loss = 0.75394868, grad/param norm = 1.7042e-01, time/batch = 0.6937s	
24839/28500 (epoch 43.577), train_loss = 0.86667296, grad/param norm = 1.8837e-01, time/batch = 0.6940s	
24840/28500 (epoch 43.579), train_loss = 0.88610890, grad/param norm = 2.1269e-01, time/batch = 0.6992s	
24841/28500 (epoch 43.581), train_loss = 0.75184022, grad/param norm = 2.2219e-01, time/batch = 0.6948s	
24842/28500 (epoch 43.582), train_loss = 0.91863229, grad/param norm = 2.0462e-01, time/batch = 0.6937s	
24843/28500 (epoch 43.584), train_loss = 0.75527176, grad/param norm = 1.8424e-01, time/batch = 0.6951s	
24844/28500 (epoch 43.586), train_loss = 0.73199135, grad/param norm = 1.6856e-01, time/batch = 0.6952s	
24845/28500 (epoch 43.588), train_loss = 0.74685224, grad/param norm = 2.0274e-01, time/batch = 0.6959s	
24846/28500 (epoch 43.589), train_loss = 0.78516356, grad/param norm = 1.8759e-01, time/batch = 0.6926s	
24847/28500 (epoch 43.591), train_loss = 0.80681699, grad/param norm = 1.8729e-01, time/batch = 0.6940s	
24848/28500 (epoch 43.593), train_loss = 0.75117267, grad/param norm = 1.7239e-01, time/batch = 0.6919s	
24849/28500 (epoch 43.595), train_loss = 0.94795981, grad/param norm = 2.0397e-01, time/batch = 0.6946s	
24850/28500 (epoch 43.596), train_loss = 0.96021974, grad/param norm = 2.2592e-01, time/batch = 0.6920s	
24851/28500 (epoch 43.598), train_loss = 0.80410959, grad/param norm = 2.1329e-01, time/batch = 0.6985s	
24852/28500 (epoch 43.600), train_loss = 0.77737618, grad/param norm = 2.0420e-01, time/batch = 0.6922s	
24853/28500 (epoch 43.602), train_loss = 0.87791300, grad/param norm = 2.2403e-01, time/batch = 0.6957s	
24854/28500 (epoch 43.604), train_loss = 0.88425763, grad/param norm = 1.7465e-01, time/batch = 0.6950s	
24855/28500 (epoch 43.605), train_loss = 0.88628670, grad/param norm = 1.9761e-01, time/batch = 0.6916s	
24856/28500 (epoch 43.607), train_loss = 0.91682658, grad/param norm = 1.9113e-01, time/batch = 0.6920s	
24857/28500 (epoch 43.609), train_loss = 0.82121001, grad/param norm = 1.9909e-01, time/batch = 0.6921s	
24858/28500 (epoch 43.611), train_loss = 0.80926243, grad/param norm = 2.0569e-01, time/batch = 0.6960s	
24859/28500 (epoch 43.612), train_loss = 0.87485844, grad/param norm = 2.4492e-01, time/batch = 0.6918s	
24860/28500 (epoch 43.614), train_loss = 0.89389204, grad/param norm = 1.9470e-01, time/batch = 0.6934s	
24861/28500 (epoch 43.616), train_loss = 0.77210487, grad/param norm = 2.4460e-01, time/batch = 0.6954s	
24862/28500 (epoch 43.618), train_loss = 0.78258421, grad/param norm = 1.8356e-01, time/batch = 0.6964s	
24863/28500 (epoch 43.619), train_loss = 0.89406342, grad/param norm = 2.2286e-01, time/batch = 0.6920s	
24864/28500 (epoch 43.621), train_loss = 0.65087332, grad/param norm = 1.8086e-01, time/batch = 0.6955s	
24865/28500 (epoch 43.623), train_loss = 0.92570486, grad/param norm = 1.9440e-01, time/batch = 0.6912s	
24866/28500 (epoch 43.625), train_loss = 0.73843316, grad/param norm = 2.0436e-01, time/batch = 0.6958s	
24867/28500 (epoch 43.626), train_loss = 0.65319300, grad/param norm = 1.7092e-01, time/batch = 0.6922s	
24868/28500 (epoch 43.628), train_loss = 0.74865068, grad/param norm = 1.9972e-01, time/batch = 0.6947s	
24869/28500 (epoch 43.630), train_loss = 0.70896125, grad/param norm = 1.6623e-01, time/batch = 0.6929s	
24870/28500 (epoch 43.632), train_loss = 0.90077281, grad/param norm = 2.0144e-01, time/batch = 0.6955s	
24871/28500 (epoch 43.633), train_loss = 0.92897986, grad/param norm = 1.7206e-01, time/batch = 0.6945s	
24872/28500 (epoch 43.635), train_loss = 0.86123028, grad/param norm = 2.6309e-01, time/batch = 0.6945s	
24873/28500 (epoch 43.637), train_loss = 0.82331297, grad/param norm = 1.8376e-01, time/batch = 0.6945s	
24874/28500 (epoch 43.639), train_loss = 0.71612807, grad/param norm = 1.9630e-01, time/batch = 0.6912s	
24875/28500 (epoch 43.640), train_loss = 0.77104937, grad/param norm = 1.9377e-01, time/batch = 0.6953s	
24876/28500 (epoch 43.642), train_loss = 0.76631178, grad/param norm = 2.0401e-01, time/batch = 0.6954s	
24877/28500 (epoch 43.644), train_loss = 0.82714808, grad/param norm = 1.8953e-01, time/batch = 0.6929s	
24878/28500 (epoch 43.646), train_loss = 0.67064872, grad/param norm = 1.6728e-01, time/batch = 0.6983s	
24879/28500 (epoch 43.647), train_loss = 0.74906747, grad/param norm = 1.6322e-01, time/batch = 0.7016s	
24880/28500 (epoch 43.649), train_loss = 0.74202053, grad/param norm = 1.9977e-01, time/batch = 0.6951s	
24881/28500 (epoch 43.651), train_loss = 0.70258879, grad/param norm = 1.5369e-01, time/batch = 0.6946s	
24882/28500 (epoch 43.653), train_loss = 0.69272118, grad/param norm = 1.8806e-01, time/batch = 0.6924s	
24883/28500 (epoch 43.654), train_loss = 0.73929290, grad/param norm = 2.1779e-01, time/batch = 0.6925s	
24884/28500 (epoch 43.656), train_loss = 0.67937303, grad/param norm = 2.2766e-01, time/batch = 0.6932s	
24885/28500 (epoch 43.658), train_loss = 0.79150698, grad/param norm = 2.1913e-01, time/batch = 0.6916s	
24886/28500 (epoch 43.660), train_loss = 0.79338506, grad/param norm = 1.6898e-01, time/batch = 0.6927s	
24887/28500 (epoch 43.661), train_loss = 0.88832978, grad/param norm = 2.0599e-01, time/batch = 0.6876s	
24888/28500 (epoch 43.663), train_loss = 0.90068433, grad/param norm = 1.9191e-01, time/batch = 0.6904s	
24889/28500 (epoch 43.665), train_loss = 0.79880662, grad/param norm = 1.9006e-01, time/batch = 0.6891s	
24890/28500 (epoch 43.667), train_loss = 0.82294385, grad/param norm = 2.0738e-01, time/batch = 0.6905s	
24891/28500 (epoch 43.668), train_loss = 0.80023095, grad/param norm = 1.9220e-01, time/batch = 0.6915s	
24892/28500 (epoch 43.670), train_loss = 0.81592718, grad/param norm = 1.8170e-01, time/batch = 0.7179s	
24893/28500 (epoch 43.672), train_loss = 0.73722923, grad/param norm = 1.9323e-01, time/batch = 0.6921s	
24894/28500 (epoch 43.674), train_loss = 0.63313622, grad/param norm = 2.0070e-01, time/batch = 0.6910s	
24895/28500 (epoch 43.675), train_loss = 0.68978011, grad/param norm = 1.9730e-01, time/batch = 0.6933s	
24896/28500 (epoch 43.677), train_loss = 0.75328016, grad/param norm = 1.7715e-01, time/batch = 0.6939s	
24897/28500 (epoch 43.679), train_loss = 0.76363088, grad/param norm = 1.9594e-01, time/batch = 0.6883s	
24898/28500 (epoch 43.681), train_loss = 0.83429779, grad/param norm = 1.8341e-01, time/batch = 0.6895s	
24899/28500 (epoch 43.682), train_loss = 0.77536578, grad/param norm = 2.0377e-01, time/batch = 0.6913s	
24900/28500 (epoch 43.684), train_loss = 0.79420257, grad/param norm = 1.7997e-01, time/batch = 0.6927s	
24901/28500 (epoch 43.686), train_loss = 0.75423689, grad/param norm = 1.8415e-01, time/batch = 0.6932s	
24902/28500 (epoch 43.688), train_loss = 0.73011327, grad/param norm = 1.5313e-01, time/batch = 0.6892s	
24903/28500 (epoch 43.689), train_loss = 0.72507332, grad/param norm = 2.2165e-01, time/batch = 0.6920s	
24904/28500 (epoch 43.691), train_loss = 0.83104433, grad/param norm = 1.8149e-01, time/batch = 0.6887s	
24905/28500 (epoch 43.693), train_loss = 0.75740381, grad/param norm = 1.9756e-01, time/batch = 0.6914s	
24906/28500 (epoch 43.695), train_loss = 0.58977728, grad/param norm = 1.6586e-01, time/batch = 0.6939s	
24907/28500 (epoch 43.696), train_loss = 0.74720205, grad/param norm = 1.9683e-01, time/batch = 0.6901s	
24908/28500 (epoch 43.698), train_loss = 0.84370217, grad/param norm = 1.9229e-01, time/batch = 0.6901s	
24909/28500 (epoch 43.700), train_loss = 0.79778796, grad/param norm = 2.0343e-01, time/batch = 0.6883s	
24910/28500 (epoch 43.702), train_loss = 0.76763636, grad/param norm = 2.0204e-01, time/batch = 0.6922s	
24911/28500 (epoch 43.704), train_loss = 0.84250051, grad/param norm = 1.8940e-01, time/batch = 0.6999s	
24912/28500 (epoch 43.705), train_loss = 0.85709141, grad/param norm = 2.8294e-01, time/batch = 0.6904s	
24913/28500 (epoch 43.707), train_loss = 0.72615997, grad/param norm = 2.1250e-01, time/batch = 0.6885s	
24914/28500 (epoch 43.709), train_loss = 0.92761505, grad/param norm = 2.2040e-01, time/batch = 0.6889s	
24915/28500 (epoch 43.711), train_loss = 0.75845595, grad/param norm = 2.0684e-01, time/batch = 0.6891s	
24916/28500 (epoch 43.712), train_loss = 0.82598765, grad/param norm = 1.8301e-01, time/batch = 0.6879s	
24917/28500 (epoch 43.714), train_loss = 0.93213043, grad/param norm = 2.7586e-01, time/batch = 0.6891s	
24918/28500 (epoch 43.716), train_loss = 0.76916924, grad/param norm = 1.7376e-01, time/batch = 0.6882s	
24919/28500 (epoch 43.718), train_loss = 0.81260784, grad/param norm = 1.9754e-01, time/batch = 0.6900s	
24920/28500 (epoch 43.719), train_loss = 0.81055595, grad/param norm = 1.7681e-01, time/batch = 0.6883s	
24921/28500 (epoch 43.721), train_loss = 0.61406462, grad/param norm = 1.7128e-01, time/batch = 0.6915s	
24922/28500 (epoch 43.723), train_loss = 0.79478850, grad/param norm = 1.8679e-01, time/batch = 0.6899s	
24923/28500 (epoch 43.725), train_loss = 0.85680289, grad/param norm = 2.1110e-01, time/batch = 0.6916s	
24924/28500 (epoch 43.726), train_loss = 0.77825577, grad/param norm = 1.8722e-01, time/batch = 0.6889s	
24925/28500 (epoch 43.728), train_loss = 0.73210154, grad/param norm = 1.8975e-01, time/batch = 0.6902s	
24926/28500 (epoch 43.730), train_loss = 0.78473738, grad/param norm = 1.8617e-01, time/batch = 0.6896s	
24927/28500 (epoch 43.732), train_loss = 0.64281683, grad/param norm = 1.7087e-01, time/batch = 0.6883s	
24928/28500 (epoch 43.733), train_loss = 0.67063851, grad/param norm = 1.7064e-01, time/batch = 0.6889s	
24929/28500 (epoch 43.735), train_loss = 0.66836010, grad/param norm = 1.7289e-01, time/batch = 0.6880s	
24930/28500 (epoch 43.737), train_loss = 0.61345288, grad/param norm = 1.5883e-01, time/batch = 0.6902s	
24931/28500 (epoch 43.739), train_loss = 0.68488693, grad/param norm = 1.7569e-01, time/batch = 0.6921s	
24932/28500 (epoch 43.740), train_loss = 0.76755441, grad/param norm = 1.7798e-01, time/batch = 0.6947s	
24933/28500 (epoch 43.742), train_loss = 0.70772995, grad/param norm = 2.0051e-01, time/batch = 0.6906s	
24934/28500 (epoch 43.744), train_loss = 0.78000612, grad/param norm = 1.8533e-01, time/batch = 0.6892s	
24935/28500 (epoch 43.746), train_loss = 0.74183049, grad/param norm = 1.6806e-01, time/batch = 0.6909s	
24936/28500 (epoch 43.747), train_loss = 0.74679607, grad/param norm = 1.7176e-01, time/batch = 0.6932s	
24937/28500 (epoch 43.749), train_loss = 0.83860067, grad/param norm = 2.0815e-01, time/batch = 0.6953s	
24938/28500 (epoch 43.751), train_loss = 0.70629997, grad/param norm = 2.3232e-01, time/batch = 0.6961s	
24939/28500 (epoch 43.753), train_loss = 0.79002067, grad/param norm = 1.6296e-01, time/batch = 0.6906s	
24940/28500 (epoch 43.754), train_loss = 0.69919157, grad/param norm = 2.0402e-01, time/batch = 0.6913s	
24941/28500 (epoch 43.756), train_loss = 0.89936808, grad/param norm = 1.9539e-01, time/batch = 0.6990s	
24942/28500 (epoch 43.758), train_loss = 0.81651425, grad/param norm = 2.1022e-01, time/batch = 0.6928s	
24943/28500 (epoch 43.760), train_loss = 0.67932990, grad/param norm = 1.7575e-01, time/batch = 0.6893s	
24944/28500 (epoch 43.761), train_loss = 0.73700753, grad/param norm = 1.9167e-01, time/batch = 0.6889s	
24945/28500 (epoch 43.763), train_loss = 0.61013072, grad/param norm = 1.8313e-01, time/batch = 0.6892s	
24946/28500 (epoch 43.765), train_loss = 0.74895189, grad/param norm = 1.6415e-01, time/batch = 0.6932s	
24947/28500 (epoch 43.767), train_loss = 0.61903182, grad/param norm = 1.4812e-01, time/batch = 0.6895s	
24948/28500 (epoch 43.768), train_loss = 0.82727504, grad/param norm = 2.0391e-01, time/batch = 0.6882s	
24949/28500 (epoch 43.770), train_loss = 0.68028267, grad/param norm = 1.6743e-01, time/batch = 0.6884s	
24950/28500 (epoch 43.772), train_loss = 0.64037247, grad/param norm = 1.6170e-01, time/batch = 0.6880s	
24951/28500 (epoch 43.774), train_loss = 0.76733226, grad/param norm = 1.7014e-01, time/batch = 0.6903s	
24952/28500 (epoch 43.775), train_loss = 0.82571309, grad/param norm = 1.8893e-01, time/batch = 0.6925s	
24953/28500 (epoch 43.777), train_loss = 0.84086915, grad/param norm = 1.7508e-01, time/batch = 0.6950s	
24954/28500 (epoch 43.779), train_loss = 0.65351856, grad/param norm = 1.4066e-01, time/batch = 0.6913s	
24955/28500 (epoch 43.781), train_loss = 0.76685449, grad/param norm = 1.9664e-01, time/batch = 0.6936s	
24956/28500 (epoch 43.782), train_loss = 0.79876399, grad/param norm = 1.6794e-01, time/batch = 0.6937s	
24957/28500 (epoch 43.784), train_loss = 0.62548759, grad/param norm = 1.4667e-01, time/batch = 0.6951s	
24958/28500 (epoch 43.786), train_loss = 0.64375380, grad/param norm = 1.7125e-01, time/batch = 0.6932s	
24959/28500 (epoch 43.788), train_loss = 0.74585646, grad/param norm = 2.0946e-01, time/batch = 0.6932s	
24960/28500 (epoch 43.789), train_loss = 0.57249009, grad/param norm = 2.1268e-01, time/batch = 0.6926s	
24961/28500 (epoch 43.791), train_loss = 0.79886458, grad/param norm = 1.8122e-01, time/batch = 0.6959s	
24962/28500 (epoch 43.793), train_loss = 0.73757766, grad/param norm = 1.7494e-01, time/batch = 0.6944s	
24963/28500 (epoch 43.795), train_loss = 0.75940928, grad/param norm = 1.7414e-01, time/batch = 0.6946s	
24964/28500 (epoch 43.796), train_loss = 0.69932288, grad/param norm = 1.8245e-01, time/batch = 0.6965s	
24965/28500 (epoch 43.798), train_loss = 0.64810983, grad/param norm = 1.6786e-01, time/batch = 0.6994s	
24966/28500 (epoch 43.800), train_loss = 0.62212959, grad/param norm = 2.0354e-01, time/batch = 0.6985s	
24967/28500 (epoch 43.802), train_loss = 0.72875838, grad/param norm = 2.2309e-01, time/batch = 0.6918s	
24968/28500 (epoch 43.804), train_loss = 0.79118353, grad/param norm = 1.8298e-01, time/batch = 0.6949s	
24969/28500 (epoch 43.805), train_loss = 0.80117746, grad/param norm = 2.0787e-01, time/batch = 0.6952s	
24970/28500 (epoch 43.807), train_loss = 0.78988342, grad/param norm = 2.0924e-01, time/batch = 0.6939s	
24971/28500 (epoch 43.809), train_loss = 0.78404435, grad/param norm = 2.4365e-01, time/batch = 0.6994s	
24972/28500 (epoch 43.811), train_loss = 0.78183723, grad/param norm = 1.9732e-01, time/batch = 0.6955s	
24973/28500 (epoch 43.812), train_loss = 0.75466458, grad/param norm = 2.2041e-01, time/batch = 0.6937s	
24974/28500 (epoch 43.814), train_loss = 0.73148113, grad/param norm = 2.1313e-01, time/batch = 0.6930s	
24975/28500 (epoch 43.816), train_loss = 0.79633209, grad/param norm = 2.1878e-01, time/batch = 0.6944s	
24976/28500 (epoch 43.818), train_loss = 0.90617822, grad/param norm = 2.1951e-01, time/batch = 0.6921s	
24977/28500 (epoch 43.819), train_loss = 0.77663730, grad/param norm = 1.9156e-01, time/batch = 0.6949s	
24978/28500 (epoch 43.821), train_loss = 0.74830504, grad/param norm = 1.9639e-01, time/batch = 0.6928s	
24979/28500 (epoch 43.823), train_loss = 0.88767460, grad/param norm = 2.2381e-01, time/batch = 0.6947s	
24980/28500 (epoch 43.825), train_loss = 0.68332168, grad/param norm = 2.1196e-01, time/batch = 0.6928s	
24981/28500 (epoch 43.826), train_loss = 0.78055788, grad/param norm = 1.9035e-01, time/batch = 0.6956s	
24982/28500 (epoch 43.828), train_loss = 0.71001279, grad/param norm = 1.7805e-01, time/batch = 0.6935s	
24983/28500 (epoch 43.830), train_loss = 0.72225246, grad/param norm = 1.5740e-01, time/batch = 0.6933s	
24984/28500 (epoch 43.832), train_loss = 0.77239776, grad/param norm = 2.4628e-01, time/batch = 0.6931s	
24985/28500 (epoch 43.833), train_loss = 0.81703246, grad/param norm = 2.0540e-01, time/batch = 0.6951s	
24986/28500 (epoch 43.835), train_loss = 0.73734549, grad/param norm = 1.8524e-01, time/batch = 0.6929s	
24987/28500 (epoch 43.837), train_loss = 0.65351933, grad/param norm = 1.7515e-01, time/batch = 0.6962s	
24988/28500 (epoch 43.839), train_loss = 0.91090702, grad/param norm = 2.3262e-01, time/batch = 0.6945s	
24989/28500 (epoch 43.840), train_loss = 0.91112058, grad/param norm = 2.0572e-01, time/batch = 0.6942s	
24990/28500 (epoch 43.842), train_loss = 0.84890087, grad/param norm = 2.6291e-01, time/batch = 0.6934s	
24991/28500 (epoch 43.844), train_loss = 0.87896869, grad/param norm = 1.9920e-01, time/batch = 0.6984s	
24992/28500 (epoch 43.846), train_loss = 0.94149632, grad/param norm = 2.4951e-01, time/batch = 0.6960s	
24993/28500 (epoch 43.847), train_loss = 0.74851325, grad/param norm = 1.8086e-01, time/batch = 0.6930s	
24994/28500 (epoch 43.849), train_loss = 0.74523655, grad/param norm = 1.9465e-01, time/batch = 0.6956s	
24995/28500 (epoch 43.851), train_loss = 0.72201237, grad/param norm = 1.7884e-01, time/batch = 0.6943s	
24996/28500 (epoch 43.853), train_loss = 0.82225986, grad/param norm = 2.0594e-01, time/batch = 0.6944s	
24997/28500 (epoch 43.854), train_loss = 0.79397614, grad/param norm = 1.9039e-01, time/batch = 0.6938s	
24998/28500 (epoch 43.856), train_loss = 0.86875204, grad/param norm = 2.4644e-01, time/batch = 0.6951s	
24999/28500 (epoch 43.858), train_loss = 0.74545563, grad/param norm = 1.7865e-01, time/batch = 0.6956s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch43.86_2.0131.t7	
25000/28500 (epoch 43.860), train_loss = 0.78827802, grad/param norm = 2.0514e-01, time/batch = 0.6961s	
25001/28500 (epoch 43.861), train_loss = 1.39228272, grad/param norm = 2.6579e-01, time/batch = 0.7016s	
25002/28500 (epoch 43.863), train_loss = 0.82264960, grad/param norm = 2.3602e-01, time/batch = 0.6936s	
25003/28500 (epoch 43.865), train_loss = 0.73989827, grad/param norm = 2.0690e-01, time/batch = 0.6935s	
25004/28500 (epoch 43.867), train_loss = 0.81362339, grad/param norm = 2.2521e-01, time/batch = 0.6948s	
25005/28500 (epoch 43.868), train_loss = 0.69777915, grad/param norm = 1.8247e-01, time/batch = 0.6948s	
25006/28500 (epoch 43.870), train_loss = 0.67264842, grad/param norm = 1.8511e-01, time/batch = 0.7017s	
25007/28500 (epoch 43.872), train_loss = 0.85541644, grad/param norm = 2.8138e-01, time/batch = 0.7000s	
25008/28500 (epoch 43.874), train_loss = 0.71104713, grad/param norm = 2.2642e-01, time/batch = 0.7002s	
25009/28500 (epoch 43.875), train_loss = 0.92926398, grad/param norm = 2.4036e-01, time/batch = 0.7014s	
25010/28500 (epoch 43.877), train_loss = 0.82639095, grad/param norm = 1.9998e-01, time/batch = 0.6963s	
25011/28500 (epoch 43.879), train_loss = 0.81891603, grad/param norm = 1.6190e-01, time/batch = 0.6980s	
25012/28500 (epoch 43.881), train_loss = 0.81155559, grad/param norm = 1.8758e-01, time/batch = 0.6931s	
25013/28500 (epoch 43.882), train_loss = 0.71551954, grad/param norm = 1.8316e-01, time/batch = 0.6958s	
25014/28500 (epoch 43.884), train_loss = 0.75385380, grad/param norm = 1.9145e-01, time/batch = 0.6936s	
25015/28500 (epoch 43.886), train_loss = 0.72506519, grad/param norm = 1.7512e-01, time/batch = 0.6919s	
25016/28500 (epoch 43.888), train_loss = 0.73717566, grad/param norm = 1.5287e-01, time/batch = 0.6925s	
25017/28500 (epoch 43.889), train_loss = 0.82252281, grad/param norm = 1.7388e-01, time/batch = 0.6965s	
25018/28500 (epoch 43.891), train_loss = 0.79924340, grad/param norm = 1.8217e-01, time/batch = 0.6927s	
25019/28500 (epoch 43.893), train_loss = 0.73092150, grad/param norm = 1.8834e-01, time/batch = 0.6945s	
25020/28500 (epoch 43.895), train_loss = 0.91647513, grad/param norm = 2.4775e-01, time/batch = 0.6924s	
25021/28500 (epoch 43.896), train_loss = 0.88540438, grad/param norm = 2.1434e-01, time/batch = 0.7055s	
25022/28500 (epoch 43.898), train_loss = 0.84016182, grad/param norm = 2.0354e-01, time/batch = 0.6993s	
25023/28500 (epoch 43.900), train_loss = 0.68457715, grad/param norm = 1.7524e-01, time/batch = 0.7020s	
25024/28500 (epoch 43.902), train_loss = 0.65255404, grad/param norm = 1.6454e-01, time/batch = 0.6982s	
25025/28500 (epoch 43.904), train_loss = 0.68977991, grad/param norm = 1.6887e-01, time/batch = 0.6998s	
25026/28500 (epoch 43.905), train_loss = 0.75357535, grad/param norm = 2.0584e-01, time/batch = 0.6967s	
25027/28500 (epoch 43.907), train_loss = 0.77016588, grad/param norm = 1.7162e-01, time/batch = 0.7071s	
25028/28500 (epoch 43.909), train_loss = 0.65767992, grad/param norm = 2.5878e-01, time/batch = 0.6962s	
25029/28500 (epoch 43.911), train_loss = 0.68997328, grad/param norm = 1.7209e-01, time/batch = 0.7047s	
25030/28500 (epoch 43.912), train_loss = 0.57884819, grad/param norm = 1.5319e-01, time/batch = 0.6964s	
25031/28500 (epoch 43.914), train_loss = 0.80676407, grad/param norm = 1.7911e-01, time/batch = 0.7041s	
25032/28500 (epoch 43.916), train_loss = 0.78840730, grad/param norm = 1.9949e-01, time/batch = 0.6986s	
25033/28500 (epoch 43.918), train_loss = 0.75363256, grad/param norm = 1.7598e-01, time/batch = 0.6994s	
25034/28500 (epoch 43.919), train_loss = 0.81717516, grad/param norm = 1.8727e-01, time/batch = 0.6970s	
25035/28500 (epoch 43.921), train_loss = 0.84869664, grad/param norm = 2.1634e-01, time/batch = 0.7000s	
25036/28500 (epoch 43.923), train_loss = 0.70760277, grad/param norm = 2.0287e-01, time/batch = 0.6975s	
25037/28500 (epoch 43.925), train_loss = 0.72249166, grad/param norm = 2.1781e-01, time/batch = 0.6987s	
25038/28500 (epoch 43.926), train_loss = 0.78387020, grad/param norm = 1.8992e-01, time/batch = 0.6983s	
25039/28500 (epoch 43.928), train_loss = 0.73160751, grad/param norm = 1.8211e-01, time/batch = 0.7002s	
25040/28500 (epoch 43.930), train_loss = 0.61900237, grad/param norm = 1.4774e-01, time/batch = 0.6989s	
25041/28500 (epoch 43.932), train_loss = 0.64200265, grad/param norm = 1.5397e-01, time/batch = 0.7041s	
25042/28500 (epoch 43.933), train_loss = 0.83657726, grad/param norm = 1.7923e-01, time/batch = 0.7040s	
25043/28500 (epoch 43.935), train_loss = 0.85008601, grad/param norm = 1.8653e-01, time/batch = 0.7151s	
25044/28500 (epoch 43.937), train_loss = 0.82423447, grad/param norm = 2.2799e-01, time/batch = 0.7022s	
25045/28500 (epoch 43.939), train_loss = 0.88425679, grad/param norm = 1.9119e-01, time/batch = 0.6977s	
25046/28500 (epoch 43.940), train_loss = 0.62105530, grad/param norm = 1.7347e-01, time/batch = 0.7064s	
25047/28500 (epoch 43.942), train_loss = 0.76410176, grad/param norm = 1.9908e-01, time/batch = 0.7122s	
25048/28500 (epoch 43.944), train_loss = 0.74653915, grad/param norm = 1.8105e-01, time/batch = 0.7030s	
25049/28500 (epoch 43.946), train_loss = 0.80368689, grad/param norm = 1.6404e-01, time/batch = 0.7039s	
25050/28500 (epoch 43.947), train_loss = 0.99214861, grad/param norm = 2.7670e-01, time/batch = 0.7008s	
25051/28500 (epoch 43.949), train_loss = 0.75681474, grad/param norm = 2.3328e-01, time/batch = 0.7005s	
25052/28500 (epoch 43.951), train_loss = 0.93608491, grad/param norm = 2.0174e-01, time/batch = 0.7030s	
25053/28500 (epoch 43.953), train_loss = 0.92969539, grad/param norm = 2.2337e-01, time/batch = 0.6988s	
25054/28500 (epoch 43.954), train_loss = 0.85369276, grad/param norm = 1.9743e-01, time/batch = 0.7030s	
25055/28500 (epoch 43.956), train_loss = 0.79252315, grad/param norm = 2.7293e-01, time/batch = 0.7004s	
25056/28500 (epoch 43.958), train_loss = 1.01470227, grad/param norm = 1.9423e-01, time/batch = 0.6977s	
25057/28500 (epoch 43.960), train_loss = 0.71962146, grad/param norm = 2.1090e-01, time/batch = 0.6976s	
25058/28500 (epoch 43.961), train_loss = 0.91205958, grad/param norm = 1.9758e-01, time/batch = 0.6988s	
25059/28500 (epoch 43.963), train_loss = 0.87181917, grad/param norm = 2.5664e-01, time/batch = 0.6997s	
25060/28500 (epoch 43.965), train_loss = 0.70767150, grad/param norm = 1.8006e-01, time/batch = 0.6991s	
25061/28500 (epoch 43.967), train_loss = 0.73261898, grad/param norm = 1.8477e-01, time/batch = 0.7081s	
25062/28500 (epoch 43.968), train_loss = 0.69364722, grad/param norm = 1.5998e-01, time/batch = 0.7044s	
25063/28500 (epoch 43.970), train_loss = 0.74059947, grad/param norm = 2.4550e-01, time/batch = 0.7081s	
25064/28500 (epoch 43.972), train_loss = 0.78756415, grad/param norm = 1.8757e-01, time/batch = 0.6987s	
25065/28500 (epoch 43.974), train_loss = 0.99663808, grad/param norm = 2.7558e-01, time/batch = 0.7131s	
25066/28500 (epoch 43.975), train_loss = 0.73385678, grad/param norm = 2.0114e-01, time/batch = 0.6983s	
25067/28500 (epoch 43.977), train_loss = 0.86706174, grad/param norm = 2.1706e-01, time/batch = 0.6995s	
25068/28500 (epoch 43.979), train_loss = 0.81640710, grad/param norm = 1.8718e-01, time/batch = 0.6975s	
25069/28500 (epoch 43.981), train_loss = 0.68195029, grad/param norm = 1.9323e-01, time/batch = 0.6961s	
25070/28500 (epoch 43.982), train_loss = 0.77906912, grad/param norm = 1.8505e-01, time/batch = 0.7047s	
25071/28500 (epoch 43.984), train_loss = 0.86064224, grad/param norm = 1.9696e-01, time/batch = 0.7014s	
25072/28500 (epoch 43.986), train_loss = 0.99271544, grad/param norm = 2.2392e-01, time/batch = 0.6979s	
25073/28500 (epoch 43.988), train_loss = 0.70641255, grad/param norm = 1.8880e-01, time/batch = 0.7013s	
25074/28500 (epoch 43.989), train_loss = 0.79510876, grad/param norm = 2.0203e-01, time/batch = 0.6983s	
25075/28500 (epoch 43.991), train_loss = 0.69894159, grad/param norm = 2.0773e-01, time/batch = 0.6993s	
25076/28500 (epoch 43.993), train_loss = 0.72890500, grad/param norm = 1.9592e-01, time/batch = 0.6966s	
25077/28500 (epoch 43.995), train_loss = 0.76196705, grad/param norm = 2.0068e-01, time/batch = 0.7001s	
25078/28500 (epoch 43.996), train_loss = 0.68410066, grad/param norm = 1.8943e-01, time/batch = 0.6961s	
25079/28500 (epoch 43.998), train_loss = 0.90187883, grad/param norm = 2.2743e-01, time/batch = 0.6987s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
25080/28500 (epoch 44.000), train_loss = 0.77443734, grad/param norm = 1.9811e-01, time/batch = 0.6978s	
25081/28500 (epoch 44.002), train_loss = 0.94057927, grad/param norm = 2.1423e-01, time/batch = 0.6998s	
25082/28500 (epoch 44.004), train_loss = 0.80627826, grad/param norm = 1.9910e-01, time/batch = 0.7008s	
25083/28500 (epoch 44.005), train_loss = 0.86842838, grad/param norm = 2.0197e-01, time/batch = 0.6971s	
25084/28500 (epoch 44.007), train_loss = 0.69933935, grad/param norm = 1.6170e-01, time/batch = 0.7082s	
25085/28500 (epoch 44.009), train_loss = 0.80676174, grad/param norm = 2.0146e-01, time/batch = 0.6983s	
25086/28500 (epoch 44.011), train_loss = 0.72663139, grad/param norm = 1.9720e-01, time/batch = 0.7031s	
25087/28500 (epoch 44.012), train_loss = 0.73204760, grad/param norm = 1.7021e-01, time/batch = 0.6962s	
25088/28500 (epoch 44.014), train_loss = 0.70679775, grad/param norm = 1.7790e-01, time/batch = 0.7005s	
25089/28500 (epoch 44.016), train_loss = 0.75976724, grad/param norm = 1.7787e-01, time/batch = 0.6981s	
25090/28500 (epoch 44.018), train_loss = 0.81591479, grad/param norm = 2.0092e-01, time/batch = 0.6972s	
25091/28500 (epoch 44.019), train_loss = 0.88809478, grad/param norm = 1.9643e-01, time/batch = 0.7029s	
25092/28500 (epoch 44.021), train_loss = 0.88821151, grad/param norm = 1.7629e-01, time/batch = 0.6966s	
25093/28500 (epoch 44.023), train_loss = 0.80632918, grad/param norm = 1.9975e-01, time/batch = 0.6990s	
25094/28500 (epoch 44.025), train_loss = 0.81957760, grad/param norm = 1.8222e-01, time/batch = 0.6963s	
25095/28500 (epoch 44.026), train_loss = 0.74913325, grad/param norm = 1.8681e-01, time/batch = 0.7005s	
25096/28500 (epoch 44.028), train_loss = 0.79749900, grad/param norm = 2.1038e-01, time/batch = 0.6986s	
25097/28500 (epoch 44.030), train_loss = 0.82479131, grad/param norm = 2.0912e-01, time/batch = 0.6975s	
25098/28500 (epoch 44.032), train_loss = 0.91397588, grad/param norm = 2.0125e-01, time/batch = 0.6990s	
25099/28500 (epoch 44.033), train_loss = 0.95060835, grad/param norm = 2.2518e-01, time/batch = 0.7017s	
25100/28500 (epoch 44.035), train_loss = 0.76752605, grad/param norm = 1.8610e-01, time/batch = 0.6976s	
25101/28500 (epoch 44.037), train_loss = 0.85918391, grad/param norm = 1.8578e-01, time/batch = 0.7013s	
25102/28500 (epoch 44.039), train_loss = 0.89948254, grad/param norm = 2.3557e-01, time/batch = 0.7003s	
25103/28500 (epoch 44.040), train_loss = 0.90705165, grad/param norm = 1.9185e-01, time/batch = 0.6983s	
25104/28500 (epoch 44.042), train_loss = 0.85856387, grad/param norm = 1.8312e-01, time/batch = 0.6991s	
25105/28500 (epoch 44.044), train_loss = 0.78581485, grad/param norm = 2.3364e-01, time/batch = 0.6991s	
25106/28500 (epoch 44.046), train_loss = 0.99509787, grad/param norm = 2.1089e-01, time/batch = 0.6977s	
25107/28500 (epoch 44.047), train_loss = 0.93309050, grad/param norm = 2.3746e-01, time/batch = 0.7016s	
25108/28500 (epoch 44.049), train_loss = 0.82343216, grad/param norm = 1.8958e-01, time/batch = 0.6977s	
25109/28500 (epoch 44.051), train_loss = 0.80793327, grad/param norm = 2.3175e-01, time/batch = 0.7008s	
25110/28500 (epoch 44.053), train_loss = 0.77684621, grad/param norm = 2.1103e-01, time/batch = 0.7025s	
25111/28500 (epoch 44.054), train_loss = 0.85650871, grad/param norm = 1.8788e-01, time/batch = 0.7078s	
25112/28500 (epoch 44.056), train_loss = 0.76244020, grad/param norm = 1.8075e-01, time/batch = 0.7062s	
25113/28500 (epoch 44.058), train_loss = 0.73823523, grad/param norm = 1.8029e-01, time/batch = 0.7056s	
25114/28500 (epoch 44.060), train_loss = 0.86475467, grad/param norm = 1.9339e-01, time/batch = 0.7102s	
25115/28500 (epoch 44.061), train_loss = 0.76277090, grad/param norm = 1.8175e-01, time/batch = 0.6942s	
25116/28500 (epoch 44.063), train_loss = 0.83732891, grad/param norm = 1.9556e-01, time/batch = 0.6973s	
25117/28500 (epoch 44.065), train_loss = 0.81546950, grad/param norm = 2.0433e-01, time/batch = 0.6916s	
25118/28500 (epoch 44.067), train_loss = 0.74728030, grad/param norm = 1.9218e-01, time/batch = 0.6942s	
25119/28500 (epoch 44.068), train_loss = 0.77914766, grad/param norm = 1.8092e-01, time/batch = 0.6940s	
25120/28500 (epoch 44.070), train_loss = 0.82713452, grad/param norm = 2.0045e-01, time/batch = 0.6890s	
25121/28500 (epoch 44.072), train_loss = 0.93076989, grad/param norm = 2.2270e-01, time/batch = 0.7066s	
25122/28500 (epoch 44.074), train_loss = 0.79202085, grad/param norm = 1.9230e-01, time/batch = 0.7021s	
25123/28500 (epoch 44.075), train_loss = 0.80710081, grad/param norm = 1.7768e-01, time/batch = 0.6931s	
25124/28500 (epoch 44.077), train_loss = 0.84513153, grad/param norm = 1.8192e-01, time/batch = 0.6895s	
25125/28500 (epoch 44.079), train_loss = 0.83488165, grad/param norm = 1.8647e-01, time/batch = 0.6900s	
25126/28500 (epoch 44.081), train_loss = 0.88887666, grad/param norm = 2.1610e-01, time/batch = 0.6914s	
25127/28500 (epoch 44.082), train_loss = 0.76507233, grad/param norm = 2.1316e-01, time/batch = 0.6958s	
25128/28500 (epoch 44.084), train_loss = 0.80853657, grad/param norm = 2.0010e-01, time/batch = 0.7039s	
25129/28500 (epoch 44.086), train_loss = 0.76436095, grad/param norm = 2.8806e-01, time/batch = 0.6917s	
25130/28500 (epoch 44.088), train_loss = 0.71879692, grad/param norm = 1.8755e-01, time/batch = 0.6893s	
25131/28500 (epoch 44.089), train_loss = 0.86757997, grad/param norm = 2.2154e-01, time/batch = 0.6922s	
25132/28500 (epoch 44.091), train_loss = 0.73866970, grad/param norm = 1.7718e-01, time/batch = 0.6935s	
25133/28500 (epoch 44.093), train_loss = 0.88854500, grad/param norm = 2.0641e-01, time/batch = 0.7039s	
25134/28500 (epoch 44.095), train_loss = 0.80977593, grad/param norm = 1.7775e-01, time/batch = 0.7065s	
25135/28500 (epoch 44.096), train_loss = 0.88981319, grad/param norm = 2.0585e-01, time/batch = 0.6988s	
25136/28500 (epoch 44.098), train_loss = 0.81379251, grad/param norm = 2.5843e-01, time/batch = 0.6905s	
25137/28500 (epoch 44.100), train_loss = 0.77917952, grad/param norm = 1.8309e-01, time/batch = 0.6908s	
25138/28500 (epoch 44.102), train_loss = 0.90786888, grad/param norm = 2.4584e-01, time/batch = 0.6925s	
25139/28500 (epoch 44.104), train_loss = 0.82820902, grad/param norm = 2.7553e-01, time/batch = 0.6948s	
25140/28500 (epoch 44.105), train_loss = 0.89764185, grad/param norm = 2.0428e-01, time/batch = 0.6982s	
25141/28500 (epoch 44.107), train_loss = 0.74853965, grad/param norm = 2.2243e-01, time/batch = 0.6970s	
25142/28500 (epoch 44.109), train_loss = 0.77805345, grad/param norm = 2.4898e-01, time/batch = 0.6971s	
25143/28500 (epoch 44.111), train_loss = 0.78323992, grad/param norm = 2.0836e-01, time/batch = 0.6914s	
25144/28500 (epoch 44.112), train_loss = 0.88648902, grad/param norm = 2.1483e-01, time/batch = 0.6943s	
25145/28500 (epoch 44.114), train_loss = 0.80671905, grad/param norm = 1.9738e-01, time/batch = 0.6914s	
25146/28500 (epoch 44.116), train_loss = 0.94168844, grad/param norm = 2.0898e-01, time/batch = 0.6948s	
25147/28500 (epoch 44.118), train_loss = 0.74027133, grad/param norm = 2.0264e-01, time/batch = 0.6937s	
25148/28500 (epoch 44.119), train_loss = 0.84998677, grad/param norm = 2.3162e-01, time/batch = 0.6921s	
25149/28500 (epoch 44.121), train_loss = 0.96368075, grad/param norm = 2.5051e-01, time/batch = 0.6898s	
25150/28500 (epoch 44.123), train_loss = 0.91185783, grad/param norm = 1.9539e-01, time/batch = 0.6890s	
25151/28500 (epoch 44.125), train_loss = 0.82904918, grad/param norm = 1.8525e-01, time/batch = 0.6920s	
25152/28500 (epoch 44.126), train_loss = 0.82523225, grad/param norm = 2.1120e-01, time/batch = 0.6897s	
25153/28500 (epoch 44.128), train_loss = 0.83101630, grad/param norm = 1.7956e-01, time/batch = 0.6902s	
25154/28500 (epoch 44.130), train_loss = 0.79109717, grad/param norm = 2.1753e-01, time/batch = 0.6894s	
25155/28500 (epoch 44.132), train_loss = 0.80589703, grad/param norm = 2.2578e-01, time/batch = 0.6889s	
25156/28500 (epoch 44.133), train_loss = 0.88261539, grad/param norm = 2.1062e-01, time/batch = 0.6890s	
25157/28500 (epoch 44.135), train_loss = 0.76851900, grad/param norm = 1.7955e-01, time/batch = 0.6892s	
25158/28500 (epoch 44.137), train_loss = 0.82015432, grad/param norm = 1.8281e-01, time/batch = 0.6889s	
25159/28500 (epoch 44.139), train_loss = 0.82359059, grad/param norm = 1.6831e-01, time/batch = 0.6903s	
25160/28500 (epoch 44.140), train_loss = 0.81347790, grad/param norm = 1.8957e-01, time/batch = 0.6885s	
25161/28500 (epoch 44.142), train_loss = 0.78984382, grad/param norm = 2.0983e-01, time/batch = 0.6914s	
25162/28500 (epoch 44.144), train_loss = 0.72809008, grad/param norm = 2.0263e-01, time/batch = 0.6897s	
25163/28500 (epoch 44.146), train_loss = 0.78444741, grad/param norm = 1.8891e-01, time/batch = 0.6911s	
25164/28500 (epoch 44.147), train_loss = 0.68809896, grad/param norm = 1.7810e-01, time/batch = 0.6912s	
25165/28500 (epoch 44.149), train_loss = 0.70589950, grad/param norm = 1.6615e-01, time/batch = 0.6927s	
25166/28500 (epoch 44.151), train_loss = 0.76241283, grad/param norm = 1.8711e-01, time/batch = 0.6974s	
25167/28500 (epoch 44.153), train_loss = 0.83329494, grad/param norm = 2.0636e-01, time/batch = 0.6895s	
25168/28500 (epoch 44.154), train_loss = 0.69195051, grad/param norm = 2.0349e-01, time/batch = 0.6957s	
25169/28500 (epoch 44.156), train_loss = 0.87525888, grad/param norm = 2.2812e-01, time/batch = 0.6948s	
25170/28500 (epoch 44.158), train_loss = 0.84947615, grad/param norm = 2.1140e-01, time/batch = 0.6892s	
25171/28500 (epoch 44.160), train_loss = 0.73328938, grad/param norm = 1.8128e-01, time/batch = 0.6910s	
25172/28500 (epoch 44.161), train_loss = 0.73576995, grad/param norm = 1.8451e-01, time/batch = 0.6998s	
25173/28500 (epoch 44.163), train_loss = 0.70309529, grad/param norm = 1.8707e-01, time/batch = 0.6932s	
25174/28500 (epoch 44.165), train_loss = 0.93150089, grad/param norm = 1.8229e-01, time/batch = 0.6922s	
25175/28500 (epoch 44.167), train_loss = 0.94503991, grad/param norm = 2.0461e-01, time/batch = 0.6892s	
25176/28500 (epoch 44.168), train_loss = 0.91010665, grad/param norm = 2.2427e-01, time/batch = 0.6885s	
25177/28500 (epoch 44.170), train_loss = 0.90621275, grad/param norm = 2.4970e-01, time/batch = 0.6880s	
25178/28500 (epoch 44.172), train_loss = 0.77362434, grad/param norm = 1.8133e-01, time/batch = 0.6891s	
25179/28500 (epoch 44.174), train_loss = 0.94622348, grad/param norm = 2.4907e-01, time/batch = 0.6939s	
25180/28500 (epoch 44.175), train_loss = 0.80289695, grad/param norm = 1.9511e-01, time/batch = 0.6925s	
25181/28500 (epoch 44.177), train_loss = 0.84226603, grad/param norm = 2.0387e-01, time/batch = 0.6915s	
25182/28500 (epoch 44.179), train_loss = 0.87016192, grad/param norm = 1.9089e-01, time/batch = 0.6895s	
25183/28500 (epoch 44.181), train_loss = 0.82123007, grad/param norm = 2.2428e-01, time/batch = 0.6886s	
25184/28500 (epoch 44.182), train_loss = 0.77146837, grad/param norm = 1.8817e-01, time/batch = 0.6898s	
25185/28500 (epoch 44.184), train_loss = 0.96428263, grad/param norm = 2.0274e-01, time/batch = 0.6891s	
25186/28500 (epoch 44.186), train_loss = 0.94485620, grad/param norm = 2.0019e-01, time/batch = 0.6889s	
25187/28500 (epoch 44.188), train_loss = 0.87693834, grad/param norm = 2.2291e-01, time/batch = 0.6890s	
25188/28500 (epoch 44.189), train_loss = 0.81792406, grad/param norm = 1.7891e-01, time/batch = 0.6902s	
25189/28500 (epoch 44.191), train_loss = 0.96411661, grad/param norm = 2.1275e-01, time/batch = 0.6891s	
25190/28500 (epoch 44.193), train_loss = 0.79858934, grad/param norm = 2.1162e-01, time/batch = 0.6886s	
25191/28500 (epoch 44.195), train_loss = 0.94345050, grad/param norm = 2.0722e-01, time/batch = 0.6914s	
25192/28500 (epoch 44.196), train_loss = 0.86770479, grad/param norm = 2.1691e-01, time/batch = 0.6894s	
25193/28500 (epoch 44.198), train_loss = 0.82249878, grad/param norm = 1.9154e-01, time/batch = 0.6903s	
25194/28500 (epoch 44.200), train_loss = 0.89772609, grad/param norm = 1.9658e-01, time/batch = 0.7068s	
25195/28500 (epoch 44.202), train_loss = 0.85238590, grad/param norm = 1.7969e-01, time/batch = 0.6913s	
25196/28500 (epoch 44.204), train_loss = 0.79812726, grad/param norm = 1.7090e-01, time/batch = 0.6899s	
25197/28500 (epoch 44.205), train_loss = 0.75506079, grad/param norm = 1.7804e-01, time/batch = 0.6902s	
25198/28500 (epoch 44.207), train_loss = 0.68685239, grad/param norm = 1.8385e-01, time/batch = 0.6887s	
25199/28500 (epoch 44.209), train_loss = 0.84103371, grad/param norm = 1.9766e-01, time/batch = 0.6892s	
25200/28500 (epoch 44.211), train_loss = 0.74232087, grad/param norm = 1.7342e-01, time/batch = 0.6896s	
25201/28500 (epoch 44.212), train_loss = 0.67146122, grad/param norm = 1.8063e-01, time/batch = 0.6905s	
25202/28500 (epoch 44.214), train_loss = 0.79556560, grad/param norm = 1.9978e-01, time/batch = 0.6896s	
25203/28500 (epoch 44.216), train_loss = 0.75175404, grad/param norm = 1.9099e-01, time/batch = 0.6891s	
25204/28500 (epoch 44.218), train_loss = 0.92327553, grad/param norm = 1.9420e-01, time/batch = 0.6887s	
25205/28500 (epoch 44.219), train_loss = 0.83623118, grad/param norm = 2.0682e-01, time/batch = 0.6916s	
25206/28500 (epoch 44.221), train_loss = 0.69649059, grad/param norm = 1.8252e-01, time/batch = 0.6892s	
25207/28500 (epoch 44.223), train_loss = 0.89957553, grad/param norm = 2.0252e-01, time/batch = 0.6888s	
25208/28500 (epoch 44.225), train_loss = 0.96047790, grad/param norm = 2.2997e-01, time/batch = 0.6882s	
25209/28500 (epoch 44.226), train_loss = 0.77388575, grad/param norm = 1.7072e-01, time/batch = 0.6887s	
25210/28500 (epoch 44.228), train_loss = 0.90280499, grad/param norm = 1.8604e-01, time/batch = 0.6887s	
25211/28500 (epoch 44.230), train_loss = 0.88577615, grad/param norm = 2.0456e-01, time/batch = 0.6926s	
25212/28500 (epoch 44.232), train_loss = 0.87924637, grad/param norm = 2.1665e-01, time/batch = 0.6911s	
25213/28500 (epoch 44.233), train_loss = 0.80063311, grad/param norm = 1.8983e-01, time/batch = 0.6912s	
25214/28500 (epoch 44.235), train_loss = 0.82080804, grad/param norm = 1.9395e-01, time/batch = 0.7035s	
25215/28500 (epoch 44.237), train_loss = 0.74390817, grad/param norm = 1.6877e-01, time/batch = 0.7105s	
25216/28500 (epoch 44.239), train_loss = 0.78798654, grad/param norm = 1.7970e-01, time/batch = 0.7014s	
25217/28500 (epoch 44.240), train_loss = 0.71286329, grad/param norm = 1.7610e-01, time/batch = 0.7038s	
25218/28500 (epoch 44.242), train_loss = 0.73951469, grad/param norm = 2.1143e-01, time/batch = 0.7015s	
25219/28500 (epoch 44.244), train_loss = 0.83713355, grad/param norm = 1.6847e-01, time/batch = 0.6957s	
25220/28500 (epoch 44.246), train_loss = 0.84484241, grad/param norm = 1.7789e-01, time/batch = 0.7033s	
25221/28500 (epoch 44.247), train_loss = 0.92304943, grad/param norm = 2.1532e-01, time/batch = 0.7231s	
25222/28500 (epoch 44.249), train_loss = 0.78648691, grad/param norm = 1.6808e-01, time/batch = 0.7082s	
25223/28500 (epoch 44.251), train_loss = 0.80910251, grad/param norm = 1.9257e-01, time/batch = 0.7263s	
25224/28500 (epoch 44.253), train_loss = 0.95019274, grad/param norm = 2.3679e-01, time/batch = 0.7177s	
25225/28500 (epoch 44.254), train_loss = 0.95224672, grad/param norm = 1.8888e-01, time/batch = 0.7096s	
25226/28500 (epoch 44.256), train_loss = 0.79960828, grad/param norm = 2.1016e-01, time/batch = 0.7156s	
25227/28500 (epoch 44.258), train_loss = 0.79601147, grad/param norm = 1.8709e-01, time/batch = 0.7183s	
25228/28500 (epoch 44.260), train_loss = 0.80365454, grad/param norm = 1.7174e-01, time/batch = 0.7205s	
25229/28500 (epoch 44.261), train_loss = 0.70540905, grad/param norm = 1.9683e-01, time/batch = 0.7195s	
25230/28500 (epoch 44.263), train_loss = 0.87207452, grad/param norm = 2.0599e-01, time/batch = 0.6959s	
25231/28500 (epoch 44.265), train_loss = 0.75549658, grad/param norm = 1.7122e-01, time/batch = 0.6997s	
25232/28500 (epoch 44.267), train_loss = 0.96283945, grad/param norm = 2.0216e-01, time/batch = 0.7002s	
25233/28500 (epoch 44.268), train_loss = 0.84233755, grad/param norm = 1.8297e-01, time/batch = 0.6954s	
25234/28500 (epoch 44.270), train_loss = 0.80119072, grad/param norm = 2.1251e-01, time/batch = 0.6998s	
25235/28500 (epoch 44.272), train_loss = 0.81579880, grad/param norm = 1.8276e-01, time/batch = 0.6950s	
25236/28500 (epoch 44.274), train_loss = 0.86330823, grad/param norm = 1.9391e-01, time/batch = 0.6995s	
25237/28500 (epoch 44.275), train_loss = 0.86871251, grad/param norm = 1.8894e-01, time/batch = 0.6980s	
25238/28500 (epoch 44.277), train_loss = 0.79690863, grad/param norm = 1.8870e-01, time/batch = 0.7020s	
25239/28500 (epoch 44.279), train_loss = 0.86231319, grad/param norm = 2.1535e-01, time/batch = 0.6969s	
25240/28500 (epoch 44.281), train_loss = 0.85830512, grad/param norm = 2.4752e-01, time/batch = 0.7026s	
25241/28500 (epoch 44.282), train_loss = 0.82034726, grad/param norm = 1.6504e-01, time/batch = 0.6995s	
25242/28500 (epoch 44.284), train_loss = 0.86989036, grad/param norm = 2.2624e-01, time/batch = 0.6951s	
25243/28500 (epoch 44.286), train_loss = 0.90232225, grad/param norm = 2.1912e-01, time/batch = 0.6950s	
25244/28500 (epoch 44.288), train_loss = 0.80151319, grad/param norm = 2.1242e-01, time/batch = 0.6985s	
25245/28500 (epoch 44.289), train_loss = 0.83763687, grad/param norm = 2.1277e-01, time/batch = 0.6927s	
25246/28500 (epoch 44.291), train_loss = 0.83252558, grad/param norm = 1.8438e-01, time/batch = 0.6946s	
25247/28500 (epoch 44.293), train_loss = 0.82751826, grad/param norm = 1.9729e-01, time/batch = 0.6938s	
25248/28500 (epoch 44.295), train_loss = 0.72945828, grad/param norm = 1.7311e-01, time/batch = 0.6955s	
25249/28500 (epoch 44.296), train_loss = 0.71582075, grad/param norm = 1.9072e-01, time/batch = 0.6931s	
25250/28500 (epoch 44.298), train_loss = 0.87496062, grad/param norm = 1.7553e-01, time/batch = 0.7034s	
25251/28500 (epoch 44.300), train_loss = 0.74061398, grad/param norm = 1.8583e-01, time/batch = 0.6989s	
25252/28500 (epoch 44.302), train_loss = 0.69216228, grad/param norm = 1.8083e-01, time/batch = 0.6960s	
25253/28500 (epoch 44.304), train_loss = 0.78939782, grad/param norm = 1.9319e-01, time/batch = 0.6938s	
25254/28500 (epoch 44.305), train_loss = 0.86017001, grad/param norm = 1.8017e-01, time/batch = 0.6961s	
25255/28500 (epoch 44.307), train_loss = 0.77865819, grad/param norm = 2.0915e-01, time/batch = 0.6944s	
25256/28500 (epoch 44.309), train_loss = 0.79988940, grad/param norm = 1.7139e-01, time/batch = 0.6983s	
25257/28500 (epoch 44.311), train_loss = 0.86224998, grad/param norm = 1.8904e-01, time/batch = 0.6964s	
25258/28500 (epoch 44.312), train_loss = 0.85382027, grad/param norm = 1.9604e-01, time/batch = 0.6951s	
25259/28500 (epoch 44.314), train_loss = 0.82984164, grad/param norm = 1.8416e-01, time/batch = 0.6954s	
25260/28500 (epoch 44.316), train_loss = 0.83024430, grad/param norm = 1.9635e-01, time/batch = 0.6971s	
25261/28500 (epoch 44.318), train_loss = 0.88979194, grad/param norm = 1.8803e-01, time/batch = 0.7034s	
25262/28500 (epoch 44.319), train_loss = 0.75977389, grad/param norm = 1.9306e-01, time/batch = 0.6917s	
25263/28500 (epoch 44.321), train_loss = 0.77473398, grad/param norm = 1.9432e-01, time/batch = 0.6949s	
25264/28500 (epoch 44.323), train_loss = 0.82750479, grad/param norm = 2.1356e-01, time/batch = 0.7019s	
25265/28500 (epoch 44.325), train_loss = 0.91839388, grad/param norm = 2.0059e-01, time/batch = 0.7057s	
25266/28500 (epoch 44.326), train_loss = 0.83356824, grad/param norm = 1.8586e-01, time/batch = 0.6993s	
25267/28500 (epoch 44.328), train_loss = 0.65971325, grad/param norm = 1.4418e-01, time/batch = 0.6978s	
25268/28500 (epoch 44.330), train_loss = 0.75267721, grad/param norm = 1.7220e-01, time/batch = 0.7025s	
25269/28500 (epoch 44.332), train_loss = 0.76559240, grad/param norm = 1.8647e-01, time/batch = 0.7017s	
25270/28500 (epoch 44.333), train_loss = 0.64081868, grad/param norm = 2.1298e-01, time/batch = 0.7008s	
25271/28500 (epoch 44.335), train_loss = 0.71493353, grad/param norm = 1.7870e-01, time/batch = 0.7031s	
25272/28500 (epoch 44.337), train_loss = 0.65971480, grad/param norm = 1.6042e-01, time/batch = 0.7119s	
25273/28500 (epoch 44.339), train_loss = 0.65729885, grad/param norm = 1.6095e-01, time/batch = 0.6998s	
25274/28500 (epoch 44.340), train_loss = 0.78262237, grad/param norm = 1.9646e-01, time/batch = 0.6999s	
25275/28500 (epoch 44.342), train_loss = 0.78517255, grad/param norm = 1.7487e-01, time/batch = 0.6992s	
25276/28500 (epoch 44.344), train_loss = 0.68703700, grad/param norm = 1.8028e-01, time/batch = 0.6987s	
25277/28500 (epoch 44.346), train_loss = 0.68047354, grad/param norm = 1.6387e-01, time/batch = 0.6978s	
25278/28500 (epoch 44.347), train_loss = 0.79674046, grad/param norm = 1.5358e-01, time/batch = 0.6994s	
25279/28500 (epoch 44.349), train_loss = 0.81521782, grad/param norm = 1.9923e-01, time/batch = 0.6951s	
25280/28500 (epoch 44.351), train_loss = 0.70751309, grad/param norm = 1.8552e-01, time/batch = 0.6939s	
25281/28500 (epoch 44.353), train_loss = 0.82116821, grad/param norm = 2.1523e-01, time/batch = 0.6959s	
25282/28500 (epoch 44.354), train_loss = 0.70363244, grad/param norm = 2.0865e-01, time/batch = 0.6944s	
25283/28500 (epoch 44.356), train_loss = 0.75046608, grad/param norm = 1.7425e-01, time/batch = 0.6945s	
25284/28500 (epoch 44.358), train_loss = 0.83671333, grad/param norm = 1.7938e-01, time/batch = 0.6937s	
25285/28500 (epoch 44.360), train_loss = 0.81031185, grad/param norm = 1.9643e-01, time/batch = 0.6931s	
25286/28500 (epoch 44.361), train_loss = 0.72142150, grad/param norm = 1.8290e-01, time/batch = 0.6934s	
25287/28500 (epoch 44.363), train_loss = 0.70214513, grad/param norm = 1.8790e-01, time/batch = 0.6936s	
25288/28500 (epoch 44.365), train_loss = 0.74297499, grad/param norm = 1.8617e-01, time/batch = 0.6936s	
25289/28500 (epoch 44.367), train_loss = 0.78094205, grad/param norm = 1.8199e-01, time/batch = 0.6963s	
25290/28500 (epoch 44.368), train_loss = 0.73043944, grad/param norm = 1.8565e-01, time/batch = 0.6972s	
25291/28500 (epoch 44.370), train_loss = 0.81434746, grad/param norm = 2.2336e-01, time/batch = 0.7007s	
25292/28500 (epoch 44.372), train_loss = 0.64253231, grad/param norm = 1.8814e-01, time/batch = 0.6997s	
25293/28500 (epoch 44.374), train_loss = 0.76308698, grad/param norm = 1.9054e-01, time/batch = 0.7025s	
25294/28500 (epoch 44.375), train_loss = 0.88174294, grad/param norm = 1.9852e-01, time/batch = 0.6975s	
25295/28500 (epoch 44.377), train_loss = 0.75123657, grad/param norm = 2.3853e-01, time/batch = 0.6990s	
25296/28500 (epoch 44.379), train_loss = 0.63077783, grad/param norm = 1.8052e-01, time/batch = 0.6976s	
25297/28500 (epoch 44.381), train_loss = 0.75505902, grad/param norm = 1.8237e-01, time/batch = 0.6987s	
25298/28500 (epoch 44.382), train_loss = 0.74037784, grad/param norm = 1.9167e-01, time/batch = 0.7000s	
25299/28500 (epoch 44.384), train_loss = 0.65201862, grad/param norm = 1.8021e-01, time/batch = 0.7007s	
25300/28500 (epoch 44.386), train_loss = 0.70783095, grad/param norm = 1.7673e-01, time/batch = 0.7139s	
25301/28500 (epoch 44.388), train_loss = 0.85197114, grad/param norm = 2.0146e-01, time/batch = 0.7099s	
25302/28500 (epoch 44.389), train_loss = 0.71469596, grad/param norm = 2.0266e-01, time/batch = 0.6993s	
25303/28500 (epoch 44.391), train_loss = 0.70358382, grad/param norm = 2.0848e-01, time/batch = 0.6984s	
25304/28500 (epoch 44.393), train_loss = 0.70545632, grad/param norm = 1.9308e-01, time/batch = 0.6976s	
25305/28500 (epoch 44.395), train_loss = 0.88134316, grad/param norm = 2.0178e-01, time/batch = 0.6997s	
25306/28500 (epoch 44.396), train_loss = 0.85760625, grad/param norm = 2.0056e-01, time/batch = 0.6999s	
25307/28500 (epoch 44.398), train_loss = 0.59691289, grad/param norm = 1.9094e-01, time/batch = 0.6986s	
25308/28500 (epoch 44.400), train_loss = 0.74788442, grad/param norm = 1.8344e-01, time/batch = 0.6993s	
25309/28500 (epoch 44.402), train_loss = 0.79212405, grad/param norm = 1.6803e-01, time/batch = 0.6977s	
25310/28500 (epoch 44.404), train_loss = 0.78462589, grad/param norm = 2.0366e-01, time/batch = 0.6984s	
25311/28500 (epoch 44.405), train_loss = 0.85014681, grad/param norm = 1.9526e-01, time/batch = 0.7007s	
25312/28500 (epoch 44.407), train_loss = 0.78946804, grad/param norm = 1.8246e-01, time/batch = 0.7018s	
25313/28500 (epoch 44.409), train_loss = 0.78137212, grad/param norm = 1.9577e-01, time/batch = 0.6980s	
25314/28500 (epoch 44.411), train_loss = 0.87780391, grad/param norm = 2.1107e-01, time/batch = 0.6971s	
25315/28500 (epoch 44.412), train_loss = 0.90706995, grad/param norm = 2.2061e-01, time/batch = 0.6967s	
25316/28500 (epoch 44.414), train_loss = 0.81322942, grad/param norm = 2.0608e-01, time/batch = 0.6973s	
25317/28500 (epoch 44.416), train_loss = 0.71386564, grad/param norm = 1.7664e-01, time/batch = 0.7030s	
25318/28500 (epoch 44.418), train_loss = 0.81576264, grad/param norm = 1.8105e-01, time/batch = 0.6973s	
25319/28500 (epoch 44.419), train_loss = 0.89376025, grad/param norm = 1.9403e-01, time/batch = 0.6971s	
25320/28500 (epoch 44.421), train_loss = 0.85627779, grad/param norm = 1.9042e-01, time/batch = 0.7013s	
25321/28500 (epoch 44.423), train_loss = 0.84645376, grad/param norm = 2.0174e-01, time/batch = 0.7039s	
25322/28500 (epoch 44.425), train_loss = 0.77353944, grad/param norm = 2.1963e-01, time/batch = 0.7002s	
25323/28500 (epoch 44.426), train_loss = 0.80057995, grad/param norm = 2.1164e-01, time/batch = 0.7070s	
25324/28500 (epoch 44.428), train_loss = 0.97484395, grad/param norm = 2.6972e-01, time/batch = 0.7022s	
25325/28500 (epoch 44.430), train_loss = 0.93108227, grad/param norm = 1.9573e-01, time/batch = 0.7012s	
25326/28500 (epoch 44.432), train_loss = 0.83640416, grad/param norm = 1.9306e-01, time/batch = 0.6990s	
25327/28500 (epoch 44.433), train_loss = 0.88849251, grad/param norm = 2.3757e-01, time/batch = 0.7095s	
25328/28500 (epoch 44.435), train_loss = 0.84197411, grad/param norm = 2.6008e-01, time/batch = 0.6959s	
25329/28500 (epoch 44.437), train_loss = 0.76687676, grad/param norm = 1.7838e-01, time/batch = 0.6980s	
25330/28500 (epoch 44.439), train_loss = 0.81670146, grad/param norm = 2.1743e-01, time/batch = 0.6976s	
25331/28500 (epoch 44.440), train_loss = 0.95248087, grad/param norm = 2.0571e-01, time/batch = 0.7002s	
25332/28500 (epoch 44.442), train_loss = 0.75103236, grad/param norm = 1.8341e-01, time/batch = 0.7010s	
25333/28500 (epoch 44.444), train_loss = 0.72053092, grad/param norm = 1.6965e-01, time/batch = 0.6990s	
25334/28500 (epoch 44.446), train_loss = 0.70090147, grad/param norm = 2.1834e-01, time/batch = 0.7010s	
25335/28500 (epoch 44.447), train_loss = 0.68904884, grad/param norm = 1.8181e-01, time/batch = 0.7197s	
25336/28500 (epoch 44.449), train_loss = 0.76548819, grad/param norm = 1.8573e-01, time/batch = 0.7017s	
25337/28500 (epoch 44.451), train_loss = 0.77342079, grad/param norm = 1.8660e-01, time/batch = 0.7151s	
25338/28500 (epoch 44.453), train_loss = 0.76773126, grad/param norm = 1.8258e-01, time/batch = 0.7057s	
25339/28500 (epoch 44.454), train_loss = 0.71639609, grad/param norm = 1.6020e-01, time/batch = 0.7048s	
25340/28500 (epoch 44.456), train_loss = 0.84860133, grad/param norm = 2.6932e-01, time/batch = 0.7006s	
25341/28500 (epoch 44.458), train_loss = 0.74303706, grad/param norm = 1.8087e-01, time/batch = 0.7057s	
25342/28500 (epoch 44.460), train_loss = 0.87625519, grad/param norm = 2.1431e-01, time/batch = 0.6993s	
25343/28500 (epoch 44.461), train_loss = 0.71595575, grad/param norm = 2.0614e-01, time/batch = 0.6998s	
25344/28500 (epoch 44.463), train_loss = 0.65966827, grad/param norm = 1.5084e-01, time/batch = 0.6982s	
25345/28500 (epoch 44.465), train_loss = 0.64065091, grad/param norm = 2.2978e-01, time/batch = 0.7010s	
25346/28500 (epoch 44.467), train_loss = 0.78134586, grad/param norm = 1.6222e-01, time/batch = 0.6985s	
25347/28500 (epoch 44.468), train_loss = 0.70127847, grad/param norm = 1.6505e-01, time/batch = 0.6975s	
25348/28500 (epoch 44.470), train_loss = 0.74775584, grad/param norm = 2.5324e-01, time/batch = 0.6960s	
25349/28500 (epoch 44.472), train_loss = 0.70305603, grad/param norm = 1.6466e-01, time/batch = 0.6991s	
25350/28500 (epoch 44.474), train_loss = 0.93155752, grad/param norm = 2.1596e-01, time/batch = 0.7032s	
25351/28500 (epoch 44.475), train_loss = 0.75304273, grad/param norm = 1.9712e-01, time/batch = 0.7025s	
25352/28500 (epoch 44.477), train_loss = 0.78889500, grad/param norm = 1.8186e-01, time/batch = 0.6995s	
25353/28500 (epoch 44.479), train_loss = 0.84725447, grad/param norm = 2.0253e-01, time/batch = 0.6973s	
25354/28500 (epoch 44.481), train_loss = 0.83735041, grad/param norm = 1.9801e-01, time/batch = 0.7040s	
25355/28500 (epoch 44.482), train_loss = 0.68614763, grad/param norm = 1.9232e-01, time/batch = 0.6995s	
25356/28500 (epoch 44.484), train_loss = 0.73600353, grad/param norm = 1.8530e-01, time/batch = 0.7041s	
25357/28500 (epoch 44.486), train_loss = 0.64855190, grad/param norm = 1.7810e-01, time/batch = 0.7003s	
25358/28500 (epoch 44.488), train_loss = 0.82772361, grad/param norm = 1.8283e-01, time/batch = 0.6991s	
25359/28500 (epoch 44.489), train_loss = 0.92478734, grad/param norm = 1.9037e-01, time/batch = 0.6993s	
25360/28500 (epoch 44.491), train_loss = 0.73097481, grad/param norm = 1.8585e-01, time/batch = 0.6973s	
25361/28500 (epoch 44.493), train_loss = 0.77209396, grad/param norm = 1.8449e-01, time/batch = 0.7005s	
25362/28500 (epoch 44.495), train_loss = 0.79479852, grad/param norm = 2.1636e-01, time/batch = 0.7013s	
25363/28500 (epoch 44.496), train_loss = 0.69691563, grad/param norm = 2.0621e-01, time/batch = 0.7018s	
25364/28500 (epoch 44.498), train_loss = 0.76087686, grad/param norm = 1.6641e-01, time/batch = 0.7002s	
25365/28500 (epoch 44.500), train_loss = 0.73301498, grad/param norm = 1.7454e-01, time/batch = 0.6996s	
25366/28500 (epoch 44.502), train_loss = 0.80806431, grad/param norm = 1.8490e-01, time/batch = 0.6988s	
25367/28500 (epoch 44.504), train_loss = 0.87326812, grad/param norm = 1.9375e-01, time/batch = 0.7032s	
25368/28500 (epoch 44.505), train_loss = 0.73599442, grad/param norm = 1.7560e-01, time/batch = 0.7024s	
25369/28500 (epoch 44.507), train_loss = 0.87498387, grad/param norm = 2.1968e-01, time/batch = 0.7011s	
25370/28500 (epoch 44.509), train_loss = 0.77444799, grad/param norm = 1.7676e-01, time/batch = 0.7066s	
25371/28500 (epoch 44.511), train_loss = 0.77561271, grad/param norm = 1.7835e-01, time/batch = 0.7045s	
25372/28500 (epoch 44.512), train_loss = 0.84253833, grad/param norm = 1.8979e-01, time/batch = 0.7014s	
25373/28500 (epoch 44.514), train_loss = 0.76403334, grad/param norm = 1.8919e-01, time/batch = 0.6966s	
25374/28500 (epoch 44.516), train_loss = 0.78155860, grad/param norm = 1.5838e-01, time/batch = 0.6987s	
25375/28500 (epoch 44.518), train_loss = 0.83905193, grad/param norm = 2.0394e-01, time/batch = 0.6982s	
25376/28500 (epoch 44.519), train_loss = 0.82806440, grad/param norm = 1.8772e-01, time/batch = 0.7004s	
25377/28500 (epoch 44.521), train_loss = 0.90048874, grad/param norm = 2.2669e-01, time/batch = 0.7047s	
25378/28500 (epoch 44.523), train_loss = 0.83009020, grad/param norm = 2.1545e-01, time/batch = 0.7084s	
25379/28500 (epoch 44.525), train_loss = 0.89572653, grad/param norm = 1.7567e-01, time/batch = 0.7047s	
25380/28500 (epoch 44.526), train_loss = 0.82946838, grad/param norm = 1.9832e-01, time/batch = 0.6953s	
25381/28500 (epoch 44.528), train_loss = 0.83695092, grad/param norm = 2.1755e-01, time/batch = 0.6916s	
25382/28500 (epoch 44.530), train_loss = 0.83619067, grad/param norm = 2.0507e-01, time/batch = 0.6963s	
25383/28500 (epoch 44.532), train_loss = 0.77539229, grad/param norm = 1.9257e-01, time/batch = 0.6924s	
25384/28500 (epoch 44.533), train_loss = 0.81868243, grad/param norm = 1.6933e-01, time/batch = 0.6935s	
25385/28500 (epoch 44.535), train_loss = 0.69032553, grad/param norm = 1.6041e-01, time/batch = 0.7059s	
25386/28500 (epoch 44.537), train_loss = 0.67455065, grad/param norm = 1.5904e-01, time/batch = 0.6997s	
25387/28500 (epoch 44.539), train_loss = 0.68234643, grad/param norm = 1.9118e-01, time/batch = 0.6987s	
25388/28500 (epoch 44.540), train_loss = 0.77912211, grad/param norm = 1.9039e-01, time/batch = 0.6991s	
25389/28500 (epoch 44.542), train_loss = 0.82200803, grad/param norm = 2.0852e-01, time/batch = 0.7007s	
25390/28500 (epoch 44.544), train_loss = 0.91017433, grad/param norm = 2.2031e-01, time/batch = 0.7137s	
25391/28500 (epoch 44.546), train_loss = 0.79208873, grad/param norm = 1.8643e-01, time/batch = 0.7105s	
25392/28500 (epoch 44.547), train_loss = 0.76264640, grad/param norm = 1.7296e-01, time/batch = 0.7149s	
25393/28500 (epoch 44.549), train_loss = 0.67758428, grad/param norm = 1.6211e-01, time/batch = 0.7169s	
25394/28500 (epoch 44.551), train_loss = 0.72834703, grad/param norm = 2.2035e-01, time/batch = 0.7048s	
25395/28500 (epoch 44.553), train_loss = 0.93590747, grad/param norm = 2.5040e-01, time/batch = 0.7113s	
25396/28500 (epoch 44.554), train_loss = 0.82252830, grad/param norm = 2.0582e-01, time/batch = 0.7066s	
25397/28500 (epoch 44.556), train_loss = 0.82462029, grad/param norm = 1.8439e-01, time/batch = 0.7009s	
25398/28500 (epoch 44.558), train_loss = 0.85532375, grad/param norm = 1.8428e-01, time/batch = 0.7067s	
25399/28500 (epoch 44.560), train_loss = 0.83317387, grad/param norm = 2.0090e-01, time/batch = 0.7049s	
25400/28500 (epoch 44.561), train_loss = 0.85028516, grad/param norm = 2.0487e-01, time/batch = 0.7023s	
25401/28500 (epoch 44.563), train_loss = 0.94421304, grad/param norm = 2.7745e-01, time/batch = 0.7017s	
25402/28500 (epoch 44.565), train_loss = 0.74332208, grad/param norm = 1.9135e-01, time/batch = 0.7048s	
25403/28500 (epoch 44.567), train_loss = 0.66864462, grad/param norm = 1.7810e-01, time/batch = 0.7011s	
25404/28500 (epoch 44.568), train_loss = 0.82109470, grad/param norm = 2.3036e-01, time/batch = 0.6981s	
25405/28500 (epoch 44.570), train_loss = 0.77500343, grad/param norm = 2.0974e-01, time/batch = 0.6997s	
25406/28500 (epoch 44.572), train_loss = 0.81368093, grad/param norm = 1.9216e-01, time/batch = 0.7027s	
25407/28500 (epoch 44.574), train_loss = 0.75949113, grad/param norm = 1.8380e-01, time/batch = 0.7012s	
25408/28500 (epoch 44.575), train_loss = 0.74334412, grad/param norm = 1.7261e-01, time/batch = 0.7126s	
25409/28500 (epoch 44.577), train_loss = 0.87101108, grad/param norm = 2.0059e-01, time/batch = 0.7265s	
25410/28500 (epoch 44.579), train_loss = 0.86923401, grad/param norm = 2.0857e-01, time/batch = 0.7228s	
25411/28500 (epoch 44.581), train_loss = 0.74144849, grad/param norm = 2.2081e-01, time/batch = 0.7038s	
25412/28500 (epoch 44.582), train_loss = 0.90336700, grad/param norm = 2.1095e-01, time/batch = 0.6967s	
25413/28500 (epoch 44.584), train_loss = 0.75853059, grad/param norm = 1.9398e-01, time/batch = 0.6982s	
25414/28500 (epoch 44.586), train_loss = 0.72320641, grad/param norm = 1.7059e-01, time/batch = 0.6961s	
25415/28500 (epoch 44.588), train_loss = 0.75173810, grad/param norm = 1.9463e-01, time/batch = 0.6938s	
25416/28500 (epoch 44.589), train_loss = 0.77806582, grad/param norm = 1.9646e-01, time/batch = 0.7155s	
25417/28500 (epoch 44.591), train_loss = 0.80237814, grad/param norm = 2.3256e-01, time/batch = 0.7062s	
25418/28500 (epoch 44.593), train_loss = 0.74238027, grad/param norm = 1.7983e-01, time/batch = 0.6964s	
25419/28500 (epoch 44.595), train_loss = 0.93513930, grad/param norm = 2.0931e-01, time/batch = 0.6951s	
25420/28500 (epoch 44.596), train_loss = 0.94911923, grad/param norm = 2.0348e-01, time/batch = 0.6949s	
25421/28500 (epoch 44.598), train_loss = 0.79135992, grad/param norm = 2.0758e-01, time/batch = 0.6980s	
25422/28500 (epoch 44.600), train_loss = 0.77901355, grad/param norm = 2.1082e-01, time/batch = 0.6994s	
25423/28500 (epoch 44.602), train_loss = 0.86490206, grad/param norm = 2.2673e-01, time/batch = 0.6945s	
25424/28500 (epoch 44.604), train_loss = 0.88131747, grad/param norm = 1.7653e-01, time/batch = 0.7014s	
25425/28500 (epoch 44.605), train_loss = 0.88197349, grad/param norm = 2.0526e-01, time/batch = 0.7077s	
25426/28500 (epoch 44.607), train_loss = 0.91929704, grad/param norm = 1.9946e-01, time/batch = 0.6979s	
25427/28500 (epoch 44.609), train_loss = 0.81757334, grad/param norm = 1.8125e-01, time/batch = 0.7002s	
25428/28500 (epoch 44.611), train_loss = 0.80507424, grad/param norm = 2.0093e-01, time/batch = 0.7000s	
25429/28500 (epoch 44.612), train_loss = 0.85276574, grad/param norm = 2.0900e-01, time/batch = 0.6934s	
25430/28500 (epoch 44.614), train_loss = 0.87995244, grad/param norm = 1.8528e-01, time/batch = 0.6964s	
25431/28500 (epoch 44.616), train_loss = 0.76699434, grad/param norm = 1.8108e-01, time/batch = 0.6997s	
25432/28500 (epoch 44.618), train_loss = 0.78197223, grad/param norm = 2.1081e-01, time/batch = 0.6937s	
25433/28500 (epoch 44.619), train_loss = 0.87467031, grad/param norm = 2.1839e-01, time/batch = 0.6939s	
25434/28500 (epoch 44.621), train_loss = 0.65493680, grad/param norm = 1.7543e-01, time/batch = 0.6966s	
25435/28500 (epoch 44.623), train_loss = 0.93422957, grad/param norm = 2.0587e-01, time/batch = 0.7015s	
25436/28500 (epoch 44.625), train_loss = 0.72483194, grad/param norm = 1.7773e-01, time/batch = 0.6929s	
25437/28500 (epoch 44.626), train_loss = 0.65362926, grad/param norm = 1.7989e-01, time/batch = 0.6929s	
25438/28500 (epoch 44.628), train_loss = 0.74026323, grad/param norm = 1.9998e-01, time/batch = 0.6936s	
25439/28500 (epoch 44.630), train_loss = 0.69827197, grad/param norm = 1.7095e-01, time/batch = 0.6930s	
25440/28500 (epoch 44.632), train_loss = 0.88299901, grad/param norm = 2.0517e-01, time/batch = 0.6959s	
25441/28500 (epoch 44.633), train_loss = 0.92416925, grad/param norm = 1.8662e-01, time/batch = 0.6965s	
25442/28500 (epoch 44.635), train_loss = 0.82929377, grad/param norm = 2.0654e-01, time/batch = 0.6967s	
25443/28500 (epoch 44.637), train_loss = 0.81696869, grad/param norm = 1.9190e-01, time/batch = 0.6931s	
25444/28500 (epoch 44.639), train_loss = 0.71021263, grad/param norm = 1.9292e-01, time/batch = 0.7093s	
25445/28500 (epoch 44.640), train_loss = 0.75347801, grad/param norm = 1.7561e-01, time/batch = 0.7015s	
25446/28500 (epoch 44.642), train_loss = 0.75454488, grad/param norm = 1.8545e-01, time/batch = 0.6970s	
25447/28500 (epoch 44.644), train_loss = 0.82541921, grad/param norm = 1.9296e-01, time/batch = 0.6947s	
25448/28500 (epoch 44.646), train_loss = 0.65016964, grad/param norm = 1.5804e-01, time/batch = 0.6936s	
25449/28500 (epoch 44.647), train_loss = 0.74918813, grad/param norm = 1.8103e-01, time/batch = 0.6938s	
25450/28500 (epoch 44.649), train_loss = 0.75469304, grad/param norm = 2.9526e-01, time/batch = 0.6936s	
25451/28500 (epoch 44.651), train_loss = 0.69765103, grad/param norm = 1.5445e-01, time/batch = 0.6968s	
25452/28500 (epoch 44.653), train_loss = 0.68443741, grad/param norm = 1.8300e-01, time/batch = 0.6947s	
25453/28500 (epoch 44.654), train_loss = 0.72065703, grad/param norm = 2.1047e-01, time/batch = 0.6933s	
25454/28500 (epoch 44.656), train_loss = 0.67277644, grad/param norm = 2.1684e-01, time/batch = 0.6962s	
25455/28500 (epoch 44.658), train_loss = 0.79282891, grad/param norm = 1.9440e-01, time/batch = 0.6973s	
25456/28500 (epoch 44.660), train_loss = 0.79586377, grad/param norm = 1.7008e-01, time/batch = 0.6930s	
25457/28500 (epoch 44.661), train_loss = 0.89029068, grad/param norm = 1.9668e-01, time/batch = 0.6931s	
25458/28500 (epoch 44.663), train_loss = 0.87602991, grad/param norm = 1.9328e-01, time/batch = 0.6931s	
25459/28500 (epoch 44.665), train_loss = 0.79835693, grad/param norm = 2.1712e-01, time/batch = 0.6930s	
25460/28500 (epoch 44.667), train_loss = 0.82234856, grad/param norm = 2.2386e-01, time/batch = 0.6942s	
25461/28500 (epoch 44.668), train_loss = 0.80165393, grad/param norm = 2.0710e-01, time/batch = 0.6952s	
25462/28500 (epoch 44.670), train_loss = 0.79845668, grad/param norm = 1.6895e-01, time/batch = 0.6934s	
25463/28500 (epoch 44.672), train_loss = 0.72577089, grad/param norm = 1.9223e-01, time/batch = 0.6957s	
25464/28500 (epoch 44.674), train_loss = 0.63842666, grad/param norm = 1.7795e-01, time/batch = 0.6946s	
25465/28500 (epoch 44.675), train_loss = 0.68574954, grad/param norm = 1.8374e-01, time/batch = 0.6942s	
25466/28500 (epoch 44.677), train_loss = 0.75514946, grad/param norm = 2.0148e-01, time/batch = 0.6952s	
25467/28500 (epoch 44.679), train_loss = 0.75351978, grad/param norm = 2.0583e-01, time/batch = 0.6814s	
25468/28500 (epoch 44.681), train_loss = 0.83943712, grad/param norm = 2.0164e-01, time/batch = 0.6765s	
25469/28500 (epoch 44.682), train_loss = 0.75276119, grad/param norm = 1.9219e-01, time/batch = 0.6779s	
25470/28500 (epoch 44.684), train_loss = 0.80560957, grad/param norm = 1.9704e-01, time/batch = 0.6861s	
25471/28500 (epoch 44.686), train_loss = 0.74875375, grad/param norm = 1.9785e-01, time/batch = 0.6970s	
25472/28500 (epoch 44.688), train_loss = 0.71488566, grad/param norm = 1.5099e-01, time/batch = 0.6776s	
25473/28500 (epoch 44.689), train_loss = 0.72246569, grad/param norm = 2.1823e-01, time/batch = 0.6795s	
25474/28500 (epoch 44.691), train_loss = 0.83909807, grad/param norm = 2.0253e-01, time/batch = 0.6773s	
25475/28500 (epoch 44.693), train_loss = 0.76269003, grad/param norm = 1.9144e-01, time/batch = 0.6762s	
25476/28500 (epoch 44.695), train_loss = 0.57970973, grad/param norm = 1.7004e-01, time/batch = 0.6787s	
25477/28500 (epoch 44.696), train_loss = 0.74871856, grad/param norm = 2.0004e-01, time/batch = 0.6775s	
25478/28500 (epoch 44.698), train_loss = 0.82165718, grad/param norm = 1.7451e-01, time/batch = 0.6767s	
25479/28500 (epoch 44.700), train_loss = 0.77849987, grad/param norm = 1.8572e-01, time/batch = 0.6762s	
25480/28500 (epoch 44.702), train_loss = 0.75590882, grad/param norm = 2.1249e-01, time/batch = 0.6758s	
25481/28500 (epoch 44.704), train_loss = 0.83338051, grad/param norm = 2.0163e-01, time/batch = 0.6808s	
25482/28500 (epoch 44.705), train_loss = 0.84705836, grad/param norm = 2.2327e-01, time/batch = 0.6785s	
25483/28500 (epoch 44.707), train_loss = 0.72765230, grad/param norm = 2.3495e-01, time/batch = 0.6783s	
25484/28500 (epoch 44.709), train_loss = 0.92650174, grad/param norm = 2.1130e-01, time/batch = 0.6779s	
25485/28500 (epoch 44.711), train_loss = 0.73591201, grad/param norm = 1.9341e-01, time/batch = 0.6780s	
25486/28500 (epoch 44.712), train_loss = 0.81917162, grad/param norm = 2.0286e-01, time/batch = 0.6810s	
25487/28500 (epoch 44.714), train_loss = 0.91924459, grad/param norm = 2.0845e-01, time/batch = 0.6839s	
25488/28500 (epoch 44.716), train_loss = 0.77746960, grad/param norm = 2.0009e-01, time/batch = 0.6811s	
25489/28500 (epoch 44.718), train_loss = 0.81755626, grad/param norm = 2.2327e-01, time/batch = 0.6778s	
25490/28500 (epoch 44.719), train_loss = 0.80766983, grad/param norm = 1.8392e-01, time/batch = 0.6759s	
25491/28500 (epoch 44.721), train_loss = 0.61602694, grad/param norm = 1.7413e-01, time/batch = 0.6791s	
25492/28500 (epoch 44.723), train_loss = 0.79727910, grad/param norm = 2.0165e-01, time/batch = 0.6774s	
25493/28500 (epoch 44.725), train_loss = 0.85199115, grad/param norm = 1.9784e-01, time/batch = 0.6784s	
25494/28500 (epoch 44.726), train_loss = 0.75626435, grad/param norm = 1.7610e-01, time/batch = 0.6840s	
25495/28500 (epoch 44.728), train_loss = 0.70238388, grad/param norm = 1.8549e-01, time/batch = 0.6834s	
25496/28500 (epoch 44.730), train_loss = 0.77881169, grad/param norm = 2.0060e-01, time/batch = 0.6778s	
25497/28500 (epoch 44.732), train_loss = 0.62506255, grad/param norm = 1.5721e-01, time/batch = 0.6791s	
25498/28500 (epoch 44.733), train_loss = 0.66711176, grad/param norm = 1.8177e-01, time/batch = 0.6783s	
25499/28500 (epoch 44.735), train_loss = 0.66386395, grad/param norm = 1.6575e-01, time/batch = 0.6784s	
25500/28500 (epoch 44.737), train_loss = 0.60158558, grad/param norm = 1.6079e-01, time/batch = 0.6887s	
25501/28500 (epoch 44.739), train_loss = 0.68019931, grad/param norm = 1.8410e-01, time/batch = 0.6813s	
25502/28500 (epoch 44.740), train_loss = 0.76713782, grad/param norm = 1.7939e-01, time/batch = 0.6766s	
25503/28500 (epoch 44.742), train_loss = 0.69337701, grad/param norm = 1.8068e-01, time/batch = 0.6791s	
25504/28500 (epoch 44.744), train_loss = 0.78798339, grad/param norm = 1.9942e-01, time/batch = 0.6764s	
25505/28500 (epoch 44.746), train_loss = 0.74110894, grad/param norm = 1.7104e-01, time/batch = 0.6758s	
25506/28500 (epoch 44.747), train_loss = 0.76428609, grad/param norm = 2.1562e-01, time/batch = 0.6763s	
25507/28500 (epoch 44.749), train_loss = 0.83152358, grad/param norm = 2.3060e-01, time/batch = 0.6761s	
25508/28500 (epoch 44.751), train_loss = 0.69969611, grad/param norm = 2.2029e-01, time/batch = 0.6752s	
25509/28500 (epoch 44.753), train_loss = 0.79582061, grad/param norm = 1.9362e-01, time/batch = 0.6751s	
25510/28500 (epoch 44.754), train_loss = 0.68546593, grad/param norm = 2.1505e-01, time/batch = 0.6756s	
25511/28500 (epoch 44.756), train_loss = 0.89374646, grad/param norm = 1.8691e-01, time/batch = 0.6770s	
25512/28500 (epoch 44.758), train_loss = 0.81857206, grad/param norm = 2.3831e-01, time/batch = 0.6764s	
25513/28500 (epoch 44.760), train_loss = 0.68032514, grad/param norm = 1.8015e-01, time/batch = 0.6767s	
25514/28500 (epoch 44.761), train_loss = 0.72601315, grad/param norm = 1.6885e-01, time/batch = 0.6761s	
25515/28500 (epoch 44.763), train_loss = 0.60493623, grad/param norm = 1.7007e-01, time/batch = 0.6758s	
25516/28500 (epoch 44.765), train_loss = 0.75989952, grad/param norm = 1.7956e-01, time/batch = 0.6762s	
25517/28500 (epoch 44.767), train_loss = 0.63670770, grad/param norm = 1.6365e-01, time/batch = 0.6773s	
25518/28500 (epoch 44.768), train_loss = 0.80448216, grad/param norm = 1.7425e-01, time/batch = 0.6769s	
25519/28500 (epoch 44.770), train_loss = 0.68842702, grad/param norm = 1.9220e-01, time/batch = 0.6764s	
25520/28500 (epoch 44.772), train_loss = 0.63424567, grad/param norm = 1.4673e-01, time/batch = 0.6767s	
25521/28500 (epoch 44.774), train_loss = 0.75687422, grad/param norm = 1.6190e-01, time/batch = 0.6796s	
25522/28500 (epoch 44.775), train_loss = 0.80455807, grad/param norm = 1.8499e-01, time/batch = 0.6763s	
25523/28500 (epoch 44.777), train_loss = 0.83605057, grad/param norm = 1.7414e-01, time/batch = 0.6760s	
25524/28500 (epoch 44.779), train_loss = 0.66536694, grad/param norm = 1.5546e-01, time/batch = 0.6759s	
25525/28500 (epoch 44.781), train_loss = 0.75550074, grad/param norm = 1.9599e-01, time/batch = 0.6769s	
25526/28500 (epoch 44.782), train_loss = 0.79201860, grad/param norm = 1.8639e-01, time/batch = 0.6781s	
25527/28500 (epoch 44.784), train_loss = 0.61070084, grad/param norm = 1.7044e-01, time/batch = 0.6768s	
25528/28500 (epoch 44.786), train_loss = 0.64009049, grad/param norm = 1.7953e-01, time/batch = 0.6768s	
25529/28500 (epoch 44.788), train_loss = 0.71093861, grad/param norm = 1.8774e-01, time/batch = 0.6769s	
25530/28500 (epoch 44.789), train_loss = 0.56084445, grad/param norm = 1.7842e-01, time/batch = 0.6757s	
25531/28500 (epoch 44.791), train_loss = 0.79503645, grad/param norm = 1.7378e-01, time/batch = 0.6804s	
25532/28500 (epoch 44.793), train_loss = 0.73566902, grad/param norm = 2.0393e-01, time/batch = 0.6793s	
25533/28500 (epoch 44.795), train_loss = 0.77391898, grad/param norm = 2.0185e-01, time/batch = 0.6783s	
25534/28500 (epoch 44.796), train_loss = 0.69898358, grad/param norm = 1.8206e-01, time/batch = 0.6766s	
25535/28500 (epoch 44.798), train_loss = 0.64251165, grad/param norm = 1.7501e-01, time/batch = 0.6766s	
25536/28500 (epoch 44.800), train_loss = 0.62902584, grad/param norm = 2.0916e-01, time/batch = 0.6767s	
25537/28500 (epoch 44.802), train_loss = 0.72769660, grad/param norm = 2.6783e-01, time/batch = 0.6766s	
25538/28500 (epoch 44.804), train_loss = 0.77603425, grad/param norm = 1.7680e-01, time/batch = 0.6763s	
25539/28500 (epoch 44.805), train_loss = 0.77603179, grad/param norm = 1.9118e-01, time/batch = 0.6764s	
25540/28500 (epoch 44.807), train_loss = 0.78815719, grad/param norm = 2.0669e-01, time/batch = 0.6764s	
25541/28500 (epoch 44.809), train_loss = 0.76359896, grad/param norm = 2.4159e-01, time/batch = 0.6785s	
25542/28500 (epoch 44.811), train_loss = 0.77416617, grad/param norm = 1.9816e-01, time/batch = 0.6779s	
25543/28500 (epoch 44.812), train_loss = 0.74852683, grad/param norm = 2.6391e-01, time/batch = 0.6765s	
25544/28500 (epoch 44.814), train_loss = 0.72328671, grad/param norm = 2.1973e-01, time/batch = 0.6761s	
25545/28500 (epoch 44.816), train_loss = 0.78691569, grad/param norm = 2.0329e-01, time/batch = 0.6805s	
25546/28500 (epoch 44.818), train_loss = 0.88096103, grad/param norm = 2.2215e-01, time/batch = 0.6807s	
25547/28500 (epoch 44.819), train_loss = 0.77759298, grad/param norm = 2.3916e-01, time/batch = 0.6791s	
25548/28500 (epoch 44.821), train_loss = 0.75199882, grad/param norm = 2.0237e-01, time/batch = 0.6808s	
25549/28500 (epoch 44.823), train_loss = 0.88020782, grad/param norm = 2.1826e-01, time/batch = 0.6792s	
25550/28500 (epoch 44.825), train_loss = 0.69479144, grad/param norm = 2.2255e-01, time/batch = 0.6826s	
25551/28500 (epoch 44.826), train_loss = 0.78468625, grad/param norm = 2.2076e-01, time/batch = 0.6844s	
25552/28500 (epoch 44.828), train_loss = 0.69889956, grad/param norm = 1.9748e-01, time/batch = 0.6821s	
25553/28500 (epoch 44.830), train_loss = 0.72325739, grad/param norm = 1.5933e-01, time/batch = 0.6806s	
25554/28500 (epoch 44.832), train_loss = 0.75193653, grad/param norm = 2.0768e-01, time/batch = 0.6813s	
25555/28500 (epoch 44.833), train_loss = 0.79808055, grad/param norm = 1.9155e-01, time/batch = 0.6791s	
25556/28500 (epoch 44.835), train_loss = 0.73020207, grad/param norm = 2.2716e-01, time/batch = 0.6814s	
25557/28500 (epoch 44.837), train_loss = 0.65807563, grad/param norm = 1.8357e-01, time/batch = 0.6829s	
25558/28500 (epoch 44.839), train_loss = 0.91811428, grad/param norm = 2.2318e-01, time/batch = 0.6977s	
25559/28500 (epoch 44.840), train_loss = 0.89876761, grad/param norm = 2.2849e-01, time/batch = 0.6829s	
25560/28500 (epoch 44.842), train_loss = 0.83027649, grad/param norm = 2.1847e-01, time/batch = 0.6835s	
25561/28500 (epoch 44.844), train_loss = 0.84547328, grad/param norm = 1.9661e-01, time/batch = 0.6832s	
25562/28500 (epoch 44.846), train_loss = 0.92123765, grad/param norm = 2.4903e-01, time/batch = 0.6782s	
25563/28500 (epoch 44.847), train_loss = 0.74782722, grad/param norm = 2.2687e-01, time/batch = 0.6782s	
25564/28500 (epoch 44.849), train_loss = 0.73581578, grad/param norm = 1.8207e-01, time/batch = 0.6773s	
25565/28500 (epoch 44.851), train_loss = 0.71714307, grad/param norm = 1.7265e-01, time/batch = 0.6787s	
25566/28500 (epoch 44.853), train_loss = 0.82381927, grad/param norm = 3.4616e-01, time/batch = 0.6788s	
25567/28500 (epoch 44.854), train_loss = 0.79830896, grad/param norm = 2.0426e-01, time/batch = 0.6777s	
25568/28500 (epoch 44.856), train_loss = 0.87786913, grad/param norm = 2.8569e-01, time/batch = 0.6762s	
25569/28500 (epoch 44.858), train_loss = 0.75090034, grad/param norm = 1.9446e-01, time/batch = 0.6766s	
25570/28500 (epoch 44.860), train_loss = 0.75803830, grad/param norm = 1.8800e-01, time/batch = 0.6770s	
25571/28500 (epoch 44.861), train_loss = 0.87008655, grad/param norm = 2.3172e-01, time/batch = 0.6789s	
25572/28500 (epoch 44.863), train_loss = 0.81742994, grad/param norm = 2.4455e-01, time/batch = 0.6811s	
25573/28500 (epoch 44.865), train_loss = 0.72977928, grad/param norm = 2.0223e-01, time/batch = 0.6771s	
25574/28500 (epoch 44.867), train_loss = 0.80371278, grad/param norm = 2.3423e-01, time/batch = 0.6764s	
25575/28500 (epoch 44.868), train_loss = 0.69070060, grad/param norm = 1.6890e-01, time/batch = 0.6767s	
25576/28500 (epoch 44.870), train_loss = 0.66171667, grad/param norm = 1.7384e-01, time/batch = 0.6813s	
25577/28500 (epoch 44.872), train_loss = 0.84448596, grad/param norm = 2.4305e-01, time/batch = 0.6783s	
25578/28500 (epoch 44.874), train_loss = 0.70640534, grad/param norm = 2.6369e-01, time/batch = 0.6759s	
25579/28500 (epoch 44.875), train_loss = 0.93172300, grad/param norm = 2.5829e-01, time/batch = 0.6766s	
25580/28500 (epoch 44.877), train_loss = 0.81771956, grad/param norm = 2.1157e-01, time/batch = 0.6771s	
25581/28500 (epoch 44.879), train_loss = 0.81827819, grad/param norm = 1.6977e-01, time/batch = 0.6788s	
25582/28500 (epoch 44.881), train_loss = 0.81142769, grad/param norm = 2.0939e-01, time/batch = 0.6778s	
25583/28500 (epoch 44.882), train_loss = 0.71328322, grad/param norm = 1.9712e-01, time/batch = 0.6796s	
25584/28500 (epoch 44.884), train_loss = 0.72755584, grad/param norm = 1.9809e-01, time/batch = 0.6792s	
25585/28500 (epoch 44.886), train_loss = 0.71912129, grad/param norm = 1.8234e-01, time/batch = 0.6777s	
25586/28500 (epoch 44.888), train_loss = 0.74910334, grad/param norm = 1.7304e-01, time/batch = 0.6813s	
25587/28500 (epoch 44.889), train_loss = 0.80454180, grad/param norm = 1.8123e-01, time/batch = 0.6785s	
25588/28500 (epoch 44.891), train_loss = 0.77520793, grad/param norm = 1.7868e-01, time/batch = 0.6765s	
25589/28500 (epoch 44.893), train_loss = 0.74184641, grad/param norm = 2.2381e-01, time/batch = 0.6765s	
25590/28500 (epoch 44.895), train_loss = 0.92370850, grad/param norm = 2.7017e-01, time/batch = 0.6767s	
25591/28500 (epoch 44.896), train_loss = 0.90135933, grad/param norm = 2.6718e-01, time/batch = 0.6819s	
25592/28500 (epoch 44.898), train_loss = 0.84930112, grad/param norm = 2.0813e-01, time/batch = 0.6854s	
25593/28500 (epoch 44.900), train_loss = 0.69260055, grad/param norm = 1.8860e-01, time/batch = 0.6788s	
25594/28500 (epoch 44.902), train_loss = 0.65970826, grad/param norm = 1.8077e-01, time/batch = 0.6772s	
25595/28500 (epoch 44.904), train_loss = 0.70378956, grad/param norm = 1.9180e-01, time/batch = 0.6763s	
25596/28500 (epoch 44.905), train_loss = 0.74443439, grad/param norm = 2.0701e-01, time/batch = 0.6761s	
25597/28500 (epoch 44.907), train_loss = 0.75632143, grad/param norm = 1.9818e-01, time/batch = 0.6767s	
25598/28500 (epoch 44.909), train_loss = 0.64688715, grad/param norm = 2.2573e-01, time/batch = 0.6768s	
25599/28500 (epoch 44.911), train_loss = 0.68523149, grad/param norm = 1.6665e-01, time/batch = 0.6782s	
25600/28500 (epoch 44.912), train_loss = 0.57236886, grad/param norm = 1.6166e-01, time/batch = 0.6784s	
25601/28500 (epoch 44.914), train_loss = 0.78423965, grad/param norm = 1.7325e-01, time/batch = 0.6797s	
25602/28500 (epoch 44.916), train_loss = 0.77515368, grad/param norm = 1.8771e-01, time/batch = 0.6773s	
25603/28500 (epoch 44.918), train_loss = 0.76307094, grad/param norm = 2.3569e-01, time/batch = 0.6767s	
25604/28500 (epoch 44.919), train_loss = 0.79684981, grad/param norm = 1.9956e-01, time/batch = 0.6770s	
25605/28500 (epoch 44.921), train_loss = 0.86705164, grad/param norm = 2.3539e-01, time/batch = 0.6763s	
25606/28500 (epoch 44.923), train_loss = 0.72097401, grad/param norm = 2.3732e-01, time/batch = 0.6762s	
25607/28500 (epoch 44.925), train_loss = 0.72075605, grad/param norm = 2.3175e-01, time/batch = 0.6762s	
25608/28500 (epoch 44.926), train_loss = 0.78287730, grad/param norm = 1.9251e-01, time/batch = 0.6779s	
25609/28500 (epoch 44.928), train_loss = 0.72580085, grad/param norm = 1.8266e-01, time/batch = 0.6763s	
25610/28500 (epoch 44.930), train_loss = 0.62900723, grad/param norm = 1.7026e-01, time/batch = 0.6758s	
25611/28500 (epoch 44.932), train_loss = 0.64505979, grad/param norm = 1.7220e-01, time/batch = 0.6790s	
25612/28500 (epoch 44.933), train_loss = 0.83426170, grad/param norm = 1.9267e-01, time/batch = 0.6770s	
25613/28500 (epoch 44.935), train_loss = 0.84802093, grad/param norm = 1.7693e-01, time/batch = 0.6773s	
25614/28500 (epoch 44.937), train_loss = 0.81343572, grad/param norm = 2.1303e-01, time/batch = 0.6776s	
25615/28500 (epoch 44.939), train_loss = 0.89080825, grad/param norm = 2.1472e-01, time/batch = 0.6924s	
25616/28500 (epoch 44.940), train_loss = 0.61805799, grad/param norm = 1.6520e-01, time/batch = 0.6830s	
25617/28500 (epoch 44.942), train_loss = 0.77195869, grad/param norm = 2.1233e-01, time/batch = 0.6814s	
25618/28500 (epoch 44.944), train_loss = 0.74084861, grad/param norm = 1.8991e-01, time/batch = 0.6787s	
25619/28500 (epoch 44.946), train_loss = 0.81431119, grad/param norm = 1.9207e-01, time/batch = 0.6772s	
25620/28500 (epoch 44.947), train_loss = 0.96639620, grad/param norm = 2.4838e-01, time/batch = 0.6857s	
25621/28500 (epoch 44.949), train_loss = 0.75749331, grad/param norm = 2.1503e-01, time/batch = 0.6792s	
25622/28500 (epoch 44.951), train_loss = 0.92434527, grad/param norm = 1.9133e-01, time/batch = 0.6772s	
25623/28500 (epoch 44.953), train_loss = 0.92543460, grad/param norm = 2.0754e-01, time/batch = 0.6768s	
25624/28500 (epoch 44.954), train_loss = 0.85423874, grad/param norm = 2.1902e-01, time/batch = 0.6848s	
25625/28500 (epoch 44.956), train_loss = 0.78770285, grad/param norm = 3.2815e-01, time/batch = 0.6801s	
25626/28500 (epoch 44.958), train_loss = 1.01087422, grad/param norm = 2.1521e-01, time/batch = 0.6810s	
25627/28500 (epoch 44.960), train_loss = 0.73435127, grad/param norm = 2.3377e-01, time/batch = 0.6783s	
25628/28500 (epoch 44.961), train_loss = 0.92790635, grad/param norm = 2.3841e-01, time/batch = 0.6804s	
25629/28500 (epoch 44.963), train_loss = 0.85966872, grad/param norm = 2.3270e-01, time/batch = 0.6786s	
25630/28500 (epoch 44.965), train_loss = 0.71550382, grad/param norm = 1.8496e-01, time/batch = 0.6794s	
25631/28500 (epoch 44.967), train_loss = 0.74713150, grad/param norm = 2.0116e-01, time/batch = 0.6800s	
25632/28500 (epoch 44.968), train_loss = 0.68969812, grad/param norm = 1.7204e-01, time/batch = 0.6800s	
25633/28500 (epoch 44.970), train_loss = 0.70535675, grad/param norm = 2.1454e-01, time/batch = 0.6802s	
25634/28500 (epoch 44.972), train_loss = 0.77072258, grad/param norm = 1.8169e-01, time/batch = 0.6769s	
25635/28500 (epoch 44.974), train_loss = 0.99443173, grad/param norm = 2.8801e-01, time/batch = 0.6783s	
25636/28500 (epoch 44.975), train_loss = 0.73314159, grad/param norm = 2.2238e-01, time/batch = 0.6775s	
25637/28500 (epoch 44.977), train_loss = 0.88722273, grad/param norm = 2.5591e-01, time/batch = 0.6759s	
25638/28500 (epoch 44.979), train_loss = 0.82463257, grad/param norm = 2.1382e-01, time/batch = 0.6754s	
25639/28500 (epoch 44.981), train_loss = 0.67257870, grad/param norm = 2.0682e-01, time/batch = 0.6762s	
25640/28500 (epoch 44.982), train_loss = 0.76700070, grad/param norm = 1.9573e-01, time/batch = 0.6759s	
25641/28500 (epoch 44.984), train_loss = 0.85107733, grad/param norm = 1.9298e-01, time/batch = 0.6779s	
25642/28500 (epoch 44.986), train_loss = 0.99808416, grad/param norm = 2.2809e-01, time/batch = 0.6771s	
25643/28500 (epoch 44.988), train_loss = 0.70612696, grad/param norm = 1.9640e-01, time/batch = 0.6776s	
25644/28500 (epoch 44.989), train_loss = 0.78752596, grad/param norm = 2.2905e-01, time/batch = 0.6780s	
25645/28500 (epoch 44.991), train_loss = 0.69794284, grad/param norm = 1.8535e-01, time/batch = 0.6793s	
25646/28500 (epoch 44.993), train_loss = 0.71108538, grad/param norm = 1.9925e-01, time/batch = 0.6894s	
25647/28500 (epoch 44.995), train_loss = 0.74964655, grad/param norm = 2.0861e-01, time/batch = 0.7023s	
25648/28500 (epoch 44.996), train_loss = 0.67950870, grad/param norm = 2.0404e-01, time/batch = 0.6927s	
25649/28500 (epoch 44.998), train_loss = 0.89247166, grad/param norm = 3.0118e-01, time/batch = 0.6789s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
25650/28500 (epoch 45.000), train_loss = 0.76373280, grad/param norm = 1.9381e-01, time/batch = 0.6849s	
25651/28500 (epoch 45.002), train_loss = 0.92703274, grad/param norm = 2.0292e-01, time/batch = 0.6850s	
25652/28500 (epoch 45.004), train_loss = 0.79375483, grad/param norm = 1.8956e-01, time/batch = 0.6868s	
25653/28500 (epoch 45.005), train_loss = 0.88097602, grad/param norm = 2.0766e-01, time/batch = 0.6827s	
25654/28500 (epoch 45.007), train_loss = 0.70884678, grad/param norm = 1.8610e-01, time/batch = 0.6829s	
25655/28500 (epoch 45.009), train_loss = 0.79228860, grad/param norm = 1.8242e-01, time/batch = 0.6823s	
25656/28500 (epoch 45.011), train_loss = 0.71621097, grad/param norm = 1.7155e-01, time/batch = 0.6890s	
25657/28500 (epoch 45.012), train_loss = 0.73103649, grad/param norm = 1.9927e-01, time/batch = 0.6800s	
25658/28500 (epoch 45.014), train_loss = 0.69884688, grad/param norm = 1.8860e-01, time/batch = 0.6859s	
25659/28500 (epoch 45.016), train_loss = 0.75781855, grad/param norm = 1.8232e-01, time/batch = 0.6819s	
25660/28500 (epoch 45.018), train_loss = 0.79752314, grad/param norm = 2.0794e-01, time/batch = 0.6867s	
25661/28500 (epoch 45.019), train_loss = 0.88075989, grad/param norm = 2.3361e-01, time/batch = 0.6819s	
25662/28500 (epoch 45.021), train_loss = 0.88295885, grad/param norm = 1.7691e-01, time/batch = 0.6792s	
25663/28500 (epoch 45.023), train_loss = 0.79140743, grad/param norm = 1.8363e-01, time/batch = 0.6765s	
25664/28500 (epoch 45.025), train_loss = 0.82513696, grad/param norm = 1.8666e-01, time/batch = 0.6781s	
25665/28500 (epoch 45.026), train_loss = 0.73057546, grad/param norm = 1.9395e-01, time/batch = 0.6772s	
25666/28500 (epoch 45.028), train_loss = 0.79191814, grad/param norm = 2.0403e-01, time/batch = 0.6816s	
25667/28500 (epoch 45.030), train_loss = 0.81240370, grad/param norm = 2.1621e-01, time/batch = 0.6766s	
25668/28500 (epoch 45.032), train_loss = 0.89490098, grad/param norm = 1.8742e-01, time/batch = 0.6792s	
25669/28500 (epoch 45.033), train_loss = 0.92509796, grad/param norm = 1.8470e-01, time/batch = 0.6799s	
25670/28500 (epoch 45.035), train_loss = 0.77121747, grad/param norm = 2.0813e-01, time/batch = 0.6758s	
25671/28500 (epoch 45.037), train_loss = 0.85641776, grad/param norm = 2.1272e-01, time/batch = 0.6805s	
25672/28500 (epoch 45.039), train_loss = 0.89518633, grad/param norm = 2.0929e-01, time/batch = 0.6782s	
25673/28500 (epoch 45.040), train_loss = 0.90050856, grad/param norm = 1.9372e-01, time/batch = 0.6778s	
25674/28500 (epoch 45.042), train_loss = 0.87020464, grad/param norm = 1.8902e-01, time/batch = 0.6762s	
25675/28500 (epoch 45.044), train_loss = 0.78292259, grad/param norm = 2.0769e-01, time/batch = 0.6765s	
25676/28500 (epoch 45.046), train_loss = 0.99686358, grad/param norm = 2.3587e-01, time/batch = 0.6794s	
25677/28500 (epoch 45.047), train_loss = 0.91328382, grad/param norm = 2.1581e-01, time/batch = 0.6770s	
25678/28500 (epoch 45.049), train_loss = 0.82326598, grad/param norm = 2.0704e-01, time/batch = 0.6756s	
25679/28500 (epoch 45.051), train_loss = 0.80033649, grad/param norm = 2.0653e-01, time/batch = 0.6759s	
25680/28500 (epoch 45.053), train_loss = 0.76347932, grad/param norm = 1.8748e-01, time/batch = 0.6764s	
25681/28500 (epoch 45.054), train_loss = 0.86069213, grad/param norm = 1.9117e-01, time/batch = 0.6789s	
25682/28500 (epoch 45.056), train_loss = 0.75688002, grad/param norm = 1.8797e-01, time/batch = 0.6866s	
25683/28500 (epoch 45.058), train_loss = 0.74361309, grad/param norm = 1.9844e-01, time/batch = 0.6955s	
25684/28500 (epoch 45.060), train_loss = 0.85704752, grad/param norm = 2.0527e-01, time/batch = 0.6782s	
25685/28500 (epoch 45.061), train_loss = 0.76701814, grad/param norm = 1.8974e-01, time/batch = 0.6807s	
25686/28500 (epoch 45.063), train_loss = 0.82988409, grad/param norm = 1.9269e-01, time/batch = 0.6785s	
25687/28500 (epoch 45.065), train_loss = 0.80760567, grad/param norm = 1.9650e-01, time/batch = 0.6850s	
25688/28500 (epoch 45.067), train_loss = 0.74511877, grad/param norm = 1.8187e-01, time/batch = 0.6861s	
25689/28500 (epoch 45.068), train_loss = 0.78915559, grad/param norm = 2.1166e-01, time/batch = 0.6759s	
25690/28500 (epoch 45.070), train_loss = 0.83230990, grad/param norm = 2.2862e-01, time/batch = 0.6792s	
25691/28500 (epoch 45.072), train_loss = 0.92350236, grad/param norm = 2.2656e-01, time/batch = 0.6807s	
25692/28500 (epoch 45.074), train_loss = 0.79119632, grad/param norm = 2.0025e-01, time/batch = 0.6774s	
25693/28500 (epoch 45.075), train_loss = 0.79552760, grad/param norm = 1.7923e-01, time/batch = 0.6821s	
25694/28500 (epoch 45.077), train_loss = 0.83874118, grad/param norm = 1.7441e-01, time/batch = 0.6778s	
25695/28500 (epoch 45.079), train_loss = 0.81925024, grad/param norm = 1.8272e-01, time/batch = 0.6758s	
25696/28500 (epoch 45.081), train_loss = 0.87513371, grad/param norm = 2.2476e-01, time/batch = 0.6774s	
25697/28500 (epoch 45.082), train_loss = 0.76402716, grad/param norm = 2.6600e-01, time/batch = 0.6773s	
25698/28500 (epoch 45.084), train_loss = 0.79770611, grad/param norm = 2.0330e-01, time/batch = 0.6783s	
25699/28500 (epoch 45.086), train_loss = 0.75903187, grad/param norm = 2.9608e-01, time/batch = 0.6803s	
25700/28500 (epoch 45.088), train_loss = 0.71367758, grad/param norm = 1.9269e-01, time/batch = 0.6814s	
25701/28500 (epoch 45.089), train_loss = 0.85213302, grad/param norm = 1.9626e-01, time/batch = 0.6819s	
25702/28500 (epoch 45.091), train_loss = 0.71319164, grad/param norm = 1.7736e-01, time/batch = 0.6849s	
25703/28500 (epoch 45.093), train_loss = 0.88389207, grad/param norm = 2.0674e-01, time/batch = 0.6808s	
25704/28500 (epoch 45.095), train_loss = 0.80784604, grad/param norm = 1.9019e-01, time/batch = 0.6787s	
25705/28500 (epoch 45.096), train_loss = 0.88265623, grad/param norm = 2.1165e-01, time/batch = 0.6769s	
25706/28500 (epoch 45.098), train_loss = 0.79096903, grad/param norm = 2.2731e-01, time/batch = 0.6819s	
25707/28500 (epoch 45.100), train_loss = 0.77331955, grad/param norm = 1.8385e-01, time/batch = 0.6801s	
25708/28500 (epoch 45.102), train_loss = 0.90819743, grad/param norm = 2.2158e-01, time/batch = 0.6912s	
25709/28500 (epoch 45.104), train_loss = 0.80915197, grad/param norm = 2.1849e-01, time/batch = 0.6901s	
25710/28500 (epoch 45.105), train_loss = 0.88518602, grad/param norm = 1.9534e-01, time/batch = 0.6976s	
25711/28500 (epoch 45.107), train_loss = 0.73574537, grad/param norm = 1.9545e-01, time/batch = 0.7018s	
25712/28500 (epoch 45.109), train_loss = 0.75238064, grad/param norm = 2.0296e-01, time/batch = 0.6808s	
25713/28500 (epoch 45.111), train_loss = 0.79037300, grad/param norm = 2.2085e-01, time/batch = 0.6888s	
25714/28500 (epoch 45.112), train_loss = 0.87808460, grad/param norm = 2.0786e-01, time/batch = 0.6784s	
25715/28500 (epoch 45.114), train_loss = 0.79863744, grad/param norm = 2.0526e-01, time/batch = 0.6835s	
25716/28500 (epoch 45.116), train_loss = 0.93448009, grad/param norm = 2.1405e-01, time/batch = 0.6903s	
25717/28500 (epoch 45.118), train_loss = 0.73514879, grad/param norm = 2.3085e-01, time/batch = 0.6813s	
25718/28500 (epoch 45.119), train_loss = 0.83113432, grad/param norm = 2.1426e-01, time/batch = 0.6856s	
25719/28500 (epoch 45.121), train_loss = 0.95905343, grad/param norm = 2.8241e-01, time/batch = 0.6766s	
25720/28500 (epoch 45.123), train_loss = 0.91023152, grad/param norm = 2.1853e-01, time/batch = 0.6774s	
25721/28500 (epoch 45.125), train_loss = 0.82793991, grad/param norm = 1.9138e-01, time/batch = 0.6799s	
25722/28500 (epoch 45.126), train_loss = 0.82081244, grad/param norm = 1.9972e-01, time/batch = 0.6798s	
25723/28500 (epoch 45.128), train_loss = 0.82802094, grad/param norm = 1.9207e-01, time/batch = 0.6781s	
25724/28500 (epoch 45.130), train_loss = 0.78200089, grad/param norm = 2.2816e-01, time/batch = 0.6765s	
25725/28500 (epoch 45.132), train_loss = 0.80171603, grad/param norm = 2.0996e-01, time/batch = 0.6768s	
25726/28500 (epoch 45.133), train_loss = 0.87730457, grad/param norm = 2.4627e-01, time/batch = 0.6788s	
25727/28500 (epoch 45.135), train_loss = 0.76290307, grad/param norm = 1.8044e-01, time/batch = 0.6768s	
25728/28500 (epoch 45.137), train_loss = 0.82126493, grad/param norm = 2.0404e-01, time/batch = 0.6811s	
25729/28500 (epoch 45.139), train_loss = 0.81148902, grad/param norm = 1.7411e-01, time/batch = 0.6825s	
25730/28500 (epoch 45.140), train_loss = 0.80166069, grad/param norm = 2.0058e-01, time/batch = 0.6774s	
25731/28500 (epoch 45.142), train_loss = 0.76435284, grad/param norm = 2.1921e-01, time/batch = 0.6808s	
25732/28500 (epoch 45.144), train_loss = 0.71974379, grad/param norm = 1.8005e-01, time/batch = 0.6857s	
25733/28500 (epoch 45.146), train_loss = 0.77578971, grad/param norm = 1.8575e-01, time/batch = 0.6872s	
25734/28500 (epoch 45.147), train_loss = 0.68631281, grad/param norm = 1.9179e-01, time/batch = 0.6932s	
25735/28500 (epoch 45.149), train_loss = 0.69703363, grad/param norm = 1.8960e-01, time/batch = 0.6894s	
25736/28500 (epoch 45.151), train_loss = 0.75966361, grad/param norm = 1.9760e-01, time/batch = 0.6808s	
25737/28500 (epoch 45.153), train_loss = 0.81839646, grad/param norm = 1.8360e-01, time/batch = 0.6809s	
25738/28500 (epoch 45.154), train_loss = 0.69278381, grad/param norm = 2.0806e-01, time/batch = 0.6803s	
25739/28500 (epoch 45.156), train_loss = 0.85252097, grad/param norm = 2.1681e-01, time/batch = 0.6861s	
25740/28500 (epoch 45.158), train_loss = 0.83189783, grad/param norm = 2.1530e-01, time/batch = 0.6819s	
25741/28500 (epoch 45.160), train_loss = 0.72595559, grad/param norm = 1.6992e-01, time/batch = 0.6836s	
25742/28500 (epoch 45.161), train_loss = 0.73671164, grad/param norm = 2.0901e-01, time/batch = 0.6822s	
25743/28500 (epoch 45.163), train_loss = 0.71059334, grad/param norm = 2.0749e-01, time/batch = 0.6815s	
25744/28500 (epoch 45.165), train_loss = 0.91787521, grad/param norm = 1.8896e-01, time/batch = 0.6820s	
25745/28500 (epoch 45.167), train_loss = 0.92095367, grad/param norm = 2.1720e-01, time/batch = 0.6903s	
25746/28500 (epoch 45.168), train_loss = 0.90086876, grad/param norm = 2.0073e-01, time/batch = 0.6799s	
25747/28500 (epoch 45.170), train_loss = 0.91470094, grad/param norm = 2.4279e-01, time/batch = 0.6798s	
25748/28500 (epoch 45.172), train_loss = 0.76493306, grad/param norm = 1.5811e-01, time/batch = 0.6792s	
25749/28500 (epoch 45.174), train_loss = 0.92854970, grad/param norm = 2.2376e-01, time/batch = 0.6796s	
25750/28500 (epoch 45.175), train_loss = 0.78012203, grad/param norm = 1.8097e-01, time/batch = 0.6812s	
25751/28500 (epoch 45.177), train_loss = 0.81769319, grad/param norm = 1.9539e-01, time/batch = 0.6834s	
25752/28500 (epoch 45.179), train_loss = 0.88188762, grad/param norm = 2.3937e-01, time/batch = 0.6808s	
25753/28500 (epoch 45.181), train_loss = 0.81973038, grad/param norm = 2.2515e-01, time/batch = 0.6806s	
25754/28500 (epoch 45.182), train_loss = 0.76007959, grad/param norm = 2.1054e-01, time/batch = 0.6826s	
25755/28500 (epoch 45.184), train_loss = 0.96792297, grad/param norm = 2.1297e-01, time/batch = 0.6794s	
25756/28500 (epoch 45.186), train_loss = 0.94199358, grad/param norm = 2.2601e-01, time/batch = 0.6795s	
25757/28500 (epoch 45.188), train_loss = 0.87583767, grad/param norm = 2.1349e-01, time/batch = 0.6784s	
25758/28500 (epoch 45.189), train_loss = 0.80670707, grad/param norm = 1.6792e-01, time/batch = 0.6798s	
25759/28500 (epoch 45.191), train_loss = 0.96508051, grad/param norm = 2.2909e-01, time/batch = 0.6795s	
25760/28500 (epoch 45.193), train_loss = 0.78961590, grad/param norm = 2.0774e-01, time/batch = 0.6814s	
25761/28500 (epoch 45.195), train_loss = 0.94033584, grad/param norm = 2.1185e-01, time/batch = 0.6807s	
25762/28500 (epoch 45.196), train_loss = 0.83827013, grad/param norm = 2.0514e-01, time/batch = 0.6816s	
25763/28500 (epoch 45.198), train_loss = 0.83124880, grad/param norm = 2.0144e-01, time/batch = 0.6794s	
25764/28500 (epoch 45.200), train_loss = 0.89375317, grad/param norm = 2.1567e-01, time/batch = 0.6802s	
25765/28500 (epoch 45.202), train_loss = 0.85264299, grad/param norm = 2.0846e-01, time/batch = 0.6805s	
25766/28500 (epoch 45.204), train_loss = 0.80049839, grad/param norm = 1.8658e-01, time/batch = 0.6818s	
25767/28500 (epoch 45.205), train_loss = 0.76263980, grad/param norm = 2.1376e-01, time/batch = 0.6812s	
25768/28500 (epoch 45.207), train_loss = 0.68531532, grad/param norm = 1.9642e-01, time/batch = 0.6796s	
25769/28500 (epoch 45.209), train_loss = 0.82116893, grad/param norm = 2.1061e-01, time/batch = 0.6798s	
25770/28500 (epoch 45.211), train_loss = 0.74621165, grad/param norm = 1.8903e-01, time/batch = 0.6805s	
25771/28500 (epoch 45.212), train_loss = 0.68275741, grad/param norm = 2.0138e-01, time/batch = 0.6857s	
25772/28500 (epoch 45.214), train_loss = 0.80820159, grad/param norm = 2.3730e-01, time/batch = 0.6848s	
25773/28500 (epoch 45.216), train_loss = 0.73765565, grad/param norm = 1.9888e-01, time/batch = 0.6843s	
25774/28500 (epoch 45.218), train_loss = 0.91972297, grad/param norm = 1.9352e-01, time/batch = 0.6797s	
25775/28500 (epoch 45.219), train_loss = 0.83797054, grad/param norm = 1.9964e-01, time/batch = 0.6785s	
25776/28500 (epoch 45.221), train_loss = 0.70781641, grad/param norm = 1.8996e-01, time/batch = 0.6775s	
25777/28500 (epoch 45.223), train_loss = 0.90254386, grad/param norm = 2.2844e-01, time/batch = 0.6760s	
25778/28500 (epoch 45.225), train_loss = 0.93673953, grad/param norm = 2.2740e-01, time/batch = 0.6759s	
25779/28500 (epoch 45.226), train_loss = 0.77636871, grad/param norm = 1.8394e-01, time/batch = 0.6770s	
25780/28500 (epoch 45.228), train_loss = 0.91855641, grad/param norm = 2.4413e-01, time/batch = 0.6763s	
25781/28500 (epoch 45.230), train_loss = 0.88610785, grad/param norm = 2.2344e-01, time/batch = 0.6786s	
25782/28500 (epoch 45.232), train_loss = 0.86514491, grad/param norm = 3.0094e-01, time/batch = 0.6770s	
25783/28500 (epoch 45.233), train_loss = 0.81273815, grad/param norm = 2.2400e-01, time/batch = 0.6774s	
25784/28500 (epoch 45.235), train_loss = 0.82074381, grad/param norm = 2.3549e-01, time/batch = 0.6781s	
25785/28500 (epoch 45.237), train_loss = 0.74374133, grad/param norm = 1.5964e-01, time/batch = 0.6776s	
25786/28500 (epoch 45.239), train_loss = 0.78604585, grad/param norm = 2.0470e-01, time/batch = 0.6765s	
25787/28500 (epoch 45.240), train_loss = 0.70975989, grad/param norm = 2.0156e-01, time/batch = 0.6777s	
25788/28500 (epoch 45.242), train_loss = 0.74382936, grad/param norm = 2.2428e-01, time/batch = 0.6762s	
25789/28500 (epoch 45.244), train_loss = 0.82883205, grad/param norm = 1.7956e-01, time/batch = 0.6761s	
25790/28500 (epoch 45.246), train_loss = 0.83804048, grad/param norm = 1.9165e-01, time/batch = 0.6762s	
25791/28500 (epoch 45.247), train_loss = 0.90563042, grad/param norm = 2.1761e-01, time/batch = 0.6796s	
25792/28500 (epoch 45.249), train_loss = 0.79432970, grad/param norm = 1.8171e-01, time/batch = 0.6770s	
25793/28500 (epoch 45.251), train_loss = 0.79917629, grad/param norm = 1.7888e-01, time/batch = 0.6783s	
25794/28500 (epoch 45.253), train_loss = 0.92751429, grad/param norm = 2.3194e-01, time/batch = 0.6775s	
25795/28500 (epoch 45.254), train_loss = 0.94278997, grad/param norm = 1.8352e-01, time/batch = 0.6763s	
25796/28500 (epoch 45.256), train_loss = 0.80143925, grad/param norm = 2.1169e-01, time/batch = 0.6763s	
25797/28500 (epoch 45.258), train_loss = 0.79982876, grad/param norm = 1.7868e-01, time/batch = 0.6764s	
25798/28500 (epoch 45.260), train_loss = 0.80120149, grad/param norm = 1.7982e-01, time/batch = 0.6770s	
25799/28500 (epoch 45.261), train_loss = 0.70662106, grad/param norm = 1.9283e-01, time/batch = 0.6778s	
25800/28500 (epoch 45.263), train_loss = 0.85800198, grad/param norm = 2.1519e-01, time/batch = 0.6786s	
25801/28500 (epoch 45.265), train_loss = 0.74603800, grad/param norm = 1.9491e-01, time/batch = 0.6799s	
25802/28500 (epoch 45.267), train_loss = 0.95789042, grad/param norm = 2.1774e-01, time/batch = 0.6773s	
25803/28500 (epoch 45.268), train_loss = 0.82709297, grad/param norm = 1.7345e-01, time/batch = 0.6774s	
25804/28500 (epoch 45.270), train_loss = 0.80141498, grad/param norm = 1.9950e-01, time/batch = 0.6772s	
25805/28500 (epoch 45.272), train_loss = 0.80913189, grad/param norm = 1.7242e-01, time/batch = 0.6778s	
25806/28500 (epoch 45.274), train_loss = 0.85643837, grad/param norm = 2.0056e-01, time/batch = 0.6773s	
25807/28500 (epoch 45.275), train_loss = 0.88095792, grad/param norm = 1.8944e-01, time/batch = 0.6770s	
25808/28500 (epoch 45.277), train_loss = 0.81874323, grad/param norm = 2.1752e-01, time/batch = 0.6762s	
25809/28500 (epoch 45.279), train_loss = 0.85467380, grad/param norm = 2.2791e-01, time/batch = 0.6764s	
25810/28500 (epoch 45.281), train_loss = 0.85693636, grad/param norm = 2.4467e-01, time/batch = 0.6802s	
25811/28500 (epoch 45.282), train_loss = 0.83861355, grad/param norm = 1.9045e-01, time/batch = 0.6791s	
25812/28500 (epoch 45.284), train_loss = 0.84353949, grad/param norm = 2.2571e-01, time/batch = 0.6773s	
25813/28500 (epoch 45.286), train_loss = 0.90499878, grad/param norm = 1.9404e-01, time/batch = 0.6785s	
25814/28500 (epoch 45.288), train_loss = 0.79672620, grad/param norm = 1.9860e-01, time/batch = 0.6769s	
25815/28500 (epoch 45.289), train_loss = 0.81659045, grad/param norm = 1.9429e-01, time/batch = 0.6774s	
25816/28500 (epoch 45.291), train_loss = 0.82750720, grad/param norm = 1.7271e-01, time/batch = 0.6772s	
25817/28500 (epoch 45.293), train_loss = 0.81698056, grad/param norm = 1.8976e-01, time/batch = 0.6789s	
25818/28500 (epoch 45.295), train_loss = 0.71618305, grad/param norm = 1.8182e-01, time/batch = 0.6787s	
25819/28500 (epoch 45.296), train_loss = 0.71273303, grad/param norm = 1.9648e-01, time/batch = 0.6777s	
25820/28500 (epoch 45.298), train_loss = 0.86944383, grad/param norm = 1.9393e-01, time/batch = 0.6806s	
25821/28500 (epoch 45.300), train_loss = 0.74032303, grad/param norm = 1.9239e-01, time/batch = 0.6921s	
25822/28500 (epoch 45.302), train_loss = 0.70603146, grad/param norm = 1.9139e-01, time/batch = 0.6800s	
25823/28500 (epoch 45.304), train_loss = 0.79033625, grad/param norm = 1.7905e-01, time/batch = 0.6768s	
25824/28500 (epoch 45.305), train_loss = 0.85743252, grad/param norm = 1.9818e-01, time/batch = 0.6763s	
25825/28500 (epoch 45.307), train_loss = 0.79352719, grad/param norm = 2.3796e-01, time/batch = 0.6762s	
25826/28500 (epoch 45.309), train_loss = 0.79657966, grad/param norm = 2.1996e-01, time/batch = 0.6804s	
25827/28500 (epoch 45.311), train_loss = 0.84930860, grad/param norm = 2.2224e-01, time/batch = 0.6816s	
25828/28500 (epoch 45.312), train_loss = 0.84949961, grad/param norm = 1.9065e-01, time/batch = 0.6864s	
25829/28500 (epoch 45.314), train_loss = 0.82268121, grad/param norm = 1.8695e-01, time/batch = 0.6765s	
25830/28500 (epoch 45.316), train_loss = 0.82972538, grad/param norm = 2.0843e-01, time/batch = 0.6764s	
25831/28500 (epoch 45.318), train_loss = 0.87916622, grad/param norm = 1.8488e-01, time/batch = 0.6782s	
25832/28500 (epoch 45.319), train_loss = 0.77085410, grad/param norm = 2.7217e-01, time/batch = 0.6809s	
25833/28500 (epoch 45.321), train_loss = 0.78404591, grad/param norm = 2.2525e-01, time/batch = 0.6772s	
25834/28500 (epoch 45.323), train_loss = 0.81542826, grad/param norm = 1.9580e-01, time/batch = 0.6778s	
25835/28500 (epoch 45.325), train_loss = 0.91890475, grad/param norm = 2.1156e-01, time/batch = 0.6773s	
25836/28500 (epoch 45.326), train_loss = 0.83788726, grad/param norm = 1.9483e-01, time/batch = 0.6777s	
25837/28500 (epoch 45.328), train_loss = 0.65671432, grad/param norm = 1.6202e-01, time/batch = 0.6760s	
25838/28500 (epoch 45.330), train_loss = 0.75789636, grad/param norm = 1.9367e-01, time/batch = 0.6760s	
25839/28500 (epoch 45.332), train_loss = 0.74170849, grad/param norm = 1.6950e-01, time/batch = 0.6758s	
25840/28500 (epoch 45.333), train_loss = 0.63030719, grad/param norm = 1.9951e-01, time/batch = 0.6762s	
25841/28500 (epoch 45.335), train_loss = 0.71313429, grad/param norm = 1.8332e-01, time/batch = 0.6793s	
25842/28500 (epoch 45.337), train_loss = 0.64751692, grad/param norm = 1.6449e-01, time/batch = 0.6765s	
25843/28500 (epoch 45.339), train_loss = 0.65152646, grad/param norm = 1.4950e-01, time/batch = 0.6761s	
25844/28500 (epoch 45.340), train_loss = 0.80179424, grad/param norm = 2.2022e-01, time/batch = 0.6754s	
25845/28500 (epoch 45.342), train_loss = 0.79237508, grad/param norm = 1.8250e-01, time/batch = 0.6751s	
25846/28500 (epoch 45.344), train_loss = 0.67755067, grad/param norm = 1.9553e-01, time/batch = 0.6756s	
25847/28500 (epoch 45.346), train_loss = 0.67948619, grad/param norm = 1.5914e-01, time/batch = 0.6758s	
25848/28500 (epoch 45.347), train_loss = 0.79468151, grad/param norm = 1.6711e-01, time/batch = 0.6755s	
25849/28500 (epoch 45.349), train_loss = 0.80322431, grad/param norm = 1.9702e-01, time/batch = 0.6758s	
25850/28500 (epoch 45.351), train_loss = 0.71700226, grad/param norm = 1.9866e-01, time/batch = 0.6755s	
25851/28500 (epoch 45.353), train_loss = 0.82056910, grad/param norm = 1.9991e-01, time/batch = 0.6793s	
25852/28500 (epoch 45.354), train_loss = 0.68420668, grad/param norm = 1.8053e-01, time/batch = 0.6778s	
25853/28500 (epoch 45.356), train_loss = 0.73919537, grad/param norm = 1.6733e-01, time/batch = 0.6767s	
25854/28500 (epoch 45.358), train_loss = 0.83054715, grad/param norm = 1.8079e-01, time/batch = 0.6766s	
25855/28500 (epoch 45.360), train_loss = 0.79471419, grad/param norm = 1.9917e-01, time/batch = 0.6790s	
25856/28500 (epoch 45.361), train_loss = 0.71099043, grad/param norm = 1.7679e-01, time/batch = 0.6760s	
25857/28500 (epoch 45.363), train_loss = 0.68192346, grad/param norm = 1.5458e-01, time/batch = 0.6756s	
25858/28500 (epoch 45.365), train_loss = 0.74023611, grad/param norm = 1.8800e-01, time/batch = 0.6754s	
25859/28500 (epoch 45.367), train_loss = 0.77989816, grad/param norm = 2.0186e-01, time/batch = 0.6757s	
25860/28500 (epoch 45.368), train_loss = 0.72667603, grad/param norm = 1.8819e-01, time/batch = 0.6757s	
25861/28500 (epoch 45.370), train_loss = 0.80318176, grad/param norm = 1.8586e-01, time/batch = 0.6805s	
25862/28500 (epoch 45.372), train_loss = 0.63747109, grad/param norm = 1.7884e-01, time/batch = 0.6941s	
25863/28500 (epoch 45.374), train_loss = 0.76053098, grad/param norm = 2.1127e-01, time/batch = 0.6770s	
25864/28500 (epoch 45.375), train_loss = 0.88787328, grad/param norm = 2.1658e-01, time/batch = 0.6799s	
25865/28500 (epoch 45.377), train_loss = 0.73236907, grad/param norm = 1.9645e-01, time/batch = 0.6782s	
25866/28500 (epoch 45.379), train_loss = 0.61980130, grad/param norm = 1.6953e-01, time/batch = 0.6763s	
25867/28500 (epoch 45.381), train_loss = 0.75311747, grad/param norm = 1.9280e-01, time/batch = 0.6810s	
25868/28500 (epoch 45.382), train_loss = 0.72957058, grad/param norm = 1.9606e-01, time/batch = 0.6782s	
25869/28500 (epoch 45.384), train_loss = 0.63144800, grad/param norm = 1.7043e-01, time/batch = 0.6787s	
25870/28500 (epoch 45.386), train_loss = 0.69819505, grad/param norm = 1.7327e-01, time/batch = 0.6759s	
25871/28500 (epoch 45.388), train_loss = 0.83671536, grad/param norm = 1.9983e-01, time/batch = 0.6782s	
25872/28500 (epoch 45.389), train_loss = 0.70947092, grad/param norm = 1.9432e-01, time/batch = 0.6766s	
25873/28500 (epoch 45.391), train_loss = 0.68929907, grad/param norm = 2.0131e-01, time/batch = 0.6761s	
25874/28500 (epoch 45.393), train_loss = 0.70059147, grad/param norm = 1.9467e-01, time/batch = 0.6761s	
25875/28500 (epoch 45.395), train_loss = 0.87414578, grad/param norm = 1.8745e-01, time/batch = 0.6758s	
25876/28500 (epoch 45.396), train_loss = 0.86105528, grad/param norm = 2.0375e-01, time/batch = 0.6755s	
25877/28500 (epoch 45.398), train_loss = 0.58807387, grad/param norm = 2.0278e-01, time/batch = 0.6760s	
25878/28500 (epoch 45.400), train_loss = 0.73629554, grad/param norm = 1.8916e-01, time/batch = 0.6759s	
25879/28500 (epoch 45.402), train_loss = 0.78456321, grad/param norm = 1.8636e-01, time/batch = 0.6762s	
25880/28500 (epoch 45.404), train_loss = 0.77964309, grad/param norm = 2.0503e-01, time/batch = 0.6767s	
25881/28500 (epoch 45.405), train_loss = 0.84837449, grad/param norm = 1.9416e-01, time/batch = 0.6843s	
25882/28500 (epoch 45.407), train_loss = 0.78129638, grad/param norm = 1.8649e-01, time/batch = 0.6814s	
25883/28500 (epoch 45.409), train_loss = 0.76848893, grad/param norm = 1.8514e-01, time/batch = 0.6799s	
25884/28500 (epoch 45.411), train_loss = 0.86446513, grad/param norm = 2.0420e-01, time/batch = 0.6809s	
25885/28500 (epoch 45.412), train_loss = 0.89600137, grad/param norm = 2.4824e-01, time/batch = 0.6813s	
25886/28500 (epoch 45.414), train_loss = 0.80998626, grad/param norm = 2.2876e-01, time/batch = 0.6848s	
25887/28500 (epoch 45.416), train_loss = 0.71336775, grad/param norm = 2.2381e-01, time/batch = 0.6809s	
25888/28500 (epoch 45.418), train_loss = 0.80945209, grad/param norm = 1.7649e-01, time/batch = 0.6822s	
25889/28500 (epoch 45.419), train_loss = 0.90207496, grad/param norm = 2.1663e-01, time/batch = 0.6815s	
25890/28500 (epoch 45.421), train_loss = 0.84748067, grad/param norm = 1.9441e-01, time/batch = 0.6805s	
25891/28500 (epoch 45.423), train_loss = 0.84747292, grad/param norm = 2.0615e-01, time/batch = 0.6829s	
25892/28500 (epoch 45.425), train_loss = 0.76814897, grad/param norm = 2.7876e-01, time/batch = 0.6815s	
25893/28500 (epoch 45.426), train_loss = 0.79334058, grad/param norm = 2.2303e-01, time/batch = 0.6823s	
25894/28500 (epoch 45.428), train_loss = 0.95489045, grad/param norm = 2.4256e-01, time/batch = 0.6860s	
25895/28500 (epoch 45.430), train_loss = 0.92305688, grad/param norm = 1.8502e-01, time/batch = 0.6805s	
25896/28500 (epoch 45.432), train_loss = 0.81781866, grad/param norm = 1.8911e-01, time/batch = 0.6801s	
25897/28500 (epoch 45.433), train_loss = 0.86344211, grad/param norm = 2.1194e-01, time/batch = 0.6795s	
25898/28500 (epoch 45.435), train_loss = 0.81931000, grad/param norm = 1.9729e-01, time/batch = 0.6801s	
25899/28500 (epoch 45.437), train_loss = 0.75553138, grad/param norm = 1.7891e-01, time/batch = 0.6804s	
25900/28500 (epoch 45.439), train_loss = 0.79371728, grad/param norm = 1.8091e-01, time/batch = 0.6808s	
25901/28500 (epoch 45.440), train_loss = 0.95366318, grad/param norm = 2.1850e-01, time/batch = 0.6800s	
25902/28500 (epoch 45.442), train_loss = 0.74631751, grad/param norm = 2.3255e-01, time/batch = 0.6781s	
25903/28500 (epoch 45.444), train_loss = 0.71073596, grad/param norm = 1.6066e-01, time/batch = 0.6766s	
25904/28500 (epoch 45.446), train_loss = 0.67639608, grad/param norm = 1.6502e-01, time/batch = 0.6765s	
25905/28500 (epoch 45.447), train_loss = 0.69055243, grad/param norm = 1.6972e-01, time/batch = 0.6775s	
25906/28500 (epoch 45.449), train_loss = 0.76116338, grad/param norm = 1.9736e-01, time/batch = 0.6778s	
25907/28500 (epoch 45.451), train_loss = 0.78040030, grad/param norm = 2.0827e-01, time/batch = 0.6790s	
25908/28500 (epoch 45.453), train_loss = 0.74273949, grad/param norm = 1.8266e-01, time/batch = 0.6802s	
25909/28500 (epoch 45.454), train_loss = 0.71145741, grad/param norm = 1.5800e-01, time/batch = 0.6807s	
25910/28500 (epoch 45.456), train_loss = 0.84142122, grad/param norm = 2.0504e-01, time/batch = 0.6859s	
25911/28500 (epoch 45.458), train_loss = 0.74909513, grad/param norm = 2.0430e-01, time/batch = 0.6783s	
25912/28500 (epoch 45.460), train_loss = 0.86292151, grad/param norm = 1.8060e-01, time/batch = 0.6775s	
25913/28500 (epoch 45.461), train_loss = 0.70456682, grad/param norm = 2.0417e-01, time/batch = 0.6762s	
25914/28500 (epoch 45.463), train_loss = 0.66135362, grad/param norm = 1.6559e-01, time/batch = 0.6795s	
25915/28500 (epoch 45.465), train_loss = 0.63375646, grad/param norm = 2.0049e-01, time/batch = 0.6798s	
25916/28500 (epoch 45.467), train_loss = 0.78651658, grad/param norm = 1.7993e-01, time/batch = 0.6763s	
25917/28500 (epoch 45.468), train_loss = 0.70655873, grad/param norm = 1.8344e-01, time/batch = 0.6757s	
25918/28500 (epoch 45.470), train_loss = 0.74330667, grad/param norm = 2.1031e-01, time/batch = 0.6827s	
25919/28500 (epoch 45.472), train_loss = 0.70328055, grad/param norm = 1.7104e-01, time/batch = 0.6823s	
25920/28500 (epoch 45.474), train_loss = 0.93142932, grad/param norm = 2.0868e-01, time/batch = 0.6908s	
25921/28500 (epoch 45.475), train_loss = 0.74000395, grad/param norm = 1.7583e-01, time/batch = 0.6850s	
25922/28500 (epoch 45.477), train_loss = 0.78275376, grad/param norm = 2.0169e-01, time/batch = 0.6790s	
25923/28500 (epoch 45.479), train_loss = 0.83298901, grad/param norm = 2.0430e-01, time/batch = 0.6784s	
25924/28500 (epoch 45.481), train_loss = 0.82209515, grad/param norm = 1.9507e-01, time/batch = 0.6774s	
25925/28500 (epoch 45.482), train_loss = 0.67666871, grad/param norm = 1.7727e-01, time/batch = 0.6784s	
25926/28500 (epoch 45.484), train_loss = 0.72161667, grad/param norm = 1.7315e-01, time/batch = 0.6792s	
25927/28500 (epoch 45.486), train_loss = 0.64345139, grad/param norm = 1.7685e-01, time/batch = 0.6791s	
25928/28500 (epoch 45.488), train_loss = 0.80490429, grad/param norm = 1.6736e-01, time/batch = 0.6885s	
25929/28500 (epoch 45.489), train_loss = 0.91074190, grad/param norm = 1.9039e-01, time/batch = 0.6812s	
25930/28500 (epoch 45.491), train_loss = 0.73166741, grad/param norm = 1.9212e-01, time/batch = 0.6837s	
25931/28500 (epoch 45.493), train_loss = 0.76815984, grad/param norm = 1.9592e-01, time/batch = 0.6788s	
25932/28500 (epoch 45.495), train_loss = 0.79009088, grad/param norm = 1.9093e-01, time/batch = 0.6784s	
25933/28500 (epoch 45.496), train_loss = 0.70697654, grad/param norm = 2.1375e-01, time/batch = 0.6847s	
25934/28500 (epoch 45.498), train_loss = 0.75525852, grad/param norm = 1.7290e-01, time/batch = 0.6764s	
25935/28500 (epoch 45.500), train_loss = 0.72637562, grad/param norm = 1.7367e-01, time/batch = 0.6771s	
25936/28500 (epoch 45.502), train_loss = 0.80405089, grad/param norm = 1.6778e-01, time/batch = 0.6791s	
25937/28500 (epoch 45.504), train_loss = 0.84996422, grad/param norm = 1.7977e-01, time/batch = 0.6781s	
25938/28500 (epoch 45.505), train_loss = 0.73054451, grad/param norm = 2.1762e-01, time/batch = 0.6764s	
25939/28500 (epoch 45.507), train_loss = 0.84949790, grad/param norm = 2.1361e-01, time/batch = 0.6761s	
25940/28500 (epoch 45.509), train_loss = 0.76003812, grad/param norm = 1.7244e-01, time/batch = 0.6767s	
25941/28500 (epoch 45.511), train_loss = 0.77472994, grad/param norm = 1.8508e-01, time/batch = 0.6784s	
25942/28500 (epoch 45.512), train_loss = 0.82654317, grad/param norm = 1.9769e-01, time/batch = 0.6767s	
25943/28500 (epoch 45.514), train_loss = 0.75393547, grad/param norm = 1.7202e-01, time/batch = 0.6761s	
25944/28500 (epoch 45.516), train_loss = 0.79141776, grad/param norm = 1.7917e-01, time/batch = 0.6765s	
25945/28500 (epoch 45.518), train_loss = 0.83039606, grad/param norm = 2.2852e-01, time/batch = 0.6765s	
25946/28500 (epoch 45.519), train_loss = 0.80594349, grad/param norm = 1.7657e-01, time/batch = 0.6765s	
25947/28500 (epoch 45.521), train_loss = 0.89695356, grad/param norm = 2.4339e-01, time/batch = 0.6760s	
25948/28500 (epoch 45.523), train_loss = 0.83185146, grad/param norm = 2.1892e-01, time/batch = 0.6798s	
25949/28500 (epoch 45.525), train_loss = 0.88336443, grad/param norm = 1.9128e-01, time/batch = 0.6772s	
25950/28500 (epoch 45.526), train_loss = 0.82941357, grad/param norm = 1.9060e-01, time/batch = 0.6766s	
25951/28500 (epoch 45.528), train_loss = 0.83155165, grad/param norm = 2.3986e-01, time/batch = 0.6920s	
25952/28500 (epoch 45.530), train_loss = 0.81665999, grad/param norm = 1.8293e-01, time/batch = 0.6794s	
25953/28500 (epoch 45.532), train_loss = 0.78221060, grad/param norm = 2.0014e-01, time/batch = 0.6827s	
25954/28500 (epoch 45.533), train_loss = 0.81949248, grad/param norm = 1.8459e-01, time/batch = 0.6805s	
25955/28500 (epoch 45.535), train_loss = 0.69966621, grad/param norm = 1.8585e-01, time/batch = 0.6791s	
25956/28500 (epoch 45.537), train_loss = 0.68046744, grad/param norm = 1.8310e-01, time/batch = 0.6773s	
25957/28500 (epoch 45.539), train_loss = 0.66781784, grad/param norm = 1.7362e-01, time/batch = 0.6792s	
25958/28500 (epoch 45.540), train_loss = 0.75495801, grad/param norm = 1.7547e-01, time/batch = 0.6782s	
25959/28500 (epoch 45.542), train_loss = 0.80990674, grad/param norm = 2.0489e-01, time/batch = 0.6791s	
25960/28500 (epoch 45.544), train_loss = 0.90984370, grad/param norm = 2.2386e-01, time/batch = 0.6760s	
25961/28500 (epoch 45.546), train_loss = 0.77527846, grad/param norm = 1.8595e-01, time/batch = 0.6816s	
25962/28500 (epoch 45.547), train_loss = 0.75465256, grad/param norm = 1.8336e-01, time/batch = 0.6786s	
25963/28500 (epoch 45.549), train_loss = 0.66502441, grad/param norm = 1.4758e-01, time/batch = 0.6767s	
25964/28500 (epoch 45.551), train_loss = 0.71745076, grad/param norm = 2.2861e-01, time/batch = 0.6778s	
25965/28500 (epoch 45.553), train_loss = 0.92676777, grad/param norm = 2.3322e-01, time/batch = 0.6773s	
25966/28500 (epoch 45.554), train_loss = 0.81489195, grad/param norm = 2.0257e-01, time/batch = 0.6767s	
25967/28500 (epoch 45.556), train_loss = 0.82835958, grad/param norm = 2.0738e-01, time/batch = 0.6791s	
25968/28500 (epoch 45.558), train_loss = 0.84346541, grad/param norm = 2.0826e-01, time/batch = 0.6818s	
25969/28500 (epoch 45.560), train_loss = 0.83476975, grad/param norm = 2.3530e-01, time/batch = 0.6763s	
25970/28500 (epoch 45.561), train_loss = 0.86662768, grad/param norm = 2.2125e-01, time/batch = 0.6814s	
25971/28500 (epoch 45.563), train_loss = 0.93817867, grad/param norm = 2.3105e-01, time/batch = 0.6805s	
25972/28500 (epoch 45.565), train_loss = 0.73022028, grad/param norm = 1.8689e-01, time/batch = 0.6788s	
25973/28500 (epoch 45.567), train_loss = 0.67188780, grad/param norm = 1.9806e-01, time/batch = 0.6767s	
25974/28500 (epoch 45.568), train_loss = 0.80289083, grad/param norm = 1.8784e-01, time/batch = 0.6796s	
25975/28500 (epoch 45.570), train_loss = 0.76531085, grad/param norm = 2.0957e-01, time/batch = 0.6774s	
25976/28500 (epoch 45.572), train_loss = 0.80119939, grad/param norm = 1.8888e-01, time/batch = 0.6763s	
25977/28500 (epoch 45.574), train_loss = 0.74554251, grad/param norm = 1.6865e-01, time/batch = 0.6763s	
25978/28500 (epoch 45.575), train_loss = 0.73423248, grad/param norm = 1.7060e-01, time/batch = 0.6758s	
25979/28500 (epoch 45.577), train_loss = 0.85646460, grad/param norm = 1.9607e-01, time/batch = 0.6758s	
25980/28500 (epoch 45.579), train_loss = 0.85612080, grad/param norm = 1.9730e-01, time/batch = 0.6759s	
25981/28500 (epoch 45.581), train_loss = 0.72709421, grad/param norm = 1.9317e-01, time/batch = 0.6780s	
25982/28500 (epoch 45.582), train_loss = 0.91346620, grad/param norm = 2.3508e-01, time/batch = 0.6768s	
25983/28500 (epoch 45.584), train_loss = 0.74134624, grad/param norm = 1.8277e-01, time/batch = 0.6765s	
25984/28500 (epoch 45.586), train_loss = 0.71529913, grad/param norm = 1.6498e-01, time/batch = 0.6767s	
25985/28500 (epoch 45.588), train_loss = 0.73453608, grad/param norm = 1.8373e-01, time/batch = 0.6762s	
25986/28500 (epoch 45.589), train_loss = 0.76414107, grad/param norm = 1.8403e-01, time/batch = 0.6763s	
25987/28500 (epoch 45.591), train_loss = 0.80085068, grad/param norm = 2.1532e-01, time/batch = 0.6758s	
25988/28500 (epoch 45.593), train_loss = 0.74212974, grad/param norm = 1.9133e-01, time/batch = 0.6760s	
25989/28500 (epoch 45.595), train_loss = 0.93804889, grad/param norm = 2.1960e-01, time/batch = 0.6802s	
25990/28500 (epoch 45.596), train_loss = 0.94607150, grad/param norm = 2.0604e-01, time/batch = 0.6798s	
25991/28500 (epoch 45.598), train_loss = 0.78191435, grad/param norm = 2.1779e-01, time/batch = 0.6875s	
25992/28500 (epoch 45.600), train_loss = 0.76154897, grad/param norm = 1.9960e-01, time/batch = 0.6807s	
25993/28500 (epoch 45.602), train_loss = 0.87119067, grad/param norm = 2.3424e-01, time/batch = 0.6828s	
25994/28500 (epoch 45.604), train_loss = 0.87867456, grad/param norm = 1.7331e-01, time/batch = 0.6857s	
25995/28500 (epoch 45.605), train_loss = 0.86249111, grad/param norm = 1.9423e-01, time/batch = 0.6822s	
25996/28500 (epoch 45.607), train_loss = 0.90675339, grad/param norm = 1.9279e-01, time/batch = 0.6813s	
25997/28500 (epoch 45.609), train_loss = 0.80010688, grad/param norm = 1.8140e-01, time/batch = 0.6840s	
25998/28500 (epoch 45.611), train_loss = 0.78960751, grad/param norm = 2.0186e-01, time/batch = 0.6850s	
25999/28500 (epoch 45.612), train_loss = 0.86239830, grad/param norm = 2.1586e-01, time/batch = 0.6799s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch45.61_2.0070.t7	
26000/28500 (epoch 45.614), train_loss = 0.87198160, grad/param norm = 1.8193e-01, time/batch = 0.6777s	
26001/28500 (epoch 45.616), train_loss = 1.22354043, grad/param norm = 2.6866e-01, time/batch = 0.6976s	
26002/28500 (epoch 45.618), train_loss = 0.76522059, grad/param norm = 1.9229e-01, time/batch = 0.6989s	
26003/28500 (epoch 45.619), train_loss = 0.87450549, grad/param norm = 2.9700e-01, time/batch = 0.7020s	
26004/28500 (epoch 45.621), train_loss = 0.64943104, grad/param norm = 1.9038e-01, time/batch = 0.6836s	
26005/28500 (epoch 45.623), train_loss = 0.92183853, grad/param norm = 2.0946e-01, time/batch = 0.6838s	
26006/28500 (epoch 45.625), train_loss = 0.72196761, grad/param norm = 1.8340e-01, time/batch = 0.6839s	
26007/28500 (epoch 45.626), train_loss = 0.64603723, grad/param norm = 1.8401e-01, time/batch = 0.6927s	
26008/28500 (epoch 45.628), train_loss = 0.74102048, grad/param norm = 2.2823e-01, time/batch = 0.6936s	
26009/28500 (epoch 45.630), train_loss = 0.70884169, grad/param norm = 1.7372e-01, time/batch = 0.6867s	
26010/28500 (epoch 45.632), train_loss = 0.89499775, grad/param norm = 2.2230e-01, time/batch = 0.7026s	
26011/28500 (epoch 45.633), train_loss = 0.91643710, grad/param norm = 1.7359e-01, time/batch = 0.6893s	
26012/28500 (epoch 45.635), train_loss = 0.84842715, grad/param norm = 2.9302e-01, time/batch = 0.6847s	
26013/28500 (epoch 45.637), train_loss = 0.81171442, grad/param norm = 1.9240e-01, time/batch = 0.6863s	
26014/28500 (epoch 45.639), train_loss = 0.71401845, grad/param norm = 1.9636e-01, time/batch = 0.6818s	
26015/28500 (epoch 45.640), train_loss = 0.76474819, grad/param norm = 1.9003e-01, time/batch = 0.6822s	
26016/28500 (epoch 45.642), train_loss = 0.74564386, grad/param norm = 1.9532e-01, time/batch = 0.6898s	
26017/28500 (epoch 45.644), train_loss = 0.83806832, grad/param norm = 2.4237e-01, time/batch = 0.6794s	
26018/28500 (epoch 45.646), train_loss = 0.64624457, grad/param norm = 1.5582e-01, time/batch = 0.6823s	
26019/28500 (epoch 45.647), train_loss = 0.74106367, grad/param norm = 1.8734e-01, time/batch = 0.6802s	
26020/28500 (epoch 45.649), train_loss = 0.74933268, grad/param norm = 2.3197e-01, time/batch = 0.6801s	
26021/28500 (epoch 45.651), train_loss = 0.69113207, grad/param norm = 1.5934e-01, time/batch = 0.6823s	
26022/28500 (epoch 45.653), train_loss = 0.69234101, grad/param norm = 2.1838e-01, time/batch = 0.6819s	
26023/28500 (epoch 45.654), train_loss = 0.72272551, grad/param norm = 2.3281e-01, time/batch = 0.6813s	
26024/28500 (epoch 45.656), train_loss = 0.67290083, grad/param norm = 2.0708e-01, time/batch = 0.6823s	
26025/28500 (epoch 45.658), train_loss = 0.78665060, grad/param norm = 1.9532e-01, time/batch = 0.6818s	
26026/28500 (epoch 45.660), train_loss = 0.79099507, grad/param norm = 1.9431e-01, time/batch = 0.6818s	
26027/28500 (epoch 45.661), train_loss = 0.88184247, grad/param norm = 2.2193e-01, time/batch = 0.6814s	
26028/28500 (epoch 45.663), train_loss = 0.89967668, grad/param norm = 2.5051e-01, time/batch = 0.6818s	
26029/28500 (epoch 45.665), train_loss = 0.78816338, grad/param norm = 2.0629e-01, time/batch = 0.6808s	
26030/28500 (epoch 45.667), train_loss = 0.81665122, grad/param norm = 2.0892e-01, time/batch = 0.6845s	
26031/28500 (epoch 45.668), train_loss = 0.79431795, grad/param norm = 1.8192e-01, time/batch = 0.6837s	
26032/28500 (epoch 45.670), train_loss = 0.81080613, grad/param norm = 1.8110e-01, time/batch = 0.6810s	
26033/28500 (epoch 45.672), train_loss = 0.72342826, grad/param norm = 1.9982e-01, time/batch = 0.6799s	
26034/28500 (epoch 45.674), train_loss = 0.63077580, grad/param norm = 2.3004e-01, time/batch = 0.6784s	
26035/28500 (epoch 45.675), train_loss = 0.67730289, grad/param norm = 1.8760e-01, time/batch = 0.6813s	
26036/28500 (epoch 45.677), train_loss = 0.74487308, grad/param norm = 1.7018e-01, time/batch = 0.6788s	
26037/28500 (epoch 45.679), train_loss = 0.75416605, grad/param norm = 2.1012e-01, time/batch = 0.6796s	
26038/28500 (epoch 45.681), train_loss = 0.82173095, grad/param norm = 2.2115e-01, time/batch = 0.6775s	
26039/28500 (epoch 45.682), train_loss = 0.77260900, grad/param norm = 2.1751e-01, time/batch = 0.6789s	
26040/28500 (epoch 45.684), train_loss = 0.78389135, grad/param norm = 1.7381e-01, time/batch = 0.6779s	
26041/28500 (epoch 45.686), train_loss = 0.74026937, grad/param norm = 1.9178e-01, time/batch = 0.6820s	
26042/28500 (epoch 45.688), train_loss = 0.72364018, grad/param norm = 1.5628e-01, time/batch = 0.6787s	
26043/28500 (epoch 45.689), train_loss = 0.71842148, grad/param norm = 1.9889e-01, time/batch = 0.6795s	
26044/28500 (epoch 45.691), train_loss = 0.83277087, grad/param norm = 1.9259e-01, time/batch = 0.6799s	
26045/28500 (epoch 45.693), train_loss = 0.75642768, grad/param norm = 2.0005e-01, time/batch = 0.6794s	
26046/28500 (epoch 45.695), train_loss = 0.58240253, grad/param norm = 2.0124e-01, time/batch = 0.6798s	
26047/28500 (epoch 45.696), train_loss = 0.72878060, grad/param norm = 1.9290e-01, time/batch = 0.6790s	
26048/28500 (epoch 45.698), train_loss = 0.83170161, grad/param norm = 1.8951e-01, time/batch = 0.6814s	
26049/28500 (epoch 45.700), train_loss = 0.77318895, grad/param norm = 1.7926e-01, time/batch = 0.6805s	
26050/28500 (epoch 45.702), train_loss = 0.77009357, grad/param norm = 2.2203e-01, time/batch = 0.6820s	
26051/28500 (epoch 45.704), train_loss = 0.82942081, grad/param norm = 2.0568e-01, time/batch = 0.6803s	
26052/28500 (epoch 45.705), train_loss = 0.83747943, grad/param norm = 2.2137e-01, time/batch = 0.6819s	
26053/28500 (epoch 45.707), train_loss = 0.72656567, grad/param norm = 2.0625e-01, time/batch = 0.6805s	
26054/28500 (epoch 45.709), train_loss = 0.91941376, grad/param norm = 2.5056e-01, time/batch = 0.6807s	
26055/28500 (epoch 45.711), train_loss = 0.75117748, grad/param norm = 1.8965e-01, time/batch = 0.6803s	
26056/28500 (epoch 45.712), train_loss = 0.80970143, grad/param norm = 2.0271e-01, time/batch = 0.6808s	
26057/28500 (epoch 45.714), train_loss = 0.90839263, grad/param norm = 2.0114e-01, time/batch = 0.6793s	
26058/28500 (epoch 45.716), train_loss = 0.75875081, grad/param norm = 1.8113e-01, time/batch = 0.6809s	
26059/28500 (epoch 45.718), train_loss = 0.81188725, grad/param norm = 2.0522e-01, time/batch = 0.6810s	
26060/28500 (epoch 45.719), train_loss = 0.79361419, grad/param norm = 1.7584e-01, time/batch = 0.6793s	
26061/28500 (epoch 45.721), train_loss = 0.61330345, grad/param norm = 1.9933e-01, time/batch = 0.6826s	
26062/28500 (epoch 45.723), train_loss = 0.78091153, grad/param norm = 1.9349e-01, time/batch = 0.6783s	
26063/28500 (epoch 45.725), train_loss = 0.84748707, grad/param norm = 1.9712e-01, time/batch = 0.6770s	
26064/28500 (epoch 45.726), train_loss = 0.76543122, grad/param norm = 1.8518e-01, time/batch = 0.6760s	
26065/28500 (epoch 45.728), train_loss = 0.71167364, grad/param norm = 2.1721e-01, time/batch = 0.6820s	
26066/28500 (epoch 45.730), train_loss = 0.76431950, grad/param norm = 2.0090e-01, time/batch = 0.6787s	
26067/28500 (epoch 45.732), train_loss = 0.62708805, grad/param norm = 1.6763e-01, time/batch = 0.6783s	
26068/28500 (epoch 45.733), train_loss = 0.66442459, grad/param norm = 1.8632e-01, time/batch = 0.6801s	
26069/28500 (epoch 45.735), train_loss = 0.67004867, grad/param norm = 1.6903e-01, time/batch = 0.6767s	
26070/28500 (epoch 45.737), train_loss = 0.59264288, grad/param norm = 1.5900e-01, time/batch = 0.6761s	
26071/28500 (epoch 45.739), train_loss = 0.66805612, grad/param norm = 1.8065e-01, time/batch = 0.6812s	
26072/28500 (epoch 45.740), train_loss = 0.77323982, grad/param norm = 1.9511e-01, time/batch = 0.6769s	
26073/28500 (epoch 45.742), train_loss = 0.69453611, grad/param norm = 1.8578e-01, time/batch = 0.6759s	
26074/28500 (epoch 45.744), train_loss = 0.77402523, grad/param norm = 1.9768e-01, time/batch = 0.6759s	
26075/28500 (epoch 45.746), train_loss = 0.74210879, grad/param norm = 1.7588e-01, time/batch = 0.6797s	
26076/28500 (epoch 45.747), train_loss = 0.75136346, grad/param norm = 1.9338e-01, time/batch = 0.6852s	
26077/28500 (epoch 45.749), train_loss = 0.83013164, grad/param norm = 2.5191e-01, time/batch = 0.6995s	
26078/28500 (epoch 45.751), train_loss = 0.72012611, grad/param norm = 2.8904e-01, time/batch = 0.6775s	
26079/28500 (epoch 45.753), train_loss = 0.79084255, grad/param norm = 1.9348e-01, time/batch = 0.6817s	
26080/28500 (epoch 45.754), train_loss = 0.68404582, grad/param norm = 2.0186e-01, time/batch = 0.6789s	
26081/28500 (epoch 45.756), train_loss = 0.90094438, grad/param norm = 2.1342e-01, time/batch = 0.6806s	
26082/28500 (epoch 45.758), train_loss = 0.82471865, grad/param norm = 2.6877e-01, time/batch = 0.6876s	
26083/28500 (epoch 45.760), train_loss = 0.67051103, grad/param norm = 2.2526e-01, time/batch = 0.6797s	
26084/28500 (epoch 45.761), train_loss = 0.72598021, grad/param norm = 1.7533e-01, time/batch = 0.6784s	
26085/28500 (epoch 45.763), train_loss = 0.60991846, grad/param norm = 1.8249e-01, time/batch = 0.6786s	
26086/28500 (epoch 45.765), train_loss = 0.74982835, grad/param norm = 1.7101e-01, time/batch = 0.6796s	
26087/28500 (epoch 45.767), train_loss = 0.62167996, grad/param norm = 1.7969e-01, time/batch = 0.6804s	
26088/28500 (epoch 45.768), train_loss = 0.81823905, grad/param norm = 1.9249e-01, time/batch = 0.6773s	
26089/28500 (epoch 45.770), train_loss = 0.67129830, grad/param norm = 1.9597e-01, time/batch = 0.6825s	
26090/28500 (epoch 45.772), train_loss = 0.64010649, grad/param norm = 1.7450e-01, time/batch = 0.6841s	
26091/28500 (epoch 45.774), train_loss = 0.76504451, grad/param norm = 1.8893e-01, time/batch = 0.6782s	
26092/28500 (epoch 45.775), train_loss = 0.81420094, grad/param norm = 2.0416e-01, time/batch = 0.6779s	
26093/28500 (epoch 45.777), train_loss = 0.82372021, grad/param norm = 1.6291e-01, time/batch = 0.6820s	
26094/28500 (epoch 45.779), train_loss = 0.64904431, grad/param norm = 1.5450e-01, time/batch = 0.6805s	
26095/28500 (epoch 45.781), train_loss = 0.75330395, grad/param norm = 1.8665e-01, time/batch = 0.6774s	
26096/28500 (epoch 45.782), train_loss = 0.79916915, grad/param norm = 2.2907e-01, time/batch = 0.6781s	
26097/28500 (epoch 45.784), train_loss = 0.61648597, grad/param norm = 1.7355e-01, time/batch = 0.6759s	
26098/28500 (epoch 45.786), train_loss = 0.63889691, grad/param norm = 1.9216e-01, time/batch = 0.6757s	
26099/28500 (epoch 45.788), train_loss = 0.73064219, grad/param norm = 2.2826e-01, time/batch = 0.6763s	
26100/28500 (epoch 45.789), train_loss = 0.56565135, grad/param norm = 2.5691e-01, time/batch = 0.6781s	
26101/28500 (epoch 45.791), train_loss = 0.79042839, grad/param norm = 1.9724e-01, time/batch = 0.6836s	
26102/28500 (epoch 45.793), train_loss = 0.73938515, grad/param norm = 2.0827e-01, time/batch = 0.6801s	
26103/28500 (epoch 45.795), train_loss = 0.75940332, grad/param norm = 1.8447e-01, time/batch = 0.6766s	
26104/28500 (epoch 45.796), train_loss = 0.69403396, grad/param norm = 2.1109e-01, time/batch = 0.6763s	
26105/28500 (epoch 45.798), train_loss = 0.64073056, grad/param norm = 1.9504e-01, time/batch = 0.6793s	
26106/28500 (epoch 45.800), train_loss = 0.61597808, grad/param norm = 2.6860e-01, time/batch = 0.6874s	
26107/28500 (epoch 45.802), train_loss = 0.72442065, grad/param norm = 2.4952e-01, time/batch = 0.6785s	
26108/28500 (epoch 45.804), train_loss = 0.78217589, grad/param norm = 1.8282e-01, time/batch = 0.6778s	
26109/28500 (epoch 45.805), train_loss = 0.78562683, grad/param norm = 1.9018e-01, time/batch = 0.6765s	
26110/28500 (epoch 45.807), train_loss = 0.79037337, grad/param norm = 2.1454e-01, time/batch = 0.6762s	
26111/28500 (epoch 45.809), train_loss = 0.77437678, grad/param norm = 2.2885e-01, time/batch = 0.6880s	
26112/28500 (epoch 45.811), train_loss = 0.77410420, grad/param norm = 2.0323e-01, time/batch = 0.6769s	
26113/28500 (epoch 45.812), train_loss = 0.74447546, grad/param norm = 2.0778e-01, time/batch = 0.6782s	
26114/28500 (epoch 45.814), train_loss = 0.69758807, grad/param norm = 1.7468e-01, time/batch = 0.6811s	
26115/28500 (epoch 45.816), train_loss = 0.78805301, grad/param norm = 2.1815e-01, time/batch = 0.6804s	
26116/28500 (epoch 45.818), train_loss = 0.88611613, grad/param norm = 2.4137e-01, time/batch = 0.6808s	
26117/28500 (epoch 45.819), train_loss = 0.75110845, grad/param norm = 1.7173e-01, time/batch = 0.6772s	
26118/28500 (epoch 45.821), train_loss = 0.74665510, grad/param norm = 1.8843e-01, time/batch = 0.6803s	
26119/28500 (epoch 45.823), train_loss = 0.87168794, grad/param norm = 2.4299e-01, time/batch = 0.6788s	
26120/28500 (epoch 45.825), train_loss = 0.66564020, grad/param norm = 1.9078e-01, time/batch = 0.6792s	
26121/28500 (epoch 45.826), train_loss = 0.77286773, grad/param norm = 1.9153e-01, time/batch = 0.6799s	
26122/28500 (epoch 45.828), train_loss = 0.70100671, grad/param norm = 2.0960e-01, time/batch = 0.6818s	
26123/28500 (epoch 45.830), train_loss = 0.71521010, grad/param norm = 1.5768e-01, time/batch = 0.6803s	
26124/28500 (epoch 45.832), train_loss = 0.74363559, grad/param norm = 1.9625e-01, time/batch = 0.6760s	
26125/28500 (epoch 45.833), train_loss = 0.79035015, grad/param norm = 1.9297e-01, time/batch = 0.6769s	
26126/28500 (epoch 45.835), train_loss = 0.73538517, grad/param norm = 2.1029e-01, time/batch = 0.6771s	
26127/28500 (epoch 45.837), train_loss = 0.64512806, grad/param norm = 1.9072e-01, time/batch = 0.6761s	
26128/28500 (epoch 45.839), train_loss = 0.92937580, grad/param norm = 3.1858e-01, time/batch = 0.6814s	
26129/28500 (epoch 45.840), train_loss = 0.89885093, grad/param norm = 2.3109e-01, time/batch = 0.6808s	
26130/28500 (epoch 45.842), train_loss = 0.83995767, grad/param norm = 2.3254e-01, time/batch = 0.6765s	
26131/28500 (epoch 45.844), train_loss = 0.86321932, grad/param norm = 2.0896e-01, time/batch = 0.6800s	
26132/28500 (epoch 45.846), train_loss = 0.90577724, grad/param norm = 2.3463e-01, time/batch = 0.6833s	
26133/28500 (epoch 45.847), train_loss = 0.73955324, grad/param norm = 2.0023e-01, time/batch = 0.6823s	
26134/28500 (epoch 45.849), train_loss = 0.73125669, grad/param norm = 1.8921e-01, time/batch = 0.6816s	
26135/28500 (epoch 45.851), train_loss = 0.70912758, grad/param norm = 1.7134e-01, time/batch = 0.6886s	
26136/28500 (epoch 45.853), train_loss = 0.82761909, grad/param norm = 2.2020e-01, time/batch = 0.6867s	
26137/28500 (epoch 45.854), train_loss = 0.79129357, grad/param norm = 2.0432e-01, time/batch = 0.6816s	
26138/28500 (epoch 45.856), train_loss = 0.85715200, grad/param norm = 2.3899e-01, time/batch = 0.6808s	
26139/28500 (epoch 45.858), train_loss = 0.74842911, grad/param norm = 1.8847e-01, time/batch = 0.6815s	
26140/28500 (epoch 45.860), train_loss = 0.76983216, grad/param norm = 1.8833e-01, time/batch = 0.6823s	
26141/28500 (epoch 45.861), train_loss = 0.85127410, grad/param norm = 2.3269e-01, time/batch = 0.6843s	
26142/28500 (epoch 45.863), train_loss = 0.81467673, grad/param norm = 2.5147e-01, time/batch = 0.6857s	
26143/28500 (epoch 45.865), train_loss = 0.74299734, grad/param norm = 2.3633e-01, time/batch = 0.6825s	
26144/28500 (epoch 45.867), train_loss = 0.80029184, grad/param norm = 2.3915e-01, time/batch = 0.6792s	
26145/28500 (epoch 45.868), train_loss = 0.68976232, grad/param norm = 1.9098e-01, time/batch = 0.6795s	
26146/28500 (epoch 45.870), train_loss = 0.66538802, grad/param norm = 1.9785e-01, time/batch = 0.6799s	
26147/28500 (epoch 45.872), train_loss = 0.84575525, grad/param norm = 2.3233e-01, time/batch = 0.6801s	
26148/28500 (epoch 45.874), train_loss = 0.70619328, grad/param norm = 2.4321e-01, time/batch = 0.6797s	
26149/28500 (epoch 45.875), train_loss = 0.90651973, grad/param norm = 2.2896e-01, time/batch = 0.6795s	
26150/28500 (epoch 45.877), train_loss = 0.83114088, grad/param norm = 2.3528e-01, time/batch = 0.6791s	
26151/28500 (epoch 45.879), train_loss = 0.79640642, grad/param norm = 1.6177e-01, time/batch = 0.6825s	
26152/28500 (epoch 45.881), train_loss = 0.78210742, grad/param norm = 1.8768e-01, time/batch = 0.6813s	
26153/28500 (epoch 45.882), train_loss = 0.70289039, grad/param norm = 1.9823e-01, time/batch = 0.6825s	
26154/28500 (epoch 45.884), train_loss = 0.72384943, grad/param norm = 1.7511e-01, time/batch = 0.6820s	
26155/28500 (epoch 45.886), train_loss = 0.70857265, grad/param norm = 1.6406e-01, time/batch = 0.6791s	
26156/28500 (epoch 45.888), train_loss = 0.73362198, grad/param norm = 1.6394e-01, time/batch = 0.6878s	
26157/28500 (epoch 45.889), train_loss = 0.79956315, grad/param norm = 1.6946e-01, time/batch = 0.6805s	
26158/28500 (epoch 45.891), train_loss = 0.78265445, grad/param norm = 1.8131e-01, time/batch = 0.6836s	
26159/28500 (epoch 45.893), train_loss = 0.72724405, grad/param norm = 1.9472e-01, time/batch = 0.6825s	
26160/28500 (epoch 45.895), train_loss = 0.89575856, grad/param norm = 2.3225e-01, time/batch = 0.6847s	
26161/28500 (epoch 45.896), train_loss = 0.86505429, grad/param norm = 2.0845e-01, time/batch = 0.6830s	
26162/28500 (epoch 45.898), train_loss = 0.84356043, grad/param norm = 1.9385e-01, time/batch = 0.6815s	
26163/28500 (epoch 45.900), train_loss = 0.68883517, grad/param norm = 1.7144e-01, time/batch = 0.6839s	
26164/28500 (epoch 45.902), train_loss = 0.65111897, grad/param norm = 1.8454e-01, time/batch = 0.6876s	
26165/28500 (epoch 45.904), train_loss = 0.69193224, grad/param norm = 1.6954e-01, time/batch = 0.6892s	
26166/28500 (epoch 45.905), train_loss = 0.71989721, grad/param norm = 1.8139e-01, time/batch = 0.6803s	
26167/28500 (epoch 45.907), train_loss = 0.75765647, grad/param norm = 1.8918e-01, time/batch = 0.6810s	
26168/28500 (epoch 45.909), train_loss = 0.63136648, grad/param norm = 1.9813e-01, time/batch = 0.6800s	
26169/28500 (epoch 45.911), train_loss = 0.68938401, grad/param norm = 2.0522e-01, time/batch = 0.6809s	
26170/28500 (epoch 45.912), train_loss = 0.57585065, grad/param norm = 1.6703e-01, time/batch = 0.6832s	
26171/28500 (epoch 45.914), train_loss = 0.78503931, grad/param norm = 1.7480e-01, time/batch = 0.6846s	
26172/28500 (epoch 45.916), train_loss = 0.76759073, grad/param norm = 2.0492e-01, time/batch = 0.6822s	
26173/28500 (epoch 45.918), train_loss = 0.76263195, grad/param norm = 1.8852e-01, time/batch = 0.6820s	
26174/28500 (epoch 45.919), train_loss = 0.81160004, grad/param norm = 1.9710e-01, time/batch = 0.6791s	
26175/28500 (epoch 45.921), train_loss = 0.85477062, grad/param norm = 2.3051e-01, time/batch = 0.6814s	
26176/28500 (epoch 45.923), train_loss = 0.69565403, grad/param norm = 4.5721e-01, time/batch = 0.6785s	
26177/28500 (epoch 45.925), train_loss = 0.75226407, grad/param norm = 3.1044e-01, time/batch = 0.6799s	
26178/28500 (epoch 45.926), train_loss = 0.80531528, grad/param norm = 2.6281e-01, time/batch = 0.6780s	
26179/28500 (epoch 45.928), train_loss = 0.71679691, grad/param norm = 1.9572e-01, time/batch = 0.6799s	
26180/28500 (epoch 45.930), train_loss = 0.61825612, grad/param norm = 1.6595e-01, time/batch = 0.6791s	
26181/28500 (epoch 45.932), train_loss = 0.62375295, grad/param norm = 1.5006e-01, time/batch = 0.6823s	
26182/28500 (epoch 45.933), train_loss = 0.82253113, grad/param norm = 1.8073e-01, time/batch = 0.6814s	
26183/28500 (epoch 45.935), train_loss = 0.83740014, grad/param norm = 1.7446e-01, time/batch = 0.6817s	
26184/28500 (epoch 45.937), train_loss = 0.82224693, grad/param norm = 2.5646e-01, time/batch = 0.6799s	
26185/28500 (epoch 45.939), train_loss = 0.89038888, grad/param norm = 2.2084e-01, time/batch = 0.6798s	
26186/28500 (epoch 45.940), train_loss = 0.61342047, grad/param norm = 1.9372e-01, time/batch = 0.6838s	
26187/28500 (epoch 45.942), train_loss = 0.77432162, grad/param norm = 1.9926e-01, time/batch = 0.6811s	
26188/28500 (epoch 45.944), train_loss = 0.74121714, grad/param norm = 2.0645e-01, time/batch = 0.6811s	
26189/28500 (epoch 45.946), train_loss = 0.81261231, grad/param norm = 1.9558e-01, time/batch = 0.6798s	
26190/28500 (epoch 45.947), train_loss = 0.98096044, grad/param norm = 3.1616e-01, time/batch = 0.6804s	
26191/28500 (epoch 45.949), train_loss = 0.74706931, grad/param norm = 2.2015e-01, time/batch = 0.6840s	
26192/28500 (epoch 45.951), train_loss = 0.92780560, grad/param norm = 2.2153e-01, time/batch = 0.6818s	
26193/28500 (epoch 45.953), train_loss = 0.92314404, grad/param norm = 2.6062e-01, time/batch = 0.6788s	
26194/28500 (epoch 45.954), train_loss = 0.85530789, grad/param norm = 2.1200e-01, time/batch = 0.6805s	
26195/28500 (epoch 45.956), train_loss = 0.77499088, grad/param norm = 2.9792e-01, time/batch = 0.6791s	
26196/28500 (epoch 45.958), train_loss = 0.99837178, grad/param norm = 1.9354e-01, time/batch = 0.6808s	
26197/28500 (epoch 45.960), train_loss = 0.72927651, grad/param norm = 2.8688e-01, time/batch = 0.6819s	
26198/28500 (epoch 45.961), train_loss = 0.92805064, grad/param norm = 2.3143e-01, time/batch = 0.6809s	
26199/28500 (epoch 45.963), train_loss = 0.87412439, grad/param norm = 2.3919e-01, time/batch = 0.6798s	
26200/28500 (epoch 45.965), train_loss = 0.71629652, grad/param norm = 2.1361e-01, time/batch = 0.6802s	
26201/28500 (epoch 45.967), train_loss = 0.71080149, grad/param norm = 1.8077e-01, time/batch = 0.6829s	
26202/28500 (epoch 45.968), train_loss = 0.69516938, grad/param norm = 1.6099e-01, time/batch = 0.6809s	
26203/28500 (epoch 45.970), train_loss = 0.69461153, grad/param norm = 2.0898e-01, time/batch = 0.6811s	
26204/28500 (epoch 45.972), train_loss = 0.76160948, grad/param norm = 1.7565e-01, time/batch = 0.6803s	
26205/28500 (epoch 45.974), train_loss = 0.99406936, grad/param norm = 2.6146e-01, time/batch = 0.6802s	
26206/28500 (epoch 45.975), train_loss = 0.71976460, grad/param norm = 1.8665e-01, time/batch = 0.6817s	
26207/28500 (epoch 45.977), train_loss = 0.86673019, grad/param norm = 2.4709e-01, time/batch = 0.6812s	
26208/28500 (epoch 45.979), train_loss = 0.81883887, grad/param norm = 1.9725e-01, time/batch = 0.6816s	
26209/28500 (epoch 45.981), train_loss = 0.65592801, grad/param norm = 1.7402e-01, time/batch = 0.6788s	
26210/28500 (epoch 45.982), train_loss = 0.77328364, grad/param norm = 1.9309e-01, time/batch = 0.6802s	
26211/28500 (epoch 45.984), train_loss = 0.83909635, grad/param norm = 1.9649e-01, time/batch = 0.6816s	
26212/28500 (epoch 45.986), train_loss = 0.99764168, grad/param norm = 3.2099e-01, time/batch = 0.6799s	
26213/28500 (epoch 45.988), train_loss = 0.70518751, grad/param norm = 1.8448e-01, time/batch = 0.6797s	
26214/28500 (epoch 45.989), train_loss = 0.79234986, grad/param norm = 2.0909e-01, time/batch = 0.6796s	
26215/28500 (epoch 45.991), train_loss = 0.68730352, grad/param norm = 1.9395e-01, time/batch = 0.6782s	
26216/28500 (epoch 45.993), train_loss = 0.70699475, grad/param norm = 2.2136e-01, time/batch = 0.6840s	
26217/28500 (epoch 45.995), train_loss = 0.74708873, grad/param norm = 1.9223e-01, time/batch = 0.6836s	
26218/28500 (epoch 45.996), train_loss = 0.68235977, grad/param norm = 1.9487e-01, time/batch = 0.6852s	
26219/28500 (epoch 45.998), train_loss = 0.89570811, grad/param norm = 2.6148e-01, time/batch = 0.6819s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
26220/28500 (epoch 46.000), train_loss = 0.76568099, grad/param norm = 1.9939e-01, time/batch = 0.6810s	
26221/28500 (epoch 46.002), train_loss = 0.93879480, grad/param norm = 2.2756e-01, time/batch = 0.6836s	
26222/28500 (epoch 46.004), train_loss = 0.81191030, grad/param norm = 1.9090e-01, time/batch = 0.6921s	
26223/28500 (epoch 46.005), train_loss = 0.88855991, grad/param norm = 2.1132e-01, time/batch = 0.6811s	
26224/28500 (epoch 46.007), train_loss = 0.70132856, grad/param norm = 1.7509e-01, time/batch = 0.6804s	
26225/28500 (epoch 46.009), train_loss = 0.79153118, grad/param norm = 2.0046e-01, time/batch = 0.6807s	
26226/28500 (epoch 46.011), train_loss = 0.71260665, grad/param norm = 1.7651e-01, time/batch = 0.6811s	
26227/28500 (epoch 46.012), train_loss = 0.72831270, grad/param norm = 1.8100e-01, time/batch = 0.6796s	
26228/28500 (epoch 46.014), train_loss = 0.69820389, grad/param norm = 2.2963e-01, time/batch = 0.6800s	
26229/28500 (epoch 46.016), train_loss = 0.75085053, grad/param norm = 2.0883e-01, time/batch = 0.6787s	
26230/28500 (epoch 46.018), train_loss = 0.79470167, grad/param norm = 1.9479e-01, time/batch = 0.6812s	
26231/28500 (epoch 46.019), train_loss = 0.88163889, grad/param norm = 1.9943e-01, time/batch = 0.6839s	
26232/28500 (epoch 46.021), train_loss = 0.88331691, grad/param norm = 1.8225e-01, time/batch = 0.6828s	
26233/28500 (epoch 46.023), train_loss = 0.78908177, grad/param norm = 1.9035e-01, time/batch = 0.6789s	
26234/28500 (epoch 46.025), train_loss = 0.81589093, grad/param norm = 1.8362e-01, time/batch = 0.6800s	
26235/28500 (epoch 46.026), train_loss = 0.73596965, grad/param norm = 2.1560e-01, time/batch = 0.6784s	
26236/28500 (epoch 46.028), train_loss = 0.78585135, grad/param norm = 2.0871e-01, time/batch = 0.6800s	
26237/28500 (epoch 46.030), train_loss = 0.80689049, grad/param norm = 2.4573e-01, time/batch = 0.6787s	
26238/28500 (epoch 46.032), train_loss = 0.90193236, grad/param norm = 2.0113e-01, time/batch = 0.6843s	
26239/28500 (epoch 46.033), train_loss = 0.92746910, grad/param norm = 2.0051e-01, time/batch = 0.6787s	
26240/28500 (epoch 46.035), train_loss = 0.76160859, grad/param norm = 2.2035e-01, time/batch = 0.6804s	
26241/28500 (epoch 46.037), train_loss = 0.85731326, grad/param norm = 1.9474e-01, time/batch = 0.6815s	
26242/28500 (epoch 46.039), train_loss = 0.87271946, grad/param norm = 2.0268e-01, time/batch = 0.6809s	
26243/28500 (epoch 46.040), train_loss = 0.90857860, grad/param norm = 2.0385e-01, time/batch = 0.6788s	
26244/28500 (epoch 46.042), train_loss = 0.87125182, grad/param norm = 2.0233e-01, time/batch = 0.6798s	
26245/28500 (epoch 46.044), train_loss = 0.76075780, grad/param norm = 1.9073e-01, time/batch = 0.6786s	
26246/28500 (epoch 46.046), train_loss = 0.97737157, grad/param norm = 2.0796e-01, time/batch = 0.6798s	
26247/28500 (epoch 46.047), train_loss = 0.92690533, grad/param norm = 2.4783e-01, time/batch = 0.6792s	
26248/28500 (epoch 46.049), train_loss = 0.80268249, grad/param norm = 1.8572e-01, time/batch = 0.6817s	
26249/28500 (epoch 46.051), train_loss = 0.78431127, grad/param norm = 2.1235e-01, time/batch = 0.6826s	
26250/28500 (epoch 46.053), train_loss = 0.77290658, grad/param norm = 2.1213e-01, time/batch = 0.6822s	
26251/28500 (epoch 46.054), train_loss = 0.85088017, grad/param norm = 1.8490e-01, time/batch = 0.6910s	
26252/28500 (epoch 46.056), train_loss = 0.74933340, grad/param norm = 1.8706e-01, time/batch = 0.6916s	
26253/28500 (epoch 46.058), train_loss = 0.72883757, grad/param norm = 1.9032e-01, time/batch = 0.6793s	
26254/28500 (epoch 46.060), train_loss = 0.84861872, grad/param norm = 2.0955e-01, time/batch = 0.6927s	
26255/28500 (epoch 46.061), train_loss = 0.75076023, grad/param norm = 1.7836e-01, time/batch = 0.6822s	
26256/28500 (epoch 46.063), train_loss = 0.82282168, grad/param norm = 2.3060e-01, time/batch = 0.6805s	
26257/28500 (epoch 46.065), train_loss = 0.81096860, grad/param norm = 2.1531e-01, time/batch = 0.7047s	
26258/28500 (epoch 46.067), train_loss = 0.73665936, grad/param norm = 1.8246e-01, time/batch = 0.6800s	
26259/28500 (epoch 46.068), train_loss = 0.76414323, grad/param norm = 1.6697e-01, time/batch = 0.6829s	
26260/28500 (epoch 46.070), train_loss = 0.80566185, grad/param norm = 1.9424e-01, time/batch = 0.6763s	
26261/28500 (epoch 46.072), train_loss = 0.93567507, grad/param norm = 2.6296e-01, time/batch = 0.6788s	
26262/28500 (epoch 46.074), train_loss = 0.77905147, grad/param norm = 2.0249e-01, time/batch = 0.6770s	
26263/28500 (epoch 46.075), train_loss = 0.79068902, grad/param norm = 1.7928e-01, time/batch = 0.6777s	
26264/28500 (epoch 46.077), train_loss = 0.83225927, grad/param norm = 1.7794e-01, time/batch = 0.6772s	
26265/28500 (epoch 46.079), train_loss = 0.81952944, grad/param norm = 1.9177e-01, time/batch = 0.6760s	
26266/28500 (epoch 46.081), train_loss = 0.88074420, grad/param norm = 2.3335e-01, time/batch = 0.6778s	
26267/28500 (epoch 46.082), train_loss = 0.77937818, grad/param norm = 3.0404e-01, time/batch = 0.6759s	
26268/28500 (epoch 46.084), train_loss = 0.77638472, grad/param norm = 1.8671e-01, time/batch = 0.6757s	
26269/28500 (epoch 46.086), train_loss = 0.74330692, grad/param norm = 2.3960e-01, time/batch = 0.6761s	
26270/28500 (epoch 46.088), train_loss = 0.70357682, grad/param norm = 1.8807e-01, time/batch = 0.6758s	
26271/28500 (epoch 46.089), train_loss = 0.85314976, grad/param norm = 2.1657e-01, time/batch = 0.6790s	
26272/28500 (epoch 46.091), train_loss = 0.71455004, grad/param norm = 1.7787e-01, time/batch = 0.6765s	
26273/28500 (epoch 46.093), train_loss = 0.88087285, grad/param norm = 2.0706e-01, time/batch = 0.6758s	
26274/28500 (epoch 46.095), train_loss = 0.80054153, grad/param norm = 1.8385e-01, time/batch = 0.6754s	
26275/28500 (epoch 46.096), train_loss = 0.87756343, grad/param norm = 1.9166e-01, time/batch = 0.6754s	
26276/28500 (epoch 46.098), train_loss = 0.78581994, grad/param norm = 2.3963e-01, time/batch = 0.6753s	
26277/28500 (epoch 46.100), train_loss = 0.76662447, grad/param norm = 1.9207e-01, time/batch = 0.6753s	
26278/28500 (epoch 46.102), train_loss = 0.88929415, grad/param norm = 2.3319e-01, time/batch = 0.6763s	
26279/28500 (epoch 46.104), train_loss = 0.81641924, grad/param norm = 2.9128e-01, time/batch = 0.6762s	
26280/28500 (epoch 46.105), train_loss = 0.88062699, grad/param norm = 2.1633e-01, time/batch = 0.6771s	
26281/28500 (epoch 46.107), train_loss = 0.72772512, grad/param norm = 2.1684e-01, time/batch = 0.6785s	
26282/28500 (epoch 46.109), train_loss = 0.76288191, grad/param norm = 2.1377e-01, time/batch = 0.6769s	
26283/28500 (epoch 46.111), train_loss = 0.77048196, grad/param norm = 2.4250e-01, time/batch = 0.6772s	
26284/28500 (epoch 46.112), train_loss = 0.86991906, grad/param norm = 2.0378e-01, time/batch = 0.6761s	
26285/28500 (epoch 46.114), train_loss = 0.79543563, grad/param norm = 1.9970e-01, time/batch = 0.6773s	
26286/28500 (epoch 46.116), train_loss = 0.93156248, grad/param norm = 2.2345e-01, time/batch = 0.6757s	
26287/28500 (epoch 46.118), train_loss = 0.73828081, grad/param norm = 2.1005e-01, time/batch = 0.6795s	
26288/28500 (epoch 46.119), train_loss = 0.81784548, grad/param norm = 2.0619e-01, time/batch = 0.6790s	
26289/28500 (epoch 46.121), train_loss = 0.96218262, grad/param norm = 2.5102e-01, time/batch = 0.6780s	
26290/28500 (epoch 46.123), train_loss = 0.90431890, grad/param norm = 2.0327e-01, time/batch = 0.6761s	
26291/28500 (epoch 46.125), train_loss = 0.81027312, grad/param norm = 2.0054e-01, time/batch = 0.6782s	
26292/28500 (epoch 46.126), train_loss = 0.82058444, grad/param norm = 2.1953e-01, time/batch = 0.6769s	
26293/28500 (epoch 46.128), train_loss = 0.83119444, grad/param norm = 1.9869e-01, time/batch = 0.6766s	
26294/28500 (epoch 46.130), train_loss = 0.76409895, grad/param norm = 1.9425e-01, time/batch = 0.6777s	
26295/28500 (epoch 46.132), train_loss = 0.80027381, grad/param norm = 2.6296e-01, time/batch = 0.6775s	
26296/28500 (epoch 46.133), train_loss = 0.87140381, grad/param norm = 2.6702e-01, time/batch = 0.6773s	
26297/28500 (epoch 46.135), train_loss = 0.75676462, grad/param norm = 1.8777e-01, time/batch = 0.6842s	
26298/28500 (epoch 46.137), train_loss = 0.81166663, grad/param norm = 1.8494e-01, time/batch = 0.6789s	
26299/28500 (epoch 46.139), train_loss = 0.82068952, grad/param norm = 1.8819e-01, time/batch = 0.6793s	
26300/28500 (epoch 46.140), train_loss = 0.80015629, grad/param norm = 2.1201e-01, time/batch = 0.6773s	
26301/28500 (epoch 46.142), train_loss = 0.76246752, grad/param norm = 1.9908e-01, time/batch = 0.6895s	
26302/28500 (epoch 46.144), train_loss = 0.72295050, grad/param norm = 2.2376e-01, time/batch = 0.6868s	
26303/28500 (epoch 46.146), train_loss = 0.77824045, grad/param norm = 1.9768e-01, time/batch = 0.6915s	
26304/28500 (epoch 46.147), train_loss = 0.68712925, grad/param norm = 2.0595e-01, time/batch = 0.7051s	
26305/28500 (epoch 46.149), train_loss = 0.70554499, grad/param norm = 1.9461e-01, time/batch = 0.7032s	
26306/28500 (epoch 46.151), train_loss = 0.75336078, grad/param norm = 1.9849e-01, time/batch = 0.6882s	
26307/28500 (epoch 46.153), train_loss = 0.81787879, grad/param norm = 1.9008e-01, time/batch = 0.6975s	
26308/28500 (epoch 46.154), train_loss = 0.68208510, grad/param norm = 2.1720e-01, time/batch = 0.6853s	
26309/28500 (epoch 46.156), train_loss = 0.85204147, grad/param norm = 2.0483e-01, time/batch = 0.6825s	
26310/28500 (epoch 46.158), train_loss = 0.81339931, grad/param norm = 2.0379e-01, time/batch = 0.6799s	
26311/28500 (epoch 46.160), train_loss = 0.72831260, grad/param norm = 1.8030e-01, time/batch = 0.6799s	
26312/28500 (epoch 46.161), train_loss = 0.72784123, grad/param norm = 1.9740e-01, time/batch = 0.6811s	
26313/28500 (epoch 46.163), train_loss = 0.68480736, grad/param norm = 1.8130e-01, time/batch = 0.6785s	
26314/28500 (epoch 46.165), train_loss = 0.90094106, grad/param norm = 1.8452e-01, time/batch = 0.6840s	
26315/28500 (epoch 46.167), train_loss = 0.92146833, grad/param norm = 2.4109e-01, time/batch = 0.6774s	
26316/28500 (epoch 46.168), train_loss = 0.89740404, grad/param norm = 2.1163e-01, time/batch = 0.6764s	
26317/28500 (epoch 46.170), train_loss = 0.88821916, grad/param norm = 2.2234e-01, time/batch = 0.6826s	
26318/28500 (epoch 46.172), train_loss = 0.76392175, grad/param norm = 1.6475e-01, time/batch = 0.6818s	
26319/28500 (epoch 46.174), train_loss = 0.93366682, grad/param norm = 2.4370e-01, time/batch = 0.6765s	
26320/28500 (epoch 46.175), train_loss = 0.78677730, grad/param norm = 2.0172e-01, time/batch = 0.6776s	
26321/28500 (epoch 46.177), train_loss = 0.81749965, grad/param norm = 2.0437e-01, time/batch = 0.6810s	
26322/28500 (epoch 46.179), train_loss = 0.85370374, grad/param norm = 2.1275e-01, time/batch = 0.6767s	
26323/28500 (epoch 46.181), train_loss = 0.81286744, grad/param norm = 2.4380e-01, time/batch = 0.6823s	
26324/28500 (epoch 46.182), train_loss = 0.75504213, grad/param norm = 1.9397e-01, time/batch = 0.7005s	
26325/28500 (epoch 46.184), train_loss = 0.95197524, grad/param norm = 2.0919e-01, time/batch = 0.6961s	
26326/28500 (epoch 46.186), train_loss = 0.93920424, grad/param norm = 1.9872e-01, time/batch = 0.6915s	
26327/28500 (epoch 46.188), train_loss = 0.85368302, grad/param norm = 2.1107e-01, time/batch = 0.7016s	
26328/28500 (epoch 46.189), train_loss = 0.80419107, grad/param norm = 1.8457e-01, time/batch = 0.7038s	
26329/28500 (epoch 46.191), train_loss = 0.96387249, grad/param norm = 2.2139e-01, time/batch = 0.6898s	
26330/28500 (epoch 46.193), train_loss = 0.78178850, grad/param norm = 2.3438e-01, time/batch = 0.6900s	
26331/28500 (epoch 46.195), train_loss = 0.93902590, grad/param norm = 2.2466e-01, time/batch = 0.6922s	
26332/28500 (epoch 46.196), train_loss = 0.83828859, grad/param norm = 2.1423e-01, time/batch = 0.6898s	
26333/28500 (epoch 46.198), train_loss = 0.82577253, grad/param norm = 1.9509e-01, time/batch = 0.6891s	
26334/28500 (epoch 46.200), train_loss = 0.87651841, grad/param norm = 2.0833e-01, time/batch = 0.6893s	
26335/28500 (epoch 46.202), train_loss = 0.83686034, grad/param norm = 1.7337e-01, time/batch = 0.6891s	
26336/28500 (epoch 46.204), train_loss = 0.80271802, grad/param norm = 2.1232e-01, time/batch = 0.6896s	
26337/28500 (epoch 46.205), train_loss = 0.74893023, grad/param norm = 1.9821e-01, time/batch = 0.6911s	
26338/28500 (epoch 46.207), train_loss = 0.67241616, grad/param norm = 1.8677e-01, time/batch = 0.6964s	
26339/28500 (epoch 46.209), train_loss = 0.80853313, grad/param norm = 1.7491e-01, time/batch = 0.6985s	
26340/28500 (epoch 46.211), train_loss = 0.74531155, grad/param norm = 2.0480e-01, time/batch = 0.7113s	
26341/28500 (epoch 46.212), train_loss = 0.67874469, grad/param norm = 2.4453e-01, time/batch = 0.6954s	
26342/28500 (epoch 46.214), train_loss = 0.80146726, grad/param norm = 1.9316e-01, time/batch = 0.7135s	
26343/28500 (epoch 46.216), train_loss = 0.74129961, grad/param norm = 2.0519e-01, time/batch = 0.6942s	
26344/28500 (epoch 46.218), train_loss = 0.90486874, grad/param norm = 1.9901e-01, time/batch = 0.6967s	
26345/28500 (epoch 46.219), train_loss = 0.81786530, grad/param norm = 1.9201e-01, time/batch = 0.6918s	
26346/28500 (epoch 46.221), train_loss = 0.68796017, grad/param norm = 1.7428e-01, time/batch = 0.6929s	
26347/28500 (epoch 46.223), train_loss = 0.86633359, grad/param norm = 1.8442e-01, time/batch = 0.6905s	
26348/28500 (epoch 46.225), train_loss = 0.91523573, grad/param norm = 2.0071e-01, time/batch = 0.6909s	
26349/28500 (epoch 46.226), train_loss = 0.77304971, grad/param norm = 2.1101e-01, time/batch = 0.6890s	
26350/28500 (epoch 46.228), train_loss = 0.91742042, grad/param norm = 1.9762e-01, time/batch = 0.6896s	
26351/28500 (epoch 46.230), train_loss = 0.87857713, grad/param norm = 2.1091e-01, time/batch = 0.6915s	
26352/28500 (epoch 46.232), train_loss = 0.85694943, grad/param norm = 2.0858e-01, time/batch = 0.6938s	
26353/28500 (epoch 46.233), train_loss = 0.81465744, grad/param norm = 2.4718e-01, time/batch = 0.7027s	
26354/28500 (epoch 46.235), train_loss = 0.81568144, grad/param norm = 2.0155e-01, time/batch = 0.6910s	
26355/28500 (epoch 46.237), train_loss = 0.73746838, grad/param norm = 1.6839e-01, time/batch = 0.6929s	
26356/28500 (epoch 46.239), train_loss = 0.76241903, grad/param norm = 1.7430e-01, time/batch = 0.6903s	
26357/28500 (epoch 46.240), train_loss = 0.71282216, grad/param norm = 2.1632e-01, time/batch = 0.6905s	
26358/28500 (epoch 46.242), train_loss = 0.73396358, grad/param norm = 2.0852e-01, time/batch = 0.6995s	
26359/28500 (epoch 46.244), train_loss = 0.81987899, grad/param norm = 1.7881e-01, time/batch = 0.6926s	
26360/28500 (epoch 46.246), train_loss = 0.83510394, grad/param norm = 1.9288e-01, time/batch = 0.6889s	
26361/28500 (epoch 46.247), train_loss = 0.91256601, grad/param norm = 2.5035e-01, time/batch = 0.6915s	
26362/28500 (epoch 46.249), train_loss = 0.77603857, grad/param norm = 1.8014e-01, time/batch = 0.6906s	
26363/28500 (epoch 46.251), train_loss = 0.79278437, grad/param norm = 1.8451e-01, time/batch = 0.6938s	
26364/28500 (epoch 46.253), train_loss = 0.93751055, grad/param norm = 2.1310e-01, time/batch = 0.6899s	
26365/28500 (epoch 46.254), train_loss = 0.94450656, grad/param norm = 1.9586e-01, time/batch = 0.6914s	
26366/28500 (epoch 46.256), train_loss = 0.78845776, grad/param norm = 2.1950e-01, time/batch = 0.6899s	
26367/28500 (epoch 46.258), train_loss = 0.78254747, grad/param norm = 1.8616e-01, time/batch = 0.6892s	
26368/28500 (epoch 46.260), train_loss = 0.80049707, grad/param norm = 1.9386e-01, time/batch = 0.6919s	
26369/28500 (epoch 46.261), train_loss = 0.69601807, grad/param norm = 1.7120e-01, time/batch = 0.6913s	
26370/28500 (epoch 46.263), train_loss = 0.86524942, grad/param norm = 2.4355e-01, time/batch = 0.6891s	
26371/28500 (epoch 46.265), train_loss = 0.74695771, grad/param norm = 1.7867e-01, time/batch = 0.6922s	
26372/28500 (epoch 46.267), train_loss = 0.95225732, grad/param norm = 2.2782e-01, time/batch = 0.6898s	
26373/28500 (epoch 46.268), train_loss = 0.82682706, grad/param norm = 1.9046e-01, time/batch = 0.6897s	
26374/28500 (epoch 46.270), train_loss = 0.79193677, grad/param norm = 1.8586e-01, time/batch = 0.6910s	
26375/28500 (epoch 46.272), train_loss = 0.79808637, grad/param norm = 1.7419e-01, time/batch = 0.6900s	
26376/28500 (epoch 46.274), train_loss = 0.86529706, grad/param norm = 2.2260e-01, time/batch = 0.6899s	
26377/28500 (epoch 46.275), train_loss = 0.86935026, grad/param norm = 1.8513e-01, time/batch = 0.6907s	
26378/28500 (epoch 46.277), train_loss = 0.80679648, grad/param norm = 2.5179e-01, time/batch = 0.6901s	
26379/28500 (epoch 46.279), train_loss = 0.85230878, grad/param norm = 2.0865e-01, time/batch = 0.6888s	
26380/28500 (epoch 46.281), train_loss = 0.83825069, grad/param norm = 2.1958e-01, time/batch = 0.6909s	
26381/28500 (epoch 46.282), train_loss = 0.82587138, grad/param norm = 1.7459e-01, time/batch = 0.6939s	
26382/28500 (epoch 46.284), train_loss = 0.84729218, grad/param norm = 2.3005e-01, time/batch = 0.6905s	
26383/28500 (epoch 46.286), train_loss = 0.89785597, grad/param norm = 2.0590e-01, time/batch = 0.6913s	
26384/28500 (epoch 46.288), train_loss = 0.80944992, grad/param norm = 2.0496e-01, time/batch = 0.6896s	
26385/28500 (epoch 46.289), train_loss = 0.82217900, grad/param norm = 2.6398e-01, time/batch = 0.6894s	
26386/28500 (epoch 46.291), train_loss = 0.81848321, grad/param norm = 1.9806e-01, time/batch = 0.6932s	
26387/28500 (epoch 46.293), train_loss = 0.81490947, grad/param norm = 1.9600e-01, time/batch = 0.6893s	
26388/28500 (epoch 46.295), train_loss = 0.70920568, grad/param norm = 1.7128e-01, time/batch = 0.6896s	
26389/28500 (epoch 46.296), train_loss = 0.71581588, grad/param norm = 1.8925e-01, time/batch = 0.6909s	
26390/28500 (epoch 46.298), train_loss = 0.86127952, grad/param norm = 1.8194e-01, time/batch = 0.6932s	
26391/28500 (epoch 46.300), train_loss = 0.72103730, grad/param norm = 1.9033e-01, time/batch = 0.6948s	
26392/28500 (epoch 46.302), train_loss = 0.67368750, grad/param norm = 1.8388e-01, time/batch = 0.6901s	
26393/28500 (epoch 46.304), train_loss = 0.77963340, grad/param norm = 1.7718e-01, time/batch = 0.6896s	
26394/28500 (epoch 46.305), train_loss = 0.85321200, grad/param norm = 2.1052e-01, time/batch = 0.6931s	
26395/28500 (epoch 46.307), train_loss = 0.78868006, grad/param norm = 2.0201e-01, time/batch = 0.6897s	
26396/28500 (epoch 46.309), train_loss = 0.79213673, grad/param norm = 1.7312e-01, time/batch = 0.6899s	
26397/28500 (epoch 46.311), train_loss = 0.84583041, grad/param norm = 1.9897e-01, time/batch = 0.6897s	
26398/28500 (epoch 46.312), train_loss = 0.85233227, grad/param norm = 2.2492e-01, time/batch = 0.6905s	
26399/28500 (epoch 46.314), train_loss = 0.81608354, grad/param norm = 2.0305e-01, time/batch = 0.6887s	
26400/28500 (epoch 46.316), train_loss = 0.82176718, grad/param norm = 2.0060e-01, time/batch = 0.6889s	
26401/28500 (epoch 46.318), train_loss = 0.88015539, grad/param norm = 1.9963e-01, time/batch = 0.6925s	
26402/28500 (epoch 46.319), train_loss = 0.75423123, grad/param norm = 2.0195e-01, time/batch = 0.6922s	
26403/28500 (epoch 46.321), train_loss = 0.77558328, grad/param norm = 2.1237e-01, time/batch = 0.6893s	
26404/28500 (epoch 46.323), train_loss = 0.82508307, grad/param norm = 2.0564e-01, time/batch = 0.6892s	
26405/28500 (epoch 46.325), train_loss = 0.90677078, grad/param norm = 2.1569e-01, time/batch = 0.6894s	
26406/28500 (epoch 46.326), train_loss = 0.83266835, grad/param norm = 2.1374e-01, time/batch = 0.6918s	
26407/28500 (epoch 46.328), train_loss = 0.65323441, grad/param norm = 1.6625e-01, time/batch = 0.6925s	
26408/28500 (epoch 46.330), train_loss = 0.73984148, grad/param norm = 1.8417e-01, time/batch = 0.6944s	
26409/28500 (epoch 46.332), train_loss = 0.74710504, grad/param norm = 1.7781e-01, time/batch = 0.6976s	
26410/28500 (epoch 46.333), train_loss = 0.61586760, grad/param norm = 1.8488e-01, time/batch = 0.6932s	
26411/28500 (epoch 46.335), train_loss = 0.70204755, grad/param norm = 1.7378e-01, time/batch = 0.6953s	
26412/28500 (epoch 46.337), train_loss = 0.64103647, grad/param norm = 1.5336e-01, time/batch = 0.6935s	
26413/28500 (epoch 46.339), train_loss = 0.64663626, grad/param norm = 1.5116e-01, time/batch = 0.6938s	
26414/28500 (epoch 46.340), train_loss = 0.77519338, grad/param norm = 2.1097e-01, time/batch = 0.6946s	
26415/28500 (epoch 46.342), train_loss = 0.77834830, grad/param norm = 1.7841e-01, time/batch = 0.6935s	
26416/28500 (epoch 46.344), train_loss = 0.67162028, grad/param norm = 1.8228e-01, time/batch = 0.6927s	
26417/28500 (epoch 46.346), train_loss = 0.67100039, grad/param norm = 1.6490e-01, time/batch = 0.6932s	
26418/28500 (epoch 46.347), train_loss = 0.79250483, grad/param norm = 1.6793e-01, time/batch = 0.6929s	
26419/28500 (epoch 46.349), train_loss = 0.79177916, grad/param norm = 2.0922e-01, time/batch = 0.6947s	
26420/28500 (epoch 46.351), train_loss = 0.71553253, grad/param norm = 1.9445e-01, time/batch = 0.6946s	
26421/28500 (epoch 46.353), train_loss = 0.80441103, grad/param norm = 1.9509e-01, time/batch = 0.6959s	
26422/28500 (epoch 46.354), train_loss = 0.69533562, grad/param norm = 1.9557e-01, time/batch = 0.6929s	
26423/28500 (epoch 46.356), train_loss = 0.74472088, grad/param norm = 1.7846e-01, time/batch = 0.6926s	
26424/28500 (epoch 46.358), train_loss = 0.81782109, grad/param norm = 1.8564e-01, time/batch = 0.6959s	
26425/28500 (epoch 46.360), train_loss = 0.80051417, grad/param norm = 2.2622e-01, time/batch = 0.7039s	
26426/28500 (epoch 46.361), train_loss = 0.70444282, grad/param norm = 1.9140e-01, time/batch = 0.7019s	
26427/28500 (epoch 46.363), train_loss = 0.69967406, grad/param norm = 1.9542e-01, time/batch = 0.6926s	
26428/28500 (epoch 46.365), train_loss = 0.71815754, grad/param norm = 1.8982e-01, time/batch = 0.6938s	
26429/28500 (epoch 46.367), train_loss = 0.76301373, grad/param norm = 1.8660e-01, time/batch = 0.6926s	
26430/28500 (epoch 46.368), train_loss = 0.71049623, grad/param norm = 1.8076e-01, time/batch = 0.6942s	
26431/28500 (epoch 46.370), train_loss = 0.80929589, grad/param norm = 1.9691e-01, time/batch = 0.6952s	
26432/28500 (epoch 46.372), train_loss = 0.62473510, grad/param norm = 1.7978e-01, time/batch = 0.6941s	
26433/28500 (epoch 46.374), train_loss = 0.76478172, grad/param norm = 2.0554e-01, time/batch = 0.6928s	
26434/28500 (epoch 46.375), train_loss = 0.87953340, grad/param norm = 2.0378e-01, time/batch = 0.6947s	
26435/28500 (epoch 46.377), train_loss = 0.75792167, grad/param norm = 3.2213e-01, time/batch = 0.6931s	
26436/28500 (epoch 46.379), train_loss = 0.60757973, grad/param norm = 1.7062e-01, time/batch = 0.6938s	
26437/28500 (epoch 46.381), train_loss = 0.74587913, grad/param norm = 1.8871e-01, time/batch = 0.6974s	
26438/28500 (epoch 46.382), train_loss = 0.72910620, grad/param norm = 2.2104e-01, time/batch = 0.6944s	
26439/28500 (epoch 46.384), train_loss = 0.63991341, grad/param norm = 1.8170e-01, time/batch = 0.6936s	
26440/28500 (epoch 46.386), train_loss = 0.69703874, grad/param norm = 1.6755e-01, time/batch = 0.6966s	
26441/28500 (epoch 46.388), train_loss = 0.82490251, grad/param norm = 1.8576e-01, time/batch = 0.6961s	
26442/28500 (epoch 46.389), train_loss = 0.70929781, grad/param norm = 2.8355e-01, time/batch = 0.6946s	
26443/28500 (epoch 46.391), train_loss = 0.69502790, grad/param norm = 2.2148e-01, time/batch = 0.6936s	
26444/28500 (epoch 46.393), train_loss = 0.68945269, grad/param norm = 1.7954e-01, time/batch = 0.6930s	
26445/28500 (epoch 46.395), train_loss = 0.86429055, grad/param norm = 2.0217e-01, time/batch = 0.6973s	
26446/28500 (epoch 46.396), train_loss = 0.85373223, grad/param norm = 2.1440e-01, time/batch = 0.6945s	
26447/28500 (epoch 46.398), train_loss = 0.58543803, grad/param norm = 1.8640e-01, time/batch = 0.6932s	
26448/28500 (epoch 46.400), train_loss = 0.72639351, grad/param norm = 2.0106e-01, time/batch = 0.6920s	
26449/28500 (epoch 46.402), train_loss = 0.77947645, grad/param norm = 2.2240e-01, time/batch = 0.6932s	
26450/28500 (epoch 46.404), train_loss = 0.77036260, grad/param norm = 2.1555e-01, time/batch = 0.6932s	
26451/28500 (epoch 46.405), train_loss = 0.83376138, grad/param norm = 1.9603e-01, time/batch = 0.6977s	
26452/28500 (epoch 46.407), train_loss = 0.76464973, grad/param norm = 1.8282e-01, time/batch = 0.6960s	
26453/28500 (epoch 46.409), train_loss = 0.77547221, grad/param norm = 2.0016e-01, time/batch = 0.6943s	
26454/28500 (epoch 46.411), train_loss = 0.86523915, grad/param norm = 2.1113e-01, time/batch = 0.6923s	
26455/28500 (epoch 46.412), train_loss = 0.88724974, grad/param norm = 2.0994e-01, time/batch = 0.6936s	
26456/28500 (epoch 46.414), train_loss = 0.81053773, grad/param norm = 2.2441e-01, time/batch = 0.6926s	
26457/28500 (epoch 46.416), train_loss = 0.70664176, grad/param norm = 1.8174e-01, time/batch = 0.6939s	
26458/28500 (epoch 46.418), train_loss = 0.80397062, grad/param norm = 1.9202e-01, time/batch = 0.6923s	
26459/28500 (epoch 46.419), train_loss = 0.89700454, grad/param norm = 2.3242e-01, time/batch = 0.6927s	
26460/28500 (epoch 46.421), train_loss = 0.84967448, grad/param norm = 2.0996e-01, time/batch = 0.6930s	
26461/28500 (epoch 46.423), train_loss = 0.83526468, grad/param norm = 2.0886e-01, time/batch = 0.6949s	
26462/28500 (epoch 46.425), train_loss = 0.75271733, grad/param norm = 2.3408e-01, time/batch = 0.6930s	
26463/28500 (epoch 46.426), train_loss = 0.79181139, grad/param norm = 2.3753e-01, time/batch = 0.6980s	
26464/28500 (epoch 46.428), train_loss = 0.94310251, grad/param norm = 2.1262e-01, time/batch = 0.6946s	
26465/28500 (epoch 46.430), train_loss = 0.92427968, grad/param norm = 2.0015e-01, time/batch = 0.6916s	
26466/28500 (epoch 46.432), train_loss = 0.82322478, grad/param norm = 2.0952e-01, time/batch = 0.6941s	
26467/28500 (epoch 46.433), train_loss = 0.86614885, grad/param norm = 2.1144e-01, time/batch = 0.6920s	
26468/28500 (epoch 46.435), train_loss = 0.81319399, grad/param norm = 2.3495e-01, time/batch = 0.6940s	
26469/28500 (epoch 46.437), train_loss = 0.75496352, grad/param norm = 1.9987e-01, time/batch = 0.6928s	
26470/28500 (epoch 46.439), train_loss = 0.80337327, grad/param norm = 1.9064e-01, time/batch = 0.6931s	
26471/28500 (epoch 46.440), train_loss = 0.93616914, grad/param norm = 1.9429e-01, time/batch = 0.6959s	
26472/28500 (epoch 46.442), train_loss = 0.73758338, grad/param norm = 1.9331e-01, time/batch = 0.6954s	
26473/28500 (epoch 46.444), train_loss = 0.71057145, grad/param norm = 1.5341e-01, time/batch = 0.6919s	
26474/28500 (epoch 46.446), train_loss = 0.68505131, grad/param norm = 1.8079e-01, time/batch = 0.6952s	
26475/28500 (epoch 46.447), train_loss = 0.67673454, grad/param norm = 1.8188e-01, time/batch = 0.6955s	
26476/28500 (epoch 46.449), train_loss = 0.76154064, grad/param norm = 2.0618e-01, time/batch = 0.6940s	
26477/28500 (epoch 46.451), train_loss = 0.75777906, grad/param norm = 1.8130e-01, time/batch = 0.6953s	
26478/28500 (epoch 46.453), train_loss = 0.75319735, grad/param norm = 1.8498e-01, time/batch = 0.7039s	
26479/28500 (epoch 46.454), train_loss = 0.70354412, grad/param norm = 1.7673e-01, time/batch = 0.6928s	
26480/28500 (epoch 46.456), train_loss = 0.84049414, grad/param norm = 2.2537e-01, time/batch = 0.6931s	
26481/28500 (epoch 46.458), train_loss = 0.74335927, grad/param norm = 1.9934e-01, time/batch = 0.6959s	
26482/28500 (epoch 46.460), train_loss = 0.87079893, grad/param norm = 2.1936e-01, time/batch = 0.6942s	
26483/28500 (epoch 46.461), train_loss = 0.69968197, grad/param norm = 1.9721e-01, time/batch = 0.6952s	
26484/28500 (epoch 46.463), train_loss = 0.65072896, grad/param norm = 1.5834e-01, time/batch = 0.6941s	
26485/28500 (epoch 46.465), train_loss = 0.61958937, grad/param norm = 1.9558e-01, time/batch = 0.6933s	
26486/28500 (epoch 46.467), train_loss = 0.77907021, grad/param norm = 1.8319e-01, time/batch = 0.6922s	
26487/28500 (epoch 46.468), train_loss = 0.70616907, grad/param norm = 1.7724e-01, time/batch = 0.6930s	
26488/28500 (epoch 46.470), train_loss = 0.72528937, grad/param norm = 1.9609e-01, time/batch = 0.6923s	
26489/28500 (epoch 46.472), train_loss = 0.69475848, grad/param norm = 1.8603e-01, time/batch = 0.6930s	
26490/28500 (epoch 46.474), train_loss = 0.90536625, grad/param norm = 2.0907e-01, time/batch = 0.6963s	
26491/28500 (epoch 46.475), train_loss = 0.73240275, grad/param norm = 2.0579e-01, time/batch = 0.6955s	
26492/28500 (epoch 46.477), train_loss = 0.77535228, grad/param norm = 1.9034e-01, time/batch = 0.6940s	
26493/28500 (epoch 46.479), train_loss = 0.82104884, grad/param norm = 1.9686e-01, time/batch = 0.6934s	
26494/28500 (epoch 46.481), train_loss = 0.82461269, grad/param norm = 2.2431e-01, time/batch = 0.6924s	
26495/28500 (epoch 46.482), train_loss = 0.67765677, grad/param norm = 1.8172e-01, time/batch = 0.6913s	
26496/28500 (epoch 46.484), train_loss = 0.71482682, grad/param norm = 1.7410e-01, time/batch = 0.6923s	
26497/28500 (epoch 46.486), train_loss = 0.64280992, grad/param norm = 2.0173e-01, time/batch = 0.6915s	
26498/28500 (epoch 46.488), train_loss = 0.80504939, grad/param norm = 2.0447e-01, time/batch = 0.6929s	
26499/28500 (epoch 46.489), train_loss = 0.91542170, grad/param norm = 2.1123e-01, time/batch = 0.6919s	
26500/28500 (epoch 46.491), train_loss = 0.72633859, grad/param norm = 1.9038e-01, time/batch = 0.6946s	
26501/28500 (epoch 46.493), train_loss = 0.75168424, grad/param norm = 1.8591e-01, time/batch = 0.6964s	
26502/28500 (epoch 46.495), train_loss = 0.78101959, grad/param norm = 1.9826e-01, time/batch = 0.6944s	
26503/28500 (epoch 46.496), train_loss = 0.69896449, grad/param norm = 2.4036e-01, time/batch = 0.6950s	
26504/28500 (epoch 46.498), train_loss = 0.79078680, grad/param norm = 2.0049e-01, time/batch = 0.6931s	
26505/28500 (epoch 46.500), train_loss = 0.72235489, grad/param norm = 1.8072e-01, time/batch = 0.6957s	
26506/28500 (epoch 46.502), train_loss = 0.79422467, grad/param norm = 1.7471e-01, time/batch = 0.6914s	
26507/28500 (epoch 46.504), train_loss = 0.85989561, grad/param norm = 1.9610e-01, time/batch = 0.6937s	
26508/28500 (epoch 46.505), train_loss = 0.72081742, grad/param norm = 1.8241e-01, time/batch = 0.6912s	
26509/28500 (epoch 46.507), train_loss = 0.85233643, grad/param norm = 2.6278e-01, time/batch = 0.6943s	
26510/28500 (epoch 46.509), train_loss = 0.75276662, grad/param norm = 1.6205e-01, time/batch = 0.6935s	
26511/28500 (epoch 46.511), train_loss = 0.77197311, grad/param norm = 1.9503e-01, time/batch = 0.6995s	
26512/28500 (epoch 46.512), train_loss = 0.83318640, grad/param norm = 1.8613e-01, time/batch = 0.7124s	
26513/28500 (epoch 46.514), train_loss = 0.74878838, grad/param norm = 1.8303e-01, time/batch = 0.7113s	
26514/28500 (epoch 46.516), train_loss = 0.78122378, grad/param norm = 1.7891e-01, time/batch = 0.6984s	
26515/28500 (epoch 46.518), train_loss = 0.82317438, grad/param norm = 2.1619e-01, time/batch = 0.6947s	
26516/28500 (epoch 46.519), train_loss = 0.80615431, grad/param norm = 1.8214e-01, time/batch = 0.6933s	
26517/28500 (epoch 46.521), train_loss = 0.89184365, grad/param norm = 2.3746e-01, time/batch = 0.6961s	
26518/28500 (epoch 46.523), train_loss = 0.83758685, grad/param norm = 2.1984e-01, time/batch = 0.6896s	
26519/28500 (epoch 46.525), train_loss = 0.88529195, grad/param norm = 2.0893e-01, time/batch = 0.6892s	
26520/28500 (epoch 46.526), train_loss = 0.80504610, grad/param norm = 1.9808e-01, time/batch = 0.7055s	
26521/28500 (epoch 46.528), train_loss = 0.83657747, grad/param norm = 2.4484e-01, time/batch = 0.6928s	
26522/28500 (epoch 46.530), train_loss = 0.81268030, grad/param norm = 2.0331e-01, time/batch = 0.6954s	
26523/28500 (epoch 46.532), train_loss = 0.77359899, grad/param norm = 1.9868e-01, time/batch = 0.6900s	
26524/28500 (epoch 46.533), train_loss = 0.81215693, grad/param norm = 1.9498e-01, time/batch = 0.6894s	
26525/28500 (epoch 46.535), train_loss = 0.69217479, grad/param norm = 1.8565e-01, time/batch = 0.6904s	
26526/28500 (epoch 46.537), train_loss = 0.66214028, grad/param norm = 1.9017e-01, time/batch = 0.6899s	
26527/28500 (epoch 46.539), train_loss = 0.67594858, grad/param norm = 2.0467e-01, time/batch = 0.6902s	
26528/28500 (epoch 46.540), train_loss = 0.75159490, grad/param norm = 1.8467e-01, time/batch = 0.6892s	
26529/28500 (epoch 46.542), train_loss = 0.80837911, grad/param norm = 2.4890e-01, time/batch = 0.6899s	
26530/28500 (epoch 46.544), train_loss = 0.89854063, grad/param norm = 2.0740e-01, time/batch = 0.6897s	
26531/28500 (epoch 46.546), train_loss = 0.78421750, grad/param norm = 2.0956e-01, time/batch = 0.6938s	
26532/28500 (epoch 46.547), train_loss = 0.74925312, grad/param norm = 1.8002e-01, time/batch = 0.6918s	
26533/28500 (epoch 46.549), train_loss = 0.66293215, grad/param norm = 1.8115e-01, time/batch = 0.6937s	
26534/28500 (epoch 46.551), train_loss = 0.71873703, grad/param norm = 2.1602e-01, time/batch = 0.6907s	
26535/28500 (epoch 46.553), train_loss = 0.92824292, grad/param norm = 2.5942e-01, time/batch = 0.6909s	
26536/28500 (epoch 46.554), train_loss = 0.81298743, grad/param norm = 2.0063e-01, time/batch = 0.6914s	
26537/28500 (epoch 46.556), train_loss = 0.81851629, grad/param norm = 2.1986e-01, time/batch = 0.6897s	
26538/28500 (epoch 46.558), train_loss = 0.82849015, grad/param norm = 1.7871e-01, time/batch = 0.6894s	
26539/28500 (epoch 46.560), train_loss = 0.84076218, grad/param norm = 1.9882e-01, time/batch = 0.6894s	
26540/28500 (epoch 46.561), train_loss = 0.85182724, grad/param norm = 2.1213e-01, time/batch = 0.6897s	
26541/28500 (epoch 46.563), train_loss = 0.91647252, grad/param norm = 2.1455e-01, time/batch = 0.6922s	
26542/28500 (epoch 46.565), train_loss = 0.75569013, grad/param norm = 2.4883e-01, time/batch = 0.6906s	
26543/28500 (epoch 46.567), train_loss = 0.66641357, grad/param norm = 1.6845e-01, time/batch = 0.6896s	
26544/28500 (epoch 46.568), train_loss = 0.79894315, grad/param norm = 1.9294e-01, time/batch = 0.7025s	
26545/28500 (epoch 46.570), train_loss = 0.75122479, grad/param norm = 1.9660e-01, time/batch = 0.6966s	
26546/28500 (epoch 46.572), train_loss = 0.79703967, grad/param norm = 1.7747e-01, time/batch = 0.6944s	
26547/28500 (epoch 46.574), train_loss = 0.73649890, grad/param norm = 1.7595e-01, time/batch = 0.6950s	
26548/28500 (epoch 46.575), train_loss = 0.73343079, grad/param norm = 1.8105e-01, time/batch = 0.6895s	
26549/28500 (epoch 46.577), train_loss = 0.85137718, grad/param norm = 2.0407e-01, time/batch = 0.6900s	
26550/28500 (epoch 46.579), train_loss = 0.85734275, grad/param norm = 2.2128e-01, time/batch = 0.6918s	
26551/28500 (epoch 46.581), train_loss = 0.72461016, grad/param norm = 2.0692e-01, time/batch = 0.6921s	
26552/28500 (epoch 46.582), train_loss = 0.90232730, grad/param norm = 2.3819e-01, time/batch = 0.6899s	
26553/28500 (epoch 46.584), train_loss = 0.75051454, grad/param norm = 1.9499e-01, time/batch = 0.6898s	
26554/28500 (epoch 46.586), train_loss = 0.72146557, grad/param norm = 1.7718e-01, time/batch = 0.6926s	
26555/28500 (epoch 46.588), train_loss = 0.73385342, grad/param norm = 2.0959e-01, time/batch = 0.6932s	
26556/28500 (epoch 46.589), train_loss = 0.76752879, grad/param norm = 2.0288e-01, time/batch = 0.6888s	
26557/28500 (epoch 46.591), train_loss = 0.79372887, grad/param norm = 2.2054e-01, time/batch = 0.6895s	
26558/28500 (epoch 46.593), train_loss = 0.72231697, grad/param norm = 1.6472e-01, time/batch = 0.6890s	
26559/28500 (epoch 46.595), train_loss = 0.92626565, grad/param norm = 2.0334e-01, time/batch = 0.6891s	
26560/28500 (epoch 46.596), train_loss = 0.94109314, grad/param norm = 2.1555e-01, time/batch = 0.6926s	
26561/28500 (epoch 46.598), train_loss = 0.76592373, grad/param norm = 2.0214e-01, time/batch = 0.6961s	
26562/28500 (epoch 46.600), train_loss = 0.75380041, grad/param norm = 1.9677e-01, time/batch = 0.6899s	
26563/28500 (epoch 46.602), train_loss = 0.84620651, grad/param norm = 2.0328e-01, time/batch = 0.6979s	
26564/28500 (epoch 46.604), train_loss = 0.87839734, grad/param norm = 1.7910e-01, time/batch = 0.7129s	
26565/28500 (epoch 46.605), train_loss = 0.86864668, grad/param norm = 1.8039e-01, time/batch = 0.6949s	
26566/28500 (epoch 46.607), train_loss = 0.90846625, grad/param norm = 1.8803e-01, time/batch = 0.6920s	
26567/28500 (epoch 46.609), train_loss = 0.80060259, grad/param norm = 1.8105e-01, time/batch = 0.6909s	
26568/28500 (epoch 46.611), train_loss = 0.78194015, grad/param norm = 1.9857e-01, time/batch = 0.6911s	
26569/28500 (epoch 46.612), train_loss = 0.84445301, grad/param norm = 2.0915e-01, time/batch = 0.6896s	
26570/28500 (epoch 46.614), train_loss = 0.89747416, grad/param norm = 2.2291e-01, time/batch = 0.6898s	
26571/28500 (epoch 46.616), train_loss = 0.77546526, grad/param norm = 2.1675e-01, time/batch = 0.6927s	
26572/28500 (epoch 46.618), train_loss = 0.77301040, grad/param norm = 2.0140e-01, time/batch = 0.6929s	
26573/28500 (epoch 46.619), train_loss = 0.87075048, grad/param norm = 2.3911e-01, time/batch = 0.6896s	
26574/28500 (epoch 46.621), train_loss = 0.63497989, grad/param norm = 1.7818e-01, time/batch = 0.6909s	
26575/28500 (epoch 46.623), train_loss = 0.91783444, grad/param norm = 2.0891e-01, time/batch = 0.6920s	
26576/28500 (epoch 46.625), train_loss = 0.71019113, grad/param norm = 2.1218e-01, time/batch = 0.6969s	
26577/28500 (epoch 46.626), train_loss = 0.64837141, grad/param norm = 1.8145e-01, time/batch = 0.6966s	
26578/28500 (epoch 46.628), train_loss = 0.72196623, grad/param norm = 1.8629e-01, time/batch = 0.7191s	
26579/28500 (epoch 46.630), train_loss = 0.69096324, grad/param norm = 1.6265e-01, time/batch = 0.7074s	
26580/28500 (epoch 46.632), train_loss = 0.89666210, grad/param norm = 2.0875e-01, time/batch = 0.6934s	
26581/28500 (epoch 46.633), train_loss = 0.90144018, grad/param norm = 1.7486e-01, time/batch = 0.6970s	
26582/28500 (epoch 46.635), train_loss = 0.83276955, grad/param norm = 2.1081e-01, time/batch = 0.6921s	
26583/28500 (epoch 46.637), train_loss = 0.78989268, grad/param norm = 1.8945e-01, time/batch = 0.6940s	
26584/28500 (epoch 46.639), train_loss = 0.70356087, grad/param norm = 2.0184e-01, time/batch = 0.6955s	
26585/28500 (epoch 46.640), train_loss = 0.75112705, grad/param norm = 1.8722e-01, time/batch = 0.6996s	
26586/28500 (epoch 46.642), train_loss = 0.73999783, grad/param norm = 2.0828e-01, time/batch = 0.6953s	
26587/28500 (epoch 46.644), train_loss = 0.82126399, grad/param norm = 2.7502e-01, time/batch = 0.6931s	
26588/28500 (epoch 46.646), train_loss = 0.64555525, grad/param norm = 1.6343e-01, time/batch = 0.6941s	
26589/28500 (epoch 46.647), train_loss = 0.74171113, grad/param norm = 2.0649e-01, time/batch = 0.6938s	
26590/28500 (epoch 46.649), train_loss = 0.73067508, grad/param norm = 2.5209e-01, time/batch = 0.7096s	
26591/28500 (epoch 46.651), train_loss = 0.69152009, grad/param norm = 1.8668e-01, time/batch = 0.7127s	
26592/28500 (epoch 46.653), train_loss = 0.68599174, grad/param norm = 1.7719e-01, time/batch = 0.7073s	
26593/28500 (epoch 46.654), train_loss = 0.70721358, grad/param norm = 1.9105e-01, time/batch = 0.6976s	
26594/28500 (epoch 46.656), train_loss = 0.64919932, grad/param norm = 1.7585e-01, time/batch = 0.6957s	
26595/28500 (epoch 46.658), train_loss = 0.78557782, grad/param norm = 2.1768e-01, time/batch = 0.6983s	
26596/28500 (epoch 46.660), train_loss = 0.76847392, grad/param norm = 1.7381e-01, time/batch = 0.6996s	
26597/28500 (epoch 46.661), train_loss = 0.86878605, grad/param norm = 2.0086e-01, time/batch = 0.7039s	
26598/28500 (epoch 46.663), train_loss = 0.89393966, grad/param norm = 2.6383e-01, time/batch = 0.7135s	
26599/28500 (epoch 46.665), train_loss = 0.78203643, grad/param norm = 1.9992e-01, time/batch = 0.7089s	
26600/28500 (epoch 46.667), train_loss = 0.81470177, grad/param norm = 1.9580e-01, time/batch = 0.7176s	
26601/28500 (epoch 46.668), train_loss = 0.78298455, grad/param norm = 1.8653e-01, time/batch = 0.7095s	
26602/28500 (epoch 46.670), train_loss = 0.79571583, grad/param norm = 1.8848e-01, time/batch = 0.7073s	
26603/28500 (epoch 46.672), train_loss = 0.70602016, grad/param norm = 1.7369e-01, time/batch = 0.7048s	
26604/28500 (epoch 46.674), train_loss = 0.63585849, grad/param norm = 2.0612e-01, time/batch = 0.6981s	
26605/28500 (epoch 46.675), train_loss = 0.68328628, grad/param norm = 1.8531e-01, time/batch = 0.6980s	
26606/28500 (epoch 46.677), train_loss = 0.73557027, grad/param norm = 1.6346e-01, time/batch = 0.6996s	
26607/28500 (epoch 46.679), train_loss = 0.75125029, grad/param norm = 1.9968e-01, time/batch = 0.7048s	
26608/28500 (epoch 46.681), train_loss = 0.81209175, grad/param norm = 2.0641e-01, time/batch = 0.7073s	
26609/28500 (epoch 46.682), train_loss = 0.74188877, grad/param norm = 1.8738e-01, time/batch = 0.7081s	
26610/28500 (epoch 46.684), train_loss = 0.78000923, grad/param norm = 2.0031e-01, time/batch = 0.6978s	
26611/28500 (epoch 46.686), train_loss = 0.73186416, grad/param norm = 1.8530e-01, time/batch = 0.7047s	
26612/28500 (epoch 46.688), train_loss = 0.71270379, grad/param norm = 1.5106e-01, time/batch = 0.6962s	
26613/28500 (epoch 46.689), train_loss = 0.70775056, grad/param norm = 1.9602e-01, time/batch = 0.7004s	
26614/28500 (epoch 46.691), train_loss = 0.81327519, grad/param norm = 1.9770e-01, time/batch = 0.7097s	
26615/28500 (epoch 46.693), train_loss = 0.75165543, grad/param norm = 2.1065e-01, time/batch = 0.7053s	
26616/28500 (epoch 46.695), train_loss = 0.56342246, grad/param norm = 1.6726e-01, time/batch = 0.7157s	
26617/28500 (epoch 46.696), train_loss = 0.72575790, grad/param norm = 2.1103e-01, time/batch = 0.7013s	
26618/28500 (epoch 46.698), train_loss = 0.81910507, grad/param norm = 1.8833e-01, time/batch = 0.7110s	
26619/28500 (epoch 46.700), train_loss = 0.77470011, grad/param norm = 2.0400e-01, time/batch = 0.6996s	
26620/28500 (epoch 46.702), train_loss = 0.73944861, grad/param norm = 2.2096e-01, time/batch = 0.7046s	
26621/28500 (epoch 46.704), train_loss = 0.83898890, grad/param norm = 2.1878e-01, time/batch = 0.6804s	
26622/28500 (epoch 46.705), train_loss = 0.85283294, grad/param norm = 3.4283e-01, time/batch = 0.6786s	
26623/28500 (epoch 46.707), train_loss = 0.73278569, grad/param norm = 2.5373e-01, time/batch = 0.6779s	
26624/28500 (epoch 46.709), train_loss = 0.90693050, grad/param norm = 2.7211e-01, time/batch = 0.6811s	
26625/28500 (epoch 46.711), train_loss = 0.74306503, grad/param norm = 1.9601e-01, time/batch = 0.6791s	
26626/28500 (epoch 46.712), train_loss = 0.81569757, grad/param norm = 1.8950e-01, time/batch = 0.6827s	
26627/28500 (epoch 46.714), train_loss = 0.90235301, grad/param norm = 2.3530e-01, time/batch = 0.6841s	
26628/28500 (epoch 46.716), train_loss = 0.75093068, grad/param norm = 1.8326e-01, time/batch = 0.6830s	
26629/28500 (epoch 46.718), train_loss = 0.81890060, grad/param norm = 2.0232e-01, time/batch = 0.6823s	
26630/28500 (epoch 46.719), train_loss = 0.80445660, grad/param norm = 1.8229e-01, time/batch = 0.6838s	
26631/28500 (epoch 46.721), train_loss = 0.60169959, grad/param norm = 1.7734e-01, time/batch = 0.6856s	
26632/28500 (epoch 46.723), train_loss = 0.77647148, grad/param norm = 1.9420e-01, time/batch = 0.6831s	
26633/28500 (epoch 46.725), train_loss = 0.84657364, grad/param norm = 2.4455e-01, time/batch = 0.6848s	
26634/28500 (epoch 46.726), train_loss = 0.76747598, grad/param norm = 2.0200e-01, time/batch = 0.6890s	
26635/28500 (epoch 46.728), train_loss = 0.69351052, grad/param norm = 1.8228e-01, time/batch = 0.6860s	
26636/28500 (epoch 46.730), train_loss = 0.77419556, grad/param norm = 2.1262e-01, time/batch = 0.6858s	
26637/28500 (epoch 46.732), train_loss = 0.62616546, grad/param norm = 1.7284e-01, time/batch = 0.6911s	
26638/28500 (epoch 46.733), train_loss = 0.65989947, grad/param norm = 1.7699e-01, time/batch = 0.6911s	
26639/28500 (epoch 46.735), train_loss = 0.66188595, grad/param norm = 1.7052e-01, time/batch = 0.6899s	
26640/28500 (epoch 46.737), train_loss = 0.59625779, grad/param norm = 1.6364e-01, time/batch = 0.6864s	
26641/28500 (epoch 46.739), train_loss = 0.67012695, grad/param norm = 2.0759e-01, time/batch = 0.6914s	
26642/28500 (epoch 46.740), train_loss = 0.75245442, grad/param norm = 1.7851e-01, time/batch = 0.6896s	
26643/28500 (epoch 46.742), train_loss = 0.69648852, grad/param norm = 2.0877e-01, time/batch = 0.6879s	
26644/28500 (epoch 46.744), train_loss = 0.76039426, grad/param norm = 1.8979e-01, time/batch = 0.6905s	
26645/28500 (epoch 46.746), train_loss = 0.73261148, grad/param norm = 1.5678e-01, time/batch = 0.6870s	
26646/28500 (epoch 46.747), train_loss = 0.73238438, grad/param norm = 1.7634e-01, time/batch = 0.6845s	
26647/28500 (epoch 46.749), train_loss = 0.81460185, grad/param norm = 2.1644e-01, time/batch = 0.6848s	
26648/28500 (epoch 46.751), train_loss = 0.68803363, grad/param norm = 2.1455e-01, time/batch = 0.6830s	
26649/28500 (epoch 46.753), train_loss = 0.78368758, grad/param norm = 1.6697e-01, time/batch = 0.6822s	
26650/28500 (epoch 46.754), train_loss = 0.67528707, grad/param norm = 2.1888e-01, time/batch = 0.6906s	
26651/28500 (epoch 46.756), train_loss = 0.88246059, grad/param norm = 1.9414e-01, time/batch = 0.6925s	
26652/28500 (epoch 46.758), train_loss = 0.81944405, grad/param norm = 2.1830e-01, time/batch = 0.6848s	
26653/28500 (epoch 46.760), train_loss = 0.67876667, grad/param norm = 1.9379e-01, time/batch = 0.6838s	
26654/28500 (epoch 46.761), train_loss = 0.74135880, grad/param norm = 2.5763e-01, time/batch = 0.6827s	
26655/28500 (epoch 46.763), train_loss = 0.60727685, grad/param norm = 1.9218e-01, time/batch = 0.6867s	
26656/28500 (epoch 46.765), train_loss = 0.75343763, grad/param norm = 1.7045e-01, time/batch = 0.6853s	
26657/28500 (epoch 46.767), train_loss = 0.61192184, grad/param norm = 1.7065e-01, time/batch = 0.6803s	
26658/28500 (epoch 46.768), train_loss = 0.79982575, grad/param norm = 1.9682e-01, time/batch = 0.6778s	
26659/28500 (epoch 46.770), train_loss = 0.65680909, grad/param norm = 1.7863e-01, time/batch = 0.6808s	
26660/28500 (epoch 46.772), train_loss = 0.63489012, grad/param norm = 1.5750e-01, time/batch = 0.6862s	
26661/28500 (epoch 46.774), train_loss = 0.75440479, grad/param norm = 1.8993e-01, time/batch = 0.6842s	
26662/28500 (epoch 46.775), train_loss = 0.79393427, grad/param norm = 1.9497e-01, time/batch = 0.6929s	
26663/28500 (epoch 46.777), train_loss = 0.83452787, grad/param norm = 1.7948e-01, time/batch = 0.6888s	
26664/28500 (epoch 46.779), train_loss = 0.64911020, grad/param norm = 1.6555e-01, time/batch = 0.6929s	
26665/28500 (epoch 46.781), train_loss = 0.73736474, grad/param norm = 1.8219e-01, time/batch = 0.6902s	
26666/28500 (epoch 46.782), train_loss = 0.77786168, grad/param norm = 1.9262e-01, time/batch = 0.6806s	
26667/28500 (epoch 46.784), train_loss = 0.61580496, grad/param norm = 1.9741e-01, time/batch = 0.6776s	
26668/28500 (epoch 46.786), train_loss = 0.63304325, grad/param norm = 1.9012e-01, time/batch = 0.6865s	
26669/28500 (epoch 46.788), train_loss = 0.70399670, grad/param norm = 2.0885e-01, time/batch = 0.6779s	
26670/28500 (epoch 46.789), train_loss = 0.56485993, grad/param norm = 2.8347e-01, time/batch = 0.6768s	
26671/28500 (epoch 46.791), train_loss = 0.77753275, grad/param norm = 1.7170e-01, time/batch = 0.6795s	
26672/28500 (epoch 46.793), train_loss = 0.72983067, grad/param norm = 1.9424e-01, time/batch = 0.6778s	
26673/28500 (epoch 46.795), train_loss = 0.75382084, grad/param norm = 1.8404e-01, time/batch = 0.6771s	
26674/28500 (epoch 46.796), train_loss = 0.69109850, grad/param norm = 1.7219e-01, time/batch = 0.6788s	
26675/28500 (epoch 46.798), train_loss = 0.63000924, grad/param norm = 1.8266e-01, time/batch = 0.6786s	
26676/28500 (epoch 46.800), train_loss = 0.62741322, grad/param norm = 2.8747e-01, time/batch = 0.6774s	
26677/28500 (epoch 46.802), train_loss = 0.74154847, grad/param norm = 2.9078e-01, time/batch = 0.6765s	
26678/28500 (epoch 46.804), train_loss = 0.77665438, grad/param norm = 1.8776e-01, time/batch = 0.6763s	
26679/28500 (epoch 46.805), train_loss = 0.79263652, grad/param norm = 2.0267e-01, time/batch = 0.6764s	
26680/28500 (epoch 46.807), train_loss = 0.76927308, grad/param norm = 2.0011e-01, time/batch = 0.6776s	
26681/28500 (epoch 46.809), train_loss = 0.76386937, grad/param norm = 4.5875e-01, time/batch = 0.6797s	
26682/28500 (epoch 46.811), train_loss = 0.75673773, grad/param norm = 2.0691e-01, time/batch = 0.6799s	
26683/28500 (epoch 46.812), train_loss = 0.73468451, grad/param norm = 2.6448e-01, time/batch = 0.6835s	
26684/28500 (epoch 46.814), train_loss = 0.71442653, grad/param norm = 1.9964e-01, time/batch = 0.6996s	
26685/28500 (epoch 46.816), train_loss = 0.77326048, grad/param norm = 2.1547e-01, time/batch = 0.6853s	
26686/28500 (epoch 46.818), train_loss = 0.87016622, grad/param norm = 2.1058e-01, time/batch = 0.6823s	
26687/28500 (epoch 46.819), train_loss = 0.76837071, grad/param norm = 2.1155e-01, time/batch = 0.6894s	
26688/28500 (epoch 46.821), train_loss = 0.74830208, grad/param norm = 2.0271e-01, time/batch = 0.6814s	
26689/28500 (epoch 46.823), train_loss = 0.87031568, grad/param norm = 2.2479e-01, time/batch = 0.6826s	
26690/28500 (epoch 46.825), train_loss = 0.66687541, grad/param norm = 2.2304e-01, time/batch = 0.6888s	
26691/28500 (epoch 46.826), train_loss = 0.77194318, grad/param norm = 2.1829e-01, time/batch = 0.6873s	
26692/28500 (epoch 46.828), train_loss = 0.69910604, grad/param norm = 2.1095e-01, time/batch = 0.6858s	
26693/28500 (epoch 46.830), train_loss = 0.71529353, grad/param norm = 1.8321e-01, time/batch = 0.6830s	
26694/28500 (epoch 46.832), train_loss = 0.74240863, grad/param norm = 2.4015e-01, time/batch = 0.6897s	
26695/28500 (epoch 46.833), train_loss = 0.78884703, grad/param norm = 2.1598e-01, time/batch = 0.6846s	
26696/28500 (epoch 46.835), train_loss = 0.72862545, grad/param norm = 1.9496e-01, time/batch = 0.6831s	
26697/28500 (epoch 46.837), train_loss = 0.63830932, grad/param norm = 1.8258e-01, time/batch = 0.6825s	
26698/28500 (epoch 46.839), train_loss = 0.91424420, grad/param norm = 3.3528e-01, time/batch = 0.6825s	
26699/28500 (epoch 46.840), train_loss = 0.90748530, grad/param norm = 2.3495e-01, time/batch = 0.6891s	
26700/28500 (epoch 46.842), train_loss = 0.84076827, grad/param norm = 2.7868e-01, time/batch = 0.6795s	
26701/28500 (epoch 46.844), train_loss = 0.85347078, grad/param norm = 2.0922e-01, time/batch = 0.6814s	
26702/28500 (epoch 46.846), train_loss = 0.91702260, grad/param norm = 2.8687e-01, time/batch = 0.6823s	
26703/28500 (epoch 46.847), train_loss = 0.73953728, grad/param norm = 2.3841e-01, time/batch = 0.6813s	
26704/28500 (epoch 46.849), train_loss = 0.71807351, grad/param norm = 1.7873e-01, time/batch = 0.6805s	
26705/28500 (epoch 46.851), train_loss = 0.71340558, grad/param norm = 1.7407e-01, time/batch = 0.6792s	
26706/28500 (epoch 46.853), train_loss = 0.81204632, grad/param norm = 2.0440e-01, time/batch = 0.6802s	
26707/28500 (epoch 46.854), train_loss = 0.77505410, grad/param norm = 1.9889e-01, time/batch = 0.6796s	
26708/28500 (epoch 46.856), train_loss = 0.85530922, grad/param norm = 2.4103e-01, time/batch = 0.6831s	
26709/28500 (epoch 46.858), train_loss = 0.73352343, grad/param norm = 1.8389e-01, time/batch = 0.6789s	
26710/28500 (epoch 46.860), train_loss = 0.76845969, grad/param norm = 2.1369e-01, time/batch = 0.6792s	
26711/28500 (epoch 46.861), train_loss = 0.85955411, grad/param norm = 2.2038e-01, time/batch = 0.6816s	
26712/28500 (epoch 46.863), train_loss = 0.81087648, grad/param norm = 2.4024e-01, time/batch = 0.6811s	
26713/28500 (epoch 46.865), train_loss = 0.72609601, grad/param norm = 2.2251e-01, time/batch = 0.6832s	
26714/28500 (epoch 46.867), train_loss = 0.79316887, grad/param norm = 2.5500e-01, time/batch = 0.6824s	
26715/28500 (epoch 46.868), train_loss = 0.68071314, grad/param norm = 1.8366e-01, time/batch = 0.6822s	
26716/28500 (epoch 46.870), train_loss = 0.65613222, grad/param norm = 1.7769e-01, time/batch = 0.6823s	
26717/28500 (epoch 46.872), train_loss = 0.85098392, grad/param norm = 2.8164e-01, time/batch = 0.6802s	
26718/28500 (epoch 46.874), train_loss = 0.69996937, grad/param norm = 2.1858e-01, time/batch = 0.6789s	
26719/28500 (epoch 46.875), train_loss = 0.92245878, grad/param norm = 2.5267e-01, time/batch = 0.6792s	
26720/28500 (epoch 46.877), train_loss = 0.80684036, grad/param norm = 2.1277e-01, time/batch = 0.6792s	
26721/28500 (epoch 46.879), train_loss = 0.80114343, grad/param norm = 1.6340e-01, time/batch = 0.6817s	
26722/28500 (epoch 46.881), train_loss = 0.80178097, grad/param norm = 2.1522e-01, time/batch = 0.6802s	
26723/28500 (epoch 46.882), train_loss = 0.70255095, grad/param norm = 2.0232e-01, time/batch = 0.6790s	
26724/28500 (epoch 46.884), train_loss = 0.72622713, grad/param norm = 1.9922e-01, time/batch = 0.6804s	
26725/28500 (epoch 46.886), train_loss = 0.69981554, grad/param norm = 2.0066e-01, time/batch = 0.6814s	
26726/28500 (epoch 46.888), train_loss = 0.73844177, grad/param norm = 1.6574e-01, time/batch = 0.6819s	
26727/28500 (epoch 46.889), train_loss = 0.79063330, grad/param norm = 1.7705e-01, time/batch = 0.6799s	
26728/28500 (epoch 46.891), train_loss = 0.77340819, grad/param norm = 1.8463e-01, time/batch = 0.6813s	
26729/28500 (epoch 46.893), train_loss = 0.72476363, grad/param norm = 1.7907e-01, time/batch = 0.6927s	
26730/28500 (epoch 46.895), train_loss = 0.88710297, grad/param norm = 2.5226e-01, time/batch = 0.6796s	
26731/28500 (epoch 46.896), train_loss = 0.85839685, grad/param norm = 1.9948e-01, time/batch = 0.6821s	
26732/28500 (epoch 46.898), train_loss = 0.84234672, grad/param norm = 1.8601e-01, time/batch = 0.6808s	
26733/28500 (epoch 46.900), train_loss = 0.66988225, grad/param norm = 1.6503e-01, time/batch = 0.6790s	
26734/28500 (epoch 46.902), train_loss = 0.63615419, grad/param norm = 1.7017e-01, time/batch = 0.6820s	
26735/28500 (epoch 46.904), train_loss = 0.68984717, grad/param norm = 1.6841e-01, time/batch = 0.6816s	
26736/28500 (epoch 46.905), train_loss = 0.72791341, grad/param norm = 2.2023e-01, time/batch = 0.6806s	
26737/28500 (epoch 46.907), train_loss = 0.74901162, grad/param norm = 1.9404e-01, time/batch = 0.6794s	
26738/28500 (epoch 46.909), train_loss = 0.62163281, grad/param norm = 2.2685e-01, time/batch = 0.6796s	
26739/28500 (epoch 46.911), train_loss = 0.67485114, grad/param norm = 1.7906e-01, time/batch = 0.6806s	
26740/28500 (epoch 46.912), train_loss = 0.56953845, grad/param norm = 1.7206e-01, time/batch = 0.6817s	
26741/28500 (epoch 46.914), train_loss = 0.77999149, grad/param norm = 1.8296e-01, time/batch = 0.6836s	
26742/28500 (epoch 46.916), train_loss = 0.78329396, grad/param norm = 2.4150e-01, time/batch = 0.6811s	
26743/28500 (epoch 46.918), train_loss = 0.74782265, grad/param norm = 1.8948e-01, time/batch = 0.6801s	
26744/28500 (epoch 46.919), train_loss = 0.78924724, grad/param norm = 1.8908e-01, time/batch = 0.6807s	
26745/28500 (epoch 46.921), train_loss = 0.84842140, grad/param norm = 2.3497e-01, time/batch = 0.6811s	
26746/28500 (epoch 46.923), train_loss = 0.69538515, grad/param norm = 2.6572e-01, time/batch = 0.6826s	
26747/28500 (epoch 46.925), train_loss = 0.71683087, grad/param norm = 2.0597e-01, time/batch = 0.6795s	
26748/28500 (epoch 46.926), train_loss = 0.77036771, grad/param norm = 1.8849e-01, time/batch = 0.6796s	
26749/28500 (epoch 46.928), train_loss = 0.72769718, grad/param norm = 2.1945e-01, time/batch = 0.6805s	
26750/28500 (epoch 46.930), train_loss = 0.61433108, grad/param norm = 1.8392e-01, time/batch = 0.6789s	
26751/28500 (epoch 46.932), train_loss = 0.62171550, grad/param norm = 1.5755e-01, time/batch = 0.6810s	
26752/28500 (epoch 46.933), train_loss = 0.82418742, grad/param norm = 1.8993e-01, time/batch = 0.6811s	
26753/28500 (epoch 46.935), train_loss = 0.82764762, grad/param norm = 1.8517e-01, time/batch = 0.6786s	
26754/28500 (epoch 46.937), train_loss = 0.81166400, grad/param norm = 2.8047e-01, time/batch = 0.6801s	
26755/28500 (epoch 46.939), train_loss = 0.88598418, grad/param norm = 2.2823e-01, time/batch = 0.6786s	
26756/28500 (epoch 46.940), train_loss = 0.61794742, grad/param norm = 1.8105e-01, time/batch = 0.6884s	
26757/28500 (epoch 46.942), train_loss = 0.77985338, grad/param norm = 2.7072e-01, time/batch = 0.6799s	
26758/28500 (epoch 46.944), train_loss = 0.74181856, grad/param norm = 2.4640e-01, time/batch = 0.6810s	
26759/28500 (epoch 46.946), train_loss = 0.82215472, grad/param norm = 2.0670e-01, time/batch = 0.6802s	
26760/28500 (epoch 46.947), train_loss = 0.97287219, grad/param norm = 2.9942e-01, time/batch = 0.6793s	
26761/28500 (epoch 46.949), train_loss = 0.74670651, grad/param norm = 2.6065e-01, time/batch = 0.6834s	
26762/28500 (epoch 46.951), train_loss = 0.91054527, grad/param norm = 2.6075e-01, time/batch = 0.6807s	
26763/28500 (epoch 46.953), train_loss = 0.91088036, grad/param norm = 2.1199e-01, time/batch = 0.6795s	
26764/28500 (epoch 46.954), train_loss = 0.85613619, grad/param norm = 2.2651e-01, time/batch = 0.6800s	
26765/28500 (epoch 46.956), train_loss = 0.79571063, grad/param norm = 4.0139e-01, time/batch = 0.6804s	
26766/28500 (epoch 46.958), train_loss = 0.98716716, grad/param norm = 2.3852e-01, time/batch = 0.6806s	
26767/28500 (epoch 46.960), train_loss = 0.71189212, grad/param norm = 2.0050e-01, time/batch = 0.6820s	
26768/28500 (epoch 46.961), train_loss = 0.93107457, grad/param norm = 2.5121e-01, time/batch = 0.6808s	
26769/28500 (epoch 46.963), train_loss = 0.85154680, grad/param norm = 2.0483e-01, time/batch = 0.6846s	
26770/28500 (epoch 46.965), train_loss = 0.70301730, grad/param norm = 1.8992e-01, time/batch = 0.6809s	
26771/28500 (epoch 46.967), train_loss = 0.71822590, grad/param norm = 2.1437e-01, time/batch = 0.6843s	
26772/28500 (epoch 46.968), train_loss = 0.68049317, grad/param norm = 1.5671e-01, time/batch = 0.6897s	
26773/28500 (epoch 46.970), train_loss = 0.70377839, grad/param norm = 2.1451e-01, time/batch = 0.6839s	
26774/28500 (epoch 46.972), train_loss = 0.77816575, grad/param norm = 2.2819e-01, time/batch = 0.6827s	
26775/28500 (epoch 46.974), train_loss = 0.98680464, grad/param norm = 3.0178e-01, time/batch = 0.6809s	
26776/28500 (epoch 46.975), train_loss = 0.71822457, grad/param norm = 2.2524e-01, time/batch = 0.6817s	
26777/28500 (epoch 46.977), train_loss = 0.86111912, grad/param norm = 2.4891e-01, time/batch = 0.6830s	
26778/28500 (epoch 46.979), train_loss = 0.80588959, grad/param norm = 1.9962e-01, time/batch = 0.6804s	
26779/28500 (epoch 46.981), train_loss = 0.66229947, grad/param norm = 1.9266e-01, time/batch = 0.6818s	
26780/28500 (epoch 46.982), train_loss = 0.77234929, grad/param norm = 2.1214e-01, time/batch = 0.6838s	
26781/28500 (epoch 46.984), train_loss = 0.83627646, grad/param norm = 1.9848e-01, time/batch = 0.6846s	
26782/28500 (epoch 46.986), train_loss = 0.98595245, grad/param norm = 2.4489e-01, time/batch = 0.6814s	
26783/28500 (epoch 46.988), train_loss = 0.70912080, grad/param norm = 2.1048e-01, time/batch = 0.6816s	
26784/28500 (epoch 46.989), train_loss = 0.78493387, grad/param norm = 2.2609e-01, time/batch = 0.6802s	
26785/28500 (epoch 46.991), train_loss = 0.68524102, grad/param norm = 2.0532e-01, time/batch = 0.6807s	
26786/28500 (epoch 46.993), train_loss = 0.71354020, grad/param norm = 2.2181e-01, time/batch = 0.6811s	
26787/28500 (epoch 46.995), train_loss = 0.75067027, grad/param norm = 2.3659e-01, time/batch = 0.6802s	
26788/28500 (epoch 46.996), train_loss = 0.67449617, grad/param norm = 2.0398e-01, time/batch = 0.6801s	
26789/28500 (epoch 46.998), train_loss = 0.90388386, grad/param norm = 2.9206e-01, time/batch = 0.6808s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
26790/28500 (epoch 47.000), train_loss = 0.74301495, grad/param norm = 1.8890e-01, time/batch = 0.6808s	
26791/28500 (epoch 47.002), train_loss = 0.93348436, grad/param norm = 2.1710e-01, time/batch = 0.6811s	
26792/28500 (epoch 47.004), train_loss = 0.79284649, grad/param norm = 1.8814e-01, time/batch = 0.6833s	
26793/28500 (epoch 47.005), train_loss = 0.87123229, grad/param norm = 1.9826e-01, time/batch = 0.6779s	
26794/28500 (epoch 47.007), train_loss = 0.70499420, grad/param norm = 2.2712e-01, time/batch = 0.6909s	
26795/28500 (epoch 47.009), train_loss = 0.78715242, grad/param norm = 2.0921e-01, time/batch = 0.6872s	
26796/28500 (epoch 47.011), train_loss = 0.70942522, grad/param norm = 1.7260e-01, time/batch = 0.6829s	
26797/28500 (epoch 47.012), train_loss = 0.71860121, grad/param norm = 1.8806e-01, time/batch = 0.6810s	
26798/28500 (epoch 47.014), train_loss = 0.69595251, grad/param norm = 1.7185e-01, time/batch = 0.6783s	
26799/28500 (epoch 47.016), train_loss = 0.76305288, grad/param norm = 1.8156e-01, time/batch = 0.6828s	
26800/28500 (epoch 47.018), train_loss = 0.79321986, grad/param norm = 1.9697e-01, time/batch = 0.6813s	
26801/28500 (epoch 47.019), train_loss = 0.87231084, grad/param norm = 2.0934e-01, time/batch = 0.6795s	
26802/28500 (epoch 47.021), train_loss = 0.88743148, grad/param norm = 1.9371e-01, time/batch = 0.6781s	
26803/28500 (epoch 47.023), train_loss = 0.78055085, grad/param norm = 1.9653e-01, time/batch = 0.6773s	
26804/28500 (epoch 47.025), train_loss = 0.81132616, grad/param norm = 1.8676e-01, time/batch = 0.6813s	
26805/28500 (epoch 47.026), train_loss = 0.72499263, grad/param norm = 1.8101e-01, time/batch = 0.6831s	
26806/28500 (epoch 47.028), train_loss = 0.76609159, grad/param norm = 2.0332e-01, time/batch = 0.6818s	
26807/28500 (epoch 47.030), train_loss = 0.79520743, grad/param norm = 2.2569e-01, time/batch = 0.6785s	
26808/28500 (epoch 47.032), train_loss = 0.87971891, grad/param norm = 1.8535e-01, time/batch = 0.6763s	
26809/28500 (epoch 47.033), train_loss = 0.91319885, grad/param norm = 1.9643e-01, time/batch = 0.6757s	
26810/28500 (epoch 47.035), train_loss = 0.75863705, grad/param norm = 2.3580e-01, time/batch = 0.6796s	
26811/28500 (epoch 47.037), train_loss = 0.86338449, grad/param norm = 2.4002e-01, time/batch = 0.6810s	
26812/28500 (epoch 47.039), train_loss = 0.86925637, grad/param norm = 1.9481e-01, time/batch = 0.6784s	
26813/28500 (epoch 47.040), train_loss = 0.87919588, grad/param norm = 1.9862e-01, time/batch = 0.6773s	
26814/28500 (epoch 47.042), train_loss = 0.84834109, grad/param norm = 2.0171e-01, time/batch = 0.7032s	
26815/28500 (epoch 47.044), train_loss = 0.77753929, grad/param norm = 2.1178e-01, time/batch = 0.6870s	
26816/28500 (epoch 47.046), train_loss = 0.98443906, grad/param norm = 2.3694e-01, time/batch = 0.6782s	
26817/28500 (epoch 47.047), train_loss = 0.90326202, grad/param norm = 2.4201e-01, time/batch = 0.6770s	
26818/28500 (epoch 47.049), train_loss = 0.81444855, grad/param norm = 2.0701e-01, time/batch = 0.6756s	
26819/28500 (epoch 47.051), train_loss = 0.77866928, grad/param norm = 2.0350e-01, time/batch = 0.6759s	
26820/28500 (epoch 47.053), train_loss = 0.75701780, grad/param norm = 2.2023e-01, time/batch = 0.6759s	
26821/28500 (epoch 47.054), train_loss = 0.85619339, grad/param norm = 2.0596e-01, time/batch = 0.6780s	
26822/28500 (epoch 47.056), train_loss = 0.75142883, grad/param norm = 1.9952e-01, time/batch = 0.6766s	
26823/28500 (epoch 47.058), train_loss = 0.73250362, grad/param norm = 2.0816e-01, time/batch = 0.6777s	
26824/28500 (epoch 47.060), train_loss = 0.86118303, grad/param norm = 2.3030e-01, time/batch = 0.6785s	
26825/28500 (epoch 47.061), train_loss = 0.76096327, grad/param norm = 1.9279e-01, time/batch = 0.6764s	
26826/28500 (epoch 47.063), train_loss = 0.81412887, grad/param norm = 2.2038e-01, time/batch = 0.6773s	
26827/28500 (epoch 47.065), train_loss = 0.79181319, grad/param norm = 2.0582e-01, time/batch = 0.6815s	
26828/28500 (epoch 47.067), train_loss = 0.72809323, grad/param norm = 1.8884e-01, time/batch = 0.6785s	
26829/28500 (epoch 47.068), train_loss = 0.75683714, grad/param norm = 1.9742e-01, time/batch = 0.6773s	
26830/28500 (epoch 47.070), train_loss = 0.81534541, grad/param norm = 1.9863e-01, time/batch = 0.6764s	
26831/28500 (epoch 47.072), train_loss = 0.91518024, grad/param norm = 2.6604e-01, time/batch = 0.6777s	
26832/28500 (epoch 47.074), train_loss = 0.78334781, grad/param norm = 2.1857e-01, time/batch = 0.6979s	
26833/28500 (epoch 47.075), train_loss = 0.78462202, grad/param norm = 1.9995e-01, time/batch = 0.6804s	
26834/28500 (epoch 47.077), train_loss = 0.82587064, grad/param norm = 1.8018e-01, time/batch = 0.6764s	
26835/28500 (epoch 47.079), train_loss = 0.80760776, grad/param norm = 1.8055e-01, time/batch = 0.6764s	
26836/28500 (epoch 47.081), train_loss = 0.87304631, grad/param norm = 2.3972e-01, time/batch = 0.6768s	
26837/28500 (epoch 47.082), train_loss = 0.75307196, grad/param norm = 2.7533e-01, time/batch = 0.6759s	
26838/28500 (epoch 47.084), train_loss = 0.77209381, grad/param norm = 2.1881e-01, time/batch = 0.6786s	
26839/28500 (epoch 47.086), train_loss = 0.73287895, grad/param norm = 1.9207e-01, time/batch = 0.6780s	
26840/28500 (epoch 47.088), train_loss = 0.69430596, grad/param norm = 1.8654e-01, time/batch = 0.6773s	
26841/28500 (epoch 47.089), train_loss = 0.84484210, grad/param norm = 2.0032e-01, time/batch = 0.6793s	
26842/28500 (epoch 47.091), train_loss = 0.70269878, grad/param norm = 1.8452e-01, time/batch = 0.6799s	
26843/28500 (epoch 47.093), train_loss = 0.87114376, grad/param norm = 2.0848e-01, time/batch = 0.6793s	
26844/28500 (epoch 47.095), train_loss = 0.79509117, grad/param norm = 1.8866e-01, time/batch = 0.6787s	
26845/28500 (epoch 47.096), train_loss = 0.87455992, grad/param norm = 2.0283e-01, time/batch = 0.6758s	
26846/28500 (epoch 47.098), train_loss = 0.78815689, grad/param norm = 3.2587e-01, time/batch = 0.6780s	
26847/28500 (epoch 47.100), train_loss = 0.76411795, grad/param norm = 1.9581e-01, time/batch = 0.6803s	
26848/28500 (epoch 47.102), train_loss = 0.87931517, grad/param norm = 2.2805e-01, time/batch = 0.6798s	
26849/28500 (epoch 47.104), train_loss = 0.82002078, grad/param norm = 2.2486e-01, time/batch = 0.6756s	
26850/28500 (epoch 47.105), train_loss = 0.86821183, grad/param norm = 1.8123e-01, time/batch = 0.6751s	
26851/28500 (epoch 47.107), train_loss = 0.71385296, grad/param norm = 1.8266e-01, time/batch = 0.6814s	
26852/28500 (epoch 47.109), train_loss = 0.73767529, grad/param norm = 2.1146e-01, time/batch = 0.6772s	
26853/28500 (epoch 47.111), train_loss = 0.77443623, grad/param norm = 2.1585e-01, time/batch = 0.6774s	
26854/28500 (epoch 47.112), train_loss = 0.87316756, grad/param norm = 2.0616e-01, time/batch = 0.6762s	
26855/28500 (epoch 47.114), train_loss = 0.78579153, grad/param norm = 2.0606e-01, time/batch = 0.6766s	
26856/28500 (epoch 47.116), train_loss = 0.93065076, grad/param norm = 2.3605e-01, time/batch = 0.6788s	
26857/28500 (epoch 47.118), train_loss = 0.72813710, grad/param norm = 2.0045e-01, time/batch = 0.6823s	
26858/28500 (epoch 47.119), train_loss = 0.82707901, grad/param norm = 2.3547e-01, time/batch = 0.6790s	
26859/28500 (epoch 47.121), train_loss = 0.93912505, grad/param norm = 2.6232e-01, time/batch = 0.6906s	
26860/28500 (epoch 47.123), train_loss = 0.89877173, grad/param norm = 2.1368e-01, time/batch = 0.6994s	
26861/28500 (epoch 47.125), train_loss = 0.80556842, grad/param norm = 1.8897e-01, time/batch = 0.7042s	
26862/28500 (epoch 47.126), train_loss = 0.81679529, grad/param norm = 2.0979e-01, time/batch = 0.7025s	
26863/28500 (epoch 47.128), train_loss = 0.80706987, grad/param norm = 1.6957e-01, time/batch = 0.7056s	
26864/28500 (epoch 47.130), train_loss = 0.76004388, grad/param norm = 2.1160e-01, time/batch = 0.6912s	
26865/28500 (epoch 47.132), train_loss = 0.79237345, grad/param norm = 2.4173e-01, time/batch = 0.6915s	
26866/28500 (epoch 47.133), train_loss = 0.86370135, grad/param norm = 2.3825e-01, time/batch = 0.6906s	
26867/28500 (epoch 47.135), train_loss = 0.75631190, grad/param norm = 1.9289e-01, time/batch = 0.6960s	
26868/28500 (epoch 47.137), train_loss = 0.79692847, grad/param norm = 1.8862e-01, time/batch = 0.6927s	
26869/28500 (epoch 47.139), train_loss = 0.81284544, grad/param norm = 2.2283e-01, time/batch = 0.7050s	
26870/28500 (epoch 47.140), train_loss = 0.80062883, grad/param norm = 2.0006e-01, time/batch = 0.6954s	
26871/28500 (epoch 47.142), train_loss = 0.74830903, grad/param norm = 2.0053e-01, time/batch = 0.6947s	
26872/28500 (epoch 47.144), train_loss = 0.70644833, grad/param norm = 1.9745e-01, time/batch = 0.6976s	
26873/28500 (epoch 47.146), train_loss = 0.76822240, grad/param norm = 1.8757e-01, time/batch = 0.6985s	
26874/28500 (epoch 47.147), train_loss = 0.67561253, grad/param norm = 1.8133e-01, time/batch = 0.6926s	
26875/28500 (epoch 47.149), train_loss = 0.68967287, grad/param norm = 1.6758e-01, time/batch = 0.6933s	
26876/28500 (epoch 47.151), train_loss = 0.75327264, grad/param norm = 1.9932e-01, time/batch = 0.6948s	
26877/28500 (epoch 47.153), train_loss = 0.79471778, grad/param norm = 1.7767e-01, time/batch = 0.6963s	
26878/28500 (epoch 47.154), train_loss = 0.66745636, grad/param norm = 1.8265e-01, time/batch = 0.7005s	
26879/28500 (epoch 47.156), train_loss = 0.85954167, grad/param norm = 2.4777e-01, time/batch = 0.6974s	
26880/28500 (epoch 47.158), train_loss = 0.80731525, grad/param norm = 1.8749e-01, time/batch = 0.7083s	
26881/28500 (epoch 47.160), train_loss = 0.71626230, grad/param norm = 1.9110e-01, time/batch = 0.6959s	
26882/28500 (epoch 47.161), train_loss = 0.72729389, grad/param norm = 2.0539e-01, time/batch = 0.6992s	
26883/28500 (epoch 47.163), train_loss = 0.68687476, grad/param norm = 3.6603e-01, time/batch = 0.6928s	
26884/28500 (epoch 47.165), train_loss = 0.90312810, grad/param norm = 1.8957e-01, time/batch = 0.6983s	
26885/28500 (epoch 47.167), train_loss = 0.91440753, grad/param norm = 2.3029e-01, time/batch = 0.6997s	
26886/28500 (epoch 47.168), train_loss = 0.88400762, grad/param norm = 2.2952e-01, time/batch = 0.6950s	
26887/28500 (epoch 47.170), train_loss = 0.89438392, grad/param norm = 2.3716e-01, time/batch = 0.6923s	
26888/28500 (epoch 47.172), train_loss = 0.75496222, grad/param norm = 1.6928e-01, time/batch = 0.6940s	
26889/28500 (epoch 47.174), train_loss = 0.92620891, grad/param norm = 2.2259e-01, time/batch = 0.6952s	
26890/28500 (epoch 47.175), train_loss = 0.77869767, grad/param norm = 1.9922e-01, time/batch = 0.6950s	
26891/28500 (epoch 47.177), train_loss = 0.80700433, grad/param norm = 2.0244e-01, time/batch = 0.6954s	
26892/28500 (epoch 47.179), train_loss = 0.83818250, grad/param norm = 1.8244e-01, time/batch = 0.6955s	
26893/28500 (epoch 47.181), train_loss = 0.79166969, grad/param norm = 2.4877e-01, time/batch = 0.6959s	
26894/28500 (epoch 47.182), train_loss = 0.74520977, grad/param norm = 1.9901e-01, time/batch = 0.6935s	
26895/28500 (epoch 47.184), train_loss = 0.94811099, grad/param norm = 2.1485e-01, time/batch = 0.6919s	
26896/28500 (epoch 47.186), train_loss = 0.94414688, grad/param norm = 2.2877e-01, time/batch = 0.6932s	
26897/28500 (epoch 47.188), train_loss = 0.83962199, grad/param norm = 2.0719e-01, time/batch = 0.6958s	
26898/28500 (epoch 47.189), train_loss = 0.79228899, grad/param norm = 1.7554e-01, time/batch = 0.6996s	
26899/28500 (epoch 47.191), train_loss = 0.95679134, grad/param norm = 2.3158e-01, time/batch = 0.6969s	
26900/28500 (epoch 47.193), train_loss = 0.77973244, grad/param norm = 2.3355e-01, time/batch = 0.6974s	
26901/28500 (epoch 47.195), train_loss = 0.93237535, grad/param norm = 2.4529e-01, time/batch = 0.7086s	
26902/28500 (epoch 47.196), train_loss = 0.82766010, grad/param norm = 2.0101e-01, time/batch = 0.7002s	
26903/28500 (epoch 47.198), train_loss = 0.81136662, grad/param norm = 1.9168e-01, time/batch = 0.6993s	
26904/28500 (epoch 47.200), train_loss = 0.89793913, grad/param norm = 2.3984e-01, time/batch = 0.7037s	
26905/28500 (epoch 47.202), train_loss = 0.82808283, grad/param norm = 1.7622e-01, time/batch = 0.6968s	
26906/28500 (epoch 47.204), train_loss = 0.78580110, grad/param norm = 1.8732e-01, time/batch = 0.6915s	
26907/28500 (epoch 47.205), train_loss = 0.73825951, grad/param norm = 1.9178e-01, time/batch = 0.6898s	
26908/28500 (epoch 47.207), train_loss = 0.66613491, grad/param norm = 1.8590e-01, time/batch = 0.7003s	
26909/28500 (epoch 47.209), train_loss = 0.80412826, grad/param norm = 2.1791e-01, time/batch = 0.6980s	
26910/28500 (epoch 47.211), train_loss = 0.73272604, grad/param norm = 2.0900e-01, time/batch = 0.6899s	
26911/28500 (epoch 47.212), train_loss = 0.67307457, grad/param norm = 1.8625e-01, time/batch = 0.6917s	
26912/28500 (epoch 47.214), train_loss = 0.78992537, grad/param norm = 2.1288e-01, time/batch = 0.6916s	
26913/28500 (epoch 47.216), train_loss = 0.72723814, grad/param norm = 2.0585e-01, time/batch = 0.6960s	
26914/28500 (epoch 47.218), train_loss = 0.90573558, grad/param norm = 1.8627e-01, time/batch = 0.6925s	
26915/28500 (epoch 47.219), train_loss = 0.81418980, grad/param norm = 1.8961e-01, time/batch = 0.6894s	
26916/28500 (epoch 47.221), train_loss = 0.69956460, grad/param norm = 1.8789e-01, time/batch = 0.6898s	
26917/28500 (epoch 47.223), train_loss = 0.86210978, grad/param norm = 1.9058e-01, time/batch = 0.6893s	
26918/28500 (epoch 47.225), train_loss = 0.93793766, grad/param norm = 2.5008e-01, time/batch = 0.6891s	
26919/28500 (epoch 47.226), train_loss = 0.77007958, grad/param norm = 1.9527e-01, time/batch = 0.6942s	
26920/28500 (epoch 47.228), train_loss = 0.91612065, grad/param norm = 2.5729e-01, time/batch = 0.6921s	
26921/28500 (epoch 47.230), train_loss = 0.87086325, grad/param norm = 2.1522e-01, time/batch = 0.6933s	
26922/28500 (epoch 47.232), train_loss = 0.85644063, grad/param norm = 2.4058e-01, time/batch = 0.6910s	
26923/28500 (epoch 47.233), train_loss = 0.80533754, grad/param norm = 2.2210e-01, time/batch = 0.6901s	
26924/28500 (epoch 47.235), train_loss = 0.80224420, grad/param norm = 1.7453e-01, time/batch = 0.6906s	
26925/28500 (epoch 47.237), train_loss = 0.74019870, grad/param norm = 1.8601e-01, time/batch = 0.6896s	
26926/28500 (epoch 47.239), train_loss = 0.76178043, grad/param norm = 2.0207e-01, time/batch = 0.6892s	
26927/28500 (epoch 47.240), train_loss = 0.70798904, grad/param norm = 2.5503e-01, time/batch = 0.6991s	
26928/28500 (epoch 47.242), train_loss = 0.72548793, grad/param norm = 2.0186e-01, time/batch = 0.6969s	
26929/28500 (epoch 47.244), train_loss = 0.81147416, grad/param norm = 1.7353e-01, time/batch = 0.6935s	
26930/28500 (epoch 47.246), train_loss = 0.83727658, grad/param norm = 2.0447e-01, time/batch = 0.6940s	
26931/28500 (epoch 47.247), train_loss = 0.89635964, grad/param norm = 2.2601e-01, time/batch = 0.6965s	
26932/28500 (epoch 47.249), train_loss = 0.76478686, grad/param norm = 1.8185e-01, time/batch = 0.6932s	
26933/28500 (epoch 47.251), train_loss = 0.79466496, grad/param norm = 1.8352e-01, time/batch = 0.6898s	
26934/28500 (epoch 47.253), train_loss = 0.91484209, grad/param norm = 2.3370e-01, time/batch = 0.6894s	
26935/28500 (epoch 47.254), train_loss = 0.92348788, grad/param norm = 2.1759e-01, time/batch = 0.6895s	
26936/28500 (epoch 47.256), train_loss = 0.79855967, grad/param norm = 2.4136e-01, time/batch = 0.6915s	
26937/28500 (epoch 47.258), train_loss = 0.78237300, grad/param norm = 1.9534e-01, time/batch = 0.6920s	
26938/28500 (epoch 47.260), train_loss = 0.78685916, grad/param norm = 1.8453e-01, time/batch = 0.6923s	
26939/28500 (epoch 47.261), train_loss = 0.69333156, grad/param norm = 1.8412e-01, time/batch = 0.6889s	
26940/28500 (epoch 47.263), train_loss = 0.84506946, grad/param norm = 2.1400e-01, time/batch = 0.6904s	
26941/28500 (epoch 47.265), train_loss = 0.73542958, grad/param norm = 1.9172e-01, time/batch = 0.6938s	
26942/28500 (epoch 47.267), train_loss = 0.95999092, grad/param norm = 2.5626e-01, time/batch = 0.6916s	
26943/28500 (epoch 47.268), train_loss = 0.81453940, grad/param norm = 1.9448e-01, time/batch = 0.6907s	
26944/28500 (epoch 47.270), train_loss = 0.78778150, grad/param norm = 1.9326e-01, time/batch = 0.6929s	
26945/28500 (epoch 47.272), train_loss = 0.79682986, grad/param norm = 2.1612e-01, time/batch = 0.7005s	
26946/28500 (epoch 47.274), train_loss = 0.85726946, grad/param norm = 2.0898e-01, time/batch = 0.7073s	
26947/28500 (epoch 47.275), train_loss = 0.86241469, grad/param norm = 1.9286e-01, time/batch = 0.6917s	
26948/28500 (epoch 47.277), train_loss = 0.78248986, grad/param norm = 1.9996e-01, time/batch = 0.6950s	
26949/28500 (epoch 47.279), train_loss = 0.84109840, grad/param norm = 2.1920e-01, time/batch = 0.6928s	
26950/28500 (epoch 47.281), train_loss = 0.83877236, grad/param norm = 2.4745e-01, time/batch = 0.6942s	
26951/28500 (epoch 47.282), train_loss = 0.82441870, grad/param norm = 1.8424e-01, time/batch = 0.7030s	
26952/28500 (epoch 47.284), train_loss = 0.84157631, grad/param norm = 2.3296e-01, time/batch = 0.7082s	
26953/28500 (epoch 47.286), train_loss = 0.89324707, grad/param norm = 2.2729e-01, time/batch = 0.7022s	
26954/28500 (epoch 47.288), train_loss = 0.82044228, grad/param norm = 2.1805e-01, time/batch = 0.7026s	
26955/28500 (epoch 47.289), train_loss = 0.81314711, grad/param norm = 1.9601e-01, time/batch = 0.7040s	
26956/28500 (epoch 47.291), train_loss = 0.81256147, grad/param norm = 1.9583e-01, time/batch = 0.7082s	
26957/28500 (epoch 47.293), train_loss = 0.80211959, grad/param norm = 1.9873e-01, time/batch = 0.7113s	
26958/28500 (epoch 47.295), train_loss = 0.70698429, grad/param norm = 1.7894e-01, time/batch = 0.7170s	
26959/28500 (epoch 47.296), train_loss = 0.70713045, grad/param norm = 2.0475e-01, time/batch = 0.7101s	
26960/28500 (epoch 47.298), train_loss = 0.85291841, grad/param norm = 1.8305e-01, time/batch = 0.7070s	
26961/28500 (epoch 47.300), train_loss = 0.72394180, grad/param norm = 1.9957e-01, time/batch = 0.6992s	
26962/28500 (epoch 47.302), train_loss = 0.68728650, grad/param norm = 1.8326e-01, time/batch = 0.6923s	
26963/28500 (epoch 47.304), train_loss = 0.79178652, grad/param norm = 2.0521e-01, time/batch = 0.6914s	
26964/28500 (epoch 47.305), train_loss = 0.86120689, grad/param norm = 2.1890e-01, time/batch = 0.6999s	
26965/28500 (epoch 47.307), train_loss = 0.77167798, grad/param norm = 1.8083e-01, time/batch = 0.6926s	
26966/28500 (epoch 47.309), train_loss = 0.79517288, grad/param norm = 1.9132e-01, time/batch = 0.6918s	
26967/28500 (epoch 47.311), train_loss = 0.84937919, grad/param norm = 2.5198e-01, time/batch = 0.6895s	
26968/28500 (epoch 47.312), train_loss = 0.83592329, grad/param norm = 2.1361e-01, time/batch = 0.6941s	
26969/28500 (epoch 47.314), train_loss = 0.80096166, grad/param norm = 1.9030e-01, time/batch = 0.6939s	
26970/28500 (epoch 47.316), train_loss = 0.82483161, grad/param norm = 2.1074e-01, time/batch = 0.6906s	
26971/28500 (epoch 47.318), train_loss = 0.85476208, grad/param norm = 1.8974e-01, time/batch = 0.6960s	
26972/28500 (epoch 47.319), train_loss = 0.74705409, grad/param norm = 2.1156e-01, time/batch = 0.6924s	
26973/28500 (epoch 47.321), train_loss = 0.75617495, grad/param norm = 2.1226e-01, time/batch = 0.6941s	
26974/28500 (epoch 47.323), train_loss = 0.80747814, grad/param norm = 1.9242e-01, time/batch = 0.6895s	
26975/28500 (epoch 47.325), train_loss = 0.88370515, grad/param norm = 1.8983e-01, time/batch = 0.6891s	
26976/28500 (epoch 47.326), train_loss = 0.82854752, grad/param norm = 1.9995e-01, time/batch = 0.6892s	
26977/28500 (epoch 47.328), train_loss = 0.65511627, grad/param norm = 1.5927e-01, time/batch = 0.6894s	
26978/28500 (epoch 47.330), train_loss = 0.73557776, grad/param norm = 1.9330e-01, time/batch = 0.6942s	
26979/28500 (epoch 47.332), train_loss = 0.74333291, grad/param norm = 2.0094e-01, time/batch = 0.6932s	
26980/28500 (epoch 47.333), train_loss = 0.61491679, grad/param norm = 2.0558e-01, time/batch = 0.6891s	
26981/28500 (epoch 47.335), train_loss = 0.71216187, grad/param norm = 1.9209e-01, time/batch = 0.6924s	
26982/28500 (epoch 47.337), train_loss = 0.64999186, grad/param norm = 1.8548e-01, time/batch = 0.7053s	
26983/28500 (epoch 47.339), train_loss = 0.64297413, grad/param norm = 1.5546e-01, time/batch = 0.7022s	
26984/28500 (epoch 47.340), train_loss = 0.75964857, grad/param norm = 2.2276e-01, time/batch = 0.6902s	
26985/28500 (epoch 47.342), train_loss = 0.79211146, grad/param norm = 1.9369e-01, time/batch = 0.6899s	
26986/28500 (epoch 47.344), train_loss = 0.67494863, grad/param norm = 1.9219e-01, time/batch = 0.6909s	
26987/28500 (epoch 47.346), train_loss = 0.67277748, grad/param norm = 1.5905e-01, time/batch = 0.6910s	
26988/28500 (epoch 47.347), train_loss = 0.79048663, grad/param norm = 1.6328e-01, time/batch = 0.6899s	
26989/28500 (epoch 47.349), train_loss = 0.77745480, grad/param norm = 1.9896e-01, time/batch = 0.6944s	
26990/28500 (epoch 47.351), train_loss = 0.70121134, grad/param norm = 1.9937e-01, time/batch = 0.6930s	
26991/28500 (epoch 47.353), train_loss = 0.81094275, grad/param norm = 2.1607e-01, time/batch = 0.6919s	
26992/28500 (epoch 47.354), train_loss = 0.68279042, grad/param norm = 2.1208e-01, time/batch = 0.6903s	
26993/28500 (epoch 47.356), train_loss = 0.73043047, grad/param norm = 1.6827e-01, time/batch = 0.6996s	
26994/28500 (epoch 47.358), train_loss = 0.80847895, grad/param norm = 1.7816e-01, time/batch = 0.6892s	
26995/28500 (epoch 47.360), train_loss = 0.78843222, grad/param norm = 2.1538e-01, time/batch = 0.6926s	
26996/28500 (epoch 47.361), train_loss = 0.69826074, grad/param norm = 1.7667e-01, time/batch = 0.6901s	
26997/28500 (epoch 47.363), train_loss = 0.68387787, grad/param norm = 1.6252e-01, time/batch = 0.6893s	
26998/28500 (epoch 47.365), train_loss = 0.73761787, grad/param norm = 2.2537e-01, time/batch = 0.6891s	
26999/28500 (epoch 47.367), train_loss = 0.76040178, grad/param norm = 1.9473e-01, time/batch = 0.6892s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch47.37_2.0413.t7	
27000/28500 (epoch 47.368), train_loss = 0.69859407, grad/param norm = 1.8076e-01, time/batch = 0.6891s	
27001/28500 (epoch 47.370), train_loss = 1.26802911, grad/param norm = 3.1491e-01, time/batch = 0.7115s	
27002/28500 (epoch 47.372), train_loss = 0.62183364, grad/param norm = 1.9620e-01, time/batch = 0.6941s	
27003/28500 (epoch 47.374), train_loss = 0.75580662, grad/param norm = 2.0440e-01, time/batch = 0.6938s	
27004/28500 (epoch 47.375), train_loss = 0.88962624, grad/param norm = 2.2458e-01, time/batch = 0.6899s	
27005/28500 (epoch 47.377), train_loss = 0.73568047, grad/param norm = 2.3006e-01, time/batch = 0.6922s	
27006/28500 (epoch 47.379), train_loss = 0.62408551, grad/param norm = 1.8688e-01, time/batch = 0.6947s	
27007/28500 (epoch 47.381), train_loss = 0.75050348, grad/param norm = 1.9703e-01, time/batch = 0.6934s	
27008/28500 (epoch 47.382), train_loss = 0.71855397, grad/param norm = 1.8612e-01, time/batch = 0.6968s	
27009/28500 (epoch 47.384), train_loss = 0.64138953, grad/param norm = 1.9697e-01, time/batch = 0.6929s	
27010/28500 (epoch 47.386), train_loss = 0.68614039, grad/param norm = 1.6887e-01, time/batch = 0.6987s	
27011/28500 (epoch 47.388), train_loss = 0.82705856, grad/param norm = 2.1301e-01, time/batch = 0.6965s	
27012/28500 (epoch 47.389), train_loss = 0.69590891, grad/param norm = 1.9910e-01, time/batch = 0.7042s	
27013/28500 (epoch 47.391), train_loss = 0.68275675, grad/param norm = 2.2502e-01, time/batch = 0.6918s	
27014/28500 (epoch 47.393), train_loss = 0.69635506, grad/param norm = 2.1016e-01, time/batch = 0.6919s	
27015/28500 (epoch 47.395), train_loss = 0.84876107, grad/param norm = 2.0132e-01, time/batch = 0.6912s	
27016/28500 (epoch 47.396), train_loss = 0.84185205, grad/param norm = 2.0326e-01, time/batch = 0.6973s	
27017/28500 (epoch 47.398), train_loss = 0.58290684, grad/param norm = 1.8523e-01, time/batch = 0.6968s	
27018/28500 (epoch 47.400), train_loss = 0.72148976, grad/param norm = 2.3042e-01, time/batch = 0.6910s	
27019/28500 (epoch 47.402), train_loss = 0.78095740, grad/param norm = 2.0289e-01, time/batch = 0.6950s	
27020/28500 (epoch 47.404), train_loss = 0.77424105, grad/param norm = 2.2083e-01, time/batch = 0.6960s	
27021/28500 (epoch 47.405), train_loss = 0.83956467, grad/param norm = 2.0860e-01, time/batch = 0.6971s	
27022/28500 (epoch 47.407), train_loss = 0.76503198, grad/param norm = 1.8160e-01, time/batch = 0.6967s	
27023/28500 (epoch 47.409), train_loss = 0.75121730, grad/param norm = 1.9504e-01, time/batch = 0.7016s	
27024/28500 (epoch 47.411), train_loss = 0.85776969, grad/param norm = 2.4117e-01, time/batch = 0.6933s	
27025/28500 (epoch 47.412), train_loss = 0.88445463, grad/param norm = 2.1405e-01, time/batch = 0.7093s	
27026/28500 (epoch 47.414), train_loss = 0.78390279, grad/param norm = 2.1322e-01, time/batch = 0.7080s	
27027/28500 (epoch 47.416), train_loss = 0.70688100, grad/param norm = 1.8596e-01, time/batch = 0.6966s	
27028/28500 (epoch 47.418), train_loss = 0.79570627, grad/param norm = 1.9171e-01, time/batch = 0.6945s	
27029/28500 (epoch 47.419), train_loss = 0.88586419, grad/param norm = 2.2636e-01, time/batch = 0.6904s	
27030/28500 (epoch 47.421), train_loss = 0.85385219, grad/param norm = 2.1217e-01, time/batch = 0.6904s	
27031/28500 (epoch 47.423), train_loss = 0.81866074, grad/param norm = 2.1680e-01, time/batch = 0.7014s	
27032/28500 (epoch 47.425), train_loss = 0.77241745, grad/param norm = 3.2355e-01, time/batch = 0.6901s	
27033/28500 (epoch 47.426), train_loss = 0.79097384, grad/param norm = 2.1594e-01, time/batch = 0.6895s	
27034/28500 (epoch 47.428), train_loss = 0.96332487, grad/param norm = 2.5699e-01, time/batch = 0.6887s	
27035/28500 (epoch 47.430), train_loss = 0.93065576, grad/param norm = 2.2084e-01, time/batch = 0.6898s	
27036/28500 (epoch 47.432), train_loss = 0.81904533, grad/param norm = 2.0135e-01, time/batch = 0.6938s	
27037/28500 (epoch 47.433), train_loss = 0.86515666, grad/param norm = 2.5747e-01, time/batch = 0.6888s	
27038/28500 (epoch 47.435), train_loss = 0.80445959, grad/param norm = 1.9721e-01, time/batch = 0.6887s	
27039/28500 (epoch 47.437), train_loss = 0.74043756, grad/param norm = 1.7161e-01, time/batch = 0.6896s	
27040/28500 (epoch 47.439), train_loss = 0.80331353, grad/param norm = 1.8882e-01, time/batch = 0.6890s	
27041/28500 (epoch 47.440), train_loss = 0.94966480, grad/param norm = 3.0112e-01, time/batch = 0.6916s	
27042/28500 (epoch 47.442), train_loss = 0.74563679, grad/param norm = 2.1810e-01, time/batch = 0.6912s	
27043/28500 (epoch 47.444), train_loss = 0.70645830, grad/param norm = 1.6210e-01, time/batch = 0.6909s	
27044/28500 (epoch 47.446), train_loss = 0.67914227, grad/param norm = 1.8392e-01, time/batch = 0.6901s	
27045/28500 (epoch 47.447), train_loss = 0.67507748, grad/param norm = 1.6663e-01, time/batch = 0.6897s	
27046/28500 (epoch 47.449), train_loss = 0.75290416, grad/param norm = 1.9377e-01, time/batch = 0.6925s	
27047/28500 (epoch 47.451), train_loss = 0.74965666, grad/param norm = 1.9859e-01, time/batch = 0.6899s	
27048/28500 (epoch 47.453), train_loss = 0.74617954, grad/param norm = 1.9210e-01, time/batch = 0.6894s	
27049/28500 (epoch 47.454), train_loss = 0.69992594, grad/param norm = 1.6179e-01, time/batch = 0.6904s	
27050/28500 (epoch 47.456), train_loss = 0.83599884, grad/param norm = 2.5725e-01, time/batch = 0.6922s	
27051/28500 (epoch 47.458), train_loss = 0.73603096, grad/param norm = 1.9579e-01, time/batch = 0.6917s	
27052/28500 (epoch 47.460), train_loss = 0.83681373, grad/param norm = 1.8727e-01, time/batch = 0.6921s	
27053/28500 (epoch 47.461), train_loss = 0.69922297, grad/param norm = 1.9889e-01, time/batch = 0.6901s	
27054/28500 (epoch 47.463), train_loss = 0.64640807, grad/param norm = 1.6870e-01, time/batch = 0.6899s	
27055/28500 (epoch 47.465), train_loss = 0.61514001, grad/param norm = 1.9801e-01, time/batch = 0.6899s	
27056/28500 (epoch 47.467), train_loss = 0.77767569, grad/param norm = 1.7912e-01, time/batch = 0.6899s	
27057/28500 (epoch 47.468), train_loss = 0.69257281, grad/param norm = 1.7181e-01, time/batch = 0.6893s	
27058/28500 (epoch 47.470), train_loss = 0.71457718, grad/param norm = 2.0895e-01, time/batch = 0.6951s	
27059/28500 (epoch 47.472), train_loss = 0.70473076, grad/param norm = 1.7550e-01, time/batch = 0.6906s	
27060/28500 (epoch 47.474), train_loss = 0.90732199, grad/param norm = 2.2448e-01, time/batch = 0.6884s	
27061/28500 (epoch 47.475), train_loss = 0.73598112, grad/param norm = 1.9096e-01, time/batch = 0.6915s	
27062/28500 (epoch 47.477), train_loss = 0.77013171, grad/param norm = 1.9017e-01, time/batch = 0.6901s	
27063/28500 (epoch 47.479), train_loss = 0.80628996, grad/param norm = 2.0522e-01, time/batch = 0.6908s	
27064/28500 (epoch 47.481), train_loss = 0.80630633, grad/param norm = 2.0492e-01, time/batch = 0.6895s	
27065/28500 (epoch 47.482), train_loss = 0.66049448, grad/param norm = 1.7733e-01, time/batch = 0.6892s	
27066/28500 (epoch 47.484), train_loss = 0.70464616, grad/param norm = 1.9092e-01, time/batch = 0.6891s	
27067/28500 (epoch 47.486), train_loss = 0.63239323, grad/param norm = 2.0983e-01, time/batch = 0.6889s	
27068/28500 (epoch 47.488), train_loss = 0.79815187, grad/param norm = 1.8525e-01, time/batch = 0.6891s	
27069/28500 (epoch 47.489), train_loss = 0.91214738, grad/param norm = 1.9998e-01, time/batch = 0.6890s	
27070/28500 (epoch 47.491), train_loss = 0.72915151, grad/param norm = 1.8120e-01, time/batch = 0.6887s	
27071/28500 (epoch 47.493), train_loss = 0.75301790, grad/param norm = 2.3092e-01, time/batch = 0.6908s	
27072/28500 (epoch 47.495), train_loss = 0.78172178, grad/param norm = 2.0734e-01, time/batch = 0.6903s	
27073/28500 (epoch 47.496), train_loss = 0.69486825, grad/param norm = 2.7117e-01, time/batch = 0.6891s	
27074/28500 (epoch 47.498), train_loss = 0.76700468, grad/param norm = 1.8827e-01, time/batch = 0.6890s	
27075/28500 (epoch 47.500), train_loss = 0.72679973, grad/param norm = 1.9385e-01, time/batch = 0.6927s	
27076/28500 (epoch 47.502), train_loss = 0.78890412, grad/param norm = 1.8143e-01, time/batch = 0.6950s	
27077/28500 (epoch 47.504), train_loss = 0.83635202, grad/param norm = 2.1014e-01, time/batch = 0.6933s	
27078/28500 (epoch 47.505), train_loss = 0.71813554, grad/param norm = 1.7216e-01, time/batch = 0.6936s	
27079/28500 (epoch 47.507), train_loss = 0.85273693, grad/param norm = 2.2834e-01, time/batch = 0.6947s	
27080/28500 (epoch 47.509), train_loss = 0.75105953, grad/param norm = 2.0507e-01, time/batch = 0.6929s	
27081/28500 (epoch 47.511), train_loss = 0.76424325, grad/param norm = 1.9784e-01, time/batch = 0.6937s	
27082/28500 (epoch 47.512), train_loss = 0.81742086, grad/param norm = 1.8514e-01, time/batch = 0.6934s	
27083/28500 (epoch 47.514), train_loss = 0.75422258, grad/param norm = 1.9233e-01, time/batch = 0.6916s	
27084/28500 (epoch 47.516), train_loss = 0.78732542, grad/param norm = 1.9221e-01, time/batch = 0.6942s	
27085/28500 (epoch 47.518), train_loss = 0.81754789, grad/param norm = 2.1046e-01, time/batch = 0.6939s	
27086/28500 (epoch 47.519), train_loss = 0.79081279, grad/param norm = 1.9261e-01, time/batch = 0.6939s	
27087/28500 (epoch 47.521), train_loss = 0.87187482, grad/param norm = 2.2942e-01, time/batch = 0.6930s	
27088/28500 (epoch 47.523), train_loss = 0.81115725, grad/param norm = 2.0416e-01, time/batch = 0.6930s	
27089/28500 (epoch 47.525), train_loss = 0.88301188, grad/param norm = 1.9095e-01, time/batch = 0.6925s	
27090/28500 (epoch 47.526), train_loss = 0.80898851, grad/param norm = 2.1083e-01, time/batch = 0.6933s	
27091/28500 (epoch 47.528), train_loss = 0.81338898, grad/param norm = 2.3217e-01, time/batch = 0.6973s	
27092/28500 (epoch 47.530), train_loss = 0.79964386, grad/param norm = 1.8226e-01, time/batch = 0.6950s	
27093/28500 (epoch 47.532), train_loss = 0.76667829, grad/param norm = 1.9112e-01, time/batch = 0.6934s	
27094/28500 (epoch 47.533), train_loss = 0.80105056, grad/param norm = 1.7548e-01, time/batch = 0.6934s	
27095/28500 (epoch 47.535), train_loss = 0.69278477, grad/param norm = 1.8734e-01, time/batch = 0.6932s	
27096/28500 (epoch 47.537), train_loss = 0.66922083, grad/param norm = 1.7582e-01, time/batch = 0.6937s	
27097/28500 (epoch 47.539), train_loss = 0.67443121, grad/param norm = 2.1213e-01, time/batch = 0.6926s	
27098/28500 (epoch 47.540), train_loss = 0.73981628, grad/param norm = 1.6517e-01, time/batch = 0.6944s	
27099/28500 (epoch 47.542), train_loss = 0.79601024, grad/param norm = 2.4187e-01, time/batch = 0.6923s	
27100/28500 (epoch 47.544), train_loss = 0.88967277, grad/param norm = 2.4340e-01, time/batch = 0.6920s	
27101/28500 (epoch 47.546), train_loss = 0.77337099, grad/param norm = 1.8848e-01, time/batch = 0.6948s	
27102/28500 (epoch 47.547), train_loss = 0.75137850, grad/param norm = 1.8776e-01, time/batch = 0.6935s	
27103/28500 (epoch 47.549), train_loss = 0.65269726, grad/param norm = 1.5341e-01, time/batch = 0.6922s	
27104/28500 (epoch 47.551), train_loss = 0.71309954, grad/param norm = 2.4332e-01, time/batch = 0.6931s	
27105/28500 (epoch 47.553), train_loss = 0.89616161, grad/param norm = 2.2851e-01, time/batch = 0.6917s	
27106/28500 (epoch 47.554), train_loss = 0.81005233, grad/param norm = 2.1218e-01, time/batch = 0.6934s	
27107/28500 (epoch 47.556), train_loss = 0.80729449, grad/param norm = 2.0829e-01, time/batch = 0.6926s	
27108/28500 (epoch 47.558), train_loss = 0.82711702, grad/param norm = 1.8602e-01, time/batch = 0.6963s	
27109/28500 (epoch 47.560), train_loss = 0.82028216, grad/param norm = 2.2158e-01, time/batch = 0.6967s	
27110/28500 (epoch 47.561), train_loss = 0.83644816, grad/param norm = 2.1143e-01, time/batch = 0.7002s	
27111/28500 (epoch 47.563), train_loss = 0.92422613, grad/param norm = 2.3695e-01, time/batch = 0.6951s	
27112/28500 (epoch 47.565), train_loss = 0.73219352, grad/param norm = 2.0088e-01, time/batch = 0.6949s	
27113/28500 (epoch 47.567), train_loss = 0.64864993, grad/param norm = 1.5748e-01, time/batch = 0.6925s	
27114/28500 (epoch 47.568), train_loss = 0.79670249, grad/param norm = 2.4420e-01, time/batch = 0.6963s	
27115/28500 (epoch 47.570), train_loss = 0.75347768, grad/param norm = 2.1647e-01, time/batch = 0.6952s	
27116/28500 (epoch 47.572), train_loss = 0.78677861, grad/param norm = 1.8268e-01, time/batch = 0.6928s	
27117/28500 (epoch 47.574), train_loss = 0.74078316, grad/param norm = 1.8891e-01, time/batch = 0.6943s	
27118/28500 (epoch 47.575), train_loss = 0.71047142, grad/param norm = 1.6825e-01, time/batch = 0.6933s	
27119/28500 (epoch 47.577), train_loss = 0.85948029, grad/param norm = 2.0578e-01, time/batch = 0.6925s	
27120/28500 (epoch 47.579), train_loss = 0.84536022, grad/param norm = 1.9847e-01, time/batch = 0.6920s	
27121/28500 (epoch 47.581), train_loss = 0.72736628, grad/param norm = 2.6054e-01, time/batch = 0.6955s	
27122/28500 (epoch 47.582), train_loss = 0.90159296, grad/param norm = 2.1503e-01, time/batch = 0.6947s	
27123/28500 (epoch 47.584), train_loss = 0.73333158, grad/param norm = 1.9241e-01, time/batch = 0.6958s	
27124/28500 (epoch 47.586), train_loss = 0.70869700, grad/param norm = 1.6436e-01, time/batch = 0.6952s	
27125/28500 (epoch 47.588), train_loss = 0.72686349, grad/param norm = 2.0510e-01, time/batch = 0.6943s	
27126/28500 (epoch 47.589), train_loss = 0.77082052, grad/param norm = 2.1351e-01, time/batch = 0.6930s	
27127/28500 (epoch 47.591), train_loss = 0.79255124, grad/param norm = 2.0534e-01, time/batch = 0.6916s	
27128/28500 (epoch 47.593), train_loss = 0.72065692, grad/param norm = 1.7893e-01, time/batch = 0.6930s	
27129/28500 (epoch 47.595), train_loss = 0.92465458, grad/param norm = 2.3592e-01, time/batch = 0.6919s	
27130/28500 (epoch 47.596), train_loss = 0.92251049, grad/param norm = 2.0309e-01, time/batch = 0.6924s	
27131/28500 (epoch 47.598), train_loss = 0.77490923, grad/param norm = 2.7614e-01, time/batch = 0.6941s	
27132/28500 (epoch 47.600), train_loss = 0.74668774, grad/param norm = 2.2005e-01, time/batch = 0.6946s	
27133/28500 (epoch 47.602), train_loss = 0.84950783, grad/param norm = 2.2710e-01, time/batch = 0.6927s	
27134/28500 (epoch 47.604), train_loss = 0.87530994, grad/param norm = 1.6996e-01, time/batch = 0.6929s	
27135/28500 (epoch 47.605), train_loss = 0.86906799, grad/param norm = 2.1359e-01, time/batch = 0.6939s	
27136/28500 (epoch 47.607), train_loss = 0.88862734, grad/param norm = 1.8161e-01, time/batch = 0.6932s	
27137/28500 (epoch 47.609), train_loss = 0.79227446, grad/param norm = 1.9040e-01, time/batch = 0.6937s	
27138/28500 (epoch 47.611), train_loss = 0.78018972, grad/param norm = 1.9573e-01, time/batch = 0.6970s	
27139/28500 (epoch 47.612), train_loss = 0.84279582, grad/param norm = 2.4124e-01, time/batch = 0.6935s	
27140/28500 (epoch 47.614), train_loss = 0.86773997, grad/param norm = 2.1958e-01, time/batch = 0.6923s	
27141/28500 (epoch 47.616), train_loss = 0.75324126, grad/param norm = 2.0685e-01, time/batch = 0.6978s	
27142/28500 (epoch 47.618), train_loss = 0.77360823, grad/param norm = 2.0742e-01, time/batch = 0.6940s	
27143/28500 (epoch 47.619), train_loss = 0.84216642, grad/param norm = 2.2658e-01, time/batch = 0.6935s	
27144/28500 (epoch 47.621), train_loss = 0.63850453, grad/param norm = 1.9255e-01, time/batch = 0.6964s	
27145/28500 (epoch 47.623), train_loss = 0.90208578, grad/param norm = 2.2883e-01, time/batch = 0.6976s	
27146/28500 (epoch 47.625), train_loss = 0.69966383, grad/param norm = 1.9071e-01, time/batch = 0.6975s	
27147/28500 (epoch 47.626), train_loss = 0.63075175, grad/param norm = 1.6075e-01, time/batch = 0.6975s	
27148/28500 (epoch 47.628), train_loss = 0.70718260, grad/param norm = 1.7883e-01, time/batch = 0.6958s	
27149/28500 (epoch 47.630), train_loss = 0.69578244, grad/param norm = 1.7848e-01, time/batch = 0.6961s	
27150/28500 (epoch 47.632), train_loss = 0.88527587, grad/param norm = 2.3481e-01, time/batch = 0.6979s	
27151/28500 (epoch 47.633), train_loss = 0.89217980, grad/param norm = 1.8049e-01, time/batch = 0.6966s	
27152/28500 (epoch 47.635), train_loss = 0.83088539, grad/param norm = 2.2194e-01, time/batch = 0.6937s	
27153/28500 (epoch 47.637), train_loss = 0.80239766, grad/param norm = 1.9191e-01, time/batch = 0.6930s	
27154/28500 (epoch 47.639), train_loss = 0.69302844, grad/param norm = 2.0652e-01, time/batch = 0.7142s	
27155/28500 (epoch 47.640), train_loss = 0.74756559, grad/param norm = 1.9536e-01, time/batch = 0.6985s	
27156/28500 (epoch 47.642), train_loss = 0.73464585, grad/param norm = 1.8498e-01, time/batch = 0.6961s	
27157/28500 (epoch 47.644), train_loss = 0.82435446, grad/param norm = 2.0522e-01, time/batch = 0.6960s	
27158/28500 (epoch 47.646), train_loss = 0.63229315, grad/param norm = 1.6340e-01, time/batch = 0.6962s	
27159/28500 (epoch 47.647), train_loss = 0.73758590, grad/param norm = 1.8587e-01, time/batch = 0.6991s	
27160/28500 (epoch 47.649), train_loss = 0.72271327, grad/param norm = 2.1325e-01, time/batch = 0.6950s	
27161/28500 (epoch 47.651), train_loss = 0.67186400, grad/param norm = 1.4920e-01, time/batch = 0.6961s	
27162/28500 (epoch 47.653), train_loss = 0.68202376, grad/param norm = 1.9043e-01, time/batch = 0.6942s	
27163/28500 (epoch 47.654), train_loss = 0.70514723, grad/param norm = 1.8261e-01, time/batch = 0.6932s	
27164/28500 (epoch 47.656), train_loss = 0.64409677, grad/param norm = 1.9244e-01, time/batch = 0.6944s	
27165/28500 (epoch 47.658), train_loss = 0.78537745, grad/param norm = 1.9043e-01, time/batch = 0.6929s	
27166/28500 (epoch 47.660), train_loss = 0.77152071, grad/param norm = 1.9972e-01, time/batch = 0.6922s	
27167/28500 (epoch 47.661), train_loss = 0.87564546, grad/param norm = 2.4128e-01, time/batch = 0.6926s	
27168/28500 (epoch 47.663), train_loss = 0.86065211, grad/param norm = 2.0952e-01, time/batch = 0.6917s	
27169/28500 (epoch 47.665), train_loss = 0.77462058, grad/param norm = 2.2212e-01, time/batch = 0.6926s	
27170/28500 (epoch 47.667), train_loss = 0.80809634, grad/param norm = 2.0941e-01, time/batch = 0.6893s	
27171/28500 (epoch 47.668), train_loss = 0.77218231, grad/param norm = 1.8398e-01, time/batch = 0.6964s	
27172/28500 (epoch 47.670), train_loss = 0.79214840, grad/param norm = 1.9892e-01, time/batch = 0.6939s	
27173/28500 (epoch 47.672), train_loss = 0.70519909, grad/param norm = 2.0691e-01, time/batch = 0.6903s	
27174/28500 (epoch 47.674), train_loss = 0.62089360, grad/param norm = 1.9257e-01, time/batch = 0.6919s	
27175/28500 (epoch 47.675), train_loss = 0.67610739, grad/param norm = 2.0738e-01, time/batch = 0.6911s	
27176/28500 (epoch 47.677), train_loss = 0.73402242, grad/param norm = 1.7469e-01, time/batch = 0.6897s	
27177/28500 (epoch 47.679), train_loss = 0.73467949, grad/param norm = 1.8788e-01, time/batch = 0.6908s	
27178/28500 (epoch 47.681), train_loss = 0.79675469, grad/param norm = 1.9490e-01, time/batch = 0.6915s	
27179/28500 (epoch 47.682), train_loss = 0.74157947, grad/param norm = 1.9560e-01, time/batch = 0.6910s	
27180/28500 (epoch 47.684), train_loss = 0.76982533, grad/param norm = 1.8790e-01, time/batch = 0.6949s	
27181/28500 (epoch 47.686), train_loss = 0.72786438, grad/param norm = 1.8861e-01, time/batch = 0.6955s	
27182/28500 (epoch 47.688), train_loss = 0.70363067, grad/param norm = 1.4399e-01, time/batch = 0.6901s	
27183/28500 (epoch 47.689), train_loss = 0.70150221, grad/param norm = 1.7289e-01, time/batch = 0.6925s	
27184/28500 (epoch 47.691), train_loss = 0.82046869, grad/param norm = 1.9415e-01, time/batch = 0.6991s	
27185/28500 (epoch 47.693), train_loss = 0.73310909, grad/param norm = 2.0547e-01, time/batch = 0.6936s	
27186/28500 (epoch 47.695), train_loss = 0.57173734, grad/param norm = 2.4451e-01, time/batch = 0.7116s	
27187/28500 (epoch 47.696), train_loss = 0.73294077, grad/param norm = 2.0508e-01, time/batch = 0.7152s	
27188/28500 (epoch 47.698), train_loss = 0.82019635, grad/param norm = 1.7551e-01, time/batch = 0.6989s	
27189/28500 (epoch 47.700), train_loss = 0.76331174, grad/param norm = 1.9685e-01, time/batch = 0.6996s	
27190/28500 (epoch 47.702), train_loss = 0.76056922, grad/param norm = 2.4122e-01, time/batch = 0.7017s	
27191/28500 (epoch 47.704), train_loss = 0.83688309, grad/param norm = 2.0485e-01, time/batch = 0.7122s	
27192/28500 (epoch 47.705), train_loss = 0.83508713, grad/param norm = 2.3981e-01, time/batch = 0.7000s	
27193/28500 (epoch 47.707), train_loss = 0.71697999, grad/param norm = 2.1811e-01, time/batch = 0.6980s	
27194/28500 (epoch 47.709), train_loss = 0.90099995, grad/param norm = 2.0259e-01, time/batch = 0.7043s	
27195/28500 (epoch 47.711), train_loss = 0.73587663, grad/param norm = 2.0676e-01, time/batch = 0.7091s	
27196/28500 (epoch 47.712), train_loss = 0.80882453, grad/param norm = 2.2851e-01, time/batch = 0.7021s	
27197/28500 (epoch 47.714), train_loss = 0.92023809, grad/param norm = 3.0001e-01, time/batch = 0.6935s	
27198/28500 (epoch 47.716), train_loss = 0.75562096, grad/param norm = 2.0051e-01, time/batch = 0.6921s	
27199/28500 (epoch 47.718), train_loss = 0.82013872, grad/param norm = 2.4822e-01, time/batch = 0.6906s	
27200/28500 (epoch 47.719), train_loss = 0.79410406, grad/param norm = 1.8197e-01, time/batch = 0.6970s	
27201/28500 (epoch 47.721), train_loss = 0.60541594, grad/param norm = 2.0092e-01, time/batch = 0.6961s	
27202/28500 (epoch 47.723), train_loss = 0.77489271, grad/param norm = 1.9106e-01, time/batch = 0.6975s	
27203/28500 (epoch 47.725), train_loss = 0.84261681, grad/param norm = 1.8032e-01, time/batch = 0.6933s	
27204/28500 (epoch 47.726), train_loss = 0.76627103, grad/param norm = 1.9894e-01, time/batch = 0.6888s	
27205/28500 (epoch 47.728), train_loss = 0.69390006, grad/param norm = 2.1080e-01, time/batch = 0.6892s	
27206/28500 (epoch 47.730), train_loss = 0.75418380, grad/param norm = 2.1851e-01, time/batch = 0.7114s	
27207/28500 (epoch 47.732), train_loss = 0.62249425, grad/param norm = 1.6763e-01, time/batch = 0.6953s	
27208/28500 (epoch 47.733), train_loss = 0.65834270, grad/param norm = 1.7829e-01, time/batch = 0.6974s	
27209/28500 (epoch 47.735), train_loss = 0.66255989, grad/param norm = 2.2131e-01, time/batch = 0.6985s	
27210/28500 (epoch 47.737), train_loss = 0.58800526, grad/param norm = 1.6521e-01, time/batch = 0.6910s	
27211/28500 (epoch 47.739), train_loss = 0.68008412, grad/param norm = 2.1246e-01, time/batch = 0.6966s	
27212/28500 (epoch 47.740), train_loss = 0.75177803, grad/param norm = 1.8101e-01, time/batch = 0.6936s	
27213/28500 (epoch 47.742), train_loss = 0.70981653, grad/param norm = 1.9985e-01, time/batch = 0.6915s	
27214/28500 (epoch 47.744), train_loss = 0.76840114, grad/param norm = 1.9388e-01, time/batch = 0.6982s	
27215/28500 (epoch 47.746), train_loss = 0.74058569, grad/param norm = 1.7752e-01, time/batch = 0.6971s	
27216/28500 (epoch 47.747), train_loss = 0.72698340, grad/param norm = 1.8796e-01, time/batch = 0.6944s	
27217/28500 (epoch 47.749), train_loss = 0.83396706, grad/param norm = 4.9813e-01, time/batch = 0.6933s	
27218/28500 (epoch 47.751), train_loss = 0.68622747, grad/param norm = 2.5911e-01, time/batch = 0.6900s	
27219/28500 (epoch 47.753), train_loss = 0.79147312, grad/param norm = 1.7634e-01, time/batch = 0.7052s	
27220/28500 (epoch 47.754), train_loss = 0.67618192, grad/param norm = 2.1464e-01, time/batch = 0.6966s	
27221/28500 (epoch 47.756), train_loss = 0.87381081, grad/param norm = 1.9780e-01, time/batch = 0.6985s	
27222/28500 (epoch 47.758), train_loss = 0.79169866, grad/param norm = 2.3048e-01, time/batch = 0.7027s	
27223/28500 (epoch 47.760), train_loss = 0.67516659, grad/param norm = 1.7773e-01, time/batch = 0.6916s	
27224/28500 (epoch 47.761), train_loss = 0.72946156, grad/param norm = 2.1754e-01, time/batch = 0.6933s	
27225/28500 (epoch 47.763), train_loss = 0.61283523, grad/param norm = 1.8247e-01, time/batch = 0.6900s	
27226/28500 (epoch 47.765), train_loss = 0.74220906, grad/param norm = 1.8542e-01, time/batch = 0.6906s	
27227/28500 (epoch 47.767), train_loss = 0.60809340, grad/param norm = 1.6021e-01, time/batch = 0.6910s	
27228/28500 (epoch 47.768), train_loss = 0.80729463, grad/param norm = 1.9008e-01, time/batch = 0.6891s	
27229/28500 (epoch 47.770), train_loss = 0.66037815, grad/param norm = 1.8755e-01, time/batch = 0.6892s	
27230/28500 (epoch 47.772), train_loss = 0.62344897, grad/param norm = 1.5630e-01, time/batch = 0.6884s	
27231/28500 (epoch 47.774), train_loss = 0.75478397, grad/param norm = 1.8562e-01, time/batch = 0.6906s	
27232/28500 (epoch 47.775), train_loss = 0.80098499, grad/param norm = 2.0385e-01, time/batch = 0.6895s	
27233/28500 (epoch 47.777), train_loss = 0.83015227, grad/param norm = 1.8595e-01, time/batch = 0.6889s	
27234/28500 (epoch 47.779), train_loss = 0.66430737, grad/param norm = 1.5536e-01, time/batch = 0.6890s	
27235/28500 (epoch 47.781), train_loss = 0.75142318, grad/param norm = 2.2871e-01, time/batch = 0.6920s	
27236/28500 (epoch 47.782), train_loss = 0.77546348, grad/param norm = 2.1281e-01, time/batch = 0.6930s	
27237/28500 (epoch 47.784), train_loss = 0.61673057, grad/param norm = 1.9027e-01, time/batch = 0.6922s	
27238/28500 (epoch 47.786), train_loss = 0.62328282, grad/param norm = 1.8364e-01, time/batch = 0.6941s	
27239/28500 (epoch 47.788), train_loss = 0.72509605, grad/param norm = 2.5147e-01, time/batch = 0.6933s	
27240/28500 (epoch 47.789), train_loss = 0.56401976, grad/param norm = 2.2994e-01, time/batch = 0.6932s	
27241/28500 (epoch 47.791), train_loss = 0.78242080, grad/param norm = 2.0096e-01, time/batch = 0.6945s	
27242/28500 (epoch 47.793), train_loss = 0.71779279, grad/param norm = 1.7768e-01, time/batch = 0.6942s	
27243/28500 (epoch 47.795), train_loss = 0.75917178, grad/param norm = 2.1156e-01, time/batch = 0.6916s	
27244/28500 (epoch 47.796), train_loss = 0.68957656, grad/param norm = 1.6680e-01, time/batch = 0.6914s	
27245/28500 (epoch 47.798), train_loss = 0.63228853, grad/param norm = 1.7436e-01, time/batch = 0.6891s	
27246/28500 (epoch 47.800), train_loss = 0.62696582, grad/param norm = 2.6457e-01, time/batch = 0.6919s	
27247/28500 (epoch 47.802), train_loss = 0.72018749, grad/param norm = 2.7065e-01, time/batch = 0.6980s	
27248/28500 (epoch 47.804), train_loss = 0.75782293, grad/param norm = 1.8235e-01, time/batch = 0.6900s	
27249/28500 (epoch 47.805), train_loss = 0.77446602, grad/param norm = 1.9922e-01, time/batch = 0.6905s	
27250/28500 (epoch 47.807), train_loss = 0.76450130, grad/param norm = 2.2917e-01, time/batch = 0.6908s	
27251/28500 (epoch 47.809), train_loss = 0.76486735, grad/param norm = 2.3513e-01, time/batch = 0.6918s	
27252/28500 (epoch 47.811), train_loss = 0.75398064, grad/param norm = 2.1137e-01, time/batch = 0.6943s	
27253/28500 (epoch 47.812), train_loss = 0.73491132, grad/param norm = 2.2030e-01, time/batch = 0.6929s	
27254/28500 (epoch 47.814), train_loss = 0.71229839, grad/param norm = 2.1696e-01, time/batch = 0.6897s	
27255/28500 (epoch 47.816), train_loss = 0.77345392, grad/param norm = 2.4214e-01, time/batch = 0.6917s	
27256/28500 (epoch 47.818), train_loss = 0.87360219, grad/param norm = 2.3584e-01, time/batch = 0.6964s	
27257/28500 (epoch 47.819), train_loss = 0.75279258, grad/param norm = 1.9386e-01, time/batch = 0.6954s	
27258/28500 (epoch 47.821), train_loss = 0.75803302, grad/param norm = 2.3717e-01, time/batch = 0.6941s	
27259/28500 (epoch 47.823), train_loss = 0.86883395, grad/param norm = 2.4677e-01, time/batch = 0.6950s	
27260/28500 (epoch 47.825), train_loss = 0.65550100, grad/param norm = 1.8059e-01, time/batch = 0.6935s	
27261/28500 (epoch 47.826), train_loss = 0.75865098, grad/param norm = 2.0117e-01, time/batch = 0.6963s	
27262/28500 (epoch 47.828), train_loss = 0.68901518, grad/param norm = 2.1328e-01, time/batch = 0.6945s	
27263/28500 (epoch 47.830), train_loss = 0.70904425, grad/param norm = 1.6884e-01, time/batch = 0.6975s	
27264/28500 (epoch 47.832), train_loss = 0.75065199, grad/param norm = 2.4543e-01, time/batch = 0.6916s	
27265/28500 (epoch 47.833), train_loss = 0.79148158, grad/param norm = 2.0353e-01, time/batch = 0.6946s	
27266/28500 (epoch 47.835), train_loss = 0.70600711, grad/param norm = 1.9014e-01, time/batch = 0.6939s	
27267/28500 (epoch 47.837), train_loss = 0.63513500, grad/param norm = 1.9764e-01, time/batch = 0.6941s	
27268/28500 (epoch 47.839), train_loss = 0.91367671, grad/param norm = 2.6099e-01, time/batch = 0.6971s	
27269/28500 (epoch 47.840), train_loss = 0.87932496, grad/param norm = 2.0199e-01, time/batch = 0.6986s	
27270/28500 (epoch 47.842), train_loss = 0.82836593, grad/param norm = 3.0047e-01, time/batch = 0.6956s	
27271/28500 (epoch 47.844), train_loss = 0.85643170, grad/param norm = 2.8887e-01, time/batch = 0.6960s	
27272/28500 (epoch 47.846), train_loss = 0.90748051, grad/param norm = 2.3940e-01, time/batch = 0.6947s	
27273/28500 (epoch 47.847), train_loss = 0.73040413, grad/param norm = 2.0998e-01, time/batch = 0.6963s	
27274/28500 (epoch 47.849), train_loss = 0.72304819, grad/param norm = 1.7803e-01, time/batch = 0.6950s	
27275/28500 (epoch 47.851), train_loss = 0.69666119, grad/param norm = 1.7316e-01, time/batch = 0.6936s	
27276/28500 (epoch 47.853), train_loss = 0.80530141, grad/param norm = 2.2658e-01, time/batch = 0.6938s	
27277/28500 (epoch 47.854), train_loss = 0.77013722, grad/param norm = 1.8684e-01, time/batch = 0.6942s	
27278/28500 (epoch 47.856), train_loss = 0.84047211, grad/param norm = 2.2108e-01, time/batch = 0.6938s	
27279/28500 (epoch 47.858), train_loss = 0.74190691, grad/param norm = 2.0219e-01, time/batch = 0.6925s	
27280/28500 (epoch 47.860), train_loss = 0.76074025, grad/param norm = 2.1775e-01, time/batch = 0.6941s	
27281/28500 (epoch 47.861), train_loss = 0.84169494, grad/param norm = 4.5973e-01, time/batch = 0.7069s	
27282/28500 (epoch 47.863), train_loss = 0.82728584, grad/param norm = 2.8156e-01, time/batch = 0.7012s	
27283/28500 (epoch 47.865), train_loss = 0.73121424, grad/param norm = 2.4228e-01, time/batch = 0.6955s	
27284/28500 (epoch 47.867), train_loss = 0.79409378, grad/param norm = 2.3073e-01, time/batch = 0.6937s	
27285/28500 (epoch 47.868), train_loss = 0.67160965, grad/param norm = 1.8498e-01, time/batch = 0.6935s	
27286/28500 (epoch 47.870), train_loss = 0.65874831, grad/param norm = 1.9741e-01, time/batch = 0.6926s	
27287/28500 (epoch 47.872), train_loss = 0.82906616, grad/param norm = 2.1799e-01, time/batch = 0.6943s	
27288/28500 (epoch 47.874), train_loss = 0.71212438, grad/param norm = 2.6568e-01, time/batch = 0.6920s	
27289/28500 (epoch 47.875), train_loss = 0.90523893, grad/param norm = 2.4676e-01, time/batch = 0.6961s	
27290/28500 (epoch 47.877), train_loss = 0.78732666, grad/param norm = 2.0044e-01, time/batch = 0.7012s	
27291/28500 (epoch 47.879), train_loss = 0.78516514, grad/param norm = 1.6399e-01, time/batch = 0.6979s	
27292/28500 (epoch 47.881), train_loss = 0.78190525, grad/param norm = 1.9217e-01, time/batch = 0.6967s	
27293/28500 (epoch 47.882), train_loss = 0.68094633, grad/param norm = 1.8074e-01, time/batch = 0.7086s	
27294/28500 (epoch 47.884), train_loss = 0.71654313, grad/param norm = 1.8159e-01, time/batch = 0.7073s	
27295/28500 (epoch 47.886), train_loss = 0.69426988, grad/param norm = 1.6603e-01, time/batch = 0.7042s	
27296/28500 (epoch 47.888), train_loss = 0.74018859, grad/param norm = 1.7633e-01, time/batch = 0.6960s	
27297/28500 (epoch 47.889), train_loss = 0.78765754, grad/param norm = 1.7504e-01, time/batch = 0.6949s	
27298/28500 (epoch 47.891), train_loss = 0.76230307, grad/param norm = 1.8323e-01, time/batch = 0.6944s	
27299/28500 (epoch 47.893), train_loss = 0.72536166, grad/param norm = 2.3651e-01, time/batch = 0.6933s	
27300/28500 (epoch 47.895), train_loss = 0.90910399, grad/param norm = 2.7966e-01, time/batch = 0.6941s	
27301/28500 (epoch 47.896), train_loss = 0.86850434, grad/param norm = 2.3546e-01, time/batch = 0.6978s	
27302/28500 (epoch 47.898), train_loss = 0.84393100, grad/param norm = 1.9872e-01, time/batch = 0.7010s	
27303/28500 (epoch 47.900), train_loss = 0.66762592, grad/param norm = 1.7466e-01, time/batch = 0.7041s	
27304/28500 (epoch 47.902), train_loss = 0.63802312, grad/param norm = 1.8329e-01, time/batch = 0.6966s	
27305/28500 (epoch 47.904), train_loss = 0.67546206, grad/param norm = 1.8953e-01, time/batch = 0.6963s	
27306/28500 (epoch 47.905), train_loss = 0.72890845, grad/param norm = 1.9674e-01, time/batch = 0.7040s	
27307/28500 (epoch 47.907), train_loss = 0.75114566, grad/param norm = 1.9356e-01, time/batch = 0.6946s	
27308/28500 (epoch 47.909), train_loss = 0.63081322, grad/param norm = 2.2281e-01, time/batch = 0.6936s	
27309/28500 (epoch 47.911), train_loss = 0.67982739, grad/param norm = 1.8746e-01, time/batch = 0.6947s	
27310/28500 (epoch 47.912), train_loss = 0.56639969, grad/param norm = 1.7264e-01, time/batch = 0.6955s	
27311/28500 (epoch 47.914), train_loss = 0.77373253, grad/param norm = 1.7442e-01, time/batch = 0.7004s	
27312/28500 (epoch 47.916), train_loss = 0.77585238, grad/param norm = 2.0594e-01, time/batch = 0.6946s	
27313/28500 (epoch 47.918), train_loss = 0.74548643, grad/param norm = 2.0741e-01, time/batch = 0.6941s	
27314/28500 (epoch 47.919), train_loss = 0.79453323, grad/param norm = 1.9655e-01, time/batch = 0.6947s	
27315/28500 (epoch 47.921), train_loss = 0.84020477, grad/param norm = 2.4102e-01, time/batch = 0.6949s	
27316/28500 (epoch 47.923), train_loss = 0.70478386, grad/param norm = 2.9306e-01, time/batch = 0.6958s	
27317/28500 (epoch 47.925), train_loss = 0.72693253, grad/param norm = 2.5928e-01, time/batch = 0.6936s	
27318/28500 (epoch 47.926), train_loss = 0.78327898, grad/param norm = 2.2751e-01, time/batch = 0.6932s	
27319/28500 (epoch 47.928), train_loss = 0.71390276, grad/param norm = 1.9568e-01, time/batch = 0.6934s	
27320/28500 (epoch 47.930), train_loss = 0.60701617, grad/param norm = 1.8745e-01, time/batch = 0.6932s	
27321/28500 (epoch 47.932), train_loss = 0.61747081, grad/param norm = 1.7127e-01, time/batch = 0.6970s	
27322/28500 (epoch 47.933), train_loss = 0.80925922, grad/param norm = 1.8023e-01, time/batch = 0.6966s	
27323/28500 (epoch 47.935), train_loss = 0.81336804, grad/param norm = 1.8002e-01, time/batch = 0.6953s	
27324/28500 (epoch 47.937), train_loss = 0.80690979, grad/param norm = 2.4747e-01, time/batch = 0.6927s	
27325/28500 (epoch 47.939), train_loss = 0.88387996, grad/param norm = 2.2066e-01, time/batch = 0.6941s	
27326/28500 (epoch 47.940), train_loss = 0.60278252, grad/param norm = 1.9360e-01, time/batch = 0.6932s	
27327/28500 (epoch 47.942), train_loss = 0.77157143, grad/param norm = 2.4555e-01, time/batch = 0.6935s	
27328/28500 (epoch 47.944), train_loss = 0.72527520, grad/param norm = 2.0829e-01, time/batch = 0.6935s	
27329/28500 (epoch 47.946), train_loss = 0.79571475, grad/param norm = 1.8658e-01, time/batch = 0.6962s	
27330/28500 (epoch 47.947), train_loss = 0.96477060, grad/param norm = 2.8316e-01, time/batch = 0.6926s	
27331/28500 (epoch 47.949), train_loss = 0.73907991, grad/param norm = 2.4972e-01, time/batch = 0.6940s	
27332/28500 (epoch 47.951), train_loss = 0.92584123, grad/param norm = 2.2995e-01, time/batch = 0.6941s	
27333/28500 (epoch 47.953), train_loss = 0.89214314, grad/param norm = 2.1464e-01, time/batch = 0.6930s	
27334/28500 (epoch 47.954), train_loss = 0.84356971, grad/param norm = 2.0612e-01, time/batch = 0.6928s	
27335/28500 (epoch 47.956), train_loss = 0.78120446, grad/param norm = 4.3944e-01, time/batch = 0.6942s	
27336/28500 (epoch 47.958), train_loss = 0.98856598, grad/param norm = 1.8724e-01, time/batch = 0.6932s	
27337/28500 (epoch 47.960), train_loss = 0.72087211, grad/param norm = 2.2609e-01, time/batch = 0.6936s	
27338/28500 (epoch 47.961), train_loss = 0.92693494, grad/param norm = 2.3432e-01, time/batch = 0.6938s	
27339/28500 (epoch 47.963), train_loss = 0.85427179, grad/param norm = 2.5103e-01, time/batch = 0.6949s	
27340/28500 (epoch 47.965), train_loss = 0.69913497, grad/param norm = 2.0131e-01, time/batch = 0.6944s	
27341/28500 (epoch 47.967), train_loss = 0.72601771, grad/param norm = 2.4977e-01, time/batch = 0.6977s	
27342/28500 (epoch 47.968), train_loss = 0.68367828, grad/param norm = 1.7374e-01, time/batch = 0.6944s	
27343/28500 (epoch 47.970), train_loss = 0.70262257, grad/param norm = 2.1413e-01, time/batch = 0.6951s	
27344/28500 (epoch 47.972), train_loss = 0.77210859, grad/param norm = 1.9799e-01, time/batch = 0.6936s	
27345/28500 (epoch 47.974), train_loss = 0.98451987, grad/param norm = 2.7287e-01, time/batch = 0.6926s	
27346/28500 (epoch 47.975), train_loss = 0.71994920, grad/param norm = 2.1117e-01, time/batch = 0.6937s	
27347/28500 (epoch 47.977), train_loss = 0.86091336, grad/param norm = 2.3743e-01, time/batch = 0.6932s	
27348/28500 (epoch 47.979), train_loss = 0.80081018, grad/param norm = 1.9845e-01, time/batch = 0.6951s	
27349/28500 (epoch 47.981), train_loss = 0.66951911, grad/param norm = 2.2990e-01, time/batch = 0.6945s	
27350/28500 (epoch 47.982), train_loss = 0.77637045, grad/param norm = 2.2095e-01, time/batch = 0.6931s	
27351/28500 (epoch 47.984), train_loss = 0.82133090, grad/param norm = 1.9228e-01, time/batch = 0.6968s	
27352/28500 (epoch 47.986), train_loss = 0.97298725, grad/param norm = 2.1751e-01, time/batch = 0.6947s	
27353/28500 (epoch 47.988), train_loss = 0.69703474, grad/param norm = 1.9438e-01, time/batch = 0.6991s	
27354/28500 (epoch 47.989), train_loss = 0.78370424, grad/param norm = 3.0146e-01, time/batch = 0.6976s	
27355/28500 (epoch 47.991), train_loss = 0.69993737, grad/param norm = 2.1288e-01, time/batch = 0.6953s	
27356/28500 (epoch 47.993), train_loss = 0.70578347, grad/param norm = 2.1944e-01, time/batch = 0.6940s	
27357/28500 (epoch 47.995), train_loss = 0.74319799, grad/param norm = 2.0172e-01, time/batch = 0.6938s	
27358/28500 (epoch 47.996), train_loss = 0.67735575, grad/param norm = 2.2584e-01, time/batch = 0.6925s	
27359/28500 (epoch 47.998), train_loss = 0.88481423, grad/param norm = 2.7050e-01, time/batch = 0.6932s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
27360/28500 (epoch 48.000), train_loss = 0.74182241, grad/param norm = 1.9178e-01, time/batch = 0.6935s	
27361/28500 (epoch 48.002), train_loss = 0.92815555, grad/param norm = 2.2257e-01, time/batch = 0.6957s	
27362/28500 (epoch 48.004), train_loss = 0.79187660, grad/param norm = 2.0514e-01, time/batch = 0.6938s	
27363/28500 (epoch 48.005), train_loss = 0.86707856, grad/param norm = 2.3695e-01, time/batch = 0.6934s	
27364/28500 (epoch 48.007), train_loss = 0.68690038, grad/param norm = 1.7730e-01, time/batch = 0.6936s	
27365/28500 (epoch 48.009), train_loss = 0.77869033, grad/param norm = 2.1194e-01, time/batch = 0.6931s	
27366/28500 (epoch 48.011), train_loss = 0.70660758, grad/param norm = 1.8421e-01, time/batch = 0.6973s	
27367/28500 (epoch 48.012), train_loss = 0.71475815, grad/param norm = 1.9118e-01, time/batch = 0.7109s	
27368/28500 (epoch 48.014), train_loss = 0.68611542, grad/param norm = 2.2751e-01, time/batch = 0.7098s	
27369/28500 (epoch 48.016), train_loss = 0.76079526, grad/param norm = 1.8930e-01, time/batch = 0.7086s	
27370/28500 (epoch 48.018), train_loss = 0.78082170, grad/param norm = 1.9235e-01, time/batch = 0.7046s	
27371/28500 (epoch 48.019), train_loss = 0.86177992, grad/param norm = 2.1218e-01, time/batch = 0.7021s	
27372/28500 (epoch 48.021), train_loss = 0.87014952, grad/param norm = 1.7536e-01, time/batch = 0.6998s	
27373/28500 (epoch 48.023), train_loss = 0.76994870, grad/param norm = 1.8130e-01, time/batch = 0.6965s	
27374/28500 (epoch 48.025), train_loss = 0.80711034, grad/param norm = 1.9358e-01, time/batch = 0.6913s	
27375/28500 (epoch 48.026), train_loss = 0.70913345, grad/param norm = 1.7928e-01, time/batch = 0.9255s	
27376/28500 (epoch 48.028), train_loss = 0.78677207, grad/param norm = 2.1995e-01, time/batch = 0.9976s	
27377/28500 (epoch 48.030), train_loss = 0.80367851, grad/param norm = 2.1685e-01, time/batch = 0.9981s	
27378/28500 (epoch 48.032), train_loss = 0.89060158, grad/param norm = 1.8982e-01, time/batch = 1.0188s	
27379/28500 (epoch 48.033), train_loss = 0.90155114, grad/param norm = 1.8707e-01, time/batch = 1.0262s	
27380/28500 (epoch 48.035), train_loss = 0.74674419, grad/param norm = 2.2892e-01, time/batch = 0.7874s	
27381/28500 (epoch 48.037), train_loss = 0.85121660, grad/param norm = 1.9597e-01, time/batch = 0.6986s	
27382/28500 (epoch 48.039), train_loss = 0.87947672, grad/param norm = 2.3461e-01, time/batch = 0.6926s	
27383/28500 (epoch 48.040), train_loss = 0.87254205, grad/param norm = 2.1675e-01, time/batch = 0.6908s	
27384/28500 (epoch 48.042), train_loss = 0.85353315, grad/param norm = 1.9536e-01, time/batch = 0.6905s	
27385/28500 (epoch 48.044), train_loss = 0.77013304, grad/param norm = 2.2368e-01, time/batch = 0.6892s	
27386/28500 (epoch 48.046), train_loss = 0.98579048, grad/param norm = 2.5026e-01, time/batch = 0.6890s	
27387/28500 (epoch 48.047), train_loss = 0.90678635, grad/param norm = 2.5212e-01, time/batch = 0.7054s	
27388/28500 (epoch 48.049), train_loss = 0.79992191, grad/param norm = 2.0033e-01, time/batch = 0.6902s	
27389/28500 (epoch 48.051), train_loss = 0.78162083, grad/param norm = 2.3378e-01, time/batch = 0.6884s	
27390/28500 (epoch 48.053), train_loss = 0.73756839, grad/param norm = 1.8983e-01, time/batch = 0.6884s	
27391/28500 (epoch 48.054), train_loss = 0.85611570, grad/param norm = 2.1383e-01, time/batch = 0.6907s	
27392/28500 (epoch 48.056), train_loss = 0.74607634, grad/param norm = 1.8548e-01, time/batch = 0.6909s	
27393/28500 (epoch 48.058), train_loss = 0.71926313, grad/param norm = 1.8454e-01, time/batch = 0.6892s	
27394/28500 (epoch 48.060), train_loss = 0.84421169, grad/param norm = 2.0538e-01, time/batch = 0.7008s	
27395/28500 (epoch 48.061), train_loss = 0.75093928, grad/param norm = 2.0308e-01, time/batch = 0.6984s	
27396/28500 (epoch 48.063), train_loss = 0.80427506, grad/param norm = 2.0868e-01, time/batch = 0.6896s	
27397/28500 (epoch 48.065), train_loss = 0.79124299, grad/param norm = 2.2521e-01, time/batch = 0.7057s	
27398/28500 (epoch 48.067), train_loss = 0.73614306, grad/param norm = 2.2295e-01, time/batch = 0.6887s	
27399/28500 (epoch 48.068), train_loss = 0.75831403, grad/param norm = 1.8736e-01, time/batch = 0.6880s	
27400/28500 (epoch 48.070), train_loss = 0.79646141, grad/param norm = 2.0365e-01, time/batch = 0.6885s	
27401/28500 (epoch 48.072), train_loss = 0.91988610, grad/param norm = 2.4349e-01, time/batch = 0.6920s	
27402/28500 (epoch 48.074), train_loss = 0.76914976, grad/param norm = 2.1965e-01, time/batch = 0.7112s	
27403/28500 (epoch 48.075), train_loss = 0.78031755, grad/param norm = 1.9163e-01, time/batch = 0.6977s	
27404/28500 (epoch 48.077), train_loss = 0.83028431, grad/param norm = 1.7955e-01, time/batch = 0.6894s	
27405/28500 (epoch 48.079), train_loss = 0.80696531, grad/param norm = 1.7949e-01, time/batch = 0.6886s	
27406/28500 (epoch 48.081), train_loss = 0.88165035, grad/param norm = 2.5545e-01, time/batch = 0.6987s	
27407/28500 (epoch 48.082), train_loss = 0.76388824, grad/param norm = 2.4964e-01, time/batch = 0.6897s	
27408/28500 (epoch 48.084), train_loss = 0.75566678, grad/param norm = 2.0736e-01, time/batch = 0.6913s	
27409/28500 (epoch 48.086), train_loss = 0.73790394, grad/param norm = 2.0656e-01, time/batch = 0.6895s	
27410/28500 (epoch 48.088), train_loss = 0.68668005, grad/param norm = 1.7711e-01, time/batch = 0.7031s	
27411/28500 (epoch 48.089), train_loss = 0.83290222, grad/param norm = 2.2041e-01, time/batch = 0.6907s	
27412/28500 (epoch 48.091), train_loss = 0.70582660, grad/param norm = 1.7861e-01, time/batch = 0.6921s	
27413/28500 (epoch 48.093), train_loss = 0.85412485, grad/param norm = 1.9853e-01, time/batch = 0.6889s	
27414/28500 (epoch 48.095), train_loss = 0.78246596, grad/param norm = 1.7772e-01, time/batch = 0.6883s	
27415/28500 (epoch 48.096), train_loss = 0.86180077, grad/param norm = 2.0194e-01, time/batch = 0.6884s	
27416/28500 (epoch 48.098), train_loss = 0.78623690, grad/param norm = 2.8591e-01, time/batch = 0.6885s	
27417/28500 (epoch 48.100), train_loss = 0.74233046, grad/param norm = 1.8489e-01, time/batch = 0.7015s	
27418/28500 (epoch 48.102), train_loss = 0.86830454, grad/param norm = 2.1123e-01, time/batch = 0.6982s	
27419/28500 (epoch 48.104), train_loss = 0.81181669, grad/param norm = 2.0213e-01, time/batch = 0.6883s	
27420/28500 (epoch 48.105), train_loss = 0.86066177, grad/param norm = 1.8569e-01, time/batch = 0.6887s	
27421/28500 (epoch 48.107), train_loss = 0.69919985, grad/param norm = 1.8373e-01, time/batch = 0.6911s	
27422/28500 (epoch 48.109), train_loss = 0.73133058, grad/param norm = 2.5986e-01, time/batch = 0.6901s	
27423/28500 (epoch 48.111), train_loss = 0.75826611, grad/param norm = 2.1170e-01, time/batch = 0.6891s	
27424/28500 (epoch 48.112), train_loss = 0.86470280, grad/param norm = 2.1041e-01, time/batch = 0.6900s	
27425/28500 (epoch 48.114), train_loss = 0.78087201, grad/param norm = 2.0101e-01, time/batch = 0.7195s	
27426/28500 (epoch 48.116), train_loss = 0.93583290, grad/param norm = 2.3482e-01, time/batch = 0.7018s	
27427/28500 (epoch 48.118), train_loss = 0.70513507, grad/param norm = 1.8705e-01, time/batch = 0.6896s	
27428/28500 (epoch 48.119), train_loss = 0.81748648, grad/param norm = 2.5436e-01, time/batch = 0.6916s	
27429/28500 (epoch 48.121), train_loss = 0.92551472, grad/param norm = 2.3752e-01, time/batch = 0.6877s	
27430/28500 (epoch 48.123), train_loss = 0.88478363, grad/param norm = 1.9640e-01, time/batch = 0.6913s	
27431/28500 (epoch 48.125), train_loss = 0.80183686, grad/param norm = 2.0929e-01, time/batch = 0.7009s	
27432/28500 (epoch 48.126), train_loss = 0.80275366, grad/param norm = 2.1939e-01, time/batch = 0.6976s	
27433/28500 (epoch 48.128), train_loss = 0.81247649, grad/param norm = 1.9262e-01, time/batch = 0.6962s	
27434/28500 (epoch 48.130), train_loss = 0.75512010, grad/param norm = 1.9028e-01, time/batch = 0.6896s	
27435/28500 (epoch 48.132), train_loss = 0.78408889, grad/param norm = 1.9715e-01, time/batch = 0.6915s	
27436/28500 (epoch 48.133), train_loss = 0.85221012, grad/param norm = 2.2203e-01, time/batch = 0.6896s	
27437/28500 (epoch 48.135), train_loss = 0.74345850, grad/param norm = 1.7790e-01, time/batch = 0.6881s	
27438/28500 (epoch 48.137), train_loss = 0.80009488, grad/param norm = 2.0061e-01, time/batch = 0.6882s	
27439/28500 (epoch 48.139), train_loss = 0.79111996, grad/param norm = 1.6549e-01, time/batch = 0.6918s	
27440/28500 (epoch 48.140), train_loss = 0.78526605, grad/param norm = 1.9971e-01, time/batch = 0.6933s	
27441/28500 (epoch 48.142), train_loss = 0.75431313, grad/param norm = 2.0809e-01, time/batch = 0.7087s	
27442/28500 (epoch 48.144), train_loss = 0.71265370, grad/param norm = 2.0930e-01, time/batch = 0.7008s	
27443/28500 (epoch 48.146), train_loss = 0.76793250, grad/param norm = 1.8966e-01, time/batch = 0.6943s	
27444/28500 (epoch 48.147), train_loss = 0.68344106, grad/param norm = 1.8616e-01, time/batch = 0.6900s	
27445/28500 (epoch 48.149), train_loss = 0.68287011, grad/param norm = 1.7618e-01, time/batch = 0.6880s	
27446/28500 (epoch 48.151), train_loss = 0.74362220, grad/param norm = 1.8836e-01, time/batch = 0.6937s	
27447/28500 (epoch 48.153), train_loss = 0.80781911, grad/param norm = 2.0090e-01, time/batch = 0.6909s	
27448/28500 (epoch 48.154), train_loss = 0.66576630, grad/param norm = 1.8076e-01, time/batch = 0.7117s	
27449/28500 (epoch 48.156), train_loss = 0.83617349, grad/param norm = 2.0625e-01, time/batch = 0.6912s	
27450/28500 (epoch 48.158), train_loss = 0.79879502, grad/param norm = 2.0831e-01, time/batch = 0.6969s	
27451/28500 (epoch 48.160), train_loss = 0.71131605, grad/param norm = 1.8111e-01, time/batch = 0.7070s	
27452/28500 (epoch 48.161), train_loss = 0.72164432, grad/param norm = 2.2505e-01, time/batch = 0.6924s	
27453/28500 (epoch 48.163), train_loss = 0.68026836, grad/param norm = 2.0046e-01, time/batch = 0.6925s	
27454/28500 (epoch 48.165), train_loss = 0.89239722, grad/param norm = 1.9712e-01, time/batch = 0.6908s	
27455/28500 (epoch 48.167), train_loss = 0.90390146, grad/param norm = 2.2749e-01, time/batch = 0.6926s	
27456/28500 (epoch 48.168), train_loss = 0.89555634, grad/param norm = 2.3266e-01, time/batch = 0.6900s	
27457/28500 (epoch 48.170), train_loss = 0.88183981, grad/param norm = 2.4012e-01, time/batch = 0.6886s	
27458/28500 (epoch 48.172), train_loss = 0.75921094, grad/param norm = 1.7034e-01, time/batch = 0.6890s	
27459/28500 (epoch 48.174), train_loss = 0.91562935, grad/param norm = 2.2847e-01, time/batch = 0.6897s	
27460/28500 (epoch 48.175), train_loss = 0.76327484, grad/param norm = 1.8693e-01, time/batch = 0.6886s	
27461/28500 (epoch 48.177), train_loss = 0.80384101, grad/param norm = 1.9867e-01, time/batch = 0.7121s	
27462/28500 (epoch 48.179), train_loss = 0.84633300, grad/param norm = 2.5629e-01, time/batch = 0.6919s	
27463/28500 (epoch 48.181), train_loss = 0.80148288, grad/param norm = 2.3103e-01, time/batch = 0.6898s	
27464/28500 (epoch 48.182), train_loss = 0.76211116, grad/param norm = 2.2331e-01, time/batch = 0.7015s	
27465/28500 (epoch 48.184), train_loss = 0.94328774, grad/param norm = 2.1806e-01, time/batch = 0.6938s	
27466/28500 (epoch 48.186), train_loss = 0.92669284, grad/param norm = 1.9282e-01, time/batch = 0.6890s	
27467/28500 (epoch 48.188), train_loss = 0.84004233, grad/param norm = 1.9988e-01, time/batch = 0.6893s	
27468/28500 (epoch 48.189), train_loss = 0.80513330, grad/param norm = 1.9497e-01, time/batch = 0.6884s	
27469/28500 (epoch 48.191), train_loss = 0.93546977, grad/param norm = 2.1278e-01, time/batch = 0.6950s	
27470/28500 (epoch 48.193), train_loss = 0.76809656, grad/param norm = 2.2253e-01, time/batch = 0.6887s	
27471/28500 (epoch 48.195), train_loss = 0.94156154, grad/param norm = 2.3818e-01, time/batch = 0.7054s	
27472/28500 (epoch 48.196), train_loss = 0.82552987, grad/param norm = 2.1715e-01, time/batch = 0.7014s	
27473/28500 (epoch 48.198), train_loss = 0.80415358, grad/param norm = 1.9667e-01, time/batch = 0.6913s	
27474/28500 (epoch 48.200), train_loss = 0.87339292, grad/param norm = 2.3102e-01, time/batch = 0.6919s	
27475/28500 (epoch 48.202), train_loss = 0.81145135, grad/param norm = 1.8032e-01, time/batch = 0.6889s	
27476/28500 (epoch 48.204), train_loss = 0.77151493, grad/param norm = 1.8009e-01, time/batch = 0.6930s	
27477/28500 (epoch 48.205), train_loss = 0.72875295, grad/param norm = 1.7803e-01, time/batch = 0.6927s	
27478/28500 (epoch 48.207), train_loss = 0.65976150, grad/param norm = 1.9995e-01, time/batch = 0.6945s	
27479/28500 (epoch 48.209), train_loss = 0.78039476, grad/param norm = 1.7607e-01, time/batch = 0.7052s	
27480/28500 (epoch 48.211), train_loss = 0.73768364, grad/param norm = 2.0701e-01, time/batch = 0.7115s	
27481/28500 (epoch 48.212), train_loss = 0.66493313, grad/param norm = 1.9499e-01, time/batch = 0.6990s	
27482/28500 (epoch 48.214), train_loss = 0.78855110, grad/param norm = 1.9785e-01, time/batch = 0.7012s	
27483/28500 (epoch 48.216), train_loss = 0.74450932, grad/param norm = 2.3759e-01, time/batch = 0.6963s	
27484/28500 (epoch 48.218), train_loss = 0.89571465, grad/param norm = 1.9248e-01, time/batch = 0.6978s	
27485/28500 (epoch 48.219), train_loss = 0.80630416, grad/param norm = 1.9232e-01, time/batch = 0.6938s	
27486/28500 (epoch 48.221), train_loss = 0.68347586, grad/param norm = 1.9439e-01, time/batch = 0.6895s	
27487/28500 (epoch 48.223), train_loss = 0.86610227, grad/param norm = 2.3072e-01, time/batch = 0.7002s	
27488/28500 (epoch 48.225), train_loss = 0.90543804, grad/param norm = 2.2585e-01, time/batch = 0.6959s	
27489/28500 (epoch 48.226), train_loss = 0.77761580, grad/param norm = 1.8931e-01, time/batch = 0.6898s	
27490/28500 (epoch 48.228), train_loss = 0.89805386, grad/param norm = 1.8937e-01, time/batch = 0.6897s	
27491/28500 (epoch 48.230), train_loss = 0.86716953, grad/param norm = 2.3329e-01, time/batch = 0.6917s	
27492/28500 (epoch 48.232), train_loss = 0.84041910, grad/param norm = 1.9168e-01, time/batch = 0.6946s	
27493/28500 (epoch 48.233), train_loss = 0.78922800, grad/param norm = 2.1868e-01, time/batch = 0.6916s	
27494/28500 (epoch 48.235), train_loss = 0.79096661, grad/param norm = 1.9937e-01, time/batch = 0.6897s	
27495/28500 (epoch 48.237), train_loss = 0.72804129, grad/param norm = 1.8613e-01, time/batch = 0.6911s	
27496/28500 (epoch 48.239), train_loss = 0.77573734, grad/param norm = 2.2350e-01, time/batch = 0.6912s	
27497/28500 (epoch 48.240), train_loss = 0.69831849, grad/param norm = 1.8729e-01, time/batch = 0.6888s	
27498/28500 (epoch 48.242), train_loss = 0.71613504, grad/param norm = 1.9882e-01, time/batch = 0.6947s	
27499/28500 (epoch 48.244), train_loss = 0.80345289, grad/param norm = 1.7738e-01, time/batch = 0.6927s	
27500/28500 (epoch 48.246), train_loss = 0.82499567, grad/param norm = 1.9777e-01, time/batch = 0.6883s	
27501/28500 (epoch 48.247), train_loss = 0.88279437, grad/param norm = 2.2029e-01, time/batch = 0.6904s	
27502/28500 (epoch 48.249), train_loss = 0.75838240, grad/param norm = 1.7436e-01, time/batch = 0.6892s	
27503/28500 (epoch 48.251), train_loss = 0.78823114, grad/param norm = 2.0211e-01, time/batch = 0.6884s	
27504/28500 (epoch 48.253), train_loss = 0.90998056, grad/param norm = 2.3560e-01, time/batch = 0.6884s	
27505/28500 (epoch 48.254), train_loss = 0.92800417, grad/param norm = 1.9115e-01, time/batch = 0.7076s	
27506/28500 (epoch 48.256), train_loss = 0.78687399, grad/param norm = 2.2202e-01, time/batch = 0.6905s	
27507/28500 (epoch 48.258), train_loss = 0.77450040, grad/param norm = 2.1228e-01, time/batch = 0.6920s	
27508/28500 (epoch 48.260), train_loss = 0.78456237, grad/param norm = 1.9091e-01, time/batch = 0.6906s	
27509/28500 (epoch 48.261), train_loss = 0.70066180, grad/param norm = 2.1237e-01, time/batch = 0.6879s	
27510/28500 (epoch 48.263), train_loss = 0.84029843, grad/param norm = 2.2518e-01, time/batch = 0.6885s	
27511/28500 (epoch 48.265), train_loss = 0.72660305, grad/param norm = 1.8512e-01, time/batch = 0.7013s	
27512/28500 (epoch 48.267), train_loss = 0.93799027, grad/param norm = 2.2036e-01, time/batch = 0.6999s	
27513/28500 (epoch 48.268), train_loss = 0.79813327, grad/param norm = 1.7709e-01, time/batch = 0.6991s	
27514/28500 (epoch 48.270), train_loss = 0.78661705, grad/param norm = 2.0919e-01, time/batch = 0.6979s	
27515/28500 (epoch 48.272), train_loss = 0.79258051, grad/param norm = 1.7996e-01, time/batch = 0.6998s	
27516/28500 (epoch 48.274), train_loss = 0.83713373, grad/param norm = 1.8613e-01, time/batch = 0.6932s	
27517/28500 (epoch 48.275), train_loss = 0.85608626, grad/param norm = 1.9594e-01, time/batch = 0.6885s	
27518/28500 (epoch 48.277), train_loss = 0.79007847, grad/param norm = 2.2105e-01, time/batch = 0.6881s	
27519/28500 (epoch 48.279), train_loss = 0.85578497, grad/param norm = 2.2683e-01, time/batch = 0.6880s	
27520/28500 (epoch 48.281), train_loss = 0.82411944, grad/param norm = 2.3341e-01, time/batch = 0.6882s	
27521/28500 (epoch 48.282), train_loss = 0.81505464, grad/param norm = 1.7596e-01, time/batch = 0.6922s	
27522/28500 (epoch 48.284), train_loss = 0.82823223, grad/param norm = 2.3390e-01, time/batch = 0.6895s	
27523/28500 (epoch 48.286), train_loss = 0.89425986, grad/param norm = 2.3360e-01, time/batch = 0.6886s	
27524/28500 (epoch 48.288), train_loss = 0.79402636, grad/param norm = 2.2475e-01, time/batch = 0.6898s	
27525/28500 (epoch 48.289), train_loss = 0.81226500, grad/param norm = 2.3092e-01, time/batch = 0.6889s	
27526/28500 (epoch 48.291), train_loss = 0.80989302, grad/param norm = 1.7591e-01, time/batch = 0.6901s	
27527/28500 (epoch 48.293), train_loss = 0.79792486, grad/param norm = 1.9356e-01, time/batch = 0.6907s	
27528/28500 (epoch 48.295), train_loss = 0.70434976, grad/param norm = 1.9018e-01, time/batch = 0.6896s	
27529/28500 (epoch 48.296), train_loss = 0.70938636, grad/param norm = 2.0859e-01, time/batch = 0.6882s	
27530/28500 (epoch 48.298), train_loss = 0.84986241, grad/param norm = 1.9380e-01, time/batch = 0.6884s	
27531/28500 (epoch 48.300), train_loss = 0.70701813, grad/param norm = 1.8534e-01, time/batch = 0.6907s	
27532/28500 (epoch 48.302), train_loss = 0.67758508, grad/param norm = 1.7797e-01, time/batch = 0.6888s	
27533/28500 (epoch 48.304), train_loss = 0.76851088, grad/param norm = 1.8397e-01, time/batch = 0.6883s	
27534/28500 (epoch 48.305), train_loss = 0.83659253, grad/param norm = 1.9308e-01, time/batch = 0.6885s	
27535/28500 (epoch 48.307), train_loss = 0.76904971, grad/param norm = 1.9452e-01, time/batch = 0.6901s	
27536/28500 (epoch 48.309), train_loss = 0.77511030, grad/param norm = 1.8934e-01, time/batch = 0.6943s	
27537/28500 (epoch 48.311), train_loss = 0.83291889, grad/param norm = 2.0877e-01, time/batch = 0.6949s	
27538/28500 (epoch 48.312), train_loss = 0.84021024, grad/param norm = 1.9649e-01, time/batch = 0.6957s	
27539/28500 (epoch 48.314), train_loss = 0.80012753, grad/param norm = 1.9450e-01, time/batch = 0.6905s	
27540/28500 (epoch 48.316), train_loss = 0.81661590, grad/param norm = 2.2044e-01, time/batch = 0.6950s	
27541/28500 (epoch 48.318), train_loss = 0.86331642, grad/param norm = 1.9589e-01, time/batch = 0.7122s	
27542/28500 (epoch 48.319), train_loss = 0.74068189, grad/param norm = 2.0988e-01, time/batch = 0.6965s	
27543/28500 (epoch 48.321), train_loss = 0.76415851, grad/param norm = 2.3966e-01, time/batch = 0.6973s	
27544/28500 (epoch 48.323), train_loss = 0.79863969, grad/param norm = 2.1051e-01, time/batch = 0.6949s	
27545/28500 (epoch 48.325), train_loss = 0.89432145, grad/param norm = 2.1497e-01, time/batch = 0.6956s	
27546/28500 (epoch 48.326), train_loss = 0.81909657, grad/param norm = 1.8805e-01, time/batch = 0.6938s	
27547/28500 (epoch 48.328), train_loss = 0.65530295, grad/param norm = 1.8807e-01, time/batch = 0.6942s	
27548/28500 (epoch 48.330), train_loss = 0.74524885, grad/param norm = 2.7318e-01, time/batch = 0.6930s	
27549/28500 (epoch 48.332), train_loss = 0.74123296, grad/param norm = 1.9206e-01, time/batch = 0.6929s	
27550/28500 (epoch 48.333), train_loss = 0.61995727, grad/param norm = 2.1842e-01, time/batch = 0.6949s	
27551/28500 (epoch 48.335), train_loss = 0.70282432, grad/param norm = 1.9163e-01, time/batch = 0.6969s	
27552/28500 (epoch 48.337), train_loss = 0.64074592, grad/param norm = 1.9771e-01, time/batch = 0.6957s	
27553/28500 (epoch 48.339), train_loss = 0.63929825, grad/param norm = 1.5347e-01, time/batch = 0.7028s	
27554/28500 (epoch 48.340), train_loss = 0.78442445, grad/param norm = 2.7424e-01, time/batch = 0.6925s	
27555/28500 (epoch 48.342), train_loss = 0.78704528, grad/param norm = 1.9704e-01, time/batch = 0.6923s	
27556/28500 (epoch 48.344), train_loss = 0.66888646, grad/param norm = 1.9322e-01, time/batch = 0.6927s	
27557/28500 (epoch 48.346), train_loss = 0.66130850, grad/param norm = 1.5622e-01, time/batch = 0.6949s	
27558/28500 (epoch 48.347), train_loss = 0.79064883, grad/param norm = 1.8689e-01, time/batch = 0.6930s	
27559/28500 (epoch 48.349), train_loss = 0.77374712, grad/param norm = 2.6153e-01, time/batch = 0.6926s	
27560/28500 (epoch 48.351), train_loss = 0.70746451, grad/param norm = 2.0590e-01, time/batch = 0.6926s	
27561/28500 (epoch 48.353), train_loss = 0.78994591, grad/param norm = 1.9920e-01, time/batch = 0.6944s	
27562/28500 (epoch 48.354), train_loss = 0.68401585, grad/param norm = 2.2081e-01, time/batch = 0.6938s	
27563/28500 (epoch 48.356), train_loss = 0.72565164, grad/param norm = 1.6989e-01, time/batch = 0.6927s	
27564/28500 (epoch 48.358), train_loss = 0.81355333, grad/param norm = 1.8856e-01, time/batch = 0.6937s	
27565/28500 (epoch 48.360), train_loss = 0.79549357, grad/param norm = 2.1780e-01, time/batch = 0.6941s	
27566/28500 (epoch 48.361), train_loss = 0.68550185, grad/param norm = 1.7933e-01, time/batch = 0.6932s	
27567/28500 (epoch 48.363), train_loss = 0.68517440, grad/param norm = 1.8949e-01, time/batch = 0.6918s	
27568/28500 (epoch 48.365), train_loss = 0.72176611, grad/param norm = 1.9523e-01, time/batch = 0.6919s	
27569/28500 (epoch 48.367), train_loss = 0.74922702, grad/param norm = 1.7691e-01, time/batch = 0.6976s	
27570/28500 (epoch 48.368), train_loss = 0.69844618, grad/param norm = 1.9130e-01, time/batch = 0.6923s	
27571/28500 (epoch 48.370), train_loss = 0.80505093, grad/param norm = 1.9067e-01, time/batch = 0.6952s	
27572/28500 (epoch 48.372), train_loss = 0.61696988, grad/param norm = 2.2229e-01, time/batch = 0.6937s	
27573/28500 (epoch 48.374), train_loss = 0.75838446, grad/param norm = 2.0996e-01, time/batch = 0.6953s	
27574/28500 (epoch 48.375), train_loss = 0.87469692, grad/param norm = 2.1561e-01, time/batch = 0.6964s	
27575/28500 (epoch 48.377), train_loss = 0.74097241, grad/param norm = 2.4281e-01, time/batch = 0.7002s	
27576/28500 (epoch 48.379), train_loss = 0.61073429, grad/param norm = 1.7018e-01, time/batch = 0.6947s	
27577/28500 (epoch 48.381), train_loss = 0.73151823, grad/param norm = 1.8134e-01, time/batch = 0.6961s	
27578/28500 (epoch 48.382), train_loss = 0.72422691, grad/param norm = 2.6606e-01, time/batch = 0.6935s	
27579/28500 (epoch 48.384), train_loss = 0.63415012, grad/param norm = 2.0137e-01, time/batch = 0.6948s	
27580/28500 (epoch 48.386), train_loss = 0.68360336, grad/param norm = 1.9120e-01, time/batch = 0.6933s	
27581/28500 (epoch 48.388), train_loss = 0.81609486, grad/param norm = 2.0332e-01, time/batch = 0.6953s	
27582/28500 (epoch 48.389), train_loss = 0.71164787, grad/param norm = 2.9679e-01, time/batch = 0.6950s	
27583/28500 (epoch 48.391), train_loss = 0.66483840, grad/param norm = 2.0361e-01, time/batch = 0.6939s	
27584/28500 (epoch 48.393), train_loss = 0.68171901, grad/param norm = 1.9321e-01, time/batch = 0.6928s	
27585/28500 (epoch 48.395), train_loss = 0.85464568, grad/param norm = 2.0090e-01, time/batch = 0.6932s	
27586/28500 (epoch 48.396), train_loss = 0.84488971, grad/param norm = 2.1685e-01, time/batch = 0.6934s	
27587/28500 (epoch 48.398), train_loss = 0.56840132, grad/param norm = 1.8221e-01, time/batch = 0.6925s	
27588/28500 (epoch 48.400), train_loss = 0.72557351, grad/param norm = 2.3199e-01, time/batch = 0.6932s	
27589/28500 (epoch 48.402), train_loss = 0.76338721, grad/param norm = 2.1623e-01, time/batch = 0.6953s	
27590/28500 (epoch 48.404), train_loss = 0.75554627, grad/param norm = 1.9838e-01, time/batch = 0.6926s	
27591/28500 (epoch 48.405), train_loss = 0.83014703, grad/param norm = 2.1145e-01, time/batch = 0.6953s	
27592/28500 (epoch 48.407), train_loss = 0.76296567, grad/param norm = 1.8844e-01, time/batch = 0.7003s	
27593/28500 (epoch 48.409), train_loss = 0.76662055, grad/param norm = 2.6454e-01, time/batch = 0.6925s	
27594/28500 (epoch 48.411), train_loss = 0.86793936, grad/param norm = 2.7292e-01, time/batch = 0.6946s	
27595/28500 (epoch 48.412), train_loss = 0.88523724, grad/param norm = 2.3265e-01, time/batch = 0.6932s	
27596/28500 (epoch 48.414), train_loss = 0.81685591, grad/param norm = 2.6215e-01, time/batch = 0.6922s	
27597/28500 (epoch 48.416), train_loss = 0.71216389, grad/param norm = 2.1976e-01, time/batch = 0.6927s	
27598/28500 (epoch 48.418), train_loss = 0.81001834, grad/param norm = 1.9050e-01, time/batch = 0.6914s	
27599/28500 (epoch 48.419), train_loss = 0.88632666, grad/param norm = 2.7853e-01, time/batch = 0.6927s	
27600/28500 (epoch 48.421), train_loss = 0.83768039, grad/param norm = 2.0660e-01, time/batch = 0.6917s	
27601/28500 (epoch 48.423), train_loss = 0.81550697, grad/param norm = 2.2006e-01, time/batch = 0.6950s	
27602/28500 (epoch 48.425), train_loss = 0.74580077, grad/param norm = 2.5376e-01, time/batch = 0.6942s	
27603/28500 (epoch 48.426), train_loss = 0.78407087, grad/param norm = 2.2720e-01, time/batch = 0.6923s	
27604/28500 (epoch 48.428), train_loss = 0.94680071, grad/param norm = 2.6928e-01, time/batch = 0.6934s	
27605/28500 (epoch 48.430), train_loss = 0.91753429, grad/param norm = 1.8437e-01, time/batch = 0.6951s	
27606/28500 (epoch 48.432), train_loss = 0.80951933, grad/param norm = 2.0711e-01, time/batch = 0.6974s	
27607/28500 (epoch 48.433), train_loss = 0.85891639, grad/param norm = 2.3922e-01, time/batch = 0.7012s	
27608/28500 (epoch 48.435), train_loss = 0.78882311, grad/param norm = 2.0092e-01, time/batch = 0.6975s	
27609/28500 (epoch 48.437), train_loss = 0.74712571, grad/param norm = 1.9934e-01, time/batch = 0.6929s	
27610/28500 (epoch 48.439), train_loss = 0.79107497, grad/param norm = 1.8630e-01, time/batch = 0.6886s	
27611/28500 (epoch 48.440), train_loss = 0.93376885, grad/param norm = 2.0769e-01, time/batch = 0.6918s	
27612/28500 (epoch 48.442), train_loss = 0.73865411, grad/param norm = 2.0574e-01, time/batch = 0.6892s	
27613/28500 (epoch 48.444), train_loss = 0.70932960, grad/param norm = 1.5745e-01, time/batch = 0.6922s	
27614/28500 (epoch 48.446), train_loss = 0.67637043, grad/param norm = 1.7707e-01, time/batch = 0.6910s	
27615/28500 (epoch 48.447), train_loss = 0.67006602, grad/param norm = 1.7414e-01, time/batch = 0.6889s	
27616/28500 (epoch 48.449), train_loss = 0.74325962, grad/param norm = 1.9506e-01, time/batch = 0.6893s	
27617/28500 (epoch 48.451), train_loss = 0.75032699, grad/param norm = 1.9701e-01, time/batch = 0.6897s	
27618/28500 (epoch 48.453), train_loss = 0.74329022, grad/param norm = 1.9415e-01, time/batch = 0.6896s	
27619/28500 (epoch 48.454), train_loss = 0.69568722, grad/param norm = 1.7364e-01, time/batch = 0.6902s	
27620/28500 (epoch 48.456), train_loss = 0.82283648, grad/param norm = 2.1893e-01, time/batch = 0.6922s	
27621/28500 (epoch 48.458), train_loss = 0.72448055, grad/param norm = 1.9733e-01, time/batch = 0.6954s	
27622/28500 (epoch 48.460), train_loss = 0.84284462, grad/param norm = 1.8867e-01, time/batch = 0.6975s	
27623/28500 (epoch 48.461), train_loss = 0.68669796, grad/param norm = 1.9280e-01, time/batch = 0.7064s	
27624/28500 (epoch 48.463), train_loss = 0.63307543, grad/param norm = 1.6088e-01, time/batch = 0.6926s	
27625/28500 (epoch 48.465), train_loss = 0.61140412, grad/param norm = 2.5813e-01, time/batch = 0.6901s	
27626/28500 (epoch 48.467), train_loss = 0.77216128, grad/param norm = 1.8208e-01, time/batch = 0.6901s	
27627/28500 (epoch 48.468), train_loss = 0.68773283, grad/param norm = 1.6967e-01, time/batch = 0.6890s	
27628/28500 (epoch 48.470), train_loss = 0.71651428, grad/param norm = 2.1997e-01, time/batch = 0.6897s	
27629/28500 (epoch 48.472), train_loss = 0.69243838, grad/param norm = 1.7550e-01, time/batch = 0.6965s	
27630/28500 (epoch 48.474), train_loss = 0.90480248, grad/param norm = 2.1512e-01, time/batch = 0.7017s	
27631/28500 (epoch 48.475), train_loss = 0.72517550, grad/param norm = 2.0096e-01, time/batch = 0.6924s	
27632/28500 (epoch 48.477), train_loss = 0.76006566, grad/param norm = 1.8781e-01, time/batch = 0.6917s	
27633/28500 (epoch 48.479), train_loss = 0.80475850, grad/param norm = 1.9581e-01, time/batch = 0.6903s	
27634/28500 (epoch 48.481), train_loss = 0.79585933, grad/param norm = 2.0000e-01, time/batch = 0.6900s	
27635/28500 (epoch 48.482), train_loss = 0.65001200, grad/param norm = 1.7372e-01, time/batch = 0.6903s	
27636/28500 (epoch 48.484), train_loss = 0.70709880, grad/param norm = 1.7475e-01, time/batch = 0.6914s	
27637/28500 (epoch 48.486), train_loss = 0.62392238, grad/param norm = 1.8546e-01, time/batch = 0.6917s	
27638/28500 (epoch 48.488), train_loss = 0.79817453, grad/param norm = 1.8697e-01, time/batch = 0.6894s	
27639/28500 (epoch 48.489), train_loss = 0.89917737, grad/param norm = 1.7643e-01, time/batch = 0.6900s	
27640/28500 (epoch 48.491), train_loss = 0.72257048, grad/param norm = 1.9485e-01, time/batch = 0.6903s	
27641/28500 (epoch 48.493), train_loss = 0.74609168, grad/param norm = 1.9874e-01, time/batch = 0.7021s	
27642/28500 (epoch 48.495), train_loss = 0.77310692, grad/param norm = 2.2411e-01, time/batch = 0.6941s	
27643/28500 (epoch 48.496), train_loss = 0.68415357, grad/param norm = 2.1294e-01, time/batch = 0.6903s	
27644/28500 (epoch 48.498), train_loss = 0.75471502, grad/param norm = 1.9075e-01, time/batch = 0.6891s	
27645/28500 (epoch 48.500), train_loss = 0.70777736, grad/param norm = 1.7942e-01, time/batch = 0.6909s	
27646/28500 (epoch 48.502), train_loss = 0.78071682, grad/param norm = 2.0263e-01, time/batch = 0.6896s	
27647/28500 (epoch 48.504), train_loss = 0.84159798, grad/param norm = 1.7571e-01, time/batch = 0.6891s	
27648/28500 (epoch 48.505), train_loss = 0.69774015, grad/param norm = 1.6807e-01, time/batch = 0.6907s	
27649/28500 (epoch 48.507), train_loss = 0.84587090, grad/param norm = 2.1202e-01, time/batch = 0.6889s	
27650/28500 (epoch 48.509), train_loss = 0.74297037, grad/param norm = 1.9794e-01, time/batch = 0.6894s	
27651/28500 (epoch 48.511), train_loss = 0.75115320, grad/param norm = 1.6977e-01, time/batch = 0.6933s	
27652/28500 (epoch 48.512), train_loss = 0.81743241, grad/param norm = 1.8501e-01, time/batch = 0.6921s	
27653/28500 (epoch 48.514), train_loss = 0.73859638, grad/param norm = 1.7433e-01, time/batch = 0.6893s	
27654/28500 (epoch 48.516), train_loss = 0.77560420, grad/param norm = 1.8802e-01, time/batch = 0.6896s	
27655/28500 (epoch 48.518), train_loss = 0.80134192, grad/param norm = 1.9152e-01, time/batch = 0.6885s	
27656/28500 (epoch 48.519), train_loss = 0.78832069, grad/param norm = 1.8262e-01, time/batch = 0.6886s	
27657/28500 (epoch 48.521), train_loss = 0.87818059, grad/param norm = 2.8361e-01, time/batch = 0.6885s	
27658/28500 (epoch 48.523), train_loss = 0.80805283, grad/param norm = 2.2651e-01, time/batch = 0.6882s	
27659/28500 (epoch 48.525), train_loss = 0.86727785, grad/param norm = 1.9819e-01, time/batch = 0.6883s	
27660/28500 (epoch 48.526), train_loss = 0.78642646, grad/param norm = 1.8921e-01, time/batch = 0.6886s	
27661/28500 (epoch 48.528), train_loss = 0.81876155, grad/param norm = 3.2367e-01, time/batch = 0.6900s	
27662/28500 (epoch 48.530), train_loss = 0.80269480, grad/param norm = 2.2899e-01, time/batch = 0.6888s	
27663/28500 (epoch 48.532), train_loss = 0.76643005, grad/param norm = 1.9542e-01, time/batch = 0.6908s	
27664/28500 (epoch 48.533), train_loss = 0.80158508, grad/param norm = 2.1313e-01, time/batch = 0.6891s	
27665/28500 (epoch 48.535), train_loss = 0.69433115, grad/param norm = 1.7891e-01, time/batch = 0.6887s	
27666/28500 (epoch 48.537), train_loss = 0.65081304, grad/param norm = 1.6100e-01, time/batch = 0.6916s	
27667/28500 (epoch 48.539), train_loss = 0.66813861, grad/param norm = 1.9384e-01, time/batch = 0.6892s	
27668/28500 (epoch 48.540), train_loss = 0.73841070, grad/param norm = 1.9520e-01, time/batch = 0.6904s	
27669/28500 (epoch 48.542), train_loss = 0.79569305, grad/param norm = 2.4520e-01, time/batch = 0.6901s	
27670/28500 (epoch 48.544), train_loss = 0.89907886, grad/param norm = 2.1966e-01, time/batch = 0.6894s	
27671/28500 (epoch 48.546), train_loss = 0.77528696, grad/param norm = 2.0895e-01, time/batch = 0.7079s	
27672/28500 (epoch 48.547), train_loss = 0.73904029, grad/param norm = 1.7168e-01, time/batch = 0.6977s	
27673/28500 (epoch 48.549), train_loss = 0.65040598, grad/param norm = 1.6324e-01, time/batch = 0.6929s	
27674/28500 (epoch 48.551), train_loss = 0.70434414, grad/param norm = 2.1772e-01, time/batch = 0.6906s	
27675/28500 (epoch 48.553), train_loss = 0.90441534, grad/param norm = 2.5651e-01, time/batch = 0.6921s	
27676/28500 (epoch 48.554), train_loss = 0.78767094, grad/param norm = 1.9666e-01, time/batch = 0.6895s	
27677/28500 (epoch 48.556), train_loss = 0.79036559, grad/param norm = 1.9080e-01, time/batch = 0.6836s	
27678/28500 (epoch 48.558), train_loss = 0.81397679, grad/param norm = 1.8927e-01, time/batch = 0.6798s	
27679/28500 (epoch 48.560), train_loss = 0.82264047, grad/param norm = 2.2398e-01, time/batch = 0.6776s	
27680/28500 (epoch 48.561), train_loss = 0.82009144, grad/param norm = 1.9110e-01, time/batch = 0.9065s	
27681/28500 (epoch 48.563), train_loss = 0.89715668, grad/param norm = 2.3429e-01, time/batch = 1.0033s	
27682/28500 (epoch 48.565), train_loss = 0.74317077, grad/param norm = 1.9600e-01, time/batch = 0.9969s	
27683/28500 (epoch 48.567), train_loss = 0.64890328, grad/param norm = 1.7305e-01, time/batch = 0.9936s	
27684/28500 (epoch 48.568), train_loss = 0.79084564, grad/param norm = 2.1586e-01, time/batch = 1.0167s	
27685/28500 (epoch 48.570), train_loss = 0.73595873, grad/param norm = 1.8305e-01, time/batch = 1.0085s	
27686/28500 (epoch 48.572), train_loss = 0.78614548, grad/param norm = 1.8408e-01, time/batch = 1.4123s	
27687/28500 (epoch 48.574), train_loss = 0.74783048, grad/param norm = 1.7962e-01, time/batch = 1.9194s	
27688/28500 (epoch 48.575), train_loss = 0.71578864, grad/param norm = 1.8278e-01, time/batch = 1.8761s	
27689/28500 (epoch 48.577), train_loss = 0.84609921, grad/param norm = 2.0449e-01, time/batch = 1.8630s	
27690/28500 (epoch 48.579), train_loss = 0.84951055, grad/param norm = 2.2642e-01, time/batch = 1.8673s	
27691/28500 (epoch 48.581), train_loss = 0.71468525, grad/param norm = 1.9727e-01, time/batch = 1.8904s	
27692/28500 (epoch 48.582), train_loss = 0.87635074, grad/param norm = 1.9429e-01, time/batch = 12.2815s	
27693/28500 (epoch 48.584), train_loss = 0.73196534, grad/param norm = 1.9856e-01, time/batch = 15.3976s	
27694/28500 (epoch 48.586), train_loss = 0.69968102, grad/param norm = 1.6231e-01, time/batch = 15.3723s	
27695/28500 (epoch 48.588), train_loss = 0.71322722, grad/param norm = 1.9899e-01, time/batch = 15.4232s	
27696/28500 (epoch 48.589), train_loss = 0.75227662, grad/param norm = 1.8153e-01, time/batch = 25.4352s	
27697/28500 (epoch 48.591), train_loss = 0.78602216, grad/param norm = 2.0592e-01, time/batch = 17.4397s	
27698/28500 (epoch 48.593), train_loss = 0.70049102, grad/param norm = 2.0402e-01, time/batch = 15.0637s	
27699/28500 (epoch 48.595), train_loss = 0.92043343, grad/param norm = 2.1522e-01, time/batch = 15.0436s	
27700/28500 (epoch 48.596), train_loss = 0.91535882, grad/param norm = 1.9691e-01, time/batch = 15.3041s	
27701/28500 (epoch 48.598), train_loss = 0.75853000, grad/param norm = 1.9214e-01, time/batch = 15.6359s	
27702/28500 (epoch 48.600), train_loss = 0.74014531, grad/param norm = 1.9304e-01, time/batch = 15.3146s	
27703/28500 (epoch 48.602), train_loss = 0.84200348, grad/param norm = 2.6327e-01, time/batch = 15.3799s	
27704/28500 (epoch 48.604), train_loss = 0.86674321, grad/param norm = 1.7424e-01, time/batch = 15.3124s	
27705/28500 (epoch 48.605), train_loss = 0.86355584, grad/param norm = 2.5664e-01, time/batch = 15.3884s	
27706/28500 (epoch 48.607), train_loss = 0.88770744, grad/param norm = 1.9134e-01, time/batch = 15.3120s	
27707/28500 (epoch 48.609), train_loss = 0.79165502, grad/param norm = 2.0875e-01, time/batch = 15.5221s	
27708/28500 (epoch 48.611), train_loss = 0.77388504, grad/param norm = 2.0240e-01, time/batch = 15.4662s	
27709/28500 (epoch 48.612), train_loss = 0.84710179, grad/param norm = 2.9432e-01, time/batch = 15.2842s	
27710/28500 (epoch 48.614), train_loss = 0.87962806, grad/param norm = 2.0227e-01, time/batch = 15.3123s	
27711/28500 (epoch 48.616), train_loss = 0.76134841, grad/param norm = 2.1530e-01, time/batch = 15.2098s	
27712/28500 (epoch 48.618), train_loss = 0.76542838, grad/param norm = 2.3988e-01, time/batch = 15.5536s	
27713/28500 (epoch 48.619), train_loss = 0.86296570, grad/param norm = 2.5737e-01, time/batch = 15.5726s	
27714/28500 (epoch 48.621), train_loss = 0.62524767, grad/param norm = 1.7596e-01, time/batch = 15.6391s	
27715/28500 (epoch 48.623), train_loss = 0.89874080, grad/param norm = 2.1346e-01, time/batch = 15.3918s	
27716/28500 (epoch 48.625), train_loss = 0.68979704, grad/param norm = 1.7853e-01, time/batch = 15.3062s	
27717/28500 (epoch 48.626), train_loss = 0.63752428, grad/param norm = 1.9368e-01, time/batch = 15.4638s	
27718/28500 (epoch 48.628), train_loss = 0.72045830, grad/param norm = 2.0869e-01, time/batch = 15.5285s	
27719/28500 (epoch 48.630), train_loss = 0.70114384, grad/param norm = 1.9925e-01, time/batch = 15.6135s	
27720/28500 (epoch 48.632), train_loss = 0.87445323, grad/param norm = 2.1542e-01, time/batch = 15.1410s	
27721/28500 (epoch 48.633), train_loss = 0.89531222, grad/param norm = 1.9358e-01, time/batch = 15.4819s	
27722/28500 (epoch 48.635), train_loss = 0.80554197, grad/param norm = 2.4419e-01, time/batch = 15.5737s	
27723/28500 (epoch 48.637), train_loss = 0.78160058, grad/param norm = 1.7471e-01, time/batch = 15.3934s	
27724/28500 (epoch 48.639), train_loss = 0.69266577, grad/param norm = 2.0666e-01, time/batch = 15.2329s	
27725/28500 (epoch 48.640), train_loss = 0.73017366, grad/param norm = 1.6625e-01, time/batch = 15.4934s	
27726/28500 (epoch 48.642), train_loss = 0.72426534, grad/param norm = 1.8912e-01, time/batch = 15.4757s	
27727/28500 (epoch 48.644), train_loss = 0.82269410, grad/param norm = 2.1401e-01, time/batch = 15.5338s	
27728/28500 (epoch 48.646), train_loss = 0.61794064, grad/param norm = 1.4624e-01, time/batch = 15.2420s	
27729/28500 (epoch 48.647), train_loss = 0.73996313, grad/param norm = 1.9981e-01, time/batch = 15.3923s	
27730/28500 (epoch 48.649), train_loss = 0.72112078, grad/param norm = 2.2166e-01, time/batch = 15.3735s	
27731/28500 (epoch 48.651), train_loss = 0.67965589, grad/param norm = 1.5658e-01, time/batch = 15.4738s	
27732/28500 (epoch 48.653), train_loss = 0.68343898, grad/param norm = 2.0723e-01, time/batch = 15.2176s	
27733/28500 (epoch 48.654), train_loss = 0.69608839, grad/param norm = 2.0286e-01, time/batch = 15.2272s	
27734/28500 (epoch 48.656), train_loss = 0.64995079, grad/param norm = 2.5962e-01, time/batch = 15.4148s	
27735/28500 (epoch 48.658), train_loss = 0.76680071, grad/param norm = 1.8777e-01, time/batch = 15.2821s	
27736/28500 (epoch 48.660), train_loss = 0.75580824, grad/param norm = 1.6740e-01, time/batch = 15.2301s	
27737/28500 (epoch 48.661), train_loss = 0.86525839, grad/param norm = 2.2256e-01, time/batch = 15.4644s	
27738/28500 (epoch 48.663), train_loss = 0.87208527, grad/param norm = 2.7831e-01, time/batch = 15.3687s	
27739/28500 (epoch 48.665), train_loss = 0.75826800, grad/param norm = 1.8044e-01, time/batch = 15.2022s	
27740/28500 (epoch 48.667), train_loss = 0.81294538, grad/param norm = 2.3596e-01, time/batch = 15.0539s	
27741/28500 (epoch 48.668), train_loss = 0.76111833, grad/param norm = 1.9187e-01, time/batch = 15.1025s	
27742/28500 (epoch 48.670), train_loss = 0.79908148, grad/param norm = 2.0214e-01, time/batch = 15.6225s	
27743/28500 (epoch 48.672), train_loss = 0.70370829, grad/param norm = 1.7672e-01, time/batch = 15.3976s	
27744/28500 (epoch 48.674), train_loss = 0.62298976, grad/param norm = 2.0273e-01, time/batch = 15.2272s	
27745/28500 (epoch 48.675), train_loss = 0.67096906, grad/param norm = 1.8519e-01, time/batch = 15.3977s	
27746/28500 (epoch 48.677), train_loss = 0.73977046, grad/param norm = 1.8478e-01, time/batch = 15.5565s	
27747/28500 (epoch 48.679), train_loss = 0.74136131, grad/param norm = 2.0973e-01, time/batch = 15.6310s	
27748/28500 (epoch 48.681), train_loss = 0.80751975, grad/param norm = 2.2012e-01, time/batch = 15.0895s	
27749/28500 (epoch 48.682), train_loss = 0.74021267, grad/param norm = 1.8051e-01, time/batch = 15.2316s	
27750/28500 (epoch 48.684), train_loss = 0.77070028, grad/param norm = 1.9286e-01, time/batch = 15.4433s	
27751/28500 (epoch 48.686), train_loss = 0.72776091, grad/param norm = 1.7907e-01, time/batch = 15.5591s	
27752/28500 (epoch 48.688), train_loss = 0.70422321, grad/param norm = 1.6544e-01, time/batch = 15.3974s	
27753/28500 (epoch 48.689), train_loss = 0.71495567, grad/param norm = 2.1849e-01, time/batch = 15.5569s	
27754/28500 (epoch 48.691), train_loss = 0.80825023, grad/param norm = 1.9307e-01, time/batch = 15.6292s	
27755/28500 (epoch 48.693), train_loss = 0.73092394, grad/param norm = 2.1095e-01, time/batch = 15.4062s	
27756/28500 (epoch 48.695), train_loss = 0.56272404, grad/param norm = 1.9526e-01, time/batch = 15.3136s	
27757/28500 (epoch 48.696), train_loss = 0.72035530, grad/param norm = 1.9841e-01, time/batch = 15.2303s	
27758/28500 (epoch 48.698), train_loss = 0.80468884, grad/param norm = 1.9900e-01, time/batch = 15.2677s	
27759/28500 (epoch 48.700), train_loss = 0.75647801, grad/param norm = 2.1935e-01, time/batch = 15.2763s	
27760/28500 (epoch 48.702), train_loss = 0.76087474, grad/param norm = 2.5147e-01, time/batch = 15.2947s	
27761/28500 (epoch 48.704), train_loss = 0.81430305, grad/param norm = 1.8497e-01, time/batch = 15.5727s	
27762/28500 (epoch 48.705), train_loss = 0.83129921, grad/param norm = 2.4238e-01, time/batch = 15.3770s	
27763/28500 (epoch 48.707), train_loss = 0.71204505, grad/param norm = 2.1350e-01, time/batch = 15.3825s	
27764/28500 (epoch 48.709), train_loss = 0.90417885, grad/param norm = 2.1224e-01, time/batch = 15.4882s	
27765/28500 (epoch 48.711), train_loss = 0.72212259, grad/param norm = 2.3145e-01, time/batch = 15.3655s	
27766/28500 (epoch 48.712), train_loss = 0.79212831, grad/param norm = 2.0174e-01, time/batch = 15.5524s	
27767/28500 (epoch 48.714), train_loss = 0.91434873, grad/param norm = 2.5261e-01, time/batch = 15.5309s	
27768/28500 (epoch 48.716), train_loss = 0.73562017, grad/param norm = 2.1042e-01, time/batch = 15.1315s	
27769/28500 (epoch 48.718), train_loss = 0.79964047, grad/param norm = 2.0438e-01, time/batch = 15.4024s	
27770/28500 (epoch 48.719), train_loss = 0.78606622, grad/param norm = 1.8148e-01, time/batch = 15.2934s	
27771/28500 (epoch 48.721), train_loss = 0.59521344, grad/param norm = 1.7593e-01, time/batch = 15.2346s	
27772/28500 (epoch 48.723), train_loss = 0.76645955, grad/param norm = 2.0943e-01, time/batch = 15.1386s	
27773/28500 (epoch 48.725), train_loss = 0.83932165, grad/param norm = 2.3036e-01, time/batch = 15.1428s	
27774/28500 (epoch 48.726), train_loss = 0.73735283, grad/param norm = 1.7834e-01, time/batch = 15.3421s	
27775/28500 (epoch 48.728), train_loss = 0.67700308, grad/param norm = 1.8465e-01, time/batch = 15.3647s	
27776/28500 (epoch 48.730), train_loss = 0.76111092, grad/param norm = 2.0494e-01, time/batch = 15.1550s	
27777/28500 (epoch 48.732), train_loss = 0.61523674, grad/param norm = 1.6389e-01, time/batch = 15.1168s	
27778/28500 (epoch 48.733), train_loss = 0.65243806, grad/param norm = 1.7550e-01, time/batch = 15.0447s	
27779/28500 (epoch 48.735), train_loss = 0.66252254, grad/param norm = 1.9318e-01, time/batch = 15.0241s	
27780/28500 (epoch 48.737), train_loss = 0.58556886, grad/param norm = 1.5788e-01, time/batch = 15.1272s	
27781/28500 (epoch 48.739), train_loss = 0.65679433, grad/param norm = 1.7862e-01, time/batch = 15.3632s	
27782/28500 (epoch 48.740), train_loss = 0.75051142, grad/param norm = 1.8794e-01, time/batch = 15.5327s	
27783/28500 (epoch 48.742), train_loss = 0.68818648, grad/param norm = 1.9863e-01, time/batch = 15.3922s	
27784/28500 (epoch 48.744), train_loss = 0.75450576, grad/param norm = 1.8745e-01, time/batch = 15.2307s	
27785/28500 (epoch 48.746), train_loss = 0.73202479, grad/param norm = 1.7461e-01, time/batch = 15.5051s	
27786/28500 (epoch 48.747), train_loss = 0.71986947, grad/param norm = 1.7929e-01, time/batch = 15.4533s	
27787/28500 (epoch 48.749), train_loss = 0.80870015, grad/param norm = 2.2772e-01, time/batch = 15.2352s	
27788/28500 (epoch 48.751), train_loss = 0.70704052, grad/param norm = 3.3985e-01, time/batch = 15.2349s	
27789/28500 (epoch 48.753), train_loss = 0.77676428, grad/param norm = 1.6493e-01, time/batch = 15.1600s	
27790/28500 (epoch 48.754), train_loss = 0.67213290, grad/param norm = 1.9377e-01, time/batch = 15.2248s	
27791/28500 (epoch 48.756), train_loss = 0.88073940, grad/param norm = 2.0750e-01, time/batch = 15.2313s	
27792/28500 (epoch 48.758), train_loss = 0.79089624, grad/param norm = 2.0646e-01, time/batch = 15.2775s	
27793/28500 (epoch 48.760), train_loss = 0.67137055, grad/param norm = 2.0017e-01, time/batch = 15.3116s	
27794/28500 (epoch 48.761), train_loss = 0.71995629, grad/param norm = 2.1188e-01, time/batch = 15.2468s	
27795/28500 (epoch 48.763), train_loss = 0.59931032, grad/param norm = 1.6599e-01, time/batch = 15.1281s	
27796/28500 (epoch 48.765), train_loss = 0.74536449, grad/param norm = 1.8036e-01, time/batch = 14.9781s	
27797/28500 (epoch 48.767), train_loss = 0.60586636, grad/param norm = 1.9449e-01, time/batch = 15.2021s	
27798/28500 (epoch 48.768), train_loss = 0.79562405, grad/param norm = 1.7395e-01, time/batch = 15.2061s	
27799/28500 (epoch 48.770), train_loss = 0.66015522, grad/param norm = 1.8448e-01, time/batch = 15.0476s	
27800/28500 (epoch 48.772), train_loss = 0.61366499, grad/param norm = 1.5039e-01, time/batch = 15.2118s	
27801/28500 (epoch 48.774), train_loss = 0.74905729, grad/param norm = 1.9894e-01, time/batch = 15.6530s	
27802/28500 (epoch 48.775), train_loss = 0.78963882, grad/param norm = 1.8142e-01, time/batch = 15.3666s	
27803/28500 (epoch 48.777), train_loss = 0.81185724, grad/param norm = 1.7261e-01, time/batch = 15.2437s	
27804/28500 (epoch 48.779), train_loss = 0.64610531, grad/param norm = 1.4942e-01, time/batch = 15.3488s	
27805/28500 (epoch 48.781), train_loss = 0.73921639, grad/param norm = 1.8734e-01, time/batch = 15.3240s	
27806/28500 (epoch 48.782), train_loss = 0.76194958, grad/param norm = 1.8733e-01, time/batch = 15.3886s	
27807/28500 (epoch 48.784), train_loss = 0.60069457, grad/param norm = 1.7820e-01, time/batch = 15.3266s	
27808/28500 (epoch 48.786), train_loss = 0.62371897, grad/param norm = 1.7604e-01, time/batch = 15.1981s	
27809/28500 (epoch 48.788), train_loss = 0.70086555, grad/param norm = 2.0243e-01, time/batch = 15.0479s	
27810/28500 (epoch 48.789), train_loss = 0.54544361, grad/param norm = 1.9305e-01, time/batch = 15.4570s	
27811/28500 (epoch 48.791), train_loss = 0.76489682, grad/param norm = 1.7968e-01, time/batch = 15.4814s	
27812/28500 (epoch 48.793), train_loss = 0.71557657, grad/param norm = 1.8515e-01, time/batch = 15.5251s	
27813/28500 (epoch 48.795), train_loss = 0.73973087, grad/param norm = 1.8524e-01, time/batch = 15.3679s	
27814/28500 (epoch 48.796), train_loss = 0.67942559, grad/param norm = 1.7847e-01, time/batch = 15.4133s	
27815/28500 (epoch 48.798), train_loss = 0.62098235, grad/param norm = 1.9026e-01, time/batch = 15.3948s	
27816/28500 (epoch 48.800), train_loss = 0.60909219, grad/param norm = 2.0391e-01, time/batch = 15.5159s	
27817/28500 (epoch 48.802), train_loss = 0.70537490, grad/param norm = 2.4553e-01, time/batch = 15.5270s	
27818/28500 (epoch 48.804), train_loss = 0.75588719, grad/param norm = 2.0358e-01, time/batch = 15.5229s	
27819/28500 (epoch 48.805), train_loss = 0.78535454, grad/param norm = 2.2541e-01, time/batch = 15.3821s	
27820/28500 (epoch 48.807), train_loss = 0.75560126, grad/param norm = 1.9860e-01, time/batch = 15.4461s	
27821/28500 (epoch 48.809), train_loss = 0.75139636, grad/param norm = 2.1483e-01, time/batch = 15.5342s	
27822/28500 (epoch 48.811), train_loss = 0.74639407, grad/param norm = 2.1399e-01, time/batch = 15.5635s	
27823/28500 (epoch 48.812), train_loss = 0.72953397, grad/param norm = 2.2350e-01, time/batch = 15.5255s	
27824/28500 (epoch 48.814), train_loss = 0.69574828, grad/param norm = 2.1726e-01, time/batch = 15.0769s	
27825/28500 (epoch 48.816), train_loss = 0.76993556, grad/param norm = 2.1718e-01, time/batch = 15.2315s	
27826/28500 (epoch 48.818), train_loss = 0.85023271, grad/param norm = 2.0914e-01, time/batch = 15.2932s	
27827/28500 (epoch 48.819), train_loss = 0.75805091, grad/param norm = 2.2205e-01, time/batch = 15.2799s	
27828/28500 (epoch 48.821), train_loss = 0.73438119, grad/param norm = 1.9433e-01, time/batch = 15.6486s	
27829/28500 (epoch 48.823), train_loss = 0.85942731, grad/param norm = 2.4393e-01, time/batch = 15.3800s	
27830/28500 (epoch 48.825), train_loss = 0.66250344, grad/param norm = 2.2055e-01, time/batch = 15.5333s	
27831/28500 (epoch 48.826), train_loss = 0.75759752, grad/param norm = 2.1498e-01, time/batch = 15.2953s	
27832/28500 (epoch 48.828), train_loss = 0.68657109, grad/param norm = 2.0468e-01, time/batch = 15.1940s	
27833/28500 (epoch 48.830), train_loss = 0.71306588, grad/param norm = 1.6215e-01, time/batch = 15.5209s	
27834/28500 (epoch 48.832), train_loss = 0.72617369, grad/param norm = 2.1941e-01, time/batch = 15.2815s	
27835/28500 (epoch 48.833), train_loss = 0.76979545, grad/param norm = 1.8210e-01, time/batch = 15.2934s	
27836/28500 (epoch 48.835), train_loss = 0.71357703, grad/param norm = 2.0153e-01, time/batch = 15.4264s	
27837/28500 (epoch 48.837), train_loss = 0.63181512, grad/param norm = 1.9723e-01, time/batch = 15.5058s	
27838/28500 (epoch 48.839), train_loss = 0.89052978, grad/param norm = 2.2672e-01, time/batch = 15.5786s	
27839/28500 (epoch 48.840), train_loss = 0.88340900, grad/param norm = 2.1950e-01, time/batch = 15.6080s	
27840/28500 (epoch 48.842), train_loss = 0.83302814, grad/param norm = 2.8829e-01, time/batch = 15.3186s	
27841/28500 (epoch 48.844), train_loss = 0.85359367, grad/param norm = 2.2272e-01, time/batch = 15.4982s	
27842/28500 (epoch 48.846), train_loss = 0.88903262, grad/param norm = 2.2628e-01, time/batch = 15.3692s	
27843/28500 (epoch 48.847), train_loss = 0.74131341, grad/param norm = 2.1573e-01, time/batch = 15.3792s	
27844/28500 (epoch 48.849), train_loss = 0.71225212, grad/param norm = 1.8077e-01, time/batch = 15.3687s	
27845/28500 (epoch 48.851), train_loss = 0.69465263, grad/param norm = 1.6889e-01, time/batch = 15.3064s	
27846/28500 (epoch 48.853), train_loss = 0.81636584, grad/param norm = 3.1638e-01, time/batch = 15.3682s	
27847/28500 (epoch 48.854), train_loss = 0.76948071, grad/param norm = 2.0371e-01, time/batch = 15.2998s	
27848/28500 (epoch 48.856), train_loss = 0.85320636, grad/param norm = 2.5505e-01, time/batch = 15.4714s	
27849/28500 (epoch 48.858), train_loss = 0.74670799, grad/param norm = 2.0744e-01, time/batch = 15.6307s	
27850/28500 (epoch 48.860), train_loss = 0.77078392, grad/param norm = 2.1611e-01, time/batch = 15.4559s	
27851/28500 (epoch 48.861), train_loss = 0.82806726, grad/param norm = 2.5471e-01, time/batch = 15.4764s	
27852/28500 (epoch 48.863), train_loss = 0.80069385, grad/param norm = 2.5566e-01, time/batch = 15.4410s	
27853/28500 (epoch 48.865), train_loss = 0.72166100, grad/param norm = 2.3184e-01, time/batch = 15.5259s	
27854/28500 (epoch 48.867), train_loss = 0.76494531, grad/param norm = 2.2813e-01, time/batch = 15.3979s	
27855/28500 (epoch 48.868), train_loss = 0.67318437, grad/param norm = 1.8171e-01, time/batch = 15.3019s	
27856/28500 (epoch 48.870), train_loss = 0.65436415, grad/param norm = 1.9791e-01, time/batch = 15.5470s	
27857/28500 (epoch 48.872), train_loss = 0.84383816, grad/param norm = 2.5674e-01, time/batch = 15.1312s	
27858/28500 (epoch 48.874), train_loss = 0.69791569, grad/param norm = 2.3727e-01, time/batch = 15.1952s	
27859/28500 (epoch 48.875), train_loss = 0.91402920, grad/param norm = 2.5239e-01, time/batch = 15.3096s	
27860/28500 (epoch 48.877), train_loss = 0.79292768, grad/param norm = 2.1765e-01, time/batch = 15.3603s	
27861/28500 (epoch 48.879), train_loss = 0.79078450, grad/param norm = 1.7311e-01, time/batch = 15.5625s	
27862/28500 (epoch 48.881), train_loss = 0.78188605, grad/param norm = 2.1929e-01, time/batch = 15.3049s	
27863/28500 (epoch 48.882), train_loss = 0.68627531, grad/param norm = 1.8916e-01, time/batch = 15.4817s	
27864/28500 (epoch 48.884), train_loss = 0.70554240, grad/param norm = 1.8259e-01, time/batch = 15.2350s	
27865/28500 (epoch 48.886), train_loss = 0.69136344, grad/param norm = 1.8166e-01, time/batch = 15.3056s	
27866/28500 (epoch 48.888), train_loss = 0.73354555, grad/param norm = 1.7138e-01, time/batch = 15.2046s	
27867/28500 (epoch 48.889), train_loss = 0.77775049, grad/param norm = 1.6583e-01, time/batch = 15.4592s	
27868/28500 (epoch 48.891), train_loss = 0.75105281, grad/param norm = 1.6604e-01, time/batch = 15.3297s	
27869/28500 (epoch 48.893), train_loss = 0.71378401, grad/param norm = 1.8732e-01, time/batch = 15.2282s	
27870/28500 (epoch 48.895), train_loss = 0.89782498, grad/param norm = 2.4645e-01, time/batch = 15.3442s	
27871/28500 (epoch 48.896), train_loss = 0.87366915, grad/param norm = 2.8617e-01, time/batch = 15.2382s	
27872/28500 (epoch 48.898), train_loss = 0.83866874, grad/param norm = 1.9917e-01, time/batch = 15.5404s	
27873/28500 (epoch 48.900), train_loss = 0.66386767, grad/param norm = 1.7296e-01, time/batch = 15.5408s	
27874/28500 (epoch 48.902), train_loss = 0.64012207, grad/param norm = 1.9994e-01, time/batch = 15.5392s	
27875/28500 (epoch 48.904), train_loss = 0.66717274, grad/param norm = 1.5796e-01, time/batch = 15.4343s	
27876/28500 (epoch 48.905), train_loss = 0.72045350, grad/param norm = 2.0640e-01, time/batch = 15.4684s	
27877/28500 (epoch 48.907), train_loss = 0.73548523, grad/param norm = 1.7108e-01, time/batch = 15.5424s	
27878/28500 (epoch 48.909), train_loss = 0.60657162, grad/param norm = 1.9485e-01, time/batch = 15.5539s	
27879/28500 (epoch 48.911), train_loss = 0.66806917, grad/param norm = 1.7463e-01, time/batch = 15.3055s	
27880/28500 (epoch 48.912), train_loss = 0.56885809, grad/param norm = 1.5808e-01, time/batch = 15.3841s	
27881/28500 (epoch 48.914), train_loss = 0.77635481, grad/param norm = 1.8784e-01, time/batch = 15.4941s	
27882/28500 (epoch 48.916), train_loss = 0.76660550, grad/param norm = 2.0417e-01, time/batch = 15.2685s	
27883/28500 (epoch 48.918), train_loss = 0.73951205, grad/param norm = 2.2492e-01, time/batch = 15.3042s	
27884/28500 (epoch 48.919), train_loss = 0.78154059, grad/param norm = 1.8299e-01, time/batch = 15.3115s	
27885/28500 (epoch 48.921), train_loss = 0.83590398, grad/param norm = 2.9662e-01, time/batch = 15.2110s	
27886/28500 (epoch 48.923), train_loss = 0.67914005, grad/param norm = 2.8456e-01, time/batch = 15.5480s	
27887/28500 (epoch 48.925), train_loss = 0.71951481, grad/param norm = 2.1915e-01, time/batch = 15.3185s	
27888/28500 (epoch 48.926), train_loss = 0.75944160, grad/param norm = 1.8993e-01, time/batch = 15.3714s	
27889/28500 (epoch 48.928), train_loss = 0.72319043, grad/param norm = 2.0759e-01, time/batch = 15.3622s	
27890/28500 (epoch 48.930), train_loss = 0.61173490, grad/param norm = 1.9412e-01, time/batch = 15.4575s	
27891/28500 (epoch 48.932), train_loss = 0.60727439, grad/param norm = 1.5279e-01, time/batch = 15.3188s	
27892/28500 (epoch 48.933), train_loss = 0.81321274, grad/param norm = 1.8668e-01, time/batch = 15.3084s	
27893/28500 (epoch 48.935), train_loss = 0.81301759, grad/param norm = 1.8572e-01, time/batch = 15.3757s	
27894/28500 (epoch 48.937), train_loss = 0.79680246, grad/param norm = 2.5261e-01, time/batch = 15.5069s	
27895/28500 (epoch 48.939), train_loss = 0.88388368, grad/param norm = 2.2438e-01, time/batch = 15.3551s	
27896/28500 (epoch 48.940), train_loss = 0.59115364, grad/param norm = 1.8302e-01, time/batch = 14.9987s	
27897/28500 (epoch 48.942), train_loss = 0.74807666, grad/param norm = 2.1604e-01, time/batch = 15.4088s	
27898/28500 (epoch 48.944), train_loss = 0.71288083, grad/param norm = 1.8965e-01, time/batch = 15.2953s	
27899/28500 (epoch 48.946), train_loss = 0.78950735, grad/param norm = 2.0327e-01, time/batch = 15.3014s	
27900/28500 (epoch 48.947), train_loss = 0.93037523, grad/param norm = 2.3766e-01, time/batch = 15.2342s	
27901/28500 (epoch 48.949), train_loss = 0.73335147, grad/param norm = 2.3741e-01, time/batch = 15.3804s	
27902/28500 (epoch 48.951), train_loss = 0.90229565, grad/param norm = 2.0822e-01, time/batch = 15.3224s	
27903/28500 (epoch 48.953), train_loss = 0.88646979, grad/param norm = 2.1148e-01, time/batch = 15.4689s	
27904/28500 (epoch 48.954), train_loss = 0.83633590, grad/param norm = 2.3738e-01, time/batch = 15.3217s	
27905/28500 (epoch 48.956), train_loss = 0.78600642, grad/param norm = 2.9491e-01, time/batch = 15.6107s	
27906/28500 (epoch 48.958), train_loss = 0.97364429, grad/param norm = 1.9541e-01, time/batch = 15.5614s	
27907/28500 (epoch 48.960), train_loss = 0.70489128, grad/param norm = 2.1533e-01, time/batch = 15.4579s	
27908/28500 (epoch 48.961), train_loss = 0.90810117, grad/param norm = 2.2759e-01, time/batch = 15.4079s	
27909/28500 (epoch 48.963), train_loss = 0.85120394, grad/param norm = 2.6327e-01, time/batch = 15.4633s	
27910/28500 (epoch 48.965), train_loss = 0.68376039, grad/param norm = 1.8137e-01, time/batch = 15.2184s	
27911/28500 (epoch 48.967), train_loss = 0.72700082, grad/param norm = 2.1962e-01, time/batch = 15.3868s	
27912/28500 (epoch 48.968), train_loss = 0.68811082, grad/param norm = 1.6623e-01, time/batch = 15.3185s	
27913/28500 (epoch 48.970), train_loss = 0.69440534, grad/param norm = 2.1830e-01, time/batch = 15.2190s	
27914/28500 (epoch 48.972), train_loss = 0.74703820, grad/param norm = 1.9018e-01, time/batch = 15.2982s	
27915/28500 (epoch 48.974), train_loss = 0.97588098, grad/param norm = 2.7871e-01, time/batch = 15.2974s	
27916/28500 (epoch 48.975), train_loss = 0.71172669, grad/param norm = 2.5693e-01, time/batch = 15.3058s	
27917/28500 (epoch 48.977), train_loss = 0.84076840, grad/param norm = 2.3039e-01, time/batch = 15.2818s	
27918/28500 (epoch 48.979), train_loss = 0.79650411, grad/param norm = 2.0622e-01, time/batch = 15.1339s	
27919/28500 (epoch 48.981), train_loss = 0.64613421, grad/param norm = 1.9053e-01, time/batch = 15.1289s	
27920/28500 (epoch 48.982), train_loss = 0.76385867, grad/param norm = 2.1068e-01, time/batch = 15.0602s	
27921/28500 (epoch 48.984), train_loss = 0.81798357, grad/param norm = 1.8227e-01, time/batch = 15.5674s	
27922/28500 (epoch 48.986), train_loss = 0.96273787, grad/param norm = 2.2951e-01, time/batch = 15.3865s	
27923/28500 (epoch 48.988), train_loss = 0.70057818, grad/param norm = 2.1318e-01, time/batch = 15.4628s	
27924/28500 (epoch 48.989), train_loss = 0.77783351, grad/param norm = 2.2180e-01, time/batch = 15.5228s	
27925/28500 (epoch 48.991), train_loss = 0.67695039, grad/param norm = 2.0069e-01, time/batch = 15.3739s	
27926/28500 (epoch 48.993), train_loss = 0.69773598, grad/param norm = 2.3688e-01, time/batch = 15.2363s	
27927/28500 (epoch 48.995), train_loss = 0.73327156, grad/param norm = 1.9733e-01, time/batch = 15.2998s	
27928/28500 (epoch 48.996), train_loss = 0.65333802, grad/param norm = 1.8640e-01, time/batch = 23.8145s	
27929/28500 (epoch 48.998), train_loss = 0.87682749, grad/param norm = 2.5007e-01, time/batch = 19.3323s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
27930/28500 (epoch 49.000), train_loss = 0.74375142, grad/param norm = 2.1772e-01, time/batch = 15.3202s	
27931/28500 (epoch 49.002), train_loss = 0.92283215, grad/param norm = 2.1622e-01, time/batch = 15.3610s	
27932/28500 (epoch 49.004), train_loss = 0.79271960, grad/param norm = 2.0822e-01, time/batch = 15.4683s	
27933/28500 (epoch 49.005), train_loss = 0.87323262, grad/param norm = 2.1747e-01, time/batch = 15.5204s	
27934/28500 (epoch 49.007), train_loss = 0.68451409, grad/param norm = 1.8140e-01, time/batch = 15.3075s	
27935/28500 (epoch 49.009), train_loss = 0.77302684, grad/param norm = 1.9927e-01, time/batch = 15.3461s	
27936/28500 (epoch 49.011), train_loss = 0.70131176, grad/param norm = 2.1044e-01, time/batch = 15.2917s	
27937/28500 (epoch 49.012), train_loss = 0.70920181, grad/param norm = 1.8458e-01, time/batch = 15.0736s	
27938/28500 (epoch 49.014), train_loss = 0.67603211, grad/param norm = 2.0080e-01, time/batch = 15.1487s	
27939/28500 (epoch 49.016), train_loss = 0.73713553, grad/param norm = 1.8789e-01, time/batch = 15.0764s	
27940/28500 (epoch 49.018), train_loss = 0.77815401, grad/param norm = 2.1109e-01, time/batch = 15.0694s	
27941/28500 (epoch 49.019), train_loss = 0.86232380, grad/param norm = 2.2035e-01, time/batch = 15.0764s	
27942/28500 (epoch 49.021), train_loss = 0.86985562, grad/param norm = 1.7558e-01, time/batch = 15.3131s	
27943/28500 (epoch 49.023), train_loss = 0.77143864, grad/param norm = 1.9455e-01, time/batch = 15.3846s	
27944/28500 (epoch 49.025), train_loss = 0.79051961, grad/param norm = 1.7907e-01, time/batch = 15.4571s	
27945/28500 (epoch 49.026), train_loss = 0.70882157, grad/param norm = 1.7501e-01, time/batch = 15.5450s	
27946/28500 (epoch 49.028), train_loss = 0.77351050, grad/param norm = 2.5514e-01, time/batch = 15.5597s	
27947/28500 (epoch 49.030), train_loss = 0.78336513, grad/param norm = 2.1265e-01, time/batch = 15.5771s	
27948/28500 (epoch 49.032), train_loss = 0.88062087, grad/param norm = 2.1506e-01, time/batch = 15.3837s	
27949/28500 (epoch 49.033), train_loss = 0.89300257, grad/param norm = 1.9110e-01, time/batch = 15.3110s	
27950/28500 (epoch 49.035), train_loss = 0.74104799, grad/param norm = 2.0451e-01, time/batch = 15.4682s	
27951/28500 (epoch 49.037), train_loss = 0.83758398, grad/param norm = 2.1008e-01, time/batch = 15.3847s	
27952/28500 (epoch 49.039), train_loss = 0.84796957, grad/param norm = 1.9647e-01, time/batch = 15.3149s	
27953/28500 (epoch 49.040), train_loss = 0.87510669, grad/param norm = 2.0435e-01, time/batch = 15.2315s	
27954/28500 (epoch 49.042), train_loss = 0.84948891, grad/param norm = 1.9829e-01, time/batch = 15.2182s	
27955/28500 (epoch 49.044), train_loss = 0.75044672, grad/param norm = 2.0594e-01, time/batch = 15.5212s	
27956/28500 (epoch 49.046), train_loss = 0.97293810, grad/param norm = 2.2513e-01, time/batch = 15.4959s	
27957/28500 (epoch 49.047), train_loss = 0.88835514, grad/param norm = 2.2954e-01, time/batch = 15.4000s	
27958/28500 (epoch 49.049), train_loss = 0.78297224, grad/param norm = 1.9813e-01, time/batch = 15.3759s	
27959/28500 (epoch 49.051), train_loss = 0.75167904, grad/param norm = 1.9285e-01, time/batch = 15.3266s	
27960/28500 (epoch 49.053), train_loss = 0.74252471, grad/param norm = 1.8307e-01, time/batch = 15.3561s	
27961/28500 (epoch 49.054), train_loss = 0.84638866, grad/param norm = 2.2402e-01, time/batch = 15.3766s	
27962/28500 (epoch 49.056), train_loss = 0.73612761, grad/param norm = 1.8569e-01, time/batch = 15.3078s	
27963/28500 (epoch 49.058), train_loss = 0.71537458, grad/param norm = 1.7409e-01, time/batch = 15.5467s	
27964/28500 (epoch 49.060), train_loss = 0.83631674, grad/param norm = 2.1358e-01, time/batch = 15.0708s	
27965/28500 (epoch 49.061), train_loss = 0.73821966, grad/param norm = 1.8874e-01, time/batch = 15.1368s	
27966/28500 (epoch 49.063), train_loss = 0.79359455, grad/param norm = 2.1148e-01, time/batch = 15.3527s	
27967/28500 (epoch 49.065), train_loss = 0.77617905, grad/param norm = 1.9264e-01, time/batch = 15.3635s	
27968/28500 (epoch 49.067), train_loss = 0.73463325, grad/param norm = 1.9379e-01, time/batch = 15.2178s	
27969/28500 (epoch 49.068), train_loss = 0.75723422, grad/param norm = 1.9053e-01, time/batch = 15.3587s	
27970/28500 (epoch 49.070), train_loss = 0.78256521, grad/param norm = 2.0721e-01, time/batch = 15.3122s	
27971/28500 (epoch 49.072), train_loss = 0.90401818, grad/param norm = 2.9008e-01, time/batch = 15.2086s	
27972/28500 (epoch 49.074), train_loss = 0.77101249, grad/param norm = 1.8361e-01, time/batch = 15.2426s	
27973/28500 (epoch 49.075), train_loss = 0.78041126, grad/param norm = 2.2450e-01, time/batch = 15.1210s	
27974/28500 (epoch 49.077), train_loss = 0.80941690, grad/param norm = 1.7216e-01, time/batch = 15.5491s	
27975/28500 (epoch 49.079), train_loss = 0.80528017, grad/param norm = 1.7588e-01, time/batch = 15.4262s	
27976/28500 (epoch 49.081), train_loss = 0.84538382, grad/param norm = 2.1872e-01, time/batch = 15.4494s	
27977/28500 (epoch 49.082), train_loss = 0.74109228, grad/param norm = 2.0864e-01, time/batch = 15.3898s	
27978/28500 (epoch 49.084), train_loss = 0.75637369, grad/param norm = 2.0556e-01, time/batch = 15.3835s	
27979/28500 (epoch 49.086), train_loss = 0.73063479, grad/param norm = 2.0888e-01, time/batch = 15.3885s	
27980/28500 (epoch 49.088), train_loss = 0.67003129, grad/param norm = 1.8113e-01, time/batch = 15.2403s	
27981/28500 (epoch 49.089), train_loss = 0.81534733, grad/param norm = 1.9767e-01, time/batch = 15.3557s	
27982/28500 (epoch 49.091), train_loss = 0.68821492, grad/param norm = 1.8759e-01, time/batch = 15.1171s	
27983/28500 (epoch 49.093), train_loss = 0.84814587, grad/param norm = 2.0618e-01, time/batch = 15.0842s	
27984/28500 (epoch 49.095), train_loss = 0.78776371, grad/param norm = 1.8456e-01, time/batch = 15.2304s	
27985/28500 (epoch 49.096), train_loss = 0.87828559, grad/param norm = 2.2408e-01, time/batch = 15.2110s	
27986/28500 (epoch 49.098), train_loss = 0.77502689, grad/param norm = 2.5286e-01, time/batch = 15.3576s	
27987/28500 (epoch 49.100), train_loss = 0.75943959, grad/param norm = 1.9655e-01, time/batch = 15.2515s	
27988/28500 (epoch 49.102), train_loss = 0.86982734, grad/param norm = 3.5695e-01, time/batch = 15.1284s	
27989/28500 (epoch 49.104), train_loss = 0.81299494, grad/param norm = 2.8183e-01, time/batch = 15.1715s	
27990/28500 (epoch 49.105), train_loss = 0.85031884, grad/param norm = 1.7812e-01, time/batch = 15.0504s	
27991/28500 (epoch 49.107), train_loss = 0.71484604, grad/param norm = 2.2867e-01, time/batch = 15.2949s	
27992/28500 (epoch 49.109), train_loss = 0.74882189, grad/param norm = 2.8522e-01, time/batch = 15.2084s	
27993/28500 (epoch 49.111), train_loss = 0.76320439, grad/param norm = 2.4641e-01, time/batch = 15.3894s	
27994/28500 (epoch 49.112), train_loss = 0.85578330, grad/param norm = 2.2436e-01, time/batch = 15.4324s	
27995/28500 (epoch 49.114), train_loss = 0.78083255, grad/param norm = 2.0072e-01, time/batch = 15.5192s	
27996/28500 (epoch 49.116), train_loss = 0.92879090, grad/param norm = 2.3768e-01, time/batch = 15.4576s	
27997/28500 (epoch 49.118), train_loss = 0.72566332, grad/param norm = 2.0111e-01, time/batch = 15.3005s	
27998/28500 (epoch 49.119), train_loss = 0.81679081, grad/param norm = 2.2699e-01, time/batch = 15.3008s	
27999/28500 (epoch 49.121), train_loss = 0.91434721, grad/param norm = 2.1474e-01, time/batch = 15.3095s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch49.12_2.0585.t7	
28000/28500 (epoch 49.123), train_loss = 0.88028036, grad/param norm = 2.0777e-01, time/batch = 15.4336s	
28001/28500 (epoch 49.125), train_loss = 1.42050092, grad/param norm = 2.7587e-01, time/batch = 15.5340s	
28002/28500 (epoch 49.126), train_loss = 0.81421912, grad/param norm = 2.3287e-01, time/batch = 14.9927s	
28003/28500 (epoch 49.128), train_loss = 0.80312319, grad/param norm = 1.7064e-01, time/batch = 15.1445s	
28004/28500 (epoch 49.130), train_loss = 0.74790514, grad/param norm = 2.3720e-01, time/batch = 15.2719s	
28005/28500 (epoch 49.132), train_loss = 0.77370626, grad/param norm = 2.2191e-01, time/batch = 15.3667s	
28006/28500 (epoch 49.133), train_loss = 0.84593269, grad/param norm = 2.2683e-01, time/batch = 15.5827s	
28007/28500 (epoch 49.135), train_loss = 0.74292162, grad/param norm = 1.9448e-01, time/batch = 15.6160s	
28008/28500 (epoch 49.137), train_loss = 0.79317012, grad/param norm = 1.8357e-01, time/batch = 15.5245s	
28009/28500 (epoch 49.139), train_loss = 0.80701669, grad/param norm = 1.7328e-01, time/batch = 15.2201s	
28010/28500 (epoch 49.140), train_loss = 0.78795270, grad/param norm = 2.0073e-01, time/batch = 15.6468s	
28011/28500 (epoch 49.142), train_loss = 0.74864618, grad/param norm = 2.3757e-01, time/batch = 15.3490s	
28012/28500 (epoch 49.144), train_loss = 0.71261551, grad/param norm = 1.9420e-01, time/batch = 15.4637s	
28013/28500 (epoch 49.146), train_loss = 0.74714382, grad/param norm = 1.8827e-01, time/batch = 15.6440s	
28014/28500 (epoch 49.147), train_loss = 0.67442437, grad/param norm = 1.9200e-01, time/batch = 15.5603s	
28015/28500 (epoch 49.149), train_loss = 0.67901932, grad/param norm = 1.8177e-01, time/batch = 15.4784s	
28016/28500 (epoch 49.151), train_loss = 0.73116761, grad/param norm = 2.0380e-01, time/batch = 15.3864s	
28017/28500 (epoch 49.153), train_loss = 0.79426333, grad/param norm = 1.8755e-01, time/batch = 15.3551s	
28018/28500 (epoch 49.154), train_loss = 0.65994839, grad/param norm = 1.9953e-01, time/batch = 15.3844s	
28019/28500 (epoch 49.156), train_loss = 0.82311606, grad/param norm = 1.9861e-01, time/batch = 15.4828s	
28020/28500 (epoch 49.158), train_loss = 0.80319663, grad/param norm = 2.1355e-01, time/batch = 15.5282s	
28021/28500 (epoch 49.160), train_loss = 0.70901667, grad/param norm = 1.6753e-01, time/batch = 14.9824s	
28022/28500 (epoch 49.161), train_loss = 0.73010145, grad/param norm = 2.8359e-01, time/batch = 15.0648s	
28023/28500 (epoch 49.163), train_loss = 0.67678230, grad/param norm = 2.1148e-01, time/batch = 15.2663s	
28024/28500 (epoch 49.165), train_loss = 0.88931216, grad/param norm = 1.9694e-01, time/batch = 15.3199s	
28025/28500 (epoch 49.167), train_loss = 0.88510538, grad/param norm = 2.2440e-01, time/batch = 15.6419s	
28026/28500 (epoch 49.168), train_loss = 0.88590450, grad/param norm = 2.4331e-01, time/batch = 15.4846s	
28027/28500 (epoch 49.170), train_loss = 0.87711313, grad/param norm = 2.7639e-01, time/batch = 15.5365s	
28028/28500 (epoch 49.172), train_loss = 0.74765340, grad/param norm = 1.7163e-01, time/batch = 15.3015s	
28029/28500 (epoch 49.174), train_loss = 0.90580314, grad/param norm = 2.3488e-01, time/batch = 15.5627s	
28030/28500 (epoch 49.175), train_loss = 0.76478697, grad/param norm = 1.9133e-01, time/batch = 15.4496s	
28031/28500 (epoch 49.177), train_loss = 0.81391894, grad/param norm = 2.0440e-01, time/batch = 15.2315s	
28032/28500 (epoch 49.179), train_loss = 0.84104682, grad/param norm = 2.2604e-01, time/batch = 15.4125s	
28033/28500 (epoch 49.181), train_loss = 0.78661076, grad/param norm = 2.1806e-01, time/batch = 15.2693s	
28034/28500 (epoch 49.182), train_loss = 0.74495873, grad/param norm = 2.0362e-01, time/batch = 15.3079s	
28035/28500 (epoch 49.184), train_loss = 0.92927332, grad/param norm = 2.1734e-01, time/batch = 14.8934s	
28036/28500 (epoch 49.186), train_loss = 0.92628908, grad/param norm = 2.1567e-01, time/batch = 15.5387s	
28037/28500 (epoch 49.188), train_loss = 0.83493437, grad/param norm = 1.9944e-01, time/batch = 15.3215s	
28038/28500 (epoch 49.189), train_loss = 0.78098101, grad/param norm = 1.7861e-01, time/batch = 15.3297s	
28039/28500 (epoch 49.191), train_loss = 0.93552341, grad/param norm = 2.2197e-01, time/batch = 15.3140s	
28040/28500 (epoch 49.193), train_loss = 0.75280657, grad/param norm = 2.0524e-01, time/batch = 15.5510s	
28041/28500 (epoch 49.195), train_loss = 0.91914901, grad/param norm = 2.2584e-01, time/batch = 15.5260s	
28042/28500 (epoch 49.196), train_loss = 0.81337491, grad/param norm = 2.0751e-01, time/batch = 15.2079s	
28043/28500 (epoch 49.198), train_loss = 0.79123457, grad/param norm = 1.9554e-01, time/batch = 15.2842s	
28044/28500 (epoch 49.200), train_loss = 0.85721305, grad/param norm = 1.8699e-01, time/batch = 15.5403s	
28045/28500 (epoch 49.202), train_loss = 0.82150042, grad/param norm = 2.0194e-01, time/batch = 15.4324s	
28046/28500 (epoch 49.204), train_loss = 0.77126417, grad/param norm = 1.9548e-01, time/batch = 15.4225s	
28047/28500 (epoch 49.205), train_loss = 0.72361808, grad/param norm = 1.9091e-01, time/batch = 15.5388s	
28048/28500 (epoch 49.207), train_loss = 0.67401809, grad/param norm = 2.3383e-01, time/batch = 15.3508s	
28049/28500 (epoch 49.209), train_loss = 0.77833304, grad/param norm = 1.6803e-01, time/batch = 15.4705s	
28050/28500 (epoch 49.211), train_loss = 0.73588654, grad/param norm = 2.2147e-01, time/batch = 15.4803s	
28051/28500 (epoch 49.212), train_loss = 0.66038674, grad/param norm = 1.9330e-01, time/batch = 15.6019s	
28052/28500 (epoch 49.214), train_loss = 0.79341636, grad/param norm = 2.2733e-01, time/batch = 15.4807s	
28053/28500 (epoch 49.216), train_loss = 0.73158825, grad/param norm = 2.0913e-01, time/batch = 15.3144s	
28054/28500 (epoch 49.218), train_loss = 0.91006943, grad/param norm = 2.3228e-01, time/batch = 15.4825s	
28055/28500 (epoch 49.219), train_loss = 0.80099629, grad/param norm = 2.0097e-01, time/batch = 15.4305s	
28056/28500 (epoch 49.221), train_loss = 0.68707087, grad/param norm = 1.9270e-01, time/batch = 15.5605s	
28057/28500 (epoch 49.223), train_loss = 0.85237197, grad/param norm = 1.9592e-01, time/batch = 15.5560s	
28058/28500 (epoch 49.225), train_loss = 0.91211311, grad/param norm = 2.7312e-01, time/batch = 15.5114s	
28059/28500 (epoch 49.226), train_loss = 0.76014178, grad/param norm = 2.0049e-01, time/batch = 15.4832s	
28060/28500 (epoch 49.228), train_loss = 0.90342316, grad/param norm = 2.2783e-01, time/batch = 15.3239s	
28061/28500 (epoch 49.230), train_loss = 0.87355367, grad/param norm = 2.0499e-01, time/batch = 15.5459s	
28062/28500 (epoch 49.232), train_loss = 0.83462480, grad/param norm = 2.0780e-01, time/batch = 15.6445s	
28063/28500 (epoch 49.233), train_loss = 0.78579836, grad/param norm = 2.1072e-01, time/batch = 15.6140s	
28064/28500 (epoch 49.235), train_loss = 0.78891524, grad/param norm = 1.9680e-01, time/batch = 15.5701s	
28065/28500 (epoch 49.237), train_loss = 0.72667285, grad/param norm = 1.8663e-01, time/batch = 15.4749s	
28066/28500 (epoch 49.239), train_loss = 0.75477320, grad/param norm = 1.8067e-01, time/batch = 15.5324s	
28067/28500 (epoch 49.240), train_loss = 0.68962316, grad/param norm = 1.8654e-01, time/batch = 15.4671s	
28068/28500 (epoch 49.242), train_loss = 0.71353264, grad/param norm = 1.9540e-01, time/batch = 15.4799s	
28069/28500 (epoch 49.244), train_loss = 0.80271267, grad/param norm = 1.7939e-01, time/batch = 15.4738s	
28070/28500 (epoch 49.246), train_loss = 0.82594905, grad/param norm = 2.2489e-01, time/batch = 15.3833s	
28071/28500 (epoch 49.247), train_loss = 0.88996667, grad/param norm = 2.4246e-01, time/batch = 15.4692s	
28072/28500 (epoch 49.249), train_loss = 0.75482597, grad/param norm = 2.0157e-01, time/batch = 15.5648s	
28073/28500 (epoch 49.251), train_loss = 0.77325755, grad/param norm = 1.8468e-01, time/batch = 15.4682s	
28074/28500 (epoch 49.253), train_loss = 0.91055853, grad/param norm = 2.5131e-01, time/batch = 15.4689s	
28075/28500 (epoch 49.254), train_loss = 0.91759346, grad/param norm = 2.0404e-01, time/batch = 15.3812s	
28076/28500 (epoch 49.256), train_loss = 0.77150367, grad/param norm = 2.2476e-01, time/batch = 15.4780s	
28077/28500 (epoch 49.258), train_loss = 0.77337750, grad/param norm = 1.9370e-01, time/batch = 15.5641s	
28078/28500 (epoch 49.260), train_loss = 0.78238108, grad/param norm = 2.0405e-01, time/batch = 15.4749s	
28079/28500 (epoch 49.261), train_loss = 0.68153648, grad/param norm = 1.8276e-01, time/batch = 15.4825s	
28080/28500 (epoch 49.263), train_loss = 0.84009906, grad/param norm = 2.4807e-01, time/batch = 15.3915s	
28081/28500 (epoch 49.265), train_loss = 0.73480039, grad/param norm = 2.3893e-01, time/batch = 15.5328s	
28082/28500 (epoch 49.267), train_loss = 0.97073267, grad/param norm = 2.5839e-01, time/batch = 15.2495s	
28083/28500 (epoch 49.268), train_loss = 0.80769403, grad/param norm = 2.1551e-01, time/batch = 15.3669s	
28084/28500 (epoch 49.270), train_loss = 0.78344891, grad/param norm = 2.0371e-01, time/batch = 15.3859s	
28085/28500 (epoch 49.272), train_loss = 0.78651577, grad/param norm = 1.9293e-01, time/batch = 15.4998s	
28086/28500 (epoch 49.274), train_loss = 0.83358359, grad/param norm = 2.1559e-01, time/batch = 15.5394s	
28087/28500 (epoch 49.275), train_loss = 0.85732950, grad/param norm = 1.8884e-01, time/batch = 15.4587s	
28088/28500 (epoch 49.277), train_loss = 0.77849216, grad/param norm = 2.1519e-01, time/batch = 15.3772s	
28089/28500 (epoch 49.279), train_loss = 0.83300317, grad/param norm = 2.3800e-01, time/batch = 15.2442s	
28090/28500 (epoch 49.281), train_loss = 0.80470187, grad/param norm = 2.0783e-01, time/batch = 15.3656s	
28091/28500 (epoch 49.282), train_loss = 0.81475343, grad/param norm = 1.6464e-01, time/batch = 15.3256s	
28092/28500 (epoch 49.284), train_loss = 0.83239957, grad/param norm = 2.2456e-01, time/batch = 15.3211s	
28093/28500 (epoch 49.286), train_loss = 0.88521888, grad/param norm = 2.2047e-01, time/batch = 15.3202s	
28094/28500 (epoch 49.288), train_loss = 0.79310553, grad/param norm = 2.2446e-01, time/batch = 15.4631s	
28095/28500 (epoch 49.289), train_loss = 0.79151614, grad/param norm = 1.9788e-01, time/batch = 15.3163s	
28096/28500 (epoch 49.291), train_loss = 0.79453936, grad/param norm = 1.8013e-01, time/batch = 15.3988s	
28097/28500 (epoch 49.293), train_loss = 0.78424638, grad/param norm = 1.9048e-01, time/batch = 15.3715s	
28098/28500 (epoch 49.295), train_loss = 0.69554124, grad/param norm = 1.8025e-01, time/batch = 15.6032s	
28099/28500 (epoch 49.296), train_loss = 0.68336900, grad/param norm = 1.8986e-01, time/batch = 15.4291s	
28100/28500 (epoch 49.298), train_loss = 0.84470402, grad/param norm = 2.1073e-01, time/batch = 15.4795s	
28101/28500 (epoch 49.300), train_loss = 0.71710463, grad/param norm = 2.3057e-01, time/batch = 15.5482s	
28102/28500 (epoch 49.302), train_loss = 0.66637608, grad/param norm = 1.8317e-01, time/batch = 15.5549s	
28103/28500 (epoch 49.304), train_loss = 0.77413578, grad/param norm = 1.9562e-01, time/batch = 15.3942s	
28104/28500 (epoch 49.305), train_loss = 0.83534771, grad/param norm = 2.0097e-01, time/batch = 15.3902s	
28105/28500 (epoch 49.307), train_loss = 0.77093494, grad/param norm = 1.9842e-01, time/batch = 15.3818s	
28106/28500 (epoch 49.309), train_loss = 0.78174683, grad/param norm = 2.4794e-01, time/batch = 15.2997s	
28107/28500 (epoch 49.311), train_loss = 0.82165967, grad/param norm = 1.9602e-01, time/batch = 15.6495s	
28108/28500 (epoch 49.312), train_loss = 0.82408505, grad/param norm = 1.8371e-01, time/batch = 15.6437s	
28109/28500 (epoch 49.314), train_loss = 0.78827053, grad/param norm = 1.8551e-01, time/batch = 15.5798s	
28110/28500 (epoch 49.316), train_loss = 0.80535340, grad/param norm = 1.9920e-01, time/batch = 15.3746s	
28111/28500 (epoch 49.318), train_loss = 0.84557805, grad/param norm = 1.8261e-01, time/batch = 15.3726s	
28112/28500 (epoch 49.319), train_loss = 0.74576191, grad/param norm = 2.2437e-01, time/batch = 15.2291s	
28113/28500 (epoch 49.321), train_loss = 0.74591606, grad/param norm = 2.1376e-01, time/batch = 15.4983s	
28114/28500 (epoch 49.323), train_loss = 0.79468142, grad/param norm = 1.9648e-01, time/batch = 15.2384s	
28115/28500 (epoch 49.325), train_loss = 0.86971519, grad/param norm = 2.0127e-01, time/batch = 15.2383s	
28116/28500 (epoch 49.326), train_loss = 0.81294444, grad/param norm = 1.9880e-01, time/batch = 15.2804s	
28117/28500 (epoch 49.328), train_loss = 0.64502462, grad/param norm = 1.6144e-01, time/batch = 15.1905s	
28118/28500 (epoch 49.330), train_loss = 0.73477100, grad/param norm = 2.0282e-01, time/batch = 14.9826s	
28119/28500 (epoch 49.332), train_loss = 0.72122838, grad/param norm = 1.8057e-01, time/batch = 15.1462s	
28120/28500 (epoch 49.333), train_loss = 0.61088066, grad/param norm = 2.2311e-01, time/batch = 15.4420s	
28121/28500 (epoch 49.335), train_loss = 0.69348384, grad/param norm = 1.8128e-01, time/batch = 15.4554s	
28122/28500 (epoch 49.337), train_loss = 0.62885532, grad/param norm = 1.9478e-01, time/batch = 15.0546s	
28123/28500 (epoch 49.339), train_loss = 0.63081044, grad/param norm = 1.4539e-01, time/batch = 15.1359s	
28124/28500 (epoch 49.340), train_loss = 0.76054389, grad/param norm = 2.1227e-01, time/batch = 15.3002s	
28125/28500 (epoch 49.342), train_loss = 0.77046627, grad/param norm = 1.7850e-01, time/batch = 15.5667s	
28126/28500 (epoch 49.344), train_loss = 0.66192941, grad/param norm = 1.9035e-01, time/batch = 15.2936s	
28127/28500 (epoch 49.346), train_loss = 0.66003439, grad/param norm = 1.6095e-01, time/batch = 15.1522s	
28128/28500 (epoch 49.347), train_loss = 0.78239670, grad/param norm = 1.7581e-01, time/batch = 15.1220s	
28129/28500 (epoch 49.349), train_loss = 0.76039761, grad/param norm = 1.9131e-01, time/batch = 15.1529s	
28130/28500 (epoch 49.351), train_loss = 0.69165342, grad/param norm = 1.8884e-01, time/batch = 15.2048s	
28131/28500 (epoch 49.353), train_loss = 0.79081858, grad/param norm = 2.1826e-01, time/batch = 15.2286s	
28132/28500 (epoch 49.354), train_loss = 0.67911131, grad/param norm = 2.0649e-01, time/batch = 15.3173s	
28133/28500 (epoch 49.356), train_loss = 0.71514278, grad/param norm = 1.6141e-01, time/batch = 15.2939s	
28134/28500 (epoch 49.358), train_loss = 0.80292332, grad/param norm = 1.9224e-01, time/batch = 15.4243s	
28135/28500 (epoch 49.360), train_loss = 0.77618983, grad/param norm = 2.0301e-01, time/batch = 15.3577s	
28136/28500 (epoch 49.361), train_loss = 0.68901562, grad/param norm = 1.9729e-01, time/batch = 15.2885s	
28137/28500 (epoch 49.363), train_loss = 0.67795099, grad/param norm = 1.7756e-01, time/batch = 15.4400s	
28138/28500 (epoch 49.365), train_loss = 0.71867945, grad/param norm = 2.0814e-01, time/batch = 15.2897s	
28139/28500 (epoch 49.367), train_loss = 0.75338617, grad/param norm = 1.8558e-01, time/batch = 15.1732s	
28140/28500 (epoch 49.368), train_loss = 0.69250799, grad/param norm = 1.9045e-01, time/batch = 14.9013s	
28141/28500 (epoch 49.370), train_loss = 0.79756774, grad/param norm = 2.0059e-01, time/batch = 15.5208s	
28142/28500 (epoch 49.372), train_loss = 0.60843020, grad/param norm = 1.8041e-01, time/batch = 15.1507s	
28143/28500 (epoch 49.374), train_loss = 0.75029793, grad/param norm = 1.9454e-01, time/batch = 14.9955s	
28144/28500 (epoch 49.375), train_loss = 0.86646076, grad/param norm = 2.0931e-01, time/batch = 15.0463s	
28145/28500 (epoch 49.377), train_loss = 0.73487917, grad/param norm = 2.2334e-01, time/batch = 15.2128s	
28146/28500 (epoch 49.379), train_loss = 0.61293919, grad/param norm = 1.8299e-01, time/batch = 15.3158s	
28147/28500 (epoch 49.381), train_loss = 0.72981097, grad/param norm = 2.1785e-01, time/batch = 15.2444s	
28148/28500 (epoch 49.382), train_loss = 0.69805039, grad/param norm = 1.8435e-01, time/batch = 15.1700s	
28149/28500 (epoch 49.384), train_loss = 0.62391416, grad/param norm = 1.8590e-01, time/batch = 15.2139s	
28150/28500 (epoch 49.386), train_loss = 0.67145493, grad/param norm = 1.6890e-01, time/batch = 15.1192s	
28151/28500 (epoch 49.388), train_loss = 0.80743761, grad/param norm = 1.9567e-01, time/batch = 15.4010s	
28152/28500 (epoch 49.389), train_loss = 0.70336433, grad/param norm = 2.1893e-01, time/batch = 22.7234s	
28153/28500 (epoch 49.391), train_loss = 0.67221710, grad/param norm = 2.2545e-01, time/batch = 20.2416s	
28154/28500 (epoch 49.393), train_loss = 0.67023622, grad/param norm = 1.9895e-01, time/batch = 15.2466s	
28155/28500 (epoch 49.395), train_loss = 0.83890571, grad/param norm = 2.0331e-01, time/batch = 15.1964s	
28156/28500 (epoch 49.396), train_loss = 0.83593111, grad/param norm = 2.0891e-01, time/batch = 15.6752s	
28157/28500 (epoch 49.398), train_loss = 0.57152135, grad/param norm = 2.0478e-01, time/batch = 15.3892s	
28158/28500 (epoch 49.400), train_loss = 0.71363098, grad/param norm = 2.0038e-01, time/batch = 15.2270s	
28159/28500 (epoch 49.402), train_loss = 0.76972122, grad/param norm = 2.1024e-01, time/batch = 15.3538s	
28160/28500 (epoch 49.404), train_loss = 0.76187897, grad/param norm = 2.1267e-01, time/batch = 15.3687s	
28161/28500 (epoch 49.405), train_loss = 0.82637131, grad/param norm = 2.0877e-01, time/batch = 15.0658s	
28162/28500 (epoch 49.407), train_loss = 0.74852153, grad/param norm = 1.8633e-01, time/batch = 15.1223s	
28163/28500 (epoch 49.409), train_loss = 0.76072310, grad/param norm = 2.6531e-01, time/batch = 15.1821s	
28164/28500 (epoch 49.411), train_loss = 0.85397301, grad/param norm = 2.2905e-01, time/batch = 15.1884s	
28165/28500 (epoch 49.412), train_loss = 0.88805056, grad/param norm = 2.6485e-01, time/batch = 15.5561s	
28166/28500 (epoch 49.414), train_loss = 0.79378972, grad/param norm = 2.3816e-01, time/batch = 15.2783s	
28167/28500 (epoch 49.416), train_loss = 0.71869540, grad/param norm = 2.5976e-01, time/batch = 15.4032s	
28168/28500 (epoch 49.418), train_loss = 0.78341873, grad/param norm = 1.8804e-01, time/batch = 15.3807s	
28169/28500 (epoch 49.419), train_loss = 0.86375630, grad/param norm = 2.0660e-01, time/batch = 15.0722s	
28170/28500 (epoch 49.421), train_loss = 0.84882918, grad/param norm = 2.2907e-01, time/batch = 15.1140s	
28171/28500 (epoch 49.423), train_loss = 0.81335866, grad/param norm = 2.3205e-01, time/batch = 15.4594s	
28172/28500 (epoch 49.425), train_loss = 0.75488207, grad/param norm = 2.5198e-01, time/batch = 15.3883s	
28173/28500 (epoch 49.426), train_loss = 0.78597836, grad/param norm = 2.5987e-01, time/batch = 15.2994s	
28174/28500 (epoch 49.428), train_loss = 0.92890544, grad/param norm = 2.3435e-01, time/batch = 15.2835s	
28175/28500 (epoch 49.430), train_loss = 0.92408620, grad/param norm = 2.0031e-01, time/batch = 15.4551s	
28176/28500 (epoch 49.432), train_loss = 0.82027357, grad/param norm = 2.3289e-01, time/batch = 15.4667s	
28177/28500 (epoch 49.433), train_loss = 0.84327583, grad/param norm = 2.1934e-01, time/batch = 15.5468s	
28178/28500 (epoch 49.435), train_loss = 0.79935276, grad/param norm = 2.2631e-01, time/batch = 15.5014s	
28179/28500 (epoch 49.437), train_loss = 0.72815573, grad/param norm = 2.0104e-01, time/batch = 15.5338s	
28180/28500 (epoch 49.439), train_loss = 0.78154258, grad/param norm = 1.7766e-01, time/batch = 15.4576s	
28181/28500 (epoch 49.440), train_loss = 0.91727319, grad/param norm = 1.9066e-01, time/batch = 15.4522s	
28182/28500 (epoch 49.442), train_loss = 0.73260485, grad/param norm = 2.1270e-01, time/batch = 15.4363s	
28183/28500 (epoch 49.444), train_loss = 0.70243305, grad/param norm = 1.6583e-01, time/batch = 15.4522s	
28184/28500 (epoch 49.446), train_loss = 0.66189803, grad/param norm = 1.7767e-01, time/batch = 15.3011s	
28185/28500 (epoch 49.447), train_loss = 0.66537967, grad/param norm = 1.8847e-01, time/batch = 15.3091s	
28186/28500 (epoch 49.449), train_loss = 0.74657761, grad/param norm = 2.0485e-01, time/batch = 15.3087s	
28187/28500 (epoch 49.451), train_loss = 0.73898082, grad/param norm = 2.0121e-01, time/batch = 15.2882s	
28188/28500 (epoch 49.453), train_loss = 0.72901568, grad/param norm = 2.0427e-01, time/batch = 15.2396s	
28189/28500 (epoch 49.454), train_loss = 0.70325717, grad/param norm = 1.8339e-01, time/batch = 15.1216s	
28190/28500 (epoch 49.456), train_loss = 0.82448628, grad/param norm = 2.4648e-01, time/batch = 15.4547s	
28191/28500 (epoch 49.458), train_loss = 0.72984320, grad/param norm = 1.9747e-01, time/batch = 15.6766s	
28192/28500 (epoch 49.460), train_loss = 0.83241557, grad/param norm = 2.0765e-01, time/batch = 15.1139s	
28193/28500 (epoch 49.461), train_loss = 0.68610336, grad/param norm = 1.9121e-01, time/batch = 15.1381s	
28194/28500 (epoch 49.463), train_loss = 0.63611963, grad/param norm = 1.6795e-01, time/batch = 15.2686s	
28195/28500 (epoch 49.465), train_loss = 0.59215660, grad/param norm = 1.9353e-01, time/batch = 15.5929s	
28196/28500 (epoch 49.467), train_loss = 0.77334951, grad/param norm = 1.8063e-01, time/batch = 15.5064s	
28197/28500 (epoch 49.468), train_loss = 0.68251441, grad/param norm = 1.8397e-01, time/batch = 15.5707s	
28198/28500 (epoch 49.470), train_loss = 0.70499395, grad/param norm = 2.2915e-01, time/batch = 15.4669s	
28199/28500 (epoch 49.472), train_loss = 0.70216514, grad/param norm = 1.8811e-01, time/batch = 15.4806s	
28200/28500 (epoch 49.474), train_loss = 0.88398896, grad/param norm = 2.0946e-01, time/batch = 15.2195s	
28201/28500 (epoch 49.475), train_loss = 0.70740383, grad/param norm = 1.7920e-01, time/batch = 15.0820s	
28202/28500 (epoch 49.477), train_loss = 0.75839449, grad/param norm = 1.8105e-01, time/batch = 15.0441s	
28203/28500 (epoch 49.479), train_loss = 0.79486686, grad/param norm = 1.9549e-01, time/batch = 15.1358s	
28204/28500 (epoch 49.481), train_loss = 0.79379484, grad/param norm = 1.9582e-01, time/batch = 15.4410s	
28205/28500 (epoch 49.482), train_loss = 0.65035859, grad/param norm = 1.7266e-01, time/batch = 15.4176s	
28206/28500 (epoch 49.484), train_loss = 0.69734253, grad/param norm = 2.0054e-01, time/batch = 15.2273s	
28207/28500 (epoch 49.486), train_loss = 0.63055371, grad/param norm = 1.9404e-01, time/batch = 15.2185s	
28208/28500 (epoch 49.488), train_loss = 0.77355193, grad/param norm = 1.7260e-01, time/batch = 15.1397s	
28209/28500 (epoch 49.489), train_loss = 0.90248567, grad/param norm = 1.9309e-01, time/batch = 15.3182s	
28210/28500 (epoch 49.491), train_loss = 0.71954959, grad/param norm = 1.8807e-01, time/batch = 15.5140s	
28211/28500 (epoch 49.493), train_loss = 0.75250144, grad/param norm = 2.0284e-01, time/batch = 15.1570s	
28212/28500 (epoch 49.495), train_loss = 0.76029172, grad/param norm = 2.0177e-01, time/batch = 15.1499s	
28213/28500 (epoch 49.496), train_loss = 0.67568772, grad/param norm = 2.4818e-01, time/batch = 15.0589s	
28214/28500 (epoch 49.498), train_loss = 0.75785669, grad/param norm = 1.9188e-01, time/batch = 15.4273s	
28215/28500 (epoch 49.500), train_loss = 0.70403166, grad/param norm = 1.8786e-01, time/batch = 15.4542s	
28216/28500 (epoch 49.502), train_loss = 0.76474618, grad/param norm = 1.7178e-01, time/batch = 15.5256s	
28217/28500 (epoch 49.504), train_loss = 0.84963013, grad/param norm = 1.8933e-01, time/batch = 15.6238s	
28218/28500 (epoch 49.505), train_loss = 0.70745595, grad/param norm = 2.0612e-01, time/batch = 15.5737s	
28219/28500 (epoch 49.507), train_loss = 0.83050916, grad/param norm = 2.4942e-01, time/batch = 15.3810s	
28220/28500 (epoch 49.509), train_loss = 0.73622344, grad/param norm = 1.7641e-01, time/batch = 15.2308s	
28221/28500 (epoch 49.511), train_loss = 0.75328035, grad/param norm = 1.9339e-01, time/batch = 15.2655s	
28222/28500 (epoch 49.512), train_loss = 0.81098646, grad/param norm = 2.0489e-01, time/batch = 15.2346s	
28223/28500 (epoch 49.514), train_loss = 0.73728032, grad/param norm = 1.8057e-01, time/batch = 15.1516s	
28224/28500 (epoch 49.516), train_loss = 0.78540177, grad/param norm = 1.9393e-01, time/batch = 15.5129s	
28225/28500 (epoch 49.518), train_loss = 0.79203187, grad/param norm = 2.0843e-01, time/batch = 15.5025s	
28226/28500 (epoch 49.519), train_loss = 0.79402839, grad/param norm = 1.9155e-01, time/batch = 15.4623s	
28227/28500 (epoch 49.521), train_loss = 0.87374053, grad/param norm = 2.4149e-01, time/batch = 15.0809s	
28228/28500 (epoch 49.523), train_loss = 0.81467394, grad/param norm = 2.3278e-01, time/batch = 14.9959s	
28229/28500 (epoch 49.525), train_loss = 0.87571009, grad/param norm = 1.9913e-01, time/batch = 15.2931s	
28230/28500 (epoch 49.526), train_loss = 0.79172446, grad/param norm = 2.2134e-01, time/batch = 15.3076s	
28231/28500 (epoch 49.528), train_loss = 0.80384670, grad/param norm = 2.6251e-01, time/batch = 15.4311s	
28232/28500 (epoch 49.530), train_loss = 0.78155748, grad/param norm = 1.9908e-01, time/batch = 15.1150s	
28233/28500 (epoch 49.532), train_loss = 0.76234842, grad/param norm = 1.9280e-01, time/batch = 14.9677s	
28234/28500 (epoch 49.533), train_loss = 0.79530316, grad/param norm = 2.0521e-01, time/batch = 14.8790s	
28235/28500 (epoch 49.535), train_loss = 0.68392271, grad/param norm = 1.6814e-01, time/batch = 15.1073s	
28236/28500 (epoch 49.537), train_loss = 0.65210525, grad/param norm = 1.7783e-01, time/batch = 15.1494s	
28237/28500 (epoch 49.539), train_loss = 0.65068340, grad/param norm = 1.8228e-01, time/batch = 15.4659s	
28238/28500 (epoch 49.540), train_loss = 0.73243132, grad/param norm = 1.9828e-01, time/batch = 15.5862s	
28239/28500 (epoch 49.542), train_loss = 0.78612860, grad/param norm = 2.0673e-01, time/batch = 15.5236s	
28240/28500 (epoch 49.544), train_loss = 0.87497028, grad/param norm = 2.2388e-01, time/batch = 15.3882s	
28241/28500 (epoch 49.546), train_loss = 0.78191925, grad/param norm = 2.2680e-01, time/batch = 15.3890s	
28242/28500 (epoch 49.547), train_loss = 0.73431374, grad/param norm = 1.8130e-01, time/batch = 15.3758s	
28243/28500 (epoch 49.549), train_loss = 0.64319308, grad/param norm = 1.5822e-01, time/batch = 15.1759s	
28244/28500 (epoch 49.551), train_loss = 0.69845781, grad/param norm = 2.0513e-01, time/batch = 15.1959s	
28245/28500 (epoch 49.553), train_loss = 0.88238480, grad/param norm = 2.1426e-01, time/batch = 15.4125s	
28246/28500 (epoch 49.554), train_loss = 0.79716662, grad/param norm = 2.1428e-01, time/batch = 15.3862s	
28247/28500 (epoch 49.556), train_loss = 0.79766248, grad/param norm = 2.3429e-01, time/batch = 15.2997s	
28248/28500 (epoch 49.558), train_loss = 0.81039863, grad/param norm = 1.9060e-01, time/batch = 15.1344s	
28249/28500 (epoch 49.560), train_loss = 0.80015278, grad/param norm = 1.8951e-01, time/batch = 15.4506s	
28250/28500 (epoch 49.561), train_loss = 0.83352554, grad/param norm = 2.1839e-01, time/batch = 15.3014s	
28251/28500 (epoch 49.563), train_loss = 0.90690638, grad/param norm = 2.8157e-01, time/batch = 15.6374s	
28252/28500 (epoch 49.565), train_loss = 0.73945728, grad/param norm = 2.2326e-01, time/batch = 15.5516s	
28253/28500 (epoch 49.567), train_loss = 0.64044265, grad/param norm = 1.9489e-01, time/batch = 15.5369s	
28254/28500 (epoch 49.568), train_loss = 0.79089090, grad/param norm = 2.1160e-01, time/batch = 15.4606s	
28255/28500 (epoch 49.570), train_loss = 0.74571172, grad/param norm = 2.1228e-01, time/batch = 15.0284s	
28256/28500 (epoch 49.572), train_loss = 0.77851940, grad/param norm = 1.8511e-01, time/batch = 14.9883s	
28257/28500 (epoch 49.574), train_loss = 0.72986451, grad/param norm = 1.9978e-01, time/batch = 15.2823s	
28258/28500 (epoch 49.575), train_loss = 0.70738312, grad/param norm = 1.7900e-01, time/batch = 15.2614s	
28259/28500 (epoch 49.577), train_loss = 0.84541539, grad/param norm = 1.9227e-01, time/batch = 15.0447s	
28260/28500 (epoch 49.579), train_loss = 0.83158024, grad/param norm = 2.1752e-01, time/batch = 15.1367s	
28261/28500 (epoch 49.581), train_loss = 0.73063379, grad/param norm = 2.3477e-01, time/batch = 15.2919s	
28262/28500 (epoch 49.582), train_loss = 0.89142381, grad/param norm = 2.5593e-01, time/batch = 15.5570s	
28263/28500 (epoch 49.584), train_loss = 0.72772965, grad/param norm = 1.9804e-01, time/batch = 15.4017s	
28264/28500 (epoch 49.586), train_loss = 0.69243611, grad/param norm = 1.6679e-01, time/batch = 15.4527s	
28265/28500 (epoch 49.588), train_loss = 0.72926736, grad/param norm = 2.4070e-01, time/batch = 15.3817s	
28266/28500 (epoch 49.589), train_loss = 0.73967268, grad/param norm = 2.0177e-01, time/batch = 15.3002s	
28267/28500 (epoch 49.591), train_loss = 0.77399010, grad/param norm = 2.3895e-01, time/batch = 15.3869s	
28268/28500 (epoch 49.593), train_loss = 0.70744463, grad/param norm = 2.0846e-01, time/batch = 15.2583s	
28269/28500 (epoch 49.595), train_loss = 0.91879350, grad/param norm = 2.1918e-01, time/batch = 15.3687s	
28270/28500 (epoch 49.596), train_loss = 0.90934097, grad/param norm = 2.2639e-01, time/batch = 15.2219s	
28271/28500 (epoch 49.598), train_loss = 0.74304955, grad/param norm = 1.8973e-01, time/batch = 15.4311s	
28272/28500 (epoch 49.600), train_loss = 0.72718116, grad/param norm = 1.9649e-01, time/batch = 15.5078s	
28273/28500 (epoch 49.602), train_loss = 0.83079746, grad/param norm = 2.0214e-01, time/batch = 15.0719s	
28274/28500 (epoch 49.604), train_loss = 0.86831038, grad/param norm = 1.9552e-01, time/batch = 15.3197s	
28275/28500 (epoch 49.605), train_loss = 0.85573994, grad/param norm = 1.9682e-01, time/batch = 15.4839s	
28276/28500 (epoch 49.607), train_loss = 0.88356867, grad/param norm = 2.0934e-01, time/batch = 15.6331s	
28277/28500 (epoch 49.609), train_loss = 0.77841798, grad/param norm = 2.0974e-01, time/batch = 15.4669s	
28278/28500 (epoch 49.611), train_loss = 0.77922858, grad/param norm = 2.0439e-01, time/batch = 15.4846s	
28279/28500 (epoch 49.612), train_loss = 0.83353438, grad/param norm = 2.5800e-01, time/batch = 15.5624s	
28280/28500 (epoch 49.614), train_loss = 0.86863399, grad/param norm = 2.0385e-01, time/batch = 15.2022s	
28281/28500 (epoch 49.616), train_loss = 0.74471626, grad/param norm = 1.9478e-01, time/batch = 15.1611s	
28282/28500 (epoch 49.618), train_loss = 0.75773772, grad/param norm = 2.4169e-01, time/batch = 15.0640s	
28283/28500 (epoch 49.619), train_loss = 0.84548729, grad/param norm = 2.4208e-01, time/batch = 15.2300s	
28284/28500 (epoch 49.621), train_loss = 0.61741235, grad/param norm = 1.6910e-01, time/batch = 15.3103s	
28285/28500 (epoch 49.623), train_loss = 0.89934482, grad/param norm = 4.3952e-01, time/batch = 15.4840s	
28286/28500 (epoch 49.625), train_loss = 0.69911957, grad/param norm = 2.0912e-01, time/batch = 15.4836s	
28287/28500 (epoch 49.626), train_loss = 0.62721204, grad/param norm = 1.8506e-01, time/batch = 15.5544s	
28288/28500 (epoch 49.628), train_loss = 0.71136149, grad/param norm = 2.1297e-01, time/batch = 15.2109s	
28289/28500 (epoch 49.630), train_loss = 0.70397811, grad/param norm = 2.1192e-01, time/batch = 15.1395s	
28290/28500 (epoch 49.632), train_loss = 0.87654913, grad/param norm = 2.4579e-01, time/batch = 15.2989s	
28291/28500 (epoch 49.633), train_loss = 0.89621048, grad/param norm = 1.9505e-01, time/batch = 15.5620s	
28292/28500 (epoch 49.635), train_loss = 0.81550172, grad/param norm = 2.2871e-01, time/batch = 15.5433s	
28293/28500 (epoch 49.637), train_loss = 0.76754784, grad/param norm = 1.7496e-01, time/batch = 15.5564s	
28294/28500 (epoch 49.639), train_loss = 0.69008182, grad/param norm = 2.1127e-01, time/batch = 15.6456s	
28295/28500 (epoch 49.640), train_loss = 0.74305128, grad/param norm = 1.8064e-01, time/batch = 15.4317s	
28296/28500 (epoch 49.642), train_loss = 0.71923348, grad/param norm = 2.0050e-01, time/batch = 15.7176s	
28297/28500 (epoch 49.644), train_loss = 0.80456665, grad/param norm = 1.9677e-01, time/batch = 15.4805s	
28298/28500 (epoch 49.646), train_loss = 0.62329155, grad/param norm = 1.7976e-01, time/batch = 15.3367s	
28299/28500 (epoch 49.647), train_loss = 0.72647264, grad/param norm = 1.8041e-01, time/batch = 15.2910s	
28300/28500 (epoch 49.649), train_loss = 0.74443503, grad/param norm = 2.9946e-01, time/batch = 15.3972s	
28301/28500 (epoch 49.651), train_loss = 0.67079831, grad/param norm = 1.7980e-01, time/batch = 15.5578s	
28302/28500 (epoch 49.653), train_loss = 0.67041789, grad/param norm = 2.0278e-01, time/batch = 15.6315s	
28303/28500 (epoch 49.654), train_loss = 0.69612055, grad/param norm = 2.1870e-01, time/batch = 15.4617s	
28304/28500 (epoch 49.656), train_loss = 0.63672696, grad/param norm = 1.8539e-01, time/batch = 15.3100s	
28305/28500 (epoch 49.658), train_loss = 0.76030719, grad/param norm = 1.9682e-01, time/batch = 15.3887s	
28306/28500 (epoch 49.660), train_loss = 0.75174451, grad/param norm = 1.7774e-01, time/batch = 15.4807s	
28307/28500 (epoch 49.661), train_loss = 0.85917732, grad/param norm = 2.0133e-01, time/batch = 15.6250s	
28308/28500 (epoch 49.663), train_loss = 0.86684187, grad/param norm = 2.0049e-01, time/batch = 15.5322s	
28309/28500 (epoch 49.665), train_loss = 0.75504931, grad/param norm = 1.9792e-01, time/batch = 15.4607s	
28310/28500 (epoch 49.667), train_loss = 0.79824254, grad/param norm = 2.1071e-01, time/batch = 15.3176s	
28311/28500 (epoch 49.668), train_loss = 0.76073861, grad/param norm = 1.9326e-01, time/batch = 15.6609s	
28312/28500 (epoch 49.670), train_loss = 0.78189778, grad/param norm = 1.9980e-01, time/batch = 15.5217s	
28313/28500 (epoch 49.672), train_loss = 0.68649989, grad/param norm = 1.8619e-01, time/batch = 15.4935s	
28314/28500 (epoch 49.674), train_loss = 0.61612629, grad/param norm = 1.8131e-01, time/batch = 15.5392s	
28315/28500 (epoch 49.675), train_loss = 0.65618000, grad/param norm = 1.6852e-01, time/batch = 15.6251s	
28316/28500 (epoch 49.677), train_loss = 0.72738971, grad/param norm = 1.9495e-01, time/batch = 15.4798s	
28317/28500 (epoch 49.679), train_loss = 0.73709337, grad/param norm = 2.1715e-01, time/batch = 15.4103s	
28318/28500 (epoch 49.681), train_loss = 0.79615285, grad/param norm = 1.9454e-01, time/batch = 15.3077s	
28319/28500 (epoch 49.682), train_loss = 0.72494246, grad/param norm = 2.0485e-01, time/batch = 15.2389s	
28320/28500 (epoch 49.684), train_loss = 0.75814105, grad/param norm = 1.9935e-01, time/batch = 15.0493s	
28321/28500 (epoch 49.686), train_loss = 0.71993091, grad/param norm = 2.2087e-01, time/batch = 15.1325s	
28322/28500 (epoch 49.688), train_loss = 0.70776628, grad/param norm = 1.6196e-01, time/batch = 15.0534s	
28323/28500 (epoch 49.689), train_loss = 0.69410355, grad/param norm = 2.1084e-01, time/batch = 15.3788s	
28324/28500 (epoch 49.691), train_loss = 0.80721189, grad/param norm = 1.9385e-01, time/batch = 15.4517s	
28325/28500 (epoch 49.693), train_loss = 0.71987330, grad/param norm = 1.8597e-01, time/batch = 15.3511s	
28326/28500 (epoch 49.695), train_loss = 0.56178658, grad/param norm = 1.7444e-01, time/batch = 15.6284s	
28327/28500 (epoch 49.696), train_loss = 0.71891445, grad/param norm = 2.1448e-01, time/batch = 15.5359s	
28328/28500 (epoch 49.698), train_loss = 0.79556740, grad/param norm = 1.7581e-01, time/batch = 15.3870s	
28329/28500 (epoch 49.700), train_loss = 0.75345130, grad/param norm = 1.9972e-01, time/batch = 15.4487s	
28330/28500 (epoch 49.702), train_loss = 0.73810993, grad/param norm = 2.1364e-01, time/batch = 15.4336s	
28331/28500 (epoch 49.704), train_loss = 0.81938711, grad/param norm = 2.0328e-01, time/batch = 15.6148s	
28332/28500 (epoch 49.705), train_loss = 0.81296826, grad/param norm = 2.3012e-01, time/batch = 15.5951s	
28333/28500 (epoch 49.707), train_loss = 0.69315807, grad/param norm = 1.8579e-01, time/batch = 15.2984s	
28334/28500 (epoch 49.709), train_loss = 0.89293681, grad/param norm = 2.0800e-01, time/batch = 15.5362s	
28335/28500 (epoch 49.711), train_loss = 0.72507427, grad/param norm = 2.1076e-01, time/batch = 15.6292s	
28336/28500 (epoch 49.712), train_loss = 0.80336512, grad/param norm = 2.3338e-01, time/batch = 15.6338s	
28337/28500 (epoch 49.714), train_loss = 0.89832251, grad/param norm = 2.1875e-01, time/batch = 15.5187s	
28338/28500 (epoch 49.716), train_loss = 0.72755962, grad/param norm = 2.0009e-01, time/batch = 15.4910s	
28339/28500 (epoch 49.718), train_loss = 0.78600921, grad/param norm = 2.1961e-01, time/batch = 15.3087s	
28340/28500 (epoch 49.719), train_loss = 0.77023173, grad/param norm = 1.7394e-01, time/batch = 15.3807s	
28341/28500 (epoch 49.721), train_loss = 0.58785405, grad/param norm = 1.9749e-01, time/batch = 15.6362s	
28342/28500 (epoch 49.723), train_loss = 0.77482708, grad/param norm = 2.1416e-01, time/batch = 15.4723s	
28343/28500 (epoch 49.725), train_loss = 0.83678852, grad/param norm = 2.3356e-01, time/batch = 15.3620s	
28344/28500 (epoch 49.726), train_loss = 0.74809853, grad/param norm = 2.0198e-01, time/batch = 15.5523s	
28345/28500 (epoch 49.728), train_loss = 0.67258399, grad/param norm = 1.7894e-01, time/batch = 15.4558s	
28346/28500 (epoch 49.730), train_loss = 0.74866541, grad/param norm = 2.2976e-01, time/batch = 15.2189s	
28347/28500 (epoch 49.732), train_loss = 0.61852568, grad/param norm = 1.6537e-01, time/batch = 15.4997s	
28348/28500 (epoch 49.733), train_loss = 0.65689370, grad/param norm = 1.8089e-01, time/batch = 15.1330s	
28349/28500 (epoch 49.735), train_loss = 0.65780382, grad/param norm = 1.8144e-01, time/batch = 15.3403s	
28350/28500 (epoch 49.737), train_loss = 0.57818982, grad/param norm = 1.7319e-01, time/batch = 15.2724s	
28351/28500 (epoch 49.739), train_loss = 0.65442563, grad/param norm = 1.8868e-01, time/batch = 15.6396s	
28352/28500 (epoch 49.740), train_loss = 0.75535547, grad/param norm = 1.8798e-01, time/batch = 15.0460s	
28353/28500 (epoch 49.742), train_loss = 0.70242269, grad/param norm = 2.9963e-01, time/batch = 15.2134s	
28354/28500 (epoch 49.744), train_loss = 0.75251416, grad/param norm = 1.8506e-01, time/batch = 15.6338s	
28355/28500 (epoch 49.746), train_loss = 0.72525675, grad/param norm = 1.6703e-01, time/batch = 15.4784s	
28356/28500 (epoch 49.747), train_loss = 0.72861865, grad/param norm = 2.0091e-01, time/batch = 15.2279s	
28357/28500 (epoch 49.749), train_loss = 0.79878258, grad/param norm = 2.1310e-01, time/batch = 15.3056s	
28358/28500 (epoch 49.751), train_loss = 0.67537786, grad/param norm = 2.2963e-01, time/batch = 15.5598s	
28359/28500 (epoch 49.753), train_loss = 0.78078347, grad/param norm = 1.6452e-01, time/batch = 15.5552s	
28360/28500 (epoch 49.754), train_loss = 0.66676853, grad/param norm = 1.8165e-01, time/batch = 15.5223s	
28361/28500 (epoch 49.756), train_loss = 0.88156057, grad/param norm = 2.0148e-01, time/batch = 15.2264s	
28362/28500 (epoch 49.758), train_loss = 0.79555040, grad/param norm = 2.2673e-01, time/batch = 15.3739s	
28363/28500 (epoch 49.760), train_loss = 0.65696597, grad/param norm = 2.3485e-01, time/batch = 15.5569s	
28364/28500 (epoch 49.761), train_loss = 0.71829614, grad/param norm = 2.3609e-01, time/batch = 15.5363s	
28365/28500 (epoch 49.763), train_loss = 0.60997248, grad/param norm = 1.9741e-01, time/batch = 15.5870s	
28366/28500 (epoch 49.765), train_loss = 0.73615543, grad/param norm = 1.6526e-01, time/batch = 15.4728s	
28367/28500 (epoch 49.767), train_loss = 0.60094975, grad/param norm = 1.7208e-01, time/batch = 15.4642s	
28368/28500 (epoch 49.768), train_loss = 0.80258997, grad/param norm = 2.0004e-01, time/batch = 15.0670s	
28369/28500 (epoch 49.770), train_loss = 0.64833214, grad/param norm = 1.7162e-01, time/batch = 15.0588s	
28370/28500 (epoch 49.772), train_loss = 0.60672221, grad/param norm = 1.4872e-01, time/batch = 15.1266s	
28371/28500 (epoch 49.774), train_loss = 0.73459765, grad/param norm = 1.7585e-01, time/batch = 15.3864s	
28372/28500 (epoch 49.775), train_loss = 0.78670864, grad/param norm = 2.0514e-01, time/batch = 15.3773s	
28373/28500 (epoch 49.777), train_loss = 0.80428167, grad/param norm = 1.7263e-01, time/batch = 15.5367s	
28374/28500 (epoch 49.779), train_loss = 0.64558494, grad/param norm = 1.6303e-01, time/batch = 15.4681s	
28375/28500 (epoch 49.781), train_loss = 0.74112282, grad/param norm = 2.1229e-01, time/batch = 15.5411s	
28376/28500 (epoch 49.782), train_loss = 0.76634197, grad/param norm = 2.4092e-01, time/batch = 15.4491s	
28377/28500 (epoch 49.784), train_loss = 0.59447659, grad/param norm = 1.9382e-01, time/batch = 15.3985s	
28378/28500 (epoch 49.786), train_loss = 0.61639491, grad/param norm = 1.8493e-01, time/batch = 15.4092s	
28379/28500 (epoch 49.788), train_loss = 0.70104221, grad/param norm = 2.1520e-01, time/batch = 15.3893s	
28380/28500 (epoch 49.789), train_loss = 0.54582459, grad/param norm = 2.1312e-01, time/batch = 15.4283s	
28381/28500 (epoch 49.791), train_loss = 0.76704246, grad/param norm = 1.9171e-01, time/batch = 15.2253s	
28382/28500 (epoch 49.793), train_loss = 0.70186761, grad/param norm = 1.8547e-01, time/batch = 15.2016s	
28383/28500 (epoch 49.795), train_loss = 0.74790625, grad/param norm = 2.1849e-01, time/batch = 15.3021s	
28384/28500 (epoch 49.796), train_loss = 0.68103218, grad/param norm = 1.7793e-01, time/batch = 22.1082s	
28385/28500 (epoch 49.798), train_loss = 0.62108109, grad/param norm = 2.0381e-01, time/batch = 20.5862s	
28386/28500 (epoch 49.800), train_loss = 0.60480424, grad/param norm = 2.1760e-01, time/batch = 15.4777s	
28387/28500 (epoch 49.802), train_loss = 0.69881794, grad/param norm = 2.6774e-01, time/batch = 15.5440s	
28388/28500 (epoch 49.804), train_loss = 0.74904104, grad/param norm = 1.7423e-01, time/batch = 15.3659s	
28389/28500 (epoch 49.805), train_loss = 0.77616383, grad/param norm = 2.1481e-01, time/batch = 15.2236s	
28390/28500 (epoch 49.807), train_loss = 0.75602320, grad/param norm = 2.4275e-01, time/batch = 15.1916s	
28391/28500 (epoch 49.809), train_loss = 0.75399249, grad/param norm = 2.5524e-01, time/batch = 15.6540s	
28392/28500 (epoch 49.811), train_loss = 0.74636205, grad/param norm = 2.0352e-01, time/batch = 15.5674s	
28393/28500 (epoch 49.812), train_loss = 0.71229722, grad/param norm = 2.2074e-01, time/batch = 15.2349s	
28394/28500 (epoch 49.814), train_loss = 0.68701846, grad/param norm = 1.9771e-01, time/batch = 15.2954s	
28395/28500 (epoch 49.816), train_loss = 0.76603724, grad/param norm = 2.0760e-01, time/batch = 15.2443s	
28396/28500 (epoch 49.818), train_loss = 0.84415951, grad/param norm = 1.9957e-01, time/batch = 15.2177s	
28397/28500 (epoch 49.819), train_loss = 0.73824373, grad/param norm = 1.8366e-01, time/batch = 15.4011s	
28398/28500 (epoch 49.821), train_loss = 0.74222880, grad/param norm = 2.1561e-01, time/batch = 15.4734s	
28399/28500 (epoch 49.823), train_loss = 0.85386363, grad/param norm = 2.4829e-01, time/batch = 15.2922s	
28400/28500 (epoch 49.825), train_loss = 0.65225137, grad/param norm = 2.0865e-01, time/batch = 15.3880s	
28401/28500 (epoch 49.826), train_loss = 0.75017435, grad/param norm = 2.4262e-01, time/batch = 15.5323s	
28402/28500 (epoch 49.828), train_loss = 0.67799332, grad/param norm = 2.2567e-01, time/batch = 15.4794s	
28403/28500 (epoch 49.830), train_loss = 0.70102114, grad/param norm = 1.7344e-01, time/batch = 15.3622s	
28404/28500 (epoch 49.832), train_loss = 0.71528673, grad/param norm = 2.5142e-01, time/batch = 15.2498s	
28405/28500 (epoch 49.833), train_loss = 0.75992547, grad/param norm = 1.8673e-01, time/batch = 15.2302s	
28406/28500 (epoch 49.835), train_loss = 0.70045073, grad/param norm = 2.3740e-01, time/batch = 15.1344s	
28407/28500 (epoch 49.837), train_loss = 0.62546554, grad/param norm = 1.9822e-01, time/batch = 15.2571s	
28408/28500 (epoch 49.839), train_loss = 0.89998258, grad/param norm = 2.5151e-01, time/batch = 14.9814s	
28409/28500 (epoch 49.840), train_loss = 0.88476533, grad/param norm = 2.0842e-01, time/batch = 15.0582s	
28410/28500 (epoch 49.842), train_loss = 0.82994026, grad/param norm = 3.0548e-01, time/batch = 14.8910s	
28411/28500 (epoch 49.844), train_loss = 0.84390666, grad/param norm = 1.8469e-01, time/batch = 15.5473s	
28412/28500 (epoch 49.846), train_loss = 0.88900939, grad/param norm = 2.4809e-01, time/batch = 15.5749s	
28413/28500 (epoch 49.847), train_loss = 0.72344446, grad/param norm = 2.2393e-01, time/batch = 15.3733s	
28414/28500 (epoch 49.849), train_loss = 0.69263743, grad/param norm = 1.7218e-01, time/batch = 15.3107s	
28415/28500 (epoch 49.851), train_loss = 0.70084883, grad/param norm = 1.7893e-01, time/batch = 15.2997s	
28416/28500 (epoch 49.853), train_loss = 0.79665792, grad/param norm = 2.2386e-01, time/batch = 15.5517s	
28417/28500 (epoch 49.854), train_loss = 0.74940923, grad/param norm = 1.9530e-01, time/batch = 15.2551s	
28418/28500 (epoch 49.856), train_loss = 0.83606660, grad/param norm = 2.5102e-01, time/batch = 15.2579s	
28419/28500 (epoch 49.858), train_loss = 0.74752839, grad/param norm = 2.3840e-01, time/batch = 15.2997s	
28420/28500 (epoch 49.860), train_loss = 0.76341023, grad/param norm = 2.5603e-01, time/batch = 15.4472s	
28421/28500 (epoch 49.861), train_loss = 0.84104136, grad/param norm = 2.3692e-01, time/batch = 15.2652s	
28422/28500 (epoch 49.863), train_loss = 0.79200374, grad/param norm = 2.3853e-01, time/batch = 15.4538s	
28423/28500 (epoch 49.865), train_loss = 0.70257196, grad/param norm = 2.0628e-01, time/batch = 15.4622s	
28424/28500 (epoch 49.867), train_loss = 0.77698239, grad/param norm = 2.1798e-01, time/batch = 15.2854s	
28425/28500 (epoch 49.868), train_loss = 0.66648569, grad/param norm = 1.8259e-01, time/batch = 15.2399s	
28426/28500 (epoch 49.870), train_loss = 0.64998011, grad/param norm = 1.8657e-01, time/batch = 15.2647s	
28427/28500 (epoch 49.872), train_loss = 0.82751215, grad/param norm = 2.6752e-01, time/batch = 15.3021s	
28428/28500 (epoch 49.874), train_loss = 0.69538305, grad/param norm = 2.6658e-01, time/batch = 15.0334s	
28429/28500 (epoch 49.875), train_loss = 0.90797156, grad/param norm = 2.2588e-01, time/batch = 14.9040s	
28430/28500 (epoch 49.877), train_loss = 0.78936425, grad/param norm = 2.0875e-01, time/batch = 15.3355s	
28431/28500 (epoch 49.879), train_loss = 0.76350955, grad/param norm = 1.5735e-01, time/batch = 15.2526s	
28432/28500 (epoch 49.881), train_loss = 0.75865496, grad/param norm = 1.9016e-01, time/batch = 15.2407s	
28433/28500 (epoch 49.882), train_loss = 0.66991798, grad/param norm = 1.9214e-01, time/batch = 15.2184s	
28434/28500 (epoch 49.884), train_loss = 0.68255738, grad/param norm = 1.8165e-01, time/batch = 15.5674s	
28435/28500 (epoch 49.886), train_loss = 0.68435961, grad/param norm = 1.7035e-01, time/batch = 15.3137s	
28436/28500 (epoch 49.888), train_loss = 0.71952741, grad/param norm = 1.6978e-01, time/batch = 15.3025s	
28437/28500 (epoch 49.889), train_loss = 0.78070960, grad/param norm = 1.7770e-01, time/batch = 15.2332s	
28438/28500 (epoch 49.891), train_loss = 0.75496358, grad/param norm = 1.8708e-01, time/batch = 15.3829s	
28439/28500 (epoch 49.893), train_loss = 0.70662297, grad/param norm = 1.9521e-01, time/batch = 15.0592s	
28440/28500 (epoch 49.895), train_loss = 0.87567616, grad/param norm = 2.6954e-01, time/batch = 15.1385s	
28441/28500 (epoch 49.896), train_loss = 0.85399460, grad/param norm = 2.2848e-01, time/batch = 15.1264s	
28442/28500 (epoch 49.898), train_loss = 0.83715369, grad/param norm = 1.9255e-01, time/batch = 15.3458s	
28443/28500 (epoch 49.900), train_loss = 0.66145417, grad/param norm = 1.7235e-01, time/batch = 15.0482s	
28444/28500 (epoch 49.902), train_loss = 0.62576764, grad/param norm = 1.9007e-01, time/batch = 15.1377s	
28445/28500 (epoch 49.904), train_loss = 0.66957663, grad/param norm = 1.7387e-01, time/batch = 14.9742s	
28446/28500 (epoch 49.905), train_loss = 0.70735799, grad/param norm = 1.9658e-01, time/batch = 15.2165s	
28447/28500 (epoch 49.907), train_loss = 0.72912545, grad/param norm = 1.8212e-01, time/batch = 15.2087s	
28448/28500 (epoch 49.909), train_loss = 0.60297869, grad/param norm = 2.0016e-01, time/batch = 14.9140s	
28449/28500 (epoch 49.911), train_loss = 0.66731677, grad/param norm = 1.7063e-01, time/batch = 15.1411s	
28450/28500 (epoch 49.912), train_loss = 0.56105814, grad/param norm = 1.5964e-01, time/batch = 15.6079s	
28451/28500 (epoch 49.914), train_loss = 0.76800509, grad/param norm = 1.8460e-01, time/batch = 15.5670s	
28452/28500 (epoch 49.916), train_loss = 0.75168594, grad/param norm = 2.0018e-01, time/batch = 15.4384s	
28453/28500 (epoch 49.918), train_loss = 0.74111144, grad/param norm = 2.5842e-01, time/batch = 15.5470s	
28454/28500 (epoch 49.919), train_loss = 0.79281153, grad/param norm = 2.6278e-01, time/batch = 15.4913s	
28455/28500 (epoch 49.921), train_loss = 0.84618231, grad/param norm = 2.6025e-01, time/batch = 15.3074s	
28456/28500 (epoch 49.923), train_loss = 0.68898406, grad/param norm = 2.4717e-01, time/batch = 15.3133s	
28457/28500 (epoch 49.925), train_loss = 0.70029503, grad/param norm = 2.1202e-01, time/batch = 15.3106s	
28458/28500 (epoch 49.926), train_loss = 0.76283592, grad/param norm = 1.8987e-01, time/batch = 15.1929s	
28459/28500 (epoch 49.928), train_loss = 0.70430228, grad/param norm = 2.0617e-01, time/batch = 14.9144s	
28460/28500 (epoch 49.930), train_loss = 0.60936255, grad/param norm = 1.7278e-01, time/batch = 15.0664s	
28461/28500 (epoch 49.932), train_loss = 0.60148413, grad/param norm = 1.6462e-01, time/batch = 15.3246s	
28462/28500 (epoch 49.933), train_loss = 0.80605744, grad/param norm = 2.0546e-01, time/batch = 15.2321s	
28463/28500 (epoch 49.935), train_loss = 0.81030957, grad/param norm = 1.8625e-01, time/batch = 15.2284s	
28464/28500 (epoch 49.937), train_loss = 0.78331800, grad/param norm = 2.8000e-01, time/batch = 14.9214s	
28465/28500 (epoch 49.939), train_loss = 0.86914519, grad/param norm = 2.0719e-01, time/batch = 15.0646s	
28466/28500 (epoch 49.940), train_loss = 0.60369982, grad/param norm = 1.9729e-01, time/batch = 15.1368s	
28467/28500 (epoch 49.942), train_loss = 0.74870800, grad/param norm = 2.1915e-01, time/batch = 15.3153s	
28468/28500 (epoch 49.944), train_loss = 0.71233729, grad/param norm = 2.1245e-01, time/batch = 15.2250s	
28469/28500 (epoch 49.946), train_loss = 0.77732398, grad/param norm = 1.8188e-01, time/batch = 15.0504s	
28470/28500 (epoch 49.947), train_loss = 0.95373347, grad/param norm = 2.8421e-01, time/batch = 15.3499s	
28471/28500 (epoch 49.949), train_loss = 0.72271415, grad/param norm = 2.1955e-01, time/batch = 15.4983s	
28472/28500 (epoch 49.951), train_loss = 0.89612670, grad/param norm = 2.0594e-01, time/batch = 15.2225s	
28473/28500 (epoch 49.953), train_loss = 0.88716229, grad/param norm = 2.6438e-01, time/batch = 14.9826s	
28474/28500 (epoch 49.954), train_loss = 0.83582395, grad/param norm = 2.1268e-01, time/batch = 15.1372s	
28475/28500 (epoch 49.956), train_loss = 0.76469936, grad/param norm = 2.8717e-01, time/batch = 15.1563s	
28476/28500 (epoch 49.958), train_loss = 1.00460109, grad/param norm = 2.2357e-01, time/batch = 15.4667s	
28477/28500 (epoch 49.960), train_loss = 0.69076621, grad/param norm = 1.8863e-01, time/batch = 15.4710s	
28478/28500 (epoch 49.961), train_loss = 0.89281196, grad/param norm = 2.2846e-01, time/batch = 15.2293s	
28479/28500 (epoch 49.963), train_loss = 0.85215674, grad/param norm = 2.3512e-01, time/batch = 15.3138s	
28480/28500 (epoch 49.965), train_loss = 0.67946030, grad/param norm = 2.0027e-01, time/batch = 15.2207s	
28481/28500 (epoch 49.967), train_loss = 0.71402380, grad/param norm = 2.2396e-01, time/batch = 15.5224s	
28482/28500 (epoch 49.968), train_loss = 0.67625966, grad/param norm = 1.6420e-01, time/batch = 15.4311s	
28483/28500 (epoch 49.970), train_loss = 0.68334173, grad/param norm = 2.1717e-01, time/batch = 15.5382s	
28484/28500 (epoch 49.972), train_loss = 0.75293111, grad/param norm = 2.1415e-01, time/batch = 15.2582s	
28485/28500 (epoch 49.974), train_loss = 0.97477414, grad/param norm = 2.7901e-01, time/batch = 15.1101s	
28486/28500 (epoch 49.975), train_loss = 0.70141876, grad/param norm = 1.9914e-01, time/batch = 15.3065s	
28487/28500 (epoch 49.977), train_loss = 0.83450658, grad/param norm = 2.3847e-01, time/batch = 15.1479s	
28488/28500 (epoch 49.979), train_loss = 0.79906743, grad/param norm = 2.1327e-01, time/batch = 15.0686s	
28489/28500 (epoch 49.981), train_loss = 0.64357665, grad/param norm = 1.8578e-01, time/batch = 15.3724s	
28490/28500 (epoch 49.982), train_loss = 0.76760902, grad/param norm = 2.1444e-01, time/batch = 15.0797s	
28491/28500 (epoch 49.984), train_loss = 0.80622362, grad/param norm = 1.8756e-01, time/batch = 15.5547s	
28492/28500 (epoch 49.986), train_loss = 0.94959254, grad/param norm = 2.4949e-01, time/batch = 15.5669s	
28493/28500 (epoch 49.988), train_loss = 0.69142322, grad/param norm = 2.2250e-01, time/batch = 15.5574s	
28494/28500 (epoch 49.989), train_loss = 0.76487276, grad/param norm = 2.4170e-01, time/batch = 15.3177s	
28495/28500 (epoch 49.991), train_loss = 0.66790807, grad/param norm = 1.8385e-01, time/batch = 15.5582s	
28496/28500 (epoch 49.993), train_loss = 0.68431219, grad/param norm = 2.2300e-01, time/batch = 15.3860s	
28497/28500 (epoch 49.995), train_loss = 0.72059125, grad/param norm = 2.0036e-01, time/batch = 15.2918s	
28498/28500 (epoch 49.996), train_loss = 0.65287301, grad/param norm = 2.0501e-01, time/batch = 15.0930s	
28499/28500 (epoch 49.998), train_loss = 0.87084812, grad/param norm = 2.8321e-01, time/batch = 15.0612s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch50.00_2.0692.t7	
28500/28500 (epoch 50.000), train_loss = 0.73125957, grad/param norm = 1.7841e-01, time/batch = 15.0910s	

real	3181m58.637s
user	3153m2.692s
sys	2m26.164s
