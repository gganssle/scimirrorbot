tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 669, val: 36, test: 0	
vocab size: 159	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 300575	
cloning rnn	
cloning criterion	
1/33450 (epoch 0.001), train_loss = 5.05994999, grad/param norm = 5.4448e-01, time/batch = 0.7606s	
2/33450 (epoch 0.003), train_loss = 4.68739958, grad/param norm = 1.8375e+00, time/batch = 0.6808s	
3/33450 (epoch 0.004), train_loss = 3.89544504, grad/param norm = 1.3492e+00, time/batch = 0.6743s	
4/33450 (epoch 0.006), train_loss = 3.71324320, grad/param norm = 7.9144e-01, time/batch = 0.6719s	
5/33450 (epoch 0.007), train_loss = 3.43513754, grad/param norm = 7.7722e-01, time/batch = 0.7023s	
6/33450 (epoch 0.009), train_loss = 3.44404521, grad/param norm = 8.3744e-01, time/batch = 0.7094s	
7/33450 (epoch 0.010), train_loss = 3.58378504, grad/param norm = 9.9213e-01, time/batch = 0.6853s	
8/33450 (epoch 0.012), train_loss = 3.50466028, grad/param norm = 6.6127e-01, time/batch = 0.6737s	
9/33450 (epoch 0.013), train_loss = 3.43325930, grad/param norm = 7.7046e-01, time/batch = 0.6856s	
10/33450 (epoch 0.015), train_loss = 3.57326720, grad/param norm = 6.1592e-01, time/batch = 0.6825s	
11/33450 (epoch 0.016), train_loss = 3.59139727, grad/param norm = 6.2610e-01, time/batch = 0.6717s	
12/33450 (epoch 0.018), train_loss = 3.55403189, grad/param norm = 7.2613e-01, time/batch = 0.6782s	
13/33450 (epoch 0.019), train_loss = 3.56426976, grad/param norm = 5.8160e-01, time/batch = 0.6759s	
14/33450 (epoch 0.021), train_loss = 3.44490668, grad/param norm = 6.4866e-01, time/batch = 0.6734s	
15/33450 (epoch 0.022), train_loss = 3.58213302, grad/param norm = 6.0529e-01, time/batch = 0.6784s	
16/33450 (epoch 0.024), train_loss = 3.51308491, grad/param norm = 6.7516e-01, time/batch = 0.6750s	
17/33450 (epoch 0.025), train_loss = 3.41996975, grad/param norm = 6.4313e-01, time/batch = 0.6713s	
18/33450 (epoch 0.027), train_loss = 3.68179909, grad/param norm = 9.2136e-01, time/batch = 0.6743s	
19/33450 (epoch 0.028), train_loss = 3.38895397, grad/param norm = 5.7543e-01, time/batch = 0.6754s	
20/33450 (epoch 0.030), train_loss = 3.44505370, grad/param norm = 8.7209e-01, time/batch = 0.7176s	
21/33450 (epoch 0.031), train_loss = 3.36562467, grad/param norm = 6.7535e-01, time/batch = 0.6962s	
22/33450 (epoch 0.033), train_loss = 3.49059647, grad/param norm = 5.9914e-01, time/batch = 0.6834s	
23/33450 (epoch 0.034), train_loss = 3.29844859, grad/param norm = 7.4023e-01, time/batch = 0.6750s	
24/33450 (epoch 0.036), train_loss = 3.43628032, grad/param norm = 8.1442e-01, time/batch = 0.6763s	
25/33450 (epoch 0.037), train_loss = 3.48738981, grad/param norm = 5.7243e-01, time/batch = 0.6757s	
26/33450 (epoch 0.039), train_loss = 3.39232113, grad/param norm = 6.3300e-01, time/batch = 0.6724s	
27/33450 (epoch 0.040), train_loss = 3.46785264, grad/param norm = 6.8668e-01, time/batch = 0.6748s	
28/33450 (epoch 0.042), train_loss = 3.47644510, grad/param norm = 6.3025e-01, time/batch = 0.6744s	
29/33450 (epoch 0.043), train_loss = 3.35197094, grad/param norm = 5.6742e-01, time/batch = 0.6780s	
30/33450 (epoch 0.045), train_loss = 3.47520421, grad/param norm = 7.5137e-01, time/batch = 0.6798s	
31/33450 (epoch 0.046), train_loss = 3.62568597, grad/param norm = 6.3489e-01, time/batch = 0.6741s	
32/33450 (epoch 0.048), train_loss = 3.48015049, grad/param norm = 6.3049e-01, time/batch = 0.6739s	
33/33450 (epoch 0.049), train_loss = 3.41568349, grad/param norm = 6.3491e-01, time/batch = 0.6742s	
34/33450 (epoch 0.051), train_loss = 3.46902057, grad/param norm = 5.9412e-01, time/batch = 0.6767s	
35/33450 (epoch 0.052), train_loss = 3.79472740, grad/param norm = 7.8218e-01, time/batch = 0.6741s	
36/33450 (epoch 0.054), train_loss = 3.33851177, grad/param norm = 8.8768e-01, time/batch = 0.6745s	
37/33450 (epoch 0.055), train_loss = 3.56145629, grad/param norm = 9.0916e-01, time/batch = 0.6739s	
38/33450 (epoch 0.057), train_loss = 3.53103646, grad/param norm = 7.8596e-01, time/batch = 0.6824s	
39/33450 (epoch 0.058), train_loss = 3.45548502, grad/param norm = 6.4213e-01, time/batch = 0.6736s	
40/33450 (epoch 0.060), train_loss = 3.36540517, grad/param norm = 6.3809e-01, time/batch = 0.6736s	
41/33450 (epoch 0.061), train_loss = 3.41370624, grad/param norm = 5.6424e-01, time/batch = 0.6751s	
42/33450 (epoch 0.063), train_loss = 3.39091768, grad/param norm = 5.2035e-01, time/batch = 0.6724s	
43/33450 (epoch 0.064), train_loss = 3.41134007, grad/param norm = 5.8640e-01, time/batch = 0.6755s	
44/33450 (epoch 0.066), train_loss = 3.30166359, grad/param norm = 5.5169e-01, time/batch = 0.6801s	
45/33450 (epoch 0.067), train_loss = 3.38880382, grad/param norm = 5.0290e-01, time/batch = 0.6844s	
46/33450 (epoch 0.069), train_loss = 3.48993504, grad/param norm = 5.0012e-01, time/batch = 0.6786s	
47/33450 (epoch 0.070), train_loss = 3.43537800, grad/param norm = 6.5185e-01, time/batch = 0.6731s	
48/33450 (epoch 0.072), train_loss = 3.39834085, grad/param norm = 6.0418e-01, time/batch = 0.6713s	
49/33450 (epoch 0.073), train_loss = 3.40402028, grad/param norm = 7.3535e-01, time/batch = 0.7039s	
50/33450 (epoch 0.075), train_loss = 3.53706298, grad/param norm = 6.5757e-01, time/batch = 0.7063s	
51/33450 (epoch 0.076), train_loss = 3.44905139, grad/param norm = 6.5240e-01, time/batch = 0.6760s	
52/33450 (epoch 0.078), train_loss = 3.54960286, grad/param norm = 5.6948e-01, time/batch = 0.6735s	
53/33450 (epoch 0.079), train_loss = 3.32580008, grad/param norm = 5.5504e-01, time/batch = 0.6747s	
54/33450 (epoch 0.081), train_loss = 3.34161295, grad/param norm = 7.5204e-01, time/batch = 0.6725s	
55/33450 (epoch 0.082), train_loss = 3.48360895, grad/param norm = 7.0007e-01, time/batch = 0.6730s	
56/33450 (epoch 0.084), train_loss = 3.38234797, grad/param norm = 6.6684e-01, time/batch = 0.6738s	
57/33450 (epoch 0.085), train_loss = 3.43827140, grad/param norm = 5.6353e-01, time/batch = 0.6720s	
58/33450 (epoch 0.087), train_loss = 3.55516908, grad/param norm = 6.4318e-01, time/batch = 0.6723s	
59/33450 (epoch 0.088), train_loss = 3.30532070, grad/param norm = 5.7781e-01, time/batch = 0.6752s	
60/33450 (epoch 0.090), train_loss = 3.50218359, grad/param norm = 6.8380e-01, time/batch = 0.6743s	
61/33450 (epoch 0.091), train_loss = 3.51210781, grad/param norm = 5.8330e-01, time/batch = 0.6726s	
62/33450 (epoch 0.093), train_loss = 3.55867922, grad/param norm = 5.7216e-01, time/batch = 0.6727s	
63/33450 (epoch 0.094), train_loss = 3.33399000, grad/param norm = 4.7192e-01, time/batch = 0.6813s	
64/33450 (epoch 0.096), train_loss = 3.26483788, grad/param norm = 5.5472e-01, time/batch = 0.7172s	
65/33450 (epoch 0.097), train_loss = 3.55663028, grad/param norm = 5.3990e-01, time/batch = 0.6904s	
66/33450 (epoch 0.099), train_loss = 3.45990183, grad/param norm = 4.4450e-01, time/batch = 0.6738s	
67/33450 (epoch 0.100), train_loss = 3.96683723, grad/param norm = 8.0586e-01, time/batch = 0.6759s	
68/33450 (epoch 0.102), train_loss = 3.51304660, grad/param norm = 5.1116e-01, time/batch = 0.6755s	
69/33450 (epoch 0.103), train_loss = 3.50394678, grad/param norm = 5.2003e-01, time/batch = 0.6777s	
70/33450 (epoch 0.105), train_loss = 3.46371985, grad/param norm = 6.8013e-01, time/batch = 0.6744s	
71/33450 (epoch 0.106), train_loss = 3.35502731, grad/param norm = 5.1340e-01, time/batch = 0.6765s	
72/33450 (epoch 0.108), train_loss = 3.52680148, grad/param norm = 6.8535e-01, time/batch = 0.6973s	
73/33450 (epoch 0.109), train_loss = 3.44917887, grad/param norm = 8.0615e-01, time/batch = 0.7038s	
74/33450 (epoch 0.111), train_loss = 3.45632497, grad/param norm = 5.8161e-01, time/batch = 0.6925s	
75/33450 (epoch 0.112), train_loss = 3.54582052, grad/param norm = 5.9613e-01, time/batch = 0.7057s	
76/33450 (epoch 0.114), train_loss = 3.47784738, grad/param norm = 7.1362e-01, time/batch = 0.7050s	
77/33450 (epoch 0.115), train_loss = 3.59238823, grad/param norm = 6.5035e-01, time/batch = 0.6906s	
78/33450 (epoch 0.117), train_loss = 3.66172898, grad/param norm = 5.8664e-01, time/batch = 0.6883s	
79/33450 (epoch 0.118), train_loss = 3.36062066, grad/param norm = 5.5906e-01, time/batch = 0.6914s	
80/33450 (epoch 0.120), train_loss = 3.56987873, grad/param norm = 7.0723e-01, time/batch = 0.6931s	
81/33450 (epoch 0.121), train_loss = 3.30854310, grad/param norm = 7.2728e-01, time/batch = 0.6961s	
82/33450 (epoch 0.123), train_loss = 3.57520417, grad/param norm = 6.6129e-01, time/batch = 0.7037s	
83/33450 (epoch 0.124), train_loss = 3.34256033, grad/param norm = 6.9508e-01, time/batch = 0.6850s	
84/33450 (epoch 0.126), train_loss = 3.51652575, grad/param norm = 5.2728e-01, time/batch = 0.6827s	
85/33450 (epoch 0.127), train_loss = 3.57560260, grad/param norm = 5.2468e-01, time/batch = 0.6782s	
86/33450 (epoch 0.129), train_loss = 3.43275281, grad/param norm = 6.2806e-01, time/batch = 0.6740s	
87/33450 (epoch 0.130), train_loss = 3.46519365, grad/param norm = 6.5967e-01, time/batch = 0.6731s	
88/33450 (epoch 0.132), train_loss = 3.56818815, grad/param norm = 7.8453e-01, time/batch = 0.6991s	
89/33450 (epoch 0.133), train_loss = 3.42965521, grad/param norm = 6.0670e-01, time/batch = 0.6806s	
90/33450 (epoch 0.135), train_loss = 3.57456870, grad/param norm = 5.3270e-01, time/batch = 0.6735s	
91/33450 (epoch 0.136), train_loss = 3.49748462, grad/param norm = 4.8180e-01, time/batch = 0.6757s	
92/33450 (epoch 0.138), train_loss = 3.51329208, grad/param norm = 4.5979e-01, time/batch = 0.6751s	
93/33450 (epoch 0.139), train_loss = 3.40210170, grad/param norm = 5.8624e-01, time/batch = 0.7195s	
94/33450 (epoch 0.141), train_loss = 3.50242306, grad/param norm = 6.5123e-01, time/batch = 0.6905s	
95/33450 (epoch 0.142), train_loss = 3.40972893, grad/param norm = 5.7245e-01, time/batch = 0.6734s	
96/33450 (epoch 0.143), train_loss = 3.72157499, grad/param norm = 6.9684e-01, time/batch = 0.6731s	
97/33450 (epoch 0.145), train_loss = 3.48940515, grad/param norm = 5.7195e-01, time/batch = 0.6739s	
98/33450 (epoch 0.146), train_loss = 3.48873848, grad/param norm = 5.2058e-01, time/batch = 0.6765s	
99/33450 (epoch 0.148), train_loss = 3.48741968, grad/param norm = 5.3252e-01, time/batch = 0.6782s	
100/33450 (epoch 0.149), train_loss = 3.52847546, grad/param norm = 5.3092e-01, time/batch = 0.6829s	
101/33450 (epoch 0.151), train_loss = 3.49876544, grad/param norm = 4.3192e-01, time/batch = 0.6822s	
102/33450 (epoch 0.152), train_loss = 3.43126233, grad/param norm = 4.9891e-01, time/batch = 0.6769s	
103/33450 (epoch 0.154), train_loss = 3.54993570, grad/param norm = 5.2582e-01, time/batch = 0.7098s	
104/33450 (epoch 0.155), train_loss = 3.48357638, grad/param norm = 5.5534e-01, time/batch = 0.6999s	
105/33450 (epoch 0.157), train_loss = 3.50694147, grad/param norm = 4.9189e-01, time/batch = 0.6747s	
106/33450 (epoch 0.158), train_loss = 3.45582471, grad/param norm = 6.6057e-01, time/batch = 0.6756s	
107/33450 (epoch 0.160), train_loss = 3.48648546, grad/param norm = 7.4530e-01, time/batch = 0.6756s	
108/33450 (epoch 0.161), train_loss = 3.46003778, grad/param norm = 5.2475e-01, time/batch = 0.6738s	
109/33450 (epoch 0.163), train_loss = 3.55116687, grad/param norm = 5.1781e-01, time/batch = 0.6774s	
110/33450 (epoch 0.164), train_loss = 3.45117155, grad/param norm = 4.6074e-01, time/batch = 0.6741s	
111/33450 (epoch 0.166), train_loss = 3.42974261, grad/param norm = 5.1944e-01, time/batch = 0.6768s	
112/33450 (epoch 0.167), train_loss = 3.46263468, grad/param norm = 5.7705e-01, time/batch = 0.6735s	
113/33450 (epoch 0.169), train_loss = 3.27705956, grad/param norm = 6.4933e-01, time/batch = 0.6741s	
114/33450 (epoch 0.170), train_loss = 3.39822827, grad/param norm = 5.3877e-01, time/batch = 0.6753s	
115/33450 (epoch 0.172), train_loss = 3.38195554, grad/param norm = 5.2065e-01, time/batch = 0.6727s	
116/33450 (epoch 0.173), train_loss = 3.40970838, grad/param norm = 6.5722e-01, time/batch = 0.6742s	
117/33450 (epoch 0.175), train_loss = 3.52092870, grad/param norm = 5.5118e-01, time/batch = 0.6828s	
118/33450 (epoch 0.176), train_loss = 3.49390044, grad/param norm = 5.4001e-01, time/batch = 0.7177s	
119/33450 (epoch 0.178), train_loss = 3.37118356, grad/param norm = 8.9931e-01, time/batch = 0.6854s	
120/33450 (epoch 0.179), train_loss = 3.34006865, grad/param norm = 9.6757e-01, time/batch = 0.6759s	
121/33450 (epoch 0.181), train_loss = 3.34408611, grad/param norm = 8.9600e-01, time/batch = 0.6760s	
122/33450 (epoch 0.182), train_loss = 3.34347067, grad/param norm = 5.3866e-01, time/batch = 0.6742s	
123/33450 (epoch 0.184), train_loss = 3.47343943, grad/param norm = 5.5029e-01, time/batch = 0.6743s	
124/33450 (epoch 0.185), train_loss = 3.41367395, grad/param norm = 5.7130e-01, time/batch = 0.6727s	
125/33450 (epoch 0.187), train_loss = 3.29231491, grad/param norm = 3.7845e-01, time/batch = 0.6728s	
126/33450 (epoch 0.188), train_loss = 3.37414154, grad/param norm = 5.5234e-01, time/batch = 0.6743s	
127/33450 (epoch 0.190), train_loss = 3.38234807, grad/param norm = 3.9105e-01, time/batch = 0.6730s	
128/33450 (epoch 0.191), train_loss = 3.35583548, grad/param norm = 4.5612e-01, time/batch = 0.6738s	
129/33450 (epoch 0.193), train_loss = 3.44068257, grad/param norm = 5.7995e-01, time/batch = 0.6755s	
130/33450 (epoch 0.194), train_loss = 3.27424854, grad/param norm = 1.1731e+00, time/batch = 0.6729s	
131/33450 (epoch 0.196), train_loss = 3.46658636, grad/param norm = 1.0707e+00, time/batch = 0.6825s	
132/33450 (epoch 0.197), train_loss = 3.32389209, grad/param norm = 6.6161e-01, time/batch = 0.7104s	
133/33450 (epoch 0.199), train_loss = 3.34298611, grad/param norm = 5.0786e-01, time/batch = 0.7116s	
134/33450 (epoch 0.200), train_loss = 3.43673959, grad/param norm = 4.6149e-01, time/batch = 0.7104s	
135/33450 (epoch 0.202), train_loss = 3.21054465, grad/param norm = 5.9053e-01, time/batch = 0.7110s	
136/33450 (epoch 0.203), train_loss = 3.40875797, grad/param norm = 6.8062e-01, time/batch = 0.7036s	
137/33450 (epoch 0.205), train_loss = 3.38602344, grad/param norm = 4.5512e-01, time/batch = 0.7020s	
138/33450 (epoch 0.206), train_loss = 3.43115513, grad/param norm = 4.1670e-01, time/batch = 0.6860s	
139/33450 (epoch 0.208), train_loss = 3.38978191, grad/param norm = 5.1099e-01, time/batch = 0.6727s	
140/33450 (epoch 0.209), train_loss = 3.29365763, grad/param norm = 8.1142e-01, time/batch = 0.6736s	
141/33450 (epoch 0.211), train_loss = 3.42951261, grad/param norm = 1.4951e+00, time/batch = 0.6732s	
142/33450 (epoch 0.212), train_loss = 3.37467816, grad/param norm = 7.6058e-01, time/batch = 0.6934s	
143/33450 (epoch 0.214), train_loss = 3.31829367, grad/param norm = 3.5351e-01, time/batch = 0.7166s	
144/33450 (epoch 0.215), train_loss = 3.35006473, grad/param norm = 4.2578e-01, time/batch = 0.6860s	
145/33450 (epoch 0.217), train_loss = 3.42005110, grad/param norm = 5.4964e-01, time/batch = 0.6742s	
146/33450 (epoch 0.218), train_loss = 3.17598118, grad/param norm = 4.8226e-01, time/batch = 0.6740s	
147/33450 (epoch 0.220), train_loss = 3.17417885, grad/param norm = 4.1928e-01, time/batch = 0.6735s	
148/33450 (epoch 0.221), train_loss = 3.57617772, grad/param norm = 6.7642e-01, time/batch = 0.6731s	
149/33450 (epoch 0.223), train_loss = 3.39913435, grad/param norm = 6.7898e-01, time/batch = 0.6735s	
150/33450 (epoch 0.224), train_loss = 3.30760922, grad/param norm = 5.4361e-01, time/batch = 0.6751s	
151/33450 (epoch 0.226), train_loss = 3.24049226, grad/param norm = 4.8081e-01, time/batch = 0.6758s	
152/33450 (epoch 0.227), train_loss = 3.27232201, grad/param norm = 6.1552e-01, time/batch = 0.6735s	
153/33450 (epoch 0.229), train_loss = 3.28658779, grad/param norm = 1.0731e+00, time/batch = 0.6747s	
154/33450 (epoch 0.230), train_loss = 3.25982088, grad/param norm = 1.2167e+00, time/batch = 0.6753s	
155/33450 (epoch 0.232), train_loss = 3.33642069, grad/param norm = 6.3908e-01, time/batch = 0.6774s	
156/33450 (epoch 0.233), train_loss = 3.25333555, grad/param norm = 4.3479e-01, time/batch = 0.6829s	
157/33450 (epoch 0.235), train_loss = 3.21280179, grad/param norm = 4.4971e-01, time/batch = 0.7136s	
158/33450 (epoch 0.236), train_loss = 3.24654064, grad/param norm = 3.8993e-01, time/batch = 0.6998s	
159/33450 (epoch 0.238), train_loss = 3.19060357, grad/param norm = 6.7404e-01, time/batch = 0.6801s	
160/33450 (epoch 0.239), train_loss = 3.40341944, grad/param norm = 1.1281e+00, time/batch = 0.6860s	
161/33450 (epoch 0.241), train_loss = 3.38848991, grad/param norm = 6.4151e-01, time/batch = 0.6843s	
162/33450 (epoch 0.242), train_loss = 3.15174651, grad/param norm = 4.4080e-01, time/batch = 0.6931s	
163/33450 (epoch 0.244), train_loss = 3.24060908, grad/param norm = 4.3326e-01, time/batch = 0.6959s	
164/33450 (epoch 0.245), train_loss = 3.17019421, grad/param norm = 4.7405e-01, time/batch = 0.6831s	
165/33450 (epoch 0.247), train_loss = 3.27219967, grad/param norm = 4.3657e-01, time/batch = 0.6806s	
166/33450 (epoch 0.248), train_loss = 3.07954249, grad/param norm = 5.3940e-01, time/batch = 0.6804s	
167/33450 (epoch 0.250), train_loss = 3.23670905, grad/param norm = 8.5793e-01, time/batch = 0.6759s	
168/33450 (epoch 0.251), train_loss = 3.34560939, grad/param norm = 1.4346e+00, time/batch = 0.6769s	
169/33450 (epoch 0.253), train_loss = 3.18044151, grad/param norm = 8.7504e-01, time/batch = 0.6738s	
170/33450 (epoch 0.254), train_loss = 3.15934950, grad/param norm = 6.1153e-01, time/batch = 0.6752s	
171/33450 (epoch 0.256), train_loss = 3.18663406, grad/param norm = 5.1121e-01, time/batch = 0.6899s	
172/33450 (epoch 0.257), train_loss = 3.12241854, grad/param norm = 4.0421e-01, time/batch = 0.7191s	
173/33450 (epoch 0.259), train_loss = 3.06822564, grad/param norm = 5.3796e-01, time/batch = 0.6833s	
174/33450 (epoch 0.260), train_loss = 3.18850610, grad/param norm = 4.5200e-01, time/batch = 0.6756s	
175/33450 (epoch 0.262), train_loss = 3.11203548, grad/param norm = 5.0463e-01, time/batch = 0.6766s	
176/33450 (epoch 0.263), train_loss = 3.14684430, grad/param norm = 8.0827e-01, time/batch = 0.6762s	
177/33450 (epoch 0.265), train_loss = 3.13353568, grad/param norm = 6.3035e-01, time/batch = 0.6746s	
178/33450 (epoch 0.266), train_loss = 3.18595141, grad/param norm = 6.9130e-01, time/batch = 0.6727s	
179/33450 (epoch 0.268), train_loss = 3.16942898, grad/param norm = 7.2679e-01, time/batch = 0.6751s	
180/33450 (epoch 0.269), train_loss = 3.03948655, grad/param norm = 6.3620e-01, time/batch = 0.6832s	
181/33450 (epoch 0.271), train_loss = 3.16421768, grad/param norm = 4.3782e-01, time/batch = 0.6786s	
182/33450 (epoch 0.272), train_loss = 3.06382583, grad/param norm = 4.2878e-01, time/batch = 0.6764s	
183/33450 (epoch 0.274), train_loss = 3.14471067, grad/param norm = 9.1626e-01, time/batch = 0.6798s	
184/33450 (epoch 0.275), train_loss = 3.25975792, grad/param norm = 1.4075e+00, time/batch = 0.6782s	
185/33450 (epoch 0.277), train_loss = 3.14667662, grad/param norm = 1.2537e+00, time/batch = 0.6725s	
186/33450 (epoch 0.278), train_loss = 3.04602786, grad/param norm = 5.0414e-01, time/batch = 0.7025s	
187/33450 (epoch 0.280), train_loss = 3.09327174, grad/param norm = 4.8625e-01, time/batch = 0.7065s	
188/33450 (epoch 0.281), train_loss = 3.06989979, grad/param norm = 4.8296e-01, time/batch = 0.6741s	
189/33450 (epoch 0.283), train_loss = 2.98904175, grad/param norm = 5.5896e-01, time/batch = 0.6737s	
190/33450 (epoch 0.284), train_loss = 3.12951292, grad/param norm = 9.3798e-01, time/batch = 0.6779s	
191/33450 (epoch 0.286), train_loss = 3.09083215, grad/param norm = 9.7723e-01, time/batch = 0.6766s	
192/33450 (epoch 0.287), train_loss = 3.00594747, grad/param norm = 7.2432e-01, time/batch = 0.6735s	
193/33450 (epoch 0.288), train_loss = 3.04770578, grad/param norm = 7.6340e-01, time/batch = 0.6794s	
194/33450 (epoch 0.290), train_loss = 3.17274116, grad/param norm = 5.2400e-01, time/batch = 0.6853s	
195/33450 (epoch 0.291), train_loss = 3.11763154, grad/param norm = 6.5210e-01, time/batch = 0.6751s	
196/33450 (epoch 0.293), train_loss = 3.07774632, grad/param norm = 7.8261e-01, time/batch = 0.6780s	
197/33450 (epoch 0.294), train_loss = 3.05213180, grad/param norm = 6.9872e-01, time/batch = 0.6746s	
198/33450 (epoch 0.296), train_loss = 3.01894259, grad/param norm = 7.1666e-01, time/batch = 0.6746s	
199/33450 (epoch 0.297), train_loss = 3.01487914, grad/param norm = 6.5993e-01, time/batch = 0.6755s	
200/33450 (epoch 0.299), train_loss = 3.08817986, grad/param norm = 7.2916e-01, time/batch = 0.6751s	
201/33450 (epoch 0.300), train_loss = 3.03823449, grad/param norm = 1.1148e+00, time/batch = 0.7112s	
202/33450 (epoch 0.302), train_loss = 3.19640131, grad/param norm = 1.3399e+00, time/batch = 0.6741s	
203/33450 (epoch 0.303), train_loss = 2.96181874, grad/param norm = 8.2090e-01, time/batch = 0.6724s	
204/33450 (epoch 0.305), train_loss = 3.05784229, grad/param norm = 7.3891e-01, time/batch = 0.6738s	
205/33450 (epoch 0.306), train_loss = 3.18856138, grad/param norm = 9.5807e-01, time/batch = 0.6748s	
206/33450 (epoch 0.308), train_loss = 3.09013494, grad/param norm = 7.2701e-01, time/batch = 0.6724s	
207/33450 (epoch 0.309), train_loss = 3.09925568, grad/param norm = 5.2529e-01, time/batch = 0.6745s	
208/33450 (epoch 0.311), train_loss = 2.90763562, grad/param norm = 4.3432e-01, time/batch = 0.6741s	
209/33450 (epoch 0.312), train_loss = 3.01166140, grad/param norm = 3.9908e-01, time/batch = 0.6749s	
210/33450 (epoch 0.314), train_loss = 3.02856292, grad/param norm = 5.9549e-01, time/batch = 0.6741s	
211/33450 (epoch 0.315), train_loss = 2.93523784, grad/param norm = 6.5584e-01, time/batch = 0.6920s	
212/33450 (epoch 0.317), train_loss = 2.88865843, grad/param norm = 4.2499e-01, time/batch = 0.6850s	
213/33450 (epoch 0.318), train_loss = 2.93766710, grad/param norm = 3.7133e-01, time/batch = 0.6747s	
214/33450 (epoch 0.320), train_loss = 2.97674293, grad/param norm = 5.6616e-01, time/batch = 0.6749s	
215/33450 (epoch 0.321), train_loss = 2.93693271, grad/param norm = 1.0237e+00, time/batch = 0.6893s	
216/33450 (epoch 0.323), train_loss = 2.91020630, grad/param norm = 1.4653e+00, time/batch = 0.7183s	
217/33450 (epoch 0.324), train_loss = 3.04053210, grad/param norm = 1.0638e+00, time/batch = 0.6737s	
218/33450 (epoch 0.326), train_loss = 2.93774639, grad/param norm = 5.1979e-01, time/batch = 0.6797s	
219/33450 (epoch 0.327), train_loss = 2.90621890, grad/param norm = 4.1430e-01, time/batch = 0.6738s	
220/33450 (epoch 0.329), train_loss = 2.91360565, grad/param norm = 5.0709e-01, time/batch = 0.6811s	
221/33450 (epoch 0.330), train_loss = 3.02440059, grad/param norm = 8.1959e-01, time/batch = 0.6828s	
222/33450 (epoch 0.332), train_loss = 3.17030544, grad/param norm = 1.0347e+00, time/batch = 0.6734s	
223/33450 (epoch 0.333), train_loss = 2.86616985, grad/param norm = 1.4118e+00, time/batch = 0.6763s	
224/33450 (epoch 0.335), train_loss = 3.13001699, grad/param norm = 9.4103e-01, time/batch = 0.6818s	
225/33450 (epoch 0.336), train_loss = 2.88468435, grad/param norm = 5.0355e-01, time/batch = 0.6768s	
226/33450 (epoch 0.338), train_loss = 2.96335146, grad/param norm = 6.2438e-01, time/batch = 0.6754s	
227/33450 (epoch 0.339), train_loss = 2.96380005, grad/param norm = 5.5264e-01, time/batch = 0.6759s	
228/33450 (epoch 0.341), train_loss = 3.01476071, grad/param norm = 5.7728e-01, time/batch = 0.6745s	
229/33450 (epoch 0.342), train_loss = 3.04048445, grad/param norm = 5.8861e-01, time/batch = 0.6725s	
230/33450 (epoch 0.344), train_loss = 2.97092083, grad/param norm = 4.2284e-01, time/batch = 0.7045s	
231/33450 (epoch 0.345), train_loss = 2.85944936, grad/param norm = 5.0705e-01, time/batch = 0.7059s	
232/33450 (epoch 0.347), train_loss = 2.88418607, grad/param norm = 9.2421e-01, time/batch = 0.6737s	
233/33450 (epoch 0.348), train_loss = 2.82193533, grad/param norm = 8.5009e-01, time/batch = 0.6745s	
234/33450 (epoch 0.350), train_loss = 3.04570147, grad/param norm = 7.0466e-01, time/batch = 0.6734s	
235/33450 (epoch 0.351), train_loss = 2.81990894, grad/param norm = 6.6387e-01, time/batch = 0.6712s	
236/33450 (epoch 0.353), train_loss = 2.92178198, grad/param norm = 7.2474e-01, time/batch = 0.6710s	
237/33450 (epoch 0.354), train_loss = 2.93093973, grad/param norm = 4.8027e-01, time/batch = 0.6717s	
238/33450 (epoch 0.356), train_loss = 2.96045443, grad/param norm = 4.0645e-01, time/batch = 0.6799s	
239/33450 (epoch 0.357), train_loss = 2.90201790, grad/param norm = 5.0415e-01, time/batch = 0.6905s	
240/33450 (epoch 0.359), train_loss = 3.00246006, grad/param norm = 6.6226e-01, time/batch = 0.6897s	
241/33450 (epoch 0.360), train_loss = 2.93097937, grad/param norm = 7.7655e-01, time/batch = 0.6919s	
242/33450 (epoch 0.362), train_loss = 3.02958628, grad/param norm = 9.4782e-01, time/batch = 0.6902s	
243/33450 (epoch 0.363), train_loss = 3.01794589, grad/param norm = 1.2034e+00, time/batch = 0.6934s	
244/33450 (epoch 0.365), train_loss = 2.99480136, grad/param norm = 8.3179e-01, time/batch = 0.6890s	
245/33450 (epoch 0.366), train_loss = 2.92579380, grad/param norm = 5.1270e-01, time/batch = 0.6920s	
246/33450 (epoch 0.368), train_loss = 2.97510569, grad/param norm = 3.9945e-01, time/batch = 0.6931s	
247/33450 (epoch 0.369), train_loss = 2.92458887, grad/param norm = 4.7144e-01, time/batch = 0.7050s	
248/33450 (epoch 0.371), train_loss = 2.90084465, grad/param norm = 5.3882e-01, time/batch = 0.6995s	
249/33450 (epoch 0.372), train_loss = 3.01202676, grad/param norm = 7.7096e-01, time/batch = 0.6978s	
250/33450 (epoch 0.374), train_loss = 3.08750426, grad/param norm = 7.0966e-01, time/batch = 0.6820s	
251/33450 (epoch 0.375), train_loss = 2.97577474, grad/param norm = 5.0877e-01, time/batch = 0.6759s	
252/33450 (epoch 0.377), train_loss = 2.93704310, grad/param norm = 5.4630e-01, time/batch = 0.6777s	
253/33450 (epoch 0.378), train_loss = 3.03626692, grad/param norm = 8.7189e-01, time/batch = 0.6733s	
254/33450 (epoch 0.380), train_loss = 3.08466823, grad/param norm = 1.1602e+00, time/batch = 0.6734s	
255/33450 (epoch 0.381), train_loss = 2.86743446, grad/param norm = 5.4626e-01, time/batch = 0.6714s	
256/33450 (epoch 0.383), train_loss = 2.81737499, grad/param norm = 6.0895e-01, time/batch = 0.6736s	
257/33450 (epoch 0.384), train_loss = 2.89321233, grad/param norm = 5.2483e-01, time/batch = 0.6796s	
258/33450 (epoch 0.386), train_loss = 2.85336480, grad/param norm = 4.1245e-01, time/batch = 0.6748s	
259/33450 (epoch 0.387), train_loss = 3.00710793, grad/param norm = 4.6917e-01, time/batch = 0.6807s	
260/33450 (epoch 0.389), train_loss = 2.92117389, grad/param norm = 3.7204e-01, time/batch = 0.6791s	
261/33450 (epoch 0.390), train_loss = 2.87413702, grad/param norm = 3.7073e-01, time/batch = 0.6769s	
262/33450 (epoch 0.392), train_loss = 2.81709388, grad/param norm = 6.4812e-01, time/batch = 0.6740s	
263/33450 (epoch 0.393), train_loss = 2.85020889, grad/param norm = 8.9930e-01, time/batch = 0.6843s	
264/33450 (epoch 0.395), train_loss = 2.89810582, grad/param norm = 9.7287e-01, time/batch = 0.6754s	
265/33450 (epoch 0.396), train_loss = 2.94537741, grad/param norm = 7.2047e-01, time/batch = 0.6745s	
266/33450 (epoch 0.398), train_loss = 2.88939977, grad/param norm = 5.0485e-01, time/batch = 0.6738s	
267/33450 (epoch 0.399), train_loss = 3.06936624, grad/param norm = 5.9534e-01, time/batch = 0.6738s	
268/33450 (epoch 0.401), train_loss = 3.04471516, grad/param norm = 5.3883e-01, time/batch = 0.6734s	
269/33450 (epoch 0.402), train_loss = 2.84571318, grad/param norm = 5.2772e-01, time/batch = 0.6736s	
270/33450 (epoch 0.404), train_loss = 2.91109662, grad/param norm = 6.9004e-01, time/batch = 0.6737s	
271/33450 (epoch 0.405), train_loss = 2.87427851, grad/param norm = 6.1903e-01, time/batch = 0.6748s	
272/33450 (epoch 0.407), train_loss = 2.81955578, grad/param norm = 5.7119e-01, time/batch = 0.6751s	
273/33450 (epoch 0.408), train_loss = 2.93422382, grad/param norm = 5.3543e-01, time/batch = 0.6763s	
274/33450 (epoch 0.410), train_loss = 2.94804983, grad/param norm = 4.6568e-01, time/batch = 0.6784s	
275/33450 (epoch 0.411), train_loss = 2.86810605, grad/param norm = 6.9223e-01, time/batch = 0.6759s	
276/33450 (epoch 0.413), train_loss = 2.88530608, grad/param norm = 1.0067e+00, time/batch = 0.6760s	
277/33450 (epoch 0.414), train_loss = 2.90166696, grad/param norm = 8.5741e-01, time/batch = 0.6764s	
278/33450 (epoch 0.416), train_loss = 2.89669903, grad/param norm = 5.3171e-01, time/batch = 0.6750s	
279/33450 (epoch 0.417), train_loss = 2.90839740, grad/param norm = 3.6527e-01, time/batch = 0.6835s	
280/33450 (epoch 0.419), train_loss = 2.87423318, grad/param norm = 4.7591e-01, time/batch = 0.6743s	
281/33450 (epoch 0.420), train_loss = 2.86977064, grad/param norm = 5.5525e-01, time/batch = 0.6757s	
282/33450 (epoch 0.422), train_loss = 2.80874686, grad/param norm = 5.1689e-01, time/batch = 0.6742s	
283/33450 (epoch 0.423), train_loss = 2.79224576, grad/param norm = 4.8696e-01, time/batch = 0.6743s	
284/33450 (epoch 0.425), train_loss = 2.74493016, grad/param norm = 5.8790e-01, time/batch = 0.6788s	
285/33450 (epoch 0.426), train_loss = 2.80210752, grad/param norm = 6.7769e-01, time/batch = 0.6755s	
286/33450 (epoch 0.428), train_loss = 2.86823286, grad/param norm = 7.5225e-01, time/batch = 0.6735s	
287/33450 (epoch 0.429), train_loss = 2.91631093, grad/param norm = 6.9763e-01, time/batch = 0.6750s	
288/33450 (epoch 0.430), train_loss = 2.87148742, grad/param norm = 1.1267e+00, time/batch = 0.6807s	
289/33450 (epoch 0.432), train_loss = 3.00288031, grad/param norm = 1.0280e+00, time/batch = 0.7183s	
290/33450 (epoch 0.433), train_loss = 2.93332657, grad/param norm = 5.2270e-01, time/batch = 0.6848s	
291/33450 (epoch 0.435), train_loss = 2.80923012, grad/param norm = 3.5751e-01, time/batch = 0.6776s	
292/33450 (epoch 0.436), train_loss = 2.84959099, grad/param norm = 3.4849e-01, time/batch = 0.6836s	
293/33450 (epoch 0.438), train_loss = 2.82926584, grad/param norm = 4.4961e-01, time/batch = 0.6752s	
294/33450 (epoch 0.439), train_loss = 2.85562407, grad/param norm = 4.2796e-01, time/batch = 0.6743s	
295/33450 (epoch 0.441), train_loss = 2.92258499, grad/param norm = 4.7861e-01, time/batch = 0.6753s	
296/33450 (epoch 0.442), train_loss = 2.97192082, grad/param norm = 5.6269e-01, time/batch = 0.6740s	
297/33450 (epoch 0.444), train_loss = 2.87991006, grad/param norm = 7.6100e-01, time/batch = 0.6741s	
298/33450 (epoch 0.445), train_loss = 2.95170467, grad/param norm = 5.8678e-01, time/batch = 0.6731s	
299/33450 (epoch 0.447), train_loss = 2.89792224, grad/param norm = 3.8593e-01, time/batch = 0.7161s	
300/33450 (epoch 0.448), train_loss = 2.79346243, grad/param norm = 6.7391e-01, time/batch = 0.6951s	
301/33450 (epoch 0.450), train_loss = 2.88698149, grad/param norm = 1.0577e+00, time/batch = 0.6783s	
302/33450 (epoch 0.451), train_loss = 2.96996073, grad/param norm = 7.4117e-01, time/batch = 0.6750s	
303/33450 (epoch 0.453), train_loss = 2.83618813, grad/param norm = 4.3130e-01, time/batch = 0.6751s	
304/33450 (epoch 0.454), train_loss = 2.75022001, grad/param norm = 5.9145e-01, time/batch = 0.6756s	
305/33450 (epoch 0.456), train_loss = 2.91156871, grad/param norm = 6.7216e-01, time/batch = 0.6732s	
306/33450 (epoch 0.457), train_loss = 2.88371018, grad/param norm = 5.2023e-01, time/batch = 0.6743s	
307/33450 (epoch 0.459), train_loss = 2.93617743, grad/param norm = 4.4125e-01, time/batch = 0.6783s	
308/33450 (epoch 0.460), train_loss = 2.90062145, grad/param norm = 4.7529e-01, time/batch = 0.6868s	
309/33450 (epoch 0.462), train_loss = 2.87150362, grad/param norm = 4.2326e-01, time/batch = 0.6815s	
310/33450 (epoch 0.463), train_loss = 2.77043794, grad/param norm = 4.9462e-01, time/batch = 0.6740s	
311/33450 (epoch 0.465), train_loss = 2.89028034, grad/param norm = 4.4931e-01, time/batch = 0.6762s	
312/33450 (epoch 0.466), train_loss = 2.77842669, grad/param norm = 4.1388e-01, time/batch = 0.6742s	
313/33450 (epoch 0.468), train_loss = 2.95552120, grad/param norm = 6.5148e-01, time/batch = 0.6877s	
314/33450 (epoch 0.469), train_loss = 2.92606187, grad/param norm = 1.0791e+00, time/batch = 0.7183s	
315/33450 (epoch 0.471), train_loss = 2.78963981, grad/param norm = 5.7028e-01, time/batch = 0.6755s	
316/33450 (epoch 0.472), train_loss = 2.86295051, grad/param norm = 8.9501e-01, time/batch = 0.6730s	
317/33450 (epoch 0.474), train_loss = 3.06310700, grad/param norm = 1.1354e+00, time/batch = 0.6747s	
318/33450 (epoch 0.475), train_loss = 2.90201713, grad/param norm = 7.9026e-01, time/batch = 0.6726s	
319/33450 (epoch 0.477), train_loss = 2.76931198, grad/param norm = 4.1625e-01, time/batch = 0.6802s	
320/33450 (epoch 0.478), train_loss = 2.84044065, grad/param norm = 4.7035e-01, time/batch = 0.6912s	
321/33450 (epoch 0.480), train_loss = 2.85562214, grad/param norm = 4.1674e-01, time/batch = 0.6813s	
322/33450 (epoch 0.481), train_loss = 2.71562944, grad/param norm = 4.0680e-01, time/batch = 0.6730s	
323/33450 (epoch 0.483), train_loss = 2.73700824, grad/param norm = 4.3799e-01, time/batch = 0.6720s	
324/33450 (epoch 0.484), train_loss = 2.93019556, grad/param norm = 4.1653e-01, time/batch = 0.6720s	
325/33450 (epoch 0.486), train_loss = 2.87827799, grad/param norm = 4.4435e-01, time/batch = 0.6840s	
326/33450 (epoch 0.487), train_loss = 2.62684767, grad/param norm = 3.4815e-01, time/batch = 0.6851s	
327/33450 (epoch 0.489), train_loss = 2.73339314, grad/param norm = 4.3157e-01, time/batch = 0.6863s	
328/33450 (epoch 0.490), train_loss = 2.76071832, grad/param norm = 4.9203e-01, time/batch = 0.7042s	
329/33450 (epoch 0.492), train_loss = 2.80533738, grad/param norm = 4.7897e-01, time/batch = 0.7031s	
330/33450 (epoch 0.493), train_loss = 2.83696739, grad/param norm = 4.6489e-01, time/batch = 0.6895s	
331/33450 (epoch 0.495), train_loss = 2.88135472, grad/param norm = 4.2302e-01, time/batch = 0.6746s	
332/33450 (epoch 0.496), train_loss = 2.83596285, grad/param norm = 2.9841e-01, time/batch = 0.6720s	
333/33450 (epoch 0.498), train_loss = 2.73914770, grad/param norm = 3.6601e-01, time/batch = 0.6708s	
334/33450 (epoch 0.499), train_loss = 2.82375650, grad/param norm = 2.7164e-01, time/batch = 0.6705s	
335/33450 (epoch 0.501), train_loss = 2.87007120, grad/param norm = 4.2647e-01, time/batch = 0.6920s	
336/33450 (epoch 0.502), train_loss = 2.91342785, grad/param norm = 5.5306e-01, time/batch = 0.6913s	
337/33450 (epoch 0.504), train_loss = 2.82593855, grad/param norm = 5.6806e-01, time/batch = 0.6984s	
338/33450 (epoch 0.505), train_loss = 2.83156293, grad/param norm = 5.1456e-01, time/batch = 0.7049s	
339/33450 (epoch 0.507), train_loss = 2.89782492, grad/param norm = 5.4543e-01, time/batch = 0.6743s	
340/33450 (epoch 0.508), train_loss = 2.76841517, grad/param norm = 5.7110e-01, time/batch = 0.6756s	
341/33450 (epoch 0.510), train_loss = 2.74250630, grad/param norm = 7.8417e-01, time/batch = 0.6778s	
342/33450 (epoch 0.511), train_loss = 2.88760914, grad/param norm = 9.4235e-01, time/batch = 0.6754s	
343/33450 (epoch 0.513), train_loss = 2.85821131, grad/param norm = 6.8808e-01, time/batch = 0.6742s	
344/33450 (epoch 0.514), train_loss = 2.80225589, grad/param norm = 3.7922e-01, time/batch = 0.6736s	
345/33450 (epoch 0.516), train_loss = 2.87433546, grad/param norm = 5.0112e-01, time/batch = 0.6811s	
346/33450 (epoch 0.517), train_loss = 2.73179998, grad/param norm = 5.7095e-01, time/batch = 0.6811s	
347/33450 (epoch 0.519), train_loss = 2.70724847, grad/param norm = 5.3863e-01, time/batch = 0.6744s	
348/33450 (epoch 0.520), train_loss = 2.81642515, grad/param norm = 3.4985e-01, time/batch = 0.6774s	
349/33450 (epoch 0.522), train_loss = 2.73914124, grad/param norm = 4.4096e-01, time/batch = 0.6739s	
350/33450 (epoch 0.523), train_loss = 2.81916566, grad/param norm = 6.4982e-01, time/batch = 0.6843s	
351/33450 (epoch 0.525), train_loss = 2.80901575, grad/param norm = 9.7627e-01, time/batch = 0.6764s	
352/33450 (epoch 0.526), train_loss = 2.81054039, grad/param norm = 8.8436e-01, time/batch = 0.6786s	
353/33450 (epoch 0.528), train_loss = 2.83902661, grad/param norm = 5.9694e-01, time/batch = 0.6761s	
354/33450 (epoch 0.529), train_loss = 2.90892830, grad/param norm = 3.7120e-01, time/batch = 0.6763s	
355/33450 (epoch 0.531), train_loss = 2.79226205, grad/param norm = 3.9244e-01, time/batch = 0.6753s	
356/33450 (epoch 0.532), train_loss = 2.69549476, grad/param norm = 4.1184e-01, time/batch = 0.6810s	
357/33450 (epoch 0.534), train_loss = 2.74120723, grad/param norm = 4.2519e-01, time/batch = 0.7030s	
358/33450 (epoch 0.535), train_loss = 2.76583856, grad/param norm = 5.0336e-01, time/batch = 0.7136s	
359/33450 (epoch 0.537), train_loss = 2.66012158, grad/param norm = 5.9136e-01, time/batch = 0.6850s	
360/33450 (epoch 0.538), train_loss = 2.64371145, grad/param norm = 5.9907e-01, time/batch = 0.6764s	
361/33450 (epoch 0.540), train_loss = 2.79134532, grad/param norm = 4.5099e-01, time/batch = 0.6797s	
362/33450 (epoch 0.541), train_loss = 2.77498948, grad/param norm = 3.7559e-01, time/batch = 0.6740s	
363/33450 (epoch 0.543), train_loss = 2.55521959, grad/param norm = 4.7100e-01, time/batch = 0.6762s	
364/33450 (epoch 0.544), train_loss = 2.74158049, grad/param norm = 6.5876e-01, time/batch = 0.6855s	
365/33450 (epoch 0.546), train_loss = 2.62035394, grad/param norm = 5.9351e-01, time/batch = 0.7008s	
366/33450 (epoch 0.547), train_loss = 2.72475784, grad/param norm = 5.9069e-01, time/batch = 0.6965s	
367/33450 (epoch 0.549), train_loss = 2.82918622, grad/param norm = 4.9871e-01, time/batch = 0.7101s	
368/33450 (epoch 0.550), train_loss = 2.68922052, grad/param norm = 4.0056e-01, time/batch = 0.6980s	
369/33450 (epoch 0.552), train_loss = 2.82102723, grad/param norm = 3.8219e-01, time/batch = 0.6884s	
370/33450 (epoch 0.553), train_loss = 2.85169097, grad/param norm = 3.4610e-01, time/batch = 0.6853s	
371/33450 (epoch 0.555), train_loss = 2.60788609, grad/param norm = 3.7366e-01, time/batch = 0.6991s	
372/33450 (epoch 0.556), train_loss = 2.69128986, grad/param norm = 4.0624e-01, time/batch = 0.7202s	
373/33450 (epoch 0.558), train_loss = 2.80615130, grad/param norm = 3.7000e-01, time/batch = 0.6989s	
374/33450 (epoch 0.559), train_loss = 2.74819463, grad/param norm = 5.3811e-01, time/batch = 0.6879s	
375/33450 (epoch 0.561), train_loss = 2.84451050, grad/param norm = 5.3360e-01, time/batch = 0.6859s	
376/33450 (epoch 0.562), train_loss = 2.80393216, grad/param norm = 3.5759e-01, time/batch = 0.6887s	
377/33450 (epoch 0.564), train_loss = 2.70454813, grad/param norm = 3.5496e-01, time/batch = 0.6873s	
378/33450 (epoch 0.565), train_loss = 2.80806867, grad/param norm = 2.8438e-01, time/batch = 0.6985s	
379/33450 (epoch 0.567), train_loss = 2.67559322, grad/param norm = 3.4240e-01, time/batch = 0.6937s	
380/33450 (epoch 0.568), train_loss = 2.70439299, grad/param norm = 3.8527e-01, time/batch = 0.6872s	
381/33450 (epoch 0.570), train_loss = 2.83016955, grad/param norm = 5.3175e-01, time/batch = 0.6816s	
382/33450 (epoch 0.571), train_loss = 2.89562482, grad/param norm = 8.2451e-01, time/batch = 0.6881s	
383/33450 (epoch 0.572), train_loss = 2.68636692, grad/param norm = 6.0234e-01, time/batch = 0.6755s	
384/33450 (epoch 0.574), train_loss = 2.57446930, grad/param norm = 3.1733e-01, time/batch = 0.6781s	
385/33450 (epoch 0.575), train_loss = 2.71215777, grad/param norm = 4.8584e-01, time/batch = 0.6918s	
386/33450 (epoch 0.577), train_loss = 2.78340737, grad/param norm = 6.6966e-01, time/batch = 0.6940s	
387/33450 (epoch 0.578), train_loss = 2.68329573, grad/param norm = 6.1352e-01, time/batch = 0.6868s	
388/33450 (epoch 0.580), train_loss = 2.66664922, grad/param norm = 5.2559e-01, time/batch = 0.6837s	
389/33450 (epoch 0.581), train_loss = 2.80595399, grad/param norm = 5.3664e-01, time/batch = 0.6719s	
390/33450 (epoch 0.583), train_loss = 2.67657740, grad/param norm = 5.2812e-01, time/batch = 0.6728s	
391/33450 (epoch 0.584), train_loss = 2.67172013, grad/param norm = 5.3452e-01, time/batch = 0.6729s	
392/33450 (epoch 0.586), train_loss = 2.63270153, grad/param norm = 4.7822e-01, time/batch = 0.6722s	
393/33450 (epoch 0.587), train_loss = 2.75979035, grad/param norm = 4.1150e-01, time/batch = 0.6753s	
394/33450 (epoch 0.589), train_loss = 2.69236395, grad/param norm = 3.2964e-01, time/batch = 0.6743s	
395/33450 (epoch 0.590), train_loss = 2.79781725, grad/param norm = 3.7808e-01, time/batch = 0.6730s	
396/33450 (epoch 0.592), train_loss = 2.71631174, grad/param norm = 3.6423e-01, time/batch = 0.6726s	
397/33450 (epoch 0.593), train_loss = 2.79517802, grad/param norm = 4.2958e-01, time/batch = 0.6720s	
398/33450 (epoch 0.595), train_loss = 2.74694592, grad/param norm = 5.4369e-01, time/batch = 0.6715s	
399/33450 (epoch 0.596), train_loss = 2.78261859, grad/param norm = 6.0405e-01, time/batch = 0.6735s	
400/33450 (epoch 0.598), train_loss = 2.72487576, grad/param norm = 6.5860e-01, time/batch = 0.6710s	
401/33450 (epoch 0.599), train_loss = 2.78047244, grad/param norm = 4.9373e-01, time/batch = 0.6728s	
402/33450 (epoch 0.601), train_loss = 2.76725701, grad/param norm = 4.6094e-01, time/batch = 0.6721s	
403/33450 (epoch 0.602), train_loss = 2.80028420, grad/param norm = 5.4894e-01, time/batch = 0.6769s	
404/33450 (epoch 0.604), train_loss = 2.59398592, grad/param norm = 3.6439e-01, time/batch = 0.6713s	
405/33450 (epoch 0.605), train_loss = 2.67450500, grad/param norm = 5.2857e-01, time/batch = 0.6729s	
406/33450 (epoch 0.607), train_loss = 2.68884751, grad/param norm = 6.2300e-01, time/batch = 0.6722s	
407/33450 (epoch 0.608), train_loss = 2.63920963, grad/param norm = 4.6354e-01, time/batch = 0.6712s	
408/33450 (epoch 0.610), train_loss = 2.68523475, grad/param norm = 4.8263e-01, time/batch = 0.6736s	
409/33450 (epoch 0.611), train_loss = 2.72276903, grad/param norm = 5.2650e-01, time/batch = 0.6789s	
410/33450 (epoch 0.613), train_loss = 2.81635957, grad/param norm = 5.1647e-01, time/batch = 0.6728s	
411/33450 (epoch 0.614), train_loss = 2.76189201, grad/param norm = 4.5227e-01, time/batch = 0.6726s	
412/33450 (epoch 0.616), train_loss = 2.54145182, grad/param norm = 3.2816e-01, time/batch = 0.6738s	
413/33450 (epoch 0.617), train_loss = 2.63698897, grad/param norm = 3.5992e-01, time/batch = 0.6740s	
414/33450 (epoch 0.619), train_loss = 2.76867936, grad/param norm = 3.8314e-01, time/batch = 0.6752s	
415/33450 (epoch 0.620), train_loss = 2.59725555, grad/param norm = 3.8536e-01, time/batch = 0.6859s	
416/33450 (epoch 0.622), train_loss = 2.65423955, grad/param norm = 4.6846e-01, time/batch = 0.7180s	
417/33450 (epoch 0.623), train_loss = 2.72830840, grad/param norm = 4.7283e-01, time/batch = 0.6835s	
418/33450 (epoch 0.625), train_loss = 2.82259506, grad/param norm = 3.5229e-01, time/batch = 0.6762s	
419/33450 (epoch 0.626), train_loss = 2.60680749, grad/param norm = 3.9328e-01, time/batch = 0.6735s	
420/33450 (epoch 0.628), train_loss = 2.61655294, grad/param norm = 4.3608e-01, time/batch = 0.6732s	
421/33450 (epoch 0.629), train_loss = 2.79639829, grad/param norm = 4.1594e-01, time/batch = 0.6744s	
422/33450 (epoch 0.631), train_loss = 2.82803116, grad/param norm = 5.4126e-01, time/batch = 0.6790s	
423/33450 (epoch 0.632), train_loss = 2.71570553, grad/param norm = 7.1308e-01, time/batch = 0.6876s	
424/33450 (epoch 0.634), train_loss = 2.75316639, grad/param norm = 7.7888e-01, time/batch = 0.6997s	
425/33450 (epoch 0.635), train_loss = 2.76778303, grad/param norm = 6.2676e-01, time/batch = 0.7171s	
426/33450 (epoch 0.637), train_loss = 2.75001178, grad/param norm = 3.7007e-01, time/batch = 0.6853s	
427/33450 (epoch 0.638), train_loss = 2.66388772, grad/param norm = 3.1844e-01, time/batch = 0.6754s	
428/33450 (epoch 0.640), train_loss = 2.70432889, grad/param norm = 3.0377e-01, time/batch = 0.6737s	
429/33450 (epoch 0.641), train_loss = 2.67573095, grad/param norm = 4.0179e-01, time/batch = 0.6726s	
430/33450 (epoch 0.643), train_loss = 2.64766384, grad/param norm = 4.1214e-01, time/batch = 0.7013s	
431/33450 (epoch 0.644), train_loss = 2.70812052, grad/param norm = 4.3163e-01, time/batch = 0.7160s	
432/33450 (epoch 0.646), train_loss = 2.68040823, grad/param norm = 4.9974e-01, time/batch = 0.6750s	
433/33450 (epoch 0.647), train_loss = 2.82479471, grad/param norm = 6.5254e-01, time/batch = 0.6825s	
434/33450 (epoch 0.649), train_loss = 2.65348203, grad/param norm = 5.0735e-01, time/batch = 0.6768s	
435/33450 (epoch 0.650), train_loss = 2.70140760, grad/param norm = 4.3813e-01, time/batch = 0.6727s	
436/33450 (epoch 0.652), train_loss = 2.49552649, grad/param norm = 4.6455e-01, time/batch = 0.6721s	
437/33450 (epoch 0.653), train_loss = 2.67766931, grad/param norm = 4.3956e-01, time/batch = 0.6723s	
438/33450 (epoch 0.655), train_loss = 2.72913517, grad/param norm = 6.6462e-01, time/batch = 0.6840s	
439/33450 (epoch 0.656), train_loss = 2.61758748, grad/param norm = 8.0820e-01, time/batch = 0.6790s	
440/33450 (epoch 0.658), train_loss = 2.67839664, grad/param norm = 6.0713e-01, time/batch = 0.6806s	
441/33450 (epoch 0.659), train_loss = 2.69240283, grad/param norm = 4.1194e-01, time/batch = 0.6746s	
442/33450 (epoch 0.661), train_loss = 2.79119247, grad/param norm = 3.3691e-01, time/batch = 0.6731s	
443/33450 (epoch 0.662), train_loss = 2.57213062, grad/param norm = 3.3608e-01, time/batch = 0.6762s	
444/33450 (epoch 0.664), train_loss = 2.63961731, grad/param norm = 3.2246e-01, time/batch = 0.6793s	
445/33450 (epoch 0.665), train_loss = 2.63001021, grad/param norm = 3.7913e-01, time/batch = 0.7255s	
446/33450 (epoch 0.667), train_loss = 2.67913183, grad/param norm = 3.4197e-01, time/batch = 0.7166s	
447/33450 (epoch 0.668), train_loss = 2.71288549, grad/param norm = 4.6105e-01, time/batch = 0.7117s	
448/33450 (epoch 0.670), train_loss = 2.65122537, grad/param norm = 4.6208e-01, time/batch = 0.7058s	
449/33450 (epoch 0.671), train_loss = 2.66255588, grad/param norm = 3.7856e-01, time/batch = 0.6994s	
450/33450 (epoch 0.673), train_loss = 2.63809512, grad/param norm = 3.5782e-01, time/batch = 0.6920s	
451/33450 (epoch 0.674), train_loss = 2.74008106, grad/param norm = 3.5744e-01, time/batch = 0.6926s	
452/33450 (epoch 0.676), train_loss = 2.71650182, grad/param norm = 4.3682e-01, time/batch = 0.6940s	
453/33450 (epoch 0.677), train_loss = 2.65212201, grad/param norm = 3.3558e-01, time/batch = 0.6851s	
454/33450 (epoch 0.679), train_loss = 2.64133713, grad/param norm = 3.5500e-01, time/batch = 0.7022s	
455/33450 (epoch 0.680), train_loss = 2.69852706, grad/param norm = 3.7351e-01, time/batch = 0.7201s	
456/33450 (epoch 0.682), train_loss = 2.55726845, grad/param norm = 3.8145e-01, time/batch = 0.6986s	
457/33450 (epoch 0.683), train_loss = 2.80538315, grad/param norm = 5.3311e-01, time/batch = 0.6934s	
458/33450 (epoch 0.685), train_loss = 2.80344409, grad/param norm = 5.2726e-01, time/batch = 0.6844s	
459/33450 (epoch 0.686), train_loss = 2.75507896, grad/param norm = 3.6969e-01, time/batch = 0.6980s	
460/33450 (epoch 0.688), train_loss = 2.81636366, grad/param norm = 3.4934e-01, time/batch = 0.6877s	
461/33450 (epoch 0.689), train_loss = 2.61235072, grad/param norm = 3.0666e-01, time/batch = 0.6880s	
462/33450 (epoch 0.691), train_loss = 2.68796000, grad/param norm = 3.4100e-01, time/batch = 0.6967s	
463/33450 (epoch 0.692), train_loss = 2.74232084, grad/param norm = 3.4616e-01, time/batch = 0.6883s	
464/33450 (epoch 0.694), train_loss = 2.54950074, grad/param norm = 3.1489e-01, time/batch = 0.6881s	
465/33450 (epoch 0.695), train_loss = 2.77887808, grad/param norm = 3.5208e-01, time/batch = 0.6863s	
466/33450 (epoch 0.697), train_loss = 2.68710488, grad/param norm = 3.7905e-01, time/batch = 0.6899s	
467/33450 (epoch 0.698), train_loss = 2.62108243, grad/param norm = 5.3312e-01, time/batch = 0.6853s	
468/33450 (epoch 0.700), train_loss = 2.82776575, grad/param norm = 4.6568e-01, time/batch = 0.6834s	
469/33450 (epoch 0.701), train_loss = 2.65885254, grad/param norm = 6.3054e-01, time/batch = 0.7168s	
470/33450 (epoch 0.703), train_loss = 2.77561640, grad/param norm = 5.8383e-01, time/batch = 0.7084s	
471/33450 (epoch 0.704), train_loss = 2.64625540, grad/param norm = 5.1827e-01, time/batch = 0.6983s	
472/33450 (epoch 0.706), train_loss = 2.64178367, grad/param norm = 4.2181e-01, time/batch = 0.6780s	
473/33450 (epoch 0.707), train_loss = 2.57496239, grad/param norm = 4.5952e-01, time/batch = 0.6836s	
474/33450 (epoch 0.709), train_loss = 2.68644128, grad/param norm = 3.9243e-01, time/batch = 0.6968s	
475/33450 (epoch 0.710), train_loss = 2.63732232, grad/param norm = 3.1206e-01, time/batch = 0.6835s	
476/33450 (epoch 0.712), train_loss = 2.55026414, grad/param norm = 4.5514e-01, time/batch = 0.6824s	
477/33450 (epoch 0.713), train_loss = 2.70377915, grad/param norm = 4.5241e-01, time/batch = 0.6915s	
478/33450 (epoch 0.714), train_loss = 2.68152843, grad/param norm = 3.8970e-01, time/batch = 0.6912s	
479/33450 (epoch 0.716), train_loss = 2.58511348, grad/param norm = 3.5412e-01, time/batch = 0.6911s	
480/33450 (epoch 0.717), train_loss = 2.59103270, grad/param norm = 4.1078e-01, time/batch = 0.6927s	
481/33450 (epoch 0.719), train_loss = 2.70304875, grad/param norm = 5.7058e-01, time/batch = 0.6956s	
482/33450 (epoch 0.720), train_loss = 2.58243272, grad/param norm = 4.7727e-01, time/batch = 0.6904s	
483/33450 (epoch 0.722), train_loss = 2.47173409, grad/param norm = 4.6105e-01, time/batch = 0.7004s	
484/33450 (epoch 0.723), train_loss = 2.52103053, grad/param norm = 3.7344e-01, time/batch = 0.7188s	
485/33450 (epoch 0.725), train_loss = 2.54282229, grad/param norm = 3.5090e-01, time/batch = 0.6862s	
486/33450 (epoch 0.726), train_loss = 2.45039274, grad/param norm = 2.7756e-01, time/batch = 0.6804s	
487/33450 (epoch 0.728), train_loss = 2.65555032, grad/param norm = 3.6227e-01, time/batch = 0.6844s	
488/33450 (epoch 0.729), train_loss = 2.60985762, grad/param norm = 3.5615e-01, time/batch = 0.6786s	
489/33450 (epoch 0.731), train_loss = 2.79603667, grad/param norm = 4.7831e-01, time/batch = 0.6772s	
490/33450 (epoch 0.732), train_loss = 2.69856798, grad/param norm = 3.5305e-01, time/batch = 0.6872s	
491/33450 (epoch 0.734), train_loss = 2.66879010, grad/param norm = 3.5460e-01, time/batch = 0.6948s	
492/33450 (epoch 0.735), train_loss = 2.76149087, grad/param norm = 4.0038e-01, time/batch = 0.6839s	
493/33450 (epoch 0.737), train_loss = 2.73066918, grad/param norm = 4.1824e-01, time/batch = 0.6895s	
494/33450 (epoch 0.738), train_loss = 2.75940324, grad/param norm = 3.7426e-01, time/batch = 0.6892s	
495/33450 (epoch 0.740), train_loss = 2.62965263, grad/param norm = 3.7941e-01, time/batch = 0.6879s	
496/33450 (epoch 0.741), train_loss = 2.64056082, grad/param norm = 3.0394e-01, time/batch = 0.6791s	
497/33450 (epoch 0.743), train_loss = 2.70884750, grad/param norm = 2.6825e-01, time/batch = 0.6863s	
498/33450 (epoch 0.744), train_loss = 2.68031362, grad/param norm = 3.5457e-01, time/batch = 0.7123s	
499/33450 (epoch 0.746), train_loss = 2.60015359, grad/param norm = 3.7979e-01, time/batch = 0.6966s	
500/33450 (epoch 0.747), train_loss = 2.70683723, grad/param norm = 3.8401e-01, time/batch = 0.6755s	
501/33450 (epoch 0.749), train_loss = 2.62067791, grad/param norm = 3.3568e-01, time/batch = 0.6750s	
502/33450 (epoch 0.750), train_loss = 2.54793027, grad/param norm = 3.6795e-01, time/batch = 0.6740s	
503/33450 (epoch 0.752), train_loss = 2.68080993, grad/param norm = 4.1432e-01, time/batch = 0.6742s	
504/33450 (epoch 0.753), train_loss = 2.63580589, grad/param norm = 4.1360e-01, time/batch = 0.6774s	
505/33450 (epoch 0.755), train_loss = 2.55293761, grad/param norm = 3.6307e-01, time/batch = 0.6834s	
506/33450 (epoch 0.756), train_loss = 2.71671290, grad/param norm = 4.4333e-01, time/batch = 0.6877s	
507/33450 (epoch 0.758), train_loss = 2.67887420, grad/param norm = 4.2090e-01, time/batch = 0.6885s	
508/33450 (epoch 0.759), train_loss = 2.61866356, grad/param norm = 5.0825e-01, time/batch = 0.6851s	
509/33450 (epoch 0.761), train_loss = 2.77795653, grad/param norm = 5.5996e-01, time/batch = 0.6994s	
510/33450 (epoch 0.762), train_loss = 2.74814436, grad/param norm = 5.1177e-01, time/batch = 0.6962s	
511/33450 (epoch 0.764), train_loss = 2.60318577, grad/param norm = 5.1965e-01, time/batch = 0.6962s	
512/33450 (epoch 0.765), train_loss = 2.68723303, grad/param norm = 6.0309e-01, time/batch = 0.6871s	
513/33450 (epoch 0.767), train_loss = 2.63198454, grad/param norm = 5.4475e-01, time/batch = 0.6930s	
514/33450 (epoch 0.768), train_loss = 2.43598621, grad/param norm = 2.8707e-01, time/batch = 0.6902s	
515/33450 (epoch 0.770), train_loss = 2.67165623, grad/param norm = 3.5456e-01, time/batch = 0.6928s	
516/33450 (epoch 0.771), train_loss = 2.77910928, grad/param norm = 2.9846e-01, time/batch = 0.6892s	
517/33450 (epoch 0.773), train_loss = 2.59208012, grad/param norm = 3.5768e-01, time/batch = 0.6999s	
518/33450 (epoch 0.774), train_loss = 2.62547789, grad/param norm = 3.6053e-01, time/batch = 0.7019s	
519/33450 (epoch 0.776), train_loss = 2.51327420, grad/param norm = 3.1440e-01, time/batch = 0.7032s	
520/33450 (epoch 0.777), train_loss = 2.59015482, grad/param norm = 4.6907e-01, time/batch = 0.7019s	
521/33450 (epoch 0.779), train_loss = 2.59089322, grad/param norm = 4.7602e-01, time/batch = 0.7052s	
522/33450 (epoch 0.780), train_loss = 2.65814958, grad/param norm = 4.6614e-01, time/batch = 0.6988s	
523/33450 (epoch 0.782), train_loss = 2.71140290, grad/param norm = 5.2879e-01, time/batch = 0.7082s	
524/33450 (epoch 0.783), train_loss = 2.68474897, grad/param norm = 5.1901e-01, time/batch = 0.6938s	
525/33450 (epoch 0.785), train_loss = 2.67572894, grad/param norm = 3.8916e-01, time/batch = 0.6884s	
526/33450 (epoch 0.786), train_loss = 2.60220947, grad/param norm = 3.7269e-01, time/batch = 0.6934s	
527/33450 (epoch 0.788), train_loss = 2.64358219, grad/param norm = 4.3921e-01, time/batch = 0.7048s	
528/33450 (epoch 0.789), train_loss = 2.64332042, grad/param norm = 4.1687e-01, time/batch = 0.6737s	
529/33450 (epoch 0.791), train_loss = 2.44058854, grad/param norm = 3.2188e-01, time/batch = 0.6776s	
530/33450 (epoch 0.792), train_loss = 2.48326622, grad/param norm = 4.1221e-01, time/batch = 0.6749s	
531/33450 (epoch 0.794), train_loss = 2.46640822, grad/param norm = 4.9348e-01, time/batch = 0.6754s	
532/33450 (epoch 0.795), train_loss = 2.67619187, grad/param norm = 4.4182e-01, time/batch = 0.6835s	
533/33450 (epoch 0.797), train_loss = 2.54366275, grad/param norm = 3.2011e-01, time/batch = 0.6996s	
534/33450 (epoch 0.798), train_loss = 2.57862076, grad/param norm = 2.8396e-01, time/batch = 0.6819s	
535/33450 (epoch 0.800), train_loss = 2.66072569, grad/param norm = 3.2118e-01, time/batch = 0.7020s	
536/33450 (epoch 0.801), train_loss = 2.71297277, grad/param norm = 2.8420e-01, time/batch = 0.6923s	
537/33450 (epoch 0.803), train_loss = 2.62403881, grad/param norm = 3.7545e-01, time/batch = 0.6916s	
538/33450 (epoch 0.804), train_loss = 2.50578006, grad/param norm = 3.5220e-01, time/batch = 0.6900s	
539/33450 (epoch 0.806), train_loss = 2.67794922, grad/param norm = 3.3874e-01, time/batch = 0.6794s	
540/33450 (epoch 0.807), train_loss = 2.52038532, grad/param norm = 3.5583e-01, time/batch = 0.6851s	
541/33450 (epoch 0.809), train_loss = 2.59646100, grad/param norm = 3.3680e-01, time/batch = 0.7012s	
542/33450 (epoch 0.810), train_loss = 2.56860050, grad/param norm = 3.5766e-01, time/batch = 0.7002s	
543/33450 (epoch 0.812), train_loss = 2.54762376, grad/param norm = 3.8919e-01, time/batch = 0.6770s	
544/33450 (epoch 0.813), train_loss = 2.50724597, grad/param norm = 3.0886e-01, time/batch = 0.6764s	
545/33450 (epoch 0.815), train_loss = 2.73115412, grad/param norm = 4.3526e-01, time/batch = 0.6840s	
546/33450 (epoch 0.816), train_loss = 2.58585259, grad/param norm = 3.9697e-01, time/batch = 0.6909s	
547/33450 (epoch 0.818), train_loss = 2.33816255, grad/param norm = 3.3611e-01, time/batch = 0.6873s	
548/33450 (epoch 0.819), train_loss = 2.59413129, grad/param norm = 3.8230e-01, time/batch = 0.7035s	
549/33450 (epoch 0.821), train_loss = 2.56327551, grad/param norm = 3.8938e-01, time/batch = 0.6951s	
550/33450 (epoch 0.822), train_loss = 2.62178059, grad/param norm = 3.9835e-01, time/batch = 0.7003s	
551/33450 (epoch 0.824), train_loss = 2.61280851, grad/param norm = 5.3321e-01, time/batch = 0.6982s	
552/33450 (epoch 0.825), train_loss = 2.73317222, grad/param norm = 6.2500e-01, time/batch = 0.6874s	
553/33450 (epoch 0.827), train_loss = 2.61790518, grad/param norm = 5.1857e-01, time/batch = 0.6896s	
554/33450 (epoch 0.828), train_loss = 2.36390658, grad/param norm = 3.0859e-01, time/batch = 0.6914s	
555/33450 (epoch 0.830), train_loss = 2.46090579, grad/param norm = 3.3567e-01, time/batch = 0.6974s	
556/33450 (epoch 0.831), train_loss = 2.55626142, grad/param norm = 3.2755e-01, time/batch = 0.7188s	
557/33450 (epoch 0.833), train_loss = 2.53337122, grad/param norm = 3.9389e-01, time/batch = 0.7037s	
558/33450 (epoch 0.834), train_loss = 2.47146446, grad/param norm = 3.4245e-01, time/batch = 0.7001s	
559/33450 (epoch 0.836), train_loss = 2.40621576, grad/param norm = 3.5132e-01, time/batch = 0.6910s	
560/33450 (epoch 0.837), train_loss = 2.62968190, grad/param norm = 3.5240e-01, time/batch = 0.6859s	
561/33450 (epoch 0.839), train_loss = 2.65086037, grad/param norm = 3.4064e-01, time/batch = 0.6871s	
562/33450 (epoch 0.840), train_loss = 2.58345686, grad/param norm = 4.8778e-01, time/batch = 0.6905s	
563/33450 (epoch 0.842), train_loss = 2.53681269, grad/param norm = 4.1995e-01, time/batch = 0.6840s	
564/33450 (epoch 0.843), train_loss = 2.44627100, grad/param norm = 4.4331e-01, time/batch = 0.6829s	
565/33450 (epoch 0.845), train_loss = 2.45784243, grad/param norm = 4.0117e-01, time/batch = 0.6890s	
566/33450 (epoch 0.846), train_loss = 2.69912678, grad/param norm = 3.5768e-01, time/batch = 0.6924s	
567/33450 (epoch 0.848), train_loss = 2.55016964, grad/param norm = 3.2426e-01, time/batch = 0.6824s	
568/33450 (epoch 0.849), train_loss = 2.60140032, grad/param norm = 3.3657e-01, time/batch = 0.6747s	
569/33450 (epoch 0.851), train_loss = 2.54449122, grad/param norm = 3.4193e-01, time/batch = 0.6772s	
570/33450 (epoch 0.852), train_loss = 2.55671898, grad/param norm = 3.6025e-01, time/batch = 0.6751s	
571/33450 (epoch 0.854), train_loss = 2.69114180, grad/param norm = 4.4330e-01, time/batch = 0.6770s	
572/33450 (epoch 0.855), train_loss = 2.58463021, grad/param norm = 3.7275e-01, time/batch = 0.6781s	
573/33450 (epoch 0.857), train_loss = 2.49467417, grad/param norm = 2.9283e-01, time/batch = 0.6760s	
574/33450 (epoch 0.858), train_loss = 2.77064724, grad/param norm = 3.6506e-01, time/batch = 0.6755s	
575/33450 (epoch 0.859), train_loss = 2.65320917, grad/param norm = 4.1982e-01, time/batch = 0.6761s	
576/33450 (epoch 0.861), train_loss = 2.70419686, grad/param norm = 3.8555e-01, time/batch = 0.6828s	
577/33450 (epoch 0.862), train_loss = 2.60539893, grad/param norm = 4.4042e-01, time/batch = 0.6794s	
578/33450 (epoch 0.864), train_loss = 2.60119795, grad/param norm = 4.3606e-01, time/batch = 0.6772s	
579/33450 (epoch 0.865), train_loss = 2.49127842, grad/param norm = 3.6790e-01, time/batch = 0.6805s	
580/33450 (epoch 0.867), train_loss = 2.59206969, grad/param norm = 3.1687e-01, time/batch = 0.6806s	
581/33450 (epoch 0.868), train_loss = 2.60332381, grad/param norm = 3.8501e-01, time/batch = 0.6838s	
582/33450 (epoch 0.870), train_loss = 2.58121712, grad/param norm = 3.3724e-01, time/batch = 0.6891s	
583/33450 (epoch 0.871), train_loss = 2.62576144, grad/param norm = 3.1324e-01, time/batch = 0.6736s	
584/33450 (epoch 0.873), train_loss = 2.52370850, grad/param norm = 3.0088e-01, time/batch = 0.6736s	
585/33450 (epoch 0.874), train_loss = 2.54162669, grad/param norm = 3.1557e-01, time/batch = 0.6724s	
586/33450 (epoch 0.876), train_loss = 2.58156930, grad/param norm = 3.1516e-01, time/batch = 0.6732s	
587/33450 (epoch 0.877), train_loss = 2.49132232, grad/param norm = 2.9933e-01, time/batch = 0.6747s	
588/33450 (epoch 0.879), train_loss = 2.48114126, grad/param norm = 2.8074e-01, time/batch = 0.6738s	
589/33450 (epoch 0.880), train_loss = 2.50516288, grad/param norm = 3.4698e-01, time/batch = 0.6757s	
590/33450 (epoch 0.882), train_loss = 2.49833916, grad/param norm = 3.7432e-01, time/batch = 0.6790s	
591/33450 (epoch 0.883), train_loss = 2.53905751, grad/param norm = 4.8527e-01, time/batch = 0.6751s	
592/33450 (epoch 0.885), train_loss = 2.50115321, grad/param norm = 4.9588e-01, time/batch = 0.6917s	
593/33450 (epoch 0.886), train_loss = 2.77114996, grad/param norm = 3.4178e-01, time/batch = 0.6855s	
594/33450 (epoch 0.888), train_loss = 2.56808828, grad/param norm = 3.4263e-01, time/batch = 0.6746s	
595/33450 (epoch 0.889), train_loss = 2.53359216, grad/param norm = 3.5570e-01, time/batch = 0.6734s	
596/33450 (epoch 0.891), train_loss = 2.66336912, grad/param norm = 3.3522e-01, time/batch = 0.6865s	
597/33450 (epoch 0.892), train_loss = 2.54621977, grad/param norm = 2.7730e-01, time/batch = 0.6824s	
598/33450 (epoch 0.894), train_loss = 2.64395308, grad/param norm = 3.5033e-01, time/batch = 0.6891s	
599/33450 (epoch 0.895), train_loss = 2.47677946, grad/param norm = 3.5752e-01, time/batch = 0.6930s	
600/33450 (epoch 0.897), train_loss = 2.45479195, grad/param norm = 3.0669e-01, time/batch = 0.7166s	
601/33450 (epoch 0.898), train_loss = 2.41765860, grad/param norm = 4.4968e-01, time/batch = 0.6777s	
602/33450 (epoch 0.900), train_loss = 2.58752471, grad/param norm = 5.1924e-01, time/batch = 0.6798s	
603/33450 (epoch 0.901), train_loss = 2.62082200, grad/param norm = 4.2313e-01, time/batch = 0.6757s	
604/33450 (epoch 0.903), train_loss = 2.49742978, grad/param norm = 4.7866e-01, time/batch = 0.6743s	
605/33450 (epoch 0.904), train_loss = 2.55959580, grad/param norm = 4.4512e-01, time/batch = 0.6772s	
606/33450 (epoch 0.906), train_loss = 2.53862789, grad/param norm = 4.1173e-01, time/batch = 0.6991s	
607/33450 (epoch 0.907), train_loss = 2.50577810, grad/param norm = 3.4107e-01, time/batch = 0.6730s	
608/33450 (epoch 0.909), train_loss = 2.53259047, grad/param norm = 3.2962e-01, time/batch = 0.6837s	
609/33450 (epoch 0.910), train_loss = 2.56672912, grad/param norm = 4.3765e-01, time/batch = 0.6919s	
610/33450 (epoch 0.912), train_loss = 2.56867320, grad/param norm = 5.0013e-01, time/batch = 0.6976s	
611/33450 (epoch 0.913), train_loss = 2.53709776, grad/param norm = 3.2589e-01, time/batch = 0.6913s	
612/33450 (epoch 0.915), train_loss = 2.58918734, grad/param norm = 2.8782e-01, time/batch = 0.6787s	
613/33450 (epoch 0.916), train_loss = 2.61870878, grad/param norm = 2.5086e-01, time/batch = 0.6760s	
614/33450 (epoch 0.918), train_loss = 2.48730439, grad/param norm = 3.7027e-01, time/batch = 0.7167s	
615/33450 (epoch 0.919), train_loss = 2.63724520, grad/param norm = 3.8183e-01, time/batch = 0.6950s	
616/33450 (epoch 0.921), train_loss = 2.64559957, grad/param norm = 3.4707e-01, time/batch = 0.6768s	
617/33450 (epoch 0.922), train_loss = 2.48534161, grad/param norm = 2.9337e-01, time/batch = 0.6742s	
618/33450 (epoch 0.924), train_loss = 2.63352634, grad/param norm = 2.9293e-01, time/batch = 0.6754s	
619/33450 (epoch 0.925), train_loss = 2.44078324, grad/param norm = 2.9918e-01, time/batch = 0.6765s	
620/33450 (epoch 0.927), train_loss = 2.57849391, grad/param norm = 2.9493e-01, time/batch = 0.6753s	
621/33450 (epoch 0.928), train_loss = 2.45584232, grad/param norm = 3.1332e-01, time/batch = 0.6771s	
622/33450 (epoch 0.930), train_loss = 2.51154771, grad/param norm = 2.9461e-01, time/batch = 0.6765s	
623/33450 (epoch 0.931), train_loss = 2.52306396, grad/param norm = 3.3037e-01, time/batch = 0.6866s	
624/33450 (epoch 0.933), train_loss = 2.45676264, grad/param norm = 3.3148e-01, time/batch = 0.6761s	
625/33450 (epoch 0.934), train_loss = 2.51095751, grad/param norm = 3.5867e-01, time/batch = 0.6739s	
626/33450 (epoch 0.936), train_loss = 2.48557589, grad/param norm = 4.1597e-01, time/batch = 0.6791s	
627/33450 (epoch 0.937), train_loss = 2.43127941, grad/param norm = 3.5281e-01, time/batch = 0.6780s	
628/33450 (epoch 0.939), train_loss = 2.44793757, grad/param norm = 3.6944e-01, time/batch = 0.6885s	
629/33450 (epoch 0.940), train_loss = 2.51394641, grad/param norm = 3.2416e-01, time/batch = 0.7188s	
630/33450 (epoch 0.942), train_loss = 2.61922898, grad/param norm = 2.8764e-01, time/batch = 0.6867s	
631/33450 (epoch 0.943), train_loss = 2.64489616, grad/param norm = 3.3050e-01, time/batch = 0.6866s	
632/33450 (epoch 0.945), train_loss = 2.63918027, grad/param norm = 2.8264e-01, time/batch = 0.6771s	
633/33450 (epoch 0.946), train_loss = 2.68106663, grad/param norm = 4.1071e-01, time/batch = 0.6810s	
634/33450 (epoch 0.948), train_loss = 2.50630659, grad/param norm = 3.8822e-01, time/batch = 0.6750s	
635/33450 (epoch 0.949), train_loss = 2.55200697, grad/param norm = 3.4259e-01, time/batch = 0.6753s	
636/33450 (epoch 0.951), train_loss = 2.55856556, grad/param norm = 3.2075e-01, time/batch = 0.6751s	
637/33450 (epoch 0.952), train_loss = 2.73333128, grad/param norm = 3.3053e-01, time/batch = 0.6768s	
638/33450 (epoch 0.954), train_loss = 2.61575317, grad/param norm = 3.3060e-01, time/batch = 0.6765s	
639/33450 (epoch 0.955), train_loss = 2.60777600, grad/param norm = 3.6104e-01, time/batch = 0.6745s	
640/33450 (epoch 0.957), train_loss = 2.73931147, grad/param norm = 3.6894e-01, time/batch = 0.6828s	
641/33450 (epoch 0.958), train_loss = 2.63020022, grad/param norm = 3.4784e-01, time/batch = 0.6765s	
642/33450 (epoch 0.960), train_loss = 2.59773278, grad/param norm = 2.9844e-01, time/batch = 0.6755s	
643/33450 (epoch 0.961), train_loss = 2.55960804, grad/param norm = 2.6832e-01, time/batch = 0.7067s	
644/33450 (epoch 0.963), train_loss = 2.58945060, grad/param norm = 3.2343e-01, time/batch = 0.6758s	
645/33450 (epoch 0.964), train_loss = 2.49155704, grad/param norm = 3.5493e-01, time/batch = 0.6759s	
646/33450 (epoch 0.966), train_loss = 2.45820855, grad/param norm = 4.1021e-01, time/batch = 0.6767s	
647/33450 (epoch 0.967), train_loss = 2.71676275, grad/param norm = 3.9419e-01, time/batch = 0.6793s	
648/33450 (epoch 0.969), train_loss = 2.44951015, grad/param norm = 3.9385e-01, time/batch = 0.6793s	
649/33450 (epoch 0.970), train_loss = 2.52445285, grad/param norm = 4.0765e-01, time/batch = 0.6771s	
650/33450 (epoch 0.972), train_loss = 2.67995716, grad/param norm = 3.7885e-01, time/batch = 0.6766s	
651/33450 (epoch 0.973), train_loss = 2.53521632, grad/param norm = 3.9286e-01, time/batch = 0.6753s	
652/33450 (epoch 0.975), train_loss = 2.46988629, grad/param norm = 3.1277e-01, time/batch = 0.6754s	
653/33450 (epoch 0.976), train_loss = 2.51020414, grad/param norm = 2.9724e-01, time/batch = 0.6765s	
654/33450 (epoch 0.978), train_loss = 2.38791000, grad/param norm = 2.4036e-01, time/batch = 0.6745s	
655/33450 (epoch 0.979), train_loss = 2.50861385, grad/param norm = 2.6370e-01, time/batch = 0.6796s	
656/33450 (epoch 0.981), train_loss = 2.53599546, grad/param norm = 3.5547e-01, time/batch = 0.6751s	
657/33450 (epoch 0.982), train_loss = 2.53821154, grad/param norm = 3.5657e-01, time/batch = 0.6758s	
658/33450 (epoch 0.984), train_loss = 2.49617108, grad/param norm = 3.1263e-01, time/batch = 0.6752s	
659/33450 (epoch 0.985), train_loss = 2.49412139, grad/param norm = 3.4596e-01, time/batch = 0.6849s	
660/33450 (epoch 0.987), train_loss = 2.55631384, grad/param norm = 3.1661e-01, time/batch = 0.7048s	
661/33450 (epoch 0.988), train_loss = 2.45188382, grad/param norm = 3.9851e-01, time/batch = 0.7063s	
662/33450 (epoch 0.990), train_loss = 2.45311232, grad/param norm = 4.5748e-01, time/batch = 0.7028s	
663/33450 (epoch 0.991), train_loss = 2.62415605, grad/param norm = 2.6663e-01, time/batch = 0.6925s	
664/33450 (epoch 0.993), train_loss = 2.55779794, grad/param norm = 3.2979e-01, time/batch = 0.6750s	
665/33450 (epoch 0.994), train_loss = 2.52517083, grad/param norm = 2.7703e-01, time/batch = 0.6839s	
666/33450 (epoch 0.996), train_loss = 2.52054240, grad/param norm = 3.8453e-01, time/batch = 0.6794s	
667/33450 (epoch 0.997), train_loss = 2.53313648, grad/param norm = 4.2799e-01, time/batch = 0.6767s	
668/33450 (epoch 0.999), train_loss = 2.58690630, grad/param norm = 4.1695e-01, time/batch = 0.6748s	
669/33450 (epoch 1.000), train_loss = 2.44467256, grad/param norm = 3.5672e-01, time/batch = 0.6845s	
670/33450 (epoch 1.001), train_loss = 2.64558616, grad/param norm = 2.8275e-01, time/batch = 0.6749s	
671/33450 (epoch 1.003), train_loss = 2.48183026, grad/param norm = 3.0160e-01, time/batch = 0.6768s	
672/33450 (epoch 1.004), train_loss = 2.50752570, grad/param norm = 2.9282e-01, time/batch = 0.6746s	
673/33450 (epoch 1.006), train_loss = 2.57955532, grad/param norm = 2.8783e-01, time/batch = 0.6747s	
674/33450 (epoch 1.007), train_loss = 2.37246826, grad/param norm = 2.8374e-01, time/batch = 0.6738s	
675/33450 (epoch 1.009), train_loss = 2.52868487, grad/param norm = 2.9250e-01, time/batch = 0.6768s	
676/33450 (epoch 1.010), train_loss = 2.51267199, grad/param norm = 3.5662e-01, time/batch = 0.6745s	
677/33450 (epoch 1.012), train_loss = 2.47668806, grad/param norm = 3.2853e-01, time/batch = 0.6723s	
678/33450 (epoch 1.013), train_loss = 2.40176596, grad/param norm = 2.6728e-01, time/batch = 0.6738s	
679/33450 (epoch 1.015), train_loss = 2.53691320, grad/param norm = 2.8528e-01, time/batch = 0.6781s	
680/33450 (epoch 1.016), train_loss = 2.55470503, grad/param norm = 3.4583e-01, time/batch = 0.6723s	
681/33450 (epoch 1.018), train_loss = 2.44335908, grad/param norm = 3.1079e-01, time/batch = 0.6750s	
682/33450 (epoch 1.019), train_loss = 2.46459632, grad/param norm = 3.0726e-01, time/batch = 0.6758s	
683/33450 (epoch 1.021), train_loss = 2.49755425, grad/param norm = 2.9191e-01, time/batch = 0.6789s	
684/33450 (epoch 1.022), train_loss = 2.52402148, grad/param norm = 2.4391e-01, time/batch = 0.6942s	
685/33450 (epoch 1.024), train_loss = 2.49871808, grad/param norm = 2.7783e-01, time/batch = 0.6799s	
686/33450 (epoch 1.025), train_loss = 2.45136229, grad/param norm = 3.1707e-01, time/batch = 0.6870s	
687/33450 (epoch 1.027), train_loss = 2.69436171, grad/param norm = 4.0573e-01, time/batch = 0.7112s	
688/33450 (epoch 1.028), train_loss = 2.52257627, grad/param norm = 3.7347e-01, time/batch = 0.6990s	
689/33450 (epoch 1.030), train_loss = 2.58399954, grad/param norm = 4.7689e-01, time/batch = 0.6741s	
690/33450 (epoch 1.031), train_loss = 2.50754303, grad/param norm = 6.1644e-01, time/batch = 0.6773s	
691/33450 (epoch 1.033), train_loss = 2.59157944, grad/param norm = 4.3121e-01, time/batch = 0.6806s	
692/33450 (epoch 1.034), train_loss = 2.49607219, grad/param norm = 3.3115e-01, time/batch = 0.6785s	
693/33450 (epoch 1.036), train_loss = 2.39808863, grad/param norm = 2.4971e-01, time/batch = 0.6757s	
694/33450 (epoch 1.037), train_loss = 2.46357021, grad/param norm = 2.4407e-01, time/batch = 0.6754s	
695/33450 (epoch 1.039), train_loss = 2.47317732, grad/param norm = 2.8368e-01, time/batch = 0.6747s	
696/33450 (epoch 1.040), train_loss = 2.55052976, grad/param norm = 2.6914e-01, time/batch = 0.6804s	
697/33450 (epoch 1.042), train_loss = 2.56152107, grad/param norm = 2.6890e-01, time/batch = 0.6773s	
698/33450 (epoch 1.043), train_loss = 2.37673556, grad/param norm = 2.6130e-01, time/batch = 0.7118s	
699/33450 (epoch 1.045), train_loss = 2.49463781, grad/param norm = 3.1333e-01, time/batch = 0.6993s	
700/33450 (epoch 1.046), train_loss = 2.50771036, grad/param norm = 3.1552e-01, time/batch = 0.6822s	
701/33450 (epoch 1.048), train_loss = 2.31136817, grad/param norm = 3.4452e-01, time/batch = 0.6929s	
702/33450 (epoch 1.049), train_loss = 2.48717284, grad/param norm = 2.8770e-01, time/batch = 0.7187s	
703/33450 (epoch 1.051), train_loss = 2.51216310, grad/param norm = 3.5282e-01, time/batch = 0.6765s	
704/33450 (epoch 1.052), train_loss = 2.58943897, grad/param norm = 3.4166e-01, time/batch = 0.6746s	
705/33450 (epoch 1.054), train_loss = 2.39844353, grad/param norm = 3.2944e-01, time/batch = 0.6736s	
706/33450 (epoch 1.055), train_loss = 2.63720305, grad/param norm = 3.4760e-01, time/batch = 0.6750s	
707/33450 (epoch 1.057), train_loss = 2.47414109, grad/param norm = 4.0336e-01, time/batch = 0.6736s	
708/33450 (epoch 1.058), train_loss = 2.38100338, grad/param norm = 3.2278e-01, time/batch = 0.6744s	
709/33450 (epoch 1.060), train_loss = 2.41908363, grad/param norm = 2.6305e-01, time/batch = 0.6730s	
710/33450 (epoch 1.061), train_loss = 2.38474760, grad/param norm = 2.9422e-01, time/batch = 0.6734s	
711/33450 (epoch 1.063), train_loss = 2.46267108, grad/param norm = 2.8010e-01, time/batch = 0.6770s	
712/33450 (epoch 1.064), train_loss = 2.43984321, grad/param norm = 2.8109e-01, time/batch = 0.6760s	
713/33450 (epoch 1.066), train_loss = 2.39445446, grad/param norm = 3.7883e-01, time/batch = 0.6805s	
714/33450 (epoch 1.067), train_loss = 2.43418284, grad/param norm = 4.1672e-01, time/batch = 0.6739s	
715/33450 (epoch 1.069), train_loss = 2.48376190, grad/param norm = 3.3699e-01, time/batch = 0.6730s	
716/33450 (epoch 1.070), train_loss = 2.39040579, grad/param norm = 2.8470e-01, time/batch = 0.6740s	
717/33450 (epoch 1.072), train_loss = 2.41315013, grad/param norm = 2.7101e-01, time/batch = 0.6736s	
718/33450 (epoch 1.073), train_loss = 2.37827969, grad/param norm = 2.9438e-01, time/batch = 0.6724s	
719/33450 (epoch 1.075), train_loss = 2.46902145, grad/param norm = 3.4258e-01, time/batch = 0.6733s	
720/33450 (epoch 1.076), train_loss = 2.46357436, grad/param norm = 3.6090e-01, time/batch = 0.6818s	
721/33450 (epoch 1.078), train_loss = 2.41805402, grad/param norm = 3.3377e-01, time/batch = 0.7203s	
722/33450 (epoch 1.079), train_loss = 2.31054377, grad/param norm = 2.7203e-01, time/batch = 0.6815s	
723/33450 (epoch 1.081), train_loss = 2.43876565, grad/param norm = 2.9321e-01, time/batch = 0.6737s	
724/33450 (epoch 1.082), train_loss = 2.49794831, grad/param norm = 2.8170e-01, time/batch = 0.6735s	
725/33450 (epoch 1.084), train_loss = 2.35400504, grad/param norm = 2.8521e-01, time/batch = 0.6744s	
726/33450 (epoch 1.085), train_loss = 2.44564650, grad/param norm = 3.0975e-01, time/batch = 0.6745s	
727/33450 (epoch 1.087), train_loss = 2.52733966, grad/param norm = 2.5973e-01, time/batch = 0.6741s	
728/33450 (epoch 1.088), train_loss = 2.35728069, grad/param norm = 2.3315e-01, time/batch = 0.6762s	
729/33450 (epoch 1.090), train_loss = 2.59513687, grad/param norm = 3.4311e-01, time/batch = 0.6754s	
730/33450 (epoch 1.091), train_loss = 2.41382588, grad/param norm = 3.5645e-01, time/batch = 0.6739s	
731/33450 (epoch 1.093), train_loss = 2.27060363, grad/param norm = 3.5468e-01, time/batch = 0.6777s	
732/33450 (epoch 1.094), train_loss = 2.30767852, grad/param norm = 3.1262e-01, time/batch = 0.6763s	
733/33450 (epoch 1.096), train_loss = 2.31557967, grad/param norm = 3.0911e-01, time/batch = 0.6779s	
734/33450 (epoch 1.097), train_loss = 2.48425158, grad/param norm = 2.9269e-01, time/batch = 0.6788s	
735/33450 (epoch 1.099), train_loss = 2.40419526, grad/param norm = 2.8594e-01, time/batch = 0.7076s	
736/33450 (epoch 1.100), train_loss = 2.52740011, grad/param norm = 4.2888e-01, time/batch = 0.7154s	
737/33450 (epoch 1.102), train_loss = 2.55467448, grad/param norm = 3.6909e-01, time/batch = 0.6955s	
738/33450 (epoch 1.103), train_loss = 2.54461983, grad/param norm = 2.6857e-01, time/batch = 0.6924s	
739/33450 (epoch 1.105), train_loss = 2.39967725, grad/param norm = 3.7317e-01, time/batch = 0.6901s	
740/33450 (epoch 1.106), train_loss = 2.40024418, grad/param norm = 2.7913e-01, time/batch = 0.6868s	
741/33450 (epoch 1.108), train_loss = 2.46966909, grad/param norm = 2.6071e-01, time/batch = 0.6941s	
742/33450 (epoch 1.109), train_loss = 2.44900194, grad/param norm = 2.9345e-01, time/batch = 0.7023s	
743/33450 (epoch 1.111), train_loss = 2.44986692, grad/param norm = 2.7586e-01, time/batch = 0.6966s	
744/33450 (epoch 1.112), train_loss = 2.58750689, grad/param norm = 3.1206e-01, time/batch = 0.6916s	
745/33450 (epoch 1.114), train_loss = 2.52988951, grad/param norm = 3.4145e-01, time/batch = 0.7107s	
746/33450 (epoch 1.115), train_loss = 2.44189378, grad/param norm = 3.1559e-01, time/batch = 0.7102s	
747/33450 (epoch 1.117), train_loss = 2.44312447, grad/param norm = 2.5416e-01, time/batch = 0.6764s	
748/33450 (epoch 1.118), train_loss = 2.42972488, grad/param norm = 2.6542e-01, time/batch = 0.6752s	
749/33450 (epoch 1.120), train_loss = 2.61396261, grad/param norm = 3.2468e-01, time/batch = 0.6821s	
750/33450 (epoch 1.121), train_loss = 2.37326451, grad/param norm = 3.1377e-01, time/batch = 0.7171s	
751/33450 (epoch 1.123), train_loss = 2.55315168, grad/param norm = 3.4406e-01, time/batch = 0.6964s	
752/33450 (epoch 1.124), train_loss = 2.37136294, grad/param norm = 3.9102e-01, time/batch = 0.6847s	
753/33450 (epoch 1.126), train_loss = 2.44437646, grad/param norm = 3.9585e-01, time/batch = 0.6736s	
754/33450 (epoch 1.127), train_loss = 2.50502272, grad/param norm = 3.8561e-01, time/batch = 0.6739s	
755/33450 (epoch 1.129), train_loss = 2.40361114, grad/param norm = 3.7557e-01, time/batch = 0.6741s	
756/33450 (epoch 1.130), train_loss = 2.55544045, grad/param norm = 3.1318e-01, time/batch = 0.6736s	
757/33450 (epoch 1.132), train_loss = 2.54593560, grad/param norm = 3.5695e-01, time/batch = 0.6760s	
758/33450 (epoch 1.133), train_loss = 2.59381145, grad/param norm = 3.0954e-01, time/batch = 0.6720s	
759/33450 (epoch 1.135), train_loss = 2.52192838, grad/param norm = 2.7350e-01, time/batch = 0.6739s	
760/33450 (epoch 1.136), train_loss = 2.51625223, grad/param norm = 2.4086e-01, time/batch = 0.6723s	
761/33450 (epoch 1.138), train_loss = 2.46516860, grad/param norm = 2.6949e-01, time/batch = 0.6750s	
762/33450 (epoch 1.139), train_loss = 2.32771234, grad/param norm = 2.6500e-01, time/batch = 0.6808s	
763/33450 (epoch 1.141), train_loss = 2.34738255, grad/param norm = 2.7103e-01, time/batch = 0.6863s	
764/33450 (epoch 1.142), train_loss = 2.45922083, grad/param norm = 3.0830e-01, time/batch = 0.6850s	
765/33450 (epoch 1.143), train_loss = 2.76945369, grad/param norm = 3.3346e-01, time/batch = 0.6734s	
766/33450 (epoch 1.145), train_loss = 2.53043000, grad/param norm = 3.1201e-01, time/batch = 0.6729s	
767/33450 (epoch 1.146), train_loss = 2.42914788, grad/param norm = 2.9279e-01, time/batch = 0.6752s	
768/33450 (epoch 1.148), train_loss = 2.43153039, grad/param norm = 3.5137e-01, time/batch = 0.6832s	
769/33450 (epoch 1.149), train_loss = 2.50424799, grad/param norm = 3.6164e-01, time/batch = 0.6780s	
770/33450 (epoch 1.151), train_loss = 2.52014487, grad/param norm = 3.4441e-01, time/batch = 0.6727s	
771/33450 (epoch 1.152), train_loss = 2.50120966, grad/param norm = 3.3588e-01, time/batch = 0.6928s	
772/33450 (epoch 1.154), train_loss = 2.52642713, grad/param norm = 3.2325e-01, time/batch = 0.6876s	
773/33450 (epoch 1.155), train_loss = 2.53179042, grad/param norm = 3.4931e-01, time/batch = 0.6775s	
774/33450 (epoch 1.157), train_loss = 2.43894303, grad/param norm = 2.7591e-01, time/batch = 0.6798s	
775/33450 (epoch 1.158), train_loss = 2.52370603, grad/param norm = 2.8804e-01, time/batch = 0.6709s	
776/33450 (epoch 1.160), train_loss = 2.38254952, grad/param norm = 2.7204e-01, time/batch = 0.6708s	
777/33450 (epoch 1.161), train_loss = 2.40489924, grad/param norm = 2.8613e-01, time/batch = 0.6733s	
778/33450 (epoch 1.163), train_loss = 2.36450702, grad/param norm = 2.5187e-01, time/batch = 0.6709s	
779/33450 (epoch 1.164), train_loss = 2.44458102, grad/param norm = 2.5777e-01, time/batch = 0.6703s	
780/33450 (epoch 1.166), train_loss = 2.49313150, grad/param norm = 2.7243e-01, time/batch = 0.6774s	
781/33450 (epoch 1.167), train_loss = 2.37971729, grad/param norm = 4.0393e-01, time/batch = 0.6727s	
782/33450 (epoch 1.169), train_loss = 2.45564381, grad/param norm = 4.6777e-01, time/batch = 0.6741s	
783/33450 (epoch 1.170), train_loss = 2.44797566, grad/param norm = 4.5103e-01, time/batch = 0.6718s	
784/33450 (epoch 1.172), train_loss = 2.37630795, grad/param norm = 4.1151e-01, time/batch = 0.7002s	
785/33450 (epoch 1.173), train_loss = 2.40984233, grad/param norm = 3.1485e-01, time/batch = 0.6718s	
786/33450 (epoch 1.175), train_loss = 2.60108936, grad/param norm = 2.9307e-01, time/batch = 0.6814s	
787/33450 (epoch 1.176), train_loss = 2.55080313, grad/param norm = 3.3094e-01, time/batch = 0.6773s	
788/33450 (epoch 1.178), train_loss = 2.36525654, grad/param norm = 3.3695e-01, time/batch = 0.6970s	
789/33450 (epoch 1.179), train_loss = 2.28927810, grad/param norm = 3.0968e-01, time/batch = 0.7023s	
790/33450 (epoch 1.181), train_loss = 2.43550815, grad/param norm = 2.7502e-01, time/batch = 0.6916s	
791/33450 (epoch 1.182), train_loss = 2.38941309, grad/param norm = 2.5331e-01, time/batch = 0.6767s	
792/33450 (epoch 1.184), train_loss = 2.35651613, grad/param norm = 2.8436e-01, time/batch = 0.6752s	
793/33450 (epoch 1.185), train_loss = 2.36345943, grad/param norm = 3.1959e-01, time/batch = 0.6931s	
794/33450 (epoch 1.187), train_loss = 2.27805043, grad/param norm = 2.5558e-01, time/batch = 0.7184s	
795/33450 (epoch 1.188), train_loss = 2.36700325, grad/param norm = 3.5338e-01, time/batch = 0.6782s	
796/33450 (epoch 1.190), train_loss = 2.48151346, grad/param norm = 2.9428e-01, time/batch = 0.6745s	
797/33450 (epoch 1.191), train_loss = 2.49639021, grad/param norm = 3.0356e-01, time/batch = 0.6771s	
798/33450 (epoch 1.193), train_loss = 2.50037280, grad/param norm = 2.8201e-01, time/batch = 0.6766s	
799/33450 (epoch 1.194), train_loss = 2.47715742, grad/param norm = 3.1258e-01, time/batch = 0.6784s	
800/33450 (epoch 1.196), train_loss = 2.33285527, grad/param norm = 2.4452e-01, time/batch = 0.6846s	
801/33450 (epoch 1.197), train_loss = 2.40299002, grad/param norm = 2.6345e-01, time/batch = 0.6871s	
802/33450 (epoch 1.199), train_loss = 2.34892084, grad/param norm = 2.4043e-01, time/batch = 0.6767s	
803/33450 (epoch 1.200), train_loss = 2.57872713, grad/param norm = 2.8949e-01, time/batch = 0.6885s	
804/33450 (epoch 1.202), train_loss = 2.42439211, grad/param norm = 3.2228e-01, time/batch = 0.6908s	
805/33450 (epoch 1.203), train_loss = 2.32928848, grad/param norm = 2.8772e-01, time/batch = 0.6915s	
806/33450 (epoch 1.205), train_loss = 2.42927724, grad/param norm = 2.8370e-01, time/batch = 0.6962s	
807/33450 (epoch 1.206), train_loss = 2.54753551, grad/param norm = 3.4937e-01, time/batch = 0.6973s	
808/33450 (epoch 1.208), train_loss = 2.44804779, grad/param norm = 3.3657e-01, time/batch = 0.7154s	
809/33450 (epoch 1.209), train_loss = 2.48692620, grad/param norm = 2.8030e-01, time/batch = 0.7066s	
810/33450 (epoch 1.211), train_loss = 2.44751550, grad/param norm = 3.2850e-01, time/batch = 0.6865s	
811/33450 (epoch 1.212), train_loss = 2.47613867, grad/param norm = 2.9133e-01, time/batch = 0.6911s	
812/33450 (epoch 1.214), train_loss = 2.50119494, grad/param norm = 3.1867e-01, time/batch = 0.6908s	
813/33450 (epoch 1.215), train_loss = 2.50472015, grad/param norm = 2.6912e-01, time/batch = 0.6855s	
814/33450 (epoch 1.217), train_loss = 2.40507458, grad/param norm = 2.7243e-01, time/batch = 0.6881s	
815/33450 (epoch 1.218), train_loss = 2.38715641, grad/param norm = 2.8074e-01, time/batch = 0.7000s	
816/33450 (epoch 1.220), train_loss = 2.28594055, grad/param norm = 2.7469e-01, time/batch = 0.6928s	
817/33450 (epoch 1.221), train_loss = 2.63560281, grad/param norm = 3.5249e-01, time/batch = 0.6926s	
818/33450 (epoch 1.223), train_loss = 2.52590664, grad/param norm = 2.7395e-01, time/batch = 0.6869s	
819/33450 (epoch 1.224), train_loss = 2.40502198, grad/param norm = 2.7749e-01, time/batch = 0.6816s	
820/33450 (epoch 1.226), train_loss = 2.43228111, grad/param norm = 2.4100e-01, time/batch = 0.6857s	
821/33450 (epoch 1.227), train_loss = 2.45188877, grad/param norm = 2.7120e-01, time/batch = 0.6986s	
822/33450 (epoch 1.229), train_loss = 2.35530893, grad/param norm = 2.7589e-01, time/batch = 0.7063s	
823/33450 (epoch 1.230), train_loss = 2.35685702, grad/param norm = 2.9725e-01, time/batch = 0.7133s	
824/33450 (epoch 1.232), train_loss = 2.47876921, grad/param norm = 2.9786e-01, time/batch = 0.6735s	
825/33450 (epoch 1.233), train_loss = 2.43016997, grad/param norm = 2.7795e-01, time/batch = 0.6753s	
826/33450 (epoch 1.235), train_loss = 2.36461741, grad/param norm = 2.7877e-01, time/batch = 0.6782s	
827/33450 (epoch 1.236), train_loss = 2.39116446, grad/param norm = 2.9526e-01, time/batch = 0.6735s	
828/33450 (epoch 1.238), train_loss = 2.29967989, grad/param norm = 3.4115e-01, time/batch = 0.6739s	
829/33450 (epoch 1.239), train_loss = 2.53093070, grad/param norm = 3.3283e-01, time/batch = 0.6744s	
830/33450 (epoch 1.241), train_loss = 2.66813611, grad/param norm = 3.0591e-01, time/batch = 0.6782s	
831/33450 (epoch 1.242), train_loss = 2.43764444, grad/param norm = 3.6640e-01, time/batch = 0.6749s	
832/33450 (epoch 1.244), train_loss = 2.53929234, grad/param norm = 3.0425e-01, time/batch = 0.6769s	
833/33450 (epoch 1.245), train_loss = 2.35265817, grad/param norm = 2.8179e-01, time/batch = 0.6737s	
834/33450 (epoch 1.247), train_loss = 2.52414864, grad/param norm = 3.8218e-01, time/batch = 0.6737s	
835/33450 (epoch 1.248), train_loss = 2.30569884, grad/param norm = 4.7512e-01, time/batch = 0.6741s	
836/33450 (epoch 1.250), train_loss = 2.34231338, grad/param norm = 4.1327e-01, time/batch = 0.6732s	
837/33450 (epoch 1.251), train_loss = 2.37632771, grad/param norm = 3.7738e-01, time/batch = 0.6924s	
838/33450 (epoch 1.253), train_loss = 2.47896289, grad/param norm = 3.0725e-01, time/batch = 0.6859s	
839/33450 (epoch 1.254), train_loss = 2.46296170, grad/param norm = 3.8990e-01, time/batch = 0.6722s	
840/33450 (epoch 1.256), train_loss = 2.61575005, grad/param norm = 4.8593e-01, time/batch = 0.6721s	
841/33450 (epoch 1.257), train_loss = 2.35730523, grad/param norm = 3.3666e-01, time/batch = 0.6747s	
842/33450 (epoch 1.259), train_loss = 2.38585572, grad/param norm = 2.9354e-01, time/batch = 0.6738s	
843/33450 (epoch 1.260), train_loss = 2.53955596, grad/param norm = 2.6048e-01, time/batch = 0.6735s	
844/33450 (epoch 1.262), train_loss = 2.50083410, grad/param norm = 2.8231e-01, time/batch = 0.6739s	
845/33450 (epoch 1.263), train_loss = 2.47198211, grad/param norm = 2.5722e-01, time/batch = 0.6780s	
846/33450 (epoch 1.265), train_loss = 2.41838959, grad/param norm = 3.1321e-01, time/batch = 0.6933s	
847/33450 (epoch 1.266), train_loss = 2.51344887, grad/param norm = 2.7014e-01, time/batch = 0.6917s	
848/33450 (epoch 1.268), train_loss = 2.37986161, grad/param norm = 2.2802e-01, time/batch = 0.6739s	
849/33450 (epoch 1.269), train_loss = 2.29844183, grad/param norm = 2.5985e-01, time/batch = 0.6738s	
850/33450 (epoch 1.271), train_loss = 2.36433307, grad/param norm = 2.9003e-01, time/batch = 0.6759s	
851/33450 (epoch 1.272), train_loss = 2.41463538, grad/param norm = 2.7734e-01, time/batch = 0.6754s	
852/33450 (epoch 1.274), train_loss = 2.38198012, grad/param norm = 3.5841e-01, time/batch = 0.6756s	
853/33450 (epoch 1.275), train_loss = 2.46004648, grad/param norm = 3.2896e-01, time/batch = 0.6730s	
854/33450 (epoch 1.277), train_loss = 2.31918060, grad/param norm = 3.0175e-01, time/batch = 0.6723s	
855/33450 (epoch 1.278), train_loss = 2.36144470, grad/param norm = 2.6647e-01, time/batch = 0.6717s	
856/33450 (epoch 1.280), train_loss = 2.36639437, grad/param norm = 2.9289e-01, time/batch = 0.6883s	
857/33450 (epoch 1.281), train_loss = 2.42146942, grad/param norm = 2.5483e-01, time/batch = 0.6873s	
858/33450 (epoch 1.283), train_loss = 2.30963982, grad/param norm = 3.1131e-01, time/batch = 0.6807s	
859/33450 (epoch 1.284), train_loss = 2.47723493, grad/param norm = 3.3626e-01, time/batch = 0.6968s	
860/33450 (epoch 1.286), train_loss = 2.40245257, grad/param norm = 2.8549e-01, time/batch = 0.7025s	
861/33450 (epoch 1.287), train_loss = 2.26746590, grad/param norm = 2.9881e-01, time/batch = 0.6964s	
862/33450 (epoch 1.288), train_loss = 2.35268337, grad/param norm = 2.9670e-01, time/batch = 0.6799s	
863/33450 (epoch 1.290), train_loss = 2.44095904, grad/param norm = 2.3202e-01, time/batch = 0.6877s	
864/33450 (epoch 1.291), train_loss = 2.41324185, grad/param norm = 2.6056e-01, time/batch = 0.6801s	
865/33450 (epoch 1.293), train_loss = 2.34557973, grad/param norm = 2.6963e-01, time/batch = 0.6753s	
866/33450 (epoch 1.294), train_loss = 2.32612574, grad/param norm = 2.6686e-01, time/batch = 0.7070s	
867/33450 (epoch 1.296), train_loss = 2.38927170, grad/param norm = 2.5843e-01, time/batch = 0.7160s	
868/33450 (epoch 1.297), train_loss = 2.44882840, grad/param norm = 3.0484e-01, time/batch = 0.7116s	
869/33450 (epoch 1.299), train_loss = 2.40118906, grad/param norm = 3.1339e-01, time/batch = 0.6985s	
870/33450 (epoch 1.300), train_loss = 2.42646532, grad/param norm = 3.3421e-01, time/batch = 0.6973s	
871/33450 (epoch 1.302), train_loss = 2.41215344, grad/param norm = 3.4240e-01, time/batch = 0.6983s	
872/33450 (epoch 1.303), train_loss = 2.32855728, grad/param norm = 3.0479e-01, time/batch = 0.6978s	
873/33450 (epoch 1.305), train_loss = 2.48120602, grad/param norm = 3.6235e-01, time/batch = 0.6954s	
874/33450 (epoch 1.306), train_loss = 2.58298735, grad/param norm = 4.0603e-01, time/batch = 0.7053s	
875/33450 (epoch 1.308), train_loss = 2.43013436, grad/param norm = 2.7408e-01, time/batch = 0.6759s	
876/33450 (epoch 1.309), train_loss = 2.48542960, grad/param norm = 3.0499e-01, time/batch = 0.6797s	
877/33450 (epoch 1.311), train_loss = 2.35388992, grad/param norm = 2.5917e-01, time/batch = 0.6754s	
878/33450 (epoch 1.312), train_loss = 2.47509872, grad/param norm = 2.6640e-01, time/batch = 0.6828s	
879/33450 (epoch 1.314), train_loss = 2.35324345, grad/param norm = 2.8585e-01, time/batch = 0.6823s	
880/33450 (epoch 1.315), train_loss = 2.33862314, grad/param norm = 2.8109e-01, time/batch = 0.6860s	
881/33450 (epoch 1.317), train_loss = 2.33190537, grad/param norm = 2.4204e-01, time/batch = 0.6754s	
882/33450 (epoch 1.318), train_loss = 2.38710577, grad/param norm = 2.6200e-01, time/batch = 0.6742s	
883/33450 (epoch 1.320), train_loss = 2.30600605, grad/param norm = 2.7594e-01, time/batch = 0.6765s	
884/33450 (epoch 1.321), train_loss = 2.27960870, grad/param norm = 3.6273e-01, time/batch = 0.6796s	
885/33450 (epoch 1.323), train_loss = 2.23485543, grad/param norm = 3.6618e-01, time/batch = 0.6769s	
886/33450 (epoch 1.324), train_loss = 2.27013545, grad/param norm = 3.2453e-01, time/batch = 0.6752s	
887/33450 (epoch 1.326), train_loss = 2.26017806, grad/param norm = 3.5224e-01, time/batch = 0.6757s	
888/33450 (epoch 1.327), train_loss = 2.32983875, grad/param norm = 2.6763e-01, time/batch = 0.6769s	
889/33450 (epoch 1.329), train_loss = 2.35763000, grad/param norm = 2.6583e-01, time/batch = 0.6725s	
890/33450 (epoch 1.330), train_loss = 2.46017322, grad/param norm = 2.9409e-01, time/batch = 0.6740s	
891/33450 (epoch 1.332), train_loss = 2.51071427, grad/param norm = 2.5871e-01, time/batch = 0.6759s	
892/33450 (epoch 1.333), train_loss = 2.19473041, grad/param norm = 2.7657e-01, time/batch = 0.6771s	
893/33450 (epoch 1.335), train_loss = 2.42242211, grad/param norm = 2.5284e-01, time/batch = 0.6746s	
894/33450 (epoch 1.336), train_loss = 2.34244968, grad/param norm = 2.5185e-01, time/batch = 0.6770s	
895/33450 (epoch 1.338), train_loss = 2.23483840, grad/param norm = 2.5554e-01, time/batch = 0.7114s	
896/33450 (epoch 1.339), train_loss = 2.20919020, grad/param norm = 2.6684e-01, time/batch = 0.7114s	
897/33450 (epoch 1.341), train_loss = 2.47430996, grad/param norm = 2.8050e-01, time/batch = 0.6781s	
898/33450 (epoch 1.342), train_loss = 2.40820293, grad/param norm = 2.6963e-01, time/batch = 0.6771s	
899/33450 (epoch 1.344), train_loss = 2.41186580, grad/param norm = 2.5997e-01, time/batch = 0.6761s	
900/33450 (epoch 1.345), train_loss = 2.31105544, grad/param norm = 3.3258e-01, time/batch = 0.6745s	
901/33450 (epoch 1.347), train_loss = 2.31269729, grad/param norm = 4.8656e-01, time/batch = 0.6764s	
902/33450 (epoch 1.348), train_loss = 2.27706524, grad/param norm = 3.5874e-01, time/batch = 0.6777s	
903/33450 (epoch 1.350), train_loss = 2.50856668, grad/param norm = 2.7959e-01, time/batch = 0.6784s	
904/33450 (epoch 1.351), train_loss = 2.28861227, grad/param norm = 2.5065e-01, time/batch = 0.6776s	
905/33450 (epoch 1.353), train_loss = 2.30805809, grad/param norm = 2.8213e-01, time/batch = 0.6777s	
906/33450 (epoch 1.354), train_loss = 2.29220714, grad/param norm = 2.4834e-01, time/batch = 0.6733s	
907/33450 (epoch 1.356), train_loss = 2.36226801, grad/param norm = 3.2124e-01, time/batch = 0.6742s	
908/33450 (epoch 1.357), train_loss = 2.30606823, grad/param norm = 3.0619e-01, time/batch = 0.6764s	
909/33450 (epoch 1.359), train_loss = 2.34363731, grad/param norm = 3.3392e-01, time/batch = 0.6747s	
910/33450 (epoch 1.360), train_loss = 2.43051594, grad/param norm = 3.4627e-01, time/batch = 0.7136s	
911/33450 (epoch 1.362), train_loss = 2.43732963, grad/param norm = 2.6891e-01, time/batch = 0.6964s	
912/33450 (epoch 1.363), train_loss = 2.39509039, grad/param norm = 2.9505e-01, time/batch = 0.6774s	
913/33450 (epoch 1.365), train_loss = 2.36986728, grad/param norm = 2.3134e-01, time/batch = 0.6745s	
914/33450 (epoch 1.366), train_loss = 2.43154833, grad/param norm = 2.6109e-01, time/batch = 0.6754s	
915/33450 (epoch 1.368), train_loss = 2.39442140, grad/param norm = 2.4864e-01, time/batch = 0.6747s	
916/33450 (epoch 1.369), train_loss = 2.32935002, grad/param norm = 2.5048e-01, time/batch = 0.6754s	
917/33450 (epoch 1.371), train_loss = 2.36752472, grad/param norm = 2.6696e-01, time/batch = 0.6735s	
918/33450 (epoch 1.372), train_loss = 2.42088325, grad/param norm = 3.0598e-01, time/batch = 0.6815s	
919/33450 (epoch 1.374), train_loss = 2.60956164, grad/param norm = 2.8318e-01, time/batch = 0.6719s	
920/33450 (epoch 1.375), train_loss = 2.46048197, grad/param norm = 2.6252e-01, time/batch = 0.6796s	
921/33450 (epoch 1.377), train_loss = 2.41374306, grad/param norm = 3.1064e-01, time/batch = 0.6789s	
922/33450 (epoch 1.378), train_loss = 2.50944577, grad/param norm = 3.0658e-01, time/batch = 0.6930s	
923/33450 (epoch 1.380), train_loss = 2.43844282, grad/param norm = 2.5030e-01, time/batch = 0.6967s	
924/33450 (epoch 1.381), train_loss = 2.41833368, grad/param norm = 3.1157e-01, time/batch = 0.6901s	
925/33450 (epoch 1.383), train_loss = 2.39247361, grad/param norm = 2.8900e-01, time/batch = 0.7178s	
926/33450 (epoch 1.384), train_loss = 2.35552781, grad/param norm = 2.3194e-01, time/batch = 0.6744s	
927/33450 (epoch 1.386), train_loss = 2.35962271, grad/param norm = 2.2858e-01, time/batch = 0.6733s	
928/33450 (epoch 1.387), train_loss = 2.46842154, grad/param norm = 2.5270e-01, time/batch = 0.6729s	
929/33450 (epoch 1.389), train_loss = 2.52270534, grad/param norm = 3.2731e-01, time/batch = 0.6719s	
930/33450 (epoch 1.390), train_loss = 2.39203507, grad/param norm = 2.6992e-01, time/batch = 0.6744s	
931/33450 (epoch 1.392), train_loss = 2.37825452, grad/param norm = 2.6751e-01, time/batch = 0.6808s	
932/33450 (epoch 1.393), train_loss = 2.30309066, grad/param norm = 2.9931e-01, time/batch = 0.6753s	
933/33450 (epoch 1.395), train_loss = 2.30926575, grad/param norm = 2.8569e-01, time/batch = 0.6742s	
934/33450 (epoch 1.396), train_loss = 2.37485330, grad/param norm = 2.5714e-01, time/batch = 0.6736s	
935/33450 (epoch 1.398), train_loss = 2.43463024, grad/param norm = 2.7251e-01, time/batch = 0.6734s	
936/33450 (epoch 1.399), train_loss = 2.52958213, grad/param norm = 3.2577e-01, time/batch = 0.6735s	
937/33450 (epoch 1.401), train_loss = 2.55535049, grad/param norm = 2.6246e-01, time/batch = 0.6735s	
938/33450 (epoch 1.402), train_loss = 2.26028911, grad/param norm = 2.2768e-01, time/batch = 0.7108s	
939/33450 (epoch 1.404), train_loss = 2.32114625, grad/param norm = 2.5548e-01, time/batch = 0.7185s	
940/33450 (epoch 1.405), train_loss = 2.33056589, grad/param norm = 2.6235e-01, time/batch = 0.7108s	
941/33450 (epoch 1.407), train_loss = 2.31626312, grad/param norm = 2.6802e-01, time/batch = 0.6918s	
942/33450 (epoch 1.408), train_loss = 2.48830970, grad/param norm = 3.3950e-01, time/batch = 0.6886s	
943/33450 (epoch 1.410), train_loss = 2.39686659, grad/param norm = 2.4240e-01, time/batch = 0.6809s	
944/33450 (epoch 1.411), train_loss = 2.27637767, grad/param norm = 2.3219e-01, time/batch = 0.6894s	
945/33450 (epoch 1.413), train_loss = 2.29162845, grad/param norm = 2.6940e-01, time/batch = 0.6908s	
946/33450 (epoch 1.414), train_loss = 2.40696897, grad/param norm = 2.8081e-01, time/batch = 0.7048s	
947/33450 (epoch 1.416), train_loss = 2.37391274, grad/param norm = 2.9170e-01, time/batch = 0.6969s	
948/33450 (epoch 1.417), train_loss = 2.33993414, grad/param norm = 2.6966e-01, time/batch = 0.7077s	
949/33450 (epoch 1.419), train_loss = 2.28086815, grad/param norm = 2.9329e-01, time/batch = 0.7183s	
950/33450 (epoch 1.420), train_loss = 2.36656274, grad/param norm = 2.8865e-01, time/batch = 0.7026s	
951/33450 (epoch 1.422), train_loss = 2.20154352, grad/param norm = 2.6498e-01, time/batch = 0.6732s	
952/33450 (epoch 1.423), train_loss = 2.32127476, grad/param norm = 2.6180e-01, time/batch = 0.6743s	
953/33450 (epoch 1.425), train_loss = 2.22417292, grad/param norm = 2.4585e-01, time/batch = 0.6736s	
954/33450 (epoch 1.426), train_loss = 2.29447706, grad/param norm = 2.5819e-01, time/batch = 0.6922s	
955/33450 (epoch 1.428), train_loss = 2.32148978, grad/param norm = 2.9147e-01, time/batch = 0.6734s	
956/33450 (epoch 1.429), train_loss = 2.36936460, grad/param norm = 2.8227e-01, time/batch = 0.6716s	
957/33450 (epoch 1.430), train_loss = 2.33388569, grad/param norm = 4.1589e-01, time/batch = 0.6736s	
958/33450 (epoch 1.432), train_loss = 2.38171551, grad/param norm = 3.9744e-01, time/batch = 0.6772s	
959/33450 (epoch 1.433), train_loss = 2.39347848, grad/param norm = 2.6578e-01, time/batch = 0.6738s	
960/33450 (epoch 1.435), train_loss = 2.27051149, grad/param norm = 2.4056e-01, time/batch = 0.6817s	
961/33450 (epoch 1.436), train_loss = 2.27156844, grad/param norm = 2.4422e-01, time/batch = 0.6919s	
962/33450 (epoch 1.438), train_loss = 2.31375397, grad/param norm = 2.7086e-01, time/batch = 0.6750s	
963/33450 (epoch 1.439), train_loss = 2.29213917, grad/param norm = 2.4140e-01, time/batch = 0.6997s	
964/33450 (epoch 1.441), train_loss = 2.49802534, grad/param norm = 2.5084e-01, time/batch = 0.7082s	
965/33450 (epoch 1.442), train_loss = 2.35223827, grad/param norm = 2.4361e-01, time/batch = 0.6861s	
966/33450 (epoch 1.444), train_loss = 2.41802561, grad/param norm = 2.8144e-01, time/batch = 0.6807s	
967/33450 (epoch 1.445), train_loss = 2.43465218, grad/param norm = 3.1200e-01, time/batch = 0.6736s	
968/33450 (epoch 1.447), train_loss = 2.41396203, grad/param norm = 2.9823e-01, time/batch = 0.6777s	
969/33450 (epoch 1.448), train_loss = 2.39065854, grad/param norm = 3.1552e-01, time/batch = 0.6846s	
970/33450 (epoch 1.450), train_loss = 2.33573143, grad/param norm = 2.9959e-01, time/batch = 0.6729s	
971/33450 (epoch 1.451), train_loss = 2.44743152, grad/param norm = 3.1464e-01, time/batch = 0.6743s	
972/33450 (epoch 1.453), train_loss = 2.28692972, grad/param norm = 2.3034e-01, time/batch = 0.6741s	
973/33450 (epoch 1.454), train_loss = 2.30269994, grad/param norm = 2.8224e-01, time/batch = 0.6729s	
974/33450 (epoch 1.456), train_loss = 2.31465449, grad/param norm = 2.4362e-01, time/batch = 0.6732s	
975/33450 (epoch 1.457), train_loss = 2.39881322, grad/param norm = 2.5871e-01, time/batch = 0.6759s	
976/33450 (epoch 1.459), train_loss = 2.32235159, grad/param norm = 2.5964e-01, time/batch = 0.6757s	
977/33450 (epoch 1.460), train_loss = 2.52401437, grad/param norm = 2.6640e-01, time/batch = 0.6732s	
978/33450 (epoch 1.462), train_loss = 2.50618478, grad/param norm = 2.9303e-01, time/batch = 0.6998s	
979/33450 (epoch 1.463), train_loss = 2.27469094, grad/param norm = 2.7992e-01, time/batch = 0.7135s	
980/33450 (epoch 1.465), train_loss = 2.29609566, grad/param norm = 2.7065e-01, time/batch = 0.6747s	
981/33450 (epoch 1.466), train_loss = 2.35075730, grad/param norm = 2.7492e-01, time/batch = 0.6761s	
982/33450 (epoch 1.468), train_loss = 2.49674579, grad/param norm = 3.3378e-01, time/batch = 0.6801s	
983/33450 (epoch 1.469), train_loss = 2.46301637, grad/param norm = 3.8562e-01, time/batch = 0.6737s	
984/33450 (epoch 1.471), train_loss = 2.42292202, grad/param norm = 2.9864e-01, time/batch = 0.6755s	
985/33450 (epoch 1.472), train_loss = 2.29826433, grad/param norm = 2.5861e-01, time/batch = 0.6737s	
986/33450 (epoch 1.474), train_loss = 2.61245341, grad/param norm = 3.2631e-01, time/batch = 0.6734s	
987/33450 (epoch 1.475), train_loss = 2.44000486, grad/param norm = 3.3691e-01, time/batch = 0.6745s	
988/33450 (epoch 1.477), train_loss = 2.27562989, grad/param norm = 2.7201e-01, time/batch = 0.6742s	
989/33450 (epoch 1.478), train_loss = 2.28783777, grad/param norm = 3.0025e-01, time/batch = 0.6731s	
990/33450 (epoch 1.480), train_loss = 2.14939985, grad/param norm = 2.8289e-01, time/batch = 0.6749s	
991/33450 (epoch 1.481), train_loss = 2.21024015, grad/param norm = 2.5821e-01, time/batch = 0.6782s	
992/33450 (epoch 1.483), train_loss = 2.21699799, grad/param norm = 2.8156e-01, time/batch = 0.6772s	
993/33450 (epoch 1.484), train_loss = 2.34811560, grad/param norm = 2.8049e-01, time/batch = 0.6774s	
994/33450 (epoch 1.486), train_loss = 2.40416529, grad/param norm = 2.6787e-01, time/batch = 0.6751s	
995/33450 (epoch 1.487), train_loss = 2.24425538, grad/param norm = 2.7360e-01, time/batch = 0.6745s	
996/33450 (epoch 1.489), train_loss = 2.27228968, grad/param norm = 2.7943e-01, time/batch = 0.6744s	
997/33450 (epoch 1.490), train_loss = 2.35227201, grad/param norm = 3.1105e-01, time/batch = 0.6755s	
998/33450 (epoch 1.492), train_loss = 2.33545616, grad/param norm = 2.9273e-01, time/batch = 0.6757s	
999/33450 (epoch 1.493), train_loss = 2.41176763, grad/param norm = 3.1499e-01, time/batch = 0.6855s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_melania_guerra_epoch1.49_2.3667.t7	
1000/33450 (epoch 1.495), train_loss = 2.36947679, grad/param norm = 3.2513e-01, time/batch = 0.6850s	
1001/33450 (epoch 1.496), train_loss = 2.46372450, grad/param norm = 3.1392e-01, time/batch = 0.6783s	
1002/33450 (epoch 1.498), train_loss = 2.34622610, grad/param norm = 2.6571e-01, time/batch = 0.6795s	
1003/33450 (epoch 1.499), train_loss = 2.37229968, grad/param norm = 2.2585e-01, time/batch = 0.6803s	
1004/33450 (epoch 1.501), train_loss = 2.44504399, grad/param norm = 2.7035e-01, time/batch = 0.6772s	
1005/33450 (epoch 1.502), train_loss = 2.40058135, grad/param norm = 2.4114e-01, time/batch = 0.6733s	
1006/33450 (epoch 1.504), train_loss = 2.37278302, grad/param norm = 2.8545e-01, time/batch = 0.6733s	
1007/33450 (epoch 1.505), train_loss = 2.40443026, grad/param norm = 2.6884e-01, time/batch = 0.6726s	
1008/33450 (epoch 1.507), train_loss = 2.40424196, grad/param norm = 3.4318e-01, time/batch = 0.6734s	
1009/33450 (epoch 1.508), train_loss = 2.28608829, grad/param norm = 3.2063e-01, time/batch = 0.6723s	
1010/33450 (epoch 1.510), train_loss = 2.26427985, grad/param norm = 2.4083e-01, time/batch = 0.6766s	
1011/33450 (epoch 1.511), train_loss = 2.43533561, grad/param norm = 2.4721e-01, time/batch = 0.6735s	
1012/33450 (epoch 1.513), train_loss = 2.43714502, grad/param norm = 2.6648e-01, time/batch = 0.6836s	
1013/33450 (epoch 1.514), train_loss = 2.37256382, grad/param norm = 2.6247e-01, time/batch = 0.7190s	
1014/33450 (epoch 1.516), train_loss = 2.38211080, grad/param norm = 2.8568e-01, time/batch = 0.6812s	
1015/33450 (epoch 1.517), train_loss = 2.33180164, grad/param norm = 2.8228e-01, time/batch = 0.6900s	
1016/33450 (epoch 1.519), train_loss = 2.22966162, grad/param norm = 2.4351e-01, time/batch = 0.6886s	
1017/33450 (epoch 1.520), train_loss = 2.50551191, grad/param norm = 2.6995e-01, time/batch = 0.6809s	
1018/33450 (epoch 1.522), train_loss = 2.42768537, grad/param norm = 2.8160e-01, time/batch = 0.6944s	
1019/33450 (epoch 1.523), train_loss = 2.39772032, grad/param norm = 2.6559e-01, time/batch = 0.6937s	
1020/33450 (epoch 1.525), train_loss = 2.23751782, grad/param norm = 2.7916e-01, time/batch = 0.6908s	
1021/33450 (epoch 1.526), train_loss = 2.36229252, grad/param norm = 2.9959e-01, time/batch = 0.6888s	
1022/33450 (epoch 1.528), train_loss = 2.45388959, grad/param norm = 2.8241e-01, time/batch = 0.6897s	
1023/33450 (epoch 1.529), train_loss = 2.43445482, grad/param norm = 2.5727e-01, time/batch = 0.7003s	
1024/33450 (epoch 1.531), train_loss = 2.34129896, grad/param norm = 2.5544e-01, time/batch = 0.6996s	
1025/33450 (epoch 1.532), train_loss = 2.32200226, grad/param norm = 2.4187e-01, time/batch = 0.6936s	
1026/33450 (epoch 1.534), train_loss = 2.36519711, grad/param norm = 2.5956e-01, time/batch = 0.7004s	
1027/33450 (epoch 1.535), train_loss = 2.41444042, grad/param norm = 2.6683e-01, time/batch = 0.7133s	
1028/33450 (epoch 1.537), train_loss = 2.15188007, grad/param norm = 2.6774e-01, time/batch = 0.7027s	
1029/33450 (epoch 1.538), train_loss = 2.20510491, grad/param norm = 2.7230e-01, time/batch = 0.6922s	
1030/33450 (epoch 1.540), train_loss = 2.38318139, grad/param norm = 2.8081e-01, time/batch = 0.6954s	
1031/33450 (epoch 1.541), train_loss = 2.28996713, grad/param norm = 2.3619e-01, time/batch = 0.6943s	
1032/33450 (epoch 1.543), train_loss = 2.10346590, grad/param norm = 2.5873e-01, time/batch = 0.6934s	
1033/33450 (epoch 1.544), train_loss = 2.23813683, grad/param norm = 2.8872e-01, time/batch = 0.6764s	
1034/33450 (epoch 1.546), train_loss = 2.20612749, grad/param norm = 2.4746e-01, time/batch = 0.6741s	
1035/33450 (epoch 1.547), train_loss = 2.17667511, grad/param norm = 2.5571e-01, time/batch = 0.6735s	
1036/33450 (epoch 1.549), train_loss = 2.44875435, grad/param norm = 2.7228e-01, time/batch = 0.6733s	
1037/33450 (epoch 1.550), train_loss = 2.28906560, grad/param norm = 2.5277e-01, time/batch = 0.6730s	
1038/33450 (epoch 1.552), train_loss = 2.43451334, grad/param norm = 2.7501e-01, time/batch = 0.6739s	
1039/33450 (epoch 1.553), train_loss = 2.37745862, grad/param norm = 2.3927e-01, time/batch = 0.6830s	
1040/33450 (epoch 1.555), train_loss = 2.03022568, grad/param norm = 2.4879e-01, time/batch = 0.6790s	
1041/33450 (epoch 1.556), train_loss = 2.23750993, grad/param norm = 2.4472e-01, time/batch = 0.6959s	
1042/33450 (epoch 1.558), train_loss = 2.34939275, grad/param norm = 2.4169e-01, time/batch = 0.7175s	
1043/33450 (epoch 1.559), train_loss = 2.15803675, grad/param norm = 2.4441e-01, time/batch = 0.6822s	
1044/33450 (epoch 1.561), train_loss = 2.38798853, grad/param norm = 2.8796e-01, time/batch = 0.6811s	
1045/33450 (epoch 1.562), train_loss = 2.31167846, grad/param norm = 2.7486e-01, time/batch = 0.6781s	
1046/33450 (epoch 1.564), train_loss = 2.27752402, grad/param norm = 2.6566e-01, time/batch = 0.6734s	
1047/33450 (epoch 1.565), train_loss = 2.41262368, grad/param norm = 2.3165e-01, time/batch = 0.6732s	
1048/33450 (epoch 1.567), train_loss = 2.14638023, grad/param norm = 2.5773e-01, time/batch = 0.6743s	
1049/33450 (epoch 1.568), train_loss = 2.27979267, grad/param norm = 3.6512e-01, time/batch = 0.6790s	
1050/33450 (epoch 1.570), train_loss = 2.46276764, grad/param norm = 4.3729e-01, time/batch = 0.6783s	
1051/33450 (epoch 1.571), train_loss = 2.41945419, grad/param norm = 2.8567e-01, time/batch = 0.6769s	
1052/33450 (epoch 1.572), train_loss = 2.22878484, grad/param norm = 2.4844e-01, time/batch = 0.6744s	
1053/33450 (epoch 1.574), train_loss = 2.12039976, grad/param norm = 2.8565e-01, time/batch = 0.6738s	
1054/33450 (epoch 1.575), train_loss = 2.17118171, grad/param norm = 2.2980e-01, time/batch = 0.6837s	
1055/33450 (epoch 1.577), train_loss = 2.39450767, grad/param norm = 3.2438e-01, time/batch = 0.6752s	
1056/33450 (epoch 1.578), train_loss = 2.15270420, grad/param norm = 3.0377e-01, time/batch = 0.7039s	
1057/33450 (epoch 1.580), train_loss = 2.22545188, grad/param norm = 2.7461e-01, time/batch = 0.7109s	
1058/33450 (epoch 1.581), train_loss = 2.34926462, grad/param norm = 2.6884e-01, time/batch = 0.6832s	
1059/33450 (epoch 1.583), train_loss = 2.27191113, grad/param norm = 2.7011e-01, time/batch = 0.6741s	
1060/33450 (epoch 1.584), train_loss = 2.19217280, grad/param norm = 2.6481e-01, time/batch = 0.6804s	
1061/33450 (epoch 1.586), train_loss = 2.23046957, grad/param norm = 2.5126e-01, time/batch = 0.6734s	
1062/33450 (epoch 1.587), train_loss = 2.37587713, grad/param norm = 2.4232e-01, time/batch = 0.6782s	
1063/33450 (epoch 1.589), train_loss = 2.23855762, grad/param norm = 2.3968e-01, time/batch = 0.6729s	
1064/33450 (epoch 1.590), train_loss = 2.36728847, grad/param norm = 2.4540e-01, time/batch = 0.6713s	
1065/33450 (epoch 1.592), train_loss = 2.35669255, grad/param norm = 2.9042e-01, time/batch = 0.6723s	
1066/33450 (epoch 1.593), train_loss = 2.38618015, grad/param norm = 3.7535e-01, time/batch = 0.6732s	
1067/33450 (epoch 1.595), train_loss = 2.36144390, grad/param norm = 3.1599e-01, time/batch = 0.6772s	
1068/33450 (epoch 1.596), train_loss = 2.39926676, grad/param norm = 3.1324e-01, time/batch = 0.6783s	
1069/33450 (epoch 1.598), train_loss = 2.32842542, grad/param norm = 3.0952e-01, time/batch = 0.6733s	
1070/33450 (epoch 1.599), train_loss = 2.40584000, grad/param norm = 2.3498e-01, time/batch = 0.6741s	
1071/33450 (epoch 1.601), train_loss = 2.33786440, grad/param norm = 2.3237e-01, time/batch = 0.7195s	
1072/33450 (epoch 1.602), train_loss = 2.38057861, grad/param norm = 2.8036e-01, time/batch = 0.7001s	
1073/33450 (epoch 1.604), train_loss = 2.17927532, grad/param norm = 2.3213e-01, time/batch = 0.6939s	
1074/33450 (epoch 1.605), train_loss = 2.20417767, grad/param norm = 2.9881e-01, time/batch = 0.6975s	
1075/33450 (epoch 1.607), train_loss = 2.28374399, grad/param norm = 2.8504e-01, time/batch = 0.6853s	
1076/33450 (epoch 1.608), train_loss = 2.21641855, grad/param norm = 2.9331e-01, time/batch = 0.6741s	
1077/33450 (epoch 1.610), train_loss = 2.32945531, grad/param norm = 2.6377e-01, time/batch = 0.6725s	
1078/33450 (epoch 1.611), train_loss = 2.32582332, grad/param norm = 2.3976e-01, time/batch = 0.6719s	
1079/33450 (epoch 1.613), train_loss = 2.32622535, grad/param norm = 2.4778e-01, time/batch = 0.6726s	
1080/33450 (epoch 1.614), train_loss = 2.34677552, grad/param norm = 2.6169e-01, time/batch = 0.6730s	
1081/33450 (epoch 1.616), train_loss = 2.24202950, grad/param norm = 2.8844e-01, time/batch = 0.6759s	
1082/33450 (epoch 1.617), train_loss = 2.21237868, grad/param norm = 2.5880e-01, time/batch = 0.6787s	
1083/33450 (epoch 1.619), train_loss = 2.31995539, grad/param norm = 2.4605e-01, time/batch = 0.6777s	
1084/33450 (epoch 1.620), train_loss = 2.10342432, grad/param norm = 2.3090e-01, time/batch = 0.6745s	
1085/33450 (epoch 1.622), train_loss = 2.32728403, grad/param norm = 2.4683e-01, time/batch = 0.6986s	
1086/33450 (epoch 1.623), train_loss = 2.27196916, grad/param norm = 2.5215e-01, time/batch = 0.7135s	
1087/33450 (epoch 1.625), train_loss = 2.41756953, grad/param norm = 2.5057e-01, time/batch = 0.6720s	
1088/33450 (epoch 1.626), train_loss = 2.12508755, grad/param norm = 2.3880e-01, time/batch = 0.6746s	
1089/33450 (epoch 1.628), train_loss = 2.13152909, grad/param norm = 2.4055e-01, time/batch = 0.6730s	
1090/33450 (epoch 1.629), train_loss = 2.41041522, grad/param norm = 3.0546e-01, time/batch = 0.6737s	
1091/33450 (epoch 1.631), train_loss = 2.44249208, grad/param norm = 3.2591e-01, time/batch = 0.6745s	
1092/33450 (epoch 1.632), train_loss = 2.16870078, grad/param norm = 2.5276e-01, time/batch = 0.6749s	
1093/33450 (epoch 1.634), train_loss = 2.25354967, grad/param norm = 2.9617e-01, time/batch = 0.6739s	
1094/33450 (epoch 1.635), train_loss = 2.33283235, grad/param norm = 2.7532e-01, time/batch = 0.6731s	
1095/33450 (epoch 1.637), train_loss = 2.36976649, grad/param norm = 2.4891e-01, time/batch = 0.6743s	
1096/33450 (epoch 1.638), train_loss = 2.20212620, grad/param norm = 2.2027e-01, time/batch = 0.6790s	
1097/33450 (epoch 1.640), train_loss = 2.29295639, grad/param norm = 2.2428e-01, time/batch = 0.6775s	
1098/33450 (epoch 1.641), train_loss = 2.26340445, grad/param norm = 2.8331e-01, time/batch = 0.6790s	
1099/33450 (epoch 1.643), train_loss = 2.18405010, grad/param norm = 2.4176e-01, time/batch = 0.7074s	
1100/33450 (epoch 1.644), train_loss = 2.29544367, grad/param norm = 2.5269e-01, time/batch = 0.7181s	
1101/33450 (epoch 1.646), train_loss = 2.35420825, grad/param norm = 2.4135e-01, time/batch = 0.6984s	
1102/33450 (epoch 1.647), train_loss = 2.42723190, grad/param norm = 3.0653e-01, time/batch = 0.6805s	
1103/33450 (epoch 1.649), train_loss = 2.29771439, grad/param norm = 2.2557e-01, time/batch = 0.6821s	
1104/33450 (epoch 1.650), train_loss = 2.23373516, grad/param norm = 2.6343e-01, time/batch = 0.6831s	
1105/33450 (epoch 1.652), train_loss = 2.00004455, grad/param norm = 3.2298e-01, time/batch = 0.6774s	
1106/33450 (epoch 1.653), train_loss = 2.28123981, grad/param norm = 2.9471e-01, time/batch = 0.6751s	
1107/33450 (epoch 1.655), train_loss = 2.36544069, grad/param norm = 3.0966e-01, time/batch = 0.6756s	
1108/33450 (epoch 1.656), train_loss = 2.16312314, grad/param norm = 3.4577e-01, time/batch = 0.6733s	
1109/33450 (epoch 1.658), train_loss = 2.25777867, grad/param norm = 3.1188e-01, time/batch = 0.6793s	
1110/33450 (epoch 1.659), train_loss = 2.30206513, grad/param norm = 3.7009e-01, time/batch = 0.6757s	
1111/33450 (epoch 1.661), train_loss = 2.41814137, grad/param norm = 2.5066e-01, time/batch = 0.6970s	
1112/33450 (epoch 1.662), train_loss = 2.15295385, grad/param norm = 2.4343e-01, time/batch = 0.6990s	
1113/33450 (epoch 1.664), train_loss = 2.28774440, grad/param norm = 2.2099e-01, time/batch = 0.7185s	
1114/33450 (epoch 1.665), train_loss = 2.17735514, grad/param norm = 2.8139e-01, time/batch = 0.7154s	
1115/33450 (epoch 1.667), train_loss = 2.32792656, grad/param norm = 2.4664e-01, time/batch = 0.7179s	
1116/33450 (epoch 1.668), train_loss = 2.30109583, grad/param norm = 2.3754e-01, time/batch = 0.6918s	
1117/33450 (epoch 1.670), train_loss = 2.21998877, grad/param norm = 2.5486e-01, time/batch = 0.6926s	
1118/33450 (epoch 1.671), train_loss = 2.30837967, grad/param norm = 2.4910e-01, time/batch = 0.7118s	
1119/33450 (epoch 1.673), train_loss = 2.30839916, grad/param norm = 2.7200e-01, time/batch = 0.6945s	
1120/33450 (epoch 1.674), train_loss = 2.38181302, grad/param norm = 2.5329e-01, time/batch = 0.6900s	
1121/33450 (epoch 1.676), train_loss = 2.35887939, grad/param norm = 2.4408e-01, time/batch = 0.6918s	
1122/33450 (epoch 1.677), train_loss = 2.30087804, grad/param norm = 2.5046e-01, time/batch = 0.6941s	
1123/33450 (epoch 1.679), train_loss = 2.24041687, grad/param norm = 2.4414e-01, time/batch = 0.6874s	
1124/33450 (epoch 1.680), train_loss = 2.26658778, grad/param norm = 2.4774e-01, time/batch = 0.6736s	
1125/33450 (epoch 1.682), train_loss = 2.20612343, grad/param norm = 2.4571e-01, time/batch = 0.7047s	
1126/33450 (epoch 1.683), train_loss = 2.45876461, grad/param norm = 2.4052e-01, time/batch = 0.6815s	
1127/33450 (epoch 1.685), train_loss = 2.48310645, grad/param norm = 2.8670e-01, time/batch = 0.6826s	
1128/33450 (epoch 1.686), train_loss = 2.43549537, grad/param norm = 2.4088e-01, time/batch = 0.6801s	
1129/33450 (epoch 1.688), train_loss = 2.46222282, grad/param norm = 2.6544e-01, time/batch = 0.7185s	
1130/33450 (epoch 1.689), train_loss = 2.28046238, grad/param norm = 2.5620e-01, time/batch = 0.6897s	
1131/33450 (epoch 1.691), train_loss = 2.27705126, grad/param norm = 2.8638e-01, time/batch = 0.6748s	
1132/33450 (epoch 1.692), train_loss = 2.38238710, grad/param norm = 2.5555e-01, time/batch = 0.6753s	
1133/33450 (epoch 1.694), train_loss = 2.13189875, grad/param norm = 2.7534e-01, time/batch = 0.6729s	
1134/33450 (epoch 1.695), train_loss = 2.46648507, grad/param norm = 2.7019e-01, time/batch = 0.6728s	
1135/33450 (epoch 1.697), train_loss = 2.37839238, grad/param norm = 2.3957e-01, time/batch = 0.6728s	
1136/33450 (epoch 1.698), train_loss = 2.12511024, grad/param norm = 2.6766e-01, time/batch = 0.6724s	
1137/33450 (epoch 1.700), train_loss = 2.48423588, grad/param norm = 3.3335e-01, time/batch = 0.6719s	
1138/33450 (epoch 1.701), train_loss = 2.29293266, grad/param norm = 3.4261e-01, time/batch = 0.6779s	
1139/33450 (epoch 1.703), train_loss = 2.38055411, grad/param norm = 2.9901e-01, time/batch = 0.6779s	
1140/33450 (epoch 1.704), train_loss = 2.20681612, grad/param norm = 2.3983e-01, time/batch = 0.6788s	
1141/33450 (epoch 1.706), train_loss = 2.22120286, grad/param norm = 2.4531e-01, time/batch = 0.6755s	
1142/33450 (epoch 1.707), train_loss = 2.19172011, grad/param norm = 2.4738e-01, time/batch = 0.6751s	
1143/33450 (epoch 1.709), train_loss = 2.38502970, grad/param norm = 3.1401e-01, time/batch = 0.6758s	
1144/33450 (epoch 1.710), train_loss = 2.25229251, grad/param norm = 2.7554e-01, time/batch = 0.6749s	
1145/33450 (epoch 1.712), train_loss = 2.16284063, grad/param norm = 3.0266e-01, time/batch = 0.6748s	
1146/33450 (epoch 1.713), train_loss = 2.41895354, grad/param norm = 2.6514e-01, time/batch = 0.6749s	
1147/33450 (epoch 1.714), train_loss = 2.28669241, grad/param norm = 2.3276e-01, time/batch = 0.6739s	
1148/33450 (epoch 1.716), train_loss = 2.19073077, grad/param norm = 2.3099e-01, time/batch = 0.6804s	
1149/33450 (epoch 1.717), train_loss = 2.27818921, grad/param norm = 2.7054e-01, time/batch = 0.6745s	
1150/33450 (epoch 1.719), train_loss = 2.38617257, grad/param norm = 2.9252e-01, time/batch = 0.6755s	
1151/33450 (epoch 1.720), train_loss = 2.20947515, grad/param norm = 2.6530e-01, time/batch = 0.6756s	
1152/33450 (epoch 1.722), train_loss = 2.06226577, grad/param norm = 2.5638e-01, time/batch = 0.6750s	
1153/33450 (epoch 1.723), train_loss = 2.21056827, grad/param norm = 3.0487e-01, time/batch = 0.6755s	
1154/33450 (epoch 1.725), train_loss = 2.14453133, grad/param norm = 2.5825e-01, time/batch = 0.6753s	
1155/33450 (epoch 1.726), train_loss = 2.06175069, grad/param norm = 2.3016e-01, time/batch = 0.6772s	
1156/33450 (epoch 1.728), train_loss = 2.17097006, grad/param norm = 2.7433e-01, time/batch = 0.6826s	
1157/33450 (epoch 1.729), train_loss = 2.30648540, grad/param norm = 3.1036e-01, time/batch = 0.6794s	
1158/33450 (epoch 1.731), train_loss = 2.55667901, grad/param norm = 3.4576e-01, time/batch = 0.7035s	
1159/33450 (epoch 1.732), train_loss = 2.44254360, grad/param norm = 3.0723e-01, time/batch = 0.7118s	
1160/33450 (epoch 1.734), train_loss = 2.38068931, grad/param norm = 2.9436e-01, time/batch = 0.7048s	
1161/33450 (epoch 1.735), train_loss = 2.44199751, grad/param norm = 2.6997e-01, time/batch = 0.7143s	
1162/33450 (epoch 1.737), train_loss = 2.36105420, grad/param norm = 2.8066e-01, time/batch = 0.7133s	
1163/33450 (epoch 1.738), train_loss = 2.45891713, grad/param norm = 2.2929e-01, time/batch = 0.7025s	
1164/33450 (epoch 1.740), train_loss = 2.27902768, grad/param norm = 2.5548e-01, time/batch = 0.6976s	
1165/33450 (epoch 1.741), train_loss = 2.24245757, grad/param norm = 2.4358e-01, time/batch = 0.6824s	
1166/33450 (epoch 1.743), train_loss = 2.34612930, grad/param norm = 2.6205e-01, time/batch = 0.6865s	
1167/33450 (epoch 1.744), train_loss = 2.34639843, grad/param norm = 2.4226e-01, time/batch = 0.6758s	
1168/33450 (epoch 1.746), train_loss = 2.23498893, grad/param norm = 2.1324e-01, time/batch = 0.7054s	
1169/33450 (epoch 1.747), train_loss = 2.40734253, grad/param norm = 2.5974e-01, time/batch = 0.7037s	
1170/33450 (epoch 1.749), train_loss = 2.22820845, grad/param norm = 2.5231e-01, time/batch = 0.6765s	
1171/33450 (epoch 1.750), train_loss = 2.19000904, grad/param norm = 2.3194e-01, time/batch = 0.6747s	
1172/33450 (epoch 1.752), train_loss = 2.39299394, grad/param norm = 2.8765e-01, time/batch = 0.6737s	
1173/33450 (epoch 1.753), train_loss = 2.32798840, grad/param norm = 2.6818e-01, time/batch = 0.6759s	
1174/33450 (epoch 1.755), train_loss = 2.25083567, grad/param norm = 2.4840e-01, time/batch = 0.6759s	
1175/33450 (epoch 1.756), train_loss = 2.38876075, grad/param norm = 2.4924e-01, time/batch = 0.6754s	
1176/33450 (epoch 1.758), train_loss = 2.30382799, grad/param norm = 2.2285e-01, time/batch = 0.6777s	
1177/33450 (epoch 1.759), train_loss = 2.31612976, grad/param norm = 2.4070e-01, time/batch = 0.6725s	
1178/33450 (epoch 1.761), train_loss = 2.36490087, grad/param norm = 2.9929e-01, time/batch = 0.6728s	
1179/33450 (epoch 1.762), train_loss = 2.44309197, grad/param norm = 2.8272e-01, time/batch = 0.6722s	
1180/33450 (epoch 1.764), train_loss = 2.22633936, grad/param norm = 2.6141e-01, time/batch = 0.6717s	
1181/33450 (epoch 1.765), train_loss = 2.25487029, grad/param norm = 2.9577e-01, time/batch = 0.6754s	
1182/33450 (epoch 1.767), train_loss = 2.30857682, grad/param norm = 3.2984e-01, time/batch = 0.6877s	
1183/33450 (epoch 1.768), train_loss = 2.17183325, grad/param norm = 2.5895e-01, time/batch = 0.7189s	
1184/33450 (epoch 1.770), train_loss = 2.36794321, grad/param norm = 2.6230e-01, time/batch = 0.6890s	
1185/33450 (epoch 1.771), train_loss = 2.49860456, grad/param norm = 2.5158e-01, time/batch = 0.6720s	
1186/33450 (epoch 1.773), train_loss = 2.29068813, grad/param norm = 2.8943e-01, time/batch = 0.6717s	
1187/33450 (epoch 1.774), train_loss = 2.31428178, grad/param norm = 2.5143e-01, time/batch = 0.6717s	
1188/33450 (epoch 1.776), train_loss = 2.21112412, grad/param norm = 2.1059e-01, time/batch = 0.6746s	
1189/33450 (epoch 1.777), train_loss = 2.20657716, grad/param norm = 2.1721e-01, time/batch = 0.6800s	
1190/33450 (epoch 1.779), train_loss = 2.19929780, grad/param norm = 2.1252e-01, time/batch = 0.6798s	
1191/33450 (epoch 1.780), train_loss = 2.21779365, grad/param norm = 2.4930e-01, time/batch = 0.6920s	
1192/33450 (epoch 1.782), train_loss = 2.36944118, grad/param norm = 2.8150e-01, time/batch = 0.6859s	
1193/33450 (epoch 1.783), train_loss = 2.32322697, grad/param norm = 3.3800e-01, time/batch = 0.6797s	
1194/33450 (epoch 1.785), train_loss = 2.33107929, grad/param norm = 3.4458e-01, time/batch = 0.6724s	
1195/33450 (epoch 1.786), train_loss = 2.23732942, grad/param norm = 2.6494e-01, time/batch = 0.6710s	
1196/33450 (epoch 1.788), train_loss = 2.21398007, grad/param norm = 2.3406e-01, time/batch = 0.6718s	
1197/33450 (epoch 1.789), train_loss = 2.19531999, grad/param norm = 2.4497e-01, time/batch = 0.6741s	
1198/33450 (epoch 1.791), train_loss = 2.07929498, grad/param norm = 2.2502e-01, time/batch = 0.6807s	
1199/33450 (epoch 1.792), train_loss = 2.18464889, grad/param norm = 2.4807e-01, time/batch = 0.6949s	
1200/33450 (epoch 1.794), train_loss = 2.15251495, grad/param norm = 2.9222e-01, time/batch = 0.6876s	
1201/33450 (epoch 1.795), train_loss = 2.33593605, grad/param norm = 3.1018e-01, time/batch = 0.6835s	
1202/33450 (epoch 1.797), train_loss = 2.27848360, grad/param norm = 2.4792e-01, time/batch = 0.6837s	
1203/33450 (epoch 1.798), train_loss = 2.27520090, grad/param norm = 2.5975e-01, time/batch = 0.6798s	
1204/33450 (epoch 1.800), train_loss = 2.35694473, grad/param norm = 2.4057e-01, time/batch = 0.6766s	
1205/33450 (epoch 1.801), train_loss = 2.38932753, grad/param norm = 2.6917e-01, time/batch = 0.6716s	
1206/33450 (epoch 1.803), train_loss = 2.33179491, grad/param norm = 2.8638e-01, time/batch = 0.6734s	
1207/33450 (epoch 1.804), train_loss = 2.12794554, grad/param norm = 2.4522e-01, time/batch = 0.6738s	
1208/33450 (epoch 1.806), train_loss = 2.28063788, grad/param norm = 2.5665e-01, time/batch = 0.6910s	
1209/33450 (epoch 1.807), train_loss = 2.21052689, grad/param norm = 2.4271e-01, time/batch = 0.6757s	
1210/33450 (epoch 1.809), train_loss = 2.21579344, grad/param norm = 2.2025e-01, time/batch = 0.6745s	
1211/33450 (epoch 1.810), train_loss = 2.22630813, grad/param norm = 2.2582e-01, time/batch = 0.6780s	
1212/33450 (epoch 1.812), train_loss = 2.17549495, grad/param norm = 2.7789e-01, time/batch = 0.6757s	
1213/33450 (epoch 1.813), train_loss = 2.14841822, grad/param norm = 2.8645e-01, time/batch = 0.6786s	
1214/33450 (epoch 1.815), train_loss = 2.42791673, grad/param norm = 3.1627e-01, time/batch = 0.6765s	
1215/33450 (epoch 1.816), train_loss = 2.25169617, grad/param norm = 2.1826e-01, time/batch = 0.6750s	
1216/33450 (epoch 1.818), train_loss = 1.98250720, grad/param norm = 2.2687e-01, time/batch = 0.6934s	
1217/33450 (epoch 1.819), train_loss = 2.21375008, grad/param norm = 2.5654e-01, time/batch = 0.6914s	
1218/33450 (epoch 1.821), train_loss = 2.29785056, grad/param norm = 2.3672e-01, time/batch = 0.6761s	
1219/33450 (epoch 1.822), train_loss = 2.28893313, grad/param norm = 2.4796e-01, time/batch = 0.6752s	
1220/33450 (epoch 1.824), train_loss = 2.22273811, grad/param norm = 2.4189e-01, time/batch = 0.6778s	
1221/33450 (epoch 1.825), train_loss = 2.26806509, grad/param norm = 2.7042e-01, time/batch = 0.6754s	
1222/33450 (epoch 1.827), train_loss = 2.33068665, grad/param norm = 2.2853e-01, time/batch = 0.6747s	
1223/33450 (epoch 1.828), train_loss = 2.05880525, grad/param norm = 2.5680e-01, time/batch = 0.6750s	
1224/33450 (epoch 1.830), train_loss = 2.15648844, grad/param norm = 2.6054e-01, time/batch = 0.6756s	
1225/33450 (epoch 1.831), train_loss = 2.22449589, grad/param norm = 2.5767e-01, time/batch = 0.6766s	
1226/33450 (epoch 1.833), train_loss = 2.19790384, grad/param norm = 2.7198e-01, time/batch = 0.6790s	
1227/33450 (epoch 1.834), train_loss = 2.18289914, grad/param norm = 2.5133e-01, time/batch = 0.6751s	
1228/33450 (epoch 1.836), train_loss = 2.09678718, grad/param norm = 2.3747e-01, time/batch = 0.6770s	
1229/33450 (epoch 1.837), train_loss = 2.35071023, grad/param norm = 2.4621e-01, time/batch = 0.6766s	
1230/33450 (epoch 1.839), train_loss = 2.34586800, grad/param norm = 2.4137e-01, time/batch = 0.6747s	
1231/33450 (epoch 1.840), train_loss = 2.32576454, grad/param norm = 2.9277e-01, time/batch = 0.7074s	
1232/33450 (epoch 1.842), train_loss = 2.23184214, grad/param norm = 2.4835e-01, time/batch = 0.7037s	
1233/33450 (epoch 1.843), train_loss = 2.11067544, grad/param norm = 2.7928e-01, time/batch = 0.6755s	
1234/33450 (epoch 1.845), train_loss = 2.11423423, grad/param norm = 2.5751e-01, time/batch = 0.6822s	
1235/33450 (epoch 1.846), train_loss = 2.37741662, grad/param norm = 2.4901e-01, time/batch = 0.6803s	
1236/33450 (epoch 1.848), train_loss = 2.25942382, grad/param norm = 2.5120e-01, time/batch = 0.6786s	
1237/33450 (epoch 1.849), train_loss = 2.30999872, grad/param norm = 3.0808e-01, time/batch = 0.6737s	
1238/33450 (epoch 1.851), train_loss = 2.17448064, grad/param norm = 2.5734e-01, time/batch = 0.6730s	
1239/33450 (epoch 1.852), train_loss = 2.21502008, grad/param norm = 2.4475e-01, time/batch = 0.6721s	
1240/33450 (epoch 1.854), train_loss = 2.33765639, grad/param norm = 2.7954e-01, time/batch = 0.6729s	
1241/33450 (epoch 1.855), train_loss = 2.24697228, grad/param norm = 2.6598e-01, time/batch = 0.6769s	
1242/33450 (epoch 1.857), train_loss = 2.19542908, grad/param norm = 2.5783e-01, time/batch = 0.6791s	
1243/33450 (epoch 1.858), train_loss = 2.47439984, grad/param norm = 2.8444e-01, time/batch = 0.6746s	
1244/33450 (epoch 1.859), train_loss = 2.43394900, grad/param norm = 2.6605e-01, time/batch = 0.6731s	
1245/33450 (epoch 1.861), train_loss = 2.42137126, grad/param norm = 3.1842e-01, time/batch = 0.6749s	
1246/33450 (epoch 1.862), train_loss = 2.21475940, grad/param norm = 3.0495e-01, time/batch = 0.6732s	
1247/33450 (epoch 1.864), train_loss = 2.31353917, grad/param norm = 4.1305e-01, time/batch = 0.6743s	
1248/33450 (epoch 1.865), train_loss = 2.22640908, grad/param norm = 2.8345e-01, time/batch = 0.6740s	
1249/33450 (epoch 1.867), train_loss = 2.33212783, grad/param norm = 2.6499e-01, time/batch = 0.6728s	
1250/33450 (epoch 1.868), train_loss = 2.32437544, grad/param norm = 2.7128e-01, time/batch = 0.6794s	
1251/33450 (epoch 1.870), train_loss = 2.27674839, grad/param norm = 2.2067e-01, time/batch = 0.6752s	
1252/33450 (epoch 1.871), train_loss = 2.34883507, grad/param norm = 2.6898e-01, time/batch = 0.6778s	
1253/33450 (epoch 1.873), train_loss = 2.14497626, grad/param norm = 2.5483e-01, time/batch = 0.6738s	
1254/33450 (epoch 1.874), train_loss = 2.22558066, grad/param norm = 2.5375e-01, time/batch = 0.6741s	
1255/33450 (epoch 1.876), train_loss = 2.31852929, grad/param norm = 2.4540e-01, time/batch = 0.6747s	
1256/33450 (epoch 1.877), train_loss = 2.23107561, grad/param norm = 2.2802e-01, time/batch = 0.6739s	
1257/33450 (epoch 1.879), train_loss = 2.09237208, grad/param norm = 2.1766e-01, time/batch = 0.6806s	
1258/33450 (epoch 1.880), train_loss = 2.19997318, grad/param norm = 2.6417e-01, time/batch = 0.6763s	
1259/33450 (epoch 1.882), train_loss = 2.26960804, grad/param norm = 2.5964e-01, time/batch = 0.6747s	
1260/33450 (epoch 1.883), train_loss = 2.22189309, grad/param norm = 2.9699e-01, time/batch = 0.6734s	
1261/33450 (epoch 1.885), train_loss = 2.22957494, grad/param norm = 2.2383e-01, time/batch = 0.6759s	
1262/33450 (epoch 1.886), train_loss = 2.44271391, grad/param norm = 2.8367e-01, time/batch = 0.6748s	
1263/33450 (epoch 1.888), train_loss = 2.28200203, grad/param norm = 2.9682e-01, time/batch = 0.6768s	
1264/33450 (epoch 1.889), train_loss = 2.14833448, grad/param norm = 2.5794e-01, time/batch = 0.6745s	
1265/33450 (epoch 1.891), train_loss = 2.35887137, grad/param norm = 2.4496e-01, time/batch = 0.6751s	
1266/33450 (epoch 1.892), train_loss = 2.22597557, grad/param norm = 2.5702e-01, time/batch = 0.6892s	
1267/33450 (epoch 1.894), train_loss = 2.36159903, grad/param norm = 4.3425e-01, time/batch = 0.6995s	
1268/33450 (epoch 1.895), train_loss = 2.15006225, grad/param norm = 3.4518e-01, time/batch = 0.7011s	
1269/33450 (epoch 1.897), train_loss = 2.14305232, grad/param norm = 2.6557e-01, time/batch = 0.6966s	
1270/33450 (epoch 1.898), train_loss = 2.14808653, grad/param norm = 2.8235e-01, time/batch = 0.6913s	
1271/33450 (epoch 1.900), train_loss = 2.25926131, grad/param norm = 2.7683e-01, time/batch = 0.6854s	
1272/33450 (epoch 1.901), train_loss = 2.29165294, grad/param norm = 3.0017e-01, time/batch = 0.6928s	
1273/33450 (epoch 1.903), train_loss = 2.04251719, grad/param norm = 2.9828e-01, time/batch = 0.6976s	
1274/33450 (epoch 1.904), train_loss = 2.25952710, grad/param norm = 3.1806e-01, time/batch = 0.6934s	
1275/33450 (epoch 1.906), train_loss = 2.23540378, grad/param norm = 2.7453e-01, time/batch = 0.6935s	
1276/33450 (epoch 1.907), train_loss = 2.22825265, grad/param norm = 2.2997e-01, time/batch = 0.6924s	
1277/33450 (epoch 1.909), train_loss = 2.16938320, grad/param norm = 2.1933e-01, time/batch = 0.6814s	
1278/33450 (epoch 1.910), train_loss = 2.26154086, grad/param norm = 2.9491e-01, time/batch = 0.6740s	
1279/33450 (epoch 1.912), train_loss = 2.27461466, grad/param norm = 3.1882e-01, time/batch = 0.6748s	
1280/33450 (epoch 1.913), train_loss = 2.24558189, grad/param norm = 2.3593e-01, time/batch = 0.6738s	
1281/33450 (epoch 1.915), train_loss = 2.20930487, grad/param norm = 2.6593e-01, time/batch = 0.7159s	
1282/33450 (epoch 1.916), train_loss = 2.34337935, grad/param norm = 2.3027e-01, time/batch = 0.6837s	
1283/33450 (epoch 1.918), train_loss = 2.17195803, grad/param norm = 2.5668e-01, time/batch = 0.6732s	
1284/33450 (epoch 1.919), train_loss = 2.30160185, grad/param norm = 2.2986e-01, time/batch = 0.6932s	
1285/33450 (epoch 1.921), train_loss = 2.30492083, grad/param norm = 2.3011e-01, time/batch = 0.6933s	
1286/33450 (epoch 1.922), train_loss = 2.20031916, grad/param norm = 2.3395e-01, time/batch = 0.7154s	
1287/33450 (epoch 1.924), train_loss = 2.35499361, grad/param norm = 2.3452e-01, time/batch = 0.6844s	
1288/33450 (epoch 1.925), train_loss = 2.13951822, grad/param norm = 2.0593e-01, time/batch = 0.6750s	
1289/33450 (epoch 1.927), train_loss = 2.25408710, grad/param norm = 2.3832e-01, time/batch = 0.7153s	
1290/33450 (epoch 1.928), train_loss = 2.19105098, grad/param norm = 2.2723e-01, time/batch = 0.6908s	
1291/33450 (epoch 1.930), train_loss = 2.18603544, grad/param norm = 2.8058e-01, time/batch = 0.6750s	
1292/33450 (epoch 1.931), train_loss = 2.14652483, grad/param norm = 2.9537e-01, time/batch = 0.6936s	
1293/33450 (epoch 1.933), train_loss = 2.24080536, grad/param norm = 2.4962e-01, time/batch = 0.6909s	
1294/33450 (epoch 1.934), train_loss = 2.16846649, grad/param norm = 3.2609e-01, time/batch = 0.6824s	
1295/33450 (epoch 1.936), train_loss = 2.21019188, grad/param norm = 2.2472e-01, time/batch = 0.7075s	
1296/33450 (epoch 1.937), train_loss = 2.12551552, grad/param norm = 2.1929e-01, time/batch = 0.7104s	
1297/33450 (epoch 1.939), train_loss = 2.15460462, grad/param norm = 2.1968e-01, time/batch = 0.6817s	
1298/33450 (epoch 1.940), train_loss = 2.22224972, grad/param norm = 2.1666e-01, time/batch = 0.6741s	
1299/33450 (epoch 1.942), train_loss = 2.27631794, grad/param norm = 2.7227e-01, time/batch = 0.6739s	
1300/33450 (epoch 1.943), train_loss = 2.25297213, grad/param norm = 2.2507e-01, time/batch = 0.6746s	
1301/33450 (epoch 1.945), train_loss = 2.33606522, grad/param norm = 2.2260e-01, time/batch = 0.6772s	
1302/33450 (epoch 1.946), train_loss = 2.35635805, grad/param norm = 3.0230e-01, time/batch = 0.6778s	
1303/33450 (epoch 1.948), train_loss = 2.17786299, grad/param norm = 2.7526e-01, time/batch = 0.6739s	
1304/33450 (epoch 1.949), train_loss = 2.29480500, grad/param norm = 2.4126e-01, time/batch = 0.6756s	
1305/33450 (epoch 1.951), train_loss = 2.29302802, grad/param norm = 2.3916e-01, time/batch = 0.6737s	
1306/33450 (epoch 1.952), train_loss = 2.35815565, grad/param norm = 2.7915e-01, time/batch = 0.6805s	
1307/33450 (epoch 1.954), train_loss = 2.33027328, grad/param norm = 2.5243e-01, time/batch = 0.6853s	
1308/33450 (epoch 1.955), train_loss = 2.29282104, grad/param norm = 2.8970e-01, time/batch = 0.6746s	
1309/33450 (epoch 1.957), train_loss = 2.46677062, grad/param norm = 3.0800e-01, time/batch = 0.6736s	
1310/33450 (epoch 1.958), train_loss = 2.30199033, grad/param norm = 2.5467e-01, time/batch = 0.7060s	
1311/33450 (epoch 1.960), train_loss = 2.31988101, grad/param norm = 2.2700e-01, time/batch = 0.6753s	
1312/33450 (epoch 1.961), train_loss = 2.32127733, grad/param norm = 2.3170e-01, time/batch = 0.6749s	
1313/33450 (epoch 1.963), train_loss = 2.39156358, grad/param norm = 2.9783e-01, time/batch = 0.6736s	
1314/33450 (epoch 1.964), train_loss = 2.23956189, grad/param norm = 2.8245e-01, time/batch = 0.6745s	
1315/33450 (epoch 1.966), train_loss = 2.18328601, grad/param norm = 2.8783e-01, time/batch = 0.6827s	
1316/33450 (epoch 1.967), train_loss = 2.41240548, grad/param norm = 2.8449e-01, time/batch = 0.6731s	
1317/33450 (epoch 1.969), train_loss = 2.14258971, grad/param norm = 2.4383e-01, time/batch = 0.6722s	
1318/33450 (epoch 1.970), train_loss = 2.23949777, grad/param norm = 2.8183e-01, time/batch = 0.6732s	
1319/33450 (epoch 1.972), train_loss = 2.38388385, grad/param norm = 2.8015e-01, time/batch = 0.6722s	
1320/33450 (epoch 1.973), train_loss = 2.26573749, grad/param norm = 2.6008e-01, time/batch = 0.6723s	
1321/33450 (epoch 1.975), train_loss = 2.17216474, grad/param norm = 2.3635e-01, time/batch = 0.6758s	
1322/33450 (epoch 1.976), train_loss = 2.25655572, grad/param norm = 2.3141e-01, time/batch = 0.6819s	
1323/33450 (epoch 1.978), train_loss = 2.13545636, grad/param norm = 2.6364e-01, time/batch = 0.7046s	
1324/33450 (epoch 1.979), train_loss = 2.20637508, grad/param norm = 2.5731e-01, time/batch = 0.7179s	
1325/33450 (epoch 1.981), train_loss = 2.19743414, grad/param norm = 2.7357e-01, time/batch = 0.7204s	
1326/33450 (epoch 1.982), train_loss = 2.19992079, grad/param norm = 2.3748e-01, time/batch = 0.7026s	
1327/33450 (epoch 1.984), train_loss = 2.13406857, grad/param norm = 2.5267e-01, time/batch = 0.6892s	
1328/33450 (epoch 1.985), train_loss = 2.13997663, grad/param norm = 2.5342e-01, time/batch = 0.6750s	
1329/33450 (epoch 1.987), train_loss = 2.23505279, grad/param norm = 2.2755e-01, time/batch = 0.6828s	
1330/33450 (epoch 1.988), train_loss = 2.13303328, grad/param norm = 2.7375e-01, time/batch = 0.6920s	
1331/33450 (epoch 1.990), train_loss = 2.06742795, grad/param norm = 2.7452e-01, time/batch = 0.6789s	
1332/33450 (epoch 1.991), train_loss = 2.27442904, grad/param norm = 2.1889e-01, time/batch = 0.7078s	
1333/33450 (epoch 1.993), train_loss = 2.19254384, grad/param norm = 2.7469e-01, time/batch = 0.7176s	
1334/33450 (epoch 1.994), train_loss = 2.21328271, grad/param norm = 2.2018e-01, time/batch = 0.7069s	
1335/33450 (epoch 1.996), train_loss = 2.18290223, grad/param norm = 3.0283e-01, time/batch = 0.6979s	
1336/33450 (epoch 1.997), train_loss = 2.16527390, grad/param norm = 2.8159e-01, time/batch = 0.6926s	
1337/33450 (epoch 1.999), train_loss = 2.30196749, grad/param norm = 3.0407e-01, time/batch = 0.6771s	
1338/33450 (epoch 2.000), train_loss = 2.18135331, grad/param norm = 2.8427e-01, time/batch = 0.6786s	
1339/33450 (epoch 2.001), train_loss = 2.45174207, grad/param norm = 2.4223e-01, time/batch = 0.7180s	
1340/33450 (epoch 2.003), train_loss = 2.22346831, grad/param norm = 2.2387e-01, time/batch = 0.6908s	
1341/33450 (epoch 2.004), train_loss = 2.26139116, grad/param norm = 2.3257e-01, time/batch = 0.6748s	
1342/33450 (epoch 2.006), train_loss = 2.23345730, grad/param norm = 2.2506e-01, time/batch = 0.6756s	
1343/33450 (epoch 2.007), train_loss = 2.01103297, grad/param norm = 2.2964e-01, time/batch = 0.6882s	
1344/33450 (epoch 2.009), train_loss = 2.30644764, grad/param norm = 2.5739e-01, time/batch = 0.6887s	
1345/33450 (epoch 2.010), train_loss = 2.22293752, grad/param norm = 3.2709e-01, time/batch = 0.6876s	
1346/33450 (epoch 2.012), train_loss = 2.16806330, grad/param norm = 2.2903e-01, time/batch = 0.6763s	
1347/33450 (epoch 2.013), train_loss = 2.14128706, grad/param norm = 2.4825e-01, time/batch = 0.6738s	
1348/33450 (epoch 2.015), train_loss = 2.21438459, grad/param norm = 2.3773e-01, time/batch = 0.6739s	
1349/33450 (epoch 2.016), train_loss = 2.23797913, grad/param norm = 2.4503e-01, time/batch = 0.6729s	
1350/33450 (epoch 2.018), train_loss = 2.15016537, grad/param norm = 2.4128e-01, time/batch = 0.6761s	
1351/33450 (epoch 2.019), train_loss = 2.13166297, grad/param norm = 2.4457e-01, time/batch = 0.6750s	
1352/33450 (epoch 2.021), train_loss = 2.23831857, grad/param norm = 2.6995e-01, time/batch = 0.6740s	
1353/33450 (epoch 2.022), train_loss = 2.24561786, grad/param norm = 2.7495e-01, time/batch = 0.6732s	
1354/33450 (epoch 2.024), train_loss = 2.13266804, grad/param norm = 2.6145e-01, time/batch = 0.6727s	
1355/33450 (epoch 2.025), train_loss = 2.15524900, grad/param norm = 2.3194e-01, time/batch = 0.6730s	
1356/33450 (epoch 2.027), train_loss = 2.24457856, grad/param norm = 2.4064e-01, time/batch = 0.6751s	
1357/33450 (epoch 2.028), train_loss = 2.24117455, grad/param norm = 2.1042e-01, time/batch = 0.6778s	
1358/33450 (epoch 2.030), train_loss = 2.33099701, grad/param norm = 2.8483e-01, time/batch = 0.6755s	
1359/33450 (epoch 2.031), train_loss = 2.21387143, grad/param norm = 3.2080e-01, time/batch = 0.6791s	
1360/33450 (epoch 2.033), train_loss = 2.31734354, grad/param norm = 2.4233e-01, time/batch = 0.6760s	
1361/33450 (epoch 2.034), train_loss = 2.30973997, grad/param norm = 3.0364e-01, time/batch = 0.6776s	
1362/33450 (epoch 2.036), train_loss = 2.07546351, grad/param norm = 2.3601e-01, time/batch = 0.6745s	
1363/33450 (epoch 2.037), train_loss = 2.19036335, grad/param norm = 2.1345e-01, time/batch = 0.6743s	
1364/33450 (epoch 2.039), train_loss = 2.18412897, grad/param norm = 2.0288e-01, time/batch = 0.6740s	
1365/33450 (epoch 2.040), train_loss = 2.30390567, grad/param norm = 2.2379e-01, time/batch = 0.6744s	
1366/33450 (epoch 2.042), train_loss = 2.24321577, grad/param norm = 2.2135e-01, time/batch = 0.6741s	
1367/33450 (epoch 2.043), train_loss = 2.15997237, grad/param norm = 2.3203e-01, time/batch = 0.6752s	
1368/33450 (epoch 2.045), train_loss = 2.25043302, grad/param norm = 2.4283e-01, time/batch = 0.6738s	
1369/33450 (epoch 2.046), train_loss = 2.15874228, grad/param norm = 2.3687e-01, time/batch = 0.6726s	
1370/33450 (epoch 2.048), train_loss = 1.97496183, grad/param norm = 2.5417e-01, time/batch = 0.6719s	
1371/33450 (epoch 2.049), train_loss = 2.16781954, grad/param norm = 2.1812e-01, time/batch = 0.6747s	
1372/33450 (epoch 2.051), train_loss = 2.15882403, grad/param norm = 2.4075e-01, time/batch = 0.6855s	
1373/33450 (epoch 2.052), train_loss = 2.28246176, grad/param norm = 2.3200e-01, time/batch = 0.7188s	
1374/33450 (epoch 2.054), train_loss = 2.13066289, grad/param norm = 2.3993e-01, time/batch = 0.6954s	
1375/33450 (epoch 2.055), train_loss = 2.28489874, grad/param norm = 3.0151e-01, time/batch = 0.6819s	
1376/33450 (epoch 2.057), train_loss = 2.20391473, grad/param norm = 2.9493e-01, time/batch = 0.6802s	
1377/33450 (epoch 2.058), train_loss = 2.05693233, grad/param norm = 2.5631e-01, time/batch = 0.6778s	
1378/33450 (epoch 2.060), train_loss = 2.13421347, grad/param norm = 2.3711e-01, time/batch = 0.6737s	
1379/33450 (epoch 2.061), train_loss = 2.13985114, grad/param norm = 2.2440e-01, time/batch = 0.6731s	
1380/33450 (epoch 2.063), train_loss = 2.09471096, grad/param norm = 2.2326e-01, time/batch = 0.6742s	
1381/33450 (epoch 2.064), train_loss = 2.08414620, grad/param norm = 3.3113e-01, time/batch = 0.6752s	
1382/33450 (epoch 2.066), train_loss = 2.10792991, grad/param norm = 2.4965e-01, time/batch = 0.6738s	
1383/33450 (epoch 2.067), train_loss = 2.19474639, grad/param norm = 2.3272e-01, time/batch = 0.6750s	
1384/33450 (epoch 2.069), train_loss = 2.24257970, grad/param norm = 2.3941e-01, time/batch = 0.6757s	
1385/33450 (epoch 2.070), train_loss = 2.13549449, grad/param norm = 2.3053e-01, time/batch = 0.6849s	
1386/33450 (epoch 2.072), train_loss = 2.14484816, grad/param norm = 2.4134e-01, time/batch = 0.6761s	
1387/33450 (epoch 2.073), train_loss = 2.12649718, grad/param norm = 2.1982e-01, time/batch = 0.7026s	
1388/33450 (epoch 2.075), train_loss = 2.13762661, grad/param norm = 2.6576e-01, time/batch = 0.7081s	
1389/33450 (epoch 2.076), train_loss = 2.19440246, grad/param norm = 2.5538e-01, time/batch = 0.6776s	
1390/33450 (epoch 2.078), train_loss = 2.16608891, grad/param norm = 2.2426e-01, time/batch = 0.6742s	
1391/33450 (epoch 2.079), train_loss = 2.00956915, grad/param norm = 2.3357e-01, time/batch = 0.6798s	
1392/33450 (epoch 2.081), train_loss = 2.14367947, grad/param norm = 2.4906e-01, time/batch = 0.6768s	
1393/33450 (epoch 2.082), train_loss = 2.22591030, grad/param norm = 2.6037e-01, time/batch = 0.6757s	
1394/33450 (epoch 2.084), train_loss = 2.12271197, grad/param norm = 2.4295e-01, time/batch = 0.6776s	
1395/33450 (epoch 2.085), train_loss = 2.19220257, grad/param norm = 2.2947e-01, time/batch = 0.6756s	
1396/33450 (epoch 2.087), train_loss = 2.26199959, grad/param norm = 2.1121e-01, time/batch = 0.6736s	
1397/33450 (epoch 2.088), train_loss = 2.15116933, grad/param norm = 2.1869e-01, time/batch = 0.6741s	
1398/33450 (epoch 2.090), train_loss = 2.27233403, grad/param norm = 2.6115e-01, time/batch = 0.6747s	
1399/33450 (epoch 2.091), train_loss = 2.07239350, grad/param norm = 2.2769e-01, time/batch = 0.6736s	
1400/33450 (epoch 2.093), train_loss = 1.93664408, grad/param norm = 2.2525e-01, time/batch = 0.6746s	
1401/33450 (epoch 2.094), train_loss = 2.04036984, grad/param norm = 2.0913e-01, time/batch = 0.6985s	
1402/33450 (epoch 2.096), train_loss = 1.99809422, grad/param norm = 2.3078e-01, time/batch = 0.7202s	
1403/33450 (epoch 2.097), train_loss = 2.24109366, grad/param norm = 2.4778e-01, time/batch = 0.7105s	
1404/33450 (epoch 2.099), train_loss = 2.13972262, grad/param norm = 2.2027e-01, time/batch = 0.7078s	
1405/33450 (epoch 2.100), train_loss = 2.18280420, grad/param norm = 2.2577e-01, time/batch = 0.7058s	
1406/33450 (epoch 2.102), train_loss = 2.25445575, grad/param norm = 2.2935e-01, time/batch = 0.6980s	
1407/33450 (epoch 2.103), train_loss = 2.30936154, grad/param norm = 2.7743e-01, time/batch = 0.7066s	
1408/33450 (epoch 2.105), train_loss = 2.09414433, grad/param norm = 2.5150e-01, time/batch = 0.7019s	
1409/33450 (epoch 2.106), train_loss = 2.06854166, grad/param norm = 2.2233e-01, time/batch = 0.7081s	
1410/33450 (epoch 2.108), train_loss = 2.20525258, grad/param norm = 2.1355e-01, time/batch = 0.7042s	
1411/33450 (epoch 2.109), train_loss = 2.19252040, grad/param norm = 2.2903e-01, time/batch = 0.7034s	
1412/33450 (epoch 2.111), train_loss = 2.26078984, grad/param norm = 2.5885e-01, time/batch = 0.6887s	
1413/33450 (epoch 2.112), train_loss = 2.31817726, grad/param norm = 2.3687e-01, time/batch = 0.6853s	
1414/33450 (epoch 2.114), train_loss = 2.27602798, grad/param norm = 2.8977e-01, time/batch = 0.6853s	
1415/33450 (epoch 2.115), train_loss = 2.17625047, grad/param norm = 2.4345e-01, time/batch = 0.6884s	
1416/33450 (epoch 2.117), train_loss = 2.21882525, grad/param norm = 2.3581e-01, time/batch = 0.6871s	
1417/33450 (epoch 2.118), train_loss = 2.17814589, grad/param norm = 2.3404e-01, time/batch = 0.6834s	
1418/33450 (epoch 2.120), train_loss = 2.37501045, grad/param norm = 2.7179e-01, time/batch = 0.6973s	
1419/33450 (epoch 2.121), train_loss = 2.06545580, grad/param norm = 2.1164e-01, time/batch = 0.6902s	
1420/33450 (epoch 2.123), train_loss = 2.23206498, grad/param norm = 2.3384e-01, time/batch = 0.6827s	
1421/33450 (epoch 2.124), train_loss = 2.05025291, grad/param norm = 2.4592e-01, time/batch = 0.6820s	
1422/33450 (epoch 2.126), train_loss = 2.11502141, grad/param norm = 2.3123e-01, time/batch = 0.6755s	
1423/33450 (epoch 2.127), train_loss = 2.21186074, grad/param norm = 2.1360e-01, time/batch = 0.6744s	
1424/33450 (epoch 2.129), train_loss = 2.16314721, grad/param norm = 2.0549e-01, time/batch = 0.6785s	
1425/33450 (epoch 2.130), train_loss = 2.30719472, grad/param norm = 2.6963e-01, time/batch = 0.6818s	
1426/33450 (epoch 2.132), train_loss = 2.28086243, grad/param norm = 2.8639e-01, time/batch = 0.6756s	
1427/33450 (epoch 2.133), train_loss = 2.33791323, grad/param norm = 2.7637e-01, time/batch = 0.6749s	
1428/33450 (epoch 2.135), train_loss = 2.22409007, grad/param norm = 2.2141e-01, time/batch = 0.6747s	
1429/33450 (epoch 2.136), train_loss = 2.30691643, grad/param norm = 2.2701e-01, time/batch = 0.6752s	
1430/33450 (epoch 2.138), train_loss = 2.21451697, grad/param norm = 2.3333e-01, time/batch = 0.6755s	
1431/33450 (epoch 2.139), train_loss = 2.01210040, grad/param norm = 2.2738e-01, time/batch = 0.6802s	
1432/33450 (epoch 2.141), train_loss = 1.99609609, grad/param norm = 2.1546e-01, time/batch = 0.6832s	
1433/33450 (epoch 2.142), train_loss = 2.11150107, grad/param norm = 2.1716e-01, time/batch = 0.6818s	
1434/33450 (epoch 2.143), train_loss = 2.50607547, grad/param norm = 2.6695e-01, time/batch = 0.6879s	
1435/33450 (epoch 2.145), train_loss = 2.20616647, grad/param norm = 2.4385e-01, time/batch = 0.6841s	
1436/33450 (epoch 2.146), train_loss = 2.09446363, grad/param norm = 2.2559e-01, time/batch = 0.6722s	
1437/33450 (epoch 2.148), train_loss = 2.17991783, grad/param norm = 2.5638e-01, time/batch = 0.6721s	
1438/33450 (epoch 2.149), train_loss = 2.27516988, grad/param norm = 2.7768e-01, time/batch = 0.6774s	
1439/33450 (epoch 2.151), train_loss = 2.31511594, grad/param norm = 2.3111e-01, time/batch = 0.6738s	
1440/33450 (epoch 2.152), train_loss = 2.25994600, grad/param norm = 2.6590e-01, time/batch = 0.6737s	
1441/33450 (epoch 2.154), train_loss = 2.27598333, grad/param norm = 3.7075e-01, time/batch = 0.6977s	
1442/33450 (epoch 2.155), train_loss = 2.28964042, grad/param norm = 3.0991e-01, time/batch = 0.6935s	
1443/33450 (epoch 2.157), train_loss = 2.20093864, grad/param norm = 2.3273e-01, time/batch = 0.6734s	
1444/33450 (epoch 2.158), train_loss = 2.30976214, grad/param norm = 2.4014e-01, time/batch = 0.6767s	
1445/33450 (epoch 2.160), train_loss = 2.15584438, grad/param norm = 2.1305e-01, time/batch = 0.6986s	
1446/33450 (epoch 2.161), train_loss = 2.13607797, grad/param norm = 2.2703e-01, time/batch = 0.7118s	
1447/33450 (epoch 2.163), train_loss = 2.03015224, grad/param norm = 2.0582e-01, time/batch = 0.6761s	
1448/33450 (epoch 2.164), train_loss = 2.19792562, grad/param norm = 2.2638e-01, time/batch = 0.6721s	
1449/33450 (epoch 2.166), train_loss = 2.22524746, grad/param norm = 2.3020e-01, time/batch = 0.6743s	
1450/33450 (epoch 2.167), train_loss = 2.16346611, grad/param norm = 2.7355e-01, time/batch = 0.6721s	
1451/33450 (epoch 2.169), train_loss = 2.23072155, grad/param norm = 2.7165e-01, time/batch = 0.6737s	
1452/33450 (epoch 2.170), train_loss = 2.20274246, grad/param norm = 2.4307e-01, time/batch = 0.6741s	
1453/33450 (epoch 2.172), train_loss = 2.08711308, grad/param norm = 2.4851e-01, time/batch = 0.6757s	
1454/33450 (epoch 2.173), train_loss = 2.16452756, grad/param norm = 2.5760e-01, time/batch = 0.6732s	
1455/33450 (epoch 2.175), train_loss = 2.40084992, grad/param norm = 2.6457e-01, time/batch = 0.6724s	
1456/33450 (epoch 2.176), train_loss = 2.29208010, grad/param norm = 2.6911e-01, time/batch = 0.6747s	
1457/33450 (epoch 2.178), train_loss = 2.15494436, grad/param norm = 3.2968e-01, time/batch = 0.6757s	
1458/33450 (epoch 2.179), train_loss = 2.06303170, grad/param norm = 2.3589e-01, time/batch = 0.6738s	
1459/33450 (epoch 2.181), train_loss = 2.22667018, grad/param norm = 2.2758e-01, time/batch = 0.6729s	
1460/33450 (epoch 2.182), train_loss = 2.22366231, grad/param norm = 2.1984e-01, time/batch = 0.7168s	
1461/33450 (epoch 2.184), train_loss = 2.05264738, grad/param norm = 2.3023e-01, time/batch = 0.7112s	
1462/33450 (epoch 2.185), train_loss = 2.11303927, grad/param norm = 2.4253e-01, time/batch = 0.6871s	
1463/33450 (epoch 2.187), train_loss = 1.99956333, grad/param norm = 1.9637e-01, time/batch = 0.6862s	
1464/33450 (epoch 2.188), train_loss = 2.09485738, grad/param norm = 2.5833e-01, time/batch = 0.6876s	
1465/33450 (epoch 2.190), train_loss = 2.21750740, grad/param norm = 2.3821e-01, time/batch = 0.6977s	
1466/33450 (epoch 2.191), train_loss = 2.27536603, grad/param norm = 2.4444e-01, time/batch = 0.6826s	
1467/33450 (epoch 2.193), train_loss = 2.28320364, grad/param norm = 2.5477e-01, time/batch = 0.6766s	
1468/33450 (epoch 2.194), train_loss = 2.27478103, grad/param norm = 2.9477e-01, time/batch = 0.6769s	
1469/33450 (epoch 2.196), train_loss = 2.13195326, grad/param norm = 2.2788e-01, time/batch = 0.6747s	
1470/33450 (epoch 2.197), train_loss = 2.13869759, grad/param norm = 2.2552e-01, time/batch = 0.6729s	
1471/33450 (epoch 2.199), train_loss = 2.08145344, grad/param norm = 2.1627e-01, time/batch = 0.6753s	
1472/33450 (epoch 2.200), train_loss = 2.33107503, grad/param norm = 2.4025e-01, time/batch = 0.6735s	
1473/33450 (epoch 2.202), train_loss = 2.15955854, grad/param norm = 2.4155e-01, time/batch = 0.6747s	
1474/33450 (epoch 2.203), train_loss = 1.98305307, grad/param norm = 2.1184e-01, time/batch = 0.6741s	
1475/33450 (epoch 2.205), train_loss = 2.20887196, grad/param norm = 2.5275e-01, time/batch = 0.6725s	
1476/33450 (epoch 2.206), train_loss = 2.28120790, grad/param norm = 2.5409e-01, time/batch = 0.6803s	
1477/33450 (epoch 2.208), train_loss = 2.18050372, grad/param norm = 3.2682e-01, time/batch = 0.6729s	
1478/33450 (epoch 2.209), train_loss = 2.29691603, grad/param norm = 2.4680e-01, time/batch = 0.6721s	
1479/33450 (epoch 2.211), train_loss = 2.15448258, grad/param norm = 2.4995e-01, time/batch = 0.6744s	
1480/33450 (epoch 2.212), train_loss = 2.22320662, grad/param norm = 2.9921e-01, time/batch = 0.6755s	
1481/33450 (epoch 2.214), train_loss = 2.24140769, grad/param norm = 2.4183e-01, time/batch = 0.6774s	
1482/33450 (epoch 2.215), train_loss = 2.24434817, grad/param norm = 2.3096e-01, time/batch = 0.6789s	
1483/33450 (epoch 2.217), train_loss = 2.11427769, grad/param norm = 2.3344e-01, time/batch = 0.6753s	
1484/33450 (epoch 2.218), train_loss = 2.12851003, grad/param norm = 2.4240e-01, time/batch = 0.6748s	
1485/33450 (epoch 2.220), train_loss = 1.98311008, grad/param norm = 2.1825e-01, time/batch = 0.6827s	
1486/33450 (epoch 2.221), train_loss = 2.34826371, grad/param norm = 2.8687e-01, time/batch = 0.6741s	
1487/33450 (epoch 2.223), train_loss = 2.27232491, grad/param norm = 2.3437e-01, time/batch = 0.6741s	
1488/33450 (epoch 2.224), train_loss = 2.14641770, grad/param norm = 2.2138e-01, time/batch = 0.6759s	
1489/33450 (epoch 2.226), train_loss = 2.18773806, grad/param norm = 2.1617e-01, time/batch = 0.6909s	
1490/33450 (epoch 2.227), train_loss = 2.14904018, grad/param norm = 2.3218e-01, time/batch = 0.6967s	
1491/33450 (epoch 2.229), train_loss = 2.05301256, grad/param norm = 2.2180e-01, time/batch = 0.6817s	
1492/33450 (epoch 2.230), train_loss = 2.07915997, grad/param norm = 2.3529e-01, time/batch = 0.6802s	
1493/33450 (epoch 2.232), train_loss = 2.23477993, grad/param norm = 2.4492e-01, time/batch = 0.6742s	
1494/33450 (epoch 2.233), train_loss = 2.19518196, grad/param norm = 2.2218e-01, time/batch = 0.6753s	
1495/33450 (epoch 2.235), train_loss = 2.11472189, grad/param norm = 2.6654e-01, time/batch = 0.6842s	
1496/33450 (epoch 2.236), train_loss = 2.09447626, grad/param norm = 2.6685e-01, time/batch = 0.6993s	
1497/33450 (epoch 2.238), train_loss = 2.03430846, grad/param norm = 2.5887e-01, time/batch = 0.7024s	
1498/33450 (epoch 2.239), train_loss = 2.21226243, grad/param norm = 2.9462e-01, time/batch = 0.6757s	
1499/33450 (epoch 2.241), train_loss = 2.37316027, grad/param norm = 2.4060e-01, time/batch = 0.6754s	
1500/33450 (epoch 2.242), train_loss = 2.22707582, grad/param norm = 2.7596e-01, time/batch = 0.6733s	
1501/33450 (epoch 2.244), train_loss = 2.31574868, grad/param norm = 2.3952e-01, time/batch = 0.6739s	
1502/33450 (epoch 2.245), train_loss = 2.08607781, grad/param norm = 2.8005e-01, time/batch = 0.6744s	
1503/33450 (epoch 2.247), train_loss = 2.25774945, grad/param norm = 2.6668e-01, time/batch = 0.6785s	
1504/33450 (epoch 2.248), train_loss = 1.98681358, grad/param norm = 2.6126e-01, time/batch = 0.6929s	
1505/33450 (epoch 2.250), train_loss = 2.03078817, grad/param norm = 2.2200e-01, time/batch = 0.6926s	
1506/33450 (epoch 2.251), train_loss = 2.03217015, grad/param norm = 2.5111e-01, time/batch = 0.6744s	
1507/33450 (epoch 2.253), train_loss = 2.17030099, grad/param norm = 3.2216e-01, time/batch = 0.6732s	
1508/33450 (epoch 2.254), train_loss = 2.25735144, grad/param norm = 3.3827e-01, time/batch = 0.6742s	
1509/33450 (epoch 2.256), train_loss = 2.42692198, grad/param norm = 3.8234e-01, time/batch = 0.6740s	
1510/33450 (epoch 2.257), train_loss = 2.12237833, grad/param norm = 2.9428e-01, time/batch = 0.6751s	
1511/33450 (epoch 2.259), train_loss = 2.09917008, grad/param norm = 2.5368e-01, time/batch = 0.6773s	
1512/33450 (epoch 2.260), train_loss = 2.19010695, grad/param norm = 2.1932e-01, time/batch = 0.6798s	
1513/33450 (epoch 2.262), train_loss = 2.31834327, grad/param norm = 2.5010e-01, time/batch = 0.6769s	
1514/33450 (epoch 2.263), train_loss = 2.19392609, grad/param norm = 2.2555e-01, time/batch = 0.6766s	
1515/33450 (epoch 2.265), train_loss = 2.15059718, grad/param norm = 2.4248e-01, time/batch = 0.6749s	
1516/33450 (epoch 2.266), train_loss = 2.29793891, grad/param norm = 2.3574e-01, time/batch = 0.6744s	
1517/33450 (epoch 2.268), train_loss = 2.16348057, grad/param norm = 2.1088e-01, time/batch = 0.6752s	
1518/33450 (epoch 2.269), train_loss = 1.99799039, grad/param norm = 2.2423e-01, time/batch = 0.6919s	
1519/33450 (epoch 2.271), train_loss = 2.12783841, grad/param norm = 2.8971e-01, time/batch = 0.7189s	
1520/33450 (epoch 2.272), train_loss = 2.17781506, grad/param norm = 2.6834e-01, time/batch = 0.6846s	
1521/33450 (epoch 2.274), train_loss = 2.10981727, grad/param norm = 2.4515e-01, time/batch = 0.6782s	
1522/33450 (epoch 2.275), train_loss = 2.17668773, grad/param norm = 2.2344e-01, time/batch = 0.6760s	
1523/33450 (epoch 2.277), train_loss = 2.00088902, grad/param norm = 2.2306e-01, time/batch = 0.6754s	
1524/33450 (epoch 2.278), train_loss = 2.10159451, grad/param norm = 2.2439e-01, time/batch = 0.6738s	
1525/33450 (epoch 2.280), train_loss = 2.07685578, grad/param norm = 2.3019e-01, time/batch = 0.6753s	
1526/33450 (epoch 2.281), train_loss = 2.20753504, grad/param norm = 2.2849e-01, time/batch = 0.6793s	
1527/33450 (epoch 2.283), train_loss = 2.07840618, grad/param norm = 2.5300e-01, time/batch = 0.6767s	
1528/33450 (epoch 2.284), train_loss = 2.23380748, grad/param norm = 2.6073e-01, time/batch = 0.6764s	
1529/33450 (epoch 2.286), train_loss = 2.18278658, grad/param norm = 2.1815e-01, time/batch = 0.6743s	
1530/33450 (epoch 2.287), train_loss = 2.01449291, grad/param norm = 2.5278e-01, time/batch = 0.6748s	
1531/33450 (epoch 2.288), train_loss = 2.11321927, grad/param norm = 2.2982e-01, time/batch = 0.6775s	
1532/33450 (epoch 2.290), train_loss = 2.12759635, grad/param norm = 2.1515e-01, time/batch = 0.6798s	
1533/33450 (epoch 2.291), train_loss = 2.18388933, grad/param norm = 2.4365e-01, time/batch = 0.7068s	
1534/33450 (epoch 2.293), train_loss = 2.10665664, grad/param norm = 2.5816e-01, time/batch = 0.7042s	
1535/33450 (epoch 2.294), train_loss = 2.05454307, grad/param norm = 2.1035e-01, time/batch = 0.6840s	
1536/33450 (epoch 2.296), train_loss = 2.13851820, grad/param norm = 2.1559e-01, time/batch = 0.6739s	
1537/33450 (epoch 2.297), train_loss = 2.21129779, grad/param norm = 2.5395e-01, time/batch = 0.6727s	
1538/33450 (epoch 2.299), train_loss = 2.14819050, grad/param norm = 2.8360e-01, time/batch = 0.6747s	
1539/33450 (epoch 2.300), train_loss = 2.18835776, grad/param norm = 2.6386e-01, time/batch = 0.6747s	
1540/33450 (epoch 2.302), train_loss = 2.14486335, grad/param norm = 2.6661e-01, time/batch = 0.6754s	
1541/33450 (epoch 2.303), train_loss = 2.07932405, grad/param norm = 3.2726e-01, time/batch = 0.6765s	
1542/33450 (epoch 2.305), train_loss = 2.26517139, grad/param norm = 2.6941e-01, time/batch = 0.6764s	
1543/33450 (epoch 2.306), train_loss = 2.36202063, grad/param norm = 2.9414e-01, time/batch = 0.6807s	
1544/33450 (epoch 2.308), train_loss = 2.17793005, grad/param norm = 2.2048e-01, time/batch = 0.7143s	
1545/33450 (epoch 2.309), train_loss = 2.23696258, grad/param norm = 2.3863e-01, time/batch = 0.6752s	
1546/33450 (epoch 2.311), train_loss = 2.13866787, grad/param norm = 2.3171e-01, time/batch = 0.6747s	
1547/33450 (epoch 2.312), train_loss = 2.30927999, grad/param norm = 2.4588e-01, time/batch = 0.6817s	
1548/33450 (epoch 2.314), train_loss = 2.09313118, grad/param norm = 2.4257e-01, time/batch = 0.7181s	
1549/33450 (epoch 2.315), train_loss = 2.07498127, grad/param norm = 2.1980e-01, time/batch = 0.6991s	
1550/33450 (epoch 2.317), train_loss = 2.13661344, grad/param norm = 2.3462e-01, time/batch = 0.6916s	
1551/33450 (epoch 2.318), train_loss = 2.15537570, grad/param norm = 2.1661e-01, time/batch = 0.6840s	
1552/33450 (epoch 2.320), train_loss = 2.05267389, grad/param norm = 2.3583e-01, time/batch = 0.6831s	
1553/33450 (epoch 2.321), train_loss = 2.05300382, grad/param norm = 2.7583e-01, time/batch = 0.6749s	
1554/33450 (epoch 2.323), train_loss = 1.95748626, grad/param norm = 2.5396e-01, time/batch = 0.6750s	
1555/33450 (epoch 2.324), train_loss = 1.98403595, grad/param norm = 2.2635e-01, time/batch = 0.6781s	
1556/33450 (epoch 2.326), train_loss = 2.04722156, grad/param norm = 2.4963e-01, time/batch = 0.6913s	
1557/33450 (epoch 2.327), train_loss = 2.07152596, grad/param norm = 2.6135e-01, time/batch = 0.6835s	
1558/33450 (epoch 2.329), train_loss = 2.10127757, grad/param norm = 2.4173e-01, time/batch = 0.6758s	
1559/33450 (epoch 2.330), train_loss = 2.18797646, grad/param norm = 2.5698e-01, time/batch = 0.6767s	
1560/33450 (epoch 2.332), train_loss = 2.26176171, grad/param norm = 3.0863e-01, time/batch = 0.6742s	
1561/33450 (epoch 2.333), train_loss = 1.92826491, grad/param norm = 2.3567e-01, time/batch = 0.6753s	
1562/33450 (epoch 2.335), train_loss = 2.21394219, grad/param norm = 2.2896e-01, time/batch = 0.7011s	
1563/33450 (epoch 2.336), train_loss = 2.10196408, grad/param norm = 2.2921e-01, time/batch = 0.7074s	
1564/33450 (epoch 2.338), train_loss = 1.98328151, grad/param norm = 2.0496e-01, time/batch = 0.6817s	
1565/33450 (epoch 2.339), train_loss = 1.95962397, grad/param norm = 1.9291e-01, time/batch = 0.6795s	
1566/33450 (epoch 2.341), train_loss = 2.23004807, grad/param norm = 2.3703e-01, time/batch = 0.6878s	
1567/33450 (epoch 2.342), train_loss = 2.11602395, grad/param norm = 2.2363e-01, time/batch = 0.6745s	
1568/33450 (epoch 2.344), train_loss = 2.17278370, grad/param norm = 2.1315e-01, time/batch = 0.6725s	
1569/33450 (epoch 2.345), train_loss = 2.05928572, grad/param norm = 2.2002e-01, time/batch = 0.6738s	
1570/33450 (epoch 2.347), train_loss = 2.04720051, grad/param norm = 2.9265e-01, time/batch = 0.6762s	
1571/33450 (epoch 2.348), train_loss = 2.04798352, grad/param norm = 2.3165e-01, time/batch = 0.6745s	
1572/33450 (epoch 2.350), train_loss = 2.26931221, grad/param norm = 2.6213e-01, time/batch = 0.6731s	
1573/33450 (epoch 2.351), train_loss = 2.10232319, grad/param norm = 2.4288e-01, time/batch = 0.6758s	
1574/33450 (epoch 2.353), train_loss = 1.99661424, grad/param norm = 2.3729e-01, time/batch = 0.6726s	
1575/33450 (epoch 2.354), train_loss = 1.99266230, grad/param norm = 2.2844e-01, time/batch = 0.6709s	
1576/33450 (epoch 2.356), train_loss = 2.09954025, grad/param norm = 2.5975e-01, time/batch = 0.6738s	
1577/33450 (epoch 2.357), train_loss = 1.95048892, grad/param norm = 3.9716e-01, time/batch = 0.7172s	
1578/33450 (epoch 2.359), train_loss = 2.01243407, grad/param norm = 2.5276e-01, time/batch = 0.6967s	
1579/33450 (epoch 2.360), train_loss = 2.18368431, grad/param norm = 2.5593e-01, time/batch = 0.6755s	
1580/33450 (epoch 2.362), train_loss = 2.19500638, grad/param norm = 2.2567e-01, time/batch = 0.6774s	
1581/33450 (epoch 2.363), train_loss = 2.13494077, grad/param norm = 2.5943e-01, time/batch = 0.6734s	
1582/33450 (epoch 2.365), train_loss = 2.07395507, grad/param norm = 2.0149e-01, time/batch = 0.6738s	
1583/33450 (epoch 2.366), train_loss = 2.20364714, grad/param norm = 2.3522e-01, time/batch = 0.6734s	
1584/33450 (epoch 2.368), train_loss = 2.16359081, grad/param norm = 2.1155e-01, time/batch = 0.6737s	
1585/33450 (epoch 2.369), train_loss = 2.05202558, grad/param norm = 2.1783e-01, time/batch = 0.6824s	
1586/33450 (epoch 2.371), train_loss = 2.13750715, grad/param norm = 2.4926e-01, time/batch = 0.6739s	
1587/33450 (epoch 2.372), train_loss = 2.18402682, grad/param norm = 2.4954e-01, time/batch = 0.6730s	
1588/33450 (epoch 2.374), train_loss = 2.44060791, grad/param norm = 2.3906e-01, time/batch = 0.6729s	
1589/33450 (epoch 2.375), train_loss = 2.24377139, grad/param norm = 2.3430e-01, time/batch = 0.6723s	
1590/33450 (epoch 2.377), train_loss = 2.17055475, grad/param norm = 2.8499e-01, time/batch = 0.6763s	
1591/33450 (epoch 2.378), train_loss = 2.27813519, grad/param norm = 2.5246e-01, time/batch = 0.6769s	
1592/33450 (epoch 2.380), train_loss = 2.23379662, grad/param norm = 2.1668e-01, time/batch = 0.6742s	
1593/33450 (epoch 2.381), train_loss = 2.17174828, grad/param norm = 2.1012e-01, time/batch = 0.6774s	
1594/33450 (epoch 2.383), train_loss = 2.23090326, grad/param norm = 2.1577e-01, time/batch = 0.6858s	
1595/33450 (epoch 2.384), train_loss = 2.15663190, grad/param norm = 2.1625e-01, time/batch = 0.7170s	
1596/33450 (epoch 2.386), train_loss = 2.16985790, grad/param norm = 2.2367e-01, time/batch = 0.6911s	
1597/33450 (epoch 2.387), train_loss = 2.26933544, grad/param norm = 2.5817e-01, time/batch = 0.6923s	
1598/33450 (epoch 2.389), train_loss = 2.25995363, grad/param norm = 2.7067e-01, time/batch = 0.6939s	
1599/33450 (epoch 2.390), train_loss = 2.23177744, grad/param norm = 2.3177e-01, time/batch = 0.6898s	
1600/33450 (epoch 2.392), train_loss = 2.16862974, grad/param norm = 2.4485e-01, time/batch = 0.6858s	
1601/33450 (epoch 2.393), train_loss = 1.99864449, grad/param norm = 2.2800e-01, time/batch = 0.6960s	
1602/33450 (epoch 2.395), train_loss = 2.05402583, grad/param norm = 2.2424e-01, time/batch = 0.7014s	
1603/33450 (epoch 2.396), train_loss = 2.14349210, grad/param norm = 2.2968e-01, time/batch = 0.6933s	
1604/33450 (epoch 2.398), train_loss = 2.29979936, grad/param norm = 2.3921e-01, time/batch = 0.6947s	
1605/33450 (epoch 2.399), train_loss = 2.29566821, grad/param norm = 3.4280e-01, time/batch = 0.6866s	
1606/33450 (epoch 2.401), train_loss = 2.32024691, grad/param norm = 2.3436e-01, time/batch = 0.6737s	
1607/33450 (epoch 2.402), train_loss = 2.02391259, grad/param norm = 2.2877e-01, time/batch = 0.6722s	
1608/33450 (epoch 2.404), train_loss = 2.07528229, grad/param norm = 2.1484e-01, time/batch = 0.6776s	
1609/33450 (epoch 2.405), train_loss = 2.11151637, grad/param norm = 2.2645e-01, time/batch = 0.6728s	
1610/33450 (epoch 2.407), train_loss = 2.08642985, grad/param norm = 2.2143e-01, time/batch = 0.6714s	
1611/33450 (epoch 2.408), train_loss = 2.27497144, grad/param norm = 2.6703e-01, time/batch = 0.6739s	
1612/33450 (epoch 2.410), train_loss = 2.18509034, grad/param norm = 2.6774e-01, time/batch = 0.6833s	
1613/33450 (epoch 2.411), train_loss = 2.04785475, grad/param norm = 2.2698e-01, time/batch = 0.6929s	
1614/33450 (epoch 2.413), train_loss = 2.12646915, grad/param norm = 2.4180e-01, time/batch = 0.7065s	
1615/33450 (epoch 2.414), train_loss = 2.17937377, grad/param norm = 2.2735e-01, time/batch = 0.6728s	
1616/33450 (epoch 2.416), train_loss = 2.14756691, grad/param norm = 2.2751e-01, time/batch = 0.6738s	
1617/33450 (epoch 2.417), train_loss = 2.05393467, grad/param norm = 2.5635e-01, time/batch = 0.6727s	
1618/33450 (epoch 2.419), train_loss = 1.96653246, grad/param norm = 2.7112e-01, time/batch = 0.6721s	
1619/33450 (epoch 2.420), train_loss = 2.09917963, grad/param norm = 2.3124e-01, time/batch = 0.6717s	
1620/33450 (epoch 2.422), train_loss = 1.94159728, grad/param norm = 2.1408e-01, time/batch = 0.6729s	
1621/33450 (epoch 2.423), train_loss = 2.11237936, grad/param norm = 2.2602e-01, time/batch = 0.6740s	
1622/33450 (epoch 2.425), train_loss = 2.00415998, grad/param norm = 2.0821e-01, time/batch = 0.6783s	
1623/33450 (epoch 2.426), train_loss = 2.06379251, grad/param norm = 2.2344e-01, time/batch = 0.6775s	
1624/33450 (epoch 2.428), train_loss = 2.02885999, grad/param norm = 2.4585e-01, time/batch = 0.6792s	
1625/33450 (epoch 2.429), train_loss = 2.11409091, grad/param norm = 2.2518e-01, time/batch = 0.6761s	
1626/33450 (epoch 2.430), train_loss = 2.05376753, grad/param norm = 2.5709e-01, time/batch = 0.6743s	
1627/33450 (epoch 2.432), train_loss = 2.12148911, grad/param norm = 2.3646e-01, time/batch = 0.6963s	
1628/33450 (epoch 2.433), train_loss = 2.13406731, grad/param norm = 2.3065e-01, time/batch = 0.6916s	
1629/33450 (epoch 2.435), train_loss = 2.02783999, grad/param norm = 2.1066e-01, time/batch = 0.6940s	
1630/33450 (epoch 2.436), train_loss = 2.02512311, grad/param norm = 1.9673e-01, time/batch = 0.7149s	
1631/33450 (epoch 2.438), train_loss = 2.02701740, grad/param norm = 2.2289e-01, time/batch = 0.6752s	
1632/33450 (epoch 2.439), train_loss = 2.09528627, grad/param norm = 2.2721e-01, time/batch = 0.6763s	
1633/33450 (epoch 2.441), train_loss = 2.33220746, grad/param norm = 2.3293e-01, time/batch = 0.6730s	
1634/33450 (epoch 2.442), train_loss = 2.11333087, grad/param norm = 2.0869e-01, time/batch = 0.6730s	
1635/33450 (epoch 2.444), train_loss = 2.21785284, grad/param norm = 2.3584e-01, time/batch = 0.7009s	
1636/33450 (epoch 2.445), train_loss = 2.23251442, grad/param norm = 2.7015e-01, time/batch = 0.7144s	
1637/33450 (epoch 2.447), train_loss = 2.22557738, grad/param norm = 2.4480e-01, time/batch = 0.6829s	
1638/33450 (epoch 2.448), train_loss = 2.16580879, grad/param norm = 2.3102e-01, time/batch = 0.6916s	
1639/33450 (epoch 2.450), train_loss = 2.08874621, grad/param norm = 2.2993e-01, time/batch = 0.6996s	
1640/33450 (epoch 2.451), train_loss = 2.19735176, grad/param norm = 2.4890e-01, time/batch = 0.6997s	
1641/33450 (epoch 2.453), train_loss = 2.04813688, grad/param norm = 2.0748e-01, time/batch = 0.6796s	
1642/33450 (epoch 2.454), train_loss = 2.06997280, grad/param norm = 2.3773e-01, time/batch = 0.6756s	
1643/33450 (epoch 2.456), train_loss = 2.01870298, grad/param norm = 2.4616e-01, time/batch = 0.6737s	
1644/33450 (epoch 2.457), train_loss = 2.17525797, grad/param norm = 2.4314e-01, time/batch = 0.6748s	
1645/33450 (epoch 2.459), train_loss = 2.00485269, grad/param norm = 2.2354e-01, time/batch = 0.6720s	
1646/33450 (epoch 2.460), train_loss = 2.29721620, grad/param norm = 2.3260e-01, time/batch = 0.6724s	
1647/33450 (epoch 2.462), train_loss = 2.31840868, grad/param norm = 2.4614e-01, time/batch = 0.6722s	
1648/33450 (epoch 2.463), train_loss = 2.05653499, grad/param norm = 2.6884e-01, time/batch = 0.6743s	
1649/33450 (epoch 2.465), train_loss = 2.02832889, grad/param norm = 2.5137e-01, time/batch = 0.6760s	
1650/33450 (epoch 2.466), train_loss = 2.17262588, grad/param norm = 2.4683e-01, time/batch = 0.7177s	
1651/33450 (epoch 2.468), train_loss = 2.18162357, grad/param norm = 2.3553e-01, time/batch = 0.6911s	
1652/33450 (epoch 2.469), train_loss = 2.23504444, grad/param norm = 2.7182e-01, time/batch = 0.6738s	
1653/33450 (epoch 2.471), train_loss = 2.18723059, grad/param norm = 2.3653e-01, time/batch = 0.6838s	
1654/33450 (epoch 2.472), train_loss = 2.10403313, grad/param norm = 2.2912e-01, time/batch = 0.6760s	
1655/33450 (epoch 2.474), train_loss = 2.42468284, grad/param norm = 2.6284e-01, time/batch = 0.6744s	
1656/33450 (epoch 2.475), train_loss = 2.19655212, grad/param norm = 2.6397e-01, time/batch = 0.6748s	
1657/33450 (epoch 2.477), train_loss = 2.02323127, grad/param norm = 2.2615e-01, time/batch = 0.6751s	
1658/33450 (epoch 2.478), train_loss = 1.97785231, grad/param norm = 2.1164e-01, time/batch = 0.6755s	
1659/33450 (epoch 2.480), train_loss = 1.87337042, grad/param norm = 2.1351e-01, time/batch = 0.6718s	
1660/33450 (epoch 2.481), train_loss = 1.96322549, grad/param norm = 2.0918e-01, time/batch = 0.6725s	
1661/33450 (epoch 2.483), train_loss = 1.93598783, grad/param norm = 2.5248e-01, time/batch = 0.6758s	
1662/33450 (epoch 2.484), train_loss = 2.06439623, grad/param norm = 2.3624e-01, time/batch = 0.6797s	
1663/33450 (epoch 2.486), train_loss = 2.16706574, grad/param norm = 2.2962e-01, time/batch = 0.6755s	
1664/33450 (epoch 2.487), train_loss = 2.04693855, grad/param norm = 2.3226e-01, time/batch = 0.6931s	
1665/33450 (epoch 2.489), train_loss = 2.08849818, grad/param norm = 2.4247e-01, time/batch = 0.7170s	
1666/33450 (epoch 2.490), train_loss = 2.14233704, grad/param norm = 2.2419e-01, time/batch = 0.6779s	
1667/33450 (epoch 2.492), train_loss = 2.15964668, grad/param norm = 2.3770e-01, time/batch = 0.6726s	
1668/33450 (epoch 2.493), train_loss = 2.27486525, grad/param norm = 2.5281e-01, time/batch = 0.6712s	
1669/33450 (epoch 2.495), train_loss = 2.14666494, grad/param norm = 2.4503e-01, time/batch = 0.6736s	
1670/33450 (epoch 2.496), train_loss = 2.20224423, grad/param norm = 2.5334e-01, time/batch = 0.6828s	
1671/33450 (epoch 2.498), train_loss = 2.20841055, grad/param norm = 2.4239e-01, time/batch = 0.6759s	
1672/33450 (epoch 2.499), train_loss = 2.09598142, grad/param norm = 2.1197e-01, time/batch = 0.6740s	
1673/33450 (epoch 2.501), train_loss = 2.23016414, grad/param norm = 2.5572e-01, time/batch = 0.6783s	
1674/33450 (epoch 2.502), train_loss = 2.13143886, grad/param norm = 2.1199e-01, time/batch = 0.6811s	
1675/33450 (epoch 2.504), train_loss = 2.12681432, grad/param norm = 2.6129e-01, time/batch = 0.6737s	
1676/33450 (epoch 2.505), train_loss = 2.20460080, grad/param norm = 2.3588e-01, time/batch = 0.6733s	
1677/33450 (epoch 2.507), train_loss = 2.18062014, grad/param norm = 2.7341e-01, time/batch = 0.6742s	
1678/33450 (epoch 2.508), train_loss = 2.03550771, grad/param norm = 2.5596e-01, time/batch = 0.6765s	
1679/33450 (epoch 2.510), train_loss = 2.03503647, grad/param norm = 2.1789e-01, time/batch = 0.7072s	
1680/33450 (epoch 2.511), train_loss = 2.21575428, grad/param norm = 2.2979e-01, time/batch = 0.7013s	
1681/33450 (epoch 2.513), train_loss = 2.27199373, grad/param norm = 3.1779e-01, time/batch = 0.6833s	
1682/33450 (epoch 2.514), train_loss = 2.21268288, grad/param norm = 3.0728e-01, time/batch = 0.6753s	
1683/33450 (epoch 2.516), train_loss = 2.21497566, grad/param norm = 2.2295e-01, time/batch = 0.6735s	
1684/33450 (epoch 2.517), train_loss = 2.13907913, grad/param norm = 2.3787e-01, time/batch = 0.6741s	
1685/33450 (epoch 2.519), train_loss = 2.00544815, grad/param norm = 2.4489e-01, time/batch = 0.6724s	
1686/33450 (epoch 2.520), train_loss = 2.29580260, grad/param norm = 2.2496e-01, time/batch = 0.6739s	
1687/33450 (epoch 2.522), train_loss = 2.23866577, grad/param norm = 2.3386e-01, time/batch = 0.6745s	
1688/33450 (epoch 2.523), train_loss = 2.18665191, grad/param norm = 2.3088e-01, time/batch = 0.6732s	
1689/33450 (epoch 2.525), train_loss = 2.05618076, grad/param norm = 2.2952e-01, time/batch = 0.6732s	
1690/33450 (epoch 2.526), train_loss = 2.12542706, grad/param norm = 2.4456e-01, time/batch = 0.6735s	
1691/33450 (epoch 2.528), train_loss = 2.20802182, grad/param norm = 2.1924e-01, time/batch = 0.6761s	
1692/33450 (epoch 2.529), train_loss = 2.17055857, grad/param norm = 2.0369e-01, time/batch = 0.6925s	
1693/33450 (epoch 2.531), train_loss = 2.10121695, grad/param norm = 2.1861e-01, time/batch = 0.6900s	
1694/33450 (epoch 2.532), train_loss = 2.12302165, grad/param norm = 2.1656e-01, time/batch = 0.7220s	
1695/33450 (epoch 2.534), train_loss = 2.16821742, grad/param norm = 2.1784e-01, time/batch = 0.7034s	
1696/33450 (epoch 2.535), train_loss = 2.22265390, grad/param norm = 2.2848e-01, time/batch = 0.6867s	
1697/33450 (epoch 2.537), train_loss = 1.88213758, grad/param norm = 2.1031e-01, time/batch = 0.6846s	
1698/33450 (epoch 2.538), train_loss = 2.00356379, grad/param norm = 2.2415e-01, time/batch = 0.6850s	
1699/33450 (epoch 2.540), train_loss = 2.08980418, grad/param norm = 2.3932e-01, time/batch = 0.6932s	
1700/33450 (epoch 2.541), train_loss = 2.05345126, grad/param norm = 2.1273e-01, time/batch = 0.6880s	
1701/33450 (epoch 2.543), train_loss = 1.86943199, grad/param norm = 2.1063e-01, time/batch = 0.6925s	
1702/33450 (epoch 2.544), train_loss = 1.99608338, grad/param norm = 2.1612e-01, time/batch = 0.7013s	
1703/33450 (epoch 2.546), train_loss = 2.01561094, grad/param norm = 2.0908e-01, time/batch = 0.7018s	
1704/33450 (epoch 2.547), train_loss = 1.99506059, grad/param norm = 2.1681e-01, time/batch = 0.6867s	
1705/33450 (epoch 2.549), train_loss = 2.24496918, grad/param norm = 2.3850e-01, time/batch = 0.6898s	
1706/33450 (epoch 2.550), train_loss = 2.07599873, grad/param norm = 2.2816e-01, time/batch = 0.6937s	
1707/33450 (epoch 2.552), train_loss = 2.23107556, grad/param norm = 2.2120e-01, time/batch = 0.6883s	
1708/33450 (epoch 2.553), train_loss = 2.18469472, grad/param norm = 2.2544e-01, time/batch = 0.7123s	
1709/33450 (epoch 2.555), train_loss = 1.78733559, grad/param norm = 2.2235e-01, time/batch = 0.7101s	
1710/33450 (epoch 2.556), train_loss = 2.03273357, grad/param norm = 2.1563e-01, time/batch = 0.6829s	
1711/33450 (epoch 2.558), train_loss = 2.11903912, grad/param norm = 2.0467e-01, time/batch = 0.6771s	
1712/33450 (epoch 2.559), train_loss = 1.92058861, grad/param norm = 2.0030e-01, time/batch = 0.6759s	
1713/33450 (epoch 2.561), train_loss = 2.18991766, grad/param norm = 2.3374e-01, time/batch = 0.6768s	
1714/33450 (epoch 2.562), train_loss = 2.03748341, grad/param norm = 2.1239e-01, time/batch = 0.6750s	
1715/33450 (epoch 2.564), train_loss = 2.04513137, grad/param norm = 2.3897e-01, time/batch = 0.6776s	
1716/33450 (epoch 2.565), train_loss = 2.14944576, grad/param norm = 2.7122e-01, time/batch = 0.6773s	
1717/33450 (epoch 2.567), train_loss = 1.90290973, grad/param norm = 2.6774e-01, time/batch = 0.6770s	
1718/33450 (epoch 2.568), train_loss = 2.04604285, grad/param norm = 2.6545e-01, time/batch = 0.6810s	
1719/33450 (epoch 2.570), train_loss = 2.22105464, grad/param norm = 2.3849e-01, time/batch = 0.6806s	
1720/33450 (epoch 2.571), train_loss = 2.19690582, grad/param norm = 2.4977e-01, time/batch = 0.6772s	
1721/33450 (epoch 2.572), train_loss = 2.00036089, grad/param norm = 2.6288e-01, time/batch = 0.6797s	
1722/33450 (epoch 2.574), train_loss = 1.89256055, grad/param norm = 2.3549e-01, time/batch = 0.6872s	
1723/33450 (epoch 2.575), train_loss = 1.99334955, grad/param norm = 2.0325e-01, time/batch = 0.7188s	
1724/33450 (epoch 2.577), train_loss = 2.15789243, grad/param norm = 2.6474e-01, time/batch = 0.6932s	
1725/33450 (epoch 2.578), train_loss = 1.93236186, grad/param norm = 2.4118e-01, time/batch = 0.7064s	
1726/33450 (epoch 2.580), train_loss = 1.98654183, grad/param norm = 2.2917e-01, time/batch = 0.7046s	
1727/33450 (epoch 2.581), train_loss = 2.14581014, grad/param norm = 2.1998e-01, time/batch = 0.6948s	
1728/33450 (epoch 2.583), train_loss = 2.06179191, grad/param norm = 2.1494e-01, time/batch = 0.6746s	
1729/33450 (epoch 2.584), train_loss = 1.94102714, grad/param norm = 2.5960e-01, time/batch = 0.6802s	
1730/33450 (epoch 2.586), train_loss = 2.02205956, grad/param norm = 2.2379e-01, time/batch = 0.6865s	
1731/33450 (epoch 2.587), train_loss = 2.14859523, grad/param norm = 2.0892e-01, time/batch = 0.6889s	
1732/33450 (epoch 2.589), train_loss = 1.94543411, grad/param norm = 1.9979e-01, time/batch = 0.6850s	
1733/33450 (epoch 2.590), train_loss = 2.15570861, grad/param norm = 2.1656e-01, time/batch = 0.6905s	
1734/33450 (epoch 2.592), train_loss = 2.21387352, grad/param norm = 2.5590e-01, time/batch = 0.6746s	
1735/33450 (epoch 2.593), train_loss = 2.20112619, grad/param norm = 3.3501e-01, time/batch = 0.6741s	
1736/33450 (epoch 2.595), train_loss = 2.18674475, grad/param norm = 2.3966e-01, time/batch = 0.6730s	
1737/33450 (epoch 2.596), train_loss = 2.20089884, grad/param norm = 2.2204e-01, time/batch = 0.7072s	
1738/33450 (epoch 2.598), train_loss = 2.07666118, grad/param norm = 2.3212e-01, time/batch = 0.7056s	
1739/33450 (epoch 2.599), train_loss = 2.21871780, grad/param norm = 2.0531e-01, time/batch = 0.6781s	
1740/33450 (epoch 2.601), train_loss = 2.11075193, grad/param norm = 2.1067e-01, time/batch = 0.6739s	
1741/33450 (epoch 2.602), train_loss = 2.12524101, grad/param norm = 2.4528e-01, time/batch = 0.6759s	
1742/33450 (epoch 2.604), train_loss = 1.94748999, grad/param norm = 1.9871e-01, time/batch = 0.6734s	
1743/33450 (epoch 2.605), train_loss = 1.94606777, grad/param norm = 2.3843e-01, time/batch = 0.6737s	
1744/33450 (epoch 2.607), train_loss = 2.07322838, grad/param norm = 2.2930e-01, time/batch = 0.6737s	
1745/33450 (epoch 2.608), train_loss = 2.01181915, grad/param norm = 2.3291e-01, time/batch = 0.6755s	
1746/33450 (epoch 2.610), train_loss = 2.13029269, grad/param norm = 2.5447e-01, time/batch = 0.6775s	
1747/33450 (epoch 2.611), train_loss = 2.10798542, grad/param norm = 2.5775e-01, time/batch = 0.6737s	
1748/33450 (epoch 2.613), train_loss = 2.09550453, grad/param norm = 2.6248e-01, time/batch = 0.6754s	
1749/33450 (epoch 2.614), train_loss = 2.10562437, grad/param norm = 2.3410e-01, time/batch = 0.6751s	
1750/33450 (epoch 2.616), train_loss = 2.09649785, grad/param norm = 2.7311e-01, time/batch = 0.6742s	
1751/33450 (epoch 2.617), train_loss = 1.95250105, grad/param norm = 1.9938e-01, time/batch = 0.6826s	
1752/33450 (epoch 2.619), train_loss = 2.05027687, grad/param norm = 2.2318e-01, time/batch = 0.7194s	
1753/33450 (epoch 2.620), train_loss = 1.83913121, grad/param norm = 2.2791e-01, time/batch = 0.7037s	
1754/33450 (epoch 2.622), train_loss = 2.16013537, grad/param norm = 2.2166e-01, time/batch = 0.6956s	
1755/33450 (epoch 2.623), train_loss = 2.06382664, grad/param norm = 2.2738e-01, time/batch = 0.6953s	
1756/33450 (epoch 2.625), train_loss = 2.19154566, grad/param norm = 2.4346e-01, time/batch = 0.6983s	
1757/33450 (epoch 2.626), train_loss = 1.89620593, grad/param norm = 2.0405e-01, time/batch = 0.6850s	
1758/33450 (epoch 2.628), train_loss = 1.91538935, grad/param norm = 2.0559e-01, time/batch = 0.6860s	
1759/33450 (epoch 2.629), train_loss = 2.19395568, grad/param norm = 2.5766e-01, time/batch = 0.6957s	
1760/33450 (epoch 2.631), train_loss = 2.14409118, grad/param norm = 2.5296e-01, time/batch = 0.7080s	
1761/33450 (epoch 2.632), train_loss = 1.94945504, grad/param norm = 2.1085e-01, time/batch = 0.6923s	
1762/33450 (epoch 2.634), train_loss = 1.99063295, grad/param norm = 2.4218e-01, time/batch = 0.6948s	
1763/33450 (epoch 2.635), train_loss = 2.11967483, grad/param norm = 3.0541e-01, time/batch = 0.6887s	
1764/33450 (epoch 2.637), train_loss = 2.18063523, grad/param norm = 2.6050e-01, time/batch = 0.6760s	
1765/33450 (epoch 2.638), train_loss = 1.97106481, grad/param norm = 1.9595e-01, time/batch = 0.6749s	
1766/33450 (epoch 2.640), train_loss = 2.01589006, grad/param norm = 2.0712e-01, time/batch = 0.7074s	
1767/33450 (epoch 2.641), train_loss = 2.00419415, grad/param norm = 2.0572e-01, time/batch = 0.7100s	
1768/33450 (epoch 2.643), train_loss = 1.90315676, grad/param norm = 2.0686e-01, time/batch = 0.6799s	
1769/33450 (epoch 2.644), train_loss = 2.05133644, grad/param norm = 2.2010e-01, time/batch = 0.6750s	
1770/33450 (epoch 2.646), train_loss = 2.18319219, grad/param norm = 2.6451e-01, time/batch = 0.6747s	
1771/33450 (epoch 2.647), train_loss = 2.23397741, grad/param norm = 2.7527e-01, time/batch = 0.6760s	
1772/33450 (epoch 2.649), train_loss = 2.09423397, grad/param norm = 2.2562e-01, time/batch = 0.6774s	
1773/33450 (epoch 2.650), train_loss = 1.95784869, grad/param norm = 2.2147e-01, time/batch = 0.6769s	
1774/33450 (epoch 2.652), train_loss = 1.76523510, grad/param norm = 2.4353e-01, time/batch = 0.6789s	
1775/33450 (epoch 2.653), train_loss = 2.02437677, grad/param norm = 2.4927e-01, time/batch = 0.6762s	
1776/33450 (epoch 2.655), train_loss = 2.15085521, grad/param norm = 2.5248e-01, time/batch = 0.6764s	
1777/33450 (epoch 2.656), train_loss = 1.91585846, grad/param norm = 2.3031e-01, time/batch = 0.6764s	
1778/33450 (epoch 2.658), train_loss = 2.06012480, grad/param norm = 2.2582e-01, time/batch = 0.6763s	
1779/33450 (epoch 2.659), train_loss = 2.05098083, grad/param norm = 2.2712e-01, time/batch = 0.6778s	
1780/33450 (epoch 2.661), train_loss = 2.19163399, grad/param norm = 2.0788e-01, time/batch = 0.6824s	
1781/33450 (epoch 2.662), train_loss = 1.89485935, grad/param norm = 2.0967e-01, time/batch = 0.7198s	
1782/33450 (epoch 2.664), train_loss = 2.10839404, grad/param norm = 1.9127e-01, time/batch = 0.6870s	
1783/33450 (epoch 2.665), train_loss = 1.96683175, grad/param norm = 2.1612e-01, time/batch = 0.6776s	
1784/33450 (epoch 2.667), train_loss = 2.15057825, grad/param norm = 2.0886e-01, time/batch = 0.6760s	
1785/33450 (epoch 2.668), train_loss = 2.10438388, grad/param norm = 1.9558e-01, time/batch = 0.6750s	
1786/33450 (epoch 2.670), train_loss = 1.97417173, grad/param norm = 2.2506e-01, time/batch = 0.6760s	
1787/33450 (epoch 2.671), train_loss = 2.13843979, grad/param norm = 2.1146e-01, time/batch = 0.6757s	
1788/33450 (epoch 2.673), train_loss = 2.11995036, grad/param norm = 2.3293e-01, time/batch = 0.6751s	
1789/33450 (epoch 2.674), train_loss = 2.18563328, grad/param norm = 2.0935e-01, time/batch = 0.6748s	
1790/33450 (epoch 2.676), train_loss = 2.16821560, grad/param norm = 2.2347e-01, time/batch = 0.6780s	
1791/33450 (epoch 2.677), train_loss = 2.11470310, grad/param norm = 2.0775e-01, time/batch = 0.6760s	
1792/33450 (epoch 2.679), train_loss = 2.01005065, grad/param norm = 1.9369e-01, time/batch = 0.6753s	
1793/33450 (epoch 2.680), train_loss = 2.03806203, grad/param norm = 2.0462e-01, time/batch = 0.6742s	
1794/33450 (epoch 2.682), train_loss = 2.00737206, grad/param norm = 2.0681e-01, time/batch = 0.6743s	
1795/33450 (epoch 2.683), train_loss = 2.26930809, grad/param norm = 2.1619e-01, time/batch = 0.6976s	
1796/33450 (epoch 2.685), train_loss = 2.30508962, grad/param norm = 2.6076e-01, time/batch = 0.7151s	
1797/33450 (epoch 2.686), train_loss = 2.20143323, grad/param norm = 2.1507e-01, time/batch = 0.6755s	
1798/33450 (epoch 2.688), train_loss = 2.27439549, grad/param norm = 2.3691e-01, time/batch = 0.6744s	
1799/33450 (epoch 2.689), train_loss = 2.05540594, grad/param norm = 2.1192e-01, time/batch = 0.6765s	
1800/33450 (epoch 2.691), train_loss = 2.06849035, grad/param norm = 2.3513e-01, time/batch = 0.6761s	
1801/33450 (epoch 2.692), train_loss = 2.20465582, grad/param norm = 2.3624e-01, time/batch = 0.6778s	
1802/33450 (epoch 2.694), train_loss = 1.93601500, grad/param norm = 2.5410e-01, time/batch = 0.6774s	
1803/33450 (epoch 2.695), train_loss = 2.23301928, grad/param norm = 2.4320e-01, time/batch = 0.6748s	
1804/33450 (epoch 2.697), train_loss = 2.21611528, grad/param norm = 2.1841e-01, time/batch = 0.6746s	
1805/33450 (epoch 2.698), train_loss = 1.87536088, grad/param norm = 2.3269e-01, time/batch = 0.6745s	
1806/33450 (epoch 2.700), train_loss = 2.25770476, grad/param norm = 2.6755e-01, time/batch = 0.6759s	
1807/33450 (epoch 2.701), train_loss = 2.06930726, grad/param norm = 2.3694e-01, time/batch = 0.6806s	
1808/33450 (epoch 2.703), train_loss = 2.15605636, grad/param norm = 2.1124e-01, time/batch = 0.6738s	
1809/33450 (epoch 2.704), train_loss = 1.98792457, grad/param norm = 1.9870e-01, time/batch = 0.6750s	
1810/33450 (epoch 2.706), train_loss = 2.00563801, grad/param norm = 2.0803e-01, time/batch = 0.7119s	
1811/33450 (epoch 2.707), train_loss = 1.97274584, grad/param norm = 2.2599e-01, time/batch = 0.7094s	
1812/33450 (epoch 2.709), train_loss = 2.21199973, grad/param norm = 3.1196e-01, time/batch = 0.6881s	
1813/33450 (epoch 2.710), train_loss = 2.02795071, grad/param norm = 2.5668e-01, time/batch = 0.6884s	
1814/33450 (epoch 2.712), train_loss = 1.97295112, grad/param norm = 2.2320e-01, time/batch = 0.6873s	
1815/33450 (epoch 2.713), train_loss = 2.24000194, grad/param norm = 2.3755e-01, time/batch = 0.6773s	
1816/33450 (epoch 2.714), train_loss = 2.03014443, grad/param norm = 2.3028e-01, time/batch = 0.6739s	
1817/33450 (epoch 2.716), train_loss = 1.97724004, grad/param norm = 2.0286e-01, time/batch = 0.6790s	
1818/33450 (epoch 2.717), train_loss = 2.08917748, grad/param norm = 2.3520e-01, time/batch = 0.6762s	
1819/33450 (epoch 2.719), train_loss = 2.18858518, grad/param norm = 2.2628e-01, time/batch = 0.6740s	
1820/33450 (epoch 2.720), train_loss = 1.99468304, grad/param norm = 2.0875e-01, time/batch = 0.6801s	
1821/33450 (epoch 2.722), train_loss = 1.86164337, grad/param norm = 2.2061e-01, time/batch = 0.6761s	
1822/33450 (epoch 2.723), train_loss = 2.01396419, grad/param norm = 2.4635e-01, time/batch = 0.6974s	
1823/33450 (epoch 2.725), train_loss = 1.92995909, grad/param norm = 2.3720e-01, time/batch = 0.6808s	
1824/33450 (epoch 2.726), train_loss = 1.84225022, grad/param norm = 2.1483e-01, time/batch = 0.6754s	
1825/33450 (epoch 2.728), train_loss = 1.93123920, grad/param norm = 2.2797e-01, time/batch = 0.6835s	
1826/33450 (epoch 2.729), train_loss = 2.05897004, grad/param norm = 2.2299e-01, time/batch = 0.6780s	
1827/33450 (epoch 2.731), train_loss = 2.34911124, grad/param norm = 2.5096e-01, time/batch = 0.6729s	
1828/33450 (epoch 2.732), train_loss = 2.30477540, grad/param norm = 2.3498e-01, time/batch = 0.6781s	
1829/33450 (epoch 2.734), train_loss = 2.18578847, grad/param norm = 2.3131e-01, time/batch = 0.6825s	
1830/33450 (epoch 2.735), train_loss = 2.21975366, grad/param norm = 2.1515e-01, time/batch = 0.6815s	
1831/33450 (epoch 2.737), train_loss = 2.16328369, grad/param norm = 2.2451e-01, time/batch = 0.6775s	
1832/33450 (epoch 2.738), train_loss = 2.26415253, grad/param norm = 2.0482e-01, time/batch = 0.6774s	
1833/33450 (epoch 2.740), train_loss = 2.06653001, grad/param norm = 2.2110e-01, time/batch = 0.6775s	
1834/33450 (epoch 2.741), train_loss = 2.03472595, grad/param norm = 1.9257e-01, time/batch = 0.6754s	
1835/33450 (epoch 2.743), train_loss = 2.15759385, grad/param norm = 2.3539e-01, time/batch = 0.6733s	
1836/33450 (epoch 2.744), train_loss = 2.16427536, grad/param norm = 2.1803e-01, time/batch = 0.6720s	
1837/33450 (epoch 2.746), train_loss = 2.05617575, grad/param norm = 2.1527e-01, time/batch = 0.6725s	
1838/33450 (epoch 2.747), train_loss = 2.22357620, grad/param norm = 2.4421e-01, time/batch = 0.6738s	
1839/33450 (epoch 2.749), train_loss = 2.00482454, grad/param norm = 2.1488e-01, time/batch = 0.6723s	
1840/33450 (epoch 2.750), train_loss = 1.99258317, grad/param norm = 2.1745e-01, time/batch = 0.6737s	
1841/33450 (epoch 2.752), train_loss = 2.19878663, grad/param norm = 2.4741e-01, time/batch = 0.6815s	
1842/33450 (epoch 2.753), train_loss = 2.18669445, grad/param norm = 2.3047e-01, time/batch = 0.6742s	
1843/33450 (epoch 2.755), train_loss = 2.05012351, grad/param norm = 2.2655e-01, time/batch = 0.6744s	
1844/33450 (epoch 2.756), train_loss = 2.18720936, grad/param norm = 2.1226e-01, time/batch = 0.6736s	
1845/33450 (epoch 2.758), train_loss = 2.11384132, grad/param norm = 2.0597e-01, time/batch = 0.6765s	
1846/33450 (epoch 2.759), train_loss = 2.15103656, grad/param norm = 2.0093e-01, time/batch = 0.6745s	
1847/33450 (epoch 2.761), train_loss = 2.10210833, grad/param norm = 2.3282e-01, time/batch = 0.6749s	
1848/33450 (epoch 2.762), train_loss = 2.25539916, grad/param norm = 2.4755e-01, time/batch = 0.6853s	
1849/33450 (epoch 2.764), train_loss = 2.05222115, grad/param norm = 2.2550e-01, time/batch = 0.6742s	
1850/33450 (epoch 2.765), train_loss = 2.04872036, grad/param norm = 2.1866e-01, time/batch = 0.6762s	
1851/33450 (epoch 2.767), train_loss = 2.08404458, grad/param norm = 2.4470e-01, time/batch = 0.6741s	
1852/33450 (epoch 2.768), train_loss = 2.03928314, grad/param norm = 2.0666e-01, time/batch = 0.6746s	
1853/33450 (epoch 2.770), train_loss = 2.19343664, grad/param norm = 2.3043e-01, time/batch = 0.6745s	
1854/33450 (epoch 2.771), train_loss = 2.35364135, grad/param norm = 2.2655e-01, time/batch = 0.6733s	
1855/33450 (epoch 2.773), train_loss = 2.13037240, grad/param norm = 2.1669e-01, time/batch = 0.6715s	
1856/33450 (epoch 2.774), train_loss = 2.09552035, grad/param norm = 2.1363e-01, time/batch = 0.6838s	
1857/33450 (epoch 2.776), train_loss = 2.07699774, grad/param norm = 1.9333e-01, time/batch = 0.6719s	
1858/33450 (epoch 2.777), train_loss = 2.00494725, grad/param norm = 2.0158e-01, time/batch = 0.6717s	
1859/33450 (epoch 2.779), train_loss = 2.02776485, grad/param norm = 1.8700e-01, time/batch = 0.6719s	
1860/33450 (epoch 2.780), train_loss = 1.95060408, grad/param norm = 2.0995e-01, time/batch = 0.6736s	
1861/33450 (epoch 2.782), train_loss = 2.15961971, grad/param norm = 2.3811e-01, time/batch = 0.6748s	
1862/33450 (epoch 2.783), train_loss = 2.15994261, grad/param norm = 2.6782e-01, time/batch = 0.6791s	
1863/33450 (epoch 2.785), train_loss = 2.11041596, grad/param norm = 2.5550e-01, time/batch = 0.6743s	
1864/33450 (epoch 2.786), train_loss = 2.02425089, grad/param norm = 2.1146e-01, time/batch = 0.6733s	
1865/33450 (epoch 2.788), train_loss = 2.00515058, grad/param norm = 1.9533e-01, time/batch = 0.6741s	
1866/33450 (epoch 2.789), train_loss = 1.99640619, grad/param norm = 2.1354e-01, time/batch = 0.6733s	
1867/33450 (epoch 2.791), train_loss = 1.85327971, grad/param norm = 2.0834e-01, time/batch = 0.6728s	
1868/33450 (epoch 2.792), train_loss = 2.02112811, grad/param norm = 2.2138e-01, time/batch = 0.6750s	
1869/33450 (epoch 2.794), train_loss = 1.97999120, grad/param norm = 2.4317e-01, time/batch = 0.6743s	
1870/33450 (epoch 2.795), train_loss = 2.12650227, grad/param norm = 2.1836e-01, time/batch = 0.6785s	
1871/33450 (epoch 2.797), train_loss = 2.12429799, grad/param norm = 2.2553e-01, time/batch = 0.6785s	
1872/33450 (epoch 2.798), train_loss = 2.09810186, grad/param norm = 2.6361e-01, time/batch = 0.6806s	
1873/33450 (epoch 2.800), train_loss = 2.17453956, grad/param norm = 2.1579e-01, time/batch = 0.6795s	
1874/33450 (epoch 2.801), train_loss = 2.22714650, grad/param norm = 2.1922e-01, time/batch = 0.6823s	
1875/33450 (epoch 2.803), train_loss = 2.15358041, grad/param norm = 2.3593e-01, time/batch = 0.6775s	
1876/33450 (epoch 2.804), train_loss = 1.90928461, grad/param norm = 2.0925e-01, time/batch = 0.6740s	
1877/33450 (epoch 2.806), train_loss = 2.04185565, grad/param norm = 2.1146e-01, time/batch = 0.6744s	
1878/33450 (epoch 2.807), train_loss = 2.03279572, grad/param norm = 2.0246e-01, time/batch = 0.6731s	
1879/33450 (epoch 2.809), train_loss = 2.01964057, grad/param norm = 1.9964e-01, time/batch = 0.6730s	
1880/33450 (epoch 2.810), train_loss = 2.03858821, grad/param norm = 2.0408e-01, time/batch = 0.6735s	
1881/33450 (epoch 2.812), train_loss = 1.96174151, grad/param norm = 2.3329e-01, time/batch = 0.6746s	
1882/33450 (epoch 2.813), train_loss = 1.94459124, grad/param norm = 2.8126e-01, time/batch = 0.6738s	
1883/33450 (epoch 2.815), train_loss = 2.22660194, grad/param norm = 2.4354e-01, time/batch = 0.6909s	
1884/33450 (epoch 2.816), train_loss = 2.10135676, grad/param norm = 1.9433e-01, time/batch = 0.7131s	
1885/33450 (epoch 2.818), train_loss = 1.76682492, grad/param norm = 1.9852e-01, time/batch = 0.6812s	
1886/33450 (epoch 2.819), train_loss = 2.02370818, grad/param norm = 2.2485e-01, time/batch = 0.6742s	
1887/33450 (epoch 2.821), train_loss = 2.10456585, grad/param norm = 2.1214e-01, time/batch = 0.6737s	
1888/33450 (epoch 2.822), train_loss = 2.12217814, grad/param norm = 2.2078e-01, time/batch = 0.6727s	
1889/33450 (epoch 2.824), train_loss = 1.98169980, grad/param norm = 2.2704e-01, time/batch = 0.6725s	
1890/33450 (epoch 2.825), train_loss = 2.03759673, grad/param norm = 2.1148e-01, time/batch = 0.6745s	
1891/33450 (epoch 2.827), train_loss = 2.17177067, grad/param norm = 2.0907e-01, time/batch = 0.6758s	
1892/33450 (epoch 2.828), train_loss = 1.89821836, grad/param norm = 2.2497e-01, time/batch = 0.6748s	
1893/33450 (epoch 2.830), train_loss = 1.98197138, grad/param norm = 2.2009e-01, time/batch = 0.6736s	
1894/33450 (epoch 2.831), train_loss = 2.05379988, grad/param norm = 2.2595e-01, time/batch = 0.6952s	
1895/33450 (epoch 2.833), train_loss = 1.96458128, grad/param norm = 2.1186e-01, time/batch = 0.6833s	
1896/33450 (epoch 2.834), train_loss = 2.03736378, grad/param norm = 2.0977e-01, time/batch = 0.6720s	
1897/33450 (epoch 2.836), train_loss = 1.93776575, grad/param norm = 1.8583e-01, time/batch = 0.6728s	
1898/33450 (epoch 2.837), train_loss = 2.17139285, grad/param norm = 2.1768e-01, time/batch = 0.7075s	
1899/33450 (epoch 2.839), train_loss = 2.14316840, grad/param norm = 2.2543e-01, time/batch = 0.7064s	
1900/33450 (epoch 2.840), train_loss = 2.18640855, grad/param norm = 2.6384e-01, time/batch = 0.6874s	
1901/33450 (epoch 2.842), train_loss = 2.04056330, grad/param norm = 2.2129e-01, time/batch = 0.6897s	
1902/33450 (epoch 2.843), train_loss = 1.91666567, grad/param norm = 2.4965e-01, time/batch = 0.6819s	
1903/33450 (epoch 2.845), train_loss = 1.96810297, grad/param norm = 2.2538e-01, time/batch = 0.6809s	
1904/33450 (epoch 2.846), train_loss = 2.18842467, grad/param norm = 2.1896e-01, time/batch = 0.6765s	
1905/33450 (epoch 2.848), train_loss = 2.09086682, grad/param norm = 2.0872e-01, time/batch = 0.6863s	
1906/33450 (epoch 2.849), train_loss = 2.11146880, grad/param norm = 2.0287e-01, time/batch = 0.6824s	
1907/33450 (epoch 2.851), train_loss = 1.96675297, grad/param norm = 1.9081e-01, time/batch = 0.6790s	
1908/33450 (epoch 2.852), train_loss = 2.01592966, grad/param norm = 2.0823e-01, time/batch = 0.6749s	
1909/33450 (epoch 2.854), train_loss = 2.11865373, grad/param norm = 2.3746e-01, time/batch = 0.6852s	
1910/33450 (epoch 2.855), train_loss = 2.04544828, grad/param norm = 2.2133e-01, time/batch = 0.6780s	
1911/33450 (epoch 2.857), train_loss = 1.99266123, grad/param norm = 2.1044e-01, time/batch = 0.6765s	
1912/33450 (epoch 2.858), train_loss = 2.30214108, grad/param norm = 2.4539e-01, time/batch = 0.6884s	
1913/33450 (epoch 2.859), train_loss = 2.30651509, grad/param norm = 2.1873e-01, time/batch = 0.7185s	
1914/33450 (epoch 2.861), train_loss = 2.23844619, grad/param norm = 2.3851e-01, time/batch = 0.6940s	
1915/33450 (epoch 2.862), train_loss = 1.96722231, grad/param norm = 2.2265e-01, time/batch = 0.6764s	
1916/33450 (epoch 2.864), train_loss = 2.11357568, grad/param norm = 2.9291e-01, time/batch = 0.6856s	
1917/33450 (epoch 2.865), train_loss = 2.04075091, grad/param norm = 2.8350e-01, time/batch = 0.6898s	
1918/33450 (epoch 2.867), train_loss = 2.13531903, grad/param norm = 2.2953e-01, time/batch = 0.6809s	
1919/33450 (epoch 2.868), train_loss = 2.10833841, grad/param norm = 2.3543e-01, time/batch = 0.6768s	
1920/33450 (epoch 2.870), train_loss = 2.10311540, grad/param norm = 2.5545e-01, time/batch = 0.6784s	
1921/33450 (epoch 2.871), train_loss = 2.19827127, grad/param norm = 2.8848e-01, time/batch = 0.6824s	
1922/33450 (epoch 2.873), train_loss = 1.92390027, grad/param norm = 2.2465e-01, time/batch = 0.6787s	
1923/33450 (epoch 2.874), train_loss = 2.04068360, grad/param norm = 2.3326e-01, time/batch = 0.7086s	
1924/33450 (epoch 2.876), train_loss = 2.13765626, grad/param norm = 2.2754e-01, time/batch = 0.6873s	
1925/33450 (epoch 2.877), train_loss = 2.03840289, grad/param norm = 1.9873e-01, time/batch = 0.6742s	
1926/33450 (epoch 2.879), train_loss = 1.85901243, grad/param norm = 2.0045e-01, time/batch = 0.6735s	
1927/33450 (epoch 2.880), train_loss = 2.01827761, grad/param norm = 2.1536e-01, time/batch = 0.7067s	
1928/33450 (epoch 2.882), train_loss = 2.08747950, grad/param norm = 2.0567e-01, time/batch = 0.7022s	
1929/33450 (epoch 2.883), train_loss = 2.04361324, grad/param norm = 2.3936e-01, time/batch = 0.6779s	
1930/33450 (epoch 2.885), train_loss = 2.07231270, grad/param norm = 1.9135e-01, time/batch = 0.6736s	
1931/33450 (epoch 2.886), train_loss = 2.20225198, grad/param norm = 2.3285e-01, time/batch = 0.6753s	
1932/33450 (epoch 2.888), train_loss = 2.09265635, grad/param norm = 2.2502e-01, time/batch = 0.6755s	
1933/33450 (epoch 2.889), train_loss = 1.92786162, grad/param norm = 1.8709e-01, time/batch = 0.6729s	
1934/33450 (epoch 2.891), train_loss = 2.16639367, grad/param norm = 2.1590e-01, time/batch = 0.6733s	
1935/33450 (epoch 2.892), train_loss = 2.02755879, grad/param norm = 2.0899e-01, time/batch = 0.6777s	
1936/33450 (epoch 2.894), train_loss = 2.12509261, grad/param norm = 2.3493e-01, time/batch = 0.6799s	
1937/33450 (epoch 2.895), train_loss = 1.86668067, grad/param norm = 2.3727e-01, time/batch = 0.6727s	
1938/33450 (epoch 2.897), train_loss = 1.95337903, grad/param norm = 2.2321e-01, time/batch = 0.6725s	
1939/33450 (epoch 2.898), train_loss = 2.01227906, grad/param norm = 2.0832e-01, time/batch = 0.6718s	
1940/33450 (epoch 2.900), train_loss = 2.06354582, grad/param norm = 2.1302e-01, time/batch = 0.6720s	
1941/33450 (epoch 2.901), train_loss = 2.11238835, grad/param norm = 2.1848e-01, time/batch = 0.6792s	
1942/33450 (epoch 2.903), train_loss = 1.79654143, grad/param norm = 2.0440e-01, time/batch = 0.7190s	
1943/33450 (epoch 2.904), train_loss = 2.10290384, grad/param norm = 2.4514e-01, time/batch = 0.6881s	
1944/33450 (epoch 2.906), train_loss = 2.03214083, grad/param norm = 2.3029e-01, time/batch = 0.6736s	
1945/33450 (epoch 2.907), train_loss = 2.07650768, grad/param norm = 2.1936e-01, time/batch = 0.6730s	
1946/33450 (epoch 2.909), train_loss = 1.96516309, grad/param norm = 1.8921e-01, time/batch = 0.6757s	
1947/33450 (epoch 2.910), train_loss = 2.09800105, grad/param norm = 2.3432e-01, time/batch = 0.6764s	
1948/33450 (epoch 2.912), train_loss = 2.08527720, grad/param norm = 2.4861e-01, time/batch = 0.6765s	
1949/33450 (epoch 2.913), train_loss = 2.08280188, grad/param norm = 2.0469e-01, time/batch = 0.6755s	
1950/33450 (epoch 2.915), train_loss = 1.97879548, grad/param norm = 2.3545e-01, time/batch = 0.6809s	
1951/33450 (epoch 2.916), train_loss = 2.14125542, grad/param norm = 2.0174e-01, time/batch = 0.6773s	
1952/33450 (epoch 2.918), train_loss = 1.98897271, grad/param norm = 2.2250e-01, time/batch = 0.6767s	
1953/33450 (epoch 2.919), train_loss = 2.08108559, grad/param norm = 2.0159e-01, time/batch = 0.6759s	
1954/33450 (epoch 2.921), train_loss = 2.10118129, grad/param norm = 2.1898e-01, time/batch = 0.6744s	
1955/33450 (epoch 2.922), train_loss = 2.00769914, grad/param norm = 2.3002e-01, time/batch = 0.6739s	
1956/33450 (epoch 2.924), train_loss = 2.18891789, grad/param norm = 2.2983e-01, time/batch = 0.6956s	
1957/33450 (epoch 2.925), train_loss = 1.96013948, grad/param norm = 1.9523e-01, time/batch = 0.7190s	
1958/33450 (epoch 2.927), train_loss = 2.01070887, grad/param norm = 2.3934e-01, time/batch = 0.6836s	
1959/33450 (epoch 2.928), train_loss = 1.99906808, grad/param norm = 2.1275e-01, time/batch = 0.6743s	
1960/33450 (epoch 2.930), train_loss = 1.99876151, grad/param norm = 2.3105e-01, time/batch = 0.6940s	
1961/33450 (epoch 2.931), train_loss = 1.87026031, grad/param norm = 2.1639e-01, time/batch = 0.6979s	
1962/33450 (epoch 2.933), train_loss = 2.11934014, grad/param norm = 2.0852e-01, time/batch = 0.6953s	
1963/33450 (epoch 2.934), train_loss = 1.93531111, grad/param norm = 2.0387e-01, time/batch = 0.6938s	
1964/33450 (epoch 2.936), train_loss = 2.03363041, grad/param norm = 1.9614e-01, time/batch = 0.6936s	
1965/33450 (epoch 2.937), train_loss = 1.94968195, grad/param norm = 2.0207e-01, time/batch = 0.6820s	
1966/33450 (epoch 2.939), train_loss = 1.99616210, grad/param norm = 1.9698e-01, time/batch = 0.6891s	
1967/33450 (epoch 2.940), train_loss = 2.05217182, grad/param norm = 1.9075e-01, time/batch = 0.6975s	
1968/33450 (epoch 2.942), train_loss = 2.04715170, grad/param norm = 2.2447e-01, time/batch = 0.7047s	
1969/33450 (epoch 2.943), train_loss = 2.04359495, grad/param norm = 2.0100e-01, time/batch = 0.7103s	
1970/33450 (epoch 2.945), train_loss = 2.15006217, grad/param norm = 2.0757e-01, time/batch = 0.7137s	
1971/33450 (epoch 2.946), train_loss = 2.16073297, grad/param norm = 2.3321e-01, time/batch = 0.7236s	
1972/33450 (epoch 2.948), train_loss = 1.96956439, grad/param norm = 2.2391e-01, time/batch = 0.7142s	
1973/33450 (epoch 2.949), train_loss = 2.11378235, grad/param norm = 2.2130e-01, time/batch = 0.7036s	
1974/33450 (epoch 2.951), train_loss = 2.09393327, grad/param norm = 2.2624e-01, time/batch = 0.6856s	
1975/33450 (epoch 2.952), train_loss = 2.08959778, grad/param norm = 2.2520e-01, time/batch = 0.6785s	
1976/33450 (epoch 2.954), train_loss = 2.10096573, grad/param norm = 2.0206e-01, time/batch = 0.6715s	
1977/33450 (epoch 2.955), train_loss = 2.06402378, grad/param norm = 1.9209e-01, time/batch = 0.6731s	
1978/33450 (epoch 2.957), train_loss = 2.24264491, grad/param norm = 2.2475e-01, time/batch = 0.6739s	
1979/33450 (epoch 2.958), train_loss = 2.10818381, grad/param norm = 2.2405e-01, time/batch = 0.6729s	
1980/33450 (epoch 2.960), train_loss = 2.15017732, grad/param norm = 2.1467e-01, time/batch = 0.6723s	
1981/33450 (epoch 2.961), train_loss = 2.12472201, grad/param norm = 2.1458e-01, time/batch = 0.6822s	
1982/33450 (epoch 2.963), train_loss = 2.25570754, grad/param norm = 2.8206e-01, time/batch = 0.6733s	
1983/33450 (epoch 2.964), train_loss = 2.06458494, grad/param norm = 2.2813e-01, time/batch = 0.6756s	
1984/33450 (epoch 2.966), train_loss = 2.03023248, grad/param norm = 2.3897e-01, time/batch = 0.6738s	
1985/33450 (epoch 2.967), train_loss = 2.24558409, grad/param norm = 2.3106e-01, time/batch = 0.6999s	
1986/33450 (epoch 2.969), train_loss = 1.96849232, grad/param norm = 2.0004e-01, time/batch = 0.7147s	
1987/33450 (epoch 2.970), train_loss = 2.05372646, grad/param norm = 2.3330e-01, time/batch = 0.6904s	
1988/33450 (epoch 2.972), train_loss = 2.20940504, grad/param norm = 2.4622e-01, time/batch = 0.6782s	
1989/33450 (epoch 2.973), train_loss = 2.04960383, grad/param norm = 2.2196e-01, time/batch = 0.6800s	
1990/33450 (epoch 2.975), train_loss = 1.98490413, grad/param norm = 2.1303e-01, time/batch = 0.6730s	
1991/33450 (epoch 2.976), train_loss = 2.10683567, grad/param norm = 2.0629e-01, time/batch = 0.6753s	
1992/33450 (epoch 2.978), train_loss = 1.96637220, grad/param norm = 2.0264e-01, time/batch = 0.6748s	
1993/33450 (epoch 2.979), train_loss = 2.05780080, grad/param norm = 2.1164e-01, time/batch = 0.6763s	
1994/33450 (epoch 2.981), train_loss = 2.00289227, grad/param norm = 2.2835e-01, time/batch = 0.6751s	
1995/33450 (epoch 2.982), train_loss = 2.00707745, grad/param norm = 2.0424e-01, time/batch = 0.6758s	
1996/33450 (epoch 2.984), train_loss = 1.92948695, grad/param norm = 1.9628e-01, time/batch = 0.6754s	
1997/33450 (epoch 2.985), train_loss = 1.92301586, grad/param norm = 2.0574e-01, time/batch = 0.6747s	
1998/33450 (epoch 2.987), train_loss = 2.05529897, grad/param norm = 2.1111e-01, time/batch = 0.6931s	
1999/33450 (epoch 2.988), train_loss = 1.93462443, grad/param norm = 2.3463e-01, time/batch = 0.6775s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_melania_guerra_epoch2.99_2.0832.t7	
2000/33450 (epoch 2.990), train_loss = 1.82821008, grad/param norm = 2.1116e-01, time/batch = 0.7178s	
2001/33450 (epoch 2.991), train_loss = 2.25282751, grad/param norm = 2.3525e-01, time/batch = 0.6884s	
2002/33450 (epoch 2.993), train_loss = 1.97509501, grad/param norm = 2.6312e-01, time/batch = 0.6761s	
2003/33450 (epoch 2.994), train_loss = 2.05695667, grad/param norm = 2.1388e-01, time/batch = 0.6791s	
2004/33450 (epoch 2.996), train_loss = 2.02147845, grad/param norm = 2.4854e-01, time/batch = 0.6765s	
2005/33450 (epoch 2.997), train_loss = 1.95450062, grad/param norm = 1.9975e-01, time/batch = 0.6757s	
2006/33450 (epoch 2.999), train_loss = 2.11619474, grad/param norm = 2.4360e-01, time/batch = 0.6881s	
2007/33450 (epoch 3.000), train_loss = 1.96965547, grad/param norm = 2.1929e-01, time/batch = 0.6777s	
2008/33450 (epoch 3.001), train_loss = 2.32513734, grad/param norm = 2.1918e-01, time/batch = 0.6817s	
2009/33450 (epoch 3.003), train_loss = 2.07170703, grad/param norm = 1.8508e-01, time/batch = 0.6816s	
2010/33450 (epoch 3.004), train_loss = 2.10434529, grad/param norm = 2.0858e-01, time/batch = 0.6786s	
2011/33450 (epoch 3.006), train_loss = 2.01972840, grad/param norm = 2.0289e-01, time/batch = 0.6752s	
2012/33450 (epoch 3.007), train_loss = 1.79525803, grad/param norm = 2.0193e-01, time/batch = 0.6763s	
2013/33450 (epoch 3.009), train_loss = 2.16454454, grad/param norm = 2.2135e-01, time/batch = 0.6875s	
2014/33450 (epoch 3.010), train_loss = 2.06334595, grad/param norm = 2.4905e-01, time/batch = 0.6818s	
2015/33450 (epoch 3.012), train_loss = 2.00248547, grad/param norm = 2.0207e-01, time/batch = 0.6879s	
2016/33450 (epoch 3.013), train_loss = 1.93976648, grad/param norm = 2.2140e-01, time/batch = 0.6773s	
2017/33450 (epoch 3.015), train_loss = 1.97712716, grad/param norm = 2.1628e-01, time/batch = 0.6759s	
2018/33450 (epoch 3.016), train_loss = 2.08620383, grad/param norm = 2.2159e-01, time/batch = 0.6736s	
2019/33450 (epoch 3.018), train_loss = 1.99017248, grad/param norm = 2.1278e-01, time/batch = 0.6741s	
2020/33450 (epoch 3.019), train_loss = 1.92414768, grad/param norm = 2.1223e-01, time/batch = 0.6739s	
2021/33450 (epoch 3.021), train_loss = 2.02882775, grad/param norm = 2.4470e-01, time/batch = 0.6810s	
2022/33450 (epoch 3.022), train_loss = 2.02729018, grad/param norm = 2.5484e-01, time/batch = 0.6782s	
2023/33450 (epoch 3.024), train_loss = 1.90737005, grad/param norm = 2.1522e-01, time/batch = 0.6811s	
2024/33450 (epoch 3.025), train_loss = 1.97112428, grad/param norm = 1.9773e-01, time/batch = 0.6755s	
2025/33450 (epoch 3.027), train_loss = 2.03671983, grad/param norm = 2.0444e-01, time/batch = 0.6735s	
2026/33450 (epoch 3.028), train_loss = 2.09089069, grad/param norm = 1.8876e-01, time/batch = 0.6753s	
2027/33450 (epoch 3.030), train_loss = 2.20204957, grad/param norm = 2.3338e-01, time/batch = 0.6749s	
2028/33450 (epoch 3.031), train_loss = 2.02864873, grad/param norm = 2.3073e-01, time/batch = 0.6736s	
2029/33450 (epoch 3.033), train_loss = 2.16987491, grad/param norm = 2.0118e-01, time/batch = 0.6728s	
2030/33450 (epoch 3.034), train_loss = 2.14934483, grad/param norm = 2.3890e-01, time/batch = 0.6721s	
2031/33450 (epoch 3.036), train_loss = 1.89618874, grad/param norm = 2.0526e-01, time/batch = 0.6742s	
2032/33450 (epoch 3.037), train_loss = 2.00359661, grad/param norm = 1.8994e-01, time/batch = 0.6732s	
2033/33450 (epoch 3.039), train_loss = 1.98568675, grad/param norm = 1.9415e-01, time/batch = 0.6754s	
2034/33450 (epoch 3.040), train_loss = 2.13898174, grad/param norm = 1.9910e-01, time/batch = 0.6734s	
2035/33450 (epoch 3.042), train_loss = 2.04395776, grad/param norm = 2.1350e-01, time/batch = 0.6754s	
2036/33450 (epoch 3.043), train_loss = 2.01942988, grad/param norm = 2.0721e-01, time/batch = 0.6787s	
2037/33450 (epoch 3.045), train_loss = 2.09588700, grad/param norm = 2.2690e-01, time/batch = 0.6746s	
2038/33450 (epoch 3.046), train_loss = 1.95070223, grad/param norm = 2.1381e-01, time/batch = 0.6748s	
2039/33450 (epoch 3.048), train_loss = 1.76569902, grad/param norm = 2.1394e-01, time/batch = 0.6744s	
2040/33450 (epoch 3.049), train_loss = 1.98836072, grad/param norm = 1.9772e-01, time/batch = 0.6743s	
2041/33450 (epoch 3.051), train_loss = 1.95031167, grad/param norm = 1.9779e-01, time/batch = 0.6780s	
2042/33450 (epoch 3.052), train_loss = 2.11414791, grad/param norm = 2.1326e-01, time/batch = 0.6733s	
2043/33450 (epoch 3.054), train_loss = 1.97030015, grad/param norm = 2.2429e-01, time/batch = 0.6733s	
2044/33450 (epoch 3.055), train_loss = 2.04864675, grad/param norm = 2.4953e-01, time/batch = 0.6740s	
2045/33450 (epoch 3.057), train_loss = 2.00126632, grad/param norm = 2.3022e-01, time/batch = 0.6762s	
2046/33450 (epoch 3.058), train_loss = 1.84980735, grad/param norm = 1.9427e-01, time/batch = 0.6739s	
2047/33450 (epoch 3.060), train_loss = 1.99032964, grad/param norm = 2.1052e-01, time/batch = 0.6748s	
2048/33450 (epoch 3.061), train_loss = 1.98016391, grad/param norm = 2.0671e-01, time/batch = 0.6746s	
2049/33450 (epoch 3.063), train_loss = 1.89892026, grad/param norm = 1.8959e-01, time/batch = 0.7172s	
2050/33450 (epoch 3.064), train_loss = 1.88012338, grad/param norm = 2.1093e-01, time/batch = 0.6948s	
2051/33450 (epoch 3.066), train_loss = 1.91552065, grad/param norm = 2.2881e-01, time/batch = 0.6761s	
2052/33450 (epoch 3.067), train_loss = 2.02162882, grad/param norm = 1.9416e-01, time/batch = 0.6753s	
2053/33450 (epoch 3.069), train_loss = 2.08640329, grad/param norm = 2.4072e-01, time/batch = 0.6754s	
2054/33450 (epoch 3.070), train_loss = 1.98729906, grad/param norm = 2.2034e-01, time/batch = 0.6743s	
2055/33450 (epoch 3.072), train_loss = 2.01194228, grad/param norm = 2.3252e-01, time/batch = 0.6755s	
2056/33450 (epoch 3.073), train_loss = 1.96309891, grad/param norm = 1.9762e-01, time/batch = 0.6833s	
2057/33450 (epoch 3.075), train_loss = 1.96851458, grad/param norm = 2.3094e-01, time/batch = 0.6949s	
2058/33450 (epoch 3.076), train_loss = 2.05411490, grad/param norm = 2.1235e-01, time/batch = 0.6875s	
2059/33450 (epoch 3.078), train_loss = 2.03225944, grad/param norm = 1.8667e-01, time/batch = 0.6743s	
2060/33450 (epoch 3.079), train_loss = 1.82806311, grad/param norm = 2.0158e-01, time/batch = 0.6767s	
2061/33450 (epoch 3.081), train_loss = 1.97367677, grad/param norm = 1.9811e-01, time/batch = 0.6747s	
2062/33450 (epoch 3.082), train_loss = 2.03933960, grad/param norm = 2.1282e-01, time/batch = 0.6742s	
2063/33450 (epoch 3.084), train_loss = 1.96770165, grad/param norm = 2.1718e-01, time/batch = 0.6929s	
2064/33450 (epoch 3.085), train_loss = 2.01290919, grad/param norm = 2.0207e-01, time/batch = 0.7185s	
2065/33450 (epoch 3.087), train_loss = 2.11212904, grad/param norm = 1.9738e-01, time/batch = 0.6941s	
2066/33450 (epoch 3.088), train_loss = 2.02456446, grad/param norm = 2.3953e-01, time/batch = 0.6808s	
2067/33450 (epoch 3.090), train_loss = 2.05924050, grad/param norm = 2.3916e-01, time/batch = 0.6876s	
2068/33450 (epoch 3.091), train_loss = 1.86609590, grad/param norm = 1.8391e-01, time/batch = 0.6792s	
2069/33450 (epoch 3.093), train_loss = 1.76761541, grad/param norm = 1.8779e-01, time/batch = 0.6724s	
2070/33450 (epoch 3.094), train_loss = 1.86054322, grad/param norm = 1.8383e-01, time/batch = 0.6750s	
2071/33450 (epoch 3.096), train_loss = 1.83162265, grad/param norm = 2.2733e-01, time/batch = 0.6756s	
2072/33450 (epoch 3.097), train_loss = 2.07749152, grad/param norm = 2.3337e-01, time/batch = 0.6735s	
2073/33450 (epoch 3.099), train_loss = 1.98271012, grad/param norm = 2.1942e-01, time/batch = 0.6728s	
2074/33450 (epoch 3.100), train_loss = 2.02320379, grad/param norm = 2.0584e-01, time/batch = 0.6814s	
2075/33450 (epoch 3.102), train_loss = 2.08472032, grad/param norm = 2.1165e-01, time/batch = 0.6729s	
2076/33450 (epoch 3.103), train_loss = 2.16538458, grad/param norm = 2.3853e-01, time/batch = 0.6735s	
2077/33450 (epoch 3.105), train_loss = 1.92010921, grad/param norm = 1.9985e-01, time/batch = 0.6737s	
2078/33450 (epoch 3.106), train_loss = 1.87906953, grad/param norm = 2.0642e-01, time/batch = 0.7080s	
2079/33450 (epoch 3.108), train_loss = 2.02238817, grad/param norm = 1.9756e-01, time/batch = 0.7054s	
2080/33450 (epoch 3.109), train_loss = 2.00499104, grad/param norm = 2.1307e-01, time/batch = 0.6744s	
2081/33450 (epoch 3.111), train_loss = 2.12259506, grad/param norm = 2.1793e-01, time/batch = 0.6746s	
2082/33450 (epoch 3.112), train_loss = 2.13387370, grad/param norm = 2.0390e-01, time/batch = 0.6743s	
2083/33450 (epoch 3.114), train_loss = 2.06015388, grad/param norm = 2.4337e-01, time/batch = 0.6762s	
2084/33450 (epoch 3.115), train_loss = 2.00899579, grad/param norm = 2.2098e-01, time/batch = 0.6740s	
2085/33450 (epoch 3.117), train_loss = 2.04990601, grad/param norm = 2.2951e-01, time/batch = 0.6737s	
2086/33450 (epoch 3.118), train_loss = 2.02585530, grad/param norm = 2.0624e-01, time/batch = 0.6751s	
2087/33450 (epoch 3.120), train_loss = 2.20615910, grad/param norm = 2.2254e-01, time/batch = 0.6724s	
2088/33450 (epoch 3.121), train_loss = 1.86126125, grad/param norm = 2.0053e-01, time/batch = 0.6767s	
2089/33450 (epoch 3.123), train_loss = 2.03676747, grad/param norm = 2.1759e-01, time/batch = 0.6745s	
2090/33450 (epoch 3.124), train_loss = 1.87181310, grad/param norm = 2.1340e-01, time/batch = 0.6756s	
2091/33450 (epoch 3.126), train_loss = 1.93157603, grad/param norm = 1.9597e-01, time/batch = 0.6753s	
2092/33450 (epoch 3.127), train_loss = 2.03678060, grad/param norm = 1.8442e-01, time/batch = 0.6813s	
2093/33450 (epoch 3.129), train_loss = 2.02515688, grad/param norm = 1.8192e-01, time/batch = 0.7187s	
2094/33450 (epoch 3.130), train_loss = 2.10107992, grad/param norm = 2.3410e-01, time/batch = 0.6885s	
2095/33450 (epoch 3.132), train_loss = 2.09517968, grad/param norm = 2.4139e-01, time/batch = 0.6741s	
2096/33450 (epoch 3.133), train_loss = 2.17658029, grad/param norm = 2.1245e-01, time/batch = 0.6743s	
2097/33450 (epoch 3.135), train_loss = 2.02904107, grad/param norm = 2.0041e-01, time/batch = 0.6772s	
2098/33450 (epoch 3.136), train_loss = 2.13144574, grad/param norm = 2.0733e-01, time/batch = 0.6758s	
2099/33450 (epoch 3.138), train_loss = 2.06065524, grad/param norm = 2.1434e-01, time/batch = 0.6789s	
2100/33450 (epoch 3.139), train_loss = 1.86027511, grad/param norm = 1.9431e-01, time/batch = 0.6758s	
2101/33450 (epoch 3.141), train_loss = 1.83198921, grad/param norm = 1.9741e-01, time/batch = 0.6860s	
2102/33450 (epoch 3.142), train_loss = 1.90233808, grad/param norm = 2.0840e-01, time/batch = 0.6837s	
2103/33450 (epoch 3.143), train_loss = 2.34027227, grad/param norm = 2.3755e-01, time/batch = 0.6795s	
2104/33450 (epoch 3.145), train_loss = 2.02361640, grad/param norm = 2.1701e-01, time/batch = 0.6766s	
2105/33450 (epoch 3.146), train_loss = 1.86260237, grad/param norm = 1.8379e-01, time/batch = 0.6757s	
2106/33450 (epoch 3.148), train_loss = 2.02683318, grad/param norm = 2.3254e-01, time/batch = 0.6749s	
2107/33450 (epoch 3.149), train_loss = 2.10424788, grad/param norm = 2.4354e-01, time/batch = 0.6737s	
2108/33450 (epoch 3.151), train_loss = 2.15821488, grad/param norm = 2.2581e-01, time/batch = 0.6850s	
2109/33450 (epoch 3.152), train_loss = 2.06566139, grad/param norm = 2.1675e-01, time/batch = 0.6800s	
2110/33450 (epoch 3.154), train_loss = 2.09277027, grad/param norm = 2.6132e-01, time/batch = 0.6920s	
2111/33450 (epoch 3.155), train_loss = 2.12854703, grad/param norm = 2.3815e-01, time/batch = 0.6765s	
2112/33450 (epoch 3.157), train_loss = 2.04489641, grad/param norm = 2.0958e-01, time/batch = 0.6777s	
2113/33450 (epoch 3.158), train_loss = 2.15835597, grad/param norm = 2.2519e-01, time/batch = 0.6742s	
2114/33450 (epoch 3.160), train_loss = 2.01668811, grad/param norm = 1.9873e-01, time/batch = 0.6754s	
2115/33450 (epoch 3.161), train_loss = 1.96521353, grad/param norm = 2.1624e-01, time/batch = 0.6748s	
2116/33450 (epoch 3.163), train_loss = 1.84310693, grad/param norm = 1.9484e-01, time/batch = 0.6748s	
2117/33450 (epoch 3.164), train_loss = 2.06683350, grad/param norm = 2.1398e-01, time/batch = 0.6747s	
2118/33450 (epoch 3.166), train_loss = 2.08048446, grad/param norm = 2.0319e-01, time/batch = 0.6838s	
2119/33450 (epoch 3.167), train_loss = 2.04069345, grad/param norm = 1.9724e-01, time/batch = 0.6792s	
2120/33450 (epoch 3.169), train_loss = 2.06076252, grad/param norm = 2.1935e-01, time/batch = 0.6735s	
2121/33450 (epoch 3.170), train_loss = 2.06945072, grad/param norm = 2.0184e-01, time/batch = 0.6771s	
2122/33450 (epoch 3.172), train_loss = 1.90011077, grad/param norm = 2.0935e-01, time/batch = 0.7131s	
2123/33450 (epoch 3.173), train_loss = 2.00701080, grad/param norm = 2.0578e-01, time/batch = 0.7001s	
2124/33450 (epoch 3.175), train_loss = 2.25129769, grad/param norm = 2.3399e-01, time/batch = 0.6734s	
2125/33450 (epoch 3.176), train_loss = 2.16377766, grad/param norm = 2.4362e-01, time/batch = 0.6719s	
2126/33450 (epoch 3.178), train_loss = 1.95529911, grad/param norm = 2.2109e-01, time/batch = 0.6722s	
2127/33450 (epoch 3.179), train_loss = 1.90992094, grad/param norm = 2.0297e-01, time/batch = 0.6726s	
2128/33450 (epoch 3.181), train_loss = 2.08239775, grad/param norm = 1.9757e-01, time/batch = 0.6723s	
2129/33450 (epoch 3.182), train_loss = 2.10213702, grad/param norm = 2.0543e-01, time/batch = 0.6756s	
2130/33450 (epoch 3.184), train_loss = 1.85537053, grad/param norm = 2.0650e-01, time/batch = 0.6894s	
2131/33450 (epoch 3.185), train_loss = 1.94266516, grad/param norm = 2.0855e-01, time/batch = 0.6901s	
2132/33450 (epoch 3.187), train_loss = 1.81212975, grad/param norm = 1.7602e-01, time/batch = 0.6761s	
2133/33450 (epoch 3.188), train_loss = 1.92517030, grad/param norm = 2.1718e-01, time/batch = 0.6744s	
2134/33450 (epoch 3.190), train_loss = 2.03379160, grad/param norm = 2.0513e-01, time/batch = 0.6778s	
2135/33450 (epoch 3.191), train_loss = 2.13572452, grad/param norm = 2.2842e-01, time/batch = 0.6773s	
2136/33450 (epoch 3.193), train_loss = 2.09232277, grad/param norm = 2.1475e-01, time/batch = 0.6845s	
2137/33450 (epoch 3.194), train_loss = 2.07249900, grad/param norm = 2.4970e-01, time/batch = 0.7182s	
2138/33450 (epoch 3.196), train_loss = 1.97317319, grad/param norm = 2.1368e-01, time/batch = 0.6892s	
2139/33450 (epoch 3.197), train_loss = 1.98614478, grad/param norm = 1.9626e-01, time/batch = 0.6747s	
2140/33450 (epoch 3.199), train_loss = 1.92545881, grad/param norm = 2.0668e-01, time/batch = 0.7172s	
2141/33450 (epoch 3.200), train_loss = 2.16431611, grad/param norm = 2.3996e-01, time/batch = 0.7198s	
2142/33450 (epoch 3.202), train_loss = 1.99748555, grad/param norm = 3.1608e-01, time/batch = 0.6924s	
2143/33450 (epoch 3.203), train_loss = 1.81878340, grad/param norm = 2.2610e-01, time/batch = 0.6807s	
2144/33450 (epoch 3.205), train_loss = 2.09077338, grad/param norm = 2.3038e-01, time/batch = 0.6742s	
2145/33450 (epoch 3.206), train_loss = 2.14280781, grad/param norm = 2.2686e-01, time/batch = 0.6737s	
2146/33450 (epoch 3.208), train_loss = 1.98754897, grad/param norm = 2.3669e-01, time/batch = 0.6744s	
2147/33450 (epoch 3.209), train_loss = 2.14952129, grad/param norm = 2.0960e-01, time/batch = 0.6754s	
2148/33450 (epoch 3.211), train_loss = 1.97167134, grad/param norm = 2.0756e-01, time/batch = 0.6737s	
2149/33450 (epoch 3.212), train_loss = 2.03290395, grad/param norm = 1.9878e-01, time/batch = 0.6765s	
2150/33450 (epoch 3.214), train_loss = 2.09217630, grad/param norm = 2.1205e-01, time/batch = 0.6759s	
2151/33450 (epoch 3.215), train_loss = 2.09524483, grad/param norm = 2.0439e-01, time/batch = 0.6784s	
2152/33450 (epoch 3.217), train_loss = 1.93242295, grad/param norm = 2.0012e-01, time/batch = 0.7042s	
2153/33450 (epoch 3.218), train_loss = 1.93815311, grad/param norm = 2.0431e-01, time/batch = 0.7140s	
2154/33450 (epoch 3.220), train_loss = 1.79561470, grad/param norm = 1.9808e-01, time/batch = 0.7015s	
2155/33450 (epoch 3.221), train_loss = 2.17276902, grad/param norm = 2.5602e-01, time/batch = 0.6889s	
2156/33450 (epoch 3.223), train_loss = 2.07846521, grad/param norm = 2.0469e-01, time/batch = 0.6759s	
2157/33450 (epoch 3.224), train_loss = 1.96091909, grad/param norm = 1.9557e-01, time/batch = 0.6739s	
2158/33450 (epoch 3.226), train_loss = 2.02885104, grad/param norm = 1.8313e-01, time/batch = 0.6756s	
2159/33450 (epoch 3.227), train_loss = 1.95968311, grad/param norm = 2.0532e-01, time/batch = 0.6768s	
2160/33450 (epoch 3.229), train_loss = 1.85884044, grad/param norm = 1.9446e-01, time/batch = 0.6736s	
2161/33450 (epoch 3.230), train_loss = 1.90969383, grad/param norm = 2.0166e-01, time/batch = 0.6751s	
2162/33450 (epoch 3.232), train_loss = 2.06042836, grad/param norm = 2.0777e-01, time/batch = 0.6829s	
2163/33450 (epoch 3.233), train_loss = 2.03924009, grad/param norm = 1.9490e-01, time/batch = 0.6880s	
2164/33450 (epoch 3.235), train_loss = 1.94267827, grad/param norm = 2.2231e-01, time/batch = 0.6776s	
2165/33450 (epoch 3.236), train_loss = 1.89749741, grad/param norm = 2.1115e-01, time/batch = 0.7186s	
2166/33450 (epoch 3.238), train_loss = 1.82697912, grad/param norm = 2.0847e-01, time/batch = 0.7182s	
2167/33450 (epoch 3.239), train_loss = 2.02339614, grad/param norm = 2.1121e-01, time/batch = 0.6854s	
2168/33450 (epoch 3.241), train_loss = 2.15841329, grad/param norm = 2.2014e-01, time/batch = 0.6739s	
2169/33450 (epoch 3.242), train_loss = 2.04990416, grad/param norm = 2.0491e-01, time/batch = 0.6741s	
2170/33450 (epoch 3.244), train_loss = 2.15186418, grad/param norm = 2.3416e-01, time/batch = 0.6766s	
2171/33450 (epoch 3.245), train_loss = 1.90732991, grad/param norm = 2.3677e-01, time/batch = 0.6777s	
2172/33450 (epoch 3.247), train_loss = 2.07507342, grad/param norm = 2.4465e-01, time/batch = 0.6785s	
2173/33450 (epoch 3.248), train_loss = 1.81828422, grad/param norm = 2.1473e-01, time/batch = 0.6766s	
2174/33450 (epoch 3.250), train_loss = 1.83909023, grad/param norm = 1.8710e-01, time/batch = 0.6755s	
2175/33450 (epoch 3.251), train_loss = 1.81363215, grad/param norm = 1.9842e-01, time/batch = 0.6749s	
2176/33450 (epoch 3.253), train_loss = 1.94306977, grad/param norm = 2.0333e-01, time/batch = 0.6749s	
2177/33450 (epoch 3.254), train_loss = 2.12508756, grad/param norm = 2.8524e-01, time/batch = 0.6752s	
2178/33450 (epoch 3.256), train_loss = 2.24073420, grad/param norm = 2.5948e-01, time/batch = 0.6801s	
2179/33450 (epoch 3.257), train_loss = 1.92850143, grad/param norm = 2.5779e-01, time/batch = 0.6753s	
2180/33450 (epoch 3.259), train_loss = 1.92177726, grad/param norm = 2.3679e-01, time/batch = 0.6768s	
2181/33450 (epoch 3.260), train_loss = 1.97432806, grad/param norm = 1.9530e-01, time/batch = 0.6838s	
2182/33450 (epoch 3.262), train_loss = 2.21478646, grad/param norm = 2.2137e-01, time/batch = 0.6974s	
2183/33450 (epoch 3.263), train_loss = 2.02904899, grad/param norm = 1.9768e-01, time/batch = 0.6769s	
2184/33450 (epoch 3.265), train_loss = 1.99233242, grad/param norm = 2.1201e-01, time/batch = 0.6776s	
2185/33450 (epoch 3.266), train_loss = 2.14727731, grad/param norm = 2.1906e-01, time/batch = 0.6772s	
2186/33450 (epoch 3.268), train_loss = 1.99827350, grad/param norm = 1.9230e-01, time/batch = 0.6755s	
2187/33450 (epoch 3.269), train_loss = 1.78554507, grad/param norm = 2.0800e-01, time/batch = 0.6752s	
2188/33450 (epoch 3.271), train_loss = 1.94952616, grad/param norm = 2.4630e-01, time/batch = 0.6806s	
2189/33450 (epoch 3.272), train_loss = 1.96994905, grad/param norm = 2.1252e-01, time/batch = 0.6819s	
2190/33450 (epoch 3.274), train_loss = 1.98055292, grad/param norm = 2.2133e-01, time/batch = 0.6744s	
2191/33450 (epoch 3.275), train_loss = 1.98380503, grad/param norm = 2.1086e-01, time/batch = 0.6796s	
2192/33450 (epoch 3.277), train_loss = 1.81202155, grad/param norm = 2.0925e-01, time/batch = 0.6781s	
2193/33450 (epoch 3.278), train_loss = 1.93875720, grad/param norm = 2.0758e-01, time/batch = 0.6756s	
2194/33450 (epoch 3.280), train_loss = 1.91930851, grad/param norm = 2.1109e-01, time/batch = 0.6770s	
2195/33450 (epoch 3.281), train_loss = 2.02345173, grad/param norm = 2.1275e-01, time/batch = 0.6805s	
2196/33450 (epoch 3.283), train_loss = 1.89301134, grad/param norm = 2.0766e-01, time/batch = 0.6830s	
2197/33450 (epoch 3.284), train_loss = 2.07334344, grad/param norm = 2.1140e-01, time/batch = 0.6747s	
2198/33450 (epoch 3.286), train_loss = 2.02019339, grad/param norm = 2.0083e-01, time/batch = 0.6883s	
2199/33450 (epoch 3.287), train_loss = 1.83136718, grad/param norm = 2.4857e-01, time/batch = 0.6777s	
2200/33450 (epoch 3.288), train_loss = 1.97414902, grad/param norm = 2.2640e-01, time/batch = 0.6752s	
2201/33450 (epoch 3.290), train_loss = 1.93235284, grad/param norm = 2.0090e-01, time/batch = 0.6755s	
2202/33450 (epoch 3.291), train_loss = 2.02233243, grad/param norm = 2.2368e-01, time/batch = 0.6746s	
2203/33450 (epoch 3.293), train_loss = 1.94309745, grad/param norm = 2.2228e-01, time/batch = 0.6847s	
2204/33450 (epoch 3.294), train_loss = 1.88070823, grad/param norm = 1.8131e-01, time/batch = 0.6774s	
2205/33450 (epoch 3.296), train_loss = 1.95642781, grad/param norm = 1.9757e-01, time/batch = 0.6750s	
2206/33450 (epoch 3.297), train_loss = 2.02418856, grad/param norm = 2.1504e-01, time/batch = 0.6739s	
2207/33450 (epoch 3.299), train_loss = 1.95906732, grad/param norm = 2.1274e-01, time/batch = 0.6736s	
2208/33450 (epoch 3.300), train_loss = 2.01577840, grad/param norm = 2.0982e-01, time/batch = 0.6831s	
2209/33450 (epoch 3.302), train_loss = 1.95104196, grad/param norm = 2.0835e-01, time/batch = 0.7042s	
2210/33450 (epoch 3.303), train_loss = 1.90223772, grad/param norm = 2.1718e-01, time/batch = 0.7178s	
2211/33450 (epoch 3.305), train_loss = 2.09760485, grad/param norm = 2.2341e-01, time/batch = 0.6852s	
2212/33450 (epoch 3.306), train_loss = 2.22505999, grad/param norm = 2.1932e-01, time/batch = 0.6736s	
2213/33450 (epoch 3.308), train_loss = 2.05508313, grad/param norm = 1.9956e-01, time/batch = 0.6784s	
2214/33450 (epoch 3.309), train_loss = 2.08254210, grad/param norm = 2.1321e-01, time/batch = 0.7127s	
2215/33450 (epoch 3.311), train_loss = 2.02162570, grad/param norm = 2.1113e-01, time/batch = 0.7157s	
2216/33450 (epoch 3.312), train_loss = 2.19083303, grad/param norm = 2.5820e-01, time/batch = 0.7111s	
2217/33450 (epoch 3.314), train_loss = 1.94351595, grad/param norm = 2.3374e-01, time/batch = 0.6925s	
2218/33450 (epoch 3.315), train_loss = 1.90610236, grad/param norm = 1.9560e-01, time/batch = 0.6930s	
2219/33450 (epoch 3.317), train_loss = 1.99891635, grad/param norm = 2.0398e-01, time/batch = 0.6911s	
2220/33450 (epoch 3.318), train_loss = 2.01466220, grad/param norm = 1.9127e-01, time/batch = 0.6914s	
2221/33450 (epoch 3.320), train_loss = 1.88130359, grad/param norm = 1.9726e-01, time/batch = 0.6952s	
2222/33450 (epoch 3.321), train_loss = 1.88633306, grad/param norm = 2.2329e-01, time/batch = 0.6925s	
2223/33450 (epoch 3.323), train_loss = 1.78338070, grad/param norm = 2.0408e-01, time/batch = 0.6951s	
2224/33450 (epoch 3.324), train_loss = 1.80055806, grad/param norm = 1.9043e-01, time/batch = 0.7204s	
2225/33450 (epoch 3.326), train_loss = 1.92327447, grad/param norm = 2.1657e-01, time/batch = 0.6906s	
2226/33450 (epoch 3.327), train_loss = 1.86324561, grad/param norm = 2.3044e-01, time/batch = 0.6718s	
2227/33450 (epoch 3.329), train_loss = 1.92898837, grad/param norm = 2.2246e-01, time/batch = 0.6707s	
2228/33450 (epoch 3.330), train_loss = 2.02007701, grad/param norm = 2.1297e-01, time/batch = 0.6706s	
2229/33450 (epoch 3.332), train_loss = 2.09737282, grad/param norm = 2.0178e-01, time/batch = 0.6739s	
2230/33450 (epoch 3.333), train_loss = 1.78210202, grad/param norm = 1.8937e-01, time/batch = 0.6714s	
2231/33450 (epoch 3.335), train_loss = 2.05549781, grad/param norm = 2.0286e-01, time/batch = 0.6742s	
2232/33450 (epoch 3.336), train_loss = 1.95054834, grad/param norm = 2.0296e-01, time/batch = 0.6754s	
2233/33450 (epoch 3.338), train_loss = 1.84793660, grad/param norm = 1.9672e-01, time/batch = 0.6721s	
2234/33450 (epoch 3.339), train_loss = 1.80365449, grad/param norm = 1.7379e-01, time/batch = 0.6756s	
2235/33450 (epoch 3.341), train_loss = 2.06396506, grad/param norm = 2.1298e-01, time/batch = 0.6732s	
2236/33450 (epoch 3.342), train_loss = 1.94424402, grad/param norm = 2.0317e-01, time/batch = 0.6717s	
2237/33450 (epoch 3.344), train_loss = 2.02499841, grad/param norm = 2.0367e-01, time/batch = 0.6716s	
2238/33450 (epoch 3.345), train_loss = 1.90210097, grad/param norm = 2.0375e-01, time/batch = 0.6866s	
2239/33450 (epoch 3.347), train_loss = 1.90355553, grad/param norm = 2.4196e-01, time/batch = 0.7187s	
2240/33450 (epoch 3.348), train_loss = 1.88530422, grad/param norm = 1.9057e-01, time/batch = 0.6892s	
2241/33450 (epoch 3.350), train_loss = 2.08832763, grad/param norm = 2.6496e-01, time/batch = 0.7010s	
2242/33450 (epoch 3.351), train_loss = 1.94951275, grad/param norm = 2.0275e-01, time/batch = 0.6798s	
2243/33450 (epoch 3.353), train_loss = 1.82672503, grad/param norm = 2.0322e-01, time/batch = 0.6755s	
2244/33450 (epoch 3.354), train_loss = 1.77466975, grad/param norm = 1.9170e-01, time/batch = 0.6747s	
2245/33450 (epoch 3.356), train_loss = 1.93213154, grad/param norm = 2.1258e-01, time/batch = 0.6737s	
2246/33450 (epoch 3.357), train_loss = 1.70783275, grad/param norm = 1.7965e-01, time/batch = 0.6722s	
2247/33450 (epoch 3.359), train_loss = 1.84731488, grad/param norm = 2.1332e-01, time/batch = 0.6756s	
2248/33450 (epoch 3.360), train_loss = 2.01928590, grad/param norm = 1.9180e-01, time/batch = 0.6732s	
2249/33450 (epoch 3.362), train_loss = 2.07887411, grad/param norm = 2.1266e-01, time/batch = 0.7049s	
2250/33450 (epoch 3.363), train_loss = 1.96633283, grad/param norm = 2.3104e-01, time/batch = 0.7152s	
2251/33450 (epoch 3.365), train_loss = 1.91993256, grad/param norm = 1.9092e-01, time/batch = 0.7185s	
2252/33450 (epoch 3.366), train_loss = 2.04389028, grad/param norm = 2.1523e-01, time/batch = 0.7178s	
2253/33450 (epoch 3.368), train_loss = 2.01752592, grad/param norm = 1.8597e-01, time/batch = 0.6757s	
2254/33450 (epoch 3.369), train_loss = 1.86868741, grad/param norm = 1.9641e-01, time/batch = 0.6744s	
2255/33450 (epoch 3.371), train_loss = 1.96986439, grad/param norm = 2.1859e-01, time/batch = 0.6741s	
2256/33450 (epoch 3.372), train_loss = 2.01930813, grad/param norm = 2.2448e-01, time/batch = 0.6717s	
2257/33450 (epoch 3.374), train_loss = 2.32167782, grad/param norm = 2.2692e-01, time/batch = 0.6737s	
2258/33450 (epoch 3.375), train_loss = 2.10215097, grad/param norm = 2.2205e-01, time/batch = 0.6759s	
2259/33450 (epoch 3.377), train_loss = 2.02550467, grad/param norm = 2.0656e-01, time/batch = 0.6761s	
2260/33450 (epoch 3.378), train_loss = 2.10511139, grad/param norm = 2.0734e-01, time/batch = 0.6743s	
2261/33450 (epoch 3.380), train_loss = 2.11160479, grad/param norm = 2.0026e-01, time/batch = 0.6762s	
2262/33450 (epoch 3.381), train_loss = 2.02657958, grad/param norm = 1.9084e-01, time/batch = 0.6727s	
2263/33450 (epoch 3.383), train_loss = 2.10014671, grad/param norm = 1.9663e-01, time/batch = 0.6730s	
2264/33450 (epoch 3.384), train_loss = 2.00666929, grad/param norm = 1.8376e-01, time/batch = 0.6750s	
2265/33450 (epoch 3.386), train_loss = 2.02724205, grad/param norm = 1.9163e-01, time/batch = 0.6733s	
2266/33450 (epoch 3.387), train_loss = 2.10667036, grad/param norm = 2.2351e-01, time/batch = 0.6934s	
2267/33450 (epoch 3.389), train_loss = 2.07152148, grad/param norm = 2.3218e-01, time/batch = 0.6800s	
2268/33450 (epoch 3.390), train_loss = 2.11078960, grad/param norm = 2.0182e-01, time/batch = 0.6810s	
2269/33450 (epoch 3.392), train_loss = 2.03561206, grad/param norm = 2.2539e-01, time/batch = 0.6806s	
2270/33450 (epoch 3.393), train_loss = 1.83209007, grad/param norm = 2.0240e-01, time/batch = 0.6741s	
2271/33450 (epoch 3.395), train_loss = 1.91394146, grad/param norm = 1.9313e-01, time/batch = 0.6752s	
2272/33450 (epoch 3.396), train_loss = 1.99635874, grad/param norm = 2.2847e-01, time/batch = 0.7104s	
2273/33450 (epoch 3.398), train_loss = 2.16329695, grad/param norm = 2.3176e-01, time/batch = 0.7032s	
2274/33450 (epoch 3.399), train_loss = 2.09578561, grad/param norm = 2.3132e-01, time/batch = 0.6763s	
2275/33450 (epoch 3.401), train_loss = 2.12644868, grad/param norm = 2.2215e-01, time/batch = 0.6751s	
2276/33450 (epoch 3.402), train_loss = 1.88403624, grad/param norm = 2.4001e-01, time/batch = 0.6881s	
2277/33450 (epoch 3.404), train_loss = 1.94155401, grad/param norm = 2.0030e-01, time/batch = 0.6779s	
2278/33450 (epoch 3.405), train_loss = 1.98198729, grad/param norm = 2.0424e-01, time/batch = 0.6748s	
2279/33450 (epoch 3.407), train_loss = 1.94449940, grad/param norm = 2.0248e-01, time/batch = 0.6739s	
2280/33450 (epoch 3.408), train_loss = 2.12841947, grad/param norm = 2.4812e-01, time/batch = 0.6771s	
2281/33450 (epoch 3.410), train_loss = 2.05428058, grad/param norm = 2.1069e-01, time/batch = 0.6764s	
2282/33450 (epoch 3.411), train_loss = 1.86333478, grad/param norm = 1.9670e-01, time/batch = 0.6748s	
2283/33450 (epoch 3.413), train_loss = 2.01051144, grad/param norm = 2.0933e-01, time/batch = 0.6738s	
2284/33450 (epoch 3.414), train_loss = 2.01969530, grad/param norm = 2.0549e-01, time/batch = 0.6768s	
2285/33450 (epoch 3.416), train_loss = 2.00473443, grad/param norm = 2.1177e-01, time/batch = 0.6728s	
2286/33450 (epoch 3.417), train_loss = 1.88509379, grad/param norm = 2.0945e-01, time/batch = 0.6730s	
2287/33450 (epoch 3.419), train_loss = 1.73618983, grad/param norm = 2.0897e-01, time/batch = 0.6753s	
2288/33450 (epoch 3.420), train_loss = 1.88542835, grad/param norm = 1.9353e-01, time/batch = 0.6762s	
2289/33450 (epoch 3.422), train_loss = 1.77004929, grad/param norm = 1.7762e-01, time/batch = 0.6742s	
2290/33450 (epoch 3.423), train_loss = 1.96250594, grad/param norm = 2.0607e-01, time/batch = 0.6746s	
2291/33450 (epoch 3.425), train_loss = 1.86832049, grad/param norm = 1.8725e-01, time/batch = 0.6752s	
2292/33450 (epoch 3.426), train_loss = 1.90224721, grad/param norm = 1.8530e-01, time/batch = 0.6734s	
2293/33450 (epoch 3.428), train_loss = 1.84747455, grad/param norm = 1.9954e-01, time/batch = 0.6718s	
2294/33450 (epoch 3.429), train_loss = 1.98930634, grad/param norm = 2.2192e-01, time/batch = 0.6717s	
2295/33450 (epoch 3.430), train_loss = 1.94009730, grad/param norm = 2.3760e-01, time/batch = 0.6726s	
2296/33450 (epoch 3.432), train_loss = 1.99207743, grad/param norm = 2.0573e-01, time/batch = 0.6729s	
2297/33450 (epoch 3.433), train_loss = 1.95309785, grad/param norm = 2.0242e-01, time/batch = 0.6736s	
2298/33450 (epoch 3.435), train_loss = 1.88028252, grad/param norm = 1.8227e-01, time/batch = 0.6764s	
2299/33450 (epoch 3.436), train_loss = 1.86081807, grad/param norm = 1.8424e-01, time/batch = 0.6734s	
2300/33450 (epoch 3.438), train_loss = 1.83897278, grad/param norm = 1.9191e-01, time/batch = 0.6725s	
2301/33450 (epoch 3.439), train_loss = 1.94792099, grad/param norm = 2.0587e-01, time/batch = 0.6738s	
2302/33450 (epoch 3.441), train_loss = 2.22689374, grad/param norm = 2.1355e-01, time/batch = 0.6750s	
2303/33450 (epoch 3.442), train_loss = 1.95203207, grad/param norm = 1.8587e-01, time/batch = 0.6741s	
2304/33450 (epoch 3.444), train_loss = 2.05641447, grad/param norm = 2.1324e-01, time/batch = 0.6889s	
2305/33450 (epoch 3.445), train_loss = 2.09000547, grad/param norm = 2.1149e-01, time/batch = 0.6954s	
2306/33450 (epoch 3.447), train_loss = 2.07851041, grad/param norm = 2.2966e-01, time/batch = 0.6941s	
2307/33450 (epoch 3.448), train_loss = 2.01810592, grad/param norm = 2.1414e-01, time/batch = 0.6946s	
2308/33450 (epoch 3.450), train_loss = 1.93572685, grad/param norm = 2.0705e-01, time/batch = 0.6921s	
2309/33450 (epoch 3.451), train_loss = 2.03947683, grad/param norm = 2.0581e-01, time/batch = 0.6824s	
2310/33450 (epoch 3.453), train_loss = 1.89880639, grad/param norm = 2.0543e-01, time/batch = 0.6898s	
2311/33450 (epoch 3.454), train_loss = 1.92270750, grad/param norm = 2.0876e-01, time/batch = 0.6942s	
2312/33450 (epoch 3.456), train_loss = 1.84744899, grad/param norm = 1.9605e-01, time/batch = 0.6940s	
2313/33450 (epoch 3.457), train_loss = 2.05387653, grad/param norm = 2.0900e-01, time/batch = 0.6951s	
2314/33450 (epoch 3.459), train_loss = 1.80734411, grad/param norm = 1.9488e-01, time/batch = 0.6994s	
2315/33450 (epoch 3.460), train_loss = 2.13560823, grad/param norm = 2.1903e-01, time/batch = 0.6768s	
2316/33450 (epoch 3.462), train_loss = 2.14563188, grad/param norm = 2.3610e-01, time/batch = 0.7156s	
2317/33450 (epoch 3.463), train_loss = 1.93281956, grad/param norm = 2.4724e-01, time/batch = 0.6929s	
2318/33450 (epoch 3.465), train_loss = 1.88171638, grad/param norm = 2.0907e-01, time/batch = 0.6740s	
2319/33450 (epoch 3.466), train_loss = 2.03901916, grad/param norm = 2.1363e-01, time/batch = 0.6731s	
2320/33450 (epoch 3.468), train_loss = 1.99751461, grad/param norm = 2.0082e-01, time/batch = 0.6736s	
2321/33450 (epoch 3.469), train_loss = 2.07778954, grad/param norm = 2.2621e-01, time/batch = 0.6788s	
2322/33450 (epoch 3.471), train_loss = 2.02695801, grad/param norm = 1.9669e-01, time/batch = 0.6834s	
2323/33450 (epoch 3.472), train_loss = 1.99367706, grad/param norm = 1.9938e-01, time/batch = 0.6800s	
2324/33450 (epoch 3.474), train_loss = 2.29662692, grad/param norm = 2.3944e-01, time/batch = 0.6844s	
2325/33450 (epoch 3.475), train_loss = 2.03615323, grad/param norm = 2.3588e-01, time/batch = 0.6950s	
2326/33450 (epoch 3.477), train_loss = 1.85736587, grad/param norm = 1.9002e-01, time/batch = 0.6886s	
2327/33450 (epoch 3.478), train_loss = 1.81378407, grad/param norm = 1.9204e-01, time/batch = 0.7099s	
2328/33450 (epoch 3.480), train_loss = 1.71140047, grad/param norm = 1.9261e-01, time/batch = 0.7047s	
2329/33450 (epoch 3.481), train_loss = 1.80957894, grad/param norm = 1.8962e-01, time/batch = 0.7032s	
2330/33450 (epoch 3.483), train_loss = 1.73581701, grad/param norm = 1.9491e-01, time/batch = 0.7118s	
2331/33450 (epoch 3.484), train_loss = 1.86093468, grad/param norm = 1.8703e-01, time/batch = 0.7180s	
2332/33450 (epoch 3.486), train_loss = 2.00242017, grad/param norm = 2.0346e-01, time/batch = 0.6925s	
2333/33450 (epoch 3.487), train_loss = 1.90928474, grad/param norm = 1.9627e-01, time/batch = 0.6911s	
2334/33450 (epoch 3.489), train_loss = 1.97801123, grad/param norm = 2.0325e-01, time/batch = 0.6922s	
2335/33450 (epoch 3.490), train_loss = 2.01944536, grad/param norm = 1.9622e-01, time/batch = 0.6934s	
2336/33450 (epoch 3.492), train_loss = 2.03557286, grad/param norm = 2.0503e-01, time/batch = 0.7013s	
2337/33450 (epoch 3.493), train_loss = 2.17126914, grad/param norm = 2.2742e-01, time/batch = 0.7073s	
2338/33450 (epoch 3.495), train_loss = 2.04837622, grad/param norm = 2.2876e-01, time/batch = 0.6919s	
2339/33450 (epoch 3.496), train_loss = 2.09224148, grad/param norm = 2.2280e-01, time/batch = 0.6945s	
2340/33450 (epoch 3.498), train_loss = 2.11663165, grad/param norm = 2.1451e-01, time/batch = 0.6834s	
2341/33450 (epoch 3.499), train_loss = 1.91447892, grad/param norm = 1.9593e-01, time/batch = 0.6941s	
2342/33450 (epoch 3.501), train_loss = 2.08230969, grad/param norm = 2.1321e-01, time/batch = 0.6950s	
2343/33450 (epoch 3.502), train_loss = 1.93076262, grad/param norm = 1.7998e-01, time/batch = 0.6765s	
2344/33450 (epoch 3.504), train_loss = 1.96335249, grad/param norm = 1.9282e-01, time/batch = 0.6841s	
2345/33450 (epoch 3.505), train_loss = 2.01251719, grad/param norm = 2.1326e-01, time/batch = 0.7188s	
2346/33450 (epoch 3.507), train_loss = 2.04371148, grad/param norm = 2.5409e-01, time/batch = 0.6833s	
2347/33450 (epoch 3.508), train_loss = 1.88001609, grad/param norm = 2.0943e-01, time/batch = 0.6932s	
2348/33450 (epoch 3.510), train_loss = 1.89647529, grad/param norm = 2.3678e-01, time/batch = 0.7100s	
2349/33450 (epoch 3.511), train_loss = 2.06566246, grad/param norm = 2.0876e-01, time/batch = 0.7109s	
2350/33450 (epoch 3.513), train_loss = 2.14699619, grad/param norm = 3.3729e-01, time/batch = 0.7099s	
2351/33450 (epoch 3.514), train_loss = 2.08762962, grad/param norm = 2.6991e-01, time/batch = 0.7152s	
2352/33450 (epoch 3.516), train_loss = 2.09032486, grad/param norm = 2.0091e-01, time/batch = 0.6938s	
2353/33450 (epoch 3.517), train_loss = 1.99515668, grad/param norm = 2.1131e-01, time/batch = 0.6785s	
2354/33450 (epoch 3.519), train_loss = 1.87990382, grad/param norm = 1.9405e-01, time/batch = 0.6836s	
2355/33450 (epoch 3.520), train_loss = 2.13530821, grad/param norm = 2.0642e-01, time/batch = 0.7181s	
2356/33450 (epoch 3.522), train_loss = 2.12567223, grad/param norm = 2.0061e-01, time/batch = 0.6828s	
2357/33450 (epoch 3.523), train_loss = 2.03045282, grad/param norm = 2.1132e-01, time/batch = 0.6735s	
2358/33450 (epoch 3.525), train_loss = 1.89951370, grad/param norm = 2.0423e-01, time/batch = 0.6713s	
2359/33450 (epoch 3.526), train_loss = 1.98560354, grad/param norm = 2.1115e-01, time/batch = 0.6771s	
2360/33450 (epoch 3.528), train_loss = 2.04166740, grad/param norm = 2.0233e-01, time/batch = 0.6733s	
2361/33450 (epoch 3.529), train_loss = 1.98895513, grad/param norm = 1.8415e-01, time/batch = 0.6734s	
2362/33450 (epoch 3.531), train_loss = 1.94102626, grad/param norm = 2.1191e-01, time/batch = 0.6726s	
2363/33450 (epoch 3.532), train_loss = 2.01213669, grad/param norm = 2.0315e-01, time/batch = 0.6792s	
2364/33450 (epoch 3.534), train_loss = 2.00828471, grad/param norm = 1.9941e-01, time/batch = 0.6740s	
2365/33450 (epoch 3.535), train_loss = 2.09880839, grad/param norm = 2.0092e-01, time/batch = 0.6743s	
2366/33450 (epoch 3.537), train_loss = 1.70867966, grad/param norm = 1.7891e-01, time/batch = 0.6734s	
2367/33450 (epoch 3.538), train_loss = 1.87899155, grad/param norm = 2.0419e-01, time/batch = 0.6729s	
2368/33450 (epoch 3.540), train_loss = 1.92697621, grad/param norm = 2.0396e-01, time/batch = 0.6742s	
2369/33450 (epoch 3.541), train_loss = 1.89404792, grad/param norm = 1.8648e-01, time/batch = 0.6741s	
2370/33450 (epoch 3.543), train_loss = 1.73969996, grad/param norm = 1.8136e-01, time/batch = 0.6834s	
2371/33450 (epoch 3.544), train_loss = 1.85945226, grad/param norm = 1.8734e-01, time/batch = 0.6754s	
2372/33450 (epoch 3.546), train_loss = 1.89710272, grad/param norm = 1.8696e-01, time/batch = 0.6774s	
2373/33450 (epoch 3.547), train_loss = 1.88131540, grad/param norm = 1.9450e-01, time/batch = 0.6732s	
2374/33450 (epoch 3.549), train_loss = 2.09280687, grad/param norm = 2.1398e-01, time/batch = 0.6770s	
2375/33450 (epoch 3.550), train_loss = 1.93648149, grad/param norm = 2.0639e-01, time/batch = 0.6760s	
2376/33450 (epoch 3.552), train_loss = 2.10862417, grad/param norm = 2.0065e-01, time/batch = 0.6766s	
2377/33450 (epoch 3.553), train_loss = 2.06554109, grad/param norm = 2.0007e-01, time/batch = 0.6749s	
2378/33450 (epoch 3.555), train_loss = 1.67296177, grad/param norm = 1.8248e-01, time/batch = 0.6745s	
2379/33450 (epoch 3.556), train_loss = 1.85271096, grad/param norm = 1.8594e-01, time/batch = 0.6742s	
2380/33450 (epoch 3.558), train_loss = 1.98479443, grad/param norm = 1.8572e-01, time/batch = 0.6744s	
2381/33450 (epoch 3.559), train_loss = 1.79511572, grad/param norm = 1.8728e-01, time/batch = 0.6761s	
2382/33450 (epoch 3.561), train_loss = 2.08015562, grad/param norm = 1.9553e-01, time/batch = 0.6756s	
2383/33450 (epoch 3.562), train_loss = 1.88422741, grad/param norm = 1.9526e-01, time/batch = 0.6879s	
2384/33450 (epoch 3.564), train_loss = 1.87777947, grad/param norm = 2.0986e-01, time/batch = 0.7143s	
2385/33450 (epoch 3.565), train_loss = 1.98229591, grad/param norm = 1.8606e-01, time/batch = 0.6998s	
2386/33450 (epoch 3.567), train_loss = 1.71883682, grad/param norm = 1.8678e-01, time/batch = 0.6736s	
2387/33450 (epoch 3.568), train_loss = 1.89330073, grad/param norm = 2.3996e-01, time/batch = 0.6734s	
2388/33450 (epoch 3.570), train_loss = 2.08762781, grad/param norm = 2.1375e-01, time/batch = 0.6739s	
2389/33450 (epoch 3.571), train_loss = 2.02477042, grad/param norm = 2.0891e-01, time/batch = 0.6737s	
2390/33450 (epoch 3.572), train_loss = 1.85085741, grad/param norm = 2.0049e-01, time/batch = 0.6748s	
2391/33450 (epoch 3.574), train_loss = 1.75749365, grad/param norm = 2.0854e-01, time/batch = 0.6759s	
2392/33450 (epoch 3.575), train_loss = 1.88601446, grad/param norm = 1.9123e-01, time/batch = 0.6751s	
2393/33450 (epoch 3.577), train_loss = 1.96705657, grad/param norm = 2.3427e-01, time/batch = 0.6749s	
2394/33450 (epoch 3.578), train_loss = 1.78306974, grad/param norm = 2.0259e-01, time/batch = 0.6735s	
2395/33450 (epoch 3.580), train_loss = 1.82195366, grad/param norm = 2.1031e-01, time/batch = 0.6737s	
2396/33450 (epoch 3.581), train_loss = 2.01607562, grad/param norm = 2.0418e-01, time/batch = 0.6731s	
2397/33450 (epoch 3.583), train_loss = 1.92188974, grad/param norm = 1.8819e-01, time/batch = 0.6801s	
2398/33450 (epoch 3.584), train_loss = 1.74663287, grad/param norm = 2.2590e-01, time/batch = 0.6802s	
2399/33450 (epoch 3.586), train_loss = 1.88659817, grad/param norm = 2.0179e-01, time/batch = 0.6781s	
2400/33450 (epoch 3.587), train_loss = 2.00116385, grad/param norm = 2.1209e-01, time/batch = 0.6833s	
2401/33450 (epoch 3.589), train_loss = 1.77128251, grad/param norm = 1.8015e-01, time/batch = 0.6818s	
2402/33450 (epoch 3.590), train_loss = 2.03299744, grad/param norm = 1.9387e-01, time/batch = 0.6786s	
2403/33450 (epoch 3.592), train_loss = 2.14423886, grad/param norm = 2.2454e-01, time/batch = 0.6819s	
2404/33450 (epoch 3.593), train_loss = 2.04455111, grad/param norm = 2.5079e-01, time/batch = 0.6804s	
2405/33450 (epoch 3.595), train_loss = 2.05810791, grad/param norm = 1.9957e-01, time/batch = 0.6785s	
2406/33450 (epoch 3.596), train_loss = 2.07754937, grad/param norm = 2.0755e-01, time/batch = 0.6779s	
2407/33450 (epoch 3.598), train_loss = 1.92673386, grad/param norm = 2.0322e-01, time/batch = 0.6784s	
2408/33450 (epoch 3.599), train_loss = 2.07352661, grad/param norm = 2.0002e-01, time/batch = 0.6773s	
2409/33450 (epoch 3.601), train_loss = 1.97120522, grad/param norm = 1.8819e-01, time/batch = 0.6750s	
2410/33450 (epoch 3.602), train_loss = 1.96907182, grad/param norm = 2.1071e-01, time/batch = 0.6748s	
2411/33450 (epoch 3.604), train_loss = 1.79162010, grad/param norm = 1.8594e-01, time/batch = 0.6761s	
2412/33450 (epoch 3.605), train_loss = 1.78790903, grad/param norm = 2.0978e-01, time/batch = 0.6756s	
2413/33450 (epoch 3.607), train_loss = 1.96935285, grad/param norm = 2.0349e-01, time/batch = 0.6745s	
2414/33450 (epoch 3.608), train_loss = 1.88270845, grad/param norm = 2.0407e-01, time/batch = 0.6998s	
2415/33450 (epoch 3.610), train_loss = 1.96720538, grad/param norm = 2.3389e-01, time/batch = 0.6811s	
2416/33450 (epoch 3.611), train_loss = 1.94881482, grad/param norm = 1.7767e-01, time/batch = 0.6904s	
2417/33450 (epoch 3.613), train_loss = 1.93350752, grad/param norm = 2.0060e-01, time/batch = 0.7053s	
2418/33450 (epoch 3.614), train_loss = 1.92712914, grad/param norm = 2.0266e-01, time/batch = 0.6965s	
2419/33450 (epoch 3.616), train_loss = 1.98366000, grad/param norm = 2.2745e-01, time/batch = 0.6849s	
2420/33450 (epoch 3.617), train_loss = 1.80461233, grad/param norm = 1.8176e-01, time/batch = 0.6766s	
2421/33450 (epoch 3.619), train_loss = 1.88441824, grad/param norm = 1.9525e-01, time/batch = 0.6795s	
2422/33450 (epoch 3.620), train_loss = 1.64713146, grad/param norm = 2.0277e-01, time/batch = 0.6779s	
2423/33450 (epoch 3.622), train_loss = 2.03627108, grad/param norm = 2.0018e-01, time/batch = 0.6761s	
2424/33450 (epoch 3.623), train_loss = 1.93491808, grad/param norm = 2.0232e-01, time/batch = 0.6829s	
2425/33450 (epoch 3.625), train_loss = 2.01799005, grad/param norm = 1.9681e-01, time/batch = 0.6735s	
2426/33450 (epoch 3.626), train_loss = 1.77127983, grad/param norm = 1.8932e-01, time/batch = 0.6743s	
2427/33450 (epoch 3.628), train_loss = 1.78135215, grad/param norm = 1.7593e-01, time/batch = 0.6742s	
2428/33450 (epoch 3.629), train_loss = 2.02152790, grad/param norm = 2.0662e-01, time/batch = 0.6731s	
2429/33450 (epoch 3.631), train_loss = 1.94080209, grad/param norm = 2.0628e-01, time/batch = 0.6745s	
2430/33450 (epoch 3.632), train_loss = 1.79538053, grad/param norm = 1.8916e-01, time/batch = 0.6853s	
2431/33450 (epoch 3.634), train_loss = 1.83366988, grad/param norm = 2.0047e-01, time/batch = 0.6769s	
2432/33450 (epoch 3.635), train_loss = 1.95757052, grad/param norm = 1.8637e-01, time/batch = 0.6987s	
2433/33450 (epoch 3.637), train_loss = 2.02186990, grad/param norm = 1.8588e-01, time/batch = 0.7129s	
2434/33450 (epoch 3.638), train_loss = 1.82501989, grad/param norm = 1.7830e-01, time/batch = 0.6801s	
2435/33450 (epoch 3.640), train_loss = 1.82338551, grad/param norm = 1.8119e-01, time/batch = 0.6782s	
2436/33450 (epoch 3.641), train_loss = 1.84087682, grad/param norm = 1.8635e-01, time/batch = 0.6770s	
2437/33450 (epoch 3.643), train_loss = 1.73522665, grad/param norm = 1.7672e-01, time/batch = 0.6750s	
2438/33450 (epoch 3.644), train_loss = 1.88773639, grad/param norm = 1.9819e-01, time/batch = 0.6766s	
2439/33450 (epoch 3.646), train_loss = 2.03977746, grad/param norm = 2.1520e-01, time/batch = 0.6755s	
2440/33450 (epoch 3.647), train_loss = 2.08886773, grad/param norm = 2.1343e-01, time/batch = 0.6742s	
2441/33450 (epoch 3.649), train_loss = 1.94187498, grad/param norm = 2.4386e-01, time/batch = 0.6762s	
2442/33450 (epoch 3.650), train_loss = 1.78783696, grad/param norm = 1.8973e-01, time/batch = 0.6771s	
2443/33450 (epoch 3.652), train_loss = 1.61883860, grad/param norm = 1.9780e-01, time/batch = 0.6754s	
2444/33450 (epoch 3.653), train_loss = 1.83512006, grad/param norm = 1.9379e-01, time/batch = 0.6767s	
2445/33450 (epoch 3.655), train_loss = 1.99760253, grad/param norm = 2.0398e-01, time/batch = 0.6739s	
2446/33450 (epoch 3.656), train_loss = 1.77521472, grad/param norm = 1.9531e-01, time/batch = 0.6728s	
2447/33450 (epoch 3.658), train_loss = 1.91746860, grad/param norm = 1.9648e-01, time/batch = 0.7141s	
2448/33450 (epoch 3.659), train_loss = 1.91445225, grad/param norm = 2.0539e-01, time/batch = 0.7045s	
2449/33450 (epoch 3.661), train_loss = 2.05141268, grad/param norm = 1.9273e-01, time/batch = 0.6806s	
2450/33450 (epoch 3.662), train_loss = 1.75390772, grad/param norm = 1.8990e-01, time/batch = 0.6780s	
2451/33450 (epoch 3.664), train_loss = 1.98347940, grad/param norm = 1.8587e-01, time/batch = 0.6843s	
2452/33450 (epoch 3.665), train_loss = 1.84019873, grad/param norm = 1.8732e-01, time/batch = 0.6767s	
2453/33450 (epoch 3.667), train_loss = 2.02500616, grad/param norm = 1.8471e-01, time/batch = 0.6752s	
2454/33450 (epoch 3.668), train_loss = 1.97599130, grad/param norm = 1.7888e-01, time/batch = 0.6779s	
2455/33450 (epoch 3.670), train_loss = 1.81922126, grad/param norm = 2.0028e-01, time/batch = 0.6738s	
2456/33450 (epoch 3.671), train_loss = 2.03993928, grad/param norm = 2.1543e-01, time/batch = 0.6761s	
2457/33450 (epoch 3.673), train_loss = 2.00774658, grad/param norm = 2.0895e-01, time/batch = 0.6746s	
2458/33450 (epoch 3.674), train_loss = 2.03334304, grad/param norm = 1.9692e-01, time/batch = 0.6795s	
2459/33450 (epoch 3.676), train_loss = 2.05047257, grad/param norm = 2.1078e-01, time/batch = 0.6789s	
2460/33450 (epoch 3.677), train_loss = 1.98778963, grad/param norm = 1.8864e-01, time/batch = 0.6742s	
2461/33450 (epoch 3.679), train_loss = 1.85301655, grad/param norm = 1.8578e-01, time/batch = 0.6885s	
2462/33450 (epoch 3.680), train_loss = 1.89201747, grad/param norm = 1.8519e-01, time/batch = 0.7191s	
2463/33450 (epoch 3.682), train_loss = 1.86576857, grad/param norm = 1.7790e-01, time/batch = 0.6809s	
2464/33450 (epoch 3.683), train_loss = 2.13420987, grad/param norm = 2.0056e-01, time/batch = 0.6799s	
2465/33450 (epoch 3.685), train_loss = 2.17290274, grad/param norm = 2.2064e-01, time/batch = 0.6739s	
2466/33450 (epoch 3.686), train_loss = 2.03603028, grad/param norm = 1.8385e-01, time/batch = 0.6755s	
2467/33450 (epoch 3.688), train_loss = 2.13185286, grad/param norm = 2.0571e-01, time/batch = 0.6728s	
2468/33450 (epoch 3.689), train_loss = 1.91338512, grad/param norm = 1.9967e-01, time/batch = 0.6745s	
2469/33450 (epoch 3.691), train_loss = 1.90899975, grad/param norm = 1.9054e-01, time/batch = 0.6726s	
2470/33450 (epoch 3.692), train_loss = 2.06552532, grad/param norm = 1.9357e-01, time/batch = 0.6737s	
2471/33450 (epoch 3.694), train_loss = 1.80515883, grad/param norm = 2.1567e-01, time/batch = 0.6749s	
2472/33450 (epoch 3.695), train_loss = 2.08280715, grad/param norm = 2.1316e-01, time/batch = 0.6732s	
2473/33450 (epoch 3.697), train_loss = 2.07148011, grad/param norm = 2.0173e-01, time/batch = 0.6753s	
2474/33450 (epoch 3.698), train_loss = 1.69078418, grad/param norm = 2.0223e-01, time/batch = 0.6798s	
2475/33450 (epoch 3.700), train_loss = 2.08708282, grad/param norm = 2.1645e-01, time/batch = 0.6717s	
2476/33450 (epoch 3.701), train_loss = 1.90184238, grad/param norm = 1.9576e-01, time/batch = 0.7016s	
2477/33450 (epoch 3.703), train_loss = 2.02481489, grad/param norm = 1.9026e-01, time/batch = 0.7071s	
2478/33450 (epoch 3.704), train_loss = 1.84421725, grad/param norm = 1.7922e-01, time/batch = 0.6749s	
2479/33450 (epoch 3.706), train_loss = 1.88861832, grad/param norm = 1.9571e-01, time/batch = 0.6894s	
2480/33450 (epoch 3.707), train_loss = 1.82373771, grad/param norm = 1.9698e-01, time/batch = 0.6806s	
2481/33450 (epoch 3.709), train_loss = 2.09371611, grad/param norm = 2.5712e-01, time/batch = 0.6771s	
2482/33450 (epoch 3.710), train_loss = 1.89600108, grad/param norm = 1.9919e-01, time/batch = 0.6748s	
2483/33450 (epoch 3.712), train_loss = 1.84880562, grad/param norm = 2.0386e-01, time/batch = 0.6736s	
2484/33450 (epoch 3.713), train_loss = 2.11530422, grad/param norm = 2.0677e-01, time/batch = 0.6733s	
2485/33450 (epoch 3.714), train_loss = 1.85620660, grad/param norm = 1.9096e-01, time/batch = 0.6746s	
2486/33450 (epoch 3.716), train_loss = 1.83051832, grad/param norm = 1.8161e-01, time/batch = 0.6761s	
2487/33450 (epoch 3.717), train_loss = 1.94179029, grad/param norm = 2.1823e-01, time/batch = 0.6778s	
2488/33450 (epoch 3.719), train_loss = 2.04481191, grad/param norm = 1.9000e-01, time/batch = 0.6745s	
2489/33450 (epoch 3.720), train_loss = 1.87629727, grad/param norm = 1.8590e-01, time/batch = 0.6731s	
2490/33450 (epoch 3.722), train_loss = 1.70455675, grad/param norm = 1.8421e-01, time/batch = 0.6739s	
2491/33450 (epoch 3.723), train_loss = 1.88298519, grad/param norm = 1.9624e-01, time/batch = 0.6979s	
2492/33450 (epoch 3.725), train_loss = 1.81765969, grad/param norm = 2.2317e-01, time/batch = 0.6737s	
2493/33450 (epoch 3.726), train_loss = 1.69513015, grad/param norm = 1.8715e-01, time/batch = 0.6849s	
2494/33450 (epoch 3.728), train_loss = 1.77831832, grad/param norm = 1.9819e-01, time/batch = 0.6846s	
2495/33450 (epoch 3.729), train_loss = 1.88122504, grad/param norm = 1.9915e-01, time/batch = 0.6850s	
2496/33450 (epoch 3.731), train_loss = 2.22604730, grad/param norm = 2.2231e-01, time/batch = 0.6717s	
2497/33450 (epoch 3.732), train_loss = 2.21360892, grad/param norm = 2.1990e-01, time/batch = 0.6781s	
2498/33450 (epoch 3.734), train_loss = 2.07978202, grad/param norm = 2.1701e-01, time/batch = 0.6735s	
2499/33450 (epoch 3.735), train_loss = 2.04964026, grad/param norm = 2.0672e-01, time/batch = 0.6719s	
2500/33450 (epoch 3.737), train_loss = 2.02999115, grad/param norm = 2.0208e-01, time/batch = 0.6718s	
2501/33450 (epoch 3.738), train_loss = 2.13302412, grad/param norm = 1.9650e-01, time/batch = 0.6755s	
2502/33450 (epoch 3.740), train_loss = 1.92268561, grad/param norm = 1.8891e-01, time/batch = 0.6934s	
2503/33450 (epoch 3.741), train_loss = 1.90600820, grad/param norm = 1.7205e-01, time/batch = 0.6914s	
2504/33450 (epoch 3.743), train_loss = 2.00494702, grad/param norm = 1.9256e-01, time/batch = 0.6901s	
2505/33450 (epoch 3.744), train_loss = 2.01009652, grad/param norm = 2.0371e-01, time/batch = 0.6769s	
2506/33450 (epoch 3.746), train_loss = 1.93890868, grad/param norm = 1.9930e-01, time/batch = 0.6763s	
2507/33450 (epoch 3.747), train_loss = 2.06909241, grad/param norm = 2.1923e-01, time/batch = 0.6732s	
2508/33450 (epoch 3.749), train_loss = 1.88325960, grad/param norm = 1.9780e-01, time/batch = 0.6736s	
2509/33450 (epoch 3.750), train_loss = 1.86658233, grad/param norm = 1.8900e-01, time/batch = 0.6735s	
2510/33450 (epoch 3.752), train_loss = 2.05158425, grad/param norm = 2.0533e-01, time/batch = 0.6732s	
2511/33450 (epoch 3.753), train_loss = 2.09130181, grad/param norm = 2.1901e-01, time/batch = 0.6872s	
2512/33450 (epoch 3.755), train_loss = 1.92345235, grad/param norm = 1.9718e-01, time/batch = 0.6799s	
2513/33450 (epoch 3.756), train_loss = 2.05563016, grad/param norm = 1.9668e-01, time/batch = 0.6797s	
2514/33450 (epoch 3.758), train_loss = 1.96285347, grad/param norm = 1.9613e-01, time/batch = 0.6763s	
2515/33450 (epoch 3.759), train_loss = 2.04885477, grad/param norm = 1.8548e-01, time/batch = 0.6782s	
2516/33450 (epoch 3.761), train_loss = 1.93962238, grad/param norm = 2.0512e-01, time/batch = 0.6763s	
2517/33450 (epoch 3.762), train_loss = 2.11160484, grad/param norm = 2.2589e-01, time/batch = 0.6764s	
2518/33450 (epoch 3.764), train_loss = 1.92712142, grad/param norm = 1.8686e-01, time/batch = 0.6755s	
2519/33450 (epoch 3.765), train_loss = 1.87773499, grad/param norm = 1.8103e-01, time/batch = 0.6735s	
2520/33450 (epoch 3.767), train_loss = 1.93619754, grad/param norm = 2.1054e-01, time/batch = 0.6739s	
2521/33450 (epoch 3.768), train_loss = 1.94516882, grad/param norm = 1.8861e-01, time/batch = 0.6746s	
2522/33450 (epoch 3.770), train_loss = 2.05292394, grad/param norm = 2.0304e-01, time/batch = 0.6771s	
2523/33450 (epoch 3.771), train_loss = 2.21670239, grad/param norm = 1.9724e-01, time/batch = 0.6728s	
2524/33450 (epoch 3.773), train_loss = 2.01474057, grad/param norm = 1.8615e-01, time/batch = 0.6723s	
2525/33450 (epoch 3.774), train_loss = 1.92826030, grad/param norm = 1.8618e-01, time/batch = 0.6718s	
2526/33450 (epoch 3.776), train_loss = 1.96803068, grad/param norm = 1.8305e-01, time/batch = 0.6729s	
2527/33450 (epoch 3.777), train_loss = 1.87194263, grad/param norm = 1.8492e-01, time/batch = 0.6736s	
2528/33450 (epoch 3.779), train_loss = 1.89535378, grad/param norm = 1.7669e-01, time/batch = 0.6736s	
2529/33450 (epoch 3.780), train_loss = 1.79677635, grad/param norm = 1.7840e-01, time/batch = 0.6745s	
2530/33450 (epoch 3.782), train_loss = 2.01729366, grad/param norm = 2.0640e-01, time/batch = 0.6744s	
2531/33450 (epoch 3.783), train_loss = 2.03449045, grad/param norm = 2.3428e-01, time/batch = 0.6776s	
2532/33450 (epoch 3.785), train_loss = 1.97288597, grad/param norm = 2.1484e-01, time/batch = 0.6825s	
2533/33450 (epoch 3.786), train_loss = 1.87830260, grad/param norm = 1.8496e-01, time/batch = 0.6729s	
2534/33450 (epoch 3.788), train_loss = 1.87440160, grad/param norm = 1.7518e-01, time/batch = 0.6731s	
2535/33450 (epoch 3.789), train_loss = 1.87823277, grad/param norm = 1.9123e-01, time/batch = 0.7156s	
2536/33450 (epoch 3.791), train_loss = 1.68973919, grad/param norm = 1.8124e-01, time/batch = 0.6944s	
2537/33450 (epoch 3.792), train_loss = 1.89976683, grad/param norm = 2.0113e-01, time/batch = 0.6738s	
2538/33450 (epoch 3.794), train_loss = 1.84963528, grad/param norm = 2.0694e-01, time/batch = 0.6794s	
2539/33450 (epoch 3.795), train_loss = 1.99166493, grad/param norm = 1.9780e-01, time/batch = 0.6731s	
2540/33450 (epoch 3.797), train_loss = 2.01401156, grad/param norm = 1.9967e-01, time/batch = 0.6744s	
2541/33450 (epoch 3.798), train_loss = 1.96768291, grad/param norm = 2.0155e-01, time/batch = 0.6741s	
2542/33450 (epoch 3.800), train_loss = 2.04525091, grad/param norm = 1.9040e-01, time/batch = 0.6732s	
2543/33450 (epoch 3.801), train_loss = 2.11295778, grad/param norm = 1.9715e-01, time/batch = 0.6719s	
2544/33450 (epoch 3.803), train_loss = 2.04837705, grad/param norm = 2.0971e-01, time/batch = 0.6727s	
2545/33450 (epoch 3.804), train_loss = 1.74884580, grad/param norm = 1.8096e-01, time/batch = 0.6728s	
2546/33450 (epoch 3.806), train_loss = 1.89997261, grad/param norm = 1.8423e-01, time/batch = 0.6722s	
2547/33450 (epoch 3.807), train_loss = 1.90386715, grad/param norm = 1.7987e-01, time/batch = 0.6797s	
2548/33450 (epoch 3.809), train_loss = 1.88955617, grad/param norm = 1.8509e-01, time/batch = 0.6752s	
2549/33450 (epoch 3.810), train_loss = 1.89600384, grad/param norm = 1.9053e-01, time/batch = 0.6725s	
2550/33450 (epoch 3.812), train_loss = 1.83702186, grad/param norm = 1.9900e-01, time/batch = 0.6726s	
2551/33450 (epoch 3.813), train_loss = 1.79996628, grad/param norm = 1.9947e-01, time/batch = 0.6754s	
2552/33450 (epoch 3.815), train_loss = 2.07895272, grad/param norm = 2.0750e-01, time/batch = 0.6748s	
2553/33450 (epoch 3.816), train_loss = 1.98635271, grad/param norm = 1.7892e-01, time/batch = 0.6787s	
2554/33450 (epoch 3.818), train_loss = 1.64198470, grad/param norm = 1.8019e-01, time/batch = 0.6779s	
2555/33450 (epoch 3.819), train_loss = 1.89485196, grad/param norm = 1.9614e-01, time/batch = 0.6748s	
2556/33450 (epoch 3.821), train_loss = 1.95498907, grad/param norm = 1.8991e-01, time/batch = 0.6749s	
2557/33450 (epoch 3.822), train_loss = 1.99021241, grad/param norm = 1.9996e-01, time/batch = 0.6737s	
2558/33450 (epoch 3.824), train_loss = 1.81969806, grad/param norm = 2.0331e-01, time/batch = 0.6730s	
2559/33450 (epoch 3.825), train_loss = 1.88002414, grad/param norm = 1.9454e-01, time/batch = 0.6768s	
2560/33450 (epoch 3.827), train_loss = 2.02601413, grad/param norm = 1.9789e-01, time/batch = 0.6832s	
2561/33450 (epoch 3.828), train_loss = 1.78402866, grad/param norm = 1.9390e-01, time/batch = 0.6979s	
2562/33450 (epoch 3.830), train_loss = 1.85766822, grad/param norm = 1.9407e-01, time/batch = 0.6933s	
2563/33450 (epoch 3.831), train_loss = 1.93858200, grad/param norm = 1.9361e-01, time/batch = 0.6895s	
2564/33450 (epoch 3.833), train_loss = 1.80064739, grad/param norm = 1.8714e-01, time/batch = 0.6894s	
2565/33450 (epoch 3.834), train_loss = 1.94180662, grad/param norm = 1.8638e-01, time/batch = 0.7003s	
2566/33450 (epoch 3.836), train_loss = 1.81167248, grad/param norm = 1.7049e-01, time/batch = 0.6968s	
2567/33450 (epoch 3.837), train_loss = 2.04275921, grad/param norm = 2.2324e-01, time/batch = 0.6912s	
2568/33450 (epoch 3.839), train_loss = 2.01257769, grad/param norm = 2.0704e-01, time/batch = 0.6903s	
2569/33450 (epoch 3.840), train_loss = 2.05738168, grad/param norm = 2.2992e-01, time/batch = 0.6991s	
2570/33450 (epoch 3.842), train_loss = 1.91878367, grad/param norm = 1.8829e-01, time/batch = 0.7148s	
2571/33450 (epoch 3.843), train_loss = 1.77586696, grad/param norm = 2.0138e-01, time/batch = 0.6886s	
2572/33450 (epoch 3.845), train_loss = 1.84399238, grad/param norm = 1.9786e-01, time/batch = 0.6743s	
2573/33450 (epoch 3.846), train_loss = 2.08164130, grad/param norm = 2.0416e-01, time/batch = 0.6737s	
2574/33450 (epoch 3.848), train_loss = 1.97085462, grad/param norm = 1.9289e-01, time/batch = 0.6729s	
2575/33450 (epoch 3.849), train_loss = 1.99766998, grad/param norm = 1.9002e-01, time/batch = 0.6883s	
2576/33450 (epoch 3.851), train_loss = 1.86506126, grad/param norm = 1.7885e-01, time/batch = 0.6802s	
2577/33450 (epoch 3.852), train_loss = 1.89645202, grad/param norm = 1.7809e-01, time/batch = 0.6743s	
2578/33450 (epoch 3.854), train_loss = 1.95303889, grad/param norm = 2.1142e-01, time/batch = 0.6776s	
2579/33450 (epoch 3.855), train_loss = 1.91973731, grad/param norm = 2.0463e-01, time/batch = 0.6753s	
2580/33450 (epoch 3.857), train_loss = 1.85226491, grad/param norm = 1.9318e-01, time/batch = 0.6755s	
2581/33450 (epoch 3.858), train_loss = 2.18561322, grad/param norm = 2.2066e-01, time/batch = 0.6778s	
2582/33450 (epoch 3.859), train_loss = 2.21133643, grad/param norm = 1.9858e-01, time/batch = 0.6761s	
2583/33450 (epoch 3.861), train_loss = 2.10450954, grad/param norm = 1.9867e-01, time/batch = 0.7062s	
2584/33450 (epoch 3.862), train_loss = 1.80280890, grad/param norm = 1.9627e-01, time/batch = 0.7043s	
2585/33450 (epoch 3.864), train_loss = 1.96053717, grad/param norm = 2.2551e-01, time/batch = 0.6746s	
2586/33450 (epoch 3.865), train_loss = 1.90837898, grad/param norm = 1.8663e-01, time/batch = 0.6749s	
2587/33450 (epoch 3.867), train_loss = 2.01607193, grad/param norm = 2.0495e-01, time/batch = 0.6728s	
2588/33450 (epoch 3.868), train_loss = 1.94360642, grad/param norm = 2.0506e-01, time/batch = 0.6752s	
2589/33450 (epoch 3.870), train_loss = 1.98150437, grad/param norm = 2.0322e-01, time/batch = 0.6787s	
2590/33450 (epoch 3.871), train_loss = 2.03473446, grad/param norm = 2.0324e-01, time/batch = 0.6902s	
2591/33450 (epoch 3.873), train_loss = 1.79652824, grad/param norm = 1.9065e-01, time/batch = 1.1804s	
2592/33450 (epoch 3.874), train_loss = 1.93099278, grad/param norm = 2.0934e-01, time/batch = 1.9929s	
2593/33450 (epoch 3.876), train_loss = 1.99947171, grad/param norm = 2.0520e-01, time/batch = 3.6805s	
2594/33450 (epoch 3.877), train_loss = 1.89648645, grad/param norm = 1.9901e-01, time/batch = 4.8413s	
2595/33450 (epoch 3.879), train_loss = 1.70903141, grad/param norm = 1.6224e-01, time/batch = 40.2308s	
2596/33450 (epoch 3.880), train_loss = 1.89622964, grad/param norm = 1.9412e-01, time/batch = 88.7583s	
2597/33450 (epoch 3.882), train_loss = 1.96784149, grad/param norm = 1.8961e-01, time/batch = 47.9428s	
2598/33450 (epoch 3.883), train_loss = 1.93534539, grad/param norm = 1.9393e-01, time/batch = 2.0288s	
2599/33450 (epoch 3.885), train_loss = 1.96237695, grad/param norm = 1.7617e-01, time/batch = 2.5360s	
2600/33450 (epoch 3.886), train_loss = 2.05306750, grad/param norm = 2.0915e-01, time/batch = 2.4084s	
2601/33450 (epoch 3.888), train_loss = 1.95713136, grad/param norm = 1.9497e-01, time/batch = 1.2167s	
2602/33450 (epoch 3.889), train_loss = 1.81209914, grad/param norm = 1.6835e-01, time/batch = 2.1195s	
2603/33450 (epoch 3.891), train_loss = 2.04827513, grad/param norm = 1.9835e-01, time/batch = 6.6444s	
2604/33450 (epoch 3.892), train_loss = 1.88979499, grad/param norm = 1.9087e-01, time/batch = 3.3454s	
2605/33450 (epoch 3.894), train_loss = 1.99337821, grad/param norm = 2.0347e-01, time/batch = 5.7333s	
2606/33450 (epoch 3.895), train_loss = 1.71292772, grad/param norm = 1.9775e-01, time/batch = 1.6397s	
2607/33450 (epoch 3.897), train_loss = 1.81934865, grad/param norm = 2.0040e-01, time/batch = 1.2343s	
2608/33450 (epoch 3.898), train_loss = 1.90961257, grad/param norm = 1.8905e-01, time/batch = 2.2210s	
2609/33450 (epoch 3.900), train_loss = 1.95264465, grad/param norm = 2.0077e-01, time/batch = 3.6069s	
2610/33450 (epoch 3.901), train_loss = 1.99547294, grad/param norm = 1.9083e-01, time/batch = 1.7543s	
2611/33450 (epoch 3.903), train_loss = 1.65926788, grad/param norm = 1.7181e-01, time/batch = 3.2121s	
2612/33450 (epoch 3.904), train_loss = 1.97472202, grad/param norm = 2.3833e-01, time/batch = 5.8715s	
2613/33450 (epoch 3.906), train_loss = 1.90710038, grad/param norm = 2.1614e-01, time/batch = 24.6471s	
2614/33450 (epoch 3.907), train_loss = 1.95062506, grad/param norm = 2.0267e-01, time/batch = 1.3386s	
2615/33450 (epoch 3.909), train_loss = 1.84080626, grad/param norm = 1.7160e-01, time/batch = 1.3708s	
2616/33450 (epoch 3.910), train_loss = 2.01750642, grad/param norm = 2.4012e-01, time/batch = 1.7146s	
2617/33450 (epoch 3.912), train_loss = 1.94028269, grad/param norm = 2.3363e-01, time/batch = 2.7635s	
2618/33450 (epoch 3.913), train_loss = 1.97863950, grad/param norm = 1.7916e-01, time/batch = 2.7181s	
2619/33450 (epoch 3.915), train_loss = 1.81081078, grad/param norm = 1.9812e-01, time/batch = 1.4116s	
2620/33450 (epoch 3.916), train_loss = 2.00100172, grad/param norm = 1.7670e-01, time/batch = 1.3312s	
2621/33450 (epoch 3.918), train_loss = 1.87624757, grad/param norm = 1.9557e-01, time/batch = 3.0504s	
2622/33450 (epoch 3.919), train_loss = 1.90489572, grad/param norm = 1.8562e-01, time/batch = 134.0431s	
/home/ubuntu/scimirrorbot/train_cron.sh: line 37: 19688 Killed                  th train.lua -data_dir $TRANDIR -batch_size 10 -gpuid -1 -checkpoint_dir $MODLDIR -savefile $TRNUSR

real	38m59.788s
user	30m18.916s
sys	0m2.480s
