tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 598, val: 32, test: 0	
vocab size: 166	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 305062	
cloning rnn	
cloning criterion	
1/29900 (epoch 0.002), train_loss = 5.12849393, grad/param norm = 6.0287e-01, time/batch = 0.7246s	
2/29900 (epoch 0.003), train_loss = 4.79527280, grad/param norm = 1.5346e+00, time/batch = 0.6826s	
3/29900 (epoch 0.005), train_loss = 3.94708587, grad/param norm = 1.4242e+00, time/batch = 0.6820s	
4/29900 (epoch 0.007), train_loss = 3.56432156, grad/param norm = 9.1745e-01, time/batch = 0.6811s	
5/29900 (epoch 0.008), train_loss = 3.45584511, grad/param norm = 7.2570e-01, time/batch = 0.6835s	
6/29900 (epoch 0.010), train_loss = 3.43911016, grad/param norm = 8.7638e-01, time/batch = 0.6858s	
7/29900 (epoch 0.012), train_loss = 3.53626127, grad/param norm = 7.5531e-01, time/batch = 0.6908s	
8/29900 (epoch 0.013), train_loss = 3.69463531, grad/param norm = 7.5350e-01, time/batch = 0.7001s	
9/29900 (epoch 0.015), train_loss = 3.46886491, grad/param norm = 8.7562e-01, time/batch = 0.6857s	
10/29900 (epoch 0.017), train_loss = 3.60527551, grad/param norm = 8.2815e-01, time/batch = 0.6900s	
11/29900 (epoch 0.018), train_loss = 3.63250255, grad/param norm = 8.4126e-01, time/batch = 0.6858s	
12/29900 (epoch 0.020), train_loss = 3.41843792, grad/param norm = 8.3369e-01, time/batch = 0.7083s	
13/29900 (epoch 0.022), train_loss = 3.44066090, grad/param norm = 7.7455e-01, time/batch = 0.7138s	
14/29900 (epoch 0.023), train_loss = 3.47741613, grad/param norm = 6.1591e-01, time/batch = 0.6813s	
15/29900 (epoch 0.025), train_loss = 3.27628448, grad/param norm = 6.5364e-01, time/batch = 0.6802s	
16/29900 (epoch 0.027), train_loss = 3.43173970, grad/param norm = 5.7290e-01, time/batch = 0.6804s	
17/29900 (epoch 0.028), train_loss = 3.80871342, grad/param norm = 7.8270e-01, time/batch = 0.6803s	
18/29900 (epoch 0.030), train_loss = 3.93093852, grad/param norm = 1.0589e+00, time/batch = 0.6803s	
19/29900 (epoch 0.032), train_loss = 3.66426851, grad/param norm = 5.7613e-01, time/batch = 0.6822s	
20/29900 (epoch 0.033), train_loss = 3.50899069, grad/param norm = 7.8466e-01, time/batch = 0.6865s	
21/29900 (epoch 0.035), train_loss = 3.40126003, grad/param norm = 6.9095e-01, time/batch = 0.6824s	
22/29900 (epoch 0.037), train_loss = 3.46608341, grad/param norm = 5.0843e-01, time/batch = 0.6810s	
23/29900 (epoch 0.038), train_loss = 3.55476001, grad/param norm = 5.7136e-01, time/batch = 0.6787s	
24/29900 (epoch 0.040), train_loss = 3.47499165, grad/param norm = 5.2434e-01, time/batch = 0.6794s	
25/29900 (epoch 0.042), train_loss = 3.44342808, grad/param norm = 6.2793e-01, time/batch = 0.6802s	
26/29900 (epoch 0.043), train_loss = 3.70288609, grad/param norm = 7.3710e-01, time/batch = 0.6807s	
27/29900 (epoch 0.045), train_loss = 3.48001396, grad/param norm = 8.3609e-01, time/batch = 0.6801s	
28/29900 (epoch 0.047), train_loss = 3.60912394, grad/param norm = 6.2117e-01, time/batch = 0.6813s	
29/29900 (epoch 0.048), train_loss = 3.63807551, grad/param norm = 7.2412e-01, time/batch = 0.6822s	
30/29900 (epoch 0.050), train_loss = 3.44660345, grad/param norm = 6.6782e-01, time/batch = 0.6866s	
31/29900 (epoch 0.052), train_loss = 3.46798616, grad/param norm = 4.7942e-01, time/batch = 0.7145s	
32/29900 (epoch 0.054), train_loss = 3.57989814, grad/param norm = 6.9289e-01, time/batch = 0.7130s	
33/29900 (epoch 0.055), train_loss = 3.60573983, grad/param norm = 6.7514e-01, time/batch = 0.6882s	
34/29900 (epoch 0.057), train_loss = 3.53822206, grad/param norm = 5.2998e-01, time/batch = 0.6827s	
35/29900 (epoch 0.059), train_loss = 3.50425839, grad/param norm = 5.2186e-01, time/batch = 0.6839s	
36/29900 (epoch 0.060), train_loss = 3.39515213, grad/param norm = 6.0191e-01, time/batch = 0.6814s	
37/29900 (epoch 0.062), train_loss = 3.68123641, grad/param norm = 5.3154e-01, time/batch = 0.6828s	
38/29900 (epoch 0.064), train_loss = 3.57895411, grad/param norm = 6.0324e-01, time/batch = 0.6804s	
39/29900 (epoch 0.065), train_loss = 3.69850360, grad/param norm = 7.9189e-01, time/batch = 0.6805s	
40/29900 (epoch 0.067), train_loss = 3.64324323, grad/param norm = 5.8415e-01, time/batch = 0.6804s	
41/29900 (epoch 0.069), train_loss = 3.47247241, grad/param norm = 6.3328e-01, time/batch = 0.6828s	
42/29900 (epoch 0.070), train_loss = 3.42795813, grad/param norm = 8.6106e-01, time/batch = 0.6831s	
43/29900 (epoch 0.072), train_loss = 3.54160784, grad/param norm = 1.0065e+00, time/batch = 0.6820s	
44/29900 (epoch 0.074), train_loss = 3.53553265, grad/param norm = 6.9321e-01, time/batch = 0.6839s	
45/29900 (epoch 0.075), train_loss = 3.39672956, grad/param norm = 7.2499e-01, time/batch = 0.6845s	
46/29900 (epoch 0.077), train_loss = 3.55118853, grad/param norm = 7.9569e-01, time/batch = 0.6802s	
47/29900 (epoch 0.079), train_loss = 3.46591826, grad/param norm = 7.3033e-01, time/batch = 0.6809s	
48/29900 (epoch 0.080), train_loss = 3.40820664, grad/param norm = 9.0915e-01, time/batch = 0.6806s	
49/29900 (epoch 0.082), train_loss = 3.57779284, grad/param norm = 8.5892e-01, time/batch = 0.6800s	
50/29900 (epoch 0.084), train_loss = 3.64318865, grad/param norm = 6.7229e-01, time/batch = 0.6832s	
51/29900 (epoch 0.085), train_loss = 3.49804706, grad/param norm = 4.8576e-01, time/batch = 0.6842s	
52/29900 (epoch 0.087), train_loss = 3.57113458, grad/param norm = 6.5483e-01, time/batch = 0.6830s	
53/29900 (epoch 0.089), train_loss = 3.55319504, grad/param norm = 5.7846e-01, time/batch = 0.6870s	
54/29900 (epoch 0.090), train_loss = 3.68856160, grad/param norm = 7.4145e-01, time/batch = 0.7045s	
55/29900 (epoch 0.092), train_loss = 3.43506743, grad/param norm = 6.1790e-01, time/batch = 0.7198s	
56/29900 (epoch 0.094), train_loss = 3.52315055, grad/param norm = 6.0655e-01, time/batch = 0.6823s	
57/29900 (epoch 0.095), train_loss = 3.59926433, grad/param norm = 5.1581e-01, time/batch = 0.6844s	
58/29900 (epoch 0.097), train_loss = 3.61176724, grad/param norm = 6.3278e-01, time/batch = 0.6818s	
59/29900 (epoch 0.099), train_loss = 3.45865444, grad/param norm = 9.5463e-01, time/batch = 0.6816s	
60/29900 (epoch 0.100), train_loss = 3.31969828, grad/param norm = 8.1570e-01, time/batch = 0.6834s	
61/29900 (epoch 0.102), train_loss = 3.52314955, grad/param norm = 7.3232e-01, time/batch = 0.6841s	
62/29900 (epoch 0.104), train_loss = 3.51977753, grad/param norm = 6.0383e-01, time/batch = 0.6858s	
63/29900 (epoch 0.105), train_loss = 3.48772749, grad/param norm = 7.0014e-01, time/batch = 0.6832s	
64/29900 (epoch 0.107), train_loss = 3.49459180, grad/param norm = 6.7604e-01, time/batch = 0.6839s	
65/29900 (epoch 0.109), train_loss = 3.77102185, grad/param norm = 6.6610e-01, time/batch = 0.6864s	
66/29900 (epoch 0.110), train_loss = 3.47377065, grad/param norm = 5.2534e-01, time/batch = 0.6822s	
67/29900 (epoch 0.112), train_loss = 3.63877842, grad/param norm = 4.6466e-01, time/batch = 0.6832s	
68/29900 (epoch 0.114), train_loss = 3.45606904, grad/param norm = 4.5075e-01, time/batch = 0.6832s	
69/29900 (epoch 0.115), train_loss = 3.52331894, grad/param norm = 5.9788e-01, time/batch = 0.6885s	
70/29900 (epoch 0.117), train_loss = 3.49326668, grad/param norm = 7.1622e-01, time/batch = 0.6907s	
71/29900 (epoch 0.119), train_loss = 3.38124172, grad/param norm = 8.9030e-01, time/batch = 0.7017s	
72/29900 (epoch 0.120), train_loss = 3.46035958, grad/param norm = 4.7914e-01, time/batch = 0.6981s	
73/29900 (epoch 0.122), train_loss = 3.49705618, grad/param norm = 6.4146e-01, time/batch = 0.7005s	
74/29900 (epoch 0.124), train_loss = 3.53546982, grad/param norm = 6.2096e-01, time/batch = 0.7027s	
75/29900 (epoch 0.125), train_loss = 3.34714035, grad/param norm = 5.3106e-01, time/batch = 0.6881s	
76/29900 (epoch 0.127), train_loss = 3.43982792, grad/param norm = 4.9341e-01, time/batch = 0.6872s	
77/29900 (epoch 0.129), train_loss = 3.49543128, grad/param norm = 6.3970e-01, time/batch = 0.6820s	
78/29900 (epoch 0.130), train_loss = 3.46724745, grad/param norm = 5.4624e-01, time/batch = 0.6930s	
79/29900 (epoch 0.132), train_loss = 3.48355941, grad/param norm = 4.5830e-01, time/batch = 0.6875s	
80/29900 (epoch 0.134), train_loss = 3.46514091, grad/param norm = 6.7184e-01, time/batch = 0.6820s	
81/29900 (epoch 0.135), train_loss = 3.33570900, grad/param norm = 7.4064e-01, time/batch = 0.6818s	
82/29900 (epoch 0.137), train_loss = 3.55573309, grad/param norm = 6.6387e-01, time/batch = 0.6815s	
83/29900 (epoch 0.139), train_loss = 3.42544574, grad/param norm = 5.5819e-01, time/batch = 0.6826s	
84/29900 (epoch 0.140), train_loss = 3.83165392, grad/param norm = 5.8152e-01, time/batch = 0.6826s	
85/29900 (epoch 0.142), train_loss = 3.61879244, grad/param norm = 4.5596e-01, time/batch = 0.6824s	
86/29900 (epoch 0.144), train_loss = 3.69383405, grad/param norm = 5.3192e-01, time/batch = 0.6810s	
87/29900 (epoch 0.145), train_loss = 3.60200861, grad/param norm = 6.2097e-01, time/batch = 0.6812s	
88/29900 (epoch 0.147), train_loss = 3.59256974, grad/param norm = 6.3069e-01, time/batch = 0.6805s	
89/29900 (epoch 0.149), train_loss = 3.62859920, grad/param norm = 5.3500e-01, time/batch = 0.6814s	
90/29900 (epoch 0.151), train_loss = 3.58946978, grad/param norm = 9.9921e-01, time/batch = 0.6827s	
91/29900 (epoch 0.152), train_loss = 3.43125215, grad/param norm = 8.1251e-01, time/batch = 0.6899s	
92/29900 (epoch 0.154), train_loss = 3.55198751, grad/param norm = 4.9558e-01, time/batch = 0.7203s	
93/29900 (epoch 0.156), train_loss = 3.54727543, grad/param norm = 4.7412e-01, time/batch = 0.7051s	
94/29900 (epoch 0.157), train_loss = 3.44663758, grad/param norm = 4.5742e-01, time/batch = 0.7039s	
95/29900 (epoch 0.159), train_loss = 3.53037366, grad/param norm = 4.4647e-01, time/batch = 0.6927s	
96/29900 (epoch 0.161), train_loss = 3.78866642, grad/param norm = 5.9285e-01, time/batch = 0.6899s	
97/29900 (epoch 0.162), train_loss = 3.57426399, grad/param norm = 5.0568e-01, time/batch = 0.6829s	
98/29900 (epoch 0.164), train_loss = 3.47667823, grad/param norm = 4.3609e-01, time/batch = 0.7016s	
99/29900 (epoch 0.166), train_loss = 3.64928712, grad/param norm = 4.6618e-01, time/batch = 0.6934s	
100/29900 (epoch 0.167), train_loss = 3.57396085, grad/param norm = 3.6419e-01, time/batch = 0.6811s	
101/29900 (epoch 0.169), train_loss = 3.26773154, grad/param norm = 5.1441e-01, time/batch = 0.6833s	
102/29900 (epoch 0.171), train_loss = 3.31788545, grad/param norm = 5.4527e-01, time/batch = 0.6864s	
103/29900 (epoch 0.172), train_loss = 3.57797928, grad/param norm = 4.9034e-01, time/batch = 0.6881s	
104/29900 (epoch 0.174), train_loss = 3.51275139, grad/param norm = 6.0868e-01, time/batch = 0.6832s	
105/29900 (epoch 0.176), train_loss = 3.57967852, grad/param norm = 5.4464e-01, time/batch = 0.6845s	
106/29900 (epoch 0.177), train_loss = 3.50676092, grad/param norm = 5.1191e-01, time/batch = 0.6849s	
107/29900 (epoch 0.179), train_loss = 3.43990559, grad/param norm = 5.4150e-01, time/batch = 0.6835s	
108/29900 (epoch 0.181), train_loss = 3.65125671, grad/param norm = 6.0331e-01, time/batch = 0.6819s	
109/29900 (epoch 0.182), train_loss = 3.47753513, grad/param norm = 6.1063e-01, time/batch = 0.6822s	
110/29900 (epoch 0.184), train_loss = 3.51051509, grad/param norm = 5.8739e-01, time/batch = 0.6855s	
111/29900 (epoch 0.186), train_loss = 3.65400708, grad/param norm = 4.9069e-01, time/batch = 0.7263s	
112/29900 (epoch 0.187), train_loss = 3.53619840, grad/param norm = 5.8199e-01, time/batch = 0.6979s	
113/29900 (epoch 0.189), train_loss = 3.51276248, grad/param norm = 6.1522e-01, time/batch = 0.6845s	
114/29900 (epoch 0.191), train_loss = 3.44453414, grad/param norm = 5.2045e-01, time/batch = 0.6843s	
115/29900 (epoch 0.192), train_loss = 3.46298194, grad/param norm = 5.1972e-01, time/batch = 0.6809s	
116/29900 (epoch 0.194), train_loss = 3.61392446, grad/param norm = 4.3625e-01, time/batch = 0.6819s	
117/29900 (epoch 0.196), train_loss = 3.45241866, grad/param norm = 5.9430e-01, time/batch = 0.6810s	
118/29900 (epoch 0.197), train_loss = 3.53527705, grad/param norm = 4.5223e-01, time/batch = 0.6822s	
119/29900 (epoch 0.199), train_loss = 3.45977367, grad/param norm = 3.9795e-01, time/batch = 0.6819s	
120/29900 (epoch 0.201), train_loss = 3.54628973, grad/param norm = 4.8602e-01, time/batch = 0.6817s	
121/29900 (epoch 0.202), train_loss = 3.48959918, grad/param norm = 4.3305e-01, time/batch = 0.6875s	
122/29900 (epoch 0.204), train_loss = 3.43198424, grad/param norm = 5.3057e-01, time/batch = 0.6846s	
123/29900 (epoch 0.206), train_loss = 3.58964551, grad/param norm = 6.6367e-01, time/batch = 0.6813s	
124/29900 (epoch 0.207), train_loss = 3.58675664, grad/param norm = 6.4283e-01, time/batch = 0.6827s	
125/29900 (epoch 0.209), train_loss = 3.51684555, grad/param norm = 4.2949e-01, time/batch = 0.6809s	
126/29900 (epoch 0.211), train_loss = 3.39495665, grad/param norm = 7.6472e-01, time/batch = 0.6828s	
127/29900 (epoch 0.212), train_loss = 3.48528440, grad/param norm = 8.4249e-01, time/batch = 0.6835s	
128/29900 (epoch 0.214), train_loss = 3.60449936, grad/param norm = 5.9573e-01, time/batch = 0.6839s	
129/29900 (epoch 0.216), train_loss = 3.43400839, grad/param norm = 7.2081e-01, time/batch = 0.6939s	
130/29900 (epoch 0.217), train_loss = 3.42680554, grad/param norm = 6.1665e-01, time/batch = 0.7248s	
131/29900 (epoch 0.219), train_loss = 3.49614391, grad/param norm = 3.8176e-01, time/batch = 0.6897s	
132/29900 (epoch 0.221), train_loss = 3.49875032, grad/param norm = 3.8331e-01, time/batch = 0.6827s	
133/29900 (epoch 0.222), train_loss = 3.40704108, grad/param norm = 5.5273e-01, time/batch = 0.6828s	
134/29900 (epoch 0.224), train_loss = 3.28065746, grad/param norm = 4.5964e-01, time/batch = 0.6831s	
135/29900 (epoch 0.226), train_loss = 3.46713902, grad/param norm = 5.1553e-01, time/batch = 0.6828s	
136/29900 (epoch 0.227), train_loss = 3.50785803, grad/param norm = 1.0989e+00, time/batch = 0.6848s	
137/29900 (epoch 0.229), train_loss = 3.50184462, grad/param norm = 9.1027e-01, time/batch = 0.6861s	
138/29900 (epoch 0.231), train_loss = 3.40187340, grad/param norm = 4.1101e-01, time/batch = 0.6833s	
139/29900 (epoch 0.232), train_loss = 3.30142665, grad/param norm = 4.6811e-01, time/batch = 0.6841s	
140/29900 (epoch 0.234), train_loss = 3.42036001, grad/param norm = 5.1027e-01, time/batch = 0.6822s	
141/29900 (epoch 0.236), train_loss = 3.54499445, grad/param norm = 4.3800e-01, time/batch = 0.6835s	
142/29900 (epoch 0.237), train_loss = 3.59556992, grad/param norm = 4.5190e-01, time/batch = 0.6829s	
143/29900 (epoch 0.239), train_loss = 3.33734809, grad/param norm = 6.3785e-01, time/batch = 0.6840s	
144/29900 (epoch 0.241), train_loss = 3.45854481, grad/param norm = 6.9295e-01, time/batch = 0.6902s	
145/29900 (epoch 0.242), train_loss = 3.54926113, grad/param norm = 6.7855e-01, time/batch = 0.6891s	
146/29900 (epoch 0.244), train_loss = 3.45572282, grad/param norm = 4.7608e-01, time/batch = 0.6839s	
147/29900 (epoch 0.246), train_loss = 3.30304195, grad/param norm = 3.6848e-01, time/batch = 0.6810s	
148/29900 (epoch 0.247), train_loss = 3.32532892, grad/param norm = 4.8350e-01, time/batch = 0.6979s	
149/29900 (epoch 0.249), train_loss = 3.26848823, grad/param norm = 5.5257e-01, time/batch = 0.7246s	
150/29900 (epoch 0.251), train_loss = 3.44885229, grad/param norm = 7.3235e-01, time/batch = 0.6823s	
151/29900 (epoch 0.253), train_loss = 3.41282442, grad/param norm = 7.2006e-01, time/batch = 0.6835s	
152/29900 (epoch 0.254), train_loss = 3.27277602, grad/param norm = 4.1190e-01, time/batch = 0.6827s	
153/29900 (epoch 0.256), train_loss = 3.38792487, grad/param norm = 5.4430e-01, time/batch = 0.6819s	
154/29900 (epoch 0.258), train_loss = 3.32961070, grad/param norm = 6.7380e-01, time/batch = 0.6809s	
155/29900 (epoch 0.259), train_loss = 3.49872151, grad/param norm = 7.8140e-01, time/batch = 0.6814s	
156/29900 (epoch 0.261), train_loss = 3.28634654, grad/param norm = 7.4875e-01, time/batch = 0.6834s	
157/29900 (epoch 0.263), train_loss = 3.40848534, grad/param norm = 8.0246e-01, time/batch = 0.6920s	
158/29900 (epoch 0.264), train_loss = 3.44802250, grad/param norm = 5.3642e-01, time/batch = 0.7032s	
159/29900 (epoch 0.266), train_loss = 3.40163102, grad/param norm = 4.2874e-01, time/batch = 0.6927s	
160/29900 (epoch 0.268), train_loss = 3.27391319, grad/param norm = 6.4199e-01, time/batch = 0.7023s	
161/29900 (epoch 0.269), train_loss = 3.20785911, grad/param norm = 6.1101e-01, time/batch = 0.6864s	
162/29900 (epoch 0.271), train_loss = 3.46309045, grad/param norm = 6.4252e-01, time/batch = 0.6866s	
163/29900 (epoch 0.273), train_loss = 3.21651404, grad/param norm = 9.9823e-01, time/batch = 0.6825s	
164/29900 (epoch 0.274), train_loss = 3.41449570, grad/param norm = 7.6854e-01, time/batch = 0.6868s	
165/29900 (epoch 0.276), train_loss = 3.42801587, grad/param norm = 4.8817e-01, time/batch = 0.6865s	
166/29900 (epoch 0.278), train_loss = 3.32508649, grad/param norm = 3.6437e-01, time/batch = 0.6862s	
167/29900 (epoch 0.279), train_loss = 3.31410057, grad/param norm = 4.9046e-01, time/batch = 0.6901s	
168/29900 (epoch 0.281), train_loss = 3.32037262, grad/param norm = 3.1465e-01, time/batch = 0.6913s	
169/29900 (epoch 0.283), train_loss = 3.39306027, grad/param norm = 4.3113e-01, time/batch = 0.6860s	
170/29900 (epoch 0.284), train_loss = 3.31715365, grad/param norm = 5.0756e-01, time/batch = 0.6876s	
171/29900 (epoch 0.286), train_loss = 3.35836426, grad/param norm = 4.1211e-01, time/batch = 0.6840s	
172/29900 (epoch 0.288), train_loss = 3.83237011, grad/param norm = 7.3323e-01, time/batch = 0.6848s	
173/29900 (epoch 0.289), train_loss = 3.80776420, grad/param norm = 2.4735e+00, time/batch = 0.6888s	
174/29900 (epoch 0.291), train_loss = 3.50073114, grad/param norm = 1.1311e+00, time/batch = 0.6890s	
175/29900 (epoch 0.293), train_loss = 3.28430512, grad/param norm = 6.9121e-01, time/batch = 0.6970s	
176/29900 (epoch 0.294), train_loss = 3.26047867, grad/param norm = 7.1879e-01, time/batch = 0.7194s	
177/29900 (epoch 0.296), train_loss = 3.15496884, grad/param norm = 4.2844e-01, time/batch = 0.7223s	
178/29900 (epoch 0.298), train_loss = 3.25299418, grad/param norm = 5.0629e-01, time/batch = 0.7214s	
179/29900 (epoch 0.299), train_loss = 3.22988827, grad/param norm = 5.3595e-01, time/batch = 0.6952s	
180/29900 (epoch 0.301), train_loss = 3.21289063, grad/param norm = 8.1397e-01, time/batch = 0.6802s	
181/29900 (epoch 0.303), train_loss = 3.58946343, grad/param norm = 9.5736e-01, time/batch = 0.6839s	
182/29900 (epoch 0.304), train_loss = 3.35881938, grad/param norm = 1.2943e+00, time/batch = 0.6832s	
183/29900 (epoch 0.306), train_loss = 3.47096101, grad/param norm = 1.0563e+00, time/batch = 0.6852s	
184/29900 (epoch 0.308), train_loss = 3.23158679, grad/param norm = 6.0159e-01, time/batch = 0.6798s	
185/29900 (epoch 0.309), train_loss = 3.22956359, grad/param norm = 4.9680e-01, time/batch = 0.6800s	
186/29900 (epoch 0.311), train_loss = 3.11939035, grad/param norm = 6.4545e-01, time/batch = 0.6829s	
187/29900 (epoch 0.313), train_loss = 3.26656779, grad/param norm = 6.5246e-01, time/batch = 0.6834s	
188/29900 (epoch 0.314), train_loss = 3.09867918, grad/param norm = 6.3591e-01, time/batch = 0.6816s	
189/29900 (epoch 0.316), train_loss = 3.37562422, grad/param norm = 8.9426e-01, time/batch = 0.6860s	
190/29900 (epoch 0.318), train_loss = 3.27604999, grad/param norm = 7.4794e-01, time/batch = 0.7021s	
191/29900 (epoch 0.319), train_loss = 3.11054334, grad/param norm = 4.3692e-01, time/batch = 0.6847s	
192/29900 (epoch 0.321), train_loss = 3.24232827, grad/param norm = 3.4547e-01, time/batch = 0.6828s	
193/29900 (epoch 0.323), train_loss = 3.03108206, grad/param norm = 3.2587e-01, time/batch = 0.6834s	
194/29900 (epoch 0.324), train_loss = 3.11493915, grad/param norm = 4.2195e-01, time/batch = 0.6821s	
195/29900 (epoch 0.326), train_loss = 3.13800717, grad/param norm = 5.5948e-01, time/batch = 0.6821s	
196/29900 (epoch 0.328), train_loss = 3.17852649, grad/param norm = 6.3010e-01, time/batch = 0.7161s	
197/29900 (epoch 0.329), train_loss = 3.39667571, grad/param norm = 9.3661e-01, time/batch = 0.7124s	
198/29900 (epoch 0.331), train_loss = 3.34557518, grad/param norm = 1.1718e+00, time/batch = 0.6843s	
199/29900 (epoch 0.333), train_loss = 3.37281929, grad/param norm = 8.1082e-01, time/batch = 0.6823s	
200/29900 (epoch 0.334), train_loss = 3.32371871, grad/param norm = 3.6983e-01, time/batch = 0.6812s	
201/29900 (epoch 0.336), train_loss = 3.25435676, grad/param norm = 4.9892e-01, time/batch = 0.6887s	
202/29900 (epoch 0.338), train_loss = 3.18589974, grad/param norm = 6.5546e-01, time/batch = 0.6829s	
203/29900 (epoch 0.339), train_loss = 3.30597065, grad/param norm = 1.3251e+00, time/batch = 0.6853s	
204/29900 (epoch 0.341), train_loss = 3.25897783, grad/param norm = 1.2040e+00, time/batch = 0.6811s	
205/29900 (epoch 0.343), train_loss = 3.25212253, grad/param norm = 8.7337e-01, time/batch = 0.6865s	
206/29900 (epoch 0.344), train_loss = 3.13959992, grad/param norm = 6.7196e-01, time/batch = 0.6816s	
207/29900 (epoch 0.346), train_loss = 3.07687022, grad/param norm = 4.0627e-01, time/batch = 0.6805s	
208/29900 (epoch 0.348), train_loss = 2.98539706, grad/param norm = 4.5999e-01, time/batch = 0.6818s	
209/29900 (epoch 0.349), train_loss = 3.20827593, grad/param norm = 6.7870e-01, time/batch = 0.6857s	
210/29900 (epoch 0.351), train_loss = 3.17604222, grad/param norm = 5.9362e-01, time/batch = 0.6815s	
211/29900 (epoch 0.353), train_loss = 3.09817483, grad/param norm = 4.7983e-01, time/batch = 0.6830s	
212/29900 (epoch 0.355), train_loss = 3.09715295, grad/param norm = 4.4834e-01, time/batch = 0.6842s	
213/29900 (epoch 0.356), train_loss = 3.08109629, grad/param norm = 3.7448e-01, time/batch = 0.6856s	
214/29900 (epoch 0.358), train_loss = 3.07481013, grad/param norm = 4.4630e-01, time/batch = 0.6901s	
215/29900 (epoch 0.360), train_loss = 3.11308552, grad/param norm = 5.1768e-01, time/batch = 0.6859s	
216/29900 (epoch 0.361), train_loss = 3.26709008, grad/param norm = 5.8156e-01, time/batch = 0.6839s	
217/29900 (epoch 0.363), train_loss = 3.12917513, grad/param norm = 8.1419e-01, time/batch = 0.6823s	
218/29900 (epoch 0.365), train_loss = 3.12477007, grad/param norm = 6.5684e-01, time/batch = 0.6851s	
219/29900 (epoch 0.366), train_loss = 3.01442527, grad/param norm = 5.0801e-01, time/batch = 0.6822s	
220/29900 (epoch 0.368), train_loss = 2.80424420, grad/param norm = 6.2002e-01, time/batch = 0.6885s	
221/29900 (epoch 0.370), train_loss = 3.02282311, grad/param norm = 9.1311e-01, time/batch = 0.6874s	
222/29900 (epoch 0.371), train_loss = 3.26315585, grad/param norm = 8.9367e-01, time/batch = 0.6826s	
223/29900 (epoch 0.373), train_loss = 3.17151643, grad/param norm = 1.0250e+00, time/batch = 0.6820s	
224/29900 (epoch 0.375), train_loss = 3.32299542, grad/param norm = 6.7892e-01, time/batch = 0.6806s	
225/29900 (epoch 0.376), train_loss = 3.21706652, grad/param norm = 4.7374e-01, time/batch = 0.6825s	
226/29900 (epoch 0.378), train_loss = 3.18340745, grad/param norm = 5.7671e-01, time/batch = 0.6796s	
227/29900 (epoch 0.380), train_loss = 3.14275885, grad/param norm = 5.5552e-01, time/batch = 0.6832s	
228/29900 (epoch 0.381), train_loss = 3.20798903, grad/param norm = 4.8655e-01, time/batch = 0.6848s	
229/29900 (epoch 0.383), train_loss = 2.97007117, grad/param norm = 3.8065e-01, time/batch = 0.6957s	
230/29900 (epoch 0.385), train_loss = 2.90021249, grad/param norm = 4.5353e-01, time/batch = 0.7254s	
231/29900 (epoch 0.386), train_loss = 2.97969513, grad/param norm = 4.4862e-01, time/batch = 0.6834s	
232/29900 (epoch 0.388), train_loss = 2.99665471, grad/param norm = 4.5768e-01, time/batch = 0.6812s	
233/29900 (epoch 0.390), train_loss = 3.12403277, grad/param norm = 6.5928e-01, time/batch = 0.6819s	
234/29900 (epoch 0.391), train_loss = 3.09132062, grad/param norm = 7.0692e-01, time/batch = 0.6885s	
235/29900 (epoch 0.393), train_loss = 3.05598089, grad/param norm = 7.3382e-01, time/batch = 0.6896s	
236/29900 (epoch 0.395), train_loss = 2.88153229, grad/param norm = 9.4648e-01, time/batch = 0.6940s	
237/29900 (epoch 0.396), train_loss = 3.16117147, grad/param norm = 1.0509e+00, time/batch = 0.6983s	
238/29900 (epoch 0.398), train_loss = 3.22382948, grad/param norm = 7.9158e-01, time/batch = 0.6875s	
239/29900 (epoch 0.400), train_loss = 3.17516629, grad/param norm = 5.3145e-01, time/batch = 0.6910s	
240/29900 (epoch 0.401), train_loss = 3.20923325, grad/param norm = 3.9702e-01, time/batch = 0.6887s	
241/29900 (epoch 0.403), train_loss = 3.14204851, grad/param norm = 3.7537e-01, time/batch = 0.6905s	
242/29900 (epoch 0.405), train_loss = 2.89379717, grad/param norm = 4.3474e-01, time/batch = 0.6980s	
243/29900 (epoch 0.406), train_loss = 2.98076509, grad/param norm = 5.7478e-01, time/batch = 0.6988s	
244/29900 (epoch 0.408), train_loss = 2.86476958, grad/param norm = 8.4320e-01, time/batch = 0.7310s	
245/29900 (epoch 0.410), train_loss = 3.14151718, grad/param norm = 1.3632e+00, time/batch = 0.7078s	
246/29900 (epoch 0.411), train_loss = 3.19545149, grad/param norm = 9.8200e-01, time/batch = 0.7028s	
247/29900 (epoch 0.413), train_loss = 3.07291215, grad/param norm = 5.6871e-01, time/batch = 0.7042s	
248/29900 (epoch 0.415), train_loss = 3.01188388, grad/param norm = 4.8113e-01, time/batch = 0.6841s	
249/29900 (epoch 0.416), train_loss = 2.95581962, grad/param norm = 3.4234e-01, time/batch = 0.6881s	
250/29900 (epoch 0.418), train_loss = 2.84861986, grad/param norm = 4.4666e-01, time/batch = 0.6892s	
251/29900 (epoch 0.420), train_loss = 3.01527660, grad/param norm = 6.9121e-01, time/batch = 0.6994s	
252/29900 (epoch 0.421), train_loss = 3.01239151, grad/param norm = 8.3980e-01, time/batch = 0.6939s	
253/29900 (epoch 0.423), train_loss = 2.93454498, grad/param norm = 6.2738e-01, time/batch = 0.6814s	
254/29900 (epoch 0.425), train_loss = 2.98144775, grad/param norm = 5.7541e-01, time/batch = 0.6801s	
255/29900 (epoch 0.426), train_loss = 2.93821483, grad/param norm = 5.2942e-01, time/batch = 0.6809s	
256/29900 (epoch 0.428), train_loss = 3.02969684, grad/param norm = 5.4225e-01, time/batch = 0.6814s	
257/29900 (epoch 0.430), train_loss = 3.03587959, grad/param norm = 6.3459e-01, time/batch = 0.6855s	
258/29900 (epoch 0.431), train_loss = 2.95900634, grad/param norm = 7.7264e-01, time/batch = 0.7131s	
259/29900 (epoch 0.433), train_loss = 3.03990573, grad/param norm = 7.6689e-01, time/batch = 0.7129s	
260/29900 (epoch 0.435), train_loss = 3.03813209, grad/param norm = 7.3174e-01, time/batch = 0.6813s	
261/29900 (epoch 0.436), train_loss = 2.90623856, grad/param norm = 9.0608e-01, time/batch = 0.6837s	
262/29900 (epoch 0.438), train_loss = 2.73711554, grad/param norm = 6.5613e-01, time/batch = 0.6860s	
263/29900 (epoch 0.440), train_loss = 2.96132431, grad/param norm = 5.3664e-01, time/batch = 0.6829s	
264/29900 (epoch 0.441), train_loss = 3.00277645, grad/param norm = 4.3068e-01, time/batch = 0.6836s	
265/29900 (epoch 0.443), train_loss = 2.98546985, grad/param norm = 3.7123e-01, time/batch = 0.6857s	
266/29900 (epoch 0.445), train_loss = 2.88228615, grad/param norm = 6.5284e-01, time/batch = 0.6838s	
267/29900 (epoch 0.446), train_loss = 2.99211893, grad/param norm = 1.0036e+00, time/batch = 0.6828s	
268/29900 (epoch 0.448), train_loss = 2.95500331, grad/param norm = 7.0053e-01, time/batch = 0.6853s	
269/29900 (epoch 0.450), train_loss = 2.86135595, grad/param norm = 4.1699e-01, time/batch = 0.6891s	
270/29900 (epoch 0.452), train_loss = 2.96683139, grad/param norm = 4.0612e-01, time/batch = 0.6870s	
271/29900 (epoch 0.453), train_loss = 3.04969544, grad/param norm = 3.7681e-01, time/batch = 0.6849s	
272/29900 (epoch 0.455), train_loss = 2.96231670, grad/param norm = 3.9157e-01, time/batch = 0.6875s	
273/29900 (epoch 0.457), train_loss = 2.84421260, grad/param norm = 5.3356e-01, time/batch = 0.6869s	
274/29900 (epoch 0.458), train_loss = 3.01437146, grad/param norm = 6.6623e-01, time/batch = 0.6824s	
275/29900 (epoch 0.460), train_loss = 2.81568198, grad/param norm = 8.2604e-01, time/batch = 0.6827s	
276/29900 (epoch 0.462), train_loss = 2.84629113, grad/param norm = 7.9033e-01, time/batch = 0.6808s	
277/29900 (epoch 0.463), train_loss = 2.87273976, grad/param norm = 5.5571e-01, time/batch = 0.6825s	
278/29900 (epoch 0.465), train_loss = 3.06237384, grad/param norm = 5.1349e-01, time/batch = 0.6816s	
279/29900 (epoch 0.467), train_loss = 3.07913008, grad/param norm = 6.3849e-01, time/batch = 0.6831s	
280/29900 (epoch 0.468), train_loss = 3.14441357, grad/param norm = 4.5306e-01, time/batch = 0.6867s	
281/29900 (epoch 0.470), train_loss = 2.81317304, grad/param norm = 3.0315e-01, time/batch = 0.7076s	
282/29900 (epoch 0.472), train_loss = 2.93723904, grad/param norm = 4.9432e-01, time/batch = 0.7206s	
283/29900 (epoch 0.473), train_loss = 2.88319270, grad/param norm = 5.3498e-01, time/batch = 0.6927s	
284/29900 (epoch 0.475), train_loss = 2.97844728, grad/param norm = 4.3307e-01, time/batch = 0.7027s	
285/29900 (epoch 0.477), train_loss = 2.96432890, grad/param norm = 6.6477e-01, time/batch = 0.6979s	
286/29900 (epoch 0.478), train_loss = 2.89357809, grad/param norm = 1.0745e+00, time/batch = 0.6979s	
287/29900 (epoch 0.480), train_loss = 2.97684686, grad/param norm = 8.8252e-01, time/batch = 0.7015s	
288/29900 (epoch 0.482), train_loss = 2.86685384, grad/param norm = 6.3745e-01, time/batch = 0.7039s	
289/29900 (epoch 0.483), train_loss = 2.96856810, grad/param norm = 6.1741e-01, time/batch = 0.6922s	
290/29900 (epoch 0.485), train_loss = 2.93647081, grad/param norm = 6.6076e-01, time/batch = 0.6941s	
291/29900 (epoch 0.487), train_loss = 2.85180709, grad/param norm = 6.0991e-01, time/batch = 0.6898s	
292/29900 (epoch 0.488), train_loss = 2.86812192, grad/param norm = 7.0745e-01, time/batch = 0.6877s	
293/29900 (epoch 0.490), train_loss = 2.82025335, grad/param norm = 6.3469e-01, time/batch = 0.6915s	
294/29900 (epoch 0.492), train_loss = 2.85391854, grad/param norm = 4.4543e-01, time/batch = 0.6860s	
295/29900 (epoch 0.493), train_loss = 2.91928912, grad/param norm = 3.0056e-01, time/batch = 0.7114s	
296/29900 (epoch 0.495), train_loss = 2.79691610, grad/param norm = 3.2584e-01, time/batch = 0.7255s	
297/29900 (epoch 0.497), train_loss = 2.98771527, grad/param norm = 2.8778e-01, time/batch = 0.7107s	
298/29900 (epoch 0.498), train_loss = 2.92697941, grad/param norm = 3.7854e-01, time/batch = 0.6956s	
299/29900 (epoch 0.500), train_loss = 3.04005133, grad/param norm = 5.6582e-01, time/batch = 0.6855s	
300/29900 (epoch 0.502), train_loss = 2.85318849, grad/param norm = 6.1919e-01, time/batch = 0.6902s	
301/29900 (epoch 0.503), train_loss = 2.83848235, grad/param norm = 6.0956e-01, time/batch = 0.6873s	
302/29900 (epoch 0.505), train_loss = 2.88196656, grad/param norm = 4.5405e-01, time/batch = 0.6943s	
303/29900 (epoch 0.507), train_loss = 2.91658909, grad/param norm = 4.2328e-01, time/batch = 0.6844s	
304/29900 (epoch 0.508), train_loss = 2.87923549, grad/param norm = 8.2844e-01, time/batch = 0.6828s	
305/29900 (epoch 0.510), train_loss = 2.89575146, grad/param norm = 1.0765e+00, time/batch = 0.6834s	
306/29900 (epoch 0.512), train_loss = 3.06162966, grad/param norm = 6.8179e-01, time/batch = 0.6866s	
307/29900 (epoch 0.513), train_loss = 3.05140711, grad/param norm = 4.5652e-01, time/batch = 0.6873s	
308/29900 (epoch 0.515), train_loss = 2.77998461, grad/param norm = 3.7447e-01, time/batch = 0.6847s	
309/29900 (epoch 0.517), train_loss = 2.90365612, grad/param norm = 3.4500e-01, time/batch = 0.6853s	
310/29900 (epoch 0.518), train_loss = 2.92859618, grad/param norm = 3.7979e-01, time/batch = 0.6886s	
311/29900 (epoch 0.520), train_loss = 2.92012576, grad/param norm = 3.6856e-01, time/batch = 0.6878s	
312/29900 (epoch 0.522), train_loss = 2.90727434, grad/param norm = 4.0627e-01, time/batch = 0.6834s	
313/29900 (epoch 0.523), train_loss = 2.84829625, grad/param norm = 3.5231e-01, time/batch = 0.6838s	
314/29900 (epoch 0.525), train_loss = 2.59245362, grad/param norm = 3.0840e-01, time/batch = 0.7047s	
315/29900 (epoch 0.527), train_loss = 2.74176960, grad/param norm = 2.9421e-01, time/batch = 0.7185s	
316/29900 (epoch 0.528), train_loss = 2.81183771, grad/param norm = 4.0892e-01, time/batch = 0.6829s	
317/29900 (epoch 0.530), train_loss = 2.84516147, grad/param norm = 4.6564e-01, time/batch = 0.6880s	
318/29900 (epoch 0.532), train_loss = 2.98249857, grad/param norm = 9.2059e-01, time/batch = 0.6871s	
319/29900 (epoch 0.533), train_loss = 3.04376929, grad/param norm = 9.8945e-01, time/batch = 0.6811s	
320/29900 (epoch 0.535), train_loss = 2.75679978, grad/param norm = 3.1682e-01, time/batch = 0.6840s	
321/29900 (epoch 0.537), train_loss = 2.67645583, grad/param norm = 3.1460e-01, time/batch = 0.6876s	
322/29900 (epoch 0.538), train_loss = 2.81997160, grad/param norm = 4.6341e-01, time/batch = 0.6849s	
323/29900 (epoch 0.540), train_loss = 2.83170229, grad/param norm = 6.2217e-01, time/batch = 0.6879s	
324/29900 (epoch 0.542), train_loss = 2.81229484, grad/param norm = 6.6648e-01, time/batch = 0.6893s	
325/29900 (epoch 0.543), train_loss = 2.89364926, grad/param norm = 4.9609e-01, time/batch = 0.6862s	
326/29900 (epoch 0.545), train_loss = 2.88616970, grad/param norm = 4.4749e-01, time/batch = 0.6834s	
327/29900 (epoch 0.547), train_loss = 2.86100163, grad/param norm = 3.3169e-01, time/batch = 0.6840s	
328/29900 (epoch 0.548), train_loss = 2.96628919, grad/param norm = 5.7300e-01, time/batch = 0.6810s	
329/29900 (epoch 0.550), train_loss = 2.72621340, grad/param norm = 9.3094e-01, time/batch = 0.6858s	
330/29900 (epoch 0.552), train_loss = 2.82334525, grad/param norm = 1.0995e+00, time/batch = 0.6926s	
331/29900 (epoch 0.554), train_loss = 2.94469563, grad/param norm = 6.9264e-01, time/batch = 0.7116s	
332/29900 (epoch 0.555), train_loss = 2.86061145, grad/param norm = 4.5512e-01, time/batch = 0.7168s	
333/29900 (epoch 0.557), train_loss = 2.96050636, grad/param norm = 5.3057e-01, time/batch = 0.7250s	
334/29900 (epoch 0.559), train_loss = 2.79105499, grad/param norm = 4.6124e-01, time/batch = 0.7018s	
335/29900 (epoch 0.560), train_loss = 2.75510322, grad/param norm = 4.4193e-01, time/batch = 0.6867s	
336/29900 (epoch 0.562), train_loss = 2.78980185, grad/param norm = 3.5853e-01, time/batch = 0.6856s	
337/29900 (epoch 0.564), train_loss = 2.84199609, grad/param norm = 4.1459e-01, time/batch = 0.7072s	
338/29900 (epoch 0.565), train_loss = 2.82597947, grad/param norm = 2.9361e-01, time/batch = 0.7233s	
339/29900 (epoch 0.567), train_loss = 2.73076362, grad/param norm = 3.3127e-01, time/batch = 0.6897s	
340/29900 (epoch 0.569), train_loss = 2.92127212, grad/param norm = 3.7831e-01, time/batch = 0.6850s	
341/29900 (epoch 0.570), train_loss = 2.87995005, grad/param norm = 4.4256e-01, time/batch = 0.6932s	
342/29900 (epoch 0.572), train_loss = 2.60969263, grad/param norm = 3.2944e-01, time/batch = 0.6855s	
343/29900 (epoch 0.574), train_loss = 2.72357367, grad/param norm = 4.5932e-01, time/batch = 0.6819s	
344/29900 (epoch 0.575), train_loss = 2.75236629, grad/param norm = 7.3862e-01, time/batch = 0.6956s	
345/29900 (epoch 0.577), train_loss = 2.90483187, grad/param norm = 8.2703e-01, time/batch = 0.6944s	
346/29900 (epoch 0.579), train_loss = 2.92419612, grad/param norm = 6.6463e-01, time/batch = 0.6952s	
347/29900 (epoch 0.580), train_loss = 2.87751794, grad/param norm = 5.0932e-01, time/batch = 0.6868s	
348/29900 (epoch 0.582), train_loss = 3.00550993, grad/param norm = 8.4718e-01, time/batch = 0.6869s	
349/29900 (epoch 0.584), train_loss = 2.77684142, grad/param norm = 4.8039e-01, time/batch = 0.6813s	
350/29900 (epoch 0.585), train_loss = 2.91058195, grad/param norm = 4.0392e-01, time/batch = 0.6900s	
351/29900 (epoch 0.587), train_loss = 2.76031218, grad/param norm = 3.4667e-01, time/batch = 0.6928s	
352/29900 (epoch 0.589), train_loss = 2.88749213, grad/param norm = 3.5166e-01, time/batch = 0.7259s	
353/29900 (epoch 0.590), train_loss = 2.85619532, grad/param norm = 4.9206e-01, time/batch = 0.6974s	
354/29900 (epoch 0.592), train_loss = 2.90320866, grad/param norm = 5.0442e-01, time/batch = 0.6873s	
355/29900 (epoch 0.594), train_loss = 2.80645382, grad/param norm = 4.6027e-01, time/batch = 0.6853s	
356/29900 (epoch 0.595), train_loss = 2.85084928, grad/param norm = 5.1623e-01, time/batch = 0.6826s	
357/29900 (epoch 0.597), train_loss = 2.70164264, grad/param norm = 5.2464e-01, time/batch = 0.6833s	
358/29900 (epoch 0.599), train_loss = 2.62962371, grad/param norm = 4.6168e-01, time/batch = 0.6828s	
359/29900 (epoch 0.600), train_loss = 2.72590460, grad/param norm = 4.2262e-01, time/batch = 0.6844s	
360/29900 (epoch 0.602), train_loss = 2.87429203, grad/param norm = 6.3723e-01, time/batch = 0.6867s	
361/29900 (epoch 0.604), train_loss = 2.86087048, grad/param norm = 5.3735e-01, time/batch = 0.6885s	
362/29900 (epoch 0.605), train_loss = 2.82739734, grad/param norm = 3.3225e-01, time/batch = 0.6896s	
363/29900 (epoch 0.607), train_loss = 2.75422185, grad/param norm = 5.6916e-01, time/batch = 0.6896s	
364/29900 (epoch 0.609), train_loss = 2.87687513, grad/param norm = 6.5123e-01, time/batch = 0.6844s	
365/29900 (epoch 0.610), train_loss = 2.96068651, grad/param norm = 5.9076e-01, time/batch = 0.6848s	
366/29900 (epoch 0.612), train_loss = 2.85541537, grad/param norm = 4.2589e-01, time/batch = 0.6856s	
367/29900 (epoch 0.614), train_loss = 2.78314797, grad/param norm = 3.7811e-01, time/batch = 0.6921s	
368/29900 (epoch 0.615), train_loss = 2.99093147, grad/param norm = 4.3264e-01, time/batch = 0.6969s	
369/29900 (epoch 0.617), train_loss = 2.84254541, grad/param norm = 4.8267e-01, time/batch = 0.6873s	
370/29900 (epoch 0.619), train_loss = 2.81682602, grad/param norm = 4.5366e-01, time/batch = 0.7029s	
371/29900 (epoch 0.620), train_loss = 2.79990008, grad/param norm = 4.4257e-01, time/batch = 0.7038s	
372/29900 (epoch 0.622), train_loss = 2.83652891, grad/param norm = 3.8183e-01, time/batch = 0.6918s	
373/29900 (epoch 0.624), train_loss = 2.79038453, grad/param norm = 3.3275e-01, time/batch = 0.6980s	
374/29900 (epoch 0.625), train_loss = 2.74937793, grad/param norm = 3.5945e-01, time/batch = 0.6960s	
375/29900 (epoch 0.627), train_loss = 2.67655477, grad/param norm = 4.6176e-01, time/batch = 0.7002s	
376/29900 (epoch 0.629), train_loss = 2.72677610, grad/param norm = 4.5528e-01, time/batch = 0.7088s	
377/29900 (epoch 0.630), train_loss = 2.81170129, grad/param norm = 3.7964e-01, time/batch = 0.7082s	
378/29900 (epoch 0.632), train_loss = 2.82901306, grad/param norm = 3.8261e-01, time/batch = 0.7056s	
379/29900 (epoch 0.634), train_loss = 2.73715727, grad/param norm = 3.8380e-01, time/batch = 0.7079s	
380/29900 (epoch 0.635), train_loss = 2.77993952, grad/param norm = 3.7074e-01, time/batch = 0.6923s	
381/29900 (epoch 0.637), train_loss = 2.85720083, grad/param norm = 3.8904e-01, time/batch = 0.6861s	
382/29900 (epoch 0.639), train_loss = 2.92262676, grad/param norm = 4.1866e-01, time/batch = 0.6901s	
383/29900 (epoch 0.640), train_loss = 2.87014921, grad/param norm = 7.0448e-01, time/batch = 0.6845s	
384/29900 (epoch 0.642), train_loss = 2.90107724, grad/param norm = 6.2048e-01, time/batch = 0.6810s	
385/29900 (epoch 0.644), train_loss = 2.70267439, grad/param norm = 6.7541e-01, time/batch = 0.6836s	
386/29900 (epoch 0.645), train_loss = 3.00495371, grad/param norm = 1.0010e+00, time/batch = 0.6840s	
387/29900 (epoch 0.647), train_loss = 2.71749408, grad/param norm = 7.1066e-01, time/batch = 0.6807s	
388/29900 (epoch 0.649), train_loss = 2.67345890, grad/param norm = 4.5881e-01, time/batch = 0.6816s	
389/29900 (epoch 0.651), train_loss = 2.74449757, grad/param norm = 4.6283e-01, time/batch = 0.7154s	
390/29900 (epoch 0.652), train_loss = 2.66994034, grad/param norm = 3.3024e-01, time/batch = 0.7113s	
391/29900 (epoch 0.654), train_loss = 2.76357443, grad/param norm = 4.7986e-01, time/batch = 0.6882s	
392/29900 (epoch 0.656), train_loss = 2.68963463, grad/param norm = 4.5094e-01, time/batch = 0.6944s	
393/29900 (epoch 0.657), train_loss = 2.62470643, grad/param norm = 3.7547e-01, time/batch = 0.6989s	
394/29900 (epoch 0.659), train_loss = 2.58955166, grad/param norm = 5.3913e-01, time/batch = 0.7032s	
395/29900 (epoch 0.661), train_loss = 2.90901792, grad/param norm = 6.3148e-01, time/batch = 0.6880s	
396/29900 (epoch 0.662), train_loss = 2.85511521, grad/param norm = 4.1265e-01, time/batch = 0.6877s	
397/29900 (epoch 0.664), train_loss = 2.67097575, grad/param norm = 3.9149e-01, time/batch = 0.6844s	
398/29900 (epoch 0.666), train_loss = 2.65790364, grad/param norm = 3.9430e-01, time/batch = 0.6844s	
399/29900 (epoch 0.667), train_loss = 2.64146049, grad/param norm = 3.6536e-01, time/batch = 0.6856s	
400/29900 (epoch 0.669), train_loss = 2.70702030, grad/param norm = 5.0086e-01, time/batch = 0.6846s	
401/29900 (epoch 0.671), train_loss = 2.72174590, grad/param norm = 4.6004e-01, time/batch = 0.6884s	
402/29900 (epoch 0.672), train_loss = 2.73712703, grad/param norm = 3.2479e-01, time/batch = 0.6872s	
403/29900 (epoch 0.674), train_loss = 2.73381674, grad/param norm = 3.3083e-01, time/batch = 0.6863s	
404/29900 (epoch 0.676), train_loss = 2.68433728, grad/param norm = 3.7129e-01, time/batch = 0.6840s	
405/29900 (epoch 0.677), train_loss = 2.80645615, grad/param norm = 4.0555e-01, time/batch = 0.6828s	
406/29900 (epoch 0.679), train_loss = 2.87934599, grad/param norm = 3.0422e-01, time/batch = 0.6838s	
407/29900 (epoch 0.681), train_loss = 2.80888620, grad/param norm = 3.7825e-01, time/batch = 0.6871s	
408/29900 (epoch 0.682), train_loss = 2.90534133, grad/param norm = 4.4730e-01, time/batch = 0.7249s	
409/29900 (epoch 0.684), train_loss = 2.73340308, grad/param norm = 5.4571e-01, time/batch = 0.7022s	
410/29900 (epoch 0.686), train_loss = 2.89407943, grad/param norm = 5.4129e-01, time/batch = 0.6881s	
411/29900 (epoch 0.687), train_loss = 2.66538575, grad/param norm = 4.8876e-01, time/batch = 0.6917s	
412/29900 (epoch 0.689), train_loss = 2.74154480, grad/param norm = 5.5104e-01, time/batch = 0.6878s	
413/29900 (epoch 0.691), train_loss = 2.88309193, grad/param norm = 4.5431e-01, time/batch = 0.6852s	
414/29900 (epoch 0.692), train_loss = 2.83528306, grad/param norm = 3.6583e-01, time/batch = 0.6832s	
415/29900 (epoch 0.694), train_loss = 2.65156548, grad/param norm = 4.3153e-01, time/batch = 0.6922s	
416/29900 (epoch 0.696), train_loss = 2.61009789, grad/param norm = 4.4983e-01, time/batch = 0.6949s	
417/29900 (epoch 0.697), train_loss = 2.77359819, grad/param norm = 3.9439e-01, time/batch = 0.6988s	
418/29900 (epoch 0.699), train_loss = 2.56984303, grad/param norm = 4.2479e-01, time/batch = 0.6931s	
419/29900 (epoch 0.701), train_loss = 2.62647652, grad/param norm = 4.7465e-01, time/batch = 0.7259s	
420/29900 (epoch 0.702), train_loss = 2.73014664, grad/param norm = 3.9717e-01, time/batch = 0.6977s	
421/29900 (epoch 0.704), train_loss = 2.57087366, grad/param norm = 4.6263e-01, time/batch = 0.6899s	
422/29900 (epoch 0.706), train_loss = 2.59811773, grad/param norm = 5.9132e-01, time/batch = 0.6883s	
423/29900 (epoch 0.707), train_loss = 2.78542472, grad/param norm = 4.5091e-01, time/batch = 0.6990s	
424/29900 (epoch 0.709), train_loss = 2.70734491, grad/param norm = 4.0160e-01, time/batch = 0.7036s	
425/29900 (epoch 0.711), train_loss = 2.62894821, grad/param norm = 3.7634e-01, time/batch = 0.6907s	
426/29900 (epoch 0.712), train_loss = 2.61879289, grad/param norm = 3.2544e-01, time/batch = 0.7076s	
427/29900 (epoch 0.714), train_loss = 2.66668519, grad/param norm = 3.3431e-01, time/batch = 0.7212s	
428/29900 (epoch 0.716), train_loss = 2.60557846, grad/param norm = 3.4172e-01, time/batch = 0.6888s	
429/29900 (epoch 0.717), train_loss = 2.58525367, grad/param norm = 3.5977e-01, time/batch = 0.6840s	
430/29900 (epoch 0.719), train_loss = 2.57667619, grad/param norm = 4.2340e-01, time/batch = 0.6851s	
431/29900 (epoch 0.721), train_loss = 2.70230026, grad/param norm = 6.6969e-01, time/batch = 0.6887s	
432/29900 (epoch 0.722), train_loss = 2.85286211, grad/param norm = 8.7240e-01, time/batch = 0.6886s	
433/29900 (epoch 0.724), train_loss = 2.80957001, grad/param norm = 5.7445e-01, time/batch = 0.6856s	
434/29900 (epoch 0.726), train_loss = 2.68607466, grad/param norm = 4.1690e-01, time/batch = 0.6841s	
435/29900 (epoch 0.727), train_loss = 2.66910530, grad/param norm = 4.4638e-01, time/batch = 0.6842s	
436/29900 (epoch 0.729), train_loss = 2.65102408, grad/param norm = 3.8276e-01, time/batch = 0.6847s	
437/29900 (epoch 0.731), train_loss = 2.63518912, grad/param norm = 3.3694e-01, time/batch = 0.6891s	
438/29900 (epoch 0.732), train_loss = 2.68565263, grad/param norm = 3.9231e-01, time/batch = 0.6875s	
439/29900 (epoch 0.734), train_loss = 2.75820883, grad/param norm = 5.1314e-01, time/batch = 0.6894s	
440/29900 (epoch 0.736), train_loss = 2.79269244, grad/param norm = 5.1640e-01, time/batch = 0.6871s	
441/29900 (epoch 0.737), train_loss = 2.67386466, grad/param norm = 4.0410e-01, time/batch = 0.6858s	
442/29900 (epoch 0.739), train_loss = 2.80441551, grad/param norm = 4.0658e-01, time/batch = 0.6866s	
443/29900 (epoch 0.741), train_loss = 2.60425025, grad/param norm = 3.6396e-01, time/batch = 0.6872s	
444/29900 (epoch 0.742), train_loss = 2.51316022, grad/param norm = 3.9385e-01, time/batch = 0.6871s	
445/29900 (epoch 0.744), train_loss = 2.64720819, grad/param norm = 5.5284e-01, time/batch = 0.6928s	
446/29900 (epoch 0.746), train_loss = 2.66677368, grad/param norm = 6.3863e-01, time/batch = 0.6936s	
447/29900 (epoch 0.747), train_loss = 2.78902722, grad/param norm = 4.4319e-01, time/batch = 0.6917s	
448/29900 (epoch 0.749), train_loss = 2.63176728, grad/param norm = 3.2315e-01, time/batch = 0.6830s	
449/29900 (epoch 0.751), train_loss = 2.74220452, grad/param norm = 3.2821e-01, time/batch = 0.6996s	
450/29900 (epoch 0.753), train_loss = 2.77362885, grad/param norm = 3.1747e-01, time/batch = 0.7253s	
451/29900 (epoch 0.754), train_loss = 2.62729744, grad/param norm = 4.5454e-01, time/batch = 0.6836s	
452/29900 (epoch 0.756), train_loss = 2.66605536, grad/param norm = 4.6709e-01, time/batch = 0.6849s	
453/29900 (epoch 0.758), train_loss = 2.81163869, grad/param norm = 4.9590e-01, time/batch = 0.6862s	
454/29900 (epoch 0.759), train_loss = 2.73576248, grad/param norm = 4.3821e-01, time/batch = 0.6848s	
455/29900 (epoch 0.761), train_loss = 2.70169055, grad/param norm = 3.5506e-01, time/batch = 0.6841s	
456/29900 (epoch 0.763), train_loss = 2.63110002, grad/param norm = 3.3514e-01, time/batch = 0.6829s	
457/29900 (epoch 0.764), train_loss = 2.60838034, grad/param norm = 3.0162e-01, time/batch = 0.6844s	
458/29900 (epoch 0.766), train_loss = 2.64431194, grad/param norm = 4.0938e-01, time/batch = 0.6827s	
459/29900 (epoch 0.768), train_loss = 2.64426644, grad/param norm = 3.8305e-01, time/batch = 0.6826s	
460/29900 (epoch 0.769), train_loss = 2.69799260, grad/param norm = 2.8331e-01, time/batch = 0.6866s	
461/29900 (epoch 0.771), train_loss = 2.67446322, grad/param norm = 3.2637e-01, time/batch = 0.6897s	
462/29900 (epoch 0.773), train_loss = 2.74060570, grad/param norm = 3.5728e-01, time/batch = 0.6870s	
463/29900 (epoch 0.774), train_loss = 2.63392071, grad/param norm = 3.8971e-01, time/batch = 0.6848s	
464/29900 (epoch 0.776), train_loss = 2.46237844, grad/param norm = 3.8081e-01, time/batch = 0.6832s	
465/29900 (epoch 0.778), train_loss = 2.68926387, grad/param norm = 4.2262e-01, time/batch = 0.6847s	
466/29900 (epoch 0.779), train_loss = 2.74298834, grad/param norm = 4.8574e-01, time/batch = 0.6854s	
467/29900 (epoch 0.781), train_loss = 2.53706389, grad/param norm = 5.6173e-01, time/batch = 0.6826s	
468/29900 (epoch 0.783), train_loss = 2.74165727, grad/param norm = 6.0140e-01, time/batch = 0.7068s	
469/29900 (epoch 0.784), train_loss = 2.64072345, grad/param norm = 4.9366e-01, time/batch = 0.7182s	
470/29900 (epoch 0.786), train_loss = 2.69998424, grad/param norm = 3.7401e-01, time/batch = 0.6872s	
471/29900 (epoch 0.788), train_loss = 2.70373766, grad/param norm = 2.6535e-01, time/batch = 0.6885s	
472/29900 (epoch 0.789), train_loss = 2.72635725, grad/param norm = 3.3127e-01, time/batch = 0.6837s	
473/29900 (epoch 0.791), train_loss = 2.45970913, grad/param norm = 2.5867e-01, time/batch = 0.6874s	
474/29900 (epoch 0.793), train_loss = 2.56739640, grad/param norm = 3.4716e-01, time/batch = 0.6852s	
475/29900 (epoch 0.794), train_loss = 2.64582703, grad/param norm = 3.7910e-01, time/batch = 0.6869s	
476/29900 (epoch 0.796), train_loss = 2.66817736, grad/param norm = 3.4326e-01, time/batch = 0.6912s	
477/29900 (epoch 0.798), train_loss = 2.68663933, grad/param norm = 4.0060e-01, time/batch = 0.6842s	
478/29900 (epoch 0.799), train_loss = 2.60043822, grad/param norm = 3.8130e-01, time/batch = 0.6817s	
479/29900 (epoch 0.801), train_loss = 2.60234496, grad/param norm = 3.9168e-01, time/batch = 0.6818s	
480/29900 (epoch 0.803), train_loss = 2.68873068, grad/param norm = 4.8606e-01, time/batch = 0.6817s	
481/29900 (epoch 0.804), train_loss = 2.71486880, grad/param norm = 4.2120e-01, time/batch = 0.6838s	
482/29900 (epoch 0.806), train_loss = 2.51741500, grad/param norm = 4.2169e-01, time/batch = 0.6845s	
483/29900 (epoch 0.808), train_loss = 2.64720528, grad/param norm = 5.0375e-01, time/batch = 0.6882s	
484/29900 (epoch 0.809), train_loss = 2.60879061, grad/param norm = 3.9351e-01, time/batch = 0.6883s	
485/29900 (epoch 0.811), train_loss = 2.63779351, grad/param norm = 3.8766e-01, time/batch = 0.6911s	
486/29900 (epoch 0.813), train_loss = 2.86218861, grad/param norm = 3.2586e-01, time/batch = 0.6880s	
487/29900 (epoch 0.814), train_loss = 2.68490290, grad/param norm = 2.7207e-01, time/batch = 0.7170s	
488/29900 (epoch 0.816), train_loss = 2.93605093, grad/param norm = 2.9737e-01, time/batch = 0.7072s	
489/29900 (epoch 0.818), train_loss = 2.75462689, grad/param norm = 3.7921e-01, time/batch = 0.6831s	
490/29900 (epoch 0.819), train_loss = 2.87382743, grad/param norm = 3.3802e-01, time/batch = 0.6824s	
491/29900 (epoch 0.821), train_loss = 2.65029056, grad/param norm = 2.8578e-01, time/batch = 0.6847s	
492/29900 (epoch 0.823), train_loss = 2.65329861, grad/param norm = 2.7331e-01, time/batch = 0.6845s	
493/29900 (epoch 0.824), train_loss = 2.79908493, grad/param norm = 3.2876e-01, time/batch = 0.6834s	
494/29900 (epoch 0.826), train_loss = 2.72292986, grad/param norm = 4.0183e-01, time/batch = 0.6830s	
495/29900 (epoch 0.828), train_loss = 2.62538013, grad/param norm = 4.8811e-01, time/batch = 0.6830s	
496/29900 (epoch 0.829), train_loss = 2.74098780, grad/param norm = 5.7181e-01, time/batch = 0.6823s	
497/29900 (epoch 0.831), train_loss = 2.76157231, grad/param norm = 4.8030e-01, time/batch = 0.6909s	
498/29900 (epoch 0.833), train_loss = 2.65519794, grad/param norm = 5.3523e-01, time/batch = 0.6881s	
499/29900 (epoch 0.834), train_loss = 2.56570447, grad/param norm = 3.6441e-01, time/batch = 0.6913s	
500/29900 (epoch 0.836), train_loss = 2.68774583, grad/param norm = 3.7173e-01, time/batch = 0.6926s	
501/29900 (epoch 0.838), train_loss = 2.72166635, grad/param norm = 6.4671e-01, time/batch = 0.6845s	
502/29900 (epoch 0.839), train_loss = 2.66331352, grad/param norm = 7.2044e-01, time/batch = 0.6909s	
503/29900 (epoch 0.841), train_loss = 2.81165504, grad/param norm = 4.8502e-01, time/batch = 0.6938s	
504/29900 (epoch 0.843), train_loss = 2.74539236, grad/param norm = 5.8168e-01, time/batch = 0.6974s	
505/29900 (epoch 0.844), train_loss = 2.56776932, grad/param norm = 3.9981e-01, time/batch = 0.6913s	
506/29900 (epoch 0.846), train_loss = 2.47541372, grad/param norm = 2.6614e-01, time/batch = 0.7285s	
507/29900 (epoch 0.848), train_loss = 2.59179955, grad/param norm = 2.3098e-01, time/batch = 0.7172s	
508/29900 (epoch 0.849), train_loss = 2.70923664, grad/param norm = 3.1154e-01, time/batch = 0.6980s	
509/29900 (epoch 0.851), train_loss = 2.65537581, grad/param norm = 3.3361e-01, time/batch = 0.6845s	
510/29900 (epoch 0.853), train_loss = 2.67995413, grad/param norm = 3.5184e-01, time/batch = 0.6819s	
511/29900 (epoch 0.855), train_loss = 2.62781004, grad/param norm = 3.6180e-01, time/batch = 0.6854s	
512/29900 (epoch 0.856), train_loss = 2.64367162, grad/param norm = 3.7580e-01, time/batch = 0.6817s	
513/29900 (epoch 0.858), train_loss = 2.51006298, grad/param norm = 2.8995e-01, time/batch = 0.6813s	
514/29900 (epoch 0.860), train_loss = 2.44456312, grad/param norm = 2.7388e-01, time/batch = 0.6847s	
515/29900 (epoch 0.861), train_loss = 2.62592604, grad/param norm = 3.3076e-01, time/batch = 0.6912s	
516/29900 (epoch 0.863), train_loss = 2.45993405, grad/param norm = 5.8080e-01, time/batch = 0.6915s	
517/29900 (epoch 0.865), train_loss = 2.42190310, grad/param norm = 6.6928e-01, time/batch = 0.6934s	
518/29900 (epoch 0.866), train_loss = 2.63977152, grad/param norm = 6.8775e-01, time/batch = 0.7003s	
519/29900 (epoch 0.868), train_loss = 2.65317324, grad/param norm = 4.6389e-01, time/batch = 0.6898s	
520/29900 (epoch 0.870), train_loss = 2.76873245, grad/param norm = 2.7036e-01, time/batch = 0.6919s	
521/29900 (epoch 0.871), train_loss = 2.48575120, grad/param norm = 3.4528e-01, time/batch = 0.6952s	
522/29900 (epoch 0.873), train_loss = 2.53470831, grad/param norm = 3.6198e-01, time/batch = 0.6919s	
523/29900 (epoch 0.875), train_loss = 2.60323640, grad/param norm = 2.9073e-01, time/batch = 0.6998s	
524/29900 (epoch 0.876), train_loss = 2.42548666, grad/param norm = 2.3813e-01, time/batch = 0.7132s	
525/29900 (epoch 0.878), train_loss = 2.65262347, grad/param norm = 2.9136e-01, time/batch = 0.7283s	
526/29900 (epoch 0.880), train_loss = 2.38567769, grad/param norm = 2.6450e-01, time/batch = 0.6810s	
527/29900 (epoch 0.881), train_loss = 2.74012102, grad/param norm = 2.8301e-01, time/batch = 0.6861s	
528/29900 (epoch 0.883), train_loss = 2.74574249, grad/param norm = 2.9747e-01, time/batch = 0.7005s	
529/29900 (epoch 0.885), train_loss = 2.77797267, grad/param norm = 2.7284e-01, time/batch = 0.7206s	
530/29900 (epoch 0.886), train_loss = 2.65476846, grad/param norm = 3.2200e-01, time/batch = 0.7173s	
531/29900 (epoch 0.888), train_loss = 2.54782054, grad/param norm = 3.1407e-01, time/batch = 0.7137s	
532/29900 (epoch 0.890), train_loss = 2.53968050, grad/param norm = 3.7364e-01, time/batch = 0.7051s	
533/29900 (epoch 0.891), train_loss = 2.53894140, grad/param norm = 2.6581e-01, time/batch = 0.6916s	
534/29900 (epoch 0.893), train_loss = 2.42913271, grad/param norm = 2.7351e-01, time/batch = 0.6818s	
535/29900 (epoch 0.895), train_loss = 2.59096659, grad/param norm = 3.4803e-01, time/batch = 0.6811s	
536/29900 (epoch 0.896), train_loss = 2.57011174, grad/param norm = 2.9870e-01, time/batch = 0.6823s	
537/29900 (epoch 0.898), train_loss = 2.63734790, grad/param norm = 3.5507e-01, time/batch = 0.6868s	
538/29900 (epoch 0.900), train_loss = 2.59812913, grad/param norm = 2.9261e-01, time/batch = 0.6856s	
539/29900 (epoch 0.901), train_loss = 2.48257465, grad/param norm = 2.4030e-01, time/batch = 0.7248s	
540/29900 (epoch 0.903), train_loss = 2.48470891, grad/param norm = 4.0032e-01, time/batch = 0.6913s	
541/29900 (epoch 0.905), train_loss = 2.59316580, grad/param norm = 5.6019e-01, time/batch = 0.6828s	
542/29900 (epoch 0.906), train_loss = 2.76928759, grad/param norm = 5.1152e-01, time/batch = 0.6814s	
543/29900 (epoch 0.908), train_loss = 2.62578730, grad/param norm = 5.1571e-01, time/batch = 0.6818s	
544/29900 (epoch 0.910), train_loss = 2.61029928, grad/param norm = 5.3859e-01, time/batch = 0.6863s	
545/29900 (epoch 0.911), train_loss = 2.47677129, grad/param norm = 4.2354e-01, time/batch = 0.6826s	
546/29900 (epoch 0.913), train_loss = 2.36307064, grad/param norm = 2.5424e-01, time/batch = 0.6831s	
547/29900 (epoch 0.915), train_loss = 2.58290259, grad/param norm = 3.4442e-01, time/batch = 0.6832s	
548/29900 (epoch 0.916), train_loss = 2.47725639, grad/param norm = 3.8403e-01, time/batch = 0.6814s	
549/29900 (epoch 0.918), train_loss = 2.71305532, grad/param norm = 4.0735e-01, time/batch = 0.6805s	
550/29900 (epoch 0.920), train_loss = 2.82464496, grad/param norm = 4.2416e-01, time/batch = 0.6807s	
551/29900 (epoch 0.921), train_loss = 2.73458373, grad/param norm = 3.6581e-01, time/batch = 0.6835s	
552/29900 (epoch 0.923), train_loss = 2.70766403, grad/param norm = 2.8607e-01, time/batch = 0.6848s	
553/29900 (epoch 0.925), train_loss = 2.44805134, grad/param norm = 2.8898e-01, time/batch = 0.6834s	
554/29900 (epoch 0.926), train_loss = 2.45069981, grad/param norm = 3.2297e-01, time/batch = 0.6826s	
555/29900 (epoch 0.928), train_loss = 2.45230013, grad/param norm = 3.3126e-01, time/batch = 0.6812s	
556/29900 (epoch 0.930), train_loss = 2.52541550, grad/param norm = 4.0808e-01, time/batch = 0.6814s	
557/29900 (epoch 0.931), train_loss = 2.38330763, grad/param norm = 3.6029e-01, time/batch = 0.6956s	
558/29900 (epoch 0.933), train_loss = 2.54457550, grad/param norm = 3.4226e-01, time/batch = 0.7252s	
559/29900 (epoch 0.935), train_loss = 2.87928390, grad/param norm = 2.8405e-01, time/batch = 0.6891s	
560/29900 (epoch 0.936), train_loss = 2.72319495, grad/param norm = 3.9362e-01, time/batch = 0.6831s	
561/29900 (epoch 0.938), train_loss = 2.42830560, grad/param norm = 3.4756e-01, time/batch = 0.6883s	
562/29900 (epoch 0.940), train_loss = 2.55840293, grad/param norm = 3.9906e-01, time/batch = 0.6823s	
563/29900 (epoch 0.941), train_loss = 2.56378330, grad/param norm = 3.9047e-01, time/batch = 0.6817s	
564/29900 (epoch 0.943), train_loss = 2.64893342, grad/param norm = 3.5232e-01, time/batch = 0.6815s	
565/29900 (epoch 0.945), train_loss = 2.66329138, grad/param norm = 3.2680e-01, time/batch = 0.7006s	
566/29900 (epoch 0.946), train_loss = 2.65206622, grad/param norm = 4.9477e-01, time/batch = 0.6932s	
567/29900 (epoch 0.948), train_loss = 2.50147396, grad/param norm = 5.0850e-01, time/batch = 0.6836s	
568/29900 (epoch 0.950), train_loss = 2.70990705, grad/param norm = 3.4790e-01, time/batch = 0.6872s	
569/29900 (epoch 0.952), train_loss = 2.38076969, grad/param norm = 3.1429e-01, time/batch = 0.6821s	
570/29900 (epoch 0.953), train_loss = 2.37397945, grad/param norm = 3.1939e-01, time/batch = 0.6813s	
571/29900 (epoch 0.955), train_loss = 2.57940918, grad/param norm = 4.3115e-01, time/batch = 0.6842s	
572/29900 (epoch 0.957), train_loss = 2.65303839, grad/param norm = 4.7096e-01, time/batch = 0.6848s	
573/29900 (epoch 0.958), train_loss = 2.69245672, grad/param norm = 5.4776e-01, time/batch = 0.6861s	
574/29900 (epoch 0.960), train_loss = 2.64044788, grad/param norm = 5.9940e-01, time/batch = 0.6859s	
575/29900 (epoch 0.962), train_loss = 2.87471708, grad/param norm = 4.9938e-01, time/batch = 0.6856s	
576/29900 (epoch 0.963), train_loss = 2.65456395, grad/param norm = 3.9042e-01, time/batch = 0.7085s	
577/29900 (epoch 0.965), train_loss = 2.60068451, grad/param norm = 3.6337e-01, time/batch = 0.7205s	
578/29900 (epoch 0.967), train_loss = 2.46707534, grad/param norm = 3.1554e-01, time/batch = 0.6829s	
579/29900 (epoch 0.968), train_loss = 2.63194801, grad/param norm = 3.6552e-01, time/batch = 0.6880s	
580/29900 (epoch 0.970), train_loss = 2.58553688, grad/param norm = 2.9644e-01, time/batch = 0.7036s	
581/29900 (epoch 0.972), train_loss = 2.31738716, grad/param norm = 3.0565e-01, time/batch = 0.6918s	
582/29900 (epoch 0.973), train_loss = 2.39531364, grad/param norm = 2.7909e-01, time/batch = 0.6879s	
583/29900 (epoch 0.975), train_loss = 2.62631579, grad/param norm = 3.5929e-01, time/batch = 0.6868s	
584/29900 (epoch 0.977), train_loss = 2.47568761, grad/param norm = 3.0106e-01, time/batch = 0.6846s	
585/29900 (epoch 0.978), train_loss = 2.49742024, grad/param norm = 3.2468e-01, time/batch = 0.6821s	
586/29900 (epoch 0.980), train_loss = 2.63357200, grad/param norm = 2.7145e-01, time/batch = 0.6815s	
587/29900 (epoch 0.982), train_loss = 2.58812643, grad/param norm = 3.3360e-01, time/batch = 0.6805s	
588/29900 (epoch 0.983), train_loss = 2.66106447, grad/param norm = 3.2128e-01, time/batch = 0.6806s	
589/29900 (epoch 0.985), train_loss = 2.64781944, grad/param norm = 2.8507e-01, time/batch = 0.6943s	
590/29900 (epoch 0.987), train_loss = 2.49915494, grad/param norm = 3.0716e-01, time/batch = 0.6975s	
591/29900 (epoch 0.988), train_loss = 2.55956669, grad/param norm = 2.9121e-01, time/batch = 0.6948s	
592/29900 (epoch 0.990), train_loss = 2.57215060, grad/param norm = 3.9210e-01, time/batch = 0.7130s	
593/29900 (epoch 0.992), train_loss = 2.44501967, grad/param norm = 4.6449e-01, time/batch = 0.6928s	
594/29900 (epoch 0.993), train_loss = 2.50280419, grad/param norm = 3.8302e-01, time/batch = 0.6837s	
595/29900 (epoch 0.995), train_loss = 2.50728864, grad/param norm = 3.6140e-01, time/batch = 0.7175s	
596/29900 (epoch 0.997), train_loss = 2.55065707, grad/param norm = 3.6660e-01, time/batch = 0.7087s	
597/29900 (epoch 0.998), train_loss = 2.48105284, grad/param norm = 3.6158e-01, time/batch = 0.6852s	
598/29900 (epoch 1.000), train_loss = 2.47301234, grad/param norm = 4.5897e-01, time/batch = 0.6829s	
599/29900 (epoch 1.002), train_loss = 2.58069353, grad/param norm = 4.1788e-01, time/batch = 0.6854s	
600/29900 (epoch 1.003), train_loss = 2.54629735, grad/param norm = 3.8198e-01, time/batch = 0.6816s	
601/29900 (epoch 1.005), train_loss = 2.51631373, grad/param norm = 3.8271e-01, time/batch = 0.6811s	
602/29900 (epoch 1.007), train_loss = 2.61728740, grad/param norm = 4.8378e-01, time/batch = 0.6809s	
603/29900 (epoch 1.008), train_loss = 2.56823761, grad/param norm = 3.7070e-01, time/batch = 0.6830s	
604/29900 (epoch 1.010), train_loss = 2.42189423, grad/param norm = 2.7646e-01, time/batch = 0.6821s	
605/29900 (epoch 1.012), train_loss = 2.42164921, grad/param norm = 2.6527e-01, time/batch = 0.6911s	
606/29900 (epoch 1.013), train_loss = 2.57099368, grad/param norm = 3.3972e-01, time/batch = 0.6837s	
607/29900 (epoch 1.015), train_loss = 2.62019929, grad/param norm = 4.5693e-01, time/batch = 0.6852s	
608/29900 (epoch 1.017), train_loss = 2.64128257, grad/param norm = 4.9741e-01, time/batch = 0.6814s	
609/29900 (epoch 1.018), train_loss = 2.63899533, grad/param norm = 4.4719e-01, time/batch = 0.6811s	
610/29900 (epoch 1.020), train_loss = 2.62131526, grad/param norm = 3.1433e-01, time/batch = 0.6804s	
611/29900 (epoch 1.022), train_loss = 2.44337581, grad/param norm = 3.7056e-01, time/batch = 0.6835s	
612/29900 (epoch 1.023), train_loss = 2.58256285, grad/param norm = 5.1998e-01, time/batch = 0.6825s	
613/29900 (epoch 1.025), train_loss = 2.45096894, grad/param norm = 3.0539e-01, time/batch = 0.6829s	
614/29900 (epoch 1.027), train_loss = 2.34612603, grad/param norm = 2.6304e-01, time/batch = 0.7245s	
615/29900 (epoch 1.028), train_loss = 2.74695327, grad/param norm = 3.6797e-01, time/batch = 0.6988s	
616/29900 (epoch 1.030), train_loss = 2.78919502, grad/param norm = 4.5643e-01, time/batch = 0.6828s	
617/29900 (epoch 1.032), train_loss = 2.59963854, grad/param norm = 3.1606e-01, time/batch = 0.6830s	
618/29900 (epoch 1.033), train_loss = 2.61645515, grad/param norm = 3.3148e-01, time/batch = 0.6826s	
619/29900 (epoch 1.035), train_loss = 2.43292732, grad/param norm = 3.3108e-01, time/batch = 0.6833s	
620/29900 (epoch 1.037), train_loss = 2.51466581, grad/param norm = 2.7034e-01, time/batch = 0.6827s	
621/29900 (epoch 1.038), train_loss = 2.49324872, grad/param norm = 2.6481e-01, time/batch = 0.6859s	
622/29900 (epoch 1.040), train_loss = 2.39485484, grad/param norm = 3.2256e-01, time/batch = 0.6926s	
623/29900 (epoch 1.042), train_loss = 2.55529611, grad/param norm = 3.7285e-01, time/batch = 0.6859s	
624/29900 (epoch 1.043), train_loss = 2.70233656, grad/param norm = 3.4220e-01, time/batch = 0.6860s	
625/29900 (epoch 1.045), train_loss = 2.46841177, grad/param norm = 3.1676e-01, time/batch = 0.7082s	
626/29900 (epoch 1.047), train_loss = 2.62291719, grad/param norm = 3.5685e-01, time/batch = 0.6835s	
627/29900 (epoch 1.048), train_loss = 2.42318046, grad/param norm = 4.3567e-01, time/batch = 0.6833s	
628/29900 (epoch 1.050), train_loss = 2.32872564, grad/param norm = 2.9299e-01, time/batch = 0.6837s	
629/29900 (epoch 1.052), train_loss = 2.40210572, grad/param norm = 3.1807e-01, time/batch = 0.6864s	
630/29900 (epoch 1.054), train_loss = 2.64796826, grad/param norm = 4.3751e-01, time/batch = 0.6830s	
631/29900 (epoch 1.055), train_loss = 2.58458067, grad/param norm = 3.9829e-01, time/batch = 0.6891s	
632/29900 (epoch 1.057), train_loss = 2.46304338, grad/param norm = 3.2386e-01, time/batch = 0.6871s	
633/29900 (epoch 1.059), train_loss = 2.58959180, grad/param norm = 3.3898e-01, time/batch = 0.6928s	
634/29900 (epoch 1.060), train_loss = 2.56537470, grad/param norm = 3.3864e-01, time/batch = 0.6836s	
635/29900 (epoch 1.062), train_loss = 2.60670832, grad/param norm = 2.9497e-01, time/batch = 0.6848s	
636/29900 (epoch 1.064), train_loss = 2.56334047, grad/param norm = 2.8746e-01, time/batch = 0.6835s	
637/29900 (epoch 1.065), train_loss = 2.60740579, grad/param norm = 2.8946e-01, time/batch = 0.7179s	
638/29900 (epoch 1.067), train_loss = 2.49152570, grad/param norm = 2.6872e-01, time/batch = 0.7052s	
639/29900 (epoch 1.069), train_loss = 2.63925679, grad/param norm = 2.7725e-01, time/batch = 0.6824s	
640/29900 (epoch 1.070), train_loss = 2.47391489, grad/param norm = 3.2319e-01, time/batch = 0.6849s	
641/29900 (epoch 1.072), train_loss = 2.52023189, grad/param norm = 3.6420e-01, time/batch = 0.6843s	
642/29900 (epoch 1.074), train_loss = 2.66933503, grad/param norm = 3.5176e-01, time/batch = 0.6827s	
643/29900 (epoch 1.075), train_loss = 2.43651668, grad/param norm = 2.6088e-01, time/batch = 0.6856s	
644/29900 (epoch 1.077), train_loss = 2.33292691, grad/param norm = 3.1453e-01, time/batch = 0.6858s	
645/29900 (epoch 1.079), train_loss = 2.46751943, grad/param norm = 4.0857e-01, time/batch = 0.6828s	
646/29900 (epoch 1.080), train_loss = 2.36064398, grad/param norm = 6.4915e-01, time/batch = 0.6833s	
647/29900 (epoch 1.082), train_loss = 2.48494307, grad/param norm = 5.8721e-01, time/batch = 0.6836s	
648/29900 (epoch 1.084), train_loss = 2.74683628, grad/param norm = 3.1130e-01, time/batch = 0.6829s	
649/29900 (epoch 1.085), train_loss = 2.58076760, grad/param norm = 2.7198e-01, time/batch = 0.6832s	
650/29900 (epoch 1.087), train_loss = 2.64220560, grad/param norm = 2.7690e-01, time/batch = 0.6848s	
651/29900 (epoch 1.089), train_loss = 2.58184934, grad/param norm = 2.9848e-01, time/batch = 0.6843s	
652/29900 (epoch 1.090), train_loss = 2.51042510, grad/param norm = 3.3330e-01, time/batch = 0.6844s	
653/29900 (epoch 1.092), train_loss = 2.33987724, grad/param norm = 3.2597e-01, time/batch = 0.6823s	
654/29900 (epoch 1.094), train_loss = 2.48112509, grad/param norm = 2.5742e-01, time/batch = 0.6819s	
655/29900 (epoch 1.095), train_loss = 2.56687310, grad/param norm = 2.5931e-01, time/batch = 0.6946s	
656/29900 (epoch 1.097), train_loss = 2.47828729, grad/param norm = 3.3207e-01, time/batch = 0.7275s	
657/29900 (epoch 1.099), train_loss = 2.53173920, grad/param norm = 3.8184e-01, time/batch = 0.6987s	
658/29900 (epoch 1.100), train_loss = 2.25864591, grad/param norm = 3.8722e-01, time/batch = 0.6830s	
659/29900 (epoch 1.102), train_loss = 2.49308323, grad/param norm = 4.7710e-01, time/batch = 0.6815s	
660/29900 (epoch 1.104), train_loss = 2.50889471, grad/param norm = 3.9867e-01, time/batch = 0.6858s	
661/29900 (epoch 1.105), train_loss = 2.58995496, grad/param norm = 3.0607e-01, time/batch = 0.6845s	
662/29900 (epoch 1.107), train_loss = 2.50953577, grad/param norm = 3.0472e-01, time/batch = 0.6941s	
663/29900 (epoch 1.109), train_loss = 2.61331141, grad/param norm = 3.1345e-01, time/batch = 0.6948s	
664/29900 (epoch 1.110), train_loss = 2.49762569, grad/param norm = 2.6932e-01, time/batch = 0.6943s	
665/29900 (epoch 1.112), train_loss = 2.49818832, grad/param norm = 2.5453e-01, time/batch = 0.6921s	
666/29900 (epoch 1.114), train_loss = 2.39539270, grad/param norm = 2.5878e-01, time/batch = 0.6924s	
667/29900 (epoch 1.115), train_loss = 2.46407519, grad/param norm = 2.7565e-01, time/batch = 0.6942s	
668/29900 (epoch 1.117), train_loss = 2.41929939, grad/param norm = 3.3483e-01, time/batch = 0.6829s	
669/29900 (epoch 1.119), train_loss = 2.38294722, grad/param norm = 4.4055e-01, time/batch = 0.6885s	
670/29900 (epoch 1.120), train_loss = 2.52541889, grad/param norm = 3.6154e-01, time/batch = 0.6843s	
671/29900 (epoch 1.122), train_loss = 2.57560447, grad/param norm = 2.9228e-01, time/batch = 0.6842s	
672/29900 (epoch 1.124), train_loss = 2.52859470, grad/param norm = 3.4690e-01, time/batch = 0.6819s	
673/29900 (epoch 1.125), train_loss = 2.39298344, grad/param norm = 3.5679e-01, time/batch = 0.6814s	
674/29900 (epoch 1.127), train_loss = 2.48161878, grad/param norm = 2.7411e-01, time/batch = 0.6941s	
675/29900 (epoch 1.129), train_loss = 2.51301340, grad/param norm = 4.1306e-01, time/batch = 0.7254s	
676/29900 (epoch 1.130), train_loss = 2.48427202, grad/param norm = 3.3771e-01, time/batch = 0.6963s	
677/29900 (epoch 1.132), train_loss = 2.39254007, grad/param norm = 3.1874e-01, time/batch = 0.7032s	
678/29900 (epoch 1.134), train_loss = 2.61756749, grad/param norm = 2.7919e-01, time/batch = 0.6931s	
679/29900 (epoch 1.135), train_loss = 2.36520772, grad/param norm = 3.3816e-01, time/batch = 0.7063s	
680/29900 (epoch 1.137), train_loss = 2.34339876, grad/param norm = 3.7946e-01, time/batch = 0.6831s	
681/29900 (epoch 1.139), train_loss = 2.35523075, grad/param norm = 2.9525e-01, time/batch = 0.6871s	
682/29900 (epoch 1.140), train_loss = 2.41684412, grad/param norm = 2.9685e-01, time/batch = 0.6880s	
683/29900 (epoch 1.142), train_loss = 2.29055126, grad/param norm = 3.2064e-01, time/batch = 0.6886s	
684/29900 (epoch 1.144), train_loss = 2.42372517, grad/param norm = 2.9942e-01, time/batch = 0.6874s	
685/29900 (epoch 1.145), train_loss = 2.44262958, grad/param norm = 3.6741e-01, time/batch = 0.6840s	
686/29900 (epoch 1.147), train_loss = 2.35471464, grad/param norm = 4.5736e-01, time/batch = 0.6829s	
687/29900 (epoch 1.149), train_loss = 2.41581736, grad/param norm = 5.0051e-01, time/batch = 0.6815s	
688/29900 (epoch 1.151), train_loss = 2.48062376, grad/param norm = 4.6153e-01, time/batch = 0.6881s	
689/29900 (epoch 1.152), train_loss = 2.41120686, grad/param norm = 3.0430e-01, time/batch = 0.6995s	
690/29900 (epoch 1.154), train_loss = 2.30407563, grad/param norm = 2.4984e-01, time/batch = 0.6905s	
691/29900 (epoch 1.156), train_loss = 2.42417547, grad/param norm = 2.8296e-01, time/batch = 0.6845s	
692/29900 (epoch 1.157), train_loss = 2.53263059, grad/param norm = 2.6088e-01, time/batch = 0.6870s	
693/29900 (epoch 1.159), train_loss = 2.44623260, grad/param norm = 3.1934e-01, time/batch = 0.7090s	
694/29900 (epoch 1.161), train_loss = 2.58709477, grad/param norm = 3.6601e-01, time/batch = 0.6920s	
695/29900 (epoch 1.162), train_loss = 2.50446994, grad/param norm = 3.2407e-01, time/batch = 0.6807s	
696/29900 (epoch 1.164), train_loss = 2.53240909, grad/param norm = 3.2544e-01, time/batch = 0.6831s	
697/29900 (epoch 1.166), train_loss = 2.42668700, grad/param norm = 4.0157e-01, time/batch = 0.6845s	
698/29900 (epoch 1.167), train_loss = 2.51028974, grad/param norm = 4.1473e-01, time/batch = 0.6856s	
699/29900 (epoch 1.169), train_loss = 2.24804693, grad/param norm = 3.2493e-01, time/batch = 0.6800s	
700/29900 (epoch 1.171), train_loss = 2.34109727, grad/param norm = 3.0982e-01, time/batch = 0.6793s	
701/29900 (epoch 1.172), train_loss = 2.50812466, grad/param norm = 2.6491e-01, time/batch = 0.6846s	
702/29900 (epoch 1.174), train_loss = 2.55230694, grad/param norm = 2.9538e-01, time/batch = 0.6816s	
703/29900 (epoch 1.176), train_loss = 2.43038893, grad/param norm = 3.2020e-01, time/batch = 0.6806s	
704/29900 (epoch 1.177), train_loss = 2.34615590, grad/param norm = 3.2901e-01, time/batch = 0.6819s	
705/29900 (epoch 1.179), train_loss = 2.45428684, grad/param norm = 3.6622e-01, time/batch = 0.6812s	
706/29900 (epoch 1.181), train_loss = 2.36741244, grad/param norm = 3.8491e-01, time/batch = 0.6866s	
707/29900 (epoch 1.182), train_loss = 2.51347105, grad/param norm = 3.6901e-01, time/batch = 0.6804s	
708/29900 (epoch 1.184), train_loss = 2.38245913, grad/param norm = 3.3656e-01, time/batch = 0.6810s	
709/29900 (epoch 1.186), train_loss = 2.37213515, grad/param norm = 3.0204e-01, time/batch = 0.6827s	
710/29900 (epoch 1.187), train_loss = 2.33892522, grad/param norm = 2.7584e-01, time/batch = 0.6811s	
711/29900 (epoch 1.189), train_loss = 2.37809510, grad/param norm = 3.2612e-01, time/batch = 0.6826s	
712/29900 (epoch 1.191), train_loss = 2.46303857, grad/param norm = 2.9504e-01, time/batch = 0.7110s	
713/29900 (epoch 1.192), train_loss = 2.42115377, grad/param norm = 2.4707e-01, time/batch = 0.7145s	
714/29900 (epoch 1.194), train_loss = 2.45640384, grad/param norm = 2.8502e-01, time/batch = 0.6875s	
715/29900 (epoch 1.196), train_loss = 2.47418750, grad/param norm = 3.1754e-01, time/batch = 0.6871s	
716/29900 (epoch 1.197), train_loss = 2.36474562, grad/param norm = 3.0951e-01, time/batch = 0.6822s	
717/29900 (epoch 1.199), train_loss = 2.51625337, grad/param norm = 3.8552e-01, time/batch = 0.6792s	
718/29900 (epoch 1.201), train_loss = 2.45176957, grad/param norm = 3.0722e-01, time/batch = 0.6821s	
719/29900 (epoch 1.202), train_loss = 2.39090123, grad/param norm = 3.3930e-01, time/batch = 0.6827s	
720/29900 (epoch 1.204), train_loss = 2.53540650, grad/param norm = 3.2412e-01, time/batch = 0.6911s	
721/29900 (epoch 1.206), train_loss = 2.57826503, grad/param norm = 2.5541e-01, time/batch = 0.6994s	
722/29900 (epoch 1.207), train_loss = 2.44903865, grad/param norm = 3.1007e-01, time/batch = 0.7170s	
723/29900 (epoch 1.209), train_loss = 2.38416163, grad/param norm = 2.7613e-01, time/batch = 0.6950s	
724/29900 (epoch 1.211), train_loss = 2.26751825, grad/param norm = 2.9179e-01, time/batch = 0.7023s	
725/29900 (epoch 1.212), train_loss = 2.30099759, grad/param norm = 2.6228e-01, time/batch = 0.7066s	
726/29900 (epoch 1.214), train_loss = 2.50765321, grad/param norm = 2.9620e-01, time/batch = 0.6897s	
727/29900 (epoch 1.216), train_loss = 2.43516508, grad/param norm = 3.4236e-01, time/batch = 0.6833s	
728/29900 (epoch 1.217), train_loss = 2.49213252, grad/param norm = 3.7039e-01, time/batch = 0.6880s	
729/29900 (epoch 1.219), train_loss = 2.52112381, grad/param norm = 3.5287e-01, time/batch = 0.6830s	
730/29900 (epoch 1.221), train_loss = 2.48836668, grad/param norm = 4.9824e-01, time/batch = 0.6812s	
731/29900 (epoch 1.222), train_loss = 2.49654465, grad/param norm = 4.6774e-01, time/batch = 0.7270s	
732/29900 (epoch 1.224), train_loss = 2.37821657, grad/param norm = 2.9018e-01, time/batch = 0.6975s	
733/29900 (epoch 1.226), train_loss = 2.50503268, grad/param norm = 2.9430e-01, time/batch = 0.6814s	
734/29900 (epoch 1.227), train_loss = 2.34908512, grad/param norm = 2.7906e-01, time/batch = 0.6813s	
735/29900 (epoch 1.229), train_loss = 2.26457973, grad/param norm = 3.0664e-01, time/batch = 0.6836s	
736/29900 (epoch 1.231), train_loss = 2.22906185, grad/param norm = 3.3316e-01, time/batch = 0.6851s	
737/29900 (epoch 1.232), train_loss = 2.39599024, grad/param norm = 3.2766e-01, time/batch = 0.6808s	
738/29900 (epoch 1.234), train_loss = 2.36631100, grad/param norm = 2.8793e-01, time/batch = 0.6807s	
739/29900 (epoch 1.236), train_loss = 2.50790037, grad/param norm = 2.6251e-01, time/batch = 0.6801s	
740/29900 (epoch 1.237), train_loss = 2.52296831, grad/param norm = 3.1266e-01, time/batch = 0.6799s	
741/29900 (epoch 1.239), train_loss = 2.39428069, grad/param norm = 2.8351e-01, time/batch = 0.6868s	
742/29900 (epoch 1.241), train_loss = 2.42047599, grad/param norm = 2.3833e-01, time/batch = 0.6830s	
743/29900 (epoch 1.242), train_loss = 2.49208406, grad/param norm = 3.5738e-01, time/batch = 0.6848s	
744/29900 (epoch 1.244), train_loss = 2.51492368, grad/param norm = 3.2440e-01, time/batch = 0.6837s	
745/29900 (epoch 1.246), train_loss = 2.21196416, grad/param norm = 3.0939e-01, time/batch = 0.7022s	
746/29900 (epoch 1.247), train_loss = 2.39198357, grad/param norm = 5.1200e-01, time/batch = 0.7202s	
747/29900 (epoch 1.249), train_loss = 2.44179733, grad/param norm = 5.7460e-01, time/batch = 0.6798s	
748/29900 (epoch 1.251), train_loss = 2.60209846, grad/param norm = 3.6782e-01, time/batch = 0.6819s	
749/29900 (epoch 1.253), train_loss = 2.47576789, grad/param norm = 2.4580e-01, time/batch = 0.6797s	
750/29900 (epoch 1.254), train_loss = 2.45176387, grad/param norm = 2.5039e-01, time/batch = 0.6830s	
751/29900 (epoch 1.256), train_loss = 2.44633207, grad/param norm = 3.2802e-01, time/batch = 0.6843s	
752/29900 (epoch 1.258), train_loss = 2.46511293, grad/param norm = 2.7088e-01, time/batch = 0.6848s	
753/29900 (epoch 1.259), train_loss = 2.50474132, grad/param norm = 3.1561e-01, time/batch = 0.6806s	
754/29900 (epoch 1.261), train_loss = 2.44379735, grad/param norm = 3.4314e-01, time/batch = 0.6810s	
755/29900 (epoch 1.263), train_loss = 2.58920163, grad/param norm = 3.8980e-01, time/batch = 0.6817s	
756/29900 (epoch 1.264), train_loss = 2.37426368, grad/param norm = 4.2027e-01, time/batch = 0.6834s	
757/29900 (epoch 1.266), train_loss = 2.43762318, grad/param norm = 2.8590e-01, time/batch = 0.6966s	
758/29900 (epoch 1.268), train_loss = 2.43485191, grad/param norm = 3.2384e-01, time/batch = 0.6863s	
759/29900 (epoch 1.269), train_loss = 2.41299498, grad/param norm = 2.9384e-01, time/batch = 0.6837s	
760/29900 (epoch 1.271), train_loss = 2.36520594, grad/param norm = 2.7968e-01, time/batch = 0.6798s	
761/29900 (epoch 1.273), train_loss = 2.33138779, grad/param norm = 3.2674e-01, time/batch = 0.6826s	
762/29900 (epoch 1.274), train_loss = 2.55368904, grad/param norm = 4.0612e-01, time/batch = 0.6873s	
763/29900 (epoch 1.276), train_loss = 2.47975074, grad/param norm = 2.8711e-01, time/batch = 0.6990s	
764/29900 (epoch 1.278), train_loss = 2.40993618, grad/param norm = 2.7587e-01, time/batch = 0.6870s	
765/29900 (epoch 1.279), train_loss = 2.58797775, grad/param norm = 3.3330e-01, time/batch = 0.6917s	
766/29900 (epoch 1.281), train_loss = 2.41377439, grad/param norm = 2.5355e-01, time/batch = 0.7030s	
767/29900 (epoch 1.283), train_loss = 2.52695490, grad/param norm = 2.7449e-01, time/batch = 0.6888s	
768/29900 (epoch 1.284), train_loss = 2.48505319, grad/param norm = 2.8578e-01, time/batch = 0.6994s	
769/29900 (epoch 1.286), train_loss = 2.71326432, grad/param norm = 2.6283e-01, time/batch = 0.7250s	
770/29900 (epoch 1.288), train_loss = 3.58722801, grad/param norm = 8.5158e-01, time/batch = 0.6938s	
771/29900 (epoch 1.289), train_loss = 3.04463017, grad/param norm = 6.4494e-01, time/batch = 0.6958s	
772/29900 (epoch 1.291), train_loss = 2.89175913, grad/param norm = 5.5327e-01, time/batch = 0.6879s	
773/29900 (epoch 1.293), train_loss = 2.32946804, grad/param norm = 3.6265e-01, time/batch = 0.6881s	
774/29900 (epoch 1.294), train_loss = 2.39463297, grad/param norm = 5.8700e-01, time/batch = 0.6867s	
775/29900 (epoch 1.296), train_loss = 2.19770038, grad/param norm = 3.4073e-01, time/batch = 0.6831s	
776/29900 (epoch 1.298), train_loss = 2.33425197, grad/param norm = 3.0905e-01, time/batch = 0.6858s	
777/29900 (epoch 1.299), train_loss = 2.35078973, grad/param norm = 2.8598e-01, time/batch = 0.6837s	
778/29900 (epoch 1.301), train_loss = 2.33799694, grad/param norm = 2.5080e-01, time/batch = 0.6870s	
779/29900 (epoch 1.303), train_loss = 2.68658721, grad/param norm = 4.1424e-01, time/batch = 0.6888s	
780/29900 (epoch 1.304), train_loss = 2.37701826, grad/param norm = 4.7456e-01, time/batch = 0.6921s	
781/29900 (epoch 1.306), train_loss = 2.40221507, grad/param norm = 3.7434e-01, time/batch = 0.6888s	
782/29900 (epoch 1.308), train_loss = 2.32444083, grad/param norm = 2.8844e-01, time/batch = 0.6851s	
783/29900 (epoch 1.309), train_loss = 2.28104071, grad/param norm = 2.6266e-01, time/batch = 0.6825s	
784/29900 (epoch 1.311), train_loss = 2.34673833, grad/param norm = 2.7803e-01, time/batch = 0.6819s	
785/29900 (epoch 1.313), train_loss = 2.56234099, grad/param norm = 2.8839e-01, time/batch = 0.6829s	
786/29900 (epoch 1.314), train_loss = 2.31230215, grad/param norm = 2.6436e-01, time/batch = 0.6824s	
787/29900 (epoch 1.316), train_loss = 2.56672912, grad/param norm = 3.2637e-01, time/batch = 0.7089s	
788/29900 (epoch 1.318), train_loss = 2.40202510, grad/param norm = 2.7776e-01, time/batch = 0.7183s	
789/29900 (epoch 1.319), train_loss = 2.40646495, grad/param norm = 2.4831e-01, time/batch = 0.6860s	
790/29900 (epoch 1.321), train_loss = 2.52265988, grad/param norm = 2.7693e-01, time/batch = 0.6843s	
791/29900 (epoch 1.323), train_loss = 2.33438424, grad/param norm = 2.7529e-01, time/batch = 0.6984s	
792/29900 (epoch 1.324), train_loss = 2.35804580, grad/param norm = 3.1986e-01, time/batch = 0.7258s	
793/29900 (epoch 1.326), train_loss = 2.33673685, grad/param norm = 3.9956e-01, time/batch = 0.6854s	
794/29900 (epoch 1.328), train_loss = 2.45568311, grad/param norm = 4.0754e-01, time/batch = 0.6840s	
795/29900 (epoch 1.329), train_loss = 2.49476220, grad/param norm = 3.1405e-01, time/batch = 0.6855s	
796/29900 (epoch 1.331), train_loss = 2.55811252, grad/param norm = 2.6933e-01, time/batch = 0.6857s	
797/29900 (epoch 1.333), train_loss = 2.51166679, grad/param norm = 2.8876e-01, time/batch = 0.6861s	
798/29900 (epoch 1.334), train_loss = 2.47945533, grad/param norm = 2.7035e-01, time/batch = 0.6828s	
799/29900 (epoch 1.336), train_loss = 2.25931719, grad/param norm = 2.4508e-01, time/batch = 0.6832s	
800/29900 (epoch 1.338), train_loss = 2.48493936, grad/param norm = 3.1311e-01, time/batch = 0.6824s	
801/29900 (epoch 1.339), train_loss = 2.52227140, grad/param norm = 3.4702e-01, time/batch = 0.6853s	
802/29900 (epoch 1.341), train_loss = 2.35095015, grad/param norm = 3.0225e-01, time/batch = 0.6849s	
803/29900 (epoch 1.343), train_loss = 2.49443465, grad/param norm = 3.0416e-01, time/batch = 0.6839s	
804/29900 (epoch 1.344), train_loss = 2.31477408, grad/param norm = 2.7217e-01, time/batch = 0.6865s	
805/29900 (epoch 1.346), train_loss = 2.29113253, grad/param norm = 2.7449e-01, time/batch = 0.6895s	
806/29900 (epoch 1.348), train_loss = 2.27351173, grad/param norm = 2.8088e-01, time/batch = 0.7227s	
807/29900 (epoch 1.349), train_loss = 2.51203252, grad/param norm = 2.9916e-01, time/batch = 0.7081s	
808/29900 (epoch 1.351), train_loss = 2.41602117, grad/param norm = 4.1447e-01, time/batch = 0.7063s	
809/29900 (epoch 1.353), train_loss = 2.36603616, grad/param norm = 3.2416e-01, time/batch = 0.6988s	
810/29900 (epoch 1.355), train_loss = 2.31439153, grad/param norm = 2.7046e-01, time/batch = 0.6993s	
811/29900 (epoch 1.356), train_loss = 2.37022627, grad/param norm = 3.0730e-01, time/batch = 0.6901s	
812/29900 (epoch 1.358), train_loss = 2.40245575, grad/param norm = 2.9152e-01, time/batch = 0.7092s	
813/29900 (epoch 1.360), train_loss = 2.49959796, grad/param norm = 2.3610e-01, time/batch = 0.6997s	
814/29900 (epoch 1.361), train_loss = 2.62729945, grad/param norm = 2.6415e-01, time/batch = 0.6849s	
815/29900 (epoch 1.363), train_loss = 2.36538851, grad/param norm = 3.1350e-01, time/batch = 0.6863s	
816/29900 (epoch 1.365), train_loss = 2.31888016, grad/param norm = 2.7084e-01, time/batch = 0.6813s	
817/29900 (epoch 1.366), train_loss = 2.23937435, grad/param norm = 2.5346e-01, time/batch = 0.6841s	
818/29900 (epoch 1.368), train_loss = 2.17395995, grad/param norm = 2.4143e-01, time/batch = 0.6828s	
819/29900 (epoch 1.370), train_loss = 2.37090116, grad/param norm = 2.4705e-01, time/batch = 0.6852s	
820/29900 (epoch 1.371), train_loss = 2.49025150, grad/param norm = 2.6388e-01, time/batch = 0.6826s	
821/29900 (epoch 1.373), train_loss = 2.38672698, grad/param norm = 3.3091e-01, time/batch = 0.6858s	
822/29900 (epoch 1.375), train_loss = 2.52941046, grad/param norm = 2.8689e-01, time/batch = 0.6883s	
823/29900 (epoch 1.376), train_loss = 2.55026564, grad/param norm = 2.6150e-01, time/batch = 0.6872s	
824/29900 (epoch 1.378), train_loss = 2.39764312, grad/param norm = 3.1542e-01, time/batch = 0.6936s	
825/29900 (epoch 1.380), train_loss = 2.43131780, grad/param norm = 2.9302e-01, time/batch = 0.7254s	
826/29900 (epoch 1.381), train_loss = 2.56826883, grad/param norm = 3.1613e-01, time/batch = 0.6904s	
827/29900 (epoch 1.383), train_loss = 2.17422173, grad/param norm = 3.3046e-01, time/batch = 0.6827s	
828/29900 (epoch 1.385), train_loss = 2.31749791, grad/param norm = 3.3730e-01, time/batch = 0.6811s	
829/29900 (epoch 1.386), train_loss = 2.28683244, grad/param norm = 3.7549e-01, time/batch = 0.6823s	
830/29900 (epoch 1.388), train_loss = 2.46960922, grad/param norm = 2.4572e-01, time/batch = 0.6832s	
831/29900 (epoch 1.390), train_loss = 2.40853418, grad/param norm = 2.9229e-01, time/batch = 0.6844s	
832/29900 (epoch 1.391), train_loss = 2.34737539, grad/param norm = 2.9129e-01, time/batch = 0.6840s	
833/29900 (epoch 1.393), train_loss = 2.41366576, grad/param norm = 3.0504e-01, time/batch = 0.6865s	
834/29900 (epoch 1.395), train_loss = 2.24276432, grad/param norm = 3.5758e-01, time/batch = 0.6847s	
835/29900 (epoch 1.396), train_loss = 2.50062465, grad/param norm = 2.8257e-01, time/batch = 0.6845s	
836/29900 (epoch 1.398), train_loss = 2.47231769, grad/param norm = 2.5337e-01, time/batch = 0.6828s	
837/29900 (epoch 1.400), train_loss = 2.48628798, grad/param norm = 2.8059e-01, time/batch = 0.6835s	
838/29900 (epoch 1.401), train_loss = 2.46278783, grad/param norm = 2.5546e-01, time/batch = 0.6830s	
839/29900 (epoch 1.403), train_loss = 2.53360934, grad/param norm = 3.2804e-01, time/batch = 0.6835s	
840/29900 (epoch 1.405), train_loss = 2.37363803, grad/param norm = 4.1711e-01, time/batch = 0.6824s	
841/29900 (epoch 1.406), train_loss = 2.26517331, grad/param norm = 3.8616e-01, time/batch = 0.6845s	
842/29900 (epoch 1.408), train_loss = 2.16964126, grad/param norm = 3.5501e-01, time/batch = 0.6858s	
843/29900 (epoch 1.410), train_loss = 2.51128596, grad/param norm = 3.9134e-01, time/batch = 0.6855s	
844/29900 (epoch 1.411), train_loss = 2.55329606, grad/param norm = 3.3433e-01, time/batch = 0.6833s	
845/29900 (epoch 1.413), train_loss = 2.41349885, grad/param norm = 2.7431e-01, time/batch = 0.6889s	
846/29900 (epoch 1.415), train_loss = 2.32759973, grad/param norm = 2.9066e-01, time/batch = 0.6837s	
847/29900 (epoch 1.416), train_loss = 2.35313957, grad/param norm = 2.3674e-01, time/batch = 0.6842s	
848/29900 (epoch 1.418), train_loss = 2.18747824, grad/param norm = 2.5598e-01, time/batch = 0.7249s	
849/29900 (epoch 1.420), train_loss = 2.50177090, grad/param norm = 2.6146e-01, time/batch = 0.7118s	
850/29900 (epoch 1.421), train_loss = 2.54869370, grad/param norm = 2.7111e-01, time/batch = 0.7056s	
851/29900 (epoch 1.423), train_loss = 2.38102059, grad/param norm = 2.4244e-01, time/batch = 0.7184s	
852/29900 (epoch 1.425), train_loss = 2.33084233, grad/param norm = 2.7516e-01, time/batch = 0.7110s	
853/29900 (epoch 1.426), train_loss = 2.30061907, grad/param norm = 2.9130e-01, time/batch = 0.6972s	
854/29900 (epoch 1.428), train_loss = 2.42785805, grad/param norm = 3.1672e-01, time/batch = 0.6851s	
855/29900 (epoch 1.430), train_loss = 2.38295212, grad/param norm = 2.5337e-01, time/batch = 0.6925s	
856/29900 (epoch 1.431), train_loss = 2.38169184, grad/param norm = 2.3621e-01, time/batch = 0.6867s	
857/29900 (epoch 1.433), train_loss = 2.35375087, grad/param norm = 2.8659e-01, time/batch = 0.6889s	
858/29900 (epoch 1.435), train_loss = 2.38345161, grad/param norm = 2.7155e-01, time/batch = 0.6909s	
859/29900 (epoch 1.436), train_loss = 2.22677282, grad/param norm = 3.2667e-01, time/batch = 0.6873s	
860/29900 (epoch 1.438), train_loss = 2.21778814, grad/param norm = 3.0965e-01, time/batch = 0.6874s	
861/29900 (epoch 1.440), train_loss = 2.29027775, grad/param norm = 2.8898e-01, time/batch = 0.6969s	
862/29900 (epoch 1.441), train_loss = 2.29181984, grad/param norm = 3.0601e-01, time/batch = 0.7177s	
863/29900 (epoch 1.443), train_loss = 2.43649615, grad/param norm = 2.7116e-01, time/batch = 0.7099s	
864/29900 (epoch 1.445), train_loss = 2.41402158, grad/param norm = 2.2961e-01, time/batch = 0.6927s	
865/29900 (epoch 1.446), train_loss = 2.19761130, grad/param norm = 2.6065e-01, time/batch = 0.7021s	
866/29900 (epoch 1.448), train_loss = 2.40319714, grad/param norm = 3.3966e-01, time/batch = 0.6820s	
867/29900 (epoch 1.450), train_loss = 2.31534342, grad/param norm = 2.5590e-01, time/batch = 0.6813s	
868/29900 (epoch 1.452), train_loss = 2.38643179, grad/param norm = 2.5124e-01, time/batch = 0.6839s	
869/29900 (epoch 1.453), train_loss = 2.45203327, grad/param norm = 3.0780e-01, time/batch = 0.6805s	
870/29900 (epoch 1.455), train_loss = 2.39243063, grad/param norm = 3.2446e-01, time/batch = 0.6805s	
871/29900 (epoch 1.457), train_loss = 2.23650921, grad/param norm = 2.5049e-01, time/batch = 0.6850s	
872/29900 (epoch 1.458), train_loss = 2.36260527, grad/param norm = 2.8477e-01, time/batch = 0.6896s	
873/29900 (epoch 1.460), train_loss = 2.25712811, grad/param norm = 3.0524e-01, time/batch = 0.6845s	
874/29900 (epoch 1.462), train_loss = 2.20686438, grad/param norm = 2.5792e-01, time/batch = 0.6811s	
875/29900 (epoch 1.463), train_loss = 2.06227634, grad/param norm = 2.1719e-01, time/batch = 0.6881s	
876/29900 (epoch 1.465), train_loss = 2.44816005, grad/param norm = 2.4812e-01, time/batch = 0.6855s	
877/29900 (epoch 1.467), train_loss = 2.49250863, grad/param norm = 2.8966e-01, time/batch = 0.6840s	
878/29900 (epoch 1.468), train_loss = 2.67003930, grad/param norm = 2.9740e-01, time/batch = 0.6821s	
879/29900 (epoch 1.470), train_loss = 2.34722982, grad/param norm = 2.4418e-01, time/batch = 0.6816s	
880/29900 (epoch 1.472), train_loss = 2.29831427, grad/param norm = 2.8997e-01, time/batch = 0.6850s	
881/29900 (epoch 1.473), train_loss = 2.31196122, grad/param norm = 3.5172e-01, time/batch = 0.7268s	
882/29900 (epoch 1.475), train_loss = 2.32432574, grad/param norm = 2.5635e-01, time/batch = 0.7021s	
883/29900 (epoch 1.477), train_loss = 2.38348800, grad/param norm = 2.6047e-01, time/batch = 0.6900s	
884/29900 (epoch 1.478), train_loss = 2.39874661, grad/param norm = 2.4759e-01, time/batch = 0.6813s	
885/29900 (epoch 1.480), train_loss = 2.28630608, grad/param norm = 2.6678e-01, time/batch = 0.6812s	
886/29900 (epoch 1.482), train_loss = 2.35099513, grad/param norm = 2.5881e-01, time/batch = 0.6828s	
887/29900 (epoch 1.483), train_loss = 2.36843595, grad/param norm = 2.8250e-01, time/batch = 0.6881s	
888/29900 (epoch 1.485), train_loss = 2.46670028, grad/param norm = 3.1824e-01, time/batch = 0.6859s	
889/29900 (epoch 1.487), train_loss = 2.22003591, grad/param norm = 2.8265e-01, time/batch = 0.6814s	
890/29900 (epoch 1.488), train_loss = 2.34257042, grad/param norm = 3.8116e-01, time/batch = 0.6806s	
891/29900 (epoch 1.490), train_loss = 2.24654700, grad/param norm = 3.0467e-01, time/batch = 0.6819s	
892/29900 (epoch 1.492), train_loss = 2.41377399, grad/param norm = 3.2516e-01, time/batch = 0.6817s	
893/29900 (epoch 1.493), train_loss = 2.29273720, grad/param norm = 2.4527e-01, time/batch = 0.6887s	
894/29900 (epoch 1.495), train_loss = 2.30047551, grad/param norm = 2.4162e-01, time/batch = 0.6871s	
895/29900 (epoch 1.497), train_loss = 2.32814192, grad/param norm = 2.5284e-01, time/batch = 0.6853s	
896/29900 (epoch 1.498), train_loss = 2.31460427, grad/param norm = 2.7742e-01, time/batch = 0.6820s	
897/29900 (epoch 1.500), train_loss = 2.51414737, grad/param norm = 2.8389e-01, time/batch = 0.6833s	
898/29900 (epoch 1.502), train_loss = 2.44316598, grad/param norm = 2.7306e-01, time/batch = 0.6805s	
899/29900 (epoch 1.503), train_loss = 2.33567560, grad/param norm = 2.5969e-01, time/batch = 0.6931s	
900/29900 (epoch 1.505), train_loss = 2.18908357, grad/param norm = 2.8986e-01, time/batch = 0.6864s	
901/29900 (epoch 1.507), train_loss = 2.36748252, grad/param norm = 3.7909e-01, time/batch = 0.6868s	
902/29900 (epoch 1.508), train_loss = 2.27021205, grad/param norm = 3.7996e-01, time/batch = 0.7103s	
903/29900 (epoch 1.510), train_loss = 2.21597032, grad/param norm = 2.6855e-01, time/batch = 0.6890s	
904/29900 (epoch 1.512), train_loss = 2.46945954, grad/param norm = 2.9992e-01, time/batch = 0.7220s	
905/29900 (epoch 1.513), train_loss = 2.50622690, grad/param norm = 3.1240e-01, time/batch = 0.7082s	
906/29900 (epoch 1.515), train_loss = 2.22781657, grad/param norm = 2.4756e-01, time/batch = 0.6952s	
907/29900 (epoch 1.517), train_loss = 2.31452186, grad/param norm = 2.5899e-01, time/batch = 0.7180s	
908/29900 (epoch 1.518), train_loss = 2.24686526, grad/param norm = 2.5112e-01, time/batch = 0.7134s	
909/29900 (epoch 1.520), train_loss = 2.40998645, grad/param norm = 2.8586e-01, time/batch = 0.7012s	
910/29900 (epoch 1.522), train_loss = 2.35251875, grad/param norm = 2.9477e-01, time/batch = 0.6906s	
911/29900 (epoch 1.523), train_loss = 2.35133277, grad/param norm = 2.4407e-01, time/batch = 0.6832s	
912/29900 (epoch 1.525), train_loss = 2.23361732, grad/param norm = 3.4056e-01, time/batch = 0.6829s	
913/29900 (epoch 1.527), train_loss = 2.35012711, grad/param norm = 3.7347e-01, time/batch = 0.6806s	
914/29900 (epoch 1.528), train_loss = 2.34183860, grad/param norm = 2.8258e-01, time/batch = 0.6813s	
915/29900 (epoch 1.530), train_loss = 2.44289767, grad/param norm = 2.8501e-01, time/batch = 0.6812s	
916/29900 (epoch 1.532), train_loss = 2.36455802, grad/param norm = 2.8849e-01, time/batch = 0.6817s	
917/29900 (epoch 1.533), train_loss = 2.30687283, grad/param norm = 3.1115e-01, time/batch = 0.6825s	
918/29900 (epoch 1.535), train_loss = 2.33599771, grad/param norm = 3.9681e-01, time/batch = 0.6850s	
919/29900 (epoch 1.537), train_loss = 2.21637137, grad/param norm = 3.1540e-01, time/batch = 0.6813s	
920/29900 (epoch 1.538), train_loss = 2.30080729, grad/param norm = 3.0696e-01, time/batch = 0.6812s	
921/29900 (epoch 1.540), train_loss = 2.28312813, grad/param norm = 2.8937e-01, time/batch = 0.6839s	
922/29900 (epoch 1.542), train_loss = 2.30527562, grad/param norm = 2.4362e-01, time/batch = 0.6892s	
923/29900 (epoch 1.543), train_loss = 2.43358446, grad/param norm = 2.2803e-01, time/batch = 0.7253s	
924/29900 (epoch 1.545), train_loss = 2.45984880, grad/param norm = 2.7848e-01, time/batch = 0.6921s	
925/29900 (epoch 1.547), train_loss = 2.42315262, grad/param norm = 2.7941e-01, time/batch = 0.6842s	
926/29900 (epoch 1.548), train_loss = 2.38066004, grad/param norm = 3.5542e-01, time/batch = 0.6828s	
927/29900 (epoch 1.550), train_loss = 2.19413527, grad/param norm = 3.8960e-01, time/batch = 0.6826s	
928/29900 (epoch 1.552), train_loss = 2.24454290, grad/param norm = 3.4227e-01, time/batch = 0.6816s	
929/29900 (epoch 1.554), train_loss = 2.45391289, grad/param norm = 2.9208e-01, time/batch = 0.6806s	
930/29900 (epoch 1.555), train_loss = 2.40921171, grad/param norm = 2.4312e-01, time/batch = 0.6840s	
931/29900 (epoch 1.557), train_loss = 2.49355199, grad/param norm = 2.4595e-01, time/batch = 0.6834s	
932/29900 (epoch 1.559), train_loss = 2.28776251, grad/param norm = 2.2900e-01, time/batch = 0.6822s	
933/29900 (epoch 1.560), train_loss = 2.31341115, grad/param norm = 2.2826e-01, time/batch = 0.6823s	
934/29900 (epoch 1.562), train_loss = 2.25434288, grad/param norm = 2.6904e-01, time/batch = 0.6845s	
935/29900 (epoch 1.564), train_loss = 2.36521937, grad/param norm = 2.9206e-01, time/batch = 0.6842s	
936/29900 (epoch 1.565), train_loss = 2.41844005, grad/param norm = 2.2348e-01, time/batch = 0.7083s	
937/29900 (epoch 1.567), train_loss = 2.36324874, grad/param norm = 2.5867e-01, time/batch = 0.7236s	
938/29900 (epoch 1.569), train_loss = 2.49137165, grad/param norm = 2.3108e-01, time/batch = 0.7185s	
939/29900 (epoch 1.570), train_loss = 2.37840457, grad/param norm = 2.9547e-01, time/batch = 0.7028s	
940/29900 (epoch 1.572), train_loss = 2.16199551, grad/param norm = 2.6459e-01, time/batch = 0.7046s	
941/29900 (epoch 1.574), train_loss = 2.27893190, grad/param norm = 2.9649e-01, time/batch = 0.6918s	
942/29900 (epoch 1.575), train_loss = 2.28362236, grad/param norm = 3.1744e-01, time/batch = 0.6908s	
943/29900 (epoch 1.577), train_loss = 2.42323536, grad/param norm = 2.8051e-01, time/batch = 0.6850s	
944/29900 (epoch 1.579), train_loss = 2.46828752, grad/param norm = 2.4454e-01, time/batch = 0.6852s	
945/29900 (epoch 1.580), train_loss = 2.30533184, grad/param norm = 2.1831e-01, time/batch = 0.6938s	
946/29900 (epoch 1.582), train_loss = 2.34663612, grad/param norm = 5.6972e-01, time/batch = 0.6825s	
947/29900 (epoch 1.584), train_loss = 2.33073003, grad/param norm = 3.7860e-01, time/batch = 0.6805s	
948/29900 (epoch 1.585), train_loss = 2.45392775, grad/param norm = 2.8427e-01, time/batch = 0.6922s	
949/29900 (epoch 1.587), train_loss = 2.33107846, grad/param norm = 2.4564e-01, time/batch = 0.6855s	
950/29900 (epoch 1.589), train_loss = 2.50835675, grad/param norm = 2.7898e-01, time/batch = 0.6857s	
951/29900 (epoch 1.590), train_loss = 2.24788613, grad/param norm = 2.8937e-01, time/batch = 0.6859s	
952/29900 (epoch 1.592), train_loss = 2.34184179, grad/param norm = 2.7338e-01, time/batch = 0.6821s	
953/29900 (epoch 1.594), train_loss = 2.31642684, grad/param norm = 2.8475e-01, time/batch = 0.6818s	
954/29900 (epoch 1.595), train_loss = 2.42780878, grad/param norm = 3.3735e-01, time/batch = 0.6826s	
955/29900 (epoch 1.597), train_loss = 2.28257161, grad/param norm = 2.4484e-01, time/batch = 0.6846s	
956/29900 (epoch 1.599), train_loss = 2.08424902, grad/param norm = 2.2556e-01, time/batch = 0.7242s	
957/29900 (epoch 1.600), train_loss = 2.27825038, grad/param norm = 2.7760e-01, time/batch = 0.6985s	
958/29900 (epoch 1.602), train_loss = 2.36746260, grad/param norm = 3.4438e-01, time/batch = 0.6818s	
959/29900 (epoch 1.604), train_loss = 2.38956958, grad/param norm = 2.5466e-01, time/batch = 0.6807s	
960/29900 (epoch 1.605), train_loss = 2.40948598, grad/param norm = 2.2707e-01, time/batch = 0.6806s	
961/29900 (epoch 1.607), train_loss = 2.28485309, grad/param norm = 2.6798e-01, time/batch = 0.6846s	
962/29900 (epoch 1.609), train_loss = 2.37805882, grad/param norm = 2.6069e-01, time/batch = 0.6823s	
963/29900 (epoch 1.610), train_loss = 2.53816275, grad/param norm = 2.6732e-01, time/batch = 0.6830s	
964/29900 (epoch 1.612), train_loss = 2.45473542, grad/param norm = 2.6958e-01, time/batch = 0.6828s	
965/29900 (epoch 1.614), train_loss = 2.43681655, grad/param norm = 2.7761e-01, time/batch = 0.6799s	
966/29900 (epoch 1.615), train_loss = 2.64928541, grad/param norm = 2.9197e-01, time/batch = 0.6811s	
967/29900 (epoch 1.617), train_loss = 2.33593930, grad/param norm = 2.5406e-01, time/batch = 0.6807s	
968/29900 (epoch 1.619), train_loss = 2.33553236, grad/param norm = 2.9092e-01, time/batch = 0.6798s	
969/29900 (epoch 1.620), train_loss = 2.32661703, grad/param norm = 2.3351e-01, time/batch = 0.6825s	
970/29900 (epoch 1.622), train_loss = 2.34080321, grad/param norm = 3.0573e-01, time/batch = 0.6820s	
971/29900 (epoch 1.624), train_loss = 2.31512167, grad/param norm = 3.1276e-01, time/batch = 0.6850s	
972/29900 (epoch 1.625), train_loss = 2.31644399, grad/param norm = 2.4787e-01, time/batch = 0.6841s	
973/29900 (epoch 1.627), train_loss = 2.06924853, grad/param norm = 2.5190e-01, time/batch = 0.6831s	
974/29900 (epoch 1.629), train_loss = 2.24991630, grad/param norm = 2.4673e-01, time/batch = 0.6823s	
975/29900 (epoch 1.630), train_loss = 2.38715026, grad/param norm = 2.4811e-01, time/batch = 0.6817s	
976/29900 (epoch 1.632), train_loss = 2.40075490, grad/param norm = 2.5528e-01, time/batch = 0.6828s	
977/29900 (epoch 1.634), train_loss = 2.24838282, grad/param norm = 2.9158e-01, time/batch = 0.6812s	
978/29900 (epoch 1.635), train_loss = 2.33556273, grad/param norm = 2.5371e-01, time/batch = 0.6868s	
979/29900 (epoch 1.637), train_loss = 2.41222195, grad/param norm = 2.6318e-01, time/batch = 0.7138s	
980/29900 (epoch 1.639), train_loss = 2.36743501, grad/param norm = 2.7736e-01, time/batch = 0.7111s	
981/29900 (epoch 1.640), train_loss = 2.43438890, grad/param norm = 2.5771e-01, time/batch = 0.6833s	
982/29900 (epoch 1.642), train_loss = 2.42650671, grad/param norm = 2.7287e-01, time/batch = 0.6817s	
983/29900 (epoch 1.644), train_loss = 2.21355497, grad/param norm = 2.5693e-01, time/batch = 0.6829s	
984/29900 (epoch 1.645), train_loss = 2.62049854, grad/param norm = 3.2794e-01, time/batch = 0.6818s	
985/29900 (epoch 1.647), train_loss = 2.25783086, grad/param norm = 2.9948e-01, time/batch = 0.6841s	
986/29900 (epoch 1.649), train_loss = 2.13138437, grad/param norm = 2.6301e-01, time/batch = 0.6858s	
987/29900 (epoch 1.651), train_loss = 2.18709863, grad/param norm = 2.3663e-01, time/batch = 0.6871s	
988/29900 (epoch 1.652), train_loss = 2.14736737, grad/param norm = 2.4913e-01, time/batch = 0.7014s	
989/29900 (epoch 1.654), train_loss = 2.36178377, grad/param norm = 3.7730e-01, time/batch = 0.6930s	
990/29900 (epoch 1.656), train_loss = 2.36808053, grad/param norm = 2.9162e-01, time/batch = 0.6842s	
991/29900 (epoch 1.657), train_loss = 2.14931243, grad/param norm = 2.1281e-01, time/batch = 0.6839s	
992/29900 (epoch 1.659), train_loss = 2.04127113, grad/param norm = 2.8294e-01, time/batch = 0.6837s	
993/29900 (epoch 1.661), train_loss = 2.50796229, grad/param norm = 3.6085e-01, time/batch = 0.6835s	
994/29900 (epoch 1.662), train_loss = 2.37193712, grad/param norm = 2.6730e-01, time/batch = 0.6862s	
995/29900 (epoch 1.664), train_loss = 2.26965708, grad/param norm = 2.4551e-01, time/batch = 0.6819s	
996/29900 (epoch 1.666), train_loss = 2.11123446, grad/param norm = 2.4681e-01, time/batch = 0.6821s	
997/29900 (epoch 1.667), train_loss = 2.18099523, grad/param norm = 2.7031e-01, time/batch = 0.6807s	
998/29900 (epoch 1.669), train_loss = 2.09119839, grad/param norm = 2.5917e-01, time/batch = 0.7212s	
999/29900 (epoch 1.671), train_loss = 2.26620608, grad/param norm = 2.2984e-01, time/batch = 0.7030s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_dynamicwebpaige_epoch1.67_2.3354.t7	
1000/29900 (epoch 1.672), train_loss = 2.31716048, grad/param norm = 2.3531e-01, time/batch = 0.6849s	
1001/29900 (epoch 1.674), train_loss = 2.30237964, grad/param norm = 2.1942e-01, time/batch = 0.6919s	
1002/29900 (epoch 1.676), train_loss = 2.17143575, grad/param norm = 2.6276e-01, time/batch = 0.6896s	
1003/29900 (epoch 1.677), train_loss = 2.41366590, grad/param norm = 2.8152e-01, time/batch = 0.6866s	
1004/29900 (epoch 1.679), train_loss = 2.45724407, grad/param norm = 2.5958e-01, time/batch = 0.6911s	
1005/29900 (epoch 1.681), train_loss = 2.42568303, grad/param norm = 3.6937e-01, time/batch = 0.6865s	
1006/29900 (epoch 1.682), train_loss = 2.42790477, grad/param norm = 3.2514e-01, time/batch = 0.6836s	
1007/29900 (epoch 1.684), train_loss = 2.40121875, grad/param norm = 2.7309e-01, time/batch = 0.6842s	
1008/29900 (epoch 1.686), train_loss = 2.51118888, grad/param norm = 2.6209e-01, time/batch = 0.6817s	
1009/29900 (epoch 1.687), train_loss = 2.16277084, grad/param norm = 2.5808e-01, time/batch = 0.6820s	
1010/29900 (epoch 1.689), train_loss = 2.29394553, grad/param norm = 2.5998e-01, time/batch = 0.6795s	
1011/29900 (epoch 1.691), train_loss = 2.48058176, grad/param norm = 2.4699e-01, time/batch = 0.6840s	
1012/29900 (epoch 1.692), train_loss = 2.49493899, grad/param norm = 2.6629e-01, time/batch = 0.7048s	
1013/29900 (epoch 1.694), train_loss = 2.14252881, grad/param norm = 2.1765e-01, time/batch = 0.7253s	
1014/29900 (epoch 1.696), train_loss = 2.05593607, grad/param norm = 2.4002e-01, time/batch = 0.6974s	
1015/29900 (epoch 1.697), train_loss = 2.34433579, grad/param norm = 2.5417e-01, time/batch = 0.6944s	
1016/29900 (epoch 1.699), train_loss = 2.13975111, grad/param norm = 2.6553e-01, time/batch = 0.7008s	
1017/29900 (epoch 1.701), train_loss = 2.23938201, grad/param norm = 2.5055e-01, time/batch = 0.7035s	
1018/29900 (epoch 1.702), train_loss = 2.28540514, grad/param norm = 2.2627e-01, time/batch = 0.6850s	
1019/29900 (epoch 1.704), train_loss = 2.20382606, grad/param norm = 2.5032e-01, time/batch = 0.6827s	
1020/29900 (epoch 1.706), train_loss = 2.09684458, grad/param norm = 2.2291e-01, time/batch = 0.6835s	
1021/29900 (epoch 1.707), train_loss = 2.37514621, grad/param norm = 2.5498e-01, time/batch = 0.6949s	
1022/29900 (epoch 1.709), train_loss = 2.36757098, grad/param norm = 2.4099e-01, time/batch = 0.6878s	
1023/29900 (epoch 1.711), train_loss = 2.24678359, grad/param norm = 2.5573e-01, time/batch = 0.6871s	
1024/29900 (epoch 1.712), train_loss = 2.14191782, grad/param norm = 2.6855e-01, time/batch = 0.6892s	
1025/29900 (epoch 1.714), train_loss = 2.31431749, grad/param norm = 3.0907e-01, time/batch = 0.6913s	
1026/29900 (epoch 1.716), train_loss = 2.25997096, grad/param norm = 3.0520e-01, time/batch = 0.6873s	
1027/29900 (epoch 1.717), train_loss = 2.18550361, grad/param norm = 2.3406e-01, time/batch = 0.6826s	
1028/29900 (epoch 1.719), train_loss = 2.10741179, grad/param norm = 2.3191e-01, time/batch = 0.6832s	
1029/29900 (epoch 1.721), train_loss = 2.37435123, grad/param norm = 2.5734e-01, time/batch = 0.6834s	
1030/29900 (epoch 1.722), train_loss = 2.40161579, grad/param norm = 2.3752e-01, time/batch = 0.6910s	
1031/29900 (epoch 1.724), train_loss = 2.38288833, grad/param norm = 3.0910e-01, time/batch = 0.7149s	
1032/29900 (epoch 1.726), train_loss = 2.28330709, grad/param norm = 3.0743e-01, time/batch = 0.6966s	
1033/29900 (epoch 1.727), train_loss = 2.17603329, grad/param norm = 2.3358e-01, time/batch = 0.6983s	
1034/29900 (epoch 1.729), train_loss = 2.27223300, grad/param norm = 2.6432e-01, time/batch = 0.6884s	
1035/29900 (epoch 1.731), train_loss = 2.19148102, grad/param norm = 2.6981e-01, time/batch = 0.6873s	
1036/29900 (epoch 1.732), train_loss = 2.39581086, grad/param norm = 3.3481e-01, time/batch = 0.6835s	
1037/29900 (epoch 1.734), train_loss = 2.44559939, grad/param norm = 4.3176e-01, time/batch = 0.6825s	
1038/29900 (epoch 1.736), train_loss = 2.44364892, grad/param norm = 3.3116e-01, time/batch = 0.6841s	
1039/29900 (epoch 1.737), train_loss = 2.21625646, grad/param norm = 2.6464e-01, time/batch = 0.6884s	
1040/29900 (epoch 1.739), train_loss = 2.46215647, grad/param norm = 3.0759e-01, time/batch = 0.6954s	
1041/29900 (epoch 1.741), train_loss = 2.11425632, grad/param norm = 2.3532e-01, time/batch = 0.6966s	
1042/29900 (epoch 1.742), train_loss = 2.13066263, grad/param norm = 2.4062e-01, time/batch = 0.6897s	
1043/29900 (epoch 1.744), train_loss = 2.11288401, grad/param norm = 2.5824e-01, time/batch = 0.6850s	
1044/29900 (epoch 1.746), train_loss = 2.18846475, grad/param norm = 2.6111e-01, time/batch = 0.6835s	
1045/29900 (epoch 1.747), train_loss = 2.43274564, grad/param norm = 2.7264e-01, time/batch = 0.6836s	
1046/29900 (epoch 1.749), train_loss = 2.19368702, grad/param norm = 2.3060e-01, time/batch = 0.6867s	
1047/29900 (epoch 1.751), train_loss = 2.37051885, grad/param norm = 2.7644e-01, time/batch = 0.6848s	
1048/29900 (epoch 1.753), train_loss = 2.46975130, grad/param norm = 2.7541e-01, time/batch = 0.6839s	
1049/29900 (epoch 1.754), train_loss = 2.20375112, grad/param norm = 2.7486e-01, time/batch = 0.6833s	
1050/29900 (epoch 1.756), train_loss = 2.29811021, grad/param norm = 2.3546e-01, time/batch = 0.6817s	
1051/29900 (epoch 1.758), train_loss = 2.39221546, grad/param norm = 3.0977e-01, time/batch = 0.6841s	
1052/29900 (epoch 1.759), train_loss = 2.34920333, grad/param norm = 2.7523e-01, time/batch = 0.6838s	
1053/29900 (epoch 1.761), train_loss = 2.30802364, grad/param norm = 2.3060e-01, time/batch = 0.6829s	
1054/29900 (epoch 1.763), train_loss = 2.28528428, grad/param norm = 2.1892e-01, time/batch = 0.7116s	
1055/29900 (epoch 1.764), train_loss = 2.25740703, grad/param norm = 2.0981e-01, time/batch = 0.6879s	
1056/29900 (epoch 1.766), train_loss = 2.24412424, grad/param norm = 2.8525e-01, time/batch = 0.6806s	
1057/29900 (epoch 1.768), train_loss = 2.19042696, grad/param norm = 2.4962e-01, time/batch = 0.6829s	
1058/29900 (epoch 1.769), train_loss = 2.29378808, grad/param norm = 2.6284e-01, time/batch = 0.6824s	
1059/29900 (epoch 1.771), train_loss = 2.25232036, grad/param norm = 2.5721e-01, time/batch = 0.6820s	
1060/29900 (epoch 1.773), train_loss = 2.31543064, grad/param norm = 2.6129e-01, time/batch = 0.6827s	
1061/29900 (epoch 1.774), train_loss = 2.21367601, grad/param norm = 2.3944e-01, time/batch = 0.6848s	
1062/29900 (epoch 1.776), train_loss = 2.08966668, grad/param norm = 2.4037e-01, time/batch = 0.6839s	
1063/29900 (epoch 1.778), train_loss = 2.30399274, grad/param norm = 2.5819e-01, time/batch = 0.6828s	
1064/29900 (epoch 1.779), train_loss = 2.36204925, grad/param norm = 2.5241e-01, time/batch = 0.6856s	
1065/29900 (epoch 1.781), train_loss = 2.09065707, grad/param norm = 2.5556e-01, time/batch = 0.6831s	
1066/29900 (epoch 1.783), train_loss = 2.29385836, grad/param norm = 2.4938e-01, time/batch = 0.6831s	
1067/29900 (epoch 1.784), train_loss = 2.24362324, grad/param norm = 2.5356e-01, time/batch = 0.6875s	
1068/29900 (epoch 1.786), train_loss = 2.35254685, grad/param norm = 2.4353e-01, time/batch = 0.6828s	
1069/29900 (epoch 1.788), train_loss = 2.34670057, grad/param norm = 2.5612e-01, time/batch = 0.6832s	
1070/29900 (epoch 1.789), train_loss = 2.24436362, grad/param norm = 3.0547e-01, time/batch = 0.6831s	
1071/29900 (epoch 1.791), train_loss = 2.16011633, grad/param norm = 2.4911e-01, time/batch = 0.6836s	
1072/29900 (epoch 1.793), train_loss = 2.09999088, grad/param norm = 2.2877e-01, time/batch = 0.6837s	
1073/29900 (epoch 1.794), train_loss = 2.28198857, grad/param norm = 2.1431e-01, time/batch = 0.6826s	
1074/29900 (epoch 1.796), train_loss = 2.32369010, grad/param norm = 2.5505e-01, time/batch = 0.6833s	
1075/29900 (epoch 1.798), train_loss = 2.27255862, grad/param norm = 2.3629e-01, time/batch = 0.6945s	
1076/29900 (epoch 1.799), train_loss = 2.21035755, grad/param norm = 2.3438e-01, time/batch = 0.6913s	
1077/29900 (epoch 1.801), train_loss = 2.28127167, grad/param norm = 3.1886e-01, time/batch = 0.7094s	
1078/29900 (epoch 1.803), train_loss = 2.37295026, grad/param norm = 4.0026e-01, time/batch = 0.7082s	
1079/29900 (epoch 1.804), train_loss = 2.45480633, grad/param norm = 2.8189e-01, time/batch = 0.6970s	
1080/29900 (epoch 1.806), train_loss = 2.13504129, grad/param norm = 2.7733e-01, time/batch = 0.6883s	
1081/29900 (epoch 1.808), train_loss = 2.32528190, grad/param norm = 2.7662e-01, time/batch = 0.6947s	
1082/29900 (epoch 1.809), train_loss = 2.32864500, grad/param norm = 2.5970e-01, time/batch = 0.6875s	
1083/29900 (epoch 1.811), train_loss = 2.27186841, grad/param norm = 2.2948e-01, time/batch = 0.6902s	
1084/29900 (epoch 1.813), train_loss = 2.48251131, grad/param norm = 2.2947e-01, time/batch = 0.6913s	
1085/29900 (epoch 1.814), train_loss = 2.42900454, grad/param norm = 2.5374e-01, time/batch = 0.6950s	
1086/29900 (epoch 1.816), train_loss = 2.60850453, grad/param norm = 2.7440e-01, time/batch = 0.6843s	
1087/29900 (epoch 1.818), train_loss = 2.40749623, grad/param norm = 2.8121e-01, time/batch = 0.6819s	
1088/29900 (epoch 1.819), train_loss = 2.59488112, grad/param norm = 2.4252e-01, time/batch = 0.6817s	
1089/29900 (epoch 1.821), train_loss = 2.29849164, grad/param norm = 2.2951e-01, time/batch = 0.6823s	
1090/29900 (epoch 1.823), train_loss = 2.30125063, grad/param norm = 2.3630e-01, time/batch = 0.6841s	
1091/29900 (epoch 1.824), train_loss = 2.44326180, grad/param norm = 2.7588e-01, time/batch = 0.6848s	
1092/29900 (epoch 1.826), train_loss = 2.41160345, grad/param norm = 2.9848e-01, time/batch = 0.6859s	
1093/29900 (epoch 1.828), train_loss = 2.27826763, grad/param norm = 2.6019e-01, time/batch = 0.6872s	
1094/29900 (epoch 1.829), train_loss = 2.33847324, grad/param norm = 2.5177e-01, time/batch = 0.6900s	
1095/29900 (epoch 1.831), train_loss = 2.38188298, grad/param norm = 2.6732e-01, time/batch = 0.6868s	
1096/29900 (epoch 1.833), train_loss = 2.24271017, grad/param norm = 2.3376e-01, time/batch = 0.7135s	
1097/29900 (epoch 1.834), train_loss = 2.20071841, grad/param norm = 2.4278e-01, time/batch = 0.7127s	
1098/29900 (epoch 1.836), train_loss = 2.37491598, grad/param norm = 2.4582e-01, time/batch = 0.6831s	
1099/29900 (epoch 1.838), train_loss = 2.37617562, grad/param norm = 3.0631e-01, time/batch = 0.6836s	
1100/29900 (epoch 1.839), train_loss = 2.21432669, grad/param norm = 3.4554e-01, time/batch = 0.6945s	
1101/29900 (epoch 1.841), train_loss = 2.51670843, grad/param norm = 3.7695e-01, time/batch = 0.7087s	
1102/29900 (epoch 1.843), train_loss = 2.32934804, grad/param norm = 4.0845e-01, time/batch = 0.7015s	
1103/29900 (epoch 1.844), train_loss = 2.22459690, grad/param norm = 2.5731e-01, time/batch = 0.7220s	
1104/29900 (epoch 1.846), train_loss = 2.18483728, grad/param norm = 2.3033e-01, time/batch = 0.6999s	
1105/29900 (epoch 1.848), train_loss = 2.24666449, grad/param norm = 2.0921e-01, time/batch = 0.6875s	
1106/29900 (epoch 1.849), train_loss = 2.33815283, grad/param norm = 2.6751e-01, time/batch = 0.6867s	
1107/29900 (epoch 1.851), train_loss = 2.34992189, grad/param norm = 2.9351e-01, time/batch = 0.6897s	
1108/29900 (epoch 1.853), train_loss = 2.26586841, grad/param norm = 2.9468e-01, time/batch = 0.6913s	
1109/29900 (epoch 1.855), train_loss = 2.22072028, grad/param norm = 2.4945e-01, time/batch = 0.6833s	
1110/29900 (epoch 1.856), train_loss = 2.26205071, grad/param norm = 2.8823e-01, time/batch = 0.7006s	
1111/29900 (epoch 1.858), train_loss = 2.14062593, grad/param norm = 2.3688e-01, time/batch = 0.7247s	
1112/29900 (epoch 1.860), train_loss = 2.04942965, grad/param norm = 2.1978e-01, time/batch = 0.6952s	
1113/29900 (epoch 1.861), train_loss = 2.32228805, grad/param norm = 2.7477e-01, time/batch = 0.6933s	
1114/29900 (epoch 1.863), train_loss = 2.15355305, grad/param norm = 3.2597e-01, time/batch = 0.6983s	
1115/29900 (epoch 1.865), train_loss = 2.01459048, grad/param norm = 2.6343e-01, time/batch = 0.6981s	
1116/29900 (epoch 1.866), train_loss = 2.21915226, grad/param norm = 3.0603e-01, time/batch = 0.6862s	
1117/29900 (epoch 1.868), train_loss = 2.25497172, grad/param norm = 2.9072e-01, time/batch = 0.6835s	
1118/29900 (epoch 1.870), train_loss = 2.44093501, grad/param norm = 2.4348e-01, time/batch = 0.6836s	
1119/29900 (epoch 1.871), train_loss = 2.16530092, grad/param norm = 2.3941e-01, time/batch = 0.6826s	
1120/29900 (epoch 1.873), train_loss = 2.28036342, grad/param norm = 3.0689e-01, time/batch = 0.6819s	
1121/29900 (epoch 1.875), train_loss = 2.30672762, grad/param norm = 2.1480e-01, time/batch = 0.6848s	
1122/29900 (epoch 1.876), train_loss = 2.09667102, grad/param norm = 2.1048e-01, time/batch = 0.6849s	
1123/29900 (epoch 1.878), train_loss = 2.33834823, grad/param norm = 2.2749e-01, time/batch = 0.6852s	
1124/29900 (epoch 1.880), train_loss = 2.04476319, grad/param norm = 2.2185e-01, time/batch = 0.6841s	
1125/29900 (epoch 1.881), train_loss = 2.46215967, grad/param norm = 2.3877e-01, time/batch = 0.6881s	
1126/29900 (epoch 1.883), train_loss = 2.38395328, grad/param norm = 2.5983e-01, time/batch = 0.6827s	
1127/29900 (epoch 1.885), train_loss = 2.46292716, grad/param norm = 2.1891e-01, time/batch = 0.6820s	
1128/29900 (epoch 1.886), train_loss = 2.41154868, grad/param norm = 2.3496e-01, time/batch = 0.6822s	
1129/29900 (epoch 1.888), train_loss = 2.24509310, grad/param norm = 2.3616e-01, time/batch = 0.7102s	
1130/29900 (epoch 1.890), train_loss = 2.18722716, grad/param norm = 2.6321e-01, time/batch = 0.7143s	
1131/29900 (epoch 1.891), train_loss = 2.24889664, grad/param norm = 2.2932e-01, time/batch = 0.6862s	
1132/29900 (epoch 1.893), train_loss = 2.11478345, grad/param norm = 2.1936e-01, time/batch = 0.6826s	
1133/29900 (epoch 1.895), train_loss = 2.21417831, grad/param norm = 2.3987e-01, time/batch = 0.6876s	
1134/29900 (epoch 1.896), train_loss = 2.20849669, grad/param norm = 2.3292e-01, time/batch = 0.6833s	
1135/29900 (epoch 1.898), train_loss = 2.28254654, grad/param norm = 2.3644e-01, time/batch = 0.6848s	
1136/29900 (epoch 1.900), train_loss = 2.29678779, grad/param norm = 2.2496e-01, time/batch = 0.6988s	
1137/29900 (epoch 1.901), train_loss = 2.13527655, grad/param norm = 2.0795e-01, time/batch = 0.6845s	
1138/29900 (epoch 1.903), train_loss = 2.14026391, grad/param norm = 2.9040e-01, time/batch = 0.6837s	
1139/29900 (epoch 1.905), train_loss = 2.30562989, grad/param norm = 3.6068e-01, time/batch = 0.6836s	
1140/29900 (epoch 1.906), train_loss = 2.50723522, grad/param norm = 3.1300e-01, time/batch = 0.6830s	
1141/29900 (epoch 1.908), train_loss = 2.29590999, grad/param norm = 2.6247e-01, time/batch = 0.6841s	
1142/29900 (epoch 1.910), train_loss = 2.20806759, grad/param norm = 2.4939e-01, time/batch = 0.6840s	
1143/29900 (epoch 1.911), train_loss = 2.17415366, grad/param norm = 2.9677e-01, time/batch = 0.6850s	
1144/29900 (epoch 1.913), train_loss = 1.99965419, grad/param norm = 2.0870e-01, time/batch = 0.6842s	
1145/29900 (epoch 1.915), train_loss = 2.26207171, grad/param norm = 2.5675e-01, time/batch = 0.6856s	
1146/29900 (epoch 1.916), train_loss = 2.06237803, grad/param norm = 2.3491e-01, time/batch = 0.6865s	
1147/29900 (epoch 1.918), train_loss = 2.37036543, grad/param norm = 2.6822e-01, time/batch = 0.6807s	
1148/29900 (epoch 1.920), train_loss = 2.54272594, grad/param norm = 2.6367e-01, time/batch = 0.6899s	
1149/29900 (epoch 1.921), train_loss = 2.47775840, grad/param norm = 2.7316e-01, time/batch = 0.6818s	
1150/29900 (epoch 1.923), train_loss = 2.34911402, grad/param norm = 2.1925e-01, time/batch = 0.6824s	
1151/29900 (epoch 1.925), train_loss = 2.17254780, grad/param norm = 2.2493e-01, time/batch = 0.6845s	
1152/29900 (epoch 1.926), train_loss = 2.10859315, grad/param norm = 2.5445e-01, time/batch = 0.7055s	
1153/29900 (epoch 1.928), train_loss = 2.17558658, grad/param norm = 2.4413e-01, time/batch = 0.7201s	
1154/29900 (epoch 1.930), train_loss = 2.18420525, grad/param norm = 2.5606e-01, time/batch = 0.6876s	
1155/29900 (epoch 1.931), train_loss = 2.03567432, grad/param norm = 2.2906e-01, time/batch = 0.6813s	
1156/29900 (epoch 1.933), train_loss = 2.19091165, grad/param norm = 2.1058e-01, time/batch = 0.6804s	
1157/29900 (epoch 1.935), train_loss = 2.54865615, grad/param norm = 2.4148e-01, time/batch = 0.6819s	
1158/29900 (epoch 1.936), train_loss = 2.40834015, grad/param norm = 2.6912e-01, time/batch = 0.6829s	
1159/29900 (epoch 1.938), train_loss = 2.05000507, grad/param norm = 2.3088e-01, time/batch = 0.6847s	
1160/29900 (epoch 1.940), train_loss = 2.17250662, grad/param norm = 2.5011e-01, time/batch = 0.6842s	
1161/29900 (epoch 1.941), train_loss = 2.19428982, grad/param norm = 2.6065e-01, time/batch = 0.6904s	
1162/29900 (epoch 1.943), train_loss = 2.27511463, grad/param norm = 2.2525e-01, time/batch = 0.6880s	
1163/29900 (epoch 1.945), train_loss = 2.38456731, grad/param norm = 2.5873e-01, time/batch = 0.6817s	
1164/29900 (epoch 1.946), train_loss = 2.34160598, grad/param norm = 2.9119e-01, time/batch = 0.6823s	
1165/29900 (epoch 1.948), train_loss = 2.12853003, grad/param norm = 2.6079e-01, time/batch = 0.6821s	
1166/29900 (epoch 1.950), train_loss = 2.36369874, grad/param norm = 2.3780e-01, time/batch = 0.6829s	
1167/29900 (epoch 1.952), train_loss = 2.01030987, grad/param norm = 2.0578e-01, time/batch = 0.6828s	
1168/29900 (epoch 1.953), train_loss = 2.04015252, grad/param norm = 2.4672e-01, time/batch = 0.6866s	
1169/29900 (epoch 1.955), train_loss = 2.27959337, grad/param norm = 2.8062e-01, time/batch = 0.6868s	
1170/29900 (epoch 1.957), train_loss = 2.33361863, grad/param norm = 2.9816e-01, time/batch = 0.6974s	
1171/29900 (epoch 1.958), train_loss = 2.39479187, grad/param norm = 2.4509e-01, time/batch = 0.6973s	
1172/29900 (epoch 1.960), train_loss = 2.36869238, grad/param norm = 2.4883e-01, time/batch = 0.6894s	
1173/29900 (epoch 1.962), train_loss = 2.50734331, grad/param norm = 3.2944e-01, time/batch = 0.6838s	
1174/29900 (epoch 1.963), train_loss = 2.23071014, grad/param norm = 2.1994e-01, time/batch = 0.6856s	
1175/29900 (epoch 1.965), train_loss = 2.31239952, grad/param norm = 2.5977e-01, time/batch = 0.6911s	
1176/29900 (epoch 1.967), train_loss = 2.12909993, grad/param norm = 2.6203e-01, time/batch = 0.6926s	
1177/29900 (epoch 1.968), train_loss = 2.34016270, grad/param norm = 2.7442e-01, time/batch = 0.6883s	
1178/29900 (epoch 1.970), train_loss = 2.22431286, grad/param norm = 2.6808e-01, time/batch = 0.6837s	
1179/29900 (epoch 1.972), train_loss = 1.93647857, grad/param norm = 2.2840e-01, time/batch = 0.6838s	
1180/29900 (epoch 1.973), train_loss = 1.99973180, grad/param norm = 2.3927e-01, time/batch = 0.6830s	
1181/29900 (epoch 1.975), train_loss = 2.28590455, grad/param norm = 2.8495e-01, time/batch = 0.6847s	
1182/29900 (epoch 1.977), train_loss = 2.13830832, grad/param norm = 2.2804e-01, time/batch = 0.6861s	
1183/29900 (epoch 1.978), train_loss = 2.16550337, grad/param norm = 2.4053e-01, time/batch = 0.6854s	
1184/29900 (epoch 1.980), train_loss = 2.33124554, grad/param norm = 2.1729e-01, time/batch = 0.6865s	
1185/29900 (epoch 1.982), train_loss = 2.25139419, grad/param norm = 2.4843e-01, time/batch = 0.6915s	
1186/29900 (epoch 1.983), train_loss = 2.34144142, grad/param norm = 2.7791e-01, time/batch = 0.7280s	
1187/29900 (epoch 1.985), train_loss = 2.37802862, grad/param norm = 2.6574e-01, time/batch = 0.7156s	
1188/29900 (epoch 1.987), train_loss = 2.17832205, grad/param norm = 2.4171e-01, time/batch = 0.7208s	
1189/29900 (epoch 1.988), train_loss = 2.20772560, grad/param norm = 2.2450e-01, time/batch = 0.7324s	
1190/29900 (epoch 1.990), train_loss = 2.17334888, grad/param norm = 2.4442e-01, time/batch = 0.7190s	
1191/29900 (epoch 1.992), train_loss = 2.02482562, grad/param norm = 2.7625e-01, time/batch = 0.7157s	
1192/29900 (epoch 1.993), train_loss = 2.22488385, grad/param norm = 2.2993e-01, time/batch = 0.6991s	
1193/29900 (epoch 1.995), train_loss = 2.19005085, grad/param norm = 2.1022e-01, time/batch = 0.6893s	
1194/29900 (epoch 1.997), train_loss = 2.24862257, grad/param norm = 2.3967e-01, time/batch = 0.6860s	
1195/29900 (epoch 1.998), train_loss = 2.16324552, grad/param norm = 2.4141e-01, time/batch = 0.6914s	
1196/29900 (epoch 2.000), train_loss = 2.13058931, grad/param norm = 2.2997e-01, time/batch = 0.7035s	
1197/29900 (epoch 2.002), train_loss = 2.27867447, grad/param norm = 2.4830e-01, time/batch = 0.6947s	
1198/29900 (epoch 2.003), train_loss = 2.26481178, grad/param norm = 2.5675e-01, time/batch = 0.6866s	
1199/29900 (epoch 2.005), train_loss = 2.21888051, grad/param norm = 2.5287e-01, time/batch = 0.6838s	
1200/29900 (epoch 2.007), train_loss = 2.29202058, grad/param norm = 2.2708e-01, time/batch = 0.6799s	
1201/29900 (epoch 2.008), train_loss = 2.29235162, grad/param norm = 2.4818e-01, time/batch = 0.6906s	
1202/29900 (epoch 2.010), train_loss = 2.17859694, grad/param norm = 2.0745e-01, time/batch = 0.6864s	
1203/29900 (epoch 2.012), train_loss = 2.09601389, grad/param norm = 2.1362e-01, time/batch = 0.6867s	
1204/29900 (epoch 2.013), train_loss = 2.22741438, grad/param norm = 2.6135e-01, time/batch = 0.7147s	
1205/29900 (epoch 2.015), train_loss = 2.25698478, grad/param norm = 2.9960e-01, time/batch = 0.7102s	
1206/29900 (epoch 2.017), train_loss = 2.26106257, grad/param norm = 2.8806e-01, time/batch = 0.6841s	
1207/29900 (epoch 2.018), train_loss = 2.32977208, grad/param norm = 2.8730e-01, time/batch = 0.6919s	
1208/29900 (epoch 2.020), train_loss = 2.29451319, grad/param norm = 2.7433e-01, time/batch = 0.6889s	
1209/29900 (epoch 2.022), train_loss = 2.17652977, grad/param norm = 2.4482e-01, time/batch = 0.6837s	
1210/29900 (epoch 2.023), train_loss = 2.28875855, grad/param norm = 2.9931e-01, time/batch = 0.6815s	
1211/29900 (epoch 2.025), train_loss = 2.21434332, grad/param norm = 2.2393e-01, time/batch = 0.6843s	
1212/29900 (epoch 2.027), train_loss = 2.04051742, grad/param norm = 2.0910e-01, time/batch = 0.6840s	
1213/29900 (epoch 2.028), train_loss = 2.39051284, grad/param norm = 2.5745e-01, time/batch = 0.6844s	
1214/29900 (epoch 2.030), train_loss = 2.38280531, grad/param norm = 2.9588e-01, time/batch = 0.6856s	
1215/29900 (epoch 2.032), train_loss = 2.22250145, grad/param norm = 2.4997e-01, time/batch = 0.6833s	
1216/29900 (epoch 2.033), train_loss = 2.28089676, grad/param norm = 2.4712e-01, time/batch = 0.6843s	
1217/29900 (epoch 2.035), train_loss = 2.12381329, grad/param norm = 2.3587e-01, time/batch = 0.6832s	
1218/29900 (epoch 2.037), train_loss = 2.17101036, grad/param norm = 2.1554e-01, time/batch = 0.6843s	
1219/29900 (epoch 2.038), train_loss = 2.23921815, grad/param norm = 2.6062e-01, time/batch = 0.6809s	
1220/29900 (epoch 2.040), train_loss = 2.04877677, grad/param norm = 3.2092e-01, time/batch = 0.6842s	
1221/29900 (epoch 2.042), train_loss = 2.22395380, grad/param norm = 3.3070e-01, time/batch = 0.6901s	
1222/29900 (epoch 2.043), train_loss = 2.37111567, grad/param norm = 2.7549e-01, time/batch = 0.6848s	
1223/29900 (epoch 2.045), train_loss = 2.19795985, grad/param norm = 2.3809e-01, time/batch = 0.7232s	
1224/29900 (epoch 2.047), train_loss = 2.28036460, grad/param norm = 2.7740e-01, time/batch = 0.7019s	
1225/29900 (epoch 2.048), train_loss = 2.05411865, grad/param norm = 3.0591e-01, time/batch = 0.6838s	
1226/29900 (epoch 2.050), train_loss = 2.01955583, grad/param norm = 2.1585e-01, time/batch = 0.6826s	
1227/29900 (epoch 2.052), train_loss = 2.04452366, grad/param norm = 1.8253e-01, time/batch = 0.6846s	
1228/29900 (epoch 2.054), train_loss = 2.28434689, grad/param norm = 2.5465e-01, time/batch = 0.6834s	
1229/29900 (epoch 2.055), train_loss = 2.23972664, grad/param norm = 3.0125e-01, time/batch = 0.6846s	
1230/29900 (epoch 2.057), train_loss = 2.15049225, grad/param norm = 2.4126e-01, time/batch = 0.7065s	
1231/29900 (epoch 2.059), train_loss = 2.34415836, grad/param norm = 2.5754e-01, time/batch = 0.6947s	
1232/29900 (epoch 2.060), train_loss = 2.24948738, grad/param norm = 2.6980e-01, time/batch = 0.6893s	
1233/29900 (epoch 2.062), train_loss = 2.24420264, grad/param norm = 2.4784e-01, time/batch = 0.6996s	
1234/29900 (epoch 2.064), train_loss = 2.22815062, grad/param norm = 2.6501e-01, time/batch = 0.6950s	
1235/29900 (epoch 2.065), train_loss = 2.37487208, grad/param norm = 2.4884e-01, time/batch = 0.6969s	
1236/29900 (epoch 2.067), train_loss = 2.18618117, grad/param norm = 2.2039e-01, time/batch = 0.6860s	
1237/29900 (epoch 2.069), train_loss = 2.26534925, grad/param norm = 2.2509e-01, time/batch = 0.6871s	
1238/29900 (epoch 2.070), train_loss = 2.18589406, grad/param norm = 2.2925e-01, time/batch = 0.6813s	
1239/29900 (epoch 2.072), train_loss = 2.16922214, grad/param norm = 2.6047e-01, time/batch = 0.6822s	
1240/29900 (epoch 2.074), train_loss = 2.32540936, grad/param norm = 2.5734e-01, time/batch = 0.6857s	
1241/29900 (epoch 2.075), train_loss = 2.15220049, grad/param norm = 2.2542e-01, time/batch = 0.6929s	
1242/29900 (epoch 2.077), train_loss = 2.02582957, grad/param norm = 2.2614e-01, time/batch = 0.7262s	
1243/29900 (epoch 2.079), train_loss = 2.13574023, grad/param norm = 3.1096e-01, time/batch = 0.6882s	
1244/29900 (epoch 2.080), train_loss = 2.01225658, grad/param norm = 3.7110e-01, time/batch = 0.6832s	
1245/29900 (epoch 2.082), train_loss = 2.07664719, grad/param norm = 2.7533e-01, time/batch = 0.6833s	
1246/29900 (epoch 2.084), train_loss = 2.43781265, grad/param norm = 2.3136e-01, time/batch = 0.6811s	
1247/29900 (epoch 2.085), train_loss = 2.33374877, grad/param norm = 2.2619e-01, time/batch = 0.6828s	
1248/29900 (epoch 2.087), train_loss = 2.36740846, grad/param norm = 2.3780e-01, time/batch = 0.6811s	
1249/29900 (epoch 2.089), train_loss = 2.22429261, grad/param norm = 3.0927e-01, time/batch = 0.6810s	
1250/29900 (epoch 2.090), train_loss = 2.16491262, grad/param norm = 2.8193e-01, time/batch = 0.6811s	
1251/29900 (epoch 2.092), train_loss = 2.00249924, grad/param norm = 2.5670e-01, time/batch = 0.6829s	
1252/29900 (epoch 2.094), train_loss = 2.20790546, grad/param norm = 2.2035e-01, time/batch = 0.6844s	
1253/29900 (epoch 2.095), train_loss = 2.24909583, grad/param norm = 2.2374e-01, time/batch = 0.6828s	
1254/29900 (epoch 2.097), train_loss = 2.10754288, grad/param norm = 2.3771e-01, time/batch = 0.6821s	
1255/29900 (epoch 2.099), train_loss = 2.19511461, grad/param norm = 2.4879e-01, time/batch = 0.6823s	
1256/29900 (epoch 2.100), train_loss = 1.87613457, grad/param norm = 2.5785e-01, time/batch = 0.6821s	
1257/29900 (epoch 2.102), train_loss = 2.14693230, grad/param norm = 3.1244e-01, time/batch = 0.6817s	
1258/29900 (epoch 2.104), train_loss = 2.23945893, grad/param norm = 2.7832e-01, time/batch = 0.6810s	
1259/29900 (epoch 2.105), train_loss = 2.24058243, grad/param norm = 2.2228e-01, time/batch = 0.6878s	
1260/29900 (epoch 2.107), train_loss = 2.16992679, grad/param norm = 2.3451e-01, time/batch = 0.7006s	
1261/29900 (epoch 2.109), train_loss = 2.26996800, grad/param norm = 2.5099e-01, time/batch = 0.7272s	
1262/29900 (epoch 2.110), train_loss = 2.19020492, grad/param norm = 2.5303e-01, time/batch = 0.6821s	
1263/29900 (epoch 2.112), train_loss = 2.21841155, grad/param norm = 2.1555e-01, time/batch = 0.6826s	
1264/29900 (epoch 2.114), train_loss = 2.11021985, grad/param norm = 2.4980e-01, time/batch = 0.6836s	
1265/29900 (epoch 2.115), train_loss = 2.16785214, grad/param norm = 2.3949e-01, time/batch = 0.6826s	
1266/29900 (epoch 2.117), train_loss = 2.13998208, grad/param norm = 2.5591e-01, time/batch = 0.6838s	
1267/29900 (epoch 2.119), train_loss = 2.02574401, grad/param norm = 2.4289e-01, time/batch = 0.6836s	
1268/29900 (epoch 2.120), train_loss = 2.23611389, grad/param norm = 2.6390e-01, time/batch = 0.6840s	
1269/29900 (epoch 2.122), train_loss = 2.30688459, grad/param norm = 2.3492e-01, time/batch = 0.6800s	
1270/29900 (epoch 2.124), train_loss = 2.22486866, grad/param norm = 2.2097e-01, time/batch = 0.6824s	
1271/29900 (epoch 2.125), train_loss = 2.06264345, grad/param norm = 2.0867e-01, time/batch = 0.6835s	
1272/29900 (epoch 2.127), train_loss = 2.19346038, grad/param norm = 2.2827e-01, time/batch = 0.6833s	
1273/29900 (epoch 2.129), train_loss = 2.24349978, grad/param norm = 2.8644e-01, time/batch = 0.6924s	
1274/29900 (epoch 2.130), train_loss = 2.17324338, grad/param norm = 2.3833e-01, time/batch = 0.7049s	
1275/29900 (epoch 2.132), train_loss = 2.10336363, grad/param norm = 2.5060e-01, time/batch = 0.7032s	
1276/29900 (epoch 2.134), train_loss = 2.33328990, grad/param norm = 2.0649e-01, time/batch = 0.7203s	
1277/29900 (epoch 2.135), train_loss = 2.04928945, grad/param norm = 2.6199e-01, time/batch = 0.6959s	
1278/29900 (epoch 2.137), train_loss = 2.02535108, grad/param norm = 2.4560e-01, time/batch = 0.6861s	
1279/29900 (epoch 2.139), train_loss = 2.11424540, grad/param norm = 2.3815e-01, time/batch = 0.7145s	
1280/29900 (epoch 2.140), train_loss = 2.13166948, grad/param norm = 2.2105e-01, time/batch = 0.7149s	
1281/29900 (epoch 2.142), train_loss = 1.98177424, grad/param norm = 2.2741e-01, time/batch = 0.6855s	
1282/29900 (epoch 2.144), train_loss = 2.12459793, grad/param norm = 2.1844e-01, time/batch = 0.6854s	
1283/29900 (epoch 2.145), train_loss = 2.16168951, grad/param norm = 2.3831e-01, time/batch = 0.6872s	
1284/29900 (epoch 2.147), train_loss = 2.00105247, grad/param norm = 2.6882e-01, time/batch = 0.6807s	
1285/29900 (epoch 2.149), train_loss = 2.04441929, grad/param norm = 2.9219e-01, time/batch = 0.6813s	
1286/29900 (epoch 2.151), train_loss = 2.08780503, grad/param norm = 3.0548e-01, time/batch = 0.6795s	
1287/29900 (epoch 2.152), train_loss = 2.11054449, grad/param norm = 2.4892e-01, time/batch = 0.6825s	
1288/29900 (epoch 2.154), train_loss = 2.08011785, grad/param norm = 2.1454e-01, time/batch = 0.6824s	
1289/29900 (epoch 2.156), train_loss = 2.15422841, grad/param norm = 2.1536e-01, time/batch = 0.6942s	
1290/29900 (epoch 2.157), train_loss = 2.21979350, grad/param norm = 2.1858e-01, time/batch = 0.6991s	
1291/29900 (epoch 2.159), train_loss = 2.12541408, grad/param norm = 2.0556e-01, time/batch = 0.6955s	
1292/29900 (epoch 2.161), train_loss = 2.28792499, grad/param norm = 2.4732e-01, time/batch = 0.6907s	
1293/29900 (epoch 2.162), train_loss = 2.20314430, grad/param norm = 2.3725e-01, time/batch = 0.6963s	
1294/29900 (epoch 2.164), train_loss = 2.30248580, grad/param norm = 2.0368e-01, time/batch = 0.7276s	
1295/29900 (epoch 2.166), train_loss = 2.08383145, grad/param norm = 2.4506e-01, time/batch = 0.6868s	
1296/29900 (epoch 2.167), train_loss = 2.23522340, grad/param norm = 2.1534e-01, time/batch = 0.6843s	
1297/29900 (epoch 2.169), train_loss = 1.97031215, grad/param norm = 2.5867e-01, time/batch = 0.6869s	
1298/29900 (epoch 2.171), train_loss = 2.07004541, grad/param norm = 2.4369e-01, time/batch = 0.6847s	
1299/29900 (epoch 2.172), train_loss = 2.16078458, grad/param norm = 2.1932e-01, time/batch = 0.6824s	
1300/29900 (epoch 2.174), train_loss = 2.14753979, grad/param norm = 2.2246e-01, time/batch = 0.6818s	
1301/29900 (epoch 2.176), train_loss = 2.08848919, grad/param norm = 2.2467e-01, time/batch = 0.6840s	
1302/29900 (epoch 2.177), train_loss = 1.98793140, grad/param norm = 2.3807e-01, time/batch = 0.6826s	
1303/29900 (epoch 2.179), train_loss = 2.13857778, grad/param norm = 2.6100e-01, time/batch = 0.6845s	
1304/29900 (epoch 2.181), train_loss = 2.03590592, grad/param norm = 2.6904e-01, time/batch = 0.6852s	
1305/29900 (epoch 2.182), train_loss = 2.20149848, grad/param norm = 2.9130e-01, time/batch = 0.6846s	
1306/29900 (epoch 2.184), train_loss = 2.08823110, grad/param norm = 2.8326e-01, time/batch = 0.6899s	
1307/29900 (epoch 2.186), train_loss = 2.03266524, grad/param norm = 2.5150e-01, time/batch = 0.6828s	
1308/29900 (epoch 2.187), train_loss = 2.05543726, grad/param norm = 2.0649e-01, time/batch = 0.6820s	
1309/29900 (epoch 2.189), train_loss = 2.10858537, grad/param norm = 2.2240e-01, time/batch = 0.6848s	
1310/29900 (epoch 2.191), train_loss = 2.10292496, grad/param norm = 2.5396e-01, time/batch = 0.6893s	
1311/29900 (epoch 2.192), train_loss = 2.18974651, grad/param norm = 2.2481e-01, time/batch = 0.6909s	
1312/29900 (epoch 2.194), train_loss = 2.14142876, grad/param norm = 2.1475e-01, time/batch = 0.7046s	
1313/29900 (epoch 2.196), train_loss = 2.19895526, grad/param norm = 2.4156e-01, time/batch = 0.7222s	
1314/29900 (epoch 2.197), train_loss = 1.97972633, grad/param norm = 2.3478e-01, time/batch = 0.6853s	
1315/29900 (epoch 2.199), train_loss = 2.18611383, grad/param norm = 2.6427e-01, time/batch = 0.6822s	
1316/29900 (epoch 2.201), train_loss = 2.21711799, grad/param norm = 2.0886e-01, time/batch = 0.6840s	
1317/29900 (epoch 2.202), train_loss = 2.09625022, grad/param norm = 2.2559e-01, time/batch = 0.6829s	
1318/29900 (epoch 2.204), train_loss = 2.21663830, grad/param norm = 2.6322e-01, time/batch = 0.6820s	
1319/29900 (epoch 2.206), train_loss = 2.37220444, grad/param norm = 2.4110e-01, time/batch = 0.6824s	
1320/29900 (epoch 2.207), train_loss = 2.12741690, grad/param norm = 2.6105e-01, time/batch = 0.6832s	
1321/29900 (epoch 2.209), train_loss = 2.14147671, grad/param norm = 2.6289e-01, time/batch = 0.6868s	
1322/29900 (epoch 2.211), train_loss = 1.93449248, grad/param norm = 2.2192e-01, time/batch = 0.6833s	
1323/29900 (epoch 2.212), train_loss = 2.02909768, grad/param norm = 2.1744e-01, time/batch = 0.6813s	
1324/29900 (epoch 2.214), train_loss = 2.28171701, grad/param norm = 2.4599e-01, time/batch = 0.6909s	
1325/29900 (epoch 2.216), train_loss = 2.15290887, grad/param norm = 2.3490e-01, time/batch = 0.6972s	
1326/29900 (epoch 2.217), train_loss = 2.21646328, grad/param norm = 2.4305e-01, time/batch = 0.6841s	
1327/29900 (epoch 2.219), train_loss = 2.28645078, grad/param norm = 2.2765e-01, time/batch = 0.6854s	
1328/29900 (epoch 2.221), train_loss = 2.21478483, grad/param norm = 2.7838e-01, time/batch = 0.6854s	
1329/29900 (epoch 2.222), train_loss = 2.21631864, grad/param norm = 2.5346e-01, time/batch = 0.6843s	
1330/29900 (epoch 2.224), train_loss = 2.10382486, grad/param norm = 2.0148e-01, time/batch = 0.6802s	
1331/29900 (epoch 2.226), train_loss = 2.25797233, grad/param norm = 2.3265e-01, time/batch = 0.7119s	
1332/29900 (epoch 2.227), train_loss = 2.07043299, grad/param norm = 2.1224e-01, time/batch = 0.6854s	
1333/29900 (epoch 2.229), train_loss = 1.96984784, grad/param norm = 2.2848e-01, time/batch = 0.6833s	
1334/29900 (epoch 2.231), train_loss = 1.94918334, grad/param norm = 2.3717e-01, time/batch = 0.6836s	
1335/29900 (epoch 2.232), train_loss = 2.15914923, grad/param norm = 2.7897e-01, time/batch = 0.6865s	
1336/29900 (epoch 2.234), train_loss = 2.10040102, grad/param norm = 2.3367e-01, time/batch = 0.6878s	
1337/29900 (epoch 2.236), train_loss = 2.18583404, grad/param norm = 2.2664e-01, time/batch = 0.6814s	
1338/29900 (epoch 2.237), train_loss = 2.25570421, grad/param norm = 2.6375e-01, time/batch = 0.6828s	
1339/29900 (epoch 2.239), train_loss = 2.13416863, grad/param norm = 2.2603e-01, time/batch = 0.6820s	
1340/29900 (epoch 2.241), train_loss = 2.11919228, grad/param norm = 2.2102e-01, time/batch = 0.6834s	
1341/29900 (epoch 2.242), train_loss = 2.22992559, grad/param norm = 2.8349e-01, time/batch = 0.6860s	
1342/29900 (epoch 2.244), train_loss = 2.22230286, grad/param norm = 2.4218e-01, time/batch = 0.6848s	
1343/29900 (epoch 2.246), train_loss = 1.97044212, grad/param norm = 2.0444e-01, time/batch = 0.6836s	
1344/29900 (epoch 2.247), train_loss = 2.09879470, grad/param norm = 2.4972e-01, time/batch = 0.6851s	
1345/29900 (epoch 2.249), train_loss = 2.18315793, grad/param norm = 3.3041e-01, time/batch = 0.6822s	
1346/29900 (epoch 2.251), train_loss = 2.32661631, grad/param norm = 2.6864e-01, time/batch = 0.6834s	
1347/29900 (epoch 2.253), train_loss = 2.20321053, grad/param norm = 2.1540e-01, time/batch = 0.6855s	
1348/29900 (epoch 2.254), train_loss = 2.17517370, grad/param norm = 2.3775e-01, time/batch = 0.6840s	
1349/29900 (epoch 2.256), train_loss = 2.18294486, grad/param norm = 3.1671e-01, time/batch = 0.6827s	
1350/29900 (epoch 2.258), train_loss = 2.25987914, grad/param norm = 2.6727e-01, time/batch = 0.6854s	
1351/29900 (epoch 2.259), train_loss = 2.19747246, grad/param norm = 2.4711e-01, time/batch = 0.6847s	
1352/29900 (epoch 2.261), train_loss = 2.17914684, grad/param norm = 2.6842e-01, time/batch = 0.6846s	
1353/29900 (epoch 2.263), train_loss = 2.33459696, grad/param norm = 2.9214e-01, time/batch = 0.6853s	
1354/29900 (epoch 2.264), train_loss = 2.08379591, grad/param norm = 2.9407e-01, time/batch = 0.7024s	
1355/29900 (epoch 2.266), train_loss = 2.18159801, grad/param norm = 2.2227e-01, time/batch = 0.6964s	
1356/29900 (epoch 2.268), train_loss = 2.17113669, grad/param norm = 2.4751e-01, time/batch = 0.6845s	
1357/29900 (epoch 2.269), train_loss = 2.17021517, grad/param norm = 2.1631e-01, time/batch = 0.6858s	
1358/29900 (epoch 2.271), train_loss = 2.03251659, grad/param norm = 2.0311e-01, time/batch = 0.6889s	
1359/29900 (epoch 2.273), train_loss = 2.08812883, grad/param norm = 2.3721e-01, time/batch = 0.6890s	
1360/29900 (epoch 2.274), train_loss = 2.27427306, grad/param norm = 2.8498e-01, time/batch = 0.7001s	
1361/29900 (epoch 2.276), train_loss = 2.21838106, grad/param norm = 2.3334e-01, time/batch = 0.6954s	
1362/29900 (epoch 2.278), train_loss = 2.13723846, grad/param norm = 2.1168e-01, time/batch = 0.7034s	
1363/29900 (epoch 2.279), train_loss = 2.32450482, grad/param norm = 2.6829e-01, time/batch = 0.7191s	
1364/29900 (epoch 2.281), train_loss = 2.09056540, grad/param norm = 2.1376e-01, time/batch = 0.6911s	
1365/29900 (epoch 2.283), train_loss = 2.27770319, grad/param norm = 2.3026e-01, time/batch = 0.6875s	
1366/29900 (epoch 2.284), train_loss = 2.29108663, grad/param norm = 2.4157e-01, time/batch = 0.6874s	
1367/29900 (epoch 2.286), train_loss = 2.52950837, grad/param norm = 2.2343e-01, time/batch = 0.6866s	
1368/29900 (epoch 2.288), train_loss = 3.36957951, grad/param norm = 5.8276e-01, time/batch = 0.6824s	
1369/29900 (epoch 2.289), train_loss = 2.69138459, grad/param norm = 2.9401e-01, time/batch = 0.6815s	
1370/29900 (epoch 2.291), train_loss = 2.52340965, grad/param norm = 3.6289e-01, time/batch = 0.6834s	
1371/29900 (epoch 2.293), train_loss = 2.01912018, grad/param norm = 2.4053e-01, time/batch = 0.6857s	
1372/29900 (epoch 2.294), train_loss = 2.10621794, grad/param norm = 2.9223e-01, time/batch = 0.6856s	
1373/29900 (epoch 2.296), train_loss = 2.00335069, grad/param norm = 2.4491e-01, time/batch = 0.7128s	
1374/29900 (epoch 2.298), train_loss = 2.00276442, grad/param norm = 2.3637e-01, time/batch = 0.7121s	
1375/29900 (epoch 2.299), train_loss = 2.06887776, grad/param norm = 2.2637e-01, time/batch = 0.6847s	
1376/29900 (epoch 2.301), train_loss = 2.02125288, grad/param norm = 2.2410e-01, time/batch = 0.6877s	
1377/29900 (epoch 2.303), train_loss = 2.33341618, grad/param norm = 2.2917e-01, time/batch = 0.6839s	
1378/29900 (epoch 2.304), train_loss = 2.06112860, grad/param norm = 2.7512e-01, time/batch = 0.6823s	
1379/29900 (epoch 2.306), train_loss = 2.06990770, grad/param norm = 2.3922e-01, time/batch = 0.6855s	
1380/29900 (epoch 2.308), train_loss = 2.01959967, grad/param norm = 2.3419e-01, time/batch = 0.6929s	
1381/29900 (epoch 2.309), train_loss = 1.94375136, grad/param norm = 2.0971e-01, time/batch = 0.6858s	
1382/29900 (epoch 2.311), train_loss = 2.08340953, grad/param norm = 2.1351e-01, time/batch = 0.6858s	
1383/29900 (epoch 2.313), train_loss = 2.31967819, grad/param norm = 2.4136e-01, time/batch = 0.6969s	
1384/29900 (epoch 2.314), train_loss = 2.10531909, grad/param norm = 2.1542e-01, time/batch = 0.6902s	
1385/29900 (epoch 2.316), train_loss = 2.31587140, grad/param norm = 2.6693e-01, time/batch = 0.6898s	
1386/29900 (epoch 2.318), train_loss = 2.18619417, grad/param norm = 2.1713e-01, time/batch = 0.6833s	
1387/29900 (epoch 2.319), train_loss = 2.17079496, grad/param norm = 2.0239e-01, time/batch = 0.6856s	
1388/29900 (epoch 2.321), train_loss = 2.29233331, grad/param norm = 2.1920e-01, time/batch = 0.6830s	
1389/29900 (epoch 2.323), train_loss = 2.13042688, grad/param norm = 2.3579e-01, time/batch = 0.6878s	
1390/29900 (epoch 2.324), train_loss = 2.06000944, grad/param norm = 2.6985e-01, time/batch = 0.6857s	
1391/29900 (epoch 2.326), train_loss = 2.06331835, grad/param norm = 3.0071e-01, time/batch = 0.6842s	
1392/29900 (epoch 2.328), train_loss = 2.22367028, grad/param norm = 2.9308e-01, time/batch = 0.6845s	
1393/29900 (epoch 2.329), train_loss = 2.28643694, grad/param norm = 2.5516e-01, time/batch = 0.6855s	
1394/29900 (epoch 2.331), train_loss = 2.32604941, grad/param norm = 2.3399e-01, time/batch = 0.6834s	
1395/29900 (epoch 2.333), train_loss = 2.25831093, grad/param norm = 2.4413e-01, time/batch = 0.6821s	
1396/29900 (epoch 2.334), train_loss = 2.23551324, grad/param norm = 2.5375e-01, time/batch = 0.7077s	
1397/29900 (epoch 2.336), train_loss = 1.96185534, grad/param norm = 2.1936e-01, time/batch = 0.7171s	
1398/29900 (epoch 2.338), train_loss = 2.19722160, grad/param norm = 2.3355e-01, time/batch = 0.6852s	
1399/29900 (epoch 2.339), train_loss = 2.25814291, grad/param norm = 2.7303e-01, time/batch = 0.6850s	
1400/29900 (epoch 2.341), train_loss = 2.09695562, grad/param norm = 2.4138e-01, time/batch = 0.6885s	
1401/29900 (epoch 2.343), train_loss = 2.25829736, grad/param norm = 2.4887e-01, time/batch = 0.6857s	
1402/29900 (epoch 2.344), train_loss = 2.02832353, grad/param norm = 2.2107e-01, time/batch = 0.6847s	
1403/29900 (epoch 2.346), train_loss = 2.02523745, grad/param norm = 2.2268e-01, time/batch = 0.6851s	
1404/29900 (epoch 2.348), train_loss = 2.06333788, grad/param norm = 2.4220e-01, time/batch = 0.6949s	
1405/29900 (epoch 2.349), train_loss = 2.21214464, grad/param norm = 2.3055e-01, time/batch = 0.6904s	
1406/29900 (epoch 2.351), train_loss = 2.06334923, grad/param norm = 2.8867e-01, time/batch = 0.6839s	
1407/29900 (epoch 2.353), train_loss = 2.13008981, grad/param norm = 2.2617e-01, time/batch = 0.6823s	
1408/29900 (epoch 2.355), train_loss = 2.05683563, grad/param norm = 2.1394e-01, time/batch = 0.6805s	
1409/29900 (epoch 2.356), train_loss = 2.12598695, grad/param norm = 2.3725e-01, time/batch = 0.6816s	
1410/29900 (epoch 2.358), train_loss = 2.11450499, grad/param norm = 2.2123e-01, time/batch = 0.6826s	
1411/29900 (epoch 2.360), train_loss = 2.26968165, grad/param norm = 2.4228e-01, time/batch = 0.6875s	
1412/29900 (epoch 2.361), train_loss = 2.35008377, grad/param norm = 2.5260e-01, time/batch = 0.6946s	
1413/29900 (epoch 2.363), train_loss = 2.01741215, grad/param norm = 2.6555e-01, time/batch = 0.7026s	
1414/29900 (epoch 2.365), train_loss = 2.06447285, grad/param norm = 2.0933e-01, time/batch = 0.7201s	
1415/29900 (epoch 2.366), train_loss = 1.96293074, grad/param norm = 2.1691e-01, time/batch = 0.7294s	
1416/29900 (epoch 2.368), train_loss = 1.97692943, grad/param norm = 2.4297e-01, time/batch = 0.7138s	
1417/29900 (epoch 2.370), train_loss = 2.10885718, grad/param norm = 2.5083e-01, time/batch = 0.6890s	
1418/29900 (epoch 2.371), train_loss = 2.19637512, grad/param norm = 2.4713e-01, time/batch = 0.6818s	
1419/29900 (epoch 2.373), train_loss = 2.09178264, grad/param norm = 2.6218e-01, time/batch = 0.6975s	
1420/29900 (epoch 2.375), train_loss = 2.22105819, grad/param norm = 2.3062e-01, time/batch = 0.6825s	
1421/29900 (epoch 2.376), train_loss = 2.25987499, grad/param norm = 2.3752e-01, time/batch = 0.6816s	
1422/29900 (epoch 2.378), train_loss = 2.09933272, grad/param norm = 2.4689e-01, time/batch = 0.6821s	
1423/29900 (epoch 2.380), train_loss = 2.09537965, grad/param norm = 2.3678e-01, time/batch = 0.6869s	
1424/29900 (epoch 2.381), train_loss = 2.29594678, grad/param norm = 2.6733e-01, time/batch = 0.7094s	
1425/29900 (epoch 2.383), train_loss = 1.95386151, grad/param norm = 2.4918e-01, time/batch = 0.6895s	
1426/29900 (epoch 2.385), train_loss = 2.02298896, grad/param norm = 2.6084e-01, time/batch = 0.6852s	
1427/29900 (epoch 2.386), train_loss = 2.01670717, grad/param norm = 2.6808e-01, time/batch = 0.6886s	
1428/29900 (epoch 2.388), train_loss = 2.23915214, grad/param norm = 2.2668e-01, time/batch = 0.6801s	
1429/29900 (epoch 2.390), train_loss = 2.13642340, grad/param norm = 2.5542e-01, time/batch = 0.7016s	
1430/29900 (epoch 2.391), train_loss = 2.03015493, grad/param norm = 2.5280e-01, time/batch = 0.7201s	
1431/29900 (epoch 2.393), train_loss = 2.18837259, grad/param norm = 2.3898e-01, time/batch = 0.6826s	
1432/29900 (epoch 2.395), train_loss = 1.99345640, grad/param norm = 2.5313e-01, time/batch = 0.6820s	
1433/29900 (epoch 2.396), train_loss = 2.27745633, grad/param norm = 2.6272e-01, time/batch = 0.6856s	
1434/29900 (epoch 2.398), train_loss = 2.16995946, grad/param norm = 2.3280e-01, time/batch = 0.6826s	
1435/29900 (epoch 2.400), train_loss = 2.18921206, grad/param norm = 2.2973e-01, time/batch = 0.6867s	
1436/29900 (epoch 2.401), train_loss = 2.18586379, grad/param norm = 2.1232e-01, time/batch = 0.6812s	
1437/29900 (epoch 2.403), train_loss = 2.20450167, grad/param norm = 2.5581e-01, time/batch = 0.6818s	
1438/29900 (epoch 2.405), train_loss = 2.14149708, grad/param norm = 2.8350e-01, time/batch = 0.6797s	
1439/29900 (epoch 2.406), train_loss = 1.93067981, grad/param norm = 2.4688e-01, time/batch = 0.6806s	
1440/29900 (epoch 2.408), train_loss = 1.85259757, grad/param norm = 2.2089e-01, time/batch = 0.6824s	
1441/29900 (epoch 2.410), train_loss = 2.26490264, grad/param norm = 2.4571e-01, time/batch = 0.6854s	
1442/29900 (epoch 2.411), train_loss = 2.23291929, grad/param norm = 2.6994e-01, time/batch = 0.6862s	
1443/29900 (epoch 2.413), train_loss = 2.17182965, grad/param norm = 2.3205e-01, time/batch = 0.6829s	
1444/29900 (epoch 2.415), train_loss = 2.01107021, grad/param norm = 2.3006e-01, time/batch = 0.6834s	
1445/29900 (epoch 2.416), train_loss = 2.10136405, grad/param norm = 2.1790e-01, time/batch = 0.6845s	
1446/29900 (epoch 2.418), train_loss = 1.97755032, grad/param norm = 2.2317e-01, time/batch = 0.6975s	
1447/29900 (epoch 2.420), train_loss = 2.23739356, grad/param norm = 2.1774e-01, time/batch = 0.6985s	
1448/29900 (epoch 2.421), train_loss = 2.38295570, grad/param norm = 2.2702e-01, time/batch = 0.7201s	
1449/29900 (epoch 2.423), train_loss = 2.12654794, grad/param norm = 1.9883e-01, time/batch = 0.7259s	
1450/29900 (epoch 2.425), train_loss = 2.08667753, grad/param norm = 2.2297e-01, time/batch = 0.6940s	
1451/29900 (epoch 2.426), train_loss = 2.04157780, grad/param norm = 2.4334e-01, time/batch = 0.6886s	
1452/29900 (epoch 2.428), train_loss = 2.14843718, grad/param norm = 2.4234e-01, time/batch = 0.6834s	
1453/29900 (epoch 2.430), train_loss = 2.12908267, grad/param norm = 2.1950e-01, time/batch = 0.6826s	
1454/29900 (epoch 2.431), train_loss = 2.14271436, grad/param norm = 2.2993e-01, time/batch = 0.6821s	
1455/29900 (epoch 2.433), train_loss = 2.03523076, grad/param norm = 2.3108e-01, time/batch = 0.7037s	
1456/29900 (epoch 2.435), train_loss = 2.15231898, grad/param norm = 2.3094e-01, time/batch = 0.6871s	
1457/29900 (epoch 2.436), train_loss = 2.03236475, grad/param norm = 2.4800e-01, time/batch = 0.6860s	
1458/29900 (epoch 2.438), train_loss = 2.04469716, grad/param norm = 2.1893e-01, time/batch = 0.6832s	
1459/29900 (epoch 2.440), train_loss = 1.99561978, grad/param norm = 2.4794e-01, time/batch = 0.6822s	
1460/29900 (epoch 2.441), train_loss = 1.94153083, grad/param norm = 2.3848e-01, time/batch = 0.6813s	
1461/29900 (epoch 2.443), train_loss = 2.19913483, grad/param norm = 2.1291e-01, time/batch = 0.6900s	
1462/29900 (epoch 2.445), train_loss = 2.22993919, grad/param norm = 2.1643e-01, time/batch = 0.6867s	
1463/29900 (epoch 2.446), train_loss = 1.91696386, grad/param norm = 2.3597e-01, time/batch = 0.6844s	
1464/29900 (epoch 2.448), train_loss = 2.13627224, grad/param norm = 2.2681e-01, time/batch = 0.6843s	
1465/29900 (epoch 2.450), train_loss = 2.14869932, grad/param norm = 2.1255e-01, time/batch = 0.6885s	
1466/29900 (epoch 2.452), train_loss = 2.10596797, grad/param norm = 2.3841e-01, time/batch = 0.6840s	
1467/29900 (epoch 2.453), train_loss = 2.16110885, grad/param norm = 2.4431e-01, time/batch = 0.7234s	
1468/29900 (epoch 2.455), train_loss = 2.13382077, grad/param norm = 2.1176e-01, time/batch = 0.7017s	
1469/29900 (epoch 2.457), train_loss = 1.98225373, grad/param norm = 2.2940e-01, time/batch = 0.6845s	
1470/29900 (epoch 2.458), train_loss = 2.14345128, grad/param norm = 2.2661e-01, time/batch = 0.6845s	
1471/29900 (epoch 2.460), train_loss = 2.02926572, grad/param norm = 2.1177e-01, time/batch = 0.6865s	
1472/29900 (epoch 2.462), train_loss = 2.00793154, grad/param norm = 2.2178e-01, time/batch = 0.6853s	
1473/29900 (epoch 2.463), train_loss = 1.79280327, grad/param norm = 1.9060e-01, time/batch = 0.6861s	
1474/29900 (epoch 2.465), train_loss = 2.18368102, grad/param norm = 2.2077e-01, time/batch = 0.6835s	
1475/29900 (epoch 2.467), train_loss = 2.23998635, grad/param norm = 2.1821e-01, time/batch = 0.6835s	
1476/29900 (epoch 2.468), train_loss = 2.42621308, grad/param norm = 2.7162e-01, time/batch = 0.6845s	
1477/29900 (epoch 2.470), train_loss = 2.12799889, grad/param norm = 2.0194e-01, time/batch = 0.6836s	
1478/29900 (epoch 2.472), train_loss = 2.03936510, grad/param norm = 2.7060e-01, time/batch = 0.6832s	
1479/29900 (epoch 2.473), train_loss = 2.06579828, grad/param norm = 2.7255e-01, time/batch = 0.6850s	
1480/29900 (epoch 2.475), train_loss = 2.07412816, grad/param norm = 2.0955e-01, time/batch = 0.6892s	
1481/29900 (epoch 2.477), train_loss = 2.10967872, grad/param norm = 2.3981e-01, time/batch = 0.6928s	
1482/29900 (epoch 2.478), train_loss = 2.21972937, grad/param norm = 2.1676e-01, time/batch = 0.6899s	
1483/29900 (epoch 2.480), train_loss = 2.04280122, grad/param norm = 2.2085e-01, time/batch = 0.6876s	
1484/29900 (epoch 2.482), train_loss = 2.14407492, grad/param norm = 2.0937e-01, time/batch = 0.6843s	
1485/29900 (epoch 2.483), train_loss = 2.07827676, grad/param norm = 2.2291e-01, time/batch = 0.6875s	
1486/29900 (epoch 2.485), train_loss = 2.23134080, grad/param norm = 2.5843e-01, time/batch = 0.7035s	
1487/29900 (epoch 2.487), train_loss = 2.00447932, grad/param norm = 2.2372e-01, time/batch = 0.6969s	
1488/29900 (epoch 2.488), train_loss = 2.15576762, grad/param norm = 2.9656e-01, time/batch = 0.6871s	
1489/29900 (epoch 2.490), train_loss = 2.04269475, grad/param norm = 2.1354e-01, time/batch = 0.6833s	
1490/29900 (epoch 2.492), train_loss = 2.16005301, grad/param norm = 2.4443e-01, time/batch = 0.7179s	
1491/29900 (epoch 2.493), train_loss = 2.04719884, grad/param norm = 2.0074e-01, time/batch = 0.7074s	
1492/29900 (epoch 2.495), train_loss = 2.07994536, grad/param norm = 2.2417e-01, time/batch = 0.6883s	
1493/29900 (epoch 2.497), train_loss = 2.08748895, grad/param norm = 2.0223e-01, time/batch = 0.6845s	
1494/29900 (epoch 2.498), train_loss = 2.04199902, grad/param norm = 2.1356e-01, time/batch = 0.6837s	
1495/29900 (epoch 2.500), train_loss = 2.26343879, grad/param norm = 2.6794e-01, time/batch = 0.6859s	
1496/29900 (epoch 2.502), train_loss = 2.24135923, grad/param norm = 2.1761e-01, time/batch = 0.6835s	
1497/29900 (epoch 2.503), train_loss = 2.07820403, grad/param norm = 2.0675e-01, time/batch = 0.7037s	
1498/29900 (epoch 2.505), train_loss = 1.87826543, grad/param norm = 2.3633e-01, time/batch = 0.6976s	
1499/29900 (epoch 2.507), train_loss = 2.09099755, grad/param norm = 2.7123e-01, time/batch = 0.6845s	
1500/29900 (epoch 2.508), train_loss = 2.04642537, grad/param norm = 2.8949e-01, time/batch = 0.6854s	
1501/29900 (epoch 2.510), train_loss = 1.92462270, grad/param norm = 2.3670e-01, time/batch = 0.6850s	
1502/29900 (epoch 2.512), train_loss = 2.24174877, grad/param norm = 2.6814e-01, time/batch = 0.6871s	
1503/29900 (epoch 2.513), train_loss = 2.23296016, grad/param norm = 2.5141e-01, time/batch = 0.6860s	
1504/29900 (epoch 2.515), train_loss = 2.02972342, grad/param norm = 2.3169e-01, time/batch = 0.6837s	
1505/29900 (epoch 2.517), train_loss = 2.10874949, grad/param norm = 2.5070e-01, time/batch = 0.6827s	
1506/29900 (epoch 2.518), train_loss = 1.98494146, grad/param norm = 2.2542e-01, time/batch = 0.6852s	
1507/29900 (epoch 2.520), train_loss = 2.22156890, grad/param norm = 2.1961e-01, time/batch = 0.6856s	
1508/29900 (epoch 2.522), train_loss = 2.12048857, grad/param norm = 2.3662e-01, time/batch = 0.6878s	
1509/29900 (epoch 2.523), train_loss = 2.11683292, grad/param norm = 2.0099e-01, time/batch = 0.7254s	
1510/29900 (epoch 2.525), train_loss = 2.06116942, grad/param norm = 2.4002e-01, time/batch = 0.6971s	
1511/29900 (epoch 2.527), train_loss = 2.11301392, grad/param norm = 2.3404e-01, time/batch = 0.6884s	
1512/29900 (epoch 2.528), train_loss = 2.12292045, grad/param norm = 2.1552e-01, time/batch = 0.6866s	
1513/29900 (epoch 2.530), train_loss = 2.23223240, grad/param norm = 2.2525e-01, time/batch = 0.6869s	
1514/29900 (epoch 2.532), train_loss = 2.12761129, grad/param norm = 2.3425e-01, time/batch = 0.6824s	
1515/29900 (epoch 2.533), train_loss = 2.06956626, grad/param norm = 2.5567e-01, time/batch = 0.7075s	
1516/29900 (epoch 2.535), train_loss = 2.11253393, grad/param norm = 3.3278e-01, time/batch = 0.7107s	
1517/29900 (epoch 2.537), train_loss = 1.98820607, grad/param norm = 2.4366e-01, time/batch = 0.7089s	
1518/29900 (epoch 2.538), train_loss = 2.05309231, grad/param norm = 2.3403e-01, time/batch = 0.7105s	
1519/29900 (epoch 2.540), train_loss = 2.04169305, grad/param norm = 2.3982e-01, time/batch = 0.7007s	
1520/29900 (epoch 2.542), train_loss = 2.06703595, grad/param norm = 2.1659e-01, time/batch = 0.6837s	
1521/29900 (epoch 2.543), train_loss = 2.25816671, grad/param norm = 2.1915e-01, time/batch = 0.6861s	
1522/29900 (epoch 2.545), train_loss = 2.23122394, grad/param norm = 2.3255e-01, time/batch = 0.6830s	
1523/29900 (epoch 2.547), train_loss = 2.20915275, grad/param norm = 2.3393e-01, time/batch = 0.6845s	
1524/29900 (epoch 2.548), train_loss = 2.07083079, grad/param norm = 2.7678e-01, time/batch = 0.6854s	
1525/29900 (epoch 2.550), train_loss = 2.00954557, grad/param norm = 2.7263e-01, time/batch = 0.6848s	
1526/29900 (epoch 2.552), train_loss = 2.05993377, grad/param norm = 2.3871e-01, time/batch = 0.6866s	
1527/29900 (epoch 2.554), train_loss = 2.26501246, grad/param norm = 2.3186e-01, time/batch = 0.7028s	
1528/29900 (epoch 2.555), train_loss = 2.23464566, grad/param norm = 1.9571e-01, time/batch = 0.7220s	
1529/29900 (epoch 2.557), train_loss = 2.26737571, grad/param norm = 2.1406e-01, time/batch = 0.6832s	
1530/29900 (epoch 2.559), train_loss = 2.11075750, grad/param norm = 2.1738e-01, time/batch = 0.6832s	
1531/29900 (epoch 2.560), train_loss = 2.14384462, grad/param norm = 2.0362e-01, time/batch = 0.6858s	
1532/29900 (epoch 2.562), train_loss = 2.06650833, grad/param norm = 2.2033e-01, time/batch = 0.6895s	
1533/29900 (epoch 2.564), train_loss = 2.10554835, grad/param norm = 2.2483e-01, time/batch = 0.6998s	
1534/29900 (epoch 2.565), train_loss = 2.28298179, grad/param norm = 2.1194e-01, time/batch = 0.6961s	
1535/29900 (epoch 2.567), train_loss = 2.20765261, grad/param norm = 2.3740e-01, time/batch = 0.6869s	
1536/29900 (epoch 2.569), train_loss = 2.31804771, grad/param norm = 2.2390e-01, time/batch = 0.7099s	
1537/29900 (epoch 2.570), train_loss = 2.15227266, grad/param norm = 2.4888e-01, time/batch = 0.6877s	
1538/29900 (epoch 2.572), train_loss = 1.95121427, grad/param norm = 2.2920e-01, time/batch = 0.6876s	
1539/29900 (epoch 2.574), train_loss = 2.02694861, grad/param norm = 2.3476e-01, time/batch = 0.6946s	
1540/29900 (epoch 2.575), train_loss = 2.12245565, grad/param norm = 2.3356e-01, time/batch = 0.6894s	
1541/29900 (epoch 2.577), train_loss = 2.16900550, grad/param norm = 2.2221e-01, time/batch = 0.6900s	
1542/29900 (epoch 2.579), train_loss = 2.22572376, grad/param norm = 2.0704e-01, time/batch = 0.6873s	
1543/29900 (epoch 2.580), train_loss = 2.07095213, grad/param norm = 2.0600e-01, time/batch = 0.6929s	
1544/29900 (epoch 2.582), train_loss = 1.96227836, grad/param norm = 4.2375e-01, time/batch = 0.6873s	
1545/29900 (epoch 2.584), train_loss = 2.08084290, grad/param norm = 2.5045e-01, time/batch = 0.7061s	
1546/29900 (epoch 2.585), train_loss = 2.24699076, grad/param norm = 2.2697e-01, time/batch = 0.7204s	
1547/29900 (epoch 2.587), train_loss = 2.15035140, grad/param norm = 2.0658e-01, time/batch = 0.7166s	
1548/29900 (epoch 2.589), train_loss = 2.35628123, grad/param norm = 2.3691e-01, time/batch = 0.6965s	
1549/29900 (epoch 2.590), train_loss = 1.98414907, grad/param norm = 2.1745e-01, time/batch = 0.6842s	
1550/29900 (epoch 2.592), train_loss = 2.14158635, grad/param norm = 2.1887e-01, time/batch = 0.7062s	
1551/29900 (epoch 2.594), train_loss = 2.07053240, grad/param norm = 2.2428e-01, time/batch = 0.7176s	
1552/29900 (epoch 2.595), train_loss = 2.18622521, grad/param norm = 2.4774e-01, time/batch = 0.6815s	
1553/29900 (epoch 2.597), train_loss = 2.06187005, grad/param norm = 2.1769e-01, time/batch = 0.6815s	
1554/29900 (epoch 2.599), train_loss = 1.87143616, grad/param norm = 1.8412e-01, time/batch = 0.6820s	
1555/29900 (epoch 2.600), train_loss = 2.11228404, grad/param norm = 2.0719e-01, time/batch = 0.6847s	
1556/29900 (epoch 2.602), train_loss = 2.12298370, grad/param norm = 2.4935e-01, time/batch = 0.6865s	
1557/29900 (epoch 2.604), train_loss = 2.18895709, grad/param norm = 2.0142e-01, time/batch = 0.6824s	
1558/29900 (epoch 2.605), train_loss = 2.20295725, grad/param norm = 2.1283e-01, time/batch = 0.6801s	
1559/29900 (epoch 2.607), train_loss = 2.04929728, grad/param norm = 2.1780e-01, time/batch = 0.6801s	
1560/29900 (epoch 2.609), train_loss = 2.17677856, grad/param norm = 2.4116e-01, time/batch = 0.6801s	
1561/29900 (epoch 2.610), train_loss = 2.35396542, grad/param norm = 2.2158e-01, time/batch = 0.6824s	
1562/29900 (epoch 2.612), train_loss = 2.26780172, grad/param norm = 2.2099e-01, time/batch = 0.6852s	
1563/29900 (epoch 2.614), train_loss = 2.24295750, grad/param norm = 2.0279e-01, time/batch = 0.6860s	
1564/29900 (epoch 2.615), train_loss = 2.51498876, grad/param norm = 2.2896e-01, time/batch = 0.6899s	
1565/29900 (epoch 2.617), train_loss = 2.14485507, grad/param norm = 2.0133e-01, time/batch = 0.7255s	
1566/29900 (epoch 2.619), train_loss = 2.06915442, grad/param norm = 2.2359e-01, time/batch = 0.6999s	
1567/29900 (epoch 2.620), train_loss = 2.11050284, grad/param norm = 2.0211e-01, time/batch = 0.6854s	
1568/29900 (epoch 2.622), train_loss = 2.14970761, grad/param norm = 2.3971e-01, time/batch = 0.6831s	
1569/29900 (epoch 2.624), train_loss = 2.09218074, grad/param norm = 2.4115e-01, time/batch = 0.6837s	
1570/29900 (epoch 2.625), train_loss = 2.15079933, grad/param norm = 2.2817e-01, time/batch = 0.6848s	
1571/29900 (epoch 2.627), train_loss = 1.78460687, grad/param norm = 1.8326e-01, time/batch = 0.6890s	
1572/29900 (epoch 2.629), train_loss = 2.07856589, grad/param norm = 2.1773e-01, time/batch = 0.6933s	
1573/29900 (epoch 2.630), train_loss = 2.19278813, grad/param norm = 2.1838e-01, time/batch = 0.6849s	
1574/29900 (epoch 2.632), train_loss = 2.18355243, grad/param norm = 2.3028e-01, time/batch = 0.6824s	
1575/29900 (epoch 2.634), train_loss = 2.03369002, grad/param norm = 2.2377e-01, time/batch = 0.6812s	
1576/29900 (epoch 2.635), train_loss = 2.14929680, grad/param norm = 2.2499e-01, time/batch = 0.6819s	
1577/29900 (epoch 2.637), train_loss = 2.22710342, grad/param norm = 2.3770e-01, time/batch = 0.6855s	
1578/29900 (epoch 2.639), train_loss = 2.12145159, grad/param norm = 2.4479e-01, time/batch = 0.6827s	
1579/29900 (epoch 2.640), train_loss = 2.22398270, grad/param norm = 2.0587e-01, time/batch = 0.6886s	
1580/29900 (epoch 2.642), train_loss = 2.20020204, grad/param norm = 2.4643e-01, time/batch = 0.6868s	
1581/29900 (epoch 2.644), train_loss = 2.00230627, grad/param norm = 2.1187e-01, time/batch = 0.6884s	
1582/29900 (epoch 2.645), train_loss = 2.38916821, grad/param norm = 2.7865e-01, time/batch = 0.6909s	
1583/29900 (epoch 2.647), train_loss = 2.04544306, grad/param norm = 2.2243e-01, time/batch = 0.6847s	
1584/29900 (epoch 2.649), train_loss = 1.86170552, grad/param norm = 1.9560e-01, time/batch = 0.6886s	
1585/29900 (epoch 2.651), train_loss = 1.97506556, grad/param norm = 1.9704e-01, time/batch = 0.6851s	
1586/29900 (epoch 2.652), train_loss = 1.88314871, grad/param norm = 1.9577e-01, time/batch = 0.6906s	
1587/29900 (epoch 2.654), train_loss = 2.12032688, grad/param norm = 2.6145e-01, time/batch = 0.6869s	
1588/29900 (epoch 2.656), train_loss = 2.22299688, grad/param norm = 2.2712e-01, time/batch = 0.7234s	
1589/29900 (epoch 2.657), train_loss = 1.93278503, grad/param norm = 1.8848e-01, time/batch = 0.7031s	
1590/29900 (epoch 2.659), train_loss = 1.78403689, grad/param norm = 2.1825e-01, time/batch = 0.6836s	
1591/29900 (epoch 2.661), train_loss = 2.27231478, grad/param norm = 2.6170e-01, time/batch = 0.6886s	
1592/29900 (epoch 2.662), train_loss = 2.18574468, grad/param norm = 2.0204e-01, time/batch = 0.6846s	
1593/29900 (epoch 2.664), train_loss = 2.06479149, grad/param norm = 2.0739e-01, time/batch = 0.6833s	
1594/29900 (epoch 2.666), train_loss = 1.89560533, grad/param norm = 2.0102e-01, time/batch = 0.6838s	
1595/29900 (epoch 2.667), train_loss = 1.99046561, grad/param norm = 2.0637e-01, time/batch = 0.6826s	
1596/29900 (epoch 2.669), train_loss = 1.85127387, grad/param norm = 1.9350e-01, time/batch = 0.6819s	
1597/29900 (epoch 2.671), train_loss = 2.04136197, grad/param norm = 1.9996e-01, time/batch = 0.6814s	
1598/29900 (epoch 2.672), train_loss = 2.08029875, grad/param norm = 2.2882e-01, time/batch = 0.6830s	
1599/29900 (epoch 2.674), train_loss = 2.08591272, grad/param norm = 1.9972e-01, time/batch = 0.6834s	
1600/29900 (epoch 2.676), train_loss = 1.91328434, grad/param norm = 1.9535e-01, time/batch = 0.6827s	
1601/29900 (epoch 2.677), train_loss = 2.19416891, grad/param norm = 2.1394e-01, time/batch = 0.6997s	
1602/29900 (epoch 2.679), train_loss = 2.25169307, grad/param norm = 2.4110e-01, time/batch = 0.6986s	
1603/29900 (epoch 2.681), train_loss = 2.26468848, grad/param norm = 3.0150e-01, time/batch = 0.7115s	
1604/29900 (epoch 2.682), train_loss = 2.23994773, grad/param norm = 2.2859e-01, time/batch = 0.7141s	
1605/29900 (epoch 2.684), train_loss = 2.20771105, grad/param norm = 2.2303e-01, time/batch = 0.7002s	
1606/29900 (epoch 2.686), train_loss = 2.28144514, grad/param norm = 2.2034e-01, time/batch = 0.7018s	
1607/29900 (epoch 2.687), train_loss = 1.98810440, grad/param norm = 2.3949e-01, time/batch = 0.7258s	
1608/29900 (epoch 2.689), train_loss = 2.10605282, grad/param norm = 2.2407e-01, time/batch = 0.6987s	
1609/29900 (epoch 2.691), train_loss = 2.28987860, grad/param norm = 2.1473e-01, time/batch = 0.6875s	
1610/29900 (epoch 2.692), train_loss = 2.30141906, grad/param norm = 2.3251e-01, time/batch = 0.6854s	
1611/29900 (epoch 2.694), train_loss = 1.93625414, grad/param norm = 1.9242e-01, time/batch = 0.6851s	
1612/29900 (epoch 2.696), train_loss = 1.88255342, grad/param norm = 2.1332e-01, time/batch = 0.6910s	
1613/29900 (epoch 2.697), train_loss = 2.15458441, grad/param norm = 2.2347e-01, time/batch = 0.6890s	
1614/29900 (epoch 2.699), train_loss = 1.93475320, grad/param norm = 2.3413e-01, time/batch = 0.6858s	
1615/29900 (epoch 2.701), train_loss = 2.05151135, grad/param norm = 2.0725e-01, time/batch = 0.6879s	
1616/29900 (epoch 2.702), train_loss = 2.12595301, grad/param norm = 2.1318e-01, time/batch = 0.6847s	
1617/29900 (epoch 2.704), train_loss = 2.03117198, grad/param norm = 2.1978e-01, time/batch = 0.6819s	
1618/29900 (epoch 2.706), train_loss = 1.90423257, grad/param norm = 2.1028e-01, time/batch = 0.6826s	
1619/29900 (epoch 2.707), train_loss = 2.18696599, grad/param norm = 2.3839e-01, time/batch = 0.6914s	
1620/29900 (epoch 2.709), train_loss = 2.20396656, grad/param norm = 2.3789e-01, time/batch = 0.6995s	
1621/29900 (epoch 2.711), train_loss = 2.06038229, grad/param norm = 2.1810e-01, time/batch = 0.6905s	
1622/29900 (epoch 2.712), train_loss = 1.94758428, grad/param norm = 1.9999e-01, time/batch = 0.7138s	
1623/29900 (epoch 2.714), train_loss = 2.09291206, grad/param norm = 2.5068e-01, time/batch = 0.7151s	
1624/29900 (epoch 2.716), train_loss = 2.08121961, grad/param norm = 2.2097e-01, time/batch = 0.6959s	
1625/29900 (epoch 2.717), train_loss = 2.03500519, grad/param norm = 2.1087e-01, time/batch = 0.7101s	
1626/29900 (epoch 2.719), train_loss = 1.96452994, grad/param norm = 2.0295e-01, time/batch = 0.7135s	
1627/29900 (epoch 2.721), train_loss = 2.21624878, grad/param norm = 2.1579e-01, time/batch = 0.6927s	
1628/29900 (epoch 2.722), train_loss = 2.21930849, grad/param norm = 1.9729e-01, time/batch = 0.6998s	
1629/29900 (epoch 2.724), train_loss = 2.13598347, grad/param norm = 2.4815e-01, time/batch = 0.6945s	
1630/29900 (epoch 2.726), train_loss = 2.07368418, grad/param norm = 2.5051e-01, time/batch = 0.6845s	
1631/29900 (epoch 2.727), train_loss = 1.98428801, grad/param norm = 1.9106e-01, time/batch = 0.6871s	
1632/29900 (epoch 2.729), train_loss = 2.05918017, grad/param norm = 2.0219e-01, time/batch = 0.6895s	
1633/29900 (epoch 2.731), train_loss = 1.99027495, grad/param norm = 2.2792e-01, time/batch = 0.6832s	
1634/29900 (epoch 2.732), train_loss = 2.29271785, grad/param norm = 2.7997e-01, time/batch = 0.6812s	
1635/29900 (epoch 2.734), train_loss = 2.24443488, grad/param norm = 3.0987e-01, time/batch = 0.6831s	
1636/29900 (epoch 2.736), train_loss = 2.20788063, grad/param norm = 2.4019e-01, time/batch = 0.6875s	
1637/29900 (epoch 2.737), train_loss = 1.94419519, grad/param norm = 2.0941e-01, time/batch = 0.6822s	
1638/29900 (epoch 2.739), train_loss = 2.24026104, grad/param norm = 2.6352e-01, time/batch = 0.6863s	
1639/29900 (epoch 2.741), train_loss = 1.94708776, grad/param norm = 2.0606e-01, time/batch = 0.6907s	
1640/29900 (epoch 2.742), train_loss = 1.97692080, grad/param norm = 2.4838e-01, time/batch = 0.6875s	
1641/29900 (epoch 2.744), train_loss = 1.90199327, grad/param norm = 2.1850e-01, time/batch = 0.6840s	
1642/29900 (epoch 2.746), train_loss = 1.99310440, grad/param norm = 2.0775e-01, time/batch = 0.6841s	
1643/29900 (epoch 2.747), train_loss = 2.20212512, grad/param norm = 2.1931e-01, time/batch = 0.6846s	
1644/29900 (epoch 2.749), train_loss = 2.03122643, grad/param norm = 2.1654e-01, time/batch = 0.7214s	
1645/29900 (epoch 2.751), train_loss = 2.14887013, grad/param norm = 2.4687e-01, time/batch = 0.7039s	
1646/29900 (epoch 2.753), train_loss = 2.28037242, grad/param norm = 2.3038e-01, time/batch = 0.6856s	
1647/29900 (epoch 2.754), train_loss = 1.95230528, grad/param norm = 1.9820e-01, time/batch = 0.6835s	
1648/29900 (epoch 2.756), train_loss = 2.12238327, grad/param norm = 1.9956e-01, time/batch = 0.6826s	
1649/29900 (epoch 2.758), train_loss = 2.18014901, grad/param norm = 2.4171e-01, time/batch = 0.6834s	
1650/29900 (epoch 2.759), train_loss = 2.14724643, grad/param norm = 2.3232e-01, time/batch = 0.6833s	
1651/29900 (epoch 2.761), train_loss = 2.07328959, grad/param norm = 2.0170e-01, time/batch = 0.6841s	
1652/29900 (epoch 2.763), train_loss = 2.10968663, grad/param norm = 1.8962e-01, time/batch = 0.6848s	
1653/29900 (epoch 2.764), train_loss = 2.10318199, grad/param norm = 1.9425e-01, time/batch = 0.6831s	
1654/29900 (epoch 2.766), train_loss = 2.06516712, grad/param norm = 2.3562e-01, time/batch = 0.6866s	
1655/29900 (epoch 2.768), train_loss = 1.98265070, grad/param norm = 2.0138e-01, time/batch = 0.6831s	
1656/29900 (epoch 2.769), train_loss = 2.09924152, grad/param norm = 2.3973e-01, time/batch = 0.6822s	
1657/29900 (epoch 2.771), train_loss = 2.06990050, grad/param norm = 2.1699e-01, time/batch = 0.6829s	
1658/29900 (epoch 2.773), train_loss = 2.12847790, grad/param norm = 2.2603e-01, time/batch = 0.6858s	
1659/29900 (epoch 2.774), train_loss = 2.04848383, grad/param norm = 2.3649e-01, time/batch = 0.6849s	
1660/29900 (epoch 2.776), train_loss = 1.90927706, grad/param norm = 2.0059e-01, time/batch = 0.6833s	
1661/29900 (epoch 2.778), train_loss = 2.13558050, grad/param norm = 2.1752e-01, time/batch = 0.6861s	
1662/29900 (epoch 2.779), train_loss = 2.13748048, grad/param norm = 2.1700e-01, time/batch = 0.6914s	
1663/29900 (epoch 2.781), train_loss = 1.87893998, grad/param norm = 2.1130e-01, time/batch = 0.7257s	
1664/29900 (epoch 2.783), train_loss = 2.02960289, grad/param norm = 2.2670e-01, time/batch = 0.6982s	
1665/29900 (epoch 2.784), train_loss = 2.08316999, grad/param norm = 2.2839e-01, time/batch = 0.6988s	
1666/29900 (epoch 2.786), train_loss = 2.17413145, grad/param norm = 2.0158e-01, time/batch = 0.7262s	
1667/29900 (epoch 2.788), train_loss = 2.15872933, grad/param norm = 2.3372e-01, time/batch = 0.7009s	
1668/29900 (epoch 2.789), train_loss = 2.00870017, grad/param norm = 2.4846e-01, time/batch = 0.6833s	
1669/29900 (epoch 2.791), train_loss = 1.97454463, grad/param norm = 2.0355e-01, time/batch = 0.6844s	
1670/29900 (epoch 2.793), train_loss = 1.90316572, grad/param norm = 2.1477e-01, time/batch = 0.6830s	
1671/29900 (epoch 2.794), train_loss = 2.11840923, grad/param norm = 2.0455e-01, time/batch = 0.6819s	
1672/29900 (epoch 2.796), train_loss = 2.16203209, grad/param norm = 2.2934e-01, time/batch = 0.6821s	
1673/29900 (epoch 2.798), train_loss = 2.11692274, grad/param norm = 2.0688e-01, time/batch = 0.6807s	
1674/29900 (epoch 2.799), train_loss = 2.04061108, grad/param norm = 2.2859e-01, time/batch = 0.6804s	
1675/29900 (epoch 2.801), train_loss = 2.11517416, grad/param norm = 2.6236e-01, time/batch = 0.6811s	
1676/29900 (epoch 2.803), train_loss = 2.20885056, grad/param norm = 2.7369e-01, time/batch = 0.6811s	
1677/29900 (epoch 2.804), train_loss = 2.31336897, grad/param norm = 2.4829e-01, time/batch = 0.6843s	
1678/29900 (epoch 2.806), train_loss = 1.95129352, grad/param norm = 2.2289e-01, time/batch = 0.6851s	
1679/29900 (epoch 2.808), train_loss = 2.12771882, grad/param norm = 2.1705e-01, time/batch = 0.6815s	
1680/29900 (epoch 2.809), train_loss = 2.19486259, grad/param norm = 2.1677e-01, time/batch = 0.6809s	
1681/29900 (epoch 2.811), train_loss = 2.09781013, grad/param norm = 2.1818e-01, time/batch = 0.6977s	
1682/29900 (epoch 2.813), train_loss = 2.27143103, grad/param norm = 2.1379e-01, time/batch = 0.7268s	
1683/29900 (epoch 2.814), train_loss = 2.28700715, grad/param norm = 2.2168e-01, time/batch = 0.6830s	
1684/29900 (epoch 2.816), train_loss = 2.39654070, grad/param norm = 2.3101e-01, time/batch = 0.6837s	
1685/29900 (epoch 2.818), train_loss = 2.24312204, grad/param norm = 2.3901e-01, time/batch = 0.6824s	
1686/29900 (epoch 2.819), train_loss = 2.42802687, grad/param norm = 2.1095e-01, time/batch = 0.6800s	
1687/29900 (epoch 2.821), train_loss = 2.10422263, grad/param norm = 1.9754e-01, time/batch = 0.6822s	
1688/29900 (epoch 2.823), train_loss = 2.10433107, grad/param norm = 2.1365e-01, time/batch = 0.6816s	
1689/29900 (epoch 2.824), train_loss = 2.21961717, grad/param norm = 2.2131e-01, time/batch = 0.6807s	
1690/29900 (epoch 2.826), train_loss = 2.24493368, grad/param norm = 2.4956e-01, time/batch = 0.6868s	
1691/29900 (epoch 2.828), train_loss = 2.11204223, grad/param norm = 2.1818e-01, time/batch = 0.6892s	
1692/29900 (epoch 2.829), train_loss = 2.07477941, grad/param norm = 2.2766e-01, time/batch = 0.6871s	
1693/29900 (epoch 2.831), train_loss = 2.18071668, grad/param norm = 2.2816e-01, time/batch = 0.6827s	
1694/29900 (epoch 2.833), train_loss = 2.02120200, grad/param norm = 2.0307e-01, time/batch = 0.6818s	
1695/29900 (epoch 2.834), train_loss = 2.02794787, grad/param norm = 2.2539e-01, time/batch = 0.6812s	
1696/29900 (epoch 2.836), train_loss = 2.15327325, grad/param norm = 2.0805e-01, time/batch = 0.6849s	
1697/29900 (epoch 2.838), train_loss = 2.22252135, grad/param norm = 2.3769e-01, time/batch = 0.6937s	
1698/29900 (epoch 2.839), train_loss = 1.99582239, grad/param norm = 2.2951e-01, time/batch = 0.6823s	
1699/29900 (epoch 2.841), train_loss = 2.29907869, grad/param norm = 2.5468e-01, time/batch = 0.6836s	
1700/29900 (epoch 2.843), train_loss = 2.08459455, grad/param norm = 2.6420e-01, time/batch = 0.7028s	
1701/29900 (epoch 2.844), train_loss = 2.05047498, grad/param norm = 2.1700e-01, time/batch = 0.6877s	
1702/29900 (epoch 2.846), train_loss = 2.04173210, grad/param norm = 2.1222e-01, time/batch = 0.6999s	
1703/29900 (epoch 2.848), train_loss = 2.03785692, grad/param norm = 1.9236e-01, time/batch = 0.6818s	
1704/29900 (epoch 2.849), train_loss = 2.14041971, grad/param norm = 2.4845e-01, time/batch = 0.6820s	
1705/29900 (epoch 2.851), train_loss = 2.15721670, grad/param norm = 2.3675e-01, time/batch = 0.6823s	
1706/29900 (epoch 2.853), train_loss = 2.04349250, grad/param norm = 2.2832e-01, time/batch = 0.7017s	
1707/29900 (epoch 2.855), train_loss = 2.02989876, grad/param norm = 1.9544e-01, time/batch = 0.6953s	
1708/29900 (epoch 2.856), train_loss = 2.02182963, grad/param norm = 2.3870e-01, time/batch = 0.6823s	
1709/29900 (epoch 2.858), train_loss = 1.93585556, grad/param norm = 1.9900e-01, time/batch = 0.7317s	
1710/29900 (epoch 2.860), train_loss = 1.86345799, grad/param norm = 1.9938e-01, time/batch = 0.6936s	
1711/29900 (epoch 2.861), train_loss = 2.16846745, grad/param norm = 2.5080e-01, time/batch = 0.6912s	
1712/29900 (epoch 2.863), train_loss = 2.00632411, grad/param norm = 2.6853e-01, time/batch = 0.6832s	
1713/29900 (epoch 2.865), train_loss = 1.83104675, grad/param norm = 2.2196e-01, time/batch = 0.6862s	
1714/29900 (epoch 2.866), train_loss = 2.02441866, grad/param norm = 2.0851e-01, time/batch = 0.6865s	
1715/29900 (epoch 2.868), train_loss = 2.08833979, grad/param norm = 2.2620e-01, time/batch = 0.6898s	
1716/29900 (epoch 2.870), train_loss = 2.24182677, grad/param norm = 2.2117e-01, time/batch = 0.6872s	
1717/29900 (epoch 2.871), train_loss = 1.99349372, grad/param norm = 2.1881e-01, time/batch = 0.6828s	
1718/29900 (epoch 2.873), train_loss = 2.12582608, grad/param norm = 2.3322e-01, time/batch = 0.6882s	
1719/29900 (epoch 2.875), train_loss = 2.14943153, grad/param norm = 1.9791e-01, time/batch = 0.7160s	
1720/29900 (epoch 2.876), train_loss = 1.92934636, grad/param norm = 1.9951e-01, time/batch = 0.7115s	
1721/29900 (epoch 2.878), train_loss = 2.14916446, grad/param norm = 2.0313e-01, time/batch = 0.7103s	
1722/29900 (epoch 2.880), train_loss = 1.89743654, grad/param norm = 2.0871e-01, time/batch = 0.7189s	
1723/29900 (epoch 2.881), train_loss = 2.28327287, grad/param norm = 2.1614e-01, time/batch = 0.7147s	
1724/29900 (epoch 2.883), train_loss = 2.15869886, grad/param norm = 2.2673e-01, time/batch = 0.7032s	
1725/29900 (epoch 2.885), train_loss = 2.26359443, grad/param norm = 1.9218e-01, time/batch = 0.7086s	
1726/29900 (epoch 2.886), train_loss = 2.27898591, grad/param norm = 2.0419e-01, time/batch = 0.7146s	
1727/29900 (epoch 2.888), train_loss = 2.08394772, grad/param norm = 1.9190e-01, time/batch = 0.7174s	
1728/29900 (epoch 2.890), train_loss = 1.99170715, grad/param norm = 2.0691e-01, time/batch = 0.7138s	
1729/29900 (epoch 2.891), train_loss = 2.07044663, grad/param norm = 2.1034e-01, time/batch = 0.7190s	
1730/29900 (epoch 2.893), train_loss = 1.96094130, grad/param norm = 2.1923e-01, time/batch = 0.7120s	
1731/29900 (epoch 2.895), train_loss = 1.99566593, grad/param norm = 2.1283e-01, time/batch = 0.7118s	
1732/29900 (epoch 2.896), train_loss = 2.04058358, grad/param norm = 2.0027e-01, time/batch = 0.7025s	
1733/29900 (epoch 2.898), train_loss = 2.11361569, grad/param norm = 2.2470e-01, time/batch = 0.7197s	
1734/29900 (epoch 2.900), train_loss = 2.10862692, grad/param norm = 2.0918e-01, time/batch = 0.7057s	
1735/29900 (epoch 2.901), train_loss = 1.93398266, grad/param norm = 1.8105e-01, time/batch = 0.6837s	
1736/29900 (epoch 2.903), train_loss = 1.92395949, grad/param norm = 1.9008e-01, time/batch = 0.6850s	
1737/29900 (epoch 2.905), train_loss = 2.08815912, grad/param norm = 2.2748e-01, time/batch = 0.6849s	
1738/29900 (epoch 2.906), train_loss = 2.33374853, grad/param norm = 2.3950e-01, time/batch = 0.6832s	
1739/29900 (epoch 2.908), train_loss = 2.12436450, grad/param norm = 2.0697e-01, time/batch = 0.6822s	
1740/29900 (epoch 2.910), train_loss = 2.01656583, grad/param norm = 2.1055e-01, time/batch = 0.6835s	
1741/29900 (epoch 2.911), train_loss = 1.98977727, grad/param norm = 2.3420e-01, time/batch = 0.6844s	
1742/29900 (epoch 2.913), train_loss = 1.81917704, grad/param norm = 1.9015e-01, time/batch = 0.6816s	
1743/29900 (epoch 2.915), train_loss = 2.08311616, grad/param norm = 2.5308e-01, time/batch = 0.6828s	
1744/29900 (epoch 2.916), train_loss = 1.84579335, grad/param norm = 1.9802e-01, time/batch = 0.6844s	
1745/29900 (epoch 2.918), train_loss = 2.18356212, grad/param norm = 2.2208e-01, time/batch = 0.6848s	
1746/29900 (epoch 2.920), train_loss = 2.38430754, grad/param norm = 2.1673e-01, time/batch = 0.6808s	
1747/29900 (epoch 2.921), train_loss = 2.30940186, grad/param norm = 2.2248e-01, time/batch = 0.6819s	
1748/29900 (epoch 2.923), train_loss = 2.15249033, grad/param norm = 1.9892e-01, time/batch = 0.6829s	
1749/29900 (epoch 2.925), train_loss = 2.01867711, grad/param norm = 2.0614e-01, time/batch = 0.6821s	
1750/29900 (epoch 2.926), train_loss = 1.91280805, grad/param norm = 2.1695e-01, time/batch = 0.6822s	
1751/29900 (epoch 2.928), train_loss = 2.01619669, grad/param norm = 2.1147e-01, time/batch = 0.6838s	
1752/29900 (epoch 2.930), train_loss = 1.99374289, grad/param norm = 2.1389e-01, time/batch = 0.6917s	
1753/29900 (epoch 2.931), train_loss = 1.86635492, grad/param norm = 2.0184e-01, time/batch = 0.6873s	
1754/29900 (epoch 2.933), train_loss = 2.01437280, grad/param norm = 1.9439e-01, time/batch = 0.6815s	
1755/29900 (epoch 2.935), train_loss = 2.34865186, grad/param norm = 2.1331e-01, time/batch = 0.6875s	
1756/29900 (epoch 2.936), train_loss = 2.12107267, grad/param norm = 2.2850e-01, time/batch = 0.7094s	
1757/29900 (epoch 2.938), train_loss = 1.82268457, grad/param norm = 2.0434e-01, time/batch = 0.7148s	
1758/29900 (epoch 2.940), train_loss = 1.97615836, grad/param norm = 2.0847e-01, time/batch = 0.6830s	
1759/29900 (epoch 2.941), train_loss = 1.97877959, grad/param norm = 2.0779e-01, time/batch = 0.6838s	
1760/29900 (epoch 2.943), train_loss = 2.07095917, grad/param norm = 1.9259e-01, time/batch = 0.6866s	
1761/29900 (epoch 2.945), train_loss = 2.22450386, grad/param norm = 2.4361e-01, time/batch = 0.6821s	
1762/29900 (epoch 2.946), train_loss = 2.14931765, grad/param norm = 2.2853e-01, time/batch = 0.6820s	
1763/29900 (epoch 2.948), train_loss = 1.91590608, grad/param norm = 1.9664e-01, time/batch = 0.6954s	
1764/29900 (epoch 2.950), train_loss = 2.17322210, grad/param norm = 2.0333e-01, time/batch = 0.6936s	
1765/29900 (epoch 2.952), train_loss = 1.82987481, grad/param norm = 1.9006e-01, time/batch = 0.6873s	
1766/29900 (epoch 2.953), train_loss = 1.82427078, grad/param norm = 1.9561e-01, time/batch = 0.6875s	
1767/29900 (epoch 2.955), train_loss = 2.10193927, grad/param norm = 2.1859e-01, time/batch = 0.6827s	
1768/29900 (epoch 2.957), train_loss = 2.14441342, grad/param norm = 2.3284e-01, time/batch = 0.6838s	
1769/29900 (epoch 2.958), train_loss = 2.22666362, grad/param norm = 1.9582e-01, time/batch = 0.6812s	
1770/29900 (epoch 2.960), train_loss = 2.23097456, grad/param norm = 2.0970e-01, time/batch = 0.6812s	
1771/29900 (epoch 2.962), train_loss = 2.29228276, grad/param norm = 2.6258e-01, time/batch = 0.6830s	
1772/29900 (epoch 2.963), train_loss = 2.01340720, grad/param norm = 1.8823e-01, time/batch = 0.6823s	
1773/29900 (epoch 2.965), train_loss = 2.12799936, grad/param norm = 2.2194e-01, time/batch = 0.6830s	
1774/29900 (epoch 2.967), train_loss = 1.94514379, grad/param norm = 2.2194e-01, time/batch = 0.6848s	
1775/29900 (epoch 2.968), train_loss = 2.18935811, grad/param norm = 2.2147e-01, time/batch = 0.7252s	
1776/29900 (epoch 2.970), train_loss = 2.01217855, grad/param norm = 2.0898e-01, time/batch = 0.7067s	
1777/29900 (epoch 2.972), train_loss = 1.75167736, grad/param norm = 1.9717e-01, time/batch = 0.6816s	
1778/29900 (epoch 2.973), train_loss = 1.80065705, grad/param norm = 1.9539e-01, time/batch = 0.6812s	
1779/29900 (epoch 2.975), train_loss = 2.10349275, grad/param norm = 2.2673e-01, time/batch = 0.6832s	
1780/29900 (epoch 2.977), train_loss = 1.96613343, grad/param norm = 1.7742e-01, time/batch = 0.6817s	
1781/29900 (epoch 2.978), train_loss = 1.96815652, grad/param norm = 2.1029e-01, time/batch = 0.6834s	
1782/29900 (epoch 2.980), train_loss = 2.13070528, grad/param norm = 2.0324e-01, time/batch = 0.6861s	
1783/29900 (epoch 2.982), train_loss = 2.05919773, grad/param norm = 2.1159e-01, time/batch = 0.6843s	
1784/29900 (epoch 2.983), train_loss = 2.12588190, grad/param norm = 2.4085e-01, time/batch = 0.6839s	
1785/29900 (epoch 2.985), train_loss = 2.22084663, grad/param norm = 2.2722e-01, time/batch = 0.7012s	
1786/29900 (epoch 2.987), train_loss = 2.01227997, grad/param norm = 2.0734e-01, time/batch = 0.6900s	
1787/29900 (epoch 2.988), train_loss = 2.02464855, grad/param norm = 1.8516e-01, time/batch = 0.6803s	
1788/29900 (epoch 2.990), train_loss = 1.97588741, grad/param norm = 2.0796e-01, time/batch = 0.6860s	
1789/29900 (epoch 2.992), train_loss = 1.78510562, grad/param norm = 2.0845e-01, time/batch = 0.6983s	
1790/29900 (epoch 2.993), train_loss = 2.04722595, grad/param norm = 1.8597e-01, time/batch = 0.7181s	
1791/29900 (epoch 2.995), train_loss = 2.01923055, grad/param norm = 1.8172e-01, time/batch = 0.7109s	
1792/29900 (epoch 2.997), train_loss = 2.07623264, grad/param norm = 1.9113e-01, time/batch = 0.7062s	
1793/29900 (epoch 2.998), train_loss = 2.00710938, grad/param norm = 2.1993e-01, time/batch = 0.7079s	
1794/29900 (epoch 3.000), train_loss = 1.95137405, grad/param norm = 1.9711e-01, time/batch = 0.7303s	
1795/29900 (epoch 3.002), train_loss = 2.09423598, grad/param norm = 2.2096e-01, time/batch = 0.7044s	
1796/29900 (epoch 3.003), train_loss = 2.05842709, grad/param norm = 2.2064e-01, time/batch = 0.6841s	
1797/29900 (epoch 3.005), train_loss = 2.05517493, grad/param norm = 2.2077e-01, time/batch = 0.6829s	
1798/29900 (epoch 3.007), train_loss = 2.11569028, grad/param norm = 2.1667e-01, time/batch = 0.6829s	
1799/29900 (epoch 3.008), train_loss = 2.09390470, grad/param norm = 2.4150e-01, time/batch = 0.6861s	
1800/29900 (epoch 3.010), train_loss = 2.02062898, grad/param norm = 1.9478e-01, time/batch = 0.6858s	
1801/29900 (epoch 3.012), train_loss = 1.90547788, grad/param norm = 1.8332e-01, time/batch = 0.6982s	
1802/29900 (epoch 3.013), train_loss = 2.01429889, grad/param norm = 2.1809e-01, time/batch = 0.6950s	
1803/29900 (epoch 3.015), train_loss = 2.04502460, grad/param norm = 2.5037e-01, time/batch = 0.6868s	
1804/29900 (epoch 3.017), train_loss = 2.03830907, grad/param norm = 2.4254e-01, time/batch = 0.6841s	
1805/29900 (epoch 3.018), train_loss = 2.14420805, grad/param norm = 2.4011e-01, time/batch = 0.6852s	
1806/29900 (epoch 3.020), train_loss = 2.13038334, grad/param norm = 2.2069e-01, time/batch = 0.6877s	
1807/29900 (epoch 3.022), train_loss = 2.03256295, grad/param norm = 2.2329e-01, time/batch = 0.6822s	
1808/29900 (epoch 3.023), train_loss = 2.16590607, grad/param norm = 2.1462e-01, time/batch = 0.7146s	
1809/29900 (epoch 3.025), train_loss = 2.05538698, grad/param norm = 2.1326e-01, time/batch = 0.7083s	
1810/29900 (epoch 3.027), train_loss = 1.86886466, grad/param norm = 2.0298e-01, time/batch = 0.6820s	
1811/29900 (epoch 3.028), train_loss = 2.22018214, grad/param norm = 2.2335e-01, time/batch = 0.6845s	
1812/29900 (epoch 3.030), train_loss = 2.15039468, grad/param norm = 2.2849e-01, time/batch = 0.6837s	
1813/29900 (epoch 3.032), train_loss = 1.98567363, grad/param norm = 2.2099e-01, time/batch = 0.6846s	
1814/29900 (epoch 3.033), train_loss = 2.06900975, grad/param norm = 2.0707e-01, time/batch = 0.6932s	
1815/29900 (epoch 3.035), train_loss = 1.92886598, grad/param norm = 2.0804e-01, time/batch = 0.6839s	
1816/29900 (epoch 3.037), train_loss = 1.98865645, grad/param norm = 1.8835e-01, time/batch = 0.6940s	
1817/29900 (epoch 3.038), train_loss = 2.08257554, grad/param norm = 2.2772e-01, time/batch = 0.6957s	
1818/29900 (epoch 3.040), train_loss = 1.83287540, grad/param norm = 2.5975e-01, time/batch = 0.6836s	
1819/29900 (epoch 3.042), train_loss = 1.96938324, grad/param norm = 2.5056e-01, time/batch = 0.6819s	
1820/29900 (epoch 3.043), train_loss = 2.16370062, grad/param norm = 2.2412e-01, time/batch = 0.6852s	
1821/29900 (epoch 3.045), train_loss = 2.03040184, grad/param norm = 2.0878e-01, time/batch = 0.6922s	
1822/29900 (epoch 3.047), train_loss = 2.02088398, grad/param norm = 2.3295e-01, time/batch = 0.6851s	
1823/29900 (epoch 3.048), train_loss = 1.87426958, grad/param norm = 2.4252e-01, time/batch = 0.6811s	
1824/29900 (epoch 3.050), train_loss = 1.83269382, grad/param norm = 1.8249e-01, time/batch = 0.6888s	
1825/29900 (epoch 3.052), train_loss = 1.85138568, grad/param norm = 1.7653e-01, time/batch = 0.6927s	
1826/29900 (epoch 3.054), train_loss = 2.11336392, grad/param norm = 2.3896e-01, time/batch = 0.6905s	
1827/29900 (epoch 3.055), train_loss = 2.05191293, grad/param norm = 2.6456e-01, time/batch = 0.7253s	
1828/29900 (epoch 3.057), train_loss = 1.97029725, grad/param norm = 2.0753e-01, time/batch = 0.6996s	
1829/29900 (epoch 3.059), train_loss = 2.16426005, grad/param norm = 2.1920e-01, time/batch = 0.6828s	
1830/29900 (epoch 3.060), train_loss = 2.08873684, grad/param norm = 2.3368e-01, time/batch = 0.6864s	
1831/29900 (epoch 3.062), train_loss = 2.00897544, grad/param norm = 1.9697e-01, time/batch = 0.6819s	
1832/29900 (epoch 3.064), train_loss = 2.04964551, grad/param norm = 2.0920e-01, time/batch = 0.6829s	
1833/29900 (epoch 3.065), train_loss = 2.25071724, grad/param norm = 2.1542e-01, time/batch = 0.6854s	
1834/29900 (epoch 3.067), train_loss = 2.02000424, grad/param norm = 1.9864e-01, time/batch = 0.6881s	
1835/29900 (epoch 3.069), train_loss = 2.03434437, grad/param norm = 1.9524e-01, time/batch = 0.6873s	
1836/29900 (epoch 3.070), train_loss = 2.01538105, grad/param norm = 2.0020e-01, time/batch = 0.6866s	
1837/29900 (epoch 3.072), train_loss = 2.00625052, grad/param norm = 2.1692e-01, time/batch = 0.6848s	
1838/29900 (epoch 3.074), train_loss = 2.08857649, grad/param norm = 2.3038e-01, time/batch = 0.6845s	
1839/29900 (epoch 3.075), train_loss = 1.97306857, grad/param norm = 2.0323e-01, time/batch = 0.6844s	
1840/29900 (epoch 3.077), train_loss = 1.87093362, grad/param norm = 2.0746e-01, time/batch = 0.6823s	
1841/29900 (epoch 3.079), train_loss = 1.94717271, grad/param norm = 2.4596e-01, time/batch = 0.6860s	
1842/29900 (epoch 3.080), train_loss = 1.81464509, grad/param norm = 2.3202e-01, time/batch = 0.6835s	
1843/29900 (epoch 3.082), train_loss = 1.85021992, grad/param norm = 2.0032e-01, time/batch = 0.6835s	
1844/29900 (epoch 3.084), train_loss = 2.21838074, grad/param norm = 2.0796e-01, time/batch = 0.6815s	
1845/29900 (epoch 3.085), train_loss = 2.17950311, grad/param norm = 1.9492e-01, time/batch = 0.6928s	
1846/29900 (epoch 3.087), train_loss = 2.20019116, grad/param norm = 2.0302e-01, time/batch = 0.7253s	
1847/29900 (epoch 3.089), train_loss = 1.97458231, grad/param norm = 2.1580e-01, time/batch = 0.6904s	
1848/29900 (epoch 3.090), train_loss = 1.94119162, grad/param norm = 2.3259e-01, time/batch = 0.6836s	
1849/29900 (epoch 3.092), train_loss = 1.82584657, grad/param norm = 2.0780e-01, time/batch = 0.6818s	
1850/29900 (epoch 3.094), train_loss = 2.04374374, grad/param norm = 2.0594e-01, time/batch = 0.6829s	
1851/29900 (epoch 3.095), train_loss = 2.02678704, grad/param norm = 1.9814e-01, time/batch = 0.6838s	
1852/29900 (epoch 3.097), train_loss = 1.93307612, grad/param norm = 2.1751e-01, time/batch = 0.6868s	
1853/29900 (epoch 3.099), train_loss = 1.99106534, grad/param norm = 2.1427e-01, time/batch = 0.6846s	
1854/29900 (epoch 3.100), train_loss = 1.66455986, grad/param norm = 2.0332e-01, time/batch = 0.6829s	
1855/29900 (epoch 3.102), train_loss = 1.93324951, grad/param norm = 2.3624e-01, time/batch = 0.6822s	
1856/29900 (epoch 3.104), train_loss = 2.06182853, grad/param norm = 2.3319e-01, time/batch = 0.6834s	
1857/29900 (epoch 3.105), train_loss = 2.01982646, grad/param norm = 1.9326e-01, time/batch = 0.6823s	
1858/29900 (epoch 3.107), train_loss = 1.95445047, grad/param norm = 2.0447e-01, time/batch = 0.6854s	
1859/29900 (epoch 3.109), train_loss = 2.07797516, grad/param norm = 2.1400e-01, time/batch = 0.6829s	
1860/29900 (epoch 3.110), train_loss = 1.99675400, grad/param norm = 2.1994e-01, time/batch = 0.6830s	
1861/29900 (epoch 3.112), train_loss = 2.05639009, grad/param norm = 1.9783e-01, time/batch = 0.6878s	
1862/29900 (epoch 3.114), train_loss = 1.91646039, grad/param norm = 2.0502e-01, time/batch = 0.6831s	
1863/29900 (epoch 3.115), train_loss = 1.99013202, grad/param norm = 2.1373e-01, time/batch = 0.6834s	
1864/29900 (epoch 3.117), train_loss = 1.96056694, grad/param norm = 2.3784e-01, time/batch = 0.6989s	
1865/29900 (epoch 3.119), train_loss = 1.85048541, grad/param norm = 2.0197e-01, time/batch = 0.7253s	
1866/29900 (epoch 3.120), train_loss = 2.06027582, grad/param norm = 2.3036e-01, time/batch = 0.6826s	
1867/29900 (epoch 3.122), train_loss = 2.12506872, grad/param norm = 2.2823e-01, time/batch = 0.6836s	
1868/29900 (epoch 3.124), train_loss = 2.04564725, grad/param norm = 2.0407e-01, time/batch = 0.6914s	
1869/29900 (epoch 3.125), train_loss = 1.87898829, grad/param norm = 1.9668e-01, time/batch = 0.6852s	
1870/29900 (epoch 3.127), train_loss = 2.02719611, grad/param norm = 2.1272e-01, time/batch = 0.6829s	
1871/29900 (epoch 3.129), train_loss = 2.06479062, grad/param norm = 2.2868e-01, time/batch = 0.6846s	
1872/29900 (epoch 3.130), train_loss = 1.90136784, grad/param norm = 2.0483e-01, time/batch = 0.6843s	
1873/29900 (epoch 3.132), train_loss = 1.91562792, grad/param norm = 2.1358e-01, time/batch = 0.6837s	
1874/29900 (epoch 3.134), train_loss = 2.14733614, grad/param norm = 1.9495e-01, time/batch = 0.6849s	
1875/29900 (epoch 3.135), train_loss = 1.86133421, grad/param norm = 2.2213e-01, time/batch = 0.6849s	
1876/29900 (epoch 3.137), train_loss = 1.86872543, grad/param norm = 2.0112e-01, time/batch = 0.6874s	
1877/29900 (epoch 3.139), train_loss = 1.98132282, grad/param norm = 2.3153e-01, time/batch = 0.6871s	
1878/29900 (epoch 3.140), train_loss = 1.97389564, grad/param norm = 1.9838e-01, time/batch = 0.6833s	
1879/29900 (epoch 3.142), train_loss = 1.82136865, grad/param norm = 1.8953e-01, time/batch = 0.7019s	
1880/29900 (epoch 3.144), train_loss = 1.92947268, grad/param norm = 2.0553e-01, time/batch = 0.7016s	
1881/29900 (epoch 3.145), train_loss = 1.98808073, grad/param norm = 2.1107e-01, time/batch = 0.6976s	
1882/29900 (epoch 3.147), train_loss = 1.78886602, grad/param norm = 2.0288e-01, time/batch = 0.6877s	
1883/29900 (epoch 3.149), train_loss = 1.82141269, grad/param norm = 2.1382e-01, time/batch = 0.7003s	
1884/29900 (epoch 3.151), train_loss = 1.88087056, grad/param norm = 2.3653e-01, time/batch = 0.6926s	
1885/29900 (epoch 3.152), train_loss = 1.96707368, grad/param norm = 2.2050e-01, time/batch = 0.6919s	
1886/29900 (epoch 3.154), train_loss = 1.95178082, grad/param norm = 2.1076e-01, time/batch = 0.6823s	
1887/29900 (epoch 3.156), train_loss = 2.01670668, grad/param norm = 1.9178e-01, time/batch = 0.6965s	
1888/29900 (epoch 3.157), train_loss = 2.01691553, grad/param norm = 2.0117e-01, time/batch = 0.7253s	
1889/29900 (epoch 3.159), train_loss = 1.95887298, grad/param norm = 2.0318e-01, time/batch = 0.7076s	
1890/29900 (epoch 3.161), train_loss = 2.09556563, grad/param norm = 2.2309e-01, time/batch = 0.6945s	
1891/29900 (epoch 3.162), train_loss = 2.01436199, grad/param norm = 2.0226e-01, time/batch = 0.6851s	
1892/29900 (epoch 3.164), train_loss = 2.17763764, grad/param norm = 1.9127e-01, time/batch = 0.7061s	
1893/29900 (epoch 3.166), train_loss = 1.87275689, grad/param norm = 1.8100e-01, time/batch = 0.6830s	
1894/29900 (epoch 3.167), train_loss = 2.09648337, grad/param norm = 1.9214e-01, time/batch = 0.6842s	
1895/29900 (epoch 3.169), train_loss = 1.79014699, grad/param norm = 2.1441e-01, time/batch = 0.6797s	
1896/29900 (epoch 3.171), train_loss = 1.89597622, grad/param norm = 1.9401e-01, time/batch = 0.6866s	
1897/29900 (epoch 3.172), train_loss = 1.95906089, grad/param norm = 1.9204e-01, time/batch = 0.6824s	
1898/29900 (epoch 3.174), train_loss = 1.89912432, grad/param norm = 2.0507e-01, time/batch = 0.6894s	
1899/29900 (epoch 3.176), train_loss = 1.89335051, grad/param norm = 2.0633e-01, time/batch = 0.6914s	
1900/29900 (epoch 3.177), train_loss = 1.78905982, grad/param norm = 2.0871e-01, time/batch = 0.6796s	
1901/29900 (epoch 3.179), train_loss = 1.94948212, grad/param norm = 2.5938e-01, time/batch = 0.6844s	
1902/29900 (epoch 3.181), train_loss = 1.82555706, grad/param norm = 2.1541e-01, time/batch = 0.6845s	
1903/29900 (epoch 3.182), train_loss = 1.99922823, grad/param norm = 2.1998e-01, time/batch = 0.6830s	
1904/29900 (epoch 3.184), train_loss = 1.90746589, grad/param norm = 2.2388e-01, time/batch = 0.6837s	
1905/29900 (epoch 3.186), train_loss = 1.82146923, grad/param norm = 1.9086e-01, time/batch = 0.6838s	
1906/29900 (epoch 3.187), train_loss = 1.90727472, grad/param norm = 1.8791e-01, time/batch = 0.6859s	
1907/29900 (epoch 3.189), train_loss = 1.95848919, grad/param norm = 1.9196e-01, time/batch = 0.6860s	
1908/29900 (epoch 3.191), train_loss = 1.90824636, grad/param norm = 2.2768e-01, time/batch = 0.6823s	
1909/29900 (epoch 3.192), train_loss = 2.03216400, grad/param norm = 2.0026e-01, time/batch = 0.6821s	
1910/29900 (epoch 3.194), train_loss = 1.97552183, grad/param norm = 1.9558e-01, time/batch = 0.6829s	
1911/29900 (epoch 3.196), train_loss = 2.04141917, grad/param norm = 2.1042e-01, time/batch = 0.6833s	
1912/29900 (epoch 3.197), train_loss = 1.77181080, grad/param norm = 1.8579e-01, time/batch = 0.6846s	
1913/29900 (epoch 3.199), train_loss = 1.99261920, grad/param norm = 2.2595e-01, time/batch = 0.6911s	
1914/29900 (epoch 3.201), train_loss = 2.07881422, grad/param norm = 1.8510e-01, time/batch = 0.7006s	
1915/29900 (epoch 3.202), train_loss = 1.95139394, grad/param norm = 1.9782e-01, time/batch = 0.7183s	
1916/29900 (epoch 3.204), train_loss = 2.02498517, grad/param norm = 2.5049e-01, time/batch = 0.6804s	
1917/29900 (epoch 3.206), train_loss = 2.23528742, grad/param norm = 2.3238e-01, time/batch = 0.6818s	
1918/29900 (epoch 3.207), train_loss = 1.92178002, grad/param norm = 2.3755e-01, time/batch = 0.6840s	
1919/29900 (epoch 3.209), train_loss = 1.98726352, grad/param norm = 2.2948e-01, time/batch = 0.6804s	
1920/29900 (epoch 3.211), train_loss = 1.75297436, grad/param norm = 1.9721e-01, time/batch = 0.6904s	
1921/29900 (epoch 3.212), train_loss = 1.86394889, grad/param norm = 1.9975e-01, time/batch = 0.7071s	
1922/29900 (epoch 3.214), train_loss = 2.12824920, grad/param norm = 2.2279e-01, time/batch = 0.6956s	
1923/29900 (epoch 3.216), train_loss = 1.95095836, grad/param norm = 2.0286e-01, time/batch = 0.6800s	
1924/29900 (epoch 3.217), train_loss = 2.05410790, grad/param norm = 2.2041e-01, time/batch = 0.6853s	
1925/29900 (epoch 3.219), train_loss = 2.12704960, grad/param norm = 2.0555e-01, time/batch = 0.7172s	
1926/29900 (epoch 3.221), train_loss = 2.05424865, grad/param norm = 2.1619e-01, time/batch = 0.7079s	
1927/29900 (epoch 3.222), train_loss = 2.03245097, grad/param norm = 2.1182e-01, time/batch = 0.6855s	
1928/29900 (epoch 3.224), train_loss = 1.93389324, grad/param norm = 1.7810e-01, time/batch = 0.6846s	
1929/29900 (epoch 3.226), train_loss = 2.05534455, grad/param norm = 2.0422e-01, time/batch = 0.6831s	
1930/29900 (epoch 3.227), train_loss = 1.89796621, grad/param norm = 1.9240e-01, time/batch = 0.6841s	
1931/29900 (epoch 3.229), train_loss = 1.80217271, grad/param norm = 1.7895e-01, time/batch = 0.6808s	
1932/29900 (epoch 3.231), train_loss = 1.80030395, grad/param norm = 1.8623e-01, time/batch = 0.6821s	
1933/29900 (epoch 3.232), train_loss = 1.97021660, grad/param norm = 2.0717e-01, time/batch = 0.6867s	
1934/29900 (epoch 3.234), train_loss = 1.92347740, grad/param norm = 1.8409e-01, time/batch = 0.6813s	
1935/29900 (epoch 3.236), train_loss = 1.99106840, grad/param norm = 2.1247e-01, time/batch = 0.6814s	
1936/29900 (epoch 3.237), train_loss = 2.11210250, grad/param norm = 2.5511e-01, time/batch = 0.6841s	
1937/29900 (epoch 3.239), train_loss = 1.98790800, grad/param norm = 2.1294e-01, time/batch = 0.6856s	
1938/29900 (epoch 3.241), train_loss = 1.93976335, grad/param norm = 2.0648e-01, time/batch = 0.6825s	
1939/29900 (epoch 3.242), train_loss = 2.06889088, grad/param norm = 2.2778e-01, time/batch = 0.6950s	
1940/29900 (epoch 3.244), train_loss = 2.05537791, grad/param norm = 2.1166e-01, time/batch = 0.7252s	
1941/29900 (epoch 3.246), train_loss = 1.84993296, grad/param norm = 1.8649e-01, time/batch = 0.6849s	
1942/29900 (epoch 3.247), train_loss = 1.93007145, grad/param norm = 2.1014e-01, time/batch = 0.6834s	
1943/29900 (epoch 3.249), train_loss = 2.02378080, grad/param norm = 2.5440e-01, time/batch = 0.6849s	
1944/29900 (epoch 3.251), train_loss = 2.13868148, grad/param norm = 2.0370e-01, time/batch = 0.6904s	
1945/29900 (epoch 3.253), train_loss = 2.04696000, grad/param norm = 2.1151e-01, time/batch = 0.6848s	
1946/29900 (epoch 3.254), train_loss = 2.01795367, grad/param norm = 2.1556e-01, time/batch = 0.6826s	
1947/29900 (epoch 3.256), train_loss = 1.98789237, grad/param norm = 2.3427e-01, time/batch = 0.6830s	
1948/29900 (epoch 3.258), train_loss = 2.10000249, grad/param norm = 2.0867e-01, time/batch = 0.6832s	
1949/29900 (epoch 3.259), train_loss = 2.02610313, grad/param norm = 2.2615e-01, time/batch = 0.6821s	
1950/29900 (epoch 3.261), train_loss = 2.03897772, grad/param norm = 2.3202e-01, time/batch = 0.6811s	
1951/29900 (epoch 3.263), train_loss = 2.18261109, grad/param norm = 2.5815e-01, time/batch = 0.6845s	
1952/29900 (epoch 3.264), train_loss = 1.92807751, grad/param norm = 2.4067e-01, time/batch = 0.6836s	
1953/29900 (epoch 3.266), train_loss = 2.03807865, grad/param norm = 2.0230e-01, time/batch = 0.6815s	
1954/29900 (epoch 3.268), train_loss = 2.00043994, grad/param norm = 2.1084e-01, time/batch = 0.6816s	
1955/29900 (epoch 3.269), train_loss = 2.03418572, grad/param norm = 1.8137e-01, time/batch = 0.6845s	
1956/29900 (epoch 3.271), train_loss = 1.85624415, grad/param norm = 1.9276e-01, time/batch = 0.6813s	
1957/29900 (epoch 3.273), train_loss = 1.94097220, grad/param norm = 2.0677e-01, time/batch = 0.6808s	
1958/29900 (epoch 3.274), train_loss = 2.09564153, grad/param norm = 2.3314e-01, time/batch = 0.6839s	
1959/29900 (epoch 3.276), train_loss = 2.07451223, grad/param norm = 2.0463e-01, time/batch = 0.6911s	
1960/29900 (epoch 3.278), train_loss = 1.95765503, grad/param norm = 1.8831e-01, time/batch = 0.6962s	
1961/29900 (epoch 3.279), train_loss = 2.16279919, grad/param norm = 2.5494e-01, time/batch = 0.6979s	
1962/29900 (epoch 3.281), train_loss = 1.91188305, grad/param norm = 2.0791e-01, time/batch = 0.7009s	
1963/29900 (epoch 3.283), train_loss = 2.12969307, grad/param norm = 2.0574e-01, time/batch = 0.6846s	
1964/29900 (epoch 3.284), train_loss = 2.19233688, grad/param norm = 2.0806e-01, time/batch = 0.6922s	
1965/29900 (epoch 3.286), train_loss = 2.42050567, grad/param norm = 2.0506e-01, time/batch = 0.6888s	
1966/29900 (epoch 3.288), train_loss = 3.10973602, grad/param norm = 6.0456e-01, time/batch = 0.7000s	
1967/29900 (epoch 3.289), train_loss = 2.48054196, grad/param norm = 2.3702e-01, time/batch = 0.7157s	
1968/29900 (epoch 3.291), train_loss = 2.26063654, grad/param norm = 3.0005e-01, time/batch = 0.6818s	
1969/29900 (epoch 3.293), train_loss = 1.82336680, grad/param norm = 2.5579e-01, time/batch = 0.6815s	
1970/29900 (epoch 3.294), train_loss = 1.99025512, grad/param norm = 3.0835e-01, time/batch = 0.6845s	
1971/29900 (epoch 3.296), train_loss = 1.87609531, grad/param norm = 2.0062e-01, time/batch = 0.6839s	
1972/29900 (epoch 3.298), train_loss = 1.80184063, grad/param norm = 1.8599e-01, time/batch = 0.6830s	
1973/29900 (epoch 3.299), train_loss = 1.88035347, grad/param norm = 1.9076e-01, time/batch = 0.7025s	
1974/29900 (epoch 3.301), train_loss = 1.84992965, grad/param norm = 2.1589e-01, time/batch = 0.6912s	
1975/29900 (epoch 3.303), train_loss = 2.17221533, grad/param norm = 2.1455e-01, time/batch = 0.6841s	
1976/29900 (epoch 3.304), train_loss = 1.89127891, grad/param norm = 2.1399e-01, time/batch = 0.6814s	
1977/29900 (epoch 3.306), train_loss = 1.88506005, grad/param norm = 1.9477e-01, time/batch = 0.7139s	
1978/29900 (epoch 3.308), train_loss = 1.83498339, grad/param norm = 1.9092e-01, time/batch = 0.7088s	
1979/29900 (epoch 3.309), train_loss = 1.76082923, grad/param norm = 1.8125e-01, time/batch = 0.6793s	
1980/29900 (epoch 3.311), train_loss = 1.91182817, grad/param norm = 2.0369e-01, time/batch = 0.6821s	
1981/29900 (epoch 3.313), train_loss = 2.14318816, grad/param norm = 2.2051e-01, time/batch = 0.6909s	
1982/29900 (epoch 3.314), train_loss = 1.97559104, grad/param norm = 2.1021e-01, time/batch = 0.6888s	
1983/29900 (epoch 3.316), train_loss = 2.12983690, grad/param norm = 2.3714e-01, time/batch = 0.6823s	
1984/29900 (epoch 3.318), train_loss = 2.06900029, grad/param norm = 2.0912e-01, time/batch = 0.6819s	
1985/29900 (epoch 3.319), train_loss = 1.99713550, grad/param norm = 1.9100e-01, time/batch = 0.6829s	
1986/29900 (epoch 3.321), train_loss = 2.11626123, grad/param norm = 1.9877e-01, time/batch = 0.6820s	
1987/29900 (epoch 3.323), train_loss = 2.00027311, grad/param norm = 2.1369e-01, time/batch = 0.6798s	
1988/29900 (epoch 3.324), train_loss = 1.88481723, grad/param norm = 2.2941e-01, time/batch = 0.6809s	
1989/29900 (epoch 3.326), train_loss = 1.88560164, grad/param norm = 2.1895e-01, time/batch = 0.6850s	
1990/29900 (epoch 3.328), train_loss = 2.08217481, grad/param norm = 2.1993e-01, time/batch = 0.6891s	
1991/29900 (epoch 3.329), train_loss = 2.09965359, grad/param norm = 2.2928e-01, time/batch = 0.6826s	
1992/29900 (epoch 3.331), train_loss = 2.17789707, grad/param norm = 2.1994e-01, time/batch = 0.6814s	
1993/29900 (epoch 3.333), train_loss = 2.06878854, grad/param norm = 2.1489e-01, time/batch = 0.6805s	
1994/29900 (epoch 3.334), train_loss = 2.08661969, grad/param norm = 2.2221e-01, time/batch = 0.6806s	
1995/29900 (epoch 3.336), train_loss = 1.75922072, grad/param norm = 1.8655e-01, time/batch = 0.6839s	
1996/29900 (epoch 3.338), train_loss = 2.04727870, grad/param norm = 2.0742e-01, time/batch = 0.7211s	
1997/29900 (epoch 3.339), train_loss = 2.09910616, grad/param norm = 2.2566e-01, time/batch = 0.7067s	
1998/29900 (epoch 3.341), train_loss = 1.97081199, grad/param norm = 2.2633e-01, time/batch = 0.6801s	
1999/29900 (epoch 3.343), train_loss = 2.08681357, grad/param norm = 2.1933e-01, time/batch = 0.6800s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_dynamicwebpaige_epoch3.34_2.0528.t7	
2000/29900 (epoch 3.344), train_loss = 1.87638561, grad/param norm = 1.8759e-01, time/batch = 0.6797s	
2001/29900 (epoch 3.346), train_loss = 1.91024976, grad/param norm = 2.0106e-01, time/batch = 0.6926s	
2002/29900 (epoch 3.348), train_loss = 1.92447557, grad/param norm = 2.0121e-01, time/batch = 0.6969s	
2003/29900 (epoch 3.349), train_loss = 2.02242290, grad/param norm = 2.0991e-01, time/batch = 0.6882s	
2004/29900 (epoch 3.351), train_loss = 1.86677831, grad/param norm = 2.3325e-01, time/batch = 0.6927s	
2005/29900 (epoch 3.353), train_loss = 1.98624655, grad/param norm = 2.0030e-01, time/batch = 0.7003s	
2006/29900 (epoch 3.355), train_loss = 1.90692516, grad/param norm = 1.9263e-01, time/batch = 0.7179s	
2007/29900 (epoch 3.356), train_loss = 1.97517361, grad/param norm = 2.0168e-01, time/batch = 0.7077s	
2008/29900 (epoch 3.358), train_loss = 1.93541320, grad/param norm = 1.9405e-01, time/batch = 0.6840s	
2009/29900 (epoch 3.360), train_loss = 2.12458982, grad/param norm = 2.0428e-01, time/batch = 0.6835s	
2010/29900 (epoch 3.361), train_loss = 2.13463569, grad/param norm = 2.1260e-01, time/batch = 0.6896s	
2011/29900 (epoch 3.363), train_loss = 1.83504703, grad/param norm = 2.0807e-01, time/batch = 0.6927s	
2012/29900 (epoch 3.365), train_loss = 1.91180390, grad/param norm = 1.9156e-01, time/batch = 0.6871s	
2013/29900 (epoch 3.366), train_loss = 1.81299946, grad/param norm = 2.1188e-01, time/batch = 0.6935s	
2014/29900 (epoch 3.368), train_loss = 1.84994207, grad/param norm = 2.1454e-01, time/batch = 0.6912s	
2015/29900 (epoch 3.370), train_loss = 1.90664907, grad/param norm = 2.0143e-01, time/batch = 0.6902s	
2016/29900 (epoch 3.371), train_loss = 1.99825783, grad/param norm = 2.1656e-01, time/batch = 0.6907s	
2017/29900 (epoch 3.373), train_loss = 1.89529844, grad/param norm = 2.0581e-01, time/batch = 0.6964s	
2018/29900 (epoch 3.375), train_loss = 2.05759500, grad/param norm = 2.1883e-01, time/batch = 0.7036s	
2019/29900 (epoch 3.376), train_loss = 2.05863996, grad/param norm = 1.9230e-01, time/batch = 0.6955s	
2020/29900 (epoch 3.378), train_loss = 1.90492514, grad/param norm = 1.9877e-01, time/batch = 0.6856s	
2021/29900 (epoch 3.380), train_loss = 1.88659702, grad/param norm = 2.1434e-01, time/batch = 0.6896s	
2022/29900 (epoch 3.381), train_loss = 2.08574226, grad/param norm = 2.3278e-01, time/batch = 0.6903s	
2023/29900 (epoch 3.383), train_loss = 1.83098989, grad/param norm = 2.0483e-01, time/batch = 0.6891s	
2024/29900 (epoch 3.385), train_loss = 1.85382892, grad/param norm = 2.1630e-01, time/batch = 0.6946s	
2025/29900 (epoch 3.386), train_loss = 1.86536210, grad/param norm = 2.0600e-01, time/batch = 0.6970s	
2026/29900 (epoch 3.388), train_loss = 2.05842429, grad/param norm = 1.9717e-01, time/batch = 0.6922s	
2027/29900 (epoch 3.390), train_loss = 1.95168181, grad/param norm = 2.1657e-01, time/batch = 0.6946s	
2028/29900 (epoch 3.391), train_loss = 1.84570835, grad/param norm = 2.2161e-01, time/batch = 0.6870s	
2029/29900 (epoch 3.393), train_loss = 2.04023612, grad/param norm = 2.0302e-01, time/batch = 0.6885s	
2030/29900 (epoch 3.395), train_loss = 1.83642067, grad/param norm = 2.2051e-01, time/batch = 0.6893s	
2031/29900 (epoch 3.396), train_loss = 2.12988909, grad/param norm = 2.2587e-01, time/batch = 0.6942s	
2032/29900 (epoch 3.398), train_loss = 1.96062580, grad/param norm = 1.8454e-01, time/batch = 0.6901s	
2033/29900 (epoch 3.400), train_loss = 2.02640242, grad/param norm = 2.1351e-01, time/batch = 0.6914s	
2034/29900 (epoch 3.401), train_loss = 2.01543342, grad/param norm = 2.0121e-01, time/batch = 0.6836s	
2035/29900 (epoch 3.403), train_loss = 2.02265001, grad/param norm = 2.1530e-01, time/batch = 0.6818s	
2036/29900 (epoch 3.405), train_loss = 1.99752823, grad/param norm = 2.3173e-01, time/batch = 0.6823s	
2037/29900 (epoch 3.406), train_loss = 1.73502123, grad/param norm = 1.7683e-01, time/batch = 0.6895s	
2038/29900 (epoch 3.408), train_loss = 1.66793261, grad/param norm = 1.7125e-01, time/batch = 0.6828s	
2039/29900 (epoch 3.410), train_loss = 2.11668351, grad/param norm = 2.0236e-01, time/batch = 0.7123s	
2040/29900 (epoch 3.411), train_loss = 2.00912426, grad/param norm = 2.5600e-01, time/batch = 0.7148s	
2041/29900 (epoch 3.413), train_loss = 2.01441742, grad/param norm = 2.0695e-01, time/batch = 0.6890s	
2042/29900 (epoch 3.415), train_loss = 1.84149434, grad/param norm = 1.8386e-01, time/batch = 0.6898s	
2043/29900 (epoch 3.416), train_loss = 1.95555906, grad/param norm = 1.9074e-01, time/batch = 0.6886s	
2044/29900 (epoch 3.418), train_loss = 1.84338780, grad/param norm = 1.9291e-01, time/batch = 0.7082s	
2045/29900 (epoch 3.420), train_loss = 2.06770518, grad/param norm = 1.9342e-01, time/batch = 0.7095s	
2046/29900 (epoch 3.421), train_loss = 2.25539842, grad/param norm = 1.9650e-01, time/batch = 0.6905s	
2047/29900 (epoch 3.423), train_loss = 1.96431242, grad/param norm = 1.7493e-01, time/batch = 0.6899s	
2048/29900 (epoch 3.425), train_loss = 1.91970223, grad/param norm = 1.9855e-01, time/batch = 0.6911s	
2049/29900 (epoch 3.426), train_loss = 1.87386242, grad/param norm = 2.2681e-01, time/batch = 0.6929s	
2050/29900 (epoch 3.428), train_loss = 1.98784851, grad/param norm = 2.2052e-01, time/batch = 0.6863s	
2051/29900 (epoch 3.430), train_loss = 1.96294250, grad/param norm = 1.9838e-01, time/batch = 0.6914s	
2052/29900 (epoch 3.431), train_loss = 1.95050117, grad/param norm = 1.9875e-01, time/batch = 0.6850s	
2053/29900 (epoch 3.433), train_loss = 1.87169658, grad/param norm = 2.0493e-01, time/batch = 0.6873s	
2054/29900 (epoch 3.435), train_loss = 1.98231978, grad/param norm = 1.9846e-01, time/batch = 0.6948s	
2055/29900 (epoch 3.436), train_loss = 1.90877430, grad/param norm = 2.0466e-01, time/batch = 0.6947s	
2056/29900 (epoch 3.438), train_loss = 1.92370590, grad/param norm = 2.0229e-01, time/batch = 0.7034s	
2057/29900 (epoch 3.440), train_loss = 1.81654667, grad/param norm = 2.1168e-01, time/batch = 0.6941s	
2058/29900 (epoch 3.441), train_loss = 1.73725649, grad/param norm = 1.9732e-01, time/batch = 0.7258s	
2059/29900 (epoch 3.443), train_loss = 2.05701625, grad/param norm = 1.9596e-01, time/batch = 0.6993s	
2060/29900 (epoch 3.445), train_loss = 2.09505344, grad/param norm = 2.0433e-01, time/batch = 0.6849s	
2061/29900 (epoch 3.446), train_loss = 1.77124521, grad/param norm = 1.9752e-01, time/batch = 0.6859s	
2062/29900 (epoch 3.448), train_loss = 1.97838417, grad/param norm = 2.0590e-01, time/batch = 0.6863s	
2063/29900 (epoch 3.450), train_loss = 2.03579105, grad/param norm = 1.9571e-01, time/batch = 0.6854s	
2064/29900 (epoch 3.452), train_loss = 1.92980831, grad/param norm = 2.1811e-01, time/batch = 0.6917s	
2065/29900 (epoch 3.453), train_loss = 1.96472629, grad/param norm = 2.1922e-01, time/batch = 0.6905s	
2066/29900 (epoch 3.455), train_loss = 1.97524871, grad/param norm = 1.9183e-01, time/batch = 0.6823s	
2067/29900 (epoch 3.457), train_loss = 1.82907725, grad/param norm = 1.9874e-01, time/batch = 0.6858s	
2068/29900 (epoch 3.458), train_loss = 2.00253384, grad/param norm = 1.9236e-01, time/batch = 0.6830s	
2069/29900 (epoch 3.460), train_loss = 1.91112351, grad/param norm = 1.8772e-01, time/batch = 0.6860s	
2070/29900 (epoch 3.462), train_loss = 1.86627103, grad/param norm = 1.9244e-01, time/batch = 0.6869s	
2071/29900 (epoch 3.463), train_loss = 1.65425955, grad/param norm = 1.6466e-01, time/batch = 0.6906s	
2072/29900 (epoch 3.465), train_loss = 2.01104177, grad/param norm = 1.8910e-01, time/batch = 0.6977s	
2073/29900 (epoch 3.467), train_loss = 2.08239632, grad/param norm = 2.1108e-01, time/batch = 0.6947s	
2074/29900 (epoch 3.468), train_loss = 2.23688965, grad/param norm = 2.3492e-01, time/batch = 0.6850s	
2075/29900 (epoch 3.470), train_loss = 2.00192726, grad/param norm = 1.9199e-01, time/batch = 0.6859s	
2076/29900 (epoch 3.472), train_loss = 1.89794282, grad/param norm = 2.2810e-01, time/batch = 0.7022s	
2077/29900 (epoch 3.473), train_loss = 1.91322560, grad/param norm = 2.2975e-01, time/batch = 0.7254s	
2078/29900 (epoch 3.475), train_loss = 1.94052880, grad/param norm = 1.9989e-01, time/batch = 0.6850s	
2079/29900 (epoch 3.477), train_loss = 1.95508717, grad/param norm = 2.2410e-01, time/batch = 0.6825s	
2080/29900 (epoch 3.478), train_loss = 2.08785513, grad/param norm = 2.0033e-01, time/batch = 0.6819s	
2081/29900 (epoch 3.480), train_loss = 1.91667182, grad/param norm = 2.0066e-01, time/batch = 0.6839s	
2082/29900 (epoch 3.482), train_loss = 2.02005493, grad/param norm = 1.8746e-01, time/batch = 0.6839s	
2083/29900 (epoch 3.483), train_loss = 1.89224728, grad/param norm = 2.0118e-01, time/batch = 0.6860s	
2084/29900 (epoch 3.485), train_loss = 2.05621557, grad/param norm = 2.1337e-01, time/batch = 0.6871s	
2085/29900 (epoch 3.487), train_loss = 1.87949981, grad/param norm = 2.1025e-01, time/batch = 0.6902s	
2086/29900 (epoch 3.488), train_loss = 2.02817348, grad/param norm = 2.3690e-01, time/batch = 0.6911s	
2087/29900 (epoch 3.490), train_loss = 1.91375609, grad/param norm = 1.9862e-01, time/batch = 0.6964s	
2088/29900 (epoch 3.492), train_loss = 2.00360093, grad/param norm = 2.2307e-01, time/batch = 0.6900s	
2089/29900 (epoch 3.493), train_loss = 1.89626376, grad/param norm = 1.9518e-01, time/batch = 0.7086s	
2090/29900 (epoch 3.495), train_loss = 1.95008289, grad/param norm = 2.0163e-01, time/batch = 0.6968s	
2091/29900 (epoch 3.497), train_loss = 1.93858777, grad/param norm = 1.9094e-01, time/batch = 0.7029s	
2092/29900 (epoch 3.498), train_loss = 1.86958502, grad/param norm = 1.8847e-01, time/batch = 0.6993s	
2093/29900 (epoch 3.500), train_loss = 2.07158447, grad/param norm = 2.1518e-01, time/batch = 0.6867s	
2094/29900 (epoch 3.502), train_loss = 2.11185273, grad/param norm = 2.0487e-01, time/batch = 0.6895s	
2095/29900 (epoch 3.503), train_loss = 1.91770260, grad/param norm = 1.9209e-01, time/batch = 0.7143s	
2096/29900 (epoch 3.505), train_loss = 1.66912807, grad/param norm = 1.9441e-01, time/batch = 0.7116s	
2097/29900 (epoch 3.507), train_loss = 1.89938181, grad/param norm = 2.1001e-01, time/batch = 0.6853s	
2098/29900 (epoch 3.508), train_loss = 1.88570320, grad/param norm = 2.1761e-01, time/batch = 0.6880s	
2099/29900 (epoch 3.510), train_loss = 1.74987570, grad/param norm = 1.9282e-01, time/batch = 0.6849s	
2100/29900 (epoch 3.512), train_loss = 2.07943979, grad/param norm = 2.0541e-01, time/batch = 0.7020s	
2101/29900 (epoch 3.513), train_loss = 2.04982031, grad/param norm = 1.9898e-01, time/batch = 0.7045s	
2102/29900 (epoch 3.515), train_loss = 1.91243615, grad/param norm = 2.2243e-01, time/batch = 0.6908s	
2103/29900 (epoch 3.517), train_loss = 1.98435279, grad/param norm = 2.3589e-01, time/batch = 0.6878s	
2104/29900 (epoch 3.518), train_loss = 1.81532106, grad/param norm = 1.9331e-01, time/batch = 0.6844s	
2105/29900 (epoch 3.520), train_loss = 2.07407204, grad/param norm = 1.9758e-01, time/batch = 0.6860s	
2106/29900 (epoch 3.522), train_loss = 1.98868943, grad/param norm = 2.2129e-01, time/batch = 0.6829s	
2107/29900 (epoch 3.523), train_loss = 1.97237879, grad/param norm = 1.8834e-01, time/batch = 0.6851s	
2108/29900 (epoch 3.525), train_loss = 1.93915269, grad/param norm = 2.0733e-01, time/batch = 0.6840s	
2109/29900 (epoch 3.527), train_loss = 1.96787624, grad/param norm = 1.9999e-01, time/batch = 0.6975s	
2110/29900 (epoch 3.528), train_loss = 1.97447776, grad/param norm = 1.9255e-01, time/batch = 0.7249s	
2111/29900 (epoch 3.530), train_loss = 2.09548405, grad/param norm = 2.0151e-01, time/batch = 0.6878s	
2112/29900 (epoch 3.532), train_loss = 1.99189412, grad/param norm = 2.0089e-01, time/batch = 0.6879s	
2113/29900 (epoch 3.533), train_loss = 1.90993238, grad/param norm = 2.1636e-01, time/batch = 0.6837s	
2114/29900 (epoch 3.535), train_loss = 1.92250658, grad/param norm = 2.4791e-01, time/batch = 0.6837s	
2115/29900 (epoch 3.537), train_loss = 1.82937972, grad/param norm = 2.0697e-01, time/batch = 0.6839s	
2116/29900 (epoch 3.538), train_loss = 1.90478326, grad/param norm = 2.0830e-01, time/batch = 0.6853s	
2117/29900 (epoch 3.540), train_loss = 1.88333046, grad/param norm = 2.0999e-01, time/batch = 0.6855s	
2118/29900 (epoch 3.542), train_loss = 1.89597002, grad/param norm = 2.0042e-01, time/batch = 0.6824s	
2119/29900 (epoch 3.543), train_loss = 2.13835837, grad/param norm = 2.2613e-01, time/batch = 0.6881s	
2120/29900 (epoch 3.545), train_loss = 2.08334333, grad/param norm = 2.1710e-01, time/batch = 0.6833s	
2121/29900 (epoch 3.547), train_loss = 2.05784026, grad/param norm = 1.9860e-01, time/batch = 0.6857s	
2122/29900 (epoch 3.548), train_loss = 1.87587757, grad/param norm = 2.1907e-01, time/batch = 0.6864s	
2123/29900 (epoch 3.550), train_loss = 1.89277963, grad/param norm = 2.3181e-01, time/batch = 0.6890s	
2124/29900 (epoch 3.552), train_loss = 1.90665174, grad/param norm = 1.9360e-01, time/batch = 0.6892s	
2125/29900 (epoch 3.554), train_loss = 2.15040723, grad/param norm = 2.1825e-01, time/batch = 0.6858s	
2126/29900 (epoch 3.555), train_loss = 2.10943409, grad/param norm = 1.9106e-01, time/batch = 0.6876s	
2127/29900 (epoch 3.557), train_loss = 2.12387274, grad/param norm = 1.9809e-01, time/batch = 0.6861s	
2128/29900 (epoch 3.559), train_loss = 1.96364096, grad/param norm = 2.0692e-01, time/batch = 0.7080s	
2129/29900 (epoch 3.560), train_loss = 2.01340666, grad/param norm = 1.9637e-01, time/batch = 0.7214s	
2130/29900 (epoch 3.562), train_loss = 1.92480225, grad/param norm = 1.9702e-01, time/batch = 0.7061s	
2131/29900 (epoch 3.564), train_loss = 1.96532612, grad/param norm = 2.0115e-01, time/batch = 0.7142s	
2132/29900 (epoch 3.565), train_loss = 2.17873850, grad/param norm = 2.0577e-01, time/batch = 0.7400s	
2133/29900 (epoch 3.567), train_loss = 2.08316752, grad/param norm = 2.2934e-01, time/batch = 0.7194s	
2134/29900 (epoch 3.569), train_loss = 2.19616695, grad/param norm = 2.1647e-01, time/batch = 0.6952s	
2135/29900 (epoch 3.570), train_loss = 1.98514680, grad/param norm = 2.2363e-01, time/batch = 0.7018s	
2136/29900 (epoch 3.572), train_loss = 1.82848292, grad/param norm = 2.2332e-01, time/batch = 0.7021s	
2137/29900 (epoch 3.574), train_loss = 1.87075752, grad/param norm = 1.9835e-01, time/batch = 0.6974s	
2138/29900 (epoch 3.575), train_loss = 1.99822514, grad/param norm = 2.1247e-01, time/batch = 0.6961s	
2139/29900 (epoch 3.577), train_loss = 2.00202662, grad/param norm = 1.9797e-01, time/batch = 0.7036s	
2140/29900 (epoch 3.579), train_loss = 2.10704670, grad/param norm = 1.9007e-01, time/batch = 0.6970s	
2141/29900 (epoch 3.580), train_loss = 1.94183850, grad/param norm = 1.9782e-01, time/batch = 0.7005s	
2142/29900 (epoch 3.582), train_loss = 1.76105492, grad/param norm = 3.0706e-01, time/batch = 0.7176s	
2143/29900 (epoch 3.584), train_loss = 1.93398753, grad/param norm = 2.1600e-01, time/batch = 0.7239s	
2144/29900 (epoch 3.585), train_loss = 2.11854074, grad/param norm = 2.0785e-01, time/batch = 0.6996s	
2145/29900 (epoch 3.587), train_loss = 2.01561102, grad/param norm = 1.7941e-01, time/batch = 0.6980s	
2146/29900 (epoch 3.589), train_loss = 2.23825094, grad/param norm = 2.0984e-01, time/batch = 0.6897s	
2147/29900 (epoch 3.590), train_loss = 1.84136740, grad/param norm = 1.9174e-01, time/batch = 0.6919s	
2148/29900 (epoch 3.592), train_loss = 2.01461116, grad/param norm = 2.0160e-01, time/batch = 0.6851s	
2149/29900 (epoch 3.594), train_loss = 1.93825143, grad/param norm = 2.1193e-01, time/batch = 0.6807s	
2150/29900 (epoch 3.595), train_loss = 2.00591529, grad/param norm = 2.0725e-01, time/batch = 0.7024s	
2151/29900 (epoch 3.597), train_loss = 1.92789693, grad/param norm = 1.8604e-01, time/batch = 0.6911s	
2152/29900 (epoch 3.599), train_loss = 1.72742695, grad/param norm = 1.6825e-01, time/batch = 0.6825s	
2153/29900 (epoch 3.600), train_loss = 2.02356370, grad/param norm = 1.9889e-01, time/batch = 0.6831s	
2154/29900 (epoch 3.602), train_loss = 1.98662500, grad/param norm = 2.1741e-01, time/batch = 0.6835s	
2155/29900 (epoch 3.604), train_loss = 2.06854474, grad/param norm = 1.6993e-01, time/batch = 0.6886s	
2156/29900 (epoch 3.605), train_loss = 2.08747836, grad/param norm = 1.9482e-01, time/batch = 0.6822s	
2157/29900 (epoch 3.607), train_loss = 1.90486928, grad/param norm = 1.8968e-01, time/batch = 0.6848s	
2158/29900 (epoch 3.609), train_loss = 2.05047557, grad/param norm = 2.1042e-01, time/batch = 0.6856s	
2159/29900 (epoch 3.610), train_loss = 2.22910107, grad/param norm = 2.0273e-01, time/batch = 0.6858s	
2160/29900 (epoch 3.612), train_loss = 2.14637809, grad/param norm = 1.9972e-01, time/batch = 0.6850s	
2161/29900 (epoch 3.614), train_loss = 2.08414600, grad/param norm = 1.8529e-01, time/batch = 0.7175s	
2162/29900 (epoch 3.615), train_loss = 2.39034089, grad/param norm = 1.9642e-01, time/batch = 0.7151s	
2163/29900 (epoch 3.617), train_loss = 2.01080532, grad/param norm = 1.7987e-01, time/batch = 0.6836s	
2164/29900 (epoch 3.619), train_loss = 1.91166151, grad/param norm = 2.0084e-01, time/batch = 0.6835s	
2165/29900 (epoch 3.620), train_loss = 1.98141762, grad/param norm = 1.8876e-01, time/batch = 0.6845s	
2166/29900 (epoch 3.622), train_loss = 1.99245603, grad/param norm = 2.0604e-01, time/batch = 0.6999s	
2167/29900 (epoch 3.624), train_loss = 1.94552420, grad/param norm = 2.0796e-01, time/batch = 0.6919s	
2168/29900 (epoch 3.625), train_loss = 2.02251732, grad/param norm = 1.9965e-01, time/batch = 0.6947s	
2169/29900 (epoch 3.627), train_loss = 1.63992629, grad/param norm = 1.6639e-01, time/batch = 0.6956s	
2170/29900 (epoch 3.629), train_loss = 1.97661088, grad/param norm = 2.0037e-01, time/batch = 0.6919s	
2171/29900 (epoch 3.630), train_loss = 2.06391732, grad/param norm = 1.9795e-01, time/batch = 0.6917s	
2172/29900 (epoch 3.632), train_loss = 2.03004890, grad/param norm = 2.0442e-01, time/batch = 0.6866s	
2173/29900 (epoch 3.634), train_loss = 1.89345626, grad/param norm = 1.8339e-01, time/batch = 0.6930s	
2174/29900 (epoch 3.635), train_loss = 2.00887315, grad/param norm = 2.0276e-01, time/batch = 0.6950s	
2175/29900 (epoch 3.637), train_loss = 2.10806781, grad/param norm = 2.1227e-01, time/batch = 0.7075s	
2176/29900 (epoch 3.639), train_loss = 1.95775179, grad/param norm = 1.9506e-01, time/batch = 0.7014s	
2177/29900 (epoch 3.640), train_loss = 2.05889632, grad/param norm = 1.7651e-01, time/batch = 0.6953s	
2178/29900 (epoch 3.642), train_loss = 2.04279630, grad/param norm = 2.1107e-01, time/batch = 0.6828s	
2179/29900 (epoch 3.644), train_loss = 1.87064612, grad/param norm = 1.8758e-01, time/batch = 0.6903s	
2180/29900 (epoch 3.645), train_loss = 2.20435560, grad/param norm = 2.2613e-01, time/batch = 0.7249s	
2181/29900 (epoch 3.647), train_loss = 1.92108877, grad/param norm = 1.9319e-01, time/batch = 0.6938s	
2182/29900 (epoch 3.649), train_loss = 1.72191103, grad/param norm = 1.7870e-01, time/batch = 0.6840s	
2183/29900 (epoch 3.651), train_loss = 1.82807759, grad/param norm = 1.7383e-01, time/batch = 0.6831s	
2184/29900 (epoch 3.652), train_loss = 1.72876980, grad/param norm = 1.7627e-01, time/batch = 0.6933s	
2185/29900 (epoch 3.654), train_loss = 1.98329862, grad/param norm = 2.2378e-01, time/batch = 0.6837s	
2186/29900 (epoch 3.656), train_loss = 2.11690941, grad/param norm = 2.0413e-01, time/batch = 0.6917s	
2187/29900 (epoch 3.657), train_loss = 1.78512515, grad/param norm = 1.7130e-01, time/batch = 0.6856s	
2188/29900 (epoch 3.659), train_loss = 1.63947687, grad/param norm = 2.0504e-01, time/batch = 0.6851s	
2189/29900 (epoch 3.661), train_loss = 2.13743322, grad/param norm = 2.3200e-01, time/batch = 0.6849s	
2190/29900 (epoch 3.662), train_loss = 2.05179124, grad/param norm = 1.8796e-01, time/batch = 0.6860s	
2191/29900 (epoch 3.664), train_loss = 1.95997951, grad/param norm = 1.8933e-01, time/batch = 0.6881s	
2192/29900 (epoch 3.666), train_loss = 1.77978696, grad/param norm = 1.8884e-01, time/batch = 0.6832s	
2193/29900 (epoch 3.667), train_loss = 1.86628886, grad/param norm = 1.8489e-01, time/batch = 0.6853s	
2194/29900 (epoch 3.669), train_loss = 1.74004477, grad/param norm = 1.7441e-01, time/batch = 0.6841s	
2195/29900 (epoch 3.671), train_loss = 1.91334507, grad/param norm = 1.8806e-01, time/batch = 0.6829s	
2196/29900 (epoch 3.672), train_loss = 1.94333658, grad/param norm = 1.9944e-01, time/batch = 0.6823s	
2197/29900 (epoch 3.674), train_loss = 1.96517474, grad/param norm = 1.8200e-01, time/batch = 0.6818s	
2198/29900 (epoch 3.676), train_loss = 1.77702707, grad/param norm = 1.8066e-01, time/batch = 0.6977s	
2199/29900 (epoch 3.677), train_loss = 2.04280200, grad/param norm = 1.9010e-01, time/batch = 0.6945s	
2200/29900 (epoch 3.679), train_loss = 2.09199373, grad/param norm = 2.1173e-01, time/batch = 0.6842s	
2201/29900 (epoch 3.681), train_loss = 2.11224996, grad/param norm = 2.4967e-01, time/batch = 0.6854s	
2202/29900 (epoch 3.682), train_loss = 2.11332965, grad/param norm = 2.2981e-01, time/batch = 0.6874s	
2203/29900 (epoch 3.684), train_loss = 2.07685952, grad/param norm = 1.9660e-01, time/batch = 0.6837s	
2204/29900 (epoch 3.686), train_loss = 2.12205056, grad/param norm = 2.0172e-01, time/batch = 0.6850s	
2205/29900 (epoch 3.687), train_loss = 1.86242963, grad/param norm = 1.9267e-01, time/batch = 0.6848s	
2206/29900 (epoch 3.689), train_loss = 1.97575664, grad/param norm = 2.1228e-01, time/batch = 0.6862s	
2207/29900 (epoch 3.691), train_loss = 2.17872562, grad/param norm = 1.9922e-01, time/batch = 0.6856s	
2208/29900 (epoch 3.692), train_loss = 2.17511903, grad/param norm = 2.2063e-01, time/batch = 0.6843s	
2209/29900 (epoch 3.694), train_loss = 1.80477019, grad/param norm = 1.7745e-01, time/batch = 0.6848s	
2210/29900 (epoch 3.696), train_loss = 1.75604433, grad/param norm = 1.9858e-01, time/batch = 0.6816s	
2211/29900 (epoch 3.697), train_loss = 2.01128985, grad/param norm = 1.9390e-01, time/batch = 0.6828s	
2212/29900 (epoch 3.699), train_loss = 1.78975953, grad/param norm = 1.9794e-01, time/batch = 0.6837s	
2213/29900 (epoch 3.701), train_loss = 1.94704884, grad/param norm = 1.9528e-01, time/batch = 0.6864s	
2214/29900 (epoch 3.702), train_loss = 2.00632833, grad/param norm = 1.9750e-01, time/batch = 0.6890s	
2215/29900 (epoch 3.704), train_loss = 1.91796062, grad/param norm = 2.1848e-01, time/batch = 0.6873s	
2216/29900 (epoch 3.706), train_loss = 1.78928350, grad/param norm = 1.9256e-01, time/batch = 0.6969s	
2217/29900 (epoch 3.707), train_loss = 2.07704274, grad/param norm = 2.1663e-01, time/batch = 0.7150s	
2218/29900 (epoch 3.709), train_loss = 2.04631821, grad/param norm = 2.2406e-01, time/batch = 0.7242s	
2219/29900 (epoch 3.711), train_loss = 1.92355338, grad/param norm = 1.9448e-01, time/batch = 0.6869s	
2220/29900 (epoch 3.712), train_loss = 1.83244999, grad/param norm = 1.8502e-01, time/batch = 0.6830s	
2221/29900 (epoch 3.714), train_loss = 1.93879444, grad/param norm = 2.1416e-01, time/batch = 0.6870s	
2222/29900 (epoch 3.716), train_loss = 1.97534788, grad/param norm = 1.9993e-01, time/batch = 0.6894s	
2223/29900 (epoch 3.717), train_loss = 1.93531394, grad/param norm = 1.9681e-01, time/batch = 0.6855s	
2224/29900 (epoch 3.719), train_loss = 1.88221915, grad/param norm = 1.8489e-01, time/batch = 0.6811s	
2225/29900 (epoch 3.721), train_loss = 2.10904694, grad/param norm = 1.8879e-01, time/batch = 0.6815s	
2226/29900 (epoch 3.722), train_loss = 2.08710051, grad/param norm = 1.8475e-01, time/batch = 0.6813s	
2227/29900 (epoch 3.724), train_loss = 1.96284268, grad/param norm = 2.2037e-01, time/batch = 0.6920s	
2228/29900 (epoch 3.726), train_loss = 1.95631697, grad/param norm = 2.1434e-01, time/batch = 0.6847s	
2229/29900 (epoch 3.727), train_loss = 1.86934176, grad/param norm = 1.6854e-01, time/batch = 0.6861s	
2230/29900 (epoch 3.729), train_loss = 1.94667602, grad/param norm = 1.8052e-01, time/batch = 0.6873s	
2231/29900 (epoch 3.731), train_loss = 1.88222894, grad/param norm = 2.0516e-01, time/batch = 0.6940s	
2232/29900 (epoch 3.732), train_loss = 2.19897572, grad/param norm = 2.4006e-01, time/batch = 0.6820s	
2233/29900 (epoch 3.734), train_loss = 2.10011415, grad/param norm = 2.3404e-01, time/batch = 0.6843s	
2234/29900 (epoch 3.736), train_loss = 2.06500019, grad/param norm = 1.9553e-01, time/batch = 0.6806s	
2235/29900 (epoch 3.737), train_loss = 1.78673625, grad/param norm = 1.8882e-01, time/batch = 0.6841s	
2236/29900 (epoch 3.739), train_loss = 2.08602587, grad/param norm = 2.3596e-01, time/batch = 0.7142s	
2237/29900 (epoch 3.741), train_loss = 1.84586807, grad/param norm = 1.8747e-01, time/batch = 0.7101s	
2238/29900 (epoch 3.742), train_loss = 1.90165555, grad/param norm = 2.2722e-01, time/batch = 0.6818s	
2239/29900 (epoch 3.744), train_loss = 1.76141691, grad/param norm = 2.2779e-01, time/batch = 0.6824s	
2240/29900 (epoch 3.746), train_loss = 1.90341474, grad/param norm = 1.8507e-01, time/batch = 0.6813s	
2241/29900 (epoch 3.747), train_loss = 2.04778521, grad/param norm = 2.0774e-01, time/batch = 0.6950s	
2242/29900 (epoch 3.749), train_loss = 1.90159945, grad/param norm = 1.8799e-01, time/batch = 0.6902s	
2243/29900 (epoch 3.751), train_loss = 2.00503673, grad/param norm = 2.1151e-01, time/batch = 0.6846s	
2244/29900 (epoch 3.753), train_loss = 2.13798245, grad/param norm = 2.0360e-01, time/batch = 0.6830s	
2245/29900 (epoch 3.754), train_loss = 1.80372648, grad/param norm = 1.7782e-01, time/batch = 0.7071s	
2246/29900 (epoch 3.756), train_loss = 2.00350495, grad/param norm = 1.7507e-01, time/batch = 0.6948s	
2247/29900 (epoch 3.758), train_loss = 2.03093297, grad/param norm = 2.0900e-01, time/batch = 0.6817s	
2248/29900 (epoch 3.759), train_loss = 1.98813595, grad/param norm = 1.9040e-01, time/batch = 0.6812s	
2249/29900 (epoch 3.761), train_loss = 1.91159360, grad/param norm = 1.8886e-01, time/batch = 0.6829s	
2250/29900 (epoch 3.763), train_loss = 1.99295716, grad/param norm = 1.8202e-01, time/batch = 0.6797s	
2251/29900 (epoch 3.764), train_loss = 1.97635887, grad/param norm = 1.7791e-01, time/batch = 0.6840s	
2252/29900 (epoch 3.766), train_loss = 1.94749854, grad/param norm = 1.9903e-01, time/batch = 0.6846s	
2253/29900 (epoch 3.768), train_loss = 1.84757196, grad/param norm = 1.7656e-01, time/batch = 0.6907s	
2254/29900 (epoch 3.769), train_loss = 1.97388537, grad/param norm = 1.9955e-01, time/batch = 0.6869s	
2255/29900 (epoch 3.771), train_loss = 1.93428696, grad/param norm = 1.8316e-01, time/batch = 0.6840s	
2256/29900 (epoch 3.773), train_loss = 2.00530733, grad/param norm = 1.9901e-01, time/batch = 0.6845s	
2257/29900 (epoch 3.774), train_loss = 1.89795347, grad/param norm = 2.1635e-01, time/batch = 0.6825s	
2258/29900 (epoch 3.776), train_loss = 1.77687463, grad/param norm = 1.8339e-01, time/batch = 0.6850s	
2259/29900 (epoch 3.778), train_loss = 2.01146455, grad/param norm = 2.0558e-01, time/batch = 0.7091s	
2260/29900 (epoch 3.779), train_loss = 1.99858315, grad/param norm = 1.9810e-01, time/batch = 0.7165s	
2261/29900 (epoch 3.781), train_loss = 1.74578143, grad/param norm = 1.8483e-01, time/batch = 0.6850s	
2262/29900 (epoch 3.783), train_loss = 1.85161971, grad/param norm = 1.9755e-01, time/batch = 0.6855s	
2263/29900 (epoch 3.784), train_loss = 1.97240560, grad/param norm = 2.0520e-01, time/batch = 0.6823s	
2264/29900 (epoch 3.786), train_loss = 2.04383185, grad/param norm = 1.8627e-01, time/batch = 0.6815s	
2265/29900 (epoch 3.788), train_loss = 2.03133118, grad/param norm = 2.0157e-01, time/batch = 0.6903s	
2266/29900 (epoch 3.789), train_loss = 1.86040248, grad/param norm = 2.0901e-01, time/batch = 0.6837s	
2267/29900 (epoch 3.791), train_loss = 1.86538941, grad/param norm = 1.8484e-01, time/batch = 0.6840s	
2268/29900 (epoch 3.793), train_loss = 1.78140555, grad/param norm = 1.8530e-01, time/batch = 0.6856s	
2269/29900 (epoch 3.794), train_loss = 2.01669284, grad/param norm = 2.1313e-01, time/batch = 0.6839s	
2270/29900 (epoch 3.796), train_loss = 2.04607331, grad/param norm = 2.1420e-01, time/batch = 0.6964s	
2271/29900 (epoch 3.798), train_loss = 2.01500689, grad/param norm = 1.9672e-01, time/batch = 0.6953s	
2272/29900 (epoch 3.799), train_loss = 1.93317122, grad/param norm = 2.0137e-01, time/batch = 0.6845s	
2273/29900 (epoch 3.801), train_loss = 1.98893135, grad/param norm = 2.1194e-01, time/batch = 0.6817s	
2274/29900 (epoch 3.803), train_loss = 2.08403863, grad/param norm = 2.2441e-01, time/batch = 0.6818s	
2275/29900 (epoch 3.804), train_loss = 2.21244665, grad/param norm = 2.2467e-01, time/batch = 0.6844s	
2276/29900 (epoch 3.806), train_loss = 1.82020723, grad/param norm = 1.9637e-01, time/batch = 0.6861s	
2277/29900 (epoch 3.808), train_loss = 1.97805928, grad/param norm = 1.8942e-01, time/batch = 0.6859s	
2278/29900 (epoch 3.809), train_loss = 2.10173915, grad/param norm = 2.0072e-01, time/batch = 0.7172s	
2279/29900 (epoch 3.811), train_loss = 1.96976714, grad/param norm = 2.0620e-01, time/batch = 0.7064s	
2280/29900 (epoch 3.813), train_loss = 2.13632025, grad/param norm = 1.9590e-01, time/batch = 0.6794s	
2281/29900 (epoch 3.814), train_loss = 2.18571600, grad/param norm = 2.0763e-01, time/batch = 0.6831s	
2282/29900 (epoch 3.816), train_loss = 2.26129597, grad/param norm = 2.2371e-01, time/batch = 0.6816s	
2283/29900 (epoch 3.818), train_loss = 2.13184005, grad/param norm = 2.2316e-01, time/batch = 0.6842s	
2284/29900 (epoch 3.819), train_loss = 2.31189150, grad/param norm = 1.9362e-01, time/batch = 0.6832s	
2285/29900 (epoch 3.821), train_loss = 1.97722261, grad/param norm = 1.9239e-01, time/batch = 0.6827s	
2286/29900 (epoch 3.823), train_loss = 1.97553102, grad/param norm = 1.9514e-01, time/batch = 0.6831s	
2287/29900 (epoch 3.824), train_loss = 2.08006796, grad/param norm = 1.9908e-01, time/batch = 0.6834s	
2288/29900 (epoch 3.826), train_loss = 2.14200754, grad/param norm = 2.1784e-01, time/batch = 0.6829s	
2289/29900 (epoch 3.828), train_loss = 2.01831980, grad/param norm = 1.9273e-01, time/batch = 0.6852s	
2290/29900 (epoch 3.829), train_loss = 1.88372842, grad/param norm = 1.9761e-01, time/batch = 0.6850s	
2291/29900 (epoch 3.831), train_loss = 2.03900953, grad/param norm = 1.9506e-01, time/batch = 0.6848s	
2292/29900 (epoch 3.833), train_loss = 1.86950386, grad/param norm = 1.7735e-01, time/batch = 0.6833s	
2293/29900 (epoch 3.834), train_loss = 1.87821098, grad/param norm = 1.8801e-01, time/batch = 0.6838s	
2294/29900 (epoch 3.836), train_loss = 2.01306213, grad/param norm = 1.7366e-01, time/batch = 0.6829s	
2295/29900 (epoch 3.838), train_loss = 2.09708396, grad/param norm = 1.9440e-01, time/batch = 0.6817s	
2296/29900 (epoch 3.839), train_loss = 1.85727772, grad/param norm = 1.9548e-01, time/batch = 0.6812s	
2297/29900 (epoch 3.841), train_loss = 2.12763417, grad/param norm = 2.1871e-01, time/batch = 0.6812s	
2298/29900 (epoch 3.843), train_loss = 1.93261060, grad/param norm = 2.0584e-01, time/batch = 0.6805s	
2299/29900 (epoch 3.844), train_loss = 1.91460428, grad/param norm = 1.8499e-01, time/batch = 0.6839s	
2300/29900 (epoch 3.846), train_loss = 1.91155693, grad/param norm = 1.9257e-01, time/batch = 0.6821s	
2301/29900 (epoch 3.848), train_loss = 1.90739698, grad/param norm = 1.8762e-01, time/batch = 0.6892s	
2302/29900 (epoch 3.849), train_loss = 2.01977188, grad/param norm = 2.3067e-01, time/batch = 0.6923s	
2303/29900 (epoch 3.851), train_loss = 2.03033116, grad/param norm = 2.0314e-01, time/batch = 0.7055s	
2304/29900 (epoch 3.853), train_loss = 1.89902204, grad/param norm = 2.0055e-01, time/batch = 0.6859s	
2305/29900 (epoch 3.855), train_loss = 1.90407860, grad/param norm = 1.8029e-01, time/batch = 0.7090s	
2306/29900 (epoch 3.856), train_loss = 1.85206350, grad/param norm = 2.1128e-01, time/batch = 0.6964s	
2307/29900 (epoch 3.858), train_loss = 1.81301662, grad/param norm = 1.7812e-01, time/batch = 0.6865s	
2308/29900 (epoch 3.860), train_loss = 1.73449198, grad/param norm = 1.8113e-01, time/batch = 0.6851s	
2309/29900 (epoch 3.861), train_loss = 2.06665421, grad/param norm = 2.0707e-01, time/batch = 0.6847s	
2310/29900 (epoch 3.863), train_loss = 1.87111896, grad/param norm = 2.2451e-01, time/batch = 0.6841s	
2311/29900 (epoch 3.865), train_loss = 1.70881502, grad/param norm = 1.8625e-01, time/batch = 0.6975s	
2312/29900 (epoch 3.866), train_loss = 1.91069421, grad/param norm = 1.8874e-01, time/batch = 0.6913s	
2313/29900 (epoch 3.868), train_loss = 1.97502288, grad/param norm = 1.9795e-01, time/batch = 0.6833s	
2314/29900 (epoch 3.870), train_loss = 2.11263060, grad/param norm = 2.1580e-01, time/batch = 0.6858s	
2315/29900 (epoch 3.871), train_loss = 1.88427559, grad/param norm = 2.0731e-01, time/batch = 0.6959s	
2316/29900 (epoch 3.873), train_loss = 1.98741200, grad/param norm = 1.9615e-01, time/batch = 0.7254s	
2317/29900 (epoch 3.875), train_loss = 2.04713872, grad/param norm = 1.8739e-01, time/batch = 0.6907s	
2318/29900 (epoch 3.876), train_loss = 1.81925080, grad/param norm = 1.7781e-01, time/batch = 0.6847s	
2319/29900 (epoch 3.878), train_loss = 2.02729975, grad/param norm = 1.8988e-01, time/batch = 0.6822s	
2320/29900 (epoch 3.880), train_loss = 1.78925436, grad/param norm = 1.9448e-01, time/batch = 0.6846s	
2321/29900 (epoch 3.881), train_loss = 2.14257765, grad/param norm = 1.9302e-01, time/batch = 0.6926s	
2322/29900 (epoch 3.883), train_loss = 2.00792531, grad/param norm = 1.9705e-01, time/batch = 0.6953s	
2323/29900 (epoch 3.885), train_loss = 2.11781029, grad/param norm = 1.9196e-01, time/batch = 0.7080s	
2324/29900 (epoch 3.886), train_loss = 2.16050052, grad/param norm = 1.9450e-01, time/batch = 0.7218s	
2325/29900 (epoch 3.888), train_loss = 1.98633909, grad/param norm = 1.8375e-01, time/batch = 0.7205s	
2326/29900 (epoch 3.890), train_loss = 1.86475255, grad/param norm = 1.7736e-01, time/batch = 0.7105s	
2327/29900 (epoch 3.891), train_loss = 1.95260279, grad/param norm = 2.0860e-01, time/batch = 0.7079s	
2328/29900 (epoch 3.893), train_loss = 1.86073570, grad/param norm = 2.0266e-01, time/batch = 0.6982s	
2329/29900 (epoch 3.895), train_loss = 1.86105224, grad/param norm = 1.8427e-01, time/batch = 0.6842s	
2330/29900 (epoch 3.896), train_loss = 1.91411062, grad/param norm = 1.8678e-01, time/batch = 0.6831s	
2331/29900 (epoch 3.898), train_loss = 1.95480994, grad/param norm = 2.4320e-01, time/batch = 0.6837s	
2332/29900 (epoch 3.900), train_loss = 1.98445932, grad/param norm = 1.9285e-01, time/batch = 0.6859s	
2333/29900 (epoch 3.901), train_loss = 1.79354073, grad/param norm = 1.6909e-01, time/batch = 0.6816s	
2334/29900 (epoch 3.903), train_loss = 1.77632443, grad/param norm = 1.7428e-01, time/batch = 0.7126s	
2335/29900 (epoch 3.905), train_loss = 1.94694778, grad/param norm = 1.9024e-01, time/batch = 0.7186s	
2336/29900 (epoch 3.906), train_loss = 2.18911855, grad/param norm = 2.1814e-01, time/batch = 0.6856s	
2337/29900 (epoch 3.908), train_loss = 2.00817866, grad/param norm = 1.8846e-01, time/batch = 0.6842s	
2338/29900 (epoch 3.910), train_loss = 1.90992995, grad/param norm = 2.0041e-01, time/batch = 0.6828s	
2339/29900 (epoch 3.911), train_loss = 1.88617679, grad/param norm = 2.1853e-01, time/batch = 0.6835s	
2340/29900 (epoch 3.913), train_loss = 1.69776425, grad/param norm = 1.7377e-01, time/batch = 0.6817s	
2341/29900 (epoch 3.915), train_loss = 1.95677343, grad/param norm = 2.1701e-01, time/batch = 0.6831s	
2342/29900 (epoch 3.916), train_loss = 1.69653776, grad/param norm = 1.7262e-01, time/batch = 0.6821s	
2343/29900 (epoch 3.918), train_loss = 2.03622055, grad/param norm = 2.1629e-01, time/batch = 0.6840s	
2344/29900 (epoch 3.920), train_loss = 2.27830284, grad/param norm = 1.9607e-01, time/batch = 0.6845s	
2345/29900 (epoch 3.921), train_loss = 2.17142979, grad/param norm = 2.0289e-01, time/batch = 0.6873s	
2346/29900 (epoch 3.923), train_loss = 2.00347871, grad/param norm = 1.8546e-01, time/batch = 0.6948s	
2347/29900 (epoch 3.925), train_loss = 1.90730750, grad/param norm = 1.8511e-01, time/batch = 0.7007s	
2348/29900 (epoch 3.926), train_loss = 1.78672344, grad/param norm = 1.9803e-01, time/batch = 0.7056s	
2349/29900 (epoch 3.928), train_loss = 1.88520479, grad/param norm = 1.9519e-01, time/batch = 0.6975s	
2350/29900 (epoch 3.930), train_loss = 1.86324414, grad/param norm = 2.0103e-01, time/batch = 0.6875s	
2351/29900 (epoch 3.931), train_loss = 1.77460128, grad/param norm = 1.8625e-01, time/batch = 0.6836s	
2352/29900 (epoch 3.933), train_loss = 1.89651353, grad/param norm = 1.8524e-01, time/batch = 0.6871s	
2353/29900 (epoch 3.935), train_loss = 2.18101929, grad/param norm = 2.0827e-01, time/batch = 0.7221s	
2354/29900 (epoch 3.936), train_loss = 1.92684370, grad/param norm = 2.0605e-01, time/batch = 0.7015s	
2355/29900 (epoch 3.938), train_loss = 1.66579776, grad/param norm = 1.7582e-01, time/batch = 0.6825s	
2356/29900 (epoch 3.940), train_loss = 1.84317066, grad/param norm = 1.9798e-01, time/batch = 0.6816s	
2357/29900 (epoch 3.941), train_loss = 1.82242871, grad/param norm = 1.8684e-01, time/batch = 0.6823s	
2358/29900 (epoch 3.943), train_loss = 1.94392657, grad/param norm = 1.9269e-01, time/batch = 0.6844s	
2359/29900 (epoch 3.945), train_loss = 2.08790490, grad/param norm = 2.1392e-01, time/batch = 0.6844s	
2360/29900 (epoch 3.946), train_loss = 2.01222096, grad/param norm = 1.9336e-01, time/batch = 0.6842s	
2361/29900 (epoch 3.948), train_loss = 1.76361720, grad/param norm = 1.6819e-01, time/batch = 0.6872s	
2362/29900 (epoch 3.950), train_loss = 2.04218382, grad/param norm = 1.8605e-01, time/batch = 0.6856s	
2363/29900 (epoch 3.952), train_loss = 1.68767138, grad/param norm = 1.7338e-01, time/batch = 0.6820s	
2364/29900 (epoch 3.953), train_loss = 1.68537182, grad/param norm = 1.8298e-01, time/batch = 0.6824s	
2365/29900 (epoch 3.955), train_loss = 1.98917493, grad/param norm = 1.9455e-01, time/batch = 0.6804s	
2366/29900 (epoch 3.957), train_loss = 2.01160163, grad/param norm = 1.9806e-01, time/batch = 0.6820s	
2367/29900 (epoch 3.958), train_loss = 2.09017164, grad/param norm = 1.8276e-01, time/batch = 0.6837s	
2368/29900 (epoch 3.960), train_loss = 2.13920196, grad/param norm = 2.0503e-01, time/batch = 0.6872s	
2369/29900 (epoch 3.962), train_loss = 2.13041449, grad/param norm = 2.2590e-01, time/batch = 0.6835s	
2370/29900 (epoch 3.963), train_loss = 1.87931981, grad/param norm = 1.7553e-01, time/batch = 0.6887s	
2371/29900 (epoch 3.965), train_loss = 1.97103277, grad/param norm = 1.9139e-01, time/batch = 0.6881s	
2372/29900 (epoch 3.967), train_loss = 1.82652078, grad/param norm = 1.9944e-01, time/batch = 0.6858s	
2373/29900 (epoch 3.968), train_loss = 2.06229229, grad/param norm = 1.9578e-01, time/batch = 0.6858s	
2374/29900 (epoch 3.970), train_loss = 1.87699578, grad/param norm = 1.8932e-01, time/batch = 0.6855s	
2375/29900 (epoch 3.972), train_loss = 1.65215695, grad/param norm = 1.8102e-01, time/batch = 0.6860s	
2376/29900 (epoch 3.973), train_loss = 1.67310092, grad/param norm = 1.6686e-01, time/batch = 0.6867s	
2377/29900 (epoch 3.975), train_loss = 1.97909530, grad/param norm = 2.0512e-01, time/batch = 0.6897s	
2378/29900 (epoch 3.977), train_loss = 1.86418209, grad/param norm = 1.6685e-01, time/batch = 0.6820s	
2379/29900 (epoch 3.978), train_loss = 1.85700002, grad/param norm = 1.8834e-01, time/batch = 0.6840s	
2380/29900 (epoch 3.980), train_loss = 1.99000256, grad/param norm = 1.8582e-01, time/batch = 0.6826s	
2381/29900 (epoch 3.982), train_loss = 1.93111740, grad/param norm = 1.8516e-01, time/batch = 0.6873s	
2382/29900 (epoch 3.983), train_loss = 1.96964808, grad/param norm = 2.1848e-01, time/batch = 0.6874s	
2383/29900 (epoch 3.985), train_loss = 2.09549796, grad/param norm = 2.0581e-01, time/batch = 0.6878s	
2384/29900 (epoch 3.987), train_loss = 1.89796145, grad/param norm = 1.9531e-01, time/batch = 0.6852s	
2385/29900 (epoch 3.988), train_loss = 1.91227730, grad/param norm = 1.6157e-01, time/batch = 0.6836s	
2386/29900 (epoch 3.990), train_loss = 1.84153686, grad/param norm = 2.0115e-01, time/batch = 0.6833s	
2387/29900 (epoch 3.992), train_loss = 1.64075030, grad/param norm = 1.9249e-01, time/batch = 0.6831s	
2388/29900 (epoch 3.993), train_loss = 1.92734335, grad/param norm = 1.8269e-01, time/batch = 0.6937s	
2389/29900 (epoch 3.995), train_loss = 1.88037352, grad/param norm = 1.7876e-01, time/batch = 0.6943s	
2390/29900 (epoch 3.997), train_loss = 1.96768546, grad/param norm = 1.7484e-01, time/batch = 0.7100s	
2391/29900 (epoch 3.998), train_loss = 1.89621566, grad/param norm = 2.0848e-01, time/batch = 0.7363s	
2392/29900 (epoch 4.000), train_loss = 1.81118368, grad/param norm = 1.8312e-01, time/batch = 0.6888s	
2393/29900 (epoch 4.002), train_loss = 1.95219821, grad/param norm = 1.9442e-01, time/batch = 0.6854s	
2394/29900 (epoch 4.003), train_loss = 1.90047533, grad/param norm = 2.0125e-01, time/batch = 0.6829s	
2395/29900 (epoch 4.005), train_loss = 1.92396956, grad/param norm = 1.9648e-01, time/batch = 0.6819s	
2396/29900 (epoch 4.007), train_loss = 1.98062354, grad/param norm = 2.0293e-01, time/batch = 0.6927s	
2397/29900 (epoch 4.008), train_loss = 1.92281312, grad/param norm = 2.0837e-01, time/batch = 0.6862s	
2398/29900 (epoch 4.010), train_loss = 1.89064804, grad/param norm = 1.8193e-01, time/batch = 0.6862s	
2399/29900 (epoch 4.012), train_loss = 1.77803373, grad/param norm = 1.6705e-01, time/batch = 0.6839s	
2400/29900 (epoch 4.013), train_loss = 1.85004112, grad/param norm = 2.0645e-01, time/batch = 0.6823s	
2401/29900 (epoch 4.015), train_loss = 1.90456125, grad/param norm = 2.1387e-01, time/batch = 0.6834s	
2402/29900 (epoch 4.017), train_loss = 1.90679103, grad/param norm = 2.1129e-01, time/batch = 0.6883s	
2403/29900 (epoch 4.018), train_loss = 1.98942780, grad/param norm = 2.2844e-01, time/batch = 0.6906s	
2404/29900 (epoch 4.020), train_loss = 1.99979309, grad/param norm = 1.9507e-01, time/batch = 0.6839s	
2405/29900 (epoch 4.022), train_loss = 1.91378668, grad/param norm = 2.0243e-01, time/batch = 0.6872s	
2406/29900 (epoch 4.023), train_loss = 2.06649462, grad/param norm = 1.9393e-01, time/batch = 0.6864s	
2407/29900 (epoch 4.025), train_loss = 1.94162269, grad/param norm = 1.9617e-01, time/batch = 0.6848s	
2408/29900 (epoch 4.027), train_loss = 1.74864690, grad/param norm = 1.8657e-01, time/batch = 0.6843s	
2409/29900 (epoch 4.028), train_loss = 2.09581056, grad/param norm = 2.1109e-01, time/batch = 0.7008s	
2410/29900 (epoch 4.030), train_loss = 2.00621952, grad/param norm = 2.0718e-01, time/batch = 0.7227s	
2411/29900 (epoch 4.032), train_loss = 1.81778077, grad/param norm = 1.9328e-01, time/batch = 0.6871s	
2412/29900 (epoch 4.033), train_loss = 1.90212889, grad/param norm = 1.8718e-01, time/batch = 0.6880s	
2413/29900 (epoch 4.035), train_loss = 1.79651422, grad/param norm = 1.8446e-01, time/batch = 0.6853s	
2414/29900 (epoch 4.037), train_loss = 1.87444599, grad/param norm = 1.7556e-01, time/batch = 0.6892s	
2415/29900 (epoch 4.038), train_loss = 1.94312260, grad/param norm = 1.9299e-01, time/batch = 0.6822s	
2416/29900 (epoch 4.040), train_loss = 1.68559205, grad/param norm = 2.2566e-01, time/batch = 0.6831s	
2417/29900 (epoch 4.042), train_loss = 1.78114769, grad/param norm = 2.0725e-01, time/batch = 0.6862s	
2418/29900 (epoch 4.043), train_loss = 2.02285481, grad/param norm = 2.0176e-01, time/batch = 0.6841s	
2419/29900 (epoch 4.045), train_loss = 1.90638725, grad/param norm = 1.8980e-01, time/batch = 0.6839s	
2420/29900 (epoch 4.047), train_loss = 1.83196369, grad/param norm = 2.0625e-01, time/batch = 0.6860s	
2421/29900 (epoch 4.048), train_loss = 1.75416183, grad/param norm = 2.1227e-01, time/batch = 0.6861s	
2422/29900 (epoch 4.050), train_loss = 1.71425928, grad/param norm = 1.6720e-01, time/batch = 0.6869s	
2423/29900 (epoch 4.052), train_loss = 1.71429387, grad/param norm = 1.7686e-01, time/batch = 0.6833s	
2424/29900 (epoch 4.054), train_loss = 1.99744033, grad/param norm = 2.0859e-01, time/batch = 0.6815s	
2425/29900 (epoch 4.055), train_loss = 1.93085690, grad/param norm = 2.4819e-01, time/batch = 0.6914s	
2426/29900 (epoch 4.057), train_loss = 1.84146597, grad/param norm = 1.9597e-01, time/batch = 0.6857s	
2427/29900 (epoch 4.059), train_loss = 2.03510197, grad/param norm = 1.9877e-01, time/batch = 0.6826s	
2428/29900 (epoch 4.060), train_loss = 1.96372810, grad/param norm = 2.1440e-01, time/batch = 0.7109s	
2429/29900 (epoch 4.062), train_loss = 1.88716018, grad/param norm = 1.9319e-01, time/batch = 0.7129s	
2430/29900 (epoch 4.064), train_loss = 1.93652406, grad/param norm = 1.8281e-01, time/batch = 0.6812s	
2431/29900 (epoch 4.065), train_loss = 2.17097026, grad/param norm = 2.0487e-01, time/batch = 0.6845s	
2432/29900 (epoch 4.067), train_loss = 1.90969134, grad/param norm = 1.8090e-01, time/batch = 0.6832s	
2433/29900 (epoch 4.069), train_loss = 1.87737377, grad/param norm = 1.8375e-01, time/batch = 0.6899s	
2434/29900 (epoch 4.070), train_loss = 1.89473597, grad/param norm = 1.8064e-01, time/batch = 0.6842s	
2435/29900 (epoch 4.072), train_loss = 1.88867065, grad/param norm = 1.9518e-01, time/batch = 0.6840s	
2436/29900 (epoch 4.074), train_loss = 1.92051779, grad/param norm = 2.0885e-01, time/batch = 0.6877s	
2437/29900 (epoch 4.075), train_loss = 1.84280315, grad/param norm = 1.8908e-01, time/batch = 0.6851s	
2438/29900 (epoch 4.077), train_loss = 1.75386169, grad/param norm = 1.8459e-01, time/batch = 0.6818s	
2439/29900 (epoch 4.079), train_loss = 1.79205904, grad/param norm = 2.0852e-01, time/batch = 0.6833s	
2440/29900 (epoch 4.080), train_loss = 1.68593833, grad/param norm = 1.9834e-01, time/batch = 0.6834s	
2441/29900 (epoch 4.082), train_loss = 1.72533320, grad/param norm = 1.7945e-01, time/batch = 0.6846s	
2442/29900 (epoch 4.084), train_loss = 2.05828262, grad/param norm = 1.9407e-01, time/batch = 0.6854s	
2443/29900 (epoch 4.085), train_loss = 2.09090573, grad/param norm = 1.7489e-01, time/batch = 0.6869s	
2444/29900 (epoch 4.087), train_loss = 2.07119114, grad/param norm = 1.8522e-01, time/batch = 0.6859s	
2445/29900 (epoch 4.089), train_loss = 1.81699157, grad/param norm = 1.8926e-01, time/batch = 0.6952s	
2446/29900 (epoch 4.090), train_loss = 1.78440232, grad/param norm = 2.2039e-01, time/batch = 0.6824s	
2447/29900 (epoch 4.092), train_loss = 1.70058085, grad/param norm = 1.9145e-01, time/batch = 0.7199s	
2448/29900 (epoch 4.094), train_loss = 1.92257503, grad/param norm = 1.9480e-01, time/batch = 0.7039s	
2449/29900 (epoch 4.095), train_loss = 1.86874573, grad/param norm = 1.8134e-01, time/batch = 0.6810s	
2450/29900 (epoch 4.097), train_loss = 1.81258425, grad/param norm = 1.8698e-01, time/batch = 0.6821s	
2451/29900 (epoch 4.099), train_loss = 1.84357045, grad/param norm = 1.9025e-01, time/batch = 0.6857s	
2452/29900 (epoch 4.100), train_loss = 1.54696971, grad/param norm = 1.7726e-01, time/batch = 0.6859s	
2453/29900 (epoch 4.102), train_loss = 1.79256103, grad/param norm = 1.8965e-01, time/batch = 0.6830s	
2454/29900 (epoch 4.104), train_loss = 1.93109505, grad/param norm = 1.9800e-01, time/batch = 0.6846s	
2455/29900 (epoch 4.105), train_loss = 1.87076800, grad/param norm = 1.8189e-01, time/batch = 0.6849s	
2456/29900 (epoch 4.107), train_loss = 1.81890323, grad/param norm = 1.8190e-01, time/batch = 0.6840s	
2457/29900 (epoch 4.109), train_loss = 1.95562834, grad/param norm = 1.9622e-01, time/batch = 0.6818s	
2458/29900 (epoch 4.110), train_loss = 1.83739040, grad/param norm = 1.8666e-01, time/batch = 0.6839s	
2459/29900 (epoch 4.112), train_loss = 1.91915686, grad/param norm = 1.8295e-01, time/batch = 0.6869s	
2460/29900 (epoch 4.114), train_loss = 1.75454705, grad/param norm = 1.7124e-01, time/batch = 0.6963s	
2461/29900 (epoch 4.115), train_loss = 1.87701218, grad/param norm = 1.9857e-01, time/batch = 0.6843s	
2462/29900 (epoch 4.117), train_loss = 1.79812431, grad/param norm = 2.0899e-01, time/batch = 0.6862s	
2463/29900 (epoch 4.119), train_loss = 1.72220136, grad/param norm = 1.8460e-01, time/batch = 0.6858s	
2464/29900 (epoch 4.120), train_loss = 1.95125601, grad/param norm = 2.1051e-01, time/batch = 0.6842s	
2465/29900 (epoch 4.122), train_loss = 1.98262785, grad/param norm = 2.0234e-01, time/batch = 0.6893s	
2466/29900 (epoch 4.124), train_loss = 1.90273074, grad/param norm = 1.7392e-01, time/batch = 0.7255s	
2467/29900 (epoch 4.125), train_loss = 1.75245451, grad/param norm = 1.8141e-01, time/batch = 0.6996s	
2468/29900 (epoch 4.127), train_loss = 1.91225751, grad/param norm = 2.1110e-01, time/batch = 0.6871s	
2469/29900 (epoch 4.129), train_loss = 1.94554132, grad/param norm = 2.1231e-01, time/batch = 0.6844s	
2470/29900 (epoch 4.130), train_loss = 1.70919280, grad/param norm = 1.7522e-01, time/batch = 0.6850s	
2471/29900 (epoch 4.132), train_loss = 1.75029797, grad/param norm = 1.9954e-01, time/batch = 0.6881s	
2472/29900 (epoch 4.134), train_loss = 2.03921725, grad/param norm = 1.9531e-01, time/batch = 0.6837s	
2473/29900 (epoch 4.135), train_loss = 1.72258365, grad/param norm = 2.0014e-01, time/batch = 0.6862s	
2474/29900 (epoch 4.137), train_loss = 1.74618560, grad/param norm = 1.7874e-01, time/batch = 0.6851s	
2475/29900 (epoch 4.139), train_loss = 1.87361010, grad/param norm = 2.0591e-01, time/batch = 0.6926s	
2476/29900 (epoch 4.140), train_loss = 1.84077614, grad/param norm = 1.7768e-01, time/batch = 0.7060s	
2477/29900 (epoch 4.142), train_loss = 1.69818353, grad/param norm = 1.7889e-01, time/batch = 0.6861s	
2478/29900 (epoch 4.144), train_loss = 1.80833932, grad/param norm = 1.8312e-01, time/batch = 0.7075s	
2479/29900 (epoch 4.145), train_loss = 1.84351428, grad/param norm = 1.7831e-01, time/batch = 0.6900s	
2480/29900 (epoch 4.147), train_loss = 1.62692483, grad/param norm = 1.7341e-01, time/batch = 0.7028s	
2481/29900 (epoch 4.149), train_loss = 1.67418731, grad/param norm = 1.8190e-01, time/batch = 0.6949s	
2482/29900 (epoch 4.151), train_loss = 1.75416544, grad/param norm = 2.1558e-01, time/batch = 0.6862s	
2483/29900 (epoch 4.152), train_loss = 1.87030803, grad/param norm = 2.0596e-01, time/batch = 0.6873s	
2484/29900 (epoch 4.154), train_loss = 1.84621115, grad/param norm = 1.9803e-01, time/batch = 0.7002s	
2485/29900 (epoch 4.156), train_loss = 1.90174189, grad/param norm = 1.8823e-01, time/batch = 0.7247s	
2486/29900 (epoch 4.157), train_loss = 1.88037233, grad/param norm = 1.8694e-01, time/batch = 0.6819s	
2487/29900 (epoch 4.159), train_loss = 1.86958730, grad/param norm = 1.8666e-01, time/batch = 0.7043s	
2488/29900 (epoch 4.161), train_loss = 1.95686196, grad/param norm = 2.0084e-01, time/batch = 0.6919s	
2489/29900 (epoch 4.162), train_loss = 1.87776543, grad/param norm = 1.8503e-01, time/batch = 0.6817s	
2490/29900 (epoch 4.164), train_loss = 2.08153210, grad/param norm = 1.8065e-01, time/batch = 0.6830s	
2491/29900 (epoch 4.166), train_loss = 1.74771773, grad/param norm = 1.6540e-01, time/batch = 0.6938s	
2492/29900 (epoch 4.167), train_loss = 2.00271216, grad/param norm = 1.7631e-01, time/batch = 0.6832s	
2493/29900 (epoch 4.169), train_loss = 1.64015861, grad/param norm = 1.8132e-01, time/batch = 0.6871s	
2494/29900 (epoch 4.171), train_loss = 1.78391106, grad/param norm = 1.7538e-01, time/batch = 0.6828s	
2495/29900 (epoch 4.172), train_loss = 1.84141621, grad/param norm = 1.7394e-01, time/batch = 0.6816s	
2496/29900 (epoch 4.174), train_loss = 1.74099453, grad/param norm = 1.8448e-01, time/batch = 0.6823s	
2497/29900 (epoch 4.176), train_loss = 1.75253953, grad/param norm = 1.9083e-01, time/batch = 0.6822s	
2498/29900 (epoch 4.177), train_loss = 1.67165991, grad/param norm = 1.8688e-01, time/batch = 0.6853s	
2499/29900 (epoch 4.179), train_loss = 1.80611835, grad/param norm = 2.0134e-01, time/batch = 0.6839s	
2500/29900 (epoch 4.181), train_loss = 1.65401818, grad/param norm = 1.8232e-01, time/batch = 0.6830s	
2501/29900 (epoch 4.182), train_loss = 1.86328788, grad/param norm = 2.0101e-01, time/batch = 0.6853s	
2502/29900 (epoch 4.184), train_loss = 1.78021643, grad/param norm = 2.0507e-01, time/batch = 0.6837s	
2503/29900 (epoch 4.186), train_loss = 1.70486813, grad/param norm = 1.7518e-01, time/batch = 0.7095s	
2504/29900 (epoch 4.187), train_loss = 1.79959478, grad/param norm = 1.7422e-01, time/batch = 0.7161s	
2505/29900 (epoch 4.189), train_loss = 1.84809131, grad/param norm = 1.7293e-01, time/batch = 0.6859s	
2506/29900 (epoch 4.191), train_loss = 1.76779351, grad/param norm = 1.8856e-01, time/batch = 0.6868s	
2507/29900 (epoch 4.192), train_loss = 1.92896288, grad/param norm = 1.8600e-01, time/batch = 0.6828s	
2508/29900 (epoch 4.194), train_loss = 1.86040008, grad/param norm = 1.8068e-01, time/batch = 0.6825s	
2509/29900 (epoch 4.196), train_loss = 1.91505949, grad/param norm = 1.8806e-01, time/batch = 0.6830s	
2510/29900 (epoch 4.197), train_loss = 1.65200253, grad/param norm = 1.7345e-01, time/batch = 0.6862s	
2511/29900 (epoch 4.199), train_loss = 1.85318680, grad/param norm = 2.0824e-01, time/batch = 0.6947s	
2512/29900 (epoch 4.201), train_loss = 1.98111406, grad/param norm = 1.7668e-01, time/batch = 0.7016s	
2513/29900 (epoch 4.202), train_loss = 1.84392225, grad/param norm = 1.9278e-01, time/batch = 0.6876s	
2514/29900 (epoch 4.204), train_loss = 1.88538184, grad/param norm = 2.3685e-01, time/batch = 0.6845s	
2515/29900 (epoch 4.206), train_loss = 2.09610409, grad/param norm = 2.1069e-01, time/batch = 0.6841s	
2516/29900 (epoch 4.207), train_loss = 1.79060236, grad/param norm = 2.2102e-01, time/batch = 0.6834s	
2517/29900 (epoch 4.209), train_loss = 1.86110895, grad/param norm = 1.9775e-01, time/batch = 0.6844s	
2518/29900 (epoch 4.211), train_loss = 1.64068696, grad/param norm = 1.8024e-01, time/batch = 0.6824s	
2519/29900 (epoch 4.212), train_loss = 1.74870980, grad/param norm = 1.8653e-01, time/batch = 0.6822s	
2520/29900 (epoch 4.214), train_loss = 1.98734063, grad/param norm = 2.0829e-01, time/batch = 0.6854s	
2521/29900 (epoch 4.216), train_loss = 1.80307432, grad/param norm = 1.7429e-01, time/batch = 0.7079s	
2522/29900 (epoch 4.217), train_loss = 1.92337766, grad/param norm = 1.9652e-01, time/batch = 0.6961s	
2523/29900 (epoch 4.219), train_loss = 1.97801027, grad/param norm = 1.9787e-01, time/batch = 0.6958s	
2524/29900 (epoch 4.221), train_loss = 1.93508184, grad/param norm = 1.9861e-01, time/batch = 0.7002s	
2525/29900 (epoch 4.222), train_loss = 1.88717990, grad/param norm = 1.9846e-01, time/batch = 0.6992s	
2526/29900 (epoch 4.224), train_loss = 1.82368045, grad/param norm = 1.6725e-01, time/batch = 0.7017s	
2527/29900 (epoch 4.226), train_loss = 1.89422436, grad/param norm = 1.9255e-01, time/batch = 0.6951s	
2528/29900 (epoch 4.227), train_loss = 1.78494739, grad/param norm = 1.7988e-01, time/batch = 0.6844s	
2529/29900 (epoch 4.229), train_loss = 1.71784924, grad/param norm = 1.6384e-01, time/batch = 0.6835s	
2530/29900 (epoch 4.231), train_loss = 1.69647885, grad/param norm = 1.7686e-01, time/batch = 0.6800s	
2531/29900 (epoch 4.232), train_loss = 1.84503675, grad/param norm = 1.8989e-01, time/batch = 0.6835s	
2532/29900 (epoch 4.234), train_loss = 1.80478646, grad/param norm = 1.7469e-01, time/batch = 0.6834s	
2533/29900 (epoch 4.236), train_loss = 1.85662218, grad/param norm = 1.9134e-01, time/batch = 0.6815s	
2534/29900 (epoch 4.237), train_loss = 2.01041499, grad/param norm = 2.1049e-01, time/batch = 0.6826s	
2535/29900 (epoch 4.239), train_loss = 1.86682401, grad/param norm = 1.8731e-01, time/batch = 0.6846s	
2536/29900 (epoch 4.241), train_loss = 1.81078375, grad/param norm = 1.9458e-01, time/batch = 0.6823s	
2537/29900 (epoch 4.242), train_loss = 1.96297906, grad/param norm = 2.0135e-01, time/batch = 0.6840s	
2538/29900 (epoch 4.244), train_loss = 1.93693977, grad/param norm = 1.8881e-01, time/batch = 0.6852s	
2539/29900 (epoch 4.246), train_loss = 1.75665001, grad/param norm = 1.6904e-01, time/batch = 0.6835s	
2540/29900 (epoch 4.247), train_loss = 1.80926936, grad/param norm = 1.7110e-01, time/batch = 0.6862s	
2541/29900 (epoch 4.249), train_loss = 1.86204649, grad/param norm = 1.9409e-01, time/batch = 0.6853s	
2542/29900 (epoch 4.251), train_loss = 2.00672083, grad/param norm = 1.9058e-01, time/batch = 0.6857s	
2543/29900 (epoch 4.253), train_loss = 1.90720325, grad/param norm = 1.9654e-01, time/batch = 0.6887s	
2544/29900 (epoch 4.254), train_loss = 1.91283899, grad/param norm = 1.9381e-01, time/batch = 0.6904s	
2545/29900 (epoch 4.256), train_loss = 1.84932471, grad/param norm = 1.8468e-01, time/batch = 0.7093s	
2546/29900 (epoch 4.258), train_loss = 2.01026252, grad/param norm = 1.8416e-01, time/batch = 0.6917s	
2547/29900 (epoch 4.259), train_loss = 1.91050132, grad/param norm = 1.9898e-01, time/batch = 0.6841s	
2548/29900 (epoch 4.261), train_loss = 1.91355675, grad/param norm = 2.0845e-01, time/batch = 0.6843s	
2549/29900 (epoch 4.263), train_loss = 2.08119802, grad/param norm = 2.3327e-01, time/batch = 0.6857s	
2550/29900 (epoch 4.264), train_loss = 1.79777188, grad/param norm = 1.9573e-01, time/batch = 0.6854s	
2551/29900 (epoch 4.266), train_loss = 1.94286456, grad/param norm = 1.8924e-01, time/batch = 0.6913s	
2552/29900 (epoch 4.268), train_loss = 1.86798125, grad/param norm = 1.8277e-01, time/batch = 0.6897s	
2553/29900 (epoch 4.269), train_loss = 1.92225625, grad/param norm = 1.7260e-01, time/batch = 0.6858s	
2554/29900 (epoch 4.271), train_loss = 1.75681293, grad/param norm = 1.8415e-01, time/batch = 0.6967s	
2555/29900 (epoch 4.273), train_loss = 1.81994086, grad/param norm = 1.8261e-01, time/batch = 0.6875s	
2556/29900 (epoch 4.274), train_loss = 1.96938609, grad/param norm = 2.0200e-01, time/batch = 0.6915s	
2557/29900 (epoch 4.276), train_loss = 1.93115187, grad/param norm = 1.9995e-01, time/batch = 0.6832s	
2558/29900 (epoch 4.278), train_loss = 1.81902447, grad/param norm = 1.7594e-01, time/batch = 0.6840s	
2559/29900 (epoch 4.279), train_loss = 2.02440559, grad/param norm = 2.3482e-01, time/batch = 0.6844s	
2560/29900 (epoch 4.281), train_loss = 1.79336524, grad/param norm = 1.8139e-01, time/batch = 0.6852s	
2561/29900 (epoch 4.283), train_loss = 2.01646468, grad/param norm = 1.9542e-01, time/batch = 0.6864s	
2562/29900 (epoch 4.284), train_loss = 2.12254111, grad/param norm = 1.9632e-01, time/batch = 0.6913s	
2563/29900 (epoch 4.286), train_loss = 2.34198123, grad/param norm = 1.9755e-01, time/batch = 0.7014s	
2564/29900 (epoch 4.288), train_loss = 2.78901716, grad/param norm = 6.4547e-01, time/batch = 0.8039s	
