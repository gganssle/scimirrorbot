tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 227, val: 12, test: 0	
vocab size: 171	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 308267	
cloning rnn	
cloning criterion	
1/11350 (epoch 0.004), train_loss = 5.15441183, grad/param norm = 5.2321e-01, time/batch = 0.7236s	
2/11350 (epoch 0.009), train_loss = 4.78839134, grad/param norm = 1.7956e+00, time/batch = 0.6868s	
3/11350 (epoch 0.013), train_loss = 3.91956884, grad/param norm = 1.5333e+00, time/batch = 0.6841s	
4/11350 (epoch 0.018), train_loss = 3.56385711, grad/param norm = 8.0581e-01, time/batch = 0.6880s	
5/11350 (epoch 0.022), train_loss = 3.58378185, grad/param norm = 6.7899e-01, time/batch = 0.6869s	
6/11350 (epoch 0.026), train_loss = 3.50571837, grad/param norm = 7.8721e-01, time/batch = 0.6862s	
7/11350 (epoch 0.031), train_loss = 3.37317731, grad/param norm = 7.9840e-01, time/batch = 0.6860s	
8/11350 (epoch 0.035), train_loss = 3.51261883, grad/param norm = 7.0321e-01, time/batch = 0.6846s	
9/11350 (epoch 0.040), train_loss = 3.45457666, grad/param norm = 6.7811e-01, time/batch = 0.6843s	
10/11350 (epoch 0.044), train_loss = 3.61191825, grad/param norm = 5.6101e-01, time/batch = 0.6836s	
11/11350 (epoch 0.048), train_loss = 3.58012411, grad/param norm = 6.0762e-01, time/batch = 0.6860s	
12/11350 (epoch 0.053), train_loss = 3.49454644, grad/param norm = 5.7601e-01, time/batch = 0.6860s	
13/11350 (epoch 0.057), train_loss = 3.52739418, grad/param norm = 6.2316e-01, time/batch = 0.6867s	
14/11350 (epoch 0.062), train_loss = 3.50982467, grad/param norm = 5.5569e-01, time/batch = 0.6831s	
15/11350 (epoch 0.066), train_loss = 3.56044621, grad/param norm = 6.1981e-01, time/batch = 0.6847s	
16/11350 (epoch 0.070), train_loss = 3.45696276, grad/param norm = 6.8516e-01, time/batch = 0.6841s	
17/11350 (epoch 0.075), train_loss = 3.37575410, grad/param norm = 6.7806e-01, time/batch = 0.6836s	
18/11350 (epoch 0.079), train_loss = 3.53293827, grad/param norm = 5.7294e-01, time/batch = 0.6848s	
19/11350 (epoch 0.084), train_loss = 3.43679463, grad/param norm = 5.7158e-01, time/batch = 0.6865s	
20/11350 (epoch 0.088), train_loss = 3.46781632, grad/param norm = 5.8316e-01, time/batch = 0.6854s	
21/11350 (epoch 0.093), train_loss = 3.28906269, grad/param norm = 5.7747e-01, time/batch = 0.6881s	
22/11350 (epoch 0.097), train_loss = 3.59803342, grad/param norm = 6.2898e-01, time/batch = 0.6931s	
23/11350 (epoch 0.101), train_loss = 3.44888930, grad/param norm = 6.8877e-01, time/batch = 0.6927s	
24/11350 (epoch 0.106), train_loss = 3.63957236, grad/param norm = 5.7350e-01, time/batch = 0.6813s	
25/11350 (epoch 0.110), train_loss = 3.45697571, grad/param norm = 7.4800e-01, time/batch = 0.6825s	
26/11350 (epoch 0.115), train_loss = 3.55669989, grad/param norm = 5.4606e-01, time/batch = 0.6912s	
27/11350 (epoch 0.119), train_loss = 3.45364227, grad/param norm = 4.4771e-01, time/batch = 0.6879s	
28/11350 (epoch 0.123), train_loss = 3.42939464, grad/param norm = 6.8247e-01, time/batch = 0.6870s	
29/11350 (epoch 0.128), train_loss = 3.43880970, grad/param norm = 6.1139e-01, time/batch = 0.6894s	
30/11350 (epoch 0.132), train_loss = 3.39344121, grad/param norm = 6.2750e-01, time/batch = 0.7023s	
31/11350 (epoch 0.137), train_loss = 3.45747235, grad/param norm = 6.9510e-01, time/batch = 0.6916s	
32/11350 (epoch 0.141), train_loss = 3.45864992, grad/param norm = 5.1812e-01, time/batch = 0.6887s	
33/11350 (epoch 0.145), train_loss = 3.55734591, grad/param norm = 7.0905e-01, time/batch = 0.6901s	
34/11350 (epoch 0.150), train_loss = 3.57499297, grad/param norm = 5.4953e-01, time/batch = 0.6840s	
35/11350 (epoch 0.154), train_loss = 3.61290500, grad/param norm = 5.4795e-01, time/batch = 0.6868s	
36/11350 (epoch 0.159), train_loss = 3.42653997, grad/param norm = 5.2669e-01, time/batch = 0.7176s	
37/11350 (epoch 0.163), train_loss = 3.41552410, grad/param norm = 5.5365e-01, time/batch = 0.7218s	
38/11350 (epoch 0.167), train_loss = 3.45262573, grad/param norm = 6.9097e-01, time/batch = 0.7013s	
39/11350 (epoch 0.172), train_loss = 3.61573599, grad/param norm = 7.4103e-01, time/batch = 0.6973s	
40/11350 (epoch 0.176), train_loss = 3.49826981, grad/param norm = 5.6012e-01, time/batch = 0.7044s	
41/11350 (epoch 0.181), train_loss = 3.52626436, grad/param norm = 7.6981e-01, time/batch = 0.7212s	
42/11350 (epoch 0.185), train_loss = 3.56948414, grad/param norm = 5.5182e-01, time/batch = 0.7187s	
43/11350 (epoch 0.189), train_loss = 3.44301228, grad/param norm = 6.6996e-01, time/batch = 0.7174s	
44/11350 (epoch 0.194), train_loss = 3.46396601, grad/param norm = 6.2518e-01, time/batch = 0.7059s	
45/11350 (epoch 0.198), train_loss = 3.51541513, grad/param norm = 6.0189e-01, time/batch = 0.6855s	
46/11350 (epoch 0.203), train_loss = 3.56575788, grad/param norm = 5.6023e-01, time/batch = 0.6886s	
47/11350 (epoch 0.207), train_loss = 3.47320435, grad/param norm = 7.2516e-01, time/batch = 0.6835s	
48/11350 (epoch 0.211), train_loss = 3.54526132, grad/param norm = 8.4808e-01, time/batch = 0.6811s	
49/11350 (epoch 0.216), train_loss = 3.50150029, grad/param norm = 6.7090e-01, time/batch = 0.6844s	
50/11350 (epoch 0.220), train_loss = 3.41871736, grad/param norm = 6.8081e-01, time/batch = 0.6863s	
51/11350 (epoch 0.225), train_loss = 3.45105622, grad/param norm = 5.5105e-01, time/batch = 0.6856s	
52/11350 (epoch 0.229), train_loss = 3.66066713, grad/param norm = 8.4077e-01, time/batch = 0.6841s	
53/11350 (epoch 0.233), train_loss = 3.50662570, grad/param norm = 7.5264e-01, time/batch = 0.6828s	
54/11350 (epoch 0.238), train_loss = 3.64629613, grad/param norm = 7.0095e-01, time/batch = 0.6832s	
55/11350 (epoch 0.242), train_loss = 3.44160841, grad/param norm = 6.1399e-01, time/batch = 0.6849s	
56/11350 (epoch 0.247), train_loss = 3.53151336, grad/param norm = 5.4357e-01, time/batch = 0.6876s	
57/11350 (epoch 0.251), train_loss = 3.48746662, grad/param norm = 4.4032e-01, time/batch = 0.6851s	
58/11350 (epoch 0.256), train_loss = 3.71329895, grad/param norm = 5.8520e-01, time/batch = 0.6860s	
59/11350 (epoch 0.260), train_loss = 3.57305474, grad/param norm = 5.7810e-01, time/batch = 0.6851s	
60/11350 (epoch 0.264), train_loss = 3.37264630, grad/param norm = 6.4367e-01, time/batch = 0.6838s	
61/11350 (epoch 0.269), train_loss = 3.55106767, grad/param norm = 6.7405e-01, time/batch = 0.6835s	
62/11350 (epoch 0.273), train_loss = 3.49299330, grad/param norm = 7.2145e-01, time/batch = 0.6852s	
63/11350 (epoch 0.278), train_loss = 3.43025009, grad/param norm = 5.8864e-01, time/batch = 0.6821s	
64/11350 (epoch 0.282), train_loss = 3.61747222, grad/param norm = 6.4807e-01, time/batch = 0.6836s	
65/11350 (epoch 0.286), train_loss = 3.39108239, grad/param norm = 7.6515e-01, time/batch = 0.6831s	
66/11350 (epoch 0.291), train_loss = 3.51418324, grad/param norm = 8.6753e-01, time/batch = 0.6806s	
67/11350 (epoch 0.295), train_loss = 3.47119011, grad/param norm = 6.3239e-01, time/batch = 0.6851s	
68/11350 (epoch 0.300), train_loss = 3.46825928, grad/param norm = 6.0444e-01, time/batch = 0.6822s	
69/11350 (epoch 0.304), train_loss = 3.48772403, grad/param norm = 4.5922e-01, time/batch = 0.6787s	
70/11350 (epoch 0.308), train_loss = 3.65495833, grad/param norm = 6.5641e-01, time/batch = 0.6815s	
71/11350 (epoch 0.313), train_loss = 3.47715501, grad/param norm = 5.6551e-01, time/batch = 0.6823s	
72/11350 (epoch 0.317), train_loss = 3.48187367, grad/param norm = 5.4177e-01, time/batch = 0.6816s	
73/11350 (epoch 0.322), train_loss = 3.40930727, grad/param norm = 5.4973e-01, time/batch = 0.6854s	
74/11350 (epoch 0.326), train_loss = 3.53934662, grad/param norm = 7.6365e-01, time/batch = 0.6803s	
75/11350 (epoch 0.330), train_loss = 3.34750959, grad/param norm = 5.9094e-01, time/batch = 0.6820s	
76/11350 (epoch 0.335), train_loss = 3.45674882, grad/param norm = 6.4769e-01, time/batch = 0.6837s	
77/11350 (epoch 0.339), train_loss = 3.35585628, grad/param norm = 5.9769e-01, time/batch = 0.6877s	
78/11350 (epoch 0.344), train_loss = 3.41642576, grad/param norm = 4.5810e-01, time/batch = 0.7118s	
79/11350 (epoch 0.348), train_loss = 3.39304085, grad/param norm = 4.4899e-01, time/batch = 0.7163s	
80/11350 (epoch 0.352), train_loss = 3.42919492, grad/param norm = 7.6714e-01, time/batch = 0.6945s	
81/11350 (epoch 0.357), train_loss = 3.53026527, grad/param norm = 6.6217e-01, time/batch = 0.6949s	
82/11350 (epoch 0.361), train_loss = 3.35654410, grad/param norm = 6.5492e-01, time/batch = 0.6819s	
83/11350 (epoch 0.366), train_loss = 3.58071874, grad/param norm = 5.9706e-01, time/batch = 0.6822s	
84/11350 (epoch 0.370), train_loss = 3.57572758, grad/param norm = 6.4221e-01, time/batch = 0.6833s	
85/11350 (epoch 0.374), train_loss = 3.65711491, grad/param norm = 5.3690e-01, time/batch = 0.6841s	
86/11350 (epoch 0.379), train_loss = 3.40831442, grad/param norm = 6.3836e-01, time/batch = 0.6827s	
87/11350 (epoch 0.383), train_loss = 3.50331177, grad/param norm = 6.4627e-01, time/batch = 0.6847s	
88/11350 (epoch 0.388), train_loss = 3.47215556, grad/param norm = 4.9602e-01, time/batch = 0.6848s	
89/11350 (epoch 0.392), train_loss = 3.37586978, grad/param norm = 7.1447e-01, time/batch = 0.6824s	
90/11350 (epoch 0.396), train_loss = 3.48859408, grad/param norm = 7.5058e-01, time/batch = 0.7218s	
91/11350 (epoch 0.401), train_loss = 3.42705499, grad/param norm = 5.7494e-01, time/batch = 0.6957s	
92/11350 (epoch 0.405), train_loss = 3.42518289, grad/param norm = 4.7021e-01, time/batch = 0.6875s	
93/11350 (epoch 0.410), train_loss = 3.47834718, grad/param norm = 5.0553e-01, time/batch = 0.6843s	
94/11350 (epoch 0.414), train_loss = 3.41212946, grad/param norm = 5.5002e-01, time/batch = 0.6891s	
95/11350 (epoch 0.419), train_loss = 4.23336876, grad/param norm = 9.2418e-01, time/batch = 0.6852s	
96/11350 (epoch 0.423), train_loss = 3.86352278, grad/param norm = 5.2343e-01, time/batch = 0.6840s	
97/11350 (epoch 0.427), train_loss = 3.52964868, grad/param norm = 6.1159e-01, time/batch = 0.7018s	
98/11350 (epoch 0.432), train_loss = 3.97183683, grad/param norm = 6.4249e-01, time/batch = 0.7207s	
99/11350 (epoch 0.436), train_loss = 4.25352447, grad/param norm = 6.7157e-01, time/batch = 0.6813s	
100/11350 (epoch 0.441), train_loss = 3.84695628, grad/param norm = 6.3620e-01, time/batch = 0.6836s	
101/11350 (epoch 0.445), train_loss = 3.61810811, grad/param norm = 3.9703e-01, time/batch = 0.6851s	
102/11350 (epoch 0.449), train_loss = 3.50924631, grad/param norm = 4.4136e-01, time/batch = 0.6834s	
103/11350 (epoch 0.454), train_loss = 3.50802865, grad/param norm = 6.1149e-01, time/batch = 0.6853s	
104/11350 (epoch 0.458), train_loss = 3.41439515, grad/param norm = 6.1529e-01, time/batch = 0.6841s	
105/11350 (epoch 0.463), train_loss = 3.46571199, grad/param norm = 4.8096e-01, time/batch = 0.6841s	
106/11350 (epoch 0.467), train_loss = 3.47253997, grad/param norm = 4.5458e-01, time/batch = 0.6850s	
107/11350 (epoch 0.471), train_loss = 3.33372569, grad/param norm = 5.5800e-01, time/batch = 0.6963s	
108/11350 (epoch 0.476), train_loss = 3.48280553, grad/param norm = 6.3642e-01, time/batch = 0.7229s	
109/11350 (epoch 0.480), train_loss = 3.90279501, grad/param norm = 7.5879e-01, time/batch = 0.6836s	
110/11350 (epoch 0.485), train_loss = 3.64080803, grad/param norm = 4.9476e-01, time/batch = 0.6838s	
111/11350 (epoch 0.489), train_loss = 3.42580126, grad/param norm = 4.9066e-01, time/batch = 0.6836s	
112/11350 (epoch 0.493), train_loss = 3.46093243, grad/param norm = 5.8942e-01, time/batch = 0.6842s	
113/11350 (epoch 0.498), train_loss = 3.37521691, grad/param norm = 4.6597e-01, time/batch = 0.6845s	
114/11350 (epoch 0.502), train_loss = 3.47464758, grad/param norm = 4.9141e-01, time/batch = 0.6851s	
115/11350 (epoch 0.507), train_loss = 3.35311352, grad/param norm = 6.0257e-01, time/batch = 0.6887s	
116/11350 (epoch 0.511), train_loss = 3.33625689, grad/param norm = 5.3272e-01, time/batch = 0.6965s	
117/11350 (epoch 0.515), train_loss = 3.43330911, grad/param norm = 5.8711e-01, time/batch = 0.6979s	
118/11350 (epoch 0.520), train_loss = 3.37828307, grad/param norm = 6.2816e-01, time/batch = 0.7156s	
119/11350 (epoch 0.524), train_loss = 3.55689723, grad/param norm = 4.7669e-01, time/batch = 0.6866s	
120/11350 (epoch 0.529), train_loss = 3.76107364, grad/param norm = 4.9055e-01, time/batch = 0.6875s	
121/11350 (epoch 0.533), train_loss = 3.58635764, grad/param norm = 6.6627e-01, time/batch = 0.6857s	
122/11350 (epoch 0.537), train_loss = 3.48313734, grad/param norm = 6.0780e-01, time/batch = 0.6859s	
123/11350 (epoch 0.542), train_loss = 3.65533378, grad/param norm = 5.4497e-01, time/batch = 0.6859s	
124/11350 (epoch 0.546), train_loss = 3.72693532, grad/param norm = 5.4057e-01, time/batch = 0.6821s	
125/11350 (epoch 0.551), train_loss = 3.64370713, grad/param norm = 4.8508e-01, time/batch = 0.6871s	
126/11350 (epoch 0.555), train_loss = 4.78209915, grad/param norm = 4.4458e+00, time/batch = 0.6817s	
127/11350 (epoch 0.559), train_loss = 3.49992238, grad/param norm = 3.2675e-01, time/batch = 0.6825s	
128/11350 (epoch 0.564), train_loss = 3.38102133, grad/param norm = 4.2155e-01, time/batch = 0.6828s	
129/11350 (epoch 0.568), train_loss = 3.39051254, grad/param norm = 3.5128e-01, time/batch = 0.6905s	
130/11350 (epoch 0.573), train_loss = 3.40591054, grad/param norm = 2.6006e-01, time/batch = 0.6853s	
131/11350 (epoch 0.577), train_loss = 3.39548977, grad/param norm = 3.6159e-01, time/batch = 0.6850s	
132/11350 (epoch 0.581), train_loss = 3.27869265, grad/param norm = 5.2479e-01, time/batch = 0.6830s	
133/11350 (epoch 0.586), train_loss = 3.32684124, grad/param norm = 5.2133e-01, time/batch = 0.6852s	
134/11350 (epoch 0.590), train_loss = 3.47870001, grad/param norm = 6.4812e-01, time/batch = 0.6830s	
135/11350 (epoch 0.595), train_loss = 3.38406462, grad/param norm = 3.9704e-01, time/batch = 0.6882s	
136/11350 (epoch 0.599), train_loss = 3.43418369, grad/param norm = 4.2673e-01, time/batch = 0.6823s	
137/11350 (epoch 0.604), train_loss = 3.67191768, grad/param norm = 4.7190e-01, time/batch = 0.6843s	
138/11350 (epoch 0.608), train_loss = 3.57660421, grad/param norm = 4.8867e-01, time/batch = 0.6810s	
139/11350 (epoch 0.612), train_loss = 3.27396683, grad/param norm = 4.0579e-01, time/batch = 0.6851s	
140/11350 (epoch 0.617), train_loss = 3.36762840, grad/param norm = 3.9091e-01, time/batch = 0.6830s	
141/11350 (epoch 0.621), train_loss = 3.28627005, grad/param norm = 3.9604e-01, time/batch = 0.6879s	
142/11350 (epoch 0.626), train_loss = 3.36077126, grad/param norm = 4.4843e-01, time/batch = 0.7014s	
143/11350 (epoch 0.630), train_loss = 3.55730064, grad/param norm = 5.9547e-01, time/batch = 0.7075s	
144/11350 (epoch 0.634), train_loss = 3.47454440, grad/param norm = 7.5882e-01, time/batch = 0.7000s	
145/11350 (epoch 0.639), train_loss = 3.29052746, grad/param norm = 6.4708e-01, time/batch = 0.6905s	
146/11350 (epoch 0.643), train_loss = 3.35742139, grad/param norm = 4.9065e-01, time/batch = 0.6728s	
147/11350 (epoch 0.648), train_loss = 3.27365474, grad/param norm = 4.5971e-01, time/batch = 0.6698s	
148/11350 (epoch 0.652), train_loss = 3.16687121, grad/param norm = 4.1674e-01, time/batch = 0.6715s	
149/11350 (epoch 0.656), train_loss = 3.39164267, grad/param norm = 4.8826e-01, time/batch = 0.6683s	
150/11350 (epoch 0.661), train_loss = 3.56940106, grad/param norm = 4.2140e-01, time/batch = 0.6748s	
151/11350 (epoch 0.665), train_loss = 3.46965925, grad/param norm = 5.8345e-01, time/batch = 0.6684s	
152/11350 (epoch 0.670), train_loss = 3.39037363, grad/param norm = 6.3684e-01, time/batch = 0.6694s	
153/11350 (epoch 0.674), train_loss = 3.30834118, grad/param norm = 6.9302e-01, time/batch = 0.6676s	
154/11350 (epoch 0.678), train_loss = 3.35282465, grad/param norm = 7.3382e-01, time/batch = 0.6901s	
155/11350 (epoch 0.683), train_loss = 3.27175423, grad/param norm = 5.2655e-01, time/batch = 0.6691s	
156/11350 (epoch 0.687), train_loss = 3.29027554, grad/param norm = 6.0987e-01, time/batch = 0.6678s	
157/11350 (epoch 0.692), train_loss = 3.37876982, grad/param norm = 5.8871e-01, time/batch = 0.6700s	
158/11350 (epoch 0.696), train_loss = 3.28016333, grad/param norm = 4.2301e-01, time/batch = 0.6684s	
159/11350 (epoch 0.700), train_loss = 3.37427537, grad/param norm = 4.4541e-01, time/batch = 0.6689s	
160/11350 (epoch 0.705), train_loss = 3.32244593, grad/param norm = 3.8146e-01, time/batch = 0.6734s	
161/11350 (epoch 0.709), train_loss = 3.49742578, grad/param norm = 4.0860e-01, time/batch = 0.6696s	
162/11350 (epoch 0.714), train_loss = 3.40890622, grad/param norm = 6.6508e-01, time/batch = 0.6715s	
163/11350 (epoch 0.718), train_loss = 3.47558067, grad/param norm = 1.0896e+00, time/batch = 0.6711s	
164/11350 (epoch 0.722), train_loss = 3.41725016, grad/param norm = 9.8326e-01, time/batch = 0.6711s	
165/11350 (epoch 0.727), train_loss = 3.46530624, grad/param norm = 7.4632e-01, time/batch = 0.6960s	
166/11350 (epoch 0.731), train_loss = 3.48738751, grad/param norm = 4.3513e-01, time/batch = 0.7049s	
167/11350 (epoch 0.736), train_loss = 3.55480894, grad/param norm = 4.7101e-01, time/batch = 0.6876s	
168/11350 (epoch 0.740), train_loss = 3.56777673, grad/param norm = 8.3300e-01, time/batch = 0.7048s	
169/11350 (epoch 0.744), train_loss = 3.56072086, grad/param norm = 1.5242e+00, time/batch = 0.7194s	
170/11350 (epoch 0.749), train_loss = 3.58003075, grad/param norm = 2.7350e+00, time/batch = 0.6922s	
171/11350 (epoch 0.753), train_loss = 3.46697261, grad/param norm = 6.9670e-01, time/batch = 0.6720s	
172/11350 (epoch 0.758), train_loss = 3.19111508, grad/param norm = 5.6157e-01, time/batch = 0.6758s	
173/11350 (epoch 0.762), train_loss = 3.22573982, grad/param norm = 4.0163e-01, time/batch = 0.6728s	
174/11350 (epoch 0.767), train_loss = 3.29320406, grad/param norm = 2.9880e-01, time/batch = 0.6737s	
175/11350 (epoch 0.771), train_loss = 3.42165185, grad/param norm = 4.0678e-01, time/batch = 0.6735s	
176/11350 (epoch 0.775), train_loss = 3.37737015, grad/param norm = 2.9710e-01, time/batch = 0.6712s	
177/11350 (epoch 0.780), train_loss = 3.22649406, grad/param norm = 4.4044e-01, time/batch = 0.6726s	
178/11350 (epoch 0.784), train_loss = 3.28163858, grad/param norm = 5.3598e-01, time/batch = 0.6708s	
179/11350 (epoch 0.789), train_loss = 3.17888423, grad/param norm = 4.4475e-01, time/batch = 0.7108s	
180/11350 (epoch 0.793), train_loss = 3.11720330, grad/param norm = 3.6829e-01, time/batch = 0.6980s	
181/11350 (epoch 0.797), train_loss = 3.14301327, grad/param norm = 2.9675e-01, time/batch = 0.6831s	
182/11350 (epoch 0.802), train_loss = 3.11542686, grad/param norm = 3.7503e-01, time/batch = 0.6968s	
183/11350 (epoch 0.806), train_loss = 3.21810289, grad/param norm = 6.7299e-01, time/batch = 0.6785s	
184/11350 (epoch 0.811), train_loss = 3.29872904, grad/param norm = 1.0502e+00, time/batch = 0.6812s	
185/11350 (epoch 0.815), train_loss = 3.29365508, grad/param norm = 1.0682e+00, time/batch = 0.6725s	
186/11350 (epoch 0.819), train_loss = 3.24617865, grad/param norm = 6.8296e-01, time/batch = 0.6700s	
187/11350 (epoch 0.824), train_loss = 3.20200986, grad/param norm = 5.6075e-01, time/batch = 0.6724s	
188/11350 (epoch 0.828), train_loss = 3.22101507, grad/param norm = 4.1980e-01, time/batch = 0.6684s	
189/11350 (epoch 0.833), train_loss = 3.26590237, grad/param norm = 4.1060e-01, time/batch = 0.7005s	
190/11350 (epoch 0.837), train_loss = 3.09323865, grad/param norm = 3.7910e-01, time/batch = 0.6948s	
191/11350 (epoch 0.841), train_loss = 3.21157891, grad/param norm = 4.3716e-01, time/batch = 0.6714s	
192/11350 (epoch 0.846), train_loss = 3.15293830, grad/param norm = 4.4137e-01, time/batch = 0.6786s	
193/11350 (epoch 0.850), train_loss = 3.22525570, grad/param norm = 7.8400e-01, time/batch = 0.6737s	
194/11350 (epoch 0.855), train_loss = 3.16015671, grad/param norm = 7.2463e-01, time/batch = 0.6764s	
195/11350 (epoch 0.859), train_loss = 3.27574820, grad/param norm = 6.7297e-01, time/batch = 0.6705s	
196/11350 (epoch 0.863), train_loss = 3.15456465, grad/param norm = 5.8259e-01, time/batch = 0.6721s	
197/11350 (epoch 0.868), train_loss = 3.06079421, grad/param norm = 7.1629e-01, time/batch = 0.6767s	
198/11350 (epoch 0.872), train_loss = 3.05269644, grad/param norm = 7.2872e-01, time/batch = 0.6704s	
199/11350 (epoch 0.877), train_loss = 3.24568984, grad/param norm = 3.9341e-01, time/batch = 0.6919s	
200/11350 (epoch 0.881), train_loss = 3.30726169, grad/param norm = 3.4136e-01, time/batch = 0.7055s	
201/11350 (epoch 0.885), train_loss = 3.15766332, grad/param norm = 3.8602e-01, time/batch = 0.6732s	
202/11350 (epoch 0.890), train_loss = 3.16155508, grad/param norm = 3.7606e-01, time/batch = 0.6750s	
203/11350 (epoch 0.894), train_loss = 3.47424461, grad/param norm = 4.9854e-01, time/batch = 0.6765s	
204/11350 (epoch 0.899), train_loss = 3.38777607, grad/param norm = 3.2335e-01, time/batch = 0.6692s	
205/11350 (epoch 0.903), train_loss = 3.53080237, grad/param norm = 8.8513e-01, time/batch = 0.6726s	
206/11350 (epoch 0.907), train_loss = 4.12100255, grad/param norm = 5.8968e+00, time/batch = 0.6744s	
207/11350 (epoch 0.912), train_loss = 3.36178573, grad/param norm = 8.4960e-01, time/batch = 0.6777s	
208/11350 (epoch 0.916), train_loss = 3.18488211, grad/param norm = 7.1048e-01, time/batch = 0.6708s	
209/11350 (epoch 0.921), train_loss = 3.12006187, grad/param norm = 5.8636e-01, time/batch = 0.6804s	
210/11350 (epoch 0.925), train_loss = 3.30977676, grad/param norm = 4.5421e-01, time/batch = 0.7090s	
211/11350 (epoch 0.930), train_loss = 3.10417027, grad/param norm = 4.0747e-01, time/batch = 0.6786s	
212/11350 (epoch 0.934), train_loss = 3.24836503, grad/param norm = 4.7292e-01, time/batch = 0.6728s	
213/11350 (epoch 0.938), train_loss = 3.13852687, grad/param norm = 4.6496e-01, time/batch = 0.6766s	
214/11350 (epoch 0.943), train_loss = 3.19840483, grad/param norm = 4.5194e-01, time/batch = 0.6701s	
215/11350 (epoch 0.947), train_loss = 3.27192930, grad/param norm = 6.6168e-01, time/batch = 0.6711s	
216/11350 (epoch 0.952), train_loss = 3.44896759, grad/param norm = 1.2531e+00, time/batch = 0.6734s	
217/11350 (epoch 0.956), train_loss = 3.41770976, grad/param norm = 1.0777e+00, time/batch = 0.6702s	
218/11350 (epoch 0.960), train_loss = 3.35624137, grad/param norm = 7.2772e-01, time/batch = 0.6729s	
219/11350 (epoch 0.965), train_loss = 3.34686316, grad/param norm = 4.7413e-01, time/batch = 0.6707s	
220/11350 (epoch 0.969), train_loss = 3.21558042, grad/param norm = 4.3639e-01, time/batch = 0.7074s	
221/11350 (epoch 0.974), train_loss = 3.14860003, grad/param norm = 4.2401e-01, time/batch = 0.6884s	
222/11350 (epoch 0.978), train_loss = 3.27498015, grad/param norm = 4.9413e-01, time/batch = 0.6730s	
223/11350 (epoch 0.982), train_loss = 3.03112873, grad/param norm = 4.4575e-01, time/batch = 0.6739s	
224/11350 (epoch 0.987), train_loss = 3.07502121, grad/param norm = 5.0902e-01, time/batch = 0.6697s	
225/11350 (epoch 0.991), train_loss = 2.98508251, grad/param norm = 5.9077e-01, time/batch = 0.6708s	
226/11350 (epoch 0.996), train_loss = 3.12945953, grad/param norm = 5.5894e-01, time/batch = 0.6689s	
227/11350 (epoch 1.000), train_loss = 3.03092376, grad/param norm = 4.3153e-01, time/batch = 0.6697s	
228/11350 (epoch 1.004), train_loss = 3.04450845, grad/param norm = 5.7152e-01, time/batch = 0.6699s	
229/11350 (epoch 1.009), train_loss = 3.26157483, grad/param norm = 1.5584e+00, time/batch = 0.6710s	
230/11350 (epoch 1.013), train_loss = 3.12690803, grad/param norm = 1.6154e+00, time/batch = 0.6709s	
231/11350 (epoch 1.018), train_loss = 3.03966257, grad/param norm = 4.9760e-01, time/batch = 0.6824s	
232/11350 (epoch 1.022), train_loss = 3.07965280, grad/param norm = 5.0088e-01, time/batch = 0.6771s	
233/11350 (epoch 1.026), train_loss = 3.07348282, grad/param norm = 6.2078e-01, time/batch = 0.6737s	
234/11350 (epoch 1.031), train_loss = 2.87773868, grad/param norm = 3.6928e-01, time/batch = 0.6702s	
235/11350 (epoch 1.035), train_loss = 3.08984139, grad/param norm = 3.7810e-01, time/batch = 0.6749s	
236/11350 (epoch 1.040), train_loss = 3.03837407, grad/param norm = 5.1516e-01, time/batch = 0.6826s	
237/11350 (epoch 1.044), train_loss = 3.10802089, grad/param norm = 5.9483e-01, time/batch = 0.6692s	
238/11350 (epoch 1.048), train_loss = 3.12830295, grad/param norm = 5.6260e-01, time/batch = 0.6726s	
239/11350 (epoch 1.053), train_loss = 3.02636771, grad/param norm = 3.8310e-01, time/batch = 0.6710s	
240/11350 (epoch 1.057), train_loss = 3.08210431, grad/param norm = 4.7150e-01, time/batch = 0.6811s	
241/11350 (epoch 1.062), train_loss = 2.95303463, grad/param norm = 7.4669e-01, time/batch = 0.6720s	
242/11350 (epoch 1.066), train_loss = 3.09073926, grad/param norm = 9.2561e-01, time/batch = 0.6744s	
243/11350 (epoch 1.070), train_loss = 3.09576687, grad/param norm = 7.7739e-01, time/batch = 0.6745s	
244/11350 (epoch 1.075), train_loss = 2.91645518, grad/param norm = 7.3358e-01, time/batch = 0.6713s	
245/11350 (epoch 1.079), train_loss = 3.12596538, grad/param norm = 8.8994e-01, time/batch = 0.6700s	
246/11350 (epoch 1.084), train_loss = 3.09298465, grad/param norm = 1.5145e+00, time/batch = 0.6727s	
247/11350 (epoch 1.088), train_loss = 3.20448677, grad/param norm = 1.4329e+00, time/batch = 0.6811s	
248/11350 (epoch 1.093), train_loss = 2.84052081, grad/param norm = 7.9920e-01, time/batch = 0.6862s	
249/11350 (epoch 1.097), train_loss = 3.12683287, grad/param norm = 6.6442e-01, time/batch = 0.6777s	
250/11350 (epoch 1.101), train_loss = 2.95275307, grad/param norm = 4.2133e-01, time/batch = 0.6846s	
251/11350 (epoch 1.106), train_loss = 3.06164810, grad/param norm = 3.3366e-01, time/batch = 0.7000s	
252/11350 (epoch 1.110), train_loss = 2.92919021, grad/param norm = 4.2040e-01, time/batch = 0.6855s	
253/11350 (epoch 1.115), train_loss = 3.02071901, grad/param norm = 4.7444e-01, time/batch = 0.7057s	
254/11350 (epoch 1.119), train_loss = 3.00466250, grad/param norm = 5.6988e-01, time/batch = 0.7130s	
255/11350 (epoch 1.123), train_loss = 2.88610818, grad/param norm = 7.0397e-01, time/batch = 0.7013s	
256/11350 (epoch 1.128), train_loss = 3.03367168, grad/param norm = 8.6766e-01, time/batch = 0.6897s	
257/11350 (epoch 1.132), train_loss = 2.91002544, grad/param norm = 8.9131e-01, time/batch = 0.6839s	
258/11350 (epoch 1.137), train_loss = 2.96763274, grad/param norm = 7.5042e-01, time/batch = 0.7193s	
259/11350 (epoch 1.141), train_loss = 2.93319381, grad/param norm = 8.1454e-01, time/batch = 0.6988s	
260/11350 (epoch 1.145), train_loss = 3.08497039, grad/param norm = 9.6208e-01, time/batch = 0.6914s	
261/11350 (epoch 1.150), train_loss = 3.07415246, grad/param norm = 6.2201e-01, time/batch = 0.6890s	
262/11350 (epoch 1.154), train_loss = 3.00812737, grad/param norm = 4.3762e-01, time/batch = 0.6886s	
263/11350 (epoch 1.159), train_loss = 2.86430808, grad/param norm = 5.1539e-01, time/batch = 0.6893s	
264/11350 (epoch 1.163), train_loss = 2.95402451, grad/param norm = 5.1870e-01, time/batch = 0.6927s	
265/11350 (epoch 1.167), train_loss = 2.94735156, grad/param norm = 5.4040e-01, time/batch = 0.6909s	
266/11350 (epoch 1.172), train_loss = 3.09077110, grad/param norm = 4.6317e-01, time/batch = 0.6714s	
267/11350 (epoch 1.176), train_loss = 2.87268286, grad/param norm = 4.6372e-01, time/batch = 0.6744s	
268/11350 (epoch 1.181), train_loss = 2.94361733, grad/param norm = 5.7197e-01, time/batch = 0.6741s	
269/11350 (epoch 1.185), train_loss = 3.06316379, grad/param norm = 6.9598e-01, time/batch = 0.6733s	
270/11350 (epoch 1.189), train_loss = 2.94189603, grad/param norm = 1.2183e+00, time/batch = 0.6754s	
271/11350 (epoch 1.194), train_loss = 2.94539748, grad/param norm = 1.6588e+00, time/batch = 0.6734s	
272/11350 (epoch 1.198), train_loss = 2.99868630, grad/param norm = 8.3042e-01, time/batch = 0.6725s	
273/11350 (epoch 1.203), train_loss = 2.95048712, grad/param norm = 4.0137e-01, time/batch = 0.6736s	
274/11350 (epoch 1.207), train_loss = 2.95912052, grad/param norm = 4.2929e-01, time/batch = 0.6722s	
275/11350 (epoch 1.211), train_loss = 3.04307071, grad/param norm = 4.7130e-01, time/batch = 0.6726s	
276/11350 (epoch 1.216), train_loss = 2.88610004, grad/param norm = 5.9709e-01, time/batch = 0.6703s	
277/11350 (epoch 1.220), train_loss = 3.00191455, grad/param norm = 1.1724e+00, time/batch = 0.6708s	
278/11350 (epoch 1.225), train_loss = 2.91985994, grad/param norm = 1.0831e+00, time/batch = 0.6712s	
279/11350 (epoch 1.229), train_loss = 3.15870292, grad/param norm = 8.8784e-01, time/batch = 0.6700s	
280/11350 (epoch 1.233), train_loss = 2.94826843, grad/param norm = 7.2141e-01, time/batch = 0.6724s	
281/11350 (epoch 1.238), train_loss = 3.12479244, grad/param norm = 8.6103e-01, time/batch = 0.6701s	
282/11350 (epoch 1.242), train_loss = 2.99810803, grad/param norm = 8.4370e-01, time/batch = 0.6761s	
283/11350 (epoch 1.247), train_loss = 2.84248017, grad/param norm = 6.8436e-01, time/batch = 0.6724s	
284/11350 (epoch 1.251), train_loss = 2.96544924, grad/param norm = 5.8947e-01, time/batch = 0.6740s	
285/11350 (epoch 1.256), train_loss = 3.07405353, grad/param norm = 6.8872e-01, time/batch = 0.6686s	
286/11350 (epoch 1.260), train_loss = 3.08080466, grad/param norm = 8.2113e-01, time/batch = 0.6701s	
287/11350 (epoch 1.264), train_loss = 2.69320987, grad/param norm = 7.4639e-01, time/batch = 0.6725s	
288/11350 (epoch 1.269), train_loss = 2.98004566, grad/param norm = 8.7570e-01, time/batch = 0.6705s	
289/11350 (epoch 1.273), train_loss = 2.94226127, grad/param norm = 9.7438e-01, time/batch = 0.6726s	
290/11350 (epoch 1.278), train_loss = 2.87170197, grad/param norm = 8.3120e-01, time/batch = 0.6695s	
291/11350 (epoch 1.282), train_loss = 3.02388566, grad/param norm = 5.7321e-01, time/batch = 0.6753s	
292/11350 (epoch 1.286), train_loss = 2.84378694, grad/param norm = 5.0333e-01, time/batch = 0.7098s	
293/11350 (epoch 1.291), train_loss = 2.85794337, grad/param norm = 7.7903e-01, time/batch = 0.6828s	
294/11350 (epoch 1.295), train_loss = 2.93543927, grad/param norm = 9.7180e-01, time/batch = 0.6722s	
295/11350 (epoch 1.300), train_loss = 2.81958672, grad/param norm = 8.2041e-01, time/batch = 0.6759s	
296/11350 (epoch 1.304), train_loss = 2.83493974, grad/param norm = 7.9566e-01, time/batch = 0.6724s	
297/11350 (epoch 1.308), train_loss = 2.92490589, grad/param norm = 7.6111e-01, time/batch = 0.6758s	
298/11350 (epoch 1.313), train_loss = 2.84039225, grad/param norm = 7.0713e-01, time/batch = 0.6688s	
299/11350 (epoch 1.317), train_loss = 2.70770342, grad/param norm = 5.4779e-01, time/batch = 0.6722s	
300/11350 (epoch 1.322), train_loss = 2.71161683, grad/param norm = 4.5461e-01, time/batch = 0.6694s	
301/11350 (epoch 1.326), train_loss = 2.90207129, grad/param norm = 4.1748e-01, time/batch = 0.6707s	
302/11350 (epoch 1.330), train_loss = 2.74050393, grad/param norm = 3.6055e-01, time/batch = 0.7017s	
303/11350 (epoch 1.335), train_loss = 2.77915532, grad/param norm = 5.4218e-01, time/batch = 0.6922s	
304/11350 (epoch 1.339), train_loss = 2.78634786, grad/param norm = 7.6794e-01, time/batch = 0.6714s	
305/11350 (epoch 1.344), train_loss = 2.91556821, grad/param norm = 1.1599e+00, time/batch = 0.6747s	
306/11350 (epoch 1.348), train_loss = 2.84910707, grad/param norm = 1.3690e+00, time/batch = 0.6877s	
307/11350 (epoch 1.352), train_loss = 2.71714578, grad/param norm = 1.2878e+00, time/batch = 0.6935s	
308/11350 (epoch 1.357), train_loss = 2.90607011, grad/param norm = 7.5404e-01, time/batch = 0.6795s	
309/11350 (epoch 1.361), train_loss = 2.66267351, grad/param norm = 6.6577e-01, time/batch = 0.6762s	
310/11350 (epoch 1.366), train_loss = 2.87811581, grad/param norm = 5.9177e-01, time/batch = 0.6799s	
311/11350 (epoch 1.370), train_loss = 2.84387945, grad/param norm = 3.8076e-01, time/batch = 0.7002s	
312/11350 (epoch 1.374), train_loss = 2.91287175, grad/param norm = 6.0649e-01, time/batch = 0.6988s	
313/11350 (epoch 1.379), train_loss = 2.81036881, grad/param norm = 7.5857e-01, time/batch = 0.6871s	
314/11350 (epoch 1.383), train_loss = 2.81243206, grad/param norm = 1.1243e+00, time/batch = 0.6851s	
315/11350 (epoch 1.388), train_loss = 2.89113475, grad/param norm = 1.4101e+00, time/batch = 0.6831s	
316/11350 (epoch 1.392), train_loss = 2.83526620, grad/param norm = 9.9049e-01, time/batch = 0.6838s	
317/11350 (epoch 1.396), train_loss = 2.81932460, grad/param norm = 7.2188e-01, time/batch = 0.6831s	
318/11350 (epoch 1.401), train_loss = 2.69602491, grad/param norm = 5.5092e-01, time/batch = 0.6746s	
319/11350 (epoch 1.405), train_loss = 2.74879514, grad/param norm = 4.8155e-01, time/batch = 0.6700s	
320/11350 (epoch 1.410), train_loss = 2.90581884, grad/param norm = 4.2578e-01, time/batch = 0.6801s	
321/11350 (epoch 1.414), train_loss = 2.57400134, grad/param norm = 3.5977e-01, time/batch = 0.6833s	
322/11350 (epoch 1.419), train_loss = 3.45051859, grad/param norm = 8.7251e-01, time/batch = 0.6825s	
323/11350 (epoch 1.423), train_loss = 3.08990353, grad/param norm = 1.9591e+00, time/batch = 0.6829s	
324/11350 (epoch 1.427), train_loss = 2.91554728, grad/param norm = 6.8308e-01, time/batch = 0.6807s	
325/11350 (epoch 1.432), train_loss = 3.26094436, grad/param norm = 7.4910e-01, time/batch = 0.6708s	
326/11350 (epoch 1.436), train_loss = 3.21251251, grad/param norm = 7.4774e-01, time/batch = 0.6758s	
327/11350 (epoch 1.441), train_loss = 2.88608081, grad/param norm = 3.6034e-01, time/batch = 0.6703s	
328/11350 (epoch 1.445), train_loss = 2.69297191, grad/param norm = 3.5540e-01, time/batch = 0.6741s	
329/11350 (epoch 1.449), train_loss = 2.71304363, grad/param norm = 4.2845e-01, time/batch = 0.6715s	
330/11350 (epoch 1.454), train_loss = 2.71688043, grad/param norm = 5.7660e-01, time/batch = 0.6723s	
331/11350 (epoch 1.458), train_loss = 2.62736499, grad/param norm = 6.0418e-01, time/batch = 0.6731s	
332/11350 (epoch 1.463), train_loss = 2.78104975, grad/param norm = 5.5328e-01, time/batch = 0.6749s	
333/11350 (epoch 1.467), train_loss = 2.87019320, grad/param norm = 5.6834e-01, time/batch = 0.6726s	
334/11350 (epoch 1.471), train_loss = 2.80823709, grad/param norm = 6.9158e-01, time/batch = 0.6706s	
335/11350 (epoch 1.476), train_loss = 2.74332228, grad/param norm = 6.6165e-01, time/batch = 0.6780s	
336/11350 (epoch 1.480), train_loss = 3.13037800, grad/param norm = 7.6826e-01, time/batch = 0.6747s	
337/11350 (epoch 1.485), train_loss = 2.76521053, grad/param norm = 6.5611e-01, time/batch = 0.6983s	
338/11350 (epoch 1.489), train_loss = 2.85961874, grad/param norm = 7.2300e-01, time/batch = 0.7005s	
339/11350 (epoch 1.493), train_loss = 2.82493684, grad/param norm = 5.8670e-01, time/batch = 0.6775s	
340/11350 (epoch 1.498), train_loss = 2.65439848, grad/param norm = 5.5722e-01, time/batch = 0.6747s	
341/11350 (epoch 1.502), train_loss = 2.83003035, grad/param norm = 6.0987e-01, time/batch = 0.6981s	
342/11350 (epoch 1.507), train_loss = 2.71710459, grad/param norm = 6.5033e-01, time/batch = 0.7097s	
343/11350 (epoch 1.511), train_loss = 2.64351167, grad/param norm = 6.9767e-01, time/batch = 0.6958s	
344/11350 (epoch 1.515), train_loss = 2.81749922, grad/param norm = 4.3810e-01, time/batch = 0.7053s	
345/11350 (epoch 1.520), train_loss = 2.83667632, grad/param norm = 4.0011e-01, time/batch = 0.7118s	
346/11350 (epoch 1.524), train_loss = 2.79691180, grad/param norm = 5.3612e-01, time/batch = 0.6887s	
347/11350 (epoch 1.529), train_loss = 2.90210144, grad/param norm = 5.1869e-01, time/batch = 0.7131s	
348/11350 (epoch 1.533), train_loss = 2.72673262, grad/param norm = 3.3314e-01, time/batch = 0.7001s	
349/11350 (epoch 1.537), train_loss = 2.75790896, grad/param norm = 3.6044e-01, time/batch = 0.6909s	
350/11350 (epoch 1.542), train_loss = 2.80924721, grad/param norm = 3.7598e-01, time/batch = 0.6915s	
351/11350 (epoch 1.546), train_loss = 3.05497837, grad/param norm = 6.6556e-01, time/batch = 0.6909s	
352/11350 (epoch 1.551), train_loss = 2.93147003, grad/param norm = 8.9386e-01, time/batch = 0.6898s	
353/11350 (epoch 1.555), train_loss = 2.95470910, grad/param norm = 7.9821e-01, time/batch = 0.6898s	
354/11350 (epoch 1.559), train_loss = 2.68225039, grad/param norm = 6.4588e-01, time/batch = 0.6879s	
355/11350 (epoch 1.564), train_loss = 2.78305824, grad/param norm = 6.2664e-01, time/batch = 0.6889s	
356/11350 (epoch 1.568), train_loss = 2.93538354, grad/param norm = 6.7891e-01, time/batch = 0.6929s	
357/11350 (epoch 1.573), train_loss = 2.90197528, grad/param norm = 5.6801e-01, time/batch = 0.6886s	
358/11350 (epoch 1.577), train_loss = 2.86020560, grad/param norm = 4.8438e-01, time/batch = 0.6903s	
359/11350 (epoch 1.581), train_loss = 2.69612796, grad/param norm = 5.5904e-01, time/batch = 0.6905s	
360/11350 (epoch 1.586), train_loss = 2.78917085, grad/param norm = 5.0760e-01, time/batch = 0.6858s	
361/11350 (epoch 1.590), train_loss = 2.93603013, grad/param norm = 5.4399e-01, time/batch = 0.6872s	
362/11350 (epoch 1.595), train_loss = 2.87490370, grad/param norm = 4.6788e-01, time/batch = 0.6861s	
363/11350 (epoch 1.599), train_loss = 2.79861359, grad/param norm = 5.4397e-01, time/batch = 0.7194s	
364/11350 (epoch 1.604), train_loss = 2.78628642, grad/param norm = 4.7499e-01, time/batch = 0.7038s	
365/11350 (epoch 1.608), train_loss = 2.99548454, grad/param norm = 6.1516e-01, time/batch = 0.6849s	
366/11350 (epoch 1.612), train_loss = 2.61147946, grad/param norm = 9.5376e-01, time/batch = 0.6898s	
367/11350 (epoch 1.617), train_loss = 2.96597181, grad/param norm = 7.8452e-01, time/batch = 0.6865s	
368/11350 (epoch 1.621), train_loss = 2.72072644, grad/param norm = 8.5491e-01, time/batch = 0.6833s	
369/11350 (epoch 1.626), train_loss = 2.78912875, grad/param norm = 6.8380e-01, time/batch = 0.6842s	
370/11350 (epoch 1.630), train_loss = 3.01906721, grad/param norm = 4.4049e-01, time/batch = 0.6871s	
371/11350 (epoch 1.634), train_loss = 2.91074294, grad/param norm = 3.8304e-01, time/batch = 0.6866s	
372/11350 (epoch 1.639), train_loss = 2.74513042, grad/param norm = 2.9410e-01, time/batch = 0.6921s	
373/11350 (epoch 1.643), train_loss = 2.70038971, grad/param norm = 3.2189e-01, time/batch = 0.7019s	
374/11350 (epoch 1.648), train_loss = 2.71151091, grad/param norm = 3.9485e-01, time/batch = 0.6998s	
375/11350 (epoch 1.652), train_loss = 2.60263202, grad/param norm = 4.7745e-01, time/batch = 0.6951s	
376/11350 (epoch 1.656), train_loss = 2.84489235, grad/param norm = 6.7967e-01, time/batch = 0.6855s	
377/11350 (epoch 1.661), train_loss = 2.87028533, grad/param norm = 5.7651e-01, time/batch = 0.6828s	
378/11350 (epoch 1.665), train_loss = 2.87345088, grad/param norm = 4.9654e-01, time/batch = 0.6837s	
379/11350 (epoch 1.670), train_loss = 2.87029393, grad/param norm = 3.3373e-01, time/batch = 0.6871s	
380/11350 (epoch 1.674), train_loss = 2.75603683, grad/param norm = 3.4614e-01, time/batch = 0.6839s	
381/11350 (epoch 1.678), train_loss = 2.75724938, grad/param norm = 4.3142e-01, time/batch = 0.6868s	
382/11350 (epoch 1.683), train_loss = 2.67181633, grad/param norm = 5.1515e-01, time/batch = 0.6890s	
383/11350 (epoch 1.687), train_loss = 2.74685780, grad/param norm = 5.9748e-01, time/batch = 0.6830s	
384/11350 (epoch 1.692), train_loss = 2.93159569, grad/param norm = 8.6068e-01, time/batch = 0.6869s	
385/11350 (epoch 1.696), train_loss = 2.74983550, grad/param norm = 8.0355e-01, time/batch = 0.6913s	
386/11350 (epoch 1.700), train_loss = 2.86832860, grad/param norm = 6.8251e-01, time/batch = 0.6838s	
387/11350 (epoch 1.705), train_loss = 2.80358409, grad/param norm = 4.0580e-01, time/batch = 0.6858s	
388/11350 (epoch 1.709), train_loss = 2.90187102, grad/param norm = 5.3195e-01, time/batch = 0.6860s	
389/11350 (epoch 1.714), train_loss = 2.84706921, grad/param norm = 8.2368e-01, time/batch = 0.6837s	
390/11350 (epoch 1.718), train_loss = 2.89255391, grad/param norm = 7.0860e-01, time/batch = 0.6842s	
391/11350 (epoch 1.722), train_loss = 2.82097438, grad/param norm = 5.2387e-01, time/batch = 0.6858s	
392/11350 (epoch 1.727), train_loss = 2.70725116, grad/param norm = 4.7502e-01, time/batch = 0.6838s	
393/11350 (epoch 1.731), train_loss = 2.74947189, grad/param norm = 4.3379e-01, time/batch = 0.6887s	
394/11350 (epoch 1.736), train_loss = 2.76094054, grad/param norm = 3.6638e-01, time/batch = 0.6839s	
395/11350 (epoch 1.740), train_loss = 2.86639541, grad/param norm = 4.6397e-01, time/batch = 0.6831s	
396/11350 (epoch 1.744), train_loss = 2.80944694, grad/param norm = 5.5702e-01, time/batch = 0.6844s	
397/11350 (epoch 1.749), train_loss = 2.78687920, grad/param norm = 4.8765e-01, time/batch = 0.6847s	
398/11350 (epoch 1.753), train_loss = 2.84725516, grad/param norm = 6.3209e-01, time/batch = 0.6819s	
399/11350 (epoch 1.758), train_loss = 2.59199305, grad/param norm = 6.8460e-01, time/batch = 0.6841s	
400/11350 (epoch 1.762), train_loss = 2.67955376, grad/param norm = 3.4086e-01, time/batch = 0.6840s	
401/11350 (epoch 1.767), train_loss = 2.74218776, grad/param norm = 3.0995e-01, time/batch = 0.6804s	
402/11350 (epoch 1.771), train_loss = 2.77192408, grad/param norm = 3.7563e-01, time/batch = 0.6860s	
403/11350 (epoch 1.775), train_loss = 2.74871563, grad/param norm = 3.6884e-01, time/batch = 0.6827s	
404/11350 (epoch 1.780), train_loss = 2.71369992, grad/param norm = 5.2782e-01, time/batch = 0.6830s	
405/11350 (epoch 1.784), train_loss = 2.71395169, grad/param norm = 7.1982e-01, time/batch = 0.6837s	
406/11350 (epoch 1.789), train_loss = 2.68552108, grad/param norm = 7.0228e-01, time/batch = 0.6867s	
407/11350 (epoch 1.793), train_loss = 2.58536538, grad/param norm = 5.5405e-01, time/batch = 0.6803s	
408/11350 (epoch 1.797), train_loss = 2.54710701, grad/param norm = 4.8267e-01, time/batch = 0.6853s	
409/11350 (epoch 1.802), train_loss = 2.61333617, grad/param norm = 5.3633e-01, time/batch = 0.6816s	
410/11350 (epoch 1.806), train_loss = 2.67500605, grad/param norm = 6.4893e-01, time/batch = 0.6824s	
411/11350 (epoch 1.811), train_loss = 2.81785155, grad/param norm = 8.2065e-01, time/batch = 0.6849s	
412/11350 (epoch 1.815), train_loss = 2.57564920, grad/param norm = 8.4879e-01, time/batch = 0.6855s	
413/11350 (epoch 1.819), train_loss = 2.64135219, grad/param norm = 4.6134e-01, time/batch = 0.6857s	
414/11350 (epoch 1.824), train_loss = 2.72989670, grad/param norm = 3.8669e-01, time/batch = 0.6897s	
415/11350 (epoch 1.828), train_loss = 2.62503509, grad/param norm = 4.4650e-01, time/batch = 0.7271s	
416/11350 (epoch 1.833), train_loss = 2.76130009, grad/param norm = 5.3694e-01, time/batch = 0.7209s	
417/11350 (epoch 1.837), train_loss = 2.55373897, grad/param norm = 4.5712e-01, time/batch = 0.7030s	
418/11350 (epoch 1.841), train_loss = 2.77184491, grad/param norm = 4.8787e-01, time/batch = 0.7212s	
419/11350 (epoch 1.846), train_loss = 2.59833847, grad/param norm = 4.3687e-01, time/batch = 0.7037s	
420/11350 (epoch 1.850), train_loss = 2.71694585, grad/param norm = 4.4077e-01, time/batch = 0.6834s	
421/11350 (epoch 1.855), train_loss = 2.50138150, grad/param norm = 4.8350e-01, time/batch = 0.6833s	
422/11350 (epoch 1.859), train_loss = 2.75321067, grad/param norm = 7.1687e-01, time/batch = 0.6864s	
423/11350 (epoch 1.863), train_loss = 2.56199373, grad/param norm = 9.3891e-01, time/batch = 0.6864s	
424/11350 (epoch 1.868), train_loss = 2.58038262, grad/param norm = 6.5227e-01, time/batch = 0.6853s	
425/11350 (epoch 1.872), train_loss = 2.65964299, grad/param norm = 6.5047e-01, time/batch = 0.6858s	
426/11350 (epoch 1.877), train_loss = 2.70177151, grad/param norm = 5.7886e-01, time/batch = 0.6839s	
427/11350 (epoch 1.881), train_loss = 2.86975891, grad/param norm = 4.9893e-01, time/batch = 0.6987s	
428/11350 (epoch 1.885), train_loss = 2.66546400, grad/param norm = 3.9694e-01, time/batch = 0.7094s	
429/11350 (epoch 1.890), train_loss = 2.62778284, grad/param norm = 3.6458e-01, time/batch = 0.7335s	
430/11350 (epoch 1.894), train_loss = 2.80238415, grad/param norm = 4.4460e-01, time/batch = 0.7080s	
431/11350 (epoch 1.899), train_loss = 2.78976116, grad/param norm = 4.4950e-01, time/batch = 0.7024s	
432/11350 (epoch 1.903), train_loss = 2.91440914, grad/param norm = 4.6689e-01, time/batch = 0.7123s	
433/11350 (epoch 1.907), train_loss = 2.79160044, grad/param norm = 5.6231e-01, time/batch = 0.7462s	
434/11350 (epoch 1.912), train_loss = 2.66132500, grad/param norm = 5.9068e-01, time/batch = 0.7295s	
435/11350 (epoch 1.916), train_loss = 2.74898250, grad/param norm = 6.1966e-01, time/batch = 0.7246s	
436/11350 (epoch 1.921), train_loss = 2.54638335, grad/param norm = 5.3568e-01, time/batch = 0.7103s	
437/11350 (epoch 1.925), train_loss = 2.69513067, grad/param norm = 4.9401e-01, time/batch = 0.6968s	
438/11350 (epoch 1.930), train_loss = 2.61821473, grad/param norm = 4.7083e-01, time/batch = 0.7244s	
439/11350 (epoch 1.934), train_loss = 2.81652653, grad/param norm = 3.9681e-01, time/batch = 0.6955s	
440/11350 (epoch 1.938), train_loss = 2.62547114, grad/param norm = 3.4683e-01, time/batch = 0.6855s	
441/11350 (epoch 1.943), train_loss = 2.76885803, grad/param norm = 3.7914e-01, time/batch = 0.6837s	
442/11350 (epoch 1.947), train_loss = 2.70900858, grad/param norm = 4.9194e-01, time/batch = 0.6880s	
443/11350 (epoch 1.952), train_loss = 2.83711981, grad/param norm = 4.7416e-01, time/batch = 0.6877s	
444/11350 (epoch 1.956), train_loss = 2.83423902, grad/param norm = 1.2166e+00, time/batch = 0.6851s	
445/11350 (epoch 1.960), train_loss = 2.82697316, grad/param norm = 6.4688e-01, time/batch = 0.6857s	
446/11350 (epoch 1.965), train_loss = 2.78946538, grad/param norm = 6.3208e-01, time/batch = 0.6857s	
447/11350 (epoch 1.969), train_loss = 2.77618563, grad/param norm = 5.0011e-01, time/batch = 0.6883s	
448/11350 (epoch 1.974), train_loss = 2.59066729, grad/param norm = 2.7802e-01, time/batch = 0.7243s	
449/11350 (epoch 1.978), train_loss = 2.74376039, grad/param norm = 3.2648e-01, time/batch = 0.6957s	
450/11350 (epoch 1.982), train_loss = 2.42121176, grad/param norm = 3.7934e-01, time/batch = 0.6846s	
451/11350 (epoch 1.987), train_loss = 2.61694105, grad/param norm = 5.0736e-01, time/batch = 0.6851s	
452/11350 (epoch 1.991), train_loss = 2.50659107, grad/param norm = 7.4820e-01, time/batch = 0.6848s	
453/11350 (epoch 1.996), train_loss = 2.74744452, grad/param norm = 6.5530e-01, time/batch = 0.6861s	
454/11350 (epoch 2.000), train_loss = 2.46601821, grad/param norm = 4.4324e-01, time/batch = 0.6898s	
455/11350 (epoch 2.004), train_loss = 2.57951336, grad/param norm = 6.6674e-01, time/batch = 0.6914s	
456/11350 (epoch 2.009), train_loss = 2.88516518, grad/param norm = 9.2611e-01, time/batch = 0.6848s	
457/11350 (epoch 2.013), train_loss = 2.37727521, grad/param norm = 7.0703e-01, time/batch = 0.6830s	
458/11350 (epoch 2.018), train_loss = 2.47316880, grad/param norm = 3.6468e-01, time/batch = 0.7421s	
459/11350 (epoch 2.022), train_loss = 2.39949118, grad/param norm = 4.1793e-01, time/batch = 0.7093s	
460/11350 (epoch 2.026), train_loss = 2.52856114, grad/param norm = 4.1960e-01, time/batch = 0.6850s	
461/11350 (epoch 2.031), train_loss = 2.33959353, grad/param norm = 3.1671e-01, time/batch = 0.6891s	
462/11350 (epoch 2.035), train_loss = 2.58672134, grad/param norm = 3.2662e-01, time/batch = 0.6874s	
463/11350 (epoch 2.040), train_loss = 2.52415972, grad/param norm = 4.0962e-01, time/batch = 0.6870s	
464/11350 (epoch 2.044), train_loss = 2.47992845, grad/param norm = 4.4932e-01, time/batch = 0.6861s	
465/11350 (epoch 2.048), train_loss = 2.53513760, grad/param norm = 4.1905e-01, time/batch = 0.6864s	
466/11350 (epoch 2.053), train_loss = 2.42170993, grad/param norm = 3.0581e-01, time/batch = 0.6838s	
467/11350 (epoch 2.057), train_loss = 2.57593745, grad/param norm = 4.1199e-01, time/batch = 0.6873s	
468/11350 (epoch 2.062), train_loss = 2.33376904, grad/param norm = 5.4363e-01, time/batch = 0.7199s	
469/11350 (epoch 2.066), train_loss = 2.46189125, grad/param norm = 5.4969e-01, time/batch = 0.7036s	
470/11350 (epoch 2.070), train_loss = 2.55759831, grad/param norm = 5.7998e-01, time/batch = 0.6872s	
471/11350 (epoch 2.075), train_loss = 2.38841632, grad/param norm = 5.4942e-01, time/batch = 0.6918s	
472/11350 (epoch 2.079), train_loss = 2.56580121, grad/param norm = 5.8432e-01, time/batch = 0.6880s	
473/11350 (epoch 2.084), train_loss = 2.67304072, grad/param norm = 5.3043e-01, time/batch = 0.6868s	
474/11350 (epoch 2.088), train_loss = 2.63232506, grad/param norm = 5.1900e-01, time/batch = 0.6858s	
475/11350 (epoch 2.093), train_loss = 2.26325829, grad/param norm = 4.0208e-01, time/batch = 0.6919s	
476/11350 (epoch 2.097), train_loss = 2.66464119, grad/param norm = 6.2151e-01, time/batch = 0.6841s	
477/11350 (epoch 2.101), train_loss = 2.43682610, grad/param norm = 6.2147e-01, time/batch = 0.7049s	
478/11350 (epoch 2.106), train_loss = 2.57573952, grad/param norm = 4.9588e-01, time/batch = 0.7271s	
479/11350 (epoch 2.110), train_loss = 2.34350366, grad/param norm = 4.4089e-01, time/batch = 0.7100s	
480/11350 (epoch 2.115), train_loss = 2.45338184, grad/param norm = 3.7734e-01, time/batch = 0.6921s	
481/11350 (epoch 2.119), train_loss = 2.47779542, grad/param norm = 3.4412e-01, time/batch = 0.6895s	
482/11350 (epoch 2.123), train_loss = 2.35571355, grad/param norm = 3.7630e-01, time/batch = 0.6856s	
483/11350 (epoch 2.128), train_loss = 2.43212150, grad/param norm = 3.2636e-01, time/batch = 0.6859s	
484/11350 (epoch 2.132), train_loss = 2.41796060, grad/param norm = 3.4932e-01, time/batch = 0.6882s	
485/11350 (epoch 2.137), train_loss = 2.33173226, grad/param norm = 2.8648e-01, time/batch = 0.6842s	
486/11350 (epoch 2.141), train_loss = 2.46380052, grad/param norm = 3.0224e-01, time/batch = 0.6856s	
487/11350 (epoch 2.145), train_loss = 2.50157838, grad/param norm = 3.6486e-01, time/batch = 0.7047s	
488/11350 (epoch 2.150), train_loss = 2.55605343, grad/param norm = 5.6366e-01, time/batch = 0.7190s	
489/11350 (epoch 2.154), train_loss = 2.54320903, grad/param norm = 7.9359e-01, time/batch = 0.7035s	
490/11350 (epoch 2.159), train_loss = 2.44207205, grad/param norm = 7.2026e-01, time/batch = 0.6852s	
491/11350 (epoch 2.163), train_loss = 2.52118590, grad/param norm = 5.4686e-01, time/batch = 0.6857s	
492/11350 (epoch 2.167), train_loss = 2.56495483, grad/param norm = 6.2305e-01, time/batch = 0.6901s	
493/11350 (epoch 2.172), train_loss = 2.66592674, grad/param norm = 5.0375e-01, time/batch = 0.6867s	
494/11350 (epoch 2.176), train_loss = 2.42519272, grad/param norm = 3.8252e-01, time/batch = 0.6894s	
495/11350 (epoch 2.181), train_loss = 2.43421544, grad/param norm = 3.9634e-01, time/batch = 0.6884s	
496/11350 (epoch 2.185), train_loss = 2.60222675, grad/param norm = 3.8609e-01, time/batch = 0.6931s	
497/11350 (epoch 2.189), train_loss = 2.40067011, grad/param norm = 5.7797e-01, time/batch = 0.6857s	
498/11350 (epoch 2.194), train_loss = 2.32778826, grad/param norm = 6.1719e-01, time/batch = 0.7141s	
499/11350 (epoch 2.198), train_loss = 2.47956580, grad/param norm = 4.8545e-01, time/batch = 0.7051s	
500/11350 (epoch 2.203), train_loss = 2.39435624, grad/param norm = 3.6175e-01, time/batch = 0.6939s	
501/11350 (epoch 2.207), train_loss = 2.49442533, grad/param norm = 4.6277e-01, time/batch = 0.6902s	
502/11350 (epoch 2.211), train_loss = 2.62263109, grad/param norm = 4.1532e-01, time/batch = 0.6843s	
503/11350 (epoch 2.216), train_loss = 2.44416915, grad/param norm = 3.6300e-01, time/batch = 0.6840s	
504/11350 (epoch 2.220), train_loss = 2.51377474, grad/param norm = 3.5193e-01, time/batch = 0.6835s	
505/11350 (epoch 2.225), train_loss = 2.38109620, grad/param norm = 3.0738e-01, time/batch = 0.6822s	
506/11350 (epoch 2.229), train_loss = 2.62682575, grad/param norm = 4.0918e-01, time/batch = 0.6847s	
507/11350 (epoch 2.233), train_loss = 2.47463086, grad/param norm = 5.4966e-01, time/batch = 0.6973s	
508/11350 (epoch 2.238), train_loss = 2.73824444, grad/param norm = 6.9735e-01, time/batch = 0.7191s	
509/11350 (epoch 2.242), train_loss = 2.62952666, grad/param norm = 4.9234e-01, time/batch = 0.7219s	
510/11350 (epoch 2.247), train_loss = 2.31245738, grad/param norm = 4.3517e-01, time/batch = 0.6933s	
511/11350 (epoch 2.251), train_loss = 2.57522447, grad/param norm = 4.8710e-01, time/batch = 0.7147s	
512/11350 (epoch 2.256), train_loss = 2.62227870, grad/param norm = 4.0819e-01, time/batch = 0.7181s	
513/11350 (epoch 2.260), train_loss = 2.61793382, grad/param norm = 4.1085e-01, time/batch = 0.7206s	
514/11350 (epoch 2.264), train_loss = 2.27704500, grad/param norm = 5.8046e-01, time/batch = 0.7193s	
515/11350 (epoch 2.269), train_loss = 2.55830295, grad/param norm = 6.9157e-01, time/batch = 0.7158s	
516/11350 (epoch 2.273), train_loss = 2.49632202, grad/param norm = 4.3108e-01, time/batch = 0.6954s	
517/11350 (epoch 2.278), train_loss = 2.39173209, grad/param norm = 4.2970e-01, time/batch = 0.7248s	
518/11350 (epoch 2.282), train_loss = 2.63956277, grad/param norm = 5.0054e-01, time/batch = 0.6851s	
519/11350 (epoch 2.286), train_loss = 2.54133324, grad/param norm = 6.6449e-01, time/batch = 0.6895s	
520/11350 (epoch 2.291), train_loss = 2.41936787, grad/param norm = 6.7871e-01, time/batch = 0.6864s	
521/11350 (epoch 2.295), train_loss = 2.58550367, grad/param norm = 6.9419e-01, time/batch = 0.6927s	
522/11350 (epoch 2.300), train_loss = 2.42497985, grad/param norm = 4.1972e-01, time/batch = 0.6861s	
523/11350 (epoch 2.304), train_loss = 2.32261417, grad/param norm = 3.2998e-01, time/batch = 0.6829s	
524/11350 (epoch 2.308), train_loss = 2.41821552, grad/param norm = 3.7466e-01, time/batch = 0.6826s	
525/11350 (epoch 2.313), train_loss = 2.39379150, grad/param norm = 5.1066e-01, time/batch = 0.6829s	
526/11350 (epoch 2.317), train_loss = 2.22931016, grad/param norm = 5.3005e-01, time/batch = 0.6858s	
527/11350 (epoch 2.322), train_loss = 2.28026275, grad/param norm = 3.7760e-01, time/batch = 0.6856s	
528/11350 (epoch 2.326), train_loss = 2.44397546, grad/param norm = 4.2747e-01, time/batch = 0.7158s	
529/11350 (epoch 2.330), train_loss = 2.32658041, grad/param norm = 3.6269e-01, time/batch = 0.7051s	
530/11350 (epoch 2.335), train_loss = 2.26924232, grad/param norm = 3.2991e-01, time/batch = 0.6831s	
531/11350 (epoch 2.339), train_loss = 2.31960369, grad/param norm = 3.7021e-01, time/batch = 0.6836s	
532/11350 (epoch 2.344), train_loss = 2.42871025, grad/param norm = 5.7095e-01, time/batch = 0.6816s	
533/11350 (epoch 2.348), train_loss = 2.44256281, grad/param norm = 8.8852e-01, time/batch = 0.6849s	
534/11350 (epoch 2.352), train_loss = 2.21383171, grad/param norm = 7.5341e-01, time/batch = 0.6847s	
535/11350 (epoch 2.357), train_loss = 2.49588461, grad/param norm = 4.8475e-01, time/batch = 0.6837s	
536/11350 (epoch 2.361), train_loss = 2.18463464, grad/param norm = 4.4999e-01, time/batch = 0.6851s	
537/11350 (epoch 2.366), train_loss = 2.47591966, grad/param norm = 4.3343e-01, time/batch = 0.6829s	
538/11350 (epoch 2.370), train_loss = 2.37615311, grad/param norm = 3.3146e-01, time/batch = 0.7105s	
539/11350 (epoch 2.374), train_loss = 2.42303198, grad/param norm = 4.1782e-01, time/batch = 0.7095s	
540/11350 (epoch 2.379), train_loss = 2.41217442, grad/param norm = 3.9148e-01, time/batch = 0.6883s	
541/11350 (epoch 2.383), train_loss = 2.31272772, grad/param norm = 4.4973e-01, time/batch = 0.6906s	
542/11350 (epoch 2.388), train_loss = 2.40622585, grad/param norm = 5.4262e-01, time/batch = 0.6936s	
543/11350 (epoch 2.392), train_loss = 2.41206719, grad/param norm = 3.7879e-01, time/batch = 0.6851s	
544/11350 (epoch 2.396), train_loss = 2.35621722, grad/param norm = 3.3616e-01, time/batch = 0.6864s	
545/11350 (epoch 2.401), train_loss = 2.26261733, grad/param norm = 3.5257e-01, time/batch = 0.6833s	
546/11350 (epoch 2.405), train_loss = 2.39165559, grad/param norm = 3.4880e-01, time/batch = 0.6834s	
547/11350 (epoch 2.410), train_loss = 2.60518804, grad/param norm = 3.6554e-01, time/batch = 0.6829s	
548/11350 (epoch 2.414), train_loss = 2.19550153, grad/param norm = 2.9241e-01, time/batch = 0.7076s	
549/11350 (epoch 2.419), train_loss = 2.84235333, grad/param norm = 4.5443e-01, time/batch = 0.7120s	
550/11350 (epoch 2.423), train_loss = 2.59876306, grad/param norm = 4.9471e-01, time/batch = 0.6838s	
551/11350 (epoch 2.427), train_loss = 2.50617699, grad/param norm = 3.0018e-01, time/batch = 0.6858s	
552/11350 (epoch 2.432), train_loss = 2.79841753, grad/param norm = 3.9782e-01, time/batch = 0.6844s	
553/11350 (epoch 2.436), train_loss = 2.60272828, grad/param norm = 3.9987e-01, time/batch = 0.7232s	
554/11350 (epoch 2.441), train_loss = 2.49240911, grad/param norm = 4.2775e-01, time/batch = 0.6864s	
555/11350 (epoch 2.445), train_loss = 2.17477347, grad/param norm = 3.9501e-01, time/batch = 0.6884s	
556/11350 (epoch 2.449), train_loss = 2.33416221, grad/param norm = 3.5048e-01, time/batch = 0.6873s	
557/11350 (epoch 2.454), train_loss = 2.34089411, grad/param norm = 4.3033e-01, time/batch = 0.6888s	
558/11350 (epoch 2.458), train_loss = 2.22872199, grad/param norm = 3.4815e-01, time/batch = 0.6875s	
559/11350 (epoch 2.463), train_loss = 2.36771421, grad/param norm = 3.4891e-01, time/batch = 0.6848s	
560/11350 (epoch 2.467), train_loss = 2.54487183, grad/param norm = 3.9767e-01, time/batch = 0.6882s	
561/11350 (epoch 2.471), train_loss = 2.49326449, grad/param norm = 4.7997e-01, time/batch = 0.6864s	
562/11350 (epoch 2.476), train_loss = 2.36488697, grad/param norm = 4.8486e-01, time/batch = 0.6889s	
563/11350 (epoch 2.480), train_loss = 2.74365778, grad/param norm = 6.0493e-01, time/batch = 0.6893s	
564/11350 (epoch 2.485), train_loss = 2.34813068, grad/param norm = 6.2803e-01, time/batch = 0.6975s	
565/11350 (epoch 2.489), train_loss = 2.56125427, grad/param norm = 4.9454e-01, time/batch = 0.6893s	
566/11350 (epoch 2.493), train_loss = 2.44676187, grad/param norm = 4.0623e-01, time/batch = 0.6840s	
567/11350 (epoch 2.498), train_loss = 2.20907327, grad/param norm = 3.2007e-01, time/batch = 0.6826s	
568/11350 (epoch 2.502), train_loss = 2.48071078, grad/param norm = 3.5122e-01, time/batch = 0.7068s	
569/11350 (epoch 2.507), train_loss = 2.29285437, grad/param norm = 3.3487e-01, time/batch = 0.7186s	
570/11350 (epoch 2.511), train_loss = 2.39833206, grad/param norm = 4.1471e-01, time/batch = 0.6860s	
571/11350 (epoch 2.515), train_loss = 2.43932050, grad/param norm = 5.7898e-01, time/batch = 0.6833s	
572/11350 (epoch 2.520), train_loss = 2.56623152, grad/param norm = 6.9231e-01, time/batch = 0.6864s	
573/11350 (epoch 2.524), train_loss = 2.48065714, grad/param norm = 6.4905e-01, time/batch = 0.6823s	
574/11350 (epoch 2.529), train_loss = 2.51771759, grad/param norm = 4.7549e-01, time/batch = 0.6854s	
575/11350 (epoch 2.533), train_loss = 2.47226642, grad/param norm = 3.9101e-01, time/batch = 0.6836s	
576/11350 (epoch 2.537), train_loss = 2.42218395, grad/param norm = 3.6928e-01, time/batch = 0.6828s	
577/11350 (epoch 2.542), train_loss = 2.53689142, grad/param norm = 3.2012e-01, time/batch = 0.6859s	
578/11350 (epoch 2.546), train_loss = 2.73370756, grad/param norm = 4.6022e-01, time/batch = 0.6849s	
579/11350 (epoch 2.551), train_loss = 2.50216505, grad/param norm = 4.3024e-01, time/batch = 0.6829s	
580/11350 (epoch 2.555), train_loss = 2.56275151, grad/param norm = 3.9871e-01, time/batch = 0.6921s	
581/11350 (epoch 2.559), train_loss = 2.24228909, grad/param norm = 2.7093e-01, time/batch = 0.7017s	
582/11350 (epoch 2.564), train_loss = 2.38682694, grad/param norm = 3.1954e-01, time/batch = 0.7066s	
583/11350 (epoch 2.568), train_loss = 2.57837532, grad/param norm = 3.9365e-01, time/batch = 0.6948s	
584/11350 (epoch 2.573), train_loss = 2.56143086, grad/param norm = 3.2123e-01, time/batch = 0.6858s	
585/11350 (epoch 2.577), train_loss = 2.53696103, grad/param norm = 3.2698e-01, time/batch = 0.6872s	
586/11350 (epoch 2.581), train_loss = 2.39619674, grad/param norm = 3.6307e-01, time/batch = 0.6866s	
587/11350 (epoch 2.586), train_loss = 2.48321674, grad/param norm = 3.4680e-01, time/batch = 0.6870s	
588/11350 (epoch 2.590), train_loss = 2.64527327, grad/param norm = 3.8276e-01, time/batch = 0.6960s	
589/11350 (epoch 2.595), train_loss = 2.59511553, grad/param norm = 3.6386e-01, time/batch = 0.7217s	
590/11350 (epoch 2.599), train_loss = 2.39990170, grad/param norm = 3.3490e-01, time/batch = 0.6874s	
591/11350 (epoch 2.604), train_loss = 2.43605308, grad/param norm = 2.8093e-01, time/batch = 0.6826s	
592/11350 (epoch 2.608), train_loss = 2.67662689, grad/param norm = 4.6119e-01, time/batch = 0.7000s	
593/11350 (epoch 2.612), train_loss = 2.27422074, grad/param norm = 5.9635e-01, time/batch = 0.6939s	
594/11350 (epoch 2.617), train_loss = 2.75083705, grad/param norm = 6.7341e-01, time/batch = 0.6877s	
595/11350 (epoch 2.621), train_loss = 2.41826535, grad/param norm = 6.8604e-01, time/batch = 0.6833s	
596/11350 (epoch 2.626), train_loss = 2.45590530, grad/param norm = 4.3317e-01, time/batch = 0.6874s	
597/11350 (epoch 2.630), train_loss = 2.62781729, grad/param norm = 3.0869e-01, time/batch = 0.6887s	
598/11350 (epoch 2.634), train_loss = 2.61859941, grad/param norm = 3.7234e-01, time/batch = 0.6841s	
599/11350 (epoch 2.639), train_loss = 2.36424995, grad/param norm = 2.7191e-01, time/batch = 0.7039s	
600/11350 (epoch 2.643), train_loss = 2.38330354, grad/param norm = 3.6727e-01, time/batch = 0.7151s	
601/11350 (epoch 2.648), train_loss = 2.42992822, grad/param norm = 3.5156e-01, time/batch = 0.7181s	
602/11350 (epoch 2.652), train_loss = 2.30225283, grad/param norm = 3.4258e-01, time/batch = 0.6976s	
603/11350 (epoch 2.656), train_loss = 2.50963338, grad/param norm = 4.3975e-01, time/batch = 0.7111s	
604/11350 (epoch 2.661), train_loss = 2.50691386, grad/param norm = 3.1407e-01, time/batch = 0.6859s	
605/11350 (epoch 2.665), train_loss = 2.49436908, grad/param norm = 3.5974e-01, time/batch = 0.6850s	
606/11350 (epoch 2.670), train_loss = 2.55989824, grad/param norm = 3.9188e-01, time/batch = 0.6896s	
607/11350 (epoch 2.674), train_loss = 2.46903033, grad/param norm = 4.0206e-01, time/batch = 0.6889s	
608/11350 (epoch 2.678), train_loss = 2.45572125, grad/param norm = 4.7265e-01, time/batch = 0.6865s	
609/11350 (epoch 2.683), train_loss = 2.37652358, grad/param norm = 4.7339e-01, time/batch = 0.6860s	
610/11350 (epoch 2.687), train_loss = 2.41182983, grad/param norm = 3.2473e-01, time/batch = 0.6852s	
611/11350 (epoch 2.692), train_loss = 2.69718572, grad/param norm = 4.4199e-01, time/batch = 0.6863s	
612/11350 (epoch 2.696), train_loss = 2.38830175, grad/param norm = 3.9398e-01, time/batch = 0.6999s	
613/11350 (epoch 2.700), train_loss = 2.57283024, grad/param norm = 3.3310e-01, time/batch = 0.6999s	
614/11350 (epoch 2.705), train_loss = 2.50617625, grad/param norm = 3.0912e-01, time/batch = 0.7058s	
615/11350 (epoch 2.709), train_loss = 2.63603820, grad/param norm = 3.9163e-01, time/batch = 0.7013s	
616/11350 (epoch 2.714), train_loss = 2.44360751, grad/param norm = 5.0613e-01, time/batch = 0.7128s	
617/11350 (epoch 2.718), train_loss = 2.56541230, grad/param norm = 4.4784e-01, time/batch = 0.7014s	
618/11350 (epoch 2.722), train_loss = 2.52492103, grad/param norm = 3.8781e-01, time/batch = 0.6983s	
619/11350 (epoch 2.727), train_loss = 2.35164111, grad/param norm = 3.5030e-01, time/batch = 0.6972s	
620/11350 (epoch 2.731), train_loss = 2.43571891, grad/param norm = 3.0881e-01, time/batch = 0.6984s	
621/11350 (epoch 2.736), train_loss = 2.47084237, grad/param norm = 3.0596e-01, time/batch = 0.7080s	
622/11350 (epoch 2.740), train_loss = 2.56989008, grad/param norm = 3.7621e-01, time/batch = 0.7245s	
623/11350 (epoch 2.744), train_loss = 2.57077440, grad/param norm = 4.4502e-01, time/batch = 0.7032s	
624/11350 (epoch 2.749), train_loss = 2.53144059, grad/param norm = 4.0015e-01, time/batch = 0.7099s	
625/11350 (epoch 2.753), train_loss = 2.50620370, grad/param norm = 4.7894e-01, time/batch = 0.7059s	
626/11350 (epoch 2.758), train_loss = 2.31533523, grad/param norm = 5.5139e-01, time/batch = 0.7051s	
627/11350 (epoch 2.762), train_loss = 2.38230633, grad/param norm = 3.3360e-01, time/batch = 0.6992s	
628/11350 (epoch 2.767), train_loss = 2.50214943, grad/param norm = 3.0356e-01, time/batch = 0.7022s	
629/11350 (epoch 2.771), train_loss = 2.44140965, grad/param norm = 3.0570e-01, time/batch = 0.7092s	
630/11350 (epoch 2.775), train_loss = 2.43467970, grad/param norm = 3.0421e-01, time/batch = 0.7075s	
631/11350 (epoch 2.780), train_loss = 2.38435060, grad/param norm = 3.4973e-01, time/batch = 0.6883s	
632/11350 (epoch 2.784), train_loss = 2.35777371, grad/param norm = 3.7199e-01, time/batch = 0.6849s	
633/11350 (epoch 2.789), train_loss = 2.36032525, grad/param norm = 3.9291e-01, time/batch = 0.6861s	
634/11350 (epoch 2.793), train_loss = 2.31262970, grad/param norm = 3.8833e-01, time/batch = 0.6874s	
635/11350 (epoch 2.797), train_loss = 2.23510756, grad/param norm = 3.7730e-01, time/batch = 0.6861s	
636/11350 (epoch 2.802), train_loss = 2.39746518, grad/param norm = 3.9493e-01, time/batch = 0.6863s	
637/11350 (epoch 2.806), train_loss = 2.32719602, grad/param norm = 3.7441e-01, time/batch = 0.6878s	
638/11350 (epoch 2.811), train_loss = 2.52016773, grad/param norm = 4.7637e-01, time/batch = 0.6839s	
639/11350 (epoch 2.815), train_loss = 2.22128943, grad/param norm = 5.8878e-01, time/batch = 0.6849s	
640/11350 (epoch 2.819), train_loss = 2.34539448, grad/param norm = 4.4211e-01, time/batch = 0.6853s	
641/11350 (epoch 2.824), train_loss = 2.43574832, grad/param norm = 3.6575e-01, time/batch = 0.6843s	
642/11350 (epoch 2.828), train_loss = 2.33227254, grad/param norm = 3.6524e-01, time/batch = 0.6894s	
643/11350 (epoch 2.833), train_loss = 2.46650114, grad/param norm = 4.2238e-01, time/batch = 0.6844s	
644/11350 (epoch 2.837), train_loss = 2.26597865, grad/param norm = 3.8575e-01, time/batch = 0.6889s	
645/11350 (epoch 2.841), train_loss = 2.52375924, grad/param norm = 3.0990e-01, time/batch = 0.6824s	
646/11350 (epoch 2.846), train_loss = 2.27131486, grad/param norm = 3.8884e-01, time/batch = 0.6840s	
647/11350 (epoch 2.850), train_loss = 2.47459900, grad/param norm = 3.9415e-01, time/batch = 0.6834s	
648/11350 (epoch 2.855), train_loss = 2.14895084, grad/param norm = 4.3244e-01, time/batch = 0.6903s	
649/11350 (epoch 2.859), train_loss = 2.47990516, grad/param norm = 5.5638e-01, time/batch = 0.6811s	
650/11350 (epoch 2.863), train_loss = 2.16443766, grad/param norm = 4.5064e-01, time/batch = 0.6874s	
651/11350 (epoch 2.868), train_loss = 2.31343772, grad/param norm = 3.0521e-01, time/batch = 0.6833s	
652/11350 (epoch 2.872), train_loss = 2.34737369, grad/param norm = 3.8636e-01, time/batch = 0.6830s	
653/11350 (epoch 2.877), train_loss = 2.38089798, grad/param norm = 3.6510e-01, time/batch = 0.6826s	
654/11350 (epoch 2.881), train_loss = 2.56964210, grad/param norm = 3.7349e-01, time/batch = 0.6815s	
655/11350 (epoch 2.885), train_loss = 2.45058229, grad/param norm = 4.7533e-01, time/batch = 0.7029s	
656/11350 (epoch 2.890), train_loss = 2.32935782, grad/param norm = 3.4797e-01, time/batch = 0.6852s	
657/11350 (epoch 2.894), train_loss = 2.43298165, grad/param norm = 3.6979e-01, time/batch = 0.6806s	
658/11350 (epoch 2.899), train_loss = 2.46595549, grad/param norm = 3.5715e-01, time/batch = 0.6853s	
659/11350 (epoch 2.903), train_loss = 2.68885637, grad/param norm = 3.3787e-01, time/batch = 0.6836s	
660/11350 (epoch 2.907), train_loss = 2.52164979, grad/param norm = 3.3007e-01, time/batch = 0.6810s	
661/11350 (epoch 2.912), train_loss = 2.30941890, grad/param norm = 3.5771e-01, time/batch = 0.6926s	
662/11350 (epoch 2.916), train_loss = 2.48277372, grad/param norm = 4.0879e-01, time/batch = 0.6853s	
663/11350 (epoch 2.921), train_loss = 2.32251101, grad/param norm = 4.2931e-01, time/batch = 0.6822s	
664/11350 (epoch 2.925), train_loss = 2.30285183, grad/param norm = 3.6620e-01, time/batch = 0.6867s	
665/11350 (epoch 2.930), train_loss = 2.35801700, grad/param norm = 3.4315e-01, time/batch = 0.6845s	
666/11350 (epoch 2.934), train_loss = 2.53670860, grad/param norm = 3.7995e-01, time/batch = 0.6885s	
667/11350 (epoch 2.938), train_loss = 2.35394070, grad/param norm = 3.3047e-01, time/batch = 0.6858s	
668/11350 (epoch 2.943), train_loss = 2.52658673, grad/param norm = 2.7474e-01, time/batch = 0.6844s	
669/11350 (epoch 2.947), train_loss = 2.46303524, grad/param norm = 3.4163e-01, time/batch = 0.6836s	
670/11350 (epoch 2.952), train_loss = 2.47688858, grad/param norm = 3.0772e-01, time/batch = 0.6814s	
671/11350 (epoch 2.956), train_loss = 2.42112926, grad/param norm = 4.3179e-01, time/batch = 0.6846s	
672/11350 (epoch 2.960), train_loss = 2.50193058, grad/param norm = 3.8886e-01, time/batch = 0.6872s	
673/11350 (epoch 2.965), train_loss = 2.43771607, grad/param norm = 3.1162e-01, time/batch = 0.6857s	
674/11350 (epoch 2.969), train_loss = 2.49193615, grad/param norm = 3.4700e-01, time/batch = 0.6856s	
675/11350 (epoch 2.974), train_loss = 2.23980181, grad/param norm = 3.1232e-01, time/batch = 0.6894s	
676/11350 (epoch 2.978), train_loss = 2.50912764, grad/param norm = 3.0951e-01, time/batch = 0.6857s	
677/11350 (epoch 2.982), train_loss = 2.11603488, grad/param norm = 3.3971e-01, time/batch = 0.6869s	
678/11350 (epoch 2.987), train_loss = 2.35597644, grad/param norm = 3.7038e-01, time/batch = 0.6897s	
679/11350 (epoch 2.991), train_loss = 2.13180920, grad/param norm = 2.9381e-01, time/batch = 0.6848s	
680/11350 (epoch 2.996), train_loss = 2.47762251, grad/param norm = 3.6726e-01, time/batch = 0.6867s	
681/11350 (epoch 3.000), train_loss = 2.12525096, grad/param norm = 3.4378e-01, time/batch = 0.6882s	
682/11350 (epoch 3.004), train_loss = 2.27744710, grad/param norm = 3.8314e-01, time/batch = 0.6848s	
683/11350 (epoch 3.009), train_loss = 2.63463573, grad/param norm = 8.1804e-01, time/batch = 0.6868s	
684/11350 (epoch 3.013), train_loss = 2.01593121, grad/param norm = 5.5001e-01, time/batch = 0.6837s	
685/11350 (epoch 3.018), train_loss = 2.12723597, grad/param norm = 3.8454e-01, time/batch = 0.6878s	
686/11350 (epoch 3.022), train_loss = 2.01579167, grad/param norm = 3.9389e-01, time/batch = 0.7114s	
687/11350 (epoch 3.026), train_loss = 2.20422190, grad/param norm = 3.0441e-01, time/batch = 0.7172s	
688/11350 (epoch 3.031), train_loss = 1.98528347, grad/param norm = 2.9043e-01, time/batch = 0.6990s	
689/11350 (epoch 3.035), train_loss = 2.22805269, grad/param norm = 2.9142e-01, time/batch = 0.7157s	
690/11350 (epoch 3.040), train_loss = 2.17776511, grad/param norm = 3.3975e-01, time/batch = 0.7081s	
691/11350 (epoch 3.044), train_loss = 2.12452256, grad/param norm = 2.6526e-01, time/batch = 0.6926s	
692/11350 (epoch 3.048), train_loss = 2.16656078, grad/param norm = 2.8938e-01, time/batch = 0.6898s	
693/11350 (epoch 3.053), train_loss = 2.08761878, grad/param norm = 3.4122e-01, time/batch = 0.7090s	
694/11350 (epoch 3.057), train_loss = 2.26953183, grad/param norm = 3.2187e-01, time/batch = 0.7212s	
695/11350 (epoch 3.062), train_loss = 1.92844729, grad/param norm = 2.6708e-01, time/batch = 0.6869s	
696/11350 (epoch 3.066), train_loss = 2.03959076, grad/param norm = 2.9352e-01, time/batch = 0.6833s	
697/11350 (epoch 3.070), train_loss = 2.14790211, grad/param norm = 3.4623e-01, time/batch = 0.6832s	
698/11350 (epoch 3.075), train_loss = 2.03878690, grad/param norm = 4.0304e-01, time/batch = 0.6841s	
699/11350 (epoch 3.079), train_loss = 2.14229026, grad/param norm = 3.2958e-01, time/batch = 0.6855s	
700/11350 (epoch 3.084), train_loss = 2.41758103, grad/param norm = 2.7221e-01, time/batch = 0.6846s	
701/11350 (epoch 3.088), train_loss = 2.25113619, grad/param norm = 3.0478e-01, time/batch = 0.6883s	
702/11350 (epoch 3.093), train_loss = 1.95333718, grad/param norm = 3.2775e-01, time/batch = 0.6856s	
703/11350 (epoch 3.097), train_loss = 2.32842069, grad/param norm = 4.1547e-01, time/batch = 0.6952s	
704/11350 (epoch 3.101), train_loss = 2.11917185, grad/param norm = 4.4673e-01, time/batch = 0.7219s	
705/11350 (epoch 3.106), train_loss = 2.31320853, grad/param norm = 5.0343e-01, time/batch = 0.6922s	
706/11350 (epoch 3.110), train_loss = 2.06609313, grad/param norm = 9.0913e-01, time/batch = 0.6895s	
707/11350 (epoch 3.115), train_loss = 2.13948449, grad/param norm = 4.4347e-01, time/batch = 0.6893s	
708/11350 (epoch 3.119), train_loss = 2.20121550, grad/param norm = 3.5517e-01, time/batch = 0.6998s	
709/11350 (epoch 3.123), train_loss = 2.05599409, grad/param norm = 3.1672e-01, time/batch = 0.7227s	
710/11350 (epoch 3.128), train_loss = 2.09859302, grad/param norm = 2.5407e-01, time/batch = 0.6817s	
711/11350 (epoch 3.132), train_loss = 2.14356077, grad/param norm = 2.7912e-01, time/batch = 0.6921s	
712/11350 (epoch 3.137), train_loss = 1.94518247, grad/param norm = 2.4445e-01, time/batch = 0.6987s	
713/11350 (epoch 3.141), train_loss = 2.17697714, grad/param norm = 2.7068e-01, time/batch = 0.6954s	
714/11350 (epoch 3.145), train_loss = 2.11134840, grad/param norm = 2.7862e-01, time/batch = 0.7217s	
715/11350 (epoch 3.150), train_loss = 2.19880263, grad/param norm = 3.0411e-01, time/batch = 0.6935s	
716/11350 (epoch 3.154), train_loss = 2.20046242, grad/param norm = 3.2720e-01, time/batch = 0.6824s	
717/11350 (epoch 3.159), train_loss = 2.08489720, grad/param norm = 2.8601e-01, time/batch = 0.6819s	
718/11350 (epoch 3.163), train_loss = 2.21923233, grad/param norm = 3.2937e-01, time/batch = 0.6840s	
719/11350 (epoch 3.167), train_loss = 2.29005967, grad/param norm = 3.8085e-01, time/batch = 0.6825s	
720/11350 (epoch 3.172), train_loss = 2.41480085, grad/param norm = 3.3688e-01, time/batch = 0.6866s	
721/11350 (epoch 3.176), train_loss = 2.12245571, grad/param norm = 2.8522e-01, time/batch = 0.6872s	
722/11350 (epoch 3.181), train_loss = 2.16494466, grad/param norm = 3.2623e-01, time/batch = 0.6851s	
723/11350 (epoch 3.185), train_loss = 2.29142711, grad/param norm = 3.1575e-01, time/batch = 0.6907s	
724/11350 (epoch 3.189), train_loss = 2.03699045, grad/param norm = 3.8396e-01, time/batch = 0.6897s	
725/11350 (epoch 3.194), train_loss = 2.02843147, grad/param norm = 4.0751e-01, time/batch = 0.6847s	
726/11350 (epoch 3.198), train_loss = 2.17426014, grad/param norm = 3.6097e-01, time/batch = 0.6861s	
727/11350 (epoch 3.203), train_loss = 2.04546609, grad/param norm = 2.5471e-01, time/batch = 0.6863s	
728/11350 (epoch 3.207), train_loss = 2.15856192, grad/param norm = 3.1003e-01, time/batch = 0.6857s	
729/11350 (epoch 3.211), train_loss = 2.29578175, grad/param norm = 2.8216e-01, time/batch = 0.6842s	
730/11350 (epoch 3.216), train_loss = 2.18815954, grad/param norm = 3.4604e-01, time/batch = 0.6900s	
731/11350 (epoch 3.220), train_loss = 2.22696824, grad/param norm = 3.3368e-01, time/batch = 0.6841s	
732/11350 (epoch 3.225), train_loss = 2.10751208, grad/param norm = 2.8705e-01, time/batch = 0.6856s	
733/11350 (epoch 3.229), train_loss = 2.30956643, grad/param norm = 3.1486e-01, time/batch = 0.6874s	
734/11350 (epoch 3.233), train_loss = 2.14792059, grad/param norm = 3.6951e-01, time/batch = 0.7217s	
735/11350 (epoch 3.238), train_loss = 2.46989689, grad/param norm = 4.9529e-01, time/batch = 0.6948s	
736/11350 (epoch 3.242), train_loss = 2.47446561, grad/param norm = 4.5891e-01, time/batch = 0.6911s	
737/11350 (epoch 3.247), train_loss = 1.99634155, grad/param norm = 3.8066e-01, time/batch = 0.6824s	
738/11350 (epoch 3.251), train_loss = 2.26151670, grad/param norm = 3.3521e-01, time/batch = 0.6864s	
739/11350 (epoch 3.256), train_loss = 2.27890760, grad/param norm = 3.2643e-01, time/batch = 0.6832s	
740/11350 (epoch 3.260), train_loss = 2.27580774, grad/param norm = 3.6756e-01, time/batch = 0.6823s	
741/11350 (epoch 3.264), train_loss = 2.01257355, grad/param norm = 3.7862e-01, time/batch = 0.6840s	
742/11350 (epoch 3.269), train_loss = 2.21573527, grad/param norm = 4.0291e-01, time/batch = 0.6864s	
743/11350 (epoch 3.273), train_loss = 2.27037243, grad/param norm = 3.2711e-01, time/batch = 0.7041s	
744/11350 (epoch 3.278), train_loss = 2.05594719, grad/param norm = 3.2883e-01, time/batch = 0.7057s	
745/11350 (epoch 3.282), train_loss = 2.31796255, grad/param norm = 3.8038e-01, time/batch = 0.7042s	
746/11350 (epoch 3.286), train_loss = 2.31606012, grad/param norm = 4.1909e-01, time/batch = 0.7038s	
747/11350 (epoch 3.291), train_loss = 2.11280715, grad/param norm = 3.9532e-01, time/batch = 0.7024s	
748/11350 (epoch 3.295), train_loss = 2.28356000, grad/param norm = 3.6880e-01, time/batch = 0.7011s	
749/11350 (epoch 3.300), train_loss = 2.13808359, grad/param norm = 2.8062e-01, time/batch = 0.7039s	
750/11350 (epoch 3.304), train_loss = 2.02519299, grad/param norm = 3.0732e-01, time/batch = 0.6860s	
751/11350 (epoch 3.308), train_loss = 2.09064488, grad/param norm = 3.3021e-01, time/batch = 0.6826s	
752/11350 (epoch 3.313), train_loss = 2.09668575, grad/param norm = 4.1050e-01, time/batch = 0.6841s	
753/11350 (epoch 3.317), train_loss = 1.89325894, grad/param norm = 4.1357e-01, time/batch = 0.6830s	
754/11350 (epoch 3.322), train_loss = 2.00847513, grad/param norm = 3.5267e-01, time/batch = 0.7220s	
755/11350 (epoch 3.326), train_loss = 2.11986080, grad/param norm = 3.4964e-01, time/batch = 0.7001s	
756/11350 (epoch 3.330), train_loss = 1.95741331, grad/param norm = 2.8261e-01, time/batch = 0.6818s	
757/11350 (epoch 3.335), train_loss = 1.91416056, grad/param norm = 3.5483e-01, time/batch = 0.6903s	
758/11350 (epoch 3.339), train_loss = 1.99297495, grad/param norm = 3.8085e-01, time/batch = 0.6905s	
759/11350 (epoch 3.344), train_loss = 2.09134782, grad/param norm = 3.7121e-01, time/batch = 0.6858s	
760/11350 (epoch 3.348), train_loss = 2.11407207, grad/param norm = 5.3196e-01, time/batch = 0.6802s	
761/11350 (epoch 3.352), train_loss = 1.85992023, grad/param norm = 4.6518e-01, time/batch = 0.6863s	
762/11350 (epoch 3.357), train_loss = 2.15814159, grad/param norm = 3.1762e-01, time/batch = 0.6830s	
763/11350 (epoch 3.361), train_loss = 1.84169401, grad/param norm = 3.0542e-01, time/batch = 0.6825s	
764/11350 (epoch 3.366), train_loss = 2.22622032, grad/param norm = 3.9967e-01, time/batch = 0.7181s	
765/11350 (epoch 3.370), train_loss = 2.05696658, grad/param norm = 3.0804e-01, time/batch = 0.7053s	
766/11350 (epoch 3.374), train_loss = 2.09603142, grad/param norm = 3.9830e-01, time/batch = 0.6862s	
767/11350 (epoch 3.379), train_loss = 2.22540164, grad/param norm = 3.9026e-01, time/batch = 0.6850s	
768/11350 (epoch 3.383), train_loss = 2.00957493, grad/param norm = 3.5868e-01, time/batch = 0.6822s	
769/11350 (epoch 3.388), train_loss = 2.13167093, grad/param norm = 4.2080e-01, time/batch = 0.6838s	
770/11350 (epoch 3.392), train_loss = 2.18803355, grad/param norm = 3.3215e-01, time/batch = 0.6852s	
771/11350 (epoch 3.396), train_loss = 2.09843889, grad/param norm = 3.1336e-01, time/batch = 0.6907s	
772/11350 (epoch 3.401), train_loss = 1.98211406, grad/param norm = 2.8162e-01, time/batch = 0.7155s	
773/11350 (epoch 3.405), train_loss = 2.15311691, grad/param norm = 2.8784e-01, time/batch = 0.7145s	
774/11350 (epoch 3.410), train_loss = 2.42004779, grad/param norm = 3.0027e-01, time/batch = 0.7230s	
775/11350 (epoch 3.414), train_loss = 1.95276840, grad/param norm = 3.0689e-01, time/batch = 0.7086s	
776/11350 (epoch 3.419), train_loss = 2.51103939, grad/param norm = 4.2939e-01, time/batch = 0.6903s	
777/11350 (epoch 3.423), train_loss = 2.37340363, grad/param norm = 4.0130e-01, time/batch = 0.6901s	
778/11350 (epoch 3.427), train_loss = 2.26899893, grad/param norm = 2.4734e-01, time/batch = 0.6921s	
779/11350 (epoch 3.432), train_loss = 2.52733579, grad/param norm = 4.1378e-01, time/batch = 0.6950s	
780/11350 (epoch 3.436), train_loss = 2.31520317, grad/param norm = 3.0500e-01, time/batch = 0.7019s	
781/11350 (epoch 3.441), train_loss = 2.26913799, grad/param norm = 2.9292e-01, time/batch = 0.7278s	
782/11350 (epoch 3.445), train_loss = 1.81886125, grad/param norm = 2.7263e-01, time/batch = 0.6898s	
783/11350 (epoch 3.449), train_loss = 2.05927254, grad/param norm = 3.5726e-01, time/batch = 0.6873s	
784/11350 (epoch 3.454), train_loss = 2.14110371, grad/param norm = 3.6885e-01, time/batch = 0.7201s	
785/11350 (epoch 3.458), train_loss = 1.98078108, grad/param norm = 3.3724e-01, time/batch = 0.7371s	
786/11350 (epoch 3.463), train_loss = 2.08115485, grad/param norm = 2.9754e-01, time/batch = 0.6992s	
787/11350 (epoch 3.467), train_loss = 2.31690776, grad/param norm = 2.7567e-01, time/batch = 0.6897s	
788/11350 (epoch 3.471), train_loss = 2.27501308, grad/param norm = 3.3953e-01, time/batch = 0.6898s	
789/11350 (epoch 3.476), train_loss = 2.12586340, grad/param norm = 3.3760e-01, time/batch = 0.7007s	
790/11350 (epoch 3.480), train_loss = 2.46708228, grad/param norm = 3.7166e-01, time/batch = 0.6844s	
791/11350 (epoch 3.485), train_loss = 2.06511544, grad/param norm = 3.2430e-01, time/batch = 0.6856s	
792/11350 (epoch 3.489), train_loss = 2.32318177, grad/param norm = 3.0910e-01, time/batch = 0.6864s	
793/11350 (epoch 3.493), train_loss = 2.19633485, grad/param norm = 2.6733e-01, time/batch = 0.6856s	
794/11350 (epoch 3.498), train_loss = 1.90758560, grad/param norm = 2.7142e-01, time/batch = 0.6841s	
795/11350 (epoch 3.502), train_loss = 2.26512270, grad/param norm = 3.0028e-01, time/batch = 0.6850s	
796/11350 (epoch 3.507), train_loss = 2.04701564, grad/param norm = 3.0123e-01, time/batch = 0.6826s	
797/11350 (epoch 3.511), train_loss = 2.25874166, grad/param norm = 3.5645e-01, time/batch = 0.6827s	
798/11350 (epoch 3.515), train_loss = 2.11581605, grad/param norm = 3.4298e-01, time/batch = 0.6827s	
799/11350 (epoch 3.520), train_loss = 2.29242616, grad/param norm = 3.7010e-01, time/batch = 0.6835s	
800/11350 (epoch 3.524), train_loss = 2.19508526, grad/param norm = 4.1612e-01, time/batch = 0.6853s	
801/11350 (epoch 3.529), train_loss = 2.29466743, grad/param norm = 3.3560e-01, time/batch = 0.6861s	
802/11350 (epoch 3.533), train_loss = 2.26506225, grad/param norm = 2.8715e-01, time/batch = 0.6872s	
803/11350 (epoch 3.537), train_loss = 2.18135537, grad/param norm = 3.0970e-01, time/batch = 0.6837s	
804/11350 (epoch 3.542), train_loss = 2.35109313, grad/param norm = 2.7776e-01, time/batch = 0.6838s	
805/11350 (epoch 3.546), train_loss = 2.52288395, grad/param norm = 4.2533e-01, time/batch = 0.6818s	
806/11350 (epoch 3.551), train_loss = 2.21207564, grad/param norm = 3.7782e-01, time/batch = 0.6840s	
807/11350 (epoch 3.555), train_loss = 2.35374227, grad/param norm = 4.9852e-01, time/batch = 0.6829s	
808/11350 (epoch 3.559), train_loss = 2.06285651, grad/param norm = 3.7807e-01, time/batch = 0.6809s	
809/11350 (epoch 3.564), train_loss = 2.19120626, grad/param norm = 3.4128e-01, time/batch = 0.6842s	
810/11350 (epoch 3.568), train_loss = 2.32321697, grad/param norm = 3.1948e-01, time/batch = 0.6862s	
811/11350 (epoch 3.573), train_loss = 2.36274540, grad/param norm = 2.9740e-01, time/batch = 0.6899s	
812/11350 (epoch 3.577), train_loss = 2.34147159, grad/param norm = 3.0891e-01, time/batch = 0.6855s	
813/11350 (epoch 3.581), train_loss = 2.21756454, grad/param norm = 3.7840e-01, time/batch = 0.6864s	
814/11350 (epoch 3.586), train_loss = 2.30384053, grad/param norm = 2.9191e-01, time/batch = 0.6790s	
815/11350 (epoch 3.590), train_loss = 2.45690217, grad/param norm = 3.0118e-01, time/batch = 0.6815s	
816/11350 (epoch 3.595), train_loss = 2.38760362, grad/param norm = 3.0881e-01, time/batch = 0.6838s	
817/11350 (epoch 3.599), train_loss = 2.18030975, grad/param norm = 2.9641e-01, time/batch = 0.6827s	
818/11350 (epoch 3.604), train_loss = 2.21838074, grad/param norm = 2.5783e-01, time/batch = 0.6812s	
819/11350 (epoch 3.608), train_loss = 2.46059859, grad/param norm = 4.3104e-01, time/batch = 0.6884s	
820/11350 (epoch 3.612), train_loss = 2.05103757, grad/param norm = 3.6664e-01, time/batch = 0.6812s	
821/11350 (epoch 3.617), train_loss = 2.47676373, grad/param norm = 3.4208e-01, time/batch = 0.6818s	
822/11350 (epoch 3.621), train_loss = 2.20455279, grad/param norm = 4.1858e-01, time/batch = 0.6922s	
823/11350 (epoch 3.626), train_loss = 2.25656082, grad/param norm = 3.4879e-01, time/batch = 0.6872s	
824/11350 (epoch 3.630), train_loss = 2.37835390, grad/param norm = 2.7561e-01, time/batch = 0.6861s	
825/11350 (epoch 3.634), train_loss = 2.39048578, grad/param norm = 3.3017e-01, time/batch = 0.6871s	
826/11350 (epoch 3.639), train_loss = 2.15486019, grad/param norm = 3.0747e-01, time/batch = 0.6853s	
827/11350 (epoch 3.643), train_loss = 2.18560339, grad/param norm = 3.8849e-01, time/batch = 0.6843s	
828/11350 (epoch 3.648), train_loss = 2.23505612, grad/param norm = 3.2582e-01, time/batch = 0.6882s	
829/11350 (epoch 3.652), train_loss = 2.11026358, grad/param norm = 2.9015e-01, time/batch = 0.7215s	
830/11350 (epoch 3.656), train_loss = 2.30701282, grad/param norm = 3.3400e-01, time/batch = 0.6979s	
831/11350 (epoch 3.661), train_loss = 2.30360484, grad/param norm = 2.8391e-01, time/batch = 0.6890s	
832/11350 (epoch 3.665), train_loss = 2.23035292, grad/param norm = 3.1009e-01, time/batch = 0.6911s	
833/11350 (epoch 3.670), train_loss = 2.33418166, grad/param norm = 3.2657e-01, time/batch = 0.7049s	
834/11350 (epoch 3.674), train_loss = 2.25215371, grad/param norm = 3.5812e-01, time/batch = 0.6961s	
835/11350 (epoch 3.678), train_loss = 2.23809746, grad/param norm = 3.6845e-01, time/batch = 0.6882s	
836/11350 (epoch 3.683), train_loss = 2.19989702, grad/param norm = 3.5976e-01, time/batch = 0.6866s	
837/11350 (epoch 3.687), train_loss = 2.22335126, grad/param norm = 2.8618e-01, time/batch = 0.6884s	
838/11350 (epoch 3.692), train_loss = 2.51963600, grad/param norm = 3.6797e-01, time/batch = 0.6851s	
839/11350 (epoch 3.696), train_loss = 2.19143579, grad/param norm = 3.3992e-01, time/batch = 0.7220s	
840/11350 (epoch 3.700), train_loss = 2.36240552, grad/param norm = 2.8870e-01, time/batch = 0.6993s	
841/11350 (epoch 3.705), train_loss = 2.32302943, grad/param norm = 2.8519e-01, time/batch = 0.6876s	
842/11350 (epoch 3.709), train_loss = 2.43850964, grad/param norm = 3.1274e-01, time/batch = 0.6876s	
843/11350 (epoch 3.714), train_loss = 2.18333998, grad/param norm = 2.9033e-01, time/batch = 0.6871s	
844/11350 (epoch 3.718), train_loss = 2.33577229, grad/param norm = 2.9984e-01, time/batch = 0.6845s	
845/11350 (epoch 3.722), train_loss = 2.31959563, grad/param norm = 3.2720e-01, time/batch = 0.6867s	
846/11350 (epoch 3.727), train_loss = 2.18007373, grad/param norm = 2.9673e-01, time/batch = 0.6838s	
847/11350 (epoch 3.731), train_loss = 2.25819336, grad/param norm = 2.6849e-01, time/batch = 0.6871s	
848/11350 (epoch 3.736), train_loss = 2.29455699, grad/param norm = 2.8145e-01, time/batch = 0.6864s	
849/11350 (epoch 3.740), train_loss = 2.35065982, grad/param norm = 2.9608e-01, time/batch = 0.6847s	
850/11350 (epoch 3.744), train_loss = 2.41226410, grad/param norm = 3.5611e-01, time/batch = 0.6868s	
851/11350 (epoch 3.749), train_loss = 2.35619903, grad/param norm = 3.6358e-01, time/batch = 0.6864s	
852/11350 (epoch 3.753), train_loss = 2.32083579, grad/param norm = 4.7363e-01, time/batch = 0.6873s	
853/11350 (epoch 3.758), train_loss = 2.13459785, grad/param norm = 4.9571e-01, time/batch = 0.6874s	
854/11350 (epoch 3.762), train_loss = 2.19355420, grad/param norm = 3.4325e-01, time/batch = 0.6860s	
855/11350 (epoch 3.767), train_loss = 2.31504121, grad/param norm = 3.1212e-01, time/batch = 0.6851s	
856/11350 (epoch 3.771), train_loss = 2.24132793, grad/param norm = 2.9075e-01, time/batch = 0.6860s	
857/11350 (epoch 3.775), train_loss = 2.19652533, grad/param norm = 2.8854e-01, time/batch = 0.6885s	
858/11350 (epoch 3.780), train_loss = 2.18485799, grad/param norm = 2.8461e-01, time/batch = 0.7033s	
859/11350 (epoch 3.784), train_loss = 2.15289162, grad/param norm = 3.0970e-01, time/batch = 0.7244s	
860/11350 (epoch 3.789), train_loss = 2.18485092, grad/param norm = 3.3265e-01, time/batch = 0.9030s	
861/11350 (epoch 3.793), train_loss = 2.15391604, grad/param norm = 3.4561e-01, time/batch = 1.0505s	
862/11350 (epoch 3.797), train_loss = 2.04893452, grad/param norm = 3.2329e-01, time/batch = 1.0075s	
863/11350 (epoch 3.802), train_loss = 2.23747228, grad/param norm = 3.3070e-01, time/batch = 1.0098s	
864/11350 (epoch 3.806), train_loss = 2.12441953, grad/param norm = 2.8867e-01, time/batch = 1.0073s	
865/11350 (epoch 3.811), train_loss = 2.28821806, grad/param norm = 3.6198e-01, time/batch = 0.7728s	
866/11350 (epoch 3.815), train_loss = 1.97876424, grad/param norm = 4.0167e-01, time/batch = 0.7081s	
867/11350 (epoch 3.819), train_loss = 2.14836696, grad/param norm = 3.1335e-01, time/batch = 0.7331s	
868/11350 (epoch 3.824), train_loss = 2.22049409, grad/param norm = 3.0967e-01, time/batch = 0.7078s	
869/11350 (epoch 3.828), train_loss = 2.17710988, grad/param norm = 3.8801e-01, time/batch = 0.6832s	
870/11350 (epoch 3.833), train_loss = 2.28452705, grad/param norm = 4.3961e-01, time/batch = 0.6875s	
871/11350 (epoch 3.837), train_loss = 2.10290907, grad/param norm = 3.5347e-01, time/batch = 0.6903s	
872/11350 (epoch 3.841), train_loss = 2.39012321, grad/param norm = 3.8179e-01, time/batch = 0.7015s	
873/11350 (epoch 3.846), train_loss = 2.08674816, grad/param norm = 3.6990e-01, time/batch = 0.6861s	
874/11350 (epoch 3.850), train_loss = 2.25964403, grad/param norm = 3.5733e-01, time/batch = 0.6832s	
875/11350 (epoch 3.855), train_loss = 1.94544412, grad/param norm = 3.1490e-01, time/batch = 0.6825s	
876/11350 (epoch 3.859), train_loss = 2.26972181, grad/param norm = 3.6828e-01, time/batch = 0.6894s	
877/11350 (epoch 3.863), train_loss = 1.95728136, grad/param norm = 3.2228e-01, time/batch = 0.7216s	
878/11350 (epoch 3.868), train_loss = 2.16463997, grad/param norm = 2.5132e-01, time/batch = 0.6969s	
879/11350 (epoch 3.872), train_loss = 2.17574574, grad/param norm = 3.0397e-01, time/batch = 0.7046s	
880/11350 (epoch 3.877), train_loss = 2.18974300, grad/param norm = 3.3405e-01, time/batch = 0.7038s	
881/11350 (epoch 3.881), train_loss = 2.41275000, grad/param norm = 3.5410e-01, time/batch = 0.6968s	
882/11350 (epoch 3.885), train_loss = 2.30145516, grad/param norm = 3.1260e-01, time/batch = 0.6838s	
883/11350 (epoch 3.890), train_loss = 2.13897679, grad/param norm = 2.3109e-01, time/batch = 0.6844s	
884/11350 (epoch 3.894), train_loss = 2.16529370, grad/param norm = 2.9687e-01, time/batch = 0.6906s	
885/11350 (epoch 3.899), train_loss = 2.26236208, grad/param norm = 3.0146e-01, time/batch = 0.6871s	
886/11350 (epoch 3.903), train_loss = 2.50441872, grad/param norm = 2.9376e-01, time/batch = 0.7908s	
887/11350 (epoch 3.907), train_loss = 2.36755518, grad/param norm = 3.6663e-01, time/batch = 1.0471s	
888/11350 (epoch 3.912), train_loss = 2.15148072, grad/param norm = 3.1741e-01, time/batch = 1.0083s	
889/11350 (epoch 3.916), train_loss = 2.29239282, grad/param norm = 2.6219e-01, time/batch = 1.0025s	
890/11350 (epoch 3.921), train_loss = 2.16208417, grad/param norm = 3.1705e-01, time/batch = 1.0172s	
891/11350 (epoch 3.925), train_loss = 2.07717961, grad/param norm = 2.6306e-01, time/batch = 1.3945s	
892/11350 (epoch 3.930), train_loss = 2.20468234, grad/param norm = 2.4527e-01, time/batch = 1.9039s	
893/11350 (epoch 3.934), train_loss = 2.34866253, grad/param norm = 3.1109e-01, time/batch = 1.8590s	
894/11350 (epoch 3.938), train_loss = 2.14497652, grad/param norm = 3.0218e-01, time/batch = 16.5567s	
895/11350 (epoch 3.943), train_loss = 2.34100740, grad/param norm = 2.8396e-01, time/batch = 18.4629s	
896/11350 (epoch 3.947), train_loss = 2.31354451, grad/param norm = 3.0473e-01, time/batch = 18.3787s	
897/11350 (epoch 3.952), train_loss = 2.28390168, grad/param norm = 3.0050e-01, time/batch = 19.9522s	
898/11350 (epoch 3.956), train_loss = 2.14751311, grad/param norm = 4.3278e-01, time/batch = 19.0272s	
899/11350 (epoch 3.960), train_loss = 2.33021624, grad/param norm = 5.1126e-01, time/batch = 18.7884s	
900/11350 (epoch 3.965), train_loss = 2.21918245, grad/param norm = 3.3457e-01, time/batch = 19.8728s	
901/11350 (epoch 3.969), train_loss = 2.29931674, grad/param norm = 3.2048e-01, time/batch = 17.0427s	
902/11350 (epoch 3.974), train_loss = 1.98105598, grad/param norm = 2.8942e-01, time/batch = 19.3546s	
903/11350 (epoch 3.978), train_loss = 2.32819839, grad/param norm = 3.2367e-01, time/batch = 18.5996s	
904/11350 (epoch 3.982), train_loss = 1.95264836, grad/param norm = 2.9902e-01, time/batch = 18.7762s	
905/11350 (epoch 3.987), train_loss = 2.12870664, grad/param norm = 2.8754e-01, time/batch = 17.5334s	
906/11350 (epoch 3.991), train_loss = 1.91170182, grad/param norm = 2.6688e-01, time/batch = 19.6303s	
907/11350 (epoch 3.996), train_loss = 2.33039385, grad/param norm = 3.3252e-01, time/batch = 19.2794s	
908/11350 (epoch 4.000), train_loss = 1.89490206, grad/param norm = 2.6593e-01, time/batch = 17.6926s	
909/11350 (epoch 4.004), train_loss = 2.11104381, grad/param norm = 3.1978e-01, time/batch = 20.0334s	
910/11350 (epoch 4.009), train_loss = 2.38685308, grad/param norm = 4.8454e-01, time/batch = 18.5972s	
911/11350 (epoch 4.013), train_loss = 1.68539354, grad/param norm = 4.0897e-01, time/batch = 18.6967s	
912/11350 (epoch 4.018), train_loss = 1.80709760, grad/param norm = 3.2837e-01, time/batch = 19.6334s	
913/11350 (epoch 4.022), train_loss = 1.77070902, grad/param norm = 3.6786e-01, time/batch = 18.6301s	
914/11350 (epoch 4.026), train_loss = 1.97352729, grad/param norm = 2.9657e-01, time/batch = 16.5354s	
915/11350 (epoch 4.031), train_loss = 1.72758344, grad/param norm = 2.6157e-01, time/batch = 19.3675s	
916/11350 (epoch 4.035), train_loss = 1.94138256, grad/param norm = 2.7392e-01, time/batch = 20.0298s	
917/11350 (epoch 4.040), train_loss = 1.93563953, grad/param norm = 3.3141e-01, time/batch = 18.9498s	
918/11350 (epoch 4.044), train_loss = 1.90438612, grad/param norm = 2.5949e-01, time/batch = 20.0325s	
919/11350 (epoch 4.048), train_loss = 1.92030187, grad/param norm = 2.6253e-01, time/batch = 19.4539s	
920/11350 (epoch 4.053), train_loss = 1.83408209, grad/param norm = 2.6651e-01, time/batch = 18.6729s	
921/11350 (epoch 4.057), train_loss = 2.06136059, grad/param norm = 2.9501e-01, time/batch = 19.9318s	
922/11350 (epoch 4.062), train_loss = 1.69600496, grad/param norm = 2.7210e-01, time/batch = 16.8010s	
923/11350 (epoch 4.066), train_loss = 1.76111016, grad/param norm = 3.3366e-01, time/batch = 20.9522s	
924/11350 (epoch 4.070), train_loss = 1.92724360, grad/param norm = 3.5463e-01, time/batch = 16.2537s	
925/11350 (epoch 4.075), train_loss = 1.81690438, grad/param norm = 3.1115e-01, time/batch = 20.1159s	
926/11350 (epoch 4.079), train_loss = 1.92206314, grad/param norm = 2.7334e-01, time/batch = 19.3687s	
927/11350 (epoch 4.084), train_loss = 2.24376212, grad/param norm = 2.7349e-01, time/batch = 18.0277s	
928/11350 (epoch 4.088), train_loss = 2.06322983, grad/param norm = 3.1635e-01, time/batch = 19.0475s	
929/11350 (epoch 4.093), train_loss = 1.78346775, grad/param norm = 2.7977e-01, time/batch = 20.1209s	
930/11350 (epoch 4.097), train_loss = 2.07803955, grad/param norm = 3.1187e-01, time/batch = 18.4623s	
931/11350 (epoch 4.101), train_loss = 1.89242483, grad/param norm = 3.0816e-01, time/batch = 18.5251s	
932/11350 (epoch 4.106), train_loss = 2.11460336, grad/param norm = 3.0925e-01, time/batch = 18.8820s	
933/11350 (epoch 4.110), train_loss = 1.79594950, grad/param norm = 2.5788e-01, time/batch = 18.5406s	
934/11350 (epoch 4.115), train_loss = 1.85669151, grad/param norm = 2.6612e-01, time/batch = 18.7086s	
935/11350 (epoch 4.119), train_loss = 1.98931465, grad/param norm = 2.5017e-01, time/batch = 18.2926s	
936/11350 (epoch 4.123), train_loss = 1.85345300, grad/param norm = 3.2086e-01, time/batch = 18.7796s	
937/11350 (epoch 4.128), train_loss = 1.90107729, grad/param norm = 2.8412e-01, time/batch = 19.6251s	
938/11350 (epoch 4.132), train_loss = 1.97628152, grad/param norm = 3.0710e-01, time/batch = 18.7138s	
939/11350 (epoch 4.137), train_loss = 1.72869331, grad/param norm = 2.6416e-01, time/batch = 20.2807s	
940/11350 (epoch 4.141), train_loss = 1.99118250, grad/param norm = 2.7662e-01, time/batch = 19.5036s	
941/11350 (epoch 4.145), train_loss = 1.87053774, grad/param norm = 2.3724e-01, time/batch = 17.1097s	
942/11350 (epoch 4.150), train_loss = 1.99829838, grad/param norm = 2.6291e-01, time/batch = 18.7775s	
943/11350 (epoch 4.154), train_loss = 2.04204349, grad/param norm = 2.9914e-01, time/batch = 19.6812s	
944/11350 (epoch 4.159), train_loss = 1.89218631, grad/param norm = 2.5503e-01, time/batch = 18.9496s	
945/11350 (epoch 4.163), train_loss = 2.02405522, grad/param norm = 2.7171e-01, time/batch = 20.6289s	
946/11350 (epoch 4.167), train_loss = 2.12518410, grad/param norm = 3.0983e-01, time/batch = 18.5171s	
947/11350 (epoch 4.172), train_loss = 2.25445456, grad/param norm = 2.9994e-01, time/batch = 16.2457s	
948/11350 (epoch 4.176), train_loss = 1.96002804, grad/param norm = 2.8391e-01, time/batch = 19.2852s	
949/11350 (epoch 4.181), train_loss = 2.00999446, grad/param norm = 3.3814e-01, time/batch = 16.7764s	
950/11350 (epoch 4.185), train_loss = 2.07757347, grad/param norm = 2.9286e-01, time/batch = 17.6164s	
951/11350 (epoch 4.189), train_loss = 1.81907366, grad/param norm = 2.9718e-01, time/batch = 17.8002s	
952/11350 (epoch 4.194), train_loss = 1.83053968, grad/param norm = 3.4039e-01, time/batch = 18.2028s	
953/11350 (epoch 4.198), train_loss = 2.02023710, grad/param norm = 3.8694e-01, time/batch = 19.6246s	
954/11350 (epoch 4.203), train_loss = 1.83536567, grad/param norm = 2.9232e-01, time/batch = 19.4672s	
955/11350 (epoch 4.207), train_loss = 1.94839448, grad/param norm = 2.9071e-01, time/batch = 19.7671s	
956/11350 (epoch 4.211), train_loss = 2.06980495, grad/param norm = 2.7230e-01, time/batch = 37.3760s	
957/11350 (epoch 4.216), train_loss = 2.02073688, grad/param norm = 3.6092e-01, time/batch = 19.5476s	
958/11350 (epoch 4.220), train_loss = 1.99849289, grad/param norm = 2.8822e-01, time/batch = 19.1058s	
959/11350 (epoch 4.225), train_loss = 1.88449843, grad/param norm = 2.5473e-01, time/batch = 18.1938s	
960/11350 (epoch 4.229), train_loss = 2.10270855, grad/param norm = 2.9916e-01, time/batch = 17.8613s	
961/11350 (epoch 4.233), train_loss = 1.96346500, grad/param norm = 2.5683e-01, time/batch = 18.9440s	
962/11350 (epoch 4.238), train_loss = 2.26486277, grad/param norm = 3.5562e-01, time/batch = 19.1969s	
963/11350 (epoch 4.242), train_loss = 2.30450423, grad/param norm = 3.3532e-01, time/batch = 16.6106s	
964/11350 (epoch 4.247), train_loss = 1.78903014, grad/param norm = 2.8337e-01, time/batch = 18.0253s	
965/11350 (epoch 4.251), train_loss = 2.05658648, grad/param norm = 2.9686e-01, time/batch = 20.1165s	
966/11350 (epoch 4.256), train_loss = 2.09136660, grad/param norm = 2.8679e-01, time/batch = 18.7766s	
967/11350 (epoch 4.260), train_loss = 2.03226674, grad/param norm = 2.8372e-01, time/batch = 18.9438s	
968/11350 (epoch 4.264), train_loss = 1.85063160, grad/param norm = 2.8623e-01, time/batch = 20.1015s	
969/11350 (epoch 4.269), train_loss = 1.98784994, grad/param norm = 3.2082e-01, time/batch = 20.5330s	
970/11350 (epoch 4.273), train_loss = 2.12168029, grad/param norm = 2.7439e-01, time/batch = 19.0924s	
971/11350 (epoch 4.278), train_loss = 1.83112038, grad/param norm = 2.9380e-01, time/batch = 19.2889s	
972/11350 (epoch 4.282), train_loss = 2.09483370, grad/param norm = 3.4263e-01, time/batch = 17.2990s	
973/11350 (epoch 4.286), train_loss = 2.16288474, grad/param norm = 3.7770e-01, time/batch = 17.9518s	
974/11350 (epoch 4.291), train_loss = 1.87146332, grad/param norm = 3.2717e-01, time/batch = 17.7778s	
975/11350 (epoch 4.295), train_loss = 2.10067548, grad/param norm = 2.7952e-01, time/batch = 19.2099s	
976/11350 (epoch 4.300), train_loss = 1.93950684, grad/param norm = 2.7531e-01, time/batch = 19.6337s	
977/11350 (epoch 4.304), train_loss = 1.86513869, grad/param norm = 2.7630e-01, time/batch = 17.1108s	
978/11350 (epoch 4.308), train_loss = 1.89338471, grad/param norm = 2.8428e-01, time/batch = 19.7927s	
979/11350 (epoch 4.313), train_loss = 1.92984263, grad/param norm = 3.3693e-01, time/batch = 20.1301s	
980/11350 (epoch 4.317), train_loss = 1.68546047, grad/param norm = 2.9992e-01, time/batch = 17.4446s	
981/11350 (epoch 4.322), train_loss = 1.83028927, grad/param norm = 3.1365e-01, time/batch = 20.0439s	
982/11350 (epoch 4.326), train_loss = 1.90957640, grad/param norm = 2.8889e-01, time/batch = 18.5165s	
983/11350 (epoch 4.330), train_loss = 1.72079406, grad/param norm = 2.6909e-01, time/batch = 17.6245s	
984/11350 (epoch 4.335), train_loss = 1.72727040, grad/param norm = 2.9199e-01, time/batch = 16.8635s	
985/11350 (epoch 4.339), train_loss = 1.76809175, grad/param norm = 2.7668e-01, time/batch = 17.8742s	
986/11350 (epoch 4.344), train_loss = 1.91783004, grad/param norm = 3.2905e-01, time/batch = 19.4569s	
987/11350 (epoch 4.348), train_loss = 1.95922632, grad/param norm = 4.3282e-01, time/batch = 19.7728s	
988/11350 (epoch 4.352), train_loss = 1.70185919, grad/param norm = 3.8900e-01, time/batch = 17.7827s	
989/11350 (epoch 4.357), train_loss = 1.93654417, grad/param norm = 2.6317e-01, time/batch = 19.1173s	
990/11350 (epoch 4.361), train_loss = 1.65058245, grad/param norm = 2.8794e-01, time/batch = 18.1840s	
991/11350 (epoch 4.366), train_loss = 2.06334666, grad/param norm = 3.7543e-01, time/batch = 20.5249s	
992/11350 (epoch 4.370), train_loss = 1.89174001, grad/param norm = 3.3248e-01, time/batch = 19.7068s	
993/11350 (epoch 4.374), train_loss = 1.90302714, grad/param norm = 3.0723e-01, time/batch = 16.4120s	
994/11350 (epoch 4.379), train_loss = 2.06409918, grad/param norm = 3.5772e-01, time/batch = 20.2887s	
995/11350 (epoch 4.383), train_loss = 1.81131003, grad/param norm = 3.5381e-01, time/batch = 19.4684s	
996/11350 (epoch 4.388), train_loss = 2.01656449, grad/param norm = 4.2397e-01, time/batch = 19.2691s	
997/11350 (epoch 4.392), train_loss = 2.03708440, grad/param norm = 3.0375e-01, time/batch = 16.9790s	
998/11350 (epoch 4.396), train_loss = 1.96405025, grad/param norm = 2.7488e-01, time/batch = 17.4602s	
999/11350 (epoch 4.401), train_loss = 1.84856557, grad/param norm = 2.7365e-01, time/batch = 18.2041s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch4.41_2.1666.t7	
1000/11350 (epoch 4.405), train_loss = 1.99952739, grad/param norm = 3.5055e-01, time/batch = 18.7211s	
1001/11350 (epoch 4.410), train_loss = 2.44032810, grad/param norm = 1.1281e+00, time/batch = 19.1221s	
1002/11350 (epoch 4.414), train_loss = 1.80344155, grad/param norm = 3.5633e-01, time/batch = 18.7016s	
1003/11350 (epoch 4.419), train_loss = 2.30991532, grad/param norm = 3.5122e-01, time/batch = 18.2181s	
1004/11350 (epoch 4.423), train_loss = 2.23327902, grad/param norm = 2.5735e-01, time/batch = 17.2022s	
1005/11350 (epoch 4.427), train_loss = 2.15872832, grad/param norm = 3.1907e-01, time/batch = 20.0316s	
1006/11350 (epoch 4.432), train_loss = 2.35287932, grad/param norm = 3.9268e-01, time/batch = 18.9459s	
1007/11350 (epoch 4.436), train_loss = 2.14066932, grad/param norm = 2.9411e-01, time/batch = 19.8644s	
1008/11350 (epoch 4.441), train_loss = 2.14007738, grad/param norm = 2.7992e-01, time/batch = 19.0256s	
1009/11350 (epoch 4.445), train_loss = 1.65468716, grad/param norm = 2.5903e-01, time/batch = 18.7036s	
1010/11350 (epoch 4.449), train_loss = 1.88603967, grad/param norm = 3.1336e-01, time/batch = 19.1975s	
1011/11350 (epoch 4.454), train_loss = 2.01626344, grad/param norm = 2.9389e-01, time/batch = 18.3684s	
1012/11350 (epoch 4.458), train_loss = 1.80477075, grad/param norm = 3.2075e-01, time/batch = 18.5928s	
1013/11350 (epoch 4.463), train_loss = 1.90738247, grad/param norm = 2.6178e-01, time/batch = 18.2770s	
1014/11350 (epoch 4.467), train_loss = 2.19814004, grad/param norm = 2.8397e-01, time/batch = 17.7076s	
1015/11350 (epoch 4.471), train_loss = 2.13188478, grad/param norm = 2.8444e-01, time/batch = 19.5379s	
1016/11350 (epoch 4.476), train_loss = 1.99906229, grad/param norm = 2.7914e-01, time/batch = 18.7656s	
1017/11350 (epoch 4.480), train_loss = 2.28527754, grad/param norm = 3.0144e-01, time/batch = 19.2117s	
1018/11350 (epoch 4.485), train_loss = 1.89761336, grad/param norm = 2.6786e-01, time/batch = 19.7018s	
1019/11350 (epoch 4.489), train_loss = 2.15532583, grad/param norm = 2.6377e-01, time/batch = 18.0896s	
1020/11350 (epoch 4.493), train_loss = 2.03419748, grad/param norm = 2.5385e-01, time/batch = 19.6243s	
1021/11350 (epoch 4.498), train_loss = 1.71129320, grad/param norm = 2.5103e-01, time/batch = 19.4520s	
1022/11350 (epoch 4.502), train_loss = 2.08329181, grad/param norm = 2.7733e-01, time/batch = 18.5329s	
1023/11350 (epoch 4.507), train_loss = 1.87023806, grad/param norm = 2.5829e-01, time/batch = 20.0276s	
1024/11350 (epoch 4.511), train_loss = 2.15056979, grad/param norm = 2.8397e-01, time/batch = 19.0318s	
1025/11350 (epoch 4.515), train_loss = 1.91965526, grad/param norm = 3.1982e-01, time/batch = 17.8610s	
1026/11350 (epoch 4.520), train_loss = 2.14937713, grad/param norm = 3.4341e-01, time/batch = 20.1347s	
1027/11350 (epoch 4.524), train_loss = 1.98821996, grad/param norm = 3.2628e-01, time/batch = 17.4431s	
1028/11350 (epoch 4.529), train_loss = 2.13568783, grad/param norm = 2.7731e-01, time/batch = 18.7788s	
1029/11350 (epoch 4.533), train_loss = 2.12915948, grad/param norm = 2.3479e-01, time/batch = 20.7087s	
1030/11350 (epoch 4.537), train_loss = 2.02468412, grad/param norm = 2.5698e-01, time/batch = 19.1113s	
1031/11350 (epoch 4.542), train_loss = 2.18239012, grad/param norm = 2.6481e-01, time/batch = 18.5180s	
1032/11350 (epoch 4.546), train_loss = 2.33980864, grad/param norm = 3.2270e-01, time/batch = 19.7748s	
1033/11350 (epoch 4.551), train_loss = 1.97489700, grad/param norm = 2.9725e-01, time/batch = 18.3846s	
1034/11350 (epoch 4.555), train_loss = 2.12593439, grad/param norm = 3.6237e-01, time/batch = 18.5239s	
1035/11350 (epoch 4.559), train_loss = 1.89140465, grad/param norm = 2.3172e-01, time/batch = 16.6968s	
1036/11350 (epoch 4.564), train_loss = 2.05258680, grad/param norm = 3.0378e-01, time/batch = 18.6884s	
1037/11350 (epoch 4.568), train_loss = 2.12808656, grad/param norm = 3.0228e-01, time/batch = 20.2799s	
1038/11350 (epoch 4.573), train_loss = 2.21459343, grad/param norm = 2.5713e-01, time/batch = 17.0202s	
1039/11350 (epoch 4.577), train_loss = 2.20924161, grad/param norm = 3.0061e-01, time/batch = 20.3047s	
1040/11350 (epoch 4.581), train_loss = 2.06586704, grad/param norm = 3.4970e-01, time/batch = 20.7120s	
1041/11350 (epoch 4.586), train_loss = 2.15893060, grad/param norm = 2.8568e-01, time/batch = 19.1821s	
1042/11350 (epoch 4.590), train_loss = 2.29794426, grad/param norm = 2.8435e-01, time/batch = 20.2031s	
1043/11350 (epoch 4.595), train_loss = 2.21643946, grad/param norm = 2.6097e-01, time/batch = 15.9588s	
1044/11350 (epoch 4.599), train_loss = 2.03952400, grad/param norm = 2.7371e-01, time/batch = 17.7793s	
1045/11350 (epoch 4.604), train_loss = 2.01705184, grad/param norm = 2.5232e-01, time/batch = 17.7936s	
1046/11350 (epoch 4.608), train_loss = 2.26848985, grad/param norm = 3.7478e-01, time/batch = 15.1584s	
1047/11350 (epoch 4.612), train_loss = 1.89208535, grad/param norm = 2.8463e-01, time/batch = 16.1127s	
1048/11350 (epoch 4.617), train_loss = 2.29295340, grad/param norm = 3.3616e-01, time/batch = 17.9425s	
1049/11350 (epoch 4.621), train_loss = 2.09132095, grad/param norm = 3.6906e-01, time/batch = 18.6881s	
1050/11350 (epoch 4.626), train_loss = 2.09532388, grad/param norm = 2.9513e-01, time/batch = 18.7046s	
1051/11350 (epoch 4.630), train_loss = 2.20482874, grad/param norm = 2.7727e-01, time/batch = 17.9506s	
1052/11350 (epoch 4.634), train_loss = 2.22811163, grad/param norm = 2.8942e-01, time/batch = 20.2785s	
1053/11350 (epoch 4.639), train_loss = 2.02432905, grad/param norm = 2.8004e-01, time/batch = 19.7750s	
1054/11350 (epoch 4.643), train_loss = 2.03441559, grad/param norm = 3.0851e-01, time/batch = 18.1974s	
1055/11350 (epoch 4.648), train_loss = 2.09700344, grad/param norm = 3.1583e-01, time/batch = 19.2917s	
1056/11350 (epoch 4.652), train_loss = 2.00019446, grad/param norm = 3.0445e-01, time/batch = 20.2914s	
1057/11350 (epoch 4.656), train_loss = 2.17685967, grad/param norm = 3.2166e-01, time/batch = 17.9419s	
1058/11350 (epoch 4.661), train_loss = 2.14292775, grad/param norm = 2.6019e-01, time/batch = 18.9556s	
1059/11350 (epoch 4.665), train_loss = 2.05938467, grad/param norm = 3.0838e-01, time/batch = 18.4490s	
1060/11350 (epoch 4.670), train_loss = 2.15198170, grad/param norm = 3.1487e-01, time/batch = 17.9495s	
1061/11350 (epoch 4.674), train_loss = 2.09086794, grad/param norm = 3.1661e-01, time/batch = 19.1181s	
1062/11350 (epoch 4.678), train_loss = 2.07177320, grad/param norm = 2.9942e-01, time/batch = 19.6326s	
1063/11350 (epoch 4.683), train_loss = 2.03429017, grad/param norm = 2.9859e-01, time/batch = 18.7762s	
1064/11350 (epoch 4.687), train_loss = 2.06597085, grad/param norm = 2.8643e-01, time/batch = 20.2651s	
1065/11350 (epoch 4.692), train_loss = 2.38957266, grad/param norm = 3.7932e-01, time/batch = 19.2942s	
1066/11350 (epoch 4.696), train_loss = 2.07030447, grad/param norm = 3.4551e-01, time/batch = 18.6984s	
1067/11350 (epoch 4.700), train_loss = 2.19061936, grad/param norm = 2.5765e-01, time/batch = 18.3804s	
1068/11350 (epoch 4.705), train_loss = 2.19808412, grad/param norm = 2.9267e-01, time/batch = 20.6132s	
1069/11350 (epoch 4.709), train_loss = 2.27294834, grad/param norm = 2.7353e-01, time/batch = 18.8751s	
1070/11350 (epoch 4.714), train_loss = 1.99387370, grad/param norm = 2.7253e-01, time/batch = 17.5194s	
1071/11350 (epoch 4.718), train_loss = 2.13945621, grad/param norm = 3.1045e-01, time/batch = 19.1201s	
1072/11350 (epoch 4.722), train_loss = 2.16846401, grad/param norm = 3.3551e-01, time/batch = 20.0342s	
1073/11350 (epoch 4.727), train_loss = 2.05213384, grad/param norm = 2.9723e-01, time/batch = 20.0249s	
1074/11350 (epoch 4.731), train_loss = 2.09694265, grad/param norm = 2.5756e-01, time/batch = 19.0468s	
1075/11350 (epoch 4.736), train_loss = 2.14088313, grad/param norm = 2.5926e-01, time/batch = 18.0096s	
1076/11350 (epoch 4.740), train_loss = 2.13095936, grad/param norm = 2.8724e-01, time/batch = 18.6805s	
1077/11350 (epoch 4.744), train_loss = 2.25427501, grad/param norm = 2.9084e-01, time/batch = 19.6982s	
1078/11350 (epoch 4.749), train_loss = 2.20958691, grad/param norm = 2.9105e-01, time/batch = 20.2825s	
1079/11350 (epoch 4.753), train_loss = 2.17583385, grad/param norm = 4.5811e-01, time/batch = 17.7867s	
1080/11350 (epoch 4.758), train_loss = 1.96209766, grad/param norm = 3.8743e-01, time/batch = 18.9633s	
1081/11350 (epoch 4.762), train_loss = 2.06728550, grad/param norm = 3.1512e-01, time/batch = 19.7915s	
1082/11350 (epoch 4.767), train_loss = 2.14471018, grad/param norm = 2.6102e-01, time/batch = 18.1924s	
1083/11350 (epoch 4.771), train_loss = 2.09113410, grad/param norm = 2.8170e-01, time/batch = 19.7742s	
1084/11350 (epoch 4.775), train_loss = 2.00294888, grad/param norm = 2.9234e-01, time/batch = 19.3740s	
1085/11350 (epoch 4.780), train_loss = 2.05075002, grad/param norm = 2.7312e-01, time/batch = 18.6218s	
1086/11350 (epoch 4.784), train_loss = 1.99158680, grad/param norm = 3.0858e-01, time/batch = 17.9480s	
1087/11350 (epoch 4.789), train_loss = 2.05497865, grad/param norm = 3.2175e-01, time/batch = 18.8845s	
1088/11350 (epoch 4.793), train_loss = 2.02495297, grad/param norm = 3.2484e-01, time/batch = 19.8699s	
1089/11350 (epoch 4.797), train_loss = 1.90844985, grad/param norm = 2.8316e-01, time/batch = 17.9409s	
1090/11350 (epoch 4.802), train_loss = 2.10475572, grad/param norm = 3.2111e-01, time/batch = 18.7144s	
1091/11350 (epoch 4.806), train_loss = 1.99659133, grad/param norm = 3.1636e-01, time/batch = 19.9327s	
1092/11350 (epoch 4.811), train_loss = 2.10106226, grad/param norm = 3.3674e-01, time/batch = 19.2143s	
1093/11350 (epoch 4.815), train_loss = 1.81496020, grad/param norm = 3.3645e-01, time/batch = 16.6822s	
1094/11350 (epoch 4.819), train_loss = 1.99993568, grad/param norm = 2.7529e-01, time/batch = 20.7635s	
1095/11350 (epoch 4.824), train_loss = 2.06475995, grad/param norm = 3.0898e-01, time/batch = 18.0914s	
1096/11350 (epoch 4.828), train_loss = 2.03343698, grad/param norm = 3.7141e-01, time/batch = 19.0459s	
1097/11350 (epoch 4.833), train_loss = 2.15147484, grad/param norm = 4.3414e-01, time/batch = 18.6174s	
1098/11350 (epoch 4.837), train_loss = 1.98231909, grad/param norm = 3.4675e-01, time/batch = 18.4265s	
1099/11350 (epoch 4.841), train_loss = 2.26242036, grad/param norm = 2.9320e-01, time/batch = 19.5434s	
1100/11350 (epoch 4.846), train_loss = 1.92288278, grad/param norm = 3.0039e-01, time/batch = 20.1983s	
1101/11350 (epoch 4.850), train_loss = 2.08499600, grad/param norm = 3.3144e-01, time/batch = 18.6274s	
1102/11350 (epoch 4.855), train_loss = 1.81181035, grad/param norm = 2.9468e-01, time/batch = 20.2754s	
1103/11350 (epoch 4.859), train_loss = 2.10722123, grad/param norm = 3.4740e-01, time/batch = 19.0364s	
1104/11350 (epoch 4.863), train_loss = 1.84931698, grad/param norm = 3.1152e-01, time/batch = 18.3781s	
1105/11350 (epoch 4.868), train_loss = 2.05711219, grad/param norm = 2.5478e-01, time/batch = 20.2055s	
1106/11350 (epoch 4.872), train_loss = 2.03628465, grad/param norm = 2.6378e-01, time/batch = 17.3510s	
1107/11350 (epoch 4.877), train_loss = 2.03282640, grad/param norm = 3.0402e-01, time/batch = 18.2832s	
1108/11350 (epoch 4.881), train_loss = 2.27955964, grad/param norm = 3.1810e-01, time/batch = 16.3488s	
1109/11350 (epoch 4.885), train_loss = 2.18596370, grad/param norm = 2.8437e-01, time/batch = 18.3839s	
1110/11350 (epoch 4.890), train_loss = 2.02251947, grad/param norm = 2.3878e-01, time/batch = 19.7846s	
1111/11350 (epoch 4.894), train_loss = 1.95750729, grad/param norm = 2.8210e-01, time/batch = 17.8580s	
1112/11350 (epoch 4.899), train_loss = 2.09671750, grad/param norm = 2.7711e-01, time/batch = 19.6712s	
1113/11350 (epoch 4.903), train_loss = 2.32101934, grad/param norm = 2.7903e-01, time/batch = 19.3810s	
1114/11350 (epoch 4.907), train_loss = 2.20340662, grad/param norm = 2.5548e-01, time/batch = 18.3606s	
1115/11350 (epoch 4.912), train_loss = 2.01934145, grad/param norm = 2.6242e-01, time/batch = 18.8706s	
1116/11350 (epoch 4.916), train_loss = 2.14437227, grad/param norm = 2.5004e-01, time/batch = 19.7909s	
1117/11350 (epoch 4.921), train_loss = 2.04267144, grad/param norm = 2.9970e-01, time/batch = 17.0438s	
1118/11350 (epoch 4.925), train_loss = 1.92550915, grad/param norm = 2.4583e-01, time/batch = 20.0273s	
1119/11350 (epoch 4.930), train_loss = 2.08679410, grad/param norm = 2.3440e-01, time/batch = 20.0397s	
1120/11350 (epoch 4.934), train_loss = 2.19935198, grad/param norm = 2.8627e-01, time/batch = 18.2656s	
1121/11350 (epoch 4.938), train_loss = 1.98999665, grad/param norm = 2.9635e-01, time/batch = 17.5252s	
1122/11350 (epoch 4.943), train_loss = 2.19754632, grad/param norm = 2.6541e-01, time/batch = 17.9300s	
1123/11350 (epoch 4.947), train_loss = 2.20396807, grad/param norm = 2.9132e-01, time/batch = 18.2987s	
1124/11350 (epoch 4.952), train_loss = 2.13310135, grad/param norm = 2.6824e-01, time/batch = 19.3761s	
1125/11350 (epoch 4.956), train_loss = 1.91644332, grad/param norm = 3.3237e-01, time/batch = 18.2107s	
1126/11350 (epoch 4.960), train_loss = 2.14231052, grad/param norm = 3.2821e-01, time/batch = 18.3707s	
1127/11350 (epoch 4.965), train_loss = 1.99196218, grad/param norm = 3.1324e-01, time/batch = 18.0328s	
1128/11350 (epoch 4.969), train_loss = 2.10496226, grad/param norm = 2.9235e-01, time/batch = 18.9653s	
1129/11350 (epoch 4.974), train_loss = 1.81264589, grad/param norm = 2.7501e-01, time/batch = 18.4398s	
1130/11350 (epoch 4.978), train_loss = 2.14785672, grad/param norm = 2.9994e-01, time/batch = 17.7125s	
1131/11350 (epoch 4.982), train_loss = 1.81596314, grad/param norm = 2.7597e-01, time/batch = 18.7209s	
1132/11350 (epoch 4.987), train_loss = 1.95727782, grad/param norm = 2.6894e-01, time/batch = 20.5413s	
1133/11350 (epoch 4.991), train_loss = 1.77618532, grad/param norm = 2.5743e-01, time/batch = 17.5215s	
1134/11350 (epoch 4.996), train_loss = 2.18992585, grad/param norm = 3.0048e-01, time/batch = 17.0907s	
1135/11350 (epoch 5.000), train_loss = 1.71348874, grad/param norm = 2.4692e-01, time/batch = 20.2888s	
1136/11350 (epoch 5.004), train_loss = 1.96207968, grad/param norm = 2.8920e-01, time/batch = 18.8604s	
1137/11350 (epoch 5.009), train_loss = 2.21047683, grad/param norm = 3.5722e-01, time/batch = 18.7143s	
1138/11350 (epoch 5.013), train_loss = 1.50093497, grad/param norm = 3.2068e-01, time/batch = 18.2994s	
1139/11350 (epoch 5.018), train_loss = 1.61091226, grad/param norm = 2.7936e-01, time/batch = 19.1158s	
1140/11350 (epoch 5.022), train_loss = 1.61884963, grad/param norm = 3.0803e-01, time/batch = 20.1884s	
1141/11350 (epoch 5.026), train_loss = 1.80655116, grad/param norm = 2.7031e-01, time/batch = 20.1328s	
1142/11350 (epoch 5.031), train_loss = 1.57386708, grad/param norm = 2.9229e-01, time/batch = 23.2163s	
1143/11350 (epoch 5.035), train_loss = 1.77417444, grad/param norm = 2.8230e-01, time/batch = 28.6689s	
1144/11350 (epoch 5.040), train_loss = 1.79007342, grad/param norm = 3.2697e-01, time/batch = 19.4535s	
1145/11350 (epoch 5.044), train_loss = 1.75824130, grad/param norm = 2.6340e-01, time/batch = 15.3029s	
1146/11350 (epoch 5.048), train_loss = 1.77112559, grad/param norm = 2.8088e-01, time/batch = 17.3138s	
1147/11350 (epoch 5.053), train_loss = 1.69826121, grad/param norm = 2.5320e-01, time/batch = 18.7116s	
1148/11350 (epoch 5.057), train_loss = 1.94214529, grad/param norm = 2.9072e-01, time/batch = 17.9546s	
1149/11350 (epoch 5.062), train_loss = 1.56081623, grad/param norm = 2.5909e-01, time/batch = 18.3792s	
1150/11350 (epoch 5.066), train_loss = 1.58263446, grad/param norm = 2.6330e-01, time/batch = 19.8874s	
1151/11350 (epoch 5.070), train_loss = 1.74561577, grad/param norm = 2.4809e-01, time/batch = 19.1216s	
1152/11350 (epoch 5.075), train_loss = 1.66524353, grad/param norm = 2.7337e-01, time/batch = 19.1096s	
1153/11350 (epoch 5.079), train_loss = 1.77878148, grad/param norm = 2.5695e-01, time/batch = 18.7048s	
1154/11350 (epoch 5.084), train_loss = 2.09115181, grad/param norm = 2.6007e-01, time/batch = 19.0013s	
1155/11350 (epoch 5.088), train_loss = 1.92923428, grad/param norm = 2.6995e-01, time/batch = 18.0067s	
1156/11350 (epoch 5.093), train_loss = 1.69012064, grad/param norm = 2.6295e-01, time/batch = 18.6406s	
1157/11350 (epoch 5.097), train_loss = 1.89410219, grad/param norm = 3.1696e-01, time/batch = 20.2709s	
1158/11350 (epoch 5.101), train_loss = 1.72370100, grad/param norm = 2.7942e-01, time/batch = 17.3463s	
1159/11350 (epoch 5.106), train_loss = 1.98223131, grad/param norm = 3.0179e-01, time/batch = 20.6163s	
1160/11350 (epoch 5.110), train_loss = 1.67987396, grad/param norm = 2.4979e-01, time/batch = 20.3550s	
1161/11350 (epoch 5.115), train_loss = 1.71437578, grad/param norm = 2.3701e-01, time/batch = 17.5924s	
1162/11350 (epoch 5.119), train_loss = 1.87709028, grad/param norm = 2.3857e-01, time/batch = 19.7816s	
1163/11350 (epoch 5.123), train_loss = 1.71263185, grad/param norm = 2.8793e-01, time/batch = 20.4519s	
1164/11350 (epoch 5.128), train_loss = 1.77130670, grad/param norm = 2.6897e-01, time/batch = 18.7984s	
1165/11350 (epoch 5.132), train_loss = 1.83879955, grad/param norm = 2.8878e-01, time/batch = 18.4407s	
1166/11350 (epoch 5.137), train_loss = 1.61181843, grad/param norm = 2.5279e-01, time/batch = 20.3798s	
1167/11350 (epoch 5.141), train_loss = 1.86904269, grad/param norm = 2.7646e-01, time/batch = 18.3696s	
1168/11350 (epoch 5.145), train_loss = 1.72464827, grad/param norm = 2.3976e-01, time/batch = 19.9546s	
1169/11350 (epoch 5.150), train_loss = 1.89089400, grad/param norm = 2.9549e-01, time/batch = 18.0362s	
1170/11350 (epoch 5.154), train_loss = 1.93897338, grad/param norm = 2.7100e-01, time/batch = 18.2596s	
1171/11350 (epoch 5.159), train_loss = 1.74267915, grad/param norm = 2.5702e-01, time/batch = 20.0410s	
1172/11350 (epoch 5.163), train_loss = 1.90844756, grad/param norm = 2.8288e-01, time/batch = 18.5161s	
1173/11350 (epoch 5.167), train_loss = 2.00396301, grad/param norm = 2.9203e-01, time/batch = 17.9190s	
1174/11350 (epoch 5.172), train_loss = 2.12934977, grad/param norm = 2.7345e-01, time/batch = 20.1298s	
1175/11350 (epoch 5.176), train_loss = 1.84502458, grad/param norm = 2.6536e-01, time/batch = 17.1867s	
1176/11350 (epoch 5.181), train_loss = 1.89526525, grad/param norm = 2.9344e-01, time/batch = 19.0326s	
1177/11350 (epoch 5.185), train_loss = 1.91390450, grad/param norm = 2.6325e-01, time/batch = 19.1149s	
1178/11350 (epoch 5.189), train_loss = 1.71596275, grad/param norm = 3.5823e-01, time/batch = 18.4699s	
1179/11350 (epoch 5.194), train_loss = 1.70701144, grad/param norm = 3.6192e-01, time/batch = 19.7212s	
1180/11350 (epoch 5.198), train_loss = 1.87278350, grad/param norm = 3.5245e-01, time/batch = 17.9431s	
1181/11350 (epoch 5.203), train_loss = 1.64736051, grad/param norm = 2.6755e-01, time/batch = 19.7163s	
1182/11350 (epoch 5.207), train_loss = 1.78895873, grad/param norm = 2.7658e-01, time/batch = 19.2074s	
1183/11350 (epoch 5.211), train_loss = 1.89455843, grad/param norm = 2.4720e-01, time/batch = 18.9461s	
1184/11350 (epoch 5.216), train_loss = 1.88869009, grad/param norm = 3.5100e-01, time/batch = 16.8699s	
1185/11350 (epoch 5.220), train_loss = 1.83554886, grad/param norm = 2.8306e-01, time/batch = 17.0329s	
1186/11350 (epoch 5.225), train_loss = 1.70955905, grad/param norm = 2.4874e-01, time/batch = 17.9354s	
1187/11350 (epoch 5.229), train_loss = 1.94883465, grad/param norm = 2.6445e-01, time/batch = 19.9547s	
1188/11350 (epoch 5.233), train_loss = 1.83824077, grad/param norm = 2.5355e-01, time/batch = 20.2001s	
1189/11350 (epoch 5.238), train_loss = 2.11296480, grad/param norm = 3.1498e-01, time/batch = 18.3680s	
1190/11350 (epoch 5.242), train_loss = 2.16936233, grad/param norm = 2.9447e-01, time/batch = 17.8818s	
1191/11350 (epoch 5.247), train_loss = 1.63220829, grad/param norm = 2.4921e-01, time/batch = 18.8878s	
1192/11350 (epoch 5.251), train_loss = 1.91037682, grad/param norm = 2.6164e-01, time/batch = 17.2745s	
1193/11350 (epoch 5.256), train_loss = 1.94865030, grad/param norm = 2.5172e-01, time/batch = 17.8459s	
1194/11350 (epoch 5.260), train_loss = 1.87311588, grad/param norm = 2.4028e-01, time/batch = 18.6749s	
1195/11350 (epoch 5.264), train_loss = 1.73643356, grad/param norm = 2.6016e-01, time/batch = 20.2170s	
1196/11350 (epoch 5.269), train_loss = 1.83599280, grad/param norm = 2.9410e-01, time/batch = 19.5186s	
1197/11350 (epoch 5.273), train_loss = 2.01061701, grad/param norm = 2.5593e-01, time/batch = 18.0576s	
1198/11350 (epoch 5.278), train_loss = 1.66646665, grad/param norm = 2.4948e-01, time/batch = 20.1357s	
1199/11350 (epoch 5.282), train_loss = 1.93320448, grad/param norm = 2.8580e-01, time/batch = 17.7105s	
1200/11350 (epoch 5.286), train_loss = 2.04409601, grad/param norm = 3.3645e-01, time/batch = 18.7159s	
1201/11350 (epoch 5.291), train_loss = 1.68633120, grad/param norm = 2.8374e-01, time/batch = 17.9634s	
1202/11350 (epoch 5.295), train_loss = 1.94064252, grad/param norm = 2.5079e-01, time/batch = 17.6265s	
1203/11350 (epoch 5.300), train_loss = 1.80244060, grad/param norm = 3.0903e-01, time/batch = 18.1948s	
1204/11350 (epoch 5.304), train_loss = 1.74778775, grad/param norm = 2.6613e-01, time/batch = 18.5365s	
1205/11350 (epoch 5.308), train_loss = 1.74071694, grad/param norm = 2.5784e-01, time/batch = 18.0421s	
1206/11350 (epoch 5.313), train_loss = 1.82397049, grad/param norm = 2.9493e-01, time/batch = 18.0568s	
1207/11350 (epoch 5.317), train_loss = 1.53955252, grad/param norm = 2.6034e-01, time/batch = 18.2873s	
1208/11350 (epoch 5.322), train_loss = 1.69583129, grad/param norm = 2.8136e-01, time/batch = 19.1234s	
1209/11350 (epoch 5.326), train_loss = 1.77557809, grad/param norm = 2.5322e-01, time/batch = 18.6950s	
1210/11350 (epoch 5.330), train_loss = 1.55615307, grad/param norm = 2.6079e-01, time/batch = 18.0379s	
1211/11350 (epoch 5.335), train_loss = 1.60076332, grad/param norm = 2.7947e-01, time/batch = 18.3607s	
1212/11350 (epoch 5.339), train_loss = 1.62729465, grad/param norm = 2.5908e-01, time/batch = 17.6659s	
1213/11350 (epoch 5.344), train_loss = 1.79135248, grad/param norm = 2.9150e-01, time/batch = 18.9624s	
1214/11350 (epoch 5.348), train_loss = 1.80506732, grad/param norm = 3.2456e-01, time/batch = 20.1972s	
1215/11350 (epoch 5.352), train_loss = 1.57474218, grad/param norm = 2.9936e-01, time/batch = 19.2876s	
1216/11350 (epoch 5.357), train_loss = 1.78014446, grad/param norm = 2.5460e-01, time/batch = 18.3538s	
1217/11350 (epoch 5.361), train_loss = 1.52217936, grad/param norm = 2.7834e-01, time/batch = 16.7081s	
1218/11350 (epoch 5.366), train_loss = 1.92212684, grad/param norm = 3.0438e-01, time/batch = 18.9627s	
1219/11350 (epoch 5.370), train_loss = 1.77220009, grad/param norm = 2.6565e-01, time/batch = 19.6151s	
1220/11350 (epoch 5.374), train_loss = 1.76597465, grad/param norm = 2.3825e-01, time/batch = 19.5217s	
1221/11350 (epoch 5.379), train_loss = 1.91558312, grad/param norm = 4.0427e-01, time/batch = 19.3514s	
1222/11350 (epoch 5.383), train_loss = 1.69513491, grad/param norm = 4.1969e-01, time/batch = 18.5292s	
1223/11350 (epoch 5.388), train_loss = 1.89552362, grad/param norm = 2.7723e-01, time/batch = 19.2998s	
1224/11350 (epoch 5.392), train_loss = 1.89256608, grad/param norm = 3.0001e-01, time/batch = 19.4393s	
1225/11350 (epoch 5.396), train_loss = 1.87230271, grad/param norm = 3.2900e-01, time/batch = 18.5483s	
1226/11350 (epoch 5.401), train_loss = 1.73586545, grad/param norm = 2.7945e-01, time/batch = 18.6179s	
1227/11350 (epoch 5.405), train_loss = 1.87845464, grad/param norm = 2.3951e-01, time/batch = 20.0455s	
1228/11350 (epoch 5.410), train_loss = 2.15915080, grad/param norm = 2.8213e-01, time/batch = 18.0982s	
1229/11350 (epoch 5.414), train_loss = 1.65471956, grad/param norm = 2.6334e-01, time/batch = 16.2063s	
1230/11350 (epoch 5.419), train_loss = 2.10304319, grad/param norm = 3.6735e-01, time/batch = 20.2872s	
1231/11350 (epoch 5.423), train_loss = 2.10440167, grad/param norm = 2.8486e-01, time/batch = 18.2112s	
1232/11350 (epoch 5.427), train_loss = 2.05535842, grad/param norm = 3.1701e-01, time/batch = 18.9515s	
1233/11350 (epoch 5.432), train_loss = 2.19173953, grad/param norm = 3.7370e-01, time/batch = 18.7087s	
1234/11350 (epoch 5.436), train_loss = 1.96927605, grad/param norm = 2.9502e-01, time/batch = 18.6025s	
1235/11350 (epoch 5.441), train_loss = 2.01926547, grad/param norm = 2.8799e-01, time/batch = 19.2850s	
1236/11350 (epoch 5.445), train_loss = 1.51232307, grad/param norm = 2.4143e-01, time/batch = 19.2008s	
1237/11350 (epoch 5.449), train_loss = 1.75757994, grad/param norm = 3.0524e-01, time/batch = 18.1937s	
1238/11350 (epoch 5.454), train_loss = 1.92910525, grad/param norm = 2.7784e-01, time/batch = 18.1837s	
1239/11350 (epoch 5.458), train_loss = 1.63778239, grad/param norm = 2.5896e-01, time/batch = 17.3803s	
1240/11350 (epoch 5.463), train_loss = 1.75060458, grad/param norm = 2.6225e-01, time/batch = 19.0467s	
1241/11350 (epoch 5.467), train_loss = 2.10496070, grad/param norm = 2.8141e-01, time/batch = 17.6122s	
1242/11350 (epoch 5.471), train_loss = 2.02037768, grad/param norm = 2.7659e-01, time/batch = 18.3619s	
1243/11350 (epoch 5.476), train_loss = 1.90401930, grad/param norm = 2.9682e-01, time/batch = 19.9427s	
1244/11350 (epoch 5.480), train_loss = 2.13899744, grad/param norm = 2.9871e-01, time/batch = 19.1130s	
1245/11350 (epoch 5.485), train_loss = 1.75280643, grad/param norm = 2.6301e-01, time/batch = 18.8600s	
1246/11350 (epoch 5.489), train_loss = 2.01497203, grad/param norm = 2.5761e-01, time/batch = 18.4643s	
1247/11350 (epoch 5.493), train_loss = 1.90777536, grad/param norm = 2.6980e-01, time/batch = 16.0152s	
1248/11350 (epoch 5.498), train_loss = 1.56551002, grad/param norm = 2.7366e-01, time/batch = 18.6375s	
1249/11350 (epoch 5.502), train_loss = 1.92634536, grad/param norm = 2.7404e-01, time/batch = 15.6580s	
1250/11350 (epoch 5.507), train_loss = 1.71739828, grad/param norm = 2.5952e-01, time/batch = 19.2507s	
1251/11350 (epoch 5.511), train_loss = 2.08304697, grad/param norm = 2.7539e-01, time/batch = 20.0374s	
1252/11350 (epoch 5.515), train_loss = 1.78096895, grad/param norm = 3.1867e-01, time/batch = 17.2805s	
1253/11350 (epoch 5.520), train_loss = 2.02729357, grad/param norm = 3.0125e-01, time/batch = 19.3719s	
1254/11350 (epoch 5.524), train_loss = 1.82289885, grad/param norm = 2.9274e-01, time/batch = 18.6855s	
1255/11350 (epoch 5.529), train_loss = 1.97588482, grad/param norm = 2.5480e-01, time/batch = 19.2989s	
1256/11350 (epoch 5.533), train_loss = 2.01506851, grad/param norm = 2.5279e-01, time/batch = 19.4636s	
1257/11350 (epoch 5.537), train_loss = 1.89473623, grad/param norm = 2.4704e-01, time/batch = 19.0215s	
1258/11350 (epoch 5.542), train_loss = 2.02827511, grad/param norm = 2.7494e-01, time/batch = 18.5408s	
1259/11350 (epoch 5.546), train_loss = 2.18558268, grad/param norm = 3.1134e-01, time/batch = 19.8631s	
1260/11350 (epoch 5.551), train_loss = 1.80125650, grad/param norm = 2.8505e-01, time/batch = 18.7810s	
1261/11350 (epoch 5.555), train_loss = 1.93684344, grad/param norm = 3.1992e-01, time/batch = 20.0366s	
1262/11350 (epoch 5.559), train_loss = 1.76372086, grad/param norm = 2.1356e-01, time/batch = 19.3720s	
1263/11350 (epoch 5.564), train_loss = 1.94773744, grad/param norm = 2.6775e-01, time/batch = 17.5234s	
1264/11350 (epoch 5.568), train_loss = 1.96714289, grad/param norm = 2.7254e-01, time/batch = 20.0434s	
1265/11350 (epoch 5.573), train_loss = 2.09988307, grad/param norm = 2.4953e-01, time/batch = 17.8351s	
1266/11350 (epoch 5.577), train_loss = 2.08523280, grad/param norm = 2.6893e-01, time/batch = 16.3423s	
1267/11350 (epoch 5.581), train_loss = 1.93928265, grad/param norm = 3.2487e-01, time/batch = 19.1906s	
1268/11350 (epoch 5.586), train_loss = 2.03009515, grad/param norm = 2.6055e-01, time/batch = 20.6927s	
1269/11350 (epoch 5.590), train_loss = 2.16082640, grad/param norm = 2.8152e-01, time/batch = 18.3681s	
1270/11350 (epoch 5.595), train_loss = 2.09283005, grad/param norm = 2.7065e-01, time/batch = 19.1911s	
1271/11350 (epoch 5.599), train_loss = 1.93482375, grad/param norm = 2.6732e-01, time/batch = 18.2103s	
1272/11350 (epoch 5.604), train_loss = 1.85788265, grad/param norm = 2.5472e-01, time/batch = 18.8646s	
1273/11350 (epoch 5.608), train_loss = 2.10161866, grad/param norm = 3.5192e-01, time/batch = 19.6831s	
1274/11350 (epoch 5.612), train_loss = 1.77233517, grad/param norm = 2.7877e-01, time/batch = 19.2776s	
1275/11350 (epoch 5.617), train_loss = 2.15918866, grad/param norm = 3.2989e-01, time/batch = 19.5340s	
1276/11350 (epoch 5.621), train_loss = 1.97902665, grad/param norm = 3.1327e-01, time/batch = 19.1029s	
1277/11350 (epoch 5.626), train_loss = 1.96266746, grad/param norm = 2.6770e-01, time/batch = 19.6191s	
1278/11350 (epoch 5.630), train_loss = 2.06951465, grad/param norm = 2.7948e-01, time/batch = 19.3709s	
1279/11350 (epoch 5.634), train_loss = 2.09143699, grad/param norm = 2.4942e-01, time/batch = 18.8588s	
1280/11350 (epoch 5.639), train_loss = 1.89212700, grad/param norm = 2.4493e-01, time/batch = 18.2084s	
1281/11350 (epoch 5.643), train_loss = 1.90362152, grad/param norm = 2.8008e-01, time/batch = 18.7810s	
1282/11350 (epoch 5.648), train_loss = 1.96593759, grad/param norm = 3.0047e-01, time/batch = 19.0332s	
1283/11350 (epoch 5.652), train_loss = 1.90383584, grad/param norm = 3.2110e-01, time/batch = 18.9480s	
1284/11350 (epoch 5.656), train_loss = 2.06995532, grad/param norm = 3.3272e-01, time/batch = 20.5376s	
1285/11350 (epoch 5.661), train_loss = 2.02198490, grad/param norm = 2.6341e-01, time/batch = 17.6770s	
1286/11350 (epoch 5.665), train_loss = 1.91659278, grad/param norm = 2.7753e-01, time/batch = 17.3590s	
1287/11350 (epoch 5.670), train_loss = 1.99376611, grad/param norm = 2.9574e-01, time/batch = 18.2709s	
1288/11350 (epoch 5.674), train_loss = 1.93739556, grad/param norm = 2.7457e-01, time/batch = 18.7782s	
1289/11350 (epoch 5.678), train_loss = 1.94490465, grad/param norm = 2.6673e-01, time/batch = 17.2788s	
1290/11350 (epoch 5.683), train_loss = 1.89623027, grad/param norm = 2.6702e-01, time/batch = 19.1162s	
1291/11350 (epoch 5.687), train_loss = 1.92426525, grad/param norm = 2.9117e-01, time/batch = 19.5247s	
1292/11350 (epoch 5.692), train_loss = 2.27856752, grad/param norm = 4.0412e-01, time/batch = 18.2839s	
1293/11350 (epoch 5.696), train_loss = 1.96343403, grad/param norm = 3.2435e-01, time/batch = 19.4716s	
1294/11350 (epoch 5.700), train_loss = 2.04412283, grad/param norm = 2.4212e-01, time/batch = 19.2758s	
1295/11350 (epoch 5.705), train_loss = 2.09093355, grad/param norm = 2.7412e-01, time/batch = 19.1591s	
1296/11350 (epoch 5.709), train_loss = 2.13574923, grad/param norm = 2.5769e-01, time/batch = 19.2060s	
1297/11350 (epoch 5.714), train_loss = 1.84238455, grad/param norm = 2.6536e-01, time/batch = 15.4456s	
1298/11350 (epoch 5.718), train_loss = 1.97069999, grad/param norm = 3.1117e-01, time/batch = 16.9672s	
1299/11350 (epoch 5.722), train_loss = 2.04795323, grad/param norm = 3.2206e-01, time/batch = 18.6162s	
1300/11350 (epoch 5.727), train_loss = 1.90570776, grad/param norm = 2.7180e-01, time/batch = 17.0517s	
1301/11350 (epoch 5.731), train_loss = 1.96121405, grad/param norm = 2.4916e-01, time/batch = 16.4338s	
1302/11350 (epoch 5.736), train_loss = 1.98923906, grad/param norm = 2.5131e-01, time/batch = 18.7884s	
1303/11350 (epoch 5.740), train_loss = 1.97360897, grad/param norm = 2.8160e-01, time/batch = 18.1145s	
1304/11350 (epoch 5.744), train_loss = 2.13089268, grad/param norm = 2.7865e-01, time/batch = 17.8641s	
1305/11350 (epoch 5.749), train_loss = 2.08179542, grad/param norm = 2.6322e-01, time/batch = 19.1814s	
1306/11350 (epoch 5.753), train_loss = 2.04252903, grad/param norm = 3.1450e-01, time/batch = 19.7180s	
1307/11350 (epoch 5.758), train_loss = 1.83741644, grad/param norm = 2.8124e-01, time/batch = 19.6356s	
1308/11350 (epoch 5.762), train_loss = 1.95664202, grad/param norm = 3.2028e-01, time/batch = 16.6748s	
1309/11350 (epoch 5.767), train_loss = 1.99865092, grad/param norm = 2.2862e-01, time/batch = 19.7064s	
1310/11350 (epoch 5.771), train_loss = 1.97962228, grad/param norm = 2.6862e-01, time/batch = 17.8415s	
1311/11350 (epoch 5.775), train_loss = 1.85788459, grad/param norm = 2.6429e-01, time/batch = 17.7663s	
1312/11350 (epoch 5.780), train_loss = 1.94521539, grad/param norm = 2.5549e-01, time/batch = 17.8560s	
1313/11350 (epoch 5.784), train_loss = 1.85372995, grad/param norm = 2.8643e-01, time/batch = 19.3483s	
1314/11350 (epoch 5.789), train_loss = 1.93823207, grad/param norm = 3.0981e-01, time/batch = 19.0266s	
1315/11350 (epoch 5.793), train_loss = 1.90833058, grad/param norm = 2.9339e-01, time/batch = 18.3700s	
1316/11350 (epoch 5.797), train_loss = 1.80057215, grad/param norm = 2.4869e-01, time/batch = 20.5351s	
1317/11350 (epoch 5.802), train_loss = 1.98351300, grad/param norm = 2.6393e-01, time/batch = 18.4423s	
1318/11350 (epoch 5.806), train_loss = 1.88026023, grad/param norm = 2.6855e-01, time/batch = 16.5500s	
1319/11350 (epoch 5.811), train_loss = 1.91375822, grad/param norm = 2.8808e-01, time/batch = 18.8800s	
1320/11350 (epoch 5.815), train_loss = 1.68214275, grad/param norm = 2.7855e-01, time/batch = 19.7115s	
1321/11350 (epoch 5.819), train_loss = 1.86483022, grad/param norm = 2.5250e-01, time/batch = 18.4459s	
1322/11350 (epoch 5.824), train_loss = 1.93028649, grad/param norm = 2.9693e-01, time/batch = 18.2626s	
1323/11350 (epoch 5.828), train_loss = 1.91006460, grad/param norm = 3.5085e-01, time/batch = 19.0466s	
1324/11350 (epoch 5.833), train_loss = 2.02877563, grad/param norm = 4.1840e-01, time/batch = 17.0500s	
1325/11350 (epoch 5.837), train_loss = 1.88199834, grad/param norm = 3.5725e-01, time/batch = 18.8019s	
1326/11350 (epoch 5.841), train_loss = 2.17227733, grad/param norm = 2.8378e-01, time/batch = 19.3882s	
1327/11350 (epoch 5.846), train_loss = 1.79846478, grad/param norm = 2.8475e-01, time/batch = 18.2856s	
1328/11350 (epoch 5.850), train_loss = 1.96730386, grad/param norm = 2.9747e-01, time/batch = 18.0428s	
1329/11350 (epoch 5.855), train_loss = 1.69909923, grad/param norm = 2.8037e-01, time/batch = 17.6242s	
1330/11350 (epoch 5.859), train_loss = 1.96438599, grad/param norm = 3.2618e-01, time/batch = 18.5397s	
1331/11350 (epoch 5.863), train_loss = 1.75159637, grad/param norm = 3.0949e-01, time/batch = 16.1970s	
1332/11350 (epoch 5.868), train_loss = 1.94854771, grad/param norm = 2.6511e-01, time/batch = 18.8777s	
1333/11350 (epoch 5.872), train_loss = 1.91213464, grad/param norm = 2.7440e-01, time/batch = 19.0336s	
1334/11350 (epoch 5.877), train_loss = 1.89814494, grad/param norm = 2.9654e-01, time/batch = 34.6085s	
1335/11350 (epoch 5.881), train_loss = 2.17429778, grad/param norm = 3.0713e-01, time/batch = 18.0403s	
1336/11350 (epoch 5.885), train_loss = 2.07997536, grad/param norm = 2.7073e-01, time/batch = 18.3661s	
1337/11350 (epoch 5.890), train_loss = 1.92337418, grad/param norm = 2.3017e-01, time/batch = 17.9482s	
1338/11350 (epoch 5.894), train_loss = 1.79930316, grad/param norm = 2.5346e-01, time/batch = 19.5466s	
1339/11350 (epoch 5.899), train_loss = 1.96719324, grad/param norm = 2.5116e-01, time/batch = 18.7886s	
1340/11350 (epoch 5.903), train_loss = 2.16606294, grad/param norm = 2.6350e-01, time/batch = 19.0353s	
1341/11350 (epoch 5.907), train_loss = 2.07252416, grad/param norm = 2.4290e-01, time/batch = 20.0211s	
1342/11350 (epoch 5.912), train_loss = 1.90323262, grad/param norm = 2.7584e-01, time/batch = 18.5287s	
1343/11350 (epoch 5.916), train_loss = 2.03308480, grad/param norm = 2.5683e-01, time/batch = 16.8097s	
1344/11350 (epoch 5.921), train_loss = 1.93947277, grad/param norm = 2.8116e-01, time/batch = 15.4560s	
1345/11350 (epoch 5.925), train_loss = 1.78777533, grad/param norm = 2.4698e-01, time/batch = 15.3878s	
1346/11350 (epoch 5.930), train_loss = 1.97879425, grad/param norm = 2.4053e-01, time/batch = 16.1217s	
1347/11350 (epoch 5.934), train_loss = 2.07920304, grad/param norm = 2.9422e-01, time/batch = 20.6940s	
1348/11350 (epoch 5.938), train_loss = 1.88109102, grad/param norm = 3.0764e-01, time/batch = 19.7260s	
1349/11350 (epoch 5.943), train_loss = 2.06706200, grad/param norm = 2.6492e-01, time/batch = 17.9496s	
1350/11350 (epoch 5.947), train_loss = 2.09961924, grad/param norm = 2.8401e-01, time/batch = 20.1843s	
1351/11350 (epoch 5.952), train_loss = 2.01990110, grad/param norm = 2.6099e-01, time/batch = 15.7619s	
1352/11350 (epoch 5.956), train_loss = 1.76096344, grad/param norm = 3.0789e-01, time/batch = 18.7849s	
1353/11350 (epoch 5.960), train_loss = 2.01790368, grad/param norm = 3.0590e-01, time/batch = 18.7723s	
1354/11350 (epoch 5.965), train_loss = 1.84216366, grad/param norm = 3.3162e-01, time/batch = 18.8801s	
1355/11350 (epoch 5.969), train_loss = 1.96386216, grad/param norm = 2.9526e-01, time/batch = 18.4498s	
1356/11350 (epoch 5.974), train_loss = 1.70808697, grad/param norm = 2.6092e-01, time/batch = 16.4597s	
1357/11350 (epoch 5.978), train_loss = 1.99890713, grad/param norm = 2.9781e-01, time/batch = 19.8542s	
1358/11350 (epoch 5.982), train_loss = 1.69512237, grad/param norm = 2.5306e-01, time/batch = 18.6983s	
1359/11350 (epoch 5.987), train_loss = 1.82953684, grad/param norm = 2.6804e-01, time/batch = 18.1965s	
1360/11350 (epoch 5.991), train_loss = 1.67535477, grad/param norm = 2.6088e-01, time/batch = 18.2126s	
1361/11350 (epoch 5.996), train_loss = 2.04986194, grad/param norm = 3.0150e-01, time/batch = 17.8651s	
1362/11350 (epoch 6.000), train_loss = 1.59211236, grad/param norm = 2.6698e-01, time/batch = 18.4444s	
1363/11350 (epoch 6.004), train_loss = 1.85316014, grad/param norm = 3.6395e-01, time/batch = 19.1278s	
1364/11350 (epoch 6.009), train_loss = 2.12556959, grad/param norm = 5.6624e-01, time/batch = 20.0344s	
1365/11350 (epoch 6.013), train_loss = 1.40302699, grad/param norm = 3.0422e-01, time/batch = 19.1100s	
1366/11350 (epoch 6.018), train_loss = 1.48414811, grad/param norm = 2.6256e-01, time/batch = 18.6225s	
1367/11350 (epoch 6.022), train_loss = 1.52752692, grad/param norm = 3.2303e-01, time/batch = 19.0279s	
1368/11350 (epoch 6.026), train_loss = 1.68191710, grad/param norm = 2.5806e-01, time/batch = 19.7883s	
1369/11350 (epoch 6.031), train_loss = 1.45204842, grad/param norm = 2.6260e-01, time/batch = 18.7056s	
1370/11350 (epoch 6.035), train_loss = 1.64104671, grad/param norm = 2.6292e-01, time/batch = 18.7866s	
1371/11350 (epoch 6.040), train_loss = 1.67925929, grad/param norm = 3.0307e-01, time/batch = 19.8498s	
1372/11350 (epoch 6.044), train_loss = 1.63370449, grad/param norm = 2.3824e-01, time/batch = 17.9526s	
1373/11350 (epoch 6.048), train_loss = 1.65028750, grad/param norm = 2.5788e-01, time/batch = 16.8458s	
1374/11350 (epoch 6.053), train_loss = 1.60303338, grad/param norm = 2.4956e-01, time/batch = 20.1102s	
1375/11350 (epoch 6.057), train_loss = 1.83924730, grad/param norm = 2.7206e-01, time/batch = 19.3617s	
1376/11350 (epoch 6.062), train_loss = 1.46577579, grad/param norm = 2.4806e-01, time/batch = 16.3808s	
1377/11350 (epoch 6.066), train_loss = 1.46947120, grad/param norm = 2.4482e-01, time/batch = 18.5382s	
1378/11350 (epoch 6.070), train_loss = 1.62442999, grad/param norm = 2.3033e-01, time/batch = 19.0193s	
1379/11350 (epoch 6.075), train_loss = 1.54743500, grad/param norm = 2.4952e-01, time/batch = 16.6456s	
1380/11350 (epoch 6.079), train_loss = 1.66816254, grad/param norm = 2.5387e-01, time/batch = 20.5358s	
1381/11350 (epoch 6.084), train_loss = 1.96485257, grad/param norm = 2.5868e-01, time/batch = 17.0020s	
1382/11350 (epoch 6.088), train_loss = 1.82111271, grad/param norm = 2.5652e-01, time/batch = 19.2657s	
1383/11350 (epoch 6.093), train_loss = 1.62386196, grad/param norm = 2.4907e-01, time/batch = 17.1182s	
1384/11350 (epoch 6.097), train_loss = 1.75258447, grad/param norm = 2.6555e-01, time/batch = 19.1193s	
1385/11350 (epoch 6.101), train_loss = 1.58355451, grad/param norm = 2.5687e-01, time/batch = 20.1117s	
1386/11350 (epoch 6.106), train_loss = 1.87618497, grad/param norm = 2.8771e-01, time/batch = 18.1961s	
1387/11350 (epoch 6.110), train_loss = 1.59465260, grad/param norm = 2.4139e-01, time/batch = 19.9433s	
1388/11350 (epoch 6.115), train_loss = 1.60000884, grad/param norm = 2.3208e-01, time/batch = 18.5348s	
1389/11350 (epoch 6.119), train_loss = 1.79501569, grad/param norm = 2.5107e-01, time/batch = 16.6849s	
1390/11350 (epoch 6.123), train_loss = 1.60278631, grad/param norm = 2.7506e-01, time/batch = 19.0302s	
1391/11350 (epoch 6.128), train_loss = 1.66736000, grad/param norm = 2.6197e-01, time/batch = 18.3610s	
1392/11350 (epoch 6.132), train_loss = 1.72000536, grad/param norm = 2.4571e-01, time/batch = 18.6172s	
1393/11350 (epoch 6.137), train_loss = 1.52128342, grad/param norm = 2.4131e-01, time/batch = 18.1826s	
1394/11350 (epoch 6.141), train_loss = 1.77371234, grad/param norm = 2.7212e-01, time/batch = 18.7828s	
1395/11350 (epoch 6.145), train_loss = 1.61066210, grad/param norm = 2.3248e-01, time/batch = 20.0220s	
1396/11350 (epoch 6.150), train_loss = 1.80162753, grad/param norm = 2.7990e-01, time/batch = 18.8743s	
1397/11350 (epoch 6.154), train_loss = 1.85309824, grad/param norm = 2.5840e-01, time/batch = 18.2042s	
1398/11350 (epoch 6.159), train_loss = 1.62060342, grad/param norm = 2.4754e-01, time/batch = 19.9546s	
1399/11350 (epoch 6.163), train_loss = 1.81598416, grad/param norm = 2.4881e-01, time/batch = 18.7052s	
1400/11350 (epoch 6.167), train_loss = 1.87860626, grad/param norm = 2.5879e-01, time/batch = 19.0391s	
1401/11350 (epoch 6.172), train_loss = 2.03000867, grad/param norm = 2.7757e-01, time/batch = 19.4482s	
1402/11350 (epoch 6.176), train_loss = 1.75187204, grad/param norm = 2.8423e-01, time/batch = 19.4466s	
1403/11350 (epoch 6.181), train_loss = 1.78765022, grad/param norm = 2.8166e-01, time/batch = 19.3553s	
1404/11350 (epoch 6.185), train_loss = 1.77704286, grad/param norm = 2.6826e-01, time/batch = 19.8657s	
1405/11350 (epoch 6.189), train_loss = 1.63006984, grad/param norm = 3.5722e-01, time/batch = 19.1240s	
1406/11350 (epoch 6.194), train_loss = 1.58764517, grad/param norm = 3.0470e-01, time/batch = 20.2006s	
1407/11350 (epoch 6.198), train_loss = 1.72967202, grad/param norm = 2.9875e-01, time/batch = 16.7802s	
1408/11350 (epoch 6.203), train_loss = 1.50963554, grad/param norm = 2.5022e-01, time/batch = 17.8713s	
1409/11350 (epoch 6.207), train_loss = 1.67038159, grad/param norm = 2.8162e-01, time/batch = 18.7872s	
1410/11350 (epoch 6.211), train_loss = 1.77123968, grad/param norm = 2.5635e-01, time/batch = 17.2919s	
1411/11350 (epoch 6.216), train_loss = 1.76173233, grad/param norm = 2.7998e-01, time/batch = 18.9487s	
1412/11350 (epoch 6.220), train_loss = 1.71370103, grad/param norm = 2.5161e-01, time/batch = 19.7014s	
1413/11350 (epoch 6.225), train_loss = 1.57980711, grad/param norm = 2.4722e-01, time/batch = 17.0780s	
1414/11350 (epoch 6.229), train_loss = 1.82568008, grad/param norm = 2.4245e-01, time/batch = 19.9177s	
1415/11350 (epoch 6.233), train_loss = 1.74706969, grad/param norm = 2.8085e-01, time/batch = 18.8559s	
1416/11350 (epoch 6.238), train_loss = 2.00555367, grad/param norm = 3.4183e-01, time/batch = 18.8739s	
1417/11350 (epoch 6.242), train_loss = 2.05981401, grad/param norm = 2.9962e-01, time/batch = 19.5353s	
1418/11350 (epoch 6.247), train_loss = 1.51371902, grad/param norm = 2.3110e-01, time/batch = 18.3794s	
1419/11350 (epoch 6.251), train_loss = 1.79506698, grad/param norm = 2.4728e-01, time/batch = 19.2876s	
1420/11350 (epoch 6.256), train_loss = 1.86137201, grad/param norm = 2.5754e-01, time/batch = 17.3426s	
1421/11350 (epoch 6.260), train_loss = 1.74688947, grad/param norm = 2.4854e-01, time/batch = 18.4553s	
1422/11350 (epoch 6.264), train_loss = 1.63991852, grad/param norm = 2.5233e-01, time/batch = 19.9545s	
1423/11350 (epoch 6.269), train_loss = 1.72471938, grad/param norm = 2.8386e-01, time/batch = 19.8604s	
1424/11350 (epoch 6.273), train_loss = 1.90810623, grad/param norm = 2.6773e-01, time/batch = 19.2083s	
1425/11350 (epoch 6.278), train_loss = 1.54594595, grad/param norm = 2.4268e-01, time/batch = 17.3326s	
1426/11350 (epoch 6.282), train_loss = 1.81970744, grad/param norm = 2.7914e-01, time/batch = 18.9321s	
1427/11350 (epoch 6.286), train_loss = 1.94996707, grad/param norm = 3.3081e-01, time/batch = 19.8778s	
1428/11350 (epoch 6.291), train_loss = 1.55408891, grad/param norm = 2.8000e-01, time/batch = 19.5377s	
1429/11350 (epoch 6.295), train_loss = 1.81399829, grad/param norm = 2.5783e-01, time/batch = 12.5597s	
1430/11350 (epoch 6.300), train_loss = 1.70111622, grad/param norm = 2.7472e-01, time/batch = 0.6865s	
1431/11350 (epoch 6.304), train_loss = 1.63606366, grad/param norm = 2.3622e-01, time/batch = 0.6936s	
1432/11350 (epoch 6.308), train_loss = 1.62355574, grad/param norm = 2.4357e-01, time/batch = 0.7218s	
1433/11350 (epoch 6.313), train_loss = 1.74389407, grad/param norm = 2.7758e-01, time/batch = 0.6872s	
1434/11350 (epoch 6.317), train_loss = 1.44464291, grad/param norm = 2.3746e-01, time/batch = 0.6850s	
1435/11350 (epoch 6.322), train_loss = 1.58608211, grad/param norm = 2.6400e-01, time/batch = 0.6838s	
1436/11350 (epoch 6.326), train_loss = 1.67749481, grad/param norm = 2.5859e-01, time/batch = 0.7390s	
1437/11350 (epoch 6.330), train_loss = 1.44947761, grad/param norm = 2.7511e-01, time/batch = 1.0174s	
1438/11350 (epoch 6.335), train_loss = 1.49283145, grad/param norm = 2.7884e-01, time/batch = 1.0078s	
1439/11350 (epoch 6.339), train_loss = 1.53025091, grad/param norm = 2.5970e-01, time/batch = 0.9997s	
1440/11350 (epoch 6.344), train_loss = 1.67643776, grad/param norm = 2.6461e-01, time/batch = 0.9990s	
1441/11350 (epoch 6.348), train_loss = 1.68489720, grad/param norm = 2.7720e-01, time/batch = 1.1886s	
1442/11350 (epoch 6.352), train_loss = 1.47700261, grad/param norm = 2.7922e-01, time/batch = 1.8907s	
1443/11350 (epoch 6.357), train_loss = 1.65681616, grad/param norm = 2.2599e-01, time/batch = 1.8563s	
1444/11350 (epoch 6.361), train_loss = 1.40329236, grad/param norm = 2.4849e-01, time/batch = 11.8718s	
1445/11350 (epoch 6.366), train_loss = 1.82688677, grad/param norm = 2.6708e-01, time/batch = 19.4548s	
1446/11350 (epoch 6.370), train_loss = 1.68003648, grad/param norm = 2.6359e-01, time/batch = 18.6950s	
1447/11350 (epoch 6.374), train_loss = 1.67453333, grad/param norm = 2.4895e-01, time/batch = 17.9633s	
1448/11350 (epoch 6.379), train_loss = 1.80260348, grad/param norm = 2.9286e-01, time/batch = 19.1980s	
1449/11350 (epoch 6.383), train_loss = 1.52833574, grad/param norm = 2.8972e-01, time/batch = 19.1045s	
1450/11350 (epoch 6.388), train_loss = 1.81251845, grad/param norm = 3.0777e-01, time/batch = 19.3598s	
1451/11350 (epoch 6.392), train_loss = 1.78091569, grad/param norm = 2.9719e-01, time/batch = 19.7021s	
1452/11350 (epoch 6.396), train_loss = 1.78109874, grad/param norm = 2.7050e-01, time/batch = 19.6023s	
1453/11350 (epoch 6.401), train_loss = 1.64053911, grad/param norm = 2.4557e-01, time/batch = 18.5008s	
1454/11350 (epoch 6.405), train_loss = 1.78833530, grad/param norm = 3.1174e-01, time/batch = 18.6284s	
1455/11350 (epoch 6.410), train_loss = 2.06293346, grad/param norm = 3.3945e-01, time/batch = 19.2650s	
1456/11350 (epoch 6.414), train_loss = 1.54249119, grad/param norm = 2.4825e-01, time/batch = 18.8621s	
1457/11350 (epoch 6.419), train_loss = 1.92560016, grad/param norm = 2.9788e-01, time/batch = 16.5169s	
1458/11350 (epoch 6.423), train_loss = 1.97314422, grad/param norm = 2.5931e-01, time/batch = 20.3722s	
1459/11350 (epoch 6.427), train_loss = 1.95811275, grad/param norm = 3.4858e-01, time/batch = 16.9251s	
1460/11350 (epoch 6.432), train_loss = 2.07080779, grad/param norm = 3.5825e-01, time/batch = 19.3786s	
1461/11350 (epoch 6.436), train_loss = 1.83222037, grad/param norm = 2.7300e-01, time/batch = 20.2131s	
1462/11350 (epoch 6.441), train_loss = 1.92937924, grad/param norm = 2.8487e-01, time/batch = 17.6742s	
1463/11350 (epoch 6.445), train_loss = 1.40543957, grad/param norm = 2.2407e-01, time/batch = 16.3496s	
1464/11350 (epoch 6.449), train_loss = 1.65808388, grad/param norm = 3.0075e-01, time/batch = 16.0973s	
1465/11350 (epoch 6.454), train_loss = 1.83927216, grad/param norm = 2.7092e-01, time/batch = 16.3524s	
1466/11350 (epoch 6.458), train_loss = 1.50647041, grad/param norm = 2.5390e-01, time/batch = 15.8559s	
1467/11350 (epoch 6.463), train_loss = 1.61961692, grad/param norm = 2.4857e-01, time/batch = 14.9681s	
1468/11350 (epoch 6.467), train_loss = 2.02457701, grad/param norm = 2.7413e-01, time/batch = 16.1287s	
1469/11350 (epoch 6.471), train_loss = 1.92741923, grad/param norm = 2.8859e-01, time/batch = 18.0230s	
1470/11350 (epoch 6.476), train_loss = 1.81582362, grad/param norm = 2.8514e-01, time/batch = 20.3649s	
1471/11350 (epoch 6.480), train_loss = 2.01574403, grad/param norm = 3.0198e-01, time/batch = 15.2060s	
1472/11350 (epoch 6.485), train_loss = 1.64831104, grad/param norm = 2.4347e-01, time/batch = 17.0017s	
1473/11350 (epoch 6.489), train_loss = 1.90238107, grad/param norm = 2.6028e-01, time/batch = 17.3734s	
1474/11350 (epoch 6.493), train_loss = 1.79434798, grad/param norm = 2.5346e-01, time/batch = 19.2972s	
1475/11350 (epoch 6.498), train_loss = 1.43841560, grad/param norm = 2.3258e-01, time/batch = 19.4614s	
1476/11350 (epoch 6.502), train_loss = 1.80105463, grad/param norm = 2.7229e-01, time/batch = 17.1948s	
1477/11350 (epoch 6.507), train_loss = 1.59006149, grad/param norm = 2.6008e-01, time/batch = 19.3735s	
1478/11350 (epoch 6.511), train_loss = 1.99957155, grad/param norm = 2.8688e-01, time/batch = 18.3851s	
1479/11350 (epoch 6.515), train_loss = 1.67261872, grad/param norm = 2.9434e-01, time/batch = 17.6206s	
1480/11350 (epoch 6.520), train_loss = 1.91311928, grad/param norm = 2.7796e-01, time/batch = 15.9942s	
1481/11350 (epoch 6.524), train_loss = 1.71061036, grad/param norm = 2.6627e-01, time/batch = 18.6425s	
1482/11350 (epoch 6.529), train_loss = 1.86659398, grad/param norm = 2.6130e-01, time/batch = 18.9561s	
1483/11350 (epoch 6.533), train_loss = 1.93434159, grad/param norm = 2.4061e-01, time/batch = 19.5349s	
1484/11350 (epoch 6.537), train_loss = 1.80280300, grad/param norm = 2.5789e-01, time/batch = 19.4494s	
1485/11350 (epoch 6.542), train_loss = 1.91246532, grad/param norm = 2.6204e-01, time/batch = 18.7109s	
1486/11350 (epoch 6.546), train_loss = 2.08378607, grad/param norm = 2.9336e-01, time/batch = 17.8679s	
1487/11350 (epoch 6.551), train_loss = 1.68293295, grad/param norm = 2.4846e-01, time/batch = 20.5454s	
1488/11350 (epoch 6.555), train_loss = 1.80387145, grad/param norm = 3.3080e-01, time/batch = 18.5944s	
1489/11350 (epoch 6.559), train_loss = 1.68576040, grad/param norm = 2.6390e-01, time/batch = 19.1912s	
1490/11350 (epoch 6.564), train_loss = 1.86460494, grad/param norm = 2.7751e-01, time/batch = 20.4410s	
1491/11350 (epoch 6.568), train_loss = 1.85618090, grad/param norm = 2.7014e-01, time/batch = 18.8742s	
1492/11350 (epoch 6.573), train_loss = 1.99853331, grad/param norm = 2.5054e-01, time/batch = 17.1832s	
1493/11350 (epoch 6.577), train_loss = 1.99521582, grad/param norm = 2.6452e-01, time/batch = 17.0945s	
1494/11350 (epoch 6.581), train_loss = 1.82818750, grad/param norm = 2.8455e-01, time/batch = 18.7979s	
1495/11350 (epoch 6.586), train_loss = 1.92356694, grad/param norm = 2.6098e-01, time/batch = 19.2677s	
1496/11350 (epoch 6.590), train_loss = 2.04544933, grad/param norm = 2.8294e-01, time/batch = 19.9459s	
1497/11350 (epoch 6.595), train_loss = 1.98493916, grad/param norm = 2.4115e-01, time/batch = 17.3642s	
1498/11350 (epoch 6.599), train_loss = 1.85744465, grad/param norm = 2.6738e-01, time/batch = 19.3685s	
1499/11350 (epoch 6.604), train_loss = 1.75299444, grad/param norm = 2.5458e-01, time/batch = 18.3767s	
1500/11350 (epoch 6.608), train_loss = 1.96504703, grad/param norm = 3.0145e-01, time/batch = 19.1241s	
1501/11350 (epoch 6.612), train_loss = 1.66229451, grad/param norm = 2.6166e-01, time/batch = 16.3640s	
1502/11350 (epoch 6.617), train_loss = 2.04518521, grad/param norm = 2.9077e-01, time/batch = 17.4546s	
1503/11350 (epoch 6.621), train_loss = 1.87899538, grad/param norm = 2.7434e-01, time/batch = 18.9665s	
1504/11350 (epoch 6.626), train_loss = 1.85248734, grad/param norm = 2.5888e-01, time/batch = 16.2905s	
1505/11350 (epoch 6.630), train_loss = 1.95452568, grad/param norm = 2.8446e-01, time/batch = 17.7111s	
1506/11350 (epoch 6.634), train_loss = 1.97341627, grad/param norm = 2.4088e-01, time/batch = 17.8941s	
1507/11350 (epoch 6.639), train_loss = 1.77033845, grad/param norm = 2.4072e-01, time/batch = 19.5420s	
1508/11350 (epoch 6.643), train_loss = 1.79212489, grad/param norm = 2.5019e-01, time/batch = 18.2047s	
1509/11350 (epoch 6.648), train_loss = 1.86059475, grad/param norm = 2.9599e-01, time/batch = 18.8583s	
1510/11350 (epoch 6.652), train_loss = 1.82267707, grad/param norm = 3.1644e-01, time/batch = 19.1313s	
1511/11350 (epoch 6.656), train_loss = 1.97521541, grad/param norm = 3.1263e-01, time/batch = 18.2607s	
1512/11350 (epoch 6.661), train_loss = 1.93638212, grad/param norm = 2.6417e-01, time/batch = 19.6692s	
1513/11350 (epoch 6.665), train_loss = 1.79631892, grad/param norm = 2.8909e-01, time/batch = 20.6020s	
1514/11350 (epoch 6.670), train_loss = 1.87588278, grad/param norm = 3.2961e-01, time/batch = 18.6187s	
1515/11350 (epoch 6.674), train_loss = 1.82268056, grad/param norm = 3.0440e-01, time/batch = 19.0416s	
1516/11350 (epoch 6.678), train_loss = 1.83874870, grad/param norm = 2.7229e-01, time/batch = 19.9645s	
1517/11350 (epoch 6.683), train_loss = 1.77919941, grad/param norm = 2.7894e-01, time/batch = 18.7092s	
1518/11350 (epoch 6.687), train_loss = 1.80071933, grad/param norm = 2.9537e-01, time/batch = 20.2882s	
1519/11350 (epoch 6.692), train_loss = 2.16623182, grad/param norm = 3.6750e-01, time/batch = 19.7008s	
1520/11350 (epoch 6.696), train_loss = 1.87839823, grad/param norm = 2.9969e-01, time/batch = 18.2618s	
1521/11350 (epoch 6.700), train_loss = 1.92419674, grad/param norm = 2.4220e-01, time/batch = 18.1075s	
1522/11350 (epoch 6.705), train_loss = 1.99411496, grad/param norm = 2.5812e-01, time/batch = 20.0502s	
1523/11350 (epoch 6.709), train_loss = 2.02117371, grad/param norm = 2.6313e-01, time/batch = 19.6302s	
1524/11350 (epoch 6.714), train_loss = 1.72649523, grad/param norm = 2.6757e-01, time/batch = 19.0834s	
1525/11350 (epoch 6.718), train_loss = 1.81613390, grad/param norm = 3.1672e-01, time/batch = 19.5435s	
1526/11350 (epoch 6.722), train_loss = 1.93933628, grad/param norm = 2.8518e-01, time/batch = 18.3506s	
1527/11350 (epoch 6.727), train_loss = 1.79367170, grad/param norm = 2.4814e-01, time/batch = 18.9373s	
1528/11350 (epoch 6.731), train_loss = 1.86755106, grad/param norm = 2.5857e-01, time/batch = 19.6268s	
1529/11350 (epoch 6.736), train_loss = 1.86782713, grad/param norm = 2.4665e-01, time/batch = 19.4567s	
1530/11350 (epoch 6.740), train_loss = 1.85850330, grad/param norm = 2.7166e-01, time/batch = 18.8635s	
1531/11350 (epoch 6.744), train_loss = 2.02446612, grad/param norm = 2.6282e-01, time/batch = 19.7894s	
1532/11350 (epoch 6.749), train_loss = 1.97738833, grad/param norm = 2.4815e-01, time/batch = 16.5456s	
1533/11350 (epoch 6.753), train_loss = 1.93365434, grad/param norm = 2.9317e-01, time/batch = 18.0288s	
1534/11350 (epoch 6.758), train_loss = 1.74746699, grad/param norm = 2.5841e-01, time/batch = 16.2696s	
1535/11350 (epoch 6.762), train_loss = 1.85590753, grad/param norm = 2.9275e-01, time/batch = 19.7016s	
1536/11350 (epoch 6.767), train_loss = 1.87962775, grad/param norm = 2.1724e-01, time/batch = 19.1122s	
1537/11350 (epoch 6.771), train_loss = 1.89188076, grad/param norm = 2.5144e-01, time/batch = 20.2594s	
1538/11350 (epoch 6.775), train_loss = 1.74641434, grad/param norm = 2.4305e-01, time/batch = 18.8847s	
1539/11350 (epoch 6.780), train_loss = 1.85811506, grad/param norm = 2.5489e-01, time/batch = 20.3245s	
1540/11350 (epoch 6.784), train_loss = 1.74311209, grad/param norm = 2.7602e-01, time/batch = 32.3788s	
1541/11350 (epoch 6.789), train_loss = 1.83586664, grad/param norm = 2.8666e-01, time/batch = 18.6972s	
1542/11350 (epoch 6.793), train_loss = 1.81680629, grad/param norm = 2.7392e-01, time/batch = 17.2617s	
1543/11350 (epoch 6.797), train_loss = 1.71718289, grad/param norm = 2.4474e-01, time/batch = 18.7964s	
1544/11350 (epoch 6.802), train_loss = 1.87233371, grad/param norm = 2.4743e-01, time/batch = 17.1381s	
1545/11350 (epoch 6.806), train_loss = 1.79928573, grad/param norm = 2.7164e-01, time/batch = 18.2871s	
1546/11350 (epoch 6.811), train_loss = 1.77302121, grad/param norm = 2.9344e-01, time/batch = 18.7795s	
1547/11350 (epoch 6.815), train_loss = 1.58282861, grad/param norm = 2.7147e-01, time/batch = 19.5246s	
1548/11350 (epoch 6.819), train_loss = 1.75154660, grad/param norm = 2.5388e-01, time/batch = 19.6138s	
1549/11350 (epoch 6.824), train_loss = 1.81835928, grad/param norm = 2.9057e-01, time/batch = 18.9551s	
1550/11350 (epoch 6.828), train_loss = 1.80228004, grad/param norm = 3.1039e-01, time/batch = 18.7211s	
1551/11350 (epoch 6.833), train_loss = 1.91413373, grad/param norm = 3.6860e-01, time/batch = 18.7536s	
1552/11350 (epoch 6.837), train_loss = 1.78282309, grad/param norm = 3.3220e-01, time/batch = 18.7245s	
1553/11350 (epoch 6.841), train_loss = 2.09847227, grad/param norm = 2.8050e-01, time/batch = 19.8728s	
1554/11350 (epoch 6.846), train_loss = 1.70656727, grad/param norm = 2.6814e-01, time/batch = 19.8725s	
1555/11350 (epoch 6.850), train_loss = 1.87171490, grad/param norm = 2.7542e-01, time/batch = 19.9213s	
1556/11350 (epoch 6.855), train_loss = 1.60579935, grad/param norm = 2.7763e-01, time/batch = 20.7819s	
1557/11350 (epoch 6.859), train_loss = 1.84650909, grad/param norm = 3.2184e-01, time/batch = 19.1112s	
1558/11350 (epoch 6.863), train_loss = 1.66516413, grad/param norm = 3.0008e-01, time/batch = 19.5335s	
1559/11350 (epoch 6.868), train_loss = 1.84308141, grad/param norm = 2.6653e-01, time/batch = 19.2814s	
1560/11350 (epoch 6.872), train_loss = 1.79119471, grad/param norm = 2.7208e-01, time/batch = 20.0367s	
1561/11350 (epoch 6.877), train_loss = 1.78424710, grad/param norm = 2.8939e-01, time/batch = 19.1223s	
1562/11350 (epoch 6.881), train_loss = 2.07668688, grad/param norm = 2.9902e-01, time/batch = 19.7108s	
1563/11350 (epoch 6.885), train_loss = 1.99565895, grad/param norm = 2.6611e-01, time/batch = 17.3738s	
1564/11350 (epoch 6.890), train_loss = 1.83924295, grad/param norm = 2.3855e-01, time/batch = 18.0313s	
1565/11350 (epoch 6.894), train_loss = 1.67466858, grad/param norm = 2.4858e-01, time/batch = 15.9522s	
1566/11350 (epoch 6.899), train_loss = 1.87072069, grad/param norm = 2.4136e-01, time/batch = 18.5331s	
1567/11350 (epoch 6.903), train_loss = 2.03851545, grad/param norm = 2.5167e-01, time/batch = 18.0416s	
1568/11350 (epoch 6.907), train_loss = 1.96833574, grad/param norm = 2.3927e-01, time/batch = 17.8725s	
1569/11350 (epoch 6.912), train_loss = 1.80808053, grad/param norm = 2.8740e-01, time/batch = 19.6070s	
1570/11350 (epoch 6.916), train_loss = 1.92106049, grad/param norm = 2.4788e-01, time/batch = 15.4755s	
1571/11350 (epoch 6.921), train_loss = 1.84914382, grad/param norm = 2.8513e-01, time/batch = 17.6234s	
1572/11350 (epoch 6.925), train_loss = 1.68027072, grad/param norm = 2.4616e-01, time/batch = 17.5530s	
1573/11350 (epoch 6.930), train_loss = 1.89253047, grad/param norm = 2.5124e-01, time/batch = 18.3050s	
1574/11350 (epoch 6.934), train_loss = 1.98199191, grad/param norm = 3.0238e-01, time/batch = 17.6240s	
1575/11350 (epoch 6.938), train_loss = 1.78203633, grad/param norm = 3.4531e-01, time/batch = 16.1294s	
1576/11350 (epoch 6.943), train_loss = 1.96250121, grad/param norm = 2.7329e-01, time/batch = 18.5443s	
1577/11350 (epoch 6.947), train_loss = 2.01016920, grad/param norm = 2.8576e-01, time/batch = 17.7089s	
1578/11350 (epoch 6.952), train_loss = 1.93098430, grad/param norm = 2.5005e-01, time/batch = 16.2294s	
1579/11350 (epoch 6.956), train_loss = 1.65200155, grad/param norm = 2.6962e-01, time/batch = 18.3573s	
1580/11350 (epoch 6.960), train_loss = 1.89914006, grad/param norm = 2.9820e-01, time/batch = 19.7743s	
1581/11350 (epoch 6.965), train_loss = 1.73036078, grad/param norm = 3.3292e-01, time/batch = 19.6870s	
1582/11350 (epoch 6.969), train_loss = 1.84447212, grad/param norm = 3.3052e-01, time/batch = 16.3062s	
1583/11350 (epoch 6.974), train_loss = 1.63177121, grad/param norm = 2.7550e-01, time/batch = 17.6897s	
1584/11350 (epoch 6.978), train_loss = 1.88701343, grad/param norm = 2.9792e-01, time/batch = 18.8520s	
1585/11350 (epoch 6.982), train_loss = 1.59037379, grad/param norm = 2.3863e-01, time/batch = 18.6254s	
1586/11350 (epoch 6.987), train_loss = 1.73698368, grad/param norm = 2.9039e-01, time/batch = 19.7051s	
1587/11350 (epoch 6.991), train_loss = 1.60980227, grad/param norm = 2.8625e-01, time/batch = 17.6000s	
1588/11350 (epoch 6.996), train_loss = 1.93261548, grad/param norm = 2.9460e-01, time/batch = 19.9596s	
1589/11350 (epoch 7.000), train_loss = 1.49554946, grad/param norm = 2.7440e-01, time/batch = 18.7207s	
1590/11350 (epoch 7.004), train_loss = 1.76505573, grad/param norm = 3.3370e-01, time/batch = 19.0256s	
1591/11350 (epoch 7.009), train_loss = 1.96837687, grad/param norm = 3.5404e-01, time/batch = 20.5279s	
1592/11350 (epoch 7.013), train_loss = 1.29476222, grad/param norm = 2.4637e-01, time/batch = 19.5398s	
1593/11350 (epoch 7.018), train_loss = 1.37110180, grad/param norm = 2.5660e-01, time/batch = 18.6104s	
1594/11350 (epoch 7.022), train_loss = 1.43399355, grad/param norm = 2.8138e-01, time/batch = 19.3550s	
1595/11350 (epoch 7.026), train_loss = 1.57643941, grad/param norm = 2.4199e-01, time/batch = 17.6885s	
1596/11350 (epoch 7.031), train_loss = 1.35490824, grad/param norm = 2.4471e-01, time/batch = 18.7771s	
1597/11350 (epoch 7.035), train_loss = 1.54806079, grad/param norm = 2.7819e-01, time/batch = 18.2718s	
1598/11350 (epoch 7.040), train_loss = 1.59503084, grad/param norm = 3.1359e-01, time/batch = 20.3655s	
1599/11350 (epoch 7.044), train_loss = 1.53478291, grad/param norm = 2.5074e-01, time/batch = 18.7839s	
1600/11350 (epoch 7.048), train_loss = 1.55758124, grad/param norm = 2.5080e-01, time/batch = 16.9443s	
1601/11350 (epoch 7.053), train_loss = 1.53438219, grad/param norm = 2.4593e-01, time/batch = 17.8089s	
1602/11350 (epoch 7.057), train_loss = 1.74478405, grad/param norm = 2.7221e-01, time/batch = 19.2084s	
1603/11350 (epoch 7.062), train_loss = 1.37854990, grad/param norm = 2.4234e-01, time/batch = 17.4649s	
1604/11350 (epoch 7.066), train_loss = 1.38210143, grad/param norm = 2.3812e-01, time/batch = 18.4647s	
1605/11350 (epoch 7.070), train_loss = 1.53333217, grad/param norm = 2.3024e-01, time/batch = 18.4807s	
1606/11350 (epoch 7.075), train_loss = 1.44720969, grad/param norm = 2.4566e-01, time/batch = 19.2073s	
1607/11350 (epoch 7.079), train_loss = 1.58092823, grad/param norm = 2.7388e-01, time/batch = 16.6769s	
1608/11350 (epoch 7.084), train_loss = 1.85355889, grad/param norm = 2.6670e-01, time/batch = 18.8649s	
1609/11350 (epoch 7.088), train_loss = 1.74778966, grad/param norm = 2.8464e-01, time/batch = 18.1937s	
1610/11350 (epoch 7.093), train_loss = 1.56928019, grad/param norm = 2.4198e-01, time/batch = 18.4507s	
1611/11350 (epoch 7.097), train_loss = 1.65198018, grad/param norm = 2.5673e-01, time/batch = 19.9667s	
1612/11350 (epoch 7.101), train_loss = 1.49289624, grad/param norm = 2.4889e-01, time/batch = 19.0221s	
1613/11350 (epoch 7.106), train_loss = 1.76757870, grad/param norm = 2.5778e-01, time/batch = 20.1027s	
1614/11350 (epoch 7.110), train_loss = 1.52455278, grad/param norm = 2.3782e-01, time/batch = 19.0125s	
1615/11350 (epoch 7.115), train_loss = 1.51221161, grad/param norm = 2.3072e-01, time/batch = 18.3893s	
1616/11350 (epoch 7.119), train_loss = 1.72456845, grad/param norm = 2.6247e-01, time/batch = 19.7642s	
1617/11350 (epoch 7.123), train_loss = 1.51645046, grad/param norm = 2.7270e-01, time/batch = 19.6317s	
1618/11350 (epoch 7.128), train_loss = 1.57178802, grad/param norm = 2.5351e-01, time/batch = 18.0348s	
1619/11350 (epoch 7.132), train_loss = 1.61706622, grad/param norm = 2.4228e-01, time/batch = 18.6060s	
1620/11350 (epoch 7.137), train_loss = 1.44897962, grad/param norm = 2.4448e-01, time/batch = 19.4703s	
1621/11350 (epoch 7.141), train_loss = 1.69942266, grad/param norm = 2.8618e-01, time/batch = 18.6120s	
1622/11350 (epoch 7.145), train_loss = 1.53310396, grad/param norm = 2.6372e-01, time/batch = 18.9536s	
1623/11350 (epoch 7.150), train_loss = 1.73096119, grad/param norm = 2.6714e-01, time/batch = 18.4470s	
1624/11350 (epoch 7.154), train_loss = 1.77883457, grad/param norm = 2.4382e-01, time/batch = 16.7044s	
1625/11350 (epoch 7.159), train_loss = 1.52044188, grad/param norm = 2.6241e-01, time/batch = 18.5374s	
1626/11350 (epoch 7.163), train_loss = 1.73972852, grad/param norm = 2.4664e-01, time/batch = 18.1266s	
1627/11350 (epoch 7.167), train_loss = 1.78293646, grad/param norm = 2.5129e-01, time/batch = 19.4646s	
1628/11350 (epoch 7.172), train_loss = 1.94562998, grad/param norm = 2.8096e-01, time/batch = 19.1216s	
1629/11350 (epoch 7.176), train_loss = 1.68117069, grad/param norm = 2.9605e-01, time/batch = 18.5332s	
1630/11350 (epoch 7.181), train_loss = 1.70185460, grad/param norm = 2.9072e-01, time/batch = 18.3794s	
1631/11350 (epoch 7.185), train_loss = 1.65491306, grad/param norm = 2.6958e-01, time/batch = 17.8766s	
1632/11350 (epoch 7.189), train_loss = 1.55215131, grad/param norm = 3.2329e-01, time/batch = 19.1027s	
1633/11350 (epoch 7.194), train_loss = 1.48731565, grad/param norm = 2.5935e-01, time/batch = 18.0517s	
1634/11350 (epoch 7.198), train_loss = 1.61292603, grad/param norm = 2.7531e-01, time/batch = 19.8730s	
1635/11350 (epoch 7.203), train_loss = 1.42102725, grad/param norm = 2.4394e-01, time/batch = 17.4540s	
1636/11350 (epoch 7.207), train_loss = 1.56357254, grad/param norm = 2.7075e-01, time/batch = 19.0488s	
1637/11350 (epoch 7.211), train_loss = 1.67830193, grad/param norm = 2.4899e-01, time/batch = 17.9673s	
1638/11350 (epoch 7.216), train_loss = 1.66073982, grad/param norm = 2.6553e-01, time/batch = 19.1831s	
1639/11350 (epoch 7.220), train_loss = 1.62706658, grad/param norm = 2.7845e-01, time/batch = 20.4308s	
1640/11350 (epoch 7.225), train_loss = 1.48624821, grad/param norm = 2.6892e-01, time/batch = 19.7790s	
1641/11350 (epoch 7.229), train_loss = 1.73312735, grad/param norm = 2.3655e-01, time/batch = 16.8671s	
1642/11350 (epoch 7.233), train_loss = 1.65122159, grad/param norm = 2.6803e-01, time/batch = 19.1198s	
1643/11350 (epoch 7.238), train_loss = 1.90475697, grad/param norm = 3.1231e-01, time/batch = 17.0927s	
1644/11350 (epoch 7.242), train_loss = 1.94572962, grad/param norm = 2.7643e-01, time/batch = 18.5961s	
1645/11350 (epoch 7.247), train_loss = 1.41806041, grad/param norm = 2.3372e-01, time/batch = 19.2820s	
1646/11350 (epoch 7.251), train_loss = 1.71733149, grad/param norm = 2.8865e-01, time/batch = 18.5498s	
1647/11350 (epoch 7.256), train_loss = 1.78759694, grad/param norm = 2.6906e-01, time/batch = 18.3017s	
1648/11350 (epoch 7.260), train_loss = 1.63513233, grad/param norm = 2.5608e-01, time/batch = 17.9313s	
1649/11350 (epoch 7.264), train_loss = 1.56942660, grad/param norm = 2.4968e-01, time/batch = 19.2137s	
1650/11350 (epoch 7.269), train_loss = 1.63807428, grad/param norm = 2.6957e-01, time/batch = 20.1994s	
1651/11350 (epoch 7.273), train_loss = 1.80434436, grad/param norm = 2.5943e-01, time/batch = 18.6842s	
1652/11350 (epoch 7.278), train_loss = 1.44858296, grad/param norm = 2.1966e-01, time/batch = 19.9544s	
1653/11350 (epoch 7.282), train_loss = 1.73877824, grad/param norm = 2.8891e-01, time/batch = 18.6990s	
1654/11350 (epoch 7.286), train_loss = 1.85747524, grad/param norm = 3.2570e-01, time/batch = 17.7880s	
1655/11350 (epoch 7.291), train_loss = 1.44542145, grad/param norm = 2.5766e-01, time/batch = 18.3002s	
1656/11350 (epoch 7.295), train_loss = 1.69536340, grad/param norm = 2.4966e-01, time/batch = 20.7020s	
1657/11350 (epoch 7.300), train_loss = 1.61879396, grad/param norm = 2.5102e-01, time/batch = 18.7952s	
1658/11350 (epoch 7.304), train_loss = 1.54593396, grad/param norm = 2.2648e-01, time/batch = 20.6931s	
1659/11350 (epoch 7.308), train_loss = 1.54518272, grad/param norm = 2.4163e-01, time/batch = 16.3253s	
1660/11350 (epoch 7.313), train_loss = 1.67396532, grad/param norm = 2.6563e-01, time/batch = 19.6111s	
1661/11350 (epoch 7.317), train_loss = 1.37351721, grad/param norm = 2.4311e-01, time/batch = 20.2789s	
1662/11350 (epoch 7.322), train_loss = 1.50045412, grad/param norm = 2.5981e-01, time/batch = 18.3713s	
1663/11350 (epoch 7.326), train_loss = 1.59083604, grad/param norm = 2.7257e-01, time/batch = 17.8693s	
1664/11350 (epoch 7.330), train_loss = 1.36513107, grad/param norm = 2.6076e-01, time/batch = 18.7120s	
1665/11350 (epoch 7.335), train_loss = 1.38337090, grad/param norm = 2.5876e-01, time/batch = 19.7096s	
1666/11350 (epoch 7.339), train_loss = 1.45199143, grad/param norm = 2.5011e-01, time/batch = 19.7915s	
1667/11350 (epoch 7.344), train_loss = 1.57017808, grad/param norm = 2.4107e-01, time/batch = 18.3565s	
1668/11350 (epoch 7.348), train_loss = 1.58076071, grad/param norm = 2.5617e-01, time/batch = 19.7931s	
1669/11350 (epoch 7.352), train_loss = 1.40121581, grad/param norm = 2.8280e-01, time/batch = 18.0379s	
1670/11350 (epoch 7.357), train_loss = 1.56042914, grad/param norm = 2.3142e-01, time/batch = 18.7114s	
1671/11350 (epoch 7.361), train_loss = 1.31322264, grad/param norm = 2.3762e-01, time/batch = 19.6144s	
1672/11350 (epoch 7.366), train_loss = 1.75078717, grad/param norm = 2.6485e-01, time/batch = 18.1221s	
1673/11350 (epoch 7.370), train_loss = 1.58661070, grad/param norm = 2.4546e-01, time/batch = 18.0922s	
1674/11350 (epoch 7.374), train_loss = 1.58429053, grad/param norm = 2.5851e-01, time/batch = 15.7773s	
1675/11350 (epoch 7.379), train_loss = 1.70354655, grad/param norm = 3.0916e-01, time/batch = 20.4555s	
1676/11350 (epoch 7.383), train_loss = 1.41631769, grad/param norm = 2.8993e-01, time/batch = 17.5453s	
1677/11350 (epoch 7.388), train_loss = 1.72668350, grad/param norm = 2.8906e-01, time/batch = 18.6301s	
1678/11350 (epoch 7.392), train_loss = 1.66835016, grad/param norm = 2.8495e-01, time/batch = 20.3752s	
1679/11350 (epoch 7.396), train_loss = 1.70054671, grad/param norm = 2.7164e-01, time/batch = 18.0190s	
1680/11350 (epoch 7.401), train_loss = 1.56461277, grad/param norm = 2.5356e-01, time/batch = 18.6234s	
1681/11350 (epoch 7.405), train_loss = 1.71062009, grad/param norm = 4.3167e-01, time/batch = 20.3631s	
1682/11350 (epoch 7.410), train_loss = 1.96501951, grad/param norm = 5.7859e-01, time/batch = 17.8713s	
1683/11350 (epoch 7.414), train_loss = 1.48423038, grad/param norm = 2.8342e-01, time/batch = 19.3224s	
1684/11350 (epoch 7.419), train_loss = 1.80674684, grad/param norm = 2.9126e-01, time/batch = 19.1896s	
1685/11350 (epoch 7.423), train_loss = 1.85941281, grad/param norm = 2.5124e-01, time/batch = 19.8601s	
1686/11350 (epoch 7.427), train_loss = 1.86370911, grad/param norm = 3.1954e-01, time/batch = 15.8572s	
1687/11350 (epoch 7.432), train_loss = 1.94790435, grad/param norm = 3.0470e-01, time/batch = 19.0307s	
1688/11350 (epoch 7.436), train_loss = 1.71170553, grad/param norm = 2.4947e-01, time/batch = 19.7952s	
1689/11350 (epoch 7.441), train_loss = 1.85383918, grad/param norm = 2.7798e-01, time/batch = 18.1922s	
1690/11350 (epoch 7.445), train_loss = 1.32350527, grad/param norm = 2.2719e-01, time/batch = 19.4526s	
1691/11350 (epoch 7.449), train_loss = 1.57485261, grad/param norm = 2.9379e-01, time/batch = 16.1962s	
1692/11350 (epoch 7.454), train_loss = 1.75456312, grad/param norm = 2.7003e-01, time/batch = 18.6981s	
1693/11350 (epoch 7.458), train_loss = 1.40686107, grad/param norm = 2.4244e-01, time/batch = 18.7869s	
1694/11350 (epoch 7.463), train_loss = 1.51329793, grad/param norm = 2.4579e-01, time/batch = 19.1260s	
1695/11350 (epoch 7.467), train_loss = 1.94451456, grad/param norm = 2.7132e-01, time/batch = 17.6112s	
1696/11350 (epoch 7.471), train_loss = 1.83521444, grad/param norm = 3.0655e-01, time/batch = 18.7984s	
1697/11350 (epoch 7.476), train_loss = 1.73890725, grad/param norm = 2.8095e-01, time/batch = 15.6603s	
1698/11350 (epoch 7.480), train_loss = 1.90921019, grad/param norm = 2.7953e-01, time/batch = 19.2133s	
1699/11350 (epoch 7.485), train_loss = 1.56221905, grad/param norm = 2.3376e-01, time/batch = 17.2145s	
1700/11350 (epoch 7.489), train_loss = 1.80625191, grad/param norm = 2.6274e-01, time/batch = 18.7110s	
1701/11350 (epoch 7.493), train_loss = 1.69720163, grad/param norm = 2.4680e-01, time/batch = 17.3687s	
1702/11350 (epoch 7.498), train_loss = 1.35173873, grad/param norm = 2.5607e-01, time/batch = 18.4206s	
1703/11350 (epoch 7.502), train_loss = 1.71488064, grad/param norm = 2.9967e-01, time/batch = 19.2860s	
1704/11350 (epoch 7.507), train_loss = 1.48161673, grad/param norm = 2.3823e-01, time/batch = 19.6287s	
1705/11350 (epoch 7.511), train_loss = 1.92022677, grad/param norm = 2.6844e-01, time/batch = 16.5945s	
1706/11350 (epoch 7.515), train_loss = 1.57437151, grad/param norm = 2.5156e-01, time/batch = 19.7021s	
1707/11350 (epoch 7.520), train_loss = 1.82447725, grad/param norm = 2.6923e-01, time/batch = 19.6020s	
1708/11350 (epoch 7.524), train_loss = 1.62571371, grad/param norm = 2.6575e-01, time/batch = 19.1160s	
1709/11350 (epoch 7.529), train_loss = 1.76080508, grad/param norm = 2.6177e-01, time/batch = 18.4701s	
1710/11350 (epoch 7.533), train_loss = 1.87061157, grad/param norm = 2.4487e-01, time/batch = 16.9376s	
1711/11350 (epoch 7.537), train_loss = 1.72190146, grad/param norm = 2.7640e-01, time/batch = 18.3597s	
1712/11350 (epoch 7.542), train_loss = 1.82123185, grad/param norm = 2.6900e-01, time/batch = 19.4347s	
1713/11350 (epoch 7.546), train_loss = 2.01769711, grad/param norm = 3.2462e-01, time/batch = 20.2930s	
1714/11350 (epoch 7.551), train_loss = 1.61407528, grad/param norm = 3.1241e-01, time/batch = 19.7841s	
1715/11350 (epoch 7.555), train_loss = 1.70677004, grad/param norm = 3.9078e-01, time/batch = 17.8460s	
1716/11350 (epoch 7.559), train_loss = 1.60425983, grad/param norm = 2.5162e-01, time/batch = 19.4571s	
1717/11350 (epoch 7.564), train_loss = 1.79274790, grad/param norm = 2.7597e-01, time/batch = 19.1300s	
1718/11350 (epoch 7.568), train_loss = 1.76255107, grad/param norm = 2.6873e-01, time/batch = 18.1982s	
1719/11350 (epoch 7.573), train_loss = 1.91769263, grad/param norm = 2.5800e-01, time/batch = 19.7762s	
1720/11350 (epoch 7.577), train_loss = 1.91678935, grad/param norm = 2.5932e-01, time/batch = 20.5379s	
1721/11350 (epoch 7.581), train_loss = 1.73877204, grad/param norm = 2.6343e-01, time/batch = 16.8719s	
1722/11350 (epoch 7.586), train_loss = 1.82633063, grad/param norm = 2.5381e-01, time/batch = 20.2100s	
1723/11350 (epoch 7.590), train_loss = 1.94016171, grad/param norm = 2.7279e-01, time/batch = 20.6234s	
1724/11350 (epoch 7.595), train_loss = 1.90717839, grad/param norm = 2.4199e-01, time/batch = 17.4330s	
1725/11350 (epoch 7.599), train_loss = 1.78648641, grad/param norm = 2.5609e-01, time/batch = 19.8830s	
1726/11350 (epoch 7.604), train_loss = 1.65580169, grad/param norm = 2.4312e-01, time/batch = 18.9471s	
1727/11350 (epoch 7.608), train_loss = 1.85558948, grad/param norm = 2.8417e-01, time/batch = 19.0189s	
1728/11350 (epoch 7.612), train_loss = 1.57574503, grad/param norm = 2.5440e-01, time/batch = 19.7008s	
1729/11350 (epoch 7.617), train_loss = 1.94471415, grad/param norm = 2.7833e-01, time/batch = 18.9633s	
1730/11350 (epoch 7.621), train_loss = 1.79932926, grad/param norm = 2.5238e-01, time/batch = 22.7300s	
1731/11350 (epoch 7.626), train_loss = 1.76039167, grad/param norm = 2.6119e-01, time/batch = 28.2431s	
1732/11350 (epoch 7.630), train_loss = 1.85651632, grad/param norm = 2.8486e-01, time/batch = 20.1791s	
1733/11350 (epoch 7.634), train_loss = 1.86273282, grad/param norm = 2.3728e-01, time/batch = 18.6050s	
1734/11350 (epoch 7.639), train_loss = 1.66997388, grad/param norm = 2.4676e-01, time/batch = 19.2971s	
1735/11350 (epoch 7.643), train_loss = 1.69612803, grad/param norm = 2.4442e-01, time/batch = 21.1072s	
1736/11350 (epoch 7.648), train_loss = 1.76650791, grad/param norm = 2.9034e-01, time/batch = 17.5939s	
1737/11350 (epoch 7.652), train_loss = 1.74167618, grad/param norm = 2.9717e-01, time/batch = 18.7894s	
1738/11350 (epoch 7.656), train_loss = 1.89241625, grad/param norm = 2.9379e-01, time/batch = 19.0348s	
1739/11350 (epoch 7.661), train_loss = 1.87268034, grad/param norm = 2.8018e-01, time/batch = 18.5986s	
1740/11350 (epoch 7.665), train_loss = 1.70585263, grad/param norm = 3.3579e-01, time/batch = 18.8581s	
1741/11350 (epoch 7.670), train_loss = 1.79814298, grad/param norm = 3.6167e-01, time/batch = 19.1979s	
1742/11350 (epoch 7.674), train_loss = 1.71772991, grad/param norm = 2.8593e-01, time/batch = 18.0043s	
1743/11350 (epoch 7.678), train_loss = 1.73235785, grad/param norm = 2.4745e-01, time/batch = 20.6182s	
1744/11350 (epoch 7.683), train_loss = 1.67416146, grad/param norm = 2.6202e-01, time/batch = 19.4589s	
1745/11350 (epoch 7.687), train_loss = 1.68777899, grad/param norm = 2.7033e-01, time/batch = 18.7713s	
1746/11350 (epoch 7.692), train_loss = 2.07502466, grad/param norm = 3.2545e-01, time/batch = 19.9555s	
1747/11350 (epoch 7.696), train_loss = 1.81238711, grad/param norm = 2.7758e-01, time/batch = 18.0535s	
1748/11350 (epoch 7.700), train_loss = 1.81215180, grad/param norm = 2.4332e-01, time/batch = 19.5360s	
1749/11350 (epoch 7.705), train_loss = 1.90263694, grad/param norm = 2.5662e-01, time/batch = 18.3698s	
1750/11350 (epoch 7.709), train_loss = 1.91863588, grad/param norm = 2.6742e-01, time/batch = 19.9625s	
1751/11350 (epoch 7.714), train_loss = 1.62232986, grad/param norm = 2.5426e-01, time/batch = 18.7595s	
1752/11350 (epoch 7.718), train_loss = 1.67269294, grad/param norm = 2.8819e-01, time/batch = 20.1951s	
1753/11350 (epoch 7.722), train_loss = 1.84579054, grad/param norm = 2.7753e-01, time/batch = 16.9548s	
1754/11350 (epoch 7.727), train_loss = 1.70480358, grad/param norm = 2.3823e-01, time/batch = 18.5353s	
1755/11350 (epoch 7.731), train_loss = 1.79442503, grad/param norm = 2.5383e-01, time/batch = 17.6698s	
1756/11350 (epoch 7.736), train_loss = 1.77701732, grad/param norm = 2.4132e-01, time/batch = 20.2849s	
1757/11350 (epoch 7.740), train_loss = 1.76213429, grad/param norm = 2.6435e-01, time/batch = 18.4535s	
1758/11350 (epoch 7.744), train_loss = 1.94126004, grad/param norm = 2.5084e-01, time/batch = 18.8798s	
1759/11350 (epoch 7.749), train_loss = 1.89196286, grad/param norm = 2.4682e-01, time/batch = 19.8783s	
1760/11350 (epoch 7.753), train_loss = 1.83326824, grad/param norm = 2.8298e-01, time/batch = 19.9607s	
1761/11350 (epoch 7.758), train_loss = 1.67353926, grad/param norm = 2.5450e-01, time/batch = 18.0226s	
1762/11350 (epoch 7.762), train_loss = 1.77796575, grad/param norm = 2.7514e-01, time/batch = 19.2814s	
1763/11350 (epoch 7.767), train_loss = 1.78218920, grad/param norm = 2.1755e-01, time/batch = 18.9482s	
1764/11350 (epoch 7.771), train_loss = 1.81515539, grad/param norm = 2.6479e-01, time/batch = 18.4414s	
1765/11350 (epoch 7.775), train_loss = 1.65092313, grad/param norm = 2.3602e-01, time/batch = 19.1131s	
1766/11350 (epoch 7.780), train_loss = 1.78163798, grad/param norm = 2.5582e-01, time/batch = 20.3598s	
1767/11350 (epoch 7.784), train_loss = 1.64835455, grad/param norm = 2.6272e-01, time/batch = 17.8797s	
1768/11350 (epoch 7.789), train_loss = 1.74649145, grad/param norm = 2.7764e-01, time/batch = 17.4343s	
1769/11350 (epoch 7.793), train_loss = 1.73771286, grad/param norm = 2.6250e-01, time/batch = 18.9517s	
1770/11350 (epoch 7.797), train_loss = 1.65543964, grad/param norm = 2.5111e-01, time/batch = 18.9579s	
1771/11350 (epoch 7.802), train_loss = 1.77577652, grad/param norm = 2.4486e-01, time/batch = 17.4620s	
1772/11350 (epoch 7.806), train_loss = 1.72392689, grad/param norm = 2.6942e-01, time/batch = 16.3085s	
1773/11350 (epoch 7.811), train_loss = 1.66420360, grad/param norm = 2.9345e-01, time/batch = 17.8596s	
1774/11350 (epoch 7.815), train_loss = 1.50377592, grad/param norm = 2.8338e-01, time/batch = 16.2719s	
1775/11350 (epoch 7.819), train_loss = 1.66034345, grad/param norm = 2.4033e-01, time/batch = 19.2947s	
1776/11350 (epoch 7.824), train_loss = 1.72836866, grad/param norm = 2.8136e-01, time/batch = 19.6308s	
1777/11350 (epoch 7.828), train_loss = 1.70988967, grad/param norm = 2.7766e-01, time/batch = 18.2880s	
1778/11350 (epoch 7.833), train_loss = 1.80436160, grad/param norm = 3.1375e-01, time/batch = 17.1127s	
1779/11350 (epoch 7.837), train_loss = 1.70687777, grad/param norm = 3.1523e-01, time/batch = 17.7930s	
1780/11350 (epoch 7.841), train_loss = 2.02263796, grad/param norm = 2.7082e-01, time/batch = 18.8777s	
1781/11350 (epoch 7.846), train_loss = 1.63392752, grad/param norm = 2.6090e-01, time/batch = 17.9436s	
1782/11350 (epoch 7.850), train_loss = 1.80093021, grad/param norm = 2.7247e-01, time/batch = 15.3895s	
1783/11350 (epoch 7.855), train_loss = 1.52217440, grad/param norm = 2.7547e-01, time/batch = 16.8620s	
1784/11350 (epoch 7.859), train_loss = 1.74869034, grad/param norm = 3.2168e-01, time/batch = 18.7556s	
1785/11350 (epoch 7.863), train_loss = 1.59110346, grad/param norm = 3.0345e-01, time/batch = 17.2013s	
1786/11350 (epoch 7.868), train_loss = 1.74968004, grad/param norm = 2.6798e-01, time/batch = 20.1214s	
1787/11350 (epoch 7.872), train_loss = 1.68985459, grad/param norm = 2.5951e-01, time/batch = 18.3634s	
1788/11350 (epoch 7.877), train_loss = 1.68898803, grad/param norm = 2.7568e-01, time/batch = 18.7718s	
1789/11350 (epoch 7.881), train_loss = 1.99126411, grad/param norm = 3.0114e-01, time/batch = 20.4561s	
1790/11350 (epoch 7.885), train_loss = 1.93066830, grad/param norm = 2.7812e-01, time/batch = 16.2077s	
1791/11350 (epoch 7.890), train_loss = 1.76473844, grad/param norm = 2.4104e-01, time/batch = 19.6195s	
1792/11350 (epoch 7.894), train_loss = 1.56397811, grad/param norm = 2.3484e-01, time/batch = 16.5441s	
1793/11350 (epoch 7.899), train_loss = 1.79986355, grad/param norm = 2.4360e-01, time/batch = 20.3686s	
1794/11350 (epoch 7.903), train_loss = 1.92778663, grad/param norm = 2.4091e-01, time/batch = 19.2581s	
1795/11350 (epoch 7.907), train_loss = 1.87361677, grad/param norm = 2.5971e-01, time/batch = 17.6910s	
1796/11350 (epoch 7.912), train_loss = 1.75200065, grad/param norm = 4.7569e-01, time/batch = 20.5190s	
1797/11350 (epoch 7.916), train_loss = 1.84143941, grad/param norm = 2.8312e-01, time/batch = 19.0106s	
1798/11350 (epoch 7.921), train_loss = 1.77329790, grad/param norm = 2.6340e-01, time/batch = 20.1276s	
1799/11350 (epoch 7.925), train_loss = 1.59346412, grad/param norm = 2.5592e-01, time/batch = 20.4445s	
1800/11350 (epoch 7.930), train_loss = 1.81702407, grad/param norm = 2.4733e-01, time/batch = 17.8669s	
1801/11350 (epoch 7.934), train_loss = 1.89364800, grad/param norm = 2.9594e-01, time/batch = 19.2049s	
1802/11350 (epoch 7.938), train_loss = 1.68126961, grad/param norm = 3.2164e-01, time/batch = 20.2780s	
1803/11350 (epoch 7.943), train_loss = 1.86978705, grad/param norm = 2.7617e-01, time/batch = 17.3314s	
1804/11350 (epoch 7.947), train_loss = 1.93275444, grad/param norm = 2.9152e-01, time/batch = 19.2850s	
1805/11350 (epoch 7.952), train_loss = 1.83891589, grad/param norm = 2.7974e-01, time/batch = 19.7720s	
1806/11350 (epoch 7.956), train_loss = 1.55200190, grad/param norm = 2.5903e-01, time/batch = 18.2838s	
1807/11350 (epoch 7.960), train_loss = 1.81333419, grad/param norm = 3.0905e-01, time/batch = 20.2819s	
1808/11350 (epoch 7.965), train_loss = 1.63050645, grad/param norm = 2.8488e-01, time/batch = 19.1361s	
1809/11350 (epoch 7.969), train_loss = 1.73109984, grad/param norm = 3.3548e-01, time/batch = 18.8722s	
1810/11350 (epoch 7.974), train_loss = 1.55756289, grad/param norm = 2.9507e-01, time/batch = 19.3710s	
1811/11350 (epoch 7.978), train_loss = 1.79189455, grad/param norm = 2.9062e-01, time/batch = 18.8753s	
1812/11350 (epoch 7.982), train_loss = 1.48350984, grad/param norm = 2.2982e-01, time/batch = 18.2216s	
1813/11350 (epoch 7.987), train_loss = 1.64431991, grad/param norm = 2.6018e-01, time/batch = 18.2221s	
1814/11350 (epoch 7.991), train_loss = 1.53771966, grad/param norm = 2.8685e-01, time/batch = 18.6261s	
1815/11350 (epoch 7.996), train_loss = 1.83585674, grad/param norm = 2.8381e-01, time/batch = 19.1276s	
1816/11350 (epoch 8.000), train_loss = 1.40743710, grad/param norm = 2.8363e-01, time/batch = 18.4612s	
1817/11350 (epoch 8.004), train_loss = 1.68202528, grad/param norm = 3.0392e-01, time/batch = 16.1262s	
1818/11350 (epoch 8.009), train_loss = 1.85631776, grad/param norm = 2.9075e-01, time/batch = 17.9449s	
1819/11350 (epoch 8.013), train_loss = 1.20490874, grad/param norm = 2.2828e-01, time/batch = 17.5550s	
1820/11350 (epoch 8.018), train_loss = 1.28531221, grad/param norm = 2.6213e-01, time/batch = 17.6479s	
1821/11350 (epoch 8.022), train_loss = 1.34888229, grad/param norm = 2.6380e-01, time/batch = 16.2740s	
1822/11350 (epoch 8.026), train_loss = 1.48746510, grad/param norm = 2.4632e-01, time/batch = 17.7742s	
1823/11350 (epoch 8.031), train_loss = 1.28792736, grad/param norm = 2.4020e-01, time/batch = 17.9678s	
1824/11350 (epoch 8.035), train_loss = 1.46652355, grad/param norm = 2.6477e-01, time/batch = 18.9798s	
1825/11350 (epoch 8.040), train_loss = 1.50938677, grad/param norm = 2.8127e-01, time/batch = 19.0517s	
1826/11350 (epoch 8.044), train_loss = 1.43915754, grad/param norm = 2.2458e-01, time/batch = 16.3696s	
1827/11350 (epoch 8.048), train_loss = 1.46368447, grad/param norm = 2.3964e-01, time/batch = 18.7804s	
1828/11350 (epoch 8.053), train_loss = 1.47149419, grad/param norm = 2.4451e-01, time/batch = 18.3810s	
1829/11350 (epoch 8.057), train_loss = 1.64955490, grad/param norm = 2.7505e-01, time/batch = 17.2785s	
1830/11350 (epoch 8.062), train_loss = 1.30497889, grad/param norm = 2.2987e-01, time/batch = 20.5418s	
1831/11350 (epoch 8.066), train_loss = 1.30772907, grad/param norm = 2.2541e-01, time/batch = 20.3762s	
1832/11350 (epoch 8.070), train_loss = 1.45886709, grad/param norm = 2.2738e-01, time/batch = 17.5118s	
1833/11350 (epoch 8.075), train_loss = 1.35936516, grad/param norm = 2.3944e-01, time/batch = 18.2972s	
1834/11350 (epoch 8.079), train_loss = 1.49582938, grad/param norm = 2.5613e-01, time/batch = 20.0407s	
1835/11350 (epoch 8.084), train_loss = 1.75217585, grad/param norm = 2.4740e-01, time/batch = 19.4520s	
1836/11350 (epoch 8.088), train_loss = 1.66619496, grad/param norm = 2.6400e-01, time/batch = 19.1878s	
1837/11350 (epoch 8.093), train_loss = 1.51434419, grad/param norm = 2.4004e-01, time/batch = 16.7653s	
1838/11350 (epoch 8.097), train_loss = 1.57129871, grad/param norm = 2.5373e-01, time/batch = 17.9471s	
1839/11350 (epoch 8.101), train_loss = 1.41194647, grad/param norm = 2.3283e-01, time/batch = 19.9420s	
1840/11350 (epoch 8.106), train_loss = 1.68420805, grad/param norm = 2.4403e-01, time/batch = 18.7131s	
1841/11350 (epoch 8.110), train_loss = 1.45921210, grad/param norm = 2.3933e-01, time/batch = 20.0328s	
1842/11350 (epoch 8.115), train_loss = 1.44342707, grad/param norm = 2.2703e-01, time/batch = 18.0775s	
1843/11350 (epoch 8.119), train_loss = 1.66082003, grad/param norm = 2.6276e-01, time/batch = 19.6202s	
1844/11350 (epoch 8.123), train_loss = 1.43500601, grad/param norm = 2.5719e-01, time/batch = 17.1164s	
1845/11350 (epoch 8.128), train_loss = 1.48753647, grad/param norm = 2.4540e-01, time/batch = 17.6904s	
1846/11350 (epoch 8.132), train_loss = 1.52669214, grad/param norm = 2.4241e-01, time/batch = 20.3747s	
1847/11350 (epoch 8.137), train_loss = 1.39232947, grad/param norm = 2.4757e-01, time/batch = 20.0426s	
1848/11350 (epoch 8.141), train_loss = 1.63064308, grad/param norm = 2.8964e-01, time/batch = 19.6115s	
1849/11350 (epoch 8.145), train_loss = 1.44788818, grad/param norm = 2.4605e-01, time/batch = 19.3822s	
1850/11350 (epoch 8.150), train_loss = 1.66260515, grad/param norm = 2.6298e-01, time/batch = 18.5497s	
1851/11350 (epoch 8.154), train_loss = 1.72328253, grad/param norm = 2.5321e-01, time/batch = 18.9295s	
1852/11350 (epoch 8.159), train_loss = 1.43673995, grad/param norm = 2.5923e-01, time/batch = 18.2886s	
1853/11350 (epoch 8.163), train_loss = 1.66523582, grad/param norm = 2.4858e-01, time/batch = 18.6106s	
1854/11350 (epoch 8.167), train_loss = 1.70285584, grad/param norm = 2.4277e-01, time/batch = 17.8471s	
1855/11350 (epoch 8.172), train_loss = 1.86546316, grad/param norm = 2.7798e-01, time/batch = 20.3039s	
1856/11350 (epoch 8.176), train_loss = 1.61055906, grad/param norm = 2.7936e-01, time/batch = 18.9680s	
1857/11350 (epoch 8.181), train_loss = 1.61662076, grad/param norm = 2.6918e-01, time/batch = 18.7800s	
1858/11350 (epoch 8.185), train_loss = 1.54778355, grad/param norm = 2.5535e-01, time/batch = 19.5335s	
1859/11350 (epoch 8.189), train_loss = 1.47750847, grad/param norm = 2.7593e-01, time/batch = 16.9472s	
1860/11350 (epoch 8.194), train_loss = 1.41202411, grad/param norm = 2.4516e-01, time/batch = 19.2924s	
1861/11350 (epoch 8.198), train_loss = 1.51029622, grad/param norm = 2.6539e-01, time/batch = 19.0305s	
1862/11350 (epoch 8.203), train_loss = 1.35546929, grad/param norm = 2.4130e-01, time/batch = 20.2975s	
1863/11350 (epoch 8.207), train_loss = 1.46303536, grad/param norm = 2.6541e-01, time/batch = 19.3787s	
1864/11350 (epoch 8.211), train_loss = 1.59632361, grad/param norm = 2.3855e-01, time/batch = 20.5188s	
1865/11350 (epoch 8.216), train_loss = 1.57432518, grad/param norm = 2.6978e-01, time/batch = 17.8041s	
1866/11350 (epoch 8.220), train_loss = 1.54029229, grad/param norm = 2.5574e-01, time/batch = 19.7926s	
1867/11350 (epoch 8.225), train_loss = 1.40171435, grad/param norm = 2.8390e-01, time/batch = 19.9506s	
1868/11350 (epoch 8.229), train_loss = 1.65511833, grad/param norm = 2.4632e-01, time/batch = 18.9578s	
1869/11350 (epoch 8.233), train_loss = 1.57017061, grad/param norm = 2.5651e-01, time/batch = 18.1976s	
1870/11350 (epoch 8.238), train_loss = 1.82207169, grad/param norm = 3.1292e-01, time/batch = 19.3682s	
1871/11350 (epoch 8.242), train_loss = 1.85108909, grad/param norm = 2.7884e-01, time/batch = 19.5369s	
1872/11350 (epoch 8.247), train_loss = 1.33891779, grad/param norm = 2.3495e-01, time/batch = 19.6239s	
1873/11350 (epoch 8.251), train_loss = 1.63933118, grad/param norm = 2.9362e-01, time/batch = 17.5162s	
1874/11350 (epoch 8.256), train_loss = 1.72639452, grad/param norm = 2.6939e-01, time/batch = 17.4317s	
1875/11350 (epoch 8.260), train_loss = 1.53395785, grad/param norm = 2.6742e-01, time/batch = 19.2056s	
1876/11350 (epoch 8.264), train_loss = 1.50451316, grad/param norm = 2.3680e-01, time/batch = 18.2898s	
1877/11350 (epoch 8.269), train_loss = 1.54852325, grad/param norm = 2.5223e-01, time/batch = 18.2988s	
1878/11350 (epoch 8.273), train_loss = 1.71286661, grad/param norm = 2.5596e-01, time/batch = 17.2103s	
1879/11350 (epoch 8.278), train_loss = 1.36882633, grad/param norm = 2.1361e-01, time/batch = 18.6862s	
1880/11350 (epoch 8.282), train_loss = 1.66138892, grad/param norm = 2.9053e-01, time/batch = 18.0443s	
1881/11350 (epoch 8.286), train_loss = 1.77310266, grad/param norm = 3.2631e-01, time/batch = 16.6980s	
1882/11350 (epoch 8.291), train_loss = 1.36793398, grad/param norm = 2.5761e-01, time/batch = 20.9496s	
1883/11350 (epoch 8.295), train_loss = 1.59525557, grad/param norm = 2.3776e-01, time/batch = 18.3478s	
1884/11350 (epoch 8.300), train_loss = 1.53897188, grad/param norm = 2.4433e-01, time/batch = 20.6133s	
1885/11350 (epoch 8.304), train_loss = 1.47319194, grad/param norm = 2.3237e-01, time/batch = 18.4487s	
1886/11350 (epoch 8.308), train_loss = 1.47788651, grad/param norm = 2.3384e-01, time/batch = 18.6905s	
1887/11350 (epoch 8.313), train_loss = 1.60466991, grad/param norm = 2.5463e-01, time/batch = 17.5511s	
1888/11350 (epoch 8.317), train_loss = 1.31850463, grad/param norm = 2.4646e-01, time/batch = 19.7844s	
1889/11350 (epoch 8.322), train_loss = 1.43305002, grad/param norm = 2.5268e-01, time/batch = 16.3703s	
1890/11350 (epoch 8.326), train_loss = 1.51114014, grad/param norm = 2.4748e-01, time/batch = 19.6040s	
1891/11350 (epoch 8.330), train_loss = 1.29600323, grad/param norm = 2.5286e-01, time/batch = 19.1220s	
1892/11350 (epoch 8.335), train_loss = 1.28498333, grad/param norm = 2.4016e-01, time/batch = 18.1781s	
1893/11350 (epoch 8.339), train_loss = 1.37810817, grad/param norm = 2.3790e-01, time/batch = 17.7518s	
1894/11350 (epoch 8.344), train_loss = 1.48837813, grad/param norm = 2.4483e-01, time/batch = 18.7974s	
1895/11350 (epoch 8.348), train_loss = 1.49248635, grad/param norm = 2.5077e-01, time/batch = 19.0818s	
1896/11350 (epoch 8.352), train_loss = 1.32724234, grad/param norm = 2.5572e-01, time/batch = 19.2828s	
1897/11350 (epoch 8.357), train_loss = 1.48133445, grad/param norm = 2.3281e-01, time/batch = 18.8017s	
1898/11350 (epoch 8.361), train_loss = 1.23765803, grad/param norm = 2.3495e-01, time/batch = 20.3651s	
1899/11350 (epoch 8.366), train_loss = 1.67641551, grad/param norm = 2.5616e-01, time/batch = 16.3810s	
1900/11350 (epoch 8.370), train_loss = 1.50823345, grad/param norm = 2.4616e-01, time/batch = 19.2943s	
1901/11350 (epoch 8.374), train_loss = 1.50406878, grad/param norm = 2.7004e-01, time/batch = 18.3696s	
1902/11350 (epoch 8.379), train_loss = 1.59844184, grad/param norm = 2.8578e-01, time/batch = 16.6845s	
1903/11350 (epoch 8.383), train_loss = 1.32942950, grad/param norm = 2.6873e-01, time/batch = 18.5357s	
1904/11350 (epoch 8.388), train_loss = 1.64890512, grad/param norm = 2.8084e-01, time/batch = 18.3690s	
1905/11350 (epoch 8.392), train_loss = 1.58104882, grad/param norm = 3.0304e-01, time/batch = 17.7941s	
1906/11350 (epoch 8.396), train_loss = 1.63283463, grad/param norm = 2.6818e-01, time/batch = 18.7855s	
1907/11350 (epoch 8.401), train_loss = 1.49262102, grad/param norm = 2.3031e-01, time/batch = 18.7962s	
1908/11350 (epoch 8.405), train_loss = 1.63637151, grad/param norm = 2.5048e-01, time/batch = 18.2012s	
1909/11350 (epoch 8.410), train_loss = 1.87157521, grad/param norm = 3.1364e-01, time/batch = 18.9584s	
1910/11350 (epoch 8.414), train_loss = 1.39434742, grad/param norm = 2.5618e-01, time/batch = 19.8046s	
1911/11350 (epoch 8.419), train_loss = 1.69117087, grad/param norm = 3.1299e-01, time/batch = 18.6133s	
1912/11350 (epoch 8.423), train_loss = 1.76491085, grad/param norm = 2.5681e-01, time/batch = 18.9629s	
1913/11350 (epoch 8.427), train_loss = 1.77176503, grad/param norm = 2.9289e-01, time/batch = 17.7697s	
1914/11350 (epoch 8.432), train_loss = 1.83687914, grad/param norm = 2.8370e-01, time/batch = 19.3843s	
1915/11350 (epoch 8.436), train_loss = 1.62653114, grad/param norm = 2.5181e-01, time/batch = 17.4563s	
1916/11350 (epoch 8.441), train_loss = 1.78484179, grad/param norm = 2.9333e-01, time/batch = 17.1101s	
1917/11350 (epoch 8.445), train_loss = 1.26321771, grad/param norm = 2.3108e-01, time/batch = 18.3813s	
1918/11350 (epoch 8.449), train_loss = 1.49235593, grad/param norm = 2.8556e-01, time/batch = 17.3571s	
1919/11350 (epoch 8.454), train_loss = 1.69730920, grad/param norm = 2.7069e-01, time/batch = 19.3861s	
1920/11350 (epoch 8.458), train_loss = 1.31595806, grad/param norm = 2.4100e-01, time/batch = 19.4601s	
1921/11350 (epoch 8.463), train_loss = 1.43033857, grad/param norm = 2.8641e-01, time/batch = 22.8069s	
1922/11350 (epoch 8.467), train_loss = 1.87509221, grad/param norm = 2.8025e-01, time/batch = 29.0082s	
1923/11350 (epoch 8.471), train_loss = 1.75035114, grad/param norm = 3.0504e-01, time/batch = 18.0491s	
1924/11350 (epoch 8.476), train_loss = 1.66081268, grad/param norm = 2.7265e-01, time/batch = 17.0021s	
1925/11350 (epoch 8.480), train_loss = 1.82040773, grad/param norm = 2.7850e-01, time/batch = 18.8013s	
1926/11350 (epoch 8.485), train_loss = 1.48832950, grad/param norm = 2.3414e-01, time/batch = 18.4724s	
1927/11350 (epoch 8.489), train_loss = 1.72358170, grad/param norm = 2.5984e-01, time/batch = 16.2706s	
1928/11350 (epoch 8.493), train_loss = 1.62011604, grad/param norm = 2.4767e-01, time/batch = 18.7084s	
1929/11350 (epoch 8.498), train_loss = 1.29154331, grad/param norm = 2.6466e-01, time/batch = 18.8604s	
1930/11350 (epoch 8.502), train_loss = 1.63372096, grad/param norm = 2.8747e-01, time/batch = 16.4331s	
1931/11350 (epoch 8.507), train_loss = 1.38761185, grad/param norm = 2.2490e-01, time/batch = 19.4559s	
1932/11350 (epoch 8.511), train_loss = 1.84120148, grad/param norm = 2.8047e-01, time/batch = 16.4872s	
1933/11350 (epoch 8.515), train_loss = 1.50910836, grad/param norm = 2.4846e-01, time/batch = 17.3905s	
1934/11350 (epoch 8.520), train_loss = 1.75121661, grad/param norm = 2.6518e-01, time/batch = 17.9443s	
1935/11350 (epoch 8.524), train_loss = 1.55086127, grad/param norm = 2.6029e-01, time/batch = 18.8869s	
1936/11350 (epoch 8.529), train_loss = 1.66980786, grad/param norm = 2.5626e-01, time/batch = 19.1206s	
1937/11350 (epoch 8.533), train_loss = 1.81210004, grad/param norm = 2.4672e-01, time/batch = 17.5405s	
1938/11350 (epoch 8.537), train_loss = 1.64984432, grad/param norm = 2.7690e-01, time/batch = 19.5501s	
1939/11350 (epoch 8.542), train_loss = 1.73281524, grad/param norm = 2.6249e-01, time/batch = 17.9373s	
1940/11350 (epoch 8.546), train_loss = 1.93884492, grad/param norm = 2.9179e-01, time/batch = 19.1158s	
1941/11350 (epoch 8.551), train_loss = 1.53597639, grad/param norm = 2.3633e-01, time/batch = 18.3727s	
1942/11350 (epoch 8.555), train_loss = 1.59081442, grad/param norm = 2.9813e-01, time/batch = 16.6110s	
1943/11350 (epoch 8.559), train_loss = 1.51460873, grad/param norm = 2.2715e-01, time/batch = 19.8361s	
1944/11350 (epoch 8.564), train_loss = 1.73715253, grad/param norm = 2.8732e-01, time/batch = 19.6143s	
1945/11350 (epoch 8.568), train_loss = 1.66981422, grad/param norm = 2.7378e-01, time/batch = 19.0454s	
1946/11350 (epoch 8.573), train_loss = 1.84636061, grad/param norm = 2.6855e-01, time/batch = 20.4448s	
1947/11350 (epoch 8.577), train_loss = 1.84462104, grad/param norm = 2.7077e-01, time/batch = 19.6950s	
1948/11350 (epoch 8.581), train_loss = 1.67726075, grad/param norm = 2.7112e-01, time/batch = 18.3655s	
1949/11350 (epoch 8.586), train_loss = 1.74717440, grad/param norm = 2.5498e-01, time/batch = 16.1951s	
1950/11350 (epoch 8.590), train_loss = 1.86375726, grad/param norm = 2.8360e-01, time/batch = 18.7067s	
1951/11350 (epoch 8.595), train_loss = 1.83605655, grad/param norm = 2.4745e-01, time/batch = 19.2140s	
1952/11350 (epoch 8.599), train_loss = 1.72837861, grad/param norm = 2.6403e-01, time/batch = 20.3701s	
1953/11350 (epoch 8.604), train_loss = 1.59257862, grad/param norm = 2.5126e-01, time/batch = 16.9551s	
1954/11350 (epoch 8.608), train_loss = 1.75953630, grad/param norm = 2.7705e-01, time/batch = 18.9682s	
1955/11350 (epoch 8.612), train_loss = 1.50172601, grad/param norm = 2.5540e-01, time/batch = 18.8667s	
1956/11350 (epoch 8.617), train_loss = 1.86096950, grad/param norm = 2.8803e-01, time/batch = 18.6935s	
1957/11350 (epoch 8.621), train_loss = 1.73391546, grad/param norm = 2.6217e-01, time/batch = 19.1187s	
1958/11350 (epoch 8.626), train_loss = 1.68078422, grad/param norm = 2.6346e-01, time/batch = 20.2078s	
1959/11350 (epoch 8.630), train_loss = 1.74976937, grad/param norm = 2.4850e-01, time/batch = 19.1060s	
1960/11350 (epoch 8.634), train_loss = 1.76707369, grad/param norm = 2.4180e-01, time/batch = 19.1208s	
1961/11350 (epoch 8.639), train_loss = 1.59388884, grad/param norm = 2.5788e-01, time/batch = 19.5340s	
1962/11350 (epoch 8.643), train_loss = 1.61254274, grad/param norm = 2.4765e-01, time/batch = 19.2711s	
1963/11350 (epoch 8.648), train_loss = 1.68256890, grad/param norm = 2.8854e-01, time/batch = 18.6182s	
1964/11350 (epoch 8.652), train_loss = 1.66908629, grad/param norm = 2.8035e-01, time/batch = 16.5287s	
1965/11350 (epoch 8.656), train_loss = 1.82133487, grad/param norm = 2.8903e-01, time/batch = 17.4026s	
1966/11350 (epoch 8.661), train_loss = 1.80317217, grad/param norm = 2.7753e-01, time/batch = 18.9535s	
1967/11350 (epoch 8.665), train_loss = 1.62512195, grad/param norm = 2.8218e-01, time/batch = 20.2061s	
1968/11350 (epoch 8.670), train_loss = 1.69156539, grad/param norm = 2.9378e-01, time/batch = 19.2061s	
1969/11350 (epoch 8.674), train_loss = 1.62475456, grad/param norm = 2.5719e-01, time/batch = 17.5426s	
1970/11350 (epoch 8.678), train_loss = 1.64233743, grad/param norm = 2.4499e-01, time/batch = 18.5070s	
1971/11350 (epoch 8.683), train_loss = 1.57539835, grad/param norm = 2.5613e-01, time/batch = 18.5436s	
1972/11350 (epoch 8.687), train_loss = 1.59000247, grad/param norm = 2.7948e-01, time/batch = 18.7950s	
1973/11350 (epoch 8.692), train_loss = 1.99771284, grad/param norm = 3.2628e-01, time/batch = 17.5509s	
1974/11350 (epoch 8.696), train_loss = 1.74382451, grad/param norm = 2.5400e-01, time/batch = 18.5450s	
1975/11350 (epoch 8.700), train_loss = 1.73311855, grad/param norm = 2.5665e-01, time/batch = 18.1395s	
1976/11350 (epoch 8.705), train_loss = 1.82379958, grad/param norm = 2.6984e-01, time/batch = 17.7245s	
1977/11350 (epoch 8.709), train_loss = 1.81829452, grad/param norm = 2.6886e-01, time/batch = 17.3842s	
1978/11350 (epoch 8.714), train_loss = 1.54501476, grad/param norm = 2.5561e-01, time/batch = 18.8046s	
1979/11350 (epoch 8.718), train_loss = 1.56748117, grad/param norm = 2.8603e-01, time/batch = 18.3864s	
1980/11350 (epoch 8.722), train_loss = 1.76343325, grad/param norm = 2.7111e-01, time/batch = 17.4784s	
1981/11350 (epoch 8.727), train_loss = 1.63002780, grad/param norm = 2.4327e-01, time/batch = 17.5613s	
1982/11350 (epoch 8.731), train_loss = 1.71468447, grad/param norm = 2.4471e-01, time/batch = 16.2645s	
1983/11350 (epoch 8.736), train_loss = 1.68026691, grad/param norm = 2.4433e-01, time/batch = 18.7059s	
1984/11350 (epoch 8.740), train_loss = 1.67532716, grad/param norm = 2.6310e-01, time/batch = 18.2039s	
1985/11350 (epoch 8.744), train_loss = 1.85301914, grad/param norm = 2.4215e-01, time/batch = 18.5356s	
1986/11350 (epoch 8.749), train_loss = 1.81372476, grad/param norm = 2.5920e-01, time/batch = 15.5619s	
1987/11350 (epoch 8.753), train_loss = 1.74106575, grad/param norm = 2.6759e-01, time/batch = 19.2079s	
1988/11350 (epoch 8.758), train_loss = 1.61149567, grad/param norm = 2.5227e-01, time/batch = 18.1362s	
1989/11350 (epoch 8.762), train_loss = 1.69890500, grad/param norm = 2.6815e-01, time/batch = 19.1842s	
1990/11350 (epoch 8.767), train_loss = 1.70120538, grad/param norm = 2.2326e-01, time/batch = 17.3675s	
1991/11350 (epoch 8.771), train_loss = 1.74567491, grad/param norm = 2.7324e-01, time/batch = 18.4363s	
1992/11350 (epoch 8.775), train_loss = 1.58164425, grad/param norm = 2.4138e-01, time/batch = 18.0338s	
1993/11350 (epoch 8.780), train_loss = 1.71484375, grad/param norm = 2.5704e-01, time/batch = 18.9497s	
1994/11350 (epoch 8.784), train_loss = 1.56393669, grad/param norm = 2.6076e-01, time/batch = 20.0403s	
1995/11350 (epoch 8.789), train_loss = 1.65725748, grad/param norm = 2.7569e-01, time/batch = 19.1975s	
1996/11350 (epoch 8.793), train_loss = 1.67115584, grad/param norm = 2.6162e-01, time/batch = 17.6167s	
1997/11350 (epoch 8.797), train_loss = 1.60177442, grad/param norm = 2.6301e-01, time/batch = 16.8966s	
1998/11350 (epoch 8.802), train_loss = 1.68166241, grad/param norm = 2.3892e-01, time/batch = 17.5300s	
1999/11350 (epoch 8.806), train_loss = 1.64752319, grad/param norm = 2.6424e-01, time/batch = 19.6173s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch8.81_1.8304.t7	
2000/11350 (epoch 8.811), train_loss = 1.57651126, grad/param norm = 3.0894e-01, time/batch = 19.7928s	
2001/11350 (epoch 8.815), train_loss = 1.71400107, grad/param norm = 3.5128e-01, time/batch = 19.3005s	
2002/11350 (epoch 8.819), train_loss = 1.57799557, grad/param norm = 2.3819e-01, time/batch = 18.8739s	
2003/11350 (epoch 8.824), train_loss = 1.63778593, grad/param norm = 2.6931e-01, time/batch = 19.0421s	
2004/11350 (epoch 8.828), train_loss = 1.62031931, grad/param norm = 2.5942e-01, time/batch = 20.1117s	
2005/11350 (epoch 8.833), train_loss = 1.72704990, grad/param norm = 3.3309e-01, time/batch = 18.9400s	
2006/11350 (epoch 8.837), train_loss = 1.63766396, grad/param norm = 2.8721e-01, time/batch = 20.0530s	
2007/11350 (epoch 8.841), train_loss = 1.95879647, grad/param norm = 2.7105e-01, time/batch = 18.9477s	
2008/11350 (epoch 8.846), train_loss = 1.57095067, grad/param norm = 2.5854e-01, time/batch = 19.0304s	
2009/11350 (epoch 8.850), train_loss = 1.74408537, grad/param norm = 2.7408e-01, time/batch = 18.8041s	
2010/11350 (epoch 8.855), train_loss = 1.44899661, grad/param norm = 2.5533e-01, time/batch = 20.0367s	
2011/11350 (epoch 8.859), train_loss = 1.65149268, grad/param norm = 2.8485e-01, time/batch = 18.0216s	
2012/11350 (epoch 8.863), train_loss = 1.51043655, grad/param norm = 2.7821e-01, time/batch = 18.6201s	
2013/11350 (epoch 8.868), train_loss = 1.65733065, grad/param norm = 2.5864e-01, time/batch = 19.9557s	
2014/11350 (epoch 8.872), train_loss = 1.61513644, grad/param norm = 2.5804e-01, time/batch = 17.4472s	
2015/11350 (epoch 8.877), train_loss = 1.60786508, grad/param norm = 2.7193e-01, time/batch = 19.2557s	
2016/11350 (epoch 8.881), train_loss = 1.92262851, grad/param norm = 3.0213e-01, time/batch = 18.2842s	
2017/11350 (epoch 8.885), train_loss = 1.86785796, grad/param norm = 2.7568e-01, time/batch = 19.0117s	
2018/11350 (epoch 8.890), train_loss = 1.69557387, grad/param norm = 2.4150e-01, time/batch = 19.2746s	
2019/11350 (epoch 8.894), train_loss = 1.47071482, grad/param norm = 2.3104e-01, time/batch = 17.1072s	
2020/11350 (epoch 8.899), train_loss = 1.72903970, grad/param norm = 2.3878e-01, time/batch = 20.1004s	
2021/11350 (epoch 8.903), train_loss = 1.84109185, grad/param norm = 2.7161e-01, time/batch = 18.7779s	
2022/11350 (epoch 8.907), train_loss = 1.78670844, grad/param norm = 2.5331e-01, time/batch = 18.2940s	
2023/11350 (epoch 8.912), train_loss = 1.65010354, grad/param norm = 3.0293e-01, time/batch = 18.6201s	
2024/11350 (epoch 8.916), train_loss = 1.75027110, grad/param norm = 2.4887e-01, time/batch = 18.6309s	
2025/11350 (epoch 8.921), train_loss = 1.70178319, grad/param norm = 2.7767e-01, time/batch = 20.1956s	
2026/11350 (epoch 8.925), train_loss = 1.50752010, grad/param norm = 2.4035e-01, time/batch = 18.3668s	
2027/11350 (epoch 8.930), train_loss = 1.74712643, grad/param norm = 2.6084e-01, time/batch = 17.8398s	
2028/11350 (epoch 8.934), train_loss = 1.82713149, grad/param norm = 2.9476e-01, time/batch = 19.5403s	
2029/11350 (epoch 8.938), train_loss = 1.59019046, grad/param norm = 2.8559e-01, time/batch = 19.7044s	
2030/11350 (epoch 8.943), train_loss = 1.78483553, grad/param norm = 3.0461e-01, time/batch = 19.0168s	
2031/11350 (epoch 8.947), train_loss = 1.88710084, grad/param norm = 3.8749e-01, time/batch = 3.2778s	
2032/11350 (epoch 8.952), train_loss = 1.76157816, grad/param norm = 2.4349e-01, time/batch = 0.6853s	
2033/11350 (epoch 8.956), train_loss = 1.48533668, grad/param norm = 3.1163e-01, time/batch = 0.6896s	
2034/11350 (epoch 8.960), train_loss = 1.71024202, grad/param norm = 3.5033e-01, time/batch = 0.6914s	
2035/11350 (epoch 8.965), train_loss = 1.56097315, grad/param norm = 2.8933e-01, time/batch = 0.7220s	
2036/11350 (epoch 8.969), train_loss = 1.63784677, grad/param norm = 3.2621e-01, time/batch = 0.7108s	
2037/11350 (epoch 8.974), train_loss = 1.46257190, grad/param norm = 2.6084e-01, time/batch = 0.6985s	
2038/11350 (epoch 8.978), train_loss = 1.69893275, grad/param norm = 2.6944e-01, time/batch = 0.9243s	
2039/11350 (epoch 8.982), train_loss = 1.39469851, grad/param norm = 2.1922e-01, time/batch = 1.0493s	
2040/11350 (epoch 8.987), train_loss = 1.56948133, grad/param norm = 2.6137e-01, time/batch = 1.0243s	
2041/11350 (epoch 8.991), train_loss = 1.47510910, grad/param norm = 2.7856e-01, time/batch = 1.0024s	
2042/11350 (epoch 8.996), train_loss = 1.75151242, grad/param norm = 3.1035e-01, time/batch = 1.0042s	
2043/11350 (epoch 9.000), train_loss = 1.32792352, grad/param norm = 2.6303e-01, time/batch = 1.7406s	
2044/11350 (epoch 9.004), train_loss = 1.60053064, grad/param norm = 2.7313e-01, time/batch = 1.9473s	
2045/11350 (epoch 9.009), train_loss = 1.75942567, grad/param norm = 2.7161e-01, time/batch = 5.8611s	
2046/11350 (epoch 9.013), train_loss = 1.14941575, grad/param norm = 2.3461e-01, time/batch = 19.4580s	
2047/11350 (epoch 9.018), train_loss = 1.22294140, grad/param norm = 2.5610e-01, time/batch = 18.9456s	
2048/11350 (epoch 9.022), train_loss = 1.27306382, grad/param norm = 2.4472e-01, time/batch = 19.8567s	
2049/11350 (epoch 9.026), train_loss = 1.40558094, grad/param norm = 2.4410e-01, time/batch = 19.2705s	
2050/11350 (epoch 9.031), train_loss = 1.24533834, grad/param norm = 2.6014e-01, time/batch = 19.1013s	
2051/11350 (epoch 9.035), train_loss = 1.39243766, grad/param norm = 2.5861e-01, time/batch = 19.4559s	
2052/11350 (epoch 9.040), train_loss = 1.43751518, grad/param norm = 2.7555e-01, time/batch = 19.8724s	
2053/11350 (epoch 9.044), train_loss = 1.36516387, grad/param norm = 2.2342e-01, time/batch = 18.9487s	
2054/11350 (epoch 9.048), train_loss = 1.37685135, grad/param norm = 2.3160e-01, time/batch = 19.1186s	
2055/11350 (epoch 9.053), train_loss = 1.41624188, grad/param norm = 2.3087e-01, time/batch = 18.6298s	
2056/11350 (epoch 9.057), train_loss = 1.55955859, grad/param norm = 2.6266e-01, time/batch = 17.3269s	
2057/11350 (epoch 9.062), train_loss = 1.24286366, grad/param norm = 2.2694e-01, time/batch = 18.9404s	
2058/11350 (epoch 9.066), train_loss = 1.25399677, grad/param norm = 2.4270e-01, time/batch = 18.8554s	
2059/11350 (epoch 9.070), train_loss = 1.39818830, grad/param norm = 2.3623e-01, time/batch = 19.5431s	
2060/11350 (epoch 9.075), train_loss = 1.28569938, grad/param norm = 2.4103e-01, time/batch = 17.6018s	
2061/11350 (epoch 9.079), train_loss = 1.42847594, grad/param norm = 2.5672e-01, time/batch = 17.3016s	
2062/11350 (epoch 9.084), train_loss = 1.67600222, grad/param norm = 2.4852e-01, time/batch = 18.6306s	
2063/11350 (epoch 9.088), train_loss = 1.60154848, grad/param norm = 2.5926e-01, time/batch = 19.0329s	
2064/11350 (epoch 9.093), train_loss = 1.46207939, grad/param norm = 2.4511e-01, time/batch = 20.0506s	
2065/11350 (epoch 9.097), train_loss = 1.49775771, grad/param norm = 2.5545e-01, time/batch = 19.0468s	
2066/11350 (epoch 9.101), train_loss = 1.34377945, grad/param norm = 2.3691e-01, time/batch = 19.8576s	
2067/11350 (epoch 9.106), train_loss = 1.61010856, grad/param norm = 2.5260e-01, time/batch = 19.9541s	
2068/11350 (epoch 9.110), train_loss = 1.40728800, grad/param norm = 2.4821e-01, time/batch = 18.6193s	
2069/11350 (epoch 9.115), train_loss = 1.38141522, grad/param norm = 2.2673e-01, time/batch = 19.5289s	
2070/11350 (epoch 9.119), train_loss = 1.59864363, grad/param norm = 2.6483e-01, time/batch = 18.6274s	
2071/11350 (epoch 9.123), train_loss = 1.36142389, grad/param norm = 2.3462e-01, time/batch = 20.1188s	
2072/11350 (epoch 9.128), train_loss = 1.40753990, grad/param norm = 2.3886e-01, time/batch = 17.5225s	
2073/11350 (epoch 9.132), train_loss = 1.44465906, grad/param norm = 2.3856e-01, time/batch = 17.5569s	
2074/11350 (epoch 9.137), train_loss = 1.34018167, grad/param norm = 2.4421e-01, time/batch = 18.6324s	
2075/11350 (epoch 9.141), train_loss = 1.57012733, grad/param norm = 2.9453e-01, time/batch = 15.6986s	
2076/11350 (epoch 9.145), train_loss = 1.37471904, grad/param norm = 2.3922e-01, time/batch = 17.5205s	
2077/11350 (epoch 9.150), train_loss = 1.60087396, grad/param norm = 2.7463e-01, time/batch = 19.7054s	
2078/11350 (epoch 9.154), train_loss = 1.66137153, grad/param norm = 2.5212e-01, time/batch = 17.8759s	
2079/11350 (epoch 9.159), train_loss = 1.36079344, grad/param norm = 2.7612e-01, time/batch = 18.0094s	
2080/11350 (epoch 9.163), train_loss = 1.60444647, grad/param norm = 2.8044e-01, time/batch = 19.1073s	
2081/11350 (epoch 9.167), train_loss = 1.63210825, grad/param norm = 2.5060e-01, time/batch = 19.1954s	
2082/11350 (epoch 9.172), train_loss = 1.79133500, grad/param norm = 2.7563e-01, time/batch = 18.4552s	
2083/11350 (epoch 9.176), train_loss = 1.54779903, grad/param norm = 2.6697e-01, time/batch = 19.6886s	
2084/11350 (epoch 9.181), train_loss = 1.55155761, grad/param norm = 2.7574e-01, time/batch = 18.6318s	
2085/11350 (epoch 9.185), train_loss = 1.45881536, grad/param norm = 2.6444e-01, time/batch = 19.1247s	
2086/11350 (epoch 9.189), train_loss = 1.42181849, grad/param norm = 2.6189e-01, time/batch = 16.6826s	
2087/11350 (epoch 9.194), train_loss = 1.37186009, grad/param norm = 3.4763e-01, time/batch = 19.5418s	
2088/11350 (epoch 9.198), train_loss = 1.42308873, grad/param norm = 2.6008e-01, time/batch = 18.3004s	
2089/11350 (epoch 9.203), train_loss = 1.29534819, grad/param norm = 2.3865e-01, time/batch = 18.6858s	
2090/11350 (epoch 9.207), train_loss = 1.38512015, grad/param norm = 2.6774e-01, time/batch = 17.8888s	
2091/11350 (epoch 9.211), train_loss = 1.54223954, grad/param norm = 2.5880e-01, time/batch = 20.6233s	
2092/11350 (epoch 9.216), train_loss = 1.50951765, grad/param norm = 3.3729e-01, time/batch = 17.4431s	
2093/11350 (epoch 9.220), train_loss = 1.47180697, grad/param norm = 2.4499e-01, time/batch = 19.6253s	
2094/11350 (epoch 9.225), train_loss = 1.33541598, grad/param norm = 2.8483e-01, time/batch = 20.0322s	
2095/11350 (epoch 9.229), train_loss = 1.57638126, grad/param norm = 2.4280e-01, time/batch = 17.1187s	
2096/11350 (epoch 9.233), train_loss = 1.49761813, grad/param norm = 2.5048e-01, time/batch = 16.6464s	
2097/11350 (epoch 9.238), train_loss = 1.73954779, grad/param norm = 2.9669e-01, time/batch = 16.3491s	
2098/11350 (epoch 9.242), train_loss = 1.76322743, grad/param norm = 2.7765e-01, time/batch = 18.6922s	
2099/11350 (epoch 9.247), train_loss = 1.26677046, grad/param norm = 2.3353e-01, time/batch = 16.2101s	
2100/11350 (epoch 9.251), train_loss = 1.56144976, grad/param norm = 2.7269e-01, time/batch = 19.2840s	
2101/11350 (epoch 9.256), train_loss = 1.64391602, grad/param norm = 2.8190e-01, time/batch = 20.5394s	
2102/11350 (epoch 9.260), train_loss = 1.44229827, grad/param norm = 2.4482e-01, time/batch = 19.1138s	
2103/11350 (epoch 9.264), train_loss = 1.44095005, grad/param norm = 2.2942e-01, time/batch = 17.0248s	
2104/11350 (epoch 9.269), train_loss = 1.47787501, grad/param norm = 2.4090e-01, time/batch = 18.7741s	
2105/11350 (epoch 9.273), train_loss = 1.62548807, grad/param norm = 2.4909e-01, time/batch = 17.1998s	
2106/11350 (epoch 9.278), train_loss = 1.30641575, grad/param norm = 2.1377e-01, time/batch = 19.5382s	
2107/11350 (epoch 9.282), train_loss = 1.59285091, grad/param norm = 2.9007e-01, time/batch = 19.2029s	
2108/11350 (epoch 9.286), train_loss = 1.69131410, grad/param norm = 3.3300e-01, time/batch = 18.3644s	
2109/11350 (epoch 9.291), train_loss = 1.29943879, grad/param norm = 2.5540e-01, time/batch = 18.7155s	
2110/11350 (epoch 9.295), train_loss = 1.50366869, grad/param norm = 2.3328e-01, time/batch = 18.6360s	
2111/11350 (epoch 9.300), train_loss = 1.46883757, grad/param norm = 2.5007e-01, time/batch = 18.4342s	
2112/11350 (epoch 9.304), train_loss = 1.40727778, grad/param norm = 2.3831e-01, time/batch = 18.8582s	
2113/11350 (epoch 9.308), train_loss = 1.42055252, grad/param norm = 2.4079e-01, time/batch = 17.9378s	
2114/11350 (epoch 9.313), train_loss = 1.54347144, grad/param norm = 2.3835e-01, time/batch = 16.5256s	
2115/11350 (epoch 9.317), train_loss = 1.27053983, grad/param norm = 2.3663e-01, time/batch = 17.6971s	
2116/11350 (epoch 9.322), train_loss = 1.37737392, grad/param norm = 2.5095e-01, time/batch = 19.1398s	
2117/11350 (epoch 9.326), train_loss = 1.44899907, grad/param norm = 2.5157e-01, time/batch = 19.9661s	
2118/11350 (epoch 9.330), train_loss = 1.23247566, grad/param norm = 2.5581e-01, time/batch = 18.0445s	
2119/11350 (epoch 9.335), train_loss = 1.19916632, grad/param norm = 2.2598e-01, time/batch = 19.5306s	
2120/11350 (epoch 9.339), train_loss = 1.31039299, grad/param norm = 2.2528e-01, time/batch = 17.7886s	
2121/11350 (epoch 9.344), train_loss = 1.41201889, grad/param norm = 2.3945e-01, time/batch = 19.0210s	
2122/11350 (epoch 9.348), train_loss = 1.41824543, grad/param norm = 2.4899e-01, time/batch = 20.5498s	
2123/11350 (epoch 9.352), train_loss = 1.25819982, grad/param norm = 2.4691e-01, time/batch = 19.6872s	
2124/11350 (epoch 9.357), train_loss = 1.40784280, grad/param norm = 2.4331e-01, time/batch = 24.5908s	
2125/11350 (epoch 9.361), train_loss = 1.18001922, grad/param norm = 2.2727e-01, time/batch = 26.5907s	
2126/11350 (epoch 9.366), train_loss = 1.60823779, grad/param norm = 2.4942e-01, time/batch = 19.7827s	
2127/11350 (epoch 9.370), train_loss = 1.42772825, grad/param norm = 2.5279e-01, time/batch = 18.3789s	
2128/11350 (epoch 9.374), train_loss = 1.42304418, grad/param norm = 2.6260e-01, time/batch = 20.0168s	
2129/11350 (epoch 9.379), train_loss = 1.50785258, grad/param norm = 2.8178e-01, time/batch = 19.6816s	
2130/11350 (epoch 9.383), train_loss = 1.24407557, grad/param norm = 2.4686e-01, time/batch = 18.6980s	
2131/11350 (epoch 9.388), train_loss = 1.56965796, grad/param norm = 2.8365e-01, time/batch = 19.8698s	
2132/11350 (epoch 9.392), train_loss = 1.48302418, grad/param norm = 3.0155e-01, time/batch = 17.9432s	
2133/11350 (epoch 9.396), train_loss = 1.56795975, grad/param norm = 2.7394e-01, time/batch = 17.5384s	
2134/11350 (epoch 9.401), train_loss = 1.43197181, grad/param norm = 2.5842e-01, time/batch = 19.3038s	
2135/11350 (epoch 9.405), train_loss = 1.57779241, grad/param norm = 2.4275e-01, time/batch = 16.0345s	
2136/11350 (epoch 9.410), train_loss = 1.76752066, grad/param norm = 3.0482e-01, time/batch = 18.0212s	
2137/11350 (epoch 9.414), train_loss = 1.31593653, grad/param norm = 2.5365e-01, time/batch = 19.5228s	
2138/11350 (epoch 9.419), train_loss = 1.57342521, grad/param norm = 2.9646e-01, time/batch = 19.7010s	
2139/11350 (epoch 9.423), train_loss = 1.66498604, grad/param norm = 2.4989e-01, time/batch = 18.1999s	
2140/11350 (epoch 9.427), train_loss = 1.68177264, grad/param norm = 2.8387e-01, time/batch = 18.9593s	
2141/11350 (epoch 9.432), train_loss = 1.72463100, grad/param norm = 2.7985e-01, time/batch = 18.7177s	
2142/11350 (epoch 9.436), train_loss = 1.53543299, grad/param norm = 2.6617e-01, time/batch = 19.6982s	
2143/11350 (epoch 9.441), train_loss = 1.72600310, grad/param norm = 2.9489e-01, time/batch = 16.9726s	
2144/11350 (epoch 9.445), train_loss = 1.20238637, grad/param norm = 2.3383e-01, time/batch = 19.2998s	
2145/11350 (epoch 9.449), train_loss = 1.41029820, grad/param norm = 2.7500e-01, time/batch = 20.4562s	
2146/11350 (epoch 9.454), train_loss = 1.63833815, grad/param norm = 2.7730e-01, time/batch = 19.0257s	
2147/11350 (epoch 9.458), train_loss = 1.24350055, grad/param norm = 2.4988e-01, time/batch = 20.2846s	
2148/11350 (epoch 9.463), train_loss = 1.34506438, grad/param norm = 2.6503e-01, time/batch = 19.7064s	
2149/11350 (epoch 9.467), train_loss = 1.80827036, grad/param norm = 2.9933e-01, time/batch = 19.1838s	
2150/11350 (epoch 9.471), train_loss = 1.67987103, grad/param norm = 3.4642e-01, time/batch = 18.7760s	
2151/11350 (epoch 9.476), train_loss = 1.59110624, grad/param norm = 2.7161e-01, time/batch = 16.5550s	
2152/11350 (epoch 9.480), train_loss = 1.74494071, grad/param norm = 2.7656e-01, time/batch = 18.2832s	
2153/11350 (epoch 9.485), train_loss = 1.42898180, grad/param norm = 2.2888e-01, time/batch = 19.7033s	
2154/11350 (epoch 9.489), train_loss = 1.65266739, grad/param norm = 2.6023e-01, time/batch = 17.7219s	
2155/11350 (epoch 9.493), train_loss = 1.55312610, grad/param norm = 2.4551e-01, time/batch = 16.1657s	
2156/11350 (epoch 9.498), train_loss = 1.22913897, grad/param norm = 2.5353e-01, time/batch = 18.0434s	
2157/11350 (epoch 9.502), train_loss = 1.54647811, grad/param norm = 2.5711e-01, time/batch = 19.6160s	
2158/11350 (epoch 9.507), train_loss = 1.31202922, grad/param norm = 2.2934e-01, time/batch = 18.9642s	
2159/11350 (epoch 9.511), train_loss = 1.76777183, grad/param norm = 2.7372e-01, time/batch = 18.5398s	
2160/11350 (epoch 9.515), train_loss = 1.44249409, grad/param norm = 2.4377e-01, time/batch = 20.4506s	
2161/11350 (epoch 9.520), train_loss = 1.68711071, grad/param norm = 2.7157e-01, time/batch = 19.1979s	
2162/11350 (epoch 9.524), train_loss = 1.47549507, grad/param norm = 2.5088e-01, time/batch = 20.3675s	
2163/11350 (epoch 9.529), train_loss = 1.57821420, grad/param norm = 2.5248e-01, time/batch = 18.8778s	
2164/11350 (epoch 9.533), train_loss = 1.76077799, grad/param norm = 2.4885e-01, time/batch = 18.6978s	
2165/11350 (epoch 9.537), train_loss = 1.58565812, grad/param norm = 2.6988e-01, time/batch = 19.0336s	
2166/11350 (epoch 9.542), train_loss = 1.65178727, grad/param norm = 2.5159e-01, time/batch = 16.0423s	
2167/11350 (epoch 9.546), train_loss = 1.87119816, grad/param norm = 2.7952e-01, time/batch = 19.1214s	
2168/11350 (epoch 9.551), train_loss = 1.47712281, grad/param norm = 2.6333e-01, time/batch = 18.4349s	
2169/11350 (epoch 9.555), train_loss = 1.51167054, grad/param norm = 3.6727e-01, time/batch = 18.4641s	
2170/11350 (epoch 9.559), train_loss = 1.44368068, grad/param norm = 2.5321e-01, time/batch = 16.5938s	
2171/11350 (epoch 9.564), train_loss = 1.67006798, grad/param norm = 2.8015e-01, time/batch = 17.8648s	
2172/11350 (epoch 9.568), train_loss = 1.58307354, grad/param norm = 2.7019e-01, time/batch = 18.7139s	
2173/11350 (epoch 9.573), train_loss = 1.77489554, grad/param norm = 2.7699e-01, time/batch = 19.4375s	
2174/11350 (epoch 9.577), train_loss = 1.77922864, grad/param norm = 3.0278e-01, time/batch = 18.8739s	
2175/11350 (epoch 9.581), train_loss = 1.62833462, grad/param norm = 2.6875e-01, time/batch = 19.7107s	
2176/11350 (epoch 9.586), train_loss = 1.67964926, grad/param norm = 2.5880e-01, time/batch = 19.8704s	
2177/11350 (epoch 9.590), train_loss = 1.78644743, grad/param norm = 2.6904e-01, time/batch = 18.7765s	
2178/11350 (epoch 9.595), train_loss = 1.76550873, grad/param norm = 2.4168e-01, time/batch = 20.6003s	
2179/11350 (epoch 9.599), train_loss = 1.65243992, grad/param norm = 2.6314e-01, time/batch = 19.0313s	
2180/11350 (epoch 9.604), train_loss = 1.52550171, grad/param norm = 2.5419e-01, time/batch = 16.6633s	
2181/11350 (epoch 9.608), train_loss = 1.67687460, grad/param norm = 2.7459e-01, time/batch = 18.7738s	
2182/11350 (epoch 9.612), train_loss = 1.43358781, grad/param norm = 2.3897e-01, time/batch = 18.9641s	
2183/11350 (epoch 9.617), train_loss = 1.78025122, grad/param norm = 2.7526e-01, time/batch = 18.3760s	
2184/11350 (epoch 9.621), train_loss = 1.67088170, grad/param norm = 2.5477e-01, time/batch = 18.5278s	
2185/11350 (epoch 9.626), train_loss = 1.61663434, grad/param norm = 2.6472e-01, time/batch = 18.8788s	
2186/11350 (epoch 9.630), train_loss = 1.65907787, grad/param norm = 2.4073e-01, time/batch = 18.8631s	
2187/11350 (epoch 9.634), train_loss = 1.69287445, grad/param norm = 2.4899e-01, time/batch = 18.1999s	
2188/11350 (epoch 9.639), train_loss = 1.52064797, grad/param norm = 2.4941e-01, time/batch = 15.9373s	
2189/11350 (epoch 9.643), train_loss = 1.53101482, grad/param norm = 2.4212e-01, time/batch = 16.0888s	
2190/11350 (epoch 9.648), train_loss = 1.60575576, grad/param norm = 2.8150e-01, time/batch = 16.8705s	
2191/11350 (epoch 9.652), train_loss = 1.60193522, grad/param norm = 2.8392e-01, time/batch = 16.4955s	
2192/11350 (epoch 9.656), train_loss = 1.75214343, grad/param norm = 2.9317e-01, time/batch = 15.0241s	
2193/11350 (epoch 9.661), train_loss = 1.73633721, grad/param norm = 2.7174e-01, time/batch = 16.1768s	
2194/11350 (epoch 9.665), train_loss = 1.55910156, grad/param norm = 2.7266e-01, time/batch = 18.4470s	
2195/11350 (epoch 9.670), train_loss = 1.60401558, grad/param norm = 2.7275e-01, time/batch = 19.9579s	
2196/11350 (epoch 9.674), train_loss = 1.53357310, grad/param norm = 2.3979e-01, time/batch = 18.9440s	
2197/11350 (epoch 9.678), train_loss = 1.55773182, grad/param norm = 2.3672e-01, time/batch = 18.7002s	
2198/11350 (epoch 9.683), train_loss = 1.49049223, grad/param norm = 2.4329e-01, time/batch = 20.0330s	
2199/11350 (epoch 9.687), train_loss = 1.50346919, grad/param norm = 2.6690e-01, time/batch = 19.8592s	
2200/11350 (epoch 9.692), train_loss = 1.91430108, grad/param norm = 3.0192e-01, time/batch = 17.7337s	
2201/11350 (epoch 9.696), train_loss = 1.68589881, grad/param norm = 2.5933e-01, time/batch = 15.4847s	
2202/11350 (epoch 9.700), train_loss = 1.65531475, grad/param norm = 2.5853e-01, time/batch = 19.2810s	
2203/11350 (epoch 9.705), train_loss = 1.74364241, grad/param norm = 2.6923e-01, time/batch = 20.2049s	
2204/11350 (epoch 9.709), train_loss = 1.72895203, grad/param norm = 2.3436e-01, time/batch = 18.1051s	
2205/11350 (epoch 9.714), train_loss = 1.47276330, grad/param norm = 2.4799e-01, time/batch = 17.4304s	
2206/11350 (epoch 9.718), train_loss = 1.47070274, grad/param norm = 2.7894e-01, time/batch = 15.3079s	
2207/11350 (epoch 9.722), train_loss = 1.68611107, grad/param norm = 2.8309e-01, time/batch = 19.1125s	
2208/11350 (epoch 9.727), train_loss = 1.57433921, grad/param norm = 2.6031e-01, time/batch = 19.1936s	
2209/11350 (epoch 9.731), train_loss = 1.65068970, grad/param norm = 2.5340e-01, time/batch = 19.3815s	
2210/11350 (epoch 9.736), train_loss = 1.59862595, grad/param norm = 2.5247e-01, time/batch = 19.7759s	
2211/11350 (epoch 9.740), train_loss = 1.59485494, grad/param norm = 2.7997e-01, time/batch = 19.1030s	
2212/11350 (epoch 9.744), train_loss = 1.77309798, grad/param norm = 2.5203e-01, time/batch = 19.2147s	
2213/11350 (epoch 9.749), train_loss = 1.72676290, grad/param norm = 2.5434e-01, time/batch = 19.3594s	
2214/11350 (epoch 9.753), train_loss = 1.67281009, grad/param norm = 2.6317e-01, time/batch = 19.3725s	
2215/11350 (epoch 9.758), train_loss = 1.55234534, grad/param norm = 2.5441e-01, time/batch = 18.3926s	
2216/11350 (epoch 9.762), train_loss = 1.62922165, grad/param norm = 2.6582e-01, time/batch = 18.5363s	
2217/11350 (epoch 9.767), train_loss = 1.63493575, grad/param norm = 2.2983e-01, time/batch = 17.6506s	
2218/11350 (epoch 9.771), train_loss = 1.67930221, grad/param norm = 2.5672e-01, time/batch = 19.3570s	
2219/11350 (epoch 9.775), train_loss = 1.51318175, grad/param norm = 2.3585e-01, time/batch = 20.0415s	
2220/11350 (epoch 9.780), train_loss = 1.65403436, grad/param norm = 2.5671e-01, time/batch = 16.5384s	
2221/11350 (epoch 9.784), train_loss = 1.49539414, grad/param norm = 2.6756e-01, time/batch = 19.8785s	
2222/11350 (epoch 9.789), train_loss = 1.58044046, grad/param norm = 2.8626e-01, time/batch = 19.1140s	
2223/11350 (epoch 9.793), train_loss = 1.60953126, grad/param norm = 2.6111e-01, time/batch = 19.0986s	
2224/11350 (epoch 9.797), train_loss = 1.52804546, grad/param norm = 2.5267e-01, time/batch = 18.8851s	
2225/11350 (epoch 9.802), train_loss = 1.59815311, grad/param norm = 2.4337e-01, time/batch = 19.3802s	
2226/11350 (epoch 9.806), train_loss = 1.57764743, grad/param norm = 2.4784e-01, time/batch = 18.5274s	
2227/11350 (epoch 9.811), train_loss = 1.50918286, grad/param norm = 3.0561e-01, time/batch = 18.8671s	
2228/11350 (epoch 9.815), train_loss = 1.38776041, grad/param norm = 2.7307e-01, time/batch = 17.2687s	
2229/11350 (epoch 9.819), train_loss = 1.50344292, grad/param norm = 2.3060e-01, time/batch = 18.1991s	
2230/11350 (epoch 9.824), train_loss = 1.56168825, grad/param norm = 2.6272e-01, time/batch = 18.3753s	
2231/11350 (epoch 9.828), train_loss = 1.54797546, grad/param norm = 2.5419e-01, time/batch = 20.0379s	
2232/11350 (epoch 9.833), train_loss = 1.63516467, grad/param norm = 3.1831e-01, time/batch = 17.5327s	
2233/11350 (epoch 9.837), train_loss = 1.57185950, grad/param norm = 2.7806e-01, time/batch = 18.8683s	
2234/11350 (epoch 9.841), train_loss = 1.88023603, grad/param norm = 2.6001e-01, time/batch = 19.7041s	
2235/11350 (epoch 9.846), train_loss = 1.51224974, grad/param norm = 2.5454e-01, time/batch = 18.7876s	
2236/11350 (epoch 9.850), train_loss = 1.68161584, grad/param norm = 2.8022e-01, time/batch = 17.9312s	
2237/11350 (epoch 9.855), train_loss = 1.38530062, grad/param norm = 2.5397e-01, time/batch = 19.4728s	
2238/11350 (epoch 9.859), train_loss = 1.58723965, grad/param norm = 2.9692e-01, time/batch = 19.8733s	
2239/11350 (epoch 9.863), train_loss = 1.44649277, grad/param norm = 2.8067e-01, time/batch = 18.8612s	
2240/11350 (epoch 9.868), train_loss = 1.58206016, grad/param norm = 2.5735e-01, time/batch = 16.5144s	
2241/11350 (epoch 9.872), train_loss = 1.54466056, grad/param norm = 2.5089e-01, time/batch = 19.1047s	
2242/11350 (epoch 9.877), train_loss = 1.53849503, grad/param norm = 2.6787e-01, time/batch = 18.5421s	
2243/11350 (epoch 9.881), train_loss = 1.85211864, grad/param norm = 3.0697e-01, time/batch = 19.9481s	
2244/11350 (epoch 9.885), train_loss = 1.80301501, grad/param norm = 2.7480e-01, time/batch = 19.3734s	
2245/11350 (epoch 9.890), train_loss = 1.63402465, grad/param norm = 2.5444e-01, time/batch = 18.8613s	
2246/11350 (epoch 9.894), train_loss = 1.39553801, grad/param norm = 2.3367e-01, time/batch = 18.7074s	
2247/11350 (epoch 9.899), train_loss = 1.66243035, grad/param norm = 2.3783e-01, time/batch = 20.7752s	
2248/11350 (epoch 9.903), train_loss = 1.74287668, grad/param norm = 2.4697e-01, time/batch = 17.1991s	
2249/11350 (epoch 9.907), train_loss = 1.68401386, grad/param norm = 2.4482e-01, time/batch = 19.2877s	
2250/11350 (epoch 9.912), train_loss = 1.56790096, grad/param norm = 2.7298e-01, time/batch = 16.9504s	
2251/11350 (epoch 9.916), train_loss = 1.69455434, grad/param norm = 2.8702e-01, time/batch = 20.1034s	
2252/11350 (epoch 9.921), train_loss = 1.64633762, grad/param norm = 2.9153e-01, time/batch = 18.4289s	
2253/11350 (epoch 9.925), train_loss = 1.43847161, grad/param norm = 2.4743e-01, time/batch = 18.6299s	
2254/11350 (epoch 9.930), train_loss = 1.67792526, grad/param norm = 2.6221e-01, time/batch = 20.6908s	
2255/11350 (epoch 9.934), train_loss = 1.76296298, grad/param norm = 3.0442e-01, time/batch = 19.4304s	
2256/11350 (epoch 9.938), train_loss = 1.51117175, grad/param norm = 2.7517e-01, time/batch = 19.0394s	
2257/11350 (epoch 9.943), train_loss = 1.71309892, grad/param norm = 2.7989e-01, time/batch = 21.0253s	
2258/11350 (epoch 9.947), train_loss = 1.78557632, grad/param norm = 3.2860e-01, time/batch = 18.5996s	
2259/11350 (epoch 9.952), train_loss = 1.69290905, grad/param norm = 2.5445e-01, time/batch = 19.0257s	
2260/11350 (epoch 9.956), train_loss = 1.39524298, grad/param norm = 2.8800e-01, time/batch = 19.0163s	
2261/11350 (epoch 9.960), train_loss = 1.61233236, grad/param norm = 2.9153e-01, time/batch = 19.0287s	
2262/11350 (epoch 9.965), train_loss = 1.47040688, grad/param norm = 2.6339e-01, time/batch = 20.3743s	
2263/11350 (epoch 9.969), train_loss = 1.53692598, grad/param norm = 3.1294e-01, time/batch = 18.7006s	
2264/11350 (epoch 9.974), train_loss = 1.39596149, grad/param norm = 2.6543e-01, time/batch = 18.6867s	
2265/11350 (epoch 9.978), train_loss = 1.61827934, grad/param norm = 2.6921e-01, time/batch = 19.2875s	
2266/11350 (epoch 9.982), train_loss = 1.31200851, grad/param norm = 2.3498e-01, time/batch = 19.9531s	
2267/11350 (epoch 9.987), train_loss = 1.51293534, grad/param norm = 2.8671e-01, time/batch = 18.0201s	
2268/11350 (epoch 9.991), train_loss = 1.40610093, grad/param norm = 2.5975e-01, time/batch = 18.5442s	
2269/11350 (epoch 9.996), train_loss = 1.65146533, grad/param norm = 3.0959e-01, time/batch = 17.4492s	
decayed learning rate by a factor 0.97 to 0.00194	
2270/11350 (epoch 10.000), train_loss = 1.27040785, grad/param norm = 2.9385e-01, time/batch = 17.3339s	
2271/11350 (epoch 10.004), train_loss = 1.53289154, grad/param norm = 2.7135e-01, time/batch = 19.2763s	
2272/11350 (epoch 10.009), train_loss = 1.68055810, grad/param norm = 2.8333e-01, time/batch = 18.8623s	
2273/11350 (epoch 10.013), train_loss = 1.07229246, grad/param norm = 2.1493e-01, time/batch = 19.2009s	
2274/11350 (epoch 10.018), train_loss = 1.16143171, grad/param norm = 2.5391e-01, time/batch = 20.1875s	
2275/11350 (epoch 10.022), train_loss = 1.20789046, grad/param norm = 2.4487e-01, time/batch = 19.0506s	
2276/11350 (epoch 10.026), train_loss = 1.32081265, grad/param norm = 2.4725e-01, time/batch = 19.5441s	
2277/11350 (epoch 10.031), train_loss = 1.20311874, grad/param norm = 2.6133e-01, time/batch = 17.8754s	
2278/11350 (epoch 10.035), train_loss = 1.33361785, grad/param norm = 2.6136e-01, time/batch = 16.5411s	
2279/11350 (epoch 10.040), train_loss = 1.36496849, grad/param norm = 2.5759e-01, time/batch = 18.8759s	
2280/11350 (epoch 10.044), train_loss = 1.30590725, grad/param norm = 2.2981e-01, time/batch = 18.4265s	
2281/11350 (epoch 10.048), train_loss = 1.30295692, grad/param norm = 2.3131e-01, time/batch = 18.7181s	
2282/11350 (epoch 10.053), train_loss = 1.36298972, grad/param norm = 2.2786e-01, time/batch = 19.3656s	
2283/11350 (epoch 10.057), train_loss = 1.48738713, grad/param norm = 2.6462e-01, time/batch = 17.9440s	
2284/11350 (epoch 10.062), train_loss = 1.18840123, grad/param norm = 2.3146e-01, time/batch = 19.6135s	
2285/11350 (epoch 10.066), train_loss = 1.19581519, grad/param norm = 2.2767e-01, time/batch = 18.0426s	
2286/11350 (epoch 10.070), train_loss = 1.33460395, grad/param norm = 2.3328e-01, time/batch = 18.7781s	
2287/11350 (epoch 10.075), train_loss = 1.20944660, grad/param norm = 2.3507e-01, time/batch = 17.5977s	
2288/11350 (epoch 10.079), train_loss = 1.36479943, grad/param norm = 2.5699e-01, time/batch = 19.3718s	
2289/11350 (epoch 10.084), train_loss = 1.60660399, grad/param norm = 2.5337e-01, time/batch = 18.7739s	
2290/11350 (epoch 10.088), train_loss = 1.54318127, grad/param norm = 2.6426e-01, time/batch = 18.2645s	
2291/11350 (epoch 10.093), train_loss = 1.42237835, grad/param norm = 2.3949e-01, time/batch = 18.4450s	
2292/11350 (epoch 10.097), train_loss = 1.42557557, grad/param norm = 2.5400e-01, time/batch = 19.9483s	
2293/11350 (epoch 10.101), train_loss = 1.28675251, grad/param norm = 2.4757e-01, time/batch = 18.6978s	
2294/11350 (epoch 10.106), train_loss = 1.53934108, grad/param norm = 2.4132e-01, time/batch = 17.8625s	
2295/11350 (epoch 10.110), train_loss = 1.34704711, grad/param norm = 2.5978e-01, time/batch = 18.7826s	
2296/11350 (epoch 10.115), train_loss = 1.32456201, grad/param norm = 2.3208e-01, time/batch = 17.6047s	
2297/11350 (epoch 10.119), train_loss = 1.54238305, grad/param norm = 2.6471e-01, time/batch = 18.1229s	
2298/11350 (epoch 10.123), train_loss = 1.29770883, grad/param norm = 2.2655e-01, time/batch = 18.2814s	
2299/11350 (epoch 10.128), train_loss = 1.33473295, grad/param norm = 2.3817e-01, time/batch = 17.6194s	
2300/11350 (epoch 10.132), train_loss = 1.37353321, grad/param norm = 2.3265e-01, time/batch = 18.1295s	
2301/11350 (epoch 10.137), train_loss = 1.28708602, grad/param norm = 2.4132e-01, time/batch = 17.2967s	
2302/11350 (epoch 10.141), train_loss = 1.51047492, grad/param norm = 2.5801e-01, time/batch = 18.6248s	
2303/11350 (epoch 10.145), train_loss = 1.30623384, grad/param norm = 2.3030e-01, time/batch = 18.7182s	
2304/11350 (epoch 10.150), train_loss = 1.53566983, grad/param norm = 2.9109e-01, time/batch = 17.8906s	
2305/11350 (epoch 10.154), train_loss = 1.60361798, grad/param norm = 2.6226e-01, time/batch = 18.9656s	
2306/11350 (epoch 10.159), train_loss = 1.29562222, grad/param norm = 2.7695e-01, time/batch = 18.2975s	
2307/11350 (epoch 10.163), train_loss = 1.53855895, grad/param norm = 2.4532e-01, time/batch = 18.7203s	
2308/11350 (epoch 10.167), train_loss = 1.55918814, grad/param norm = 2.5268e-01, time/batch = 16.1858s	
2309/11350 (epoch 10.172), train_loss = 1.71146987, grad/param norm = 2.7548e-01, time/batch = 18.1389s	
2310/11350 (epoch 10.176), train_loss = 1.49059020, grad/param norm = 2.5528e-01, time/batch = 19.2140s	
2311/11350 (epoch 10.181), train_loss = 1.48606265, grad/param norm = 2.6989e-01, time/batch = 15.0021s	
2312/11350 (epoch 10.185), train_loss = 1.37776586, grad/param norm = 2.7239e-01, time/batch = 17.2180s	
2313/11350 (epoch 10.189), train_loss = 1.36746833, grad/param norm = 2.5394e-01, time/batch = 18.1330s	
2314/11350 (epoch 10.194), train_loss = 1.29087431, grad/param norm = 2.5302e-01, time/batch = 19.5522s	
2315/11350 (epoch 10.198), train_loss = 1.35027522, grad/param norm = 2.6574e-01, time/batch = 19.0508s	
2316/11350 (epoch 10.203), train_loss = 1.22627338, grad/param norm = 2.2364e-01, time/batch = 34.4891s	
2317/11350 (epoch 10.207), train_loss = 1.30362361, grad/param norm = 2.5963e-01, time/batch = 19.7102s	
2318/11350 (epoch 10.211), train_loss = 1.47847062, grad/param norm = 2.6365e-01, time/batch = 18.2894s	
2319/11350 (epoch 10.216), train_loss = 1.43888596, grad/param norm = 2.7776e-01, time/batch = 19.8682s	
2320/11350 (epoch 10.220), train_loss = 1.41441326, grad/param norm = 2.9205e-01, time/batch = 19.1197s	
2321/11350 (epoch 10.225), train_loss = 1.27548746, grad/param norm = 2.6809e-01, time/batch = 18.8002s	
2322/11350 (epoch 10.229), train_loss = 1.49661753, grad/param norm = 2.3162e-01, time/batch = 19.3699s	
2323/11350 (epoch 10.233), train_loss = 1.43471512, grad/param norm = 2.6399e-01, time/batch = 19.5393s	
2324/11350 (epoch 10.238), train_loss = 1.65573053, grad/param norm = 3.0474e-01, time/batch = 18.8588s	
2325/11350 (epoch 10.242), train_loss = 1.68255589, grad/param norm = 2.8617e-01, time/batch = 16.6610s	
2326/11350 (epoch 10.247), train_loss = 1.20344655, grad/param norm = 2.2819e-01, time/batch = 19.7837s	
2327/11350 (epoch 10.251), train_loss = 1.50276399, grad/param norm = 2.6776e-01, time/batch = 18.0040s	
2328/11350 (epoch 10.256), train_loss = 1.55928266, grad/param norm = 2.6734e-01, time/batch = 19.8533s	
2329/11350 (epoch 10.260), train_loss = 1.34681778, grad/param norm = 2.4476e-01, time/batch = 19.0378s	
2330/11350 (epoch 10.264), train_loss = 1.39082402, grad/param norm = 2.3668e-01, time/batch = 20.1244s	
2331/11350 (epoch 10.269), train_loss = 1.41779122, grad/param norm = 2.4404e-01, time/batch = 17.8643s	
2332/11350 (epoch 10.273), train_loss = 1.55192174, grad/param norm = 2.6254e-01, time/batch = 18.5285s	
2333/11350 (epoch 10.278), train_loss = 1.25958358, grad/param norm = 2.3488e-01, time/batch = 19.8776s	
2334/11350 (epoch 10.282), train_loss = 1.53194680, grad/param norm = 2.8669e-01, time/batch = 18.0269s	
2335/11350 (epoch 10.286), train_loss = 1.60727716, grad/param norm = 3.0481e-01, time/batch = 16.6887s	
2336/11350 (epoch 10.291), train_loss = 1.24556143, grad/param norm = 2.5537e-01, time/batch = 18.0479s	
2337/11350 (epoch 10.295), train_loss = 1.42529412, grad/param norm = 2.3010e-01, time/batch = 18.1837s	
2338/11350 (epoch 10.300), train_loss = 1.40151582, grad/param norm = 2.4891e-01, time/batch = 19.3870s	
2339/11350 (epoch 10.304), train_loss = 1.33817724, grad/param norm = 2.3569e-01, time/batch = 18.1294s	
2340/11350 (epoch 10.308), train_loss = 1.36253892, grad/param norm = 2.4697e-01, time/batch = 19.2872s	
2341/11350 (epoch 10.313), train_loss = 1.48116628, grad/param norm = 2.4168e-01, time/batch = 18.6898s	
2342/11350 (epoch 10.317), train_loss = 1.22798178, grad/param norm = 2.3915e-01, time/batch = 18.9642s	
2343/11350 (epoch 10.322), train_loss = 1.32529975, grad/param norm = 2.5734e-01, time/batch = 17.5477s	
2344/11350 (epoch 10.326), train_loss = 1.38558636, grad/param norm = 2.4470e-01, time/batch = 19.3624s	
2345/11350 (epoch 10.330), train_loss = 1.17239742, grad/param norm = 2.4773e-01, time/batch = 16.9688s	
2346/11350 (epoch 10.335), train_loss = 1.12914201, grad/param norm = 2.2775e-01, time/batch = 18.8527s	
2347/11350 (epoch 10.339), train_loss = 1.24940478, grad/param norm = 2.2309e-01, time/batch = 18.2741s	
2348/11350 (epoch 10.344), train_loss = 1.34001303, grad/param norm = 2.3416e-01, time/batch = 18.9475s	
2349/11350 (epoch 10.348), train_loss = 1.35753100, grad/param norm = 2.5725e-01, time/batch = 19.4662s	
2350/11350 (epoch 10.352), train_loss = 1.19247902, grad/param norm = 2.4064e-01, time/batch = 18.1184s	
2351/11350 (epoch 10.357), train_loss = 1.33658738, grad/param norm = 2.4243e-01, time/batch = 20.6930s	
2352/11350 (epoch 10.361), train_loss = 1.12680413, grad/param norm = 2.1928e-01, time/batch = 20.2719s	
2353/11350 (epoch 10.366), train_loss = 1.53359228, grad/param norm = 2.5999e-01, time/batch = 18.0168s	
2354/11350 (epoch 10.370), train_loss = 1.36151180, grad/param norm = 2.7678e-01, time/batch = 20.3573s	
2355/11350 (epoch 10.374), train_loss = 1.35161395, grad/param norm = 2.4980e-01, time/batch = 20.4380s	
2356/11350 (epoch 10.379), train_loss = 1.42771132, grad/param norm = 2.6134e-01, time/batch = 17.7900s	
2357/11350 (epoch 10.383), train_loss = 1.16774065, grad/param norm = 2.3501e-01, time/batch = 19.4211s	
2358/11350 (epoch 10.388), train_loss = 1.49299235, grad/param norm = 2.9614e-01, time/batch = 19.0372s	
2359/11350 (epoch 10.392), train_loss = 1.40989812, grad/param norm = 3.1166e-01, time/batch = 17.6039s	
2360/11350 (epoch 10.396), train_loss = 1.48997229, grad/param norm = 2.5963e-01, time/batch = 20.5062s	
2361/11350 (epoch 10.401), train_loss = 1.36591083, grad/param norm = 2.4967e-01, time/batch = 19.8779s	
2362/11350 (epoch 10.405), train_loss = 1.52210435, grad/param norm = 2.3220e-01, time/batch = 18.8578s	
2363/11350 (epoch 10.410), train_loss = 1.67654520, grad/param norm = 2.8934e-01, time/batch = 17.1630s	
2364/11350 (epoch 10.414), train_loss = 1.25527247, grad/param norm = 2.6880e-01, time/batch = 18.6070s	
2365/11350 (epoch 10.419), train_loss = 1.48592227, grad/param norm = 2.8821e-01, time/batch = 19.6204s	
2366/11350 (epoch 10.423), train_loss = 1.57324370, grad/param norm = 2.4001e-01, time/batch = 17.3968s	
2367/11350 (epoch 10.427), train_loss = 1.59653658, grad/param norm = 2.6930e-01, time/batch = 20.3484s	
2368/11350 (epoch 10.432), train_loss = 1.61857473, grad/param norm = 2.6445e-01, time/batch = 20.0266s	
2369/11350 (epoch 10.436), train_loss = 1.45214233, grad/param norm = 2.9545e-01, time/batch = 18.4426s	
2370/11350 (epoch 10.441), train_loss = 1.66631899, grad/param norm = 2.9983e-01, time/batch = 18.2910s	
2371/11350 (epoch 10.445), train_loss = 1.14925202, grad/param norm = 2.2239e-01, time/batch = 20.0321s	
2372/11350 (epoch 10.449), train_loss = 1.33681910, grad/param norm = 2.6935e-01, time/batch = 18.9421s	
2373/11350 (epoch 10.454), train_loss = 1.57328315, grad/param norm = 2.8273e-01, time/batch = 18.4522s	
2374/11350 (epoch 10.458), train_loss = 1.17792559, grad/param norm = 2.7124e-01, time/batch = 19.1961s	
2375/11350 (epoch 10.463), train_loss = 1.27796833, grad/param norm = 3.0420e-01, time/batch = 18.0255s	
2376/11350 (epoch 10.467), train_loss = 1.73749530, grad/param norm = 3.1001e-01, time/batch = 19.7032s	
2377/11350 (epoch 10.471), train_loss = 1.59845070, grad/param norm = 3.2779e-01, time/batch = 16.9329s	
2378/11350 (epoch 10.476), train_loss = 1.52805994, grad/param norm = 2.7306e-01, time/batch = 18.2755s	
2379/11350 (epoch 10.480), train_loss = 1.66079547, grad/param norm = 2.6914e-01, time/batch = 19.3627s	
2380/11350 (epoch 10.485), train_loss = 1.37872108, grad/param norm = 2.3160e-01, time/batch = 17.1056s	
2381/11350 (epoch 10.489), train_loss = 1.58434456, grad/param norm = 2.6952e-01, time/batch = 18.6300s	
2382/11350 (epoch 10.493), train_loss = 1.49899061, grad/param norm = 2.5188e-01, time/batch = 16.5478s	
2383/11350 (epoch 10.498), train_loss = 1.17309160, grad/param norm = 2.5860e-01, time/batch = 19.0550s	
2384/11350 (epoch 10.502), train_loss = 1.49133351, grad/param norm = 2.6723e-01, time/batch = 18.9685s	
2385/11350 (epoch 10.507), train_loss = 1.24822110, grad/param norm = 2.3594e-01, time/batch = 17.2051s	
2386/11350 (epoch 10.511), train_loss = 1.69639452, grad/param norm = 2.6888e-01, time/batch = 19.7165s	
2387/11350 (epoch 10.515), train_loss = 1.37976850, grad/param norm = 2.2611e-01, time/batch = 19.5400s	
2388/11350 (epoch 10.520), train_loss = 1.61673555, grad/param norm = 2.7469e-01, time/batch = 19.2022s	
2389/11350 (epoch 10.524), train_loss = 1.40385215, grad/param norm = 2.5605e-01, time/batch = 18.5446s	
2390/11350 (epoch 10.529), train_loss = 1.49090543, grad/param norm = 2.5886e-01, time/batch = 20.0446s	
2391/11350 (epoch 10.533), train_loss = 1.70612808, grad/param norm = 2.6163e-01, time/batch = 18.1134s	
2392/11350 (epoch 10.537), train_loss = 1.51224151, grad/param norm = 2.7096e-01, time/batch = 20.3670s	
2393/11350 (epoch 10.542), train_loss = 1.56967690, grad/param norm = 2.3765e-01, time/batch = 20.7848s	
2394/11350 (epoch 10.546), train_loss = 1.80092398, grad/param norm = 2.7207e-01, time/batch = 17.6147s	
2395/11350 (epoch 10.551), train_loss = 1.41911490, grad/param norm = 2.2740e-01, time/batch = 18.6894s	
2396/11350 (epoch 10.555), train_loss = 1.41344598, grad/param norm = 2.8489e-01, time/batch = 20.0052s	
2397/11350 (epoch 10.559), train_loss = 1.37084473, grad/param norm = 2.3355e-01, time/batch = 18.5271s	
2398/11350 (epoch 10.564), train_loss = 1.60351483, grad/param norm = 2.8020e-01, time/batch = 19.4441s	
2399/11350 (epoch 10.568), train_loss = 1.50608011, grad/param norm = 2.6129e-01, time/batch = 16.1849s	
2400/11350 (epoch 10.573), train_loss = 1.70440442, grad/param norm = 2.8264e-01, time/batch = 19.1281s	
2401/11350 (epoch 10.577), train_loss = 1.72081352, grad/param norm = 3.0879e-01, time/batch = 19.3592s	
2402/11350 (epoch 10.581), train_loss = 1.56977640, grad/param norm = 2.6395e-01, time/batch = 17.5341s	
2403/11350 (epoch 10.586), train_loss = 1.61439504, grad/param norm = 2.6205e-01, time/batch = 20.5398s	
2404/11350 (epoch 10.590), train_loss = 1.71345080, grad/param norm = 2.6869e-01, time/batch = 18.8589s	
2405/11350 (epoch 10.595), train_loss = 1.70992228, grad/param norm = 2.5436e-01, time/batch = 19.8804s	
2406/11350 (epoch 10.599), train_loss = 1.58355585, grad/param norm = 2.6332e-01, time/batch = 17.4696s	
2407/11350 (epoch 10.604), train_loss = 1.47011627, grad/param norm = 2.5367e-01, time/batch = 18.6145s	
2408/11350 (epoch 10.608), train_loss = 1.60006997, grad/param norm = 2.6822e-01, time/batch = 18.5434s	
2409/11350 (epoch 10.612), train_loss = 1.36995519, grad/param norm = 2.3186e-01, time/batch = 17.8626s	
2410/11350 (epoch 10.617), train_loss = 1.70642804, grad/param norm = 2.6982e-01, time/batch = 16.7495s	
2411/11350 (epoch 10.621), train_loss = 1.61193557, grad/param norm = 2.5739e-01, time/batch = 16.1378s	
2412/11350 (epoch 10.626), train_loss = 1.55008467, grad/param norm = 2.7510e-01, time/batch = 18.5501s	
2413/11350 (epoch 10.630), train_loss = 1.57072945, grad/param norm = 2.3334e-01, time/batch = 19.1220s	
2414/11350 (epoch 10.634), train_loss = 1.62358663, grad/param norm = 2.5640e-01, time/batch = 19.7910s	
2415/11350 (epoch 10.639), train_loss = 1.44405268, grad/param norm = 2.4112e-01, time/batch = 17.1944s	
2416/11350 (epoch 10.643), train_loss = 1.45242878, grad/param norm = 2.4204e-01, time/batch = 19.8602s	
2417/11350 (epoch 10.648), train_loss = 1.52708678, grad/param norm = 2.7323e-01, time/batch = 18.4402s	
2418/11350 (epoch 10.652), train_loss = 1.52206751, grad/param norm = 2.7975e-01, time/batch = 19.7916s	
2419/11350 (epoch 10.656), train_loss = 1.67338259, grad/param norm = 2.9225e-01, time/batch = 20.6999s	
2420/11350 (epoch 10.661), train_loss = 1.66856768, grad/param norm = 2.6613e-01, time/batch = 19.1933s	
2421/11350 (epoch 10.665), train_loss = 1.51393961, grad/param norm = 2.7525e-01, time/batch = 18.4433s	
2422/11350 (epoch 10.670), train_loss = 1.53726812, grad/param norm = 2.7838e-01, time/batch = 19.0294s	
2423/11350 (epoch 10.674), train_loss = 1.44848038, grad/param norm = 2.4312e-01, time/batch = 18.1957s	
2424/11350 (epoch 10.678), train_loss = 1.47845686, grad/param norm = 2.2771e-01, time/batch = 19.3752s	
2425/11350 (epoch 10.683), train_loss = 1.42088018, grad/param norm = 2.6187e-01, time/batch = 19.5377s	
2426/11350 (epoch 10.687), train_loss = 1.42682462, grad/param norm = 2.7544e-01, time/batch = 15.7759s	
2427/11350 (epoch 10.692), train_loss = 1.84589690, grad/param norm = 3.0029e-01, time/batch = 17.2482s	
2428/11350 (epoch 10.696), train_loss = 1.63127056, grad/param norm = 2.6279e-01, time/batch = 18.9491s	
2429/11350 (epoch 10.700), train_loss = 1.58528375, grad/param norm = 2.5881e-01, time/batch = 18.9487s	
2430/11350 (epoch 10.705), train_loss = 1.67942848, grad/param norm = 2.8327e-01, time/batch = 18.8697s	
2431/11350 (epoch 10.709), train_loss = 1.65400219, grad/param norm = 2.4429e-01, time/batch = 19.2878s	
2432/11350 (epoch 10.714), train_loss = 1.40864772, grad/param norm = 2.4843e-01, time/batch = 18.9432s	
2433/11350 (epoch 10.718), train_loss = 1.38889459, grad/param norm = 2.6547e-01, time/batch = 19.5277s	
2434/11350 (epoch 10.722), train_loss = 1.60409330, grad/param norm = 2.9430e-01, time/batch = 21.0187s	
2435/11350 (epoch 10.727), train_loss = 1.51682879, grad/param norm = 2.5051e-01, time/batch = 19.6933s	
2436/11350 (epoch 10.731), train_loss = 1.57604233, grad/param norm = 2.5408e-01, time/batch = 17.9669s	
2437/11350 (epoch 10.736), train_loss = 1.51788653, grad/param norm = 2.5709e-01, time/batch = 19.8727s	
2438/11350 (epoch 10.740), train_loss = 1.51384087, grad/param norm = 2.8264e-01, time/batch = 16.9559s	
2439/11350 (epoch 10.744), train_loss = 1.68401723, grad/param norm = 2.5329e-01, time/batch = 18.1238s	
2440/11350 (epoch 10.749), train_loss = 1.64978895, grad/param norm = 2.6214e-01, time/batch = 19.6996s	
2441/11350 (epoch 10.753), train_loss = 1.61765896, grad/param norm = 2.9802e-01, time/batch = 18.9575s	
2442/11350 (epoch 10.758), train_loss = 1.49490091, grad/param norm = 2.6226e-01, time/batch = 18.1053s	
2443/11350 (epoch 10.762), train_loss = 1.57168899, grad/param norm = 2.7345e-01, time/batch = 19.7014s	
2444/11350 (epoch 10.767), train_loss = 1.57126937, grad/param norm = 2.4365e-01, time/batch = 18.0341s	
2445/11350 (epoch 10.771), train_loss = 1.62343384, grad/param norm = 2.6441e-01, time/batch = 18.6962s	
2446/11350 (epoch 10.775), train_loss = 1.44423177, grad/param norm = 2.3663e-01, time/batch = 18.5196s	
2447/11350 (epoch 10.780), train_loss = 1.59840487, grad/param norm = 2.5478e-01, time/batch = 19.5815s	
2448/11350 (epoch 10.784), train_loss = 1.42069459, grad/param norm = 2.5577e-01, time/batch = 18.7893s	
2449/11350 (epoch 10.789), train_loss = 1.51252341, grad/param norm = 2.9652e-01, time/batch = 18.0979s	
2450/11350 (epoch 10.793), train_loss = 1.54664283, grad/param norm = 2.5531e-01, time/batch = 18.3447s	
2451/11350 (epoch 10.797), train_loss = 1.46398980, grad/param norm = 2.6371e-01, time/batch = 19.1009s	
2452/11350 (epoch 10.802), train_loss = 1.52370080, grad/param norm = 2.4324e-01, time/batch = 19.8690s	
2453/11350 (epoch 10.806), train_loss = 1.51774324, grad/param norm = 2.4976e-01, time/batch = 19.1258s	
2454/11350 (epoch 10.811), train_loss = 1.43857994, grad/param norm = 3.0226e-01, time/batch = 17.4535s	
2455/11350 (epoch 10.815), train_loss = 1.32780203, grad/param norm = 2.6309e-01, time/batch = 19.7738s	
2456/11350 (epoch 10.819), train_loss = 1.43269376, grad/param norm = 2.4191e-01, time/batch = 19.0487s	
2457/11350 (epoch 10.824), train_loss = 1.49594266, grad/param norm = 2.6033e-01, time/batch = 18.1280s	
2458/11350 (epoch 10.828), train_loss = 1.48577401, grad/param norm = 2.4843e-01, time/batch = 17.2691s	
2459/11350 (epoch 10.833), train_loss = 1.54442166, grad/param norm = 2.8802e-01, time/batch = 18.1873s	
2460/11350 (epoch 10.837), train_loss = 1.50025650, grad/param norm = 2.6547e-01, time/batch = 18.2239s	
2461/11350 (epoch 10.841), train_loss = 1.81236843, grad/param norm = 2.5506e-01, time/batch = 18.6140s	
2462/11350 (epoch 10.846), train_loss = 1.45654425, grad/param norm = 2.4879e-01, time/batch = 20.0222s	
2463/11350 (epoch 10.850), train_loss = 1.62033429, grad/param norm = 2.9323e-01, time/batch = 19.1326s	
2464/11350 (epoch 10.855), train_loss = 1.31952195, grad/param norm = 2.4172e-01, time/batch = 18.4434s	
2465/11350 (epoch 10.859), train_loss = 1.51416832, grad/param norm = 2.7191e-01, time/batch = 20.6975s	
2466/11350 (epoch 10.863), train_loss = 1.37907164, grad/param norm = 2.7564e-01, time/batch = 18.7922s	
2467/11350 (epoch 10.868), train_loss = 1.50986911, grad/param norm = 2.5124e-01, time/batch = 19.1216s	
2468/11350 (epoch 10.872), train_loss = 1.47454539, grad/param norm = 2.4914e-01, time/batch = 19.0421s	
2469/11350 (epoch 10.877), train_loss = 1.47512516, grad/param norm = 2.6888e-01, time/batch = 17.3335s	
2470/11350 (epoch 10.881), train_loss = 1.77976516, grad/param norm = 3.0189e-01, time/batch = 16.3573s	
2471/11350 (epoch 10.885), train_loss = 1.74048543, grad/param norm = 2.8338e-01, time/batch = 20.0960s	
2472/11350 (epoch 10.890), train_loss = 1.57642047, grad/param norm = 2.6270e-01, time/batch = 17.1299s	
2473/11350 (epoch 10.894), train_loss = 1.33109872, grad/param norm = 2.3887e-01, time/batch = 19.2778s	
2474/11350 (epoch 10.899), train_loss = 1.59729851, grad/param norm = 2.3489e-01, time/batch = 16.3786s	
2475/11350 (epoch 10.903), train_loss = 1.66285053, grad/param norm = 2.3612e-01, time/batch = 20.5323s	
2476/11350 (epoch 10.907), train_loss = 1.60240535, grad/param norm = 2.5350e-01, time/batch = 19.1232s	
2477/11350 (epoch 10.912), train_loss = 1.50009128, grad/param norm = 2.9988e-01, time/batch = 17.4381s	
2478/11350 (epoch 10.916), train_loss = 1.61693003, grad/param norm = 2.5406e-01, time/batch = 20.0344s	
2479/11350 (epoch 10.921), train_loss = 1.57648793, grad/param norm = 2.6084e-01, time/batch = 19.5290s	
2480/11350 (epoch 10.925), train_loss = 1.36161219, grad/param norm = 2.2997e-01, time/batch = 18.8771s	
2481/11350 (epoch 10.930), train_loss = 1.60602484, grad/param norm = 2.6488e-01, time/batch = 19.8535s	
2482/11350 (epoch 10.934), train_loss = 1.69726795, grad/param norm = 2.9231e-01, time/batch = 17.7960s	
2483/11350 (epoch 10.938), train_loss = 1.44172946, grad/param norm = 2.5785e-01, time/batch = 19.1177s	
2484/11350 (epoch 10.943), train_loss = 1.64105475, grad/param norm = 2.8713e-01, time/batch = 19.8658s	
2485/11350 (epoch 10.947), train_loss = 1.70300595, grad/param norm = 3.3224e-01, time/batch = 18.3764s	
2486/11350 (epoch 10.952), train_loss = 1.62186959, grad/param norm = 2.5057e-01, time/batch = 17.6954s	
2487/11350 (epoch 10.956), train_loss = 1.33421586, grad/param norm = 2.9787e-01, time/batch = 19.3644s	
2488/11350 (epoch 10.960), train_loss = 1.52876482, grad/param norm = 2.6701e-01, time/batch = 19.9682s	
2489/11350 (epoch 10.965), train_loss = 1.40299360, grad/param norm = 2.6664e-01, time/batch = 20.4388s	
2490/11350 (epoch 10.969), train_loss = 1.45477323, grad/param norm = 2.8981e-01, time/batch = 19.1006s	
2491/11350 (epoch 10.974), train_loss = 1.33372320, grad/param norm = 2.8949e-01, time/batch = 18.1198s	
2492/11350 (epoch 10.978), train_loss = 1.54787799, grad/param norm = 2.8950e-01, time/batch = 16.9392s	
2493/11350 (epoch 10.982), train_loss = 1.24997072, grad/param norm = 2.6445e-01, time/batch = 18.1934s	
2494/11350 (epoch 10.987), train_loss = 1.45514982, grad/param norm = 2.8880e-01, time/batch = 20.2054s	
2495/11350 (epoch 10.991), train_loss = 1.34724050, grad/param norm = 2.6156e-01, time/batch = 17.9586s	
2496/11350 (epoch 10.996), train_loss = 1.56184580, grad/param norm = 2.8826e-01, time/batch = 18.5339s	
decayed learning rate by a factor 0.97 to 0.0018818	
2497/11350 (epoch 11.000), train_loss = 1.20361324, grad/param norm = 2.5936e-01, time/batch = 20.2983s	
2498/11350 (epoch 11.004), train_loss = 1.47192221, grad/param norm = 2.7566e-01, time/batch = 18.2033s	
2499/11350 (epoch 11.009), train_loss = 1.59648158, grad/param norm = 2.7182e-01, time/batch = 18.4493s	
2500/11350 (epoch 11.013), train_loss = 1.02867437, grad/param norm = 2.0883e-01, time/batch = 18.9593s	
2501/11350 (epoch 11.018), train_loss = 1.10985397, grad/param norm = 2.4507e-01, time/batch = 20.0367s	
2502/11350 (epoch 11.022), train_loss = 1.15197722, grad/param norm = 2.9500e-01, time/batch = 16.6903s	
2503/11350 (epoch 11.026), train_loss = 1.26647119, grad/param norm = 2.7611e-01, time/batch = 19.6816s	
2504/11350 (epoch 11.031), train_loss = 1.16279214, grad/param norm = 2.5192e-01, time/batch = 18.1271s	
2505/11350 (epoch 11.035), train_loss = 1.28021972, grad/param norm = 2.5047e-01, time/batch = 17.3676s	
2506/11350 (epoch 11.040), train_loss = 1.30725260, grad/param norm = 2.5936e-01, time/batch = 34.2437s	
2507/11350 (epoch 11.044), train_loss = 1.24751700, grad/param norm = 2.2851e-01, time/batch = 18.6201s	
2508/11350 (epoch 11.048), train_loss = 1.23653559, grad/param norm = 2.3523e-01, time/batch = 17.1911s	
2509/11350 (epoch 11.053), train_loss = 1.31571942, grad/param norm = 2.2981e-01, time/batch = 19.9549s	
2510/11350 (epoch 11.057), train_loss = 1.42776978, grad/param norm = 2.6332e-01, time/batch = 19.6906s	
2511/11350 (epoch 11.062), train_loss = 1.12990165, grad/param norm = 2.2303e-01, time/batch = 19.1897s	
2512/11350 (epoch 11.066), train_loss = 1.14272019, grad/param norm = 2.1831e-01, time/batch = 15.0812s	
2513/11350 (epoch 11.070), train_loss = 1.27499271, grad/param norm = 2.2754e-01, time/batch = 17.3762s	
2514/11350 (epoch 11.075), train_loss = 1.14495116, grad/param norm = 2.4190e-01, time/batch = 19.6213s	
2515/11350 (epoch 11.079), train_loss = 1.30346076, grad/param norm = 2.5880e-01, time/batch = 19.0359s	
2516/11350 (epoch 11.084), train_loss = 1.54517606, grad/param norm = 2.6441e-01, time/batch = 16.9625s	
2517/11350 (epoch 11.088), train_loss = 1.48884796, grad/param norm = 2.8374e-01, time/batch = 17.8758s	
2518/11350 (epoch 11.093), train_loss = 1.38246563, grad/param norm = 2.4720e-01, time/batch = 16.8639s	
2519/11350 (epoch 11.097), train_loss = 1.36512740, grad/param norm = 2.5957e-01, time/batch = 19.2178s	
2520/11350 (epoch 11.101), train_loss = 1.23241435, grad/param norm = 2.4638e-01, time/batch = 19.4473s	
2521/11350 (epoch 11.106), train_loss = 1.47674913, grad/param norm = 2.5221e-01, time/batch = 18.1115s	
2522/11350 (epoch 11.110), train_loss = 1.28722162, grad/param norm = 2.6335e-01, time/batch = 19.2015s	
2523/11350 (epoch 11.115), train_loss = 1.27323207, grad/param norm = 2.3255e-01, time/batch = 20.1169s	
2524/11350 (epoch 11.119), train_loss = 1.48169822, grad/param norm = 2.6906e-01, time/batch = 18.7852s	
2525/11350 (epoch 11.123), train_loss = 1.24261497, grad/param norm = 2.3454e-01, time/batch = 17.0798s	
2526/11350 (epoch 11.128), train_loss = 1.26708083, grad/param norm = 2.3646e-01, time/batch = 20.0243s	
2527/11350 (epoch 11.132), train_loss = 1.31394953, grad/param norm = 2.3607e-01, time/batch = 18.9316s	
2528/11350 (epoch 11.137), train_loss = 1.23928460, grad/param norm = 2.4511e-01, time/batch = 19.3632s	
2529/11350 (epoch 11.141), train_loss = 1.45051954, grad/param norm = 2.4995e-01, time/batch = 15.6451s	
2530/11350 (epoch 11.145), train_loss = 1.24449116, grad/param norm = 2.2773e-01, time/batch = 20.4543s	
2531/11350 (epoch 11.150), train_loss = 1.46427118, grad/param norm = 2.7523e-01, time/batch = 18.4360s	
2532/11350 (epoch 11.154), train_loss = 1.55610724, grad/param norm = 2.9753e-01, time/batch = 18.6972s	
2533/11350 (epoch 11.159), train_loss = 1.23317002, grad/param norm = 2.8010e-01, time/batch = 18.9429s	
2534/11350 (epoch 11.163), train_loss = 1.47285070, grad/param norm = 2.4630e-01, time/batch = 17.8628s	
2535/11350 (epoch 11.167), train_loss = 1.49567897, grad/param norm = 2.6956e-01, time/batch = 19.3810s	
2536/11350 (epoch 11.172), train_loss = 1.63166079, grad/param norm = 2.9032e-01, time/batch = 20.2845s	
2537/11350 (epoch 11.176), train_loss = 1.42947450, grad/param norm = 2.4872e-01, time/batch = 17.6000s	
2538/11350 (epoch 11.181), train_loss = 1.42479762, grad/param norm = 2.7306e-01, time/batch = 19.0407s	
2539/11350 (epoch 11.185), train_loss = 1.30677580, grad/param norm = 2.7729e-01, time/batch = 18.7827s	
2540/11350 (epoch 11.189), train_loss = 1.32322017, grad/param norm = 2.5225e-01, time/batch = 18.3544s	
2541/11350 (epoch 11.194), train_loss = 1.24378978, grad/param norm = 2.6221e-01, time/batch = 18.8688s	
2542/11350 (epoch 11.198), train_loss = 1.27653356, grad/param norm = 2.6593e-01, time/batch = 19.8662s	
2543/11350 (epoch 11.203), train_loss = 1.16724971, grad/param norm = 2.3240e-01, time/batch = 17.4463s	
2544/11350 (epoch 11.207), train_loss = 1.23297374, grad/param norm = 2.6613e-01, time/batch = 19.5946s	
2545/11350 (epoch 11.211), train_loss = 1.41524772, grad/param norm = 2.6169e-01, time/batch = 16.8976s	
2546/11350 (epoch 11.216), train_loss = 1.38335431, grad/param norm = 2.8583e-01, time/batch = 18.7952s	
2547/11350 (epoch 11.220), train_loss = 1.35117399, grad/param norm = 2.8564e-01, time/batch = 18.8639s	
2548/11350 (epoch 11.225), train_loss = 1.21849854, grad/param norm = 2.5503e-01, time/batch = 16.2875s	
2549/11350 (epoch 11.229), train_loss = 1.44017491, grad/param norm = 2.4673e-01, time/batch = 19.3708s	
2550/11350 (epoch 11.233), train_loss = 1.37240337, grad/param norm = 2.5902e-01, time/batch = 18.5140s	
2551/11350 (epoch 11.238), train_loss = 1.57135946, grad/param norm = 2.9204e-01, time/batch = 20.1085s	
2552/11350 (epoch 11.242), train_loss = 1.60337577, grad/param norm = 2.9599e-01, time/batch = 18.8781s	
2553/11350 (epoch 11.247), train_loss = 1.14947675, grad/param norm = 2.2704e-01, time/batch = 17.5083s	
2554/11350 (epoch 11.251), train_loss = 1.43562439, grad/param norm = 2.5568e-01, time/batch = 20.7770s	
2555/11350 (epoch 11.256), train_loss = 1.48869862, grad/param norm = 2.6782e-01, time/batch = 17.5285s	
2556/11350 (epoch 11.260), train_loss = 1.28269382, grad/param norm = 2.5898e-01, time/batch = 16.5058s	
2557/11350 (epoch 11.264), train_loss = 1.33567530, grad/param norm = 2.4454e-01, time/batch = 19.3760s	
2558/11350 (epoch 11.269), train_loss = 1.37013687, grad/param norm = 2.5481e-01, time/batch = 19.3709s	
2559/11350 (epoch 11.273), train_loss = 1.47568882, grad/param norm = 2.6550e-01, time/batch = 19.6158s	
2560/11350 (epoch 11.278), train_loss = 1.20214205, grad/param norm = 2.3266e-01, time/batch = 18.7215s	
2561/11350 (epoch 11.282), train_loss = 1.47119334, grad/param norm = 2.8100e-01, time/batch = 19.4546s	
2562/11350 (epoch 11.286), train_loss = 1.53017854, grad/param norm = 3.0172e-01, time/batch = 19.4383s	
2563/11350 (epoch 11.291), train_loss = 1.19682697, grad/param norm = 2.7046e-01, time/batch = 16.9341s	
2564/11350 (epoch 11.295), train_loss = 1.36650501, grad/param norm = 2.6709e-01, time/batch = 19.5267s	
2565/11350 (epoch 11.300), train_loss = 1.34407926, grad/param norm = 2.4934e-01, time/batch = 18.4313s	
2566/11350 (epoch 11.304), train_loss = 1.27206265, grad/param norm = 2.3668e-01, time/batch = 18.4554s	
2567/11350 (epoch 11.308), train_loss = 1.31182446, grad/param norm = 2.4937e-01, time/batch = 17.7165s	
2568/11350 (epoch 11.313), train_loss = 1.43559583, grad/param norm = 2.7165e-01, time/batch = 18.5466s	
2569/11350 (epoch 11.317), train_loss = 1.18147751, grad/param norm = 2.2849e-01, time/batch = 16.8803s	
2570/11350 (epoch 11.322), train_loss = 1.28913608, grad/param norm = 2.8484e-01, time/batch = 19.7918s	
2571/11350 (epoch 11.326), train_loss = 1.33636675, grad/param norm = 2.5061e-01, time/batch = 19.1329s	
2572/11350 (epoch 11.330), train_loss = 1.12199456, grad/param norm = 2.4032e-01, time/batch = 18.3637s	
2573/11350 (epoch 11.335), train_loss = 1.06641479, grad/param norm = 2.3008e-01, time/batch = 20.0448s	
2574/11350 (epoch 11.339), train_loss = 1.19163845, grad/param norm = 2.2915e-01, time/batch = 18.9493s	
2575/11350 (epoch 11.344), train_loss = 1.27120743, grad/param norm = 2.3112e-01, time/batch = 19.2824s	
2576/11350 (epoch 11.348), train_loss = 1.29827581, grad/param norm = 2.4840e-01, time/batch = 19.3585s	
2577/11350 (epoch 11.352), train_loss = 1.14023125, grad/param norm = 2.3697e-01, time/batch = 19.2137s	
2578/11350 (epoch 11.357), train_loss = 1.26792542, grad/param norm = 2.3345e-01, time/batch = 19.5341s	
2579/11350 (epoch 11.361), train_loss = 1.06912952, grad/param norm = 2.1641e-01, time/batch = 18.1092s	
2580/11350 (epoch 11.366), train_loss = 1.46160223, grad/param norm = 2.7460e-01, time/batch = 17.1058s	
2581/11350 (epoch 11.370), train_loss = 1.29969424, grad/param norm = 2.7427e-01, time/batch = 17.5427s	
2582/11350 (epoch 11.374), train_loss = 1.28467823, grad/param norm = 2.5920e-01, time/batch = 18.7776s	
2583/11350 (epoch 11.379), train_loss = 1.36574576, grad/param norm = 2.6968e-01, time/batch = 19.9468s	
2584/11350 (epoch 11.383), train_loss = 1.11291719, grad/param norm = 2.6081e-01, time/batch = 19.9416s	
2585/11350 (epoch 11.388), train_loss = 1.42163005, grad/param norm = 3.0808e-01, time/batch = 18.2772s	
2586/11350 (epoch 11.392), train_loss = 1.34931284, grad/param norm = 3.1656e-01, time/batch = 18.7887s	
2587/11350 (epoch 11.396), train_loss = 1.42125566, grad/param norm = 2.5663e-01, time/batch = 19.9535s	
2588/11350 (epoch 11.401), train_loss = 1.31334771, grad/param norm = 2.5805e-01, time/batch = 18.0365s	
2589/11350 (epoch 11.405), train_loss = 1.46746267, grad/param norm = 2.3899e-01, time/batch = 19.2161s	
2590/11350 (epoch 11.410), train_loss = 1.59237142, grad/param norm = 2.8423e-01, time/batch = 19.2828s	
2591/11350 (epoch 11.414), train_loss = 1.18940768, grad/param norm = 2.7037e-01, time/batch = 17.3002s	
2592/11350 (epoch 11.419), train_loss = 1.37990369, grad/param norm = 2.6909e-01, time/batch = 17.6723s	
2593/11350 (epoch 11.423), train_loss = 1.50241388, grad/param norm = 2.7056e-01, time/batch = 18.8707s	
2594/11350 (epoch 11.427), train_loss = 1.51602012, grad/param norm = 2.6364e-01, time/batch = 18.6247s	
2595/11350 (epoch 11.432), train_loss = 1.53644738, grad/param norm = 2.6838e-01, time/batch = 17.0406s	
2596/11350 (epoch 11.436), train_loss = 1.38427146, grad/param norm = 3.1169e-01, time/batch = 19.2048s	
2597/11350 (epoch 11.441), train_loss = 1.59862995, grad/param norm = 3.0016e-01, time/batch = 18.7005s	
2598/11350 (epoch 11.445), train_loss = 1.10320306, grad/param norm = 2.2049e-01, time/batch = 16.8263s	
2599/11350 (epoch 11.449), train_loss = 1.27838823, grad/param norm = 2.8042e-01, time/batch = 18.8719s	
2600/11350 (epoch 11.454), train_loss = 1.51624770, grad/param norm = 2.7986e-01, time/batch = 20.2781s	
2601/11350 (epoch 11.458), train_loss = 1.12393754, grad/param norm = 2.7338e-01, time/batch = 17.1178s	
2602/11350 (epoch 11.463), train_loss = 1.21292311, grad/param norm = 2.5239e-01, time/batch = 19.9518s	
2603/11350 (epoch 11.467), train_loss = 1.67106180, grad/param norm = 3.2562e-01, time/batch = 20.0355s	
2604/11350 (epoch 11.471), train_loss = 1.52782570, grad/param norm = 3.5392e-01, time/batch = 19.0230s	
2605/11350 (epoch 11.476), train_loss = 1.46290156, grad/param norm = 2.6409e-01, time/batch = 18.1221s	
2606/11350 (epoch 11.480), train_loss = 1.58686282, grad/param norm = 2.7047e-01, time/batch = 20.1274s	
2607/11350 (epoch 11.485), train_loss = 1.33161642, grad/param norm = 2.4087e-01, time/batch = 18.3664s	
2608/11350 (epoch 11.489), train_loss = 1.51399229, grad/param norm = 2.6707e-01, time/batch = 20.3438s	
2609/11350 (epoch 11.493), train_loss = 1.43983253, grad/param norm = 2.5193e-01, time/batch = 19.3699s	
2610/11350 (epoch 11.498), train_loss = 1.11478997, grad/param norm = 2.5230e-01, time/batch = 17.6818s	
2611/11350 (epoch 11.502), train_loss = 1.42828741, grad/param norm = 2.6293e-01, time/batch = 18.4574s	
2612/11350 (epoch 11.507), train_loss = 1.19730633, grad/param norm = 2.8307e-01, time/batch = 19.1083s	
2613/11350 (epoch 11.511), train_loss = 1.63350776, grad/param norm = 2.8447e-01, time/batch = 17.8519s	
2614/11350 (epoch 11.515), train_loss = 1.32931075, grad/param norm = 2.3140e-01, time/batch = 19.1872s	
2615/11350 (epoch 11.520), train_loss = 1.56238140, grad/param norm = 2.7751e-01, time/batch = 18.2077s	
2616/11350 (epoch 11.524), train_loss = 1.34862080, grad/param norm = 2.6702e-01, time/batch = 16.1603s	
2617/11350 (epoch 11.529), train_loss = 1.41901998, grad/param norm = 2.5835e-01, time/batch = 16.3482s	
2618/11350 (epoch 11.533), train_loss = 1.64739421, grad/param norm = 2.6805e-01, time/batch = 20.3640s	
2619/11350 (epoch 11.537), train_loss = 1.44194502, grad/param norm = 2.6171e-01, time/batch = 16.9854s	
2620/11350 (epoch 11.542), train_loss = 1.50095021, grad/param norm = 2.3228e-01, time/batch = 16.3465s	
2621/11350 (epoch 11.546), train_loss = 1.73578123, grad/param norm = 2.7653e-01, time/batch = 18.6272s	
2622/11350 (epoch 11.551), train_loss = 1.38021869, grad/param norm = 2.2551e-01, time/batch = 17.8763s	
2623/11350 (epoch 11.555), train_loss = 1.33126714, grad/param norm = 2.4972e-01, time/batch = 18.5493s	
2624/11350 (epoch 11.559), train_loss = 1.31322524, grad/param norm = 2.3934e-01, time/batch = 18.9531s	
2625/11350 (epoch 11.564), train_loss = 1.54559488, grad/param norm = 2.8427e-01, time/batch = 19.4329s	
2626/11350 (epoch 11.568), train_loss = 1.44295561, grad/param norm = 2.5395e-01, time/batch = 18.8886s	
2627/11350 (epoch 11.573), train_loss = 1.64055200, grad/param norm = 2.9859e-01, time/batch = 19.0242s	
2628/11350 (epoch 11.577), train_loss = 1.64042247, grad/param norm = 2.7150e-01, time/batch = 20.5324s	
2629/11350 (epoch 11.581), train_loss = 1.51699668, grad/param norm = 2.6156e-01, time/batch = 17.9614s	
2630/11350 (epoch 11.586), train_loss = 1.54721859, grad/param norm = 2.6427e-01, time/batch = 18.1817s	
2631/11350 (epoch 11.590), train_loss = 1.64595223, grad/param norm = 2.8659e-01, time/batch = 20.2022s	
2632/11350 (epoch 11.595), train_loss = 1.64856482, grad/param norm = 2.6737e-01, time/batch = 20.2882s	
2633/11350 (epoch 11.599), train_loss = 1.52242439, grad/param norm = 2.6611e-01, time/batch = 17.9435s	
2634/11350 (epoch 11.604), train_loss = 1.40313813, grad/param norm = 2.4163e-01, time/batch = 18.1230s	
2635/11350 (epoch 11.608), train_loss = 1.52630461, grad/param norm = 2.6891e-01, time/batch = 19.6949s	
2636/11350 (epoch 11.612), train_loss = 1.31079739, grad/param norm = 2.2772e-01, time/batch = 19.0281s	
2637/11350 (epoch 11.617), train_loss = 1.63429130, grad/param norm = 2.8370e-01, time/batch = 20.3699s	
2638/11350 (epoch 11.621), train_loss = 1.56102919, grad/param norm = 2.6897e-01, time/batch = 17.6711s	
2639/11350 (epoch 11.626), train_loss = 1.48241985, grad/param norm = 2.7033e-01, time/batch = 17.8223s	
2640/11350 (epoch 11.630), train_loss = 1.50924590, grad/param norm = 2.3957e-01, time/batch = 19.1276s	
2641/11350 (epoch 11.634), train_loss = 1.55132386, grad/param norm = 2.5631e-01, time/batch = 16.7214s	
2642/11350 (epoch 11.639), train_loss = 1.38400927, grad/param norm = 2.4518e-01, time/batch = 19.0386s	
2643/11350 (epoch 11.643), train_loss = 1.37861306, grad/param norm = 2.4215e-01, time/batch = 20.3647s	
2644/11350 (epoch 11.648), train_loss = 1.45848059, grad/param norm = 2.7509e-01, time/batch = 19.3665s	
2645/11350 (epoch 11.652), train_loss = 1.44521732, grad/param norm = 2.8358e-01, time/batch = 18.1215s	
2646/11350 (epoch 11.656), train_loss = 1.60347372, grad/param norm = 3.2031e-01, time/batch = 18.2009s	
2647/11350 (epoch 11.661), train_loss = 1.62451422, grad/param norm = 2.7517e-01, time/batch = 19.8645s	
2648/11350 (epoch 11.665), train_loss = 1.46954898, grad/param norm = 2.8288e-01, time/batch = 20.3641s	
2649/11350 (epoch 11.670), train_loss = 1.48090618, grad/param norm = 2.8187e-01, time/batch = 9.2512s	
2650/11350 (epoch 11.674), train_loss = 1.38372618, grad/param norm = 2.4063e-01, time/batch = 0.7080s	
2651/11350 (epoch 11.678), train_loss = 1.41072386, grad/param norm = 2.3257e-01, time/batch = 0.7106s	
2652/11350 (epoch 11.683), train_loss = 1.35744969, grad/param norm = 2.3998e-01, time/batch = 0.7015s	
2653/11350 (epoch 11.687), train_loss = 1.35405199, grad/param norm = 2.8459e-01, time/batch = 0.6979s	
2654/11350 (epoch 11.692), train_loss = 1.78421775, grad/param norm = 3.1708e-01, time/batch = 0.6905s	
2655/11350 (epoch 11.696), train_loss = 1.58639121, grad/param norm = 2.8899e-01, time/batch = 0.6911s	
2656/11350 (epoch 11.700), train_loss = 1.52913713, grad/param norm = 2.6074e-01, time/batch = 0.8245s	
2657/11350 (epoch 11.705), train_loss = 1.61405869, grad/param norm = 2.7583e-01, time/batch = 1.0173s	
2658/11350 (epoch 11.709), train_loss = 1.59218713, grad/param norm = 2.6966e-01, time/batch = 1.0150s	
2659/11350 (epoch 11.714), train_loss = 1.36268484, grad/param norm = 2.5771e-01, time/batch = 1.0047s	
2660/11350 (epoch 11.718), train_loss = 1.32433603, grad/param norm = 2.7456e-01, time/batch = 1.0122s	
2661/11350 (epoch 11.722), train_loss = 1.54842204, grad/param norm = 3.1157e-01, time/batch = 1.5482s	
2662/11350 (epoch 11.727), train_loss = 1.45424503, grad/param norm = 2.4895e-01, time/batch = 1.9131s	
2663/11350 (epoch 11.731), train_loss = 1.51490603, grad/param norm = 2.6430e-01, time/batch = 1.9047s	
2664/11350 (epoch 11.736), train_loss = 1.45277410, grad/param norm = 2.7397e-01, time/batch = 16.9012s	
2665/11350 (epoch 11.740), train_loss = 1.44982258, grad/param norm = 2.8741e-01, time/batch = 19.6196s	
2666/11350 (epoch 11.744), train_loss = 1.61927473, grad/param norm = 2.7136e-01, time/batch = 19.9309s	
2667/11350 (epoch 11.749), train_loss = 1.59293102, grad/param norm = 2.7865e-01, time/batch = 18.5394s	
2668/11350 (epoch 11.753), train_loss = 1.55885669, grad/param norm = 3.0577e-01, time/batch = 20.2009s	
2669/11350 (epoch 11.758), train_loss = 1.43109446, grad/param norm = 2.6195e-01, time/batch = 18.4253s	
2670/11350 (epoch 11.762), train_loss = 1.50706510, grad/param norm = 2.7034e-01, time/batch = 19.4282s	
2671/11350 (epoch 11.767), train_loss = 1.51502247, grad/param norm = 2.5537e-01, time/batch = 20.1992s	
2672/11350 (epoch 11.771), train_loss = 1.57854034, grad/param norm = 2.5666e-01, time/batch = 17.0984s	
2673/11350 (epoch 11.775), train_loss = 1.38356032, grad/param norm = 2.5112e-01, time/batch = 19.6839s	
2674/11350 (epoch 11.780), train_loss = 1.53467013, grad/param norm = 2.5167e-01, time/batch = 19.2733s	
2675/11350 (epoch 11.784), train_loss = 1.35766748, grad/param norm = 2.4780e-01, time/batch = 17.5201s	
2676/11350 (epoch 11.789), train_loss = 1.44501435, grad/param norm = 2.8949e-01, time/batch = 20.0212s	
2677/11350 (epoch 11.793), train_loss = 1.49664026, grad/param norm = 2.5523e-01, time/batch = 19.9408s	
2678/11350 (epoch 11.797), train_loss = 1.40235171, grad/param norm = 2.5726e-01, time/batch = 18.5957s	
2679/11350 (epoch 11.802), train_loss = 1.47006933, grad/param norm = 2.4811e-01, time/batch = 21.2796s	
2680/11350 (epoch 11.806), train_loss = 1.46537144, grad/param norm = 2.5078e-01, time/batch = 18.1359s	
2681/11350 (epoch 11.811), train_loss = 1.39185015, grad/param norm = 3.0615e-01, time/batch = 18.0349s	
2682/11350 (epoch 11.815), train_loss = 1.27893944, grad/param norm = 2.4270e-01, time/batch = 20.8553s	
2683/11350 (epoch 11.819), train_loss = 1.35942636, grad/param norm = 2.5754e-01, time/batch = 20.1092s	
2684/11350 (epoch 11.824), train_loss = 1.42790443, grad/param norm = 2.5603e-01, time/batch = 19.1966s	
2685/11350 (epoch 11.828), train_loss = 1.42830985, grad/param norm = 2.5257e-01, time/batch = 18.9429s	
2686/11350 (epoch 11.833), train_loss = 1.47694213, grad/param norm = 2.8557e-01, time/batch = 16.7537s	
2687/11350 (epoch 11.837), train_loss = 1.43558608, grad/param norm = 2.5671e-01, time/batch = 19.7002s	
2688/11350 (epoch 11.841), train_loss = 1.75252573, grad/param norm = 2.6778e-01, time/batch = 17.8831s	
2689/11350 (epoch 11.846), train_loss = 1.41038032, grad/param norm = 2.5902e-01, time/batch = 19.6294s	
2690/11350 (epoch 11.850), train_loss = 1.56401969, grad/param norm = 2.9824e-01, time/batch = 18.3750s	
2691/11350 (epoch 11.855), train_loss = 1.26220191, grad/param norm = 2.4098e-01, time/batch = 18.3675s	
2692/11350 (epoch 11.859), train_loss = 1.45121163, grad/param norm = 2.6808e-01, time/batch = 18.9649s	
2693/11350 (epoch 11.863), train_loss = 1.31973109, grad/param norm = 2.8218e-01, time/batch = 20.6139s	
2694/11350 (epoch 11.868), train_loss = 1.44200669, grad/param norm = 2.5324e-01, time/batch = 18.1130s	
2695/11350 (epoch 11.872), train_loss = 1.41579361, grad/param norm = 2.5609e-01, time/batch = 18.5512s	
2696/11350 (epoch 11.877), train_loss = 1.40995083, grad/param norm = 2.6072e-01, time/batch = 19.1869s	
2697/11350 (epoch 11.881), train_loss = 1.71282128, grad/param norm = 3.0151e-01, time/batch = 18.6006s	
2698/11350 (epoch 11.885), train_loss = 1.67663629, grad/param norm = 2.8550e-01, time/batch = 20.2768s	
2699/11350 (epoch 11.890), train_loss = 1.51444180, grad/param norm = 2.6405e-01, time/batch = 20.1959s	
2700/11350 (epoch 11.894), train_loss = 1.27728439, grad/param norm = 2.4568e-01, time/batch = 18.9376s	
2701/11350 (epoch 11.899), train_loss = 1.54048246, grad/param norm = 2.4265e-01, time/batch = 19.5388s	
2702/11350 (epoch 11.903), train_loss = 1.59182437, grad/param norm = 2.3954e-01, time/batch = 20.0390s	
2703/11350 (epoch 11.907), train_loss = 1.53136669, grad/param norm = 2.5186e-01, time/batch = 19.0222s	
2704/11350 (epoch 11.912), train_loss = 1.43425278, grad/param norm = 2.6318e-01, time/batch = 20.4613s	
2705/11350 (epoch 11.916), train_loss = 1.56978218, grad/param norm = 3.1784e-01, time/batch = 18.0007s	
2706/11350 (epoch 11.921), train_loss = 1.52691659, grad/param norm = 2.8416e-01, time/batch = 18.1855s	
2707/11350 (epoch 11.925), train_loss = 1.30023274, grad/param norm = 2.2855e-01, time/batch = 18.4377s	
2708/11350 (epoch 11.930), train_loss = 1.55017129, grad/param norm = 2.6449e-01, time/batch = 16.9574s	
2709/11350 (epoch 11.934), train_loss = 1.62646437, grad/param norm = 2.6297e-01, time/batch = 21.4918s	
2710/11350 (epoch 11.938), train_loss = 1.38817161, grad/param norm = 2.6098e-01, time/batch = 32.1389s	
2711/11350 (epoch 11.943), train_loss = 1.58631584, grad/param norm = 3.0364e-01, time/batch = 18.4336s	
2712/11350 (epoch 11.947), train_loss = 1.61495901, grad/param norm = 3.2376e-01, time/batch = 19.1048s	
2713/11350 (epoch 11.952), train_loss = 1.55960633, grad/param norm = 2.6057e-01, time/batch = 20.0338s	
2714/11350 (epoch 11.956), train_loss = 1.25952201, grad/param norm = 2.5501e-01, time/batch = 19.8589s	
2715/11350 (epoch 11.960), train_loss = 1.45854298, grad/param norm = 2.6514e-01, time/batch = 19.3527s	
2716/11350 (epoch 11.965), train_loss = 1.34426230, grad/param norm = 2.6754e-01, time/batch = 20.4506s	
2717/11350 (epoch 11.969), train_loss = 1.38300598, grad/param norm = 2.9919e-01, time/batch = 17.6779s	
2718/11350 (epoch 11.974), train_loss = 1.26680077, grad/param norm = 2.7768e-01, time/batch = 17.4476s	
2719/11350 (epoch 11.978), train_loss = 1.47053916, grad/param norm = 2.7873e-01, time/batch = 19.6933s	
2720/11350 (epoch 11.982), train_loss = 1.19267514, grad/param norm = 2.6499e-01, time/batch = 19.1935s	
2721/11350 (epoch 11.987), train_loss = 1.40427231, grad/param norm = 2.7708e-01, time/batch = 17.1949s	
2722/11350 (epoch 11.991), train_loss = 1.30213692, grad/param norm = 2.9488e-01, time/batch = 18.3636s	
2723/11350 (epoch 11.996), train_loss = 1.50473619, grad/param norm = 3.0249e-01, time/batch = 19.7901s	
decayed learning rate by a factor 0.97 to 0.001825346	
2724/11350 (epoch 12.000), train_loss = 1.15334237, grad/param norm = 2.5654e-01, time/batch = 17.7767s	
2725/11350 (epoch 12.004), train_loss = 1.41673796, grad/param norm = 2.6859e-01, time/batch = 17.8597s	
2726/11350 (epoch 12.009), train_loss = 1.51688301, grad/param norm = 2.6108e-01, time/batch = 19.0548s	
2727/11350 (epoch 12.013), train_loss = 0.98465966, grad/param norm = 2.1646e-01, time/batch = 18.8915s	
2728/11350 (epoch 12.018), train_loss = 1.06196280, grad/param norm = 2.4896e-01, time/batch = 17.3277s	
2729/11350 (epoch 12.022), train_loss = 1.10517477, grad/param norm = 2.5504e-01, time/batch = 17.9519s	
2730/11350 (epoch 12.026), train_loss = 1.19572543, grad/param norm = 2.5471e-01, time/batch = 18.9612s	
2731/11350 (epoch 12.031), train_loss = 1.12553108, grad/param norm = 2.4892e-01, time/batch = 15.9782s	
2732/11350 (epoch 12.035), train_loss = 1.22159348, grad/param norm = 2.4302e-01, time/batch = 16.7177s	
2733/11350 (epoch 12.040), train_loss = 1.25071731, grad/param norm = 2.5035e-01, time/batch = 20.4395s	
2734/11350 (epoch 12.044), train_loss = 1.18688433, grad/param norm = 2.4413e-01, time/batch = 18.4456s	
2735/11350 (epoch 12.048), train_loss = 1.17752439, grad/param norm = 2.4555e-01, time/batch = 19.4596s	
2736/11350 (epoch 12.053), train_loss = 1.26191814, grad/param norm = 2.3373e-01, time/batch = 19.3021s	
2737/11350 (epoch 12.057), train_loss = 1.36383911, grad/param norm = 2.6373e-01, time/batch = 17.6009s	
2738/11350 (epoch 12.062), train_loss = 1.08424894, grad/param norm = 2.2959e-01, time/batch = 18.1246s	
2739/11350 (epoch 12.066), train_loss = 1.09859088, grad/param norm = 2.3951e-01, time/batch = 18.8873s	
2740/11350 (epoch 12.070), train_loss = 1.22708043, grad/param norm = 2.4474e-01, time/batch = 17.5363s	
2741/11350 (epoch 12.075), train_loss = 1.09821773, grad/param norm = 2.4687e-01, time/batch = 18.7428s	
2742/11350 (epoch 12.079), train_loss = 1.24885470, grad/param norm = 2.5418e-01, time/batch = 18.2161s	
2743/11350 (epoch 12.084), train_loss = 1.49704711, grad/param norm = 2.8741e-01, time/batch = 19.3012s	
2744/11350 (epoch 12.088), train_loss = 1.43746069, grad/param norm = 2.9854e-01, time/batch = 18.5418s	
2745/11350 (epoch 12.093), train_loss = 1.33660363, grad/param norm = 2.4157e-01, time/batch = 19.8621s	
2746/11350 (epoch 12.097), train_loss = 1.31234782, grad/param norm = 2.6689e-01, time/batch = 19.9629s	
2747/11350 (epoch 12.101), train_loss = 1.16425507, grad/param norm = 2.3683e-01, time/batch = 18.6032s	
2748/11350 (epoch 12.106), train_loss = 1.42286955, grad/param norm = 2.6299e-01, time/batch = 20.2803s	
2749/11350 (epoch 12.110), train_loss = 1.24338491, grad/param norm = 2.8381e-01, time/batch = 18.8692s	
2750/11350 (epoch 12.115), train_loss = 1.22976044, grad/param norm = 2.3516e-01, time/batch = 18.9514s	
2751/11350 (epoch 12.119), train_loss = 1.42397361, grad/param norm = 2.6866e-01, time/batch = 17.3868s	
2752/11350 (epoch 12.123), train_loss = 1.18191092, grad/param norm = 2.3189e-01, time/batch = 17.3478s	
2753/11350 (epoch 12.128), train_loss = 1.21253494, grad/param norm = 2.4999e-01, time/batch = 17.0413s	
2754/11350 (epoch 12.132), train_loss = 1.25776822, grad/param norm = 2.3714e-01, time/batch = 19.2008s	
2755/11350 (epoch 12.137), train_loss = 1.19588580, grad/param norm = 2.6039e-01, time/batch = 19.7100s	
2756/11350 (epoch 12.141), train_loss = 1.40227815, grad/param norm = 2.5593e-01, time/batch = 19.5310s	
2757/11350 (epoch 12.145), train_loss = 1.19204014, grad/param norm = 2.3457e-01, time/batch = 17.1842s	
2758/11350 (epoch 12.150), train_loss = 1.39671923, grad/param norm = 2.8324e-01, time/batch = 17.9597s	
2759/11350 (epoch 12.154), train_loss = 1.50790416, grad/param norm = 3.2921e-01, time/batch = 19.7839s	
2760/11350 (epoch 12.159), train_loss = 1.18122507, grad/param norm = 2.9905e-01, time/batch = 17.0450s	
2761/11350 (epoch 12.163), train_loss = 1.40429325, grad/param norm = 2.5272e-01, time/batch = 20.2761s	
2762/11350 (epoch 12.167), train_loss = 1.42515780, grad/param norm = 2.5845e-01, time/batch = 19.2634s	
2763/11350 (epoch 12.172), train_loss = 1.56185761, grad/param norm = 2.6936e-01, time/batch = 17.3418s	
2764/11350 (epoch 12.176), train_loss = 1.37088528, grad/param norm = 2.4749e-01, time/batch = 18.2940s	
2765/11350 (epoch 12.181), train_loss = 1.35990528, grad/param norm = 2.7523e-01, time/batch = 19.3811s	
2766/11350 (epoch 12.185), train_loss = 1.22876521, grad/param norm = 2.7488e-01, time/batch = 17.9467s	
2767/11350 (epoch 12.189), train_loss = 1.26944867, grad/param norm = 2.4851e-01, time/batch = 18.7071s	
2768/11350 (epoch 12.194), train_loss = 1.20297796, grad/param norm = 2.7275e-01, time/batch = 19.2890s	
2769/11350 (epoch 12.198), train_loss = 1.21107024, grad/param norm = 2.7098e-01, time/batch = 17.2848s	
2770/11350 (epoch 12.203), train_loss = 1.11799672, grad/param norm = 2.3275e-01, time/batch = 19.4996s	
2771/11350 (epoch 12.207), train_loss = 1.16802875, grad/param norm = 2.6393e-01, time/batch = 15.8972s	
2772/11350 (epoch 12.211), train_loss = 1.36590427, grad/param norm = 2.7260e-01, time/batch = 18.7085s	
2773/11350 (epoch 12.216), train_loss = 1.32206960, grad/param norm = 2.7777e-01, time/batch = 17.7814s	
2774/11350 (epoch 12.220), train_loss = 1.28654807, grad/param norm = 2.5479e-01, time/batch = 18.0435s	
2775/11350 (epoch 12.225), train_loss = 1.16862936, grad/param norm = 2.4658e-01, time/batch = 19.3817s	
2776/11350 (epoch 12.229), train_loss = 1.37714301, grad/param norm = 2.3728e-01, time/batch = 18.7800s	
2777/11350 (epoch 12.233), train_loss = 1.31903187, grad/param norm = 2.5736e-01, time/batch = 19.7653s	
2778/11350 (epoch 12.238), train_loss = 1.51008436, grad/param norm = 2.9562e-01, time/batch = 19.7062s	
2779/11350 (epoch 12.242), train_loss = 1.51736657, grad/param norm = 3.0259e-01, time/batch = 18.7032s	
2780/11350 (epoch 12.247), train_loss = 1.09850046, grad/param norm = 2.2934e-01, time/batch = 19.2826s	
2781/11350 (epoch 12.251), train_loss = 1.37242230, grad/param norm = 2.5684e-01, time/batch = 17.6237s	
2782/11350 (epoch 12.256), train_loss = 1.40905311, grad/param norm = 2.6251e-01, time/batch = 16.9504s	
2783/11350 (epoch 12.260), train_loss = 1.22350496, grad/param norm = 2.7187e-01, time/batch = 17.4308s	
2784/11350 (epoch 12.264), train_loss = 1.27835696, grad/param norm = 2.4650e-01, time/batch = 19.1277s	
2785/11350 (epoch 12.269), train_loss = 1.32551395, grad/param norm = 2.8053e-01, time/batch = 18.0424s	
2786/11350 (epoch 12.273), train_loss = 1.41212719, grad/param norm = 2.7411e-01, time/batch = 17.5995s	
2787/11350 (epoch 12.278), train_loss = 1.14989476, grad/param norm = 2.2872e-01, time/batch = 18.9613s	
2788/11350 (epoch 12.282), train_loss = 1.40791301, grad/param norm = 2.7931e-01, time/batch = 18.6342s	
2789/11350 (epoch 12.286), train_loss = 1.45908567, grad/param norm = 2.8185e-01, time/batch = 17.0957s	
2790/11350 (epoch 12.291), train_loss = 1.14654945, grad/param norm = 2.7227e-01, time/batch = 18.5510s	
2791/11350 (epoch 12.295), train_loss = 1.29848384, grad/param norm = 2.4576e-01, time/batch = 18.3188s	
2792/11350 (epoch 12.300), train_loss = 1.29056610, grad/param norm = 2.4538e-01, time/batch = 18.6943s	
2793/11350 (epoch 12.304), train_loss = 1.22096969, grad/param norm = 2.3622e-01, time/batch = 18.2133s	
2794/11350 (epoch 12.308), train_loss = 1.25208794, grad/param norm = 2.5190e-01, time/batch = 20.4478s	
2795/11350 (epoch 12.313), train_loss = 1.37737431, grad/param norm = 2.5164e-01, time/batch = 18.4616s	
2796/11350 (epoch 12.317), train_loss = 1.14510997, grad/param norm = 2.2899e-01, time/batch = 18.6281s	
2797/11350 (epoch 12.322), train_loss = 1.23989192, grad/param norm = 2.6807e-01, time/batch = 20.2850s	
2798/11350 (epoch 12.326), train_loss = 1.28657639, grad/param norm = 2.3877e-01, time/batch = 18.1854s	
2799/11350 (epoch 12.330), train_loss = 1.08297563, grad/param norm = 2.4389e-01, time/batch = 19.0272s	
2800/11350 (epoch 12.335), train_loss = 1.00940092, grad/param norm = 2.3454e-01, time/batch = 18.0464s	
2801/11350 (epoch 12.339), train_loss = 1.13966140, grad/param norm = 2.4017e-01, time/batch = 19.4236s	
2802/11350 (epoch 12.344), train_loss = 1.21074262, grad/param norm = 2.3494e-01, time/batch = 18.3248s	
2803/11350 (epoch 12.348), train_loss = 1.24155615, grad/param norm = 2.4075e-01, time/batch = 20.1084s	
2804/11350 (epoch 12.352), train_loss = 1.09218390, grad/param norm = 2.2550e-01, time/batch = 20.4402s	
2805/11350 (epoch 12.357), train_loss = 1.21307505, grad/param norm = 2.4368e-01, time/batch = 17.6062s	
2806/11350 (epoch 12.361), train_loss = 1.01256786, grad/param norm = 2.1810e-01, time/batch = 17.7246s	
2807/11350 (epoch 12.366), train_loss = 1.38275642, grad/param norm = 2.8052e-01, time/batch = 19.5386s	
2808/11350 (epoch 12.370), train_loss = 1.23660998, grad/param norm = 2.7633e-01, time/batch = 19.1934s	
2809/11350 (epoch 12.374), train_loss = 1.23599769, grad/param norm = 2.6934e-01, time/batch = 19.7778s	
2810/11350 (epoch 12.379), train_loss = 1.30350148, grad/param norm = 2.5413e-01, time/batch = 19.7817s	
2811/11350 (epoch 12.383), train_loss = 1.05859432, grad/param norm = 2.2022e-01, time/batch = 18.2844s	
2812/11350 (epoch 12.388), train_loss = 1.33939462, grad/param norm = 2.7873e-01, time/batch = 18.5469s	
2813/11350 (epoch 12.392), train_loss = 1.28268967, grad/param norm = 3.0947e-01, time/batch = 18.9609s	
2814/11350 (epoch 12.396), train_loss = 1.35817138, grad/param norm = 2.7074e-01, time/batch = 18.6159s	
2815/11350 (epoch 12.401), train_loss = 1.26200744, grad/param norm = 2.5884e-01, time/batch = 16.9413s	
2816/11350 (epoch 12.405), train_loss = 1.42540994, grad/param norm = 2.4551e-01, time/batch = 20.0331s	
2817/11350 (epoch 12.410), train_loss = 1.51690855, grad/param norm = 2.7994e-01, time/batch = 17.8650s	
2818/11350 (epoch 12.414), train_loss = 1.13761447, grad/param norm = 2.4874e-01, time/batch = 18.3550s	
2819/11350 (epoch 12.419), train_loss = 1.29245560, grad/param norm = 2.9154e-01, time/batch = 19.0490s	
2820/11350 (epoch 12.423), train_loss = 1.42525032, grad/param norm = 2.8404e-01, time/batch = 20.8665s	
2821/11350 (epoch 12.427), train_loss = 1.45418177, grad/param norm = 2.7085e-01, time/batch = 19.1779s	
2822/11350 (epoch 12.432), train_loss = 1.46896779, grad/param norm = 2.8633e-01, time/batch = 16.8802s	
2823/11350 (epoch 12.436), train_loss = 1.32012469, grad/param norm = 2.9268e-01, time/batch = 18.7686s	
2824/11350 (epoch 12.441), train_loss = 1.54286345, grad/param norm = 2.9735e-01, time/batch = 17.6182s	
2825/11350 (epoch 12.445), train_loss = 1.05683940, grad/param norm = 2.1695e-01, time/batch = 20.3597s	
2826/11350 (epoch 12.449), train_loss = 1.23004004, grad/param norm = 2.7545e-01, time/batch = 19.2893s	
2827/11350 (epoch 12.454), train_loss = 1.46354393, grad/param norm = 3.0241e-01, time/batch = 17.9578s	
2828/11350 (epoch 12.458), train_loss = 1.06578593, grad/param norm = 2.3082e-01, time/batch = 20.6189s	
2829/11350 (epoch 12.463), train_loss = 1.14528012, grad/param norm = 2.3457e-01, time/batch = 19.3739s	
2830/11350 (epoch 12.467), train_loss = 1.59951050, grad/param norm = 3.0528e-01, time/batch = 18.5104s	
2831/11350 (epoch 12.471), train_loss = 1.45512106, grad/param norm = 3.0796e-01, time/batch = 19.6841s	
2832/11350 (epoch 12.476), train_loss = 1.41019595, grad/param norm = 2.5811e-01, time/batch = 18.2196s	
2833/11350 (epoch 12.480), train_loss = 1.51868148, grad/param norm = 2.6848e-01, time/batch = 16.9486s	
2834/11350 (epoch 12.485), train_loss = 1.28617103, grad/param norm = 2.4418e-01, time/batch = 17.3795s	
2835/11350 (epoch 12.489), train_loss = 1.44372632, grad/param norm = 2.6579e-01, time/batch = 19.2010s	
2836/11350 (epoch 12.493), train_loss = 1.39922233, grad/param norm = 2.6651e-01, time/batch = 19.1936s	
2837/11350 (epoch 12.498), train_loss = 1.05758874, grad/param norm = 2.3770e-01, time/batch = 18.7711s	
2838/11350 (epoch 12.502), train_loss = 1.37639120, grad/param norm = 2.6973e-01, time/batch = 18.7094s	
2839/11350 (epoch 12.507), train_loss = 1.12715109, grad/param norm = 2.4177e-01, time/batch = 19.7818s	
2840/11350 (epoch 12.511), train_loss = 1.57156037, grad/param norm = 2.7841e-01, time/batch = 17.5085s	
2841/11350 (epoch 12.515), train_loss = 1.27825045, grad/param norm = 2.6602e-01, time/batch = 20.0391s	
2842/11350 (epoch 12.520), train_loss = 1.51510125, grad/param norm = 2.9546e-01, time/batch = 17.2239s	
2843/11350 (epoch 12.524), train_loss = 1.29071009, grad/param norm = 2.5881e-01, time/batch = 17.8698s	
2844/11350 (epoch 12.529), train_loss = 1.34952935, grad/param norm = 2.5199e-01, time/batch = 18.7786s	
2845/11350 (epoch 12.533), train_loss = 1.60137505, grad/param norm = 2.7856e-01, time/batch = 16.4320s	
2846/11350 (epoch 12.537), train_loss = 1.39663110, grad/param norm = 2.7866e-01, time/batch = 18.5371s	
2847/11350 (epoch 12.542), train_loss = 1.44391179, grad/param norm = 2.3472e-01, time/batch = 19.4521s	
2848/11350 (epoch 12.546), train_loss = 1.67934513, grad/param norm = 2.7704e-01, time/batch = 18.6302s	
2849/11350 (epoch 12.551), train_loss = 1.33714076, grad/param norm = 2.3014e-01, time/batch = 17.7927s	
2850/11350 (epoch 12.555), train_loss = 1.27026689, grad/param norm = 2.5045e-01, time/batch = 19.3443s	
2851/11350 (epoch 12.559), train_loss = 1.26835258, grad/param norm = 2.5568e-01, time/batch = 20.1862s	
2852/11350 (epoch 12.564), train_loss = 1.48473182, grad/param norm = 2.8809e-01, time/batch = 19.2923s	
2853/11350 (epoch 12.568), train_loss = 1.39335114, grad/param norm = 2.5093e-01, time/batch = 18.5044s	
2854/11350 (epoch 12.573), train_loss = 1.57323931, grad/param norm = 2.9568e-01, time/batch = 18.1421s	
2855/11350 (epoch 12.577), train_loss = 1.56593645, grad/param norm = 2.8876e-01, time/batch = 18.6315s	
2856/11350 (epoch 12.581), train_loss = 1.45134508, grad/param norm = 2.5711e-01, time/batch = 17.7112s	
2857/11350 (epoch 12.586), train_loss = 1.48880444, grad/param norm = 2.8608e-01, time/batch = 18.4588s	
2858/11350 (epoch 12.590), train_loss = 1.59357473, grad/param norm = 2.8699e-01, time/batch = 20.5341s	
2859/11350 (epoch 12.595), train_loss = 1.58634733, grad/param norm = 2.6819e-01, time/batch = 18.3670s	
2860/11350 (epoch 12.599), train_loss = 1.46609099, grad/param norm = 2.6622e-01, time/batch = 20.0910s	
2861/11350 (epoch 12.604), train_loss = 1.34248705, grad/param norm = 2.3744e-01, time/batch = 20.2071s	
2862/11350 (epoch 12.608), train_loss = 1.45465598, grad/param norm = 2.6260e-01, time/batch = 16.9173s	
2863/11350 (epoch 12.612), train_loss = 1.27030668, grad/param norm = 2.3343e-01, time/batch = 17.2091s	
2864/11350 (epoch 12.617), train_loss = 1.57392210, grad/param norm = 2.9143e-01, time/batch = 17.7745s	
2865/11350 (epoch 12.621), train_loss = 1.50989185, grad/param norm = 2.6323e-01, time/batch = 17.6758s	
2866/11350 (epoch 12.626), train_loss = 1.41719132, grad/param norm = 2.7000e-01, time/batch = 18.5162s	
2867/11350 (epoch 12.630), train_loss = 1.45019509, grad/param norm = 2.5096e-01, time/batch = 17.6402s	
2868/11350 (epoch 12.634), train_loss = 1.47560284, grad/param norm = 2.4926e-01, time/batch = 19.4660s	
2869/11350 (epoch 12.639), train_loss = 1.32184920, grad/param norm = 2.4895e-01, time/batch = 17.8494s	
2870/11350 (epoch 12.643), train_loss = 1.31387131, grad/param norm = 2.4598e-01, time/batch = 19.8674s	
2871/11350 (epoch 12.648), train_loss = 1.38569211, grad/param norm = 2.7054e-01, time/batch = 19.7750s	
2872/11350 (epoch 12.652), train_loss = 1.38147408, grad/param norm = 2.8983e-01, time/batch = 17.9419s	
2873/11350 (epoch 12.656), train_loss = 1.52850595, grad/param norm = 2.9571e-01, time/batch = 19.6171s	
2874/11350 (epoch 12.661), train_loss = 1.56296510, grad/param norm = 2.6249e-01, time/batch = 16.3504s	
2875/11350 (epoch 12.665), train_loss = 1.41188331, grad/param norm = 2.7633e-01, time/batch = 17.5508s	
2876/11350 (epoch 12.670), train_loss = 1.42252225, grad/param norm = 2.9803e-01, time/batch = 19.3034s	
2877/11350 (epoch 12.674), train_loss = 1.32254388, grad/param norm = 2.4789e-01, time/batch = 19.2852s	
2878/11350 (epoch 12.678), train_loss = 1.35840528, grad/param norm = 2.3847e-01, time/batch = 18.7100s	
2879/11350 (epoch 12.683), train_loss = 1.29831736, grad/param norm = 2.4377e-01, time/batch = 18.6809s	
2880/11350 (epoch 12.687), train_loss = 1.27762096, grad/param norm = 2.7931e-01, time/batch = 20.3812s	
2881/11350 (epoch 12.692), train_loss = 1.72912559, grad/param norm = 3.1277e-01, time/batch = 18.0286s	
2882/11350 (epoch 12.696), train_loss = 1.54071765, grad/param norm = 2.7198e-01, time/batch = 18.6313s	
2883/11350 (epoch 12.700), train_loss = 1.46909333, grad/param norm = 2.6321e-01, time/batch = 20.2899s	
2884/11350 (epoch 12.705), train_loss = 1.55556660, grad/param norm = 2.7719e-01, time/batch = 20.7553s	
2885/11350 (epoch 12.709), train_loss = 1.52166776, grad/param norm = 2.5058e-01, time/batch = 18.7140s	
2886/11350 (epoch 12.714), train_loss = 1.32156480, grad/param norm = 2.4088e-01, time/batch = 18.3742s	
2887/11350 (epoch 12.718), train_loss = 1.26104975, grad/param norm = 2.6488e-01, time/batch = 20.5325s	
2888/11350 (epoch 12.722), train_loss = 1.48650026, grad/param norm = 3.3055e-01, time/batch = 18.4345s	
2889/11350 (epoch 12.727), train_loss = 1.39309391, grad/param norm = 2.5300e-01, time/batch = 20.7763s	
2890/11350 (epoch 12.731), train_loss = 1.46140760, grad/param norm = 2.6070e-01, time/batch = 20.9590s	
2891/11350 (epoch 12.736), train_loss = 1.38898818, grad/param norm = 3.0810e-01, time/batch = 19.5250s	
2892/11350 (epoch 12.740), train_loss = 1.38806298, grad/param norm = 3.0890e-01, time/batch = 20.9583s	
2893/11350 (epoch 12.744), train_loss = 1.53201158, grad/param norm = 2.5504e-01, time/batch = 20.4296s	
2894/11350 (epoch 12.749), train_loss = 1.51386679, grad/param norm = 2.8403e-01, time/batch = 17.6980s	
2895/11350 (epoch 12.753), train_loss = 1.49062559, grad/param norm = 3.1384e-01, time/batch = 18.5098s	
2896/11350 (epoch 12.758), train_loss = 1.37185941, grad/param norm = 2.6754e-01, time/batch = 19.4509s	
2897/11350 (epoch 12.762), train_loss = 1.45928970, grad/param norm = 2.8414e-01, time/batch = 19.1023s	
2898/11350 (epoch 12.767), train_loss = 1.47283729, grad/param norm = 2.6503e-01, time/batch = 19.2837s	
2899/11350 (epoch 12.771), train_loss = 1.52945645, grad/param norm = 2.5884e-01, time/batch = 20.4578s	
2900/11350 (epoch 12.775), train_loss = 1.32774828, grad/param norm = 2.6645e-01, time/batch = 34.2801s	
2901/11350 (epoch 12.780), train_loss = 1.47888202, grad/param norm = 2.5754e-01, time/batch = 18.6046s	
2902/11350 (epoch 12.784), train_loss = 1.31116486, grad/param norm = 2.4584e-01, time/batch = 18.7666s	
2903/11350 (epoch 12.789), train_loss = 1.39357424, grad/param norm = 2.9876e-01, time/batch = 19.9667s	
2904/11350 (epoch 12.793), train_loss = 1.44918497, grad/param norm = 2.5298e-01, time/batch = 18.8828s	
2905/11350 (epoch 12.797), train_loss = 1.35422743, grad/param norm = 2.6157e-01, time/batch = 19.0138s	
2906/11350 (epoch 12.802), train_loss = 1.41708432, grad/param norm = 2.5409e-01, time/batch = 19.9611s	
2907/11350 (epoch 12.806), train_loss = 1.42141610, grad/param norm = 2.5387e-01, time/batch = 19.5177s	
2908/11350 (epoch 12.811), train_loss = 1.34134087, grad/param norm = 3.0737e-01, time/batch = 17.5851s	
2909/11350 (epoch 12.815), train_loss = 1.23102348, grad/param norm = 2.4112e-01, time/batch = 18.2996s	
2910/11350 (epoch 12.819), train_loss = 1.29633569, grad/param norm = 2.7415e-01, time/batch = 19.3731s	
2911/11350 (epoch 12.824), train_loss = 1.36749451, grad/param norm = 2.5387e-01, time/batch = 18.1260s	
2912/11350 (epoch 12.828), train_loss = 1.37406347, grad/param norm = 2.5613e-01, time/batch = 19.1125s	
2913/11350 (epoch 12.833), train_loss = 1.41451844, grad/param norm = 2.8347e-01, time/batch = 20.1009s	
2914/11350 (epoch 12.837), train_loss = 1.37888053, grad/param norm = 2.5540e-01, time/batch = 18.1935s	
2915/11350 (epoch 12.841), train_loss = 1.68576554, grad/param norm = 2.7069e-01, time/batch = 19.0802s	
2916/11350 (epoch 12.846), train_loss = 1.36711154, grad/param norm = 2.7108e-01, time/batch = 20.2844s	
2917/11350 (epoch 12.850), train_loss = 1.50225309, grad/param norm = 2.9510e-01, time/batch = 19.8736s	
2918/11350 (epoch 12.855), train_loss = 1.21313050, grad/param norm = 2.4238e-01, time/batch = 18.6849s	
2919/11350 (epoch 12.859), train_loss = 1.40491483, grad/param norm = 2.9559e-01, time/batch = 18.4499s	
2920/11350 (epoch 12.863), train_loss = 1.25872802, grad/param norm = 2.6430e-01, time/batch = 16.6718s	
2921/11350 (epoch 12.868), train_loss = 1.38081891, grad/param norm = 2.5440e-01, time/batch = 18.9420s	
2922/11350 (epoch 12.872), train_loss = 1.35751256, grad/param norm = 2.6335e-01, time/batch = 19.2859s	
2923/11350 (epoch 12.877), train_loss = 1.37010822, grad/param norm = 2.6357e-01, time/batch = 19.9517s	
2924/11350 (epoch 12.881), train_loss = 1.65193824, grad/param norm = 2.9038e-01, time/batch = 18.0405s	
2925/11350 (epoch 12.885), train_loss = 1.61175789, grad/param norm = 2.7530e-01, time/batch = 19.6355s	
2926/11350 (epoch 12.890), train_loss = 1.46307784, grad/param norm = 2.6140e-01, time/batch = 19.1092s	
2927/11350 (epoch 12.894), train_loss = 1.22103256, grad/param norm = 2.5529e-01, time/batch = 17.6914s	
2928/11350 (epoch 12.899), train_loss = 1.48340339, grad/param norm = 2.4584e-01, time/batch = 19.6220s	
2929/11350 (epoch 12.903), train_loss = 1.53482343, grad/param norm = 2.5783e-01, time/batch = 18.1375s	
2930/11350 (epoch 12.907), train_loss = 1.46949358, grad/param norm = 2.5890e-01, time/batch = 19.2127s	
2931/11350 (epoch 12.912), train_loss = 1.36298098, grad/param norm = 2.5207e-01, time/batch = 19.6899s	
2932/11350 (epoch 12.916), train_loss = 1.52985222, grad/param norm = 3.3826e-01, time/batch = 18.8656s	
2933/11350 (epoch 12.921), train_loss = 1.46250183, grad/param norm = 2.6488e-01, time/batch = 19.6038s	
2934/11350 (epoch 12.925), train_loss = 1.24995272, grad/param norm = 2.3708e-01, time/batch = 16.2826s	
2935/11350 (epoch 12.930), train_loss = 1.50494100, grad/param norm = 2.6918e-01, time/batch = 18.3725s	
2936/11350 (epoch 12.934), train_loss = 1.56834337, grad/param norm = 2.5752e-01, time/batch = 17.6064s	
2937/11350 (epoch 12.938), train_loss = 1.33458469, grad/param norm = 2.6106e-01, time/batch = 18.3788s	
2938/11350 (epoch 12.943), train_loss = 1.53299265, grad/param norm = 2.8412e-01, time/batch = 17.2102s	
2939/11350 (epoch 12.947), train_loss = 1.54050859, grad/param norm = 3.1997e-01, time/batch = 18.0610s	
2940/11350 (epoch 12.952), train_loss = 1.50768577, grad/param norm = 3.3459e-01, time/batch = 18.8664s	
2941/11350 (epoch 12.956), train_loss = 1.20705723, grad/param norm = 2.8084e-01, time/batch = 19.6980s	
2942/11350 (epoch 12.960), train_loss = 1.41225574, grad/param norm = 2.9232e-01, time/batch = 18.2737s	
2943/11350 (epoch 12.965), train_loss = 1.29561394, grad/param norm = 2.7792e-01, time/batch = 18.1834s	
2944/11350 (epoch 12.969), train_loss = 1.32007792, grad/param norm = 3.0920e-01, time/batch = 18.6081s	
2945/11350 (epoch 12.974), train_loss = 1.21517426, grad/param norm = 2.7381e-01, time/batch = 20.1236s	
2946/11350 (epoch 12.978), train_loss = 1.41089313, grad/param norm = 2.7727e-01, time/batch = 19.9528s	
2947/11350 (epoch 12.982), train_loss = 1.13189028, grad/param norm = 2.3708e-01, time/batch = 15.6188s	
2948/11350 (epoch 12.987), train_loss = 1.34902644, grad/param norm = 2.5614e-01, time/batch = 18.1822s	
2949/11350 (epoch 12.991), train_loss = 1.24489072, grad/param norm = 3.0069e-01, time/batch = 19.8696s	
2950/11350 (epoch 12.996), train_loss = 1.44277523, grad/param norm = 2.9134e-01, time/batch = 19.0247s	
decayed learning rate by a factor 0.97 to 0.00177058562	
2951/11350 (epoch 13.000), train_loss = 1.10910636, grad/param norm = 2.6148e-01, time/batch = 19.8729s	
2952/11350 (epoch 13.004), train_loss = 1.37224156, grad/param norm = 2.8302e-01, time/batch = 20.2846s	
2953/11350 (epoch 13.009), train_loss = 1.43472476, grad/param norm = 2.6880e-01, time/batch = 17.1864s	
2954/11350 (epoch 13.013), train_loss = 0.93939355, grad/param norm = 2.1969e-01, time/batch = 20.5216s	
2955/11350 (epoch 13.018), train_loss = 1.02511542, grad/param norm = 2.4614e-01, time/batch = 18.7110s	
2956/11350 (epoch 13.022), train_loss = 1.07506472, grad/param norm = 2.6065e-01, time/batch = 18.2701s	
2957/11350 (epoch 13.026), train_loss = 1.14049033, grad/param norm = 2.5252e-01, time/batch = 18.0189s	
2958/11350 (epoch 13.031), train_loss = 1.09126858, grad/param norm = 2.4962e-01, time/batch = 19.4677s	
2959/11350 (epoch 13.035), train_loss = 1.18069254, grad/param norm = 2.5101e-01, time/batch = 17.0364s	
2960/11350 (epoch 13.040), train_loss = 1.20154687, grad/param norm = 2.6729e-01, time/batch = 18.5364s	
2961/11350 (epoch 13.044), train_loss = 1.14317148, grad/param norm = 2.5809e-01, time/batch = 16.4416s	
2962/11350 (epoch 13.048), train_loss = 1.12840420, grad/param norm = 2.3480e-01, time/batch = 19.0204s	
2963/11350 (epoch 13.053), train_loss = 1.21060129, grad/param norm = 2.3398e-01, time/batch = 17.8344s	
2964/11350 (epoch 13.057), train_loss = 1.29760785, grad/param norm = 2.6213e-01, time/batch = 20.3718s	
2965/11350 (epoch 13.062), train_loss = 1.04421495, grad/param norm = 2.2848e-01, time/batch = 17.3862s	
2966/11350 (epoch 13.066), train_loss = 1.05200797, grad/param norm = 2.5037e-01, time/batch = 17.5226s	
2967/11350 (epoch 13.070), train_loss = 1.18289875, grad/param norm = 2.6415e-01, time/batch = 18.4492s	
2968/11350 (epoch 13.075), train_loss = 1.04878466, grad/param norm = 2.5166e-01, time/batch = 20.3021s	
2969/11350 (epoch 13.079), train_loss = 1.19305495, grad/param norm = 2.5309e-01, time/batch = 18.6172s	
2970/11350 (epoch 13.084), train_loss = 1.45183036, grad/param norm = 3.2563e-01, time/batch = 19.2097s	
2971/11350 (epoch 13.088), train_loss = 1.38831276, grad/param norm = 3.2172e-01, time/batch = 17.6335s	
2972/11350 (epoch 13.093), train_loss = 1.30405475, grad/param norm = 2.4848e-01, time/batch = 18.3478s	
2973/11350 (epoch 13.097), train_loss = 1.25256021, grad/param norm = 2.6466e-01, time/batch = 17.6074s	
2974/11350 (epoch 13.101), train_loss = 1.11547387, grad/param norm = 2.4762e-01, time/batch = 16.9452s	
2975/11350 (epoch 13.106), train_loss = 1.35728496, grad/param norm = 2.5307e-01, time/batch = 18.4689s	
2976/11350 (epoch 13.110), train_loss = 1.19106010, grad/param norm = 2.6568e-01, time/batch = 18.9364s	
2977/11350 (epoch 13.115), train_loss = 1.18726910, grad/param norm = 2.5114e-01, time/batch = 18.7972s	
2978/11350 (epoch 13.119), train_loss = 1.35917365, grad/param norm = 2.6207e-01, time/batch = 19.7100s	
2979/11350 (epoch 13.123), train_loss = 1.13611940, grad/param norm = 2.4107e-01, time/batch = 18.0115s	
2980/11350 (epoch 13.128), train_loss = 1.16327328, grad/param norm = 2.7166e-01, time/batch = 19.9604s	
2981/11350 (epoch 13.132), train_loss = 1.20852096, grad/param norm = 2.3934e-01, time/batch = 17.1228s	
2982/11350 (epoch 13.137), train_loss = 1.15446474, grad/param norm = 2.6988e-01, time/batch = 18.2884s	
2983/11350 (epoch 13.141), train_loss = 1.35808205, grad/param norm = 2.6105e-01, time/batch = 20.1242s	
2984/11350 (epoch 13.145), train_loss = 1.14633774, grad/param norm = 2.3479e-01, time/batch = 19.8763s	
2985/11350 (epoch 13.150), train_loss = 1.34040455, grad/param norm = 3.1152e-01, time/batch = 18.8669s	
2986/11350 (epoch 13.154), train_loss = 1.45630000, grad/param norm = 3.6798e-01, time/batch = 19.7815s	
2987/11350 (epoch 13.159), train_loss = 1.11845162, grad/param norm = 2.8340e-01, time/batch = 19.8543s	
2988/11350 (epoch 13.163), train_loss = 1.34167024, grad/param norm = 2.5054e-01, time/batch = 18.6303s	
2989/11350 (epoch 13.167), train_loss = 1.38137202, grad/param norm = 2.8948e-01, time/batch = 19.9634s	
2990/11350 (epoch 13.172), train_loss = 1.50346018, grad/param norm = 2.7437e-01, time/batch = 20.4407s	
2991/11350 (epoch 13.176), train_loss = 1.32211747, grad/param norm = 2.5437e-01, time/batch = 17.7852s	
2992/11350 (epoch 13.181), train_loss = 1.30040748, grad/param norm = 2.8094e-01, time/batch = 16.3478s	
2993/11350 (epoch 13.185), train_loss = 1.16645736, grad/param norm = 2.6892e-01, time/batch = 19.4597s	
2994/11350 (epoch 13.189), train_loss = 1.21051855, grad/param norm = 2.3885e-01, time/batch = 19.3698s	
2995/11350 (epoch 13.194), train_loss = 1.14982908, grad/param norm = 2.6193e-01, time/batch = 18.1018s	
2996/11350 (epoch 13.198), train_loss = 1.15901015, grad/param norm = 2.7987e-01, time/batch = 19.1213s	
2997/11350 (epoch 13.203), train_loss = 1.08294986, grad/param norm = 2.3920e-01, time/batch = 19.7859s	
2998/11350 (epoch 13.207), train_loss = 1.12402214, grad/param norm = 2.6859e-01, time/batch = 19.8444s	
2999/11350 (epoch 13.211), train_loss = 1.30374131, grad/param norm = 2.5545e-01, time/batch = 20.4629s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch13.22_1.7131.t7	
3000/11350 (epoch 13.216), train_loss = 1.26938767, grad/param norm = 2.7502e-01, time/batch = 19.4481s	
3001/11350 (epoch 13.220), train_loss = 1.45115034, grad/param norm = 3.4990e-01, time/batch = 19.5400s	
3002/11350 (epoch 13.225), train_loss = 1.13425486, grad/param norm = 2.7226e-01, time/batch = 16.8654s	
3003/11350 (epoch 13.229), train_loss = 1.33652788, grad/param norm = 2.4184e-01, time/batch = 16.0435s	
3004/11350 (epoch 13.233), train_loss = 1.26383158, grad/param norm = 2.4521e-01, time/batch = 17.5328s	
3005/11350 (epoch 13.238), train_loss = 1.44863581, grad/param norm = 2.9493e-01, time/batch = 18.7721s	
3006/11350 (epoch 13.242), train_loss = 1.45213592, grad/param norm = 3.0792e-01, time/batch = 17.5493s	
3007/11350 (epoch 13.247), train_loss = 1.06259149, grad/param norm = 2.4865e-01, time/batch = 20.6957s	
3008/11350 (epoch 13.251), train_loss = 1.32043980, grad/param norm = 2.7471e-01, time/batch = 19.0785s	
3009/11350 (epoch 13.256), train_loss = 1.34760604, grad/param norm = 2.6855e-01, time/batch = 19.7025s	
3010/11350 (epoch 13.260), train_loss = 1.17894493, grad/param norm = 3.0244e-01, time/batch = 19.3684s	
3011/11350 (epoch 13.264), train_loss = 1.22080946, grad/param norm = 2.5039e-01, time/batch = 18.8478s	
3012/11350 (epoch 13.269), train_loss = 1.27840273, grad/param norm = 2.8879e-01, time/batch = 19.2026s	
3013/11350 (epoch 13.273), train_loss = 1.35968226, grad/param norm = 2.8501e-01, time/batch = 20.6127s	
3014/11350 (epoch 13.278), train_loss = 1.11639454, grad/param norm = 2.5472e-01, time/batch = 18.4499s	
3015/11350 (epoch 13.282), train_loss = 1.35389549, grad/param norm = 2.7878e-01, time/batch = 19.2968s	
3016/11350 (epoch 13.286), train_loss = 1.39336341, grad/param norm = 2.6809e-01, time/batch = 19.4569s	
3017/11350 (epoch 13.291), train_loss = 1.10286600, grad/param norm = 3.1381e-01, time/batch = 18.0055s	
3018/11350 (epoch 13.295), train_loss = 1.25915493, grad/param norm = 2.6995e-01, time/batch = 19.3639s	
3019/11350 (epoch 13.300), train_loss = 1.24325193, grad/param norm = 2.3757e-01, time/batch = 18.8736s	
3020/11350 (epoch 13.304), train_loss = 1.17732201, grad/param norm = 2.3718e-01, time/batch = 17.6114s	
3021/11350 (epoch 13.308), train_loss = 1.20154740, grad/param norm = 2.5805e-01, time/batch = 20.5227s	
3022/11350 (epoch 13.313), train_loss = 1.32290634, grad/param norm = 2.4843e-01, time/batch = 18.7073s	
3023/11350 (epoch 13.317), train_loss = 1.11993017, grad/param norm = 2.4476e-01, time/batch = 16.4308s	
3024/11350 (epoch 13.322), train_loss = 1.19141410, grad/param norm = 2.6938e-01, time/batch = 17.6911s	
3025/11350 (epoch 13.326), train_loss = 1.24262482, grad/param norm = 2.3893e-01, time/batch = 19.2058s	
3026/11350 (epoch 13.330), train_loss = 1.04824188, grad/param norm = 2.5277e-01, time/batch = 19.3776s	
3027/11350 (epoch 13.335), train_loss = 0.95850046, grad/param norm = 2.3824e-01, time/batch = 19.1908s	
3028/11350 (epoch 13.339), train_loss = 1.09096164, grad/param norm = 2.4881e-01, time/batch = 19.8615s	
3029/11350 (epoch 13.344), train_loss = 1.15683529, grad/param norm = 2.2708e-01, time/batch = 20.1229s	
3030/11350 (epoch 13.348), train_loss = 1.19109622, grad/param norm = 2.3811e-01, time/batch = 18.7766s	
3031/11350 (epoch 13.352), train_loss = 1.05202009, grad/param norm = 2.2954e-01, time/batch = 19.6144s	
3032/11350 (epoch 13.357), train_loss = 1.15926897, grad/param norm = 2.3696e-01, time/batch = 19.5382s	
3033/11350 (epoch 13.361), train_loss = 0.96648713, grad/param norm = 2.1308e-01, time/batch = 18.2143s	
3034/11350 (epoch 13.366), train_loss = 1.32014263, grad/param norm = 2.6299e-01, time/batch = 20.7897s	
3035/11350 (epoch 13.370), train_loss = 1.18075128, grad/param norm = 2.9354e-01, time/batch = 18.1862s	
3036/11350 (epoch 13.374), train_loss = 1.19733705, grad/param norm = 2.9836e-01, time/batch = 18.2596s	
3037/11350 (epoch 13.379), train_loss = 1.24079505, grad/param norm = 2.6156e-01, time/batch = 20.4604s	
3038/11350 (epoch 13.383), train_loss = 1.02122536, grad/param norm = 2.2153e-01, time/batch = 18.9564s	
3039/11350 (epoch 13.388), train_loss = 1.28037787, grad/param norm = 2.8753e-01, time/batch = 18.8720s	
3040/11350 (epoch 13.392), train_loss = 1.21490494, grad/param norm = 3.0581e-01, time/batch = 19.6272s	
3041/11350 (epoch 13.396), train_loss = 1.28728211, grad/param norm = 2.5282e-01, time/batch = 18.7880s	
3042/11350 (epoch 13.401), train_loss = 1.21667438, grad/param norm = 2.6756e-01, time/batch = 17.8483s	
3043/11350 (epoch 13.405), train_loss = 1.37574850, grad/param norm = 2.4960e-01, time/batch = 19.2898s	
3044/11350 (epoch 13.410), train_loss = 1.45073451, grad/param norm = 2.8041e-01, time/batch = 19.1241s	
3045/11350 (epoch 13.414), train_loss = 1.07725114, grad/param norm = 2.5100e-01, time/batch = 18.8644s	
3046/11350 (epoch 13.419), train_loss = 1.20985810, grad/param norm = 2.9872e-01, time/batch = 17.1986s	
3047/11350 (epoch 13.423), train_loss = 1.35417774, grad/param norm = 2.6703e-01, time/batch = 18.5213s	
3048/11350 (epoch 13.427), train_loss = 1.39086093, grad/param norm = 2.7402e-01, time/batch = 14.8404s	
3049/11350 (epoch 13.432), train_loss = 1.39931447, grad/param norm = 2.9535e-01, time/batch = 18.5377s	
3050/11350 (epoch 13.436), train_loss = 1.26546823, grad/param norm = 3.2095e-01, time/batch = 18.1372s	
3051/11350 (epoch 13.441), train_loss = 1.49246573, grad/param norm = 3.0657e-01, time/batch = 15.9400s	
3052/11350 (epoch 13.445), train_loss = 1.01274330, grad/param norm = 2.0874e-01, time/batch = 17.2796s	
3053/11350 (epoch 13.449), train_loss = 1.18205703, grad/param norm = 2.6899e-01, time/batch = 19.3604s	
3054/11350 (epoch 13.454), train_loss = 1.40283770, grad/param norm = 2.8063e-01, time/batch = 17.4424s	
3055/11350 (epoch 13.458), train_loss = 1.02411891, grad/param norm = 2.3681e-01, time/batch = 16.3318s	
3056/11350 (epoch 13.463), train_loss = 1.09521987, grad/param norm = 2.3111e-01, time/batch = 16.2410s	
3057/11350 (epoch 13.467), train_loss = 1.54048185, grad/param norm = 3.0398e-01, time/batch = 17.4283s	
3058/11350 (epoch 13.471), train_loss = 1.39841606, grad/param norm = 3.2931e-01, time/batch = 15.6943s	
3059/11350 (epoch 13.476), train_loss = 1.34340605, grad/param norm = 2.5071e-01, time/batch = 15.3104s	
3060/11350 (epoch 13.480), train_loss = 1.45236322, grad/param norm = 2.5697e-01, time/batch = 16.3475s	
3061/11350 (epoch 13.485), train_loss = 1.23448519, grad/param norm = 2.4126e-01, time/batch = 19.9592s	
3062/11350 (epoch 13.489), train_loss = 1.39834603, grad/param norm = 2.7698e-01, time/batch = 19.1153s	
3063/11350 (epoch 13.493), train_loss = 1.34787569, grad/param norm = 2.7851e-01, time/batch = 16.1945s	
3064/11350 (epoch 13.498), train_loss = 1.01674336, grad/param norm = 2.4488e-01, time/batch = 19.6130s	
3065/11350 (epoch 13.502), train_loss = 1.32048064, grad/param norm = 2.7449e-01, time/batch = 17.5273s	
3066/11350 (epoch 13.507), train_loss = 1.08692248, grad/param norm = 2.4347e-01, time/batch = 18.4412s	
3067/11350 (epoch 13.511), train_loss = 1.50542210, grad/param norm = 2.7104e-01, time/batch = 18.8847s	
3068/11350 (epoch 13.515), train_loss = 1.22884727, grad/param norm = 2.3595e-01, time/batch = 20.7846s	
3069/11350 (epoch 13.520), train_loss = 1.45733194, grad/param norm = 2.9065e-01, time/batch = 17.1976s	
3070/11350 (epoch 13.524), train_loss = 1.25023704, grad/param norm = 2.6413e-01, time/batch = 20.6148s	
3071/11350 (epoch 13.529), train_loss = 1.27322210, grad/param norm = 2.3925e-01, time/batch = 21.0224s	
3072/11350 (epoch 13.533), train_loss = 1.54206017, grad/param norm = 2.7773e-01, time/batch = 17.7820s	
3073/11350 (epoch 13.537), train_loss = 1.34349391, grad/param norm = 2.7368e-01, time/batch = 20.1778s	
3074/11350 (epoch 13.542), train_loss = 1.38797043, grad/param norm = 2.4584e-01, time/batch = 18.7869s	
3075/11350 (epoch 13.546), train_loss = 1.60798846, grad/param norm = 2.9745e-01, time/batch = 19.0339s	
3076/11350 (epoch 13.551), train_loss = 1.30025716, grad/param norm = 2.4880e-01, time/batch = 20.2834s	
3077/11350 (epoch 13.555), train_loss = 1.21209821, grad/param norm = 2.4532e-01, time/batch = 18.3808s	
3078/11350 (epoch 13.559), train_loss = 1.21916945, grad/param norm = 2.5769e-01, time/batch = 19.0413s	
3079/11350 (epoch 13.564), train_loss = 1.43121598, grad/param norm = 2.7964e-01, time/batch = 19.6333s	
3080/11350 (epoch 13.568), train_loss = 1.34002966, grad/param norm = 2.4583e-01, time/batch = 19.3785s	
3081/11350 (epoch 13.573), train_loss = 1.51542746, grad/param norm = 3.0473e-01, time/batch = 18.8617s	
3082/11350 (epoch 13.577), train_loss = 1.49143999, grad/param norm = 2.9297e-01, time/batch = 18.1861s	
3083/11350 (epoch 13.581), train_loss = 1.39849863, grad/param norm = 2.5872e-01, time/batch = 19.4656s	
3084/11350 (epoch 13.586), train_loss = 1.42764591, grad/param norm = 2.7105e-01, time/batch = 18.2023s	
3085/11350 (epoch 13.590), train_loss = 1.53347920, grad/param norm = 2.9985e-01, time/batch = 18.6172s	
3086/11350 (epoch 13.595), train_loss = 1.52577906, grad/param norm = 2.5625e-01, time/batch = 18.9576s	
3087/11350 (epoch 13.599), train_loss = 1.42318218, grad/param norm = 2.7790e-01, time/batch = 20.2853s	
3088/11350 (epoch 13.604), train_loss = 1.29942379, grad/param norm = 2.5257e-01, time/batch = 33.0147s	
3089/11350 (epoch 13.608), train_loss = 1.38879768, grad/param norm = 2.7625e-01, time/batch = 17.9730s	
3090/11350 (epoch 13.612), train_loss = 1.23418923, grad/param norm = 2.6034e-01, time/batch = 19.4441s	
3091/11350 (epoch 13.617), train_loss = 1.50436218, grad/param norm = 2.9089e-01, time/batch = 19.9690s	
3092/11350 (epoch 13.621), train_loss = 1.45883217, grad/param norm = 2.5930e-01, time/batch = 18.8543s	
3093/11350 (epoch 13.626), train_loss = 1.36250829, grad/param norm = 2.6701e-01, time/batch = 19.2008s	
3094/11350 (epoch 13.630), train_loss = 1.40467066, grad/param norm = 2.5066e-01, time/batch = 19.9436s	
3095/11350 (epoch 13.634), train_loss = 1.41409790, grad/param norm = 2.5421e-01, time/batch = 18.5257s	
3096/11350 (epoch 13.639), train_loss = 1.26488290, grad/param norm = 2.5512e-01, time/batch = 19.1155s	
3097/11350 (epoch 13.643), train_loss = 1.25721828, grad/param norm = 2.5130e-01, time/batch = 18.6179s	
3098/11350 (epoch 13.648), train_loss = 1.32436891, grad/param norm = 2.7849e-01, time/batch = 17.9408s	
3099/11350 (epoch 13.652), train_loss = 1.30793510, grad/param norm = 2.7396e-01, time/batch = 18.1687s	
3100/11350 (epoch 13.656), train_loss = 1.46221586, grad/param norm = 3.1141e-01, time/batch = 19.3431s	
3101/11350 (epoch 13.661), train_loss = 1.51639288, grad/param norm = 2.7080e-01, time/batch = 18.9566s	
3102/11350 (epoch 13.665), train_loss = 1.37646478, grad/param norm = 2.9144e-01, time/batch = 19.4453s	
3103/11350 (epoch 13.670), train_loss = 1.37611824, grad/param norm = 2.9964e-01, time/batch = 18.8593s	
3104/11350 (epoch 13.674), train_loss = 1.26457999, grad/param norm = 2.4677e-01, time/batch = 18.5377s	
3105/11350 (epoch 13.678), train_loss = 1.29990368, grad/param norm = 2.3710e-01, time/batch = 19.3821s	
3106/11350 (epoch 13.683), train_loss = 1.24427193, grad/param norm = 2.4674e-01, time/batch = 17.0374s	
3107/11350 (epoch 13.687), train_loss = 1.21241236, grad/param norm = 2.8133e-01, time/batch = 16.4394s	
3108/11350 (epoch 13.692), train_loss = 1.66555916, grad/param norm = 3.2705e-01, time/batch = 20.7837s	
3109/11350 (epoch 13.696), train_loss = 1.48573700, grad/param norm = 2.9626e-01, time/batch = 18.2808s	
3110/11350 (epoch 13.700), train_loss = 1.40619290, grad/param norm = 2.6854e-01, time/batch = 18.5443s	
3111/11350 (epoch 13.705), train_loss = 1.51125183, grad/param norm = 2.9363e-01, time/batch = 20.4555s	
3112/11350 (epoch 13.709), train_loss = 1.46110172, grad/param norm = 2.5541e-01, time/batch = 18.9466s	
3113/11350 (epoch 13.714), train_loss = 1.26867119, grad/param norm = 2.4708e-01, time/batch = 18.5356s	
3114/11350 (epoch 13.718), train_loss = 1.21557574, grad/param norm = 2.6606e-01, time/batch = 20.4537s	
3115/11350 (epoch 13.722), train_loss = 1.41068955, grad/param norm = 3.2178e-01, time/batch = 18.1191s	
3116/11350 (epoch 13.727), train_loss = 1.34549717, grad/param norm = 2.7538e-01, time/batch = 19.2840s	
3117/11350 (epoch 13.731), train_loss = 1.40121164, grad/param norm = 2.6042e-01, time/batch = 20.0463s	
3118/11350 (epoch 13.736), train_loss = 1.31924785, grad/param norm = 2.8456e-01, time/batch = 17.2005s	
3119/11350 (epoch 13.740), train_loss = 1.32938715, grad/param norm = 3.3073e-01, time/batch = 17.9345s	
3120/11350 (epoch 13.744), train_loss = 1.47243759, grad/param norm = 2.8469e-01, time/batch = 19.7104s	
3121/11350 (epoch 13.749), train_loss = 1.47315623, grad/param norm = 2.9290e-01, time/batch = 20.0223s	
3122/11350 (epoch 13.753), train_loss = 1.43825077, grad/param norm = 3.0786e-01, time/batch = 17.2547s	
3123/11350 (epoch 13.758), train_loss = 1.30302604, grad/param norm = 2.8345e-01, time/batch = 18.3781s	
3124/11350 (epoch 13.762), train_loss = 1.40210768, grad/param norm = 2.7831e-01, time/batch = 20.2014s	
3125/11350 (epoch 13.767), train_loss = 1.41420088, grad/param norm = 2.5872e-01, time/batch = 17.7043s	
3126/11350 (epoch 13.771), train_loss = 1.47890117, grad/param norm = 2.5469e-01, time/batch = 18.7683s	
3127/11350 (epoch 13.775), train_loss = 1.28244515, grad/param norm = 2.7189e-01, time/batch = 19.7931s	
3128/11350 (epoch 13.780), train_loss = 1.42192704, grad/param norm = 2.5698e-01, time/batch = 17.3654s	
3129/11350 (epoch 13.784), train_loss = 1.25428985, grad/param norm = 2.4363e-01, time/batch = 18.5927s	
3130/11350 (epoch 13.789), train_loss = 1.33669020, grad/param norm = 2.8732e-01, time/batch = 17.2106s	
3131/11350 (epoch 13.793), train_loss = 1.41246071, grad/param norm = 2.6739e-01, time/batch = 18.2714s	
3132/11350 (epoch 13.797), train_loss = 1.29232212, grad/param norm = 2.5719e-01, time/batch = 18.8789s	
3133/11350 (epoch 13.802), train_loss = 1.37509914, grad/param norm = 2.6569e-01, time/batch = 19.3767s	
3134/11350 (epoch 13.806), train_loss = 1.38252132, grad/param norm = 2.6000e-01, time/batch = 19.9485s	
3135/11350 (epoch 13.811), train_loss = 1.30442552, grad/param norm = 3.1692e-01, time/batch = 19.7796s	
3136/11350 (epoch 13.815), train_loss = 1.19861710, grad/param norm = 2.5170e-01, time/batch = 19.3736s	
3137/11350 (epoch 13.819), train_loss = 1.23831579, grad/param norm = 2.6985e-01, time/batch = 19.5494s	
3138/11350 (epoch 13.824), train_loss = 1.29758098, grad/param norm = 2.6695e-01, time/batch = 20.1062s	
3139/11350 (epoch 13.828), train_loss = 1.33185369, grad/param norm = 2.6714e-01, time/batch = 19.7062s	
3140/11350 (epoch 13.833), train_loss = 1.35657236, grad/param norm = 2.8290e-01, time/batch = 19.4582s	
3141/11350 (epoch 13.837), train_loss = 1.33176247, grad/param norm = 2.6300e-01, time/batch = 19.8515s	
3142/11350 (epoch 13.841), train_loss = 1.62979089, grad/param norm = 2.8979e-01, time/batch = 19.7973s	
3143/11350 (epoch 13.846), train_loss = 1.32436855, grad/param norm = 2.7645e-01, time/batch = 17.1932s	
3144/11350 (epoch 13.850), train_loss = 1.44885310, grad/param norm = 2.9633e-01, time/batch = 17.0415s	
3145/11350 (epoch 13.855), train_loss = 1.17251705, grad/param norm = 2.4645e-01, time/batch = 20.0392s	
3146/11350 (epoch 13.859), train_loss = 1.34937231, grad/param norm = 2.8614e-01, time/batch = 20.4563s	
3147/11350 (epoch 13.863), train_loss = 1.20664103, grad/param norm = 2.5838e-01, time/batch = 17.1095s	
3148/11350 (epoch 13.868), train_loss = 1.32153908, grad/param norm = 2.5125e-01, time/batch = 19.3087s	
3149/11350 (epoch 13.872), train_loss = 1.30895361, grad/param norm = 2.7944e-01, time/batch = 16.9588s	
3150/11350 (epoch 13.877), train_loss = 1.31814651, grad/param norm = 2.5431e-01, time/batch = 16.4427s	
3151/11350 (epoch 13.881), train_loss = 1.58797351, grad/param norm = 2.9975e-01, time/batch = 18.1212s	
3152/11350 (epoch 13.885), train_loss = 1.55112409, grad/param norm = 2.7470e-01, time/batch = 16.4563s	
3153/11350 (epoch 13.890), train_loss = 1.41807842, grad/param norm = 2.6072e-01, time/batch = 20.0255s	
3154/11350 (epoch 13.894), train_loss = 1.16718365, grad/param norm = 2.5182e-01, time/batch = 19.6843s	
3155/11350 (epoch 13.899), train_loss = 1.43598312, grad/param norm = 2.6485e-01, time/batch = 17.1995s	
3156/11350 (epoch 13.903), train_loss = 1.47223295, grad/param norm = 2.7672e-01, time/batch = 18.6344s	
3157/11350 (epoch 13.907), train_loss = 1.41695195, grad/param norm = 2.6965e-01, time/batch = 19.1166s	
3158/11350 (epoch 13.912), train_loss = 1.31042714, grad/param norm = 2.6795e-01, time/batch = 20.1947s	
3159/11350 (epoch 13.916), train_loss = 1.45364562, grad/param norm = 2.5836e-01, time/batch = 16.5568s	
3160/11350 (epoch 13.921), train_loss = 1.40715056, grad/param norm = 2.5928e-01, time/batch = 19.0251s	
3161/11350 (epoch 13.925), train_loss = 1.19864461, grad/param norm = 2.3649e-01, time/batch = 18.9699s	
3162/11350 (epoch 13.930), train_loss = 1.45832362, grad/param norm = 2.7809e-01, time/batch = 20.4528s	
3163/11350 (epoch 13.934), train_loss = 1.51676326, grad/param norm = 2.5967e-01, time/batch = 17.4570s	
3164/11350 (epoch 13.938), train_loss = 1.29917555, grad/param norm = 2.7111e-01, time/batch = 18.2876s	
3165/11350 (epoch 13.943), train_loss = 1.47115633, grad/param norm = 2.8999e-01, time/batch = 19.2186s	
3166/11350 (epoch 13.947), train_loss = 1.47030467, grad/param norm = 3.0049e-01, time/batch = 18.9529s	
3167/11350 (epoch 13.952), train_loss = 1.44383146, grad/param norm = 3.0683e-01, time/batch = 19.0294s	
3168/11350 (epoch 13.956), train_loss = 1.14160617, grad/param norm = 2.5297e-01, time/batch = 17.5251s	
3169/11350 (epoch 13.960), train_loss = 1.35529481, grad/param norm = 2.8942e-01, time/batch = 18.9516s	
3170/11350 (epoch 13.965), train_loss = 1.25345601, grad/param norm = 2.7731e-01, time/batch = 18.2636s	
3171/11350 (epoch 13.969), train_loss = 1.27151200, grad/param norm = 3.0168e-01, time/batch = 20.1249s	
3172/11350 (epoch 13.974), train_loss = 1.16839939, grad/param norm = 2.7115e-01, time/batch = 20.1994s	
3173/11350 (epoch 13.978), train_loss = 1.35299005, grad/param norm = 2.7440e-01, time/batch = 19.4360s	
3174/11350 (epoch 13.982), train_loss = 1.08435147, grad/param norm = 2.5760e-01, time/batch = 20.1265s	
3175/11350 (epoch 13.987), train_loss = 1.31632769, grad/param norm = 2.7622e-01, time/batch = 19.6240s	
3176/11350 (epoch 13.991), train_loss = 1.19899158, grad/param norm = 2.9974e-01, time/batch = 18.6876s	
3177/11350 (epoch 13.996), train_loss = 1.39749481, grad/param norm = 3.4404e-01, time/batch = 18.3679s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
3178/11350 (epoch 14.000), train_loss = 1.07098654, grad/param norm = 2.7306e-01, time/batch = 19.9576s	
3179/11350 (epoch 14.004), train_loss = 1.32790486, grad/param norm = 2.8812e-01, time/batch = 17.4125s	
3180/11350 (epoch 14.009), train_loss = 1.36423696, grad/param norm = 2.6649e-01, time/batch = 18.1915s	
3181/11350 (epoch 14.013), train_loss = 0.90819898, grad/param norm = 2.1897e-01, time/batch = 20.0439s	
3182/11350 (epoch 14.018), train_loss = 0.98686833, grad/param norm = 2.4889e-01, time/batch = 17.2923s	
3183/11350 (epoch 14.022), train_loss = 1.03336986, grad/param norm = 2.6364e-01, time/batch = 17.3618s	
3184/11350 (epoch 14.026), train_loss = 1.10121587, grad/param norm = 2.6510e-01, time/batch = 18.7190s	
3185/11350 (epoch 14.031), train_loss = 1.05375859, grad/param norm = 2.5596e-01, time/batch = 17.7795s	
3186/11350 (epoch 14.035), train_loss = 1.13524402, grad/param norm = 2.6371e-01, time/batch = 19.1248s	
3187/11350 (epoch 14.040), train_loss = 1.16081291, grad/param norm = 2.7450e-01, time/batch = 19.1258s	
3188/11350 (epoch 14.044), train_loss = 1.09684140, grad/param norm = 2.4675e-01, time/batch = 18.5535s	
3189/11350 (epoch 14.048), train_loss = 1.07873607, grad/param norm = 2.5398e-01, time/batch = 18.4487s	
3190/11350 (epoch 14.053), train_loss = 1.17260219, grad/param norm = 2.3783e-01, time/batch = 16.8503s	
3191/11350 (epoch 14.057), train_loss = 1.25872029, grad/param norm = 2.7057e-01, time/batch = 19.3084s	
3192/11350 (epoch 14.062), train_loss = 1.01329592, grad/param norm = 2.2958e-01, time/batch = 18.2874s	
3193/11350 (epoch 14.066), train_loss = 1.00932343, grad/param norm = 2.3799e-01, time/batch = 18.7243s	
3194/11350 (epoch 14.070), train_loss = 1.13748516, grad/param norm = 2.5193e-01, time/batch = 18.3881s	
3195/11350 (epoch 14.075), train_loss = 1.00792644, grad/param norm = 2.5312e-01, time/batch = 17.6056s	
3196/11350 (epoch 14.079), train_loss = 1.15687389, grad/param norm = 2.6095e-01, time/batch = 19.8577s	
3197/11350 (epoch 14.084), train_loss = 1.39465979, grad/param norm = 2.9506e-01, time/batch = 20.2823s	
3198/11350 (epoch 14.088), train_loss = 1.34116142, grad/param norm = 3.2305e-01, time/batch = 17.7658s	
3199/11350 (epoch 14.093), train_loss = 1.26514958, grad/param norm = 2.5656e-01, time/batch = 19.6868s	
3200/11350 (epoch 14.097), train_loss = 1.20072620, grad/param norm = 2.6532e-01, time/batch = 18.9685s	
3201/11350 (epoch 14.101), train_loss = 1.06727119, grad/param norm = 2.5365e-01, time/batch = 19.1162s	
3202/11350 (epoch 14.106), train_loss = 1.31077295, grad/param norm = 2.5297e-01, time/batch = 20.2037s	
3203/11350 (epoch 14.110), train_loss = 1.14657731, grad/param norm = 2.6824e-01, time/batch = 16.2625s	
3204/11350 (epoch 14.115), train_loss = 1.13607098, grad/param norm = 2.6293e-01, time/batch = 19.7902s	
3205/11350 (epoch 14.119), train_loss = 1.32979087, grad/param norm = 2.9849e-01, time/batch = 20.1993s	
3206/11350 (epoch 14.123), train_loss = 1.09083912, grad/param norm = 2.4303e-01, time/batch = 17.5532s	
3207/11350 (epoch 14.128), train_loss = 1.11388536, grad/param norm = 2.5681e-01, time/batch = 20.1161s	
3208/11350 (epoch 14.132), train_loss = 1.15795315, grad/param norm = 2.4375e-01, time/batch = 18.7796s	
3209/11350 (epoch 14.137), train_loss = 1.11346554, grad/param norm = 2.8417e-01, time/batch = 18.6299s	
3210/11350 (epoch 14.141), train_loss = 1.31174911, grad/param norm = 2.5800e-01, time/batch = 20.4645s	
3211/11350 (epoch 14.145), train_loss = 1.10426505, grad/param norm = 2.3793e-01, time/batch = 19.5214s	
3212/11350 (epoch 14.150), train_loss = 1.29034447, grad/param norm = 3.3083e-01, time/batch = 19.6933s	
3213/11350 (epoch 14.154), train_loss = 1.38298294, grad/param norm = 2.8495e-01, time/batch = 20.0390s	
3214/11350 (epoch 14.159), train_loss = 1.05146265, grad/param norm = 2.7093e-01, time/batch = 17.3306s	
3215/11350 (epoch 14.163), train_loss = 1.29713403, grad/param norm = 2.6918e-01, time/batch = 18.8660s	
3216/11350 (epoch 14.167), train_loss = 1.33455004, grad/param norm = 2.7527e-01, time/batch = 18.9598s	
3217/11350 (epoch 14.172), train_loss = 1.46050625, grad/param norm = 2.8653e-01, time/batch = 17.6952s	
3218/11350 (epoch 14.176), train_loss = 1.27382840, grad/param norm = 2.6631e-01, time/batch = 18.5509s	
3219/11350 (epoch 14.181), train_loss = 1.24779443, grad/param norm = 2.7819e-01, time/batch = 19.8834s	
3220/11350 (epoch 14.185), train_loss = 1.10606165, grad/param norm = 2.7918e-01, time/batch = 18.9443s	
3221/11350 (epoch 14.189), train_loss = 1.16412646, grad/param norm = 2.5159e-01, time/batch = 19.6208s	
3222/11350 (epoch 14.194), train_loss = 1.11294108, grad/param norm = 2.6855e-01, time/batch = 17.4309s	
3223/11350 (epoch 14.198), train_loss = 1.11664108, grad/param norm = 2.9166e-01, time/batch = 18.4384s	
3224/11350 (epoch 14.203), train_loss = 1.04675005, grad/param norm = 2.4217e-01, time/batch = 20.1287s	
3225/11350 (epoch 14.207), train_loss = 1.07194303, grad/param norm = 2.7269e-01, time/batch = 19.4641s	
3226/11350 (epoch 14.211), train_loss = 1.25725707, grad/param norm = 2.6320e-01, time/batch = 18.9423s	
3227/11350 (epoch 14.216), train_loss = 1.22859629, grad/param norm = 2.7945e-01, time/batch = 19.2019s	
3228/11350 (epoch 14.220), train_loss = 1.20286640, grad/param norm = 2.5755e-01, time/batch = 18.6195s	
3229/11350 (epoch 14.225), train_loss = 1.08272590, grad/param norm = 2.3796e-01, time/batch = 19.1408s	
3230/11350 (epoch 14.229), train_loss = 1.28195950, grad/param norm = 2.6171e-01, time/batch = 17.9351s	
3231/11350 (epoch 14.233), train_loss = 1.22141887, grad/param norm = 2.6321e-01, time/batch = 19.2233s	
3232/11350 (epoch 14.238), train_loss = 1.39037420, grad/param norm = 3.0281e-01, time/batch = 18.6304s	
3233/11350 (epoch 14.242), train_loss = 1.39372284, grad/param norm = 3.3364e-01, time/batch = 17.8808s	
3234/11350 (epoch 14.247), train_loss = 1.01029686, grad/param norm = 2.1904e-01, time/batch = 16.6277s	
3235/11350 (epoch 14.251), train_loss = 1.25994832, grad/param norm = 2.7946e-01, time/batch = 19.4480s	
3236/11350 (epoch 14.256), train_loss = 1.28598011, grad/param norm = 2.7128e-01, time/batch = 19.1197s	
3237/11350 (epoch 14.260), train_loss = 1.12784711, grad/param norm = 2.9090e-01, time/batch = 18.7167s	
3238/11350 (epoch 14.264), train_loss = 1.16652627, grad/param norm = 2.5043e-01, time/batch = 18.3822s	
3239/11350 (epoch 14.269), train_loss = 1.22661272, grad/param norm = 2.8036e-01, time/batch = 18.1997s	
3240/11350 (epoch 14.273), train_loss = 1.31993443, grad/param norm = 3.0541e-01, time/batch = 19.2101s	
3241/11350 (epoch 14.278), train_loss = 1.07551680, grad/param norm = 2.4112e-01, time/batch = 19.1169s	
3242/11350 (epoch 14.282), train_loss = 1.28798538, grad/param norm = 2.8480e-01, time/batch = 18.1121s	
3243/11350 (epoch 14.286), train_loss = 1.33925397, grad/param norm = 2.7500e-01, time/batch = 18.3503s	
3244/11350 (epoch 14.291), train_loss = 1.06815107, grad/param norm = 3.1874e-01, time/batch = 15.7195s	
3245/11350 (epoch 14.295), train_loss = 1.20710867, grad/param norm = 2.4944e-01, time/batch = 18.3964s	
3246/11350 (epoch 14.300), train_loss = 1.19158813, grad/param norm = 2.2914e-01, time/batch = 16.2687s	
3247/11350 (epoch 14.304), train_loss = 1.12757976, grad/param norm = 2.4115e-01, time/batch = 18.5484s	
3248/11350 (epoch 14.308), train_loss = 1.15131599, grad/param norm = 2.5925e-01, time/batch = 18.2179s	
3249/11350 (epoch 14.313), train_loss = 1.27834919, grad/param norm = 2.4830e-01, time/batch = 18.2941s	
3250/11350 (epoch 14.317), train_loss = 1.08929255, grad/param norm = 2.4386e-01, time/batch = 18.7795s	
3251/11350 (epoch 14.322), train_loss = 1.13760462, grad/param norm = 2.6085e-01, time/batch = 19.6336s	
3252/11350 (epoch 14.326), train_loss = 1.20440632, grad/param norm = 2.3903e-01, time/batch = 18.4548s	
3253/11350 (epoch 14.330), train_loss = 1.00765603, grad/param norm = 2.6045e-01, time/batch = 18.2235s	
3254/11350 (epoch 14.335), train_loss = 0.91028848, grad/param norm = 2.2521e-01, time/batch = 19.7830s	
3255/11350 (epoch 14.339), train_loss = 1.04863083, grad/param norm = 2.7002e-01, time/batch = 18.3748s	
3256/11350 (epoch 14.344), train_loss = 1.11721676, grad/param norm = 2.3816e-01, time/batch = 18.2129s	
3257/11350 (epoch 14.348), train_loss = 1.13773904, grad/param norm = 2.3322e-01, time/batch = 20.0355s	
3258/11350 (epoch 14.352), train_loss = 1.01978229, grad/param norm = 2.3272e-01, time/batch = 19.5415s	
3259/11350 (epoch 14.357), train_loss = 1.10147354, grad/param norm = 2.3582e-01, time/batch = 18.0367s	
3260/11350 (epoch 14.361), train_loss = 0.92763848, grad/param norm = 2.2377e-01, time/batch = 16.3675s	
3261/11350 (epoch 14.366), train_loss = 1.27004900, grad/param norm = 2.6939e-01, time/batch = 20.7083s	
3262/11350 (epoch 14.370), train_loss = 1.12542266, grad/param norm = 2.6842e-01, time/batch = 14.3840s	
3263/11350 (epoch 14.374), train_loss = 1.14230249, grad/param norm = 2.8371e-01, time/batch = 0.7221s	
3264/11350 (epoch 14.379), train_loss = 1.18115157, grad/param norm = 2.4842e-01, time/batch = 0.7041s	
3265/11350 (epoch 14.383), train_loss = 0.99024610, grad/param norm = 2.3464e-01, time/batch = 0.7063s	
3266/11350 (epoch 14.388), train_loss = 1.21769953, grad/param norm = 2.9465e-01, time/batch = 0.7243s	
3267/11350 (epoch 14.392), train_loss = 1.16013604, grad/param norm = 2.9503e-01, time/batch = 0.6929s	
3268/11350 (epoch 14.396), train_loss = 1.23844744, grad/param norm = 2.7128e-01, time/batch = 0.6874s	
3269/11350 (epoch 14.401), train_loss = 1.16988164, grad/param norm = 2.5453e-01, time/batch = 0.7122s	
3270/11350 (epoch 14.405), train_loss = 1.32474528, grad/param norm = 2.5705e-01, time/batch = 0.9995s	
3271/11350 (epoch 14.410), train_loss = 1.39390720, grad/param norm = 2.7663e-01, time/batch = 1.0086s	
3272/11350 (epoch 14.414), train_loss = 1.03414875, grad/param norm = 2.6141e-01, time/batch = 0.9987s	
3273/11350 (epoch 14.419), train_loss = 1.13900191, grad/param norm = 2.6114e-01, time/batch = 0.9973s	
3274/11350 (epoch 14.423), train_loss = 1.28953727, grad/param norm = 2.5864e-01, time/batch = 1.2037s	
3275/11350 (epoch 14.427), train_loss = 1.34242838, grad/param norm = 3.0544e-01, time/batch = 1.8931s	
3276/11350 (epoch 14.432), train_loss = 1.32712598, grad/param norm = 2.8699e-01, time/batch = 1.8691s	
3277/11350 (epoch 14.436), train_loss = 1.19592562, grad/param norm = 2.8752e-01, time/batch = 9.2103s	
3278/11350 (epoch 14.441), train_loss = 1.46888680, grad/param norm = 3.4499e-01, time/batch = 17.7247s	
3279/11350 (epoch 14.445), train_loss = 0.98245154, grad/param norm = 2.2369e-01, time/batch = 17.8736s	
3280/11350 (epoch 14.449), train_loss = 1.14394563, grad/param norm = 2.8158e-01, time/batch = 15.8639s	
3281/11350 (epoch 14.454), train_loss = 1.35556803, grad/param norm = 2.7676e-01, time/batch = 19.0376s	
3282/11350 (epoch 14.458), train_loss = 0.97861426, grad/param norm = 2.3489e-01, time/batch = 19.1294s	
3283/11350 (epoch 14.463), train_loss = 1.06055545, grad/param norm = 2.5633e-01, time/batch = 16.8870s	
3284/11350 (epoch 14.467), train_loss = 1.49848225, grad/param norm = 3.1262e-01, time/batch = 17.7138s	
3285/11350 (epoch 14.471), train_loss = 1.34536499, grad/param norm = 3.0891e-01, time/batch = 19.7976s	
3286/11350 (epoch 14.476), train_loss = 1.30107607, grad/param norm = 2.8177e-01, time/batch = 17.9560s	
3287/11350 (epoch 14.480), train_loss = 1.40078009, grad/param norm = 2.7094e-01, time/batch = 19.3868s	
3288/11350 (epoch 14.485), train_loss = 1.18291875, grad/param norm = 2.4160e-01, time/batch = 18.8563s	
3289/11350 (epoch 14.489), train_loss = 1.33595100, grad/param norm = 2.7659e-01, time/batch = 16.7898s	
3290/11350 (epoch 14.493), train_loss = 1.31379361, grad/param norm = 2.9423e-01, time/batch = 18.7194s	
3291/11350 (epoch 14.498), train_loss = 0.97902506, grad/param norm = 2.4845e-01, time/batch = 19.3864s	
3292/11350 (epoch 14.502), train_loss = 1.27508314, grad/param norm = 2.7205e-01, time/batch = 24.6194s	
3293/11350 (epoch 14.507), train_loss = 1.05148778, grad/param norm = 2.4856e-01, time/batch = 26.2249s	
3294/11350 (epoch 14.511), train_loss = 1.43266007, grad/param norm = 2.6432e-01, time/batch = 17.7842s	
3295/11350 (epoch 14.515), train_loss = 1.18803819, grad/param norm = 2.3691e-01, time/batch = 17.3644s	
3296/11350 (epoch 14.520), train_loss = 1.40220084, grad/param norm = 3.0836e-01, time/batch = 17.9666s	
3297/11350 (epoch 14.524), train_loss = 1.20782913, grad/param norm = 2.6195e-01, time/batch = 19.6300s	
3298/11350 (epoch 14.529), train_loss = 1.21529211, grad/param norm = 2.4182e-01, time/batch = 17.1959s	
3299/11350 (epoch 14.533), train_loss = 1.48474528, grad/param norm = 2.6535e-01, time/batch = 19.5143s	
3300/11350 (epoch 14.537), train_loss = 1.29373839, grad/param norm = 2.7002e-01, time/batch = 18.2756s	
3301/11350 (epoch 14.542), train_loss = 1.31545069, grad/param norm = 2.2552e-01, time/batch = 19.1174s	
3302/11350 (epoch 14.546), train_loss = 1.55194252, grad/param norm = 2.9718e-01, time/batch = 19.6254s	
3303/11350 (epoch 14.551), train_loss = 1.24895981, grad/param norm = 2.3967e-01, time/batch = 18.8053s	
3304/11350 (epoch 14.555), train_loss = 1.17237721, grad/param norm = 2.7473e-01, time/batch = 18.6851s	
3305/11350 (epoch 14.559), train_loss = 1.18216436, grad/param norm = 2.7746e-01, time/batch = 19.9259s	
3306/11350 (epoch 14.564), train_loss = 1.36456648, grad/param norm = 2.7651e-01, time/batch = 19.5448s	
3307/11350 (epoch 14.568), train_loss = 1.29151533, grad/param norm = 2.4943e-01, time/batch = 19.8481s	
3308/11350 (epoch 14.573), train_loss = 1.46372946, grad/param norm = 3.3164e-01, time/batch = 19.6868s	
3309/11350 (epoch 14.577), train_loss = 1.42891879, grad/param norm = 3.1500e-01, time/batch = 18.2867s	
3310/11350 (epoch 14.581), train_loss = 1.35534166, grad/param norm = 2.6485e-01, time/batch = 19.2081s	
3311/11350 (epoch 14.586), train_loss = 1.38117657, grad/param norm = 2.9338e-01, time/batch = 17.7115s	
3312/11350 (epoch 14.590), train_loss = 1.49482264, grad/param norm = 3.0911e-01, time/batch = 20.3619s	
3313/11350 (epoch 14.595), train_loss = 1.47922831, grad/param norm = 2.7571e-01, time/batch = 18.7882s	
3314/11350 (epoch 14.599), train_loss = 1.37525123, grad/param norm = 2.9076e-01, time/batch = 19.1112s	
3315/11350 (epoch 14.604), train_loss = 1.24574693, grad/param norm = 2.3526e-01, time/batch = 18.3785s	
3316/11350 (epoch 14.608), train_loss = 1.32819378, grad/param norm = 2.8335e-01, time/batch = 19.8084s	
3317/11350 (epoch 14.612), train_loss = 1.19240045, grad/param norm = 2.5064e-01, time/batch = 17.6927s	
3318/11350 (epoch 14.617), train_loss = 1.44376038, grad/param norm = 2.8558e-01, time/batch = 19.3820s	
3319/11350 (epoch 14.621), train_loss = 1.40796389, grad/param norm = 2.5290e-01, time/batch = 20.0422s	
3320/11350 (epoch 14.626), train_loss = 1.30636705, grad/param norm = 2.6770e-01, time/batch = 16.5264s	
3321/11350 (epoch 14.630), train_loss = 1.35812730, grad/param norm = 2.5400e-01, time/batch = 19.6057s	
3322/11350 (epoch 14.634), train_loss = 1.35564274, grad/param norm = 2.6081e-01, time/batch = 17.3500s	
3323/11350 (epoch 14.639), train_loss = 1.20014581, grad/param norm = 2.4637e-01, time/batch = 18.4397s	
3324/11350 (epoch 14.643), train_loss = 1.19966993, grad/param norm = 2.5717e-01, time/batch = 16.9344s	
3325/11350 (epoch 14.648), train_loss = 1.27083304, grad/param norm = 2.7324e-01, time/batch = 18.8636s	
3326/11350 (epoch 14.652), train_loss = 1.24732332, grad/param norm = 2.6999e-01, time/batch = 19.2127s	
3327/11350 (epoch 14.656), train_loss = 1.39303271, grad/param norm = 3.1645e-01, time/batch = 18.3715s	
3328/11350 (epoch 14.661), train_loss = 1.46653517, grad/param norm = 2.8096e-01, time/batch = 18.9641s	
3329/11350 (epoch 14.665), train_loss = 1.31998850, grad/param norm = 2.7333e-01, time/batch = 17.3664s	
3330/11350 (epoch 14.670), train_loss = 1.30284098, grad/param norm = 2.9672e-01, time/batch = 18.4492s	
3331/11350 (epoch 14.674), train_loss = 1.21568220, grad/param norm = 2.4939e-01, time/batch = 18.1431s	
3332/11350 (epoch 14.678), train_loss = 1.24221314, grad/param norm = 2.3298e-01, time/batch = 19.4671s	
3333/11350 (epoch 14.683), train_loss = 1.18799899, grad/param norm = 2.5450e-01, time/batch = 18.6072s	
3334/11350 (epoch 14.687), train_loss = 1.16920930, grad/param norm = 2.9338e-01, time/batch = 18.2890s	
3335/11350 (epoch 14.692), train_loss = 1.60777342, grad/param norm = 3.0709e-01, time/batch = 18.3805s	
3336/11350 (epoch 14.696), train_loss = 1.43819411, grad/param norm = 2.9414e-01, time/batch = 18.2609s	
3337/11350 (epoch 14.700), train_loss = 1.36489445, grad/param norm = 2.7030e-01, time/batch = 20.1298s	
3338/11350 (epoch 14.705), train_loss = 1.45913606, grad/param norm = 2.9469e-01, time/batch = 18.9506s	
3339/11350 (epoch 14.709), train_loss = 1.41091182, grad/param norm = 2.8671e-01, time/batch = 17.2751s	
3340/11350 (epoch 14.714), train_loss = 1.23809866, grad/param norm = 2.5355e-01, time/batch = 17.8685s	
3341/11350 (epoch 14.718), train_loss = 1.16540052, grad/param norm = 2.6917e-01, time/batch = 18.6848s	
3342/11350 (epoch 14.722), train_loss = 1.36060783, grad/param norm = 3.3401e-01, time/batch = 19.9649s	
3343/11350 (epoch 14.727), train_loss = 1.30060344, grad/param norm = 2.9083e-01, time/batch = 19.8543s	
3344/11350 (epoch 14.731), train_loss = 1.36899910, grad/param norm = 2.9096e-01, time/batch = 20.0495s	
3345/11350 (epoch 14.736), train_loss = 1.26723477, grad/param norm = 2.8745e-01, time/batch = 20.0412s	
3346/11350 (epoch 14.740), train_loss = 1.28329833, grad/param norm = 3.0675e-01, time/batch = 17.9551s	
3347/11350 (epoch 14.744), train_loss = 1.40859920, grad/param norm = 2.8593e-01, time/batch = 20.1230s	
3348/11350 (epoch 14.749), train_loss = 1.43157249, grad/param norm = 3.0455e-01, time/batch = 20.2063s	
3349/11350 (epoch 14.753), train_loss = 1.38335083, grad/param norm = 2.9543e-01, time/batch = 18.3554s	
3350/11350 (epoch 14.758), train_loss = 1.25053574, grad/param norm = 2.8716e-01, time/batch = 17.9532s	
3351/11350 (epoch 14.762), train_loss = 1.34291209, grad/param norm = 2.7577e-01, time/batch = 18.4462s	
3352/11350 (epoch 14.767), train_loss = 1.36223792, grad/param norm = 2.6184e-01, time/batch = 16.2679s	
3353/11350 (epoch 14.771), train_loss = 1.44178515, grad/param norm = 2.6358e-01, time/batch = 19.7220s	
3354/11350 (epoch 14.775), train_loss = 1.22684603, grad/param norm = 2.6845e-01, time/batch = 18.2317s	
3355/11350 (epoch 14.780), train_loss = 1.37448275, grad/param norm = 2.6994e-01, time/batch = 17.6174s	
3356/11350 (epoch 14.784), train_loss = 1.20503118, grad/param norm = 2.4048e-01, time/batch = 18.6831s	
3357/11350 (epoch 14.789), train_loss = 1.28905124, grad/param norm = 2.9286e-01, time/batch = 19.4539s	
3358/11350 (epoch 14.793), train_loss = 1.36681223, grad/param norm = 2.6487e-01, time/batch = 19.2706s	
3359/11350 (epoch 14.797), train_loss = 1.25016423, grad/param norm = 2.6693e-01, time/batch = 20.5877s	
3360/11350 (epoch 14.802), train_loss = 1.33350577, grad/param norm = 2.6652e-01, time/batch = 19.0462s	
3361/11350 (epoch 14.806), train_loss = 1.34428408, grad/param norm = 2.6907e-01, time/batch = 18.7811s	
3362/11350 (epoch 14.811), train_loss = 1.26439714, grad/param norm = 2.8866e-01, time/batch = 19.2894s	
3363/11350 (epoch 14.815), train_loss = 1.16453721, grad/param norm = 2.5251e-01, time/batch = 19.0459s	
3364/11350 (epoch 14.819), train_loss = 1.18902875, grad/param norm = 2.6171e-01, time/batch = 19.4543s	
3365/11350 (epoch 14.824), train_loss = 1.24370901, grad/param norm = 2.7881e-01, time/batch = 19.1053s	
3366/11350 (epoch 14.828), train_loss = 1.28216421, grad/param norm = 2.7978e-01, time/batch = 20.3765s	
3367/11350 (epoch 14.833), train_loss = 1.30703873, grad/param norm = 3.1302e-01, time/batch = 16.5274s	
3368/11350 (epoch 14.837), train_loss = 1.28543034, grad/param norm = 2.6912e-01, time/batch = 17.6757s	
3369/11350 (epoch 14.841), train_loss = 1.57754572, grad/param norm = 3.0123e-01, time/batch = 19.8670s	
3370/11350 (epoch 14.846), train_loss = 1.27156159, grad/param norm = 2.6623e-01, time/batch = 19.9449s	
3371/11350 (epoch 14.850), train_loss = 1.39983608, grad/param norm = 2.9194e-01, time/batch = 18.1055s	
3372/11350 (epoch 14.855), train_loss = 1.13863339, grad/param norm = 2.5754e-01, time/batch = 19.3777s	
3373/11350 (epoch 14.859), train_loss = 1.31366135, grad/param norm = 3.2369e-01, time/batch = 18.6165s	
3374/11350 (epoch 14.863), train_loss = 1.17196117, grad/param norm = 2.6683e-01, time/batch = 18.6746s	
3375/11350 (epoch 14.868), train_loss = 1.27038559, grad/param norm = 2.6041e-01, time/batch = 19.1194s	
3376/11350 (epoch 14.872), train_loss = 1.25875836, grad/param norm = 2.7821e-01, time/batch = 20.1004s	
3377/11350 (epoch 14.877), train_loss = 1.27633492, grad/param norm = 2.5817e-01, time/batch = 18.0265s	
3378/11350 (epoch 14.881), train_loss = 1.53359269, grad/param norm = 3.1422e-01, time/batch = 18.2808s	
3379/11350 (epoch 14.885), train_loss = 1.49539934, grad/param norm = 2.7286e-01, time/batch = 19.7134s	
3380/11350 (epoch 14.890), train_loss = 1.37743429, grad/param norm = 2.6670e-01, time/batch = 18.7791s	
3381/11350 (epoch 14.894), train_loss = 1.12084864, grad/param norm = 2.6000e-01, time/batch = 15.7365s	
3382/11350 (epoch 14.899), train_loss = 1.39393481, grad/param norm = 2.6429e-01, time/batch = 18.7817s	
3383/11350 (epoch 14.903), train_loss = 1.40980672, grad/param norm = 2.7603e-01, time/batch = 20.0278s	
3384/11350 (epoch 14.907), train_loss = 1.35073968, grad/param norm = 2.4732e-01, time/batch = 19.5083s	
3385/11350 (epoch 14.912), train_loss = 1.25802357, grad/param norm = 2.7020e-01, time/batch = 17.8887s	
3386/11350 (epoch 14.916), train_loss = 1.40588514, grad/param norm = 2.8828e-01, time/batch = 20.1246s	
3387/11350 (epoch 14.921), train_loss = 1.35258328, grad/param norm = 2.6020e-01, time/batch = 16.9402s	
3388/11350 (epoch 14.925), train_loss = 1.15590728, grad/param norm = 2.4612e-01, time/batch = 19.7934s	
3389/11350 (epoch 14.930), train_loss = 1.40648802, grad/param norm = 2.7607e-01, time/batch = 19.2846s	
3390/11350 (epoch 14.934), train_loss = 1.47020263, grad/param norm = 2.7077e-01, time/batch = 18.4581s	
3391/11350 (epoch 14.938), train_loss = 1.25236733, grad/param norm = 2.5133e-01, time/batch = 18.7145s	
3392/11350 (epoch 14.943), train_loss = 1.42354916, grad/param norm = 2.7599e-01, time/batch = 19.9414s	
3393/11350 (epoch 14.947), train_loss = 1.42311623, grad/param norm = 3.2560e-01, time/batch = 18.6928s	
3394/11350 (epoch 14.952), train_loss = 1.38710331, grad/param norm = 3.0672e-01, time/batch = 16.3053s	
3395/11350 (epoch 14.956), train_loss = 1.11759209, grad/param norm = 3.0776e-01, time/batch = 19.9407s	
3396/11350 (epoch 14.960), train_loss = 1.29381438, grad/param norm = 2.8803e-01, time/batch = 18.4503s	
3397/11350 (epoch 14.965), train_loss = 1.20982284, grad/param norm = 2.7902e-01, time/batch = 19.9393s	
3398/11350 (epoch 14.969), train_loss = 1.21585325, grad/param norm = 3.0308e-01, time/batch = 17.5368s	
3399/11350 (epoch 14.974), train_loss = 1.12121940, grad/param norm = 2.5638e-01, time/batch = 18.2456s	
3400/11350 (epoch 14.978), train_loss = 1.29668325, grad/param norm = 2.6494e-01, time/batch = 18.7536s	
3401/11350 (epoch 14.982), train_loss = 1.03275692, grad/param norm = 2.4498e-01, time/batch = 19.4523s	
3402/11350 (epoch 14.987), train_loss = 1.27886139, grad/param norm = 2.7080e-01, time/batch = 19.6289s	
3403/11350 (epoch 14.991), train_loss = 1.14429820, grad/param norm = 2.7851e-01, time/batch = 17.4288s	
3404/11350 (epoch 14.996), train_loss = 1.33407596, grad/param norm = 3.3347e-01, time/batch = 20.1065s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
3405/11350 (epoch 15.000), train_loss = 1.01009510, grad/param norm = 2.5793e-01, time/batch = 20.1353s	
3406/11350 (epoch 15.004), train_loss = 1.28384495, grad/param norm = 3.0357e-01, time/batch = 17.5251s	
3407/11350 (epoch 15.009), train_loss = 1.31815990, grad/param norm = 2.7675e-01, time/batch = 19.5300s	
3408/11350 (epoch 15.013), train_loss = 0.87308137, grad/param norm = 2.1832e-01, time/batch = 15.8781s	
3409/11350 (epoch 15.018), train_loss = 0.95427421, grad/param norm = 2.4343e-01, time/batch = 18.7154s	
3410/11350 (epoch 15.022), train_loss = 0.98686860, grad/param norm = 2.3934e-01, time/batch = 19.7822s	
3411/11350 (epoch 15.026), train_loss = 1.05641658, grad/param norm = 2.6524e-01, time/batch = 20.0385s	
3412/11350 (epoch 15.031), train_loss = 1.02602360, grad/param norm = 2.5592e-01, time/batch = 18.2837s	
3413/11350 (epoch 15.035), train_loss = 1.09880878, grad/param norm = 2.7488e-01, time/batch = 19.1901s	
3414/11350 (epoch 15.040), train_loss = 1.11466074, grad/param norm = 2.8592e-01, time/batch = 18.8713s	
3415/11350 (epoch 15.044), train_loss = 1.05155054, grad/param norm = 2.4151e-01, time/batch = 18.3641s	
3416/11350 (epoch 15.048), train_loss = 1.03576669, grad/param norm = 2.3584e-01, time/batch = 18.4620s	
3417/11350 (epoch 15.053), train_loss = 1.13766892, grad/param norm = 2.5252e-01, time/batch = 20.2959s	
3418/11350 (epoch 15.057), train_loss = 1.20350029, grad/param norm = 2.9212e-01, time/batch = 19.7788s	
3419/11350 (epoch 15.062), train_loss = 0.97484463, grad/param norm = 2.3700e-01, time/batch = 17.9312s	
3420/11350 (epoch 15.066), train_loss = 0.97252490, grad/param norm = 2.7292e-01, time/batch = 19.6243s	
3421/11350 (epoch 15.070), train_loss = 1.10440598, grad/param norm = 2.5317e-01, time/batch = 19.7942s	
3422/11350 (epoch 15.075), train_loss = 0.96016241, grad/param norm = 2.3813e-01, time/batch = 18.1902s	
3423/11350 (epoch 15.079), train_loss = 1.11387115, grad/param norm = 2.5708e-01, time/batch = 19.7764s	
3424/11350 (epoch 15.084), train_loss = 1.33763680, grad/param norm = 2.9709e-01, time/batch = 19.3675s	
3425/11350 (epoch 15.088), train_loss = 1.30308440, grad/param norm = 3.3562e-01, time/batch = 18.6135s	
3426/11350 (epoch 15.093), train_loss = 1.21949434, grad/param norm = 2.5306e-01, time/batch = 18.3800s	
3427/11350 (epoch 15.097), train_loss = 1.15922267, grad/param norm = 2.7451e-01, time/batch = 19.2943s	
3428/11350 (epoch 15.101), train_loss = 1.02300199, grad/param norm = 2.5347e-01, time/batch = 16.5613s	
3429/11350 (epoch 15.106), train_loss = 1.26024219, grad/param norm = 2.6330e-01, time/batch = 19.7185s	
3430/11350 (epoch 15.110), train_loss = 1.11156286, grad/param norm = 2.9658e-01, time/batch = 19.0589s	
3431/11350 (epoch 15.115), train_loss = 1.09882357, grad/param norm = 2.9567e-01, time/batch = 17.6006s	
3432/11350 (epoch 15.119), train_loss = 1.29109446, grad/param norm = 3.4789e-01, time/batch = 19.9471s	
3433/11350 (epoch 15.123), train_loss = 1.06023024, grad/param norm = 2.5344e-01, time/batch = 20.0473s	
3434/11350 (epoch 15.128), train_loss = 1.06562518, grad/param norm = 2.5032e-01, time/batch = 18.3417s	
3435/11350 (epoch 15.132), train_loss = 1.11208945, grad/param norm = 2.4794e-01, time/batch = 18.6438s	
3436/11350 (epoch 15.137), train_loss = 1.07167388, grad/param norm = 2.6235e-01, time/batch = 18.2931s	
3437/11350 (epoch 15.141), train_loss = 1.27944286, grad/param norm = 2.7734e-01, time/batch = 19.1262s	
3438/11350 (epoch 15.145), train_loss = 1.06592074, grad/param norm = 2.4494e-01, time/batch = 18.3646s	
3439/11350 (epoch 15.150), train_loss = 1.24271279, grad/param norm = 3.2443e-01, time/batch = 19.6144s	
3440/11350 (epoch 15.154), train_loss = 1.34682599, grad/param norm = 2.9882e-01, time/batch = 19.3564s	
3441/11350 (epoch 15.159), train_loss = 1.01257564, grad/param norm = 2.8165e-01, time/batch = 19.8478s	
3442/11350 (epoch 15.163), train_loss = 1.24201179, grad/param norm = 2.6600e-01, time/batch = 19.1201s	
3443/11350 (epoch 15.167), train_loss = 1.29617204, grad/param norm = 2.9590e-01, time/batch = 20.0479s	
3444/11350 (epoch 15.172), train_loss = 1.41795369, grad/param norm = 2.8688e-01, time/batch = 17.8554s	
3445/11350 (epoch 15.176), train_loss = 1.23220936, grad/param norm = 2.7977e-01, time/batch = 19.1361s	
3446/11350 (epoch 15.181), train_loss = 1.21353100, grad/param norm = 3.0144e-01, time/batch = 20.3671s	
3447/11350 (epoch 15.185), train_loss = 1.06338592, grad/param norm = 2.8788e-01, time/batch = 18.2605s	
3448/11350 (epoch 15.189), train_loss = 1.11322217, grad/param norm = 2.4884e-01, time/batch = 18.2802s	
3449/11350 (epoch 15.194), train_loss = 1.07263093, grad/param norm = 2.7356e-01, time/batch = 20.9222s	
3450/11350 (epoch 15.198), train_loss = 1.06120483, grad/param norm = 3.0199e-01, time/batch = 16.6008s	
3451/11350 (epoch 15.203), train_loss = 1.01002045, grad/param norm = 2.2440e-01, time/batch = 17.6996s	
3452/11350 (epoch 15.207), train_loss = 1.01259249, grad/param norm = 2.6359e-01, time/batch = 18.1386s	
3453/11350 (epoch 15.211), train_loss = 1.21662336, grad/param norm = 2.8085e-01, time/batch = 18.9485s	
3454/11350 (epoch 15.216), train_loss = 1.17728713, grad/param norm = 2.5522e-01, time/batch = 19.5462s	
3455/11350 (epoch 15.220), train_loss = 1.16311241, grad/param norm = 2.5386e-01, time/batch = 18.3006s	
3456/11350 (epoch 15.225), train_loss = 1.04441503, grad/param norm = 2.4708e-01, time/batch = 18.5399s	
3457/11350 (epoch 15.229), train_loss = 1.23164344, grad/param norm = 2.5729e-01, time/batch = 19.8725s	
3458/11350 (epoch 15.233), train_loss = 1.17829682, grad/param norm = 2.5930e-01, time/batch = 18.0233s	
3459/11350 (epoch 15.238), train_loss = 1.35098367, grad/param norm = 3.2636e-01, time/batch = 17.5009s	
3460/11350 (epoch 15.242), train_loss = 1.32588841, grad/param norm = 2.9692e-01, time/batch = 18.7795s	
3461/11350 (epoch 15.247), train_loss = 0.97293079, grad/param norm = 2.3400e-01, time/batch = 20.2072s	
3462/11350 (epoch 15.251), train_loss = 1.21927491, grad/param norm = 2.9118e-01, time/batch = 19.7878s	
3463/11350 (epoch 15.256), train_loss = 1.23046222, grad/param norm = 2.6068e-01, time/batch = 19.1834s	
3464/11350 (epoch 15.260), train_loss = 1.07981813, grad/param norm = 2.7167e-01, time/batch = 18.7867s	
3465/11350 (epoch 15.264), train_loss = 1.11615336, grad/param norm = 2.5804e-01, time/batch = 19.5423s	
3466/11350 (epoch 15.269), train_loss = 1.18255129, grad/param norm = 2.7148e-01, time/batch = 16.8584s	
3467/11350 (epoch 15.273), train_loss = 1.26104829, grad/param norm = 2.8073e-01, time/batch = 19.0352s	
3468/11350 (epoch 15.278), train_loss = 1.04113038, grad/param norm = 2.5400e-01, time/batch = 17.7247s	
3469/11350 (epoch 15.282), train_loss = 1.22796193, grad/param norm = 2.9796e-01, time/batch = 17.9610s	
3470/11350 (epoch 15.286), train_loss = 1.27905306, grad/param norm = 2.7496e-01, time/batch = 19.5432s	
3471/11350 (epoch 15.291), train_loss = 1.02672750, grad/param norm = 3.0543e-01, time/batch = 18.9532s	
3472/11350 (epoch 15.295), train_loss = 1.16923367, grad/param norm = 3.0376e-01, time/batch = 18.3782s	
3473/11350 (epoch 15.300), train_loss = 1.16383322, grad/param norm = 2.5909e-01, time/batch = 21.1214s	
3474/11350 (epoch 15.304), train_loss = 1.08857414, grad/param norm = 2.4036e-01, time/batch = 16.2670s	
3475/11350 (epoch 15.308), train_loss = 1.10150944, grad/param norm = 2.4421e-01, time/batch = 19.3677s	
3476/11350 (epoch 15.313), train_loss = 1.23380506, grad/param norm = 2.6094e-01, time/batch = 18.6291s	
3477/11350 (epoch 15.317), train_loss = 1.05856168, grad/param norm = 2.4207e-01, time/batch = 20.0429s	
3478/11350 (epoch 15.322), train_loss = 1.09826335, grad/param norm = 2.5630e-01, time/batch = 20.3612s	
3479/11350 (epoch 15.326), train_loss = 1.16054794, grad/param norm = 2.3937e-01, time/batch = 19.9185s	
3480/11350 (epoch 15.330), train_loss = 0.96173793, grad/param norm = 2.5565e-01, time/batch = 18.7937s	
3481/11350 (epoch 15.335), train_loss = 0.87030666, grad/param norm = 2.3236e-01, time/batch = 20.6217s	
3482/11350 (epoch 15.339), train_loss = 1.00361830, grad/param norm = 2.4701e-01, time/batch = 34.1063s	
3483/11350 (epoch 15.344), train_loss = 1.06954649, grad/param norm = 2.2367e-01, time/batch = 19.3737s	
3484/11350 (epoch 15.348), train_loss = 1.09899322, grad/param norm = 2.5012e-01, time/batch = 17.8502s	
3485/11350 (epoch 15.352), train_loss = 0.98067713, grad/param norm = 2.3982e-01, time/batch = 18.7108s	
3486/11350 (epoch 15.357), train_loss = 1.05864767, grad/param norm = 2.5028e-01, time/batch = 18.2086s	
3487/11350 (epoch 15.361), train_loss = 0.88964882, grad/param norm = 2.3183e-01, time/batch = 17.8776s	
3488/11350 (epoch 15.366), train_loss = 1.22680750, grad/param norm = 2.7049e-01, time/batch = 15.1547s	
3489/11350 (epoch 15.370), train_loss = 1.09525638, grad/param norm = 2.9084e-01, time/batch = 17.5604s	
3490/11350 (epoch 15.374), train_loss = 1.08916557, grad/param norm = 2.6251e-01, time/batch = 18.8038s	
3491/11350 (epoch 15.379), train_loss = 1.13113800, grad/param norm = 2.5691e-01, time/batch = 18.6173s	
3492/11350 (epoch 15.383), train_loss = 0.95727700, grad/param norm = 2.2435e-01, time/batch = 18.6957s	
3493/11350 (epoch 15.388), train_loss = 1.15652371, grad/param norm = 2.9513e-01, time/batch = 19.7938s	
3494/11350 (epoch 15.392), train_loss = 1.10502224, grad/param norm = 2.9384e-01, time/batch = 16.8575s	
3495/11350 (epoch 15.396), train_loss = 1.17589975, grad/param norm = 2.8435e-01, time/batch = 16.1047s	
3496/11350 (epoch 15.401), train_loss = 1.13750597, grad/param norm = 2.7508e-01, time/batch = 17.0315s	
3497/11350 (epoch 15.405), train_loss = 1.28512184, grad/param norm = 2.6798e-01, time/batch = 18.1949s	
3498/11350 (epoch 15.410), train_loss = 1.34625180, grad/param norm = 3.1199e-01, time/batch = 18.2131s	
3499/11350 (epoch 15.414), train_loss = 0.99292129, grad/param norm = 2.6923e-01, time/batch = 18.1969s	
3500/11350 (epoch 15.419), train_loss = 1.09376992, grad/param norm = 3.0081e-01, time/batch = 16.2424s	
3501/11350 (epoch 15.423), train_loss = 1.23884179, grad/param norm = 3.0812e-01, time/batch = 18.4432s	
3502/11350 (epoch 15.427), train_loss = 1.28241172, grad/param norm = 2.8763e-01, time/batch = 18.1347s	
3503/11350 (epoch 15.432), train_loss = 1.26625659, grad/param norm = 2.9759e-01, time/batch = 18.7332s	
3504/11350 (epoch 15.436), train_loss = 1.15126272, grad/param norm = 2.9140e-01, time/batch = 17.8608s	
3505/11350 (epoch 15.441), train_loss = 1.38548069, grad/param norm = 3.1539e-01, time/batch = 19.2043s	
3506/11350 (epoch 15.445), train_loss = 0.94393766, grad/param norm = 2.1687e-01, time/batch = 19.1310s	
3507/11350 (epoch 15.449), train_loss = 1.10725651, grad/param norm = 2.9295e-01, time/batch = 17.9358s	
3508/11350 (epoch 15.454), train_loss = 1.29665098, grad/param norm = 2.8361e-01, time/batch = 19.0489s	
3509/11350 (epoch 15.458), train_loss = 0.93986039, grad/param norm = 2.2633e-01, time/batch = 18.3855s	
3510/11350 (epoch 15.463), train_loss = 1.02072540, grad/param norm = 2.5428e-01, time/batch = 16.2656s	
3511/11350 (epoch 15.467), train_loss = 1.45468321, grad/param norm = 3.0308e-01, time/batch = 17.3637s	
3512/11350 (epoch 15.471), train_loss = 1.30202490, grad/param norm = 3.1110e-01, time/batch = 19.3608s	
3513/11350 (epoch 15.476), train_loss = 1.23985841, grad/param norm = 2.6209e-01, time/batch = 18.8886s	
3514/11350 (epoch 15.480), train_loss = 1.35530926, grad/param norm = 2.7118e-01, time/batch = 17.0970s	
3515/11350 (epoch 15.485), train_loss = 1.14099847, grad/param norm = 2.4609e-01, time/batch = 18.8747s	
3516/11350 (epoch 15.489), train_loss = 1.30244266, grad/param norm = 2.8694e-01, time/batch = 18.4545s	
3517/11350 (epoch 15.493), train_loss = 1.27259453, grad/param norm = 3.0085e-01, time/batch = 17.2965s	
3518/11350 (epoch 15.498), train_loss = 0.93289555, grad/param norm = 2.4402e-01, time/batch = 19.1291s	
3519/11350 (epoch 15.502), train_loss = 1.22107740, grad/param norm = 2.6153e-01, time/batch = 19.7167s	
3520/11350 (epoch 15.507), train_loss = 1.01975170, grad/param norm = 2.5903e-01, time/batch = 17.6688s	
3521/11350 (epoch 15.511), train_loss = 1.37545927, grad/param norm = 2.7743e-01, time/batch = 18.8783s	
3522/11350 (epoch 15.515), train_loss = 1.15209355, grad/param norm = 2.4848e-01, time/batch = 18.1288s	
3523/11350 (epoch 15.520), train_loss = 1.35256428, grad/param norm = 3.0900e-01, time/batch = 17.9615s	
3524/11350 (epoch 15.524), train_loss = 1.16214357, grad/param norm = 2.6964e-01, time/batch = 18.2980s	
3525/11350 (epoch 15.529), train_loss = 1.16347160, grad/param norm = 2.4321e-01, time/batch = 16.3753s	
3526/11350 (epoch 15.533), train_loss = 1.43257001, grad/param norm = 2.6987e-01, time/batch = 18.8819s	
3527/11350 (epoch 15.537), train_loss = 1.24191672, grad/param norm = 2.7162e-01, time/batch = 16.5219s	
3528/11350 (epoch 15.542), train_loss = 1.26419096, grad/param norm = 2.3355e-01, time/batch = 18.4261s	
3529/11350 (epoch 15.546), train_loss = 1.49366416, grad/param norm = 2.9193e-01, time/batch = 20.2857s	
3530/11350 (epoch 15.551), train_loss = 1.20953180, grad/param norm = 2.5509e-01, time/batch = 17.3642s	
3531/11350 (epoch 15.555), train_loss = 1.13158369, grad/param norm = 2.8108e-01, time/batch = 18.4653s	
3532/11350 (epoch 15.559), train_loss = 1.14532627, grad/param norm = 2.8141e-01, time/batch = 18.7680s	
3533/11350 (epoch 15.564), train_loss = 1.32084321, grad/param norm = 3.0217e-01, time/batch = 19.1203s	
3534/11350 (epoch 15.568), train_loss = 1.25710283, grad/param norm = 2.6746e-01, time/batch = 20.8509s	
3535/11350 (epoch 15.573), train_loss = 1.40841849, grad/param norm = 3.2133e-01, time/batch = 18.0414s	
3536/11350 (epoch 15.577), train_loss = 1.40865334, grad/param norm = 3.5591e-01, time/batch = 18.7826s	
3537/11350 (epoch 15.581), train_loss = 1.31135647, grad/param norm = 2.8453e-01, time/batch = 19.2780s	
3538/11350 (epoch 15.586), train_loss = 1.35877471, grad/param norm = 3.5132e-01, time/batch = 19.2124s	
3539/11350 (epoch 15.590), train_loss = 1.44396166, grad/param norm = 3.5305e-01, time/batch = 19.6986s	
3540/11350 (epoch 15.595), train_loss = 1.43627686, grad/param norm = 2.7663e-01, time/batch = 18.5400s	
3541/11350 (epoch 15.599), train_loss = 1.33377269, grad/param norm = 3.0568e-01, time/batch = 19.2021s	
3542/11350 (epoch 15.604), train_loss = 1.20492171, grad/param norm = 2.4356e-01, time/batch = 19.3012s	
3543/11350 (epoch 15.608), train_loss = 1.27312872, grad/param norm = 2.8678e-01, time/batch = 17.9348s	
3544/11350 (epoch 15.612), train_loss = 1.15702657, grad/param norm = 2.5028e-01, time/batch = 18.0391s	
3545/11350 (epoch 15.617), train_loss = 1.37976257, grad/param norm = 2.9183e-01, time/batch = 17.3041s	
3546/11350 (epoch 15.621), train_loss = 1.36620269, grad/param norm = 2.5623e-01, time/batch = 15.9542s	
3547/11350 (epoch 15.626), train_loss = 1.25203291, grad/param norm = 2.6145e-01, time/batch = 15.3095s	
3548/11350 (epoch 15.630), train_loss = 1.31394593, grad/param norm = 2.8188e-01, time/batch = 15.7142s	
3549/11350 (epoch 15.634), train_loss = 1.31034222, grad/param norm = 2.8337e-01, time/batch = 16.0556s	
3550/11350 (epoch 15.639), train_loss = 1.15463404, grad/param norm = 2.7834e-01, time/batch = 16.7596s	
3551/11350 (epoch 15.643), train_loss = 1.14627009, grad/param norm = 2.5891e-01, time/batch = 19.7510s	
3552/11350 (epoch 15.648), train_loss = 1.22137961, grad/param norm = 2.6638e-01, time/batch = 20.3703s	
3553/11350 (epoch 15.652), train_loss = 1.19399780, grad/param norm = 2.7217e-01, time/batch = 17.8866s	
3554/11350 (epoch 15.656), train_loss = 1.33233468, grad/param norm = 3.2843e-01, time/batch = 17.6132s	
3555/11350 (epoch 15.661), train_loss = 1.41975102, grad/param norm = 2.8783e-01, time/batch = 20.2029s	
3556/11350 (epoch 15.665), train_loss = 1.28241836, grad/param norm = 2.8920e-01, time/batch = 17.3557s	
3557/11350 (epoch 15.670), train_loss = 1.25042551, grad/param norm = 2.8537e-01, time/batch = 19.6965s	
3558/11350 (epoch 15.674), train_loss = 1.16778501, grad/param norm = 2.4814e-01, time/batch = 18.3708s	
3559/11350 (epoch 15.678), train_loss = 1.20195474, grad/param norm = 2.4948e-01, time/batch = 17.0981s	
3560/11350 (epoch 15.683), train_loss = 1.14675876, grad/param norm = 2.5920e-01, time/batch = 19.2055s	
3561/11350 (epoch 15.687), train_loss = 1.12438433, grad/param norm = 2.8779e-01, time/batch = 18.7960s	
3562/11350 (epoch 15.692), train_loss = 1.56145211, grad/param norm = 3.4113e-01, time/batch = 20.3528s	
3563/11350 (epoch 15.696), train_loss = 1.38802970, grad/param norm = 3.1754e-01, time/batch = 18.7724s	
3564/11350 (epoch 15.700), train_loss = 1.33716589, grad/param norm = 3.1400e-01, time/batch = 19.7843s	
3565/11350 (epoch 15.705), train_loss = 1.42162153, grad/param norm = 3.0692e-01, time/batch = 20.3025s	
3566/11350 (epoch 15.709), train_loss = 1.36613650, grad/param norm = 3.0046e-01, time/batch = 19.6796s	
3567/11350 (epoch 15.714), train_loss = 1.20058659, grad/param norm = 2.3808e-01, time/batch = 20.0488s	
3568/11350 (epoch 15.718), train_loss = 1.11248891, grad/param norm = 2.4891e-01, time/batch = 19.0445s	
3569/11350 (epoch 15.722), train_loss = 1.29682326, grad/param norm = 3.0673e-01, time/batch = 17.5940s	
3570/11350 (epoch 15.727), train_loss = 1.24498254, grad/param norm = 2.6522e-01, time/batch = 18.5331s	
3571/11350 (epoch 15.731), train_loss = 1.31950373, grad/param norm = 2.8807e-01, time/batch = 19.8737s	
3572/11350 (epoch 15.736), train_loss = 1.23045664, grad/param norm = 2.8100e-01, time/batch = 18.3546s	
3573/11350 (epoch 15.740), train_loss = 1.23094963, grad/param norm = 2.8928e-01, time/batch = 20.1129s	
3574/11350 (epoch 15.744), train_loss = 1.34540937, grad/param norm = 2.8942e-01, time/batch = 19.3753s	
3575/11350 (epoch 15.749), train_loss = 1.38309602, grad/param norm = 2.9703e-01, time/batch = 18.0326s	
3576/11350 (epoch 15.753), train_loss = 1.34155858, grad/param norm = 2.9473e-01, time/batch = 20.0449s	
3577/11350 (epoch 15.758), train_loss = 1.19904685, grad/param norm = 3.3490e-01, time/batch = 17.8092s	
3578/11350 (epoch 15.762), train_loss = 1.31713320, grad/param norm = 3.0599e-01, time/batch = 17.2103s	
3579/11350 (epoch 15.767), train_loss = 1.32112602, grad/param norm = 2.4135e-01, time/batch = 17.6334s	
3580/11350 (epoch 15.771), train_loss = 1.40994960, grad/param norm = 2.6868e-01, time/batch = 17.8868s	
3581/11350 (epoch 15.775), train_loss = 1.19306877, grad/param norm = 2.9306e-01, time/batch = 19.0283s	
3582/11350 (epoch 15.780), train_loss = 1.34347980, grad/param norm = 2.6505e-01, time/batch = 20.1236s	
3583/11350 (epoch 15.784), train_loss = 1.16941727, grad/param norm = 2.4570e-01, time/batch = 18.2128s	
3584/11350 (epoch 15.789), train_loss = 1.24313097, grad/param norm = 2.9300e-01, time/batch = 19.7093s	
3585/11350 (epoch 15.793), train_loss = 1.32110918, grad/param norm = 2.6347e-01, time/batch = 18.6124s	
3586/11350 (epoch 15.797), train_loss = 1.20307214, grad/param norm = 2.5632e-01, time/batch = 18.9671s	
3587/11350 (epoch 15.802), train_loss = 1.29797939, grad/param norm = 2.8347e-01, time/batch = 18.2667s	
3588/11350 (epoch 15.806), train_loss = 1.30228267, grad/param norm = 2.7011e-01, time/batch = 18.9574s	
3589/11350 (epoch 15.811), train_loss = 1.23874485, grad/param norm = 2.9522e-01, time/batch = 18.5413s	
3590/11350 (epoch 15.815), train_loss = 1.13740303, grad/param norm = 2.6064e-01, time/batch = 15.8166s	
3591/11350 (epoch 15.819), train_loss = 1.13505091, grad/param norm = 2.6402e-01, time/batch = 18.4469s	
3592/11350 (epoch 15.824), train_loss = 1.18392032, grad/param norm = 2.8014e-01, time/batch = 16.2790s	
3593/11350 (epoch 15.828), train_loss = 1.24189374, grad/param norm = 2.8420e-01, time/batch = 18.6297s	
3594/11350 (epoch 15.833), train_loss = 1.24466208, grad/param norm = 2.8285e-01, time/batch = 18.9450s	
3595/11350 (epoch 15.837), train_loss = 1.24517756, grad/param norm = 2.6195e-01, time/batch = 20.4391s	
3596/11350 (epoch 15.841), train_loss = 1.50803510, grad/param norm = 2.8575e-01, time/batch = 18.4420s	
3597/11350 (epoch 15.846), train_loss = 1.23076683, grad/param norm = 2.5646e-01, time/batch = 19.1243s	
3598/11350 (epoch 15.850), train_loss = 1.35706414, grad/param norm = 3.0108e-01, time/batch = 18.7107s	
3599/11350 (epoch 15.855), train_loss = 1.10132749, grad/param norm = 2.6487e-01, time/batch = 18.3858s	
3600/11350 (epoch 15.859), train_loss = 1.25066995, grad/param norm = 2.9597e-01, time/batch = 20.4649s	
3601/11350 (epoch 15.863), train_loss = 1.11311358, grad/param norm = 2.6994e-01, time/batch = 18.4379s	
3602/11350 (epoch 15.868), train_loss = 1.21037075, grad/param norm = 2.7304e-01, time/batch = 16.6987s	
3603/11350 (epoch 15.872), train_loss = 1.21700011, grad/param norm = 2.8684e-01, time/batch = 20.0288s	
3604/11350 (epoch 15.877), train_loss = 1.23088868, grad/param norm = 2.6593e-01, time/batch = 18.9408s	
3605/11350 (epoch 15.881), train_loss = 1.47590310, grad/param norm = 3.1446e-01, time/batch = 19.3780s	
3606/11350 (epoch 15.885), train_loss = 1.44893224, grad/param norm = 2.8874e-01, time/batch = 18.1457s	
3607/11350 (epoch 15.890), train_loss = 1.32772114, grad/param norm = 2.6783e-01, time/batch = 17.7840s	
3608/11350 (epoch 15.894), train_loss = 1.07154923, grad/param norm = 2.6193e-01, time/batch = 19.1334s	
3609/11350 (epoch 15.899), train_loss = 1.33952423, grad/param norm = 2.6232e-01, time/batch = 19.0495s	
3610/11350 (epoch 15.903), train_loss = 1.36198204, grad/param norm = 3.0765e-01, time/batch = 18.5291s	
3611/11350 (epoch 15.907), train_loss = 1.31029556, grad/param norm = 2.7168e-01, time/batch = 17.0581s	
3612/11350 (epoch 15.912), train_loss = 1.21458414, grad/param norm = 2.7991e-01, time/batch = 17.7113s	
3613/11350 (epoch 15.916), train_loss = 1.35154316, grad/param norm = 2.6276e-01, time/batch = 19.7891s	
3614/11350 (epoch 15.921), train_loss = 1.31403110, grad/param norm = 2.8258e-01, time/batch = 19.5404s	
3615/11350 (epoch 15.925), train_loss = 1.11288095, grad/param norm = 2.5057e-01, time/batch = 18.7823s	
3616/11350 (epoch 15.930), train_loss = 1.35986002, grad/param norm = 2.8521e-01, time/batch = 20.2037s	
3617/11350 (epoch 15.934), train_loss = 1.41869535, grad/param norm = 2.7077e-01, time/batch = 17.3534s	
3618/11350 (epoch 15.938), train_loss = 1.21497263, grad/param norm = 2.4846e-01, time/batch = 19.0376s	
3619/11350 (epoch 15.943), train_loss = 1.38174237, grad/param norm = 2.8669e-01, time/batch = 19.2968s	
3620/11350 (epoch 15.947), train_loss = 1.38074245, grad/param norm = 3.6082e-01, time/batch = 17.1625s	
3621/11350 (epoch 15.952), train_loss = 1.34627200, grad/param norm = 3.0739e-01, time/batch = 20.3720s	
3622/11350 (epoch 15.956), train_loss = 1.04903605, grad/param norm = 2.4629e-01, time/batch = 19.4639s	
3623/11350 (epoch 15.960), train_loss = 1.24747178, grad/param norm = 2.9789e-01, time/batch = 18.0156s	
3624/11350 (epoch 15.965), train_loss = 1.15614619, grad/param norm = 2.8077e-01, time/batch = 16.5372s	
3625/11350 (epoch 15.969), train_loss = 1.16090701, grad/param norm = 3.4725e-01, time/batch = 17.7894s	
3626/11350 (epoch 15.974), train_loss = 1.07374610, grad/param norm = 2.7042e-01, time/batch = 18.6881s	
3627/11350 (epoch 15.978), train_loss = 1.24317891, grad/param norm = 2.6209e-01, time/batch = 19.7771s	
3628/11350 (epoch 15.982), train_loss = 1.00317837, grad/param norm = 2.4295e-01, time/batch = 18.5540s	
3629/11350 (epoch 15.987), train_loss = 1.25110533, grad/param norm = 2.9290e-01, time/batch = 18.0182s	
3630/11350 (epoch 15.991), train_loss = 1.09534523, grad/param norm = 2.8371e-01, time/batch = 18.1909s	
3631/11350 (epoch 15.996), train_loss = 1.28293200, grad/param norm = 3.1695e-01, time/batch = 20.5223s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
3632/11350 (epoch 16.000), train_loss = 0.99496999, grad/param norm = 2.9195e-01, time/batch = 19.4587s	
3633/11350 (epoch 16.004), train_loss = 1.23884162, grad/param norm = 3.1100e-01, time/batch = 18.2661s	
3634/11350 (epoch 16.009), train_loss = 1.25002399, grad/param norm = 2.5872e-01, time/batch = 17.8439s	
3635/11350 (epoch 16.013), train_loss = 0.85044456, grad/param norm = 2.2327e-01, time/batch = 18.6978s	
3636/11350 (epoch 16.018), train_loss = 0.92955353, grad/param norm = 2.5663e-01, time/batch = 17.7148s	
3637/11350 (epoch 16.022), train_loss = 0.95322490, grad/param norm = 2.3805e-01, time/batch = 20.0549s	
3638/11350 (epoch 16.026), train_loss = 1.02520132, grad/param norm = 2.9758e-01, time/batch = 19.2854s	
3639/11350 (epoch 16.031), train_loss = 0.99518303, grad/param norm = 2.5668e-01, time/batch = 18.1663s	
3640/11350 (epoch 16.035), train_loss = 1.05791596, grad/param norm = 2.7226e-01, time/batch = 19.1237s	
3641/11350 (epoch 16.040), train_loss = 1.06924946, grad/param norm = 2.7085e-01, time/batch = 18.0399s	
3642/11350 (epoch 16.044), train_loss = 1.01762687, grad/param norm = 2.4087e-01, time/batch = 18.2045s	
3643/11350 (epoch 16.048), train_loss = 0.99273501, grad/param norm = 2.4477e-01, time/batch = 18.7800s	
3644/11350 (epoch 16.053), train_loss = 1.09918721, grad/param norm = 2.4951e-01, time/batch = 17.8664s	
3645/11350 (epoch 16.057), train_loss = 1.15228603, grad/param norm = 2.7685e-01, time/batch = 18.2065s	
3646/11350 (epoch 16.062), train_loss = 0.94362369, grad/param norm = 2.4331e-01, time/batch = 19.1697s	
3647/11350 (epoch 16.066), train_loss = 0.93376273, grad/param norm = 2.4809e-01, time/batch = 19.6234s	
3648/11350 (epoch 16.070), train_loss = 1.06307020, grad/param norm = 2.5349e-01, time/batch = 19.4505s	
3649/11350 (epoch 16.075), train_loss = 0.93620155, grad/param norm = 2.5388e-01, time/batch = 18.3451s	
3650/11350 (epoch 16.079), train_loss = 1.08870621, grad/param norm = 2.8003e-01, time/batch = 19.2118s	
3651/11350 (epoch 16.084), train_loss = 1.28136706, grad/param norm = 2.8414e-01, time/batch = 19.1331s	
3652/11350 (epoch 16.088), train_loss = 1.26350359, grad/param norm = 3.4545e-01, time/batch = 17.9403s	
3653/11350 (epoch 16.093), train_loss = 1.18614567, grad/param norm = 2.7941e-01, time/batch = 19.5560s	
3654/11350 (epoch 16.097), train_loss = 1.11500993, grad/param norm = 2.5868e-01, time/batch = 20.0421s	
3655/11350 (epoch 16.101), train_loss = 0.98872990, grad/param norm = 2.4691e-01, time/batch = 17.7729s	
3656/11350 (epoch 16.106), train_loss = 1.20683101, grad/param norm = 2.6949e-01, time/batch = 19.9518s	
3657/11350 (epoch 16.110), train_loss = 1.07015393, grad/param norm = 2.9489e-01, time/batch = 17.1060s	
3658/11350 (epoch 16.115), train_loss = 1.05937671, grad/param norm = 2.8878e-01, time/batch = 17.9283s	
3659/11350 (epoch 16.119), train_loss = 1.25339495, grad/param norm = 3.8118e-01, time/batch = 20.1365s	
3660/11350 (epoch 16.123), train_loss = 1.02496149, grad/param norm = 2.6282e-01, time/batch = 18.2143s	
3661/11350 (epoch 16.128), train_loss = 1.01755936, grad/param norm = 2.5408e-01, time/batch = 18.0210s	
3662/11350 (epoch 16.132), train_loss = 1.07216427, grad/param norm = 2.4956e-01, time/batch = 19.8798s	
3663/11350 (epoch 16.137), train_loss = 1.03796383, grad/param norm = 2.7231e-01, time/batch = 18.6230s	
3664/11350 (epoch 16.141), train_loss = 1.24209569, grad/param norm = 2.7081e-01, time/batch = 18.7074s	
3665/11350 (epoch 16.145), train_loss = 1.02393156, grad/param norm = 2.5226e-01, time/batch = 20.3699s	
3666/11350 (epoch 16.150), train_loss = 1.18699238, grad/param norm = 3.2050e-01, time/batch = 17.1942s	
3667/11350 (epoch 16.154), train_loss = 1.29812133, grad/param norm = 2.8980e-01, time/batch = 19.9548s	
3668/11350 (epoch 16.159), train_loss = 0.97982936, grad/param norm = 3.1264e-01, time/batch = 19.5219s	
3669/11350 (epoch 16.163), train_loss = 1.20308870, grad/param norm = 3.0033e-01, time/batch = 18.6276s	
3670/11350 (epoch 16.167), train_loss = 1.24164854, grad/param norm = 2.7426e-01, time/batch = 20.5509s	
3671/11350 (epoch 16.172), train_loss = 1.38100559, grad/param norm = 2.9841e-01, time/batch = 17.6074s	
3672/11350 (epoch 16.176), train_loss = 1.19414275, grad/param norm = 2.8745e-01, time/batch = 19.2139s	
3673/11350 (epoch 16.181), train_loss = 1.17556684, grad/param norm = 3.0990e-01, time/batch = 20.0426s	
3674/11350 (epoch 16.185), train_loss = 1.00700301, grad/param norm = 2.7555e-01, time/batch = 30.7465s	
3675/11350 (epoch 16.189), train_loss = 1.07977952, grad/param norm = 2.6263e-01, time/batch = 19.6114s	
3676/11350 (epoch 16.194), train_loss = 1.03856644, grad/param norm = 2.6928e-01, time/batch = 19.1077s	
3677/11350 (epoch 16.198), train_loss = 1.02037238, grad/param norm = 3.1364e-01, time/batch = 17.0325s	
3678/11350 (epoch 16.203), train_loss = 0.99001860, grad/param norm = 2.7900e-01, time/batch = 20.2030s	
3679/11350 (epoch 16.207), train_loss = 0.98192986, grad/param norm = 2.6487e-01, time/batch = 19.6961s	
3680/11350 (epoch 16.211), train_loss = 1.18520337, grad/param norm = 3.0874e-01, time/batch = 18.2171s	
3681/11350 (epoch 16.216), train_loss = 1.13793268, grad/param norm = 2.7112e-01, time/batch = 19.4473s	
3682/11350 (epoch 16.220), train_loss = 1.12651834, grad/param norm = 2.5148e-01, time/batch = 18.5891s	
3683/11350 (epoch 16.225), train_loss = 1.00927723, grad/param norm = 2.3611e-01, time/batch = 18.7410s	
3684/11350 (epoch 16.229), train_loss = 1.18799126, grad/param norm = 2.7553e-01, time/batch = 19.4503s	
3685/11350 (epoch 16.233), train_loss = 1.13671043, grad/param norm = 2.6810e-01, time/batch = 20.6995s	
3686/11350 (epoch 16.238), train_loss = 1.28788975, grad/param norm = 3.2044e-01, time/batch = 18.7376s	
3687/11350 (epoch 16.242), train_loss = 1.27976306, grad/param norm = 3.3585e-01, time/batch = 19.8599s	
3688/11350 (epoch 16.247), train_loss = 0.93392228, grad/param norm = 2.3183e-01, time/batch = 20.6231s	
3689/11350 (epoch 16.251), train_loss = 1.16444702, grad/param norm = 2.8425e-01, time/batch = 17.8500s	
3690/11350 (epoch 16.256), train_loss = 1.17506071, grad/param norm = 2.8087e-01, time/batch = 20.5299s	
3691/11350 (epoch 16.260), train_loss = 1.03935105, grad/param norm = 2.7608e-01, time/batch = 16.7116s	
3692/11350 (epoch 16.264), train_loss = 1.08164740, grad/param norm = 2.6084e-01, time/batch = 17.7843s	
3693/11350 (epoch 16.269), train_loss = 1.13701144, grad/param norm = 2.7047e-01, time/batch = 20.0262s	
3694/11350 (epoch 16.273), train_loss = 1.21556339, grad/param norm = 2.8044e-01, time/batch = 19.2964s	
3695/11350 (epoch 16.278), train_loss = 1.00252672, grad/param norm = 2.5190e-01, time/batch = 18.7710s	
3696/11350 (epoch 16.282), train_loss = 1.16435040, grad/param norm = 2.8885e-01, time/batch = 19.6977s	
3697/11350 (epoch 16.286), train_loss = 1.23568209, grad/param norm = 2.6251e-01, time/batch = 19.6101s	
3698/11350 (epoch 16.291), train_loss = 0.98535810, grad/param norm = 3.0907e-01, time/batch = 17.9632s	
3699/11350 (epoch 16.295), train_loss = 1.14076830, grad/param norm = 3.2365e-01, time/batch = 18.1146s	
3700/11350 (epoch 16.300), train_loss = 1.12089895, grad/param norm = 2.4777e-01, time/batch = 20.4585s	
3701/11350 (epoch 16.304), train_loss = 1.05188896, grad/param norm = 2.4346e-01, time/batch = 18.3501s	
3702/11350 (epoch 16.308), train_loss = 1.06129825, grad/param norm = 2.5733e-01, time/batch = 17.3223s	
3703/11350 (epoch 16.313), train_loss = 1.18621352, grad/param norm = 2.4687e-01, time/batch = 19.4641s	
3704/11350 (epoch 16.317), train_loss = 1.02870917, grad/param norm = 2.4498e-01, time/batch = 18.8844s	
3705/11350 (epoch 16.322), train_loss = 1.05750452, grad/param norm = 2.5275e-01, time/batch = 18.0045s	
3706/11350 (epoch 16.326), train_loss = 1.12728616, grad/param norm = 2.4714e-01, time/batch = 19.2904s	
3707/11350 (epoch 16.330), train_loss = 0.91528034, grad/param norm = 2.4774e-01, time/batch = 18.5412s	
3708/11350 (epoch 16.335), train_loss = 0.84002385, grad/param norm = 2.5279e-01, time/batch = 18.3790s	
3709/11350 (epoch 16.339), train_loss = 0.94838805, grad/param norm = 2.5006e-01, time/batch = 19.5597s	
3710/11350 (epoch 16.344), train_loss = 1.02158331, grad/param norm = 2.2721e-01, time/batch = 19.5325s	
3711/11350 (epoch 16.348), train_loss = 1.05475755, grad/param norm = 2.4278e-01, time/batch = 18.6198s	
3712/11350 (epoch 16.352), train_loss = 0.95698388, grad/param norm = 2.5058e-01, time/batch = 19.1294s	
3713/11350 (epoch 16.357), train_loss = 1.01973958, grad/param norm = 2.4771e-01, time/batch = 18.2927s	
3714/11350 (epoch 16.361), train_loss = 0.85671124, grad/param norm = 2.2629e-01, time/batch = 17.5800s	
3715/11350 (epoch 16.366), train_loss = 1.17544767, grad/param norm = 2.7598e-01, time/batch = 16.6130s	
3716/11350 (epoch 16.370), train_loss = 1.03737029, grad/param norm = 3.0164e-01, time/batch = 16.2765s	
3717/11350 (epoch 16.374), train_loss = 1.04116323, grad/param norm = 2.5902e-01, time/batch = 17.3934s	
3718/11350 (epoch 16.379), train_loss = 1.07819184, grad/param norm = 2.4975e-01, time/batch = 17.2688s	
3719/11350 (epoch 16.383), train_loss = 0.92252205, grad/param norm = 2.2399e-01, time/batch = 19.1323s	
3720/11350 (epoch 16.388), train_loss = 1.11621453, grad/param norm = 2.9967e-01, time/batch = 20.5305s	
3721/11350 (epoch 16.392), train_loss = 1.06927047, grad/param norm = 2.9541e-01, time/batch = 18.1796s	
3722/11350 (epoch 16.396), train_loss = 1.12928433, grad/param norm = 2.7704e-01, time/batch = 19.2096s	
3723/11350 (epoch 16.401), train_loss = 1.09537314, grad/param norm = 2.7953e-01, time/batch = 20.1836s	
3724/11350 (epoch 16.405), train_loss = 1.24768243, grad/param norm = 2.7131e-01, time/batch = 18.4568s	
3725/11350 (epoch 16.410), train_loss = 1.29172664, grad/param norm = 2.8832e-01, time/batch = 16.5207s	
3726/11350 (epoch 16.414), train_loss = 0.96200578, grad/param norm = 2.9405e-01, time/batch = 19.8599s	
3727/11350 (epoch 16.419), train_loss = 1.04162793, grad/param norm = 2.7279e-01, time/batch = 18.4449s	
3728/11350 (epoch 16.423), train_loss = 1.17363548, grad/param norm = 3.0432e-01, time/batch = 19.9577s	
3729/11350 (epoch 16.427), train_loss = 1.24098431, grad/param norm = 3.1378e-01, time/batch = 18.8819s	
3730/11350 (epoch 16.432), train_loss = 1.20058167, grad/param norm = 3.0331e-01, time/batch = 18.5423s	
3731/11350 (epoch 16.436), train_loss = 1.11112451, grad/param norm = 3.4091e-01, time/batch = 19.2150s	
3732/11350 (epoch 16.441), train_loss = 1.34434898, grad/param norm = 3.2544e-01, time/batch = 17.3915s	
3733/11350 (epoch 16.445), train_loss = 0.91559692, grad/param norm = 2.2573e-01, time/batch = 19.3671s	
3734/11350 (epoch 16.449), train_loss = 1.06803368, grad/param norm = 3.0397e-01, time/batch = 17.6954s	
3735/11350 (epoch 16.454), train_loss = 1.26843043, grad/param norm = 3.1775e-01, time/batch = 17.7903s	
3736/11350 (epoch 16.458), train_loss = 0.90073317, grad/param norm = 2.3125e-01, time/batch = 19.2113s	
3737/11350 (epoch 16.463), train_loss = 0.99209813, grad/param norm = 2.8600e-01, time/batch = 17.8643s	
3738/11350 (epoch 16.467), train_loss = 1.42273807, grad/param norm = 3.0735e-01, time/batch = 19.9534s	
3739/11350 (epoch 16.471), train_loss = 1.25220590, grad/param norm = 2.9911e-01, time/batch = 17.7808s	
3740/11350 (epoch 16.476), train_loss = 1.19292428, grad/param norm = 2.6152e-01, time/batch = 17.4534s	
3741/11350 (epoch 16.480), train_loss = 1.30813893, grad/param norm = 2.7725e-01, time/batch = 18.8666s	
3742/11350 (epoch 16.485), train_loss = 1.10132765, grad/param norm = 2.5599e-01, time/batch = 18.3672s	
3743/11350 (epoch 16.489), train_loss = 1.26668483, grad/param norm = 3.0184e-01, time/batch = 18.7788s	
3744/11350 (epoch 16.493), train_loss = 1.23766386, grad/param norm = 3.0726e-01, time/batch = 17.0315s	
3745/11350 (epoch 16.498), train_loss = 0.89494947, grad/param norm = 2.3858e-01, time/batch = 19.6185s	
3746/11350 (epoch 16.502), train_loss = 1.17557741, grad/param norm = 2.4928e-01, time/batch = 18.5399s	
3747/11350 (epoch 16.507), train_loss = 0.98171269, grad/param norm = 2.6069e-01, time/batch = 19.1789s	
3748/11350 (epoch 16.511), train_loss = 1.32538781, grad/param norm = 2.8254e-01, time/batch = 18.6270s	
3749/11350 (epoch 16.515), train_loss = 1.12301211, grad/param norm = 2.6058e-01, time/batch = 19.7947s	
3750/11350 (epoch 16.520), train_loss = 1.30440955, grad/param norm = 3.0057e-01, time/batch = 16.3684s	
3751/11350 (epoch 16.524), train_loss = 1.11941103, grad/param norm = 2.4720e-01, time/batch = 19.7924s	
3752/11350 (epoch 16.529), train_loss = 1.11401447, grad/param norm = 2.5561e-01, time/batch = 20.1257s	
3753/11350 (epoch 16.533), train_loss = 1.37527414, grad/param norm = 2.5840e-01, time/batch = 16.2144s	
3754/11350 (epoch 16.537), train_loss = 1.20479283, grad/param norm = 2.7651e-01, time/batch = 19.7006s	
3755/11350 (epoch 16.542), train_loss = 1.21364202, grad/param norm = 2.3643e-01, time/batch = 19.6219s	
3756/11350 (epoch 16.546), train_loss = 1.43513651, grad/param norm = 3.0261e-01, time/batch = 17.4611s	
3757/11350 (epoch 16.551), train_loss = 1.17083920, grad/param norm = 2.7861e-01, time/batch = 19.9636s	
3758/11350 (epoch 16.555), train_loss = 1.10177746, grad/param norm = 2.8273e-01, time/batch = 19.7816s	
3759/11350 (epoch 16.559), train_loss = 1.09198236, grad/param norm = 2.6708e-01, time/batch = 18.7036s	
3760/11350 (epoch 16.564), train_loss = 1.26139231, grad/param norm = 2.7461e-01, time/batch = 20.1259s	
3761/11350 (epoch 16.568), train_loss = 1.20824015, grad/param norm = 2.6083e-01, time/batch = 19.7013s	
3762/11350 (epoch 16.573), train_loss = 1.35382953, grad/param norm = 2.9758e-01, time/batch = 19.6228s	
3763/11350 (epoch 16.577), train_loss = 1.33709124, grad/param norm = 3.2702e-01, time/batch = 17.1734s	
3764/11350 (epoch 16.581), train_loss = 1.26573767, grad/param norm = 2.7579e-01, time/batch = 16.3547s	
3765/11350 (epoch 16.586), train_loss = 1.31409214, grad/param norm = 3.2346e-01, time/batch = 19.5379s	
3766/11350 (epoch 16.590), train_loss = 1.39004929, grad/param norm = 3.2901e-01, time/batch = 19.6789s	
3767/11350 (epoch 16.595), train_loss = 1.38495613, grad/param norm = 2.7473e-01, time/batch = 18.2902s	
3768/11350 (epoch 16.599), train_loss = 1.31110819, grad/param norm = 3.0264e-01, time/batch = 20.4420s	
3769/11350 (epoch 16.604), train_loss = 1.16204088, grad/param norm = 2.4919e-01, time/batch = 17.0262s	
3770/11350 (epoch 16.608), train_loss = 1.22249745, grad/param norm = 2.9138e-01, time/batch = 19.3682s	
3771/11350 (epoch 16.612), train_loss = 1.12224858, grad/param norm = 2.4984e-01, time/batch = 20.3627s	
3772/11350 (epoch 16.617), train_loss = 1.32978041, grad/param norm = 2.8764e-01, time/batch = 17.6978s	
3773/11350 (epoch 16.621), train_loss = 1.33272809, grad/param norm = 2.6963e-01, time/batch = 20.0461s	
3774/11350 (epoch 16.626), train_loss = 1.19618712, grad/param norm = 2.5315e-01, time/batch = 19.2153s	
3775/11350 (epoch 16.630), train_loss = 1.28018805, grad/param norm = 2.7585e-01, time/batch = 17.4508s	
3776/11350 (epoch 16.634), train_loss = 1.26064140, grad/param norm = 2.8775e-01, time/batch = 20.8688s	
3777/11350 (epoch 16.639), train_loss = 1.10827604, grad/param norm = 2.9646e-01, time/batch = 19.6226s	
3778/11350 (epoch 16.643), train_loss = 1.10083637, grad/param norm = 2.6869e-01, time/batch = 17.9503s	
3779/11350 (epoch 16.648), train_loss = 1.17359991, grad/param norm = 2.6416e-01, time/batch = 19.2663s	
3780/11350 (epoch 16.652), train_loss = 1.13481401, grad/param norm = 2.6933e-01, time/batch = 18.8759s	
3781/11350 (epoch 16.656), train_loss = 1.27695693, grad/param norm = 3.0312e-01, time/batch = 17.7762s	
3782/11350 (epoch 16.661), train_loss = 1.37886851, grad/param norm = 3.4226e-01, time/batch = 18.4586s	
3783/11350 (epoch 16.665), train_loss = 1.23375654, grad/param norm = 2.8567e-01, time/batch = 18.5498s	
3784/11350 (epoch 16.670), train_loss = 1.21603152, grad/param norm = 3.1185e-01, time/batch = 17.1014s	
3785/11350 (epoch 16.674), train_loss = 1.12616844, grad/param norm = 2.4611e-01, time/batch = 18.0216s	
3786/11350 (epoch 16.678), train_loss = 1.15932060, grad/param norm = 2.3313e-01, time/batch = 18.7944s	
3787/11350 (epoch 16.683), train_loss = 1.10596573, grad/param norm = 2.6277e-01, time/batch = 19.5390s	
3788/11350 (epoch 16.687), train_loss = 1.07989748, grad/param norm = 2.6691e-01, time/batch = 17.3696s	
3789/11350 (epoch 16.692), train_loss = 1.52255482, grad/param norm = 3.4963e-01, time/batch = 19.5481s	
3790/11350 (epoch 16.696), train_loss = 1.35214900, grad/param norm = 3.0896e-01, time/batch = 18.7843s	
3791/11350 (epoch 16.700), train_loss = 1.26655626, grad/param norm = 2.8014e-01, time/batch = 17.6306s	
3792/11350 (epoch 16.705), train_loss = 1.36907147, grad/param norm = 2.9926e-01, time/batch = 18.5364s	
3793/11350 (epoch 16.709), train_loss = 1.32473195, grad/param norm = 2.8376e-01, time/batch = 19.4606s	
3794/11350 (epoch 16.714), train_loss = 1.16730949, grad/param norm = 2.4812e-01, time/batch = 18.2739s	
3795/11350 (epoch 16.718), train_loss = 1.08150231, grad/param norm = 2.6788e-01, time/batch = 20.1161s	
3796/11350 (epoch 16.722), train_loss = 1.24797819, grad/param norm = 3.0700e-01, time/batch = 18.0527s	
3797/11350 (epoch 16.727), train_loss = 1.21229331, grad/param norm = 2.7304e-01, time/batch = 18.6893s	
3798/11350 (epoch 16.731), train_loss = 1.28684366, grad/param norm = 2.8378e-01, time/batch = 18.9976s	
3799/11350 (epoch 16.736), train_loss = 1.18348943, grad/param norm = 2.9491e-01, time/batch = 19.7896s	
3800/11350 (epoch 16.740), train_loss = 1.19429313, grad/param norm = 2.7909e-01, time/batch = 19.4295s	
3801/11350 (epoch 16.744), train_loss = 1.28567126, grad/param norm = 3.3097e-01, time/batch = 18.9252s	
3802/11350 (epoch 16.749), train_loss = 1.33836606, grad/param norm = 3.2771e-01, time/batch = 18.8008s	
3803/11350 (epoch 16.753), train_loss = 1.30651234, grad/param norm = 3.1855e-01, time/batch = 19.6968s	
3804/11350 (epoch 16.758), train_loss = 1.16637703, grad/param norm = 2.9620e-01, time/batch = 18.6100s	
3805/11350 (epoch 16.762), train_loss = 1.27097739, grad/param norm = 2.9046e-01, time/batch = 19.8782s	
3806/11350 (epoch 16.767), train_loss = 1.26844867, grad/param norm = 2.4907e-01, time/batch = 19.0272s	
3807/11350 (epoch 16.771), train_loss = 1.38151653, grad/param norm = 2.7508e-01, time/batch = 18.1078s	
3808/11350 (epoch 16.775), train_loss = 1.14365061, grad/param norm = 2.9170e-01, time/batch = 18.7806s	
3809/11350 (epoch 16.780), train_loss = 1.29462351, grad/param norm = 2.6061e-01, time/batch = 18.7017s	
3810/11350 (epoch 16.784), train_loss = 1.13532391, grad/param norm = 2.5743e-01, time/batch = 18.6125s	
3811/11350 (epoch 16.789), train_loss = 1.20333317, grad/param norm = 2.8661e-01, time/batch = 19.6906s	
3812/11350 (epoch 16.793), train_loss = 1.28077679, grad/param norm = 2.5846e-01, time/batch = 18.6363s	
3813/11350 (epoch 16.797), train_loss = 1.16540096, grad/param norm = 2.5942e-01, time/batch = 18.0995s	
3814/11350 (epoch 16.802), train_loss = 1.26545729, grad/param norm = 2.9550e-01, time/batch = 20.2898s	
3815/11350 (epoch 16.806), train_loss = 1.27283980, grad/param norm = 2.8100e-01, time/batch = 17.5540s	
3816/11350 (epoch 16.811), train_loss = 1.19350762, grad/param norm = 2.9828e-01, time/batch = 18.5176s	
3817/11350 (epoch 16.815), train_loss = 1.10355743, grad/param norm = 2.6155e-01, time/batch = 19.2952s	
3818/11350 (epoch 16.819), train_loss = 1.09482354, grad/param norm = 2.7792e-01, time/batch = 17.3000s	
3819/11350 (epoch 16.824), train_loss = 1.13707447, grad/param norm = 3.1524e-01, time/batch = 19.3595s	
3820/11350 (epoch 16.828), train_loss = 1.19762381, grad/param norm = 3.0716e-01, time/batch = 16.0183s	
3821/11350 (epoch 16.833), train_loss = 1.20876415, grad/param norm = 2.8209e-01, time/batch = 15.2878s	
3822/11350 (epoch 16.837), train_loss = 1.20593048, grad/param norm = 2.6186e-01, time/batch = 18.3871s	
3823/11350 (epoch 16.841), train_loss = 1.46976888, grad/param norm = 3.1201e-01, time/batch = 18.4390s	
3824/11350 (epoch 16.846), train_loss = 1.20402602, grad/param norm = 2.6471e-01, time/batch = 19.7909s	
3825/11350 (epoch 16.850), train_loss = 1.31220916, grad/param norm = 3.0432e-01, time/batch = 17.9382s	
3826/11350 (epoch 16.855), train_loss = 1.06173681, grad/param norm = 2.8009e-01, time/batch = 18.1013s	
3827/11350 (epoch 16.859), train_loss = 1.20747493, grad/param norm = 3.0926e-01, time/batch = 19.6961s	
3828/11350 (epoch 16.863), train_loss = 1.06190227, grad/param norm = 2.5965e-01, time/batch = 20.6165s	
3829/11350 (epoch 16.868), train_loss = 1.15306674, grad/param norm = 2.6528e-01, time/batch = 18.2826s	
3830/11350 (epoch 16.872), train_loss = 1.16383853, grad/param norm = 2.8165e-01, time/batch = 19.9553s	
3831/11350 (epoch 16.877), train_loss = 1.18740192, grad/param norm = 2.8941e-01, time/batch = 18.5366s	
3832/11350 (epoch 16.881), train_loss = 1.40655946, grad/param norm = 2.9838e-01, time/batch = 18.0333s	
3833/11350 (epoch 16.885), train_loss = 1.39733330, grad/param norm = 2.7724e-01, time/batch = 18.7056s	
3834/11350 (epoch 16.890), train_loss = 1.28592683, grad/param norm = 2.8429e-01, time/batch = 18.8529s	
3835/11350 (epoch 16.894), train_loss = 1.04087933, grad/param norm = 2.8069e-01, time/batch = 19.2007s	
3836/11350 (epoch 16.899), train_loss = 1.29534116, grad/param norm = 2.8631e-01, time/batch = 17.4425s	
3837/11350 (epoch 16.903), train_loss = 1.29498522, grad/param norm = 2.6885e-01, time/batch = 17.1174s	
3838/11350 (epoch 16.907), train_loss = 1.25630751, grad/param norm = 2.6684e-01, time/batch = 20.0555s	
3839/11350 (epoch 16.912), train_loss = 1.15361987, grad/param norm = 2.6179e-01, time/batch = 18.1052s	
3840/11350 (epoch 16.916), train_loss = 1.31055591, grad/param norm = 2.9211e-01, time/batch = 19.4659s	
3841/11350 (epoch 16.921), train_loss = 1.27344587, grad/param norm = 2.8976e-01, time/batch = 17.3635s	
3842/11350 (epoch 16.925), train_loss = 1.06947273, grad/param norm = 2.3168e-01, time/batch = 18.1097s	
3843/11350 (epoch 16.930), train_loss = 1.30417961, grad/param norm = 2.9253e-01, time/batch = 18.8847s	
3844/11350 (epoch 16.934), train_loss = 1.38290520, grad/param norm = 2.9504e-01, time/batch = 20.6995s	
3845/11350 (epoch 16.938), train_loss = 1.17136430, grad/param norm = 2.6214e-01, time/batch = 17.9243s	
3846/11350 (epoch 16.943), train_loss = 1.33318684, grad/param norm = 2.8858e-01, time/batch = 20.7875s	
3847/11350 (epoch 16.947), train_loss = 1.31338863, grad/param norm = 3.2193e-01, time/batch = 19.5322s	
3848/11350 (epoch 16.952), train_loss = 1.28091673, grad/param norm = 2.8314e-01, time/batch = 18.1827s	
3849/11350 (epoch 16.956), train_loss = 1.01273561, grad/param norm = 2.6238e-01, time/batch = 19.8561s	
3850/11350 (epoch 16.960), train_loss = 1.18554422, grad/param norm = 2.8313e-01, time/batch = 19.2110s	
3851/11350 (epoch 16.965), train_loss = 1.10108073, grad/param norm = 2.7950e-01, time/batch = 18.0236s	
3852/11350 (epoch 16.969), train_loss = 1.12550315, grad/param norm = 3.5474e-01, time/batch = 17.6098s	
3853/11350 (epoch 16.974), train_loss = 1.03155554, grad/param norm = 2.5583e-01, time/batch = 20.6083s	
3854/11350 (epoch 16.978), train_loss = 1.19651220, grad/param norm = 2.6119e-01, time/batch = 19.8600s	
3855/11350 (epoch 16.982), train_loss = 0.95158714, grad/param norm = 2.5992e-01, time/batch = 20.2876s	
3856/11350 (epoch 16.987), train_loss = 1.20394856, grad/param norm = 2.8776e-01, time/batch = 19.8554s	
3857/11350 (epoch 16.991), train_loss = 1.06260703, grad/param norm = 2.8853e-01, time/batch = 19.6249s	
3858/11350 (epoch 16.996), train_loss = 1.23216335, grad/param norm = 2.9486e-01, time/batch = 19.6939s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
3859/11350 (epoch 17.000), train_loss = 0.94803479, grad/param norm = 2.9906e-01, time/batch = 19.1134s	
3860/11350 (epoch 17.004), train_loss = 1.20052751, grad/param norm = 2.9665e-01, time/batch = 19.9199s	
3861/11350 (epoch 17.009), train_loss = 1.20688879, grad/param norm = 2.8651e-01, time/batch = 18.0279s	
3862/11350 (epoch 17.013), train_loss = 0.83109963, grad/param norm = 2.4922e-01, time/batch = 19.8617s	
3863/11350 (epoch 17.018), train_loss = 0.89569959, grad/param norm = 2.4025e-01, time/batch = 20.7853s	
3864/11350 (epoch 17.022), train_loss = 0.92622541, grad/param norm = 2.5761e-01, time/batch = 9.9179s	
3865/11350 (epoch 17.026), train_loss = 0.97353488, grad/param norm = 2.7129e-01, time/batch = 0.7446s	
3866/11350 (epoch 17.031), train_loss = 0.95737696, grad/param norm = 2.6389e-01, time/batch = 0.7160s	
3867/11350 (epoch 17.035), train_loss = 1.02915676, grad/param norm = 2.7307e-01, time/batch = 0.7114s	
3868/11350 (epoch 17.040), train_loss = 1.02530759, grad/param norm = 2.5982e-01, time/batch = 0.7110s	
3869/11350 (epoch 17.044), train_loss = 0.98532034, grad/param norm = 2.4112e-01, time/batch = 0.6984s	
3870/11350 (epoch 17.048), train_loss = 0.94554996, grad/param norm = 2.4517e-01, time/batch = 0.8309s	
3871/11350 (epoch 17.053), train_loss = 1.07454275, grad/param norm = 2.8159e-01, time/batch = 1.0044s	
3872/11350 (epoch 17.057), train_loss = 1.10865112, grad/param norm = 2.7727e-01, time/batch = 1.0052s	
3873/11350 (epoch 17.062), train_loss = 0.91166728, grad/param norm = 2.5309e-01, time/batch = 1.0149s	
3874/11350 (epoch 17.066), train_loss = 0.90494459, grad/param norm = 2.6115e-01, time/batch = 1.0038s	
3875/11350 (epoch 17.070), train_loss = 1.01460841, grad/param norm = 2.4098e-01, time/batch = 1.4204s	
3876/11350 (epoch 17.075), train_loss = 0.89435652, grad/param norm = 2.3156e-01, time/batch = 1.8919s	
3877/11350 (epoch 17.079), train_loss = 1.05864571, grad/param norm = 2.6390e-01, time/batch = 1.8824s	
3878/11350 (epoch 17.084), train_loss = 1.23639379, grad/param norm = 2.7602e-01, time/batch = 16.6431s	
3879/11350 (epoch 17.088), train_loss = 1.20006086, grad/param norm = 3.1411e-01, time/batch = 20.1106s	
3880/11350 (epoch 17.093), train_loss = 1.13633379, grad/param norm = 2.7766e-01, time/batch = 19.3681s	
3881/11350 (epoch 17.097), train_loss = 1.07483575, grad/param norm = 2.6219e-01, time/batch = 19.8683s	
3882/11350 (epoch 17.101), train_loss = 0.96062692, grad/param norm = 2.6019e-01, time/batch = 19.7826s	
3883/11350 (epoch 17.106), train_loss = 1.15564272, grad/param norm = 2.4691e-01, time/batch = 17.7658s	
3884/11350 (epoch 17.110), train_loss = 1.04057606, grad/param norm = 3.2321e-01, time/batch = 18.0217s	
3885/11350 (epoch 17.115), train_loss = 1.01186088, grad/param norm = 2.7458e-01, time/batch = 20.2909s	
3886/11350 (epoch 17.119), train_loss = 1.17850174, grad/param norm = 2.6889e-01, time/batch = 19.3526s	
3887/11350 (epoch 17.123), train_loss = 0.97701242, grad/param norm = 3.0774e-01, time/batch = 18.8670s	
3888/11350 (epoch 17.128), train_loss = 0.98648643, grad/param norm = 3.1670e-01, time/batch = 20.3538s	
3889/11350 (epoch 17.132), train_loss = 1.04731625, grad/param norm = 2.8073e-01, time/batch = 16.8499s	
3890/11350 (epoch 17.137), train_loss = 0.98979199, grad/param norm = 2.6163e-01, time/batch = 18.7235s	
3891/11350 (epoch 17.141), train_loss = 1.23632183, grad/param norm = 3.2488e-01, time/batch = 20.2846s	
3892/11350 (epoch 17.145), train_loss = 0.99407128, grad/param norm = 2.5712e-01, time/batch = 18.5324s	
3893/11350 (epoch 17.150), train_loss = 1.14031365, grad/param norm = 3.5298e-01, time/batch = 18.5152s	
3894/11350 (epoch 17.154), train_loss = 1.26440352, grad/param norm = 2.8719e-01, time/batch = 19.0456s	
3895/11350 (epoch 17.159), train_loss = 0.93143762, grad/param norm = 2.9119e-01, time/batch = 18.4505s	
3896/11350 (epoch 17.163), train_loss = 1.17716648, grad/param norm = 3.1818e-01, time/batch = 18.5260s	
3897/11350 (epoch 17.167), train_loss = 1.20231071, grad/param norm = 2.8765e-01, time/batch = 17.9679s	
3898/11350 (epoch 17.172), train_loss = 1.33563798, grad/param norm = 2.8036e-01, time/batch = 18.3854s	
3899/11350 (epoch 17.176), train_loss = 1.15187875, grad/param norm = 3.0405e-01, time/batch = 18.0459s	
3900/11350 (epoch 17.181), train_loss = 1.14889000, grad/param norm = 3.3453e-01, time/batch = 18.8846s	
3901/11350 (epoch 17.185), train_loss = 0.97896798, grad/param norm = 3.0965e-01, time/batch = 16.3586s	
3902/11350 (epoch 17.189), train_loss = 1.04227373, grad/param norm = 2.5222e-01, time/batch = 17.2140s	
3903/11350 (epoch 17.194), train_loss = 0.99706553, grad/param norm = 2.9188e-01, time/batch = 18.8791s	
3904/11350 (epoch 17.198), train_loss = 0.97498097, grad/param norm = 3.2375e-01, time/batch = 18.8023s	
3905/11350 (epoch 17.203), train_loss = 0.97369919, grad/param norm = 2.6655e-01, time/batch = 17.1970s	
3906/11350 (epoch 17.207), train_loss = 0.96316582, grad/param norm = 3.2993e-01, time/batch = 17.9593s	
3907/11350 (epoch 17.211), train_loss = 1.15739709, grad/param norm = 3.1666e-01, time/batch = 19.5327s	
3908/11350 (epoch 17.216), train_loss = 1.11873462, grad/param norm = 3.0333e-01, time/batch = 17.7997s	
3909/11350 (epoch 17.220), train_loss = 1.09835819, grad/param norm = 2.5734e-01, time/batch = 18.1981s	
3910/11350 (epoch 17.225), train_loss = 0.99132343, grad/param norm = 2.6994e-01, time/batch = 14.8984s	
3911/11350 (epoch 17.229), train_loss = 1.14856930, grad/param norm = 2.8651e-01, time/batch = 18.8803s	
3912/11350 (epoch 17.233), train_loss = 1.10580779, grad/param norm = 2.7637e-01, time/batch = 18.1963s	
3913/11350 (epoch 17.238), train_loss = 1.25016001, grad/param norm = 3.5372e-01, time/batch = 18.3855s	
3914/11350 (epoch 17.242), train_loss = 1.23331596, grad/param norm = 3.1698e-01, time/batch = 20.9453s	
3915/11350 (epoch 17.247), train_loss = 0.90507380, grad/param norm = 2.6136e-01, time/batch = 17.8648s	
3916/11350 (epoch 17.251), train_loss = 1.14210690, grad/param norm = 3.1187e-01, time/batch = 20.2208s	
3917/11350 (epoch 17.256), train_loss = 1.14102404, grad/param norm = 2.9489e-01, time/batch = 18.2803s	
3918/11350 (epoch 17.260), train_loss = 1.00786644, grad/param norm = 2.6452e-01, time/batch = 17.2761s	
3919/11350 (epoch 17.264), train_loss = 1.03551231, grad/param norm = 2.6127e-01, time/batch = 18.2628s	
3920/11350 (epoch 17.269), train_loss = 1.08917160, grad/param norm = 2.6375e-01, time/batch = 17.4530s	
3921/11350 (epoch 17.273), train_loss = 1.16974377, grad/param norm = 2.7612e-01, time/batch = 19.6968s	
3922/11350 (epoch 17.278), train_loss = 0.96740759, grad/param norm = 2.4813e-01, time/batch = 18.3579s	
3923/11350 (epoch 17.282), train_loss = 1.11121148, grad/param norm = 2.8883e-01, time/batch = 19.8611s	
3924/11350 (epoch 17.286), train_loss = 1.20442429, grad/param norm = 2.7824e-01, time/batch = 20.1101s	
3925/11350 (epoch 17.291), train_loss = 0.95288523, grad/param norm = 3.2015e-01, time/batch = 18.5366s	
3926/11350 (epoch 17.295), train_loss = 1.11561249, grad/param norm = 2.9442e-01, time/batch = 19.1447s	
3927/11350 (epoch 17.300), train_loss = 1.09409056, grad/param norm = 2.6567e-01, time/batch = 19.6959s	
3928/11350 (epoch 17.304), train_loss = 1.01403131, grad/param norm = 2.5251e-01, time/batch = 19.4450s	
3929/11350 (epoch 17.308), train_loss = 1.02368997, grad/param norm = 2.6503e-01, time/batch = 19.1189s	
3930/11350 (epoch 17.313), train_loss = 1.15564143, grad/param norm = 2.6721e-01, time/batch = 20.5403s	
3931/11350 (epoch 17.317), train_loss = 0.99145576, grad/param norm = 2.3892e-01, time/batch = 17.3414s	
3932/11350 (epoch 17.322), train_loss = 1.02280484, grad/param norm = 2.5049e-01, time/batch = 18.2912s	
3933/11350 (epoch 17.326), train_loss = 1.07882738, grad/param norm = 2.4731e-01, time/batch = 20.3788s	
3934/11350 (epoch 17.330), train_loss = 0.88487614, grad/param norm = 2.4890e-01, time/batch = 18.4527s	
3935/11350 (epoch 17.335), train_loss = 0.80818517, grad/param norm = 2.4764e-01, time/batch = 19.6369s	
3936/11350 (epoch 17.339), train_loss = 0.91559872, grad/param norm = 2.5850e-01, time/batch = 18.0361s	
3937/11350 (epoch 17.344), train_loss = 0.99456831, grad/param norm = 2.3135e-01, time/batch = 16.9990s	
3938/11350 (epoch 17.348), train_loss = 1.01100108, grad/param norm = 2.5326e-01, time/batch = 18.1976s	
3939/11350 (epoch 17.352), train_loss = 0.91252739, grad/param norm = 2.3995e-01, time/batch = 16.8062s	
3940/11350 (epoch 17.357), train_loss = 0.98280851, grad/param norm = 2.5937e-01, time/batch = 19.1980s	
3941/11350 (epoch 17.361), train_loss = 0.81270386, grad/param norm = 2.2535e-01, time/batch = 18.9486s	
3942/11350 (epoch 17.366), train_loss = 1.12843941, grad/param norm = 2.8915e-01, time/batch = 15.5454s	
3943/11350 (epoch 17.370), train_loss = 0.97857422, grad/param norm = 2.7000e-01, time/batch = 17.3972s	
3944/11350 (epoch 17.374), train_loss = 1.00200332, grad/param norm = 2.7059e-01, time/batch = 17.2134s	
3945/11350 (epoch 17.379), train_loss = 1.02729386, grad/param norm = 2.5642e-01, time/batch = 17.7606s	
3946/11350 (epoch 17.383), train_loss = 0.89129834, grad/param norm = 2.2295e-01, time/batch = 19.0527s	
3947/11350 (epoch 17.388), train_loss = 1.07534772, grad/param norm = 3.1705e-01, time/batch = 17.8676s	
3948/11350 (epoch 17.392), train_loss = 1.02544979, grad/param norm = 2.8271e-01, time/batch = 19.2959s	
3949/11350 (epoch 17.396), train_loss = 1.09318828, grad/param norm = 2.9886e-01, time/batch = 18.1210s	
3950/11350 (epoch 17.401), train_loss = 1.06143968, grad/param norm = 2.9000e-01, time/batch = 17.5399s	
3951/11350 (epoch 17.405), train_loss = 1.22609580, grad/param norm = 2.9259e-01, time/batch = 19.2156s	
3952/11350 (epoch 17.410), train_loss = 1.25146048, grad/param norm = 3.1015e-01, time/batch = 18.7994s	
3953/11350 (epoch 17.414), train_loss = 0.91353493, grad/param norm = 2.7584e-01, time/batch = 17.2928s	
3954/11350 (epoch 17.419), train_loss = 0.99364487, grad/param norm = 2.9147e-01, time/batch = 17.9327s	
3955/11350 (epoch 17.423), train_loss = 1.12304970, grad/param norm = 2.5353e-01, time/batch = 18.4730s	
3956/11350 (epoch 17.427), train_loss = 1.18493279, grad/param norm = 2.7018e-01, time/batch = 19.2891s	
3957/11350 (epoch 17.432), train_loss = 1.14846437, grad/param norm = 3.1336e-01, time/batch = 17.6996s	
3958/11350 (epoch 17.436), train_loss = 1.05045388, grad/param norm = 2.9896e-01, time/batch = 20.2116s	
3959/11350 (epoch 17.441), train_loss = 1.27904252, grad/param norm = 3.3683e-01, time/batch = 17.7861s	
3960/11350 (epoch 17.445), train_loss = 0.87890916, grad/param norm = 2.1910e-01, time/batch = 17.5225s	
3961/11350 (epoch 17.449), train_loss = 1.02404247, grad/param norm = 2.9376e-01, time/batch = 17.9560s	
3962/11350 (epoch 17.454), train_loss = 1.20152863, grad/param norm = 2.7998e-01, time/batch = 20.2825s	
3963/11350 (epoch 17.458), train_loss = 0.87331910, grad/param norm = 2.4077e-01, time/batch = 16.6726s	
3964/11350 (epoch 17.463), train_loss = 0.93772732, grad/param norm = 2.4494e-01, time/batch = 18.8627s	
3965/11350 (epoch 17.467), train_loss = 1.36436320, grad/param norm = 2.9729e-01, time/batch = 20.5299s	
3966/11350 (epoch 17.471), train_loss = 1.21650015, grad/param norm = 3.0611e-01, time/batch = 19.7079s	
3967/11350 (epoch 17.476), train_loss = 1.15207703, grad/param norm = 2.5758e-01, time/batch = 18.9638s	
3968/11350 (epoch 17.480), train_loss = 1.25981119, grad/param norm = 2.7151e-01, time/batch = 20.2915s	
3969/11350 (epoch 17.485), train_loss = 1.05932002, grad/param norm = 2.7658e-01, time/batch = 19.2786s	
3970/11350 (epoch 17.489), train_loss = 1.22822013, grad/param norm = 3.1309e-01, time/batch = 18.5279s	
3971/11350 (epoch 17.493), train_loss = 1.19989204, grad/param norm = 3.0075e-01, time/batch = 19.8823s	
3972/11350 (epoch 17.498), train_loss = 0.86354882, grad/param norm = 2.6251e-01, time/batch = 20.1858s	
3973/11350 (epoch 17.502), train_loss = 1.15208394, grad/param norm = 2.8047e-01, time/batch = 19.5072s	
3974/11350 (epoch 17.507), train_loss = 0.94722947, grad/param norm = 3.2419e-01, time/batch = 18.7063s	
3975/11350 (epoch 17.511), train_loss = 1.26564099, grad/param norm = 2.9840e-01, time/batch = 18.6298s	
3976/11350 (epoch 17.515), train_loss = 1.09552889, grad/param norm = 2.6653e-01, time/batch = 18.1188s	
3977/11350 (epoch 17.520), train_loss = 1.26297247, grad/param norm = 3.2077e-01, time/batch = 16.6106s	
3978/11350 (epoch 17.524), train_loss = 1.09807866, grad/param norm = 2.7434e-01, time/batch = 20.6865s	
3979/11350 (epoch 17.529), train_loss = 1.07361473, grad/param norm = 2.4813e-01, time/batch = 18.6946s	
3980/11350 (epoch 17.533), train_loss = 1.32315453, grad/param norm = 2.7153e-01, time/batch = 20.2945s	
3981/11350 (epoch 17.537), train_loss = 1.16750767, grad/param norm = 2.6690e-01, time/batch = 18.6286s	
3982/11350 (epoch 17.542), train_loss = 1.18301440, grad/param norm = 2.4487e-01, time/batch = 18.1099s	
3983/11350 (epoch 17.546), train_loss = 1.39092706, grad/param norm = 3.0580e-01, time/batch = 19.7878s	
3984/11350 (epoch 17.551), train_loss = 1.13103424, grad/param norm = 2.6261e-01, time/batch = 17.9774s	
3985/11350 (epoch 17.555), train_loss = 1.06416535, grad/param norm = 2.9688e-01, time/batch = 17.9301s	
3986/11350 (epoch 17.559), train_loss = 1.06169571, grad/param norm = 2.7519e-01, time/batch = 19.1893s	
3987/11350 (epoch 17.564), train_loss = 1.21710231, grad/param norm = 2.7278e-01, time/batch = 19.2855s	
3988/11350 (epoch 17.568), train_loss = 1.17544791, grad/param norm = 2.5607e-01, time/batch = 17.0282s	
3989/11350 (epoch 17.573), train_loss = 1.31124194, grad/param norm = 3.7111e-01, time/batch = 18.2711s	
3990/11350 (epoch 17.577), train_loss = 1.27513754, grad/param norm = 3.3098e-01, time/batch = 19.7121s	
3991/11350 (epoch 17.581), train_loss = 1.22628997, grad/param norm = 2.7492e-01, time/batch = 19.2149s	
3992/11350 (epoch 17.586), train_loss = 1.25905046, grad/param norm = 3.1626e-01, time/batch = 19.6752s	
3993/11350 (epoch 17.590), train_loss = 1.36078925, grad/param norm = 3.4399e-01, time/batch = 19.3530s	
3994/11350 (epoch 17.595), train_loss = 1.34293108, grad/param norm = 2.6762e-01, time/batch = 20.0375s	
3995/11350 (epoch 17.599), train_loss = 1.25151846, grad/param norm = 2.8240e-01, time/batch = 20.8455s	
3996/11350 (epoch 17.604), train_loss = 1.13428718, grad/param norm = 2.5975e-01, time/batch = 19.6246s	
3997/11350 (epoch 17.608), train_loss = 1.18278634, grad/param norm = 3.3644e-01, time/batch = 16.7584s	
3998/11350 (epoch 17.612), train_loss = 1.08809272, grad/param norm = 2.5506e-01, time/batch = 17.5836s	
3999/11350 (epoch 17.617), train_loss = 1.27840985, grad/param norm = 3.1885e-01, time/batch = 20.1159s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch17.62_1.7764.t7	
4000/11350 (epoch 17.621), train_loss = 1.28747589, grad/param norm = 2.6837e-01, time/batch = 18.6920s	
4001/11350 (epoch 17.626), train_loss = 1.43793991, grad/param norm = 3.2402e-01, time/batch = 19.1151s	
4002/11350 (epoch 17.630), train_loss = 1.25169807, grad/param norm = 3.2383e-01, time/batch = 18.7893s	
4003/11350 (epoch 17.634), train_loss = 1.22028082, grad/param norm = 3.2662e-01, time/batch = 17.9808s	
4004/11350 (epoch 17.639), train_loss = 1.06801376, grad/param norm = 2.6870e-01, time/batch = 15.1345s	
4005/11350 (epoch 17.643), train_loss = 1.06387849, grad/param norm = 2.7067e-01, time/batch = 18.7843s	
4006/11350 (epoch 17.648), train_loss = 1.14419347, grad/param norm = 2.6553e-01, time/batch = 18.4625s	
4007/11350 (epoch 17.652), train_loss = 1.09430875, grad/param norm = 2.8080e-01, time/batch = 19.7805s	
4008/11350 (epoch 17.656), train_loss = 1.23029138, grad/param norm = 3.0339e-01, time/batch = 17.8824s	
4009/11350 (epoch 17.661), train_loss = 1.31647177, grad/param norm = 3.0235e-01, time/batch = 19.9583s	
4010/11350 (epoch 17.665), train_loss = 1.19341725, grad/param norm = 2.9279e-01, time/batch = 19.3783s	
4011/11350 (epoch 17.670), train_loss = 1.17099800, grad/param norm = 2.9784e-01, time/batch = 19.4414s	
4012/11350 (epoch 17.674), train_loss = 1.08444665, grad/param norm = 2.4842e-01, time/batch = 20.1183s	
4013/11350 (epoch 17.678), train_loss = 1.12609220, grad/param norm = 2.4186e-01, time/batch = 19.2005s	
4014/11350 (epoch 17.683), train_loss = 1.06636085, grad/param norm = 2.9959e-01, time/batch = 18.1759s	
4015/11350 (epoch 17.687), train_loss = 1.05119192, grad/param norm = 2.8628e-01, time/batch = 15.9310s	
4016/11350 (epoch 17.692), train_loss = 1.47704841, grad/param norm = 3.6690e-01, time/batch = 18.2115s	
4017/11350 (epoch 17.696), train_loss = 1.29836303, grad/param norm = 3.1232e-01, time/batch = 16.1917s	
4018/11350 (epoch 17.700), train_loss = 1.23412596, grad/param norm = 3.1510e-01, time/batch = 17.6094s	
4019/11350 (epoch 17.705), train_loss = 1.32804719, grad/param norm = 3.1044e-01, time/batch = 19.5395s	
4020/11350 (epoch 17.709), train_loss = 1.28533052, grad/param norm = 3.1673e-01, time/batch = 17.9704s	
4021/11350 (epoch 17.714), train_loss = 1.13796696, grad/param norm = 2.6278e-01, time/batch = 17.7769s	
4022/11350 (epoch 17.718), train_loss = 1.04234961, grad/param norm = 2.9509e-01, time/batch = 19.5405s	
4023/11350 (epoch 17.722), train_loss = 1.21455931, grad/param norm = 3.3328e-01, time/batch = 19.3758s	
4024/11350 (epoch 17.727), train_loss = 1.17332545, grad/param norm = 2.9025e-01, time/batch = 18.0313s	
4025/11350 (epoch 17.731), train_loss = 1.24457103, grad/param norm = 3.0352e-01, time/batch = 16.7670s	
4026/11350 (epoch 17.736), train_loss = 1.16049135, grad/param norm = 3.3403e-01, time/batch = 16.8648s	
4027/11350 (epoch 17.740), train_loss = 1.15252930, grad/param norm = 3.0824e-01, time/batch = 19.5467s	
4028/11350 (epoch 17.744), train_loss = 1.23962801, grad/param norm = 3.2796e-01, time/batch = 18.7028s	
4029/11350 (epoch 17.749), train_loss = 1.27795574, grad/param norm = 2.9265e-01, time/batch = 19.5551s	
4030/11350 (epoch 17.753), train_loss = 1.25992225, grad/param norm = 3.0714e-01, time/batch = 19.2984s	
4031/11350 (epoch 17.758), train_loss = 1.11255397, grad/param norm = 2.7183e-01, time/batch = 16.5431s	
4032/11350 (epoch 17.762), train_loss = 1.22849804, grad/param norm = 3.0091e-01, time/batch = 18.8763s	
4033/11350 (epoch 17.767), train_loss = 1.22813333, grad/param norm = 2.4982e-01, time/batch = 19.7092s	
4034/11350 (epoch 17.771), train_loss = 1.34952331, grad/param norm = 2.8468e-01, time/batch = 17.7879s	
4035/11350 (epoch 17.775), train_loss = 1.09962176, grad/param norm = 2.6844e-01, time/batch = 19.5267s	
4036/11350 (epoch 17.780), train_loss = 1.24338602, grad/param norm = 2.6487e-01, time/batch = 18.6202s	
4037/11350 (epoch 17.784), train_loss = 1.10104610, grad/param norm = 2.7198e-01, time/batch = 19.1282s	
4038/11350 (epoch 17.789), train_loss = 1.16646915, grad/param norm = 2.9265e-01, time/batch = 19.4563s	
4039/11350 (epoch 17.793), train_loss = 1.24902283, grad/param norm = 2.5902e-01, time/batch = 18.9437s	
4040/11350 (epoch 17.797), train_loss = 1.13090164, grad/param norm = 2.6176e-01, time/batch = 18.9645s	
4041/11350 (epoch 17.802), train_loss = 1.22409828, grad/param norm = 2.8607e-01, time/batch = 19.0382s	
4042/11350 (epoch 17.806), train_loss = 1.23405155, grad/param norm = 2.6782e-01, time/batch = 19.7148s	
4043/11350 (epoch 17.811), train_loss = 1.16184480, grad/param norm = 2.7918e-01, time/batch = 17.5162s	
4044/11350 (epoch 17.815), train_loss = 1.07598223, grad/param norm = 2.5285e-01, time/batch = 19.2926s	
4045/11350 (epoch 17.819), train_loss = 1.06669232, grad/param norm = 2.6198e-01, time/batch = 19.0527s	
4046/11350 (epoch 17.824), train_loss = 1.08269508, grad/param norm = 3.0193e-01, time/batch = 15.5550s	
4047/11350 (epoch 17.828), train_loss = 1.15361641, grad/param norm = 3.0472e-01, time/batch = 17.4133s	
4048/11350 (epoch 17.833), train_loss = 1.16825193, grad/param norm = 2.8195e-01, time/batch = 19.3986s	
4049/11350 (epoch 17.837), train_loss = 1.17601045, grad/param norm = 2.8805e-01, time/batch = 19.9520s	
4050/11350 (epoch 17.841), train_loss = 1.41246866, grad/param norm = 3.0966e-01, time/batch = 17.6137s	
4051/11350 (epoch 17.846), train_loss = 1.17184340, grad/param norm = 2.6735e-01, time/batch = 18.8829s	
4052/11350 (epoch 17.850), train_loss = 1.25949308, grad/param norm = 3.2122e-01, time/batch = 19.0344s	
4053/11350 (epoch 17.855), train_loss = 1.03031678, grad/param norm = 2.9083e-01, time/batch = 18.6096s	
4054/11350 (epoch 17.859), train_loss = 1.15963092, grad/param norm = 3.0127e-01, time/batch = 18.1413s	
4055/11350 (epoch 17.863), train_loss = 1.02455972, grad/param norm = 2.8141e-01, time/batch = 15.8794s	
4056/11350 (epoch 17.868), train_loss = 1.11183328, grad/param norm = 2.6627e-01, time/batch = 18.3803s	
4057/11350 (epoch 17.872), train_loss = 1.12768169, grad/param norm = 2.6251e-01, time/batch = 17.2795s	
4058/11350 (epoch 17.877), train_loss = 1.16186859, grad/param norm = 3.0676e-01, time/batch = 19.2143s	
4059/11350 (epoch 17.881), train_loss = 1.36273844, grad/param norm = 3.2668e-01, time/batch = 17.5981s	
4060/11350 (epoch 17.885), train_loss = 1.36320776, grad/param norm = 2.9060e-01, time/batch = 17.0435s	
4061/11350 (epoch 17.890), train_loss = 1.24800785, grad/param norm = 2.8990e-01, time/batch = 16.6465s	
4062/11350 (epoch 17.894), train_loss = 1.00504144, grad/param norm = 3.0012e-01, time/batch = 16.0612s	
4063/11350 (epoch 17.899), train_loss = 1.25891170, grad/param norm = 3.0342e-01, time/batch = 17.9547s	
4064/11350 (epoch 17.903), train_loss = 1.24460561, grad/param norm = 2.8618e-01, time/batch = 18.9522s	
4065/11350 (epoch 17.907), train_loss = 1.20104001, grad/param norm = 2.6696e-01, time/batch = 17.6358s	
4066/11350 (epoch 17.912), train_loss = 1.10023191, grad/param norm = 2.4911e-01, time/batch = 19.2089s	
4067/11350 (epoch 17.916), train_loss = 1.27680121, grad/param norm = 3.2953e-01, time/batch = 34.3588s	
4068/11350 (epoch 17.921), train_loss = 1.23749823, grad/param norm = 2.8143e-01, time/batch = 17.0383s	
4069/11350 (epoch 17.925), train_loss = 1.03521869, grad/param norm = 2.5503e-01, time/batch = 16.6949s	
4070/11350 (epoch 17.930), train_loss = 1.29065088, grad/param norm = 3.6451e-01, time/batch = 19.7964s	
4071/11350 (epoch 17.934), train_loss = 1.34563095, grad/param norm = 2.7255e-01, time/batch = 19.0375s	
4072/11350 (epoch 17.938), train_loss = 1.13914717, grad/param norm = 2.7609e-01, time/batch = 17.7009s	
4073/11350 (epoch 17.943), train_loss = 1.27877016, grad/param norm = 2.8367e-01, time/batch = 17.9492s	
4074/11350 (epoch 17.947), train_loss = 1.26985833, grad/param norm = 3.2044e-01, time/batch = 18.8753s	
4075/11350 (epoch 17.952), train_loss = 1.25254419, grad/param norm = 3.0540e-01, time/batch = 18.7941s	
4076/11350 (epoch 17.956), train_loss = 0.98593117, grad/param norm = 2.5590e-01, time/batch = 18.6227s	
4077/11350 (epoch 17.960), train_loss = 1.14851065, grad/param norm = 3.0945e-01, time/batch = 19.0388s	
4078/11350 (epoch 17.965), train_loss = 1.05874290, grad/param norm = 2.7441e-01, time/batch = 19.8795s	
4079/11350 (epoch 17.969), train_loss = 1.08517680, grad/param norm = 3.2772e-01, time/batch = 17.4262s	
4080/11350 (epoch 17.974), train_loss = 0.99067956, grad/param norm = 2.6365e-01, time/batch = 19.3040s	
4081/11350 (epoch 17.978), train_loss = 1.14671654, grad/param norm = 2.7352e-01, time/batch = 19.6453s	
4082/11350 (epoch 17.982), train_loss = 0.91338282, grad/param norm = 2.5886e-01, time/batch = 17.6114s	
4083/11350 (epoch 17.987), train_loss = 1.15545800, grad/param norm = 2.9174e-01, time/batch = 19.0496s	
4084/11350 (epoch 17.991), train_loss = 1.02944977, grad/param norm = 3.1952e-01, time/batch = 17.6230s	
4085/11350 (epoch 17.996), train_loss = 1.19727119, grad/param norm = 3.4640e-01, time/batch = 16.1030s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
4086/11350 (epoch 18.000), train_loss = 0.92236960, grad/param norm = 2.9471e-01, time/batch = 18.5422s	
4087/11350 (epoch 18.004), train_loss = 1.16224362, grad/param norm = 2.9291e-01, time/batch = 17.3929s	
4088/11350 (epoch 18.009), train_loss = 1.15598432, grad/param norm = 2.7625e-01, time/batch = 19.6057s	
4089/11350 (epoch 18.013), train_loss = 0.80459749, grad/param norm = 2.4212e-01, time/batch = 18.9603s	
4090/11350 (epoch 18.018), train_loss = 0.87322743, grad/param norm = 2.4601e-01, time/batch = 19.4597s	
4091/11350 (epoch 18.022), train_loss = 0.88962408, grad/param norm = 3.0151e-01, time/batch = 20.0189s	
4092/11350 (epoch 18.026), train_loss = 0.94105917, grad/param norm = 2.9486e-01, time/batch = 19.9470s	
4093/11350 (epoch 18.031), train_loss = 0.93580680, grad/param norm = 2.8136e-01, time/batch = 18.5268s	
4094/11350 (epoch 18.035), train_loss = 0.98951635, grad/param norm = 2.8158e-01, time/batch = 19.0767s	
4095/11350 (epoch 18.040), train_loss = 0.99155927, grad/param norm = 2.5908e-01, time/batch = 17.7724s	
4096/11350 (epoch 18.044), train_loss = 0.96048511, grad/param norm = 2.4091e-01, time/batch = 19.7933s	
4097/11350 (epoch 18.048), train_loss = 0.92847338, grad/param norm = 2.7988e-01, time/batch = 19.5501s	
4098/11350 (epoch 18.053), train_loss = 1.04558083, grad/param norm = 2.7274e-01, time/batch = 17.3738s	
4099/11350 (epoch 18.057), train_loss = 1.06316507, grad/param norm = 2.6796e-01, time/batch = 18.8600s	
4100/11350 (epoch 18.062), train_loss = 0.87869687, grad/param norm = 2.4589e-01, time/batch = 16.1951s	
4101/11350 (epoch 18.066), train_loss = 0.87540029, grad/param norm = 2.7455e-01, time/batch = 17.5465s	
4102/11350 (epoch 18.070), train_loss = 0.98385184, grad/param norm = 2.5664e-01, time/batch = 16.1110s	
4103/11350 (epoch 18.075), train_loss = 0.86226313, grad/param norm = 2.2479e-01, time/batch = 18.4577s	
4104/11350 (epoch 18.079), train_loss = 1.02840990, grad/param norm = 2.6757e-01, time/batch = 18.3061s	
4105/11350 (epoch 18.084), train_loss = 1.19284221, grad/param norm = 2.8889e-01, time/batch = 17.9573s	
4106/11350 (epoch 18.088), train_loss = 1.15518563, grad/param norm = 2.9566e-01, time/batch = 19.2100s	
4107/11350 (epoch 18.093), train_loss = 1.09413659, grad/param norm = 2.8824e-01, time/batch = 18.2191s	
4108/11350 (epoch 18.097), train_loss = 1.04259041, grad/param norm = 2.6807e-01, time/batch = 16.0866s	
4109/11350 (epoch 18.101), train_loss = 0.92194150, grad/param norm = 2.5995e-01, time/batch = 15.5986s	
4110/11350 (epoch 18.106), train_loss = 1.11483439, grad/param norm = 2.9288e-01, time/batch = 15.6899s	
4111/11350 (epoch 18.110), train_loss = 0.99529509, grad/param norm = 2.8731e-01, time/batch = 15.8498s	
4112/11350 (epoch 18.115), train_loss = 0.97498396, grad/param norm = 2.7306e-01, time/batch = 15.8101s	
4113/11350 (epoch 18.119), train_loss = 1.14063123, grad/param norm = 2.8218e-01, time/batch = 16.3861s	
4114/11350 (epoch 18.123), train_loss = 0.95965604, grad/param norm = 2.9831e-01, time/batch = 20.4483s	
4115/11350 (epoch 18.128), train_loss = 0.92957372, grad/param norm = 2.6869e-01, time/batch = 16.8015s	
4116/11350 (epoch 18.132), train_loss = 1.00721853, grad/param norm = 2.6260e-01, time/batch = 19.0345s	
4117/11350 (epoch 18.137), train_loss = 0.96708868, grad/param norm = 2.7345e-01, time/batch = 18.4621s	
4118/11350 (epoch 18.141), train_loss = 1.18277683, grad/param norm = 3.1079e-01, time/batch = 16.8555s	
4119/11350 (epoch 18.145), train_loss = 0.95587322, grad/param norm = 2.7281e-01, time/batch = 20.0341s	
4120/11350 (epoch 18.150), train_loss = 1.09768385, grad/param norm = 3.2217e-01, time/batch = 19.3684s	
4121/11350 (epoch 18.154), train_loss = 1.22630250, grad/param norm = 3.1492e-01, time/batch = 19.0323s	
4122/11350 (epoch 18.159), train_loss = 0.89813547, grad/param norm = 2.8617e-01, time/batch = 16.3478s	
4123/11350 (epoch 18.163), train_loss = 1.14111245, grad/param norm = 2.9390e-01, time/batch = 18.5285s	
4124/11350 (epoch 18.167), train_loss = 1.17127060, grad/param norm = 3.0353e-01, time/batch = 20.4587s	
4125/11350 (epoch 18.172), train_loss = 1.28868651, grad/param norm = 3.0586e-01, time/batch = 19.1147s	
4126/11350 (epoch 18.176), train_loss = 1.11233799, grad/param norm = 3.0426e-01, time/batch = 19.2959s	
4127/11350 (epoch 18.181), train_loss = 1.10792174, grad/param norm = 3.4650e-01, time/batch = 20.5364s	
4128/11350 (epoch 18.185), train_loss = 0.92223810, grad/param norm = 2.9328e-01, time/batch = 18.0176s	
4129/11350 (epoch 18.189), train_loss = 1.01199277, grad/param norm = 2.4920e-01, time/batch = 17.7993s	
4130/11350 (epoch 18.194), train_loss = 0.96915955, grad/param norm = 2.9032e-01, time/batch = 19.6910s	
4131/11350 (epoch 18.198), train_loss = 0.93388134, grad/param norm = 3.2283e-01, time/batch = 17.1841s	
4132/11350 (epoch 18.203), train_loss = 0.94317084, grad/param norm = 2.6774e-01, time/batch = 19.8767s	
4133/11350 (epoch 18.207), train_loss = 0.91575659, grad/param norm = 3.1262e-01, time/batch = 19.3017s	
4134/11350 (epoch 18.211), train_loss = 1.12957470, grad/param norm = 3.3030e-01, time/batch = 18.8603s	
4135/11350 (epoch 18.216), train_loss = 1.06879042, grad/param norm = 2.8126e-01, time/batch = 16.4422s	
4136/11350 (epoch 18.220), train_loss = 1.07786311, grad/param norm = 2.6801e-01, time/batch = 17.6284s	
4137/11350 (epoch 18.225), train_loss = 0.95288603, grad/param norm = 2.4636e-01, time/batch = 17.3448s	
4138/11350 (epoch 18.229), train_loss = 1.10261313, grad/param norm = 2.7760e-01, time/batch = 17.6313s	
4139/11350 (epoch 18.233), train_loss = 1.05876559, grad/param norm = 2.5594e-01, time/batch = 20.0359s	
4140/11350 (epoch 18.238), train_loss = 1.20735339, grad/param norm = 3.5403e-01, time/batch = 20.1925s	
4141/11350 (epoch 18.242), train_loss = 1.19251937, grad/param norm = 3.5994e-01, time/batch = 18.6892s	
4142/11350 (epoch 18.247), train_loss = 0.87396291, grad/param norm = 2.6110e-01, time/batch = 20.1970s	
4143/11350 (epoch 18.251), train_loss = 1.09948220, grad/param norm = 2.9961e-01, time/batch = 19.7115s	
4144/11350 (epoch 18.256), train_loss = 1.08672622, grad/param norm = 2.8719e-01, time/batch = 17.3396s	
4145/11350 (epoch 18.260), train_loss = 0.97764007, grad/param norm = 2.9277e-01, time/batch = 16.2754s	
4146/11350 (epoch 18.264), train_loss = 0.99750361, grad/param norm = 2.7647e-01, time/batch = 20.4472s	
4147/11350 (epoch 18.269), train_loss = 1.04000095, grad/param norm = 2.6487e-01, time/batch = 18.6171s	
4148/11350 (epoch 18.273), train_loss = 1.13846654, grad/param norm = 2.9055e-01, time/batch = 19.7063s	
4149/11350 (epoch 18.278), train_loss = 0.94584267, grad/param norm = 2.5175e-01, time/batch = 17.3110s	
4150/11350 (epoch 18.282), train_loss = 1.06512421, grad/param norm = 2.8732e-01, time/batch = 16.4783s	
4151/11350 (epoch 18.286), train_loss = 1.15936447, grad/param norm = 2.9333e-01, time/batch = 18.4349s	
4152/11350 (epoch 18.291), train_loss = 0.91755656, grad/param norm = 2.9018e-01, time/batch = 20.2858s	
4153/11350 (epoch 18.295), train_loss = 1.06044645, grad/param norm = 2.6492e-01, time/batch = 19.6157s	
4154/11350 (epoch 18.300), train_loss = 1.08277220, grad/param norm = 3.0656e-01, time/batch = 19.3805s	
4155/11350 (epoch 18.304), train_loss = 0.97955731, grad/param norm = 2.6796e-01, time/batch = 19.0494s	
4156/11350 (epoch 18.308), train_loss = 0.98494980, grad/param norm = 2.6109e-01, time/batch = 19.2799s	
4157/11350 (epoch 18.313), train_loss = 1.10551581, grad/param norm = 2.5578e-01, time/batch = 16.4458s	
4158/11350 (epoch 18.317), train_loss = 0.96562209, grad/param norm = 2.4705e-01, time/batch = 19.8666s	
4159/11350 (epoch 18.322), train_loss = 0.98727953, grad/param norm = 2.5920e-01, time/batch = 20.8611s	
4160/11350 (epoch 18.326), train_loss = 1.03314523, grad/param norm = 2.3772e-01, time/batch = 18.1079s	
4161/11350 (epoch 18.330), train_loss = 0.85298886, grad/param norm = 2.7203e-01, time/batch = 20.4613s	
4162/11350 (epoch 18.335), train_loss = 0.76841680, grad/param norm = 2.6440e-01, time/batch = 20.5246s	
4163/11350 (epoch 18.339), train_loss = 0.87822739, grad/param norm = 2.5716e-01, time/batch = 16.4103s	
4164/11350 (epoch 18.344), train_loss = 0.96196898, grad/param norm = 2.4487e-01, time/batch = 17.8600s	
4165/11350 (epoch 18.348), train_loss = 0.97514493, grad/param norm = 2.4512e-01, time/batch = 18.8723s	
4166/11350 (epoch 18.352), train_loss = 0.88257567, grad/param norm = 2.5767e-01, time/batch = 18.6144s	
4167/11350 (epoch 18.357), train_loss = 0.94191787, grad/param norm = 2.4864e-01, time/batch = 18.5445s	
4168/11350 (epoch 18.361), train_loss = 0.78919079, grad/param norm = 2.3562e-01, time/batch = 18.6149s	
4169/11350 (epoch 18.366), train_loss = 1.08537367, grad/param norm = 2.8747e-01, time/batch = 18.1148s	
4170/11350 (epoch 18.370), train_loss = 0.94363681, grad/param norm = 2.8606e-01, time/batch = 20.1244s	
4171/11350 (epoch 18.374), train_loss = 0.96030914, grad/param norm = 2.5838e-01, time/batch = 19.6281s	
4172/11350 (epoch 18.379), train_loss = 0.98096019, grad/param norm = 2.6093e-01, time/batch = 19.0284s	
4173/11350 (epoch 18.383), train_loss = 0.86595416, grad/param norm = 2.3911e-01, time/batch = 19.8026s	
4174/11350 (epoch 18.388), train_loss = 1.03770192, grad/param norm = 3.4556e-01, time/batch = 18.6298s	
4175/11350 (epoch 18.392), train_loss = 0.99945998, grad/param norm = 2.9693e-01, time/batch = 18.6253s	
4176/11350 (epoch 18.396), train_loss = 1.03487345, grad/param norm = 2.8139e-01, time/batch = 16.0413s	
4177/11350 (epoch 18.401), train_loss = 1.01662458, grad/param norm = 2.7468e-01, time/batch = 17.3682s	
4178/11350 (epoch 18.405), train_loss = 1.18456012, grad/param norm = 2.7922e-01, time/batch = 18.3843s	
4179/11350 (epoch 18.410), train_loss = 1.21473138, grad/param norm = 3.1858e-01, time/batch = 16.9295s	
4180/11350 (epoch 18.414), train_loss = 0.88531057, grad/param norm = 2.8882e-01, time/batch = 17.7817s	
4181/11350 (epoch 18.419), train_loss = 0.95298730, grad/param norm = 2.8330e-01, time/batch = 18.3126s	
4182/11350 (epoch 18.423), train_loss = 1.07297908, grad/param norm = 2.9174e-01, time/batch = 18.2892s	
4183/11350 (epoch 18.427), train_loss = 1.14231160, grad/param norm = 2.7610e-01, time/batch = 18.5414s	
4184/11350 (epoch 18.432), train_loss = 1.09590768, grad/param norm = 3.0037e-01, time/batch = 18.8796s	
4185/11350 (epoch 18.436), train_loss = 1.01997661, grad/param norm = 3.1174e-01, time/batch = 17.8764s	
4186/11350 (epoch 18.441), train_loss = 1.24042720, grad/param norm = 3.2719e-01, time/batch = 19.1293s	
4187/11350 (epoch 18.445), train_loss = 0.86005007, grad/param norm = 2.4164e-01, time/batch = 18.3586s	
4188/11350 (epoch 18.449), train_loss = 0.98942700, grad/param norm = 2.9028e-01, time/batch = 19.0516s	
4189/11350 (epoch 18.454), train_loss = 1.17043934, grad/param norm = 3.0476e-01, time/batch = 18.0313s	
4190/11350 (epoch 18.458), train_loss = 0.84706941, grad/param norm = 2.5313e-01, time/batch = 19.6335s	
4191/11350 (epoch 18.463), train_loss = 0.90462664, grad/param norm = 2.6940e-01, time/batch = 19.9512s	
4192/11350 (epoch 18.467), train_loss = 1.32307390, grad/param norm = 2.9421e-01, time/batch = 16.7849s	
4193/11350 (epoch 18.471), train_loss = 1.16837616, grad/param norm = 3.1196e-01, time/batch = 19.8811s	
4194/11350 (epoch 18.476), train_loss = 1.10549248, grad/param norm = 2.6189e-01, time/batch = 20.2990s	
4195/11350 (epoch 18.480), train_loss = 1.21691203, grad/param norm = 2.8221e-01, time/batch = 16.9498s	
4196/11350 (epoch 18.485), train_loss = 1.03135291, grad/param norm = 2.7191e-01, time/batch = 15.9983s	
4197/11350 (epoch 18.489), train_loss = 1.17628824, grad/param norm = 2.7597e-01, time/batch = 18.2127s	
4198/11350 (epoch 18.493), train_loss = 1.17133611, grad/param norm = 3.0812e-01, time/batch = 19.2802s	
4199/11350 (epoch 18.498), train_loss = 0.82790450, grad/param norm = 2.3572e-01, time/batch = 19.1193s	
4200/11350 (epoch 18.502), train_loss = 1.11353581, grad/param norm = 2.5854e-01, time/batch = 18.6378s	
4201/11350 (epoch 18.507), train_loss = 0.91429457, grad/param norm = 2.6214e-01, time/batch = 16.4778s	
4202/11350 (epoch 18.511), train_loss = 1.22208051, grad/param norm = 2.7808e-01, time/batch = 19.4373s	
4203/11350 (epoch 18.515), train_loss = 1.05671474, grad/param norm = 2.6115e-01, time/batch = 18.9622s	
4204/11350 (epoch 18.520), train_loss = 1.21720969, grad/param norm = 2.9783e-01, time/batch = 19.9561s	
4205/11350 (epoch 18.524), train_loss = 1.04028456, grad/param norm = 2.4870e-01, time/batch = 19.5855s	
4206/11350 (epoch 18.529), train_loss = 1.02893554, grad/param norm = 2.5565e-01, time/batch = 18.8656s	
4207/11350 (epoch 18.533), train_loss = 1.29333458, grad/param norm = 2.9072e-01, time/batch = 20.1873s	
4208/11350 (epoch 18.537), train_loss = 1.13118246, grad/param norm = 2.8977e-01, time/batch = 17.0848s	
4209/11350 (epoch 18.542), train_loss = 1.14934393, grad/param norm = 2.6069e-01, time/batch = 19.3767s	
4210/11350 (epoch 18.546), train_loss = 1.36014357, grad/param norm = 3.6240e-01, time/batch = 18.2912s	
4211/11350 (epoch 18.551), train_loss = 1.09775817, grad/param norm = 3.0584e-01, time/batch = 18.9323s	
4212/11350 (epoch 18.555), train_loss = 1.01597373, grad/param norm = 2.7508e-01, time/batch = 20.3665s	
4213/11350 (epoch 18.559), train_loss = 1.03842579, grad/param norm = 2.9890e-01, time/batch = 18.3000s	
4214/11350 (epoch 18.564), train_loss = 1.16822157, grad/param norm = 2.9928e-01, time/batch = 16.7997s	
4215/11350 (epoch 18.568), train_loss = 1.13511924, grad/param norm = 2.8193e-01, time/batch = 19.3647s	
4216/11350 (epoch 18.573), train_loss = 1.27085353, grad/param norm = 3.6467e-01, time/batch = 17.2201s	
4217/11350 (epoch 18.577), train_loss = 1.24539984, grad/param norm = 3.5981e-01, time/batch = 18.9593s	
4218/11350 (epoch 18.581), train_loss = 1.19297299, grad/param norm = 2.8650e-01, time/batch = 18.7847s	
4219/11350 (epoch 18.586), train_loss = 1.24033397, grad/param norm = 3.7089e-01, time/batch = 18.7226s	
4220/11350 (epoch 18.590), train_loss = 1.32435932, grad/param norm = 3.7478e-01, time/batch = 17.8668s	
4221/11350 (epoch 18.595), train_loss = 1.31119864, grad/param norm = 3.0128e-01, time/batch = 18.1363s	
4222/11350 (epoch 18.599), train_loss = 1.21760099, grad/param norm = 3.0304e-01, time/batch = 18.5526s	
4223/11350 (epoch 18.604), train_loss = 1.10372220, grad/param norm = 2.6158e-01, time/batch = 18.9666s	
4224/11350 (epoch 18.608), train_loss = 1.14841052, grad/param norm = 3.0611e-01, time/batch = 17.5949s	
4225/11350 (epoch 18.612), train_loss = 1.05994095, grad/param norm = 2.5628e-01, time/batch = 19.9638s	
4226/11350 (epoch 18.617), train_loss = 1.24241805, grad/param norm = 2.9602e-01, time/batch = 17.4723s	
4227/11350 (epoch 18.621), train_loss = 1.25909333, grad/param norm = 2.7383e-01, time/batch = 16.8493s	
4228/11350 (epoch 18.626), train_loss = 1.12688924, grad/param norm = 2.7072e-01, time/batch = 19.9340s	
4229/11350 (epoch 18.630), train_loss = 1.19837339, grad/param norm = 2.9228e-01, time/batch = 18.1296s	
4230/11350 (epoch 18.634), train_loss = 1.19717637, grad/param norm = 3.3721e-01, time/batch = 19.0365s	
4231/11350 (epoch 18.639), train_loss = 1.03341268, grad/param norm = 2.7783e-01, time/batch = 18.2884s	
4232/11350 (epoch 18.643), train_loss = 1.01719428, grad/param norm = 2.5709e-01, time/batch = 19.8723s	
4233/11350 (epoch 18.648), train_loss = 1.09554639, grad/param norm = 2.7364e-01, time/batch = 17.7915s	
4234/11350 (epoch 18.652), train_loss = 1.05143264, grad/param norm = 2.9074e-01, time/batch = 17.6904s	
4235/11350 (epoch 18.656), train_loss = 1.17378033, grad/param norm = 2.8642e-01, time/batch = 20.1177s	
4236/11350 (epoch 18.661), train_loss = 1.27473646, grad/param norm = 3.0522e-01, time/batch = 20.2082s	
4237/11350 (epoch 18.665), train_loss = 1.15435862, grad/param norm = 3.1621e-01, time/batch = 17.1169s	
4238/11350 (epoch 18.670), train_loss = 1.14365367, grad/param norm = 3.1632e-01, time/batch = 19.1191s	
4239/11350 (epoch 18.674), train_loss = 1.04835251, grad/param norm = 2.5405e-01, time/batch = 18.0225s	
4240/11350 (epoch 18.678), train_loss = 1.08166257, grad/param norm = 2.4313e-01, time/batch = 17.3829s	
4241/11350 (epoch 18.683), train_loss = 1.03410137, grad/param norm = 2.9443e-01, time/batch = 18.8798s	
4242/11350 (epoch 18.687), train_loss = 1.01958440, grad/param norm = 3.0478e-01, time/batch = 18.7915s	
4243/11350 (epoch 18.692), train_loss = 1.43551278, grad/param norm = 3.7224e-01, time/batch = 18.0076s	
4244/11350 (epoch 18.696), train_loss = 1.27720661, grad/param norm = 3.1242e-01, time/batch = 19.6274s	
4245/11350 (epoch 18.700), train_loss = 1.19072574, grad/param norm = 2.9477e-01, time/batch = 18.3012s	
4246/11350 (epoch 18.705), train_loss = 1.29583074, grad/param norm = 3.2486e-01, time/batch = 19.5261s	
4247/11350 (epoch 18.709), train_loss = 1.24521704, grad/param norm = 2.8177e-01, time/batch = 18.4586s	
4248/11350 (epoch 18.714), train_loss = 1.11186736, grad/param norm = 2.8082e-01, time/batch = 18.7175s	
4249/11350 (epoch 18.718), train_loss = 1.01472672, grad/param norm = 3.0804e-01, time/batch = 19.7032s	
4250/11350 (epoch 18.722), train_loss = 1.17563986, grad/param norm = 3.8067e-01, time/batch = 19.9375s	
4251/11350 (epoch 18.727), train_loss = 1.16502582, grad/param norm = 3.1887e-01, time/batch = 19.8755s	
4252/11350 (epoch 18.731), train_loss = 1.20572425, grad/param norm = 3.2340e-01, time/batch = 18.1058s	
4253/11350 (epoch 18.736), train_loss = 1.10827551, grad/param norm = 3.3007e-01, time/batch = 18.9458s	
4254/11350 (epoch 18.740), train_loss = 1.13334312, grad/param norm = 3.4166e-01, time/batch = 18.9511s	
4255/11350 (epoch 18.744), train_loss = 1.19153834, grad/param norm = 3.3865e-01, time/batch = 16.9824s	
4256/11350 (epoch 18.749), train_loss = 1.22975111, grad/param norm = 3.2260e-01, time/batch = 16.3620s	
4257/11350 (epoch 18.753), train_loss = 1.21746051, grad/param norm = 3.5154e-01, time/batch = 19.5429s	
4258/11350 (epoch 18.758), train_loss = 1.07376173, grad/param norm = 2.7144e-01, time/batch = 19.5420s	
4259/11350 (epoch 18.762), train_loss = 1.20037185, grad/param norm = 2.8495e-01, time/batch = 24.9044s	
4260/11350 (epoch 18.767), train_loss = 1.19469253, grad/param norm = 2.5339e-01, time/batch = 25.7166s	
4261/11350 (epoch 18.771), train_loss = 1.31829693, grad/param norm = 3.2748e-01, time/batch = 18.7052s	
4262/11350 (epoch 18.775), train_loss = 1.08162967, grad/param norm = 2.9694e-01, time/batch = 16.7729s	
4263/11350 (epoch 18.780), train_loss = 1.20700982, grad/param norm = 2.7393e-01, time/batch = 18.3398s	
4264/11350 (epoch 18.784), train_loss = 1.06747410, grad/param norm = 2.6018e-01, time/batch = 18.9584s	
4265/11350 (epoch 18.789), train_loss = 1.12285775, grad/param norm = 2.7017e-01, time/batch = 18.3720s	
4266/11350 (epoch 18.793), train_loss = 1.21568053, grad/param norm = 2.7377e-01, time/batch = 20.1176s	
4267/11350 (epoch 18.797), train_loss = 1.07997035, grad/param norm = 2.5459e-01, time/batch = 19.8844s	
4268/11350 (epoch 18.802), train_loss = 1.19507132, grad/param norm = 2.9551e-01, time/batch = 17.2212s	
4269/11350 (epoch 18.806), train_loss = 1.20930190, grad/param norm = 2.7529e-01, time/batch = 19.6171s	
4270/11350 (epoch 18.811), train_loss = 1.12925645, grad/param norm = 2.7906e-01, time/batch = 16.6825s	
4271/11350 (epoch 18.815), train_loss = 1.04691165, grad/param norm = 2.5911e-01, time/batch = 18.3564s	
4272/11350 (epoch 18.819), train_loss = 1.01472117, grad/param norm = 2.5118e-01, time/batch = 18.6990s	
4273/11350 (epoch 18.824), train_loss = 1.04070880, grad/param norm = 3.1902e-01, time/batch = 18.0610s	
4274/11350 (epoch 18.828), train_loss = 1.11149230, grad/param norm = 2.9594e-01, time/batch = 19.6192s	
4275/11350 (epoch 18.833), train_loss = 1.12341514, grad/param norm = 2.8675e-01, time/batch = 18.7876s	
4276/11350 (epoch 18.837), train_loss = 1.13597850, grad/param norm = 2.7211e-01, time/batch = 18.2099s	
4277/11350 (epoch 18.841), train_loss = 1.38370647, grad/param norm = 3.2091e-01, time/batch = 19.5528s	
4278/11350 (epoch 18.846), train_loss = 1.14050321, grad/param norm = 2.7238e-01, time/batch = 18.2901s	
4279/11350 (epoch 18.850), train_loss = 1.22832763, grad/param norm = 3.2125e-01, time/batch = 18.4531s	
4280/11350 (epoch 18.855), train_loss = 0.99188907, grad/param norm = 2.8887e-01, time/batch = 18.7732s	
4281/11350 (epoch 18.859), train_loss = 1.12052022, grad/param norm = 3.2215e-01, time/batch = 18.0379s	
4282/11350 (epoch 18.863), train_loss = 0.97895036, grad/param norm = 2.7067e-01, time/batch = 19.3798s	
4283/11350 (epoch 18.868), train_loss = 1.06309796, grad/param norm = 2.4855e-01, time/batch = 18.7957s	
4284/11350 (epoch 18.872), train_loss = 1.08882682, grad/param norm = 2.7307e-01, time/batch = 17.9440s	
4285/11350 (epoch 18.877), train_loss = 1.11369521, grad/param norm = 2.8514e-01, time/batch = 18.7313s	
4286/11350 (epoch 18.881), train_loss = 1.32413306, grad/param norm = 3.0478e-01, time/batch = 17.9621s	
4287/11350 (epoch 18.885), train_loss = 1.31575575, grad/param norm = 3.0256e-01, time/batch = 17.3531s	
4288/11350 (epoch 18.890), train_loss = 1.19496369, grad/param norm = 2.9966e-01, time/batch = 17.4638s	
4289/11350 (epoch 18.894), train_loss = 0.96092431, grad/param norm = 2.6667e-01, time/batch = 17.6388s	
4290/11350 (epoch 18.899), train_loss = 1.20721100, grad/param norm = 2.7936e-01, time/batch = 16.6200s	
4291/11350 (epoch 18.903), train_loss = 1.21839370, grad/param norm = 3.2724e-01, time/batch = 16.5332s	
4292/11350 (epoch 18.907), train_loss = 1.19383958, grad/param norm = 3.4060e-01, time/batch = 18.7776s	
4293/11350 (epoch 18.912), train_loss = 1.06432502, grad/param norm = 2.6425e-01, time/batch = 17.4524s	
4294/11350 (epoch 18.916), train_loss = 1.23255465, grad/param norm = 2.9751e-01, time/batch = 18.5253s	
4295/11350 (epoch 18.921), train_loss = 1.19708149, grad/param norm = 2.9402e-01, time/batch = 17.2843s	
4296/11350 (epoch 18.925), train_loss = 1.00041846, grad/param norm = 2.3954e-01, time/batch = 19.0438s	
4297/11350 (epoch 18.930), train_loss = 1.23244845, grad/param norm = 3.1992e-01, time/batch = 18.7846s	
4298/11350 (epoch 18.934), train_loss = 1.30740015, grad/param norm = 2.8575e-01, time/batch = 18.0402s	
4299/11350 (epoch 18.938), train_loss = 1.10249443, grad/param norm = 2.8932e-01, time/batch = 19.2861s	
4300/11350 (epoch 18.943), train_loss = 1.22505833, grad/param norm = 2.7507e-01, time/batch = 19.4579s	
4301/11350 (epoch 18.947), train_loss = 1.22591883, grad/param norm = 3.8824e-01, time/batch = 18.7774s	
4302/11350 (epoch 18.952), train_loss = 1.20755283, grad/param norm = 3.2753e-01, time/batch = 16.0539s	
4303/11350 (epoch 18.956), train_loss = 0.94316885, grad/param norm = 2.4402e-01, time/batch = 18.3092s	
4304/11350 (epoch 18.960), train_loss = 1.11783637, grad/param norm = 3.3791e-01, time/batch = 17.3651s	
4305/11350 (epoch 18.965), train_loss = 1.01624632, grad/param norm = 2.7406e-01, time/batch = 19.5343s	
4306/11350 (epoch 18.969), train_loss = 1.05370425, grad/param norm = 3.5900e-01, time/batch = 18.7173s	
4307/11350 (epoch 18.974), train_loss = 0.96896303, grad/param norm = 3.0416e-01, time/batch = 17.5171s	
4308/11350 (epoch 18.978), train_loss = 1.10030134, grad/param norm = 2.8076e-01, time/batch = 18.3838s	
4309/11350 (epoch 18.982), train_loss = 0.86867626, grad/param norm = 2.4213e-01, time/batch = 18.1359s	
4310/11350 (epoch 18.987), train_loss = 1.11456635, grad/param norm = 2.7790e-01, time/batch = 17.7022s	
4311/11350 (epoch 18.991), train_loss = 0.98346059, grad/param norm = 2.9571e-01, time/batch = 18.0290s	
4312/11350 (epoch 18.996), train_loss = 1.14986380, grad/param norm = 3.1729e-01, time/batch = 18.1373s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
4313/11350 (epoch 19.000), train_loss = 0.87383886, grad/param norm = 2.8098e-01, time/batch = 17.2064s	
4314/11350 (epoch 19.004), train_loss = 1.13426567, grad/param norm = 2.9681e-01, time/batch = 17.1216s	
4315/11350 (epoch 19.009), train_loss = 1.10976271, grad/param norm = 2.7327e-01, time/batch = 19.6156s	
4316/11350 (epoch 19.013), train_loss = 0.78533998, grad/param norm = 2.5186e-01, time/batch = 19.7173s	
4317/11350 (epoch 19.018), train_loss = 0.84394964, grad/param norm = 2.6225e-01, time/batch = 18.2877s	
4318/11350 (epoch 19.022), train_loss = 0.87225121, grad/param norm = 3.2684e-01, time/batch = 18.1258s	
4319/11350 (epoch 19.026), train_loss = 0.91390652, grad/param norm = 3.9120e-01, time/batch = 15.2274s	
4320/11350 (epoch 19.031), train_loss = 0.90144967, grad/param norm = 2.6860e-01, time/batch = 16.2105s	
4321/11350 (epoch 19.035), train_loss = 0.97827986, grad/param norm = 2.9897e-01, time/batch = 16.7011s	
4322/11350 (epoch 19.040), train_loss = 0.96274886, grad/param norm = 2.7834e-01, time/batch = 17.7966s	
4323/11350 (epoch 19.044), train_loss = 0.93682529, grad/param norm = 2.5427e-01, time/batch = 19.6114s	
4324/11350 (epoch 19.048), train_loss = 0.89372960, grad/param norm = 2.8065e-01, time/batch = 18.0101s	
4325/11350 (epoch 19.053), train_loss = 1.00796280, grad/param norm = 2.6253e-01, time/batch = 19.8698s	
4326/11350 (epoch 19.057), train_loss = 1.03459802, grad/param norm = 2.9110e-01, time/batch = 19.8678s	
4327/11350 (epoch 19.062), train_loss = 0.84655176, grad/param norm = 2.5785e-01, time/batch = 16.6958s	
4328/11350 (epoch 19.066), train_loss = 0.83676677, grad/param norm = 2.7489e-01, time/batch = 20.0279s	
4329/11350 (epoch 19.070), train_loss = 0.94586469, grad/param norm = 2.7683e-01, time/batch = 16.8607s	
4330/11350 (epoch 19.075), train_loss = 0.82675650, grad/param norm = 2.3770e-01, time/batch = 16.7649s	
4331/11350 (epoch 19.079), train_loss = 0.98964415, grad/param norm = 2.6467e-01, time/batch = 20.6120s	
4332/11350 (epoch 19.084), train_loss = 1.15631005, grad/param norm = 2.9571e-01, time/batch = 19.2932s	
4333/11350 (epoch 19.088), train_loss = 1.11444871, grad/param norm = 3.2540e-01, time/batch = 19.4486s	
4334/11350 (epoch 19.093), train_loss = 1.06601705, grad/param norm = 2.9696e-01, time/batch = 20.1881s	
4335/11350 (epoch 19.097), train_loss = 1.01981122, grad/param norm = 2.9751e-01, time/batch = 19.7083s	
4336/11350 (epoch 19.101), train_loss = 0.90769408, grad/param norm = 2.6606e-01, time/batch = 18.5971s	
4337/11350 (epoch 19.106), train_loss = 1.07930873, grad/param norm = 2.6730e-01, time/batch = 17.8565s	
4338/11350 (epoch 19.110), train_loss = 0.96224346, grad/param norm = 2.9351e-01, time/batch = 20.2800s	
4339/11350 (epoch 19.115), train_loss = 0.93788963, grad/param norm = 2.6821e-01, time/batch = 19.8622s	
4340/11350 (epoch 19.119), train_loss = 1.11146558, grad/param norm = 2.9109e-01, time/batch = 16.8347s	
4341/11350 (epoch 19.123), train_loss = 0.92073884, grad/param norm = 2.7887e-01, time/batch = 18.0374s	
4342/11350 (epoch 19.128), train_loss = 0.88740598, grad/param norm = 2.8583e-01, time/batch = 19.5420s	
4343/11350 (epoch 19.132), train_loss = 0.98102519, grad/param norm = 2.8975e-01, time/batch = 18.1219s	
4344/11350 (epoch 19.137), train_loss = 0.94156717, grad/param norm = 2.8292e-01, time/batch = 17.6872s	
4345/11350 (epoch 19.141), train_loss = 1.15125583, grad/param norm = 3.3317e-01, time/batch = 17.9606s	
4346/11350 (epoch 19.145), train_loss = 0.93180797, grad/param norm = 2.6916e-01, time/batch = 17.5282s	
4347/11350 (epoch 19.150), train_loss = 1.06317039, grad/param norm = 3.3039e-01, time/batch = 20.4566s	
4348/11350 (epoch 19.154), train_loss = 1.18958410, grad/param norm = 3.0173e-01, time/batch = 19.6999s	
4349/11350 (epoch 19.159), train_loss = 0.86488243, grad/param norm = 2.7394e-01, time/batch = 18.7881s	
4350/11350 (epoch 19.163), train_loss = 1.10526765, grad/param norm = 2.9887e-01, time/batch = 20.2671s	
4351/11350 (epoch 19.167), train_loss = 1.12556334, grad/param norm = 2.9494e-01, time/batch = 19.0388s	
4352/11350 (epoch 19.172), train_loss = 1.25204601, grad/param norm = 3.3016e-01, time/batch = 19.7032s	
4353/11350 (epoch 19.176), train_loss = 1.05899838, grad/param norm = 2.8759e-01, time/batch = 18.6938s	
4354/11350 (epoch 19.181), train_loss = 1.08047391, grad/param norm = 3.2709e-01, time/batch = 18.7119s	
4355/11350 (epoch 19.185), train_loss = 0.89503190, grad/param norm = 2.8793e-01, time/batch = 19.6997s	
4356/11350 (epoch 19.189), train_loss = 0.99543099, grad/param norm = 2.7796e-01, time/batch = 18.0203s	
4357/11350 (epoch 19.194), train_loss = 0.94998758, grad/param norm = 2.9327e-01, time/batch = 16.9076s	
4358/11350 (epoch 19.198), train_loss = 0.88894558, grad/param norm = 2.9591e-01, time/batch = 19.0379s	
4359/11350 (epoch 19.203), train_loss = 0.91191575, grad/param norm = 2.6407e-01, time/batch = 18.1180s	
4360/11350 (epoch 19.207), train_loss = 0.86860670, grad/param norm = 2.9486e-01, time/batch = 19.2808s	
4361/11350 (epoch 19.211), train_loss = 1.09639538, grad/param norm = 3.4436e-01, time/batch = 16.2783s	
4362/11350 (epoch 19.216), train_loss = 1.04665647, grad/param norm = 3.0975e-01, time/batch = 17.0040s	
4363/11350 (epoch 19.220), train_loss = 1.04635823, grad/param norm = 2.7294e-01, time/batch = 20.1279s	
4364/11350 (epoch 19.225), train_loss = 0.92281440, grad/param norm = 2.4138e-01, time/batch = 19.4646s	
4365/11350 (epoch 19.229), train_loss = 1.06895701, grad/param norm = 2.9160e-01, time/batch = 18.7727s	
4366/11350 (epoch 19.233), train_loss = 1.02775008, grad/param norm = 2.7267e-01, time/batch = 19.6229s	
4367/11350 (epoch 19.238), train_loss = 1.16131671, grad/param norm = 3.4552e-01, time/batch = 19.2174s	
4368/11350 (epoch 19.242), train_loss = 1.16283529, grad/param norm = 3.8665e-01, time/batch = 18.6132s	
4369/11350 (epoch 19.247), train_loss = 0.84171083, grad/param norm = 2.5449e-01, time/batch = 18.4281s	
4370/11350 (epoch 19.251), train_loss = 1.05246857, grad/param norm = 3.0388e-01, time/batch = 18.9771s	
4371/11350 (epoch 19.256), train_loss = 1.04894631, grad/param norm = 2.8141e-01, time/batch = 19.3628s	
4372/11350 (epoch 19.260), train_loss = 0.94606779, grad/param norm = 2.9645e-01, time/batch = 18.2968s	
4373/11350 (epoch 19.264), train_loss = 0.95468611, grad/param norm = 2.8406e-01, time/batch = 19.1467s	
4374/11350 (epoch 19.269), train_loss = 0.99986141, grad/param norm = 2.6360e-01, time/batch = 17.0487s	
4375/11350 (epoch 19.273), train_loss = 1.10841175, grad/param norm = 3.1383e-01, time/batch = 18.6074s	
4376/11350 (epoch 19.278), train_loss = 0.92078187, grad/param norm = 2.5852e-01, time/batch = 18.1312s	
4377/11350 (epoch 19.282), train_loss = 1.02150882, grad/param norm = 2.7813e-01, time/batch = 19.0394s	
4378/11350 (epoch 19.286), train_loss = 1.12472016, grad/param norm = 2.9644e-01, time/batch = 17.7148s	
4379/11350 (epoch 19.291), train_loss = 0.88730447, grad/param norm = 3.0178e-01, time/batch = 19.8774s	
4380/11350 (epoch 19.295), train_loss = 1.04601132, grad/param norm = 3.2839e-01, time/batch = 17.0921s	
4381/11350 (epoch 19.300), train_loss = 1.04116632, grad/param norm = 2.5202e-01, time/batch = 18.1195s	
4382/11350 (epoch 19.304), train_loss = 0.93257337, grad/param norm = 2.5862e-01, time/batch = 18.9768s	
4383/11350 (epoch 19.308), train_loss = 0.93785398, grad/param norm = 2.5093e-01, time/batch = 17.7706s	
4384/11350 (epoch 19.313), train_loss = 1.06621461, grad/param norm = 2.4989e-01, time/batch = 18.2065s	
4385/11350 (epoch 19.317), train_loss = 0.93079933, grad/param norm = 2.4472e-01, time/batch = 17.8644s	
4386/11350 (epoch 19.322), train_loss = 0.95458978, grad/param norm = 2.6481e-01, time/batch = 18.2959s	
4387/11350 (epoch 19.326), train_loss = 1.00162262, grad/param norm = 2.5750e-01, time/batch = 20.3760s	
4388/11350 (epoch 19.330), train_loss = 0.82705371, grad/param norm = 2.4385e-01, time/batch = 18.8319s	
4389/11350 (epoch 19.335), train_loss = 0.74569813, grad/param norm = 2.6767e-01, time/batch = 19.2045s	
4390/11350 (epoch 19.339), train_loss = 0.84181913, grad/param norm = 2.6792e-01, time/batch = 20.1168s	
4391/11350 (epoch 19.344), train_loss = 0.93411364, grad/param norm = 2.6566e-01, time/batch = 17.9419s	
4392/11350 (epoch 19.348), train_loss = 0.94110314, grad/param norm = 2.4705e-01, time/batch = 17.6094s	
4393/11350 (epoch 19.352), train_loss = 0.85408267, grad/param norm = 2.5089e-01, time/batch = 20.0306s	
4394/11350 (epoch 19.357), train_loss = 0.91823909, grad/param norm = 2.5584e-01, time/batch = 17.6863s	
4395/11350 (epoch 19.361), train_loss = 0.75491245, grad/param norm = 2.1860e-01, time/batch = 20.0483s	
4396/11350 (epoch 19.366), train_loss = 1.04975645, grad/param norm = 2.9267e-01, time/batch = 19.9698s	
4397/11350 (epoch 19.370), train_loss = 0.88958783, grad/param norm = 2.8175e-01, time/batch = 18.4441s	
4398/11350 (epoch 19.374), train_loss = 0.91843041, grad/param norm = 2.5185e-01, time/batch = 19.2898s	
4399/11350 (epoch 19.379), train_loss = 0.94524386, grad/param norm = 2.9707e-01, time/batch = 20.2099s	
4400/11350 (epoch 19.383), train_loss = 0.84649411, grad/param norm = 2.4462e-01, time/batch = 18.3691s	
4401/11350 (epoch 19.388), train_loss = 1.01032559, grad/param norm = 3.2302e-01, time/batch = 18.4575s	
4402/11350 (epoch 19.392), train_loss = 0.97346225, grad/param norm = 2.8170e-01, time/batch = 19.0280s	
4403/11350 (epoch 19.396), train_loss = 0.99488509, grad/param norm = 2.8704e-01, time/batch = 19.0983s	
4404/11350 (epoch 19.401), train_loss = 0.99234080, grad/param norm = 3.3010e-01, time/batch = 20.3530s	
4405/11350 (epoch 19.405), train_loss = 1.19164071, grad/param norm = 3.9082e-01, time/batch = 18.4642s	
4406/11350 (epoch 19.410), train_loss = 1.18490370, grad/param norm = 3.1389e-01, time/batch = 19.4606s	
4407/11350 (epoch 19.414), train_loss = 0.85878878, grad/param norm = 3.0418e-01, time/batch = 19.7884s	
4408/11350 (epoch 19.419), train_loss = 0.91563033, grad/param norm = 2.8314e-01, time/batch = 18.7852s	
4409/11350 (epoch 19.423), train_loss = 1.03826802, grad/param norm = 3.2260e-01, time/batch = 18.8467s	
4410/11350 (epoch 19.427), train_loss = 1.10260574, grad/param norm = 3.0450e-01, time/batch = 19.3610s	
4411/11350 (epoch 19.432), train_loss = 1.07137639, grad/param norm = 3.3636e-01, time/batch = 18.8737s	
4412/11350 (epoch 19.436), train_loss = 0.96949169, grad/param norm = 3.0076e-01, time/batch = 21.0256s	
4413/11350 (epoch 19.441), train_loss = 1.18326587, grad/param norm = 3.1906e-01, time/batch = 19.2688s	
4414/11350 (epoch 19.445), train_loss = 0.82388238, grad/param norm = 2.4672e-01, time/batch = 20.2911s	
4415/11350 (epoch 19.449), train_loss = 0.95237480, grad/param norm = 3.0307e-01, time/batch = 18.6941s	
4416/11350 (epoch 19.454), train_loss = 1.14989414, grad/param norm = 3.4981e-01, time/batch = 16.5969s	
4417/11350 (epoch 19.458), train_loss = 0.82564074, grad/param norm = 2.4533e-01, time/batch = 19.7890s	
4418/11350 (epoch 19.463), train_loss = 0.88529078, grad/param norm = 2.9409e-01, time/batch = 19.4493s	
4419/11350 (epoch 19.467), train_loss = 1.29760720, grad/param norm = 2.9697e-01, time/batch = 18.3589s	
4420/11350 (epoch 19.471), train_loss = 1.14543762, grad/param norm = 3.7611e-01, time/batch = 19.3706s	
4421/11350 (epoch 19.476), train_loss = 1.06897592, grad/param norm = 2.7117e-01, time/batch = 16.3243s	
4422/11350 (epoch 19.480), train_loss = 1.17488035, grad/param norm = 3.0319e-01, time/batch = 18.3250s	
4423/11350 (epoch 19.485), train_loss = 0.99486417, grad/param norm = 2.8164e-01, time/batch = 19.9448s	
4424/11350 (epoch 19.489), train_loss = 1.15094878, grad/param norm = 3.0545e-01, time/batch = 18.9539s	
4425/11350 (epoch 19.493), train_loss = 1.14452334, grad/param norm = 2.9526e-01, time/batch = 18.3635s	
4426/11350 (epoch 19.498), train_loss = 0.80397030, grad/param norm = 2.6040e-01, time/batch = 18.9488s	
4427/11350 (epoch 19.502), train_loss = 1.09582757, grad/param norm = 2.6700e-01, time/batch = 19.8622s	
4428/11350 (epoch 19.507), train_loss = 0.88072916, grad/param norm = 2.5461e-01, time/batch = 19.4408s	
4429/11350 (epoch 19.511), train_loss = 1.17775156, grad/param norm = 2.8472e-01, time/batch = 19.3611s	
4430/11350 (epoch 19.515), train_loss = 1.02843640, grad/param norm = 2.7216e-01, time/batch = 17.5378s	
4431/11350 (epoch 19.520), train_loss = 1.18312951, grad/param norm = 3.0779e-01, time/batch = 19.5993s	
4432/11350 (epoch 19.524), train_loss = 1.01480836, grad/param norm = 2.5955e-01, time/batch = 17.2825s	
4433/11350 (epoch 19.529), train_loss = 0.99195065, grad/param norm = 2.6706e-01, time/batch = 18.7908s	
4434/11350 (epoch 19.533), train_loss = 1.23396799, grad/param norm = 2.7394e-01, time/batch = 18.0360s	
4435/11350 (epoch 19.537), train_loss = 1.09375507, grad/param norm = 2.8326e-01, time/batch = 17.8493s	
4436/11350 (epoch 19.542), train_loss = 1.11105887, grad/param norm = 2.6027e-01, time/batch = 20.6961s	
4437/11350 (epoch 19.546), train_loss = 1.31894080, grad/param norm = 3.3500e-01, time/batch = 18.2980s	
4438/11350 (epoch 19.551), train_loss = 1.08015206, grad/param norm = 3.0143e-01, time/batch = 18.2099s	
4439/11350 (epoch 19.555), train_loss = 0.98279470, grad/param norm = 2.7243e-01, time/batch = 18.5159s	
4440/11350 (epoch 19.559), train_loss = 1.00667515, grad/param norm = 2.9699e-01, time/batch = 20.1222s	
4441/11350 (epoch 19.564), train_loss = 1.13909597, grad/param norm = 3.1500e-01, time/batch = 18.0182s	
4442/11350 (epoch 19.568), train_loss = 1.09969679, grad/param norm = 2.6043e-01, time/batch = 19.9307s	
4443/11350 (epoch 19.573), train_loss = 1.22877302, grad/param norm = 3.3411e-01, time/batch = 19.2089s	
4444/11350 (epoch 19.577), train_loss = 1.17124044, grad/param norm = 2.9746e-01, time/batch = 19.2119s	
4445/11350 (epoch 19.581), train_loss = 1.16265784, grad/param norm = 2.8974e-01, time/batch = 18.8691s	
4446/11350 (epoch 19.586), train_loss = 1.19484896, grad/param norm = 3.4440e-01, time/batch = 19.7107s	
4447/11350 (epoch 19.590), train_loss = 1.27159358, grad/param norm = 3.5005e-01, time/batch = 19.1909s	
4448/11350 (epoch 19.595), train_loss = 1.28037483, grad/param norm = 3.2976e-01, time/batch = 18.1272s	
4449/11350 (epoch 19.599), train_loss = 1.16654510, grad/param norm = 2.8098e-01, time/batch = 20.0392s	
4450/11350 (epoch 19.604), train_loss = 1.07164285, grad/param norm = 2.7511e-01, time/batch = 20.1904s	
4451/11350 (epoch 19.608), train_loss = 1.11061594, grad/param norm = 3.2607e-01, time/batch = 34.4746s	
4452/11350 (epoch 19.612), train_loss = 1.00307293, grad/param norm = 2.3534e-01, time/batch = 18.1341s	
4453/11350 (epoch 19.617), train_loss = 1.20732070, grad/param norm = 3.1424e-01, time/batch = 19.3486s	
4454/11350 (epoch 19.621), train_loss = 1.22583955, grad/param norm = 2.8094e-01, time/batch = 18.8907s	
4455/11350 (epoch 19.626), train_loss = 1.10028370, grad/param norm = 2.8040e-01, time/batch = 19.8037s	
4456/11350 (epoch 19.630), train_loss = 1.16499294, grad/param norm = 2.9842e-01, time/batch = 17.8570s	
4457/11350 (epoch 19.634), train_loss = 1.14525569, grad/param norm = 3.4618e-01, time/batch = 18.3934s	
4458/11350 (epoch 19.639), train_loss = 0.99228615, grad/param norm = 2.7874e-01, time/batch = 20.2759s	
4459/11350 (epoch 19.643), train_loss = 0.98223307, grad/param norm = 2.6266e-01, time/batch = 18.0981s	
4460/11350 (epoch 19.648), train_loss = 1.06231052, grad/param norm = 2.7562e-01, time/batch = 19.3832s	
4461/11350 (epoch 19.652), train_loss = 1.00753010, grad/param norm = 3.0697e-01, time/batch = 18.3572s	
4462/11350 (epoch 19.656), train_loss = 1.13870873, grad/param norm = 3.0270e-01, time/batch = 15.5170s	
4463/11350 (epoch 19.661), train_loss = 1.25303970, grad/param norm = 3.1502e-01, time/batch = 16.9237s	
4464/11350 (epoch 19.665), train_loss = 1.11987302, grad/param norm = 3.2927e-01, time/batch = 18.8057s	
4465/11350 (epoch 19.670), train_loss = 1.10388124, grad/param norm = 2.8583e-01, time/batch = 19.4742s	
4466/11350 (epoch 19.674), train_loss = 1.01625722, grad/param norm = 2.6116e-01, time/batch = 16.4641s	
4467/11350 (epoch 19.678), train_loss = 1.05875257, grad/param norm = 2.5958e-01, time/batch = 19.1464s	
4468/11350 (epoch 19.683), train_loss = 0.99608133, grad/param norm = 2.7824e-01, time/batch = 19.2949s	
4469/11350 (epoch 19.687), train_loss = 0.96055924, grad/param norm = 2.7947e-01, time/batch = 18.4370s	
4470/11350 (epoch 19.692), train_loss = 1.38394129, grad/param norm = 3.6589e-01, time/batch = 18.7877s	
4471/11350 (epoch 19.696), train_loss = 1.22504714, grad/param norm = 2.9096e-01, time/batch = 18.6346s	
4472/11350 (epoch 19.700), train_loss = 1.15361821, grad/param norm = 3.0815e-01, time/batch = 18.6939s	
4473/11350 (epoch 19.705), train_loss = 1.23896966, grad/param norm = 3.1970e-01, time/batch = 18.4384s	
4474/11350 (epoch 19.709), train_loss = 1.21028253, grad/param norm = 2.9277e-01, time/batch = 17.1159s	
4475/11350 (epoch 19.714), train_loss = 1.09438355, grad/param norm = 3.2909e-01, time/batch = 19.4317s	
4476/11350 (epoch 19.718), train_loss = 0.96956301, grad/param norm = 2.7992e-01, time/batch = 19.5395s	
4477/11350 (epoch 19.722), train_loss = 1.12807298, grad/param norm = 3.5005e-01, time/batch = 18.3885s	
4478/11350 (epoch 19.727), train_loss = 1.12071646, grad/param norm = 3.1123e-01, time/batch = 19.3739s	
4479/11350 (epoch 19.731), train_loss = 1.16798508, grad/param norm = 2.9014e-01, time/batch = 18.2710s	
4480/11350 (epoch 19.736), train_loss = 1.06411793, grad/param norm = 3.2473e-01, time/batch = 19.4481s	
4481/11350 (epoch 19.740), train_loss = 1.08753356, grad/param norm = 2.7763e-01, time/batch = 20.6972s	
4482/11350 (epoch 19.744), train_loss = 1.13726262, grad/param norm = 3.3789e-01, time/batch = 9.5376s	
4483/11350 (epoch 19.749), train_loss = 1.18960087, grad/param norm = 3.2825e-01, time/batch = 0.6869s	
4484/11350 (epoch 19.753), train_loss = 1.17561765, grad/param norm = 3.1710e-01, time/batch = 0.6998s	
4485/11350 (epoch 19.758), train_loss = 1.03908266, grad/param norm = 2.7894e-01, time/batch = 0.6873s	
4486/11350 (epoch 19.762), train_loss = 1.17289796, grad/param norm = 3.0640e-01, time/batch = 0.6853s	
4487/11350 (epoch 19.767), train_loss = 1.17859401, grad/param norm = 2.5989e-01, time/batch = 0.6846s	
4488/11350 (epoch 19.771), train_loss = 1.30276739, grad/param norm = 3.2218e-01, time/batch = 0.6878s	
4489/11350 (epoch 19.775), train_loss = 1.04345273, grad/param norm = 2.9549e-01, time/batch = 0.7523s	
4490/11350 (epoch 19.780), train_loss = 1.18772132, grad/param norm = 2.9966e-01, time/batch = 1.0396s	
4491/11350 (epoch 19.784), train_loss = 1.03747822, grad/param norm = 2.6889e-01, time/batch = 1.0350s	
4492/11350 (epoch 19.789), train_loss = 1.09741463, grad/param norm = 2.8199e-01, time/batch = 1.0017s	
4493/11350 (epoch 19.793), train_loss = 1.18719620, grad/param norm = 2.6593e-01, time/batch = 1.0112s	
4494/11350 (epoch 19.797), train_loss = 1.05827748, grad/param norm = 2.6813e-01, time/batch = 1.2779s	
4495/11350 (epoch 19.802), train_loss = 1.16085640, grad/param norm = 2.9743e-01, time/batch = 1.8932s	
4496/11350 (epoch 19.806), train_loss = 1.17312290, grad/param norm = 2.7590e-01, time/batch = 1.9513s	
4497/11350 (epoch 19.811), train_loss = 1.09697998, grad/param norm = 2.7017e-01, time/batch = 14.7997s	
4498/11350 (epoch 19.815), train_loss = 1.02901796, grad/param norm = 2.6752e-01, time/batch = 20.6219s	
4499/11350 (epoch 19.819), train_loss = 1.00824154, grad/param norm = 2.8011e-01, time/batch = 20.4381s	
4500/11350 (epoch 19.824), train_loss = 0.98842142, grad/param norm = 2.9050e-01, time/batch = 16.9072s	
4501/11350 (epoch 19.828), train_loss = 1.08277659, grad/param norm = 3.3428e-01, time/batch = 20.8727s	
4502/11350 (epoch 19.833), train_loss = 1.09042600, grad/param norm = 2.8106e-01, time/batch = 18.6045s	
4503/11350 (epoch 19.837), train_loss = 1.11660532, grad/param norm = 3.0448e-01, time/batch = 19.2881s	
4504/11350 (epoch 19.841), train_loss = 1.34071337, grad/param norm = 3.2080e-01, time/batch = 17.8705s	
4505/11350 (epoch 19.846), train_loss = 1.11509374, grad/param norm = 2.7274e-01, time/batch = 18.0368s	
4506/11350 (epoch 19.850), train_loss = 1.18872989, grad/param norm = 3.6030e-01, time/batch = 18.3543s	
4507/11350 (epoch 19.855), train_loss = 0.95621780, grad/param norm = 3.1187e-01, time/batch = 18.4531s	
4508/11350 (epoch 19.859), train_loss = 1.07451145, grad/param norm = 3.0215e-01, time/batch = 17.9692s	
4509/11350 (epoch 19.863), train_loss = 0.94522493, grad/param norm = 2.6647e-01, time/batch = 19.0119s	
4510/11350 (epoch 19.868), train_loss = 1.02070917, grad/param norm = 2.4866e-01, time/batch = 18.7951s	
4511/11350 (epoch 19.872), train_loss = 1.05735630, grad/param norm = 2.6768e-01, time/batch = 19.0112s	
4512/11350 (epoch 19.877), train_loss = 1.07182160, grad/param norm = 2.9053e-01, time/batch = 20.6152s	
4513/11350 (epoch 19.881), train_loss = 1.27295652, grad/param norm = 3.3428e-01, time/batch = 18.8814s	
4514/11350 (epoch 19.885), train_loss = 1.28651811, grad/param norm = 3.3299e-01, time/batch = 18.9441s	
4515/11350 (epoch 19.890), train_loss = 1.15474024, grad/param norm = 2.9885e-01, time/batch = 18.2129s	
4516/11350 (epoch 19.894), train_loss = 0.93792113, grad/param norm = 2.6274e-01, time/batch = 20.3585s	
4517/11350 (epoch 19.899), train_loss = 1.16619283, grad/param norm = 2.9076e-01, time/batch = 17.0423s	
4518/11350 (epoch 19.903), train_loss = 1.16495489, grad/param norm = 3.1087e-01, time/batch = 19.6757s	
4519/11350 (epoch 19.907), train_loss = 1.13761040, grad/param norm = 2.8705e-01, time/batch = 18.1209s	
4520/11350 (epoch 19.912), train_loss = 1.01493303, grad/param norm = 2.6055e-01, time/batch = 20.3680s	
4521/11350 (epoch 19.916), train_loss = 1.19533718, grad/param norm = 3.4058e-01, time/batch = 19.6957s	
4522/11350 (epoch 19.921), train_loss = 1.15410609, grad/param norm = 2.7987e-01, time/batch = 20.6169s	
4523/11350 (epoch 19.925), train_loss = 0.96243599, grad/param norm = 2.4943e-01, time/batch = 19.1943s	
4524/11350 (epoch 19.930), train_loss = 1.19793614, grad/param norm = 3.1801e-01, time/batch = 16.9548s	
4525/11350 (epoch 19.934), train_loss = 1.26167325, grad/param norm = 2.9975e-01, time/batch = 20.1185s	
4526/11350 (epoch 19.938), train_loss = 1.07571327, grad/param norm = 3.1111e-01, time/batch = 18.8693s	
4527/11350 (epoch 19.943), train_loss = 1.18268202, grad/param norm = 2.7610e-01, time/batch = 18.3735s	
4528/11350 (epoch 19.947), train_loss = 1.18360873, grad/param norm = 3.1594e-01, time/batch = 18.9629s	
4529/11350 (epoch 19.952), train_loss = 1.14973486, grad/param norm = 2.9447e-01, time/batch = 19.6295s	
4530/11350 (epoch 19.956), train_loss = 0.91653791, grad/param norm = 2.6920e-01, time/batch = 16.4348s	
4531/11350 (epoch 19.960), train_loss = 1.06161500, grad/param norm = 3.0692e-01, time/batch = 16.8647s	
4532/11350 (epoch 19.965), train_loss = 0.98529841, grad/param norm = 3.0248e-01, time/batch = 17.4649s	
4533/11350 (epoch 19.969), train_loss = 1.00860679, grad/param norm = 3.4207e-01, time/batch = 19.6172s	
4534/11350 (epoch 19.974), train_loss = 0.92893933, grad/param norm = 2.7833e-01, time/batch = 18.9595s	
4535/11350 (epoch 19.978), train_loss = 1.07201219, grad/param norm = 2.8836e-01, time/batch = 18.9492s	
4536/11350 (epoch 19.982), train_loss = 0.84338318, grad/param norm = 2.9143e-01, time/batch = 17.6980s	
4537/11350 (epoch 19.987), train_loss = 1.07704073, grad/param norm = 2.9436e-01, time/batch = 19.0195s	
4538/11350 (epoch 19.991), train_loss = 0.95471524, grad/param norm = 3.2784e-01, time/batch = 19.9712s	
4539/11350 (epoch 19.996), train_loss = 1.10708870, grad/param norm = 3.2204e-01, time/batch = 19.5343s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
4540/11350 (epoch 20.000), train_loss = 0.83295145, grad/param norm = 2.7665e-01, time/batch = 18.2773s	
4541/11350 (epoch 20.004), train_loss = 1.10768853, grad/param norm = 3.0858e-01, time/batch = 19.1975s	
4542/11350 (epoch 20.009), train_loss = 1.08323820, grad/param norm = 2.7441e-01, time/batch = 20.4418s	
4543/11350 (epoch 20.013), train_loss = 0.75620326, grad/param norm = 2.5428e-01, time/batch = 21.2415s	
4544/11350 (epoch 20.018), train_loss = 0.82350906, grad/param norm = 2.7667e-01, time/batch = 24.4909s	
4545/11350 (epoch 20.022), train_loss = 0.85129432, grad/param norm = 2.8846e-01, time/batch = 29.3797s	
4546/11350 (epoch 20.026), train_loss = 0.86774743, grad/param norm = 2.9407e-01, time/batch = 28.4261s	
4547/11350 (epoch 20.031), train_loss = 0.89507962, grad/param norm = 3.1345e-01, time/batch = 27.4959s	
4548/11350 (epoch 20.035), train_loss = 0.92438501, grad/param norm = 3.0640e-01, time/batch = 31.2346s	
4549/11350 (epoch 20.040), train_loss = 0.92248933, grad/param norm = 2.8035e-01, time/batch = 25.1692s	
4550/11350 (epoch 20.044), train_loss = 0.89611043, grad/param norm = 2.2994e-01, time/batch = 28.9992s	
4551/11350 (epoch 20.048), train_loss = 0.87659059, grad/param norm = 2.8554e-01, time/batch = 27.9212s	
4552/11350 (epoch 20.053), train_loss = 0.99344579, grad/param norm = 2.8015e-01, time/batch = 27.0593s	
4553/11350 (epoch 20.057), train_loss = 0.99543251, grad/param norm = 2.8298e-01, time/batch = 28.8392s	
4554/11350 (epoch 20.062), train_loss = 0.82532035, grad/param norm = 2.9271e-01, time/batch = 27.0761s	
4555/11350 (epoch 20.066), train_loss = 0.82447494, grad/param norm = 2.8787e-01, time/batch = 27.5283s	
4556/11350 (epoch 20.070), train_loss = 0.92150904, grad/param norm = 2.8350e-01, time/batch = 26.8724s	
4557/11350 (epoch 20.075), train_loss = 0.80357546, grad/param norm = 2.4555e-01, time/batch = 23.9699s	
4558/11350 (epoch 20.079), train_loss = 0.95867882, grad/param norm = 2.5968e-01, time/batch = 26.1729s	
4559/11350 (epoch 20.084), train_loss = 1.13429420, grad/param norm = 3.2947e-01, time/batch = 32.8977s	
4560/11350 (epoch 20.088), train_loss = 1.08044830, grad/param norm = 3.1491e-01, time/batch = 19.4518s	
4561/11350 (epoch 20.093), train_loss = 1.03464926, grad/param norm = 2.9155e-01, time/batch = 18.4802s	
4562/11350 (epoch 20.097), train_loss = 0.98428185, grad/param norm = 3.0569e-01, time/batch = 19.4668s	
4563/11350 (epoch 20.101), train_loss = 0.87853018, grad/param norm = 2.6814e-01, time/batch = 20.1911s	
4564/11350 (epoch 20.106), train_loss = 1.03828280, grad/param norm = 2.9005e-01, time/batch = 17.8494s	
4565/11350 (epoch 20.110), train_loss = 0.91060426, grad/param norm = 2.7090e-01, time/batch = 18.4607s	
4566/11350 (epoch 20.115), train_loss = 0.92328808, grad/param norm = 2.8642e-01, time/batch = 20.4460s	
4567/11350 (epoch 20.119), train_loss = 1.07703806, grad/param norm = 2.9264e-01, time/batch = 17.6060s	
4568/11350 (epoch 20.123), train_loss = 0.89772184, grad/param norm = 2.7185e-01, time/batch = 20.5266s	
4569/11350 (epoch 20.128), train_loss = 0.84071072, grad/param norm = 2.6938e-01, time/batch = 18.2796s	
4570/11350 (epoch 20.132), train_loss = 0.93208364, grad/param norm = 2.6653e-01, time/batch = 18.9460s	
4571/11350 (epoch 20.137), train_loss = 0.90712481, grad/param norm = 2.7884e-01, time/batch = 20.7001s	
4572/11350 (epoch 20.141), train_loss = 1.12556708, grad/param norm = 3.2844e-01, time/batch = 18.4675s	
4573/11350 (epoch 20.145), train_loss = 0.89955688, grad/param norm = 2.7664e-01, time/batch = 15.3921s	
4574/11350 (epoch 20.150), train_loss = 1.02514415, grad/param norm = 3.5351e-01, time/batch = 16.1161s	
4575/11350 (epoch 20.154), train_loss = 1.15209559, grad/param norm = 3.7528e-01, time/batch = 17.5471s	
4576/11350 (epoch 20.159), train_loss = 0.84485573, grad/param norm = 2.7481e-01, time/batch = 20.1031s	
4577/11350 (epoch 20.163), train_loss = 1.08111956, grad/param norm = 3.2152e-01, time/batch = 19.0349s	
4578/11350 (epoch 20.167), train_loss = 1.11739747, grad/param norm = 3.0018e-01, time/batch = 19.4553s	
4579/11350 (epoch 20.172), train_loss = 1.21210579, grad/param norm = 3.2212e-01, time/batch = 18.6847s	
4580/11350 (epoch 20.176), train_loss = 1.02014704, grad/param norm = 2.8704e-01, time/batch = 18.2746s	
4581/11350 (epoch 20.181), train_loss = 1.04058996, grad/param norm = 3.4149e-01, time/batch = 16.8047s	
4582/11350 (epoch 20.185), train_loss = 0.85301233, grad/param norm = 2.8958e-01, time/batch = 19.4384s	
4583/11350 (epoch 20.189), train_loss = 0.96274252, grad/param norm = 2.6534e-01, time/batch = 17.2700s	
4584/11350 (epoch 20.194), train_loss = 0.92030384, grad/param norm = 3.0133e-01, time/batch = 19.4561s	
4585/11350 (epoch 20.198), train_loss = 0.86155702, grad/param norm = 3.0938e-01, time/batch = 19.5115s	
4586/11350 (epoch 20.203), train_loss = 0.90195451, grad/param norm = 2.7351e-01, time/batch = 18.6081s	
4587/11350 (epoch 20.207), train_loss = 0.83606397, grad/param norm = 2.8874e-01, time/batch = 20.2121s	
4588/11350 (epoch 20.211), train_loss = 1.06369002, grad/param norm = 3.3987e-01, time/batch = 18.9594s	
4589/11350 (epoch 20.216), train_loss = 1.00248659, grad/param norm = 2.8170e-01, time/batch = 18.6114s	
4590/11350 (epoch 20.220), train_loss = 1.00857475, grad/param norm = 2.7069e-01, time/batch = 19.5312s	
4591/11350 (epoch 20.225), train_loss = 0.89253085, grad/param norm = 2.5150e-01, time/batch = 16.4524s	
4592/11350 (epoch 20.229), train_loss = 1.04259278, grad/param norm = 3.1489e-01, time/batch = 18.8487s	
4593/11350 (epoch 20.233), train_loss = 0.98637507, grad/param norm = 2.7155e-01, time/batch = 18.9457s	
4594/11350 (epoch 20.238), train_loss = 1.12454278, grad/param norm = 3.7275e-01, time/batch = 19.1077s	
4595/11350 (epoch 20.242), train_loss = 1.13049425, grad/param norm = 3.9945e-01, time/batch = 19.6310s	
4596/11350 (epoch 20.247), train_loss = 0.82282413, grad/param norm = 2.5781e-01, time/batch = 17.8483s	
4597/11350 (epoch 20.251), train_loss = 1.02607790, grad/param norm = 2.9397e-01, time/batch = 17.9404s	
4598/11350 (epoch 20.256), train_loss = 1.00861249, grad/param norm = 3.0222e-01, time/batch = 19.8681s	
4599/11350 (epoch 20.260), train_loss = 0.90767450, grad/param norm = 2.6521e-01, time/batch = 18.3559s	
4600/11350 (epoch 20.264), train_loss = 0.91569580, grad/param norm = 2.9043e-01, time/batch = 19.0485s	
4601/11350 (epoch 20.269), train_loss = 0.97414295, grad/param norm = 2.8227e-01, time/batch = 19.6223s	
4602/11350 (epoch 20.273), train_loss = 1.07942692, grad/param norm = 2.8495e-01, time/batch = 18.8511s	
4603/11350 (epoch 20.278), train_loss = 0.88543375, grad/param norm = 2.4123e-01, time/batch = 18.0434s	
4604/11350 (epoch 20.282), train_loss = 0.98986304, grad/param norm = 2.8542e-01, time/batch = 18.7263s	
4605/11350 (epoch 20.286), train_loss = 1.08729598, grad/param norm = 2.9895e-01, time/batch = 18.8691s	
4606/11350 (epoch 20.291), train_loss = 0.86881127, grad/param norm = 3.4443e-01, time/batch = 19.6921s	
4607/11350 (epoch 20.295), train_loss = 1.00458802, grad/param norm = 2.9298e-01, time/batch = 16.2818s	
4608/11350 (epoch 20.300), train_loss = 1.02702523, grad/param norm = 3.2169e-01, time/batch = 19.1135s	
4609/11350 (epoch 20.304), train_loss = 0.91563409, grad/param norm = 2.8468e-01, time/batch = 18.2850s	
4610/11350 (epoch 20.308), train_loss = 0.90625831, grad/param norm = 2.8413e-01, time/batch = 18.8792s	
4611/11350 (epoch 20.313), train_loss = 1.02999243, grad/param norm = 2.4658e-01, time/batch = 19.7850s	
4612/11350 (epoch 20.317), train_loss = 0.90323858, grad/param norm = 2.4994e-01, time/batch = 16.6064s	
4613/11350 (epoch 20.322), train_loss = 0.92142294, grad/param norm = 2.4760e-01, time/batch = 18.9627s	
4614/11350 (epoch 20.326), train_loss = 0.97022231, grad/param norm = 2.4498e-01, time/batch = 19.9569s	
4615/11350 (epoch 20.330), train_loss = 0.80489204, grad/param norm = 2.5000e-01, time/batch = 16.6901s	
4616/11350 (epoch 20.335), train_loss = 0.70389620, grad/param norm = 2.3485e-01, time/batch = 19.8809s	
4617/11350 (epoch 20.339), train_loss = 0.82010109, grad/param norm = 3.2020e-01, time/batch = 17.4504s	
4618/11350 (epoch 20.344), train_loss = 0.89081976, grad/param norm = 2.2882e-01, time/batch = 19.0351s	
4619/11350 (epoch 20.348), train_loss = 0.91069863, grad/param norm = 2.6361e-01, time/batch = 20.8660s	
4620/11350 (epoch 20.352), train_loss = 0.81962854, grad/param norm = 2.4230e-01, time/batch = 18.7810s	
4621/11350 (epoch 20.357), train_loss = 0.88292704, grad/param norm = 2.3999e-01, time/batch = 19.1098s	
4622/11350 (epoch 20.361), train_loss = 0.73141617, grad/param norm = 2.2094e-01, time/batch = 19.6035s	
4623/11350 (epoch 20.366), train_loss = 1.01543047, grad/param norm = 3.0658e-01, time/batch = 19.1076s	
4624/11350 (epoch 20.370), train_loss = 0.85284633, grad/param norm = 2.8532e-01, time/batch = 19.1159s	
4625/11350 (epoch 20.374), train_loss = 0.89204950, grad/param norm = 2.7108e-01, time/batch = 19.0878s	
4626/11350 (epoch 20.379), train_loss = 0.90148365, grad/param norm = 2.8927e-01, time/batch = 18.6149s	
4627/11350 (epoch 20.383), train_loss = 0.81150263, grad/param norm = 2.4906e-01, time/batch = 19.3291s	
4628/11350 (epoch 20.388), train_loss = 0.95489809, grad/param norm = 3.1060e-01, time/batch = 18.4465s	
4629/11350 (epoch 20.392), train_loss = 0.94268225, grad/param norm = 2.8813e-01, time/batch = 19.4632s	
4630/11350 (epoch 20.396), train_loss = 0.94439937, grad/param norm = 2.8115e-01, time/batch = 20.1018s	
4631/11350 (epoch 20.401), train_loss = 0.95495941, grad/param norm = 3.3014e-01, time/batch = 17.6675s	
4632/11350 (epoch 20.405), train_loss = 1.12988193, grad/param norm = 2.9071e-01, time/batch = 17.1188s	
4633/11350 (epoch 20.410), train_loss = 1.16225285, grad/param norm = 3.5016e-01, time/batch = 15.2903s	
4634/11350 (epoch 20.414), train_loss = 0.83759052, grad/param norm = 3.0154e-01, time/batch = 18.5359s	
4635/11350 (epoch 20.419), train_loss = 0.88613778, grad/param norm = 3.0348e-01, time/batch = 19.7052s	
4636/11350 (epoch 20.423), train_loss = 0.99148214, grad/param norm = 2.9536e-01, time/batch = 19.1255s	
4637/11350 (epoch 20.427), train_loss = 1.06743072, grad/param norm = 2.9725e-01, time/batch = 17.8702s	
4638/11350 (epoch 20.432), train_loss = 1.04123767, grad/param norm = 3.7342e-01, time/batch = 19.1082s	
4639/11350 (epoch 20.436), train_loss = 0.94408306, grad/param norm = 3.2928e-01, time/batch = 18.2934s	
4640/11350 (epoch 20.441), train_loss = 1.15462346, grad/param norm = 3.4140e-01, time/batch = 19.0441s	
4641/11350 (epoch 20.445), train_loss = 0.81962060, grad/param norm = 2.4591e-01, time/batch = 19.0506s	
4642/11350 (epoch 20.449), train_loss = 0.91436346, grad/param norm = 2.7510e-01, time/batch = 20.8631s	
4643/11350 (epoch 20.454), train_loss = 1.10491033, grad/param norm = 3.1749e-01, time/batch = 18.5314s	
4644/11350 (epoch 20.458), train_loss = 0.79219383, grad/param norm = 2.4116e-01, time/batch = 17.4071s	
4645/11350 (epoch 20.463), train_loss = 0.84140995, grad/param norm = 2.8435e-01, time/batch = 20.1305s	
4646/11350 (epoch 20.467), train_loss = 1.26680402, grad/param norm = 2.9688e-01, time/batch = 19.7820s	
4647/11350 (epoch 20.471), train_loss = 1.10566009, grad/param norm = 3.3981e-01, time/batch = 28.9789s	
4648/11350 (epoch 20.476), train_loss = 1.03526668, grad/param norm = 2.7065e-01, time/batch = 26.7826s	
4649/11350 (epoch 20.480), train_loss = 1.13781192, grad/param norm = 2.8805e-01, time/batch = 19.5204s	
4650/11350 (epoch 20.485), train_loss = 0.97059748, grad/param norm = 2.6097e-01, time/batch = 18.3813s	
4651/11350 (epoch 20.489), train_loss = 1.10221578, grad/param norm = 2.8739e-01, time/batch = 19.6380s	
4652/11350 (epoch 20.493), train_loss = 1.10840637, grad/param norm = 2.9594e-01, time/batch = 17.4480s	
4653/11350 (epoch 20.498), train_loss = 0.77653138, grad/param norm = 2.7699e-01, time/batch = 20.7085s	
4654/11350 (epoch 20.502), train_loss = 1.08272952, grad/param norm = 2.8142e-01, time/batch = 20.2775s	
4655/11350 (epoch 20.507), train_loss = 0.85126564, grad/param norm = 2.5401e-01, time/batch = 17.6035s	
4656/11350 (epoch 20.511), train_loss = 1.13945773, grad/param norm = 2.9013e-01, time/batch = 19.4546s	
4657/11350 (epoch 20.515), train_loss = 0.98727316, grad/param norm = 2.6379e-01, time/batch = 19.5432s	
4658/11350 (epoch 20.520), train_loss = 1.14863898, grad/param norm = 3.1376e-01, time/batch = 17.7725s	
4659/11350 (epoch 20.524), train_loss = 0.98032394, grad/param norm = 2.7305e-01, time/batch = 19.1896s	
4660/11350 (epoch 20.529), train_loss = 0.95269934, grad/param norm = 2.5975e-01, time/batch = 20.4463s	
4661/11350 (epoch 20.533), train_loss = 1.21514579, grad/param norm = 4.4745e-01, time/batch = 18.1236s	
4662/11350 (epoch 20.537), train_loss = 1.08320618, grad/param norm = 3.7521e-01, time/batch = 20.0945s	
4663/11350 (epoch 20.542), train_loss = 1.08541517, grad/param norm = 2.6649e-01, time/batch = 18.4186s	
4664/11350 (epoch 20.546), train_loss = 1.28973026, grad/param norm = 3.4226e-01, time/batch = 18.9542s	
4665/11350 (epoch 20.551), train_loss = 1.05036723, grad/param norm = 3.0751e-01, time/batch = 21.0237s	
4666/11350 (epoch 20.555), train_loss = 0.94897035, grad/param norm = 2.8323e-01, time/batch = 18.9534s	
4667/11350 (epoch 20.559), train_loss = 0.96943968, grad/param norm = 2.8975e-01, time/batch = 19.1168s	
4668/11350 (epoch 20.564), train_loss = 1.10910117, grad/param norm = 3.0359e-01, time/batch = 21.5120s	
4669/11350 (epoch 20.568), train_loss = 1.07571885, grad/param norm = 2.8237e-01, time/batch = 17.8321s	
4670/11350 (epoch 20.573), train_loss = 1.19099547, grad/param norm = 3.4244e-01, time/batch = 20.0974s	
4671/11350 (epoch 20.577), train_loss = 1.14127505, grad/param norm = 3.7584e-01, time/batch = 15.9755s	
4672/11350 (epoch 20.581), train_loss = 1.11919421, grad/param norm = 2.9595e-01, time/batch = 16.6103s	
4673/11350 (epoch 20.586), train_loss = 1.15126276, grad/param norm = 3.4464e-01, time/batch = 21.1847s	
4674/11350 (epoch 20.590), train_loss = 1.22508808, grad/param norm = 3.3916e-01, time/batch = 17.5975s	
4675/11350 (epoch 20.595), train_loss = 1.24519393, grad/param norm = 3.0991e-01, time/batch = 20.6975s	
4676/11350 (epoch 20.599), train_loss = 1.14625196, grad/param norm = 3.0221e-01, time/batch = 20.8594s	
4677/11350 (epoch 20.604), train_loss = 1.04111564, grad/param norm = 2.5299e-01, time/batch = 18.7510s	
4678/11350 (epoch 20.608), train_loss = 1.06990906, grad/param norm = 3.2448e-01, time/batch = 20.1070s	
4679/11350 (epoch 20.612), train_loss = 0.98949919, grad/param norm = 2.5242e-01, time/batch = 19.2901s	
4680/11350 (epoch 20.617), train_loss = 1.15097281, grad/param norm = 3.0399e-01, time/batch = 18.8597s	
4681/11350 (epoch 20.621), train_loss = 1.19482379, grad/param norm = 2.9570e-01, time/batch = 20.2094s	
4682/11350 (epoch 20.626), train_loss = 1.05433355, grad/param norm = 2.7899e-01, time/batch = 16.4505s	
4683/11350 (epoch 20.630), train_loss = 1.12987376, grad/param norm = 3.2571e-01, time/batch = 18.2052s	
4684/11350 (epoch 20.634), train_loss = 1.09193913, grad/param norm = 3.1351e-01, time/batch = 19.6860s	
4685/11350 (epoch 20.639), train_loss = 0.96107158, grad/param norm = 2.6924e-01, time/batch = 20.1922s	
4686/11350 (epoch 20.643), train_loss = 0.95599649, grad/param norm = 2.9014e-01, time/batch = 19.1125s	
4687/11350 (epoch 20.648), train_loss = 1.01380655, grad/param norm = 2.6764e-01, time/batch = 17.8446s	
4688/11350 (epoch 20.652), train_loss = 0.97282211, grad/param norm = 3.0391e-01, time/batch = 17.6248s	
4689/11350 (epoch 20.656), train_loss = 1.09280172, grad/param norm = 2.8598e-01, time/batch = 17.7111s	
4690/11350 (epoch 20.661), train_loss = 1.20286483, grad/param norm = 3.6869e-01, time/batch = 18.6010s	
4691/11350 (epoch 20.665), train_loss = 1.08743653, grad/param norm = 3.5827e-01, time/batch = 19.9614s	
4692/11350 (epoch 20.670), train_loss = 1.06998831, grad/param norm = 3.4752e-01, time/batch = 19.7631s	
4693/11350 (epoch 20.674), train_loss = 0.99456686, grad/param norm = 2.7778e-01, time/batch = 19.6093s	
4694/11350 (epoch 20.678), train_loss = 1.02814869, grad/param norm = 2.7339e-01, time/batch = 18.1209s	
4695/11350 (epoch 20.683), train_loss = 0.97764158, grad/param norm = 3.1715e-01, time/batch = 19.5313s	
4696/11350 (epoch 20.687), train_loss = 0.94076624, grad/param norm = 2.7990e-01, time/batch = 19.0404s	
4697/11350 (epoch 20.692), train_loss = 1.35581143, grad/param norm = 3.9264e-01, time/batch = 20.2218s	
4698/11350 (epoch 20.696), train_loss = 1.20377694, grad/param norm = 3.0356e-01, time/batch = 19.1155s	
4699/11350 (epoch 20.700), train_loss = 1.14175828, grad/param norm = 3.4673e-01, time/batch = 19.3754s	
4700/11350 (epoch 20.705), train_loss = 1.20926031, grad/param norm = 3.2647e-01, time/batch = 20.5227s	
4701/11350 (epoch 20.709), train_loss = 1.18666603, grad/param norm = 2.9222e-01, time/batch = 20.5457s	
4702/11350 (epoch 20.714), train_loss = 1.04868767, grad/param norm = 2.7726e-01, time/batch = 18.2549s	
4703/11350 (epoch 20.718), train_loss = 0.93079900, grad/param norm = 2.8701e-01, time/batch = 18.4409s	
4704/11350 (epoch 20.722), train_loss = 1.11298809, grad/param norm = 4.6563e-01, time/batch = 18.0160s	
4705/11350 (epoch 20.727), train_loss = 1.09373679, grad/param norm = 3.3496e-01, time/batch = 18.1131s	
4706/11350 (epoch 20.731), train_loss = 1.13085421, grad/param norm = 3.0476e-01, time/batch = 19.2686s	
4707/11350 (epoch 20.736), train_loss = 1.02913061, grad/param norm = 3.1269e-01, time/batch = 18.0530s	
4708/11350 (epoch 20.740), train_loss = 1.04527361, grad/param norm = 2.8467e-01, time/batch = 17.2799s	
4709/11350 (epoch 20.744), train_loss = 1.07388461, grad/param norm = 3.2353e-01, time/batch = 19.4715s	
4710/11350 (epoch 20.749), train_loss = 1.13773794, grad/param norm = 3.2701e-01, time/batch = 19.1256s	
4711/11350 (epoch 20.753), train_loss = 1.12634416, grad/param norm = 3.2991e-01, time/batch = 18.6197s	
4712/11350 (epoch 20.758), train_loss = 1.00612511, grad/param norm = 2.9257e-01, time/batch = 18.5420s	
4713/11350 (epoch 20.762), train_loss = 1.13290824, grad/param norm = 2.7073e-01, time/batch = 19.7208s	
4714/11350 (epoch 20.767), train_loss = 1.13641860, grad/param norm = 2.7517e-01, time/batch = 18.4640s	
4715/11350 (epoch 20.771), train_loss = 1.26098211, grad/param norm = 3.0851e-01, time/batch = 18.2138s	
4716/11350 (epoch 20.775), train_loss = 1.01707977, grad/param norm = 2.9671e-01, time/batch = 18.2002s	
4717/11350 (epoch 20.780), train_loss = 1.15206172, grad/param norm = 3.1080e-01, time/batch = 18.7918s	
4718/11350 (epoch 20.784), train_loss = 1.01049666, grad/param norm = 2.8233e-01, time/batch = 18.5350s	
4719/11350 (epoch 20.789), train_loss = 1.06375261, grad/param norm = 2.7624e-01, time/batch = 18.0466s	
4720/11350 (epoch 20.793), train_loss = 1.15597825, grad/param norm = 2.7218e-01, time/batch = 20.1160s	
4721/11350 (epoch 20.797), train_loss = 1.02213970, grad/param norm = 2.8205e-01, time/batch = 18.3717s	
4722/11350 (epoch 20.802), train_loss = 1.13368370, grad/param norm = 3.2249e-01, time/batch = 18.4491s	
4723/11350 (epoch 20.806), train_loss = 1.14704121, grad/param norm = 2.8062e-01, time/batch = 16.7739s	
4724/11350 (epoch 20.811), train_loss = 1.06625324, grad/param norm = 2.8436e-01, time/batch = 18.2583s	
4725/11350 (epoch 20.815), train_loss = 0.98958864, grad/param norm = 2.7232e-01, time/batch = 19.4509s	
4726/11350 (epoch 20.819), train_loss = 0.97474147, grad/param norm = 2.7584e-01, time/batch = 19.5368s	
4727/11350 (epoch 20.824), train_loss = 0.95350993, grad/param norm = 2.9231e-01, time/batch = 18.8633s	
4728/11350 (epoch 20.828), train_loss = 1.04297252, grad/param norm = 3.0831e-01, time/batch = 18.7958s	
4729/11350 (epoch 20.833), train_loss = 1.04574351, grad/param norm = 2.8528e-01, time/batch = 17.9408s	
4730/11350 (epoch 20.837), train_loss = 1.08850269, grad/param norm = 3.1376e-01, time/batch = 19.2025s	
4731/11350 (epoch 20.841), train_loss = 1.30737824, grad/param norm = 3.1481e-01, time/batch = 19.1883s	
4732/11350 (epoch 20.846), train_loss = 1.08096611, grad/param norm = 2.7459e-01, time/batch = 20.1992s	
4733/11350 (epoch 20.850), train_loss = 1.15238937, grad/param norm = 3.0149e-01, time/batch = 19.8691s	
4734/11350 (epoch 20.855), train_loss = 0.94090808, grad/param norm = 3.3316e-01, time/batch = 19.7740s	
4735/11350 (epoch 20.859), train_loss = 1.05845154, grad/param norm = 3.5822e-01, time/batch = 19.3753s	
4736/11350 (epoch 20.863), train_loss = 0.92800898, grad/param norm = 3.1081e-01, time/batch = 20.0459s	
4737/11350 (epoch 20.868), train_loss = 0.98564499, grad/param norm = 2.5224e-01, time/batch = 17.8409s	
4738/11350 (epoch 20.872), train_loss = 1.02460307, grad/param norm = 2.8715e-01, time/batch = 19.2162s	
4739/11350 (epoch 20.877), train_loss = 1.04389898, grad/param norm = 3.1460e-01, time/batch = 16.8621s	
4740/11350 (epoch 20.881), train_loss = 1.23855325, grad/param norm = 3.7178e-01, time/batch = 17.3564s	
4741/11350 (epoch 20.885), train_loss = 1.26712011, grad/param norm = 3.3347e-01, time/batch = 20.7798s	
4742/11350 (epoch 20.890), train_loss = 1.13172710, grad/param norm = 3.6456e-01, time/batch = 17.7095s	
4743/11350 (epoch 20.894), train_loss = 0.90282240, grad/param norm = 2.8810e-01, time/batch = 18.7752s	
4744/11350 (epoch 20.899), train_loss = 1.12298717, grad/param norm = 2.7751e-01, time/batch = 18.8632s	
4745/11350 (epoch 20.903), train_loss = 1.12902257, grad/param norm = 3.0357e-01, time/batch = 19.8733s	
4746/11350 (epoch 20.907), train_loss = 1.09983179, grad/param norm = 3.0465e-01, time/batch = 19.2144s	
4747/11350 (epoch 20.912), train_loss = 0.98188388, grad/param norm = 2.7463e-01, time/batch = 18.6215s	
4748/11350 (epoch 20.916), train_loss = 1.15431259, grad/param norm = 3.1182e-01, time/batch = 17.6971s	
4749/11350 (epoch 20.921), train_loss = 1.12731903, grad/param norm = 2.9612e-01, time/batch = 18.6682s	
4750/11350 (epoch 20.925), train_loss = 0.93394366, grad/param norm = 2.4599e-01, time/batch = 18.8609s	
4751/11350 (epoch 20.930), train_loss = 1.16074347, grad/param norm = 3.4286e-01, time/batch = 17.3631s	
4752/11350 (epoch 20.934), train_loss = 1.23769814, grad/param norm = 3.0466e-01, time/batch = 20.4472s	
4753/11350 (epoch 20.938), train_loss = 1.02327393, grad/param norm = 2.7637e-01, time/batch = 18.0197s	
4754/11350 (epoch 20.943), train_loss = 1.14376264, grad/param norm = 2.7263e-01, time/batch = 18.9496s	
4755/11350 (epoch 20.947), train_loss = 1.12745163, grad/param norm = 3.1275e-01, time/batch = 19.9630s	
4756/11350 (epoch 20.952), train_loss = 1.12290441, grad/param norm = 3.4423e-01, time/batch = 18.2020s	
4757/11350 (epoch 20.956), train_loss = 0.87401229, grad/param norm = 2.4449e-01, time/batch = 19.3614s	
4758/11350 (epoch 20.960), train_loss = 1.02261367, grad/param norm = 3.2437e-01, time/batch = 19.5439s	
4759/11350 (epoch 20.965), train_loss = 0.94844329, grad/param norm = 2.8733e-01, time/batch = 18.8556s	
4760/11350 (epoch 20.969), train_loss = 0.96665468, grad/param norm = 3.0028e-01, time/batch = 18.3092s	
4761/11350 (epoch 20.974), train_loss = 0.88690673, grad/param norm = 2.6213e-01, time/batch = 19.7994s	
4762/11350 (epoch 20.978), train_loss = 1.03281826, grad/param norm = 2.9079e-01, time/batch = 17.3465s	
4763/11350 (epoch 20.982), train_loss = 0.78438103, grad/param norm = 2.4445e-01, time/batch = 19.0420s	
4764/11350 (epoch 20.987), train_loss = 1.04123403, grad/param norm = 2.8323e-01, time/batch = 19.0399s	
4765/11350 (epoch 20.991), train_loss = 0.92328789, grad/param norm = 3.3259e-01, time/batch = 18.8480s	
4766/11350 (epoch 20.996), train_loss = 1.06213683, grad/param norm = 3.3280e-01, time/batch = 18.8542s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
4767/11350 (epoch 21.000), train_loss = 0.81192878, grad/param norm = 3.2440e-01, time/batch = 19.7095s	
4768/11350 (epoch 21.004), train_loss = 1.07522694, grad/param norm = 3.1966e-01, time/batch = 19.0457s	
4769/11350 (epoch 21.009), train_loss = 1.05024415, grad/param norm = 2.8079e-01, time/batch = 17.2010s	
4770/11350 (epoch 21.013), train_loss = 0.73862337, grad/param norm = 2.5456e-01, time/batch = 20.7818s	
4771/11350 (epoch 21.018), train_loss = 0.80065145, grad/param norm = 2.5654e-01, time/batch = 19.7724s	
4772/11350 (epoch 21.022), train_loss = 0.83243210, grad/param norm = 2.8680e-01, time/batch = 15.7374s	
4773/11350 (epoch 21.026), train_loss = 0.84304904, grad/param norm = 3.0418e-01, time/batch = 19.8735s	
4774/11350 (epoch 21.031), train_loss = 0.85479682, grad/param norm = 2.8262e-01, time/batch = 19.6982s	
4775/11350 (epoch 21.035), train_loss = 0.91089821, grad/param norm = 3.3101e-01, time/batch = 19.2705s	
4776/11350 (epoch 21.040), train_loss = 0.90709629, grad/param norm = 2.7842e-01, time/batch = 20.4524s	
4777/11350 (epoch 21.044), train_loss = 0.86656902, grad/param norm = 2.6475e-01, time/batch = 20.1950s	
4778/11350 (epoch 21.048), train_loss = 0.84450789, grad/param norm = 2.8006e-01, time/batch = 18.6984s	
4779/11350 (epoch 21.053), train_loss = 0.96345737, grad/param norm = 2.8247e-01, time/batch = 20.2908s	
4780/11350 (epoch 21.057), train_loss = 0.96750243, grad/param norm = 2.8391e-01, time/batch = 20.5306s	
4781/11350 (epoch 21.062), train_loss = 0.79501094, grad/param norm = 2.6383e-01, time/batch = 19.6057s	
4782/11350 (epoch 21.066), train_loss = 0.78447369, grad/param norm = 3.5940e-01, time/batch = 18.8714s	
4783/11350 (epoch 21.070), train_loss = 0.88797828, grad/param norm = 2.8562e-01, time/batch = 19.3486s	
4784/11350 (epoch 21.075), train_loss = 0.79010033, grad/param norm = 2.3413e-01, time/batch = 18.4663s	
4785/11350 (epoch 21.079), train_loss = 0.93298171, grad/param norm = 2.5754e-01, time/batch = 17.9284s	
4786/11350 (epoch 21.084), train_loss = 1.08900607, grad/param norm = 3.0000e-01, time/batch = 19.3337s	
4787/11350 (epoch 21.088), train_loss = 1.04974554, grad/param norm = 3.0883e-01, time/batch = 18.2699s	
4788/11350 (epoch 21.093), train_loss = 1.00328087, grad/param norm = 2.8303e-01, time/batch = 19.6073s	
4789/11350 (epoch 21.097), train_loss = 0.94686144, grad/param norm = 2.8376e-01, time/batch = 19.3735s	
4790/11350 (epoch 21.101), train_loss = 0.85956530, grad/param norm = 2.8705e-01, time/batch = 18.5843s	
4791/11350 (epoch 21.106), train_loss = 1.00389845, grad/param norm = 2.6853e-01, time/batch = 19.6280s	
4792/11350 (epoch 21.110), train_loss = 0.88682191, grad/param norm = 2.9464e-01, time/batch = 17.8716s	
4793/11350 (epoch 21.115), train_loss = 0.88958185, grad/param norm = 2.8416e-01, time/batch = 18.6155s	
4794/11350 (epoch 21.119), train_loss = 1.05740989, grad/param norm = 3.0987e-01, time/batch = 16.3453s	
4795/11350 (epoch 21.123), train_loss = 0.86548885, grad/param norm = 3.2536e-01, time/batch = 19.1984s	
4796/11350 (epoch 21.128), train_loss = 0.80816363, grad/param norm = 2.7204e-01, time/batch = 20.4499s	
4797/11350 (epoch 21.132), train_loss = 0.90667956, grad/param norm = 2.7530e-01, time/batch = 18.8686s	
4798/11350 (epoch 21.137), train_loss = 0.87794656, grad/param norm = 3.1117e-01, time/batch = 19.9532s	
4799/11350 (epoch 21.141), train_loss = 1.08518664, grad/param norm = 3.0484e-01, time/batch = 20.7906s	
4800/11350 (epoch 21.145), train_loss = 0.87197764, grad/param norm = 2.7108e-01, time/batch = 17.8351s	
4801/11350 (epoch 21.150), train_loss = 1.00689655, grad/param norm = 4.0672e-01, time/batch = 16.6426s	
4802/11350 (epoch 21.154), train_loss = 1.12561171, grad/param norm = 3.1518e-01, time/batch = 18.2838s	
4803/11350 (epoch 21.159), train_loss = 0.79718131, grad/param norm = 2.7457e-01, time/batch = 17.1898s	
4804/11350 (epoch 21.163), train_loss = 1.04135395, grad/param norm = 3.2060e-01, time/batch = 19.8417s	
4805/11350 (epoch 21.167), train_loss = 1.08404904, grad/param norm = 2.9504e-01, time/batch = 17.9522s	
4806/11350 (epoch 21.172), train_loss = 1.17277421, grad/param norm = 3.1538e-01, time/batch = 17.9450s	
4807/11350 (epoch 21.176), train_loss = 0.99026600, grad/param norm = 2.8208e-01, time/batch = 20.7644s	
4808/11350 (epoch 21.181), train_loss = 1.01301869, grad/param norm = 3.2686e-01, time/batch = 19.4684s	
4809/11350 (epoch 21.185), train_loss = 0.82064434, grad/param norm = 2.7930e-01, time/batch = 18.2801s	
4810/11350 (epoch 21.189), train_loss = 0.93661424, grad/param norm = 2.6179e-01, time/batch = 19.3032s	
4811/11350 (epoch 21.194), train_loss = 0.89929150, grad/param norm = 3.0351e-01, time/batch = 19.2135s	
4812/11350 (epoch 21.198), train_loss = 0.82073097, grad/param norm = 2.8930e-01, time/batch = 16.3832s	
4813/11350 (epoch 21.203), train_loss = 0.84630881, grad/param norm = 2.4159e-01, time/batch = 18.0343s	
4814/11350 (epoch 21.207), train_loss = 0.80633209, grad/param norm = 3.2950e-01, time/batch = 20.1166s	
4815/11350 (epoch 21.211), train_loss = 1.04157200, grad/param norm = 3.5217e-01, time/batch = 19.7078s	
4816/11350 (epoch 21.216), train_loss = 0.99514323, grad/param norm = 3.2275e-01, time/batch = 18.1772s	
4817/11350 (epoch 21.220), train_loss = 0.99883722, grad/param norm = 2.8532e-01, time/batch = 19.9501s	
4818/11350 (epoch 21.225), train_loss = 0.86792973, grad/param norm = 2.5377e-01, time/batch = 20.2860s	
4819/11350 (epoch 21.229), train_loss = 1.00680220, grad/param norm = 2.9051e-01, time/batch = 17.2641s	
4820/11350 (epoch 21.233), train_loss = 0.96193884, grad/param norm = 3.1313e-01, time/batch = 20.2839s	
4821/11350 (epoch 21.238), train_loss = 1.08273720, grad/param norm = 3.5019e-01, time/batch = 18.5400s	
4822/11350 (epoch 21.242), train_loss = 1.08832889, grad/param norm = 3.9830e-01, time/batch = 18.3742s	
4823/11350 (epoch 21.247), train_loss = 0.80787674, grad/param norm = 2.9185e-01, time/batch = 20.0396s	
4824/11350 (epoch 21.251), train_loss = 0.99670192, grad/param norm = 3.3015e-01, time/batch = 18.6247s	
4825/11350 (epoch 21.256), train_loss = 0.98104837, grad/param norm = 3.2752e-01, time/batch = 19.0978s	
4826/11350 (epoch 21.260), train_loss = 0.89317314, grad/param norm = 3.1807e-01, time/batch = 19.2170s	
4827/11350 (epoch 21.264), train_loss = 0.89167296, grad/param norm = 3.0476e-01, time/batch = 19.3096s	
4828/11350 (epoch 21.269), train_loss = 0.94493271, grad/param norm = 2.7356e-01, time/batch = 17.6937s	
4829/11350 (epoch 21.273), train_loss = 1.05159677, grad/param norm = 3.0614e-01, time/batch = 18.4376s	
4830/11350 (epoch 21.278), train_loss = 0.86969374, grad/param norm = 2.4204e-01, time/batch = 19.0329s	
4831/11350 (epoch 21.282), train_loss = 0.96040308, grad/param norm = 2.8772e-01, time/batch = 18.2875s	
4832/11350 (epoch 21.286), train_loss = 1.05188041, grad/param norm = 2.9846e-01, time/batch = 17.8007s	
4833/11350 (epoch 21.291), train_loss = 0.83928316, grad/param norm = 2.8429e-01, time/batch = 18.8752s	
4834/11350 (epoch 21.295), train_loss = 0.97121808, grad/param norm = 2.7984e-01, time/batch = 19.4736s	
4835/11350 (epoch 21.300), train_loss = 1.00129310, grad/param norm = 2.9310e-01, time/batch = 34.1743s	
4836/11350 (epoch 21.304), train_loss = 0.87813792, grad/param norm = 2.7250e-01, time/batch = 20.1929s	
4837/11350 (epoch 21.308), train_loss = 0.88450257, grad/param norm = 2.9274e-01, time/batch = 18.1199s	
4838/11350 (epoch 21.313), train_loss = 0.99365272, grad/param norm = 2.6022e-01, time/batch = 18.7219s	
4839/11350 (epoch 21.317), train_loss = 0.88373667, grad/param norm = 2.6358e-01, time/batch = 20.3661s	
4840/11350 (epoch 21.322), train_loss = 0.90063248, grad/param norm = 2.6704e-01, time/batch = 18.4333s	
4841/11350 (epoch 21.326), train_loss = 0.93386671, grad/param norm = 2.5147e-01, time/batch = 19.7870s	
4842/11350 (epoch 21.330), train_loss = 0.78535645, grad/param norm = 2.6581e-01, time/batch = 18.9489s	
4843/11350 (epoch 21.335), train_loss = 0.68084593, grad/param norm = 2.5340e-01, time/batch = 19.6872s	
4844/11350 (epoch 21.339), train_loss = 0.77984544, grad/param norm = 2.6083e-01, time/batch = 19.5299s	
4845/11350 (epoch 21.344), train_loss = 0.87516080, grad/param norm = 2.6009e-01, time/batch = 18.9554s	
4846/11350 (epoch 21.348), train_loss = 0.86579082, grad/param norm = 2.3993e-01, time/batch = 17.7660s	
4847/11350 (epoch 21.352), train_loss = 0.79231294, grad/param norm = 2.7261e-01, time/batch = 18.0367s	
4848/11350 (epoch 21.357), train_loss = 0.86271044, grad/param norm = 2.5152e-01, time/batch = 20.1142s	
4849/11350 (epoch 21.361), train_loss = 0.69891819, grad/param norm = 2.2030e-01, time/batch = 19.6040s	
4850/11350 (epoch 21.366), train_loss = 0.97949449, grad/param norm = 3.0903e-01, time/batch = 17.5682s	
4851/11350 (epoch 21.370), train_loss = 0.82203378, grad/param norm = 2.8723e-01, time/batch = 18.5507s	
4852/11350 (epoch 21.374), train_loss = 0.86204943, grad/param norm = 2.6188e-01, time/batch = 19.2774s	
4853/11350 (epoch 21.379), train_loss = 0.87769669, grad/param norm = 3.1480e-01, time/batch = 19.7638s	
4854/11350 (epoch 21.383), train_loss = 0.78990875, grad/param norm = 2.6365e-01, time/batch = 20.0307s	
4855/11350 (epoch 21.388), train_loss = 0.92786802, grad/param norm = 3.3244e-01, time/batch = 19.7104s	
4856/11350 (epoch 21.392), train_loss = 0.92675496, grad/param norm = 3.1166e-01, time/batch = 19.9462s	
4857/11350 (epoch 21.396), train_loss = 0.91802861, grad/param norm = 3.1707e-01, time/batch = 19.0442s	
4858/11350 (epoch 21.401), train_loss = 0.93493574, grad/param norm = 3.3542e-01, time/batch = 20.7046s	
4859/11350 (epoch 21.405), train_loss = 1.09625781, grad/param norm = 2.9729e-01, time/batch = 19.2608s	
4860/11350 (epoch 21.410), train_loss = 1.11346273, grad/param norm = 2.9918e-01, time/batch = 20.3729s	
4861/11350 (epoch 21.414), train_loss = 0.79665424, grad/param norm = 3.1568e-01, time/batch = 19.9467s	
4862/11350 (epoch 21.419), train_loss = 0.85250894, grad/param norm = 3.3860e-01, time/batch = 17.8598s	
4863/11350 (epoch 21.423), train_loss = 0.97411611, grad/param norm = 3.9869e-01, time/batch = 20.1958s	
4864/11350 (epoch 21.427), train_loss = 1.04475133, grad/param norm = 3.2875e-01, time/batch = 16.7784s	
4865/11350 (epoch 21.432), train_loss = 1.00396576, grad/param norm = 3.3430e-01, time/batch = 17.7790s	
4866/11350 (epoch 21.436), train_loss = 0.91008110, grad/param norm = 3.1327e-01, time/batch = 19.1994s	
4867/11350 (epoch 21.441), train_loss = 1.09077366, grad/param norm = 3.0586e-01, time/batch = 19.1895s	
4868/11350 (epoch 21.445), train_loss = 0.78253522, grad/param norm = 2.4339e-01, time/batch = 16.6423s	
4869/11350 (epoch 21.449), train_loss = 0.90502698, grad/param norm = 3.3318e-01, time/batch = 18.1031s	
4870/11350 (epoch 21.454), train_loss = 1.08633247, grad/param norm = 3.8227e-01, time/batch = 20.4475s	
4871/11350 (epoch 21.458), train_loss = 0.77938158, grad/param norm = 2.5847e-01, time/batch = 18.8714s	
4872/11350 (epoch 21.463), train_loss = 0.80478043, grad/param norm = 2.7071e-01, time/batch = 19.3703s	
4873/11350 (epoch 21.467), train_loss = 1.23171857, grad/param norm = 3.1994e-01, time/batch = 19.7070s	
4874/11350 (epoch 21.471), train_loss = 1.09413564, grad/param norm = 3.9943e-01, time/batch = 16.7674s	
4875/11350 (epoch 21.476), train_loss = 1.00189501, grad/param norm = 3.0924e-01, time/batch = 18.8728s	
4876/11350 (epoch 21.480), train_loss = 1.07806922, grad/param norm = 2.6377e-01, time/batch = 16.2122s	
4877/11350 (epoch 21.485), train_loss = 0.93508924, grad/param norm = 2.6047e-01, time/batch = 18.3840s	
4878/11350 (epoch 21.489), train_loss = 1.06481530, grad/param norm = 2.7540e-01, time/batch = 19.1015s	
4879/11350 (epoch 21.493), train_loss = 1.07356370, grad/param norm = 3.0538e-01, time/batch = 19.0173s	
4880/11350 (epoch 21.498), train_loss = 0.75034013, grad/param norm = 2.5912e-01, time/batch = 20.0414s	
4881/11350 (epoch 21.502), train_loss = 1.05409626, grad/param norm = 2.9226e-01, time/batch = 17.6768s	
4882/11350 (epoch 21.507), train_loss = 0.83986028, grad/param norm = 3.2286e-01, time/batch = 20.1096s	
4883/11350 (epoch 21.511), train_loss = 1.09916523, grad/param norm = 2.9934e-01, time/batch = 17.7982s	
4884/11350 (epoch 21.515), train_loss = 0.96350800, grad/param norm = 2.7700e-01, time/batch = 19.6122s	
4885/11350 (epoch 21.520), train_loss = 1.11252597, grad/param norm = 3.1717e-01, time/batch = 20.7160s	
4886/11350 (epoch 21.524), train_loss = 0.96554385, grad/param norm = 2.7443e-01, time/batch = 19.0347s	
4887/11350 (epoch 21.529), train_loss = 0.93343869, grad/param norm = 2.6897e-01, time/batch = 19.6726s	
4888/11350 (epoch 21.533), train_loss = 1.17136213, grad/param norm = 3.1957e-01, time/batch = 20.3691s	
4889/11350 (epoch 21.537), train_loss = 1.05900963, grad/param norm = 3.2988e-01, time/batch = 19.1208s	
4890/11350 (epoch 21.542), train_loss = 1.05020707, grad/param norm = 2.7025e-01, time/batch = 18.3590s	
4891/11350 (epoch 21.546), train_loss = 1.24502389, grad/param norm = 3.9026e-01, time/batch = 17.8583s	
4892/11350 (epoch 21.551), train_loss = 1.01807931, grad/param norm = 2.9562e-01, time/batch = 19.9514s	
4893/11350 (epoch 21.555), train_loss = 0.91408480, grad/param norm = 2.7879e-01, time/batch = 17.8700s	
4894/11350 (epoch 21.559), train_loss = 0.95546227, grad/param norm = 3.0428e-01, time/batch = 17.4592s	
4895/11350 (epoch 21.564), train_loss = 1.05466466, grad/param norm = 2.9280e-01, time/batch = 16.4690s	
4896/11350 (epoch 21.568), train_loss = 1.03681864, grad/param norm = 2.5217e-01, time/batch = 19.2060s	
4897/11350 (epoch 21.573), train_loss = 1.17291051, grad/param norm = 4.3965e-01, time/batch = 17.7754s	
4898/11350 (epoch 21.577), train_loss = 1.11379889, grad/param norm = 3.5557e-01, time/batch = 19.2959s	
4899/11350 (epoch 21.581), train_loss = 1.10741654, grad/param norm = 3.1816e-01, time/batch = 18.1197s	
4900/11350 (epoch 21.586), train_loss = 1.12631922, grad/param norm = 3.2779e-01, time/batch = 19.2765s	
4901/11350 (epoch 21.590), train_loss = 1.20194327, grad/param norm = 3.9445e-01, time/batch = 19.3709s	
4902/11350 (epoch 21.595), train_loss = 1.24309549, grad/param norm = 3.4993e-01, time/batch = 19.0976s	
4903/11350 (epoch 21.599), train_loss = 1.11575370, grad/param norm = 2.9665e-01, time/batch = 19.5303s	
4904/11350 (epoch 21.604), train_loss = 1.01696037, grad/param norm = 2.6467e-01, time/batch = 18.6221s	
4905/11350 (epoch 21.608), train_loss = 1.02866952, grad/param norm = 3.1678e-01, time/batch = 20.5361s	
4906/11350 (epoch 21.612), train_loss = 0.96499724, grad/param norm = 2.6047e-01, time/batch = 18.3524s	
4907/11350 (epoch 21.617), train_loss = 1.13294747, grad/param norm = 3.0672e-01, time/batch = 18.2702s	
4908/11350 (epoch 21.621), train_loss = 1.14971499, grad/param norm = 2.7595e-01, time/batch = 20.4445s	
4909/11350 (epoch 21.626), train_loss = 1.02126904, grad/param norm = 2.5284e-01, time/batch = 18.3738s	
4910/11350 (epoch 21.630), train_loss = 1.10336188, grad/param norm = 3.2389e-01, time/batch = 16.9597s	
4911/11350 (epoch 21.634), train_loss = 1.04388627, grad/param norm = 3.0035e-01, time/batch = 19.2183s	
4912/11350 (epoch 21.639), train_loss = 0.93814530, grad/param norm = 2.8276e-01, time/batch = 19.1241s	
4913/11350 (epoch 21.643), train_loss = 0.90995180, grad/param norm = 2.5669e-01, time/batch = 18.8588s	
4914/11350 (epoch 21.648), train_loss = 0.99761617, grad/param norm = 2.6634e-01, time/batch = 15.7751s	
4915/11350 (epoch 21.652), train_loss = 0.92774522, grad/param norm = 2.9605e-01, time/batch = 17.4468s	
4916/11350 (epoch 21.656), train_loss = 1.04846007, grad/param norm = 3.0081e-01, time/batch = 19.0244s	
4917/11350 (epoch 21.661), train_loss = 1.16601124, grad/param norm = 3.3304e-01, time/batch = 20.1204s	
4918/11350 (epoch 21.665), train_loss = 1.05953571, grad/param norm = 3.5389e-01, time/batch = 18.6967s	
4919/11350 (epoch 21.670), train_loss = 1.04916477, grad/param norm = 3.2875e-01, time/batch = 19.4319s	
4920/11350 (epoch 21.674), train_loss = 0.95408784, grad/param norm = 2.5959e-01, time/batch = 18.1186s	
4921/11350 (epoch 21.678), train_loss = 1.00308056, grad/param norm = 2.6206e-01, time/batch = 20.2856s	
4922/11350 (epoch 21.683), train_loss = 0.92894538, grad/param norm = 2.8091e-01, time/batch = 18.2883s	
4923/11350 (epoch 21.687), train_loss = 0.88918454, grad/param norm = 2.6190e-01, time/batch = 20.2844s	
4924/11350 (epoch 21.692), train_loss = 1.33704448, grad/param norm = 4.5607e-01, time/batch = 19.7938s	
4925/11350 (epoch 21.696), train_loss = 1.17526098, grad/param norm = 3.2183e-01, time/batch = 18.8461s	
4926/11350 (epoch 21.700), train_loss = 1.11387742, grad/param norm = 3.2628e-01, time/batch = 18.0392s	
4927/11350 (epoch 21.705), train_loss = 1.17462426, grad/param norm = 3.1971e-01, time/batch = 19.7984s	
4928/11350 (epoch 21.709), train_loss = 1.14450802, grad/param norm = 3.1190e-01, time/batch = 15.8114s	
4929/11350 (epoch 21.714), train_loss = 1.02273771, grad/param norm = 2.9625e-01, time/batch = 18.0101s	
4930/11350 (epoch 21.718), train_loss = 0.89506332, grad/param norm = 2.8045e-01, time/batch = 19.2949s	
4931/11350 (epoch 21.722), train_loss = 1.06741961, grad/param norm = 3.7770e-01, time/batch = 19.3833s	
4932/11350 (epoch 21.727), train_loss = 1.05006768, grad/param norm = 3.1318e-01, time/batch = 17.8626s	
4933/11350 (epoch 21.731), train_loss = 1.08713318, grad/param norm = 3.0059e-01, time/batch = 18.0154s	
4934/11350 (epoch 21.736), train_loss = 0.98122259, grad/param norm = 3.2609e-01, time/batch = 20.0238s	
4935/11350 (epoch 21.740), train_loss = 1.02357011, grad/param norm = 3.1031e-01, time/batch = 17.2840s	
4936/11350 (epoch 21.744), train_loss = 1.04892549, grad/param norm = 3.0651e-01, time/batch = 18.3527s	
4937/11350 (epoch 21.749), train_loss = 1.09365655, grad/param norm = 3.1106e-01, time/batch = 19.8734s	
4938/11350 (epoch 21.753), train_loss = 1.12757316, grad/param norm = 3.8706e-01, time/batch = 18.7002s	
4939/11350 (epoch 21.758), train_loss = 0.96987264, grad/param norm = 2.7866e-01, time/batch = 19.2070s	
4940/11350 (epoch 21.762), train_loss = 1.11281760, grad/param norm = 2.9677e-01, time/batch = 19.3889s	
4941/11350 (epoch 21.767), train_loss = 1.10298462, grad/param norm = 2.6652e-01, time/batch = 18.6780s	
4942/11350 (epoch 21.771), train_loss = 1.22973628, grad/param norm = 3.0287e-01, time/batch = 18.5467s	
4943/11350 (epoch 21.775), train_loss = 0.98827578, grad/param norm = 2.7487e-01, time/batch = 21.0311s	
4944/11350 (epoch 21.780), train_loss = 1.11007512, grad/param norm = 2.9206e-01, time/batch = 19.2744s	
4945/11350 (epoch 21.784), train_loss = 0.99054319, grad/param norm = 2.9465e-01, time/batch = 19.2871s	
4946/11350 (epoch 21.789), train_loss = 1.02552106, grad/param norm = 2.8972e-01, time/batch = 19.2707s	
4947/11350 (epoch 21.793), train_loss = 1.12797282, grad/param norm = 2.7780e-01, time/batch = 19.5227s	
4948/11350 (epoch 21.797), train_loss = 0.98924182, grad/param norm = 2.5502e-01, time/batch = 19.2941s	
4949/11350 (epoch 21.802), train_loss = 1.10527966, grad/param norm = 3.1786e-01, time/batch = 16.5948s	
4950/11350 (epoch 21.806), train_loss = 1.10835607, grad/param norm = 2.8418e-01, time/batch = 20.2768s	
4951/11350 (epoch 21.811), train_loss = 1.04142573, grad/param norm = 2.9644e-01, time/batch = 19.6666s	
4952/11350 (epoch 21.815), train_loss = 0.97397997, grad/param norm = 2.7507e-01, time/batch = 20.7006s	
4953/11350 (epoch 21.819), train_loss = 0.93980715, grad/param norm = 2.8338e-01, time/batch = 18.8711s	
4954/11350 (epoch 21.824), train_loss = 0.92227949, grad/param norm = 3.3747e-01, time/batch = 18.0000s	
4955/11350 (epoch 21.828), train_loss = 1.00655180, grad/param norm = 3.2433e-01, time/batch = 19.0404s	
4956/11350 (epoch 21.833), train_loss = 1.03123768, grad/param norm = 2.9888e-01, time/batch = 19.9494s	
4957/11350 (epoch 21.837), train_loss = 1.05655129, grad/param norm = 3.0325e-01, time/batch = 19.0224s	
4958/11350 (epoch 21.841), train_loss = 1.28221899, grad/param norm = 3.3832e-01, time/batch = 19.8452s	
4959/11350 (epoch 21.846), train_loss = 1.06312512, grad/param norm = 2.9732e-01, time/batch = 20.0254s	
4960/11350 (epoch 21.850), train_loss = 1.12381819, grad/param norm = 2.9881e-01, time/batch = 17.7635s	
4961/11350 (epoch 21.855), train_loss = 0.90483956, grad/param norm = 2.9072e-01, time/batch = 16.6000s	
4962/11350 (epoch 21.859), train_loss = 1.00262992, grad/param norm = 3.3427e-01, time/batch = 19.4374s	
4963/11350 (epoch 21.863), train_loss = 0.89227504, grad/param norm = 2.8002e-01, time/batch = 18.3621s	
4964/11350 (epoch 21.868), train_loss = 0.95391670, grad/param norm = 2.4984e-01, time/batch = 15.5808s	
4965/11350 (epoch 21.872), train_loss = 0.99754133, grad/param norm = 2.8659e-01, time/batch = 18.1351s	
4966/11350 (epoch 21.877), train_loss = 1.02438019, grad/param norm = 3.3476e-01, time/batch = 19.2023s	
4967/11350 (epoch 21.881), train_loss = 1.20589924, grad/param norm = 3.2561e-01, time/batch = 19.3622s	
4968/11350 (epoch 21.885), train_loss = 1.21034024, grad/param norm = 3.1183e-01, time/batch = 18.1084s	
4969/11350 (epoch 21.890), train_loss = 1.09567483, grad/param norm = 3.5797e-01, time/batch = 20.2924s	
4970/11350 (epoch 21.894), train_loss = 0.88104009, grad/param norm = 2.8307e-01, time/batch = 18.0251s	
4971/11350 (epoch 21.899), train_loss = 1.10496874, grad/param norm = 2.8992e-01, time/batch = 19.7889s	
4972/11350 (epoch 21.903), train_loss = 1.08496257, grad/param norm = 3.2624e-01, time/batch = 20.3607s	
4973/11350 (epoch 21.907), train_loss = 1.06854676, grad/param norm = 3.0165e-01, time/batch = 19.2003s	
4974/11350 (epoch 21.912), train_loss = 0.94338014, grad/param norm = 2.6112e-01, time/batch = 19.1096s	
4975/11350 (epoch 21.916), train_loss = 1.11871376, grad/param norm = 3.4067e-01, time/batch = 19.6304s	
4976/11350 (epoch 21.921), train_loss = 1.10431005, grad/param norm = 3.1423e-01, time/batch = 17.1116s	
4977/11350 (epoch 21.925), train_loss = 0.89826019, grad/param norm = 2.5267e-01, time/batch = 19.9468s	
4978/11350 (epoch 21.930), train_loss = 1.12561432, grad/param norm = 3.6700e-01, time/batch = 18.2951s	
4979/11350 (epoch 21.934), train_loss = 1.19650119, grad/param norm = 2.8863e-01, time/batch = 18.1980s	
4980/11350 (epoch 21.938), train_loss = 0.98681417, grad/param norm = 2.7607e-01, time/batch = 20.1185s	
4981/11350 (epoch 21.943), train_loss = 1.11327192, grad/param norm = 2.9010e-01, time/batch = 18.2078s	
4982/11350 (epoch 21.947), train_loss = 1.09765578, grad/param norm = 3.5911e-01, time/batch = 17.4605s	
4983/11350 (epoch 21.952), train_loss = 1.08306968, grad/param norm = 3.0578e-01, time/batch = 18.7528s	
4984/11350 (epoch 21.956), train_loss = 0.85316804, grad/param norm = 2.9082e-01, time/batch = 18.6861s	
4985/11350 (epoch 21.960), train_loss = 0.97844490, grad/param norm = 3.0017e-01, time/batch = 19.1918s	
4986/11350 (epoch 21.965), train_loss = 0.90841054, grad/param norm = 2.9136e-01, time/batch = 19.3690s	
4987/11350 (epoch 21.969), train_loss = 0.94827192, grad/param norm = 3.6559e-01, time/batch = 19.6203s	
4988/11350 (epoch 21.974), train_loss = 0.87524592, grad/param norm = 2.9034e-01, time/batch = 20.1137s	
4989/11350 (epoch 21.978), train_loss = 1.01836933, grad/param norm = 3.1156e-01, time/batch = 18.4378s	
4990/11350 (epoch 21.982), train_loss = 0.75921768, grad/param norm = 2.5926e-01, time/batch = 18.0346s	
4991/11350 (epoch 21.987), train_loss = 1.01088687, grad/param norm = 3.0607e-01, time/batch = 20.6093s	
4992/11350 (epoch 21.991), train_loss = 0.90347079, grad/param norm = 3.5541e-01, time/batch = 18.7726s	
4993/11350 (epoch 21.996), train_loss = 1.05001180, grad/param norm = 3.6880e-01, time/batch = 19.2924s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
4994/11350 (epoch 22.000), train_loss = 0.77015356, grad/param norm = 2.7963e-01, time/batch = 19.3779s	
4995/11350 (epoch 22.004), train_loss = 1.04350268, grad/param norm = 3.1407e-01, time/batch = 17.9354s	
4996/11350 (epoch 22.009), train_loss = 1.02553373, grad/param norm = 2.9697e-01, time/batch = 20.0423s	
4997/11350 (epoch 22.013), train_loss = 0.70887739, grad/param norm = 2.5182e-01, time/batch = 18.2716s	
4998/11350 (epoch 22.018), train_loss = 0.78849867, grad/param norm = 2.6276e-01, time/batch = 18.8674s	
4999/11350 (epoch 22.022), train_loss = 0.79861379, grad/param norm = 2.7826e-01, time/batch = 19.8582s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch22.03_1.8080.t7	
5000/11350 (epoch 22.026), train_loss = 0.80151019, grad/param norm = 2.9556e-01, time/batch = 19.7065s	
5001/11350 (epoch 22.031), train_loss = 1.60497160, grad/param norm = 5.2571e-01, time/batch = 17.2006s	
5002/11350 (epoch 22.035), train_loss = 0.88031377, grad/param norm = 3.4903e-01, time/batch = 18.0152s	
5003/11350 (epoch 22.040), train_loss = 0.88898241, grad/param norm = 3.7277e-01, time/batch = 20.2056s	
5004/11350 (epoch 22.044), train_loss = 0.85114917, grad/param norm = 2.5775e-01, time/batch = 18.6091s	
5005/11350 (epoch 22.048), train_loss = 0.83639363, grad/param norm = 2.9173e-01, time/batch = 18.1807s	
5006/11350 (epoch 22.053), train_loss = 0.92358809, grad/param norm = 2.8180e-01, time/batch = 19.0522s	
5007/11350 (epoch 22.057), train_loss = 0.95157350, grad/param norm = 3.2685e-01, time/batch = 19.3025s	
5008/11350 (epoch 22.062), train_loss = 0.77344001, grad/param norm = 2.7679e-01, time/batch = 18.2057s	
5009/11350 (epoch 22.066), train_loss = 0.76880794, grad/param norm = 3.2220e-01, time/batch = 20.8704s	
5010/11350 (epoch 22.070), train_loss = 0.86298016, grad/param norm = 2.9430e-01, time/batch = 19.7069s	
5011/11350 (epoch 22.075), train_loss = 0.76038049, grad/param norm = 2.4812e-01, time/batch = 19.8571s	
5012/11350 (epoch 22.079), train_loss = 0.90360448, grad/param norm = 2.6828e-01, time/batch = 19.8842s	
5013/11350 (epoch 22.084), train_loss = 1.04305038, grad/param norm = 3.0017e-01, time/batch = 17.5205s	
5014/11350 (epoch 22.088), train_loss = 1.01364761, grad/param norm = 3.0110e-01, time/batch = 18.6208s	
5015/11350 (epoch 22.093), train_loss = 0.96057405, grad/param norm = 2.7134e-01, time/batch = 18.7583s	
5016/11350 (epoch 22.097), train_loss = 0.93220888, grad/param norm = 3.1602e-01, time/batch = 19.6935s	
5017/11350 (epoch 22.101), train_loss = 0.83268726, grad/param norm = 2.9330e-01, time/batch = 18.7916s	
5018/11350 (epoch 22.106), train_loss = 0.97207243, grad/param norm = 2.9438e-01, time/batch = 17.7735s	
5019/11350 (epoch 22.110), train_loss = 0.85226391, grad/param norm = 2.8145e-01, time/batch = 20.9487s	
5020/11350 (epoch 22.115), train_loss = 0.87488432, grad/param norm = 2.9897e-01, time/batch = 24.1249s	
5021/11350 (epoch 22.119), train_loss = 1.01572176, grad/param norm = 3.0640e-01, time/batch = 28.4417s	
5022/11350 (epoch 22.123), train_loss = 0.82630563, grad/param norm = 2.7354e-01, time/batch = 19.6907s	
5023/11350 (epoch 22.128), train_loss = 0.78056950, grad/param norm = 3.1005e-01, time/batch = 17.6671s	
5024/11350 (epoch 22.132), train_loss = 0.86303930, grad/param norm = 2.7013e-01, time/batch = 18.2707s	
5025/11350 (epoch 22.137), train_loss = 0.84055849, grad/param norm = 2.8159e-01, time/batch = 16.9737s	
5026/11350 (epoch 22.141), train_loss = 1.06251013, grad/param norm = 3.2784e-01, time/batch = 18.9400s	
5027/11350 (epoch 22.145), train_loss = 0.83581578, grad/param norm = 2.6419e-01, time/batch = 20.4507s	
5028/11350 (epoch 22.150), train_loss = 0.96166134, grad/param norm = 3.5113e-01, time/batch = 19.2943s	
5029/11350 (epoch 22.154), train_loss = 1.07948957, grad/param norm = 2.9565e-01, time/batch = 18.3687s	
5030/11350 (epoch 22.159), train_loss = 0.77682547, grad/param norm = 2.7273e-01, time/batch = 19.0558s	
5031/11350 (epoch 22.163), train_loss = 1.00774533, grad/param norm = 3.3090e-01, time/batch = 18.5550s	
5032/11350 (epoch 22.167), train_loss = 1.06129883, grad/param norm = 3.0200e-01, time/batch = 17.4527s	
5033/11350 (epoch 22.172), train_loss = 1.12941708, grad/param norm = 2.9105e-01, time/batch = 16.7994s	
5034/11350 (epoch 22.176), train_loss = 0.95229913, grad/param norm = 2.9666e-01, time/batch = 18.0429s	
5035/11350 (epoch 22.181), train_loss = 0.98600222, grad/param norm = 3.4819e-01, time/batch = 19.2860s	
5036/11350 (epoch 22.185), train_loss = 0.81393541, grad/param norm = 3.1201e-01, time/batch = 18.6013s	
5037/11350 (epoch 22.189), train_loss = 0.90685378, grad/param norm = 2.6957e-01, time/batch = 17.4124s	
5038/11350 (epoch 22.194), train_loss = 0.86830266, grad/param norm = 3.0067e-01, time/batch = 18.4566s	
5039/11350 (epoch 22.198), train_loss = 0.78192007, grad/param norm = 2.8865e-01, time/batch = 17.4374s	
5040/11350 (epoch 22.203), train_loss = 0.81645673, grad/param norm = 2.7221e-01, time/batch = 18.9661s	
5041/11350 (epoch 22.207), train_loss = 0.77926365, grad/param norm = 3.6848e-01, time/batch = 16.5861s	
5042/11350 (epoch 22.211), train_loss = 1.01643333, grad/param norm = 3.6504e-01, time/batch = 17.8559s	
5043/11350 (epoch 22.216), train_loss = 0.97449030, grad/param norm = 3.3141e-01, time/batch = 19.0288s	
5044/11350 (epoch 22.220), train_loss = 0.97746564, grad/param norm = 2.8501e-01, time/batch = 18.9651s	
5045/11350 (epoch 22.225), train_loss = 0.84868806, grad/param norm = 2.6269e-01, time/batch = 18.4633s	
5046/11350 (epoch 22.229), train_loss = 0.97393509, grad/param norm = 2.8653e-01, time/batch = 18.0378s	
5047/11350 (epoch 22.233), train_loss = 0.92063859, grad/param norm = 2.7324e-01, time/batch = 19.2013s	
5048/11350 (epoch 22.238), train_loss = 1.05542953, grad/param norm = 3.7571e-01, time/batch = 19.3808s	
5049/11350 (epoch 22.242), train_loss = 1.05795547, grad/param norm = 3.7583e-01, time/batch = 18.1241s	
5050/11350 (epoch 22.247), train_loss = 0.78326575, grad/param norm = 2.5698e-01, time/batch = 18.5294s	
5051/11350 (epoch 22.251), train_loss = 0.97814701, grad/param norm = 3.1779e-01, time/batch = 19.9525s	
5052/11350 (epoch 22.256), train_loss = 0.93771413, grad/param norm = 2.9608e-01, time/batch = 18.1841s	
5053/11350 (epoch 22.260), train_loss = 0.85377809, grad/param norm = 3.1442e-01, time/batch = 19.2877s	
5054/11350 (epoch 22.264), train_loss = 0.86594821, grad/param norm = 3.4306e-01, time/batch = 19.6167s	
5055/11350 (epoch 22.269), train_loss = 0.92060637, grad/param norm = 2.9955e-01, time/batch = 18.2678s	
5056/11350 (epoch 22.273), train_loss = 1.01507132, grad/param norm = 2.9210e-01, time/batch = 18.7848s	
5057/11350 (epoch 22.278), train_loss = 0.84095825, grad/param norm = 2.3883e-01, time/batch = 20.1227s	
5058/11350 (epoch 22.282), train_loss = 0.92333497, grad/param norm = 2.8816e-01, time/batch = 16.4523s	
5059/11350 (epoch 22.286), train_loss = 1.02630558, grad/param norm = 2.8799e-01, time/batch = 20.1106s	
5060/11350 (epoch 22.291), train_loss = 0.81268220, grad/param norm = 2.9376e-01, time/batch = 20.6981s	
5061/11350 (epoch 22.295), train_loss = 0.92754505, grad/param norm = 2.9130e-01, time/batch = 19.7037s	
5062/11350 (epoch 22.300), train_loss = 0.97262875, grad/param norm = 2.7234e-01, time/batch = 16.1376s	
5063/11350 (epoch 22.304), train_loss = 0.85696437, grad/param norm = 2.8852e-01, time/batch = 19.2684s	
5064/11350 (epoch 22.308), train_loss = 0.85205275, grad/param norm = 2.8294e-01, time/batch = 17.8643s	
5065/11350 (epoch 22.313), train_loss = 0.95902135, grad/param norm = 2.5954e-01, time/batch = 17.4456s	
5066/11350 (epoch 22.317), train_loss = 0.85490371, grad/param norm = 2.6064e-01, time/batch = 19.9597s	
5067/11350 (epoch 22.322), train_loss = 0.87433465, grad/param norm = 3.0641e-01, time/batch = 20.0324s	
5068/11350 (epoch 22.326), train_loss = 0.91925600, grad/param norm = 2.8814e-01, time/batch = 4.5424s	
5069/11350 (epoch 22.330), train_loss = 0.76058091, grad/param norm = 2.6181e-01, time/batch = 0.6821s	
5070/11350 (epoch 22.335), train_loss = 0.65994438, grad/param norm = 2.7330e-01, time/batch = 0.6900s	
5071/11350 (epoch 22.339), train_loss = 0.74062650, grad/param norm = 2.8414e-01, time/batch = 0.6839s	
5072/11350 (epoch 22.344), train_loss = 0.82704286, grad/param norm = 2.3062e-01, time/batch = 0.6825s	
5073/11350 (epoch 22.348), train_loss = 0.84202188, grad/param norm = 2.3961e-01, time/batch = 0.6852s	
5074/11350 (epoch 22.352), train_loss = 0.76863001, grad/param norm = 3.7206e-01, time/batch = 0.6850s	
5075/11350 (epoch 22.357), train_loss = 0.84330764, grad/param norm = 2.6501e-01, time/batch = 0.8540s	
5076/11350 (epoch 22.361), train_loss = 0.68967094, grad/param norm = 2.3089e-01, time/batch = 1.0162s	
5077/11350 (epoch 22.366), train_loss = 0.92932006, grad/param norm = 3.0247e-01, time/batch = 1.0094s	
5078/11350 (epoch 22.370), train_loss = 0.77954522, grad/param norm = 2.8952e-01, time/batch = 1.0099s	
5079/11350 (epoch 22.374), train_loss = 0.84387261, grad/param norm = 2.8954e-01, time/batch = 1.0060s	
5080/11350 (epoch 22.379), train_loss = 0.84028186, grad/param norm = 2.7346e-01, time/batch = 1.5215s	
5081/11350 (epoch 22.383), train_loss = 0.77019900, grad/param norm = 2.7265e-01, time/batch = 1.8921s	
5082/11350 (epoch 22.388), train_loss = 0.90357828, grad/param norm = 3.2720e-01, time/batch = 2.0341s	
5083/11350 (epoch 22.392), train_loss = 0.90359946, grad/param norm = 3.2432e-01, time/batch = 17.9522s	
5084/11350 (epoch 22.396), train_loss = 0.88381686, grad/param norm = 3.3583e-01, time/batch = 20.3716s	
5085/11350 (epoch 22.401), train_loss = 0.90187861, grad/param norm = 4.0604e-01, time/batch = 19.0091s	
5086/11350 (epoch 22.405), train_loss = 1.11128919, grad/param norm = 4.0454e-01, time/batch = 19.2195s	
5087/11350 (epoch 22.410), train_loss = 1.12071534, grad/param norm = 3.9600e-01, time/batch = 20.8661s	
5088/11350 (epoch 22.414), train_loss = 0.77471115, grad/param norm = 3.7714e-01, time/batch = 17.9480s	
5089/11350 (epoch 22.419), train_loss = 0.82802864, grad/param norm = 3.4130e-01, time/batch = 20.4335s	
5090/11350 (epoch 22.423), train_loss = 0.92211031, grad/param norm = 3.1043e-01, time/batch = 20.3514s	
5091/11350 (epoch 22.427), train_loss = 1.00026157, grad/param norm = 3.1773e-01, time/batch = 18.6869s	
5092/11350 (epoch 22.432), train_loss = 0.95522186, grad/param norm = 3.2964e-01, time/batch = 19.0321s	
5093/11350 (epoch 22.436), train_loss = 0.87936447, grad/param norm = 3.6300e-01, time/batch = 20.3634s	
5094/11350 (epoch 22.441), train_loss = 1.07030280, grad/param norm = 3.2888e-01, time/batch = 18.2648s	
5095/11350 (epoch 22.445), train_loss = 0.78335510, grad/param norm = 2.9377e-01, time/batch = 18.5317s	
5096/11350 (epoch 22.449), train_loss = 0.87076518, grad/param norm = 2.9139e-01, time/batch = 19.1292s	
5097/11350 (epoch 22.454), train_loss = 1.02780246, grad/param norm = 3.1812e-01, time/batch = 17.9512s	
5098/11350 (epoch 22.458), train_loss = 0.74478949, grad/param norm = 2.7372e-01, time/batch = 17.7890s	
5099/11350 (epoch 22.463), train_loss = 0.79157382, grad/param norm = 2.9080e-01, time/batch = 18.9527s	
5100/11350 (epoch 22.467), train_loss = 1.19981625, grad/param norm = 3.1135e-01, time/batch = 16.0978s	
5101/11350 (epoch 22.471), train_loss = 1.05683790, grad/param norm = 4.0154e-01, time/batch = 19.1038s	
5102/11350 (epoch 22.476), train_loss = 0.96287855, grad/param norm = 2.8080e-01, time/batch = 19.7850s	
5103/11350 (epoch 22.480), train_loss = 1.07919645, grad/param norm = 3.2652e-01, time/batch = 19.9348s	
5104/11350 (epoch 22.485), train_loss = 0.91231611, grad/param norm = 2.7348e-01, time/batch = 20.6708s	
5105/11350 (epoch 22.489), train_loss = 1.06602570, grad/param norm = 3.1052e-01, time/batch = 19.2886s	
5106/11350 (epoch 22.493), train_loss = 1.05103977, grad/param norm = 3.0452e-01, time/batch = 19.8645s	
5107/11350 (epoch 22.498), train_loss = 0.72343606, grad/param norm = 2.6992e-01, time/batch = 18.0435s	
5108/11350 (epoch 22.502), train_loss = 1.02782670, grad/param norm = 2.9618e-01, time/batch = 17.7082s	
5109/11350 (epoch 22.507), train_loss = 0.79758150, grad/param norm = 2.6923e-01, time/batch = 20.6980s	
5110/11350 (epoch 22.511), train_loss = 1.08150055, grad/param norm = 2.9381e-01, time/batch = 16.5846s	
5111/11350 (epoch 22.515), train_loss = 0.94180020, grad/param norm = 2.6978e-01, time/batch = 19.2747s	
5112/11350 (epoch 22.520), train_loss = 1.07922800, grad/param norm = 3.0861e-01, time/batch = 19.5410s	
5113/11350 (epoch 22.524), train_loss = 0.91417167, grad/param norm = 2.6602e-01, time/batch = 17.3562s	
5114/11350 (epoch 22.529), train_loss = 0.90202615, grad/param norm = 2.7499e-01, time/batch = 18.3825s	
5115/11350 (epoch 22.533), train_loss = 1.11618351, grad/param norm = 2.7197e-01, time/batch = 17.4605s	
5116/11350 (epoch 22.537), train_loss = 1.01452897, grad/param norm = 3.0021e-01, time/batch = 18.7084s	
5117/11350 (epoch 22.542), train_loss = 1.00488490, grad/param norm = 2.7376e-01, time/batch = 19.0392s	
5118/11350 (epoch 22.546), train_loss = 1.21302537, grad/param norm = 3.5566e-01, time/batch = 18.8772s	
5119/11350 (epoch 22.551), train_loss = 0.99033369, grad/param norm = 3.1601e-01, time/batch = 19.2864s	
5120/11350 (epoch 22.555), train_loss = 0.88132371, grad/param norm = 2.7920e-01, time/batch = 18.9325s	
5121/11350 (epoch 22.559), train_loss = 0.90366348, grad/param norm = 2.7428e-01, time/batch = 18.0377s	
5122/11350 (epoch 22.564), train_loss = 1.03235722, grad/param norm = 3.4454e-01, time/batch = 17.9464s	
5123/11350 (epoch 22.568), train_loss = 1.00630622, grad/param norm = 2.6008e-01, time/batch = 20.2747s	
5124/11350 (epoch 22.573), train_loss = 1.11344417, grad/param norm = 3.1998e-01, time/batch = 19.2666s	
5125/11350 (epoch 22.577), train_loss = 1.07805171, grad/param norm = 4.1038e-01, time/batch = 20.3754s	
5126/11350 (epoch 22.581), train_loss = 1.05873325, grad/param norm = 3.0171e-01, time/batch = 19.0172s	
5127/11350 (epoch 22.586), train_loss = 1.07659550, grad/param norm = 3.5734e-01, time/batch = 19.4500s	
5128/11350 (epoch 22.590), train_loss = 1.15341183, grad/param norm = 3.2706e-01, time/batch = 19.3708s	
5129/11350 (epoch 22.595), train_loss = 1.19395697, grad/param norm = 3.1887e-01, time/batch = 16.9577s	
5130/11350 (epoch 22.599), train_loss = 1.08569270, grad/param norm = 3.1291e-01, time/batch = 20.2782s	
5131/11350 (epoch 22.604), train_loss = 0.99758204, grad/param norm = 2.9521e-01, time/batch = 19.6237s	
5132/11350 (epoch 22.608), train_loss = 0.99028605, grad/param norm = 3.7388e-01, time/batch = 18.1974s	
5133/11350 (epoch 22.612), train_loss = 0.94078200, grad/param norm = 2.7929e-01, time/batch = 16.8339s	
5134/11350 (epoch 22.617), train_loss = 1.08878935, grad/param norm = 3.2379e-01, time/batch = 19.1334s	
5135/11350 (epoch 22.621), train_loss = 1.12027468, grad/param norm = 2.8606e-01, time/batch = 18.5971s	
5136/11350 (epoch 22.626), train_loss = 0.99262843, grad/param norm = 2.8142e-01, time/batch = 20.0365s	
5137/11350 (epoch 22.630), train_loss = 1.07943988, grad/param norm = 3.2769e-01, time/batch = 20.7020s	
5138/11350 (epoch 22.634), train_loss = 1.01336475, grad/param norm = 3.1143e-01, time/batch = 18.4490s	
5139/11350 (epoch 22.639), train_loss = 0.91130126, grad/param norm = 2.9641e-01, time/batch = 18.7867s	
5140/11350 (epoch 22.643), train_loss = 0.88944955, grad/param norm = 2.9478e-01, time/batch = 19.2675s	
5141/11350 (epoch 22.648), train_loss = 0.96397244, grad/param norm = 2.8650e-01, time/batch = 18.4387s	
5142/11350 (epoch 22.652), train_loss = 0.89070434, grad/param norm = 3.0200e-01, time/batch = 18.1144s	
5143/11350 (epoch 22.656), train_loss = 1.02052381, grad/param norm = 2.7909e-01, time/batch = 16.6281s	
5144/11350 (epoch 22.661), train_loss = 1.13713003, grad/param norm = 3.3806e-01, time/batch = 15.4584s	
5145/11350 (epoch 22.665), train_loss = 0.99726977, grad/param norm = 3.4184e-01, time/batch = 17.9509s	
5146/11350 (epoch 22.670), train_loss = 1.00441757, grad/param norm = 2.9869e-01, time/batch = 19.6178s	
5147/11350 (epoch 22.674), train_loss = 0.93346371, grad/param norm = 2.6856e-01, time/batch = 17.5927s	
5148/11350 (epoch 22.678), train_loss = 0.97209215, grad/param norm = 2.6649e-01, time/batch = 18.6817s	
5149/11350 (epoch 22.683), train_loss = 0.90002733, grad/param norm = 3.0071e-01, time/batch = 19.4353s	
5150/11350 (epoch 22.687), train_loss = 0.88303004, grad/param norm = 3.3366e-01, time/batch = 20.1167s	
5151/11350 (epoch 22.692), train_loss = 1.29413147, grad/param norm = 4.2139e-01, time/batch = 17.7087s	
5152/11350 (epoch 22.696), train_loss = 1.14846157, grad/param norm = 3.5100e-01, time/batch = 19.2847s	
5153/11350 (epoch 22.700), train_loss = 1.08868741, grad/param norm = 3.5780e-01, time/batch = 20.2914s	
5154/11350 (epoch 22.705), train_loss = 1.13375804, grad/param norm = 3.3359e-01, time/batch = 18.3657s	
5155/11350 (epoch 22.709), train_loss = 1.13445672, grad/param norm = 3.1196e-01, time/batch = 19.5282s	
5156/11350 (epoch 22.714), train_loss = 1.00796799, grad/param norm = 3.6910e-01, time/batch = 18.2915s	
5157/11350 (epoch 22.718), train_loss = 0.85896832, grad/param norm = 3.1825e-01, time/batch = 16.5997s	
5158/11350 (epoch 22.722), train_loss = 1.02123521, grad/param norm = 3.7136e-01, time/batch = 19.5955s	
5159/11350 (epoch 22.727), train_loss = 1.02066160, grad/param norm = 3.4443e-01, time/batch = 19.7656s	
5160/11350 (epoch 22.731), train_loss = 1.06536496, grad/param norm = 3.0893e-01, time/batch = 20.6183s	
5161/11350 (epoch 22.736), train_loss = 0.96195290, grad/param norm = 3.5611e-01, time/batch = 19.3386s	
5162/11350 (epoch 22.740), train_loss = 0.99710485, grad/param norm = 3.0662e-01, time/batch = 19.3846s	
5163/11350 (epoch 22.744), train_loss = 1.01475744, grad/param norm = 3.4459e-01, time/batch = 19.2002s	
5164/11350 (epoch 22.749), train_loss = 1.05603004, grad/param norm = 3.5033e-01, time/batch = 18.7607s	
5165/11350 (epoch 22.753), train_loss = 1.08668881, grad/param norm = 3.5604e-01, time/batch = 19.1933s	
5166/11350 (epoch 22.758), train_loss = 0.95162898, grad/param norm = 2.9404e-01, time/batch = 20.3604s	
5167/11350 (epoch 22.762), train_loss = 1.06601555, grad/param norm = 2.7533e-01, time/batch = 19.0227s	
5168/11350 (epoch 22.767), train_loss = 1.06978532, grad/param norm = 2.6311e-01, time/batch = 18.3648s	
5169/11350 (epoch 22.771), train_loss = 1.19958429, grad/param norm = 3.0539e-01, time/batch = 18.8617s	
5170/11350 (epoch 22.775), train_loss = 0.95400162, grad/param norm = 2.8174e-01, time/batch = 18.3680s	
5171/11350 (epoch 22.780), train_loss = 1.08162593, grad/param norm = 2.9960e-01, time/batch = 20.1951s	
5172/11350 (epoch 22.784), train_loss = 0.95998711, grad/param norm = 3.0555e-01, time/batch = 19.0399s	
5173/11350 (epoch 22.789), train_loss = 1.00077385, grad/param norm = 2.8725e-01, time/batch = 17.7872s	
5174/11350 (epoch 22.793), train_loss = 1.09790496, grad/param norm = 2.9050e-01, time/batch = 17.3734s	
5175/11350 (epoch 22.797), train_loss = 0.95972129, grad/param norm = 2.8925e-01, time/batch = 16.6452s	
5176/11350 (epoch 22.802), train_loss = 1.06725817, grad/param norm = 3.2963e-01, time/batch = 19.0352s	
5177/11350 (epoch 22.806), train_loss = 1.07152367, grad/param norm = 2.7597e-01, time/batch = 19.1849s	
5178/11350 (epoch 22.811), train_loss = 1.02841984, grad/param norm = 2.7655e-01, time/batch = 19.8814s	
5179/11350 (epoch 22.815), train_loss = 0.96437976, grad/param norm = 3.5818e-01, time/batch = 19.7953s	
5180/11350 (epoch 22.819), train_loss = 0.92705698, grad/param norm = 3.0090e-01, time/batch = 17.1006s	
5181/11350 (epoch 22.824), train_loss = 0.88205066, grad/param norm = 2.8648e-01, time/batch = 19.7673s	
5182/11350 (epoch 22.828), train_loss = 0.97314836, grad/param norm = 2.9216e-01, time/batch = 20.6123s	
5183/11350 (epoch 22.833), train_loss = 0.99877466, grad/param norm = 3.4332e-01, time/batch = 20.0289s	
5184/11350 (epoch 22.837), train_loss = 1.02513243, grad/param norm = 3.1594e-01, time/batch = 18.7639s	
5185/11350 (epoch 22.841), train_loss = 1.24973460, grad/param norm = 3.5457e-01, time/batch = 20.1214s	
5186/11350 (epoch 22.846), train_loss = 1.03167436, grad/param norm = 2.9536e-01, time/batch = 19.2787s	
5187/11350 (epoch 22.850), train_loss = 1.09792977, grad/param norm = 3.1220e-01, time/batch = 19.1985s	
5188/11350 (epoch 22.855), train_loss = 0.87662350, grad/param norm = 2.8988e-01, time/batch = 20.8632s	
5189/11350 (epoch 22.859), train_loss = 0.97324875, grad/param norm = 3.2426e-01, time/batch = 18.6997s	
5190/11350 (epoch 22.863), train_loss = 0.86401327, grad/param norm = 2.8280e-01, time/batch = 18.1864s	
5191/11350 (epoch 22.868), train_loss = 0.91647485, grad/param norm = 2.5174e-01, time/batch = 18.8476s	
5192/11350 (epoch 22.872), train_loss = 0.95705116, grad/param norm = 2.8319e-01, time/batch = 17.2825s	
5193/11350 (epoch 22.877), train_loss = 0.98024536, grad/param norm = 3.0854e-01, time/batch = 20.2830s	
5194/11350 (epoch 22.881), train_loss = 1.17230622, grad/param norm = 3.7854e-01, time/batch = 18.3778s	
5195/11350 (epoch 22.885), train_loss = 1.17308816, grad/param norm = 3.1615e-01, time/batch = 18.6147s	
5196/11350 (epoch 22.890), train_loss = 1.04864089, grad/param norm = 3.1250e-01, time/batch = 19.0275s	
5197/11350 (epoch 22.894), train_loss = 0.85554663, grad/param norm = 2.8058e-01, time/batch = 20.0353s	
5198/11350 (epoch 22.899), train_loss = 1.06416722, grad/param norm = 3.2213e-01, time/batch = 18.8461s	
5199/11350 (epoch 22.903), train_loss = 1.05747247, grad/param norm = 3.1202e-01, time/batch = 19.1952s	
5200/11350 (epoch 22.907), train_loss = 1.02540440, grad/param norm = 3.2805e-01, time/batch = 20.2019s	
5201/11350 (epoch 22.912), train_loss = 0.92586015, grad/param norm = 2.8418e-01, time/batch = 18.6942s	
5202/11350 (epoch 22.916), train_loss = 1.07676846, grad/param norm = 2.9732e-01, time/batch = 18.0405s	
5203/11350 (epoch 22.921), train_loss = 1.06445652, grad/param norm = 3.0334e-01, time/batch = 18.3840s	
5204/11350 (epoch 22.925), train_loss = 0.85717461, grad/param norm = 2.3484e-01, time/batch = 19.3739s	
5205/11350 (epoch 22.930), train_loss = 1.08335456, grad/param norm = 3.2256e-01, time/batch = 18.7162s	
5206/11350 (epoch 22.934), train_loss = 1.15856882, grad/param norm = 3.1444e-01, time/batch = 20.9250s	
5207/11350 (epoch 22.938), train_loss = 0.96317090, grad/param norm = 2.7045e-01, time/batch = 19.4466s	
5208/11350 (epoch 22.943), train_loss = 1.08812376, grad/param norm = 2.8243e-01, time/batch = 19.0202s	
5209/11350 (epoch 22.947), train_loss = 1.06089263, grad/param norm = 3.2093e-01, time/batch = 19.0520s	
5210/11350 (epoch 22.952), train_loss = 1.06086527, grad/param norm = 3.6159e-01, time/batch = 18.0376s	
5211/11350 (epoch 22.956), train_loss = 0.83081088, grad/param norm = 2.7123e-01, time/batch = 19.0092s	
5212/11350 (epoch 22.960), train_loss = 0.96183484, grad/param norm = 3.2826e-01, time/batch = 18.2979s	
5213/11350 (epoch 22.965), train_loss = 0.86830332, grad/param norm = 2.8791e-01, time/batch = 18.8584s	
5214/11350 (epoch 22.969), train_loss = 0.89517962, grad/param norm = 3.1721e-01, time/batch = 18.2767s	
5215/11350 (epoch 22.974), train_loss = 0.84433965, grad/param norm = 2.9174e-01, time/batch = 20.3654s	
5216/11350 (epoch 22.978), train_loss = 0.97318943, grad/param norm = 2.9271e-01, time/batch = 20.0353s	
5217/11350 (epoch 22.982), train_loss = 0.71331472, grad/param norm = 2.4292e-01, time/batch = 18.1289s	
5218/11350 (epoch 22.987), train_loss = 0.98087915, grad/param norm = 2.8799e-01, time/batch = 18.8760s	
5219/11350 (epoch 22.991), train_loss = 0.86467750, grad/param norm = 3.2205e-01, time/batch = 20.5381s	
5220/11350 (epoch 22.996), train_loss = 1.00393829, grad/param norm = 3.4764e-01, time/batch = 18.3729s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
5221/11350 (epoch 23.000), train_loss = 0.75182312, grad/param norm = 2.8893e-01, time/batch = 17.6929s	
5222/11350 (epoch 23.004), train_loss = 1.02004904, grad/param norm = 3.3570e-01, time/batch = 20.1304s	
5223/11350 (epoch 23.009), train_loss = 0.97369698, grad/param norm = 2.8568e-01, time/batch = 26.2776s	
5224/11350 (epoch 23.013), train_loss = 0.69353548, grad/param norm = 2.3762e-01, time/batch = 27.5227s	
5225/11350 (epoch 23.018), train_loss = 0.76245669, grad/param norm = 2.6071e-01, time/batch = 19.5394s	
5226/11350 (epoch 23.022), train_loss = 0.78320877, grad/param norm = 3.1614e-01, time/batch = 18.6583s	
5227/11350 (epoch 23.026), train_loss = 0.77608146, grad/param norm = 2.9328e-01, time/batch = 18.2943s	
5228/11350 (epoch 23.031), train_loss = 0.85260417, grad/param norm = 3.1077e-01, time/batch = 17.6214s	
5229/11350 (epoch 23.035), train_loss = 0.84266744, grad/param norm = 3.2379e-01, time/batch = 18.7674s	
5230/11350 (epoch 23.040), train_loss = 0.85974874, grad/param norm = 3.0673e-01, time/batch = 19.4344s	
5231/11350 (epoch 23.044), train_loss = 0.81111204, grad/param norm = 2.5180e-01, time/batch = 21.1066s	
5232/11350 (epoch 23.048), train_loss = 0.78994250, grad/param norm = 2.6906e-01, time/batch = 19.6927s	
5233/11350 (epoch 23.053), train_loss = 0.89818103, grad/param norm = 2.9614e-01, time/batch = 18.8684s	
5234/11350 (epoch 23.057), train_loss = 0.91694969, grad/param norm = 3.0261e-01, time/batch = 19.2916s	
5235/11350 (epoch 23.062), train_loss = 0.74398224, grad/param norm = 2.9338e-01, time/batch = 17.9459s	
5236/11350 (epoch 23.066), train_loss = 0.74396430, grad/param norm = 2.9144e-01, time/batch = 18.5321s	
5237/11350 (epoch 23.070), train_loss = 0.84230753, grad/param norm = 3.2673e-01, time/batch = 20.2076s	
5238/11350 (epoch 23.075), train_loss = 0.75906281, grad/param norm = 2.4206e-01, time/batch = 18.3687s	
5239/11350 (epoch 23.079), train_loss = 0.87585993, grad/param norm = 2.5185e-01, time/batch = 17.1968s	
5240/11350 (epoch 23.084), train_loss = 1.01579680, grad/param norm = 3.2487e-01, time/batch = 17.3772s	
5241/11350 (epoch 23.088), train_loss = 0.99063312, grad/param norm = 3.4985e-01, time/batch = 18.1915s	
5242/11350 (epoch 23.093), train_loss = 0.93902528, grad/param norm = 2.7780e-01, time/batch = 18.6901s	
5243/11350 (epoch 23.097), train_loss = 0.91045106, grad/param norm = 3.1614e-01, time/batch = 20.6207s	
5244/11350 (epoch 23.101), train_loss = 0.81487660, grad/param norm = 2.9406e-01, time/batch = 19.9427s	
5245/11350 (epoch 23.106), train_loss = 0.94559187, grad/param norm = 3.2620e-01, time/batch = 16.0655s	
5246/11350 (epoch 23.110), train_loss = 0.84020475, grad/param norm = 3.3789e-01, time/batch = 18.9475s	
5247/11350 (epoch 23.115), train_loss = 0.84463052, grad/param norm = 3.0152e-01, time/batch = 20.5350s	
5248/11350 (epoch 23.119), train_loss = 0.99227393, grad/param norm = 3.6689e-01, time/batch = 18.3605s	
5249/11350 (epoch 23.123), train_loss = 0.80925492, grad/param norm = 2.7199e-01, time/batch = 19.1026s	
5250/11350 (epoch 23.128), train_loss = 0.76239678, grad/param norm = 3.4227e-01, time/batch = 18.2921s	
5251/11350 (epoch 23.132), train_loss = 0.83888878, grad/param norm = 2.8545e-01, time/batch = 19.4387s	
5252/11350 (epoch 23.137), train_loss = 0.81771482, grad/param norm = 3.1267e-01, time/batch = 19.5039s	
5253/11350 (epoch 23.141), train_loss = 1.03491156, grad/param norm = 3.3697e-01, time/batch = 21.0989s	
5254/11350 (epoch 23.145), train_loss = 0.81019437, grad/param norm = 2.7037e-01, time/batch = 17.4426s	
5255/11350 (epoch 23.150), train_loss = 0.93970681, grad/param norm = 4.3472e-01, time/batch = 20.6932s	
5256/11350 (epoch 23.154), train_loss = 1.05469696, grad/param norm = 3.1107e-01, time/batch = 20.3662s	
5257/11350 (epoch 23.159), train_loss = 0.75225392, grad/param norm = 3.0503e-01, time/batch = 18.6185s	
5258/11350 (epoch 23.163), train_loss = 0.99167614, grad/param norm = 3.4417e-01, time/batch = 17.7689s	
5259/11350 (epoch 23.167), train_loss = 1.03131480, grad/param norm = 2.9047e-01, time/batch = 19.7141s	
5260/11350 (epoch 23.172), train_loss = 1.11476485, grad/param norm = 3.0678e-01, time/batch = 18.7913s	
5261/11350 (epoch 23.176), train_loss = 0.91687151, grad/param norm = 2.9858e-01, time/batch = 21.2570s	
5262/11350 (epoch 23.181), train_loss = 0.95443247, grad/param norm = 3.7328e-01, time/batch = 19.7824s	
5263/11350 (epoch 23.185), train_loss = 0.77964428, grad/param norm = 2.7837e-01, time/batch = 19.7802s	
5264/11350 (epoch 23.189), train_loss = 0.88412299, grad/param norm = 2.8607e-01, time/batch = 17.6701s	
5265/11350 (epoch 23.194), train_loss = 0.84036907, grad/param norm = 2.9290e-01, time/batch = 19.1850s	
5266/11350 (epoch 23.198), train_loss = 0.76301362, grad/param norm = 3.3556e-01, time/batch = 20.4228s	
5267/11350 (epoch 23.203), train_loss = 0.81621783, grad/param norm = 3.0862e-01, time/batch = 18.0193s	
5268/11350 (epoch 23.207), train_loss = 0.77914606, grad/param norm = 3.7110e-01, time/batch = 20.3500s	
5269/11350 (epoch 23.211), train_loss = 0.99789176, grad/param norm = 3.6233e-01, time/batch = 17.1962s	
5270/11350 (epoch 23.216), train_loss = 0.95332039, grad/param norm = 3.2520e-01, time/batch = 18.5196s	
5271/11350 (epoch 23.220), train_loss = 0.95459652, grad/param norm = 3.1991e-01, time/batch = 20.2835s	
5272/11350 (epoch 23.225), train_loss = 0.81320371, grad/param norm = 2.5071e-01, time/batch = 19.0320s	
5273/11350 (epoch 23.229), train_loss = 0.93883319, grad/param norm = 2.9135e-01, time/batch = 20.5959s	
5274/11350 (epoch 23.233), train_loss = 0.88958664, grad/param norm = 2.8833e-01, time/batch = 19.1975s	
5275/11350 (epoch 23.238), train_loss = 1.02628221, grad/param norm = 4.0014e-01, time/batch = 20.1978s	
5276/11350 (epoch 23.242), train_loss = 1.04740415, grad/param norm = 4.4073e-01, time/batch = 19.3995s	
5277/11350 (epoch 23.247), train_loss = 0.77116273, grad/param norm = 2.7919e-01, time/batch = 18.9215s	
5278/11350 (epoch 23.251), train_loss = 0.94476418, grad/param norm = 3.2248e-01, time/batch = 20.9457s	
5279/11350 (epoch 23.256), train_loss = 0.92658917, grad/param norm = 3.3197e-01, time/batch = 19.6694s	
5280/11350 (epoch 23.260), train_loss = 0.84372757, grad/param norm = 3.1771e-01, time/batch = 20.5242s	
5281/11350 (epoch 23.264), train_loss = 0.84501433, grad/param norm = 3.2902e-01, time/batch = 20.3572s	
5282/11350 (epoch 23.269), train_loss = 0.87848381, grad/param norm = 2.8885e-01, time/batch = 19.1050s	
5283/11350 (epoch 23.273), train_loss = 1.01141730, grad/param norm = 3.2985e-01, time/batch = 18.8367s	
5284/11350 (epoch 23.278), train_loss = 0.82675002, grad/param norm = 2.5695e-01, time/batch = 20.4423s	
5285/11350 (epoch 23.282), train_loss = 0.91143952, grad/param norm = 3.1737e-01, time/batch = 19.9260s	
5286/11350 (epoch 23.286), train_loss = 0.98428633, grad/param norm = 3.1066e-01, time/batch = 19.0402s	
5287/11350 (epoch 23.291), train_loss = 0.81191308, grad/param norm = 4.1865e-01, time/batch = 20.1857s	
5288/11350 (epoch 23.295), train_loss = 0.91256261, grad/param norm = 3.0266e-01, time/batch = 17.5007s	
5289/11350 (epoch 23.300), train_loss = 0.94938057, grad/param norm = 2.9178e-01, time/batch = 20.5378s	
5290/11350 (epoch 23.304), train_loss = 0.83842398, grad/param norm = 2.7890e-01, time/batch = 20.2046s	
5291/11350 (epoch 23.308), train_loss = 0.82732768, grad/param norm = 3.3595e-01, time/batch = 20.5273s	
5292/11350 (epoch 23.313), train_loss = 0.95683132, grad/param norm = 2.9433e-01, time/batch = 18.9270s	
5293/11350 (epoch 23.317), train_loss = 0.83398768, grad/param norm = 2.5082e-01, time/batch = 20.6027s	
5294/11350 (epoch 23.322), train_loss = 0.84294280, grad/param norm = 2.8287e-01, time/batch = 19.4572s	
5295/11350 (epoch 23.326), train_loss = 0.88394128, grad/param norm = 2.7226e-01, time/batch = 16.8644s	
5296/11350 (epoch 23.330), train_loss = 0.72838470, grad/param norm = 2.4598e-01, time/batch = 18.9459s	
5297/11350 (epoch 23.335), train_loss = 0.62402373, grad/param norm = 2.4146e-01, time/batch = 19.0190s	
5298/11350 (epoch 23.339), train_loss = 0.73292541, grad/param norm = 2.9181e-01, time/batch = 16.9312s	
5299/11350 (epoch 23.344), train_loss = 0.81176439, grad/param norm = 2.4614e-01, time/batch = 19.4449s	
5300/11350 (epoch 23.348), train_loss = 0.81043409, grad/param norm = 2.4681e-01, time/batch = 19.5191s	
5301/11350 (epoch 23.352), train_loss = 0.73243792, grad/param norm = 2.5971e-01, time/batch = 19.7684s	
5302/11350 (epoch 23.357), train_loss = 0.81455302, grad/param norm = 2.7015e-01, time/batch = 19.6104s	
5303/11350 (epoch 23.361), train_loss = 0.66197541, grad/param norm = 2.2068e-01, time/batch = 19.5214s	
5304/11350 (epoch 23.366), train_loss = 0.91207842, grad/param norm = 3.7130e-01, time/batch = 20.7727s	
5305/11350 (epoch 23.370), train_loss = 0.76194928, grad/param norm = 3.3644e-01, time/batch = 19.1840s	
5306/11350 (epoch 23.374), train_loss = 0.80734203, grad/param norm = 2.6722e-01, time/batch = 20.2731s	
5307/11350 (epoch 23.379), train_loss = 0.80796613, grad/param norm = 2.7310e-01, time/batch = 17.3421s	
5308/11350 (epoch 23.383), train_loss = 0.75510500, grad/param norm = 3.2705e-01, time/batch = 19.9355s	
5309/11350 (epoch 23.388), train_loss = 0.87100227, grad/param norm = 3.4223e-01, time/batch = 18.0100s	
5310/11350 (epoch 23.392), train_loss = 0.88817819, grad/param norm = 2.9942e-01, time/batch = 17.1743s	
5311/11350 (epoch 23.396), train_loss = 0.84671872, grad/param norm = 3.0965e-01, time/batch = 19.9111s	
5312/11350 (epoch 23.401), train_loss = 0.87067408, grad/param norm = 3.1748e-01, time/batch = 20.0995s	
5313/11350 (epoch 23.405), train_loss = 1.05229731, grad/param norm = 3.2743e-01, time/batch = 19.4505s	
5314/11350 (epoch 23.410), train_loss = 1.07515967, grad/param norm = 3.3708e-01, time/batch = 19.2731s	
5315/11350 (epoch 23.414), train_loss = 0.75292816, grad/param norm = 3.0829e-01, time/batch = 20.3374s	
5316/11350 (epoch 23.419), train_loss = 0.79000140, grad/param norm = 3.0642e-01, time/batch = 19.4224s	
5317/11350 (epoch 23.423), train_loss = 0.90941021, grad/param norm = 3.4774e-01, time/batch = 20.1136s	
5318/11350 (epoch 23.427), train_loss = 0.97361412, grad/param norm = 3.0638e-01, time/batch = 19.9335s	
5319/11350 (epoch 23.432), train_loss = 0.91440196, grad/param norm = 3.5031e-01, time/batch = 18.8679s	
5320/11350 (epoch 23.436), train_loss = 0.84533317, grad/param norm = 3.3277e-01, time/batch = 20.6889s	
5321/11350 (epoch 23.441), train_loss = 1.04135109, grad/param norm = 3.4275e-01, time/batch = 20.0194s	
5322/11350 (epoch 23.445), train_loss = 0.75609656, grad/param norm = 2.4890e-01, time/batch = 20.1900s	
5323/11350 (epoch 23.449), train_loss = 0.85288795, grad/param norm = 3.2361e-01, time/batch = 19.4427s	
5324/11350 (epoch 23.454), train_loss = 1.01621809, grad/param norm = 3.2655e-01, time/batch = 20.0110s	
5325/11350 (epoch 23.458), train_loss = 0.73232454, grad/param norm = 2.7941e-01, time/batch = 19.0287s	
5326/11350 (epoch 23.463), train_loss = 0.74577410, grad/param norm = 2.7881e-01, time/batch = 19.7929s	
5327/11350 (epoch 23.467), train_loss = 1.16768123, grad/param norm = 3.1481e-01, time/batch = 20.0247s	
5328/11350 (epoch 23.471), train_loss = 1.02304384, grad/param norm = 3.8520e-01, time/batch = 17.4165s	
5329/11350 (epoch 23.476), train_loss = 0.92664625, grad/param norm = 2.7653e-01, time/batch = 18.5965s	
5330/11350 (epoch 23.480), train_loss = 1.03361909, grad/param norm = 2.9260e-01, time/batch = 21.1843s	
5331/11350 (epoch 23.485), train_loss = 0.87957067, grad/param norm = 2.9498e-01, time/batch = 19.9218s	
5332/11350 (epoch 23.489), train_loss = 1.01221223, grad/param norm = 3.1060e-01, time/batch = 19.4424s	
5333/11350 (epoch 23.493), train_loss = 1.02314009, grad/param norm = 3.0401e-01, time/batch = 19.3748s	
5334/11350 (epoch 23.498), train_loss = 0.70775868, grad/param norm = 2.8297e-01, time/batch = 18.2830s	
5335/11350 (epoch 23.502), train_loss = 0.99595053, grad/param norm = 2.6665e-01, time/batch = 18.4420s	
5336/11350 (epoch 23.507), train_loss = 0.78416607, grad/param norm = 2.9966e-01, time/batch = 19.3641s	
5337/11350 (epoch 23.511), train_loss = 1.03594995, grad/param norm = 2.8875e-01, time/batch = 18.4456s	
5338/11350 (epoch 23.515), train_loss = 0.90766148, grad/param norm = 3.0055e-01, time/batch = 19.1970s	
5339/11350 (epoch 23.520), train_loss = 1.06662821, grad/param norm = 3.1167e-01, time/batch = 21.1116s	
5340/11350 (epoch 23.524), train_loss = 0.90605031, grad/param norm = 2.7727e-01, time/batch = 19.2802s	
5341/11350 (epoch 23.529), train_loss = 0.88962742, grad/param norm = 3.0374e-01, time/batch = 19.6110s	
5342/11350 (epoch 23.533), train_loss = 1.09866109, grad/param norm = 2.9636e-01, time/batch = 20.6083s	
5343/11350 (epoch 23.537), train_loss = 0.99469336, grad/param norm = 2.8447e-01, time/batch = 15.8688s	
5344/11350 (epoch 23.542), train_loss = 0.97014777, grad/param norm = 2.6309e-01, time/batch = 18.3556s	
5345/11350 (epoch 23.546), train_loss = 1.14715579, grad/param norm = 2.9052e-01, time/batch = 19.8609s	
5346/11350 (epoch 23.551), train_loss = 0.96231580, grad/param norm = 2.8364e-01, time/batch = 18.9254s	
5347/11350 (epoch 23.555), train_loss = 0.86432576, grad/param norm = 2.9358e-01, time/batch = 19.6219s	
5348/11350 (epoch 23.559), train_loss = 0.88710264, grad/param norm = 2.8839e-01, time/batch = 19.3380s	
5349/11350 (epoch 23.564), train_loss = 0.97743835, grad/param norm = 2.9624e-01, time/batch = 19.3738s	
5350/11350 (epoch 23.568), train_loss = 0.98770588, grad/param norm = 2.7630e-01, time/batch = 19.7949s	
5351/11350 (epoch 23.573), train_loss = 1.09159467, grad/param norm = 3.4444e-01, time/batch = 18.2994s	
5352/11350 (epoch 23.577), train_loss = 1.03553047, grad/param norm = 3.6698e-01, time/batch = 17.5896s	
5353/11350 (epoch 23.581), train_loss = 1.03399368, grad/param norm = 3.2026e-01, time/batch = 19.7080s	
5354/11350 (epoch 23.586), train_loss = 1.04504977, grad/param norm = 3.0889e-01, time/batch = 17.9706s	
5355/11350 (epoch 23.590), train_loss = 1.13237602, grad/param norm = 3.8478e-01, time/batch = 20.0483s	
5356/11350 (epoch 23.595), train_loss = 1.15151053, grad/param norm = 2.9747e-01, time/batch = 17.8778s	
5357/11350 (epoch 23.599), train_loss = 1.04554722, grad/param norm = 3.1873e-01, time/batch = 18.5408s	
5358/11350 (epoch 23.604), train_loss = 0.98089991, grad/param norm = 3.0057e-01, time/batch = 19.5504s	
5359/11350 (epoch 23.608), train_loss = 0.95717965, grad/param norm = 3.3203e-01, time/batch = 17.9620s	
5360/11350 (epoch 23.612), train_loss = 0.91113517, grad/param norm = 2.7780e-01, time/batch = 17.7947s	
5361/11350 (epoch 23.617), train_loss = 1.05024539, grad/param norm = 3.1387e-01, time/batch = 19.2952s	
5362/11350 (epoch 23.621), train_loss = 1.07520068, grad/param norm = 2.8146e-01, time/batch = 17.7867s	
5363/11350 (epoch 23.626), train_loss = 0.97194858, grad/param norm = 3.0742e-01, time/batch = 18.5610s	
5364/11350 (epoch 23.630), train_loss = 1.03959524, grad/param norm = 3.4333e-01, time/batch = 18.2092s	
5365/11350 (epoch 23.634), train_loss = 1.00441363, grad/param norm = 3.6614e-01, time/batch = 18.6857s	
5366/11350 (epoch 23.639), train_loss = 0.88310799, grad/param norm = 2.9997e-01, time/batch = 19.9523s	
5367/11350 (epoch 23.643), train_loss = 0.86124509, grad/param norm = 2.7307e-01, time/batch = 19.5407s	
5368/11350 (epoch 23.648), train_loss = 0.95130154, grad/param norm = 2.8502e-01, time/batch = 19.1092s	
5369/11350 (epoch 23.652), train_loss = 0.85738589, grad/param norm = 3.0176e-01, time/batch = 18.2828s	
5370/11350 (epoch 23.656), train_loss = 0.98973921, grad/param norm = 2.9609e-01, time/batch = 15.1637s	
5371/11350 (epoch 23.661), train_loss = 1.09230772, grad/param norm = 3.1765e-01, time/batch = 20.4557s	
5372/11350 (epoch 23.665), train_loss = 0.97847655, grad/param norm = 3.3467e-01, time/batch = 19.2719s	
5373/11350 (epoch 23.670), train_loss = 0.98116684, grad/param norm = 3.2136e-01, time/batch = 18.7022s	
5374/11350 (epoch 23.674), train_loss = 0.92335099, grad/param norm = 2.8605e-01, time/batch = 16.7804s	
5375/11350 (epoch 23.678), train_loss = 0.94560146, grad/param norm = 2.6730e-01, time/batch = 16.9616s	
5376/11350 (epoch 23.683), train_loss = 0.89070113, grad/param norm = 3.6916e-01, time/batch = 17.7079s	
5377/11350 (epoch 23.687), train_loss = 0.83554940, grad/param norm = 2.7226e-01, time/batch = 18.5380s	
5378/11350 (epoch 23.692), train_loss = 1.26100991, grad/param norm = 5.2492e-01, time/batch = 18.7973s	
5379/11350 (epoch 23.696), train_loss = 1.15294785, grad/param norm = 3.4368e-01, time/batch = 18.5476s	
5380/11350 (epoch 23.700), train_loss = 1.06502733, grad/param norm = 3.2092e-01, time/batch = 18.5380s	
5381/11350 (epoch 23.705), train_loss = 1.12551651, grad/param norm = 3.5647e-01, time/batch = 18.7806s	
5382/11350 (epoch 23.709), train_loss = 1.09989888, grad/param norm = 3.1043e-01, time/batch = 17.8012s	
5383/11350 (epoch 23.714), train_loss = 0.98411792, grad/param norm = 3.2593e-01, time/batch = 19.7087s	
5384/11350 (epoch 23.718), train_loss = 0.83854909, grad/param norm = 2.9176e-01, time/batch = 20.7040s	
5385/11350 (epoch 23.722), train_loss = 0.98835522, grad/param norm = 3.5245e-01, time/batch = 18.0123s	
5386/11350 (epoch 23.727), train_loss = 0.98957958, grad/param norm = 3.3939e-01, time/batch = 18.4622s	
5387/11350 (epoch 23.731), train_loss = 1.01240398, grad/param norm = 3.0822e-01, time/batch = 19.3705s	
5388/11350 (epoch 23.736), train_loss = 0.91069036, grad/param norm = 3.2063e-01, time/batch = 17.7066s	
5389/11350 (epoch 23.740), train_loss = 0.95694396, grad/param norm = 3.1336e-01, time/batch = 17.3045s	
5390/11350 (epoch 23.744), train_loss = 0.97341276, grad/param norm = 3.3056e-01, time/batch = 17.5425s	
5391/11350 (epoch 23.749), train_loss = 1.01182177, grad/param norm = 3.4274e-01, time/batch = 17.5315s	
5392/11350 (epoch 23.753), train_loss = 1.05299044, grad/param norm = 3.7827e-01, time/batch = 16.9590s	
5393/11350 (epoch 23.758), train_loss = 0.93192657, grad/param norm = 3.1310e-01, time/batch = 17.2664s	
5394/11350 (epoch 23.762), train_loss = 1.05784994, grad/param norm = 2.8977e-01, time/batch = 19.5387s	
5395/11350 (epoch 23.767), train_loss = 1.04389817, grad/param norm = 2.6135e-01, time/batch = 18.0213s	
5396/11350 (epoch 23.771), train_loss = 1.17727053, grad/param norm = 3.1160e-01, time/batch = 18.1406s	
5397/11350 (epoch 23.775), train_loss = 0.94252062, grad/param norm = 2.9464e-01, time/batch = 19.2955s	
5398/11350 (epoch 23.780), train_loss = 1.06507823, grad/param norm = 3.3437e-01, time/batch = 18.1081s	
5399/11350 (epoch 23.784), train_loss = 0.93054052, grad/param norm = 3.0497e-01, time/batch = 19.0461s	
5400/11350 (epoch 23.789), train_loss = 0.97787554, grad/param norm = 3.3414e-01, time/batch = 19.7104s	
5401/11350 (epoch 23.793), train_loss = 1.08430557, grad/param norm = 3.2330e-01, time/batch = 18.2894s	
5402/11350 (epoch 23.797), train_loss = 0.95419817, grad/param norm = 3.0021e-01, time/batch = 20.6971s	
5403/11350 (epoch 23.802), train_loss = 1.01894861, grad/param norm = 2.7962e-01, time/batch = 19.8599s	
5404/11350 (epoch 23.806), train_loss = 1.03904533, grad/param norm = 2.7538e-01, time/batch = 17.9673s	
5405/11350 (epoch 23.811), train_loss = 0.99597650, grad/param norm = 2.8620e-01, time/batch = 17.1938s	
5406/11350 (epoch 23.815), train_loss = 0.91000010, grad/param norm = 2.6109e-01, time/batch = 17.7981s	
5407/11350 (epoch 23.819), train_loss = 0.88687986, grad/param norm = 3.0407e-01, time/batch = 18.2925s	
5408/11350 (epoch 23.824), train_loss = 0.86565148, grad/param norm = 3.0857e-01, time/batch = 19.6159s	
5409/11350 (epoch 23.828), train_loss = 0.94174428, grad/param norm = 2.9542e-01, time/batch = 18.8525s	
5410/11350 (epoch 23.833), train_loss = 0.95079810, grad/param norm = 3.4470e-01, time/batch = 19.2916s	
5411/11350 (epoch 23.837), train_loss = 1.00916611, grad/param norm = 3.2645e-01, time/batch = 32.6732s	
5412/11350 (epoch 23.841), train_loss = 1.21832192, grad/param norm = 3.3742e-01, time/batch = 17.0354s	
5413/11350 (epoch 23.846), train_loss = 1.00335657, grad/param norm = 2.7532e-01, time/batch = 17.6064s	
5414/11350 (epoch 23.850), train_loss = 1.05893059, grad/param norm = 3.1227e-01, time/batch = 19.2020s	
5415/11350 (epoch 23.855), train_loss = 0.83539363, grad/param norm = 3.1483e-01, time/batch = 19.3021s	
5416/11350 (epoch 23.859), train_loss = 0.93493306, grad/param norm = 3.2786e-01, time/batch = 18.7945s	
5417/11350 (epoch 23.863), train_loss = 0.83986829, grad/param norm = 2.9100e-01, time/batch = 18.7896s	
5418/11350 (epoch 23.868), train_loss = 0.88247896, grad/param norm = 2.5627e-01, time/batch = 19.9542s	
5419/11350 (epoch 23.872), train_loss = 0.92797624, grad/param norm = 2.7944e-01, time/batch = 18.6929s	
5420/11350 (epoch 23.877), train_loss = 0.94088675, grad/param norm = 2.9294e-01, time/batch = 16.8056s	
5421/11350 (epoch 23.881), train_loss = 1.12654109, grad/param norm = 3.2308e-01, time/batch = 16.8667s	
5422/11350 (epoch 23.885), train_loss = 1.12358865, grad/param norm = 3.1185e-01, time/batch = 19.0382s	
5423/11350 (epoch 23.890), train_loss = 1.03711996, grad/param norm = 4.1523e-01, time/batch = 19.1713s	
5424/11350 (epoch 23.894), train_loss = 0.81339059, grad/param norm = 2.6839e-01, time/batch = 17.7694s	
5425/11350 (epoch 23.899), train_loss = 1.03329582, grad/param norm = 2.8628e-01, time/batch = 19.2885s	
5426/11350 (epoch 23.903), train_loss = 1.01671460, grad/param norm = 2.8723e-01, time/batch = 18.0277s	
5427/11350 (epoch 23.907), train_loss = 0.97283717, grad/param norm = 2.9285e-01, time/batch = 17.7037s	
5428/11350 (epoch 23.912), train_loss = 0.88886250, grad/param norm = 2.7724e-01, time/batch = 18.2292s	
5429/11350 (epoch 23.916), train_loss = 1.04440091, grad/param norm = 3.1632e-01, time/batch = 18.2038s	
5430/11350 (epoch 23.921), train_loss = 1.02697991, grad/param norm = 3.1323e-01, time/batch = 19.7016s	
5431/11350 (epoch 23.925), train_loss = 0.83641531, grad/param norm = 2.6073e-01, time/batch = 17.6962s	
5432/11350 (epoch 23.930), train_loss = 1.05790759, grad/param norm = 3.5088e-01, time/batch = 16.9285s	
5433/11350 (epoch 23.934), train_loss = 1.12485828, grad/param norm = 3.1388e-01, time/batch = 20.1164s	
5434/11350 (epoch 23.938), train_loss = 0.94137537, grad/param norm = 2.9050e-01, time/batch = 19.2849s	
5435/11350 (epoch 23.943), train_loss = 1.05763110, grad/param norm = 2.8995e-01, time/batch = 19.1190s	
5436/11350 (epoch 23.947), train_loss = 1.03584617, grad/param norm = 3.7556e-01, time/batch = 19.2789s	
5437/11350 (epoch 23.952), train_loss = 1.03180523, grad/param norm = 3.3682e-01, time/batch = 18.7846s	
5438/11350 (epoch 23.956), train_loss = 0.80913859, grad/param norm = 2.7913e-01, time/batch = 19.5337s	
5439/11350 (epoch 23.960), train_loss = 0.92664290, grad/param norm = 3.3681e-01, time/batch = 18.3261s	
5440/11350 (epoch 23.965), train_loss = 0.85878143, grad/param norm = 3.2486e-01, time/batch = 18.0358s	
5441/11350 (epoch 23.969), train_loss = 0.87044551, grad/param norm = 3.4794e-01, time/batch = 18.8752s	
5442/11350 (epoch 23.974), train_loss = 0.82589632, grad/param norm = 3.0525e-01, time/batch = 17.1863s	
5443/11350 (epoch 23.978), train_loss = 0.95543686, grad/param norm = 3.1340e-01, time/batch = 15.9779s	
5444/11350 (epoch 23.982), train_loss = 0.70572976, grad/param norm = 3.1211e-01, time/batch = 19.1070s	
5445/11350 (epoch 23.987), train_loss = 0.96170412, grad/param norm = 3.3554e-01, time/batch = 17.6042s	
5446/11350 (epoch 23.991), train_loss = 0.84060954, grad/param norm = 3.6954e-01, time/batch = 19.3584s	
5447/11350 (epoch 23.996), train_loss = 0.97648856, grad/param norm = 3.2139e-01, time/batch = 17.7044s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
5448/11350 (epoch 24.000), train_loss = 0.73025521, grad/param norm = 2.7031e-01, time/batch = 18.3538s	
5449/11350 (epoch 24.004), train_loss = 0.99513362, grad/param norm = 3.4208e-01, time/batch = 19.4357s	
5450/11350 (epoch 24.009), train_loss = 0.95946268, grad/param norm = 3.0490e-01, time/batch = 18.8851s	
5451/11350 (epoch 24.013), train_loss = 0.69753949, grad/param norm = 2.7382e-01, time/batch = 20.5392s	
5452/11350 (epoch 24.018), train_loss = 0.74766903, grad/param norm = 2.7774e-01, time/batch = 17.9368s	
5453/11350 (epoch 24.022), train_loss = 0.75535217, grad/param norm = 2.8669e-01, time/batch = 16.5172s	
5454/11350 (epoch 24.026), train_loss = 0.74708106, grad/param norm = 3.5290e-01, time/batch = 20.6906s	
5455/11350 (epoch 24.031), train_loss = 0.81404880, grad/param norm = 2.9718e-01, time/batch = 17.2068s	
5456/11350 (epoch 24.035), train_loss = 0.80088207, grad/param norm = 3.0417e-01, time/batch = 18.4484s	
5457/11350 (epoch 24.040), train_loss = 0.83092319, grad/param norm = 3.1884e-01, time/batch = 19.7062s	
5458/11350 (epoch 24.044), train_loss = 0.79039394, grad/param norm = 2.6059e-01, time/batch = 17.4125s	
5459/11350 (epoch 24.048), train_loss = 0.75652124, grad/param norm = 2.5771e-01, time/batch = 18.1105s	
5460/11350 (epoch 24.053), train_loss = 0.87979727, grad/param norm = 2.9694e-01, time/batch = 17.3655s	
5461/11350 (epoch 24.057), train_loss = 0.88298314, grad/param norm = 3.0037e-01, time/batch = 19.3544s	
5462/11350 (epoch 24.062), train_loss = 0.73461462, grad/param norm = 2.8830e-01, time/batch = 19.4497s	
5463/11350 (epoch 24.066), train_loss = 0.71577894, grad/param norm = 2.6833e-01, time/batch = 19.9500s	
5464/11350 (epoch 24.070), train_loss = 0.79955906, grad/param norm = 3.0597e-01, time/batch = 17.5453s	
5465/11350 (epoch 24.075), train_loss = 0.72672026, grad/param norm = 2.5595e-01, time/batch = 19.4466s	
5466/11350 (epoch 24.079), train_loss = 0.85157093, grad/param norm = 2.8343e-01, time/batch = 18.7979s	
5467/11350 (epoch 24.084), train_loss = 0.99440601, grad/param norm = 3.1031e-01, time/batch = 20.0329s	
5468/11350 (epoch 24.088), train_loss = 0.94478352, grad/param norm = 3.2996e-01, time/batch = 19.3578s	
5469/11350 (epoch 24.093), train_loss = 0.90809997, grad/param norm = 2.8887e-01, time/batch = 18.7065s	
5470/11350 (epoch 24.097), train_loss = 0.85471401, grad/param norm = 3.0059e-01, time/batch = 17.9377s	
5471/11350 (epoch 24.101), train_loss = 0.78815958, grad/param norm = 2.7984e-01, time/batch = 18.6958s	
5472/11350 (epoch 24.106), train_loss = 0.91946501, grad/param norm = 3.1392e-01, time/batch = 18.6141s	
5473/11350 (epoch 24.110), train_loss = 0.80027883, grad/param norm = 2.7076e-01, time/batch = 17.5319s	
5474/11350 (epoch 24.115), train_loss = 0.81751338, grad/param norm = 3.0021e-01, time/batch = 17.3586s	
5475/11350 (epoch 24.119), train_loss = 0.94194493, grad/param norm = 2.9896e-01, time/batch = 16.6570s	
5476/11350 (epoch 24.123), train_loss = 0.78139770, grad/param norm = 2.9682e-01, time/batch = 17.9628s	
5477/11350 (epoch 24.128), train_loss = 0.72957876, grad/param norm = 3.1724e-01, time/batch = 18.5265s	
5478/11350 (epoch 24.132), train_loss = 0.80887356, grad/param norm = 2.8096e-01, time/batch = 16.6908s	
5479/11350 (epoch 24.137), train_loss = 0.79002490, grad/param norm = 3.0400e-01, time/batch = 18.2719s	
5480/11350 (epoch 24.141), train_loss = 1.00407920, grad/param norm = 3.4438e-01, time/batch = 18.8652s	
5481/11350 (epoch 24.145), train_loss = 0.78681984, grad/param norm = 2.6484e-01, time/batch = 17.9356s	
5482/11350 (epoch 24.150), train_loss = 0.88394551, grad/param norm = 3.6622e-01, time/batch = 18.7904s	
5483/11350 (epoch 24.154), train_loss = 1.02769502, grad/param norm = 3.2514e-01, time/batch = 18.6184s	
5484/11350 (epoch 24.159), train_loss = 0.73038470, grad/param norm = 3.2566e-01, time/batch = 18.2164s	
5485/11350 (epoch 24.163), train_loss = 0.95677894, grad/param norm = 3.5511e-01, time/batch = 18.2030s	
5486/11350 (epoch 24.167), train_loss = 0.99883410, grad/param norm = 2.9826e-01, time/batch = 20.5294s	
5487/11350 (epoch 24.172), train_loss = 1.05924641, grad/param norm = 2.7772e-01, time/batch = 17.5302s	
5488/11350 (epoch 24.176), train_loss = 0.88944884, grad/param norm = 3.0182e-01, time/batch = 18.2037s	
5489/11350 (epoch 24.181), train_loss = 0.92819310, grad/param norm = 3.3394e-01, time/batch = 20.0236s	
5490/11350 (epoch 24.185), train_loss = 0.75731601, grad/param norm = 2.8174e-01, time/batch = 19.0123s	
5491/11350 (epoch 24.189), train_loss = 0.85163097, grad/param norm = 2.9656e-01, time/batch = 18.1984s	
5492/11350 (epoch 24.194), train_loss = 0.80094493, grad/param norm = 3.0739e-01, time/batch = 18.7088s	
5493/11350 (epoch 24.198), train_loss = 0.73269660, grad/param norm = 2.9873e-01, time/batch = 19.0979s	
5494/11350 (epoch 24.203), train_loss = 0.76921804, grad/param norm = 2.8459e-01, time/batch = 18.3674s	
5495/11350 (epoch 24.207), train_loss = 0.74260681, grad/param norm = 3.6559e-01, time/batch = 19.2092s	
5496/11350 (epoch 24.211), train_loss = 0.96606467, grad/param norm = 3.4259e-01, time/batch = 17.1781s	
5497/11350 (epoch 24.216), train_loss = 0.90983017, grad/param norm = 2.9858e-01, time/batch = 17.0289s	
5498/11350 (epoch 24.220), train_loss = 0.90813368, grad/param norm = 3.0709e-01, time/batch = 20.4401s	
5499/11350 (epoch 24.225), train_loss = 0.79538266, grad/param norm = 2.5494e-01, time/batch = 17.8665s	
5500/11350 (epoch 24.229), train_loss = 0.90901711, grad/param norm = 3.0513e-01, time/batch = 17.2606s	
5501/11350 (epoch 24.233), train_loss = 0.87874969, grad/param norm = 3.1181e-01, time/batch = 19.7121s	
5502/11350 (epoch 24.238), train_loss = 0.99856390, grad/param norm = 4.1559e-01, time/batch = 20.2852s	
5503/11350 (epoch 24.242), train_loss = 1.01962688, grad/param norm = 4.0178e-01, time/batch = 19.0461s	
5504/11350 (epoch 24.247), train_loss = 0.75423987, grad/param norm = 2.6417e-01, time/batch = 19.2836s	
5505/11350 (epoch 24.251), train_loss = 0.90949932, grad/param norm = 2.9199e-01, time/batch = 19.7589s	
5506/11350 (epoch 24.256), train_loss = 0.89319751, grad/param norm = 3.3068e-01, time/batch = 18.6036s	
5507/11350 (epoch 24.260), train_loss = 0.81711042, grad/param norm = 3.1521e-01, time/batch = 19.0352s	
5508/11350 (epoch 24.264), train_loss = 0.82706582, grad/param norm = 3.3275e-01, time/batch = 18.4587s	
5509/11350 (epoch 24.269), train_loss = 0.86545225, grad/param norm = 3.1409e-01, time/batch = 19.3665s	
5510/11350 (epoch 24.273), train_loss = 0.98410892, grad/param norm = 3.1697e-01, time/batch = 17.9463s	
5511/11350 (epoch 24.278), train_loss = 0.81864478, grad/param norm = 2.8800e-01, time/batch = 18.0384s	
5512/11350 (epoch 24.282), train_loss = 0.86289658, grad/param norm = 2.8891e-01, time/batch = 15.7815s	
5513/11350 (epoch 24.286), train_loss = 0.97164550, grad/param norm = 3.2594e-01, time/batch = 17.7866s	
5514/11350 (epoch 24.291), train_loss = 0.77634555, grad/param norm = 3.4238e-01, time/batch = 18.5476s	
5515/11350 (epoch 24.295), train_loss = 0.90252628, grad/param norm = 3.9050e-01, time/batch = 18.6309s	
5516/11350 (epoch 24.300), train_loss = 0.94944178, grad/param norm = 3.1753e-01, time/batch = 18.7962s	
5517/11350 (epoch 24.304), train_loss = 0.82167667, grad/param norm = 3.1196e-01, time/batch = 18.1017s	
5518/11350 (epoch 24.308), train_loss = 0.82192034, grad/param norm = 2.9968e-01, time/batch = 18.4516s	
5519/11350 (epoch 24.313), train_loss = 0.91124479, grad/param norm = 2.7082e-01, time/batch = 18.7021s	
5520/11350 (epoch 24.317), train_loss = 0.82097237, grad/param norm = 2.6730e-01, time/batch = 17.8067s	
5521/11350 (epoch 24.322), train_loss = 0.81491653, grad/param norm = 2.6726e-01, time/batch = 17.5365s	
5522/11350 (epoch 24.326), train_loss = 0.86068642, grad/param norm = 2.5515e-01, time/batch = 18.8008s	
5523/11350 (epoch 24.330), train_loss = 0.71144878, grad/param norm = 2.5504e-01, time/batch = 17.8656s	
5524/11350 (epoch 24.335), train_loss = 0.60827955, grad/param norm = 2.6450e-01, time/batch = 20.2893s	
5525/11350 (epoch 24.339), train_loss = 0.69538991, grad/param norm = 2.6867e-01, time/batch = 17.8919s	
5526/11350 (epoch 24.344), train_loss = 0.78683764, grad/param norm = 2.5961e-01, time/batch = 17.8625s	
5527/11350 (epoch 24.348), train_loss = 0.79110113, grad/param norm = 2.6790e-01, time/batch = 18.7017s	
5528/11350 (epoch 24.352), train_loss = 0.69998180, grad/param norm = 2.5732e-01, time/batch = 19.2960s	
5529/11350 (epoch 24.357), train_loss = 0.79964630, grad/param norm = 2.5890e-01, time/batch = 17.2659s	
5530/11350 (epoch 24.361), train_loss = 0.63535618, grad/param norm = 2.2095e-01, time/batch = 18.8706s	
5531/11350 (epoch 24.366), train_loss = 0.87382686, grad/param norm = 3.1657e-01, time/batch = 20.4536s	
5532/11350 (epoch 24.370), train_loss = 0.72860870, grad/param norm = 2.9842e-01, time/batch = 19.3608s	
5533/11350 (epoch 24.374), train_loss = 0.79491577, grad/param norm = 3.0182e-01, time/batch = 19.8571s	
5534/11350 (epoch 24.379), train_loss = 0.77751875, grad/param norm = 2.6973e-01, time/batch = 19.2969s	
5535/11350 (epoch 24.383), train_loss = 0.71787781, grad/param norm = 2.7502e-01, time/batch = 17.6277s	
5536/11350 (epoch 24.388), train_loss = 0.82711029, grad/param norm = 3.5124e-01, time/batch = 17.1369s	
5537/11350 (epoch 24.392), train_loss = 0.85627066, grad/param norm = 3.0412e-01, time/batch = 18.5429s	
5538/11350 (epoch 24.396), train_loss = 0.82695805, grad/param norm = 3.0516e-01, time/batch = 19.1227s	
5539/11350 (epoch 24.401), train_loss = 0.85422200, grad/param norm = 3.4578e-01, time/batch = 17.5931s	
5540/11350 (epoch 24.405), train_loss = 1.02002947, grad/param norm = 3.3585e-01, time/batch = 18.7980s	
5541/11350 (epoch 24.410), train_loss = 1.04455520, grad/param norm = 3.6498e-01, time/batch = 18.1961s	
5542/11350 (epoch 24.414), train_loss = 0.73658389, grad/param norm = 2.9766e-01, time/batch = 17.7134s	
5543/11350 (epoch 24.419), train_loss = 0.77817875, grad/param norm = 3.5654e-01, time/batch = 18.3974s	
5544/11350 (epoch 24.423), train_loss = 0.88025566, grad/param norm = 3.9195e-01, time/batch = 18.2284s	
5545/11350 (epoch 24.427), train_loss = 0.93761645, grad/param norm = 3.1597e-01, time/batch = 18.1312s	
5546/11350 (epoch 24.432), train_loss = 0.87917584, grad/param norm = 3.3447e-01, time/batch = 19.0478s	
5547/11350 (epoch 24.436), train_loss = 0.81646306, grad/param norm = 3.1526e-01, time/batch = 19.2041s	
5548/11350 (epoch 24.441), train_loss = 1.00340432, grad/param norm = 3.1737e-01, time/batch = 17.8716s	
5549/11350 (epoch 24.445), train_loss = 0.73471837, grad/param norm = 2.5355e-01, time/batch = 18.8691s	
5550/11350 (epoch 24.449), train_loss = 0.81806135, grad/param norm = 3.1169e-01, time/batch = 15.2149s	
5551/11350 (epoch 24.454), train_loss = 0.97253701, grad/param norm = 3.1013e-01, time/batch = 19.7106s	
5552/11350 (epoch 24.458), train_loss = 0.69726062, grad/param norm = 2.6567e-01, time/batch = 16.2616s	
5553/11350 (epoch 24.463), train_loss = 0.71829788, grad/param norm = 2.6461e-01, time/batch = 18.1145s	
5554/11350 (epoch 24.467), train_loss = 1.12811879, grad/param norm = 3.1528e-01, time/batch = 19.4631s	
5555/11350 (epoch 24.471), train_loss = 0.99485922, grad/param norm = 3.6031e-01, time/batch = 16.9456s	
5556/11350 (epoch 24.476), train_loss = 0.90356048, grad/param norm = 2.9790e-01, time/batch = 19.4388s	
5557/11350 (epoch 24.480), train_loss = 0.98702666, grad/param norm = 2.9998e-01, time/batch = 18.4618s	
5558/11350 (epoch 24.485), train_loss = 0.85482195, grad/param norm = 2.7106e-01, time/batch = 17.0992s	
5559/11350 (epoch 24.489), train_loss = 0.98871178, grad/param norm = 3.0265e-01, time/batch = 19.9507s	
5560/11350 (epoch 24.493), train_loss = 0.99387632, grad/param norm = 3.2409e-01, time/batch = 19.4474s	
5561/11350 (epoch 24.498), train_loss = 0.67726980, grad/param norm = 2.4906e-01, time/batch = 18.8628s	
5562/11350 (epoch 24.502), train_loss = 0.96486520, grad/param norm = 2.8599e-01, time/batch = 18.3719s	
5563/11350 (epoch 24.507), train_loss = 0.75624249, grad/param norm = 2.7536e-01, time/batch = 20.0410s	
5564/11350 (epoch 24.511), train_loss = 1.00683226, grad/param norm = 2.9443e-01, time/batch = 19.2863s	
5565/11350 (epoch 24.515), train_loss = 0.86986876, grad/param norm = 2.7422e-01, time/batch = 17.9653s	
5566/11350 (epoch 24.520), train_loss = 1.03358319, grad/param norm = 3.1954e-01, time/batch = 20.1184s	
5567/11350 (epoch 24.524), train_loss = 0.88265886, grad/param norm = 3.0283e-01, time/batch = 20.2823s	
5568/11350 (epoch 24.529), train_loss = 0.85037241, grad/param norm = 2.8394e-01, time/batch = 19.8572s	
5569/11350 (epoch 24.533), train_loss = 1.05743852, grad/param norm = 3.1194e-01, time/batch = 17.0496s	
5570/11350 (epoch 24.537), train_loss = 0.97160190, grad/param norm = 3.0436e-01, time/batch = 16.2583s	
5571/11350 (epoch 24.542), train_loss = 0.92843673, grad/param norm = 2.5578e-01, time/batch = 16.7829s	
5572/11350 (epoch 24.546), train_loss = 1.12196802, grad/param norm = 3.2113e-01, time/batch = 20.5278s	
5573/11350 (epoch 24.551), train_loss = 0.92551461, grad/param norm = 2.8816e-01, time/batch = 19.1184s	
5574/11350 (epoch 24.555), train_loss = 0.83007980, grad/param norm = 2.9333e-01, time/batch = 18.5293s	
5575/11350 (epoch 24.559), train_loss = 0.85742142, grad/param norm = 2.8489e-01, time/batch = 18.0908s	
5576/11350 (epoch 24.564), train_loss = 0.95510100, grad/param norm = 3.1216e-01, time/batch = 19.4638s	
5577/11350 (epoch 24.568), train_loss = 0.95069382, grad/param norm = 2.5672e-01, time/batch = 19.1944s	
5578/11350 (epoch 24.573), train_loss = 1.05464202, grad/param norm = 3.0806e-01, time/batch = 19.9363s	
5579/11350 (epoch 24.577), train_loss = 1.01857154, grad/param norm = 3.6662e-01, time/batch = 18.5413s	
5580/11350 (epoch 24.581), train_loss = 0.99304725, grad/param norm = 2.9264e-01, time/batch = 18.1827s	
5581/11350 (epoch 24.586), train_loss = 1.00624720, grad/param norm = 2.8369e-01, time/batch = 18.2927s	
5582/11350 (epoch 24.590), train_loss = 1.09311020, grad/param norm = 3.4524e-01, time/batch = 19.6042s	
5583/11350 (epoch 24.595), train_loss = 1.11791272, grad/param norm = 2.8641e-01, time/batch = 19.0449s	
5584/11350 (epoch 24.599), train_loss = 1.00985962, grad/param norm = 2.9227e-01, time/batch = 16.5119s	
5585/11350 (epoch 24.604), train_loss = 0.94308972, grad/param norm = 2.7616e-01, time/batch = 16.3665s	
5586/11350 (epoch 24.608), train_loss = 0.92191651, grad/param norm = 3.3860e-01, time/batch = 18.3091s	
5587/11350 (epoch 24.612), train_loss = 0.87968993, grad/param norm = 2.6142e-01, time/batch = 15.8828s	
5588/11350 (epoch 24.617), train_loss = 1.02532487, grad/param norm = 3.5914e-01, time/batch = 16.0100s	
5589/11350 (epoch 24.621), train_loss = 1.04103788, grad/param norm = 2.8488e-01, time/batch = 15.3701s	
5590/11350 (epoch 24.626), train_loss = 0.94100981, grad/param norm = 2.9662e-01, time/batch = 15.6086s	
5591/11350 (epoch 24.630), train_loss = 0.99581972, grad/param norm = 3.1656e-01, time/batch = 15.8483s	
5592/11350 (epoch 24.634), train_loss = 0.95148163, grad/param norm = 4.3789e-01, time/batch = 14.8109s	
5593/11350 (epoch 24.639), train_loss = 0.86672050, grad/param norm = 3.0884e-01, time/batch = 16.4471s	
5594/11350 (epoch 24.643), train_loss = 0.83694435, grad/param norm = 2.9562e-01, time/batch = 18.5500s	
5595/11350 (epoch 24.648), train_loss = 0.92166463, grad/param norm = 2.8470e-01, time/batch = 18.0188s	
5596/11350 (epoch 24.652), train_loss = 0.83472761, grad/param norm = 3.0917e-01, time/batch = 18.6232s	
5597/11350 (epoch 24.656), train_loss = 0.95709068, grad/param norm = 3.1978e-01, time/batch = 19.7789s	
5598/11350 (epoch 24.661), train_loss = 1.07382970, grad/param norm = 3.8376e-01, time/batch = 19.1146s	
5599/11350 (epoch 24.665), train_loss = 0.99078811, grad/param norm = 4.6094e-01, time/batch = 20.0327s	
5600/11350 (epoch 24.670), train_loss = 0.96895207, grad/param norm = 3.0562e-01, time/batch = 17.7294s	
5601/11350 (epoch 24.674), train_loss = 0.87714174, grad/param norm = 2.6521e-01, time/batch = 17.5559s	
5602/11350 (epoch 24.678), train_loss = 0.93372666, grad/param norm = 3.4059e-01, time/batch = 18.2789s	
5603/11350 (epoch 24.683), train_loss = 0.86841913, grad/param norm = 3.3946e-01, time/batch = 18.7937s	
5604/11350 (epoch 24.687), train_loss = 0.83500030, grad/param norm = 3.2982e-01, time/batch = 26.7584s	
5605/11350 (epoch 24.692), train_loss = 1.23702533, grad/param norm = 4.1023e-01, time/batch = 25.3586s	
5606/11350 (epoch 24.696), train_loss = 1.10709415, grad/param norm = 3.2935e-01, time/batch = 17.4433s	
5607/11350 (epoch 24.700), train_loss = 1.04274478, grad/param norm = 3.4794e-01, time/batch = 18.5890s	
5608/11350 (epoch 24.705), train_loss = 1.07045542, grad/param norm = 3.4188e-01, time/batch = 20.0284s	
5609/11350 (epoch 24.709), train_loss = 1.07891191, grad/param norm = 3.4174e-01, time/batch = 19.5479s	
5610/11350 (epoch 24.714), train_loss = 0.94478251, grad/param norm = 3.0668e-01, time/batch = 18.9490s	
5611/11350 (epoch 24.718), train_loss = 0.81700661, grad/param norm = 3.0522e-01, time/batch = 20.2053s	
5612/11350 (epoch 24.722), train_loss = 0.96348258, grad/param norm = 4.0271e-01, time/batch = 20.6146s	
5613/11350 (epoch 24.727), train_loss = 0.94494676, grad/param norm = 3.0274e-01, time/batch = 18.3627s	
5614/11350 (epoch 24.731), train_loss = 0.99525661, grad/param norm = 3.3464e-01, time/batch = 18.5394s	
5615/11350 (epoch 24.736), train_loss = 0.88919335, grad/param norm = 3.6406e-01, time/batch = 20.7820s	
5616/11350 (epoch 24.740), train_loss = 0.93497241, grad/param norm = 3.1411e-01, time/batch = 18.7773s	
5617/11350 (epoch 24.744), train_loss = 0.95019199, grad/param norm = 3.1113e-01, time/batch = 17.5304s	
5618/11350 (epoch 24.749), train_loss = 0.99555811, grad/param norm = 3.9716e-01, time/batch = 20.8668s	
5619/11350 (epoch 24.753), train_loss = 1.02278950, grad/param norm = 3.4903e-01, time/batch = 16.6047s	
5620/11350 (epoch 24.758), train_loss = 0.90871574, grad/param norm = 3.1755e-01, time/batch = 17.0158s	
5621/11350 (epoch 24.762), train_loss = 1.02859923, grad/param norm = 2.8599e-01, time/batch = 19.0407s	
5622/11350 (epoch 24.767), train_loss = 1.03051384, grad/param norm = 2.8943e-01, time/batch = 19.7029s	
5623/11350 (epoch 24.771), train_loss = 1.14620292, grad/param norm = 3.2540e-01, time/batch = 20.3593s	
5624/11350 (epoch 24.775), train_loss = 0.91891087, grad/param norm = 2.9896e-01, time/batch = 18.3699s	
5625/11350 (epoch 24.780), train_loss = 1.03483634, grad/param norm = 3.0097e-01, time/batch = 20.2749s	
5626/11350 (epoch 24.784), train_loss = 0.91389868, grad/param norm = 3.0623e-01, time/batch = 19.2011s	
5627/11350 (epoch 24.789), train_loss = 0.93628140, grad/param norm = 2.8851e-01, time/batch = 19.0334s	
5628/11350 (epoch 24.793), train_loss = 1.04633979, grad/param norm = 3.0193e-01, time/batch = 19.5325s	
5629/11350 (epoch 24.797), train_loss = 0.92866396, grad/param norm = 2.7424e-01, time/batch = 18.5124s	
5630/11350 (epoch 24.802), train_loss = 1.00500697, grad/param norm = 3.0576e-01, time/batch = 20.4477s	
5631/11350 (epoch 24.806), train_loss = 1.01375329, grad/param norm = 2.9182e-01, time/batch = 16.6835s	
5632/11350 (epoch 24.811), train_loss = 0.97481199, grad/param norm = 3.0397e-01, time/batch = 20.8425s	
5633/11350 (epoch 24.815), train_loss = 0.89627999, grad/param norm = 2.7958e-01, time/batch = 18.5201s	
5634/11350 (epoch 24.819), train_loss = 0.85515621, grad/param norm = 2.8428e-01, time/batch = 20.3754s	
5635/11350 (epoch 24.824), train_loss = 0.83407199, grad/param norm = 3.1851e-01, time/batch = 18.5318s	
5636/11350 (epoch 24.828), train_loss = 0.91436605, grad/param norm = 2.8945e-01, time/batch = 19.0517s	
5637/11350 (epoch 24.833), train_loss = 0.93595748, grad/param norm = 2.9538e-01, time/batch = 20.1834s	
5638/11350 (epoch 24.837), train_loss = 0.98021966, grad/param norm = 3.6854e-01, time/batch = 18.5233s	
5639/11350 (epoch 24.841), train_loss = 1.19928677, grad/param norm = 3.3952e-01, time/batch = 18.7849s	
5640/11350 (epoch 24.846), train_loss = 0.97081941, grad/param norm = 2.7957e-01, time/batch = 20.7828s	
5641/11350 (epoch 24.850), train_loss = 1.03674083, grad/param norm = 3.4126e-01, time/batch = 18.4329s	
5642/11350 (epoch 24.855), train_loss = 0.80488155, grad/param norm = 2.7615e-01, time/batch = 20.9538s	
5643/11350 (epoch 24.859), train_loss = 0.92386422, grad/param norm = 3.5850e-01, time/batch = 20.7063s	
5644/11350 (epoch 24.863), train_loss = 0.82216320, grad/param norm = 3.1614e-01, time/batch = 18.4409s	
5645/11350 (epoch 24.868), train_loss = 0.85892707, grad/param norm = 2.7773e-01, time/batch = 16.5480s	
5646/11350 (epoch 24.872), train_loss = 0.90259903, grad/param norm = 2.9961e-01, time/batch = 20.0227s	
5647/11350 (epoch 24.877), train_loss = 0.93410139, grad/param norm = 3.1734e-01, time/batch = 17.8721s	
5648/11350 (epoch 24.881), train_loss = 1.11921003, grad/param norm = 3.9170e-01, time/batch = 18.2691s	
5649/11350 (epoch 24.885), train_loss = 1.10073853, grad/param norm = 3.5834e-01, time/batch = 19.3031s	
5650/11350 (epoch 24.890), train_loss = 0.98482322, grad/param norm = 3.1208e-01, time/batch = 18.4346s	
5651/11350 (epoch 24.894), train_loss = 0.80119148, grad/param norm = 2.9455e-01, time/batch = 15.7428s	
5652/11350 (epoch 24.899), train_loss = 1.00000304, grad/param norm = 3.2299e-01, time/batch = 18.6892s	
5653/11350 (epoch 24.903), train_loss = 0.98642660, grad/param norm = 2.9794e-01, time/batch = 19.2848s	
5654/11350 (epoch 24.907), train_loss = 0.94702148, grad/param norm = 2.9951e-01, time/batch = 17.6106s	
5655/11350 (epoch 24.912), train_loss = 0.86119683, grad/param norm = 2.6982e-01, time/batch = 18.2094s	
5656/11350 (epoch 24.916), train_loss = 1.00431735, grad/param norm = 2.9913e-01, time/batch = 19.7973s	
5657/11350 (epoch 24.921), train_loss = 0.99727085, grad/param norm = 3.0258e-01, time/batch = 19.2629s	
5658/11350 (epoch 24.925), train_loss = 0.80790392, grad/param norm = 2.4690e-01, time/batch = 18.7272s	
5659/11350 (epoch 24.930), train_loss = 1.01224790, grad/param norm = 3.4779e-01, time/batch = 18.9714s	
5660/11350 (epoch 24.934), train_loss = 1.11544977, grad/param norm = 3.8632e-01, time/batch = 17.1093s	
5661/11350 (epoch 24.938), train_loss = 0.94585277, grad/param norm = 2.9498e-01, time/batch = 19.3825s	
5662/11350 (epoch 24.943), train_loss = 1.03900035, grad/param norm = 2.8768e-01, time/batch = 18.1388s	
5663/11350 (epoch 24.947), train_loss = 0.99444313, grad/param norm = 3.2400e-01, time/batch = 18.2020s	
5664/11350 (epoch 24.952), train_loss = 1.00977016, grad/param norm = 3.5860e-01, time/batch = 17.8655s	
5665/11350 (epoch 24.956), train_loss = 0.77759211, grad/param norm = 2.5962e-01, time/batch = 17.2138s	
5666/11350 (epoch 24.960), train_loss = 0.89013500, grad/param norm = 3.4928e-01, time/batch = 18.5556s	
5667/11350 (epoch 24.965), train_loss = 0.81452489, grad/param norm = 2.8457e-01, time/batch = 4.7749s	
5668/11350 (epoch 24.969), train_loss = 0.83387107, grad/param norm = 3.0424e-01, time/batch = 0.6725s	
5669/11350 (epoch 24.974), train_loss = 0.82330824, grad/param norm = 3.3863e-01, time/batch = 0.7097s	
5670/11350 (epoch 24.978), train_loss = 0.93225256, grad/param norm = 2.9426e-01, time/batch = 0.6900s	
5671/11350 (epoch 24.982), train_loss = 0.67782646, grad/param norm = 2.8149e-01, time/batch = 0.6741s	
5672/11350 (epoch 24.987), train_loss = 0.92160292, grad/param norm = 3.0607e-01, time/batch = 0.6734s	
5673/11350 (epoch 24.991), train_loss = 0.80877571, grad/param norm = 3.0453e-01, time/batch = 0.6741s	
5674/11350 (epoch 24.996), train_loss = 0.95649303, grad/param norm = 3.2646e-01, time/batch = 0.7996s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
5675/11350 (epoch 25.000), train_loss = 0.71795002, grad/param norm = 3.0639e-01, time/batch = 0.9906s	
5676/11350 (epoch 25.004), train_loss = 0.95684464, grad/param norm = 3.2700e-01, time/batch = 0.9956s	
5677/11350 (epoch 25.009), train_loss = 0.93919939, grad/param norm = 3.4559e-01, time/batch = 0.9783s	
5678/11350 (epoch 25.013), train_loss = 0.65995894, grad/param norm = 2.7438e-01, time/batch = 0.9893s	
5679/11350 (epoch 25.018), train_loss = 0.72957511, grad/param norm = 2.8021e-01, time/batch = 1.2761s	
5680/11350 (epoch 25.022), train_loss = 0.73370148, grad/param norm = 2.9528e-01, time/batch = 1.8898s	
5681/11350 (epoch 25.026), train_loss = 0.73683470, grad/param norm = 3.2927e-01, time/batch = 1.8433s	
5682/11350 (epoch 25.031), train_loss = 0.80723283, grad/param norm = 3.0641e-01, time/batch = 13.3223s	
5683/11350 (epoch 25.035), train_loss = 0.80034437, grad/param norm = 3.5813e-01, time/batch = 17.1261s	
5684/11350 (epoch 25.040), train_loss = 0.80602186, grad/param norm = 2.8544e-01, time/batch = 16.5951s	
5685/11350 (epoch 25.044), train_loss = 0.76933105, grad/param norm = 2.4708e-01, time/batch = 19.2160s	
5686/11350 (epoch 25.048), train_loss = 0.73082812, grad/param norm = 2.4010e-01, time/batch = 19.1248s	
5687/11350 (epoch 25.053), train_loss = 0.83663424, grad/param norm = 3.3929e-01, time/batch = 17.8759s	
5688/11350 (epoch 25.057), train_loss = 0.86215660, grad/param norm = 3.3088e-01, time/batch = 19.4418s	
5689/11350 (epoch 25.062), train_loss = 0.70342794, grad/param norm = 2.7233e-01, time/batch = 20.1145s	
5690/11350 (epoch 25.066), train_loss = 0.69096099, grad/param norm = 3.2451e-01, time/batch = 19.0315s	
5691/11350 (epoch 25.070), train_loss = 0.78798895, grad/param norm = 3.2003e-01, time/batch = 19.2816s	
5692/11350 (epoch 25.075), train_loss = 0.71476479, grad/param norm = 2.5939e-01, time/batch = 18.6976s	
5693/11350 (epoch 25.079), train_loss = 0.82627153, grad/param norm = 2.7379e-01, time/batch = 19.4488s	
5694/11350 (epoch 25.084), train_loss = 0.96635767, grad/param norm = 3.3171e-01, time/batch = 17.3752s	
5695/11350 (epoch 25.088), train_loss = 0.91460341, grad/param norm = 3.2726e-01, time/batch = 16.6331s	
5696/11350 (epoch 25.093), train_loss = 0.87777069, grad/param norm = 2.6493e-01, time/batch = 20.3620s	
5697/11350 (epoch 25.097), train_loss = 0.84047003, grad/param norm = 3.1030e-01, time/batch = 17.6988s	
5698/11350 (epoch 25.101), train_loss = 0.77894343, grad/param norm = 3.1725e-01, time/batch = 18.8739s	
5699/11350 (epoch 25.106), train_loss = 0.89991454, grad/param norm = 3.4092e-01, time/batch = 19.6289s	
5700/11350 (epoch 25.110), train_loss = 0.77050161, grad/param norm = 2.9923e-01, time/batch = 19.1907s	
5701/11350 (epoch 25.115), train_loss = 0.81224850, grad/param norm = 3.1711e-01, time/batch = 18.4309s	
5702/11350 (epoch 25.119), train_loss = 0.91358355, grad/param norm = 3.0945e-01, time/batch = 15.5533s	
5703/11350 (epoch 25.123), train_loss = 0.75734021, grad/param norm = 2.8078e-01, time/batch = 18.8734s	
5704/11350 (epoch 25.128), train_loss = 0.69955475, grad/param norm = 3.0348e-01, time/batch = 16.5193s	
5705/11350 (epoch 25.132), train_loss = 0.76539082, grad/param norm = 2.6509e-01, time/batch = 18.6290s	
5706/11350 (epoch 25.137), train_loss = 0.74388522, grad/param norm = 2.4792e-01, time/batch = 20.6040s	
5707/11350 (epoch 25.141), train_loss = 0.96643163, grad/param norm = 3.6638e-01, time/batch = 18.8630s	
5708/11350 (epoch 25.145), train_loss = 0.75454045, grad/param norm = 2.7011e-01, time/batch = 19.5538s	
5709/11350 (epoch 25.150), train_loss = 0.87877642, grad/param norm = 4.3207e-01, time/batch = 20.5284s	
5710/11350 (epoch 25.154), train_loss = 0.98546970, grad/param norm = 3.5844e-01, time/batch = 18.8538s	
5711/11350 (epoch 25.159), train_loss = 0.70515756, grad/param norm = 2.6987e-01, time/batch = 17.4544s	
5712/11350 (epoch 25.163), train_loss = 0.92901877, grad/param norm = 3.7762e-01, time/batch = 20.3727s	
5713/11350 (epoch 25.167), train_loss = 0.98371197, grad/param norm = 3.1532e-01, time/batch = 17.7816s	
5714/11350 (epoch 25.172), train_loss = 1.03405773, grad/param norm = 2.9556e-01, time/batch = 19.1095s	
5715/11350 (epoch 25.176), train_loss = 0.85463885, grad/param norm = 3.1040e-01, time/batch = 19.5255s	
5716/11350 (epoch 25.181), train_loss = 0.90952973, grad/param norm = 4.3558e-01, time/batch = 18.9479s	
5717/11350 (epoch 25.185), train_loss = 0.73732541, grad/param norm = 2.9059e-01, time/batch = 20.2897s	
5718/11350 (epoch 25.189), train_loss = 0.83481805, grad/param norm = 2.8925e-01, time/batch = 18.8729s	
5719/11350 (epoch 25.194), train_loss = 0.77779185, grad/param norm = 2.9664e-01, time/batch = 16.7515s	
5720/11350 (epoch 25.198), train_loss = 0.71770362, grad/param norm = 3.2148e-01, time/batch = 20.9493s	
5721/11350 (epoch 25.203), train_loss = 0.76219998, grad/param norm = 2.9119e-01, time/batch = 19.1137s	
5722/11350 (epoch 25.207), train_loss = 0.72504762, grad/param norm = 3.7111e-01, time/batch = 19.2013s	
5723/11350 (epoch 25.211), train_loss = 0.94503393, grad/param norm = 4.4398e-01, time/batch = 19.7814s	
5724/11350 (epoch 25.216), train_loss = 0.91183177, grad/param norm = 3.2234e-01, time/batch = 17.6820s	
5725/11350 (epoch 25.220), train_loss = 0.90024050, grad/param norm = 3.0172e-01, time/batch = 18.8504s	
5726/11350 (epoch 25.225), train_loss = 0.77750646, grad/param norm = 2.6716e-01, time/batch = 19.2044s	
5727/11350 (epoch 25.229), train_loss = 0.88880101, grad/param norm = 2.7393e-01, time/batch = 18.7690s	
5728/11350 (epoch 25.233), train_loss = 0.84075868, grad/param norm = 2.7756e-01, time/batch = 19.5269s	
5729/11350 (epoch 25.238), train_loss = 0.97609984, grad/param norm = 7.5115e-01, time/batch = 19.1952s	
5730/11350 (epoch 25.242), train_loss = 1.01201266, grad/param norm = 4.1020e-01, time/batch = 19.4563s	
5731/11350 (epoch 25.247), train_loss = 0.75287151, grad/param norm = 3.4015e-01, time/batch = 18.0176s	
5732/11350 (epoch 25.251), train_loss = 0.90304708, grad/param norm = 3.5383e-01, time/batch = 19.4209s	
5733/11350 (epoch 25.256), train_loss = 0.87034707, grad/param norm = 3.1389e-01, time/batch = 20.4424s	
5734/11350 (epoch 25.260), train_loss = 0.80064976, grad/param norm = 2.9323e-01, time/batch = 18.6977s	
5735/11350 (epoch 25.264), train_loss = 0.79274942, grad/param norm = 3.2385e-01, time/batch = 18.4355s	
5736/11350 (epoch 25.269), train_loss = 0.84476902, grad/param norm = 3.1886e-01, time/batch = 18.8692s	
5737/11350 (epoch 25.273), train_loss = 0.96263257, grad/param norm = 3.1057e-01, time/batch = 19.4582s	
5738/11350 (epoch 25.278), train_loss = 0.80058534, grad/param norm = 2.7585e-01, time/batch = 17.9551s	
5739/11350 (epoch 25.282), train_loss = 0.84139886, grad/param norm = 2.9812e-01, time/batch = 18.4721s	
5740/11350 (epoch 25.286), train_loss = 0.94762266, grad/param norm = 4.2043e-01, time/batch = 19.4507s	
5741/11350 (epoch 25.291), train_loss = 0.76931005, grad/param norm = 3.4653e-01, time/batch = 17.8573s	
5742/11350 (epoch 25.295), train_loss = 0.86103871, grad/param norm = 2.9932e-01, time/batch = 18.0161s	
5743/11350 (epoch 25.300), train_loss = 0.90614327, grad/param norm = 3.0776e-01, time/batch = 17.1299s	
5744/11350 (epoch 25.304), train_loss = 0.78648934, grad/param norm = 2.9466e-01, time/batch = 19.7672s	
5745/11350 (epoch 25.308), train_loss = 0.77946498, grad/param norm = 3.0725e-01, time/batch = 19.3521s	
5746/11350 (epoch 25.313), train_loss = 0.88049439, grad/param norm = 2.7773e-01, time/batch = 19.3803s	
5747/11350 (epoch 25.317), train_loss = 0.80225115, grad/param norm = 2.7038e-01, time/batch = 19.0372s	
5748/11350 (epoch 25.322), train_loss = 0.81260835, grad/param norm = 3.1162e-01, time/batch = 18.6993s	
5749/11350 (epoch 25.326), train_loss = 0.84192893, grad/param norm = 2.6533e-01, time/batch = 19.6255s	
5750/11350 (epoch 25.330), train_loss = 0.69967636, grad/param norm = 2.5019e-01, time/batch = 18.5348s	
5751/11350 (epoch 25.335), train_loss = 0.58139931, grad/param norm = 2.7357e-01, time/batch = 18.1853s	
5752/11350 (epoch 25.339), train_loss = 0.66901997, grad/param norm = 2.5846e-01, time/batch = 19.8013s	
5753/11350 (epoch 25.344), train_loss = 0.75778813, grad/param norm = 2.5732e-01, time/batch = 20.1948s	
5754/11350 (epoch 25.348), train_loss = 0.76830355, grad/param norm = 2.7829e-01, time/batch = 19.6738s	
5755/11350 (epoch 25.352), train_loss = 0.69109066, grad/param norm = 2.9650e-01, time/batch = 20.0416s	
5756/11350 (epoch 25.357), train_loss = 0.78154451, grad/param norm = 3.1117e-01, time/batch = 17.7078s	
5757/11350 (epoch 25.361), train_loss = 0.62310764, grad/param norm = 2.2116e-01, time/batch = 18.9339s	
5758/11350 (epoch 25.366), train_loss = 0.85148449, grad/param norm = 3.1436e-01, time/batch = 18.5336s	
5759/11350 (epoch 25.370), train_loss = 0.72092981, grad/param norm = 2.9231e-01, time/batch = 20.6162s	
5760/11350 (epoch 25.374), train_loss = 0.74369588, grad/param norm = 2.7639e-01, time/batch = 18.9367s	
5761/11350 (epoch 25.379), train_loss = 0.75466536, grad/param norm = 2.9285e-01, time/batch = 17.7768s	
5762/11350 (epoch 25.383), train_loss = 0.70710902, grad/param norm = 2.6886e-01, time/batch = 19.4361s	
5763/11350 (epoch 25.388), train_loss = 0.83141821, grad/param norm = 4.0800e-01, time/batch = 18.4364s	
5764/11350 (epoch 25.392), train_loss = 0.84232421, grad/param norm = 3.3316e-01, time/batch = 18.4656s	
5765/11350 (epoch 25.396), train_loss = 0.78023036, grad/param norm = 2.8453e-01, time/batch = 20.2078s	
5766/11350 (epoch 25.401), train_loss = 0.80818415, grad/param norm = 3.1622e-01, time/batch = 18.0234s	
5767/11350 (epoch 25.405), train_loss = 0.99549562, grad/param norm = 3.2547e-01, time/batch = 18.6345s	
5768/11350 (epoch 25.410), train_loss = 1.02299639, grad/param norm = 3.9309e-01, time/batch = 16.7266s	
5769/11350 (epoch 25.414), train_loss = 0.71185879, grad/param norm = 3.0209e-01, time/batch = 18.6276s	
5770/11350 (epoch 25.419), train_loss = 0.74386104, grad/param norm = 3.3441e-01, time/batch = 18.7640s	
5771/11350 (epoch 25.423), train_loss = 0.82920054, grad/param norm = 3.3428e-01, time/batch = 19.3538s	
5772/11350 (epoch 25.427), train_loss = 0.90780457, grad/param norm = 3.3027e-01, time/batch = 20.2857s	
5773/11350 (epoch 25.432), train_loss = 0.86559949, grad/param norm = 3.4408e-01, time/batch = 19.9212s	
5774/11350 (epoch 25.436), train_loss = 0.78583508, grad/param norm = 2.9573e-01, time/batch = 17.8505s	
5775/11350 (epoch 25.441), train_loss = 0.97840396, grad/param norm = 3.3733e-01, time/batch = 16.4292s	
5776/11350 (epoch 25.445), train_loss = 0.70551434, grad/param norm = 2.4636e-01, time/batch = 17.6171s	
5777/11350 (epoch 25.449), train_loss = 0.81203533, grad/param norm = 2.8695e-01, time/batch = 20.0304s	
5778/11350 (epoch 25.454), train_loss = 0.94785575, grad/param norm = 3.2694e-01, time/batch = 18.9618s	
5779/11350 (epoch 25.458), train_loss = 0.67535676, grad/param norm = 2.5595e-01, time/batch = 18.6113s	
5780/11350 (epoch 25.463), train_loss = 0.69877676, grad/param norm = 3.0449e-01, time/batch = 19.8682s	
5781/11350 (epoch 25.467), train_loss = 1.09702075, grad/param norm = 3.1557e-01, time/batch = 20.4486s	
5782/11350 (epoch 25.471), train_loss = 0.96859254, grad/param norm = 3.7335e-01, time/batch = 18.1199s	
5783/11350 (epoch 25.476), train_loss = 0.87526056, grad/param norm = 2.8495e-01, time/batch = 18.4473s	
5784/11350 (epoch 25.480), train_loss = 0.95918606, grad/param norm = 3.0313e-01, time/batch = 19.0437s	
5785/11350 (epoch 25.485), train_loss = 0.82967605, grad/param norm = 2.6793e-01, time/batch = 19.1140s	
5786/11350 (epoch 25.489), train_loss = 0.97745080, grad/param norm = 3.0889e-01, time/batch = 17.7976s	
5787/11350 (epoch 25.493), train_loss = 0.96118634, grad/param norm = 3.0262e-01, time/batch = 18.7808s	
5788/11350 (epoch 25.498), train_loss = 0.66253026, grad/param norm = 2.6473e-01, time/batch = 19.6255s	
5789/11350 (epoch 25.502), train_loss = 0.94190015, grad/param norm = 2.8618e-01, time/batch = 18.8635s	
5790/11350 (epoch 25.507), train_loss = 0.73958141, grad/param norm = 2.9891e-01, time/batch = 18.2056s	
5791/11350 (epoch 25.511), train_loss = 0.96863343, grad/param norm = 2.8999e-01, time/batch = 16.2698s	
5792/11350 (epoch 25.515), train_loss = 0.84690938, grad/param norm = 2.9692e-01, time/batch = 18.1053s	
5793/11350 (epoch 25.520), train_loss = 1.01234799, grad/param norm = 3.2659e-01, time/batch = 20.1322s	
5794/11350 (epoch 25.524), train_loss = 0.87644474, grad/param norm = 2.9938e-01, time/batch = 19.4615s	
5795/11350 (epoch 25.529), train_loss = 0.83962976, grad/param norm = 3.0068e-01, time/batch = 17.7885s	
5796/11350 (epoch 25.533), train_loss = 1.03207637, grad/param norm = 3.1759e-01, time/batch = 19.1901s	
5797/11350 (epoch 25.537), train_loss = 0.92779303, grad/param norm = 2.8966e-01, time/batch = 18.2104s	
5798/11350 (epoch 25.542), train_loss = 0.90046816, grad/param norm = 2.7702e-01, time/batch = 18.2868s	
5799/11350 (epoch 25.546), train_loss = 1.08634500, grad/param norm = 3.3558e-01, time/batch = 19.5453s	
5800/11350 (epoch 25.551), train_loss = 0.90005910, grad/param norm = 2.8951e-01, time/batch = 15.1582s	
5801/11350 (epoch 25.555), train_loss = 0.80121190, grad/param norm = 2.8518e-01, time/batch = 19.3794s	
5802/11350 (epoch 25.559), train_loss = 0.83075161, grad/param norm = 2.8189e-01, time/batch = 18.8573s	
5803/11350 (epoch 25.564), train_loss = 0.91968720, grad/param norm = 3.3504e-01, time/batch = 18.4664s	
5804/11350 (epoch 25.568), train_loss = 0.93430656, grad/param norm = 2.7627e-01, time/batch = 20.1347s	
5805/11350 (epoch 25.573), train_loss = 1.03775030, grad/param norm = 4.1931e-01, time/batch = 18.1167s	
5806/11350 (epoch 25.577), train_loss = 0.98377144, grad/param norm = 3.8376e-01, time/batch = 16.3484s	
5807/11350 (epoch 25.581), train_loss = 0.97720265, grad/param norm = 3.1313e-01, time/batch = 18.7875s	
5808/11350 (epoch 25.586), train_loss = 0.98301810, grad/param norm = 3.1112e-01, time/batch = 26.2610s	
5809/11350 (epoch 25.590), train_loss = 1.07409908, grad/param norm = 4.1089e-01, time/batch = 25.0516s	
5810/11350 (epoch 25.595), train_loss = 1.10403851, grad/param norm = 3.2749e-01, time/batch = 19.1201s	
5811/11350 (epoch 25.599), train_loss = 0.96756286, grad/param norm = 2.9450e-01, time/batch = 18.1185s	
5812/11350 (epoch 25.604), train_loss = 0.91635135, grad/param norm = 3.2770e-01, time/batch = 17.2079s	
5813/11350 (epoch 25.608), train_loss = 0.89067085, grad/param norm = 3.2648e-01, time/batch = 19.8042s	
5814/11350 (epoch 25.612), train_loss = 0.87508544, grad/param norm = 2.9351e-01, time/batch = 18.9490s	
5815/11350 (epoch 25.617), train_loss = 0.96994193, grad/param norm = 3.0745e-01, time/batch = 19.6306s	
5816/11350 (epoch 25.621), train_loss = 1.03519893, grad/param norm = 3.1401e-01, time/batch = 20.2033s	
5817/11350 (epoch 25.626), train_loss = 0.90932933, grad/param norm = 3.3312e-01, time/batch = 19.2881s	
5818/11350 (epoch 25.630), train_loss = 0.95222231, grad/param norm = 2.9884e-01, time/batch = 16.4362s	
5819/11350 (epoch 25.634), train_loss = 0.92577519, grad/param norm = 3.0829e-01, time/batch = 17.4325s	
5820/11350 (epoch 25.639), train_loss = 0.82323997, grad/param norm = 2.9450e-01, time/batch = 18.1994s	
5821/11350 (epoch 25.643), train_loss = 0.81391826, grad/param norm = 2.9579e-01, time/batch = 18.6113s	
5822/11350 (epoch 25.648), train_loss = 0.89945494, grad/param norm = 3.1064e-01, time/batch = 19.3656s	
5823/11350 (epoch 25.652), train_loss = 0.79778648, grad/param norm = 2.9031e-01, time/batch = 18.8481s	
5824/11350 (epoch 25.656), train_loss = 0.91415584, grad/param norm = 2.8671e-01, time/batch = 19.1221s	
5825/11350 (epoch 25.661), train_loss = 1.01479454, grad/param norm = 3.2569e-01, time/batch = 18.0542s	
5826/11350 (epoch 25.665), train_loss = 0.92390094, grad/param norm = 3.7455e-01, time/batch = 19.3661s	
5827/11350 (epoch 25.670), train_loss = 0.92162186, grad/param norm = 3.0021e-01, time/batch = 18.2845s	
5828/11350 (epoch 25.674), train_loss = 0.87822183, grad/param norm = 2.8542e-01, time/batch = 20.2859s	
5829/11350 (epoch 25.678), train_loss = 0.89826473, grad/param norm = 2.7639e-01, time/batch = 19.2958s	
5830/11350 (epoch 25.683), train_loss = 0.82906730, grad/param norm = 3.2816e-01, time/batch = 19.3698s	
5831/11350 (epoch 25.687), train_loss = 0.80541667, grad/param norm = 2.9922e-01, time/batch = 20.2794s	
5832/11350 (epoch 25.692), train_loss = 1.16332318, grad/param norm = 4.0580e-01, time/batch = 19.5442s	
5833/11350 (epoch 25.696), train_loss = 1.08071716, grad/param norm = 3.5747e-01, time/batch = 19.2025s	
5834/11350 (epoch 25.700), train_loss = 1.00024885, grad/param norm = 3.3457e-01, time/batch = 18.5320s	
5835/11350 (epoch 25.705), train_loss = 1.04829482, grad/param norm = 3.6703e-01, time/batch = 18.2797s	
5836/11350 (epoch 25.709), train_loss = 1.05634413, grad/param norm = 3.3995e-01, time/batch = 19.1923s	
5837/11350 (epoch 25.714), train_loss = 0.93898834, grad/param norm = 3.9074e-01, time/batch = 17.8681s	
5838/11350 (epoch 25.718), train_loss = 0.78852203, grad/param norm = 3.1739e-01, time/batch = 18.5855s	
5839/11350 (epoch 25.722), train_loss = 0.94052103, grad/param norm = 3.7911e-01, time/batch = 16.4229s	
5840/11350 (epoch 25.727), train_loss = 0.94585764, grad/param norm = 3.5361e-01, time/batch = 18.7177s	
5841/11350 (epoch 25.731), train_loss = 0.94045022, grad/param norm = 2.9776e-01, time/batch = 19.6275s	
5842/11350 (epoch 25.736), train_loss = 0.87106506, grad/param norm = 4.0895e-01, time/batch = 18.0219s	
5843/11350 (epoch 25.740), train_loss = 0.91111822, grad/param norm = 3.0230e-01, time/batch = 19.7516s	
5844/11350 (epoch 25.744), train_loss = 0.91143938, grad/param norm = 3.3957e-01, time/batch = 19.5433s	
5845/11350 (epoch 25.749), train_loss = 0.95563751, grad/param norm = 3.4101e-01, time/batch = 18.7151s	
5846/11350 (epoch 25.753), train_loss = 1.00908209, grad/param norm = 4.7655e-01, time/batch = 19.9322s	
5847/11350 (epoch 25.758), train_loss = 0.86758753, grad/param norm = 3.0847e-01, time/batch = 17.9589s	
5848/11350 (epoch 25.762), train_loss = 1.01214861, grad/param norm = 3.3629e-01, time/batch = 19.8686s	
5849/11350 (epoch 25.767), train_loss = 1.00215856, grad/param norm = 2.8135e-01, time/batch = 18.4530s	
5850/11350 (epoch 25.771), train_loss = 1.10999391, grad/param norm = 3.0108e-01, time/batch = 16.3462s	
5851/11350 (epoch 25.775), train_loss = 0.90131193, grad/param norm = 3.2927e-01, time/batch = 20.7036s	
5852/11350 (epoch 25.780), train_loss = 1.01751226, grad/param norm = 3.3669e-01, time/batch = 19.5283s	
5853/11350 (epoch 25.784), train_loss = 0.87101580, grad/param norm = 2.8171e-01, time/batch = 17.4589s	
5854/11350 (epoch 25.789), train_loss = 0.90077142, grad/param norm = 3.0079e-01, time/batch = 20.1922s	
5855/11350 (epoch 25.793), train_loss = 1.03843894, grad/param norm = 3.3688e-01, time/batch = 17.8524s	
5856/11350 (epoch 25.797), train_loss = 0.91226548, grad/param norm = 3.2088e-01, time/batch = 19.2768s	
5857/11350 (epoch 25.802), train_loss = 0.96825313, grad/param norm = 2.8437e-01, time/batch = 18.6904s	
5858/11350 (epoch 25.806), train_loss = 1.00633117, grad/param norm = 3.3276e-01, time/batch = 17.7670s	
5859/11350 (epoch 25.811), train_loss = 0.94526240, grad/param norm = 2.9476e-01, time/batch = 18.6084s	
5860/11350 (epoch 25.815), train_loss = 0.87565612, grad/param norm = 3.0693e-01, time/batch = 19.7045s	
5861/11350 (epoch 25.819), train_loss = 0.84728471, grad/param norm = 3.1545e-01, time/batch = 18.2813s	
5862/11350 (epoch 25.824), train_loss = 0.81664703, grad/param norm = 3.2007e-01, time/batch = 20.6097s	
5863/11350 (epoch 25.828), train_loss = 0.88580548, grad/param norm = 3.0887e-01, time/batch = 17.9575s	
5864/11350 (epoch 25.833), train_loss = 0.89668985, grad/param norm = 2.9987e-01, time/batch = 17.2685s	
5865/11350 (epoch 25.837), train_loss = 0.95038632, grad/param norm = 3.2745e-01, time/batch = 17.7915s	
5866/11350 (epoch 25.841), train_loss = 1.16795483, grad/param norm = 3.4429e-01, time/batch = 20.0364s	
5867/11350 (epoch 25.846), train_loss = 0.95191288, grad/param norm = 2.7655e-01, time/batch = 20.2003s	
5868/11350 (epoch 25.850), train_loss = 1.00583527, grad/param norm = 3.4035e-01, time/batch = 19.1774s	
5869/11350 (epoch 25.855), train_loss = 0.79249561, grad/param norm = 3.2980e-01, time/batch = 17.8726s	
5870/11350 (epoch 25.859), train_loss = 0.87507748, grad/param norm = 3.2629e-01, time/batch = 20.1920s	
5871/11350 (epoch 25.863), train_loss = 0.79246889, grad/param norm = 2.8886e-01, time/batch = 19.3311s	
5872/11350 (epoch 25.868), train_loss = 0.82418701, grad/param norm = 2.6328e-01, time/batch = 20.2029s	
5873/11350 (epoch 25.872), train_loss = 0.86581359, grad/param norm = 2.7493e-01, time/batch = 19.2832s	
5874/11350 (epoch 25.877), train_loss = 0.90674262, grad/param norm = 3.6039e-01, time/batch = 16.6889s	
5875/11350 (epoch 25.881), train_loss = 1.09054147, grad/param norm = 3.5828e-01, time/batch = 17.8347s	
5876/11350 (epoch 25.885), train_loss = 1.06526783, grad/param norm = 3.3575e-01, time/batch = 19.8645s	
5877/11350 (epoch 25.890), train_loss = 0.96861147, grad/param norm = 4.9761e-01, time/batch = 19.1930s	
5878/11350 (epoch 25.894), train_loss = 0.77853075, grad/param norm = 3.1789e-01, time/batch = 18.9252s	
5879/11350 (epoch 25.899), train_loss = 0.97628334, grad/param norm = 3.4072e-01, time/batch = 20.0415s	
5880/11350 (epoch 25.903), train_loss = 0.96083783, grad/param norm = 2.9434e-01, time/batch = 19.7782s	
5881/11350 (epoch 25.907), train_loss = 0.90638705, grad/param norm = 3.1649e-01, time/batch = 18.1113s	
5882/11350 (epoch 25.912), train_loss = 0.84281543, grad/param norm = 2.7467e-01, time/batch = 20.0270s	
5883/11350 (epoch 25.916), train_loss = 0.97030881, grad/param norm = 2.8763e-01, time/batch = 18.6233s	
5884/11350 (epoch 25.921), train_loss = 0.96604507, grad/param norm = 3.0200e-01, time/batch = 18.8025s	
5885/11350 (epoch 25.925), train_loss = 0.78293725, grad/param norm = 2.4996e-01, time/batch = 20.1081s	
5886/11350 (epoch 25.930), train_loss = 0.99685031, grad/param norm = 3.6924e-01, time/batch = 17.4455s	
5887/11350 (epoch 25.934), train_loss = 1.06027563, grad/param norm = 3.0056e-01, time/batch = 18.2913s	
5888/11350 (epoch 25.938), train_loss = 0.89482796, grad/param norm = 2.7530e-01, time/batch = 19.5481s	
5889/11350 (epoch 25.943), train_loss = 0.99874901, grad/param norm = 2.8218e-01, time/batch = 17.8616s	
5890/11350 (epoch 25.947), train_loss = 0.96350720, grad/param norm = 3.3355e-01, time/batch = 16.7313s	
5891/11350 (epoch 25.952), train_loss = 0.99550857, grad/param norm = 4.2361e-01, time/batch = 20.2565s	
5892/11350 (epoch 25.956), train_loss = 0.78377808, grad/param norm = 2.8662e-01, time/batch = 20.2806s	
5893/11350 (epoch 25.960), train_loss = 0.86514671, grad/param norm = 3.4586e-01, time/batch = 18.3714s	
5894/11350 (epoch 25.965), train_loss = 0.80307671, grad/param norm = 3.1162e-01, time/batch = 19.9510s	
5895/11350 (epoch 25.969), train_loss = 0.82849350, grad/param norm = 4.1939e-01, time/batch = 20.5276s	
5896/11350 (epoch 25.974), train_loss = 0.79069603, grad/param norm = 3.2791e-01, time/batch = 17.6173s	
5897/11350 (epoch 25.978), train_loss = 0.91281144, grad/param norm = 3.1785e-01, time/batch = 16.6532s	
5898/11350 (epoch 25.982), train_loss = 0.65145013, grad/param norm = 2.6472e-01, time/batch = 19.6313s	
5899/11350 (epoch 25.987), train_loss = 0.89786839, grad/param norm = 3.0749e-01, time/batch = 17.7111s	
5900/11350 (epoch 25.991), train_loss = 0.79025964, grad/param norm = 3.6817e-01, time/batch = 18.9649s	
5901/11350 (epoch 25.996), train_loss = 0.91003025, grad/param norm = 3.1186e-01, time/batch = 19.9630s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
5902/11350 (epoch 26.000), train_loss = 0.69175805, grad/param norm = 2.8680e-01, time/batch = 18.2734s	
5903/11350 (epoch 26.004), train_loss = 0.94789798, grad/param norm = 3.5035e-01, time/batch = 19.0982s	
5904/11350 (epoch 26.009), train_loss = 0.90655005, grad/param norm = 3.2814e-01, time/batch = 18.8590s	
5905/11350 (epoch 26.013), train_loss = 0.65569362, grad/param norm = 2.5709e-01, time/batch = 18.8589s	
5906/11350 (epoch 26.018), train_loss = 0.73228232, grad/param norm = 3.1295e-01, time/batch = 18.4452s	
5907/11350 (epoch 26.022), train_loss = 0.71883492, grad/param norm = 2.7972e-01, time/batch = 16.6207s	
5908/11350 (epoch 26.026), train_loss = 0.69019936, grad/param norm = 2.9790e-01, time/batch = 19.2796s	
5909/11350 (epoch 26.031), train_loss = 0.76744003, grad/param norm = 2.9748e-01, time/batch = 18.6929s	
5910/11350 (epoch 26.035), train_loss = 0.76187277, grad/param norm = 3.2773e-01, time/batch = 18.6343s	
5911/11350 (epoch 26.040), train_loss = 0.80435015, grad/param norm = 3.5442e-01, time/batch = 20.0456s	
5912/11350 (epoch 26.044), train_loss = 0.75833710, grad/param norm = 2.7588e-01, time/batch = 18.7823s	
5913/11350 (epoch 26.048), train_loss = 0.71902873, grad/param norm = 2.7365e-01, time/batch = 17.6985s	
5914/11350 (epoch 26.053), train_loss = 0.80835232, grad/param norm = 2.8815e-01, time/batch = 20.2069s	
5915/11350 (epoch 26.057), train_loss = 0.82772879, grad/param norm = 3.0466e-01, time/batch = 17.4502s	
5916/11350 (epoch 26.062), train_loss = 0.67522781, grad/param norm = 2.8217e-01, time/batch = 18.8801s	
5917/11350 (epoch 26.066), train_loss = 0.67898690, grad/param norm = 2.7851e-01, time/batch = 20.2884s	
5918/11350 (epoch 26.070), train_loss = 0.74935442, grad/param norm = 3.0033e-01, time/batch = 18.2786s	
5919/11350 (epoch 26.075), train_loss = 0.69683655, grad/param norm = 2.6524e-01, time/batch = 19.5418s	
5920/11350 (epoch 26.079), train_loss = 0.80551664, grad/param norm = 2.7150e-01, time/batch = 19.8726s	
5921/11350 (epoch 26.084), train_loss = 0.94949168, grad/param norm = 3.2671e-01, time/batch = 15.8026s	
5922/11350 (epoch 26.088), train_loss = 0.87300977, grad/param norm = 3.0353e-01, time/batch = 18.3687s	
5923/11350 (epoch 26.093), train_loss = 0.85788970, grad/param norm = 2.8060e-01, time/batch = 18.0315s	
5924/11350 (epoch 26.097), train_loss = 0.81193612, grad/param norm = 3.1627e-01, time/batch = 19.5379s	
5925/11350 (epoch 26.101), train_loss = 0.76319310, grad/param norm = 3.4115e-01, time/batch = 18.0360s	
5926/11350 (epoch 26.106), train_loss = 0.86914740, grad/param norm = 3.4132e-01, time/batch = 19.9523s	
5927/11350 (epoch 26.110), train_loss = 0.75104237, grad/param norm = 2.9651e-01, time/batch = 20.6216s	
5928/11350 (epoch 26.115), train_loss = 0.78685287, grad/param norm = 3.1138e-01, time/batch = 19.2630s	
5929/11350 (epoch 26.119), train_loss = 0.90044430, grad/param norm = 3.3251e-01, time/batch = 18.0380s	
5930/11350 (epoch 26.123), train_loss = 0.74380893, grad/param norm = 2.8366e-01, time/batch = 20.8621s	
5931/11350 (epoch 26.128), train_loss = 0.68123852, grad/param norm = 2.9557e-01, time/batch = 18.6123s	
5932/11350 (epoch 26.132), train_loss = 0.73766386, grad/param norm = 2.6843e-01, time/batch = 19.0242s	
5933/11350 (epoch 26.137), train_loss = 0.73324153, grad/param norm = 3.2155e-01, time/batch = 19.2759s	
5934/11350 (epoch 26.141), train_loss = 0.93582364, grad/param norm = 3.2502e-01, time/batch = 16.7326s	
5935/11350 (epoch 26.145), train_loss = 0.73947535, grad/param norm = 2.7689e-01, time/batch = 19.1161s	
5936/11350 (epoch 26.150), train_loss = 0.84894847, grad/param norm = 4.4302e-01, time/batch = 17.6458s	
5937/11350 (epoch 26.154), train_loss = 0.97853280, grad/param norm = 4.0209e-01, time/batch = 17.8922s	
5938/11350 (epoch 26.159), train_loss = 0.68190096, grad/param norm = 3.0129e-01, time/batch = 17.9655s	
5939/11350 (epoch 26.163), train_loss = 0.89942785, grad/param norm = 3.2783e-01, time/batch = 19.9456s	
5940/11350 (epoch 26.167), train_loss = 0.95958664, grad/param norm = 3.1696e-01, time/batch = 17.6026s	
5941/11350 (epoch 26.172), train_loss = 1.01138140, grad/param norm = 2.9090e-01, time/batch = 19.6045s	
5942/11350 (epoch 26.176), train_loss = 0.84024146, grad/param norm = 3.3874e-01, time/batch = 19.2760s	
5943/11350 (epoch 26.181), train_loss = 0.88620770, grad/param norm = 5.1887e-01, time/batch = 19.7838s	
5944/11350 (epoch 26.185), train_loss = 0.74237618, grad/param norm = 3.1109e-01, time/batch = 18.0265s	
5945/11350 (epoch 26.189), train_loss = 0.82138867, grad/param norm = 2.9750e-01, time/batch = 19.2067s	
5946/11350 (epoch 26.194), train_loss = 0.79017240, grad/param norm = 3.3286e-01, time/batch = 19.9479s	
5947/11350 (epoch 26.198), train_loss = 0.75180738, grad/param norm = 4.0961e-01, time/batch = 18.8617s	
5948/11350 (epoch 26.203), train_loss = 0.73766245, grad/param norm = 2.9239e-01, time/batch = 18.0379s	
5949/11350 (epoch 26.207), train_loss = 0.69138320, grad/param norm = 3.2458e-01, time/batch = 20.2116s	
5950/11350 (epoch 26.211), train_loss = 0.91186225, grad/param norm = 3.2528e-01, time/batch = 17.8562s	
5951/11350 (epoch 26.216), train_loss = 0.87769529, grad/param norm = 3.2888e-01, time/batch = 18.5391s	
5952/11350 (epoch 26.220), train_loss = 0.87369718, grad/param norm = 2.9870e-01, time/batch = 18.7960s	
5953/11350 (epoch 26.225), train_loss = 0.76125431, grad/param norm = 2.8695e-01, time/batch = 17.2830s	
5954/11350 (epoch 26.229), train_loss = 0.84771059, grad/param norm = 2.8427e-01, time/batch = 17.4671s	
5955/11350 (epoch 26.233), train_loss = 0.81820716, grad/param norm = 2.8145e-01, time/batch = 18.6822s	
5956/11350 (epoch 26.238), train_loss = 0.98563513, grad/param norm = 5.9830e-01, time/batch = 18.7962s	
5957/11350 (epoch 26.242), train_loss = 1.00027924, grad/param norm = 4.2446e-01, time/batch = 18.7022s	
5958/11350 (epoch 26.247), train_loss = 0.72499223, grad/param norm = 2.6962e-01, time/batch = 18.3790s	
5959/11350 (epoch 26.251), train_loss = 0.87289360, grad/param norm = 3.4899e-01, time/batch = 17.9637s	
5960/11350 (epoch 26.256), train_loss = 0.85497032, grad/param norm = 3.5330e-01, time/batch = 17.3522s	
5961/11350 (epoch 26.260), train_loss = 0.76185209, grad/param norm = 2.7664e-01, time/batch = 19.7044s	
5962/11350 (epoch 26.264), train_loss = 0.76972870, grad/param norm = 3.0804e-01, time/batch = 19.0588s	
5963/11350 (epoch 26.269), train_loss = 0.82248195, grad/param norm = 3.0288e-01, time/batch = 18.1134s	
5964/11350 (epoch 26.273), train_loss = 0.95384099, grad/param norm = 3.2932e-01, time/batch = 16.5509s	
5965/11350 (epoch 26.278), train_loss = 0.77317554, grad/param norm = 3.0323e-01, time/batch = 17.2948s	
5966/11350 (epoch 26.282), train_loss = 0.83394544, grad/param norm = 3.1945e-01, time/batch = 17.9441s	
5967/11350 (epoch 26.286), train_loss = 0.91331679, grad/param norm = 3.4890e-01, time/batch = 18.8738s	
5968/11350 (epoch 26.291), train_loss = 0.74389531, grad/param norm = 3.3935e-01, time/batch = 18.4629s	
5969/11350 (epoch 26.295), train_loss = 0.84592910, grad/param norm = 3.3297e-01, time/batch = 18.5345s	
5970/11350 (epoch 26.300), train_loss = 0.91400231, grad/param norm = 3.2376e-01, time/batch = 17.6012s	
5971/11350 (epoch 26.304), train_loss = 0.76275144, grad/param norm = 2.8076e-01, time/batch = 18.7960s	
5972/11350 (epoch 26.308), train_loss = 0.75409823, grad/param norm = 2.9329e-01, time/batch = 16.8850s	
5973/11350 (epoch 26.313), train_loss = 0.84297433, grad/param norm = 2.6757e-01, time/batch = 15.3736s	
5974/11350 (epoch 26.317), train_loss = 0.78239612, grad/param norm = 2.7747e-01, time/batch = 17.7193s	
5975/11350 (epoch 26.322), train_loss = 0.78276737, grad/param norm = 2.8314e-01, time/batch = 19.1327s	
5976/11350 (epoch 26.326), train_loss = 0.82110584, grad/param norm = 3.2098e-01, time/batch = 18.4508s	
5977/11350 (epoch 26.330), train_loss = 0.68338323, grad/param norm = 2.7814e-01, time/batch = 19.7960s	
5978/11350 (epoch 26.335), train_loss = 0.55585047, grad/param norm = 2.3948e-01, time/batch = 19.3635s	
5979/11350 (epoch 26.339), train_loss = 0.65155519, grad/param norm = 2.6028e-01, time/batch = 18.7070s	
5980/11350 (epoch 26.344), train_loss = 0.74085041, grad/param norm = 2.5645e-01, time/batch = 19.8672s	
5981/11350 (epoch 26.348), train_loss = 0.73513903, grad/param norm = 2.6277e-01, time/batch = 20.1851s	
5982/11350 (epoch 26.352), train_loss = 0.67986383, grad/param norm = 2.7705e-01, time/batch = 18.9475s	
5983/11350 (epoch 26.357), train_loss = 0.76459610, grad/param norm = 2.5887e-01, time/batch = 18.1938s	
5984/11350 (epoch 26.361), train_loss = 0.59989303, grad/param norm = 2.4177e-01, time/batch = 18.3661s	
5985/11350 (epoch 26.366), train_loss = 0.81715915, grad/param norm = 3.1361e-01, time/batch = 19.2091s	
5986/11350 (epoch 26.370), train_loss = 0.68951800, grad/param norm = 3.4250e-01, time/batch = 19.8360s	
5987/11350 (epoch 26.374), train_loss = 0.74578230, grad/param norm = 3.1328e-01, time/batch = 20.1261s	
5988/11350 (epoch 26.379), train_loss = 0.73842136, grad/param norm = 3.0249e-01, time/batch = 20.1257s	
5989/11350 (epoch 26.383), train_loss = 0.66669433, grad/param norm = 2.3955e-01, time/batch = 19.8545s	
5990/11350 (epoch 26.388), train_loss = 0.78795653, grad/param norm = 3.7108e-01, time/batch = 19.3661s	
5991/11350 (epoch 26.392), train_loss = 0.82646301, grad/param norm = 3.1003e-01, time/batch = 20.3401s	
5992/11350 (epoch 26.396), train_loss = 0.77515824, grad/param norm = 3.3530e-01, time/batch = 18.5360s	
5993/11350 (epoch 26.401), train_loss = 0.77116150, grad/param norm = 3.1670e-01, time/batch = 19.4619s	
5994/11350 (epoch 26.405), train_loss = 0.95683050, grad/param norm = 3.1566e-01, time/batch = 19.1895s	
5995/11350 (epoch 26.410), train_loss = 0.98325207, grad/param norm = 3.4531e-01, time/batch = 18.1637s	
5996/11350 (epoch 26.414), train_loss = 0.70606453, grad/param norm = 3.3814e-01, time/batch = 18.4577s	
5997/11350 (epoch 26.419), train_loss = 0.71965593, grad/param norm = 3.4348e-01, time/batch = 20.6068s	
5998/11350 (epoch 26.423), train_loss = 0.79110547, grad/param norm = 3.0418e-01, time/batch = 31.9444s	
5999/11350 (epoch 26.427), train_loss = 0.87418743, grad/param norm = 3.2780e-01, time/batch = 20.3649s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch26.43_1.8902.t7	
6000/11350 (epoch 26.432), train_loss = 0.82572742, grad/param norm = 3.4297e-01, time/batch = 18.7845s	
6001/11350 (epoch 26.436), train_loss = 1.58317484, grad/param norm = 5.8798e-01, time/batch = 16.8398s	
6002/11350 (epoch 26.441), train_loss = 1.01274385, grad/param norm = 4.2143e-01, time/batch = 15.8326s	
6003/11350 (epoch 26.445), train_loss = 0.73504902, grad/param norm = 2.6824e-01, time/batch = 20.3675s	
6004/11350 (epoch 26.449), train_loss = 0.80696803, grad/param norm = 3.0843e-01, time/batch = 18.9484s	
6005/11350 (epoch 26.454), train_loss = 0.92294281, grad/param norm = 3.0406e-01, time/batch = 18.0599s	
6006/11350 (epoch 26.458), train_loss = 0.65890302, grad/param norm = 2.5442e-01, time/batch = 17.6071s	
6007/11350 (epoch 26.463), train_loss = 0.68165290, grad/param norm = 3.6757e-01, time/batch = 18.8580s	
6008/11350 (epoch 26.467), train_loss = 1.06960816, grad/param norm = 3.2672e-01, time/batch = 18.7946s	
6009/11350 (epoch 26.471), train_loss = 0.95623161, grad/param norm = 4.4048e-01, time/batch = 18.2831s	
6010/11350 (epoch 26.476), train_loss = 0.85624954, grad/param norm = 2.9871e-01, time/batch = 20.2666s	
6011/11350 (epoch 26.480), train_loss = 0.94395896, grad/param norm = 3.0966e-01, time/batch = 17.3920s	
6012/11350 (epoch 26.485), train_loss = 0.82922986, grad/param norm = 2.8818e-01, time/batch = 19.1234s	
6013/11350 (epoch 26.489), train_loss = 0.93638514, grad/param norm = 3.1156e-01, time/batch = 20.4518s	
6014/11350 (epoch 26.493), train_loss = 0.93488415, grad/param norm = 3.1494e-01, time/batch = 19.7630s	
6015/11350 (epoch 26.498), train_loss = 0.62985045, grad/param norm = 2.6587e-01, time/batch = 19.7079s	
6016/11350 (epoch 26.502), train_loss = 0.92950318, grad/param norm = 3.0136e-01, time/batch = 18.8624s	
6017/11350 (epoch 26.507), train_loss = 0.72486522, grad/param norm = 2.8185e-01, time/batch = 17.1594s	
6018/11350 (epoch 26.511), train_loss = 0.96206226, grad/param norm = 3.0800e-01, time/batch = 19.4570s	
6019/11350 (epoch 26.515), train_loss = 0.82818722, grad/param norm = 2.9562e-01, time/batch = 19.6314s	
6020/11350 (epoch 26.520), train_loss = 1.00114891, grad/param norm = 3.4050e-01, time/batch = 18.5159s	
6021/11350 (epoch 26.524), train_loss = 0.86446436, grad/param norm = 3.3444e-01, time/batch = 20.7029s	
6022/11350 (epoch 26.529), train_loss = 0.82207724, grad/param norm = 3.0899e-01, time/batch = 19.2021s	
6023/11350 (epoch 26.533), train_loss = 1.01036652, grad/param norm = 2.9422e-01, time/batch = 18.7877s	
6024/11350 (epoch 26.537), train_loss = 0.92485682, grad/param norm = 3.1710e-01, time/batch = 18.2915s	
6025/11350 (epoch 26.542), train_loss = 0.89098726, grad/param norm = 2.9193e-01, time/batch = 18.3006s	
6026/11350 (epoch 26.546), train_loss = 1.06817317, grad/param norm = 3.4544e-01, time/batch = 18.5124s	
6027/11350 (epoch 26.551), train_loss = 0.85695207, grad/param norm = 2.9874e-01, time/batch = 19.0208s	
6028/11350 (epoch 26.555), train_loss = 0.78420250, grad/param norm = 2.7835e-01, time/batch = 18.8033s	
6029/11350 (epoch 26.559), train_loss = 0.80584255, grad/param norm = 2.7512e-01, time/batch = 19.1801s	
6030/11350 (epoch 26.564), train_loss = 0.89996174, grad/param norm = 3.3678e-01, time/batch = 20.1907s	
6031/11350 (epoch 26.568), train_loss = 0.91883136, grad/param norm = 2.8618e-01, time/batch = 19.2803s	
6032/11350 (epoch 26.573), train_loss = 0.99504710, grad/param norm = 3.2885e-01, time/batch = 17.3416s	
6033/11350 (epoch 26.577), train_loss = 0.94862949, grad/param norm = 3.4413e-01, time/batch = 19.1795s	
6034/11350 (epoch 26.581), train_loss = 0.95294043, grad/param norm = 3.0868e-01, time/batch = 20.4342s	
6035/11350 (epoch 26.586), train_loss = 0.96852715, grad/param norm = 3.6263e-01, time/batch = 19.7728s	
6036/11350 (epoch 26.590), train_loss = 1.05190980, grad/param norm = 4.0607e-01, time/batch = 18.9513s	
6037/11350 (epoch 26.595), train_loss = 1.07917976, grad/param norm = 3.1693e-01, time/batch = 16.9401s	
6038/11350 (epoch 26.599), train_loss = 0.93377606, grad/param norm = 2.9849e-01, time/batch = 20.3660s	
6039/11350 (epoch 26.604), train_loss = 0.90163859, grad/param norm = 3.1611e-01, time/batch = 18.0841s	
6040/11350 (epoch 26.608), train_loss = 0.86438945, grad/param norm = 3.2960e-01, time/batch = 17.8660s	
6041/11350 (epoch 26.612), train_loss = 0.85259000, grad/param norm = 2.9383e-01, time/batch = 18.8735s	
6042/11350 (epoch 26.617), train_loss = 0.95763729, grad/param norm = 3.2153e-01, time/batch = 17.6128s	
6043/11350 (epoch 26.621), train_loss = 0.98717215, grad/param norm = 3.0645e-01, time/batch = 18.6251s	
6044/11350 (epoch 26.626), train_loss = 0.89059317, grad/param norm = 3.5579e-01, time/batch = 19.7006s	
6045/11350 (epoch 26.630), train_loss = 0.92347351, grad/param norm = 3.1321e-01, time/batch = 17.8703s	
6046/11350 (epoch 26.634), train_loss = 0.88536830, grad/param norm = 3.0905e-01, time/batch = 19.7983s	
6047/11350 (epoch 26.639), train_loss = 0.81414941, grad/param norm = 3.0355e-01, time/batch = 19.9362s	
6048/11350 (epoch 26.643), train_loss = 0.78004071, grad/param norm = 2.8866e-01, time/batch = 19.0186s	
6049/11350 (epoch 26.648), train_loss = 0.86293320, grad/param norm = 2.8564e-01, time/batch = 18.5341s	
6050/11350 (epoch 26.652), train_loss = 0.78561887, grad/param norm = 3.1909e-01, time/batch = 19.8751s	
6051/11350 (epoch 26.656), train_loss = 0.90029164, grad/param norm = 3.1022e-01, time/batch = 18.2872s	
6052/11350 (epoch 26.661), train_loss = 0.99776611, grad/param norm = 3.2891e-01, time/batch = 19.0280s	
6053/11350 (epoch 26.665), train_loss = 0.90047757, grad/param norm = 3.4323e-01, time/batch = 18.4394s	
6054/11350 (epoch 26.670), train_loss = 0.89865087, grad/param norm = 3.5453e-01, time/batch = 18.6944s	
6055/11350 (epoch 26.674), train_loss = 0.83383568, grad/param norm = 2.7370e-01, time/batch = 18.5913s	
6056/11350 (epoch 26.678), train_loss = 0.87021804, grad/param norm = 2.6558e-01, time/batch = 17.6856s	
6057/11350 (epoch 26.683), train_loss = 0.79904193, grad/param norm = 3.1470e-01, time/batch = 20.0272s	
6058/11350 (epoch 26.687), train_loss = 0.76587766, grad/param norm = 2.7434e-01, time/batch = 18.5993s	
6059/11350 (epoch 26.692), train_loss = 1.14515154, grad/param norm = 4.0147e-01, time/batch = 20.1097s	
6060/11350 (epoch 26.696), train_loss = 1.06083572, grad/param norm = 3.6059e-01, time/batch = 18.4462s	
6061/11350 (epoch 26.700), train_loss = 0.97443229, grad/param norm = 3.6894e-01, time/batch = 17.9421s	
6062/11350 (epoch 26.705), train_loss = 1.01321936, grad/param norm = 3.4766e-01, time/batch = 20.3741s	
6063/11350 (epoch 26.709), train_loss = 1.02271491, grad/param norm = 3.3590e-01, time/batch = 20.3712s	
6064/11350 (epoch 26.714), train_loss = 0.90021168, grad/param norm = 3.2669e-01, time/batch = 16.7082s	
6065/11350 (epoch 26.718), train_loss = 0.76604929, grad/param norm = 3.0456e-01, time/batch = 20.2904s	
6066/11350 (epoch 26.722), train_loss = 0.90170542, grad/param norm = 3.7448e-01, time/batch = 20.2769s	
6067/11350 (epoch 26.727), train_loss = 0.90517599, grad/param norm = 3.1484e-01, time/batch = 17.8518s	
6068/11350 (epoch 26.731), train_loss = 0.91361319, grad/param norm = 3.1102e-01, time/batch = 18.6243s	
6069/11350 (epoch 26.736), train_loss = 0.83137659, grad/param norm = 3.6219e-01, time/batch = 17.2709s	
6070/11350 (epoch 26.740), train_loss = 0.87690562, grad/param norm = 2.9173e-01, time/batch = 18.7834s	
6071/11350 (epoch 26.744), train_loss = 0.90014124, grad/param norm = 3.5027e-01, time/batch = 18.4519s	
6072/11350 (epoch 26.749), train_loss = 0.91702093, grad/param norm = 3.2690e-01, time/batch = 17.6138s	
6073/11350 (epoch 26.753), train_loss = 0.97409398, grad/param norm = 3.9514e-01, time/batch = 18.0322s	
6074/11350 (epoch 26.758), train_loss = 0.85662077, grad/param norm = 3.3307e-01, time/batch = 17.3216s	
6075/11350 (epoch 26.762), train_loss = 0.98098332, grad/param norm = 2.8850e-01, time/batch = 17.8570s	
6076/11350 (epoch 26.767), train_loss = 0.97381162, grad/param norm = 2.7838e-01, time/batch = 16.5464s	
6077/11350 (epoch 26.771), train_loss = 1.10036350, grad/param norm = 3.6064e-01, time/batch = 16.3523s	
6078/11350 (epoch 26.775), train_loss = 0.87732523, grad/param norm = 2.9317e-01, time/batch = 18.3059s	
6079/11350 (epoch 26.780), train_loss = 0.99784498, grad/param norm = 3.0284e-01, time/batch = 17.8699s	
6080/11350 (epoch 26.784), train_loss = 0.86981336, grad/param norm = 3.2550e-01, time/batch = 18.8702s	
6081/11350 (epoch 26.789), train_loss = 0.88901554, grad/param norm = 3.0141e-01, time/batch = 18.6385s	
6082/11350 (epoch 26.793), train_loss = 1.00190224, grad/param norm = 3.3194e-01, time/batch = 19.8735s	
6083/11350 (epoch 26.797), train_loss = 0.88099012, grad/param norm = 2.6572e-01, time/batch = 20.1908s	
6084/11350 (epoch 26.802), train_loss = 0.96431447, grad/param norm = 3.1953e-01, time/batch = 19.8592s	
6085/11350 (epoch 26.806), train_loss = 0.96895804, grad/param norm = 2.8159e-01, time/batch = 19.3692s	
6086/11350 (epoch 26.811), train_loss = 0.92566357, grad/param norm = 3.0557e-01, time/batch = 19.9426s	
6087/11350 (epoch 26.815), train_loss = 0.85009906, grad/param norm = 2.8389e-01, time/batch = 19.3520s	
6088/11350 (epoch 26.819), train_loss = 0.81194021, grad/param norm = 2.7806e-01, time/batch = 18.2134s	
6089/11350 (epoch 26.824), train_loss = 0.80165738, grad/param norm = 3.0716e-01, time/batch = 18.9534s	
6090/11350 (epoch 26.828), train_loss = 0.85068357, grad/param norm = 2.9472e-01, time/batch = 18.0224s	
6091/11350 (epoch 26.833), train_loss = 0.89038151, grad/param norm = 3.4353e-01, time/batch = 16.2526s	
6092/11350 (epoch 26.837), train_loss = 0.92301101, grad/param norm = 3.1645e-01, time/batch = 18.1368s	
6093/11350 (epoch 26.841), train_loss = 1.14310981, grad/param norm = 3.6521e-01, time/batch = 18.8704s	
6094/11350 (epoch 26.846), train_loss = 0.91846755, grad/param norm = 2.6660e-01, time/batch = 19.6933s	
6095/11350 (epoch 26.850), train_loss = 0.97552335, grad/param norm = 3.6442e-01, time/batch = 19.7051s	
6096/11350 (epoch 26.855), train_loss = 0.76133054, grad/param norm = 2.8899e-01, time/batch = 19.1053s	
6097/11350 (epoch 26.859), train_loss = 0.84666491, grad/param norm = 3.2411e-01, time/batch = 19.7790s	
6098/11350 (epoch 26.863), train_loss = 0.79456244, grad/param norm = 3.4210e-01, time/batch = 18.7023s	
6099/11350 (epoch 26.868), train_loss = 0.80449020, grad/param norm = 2.9585e-01, time/batch = 18.5385s	
6100/11350 (epoch 26.872), train_loss = 0.84257822, grad/param norm = 2.9235e-01, time/batch = 19.0396s	
6101/11350 (epoch 26.877), train_loss = 0.85925570, grad/param norm = 3.2279e-01, time/batch = 17.7823s	
6102/11350 (epoch 26.881), train_loss = 1.04973183, grad/param norm = 3.5749e-01, time/batch = 19.6132s	
6103/11350 (epoch 26.885), train_loss = 1.02323394, grad/param norm = 3.0490e-01, time/batch = 19.9490s	
6104/11350 (epoch 26.890), train_loss = 0.91584383, grad/param norm = 3.0721e-01, time/batch = 17.8809s	
6105/11350 (epoch 26.894), train_loss = 0.76766096, grad/param norm = 3.3003e-01, time/batch = 18.3031s	
6106/11350 (epoch 26.899), train_loss = 0.96834682, grad/param norm = 3.5920e-01, time/batch = 18.0107s	
6107/11350 (epoch 26.903), train_loss = 0.93754898, grad/param norm = 3.1594e-01, time/batch = 17.9607s	
6108/11350 (epoch 26.907), train_loss = 0.87207696, grad/param norm = 2.8176e-01, time/batch = 17.8609s	
6109/11350 (epoch 26.912), train_loss = 0.81182133, grad/param norm = 2.8590e-01, time/batch = 18.1291s	
6110/11350 (epoch 26.916), train_loss = 0.94201419, grad/param norm = 2.9459e-01, time/batch = 19.7927s	
6111/11350 (epoch 26.921), train_loss = 0.94511856, grad/param norm = 3.1540e-01, time/batch = 19.3675s	
6112/11350 (epoch 26.925), train_loss = 0.76426536, grad/param norm = 2.3776e-01, time/batch = 16.9432s	
6113/11350 (epoch 26.930), train_loss = 0.95439043, grad/param norm = 3.4718e-01, time/batch = 18.7141s	
6114/11350 (epoch 26.934), train_loss = 1.03428191, grad/param norm = 2.9298e-01, time/batch = 20.0393s	
6115/11350 (epoch 26.938), train_loss = 0.88068980, grad/param norm = 2.8819e-01, time/batch = 19.5193s	
6116/11350 (epoch 26.943), train_loss = 0.97691072, grad/param norm = 2.8605e-01, time/batch = 18.0052s	
6117/11350 (epoch 26.947), train_loss = 0.94193898, grad/param norm = 3.7437e-01, time/batch = 17.4214s	
6118/11350 (epoch 26.952), train_loss = 0.95750098, grad/param norm = 3.2261e-01, time/batch = 19.9520s	
6119/11350 (epoch 26.956), train_loss = 0.73537863, grad/param norm = 2.4333e-01, time/batch = 19.6071s	
6120/11350 (epoch 26.960), train_loss = 0.85350522, grad/param norm = 3.6438e-01, time/batch = 16.9622s	
6121/11350 (epoch 26.965), train_loss = 0.77596462, grad/param norm = 2.8084e-01, time/batch = 20.8675s	
6122/11350 (epoch 26.969), train_loss = 0.80522704, grad/param norm = 3.4606e-01, time/batch = 17.7686s	
6123/11350 (epoch 26.974), train_loss = 0.78012668, grad/param norm = 3.0992e-01, time/batch = 16.7848s	
6124/11350 (epoch 26.978), train_loss = 0.90976998, grad/param norm = 3.6873e-01, time/batch = 18.3591s	
6125/11350 (epoch 26.982), train_loss = 0.62434260, grad/param norm = 2.8375e-01, time/batch = 18.6212s	
6126/11350 (epoch 26.987), train_loss = 0.87737614, grad/param norm = 3.2567e-01, time/batch = 20.1171s	
6127/11350 (epoch 26.991), train_loss = 0.76971653, grad/param norm = 3.1859e-01, time/batch = 16.2065s	
6128/11350 (epoch 26.996), train_loss = 0.89427896, grad/param norm = 3.4174e-01, time/batch = 19.1149s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
6129/11350 (epoch 27.000), train_loss = 0.67557181, grad/param norm = 2.9930e-01, time/batch = 18.9400s	
6130/11350 (epoch 27.004), train_loss = 0.93619886, grad/param norm = 3.5002e-01, time/batch = 19.8674s	
6131/11350 (epoch 27.009), train_loss = 0.88903850, grad/param norm = 3.0299e-01, time/batch = 19.9422s	
6132/11350 (epoch 27.013), train_loss = 0.64570016, grad/param norm = 2.7131e-01, time/batch = 17.9651s	
6133/11350 (epoch 27.018), train_loss = 0.70697543, grad/param norm = 2.9173e-01, time/batch = 18.7976s	
6134/11350 (epoch 27.022), train_loss = 0.70257642, grad/param norm = 2.9267e-01, time/batch = 19.6861s	
6135/11350 (epoch 27.026), train_loss = 0.66915625, grad/param norm = 2.9318e-01, time/batch = 19.9511s	
6136/11350 (epoch 27.031), train_loss = 0.73220289, grad/param norm = 2.8778e-01, time/batch = 18.1987s	
6137/11350 (epoch 27.035), train_loss = 0.73484595, grad/param norm = 3.1826e-01, time/batch = 19.8694s	
6138/11350 (epoch 27.040), train_loss = 0.77010981, grad/param norm = 2.9439e-01, time/batch = 17.0294s	
6139/11350 (epoch 27.044), train_loss = 0.73007207, grad/param norm = 2.4847e-01, time/batch = 20.1122s	
6140/11350 (epoch 27.048), train_loss = 0.71061409, grad/param norm = 2.7794e-01, time/batch = 19.4678s	
6141/11350 (epoch 27.053), train_loss = 0.79606631, grad/param norm = 3.4980e-01, time/batch = 19.2037s	
6142/11350 (epoch 27.057), train_loss = 0.81009502, grad/param norm = 3.4495e-01, time/batch = 19.1195s	
6143/11350 (epoch 27.062), train_loss = 0.65652169, grad/param norm = 2.7540e-01, time/batch = 20.2815s	
6144/11350 (epoch 27.066), train_loss = 0.67132384, grad/param norm = 5.3590e-01, time/batch = 18.4325s	
6145/11350 (epoch 27.070), train_loss = 0.75432598, grad/param norm = 3.2627e-01, time/batch = 20.6982s	
6146/11350 (epoch 27.075), train_loss = 0.67987712, grad/param norm = 2.6941e-01, time/batch = 19.0967s	
6147/11350 (epoch 27.079), train_loss = 0.78734661, grad/param norm = 2.6867e-01, time/batch = 16.8317s	
6148/11350 (epoch 27.084), train_loss = 0.92110668, grad/param norm = 3.2628e-01, time/batch = 20.3665s	
6149/11350 (epoch 27.088), train_loss = 0.85744250, grad/param norm = 3.3535e-01, time/batch = 20.4422s	
6150/11350 (epoch 27.093), train_loss = 0.84231384, grad/param norm = 2.8967e-01, time/batch = 18.1925s	
6151/11350 (epoch 27.097), train_loss = 0.78384522, grad/param norm = 3.2171e-01, time/batch = 18.7808s	
6152/11350 (epoch 27.101), train_loss = 0.73189356, grad/param norm = 3.3212e-01, time/batch = 17.0548s	
6153/11350 (epoch 27.106), train_loss = 0.85735470, grad/param norm = 4.0558e-01, time/batch = 17.6162s	
6154/11350 (epoch 27.110), train_loss = 0.74105236, grad/param norm = 3.0975e-01, time/batch = 17.6153s	
6155/11350 (epoch 27.115), train_loss = 0.77289753, grad/param norm = 3.2908e-01, time/batch = 20.0430s	
6156/11350 (epoch 27.119), train_loss = 0.87448035, grad/param norm = 3.5620e-01, time/batch = 18.8698s	
6157/11350 (epoch 27.123), train_loss = 0.71776846, grad/param norm = 2.9900e-01, time/batch = 17.8661s	
6158/11350 (epoch 27.128), train_loss = 0.65117249, grad/param norm = 2.7595e-01, time/batch = 20.0304s	
6159/11350 (epoch 27.132), train_loss = 0.70941471, grad/param norm = 2.6766e-01, time/batch = 17.6174s	
6160/11350 (epoch 27.137), train_loss = 0.70730929, grad/param norm = 2.8937e-01, time/batch = 18.9511s	
6161/11350 (epoch 27.141), train_loss = 0.92066742, grad/param norm = 3.9519e-01, time/batch = 17.8689s	
6162/11350 (epoch 27.145), train_loss = 0.72042139, grad/param norm = 2.7061e-01, time/batch = 20.3631s	
6163/11350 (epoch 27.150), train_loss = 0.82049926, grad/param norm = 4.4709e-01, time/batch = 18.7885s	
6164/11350 (epoch 27.154), train_loss = 0.92706544, grad/param norm = 3.4504e-01, time/batch = 18.5300s	
6165/11350 (epoch 27.159), train_loss = 0.68139166, grad/param norm = 2.8282e-01, time/batch = 18.1939s	
6166/11350 (epoch 27.163), train_loss = 0.84949544, grad/param norm = 2.9993e-01, time/batch = 17.6858s	
6167/11350 (epoch 27.167), train_loss = 0.92237005, grad/param norm = 3.1475e-01, time/batch = 19.5993s	
6168/11350 (epoch 27.172), train_loss = 0.98036626, grad/param norm = 2.8364e-01, time/batch = 19.8538s	
6169/11350 (epoch 27.176), train_loss = 0.79054894, grad/param norm = 3.0301e-01, time/batch = 19.0993s	
6170/11350 (epoch 27.181), train_loss = 0.86711166, grad/param norm = 5.1076e-01, time/batch = 18.8689s	
6171/11350 (epoch 27.185), train_loss = 0.71808321, grad/param norm = 3.1421e-01, time/batch = 18.1052s	
6172/11350 (epoch 27.189), train_loss = 0.79476699, grad/param norm = 3.1583e-01, time/batch = 19.2716s	
6173/11350 (epoch 27.194), train_loss = 0.74306882, grad/param norm = 3.5108e-01, time/batch = 18.6170s	
6174/11350 (epoch 27.198), train_loss = 0.69995399, grad/param norm = 3.5494e-01, time/batch = 19.8785s	
6175/11350 (epoch 27.203), train_loss = 0.72444097, grad/param norm = 3.2046e-01, time/batch = 18.8715s	
6176/11350 (epoch 27.207), train_loss = 0.69901716, grad/param norm = 3.8805e-01, time/batch = 19.4547s	
6177/11350 (epoch 27.211), train_loss = 0.88443303, grad/param norm = 3.7173e-01, time/batch = 18.3097s	
6178/11350 (epoch 27.216), train_loss = 0.85595649, grad/param norm = 3.1243e-01, time/batch = 19.3715s	
6179/11350 (epoch 27.220), train_loss = 0.84795635, grad/param norm = 3.2814e-01, time/batch = 19.7721s	
6180/11350 (epoch 27.225), train_loss = 0.72808824, grad/param norm = 2.7853e-01, time/batch = 18.1956s	
6181/11350 (epoch 27.229), train_loss = 0.82778736, grad/param norm = 2.7707e-01, time/batch = 15.6191s	
6182/11350 (epoch 27.233), train_loss = 0.79486090, grad/param norm = 3.0543e-01, time/batch = 16.8455s	
6183/11350 (epoch 27.238), train_loss = 0.92323935, grad/param norm = 4.0202e-01, time/batch = 19.3660s	
6184/11350 (epoch 27.242), train_loss = 0.92860435, grad/param norm = 3.6287e-01, time/batch = 19.0367s	
6185/11350 (epoch 27.247), train_loss = 0.69263307, grad/param norm = 2.8347e-01, time/batch = 25.6132s	
6186/11350 (epoch 27.251), train_loss = 0.84150105, grad/param norm = 3.7893e-01, time/batch = 27.7831s	
6187/11350 (epoch 27.256), train_loss = 0.83474553, grad/param norm = 3.2264e-01, time/batch = 19.8561s	
6188/11350 (epoch 27.260), train_loss = 0.74668528, grad/param norm = 2.7715e-01, time/batch = 19.7727s	
6189/11350 (epoch 27.264), train_loss = 0.74600215, grad/param norm = 3.2936e-01, time/batch = 20.0330s	
6190/11350 (epoch 27.269), train_loss = 0.77866574, grad/param norm = 2.6207e-01, time/batch = 20.2708s	
6191/11350 (epoch 27.273), train_loss = 0.91402112, grad/param norm = 3.1160e-01, time/batch = 19.0405s	
6192/11350 (epoch 27.278), train_loss = 0.75293753, grad/param norm = 2.8066e-01, time/batch = 19.6220s	
6193/11350 (epoch 27.282), train_loss = 0.79236604, grad/param norm = 3.1801e-01, time/batch = 18.7745s	
6194/11350 (epoch 27.286), train_loss = 0.90483784, grad/param norm = 3.5091e-01, time/batch = 17.4971s	
6195/11350 (epoch 27.291), train_loss = 0.72464279, grad/param norm = 3.1381e-01, time/batch = 17.7133s	
6196/11350 (epoch 27.295), train_loss = 0.82141809, grad/param norm = 3.1572e-01, time/batch = 20.6954s	
6197/11350 (epoch 27.300), train_loss = 0.88039340, grad/param norm = 3.1822e-01, time/batch = 17.7867s	
6198/11350 (epoch 27.304), train_loss = 0.74173452, grad/param norm = 2.9385e-01, time/batch = 18.1090s	
6199/11350 (epoch 27.308), train_loss = 0.72689077, grad/param norm = 3.0870e-01, time/batch = 20.6104s	
6200/11350 (epoch 27.313), train_loss = 0.82085519, grad/param norm = 2.8609e-01, time/batch = 17.4419s	
6201/11350 (epoch 27.317), train_loss = 0.76062618, grad/param norm = 2.7059e-01, time/batch = 20.4566s	
6202/11350 (epoch 27.322), train_loss = 0.75776609, grad/param norm = 2.8381e-01, time/batch = 19.2704s	
6203/11350 (epoch 27.326), train_loss = 0.79337749, grad/param norm = 2.6590e-01, time/batch = 18.2725s	
6204/11350 (epoch 27.330), train_loss = 0.65786747, grad/param norm = 2.4025e-01, time/batch = 20.3695s	
6205/11350 (epoch 27.335), train_loss = 0.54190709, grad/param norm = 2.7410e-01, time/batch = 20.1973s	
6206/11350 (epoch 27.339), train_loss = 0.62550580, grad/param norm = 2.6550e-01, time/batch = 18.3447s	
6207/11350 (epoch 27.344), train_loss = 0.72042663, grad/param norm = 2.6252e-01, time/batch = 18.1857s	
6208/11350 (epoch 27.348), train_loss = 0.71429569, grad/param norm = 2.7418e-01, time/batch = 20.1193s	
6209/11350 (epoch 27.352), train_loss = 0.62906806, grad/param norm = 2.4509e-01, time/batch = 18.1117s	
6210/11350 (epoch 27.357), train_loss = 0.73367837, grad/param norm = 2.4129e-01, time/batch = 18.9482s	
6211/11350 (epoch 27.361), train_loss = 0.59260335, grad/param norm = 2.2745e-01, time/batch = 18.7872s	
6212/11350 (epoch 27.366), train_loss = 0.79192615, grad/param norm = 3.2198e-01, time/batch = 18.0166s	
6213/11350 (epoch 27.370), train_loss = 0.67054481, grad/param norm = 3.0381e-01, time/batch = 18.2855s	
6214/11350 (epoch 27.374), train_loss = 0.69175157, grad/param norm = 2.6718e-01, time/batch = 17.5146s	
6215/11350 (epoch 27.379), train_loss = 0.70013913, grad/param norm = 2.7105e-01, time/batch = 17.9480s	
6216/11350 (epoch 27.383), train_loss = 0.65544003, grad/param norm = 2.8898e-01, time/batch = 16.7916s	
6217/11350 (epoch 27.388), train_loss = 0.76679805, grad/param norm = 3.6814e-01, time/batch = 17.3115s	
6218/11350 (epoch 27.392), train_loss = 0.81086613, grad/param norm = 3.5119e-01, time/batch = 17.6193s	
6219/11350 (epoch 27.396), train_loss = 0.75394498, grad/param norm = 2.9376e-01, time/batch = 18.1139s	
6220/11350 (epoch 27.401), train_loss = 0.76059597, grad/param norm = 3.6200e-01, time/batch = 18.4616s	
6221/11350 (epoch 27.405), train_loss = 0.94271963, grad/param norm = 3.3497e-01, time/batch = 19.9531s	
6222/11350 (epoch 27.410), train_loss = 0.97203550, grad/param norm = 3.8675e-01, time/batch = 19.1121s	
6223/11350 (epoch 27.414), train_loss = 0.69052919, grad/param norm = 3.1231e-01, time/batch = 18.6119s	
6224/11350 (epoch 27.419), train_loss = 0.69324971, grad/param norm = 3.5417e-01, time/batch = 20.6973s	
6225/11350 (epoch 27.423), train_loss = 0.77520287, grad/param norm = 4.1023e-01, time/batch = 19.7809s	
6226/11350 (epoch 27.427), train_loss = 0.87341495, grad/param norm = 3.6030e-01, time/batch = 19.6061s	
6227/11350 (epoch 27.432), train_loss = 0.79601783, grad/param norm = 3.0444e-01, time/batch = 17.3276s	
6228/11350 (epoch 27.436), train_loss = 0.77011699, grad/param norm = 3.1394e-01, time/batch = 19.7044s	
6229/11350 (epoch 27.441), train_loss = 0.92920334, grad/param norm = 3.7210e-01, time/batch = 18.5883s	
6230/11350 (epoch 27.445), train_loss = 0.68112807, grad/param norm = 2.5959e-01, time/batch = 18.3722s	
6231/11350 (epoch 27.449), train_loss = 0.77460046, grad/param norm = 3.1535e-01, time/batch = 18.5552s	
6232/11350 (epoch 27.454), train_loss = 0.91287736, grad/param norm = 3.2084e-01, time/batch = 16.3585s	
6233/11350 (epoch 27.458), train_loss = 0.64159356, grad/param norm = 2.6348e-01, time/batch = 16.0466s	
6234/11350 (epoch 27.463), train_loss = 0.66921964, grad/param norm = 3.1114e-01, time/batch = 18.2214s	
6235/11350 (epoch 27.467), train_loss = 1.03501162, grad/param norm = 3.2777e-01, time/batch = 18.1205s	
6236/11350 (epoch 27.471), train_loss = 0.91957429, grad/param norm = 3.8812e-01, time/batch = 18.0456s	
6237/11350 (epoch 27.476), train_loss = 0.83753322, grad/param norm = 3.0789e-01, time/batch = 20.4592s	
6238/11350 (epoch 27.480), train_loss = 0.92255306, grad/param norm = 3.0269e-01, time/batch = 19.0337s	
6239/11350 (epoch 27.485), train_loss = 0.80161201, grad/param norm = 3.1300e-01, time/batch = 18.3000s	
6240/11350 (epoch 27.489), train_loss = 0.91693753, grad/param norm = 3.3610e-01, time/batch = 19.2154s	
6241/11350 (epoch 27.493), train_loss = 0.92051347, grad/param norm = 3.0251e-01, time/batch = 19.3882s	
6242/11350 (epoch 27.498), train_loss = 0.62540804, grad/param norm = 3.0132e-01, time/batch = 18.5300s	
6243/11350 (epoch 27.502), train_loss = 0.89642273, grad/param norm = 2.9967e-01, time/batch = 18.4630s	
6244/11350 (epoch 27.507), train_loss = 0.70168343, grad/param norm = 3.1380e-01, time/batch = 19.2917s	
6245/11350 (epoch 27.511), train_loss = 0.91909944, grad/param norm = 2.9066e-01, time/batch = 16.9486s	
6246/11350 (epoch 27.515), train_loss = 0.80355051, grad/param norm = 3.2810e-01, time/batch = 17.5497s	
6247/11350 (epoch 27.520), train_loss = 0.98015221, grad/param norm = 3.4403e-01, time/batch = 16.6404s	
6248/11350 (epoch 27.524), train_loss = 0.84711086, grad/param norm = 3.0250e-01, time/batch = 16.6320s	
6249/11350 (epoch 27.529), train_loss = 0.78959097, grad/param norm = 3.1000e-01, time/batch = 18.2801s	
6250/11350 (epoch 27.533), train_loss = 0.99303408, grad/param norm = 3.8854e-01, time/batch = 16.5242s	
6251/11350 (epoch 27.537), train_loss = 0.92235874, grad/param norm = 3.5272e-01, time/batch = 19.6260s	
6252/11350 (epoch 27.542), train_loss = 0.83961802, grad/param norm = 2.6400e-01, time/batch = 19.4301s	
6253/11350 (epoch 27.546), train_loss = 1.04249917, grad/param norm = 3.4558e-01, time/batch = 18.7802s	
6254/11350 (epoch 27.551), train_loss = 0.86692956, grad/param norm = 3.3640e-01, time/batch = 20.3673s	
6255/11350 (epoch 27.555), train_loss = 0.76036427, grad/param norm = 2.9460e-01, time/batch = 18.7575s	
6256/11350 (epoch 27.559), train_loss = 0.80655682, grad/param norm = 3.2230e-01, time/batch = 20.2098s	
6257/11350 (epoch 27.564), train_loss = 0.86324665, grad/param norm = 3.1876e-01, time/batch = 20.3595s	
6258/11350 (epoch 27.568), train_loss = 0.89783625, grad/param norm = 2.7629e-01, time/batch = 17.6127s	
6259/11350 (epoch 27.573), train_loss = 0.97153794, grad/param norm = 3.5980e-01, time/batch = 19.5259s	
6260/11350 (epoch 27.577), train_loss = 0.94064486, grad/param norm = 4.7571e-01, time/batch = 20.6903s	
6261/11350 (epoch 27.581), train_loss = 0.92661702, grad/param norm = 3.0843e-01, time/batch = 16.4146s	
6262/11350 (epoch 27.586), train_loss = 0.92725751, grad/param norm = 3.0364e-01, time/batch = 18.2521s	
6263/11350 (epoch 27.590), train_loss = 1.03611180, grad/param norm = 3.9956e-01, time/batch = 19.5297s	
6264/11350 (epoch 27.595), train_loss = 1.05462699, grad/param norm = 3.1948e-01, time/batch = 18.1056s	
6265/11350 (epoch 27.599), train_loss = 0.92177324, grad/param norm = 3.3723e-01, time/batch = 19.5270s	
6266/11350 (epoch 27.604), train_loss = 0.86945628, grad/param norm = 2.8813e-01, time/batch = 17.9661s	
6267/11350 (epoch 27.608), train_loss = 0.83294452, grad/param norm = 3.2788e-01, time/batch = 19.6923s	
6268/11350 (epoch 27.612), train_loss = 0.82389740, grad/param norm = 2.7213e-01, time/batch = 19.8685s	
6269/11350 (epoch 27.617), train_loss = 0.92542799, grad/param norm = 3.0873e-01, time/batch = 18.2998s	
6270/11350 (epoch 27.621), train_loss = 0.96678233, grad/param norm = 2.9814e-01, time/batch = 19.4460s	
6271/11350 (epoch 27.626), train_loss = 0.85621488, grad/param norm = 2.9155e-01, time/batch = 19.7870s	
6272/11350 (epoch 27.630), train_loss = 0.88516135, grad/param norm = 3.2652e-01, time/batch = 18.7033s	
6273/11350 (epoch 27.634), train_loss = 0.87317683, grad/param norm = 3.3045e-01, time/batch = 19.8721s	
6274/11350 (epoch 27.639), train_loss = 0.78297089, grad/param norm = 2.8951e-01, time/batch = 17.9695s	
6275/11350 (epoch 27.643), train_loss = 0.75439787, grad/param norm = 3.1794e-01, time/batch = 20.3641s	
6276/11350 (epoch 27.648), train_loss = 0.83012672, grad/param norm = 2.9242e-01, time/batch = 20.4267s	
6277/11350 (epoch 27.652), train_loss = 0.74583542, grad/param norm = 2.7493e-01, time/batch = 18.4617s	
6278/11350 (epoch 27.656), train_loss = 0.88109119, grad/param norm = 3.1946e-01, time/batch = 18.6990s	
6279/11350 (epoch 27.661), train_loss = 0.96514129, grad/param norm = 3.4603e-01, time/batch = 20.1981s	
6280/11350 (epoch 27.665), train_loss = 0.86935842, grad/param norm = 3.3248e-01, time/batch = 7.9922s	
6281/11350 (epoch 27.670), train_loss = 0.86564679, grad/param norm = 3.0735e-01, time/batch = 0.7111s	
6282/11350 (epoch 27.674), train_loss = 0.81880530, grad/param norm = 2.9514e-01, time/batch = 0.7072s	
6283/11350 (epoch 27.678), train_loss = 0.85008460, grad/param norm = 2.8046e-01, time/batch = 0.7052s	
6284/11350 (epoch 27.683), train_loss = 0.79028663, grad/param norm = 3.2672e-01, time/batch = 0.7059s	
6285/11350 (epoch 27.687), train_loss = 0.74320406, grad/param norm = 3.0913e-01, time/batch = 0.7136s	
6286/11350 (epoch 27.692), train_loss = 1.11542145, grad/param norm = 4.7239e-01, time/batch = 0.6998s	
6287/11350 (epoch 27.696), train_loss = 1.03030860, grad/param norm = 3.6301e-01, time/batch = 0.8759s	
6288/11350 (epoch 27.700), train_loss = 0.95497900, grad/param norm = 3.4761e-01, time/batch = 1.0310s	
6289/11350 (epoch 27.705), train_loss = 1.02177591, grad/param norm = 3.8043e-01, time/batch = 1.0490s	
6290/11350 (epoch 27.709), train_loss = 0.97866546, grad/param norm = 3.1619e-01, time/batch = 1.0271s	
6291/11350 (epoch 27.714), train_loss = 0.87742859, grad/param norm = 3.0659e-01, time/batch = 1.0214s	
6292/11350 (epoch 27.718), train_loss = 0.76444257, grad/param norm = 2.9764e-01, time/batch = 1.6501s	
6293/11350 (epoch 27.722), train_loss = 0.88637467, grad/param norm = 3.8467e-01, time/batch = 1.8885s	
6294/11350 (epoch 27.727), train_loss = 0.88634654, grad/param norm = 3.4998e-01, time/batch = 3.9692s	
6295/11350 (epoch 27.731), train_loss = 0.90300368, grad/param norm = 3.7700e-01, time/batch = 18.8058s	
6296/11350 (epoch 27.736), train_loss = 0.81263934, grad/param norm = 3.7233e-01, time/batch = 19.6964s	
6297/11350 (epoch 27.740), train_loss = 0.85837566, grad/param norm = 2.9992e-01, time/batch = 17.8973s	
6298/11350 (epoch 27.744), train_loss = 0.86085211, grad/param norm = 3.4437e-01, time/batch = 18.7735s	
6299/11350 (epoch 27.749), train_loss = 0.89566387, grad/param norm = 3.6672e-01, time/batch = 20.3433s	
6300/11350 (epoch 27.753), train_loss = 0.93636384, grad/param norm = 3.6050e-01, time/batch = 16.2905s	
6301/11350 (epoch 27.758), train_loss = 0.83984317, grad/param norm = 3.4337e-01, time/batch = 20.2750s	
6302/11350 (epoch 27.762), train_loss = 0.97715495, grad/param norm = 3.4095e-01, time/batch = 19.7179s	
6303/11350 (epoch 27.767), train_loss = 0.95786930, grad/param norm = 2.8817e-01, time/batch = 18.6841s	
6304/11350 (epoch 27.771), train_loss = 1.07326657, grad/param norm = 3.3796e-01, time/batch = 19.6020s	
6305/11350 (epoch 27.775), train_loss = 0.85397272, grad/param norm = 3.1476e-01, time/batch = 19.9219s	
6306/11350 (epoch 27.780), train_loss = 0.95251961, grad/param norm = 2.9228e-01, time/batch = 16.6498s	
6307/11350 (epoch 27.784), train_loss = 0.83400676, grad/param norm = 2.9999e-01, time/batch = 18.3553s	
6308/11350 (epoch 27.789), train_loss = 0.87034135, grad/param norm = 3.1710e-01, time/batch = 19.0024s	
6309/11350 (epoch 27.793), train_loss = 0.98553281, grad/param norm = 3.3814e-01, time/batch = 18.4357s	
6310/11350 (epoch 27.797), train_loss = 0.89289248, grad/param norm = 3.0609e-01, time/batch = 17.9349s	
6311/11350 (epoch 27.802), train_loss = 0.92498161, grad/param norm = 2.8649e-01, time/batch = 18.4391s	
6312/11350 (epoch 27.806), train_loss = 0.94082524, grad/param norm = 2.9789e-01, time/batch = 18.5253s	
6313/11350 (epoch 27.811), train_loss = 0.88949857, grad/param norm = 2.7687e-01, time/batch = 19.0345s	
6314/11350 (epoch 27.815), train_loss = 0.83798482, grad/param norm = 3.1497e-01, time/batch = 20.9498s	
6315/11350 (epoch 27.819), train_loss = 0.79323104, grad/param norm = 3.1007e-01, time/batch = 19.0284s	
6316/11350 (epoch 27.824), train_loss = 0.77287770, grad/param norm = 3.3239e-01, time/batch = 18.7698s	
6317/11350 (epoch 27.828), train_loss = 0.83298916, grad/param norm = 3.1284e-01, time/batch = 20.3702s	
6318/11350 (epoch 27.833), train_loss = 0.84848307, grad/param norm = 3.2085e-01, time/batch = 19.8561s	
6319/11350 (epoch 27.837), train_loss = 0.88873265, grad/param norm = 3.2687e-01, time/batch = 19.6973s	
6320/11350 (epoch 27.841), train_loss = 1.09764722, grad/param norm = 3.5620e-01, time/batch = 18.2854s	
6321/11350 (epoch 27.846), train_loss = 0.91100200, grad/param norm = 2.8106e-01, time/batch = 20.1237s	
6322/11350 (epoch 27.850), train_loss = 0.95368297, grad/param norm = 3.2022e-01, time/batch = 19.2827s	
6323/11350 (epoch 27.855), train_loss = 0.75120849, grad/param norm = 3.0824e-01, time/batch = 18.4477s	
6324/11350 (epoch 27.859), train_loss = 0.82438685, grad/param norm = 3.3250e-01, time/batch = 19.2817s	
6325/11350 (epoch 27.863), train_loss = 0.75312953, grad/param norm = 2.9249e-01, time/batch = 18.9335s	
6326/11350 (epoch 27.868), train_loss = 0.77192128, grad/param norm = 2.6205e-01, time/batch = 18.7957s	
6327/11350 (epoch 27.872), train_loss = 0.80496171, grad/param norm = 2.6436e-01, time/batch = 18.0938s	
6328/11350 (epoch 27.877), train_loss = 0.81131915, grad/param norm = 3.0906e-01, time/batch = 17.8613s	
6329/11350 (epoch 27.881), train_loss = 1.01836389, grad/param norm = 3.4238e-01, time/batch = 18.4465s	
6330/11350 (epoch 27.885), train_loss = 0.99785968, grad/param norm = 3.0920e-01, time/batch = 17.3317s	
6331/11350 (epoch 27.890), train_loss = 0.89790117, grad/param norm = 3.7913e-01, time/batch = 19.2899s	
6332/11350 (epoch 27.894), train_loss = 0.73771120, grad/param norm = 2.8513e-01, time/batch = 20.9417s	
6333/11350 (epoch 27.899), train_loss = 0.92135808, grad/param norm = 3.2406e-01, time/batch = 18.6126s	
6334/11350 (epoch 27.903), train_loss = 0.91781581, grad/param norm = 3.2205e-01, time/batch = 18.7975s	
6335/11350 (epoch 27.907), train_loss = 0.85320563, grad/param norm = 3.2782e-01, time/batch = 19.5435s	
6336/11350 (epoch 27.912), train_loss = 0.79288031, grad/param norm = 2.7645e-01, time/batch = 17.8775s	
6337/11350 (epoch 27.916), train_loss = 0.90959562, grad/param norm = 2.9411e-01, time/batch = 18.9402s	
6338/11350 (epoch 27.921), train_loss = 0.91340680, grad/param norm = 3.1893e-01, time/batch = 15.9868s	
6339/11350 (epoch 27.925), train_loss = 0.74693519, grad/param norm = 2.5233e-01, time/batch = 17.4615s	
6340/11350 (epoch 27.930), train_loss = 0.93651044, grad/param norm = 3.5547e-01, time/batch = 19.7871s	
6341/11350 (epoch 27.934), train_loss = 1.01291138, grad/param norm = 3.0904e-01, time/batch = 16.9512s	
6342/11350 (epoch 27.938), train_loss = 0.86410806, grad/param norm = 3.2243e-01, time/batch = 20.0286s	
6343/11350 (epoch 27.943), train_loss = 0.95039208, grad/param norm = 2.8389e-01, time/batch = 18.0525s	
6344/11350 (epoch 27.947), train_loss = 0.90723673, grad/param norm = 3.6497e-01, time/batch = 18.0464s	
6345/11350 (epoch 27.952), train_loss = 0.93263114, grad/param norm = 3.4775e-01, time/batch = 20.2862s	
6346/11350 (epoch 27.956), train_loss = 0.72835467, grad/param norm = 2.7741e-01, time/batch = 16.7599s	
6347/11350 (epoch 27.960), train_loss = 0.83030627, grad/param norm = 3.4058e-01, time/batch = 18.3676s	
6348/11350 (epoch 27.965), train_loss = 0.76255991, grad/param norm = 2.9201e-01, time/batch = 19.1284s	
6349/11350 (epoch 27.969), train_loss = 0.75360423, grad/param norm = 3.1556e-01, time/batch = 17.9659s	
6350/11350 (epoch 27.974), train_loss = 0.75991376, grad/param norm = 3.4314e-01, time/batch = 19.0376s	
6351/11350 (epoch 27.978), train_loss = 0.86432269, grad/param norm = 3.2387e-01, time/batch = 17.6810s	
6352/11350 (epoch 27.982), train_loss = 0.60538779, grad/param norm = 2.8833e-01, time/batch = 19.3809s	
6353/11350 (epoch 27.987), train_loss = 0.85220683, grad/param norm = 3.3719e-01, time/batch = 17.2900s	
6354/11350 (epoch 27.991), train_loss = 0.74247365, grad/param norm = 3.6451e-01, time/batch = 16.9325s	
6355/11350 (epoch 27.996), train_loss = 0.86659154, grad/param norm = 3.5546e-01, time/batch = 19.2005s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
6356/11350 (epoch 28.000), train_loss = 0.66210627, grad/param norm = 3.2523e-01, time/batch = 16.8685s	
6357/11350 (epoch 28.004), train_loss = 0.88714936, grad/param norm = 3.2844e-01, time/batch = 18.3639s	
6358/11350 (epoch 28.009), train_loss = 0.87330076, grad/param norm = 3.3216e-01, time/batch = 19.1155s	
6359/11350 (epoch 28.013), train_loss = 0.60753744, grad/param norm = 2.4592e-01, time/batch = 18.7236s	
6360/11350 (epoch 28.018), train_loss = 0.67945030, grad/param norm = 2.8323e-01, time/batch = 18.9509s	
6361/11350 (epoch 28.022), train_loss = 0.67826914, grad/param norm = 3.2684e-01, time/batch = 17.8596s	
6362/11350 (epoch 28.026), train_loss = 0.65185658, grad/param norm = 3.0815e-01, time/batch = 20.5358s	
6363/11350 (epoch 28.031), train_loss = 0.71826520, grad/param norm = 3.0373e-01, time/batch = 18.5292s	
6364/11350 (epoch 28.035), train_loss = 0.72108601, grad/param norm = 3.5163e-01, time/batch = 17.7577s	
6365/11350 (epoch 28.040), train_loss = 0.75621963, grad/param norm = 2.9979e-01, time/batch = 20.2937s	
6366/11350 (epoch 28.044), train_loss = 0.70187883, grad/param norm = 2.6141e-01, time/batch = 20.3647s	
6367/11350 (epoch 28.048), train_loss = 0.67794462, grad/param norm = 2.8495e-01, time/batch = 18.6996s	
6368/11350 (epoch 28.053), train_loss = 0.76507182, grad/param norm = 2.9140e-01, time/batch = 18.8665s	
6369/11350 (epoch 28.057), train_loss = 0.75973799, grad/param norm = 3.3314e-01, time/batch = 20.3711s	
6370/11350 (epoch 28.062), train_loss = 0.64304594, grad/param norm = 3.1090e-01, time/batch = 19.3673s	
6371/11350 (epoch 28.066), train_loss = 0.66164126, grad/param norm = 3.6929e-01, time/batch = 17.8758s	
6372/11350 (epoch 28.070), train_loss = 0.70605426, grad/param norm = 2.9770e-01, time/batch = 20.2803s	
6373/11350 (epoch 28.075), train_loss = 0.67095280, grad/param norm = 2.8524e-01, time/batch = 17.2774s	
6374/11350 (epoch 28.079), train_loss = 0.80297063, grad/param norm = 3.2088e-01, time/batch = 18.3747s	
6375/11350 (epoch 28.084), train_loss = 0.89883251, grad/param norm = 3.2980e-01, time/batch = 18.2987s	
6376/11350 (epoch 28.088), train_loss = 0.82305634, grad/param norm = 3.0885e-01, time/batch = 18.0399s	
6377/11350 (epoch 28.093), train_loss = 0.81252865, grad/param norm = 2.7046e-01, time/batch = 20.0325s	
6378/11350 (epoch 28.097), train_loss = 0.77069096, grad/param norm = 3.0419e-01, time/batch = 19.0352s	
6379/11350 (epoch 28.101), train_loss = 0.71753829, grad/param norm = 3.0846e-01, time/batch = 17.1891s	
6380/11350 (epoch 28.106), train_loss = 0.83301568, grad/param norm = 3.8575e-01, time/batch = 19.8766s	
6381/11350 (epoch 28.110), train_loss = 0.72344590, grad/param norm = 2.8519e-01, time/batch = 18.0028s	
6382/11350 (epoch 28.115), train_loss = 0.76081614, grad/param norm = 3.1498e-01, time/batch = 18.8684s	
6383/11350 (epoch 28.119), train_loss = 0.87589818, grad/param norm = 3.7934e-01, time/batch = 18.6290s	
6384/11350 (epoch 28.123), train_loss = 0.71427578, grad/param norm = 3.0265e-01, time/batch = 20.0369s	
6385/11350 (epoch 28.128), train_loss = 0.63941094, grad/param norm = 2.7906e-01, time/batch = 19.3707s	
6386/11350 (epoch 28.132), train_loss = 0.69824003, grad/param norm = 2.7260e-01, time/batch = 19.0056s	
6387/11350 (epoch 28.137), train_loss = 0.68120997, grad/param norm = 3.1073e-01, time/batch = 18.6216s	
6388/11350 (epoch 28.141), train_loss = 0.89273167, grad/param norm = 3.3570e-01, time/batch = 20.2030s	
6389/11350 (epoch 28.145), train_loss = 0.72119445, grad/param norm = 3.1190e-01, time/batch = 34.1340s	
6390/11350 (epoch 28.150), train_loss = 0.79786124, grad/param norm = 3.9520e-01, time/batch = 18.1314s	
6391/11350 (epoch 28.154), train_loss = 0.91384785, grad/param norm = 3.4603e-01, time/batch = 17.8723s	
6392/11350 (epoch 28.159), train_loss = 0.64069568, grad/param norm = 2.6951e-01, time/batch = 20.6956s	
6393/11350 (epoch 28.163), train_loss = 0.83605818, grad/param norm = 3.2747e-01, time/batch = 18.6243s	
6394/11350 (epoch 28.167), train_loss = 0.88602972, grad/param norm = 2.9772e-01, time/batch = 17.1902s	
6395/11350 (epoch 28.172), train_loss = 0.96976431, grad/param norm = 3.3136e-01, time/batch = 19.7053s	
6396/11350 (epoch 28.176), train_loss = 0.76900176, grad/param norm = 2.8280e-01, time/batch = 17.1407s	
6397/11350 (epoch 28.181), train_loss = 0.81830188, grad/param norm = 3.6919e-01, time/batch = 19.1953s	
6398/11350 (epoch 28.185), train_loss = 0.70247575, grad/param norm = 2.8994e-01, time/batch = 16.5203s	
6399/11350 (epoch 28.189), train_loss = 0.76680024, grad/param norm = 2.8600e-01, time/batch = 18.7828s	
6400/11350 (epoch 28.194), train_loss = 0.70789864, grad/param norm = 3.3467e-01, time/batch = 20.3603s	
6401/11350 (epoch 28.198), train_loss = 0.65808781, grad/param norm = 3.3473e-01, time/batch = 16.6886s	
6402/11350 (epoch 28.203), train_loss = 0.71005361, grad/param norm = 3.5525e-01, time/batch = 18.6037s	
6403/11350 (epoch 28.207), train_loss = 0.65119094, grad/param norm = 3.1326e-01, time/batch = 20.2902s	
6404/11350 (epoch 28.211), train_loss = 0.86554690, grad/param norm = 4.1537e-01, time/batch = 17.5227s	
6405/11350 (epoch 28.216), train_loss = 0.84720630, grad/param norm = 3.7483e-01, time/batch = 20.1151s	
6406/11350 (epoch 28.220), train_loss = 0.83068351, grad/param norm = 3.1330e-01, time/batch = 18.8373s	
6407/11350 (epoch 28.225), train_loss = 0.71935499, grad/param norm = 2.8225e-01, time/batch = 18.4384s	
6408/11350 (epoch 28.229), train_loss = 0.80609425, grad/param norm = 2.8172e-01, time/batch = 19.8708s	
6409/11350 (epoch 28.233), train_loss = 0.77948460, grad/param norm = 2.8783e-01, time/batch = 16.7575s	
6410/11350 (epoch 28.238), train_loss = 0.88354906, grad/param norm = 3.7667e-01, time/batch = 19.1896s	
6411/11350 (epoch 28.242), train_loss = 0.89571581, grad/param norm = 3.6996e-01, time/batch = 19.1312s	
6412/11350 (epoch 28.247), train_loss = 0.67021666, grad/param norm = 2.4086e-01, time/batch = 18.6296s	
6413/11350 (epoch 28.251), train_loss = 0.80929603, grad/param norm = 3.3576e-01, time/batch = 19.6213s	
6414/11350 (epoch 28.256), train_loss = 0.81092084, grad/param norm = 3.7087e-01, time/batch = 17.8018s	
6415/11350 (epoch 28.260), train_loss = 0.73617152, grad/param norm = 2.9718e-01, time/batch = 18.1102s	
6416/11350 (epoch 28.264), train_loss = 0.71762956, grad/param norm = 2.9210e-01, time/batch = 20.6145s	
6417/11350 (epoch 28.269), train_loss = 0.78028826, grad/param norm = 2.9483e-01, time/batch = 18.6848s	
6418/11350 (epoch 28.273), train_loss = 0.88587398, grad/param norm = 3.1090e-01, time/batch = 18.3761s	
6419/11350 (epoch 28.278), train_loss = 0.73235083, grad/param norm = 2.7555e-01, time/batch = 19.2175s	
6420/11350 (epoch 28.282), train_loss = 0.76357816, grad/param norm = 3.1848e-01, time/batch = 17.0914s	
6421/11350 (epoch 28.286), train_loss = 0.86307786, grad/param norm = 3.2674e-01, time/batch = 18.9328s	
6422/11350 (epoch 28.291), train_loss = 0.69743007, grad/param norm = 3.2745e-01, time/batch = 17.3080s	
6423/11350 (epoch 28.295), train_loss = 0.78945043, grad/param norm = 3.3480e-01, time/batch = 17.2066s	
6424/11350 (epoch 28.300), train_loss = 0.84763643, grad/param norm = 3.2966e-01, time/batch = 19.7017s	
6425/11350 (epoch 28.304), train_loss = 0.71764404, grad/param norm = 2.9051e-01, time/batch = 19.7018s	
6426/11350 (epoch 28.308), train_loss = 0.69353213, grad/param norm = 2.9197e-01, time/batch = 18.9552s	
6427/11350 (epoch 28.313), train_loss = 0.80257139, grad/param norm = 2.8338e-01, time/batch = 18.4584s	
6428/11350 (epoch 28.317), train_loss = 0.73877869, grad/param norm = 2.6764e-01, time/batch = 20.3766s	
6429/11350 (epoch 28.322), train_loss = 0.74107702, grad/param norm = 2.8688e-01, time/batch = 18.6195s	
6430/11350 (epoch 28.326), train_loss = 0.76595282, grad/param norm = 2.6474e-01, time/batch = 18.3083s	
6431/11350 (epoch 28.330), train_loss = 0.64105125, grad/param norm = 2.5190e-01, time/batch = 16.5058s	
6432/11350 (epoch 28.335), train_loss = 0.52179854, grad/param norm = 2.8753e-01, time/batch = 19.6940s	
6433/11350 (epoch 28.339), train_loss = 0.60810145, grad/param norm = 2.9125e-01, time/batch = 18.7770s	
6434/11350 (epoch 28.344), train_loss = 0.68835585, grad/param norm = 2.2806e-01, time/batch = 16.2498s	
6435/11350 (epoch 28.348), train_loss = 0.69955283, grad/param norm = 2.6020e-01, time/batch = 20.0286s	
6436/11350 (epoch 28.352), train_loss = 0.62056092, grad/param norm = 2.6444e-01, time/batch = 18.0999s	
6437/11350 (epoch 28.357), train_loss = 0.71623982, grad/param norm = 2.6327e-01, time/batch = 19.7053s	
6438/11350 (epoch 28.361), train_loss = 0.58116668, grad/param norm = 2.5327e-01, time/batch = 18.8632s	
6439/11350 (epoch 28.366), train_loss = 0.76443801, grad/param norm = 3.6197e-01, time/batch = 18.2808s	
6440/11350 (epoch 28.370), train_loss = 0.66019551, grad/param norm = 3.6074e-01, time/batch = 19.7864s	
6441/11350 (epoch 28.374), train_loss = 0.69109716, grad/param norm = 2.8212e-01, time/batch = 20.7864s	
6442/11350 (epoch 28.379), train_loss = 0.68631652, grad/param norm = 3.3487e-01, time/batch = 18.6027s	
6443/11350 (epoch 28.383), train_loss = 0.63635056, grad/param norm = 3.1060e-01, time/batch = 19.0547s	
6444/11350 (epoch 28.388), train_loss = 0.74787896, grad/param norm = 3.5695e-01, time/batch = 18.8782s	
6445/11350 (epoch 28.392), train_loss = 0.77719970, grad/param norm = 3.2677e-01, time/batch = 18.5367s	
6446/11350 (epoch 28.396), train_loss = 0.72692847, grad/param norm = 3.1409e-01, time/batch = 16.8996s	
6447/11350 (epoch 28.401), train_loss = 0.73577297, grad/param norm = 3.5276e-01, time/batch = 16.3818s	
6448/11350 (epoch 28.405), train_loss = 0.91897807, grad/param norm = 3.9053e-01, time/batch = 19.7934s	
6449/11350 (epoch 28.410), train_loss = 0.96172679, grad/param norm = 4.8469e-01, time/batch = 18.4483s	
6450/11350 (epoch 28.414), train_loss = 0.66635444, grad/param norm = 3.0159e-01, time/batch = 17.8709s	
6451/11350 (epoch 28.419), train_loss = 0.67501540, grad/param norm = 3.3683e-01, time/batch = 19.1285s	
6452/11350 (epoch 28.423), train_loss = 0.75032604, grad/param norm = 3.5534e-01, time/batch = 18.2013s	
6453/11350 (epoch 28.427), train_loss = 0.82549748, grad/param norm = 3.2798e-01, time/batch = 18.3721s	
6454/11350 (epoch 28.432), train_loss = 0.76660239, grad/param norm = 4.0331e-01, time/batch = 18.5479s	
6455/11350 (epoch 28.436), train_loss = 0.73186562, grad/param norm = 3.3619e-01, time/batch = 15.9367s	
6456/11350 (epoch 28.441), train_loss = 0.88498016, grad/param norm = 3.3691e-01, time/batch = 19.0431s	
6457/11350 (epoch 28.445), train_loss = 0.67409039, grad/param norm = 2.7756e-01, time/batch = 17.8726s	
6458/11350 (epoch 28.449), train_loss = 0.76650633, grad/param norm = 3.2495e-01, time/batch = 19.0437s	
6459/11350 (epoch 28.454), train_loss = 0.88192021, grad/param norm = 3.2054e-01, time/batch = 19.2845s	
6460/11350 (epoch 28.458), train_loss = 0.62886152, grad/param norm = 2.7468e-01, time/batch = 18.2914s	
6461/11350 (epoch 28.463), train_loss = 0.64123645, grad/param norm = 2.9324e-01, time/batch = 19.8646s	
6462/11350 (epoch 28.467), train_loss = 1.00591410, grad/param norm = 3.5241e-01, time/batch = 19.6207s	
6463/11350 (epoch 28.471), train_loss = 0.90735060, grad/param norm = 4.8715e-01, time/batch = 19.0287s	
6464/11350 (epoch 28.476), train_loss = 0.81354934, grad/param norm = 3.1628e-01, time/batch = 19.3579s	
6465/11350 (epoch 28.480), train_loss = 0.89069323, grad/param norm = 2.9281e-01, time/batch = 18.8557s	
6466/11350 (epoch 28.485), train_loss = 0.78554865, grad/param norm = 3.0557e-01, time/batch = 18.2845s	
6467/11350 (epoch 28.489), train_loss = 0.90062635, grad/param norm = 3.1420e-01, time/batch = 20.1944s	
6468/11350 (epoch 28.493), train_loss = 0.89341532, grad/param norm = 3.0868e-01, time/batch = 17.5145s	
6469/11350 (epoch 28.498), train_loss = 0.59121217, grad/param norm = 2.8510e-01, time/batch = 19.7874s	
6470/11350 (epoch 28.502), train_loss = 0.87844010, grad/param norm = 2.9720e-01, time/batch = 18.4563s	
6471/11350 (epoch 28.507), train_loss = 0.67599825, grad/param norm = 2.6368e-01, time/batch = 18.5324s	
6472/11350 (epoch 28.511), train_loss = 0.87978326, grad/param norm = 2.7829e-01, time/batch = 17.6962s	
6473/11350 (epoch 28.515), train_loss = 0.78841862, grad/param norm = 3.1979e-01, time/batch = 18.6405s	
6474/11350 (epoch 28.520), train_loss = 0.94286887, grad/param norm = 3.2352e-01, time/batch = 17.8712s	
6475/11350 (epoch 28.524), train_loss = 0.81375328, grad/param norm = 3.1309e-01, time/batch = 17.0497s	
6476/11350 (epoch 28.529), train_loss = 0.77278608, grad/param norm = 3.0271e-01, time/batch = 18.3671s	
6477/11350 (epoch 28.533), train_loss = 0.94549512, grad/param norm = 3.2066e-01, time/batch = 19.5467s	
6478/11350 (epoch 28.537), train_loss = 0.88078984, grad/param norm = 3.2534e-01, time/batch = 17.4595s	
6479/11350 (epoch 28.542), train_loss = 0.82836780, grad/param norm = 2.8593e-01, time/batch = 20.2890s	
6480/11350 (epoch 28.546), train_loss = 1.00671864, grad/param norm = 3.4870e-01, time/batch = 19.8591s	
6481/11350 (epoch 28.551), train_loss = 0.84329920, grad/param norm = 3.1827e-01, time/batch = 19.9329s	
6482/11350 (epoch 28.555), train_loss = 0.73404253, grad/param norm = 2.7192e-01, time/batch = 17.7862s	
6483/11350 (epoch 28.559), train_loss = 0.77141909, grad/param norm = 3.0831e-01, time/batch = 19.6977s	
6484/11350 (epoch 28.564), train_loss = 0.85484850, grad/param norm = 3.5267e-01, time/batch = 17.3543s	
6485/11350 (epoch 28.568), train_loss = 0.88368927, grad/param norm = 2.9055e-01, time/batch = 18.0557s	
6486/11350 (epoch 28.573), train_loss = 0.95224564, grad/param norm = 3.4998e-01, time/batch = 18.7212s	
6487/11350 (epoch 28.577), train_loss = 0.89370746, grad/param norm = 4.0095e-01, time/batch = 19.6837s	
6488/11350 (epoch 28.581), train_loss = 0.91546738, grad/param norm = 3.1506e-01, time/batch = 19.5451s	
6489/11350 (epoch 28.586), train_loss = 0.91501841, grad/param norm = 3.3691e-01, time/batch = 18.7912s	
6490/11350 (epoch 28.590), train_loss = 0.98586953, grad/param norm = 3.6396e-01, time/batch = 18.1957s	
6491/11350 (epoch 28.595), train_loss = 1.03002905, grad/param norm = 3.4360e-01, time/batch = 19.3031s	
6492/11350 (epoch 28.599), train_loss = 0.88768422, grad/param norm = 3.2304e-01, time/batch = 20.1139s	
6493/11350 (epoch 28.604), train_loss = 0.85111603, grad/param norm = 3.2172e-01, time/batch = 18.4395s	
6494/11350 (epoch 28.608), train_loss = 0.81585576, grad/param norm = 3.4497e-01, time/batch = 20.1117s	
6495/11350 (epoch 28.612), train_loss = 0.82669697, grad/param norm = 3.1281e-01, time/batch = 19.0368s	
6496/11350 (epoch 28.617), train_loss = 0.88741316, grad/param norm = 3.1693e-01, time/batch = 18.6813s	
6497/11350 (epoch 28.621), train_loss = 0.94627218, grad/param norm = 3.1502e-01, time/batch = 20.5407s	
6498/11350 (epoch 28.626), train_loss = 0.84518228, grad/param norm = 3.1679e-01, time/batch = 17.2525s	
6499/11350 (epoch 28.630), train_loss = 0.86415422, grad/param norm = 3.2260e-01, time/batch = 19.2771s	
6500/11350 (epoch 28.634), train_loss = 0.82942665, grad/param norm = 2.9545e-01, time/batch = 17.5866s	
6501/11350 (epoch 28.639), train_loss = 0.75973557, grad/param norm = 2.9207e-01, time/batch = 20.0334s	
6502/11350 (epoch 28.643), train_loss = 0.73104272, grad/param norm = 2.9118e-01, time/batch = 17.5279s	
6503/11350 (epoch 28.648), train_loss = 0.81590792, grad/param norm = 3.0315e-01, time/batch = 18.5351s	
6504/11350 (epoch 28.652), train_loss = 0.74212703, grad/param norm = 3.1101e-01, time/batch = 20.0419s	
6505/11350 (epoch 28.656), train_loss = 0.85763417, grad/param norm = 3.1224e-01, time/batch = 18.8725s	
6506/11350 (epoch 28.661), train_loss = 0.93069103, grad/param norm = 3.5030e-01, time/batch = 19.8555s	
6507/11350 (epoch 28.665), train_loss = 0.85505194, grad/param norm = 3.4352e-01, time/batch = 20.2907s	
6508/11350 (epoch 28.670), train_loss = 0.84097496, grad/param norm = 3.0384e-01, time/batch = 17.1804s	
6509/11350 (epoch 28.674), train_loss = 0.79844643, grad/param norm = 2.7191e-01, time/batch = 18.6856s	
6510/11350 (epoch 28.678), train_loss = 0.82749636, grad/param norm = 2.5494e-01, time/batch = 18.9568s	
6511/11350 (epoch 28.683), train_loss = 0.77071822, grad/param norm = 3.0896e-01, time/batch = 21.1110s	
6512/11350 (epoch 28.687), train_loss = 0.74544301, grad/param norm = 3.6704e-01, time/batch = 17.3801s	
6513/11350 (epoch 28.692), train_loss = 1.10690103, grad/param norm = 4.5842e-01, time/batch = 18.7891s	
6514/11350 (epoch 28.696), train_loss = 1.00741689, grad/param norm = 3.7154e-01, time/batch = 18.2909s	
6515/11350 (epoch 28.700), train_loss = 0.93512051, grad/param norm = 3.6781e-01, time/batch = 18.9508s	
6516/11350 (epoch 28.705), train_loss = 0.97423461, grad/param norm = 4.0402e-01, time/batch = 18.9458s	
6517/11350 (epoch 28.709), train_loss = 0.96332066, grad/param norm = 3.4347e-01, time/batch = 18.7212s	
6518/11350 (epoch 28.714), train_loss = 0.86179927, grad/param norm = 3.1115e-01, time/batch = 20.1172s	
6519/11350 (epoch 28.718), train_loss = 0.72455493, grad/param norm = 2.7701e-01, time/batch = 18.8644s	
6520/11350 (epoch 28.722), train_loss = 0.85594333, grad/param norm = 3.8563e-01, time/batch = 18.6801s	
6521/11350 (epoch 28.727), train_loss = 0.85969635, grad/param norm = 2.8866e-01, time/batch = 17.0797s	
6522/11350 (epoch 28.731), train_loss = 0.85758002, grad/param norm = 3.1575e-01, time/batch = 18.6919s	
6523/11350 (epoch 28.736), train_loss = 0.80662074, grad/param norm = 4.4700e-01, time/batch = 18.3638s	
6524/11350 (epoch 28.740), train_loss = 0.84668734, grad/param norm = 3.1092e-01, time/batch = 19.9532s	
6525/11350 (epoch 28.744), train_loss = 0.84909692, grad/param norm = 3.4709e-01, time/batch = 18.6088s	
6526/11350 (epoch 28.749), train_loss = 0.86999616, grad/param norm = 3.4670e-01, time/batch = 18.4410s	
6527/11350 (epoch 28.753), train_loss = 0.91157590, grad/param norm = 4.4405e-01, time/batch = 19.4565s	
6528/11350 (epoch 28.758), train_loss = 0.80793807, grad/param norm = 3.2451e-01, time/batch = 18.6253s	
6529/11350 (epoch 28.762), train_loss = 0.94127947, grad/param norm = 2.9453e-01, time/batch = 20.4489s	
6530/11350 (epoch 28.767), train_loss = 0.93007417, grad/param norm = 2.7457e-01, time/batch = 20.0146s	
6531/11350 (epoch 28.771), train_loss = 1.06020031, grad/param norm = 3.5596e-01, time/batch = 18.3691s	
6532/11350 (epoch 28.775), train_loss = 0.85177728, grad/param norm = 3.3710e-01, time/batch = 18.9610s	
6533/11350 (epoch 28.780), train_loss = 0.94227419, grad/param norm = 3.4051e-01, time/batch = 17.1318s	
6534/11350 (epoch 28.784), train_loss = 0.82777604, grad/param norm = 3.1285e-01, time/batch = 19.1341s	
6535/11350 (epoch 28.789), train_loss = 0.86521558, grad/param norm = 3.4623e-01, time/batch = 19.9502s	
6536/11350 (epoch 28.793), train_loss = 0.95525521, grad/param norm = 2.8945e-01, time/batch = 18.5291s	
6537/11350 (epoch 28.797), train_loss = 0.84895578, grad/param norm = 3.0416e-01, time/batch = 19.7764s	
6538/11350 (epoch 28.802), train_loss = 0.89444612, grad/param norm = 3.4882e-01, time/batch = 20.1981s	
6539/11350 (epoch 28.806), train_loss = 0.91440295, grad/param norm = 2.7821e-01, time/batch = 18.8686s	
6540/11350 (epoch 28.811), train_loss = 0.89066859, grad/param norm = 2.9904e-01, time/batch = 18.6119s	
6541/11350 (epoch 28.815), train_loss = 0.81658768, grad/param norm = 2.9995e-01, time/batch = 16.4583s	
6542/11350 (epoch 28.819), train_loss = 0.76988669, grad/param norm = 3.0043e-01, time/batch = 19.5961s	
6543/11350 (epoch 28.824), train_loss = 0.75766030, grad/param norm = 3.0885e-01, time/batch = 19.9427s	
6544/11350 (epoch 28.828), train_loss = 0.79675447, grad/param norm = 2.9416e-01, time/batch = 18.3537s	
6545/11350 (epoch 28.833), train_loss = 0.83116146, grad/param norm = 3.0179e-01, time/batch = 18.6138s	
6546/11350 (epoch 28.837), train_loss = 0.86971322, grad/param norm = 3.2743e-01, time/batch = 18.3772s	
6547/11350 (epoch 28.841), train_loss = 1.11135521, grad/param norm = 3.9494e-01, time/batch = 17.5298s	
6548/11350 (epoch 28.846), train_loss = 0.89914997, grad/param norm = 2.8209e-01, time/batch = 19.1969s	
6549/11350 (epoch 28.850), train_loss = 0.93396057, grad/param norm = 3.8189e-01, time/batch = 18.7112s	
6550/11350 (epoch 28.855), train_loss = 0.74409975, grad/param norm = 3.4491e-01, time/batch = 19.1241s	
6551/11350 (epoch 28.859), train_loss = 0.79854510, grad/param norm = 3.5328e-01, time/batch = 20.5280s	
6552/11350 (epoch 28.863), train_loss = 0.75111374, grad/param norm = 3.1125e-01, time/batch = 18.2169s	
6553/11350 (epoch 28.868), train_loss = 0.75858602, grad/param norm = 3.1081e-01, time/batch = 19.1999s	
6554/11350 (epoch 28.872), train_loss = 0.80465976, grad/param norm = 3.0603e-01, time/batch = 19.1198s	
6555/11350 (epoch 28.877), train_loss = 0.82222990, grad/param norm = 3.7789e-01, time/batch = 18.6917s	
6556/11350 (epoch 28.881), train_loss = 0.99362606, grad/param norm = 3.5852e-01, time/batch = 19.4353s	
6557/11350 (epoch 28.885), train_loss = 0.97916151, grad/param norm = 2.9608e-01, time/batch = 19.4575s	
6558/11350 (epoch 28.890), train_loss = 0.88811204, grad/param norm = 3.3997e-01, time/batch = 18.3780s	
6559/11350 (epoch 28.894), train_loss = 0.71576940, grad/param norm = 3.1762e-01, time/batch = 19.5162s	
6560/11350 (epoch 28.899), train_loss = 0.91692007, grad/param norm = 3.5831e-01, time/batch = 18.6191s	
6561/11350 (epoch 28.903), train_loss = 0.88157677, grad/param norm = 3.3086e-01, time/batch = 16.5804s	
6562/11350 (epoch 28.907), train_loss = 0.80461389, grad/param norm = 3.0609e-01, time/batch = 20.6137s	
6563/11350 (epoch 28.912), train_loss = 0.76458039, grad/param norm = 2.6009e-01, time/batch = 19.1043s	
6564/11350 (epoch 28.916), train_loss = 0.88523589, grad/param norm = 3.0263e-01, time/batch = 17.9675s	
6565/11350 (epoch 28.921), train_loss = 0.88574864, grad/param norm = 3.0568e-01, time/batch = 20.1258s	
6566/11350 (epoch 28.925), train_loss = 0.72647585, grad/param norm = 2.4901e-01, time/batch = 17.7969s	
6567/11350 (epoch 28.930), train_loss = 0.89662944, grad/param norm = 3.5546e-01, time/batch = 19.5467s	
6568/11350 (epoch 28.934), train_loss = 0.98803301, grad/param norm = 3.6342e-01, time/batch = 18.3527s	
6569/11350 (epoch 28.938), train_loss = 0.83971864, grad/param norm = 3.0138e-01, time/batch = 19.1222s	
6570/11350 (epoch 28.943), train_loss = 0.92392943, grad/param norm = 2.9823e-01, time/batch = 19.6291s	
6571/11350 (epoch 28.947), train_loss = 0.89148443, grad/param norm = 3.8243e-01, time/batch = 19.6911s	
6572/11350 (epoch 28.952), train_loss = 0.92140289, grad/param norm = 3.5388e-01, time/batch = 19.3686s	
6573/11350 (epoch 28.956), train_loss = 0.70578480, grad/param norm = 2.7435e-01, time/batch = 18.9569s	
6574/11350 (epoch 28.960), train_loss = 0.79284480, grad/param norm = 3.2098e-01, time/batch = 16.9391s	
6575/11350 (epoch 28.965), train_loss = 0.74180946, grad/param norm = 3.2012e-01, time/batch = 18.7874s	
6576/11350 (epoch 28.969), train_loss = 0.74338138, grad/param norm = 3.6360e-01, time/batch = 20.2984s	
6577/11350 (epoch 28.974), train_loss = 0.74657756, grad/param norm = 3.5585e-01, time/batch = 16.9700s	
6578/11350 (epoch 28.978), train_loss = 0.83252007, grad/param norm = 2.9723e-01, time/batch = 18.6381s	
6579/11350 (epoch 28.982), train_loss = 0.57927842, grad/param norm = 2.8032e-01, time/batch = 34.4060s	
6580/11350 (epoch 28.987), train_loss = 0.83084633, grad/param norm = 3.2641e-01, time/batch = 19.6253s	
6581/11350 (epoch 28.991), train_loss = 0.72368081, grad/param norm = 3.4823e-01, time/batch = 18.7021s	
6582/11350 (epoch 28.996), train_loss = 0.84894417, grad/param norm = 3.7334e-01, time/batch = 18.6298s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
6583/11350 (epoch 29.000), train_loss = 0.63687810, grad/param norm = 2.8328e-01, time/batch = 20.4674s	
6584/11350 (epoch 29.004), train_loss = 0.88860142, grad/param norm = 3.8298e-01, time/batch = 17.9364s	
6585/11350 (epoch 29.009), train_loss = 0.83876177, grad/param norm = 2.9944e-01, time/batch = 19.8597s	
6586/11350 (epoch 29.013), train_loss = 0.59646827, grad/param norm = 2.5895e-01, time/batch = 19.6115s	
6587/11350 (epoch 29.018), train_loss = 0.65544601, grad/param norm = 2.6602e-01, time/batch = 18.1160s	
6588/11350 (epoch 29.022), train_loss = 0.68634890, grad/param norm = 4.1891e-01, time/batch = 17.1155s	
6589/11350 (epoch 29.026), train_loss = 0.64107685, grad/param norm = 3.1863e-01, time/batch = 18.9721s	
6590/11350 (epoch 29.031), train_loss = 0.69760182, grad/param norm = 2.8785e-01, time/batch = 19.0296s	
6591/11350 (epoch 29.035), train_loss = 0.70066631, grad/param norm = 3.3810e-01, time/batch = 19.7826s	
6592/11350 (epoch 29.040), train_loss = 0.73926933, grad/param norm = 2.9774e-01, time/batch = 18.5439s	
6593/11350 (epoch 29.044), train_loss = 0.70036999, grad/param norm = 2.6199e-01, time/batch = 19.4529s	
6594/11350 (epoch 29.048), train_loss = 0.66778655, grad/param norm = 2.6860e-01, time/batch = 19.3514s	
6595/11350 (epoch 29.053), train_loss = 0.73884377, grad/param norm = 2.9929e-01, time/batch = 19.6130s	
6596/11350 (epoch 29.057), train_loss = 0.76262577, grad/param norm = 3.7955e-01, time/batch = 19.1984s	
6597/11350 (epoch 29.062), train_loss = 0.61917695, grad/param norm = 2.8142e-01, time/batch = 19.1028s	
6598/11350 (epoch 29.066), train_loss = 0.62694069, grad/param norm = 2.9523e-01, time/batch = 19.6200s	
6599/11350 (epoch 29.070), train_loss = 0.70043879, grad/param norm = 3.1933e-01, time/batch = 19.8575s	
6600/11350 (epoch 29.075), train_loss = 0.62996196, grad/param norm = 2.5837e-01, time/batch = 16.1849s	
6601/11350 (epoch 29.079), train_loss = 0.75963807, grad/param norm = 2.8156e-01, time/batch = 18.1290s	
6602/11350 (epoch 29.084), train_loss = 0.88817112, grad/param norm = 3.5281e-01, time/batch = 20.4188s	
6603/11350 (epoch 29.088), train_loss = 0.83440588, grad/param norm = 3.8095e-01, time/batch = 18.0359s	
6604/11350 (epoch 29.093), train_loss = 0.80555048, grad/param norm = 2.7909e-01, time/batch = 19.7981s	
6605/11350 (epoch 29.097), train_loss = 0.74681871, grad/param norm = 3.3123e-01, time/batch = 18.8644s	
6606/11350 (epoch 29.101), train_loss = 0.69530421, grad/param norm = 3.2848e-01, time/batch = 18.3721s	
6607/11350 (epoch 29.106), train_loss = 0.79748624, grad/param norm = 3.3879e-01, time/batch = 18.6277s	
6608/11350 (epoch 29.110), train_loss = 0.70118792, grad/param norm = 3.1926e-01, time/batch = 17.2077s	
6609/11350 (epoch 29.115), train_loss = 0.73329572, grad/param norm = 3.4309e-01, time/batch = 19.0252s	
6610/11350 (epoch 29.119), train_loss = 0.83685608, grad/param norm = 3.4847e-01, time/batch = 17.3710s	
6611/11350 (epoch 29.123), train_loss = 0.69785230, grad/param norm = 3.1252e-01, time/batch = 18.2983s	
6612/11350 (epoch 29.128), train_loss = 0.62467464, grad/param norm = 2.8920e-01, time/batch = 19.0477s	
6613/11350 (epoch 29.132), train_loss = 0.67686351, grad/param norm = 2.8009e-01, time/batch = 17.1297s	
6614/11350 (epoch 29.137), train_loss = 0.65615981, grad/param norm = 2.9527e-01, time/batch = 18.5484s	
6615/11350 (epoch 29.141), train_loss = 0.86507215, grad/param norm = 3.7612e-01, time/batch = 18.3808s	
6616/11350 (epoch 29.145), train_loss = 0.69291423, grad/param norm = 2.8155e-01, time/batch = 18.4453s	
6617/11350 (epoch 29.150), train_loss = 0.76517636, grad/param norm = 4.2926e-01, time/batch = 19.6285s	
6618/11350 (epoch 29.154), train_loss = 0.89612641, grad/param norm = 3.6941e-01, time/batch = 17.7190s	
6619/11350 (epoch 29.159), train_loss = 0.63074934, grad/param norm = 2.6372e-01, time/batch = 17.8786s	
6620/11350 (epoch 29.163), train_loss = 0.81242030, grad/param norm = 3.3283e-01, time/batch = 17.5445s	
6621/11350 (epoch 29.167), train_loss = 0.87261992, grad/param norm = 2.9340e-01, time/batch = 17.4326s	
6622/11350 (epoch 29.172), train_loss = 0.93234947, grad/param norm = 3.0411e-01, time/batch = 18.6873s	
6623/11350 (epoch 29.176), train_loss = 0.75946927, grad/param norm = 3.2086e-01, time/batch = 16.0880s	
6624/11350 (epoch 29.181), train_loss = 0.80861681, grad/param norm = 3.7383e-01, time/batch = 15.8485s	
6625/11350 (epoch 29.185), train_loss = 0.69038973, grad/param norm = 2.9697e-01, time/batch = 17.1689s	
6626/11350 (epoch 29.189), train_loss = 0.74380559, grad/param norm = 3.0306e-01, time/batch = 15.8396s	
6627/11350 (epoch 29.194), train_loss = 0.69189445, grad/param norm = 3.3007e-01, time/batch = 14.8150s	
6628/11350 (epoch 29.198), train_loss = 0.66180285, grad/param norm = 3.8567e-01, time/batch = 15.8592s	
6629/11350 (epoch 29.203), train_loss = 0.69510818, grad/param norm = 3.3970e-01, time/batch = 19.2864s	
6630/11350 (epoch 29.207), train_loss = 0.66645821, grad/param norm = 4.6776e-01, time/batch = 17.5166s	
6631/11350 (epoch 29.211), train_loss = 0.85336178, grad/param norm = 3.3129e-01, time/batch = 19.5523s	
6632/11350 (epoch 29.216), train_loss = 0.82176219, grad/param norm = 3.6033e-01, time/batch = 18.1158s	
6633/11350 (epoch 29.220), train_loss = 0.80192150, grad/param norm = 3.0323e-01, time/batch = 17.9443s	
6634/11350 (epoch 29.225), train_loss = 0.69794001, grad/param norm = 2.9375e-01, time/batch = 19.2927s	
6635/11350 (epoch 29.229), train_loss = 0.78095175, grad/param norm = 2.6855e-01, time/batch = 19.7103s	
6636/11350 (epoch 29.233), train_loss = 0.76901910, grad/param norm = 3.0632e-01, time/batch = 18.8686s	
6637/11350 (epoch 29.238), train_loss = 0.86562215, grad/param norm = 3.8074e-01, time/batch = 18.0550s	
6638/11350 (epoch 29.242), train_loss = 0.90022057, grad/param norm = 3.9681e-01, time/batch = 16.4434s	
6639/11350 (epoch 29.247), train_loss = 0.64898025, grad/param norm = 2.7765e-01, time/batch = 18.9461s	
6640/11350 (epoch 29.251), train_loss = 0.78691873, grad/param norm = 3.3228e-01, time/batch = 18.5311s	
6641/11350 (epoch 29.256), train_loss = 0.78142531, grad/param norm = 3.2695e-01, time/batch = 17.3494s	
6642/11350 (epoch 29.260), train_loss = 0.71402339, grad/param norm = 2.8721e-01, time/batch = 20.0278s	
6643/11350 (epoch 29.264), train_loss = 0.69619118, grad/param norm = 3.1590e-01, time/batch = 19.5020s	
6644/11350 (epoch 29.269), train_loss = 0.74558785, grad/param norm = 2.8165e-01, time/batch = 18.1132s	
6645/11350 (epoch 29.273), train_loss = 0.85913580, grad/param norm = 3.0194e-01, time/batch = 16.6408s	
6646/11350 (epoch 29.278), train_loss = 0.70262498, grad/param norm = 2.6947e-01, time/batch = 17.9584s	
6647/11350 (epoch 29.282), train_loss = 0.75716657, grad/param norm = 3.2288e-01, time/batch = 19.2816s	
6648/11350 (epoch 29.286), train_loss = 0.84741423, grad/param norm = 3.4513e-01, time/batch = 19.8675s	
6649/11350 (epoch 29.291), train_loss = 0.68004252, grad/param norm = 2.9800e-01, time/batch = 18.2961s	
6650/11350 (epoch 29.295), train_loss = 0.77872947, grad/param norm = 3.3700e-01, time/batch = 18.7862s	
6651/11350 (epoch 29.300), train_loss = 0.82353538, grad/param norm = 3.2266e-01, time/batch = 19.8758s	
6652/11350 (epoch 29.304), train_loss = 0.69131288, grad/param norm = 2.7528e-01, time/batch = 18.7898s	
6653/11350 (epoch 29.308), train_loss = 0.70312526, grad/param norm = 3.7904e-01, time/batch = 18.9492s	
6654/11350 (epoch 29.313), train_loss = 0.78772384, grad/param norm = 2.9174e-01, time/batch = 16.8600s	
6655/11350 (epoch 29.317), train_loss = 0.71239001, grad/param norm = 2.6994e-01, time/batch = 18.7771s	
6656/11350 (epoch 29.322), train_loss = 0.72319308, grad/param norm = 2.8619e-01, time/batch = 20.1176s	
6657/11350 (epoch 29.326), train_loss = 0.75659612, grad/param norm = 2.8553e-01, time/batch = 17.7827s	
6658/11350 (epoch 29.330), train_loss = 0.60781979, grad/param norm = 2.2945e-01, time/batch = 19.7855s	
6659/11350 (epoch 29.335), train_loss = 0.50646118, grad/param norm = 2.4695e-01, time/batch = 19.1623s	
6660/11350 (epoch 29.339), train_loss = 0.57780633, grad/param norm = 2.4586e-01, time/batch = 17.9607s	
6661/11350 (epoch 29.344), train_loss = 0.68135491, grad/param norm = 2.5028e-01, time/batch = 19.1359s	
6662/11350 (epoch 29.348), train_loss = 0.68619234, grad/param norm = 2.8769e-01, time/batch = 18.0388s	
6663/11350 (epoch 29.352), train_loss = 0.58672831, grad/param norm = 2.3698e-01, time/batch = 17.9566s	
6664/11350 (epoch 29.357), train_loss = 0.69995441, grad/param norm = 2.6042e-01, time/batch = 19.5508s	
6665/11350 (epoch 29.361), train_loss = 0.56603490, grad/param norm = 2.3740e-01, time/batch = 17.6344s	
6666/11350 (epoch 29.366), train_loss = 0.73000671, grad/param norm = 3.1025e-01, time/batch = 18.3546s	
6667/11350 (epoch 29.370), train_loss = 0.64538872, grad/param norm = 3.6129e-01, time/batch = 18.4425s	
6668/11350 (epoch 29.374), train_loss = 0.68705964, grad/param norm = 3.4247e-01, time/batch = 18.5235s	
6669/11350 (epoch 29.379), train_loss = 0.65507018, grad/param norm = 2.5896e-01, time/batch = 19.7816s	
6670/11350 (epoch 29.383), train_loss = 0.61103666, grad/param norm = 2.7529e-01, time/batch = 17.8749s	
6671/11350 (epoch 29.388), train_loss = 0.72083852, grad/param norm = 3.5407e-01, time/batch = 18.7638s	
6672/11350 (epoch 29.392), train_loss = 0.75491417, grad/param norm = 3.2090e-01, time/batch = 18.6368s	
6673/11350 (epoch 29.396), train_loss = 0.71507100, grad/param norm = 3.5482e-01, time/batch = 17.2845s	
6674/11350 (epoch 29.401), train_loss = 0.71470651, grad/param norm = 3.4717e-01, time/batch = 18.0274s	
6675/11350 (epoch 29.405), train_loss = 0.90119036, grad/param norm = 3.0854e-01, time/batch = 17.2625s	
6676/11350 (epoch 29.410), train_loss = 0.91247448, grad/param norm = 3.9584e-01, time/batch = 19.8631s	
6677/11350 (epoch 29.414), train_loss = 0.66059269, grad/param norm = 3.8982e-01, time/batch = 18.6328s	
6678/11350 (epoch 29.419), train_loss = 0.65285833, grad/param norm = 3.2896e-01, time/batch = 17.7128s	
6679/11350 (epoch 29.423), train_loss = 0.71939434, grad/param norm = 4.2309e-01, time/batch = 18.4745s	
6680/11350 (epoch 29.427), train_loss = 0.81932453, grad/param norm = 3.6058e-01, time/batch = 19.4619s	
6681/11350 (epoch 29.432), train_loss = 0.76120007, grad/param norm = 3.4948e-01, time/batch = 18.3556s	
6682/11350 (epoch 29.436), train_loss = 0.71168397, grad/param norm = 3.4048e-01, time/batch = 19.5388s	
6683/11350 (epoch 29.441), train_loss = 0.86725341, grad/param norm = 3.4460e-01, time/batch = 18.3680s	
6684/11350 (epoch 29.445), train_loss = 0.65505675, grad/param norm = 2.8361e-01, time/batch = 18.5905s	
6685/11350 (epoch 29.449), train_loss = 0.74150827, grad/param norm = 2.9926e-01, time/batch = 19.1077s	
6686/11350 (epoch 29.454), train_loss = 0.87484071, grad/param norm = 3.8819e-01, time/batch = 18.6046s	
6687/11350 (epoch 29.458), train_loss = 0.62477099, grad/param norm = 3.3394e-01, time/batch = 19.8589s	
6688/11350 (epoch 29.463), train_loss = 0.64486377, grad/param norm = 3.6512e-01, time/batch = 19.6052s	
6689/11350 (epoch 29.467), train_loss = 0.98950771, grad/param norm = 3.3558e-01, time/batch = 18.0392s	
6690/11350 (epoch 29.471), train_loss = 0.88098526, grad/param norm = 3.6655e-01, time/batch = 20.0517s	
6691/11350 (epoch 29.476), train_loss = 0.78374471, grad/param norm = 3.0745e-01, time/batch = 19.0066s	
6692/11350 (epoch 29.480), train_loss = 0.86933536, grad/param norm = 3.2421e-01, time/batch = 16.6700s	
6693/11350 (epoch 29.485), train_loss = 0.75922696, grad/param norm = 2.8690e-01, time/batch = 19.1315s	
6694/11350 (epoch 29.489), train_loss = 0.86410158, grad/param norm = 3.5220e-01, time/batch = 17.9526s	
6695/11350 (epoch 29.493), train_loss = 0.86819112, grad/param norm = 3.0343e-01, time/batch = 20.5310s	
6696/11350 (epoch 29.498), train_loss = 0.57909001, grad/param norm = 3.0490e-01, time/batch = 18.5308s	
6697/11350 (epoch 29.502), train_loss = 0.85259878, grad/param norm = 3.0496e-01, time/batch = 18.9486s	
6698/11350 (epoch 29.507), train_loss = 0.66739226, grad/param norm = 2.8874e-01, time/batch = 19.9589s	
6699/11350 (epoch 29.511), train_loss = 0.86014905, grad/param norm = 3.0900e-01, time/batch = 19.1768s	
6700/11350 (epoch 29.515), train_loss = 0.76906302, grad/param norm = 3.5192e-01, time/batch = 18.6169s	
6701/11350 (epoch 29.520), train_loss = 0.92613453, grad/param norm = 3.3691e-01, time/batch = 19.2811s	
6702/11350 (epoch 29.524), train_loss = 0.79661659, grad/param norm = 3.1160e-01, time/batch = 20.4540s	
6703/11350 (epoch 29.529), train_loss = 0.74977462, grad/param norm = 3.2048e-01, time/batch = 18.6086s	
6704/11350 (epoch 29.533), train_loss = 0.91411211, grad/param norm = 3.1647e-01, time/batch = 18.5441s	
6705/11350 (epoch 29.537), train_loss = 0.86856210, grad/param norm = 3.7898e-01, time/batch = 18.2914s	
6706/11350 (epoch 29.542), train_loss = 0.81539912, grad/param norm = 3.0425e-01, time/batch = 18.3645s	
6707/11350 (epoch 29.546), train_loss = 0.99077836, grad/param norm = 4.0066e-01, time/batch = 18.3569s	
6708/11350 (epoch 29.551), train_loss = 0.82107539, grad/param norm = 3.4950e-01, time/batch = 17.6892s	
6709/11350 (epoch 29.555), train_loss = 0.71972232, grad/param norm = 2.6378e-01, time/batch = 19.6244s	
6710/11350 (epoch 29.559), train_loss = 0.74845992, grad/param norm = 2.9055e-01, time/batch = 18.8488s	
6711/11350 (epoch 29.564), train_loss = 0.82657561, grad/param norm = 3.4045e-01, time/batch = 16.8740s	
6712/11350 (epoch 29.568), train_loss = 0.85762476, grad/param norm = 3.1468e-01, time/batch = 19.3819s	
6713/11350 (epoch 29.573), train_loss = 0.95063748, grad/param norm = 4.2530e-01, time/batch = 16.2962s	
6714/11350 (epoch 29.577), train_loss = 0.90177817, grad/param norm = 4.9389e-01, time/batch = 18.8121s	
6715/11350 (epoch 29.581), train_loss = 0.91469479, grad/param norm = 3.5225e-01, time/batch = 18.4406s	
6716/11350 (epoch 29.586), train_loss = 0.90168504, grad/param norm = 3.6350e-01, time/batch = 15.5422s	
6717/11350 (epoch 29.590), train_loss = 0.97579757, grad/param norm = 5.1455e-01, time/batch = 18.2726s	
6718/11350 (epoch 29.595), train_loss = 1.02165243, grad/param norm = 3.8697e-01, time/batch = 18.4597s	
6719/11350 (epoch 29.599), train_loss = 0.85045376, grad/param norm = 3.0074e-01, time/batch = 19.1267s	
6720/11350 (epoch 29.604), train_loss = 0.82144529, grad/param norm = 3.3607e-01, time/batch = 19.3579s	
6721/11350 (epoch 29.608), train_loss = 0.79124015, grad/param norm = 3.3818e-01, time/batch = 18.0392s	
6722/11350 (epoch 29.612), train_loss = 0.80118809, grad/param norm = 2.8993e-01, time/batch = 19.1991s	
6723/11350 (epoch 29.617), train_loss = 0.88284443, grad/param norm = 3.1196e-01, time/batch = 18.9368s	
6724/11350 (epoch 29.621), train_loss = 0.91594382, grad/param norm = 3.2099e-01, time/batch = 18.5427s	
6725/11350 (epoch 29.626), train_loss = 0.82245915, grad/param norm = 3.2633e-01, time/batch = 16.3445s	
6726/11350 (epoch 29.630), train_loss = 0.86293306, grad/param norm = 4.1538e-01, time/batch = 19.0296s	
6727/11350 (epoch 29.634), train_loss = 0.83024250, grad/param norm = 3.7130e-01, time/batch = 18.7154s	
6728/11350 (epoch 29.639), train_loss = 0.74801902, grad/param norm = 2.9939e-01, time/batch = 17.6224s	
6729/11350 (epoch 29.643), train_loss = 0.69354878, grad/param norm = 2.7391e-01, time/batch = 18.6033s	
6730/11350 (epoch 29.648), train_loss = 0.80055543, grad/param norm = 3.1510e-01, time/batch = 19.6069s	
6731/11350 (epoch 29.652), train_loss = 0.72029000, grad/param norm = 3.1707e-01, time/batch = 19.3776s	
6732/11350 (epoch 29.656), train_loss = 0.83448349, grad/param norm = 3.0692e-01, time/batch = 19.0210s	
6733/11350 (epoch 29.661), train_loss = 0.89894840, grad/param norm = 3.5062e-01, time/batch = 18.3392s	
6734/11350 (epoch 29.665), train_loss = 0.85332202, grad/param norm = 3.7801e-01, time/batch = 18.2922s	
6735/11350 (epoch 29.670), train_loss = 0.83465958, grad/param norm = 3.4112e-01, time/batch = 19.7723s	
6736/11350 (epoch 29.674), train_loss = 0.76872264, grad/param norm = 2.8965e-01, time/batch = 18.3451s	
6737/11350 (epoch 29.678), train_loss = 0.82352283, grad/param norm = 2.8226e-01, time/batch = 18.2793s	
6738/11350 (epoch 29.683), train_loss = 0.74663430, grad/param norm = 3.7919e-01, time/batch = 18.0199s	
6739/11350 (epoch 29.687), train_loss = 0.72818304, grad/param norm = 4.1044e-01, time/batch = 16.7477s	
6740/11350 (epoch 29.692), train_loss = 1.05582299, grad/param norm = 3.6120e-01, time/batch = 19.5118s	
6741/11350 (epoch 29.696), train_loss = 0.97935636, grad/param norm = 3.5853e-01, time/batch = 19.7807s	
6742/11350 (epoch 29.700), train_loss = 0.91335804, grad/param norm = 3.6511e-01, time/batch = 17.9483s	
6743/11350 (epoch 29.705), train_loss = 0.97720822, grad/param norm = 4.1540e-01, time/batch = 20.6723s	
6744/11350 (epoch 29.709), train_loss = 0.96273239, grad/param norm = 3.9262e-01, time/batch = 18.5375s	
6745/11350 (epoch 29.714), train_loss = 0.84741760, grad/param norm = 3.2157e-01, time/batch = 18.8773s	
6746/11350 (epoch 29.718), train_loss = 0.71687879, grad/param norm = 2.8647e-01, time/batch = 20.3547s	
6747/11350 (epoch 29.722), train_loss = 0.86901631, grad/param norm = 4.8784e-01, time/batch = 15.1580s	
6748/11350 (epoch 29.727), train_loss = 0.84938231, grad/param norm = 3.4186e-01, time/batch = 19.0240s	
6749/11350 (epoch 29.731), train_loss = 0.83887190, grad/param norm = 3.2430e-01, time/batch = 19.3570s	
6750/11350 (epoch 29.736), train_loss = 0.77405537, grad/param norm = 4.0311e-01, time/batch = 19.2821s	
6751/11350 (epoch 29.740), train_loss = 0.82677503, grad/param norm = 3.4600e-01, time/batch = 19.5407s	
6752/11350 (epoch 29.744), train_loss = 0.83319613, grad/param norm = 3.7602e-01, time/batch = 18.8711s	
6753/11350 (epoch 29.749), train_loss = 0.84085101, grad/param norm = 3.4572e-01, time/batch = 18.1314s	
6754/11350 (epoch 29.753), train_loss = 0.89238735, grad/param norm = 3.7178e-01, time/batch = 19.4491s	
6755/11350 (epoch 29.758), train_loss = 0.80400512, grad/param norm = 3.3690e-01, time/batch = 18.3480s	
6756/11350 (epoch 29.762), train_loss = 0.93980990, grad/param norm = 3.2586e-01, time/batch = 18.8423s	
6757/11350 (epoch 29.767), train_loss = 0.92146220, grad/param norm = 3.2588e-01, time/batch = 16.2821s	
6758/11350 (epoch 29.771), train_loss = 1.03085073, grad/param norm = 3.2795e-01, time/batch = 17.9411s	
6759/11350 (epoch 29.775), train_loss = 0.83351794, grad/param norm = 3.3273e-01, time/batch = 18.8665s	
6760/11350 (epoch 29.780), train_loss = 0.90760447, grad/param norm = 3.1095e-01, time/batch = 18.7052s	
6761/11350 (epoch 29.784), train_loss = 0.81561014, grad/param norm = 3.6555e-01, time/batch = 18.4480s	
6762/11350 (epoch 29.789), train_loss = 0.83845287, grad/param norm = 3.2151e-01, time/batch = 20.6124s	
6763/11350 (epoch 29.793), train_loss = 0.97228554, grad/param norm = 4.2356e-01, time/batch = 19.0471s	
6764/11350 (epoch 29.797), train_loss = 0.84943794, grad/param norm = 3.0424e-01, time/batch = 19.2921s	
6765/11350 (epoch 29.802), train_loss = 0.87134875, grad/param norm = 2.9873e-01, time/batch = 17.0310s	
6766/11350 (epoch 29.806), train_loss = 0.90147903, grad/param norm = 2.9324e-01, time/batch = 18.5367s	
6767/11350 (epoch 29.811), train_loss = 0.85455584, grad/param norm = 2.9351e-01, time/batch = 18.7161s	
6768/11350 (epoch 29.815), train_loss = 0.80993070, grad/param norm = 3.0147e-01, time/batch = 19.0284s	
6769/11350 (epoch 29.819), train_loss = 0.74952725, grad/param norm = 3.1170e-01, time/batch = 17.7008s	
6770/11350 (epoch 29.824), train_loss = 0.73288993, grad/param norm = 3.2371e-01, time/batch = 18.3821s	
6771/11350 (epoch 29.828), train_loss = 0.78416741, grad/param norm = 3.2134e-01, time/batch = 32.3475s	
6772/11350 (epoch 29.833), train_loss = 0.81074132, grad/param norm = 3.1131e-01, time/batch = 18.2265s	
6773/11350 (epoch 29.837), train_loss = 0.84024524, grad/param norm = 3.1861e-01, time/batch = 19.5301s	
6774/11350 (epoch 29.841), train_loss = 1.08889178, grad/param norm = 3.7492e-01, time/batch = 20.3640s	
6775/11350 (epoch 29.846), train_loss = 0.87178724, grad/param norm = 3.0894e-01, time/batch = 17.7034s	
6776/11350 (epoch 29.850), train_loss = 0.92086595, grad/param norm = 4.0361e-01, time/batch = 17.3696s	
6777/11350 (epoch 29.855), train_loss = 0.72235502, grad/param norm = 3.1554e-01, time/batch = 19.6169s	
6778/11350 (epoch 29.859), train_loss = 0.78051398, grad/param norm = 3.5373e-01, time/batch = 18.3624s	
6779/11350 (epoch 29.863), train_loss = 0.72317791, grad/param norm = 2.8882e-01, time/batch = 20.2945s	
6780/11350 (epoch 29.868), train_loss = 0.73755107, grad/param norm = 3.1079e-01, time/batch = 16.4228s	
6781/11350 (epoch 29.872), train_loss = 0.76702932, grad/param norm = 2.8594e-01, time/batch = 20.5181s	
6782/11350 (epoch 29.877), train_loss = 0.79969166, grad/param norm = 3.7594e-01, time/batch = 19.6116s	
6783/11350 (epoch 29.881), train_loss = 0.99316058, grad/param norm = 4.1166e-01, time/batch = 18.1160s	
6784/11350 (epoch 29.885), train_loss = 0.93508039, grad/param norm = 3.1565e-01, time/batch = 17.7796s	
6785/11350 (epoch 29.890), train_loss = 0.84081187, grad/param norm = 3.2097e-01, time/batch = 19.2761s	
6786/11350 (epoch 29.894), train_loss = 0.69699997, grad/param norm = 2.9047e-01, time/batch = 18.1201s	
6787/11350 (epoch 29.899), train_loss = 0.88672991, grad/param norm = 3.6919e-01, time/batch = 18.9577s	
6788/11350 (epoch 29.903), train_loss = 0.87853282, grad/param norm = 3.6821e-01, time/batch = 18.4632s	
6789/11350 (epoch 29.907), train_loss = 0.78731431, grad/param norm = 2.9438e-01, time/batch = 18.9386s	
6790/11350 (epoch 29.912), train_loss = 0.75315945, grad/param norm = 2.9069e-01, time/batch = 18.4536s	
6791/11350 (epoch 29.916), train_loss = 0.86618984, grad/param norm = 3.5225e-01, time/batch = 19.8840s	
6792/11350 (epoch 29.921), train_loss = 0.86637441, grad/param norm = 3.0835e-01, time/batch = 19.2787s	
6793/11350 (epoch 29.925), train_loss = 0.71663096, grad/param norm = 2.7274e-01, time/batch = 19.6885s	
6794/11350 (epoch 29.930), train_loss = 0.87193338, grad/param norm = 3.7171e-01, time/batch = 19.7848s	
6795/11350 (epoch 29.934), train_loss = 0.97307303, grad/param norm = 3.2774e-01, time/batch = 19.6929s	
6796/11350 (epoch 29.938), train_loss = 0.82304530, grad/param norm = 3.2094e-01, time/batch = 18.9552s	
6797/11350 (epoch 29.943), train_loss = 0.90248219, grad/param norm = 3.0470e-01, time/batch = 18.6330s	
6798/11350 (epoch 29.947), train_loss = 0.85582734, grad/param norm = 3.2006e-01, time/batch = 18.2643s	
6799/11350 (epoch 29.952), train_loss = 0.89244975, grad/param norm = 3.8077e-01, time/batch = 17.1779s	
6800/11350 (epoch 29.956), train_loss = 0.68056590, grad/param norm = 2.4807e-01, time/batch = 17.9429s	
6801/11350 (epoch 29.960), train_loss = 0.78303205, grad/param norm = 3.6697e-01, time/batch = 20.6949s	
6802/11350 (epoch 29.965), train_loss = 0.72815172, grad/param norm = 3.1517e-01, time/batch = 18.9316s	
6803/11350 (epoch 29.969), train_loss = 0.73491666, grad/param norm = 3.8262e-01, time/batch = 19.3778s	
6804/11350 (epoch 29.974), train_loss = 0.72785013, grad/param norm = 3.5988e-01, time/batch = 18.0473s	
6805/11350 (epoch 29.978), train_loss = 0.82045422, grad/param norm = 3.2549e-01, time/batch = 18.9583s	
6806/11350 (epoch 29.982), train_loss = 0.55747150, grad/param norm = 2.5634e-01, time/batch = 19.5237s	
6807/11350 (epoch 29.987), train_loss = 0.81859853, grad/param norm = 3.6118e-01, time/batch = 17.2921s	
6808/11350 (epoch 29.991), train_loss = 0.72341109, grad/param norm = 4.0317e-01, time/batch = 18.9413s	
6809/11350 (epoch 29.996), train_loss = 0.82832586, grad/param norm = 3.6673e-01, time/batch = 19.0483s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
6810/11350 (epoch 30.000), train_loss = 0.63996752, grad/param norm = 3.3830e-01, time/batch = 19.2939s	
6811/11350 (epoch 30.004), train_loss = 0.86078162, grad/param norm = 3.5267e-01, time/batch = 18.7633s	
6812/11350 (epoch 30.009), train_loss = 0.82984859, grad/param norm = 3.6140e-01, time/batch = 18.8618s	
6813/11350 (epoch 30.013), train_loss = 0.58669515, grad/param norm = 2.9982e-01, time/batch = 17.1064s	
6814/11350 (epoch 30.018), train_loss = 0.65532026, grad/param norm = 3.2021e-01, time/batch = 18.7825s	
6815/11350 (epoch 30.022), train_loss = 0.65833111, grad/param norm = 3.3950e-01, time/batch = 15.7281s	
6816/11350 (epoch 30.026), train_loss = 0.63877057, grad/param norm = 3.6974e-01, time/batch = 18.7606s	
6817/11350 (epoch 30.031), train_loss = 0.68608935, grad/param norm = 2.9460e-01, time/batch = 19.5461s	
6818/11350 (epoch 30.035), train_loss = 0.70303627, grad/param norm = 3.4206e-01, time/batch = 16.6180s	
6819/11350 (epoch 30.040), train_loss = 0.70575667, grad/param norm = 2.9177e-01, time/batch = 18.5300s	
6820/11350 (epoch 30.044), train_loss = 0.66198838, grad/param norm = 2.7126e-01, time/batch = 16.4889s	
6821/11350 (epoch 30.048), train_loss = 0.63912766, grad/param norm = 2.6031e-01, time/batch = 17.9563s	
6822/11350 (epoch 30.053), train_loss = 0.72395484, grad/param norm = 3.2058e-01, time/batch = 17.6486s	
6823/11350 (epoch 30.057), train_loss = 0.73139467, grad/param norm = 3.4312e-01, time/batch = 19.3052s	
6824/11350 (epoch 30.062), train_loss = 0.59397696, grad/param norm = 2.5686e-01, time/batch = 18.9542s	
6825/11350 (epoch 30.066), train_loss = 0.61093714, grad/param norm = 3.0093e-01, time/batch = 18.2938s	
6826/11350 (epoch 30.070), train_loss = 0.68713638, grad/param norm = 3.0448e-01, time/batch = 19.6311s	
6827/11350 (epoch 30.075), train_loss = 0.61823078, grad/param norm = 2.6594e-01, time/batch = 18.9669s	
6828/11350 (epoch 30.079), train_loss = 0.74834498, grad/param norm = 2.9464e-01, time/batch = 17.2184s	
6829/11350 (epoch 30.084), train_loss = 0.87538823, grad/param norm = 3.6589e-01, time/batch = 18.2266s	
6830/11350 (epoch 30.088), train_loss = 0.79295067, grad/param norm = 3.4211e-01, time/batch = 17.5144s	
6831/11350 (epoch 30.093), train_loss = 0.79573706, grad/param norm = 3.3113e-01, time/batch = 17.4392s	
6832/11350 (epoch 30.097), train_loss = 0.74660655, grad/param norm = 3.1603e-01, time/batch = 18.8872s	
6833/11350 (epoch 30.101), train_loss = 0.67801709, grad/param norm = 3.3299e-01, time/batch = 16.9542s	
6834/11350 (epoch 30.106), train_loss = 0.77528215, grad/param norm = 3.3694e-01, time/batch = 17.7816s	
6835/11350 (epoch 30.110), train_loss = 0.68521201, grad/param norm = 3.0533e-01, time/batch = 17.8743s	
6836/11350 (epoch 30.115), train_loss = 0.71712705, grad/param norm = 3.6671e-01, time/batch = 18.4757s	
6837/11350 (epoch 30.119), train_loss = 0.83204944, grad/param norm = 4.0359e-01, time/batch = 18.8905s	
6838/11350 (epoch 30.123), train_loss = 0.67204472, grad/param norm = 3.0468e-01, time/batch = 17.5901s	
6839/11350 (epoch 30.128), train_loss = 0.60889163, grad/param norm = 3.5511e-01, time/batch = 18.8881s	
6840/11350 (epoch 30.132), train_loss = 0.65381167, grad/param norm = 2.6617e-01, time/batch = 19.7107s	
6841/11350 (epoch 30.137), train_loss = 0.64406356, grad/param norm = 3.0751e-01, time/batch = 18.7783s	
6842/11350 (epoch 30.141), train_loss = 0.85470143, grad/param norm = 3.8512e-01, time/batch = 20.0464s	
6843/11350 (epoch 30.145), train_loss = 0.67508313, grad/param norm = 3.4698e-01, time/batch = 16.9596s	
6844/11350 (epoch 30.150), train_loss = 0.77089836, grad/param norm = 4.3235e-01, time/batch = 16.4576s	
6845/11350 (epoch 30.154), train_loss = 0.84393132, grad/param norm = 3.1477e-01, time/batch = 18.8812s	
6846/11350 (epoch 30.159), train_loss = 0.62160849, grad/param norm = 2.6573e-01, time/batch = 18.7735s	
6847/11350 (epoch 30.163), train_loss = 0.78503471, grad/param norm = 3.4265e-01, time/batch = 18.2914s	
6848/11350 (epoch 30.167), train_loss = 0.85028810, grad/param norm = 3.1558e-01, time/batch = 19.8827s	
6849/11350 (epoch 30.172), train_loss = 0.91254619, grad/param norm = 3.0084e-01, time/batch = 17.7872s	
6850/11350 (epoch 30.176), train_loss = 0.72642227, grad/param norm = 2.9620e-01, time/batch = 16.0869s	
6851/11350 (epoch 30.181), train_loss = 0.76903997, grad/param norm = 3.3924e-01, time/batch = 17.2652s	
6852/11350 (epoch 30.185), train_loss = 0.67099016, grad/param norm = 3.0860e-01, time/batch = 19.4653s	
6853/11350 (epoch 30.189), train_loss = 0.72578631, grad/param norm = 3.1185e-01, time/batch = 18.6220s	
6854/11350 (epoch 30.194), train_loss = 0.66887124, grad/param norm = 3.5845e-01, time/batch = 17.1212s	
6855/11350 (epoch 30.198), train_loss = 0.62093466, grad/param norm = 3.2088e-01, time/batch = 19.7754s	
6856/11350 (epoch 30.203), train_loss = 0.65496913, grad/param norm = 2.8984e-01, time/batch = 17.4655s	
6857/11350 (epoch 30.207), train_loss = 0.60738826, grad/param norm = 3.5222e-01, time/batch = 17.8816s	
6858/11350 (epoch 30.211), train_loss = 0.83350587, grad/param norm = 4.4708e-01, time/batch = 18.7069s	
6859/11350 (epoch 30.216), train_loss = 0.78954302, grad/param norm = 3.1482e-01, time/batch = 19.0283s	
6860/11350 (epoch 30.220), train_loss = 0.77836069, grad/param norm = 3.3040e-01, time/batch = 19.2819s	
6861/11350 (epoch 30.225), train_loss = 0.67645109, grad/param norm = 2.6975e-01, time/batch = 19.7843s	
6862/11350 (epoch 30.229), train_loss = 0.77303959, grad/param norm = 3.2027e-01, time/batch = 18.3854s	
6863/11350 (epoch 30.233), train_loss = 0.72653764, grad/param norm = 3.0444e-01, time/batch = 19.9443s	
6864/11350 (epoch 30.238), train_loss = 0.84958564, grad/param norm = 3.8709e-01, time/batch = 17.8055s	
6865/11350 (epoch 30.242), train_loss = 0.85694726, grad/param norm = 3.6818e-01, time/batch = 18.2035s	
6866/11350 (epoch 30.247), train_loss = 0.63722487, grad/param norm = 2.7802e-01, time/batch = 20.2124s	
6867/11350 (epoch 30.251), train_loss = 0.76058268, grad/param norm = 3.1175e-01, time/batch = 17.2753s	
6868/11350 (epoch 30.256), train_loss = 0.75007414, grad/param norm = 2.7991e-01, time/batch = 19.5253s	
6869/11350 (epoch 30.260), train_loss = 0.69237643, grad/param norm = 2.8729e-01, time/batch = 17.1692s	
6870/11350 (epoch 30.264), train_loss = 0.67958529, grad/param norm = 3.2115e-01, time/batch = 18.9410s	
6871/11350 (epoch 30.269), train_loss = 0.72654742, grad/param norm = 2.8041e-01, time/batch = 18.6874s	
6872/11350 (epoch 30.273), train_loss = 0.84152948, grad/param norm = 3.0745e-01, time/batch = 19.8621s	
6873/11350 (epoch 30.278), train_loss = 0.71154159, grad/param norm = 3.5714e-01, time/batch = 19.0318s	
6874/11350 (epoch 30.282), train_loss = 0.71122463, grad/param norm = 3.0516e-01, time/batch = 20.0445s	
6875/11350 (epoch 30.286), train_loss = 0.81362012, grad/param norm = 3.3677e-01, time/batch = 18.7166s	
6876/11350 (epoch 30.291), train_loss = 0.66688323, grad/param norm = 3.1623e-01, time/batch = 19.1999s	
6877/11350 (epoch 30.295), train_loss = 0.74419415, grad/param norm = 3.3672e-01, time/batch = 19.0365s	
6878/11350 (epoch 30.300), train_loss = 0.81108730, grad/param norm = 3.3882e-01, time/batch = 18.8724s	
6879/11350 (epoch 30.304), train_loss = 0.67525310, grad/param norm = 3.2494e-01, time/batch = 18.0105s	
6880/11350 (epoch 30.308), train_loss = 0.65494732, grad/param norm = 3.2659e-01, time/batch = 18.9301s	
6881/11350 (epoch 30.313), train_loss = 0.75427937, grad/param norm = 3.1018e-01, time/batch = 17.0388s	
6882/11350 (epoch 30.317), train_loss = 0.71337301, grad/param norm = 3.0193e-01, time/batch = 20.0300s	
6883/11350 (epoch 30.322), train_loss = 0.70624325, grad/param norm = 2.9848e-01, time/batch = 17.7098s	
6884/11350 (epoch 30.326), train_loss = 0.72425630, grad/param norm = 2.7691e-01, time/batch = 19.6990s	
6885/11350 (epoch 30.330), train_loss = 0.60994033, grad/param norm = 2.6093e-01, time/batch = 19.9460s	
6886/11350 (epoch 30.335), train_loss = 0.49008087, grad/param norm = 2.4463e-01, time/batch = 19.3645s	
6887/11350 (epoch 30.339), train_loss = 0.56120715, grad/param norm = 2.6378e-01, time/batch = 18.6301s	
6888/11350 (epoch 30.344), train_loss = 0.66307112, grad/param norm = 2.6805e-01, time/batch = 17.4403s	
6889/11350 (epoch 30.348), train_loss = 0.65725370, grad/param norm = 2.6689e-01, time/batch = 17.7596s	
6890/11350 (epoch 30.352), train_loss = 0.57018266, grad/param norm = 2.7644e-01, time/batch = 20.0309s	
6891/11350 (epoch 30.357), train_loss = 0.68367432, grad/param norm = 2.7270e-01, time/batch = 20.0955s	
6892/11350 (epoch 30.361), train_loss = 0.54416307, grad/param norm = 2.2470e-01, time/batch = 17.9444s	
6893/11350 (epoch 30.366), train_loss = 0.72922873, grad/param norm = 4.1028e-01, time/batch = 19.6094s	
6894/11350 (epoch 30.370), train_loss = 0.62319197, grad/param norm = 3.4999e-01, time/batch = 20.2930s	
6895/11350 (epoch 30.374), train_loss = 0.65486083, grad/param norm = 2.7761e-01, time/batch = 17.9309s	
6896/11350 (epoch 30.379), train_loss = 0.64650807, grad/param norm = 3.1398e-01, time/batch = 19.6198s	
6897/11350 (epoch 30.383), train_loss = 0.59823088, grad/param norm = 2.7010e-01, time/batch = 18.5978s	
6898/11350 (epoch 30.388), train_loss = 0.68642013, grad/param norm = 3.3949e-01, time/batch = 18.0339s	
6899/11350 (epoch 30.392), train_loss = 0.74920628, grad/param norm = 3.2761e-01, time/batch = 2.6403s	
6900/11350 (epoch 30.396), train_loss = 0.68854467, grad/param norm = 3.2761e-01, time/batch = 0.6899s	
6901/11350 (epoch 30.401), train_loss = 0.68509714, grad/param norm = 3.1649e-01, time/batch = 0.7351s	
6902/11350 (epoch 30.405), train_loss = 0.86828230, grad/param norm = 3.2513e-01, time/batch = 0.7097s	
6903/11350 (epoch 30.410), train_loss = 0.89400395, grad/param norm = 3.8537e-01, time/batch = 0.7027s	
6904/11350 (epoch 30.414), train_loss = 0.65178009, grad/param norm = 3.5251e-01, time/batch = 0.6849s	
6905/11350 (epoch 30.419), train_loss = 0.62887986, grad/param norm = 3.2338e-01, time/batch = 0.6882s	
6906/11350 (epoch 30.423), train_loss = 0.70664572, grad/param norm = 3.3340e-01, time/batch = 0.9382s	
6907/11350 (epoch 30.427), train_loss = 0.79290876, grad/param norm = 3.8923e-01, time/batch = 1.0037s	
6908/11350 (epoch 30.432), train_loss = 0.73863318, grad/param norm = 3.3226e-01, time/batch = 1.0142s	
6909/11350 (epoch 30.436), train_loss = 0.68232531, grad/param norm = 3.4669e-01, time/batch = 1.0020s	
6910/11350 (epoch 30.441), train_loss = 0.83431826, grad/param norm = 3.4233e-01, time/batch = 1.0011s	
6911/11350 (epoch 30.445), train_loss = 0.62509376, grad/param norm = 2.5938e-01, time/batch = 1.7628s	
6912/11350 (epoch 30.449), train_loss = 0.72919925, grad/param norm = 3.0836e-01, time/batch = 1.9284s	
6913/11350 (epoch 30.454), train_loss = 0.87103444, grad/param norm = 3.9320e-01, time/batch = 6.1505s	
6914/11350 (epoch 30.458), train_loss = 0.60021116, grad/param norm = 2.9149e-01, time/batch = 18.7032s	
6915/11350 (epoch 30.463), train_loss = 0.61571944, grad/param norm = 3.0614e-01, time/batch = 18.7838s	
6916/11350 (epoch 30.467), train_loss = 0.95562810, grad/param norm = 3.7650e-01, time/batch = 20.6909s	
6917/11350 (epoch 30.471), train_loss = 0.85412155, grad/param norm = 3.9553e-01, time/batch = 18.6258s	
6918/11350 (epoch 30.476), train_loss = 0.76285454, grad/param norm = 3.1260e-01, time/batch = 18.1969s	
6919/11350 (epoch 30.480), train_loss = 0.84055706, grad/param norm = 3.0928e-01, time/batch = 20.2820s	
6920/11350 (epoch 30.485), train_loss = 0.74384860, grad/param norm = 3.1489e-01, time/batch = 18.6277s	
6921/11350 (epoch 30.489), train_loss = 0.84216687, grad/param norm = 3.3987e-01, time/batch = 20.0033s	
6922/11350 (epoch 30.493), train_loss = 0.84492515, grad/param norm = 3.0617e-01, time/batch = 17.1691s	
6923/11350 (epoch 30.498), train_loss = 0.56551071, grad/param norm = 3.0419e-01, time/batch = 20.0351s	
6924/11350 (epoch 30.502), train_loss = 0.83429018, grad/param norm = 3.0314e-01, time/batch = 19.6145s	
6925/11350 (epoch 30.507), train_loss = 0.64497574, grad/param norm = 2.8832e-01, time/batch = 17.5273s	
6926/11350 (epoch 30.511), train_loss = 0.82288609, grad/param norm = 3.0150e-01, time/batch = 19.2923s	
6927/11350 (epoch 30.515), train_loss = 0.73740467, grad/param norm = 3.0301e-01, time/batch = 20.2691s	
6928/11350 (epoch 30.520), train_loss = 0.89529511, grad/param norm = 3.5311e-01, time/batch = 17.0252s	
6929/11350 (epoch 30.524), train_loss = 0.77684391, grad/param norm = 3.1025e-01, time/batch = 19.9538s	
6930/11350 (epoch 30.529), train_loss = 0.74262468, grad/param norm = 3.2505e-01, time/batch = 18.7944s	
6931/11350 (epoch 30.533), train_loss = 0.90752919, grad/param norm = 3.5298e-01, time/batch = 16.0144s	
6932/11350 (epoch 30.537), train_loss = 0.85988750, grad/param norm = 3.2325e-01, time/batch = 19.0697s	
6933/11350 (epoch 30.542), train_loss = 0.78006664, grad/param norm = 2.8241e-01, time/batch = 18.8686s	
6934/11350 (epoch 30.546), train_loss = 0.97317717, grad/param norm = 3.8012e-01, time/batch = 19.5284s	
6935/11350 (epoch 30.551), train_loss = 0.80860309, grad/param norm = 3.3557e-01, time/batch = 19.3584s	
6936/11350 (epoch 30.555), train_loss = 0.68928846, grad/param norm = 3.0269e-01, time/batch = 19.1257s	
6937/11350 (epoch 30.559), train_loss = 0.74062401, grad/param norm = 2.8670e-01, time/batch = 19.6103s	
6938/11350 (epoch 30.564), train_loss = 0.81326056, grad/param norm = 3.6783e-01, time/batch = 18.2175s	
6939/11350 (epoch 30.568), train_loss = 0.83921512, grad/param norm = 3.3173e-01, time/batch = 19.2868s	
6940/11350 (epoch 30.573), train_loss = 0.92252474, grad/param norm = 4.2089e-01, time/batch = 19.4653s	
6941/11350 (epoch 30.577), train_loss = 0.89938481, grad/param norm = 5.4353e-01, time/batch = 16.8747s	
6942/11350 (epoch 30.581), train_loss = 0.90666749, grad/param norm = 3.3502e-01, time/batch = 18.3693s	
6943/11350 (epoch 30.586), train_loss = 0.89270824, grad/param norm = 3.6289e-01, time/batch = 18.3481s	
6944/11350 (epoch 30.590), train_loss = 0.98046570, grad/param norm = 4.4619e-01, time/batch = 17.5077s	
6945/11350 (epoch 30.595), train_loss = 1.00359308, grad/param norm = 3.6426e-01, time/batch = 20.1191s	
6946/11350 (epoch 30.599), train_loss = 0.86408099, grad/param norm = 3.8819e-01, time/batch = 17.2313s	
6947/11350 (epoch 30.604), train_loss = 0.80373458, grad/param norm = 3.5110e-01, time/batch = 18.2933s	
6948/11350 (epoch 30.608), train_loss = 0.76867344, grad/param norm = 3.6428e-01, time/batch = 19.9559s	
6949/11350 (epoch 30.612), train_loss = 0.79752772, grad/param norm = 3.1424e-01, time/batch = 17.8105s	
6950/11350 (epoch 30.617), train_loss = 0.86920400, grad/param norm = 3.6262e-01, time/batch = 19.0288s	
6951/11350 (epoch 30.621), train_loss = 0.89782517, grad/param norm = 3.1537e-01, time/batch = 19.0470s	
6952/11350 (epoch 30.626), train_loss = 0.80535096, grad/param norm = 3.2907e-01, time/batch = 19.2877s	
6953/11350 (epoch 30.630), train_loss = 0.82256408, grad/param norm = 7.9713e-01, time/batch = 17.0174s	
6954/11350 (epoch 30.634), train_loss = 0.84391322, grad/param norm = 4.3115e-01, time/batch = 19.1906s	
6955/11350 (epoch 30.639), train_loss = 0.76556037, grad/param norm = 4.0283e-01, time/batch = 19.8032s	
6956/11350 (epoch 30.643), train_loss = 0.70964395, grad/param norm = 3.3866e-01, time/batch = 19.1995s	
6957/11350 (epoch 30.648), train_loss = 0.78964676, grad/param norm = 3.4291e-01, time/batch = 17.6862s	
6958/11350 (epoch 30.652), train_loss = 0.70749260, grad/param norm = 3.2931e-01, time/batch = 18.7754s	
6959/11350 (epoch 30.656), train_loss = 0.83446733, grad/param norm = 3.1793e-01, time/batch = 18.5943s	
6960/11350 (epoch 30.661), train_loss = 0.87349073, grad/param norm = 3.3064e-01, time/batch = 18.0177s	
6961/11350 (epoch 30.665), train_loss = 0.84360446, grad/param norm = 3.5732e-01, time/batch = 17.7770s	
6962/11350 (epoch 30.670), train_loss = 0.80198339, grad/param norm = 3.0887e-01, time/batch = 17.9674s	
6963/11350 (epoch 30.674), train_loss = 0.76590404, grad/param norm = 3.0280e-01, time/batch = 18.1215s	
6964/11350 (epoch 30.678), train_loss = 0.80294383, grad/param norm = 3.0090e-01, time/batch = 18.7260s	
6965/11350 (epoch 30.683), train_loss = 0.73544901, grad/param norm = 3.2030e-01, time/batch = 19.0463s	
6966/11350 (epoch 30.687), train_loss = 0.71749579, grad/param norm = 3.7292e-01, time/batch = 16.5602s	
6967/11350 (epoch 30.692), train_loss = 1.05090727, grad/param norm = 5.2243e-01, time/batch = 15.4794s	
6968/11350 (epoch 30.696), train_loss = 0.98150775, grad/param norm = 3.4811e-01, time/batch = 18.9646s	
6969/11350 (epoch 30.700), train_loss = 0.90247165, grad/param norm = 3.8125e-01, time/batch = 19.2174s	
6970/11350 (epoch 30.705), train_loss = 0.92165174, grad/param norm = 3.2659e-01, time/batch = 17.6354s	
6971/11350 (epoch 30.709), train_loss = 0.92875622, grad/param norm = 3.5438e-01, time/batch = 18.9579s	
6972/11350 (epoch 30.714), train_loss = 0.82283003, grad/param norm = 3.4299e-01, time/batch = 16.7803s	
6973/11350 (epoch 30.718), train_loss = 0.70039796, grad/param norm = 2.9853e-01, time/batch = 17.6964s	
6974/11350 (epoch 30.722), train_loss = 0.82819264, grad/param norm = 3.8254e-01, time/batch = 18.3846s	
6975/11350 (epoch 30.727), train_loss = 0.80901365, grad/param norm = 3.1511e-01, time/batch = 17.7097s	
6976/11350 (epoch 30.731), train_loss = 0.81878505, grad/param norm = 3.2452e-01, time/batch = 20.3447s	
6977/11350 (epoch 30.736), train_loss = 0.75516089, grad/param norm = 4.3385e-01, time/batch = 32.3179s	
6978/11350 (epoch 30.740), train_loss = 0.80655553, grad/param norm = 3.1908e-01, time/batch = 18.3719s	
6979/11350 (epoch 30.744), train_loss = 0.81026319, grad/param norm = 3.6493e-01, time/batch = 17.2749s	
6980/11350 (epoch 30.749), train_loss = 0.80412508, grad/param norm = 3.5502e-01, time/batch = 18.8088s	
6981/11350 (epoch 30.753), train_loss = 0.89971445, grad/param norm = 5.7148e-01, time/batch = 18.8841s	
6982/11350 (epoch 30.758), train_loss = 0.79342271, grad/param norm = 3.7049e-01, time/batch = 18.0428s	
6983/11350 (epoch 30.762), train_loss = 0.91969144, grad/param norm = 3.8333e-01, time/batch = 19.7876s	
6984/11350 (epoch 30.767), train_loss = 0.89795045, grad/param norm = 2.7616e-01, time/batch = 17.7089s	
6985/11350 (epoch 30.771), train_loss = 1.01095799, grad/param norm = 3.4789e-01, time/batch = 18.0377s	
6986/11350 (epoch 30.775), train_loss = 0.81391288, grad/param norm = 3.1120e-01, time/batch = 17.5853s	
6987/11350 (epoch 30.780), train_loss = 0.91274053, grad/param norm = 3.4681e-01, time/batch = 18.7954s	
6988/11350 (epoch 30.784), train_loss = 0.78945936, grad/param norm = 3.2538e-01, time/batch = 19.5451s	
6989/11350 (epoch 30.789), train_loss = 0.82708902, grad/param norm = 3.3576e-01, time/batch = 18.9310s	
6990/11350 (epoch 30.793), train_loss = 0.92106957, grad/param norm = 3.4119e-01, time/batch = 19.1059s	
6991/11350 (epoch 30.797), train_loss = 0.81932631, grad/param norm = 3.3648e-01, time/batch = 19.8771s	
6992/11350 (epoch 30.802), train_loss = 0.85403766, grad/param norm = 3.7291e-01, time/batch = 17.2009s	
6993/11350 (epoch 30.806), train_loss = 0.87887372, grad/param norm = 3.0568e-01, time/batch = 20.0389s	
6994/11350 (epoch 30.811), train_loss = 0.84368769, grad/param norm = 2.9379e-01, time/batch = 16.1927s	
6995/11350 (epoch 30.815), train_loss = 0.79337137, grad/param norm = 3.1220e-01, time/batch = 18.6893s	
6996/11350 (epoch 30.819), train_loss = 0.73794604, grad/param norm = 3.0866e-01, time/batch = 20.2766s	
6997/11350 (epoch 30.824), train_loss = 0.71818615, grad/param norm = 3.0609e-01, time/batch = 19.4551s	
6998/11350 (epoch 30.828), train_loss = 0.76613160, grad/param norm = 3.1801e-01, time/batch = 17.9204s	
6999/11350 (epoch 30.833), train_loss = 0.78710943, grad/param norm = 3.2800e-01, time/batch = 20.2056s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch30.84_1.9982.t7	
7000/11350 (epoch 30.837), train_loss = 0.82446620, grad/param norm = 3.4269e-01, time/batch = 19.3779s	
7001/11350 (epoch 30.841), train_loss = 1.70761385, grad/param norm = 5.6876e-01, time/batch = 20.1120s	
7002/11350 (epoch 30.846), train_loss = 0.89603174, grad/param norm = 3.3273e-01, time/batch = 18.3667s	
7003/11350 (epoch 30.850), train_loss = 0.93993855, grad/param norm = 4.1718e-01, time/batch = 18.7970s	
7004/11350 (epoch 30.855), train_loss = 0.69566090, grad/param norm = 2.9912e-01, time/batch = 19.4687s	
7005/11350 (epoch 30.859), train_loss = 0.76526786, grad/param norm = 3.8109e-01, time/batch = 17.7667s	
7006/11350 (epoch 30.863), train_loss = 0.70762989, grad/param norm = 2.8820e-01, time/batch = 19.2025s	
7007/11350 (epoch 30.868), train_loss = 0.72229952, grad/param norm = 2.8269e-01, time/batch = 19.2878s	
7008/11350 (epoch 30.872), train_loss = 0.76370657, grad/param norm = 3.0895e-01, time/batch = 18.7703s	
7009/11350 (epoch 30.877), train_loss = 0.76465510, grad/param norm = 3.3540e-01, time/batch = 20.1915s	
7010/11350 (epoch 30.881), train_loss = 0.95950073, grad/param norm = 3.9102e-01, time/batch = 20.4613s	
7011/11350 (epoch 30.885), train_loss = 0.93489906, grad/param norm = 3.2274e-01, time/batch = 18.0281s	
7012/11350 (epoch 30.890), train_loss = 0.84262374, grad/param norm = 3.3987e-01, time/batch = 19.6168s	
7013/11350 (epoch 30.894), train_loss = 0.68595514, grad/param norm = 2.7612e-01, time/batch = 17.7743s	
7014/11350 (epoch 30.899), train_loss = 0.86655883, grad/param norm = 3.0761e-01, time/batch = 18.7773s	
7015/11350 (epoch 30.903), train_loss = 0.83134329, grad/param norm = 3.0913e-01, time/batch = 18.5568s	
7016/11350 (epoch 30.907), train_loss = 0.77718672, grad/param norm = 3.2255e-01, time/batch = 16.8646s	
7017/11350 (epoch 30.912), train_loss = 0.72663796, grad/param norm = 2.6654e-01, time/batch = 19.0328s	
7018/11350 (epoch 30.916), train_loss = 0.85004959, grad/param norm = 3.1572e-01, time/batch = 19.3754s	
7019/11350 (epoch 30.921), train_loss = 0.84869882, grad/param norm = 3.3562e-01, time/batch = 16.8794s	
7020/11350 (epoch 30.925), train_loss = 0.69460083, grad/param norm = 2.4496e-01, time/batch = 19.8687s	
7021/11350 (epoch 30.930), train_loss = 0.86010199, grad/param norm = 3.7578e-01, time/batch = 19.0940s	
7022/11350 (epoch 30.934), train_loss = 0.94444157, grad/param norm = 3.6492e-01, time/batch = 18.2880s	
7023/11350 (epoch 30.938), train_loss = 0.80862976, grad/param norm = 3.2516e-01, time/batch = 19.0521s	
7024/11350 (epoch 30.943), train_loss = 0.88515613, grad/param norm = 3.0225e-01, time/batch = 18.5388s	
7025/11350 (epoch 30.947), train_loss = 0.84043562, grad/param norm = 3.4750e-01, time/batch = 18.7894s	
7026/11350 (epoch 30.952), train_loss = 0.86684373, grad/param norm = 3.5655e-01, time/batch = 20.0136s	
7027/11350 (epoch 30.956), train_loss = 0.67999580, grad/param norm = 2.8138e-01, time/batch = 18.9513s	
7028/11350 (epoch 30.960), train_loss = 0.76474148, grad/param norm = 3.5151e-01, time/batch = 18.8784s	
7029/11350 (epoch 30.965), train_loss = 0.69942807, grad/param norm = 3.1296e-01, time/batch = 20.0432s	
7030/11350 (epoch 30.969), train_loss = 0.69830428, grad/param norm = 3.3322e-01, time/batch = 18.3711s	
7031/11350 (epoch 30.974), train_loss = 0.69639562, grad/param norm = 3.0207e-01, time/batch = 18.0372s	
7032/11350 (epoch 30.978), train_loss = 0.79989327, grad/param norm = 3.0914e-01, time/batch = 18.1440s	
7033/11350 (epoch 30.982), train_loss = 0.54488152, grad/param norm = 2.4040e-01, time/batch = 17.6319s	
7034/11350 (epoch 30.987), train_loss = 0.78390040, grad/param norm = 3.2575e-01, time/batch = 20.1243s	
7035/11350 (epoch 30.991), train_loss = 0.68338767, grad/param norm = 3.5454e-01, time/batch = 18.2556s	
7036/11350 (epoch 30.996), train_loss = 0.79086825, grad/param norm = 3.6619e-01, time/batch = 17.9354s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
7037/11350 (epoch 31.000), train_loss = 0.60821947, grad/param norm = 3.0080e-01, time/batch = 15.7111s	
7038/11350 (epoch 31.004), train_loss = 0.84012219, grad/param norm = 3.7401e-01, time/batch = 19.6162s	
7039/11350 (epoch 31.009), train_loss = 0.80331463, grad/param norm = 2.7763e-01, time/batch = 20.1899s	
7040/11350 (epoch 31.013), train_loss = 0.55135360, grad/param norm = 2.5984e-01, time/batch = 19.5954s	
7041/11350 (epoch 31.018), train_loss = 0.63415599, grad/param norm = 3.0761e-01, time/batch = 20.1200s	
7042/11350 (epoch 31.022), train_loss = 0.65636293, grad/param norm = 3.8442e-01, time/batch = 20.7718s	
7043/11350 (epoch 31.026), train_loss = 0.61710650, grad/param norm = 3.3244e-01, time/batch = 19.6962s	
7044/11350 (epoch 31.031), train_loss = 0.66224515, grad/param norm = 2.8240e-01, time/batch = 19.1222s	
7045/11350 (epoch 31.035), train_loss = 0.66859833, grad/param norm = 3.0153e-01, time/batch = 18.4343s	
7046/11350 (epoch 31.040), train_loss = 0.69622465, grad/param norm = 3.3818e-01, time/batch = 18.1010s	
7047/11350 (epoch 31.044), train_loss = 0.66832737, grad/param norm = 2.8122e-01, time/batch = 19.8863s	
7048/11350 (epoch 31.048), train_loss = 0.63410287, grad/param norm = 3.0972e-01, time/batch = 19.5320s	
7049/11350 (epoch 31.053), train_loss = 0.68535365, grad/param norm = 2.7968e-01, time/batch = 18.3656s	
7050/11350 (epoch 31.057), train_loss = 0.69982045, grad/param norm = 3.3968e-01, time/batch = 19.1342s	
7051/11350 (epoch 31.062), train_loss = 0.58966835, grad/param norm = 3.0032e-01, time/batch = 16.5169s	
7052/11350 (epoch 31.066), train_loss = 0.58577001, grad/param norm = 2.9225e-01, time/batch = 18.3492s	
7053/11350 (epoch 31.070), train_loss = 0.65800682, grad/param norm = 2.8716e-01, time/batch = 18.5208s	
7054/11350 (epoch 31.075), train_loss = 0.60138921, grad/param norm = 2.7492e-01, time/batch = 19.2102s	
7055/11350 (epoch 31.079), train_loss = 0.71771069, grad/param norm = 2.9061e-01, time/batch = 19.1036s	
7056/11350 (epoch 31.084), train_loss = 0.85675247, grad/param norm = 3.6371e-01, time/batch = 19.8595s	
7057/11350 (epoch 31.088), train_loss = 0.77157074, grad/param norm = 3.3437e-01, time/batch = 18.3733s	
7058/11350 (epoch 31.093), train_loss = 0.75936975, grad/param norm = 3.0058e-01, time/batch = 19.6210s	
7059/11350 (epoch 31.097), train_loss = 0.73565582, grad/param norm = 3.4042e-01, time/batch = 18.6998s	
7060/11350 (epoch 31.101), train_loss = 0.64964081, grad/param norm = 2.9467e-01, time/batch = 19.2728s	
7061/11350 (epoch 31.106), train_loss = 0.74824997, grad/param norm = 3.1902e-01, time/batch = 19.0915s	
7062/11350 (epoch 31.110), train_loss = 0.66448613, grad/param norm = 2.9359e-01, time/batch = 19.5984s	
7063/11350 (epoch 31.115), train_loss = 0.68488539, grad/param norm = 2.9474e-01, time/batch = 18.2171s	
7064/11350 (epoch 31.119), train_loss = 0.80101406, grad/param norm = 4.1703e-01, time/batch = 20.2834s	
7065/11350 (epoch 31.123), train_loss = 0.67243942, grad/param norm = 3.7115e-01, time/batch = 19.0258s	
7066/11350 (epoch 31.128), train_loss = 0.59595538, grad/param norm = 2.9494e-01, time/batch = 19.4334s	
7067/11350 (epoch 31.132), train_loss = 0.64531863, grad/param norm = 2.8999e-01, time/batch = 19.4391s	
7068/11350 (epoch 31.137), train_loss = 0.62923627, grad/param norm = 3.1866e-01, time/batch = 17.3623s	
7069/11350 (epoch 31.141), train_loss = 0.82316532, grad/param norm = 3.5593e-01, time/batch = 16.5513s	
7070/11350 (epoch 31.145), train_loss = 0.65507807, grad/param norm = 2.7697e-01, time/batch = 17.6385s	
7071/11350 (epoch 31.150), train_loss = 0.73794970, grad/param norm = 4.2051e-01, time/batch = 18.4606s	
7072/11350 (epoch 31.154), train_loss = 0.85230333, grad/param norm = 3.7910e-01, time/batch = 17.2805s	
7073/11350 (epoch 31.159), train_loss = 0.60500333, grad/param norm = 3.4301e-01, time/batch = 16.2099s	
7074/11350 (epoch 31.163), train_loss = 0.76932855, grad/param norm = 3.4382e-01, time/batch = 20.2019s	
7075/11350 (epoch 31.167), train_loss = 0.81944520, grad/param norm = 3.1319e-01, time/batch = 18.5058s	
7076/11350 (epoch 31.172), train_loss = 0.88529093, grad/param norm = 3.0550e-01, time/batch = 18.3445s	
7077/11350 (epoch 31.176), train_loss = 0.70873632, grad/param norm = 3.0717e-01, time/batch = 20.2776s	
7078/11350 (epoch 31.181), train_loss = 0.75425847, grad/param norm = 3.3424e-01, time/batch = 18.8595s	
7079/11350 (epoch 31.185), train_loss = 0.63992712, grad/param norm = 2.8976e-01, time/batch = 20.1197s	
7080/11350 (epoch 31.189), train_loss = 0.70401901, grad/param norm = 2.8940e-01, time/batch = 18.7009s	
7081/11350 (epoch 31.194), train_loss = 0.61510177, grad/param norm = 2.9294e-01, time/batch = 18.6123s	
7082/11350 (epoch 31.198), train_loss = 0.60384813, grad/param norm = 3.1548e-01, time/batch = 18.8714s	
7083/11350 (epoch 31.203), train_loss = 0.64641944, grad/param norm = 3.0087e-01, time/batch = 18.3658s	
7084/11350 (epoch 31.207), train_loss = 0.60113188, grad/param norm = 3.6051e-01, time/batch = 18.6039s	
7085/11350 (epoch 31.211), train_loss = 0.80550303, grad/param norm = 3.9277e-01, time/batch = 16.9371s	
7086/11350 (epoch 31.216), train_loss = 0.76479839, grad/param norm = 3.9844e-01, time/batch = 18.6992s	
7087/11350 (epoch 31.220), train_loss = 0.76169242, grad/param norm = 3.0803e-01, time/batch = 17.8555s	
7088/11350 (epoch 31.225), train_loss = 0.67013221, grad/param norm = 3.0824e-01, time/batch = 19.1184s	
7089/11350 (epoch 31.229), train_loss = 0.75347897, grad/param norm = 2.8876e-01, time/batch = 17.1015s	
7090/11350 (epoch 31.233), train_loss = 0.71675692, grad/param norm = 3.4234e-01, time/batch = 19.0464s	
7091/11350 (epoch 31.238), train_loss = 0.81290202, grad/param norm = 3.9225e-01, time/batch = 18.0270s	
7092/11350 (epoch 31.242), train_loss = 0.84850648, grad/param norm = 4.0784e-01, time/batch = 20.0463s	
7093/11350 (epoch 31.247), train_loss = 0.61929541, grad/param norm = 2.8476e-01, time/batch = 20.4319s	
7094/11350 (epoch 31.251), train_loss = 0.74129998, grad/param norm = 3.3280e-01, time/batch = 19.2797s	
7095/11350 (epoch 31.256), train_loss = 0.72809153, grad/param norm = 3.1647e-01, time/batch = 18.9496s	
7096/11350 (epoch 31.260), train_loss = 0.67777261, grad/param norm = 2.9456e-01, time/batch = 19.5469s	
7097/11350 (epoch 31.264), train_loss = 0.64817308, grad/param norm = 3.0241e-01, time/batch = 19.4365s	
7098/11350 (epoch 31.269), train_loss = 0.70369427, grad/param norm = 2.6541e-01, time/batch = 18.7197s	
7099/11350 (epoch 31.273), train_loss = 0.82367277, grad/param norm = 3.3538e-01, time/batch = 17.7045s	
7100/11350 (epoch 31.278), train_loss = 0.68182988, grad/param norm = 3.2363e-01, time/batch = 17.1021s	
7101/11350 (epoch 31.282), train_loss = 0.70808639, grad/param norm = 3.3277e-01, time/batch = 17.4373s	
7102/11350 (epoch 31.286), train_loss = 0.79701442, grad/param norm = 3.2941e-01, time/batch = 19.5395s	
7103/11350 (epoch 31.291), train_loss = 0.66503755, grad/param norm = 3.2779e-01, time/batch = 18.8614s	
7104/11350 (epoch 31.295), train_loss = 0.73049932, grad/param norm = 3.3719e-01, time/batch = 19.5297s	
7105/11350 (epoch 31.300), train_loss = 0.78517064, grad/param norm = 3.2679e-01, time/batch = 19.8753s	
7106/11350 (epoch 31.304), train_loss = 0.67341009, grad/param norm = 3.2852e-01, time/batch = 18.4554s	
7107/11350 (epoch 31.308), train_loss = 0.64904677, grad/param norm = 3.3171e-01, time/batch = 18.0801s	
7108/11350 (epoch 31.313), train_loss = 0.72418953, grad/param norm = 2.7103e-01, time/batch = 18.3789s	
7109/11350 (epoch 31.317), train_loss = 0.67168318, grad/param norm = 2.5692e-01, time/batch = 19.7892s	
7110/11350 (epoch 31.322), train_loss = 0.69763552, grad/param norm = 3.1993e-01, time/batch = 19.2796s	
7111/11350 (epoch 31.326), train_loss = 0.72036683, grad/param norm = 3.2632e-01, time/batch = 18.3920s	
7112/11350 (epoch 31.330), train_loss = 0.57986547, grad/param norm = 2.2776e-01, time/batch = 19.2930s	
7113/11350 (epoch 31.335), train_loss = 0.47837725, grad/param norm = 2.5067e-01, time/batch = 18.3550s	
7114/11350 (epoch 31.339), train_loss = 0.54160532, grad/param norm = 2.8858e-01, time/batch = 18.0388s	
7115/11350 (epoch 31.344), train_loss = 0.65432156, grad/param norm = 2.9902e-01, time/batch = 18.2840s	
7116/11350 (epoch 31.348), train_loss = 0.64533388, grad/param norm = 2.7682e-01, time/batch = 17.5226s	
7117/11350 (epoch 31.352), train_loss = 0.54971343, grad/param norm = 2.6407e-01, time/batch = 19.2851s	
7118/11350 (epoch 31.357), train_loss = 0.67544855, grad/param norm = 2.7136e-01, time/batch = 17.8128s	
7119/11350 (epoch 31.361), train_loss = 0.53561929, grad/param norm = 2.4931e-01, time/batch = 18.6149s	
7120/11350 (epoch 31.366), train_loss = 0.68692009, grad/param norm = 3.1201e-01, time/batch = 17.1045s	
7121/11350 (epoch 31.370), train_loss = 0.58998187, grad/param norm = 3.3791e-01, time/batch = 18.7741s	
7122/11350 (epoch 31.374), train_loss = 0.63937712, grad/param norm = 3.0504e-01, time/batch = 19.8525s	
7123/11350 (epoch 31.379), train_loss = 0.62478934, grad/param norm = 2.8815e-01, time/batch = 18.5444s	
7124/11350 (epoch 31.383), train_loss = 0.58882311, grad/param norm = 3.3326e-01, time/batch = 17.5039s	
7125/11350 (epoch 31.388), train_loss = 0.67052603, grad/param norm = 3.3571e-01, time/batch = 17.5330s	
7126/11350 (epoch 31.392), train_loss = 0.71245368, grad/param norm = 2.8432e-01, time/batch = 17.2785s	
7127/11350 (epoch 31.396), train_loss = 0.64736129, grad/param norm = 3.5890e-01, time/batch = 18.8066s	
7128/11350 (epoch 31.401), train_loss = 0.67225992, grad/param norm = 3.3516e-01, time/batch = 18.8905s	
7129/11350 (epoch 31.405), train_loss = 0.85284000, grad/param norm = 3.5744e-01, time/batch = 18.0255s	
7130/11350 (epoch 31.410), train_loss = 0.86806441, grad/param norm = 3.5980e-01, time/batch = 18.7983s	
7131/11350 (epoch 31.414), train_loss = 0.62857975, grad/param norm = 3.4516e-01, time/batch = 17.3739s	
7132/11350 (epoch 31.419), train_loss = 0.60772096, grad/param norm = 3.0560e-01, time/batch = 19.2823s	
7133/11350 (epoch 31.423), train_loss = 0.67088686, grad/param norm = 3.4758e-01, time/batch = 17.7591s	
7134/11350 (epoch 31.427), train_loss = 0.75831375, grad/param norm = 3.2463e-01, time/batch = 19.1290s	
7135/11350 (epoch 31.432), train_loss = 0.70704948, grad/param norm = 3.3210e-01, time/batch = 16.3478s	
7136/11350 (epoch 31.436), train_loss = 0.65015970, grad/param norm = 3.2282e-01, time/batch = 18.2598s	
7137/11350 (epoch 31.441), train_loss = 0.83792301, grad/param norm = 4.0639e-01, time/batch = 20.7029s	
7138/11350 (epoch 31.445), train_loss = 0.63155699, grad/param norm = 2.8961e-01, time/batch = 19.8701s	
7139/11350 (epoch 31.449), train_loss = 0.72744364, grad/param norm = 3.3444e-01, time/batch = 18.9502s	
7140/11350 (epoch 31.454), train_loss = 0.83978313, grad/param norm = 3.9148e-01, time/batch = 20.4526s	
7141/11350 (epoch 31.458), train_loss = 0.58981748, grad/param norm = 2.9080e-01, time/batch = 18.1149s	
7142/11350 (epoch 31.463), train_loss = 0.59120708, grad/param norm = 3.4026e-01, time/batch = 17.7578s	
7143/11350 (epoch 31.467), train_loss = 0.92282785, grad/param norm = 3.7581e-01, time/batch = 19.9631s	
7144/11350 (epoch 31.471), train_loss = 0.82976629, grad/param norm = 4.6859e-01, time/batch = 18.5507s	
7145/11350 (epoch 31.476), train_loss = 0.74608037, grad/param norm = 3.3243e-01, time/batch = 16.8765s	
7146/11350 (epoch 31.480), train_loss = 0.83472558, grad/param norm = 3.4948e-01, time/batch = 15.9812s	
7147/11350 (epoch 31.485), train_loss = 0.72796221, grad/param norm = 3.0212e-01, time/batch = 17.3769s	
7148/11350 (epoch 31.489), train_loss = 0.81505202, grad/param norm = 3.3714e-01, time/batch = 18.7175s	
7149/11350 (epoch 31.493), train_loss = 0.82071046, grad/param norm = 2.9947e-01, time/batch = 18.2569s	
7150/11350 (epoch 31.498), train_loss = 0.55141763, grad/param norm = 3.1527e-01, time/batch = 19.0346s	
7151/11350 (epoch 31.502), train_loss = 0.81162691, grad/param norm = 3.2135e-01, time/batch = 19.7108s	
7152/11350 (epoch 31.507), train_loss = 0.61825541, grad/param norm = 2.7295e-01, time/batch = 16.9215s	
7153/11350 (epoch 31.511), train_loss = 0.79990646, grad/param norm = 2.8771e-01, time/batch = 20.2609s	
7154/11350 (epoch 31.515), train_loss = 0.72640212, grad/param norm = 3.8898e-01, time/batch = 17.6198s	
7155/11350 (epoch 31.520), train_loss = 0.87568353, grad/param norm = 3.3825e-01, time/batch = 18.5327s	
7156/11350 (epoch 31.524), train_loss = 0.76270706, grad/param norm = 3.4399e-01, time/batch = 19.1041s	
7157/11350 (epoch 31.529), train_loss = 0.70814816, grad/param norm = 2.8424e-01, time/batch = 19.6427s	
7158/11350 (epoch 31.533), train_loss = 0.88286270, grad/param norm = 3.4321e-01, time/batch = 18.5300s	
7159/11350 (epoch 31.537), train_loss = 0.82959481, grad/param norm = 3.2870e-01, time/batch = 18.5294s	
7160/11350 (epoch 31.542), train_loss = 0.76143536, grad/param norm = 2.9404e-01, time/batch = 20.5220s	
7161/11350 (epoch 31.546), train_loss = 0.94004847, grad/param norm = 4.2206e-01, time/batch = 18.2633s	
7162/11350 (epoch 31.551), train_loss = 0.79117919, grad/param norm = 3.3606e-01, time/batch = 16.6951s	
7163/11350 (epoch 31.555), train_loss = 0.68651624, grad/param norm = 2.9224e-01, time/batch = 18.6070s	
7164/11350 (epoch 31.559), train_loss = 0.73086170, grad/param norm = 2.8979e-01, time/batch = 20.2744s	
7165/11350 (epoch 31.564), train_loss = 0.77622004, grad/param norm = 3.3182e-01, time/batch = 33.7704s	
7166/11350 (epoch 31.568), train_loss = 0.81138821, grad/param norm = 3.0226e-01, time/batch = 16.1100s	
7167/11350 (epoch 31.573), train_loss = 0.91474878, grad/param norm = 4.6039e-01, time/batch = 18.8501s	
7168/11350 (epoch 31.577), train_loss = 0.87346746, grad/param norm = 5.1120e-01, time/batch = 19.7779s	
7169/11350 (epoch 31.581), train_loss = 0.88651901, grad/param norm = 3.2313e-01, time/batch = 20.7744s	
7170/11350 (epoch 31.586), train_loss = 0.86029264, grad/param norm = 3.6160e-01, time/batch = 17.7140s	
7171/11350 (epoch 31.590), train_loss = 0.91638900, grad/param norm = 3.6144e-01, time/batch = 19.9623s	
7172/11350 (epoch 31.595), train_loss = 0.95322664, grad/param norm = 3.2274e-01, time/batch = 20.4462s	
7173/11350 (epoch 31.599), train_loss = 0.84453283, grad/param norm = 3.3765e-01, time/batch = 18.3656s	
7174/11350 (epoch 31.604), train_loss = 0.79521158, grad/param norm = 3.9968e-01, time/batch = 18.7093s	
7175/11350 (epoch 31.608), train_loss = 0.75655266, grad/param norm = 3.2493e-01, time/batch = 19.3769s	
7176/11350 (epoch 31.612), train_loss = 0.78539474, grad/param norm = 3.1163e-01, time/batch = 18.9409s	
7177/11350 (epoch 31.617), train_loss = 0.84474758, grad/param norm = 3.6070e-01, time/batch = 20.6067s	
7178/11350 (epoch 31.621), train_loss = 0.87565432, grad/param norm = 2.9756e-01, time/batch = 16.9178s	
7179/11350 (epoch 31.626), train_loss = 0.79306916, grad/param norm = 2.9565e-01, time/batch = 18.4451s	
7180/11350 (epoch 31.630), train_loss = 0.84262063, grad/param norm = 3.9824e-01, time/batch = 19.5195s	
7181/11350 (epoch 31.634), train_loss = 0.80706188, grad/param norm = 3.6330e-01, time/batch = 19.2988s	
7182/11350 (epoch 31.639), train_loss = 0.71317756, grad/param norm = 3.2354e-01, time/batch = 18.9584s	
7183/11350 (epoch 31.643), train_loss = 0.66622767, grad/param norm = 3.0107e-01, time/batch = 18.2771s	
7184/11350 (epoch 31.648), train_loss = 0.74855898, grad/param norm = 3.1601e-01, time/batch = 19.5489s	
7185/11350 (epoch 31.652), train_loss = 0.69037908, grad/param norm = 3.2839e-01, time/batch = 19.7843s	
7186/11350 (epoch 31.656), train_loss = 0.79734141, grad/param norm = 3.0345e-01, time/batch = 19.7745s	
7187/11350 (epoch 31.661), train_loss = 0.83966083, grad/param norm = 3.4081e-01, time/batch = 18.7592s	
7188/11350 (epoch 31.665), train_loss = 0.80370249, grad/param norm = 3.4113e-01, time/batch = 19.4580s	
7189/11350 (epoch 31.670), train_loss = 0.79122613, grad/param norm = 3.2796e-01, time/batch = 16.4977s	
7190/11350 (epoch 31.674), train_loss = 0.74862369, grad/param norm = 3.2788e-01, time/batch = 20.1071s	
7191/11350 (epoch 31.678), train_loss = 0.78886429, grad/param norm = 3.2214e-01, time/batch = 20.4484s	
7192/11350 (epoch 31.683), train_loss = 0.71253664, grad/param norm = 3.1609e-01, time/batch = 17.8029s	
7193/11350 (epoch 31.687), train_loss = 0.68935573, grad/param norm = 3.8813e-01, time/batch = 20.3790s	
7194/11350 (epoch 31.692), train_loss = 1.03242967, grad/param norm = 4.4105e-01, time/batch = 19.0253s	
7195/11350 (epoch 31.696), train_loss = 0.96446146, grad/param norm = 3.8190e-01, time/batch = 17.5283s	
7196/11350 (epoch 31.700), train_loss = 0.88437691, grad/param norm = 3.5464e-01, time/batch = 19.3734s	
7197/11350 (epoch 31.705), train_loss = 0.92632816, grad/param norm = 3.8061e-01, time/batch = 19.2937s	
7198/11350 (epoch 31.709), train_loss = 0.90799220, grad/param norm = 3.5505e-01, time/batch = 18.1921s	
7199/11350 (epoch 31.714), train_loss = 0.80530097, grad/param norm = 3.1286e-01, time/batch = 19.8670s	
7200/11350 (epoch 31.718), train_loss = 0.68653052, grad/param norm = 3.1624e-01, time/batch = 17.4260s	
7201/11350 (epoch 31.722), train_loss = 0.80884817, grad/param norm = 4.2545e-01, time/batch = 18.1852s	
7202/11350 (epoch 31.727), train_loss = 0.80052724, grad/param norm = 3.0929e-01, time/batch = 18.5342s	
7203/11350 (epoch 31.731), train_loss = 0.79659507, grad/param norm = 3.6190e-01, time/batch = 18.2809s	
7204/11350 (epoch 31.736), train_loss = 0.72240576, grad/param norm = 4.4588e-01, time/batch = 20.1984s	
7205/11350 (epoch 31.740), train_loss = 0.78808810, grad/param norm = 3.3526e-01, time/batch = 19.6845s	
7206/11350 (epoch 31.744), train_loss = 0.78393062, grad/param norm = 3.7429e-01, time/batch = 16.7618s	
7207/11350 (epoch 31.749), train_loss = 0.79322818, grad/param norm = 3.6740e-01, time/batch = 19.2109s	
7208/11350 (epoch 31.753), train_loss = 0.86297025, grad/param norm = 4.4102e-01, time/batch = 18.9396s	
7209/11350 (epoch 31.758), train_loss = 0.76339264, grad/param norm = 3.6582e-01, time/batch = 19.2827s	
7210/11350 (epoch 31.762), train_loss = 0.88702845, grad/param norm = 3.2914e-01, time/batch = 18.1966s	
7211/11350 (epoch 31.767), train_loss = 0.88048212, grad/param norm = 3.3826e-01, time/batch = 18.3523s	
7212/11350 (epoch 31.771), train_loss = 0.98695115, grad/param norm = 3.5825e-01, time/batch = 19.2918s	
7213/11350 (epoch 31.775), train_loss = 0.80163393, grad/param norm = 3.5061e-01, time/batch = 19.0410s	
7214/11350 (epoch 31.780), train_loss = 0.87619571, grad/param norm = 3.3843e-01, time/batch = 19.5187s	
7215/11350 (epoch 31.784), train_loss = 0.77506629, grad/param norm = 3.2294e-01, time/batch = 18.9409s	
7216/11350 (epoch 31.789), train_loss = 0.80776160, grad/param norm = 3.4336e-01, time/batch = 19.0339s	
7217/11350 (epoch 31.793), train_loss = 0.88648571, grad/param norm = 3.0566e-01, time/batch = 19.3606s	
7218/11350 (epoch 31.797), train_loss = 0.79409845, grad/param norm = 2.7826e-01, time/batch = 19.7700s	
7219/11350 (epoch 31.802), train_loss = 0.82917078, grad/param norm = 3.2023e-01, time/batch = 16.7740s	
7220/11350 (epoch 31.806), train_loss = 0.85097722, grad/param norm = 3.0828e-01, time/batch = 18.2856s	
7221/11350 (epoch 31.811), train_loss = 0.81893644, grad/param norm = 3.1213e-01, time/batch = 18.3791s	
7222/11350 (epoch 31.815), train_loss = 0.77298767, grad/param norm = 3.1104e-01, time/batch = 18.3784s	
7223/11350 (epoch 31.819), train_loss = 0.70704229, grad/param norm = 2.8517e-01, time/batch = 16.8894s	
7224/11350 (epoch 31.824), train_loss = 0.71474270, grad/param norm = 3.6396e-01, time/batch = 18.1846s	
7225/11350 (epoch 31.828), train_loss = 0.73533596, grad/param norm = 3.0879e-01, time/batch = 18.9548s	
7226/11350 (epoch 31.833), train_loss = 0.77295825, grad/param norm = 3.4470e-01, time/batch = 19.1000s	
7227/11350 (epoch 31.837), train_loss = 0.80965863, grad/param norm = 3.0671e-01, time/batch = 18.2680s	
7228/11350 (epoch 31.841), train_loss = 1.04873542, grad/param norm = 3.6697e-01, time/batch = 18.9756s	
7229/11350 (epoch 31.846), train_loss = 0.84009700, grad/param norm = 2.8641e-01, time/batch = 19.7082s	
7230/11350 (epoch 31.850), train_loss = 0.87241983, grad/param norm = 3.3828e-01, time/batch = 18.6917s	
7231/11350 (epoch 31.855), train_loss = 0.69108246, grad/param norm = 3.2627e-01, time/batch = 19.7701s	
7232/11350 (epoch 31.859), train_loss = 0.75024061, grad/param norm = 3.7642e-01, time/batch = 20.1266s	
7233/11350 (epoch 31.863), train_loss = 0.70612494, grad/param norm = 3.3807e-01, time/batch = 17.7897s	
7234/11350 (epoch 31.868), train_loss = 0.70151504, grad/param norm = 2.8708e-01, time/batch = 19.7737s	
7235/11350 (epoch 31.872), train_loss = 0.73760864, grad/param norm = 2.9587e-01, time/batch = 18.5614s	
7236/11350 (epoch 31.877), train_loss = 0.74399113, grad/param norm = 3.2823e-01, time/batch = 19.0315s	
7237/11350 (epoch 31.881), train_loss = 0.95449879, grad/param norm = 4.0250e-01, time/batch = 20.0186s	
7238/11350 (epoch 31.885), train_loss = 0.89785884, grad/param norm = 3.4736e-01, time/batch = 20.1317s	
7239/11350 (epoch 31.890), train_loss = 0.82528462, grad/param norm = 3.8606e-01, time/batch = 18.5251s	
7240/11350 (epoch 31.894), train_loss = 0.67624848, grad/param norm = 2.8589e-01, time/batch = 20.6187s	
7241/11350 (epoch 31.899), train_loss = 0.83959438, grad/param norm = 3.0525e-01, time/batch = 17.9503s	
7242/11350 (epoch 31.903), train_loss = 0.81308329, grad/param norm = 3.0597e-01, time/batch = 18.7853s	
7243/11350 (epoch 31.907), train_loss = 0.75158724, grad/param norm = 3.0215e-01, time/batch = 18.2918s	
7244/11350 (epoch 31.912), train_loss = 0.71847030, grad/param norm = 3.0367e-01, time/batch = 19.4451s	
7245/11350 (epoch 31.916), train_loss = 0.82545393, grad/param norm = 3.2048e-01, time/batch = 20.2824s	
7246/11350 (epoch 31.921), train_loss = 0.82198720, grad/param norm = 3.0619e-01, time/batch = 18.5024s	
7247/11350 (epoch 31.925), train_loss = 0.69229594, grad/param norm = 2.8392e-01, time/batch = 19.6282s	
7248/11350 (epoch 31.930), train_loss = 0.82069897, grad/param norm = 3.5614e-01, time/batch = 20.1316s	
7249/11350 (epoch 31.934), train_loss = 0.93779241, grad/param norm = 3.8462e-01, time/batch = 19.2747s	
7250/11350 (epoch 31.938), train_loss = 0.79178154, grad/param norm = 3.2131e-01, time/batch = 17.9449s	
7251/11350 (epoch 31.943), train_loss = 0.86966806, grad/param norm = 3.5808e-01, time/batch = 19.7951s	
7252/11350 (epoch 31.947), train_loss = 0.81752820, grad/param norm = 3.1994e-01, time/batch = 17.5393s	
7253/11350 (epoch 31.952), train_loss = 0.84635689, grad/param norm = 3.5635e-01, time/batch = 19.0932s	
7254/11350 (epoch 31.956), train_loss = 0.64745969, grad/param norm = 2.6042e-01, time/batch = 16.7447s	
7255/11350 (epoch 31.960), train_loss = 0.74253256, grad/param norm = 3.8899e-01, time/batch = 16.2530s	
7256/11350 (epoch 31.965), train_loss = 0.68018536, grad/param norm = 3.2330e-01, time/batch = 18.6097s	
7257/11350 (epoch 31.969), train_loss = 0.67123212, grad/param norm = 3.4888e-01, time/batch = 18.6606s	
7258/11350 (epoch 31.974), train_loss = 0.68793032, grad/param norm = 3.8358e-01, time/batch = 19.8551s	
7259/11350 (epoch 31.978), train_loss = 0.77630762, grad/param norm = 3.1756e-01, time/batch = 16.9445s	
7260/11350 (epoch 31.982), train_loss = 0.53275058, grad/param norm = 3.3421e-01, time/batch = 17.2087s	
7261/11350 (epoch 31.987), train_loss = 0.77198339, grad/param norm = 3.3821e-01, time/batch = 16.8869s	
7262/11350 (epoch 31.991), train_loss = 0.66829690, grad/param norm = 3.5421e-01, time/batch = 16.7938s	
7263/11350 (epoch 31.996), train_loss = 0.77061912, grad/param norm = 3.3378e-01, time/batch = 17.4105s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
7264/11350 (epoch 32.000), train_loss = 0.60157919, grad/param norm = 3.1867e-01, time/batch = 16.7962s	
7265/11350 (epoch 32.004), train_loss = 0.85247908, grad/param norm = 3.7277e-01, time/batch = 16.7905s	
7266/11350 (epoch 32.009), train_loss = 0.79630619, grad/param norm = 3.2670e-01, time/batch = 17.4916s	
7267/11350 (epoch 32.013), train_loss = 0.56135447, grad/param norm = 3.0088e-01, time/batch = 17.1447s	
7268/11350 (epoch 32.018), train_loss = 0.62394791, grad/param norm = 3.4946e-01, time/batch = 16.7920s	
7269/11350 (epoch 32.022), train_loss = 0.61923773, grad/param norm = 3.1731e-01, time/batch = 17.0963s	
7270/11350 (epoch 32.026), train_loss = 0.61010374, grad/param norm = 3.8500e-01, time/batch = 16.7944s	
7271/11350 (epoch 32.031), train_loss = 0.65802912, grad/param norm = 3.7298e-01, time/batch = 16.3076s	
7272/11350 (epoch 32.035), train_loss = 0.65814479, grad/param norm = 2.7632e-01, time/batch = 17.0393s	
7273/11350 (epoch 32.040), train_loss = 0.67924322, grad/param norm = 3.0880e-01, time/batch = 16.8458s	
7274/11350 (epoch 32.044), train_loss = 0.63946829, grad/param norm = 2.9642e-01, time/batch = 16.7912s	
7275/11350 (epoch 32.048), train_loss = 0.61633564, grad/param norm = 2.8161e-01, time/batch = 16.8647s	
7276/11350 (epoch 32.053), train_loss = 0.68467221, grad/param norm = 2.9490e-01, time/batch = 17.3469s	
7277/11350 (epoch 32.057), train_loss = 0.67538666, grad/param norm = 3.1863e-01, time/batch = 16.3792s	
7278/11350 (epoch 32.062), train_loss = 0.57728531, grad/param norm = 3.0143e-01, time/batch = 16.7160s	
7279/11350 (epoch 32.066), train_loss = 0.57387840, grad/param norm = 2.9443e-01, time/batch = 16.4712s	
7280/11350 (epoch 32.070), train_loss = 0.65255281, grad/param norm = 3.2926e-01, time/batch = 17.1878s	
7281/11350 (epoch 32.075), train_loss = 0.59799561, grad/param norm = 2.6940e-01, time/batch = 16.7844s	
7282/11350 (epoch 32.079), train_loss = 0.70287226, grad/param norm = 2.9800e-01, time/batch = 16.6414s	
7283/11350 (epoch 32.084), train_loss = 0.82231496, grad/param norm = 3.3718e-01, time/batch = 16.6236s	
7284/11350 (epoch 32.088), train_loss = 0.75966886, grad/param norm = 3.9609e-01, time/batch = 16.3031s	
7285/11350 (epoch 32.093), train_loss = 0.75613639, grad/param norm = 2.9624e-01, time/batch = 16.9240s	
7286/11350 (epoch 32.097), train_loss = 0.69620085, grad/param norm = 3.2924e-01, time/batch = 16.7146s	
7287/11350 (epoch 32.101), train_loss = 0.64519392, grad/param norm = 3.1135e-01, time/batch = 16.7721s	
7288/11350 (epoch 32.106), train_loss = 0.72818636, grad/param norm = 3.3349e-01, time/batch = 16.2934s	
7289/11350 (epoch 32.110), train_loss = 0.65184050, grad/param norm = 3.4806e-01, time/batch = 16.3774s	
7290/11350 (epoch 32.115), train_loss = 0.66233088, grad/param norm = 3.1785e-01, time/batch = 16.1346s	
7291/11350 (epoch 32.119), train_loss = 0.77094593, grad/param norm = 3.2521e-01, time/batch = 16.1493s	
7292/11350 (epoch 32.123), train_loss = 0.62446574, grad/param norm = 2.9887e-01, time/batch = 16.3946s	
7293/11350 (epoch 32.128), train_loss = 0.57272485, grad/param norm = 3.2616e-01, time/batch = 17.0185s	
7294/11350 (epoch 32.132), train_loss = 0.62740782, grad/param norm = 2.9243e-01, time/batch = 16.7031s	
7295/11350 (epoch 32.137), train_loss = 0.61288727, grad/param norm = 2.9852e-01, time/batch = 16.8848s	
7296/11350 (epoch 32.141), train_loss = 0.79286979, grad/param norm = 3.4693e-01, time/batch = 16.6383s	
7297/11350 (epoch 32.145), train_loss = 0.63120098, grad/param norm = 2.7950e-01, time/batch = 16.4646s	
7298/11350 (epoch 32.150), train_loss = 0.71141816, grad/param norm = 3.6032e-01, time/batch = 16.5419s	
7299/11350 (epoch 32.154), train_loss = 0.83806091, grad/param norm = 4.2134e-01, time/batch = 16.3203s	
7300/11350 (epoch 32.159), train_loss = 0.58988259, grad/param norm = 2.9150e-01, time/batch = 15.8982s	
7301/11350 (epoch 32.163), train_loss = 0.74725063, grad/param norm = 3.7143e-01, time/batch = 16.4551s	
7302/11350 (epoch 32.167), train_loss = 0.78920417, grad/param norm = 3.2535e-01, time/batch = 16.2271s	
7303/11350 (epoch 32.172), train_loss = 0.87707679, grad/param norm = 3.3659e-01, time/batch = 16.8853s	
7304/11350 (epoch 32.176), train_loss = 0.72029626, grad/param norm = 3.4694e-01, time/batch = 16.4686s	
7305/11350 (epoch 32.181), train_loss = 0.71911246, grad/param norm = 3.5536e-01, time/batch = 16.5991s	
7306/11350 (epoch 32.185), train_loss = 0.62834038, grad/param norm = 2.8218e-01, time/batch = 16.3126s	
7307/11350 (epoch 32.189), train_loss = 0.68673692, grad/param norm = 3.1909e-01, time/batch = 16.5388s	
7308/11350 (epoch 32.194), train_loss = 0.62136109, grad/param norm = 3.3758e-01, time/batch = 16.9992s	
7309/11350 (epoch 32.198), train_loss = 0.58709111, grad/param norm = 3.6398e-01, time/batch = 16.6195s	
7310/11350 (epoch 32.203), train_loss = 0.63183822, grad/param norm = 3.9705e-01, time/batch = 16.4819s	
7311/11350 (epoch 32.207), train_loss = 0.60365204, grad/param norm = 4.6600e-01, time/batch = 16.7030s	
7312/11350 (epoch 32.211), train_loss = 0.80578363, grad/param norm = 4.0348e-01, time/batch = 17.2774s	
7313/11350 (epoch 32.216), train_loss = 0.75588297, grad/param norm = 3.4117e-01, time/batch = 16.3828s	
7314/11350 (epoch 32.220), train_loss = 0.74124700, grad/param norm = 3.3715e-01, time/batch = 16.4513s	
7315/11350 (epoch 32.225), train_loss = 0.65473477, grad/param norm = 3.0395e-01, time/batch = 16.1484s	
7316/11350 (epoch 32.229), train_loss = 0.73139898, grad/param norm = 3.1911e-01, time/batch = 16.7645s	
7317/11350 (epoch 32.233), train_loss = 0.68804266, grad/param norm = 3.4015e-01, time/batch = 16.0589s	
7318/11350 (epoch 32.238), train_loss = 0.82290965, grad/param norm = 4.4932e-01, time/batch = 16.2352s	
7319/11350 (epoch 32.242), train_loss = 0.81171047, grad/param norm = 3.4697e-01, time/batch = 16.5316s	
7320/11350 (epoch 32.247), train_loss = 0.60875016, grad/param norm = 2.7157e-01, time/batch = 16.6941s	
7321/11350 (epoch 32.251), train_loss = 0.71565699, grad/param norm = 3.1785e-01, time/batch = 16.2201s	
7322/11350 (epoch 32.256), train_loss = 0.72413105, grad/param norm = 3.0182e-01, time/batch = 16.3771s	
7323/11350 (epoch 32.260), train_loss = 0.65153406, grad/param norm = 2.9836e-01, time/batch = 17.1630s	
7324/11350 (epoch 32.264), train_loss = 0.63435330, grad/param norm = 3.0053e-01, time/batch = 16.3940s	
7325/11350 (epoch 32.269), train_loss = 0.68117579, grad/param norm = 2.6415e-01, time/batch = 16.6222s	
7326/11350 (epoch 32.273), train_loss = 0.78726847, grad/param norm = 3.1757e-01, time/batch = 16.4695s	
7327/11350 (epoch 32.278), train_loss = 0.65974862, grad/param norm = 3.0104e-01, time/batch = 16.4701s	
7328/11350 (epoch 32.282), train_loss = 0.68204934, grad/param norm = 3.3344e-01, time/batch = 16.5603s	
7329/11350 (epoch 32.286), train_loss = 0.79416416, grad/param norm = 3.6933e-01, time/batch = 16.7686s	
7330/11350 (epoch 32.291), train_loss = 0.63300694, grad/param norm = 3.6293e-01, time/batch = 16.7075s	
7331/11350 (epoch 32.295), train_loss = 0.71709038, grad/param norm = 3.4234e-01, time/batch = 16.3796s	
7332/11350 (epoch 32.300), train_loss = 0.76195751, grad/param norm = 3.3447e-01, time/batch = 17.4216s	
7333/11350 (epoch 32.304), train_loss = 0.63121396, grad/param norm = 2.9968e-01, time/batch = 16.4777s	
7334/11350 (epoch 32.308), train_loss = 0.62950757, grad/param norm = 3.3227e-01, time/batch = 16.7801s	
7335/11350 (epoch 32.313), train_loss = 0.70162027, grad/param norm = 3.1226e-01, time/batch = 16.4690s	
7336/11350 (epoch 32.317), train_loss = 0.66762786, grad/param norm = 2.6830e-01, time/batch = 16.7929s	
7337/11350 (epoch 32.322), train_loss = 0.67671449, grad/param norm = 3.1240e-01, time/batch = 16.6306s	
7338/11350 (epoch 32.326), train_loss = 0.70883787, grad/param norm = 3.3471e-01, time/batch = 16.8698s	
7339/11350 (epoch 32.330), train_loss = 0.57160883, grad/param norm = 3.0355e-01, time/batch = 16.3111s	
7340/11350 (epoch 32.335), train_loss = 0.47458602, grad/param norm = 3.1115e-01, time/batch = 16.9398s	
7341/11350 (epoch 32.339), train_loss = 0.52608520, grad/param norm = 3.5720e-01, time/batch = 16.8652s	
7342/11350 (epoch 32.344), train_loss = 0.63917326, grad/param norm = 2.8079e-01, time/batch = 16.5520s	
7343/11350 (epoch 32.348), train_loss = 0.62683752, grad/param norm = 2.7924e-01, time/batch = 17.2409s	
7344/11350 (epoch 32.352), train_loss = 0.52758031, grad/param norm = 2.6057e-01, time/batch = 16.8601s	
7345/11350 (epoch 32.357), train_loss = 0.65740688, grad/param norm = 3.2615e-01, time/batch = 16.8734s	
7346/11350 (epoch 32.361), train_loss = 0.53655215, grad/param norm = 2.5480e-01, time/batch = 16.5639s	
7347/11350 (epoch 32.366), train_loss = 0.69083404, grad/param norm = 4.1151e-01, time/batch = 16.2984s	
7348/11350 (epoch 32.370), train_loss = 0.59874091, grad/param norm = 4.6097e-01, time/batch = 17.1018s	
7349/11350 (epoch 32.374), train_loss = 0.62068095, grad/param norm = 2.8339e-01, time/batch = 16.6912s	
7350/11350 (epoch 32.379), train_loss = 0.62489058, grad/param norm = 3.1815e-01, time/batch = 16.5561s	
7351/11350 (epoch 32.383), train_loss = 0.57265652, grad/param norm = 2.9653e-01, time/batch = 16.3783s	
7352/11350 (epoch 32.388), train_loss = 0.65912029, grad/param norm = 4.5402e-01, time/batch = 16.6972s	
7353/11350 (epoch 32.392), train_loss = 0.70988295, grad/param norm = 3.2171e-01, time/batch = 16.4729s	
7354/11350 (epoch 32.396), train_loss = 0.65476618, grad/param norm = 4.1291e-01, time/batch = 16.2993s	
7355/11350 (epoch 32.401), train_loss = 0.65813090, grad/param norm = 3.9584e-01, time/batch = 17.1686s	
7356/11350 (epoch 32.405), train_loss = 0.82284548, grad/param norm = 3.1645e-01, time/batch = 16.1490s	
7357/11350 (epoch 32.410), train_loss = 0.83725178, grad/param norm = 3.5318e-01, time/batch = 16.4808s	
7358/11350 (epoch 32.414), train_loss = 0.60047197, grad/param norm = 2.9957e-01, time/batch = 16.5202s	
7359/11350 (epoch 32.419), train_loss = 0.59419631, grad/param norm = 3.0240e-01, time/batch = 16.7748s	
7360/11350 (epoch 32.423), train_loss = 0.64269321, grad/param norm = 3.3055e-01, time/batch = 16.3848s	
7361/11350 (epoch 32.427), train_loss = 0.73030542, grad/param norm = 3.7096e-01, time/batch = 16.3881s	
7362/11350 (epoch 32.432), train_loss = 0.68364440, grad/param norm = 3.1194e-01, time/batch = 16.2900s	
7363/11350 (epoch 32.436), train_loss = 0.62434992, grad/param norm = 3.0854e-01, time/batch = 17.0275s	
7364/11350 (epoch 32.441), train_loss = 0.77867475, grad/param norm = 3.4572e-01, time/batch = 16.4700s	
7365/11350 (epoch 32.445), train_loss = 0.61202300, grad/param norm = 3.1866e-01, time/batch = 16.6038s	
7366/11350 (epoch 32.449), train_loss = 0.69329928, grad/param norm = 3.1620e-01, time/batch = 26.3049s	
7367/11350 (epoch 32.454), train_loss = 0.81846295, grad/param norm = 3.6442e-01, time/batch = 22.3071s	
7368/11350 (epoch 32.458), train_loss = 0.57780812, grad/param norm = 3.0065e-01, time/batch = 16.3174s	
7369/11350 (epoch 32.463), train_loss = 0.57234207, grad/param norm = 2.6418e-01, time/batch = 16.8649s	
7370/11350 (epoch 32.467), train_loss = 0.91363568, grad/param norm = 4.0457e-01, time/batch = 16.7268s	
7371/11350 (epoch 32.471), train_loss = 0.81807119, grad/param norm = 5.1154e-01, time/batch = 16.6198s	
7372/11350 (epoch 32.476), train_loss = 0.72593020, grad/param norm = 3.0313e-01, time/batch = 16.6256s	
7373/11350 (epoch 32.480), train_loss = 0.80705087, grad/param norm = 3.6871e-01, time/batch = 16.5499s	
7374/11350 (epoch 32.485), train_loss = 0.72536320, grad/param norm = 3.4399e-01, time/batch = 16.5561s	
7375/11350 (epoch 32.489), train_loss = 0.80810840, grad/param norm = 3.9769e-01, time/batch = 16.6342s	
7376/11350 (epoch 32.493), train_loss = 0.81721913, grad/param norm = 3.7827e-01, time/batch = 17.4003s	
7377/11350 (epoch 32.498), train_loss = 0.52602923, grad/param norm = 3.0294e-01, time/batch = 16.6444s	
7378/11350 (epoch 32.502), train_loss = 0.81324012, grad/param norm = 3.2085e-01, time/batch = 16.7195s	
7379/11350 (epoch 32.507), train_loss = 0.61251265, grad/param norm = 2.7769e-01, time/batch = 17.1719s	
7380/11350 (epoch 32.511), train_loss = 0.76548425, grad/param norm = 2.8384e-01, time/batch = 16.9423s	
7381/11350 (epoch 32.515), train_loss = 0.70498450, grad/param norm = 3.3797e-01, time/batch = 16.9488s	
7382/11350 (epoch 32.520), train_loss = 0.87961064, grad/param norm = 3.9635e-01, time/batch = 16.7877s	
7383/11350 (epoch 32.524), train_loss = 0.74193056, grad/param norm = 3.0339e-01, time/batch = 17.1863s	
7384/11350 (epoch 32.529), train_loss = 0.69425631, grad/param norm = 3.1478e-01, time/batch = 16.6337s	
7385/11350 (epoch 32.533), train_loss = 0.86545819, grad/param norm = 3.1625e-01, time/batch = 17.0857s	
7386/11350 (epoch 32.537), train_loss = 0.81728784, grad/param norm = 3.3502e-01, time/batch = 16.5442s	
7387/11350 (epoch 32.542), train_loss = 0.72653394, grad/param norm = 2.8816e-01, time/batch = 16.9926s	
7388/11350 (epoch 32.546), train_loss = 0.91401892, grad/param norm = 4.4598e-01, time/batch = 17.1497s	
7389/11350 (epoch 32.551), train_loss = 0.78043851, grad/param norm = 3.8472e-01, time/batch = 17.0585s	
7390/11350 (epoch 32.555), train_loss = 0.66931294, grad/param norm = 3.1502e-01, time/batch = 17.3183s	
7391/11350 (epoch 32.559), train_loss = 0.70198320, grad/param norm = 2.8810e-01, time/batch = 16.5585s	
7392/11350 (epoch 32.564), train_loss = 0.76541992, grad/param norm = 3.7738e-01, time/batch = 16.5642s	
7393/11350 (epoch 32.568), train_loss = 0.79709082, grad/param norm = 3.3778e-01, time/batch = 16.6972s	
7394/11350 (epoch 32.573), train_loss = 0.88286667, grad/param norm = 3.7789e-01, time/batch = 17.5073s	
7395/11350 (epoch 32.577), train_loss = 0.83124326, grad/param norm = 4.0154e-01, time/batch = 16.3956s	
7396/11350 (epoch 32.581), train_loss = 0.85862539, grad/param norm = 3.2675e-01, time/batch = 16.6455s	
7397/11350 (epoch 32.586), train_loss = 0.82718531, grad/param norm = 3.2351e-01, time/batch = 16.6245s	
7398/11350 (epoch 32.590), train_loss = 0.90334432, grad/param norm = 3.9901e-01, time/batch = 16.4675s	
7399/11350 (epoch 32.595), train_loss = 0.94077341, grad/param norm = 3.5199e-01, time/batch = 16.9565s	
7400/11350 (epoch 32.599), train_loss = 0.80028874, grad/param norm = 3.3006e-01, time/batch = 16.2268s	
7401/11350 (epoch 32.604), train_loss = 0.76359385, grad/param norm = 3.3554e-01, time/batch = 16.7887s	
7402/11350 (epoch 32.608), train_loss = 0.72219610, grad/param norm = 3.3973e-01, time/batch = 16.4819s	
7403/11350 (epoch 32.612), train_loss = 0.77771350, grad/param norm = 3.2066e-01, time/batch = 16.6365s	
7404/11350 (epoch 32.617), train_loss = 0.82774975, grad/param norm = 3.4656e-01, time/batch = 17.2379s	
7405/11350 (epoch 32.621), train_loss = 0.84546931, grad/param norm = 3.1197e-01, time/batch = 16.7016s	
7406/11350 (epoch 32.626), train_loss = 0.77573477, grad/param norm = 3.1117e-01, time/batch = 16.9481s	
7407/11350 (epoch 32.630), train_loss = 0.77836239, grad/param norm = 3.2839e-01, time/batch = 16.7877s	
7408/11350 (epoch 32.634), train_loss = 0.76365010, grad/param norm = 3.0127e-01, time/batch = 16.8565s	
7409/11350 (epoch 32.639), train_loss = 0.68860801, grad/param norm = 2.9063e-01, time/batch = 16.6347s	
7410/11350 (epoch 32.643), train_loss = 0.65397586, grad/param norm = 3.2432e-01, time/batch = 16.1985s	
7411/11350 (epoch 32.648), train_loss = 0.73641793, grad/param norm = 3.1017e-01, time/batch = 16.6158s	
7412/11350 (epoch 32.652), train_loss = 0.67027290, grad/param norm = 3.3537e-01, time/batch = 16.3679s	
7413/11350 (epoch 32.656), train_loss = 0.77691154, grad/param norm = 2.9834e-01, time/batch = 17.5158s	
7414/11350 (epoch 32.661), train_loss = 0.80194045, grad/param norm = 3.1136e-01, time/batch = 16.2269s	
7415/11350 (epoch 32.665), train_loss = 0.79462986, grad/param norm = 3.5756e-01, time/batch = 16.7038s	
7416/11350 (epoch 32.670), train_loss = 0.75855525, grad/param norm = 3.0342e-01, time/batch = 16.3827s	
7417/11350 (epoch 32.674), train_loss = 0.74126030, grad/param norm = 3.3525e-01, time/batch = 16.9414s	
7418/11350 (epoch 32.678), train_loss = 0.78555272, grad/param norm = 3.0284e-01, time/batch = 16.1348s	
7419/11350 (epoch 32.683), train_loss = 0.70412797, grad/param norm = 4.1988e-01, time/batch = 16.6145s	
7420/11350 (epoch 32.687), train_loss = 0.67260340, grad/param norm = 3.6460e-01, time/batch = 17.1087s	
7421/11350 (epoch 32.692), train_loss = 0.99336367, grad/param norm = 3.8001e-01, time/batch = 16.5373s	
7422/11350 (epoch 32.696), train_loss = 0.93600928, grad/param norm = 3.7409e-01, time/batch = 16.7088s	
7423/11350 (epoch 32.700), train_loss = 0.83972688, grad/param norm = 3.2633e-01, time/batch = 16.7223s	
7424/11350 (epoch 32.705), train_loss = 0.90586452, grad/param norm = 4.8874e-01, time/batch = 16.4574s	
7425/11350 (epoch 32.709), train_loss = 0.88862625, grad/param norm = 3.7049e-01, time/batch = 16.3853s	
7426/11350 (epoch 32.714), train_loss = 0.80005135, grad/param norm = 3.3431e-01, time/batch = 16.8735s	
7427/11350 (epoch 32.718), train_loss = 0.66714548, grad/param norm = 2.8018e-01, time/batch = 16.9980s	
7428/11350 (epoch 32.722), train_loss = 0.78153792, grad/param norm = 4.2307e-01, time/batch = 16.4820s	
7429/11350 (epoch 32.727), train_loss = 0.78484829, grad/param norm = 3.2436e-01, time/batch = 16.5441s	
7430/11350 (epoch 32.731), train_loss = 0.77720936, grad/param norm = 3.4242e-01, time/batch = 16.7087s	
7431/11350 (epoch 32.736), train_loss = 0.70021336, grad/param norm = 3.8166e-01, time/batch = 16.5579s	
7432/11350 (epoch 32.740), train_loss = 0.76147124, grad/param norm = 3.0809e-01, time/batch = 16.1521s	
7433/11350 (epoch 32.744), train_loss = 0.76095282, grad/param norm = 3.6585e-01, time/batch = 16.6176s	
7434/11350 (epoch 32.749), train_loss = 0.75381101, grad/param norm = 3.2961e-01, time/batch = 17.1635s	
7435/11350 (epoch 32.753), train_loss = 0.83019738, grad/param norm = 3.9155e-01, time/batch = 16.6912s	
7436/11350 (epoch 32.758), train_loss = 0.73514723, grad/param norm = 3.1872e-01, time/batch = 16.3698s	
7437/11350 (epoch 32.762), train_loss = 0.87139909, grad/param norm = 3.0076e-01, time/batch = 16.7835s	
7438/11350 (epoch 32.767), train_loss = 0.86618985, grad/param norm = 2.9574e-01, time/batch = 16.2254s	
7439/11350 (epoch 32.771), train_loss = 0.96793889, grad/param norm = 3.5884e-01, time/batch = 16.6272s	
7440/11350 (epoch 32.775), train_loss = 0.79133314, grad/param norm = 3.3294e-01, time/batch = 16.7776s	
7441/11350 (epoch 32.780), train_loss = 0.84711495, grad/param norm = 3.0686e-01, time/batch = 16.3926s	
7442/11350 (epoch 32.784), train_loss = 0.76195720, grad/param norm = 3.4073e-01, time/batch = 16.2214s	
7443/11350 (epoch 32.789), train_loss = 0.78192995, grad/param norm = 3.2032e-01, time/batch = 16.3072s	
7444/11350 (epoch 32.793), train_loss = 0.86589068, grad/param norm = 2.9924e-01, time/batch = 17.0219s	
7445/11350 (epoch 32.797), train_loss = 0.77344074, grad/param norm = 3.0641e-01, time/batch = 16.3920s	
7446/11350 (epoch 32.802), train_loss = 0.81449438, grad/param norm = 3.2635e-01, time/batch = 16.6392s	
7447/11350 (epoch 32.806), train_loss = 0.83387216, grad/param norm = 3.0712e-01, time/batch = 17.4152s	
7448/11350 (epoch 32.811), train_loss = 0.80140204, grad/param norm = 3.0773e-01, time/batch = 16.4658s	
7449/11350 (epoch 32.815), train_loss = 0.76948328, grad/param norm = 3.0898e-01, time/batch = 16.6944s	
7450/11350 (epoch 32.819), train_loss = 0.69340247, grad/param norm = 3.0441e-01, time/batch = 16.5500s	
7451/11350 (epoch 32.824), train_loss = 0.68320454, grad/param norm = 3.1646e-01, time/batch = 17.1794s	
7452/11350 (epoch 32.828), train_loss = 0.72104530, grad/param norm = 3.1264e-01, time/batch = 16.4706s	
7453/11350 (epoch 32.833), train_loss = 0.74014947, grad/param norm = 2.8148e-01, time/batch = 16.7874s	
7454/11350 (epoch 32.837), train_loss = 0.79019488, grad/param norm = 3.5418e-01, time/batch = 16.7794s	
7455/11350 (epoch 32.841), train_loss = 1.02734521, grad/param norm = 3.5799e-01, time/batch = 16.5968s	
7456/11350 (epoch 32.846), train_loss = 0.82841809, grad/param norm = 3.0208e-01, time/batch = 16.3973s	
7457/11350 (epoch 32.850), train_loss = 0.85728809, grad/param norm = 3.5941e-01, time/batch = 16.7097s	
7458/11350 (epoch 32.855), train_loss = 0.67493225, grad/param norm = 3.3128e-01, time/batch = 17.0004s	
7459/11350 (epoch 32.859), train_loss = 0.72133444, grad/param norm = 3.4444e-01, time/batch = 16.6133s	
7460/11350 (epoch 32.863), train_loss = 0.67518927, grad/param norm = 2.8809e-01, time/batch = 16.6315s	
7461/11350 (epoch 32.868), train_loss = 0.68718661, grad/param norm = 2.9512e-01, time/batch = 16.8727s	
7462/11350 (epoch 32.872), train_loss = 0.72793658, grad/param norm = 3.1683e-01, time/batch = 17.1243s	
7463/11350 (epoch 32.877), train_loss = 0.73427237, grad/param norm = 3.8500e-01, time/batch = 16.2258s	
7464/11350 (epoch 32.881), train_loss = 0.92494710, grad/param norm = 3.4655e-01, time/batch = 16.3149s	
7465/11350 (epoch 32.885), train_loss = 0.87747347, grad/param norm = 3.3315e-01, time/batch = 16.6264s	
7466/11350 (epoch 32.890), train_loss = 0.78186694, grad/param norm = 3.0160e-01, time/batch = 16.7815s	
7467/11350 (epoch 32.894), train_loss = 0.66902063, grad/param norm = 3.1497e-01, time/batch = 16.7852s	
7468/11350 (epoch 32.899), train_loss = 0.82898768, grad/param norm = 3.0263e-01, time/batch = 16.0646s	
7469/11350 (epoch 32.903), train_loss = 0.80270034, grad/param norm = 3.5773e-01, time/batch = 16.3796s	
7470/11350 (epoch 32.907), train_loss = 0.72527348, grad/param norm = 2.9914e-01, time/batch = 16.3073s	
7471/11350 (epoch 32.912), train_loss = 0.69587636, grad/param norm = 2.9113e-01, time/batch = 17.5751s	
7472/11350 (epoch 32.916), train_loss = 0.80133429, grad/param norm = 3.2153e-01, time/batch = 16.6116s	
7473/11350 (epoch 32.921), train_loss = 0.80099749, grad/param norm = 3.0220e-01, time/batch = 16.6297s	
7474/11350 (epoch 32.925), train_loss = 0.67026944, grad/param norm = 2.5582e-01, time/batch = 16.7439s	
7475/11350 (epoch 32.930), train_loss = 0.80540868, grad/param norm = 3.6749e-01, time/batch = 16.3834s	
7476/11350 (epoch 32.934), train_loss = 0.91001369, grad/param norm = 3.5903e-01, time/batch = 16.7837s	
7477/11350 (epoch 32.938), train_loss = 0.75932831, grad/param norm = 3.3766e-01, time/batch = 16.2329s	
7478/11350 (epoch 32.943), train_loss = 0.84692362, grad/param norm = 3.0134e-01, time/batch = 16.5616s	
7479/11350 (epoch 32.947), train_loss = 0.81777386, grad/param norm = 4.2383e-01, time/batch = 16.6256s	
7480/11350 (epoch 32.952), train_loss = 0.81903239, grad/param norm = 4.0451e-01, time/batch = 17.1299s	
7481/11350 (epoch 32.956), train_loss = 0.64869661, grad/param norm = 2.8579e-01, time/batch = 16.3891s	
7482/11350 (epoch 32.960), train_loss = 0.73907632, grad/param norm = 3.6745e-01, time/batch = 16.6417s	
7483/11350 (epoch 32.965), train_loss = 0.65212687, grad/param norm = 3.0030e-01, time/batch = 17.1636s	
7484/11350 (epoch 32.969), train_loss = 0.67501721, grad/param norm = 3.6651e-01, time/batch = 17.5032s	
7485/11350 (epoch 32.974), train_loss = 0.65698875, grad/param norm = 3.1208e-01, time/batch = 17.3312s	
7486/11350 (epoch 32.978), train_loss = 0.73651745, grad/param norm = 3.0254e-01, time/batch = 17.1551s	
7487/11350 (epoch 32.982), train_loss = 0.51171930, grad/param norm = 2.6799e-01, time/batch = 17.0988s	
7488/11350 (epoch 32.987), train_loss = 0.75193876, grad/param norm = 3.6430e-01, time/batch = 16.8154s	
7489/11350 (epoch 32.991), train_loss = 0.66727797, grad/param norm = 4.0502e-01, time/batch = 17.4216s	
7490/11350 (epoch 32.996), train_loss = 0.73079441, grad/param norm = 3.4261e-01, time/batch = 16.7850s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
7491/11350 (epoch 33.000), train_loss = 0.58821385, grad/param norm = 2.9365e-01, time/batch = 16.3840s	
7492/11350 (epoch 33.004), train_loss = 0.78822908, grad/param norm = 3.1327e-01, time/batch = 16.4617s	
7493/11350 (epoch 33.009), train_loss = 0.77483170, grad/param norm = 3.2962e-01, time/batch = 16.4591s	
7494/11350 (epoch 33.013), train_loss = 0.55339977, grad/param norm = 3.1167e-01, time/batch = 17.0211s	
7495/11350 (epoch 33.018), train_loss = 0.59926066, grad/param norm = 3.1046e-01, time/batch = 16.7196s	
7496/11350 (epoch 33.022), train_loss = 0.63353813, grad/param norm = 4.1721e-01, time/batch = 16.5385s	
7497/11350 (epoch 33.026), train_loss = 0.58695206, grad/param norm = 2.9602e-01, time/batch = 16.5389s	
7498/11350 (epoch 33.031), train_loss = 0.63868029, grad/param norm = 2.9600e-01, time/batch = 16.3082s	
7499/11350 (epoch 33.035), train_loss = 0.64699830, grad/param norm = 3.4740e-01, time/batch = 16.4621s	
7500/11350 (epoch 33.040), train_loss = 0.68385135, grad/param norm = 3.5726e-01, time/batch = 16.0657s	
7501/11350 (epoch 33.044), train_loss = 0.62658899, grad/param norm = 2.7266e-01, time/batch = 16.9340s	
7502/11350 (epoch 33.048), train_loss = 0.60480901, grad/param norm = 2.9647e-01, time/batch = 16.3693s	
7503/11350 (epoch 33.053), train_loss = 0.66221667, grad/param norm = 2.9305e-01, time/batch = 17.4056s	
7504/11350 (epoch 33.057), train_loss = 0.65807077, grad/param norm = 3.3431e-01, time/batch = 17.2150s	
7505/11350 (epoch 33.062), train_loss = 0.56623374, grad/param norm = 2.8973e-01, time/batch = 16.5606s	
7506/11350 (epoch 33.066), train_loss = 0.54955738, grad/param norm = 2.8446e-01, time/batch = 16.4712s	
7507/11350 (epoch 33.070), train_loss = 0.64560749, grad/param norm = 3.3286e-01, time/batch = 16.4504s	
7508/11350 (epoch 33.075), train_loss = 0.58367498, grad/param norm = 3.0257e-01, time/batch = 17.0921s	
7509/11350 (epoch 33.079), train_loss = 0.69280866, grad/param norm = 3.3812e-01, time/batch = 16.4633s	
7510/11350 (epoch 33.084), train_loss = 0.82839864, grad/param norm = 3.8408e-01, time/batch = 16.4617s	
7511/11350 (epoch 33.088), train_loss = 0.73462994, grad/param norm = 3.4481e-01, time/batch = 16.6015s	
7512/11350 (epoch 33.093), train_loss = 0.75099847, grad/param norm = 3.2644e-01, time/batch = 16.8631s	
7513/11350 (epoch 33.097), train_loss = 0.67823109, grad/param norm = 3.2838e-01, time/batch = 17.2482s	
7514/11350 (epoch 33.101), train_loss = 0.64627209, grad/param norm = 3.3157e-01, time/batch = 16.5516s	
7515/11350 (epoch 33.106), train_loss = 0.71876344, grad/param norm = 4.2423e-01, time/batch = 16.5563s	
7516/11350 (epoch 33.110), train_loss = 0.63647767, grad/param norm = 3.0628e-01, time/batch = 16.5417s	
7517/11350 (epoch 33.115), train_loss = 0.65285460, grad/param norm = 3.3037e-01, time/batch = 16.2348s	
7518/11350 (epoch 33.119), train_loss = 0.75400328, grad/param norm = 3.7289e-01, time/batch = 16.3080s	
7519/11350 (epoch 33.123), train_loss = 0.63314610, grad/param norm = 3.2308e-01, time/batch = 16.7982s	
7520/11350 (epoch 33.128), train_loss = 0.56240923, grad/param norm = 3.2439e-01, time/batch = 16.6081s	
7521/11350 (epoch 33.132), train_loss = 0.61258784, grad/param norm = 2.8748e-01, time/batch = 16.7011s	
7522/11350 (epoch 33.137), train_loss = 0.59787362, grad/param norm = 3.0636e-01, time/batch = 16.7076s	
7523/11350 (epoch 33.141), train_loss = 0.77299118, grad/param norm = 3.2413e-01, time/batch = 16.5494s	
7524/11350 (epoch 33.145), train_loss = 0.63022613, grad/param norm = 3.4701e-01, time/batch = 17.0474s	
7525/11350 (epoch 33.150), train_loss = 0.70572133, grad/param norm = 5.1085e-01, time/batch = 16.6406s	
7526/11350 (epoch 33.154), train_loss = 0.82268387, grad/param norm = 4.4342e-01, time/batch = 17.3456s	
7527/11350 (epoch 33.159), train_loss = 0.60977534, grad/param norm = 3.4122e-01, time/batch = 16.4761s	
7528/11350 (epoch 33.163), train_loss = 0.73715028, grad/param norm = 3.6572e-01, time/batch = 16.8000s	
7529/11350 (epoch 33.167), train_loss = 0.78035498, grad/param norm = 2.9992e-01, time/batch = 16.4637s	
7530/11350 (epoch 33.172), train_loss = 0.83997795, grad/param norm = 3.0327e-01, time/batch = 16.2247s	
7531/11350 (epoch 33.176), train_loss = 0.67751282, grad/param norm = 3.5092e-01, time/batch = 16.3055s	
7532/11350 (epoch 33.181), train_loss = 0.70766605, grad/param norm = 3.1953e-01, time/batch = 16.3828s	
7533/11350 (epoch 33.185), train_loss = 0.61272879, grad/param norm = 2.7716e-01, time/batch = 17.1161s	
7534/11350 (epoch 33.189), train_loss = 0.67034331, grad/param norm = 2.9302e-01, time/batch = 16.3752s	
7535/11350 (epoch 33.194), train_loss = 0.59937619, grad/param norm = 3.5233e-01, time/batch = 16.2130s	
7536/11350 (epoch 33.198), train_loss = 0.57210313, grad/param norm = 3.3770e-01, time/batch = 16.9292s	
7537/11350 (epoch 33.203), train_loss = 0.60748099, grad/param norm = 2.7415e-01, time/batch = 17.2623s	
7538/11350 (epoch 33.207), train_loss = 0.58336014, grad/param norm = 4.6440e-01, time/batch = 16.9191s	
7539/11350 (epoch 33.211), train_loss = 0.77507807, grad/param norm = 4.2860e-01, time/batch = 16.3797s	
7540/11350 (epoch 33.216), train_loss = 0.73069812, grad/param norm = 3.1675e-01, time/batch = 16.6154s	
7541/11350 (epoch 33.220), train_loss = 0.71422352, grad/param norm = 3.3211e-01, time/batch = 16.5534s	
7542/11350 (epoch 33.225), train_loss = 0.64574624, grad/param norm = 2.7245e-01, time/batch = 16.8745s	
7543/11350 (epoch 33.229), train_loss = 0.71991146, grad/param norm = 2.9050e-01, time/batch = 16.4792s	
7544/11350 (epoch 33.233), train_loss = 0.67598800, grad/param norm = 3.6372e-01, time/batch = 17.1908s	
7545/11350 (epoch 33.238), train_loss = 0.81960695, grad/param norm = 4.6240e-01, time/batch = 16.5529s	
7546/11350 (epoch 33.242), train_loss = 0.79076227, grad/param norm = 4.0195e-01, time/batch = 16.8847s	
7547/11350 (epoch 33.247), train_loss = 0.58997097, grad/param norm = 2.7265e-01, time/batch = 16.6346s	
7548/11350 (epoch 33.251), train_loss = 0.69162555, grad/param norm = 2.9070e-01, time/batch = 16.6187s	
7549/11350 (epoch 33.256), train_loss = 0.69654414, grad/param norm = 2.9420e-01, time/batch = 16.5587s	
7550/11350 (epoch 33.260), train_loss = 0.64046477, grad/param norm = 2.8479e-01, time/batch = 16.3884s	
7551/11350 (epoch 33.264), train_loss = 0.61192607, grad/param norm = 3.1180e-01, time/batch = 17.1935s	
7552/11350 (epoch 33.269), train_loss = 0.66397510, grad/param norm = 2.9949e-01, time/batch = 19.0167s	
7553/11350 (epoch 33.273), train_loss = 0.76657430, grad/param norm = 3.0305e-01, time/batch = 19.5293s	
7554/11350 (epoch 33.278), train_loss = 0.65158814, grad/param norm = 3.1274e-01, time/batch = 17.1056s	
7555/11350 (epoch 33.282), train_loss = 0.65867615, grad/param norm = 3.2147e-01, time/batch = 16.8879s	
7556/11350 (epoch 33.286), train_loss = 0.75239039, grad/param norm = 3.2947e-01, time/batch = 16.5449s	
7557/11350 (epoch 33.291), train_loss = 0.61381358, grad/param norm = 3.0730e-01, time/batch = 16.4600s	
7558/11350 (epoch 33.295), train_loss = 0.68439069, grad/param norm = 3.0518e-01, time/batch = 17.1967s	
7559/11350 (epoch 33.300), train_loss = 0.76655552, grad/param norm = 3.8033e-01, time/batch = 16.1427s	
7560/11350 (epoch 33.304), train_loss = 0.61517058, grad/param norm = 3.0120e-01, time/batch = 16.6026s	
7561/11350 (epoch 33.308), train_loss = 0.59869743, grad/param norm = 3.1668e-01, time/batch = 16.6037s	
7562/11350 (epoch 33.313), train_loss = 0.68854740, grad/param norm = 2.9714e-01, time/batch = 2.9401s	
7563/11350 (epoch 33.317), train_loss = 0.65125365, grad/param norm = 2.8717e-01, time/batch = 0.7397s	
7564/11350 (epoch 33.322), train_loss = 0.65204668, grad/param norm = 2.9571e-01, time/batch = 0.7355s	
7565/11350 (epoch 33.326), train_loss = 0.67957410, grad/param norm = 3.0567e-01, time/batch = 0.7462s	
7566/11350 (epoch 33.330), train_loss = 0.56111575, grad/param norm = 2.6548e-01, time/batch = 0.7528s	
7567/11350 (epoch 33.335), train_loss = 0.45301730, grad/param norm = 2.7654e-01, time/batch = 0.7555s	
7568/11350 (epoch 33.339), train_loss = 0.51632542, grad/param norm = 3.1194e-01, time/batch = 0.8063s	
7569/11350 (epoch 33.344), train_loss = 0.62004801, grad/param norm = 3.2326e-01, time/batch = 1.0766s	
7570/11350 (epoch 33.348), train_loss = 0.62312634, grad/param norm = 2.8753e-01, time/batch = 1.0760s	
7571/11350 (epoch 33.352), train_loss = 0.53487739, grad/param norm = 2.6179e-01, time/batch = 1.0804s	
7572/11350 (epoch 33.357), train_loss = 0.63123390, grad/param norm = 2.9959e-01, time/batch = 1.0822s	
7573/11350 (epoch 33.361), train_loss = 0.50607153, grad/param norm = 2.2628e-01, time/batch = 1.6333s	
7574/11350 (epoch 33.366), train_loss = 0.65110732, grad/param norm = 3.5331e-01, time/batch = 2.0047s	
7575/11350 (epoch 33.370), train_loss = 0.56729967, grad/param norm = 3.3381e-01, time/batch = 3.2795s	
7576/11350 (epoch 33.374), train_loss = 0.61006477, grad/param norm = 3.1487e-01, time/batch = 16.5249s	
7577/11350 (epoch 33.379), train_loss = 0.59222579, grad/param norm = 3.1071e-01, time/batch = 16.9500s	
7578/11350 (epoch 33.383), train_loss = 0.54705034, grad/param norm = 3.2042e-01, time/batch = 17.1011s	
7579/11350 (epoch 33.388), train_loss = 0.64521898, grad/param norm = 3.6071e-01, time/batch = 16.4730s	
7580/11350 (epoch 33.392), train_loss = 0.69666494, grad/param norm = 3.0909e-01, time/batch = 16.7687s	
7581/11350 (epoch 33.396), train_loss = 0.64951993, grad/param norm = 4.0467e-01, time/batch = 16.6230s	
7582/11350 (epoch 33.401), train_loss = 0.63035052, grad/param norm = 3.9411e-01, time/batch = 16.0513s	
7583/11350 (epoch 33.405), train_loss = 0.79248052, grad/param norm = 3.5647e-01, time/batch = 16.3867s	
7584/11350 (epoch 33.410), train_loss = 0.83826541, grad/param norm = 4.3505e-01, time/batch = 16.5529s	
7585/11350 (epoch 33.414), train_loss = 0.58378693, grad/param norm = 3.0345e-01, time/batch = 16.4452s	
7586/11350 (epoch 33.419), train_loss = 0.57138558, grad/param norm = 3.1105e-01, time/batch = 16.1424s	
7587/11350 (epoch 33.423), train_loss = 0.63255604, grad/param norm = 3.5462e-01, time/batch = 16.0563s	
7588/11350 (epoch 33.427), train_loss = 0.70348741, grad/param norm = 3.5009e-01, time/batch = 16.3132s	
7589/11350 (epoch 33.432), train_loss = 0.66803393, grad/param norm = 3.6116e-01, time/batch = 16.6187s	
7590/11350 (epoch 33.436), train_loss = 0.61163650, grad/param norm = 3.5795e-01, time/batch = 16.2812s	
7591/11350 (epoch 33.441), train_loss = 0.78130526, grad/param norm = 3.8491e-01, time/batch = 17.0270s	
7592/11350 (epoch 33.445), train_loss = 0.59318117, grad/param norm = 2.6767e-01, time/batch = 22.5436s	
7593/11350 (epoch 33.449), train_loss = 0.67520385, grad/param norm = 3.0235e-01, time/batch = 24.7807s	
7594/11350 (epoch 33.454), train_loss = 0.79950643, grad/param norm = 3.3206e-01, time/batch = 16.0606s	
7595/11350 (epoch 33.458), train_loss = 0.56867585, grad/param norm = 3.0591e-01, time/batch = 16.9405s	
7596/11350 (epoch 33.463), train_loss = 0.58198203, grad/param norm = 3.9007e-01, time/batch = 16.9326s	
7597/11350 (epoch 33.467), train_loss = 0.88445324, grad/param norm = 3.5989e-01, time/batch = 16.3968s	
7598/11350 (epoch 33.471), train_loss = 0.81499897, grad/param norm = 5.4122e-01, time/batch = 16.3088s	
7599/11350 (epoch 33.476), train_loss = 0.71764062, grad/param norm = 3.2664e-01, time/batch = 16.7879s	
7600/11350 (epoch 33.480), train_loss = 0.78464792, grad/param norm = 3.2933e-01, time/batch = 16.7065s	
7601/11350 (epoch 33.485), train_loss = 0.71059434, grad/param norm = 3.0618e-01, time/batch = 17.1749s	
7602/11350 (epoch 33.489), train_loss = 0.77857893, grad/param norm = 3.6972e-01, time/batch = 16.9373s	
7603/11350 (epoch 33.493), train_loss = 0.79812709, grad/param norm = 3.1878e-01, time/batch = 16.3825s	
7604/11350 (epoch 33.498), train_loss = 0.52067365, grad/param norm = 3.3520e-01, time/batch = 16.4579s	
7605/11350 (epoch 33.502), train_loss = 0.80100282, grad/param norm = 3.4858e-01, time/batch = 16.5606s	
7606/11350 (epoch 33.507), train_loss = 0.58516935, grad/param norm = 2.7716e-01, time/batch = 17.1763s	
7607/11350 (epoch 33.511), train_loss = 0.76676313, grad/param norm = 3.2809e-01, time/batch = 16.2353s	
7608/11350 (epoch 33.515), train_loss = 0.68882388, grad/param norm = 3.5517e-01, time/batch = 17.1903s	
7609/11350 (epoch 33.520), train_loss = 0.85362018, grad/param norm = 3.5135e-01, time/batch = 17.0182s	
7610/11350 (epoch 33.524), train_loss = 0.73326041, grad/param norm = 3.8889e-01, time/batch = 16.4657s	
7611/11350 (epoch 33.529), train_loss = 0.67133358, grad/param norm = 3.1335e-01, time/batch = 16.6369s	
7612/11350 (epoch 33.533), train_loss = 0.85647250, grad/param norm = 3.6004e-01, time/batch = 16.3850s	
7613/11350 (epoch 33.537), train_loss = 0.80864863, grad/param norm = 3.2508e-01, time/batch = 16.7816s	
7614/11350 (epoch 33.542), train_loss = 0.70649122, grad/param norm = 2.8457e-01, time/batch = 16.6338s	
7615/11350 (epoch 33.546), train_loss = 0.89082339, grad/param norm = 3.9053e-01, time/batch = 16.5415s	
7616/11350 (epoch 33.551), train_loss = 0.73949598, grad/param norm = 3.3019e-01, time/batch = 16.7906s	
7617/11350 (epoch 33.555), train_loss = 0.67164046, grad/param norm = 3.8788e-01, time/batch = 17.3496s	
7618/11350 (epoch 33.559), train_loss = 0.69677105, grad/param norm = 3.1002e-01, time/batch = 16.4582s	
7619/11350 (epoch 33.564), train_loss = 0.75351362, grad/param norm = 3.2520e-01, time/batch = 16.3880s	
7620/11350 (epoch 33.568), train_loss = 0.76397219, grad/param norm = 3.0648e-01, time/batch = 16.4632s	
7621/11350 (epoch 33.573), train_loss = 0.85934292, grad/param norm = 4.1207e-01, time/batch = 16.9304s	
7622/11350 (epoch 33.577), train_loss = 0.80616496, grad/param norm = 4.6429e-01, time/batch = 16.3159s	
7623/11350 (epoch 33.581), train_loss = 0.84454418, grad/param norm = 3.2225e-01, time/batch = 16.4608s	
7624/11350 (epoch 33.586), train_loss = 0.81650485, grad/param norm = 3.6743e-01, time/batch = 16.5504s	
7625/11350 (epoch 33.590), train_loss = 0.86967439, grad/param norm = 3.7251e-01, time/batch = 16.3945s	
7626/11350 (epoch 33.595), train_loss = 0.93731548, grad/param norm = 3.8040e-01, time/batch = 17.0204s	
7627/11350 (epoch 33.599), train_loss = 0.78446796, grad/param norm = 3.5123e-01, time/batch = 16.6130s	
7628/11350 (epoch 33.604), train_loss = 0.74228358, grad/param norm = 3.4616e-01, time/batch = 16.7025s	
7629/11350 (epoch 33.608), train_loss = 0.70508237, grad/param norm = 3.4972e-01, time/batch = 17.0173s	
7630/11350 (epoch 33.612), train_loss = 0.74743376, grad/param norm = 3.0251e-01, time/batch = 16.4674s	
7631/11350 (epoch 33.617), train_loss = 0.79002048, grad/param norm = 3.1681e-01, time/batch = 16.8663s	
7632/11350 (epoch 33.621), train_loss = 0.83465360, grad/param norm = 2.9940e-01, time/batch = 16.6420s	
7633/11350 (epoch 33.626), train_loss = 0.75692389, grad/param norm = 2.9176e-01, time/batch = 16.0715s	
7634/11350 (epoch 33.630), train_loss = 0.76987724, grad/param norm = 3.5115e-01, time/batch = 16.6097s	
7635/11350 (epoch 33.634), train_loss = 0.76384244, grad/param norm = 3.6117e-01, time/batch = 16.7919s	
7636/11350 (epoch 33.639), train_loss = 0.67703759, grad/param norm = 3.2153e-01, time/batch = 16.3917s	
7637/11350 (epoch 33.643), train_loss = 0.62420038, grad/param norm = 2.9486e-01, time/batch = 16.3900s	
7638/11350 (epoch 33.648), train_loss = 0.70746808, grad/param norm = 2.9440e-01, time/batch = 17.4215s	
7639/11350 (epoch 33.652), train_loss = 0.64570218, grad/param norm = 3.2189e-01, time/batch = 16.8693s	
7640/11350 (epoch 33.656), train_loss = 0.76457779, grad/param norm = 3.5230e-01, time/batch = 16.6923s	
7641/11350 (epoch 33.661), train_loss = 0.78494271, grad/param norm = 3.3252e-01, time/batch = 16.5415s	
7642/11350 (epoch 33.665), train_loss = 0.77533689, grad/param norm = 3.3764e-01, time/batch = 16.5424s	
7643/11350 (epoch 33.670), train_loss = 0.75439076, grad/param norm = 3.1584e-01, time/batch = 16.3098s	
7644/11350 (epoch 33.674), train_loss = 0.70884007, grad/param norm = 2.9674e-01, time/batch = 16.6973s	
7645/11350 (epoch 33.678), train_loss = 0.75898343, grad/param norm = 2.9747e-01, time/batch = 16.8666s	
7646/11350 (epoch 33.683), train_loss = 0.68821804, grad/param norm = 3.4377e-01, time/batch = 16.7111s	
7647/11350 (epoch 33.687), train_loss = 0.64970874, grad/param norm = 3.1776e-01, time/batch = 16.6414s	
7648/11350 (epoch 33.692), train_loss = 0.97404225, grad/param norm = 4.2787e-01, time/batch = 16.4601s	
7649/11350 (epoch 33.696), train_loss = 0.91223931, grad/param norm = 3.4708e-01, time/batch = 16.6128s	
7650/11350 (epoch 33.700), train_loss = 0.82937519, grad/param norm = 3.6282e-01, time/batch = 16.1569s	
7651/11350 (epoch 33.705), train_loss = 0.88067047, grad/param norm = 3.7327e-01, time/batch = 16.6143s	
7652/11350 (epoch 33.709), train_loss = 0.86784382, grad/param norm = 3.4087e-01, time/batch = 16.7962s	
7653/11350 (epoch 33.714), train_loss = 0.76539806, grad/param norm = 3.6026e-01, time/batch = 16.2144s	
7654/11350 (epoch 33.718), train_loss = 0.65937806, grad/param norm = 3.1272e-01, time/batch = 16.3104s	
7655/11350 (epoch 33.722), train_loss = 0.76216453, grad/param norm = 3.8504e-01, time/batch = 16.9298s	
7656/11350 (epoch 33.727), train_loss = 0.77558969, grad/param norm = 3.4085e-01, time/batch = 16.6311s	
7657/11350 (epoch 33.731), train_loss = 0.74515154, grad/param norm = 3.4571e-01, time/batch = 16.7830s	
7658/11350 (epoch 33.736), train_loss = 0.70104144, grad/param norm = 3.8202e-01, time/batch = 17.0981s	
7659/11350 (epoch 33.740), train_loss = 0.76118723, grad/param norm = 3.3560e-01, time/batch = 16.6242s	
7660/11350 (epoch 33.744), train_loss = 0.74359726, grad/param norm = 3.6306e-01, time/batch = 16.1441s	
7661/11350 (epoch 33.749), train_loss = 0.72647341, grad/param norm = 3.2394e-01, time/batch = 16.1427s	
7662/11350 (epoch 33.753), train_loss = 0.79353867, grad/param norm = 3.8082e-01, time/batch = 16.4515s	
7663/11350 (epoch 33.758), train_loss = 0.72933098, grad/param norm = 3.6334e-01, time/batch = 16.6173s	
7664/11350 (epoch 33.762), train_loss = 0.84982927, grad/param norm = 3.2964e-01, time/batch = 16.6180s	
7665/11350 (epoch 33.767), train_loss = 0.83634025, grad/param norm = 2.8772e-01, time/batch = 16.8638s	
7666/11350 (epoch 33.771), train_loss = 0.94514216, grad/param norm = 3.5985e-01, time/batch = 16.1382s	
7667/11350 (epoch 33.775), train_loss = 0.77378693, grad/param norm = 3.2557e-01, time/batch = 17.1057s	
7668/11350 (epoch 33.780), train_loss = 0.82478319, grad/param norm = 2.9435e-01, time/batch = 16.4702s	
7669/11350 (epoch 33.784), train_loss = 0.73518685, grad/param norm = 2.9663e-01, time/batch = 16.4569s	
7670/11350 (epoch 33.789), train_loss = 0.75533276, grad/param norm = 3.2608e-01, time/batch = 16.4585s	
7671/11350 (epoch 33.793), train_loss = 0.84588232, grad/param norm = 3.3194e-01, time/batch = 16.2220s	
7672/11350 (epoch 33.797), train_loss = 0.74620144, grad/param norm = 2.6953e-01, time/batch = 16.5487s	
7673/11350 (epoch 33.802), train_loss = 0.78156424, grad/param norm = 3.0426e-01, time/batch = 16.2235s	
7674/11350 (epoch 33.806), train_loss = 0.81844869, grad/param norm = 3.4326e-01, time/batch = 16.9414s	
7675/11350 (epoch 33.811), train_loss = 0.76807969, grad/param norm = 3.0545e-01, time/batch = 16.2298s	
7676/11350 (epoch 33.815), train_loss = 0.74450898, grad/param norm = 3.0219e-01, time/batch = 16.3932s	
7677/11350 (epoch 33.819), train_loss = 0.66828309, grad/param norm = 2.8837e-01, time/batch = 16.5551s	
7678/11350 (epoch 33.824), train_loss = 0.66842506, grad/param norm = 3.3368e-01, time/batch = 16.3723s	
7679/11350 (epoch 33.828), train_loss = 0.69880234, grad/param norm = 3.0039e-01, time/batch = 16.1478s	
7680/11350 (epoch 33.833), train_loss = 0.73019190, grad/param norm = 3.1910e-01, time/batch = 16.7118s	
7681/11350 (epoch 33.837), train_loss = 0.77036441, grad/param norm = 3.2509e-01, time/batch = 17.4053s	
7682/11350 (epoch 33.841), train_loss = 1.00177277, grad/param norm = 3.7496e-01, time/batch = 16.4688s	
7683/11350 (epoch 33.846), train_loss = 0.81875432, grad/param norm = 2.8760e-01, time/batch = 16.4702s	
7684/11350 (epoch 33.850), train_loss = 0.83349945, grad/param norm = 3.1212e-01, time/batch = 16.1348s	
7685/11350 (epoch 33.855), train_loss = 0.66482520, grad/param norm = 2.9792e-01, time/batch = 16.6236s	
7686/11350 (epoch 33.859), train_loss = 0.70392110, grad/param norm = 3.9418e-01, time/batch = 16.7065s	
7687/11350 (epoch 33.863), train_loss = 0.66419323, grad/param norm = 2.9162e-01, time/batch = 16.3937s	
7688/11350 (epoch 33.868), train_loss = 0.66825137, grad/param norm = 2.8688e-01, time/batch = 16.2942s	
7689/11350 (epoch 33.872), train_loss = 0.70952865, grad/param norm = 3.0156e-01, time/batch = 16.6791s	
7690/11350 (epoch 33.877), train_loss = 0.70715644, grad/param norm = 3.3783e-01, time/batch = 16.2276s	
7691/11350 (epoch 33.881), train_loss = 0.91007440, grad/param norm = 3.7385e-01, time/batch = 16.3136s	
7692/11350 (epoch 33.885), train_loss = 0.85301621, grad/param norm = 3.0079e-01, time/batch = 17.3334s	
7693/11350 (epoch 33.890), train_loss = 0.78223418, grad/param norm = 3.7461e-01, time/batch = 16.1453s	
7694/11350 (epoch 33.894), train_loss = 0.66018966, grad/param norm = 3.1742e-01, time/batch = 16.0558s	
7695/11350 (epoch 33.899), train_loss = 0.80711868, grad/param norm = 3.0499e-01, time/batch = 16.2306s	
7696/11350 (epoch 33.903), train_loss = 0.77311873, grad/param norm = 3.1441e-01, time/batch = 16.7570s	
7697/11350 (epoch 33.907), train_loss = 0.70147343, grad/param norm = 2.8476e-01, time/batch = 16.2246s	
7698/11350 (epoch 33.912), train_loss = 0.68256263, grad/param norm = 2.9629e-01, time/batch = 16.8654s	
7699/11350 (epoch 33.916), train_loss = 0.78835504, grad/param norm = 3.6695e-01, time/batch = 17.0177s	
7700/11350 (epoch 33.921), train_loss = 0.79657947, grad/param norm = 3.0820e-01, time/batch = 16.4647s	
7701/11350 (epoch 33.925), train_loss = 0.65518182, grad/param norm = 2.7941e-01, time/batch = 16.4718s	
7702/11350 (epoch 33.930), train_loss = 0.78165009, grad/param norm = 3.7810e-01, time/batch = 17.1984s	
7703/11350 (epoch 33.934), train_loss = 0.88593507, grad/param norm = 3.5712e-01, time/batch = 16.9440s	
7704/11350 (epoch 33.938), train_loss = 0.75609715, grad/param norm = 3.2826e-01, time/batch = 16.2282s	
7705/11350 (epoch 33.943), train_loss = 0.83107358, grad/param norm = 3.4040e-01, time/batch = 16.7966s	
7706/11350 (epoch 33.947), train_loss = 0.77490463, grad/param norm = 3.1345e-01, time/batch = 16.6907s	
7707/11350 (epoch 33.952), train_loss = 0.80150125, grad/param norm = 3.4307e-01, time/batch = 16.7687s	
7708/11350 (epoch 33.956), train_loss = 0.63765743, grad/param norm = 2.7249e-01, time/batch = 16.5248s	
7709/11350 (epoch 33.960), train_loss = 0.71957758, grad/param norm = 3.6451e-01, time/batch = 15.9835s	
7710/11350 (epoch 33.965), train_loss = 0.63606683, grad/param norm = 3.2824e-01, time/batch = 16.6149s	
7711/11350 (epoch 33.969), train_loss = 0.65533888, grad/param norm = 3.7722e-01, time/batch = 16.6414s	
7712/11350 (epoch 33.974), train_loss = 0.64502664, grad/param norm = 3.5199e-01, time/batch = 16.4761s	
7713/11350 (epoch 33.978), train_loss = 0.72561048, grad/param norm = 3.0249e-01, time/batch = 16.9586s	
7714/11350 (epoch 33.982), train_loss = 0.49787029, grad/param norm = 3.2827e-01, time/batch = 16.7039s	
7715/11350 (epoch 33.987), train_loss = 0.73194701, grad/param norm = 3.0405e-01, time/batch = 16.5463s	
7716/11350 (epoch 33.991), train_loss = 0.63783571, grad/param norm = 3.7702e-01, time/batch = 16.7832s	
7717/11350 (epoch 33.996), train_loss = 0.75151339, grad/param norm = 4.2554e-01, time/batch = 17.1094s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
7718/11350 (epoch 34.000), train_loss = 0.58789461, grad/param norm = 3.5128e-01, time/batch = 16.3874s	
7719/11350 (epoch 34.004), train_loss = 0.79444070, grad/param norm = 3.5108e-01, time/batch = 16.3899s	
7720/11350 (epoch 34.009), train_loss = 0.76343760, grad/param norm = 3.1785e-01, time/batch = 16.4574s	
7721/11350 (epoch 34.013), train_loss = 0.52046430, grad/param norm = 2.8156e-01, time/batch = 17.1000s	
7722/11350 (epoch 34.018), train_loss = 0.59739533, grad/param norm = 3.5531e-01, time/batch = 16.1464s	
7723/11350 (epoch 34.022), train_loss = 0.60407009, grad/param norm = 3.8160e-01, time/batch = 16.6378s	
7724/11350 (epoch 34.026), train_loss = 0.56243843, grad/param norm = 2.8820e-01, time/batch = 16.7741s	
7725/11350 (epoch 34.031), train_loss = 0.61768926, grad/param norm = 3.0222e-01, time/batch = 16.8594s	
7726/11350 (epoch 34.035), train_loss = 0.61790055, grad/param norm = 2.9403e-01, time/batch = 16.4687s	
7727/11350 (epoch 34.040), train_loss = 0.64093590, grad/param norm = 2.9369e-01, time/batch = 16.8768s	
7728/11350 (epoch 34.044), train_loss = 0.60444475, grad/param norm = 2.9528e-01, time/batch = 16.9512s	
7729/11350 (epoch 34.048), train_loss = 0.58813938, grad/param norm = 2.7637e-01, time/batch = 16.3755s	
7730/11350 (epoch 34.053), train_loss = 0.64102791, grad/param norm = 2.9397e-01, time/batch = 16.4796s	
7731/11350 (epoch 34.057), train_loss = 0.64680827, grad/param norm = 3.5394e-01, time/batch = 16.5595s	
7732/11350 (epoch 34.062), train_loss = 0.54840002, grad/param norm = 2.8604e-01, time/batch = 16.6842s	
7733/11350 (epoch 34.066), train_loss = 0.55299487, grad/param norm = 3.0919e-01, time/batch = 16.4829s	
7734/11350 (epoch 34.070), train_loss = 0.61578825, grad/param norm = 2.9505e-01, time/batch = 16.7888s	
7735/11350 (epoch 34.075), train_loss = 0.56073565, grad/param norm = 2.7732e-01, time/batch = 17.0257s	
7736/11350 (epoch 34.079), train_loss = 0.66916516, grad/param norm = 2.9716e-01, time/batch = 16.6215s	
7737/11350 (epoch 34.084), train_loss = 0.79833371, grad/param norm = 3.5926e-01, time/batch = 16.7740s	
7738/11350 (epoch 34.088), train_loss = 0.72996318, grad/param norm = 3.9312e-01, time/batch = 16.8544s	
7739/11350 (epoch 34.093), train_loss = 0.71682968, grad/param norm = 2.9628e-01, time/batch = 16.5387s	
7740/11350 (epoch 34.097), train_loss = 0.66570192, grad/param norm = 2.9986e-01, time/batch = 16.6869s	
7741/11350 (epoch 34.101), train_loss = 0.61415106, grad/param norm = 3.3009e-01, time/batch = 16.5381s	
7742/11350 (epoch 34.106), train_loss = 0.70558289, grad/param norm = 3.4784e-01, time/batch = 16.9345s	
7743/11350 (epoch 34.110), train_loss = 0.61310320, grad/param norm = 3.0986e-01, time/batch = 16.7066s	
7744/11350 (epoch 34.115), train_loss = 0.63390230, grad/param norm = 3.3263e-01, time/batch = 16.3792s	
7745/11350 (epoch 34.119), train_loss = 0.73780744, grad/param norm = 3.5605e-01, time/batch = 16.1484s	
7746/11350 (epoch 34.123), train_loss = 0.59663640, grad/param norm = 3.2909e-01, time/batch = 16.7141s	
7747/11350 (epoch 34.128), train_loss = 0.54591161, grad/param norm = 2.9296e-01, time/batch = 16.3928s	
7748/11350 (epoch 34.132), train_loss = 0.59220491, grad/param norm = 2.5742e-01, time/batch = 16.2148s	
7749/11350 (epoch 34.137), train_loss = 0.58940438, grad/param norm = 3.3861e-01, time/batch = 16.5372s	
7750/11350 (epoch 34.141), train_loss = 0.74894756, grad/param norm = 3.3075e-01, time/batch = 16.6208s	
7751/11350 (epoch 34.145), train_loss = 0.61265764, grad/param norm = 2.9715e-01, time/batch = 16.3949s	
7752/11350 (epoch 34.150), train_loss = 0.68348670, grad/param norm = 3.8947e-01, time/batch = 16.6141s	
7753/11350 (epoch 34.154), train_loss = 0.79794099, grad/param norm = 3.8903e-01, time/batch = 17.0054s	
7754/11350 (epoch 34.159), train_loss = 0.56190973, grad/param norm = 3.3729e-01, time/batch = 16.2943s	
7755/11350 (epoch 34.163), train_loss = 0.73026501, grad/param norm = 4.1538e-01, time/batch = 16.4424s	
7756/11350 (epoch 34.167), train_loss = 0.75078894, grad/param norm = 3.1298e-01, time/batch = 16.3056s	
7757/11350 (epoch 34.172), train_loss = 0.83513473, grad/param norm = 3.3209e-01, time/batch = 16.9294s	
7758/11350 (epoch 34.176), train_loss = 0.67411023, grad/param norm = 3.4005e-01, time/batch = 16.3867s	
7759/11350 (epoch 34.181), train_loss = 0.68993395, grad/param norm = 3.3567e-01, time/batch = 16.3871s	
7760/11350 (epoch 34.185), train_loss = 0.59224287, grad/param norm = 3.1779e-01, time/batch = 17.3308s	
7761/11350 (epoch 34.189), train_loss = 0.64636010, grad/param norm = 3.2218e-01, time/batch = 17.7285s	
7762/11350 (epoch 34.194), train_loss = 0.58043730, grad/param norm = 3.2643e-01, time/batch = 17.4661s	
7763/11350 (epoch 34.198), train_loss = 0.54986595, grad/param norm = 3.3955e-01, time/batch = 16.3830s	
7764/11350 (epoch 34.203), train_loss = 0.58145458, grad/param norm = 2.6586e-01, time/batch = 16.9883s	
7765/11350 (epoch 34.207), train_loss = 0.57370418, grad/param norm = 4.3410e-01, time/batch = 16.2302s	
7766/11350 (epoch 34.211), train_loss = 0.76331829, grad/param norm = 3.6838e-01, time/batch = 16.4663s	
7767/11350 (epoch 34.216), train_loss = 0.70340587, grad/param norm = 2.9414e-01, time/batch = 16.8772s	
7768/11350 (epoch 34.220), train_loss = 0.69972299, grad/param norm = 3.2988e-01, time/batch = 16.8721s	
7769/11350 (epoch 34.225), train_loss = 0.62611361, grad/param norm = 2.6644e-01, time/batch = 16.7111s	
7770/11350 (epoch 34.229), train_loss = 0.69813567, grad/param norm = 3.0184e-01, time/batch = 16.6270s	
7771/11350 (epoch 34.233), train_loss = 0.65649369, grad/param norm = 3.5168e-01, time/batch = 17.1737s	
7772/11350 (epoch 34.238), train_loss = 0.78690464, grad/param norm = 4.0357e-01, time/batch = 16.5425s	
7773/11350 (epoch 34.242), train_loss = 0.77798920, grad/param norm = 3.9255e-01, time/batch = 16.7980s	
7774/11350 (epoch 34.247), train_loss = 0.58244230, grad/param norm = 2.8760e-01, time/batch = 17.3238s	
7775/11350 (epoch 34.251), train_loss = 0.67677652, grad/param norm = 2.9546e-01, time/batch = 16.8639s	
7776/11350 (epoch 34.256), train_loss = 0.68999311, grad/param norm = 3.4393e-01, time/batch = 17.0222s	
7777/11350 (epoch 34.260), train_loss = 0.62198817, grad/param norm = 3.2379e-01, time/batch = 16.7959s	
7778/11350 (epoch 34.264), train_loss = 0.61407651, grad/param norm = 3.5114e-01, time/batch = 17.0377s	
7779/11350 (epoch 34.269), train_loss = 0.66858677, grad/param norm = 2.9021e-01, time/batch = 16.8783s	
7780/11350 (epoch 34.273), train_loss = 0.75090524, grad/param norm = 3.1797e-01, time/batch = 17.1144s	
7781/11350 (epoch 34.278), train_loss = 0.63579274, grad/param norm = 2.9574e-01, time/batch = 16.4601s	
7782/11350 (epoch 34.282), train_loss = 0.64608868, grad/param norm = 3.0673e-01, time/batch = 16.5463s	
7783/11350 (epoch 34.286), train_loss = 0.74582285, grad/param norm = 3.7948e-01, time/batch = 16.8747s	
7784/11350 (epoch 34.291), train_loss = 0.61533241, grad/param norm = 3.4921e-01, time/batch = 16.5518s	
7785/11350 (epoch 34.295), train_loss = 0.67352092, grad/param norm = 3.5574e-01, time/batch = 17.2440s	
7786/11350 (epoch 34.300), train_loss = 0.74386535, grad/param norm = 3.6751e-01, time/batch = 16.1542s	
7787/11350 (epoch 34.304), train_loss = 0.59870210, grad/param norm = 2.9253e-01, time/batch = 17.2506s	
7788/11350 (epoch 34.308), train_loss = 0.59254209, grad/param norm = 3.3962e-01, time/batch = 16.3985s	
7789/11350 (epoch 34.313), train_loss = 0.65771339, grad/param norm = 2.9408e-01, time/batch = 17.6499s	
7790/11350 (epoch 34.317), train_loss = 0.63450010, grad/param norm = 2.6600e-01, time/batch = 17.1904s	
7791/11350 (epoch 34.322), train_loss = 0.64880679, grad/param norm = 3.3144e-01, time/batch = 16.5580s	
7792/11350 (epoch 34.326), train_loss = 0.66150741, grad/param norm = 2.8381e-01, time/batch = 16.7129s	
7793/11350 (epoch 34.330), train_loss = 0.53334599, grad/param norm = 2.2720e-01, time/batch = 16.5405s	
7794/11350 (epoch 34.335), train_loss = 0.44357627, grad/param norm = 2.8250e-01, time/batch = 16.4800s	
7795/11350 (epoch 34.339), train_loss = 0.49726933, grad/param norm = 3.0201e-01, time/batch = 16.5608s	
7796/11350 (epoch 34.344), train_loss = 0.59258620, grad/param norm = 2.6040e-01, time/batch = 16.9231s	
7797/11350 (epoch 34.348), train_loss = 0.60033943, grad/param norm = 2.5993e-01, time/batch = 16.6189s	
7798/11350 (epoch 34.352), train_loss = 0.50301437, grad/param norm = 2.4806e-01, time/batch = 16.8062s	
7799/11350 (epoch 34.357), train_loss = 0.61897460, grad/param norm = 2.7324e-01, time/batch = 16.8688s	
7800/11350 (epoch 34.361), train_loss = 0.49900969, grad/param norm = 2.4649e-01, time/batch = 16.8786s	
7801/11350 (epoch 34.366), train_loss = 0.63013771, grad/param norm = 3.7583e-01, time/batch = 16.6361s	
7802/11350 (epoch 34.370), train_loss = 0.53637691, grad/param norm = 3.4877e-01, time/batch = 16.8954s	
7803/11350 (epoch 34.374), train_loss = 0.57977334, grad/param norm = 2.5974e-01, time/batch = 16.7793s	
7804/11350 (epoch 34.379), train_loss = 0.57692590, grad/param norm = 2.9903e-01, time/batch = 16.8729s	
7805/11350 (epoch 34.383), train_loss = 0.53051178, grad/param norm = 2.6450e-01, time/batch = 17.0282s	
7806/11350 (epoch 34.388), train_loss = 0.61602440, grad/param norm = 3.7168e-01, time/batch = 19.4006s	
7807/11350 (epoch 34.392), train_loss = 0.68274429, grad/param norm = 3.4372e-01, time/batch = 28.9700s	
7808/11350 (epoch 34.396), train_loss = 0.59878779, grad/param norm = 3.4470e-01, time/batch = 16.4618s	
7809/11350 (epoch 34.401), train_loss = 0.63865632, grad/param norm = 4.6454e-01, time/batch = 16.7061s	
7810/11350 (epoch 34.405), train_loss = 0.81279243, grad/param norm = 3.5712e-01, time/batch = 16.7188s	
7811/11350 (epoch 34.410), train_loss = 0.82672233, grad/param norm = 4.4795e-01, time/batch = 16.7145s	
7812/11350 (epoch 34.414), train_loss = 0.59417349, grad/param norm = 3.8199e-01, time/batch = 16.4782s	
7813/11350 (epoch 34.419), train_loss = 0.57745276, grad/param norm = 3.8231e-01, time/batch = 16.7105s	
7814/11350 (epoch 34.423), train_loss = 0.63569079, grad/param norm = 4.1013e-01, time/batch = 17.7306s	
7815/11350 (epoch 34.427), train_loss = 0.69012140, grad/param norm = 3.6443e-01, time/batch = 16.4726s	
7816/11350 (epoch 34.432), train_loss = 0.65126420, grad/param norm = 3.3493e-01, time/batch = 16.6157s	
7817/11350 (epoch 34.436), train_loss = 0.59827405, grad/param norm = 3.6597e-01, time/batch = 16.6260s	
7818/11350 (epoch 34.441), train_loss = 0.75742699, grad/param norm = 3.7791e-01, time/batch = 16.7049s	
7819/11350 (epoch 34.445), train_loss = 0.57966050, grad/param norm = 3.0963e-01, time/batch = 16.8070s	
7820/11350 (epoch 34.449), train_loss = 0.66675752, grad/param norm = 3.2885e-01, time/batch = 17.4024s	
7821/11350 (epoch 34.454), train_loss = 0.76870391, grad/param norm = 3.6344e-01, time/batch = 16.8709s	
7822/11350 (epoch 34.458), train_loss = 0.56415937, grad/param norm = 3.2135e-01, time/batch = 17.3407s	
7823/11350 (epoch 34.463), train_loss = 0.55675565, grad/param norm = 3.5762e-01, time/batch = 17.0354s	
7824/11350 (epoch 34.467), train_loss = 0.87646850, grad/param norm = 3.9234e-01, time/batch = 16.9432s	
7825/11350 (epoch 34.471), train_loss = 0.77888384, grad/param norm = 4.1024e-01, time/batch = 16.7075s	
7826/11350 (epoch 34.476), train_loss = 0.68258183, grad/param norm = 3.2408e-01, time/batch = 16.7143s	
7827/11350 (epoch 34.480), train_loss = 0.75534055, grad/param norm = 3.4380e-01, time/batch = 17.2859s	
7828/11350 (epoch 34.485), train_loss = 0.67514078, grad/param norm = 3.3465e-01, time/batch = 16.9589s	
7829/11350 (epoch 34.489), train_loss = 0.76191471, grad/param norm = 3.5580e-01, time/batch = 16.8721s	
7830/11350 (epoch 34.493), train_loss = 0.78728178, grad/param norm = 3.1735e-01, time/batch = 17.0187s	
7831/11350 (epoch 34.498), train_loss = 0.50532224, grad/param norm = 3.0808e-01, time/batch = 16.4531s	
7832/11350 (epoch 34.502), train_loss = 0.76380323, grad/param norm = 3.0337e-01, time/batch = 16.3050s	
7833/11350 (epoch 34.507), train_loss = 0.58668924, grad/param norm = 2.8257e-01, time/batch = 16.6999s	
7834/11350 (epoch 34.511), train_loss = 0.71755069, grad/param norm = 2.9258e-01, time/batch = 17.2733s	
7835/11350 (epoch 34.515), train_loss = 0.66411962, grad/param norm = 3.3694e-01, time/batch = 16.6335s	
7836/11350 (epoch 34.520), train_loss = 0.81672259, grad/param norm = 3.3459e-01, time/batch = 16.4713s	
7837/11350 (epoch 34.524), train_loss = 0.71418816, grad/param norm = 3.4928e-01, time/batch = 16.6976s	
7838/11350 (epoch 34.529), train_loss = 0.64694731, grad/param norm = 3.1369e-01, time/batch = 16.3852s	
7839/11350 (epoch 34.533), train_loss = 0.83900300, grad/param norm = 4.1554e-01, time/batch = 16.5565s	
7840/11350 (epoch 34.537), train_loss = 0.77704390, grad/param norm = 3.2758e-01, time/batch = 16.9501s	
7841/11350 (epoch 34.542), train_loss = 0.69323533, grad/param norm = 3.0946e-01, time/batch = 17.0046s	
7842/11350 (epoch 34.546), train_loss = 0.86801300, grad/param norm = 3.6870e-01, time/batch = 16.9457s	
7843/11350 (epoch 34.551), train_loss = 0.71886103, grad/param norm = 2.9546e-01, time/batch = 17.2415s	
7844/11350 (epoch 34.555), train_loss = 0.63902968, grad/param norm = 2.8572e-01, time/batch = 17.1245s	
7845/11350 (epoch 34.559), train_loss = 0.66216563, grad/param norm = 2.8832e-01, time/batch = 17.2743s	
7846/11350 (epoch 34.564), train_loss = 0.71648405, grad/param norm = 3.3507e-01, time/batch = 16.5586s	
7847/11350 (epoch 34.568), train_loss = 0.74188466, grad/param norm = 2.9938e-01, time/batch = 16.6349s	
7848/11350 (epoch 34.573), train_loss = 0.84608346, grad/param norm = 4.0713e-01, time/batch = 16.9590s	
7849/11350 (epoch 34.577), train_loss = 0.79786024, grad/param norm = 4.3950e-01, time/batch = 16.7200s	
7850/11350 (epoch 34.581), train_loss = 0.83498201, grad/param norm = 3.3880e-01, time/batch = 16.7909s	
7851/11350 (epoch 34.586), train_loss = 0.78790944, grad/param norm = 3.4244e-01, time/batch = 16.8887s	
7852/11350 (epoch 34.590), train_loss = 0.85101997, grad/param norm = 4.5055e-01, time/batch = 16.7703s	
7853/11350 (epoch 34.595), train_loss = 0.90291399, grad/param norm = 3.2890e-01, time/batch = 16.8373s	
7854/11350 (epoch 34.599), train_loss = 0.74884706, grad/param norm = 3.3968e-01, time/batch = 17.2608s	
7855/11350 (epoch 34.604), train_loss = 0.72125805, grad/param norm = 3.5174e-01, time/batch = 17.2607s	
7856/11350 (epoch 34.608), train_loss = 0.70742144, grad/param norm = 3.8767e-01, time/batch = 16.7103s	
7857/11350 (epoch 34.612), train_loss = 0.71688355, grad/param norm = 2.8032e-01, time/batch = 16.8565s	
7858/11350 (epoch 34.617), train_loss = 0.78277666, grad/param norm = 3.7302e-01, time/batch = 16.4644s	
7859/11350 (epoch 34.621), train_loss = 0.82428718, grad/param norm = 3.5755e-01, time/batch = 17.1060s	
7860/11350 (epoch 34.626), train_loss = 0.73439752, grad/param norm = 2.9914e-01, time/batch = 16.6194s	
7861/11350 (epoch 34.630), train_loss = 0.74147079, grad/param norm = 3.7675e-01, time/batch = 16.9580s	
7862/11350 (epoch 34.634), train_loss = 0.73274976, grad/param norm = 3.3688e-01, time/batch = 16.9276s	
7863/11350 (epoch 34.639), train_loss = 0.64989789, grad/param norm = 3.2414e-01, time/batch = 16.8050s	
7864/11350 (epoch 34.643), train_loss = 0.61683510, grad/param norm = 2.8466e-01, time/batch = 16.8730s	
7865/11350 (epoch 34.648), train_loss = 0.69818856, grad/param norm = 4.8525e-01, time/batch = 16.8648s	
7866/11350 (epoch 34.652), train_loss = 0.65615848, grad/param norm = 3.7986e-01, time/batch = 17.1229s	
7867/11350 (epoch 34.656), train_loss = 0.76395645, grad/param norm = 3.2609e-01, time/batch = 16.8707s	
7868/11350 (epoch 34.661), train_loss = 0.76233496, grad/param norm = 3.5174e-01, time/batch = 16.7896s	
7869/11350 (epoch 34.665), train_loss = 0.77039571, grad/param norm = 3.6041e-01, time/batch = 17.0380s	
7870/11350 (epoch 34.670), train_loss = 0.73446424, grad/param norm = 3.2910e-01, time/batch = 16.5592s	
7871/11350 (epoch 34.674), train_loss = 0.68197329, grad/param norm = 3.1029e-01, time/batch = 16.7135s	
7872/11350 (epoch 34.678), train_loss = 0.74552702, grad/param norm = 2.9344e-01, time/batch = 16.7143s	
7873/11350 (epoch 34.683), train_loss = 0.68484957, grad/param norm = 4.0261e-01, time/batch = 16.9399s	
7874/11350 (epoch 34.687), train_loss = 0.64310873, grad/param norm = 3.3539e-01, time/batch = 16.5454s	
7875/11350 (epoch 34.692), train_loss = 0.94323508, grad/param norm = 3.7980e-01, time/batch = 17.2255s	
7876/11350 (epoch 34.696), train_loss = 0.92202544, grad/param norm = 4.4535e-01, time/batch = 16.9413s	
7877/11350 (epoch 34.700), train_loss = 0.81615371, grad/param norm = 3.5500e-01, time/batch = 16.9350s	
7878/11350 (epoch 34.705), train_loss = 0.87243162, grad/param norm = 4.0797e-01, time/batch = 16.5522s	
7879/11350 (epoch 34.709), train_loss = 0.83693268, grad/param norm = 3.5963e-01, time/batch = 16.8624s	
7880/11350 (epoch 34.714), train_loss = 0.73955521, grad/param norm = 3.0068e-01, time/batch = 16.6303s	
7881/11350 (epoch 34.718), train_loss = 0.62835933, grad/param norm = 2.9396e-01, time/batch = 16.1465s	
7882/11350 (epoch 34.722), train_loss = 0.73570857, grad/param norm = 3.8424e-01, time/batch = 16.3112s	
7883/11350 (epoch 34.727), train_loss = 0.74385080, grad/param norm = 3.5322e-01, time/batch = 16.2962s	
7884/11350 (epoch 34.731), train_loss = 0.72870906, grad/param norm = 3.5411e-01, time/batch = 16.6180s	
7885/11350 (epoch 34.736), train_loss = 0.68462446, grad/param norm = 4.0634e-01, time/batch = 16.3117s	
7886/11350 (epoch 34.740), train_loss = 0.72948090, grad/param norm = 3.1682e-01, time/batch = 16.8698s	
7887/11350 (epoch 34.744), train_loss = 0.71845235, grad/param norm = 3.7191e-01, time/batch = 17.2044s	
7888/11350 (epoch 34.749), train_loss = 0.71239835, grad/param norm = 3.2067e-01, time/batch = 16.7137s	
7889/11350 (epoch 34.753), train_loss = 0.79682136, grad/param norm = 4.0286e-01, time/batch = 16.6366s	
7890/11350 (epoch 34.758), train_loss = 0.70124766, grad/param norm = 3.7012e-01, time/batch = 16.3099s	
7891/11350 (epoch 34.762), train_loss = 0.84003898, grad/param norm = 3.6013e-01, time/batch = 17.2589s	
7892/11350 (epoch 34.767), train_loss = 0.82822647, grad/param norm = 3.0524e-01, time/batch = 16.3183s	
7893/11350 (epoch 34.771), train_loss = 0.92512515, grad/param norm = 3.3148e-01, time/batch = 17.3281s	
7894/11350 (epoch 34.775), train_loss = 0.74944002, grad/param norm = 3.1894e-01, time/batch = 17.1137s	
7895/11350 (epoch 34.780), train_loss = 0.80320698, grad/param norm = 3.3073e-01, time/batch = 16.9589s	
7896/11350 (epoch 34.784), train_loss = 0.73135165, grad/param norm = 3.4765e-01, time/batch = 16.5509s	
7897/11350 (epoch 34.789), train_loss = 0.74633731, grad/param norm = 3.5993e-01, time/batch = 16.7187s	
7898/11350 (epoch 34.793), train_loss = 0.83831704, grad/param norm = 3.3013e-01, time/batch = 17.0348s	
7899/11350 (epoch 34.797), train_loss = 0.75194443, grad/param norm = 3.2398e-01, time/batch = 16.6243s	
7900/11350 (epoch 34.802), train_loss = 0.75918954, grad/param norm = 2.9011e-01, time/batch = 16.3101s	
7901/11350 (epoch 34.806), train_loss = 0.78403418, grad/param norm = 2.9858e-01, time/batch = 16.7802s	
7902/11350 (epoch 34.811), train_loss = 0.75338579, grad/param norm = 2.9777e-01, time/batch = 16.7942s	
7903/11350 (epoch 34.815), train_loss = 0.73434740, grad/param norm = 3.1487e-01, time/batch = 16.7180s	
7904/11350 (epoch 34.819), train_loss = 0.65252745, grad/param norm = 2.8828e-01, time/batch = 16.4642s	
7905/11350 (epoch 34.824), train_loss = 0.64826429, grad/param norm = 3.5205e-01, time/batch = 17.1640s	
7906/11350 (epoch 34.828), train_loss = 0.69091161, grad/param norm = 3.1741e-01, time/batch = 16.5511s	
7907/11350 (epoch 34.833), train_loss = 0.71325928, grad/param norm = 3.2450e-01, time/batch = 16.4682s	
7908/11350 (epoch 34.837), train_loss = 0.73613035, grad/param norm = 3.2981e-01, time/batch = 16.5507s	
7909/11350 (epoch 34.841), train_loss = 0.99378753, grad/param norm = 3.9208e-01, time/batch = 17.1675s	
7910/11350 (epoch 34.846), train_loss = 0.80660156, grad/param norm = 3.0112e-01, time/batch = 16.7731s	
7911/11350 (epoch 34.850), train_loss = 0.81364723, grad/param norm = 3.7810e-01, time/batch = 16.7099s	
7912/11350 (epoch 34.855), train_loss = 0.64920338, grad/param norm = 4.1585e-01, time/batch = 16.9442s	
7913/11350 (epoch 34.859), train_loss = 0.70771369, grad/param norm = 4.5126e-01, time/batch = 16.6285s	
7914/11350 (epoch 34.863), train_loss = 0.65636809, grad/param norm = 3.1847e-01, time/batch = 16.7199s	
7915/11350 (epoch 34.868), train_loss = 0.67118520, grad/param norm = 3.2118e-01, time/batch = 17.1071s	
7916/11350 (epoch 34.872), train_loss = 0.68851935, grad/param norm = 2.9432e-01, time/batch = 16.7123s	
7917/11350 (epoch 34.877), train_loss = 0.70050458, grad/param norm = 3.5837e-01, time/batch = 16.7073s	
7918/11350 (epoch 34.881), train_loss = 0.88325891, grad/param norm = 3.7358e-01, time/batch = 17.4924s	
7919/11350 (epoch 34.885), train_loss = 0.83202451, grad/param norm = 3.2259e-01, time/batch = 16.8708s	
7920/11350 (epoch 34.890), train_loss = 0.77092771, grad/param norm = 3.6336e-01, time/batch = 16.5531s	
7921/11350 (epoch 34.894), train_loss = 0.64095181, grad/param norm = 3.3752e-01, time/batch = 16.8744s	
7922/11350 (epoch 34.899), train_loss = 0.80018659, grad/param norm = 3.4707e-01, time/batch = 16.7219s	
7923/11350 (epoch 34.903), train_loss = 0.75939584, grad/param norm = 3.3883e-01, time/batch = 16.7888s	
7924/11350 (epoch 34.907), train_loss = 0.69250161, grad/param norm = 3.4265e-01, time/batch = 16.8067s	
7925/11350 (epoch 34.912), train_loss = 0.66094821, grad/param norm = 2.7285e-01, time/batch = 16.6420s	
7926/11350 (epoch 34.916), train_loss = 0.78404364, grad/param norm = 4.0234e-01, time/batch = 17.0247s	
7927/11350 (epoch 34.921), train_loss = 0.76912652, grad/param norm = 3.2209e-01, time/batch = 17.0957s	
7928/11350 (epoch 34.925), train_loss = 0.63637419, grad/param norm = 2.6802e-01, time/batch = 16.7920s	
7929/11350 (epoch 34.930), train_loss = 0.75195749, grad/param norm = 3.6053e-01, time/batch = 16.6271s	
7930/11350 (epoch 34.934), train_loss = 0.86883316, grad/param norm = 4.1375e-01, time/batch = 17.4116s	
7931/11350 (epoch 34.938), train_loss = 0.74240122, grad/param norm = 3.8576e-01, time/batch = 17.1764s	
7932/11350 (epoch 34.943), train_loss = 0.79793807, grad/param norm = 3.1374e-01, time/batch = 16.8829s	
7933/11350 (epoch 34.947), train_loss = 0.75918868, grad/param norm = 3.0954e-01, time/batch = 16.7871s	
7934/11350 (epoch 34.952), train_loss = 0.77254617, grad/param norm = 3.4976e-01, time/batch = 16.7188s	
7935/11350 (epoch 34.956), train_loss = 0.61171484, grad/param norm = 2.6868e-01, time/batch = 16.9672s	
7936/11350 (epoch 34.960), train_loss = 0.70989245, grad/param norm = 3.5634e-01, time/batch = 16.6405s	
7937/11350 (epoch 34.965), train_loss = 0.63054891, grad/param norm = 3.2652e-01, time/batch = 16.7032s	
7938/11350 (epoch 34.969), train_loss = 0.63301774, grad/param norm = 3.4755e-01, time/batch = 16.4641s	
7939/11350 (epoch 34.974), train_loss = 0.63181345, grad/param norm = 3.2045e-01, time/batch = 16.5545s	
7940/11350 (epoch 34.978), train_loss = 0.70780770, grad/param norm = 3.2628e-01, time/batch = 17.1700s	
7941/11350 (epoch 34.982), train_loss = 0.47989796, grad/param norm = 2.4723e-01, time/batch = 16.9566s	
7942/11350 (epoch 34.987), train_loss = 0.71702042, grad/param norm = 3.1759e-01, time/batch = 16.9526s	
7943/11350 (epoch 34.991), train_loss = 0.62790675, grad/param norm = 3.2172e-01, time/batch = 16.4838s	
7944/11350 (epoch 34.996), train_loss = 0.70415030, grad/param norm = 3.6429e-01, time/batch = 16.8658s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
7945/11350 (epoch 35.000), train_loss = 0.56918455, grad/param norm = 3.1716e-01, time/batch = 16.7134s	
7946/11350 (epoch 35.004), train_loss = 0.76169143, grad/param norm = 3.2916e-01, time/batch = 16.9489s	
7947/11350 (epoch 35.009), train_loss = 0.75085603, grad/param norm = 3.3809e-01, time/batch = 16.4698s	
7948/11350 (epoch 35.013), train_loss = 0.53496999, grad/param norm = 2.9702e-01, time/batch = 16.9656s	
7949/11350 (epoch 35.018), train_loss = 0.57497100, grad/param norm = 3.1046e-01, time/batch = 16.3127s	
7950/11350 (epoch 35.022), train_loss = 0.59194374, grad/param norm = 3.4026e-01, time/batch = 16.5505s	
7951/11350 (epoch 35.026), train_loss = 0.55840581, grad/param norm = 2.9714e-01, time/batch = 16.8701s	
7952/11350 (epoch 35.031), train_loss = 0.60781288, grad/param norm = 3.2069e-01, time/batch = 16.3908s	
7953/11350 (epoch 35.035), train_loss = 0.61250470, grad/param norm = 2.9122e-01, time/batch = 16.5485s	
7954/11350 (epoch 35.040), train_loss = 0.63087954, grad/param norm = 3.0802e-01, time/batch = 16.3031s	
7955/11350 (epoch 35.044), train_loss = 0.59821192, grad/param norm = 2.7315e-01, time/batch = 16.7130s	
7956/11350 (epoch 35.048), train_loss = 0.57145053, grad/param norm = 2.7453e-01, time/batch = 16.9389s	
7957/11350 (epoch 35.053), train_loss = 0.62100311, grad/param norm = 2.7346e-01, time/batch = 16.8716s	
7958/11350 (epoch 35.057), train_loss = 0.64179190, grad/param norm = 3.5532e-01, time/batch = 16.6911s	
7959/11350 (epoch 35.062), train_loss = 0.53794117, grad/param norm = 2.9084e-01, time/batch = 17.1706s	
7960/11350 (epoch 35.066), train_loss = 0.52566259, grad/param norm = 3.1679e-01, time/batch = 16.5521s	
7961/11350 (epoch 35.070), train_loss = 0.60672884, grad/param norm = 3.3306e-01, time/batch = 16.6312s	
7962/11350 (epoch 35.075), train_loss = 0.55526802, grad/param norm = 2.9766e-01, time/batch = 16.8658s	
7963/11350 (epoch 35.079), train_loss = 0.66524347, grad/param norm = 3.2067e-01, time/batch = 16.6949s	
7964/11350 (epoch 35.084), train_loss = 0.77276698, grad/param norm = 3.6002e-01, time/batch = 16.8679s	
7965/11350 (epoch 35.088), train_loss = 0.72305498, grad/param norm = 3.7853e-01, time/batch = 16.6171s	
7966/11350 (epoch 35.093), train_loss = 0.70693064, grad/param norm = 3.1532e-01, time/batch = 16.8727s	
7967/11350 (epoch 35.097), train_loss = 0.65332050, grad/param norm = 3.2627e-01, time/batch = 16.6249s	
7968/11350 (epoch 35.101), train_loss = 0.61208655, grad/param norm = 3.2393e-01, time/batch = 16.6418s	
7969/11350 (epoch 35.106), train_loss = 0.68016517, grad/param norm = 3.3275e-01, time/batch = 16.4668s	
7970/11350 (epoch 35.110), train_loss = 0.61546238, grad/param norm = 3.2693e-01, time/batch = 16.2202s	
7971/11350 (epoch 35.115), train_loss = 0.61892434, grad/param norm = 3.1733e-01, time/batch = 16.3817s	
7972/11350 (epoch 35.119), train_loss = 0.73540417, grad/param norm = 3.8272e-01, time/batch = 16.6267s	
7973/11350 (epoch 35.123), train_loss = 0.60073159, grad/param norm = 3.4854e-01, time/batch = 16.7923s	
7974/11350 (epoch 35.128), train_loss = 0.53459040, grad/param norm = 3.5782e-01, time/batch = 17.0222s	
7975/11350 (epoch 35.132), train_loss = 0.58536456, grad/param norm = 3.0183e-01, time/batch = 16.5561s	
7976/11350 (epoch 35.137), train_loss = 0.56988179, grad/param norm = 3.2072e-01, time/batch = 16.8742s	
7977/11350 (epoch 35.141), train_loss = 0.71797872, grad/param norm = 3.6234e-01, time/batch = 16.7897s	
7978/11350 (epoch 35.145), train_loss = 0.58764738, grad/param norm = 2.8713e-01, time/batch = 16.9788s	
7979/11350 (epoch 35.150), train_loss = 0.65894414, grad/param norm = 3.8878e-01, time/batch = 16.8014s	
7980/11350 (epoch 35.154), train_loss = 0.77800532, grad/param norm = 3.8047e-01, time/batch = 17.4963s	
7981/11350 (epoch 35.159), train_loss = 0.54874433, grad/param norm = 2.7769e-01, time/batch = 16.7109s	
7982/11350 (epoch 35.163), train_loss = 0.69601500, grad/param norm = 3.5637e-01, time/batch = 16.9380s	
7983/11350 (epoch 35.167), train_loss = 0.73801167, grad/param norm = 3.1400e-01, time/batch = 17.0262s	
7984/11350 (epoch 35.172), train_loss = 0.82419703, grad/param norm = 3.3873e-01, time/batch = 16.7954s	
7985/11350 (epoch 35.176), train_loss = 0.64751810, grad/param norm = 3.1643e-01, time/batch = 16.8700s	
7986/11350 (epoch 35.181), train_loss = 0.66677083, grad/param norm = 3.8221e-01, time/batch = 16.8689s	
7987/11350 (epoch 35.185), train_loss = 0.59469899, grad/param norm = 3.1943e-01, time/batch = 16.7795s	
7988/11350 (epoch 35.189), train_loss = 0.62837494, grad/param norm = 2.9127e-01, time/batch = 16.2034s	
7989/11350 (epoch 35.194), train_loss = 0.56315208, grad/param norm = 3.2124e-01, time/batch = 16.3784s	
7990/11350 (epoch 35.198), train_loss = 0.52991625, grad/param norm = 3.8230e-01, time/batch = 17.0251s	
7991/11350 (epoch 35.203), train_loss = 0.57758931, grad/param norm = 2.9877e-01, time/batch = 17.4230s	
7992/11350 (epoch 35.207), train_loss = 0.53573779, grad/param norm = 3.2605e-01, time/batch = 16.5485s	
7993/11350 (epoch 35.211), train_loss = 0.72774213, grad/param norm = 3.8106e-01, time/batch = 16.5534s	
7994/11350 (epoch 35.216), train_loss = 0.68699161, grad/param norm = 3.5063e-01, time/batch = 16.7998s	
7995/11350 (epoch 35.220), train_loss = 0.68071679, grad/param norm = 3.6476e-01, time/batch = 16.3944s	
7996/11350 (epoch 35.225), train_loss = 0.61097277, grad/param norm = 2.9283e-01, time/batch = 16.7144s	
7997/11350 (epoch 35.229), train_loss = 0.69942566, grad/param norm = 3.6130e-01, time/batch = 16.9547s	
7998/11350 (epoch 35.233), train_loss = 0.63853618, grad/param norm = 3.2649e-01, time/batch = 17.0360s	
7999/11350 (epoch 35.238), train_loss = 0.75416194, grad/param norm = 4.1296e-01, time/batch = 16.7096s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch35.24_2.0366.t7	
8000/11350 (epoch 35.242), train_loss = 0.74583129, grad/param norm = 3.3941e-01, time/batch = 16.7023s	
8001/11350 (epoch 35.247), train_loss = 1.17588165, grad/param norm = 4.5454e-01, time/batch = 16.9288s	
8002/11350 (epoch 35.251), train_loss = 0.70572719, grad/param norm = 3.8330e-01, time/batch = 16.7910s	
8003/11350 (epoch 35.256), train_loss = 0.73362727, grad/param norm = 4.3003e-01, time/batch = 16.7115s	
8004/11350 (epoch 35.260), train_loss = 0.61843463, grad/param norm = 3.6112e-01, time/batch = 16.5573s	
8005/11350 (epoch 35.264), train_loss = 0.60680813, grad/param norm = 3.5846e-01, time/batch = 16.9484s	
8006/11350 (epoch 35.269), train_loss = 0.64290541, grad/param norm = 2.8732e-01, time/batch = 16.7180s	
8007/11350 (epoch 35.273), train_loss = 0.74892195, grad/param norm = 3.1590e-01, time/batch = 16.6453s	
8008/11350 (epoch 35.278), train_loss = 0.62559281, grad/param norm = 3.0059e-01, time/batch = 16.6369s	
8009/11350 (epoch 35.282), train_loss = 0.62942499, grad/param norm = 3.2709e-01, time/batch = 17.1978s	
8010/11350 (epoch 35.286), train_loss = 0.72563104, grad/param norm = 3.6953e-01, time/batch = 16.8067s	
8011/11350 (epoch 35.291), train_loss = 0.61694349, grad/param norm = 4.0494e-01, time/batch = 16.6885s	
8012/11350 (epoch 35.295), train_loss = 0.67236644, grad/param norm = 3.5669e-01, time/batch = 17.1982s	
8013/11350 (epoch 35.300), train_loss = 0.72441999, grad/param norm = 3.5019e-01, time/batch = 16.5220s	
8014/11350 (epoch 35.304), train_loss = 0.60168834, grad/param norm = 3.6323e-01, time/batch = 16.7843s	
8015/11350 (epoch 35.308), train_loss = 0.58209854, grad/param norm = 2.9334e-01, time/batch = 16.2086s	
8016/11350 (epoch 35.313), train_loss = 0.65701686, grad/param norm = 3.0112e-01, time/batch = 31.9866s	
8017/11350 (epoch 35.317), train_loss = 0.62219888, grad/param norm = 2.5629e-01, time/batch = 16.6411s	
8018/11350 (epoch 35.322), train_loss = 0.62485634, grad/param norm = 2.9672e-01, time/batch = 17.0384s	
8019/11350 (epoch 35.326), train_loss = 0.64915913, grad/param norm = 3.0435e-01, time/batch = 17.0107s	
8020/11350 (epoch 35.330), train_loss = 0.53422461, grad/param norm = 2.5696e-01, time/batch = 16.4699s	
8021/11350 (epoch 35.335), train_loss = 0.43969593, grad/param norm = 2.7045e-01, time/batch = 16.6317s	
8022/11350 (epoch 35.339), train_loss = 0.47794644, grad/param norm = 3.2250e-01, time/batch = 17.1999s	
8023/11350 (epoch 35.344), train_loss = 0.58906874, grad/param norm = 2.6326e-01, time/batch = 16.8677s	
8024/11350 (epoch 35.348), train_loss = 0.58514893, grad/param norm = 2.8968e-01, time/batch = 16.6464s	
8025/11350 (epoch 35.352), train_loss = 0.48820963, grad/param norm = 2.6922e-01, time/batch = 16.6238s	
8026/11350 (epoch 35.357), train_loss = 0.60165437, grad/param norm = 2.7373e-01, time/batch = 17.0222s	
8027/11350 (epoch 35.361), train_loss = 0.49543906, grad/param norm = 2.4926e-01, time/batch = 16.5649s	
8028/11350 (epoch 35.366), train_loss = 0.62276647, grad/param norm = 3.7807e-01, time/batch = 16.8807s	
8029/11350 (epoch 35.370), train_loss = 0.54121581, grad/param norm = 3.9747e-01, time/batch = 16.7925s	
8030/11350 (epoch 35.374), train_loss = 0.57945880, grad/param norm = 3.0361e-01, time/batch = 16.3046s	
8031/11350 (epoch 35.379), train_loss = 0.56313443, grad/param norm = 2.9805e-01, time/batch = 17.3515s	
8032/11350 (epoch 35.383), train_loss = 0.54290944, grad/param norm = 3.3529e-01, time/batch = 16.6265s	
8033/11350 (epoch 35.388), train_loss = 0.62552367, grad/param norm = 4.2442e-01, time/batch = 16.7056s	
8034/11350 (epoch 35.392), train_loss = 0.67056450, grad/param norm = 3.1805e-01, time/batch = 16.5404s	
8035/11350 (epoch 35.396), train_loss = 0.59868904, grad/param norm = 3.4409e-01, time/batch = 17.0256s	
8036/11350 (epoch 35.401), train_loss = 0.60632331, grad/param norm = 4.6799e-01, time/batch = 17.5664s	
8037/11350 (epoch 35.405), train_loss = 0.77152874, grad/param norm = 3.9028e-01, time/batch = 16.7964s	
8038/11350 (epoch 35.410), train_loss = 0.80040882, grad/param norm = 4.4319e-01, time/batch = 16.5525s	
8039/11350 (epoch 35.414), train_loss = 0.56712646, grad/param norm = 3.4976e-01, time/batch = 16.7242s	
8040/11350 (epoch 35.419), train_loss = 0.55935750, grad/param norm = 3.6311e-01, time/batch = 16.7964s	
8041/11350 (epoch 35.423), train_loss = 0.59809381, grad/param norm = 4.1722e-01, time/batch = 16.3986s	
8042/11350 (epoch 35.427), train_loss = 0.67181058, grad/param norm = 3.4079e-01, time/batch = 16.8059s	
8043/11350 (epoch 35.432), train_loss = 0.64209954, grad/param norm = 3.4281e-01, time/batch = 16.9520s	
8044/11350 (epoch 35.436), train_loss = 0.56758935, grad/param norm = 3.1888e-01, time/batch = 16.5462s	
8045/11350 (epoch 35.441), train_loss = 0.72804266, grad/param norm = 3.5538e-01, time/batch = 16.6440s	
8046/11350 (epoch 35.445), train_loss = 0.56553088, grad/param norm = 2.8042e-01, time/batch = 16.4812s	
8047/11350 (epoch 35.449), train_loss = 0.64351724, grad/param norm = 3.1079e-01, time/batch = 17.1867s	
8048/11350 (epoch 35.454), train_loss = 0.75171453, grad/param norm = 3.7442e-01, time/batch = 16.9337s	
8049/11350 (epoch 35.458), train_loss = 0.53995620, grad/param norm = 2.7812e-01, time/batch = 17.2656s	
8050/11350 (epoch 35.463), train_loss = 0.54509496, grad/param norm = 3.2149e-01, time/batch = 16.7910s	
8051/11350 (epoch 35.467), train_loss = 0.83778141, grad/param norm = 3.6270e-01, time/batch = 16.6089s	
8052/11350 (epoch 35.471), train_loss = 0.76776796, grad/param norm = 5.1137e-01, time/batch = 16.3090s	
8053/11350 (epoch 35.476), train_loss = 0.67959861, grad/param norm = 3.2987e-01, time/batch = 16.7215s	
8054/11350 (epoch 35.480), train_loss = 0.75833122, grad/param norm = 3.4638e-01, time/batch = 16.5524s	
8055/11350 (epoch 35.485), train_loss = 0.68320702, grad/param norm = 3.4387e-01, time/batch = 16.3715s	
8056/11350 (epoch 35.489), train_loss = 0.73561969, grad/param norm = 3.6315e-01, time/batch = 16.6945s	
8057/11350 (epoch 35.493), train_loss = 0.76231939, grad/param norm = 3.0330e-01, time/batch = 16.4593s	
8058/11350 (epoch 35.498), train_loss = 0.48473529, grad/param norm = 2.8028e-01, time/batch = 16.4741s	
8059/11350 (epoch 35.502), train_loss = 0.76506182, grad/param norm = 3.6525e-01, time/batch = 16.5551s	
8060/11350 (epoch 35.507), train_loss = 0.57078619, grad/param norm = 2.8660e-01, time/batch = 16.4757s	
8061/11350 (epoch 35.511), train_loss = 0.71136531, grad/param norm = 3.0336e-01, time/batch = 17.1077s	
8062/11350 (epoch 35.515), train_loss = 0.65244216, grad/param norm = 3.1827e-01, time/batch = 16.8677s	
8063/11350 (epoch 35.520), train_loss = 0.81249885, grad/param norm = 3.8684e-01, time/batch = 17.2764s	
8064/11350 (epoch 35.524), train_loss = 0.68524046, grad/param norm = 3.3352e-01, time/batch = 16.7097s	
8065/11350 (epoch 35.529), train_loss = 0.63232157, grad/param norm = 2.9496e-01, time/batch = 17.0291s	
8066/11350 (epoch 35.533), train_loss = 0.83388111, grad/param norm = 3.8744e-01, time/batch = 16.7131s	
8067/11350 (epoch 35.537), train_loss = 0.79230584, grad/param norm = 3.7517e-01, time/batch = 17.1723s	
8068/11350 (epoch 35.542), train_loss = 0.67339663, grad/param norm = 2.8962e-01, time/batch = 16.7805s	
8069/11350 (epoch 35.546), train_loss = 0.84586536, grad/param norm = 4.2271e-01, time/batch = 16.3082s	
8070/11350 (epoch 35.551), train_loss = 0.73498025, grad/param norm = 4.1683e-01, time/batch = 16.9573s	
8071/11350 (epoch 35.555), train_loss = 0.63434975, grad/param norm = 3.1877e-01, time/batch = 16.4668s	
8072/11350 (epoch 35.559), train_loss = 0.64945944, grad/param norm = 3.1028e-01, time/batch = 16.6257s	
8073/11350 (epoch 35.564), train_loss = 0.70539792, grad/param norm = 3.6080e-01, time/batch = 16.6953s	
8074/11350 (epoch 35.568), train_loss = 0.73137848, grad/param norm = 3.1679e-01, time/batch = 16.9658s	
8075/11350 (epoch 35.573), train_loss = 0.82674884, grad/param norm = 3.7187e-01, time/batch = 16.9518s	
8076/11350 (epoch 35.577), train_loss = 0.77143951, grad/param norm = 3.8306e-01, time/batch = 16.9398s	
8077/11350 (epoch 35.581), train_loss = 0.80369211, grad/param norm = 3.3035e-01, time/batch = 16.5517s	
8078/11350 (epoch 35.586), train_loss = 0.77447635, grad/param norm = 3.7625e-01, time/batch = 16.5478s	
8079/11350 (epoch 35.590), train_loss = 0.83719328, grad/param norm = 4.3204e-01, time/batch = 16.9322s	
8080/11350 (epoch 35.595), train_loss = 0.90450686, grad/param norm = 3.8810e-01, time/batch = 16.2917s	
8081/11350 (epoch 35.599), train_loss = 0.74289393, grad/param norm = 3.3552e-01, time/batch = 16.6447s	
8082/11350 (epoch 35.604), train_loss = 0.71169362, grad/param norm = 3.4978e-01, time/batch = 17.1621s	
8083/11350 (epoch 35.608), train_loss = 0.68256047, grad/param norm = 3.7125e-01, time/batch = 16.7304s	
8084/11350 (epoch 35.612), train_loss = 0.72826833, grad/param norm = 3.3353e-01, time/batch = 16.2267s	
8085/11350 (epoch 35.617), train_loss = 0.77176493, grad/param norm = 3.6103e-01, time/batch = 16.6941s	
8086/11350 (epoch 35.621), train_loss = 0.80981654, grad/param norm = 3.3045e-01, time/batch = 16.6902s	
8087/11350 (epoch 35.626), train_loss = 0.73196397, grad/param norm = 3.0240e-01, time/batch = 16.6304s	
8088/11350 (epoch 35.630), train_loss = 0.72832205, grad/param norm = 3.4833e-01, time/batch = 17.0212s	
8089/11350 (epoch 35.634), train_loss = 0.70997130, grad/param norm = 3.4212e-01, time/batch = 16.5581s	
8090/11350 (epoch 35.639), train_loss = 0.66051276, grad/param norm = 3.1561e-01, time/batch = 16.8699s	
8091/11350 (epoch 35.643), train_loss = 0.59697484, grad/param norm = 3.0413e-01, time/batch = 16.8752s	
8092/11350 (epoch 35.648), train_loss = 0.67838160, grad/param norm = 2.9291e-01, time/batch = 16.6244s	
8093/11350 (epoch 35.652), train_loss = 0.62724280, grad/param norm = 3.2678e-01, time/batch = 16.9501s	
8094/11350 (epoch 35.656), train_loss = 0.72771433, grad/param norm = 3.0135e-01, time/batch = 16.3945s	
8095/11350 (epoch 35.661), train_loss = 0.74400602, grad/param norm = 3.9056e-01, time/batch = 16.6876s	
8096/11350 (epoch 35.665), train_loss = 0.74408783, grad/param norm = 3.7321e-01, time/batch = 16.6330s	
8097/11350 (epoch 35.670), train_loss = 0.71379788, grad/param norm = 3.2187e-01, time/batch = 16.7938s	
8098/11350 (epoch 35.674), train_loss = 0.68768418, grad/param norm = 3.2301e-01, time/batch = 16.7829s	
8099/11350 (epoch 35.678), train_loss = 0.74049432, grad/param norm = 3.1621e-01, time/batch = 16.6344s	
8100/11350 (epoch 35.683), train_loss = 0.66004956, grad/param norm = 3.5986e-01, time/batch = 16.9422s	
8101/11350 (epoch 35.687), train_loss = 0.61753189, grad/param norm = 2.9248e-01, time/batch = 16.8767s	
8102/11350 (epoch 35.692), train_loss = 0.94702746, grad/param norm = 5.4658e-01, time/batch = 16.7863s	
8103/11350 (epoch 35.696), train_loss = 0.88145660, grad/param norm = 3.8333e-01, time/batch = 16.5440s	
8104/11350 (epoch 35.700), train_loss = 0.80706849, grad/param norm = 3.7704e-01, time/batch = 17.3556s	
8105/11350 (epoch 35.705), train_loss = 0.84575423, grad/param norm = 3.7797e-01, time/batch = 17.1802s	
8106/11350 (epoch 35.709), train_loss = 0.82308578, grad/param norm = 3.4043e-01, time/batch = 16.5563s	
8107/11350 (epoch 35.714), train_loss = 0.74347137, grad/param norm = 3.3507e-01, time/batch = 16.7142s	
8108/11350 (epoch 35.718), train_loss = 0.63400937, grad/param norm = 3.2518e-01, time/batch = 16.7072s	
8109/11350 (epoch 35.722), train_loss = 0.72802952, grad/param norm = 4.1451e-01, time/batch = 16.7134s	
8110/11350 (epoch 35.727), train_loss = 0.72795122, grad/param norm = 3.2838e-01, time/batch = 17.0829s	
8111/11350 (epoch 35.731), train_loss = 0.71044145, grad/param norm = 3.3074e-01, time/batch = 17.0251s	
8112/11350 (epoch 35.736), train_loss = 0.64956123, grad/param norm = 3.8750e-01, time/batch = 16.3908s	
8113/11350 (epoch 35.740), train_loss = 0.70678945, grad/param norm = 3.0419e-01, time/batch = 16.7260s	
8114/11350 (epoch 35.744), train_loss = 0.72015540, grad/param norm = 4.2415e-01, time/batch = 17.1211s	
8115/11350 (epoch 35.749), train_loss = 0.69301491, grad/param norm = 3.9764e-01, time/batch = 17.2033s	
8116/11350 (epoch 35.753), train_loss = 0.78184630, grad/param norm = 3.6058e-01, time/batch = 16.7094s	
8117/11350 (epoch 35.758), train_loss = 0.69326356, grad/param norm = 3.8664e-01, time/batch = 16.3949s	
8118/11350 (epoch 35.762), train_loss = 0.82238200, grad/param norm = 3.0645e-01, time/batch = 16.7871s	
8119/11350 (epoch 35.767), train_loss = 0.82028485, grad/param norm = 3.0650e-01, time/batch = 16.6372s	
8120/11350 (epoch 35.771), train_loss = 0.91469653, grad/param norm = 3.6764e-01, time/batch = 17.2717s	
8121/11350 (epoch 35.775), train_loss = 0.75306938, grad/param norm = 3.3282e-01, time/batch = 16.9482s	
8122/11350 (epoch 35.780), train_loss = 0.79248207, grad/param norm = 3.4353e-01, time/batch = 17.1644s	
8123/11350 (epoch 35.784), train_loss = 0.72441971, grad/param norm = 3.5654e-01, time/batch = 16.6465s	
8124/11350 (epoch 35.789), train_loss = 0.73457938, grad/param norm = 3.3606e-01, time/batch = 16.8845s	
8125/11350 (epoch 35.793), train_loss = 0.81981236, grad/param norm = 3.3297e-01, time/batch = 17.1234s	
8126/11350 (epoch 35.797), train_loss = 0.71697940, grad/param norm = 2.9741e-01, time/batch = 16.7884s	
8127/11350 (epoch 35.802), train_loss = 0.76754188, grad/param norm = 3.2845e-01, time/batch = 16.8082s	
8128/11350 (epoch 35.806), train_loss = 0.76843521, grad/param norm = 2.8366e-01, time/batch = 16.6906s	
8129/11350 (epoch 35.811), train_loss = 0.73699997, grad/param norm = 3.0760e-01, time/batch = 16.5299s	
8130/11350 (epoch 35.815), train_loss = 0.71043651, grad/param norm = 3.0906e-01, time/batch = 16.8860s	
8131/11350 (epoch 35.819), train_loss = 0.62531836, grad/param norm = 2.9177e-01, time/batch = 16.6434s	
8132/11350 (epoch 35.824), train_loss = 0.63442278, grad/param norm = 3.1807e-01, time/batch = 16.9572s	
8133/11350 (epoch 35.828), train_loss = 0.66384264, grad/param norm = 2.7940e-01, time/batch = 16.3976s	
8134/11350 (epoch 35.833), train_loss = 0.70079819, grad/param norm = 3.1737e-01, time/batch = 17.1012s	
8135/11350 (epoch 35.837), train_loss = 0.73450975, grad/param norm = 3.7856e-01, time/batch = 16.3871s	
8136/11350 (epoch 35.841), train_loss = 0.98375137, grad/param norm = 4.3254e-01, time/batch = 17.0988s	
8137/11350 (epoch 35.846), train_loss = 0.79147103, grad/param norm = 3.8844e-01, time/batch = 16.8726s	
8138/11350 (epoch 35.850), train_loss = 0.80221750, grad/param norm = 3.3472e-01, time/batch = 17.3121s	
8139/11350 (epoch 35.855), train_loss = 0.65006841, grad/param norm = 3.5592e-01, time/batch = 16.7705s	
8140/11350 (epoch 35.859), train_loss = 0.69498508, grad/param norm = 3.8891e-01, time/batch = 16.5405s	
8141/11350 (epoch 35.863), train_loss = 0.63685526, grad/param norm = 3.0896e-01, time/batch = 16.7963s	
8142/11350 (epoch 35.868), train_loss = 0.64704672, grad/param norm = 2.9920e-01, time/batch = 16.3891s	
8143/11350 (epoch 35.872), train_loss = 0.67082898, grad/param norm = 3.1898e-01, time/batch = 17.0131s	
8144/11350 (epoch 35.877), train_loss = 0.69624888, grad/param norm = 5.0711e-01, time/batch = 16.3010s	
8145/11350 (epoch 35.881), train_loss = 0.86174850, grad/param norm = 3.5963e-01, time/batch = 16.7200s	
8146/11350 (epoch 35.885), train_loss = 0.82576251, grad/param norm = 3.1566e-01, time/batch = 17.4692s	
8147/11350 (epoch 35.890), train_loss = 0.75210293, grad/param norm = 3.5370e-01, time/batch = 16.9491s	
8148/11350 (epoch 35.894), train_loss = 0.63658412, grad/param norm = 3.1827e-01, time/batch = 16.7096s	
8149/11350 (epoch 35.899), train_loss = 0.80563368, grad/param norm = 4.2688e-01, time/batch = 16.7971s	
8150/11350 (epoch 35.903), train_loss = 0.75562323, grad/param norm = 3.5192e-01, time/batch = 16.8622s	
8151/11350 (epoch 35.907), train_loss = 0.68115987, grad/param norm = 3.3528e-01, time/batch = 16.7880s	
8152/11350 (epoch 35.912), train_loss = 0.65390375, grad/param norm = 3.2965e-01, time/batch = 16.3844s	
8153/11350 (epoch 35.916), train_loss = 0.74948591, grad/param norm = 3.8730e-01, time/batch = 16.3816s	
8154/11350 (epoch 35.921), train_loss = 0.72975088, grad/param norm = 3.1454e-01, time/batch = 16.6299s	
8155/11350 (epoch 35.925), train_loss = 0.62808761, grad/param norm = 2.7951e-01, time/batch = 16.3066s	
8156/11350 (epoch 35.930), train_loss = 0.73272787, grad/param norm = 3.5193e-01, time/batch = 16.8609s	
8157/11350 (epoch 35.934), train_loss = 0.86478996, grad/param norm = 4.0383e-01, time/batch = 16.8597s	
8158/11350 (epoch 35.938), train_loss = 0.72804241, grad/param norm = 3.2786e-01, time/batch = 16.9488s	
8159/11350 (epoch 35.943), train_loss = 0.78413911, grad/param norm = 3.3454e-01, time/batch = 16.8564s	
8160/11350 (epoch 35.947), train_loss = 0.75134096, grad/param norm = 3.8543e-01, time/batch = 16.4722s	
8161/11350 (epoch 35.952), train_loss = 0.76224908, grad/param norm = 3.7481e-01, time/batch = 16.7829s	
8162/11350 (epoch 35.956), train_loss = 0.60380306, grad/param norm = 2.6244e-01, time/batch = 16.4535s	
8163/11350 (epoch 35.960), train_loss = 0.68309359, grad/param norm = 3.3897e-01, time/batch = 16.9282s	
8164/11350 (epoch 35.965), train_loss = 0.61128131, grad/param norm = 3.3944e-01, time/batch = 17.0084s	
8165/11350 (epoch 35.969), train_loss = 0.61576559, grad/param norm = 3.5692e-01, time/batch = 16.3121s	
8166/11350 (epoch 35.974), train_loss = 0.60970596, grad/param norm = 2.9307e-01, time/batch = 16.5626s	
8167/11350 (epoch 35.978), train_loss = 0.68637282, grad/param norm = 3.4960e-01, time/batch = 16.4840s	
8168/11350 (epoch 35.982), train_loss = 0.48412105, grad/param norm = 2.9278e-01, time/batch = 16.8628s	
8169/11350 (epoch 35.987), train_loss = 0.71422260, grad/param norm = 3.8493e-01, time/batch = 16.6371s	
8170/11350 (epoch 35.991), train_loss = 0.62336378, grad/param norm = 3.8740e-01, time/batch = 16.5529s	
8171/11350 (epoch 35.996), train_loss = 0.69624708, grad/param norm = 4.0115e-01, time/batch = 17.1128s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
8172/11350 (epoch 36.000), train_loss = 0.56124949, grad/param norm = 3.4089e-01, time/batch = 16.7114s	
8173/11350 (epoch 36.004), train_loss = 0.76245507, grad/param norm = 3.9149e-01, time/batch = 16.7139s	
8174/11350 (epoch 36.009), train_loss = 0.72036355, grad/param norm = 2.9259e-01, time/batch = 16.5412s	
8175/11350 (epoch 36.013), train_loss = 0.50222989, grad/param norm = 2.7236e-01, time/batch = 16.8747s	
8176/11350 (epoch 36.018), train_loss = 0.56540597, grad/param norm = 3.3075e-01, time/batch = 16.3055s	
8177/11350 (epoch 36.022), train_loss = 0.57900384, grad/param norm = 3.3342e-01, time/batch = 16.3902s	
8178/11350 (epoch 36.026), train_loss = 0.53522249, grad/param norm = 2.8618e-01, time/batch = 16.5557s	
8179/11350 (epoch 36.031), train_loss = 0.58417477, grad/param norm = 2.8553e-01, time/batch = 16.9400s	
8180/11350 (epoch 36.035), train_loss = 0.60251816, grad/param norm = 3.3184e-01, time/batch = 16.4639s	
8181/11350 (epoch 36.040), train_loss = 0.61338888, grad/param norm = 2.8844e-01, time/batch = 16.3781s	
8182/11350 (epoch 36.044), train_loss = 0.57463926, grad/param norm = 2.5879e-01, time/batch = 16.8680s	
8183/11350 (epoch 36.048), train_loss = 0.55981164, grad/param norm = 2.9443e-01, time/batch = 17.5123s	
8184/11350 (epoch 36.053), train_loss = 0.62711500, grad/param norm = 3.5809e-01, time/batch = 16.2941s	
8185/11350 (epoch 36.057), train_loss = 0.60966374, grad/param norm = 3.3123e-01, time/batch = 16.1468s	
8186/11350 (epoch 36.062), train_loss = 0.52152537, grad/param norm = 2.8718e-01, time/batch = 16.8742s	
8187/11350 (epoch 36.066), train_loss = 0.51263929, grad/param norm = 2.9517e-01, time/batch = 16.3101s	
8188/11350 (epoch 36.070), train_loss = 0.60369000, grad/param norm = 3.3966e-01, time/batch = 16.6468s	
8189/11350 (epoch 36.075), train_loss = 0.54009656, grad/param norm = 3.0785e-01, time/batch = 17.1615s	
8190/11350 (epoch 36.079), train_loss = 0.65955339, grad/param norm = 3.5273e-01, time/batch = 16.5486s	
8191/11350 (epoch 36.084), train_loss = 0.74755240, grad/param norm = 3.3070e-01, time/batch = 16.6371s	
8192/11350 (epoch 36.088), train_loss = 0.70650178, grad/param norm = 3.5680e-01, time/batch = 16.6286s	
8193/11350 (epoch 36.093), train_loss = 0.69734650, grad/param norm = 3.2509e-01, time/batch = 17.1126s	
8194/11350 (epoch 36.097), train_loss = 0.63748083, grad/param norm = 3.3941e-01, time/batch = 16.3053s	
8195/11350 (epoch 36.101), train_loss = 0.58311637, grad/param norm = 3.2071e-01, time/batch = 16.4735s	
8196/11350 (epoch 36.106), train_loss = 0.67339582, grad/param norm = 3.7743e-01, time/batch = 16.6269s	
8197/11350 (epoch 36.110), train_loss = 0.59819114, grad/param norm = 3.3324e-01, time/batch = 16.8737s	
8198/11350 (epoch 36.115), train_loss = 0.60471892, grad/param norm = 3.3647e-01, time/batch = 16.7040s	
8199/11350 (epoch 36.119), train_loss = 0.69691033, grad/param norm = 3.2325e-01, time/batch = 16.3924s	
8200/11350 (epoch 36.123), train_loss = 0.58214511, grad/param norm = 3.7383e-01, time/batch = 16.8472s	
8201/11350 (epoch 36.128), train_loss = 0.53493255, grad/param norm = 3.0817e-01, time/batch = 16.6305s	
8202/11350 (epoch 36.132), train_loss = 0.57742094, grad/param norm = 2.8938e-01, time/batch = 16.5462s	
8203/11350 (epoch 36.137), train_loss = 0.55238535, grad/param norm = 3.1389e-01, time/batch = 17.2795s	
8204/11350 (epoch 36.141), train_loss = 0.71104713, grad/param norm = 3.8713e-01, time/batch = 16.4485s	
8205/11350 (epoch 36.145), train_loss = 0.59609448, grad/param norm = 3.1440e-01, time/batch = 16.6429s	
8206/11350 (epoch 36.150), train_loss = 0.64773027, grad/param norm = 3.8233e-01, time/batch = 16.8035s	
8207/11350 (epoch 36.154), train_loss = 0.75991686, grad/param norm = 3.8243e-01, time/batch = 17.0258s	
8208/11350 (epoch 36.159), train_loss = 0.54138006, grad/param norm = 3.0813e-01, time/batch = 16.7835s	
8209/11350 (epoch 36.163), train_loss = 0.67306989, grad/param norm = 3.5430e-01, time/batch = 17.1204s	
8210/11350 (epoch 36.167), train_loss = 0.72527120, grad/param norm = 3.1758e-01, time/batch = 16.7095s	
8211/11350 (epoch 36.172), train_loss = 0.80324824, grad/param norm = 3.3171e-01, time/batch = 17.3507s	
8212/11350 (epoch 36.176), train_loss = 0.63684642, grad/param norm = 3.0698e-01, time/batch = 16.7245s	
8213/11350 (epoch 36.181), train_loss = 0.63637666, grad/param norm = 3.5044e-01, time/batch = 16.3077s	
8214/11350 (epoch 36.185), train_loss = 0.57035135, grad/param norm = 3.1425e-01, time/batch = 16.8660s	
8215/11350 (epoch 36.189), train_loss = 0.61655359, grad/param norm = 3.0765e-01, time/batch = 16.7013s	
8216/11350 (epoch 36.194), train_loss = 0.54619099, grad/param norm = 2.9861e-01, time/batch = 16.1307s	
8217/11350 (epoch 36.198), train_loss = 0.51953584, grad/param norm = 3.4230e-01, time/batch = 16.3004s	
8218/11350 (epoch 36.203), train_loss = 0.56607882, grad/param norm = 2.9825e-01, time/batch = 16.9467s	
8219/11350 (epoch 36.207), train_loss = 0.52691736, grad/param norm = 3.6525e-01, time/batch = 16.5446s	
8220/11350 (epoch 36.211), train_loss = 0.70881111, grad/param norm = 3.4809e-01, time/batch = 16.4635s	
8221/11350 (epoch 36.216), train_loss = 0.65991715, grad/param norm = 3.2628e-01, time/batch = 16.7745s	
8222/11350 (epoch 36.220), train_loss = 0.67227879, grad/param norm = 3.5054e-01, time/batch = 16.8740s	
8223/11350 (epoch 36.225), train_loss = 0.60283560, grad/param norm = 2.9092e-01, time/batch = 16.5611s	
8224/11350 (epoch 36.229), train_loss = 0.66479683, grad/param norm = 3.0813e-01, time/batch = 16.7922s	
8225/11350 (epoch 36.233), train_loss = 0.61880077, grad/param norm = 3.8708e-01, time/batch = 17.0321s	
8226/11350 (epoch 36.238), train_loss = 0.74581279, grad/param norm = 4.3373e-01, time/batch = 17.3377s	
8227/11350 (epoch 36.242), train_loss = 0.73813811, grad/param norm = 3.8340e-01, time/batch = 16.8754s	
8228/11350 (epoch 36.247), train_loss = 0.57609512, grad/param norm = 2.8977e-01, time/batch = 16.6278s	
8229/11350 (epoch 36.251), train_loss = 0.62341149, grad/param norm = 3.2131e-01, time/batch = 32.4265s	
8230/11350 (epoch 36.256), train_loss = 0.67861637, grad/param norm = 3.5687e-01, time/batch = 16.7135s	
8231/11350 (epoch 36.260), train_loss = 0.62401899, grad/param norm = 3.0183e-01, time/batch = 16.9554s	
8232/11350 (epoch 36.264), train_loss = 0.60185384, grad/param norm = 3.5667e-01, time/batch = 16.7201s	
8233/11350 (epoch 36.269), train_loss = 0.62858932, grad/param norm = 2.8606e-01, time/batch = 16.5450s	
8234/11350 (epoch 36.273), train_loss = 0.71759629, grad/param norm = 3.0166e-01, time/batch = 16.3070s	
8235/11350 (epoch 36.278), train_loss = 0.59399423, grad/param norm = 2.6364e-01, time/batch = 16.7001s	
8236/11350 (epoch 36.282), train_loss = 0.60098801, grad/param norm = 3.0355e-01, time/batch = 16.3947s	
8237/11350 (epoch 36.286), train_loss = 0.70652099, grad/param norm = 3.8407e-01, time/batch = 16.3957s	
8238/11350 (epoch 36.291), train_loss = 0.58324860, grad/param norm = 3.3357e-01, time/batch = 16.5493s	
8239/11350 (epoch 36.295), train_loss = 0.63545213, grad/param norm = 3.6498e-01, time/batch = 16.3900s	
8240/11350 (epoch 36.300), train_loss = 0.70661089, grad/param norm = 3.6869e-01, time/batch = 16.6283s	
8241/11350 (epoch 36.304), train_loss = 0.59120212, grad/param norm = 3.4146e-01, time/batch = 16.7208s	
8242/11350 (epoch 36.308), train_loss = 0.57555754, grad/param norm = 3.7994e-01, time/batch = 17.1888s	
8243/11350 (epoch 36.313), train_loss = 0.63183969, grad/param norm = 3.0431e-01, time/batch = 16.9477s	
8244/11350 (epoch 36.317), train_loss = 0.62479868, grad/param norm = 3.1093e-01, time/batch = 17.0410s	
8245/11350 (epoch 36.322), train_loss = 0.60609275, grad/param norm = 2.8031e-01, time/batch = 16.8716s	
8246/11350 (epoch 36.326), train_loss = 0.62243597, grad/param norm = 2.7979e-01, time/batch = 16.9406s	
8247/11350 (epoch 36.330), train_loss = 0.52149765, grad/param norm = 2.6147e-01, time/batch = 16.6199s	
8248/11350 (epoch 36.335), train_loss = 0.42026423, grad/param norm = 2.8870e-01, time/batch = 16.2225s	
8249/11350 (epoch 36.339), train_loss = 0.47231012, grad/param norm = 3.4617e-01, time/batch = 16.7901s	
8250/11350 (epoch 36.344), train_loss = 0.56430693, grad/param norm = 2.6612e-01, time/batch = 16.7077s	
8251/11350 (epoch 36.348), train_loss = 0.59415812, grad/param norm = 2.9968e-01, time/batch = 17.3248s	
8252/11350 (epoch 36.352), train_loss = 0.47374188, grad/param norm = 2.5623e-01, time/batch = 17.2695s	
8253/11350 (epoch 36.357), train_loss = 0.59446681, grad/param norm = 3.0062e-01, time/batch = 16.8018s	
8254/11350 (epoch 36.361), train_loss = 0.47373413, grad/param norm = 2.4639e-01, time/batch = 16.3842s	
8255/11350 (epoch 36.366), train_loss = 0.60943997, grad/param norm = 4.0971e-01, time/batch = 16.5544s	
8256/11350 (epoch 36.370), train_loss = 0.50627536, grad/param norm = 3.7212e-01, time/batch = 16.9466s	
8257/11350 (epoch 36.374), train_loss = 0.57860198, grad/param norm = 3.3146e-01, time/batch = 16.4820s	
8258/11350 (epoch 36.379), train_loss = 0.56505899, grad/param norm = 3.0873e-01, time/batch = 16.8025s	
8259/11350 (epoch 36.383), train_loss = 0.49982645, grad/param norm = 2.5770e-01, time/batch = 16.7196s	
8260/11350 (epoch 36.388), train_loss = 0.59977184, grad/param norm = 3.9039e-01, time/batch = 17.4256s	
8261/11350 (epoch 36.392), train_loss = 0.67825007, grad/param norm = 3.5263e-01, time/batch = 17.2657s	
8262/11350 (epoch 36.396), train_loss = 0.57257284, grad/param norm = 3.5226e-01, time/batch = 17.2817s	
8263/11350 (epoch 36.401), train_loss = 0.58779140, grad/param norm = 3.8260e-01, time/batch = 16.6277s	
8264/11350 (epoch 36.405), train_loss = 0.76856712, grad/param norm = 3.5522e-01, time/batch = 1.7026s	
8265/11350 (epoch 36.410), train_loss = 0.78029123, grad/param norm = 3.6084e-01, time/batch = 0.7385s	
8266/11350 (epoch 36.414), train_loss = 0.56160256, grad/param norm = 3.9409e-01, time/batch = 0.7541s	
8267/11350 (epoch 36.419), train_loss = 0.53172999, grad/param norm = 2.7253e-01, time/batch = 0.7491s	
8268/11350 (epoch 36.423), train_loss = 0.59133075, grad/param norm = 3.4905e-01, time/batch = 0.7525s	
8269/11350 (epoch 36.427), train_loss = 0.64636668, grad/param norm = 3.2392e-01, time/batch = 0.7603s	
8270/11350 (epoch 36.432), train_loss = 0.62545099, grad/param norm = 3.4611e-01, time/batch = 0.8563s	
8271/11350 (epoch 36.436), train_loss = 0.55413526, grad/param norm = 3.2224e-01, time/batch = 1.1082s	
8272/11350 (epoch 36.441), train_loss = 0.69665633, grad/param norm = 3.8163e-01, time/batch = 1.1168s	
8273/11350 (epoch 36.445), train_loss = 0.55357319, grad/param norm = 2.9826e-01, time/batch = 1.1028s	
8274/11350 (epoch 36.449), train_loss = 0.63154996, grad/param norm = 3.1559e-01, time/batch = 1.0989s	
8275/11350 (epoch 36.454), train_loss = 0.74041978, grad/param norm = 3.8461e-01, time/batch = 1.8574s	
8276/11350 (epoch 36.458), train_loss = 0.53478455, grad/param norm = 2.9460e-01, time/batch = 2.0368s	
8277/11350 (epoch 36.463), train_loss = 0.52564231, grad/param norm = 3.2059e-01, time/batch = 7.2686s	
8278/11350 (epoch 36.467), train_loss = 0.81755783, grad/param norm = 3.6715e-01, time/batch = 16.7916s	
8279/11350 (epoch 36.471), train_loss = 0.75345777, grad/param norm = 4.9623e-01, time/batch = 16.7050s	
8280/11350 (epoch 36.476), train_loss = 0.66882624, grad/param norm = 3.6775e-01, time/batch = 16.3955s	
8281/11350 (epoch 36.480), train_loss = 0.71755219, grad/param norm = 4.0220e-01, time/batch = 16.6362s	
8282/11350 (epoch 36.485), train_loss = 0.64243227, grad/param norm = 3.2229e-01, time/batch = 16.6296s	
8283/11350 (epoch 36.489), train_loss = 0.71368648, grad/param norm = 3.7258e-01, time/batch = 16.7084s	
8284/11350 (epoch 36.493), train_loss = 0.75789000, grad/param norm = 3.3576e-01, time/batch = 16.6349s	
8285/11350 (epoch 36.498), train_loss = 0.48932097, grad/param norm = 3.4540e-01, time/batch = 17.0843s	
8286/11350 (epoch 36.502), train_loss = 0.76822237, grad/param norm = 3.9464e-01, time/batch = 16.3867s	
8287/11350 (epoch 36.507), train_loss = 0.55396536, grad/param norm = 2.9845e-01, time/batch = 16.2964s	
8288/11350 (epoch 36.511), train_loss = 0.68912671, grad/param norm = 3.1119e-01, time/batch = 16.9471s	
8289/11350 (epoch 36.515), train_loss = 0.63402477, grad/param norm = 3.7787e-01, time/batch = 16.8985s	
8290/11350 (epoch 36.520), train_loss = 0.78553865, grad/param norm = 3.3369e-01, time/batch = 16.6254s	
8291/11350 (epoch 36.524), train_loss = 0.68491417, grad/param norm = 3.6846e-01, time/batch = 16.7954s	
8292/11350 (epoch 36.529), train_loss = 0.61210565, grad/param norm = 3.0589e-01, time/batch = 16.7812s	
8293/11350 (epoch 36.533), train_loss = 0.80229706, grad/param norm = 3.7855e-01, time/batch = 16.6121s	
8294/11350 (epoch 36.537), train_loss = 0.76812606, grad/param norm = 3.6735e-01, time/batch = 16.8642s	
8295/11350 (epoch 36.542), train_loss = 0.63370779, grad/param norm = 2.8530e-01, time/batch = 16.4789s	
8296/11350 (epoch 36.546), train_loss = 0.81999775, grad/param norm = 4.4044e-01, time/batch = 16.7867s	
8297/11350 (epoch 36.551), train_loss = 0.69680712, grad/param norm = 3.7747e-01, time/batch = 16.4657s	
8298/11350 (epoch 36.555), train_loss = 0.62056087, grad/param norm = 3.4006e-01, time/batch = 17.0139s	
8299/11350 (epoch 36.559), train_loss = 0.65520665, grad/param norm = 3.6494e-01, time/batch = 16.6262s	
8300/11350 (epoch 36.564), train_loss = 0.69725091, grad/param norm = 3.6943e-01, time/batch = 16.5385s	
8301/11350 (epoch 36.568), train_loss = 0.71155557, grad/param norm = 3.2972e-01, time/batch = 17.2748s	
8302/11350 (epoch 36.573), train_loss = 0.79677208, grad/param norm = 3.7271e-01, time/batch = 16.7232s	
8303/11350 (epoch 36.577), train_loss = 0.74239729, grad/param norm = 3.6207e-01, time/batch = 16.7120s	
8304/11350 (epoch 36.581), train_loss = 0.80201668, grad/param norm = 3.4678e-01, time/batch = 17.3413s	
8305/11350 (epoch 36.586), train_loss = 0.74894365, grad/param norm = 3.6867e-01, time/batch = 16.8628s	
8306/11350 (epoch 36.590), train_loss = 0.81598448, grad/param norm = 4.2870e-01, time/batch = 16.7114s	
8307/11350 (epoch 36.595), train_loss = 0.87094931, grad/param norm = 3.3682e-01, time/batch = 16.8625s	
8308/11350 (epoch 36.599), train_loss = 0.71216783, grad/param norm = 3.5004e-01, time/batch = 17.0428s	
8309/11350 (epoch 36.604), train_loss = 0.69524852, grad/param norm = 3.6699e-01, time/batch = 16.8060s	
8310/11350 (epoch 36.608), train_loss = 0.65318265, grad/param norm = 3.2803e-01, time/batch = 17.0415s	
8311/11350 (epoch 36.612), train_loss = 0.68258185, grad/param norm = 3.0046e-01, time/batch = 16.5337s	
8312/11350 (epoch 36.617), train_loss = 0.74418972, grad/param norm = 3.1166e-01, time/batch = 17.1085s	
8313/11350 (epoch 36.621), train_loss = 0.77406164, grad/param norm = 3.0778e-01, time/batch = 16.7716s	
8314/11350 (epoch 36.626), train_loss = 0.71131475, grad/param norm = 3.2828e-01, time/batch = 16.3925s	
8315/11350 (epoch 36.630), train_loss = 0.69935739, grad/param norm = 3.1607e-01, time/batch = 16.7794s	
8316/11350 (epoch 36.634), train_loss = 0.68625662, grad/param norm = 3.3088e-01, time/batch = 16.6205s	
8317/11350 (epoch 36.639), train_loss = 0.64471016, grad/param norm = 3.1929e-01, time/batch = 16.6316s	
8318/11350 (epoch 36.643), train_loss = 0.57649968, grad/param norm = 2.7630e-01, time/batch = 16.3936s	
8319/11350 (epoch 36.648), train_loss = 0.65854052, grad/param norm = 2.7787e-01, time/batch = 17.4126s	
8320/11350 (epoch 36.652), train_loss = 0.59533863, grad/param norm = 2.9962e-01, time/batch = 17.2585s	
8321/11350 (epoch 36.656), train_loss = 0.71635840, grad/param norm = 2.9943e-01, time/batch = 16.5576s	
8322/11350 (epoch 36.661), train_loss = 0.72407963, grad/param norm = 3.8195e-01, time/batch = 16.6985s	
8323/11350 (epoch 36.665), train_loss = 0.73204613, grad/param norm = 3.6992e-01, time/batch = 16.6261s	
8324/11350 (epoch 36.670), train_loss = 0.71775473, grad/param norm = 3.2342e-01, time/batch = 16.6420s	
8325/11350 (epoch 36.674), train_loss = 0.66110322, grad/param norm = 2.9845e-01, time/batch = 16.6388s	
8326/11350 (epoch 36.678), train_loss = 0.72256314, grad/param norm = 3.1785e-01, time/batch = 17.0215s	
8327/11350 (epoch 36.683), train_loss = 0.66007558, grad/param norm = 4.6580e-01, time/batch = 16.7232s	
8328/11350 (epoch 36.687), train_loss = 0.61461881, grad/param norm = 3.9046e-01, time/batch = 17.2608s	
8329/11350 (epoch 36.692), train_loss = 0.90101152, grad/param norm = 4.3202e-01, time/batch = 17.1176s	
8330/11350 (epoch 36.696), train_loss = 0.86366178, grad/param norm = 3.8529e-01, time/batch = 17.1837s	
8331/11350 (epoch 36.700), train_loss = 0.78362716, grad/param norm = 3.8163e-01, time/batch = 16.7207s	
8332/11350 (epoch 36.705), train_loss = 0.83648822, grad/param norm = 4.3411e-01, time/batch = 16.7980s	
8333/11350 (epoch 36.709), train_loss = 0.81793022, grad/param norm = 3.4163e-01, time/batch = 17.1701s	
8334/11350 (epoch 36.714), train_loss = 0.72253976, grad/param norm = 4.0060e-01, time/batch = 17.0292s	
8335/11350 (epoch 36.718), train_loss = 0.62657959, grad/param norm = 3.0000e-01, time/batch = 16.6343s	
8336/11350 (epoch 36.722), train_loss = 0.71033940, grad/param norm = 3.8013e-01, time/batch = 17.1631s	
8337/11350 (epoch 36.727), train_loss = 0.71897974, grad/param norm = 3.1385e-01, time/batch = 16.8567s	
8338/11350 (epoch 36.731), train_loss = 0.68532265, grad/param norm = 3.3878e-01, time/batch = 16.7232s	
8339/11350 (epoch 36.736), train_loss = 0.63536785, grad/param norm = 3.3594e-01, time/batch = 16.7232s	
8340/11350 (epoch 36.740), train_loss = 0.69213048, grad/param norm = 3.2052e-01, time/batch = 16.9521s	
8341/11350 (epoch 36.744), train_loss = 0.69277151, grad/param norm = 4.3319e-01, time/batch = 16.7155s	
8342/11350 (epoch 36.749), train_loss = 0.68042446, grad/param norm = 3.5782e-01, time/batch = 16.8910s	
8343/11350 (epoch 36.753), train_loss = 0.76390580, grad/param norm = 4.4930e-01, time/batch = 16.3742s	
8344/11350 (epoch 36.758), train_loss = 0.68545302, grad/param norm = 3.6590e-01, time/batch = 16.9426s	
8345/11350 (epoch 36.762), train_loss = 0.81481936, grad/param norm = 3.4669e-01, time/batch = 16.4778s	
8346/11350 (epoch 36.767), train_loss = 0.79240570, grad/param norm = 3.3536e-01, time/batch = 16.8773s	
8347/11350 (epoch 36.771), train_loss = 0.89513738, grad/param norm = 3.5928e-01, time/batch = 16.9459s	
8348/11350 (epoch 36.775), train_loss = 0.71596277, grad/param norm = 2.9487e-01, time/batch = 16.8833s	
8349/11350 (epoch 36.780), train_loss = 0.77993013, grad/param norm = 3.8472e-01, time/batch = 16.5596s	
8350/11350 (epoch 36.784), train_loss = 0.69468011, grad/param norm = 3.4646e-01, time/batch = 17.4909s	
8351/11350 (epoch 36.789), train_loss = 0.73551439, grad/param norm = 3.9010e-01, time/batch = 16.8805s	
8352/11350 (epoch 36.793), train_loss = 0.78784113, grad/param norm = 3.6454e-01, time/batch = 16.6310s	
8353/11350 (epoch 36.797), train_loss = 0.72302079, grad/param norm = 3.5710e-01, time/batch = 16.2941s	
8354/11350 (epoch 36.802), train_loss = 0.74418139, grad/param norm = 3.3990e-01, time/batch = 16.8584s	
8355/11350 (epoch 36.806), train_loss = 0.76703539, grad/param norm = 3.1567e-01, time/batch = 16.8787s	
8356/11350 (epoch 36.811), train_loss = 0.71496919, grad/param norm = 3.2288e-01, time/batch = 16.7616s	
8357/11350 (epoch 36.815), train_loss = 0.70802260, grad/param norm = 3.2229e-01, time/batch = 16.6387s	
8358/11350 (epoch 36.819), train_loss = 0.64537506, grad/param norm = 3.5552e-01, time/batch = 16.6124s	
8359/11350 (epoch 36.824), train_loss = 0.63842709, grad/param norm = 3.6442e-01, time/batch = 16.7199s	
8360/11350 (epoch 36.828), train_loss = 0.66735543, grad/param norm = 3.5687e-01, time/batch = 16.2308s	
8361/11350 (epoch 36.833), train_loss = 0.69571059, grad/param norm = 3.4694e-01, time/batch = 16.9334s	
8362/11350 (epoch 36.837), train_loss = 0.73412347, grad/param norm = 4.1969e-01, time/batch = 16.7923s	
8363/11350 (epoch 36.841), train_loss = 0.94271631, grad/param norm = 3.8581e-01, time/batch = 16.6234s	
8364/11350 (epoch 36.846), train_loss = 0.78301522, grad/param norm = 3.0937e-01, time/batch = 16.7121s	
8365/11350 (epoch 36.850), train_loss = 0.79790530, grad/param norm = 4.3018e-01, time/batch = 17.4890s	
8366/11350 (epoch 36.855), train_loss = 0.63194939, grad/param norm = 3.3565e-01, time/batch = 16.2315s	
8367/11350 (epoch 36.859), train_loss = 0.66743032, grad/param norm = 3.8135e-01, time/batch = 16.4736s	
8368/11350 (epoch 36.863), train_loss = 0.62814305, grad/param norm = 3.9860e-01, time/batch = 16.6192s	
8369/11350 (epoch 36.868), train_loss = 0.63716428, grad/param norm = 2.9920e-01, time/batch = 17.0078s	
8370/11350 (epoch 36.872), train_loss = 0.65265524, grad/param norm = 2.9859e-01, time/batch = 16.6499s	
8371/11350 (epoch 36.877), train_loss = 0.68585921, grad/param norm = 4.1051e-01, time/batch = 16.3905s	
8372/11350 (epoch 36.881), train_loss = 0.86306029, grad/param norm = 4.4798e-01, time/batch = 17.0299s	
8373/11350 (epoch 36.885), train_loss = 0.81143926, grad/param norm = 3.3310e-01, time/batch = 16.7293s	
8374/11350 (epoch 36.890), train_loss = 0.74237803, grad/param norm = 3.9648e-01, time/batch = 16.8749s	
8375/11350 (epoch 36.894), train_loss = 0.62096882, grad/param norm = 3.0096e-01, time/batch = 17.6549s	
8376/11350 (epoch 36.899), train_loss = 0.78151445, grad/param norm = 3.5034e-01, time/batch = 16.5483s	
8377/11350 (epoch 36.903), train_loss = 0.74194471, grad/param norm = 3.8405e-01, time/batch = 16.4573s	
8378/11350 (epoch 36.907), train_loss = 0.68409460, grad/param norm = 3.5817e-01, time/batch = 16.4696s	
8379/11350 (epoch 36.912), train_loss = 0.64005359, grad/param norm = 2.9269e-01, time/batch = 16.7056s	
8380/11350 (epoch 36.916), train_loss = 0.72208530, grad/param norm = 3.3271e-01, time/batch = 16.3947s	
8381/11350 (epoch 36.921), train_loss = 0.72374163, grad/param norm = 3.0969e-01, time/batch = 16.6307s	
8382/11350 (epoch 36.925), train_loss = 0.60285331, grad/param norm = 2.7557e-01, time/batch = 16.3797s	
8383/11350 (epoch 36.930), train_loss = 0.72448308, grad/param norm = 4.0140e-01, time/batch = 16.6901s	
8384/11350 (epoch 36.934), train_loss = 0.83349658, grad/param norm = 3.8373e-01, time/batch = 16.9370s	
8385/11350 (epoch 36.938), train_loss = 0.73531791, grad/param norm = 4.2275e-01, time/batch = 16.9540s	
8386/11350 (epoch 36.943), train_loss = 0.76658964, grad/param norm = 3.4763e-01, time/batch = 16.9421s	
8387/11350 (epoch 36.947), train_loss = 0.73850814, grad/param norm = 3.4716e-01, time/batch = 16.7874s	
8388/11350 (epoch 36.952), train_loss = 0.74459347, grad/param norm = 3.8910e-01, time/batch = 16.5474s	
8389/11350 (epoch 36.956), train_loss = 0.60130840, grad/param norm = 3.0409e-01, time/batch = 16.5507s	
8390/11350 (epoch 36.960), train_loss = 0.67163974, grad/param norm = 3.3660e-01, time/batch = 16.9507s	
8391/11350 (epoch 36.965), train_loss = 0.59195569, grad/param norm = 3.6164e-01, time/batch = 17.2037s	
8392/11350 (epoch 36.969), train_loss = 0.63136372, grad/param norm = 4.6747e-01, time/batch = 16.8859s	
8393/11350 (epoch 36.974), train_loss = 0.58201218, grad/param norm = 3.0443e-01, time/batch = 16.3850s	
8394/11350 (epoch 36.978), train_loss = 0.68505098, grad/param norm = 3.0902e-01, time/batch = 16.6440s	
8395/11350 (epoch 36.982), train_loss = 0.46440188, grad/param norm = 2.8077e-01, time/batch = 16.6978s	
8396/11350 (epoch 36.987), train_loss = 0.69311419, grad/param norm = 3.5089e-01, time/batch = 16.4768s	
8397/11350 (epoch 36.991), train_loss = 0.61191188, grad/param norm = 3.5424e-01, time/batch = 16.8857s	
8398/11350 (epoch 36.996), train_loss = 0.67839385, grad/param norm = 3.7944e-01, time/batch = 16.7033s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
8399/11350 (epoch 37.000), train_loss = 0.55489296, grad/param norm = 3.5809e-01, time/batch = 16.9526s	
8400/11350 (epoch 37.004), train_loss = 0.75717154, grad/param norm = 3.6253e-01, time/batch = 17.1122s	
8401/11350 (epoch 37.009), train_loss = 0.70706637, grad/param norm = 3.3880e-01, time/batch = 17.4152s	
8402/11350 (epoch 37.013), train_loss = 0.50207951, grad/param norm = 2.5932e-01, time/batch = 16.4716s	
8403/11350 (epoch 37.018), train_loss = 0.55163926, grad/param norm = 3.5437e-01, time/batch = 16.8709s	
8404/11350 (epoch 37.022), train_loss = 0.56828395, grad/param norm = 3.2678e-01, time/batch = 16.9547s	
8405/11350 (epoch 37.026), train_loss = 0.55158857, grad/param norm = 3.4345e-01, time/batch = 16.8719s	
8406/11350 (epoch 37.031), train_loss = 0.57041566, grad/param norm = 3.3211e-01, time/batch = 16.7252s	
8407/11350 (epoch 37.035), train_loss = 0.58148439, grad/param norm = 2.8234e-01, time/batch = 16.7046s	
8408/11350 (epoch 37.040), train_loss = 0.61276357, grad/param norm = 2.9724e-01, time/batch = 16.5468s	
8409/11350 (epoch 37.044), train_loss = 0.56070767, grad/param norm = 2.7924e-01, time/batch = 16.5518s	
8410/11350 (epoch 37.048), train_loss = 0.53869840, grad/param norm = 2.5501e-01, time/batch = 16.3182s	
8411/11350 (epoch 37.053), train_loss = 0.60682067, grad/param norm = 3.2168e-01, time/batch = 17.2360s	
8412/11350 (epoch 37.057), train_loss = 0.60413125, grad/param norm = 3.8542e-01, time/batch = 16.3881s	
8413/11350 (epoch 37.062), train_loss = 0.51586459, grad/param norm = 3.0349e-01, time/batch = 16.7242s	
8414/11350 (epoch 37.066), train_loss = 0.52386158, grad/param norm = 3.3787e-01, time/batch = 16.7286s	
8415/11350 (epoch 37.070), train_loss = 0.56986956, grad/param norm = 3.0169e-01, time/batch = 16.8623s	
8416/11350 (epoch 37.075), train_loss = 0.52335186, grad/param norm = 2.8856e-01, time/batch = 16.5665s	
8417/11350 (epoch 37.079), train_loss = 0.64961778, grad/param norm = 3.0970e-01, time/batch = 17.2725s	
8418/11350 (epoch 37.084), train_loss = 0.74226506, grad/param norm = 3.9907e-01, time/batch = 16.7003s	
8419/11350 (epoch 37.088), train_loss = 0.68206126, grad/param norm = 3.5917e-01, time/batch = 17.0076s	
8420/11350 (epoch 37.093), train_loss = 0.66987717, grad/param norm = 3.0348e-01, time/batch = 16.6763s	
8421/11350 (epoch 37.097), train_loss = 0.60463495, grad/param norm = 2.9386e-01, time/batch = 16.4680s	
8422/11350 (epoch 37.101), train_loss = 0.57113131, grad/param norm = 3.8194e-01, time/batch = 17.0134s	
8423/11350 (epoch 37.106), train_loss = 0.65824831, grad/param norm = 4.0674e-01, time/batch = 16.9446s	
8424/11350 (epoch 37.110), train_loss = 0.58346218, grad/param norm = 3.2957e-01, time/batch = 16.6310s	
8425/11350 (epoch 37.115), train_loss = 0.60797711, grad/param norm = 3.3641e-01, time/batch = 16.9528s	
8426/11350 (epoch 37.119), train_loss = 0.71095400, grad/param norm = 4.1710e-01, time/batch = 16.6319s	
8427/11350 (epoch 37.123), train_loss = 0.57581286, grad/param norm = 3.2419e-01, time/batch = 16.7980s	
8428/11350 (epoch 37.128), train_loss = 0.50216532, grad/param norm = 2.8927e-01, time/batch = 16.4737s	
8429/11350 (epoch 37.132), train_loss = 0.55959049, grad/param norm = 2.9631e-01, time/batch = 17.1031s	
8430/11350 (epoch 37.137), train_loss = 0.53919864, grad/param norm = 3.4823e-01, time/batch = 16.4731s	
8431/11350 (epoch 37.141), train_loss = 0.69570001, grad/param norm = 3.4761e-01, time/batch = 16.5430s	
8432/11350 (epoch 37.145), train_loss = 0.58604436, grad/param norm = 3.2437e-01, time/batch = 17.3438s	
8433/11350 (epoch 37.150), train_loss = 0.64571168, grad/param norm = 4.4411e-01, time/batch = 17.1065s	
8434/11350 (epoch 37.154), train_loss = 0.72242408, grad/param norm = 3.4674e-01, time/batch = 16.3207s	
8435/11350 (epoch 37.159), train_loss = 0.52694828, grad/param norm = 2.7383e-01, time/batch = 17.0188s	
8436/11350 (epoch 37.163), train_loss = 0.65397738, grad/param norm = 3.4025e-01, time/batch = 17.0268s	
8437/11350 (epoch 37.167), train_loss = 0.71427924, grad/param norm = 3.3200e-01, time/batch = 16.3000s	
8438/11350 (epoch 37.172), train_loss = 0.78392528, grad/param norm = 3.3988e-01, time/batch = 16.6288s	
8439/11350 (epoch 37.176), train_loss = 0.61525384, grad/param norm = 3.0017e-01, time/batch = 16.3117s	
8440/11350 (epoch 37.181), train_loss = 0.63412078, grad/param norm = 4.0881e-01, time/batch = 17.0745s	
8441/11350 (epoch 37.185), train_loss = 0.57530323, grad/param norm = 3.2418e-01, time/batch = 16.5542s	
8442/11350 (epoch 37.189), train_loss = 0.59958983, grad/param norm = 3.2839e-01, time/batch = 16.7870s	
8443/11350 (epoch 37.194), train_loss = 0.55300335, grad/param norm = 4.9733e-01, time/batch = 16.8753s	
8444/11350 (epoch 37.198), train_loss = 0.53167397, grad/param norm = 4.7119e-01, time/batch = 16.7969s	
8445/11350 (epoch 37.203), train_loss = 0.56824058, grad/param norm = 3.6607e-01, time/batch = 16.5499s	
8446/11350 (epoch 37.207), train_loss = 0.51944519, grad/param norm = 3.3097e-01, time/batch = 16.5593s	
8447/11350 (epoch 37.211), train_loss = 0.69695737, grad/param norm = 4.4218e-01, time/batch = 16.9502s	
8448/11350 (epoch 37.216), train_loss = 0.65176023, grad/param norm = 3.7415e-01, time/batch = 16.5484s	
8449/11350 (epoch 37.220), train_loss = 0.65559593, grad/param norm = 3.4202e-01, time/batch = 16.4650s	
8450/11350 (epoch 37.225), train_loss = 0.59035177, grad/param norm = 2.8339e-01, time/batch = 16.7917s	
8451/11350 (epoch 37.229), train_loss = 0.65051514, grad/param norm = 2.9781e-01, time/batch = 17.1181s	
8452/11350 (epoch 37.233), train_loss = 0.62206545, grad/param norm = 4.7411e-01, time/batch = 16.5567s	
8453/11350 (epoch 37.238), train_loss = 0.73869284, grad/param norm = 4.8882e-01, time/batch = 16.8709s	
8454/11350 (epoch 37.242), train_loss = 0.72081213, grad/param norm = 3.8712e-01, time/batch = 30.8171s	
8455/11350 (epoch 37.247), train_loss = 0.56346126, grad/param norm = 3.1581e-01, time/batch = 18.2761s	
8456/11350 (epoch 37.251), train_loss = 0.63870630, grad/param norm = 3.5172e-01, time/batch = 16.7081s	
8457/11350 (epoch 37.256), train_loss = 0.65048948, grad/param norm = 3.0248e-01, time/batch = 16.9348s	
8458/11350 (epoch 37.260), train_loss = 0.58339458, grad/param norm = 3.1731e-01, time/batch = 16.5558s	
8459/11350 (epoch 37.264), train_loss = 0.56732095, grad/param norm = 3.1424e-01, time/batch = 16.4747s	
8460/11350 (epoch 37.269), train_loss = 0.61311643, grad/param norm = 2.9070e-01, time/batch = 16.9544s	
8461/11350 (epoch 37.273), train_loss = 0.69937926, grad/param norm = 3.1204e-01, time/batch = 16.8917s	
8462/11350 (epoch 37.278), train_loss = 0.58753774, grad/param norm = 2.7239e-01, time/batch = 16.8534s	
8463/11350 (epoch 37.282), train_loss = 0.59223072, grad/param norm = 3.0933e-01, time/batch = 16.9980s	
8464/11350 (epoch 37.286), train_loss = 0.68412548, grad/param norm = 3.4094e-01, time/batch = 17.0121s	
8465/11350 (epoch 37.291), train_loss = 0.55881627, grad/param norm = 3.3508e-01, time/batch = 16.5373s	
8466/11350 (epoch 37.295), train_loss = 0.59966655, grad/param norm = 2.9913e-01, time/batch = 16.4751s	
8467/11350 (epoch 37.300), train_loss = 0.67932102, grad/param norm = 3.5242e-01, time/batch = 17.2550s	
8468/11350 (epoch 37.304), train_loss = 0.57052837, grad/param norm = 3.3908e-01, time/batch = 17.1819s	
8469/11350 (epoch 37.308), train_loss = 0.57547303, grad/param norm = 3.6843e-01, time/batch = 16.8868s	
8470/11350 (epoch 37.313), train_loss = 0.61745082, grad/param norm = 2.9110e-01, time/batch = 16.5487s	
8471/11350 (epoch 37.317), train_loss = 0.60271678, grad/param norm = 2.8601e-01, time/batch = 16.7815s	
8472/11350 (epoch 37.322), train_loss = 0.59811945, grad/param norm = 3.1546e-01, time/batch = 16.5396s	
8473/11350 (epoch 37.326), train_loss = 0.60204659, grad/param norm = 2.8695e-01, time/batch = 16.6323s	
8474/11350 (epoch 37.330), train_loss = 0.51036439, grad/param norm = 2.5384e-01, time/batch = 16.8579s	
8475/11350 (epoch 37.335), train_loss = 0.41466832, grad/param norm = 2.7924e-01, time/batch = 16.7004s	
8476/11350 (epoch 37.339), train_loss = 0.46251930, grad/param norm = 3.2084e-01, time/batch = 16.4675s	
8477/11350 (epoch 37.344), train_loss = 0.54725459, grad/param norm = 2.5519e-01, time/batch = 16.6472s	
8478/11350 (epoch 37.348), train_loss = 0.56204727, grad/param norm = 2.5239e-01, time/batch = 17.1034s	
8479/11350 (epoch 37.352), train_loss = 0.46358803, grad/param norm = 2.7118e-01, time/batch = 16.5730s	
8480/11350 (epoch 37.357), train_loss = 0.57211857, grad/param norm = 2.9437e-01, time/batch = 16.4710s	
8481/11350 (epoch 37.361), train_loss = 0.47734056, grad/param norm = 2.7340e-01, time/batch = 16.5504s	
8482/11350 (epoch 37.366), train_loss = 0.59001852, grad/param norm = 3.6998e-01, time/batch = 16.7059s	
8483/11350 (epoch 37.370), train_loss = 0.50898405, grad/param norm = 3.3387e-01, time/batch = 16.4693s	
8484/11350 (epoch 37.374), train_loss = 0.55113401, grad/param norm = 3.0893e-01, time/batch = 16.9264s	
8485/11350 (epoch 37.379), train_loss = 0.53299272, grad/param norm = 2.8332e-01, time/batch = 16.7208s	
8486/11350 (epoch 37.383), train_loss = 0.50194648, grad/param norm = 2.9449e-01, time/batch = 16.4834s	
8487/11350 (epoch 37.388), train_loss = 0.57959919, grad/param norm = 4.1750e-01, time/batch = 16.8746s	
8488/11350 (epoch 37.392), train_loss = 0.63168370, grad/param norm = 3.0225e-01, time/batch = 16.7134s	
8489/11350 (epoch 37.396), train_loss = 0.58576060, grad/param norm = 3.5984e-01, time/batch = 17.0997s	
8490/11350 (epoch 37.401), train_loss = 0.57287916, grad/param norm = 4.0229e-01, time/batch = 16.5442s	
8491/11350 (epoch 37.405), train_loss = 0.73484106, grad/param norm = 3.6972e-01, time/batch = 16.5585s	
8492/11350 (epoch 37.410), train_loss = 0.76594208, grad/param norm = 3.8669e-01, time/batch = 16.9546s	
8493/11350 (epoch 37.414), train_loss = 0.52859008, grad/param norm = 3.3030e-01, time/batch = 16.6333s	
8494/11350 (epoch 37.419), train_loss = 0.52745614, grad/param norm = 3.4523e-01, time/batch = 17.1708s	
8495/11350 (epoch 37.423), train_loss = 0.56003871, grad/param norm = 3.5775e-01, time/batch = 16.4647s	
8496/11350 (epoch 37.427), train_loss = 0.63213201, grad/param norm = 3.6716e-01, time/batch = 17.0390s	
8497/11350 (epoch 37.432), train_loss = 0.59794296, grad/param norm = 3.1727e-01, time/batch = 16.8616s	
8498/11350 (epoch 37.436), train_loss = 0.53399387, grad/param norm = 3.4408e-01, time/batch = 16.4742s	
8499/11350 (epoch 37.441), train_loss = 0.68653474, grad/param norm = 3.4992e-01, time/batch = 16.7645s	
8500/11350 (epoch 37.445), train_loss = 0.54456528, grad/param norm = 2.8347e-01, time/batch = 16.4671s	
8501/11350 (epoch 37.449), train_loss = 0.61986995, grad/param norm = 2.8184e-01, time/batch = 17.5730s	
8502/11350 (epoch 37.454), train_loss = 0.72394022, grad/param norm = 3.6211e-01, time/batch = 16.9588s	
8503/11350 (epoch 37.458), train_loss = 0.52350537, grad/param norm = 3.2815e-01, time/batch = 17.2855s	
8504/11350 (epoch 37.463), train_loss = 0.51969415, grad/param norm = 2.9065e-01, time/batch = 16.8786s	
8505/11350 (epoch 37.467), train_loss = 0.79112671, grad/param norm = 3.6179e-01, time/batch = 17.6472s	
8506/11350 (epoch 37.471), train_loss = 0.74251748, grad/param norm = 4.4079e-01, time/batch = 17.3574s	
8507/11350 (epoch 37.476), train_loss = 0.64018745, grad/param norm = 3.0487e-01, time/batch = 16.6388s	
8508/11350 (epoch 37.480), train_loss = 0.68334528, grad/param norm = 3.1914e-01, time/batch = 16.7841s	
8509/11350 (epoch 37.485), train_loss = 0.62746597, grad/param norm = 3.1310e-01, time/batch = 16.6416s	
8510/11350 (epoch 37.489), train_loss = 0.69777904, grad/param norm = 3.5368e-01, time/batch = 16.8783s	
8511/11350 (epoch 37.493), train_loss = 0.71830153, grad/param norm = 2.8835e-01, time/batch = 16.8709s	
8512/11350 (epoch 37.498), train_loss = 0.47706227, grad/param norm = 2.9801e-01, time/batch = 17.0024s	
8513/11350 (epoch 37.502), train_loss = 0.73560899, grad/param norm = 3.3743e-01, time/batch = 16.8664s	
8514/11350 (epoch 37.507), train_loss = 0.53436474, grad/param norm = 2.6689e-01, time/batch = 16.6163s	
8515/11350 (epoch 37.511), train_loss = 0.66911826, grad/param norm = 3.4088e-01, time/batch = 16.5645s	
8516/11350 (epoch 37.515), train_loss = 0.62640671, grad/param norm = 3.1850e-01, time/batch = 16.4619s	
8517/11350 (epoch 37.520), train_loss = 0.78480087, grad/param norm = 3.7374e-01, time/batch = 16.7003s	
8518/11350 (epoch 37.524), train_loss = 0.67110699, grad/param norm = 3.8438e-01, time/batch = 16.2295s	
8519/11350 (epoch 37.529), train_loss = 0.59325898, grad/param norm = 2.7850e-01, time/batch = 16.4568s	
8520/11350 (epoch 37.533), train_loss = 0.78231456, grad/param norm = 3.7460e-01, time/batch = 16.7086s	
8521/11350 (epoch 37.537), train_loss = 0.74418843, grad/param norm = 3.6265e-01, time/batch = 16.8130s	
8522/11350 (epoch 37.542), train_loss = 0.63290968, grad/param norm = 2.9019e-01, time/batch = 16.4485s	
8523/11350 (epoch 37.546), train_loss = 0.80108704, grad/param norm = 4.0200e-01, time/batch = 16.9460s	
8524/11350 (epoch 37.551), train_loss = 0.69519031, grad/param norm = 4.3377e-01, time/batch = 17.0289s	
8525/11350 (epoch 37.555), train_loss = 0.59816857, grad/param norm = 3.4134e-01, time/batch = 17.4194s	
8526/11350 (epoch 37.559), train_loss = 0.63627420, grad/param norm = 2.9401e-01, time/batch = 16.7787s	
8527/11350 (epoch 37.564), train_loss = 0.67194981, grad/param norm = 3.5156e-01, time/batch = 16.9202s	
8528/11350 (epoch 37.568), train_loss = 0.69119677, grad/param norm = 3.2710e-01, time/batch = 16.7829s	
8529/11350 (epoch 37.573), train_loss = 0.78928822, grad/param norm = 3.8820e-01, time/batch = 16.7204s	
8530/11350 (epoch 37.577), train_loss = 0.71600902, grad/param norm = 3.5831e-01, time/batch = 16.6428s	
8531/11350 (epoch 37.581), train_loss = 0.79780163, grad/param norm = 3.7004e-01, time/batch = 17.0443s	
8532/11350 (epoch 37.586), train_loss = 0.73128860, grad/param norm = 3.5673e-01, time/batch = 16.3100s	
8533/11350 (epoch 37.590), train_loss = 0.79421702, grad/param norm = 4.0798e-01, time/batch = 16.7953s	
8534/11350 (epoch 37.595), train_loss = 0.85885766, grad/param norm = 3.5765e-01, time/batch = 16.3861s	
8535/11350 (epoch 37.599), train_loss = 0.69874880, grad/param norm = 3.7533e-01, time/batch = 16.7010s	
8536/11350 (epoch 37.604), train_loss = 0.70170563, grad/param norm = 3.8012e-01, time/batch = 16.6442s	
8537/11350 (epoch 37.608), train_loss = 0.65789359, grad/param norm = 3.8590e-01, time/batch = 16.6385s	
8538/11350 (epoch 37.612), train_loss = 0.68347816, grad/param norm = 3.2131e-01, time/batch = 16.7108s	
8539/11350 (epoch 37.617), train_loss = 0.74925321, grad/param norm = 3.3719e-01, time/batch = 16.7967s	
8540/11350 (epoch 37.621), train_loss = 0.76747359, grad/param norm = 3.2981e-01, time/batch = 16.4669s	
8541/11350 (epoch 37.626), train_loss = 0.69124139, grad/param norm = 3.1726e-01, time/batch = 16.8641s	
8542/11350 (epoch 37.630), train_loss = 0.68259711, grad/param norm = 3.4657e-01, time/batch = 16.9420s	
8543/11350 (epoch 37.634), train_loss = 0.67766111, grad/param norm = 3.3942e-01, time/batch = 16.5571s	
8544/11350 (epoch 37.639), train_loss = 0.61541291, grad/param norm = 2.9393e-01, time/batch = 16.1563s	
8545/11350 (epoch 37.643), train_loss = 0.58047683, grad/param norm = 3.5030e-01, time/batch = 16.8568s	
8546/11350 (epoch 37.648), train_loss = 0.65996331, grad/param norm = 3.4587e-01, time/batch = 16.5550s	
8547/11350 (epoch 37.652), train_loss = 0.58443741, grad/param norm = 3.2876e-01, time/batch = 17.0159s	
8548/11350 (epoch 37.656), train_loss = 0.69674695, grad/param norm = 2.9993e-01, time/batch = 16.3134s	
8549/11350 (epoch 37.661), train_loss = 0.67321932, grad/param norm = 2.8356e-01, time/batch = 16.7868s	
8550/11350 (epoch 37.665), train_loss = 0.72647747, grad/param norm = 4.0723e-01, time/batch = 16.3930s	
8551/11350 (epoch 37.670), train_loss = 0.69626739, grad/param norm = 2.9681e-01, time/batch = 16.9208s	
8552/11350 (epoch 37.674), train_loss = 0.65275820, grad/param norm = 3.1220e-01, time/batch = 16.3737s	
8553/11350 (epoch 37.678), train_loss = 0.70467826, grad/param norm = 3.2764e-01, time/batch = 17.0209s	
8554/11350 (epoch 37.683), train_loss = 0.64988944, grad/param norm = 3.7447e-01, time/batch = 16.7821s	
8555/11350 (epoch 37.687), train_loss = 0.60216634, grad/param norm = 3.3858e-01, time/batch = 16.3103s	
8556/11350 (epoch 37.692), train_loss = 0.87608887, grad/param norm = 3.7202e-01, time/batch = 16.7908s	
8557/11350 (epoch 37.696), train_loss = 0.85809928, grad/param norm = 3.7928e-01, time/batch = 16.8027s	
8558/11350 (epoch 37.700), train_loss = 0.77935541, grad/param norm = 3.9875e-01, time/batch = 16.8796s	
8559/11350 (epoch 37.705), train_loss = 0.83654063, grad/param norm = 4.3007e-01, time/batch = 16.8669s	
8560/11350 (epoch 37.709), train_loss = 0.78732589, grad/param norm = 3.2964e-01, time/batch = 16.7713s	
8561/11350 (epoch 37.714), train_loss = 0.70011141, grad/param norm = 2.9872e-01, time/batch = 16.1479s	
8562/11350 (epoch 37.718), train_loss = 0.59955025, grad/param norm = 2.9953e-01, time/batch = 16.4706s	
8563/11350 (epoch 37.722), train_loss = 0.69024087, grad/param norm = 4.0090e-01, time/batch = 17.2123s	
8564/11350 (epoch 37.727), train_loss = 0.71582960, grad/param norm = 3.5993e-01, time/batch = 17.4330s	
8565/11350 (epoch 37.731), train_loss = 0.66110345, grad/param norm = 3.1684e-01, time/batch = 17.2600s	
8566/11350 (epoch 37.736), train_loss = 0.62243194, grad/param norm = 4.0539e-01, time/batch = 17.0201s	
8567/11350 (epoch 37.740), train_loss = 0.66967238, grad/param norm = 3.0610e-01, time/batch = 17.4361s	
8568/11350 (epoch 37.744), train_loss = 0.67416395, grad/param norm = 3.7159e-01, time/batch = 17.0544s	
8569/11350 (epoch 37.749), train_loss = 0.65952590, grad/param norm = 3.3435e-01, time/batch = 17.3624s	
8570/11350 (epoch 37.753), train_loss = 0.74893913, grad/param norm = 3.7048e-01, time/batch = 17.2067s	
8571/11350 (epoch 37.758), train_loss = 0.65317136, grad/param norm = 3.5197e-01, time/batch = 17.3584s	
8572/11350 (epoch 37.762), train_loss = 0.79035299, grad/param norm = 3.2894e-01, time/batch = 17.3741s	
8573/11350 (epoch 37.767), train_loss = 0.79281915, grad/param norm = 2.9887e-01, time/batch = 17.1398s	
8574/11350 (epoch 37.771), train_loss = 0.88126662, grad/param norm = 4.4692e-01, time/batch = 17.3640s	
8575/11350 (epoch 37.775), train_loss = 0.71587837, grad/param norm = 3.5302e-01, time/batch = 17.0434s	
8576/11350 (epoch 37.780), train_loss = 0.74556777, grad/param norm = 3.4128e-01, time/batch = 17.1960s	
8577/11350 (epoch 37.784), train_loss = 0.70418639, grad/param norm = 3.5416e-01, time/batch = 17.1958s	
8578/11350 (epoch 37.789), train_loss = 0.71588190, grad/param norm = 4.0533e-01, time/batch = 17.0508s	
8579/11350 (epoch 37.793), train_loss = 0.77888342, grad/param norm = 3.5899e-01, time/batch = 17.2003s	
8580/11350 (epoch 37.797), train_loss = 0.70313489, grad/param norm = 2.9053e-01, time/batch = 17.1391s	
8581/11350 (epoch 37.802), train_loss = 0.71774486, grad/param norm = 3.1056e-01, time/batch = 17.5968s	
8582/11350 (epoch 37.806), train_loss = 0.74318643, grad/param norm = 3.0767e-01, time/batch = 17.4774s	
8583/11350 (epoch 37.811), train_loss = 0.71549464, grad/param norm = 3.1335e-01, time/batch = 16.8760s	
8584/11350 (epoch 37.815), train_loss = 0.68646660, grad/param norm = 3.2894e-01, time/batch = 17.0281s	
8585/11350 (epoch 37.819), train_loss = 0.60831590, grad/param norm = 3.1686e-01, time/batch = 17.0321s	
8586/11350 (epoch 37.824), train_loss = 0.60863433, grad/param norm = 2.9891e-01, time/batch = 16.4584s	
8587/11350 (epoch 37.828), train_loss = 0.63524064, grad/param norm = 3.0914e-01, time/batch = 16.7900s	
8588/11350 (epoch 37.833), train_loss = 0.68248413, grad/param norm = 4.4108e-01, time/batch = 17.1049s	
8589/11350 (epoch 37.837), train_loss = 0.70714110, grad/param norm = 3.7237e-01, time/batch = 16.6902s	
8590/11350 (epoch 37.841), train_loss = 0.95334190, grad/param norm = 4.5998e-01, time/batch = 16.9550s	
8591/11350 (epoch 37.846), train_loss = 0.74733104, grad/param norm = 3.3171e-01, time/batch = 17.1209s	
8592/11350 (epoch 37.850), train_loss = 0.78300465, grad/param norm = 3.6121e-01, time/batch = 16.6385s	
8593/11350 (epoch 37.855), train_loss = 0.60008752, grad/param norm = 3.1949e-01, time/batch = 16.3914s	
8594/11350 (epoch 37.859), train_loss = 0.66618576, grad/param norm = 4.5415e-01, time/batch = 16.9577s	
8595/11350 (epoch 37.863), train_loss = 0.62301636, grad/param norm = 3.0501e-01, time/batch = 16.9249s	
8596/11350 (epoch 37.868), train_loss = 0.61838596, grad/param norm = 2.8248e-01, time/batch = 17.1085s	
8597/11350 (epoch 37.872), train_loss = 0.64940066, grad/param norm = 3.4995e-01, time/batch = 16.7200s	
8598/11350 (epoch 37.877), train_loss = 0.64577527, grad/param norm = 3.5945e-01, time/batch = 16.9488s	
8599/11350 (epoch 37.881), train_loss = 0.83883756, grad/param norm = 3.6958e-01, time/batch = 16.4704s	
8600/11350 (epoch 37.885), train_loss = 0.77499686, grad/param norm = 3.2226e-01, time/batch = 16.7103s	
8601/11350 (epoch 37.890), train_loss = 0.74786220, grad/param norm = 4.1052e-01, time/batch = 17.4296s	
8602/11350 (epoch 37.894), train_loss = 0.62743553, grad/param norm = 3.4969e-01, time/batch = 16.6943s	
8603/11350 (epoch 37.899), train_loss = 0.74984018, grad/param norm = 3.3261e-01, time/batch = 16.2218s	
8604/11350 (epoch 37.903), train_loss = 0.74841650, grad/param norm = 4.7328e-01, time/batch = 16.3736s	
8605/11350 (epoch 37.907), train_loss = 0.65937178, grad/param norm = 3.8954e-01, time/batch = 16.8635s	
8606/11350 (epoch 37.912), train_loss = 0.62436701, grad/param norm = 2.9961e-01, time/batch = 17.0841s	
8607/11350 (epoch 37.916), train_loss = 0.70745058, grad/param norm = 3.3375e-01, time/batch = 16.6385s	
8608/11350 (epoch 37.921), train_loss = 0.71634605, grad/param norm = 3.0227e-01, time/batch = 16.6420s	
8609/11350 (epoch 37.925), train_loss = 0.60727246, grad/param norm = 2.9582e-01, time/batch = 17.1136s	
8610/11350 (epoch 37.930), train_loss = 0.72880373, grad/param norm = 4.1959e-01, time/batch = 16.5518s	
8611/11350 (epoch 37.934), train_loss = 0.79885244, grad/param norm = 3.5378e-01, time/batch = 16.3824s	
8612/11350 (epoch 37.938), train_loss = 0.70879016, grad/param norm = 3.4301e-01, time/batch = 16.2948s	
8613/11350 (epoch 37.943), train_loss = 0.74804924, grad/param norm = 3.3184e-01, time/batch = 17.0190s	
8614/11350 (epoch 37.947), train_loss = 0.71247488, grad/param norm = 3.2684e-01, time/batch = 16.8855s	
8615/11350 (epoch 37.952), train_loss = 0.72704232, grad/param norm = 3.3809e-01, time/batch = 16.7173s	
8616/11350 (epoch 37.956), train_loss = 0.60869075, grad/param norm = 3.8834e-01, time/batch = 16.9612s	
8617/11350 (epoch 37.960), train_loss = 0.67554957, grad/param norm = 3.7147e-01, time/batch = 16.8701s	
8618/11350 (epoch 37.965), train_loss = 0.57392404, grad/param norm = 2.9164e-01, time/batch = 16.6482s	
8619/11350 (epoch 37.969), train_loss = 0.61453442, grad/param norm = 4.2264e-01, time/batch = 16.3964s	
8620/11350 (epoch 37.974), train_loss = 0.58519801, grad/param norm = 3.3699e-01, time/batch = 16.7857s	
8621/11350 (epoch 37.978), train_loss = 0.66765634, grad/param norm = 3.5031e-01, time/batch = 16.3981s	
8622/11350 (epoch 37.982), train_loss = 0.44990896, grad/param norm = 3.0113e-01, time/batch = 17.1696s	
8623/11350 (epoch 37.987), train_loss = 0.66469640, grad/param norm = 3.3825e-01, time/batch = 17.0276s	
8624/11350 (epoch 37.991), train_loss = 0.60355464, grad/param norm = 3.7560e-01, time/batch = 17.4262s	
8625/11350 (epoch 37.996), train_loss = 0.65163485, grad/param norm = 3.4897e-01, time/batch = 16.8801s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
8626/11350 (epoch 38.000), train_loss = 0.52477000, grad/param norm = 3.0372e-01, time/batch = 16.7948s	
8627/11350 (epoch 38.004), train_loss = 0.71319420, grad/param norm = 3.3768e-01, time/batch = 16.8717s	
8628/11350 (epoch 38.009), train_loss = 0.69853427, grad/param norm = 3.4911e-01, time/batch = 16.7023s	
8629/11350 (epoch 38.013), train_loss = 0.48312281, grad/param norm = 2.9084e-01, time/batch = 17.0209s	
8630/11350 (epoch 38.018), train_loss = 0.53583094, grad/param norm = 2.9272e-01, time/batch = 17.0211s	
8631/11350 (epoch 38.022), train_loss = 0.56446722, grad/param norm = 5.1886e-01, time/batch = 17.0392s	
8632/11350 (epoch 38.026), train_loss = 0.54490657, grad/param norm = 3.3868e-01, time/batch = 16.9596s	
8633/11350 (epoch 38.031), train_loss = 0.56514805, grad/param norm = 3.1067e-01, time/batch = 17.1158s	
8634/11350 (epoch 38.035), train_loss = 0.58472158, grad/param norm = 3.0686e-01, time/batch = 17.3399s	
8635/11350 (epoch 38.040), train_loss = 0.60410753, grad/param norm = 3.4836e-01, time/batch = 17.3266s	
8636/11350 (epoch 38.044), train_loss = 0.55570061, grad/param norm = 2.8971e-01, time/batch = 17.1211s	
8637/11350 (epoch 38.048), train_loss = 0.53227614, grad/param norm = 2.9954e-01, time/batch = 17.4806s	
8638/11350 (epoch 38.053), train_loss = 0.58190460, grad/param norm = 3.0472e-01, time/batch = 16.9406s	
8639/11350 (epoch 38.057), train_loss = 0.58629126, grad/param norm = 3.5506e-01, time/batch = 16.9483s	
8640/11350 (epoch 38.062), train_loss = 0.49932153, grad/param norm = 3.0491e-01, time/batch = 17.2359s	
8641/11350 (epoch 38.066), train_loss = 0.50182882, grad/param norm = 3.4841e-01, time/batch = 17.0430s	
8642/11350 (epoch 38.070), train_loss = 0.59315475, grad/param norm = 4.1892e-01, time/batch = 16.8631s	
8643/11350 (epoch 38.075), train_loss = 0.52271823, grad/param norm = 3.1635e-01, time/batch = 16.4012s	
8644/11350 (epoch 38.079), train_loss = 0.62320581, grad/param norm = 3.3362e-01, time/batch = 16.7771s	
8645/11350 (epoch 38.084), train_loss = 0.71562139, grad/param norm = 3.5688e-01, time/batch = 16.6282s	
8646/11350 (epoch 38.088), train_loss = 0.67717923, grad/param norm = 3.6314e-01, time/batch = 16.6000s	
8647/11350 (epoch 38.093), train_loss = 0.66765717, grad/param norm = 3.2532e-01, time/batch = 16.7724s	
8648/11350 (epoch 38.097), train_loss = 0.59075341, grad/param norm = 3.0358e-01, time/batch = 17.0361s	
8649/11350 (epoch 38.101), train_loss = 0.55849996, grad/param norm = 3.1873e-01, time/batch = 16.6204s	
8650/11350 (epoch 38.106), train_loss = 0.65732137, grad/param norm = 4.4651e-01, time/batch = 16.6305s	
8651/11350 (epoch 38.110), train_loss = 0.58584002, grad/param norm = 3.7611e-01, time/batch = 16.8708s	
8652/11350 (epoch 38.115), train_loss = 0.59193785, grad/param norm = 3.8193e-01, time/batch = 16.9372s	
8653/11350 (epoch 38.119), train_loss = 0.69970424, grad/param norm = 4.2001e-01, time/batch = 16.8204s	
8654/11350 (epoch 38.123), train_loss = 0.56916771, grad/param norm = 3.5989e-01, time/batch = 16.7225s	
8655/11350 (epoch 38.128), train_loss = 0.49808667, grad/param norm = 3.0657e-01, time/batch = 17.0274s	
8656/11350 (epoch 38.132), train_loss = 0.55048642, grad/param norm = 2.9592e-01, time/batch = 17.4292s	
8657/11350 (epoch 38.137), train_loss = 0.53280769, grad/param norm = 3.5992e-01, time/batch = 16.8000s	
8658/11350 (epoch 38.141), train_loss = 0.68227146, grad/param norm = 3.4696e-01, time/batch = 16.8765s	
8659/11350 (epoch 38.145), train_loss = 0.57096727, grad/param norm = 3.4417e-01, time/batch = 16.3946s	
8660/11350 (epoch 38.150), train_loss = 0.62676058, grad/param norm = 4.0768e-01, time/batch = 17.3957s	
8661/11350 (epoch 38.154), train_loss = 0.72713429, grad/param norm = 4.4827e-01, time/batch = 16.7839s	
8662/11350 (epoch 38.159), train_loss = 0.52481782, grad/param norm = 3.2858e-01, time/batch = 17.0255s	
8663/11350 (epoch 38.163), train_loss = 0.65592136, grad/param norm = 3.6964e-01, time/batch = 16.5442s	
8664/11350 (epoch 38.167), train_loss = 0.69146305, grad/param norm = 3.3439e-01, time/batch = 16.9005s	
8665/11350 (epoch 38.172), train_loss = 0.76073203, grad/param norm = 3.0299e-01, time/batch = 16.7930s	
8666/11350 (epoch 38.176), train_loss = 0.61445641, grad/param norm = 3.0668e-01, time/batch = 32.4991s	
8667/11350 (epoch 38.181), train_loss = 0.60437061, grad/param norm = 3.8569e-01, time/batch = 17.6674s	
8668/11350 (epoch 38.185), train_loss = 0.56472444, grad/param norm = 3.3495e-01, time/batch = 17.3407s	
8669/11350 (epoch 38.189), train_loss = 0.58712185, grad/param norm = 3.2109e-01, time/batch = 16.8642s	
8670/11350 (epoch 38.194), train_loss = 0.51941140, grad/param norm = 3.2343e-01, time/batch = 16.7989s	
8671/11350 (epoch 38.198), train_loss = 0.48827825, grad/param norm = 3.8538e-01, time/batch = 16.8032s	
8672/11350 (epoch 38.203), train_loss = 0.55733966, grad/param norm = 4.3552e-01, time/batch = 17.4453s	
8673/11350 (epoch 38.207), train_loss = 0.51152396, grad/param norm = 3.9457e-01, time/batch = 16.8769s	
8674/11350 (epoch 38.211), train_loss = 0.68445070, grad/param norm = 3.7093e-01, time/batch = 16.8871s	
8675/11350 (epoch 38.216), train_loss = 0.65436585, grad/param norm = 4.3537e-01, time/batch = 16.8702s	
8676/11350 (epoch 38.220), train_loss = 0.66022696, grad/param norm = 3.7553e-01, time/batch = 16.6415s	
8677/11350 (epoch 38.225), train_loss = 0.58202666, grad/param norm = 3.1422e-01, time/batch = 17.1967s	
8678/11350 (epoch 38.229), train_loss = 0.62696939, grad/param norm = 3.3183e-01, time/batch = 17.0363s	
8679/11350 (epoch 38.233), train_loss = 0.59175697, grad/param norm = 3.3241e-01, time/batch = 17.3442s	
8680/11350 (epoch 38.238), train_loss = 0.71623400, grad/param norm = 4.8736e-01, time/batch = 16.9537s	
8681/11350 (epoch 38.242), train_loss = 0.71126528, grad/param norm = 4.1222e-01, time/batch = 17.3553s	
8682/11350 (epoch 38.247), train_loss = 0.53794450, grad/param norm = 3.0282e-01, time/batch = 17.4212s	
8683/11350 (epoch 38.251), train_loss = 0.60086475, grad/param norm = 3.5520e-01, time/batch = 17.0171s	
8684/11350 (epoch 38.256), train_loss = 0.63673430, grad/param norm = 2.7699e-01, time/batch = 17.1963s	
8685/11350 (epoch 38.260), train_loss = 0.55491218, grad/param norm = 2.6849e-01, time/batch = 16.9675s	
8686/11350 (epoch 38.264), train_loss = 0.55566582, grad/param norm = 3.2256e-01, time/batch = 17.1939s	
8687/11350 (epoch 38.269), train_loss = 0.60588440, grad/param norm = 2.9807e-01, time/batch = 17.1025s	
8688/11350 (epoch 38.273), train_loss = 0.69267482, grad/param norm = 3.2443e-01, time/batch = 16.2343s	
8689/11350 (epoch 38.278), train_loss = 0.56462409, grad/param norm = 2.6187e-01, time/batch = 16.8757s	
8690/11350 (epoch 38.282), train_loss = 0.57605139, grad/param norm = 3.2939e-01, time/batch = 16.8745s	
8691/11350 (epoch 38.286), train_loss = 0.67175192, grad/param norm = 3.3800e-01, time/batch = 16.5539s	
8692/11350 (epoch 38.291), train_loss = 0.55469196, grad/param norm = 3.2536e-01, time/batch = 17.0340s	
8693/11350 (epoch 38.295), train_loss = 0.60242975, grad/param norm = 3.6709e-01, time/batch = 17.1001s	
8694/11350 (epoch 38.300), train_loss = 0.69536569, grad/param norm = 3.8323e-01, time/batch = 16.6370s	
8695/11350 (epoch 38.304), train_loss = 0.55190026, grad/param norm = 3.6342e-01, time/batch = 16.7203s	
8696/11350 (epoch 38.308), train_loss = 0.53995159, grad/param norm = 3.6147e-01, time/batch = 16.7053s	
8697/11350 (epoch 38.313), train_loss = 0.60150260, grad/param norm = 3.1779e-01, time/batch = 16.6214s	
8698/11350 (epoch 38.317), train_loss = 0.59427713, grad/param norm = 2.8521e-01, time/batch = 16.8808s	
8699/11350 (epoch 38.322), train_loss = 0.59080209, grad/param norm = 3.8576e-01, time/batch = 16.9481s	
8700/11350 (epoch 38.326), train_loss = 0.60134232, grad/param norm = 3.3338e-01, time/batch = 17.3312s	
8701/11350 (epoch 38.330), train_loss = 0.50294153, grad/param norm = 2.6992e-01, time/batch = 16.6376s	
8702/11350 (epoch 38.335), train_loss = 0.40883007, grad/param norm = 2.9825e-01, time/batch = 16.5587s	
8703/11350 (epoch 38.339), train_loss = 0.43459474, grad/param norm = 2.7930e-01, time/batch = 16.7870s	
8704/11350 (epoch 38.344), train_loss = 0.54210679, grad/param norm = 2.6040e-01, time/batch = 16.8666s	
8705/11350 (epoch 38.348), train_loss = 0.56944653, grad/param norm = 3.2667e-01, time/batch = 16.5451s	
8706/11350 (epoch 38.352), train_loss = 0.46296391, grad/param norm = 2.6149e-01, time/batch = 16.7726s	
8707/11350 (epoch 38.357), train_loss = 0.55394380, grad/param norm = 2.8951e-01, time/batch = 17.1103s	
8708/11350 (epoch 38.361), train_loss = 0.45192213, grad/param norm = 2.4309e-01, time/batch = 16.7168s	
8709/11350 (epoch 38.366), train_loss = 0.57142867, grad/param norm = 3.1181e-01, time/batch = 17.2639s	
8710/11350 (epoch 38.370), train_loss = 0.48712703, grad/param norm = 3.7482e-01, time/batch = 16.7874s	
8711/11350 (epoch 38.374), train_loss = 0.53552320, grad/param norm = 3.0278e-01, time/batch = 16.7205s	
8712/11350 (epoch 38.379), train_loss = 0.53164908, grad/param norm = 3.2374e-01, time/batch = 17.5143s	
8713/11350 (epoch 38.383), train_loss = 0.48440469, grad/param norm = 3.4956e-01, time/batch = 16.8970s	
8714/11350 (epoch 38.388), train_loss = 0.55191041, grad/param norm = 3.2963e-01, time/batch = 17.3541s	
8715/11350 (epoch 38.392), train_loss = 0.64692244, grad/param norm = 3.3055e-01, time/batch = 16.7245s	
8716/11350 (epoch 38.396), train_loss = 0.54439795, grad/param norm = 3.5955e-01, time/batch = 16.7932s	
8717/11350 (epoch 38.401), train_loss = 0.55828569, grad/param norm = 4.4685e-01, time/batch = 16.7821s	
8718/11350 (epoch 38.405), train_loss = 0.73424632, grad/param norm = 4.4154e-01, time/batch = 17.0989s	
8719/11350 (epoch 38.410), train_loss = 0.74008640, grad/param norm = 4.0734e-01, time/batch = 16.9460s	
8720/11350 (epoch 38.414), train_loss = 0.51866731, grad/param norm = 3.1402e-01, time/batch = 16.8601s	
8721/11350 (epoch 38.419), train_loss = 0.52797745, grad/param norm = 3.3538e-01, time/batch = 17.2797s	
8722/11350 (epoch 38.423), train_loss = 0.55118609, grad/param norm = 3.6163e-01, time/batch = 16.6473s	
8723/11350 (epoch 38.427), train_loss = 0.62059450, grad/param norm = 3.2306e-01, time/batch = 16.7060s	
8724/11350 (epoch 38.432), train_loss = 0.60564695, grad/param norm = 4.3390e-01, time/batch = 17.0414s	
8725/11350 (epoch 38.436), train_loss = 0.52122736, grad/param norm = 3.4047e-01, time/batch = 17.0312s	
8726/11350 (epoch 38.441), train_loss = 0.70467054, grad/param norm = 4.5513e-01, time/batch = 16.6241s	
8727/11350 (epoch 38.445), train_loss = 0.55429453, grad/param norm = 3.9024e-01, time/batch = 16.6250s	
8728/11350 (epoch 38.449), train_loss = 0.62358376, grad/param norm = 3.9744e-01, time/batch = 17.0170s	
8729/11350 (epoch 38.454), train_loss = 0.73410845, grad/param norm = 3.8038e-01, time/batch = 17.5410s	
8730/11350 (epoch 38.458), train_loss = 0.51058606, grad/param norm = 3.0061e-01, time/batch = 17.4604s	
8731/11350 (epoch 38.463), train_loss = 0.51153474, grad/param norm = 3.3621e-01, time/batch = 17.4694s	
8732/11350 (epoch 38.467), train_loss = 0.77721908, grad/param norm = 3.8154e-01, time/batch = 17.0924s	
8733/11350 (epoch 38.471), train_loss = 0.73944759, grad/param norm = 5.0287e-01, time/batch = 16.7262s	
8734/11350 (epoch 38.476), train_loss = 0.63969341, grad/param norm = 4.3135e-01, time/batch = 17.2684s	
8735/11350 (epoch 38.480), train_loss = 0.70839504, grad/param norm = 4.0799e-01, time/batch = 17.2599s	
8736/11350 (epoch 38.485), train_loss = 0.64830151, grad/param norm = 3.7967e-01, time/batch = 16.8836s	
8737/11350 (epoch 38.489), train_loss = 0.67627309, grad/param norm = 3.5775e-01, time/batch = 16.8691s	
8738/11350 (epoch 38.493), train_loss = 0.70711484, grad/param norm = 3.4761e-01, time/batch = 17.2468s	
8739/11350 (epoch 38.498), train_loss = 0.45708131, grad/param norm = 3.1480e-01, time/batch = 16.9565s	
8740/11350 (epoch 38.502), train_loss = 0.72777920, grad/param norm = 3.9375e-01, time/batch = 16.5534s	
8741/11350 (epoch 38.507), train_loss = 0.53438389, grad/param norm = 3.3499e-01, time/batch = 16.5583s	
8742/11350 (epoch 38.511), train_loss = 0.65706098, grad/param norm = 3.0913e-01, time/batch = 17.4998s	
8743/11350 (epoch 38.515), train_loss = 0.61403769, grad/param norm = 3.2237e-01, time/batch = 17.0960s	
8744/11350 (epoch 38.520), train_loss = 0.77374112, grad/param norm = 3.6689e-01, time/batch = 16.9569s	
8745/11350 (epoch 38.524), train_loss = 0.65090431, grad/param norm = 3.4424e-01, time/batch = 16.7123s	
8746/11350 (epoch 38.529), train_loss = 0.59234509, grad/param norm = 3.2973e-01, time/batch = 16.6369s	
8747/11350 (epoch 38.533), train_loss = 0.78259821, grad/param norm = 3.9252e-01, time/batch = 16.4695s	
8748/11350 (epoch 38.537), train_loss = 0.71809339, grad/param norm = 3.9580e-01, time/batch = 16.9717s	
8749/11350 (epoch 38.542), train_loss = 0.62806980, grad/param norm = 2.9320e-01, time/batch = 17.2923s	
8750/11350 (epoch 38.546), train_loss = 0.78552012, grad/param norm = 4.0581e-01, time/batch = 17.2762s	
8751/11350 (epoch 38.551), train_loss = 0.67262712, grad/param norm = 3.6245e-01, time/batch = 17.3635s	
8752/11350 (epoch 38.555), train_loss = 0.59468559, grad/param norm = 3.3079e-01, time/batch = 17.3376s	
8753/11350 (epoch 38.559), train_loss = 0.61748855, grad/param norm = 3.0138e-01, time/batch = 17.5111s	
8754/11350 (epoch 38.564), train_loss = 0.66132929, grad/param norm = 3.4593e-01, time/batch = 17.3015s	
8755/11350 (epoch 38.568), train_loss = 0.67921292, grad/param norm = 3.1136e-01, time/batch = 16.9369s	
8756/11350 (epoch 38.573), train_loss = 0.78396883, grad/param norm = 4.1533e-01, time/batch = 17.3962s	
8757/11350 (epoch 38.577), train_loss = 0.70609078, grad/param norm = 3.6862e-01, time/batch = 16.7858s	
8758/11350 (epoch 38.581), train_loss = 0.77364716, grad/param norm = 3.4622e-01, time/batch = 17.0167s	
8759/11350 (epoch 38.586), train_loss = 0.70932361, grad/param norm = 3.1560e-01, time/batch = 16.9518s	
8760/11350 (epoch 38.590), train_loss = 0.76630329, grad/param norm = 4.0072e-01, time/batch = 17.1715s	
8761/11350 (epoch 38.595), train_loss = 0.84347087, grad/param norm = 4.0116e-01, time/batch = 17.1012s	
8762/11350 (epoch 38.599), train_loss = 0.66421109, grad/param norm = 3.1613e-01, time/batch = 16.6281s	
8763/11350 (epoch 38.604), train_loss = 0.66781894, grad/param norm = 3.9298e-01, time/batch = 16.9560s	
8764/11350 (epoch 38.608), train_loss = 0.63961332, grad/param norm = 3.9607e-01, time/batch = 16.6409s	
8765/11350 (epoch 38.612), train_loss = 0.66472735, grad/param norm = 3.2783e-01, time/batch = 16.5511s	
8766/11350 (epoch 38.617), train_loss = 0.73495618, grad/param norm = 3.6951e-01, time/batch = 16.8696s	
8767/11350 (epoch 38.621), train_loss = 0.74758375, grad/param norm = 2.9838e-01, time/batch = 16.8609s	
8768/11350 (epoch 38.626), train_loss = 0.69037832, grad/param norm = 3.5140e-01, time/batch = 16.3966s	
8769/11350 (epoch 38.630), train_loss = 0.68005018, grad/param norm = 4.2174e-01, time/batch = 16.8678s	
8770/11350 (epoch 38.634), train_loss = 0.66536289, grad/param norm = 3.7231e-01, time/batch = 17.1752s	
8771/11350 (epoch 38.639), train_loss = 0.63705311, grad/param norm = 3.4059e-01, time/batch = 16.8866s	
8772/11350 (epoch 38.643), train_loss = 0.55235525, grad/param norm = 2.8240e-01, time/batch = 16.7945s	
8773/11350 (epoch 38.648), train_loss = 0.63012787, grad/param norm = 3.1953e-01, time/batch = 16.6457s	
8774/11350 (epoch 38.652), train_loss = 0.57983391, grad/param norm = 3.2029e-01, time/batch = 16.9596s	
8775/11350 (epoch 38.656), train_loss = 0.67682893, grad/param norm = 2.9702e-01, time/batch = 16.7204s	
8776/11350 (epoch 38.661), train_loss = 0.68521721, grad/param norm = 3.3490e-01, time/batch = 16.6325s	
8777/11350 (epoch 38.665), train_loss = 0.69895456, grad/param norm = 3.4109e-01, time/batch = 17.4080s	
8778/11350 (epoch 38.670), train_loss = 0.67702022, grad/param norm = 3.1997e-01, time/batch = 17.1121s	
8779/11350 (epoch 38.674), train_loss = 0.62916672, grad/param norm = 3.2058e-01, time/batch = 16.6167s	
8780/11350 (epoch 38.678), train_loss = 0.69578462, grad/param norm = 3.2853e-01, time/batch = 16.7995s	
8781/11350 (epoch 38.683), train_loss = 0.63171133, grad/param norm = 3.5424e-01, time/batch = 17.1051s	
8782/11350 (epoch 38.687), train_loss = 0.57650706, grad/param norm = 3.3205e-01, time/batch = 17.3306s	
8783/11350 (epoch 38.692), train_loss = 0.85718453, grad/param norm = 4.8837e-01, time/batch = 16.7255s	
8784/11350 (epoch 38.696), train_loss = 0.83460801, grad/param norm = 4.0920e-01, time/batch = 16.7040s	
8785/11350 (epoch 38.700), train_loss = 0.74603863, grad/param norm = 3.6017e-01, time/batch = 16.9583s	
8786/11350 (epoch 38.705), train_loss = 0.77496374, grad/param norm = 3.4121e-01, time/batch = 16.8036s	
8787/11350 (epoch 38.709), train_loss = 0.76713960, grad/param norm = 3.4920e-01, time/batch = 17.0395s	
8788/11350 (epoch 38.714), train_loss = 0.69645191, grad/param norm = 3.8148e-01, time/batch = 17.1012s	
8789/11350 (epoch 38.718), train_loss = 0.59176269, grad/param norm = 2.9303e-01, time/batch = 16.4678s	
8790/11350 (epoch 38.722), train_loss = 0.67955494, grad/param norm = 3.8369e-01, time/batch = 16.6374s	
8791/11350 (epoch 38.727), train_loss = 0.69584005, grad/param norm = 3.3865e-01, time/batch = 16.9515s	
8792/11350 (epoch 38.731), train_loss = 0.65517235, grad/param norm = 3.3369e-01, time/batch = 17.2089s	
8793/11350 (epoch 38.736), train_loss = 0.61917639, grad/param norm = 4.7105e-01, time/batch = 17.1079s	
8794/11350 (epoch 38.740), train_loss = 0.67245794, grad/param norm = 3.5232e-01, time/batch = 17.2298s	
8795/11350 (epoch 38.744), train_loss = 0.66251480, grad/param norm = 4.0812e-01, time/batch = 16.7868s	
8796/11350 (epoch 38.749), train_loss = 0.65440321, grad/param norm = 3.8346e-01, time/batch = 16.4796s	
8797/11350 (epoch 38.753), train_loss = 0.71485920, grad/param norm = 3.4000e-01, time/batch = 16.8721s	
8798/11350 (epoch 38.758), train_loss = 0.65918070, grad/param norm = 3.5940e-01, time/batch = 16.8575s	
8799/11350 (epoch 38.762), train_loss = 0.78035012, grad/param norm = 3.4958e-01, time/batch = 16.8938s	
8800/11350 (epoch 38.767), train_loss = 0.77278057, grad/param norm = 3.3921e-01, time/batch = 16.6374s	
8801/11350 (epoch 38.771), train_loss = 0.85622746, grad/param norm = 3.9361e-01, time/batch = 16.9523s	
8802/11350 (epoch 38.775), train_loss = 0.69797855, grad/param norm = 3.2149e-01, time/batch = 17.0242s	
8803/11350 (epoch 38.780), train_loss = 0.72965676, grad/param norm = 3.1598e-01, time/batch = 16.6339s	
8804/11350 (epoch 38.784), train_loss = 0.68256700, grad/param norm = 3.5067e-01, time/batch = 17.1276s	
8805/11350 (epoch 38.789), train_loss = 0.68867752, grad/param norm = 3.2934e-01, time/batch = 16.6285s	
8806/11350 (epoch 38.793), train_loss = 0.75166018, grad/param norm = 3.1366e-01, time/batch = 16.9322s	
8807/11350 (epoch 38.797), train_loss = 0.69722738, grad/param norm = 3.0788e-01, time/batch = 16.4736s	
8808/11350 (epoch 38.802), train_loss = 0.70136388, grad/param norm = 3.2211e-01, time/batch = 16.8758s	
8809/11350 (epoch 38.806), train_loss = 0.71495259, grad/param norm = 2.8682e-01, time/batch = 16.6272s	
8810/11350 (epoch 38.811), train_loss = 0.69474061, grad/param norm = 3.5159e-01, time/batch = 16.8017s	
8811/11350 (epoch 38.815), train_loss = 0.68758493, grad/param norm = 3.3272e-01, time/batch = 16.8905s	
8812/11350 (epoch 38.819), train_loss = 0.60283763, grad/param norm = 3.2158e-01, time/batch = 16.3979s	
8813/11350 (epoch 38.824), train_loss = 0.60858187, grad/param norm = 4.0117e-01, time/batch = 16.4659s	
8814/11350 (epoch 38.828), train_loss = 0.63488429, grad/param norm = 3.1289e-01, time/batch = 16.6331s	
8815/11350 (epoch 38.833), train_loss = 0.66798923, grad/param norm = 3.4306e-01, time/batch = 16.8878s	
8816/11350 (epoch 38.837), train_loss = 0.69661560, grad/param norm = 4.0407e-01, time/batch = 17.0262s	
8817/11350 (epoch 38.841), train_loss = 0.91287856, grad/param norm = 3.7618e-01, time/batch = 16.7127s	
8818/11350 (epoch 38.846), train_loss = 0.75508670, grad/param norm = 3.1601e-01, time/batch = 16.7064s	
8819/11350 (epoch 38.850), train_loss = 0.75596527, grad/param norm = 3.5437e-01, time/batch = 17.3920s	
8820/11350 (epoch 38.855), train_loss = 0.60287265, grad/param norm = 3.4029e-01, time/batch = 17.1017s	
8821/11350 (epoch 38.859), train_loss = 0.64149123, grad/param norm = 4.1398e-01, time/batch = 16.5606s	
8822/11350 (epoch 38.863), train_loss = 0.60162341, grad/param norm = 3.4445e-01, time/batch = 16.7170s	
8823/11350 (epoch 38.868), train_loss = 0.60553008, grad/param norm = 3.0169e-01, time/batch = 17.3419s	
8824/11350 (epoch 38.872), train_loss = 0.62421385, grad/param norm = 3.2584e-01, time/batch = 16.8002s	
8825/11350 (epoch 38.877), train_loss = 0.64355499, grad/param norm = 4.2577e-01, time/batch = 17.1021s	
8826/11350 (epoch 38.881), train_loss = 0.82825404, grad/param norm = 4.3578e-01, time/batch = 16.3070s	
8827/11350 (epoch 38.885), train_loss = 0.77739384, grad/param norm = 3.5335e-01, time/batch = 17.1864s	
8828/11350 (epoch 38.890), train_loss = 0.71740711, grad/param norm = 3.7854e-01, time/batch = 16.7211s	
8829/11350 (epoch 38.894), train_loss = 0.58705422, grad/param norm = 3.2181e-01, time/batch = 16.7088s	
8830/11350 (epoch 38.899), train_loss = 0.74639041, grad/param norm = 3.3921e-01, time/batch = 17.1104s	
8831/11350 (epoch 38.903), train_loss = 0.70522536, grad/param norm = 3.6585e-01, time/batch = 16.9678s	
8832/11350 (epoch 38.907), train_loss = 0.63358883, grad/param norm = 3.8414e-01, time/batch = 16.8777s	
8833/11350 (epoch 38.912), train_loss = 0.61591718, grad/param norm = 3.0854e-01, time/batch = 16.8109s	
8834/11350 (epoch 38.916), train_loss = 0.68762197, grad/param norm = 3.5547e-01, time/batch = 17.2750s	
8835/11350 (epoch 38.921), train_loss = 0.68500831, grad/param norm = 3.1032e-01, time/batch = 16.3974s	
8836/11350 (epoch 38.925), train_loss = 0.58477924, grad/param norm = 2.9542e-01, time/batch = 16.6390s	
8837/11350 (epoch 38.930), train_loss = 0.68167099, grad/param norm = 3.3640e-01, time/batch = 16.8711s	
8838/11350 (epoch 38.934), train_loss = 0.78590016, grad/param norm = 3.6534e-01, time/batch = 17.1414s	
8839/11350 (epoch 38.938), train_loss = 0.68156019, grad/param norm = 3.3041e-01, time/batch = 16.7928s	
8840/11350 (epoch 38.943), train_loss = 0.74600868, grad/param norm = 3.6794e-01, time/batch = 17.1842s	
8841/11350 (epoch 38.947), train_loss = 0.71547180, grad/param norm = 4.1643e-01, time/batch = 17.3581s	
8842/11350 (epoch 38.952), train_loss = 0.71882476, grad/param norm = 3.5168e-01, time/batch = 17.0399s	
8843/11350 (epoch 38.956), train_loss = 0.57539235, grad/param norm = 2.8558e-01, time/batch = 17.1097s	
8844/11350 (epoch 38.960), train_loss = 0.65233076, grad/param norm = 3.5608e-01, time/batch = 17.1868s	
8845/11350 (epoch 38.965), train_loss = 0.54932984, grad/param norm = 2.7933e-01, time/batch = 17.3517s	
8846/11350 (epoch 38.969), train_loss = 0.58057343, grad/param norm = 3.2637e-01, time/batch = 17.0894s	
8847/11350 (epoch 38.974), train_loss = 0.57403444, grad/param norm = 2.8805e-01, time/batch = 17.0503s	
8848/11350 (epoch 38.978), train_loss = 0.65183437, grad/param norm = 2.8711e-01, time/batch = 17.3517s	
8849/11350 (epoch 38.982), train_loss = 0.44522835, grad/param norm = 2.9350e-01, time/batch = 16.6904s	
8850/11350 (epoch 38.987), train_loss = 0.65786687, grad/param norm = 3.5675e-01, time/batch = 16.7140s	
8851/11350 (epoch 38.991), train_loss = 0.57195346, grad/param norm = 3.0108e-01, time/batch = 16.5503s	
8852/11350 (epoch 38.996), train_loss = 0.63442116, grad/param norm = 3.5789e-01, time/batch = 16.7179s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
8853/11350 (epoch 39.000), train_loss = 0.52778379, grad/param norm = 3.7089e-01, time/batch = 16.3105s	
8854/11350 (epoch 39.004), train_loss = 0.71315536, grad/param norm = 3.3803e-01, time/batch = 17.0379s	
8855/11350 (epoch 39.009), train_loss = 0.66256859, grad/param norm = 3.0587e-01, time/batch = 17.1932s	
8856/11350 (epoch 39.013), train_loss = 0.46829053, grad/param norm = 2.8967e-01, time/batch = 16.7085s	
8857/11350 (epoch 39.018), train_loss = 0.53333116, grad/param norm = 3.3322e-01, time/batch = 16.7179s	
8858/11350 (epoch 39.022), train_loss = 0.56040726, grad/param norm = 4.3174e-01, time/batch = 16.8733s	
8859/11350 (epoch 39.026), train_loss = 0.54444040, grad/param norm = 5.2024e-01, time/batch = 17.1727s	
8860/11350 (epoch 39.031), train_loss = 0.56921264, grad/param norm = 3.8758e-01, time/batch = 16.7369s	
8861/11350 (epoch 39.035), train_loss = 0.55660050, grad/param norm = 2.7743e-01, time/batch = 17.1194s	
8862/11350 (epoch 39.040), train_loss = 0.57857382, grad/param norm = 3.0073e-01, time/batch = 16.6128s	
8863/11350 (epoch 39.044), train_loss = 0.54213750, grad/param norm = 2.8188e-01, time/batch = 17.3406s	
8864/11350 (epoch 39.048), train_loss = 0.53811619, grad/param norm = 3.9870e-01, time/batch = 16.5500s	
8865/11350 (epoch 39.053), train_loss = 0.59020489, grad/param norm = 3.0960e-01, time/batch = 16.7231s	
8866/11350 (epoch 39.057), train_loss = 0.59448650, grad/param norm = 4.1253e-01, time/batch = 16.8763s	
8867/11350 (epoch 39.062), train_loss = 0.49633466, grad/param norm = 3.1361e-01, time/batch = 17.1748s	
8868/11350 (epoch 39.066), train_loss = 0.48919621, grad/param norm = 3.0419e-01, time/batch = 16.5534s	
8869/11350 (epoch 39.070), train_loss = 0.56309655, grad/param norm = 3.3698e-01, time/batch = 16.4560s	
8870/11350 (epoch 39.075), train_loss = 0.51480388, grad/param norm = 3.0750e-01, time/batch = 16.7192s	
8871/11350 (epoch 39.079), train_loss = 0.62952183, grad/param norm = 3.6940e-01, time/batch = 16.9724s	
8872/11350 (epoch 39.084), train_loss = 0.70613586, grad/param norm = 3.4486e-01, time/batch = 16.8862s	
8873/11350 (epoch 39.088), train_loss = 0.68189665, grad/param norm = 4.3363e-01, time/batch = 17.0397s	
8874/11350 (epoch 39.093), train_loss = 0.66528847, grad/param norm = 3.3740e-01, time/batch = 16.7964s	
8875/11350 (epoch 39.097), train_loss = 0.59828995, grad/param norm = 3.5077e-01, time/batch = 17.0308s	
8876/11350 (epoch 39.101), train_loss = 0.54518658, grad/param norm = 2.9091e-01, time/batch = 20.5482s	
8877/11350 (epoch 39.106), train_loss = 0.62089262, grad/param norm = 3.2673e-01, time/batch = 27.9895s	
8878/11350 (epoch 39.110), train_loss = 0.55992744, grad/param norm = 3.8918e-01, time/batch = 16.3075s	
8879/11350 (epoch 39.115), train_loss = 0.57932407, grad/param norm = 3.3600e-01, time/batch = 16.7174s	
8880/11350 (epoch 39.119), train_loss = 0.68570545, grad/param norm = 4.0347e-01, time/batch = 17.0775s	
8881/11350 (epoch 39.123), train_loss = 0.54589866, grad/param norm = 3.4512e-01, time/batch = 16.6390s	
8882/11350 (epoch 39.128), train_loss = 0.49838918, grad/param norm = 3.0884e-01, time/batch = 16.5349s	
8883/11350 (epoch 39.132), train_loss = 0.53739662, grad/param norm = 2.6761e-01, time/batch = 17.2563s	
8884/11350 (epoch 39.137), train_loss = 0.51471785, grad/param norm = 3.3894e-01, time/batch = 16.7150s	
8885/11350 (epoch 39.141), train_loss = 0.66869255, grad/param norm = 3.7188e-01, time/batch = 16.7061s	
8886/11350 (epoch 39.145), train_loss = 0.55994937, grad/param norm = 2.9169e-01, time/batch = 17.1134s	
8887/11350 (epoch 39.150), train_loss = 0.60781907, grad/param norm = 4.3479e-01, time/batch = 16.9524s	
8888/11350 (epoch 39.154), train_loss = 0.71142273, grad/param norm = 3.5086e-01, time/batch = 16.5478s	
8889/11350 (epoch 39.159), train_loss = 0.49701258, grad/param norm = 2.9165e-01, time/batch = 16.6511s	
8890/11350 (epoch 39.163), train_loss = 0.63543929, grad/param norm = 3.4525e-01, time/batch = 16.9436s	
8891/11350 (epoch 39.167), train_loss = 0.69004707, grad/param norm = 3.3675e-01, time/batch = 16.8682s	
8892/11350 (epoch 39.172), train_loss = 0.77605324, grad/param norm = 3.5635e-01, time/batch = 17.5794s	
8893/11350 (epoch 39.176), train_loss = 0.61462160, grad/param norm = 3.6993e-01, time/batch = 17.0269s	
8894/11350 (epoch 39.181), train_loss = 0.58733399, grad/param norm = 3.0652e-01, time/batch = 17.0282s	
8895/11350 (epoch 39.185), train_loss = 0.53971244, grad/param norm = 2.9796e-01, time/batch = 16.8668s	
8896/11350 (epoch 39.189), train_loss = 0.55622898, grad/param norm = 2.8985e-01, time/batch = 16.3932s	
8897/11350 (epoch 39.194), train_loss = 0.50292646, grad/param norm = 3.2201e-01, time/batch = 17.1024s	
8898/11350 (epoch 39.198), train_loss = 0.46713427, grad/param norm = 3.3090e-01, time/batch = 16.8743s	
8899/11350 (epoch 39.203), train_loss = 0.54427487, grad/param norm = 3.4091e-01, time/batch = 16.8091s	
8900/11350 (epoch 39.207), train_loss = 0.50425444, grad/param norm = 3.5276e-01, time/batch = 16.9657s	
8901/11350 (epoch 39.211), train_loss = 0.67170309, grad/param norm = 4.0033e-01, time/batch = 16.7271s	
8902/11350 (epoch 39.216), train_loss = 0.62439133, grad/param norm = 3.5022e-01, time/batch = 16.8827s	
8903/11350 (epoch 39.220), train_loss = 0.63921521, grad/param norm = 3.4916e-01, time/batch = 16.9377s	
8904/11350 (epoch 39.225), train_loss = 0.57642162, grad/param norm = 2.8926e-01, time/batch = 17.1003s	
8905/11350 (epoch 39.229), train_loss = 0.63549837, grad/param norm = 3.6662e-01, time/batch = 16.7939s	
8906/11350 (epoch 39.233), train_loss = 0.58297450, grad/param norm = 3.6332e-01, time/batch = 16.7231s	
8907/11350 (epoch 39.238), train_loss = 0.68779156, grad/param norm = 4.0534e-01, time/batch = 17.1197s	
8908/11350 (epoch 39.242), train_loss = 0.69128818, grad/param norm = 4.1063e-01, time/batch = 16.9619s	
8909/11350 (epoch 39.247), train_loss = 0.53242746, grad/param norm = 3.0946e-01, time/batch = 16.7991s	
8910/11350 (epoch 39.251), train_loss = 0.59122548, grad/param norm = 4.0388e-01, time/batch = 17.1089s	
8911/11350 (epoch 39.256), train_loss = 0.64149047, grad/param norm = 4.0107e-01, time/batch = 17.1852s	
8912/11350 (epoch 39.260), train_loss = 0.56900369, grad/param norm = 3.4045e-01, time/batch = 17.0417s	
8913/11350 (epoch 39.264), train_loss = 0.54272901, grad/param norm = 3.4888e-01, time/batch = 17.5514s	
8914/11350 (epoch 39.269), train_loss = 0.57767068, grad/param norm = 2.7400e-01, time/batch = 16.7207s	
8915/11350 (epoch 39.273), train_loss = 0.68068897, grad/param norm = 3.2769e-01, time/batch = 16.7919s	
8916/11350 (epoch 39.278), train_loss = 0.56899218, grad/param norm = 3.1836e-01, time/batch = 16.2254s	
8917/11350 (epoch 39.282), train_loss = 0.56453742, grad/param norm = 3.1112e-01, time/batch = 16.3092s	
8918/11350 (epoch 39.286), train_loss = 0.67074268, grad/param norm = 3.7475e-01, time/batch = 16.8558s	
8919/11350 (epoch 39.291), train_loss = 0.54562759, grad/param norm = 3.2185e-01, time/batch = 16.3125s	
8920/11350 (epoch 39.295), train_loss = 0.57732870, grad/param norm = 3.5226e-01, time/batch = 16.3901s	
8921/11350 (epoch 39.300), train_loss = 0.65363194, grad/param norm = 3.3646e-01, time/batch = 16.8768s	
8922/11350 (epoch 39.304), train_loss = 0.55080419, grad/param norm = 3.6614e-01, time/batch = 16.5478s	
8923/11350 (epoch 39.308), train_loss = 0.53362681, grad/param norm = 3.4606e-01, time/batch = 17.4443s	
8924/11350 (epoch 39.313), train_loss = 0.59479729, grad/param norm = 2.9470e-01, time/batch = 16.3107s	
8925/11350 (epoch 39.317), train_loss = 0.59298294, grad/param norm = 2.8440e-01, time/batch = 17.4837s	
8926/11350 (epoch 39.322), train_loss = 0.58276231, grad/param norm = 4.8731e-01, time/batch = 16.4787s	
8927/11350 (epoch 39.326), train_loss = 0.60877656, grad/param norm = 3.6620e-01, time/batch = 17.1148s	
8928/11350 (epoch 39.330), train_loss = 0.49860442, grad/param norm = 2.8263e-01, time/batch = 16.6232s	
8929/11350 (epoch 39.335), train_loss = 0.39791056, grad/param norm = 2.6242e-01, time/batch = 17.3501s	
8930/11350 (epoch 39.339), train_loss = 0.43698964, grad/param norm = 3.0747e-01, time/batch = 16.3925s	
8931/11350 (epoch 39.344), train_loss = 0.52763135, grad/param norm = 2.5747e-01, time/batch = 16.7152s	
8932/11350 (epoch 39.348), train_loss = 0.54200683, grad/param norm = 2.8990e-01, time/batch = 17.1046s	
8933/11350 (epoch 39.352), train_loss = 0.45446636, grad/param norm = 3.4738e-01, time/batch = 16.5419s	
8934/11350 (epoch 39.357), train_loss = 0.55553183, grad/param norm = 2.8015e-01, time/batch = 16.6461s	
8935/11350 (epoch 39.361), train_loss = 0.45652821, grad/param norm = 2.2823e-01, time/batch = 16.5556s	
8936/11350 (epoch 39.366), train_loss = 0.55187211, grad/param norm = 3.7296e-01, time/batch = 17.1720s	
8937/11350 (epoch 39.370), train_loss = 0.47580644, grad/param norm = 3.5377e-01, time/batch = 16.9403s	
8938/11350 (epoch 39.374), train_loss = 0.53870426, grad/param norm = 3.0148e-01, time/batch = 17.1836s	
8939/11350 (epoch 39.379), train_loss = 0.54254447, grad/param norm = 4.0556e-01, time/batch = 16.9428s	
8940/11350 (epoch 39.383), train_loss = 0.47972725, grad/param norm = 3.1552e-01, time/batch = 16.4698s	
8941/11350 (epoch 39.388), train_loss = 0.53824921, grad/param norm = 3.5906e-01, time/batch = 16.7188s	
8942/11350 (epoch 39.392), train_loss = 0.60320834, grad/param norm = 3.1210e-01, time/batch = 16.6267s	
8943/11350 (epoch 39.396), train_loss = 0.53308413, grad/param norm = 3.2715e-01, time/batch = 16.7105s	
8944/11350 (epoch 39.401), train_loss = 0.54460131, grad/param norm = 3.6006e-01, time/batch = 16.4658s	
8945/11350 (epoch 39.405), train_loss = 0.70682917, grad/param norm = 3.6401e-01, time/batch = 16.4520s	
8946/11350 (epoch 39.410), train_loss = 0.74863709, grad/param norm = 4.3115e-01, time/batch = 16.7797s	
8947/11350 (epoch 39.414), train_loss = 0.52951222, grad/param norm = 4.4016e-01, time/batch = 16.5456s	
8948/11350 (epoch 39.419), train_loss = 0.50054745, grad/param norm = 3.5369e-01, time/batch = 16.6305s	
8949/11350 (epoch 39.423), train_loss = 0.53529902, grad/param norm = 3.4961e-01, time/batch = 16.7946s	
8950/11350 (epoch 39.427), train_loss = 0.61707787, grad/param norm = 3.9206e-01, time/batch = 16.8632s	
8951/11350 (epoch 39.432), train_loss = 0.58152647, grad/param norm = 3.6372e-01, time/batch = 17.0315s	
8952/11350 (epoch 39.436), train_loss = 0.49931001, grad/param norm = 3.3886e-01, time/batch = 17.0307s	
8953/11350 (epoch 39.441), train_loss = 0.65989507, grad/param norm = 3.7461e-01, time/batch = 16.3748s	
8954/11350 (epoch 39.445), train_loss = 0.51169144, grad/param norm = 2.9530e-01, time/batch = 16.8798s	
8955/11350 (epoch 39.449), train_loss = 0.59359812, grad/param norm = 3.0843e-01, time/batch = 16.5525s	
8956/11350 (epoch 39.454), train_loss = 0.69949992, grad/param norm = 4.8165e-01, time/batch = 16.3112s	
8957/11350 (epoch 39.458), train_loss = 0.48857694, grad/param norm = 3.0656e-01, time/batch = 16.8680s	
8958/11350 (epoch 39.463), train_loss = 0.52454300, grad/param norm = 3.7660e-01, time/batch = 16.5532s	
8959/11350 (epoch 39.467), train_loss = 0.77158727, grad/param norm = 4.2068e-01, time/batch = 16.9994s	
8960/11350 (epoch 39.471), train_loss = 0.72801619, grad/param norm = 4.9118e-01, time/batch = 16.6212s	
8961/11350 (epoch 39.476), train_loss = 0.63430333, grad/param norm = 3.5537e-01, time/batch = 17.0027s	
8962/11350 (epoch 39.480), train_loss = 0.68205417, grad/param norm = 3.6549e-01, time/batch = 16.5421s	
8963/11350 (epoch 39.485), train_loss = 0.61561192, grad/param norm = 3.3189e-01, time/batch = 17.0357s	
8964/11350 (epoch 39.489), train_loss = 0.66474072, grad/param norm = 3.8072e-01, time/batch = 16.8675s	
8965/11350 (epoch 39.493), train_loss = 0.69100152, grad/param norm = 3.1139e-01, time/batch = 16.8783s	
8966/11350 (epoch 39.498), train_loss = 0.45732018, grad/param norm = 3.1312e-01, time/batch = 16.8687s	
8967/11350 (epoch 39.502), train_loss = 0.72648554, grad/param norm = 3.4665e-01, time/batch = 16.7223s	
8968/11350 (epoch 39.507), train_loss = 0.51337451, grad/param norm = 2.6611e-01, time/batch = 17.1043s	
8969/11350 (epoch 39.511), train_loss = 0.63423781, grad/param norm = 3.2258e-01, time/batch = 16.3951s	
8970/11350 (epoch 39.515), train_loss = 0.60449885, grad/param norm = 3.8198e-01, time/batch = 16.7968s	
8971/11350 (epoch 39.520), train_loss = 0.73843204, grad/param norm = 4.1735e-01, time/batch = 16.6305s	
8972/11350 (epoch 39.524), train_loss = 0.64759851, grad/param norm = 3.7567e-01, time/batch = 16.6148s	
8973/11350 (epoch 39.529), train_loss = 0.56924298, grad/param norm = 3.5245e-01, time/batch = 16.3935s	
8974/11350 (epoch 39.533), train_loss = 0.76329970, grad/param norm = 3.7642e-01, time/batch = 16.7773s	
8975/11350 (epoch 39.537), train_loss = 0.70263363, grad/param norm = 3.3387e-01, time/batch = 17.3576s	
8976/11350 (epoch 39.542), train_loss = 0.58920988, grad/param norm = 2.6815e-01, time/batch = 16.7191s	
8977/11350 (epoch 39.546), train_loss = 0.76114636, grad/param norm = 4.6912e-01, time/batch = 16.5609s	
8978/11350 (epoch 39.551), train_loss = 0.65017424, grad/param norm = 3.8206e-01, time/batch = 16.6142s	
8979/11350 (epoch 39.555), train_loss = 0.55016247, grad/param norm = 2.7575e-01, time/batch = 16.7104s	
8980/11350 (epoch 39.559), train_loss = 0.60801361, grad/param norm = 3.2490e-01, time/batch = 16.5614s	
8981/11350 (epoch 39.564), train_loss = 0.65459224, grad/param norm = 3.8833e-01, time/batch = 16.9514s	
8982/11350 (epoch 39.568), train_loss = 0.67075436, grad/param norm = 3.1462e-01, time/batch = 14.9927s	
8983/11350 (epoch 39.573), train_loss = 0.74120658, grad/param norm = 4.0598e-01, time/batch = 0.7359s	
8984/11350 (epoch 39.577), train_loss = 0.68251701, grad/param norm = 4.0856e-01, time/batch = 0.7399s	
8985/11350 (epoch 39.581), train_loss = 0.76533288, grad/param norm = 3.5613e-01, time/batch = 0.7385s	
8986/11350 (epoch 39.586), train_loss = 0.70519407, grad/param norm = 3.7683e-01, time/batch = 0.7405s	
8987/11350 (epoch 39.590), train_loss = 0.76061115, grad/param norm = 4.5461e-01, time/batch = 0.7413s	
8988/11350 (epoch 39.595), train_loss = 0.82333708, grad/param norm = 3.8608e-01, time/batch = 0.7375s	
8989/11350 (epoch 39.599), train_loss = 0.66239444, grad/param norm = 3.5545e-01, time/batch = 0.8650s	
8990/11350 (epoch 39.604), train_loss = 0.66474700, grad/param norm = 3.7806e-01, time/batch = 1.0809s	
8991/11350 (epoch 39.608), train_loss = 0.63575135, grad/param norm = 4.3146e-01, time/batch = 1.0811s	
8992/11350 (epoch 39.612), train_loss = 0.65317452, grad/param norm = 3.2626e-01, time/batch = 1.0881s	
8993/11350 (epoch 39.617), train_loss = 0.73174289, grad/param norm = 3.7708e-01, time/batch = 1.0783s	
8994/11350 (epoch 39.621), train_loss = 0.74704822, grad/param norm = 3.3927e-01, time/batch = 1.8148s	
8995/11350 (epoch 39.626), train_loss = 0.68322215, grad/param norm = 3.8322e-01, time/batch = 2.0021s	
8996/11350 (epoch 39.630), train_loss = 0.68033072, grad/param norm = 3.9235e-01, time/batch = 6.0915s	
8997/11350 (epoch 39.634), train_loss = 0.64158435, grad/param norm = 3.4497e-01, time/batch = 16.7147s	
8998/11350 (epoch 39.639), train_loss = 0.62116994, grad/param norm = 3.3041e-01, time/batch = 16.8407s	
8999/11350 (epoch 39.643), train_loss = 0.54371443, grad/param norm = 3.2689e-01, time/batch = 17.1018s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch39.65_2.1473.t7	
9000/11350 (epoch 39.648), train_loss = 0.61949451, grad/param norm = 3.2301e-01, time/batch = 16.4567s	
9001/11350 (epoch 39.652), train_loss = 1.59925790, grad/param norm = 7.0003e-01, time/batch = 16.8838s	
9002/11350 (epoch 39.656), train_loss = 0.80013067, grad/param norm = 4.1946e-01, time/batch = 16.8660s	
9003/11350 (epoch 39.661), train_loss = 0.67600766, grad/param norm = 3.7293e-01, time/batch = 16.6427s	
9004/11350 (epoch 39.665), train_loss = 0.69637842, grad/param norm = 3.5156e-01, time/batch = 16.9372s	
9005/11350 (epoch 39.670), train_loss = 0.68125383, grad/param norm = 3.2369e-01, time/batch = 16.5676s	
9006/11350 (epoch 39.674), train_loss = 0.64196905, grad/param norm = 3.2511e-01, time/batch = 17.1095s	
9007/11350 (epoch 39.678), train_loss = 0.68175150, grad/param norm = 3.0212e-01, time/batch = 16.2306s	
9008/11350 (epoch 39.683), train_loss = 0.63260507, grad/param norm = 4.2115e-01, time/batch = 17.1075s	
9009/11350 (epoch 39.687), train_loss = 0.56169887, grad/param norm = 3.6079e-01, time/batch = 17.0185s	
9010/11350 (epoch 39.692), train_loss = 0.86121588, grad/param norm = 5.8425e-01, time/batch = 17.0133s	
9011/11350 (epoch 39.696), train_loss = 0.83437123, grad/param norm = 3.7262e-01, time/batch = 16.5490s	
9012/11350 (epoch 39.700), train_loss = 0.73919331, grad/param norm = 4.0517e-01, time/batch = 16.3882s	
9013/11350 (epoch 39.705), train_loss = 0.77159011, grad/param norm = 3.6917e-01, time/batch = 16.7082s	
9014/11350 (epoch 39.709), train_loss = 0.76456043, grad/param norm = 3.6513e-01, time/batch = 16.5473s	
9015/11350 (epoch 39.714), train_loss = 0.67891292, grad/param norm = 3.6791e-01, time/batch = 16.5324s	
9016/11350 (epoch 39.718), train_loss = 0.59742075, grad/param norm = 3.8423e-01, time/batch = 16.1541s	
9017/11350 (epoch 39.722), train_loss = 0.66042495, grad/param norm = 3.8681e-01, time/batch = 16.8666s	
9018/11350 (epoch 39.727), train_loss = 0.68748313, grad/param norm = 3.5838e-01, time/batch = 16.7792s	
9019/11350 (epoch 39.731), train_loss = 0.64602408, grad/param norm = 3.7952e-01, time/batch = 17.0079s	
9020/11350 (epoch 39.736), train_loss = 0.61497058, grad/param norm = 4.4536e-01, time/batch = 16.7867s	
9021/11350 (epoch 39.740), train_loss = 0.64901817, grad/param norm = 3.3504e-01, time/batch = 16.9458s	
9022/11350 (epoch 39.744), train_loss = 0.64060069, grad/param norm = 4.0976e-01, time/batch = 16.3782s	
9023/11350 (epoch 39.749), train_loss = 0.63866652, grad/param norm = 3.3604e-01, time/batch = 16.3014s	
9024/11350 (epoch 39.753), train_loss = 0.72031539, grad/param norm = 4.6781e-01, time/batch = 17.1873s	
9025/11350 (epoch 39.758), train_loss = 0.64373715, grad/param norm = 3.7176e-01, time/batch = 16.2317s	
9026/11350 (epoch 39.762), train_loss = 0.77473946, grad/param norm = 3.6381e-01, time/batch = 16.4011s	
9027/11350 (epoch 39.767), train_loss = 0.75942074, grad/param norm = 3.0299e-01, time/batch = 16.7724s	
9028/11350 (epoch 39.771), train_loss = 0.86409316, grad/param norm = 4.1391e-01, time/batch = 17.0318s	
9029/11350 (epoch 39.775), train_loss = 0.69818323, grad/param norm = 3.5631e-01, time/batch = 16.3071s	
9030/11350 (epoch 39.780), train_loss = 0.73264141, grad/param norm = 3.8451e-01, time/batch = 16.3887s	
9031/11350 (epoch 39.784), train_loss = 0.67167007, grad/param norm = 3.3163e-01, time/batch = 17.1873s	
9032/11350 (epoch 39.789), train_loss = 0.69629278, grad/param norm = 3.8074e-01, time/batch = 16.4813s	
9033/11350 (epoch 39.793), train_loss = 0.73458274, grad/param norm = 3.2337e-01, time/batch = 16.7994s	
9034/11350 (epoch 39.797), train_loss = 0.67052526, grad/param norm = 2.8794e-01, time/batch = 16.4646s	
9035/11350 (epoch 39.802), train_loss = 0.68651784, grad/param norm = 3.1219e-01, time/batch = 16.9290s	
9036/11350 (epoch 39.806), train_loss = 0.71365552, grad/param norm = 3.2335e-01, time/batch = 16.7135s	
9037/11350 (epoch 39.811), train_loss = 0.67550262, grad/param norm = 3.3362e-01, time/batch = 16.7237s	
9038/11350 (epoch 39.815), train_loss = 0.67354755, grad/param norm = 3.4268e-01, time/batch = 16.9421s	
9039/11350 (epoch 39.819), train_loss = 0.57277848, grad/param norm = 2.9913e-01, time/batch = 16.3135s	
9040/11350 (epoch 39.824), train_loss = 0.61586298, grad/param norm = 4.0861e-01, time/batch = 16.6131s	
9041/11350 (epoch 39.828), train_loss = 0.61092400, grad/param norm = 3.5336e-01, time/batch = 16.7691s	
9042/11350 (epoch 39.833), train_loss = 0.63324132, grad/param norm = 2.9459e-01, time/batch = 16.6232s	
9043/11350 (epoch 39.837), train_loss = 0.67045186, grad/param norm = 3.4968e-01, time/batch = 16.3091s	
9044/11350 (epoch 39.841), train_loss = 0.90514534, grad/param norm = 4.2890e-01, time/batch = 16.4588s	
9045/11350 (epoch 39.846), train_loss = 0.73545992, grad/param norm = 3.2095e-01, time/batch = 17.1095s	
9046/11350 (epoch 39.850), train_loss = 0.73944151, grad/param norm = 3.3404e-01, time/batch = 16.6298s	
9047/11350 (epoch 39.855), train_loss = 0.56798338, grad/param norm = 3.0401e-01, time/batch = 16.6214s	
9048/11350 (epoch 39.859), train_loss = 0.61928291, grad/param norm = 3.8361e-01, time/batch = 16.4720s	
9049/11350 (epoch 39.863), train_loss = 0.59648741, grad/param norm = 3.2169e-01, time/batch = 16.6270s	
9050/11350 (epoch 39.868), train_loss = 0.59282359, grad/param norm = 2.9014e-01, time/batch = 16.3040s	
9051/11350 (epoch 39.872), train_loss = 0.61621376, grad/param norm = 3.1207e-01, time/batch = 16.8670s	
9052/11350 (epoch 39.877), train_loss = 0.61257719, grad/param norm = 3.3663e-01, time/batch = 16.1417s	
9053/11350 (epoch 39.881), train_loss = 0.80998756, grad/param norm = 4.1070e-01, time/batch = 16.7114s	
9054/11350 (epoch 39.885), train_loss = 0.74670878, grad/param norm = 3.1878e-01, time/batch = 16.8391s	
9055/11350 (epoch 39.890), train_loss = 0.71097971, grad/param norm = 3.9695e-01, time/batch = 16.3919s	
9056/11350 (epoch 39.894), train_loss = 0.58412715, grad/param norm = 2.7822e-01, time/batch = 16.9482s	
9057/11350 (epoch 39.899), train_loss = 0.71808620, grad/param norm = 3.0550e-01, time/batch = 16.2357s	
9058/11350 (epoch 39.903), train_loss = 0.69833212, grad/param norm = 3.7905e-01, time/batch = 16.2259s	
9059/11350 (epoch 39.907), train_loss = 0.63138301, grad/param norm = 3.8310e-01, time/batch = 16.0648s	
9060/11350 (epoch 39.912), train_loss = 0.61349843, grad/param norm = 3.4713e-01, time/batch = 17.0257s	
9061/11350 (epoch 39.916), train_loss = 0.66820857, grad/param norm = 3.5277e-01, time/batch = 16.4593s	
9062/11350 (epoch 39.921), train_loss = 0.66969819, grad/param norm = 3.0323e-01, time/batch = 16.7624s	
9063/11350 (epoch 39.925), train_loss = 0.57879994, grad/param norm = 2.8567e-01, time/batch = 16.9421s	
9064/11350 (epoch 39.930), train_loss = 0.67941412, grad/param norm = 4.9333e-01, time/batch = 17.0348s	
9065/11350 (epoch 39.934), train_loss = 0.77352956, grad/param norm = 3.9350e-01, time/batch = 16.7894s	
9066/11350 (epoch 39.938), train_loss = 0.69433884, grad/param norm = 4.2197e-01, time/batch = 17.1745s	
9067/11350 (epoch 39.943), train_loss = 0.72765195, grad/param norm = 3.8953e-01, time/batch = 16.6243s	
9068/11350 (epoch 39.947), train_loss = 0.69726783, grad/param norm = 3.8926e-01, time/batch = 16.3038s	
9069/11350 (epoch 39.952), train_loss = 0.69913774, grad/param norm = 3.6531e-01, time/batch = 16.3802s	
9070/11350 (epoch 39.956), train_loss = 0.58034897, grad/param norm = 3.0138e-01, time/batch = 16.3086s	
9071/11350 (epoch 39.960), train_loss = 0.64800071, grad/param norm = 3.7933e-01, time/batch = 16.5488s	
9072/11350 (epoch 39.965), train_loss = 0.55624990, grad/param norm = 3.3663e-01, time/batch = 16.3082s	
9073/11350 (epoch 39.969), train_loss = 0.55920844, grad/param norm = 3.5796e-01, time/batch = 16.6334s	
9074/11350 (epoch 39.974), train_loss = 0.55678757, grad/param norm = 3.5141e-01, time/batch = 16.8697s	
9075/11350 (epoch 39.978), train_loss = 0.62616273, grad/param norm = 2.7343e-01, time/batch = 16.4643s	
9076/11350 (epoch 39.982), train_loss = 0.44089923, grad/param norm = 2.8084e-01, time/batch = 16.6815s	
9077/11350 (epoch 39.987), train_loss = 0.65320830, grad/param norm = 3.5900e-01, time/batch = 16.4694s	
9078/11350 (epoch 39.991), train_loss = 0.56479645, grad/param norm = 3.4466e-01, time/batch = 16.7890s	
9079/11350 (epoch 39.996), train_loss = 0.62144678, grad/param norm = 4.3985e-01, time/batch = 16.3978s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
9080/11350 (epoch 40.000), train_loss = 0.51857917, grad/param norm = 3.3893e-01, time/batch = 16.6311s	
9081/11350 (epoch 40.004), train_loss = 0.70086058, grad/param norm = 3.6128e-01, time/batch = 17.1928s	
9082/11350 (epoch 40.009), train_loss = 0.66678677, grad/param norm = 3.9554e-01, time/batch = 16.3940s	
9083/11350 (epoch 40.013), train_loss = 0.47732057, grad/param norm = 3.0420e-01, time/batch = 16.5530s	
9084/11350 (epoch 40.018), train_loss = 0.51317807, grad/param norm = 3.2953e-01, time/batch = 16.8082s	
9085/11350 (epoch 40.022), train_loss = 0.55684480, grad/param norm = 6.5728e-01, time/batch = 16.8713s	
9086/11350 (epoch 40.026), train_loss = 0.52807377, grad/param norm = 3.2050e-01, time/batch = 16.8425s	
9087/11350 (epoch 40.031), train_loss = 0.53685200, grad/param norm = 3.0502e-01, time/batch = 16.6916s	
9088/11350 (epoch 40.035), train_loss = 0.57855447, grad/param norm = 3.6957e-01, time/batch = 16.3833s	
9089/11350 (epoch 40.040), train_loss = 0.57393607, grad/param norm = 3.1108e-01, time/batch = 16.4807s	
9090/11350 (epoch 40.044), train_loss = 0.53966452, grad/param norm = 3.2593e-01, time/batch = 16.5407s	
9091/11350 (epoch 40.048), train_loss = 0.51736021, grad/param norm = 3.2705e-01, time/batch = 16.7849s	
9092/11350 (epoch 40.053), train_loss = 0.56640301, grad/param norm = 3.3740e-01, time/batch = 16.8046s	
9093/11350 (epoch 40.057), train_loss = 0.56508208, grad/param norm = 3.4745e-01, time/batch = 16.6406s	
9094/11350 (epoch 40.062), train_loss = 0.48543283, grad/param norm = 2.7847e-01, time/batch = 16.7192s	
9095/11350 (epoch 40.066), train_loss = 0.48360570, grad/param norm = 3.2213e-01, time/batch = 16.7228s	
9096/11350 (epoch 40.070), train_loss = 0.55420354, grad/param norm = 3.2679e-01, time/batch = 16.8628s	
9097/11350 (epoch 40.075), train_loss = 0.49395699, grad/param norm = 2.8864e-01, time/batch = 16.4745s	
9098/11350 (epoch 40.079), train_loss = 0.62124310, grad/param norm = 3.4646e-01, time/batch = 16.6276s	
9099/11350 (epoch 40.084), train_loss = 0.69732172, grad/param norm = 3.6940e-01, time/batch = 23.3467s	
9100/11350 (epoch 40.088), train_loss = 0.65305854, grad/param norm = 3.3694e-01, time/batch = 24.2274s	
9101/11350 (epoch 40.093), train_loss = 0.62442904, grad/param norm = 2.9343e-01, time/batch = 16.7035s	
9102/11350 (epoch 40.097), train_loss = 0.56964429, grad/param norm = 3.1737e-01, time/batch = 17.0836s	
9103/11350 (epoch 40.101), train_loss = 0.53488478, grad/param norm = 3.3790e-01, time/batch = 16.7238s	
9104/11350 (epoch 40.106), train_loss = 0.61266493, grad/param norm = 3.5829e-01, time/batch = 17.0322s	
9105/11350 (epoch 40.110), train_loss = 0.54796297, grad/param norm = 3.5057e-01, time/batch = 16.6310s	
9106/11350 (epoch 40.115), train_loss = 0.57915494, grad/param norm = 3.8814e-01, time/batch = 16.7255s	
9107/11350 (epoch 40.119), train_loss = 0.67235067, grad/param norm = 4.2738e-01, time/batch = 16.3828s	
9108/11350 (epoch 40.123), train_loss = 0.53188099, grad/param norm = 3.5222e-01, time/batch = 16.7856s	
9109/11350 (epoch 40.128), train_loss = 0.48355329, grad/param norm = 3.5044e-01, time/batch = 16.9597s	
9110/11350 (epoch 40.132), train_loss = 0.52797582, grad/param norm = 2.9004e-01, time/batch = 16.9660s	
9111/11350 (epoch 40.137), train_loss = 0.51387930, grad/param norm = 3.9011e-01, time/batch = 16.6351s	
9112/11350 (epoch 40.141), train_loss = 0.65682570, grad/param norm = 3.8428e-01, time/batch = 16.6373s	
9113/11350 (epoch 40.145), train_loss = 0.55117696, grad/param norm = 3.2886e-01, time/batch = 16.7846s	
9114/11350 (epoch 40.150), train_loss = 0.60841907, grad/param norm = 4.6875e-01, time/batch = 16.7890s	
9115/11350 (epoch 40.154), train_loss = 0.69300079, grad/param norm = 3.6143e-01, time/batch = 17.0307s	
9116/11350 (epoch 40.159), train_loss = 0.51353754, grad/param norm = 3.3207e-01, time/batch = 17.0132s	
9117/11350 (epoch 40.163), train_loss = 0.62738708, grad/param norm = 3.5613e-01, time/batch = 17.1043s	
9118/11350 (epoch 40.167), train_loss = 0.69415796, grad/param norm = 4.2181e-01, time/batch = 17.0298s	
9119/11350 (epoch 40.172), train_loss = 0.73877861, grad/param norm = 3.4490e-01, time/batch = 16.2911s	
9120/11350 (epoch 40.176), train_loss = 0.58520787, grad/param norm = 2.9377e-01, time/batch = 17.1035s	
9121/11350 (epoch 40.181), train_loss = 0.57870878, grad/param norm = 3.2752e-01, time/batch = 16.4685s	
9122/11350 (epoch 40.185), train_loss = 0.53777664, grad/param norm = 3.3083e-01, time/batch = 17.0258s	
9123/11350 (epoch 40.189), train_loss = 0.54315045, grad/param norm = 3.0163e-01, time/batch = 16.7851s	
9124/11350 (epoch 40.194), train_loss = 0.49520471, grad/param norm = 3.3095e-01, time/batch = 16.2293s	
9125/11350 (epoch 40.198), train_loss = 0.45434679, grad/param norm = 3.3428e-01, time/batch = 17.4235s	
9126/11350 (epoch 40.203), train_loss = 0.52886319, grad/param norm = 3.0343e-01, time/batch = 16.5557s	
9127/11350 (epoch 40.207), train_loss = 0.48979750, grad/param norm = 3.8027e-01, time/batch = 16.7868s	
9128/11350 (epoch 40.211), train_loss = 0.65355221, grad/param norm = 4.0625e-01, time/batch = 16.4016s	
9129/11350 (epoch 40.216), train_loss = 0.62906271, grad/param norm = 3.8802e-01, time/batch = 17.0454s	
9130/11350 (epoch 40.220), train_loss = 0.62396161, grad/param norm = 3.5271e-01, time/batch = 17.1771s	
9131/11350 (epoch 40.225), train_loss = 0.55750616, grad/param norm = 2.8167e-01, time/batch = 17.1159s	
9132/11350 (epoch 40.229), train_loss = 0.60731163, grad/param norm = 3.1033e-01, time/batch = 16.5515s	
9133/11350 (epoch 40.233), train_loss = 0.57206851, grad/param norm = 3.4983e-01, time/batch = 16.7854s	
9134/11350 (epoch 40.238), train_loss = 0.66512433, grad/param norm = 4.0492e-01, time/batch = 16.8581s	
9135/11350 (epoch 40.242), train_loss = 0.67384934, grad/param norm = 3.5876e-01, time/batch = 17.0158s	
9136/11350 (epoch 40.247), train_loss = 0.51573944, grad/param norm = 2.8501e-01, time/batch = 16.7123s	
9137/11350 (epoch 40.251), train_loss = 0.57274787, grad/param norm = 3.3598e-01, time/batch = 16.8668s	
9138/11350 (epoch 40.256), train_loss = 0.61752824, grad/param norm = 3.1867e-01, time/batch = 16.6390s	
9139/11350 (epoch 40.260), train_loss = 0.54331033, grad/param norm = 2.9206e-01, time/batch = 16.9444s	
9140/11350 (epoch 40.264), train_loss = 0.53503924, grad/param norm = 3.4510e-01, time/batch = 16.6121s	
9141/11350 (epoch 40.269), train_loss = 0.57466169, grad/param norm = 2.7011e-01, time/batch = 16.8730s	
9142/11350 (epoch 40.273), train_loss = 0.65692331, grad/param norm = 3.2042e-01, time/batch = 16.9209s	
9143/11350 (epoch 40.278), train_loss = 0.54433459, grad/param norm = 2.4497e-01, time/batch = 16.3834s	
9144/11350 (epoch 40.282), train_loss = 0.56318735, grad/param norm = 3.5540e-01, time/batch = 16.7138s	
9145/11350 (epoch 40.286), train_loss = 0.66138442, grad/param norm = 4.0207e-01, time/batch = 16.6376s	
9146/11350 (epoch 40.291), train_loss = 0.54844064, grad/param norm = 3.3758e-01, time/batch = 17.3640s	
9147/11350 (epoch 40.295), train_loss = 0.56213513, grad/param norm = 3.2892e-01, time/batch = 16.6174s	
9148/11350 (epoch 40.300), train_loss = 0.63380095, grad/param norm = 3.4610e-01, time/batch = 16.8494s	
9149/11350 (epoch 40.304), train_loss = 0.51963237, grad/param norm = 3.7687e-01, time/batch = 16.7685s	
9150/11350 (epoch 40.308), train_loss = 0.52869903, grad/param norm = 3.6861e-01, time/batch = 16.2213s	
9151/11350 (epoch 40.313), train_loss = 0.58083683, grad/param norm = 3.1178e-01, time/batch = 16.7817s	
9152/11350 (epoch 40.317), train_loss = 0.56316935, grad/param norm = 2.7219e-01, time/batch = 17.0181s	
9153/11350 (epoch 40.322), train_loss = 0.55886449, grad/param norm = 3.3944e-01, time/batch = 16.4803s	
9154/11350 (epoch 40.326), train_loss = 0.56760019, grad/param norm = 2.7748e-01, time/batch = 16.7734s	
9155/11350 (epoch 40.330), train_loss = 0.47899832, grad/param norm = 2.6874e-01, time/batch = 16.7998s	
9156/11350 (epoch 40.335), train_loss = 0.39219834, grad/param norm = 2.5955e-01, time/batch = 16.3809s	
9157/11350 (epoch 40.339), train_loss = 0.43743545, grad/param norm = 3.4238e-01, time/batch = 16.6420s	
9158/11350 (epoch 40.344), train_loss = 0.51182404, grad/param norm = 2.7796e-01, time/batch = 16.7869s	
9159/11350 (epoch 40.348), train_loss = 0.53133703, grad/param norm = 2.6810e-01, time/batch = 16.7727s	
9160/11350 (epoch 40.352), train_loss = 0.43801222, grad/param norm = 2.6120e-01, time/batch = 16.3847s	
9161/11350 (epoch 40.357), train_loss = 0.54231251, grad/param norm = 3.2030e-01, time/batch = 16.3015s	
9162/11350 (epoch 40.361), train_loss = 0.44080420, grad/param norm = 2.5068e-01, time/batch = 16.6286s	
9163/11350 (epoch 40.366), train_loss = 0.52910200, grad/param norm = 2.8923e-01, time/batch = 16.6138s	
9164/11350 (epoch 40.370), train_loss = 0.45722885, grad/param norm = 3.4044e-01, time/batch = 16.9473s	
9165/11350 (epoch 40.374), train_loss = 0.50986878, grad/param norm = 2.8462e-01, time/batch = 16.9999s	
9166/11350 (epoch 40.379), train_loss = 0.51468015, grad/param norm = 3.5026e-01, time/batch = 16.9379s	
9167/11350 (epoch 40.383), train_loss = 0.47159218, grad/param norm = 2.9842e-01, time/batch = 16.1397s	
9168/11350 (epoch 40.388), train_loss = 0.52851317, grad/param norm = 3.2714e-01, time/batch = 16.3758s	
9169/11350 (epoch 40.392), train_loss = 0.60957069, grad/param norm = 3.7848e-01, time/batch = 16.8373s	
9170/11350 (epoch 40.396), train_loss = 0.53912655, grad/param norm = 4.0095e-01, time/batch = 17.1672s	
9171/11350 (epoch 40.401), train_loss = 0.50385912, grad/param norm = 3.3078e-01, time/batch = 16.6304s	
9172/11350 (epoch 40.405), train_loss = 0.68539065, grad/param norm = 3.6979e-01, time/batch = 16.7066s	
9173/11350 (epoch 40.410), train_loss = 0.71821891, grad/param norm = 4.1889e-01, time/batch = 17.0314s	
9174/11350 (epoch 40.414), train_loss = 0.50658600, grad/param norm = 3.3332e-01, time/batch = 16.7107s	
9175/11350 (epoch 40.419), train_loss = 0.49927216, grad/param norm = 3.6154e-01, time/batch = 16.5592s	
9176/11350 (epoch 40.423), train_loss = 0.51726627, grad/param norm = 3.3547e-01, time/batch = 16.7094s	
9177/11350 (epoch 40.427), train_loss = 0.58192830, grad/param norm = 3.1876e-01, time/batch = 17.3387s	
9178/11350 (epoch 40.432), train_loss = 0.56344507, grad/param norm = 3.3015e-01, time/batch = 16.6202s	
9179/11350 (epoch 40.436), train_loss = 0.48115243, grad/param norm = 3.2224e-01, time/batch = 16.1468s	
9180/11350 (epoch 40.441), train_loss = 0.64800719, grad/param norm = 3.8853e-01, time/batch = 16.5529s	
9181/11350 (epoch 40.445), train_loss = 0.52230487, grad/param norm = 2.8548e-01, time/batch = 16.9289s	
9182/11350 (epoch 40.449), train_loss = 0.59625880, grad/param norm = 3.2864e-01, time/batch = 16.4648s	
9183/11350 (epoch 40.454), train_loss = 0.68803383, grad/param norm = 3.7245e-01, time/batch = 16.7214s	
9184/11350 (epoch 40.458), train_loss = 0.49679495, grad/param norm = 3.2476e-01, time/batch = 16.3833s	
9185/11350 (epoch 40.463), train_loss = 0.49021792, grad/param norm = 3.1673e-01, time/batch = 16.3912s	
9186/11350 (epoch 40.467), train_loss = 0.75021839, grad/param norm = 3.8067e-01, time/batch = 17.1083s	
9187/11350 (epoch 40.471), train_loss = 0.69986596, grad/param norm = 3.9607e-01, time/batch = 16.6923s	
9188/11350 (epoch 40.476), train_loss = 0.58408978, grad/param norm = 3.0498e-01, time/batch = 17.1151s	
9189/11350 (epoch 40.480), train_loss = 0.65558530, grad/param norm = 3.9829e-01, time/batch = 16.4770s	
9190/11350 (epoch 40.485), train_loss = 0.62301450, grad/param norm = 4.1256e-01, time/batch = 16.5334s	
9191/11350 (epoch 40.489), train_loss = 0.65192448, grad/param norm = 3.8221e-01, time/batch = 16.7914s	
9192/11350 (epoch 40.493), train_loss = 0.68308325, grad/param norm = 3.2857e-01, time/batch = 16.6327s	
9193/11350 (epoch 40.498), train_loss = 0.44468358, grad/param norm = 3.0436e-01, time/batch = 16.2248s	
9194/11350 (epoch 40.502), train_loss = 0.70102578, grad/param norm = 3.5787e-01, time/batch = 16.3128s	
9195/11350 (epoch 40.507), train_loss = 0.50966323, grad/param norm = 3.0244e-01, time/batch = 16.8596s	
9196/11350 (epoch 40.511), train_loss = 0.62773895, grad/param norm = 3.2338e-01, time/batch = 16.4704s	
9197/11350 (epoch 40.515), train_loss = 0.60305805, grad/param norm = 4.0303e-01, time/batch = 16.2212s	
9198/11350 (epoch 40.520), train_loss = 0.74920332, grad/param norm = 4.5370e-01, time/batch = 16.8691s	
9199/11350 (epoch 40.524), train_loss = 0.62804781, grad/param norm = 3.6667e-01, time/batch = 16.3811s	
9200/11350 (epoch 40.529), train_loss = 0.55622362, grad/param norm = 3.1894e-01, time/batch = 16.2193s	
9201/11350 (epoch 40.533), train_loss = 0.73287026, grad/param norm = 3.5183e-01, time/batch = 16.6351s	
9202/11350 (epoch 40.537), train_loss = 0.69436079, grad/param norm = 3.3880e-01, time/batch = 16.8729s	
9203/11350 (epoch 40.542), train_loss = 0.57997856, grad/param norm = 2.7029e-01, time/batch = 17.0993s	
9204/11350 (epoch 40.546), train_loss = 0.74986965, grad/param norm = 4.1221e-01, time/batch = 16.8516s	
9205/11350 (epoch 40.551), train_loss = 0.65917156, grad/param norm = 4.1174e-01, time/batch = 16.7735s	
9206/11350 (epoch 40.555), train_loss = 0.55833624, grad/param norm = 3.1543e-01, time/batch = 16.4586s	
9207/11350 (epoch 40.559), train_loss = 0.61186563, grad/param norm = 3.0446e-01, time/batch = 16.2169s	
9208/11350 (epoch 40.564), train_loss = 0.63440823, grad/param norm = 3.4761e-01, time/batch = 16.5499s	
9209/11350 (epoch 40.568), train_loss = 0.63602583, grad/param norm = 3.2858e-01, time/batch = 16.7863s	
9210/11350 (epoch 40.573), train_loss = 0.76259725, grad/param norm = 4.7503e-01, time/batch = 16.9613s	
9211/11350 (epoch 40.577), train_loss = 0.68535861, grad/param norm = 4.2633e-01, time/batch = 16.3958s	
9212/11350 (epoch 40.581), train_loss = 0.74889598, grad/param norm = 3.6815e-01, time/batch = 16.5520s	
9213/11350 (epoch 40.586), train_loss = 0.68827868, grad/param norm = 3.7873e-01, time/batch = 16.9490s	
9214/11350 (epoch 40.590), train_loss = 0.74254275, grad/param norm = 3.8951e-01, time/batch = 16.9168s	
9215/11350 (epoch 40.595), train_loss = 0.81296422, grad/param norm = 3.5560e-01, time/batch = 16.1423s	
9216/11350 (epoch 40.599), train_loss = 0.64573541, grad/param norm = 3.8209e-01, time/batch = 16.8776s	
9217/11350 (epoch 40.604), train_loss = 0.63656414, grad/param norm = 4.1832e-01, time/batch = 16.3122s	
9218/11350 (epoch 40.608), train_loss = 0.61107046, grad/param norm = 4.0678e-01, time/batch = 16.4834s	
9219/11350 (epoch 40.612), train_loss = 0.64209772, grad/param norm = 3.3579e-01, time/batch = 16.3806s	
9220/11350 (epoch 40.617), train_loss = 0.71398880, grad/param norm = 3.6124e-01, time/batch = 16.8438s	
9221/11350 (epoch 40.621), train_loss = 0.71583041, grad/param norm = 3.1184e-01, time/batch = 16.7138s	
9222/11350 (epoch 40.626), train_loss = 0.64756100, grad/param norm = 3.1831e-01, time/batch = 16.9450s	
9223/11350 (epoch 40.630), train_loss = 0.65241183, grad/param norm = 3.5983e-01, time/batch = 16.7828s	
9224/11350 (epoch 40.634), train_loss = 0.62432525, grad/param norm = 3.1489e-01, time/batch = 16.3778s	
9225/11350 (epoch 40.639), train_loss = 0.59168876, grad/param norm = 3.0774e-01, time/batch = 16.7175s	
9226/11350 (epoch 40.643), train_loss = 0.54703528, grad/param norm = 3.3675e-01, time/batch = 16.6886s	
9227/11350 (epoch 40.648), train_loss = 0.60512935, grad/param norm = 2.8346e-01, time/batch = 17.3300s	
9228/11350 (epoch 40.652), train_loss = 0.57356822, grad/param norm = 3.5387e-01, time/batch = 17.1809s	
9229/11350 (epoch 40.656), train_loss = 0.66770553, grad/param norm = 3.3706e-01, time/batch = 16.2270s	
9230/11350 (epoch 40.661), train_loss = 0.65218146, grad/param norm = 3.4452e-01, time/batch = 17.1149s	
9231/11350 (epoch 40.665), train_loss = 0.66873247, grad/param norm = 4.4478e-01, time/batch = 16.8755s	
9232/11350 (epoch 40.670), train_loss = 0.65332898, grad/param norm = 3.3755e-01, time/batch = 16.6333s	
9233/11350 (epoch 40.674), train_loss = 0.62779860, grad/param norm = 3.4042e-01, time/batch = 16.8855s	
9234/11350 (epoch 40.678), train_loss = 0.66158269, grad/param norm = 2.8788e-01, time/batch = 16.5486s	
9235/11350 (epoch 40.683), train_loss = 0.60449655, grad/param norm = 4.2980e-01, time/batch = 16.4793s	
9236/11350 (epoch 40.687), train_loss = 0.55722192, grad/param norm = 3.4981e-01, time/batch = 16.6352s	
9237/11350 (epoch 40.692), train_loss = 0.82651220, grad/param norm = 4.5517e-01, time/batch = 16.7917s	
9238/11350 (epoch 40.696), train_loss = 0.81526406, grad/param norm = 4.4571e-01, time/batch = 16.7941s	
9239/11350 (epoch 40.700), train_loss = 0.72660560, grad/param norm = 4.0657e-01, time/batch = 16.4728s	
9240/11350 (epoch 40.705), train_loss = 0.76173551, grad/param norm = 3.4954e-01, time/batch = 17.1773s	
9241/11350 (epoch 40.709), train_loss = 0.74088069, grad/param norm = 3.5715e-01, time/batch = 17.0983s	
9242/11350 (epoch 40.714), train_loss = 0.65391040, grad/param norm = 3.4879e-01, time/batch = 16.5482s	
9243/11350 (epoch 40.718), train_loss = 0.56837889, grad/param norm = 3.0214e-01, time/batch = 16.8643s	
9244/11350 (epoch 40.722), train_loss = 0.64802212, grad/param norm = 3.8626e-01, time/batch = 16.6354s	
9245/11350 (epoch 40.727), train_loss = 0.68094617, grad/param norm = 4.0449e-01, time/batch = 16.8609s	
9246/11350 (epoch 40.731), train_loss = 0.62578150, grad/param norm = 3.1215e-01, time/batch = 16.7225s	
9247/11350 (epoch 40.736), train_loss = 0.60714512, grad/param norm = 5.1804e-01, time/batch = 16.8797s	
9248/11350 (epoch 40.740), train_loss = 0.63508519, grad/param norm = 3.5326e-01, time/batch = 17.0373s	
9249/11350 (epoch 40.744), train_loss = 0.63179035, grad/param norm = 3.8411e-01, time/batch = 17.0907s	
9250/11350 (epoch 40.749), train_loss = 0.62991332, grad/param norm = 3.4233e-01, time/batch = 16.5469s	
9251/11350 (epoch 40.753), train_loss = 0.70116490, grad/param norm = 3.7967e-01, time/batch = 16.7747s	
9252/11350 (epoch 40.758), train_loss = 0.62447347, grad/param norm = 3.5799e-01, time/batch = 16.9396s	
9253/11350 (epoch 40.762), train_loss = 0.75017606, grad/param norm = 3.4159e-01, time/batch = 16.7011s	
9254/11350 (epoch 40.767), train_loss = 0.76687348, grad/param norm = 3.3658e-01, time/batch = 16.0678s	
9255/11350 (epoch 40.771), train_loss = 0.82910166, grad/param norm = 3.5094e-01, time/batch = 16.7816s	
9256/11350 (epoch 40.775), train_loss = 0.67328936, grad/param norm = 3.2108e-01, time/batch = 16.9616s	
9257/11350 (epoch 40.780), train_loss = 0.71856090, grad/param norm = 3.6190e-01, time/batch = 16.4053s	
9258/11350 (epoch 40.784), train_loss = 0.66466377, grad/param norm = 4.0443e-01, time/batch = 16.7037s	
9259/11350 (epoch 40.789), train_loss = 0.66576624, grad/param norm = 3.9222e-01, time/batch = 16.8476s	
9260/11350 (epoch 40.793), train_loss = 0.72204234, grad/param norm = 3.3543e-01, time/batch = 16.3824s	
9261/11350 (epoch 40.797), train_loss = 0.66760169, grad/param norm = 2.9121e-01, time/batch = 16.4643s	
9262/11350 (epoch 40.802), train_loss = 0.67393952, grad/param norm = 3.0427e-01, time/batch = 16.5460s	
9263/11350 (epoch 40.806), train_loss = 0.70543505, grad/param norm = 3.1290e-01, time/batch = 16.8764s	
9264/11350 (epoch 40.811), train_loss = 0.66320177, grad/param norm = 3.0946e-01, time/batch = 16.6437s	
9265/11350 (epoch 40.815), train_loss = 0.65041788, grad/param norm = 3.0391e-01, time/batch = 16.6318s	
9266/11350 (epoch 40.819), train_loss = 0.56524940, grad/param norm = 3.0963e-01, time/batch = 16.9493s	
9267/11350 (epoch 40.824), train_loss = 0.58152789, grad/param norm = 3.2145e-01, time/batch = 16.8783s	
9268/11350 (epoch 40.828), train_loss = 0.60497077, grad/param norm = 3.4663e-01, time/batch = 16.6329s	
9269/11350 (epoch 40.833), train_loss = 0.62862804, grad/param norm = 2.9945e-01, time/batch = 16.7269s	
9270/11350 (epoch 40.837), train_loss = 0.66148755, grad/param norm = 3.4322e-01, time/batch = 17.1710s	
9271/11350 (epoch 40.841), train_loss = 0.87261411, grad/param norm = 3.6843e-01, time/batch = 16.7772s	
9272/11350 (epoch 40.846), train_loss = 0.71292373, grad/param norm = 2.9633e-01, time/batch = 16.6433s	
9273/11350 (epoch 40.850), train_loss = 0.71325210, grad/param norm = 3.2391e-01, time/batch = 16.7808s	
9274/11350 (epoch 40.855), train_loss = 0.55493228, grad/param norm = 3.0704e-01, time/batch = 16.7126s	
9275/11350 (epoch 40.859), train_loss = 0.59651937, grad/param norm = 3.7497e-01, time/batch = 17.4277s	
9276/11350 (epoch 40.863), train_loss = 0.57407979, grad/param norm = 3.0351e-01, time/batch = 16.9255s	
9277/11350 (epoch 40.868), train_loss = 0.57438472, grad/param norm = 2.8703e-01, time/batch = 17.0860s	
9278/11350 (epoch 40.872), train_loss = 0.58862428, grad/param norm = 2.9433e-01, time/batch = 16.5531s	
9279/11350 (epoch 40.877), train_loss = 0.59219269, grad/param norm = 3.6395e-01, time/batch = 16.4571s	
9280/11350 (epoch 40.881), train_loss = 0.79382947, grad/param norm = 4.2630e-01, time/batch = 16.7879s	
9281/11350 (epoch 40.885), train_loss = 0.73770390, grad/param norm = 3.4377e-01, time/batch = 17.0259s	
9282/11350 (epoch 40.890), train_loss = 0.69180307, grad/param norm = 3.8186e-01, time/batch = 16.8706s	
9283/11350 (epoch 40.894), train_loss = 0.57887804, grad/param norm = 3.2205e-01, time/batch = 16.4785s	
9284/11350 (epoch 40.899), train_loss = 0.70697239, grad/param norm = 3.3597e-01, time/batch = 16.8605s	
9285/11350 (epoch 40.903), train_loss = 0.67151918, grad/param norm = 3.4493e-01, time/batch = 16.6184s	
9286/11350 (epoch 40.907), train_loss = 0.60467668, grad/param norm = 4.1474e-01, time/batch = 16.4674s	
9287/11350 (epoch 40.912), train_loss = 0.59465442, grad/param norm = 3.0472e-01, time/batch = 16.7928s	
9288/11350 (epoch 40.916), train_loss = 0.66314946, grad/param norm = 4.0629e-01, time/batch = 16.8843s	
9289/11350 (epoch 40.921), train_loss = 0.66788647, grad/param norm = 3.4265e-01, time/batch = 16.6398s	
9290/11350 (epoch 40.925), train_loss = 0.57749980, grad/param norm = 3.2447e-01, time/batch = 16.6975s	
9291/11350 (epoch 40.930), train_loss = 0.66893421, grad/param norm = 4.1310e-01, time/batch = 17.0117s	
9292/11350 (epoch 40.934), train_loss = 0.74163525, grad/param norm = 3.4789e-01, time/batch = 16.6403s	
9293/11350 (epoch 40.938), train_loss = 0.68700306, grad/param norm = 4.2474e-01, time/batch = 16.4605s	
9294/11350 (epoch 40.943), train_loss = 0.71069288, grad/param norm = 3.5962e-01, time/batch = 16.9420s	
9295/11350 (epoch 40.947), train_loss = 0.68147122, grad/param norm = 3.5945e-01, time/batch = 17.1894s	
9296/11350 (epoch 40.952), train_loss = 0.67542447, grad/param norm = 3.4527e-01, time/batch = 16.7837s	
9297/11350 (epoch 40.956), train_loss = 0.54969337, grad/param norm = 2.7002e-01, time/batch = 16.5562s	
9298/11350 (epoch 40.960), train_loss = 0.62910014, grad/param norm = 4.8034e-01, time/batch = 16.9521s	
9299/11350 (epoch 40.965), train_loss = 0.54136206, grad/param norm = 3.1241e-01, time/batch = 17.1712s	
9300/11350 (epoch 40.969), train_loss = 0.55690969, grad/param norm = 4.1492e-01, time/batch = 16.1478s	
9301/11350 (epoch 40.974), train_loss = 0.53985122, grad/param norm = 3.2977e-01, time/batch = 16.6451s	
9302/11350 (epoch 40.978), train_loss = 0.62696027, grad/param norm = 2.9449e-01, time/batch = 16.6246s	
9303/11350 (epoch 40.982), train_loss = 0.41763749, grad/param norm = 3.0623e-01, time/batch = 16.3893s	
9304/11350 (epoch 40.987), train_loss = 0.63324731, grad/param norm = 3.3309e-01, time/batch = 16.7109s	
9305/11350 (epoch 40.991), train_loss = 0.54592113, grad/param norm = 3.3066e-01, time/batch = 16.8706s	
9306/11350 (epoch 40.996), train_loss = 0.60466696, grad/param norm = 4.1422e-01, time/batch = 16.7785s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
9307/11350 (epoch 41.000), train_loss = 0.49870648, grad/param norm = 3.1603e-01, time/batch = 16.6931s	
9308/11350 (epoch 41.004), train_loss = 0.68614721, grad/param norm = 3.4721e-01, time/batch = 16.6335s	
9309/11350 (epoch 41.009), train_loss = 0.66864392, grad/param norm = 3.8833e-01, time/batch = 16.4625s	
9310/11350 (epoch 41.013), train_loss = 0.45657719, grad/param norm = 2.9160e-01, time/batch = 16.6393s	
9311/11350 (epoch 41.018), train_loss = 0.50646621, grad/param norm = 2.8089e-01, time/batch = 16.5337s	
9312/11350 (epoch 41.022), train_loss = 0.56054716, grad/param norm = 3.8476e-01, time/batch = 19.0843s	
9313/11350 (epoch 41.026), train_loss = 0.51832939, grad/param norm = 4.5378e-01, time/batch = 29.2961s	
9314/11350 (epoch 41.031), train_loss = 0.52401778, grad/param norm = 3.3379e-01, time/batch = 16.7091s	
9315/11350 (epoch 41.035), train_loss = 0.55362640, grad/param norm = 3.2604e-01, time/batch = 17.1839s	
9316/11350 (epoch 41.040), train_loss = 0.57902606, grad/param norm = 3.5568e-01, time/batch = 17.0933s	
9317/11350 (epoch 41.044), train_loss = 0.52110738, grad/param norm = 3.0103e-01, time/batch = 16.5661s	
9318/11350 (epoch 41.048), train_loss = 0.51665889, grad/param norm = 3.3120e-01, time/batch = 16.4765s	
9319/11350 (epoch 41.053), train_loss = 0.56060468, grad/param norm = 3.2493e-01, time/batch = 16.8714s	
9320/11350 (epoch 41.057), train_loss = 0.55843521, grad/param norm = 4.0061e-01, time/batch = 16.2242s	
9321/11350 (epoch 41.062), train_loss = 0.46529274, grad/param norm = 2.8405e-01, time/batch = 16.4718s	
9322/11350 (epoch 41.066), train_loss = 0.47176383, grad/param norm = 3.5521e-01, time/batch = 16.7875s	
9323/11350 (epoch 41.070), train_loss = 0.54003871, grad/param norm = 2.9447e-01, time/batch = 16.7154s	
9324/11350 (epoch 41.075), train_loss = 0.48419854, grad/param norm = 2.7804e-01, time/batch = 16.7834s	
9325/11350 (epoch 41.079), train_loss = 0.59930637, grad/param norm = 3.8188e-01, time/batch = 16.3217s	
9326/11350 (epoch 41.084), train_loss = 0.68811826, grad/param norm = 3.7293e-01, time/batch = 17.6032s	
9327/11350 (epoch 41.088), train_loss = 0.63663798, grad/param norm = 3.8850e-01, time/batch = 16.5429s	
9328/11350 (epoch 41.093), train_loss = 0.62619726, grad/param norm = 3.0913e-01, time/batch = 16.5488s	
9329/11350 (epoch 41.097), train_loss = 0.56429864, grad/param norm = 3.5641e-01, time/batch = 17.1046s	
9330/11350 (epoch 41.101), train_loss = 0.54114921, grad/param norm = 3.5676e-01, time/batch = 16.9390s	
9331/11350 (epoch 41.106), train_loss = 0.59791029, grad/param norm = 3.1835e-01, time/batch = 16.7224s	
9332/11350 (epoch 41.110), train_loss = 0.54024946, grad/param norm = 3.4316e-01, time/batch = 17.0109s	
9333/11350 (epoch 41.115), train_loss = 0.56355232, grad/param norm = 3.4911e-01, time/batch = 17.2182s	
9334/11350 (epoch 41.119), train_loss = 0.65904088, grad/param norm = 4.3721e-01, time/batch = 16.4716s	
9335/11350 (epoch 41.123), train_loss = 0.52203415, grad/param norm = 3.4323e-01, time/batch = 16.6425s	
9336/11350 (epoch 41.128), train_loss = 0.47619024, grad/param norm = 3.2001e-01, time/batch = 16.8572s	
9337/11350 (epoch 41.132), train_loss = 0.51830301, grad/param norm = 2.9204e-01, time/batch = 16.9530s	
9338/11350 (epoch 41.137), train_loss = 0.48925031, grad/param norm = 3.6688e-01, time/batch = 16.4650s	
9339/11350 (epoch 41.141), train_loss = 0.65165077, grad/param norm = 4.1513e-01, time/batch = 16.3913s	
9340/11350 (epoch 41.145), train_loss = 0.53824670, grad/param norm = 3.4088e-01, time/batch = 16.7760s	
9341/11350 (epoch 41.150), train_loss = 0.59020646, grad/param norm = 4.6332e-01, time/batch = 16.7181s	
9342/11350 (epoch 41.154), train_loss = 0.70044581, grad/param norm = 4.3803e-01, time/batch = 16.6147s	
9343/11350 (epoch 41.159), train_loss = 0.48981728, grad/param norm = 3.0426e-01, time/batch = 16.4419s	
9344/11350 (epoch 41.163), train_loss = 0.60688270, grad/param norm = 3.9496e-01, time/batch = 16.8687s	
9345/11350 (epoch 41.167), train_loss = 0.66565811, grad/param norm = 3.5043e-01, time/batch = 16.5463s	
9346/11350 (epoch 41.172), train_loss = 0.73926790, grad/param norm = 3.4255e-01, time/batch = 17.2838s	
9347/11350 (epoch 41.176), train_loss = 0.58597250, grad/param norm = 3.6483e-01, time/batch = 17.1813s	
9348/11350 (epoch 41.181), train_loss = 0.56937680, grad/param norm = 3.8109e-01, time/batch = 16.7918s	
9349/11350 (epoch 41.185), train_loss = 0.53264554, grad/param norm = 3.1595e-01, time/batch = 16.8802s	
9350/11350 (epoch 41.189), train_loss = 0.53120634, grad/param norm = 3.3499e-01, time/batch = 16.5560s	
9351/11350 (epoch 41.194), train_loss = 0.49227424, grad/param norm = 3.6251e-01, time/batch = 17.1795s	
9352/11350 (epoch 41.198), train_loss = 0.45111476, grad/param norm = 3.4162e-01, time/batch = 16.6266s	
9353/11350 (epoch 41.203), train_loss = 0.51735119, grad/param norm = 2.9996e-01, time/batch = 17.2624s	
9354/11350 (epoch 41.207), train_loss = 0.48312027, grad/param norm = 4.1136e-01, time/batch = 16.8686s	
9355/11350 (epoch 41.211), train_loss = 0.64358481, grad/param norm = 3.8211e-01, time/batch = 17.0306s	
9356/11350 (epoch 41.216), train_loss = 0.61138778, grad/param norm = 4.1711e-01, time/batch = 16.8015s	
9357/11350 (epoch 41.220), train_loss = 0.61254607, grad/param norm = 3.5127e-01, time/batch = 16.3863s	
9358/11350 (epoch 41.225), train_loss = 0.54209816, grad/param norm = 2.8391e-01, time/batch = 16.8589s	
9359/11350 (epoch 41.229), train_loss = 0.59051627, grad/param norm = 3.0005e-01, time/batch = 17.3958s	
9360/11350 (epoch 41.233), train_loss = 0.56482376, grad/param norm = 4.8794e-01, time/batch = 16.7765s	
9361/11350 (epoch 41.238), train_loss = 0.69342017, grad/param norm = 5.0850e-01, time/batch = 16.4683s	
9362/11350 (epoch 41.242), train_loss = 0.68102864, grad/param norm = 4.3068e-01, time/batch = 16.5452s	
9363/11350 (epoch 41.247), train_loss = 0.48612685, grad/param norm = 3.0141e-01, time/batch = 16.4687s	
9364/11350 (epoch 41.251), train_loss = 0.55818903, grad/param norm = 3.7052e-01, time/batch = 17.5775s	
9365/11350 (epoch 41.256), train_loss = 0.62126736, grad/param norm = 3.3659e-01, time/batch = 17.2748s	
9366/11350 (epoch 41.260), train_loss = 0.52325237, grad/param norm = 2.9070e-01, time/batch = 16.6273s	
9367/11350 (epoch 41.264), train_loss = 0.51140101, grad/param norm = 3.3546e-01, time/batch = 16.6343s	
9368/11350 (epoch 41.269), train_loss = 0.55108018, grad/param norm = 2.5434e-01, time/batch = 16.7688s	
9369/11350 (epoch 41.273), train_loss = 0.65678501, grad/param norm = 3.4725e-01, time/batch = 16.3869s	
9370/11350 (epoch 41.278), train_loss = 0.53825710, grad/param norm = 3.1370e-01, time/batch = 16.4681s	
9371/11350 (epoch 41.282), train_loss = 0.54093790, grad/param norm = 3.1405e-01, time/batch = 16.8045s	
9372/11350 (epoch 41.286), train_loss = 0.62814690, grad/param norm = 3.6245e-01, time/batch = 17.1841s	
9373/11350 (epoch 41.291), train_loss = 0.53858436, grad/param norm = 3.5820e-01, time/batch = 16.4694s	
9374/11350 (epoch 41.295), train_loss = 0.55182187, grad/param norm = 3.7861e-01, time/batch = 16.6207s	
9375/11350 (epoch 41.300), train_loss = 0.65185819, grad/param norm = 3.8811e-01, time/batch = 16.7979s	
9376/11350 (epoch 41.304), train_loss = 0.52094270, grad/param norm = 3.4412e-01, time/batch = 16.9585s	
9377/11350 (epoch 41.308), train_loss = 0.50428204, grad/param norm = 2.8392e-01, time/batch = 16.6320s	
9378/11350 (epoch 41.313), train_loss = 0.57716157, grad/param norm = 2.9689e-01, time/batch = 16.7798s	
9379/11350 (epoch 41.317), train_loss = 0.56022616, grad/param norm = 2.8759e-01, time/batch = 17.1022s	
9380/11350 (epoch 41.322), train_loss = 0.55413725, grad/param norm = 4.0863e-01, time/batch = 16.5602s	
9381/11350 (epoch 41.326), train_loss = 0.56469246, grad/param norm = 2.7889e-01, time/batch = 16.3185s	
9382/11350 (epoch 41.330), train_loss = 0.46760355, grad/param norm = 2.5875e-01, time/batch = 16.6235s	
9383/11350 (epoch 41.335), train_loss = 0.39180090, grad/param norm = 3.2301e-01, time/batch = 17.5674s	
9384/11350 (epoch 41.339), train_loss = 0.41337905, grad/param norm = 3.5834e-01, time/batch = 16.6995s	
9385/11350 (epoch 41.344), train_loss = 0.52573273, grad/param norm = 3.3049e-01, time/batch = 16.4727s	
9386/11350 (epoch 41.348), train_loss = 0.51649134, grad/param norm = 2.6106e-01, time/batch = 16.6977s	
9387/11350 (epoch 41.352), train_loss = 0.41528818, grad/param norm = 2.4585e-01, time/batch = 16.8676s	
9388/11350 (epoch 41.357), train_loss = 0.51242810, grad/param norm = 2.5964e-01, time/batch = 16.4696s	
9389/11350 (epoch 41.361), train_loss = 0.43345238, grad/param norm = 2.4918e-01, time/batch = 16.2967s	
9390/11350 (epoch 41.366), train_loss = 0.52399817, grad/param norm = 3.4263e-01, time/batch = 17.3251s	
9391/11350 (epoch 41.370), train_loss = 0.44180374, grad/param norm = 3.0936e-01, time/batch = 16.7053s	
9392/11350 (epoch 41.374), train_loss = 0.50514090, grad/param norm = 3.3910e-01, time/batch = 16.3859s	
9393/11350 (epoch 41.379), train_loss = 0.49126204, grad/param norm = 2.8651e-01, time/batch = 16.7086s	
9394/11350 (epoch 41.383), train_loss = 0.44193273, grad/param norm = 3.4448e-01, time/batch = 16.8563s	
9395/11350 (epoch 41.388), train_loss = 0.51203516, grad/param norm = 4.0542e-01, time/batch = 16.4508s	
9396/11350 (epoch 41.392), train_loss = 0.59977400, grad/param norm = 3.0636e-01, time/batch = 16.5556s	
9397/11350 (epoch 41.396), train_loss = 0.51458809, grad/param norm = 4.2864e-01, time/batch = 16.8787s	
9398/11350 (epoch 41.401), train_loss = 0.51106895, grad/param norm = 3.7751e-01, time/batch = 16.7149s	
9399/11350 (epoch 41.405), train_loss = 0.67526362, grad/param norm = 3.6588e-01, time/batch = 16.3841s	
9400/11350 (epoch 41.410), train_loss = 0.70483035, grad/param norm = 4.0319e-01, time/batch = 17.0959s	
9401/11350 (epoch 41.414), train_loss = 0.48068354, grad/param norm = 3.2553e-01, time/batch = 22.8634s	
9402/11350 (epoch 41.419), train_loss = 0.47734372, grad/param norm = 2.9854e-01, time/batch = 23.3760s	
9403/11350 (epoch 41.423), train_loss = 0.50613503, grad/param norm = 3.5095e-01, time/batch = 24.7645s	
9404/11350 (epoch 41.427), train_loss = 0.58073650, grad/param norm = 3.5702e-01, time/batch = 25.1787s	
9405/11350 (epoch 41.432), train_loss = 0.56941302, grad/param norm = 3.5941e-01, time/batch = 22.6378s	
9406/11350 (epoch 41.436), train_loss = 0.46469009, grad/param norm = 3.2821e-01, time/batch = 24.3020s	
9407/11350 (epoch 41.441), train_loss = 0.62140622, grad/param norm = 3.6767e-01, time/batch = 25.1660s	
9408/11350 (epoch 41.445), train_loss = 0.50314541, grad/param norm = 2.8602e-01, time/batch = 24.8512s	
9409/11350 (epoch 41.449), train_loss = 0.57848459, grad/param norm = 2.9530e-01, time/batch = 25.0307s	
9410/11350 (epoch 41.454), train_loss = 0.67796654, grad/param norm = 3.7325e-01, time/batch = 22.4767s	
9411/11350 (epoch 41.458), train_loss = 0.47329195, grad/param norm = 2.8684e-01, time/batch = 23.8602s	
9412/11350 (epoch 41.463), train_loss = 0.48303572, grad/param norm = 3.2537e-01, time/batch = 24.2704s	
9413/11350 (epoch 41.467), train_loss = 0.72007914, grad/param norm = 3.6886e-01, time/batch = 24.6776s	
9414/11350 (epoch 41.471), train_loss = 0.68937415, grad/param norm = 6.0892e-01, time/batch = 23.5441s	
9415/11350 (epoch 41.476), train_loss = 0.59968178, grad/param norm = 3.7132e-01, time/batch = 23.4308s	
9416/11350 (epoch 41.480), train_loss = 0.63529415, grad/param norm = 3.3724e-01, time/batch = 22.5952s	
9417/11350 (epoch 41.485), train_loss = 0.59642566, grad/param norm = 3.4393e-01, time/batch = 23.0370s	
9418/11350 (epoch 41.489), train_loss = 0.62588587, grad/param norm = 3.4802e-01, time/batch = 26.4258s	
9419/11350 (epoch 41.493), train_loss = 0.67429416, grad/param norm = 3.3422e-01, time/batch = 24.6238s	
9420/11350 (epoch 41.498), train_loss = 0.42832013, grad/param norm = 2.7495e-01, time/batch = 16.3964s	
9421/11350 (epoch 41.502), train_loss = 0.69075110, grad/param norm = 3.6231e-01, time/batch = 16.7900s	
9422/11350 (epoch 41.507), train_loss = 0.49107907, grad/param norm = 2.6805e-01, time/batch = 16.5385s	
9423/11350 (epoch 41.511), train_loss = 0.62068490, grad/param norm = 3.1450e-01, time/batch = 16.5187s	
9424/11350 (epoch 41.515), train_loss = 0.60197423, grad/param norm = 5.2685e-01, time/batch = 17.0177s	
9425/11350 (epoch 41.520), train_loss = 0.72267905, grad/param norm = 4.0262e-01, time/batch = 17.0259s	
9426/11350 (epoch 41.524), train_loss = 0.62100973, grad/param norm = 3.6503e-01, time/batch = 16.7254s	
9427/11350 (epoch 41.529), train_loss = 0.53821370, grad/param norm = 2.6870e-01, time/batch = 16.9436s	
9428/11350 (epoch 41.533), train_loss = 0.73846519, grad/param norm = 3.8274e-01, time/batch = 17.0209s	
9429/11350 (epoch 41.537), train_loss = 0.67329721, grad/param norm = 3.4807e-01, time/batch = 17.4211s	
9430/11350 (epoch 41.542), train_loss = 0.57434068, grad/param norm = 3.0509e-01, time/batch = 16.9398s	
9431/11350 (epoch 41.546), train_loss = 0.72429427, grad/param norm = 4.0916e-01, time/batch = 16.6166s	
9432/11350 (epoch 41.551), train_loss = 0.63544679, grad/param norm = 4.1688e-01, time/batch = 17.1102s	
9433/11350 (epoch 41.555), train_loss = 0.54118354, grad/param norm = 3.2210e-01, time/batch = 16.6961s	
9434/11350 (epoch 41.559), train_loss = 0.59312898, grad/param norm = 2.8334e-01, time/batch = 16.9675s	
9435/11350 (epoch 41.564), train_loss = 0.61227485, grad/param norm = 3.3307e-01, time/batch = 16.8793s	
9436/11350 (epoch 41.568), train_loss = 0.62858149, grad/param norm = 3.0810e-01, time/batch = 16.7846s	
9437/11350 (epoch 41.573), train_loss = 0.75179105, grad/param norm = 5.3917e-01, time/batch = 16.5472s	
9438/11350 (epoch 41.577), train_loss = 0.68383566, grad/param norm = 5.2908e-01, time/batch = 16.7038s	
9439/11350 (epoch 41.581), train_loss = 0.73132294, grad/param norm = 3.7806e-01, time/batch = 16.8730s	
9440/11350 (epoch 41.586), train_loss = 0.68951064, grad/param norm = 4.1369e-01, time/batch = 16.7953s	
9441/11350 (epoch 41.590), train_loss = 0.72469502, grad/param norm = 4.3307e-01, time/batch = 16.7976s	
9442/11350 (epoch 41.595), train_loss = 0.80880292, grad/param norm = 3.5191e-01, time/batch = 17.3292s	
9443/11350 (epoch 41.599), train_loss = 0.62361573, grad/param norm = 3.7145e-01, time/batch = 16.6805s	
9444/11350 (epoch 41.604), train_loss = 0.62702999, grad/param norm = 3.4770e-01, time/batch = 16.2963s	
9445/11350 (epoch 41.608), train_loss = 0.59941144, grad/param norm = 3.8698e-01, time/batch = 16.8549s	
9446/11350 (epoch 41.612), train_loss = 0.63036044, grad/param norm = 3.4504e-01, time/batch = 17.1131s	
9447/11350 (epoch 41.617), train_loss = 0.70969769, grad/param norm = 4.0029e-01, time/batch = 16.8560s	
9448/11350 (epoch 41.621), train_loss = 0.71307500, grad/param norm = 3.4626e-01, time/batch = 16.7132s	
9449/11350 (epoch 41.626), train_loss = 0.64152183, grad/param norm = 3.1404e-01, time/batch = 17.0381s	
9450/11350 (epoch 41.630), train_loss = 0.62116057, grad/param norm = 2.9200e-01, time/batch = 16.6392s	
9451/11350 (epoch 41.634), train_loss = 0.61109568, grad/param norm = 3.2114e-01, time/batch = 17.3488s	
9452/11350 (epoch 41.639), train_loss = 0.58655732, grad/param norm = 3.5855e-01, time/batch = 16.6332s	
9453/11350 (epoch 41.643), train_loss = 0.51119104, grad/param norm = 3.2789e-01, time/batch = 16.5435s	
9454/11350 (epoch 41.648), train_loss = 0.60541975, grad/param norm = 3.3639e-01, time/batch = 16.3915s	
9455/11350 (epoch 41.652), train_loss = 0.54116662, grad/param norm = 3.2074e-01, time/batch = 16.2228s	
9456/11350 (epoch 41.656), train_loss = 0.65472760, grad/param norm = 3.2697e-01, time/batch = 16.6269s	
9457/11350 (epoch 41.661), train_loss = 0.64475585, grad/param norm = 3.5400e-01, time/batch = 16.6381s	
9458/11350 (epoch 41.665), train_loss = 0.65473110, grad/param norm = 3.6786e-01, time/batch = 16.7178s	
9459/11350 (epoch 41.670), train_loss = 0.64551431, grad/param norm = 3.0239e-01, time/batch = 16.6373s	
9460/11350 (epoch 41.674), train_loss = 0.59311735, grad/param norm = 2.9220e-01, time/batch = 16.6190s	
9461/11350 (epoch 41.678), train_loss = 0.66065581, grad/param norm = 3.0287e-01, time/batch = 16.3076s	
9462/11350 (epoch 41.683), train_loss = 0.59796006, grad/param norm = 3.2227e-01, time/batch = 16.6278s	
9463/11350 (epoch 41.687), train_loss = 0.52835450, grad/param norm = 3.3478e-01, time/batch = 16.7687s	
9464/11350 (epoch 41.692), train_loss = 0.79937758, grad/param norm = 3.9922e-01, time/batch = 16.7682s	
9465/11350 (epoch 41.696), train_loss = 0.79437306, grad/param norm = 3.6197e-01, time/batch = 16.2114s	
9466/11350 (epoch 41.700), train_loss = 0.71153376, grad/param norm = 3.8167e-01, time/batch = 16.1363s	
9467/11350 (epoch 41.705), train_loss = 0.74111526, grad/param norm = 3.7412e-01, time/batch = 17.0889s	
9468/11350 (epoch 41.709), train_loss = 0.71475149, grad/param norm = 3.8535e-01, time/batch = 16.7159s	
9469/11350 (epoch 41.714), train_loss = 0.64149479, grad/param norm = 3.6567e-01, time/batch = 16.3895s	
9470/11350 (epoch 41.718), train_loss = 0.56541871, grad/param norm = 3.1993e-01, time/batch = 16.3084s	
9471/11350 (epoch 41.722), train_loss = 0.62751784, grad/param norm = 4.2189e-01, time/batch = 16.5337s	
9472/11350 (epoch 41.727), train_loss = 0.66100079, grad/param norm = 3.4649e-01, time/batch = 16.5214s	
9473/11350 (epoch 41.731), train_loss = 0.61349705, grad/param norm = 3.8158e-01, time/batch = 16.4645s	
9474/11350 (epoch 41.736), train_loss = 0.58552607, grad/param norm = 3.8130e-01, time/batch = 16.8676s	
9475/11350 (epoch 41.740), train_loss = 0.62052611, grad/param norm = 3.2322e-01, time/batch = 16.6897s	
9476/11350 (epoch 41.744), train_loss = 0.61027895, grad/param norm = 3.2776e-01, time/batch = 16.2250s	
9477/11350 (epoch 41.749), train_loss = 0.62394091, grad/param norm = 3.5109e-01, time/batch = 16.6313s	
9478/11350 (epoch 41.753), train_loss = 0.68043452, grad/param norm = 3.5728e-01, time/batch = 16.7870s	
9479/11350 (epoch 41.758), train_loss = 0.59851237, grad/param norm = 3.4477e-01, time/batch = 17.1011s	
9480/11350 (epoch 41.762), train_loss = 0.74269286, grad/param norm = 3.4568e-01, time/batch = 16.6800s	
9481/11350 (epoch 41.767), train_loss = 0.72828475, grad/param norm = 3.1339e-01, time/batch = 17.0146s	
9482/11350 (epoch 41.771), train_loss = 0.81458491, grad/param norm = 3.4606e-01, time/batch = 16.8771s	
9483/11350 (epoch 41.775), train_loss = 0.65559268, grad/param norm = 3.4956e-01, time/batch = 16.4640s	
9484/11350 (epoch 41.780), train_loss = 0.70678419, grad/param norm = 3.6557e-01, time/batch = 16.6340s	
9485/11350 (epoch 41.784), train_loss = 0.64461040, grad/param norm = 3.1428e-01, time/batch = 17.2884s	
9486/11350 (epoch 41.789), train_loss = 0.65876429, grad/param norm = 3.4607e-01, time/batch = 16.3008s	
9487/11350 (epoch 41.793), train_loss = 0.72126304, grad/param norm = 3.4732e-01, time/batch = 16.3888s	
9488/11350 (epoch 41.797), train_loss = 0.64282032, grad/param norm = 2.9307e-01, time/batch = 16.5494s	
9489/11350 (epoch 41.802), train_loss = 0.66704232, grad/param norm = 3.4249e-01, time/batch = 16.7148s	
9490/11350 (epoch 41.806), train_loss = 0.68659475, grad/param norm = 3.0888e-01, time/batch = 17.1668s	
9491/11350 (epoch 41.811), train_loss = 0.66910862, grad/param norm = 3.1711e-01, time/batch = 16.8722s	
9492/11350 (epoch 41.815), train_loss = 0.63554538, grad/param norm = 2.9626e-01, time/batch = 16.9438s	
9493/11350 (epoch 41.819), train_loss = 0.56168638, grad/param norm = 3.1931e-01, time/batch = 16.3869s	
9494/11350 (epoch 41.824), train_loss = 0.56917168, grad/param norm = 3.3455e-01, time/batch = 16.3921s	
9495/11350 (epoch 41.828), train_loss = 0.59511433, grad/param norm = 3.2723e-01, time/batch = 16.8009s	
9496/11350 (epoch 41.833), train_loss = 0.60925070, grad/param norm = 3.2684e-01, time/batch = 16.7008s	
9497/11350 (epoch 41.837), train_loss = 0.64046916, grad/param norm = 3.2896e-01, time/batch = 16.8730s	
9498/11350 (epoch 41.841), train_loss = 0.85551885, grad/param norm = 3.7116e-01, time/batch = 16.8673s	
9499/11350 (epoch 41.846), train_loss = 0.70728628, grad/param norm = 3.1175e-01, time/batch = 16.7746s	
9500/11350 (epoch 41.850), train_loss = 0.70776977, grad/param norm = 3.4748e-01, time/batch = 16.2224s	
9501/11350 (epoch 41.855), train_loss = 0.53444797, grad/param norm = 3.1035e-01, time/batch = 17.1165s	
9502/11350 (epoch 41.859), train_loss = 0.60272515, grad/param norm = 4.4861e-01, time/batch = 16.4593s	
9503/11350 (epoch 41.863), train_loss = 0.57880391, grad/param norm = 3.8476e-01, time/batch = 16.6183s	
9504/11350 (epoch 41.868), train_loss = 0.55790567, grad/param norm = 2.8077e-01, time/batch = 16.5537s	
9505/11350 (epoch 41.872), train_loss = 0.58313378, grad/param norm = 3.2483e-01, time/batch = 16.0660s	
9506/11350 (epoch 41.877), train_loss = 0.58906562, grad/param norm = 3.6209e-01, time/batch = 16.2975s	
9507/11350 (epoch 41.881), train_loss = 0.76822264, grad/param norm = 4.0098e-01, time/batch = 16.7055s	
9508/11350 (epoch 41.885), train_loss = 0.71213935, grad/param norm = 3.1369e-01, time/batch = 16.7909s	
9509/11350 (epoch 41.890), train_loss = 0.65509882, grad/param norm = 3.6492e-01, time/batch = 16.4503s	
9510/11350 (epoch 41.894), train_loss = 0.56765344, grad/param norm = 3.2373e-01, time/batch = 16.7117s	
9511/11350 (epoch 41.899), train_loss = 0.69873253, grad/param norm = 4.0193e-01, time/batch = 16.3749s	
9512/11350 (epoch 41.903), train_loss = 0.66254504, grad/param norm = 3.5104e-01, time/batch = 16.5490s	
9513/11350 (epoch 41.907), train_loss = 0.58200864, grad/param norm = 3.3882e-01, time/batch = 16.3134s	
9514/11350 (epoch 41.912), train_loss = 0.58301597, grad/param norm = 3.0887e-01, time/batch = 16.7624s	
9515/11350 (epoch 41.916), train_loss = 0.64396772, grad/param norm = 3.4809e-01, time/batch = 17.0080s	
9516/11350 (epoch 41.921), train_loss = 0.64880375, grad/param norm = 3.2260e-01, time/batch = 16.6346s	
9517/11350 (epoch 41.925), train_loss = 0.54279876, grad/param norm = 2.6093e-01, time/batch = 19.9780s	
9518/11350 (epoch 41.930), train_loss = 0.64784667, grad/param norm = 3.6790e-01, time/batch = 28.3819s	
9519/11350 (epoch 41.934), train_loss = 0.72780916, grad/param norm = 4.0414e-01, time/batch = 19.4000s	
9520/11350 (epoch 41.938), train_loss = 0.64532282, grad/param norm = 3.3179e-01, time/batch = 17.0105s	
9521/11350 (epoch 41.943), train_loss = 0.69041232, grad/param norm = 3.4719e-01, time/batch = 16.9709s	
9522/11350 (epoch 41.947), train_loss = 0.65235673, grad/param norm = 3.0497e-01, time/batch = 16.5507s	
9523/11350 (epoch 41.952), train_loss = 0.67149466, grad/param norm = 3.3621e-01, time/batch = 16.6421s	
9524/11350 (epoch 41.956), train_loss = 0.54585496, grad/param norm = 2.9245e-01, time/batch = 16.4442s	
9525/11350 (epoch 41.960), train_loss = 0.62921131, grad/param norm = 4.0598e-01, time/batch = 16.4798s	
9526/11350 (epoch 41.965), train_loss = 0.54350117, grad/param norm = 3.5028e-01, time/batch = 16.7878s	
9527/11350 (epoch 41.969), train_loss = 0.52755837, grad/param norm = 3.2427e-01, time/batch = 16.9603s	
9528/11350 (epoch 41.974), train_loss = 0.53815711, grad/param norm = 3.4160e-01, time/batch = 16.5579s	
9529/11350 (epoch 41.978), train_loss = 0.62055823, grad/param norm = 3.4184e-01, time/batch = 16.1361s	
9530/11350 (epoch 41.982), train_loss = 0.41963410, grad/param norm = 2.8098e-01, time/batch = 16.3817s	
9531/11350 (epoch 41.987), train_loss = 0.61087513, grad/param norm = 2.9950e-01, time/batch = 16.8881s	
9532/11350 (epoch 41.991), train_loss = 0.54297838, grad/param norm = 3.7650e-01, time/batch = 16.8744s	
9533/11350 (epoch 41.996), train_loss = 0.59376049, grad/param norm = 4.1947e-01, time/batch = 17.0240s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
9534/11350 (epoch 42.000), train_loss = 0.49280267, grad/param norm = 3.5204e-01, time/batch = 17.2004s	
9535/11350 (epoch 42.004), train_loss = 0.67532375, grad/param norm = 3.5900e-01, time/batch = 16.5576s	
9536/11350 (epoch 42.009), train_loss = 0.63587171, grad/param norm = 3.2341e-01, time/batch = 16.8637s	
9537/11350 (epoch 42.013), train_loss = 0.43830918, grad/param norm = 2.7317e-01, time/batch = 17.4952s	
9538/11350 (epoch 42.018), train_loss = 0.49432953, grad/param norm = 3.2244e-01, time/batch = 16.9542s	
9539/11350 (epoch 42.022), train_loss = 0.53046535, grad/param norm = 3.6319e-01, time/batch = 16.9433s	
9540/11350 (epoch 42.026), train_loss = 0.49564843, grad/param norm = 2.9300e-01, time/batch = 16.7610s	
9541/11350 (epoch 42.031), train_loss = 0.51674101, grad/param norm = 3.2958e-01, time/batch = 17.0278s	
9542/11350 (epoch 42.035), train_loss = 0.54157367, grad/param norm = 3.2719e-01, time/batch = 16.9658s	
9543/11350 (epoch 42.040), train_loss = 0.55791149, grad/param norm = 2.9914e-01, time/batch = 16.9576s	
9544/11350 (epoch 42.044), train_loss = 0.50634868, grad/param norm = 2.8037e-01, time/batch = 16.4752s	
9545/11350 (epoch 42.048), train_loss = 0.50453104, grad/param norm = 2.9311e-01, time/batch = 16.8680s	
9546/11350 (epoch 42.053), train_loss = 0.53206957, grad/param norm = 2.7546e-01, time/batch = 16.6309s	
9547/11350 (epoch 42.057), train_loss = 0.54135989, grad/param norm = 3.5914e-01, time/batch = 16.7196s	
9548/11350 (epoch 42.062), train_loss = 0.46697533, grad/param norm = 3.4339e-01, time/batch = 16.9558s	
9549/11350 (epoch 42.066), train_loss = 0.47531426, grad/param norm = 3.8474e-01, time/batch = 16.7169s	
9550/11350 (epoch 42.070), train_loss = 0.54499786, grad/param norm = 3.4559e-01, time/batch = 16.4694s	
9551/11350 (epoch 42.075), train_loss = 0.46673561, grad/param norm = 2.6355e-01, time/batch = 17.1081s	
9552/11350 (epoch 42.079), train_loss = 0.57828684, grad/param norm = 3.2253e-01, time/batch = 16.7744s	
9553/11350 (epoch 42.084), train_loss = 0.66828786, grad/param norm = 3.5905e-01, time/batch = 16.5566s	
9554/11350 (epoch 42.088), train_loss = 0.62343823, grad/param norm = 3.2744e-01, time/batch = 16.7953s	
9555/11350 (epoch 42.093), train_loss = 0.61834352, grad/param norm = 3.4039e-01, time/batch = 16.9563s	
9556/11350 (epoch 42.097), train_loss = 0.54635884, grad/param norm = 2.9624e-01, time/batch = 16.6286s	
9557/11350 (epoch 42.101), train_loss = 0.51154689, grad/param norm = 3.1276e-01, time/batch = 16.7843s	
9558/11350 (epoch 42.106), train_loss = 0.59418590, grad/param norm = 4.2557e-01, time/batch = 16.8478s	
9559/11350 (epoch 42.110), train_loss = 0.53086949, grad/param norm = 3.4919e-01, time/batch = 16.5167s	
9560/11350 (epoch 42.115), train_loss = 0.54299793, grad/param norm = 3.5055e-01, time/batch = 16.3928s	
9561/11350 (epoch 42.119), train_loss = 0.64751754, grad/param norm = 3.7549e-01, time/batch = 16.6179s	
9562/11350 (epoch 42.123), train_loss = 0.53076863, grad/param norm = 4.0190e-01, time/batch = 16.4677s	
9563/11350 (epoch 42.128), train_loss = 0.46846997, grad/param norm = 3.7288e-01, time/batch = 17.1968s	
9564/11350 (epoch 42.132), train_loss = 0.50017212, grad/param norm = 2.8878e-01, time/batch = 17.7854s	
9565/11350 (epoch 42.137), train_loss = 0.48425128, grad/param norm = 3.9706e-01, time/batch = 16.3906s	
9566/11350 (epoch 42.141), train_loss = 0.65685883, grad/param norm = 4.2121e-01, time/batch = 17.0338s	
9567/11350 (epoch 42.145), train_loss = 0.54300314, grad/param norm = 3.1546e-01, time/batch = 16.9475s	
9568/11350 (epoch 42.150), train_loss = 0.58744363, grad/param norm = 5.3025e-01, time/batch = 16.7114s	
9569/11350 (epoch 42.154), train_loss = 0.67988209, grad/param norm = 3.9770e-01, time/batch = 17.0275s	
9570/11350 (epoch 42.159), train_loss = 0.49174895, grad/param norm = 3.6651e-01, time/batch = 17.1243s	
9571/11350 (epoch 42.163), train_loss = 0.60871518, grad/param norm = 3.5020e-01, time/batch = 16.7085s	
9572/11350 (epoch 42.167), train_loss = 0.65767223, grad/param norm = 3.9022e-01, time/batch = 16.7020s	
9573/11350 (epoch 42.172), train_loss = 0.72398725, grad/param norm = 3.1222e-01, time/batch = 16.7650s	
9574/11350 (epoch 42.176), train_loss = 0.57096084, grad/param norm = 3.1457e-01, time/batch = 16.2245s	
9575/11350 (epoch 42.181), train_loss = 0.55100182, grad/param norm = 3.4237e-01, time/batch = 16.7982s	
9576/11350 (epoch 42.185), train_loss = 0.50800302, grad/param norm = 3.1963e-01, time/batch = 16.8897s	
9577/11350 (epoch 42.189), train_loss = 0.51902425, grad/param norm = 2.9981e-01, time/batch = 16.7920s	
9578/11350 (epoch 42.194), train_loss = 0.46238969, grad/param norm = 3.1055e-01, time/batch = 17.1989s	
9579/11350 (epoch 42.198), train_loss = 0.43358610, grad/param norm = 4.3942e-01, time/batch = 16.9329s	
9580/11350 (epoch 42.203), train_loss = 0.50356102, grad/param norm = 3.1454e-01, time/batch = 16.6846s	
9581/11350 (epoch 42.207), train_loss = 0.46906341, grad/param norm = 3.9096e-01, time/batch = 16.6336s	
9582/11350 (epoch 42.211), train_loss = 0.62798620, grad/param norm = 3.8939e-01, time/batch = 16.5521s	
9583/11350 (epoch 42.216), train_loss = 0.58875653, grad/param norm = 3.4530e-01, time/batch = 16.3157s	
9584/11350 (epoch 42.220), train_loss = 0.61191736, grad/param norm = 4.1803e-01, time/batch = 16.5364s	
9585/11350 (epoch 42.225), train_loss = 0.54080815, grad/param norm = 3.1641e-01, time/batch = 16.4605s	
9586/11350 (epoch 42.229), train_loss = 0.58966322, grad/param norm = 3.6999e-01, time/batch = 16.4560s	
9587/11350 (epoch 42.233), train_loss = 0.55836613, grad/param norm = 4.7846e-01, time/batch = 16.8419s	
9588/11350 (epoch 42.238), train_loss = 0.66486945, grad/param norm = 4.8247e-01, time/batch = 16.6297s	
9589/11350 (epoch 42.242), train_loss = 0.67739530, grad/param norm = 4.9047e-01, time/batch = 17.0195s	
9590/11350 (epoch 42.247), train_loss = 0.50060668, grad/param norm = 3.1049e-01, time/batch = 16.3929s	
9591/11350 (epoch 42.251), train_loss = 0.53951364, grad/param norm = 2.9852e-01, time/batch = 17.1925s	
9592/11350 (epoch 42.256), train_loss = 0.59557620, grad/param norm = 3.1202e-01, time/batch = 16.7226s	
9593/11350 (epoch 42.260), train_loss = 0.52268279, grad/param norm = 3.0082e-01, time/batch = 16.3805s	
9594/11350 (epoch 42.264), train_loss = 0.50767150, grad/param norm = 3.4093e-01, time/batch = 16.2937s	
9595/11350 (epoch 42.269), train_loss = 0.55606779, grad/param norm = 2.8670e-01, time/batch = 16.5384s	
9596/11350 (epoch 42.273), train_loss = 0.62555220, grad/param norm = 2.9145e-01, time/batch = 17.3379s	
9597/11350 (epoch 42.278), train_loss = 0.53176588, grad/param norm = 3.0463e-01, time/batch = 16.9972s	
9598/11350 (epoch 42.282), train_loss = 0.52678452, grad/param norm = 2.9889e-01, time/batch = 16.6968s	
9599/11350 (epoch 42.286), train_loss = 0.62703153, grad/param norm = 3.4875e-01, time/batch = 16.4774s	
9600/11350 (epoch 42.291), train_loss = 0.52426671, grad/param norm = 3.8506e-01, time/batch = 16.8674s	
9601/11350 (epoch 42.295), train_loss = 0.51832509, grad/param norm = 3.5993e-01, time/batch = 16.3916s	
9602/11350 (epoch 42.300), train_loss = 0.61385046, grad/param norm = 3.2987e-01, time/batch = 16.2914s	
9603/11350 (epoch 42.304), train_loss = 0.49812122, grad/param norm = 3.3982e-01, time/batch = 16.3035s	
9604/11350 (epoch 42.308), train_loss = 0.50953286, grad/param norm = 4.4087e-01, time/batch = 16.5350s	
9605/11350 (epoch 42.313), train_loss = 0.55888335, grad/param norm = 3.0742e-01, time/batch = 16.9435s	
9606/11350 (epoch 42.317), train_loss = 0.55912940, grad/param norm = 2.7851e-01, time/batch = 16.6079s	
9607/11350 (epoch 42.322), train_loss = 0.54230601, grad/param norm = 4.3671e-01, time/batch = 16.7113s	
9608/11350 (epoch 42.326), train_loss = 0.57033436, grad/param norm = 3.5296e-01, time/batch = 16.6351s	
9609/11350 (epoch 42.330), train_loss = 0.47064928, grad/param norm = 2.6180e-01, time/batch = 16.8654s	
9610/11350 (epoch 42.335), train_loss = 0.37978210, grad/param norm = 2.7215e-01, time/batch = 17.0874s	
9611/11350 (epoch 42.339), train_loss = 0.40789572, grad/param norm = 3.0808e-01, time/batch = 16.7895s	
9612/11350 (epoch 42.344), train_loss = 0.49016784, grad/param norm = 2.6402e-01, time/batch = 16.3777s	
9613/11350 (epoch 42.348), train_loss = 0.52501083, grad/param norm = 2.8772e-01, time/batch = 16.2200s	
9614/11350 (epoch 42.352), train_loss = 0.41649822, grad/param norm = 2.2809e-01, time/batch = 16.2249s	
9615/11350 (epoch 42.357), train_loss = 0.51547740, grad/param norm = 2.8556e-01, time/batch = 16.2937s	
9616/11350 (epoch 42.361), train_loss = 0.41516369, grad/param norm = 2.2879e-01, time/batch = 16.3779s	
9617/11350 (epoch 42.366), train_loss = 0.51311313, grad/param norm = 3.7283e-01, time/batch = 16.4591s	
9618/11350 (epoch 42.370), train_loss = 0.45002890, grad/param norm = 3.4355e-01, time/batch = 16.3113s	
9619/11350 (epoch 42.374), train_loss = 0.50246136, grad/param norm = 3.0978e-01, time/batch = 16.3959s	
9620/11350 (epoch 42.379), train_loss = 0.49573528, grad/param norm = 3.3188e-01, time/batch = 16.5491s	
9621/11350 (epoch 42.383), train_loss = 0.46004036, grad/param norm = 3.8147e-01, time/batch = 16.3857s	
9622/11350 (epoch 42.388), train_loss = 0.51845299, grad/param norm = 3.9857e-01, time/batch = 16.9612s	
9623/11350 (epoch 42.392), train_loss = 0.60176242, grad/param norm = 3.7069e-01, time/batch = 16.9453s	
9624/11350 (epoch 42.396), train_loss = 0.50519545, grad/param norm = 3.7840e-01, time/batch = 16.3938s	
9625/11350 (epoch 42.401), train_loss = 0.51235013, grad/param norm = 3.7913e-01, time/batch = 16.9261s	
9626/11350 (epoch 42.405), train_loss = 0.66357391, grad/param norm = 5.5309e-01, time/batch = 17.2652s	
9627/11350 (epoch 42.410), train_loss = 0.72811185, grad/param norm = 5.4192e-01, time/batch = 16.5352s	
9628/11350 (epoch 42.414), train_loss = 0.47769616, grad/param norm = 4.0415e-01, time/batch = 16.6371s	
9629/11350 (epoch 42.419), train_loss = 0.46632427, grad/param norm = 2.9458e-01, time/batch = 16.5488s	
9630/11350 (epoch 42.423), train_loss = 0.48709209, grad/param norm = 3.7635e-01, time/batch = 16.6275s	
9631/11350 (epoch 42.427), train_loss = 0.55306802, grad/param norm = 3.1879e-01, time/batch = 16.5413s	
9632/11350 (epoch 42.432), train_loss = 0.55739779, grad/param norm = 3.5627e-01, time/batch = 16.7201s	
9633/11350 (epoch 42.436), train_loss = 0.46225116, grad/param norm = 3.1201e-01, time/batch = 16.3088s	
9634/11350 (epoch 42.441), train_loss = 0.61094122, grad/param norm = 3.6831e-01, time/batch = 16.9501s	
9635/11350 (epoch 42.445), train_loss = 0.48679103, grad/param norm = 2.7946e-01, time/batch = 16.4697s	
9636/11350 (epoch 42.449), train_loss = 0.56858809, grad/param norm = 4.1716e-01, time/batch = 16.3078s	
9637/11350 (epoch 42.454), train_loss = 0.64993995, grad/param norm = 4.0356e-01, time/batch = 16.1472s	
9638/11350 (epoch 42.458), train_loss = 0.47398246, grad/param norm = 3.0748e-01, time/batch = 16.4470s	
9639/11350 (epoch 42.463), train_loss = 0.47398599, grad/param norm = 3.0625e-01, time/batch = 16.4666s	
9640/11350 (epoch 42.467), train_loss = 0.71219090, grad/param norm = 3.9965e-01, time/batch = 16.2974s	
9641/11350 (epoch 42.471), train_loss = 0.67678297, grad/param norm = 5.0054e-01, time/batch = 17.0180s	
9642/11350 (epoch 42.476), train_loss = 0.59182741, grad/param norm = 3.3650e-01, time/batch = 16.6323s	
9643/11350 (epoch 42.480), train_loss = 0.63178256, grad/param norm = 3.8614e-01, time/batch = 16.5538s	
9644/11350 (epoch 42.485), train_loss = 0.56857907, grad/param norm = 3.0631e-01, time/batch = 17.5080s	
9645/11350 (epoch 42.489), train_loss = 0.63934677, grad/param norm = 4.6593e-01, time/batch = 17.1835s	
9646/11350 (epoch 42.493), train_loss = 0.67052500, grad/param norm = 3.9413e-01, time/batch = 16.6365s	
9647/11350 (epoch 42.498), train_loss = 0.42705052, grad/param norm = 2.8415e-01, time/batch = 16.4676s	
9648/11350 (epoch 42.502), train_loss = 0.67500438, grad/param norm = 3.3969e-01, time/batch = 16.7423s	
9649/11350 (epoch 42.507), train_loss = 0.50210475, grad/param norm = 4.4101e-01, time/batch = 16.3805s	
9650/11350 (epoch 42.511), train_loss = 0.61933884, grad/param norm = 3.8649e-01, time/batch = 16.8007s	
9651/11350 (epoch 42.515), train_loss = 0.57124100, grad/param norm = 3.4242e-01, time/batch = 16.4669s	
9652/11350 (epoch 42.520), train_loss = 0.71106374, grad/param norm = 3.6922e-01, time/batch = 16.6946s	
9653/11350 (epoch 42.524), train_loss = 0.61696720, grad/param norm = 3.8800e-01, time/batch = 16.4739s	
9654/11350 (epoch 42.529), train_loss = 0.54474448, grad/param norm = 4.4086e-01, time/batch = 16.7047s	
9655/11350 (epoch 42.533), train_loss = 0.71361847, grad/param norm = 3.9113e-01, time/batch = 16.4643s	
9656/11350 (epoch 42.537), train_loss = 0.65983744, grad/param norm = 3.3506e-01, time/batch = 16.7036s	
9657/11350 (epoch 42.542), train_loss = 0.54539627, grad/param norm = 2.5950e-01, time/batch = 16.3220s	
9658/11350 (epoch 42.546), train_loss = 0.72195124, grad/param norm = 4.5214e-01, time/batch = 16.6275s	
9659/11350 (epoch 42.551), train_loss = 0.61929977, grad/param norm = 3.9482e-01, time/batch = 16.6947s	
9660/11350 (epoch 42.555), train_loss = 0.51976455, grad/param norm = 2.8844e-01, time/batch = 16.6301s	
9661/11350 (epoch 42.559), train_loss = 0.57397960, grad/param norm = 2.9101e-01, time/batch = 16.5424s	
9662/11350 (epoch 42.564), train_loss = 0.63017049, grad/param norm = 4.6018e-01, time/batch = 16.7001s	
9663/11350 (epoch 42.568), train_loss = 0.61067533, grad/param norm = 3.1055e-01, time/batch = 17.2249s	
9664/11350 (epoch 42.573), train_loss = 0.72717652, grad/param norm = 4.2425e-01, time/batch = 16.3040s	
9665/11350 (epoch 42.577), train_loss = 0.65096544, grad/param norm = 4.2720e-01, time/batch = 16.3034s	
9666/11350 (epoch 42.581), train_loss = 0.72242683, grad/param norm = 3.4671e-01, time/batch = 16.4587s	
9667/11350 (epoch 42.586), train_loss = 0.66584976, grad/param norm = 3.9112e-01, time/batch = 16.3811s	
9668/11350 (epoch 42.590), train_loss = 0.69701969, grad/param norm = 4.0196e-01, time/batch = 16.6221s	
9669/11350 (epoch 42.595), train_loss = 0.79227894, grad/param norm = 4.0261e-01, time/batch = 16.3835s	
9670/11350 (epoch 42.599), train_loss = 0.62235749, grad/param norm = 3.7268e-01, time/batch = 17.0404s	
9671/11350 (epoch 42.604), train_loss = 0.60778167, grad/param norm = 3.1503e-01, time/batch = 16.5435s	
9672/11350 (epoch 42.608), train_loss = 0.57413284, grad/param norm = 3.4293e-01, time/batch = 16.8717s	
9673/11350 (epoch 42.612), train_loss = 0.60687161, grad/param norm = 3.0850e-01, time/batch = 16.7097s	
9674/11350 (epoch 42.617), train_loss = 0.69540170, grad/param norm = 3.3596e-01, time/batch = 16.3788s	
9675/11350 (epoch 42.621), train_loss = 0.70458860, grad/param norm = 3.1729e-01, time/batch = 16.7779s	
9676/11350 (epoch 42.626), train_loss = 0.61900162, grad/param norm = 3.1579e-01, time/batch = 16.9449s	
9677/11350 (epoch 42.630), train_loss = 0.63972242, grad/param norm = 3.5695e-01, time/batch = 17.0959s	
9678/11350 (epoch 42.634), train_loss = 0.60365874, grad/param norm = 3.3618e-01, time/batch = 16.4529s	
9679/11350 (epoch 42.639), train_loss = 0.57410340, grad/param norm = 3.1059e-01, time/batch = 16.6237s	
9680/11350 (epoch 42.643), train_loss = 0.51961267, grad/param norm = 3.1373e-01, time/batch = 16.5523s	
9681/11350 (epoch 42.648), train_loss = 0.59318653, grad/param norm = 3.1484e-01, time/batch = 17.2359s	
9682/11350 (epoch 42.652), train_loss = 0.52040981, grad/param norm = 3.0115e-01, time/batch = 16.5535s	
9683/11350 (epoch 42.656), train_loss = 0.63975193, grad/param norm = 3.1459e-01, time/batch = 16.5519s	
9684/11350 (epoch 42.661), train_loss = 0.63500825, grad/param norm = 3.7171e-01, time/batch = 16.4466s	
9685/11350 (epoch 42.665), train_loss = 0.64639302, grad/param norm = 3.8760e-01, time/batch = 16.6201s	
9686/11350 (epoch 42.670), train_loss = 0.64036698, grad/param norm = 3.3774e-01, time/batch = 17.0118s	
9687/11350 (epoch 42.674), train_loss = 0.59132947, grad/param norm = 3.0628e-01, time/batch = 16.6291s	
9688/11350 (epoch 42.678), train_loss = 0.63071357, grad/param norm = 2.9161e-01, time/batch = 16.8734s	
9689/11350 (epoch 42.683), train_loss = 0.58068269, grad/param norm = 3.9056e-01, time/batch = 16.4742s	
9690/11350 (epoch 42.687), train_loss = 0.51733517, grad/param norm = 2.9028e-01, time/batch = 16.3950s	
9691/11350 (epoch 42.692), train_loss = 0.77637010, grad/param norm = 4.0120e-01, time/batch = 16.6246s	
9692/11350 (epoch 42.696), train_loss = 0.76618904, grad/param norm = 3.2660e-01, time/batch = 16.3899s	
9693/11350 (epoch 42.700), train_loss = 0.69526488, grad/param norm = 3.8924e-01, time/batch = 16.2200s	
9694/11350 (epoch 42.705), train_loss = 0.70821006, grad/param norm = 3.6668e-01, time/batch = 16.6251s	
9695/11350 (epoch 42.709), train_loss = 0.69851069, grad/param norm = 3.6858e-01, time/batch = 15.5949s	
9696/11350 (epoch 42.714), train_loss = 0.62287884, grad/param norm = 3.3136e-01, time/batch = 0.7404s	
9697/11350 (epoch 42.718), train_loss = 0.53882130, grad/param norm = 2.8627e-01, time/batch = 0.7318s	
9698/11350 (epoch 42.722), train_loss = 0.61259235, grad/param norm = 3.4753e-01, time/batch = 0.7381s	
9699/11350 (epoch 42.727), train_loss = 0.65149199, grad/param norm = 3.4205e-01, time/batch = 0.7374s	
9700/11350 (epoch 42.731), train_loss = 0.59139142, grad/param norm = 3.1727e-01, time/batch = 0.7345s	
9701/11350 (epoch 42.736), train_loss = 0.56063479, grad/param norm = 4.5926e-01, time/batch = 0.7126s	
9702/11350 (epoch 42.740), train_loss = 0.61941811, grad/param norm = 3.6226e-01, time/batch = 0.8422s	
9703/11350 (epoch 42.744), train_loss = 0.61545071, grad/param norm = 4.5637e-01, time/batch = 1.0683s	
9704/11350 (epoch 42.749), train_loss = 0.60663935, grad/param norm = 3.9747e-01, time/batch = 1.0592s	
9705/11350 (epoch 42.753), train_loss = 0.65631464, grad/param norm = 4.2247e-01, time/batch = 1.0584s	
9706/11350 (epoch 42.758), train_loss = 0.60983077, grad/param norm = 3.5166e-01, time/batch = 1.0568s	
9707/11350 (epoch 42.762), train_loss = 0.73769146, grad/param norm = 4.0618e-01, time/batch = 1.6480s	
9708/11350 (epoch 42.767), train_loss = 0.72017575, grad/param norm = 3.0779e-01, time/batch = 2.0024s	
9709/11350 (epoch 42.771), train_loss = 0.79465597, grad/param norm = 3.6026e-01, time/batch = 3.9451s	
9710/11350 (epoch 42.775), train_loss = 0.64981789, grad/param norm = 3.2463e-01, time/batch = 16.3059s	
9711/11350 (epoch 42.780), train_loss = 0.68146832, grad/param norm = 3.5537e-01, time/batch = 16.5585s	
9712/11350 (epoch 42.784), train_loss = 0.62488257, grad/param norm = 3.2488e-01, time/batch = 17.0915s	
9713/11350 (epoch 42.789), train_loss = 0.64490892, grad/param norm = 3.6738e-01, time/batch = 16.4805s	
9714/11350 (epoch 42.793), train_loss = 0.69020070, grad/param norm = 3.8919e-01, time/batch = 16.7122s	
9715/11350 (epoch 42.797), train_loss = 0.64094561, grad/param norm = 3.0230e-01, time/batch = 16.7944s	
9716/11350 (epoch 42.802), train_loss = 0.65470358, grad/param norm = 3.4100e-01, time/batch = 16.1409s	
9717/11350 (epoch 42.806), train_loss = 0.68689249, grad/param norm = 3.5402e-01, time/batch = 16.5496s	
9718/11350 (epoch 42.811), train_loss = 0.63891766, grad/param norm = 3.1300e-01, time/batch = 16.7035s	
9719/11350 (epoch 42.815), train_loss = 0.63213796, grad/param norm = 3.3897e-01, time/batch = 17.0769s	
9720/11350 (epoch 42.819), train_loss = 0.54609336, grad/param norm = 2.9975e-01, time/batch = 16.1518s	
9721/11350 (epoch 42.824), train_loss = 0.57458476, grad/param norm = 3.4384e-01, time/batch = 16.6215s	
9722/11350 (epoch 42.828), train_loss = 0.57315387, grad/param norm = 3.4633e-01, time/batch = 16.7041s	
9723/11350 (epoch 42.833), train_loss = 0.59594173, grad/param norm = 2.8402e-01, time/batch = 16.7974s	
9724/11350 (epoch 42.837), train_loss = 0.63301418, grad/param norm = 3.6922e-01, time/batch = 16.3879s	
9725/11350 (epoch 42.841), train_loss = 0.83191838, grad/param norm = 3.7491e-01, time/batch = 16.5352s	
9726/11350 (epoch 42.846), train_loss = 0.69786604, grad/param norm = 4.3183e-01, time/batch = 16.9551s	
9727/11350 (epoch 42.850), train_loss = 0.69876633, grad/param norm = 3.2430e-01, time/batch = 16.2281s	
9728/11350 (epoch 42.855), train_loss = 0.53068172, grad/param norm = 2.9682e-01, time/batch = 16.4557s	
9729/11350 (epoch 42.859), train_loss = 0.57706159, grad/param norm = 3.9652e-01, time/batch = 16.5537s	
9730/11350 (epoch 42.863), train_loss = 0.55071808, grad/param norm = 3.3145e-01, time/batch = 16.8739s	
9731/11350 (epoch 42.868), train_loss = 0.55729611, grad/param norm = 2.9356e-01, time/batch = 16.4735s	
9732/11350 (epoch 42.872), train_loss = 0.56407461, grad/param norm = 3.0642e-01, time/batch = 16.7122s	
9733/11350 (epoch 42.877), train_loss = 0.56358770, grad/param norm = 3.2647e-01, time/batch = 16.3032s	
9734/11350 (epoch 42.881), train_loss = 0.76753075, grad/param norm = 3.7047e-01, time/batch = 16.7551s	
9735/11350 (epoch 42.885), train_loss = 0.70154578, grad/param norm = 3.5412e-01, time/batch = 16.5493s	
9736/11350 (epoch 42.890), train_loss = 0.65019858, grad/param norm = 3.5936e-01, time/batch = 16.6264s	
9737/11350 (epoch 42.894), train_loss = 0.56037258, grad/param norm = 3.6543e-01, time/batch = 16.4744s	
9738/11350 (epoch 42.899), train_loss = 0.67989921, grad/param norm = 3.5603e-01, time/batch = 16.7745s	
9739/11350 (epoch 42.903), train_loss = 0.66027740, grad/param norm = 4.1293e-01, time/batch = 17.1150s	
9740/11350 (epoch 42.907), train_loss = 0.58174154, grad/param norm = 4.2526e-01, time/batch = 16.6903s	
9741/11350 (epoch 42.912), train_loss = 0.57816702, grad/param norm = 3.2073e-01, time/batch = 16.8684s	
9742/11350 (epoch 42.916), train_loss = 0.61471691, grad/param norm = 3.3940e-01, time/batch = 16.7286s	
9743/11350 (epoch 42.921), train_loss = 0.62318601, grad/param norm = 3.1691e-01, time/batch = 16.6908s	
9744/11350 (epoch 42.925), train_loss = 0.53820148, grad/param norm = 2.8613e-01, time/batch = 24.5257s	
9745/11350 (epoch 42.930), train_loss = 0.61906727, grad/param norm = 3.4684e-01, time/batch = 24.4621s	
9746/11350 (epoch 42.934), train_loss = 0.71886239, grad/param norm = 3.7974e-01, time/batch = 16.6291s	
9747/11350 (epoch 42.938), train_loss = 0.64427427, grad/param norm = 3.9899e-01, time/batch = 16.7869s	
9748/11350 (epoch 42.943), train_loss = 0.67128860, grad/param norm = 3.5387e-01, time/batch = 16.7022s	
9749/11350 (epoch 42.947), train_loss = 0.64703032, grad/param norm = 3.5077e-01, time/batch = 16.7088s	
9750/11350 (epoch 42.952), train_loss = 0.65683480, grad/param norm = 3.9509e-01, time/batch = 16.7926s	
9751/11350 (epoch 42.956), train_loss = 0.54033788, grad/param norm = 2.9023e-01, time/batch = 16.7909s	
9752/11350 (epoch 42.960), train_loss = 0.60147945, grad/param norm = 3.5160e-01, time/batch = 16.3094s	
9753/11350 (epoch 42.965), train_loss = 0.51343730, grad/param norm = 3.3559e-01, time/batch = 16.2379s	
9754/11350 (epoch 42.969), train_loss = 0.52406683, grad/param norm = 3.4688e-01, time/batch = 17.0299s	
9755/11350 (epoch 42.974), train_loss = 0.50550968, grad/param norm = 3.0514e-01, time/batch = 16.7072s	
9756/11350 (epoch 42.978), train_loss = 0.59232243, grad/param norm = 3.1373e-01, time/batch = 17.1490s	
9757/11350 (epoch 42.982), train_loss = 0.41541177, grad/param norm = 3.1094e-01, time/batch = 16.6916s	
9758/11350 (epoch 42.987), train_loss = 0.62039979, grad/param norm = 3.3647e-01, time/batch = 16.6978s	
9759/11350 (epoch 42.991), train_loss = 0.51739005, grad/param norm = 2.9273e-01, time/batch = 16.6188s	
9760/11350 (epoch 42.996), train_loss = 0.57138970, grad/param norm = 3.2906e-01, time/batch = 17.0302s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
9761/11350 (epoch 43.000), train_loss = 0.46916578, grad/param norm = 3.0655e-01, time/batch = 16.9297s	
9762/11350 (epoch 43.004), train_loss = 0.65653523, grad/param norm = 3.7535e-01, time/batch = 16.9367s	
9763/11350 (epoch 43.009), train_loss = 0.61479160, grad/param norm = 2.8638e-01, time/batch = 16.7902s	
9764/11350 (epoch 43.013), train_loss = 0.43007196, grad/param norm = 2.7192e-01, time/batch = 16.8615s	
9765/11350 (epoch 43.018), train_loss = 0.48084669, grad/param norm = 3.2645e-01, time/batch = 16.7150s	
9766/11350 (epoch 43.022), train_loss = 0.52158596, grad/param norm = 3.8757e-01, time/batch = 16.5810s	
9767/11350 (epoch 43.026), train_loss = 0.49013618, grad/param norm = 3.5218e-01, time/batch = 16.2183s	
9768/11350 (epoch 43.031), train_loss = 0.49089616, grad/param norm = 2.9245e-01, time/batch = 16.6909s	
9769/11350 (epoch 43.035), train_loss = 0.53330055, grad/param norm = 3.2646e-01, time/batch = 16.2965s	
9770/11350 (epoch 43.040), train_loss = 0.54483489, grad/param norm = 3.5925e-01, time/batch = 16.8025s	
9771/11350 (epoch 43.044), train_loss = 0.49468743, grad/param norm = 2.4722e-01, time/batch = 16.5566s	
9772/11350 (epoch 43.048), train_loss = 0.48664374, grad/param norm = 2.7028e-01, time/batch = 16.8007s	
9773/11350 (epoch 43.053), train_loss = 0.53655849, grad/param norm = 2.7601e-01, time/batch = 16.7842s	
9774/11350 (epoch 43.057), train_loss = 0.52352091, grad/param norm = 3.8154e-01, time/batch = 16.2242s	
9775/11350 (epoch 43.062), train_loss = 0.44902333, grad/param norm = 2.9967e-01, time/batch = 16.4442s	
9776/11350 (epoch 43.066), train_loss = 0.48208296, grad/param norm = 3.6699e-01, time/batch = 16.8025s	
9777/11350 (epoch 43.070), train_loss = 0.53741100, grad/param norm = 3.7890e-01, time/batch = 16.2055s	
9778/11350 (epoch 43.075), train_loss = 0.48583235, grad/param norm = 3.5265e-01, time/batch = 16.7807s	
9779/11350 (epoch 43.079), train_loss = 0.57353106, grad/param norm = 3.4772e-01, time/batch = 17.2326s	
9780/11350 (epoch 43.084), train_loss = 0.65346528, grad/param norm = 3.8100e-01, time/batch = 16.4661s	
9781/11350 (epoch 43.088), train_loss = 0.60769708, grad/param norm = 3.9170e-01, time/batch = 16.4735s	
9782/11350 (epoch 43.093), train_loss = 0.60043146, grad/param norm = 2.9731e-01, time/batch = 16.6070s	
9783/11350 (epoch 43.097), train_loss = 0.53605233, grad/param norm = 3.8036e-01, time/batch = 16.5384s	
9784/11350 (epoch 43.101), train_loss = 0.51575226, grad/param norm = 3.8260e-01, time/batch = 16.7898s	
9785/11350 (epoch 43.106), train_loss = 0.59286538, grad/param norm = 3.6935e-01, time/batch = 17.1048s	
9786/11350 (epoch 43.110), train_loss = 0.51762151, grad/param norm = 3.0231e-01, time/batch = 16.4664s	
9787/11350 (epoch 43.115), train_loss = 0.54162796, grad/param norm = 3.5288e-01, time/batch = 16.3809s	
9788/11350 (epoch 43.119), train_loss = 0.63901986, grad/param norm = 4.8273e-01, time/batch = 16.5569s	
9789/11350 (epoch 43.123), train_loss = 0.51256363, grad/param norm = 3.5015e-01, time/batch = 16.5508s	
9790/11350 (epoch 43.128), train_loss = 0.46483672, grad/param norm = 3.5208e-01, time/batch = 16.9396s	
9791/11350 (epoch 43.132), train_loss = 0.50086307, grad/param norm = 2.8456e-01, time/batch = 17.5981s	
9792/11350 (epoch 43.137), train_loss = 0.47522315, grad/param norm = 3.4332e-01, time/batch = 16.8040s	
9793/11350 (epoch 43.141), train_loss = 0.64982075, grad/param norm = 4.8706e-01, time/batch = 16.9419s	
9794/11350 (epoch 43.145), train_loss = 0.56037982, grad/param norm = 4.1325e-01, time/batch = 16.4661s	
9795/11350 (epoch 43.150), train_loss = 0.57208798, grad/param norm = 4.2773e-01, time/batch = 17.1023s	
9796/11350 (epoch 43.154), train_loss = 0.68730120, grad/param norm = 4.7353e-01, time/batch = 17.1636s	
9797/11350 (epoch 43.159), train_loss = 0.46373283, grad/param norm = 2.8216e-01, time/batch = 17.2705s	
9798/11350 (epoch 43.163), train_loss = 0.59158017, grad/param norm = 3.5834e-01, time/batch = 16.7197s	
9799/11350 (epoch 43.167), train_loss = 0.62892858, grad/param norm = 3.2130e-01, time/batch = 16.5550s	
9800/11350 (epoch 43.172), train_loss = 0.73067753, grad/param norm = 3.6028e-01, time/batch = 16.6305s	
9801/11350 (epoch 43.176), train_loss = 0.56089828, grad/param norm = 3.2274e-01, time/batch = 16.6254s	
9802/11350 (epoch 43.181), train_loss = 0.54548984, grad/param norm = 3.8448e-01, time/batch = 16.0686s	
9803/11350 (epoch 43.185), train_loss = 0.51615932, grad/param norm = 3.0808e-01, time/batch = 16.2281s	
9804/11350 (epoch 43.189), train_loss = 0.50581538, grad/param norm = 3.3585e-01, time/batch = 16.8347s	
9805/11350 (epoch 43.194), train_loss = 0.45258025, grad/param norm = 3.0502e-01, time/batch = 16.7075s	
9806/11350 (epoch 43.198), train_loss = 0.43338060, grad/param norm = 4.4476e-01, time/batch = 16.5286s	
9807/11350 (epoch 43.203), train_loss = 0.50197089, grad/param norm = 3.4319e-01, time/batch = 16.4683s	
9808/11350 (epoch 43.207), train_loss = 0.47505814, grad/param norm = 3.4310e-01, time/batch = 16.2264s	
9809/11350 (epoch 43.211), train_loss = 0.61663023, grad/param norm = 4.3386e-01, time/batch = 16.3753s	
9810/11350 (epoch 43.216), train_loss = 0.59289255, grad/param norm = 3.4840e-01, time/batch = 16.3010s	
9811/11350 (epoch 43.220), train_loss = 0.59185744, grad/param norm = 3.2953e-01, time/batch = 16.7818s	
9812/11350 (epoch 43.225), train_loss = 0.53379368, grad/param norm = 2.8780e-01, time/batch = 16.6362s	
9813/11350 (epoch 43.229), train_loss = 0.57595554, grad/param norm = 3.9720e-01, time/batch = 16.3826s	
9814/11350 (epoch 43.233), train_loss = 0.54749736, grad/param norm = 3.8121e-01, time/batch = 16.5393s	
9815/11350 (epoch 43.238), train_loss = 0.61406450, grad/param norm = 3.8310e-01, time/batch = 17.0231s	
9816/11350 (epoch 43.242), train_loss = 0.63380941, grad/param norm = 3.4715e-01, time/batch = 16.8591s	
9817/11350 (epoch 43.247), train_loss = 0.48112632, grad/param norm = 2.8289e-01, time/batch = 16.3969s	
9818/11350 (epoch 43.251), train_loss = 0.52953027, grad/param norm = 4.7370e-01, time/batch = 16.6160s	
9819/11350 (epoch 43.256), train_loss = 0.59263598, grad/param norm = 3.8667e-01, time/batch = 16.5440s	
9820/11350 (epoch 43.260), train_loss = 0.51577850, grad/param norm = 3.1043e-01, time/batch = 16.7116s	
9821/11350 (epoch 43.264), train_loss = 0.48990026, grad/param norm = 3.4205e-01, time/batch = 17.0986s	
9822/11350 (epoch 43.269), train_loss = 0.55450136, grad/param norm = 3.0853e-01, time/batch = 17.0938s	
9823/11350 (epoch 43.273), train_loss = 0.63292819, grad/param norm = 3.2452e-01, time/batch = 16.4607s	
9824/11350 (epoch 43.278), train_loss = 0.53012657, grad/param norm = 3.2287e-01, time/batch = 16.3907s	
9825/11350 (epoch 43.282), train_loss = 0.51596528, grad/param norm = 3.3760e-01, time/batch = 16.4487s	
9826/11350 (epoch 43.286), train_loss = 0.61763143, grad/param norm = 3.4501e-01, time/batch = 16.3866s	
9827/11350 (epoch 43.291), train_loss = 0.51367103, grad/param norm = 3.8037e-01, time/batch = 16.1328s	
9828/11350 (epoch 43.295), train_loss = 0.53917423, grad/param norm = 4.0103e-01, time/batch = 16.3063s	
9829/11350 (epoch 43.300), train_loss = 0.62106167, grad/param norm = 3.8090e-01, time/batch = 16.9218s	
9830/11350 (epoch 43.304), train_loss = 0.49656140, grad/param norm = 3.4806e-01, time/batch = 16.3863s	
9831/11350 (epoch 43.308), train_loss = 0.50132424, grad/param norm = 3.8206e-01, time/batch = 16.3092s	
9832/11350 (epoch 43.313), train_loss = 0.55969708, grad/param norm = 3.0640e-01, time/batch = 17.0367s	
9833/11350 (epoch 43.317), train_loss = 0.54758139, grad/param norm = 3.2022e-01, time/batch = 16.8660s	
9834/11350 (epoch 43.322), train_loss = 0.53045958, grad/param norm = 3.5536e-01, time/batch = 16.1370s	
9835/11350 (epoch 43.326), train_loss = 0.54654626, grad/param norm = 3.7809e-01, time/batch = 16.3841s	
9836/11350 (epoch 43.330), train_loss = 0.45478545, grad/param norm = 2.5482e-01, time/batch = 16.8627s	
9837/11350 (epoch 43.335), train_loss = 0.37243113, grad/param norm = 3.0214e-01, time/batch = 16.7906s	
9838/11350 (epoch 43.339), train_loss = 0.40098854, grad/param norm = 3.1443e-01, time/batch = 16.6303s	
9839/11350 (epoch 43.344), train_loss = 0.48017920, grad/param norm = 2.9826e-01, time/batch = 16.3145s	
9840/11350 (epoch 43.348), train_loss = 0.50426116, grad/param norm = 2.5951e-01, time/batch = 16.7554s	
9841/11350 (epoch 43.352), train_loss = 0.40828833, grad/param norm = 2.4518e-01, time/batch = 16.1579s	
9842/11350 (epoch 43.357), train_loss = 0.48737237, grad/param norm = 2.4791e-01, time/batch = 16.4568s	
9843/11350 (epoch 43.361), train_loss = 0.42033916, grad/param norm = 2.3192e-01, time/batch = 16.5493s	
9844/11350 (epoch 43.366), train_loss = 0.51216938, grad/param norm = 3.9333e-01, time/batch = 16.7043s	
9845/11350 (epoch 43.370), train_loss = 0.43492570, grad/param norm = 3.7413e-01, time/batch = 16.0753s	
9846/11350 (epoch 43.374), train_loss = 0.49169503, grad/param norm = 3.6292e-01, time/batch = 16.2237s	
9847/11350 (epoch 43.379), train_loss = 0.49990454, grad/param norm = 3.5663e-01, time/batch = 16.6252s	
9848/11350 (epoch 43.383), train_loss = 0.43040327, grad/param norm = 2.7306e-01, time/batch = 17.0434s	
9849/11350 (epoch 43.388), train_loss = 0.50245109, grad/param norm = 4.2163e-01, time/batch = 16.2282s	
9850/11350 (epoch 43.392), train_loss = 0.55793865, grad/param norm = 3.1147e-01, time/batch = 16.7850s	
9851/11350 (epoch 43.396), train_loss = 0.47733554, grad/param norm = 3.4771e-01, time/batch = 17.2590s	
9852/11350 (epoch 43.401), train_loss = 0.48690155, grad/param norm = 3.5778e-01, time/batch = 16.6189s	
9853/11350 (epoch 43.405), train_loss = 0.66113444, grad/param norm = 3.8620e-01, time/batch = 16.0665s	
9854/11350 (epoch 43.410), train_loss = 0.67788180, grad/param norm = 3.9339e-01, time/batch = 17.0068s	
9855/11350 (epoch 43.414), train_loss = 0.47262120, grad/param norm = 4.0758e-01, time/batch = 16.6270s	
9856/11350 (epoch 43.419), train_loss = 0.45132450, grad/param norm = 2.9632e-01, time/batch = 16.5565s	
9857/11350 (epoch 43.423), train_loss = 0.47363633, grad/param norm = 3.3284e-01, time/batch = 16.5184s	
9858/11350 (epoch 43.427), train_loss = 0.54912159, grad/param norm = 3.6641e-01, time/batch = 16.8605s	
9859/11350 (epoch 43.432), train_loss = 0.52333301, grad/param norm = 2.8362e-01, time/batch = 16.2239s	
9860/11350 (epoch 43.436), train_loss = 0.43659914, grad/param norm = 3.3710e-01, time/batch = 16.5579s	
9861/11350 (epoch 43.441), train_loss = 0.59400628, grad/param norm = 3.4578e-01, time/batch = 16.7156s	
9862/11350 (epoch 43.445), train_loss = 0.46768491, grad/param norm = 2.8247e-01, time/batch = 16.5426s	
9863/11350 (epoch 43.449), train_loss = 0.56507199, grad/param norm = 3.1165e-01, time/batch = 16.2256s	
9864/11350 (epoch 43.454), train_loss = 0.63894196, grad/param norm = 3.5274e-01, time/batch = 16.3014s	
9865/11350 (epoch 43.458), train_loss = 0.45810454, grad/param norm = 3.0157e-01, time/batch = 16.6204s	
9866/11350 (epoch 43.463), train_loss = 0.46935477, grad/param norm = 3.3347e-01, time/batch = 16.6221s	
9867/11350 (epoch 43.467), train_loss = 0.69427719, grad/param norm = 3.8301e-01, time/batch = 16.1557s	
9868/11350 (epoch 43.471), train_loss = 0.66052035, grad/param norm = 4.2680e-01, time/batch = 17.1958s	
9869/11350 (epoch 43.476), train_loss = 0.56084049, grad/param norm = 3.2366e-01, time/batch = 16.8499s	
9870/11350 (epoch 43.480), train_loss = 0.61156877, grad/param norm = 3.0514e-01, time/batch = 16.7111s	
9871/11350 (epoch 43.485), train_loss = 0.56336043, grad/param norm = 3.1369e-01, time/batch = 16.4764s	
9872/11350 (epoch 43.489), train_loss = 0.60189010, grad/param norm = 3.3866e-01, time/batch = 16.9363s	
9873/11350 (epoch 43.493), train_loss = 0.63049597, grad/param norm = 3.3244e-01, time/batch = 16.6371s	
9874/11350 (epoch 43.498), train_loss = 0.43361202, grad/param norm = 4.3899e-01, time/batch = 17.4144s	
9875/11350 (epoch 43.502), train_loss = 0.66333951, grad/param norm = 3.5919e-01, time/batch = 16.5479s	
9876/11350 (epoch 43.507), train_loss = 0.48296651, grad/param norm = 2.8866e-01, time/batch = 16.7143s	
9877/11350 (epoch 43.511), train_loss = 0.58908434, grad/param norm = 3.2411e-01, time/batch = 16.5513s	
9878/11350 (epoch 43.515), train_loss = 0.56864470, grad/param norm = 3.3981e-01, time/batch = 16.3114s	
9879/11350 (epoch 43.520), train_loss = 0.70425713, grad/param norm = 3.5776e-01, time/batch = 16.7830s	
9880/11350 (epoch 43.524), train_loss = 0.59586822, grad/param norm = 3.1675e-01, time/batch = 16.7113s	
9881/11350 (epoch 43.529), train_loss = 0.50981697, grad/param norm = 2.9989e-01, time/batch = 16.6320s	
9882/11350 (epoch 43.533), train_loss = 0.70630090, grad/param norm = 3.4219e-01, time/batch = 16.3938s	
9883/11350 (epoch 43.537), train_loss = 0.66464104, grad/param norm = 4.0260e-01, time/batch = 17.3283s	
9884/11350 (epoch 43.542), train_loss = 0.55314868, grad/param norm = 3.2526e-01, time/batch = 16.4814s	
9885/11350 (epoch 43.546), train_loss = 0.72627388, grad/param norm = 5.0198e-01, time/batch = 16.4751s	
9886/11350 (epoch 43.551), train_loss = 0.61643826, grad/param norm = 4.3997e-01, time/batch = 17.1076s	
9887/11350 (epoch 43.555), train_loss = 0.50500202, grad/param norm = 2.9028e-01, time/batch = 16.6385s	
9888/11350 (epoch 43.559), train_loss = 0.56620156, grad/param norm = 2.9382e-01, time/batch = 16.6175s	
9889/11350 (epoch 43.564), train_loss = 0.59914123, grad/param norm = 3.4286e-01, time/batch = 16.6298s	
9890/11350 (epoch 43.568), train_loss = 0.59870958, grad/param norm = 3.3475e-01, time/batch = 16.7049s	
9891/11350 (epoch 43.573), train_loss = 0.69990461, grad/param norm = 3.5615e-01, time/batch = 16.1405s	
9892/11350 (epoch 43.577), train_loss = 0.61662793, grad/param norm = 3.4670e-01, time/batch = 16.7213s	
9893/11350 (epoch 43.581), train_loss = 0.71045507, grad/param norm = 3.6343e-01, time/batch = 16.4046s	
9894/11350 (epoch 43.586), train_loss = 0.65081801, grad/param norm = 3.5343e-01, time/batch = 16.8582s	
9895/11350 (epoch 43.590), train_loss = 0.69582417, grad/param norm = 5.1399e-01, time/batch = 16.3185s	
9896/11350 (epoch 43.595), train_loss = 0.77013117, grad/param norm = 3.4901e-01, time/batch = 17.2378s	
9897/11350 (epoch 43.599), train_loss = 0.60151201, grad/param norm = 3.4358e-01, time/batch = 16.7033s	
9898/11350 (epoch 43.604), train_loss = 0.60817136, grad/param norm = 4.0667e-01, time/batch = 16.6340s	
9899/11350 (epoch 43.608), train_loss = 0.57308295, grad/param norm = 4.1801e-01, time/batch = 16.6365s	
9900/11350 (epoch 43.612), train_loss = 0.60492785, grad/param norm = 3.3737e-01, time/batch = 16.2157s	
9901/11350 (epoch 43.617), train_loss = 0.68123875, grad/param norm = 3.6564e-01, time/batch = 16.9516s	
9902/11350 (epoch 43.621), train_loss = 0.67000968, grad/param norm = 3.1419e-01, time/batch = 16.7834s	
9903/11350 (epoch 43.626), train_loss = 0.60447945, grad/param norm = 3.1461e-01, time/batch = 16.4646s	
9904/11350 (epoch 43.630), train_loss = 0.61605383, grad/param norm = 4.5491e-01, time/batch = 17.0909s	
9905/11350 (epoch 43.634), train_loss = 0.60554935, grad/param norm = 4.2887e-01, time/batch = 16.8683s	
9906/11350 (epoch 43.639), train_loss = 0.56381885, grad/param norm = 2.9326e-01, time/batch = 16.1492s	
9907/11350 (epoch 43.643), train_loss = 0.50012893, grad/param norm = 3.1748e-01, time/batch = 16.3106s	
9908/11350 (epoch 43.648), train_loss = 0.58177570, grad/param norm = 3.7567e-01, time/batch = 16.4629s	
9909/11350 (epoch 43.652), train_loss = 0.52763074, grad/param norm = 3.5286e-01, time/batch = 16.6698s	
9910/11350 (epoch 43.656), train_loss = 0.63684126, grad/param norm = 3.4075e-01, time/batch = 16.0592s	
9911/11350 (epoch 43.661), train_loss = 0.60009379, grad/param norm = 3.4248e-01, time/batch = 16.6237s	
9912/11350 (epoch 43.665), train_loss = 0.62650888, grad/param norm = 3.8696e-01, time/batch = 16.6862s	
9913/11350 (epoch 43.670), train_loss = 0.62873465, grad/param norm = 3.2980e-01, time/batch = 16.7156s	
9914/11350 (epoch 43.674), train_loss = 0.58490971, grad/param norm = 3.1326e-01, time/batch = 16.2311s	
9915/11350 (epoch 43.678), train_loss = 0.63472156, grad/param norm = 3.1054e-01, time/batch = 16.7092s	
9916/11350 (epoch 43.683), train_loss = 0.58388954, grad/param norm = 3.7967e-01, time/batch = 16.3773s	
9917/11350 (epoch 43.687), train_loss = 0.50553538, grad/param norm = 3.0929e-01, time/batch = 16.0582s	
9918/11350 (epoch 43.692), train_loss = 0.75770346, grad/param norm = 3.9506e-01, time/batch = 16.3078s	
9919/11350 (epoch 43.696), train_loss = 0.76819285, grad/param norm = 3.6941e-01, time/batch = 16.8556s	
9920/11350 (epoch 43.700), train_loss = 0.67752011, grad/param norm = 3.7584e-01, time/batch = 16.5435s	
9921/11350 (epoch 43.705), train_loss = 0.70620078, grad/param norm = 3.7144e-01, time/batch = 16.4720s	
9922/11350 (epoch 43.709), train_loss = 0.69523671, grad/param norm = 3.5870e-01, time/batch = 16.6793s	
9923/11350 (epoch 43.714), train_loss = 0.61644102, grad/param norm = 3.6794e-01, time/batch = 16.1382s	
9924/11350 (epoch 43.718), train_loss = 0.53135180, grad/param norm = 3.0646e-01, time/batch = 16.4683s	
9925/11350 (epoch 43.722), train_loss = 0.60490928, grad/param norm = 4.0051e-01, time/batch = 16.4717s	
9926/11350 (epoch 43.727), train_loss = 0.63702692, grad/param norm = 3.6080e-01, time/batch = 16.8690s	
9927/11350 (epoch 43.731), train_loss = 0.56604191, grad/param norm = 2.9139e-01, time/batch = 16.7229s	
9928/11350 (epoch 43.736), train_loss = 0.55720810, grad/param norm = 4.2859e-01, time/batch = 16.3937s	
9929/11350 (epoch 43.740), train_loss = 0.59292322, grad/param norm = 3.5413e-01, time/batch = 16.4709s	
9930/11350 (epoch 43.744), train_loss = 0.59396501, grad/param norm = 4.1628e-01, time/batch = 16.4584s	
9931/11350 (epoch 43.749), train_loss = 0.58920470, grad/param norm = 3.3781e-01, time/batch = 16.1431s	
9932/11350 (epoch 43.753), train_loss = 0.65917964, grad/param norm = 5.2727e-01, time/batch = 16.3926s	
9933/11350 (epoch 43.758), train_loss = 0.58598637, grad/param norm = 3.6537e-01, time/batch = 16.5291s	
9934/11350 (epoch 43.762), train_loss = 0.70668918, grad/param norm = 3.0951e-01, time/batch = 16.8377s	
9935/11350 (epoch 43.767), train_loss = 0.70876687, grad/param norm = 3.0733e-01, time/batch = 16.6951s	
9936/11350 (epoch 43.771), train_loss = 0.80154499, grad/param norm = 3.8340e-01, time/batch = 16.3063s	
9937/11350 (epoch 43.775), train_loss = 0.63087364, grad/param norm = 3.3697e-01, time/batch = 17.1243s	
9938/11350 (epoch 43.780), train_loss = 0.69702273, grad/param norm = 4.1353e-01, time/batch = 16.6341s	
9939/11350 (epoch 43.784), train_loss = 0.61815442, grad/param norm = 3.6076e-01, time/batch = 16.3755s	
9940/11350 (epoch 43.789), train_loss = 0.65591138, grad/param norm = 3.8649e-01, time/batch = 16.7756s	
9941/11350 (epoch 43.793), train_loss = 0.68183565, grad/param norm = 3.4949e-01, time/batch = 16.6984s	
9942/11350 (epoch 43.797), train_loss = 0.62758008, grad/param norm = 3.1750e-01, time/batch = 16.1471s	
9943/11350 (epoch 43.802), train_loss = 0.64363952, grad/param norm = 3.5246e-01, time/batch = 16.4689s	
9944/11350 (epoch 43.806), train_loss = 0.65489700, grad/param norm = 3.1035e-01, time/batch = 16.8733s	
9945/11350 (epoch 43.811), train_loss = 0.63349530, grad/param norm = 2.9350e-01, time/batch = 16.4752s	
9946/11350 (epoch 43.815), train_loss = 0.62119680, grad/param norm = 3.4984e-01, time/batch = 16.6168s	
9947/11350 (epoch 43.819), train_loss = 0.55662417, grad/param norm = 3.4150e-01, time/batch = 16.1437s	
9948/11350 (epoch 43.824), train_loss = 0.54572573, grad/param norm = 3.0615e-01, time/batch = 17.0860s	
9949/11350 (epoch 43.828), train_loss = 0.55836077, grad/param norm = 3.3261e-01, time/batch = 16.4772s	
9950/11350 (epoch 43.833), train_loss = 0.59513808, grad/param norm = 3.6979e-01, time/batch = 16.3999s	
9951/11350 (epoch 43.837), train_loss = 0.62273169, grad/param norm = 3.9513e-01, time/batch = 16.8672s	
9952/11350 (epoch 43.841), train_loss = 0.82218578, grad/param norm = 4.1948e-01, time/batch = 16.2278s	
9953/11350 (epoch 43.846), train_loss = 0.70494948, grad/param norm = 3.2652e-01, time/batch = 16.3984s	
9954/11350 (epoch 43.850), train_loss = 0.69201130, grad/param norm = 3.7044e-01, time/batch = 16.3068s	
9955/11350 (epoch 43.855), train_loss = 0.51092024, grad/param norm = 2.8288e-01, time/batch = 17.1976s	
9956/11350 (epoch 43.859), train_loss = 0.56665167, grad/param norm = 4.1460e-01, time/batch = 16.5498s	
9957/11350 (epoch 43.863), train_loss = 0.55330453, grad/param norm = 3.4316e-01, time/batch = 16.5570s	
9958/11350 (epoch 43.868), train_loss = 0.54850299, grad/param norm = 2.8429e-01, time/batch = 19.2035s	
9959/11350 (epoch 43.872), train_loss = 0.56783140, grad/param norm = 3.3759e-01, time/batch = 29.6628s	
9960/11350 (epoch 43.877), train_loss = 0.56690593, grad/param norm = 4.1714e-01, time/batch = 16.3865s	
9961/11350 (epoch 43.881), train_loss = 0.75940749, grad/param norm = 4.3339e-01, time/batch = 16.5503s	
9962/11350 (epoch 43.885), train_loss = 0.68077433, grad/param norm = 3.0276e-01, time/batch = 16.1491s	
9963/11350 (epoch 43.890), train_loss = 0.66446674, grad/param norm = 4.4951e-01, time/batch = 16.5520s	
9964/11350 (epoch 43.894), train_loss = 0.53561106, grad/param norm = 2.8649e-01, time/batch = 16.3020s	
9965/11350 (epoch 43.899), train_loss = 0.66555312, grad/param norm = 3.2444e-01, time/batch = 16.7884s	
9966/11350 (epoch 43.903), train_loss = 0.63889989, grad/param norm = 3.5533e-01, time/batch = 16.4727s	
9967/11350 (epoch 43.907), train_loss = 0.56626491, grad/param norm = 3.4614e-01, time/batch = 17.1888s	
9968/11350 (epoch 43.912), train_loss = 0.57658187, grad/param norm = 3.5744e-01, time/batch = 16.5944s	
9969/11350 (epoch 43.916), train_loss = 0.65150747, grad/param norm = 4.2070e-01, time/batch = 16.4760s	
9970/11350 (epoch 43.921), train_loss = 0.63809192, grad/param norm = 3.3046e-01, time/batch = 16.6040s	
9971/11350 (epoch 43.925), train_loss = 0.54816200, grad/param norm = 3.4271e-01, time/batch = 16.7155s	
9972/11350 (epoch 43.930), train_loss = 0.62525904, grad/param norm = 4.4392e-01, time/batch = 16.6962s	
9973/11350 (epoch 43.934), train_loss = 0.71596362, grad/param norm = 4.2654e-01, time/batch = 16.7082s	
9974/11350 (epoch 43.938), train_loss = 0.62032510, grad/param norm = 3.6155e-01, time/batch = 16.3869s	
9975/11350 (epoch 43.943), train_loss = 0.66700184, grad/param norm = 3.6169e-01, time/batch = 17.1056s	
9976/11350 (epoch 43.947), train_loss = 0.63722295, grad/param norm = 3.3943e-01, time/batch = 16.9318s	
9977/11350 (epoch 43.952), train_loss = 0.66244431, grad/param norm = 4.6438e-01, time/batch = 17.7986s	
9978/11350 (epoch 43.956), train_loss = 0.52666858, grad/param norm = 2.7472e-01, time/batch = 16.9794s	
9979/11350 (epoch 43.960), train_loss = 0.59716358, grad/param norm = 4.0220e-01, time/batch = 17.2787s	
9980/11350 (epoch 43.965), train_loss = 0.50766785, grad/param norm = 3.2655e-01, time/batch = 16.2220s	
9981/11350 (epoch 43.969), train_loss = 0.50518956, grad/param norm = 3.3630e-01, time/batch = 16.1325s	
9982/11350 (epoch 43.974), train_loss = 0.51751100, grad/param norm = 3.3720e-01, time/batch = 16.5471s	
9983/11350 (epoch 43.978), train_loss = 0.59779793, grad/param norm = 3.8529e-01, time/batch = 16.8660s	
9984/11350 (epoch 43.982), train_loss = 0.42179892, grad/param norm = 5.8930e-01, time/batch = 16.7195s	
9985/11350 (epoch 43.987), train_loss = 0.58818389, grad/param norm = 3.2116e-01, time/batch = 16.6210s	
9986/11350 (epoch 43.991), train_loss = 0.52666027, grad/param norm = 3.6341e-01, time/batch = 16.7025s	
9987/11350 (epoch 43.996), train_loss = 0.56854522, grad/param norm = 4.1723e-01, time/batch = 16.5314s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
9988/11350 (epoch 44.000), train_loss = 0.45677057, grad/param norm = 2.9341e-01, time/batch = 16.6262s	
9989/11350 (epoch 44.004), train_loss = 0.66913094, grad/param norm = 3.4793e-01, time/batch = 16.3071s	
9990/11350 (epoch 44.009), train_loss = 0.60874124, grad/param norm = 2.9134e-01, time/batch = 16.2967s	
9991/11350 (epoch 44.013), train_loss = 0.42369345, grad/param norm = 3.1174e-01, time/batch = 16.3077s	
9992/11350 (epoch 44.018), train_loss = 0.48001199, grad/param norm = 3.1744e-01, time/batch = 16.5403s	
9993/11350 (epoch 44.022), train_loss = 0.49593025, grad/param norm = 3.5511e-01, time/batch = 17.3054s	
9994/11350 (epoch 44.026), train_loss = 0.48288688, grad/param norm = 3.6929e-01, time/batch = 16.2037s	
9995/11350 (epoch 44.031), train_loss = 0.48621569, grad/param norm = 3.0432e-01, time/batch = 16.1471s	
9996/11350 (epoch 44.035), train_loss = 0.52236671, grad/param norm = 4.4521e-01, time/batch = 16.2964s	
9997/11350 (epoch 44.040), train_loss = 0.53138209, grad/param norm = 2.7460e-01, time/batch = 16.6143s	
9998/11350 (epoch 44.044), train_loss = 0.48051846, grad/param norm = 2.7196e-01, time/batch = 16.5240s	
9999/11350 (epoch 44.048), train_loss = 0.48087417, grad/param norm = 2.7783e-01, time/batch = 16.3826s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch44.05_2.1672.t7	
10000/11350 (epoch 44.053), train_loss = 0.53235507, grad/param norm = 3.2908e-01, time/batch = 16.1417s	
10001/11350 (epoch 44.057), train_loss = 1.60349235, grad/param norm = 8.4751e-01, time/batch = 17.0383s	
10002/11350 (epoch 44.062), train_loss = 0.48841434, grad/param norm = 4.0637e-01, time/batch = 16.3785s	
10003/11350 (epoch 44.066), train_loss = 0.48737758, grad/param norm = 4.7382e-01, time/batch = 16.8786s	
10004/11350 (epoch 44.070), train_loss = 0.54064050, grad/param norm = 3.8927e-01, time/batch = 16.0573s	
10005/11350 (epoch 44.075), train_loss = 0.46728536, grad/param norm = 2.8857e-01, time/batch = 16.5393s	
10006/11350 (epoch 44.079), train_loss = 0.59451956, grad/param norm = 4.3396e-01, time/batch = 16.5341s	
10007/11350 (epoch 44.084), train_loss = 0.66330602, grad/param norm = 4.1212e-01, time/batch = 16.3162s	
10008/11350 (epoch 44.088), train_loss = 0.62117913, grad/param norm = 4.1558e-01, time/batch = 17.1721s	
10009/11350 (epoch 44.093), train_loss = 0.59862924, grad/param norm = 3.2503e-01, time/batch = 16.7829s	
10010/11350 (epoch 44.097), train_loss = 0.52429775, grad/param norm = 4.8782e-01, time/batch = 16.9677s	
10011/11350 (epoch 44.101), train_loss = 0.51782238, grad/param norm = 3.5827e-01, time/batch = 16.7141s	
10012/11350 (epoch 44.106), train_loss = 0.56929590, grad/param norm = 3.5683e-01, time/batch = 16.8659s	
10013/11350 (epoch 44.110), train_loss = 0.52915179, grad/param norm = 4.1581e-01, time/batch = 16.3966s	
10014/11350 (epoch 44.115), train_loss = 0.53970692, grad/param norm = 3.7469e-01, time/batch = 16.9562s	
10015/11350 (epoch 44.119), train_loss = 0.62798801, grad/param norm = 3.3623e-01, time/batch = 16.8336s	
10016/11350 (epoch 44.123), train_loss = 0.48730996, grad/param norm = 3.2544e-01, time/batch = 16.2122s	
10017/11350 (epoch 44.128), train_loss = 0.44920603, grad/param norm = 2.9285e-01, time/batch = 17.0884s	
10018/11350 (epoch 44.132), train_loss = 0.50605233, grad/param norm = 3.6817e-01, time/batch = 16.3832s	
10019/11350 (epoch 44.137), train_loss = 0.45444767, grad/param norm = 3.2969e-01, time/batch = 16.7066s	
10020/11350 (epoch 44.141), train_loss = 0.60598783, grad/param norm = 3.5931e-01, time/batch = 16.4605s	
10021/11350 (epoch 44.145), train_loss = 0.54051485, grad/param norm = 3.6957e-01, time/batch = 16.4633s	
10022/11350 (epoch 44.150), train_loss = 0.56748145, grad/param norm = 4.4706e-01, time/batch = 16.2287s	
10023/11350 (epoch 44.154), train_loss = 0.66213845, grad/param norm = 3.8922e-01, time/batch = 16.7801s	
10024/11350 (epoch 44.159), train_loss = 0.46783569, grad/param norm = 3.1761e-01, time/batch = 16.7204s	
10025/11350 (epoch 44.163), train_loss = 0.59745786, grad/param norm = 4.5978e-01, time/batch = 16.5389s	
10026/11350 (epoch 44.167), train_loss = 0.63722890, grad/param norm = 4.7130e-01, time/batch = 17.0100s	
10027/11350 (epoch 44.172), train_loss = 0.71253095, grad/param norm = 3.3017e-01, time/batch = 16.5390s	
10028/11350 (epoch 44.176), train_loss = 0.56315997, grad/param norm = 3.5098e-01, time/batch = 16.8609s	
10029/11350 (epoch 44.181), train_loss = 0.53012802, grad/param norm = 3.6975e-01, time/batch = 16.5568s	
10030/11350 (epoch 44.185), train_loss = 0.50219316, grad/param norm = 3.3926e-01, time/batch = 16.7844s	
10031/11350 (epoch 44.189), train_loss = 0.48884938, grad/param norm = 2.9439e-01, time/batch = 16.7891s	
10032/11350 (epoch 44.194), train_loss = 0.45237556, grad/param norm = 3.7951e-01, time/batch = 16.3958s	
10033/11350 (epoch 44.198), train_loss = 0.41704218, grad/param norm = 3.6817e-01, time/batch = 17.0318s	
10034/11350 (epoch 44.203), train_loss = 0.53181178, grad/param norm = 7.1189e-01, time/batch = 16.4765s	
10035/11350 (epoch 44.207), train_loss = 0.46472442, grad/param norm = 4.0470e-01, time/batch = 16.2303s	
10036/11350 (epoch 44.211), train_loss = 0.62776741, grad/param norm = 4.1790e-01, time/batch = 16.4593s	
10037/11350 (epoch 44.216), train_loss = 0.58003751, grad/param norm = 3.7277e-01, time/batch = 16.6227s	
10038/11350 (epoch 44.220), train_loss = 0.61159508, grad/param norm = 4.0784e-01, time/batch = 16.3147s	
10039/11350 (epoch 44.225), train_loss = 0.51947970, grad/param norm = 2.7448e-01, time/batch = 16.5437s	
10040/11350 (epoch 44.229), train_loss = 0.56635546, grad/param norm = 3.3323e-01, time/batch = 16.4683s	
10041/11350 (epoch 44.233), train_loss = 0.53409655, grad/param norm = 4.2231e-01, time/batch = 17.3414s	
10042/11350 (epoch 44.238), train_loss = 0.63083431, grad/param norm = 4.6639e-01, time/batch = 16.6162s	
10043/11350 (epoch 44.242), train_loss = 0.63849902, grad/param norm = 3.8165e-01, time/batch = 16.3875s	
10044/11350 (epoch 44.247), train_loss = 0.45291155, grad/param norm = 2.8240e-01, time/batch = 16.8496s	
10045/11350 (epoch 44.251), train_loss = 0.52972648, grad/param norm = 3.5048e-01, time/batch = 16.6301s	
10046/11350 (epoch 44.256), train_loss = 0.59685064, grad/param norm = 3.3770e-01, time/batch = 16.3689s	
10047/11350 (epoch 44.260), train_loss = 0.51237688, grad/param norm = 2.8665e-01, time/batch = 16.1516s	
10048/11350 (epoch 44.264), train_loss = 0.48302209, grad/param norm = 3.2942e-01, time/batch = 16.8628s	
10049/11350 (epoch 44.269), train_loss = 0.53732819, grad/param norm = 2.7575e-01, time/batch = 16.3888s	
10050/11350 (epoch 44.273), train_loss = 0.60531765, grad/param norm = 2.9873e-01, time/batch = 16.6250s	
10051/11350 (epoch 44.278), train_loss = 0.52552582, grad/param norm = 3.0289e-01, time/batch = 16.7968s	
10052/11350 (epoch 44.282), train_loss = 0.51799626, grad/param norm = 3.5959e-01, time/batch = 16.3923s	
10053/11350 (epoch 44.286), train_loss = 0.61970901, grad/param norm = 4.3633e-01, time/batch = 16.3064s	
10054/11350 (epoch 44.291), train_loss = 0.51811854, grad/param norm = 3.8511e-01, time/batch = 16.7618s	
10055/11350 (epoch 44.295), train_loss = 0.51042530, grad/param norm = 4.0912e-01, time/batch = 16.6319s	
10056/11350 (epoch 44.300), train_loss = 0.58868473, grad/param norm = 3.2152e-01, time/batch = 16.1421s	
10057/11350 (epoch 44.304), train_loss = 0.46952135, grad/param norm = 3.3430e-01, time/batch = 17.3502s	
10058/11350 (epoch 44.308), train_loss = 0.48667132, grad/param norm = 3.7988e-01, time/batch = 16.6105s	
10059/11350 (epoch 44.313), train_loss = 0.55507637, grad/param norm = 3.1184e-01, time/batch = 16.3048s	
10060/11350 (epoch 44.317), train_loss = 0.53797835, grad/param norm = 2.9127e-01, time/batch = 16.3856s	
10061/11350 (epoch 44.322), train_loss = 0.50405786, grad/param norm = 3.0777e-01, time/batch = 17.0338s	
10062/11350 (epoch 44.326), train_loss = 0.53821803, grad/param norm = 2.9873e-01, time/batch = 16.8418s	
10063/11350 (epoch 44.330), train_loss = 0.45207180, grad/param norm = 2.6589e-01, time/batch = 16.3715s	
10064/11350 (epoch 44.335), train_loss = 0.35720348, grad/param norm = 2.4818e-01, time/batch = 16.3843s	
10065/11350 (epoch 44.339), train_loss = 0.39502557, grad/param norm = 3.2143e-01, time/batch = 16.0647s	
10066/11350 (epoch 44.344), train_loss = 0.46122791, grad/param norm = 2.5611e-01, time/batch = 16.7032s	
10067/11350 (epoch 44.348), train_loss = 0.48666160, grad/param norm = 2.5297e-01, time/batch = 16.4842s	
10068/11350 (epoch 44.352), train_loss = 0.40105249, grad/param norm = 2.5984e-01, time/batch = 16.6182s	
10069/11350 (epoch 44.357), train_loss = 0.50153215, grad/param norm = 3.0769e-01, time/batch = 16.5331s	
10070/11350 (epoch 44.361), train_loss = 0.40977752, grad/param norm = 2.6656e-01, time/batch = 16.8598s	
10071/11350 (epoch 44.366), train_loss = 0.48002180, grad/param norm = 3.3036e-01, time/batch = 17.0192s	
10072/11350 (epoch 44.370), train_loss = 0.42729148, grad/param norm = 2.7295e-01, time/batch = 16.5503s	
10073/11350 (epoch 44.374), train_loss = 0.47052101, grad/param norm = 2.6861e-01, time/batch = 17.0341s	
10074/11350 (epoch 44.379), train_loss = 0.46722618, grad/param norm = 3.0611e-01, time/batch = 16.3876s	
10075/11350 (epoch 44.383), train_loss = 0.42053176, grad/param norm = 2.8821e-01, time/batch = 16.7950s	
10076/11350 (epoch 44.388), train_loss = 0.50054969, grad/param norm = 3.6343e-01, time/batch = 16.3525s	
10077/11350 (epoch 44.392), train_loss = 0.55328432, grad/param norm = 3.2289e-01, time/batch = 16.5625s	
10078/11350 (epoch 44.396), train_loss = 0.46365908, grad/param norm = 4.1115e-01, time/batch = 16.5560s	
10079/11350 (epoch 44.401), train_loss = 0.48078328, grad/param norm = 3.5999e-01, time/batch = 16.7143s	
10080/11350 (epoch 44.405), train_loss = 0.63599793, grad/param norm = 3.3617e-01, time/batch = 16.8509s	
10081/11350 (epoch 44.410), train_loss = 0.65365325, grad/param norm = 3.8391e-01, time/batch = 16.5305s	
10082/11350 (epoch 44.414), train_loss = 0.46403498, grad/param norm = 3.4840e-01, time/batch = 16.3817s	
10083/11350 (epoch 44.419), train_loss = 0.46643575, grad/param norm = 3.3082e-01, time/batch = 16.3133s	
10084/11350 (epoch 44.423), train_loss = 0.48087237, grad/param norm = 4.8470e-01, time/batch = 16.7909s	
10085/11350 (epoch 44.427), train_loss = 0.54070467, grad/param norm = 3.1716e-01, time/batch = 16.1538s	
10086/11350 (epoch 44.432), train_loss = 0.54088401, grad/param norm = 3.6036e-01, time/batch = 17.0310s	
10087/11350 (epoch 44.436), train_loss = 0.44596664, grad/param norm = 3.7296e-01, time/batch = 17.0872s	
10088/11350 (epoch 44.441), train_loss = 0.57835099, grad/param norm = 3.5505e-01, time/batch = 16.6063s	
10089/11350 (epoch 44.445), train_loss = 0.46210753, grad/param norm = 2.6543e-01, time/batch = 16.2215s	
10090/11350 (epoch 44.449), train_loss = 0.55053033, grad/param norm = 3.0323e-01, time/batch = 15.9811s	
10091/11350 (epoch 44.454), train_loss = 0.64066474, grad/param norm = 3.5794e-01, time/batch = 16.7150s	
10092/11350 (epoch 44.458), train_loss = 0.44334432, grad/param norm = 3.0582e-01, time/batch = 16.3847s	
10093/11350 (epoch 44.463), train_loss = 0.45726208, grad/param norm = 3.4020e-01, time/batch = 16.7145s	
10094/11350 (epoch 44.467), train_loss = 0.67372976, grad/param norm = 3.6088e-01, time/batch = 16.7628s	
10095/11350 (epoch 44.471), train_loss = 0.62515742, grad/param norm = 3.9838e-01, time/batch = 16.7150s	
10096/11350 (epoch 44.476), train_loss = 0.53009026, grad/param norm = 3.0604e-01, time/batch = 16.6278s	
10097/11350 (epoch 44.480), train_loss = 0.59706155, grad/param norm = 3.5625e-01, time/batch = 16.4689s	
10098/11350 (epoch 44.485), train_loss = 0.54428567, grad/param norm = 3.1064e-01, time/batch = 16.8478s	
10099/11350 (epoch 44.489), train_loss = 0.59210009, grad/param norm = 3.9957e-01, time/batch = 16.7122s	
10100/11350 (epoch 44.493), train_loss = 0.64416073, grad/param norm = 3.3447e-01, time/batch = 16.4855s	
10101/11350 (epoch 44.498), train_loss = 0.41054707, grad/param norm = 2.7805e-01, time/batch = 16.3965s	
10102/11350 (epoch 44.502), train_loss = 0.64557505, grad/param norm = 3.2019e-01, time/batch = 17.0090s	
10103/11350 (epoch 44.507), train_loss = 0.47039125, grad/param norm = 3.0287e-01, time/batch = 16.2267s	
10104/11350 (epoch 44.511), train_loss = 0.58155393, grad/param norm = 3.1778e-01, time/batch = 15.9820s	
10105/11350 (epoch 44.515), train_loss = 0.56246596, grad/param norm = 3.8901e-01, time/batch = 16.3835s	
10106/11350 (epoch 44.520), train_loss = 0.68220124, grad/param norm = 3.7014e-01, time/batch = 16.9289s	
10107/11350 (epoch 44.524), train_loss = 0.59399188, grad/param norm = 3.4127e-01, time/batch = 16.1470s	
10108/11350 (epoch 44.529), train_loss = 0.50586491, grad/param norm = 2.8327e-01, time/batch = 16.7928s	
10109/11350 (epoch 44.533), train_loss = 0.66470960, grad/param norm = 3.2379e-01, time/batch = 16.7077s	
10110/11350 (epoch 44.537), train_loss = 0.64069897, grad/param norm = 4.0189e-01, time/batch = 16.8783s	
10111/11350 (epoch 44.542), train_loss = 0.52563591, grad/param norm = 2.6773e-01, time/batch = 16.4681s	
10112/11350 (epoch 44.546), train_loss = 0.69527472, grad/param norm = 4.3214e-01, time/batch = 17.2419s	
10113/11350 (epoch 44.551), train_loss = 0.60975900, grad/param norm = 3.8813e-01, time/batch = 16.9669s	
10114/11350 (epoch 44.555), train_loss = 0.49793275, grad/param norm = 3.5144e-01, time/batch = 16.7141s	
10115/11350 (epoch 44.559), train_loss = 0.57589512, grad/param norm = 3.2780e-01, time/batch = 16.7916s	
10116/11350 (epoch 44.564), train_loss = 0.59474446, grad/param norm = 3.5520e-01, time/batch = 17.3366s	
10117/11350 (epoch 44.568), train_loss = 0.59771462, grad/param norm = 3.6730e-01, time/batch = 16.1370s	
10118/11350 (epoch 44.573), train_loss = 0.68022954, grad/param norm = 4.2517e-01, time/batch = 16.8828s	
10119/11350 (epoch 44.577), train_loss = 0.62731404, grad/param norm = 4.7962e-01, time/batch = 16.3063s	
10120/11350 (epoch 44.581), train_loss = 0.69949644, grad/param norm = 3.4931e-01, time/batch = 16.4580s	
10121/11350 (epoch 44.586), train_loss = 0.63833858, grad/param norm = 4.0072e-01, time/batch = 16.7545s	
10122/11350 (epoch 44.590), train_loss = 0.68077809, grad/param norm = 4.1245e-01, time/batch = 16.3977s	
10123/11350 (epoch 44.595), train_loss = 0.76642223, grad/param norm = 3.5109e-01, time/batch = 16.7811s	
10124/11350 (epoch 44.599), train_loss = 0.57500556, grad/param norm = 3.3039e-01, time/batch = 16.5442s	
10125/11350 (epoch 44.604), train_loss = 0.58052941, grad/param norm = 3.5499e-01, time/batch = 16.2155s	
10126/11350 (epoch 44.608), train_loss = 0.57406616, grad/param norm = 4.2296e-01, time/batch = 16.3954s	
10127/11350 (epoch 44.612), train_loss = 0.59540932, grad/param norm = 3.1876e-01, time/batch = 16.7031s	
10128/11350 (epoch 44.617), train_loss = 0.67730303, grad/param norm = 3.6936e-01, time/batch = 16.5531s	
10129/11350 (epoch 44.621), train_loss = 0.66836918, grad/param norm = 3.4656e-01, time/batch = 16.5525s	
10130/11350 (epoch 44.626), train_loss = 0.60655112, grad/param norm = 3.4812e-01, time/batch = 16.6244s	
10131/11350 (epoch 44.630), train_loss = 0.60847257, grad/param norm = 3.7046e-01, time/batch = 16.7082s	
10132/11350 (epoch 44.634), train_loss = 0.58980980, grad/param norm = 3.6471e-01, time/batch = 16.8521s	
10133/11350 (epoch 44.639), train_loss = 0.56387489, grad/param norm = 3.6183e-01, time/batch = 16.7685s	
10134/11350 (epoch 44.643), train_loss = 0.50675799, grad/param norm = 3.6741e-01, time/batch = 16.8578s	
10135/11350 (epoch 44.648), train_loss = 0.56715497, grad/param norm = 3.2500e-01, time/batch = 16.3176s	
10136/11350 (epoch 44.652), train_loss = 0.51354606, grad/param norm = 3.3692e-01, time/batch = 16.3086s	
10137/11350 (epoch 44.656), train_loss = 0.60005093, grad/param norm = 2.9021e-01, time/batch = 16.2921s	
10138/11350 (epoch 44.661), train_loss = 0.59543305, grad/param norm = 3.5162e-01, time/batch = 16.7315s	
10139/11350 (epoch 44.665), train_loss = 0.61953106, grad/param norm = 3.4826e-01, time/batch = 16.5518s	
10140/11350 (epoch 44.670), train_loss = 0.61348533, grad/param norm = 3.1244e-01, time/batch = 16.7083s	
10141/11350 (epoch 44.674), train_loss = 0.55852751, grad/param norm = 2.9379e-01, time/batch = 17.1151s	
10142/11350 (epoch 44.678), train_loss = 0.62968070, grad/param norm = 3.1923e-01, time/batch = 16.5452s	
10143/11350 (epoch 44.683), train_loss = 0.56016462, grad/param norm = 3.7249e-01, time/batch = 16.5526s	
10144/11350 (epoch 44.687), train_loss = 0.50124436, grad/param norm = 3.2451e-01, time/batch = 16.6366s	
10145/11350 (epoch 44.692), train_loss = 0.74414021, grad/param norm = 3.9526e-01, time/batch = 16.6141s	
10146/11350 (epoch 44.696), train_loss = 0.76398217, grad/param norm = 4.0450e-01, time/batch = 17.0139s	
10147/11350 (epoch 44.700), train_loss = 0.66535152, grad/param norm = 3.6963e-01, time/batch = 16.7091s	
10148/11350 (epoch 44.705), train_loss = 0.68727355, grad/param norm = 3.6145e-01, time/batch = 17.3878s	
10149/11350 (epoch 44.709), train_loss = 0.68931431, grad/param norm = 3.8267e-01, time/batch = 16.2249s	
10150/11350 (epoch 44.714), train_loss = 0.59931539, grad/param norm = 3.2948e-01, time/batch = 16.3051s	
10151/11350 (epoch 44.718), train_loss = 0.52318330, grad/param norm = 3.1085e-01, time/batch = 17.0360s	
10152/11350 (epoch 44.722), train_loss = 0.58163840, grad/param norm = 3.6782e-01, time/batch = 17.1843s	
10153/11350 (epoch 44.727), train_loss = 0.61922073, grad/param norm = 3.3829e-01, time/batch = 16.3009s	
10154/11350 (epoch 44.731), train_loss = 0.57770744, grad/param norm = 3.6893e-01, time/batch = 16.3995s	
10155/11350 (epoch 44.736), train_loss = 0.53490616, grad/param norm = 3.9008e-01, time/batch = 16.3778s	
10156/11350 (epoch 44.740), train_loss = 0.57215863, grad/param norm = 3.1073e-01, time/batch = 16.9602s	
10157/11350 (epoch 44.744), train_loss = 0.57482770, grad/param norm = 3.6545e-01, time/batch = 17.1753s	
10158/11350 (epoch 44.749), train_loss = 0.57292675, grad/param norm = 3.2726e-01, time/batch = 16.2206s	
10159/11350 (epoch 44.753), train_loss = 0.63423658, grad/param norm = 3.4405e-01, time/batch = 17.0308s	
10160/11350 (epoch 44.758), train_loss = 0.56384998, grad/param norm = 3.9860e-01, time/batch = 16.7104s	
10161/11350 (epoch 44.762), train_loss = 0.71576291, grad/param norm = 3.8414e-01, time/batch = 16.3074s	
10162/11350 (epoch 44.767), train_loss = 0.70985094, grad/param norm = 3.6884e-01, time/batch = 16.1414s	
10163/11350 (epoch 44.771), train_loss = 0.77820568, grad/param norm = 4.4927e-01, time/batch = 16.4476s	
10164/11350 (epoch 44.775), train_loss = 0.63818884, grad/param norm = 4.7523e-01, time/batch = 16.1453s	
10165/11350 (epoch 44.780), train_loss = 0.65370488, grad/param norm = 3.5515e-01, time/batch = 16.6161s	
10166/11350 (epoch 44.784), train_loss = 0.60961891, grad/param norm = 3.5824e-01, time/batch = 16.6739s	
10167/11350 (epoch 44.789), train_loss = 0.61333000, grad/param norm = 3.4269e-01, time/batch = 16.0615s	
10168/11350 (epoch 44.793), train_loss = 0.66377081, grad/param norm = 3.5750e-01, time/batch = 16.3692s	
10169/11350 (epoch 44.797), train_loss = 0.61878724, grad/param norm = 3.1632e-01, time/batch = 16.3045s	
10170/11350 (epoch 44.802), train_loss = 0.62412026, grad/param norm = 2.8811e-01, time/batch = 28.3881s	
10171/11350 (epoch 44.806), train_loss = 0.64124833, grad/param norm = 3.1618e-01, time/batch = 18.6166s	
10172/11350 (epoch 44.811), train_loss = 0.62477650, grad/param norm = 3.1354e-01, time/batch = 16.3639s	
10173/11350 (epoch 44.815), train_loss = 0.59414942, grad/param norm = 3.0002e-01, time/batch = 16.6139s	
10174/11350 (epoch 44.819), train_loss = 0.54313995, grad/param norm = 3.9544e-01, time/batch = 17.2631s	
10175/11350 (epoch 44.824), train_loss = 0.54430994, grad/param norm = 3.6838e-01, time/batch = 16.3945s	
10176/11350 (epoch 44.828), train_loss = 0.54822479, grad/param norm = 3.0910e-01, time/batch = 16.8428s	
10177/11350 (epoch 44.833), train_loss = 0.57552183, grad/param norm = 2.8309e-01, time/batch = 16.6126s	
10178/11350 (epoch 44.837), train_loss = 0.61473968, grad/param norm = 3.6792e-01, time/batch = 16.1381s	
10179/11350 (epoch 44.841), train_loss = 0.81311307, grad/param norm = 3.9796e-01, time/batch = 16.1423s	
10180/11350 (epoch 44.846), train_loss = 0.67162123, grad/param norm = 3.3219e-01, time/batch = 17.0017s	
10181/11350 (epoch 44.850), train_loss = 0.67447736, grad/param norm = 3.2997e-01, time/batch = 16.5630s	
10182/11350 (epoch 44.855), train_loss = 0.51045258, grad/param norm = 3.3130e-01, time/batch = 16.4789s	
10183/11350 (epoch 44.859), train_loss = 0.54774070, grad/param norm = 4.2221e-01, time/batch = 16.7024s	
10184/11350 (epoch 44.863), train_loss = 0.53876068, grad/param norm = 3.3781e-01, time/batch = 16.8627s	
10185/11350 (epoch 44.868), train_loss = 0.52847932, grad/param norm = 2.9929e-01, time/batch = 16.7271s	
10186/11350 (epoch 44.872), train_loss = 0.54107107, grad/param norm = 3.3355e-01, time/batch = 16.5461s	
10187/11350 (epoch 44.877), train_loss = 0.54949773, grad/param norm = 3.3867e-01, time/batch = 16.9466s	
10188/11350 (epoch 44.881), train_loss = 0.73373397, grad/param norm = 3.9471e-01, time/batch = 16.6939s	
10189/11350 (epoch 44.885), train_loss = 0.68291167, grad/param norm = 3.5019e-01, time/batch = 16.2273s	
10190/11350 (epoch 44.890), train_loss = 0.65302422, grad/param norm = 4.3104e-01, time/batch = 16.2329s	
10191/11350 (epoch 44.894), train_loss = 0.54957266, grad/param norm = 3.7510e-01, time/batch = 17.1093s	
10192/11350 (epoch 44.899), train_loss = 0.65257456, grad/param norm = 3.3630e-01, time/batch = 16.3060s	
10193/11350 (epoch 44.903), train_loss = 0.62449073, grad/param norm = 3.9703e-01, time/batch = 16.3113s	
10194/11350 (epoch 44.907), train_loss = 0.54592177, grad/param norm = 3.7583e-01, time/batch = 17.0872s	
10195/11350 (epoch 44.912), train_loss = 0.54044036, grad/param norm = 3.0368e-01, time/batch = 16.7050s	
10196/11350 (epoch 44.916), train_loss = 0.60004697, grad/param norm = 3.1674e-01, time/batch = 16.4570s	
10197/11350 (epoch 44.921), train_loss = 0.60470872, grad/param norm = 3.3424e-01, time/batch = 16.9415s	
10198/11350 (epoch 44.925), train_loss = 0.52311287, grad/param norm = 2.8764e-01, time/batch = 17.0132s	
10199/11350 (epoch 44.930), train_loss = 0.59628775, grad/param norm = 3.8904e-01, time/batch = 16.3783s	
10200/11350 (epoch 44.934), train_loss = 0.68068444, grad/param norm = 3.6646e-01, time/batch = 16.6243s	
10201/11350 (epoch 44.938), train_loss = 0.61730239, grad/param norm = 4.4724e-01, time/batch = 16.5995s	
10202/11350 (epoch 44.943), train_loss = 0.65604597, grad/param norm = 3.5365e-01, time/batch = 16.5566s	
10203/11350 (epoch 44.947), train_loss = 0.61840221, grad/param norm = 3.4139e-01, time/batch = 16.7187s	
10204/11350 (epoch 44.952), train_loss = 0.63613178, grad/param norm = 3.4634e-01, time/batch = 16.8903s	
10205/11350 (epoch 44.956), train_loss = 0.51811385, grad/param norm = 2.9771e-01, time/batch = 16.9299s	
10206/11350 (epoch 44.960), train_loss = 0.58686811, grad/param norm = 3.6341e-01, time/batch = 16.3972s	
10207/11350 (epoch 44.965), train_loss = 0.50832015, grad/param norm = 3.4279e-01, time/batch = 17.0828s	
10208/11350 (epoch 44.969), train_loss = 0.51251686, grad/param norm = 3.4761e-01, time/batch = 16.4652s	
10209/11350 (epoch 44.974), train_loss = 0.50820527, grad/param norm = 3.5884e-01, time/batch = 16.9441s	
10210/11350 (epoch 44.978), train_loss = 0.57200096, grad/param norm = 2.9823e-01, time/batch = 16.9894s	
10211/11350 (epoch 44.982), train_loss = 0.41115938, grad/param norm = 2.8530e-01, time/batch = 16.8799s	
10212/11350 (epoch 44.987), train_loss = 0.59757881, grad/param norm = 3.4090e-01, time/batch = 16.9562s	
10213/11350 (epoch 44.991), train_loss = 0.50902001, grad/param norm = 3.3411e-01, time/batch = 16.8035s	
10214/11350 (epoch 44.996), train_loss = 0.54320754, grad/param norm = 3.2951e-01, time/batch = 16.7104s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
10215/11350 (epoch 45.000), train_loss = 0.45304502, grad/param norm = 3.5408e-01, time/batch = 16.3829s	
10216/11350 (epoch 45.004), train_loss = 0.63206139, grad/param norm = 3.2046e-01, time/batch = 16.7784s	
10217/11350 (epoch 45.009), train_loss = 0.59358409, grad/param norm = 3.2808e-01, time/batch = 17.2711s	
10218/11350 (epoch 45.013), train_loss = 0.41216683, grad/param norm = 2.6700e-01, time/batch = 16.3890s	
10219/11350 (epoch 45.018), train_loss = 0.46501812, grad/param norm = 3.1210e-01, time/batch = 16.7887s	
10220/11350 (epoch 45.022), train_loss = 0.49267247, grad/param norm = 4.0465e-01, time/batch = 16.7076s	
10221/11350 (epoch 45.026), train_loss = 0.46622437, grad/param norm = 3.3755e-01, time/batch = 16.2989s	
10222/11350 (epoch 45.031), train_loss = 0.47593137, grad/param norm = 3.3286e-01, time/batch = 16.9521s	
10223/11350 (epoch 45.035), train_loss = 0.51617813, grad/param norm = 2.9777e-01, time/batch = 16.5439s	
10224/11350 (epoch 45.040), train_loss = 0.51960050, grad/param norm = 2.8746e-01, time/batch = 16.7996s	
10225/11350 (epoch 45.044), train_loss = 0.47454332, grad/param norm = 2.6499e-01, time/batch = 16.2961s	
10226/11350 (epoch 45.048), train_loss = 0.46057826, grad/param norm = 2.5155e-01, time/batch = 16.7067s	
10227/11350 (epoch 45.053), train_loss = 0.51292371, grad/param norm = 3.3999e-01, time/batch = 16.6974s	
10228/11350 (epoch 45.057), train_loss = 0.53990318, grad/param norm = 4.4346e-01, time/batch = 16.6062s	
10229/11350 (epoch 45.062), train_loss = 0.44838961, grad/param norm = 3.3533e-01, time/batch = 16.3075s	
10230/11350 (epoch 45.066), train_loss = 0.44571623, grad/param norm = 3.5361e-01, time/batch = 16.8739s	
10231/11350 (epoch 45.070), train_loss = 0.51966421, grad/param norm = 3.2062e-01, time/batch = 16.7147s	
10232/11350 (epoch 45.075), train_loss = 0.44127617, grad/param norm = 2.5220e-01, time/batch = 16.8053s	
10233/11350 (epoch 45.079), train_loss = 0.55452140, grad/param norm = 3.2924e-01, time/batch = 16.7055s	
10234/11350 (epoch 45.084), train_loss = 0.63605958, grad/param norm = 3.5545e-01, time/batch = 16.7220s	
10235/11350 (epoch 45.088), train_loss = 0.58809848, grad/param norm = 3.3243e-01, time/batch = 17.1628s	
10236/11350 (epoch 45.093), train_loss = 0.58180534, grad/param norm = 3.3513e-01, time/batch = 16.6301s	
10237/11350 (epoch 45.097), train_loss = 0.53045948, grad/param norm = 3.5108e-01, time/batch = 16.7086s	
10238/11350 (epoch 45.101), train_loss = 0.50924967, grad/param norm = 4.4879e-01, time/batch = 16.6464s	
10239/11350 (epoch 45.106), train_loss = 0.57300983, grad/param norm = 3.7489e-01, time/batch = 16.6230s	
10240/11350 (epoch 45.110), train_loss = 0.49988427, grad/param norm = 4.2079e-01, time/batch = 17.0863s	
10241/11350 (epoch 45.115), train_loss = 0.52787317, grad/param norm = 3.8153e-01, time/batch = 17.1062s	
10242/11350 (epoch 45.119), train_loss = 0.61823161, grad/param norm = 3.7149e-01, time/batch = 16.7889s	
10243/11350 (epoch 45.123), train_loss = 0.48077125, grad/param norm = 3.5142e-01, time/batch = 16.3890s	
10244/11350 (epoch 45.128), train_loss = 0.43897618, grad/param norm = 3.2605e-01, time/batch = 16.8648s	
10245/11350 (epoch 45.132), train_loss = 0.47728391, grad/param norm = 2.9221e-01, time/batch = 17.1230s	
10246/11350 (epoch 45.137), train_loss = 0.47073468, grad/param norm = 3.8126e-01, time/batch = 16.6923s	
10247/11350 (epoch 45.141), train_loss = 0.58952045, grad/param norm = 3.5705e-01, time/batch = 16.3764s	
10248/11350 (epoch 45.145), train_loss = 0.51788244, grad/param norm = 3.1385e-01, time/batch = 17.2377s	
10249/11350 (epoch 45.150), train_loss = 0.54891830, grad/param norm = 4.0906e-01, time/batch = 16.7102s	
10250/11350 (epoch 45.154), train_loss = 0.64367429, grad/param norm = 3.6769e-01, time/batch = 16.3044s	
10251/11350 (epoch 45.159), train_loss = 0.46285322, grad/param norm = 3.1888e-01, time/batch = 16.8644s	
10252/11350 (epoch 45.163), train_loss = 0.58739962, grad/param norm = 3.8182e-01, time/batch = 16.6407s	
10253/11350 (epoch 45.167), train_loss = 0.62223681, grad/param norm = 3.4965e-01, time/batch = 16.7118s	
10254/11350 (epoch 45.172), train_loss = 0.69562094, grad/param norm = 3.5297e-01, time/batch = 16.2121s	
10255/11350 (epoch 45.176), train_loss = 0.53620916, grad/param norm = 2.9662e-01, time/batch = 16.8389s	
10256/11350 (epoch 45.181), train_loss = 0.53857103, grad/param norm = 3.9549e-01, time/batch = 16.3873s	
10257/11350 (epoch 45.185), train_loss = 0.49153956, grad/param norm = 2.7415e-01, time/batch = 16.3869s	
10258/11350 (epoch 45.189), train_loss = 0.49111191, grad/param norm = 3.3737e-01, time/batch = 16.8574s	
10259/11350 (epoch 45.194), train_loss = 0.45213756, grad/param norm = 3.8504e-01, time/batch = 17.1741s	
10260/11350 (epoch 45.198), train_loss = 0.40664343, grad/param norm = 3.4068e-01, time/batch = 16.8621s	
10261/11350 (epoch 45.203), train_loss = 0.50520793, grad/param norm = 4.3968e-01, time/batch = 17.4969s	
10262/11350 (epoch 45.207), train_loss = 0.45060937, grad/param norm = 3.7508e-01, time/batch = 17.0092s	
10263/11350 (epoch 45.211), train_loss = 0.60351016, grad/param norm = 4.1491e-01, time/batch = 16.7813s	
10264/11350 (epoch 45.216), train_loss = 0.55039188, grad/param norm = 3.1573e-01, time/batch = 17.5822s	
10265/11350 (epoch 45.220), train_loss = 0.59093596, grad/param norm = 3.4887e-01, time/batch = 16.8179s	
10266/11350 (epoch 45.225), train_loss = 0.51214208, grad/param norm = 2.7488e-01, time/batch = 17.2372s	
10267/11350 (epoch 45.229), train_loss = 0.54121312, grad/param norm = 2.8349e-01, time/batch = 16.5487s	
10268/11350 (epoch 45.233), train_loss = 0.51050162, grad/param norm = 3.6278e-01, time/batch = 16.0618s	
10269/11350 (epoch 45.238), train_loss = 0.59274088, grad/param norm = 3.4963e-01, time/batch = 16.7843s	
10270/11350 (epoch 45.242), train_loss = 0.62476466, grad/param norm = 3.7615e-01, time/batch = 16.4697s	
10271/11350 (epoch 45.247), train_loss = 0.44883018, grad/param norm = 2.6860e-01, time/batch = 16.8599s	
10272/11350 (epoch 45.251), train_loss = 0.52234439, grad/param norm = 3.6937e-01, time/batch = 16.6025s	
10273/11350 (epoch 45.256), train_loss = 0.56144849, grad/param norm = 3.3661e-01, time/batch = 16.8635s	
10274/11350 (epoch 45.260), train_loss = 0.49277691, grad/param norm = 3.3166e-01, time/batch = 16.1424s	
10275/11350 (epoch 45.264), train_loss = 0.46493022, grad/param norm = 3.2957e-01, time/batch = 16.1439s	
10276/11350 (epoch 45.269), train_loss = 0.52011509, grad/param norm = 2.6449e-01, time/batch = 17.1596s	
10277/11350 (epoch 45.273), train_loss = 0.60734835, grad/param norm = 3.1032e-01, time/batch = 16.1482s	
10278/11350 (epoch 45.278), train_loss = 0.50704687, grad/param norm = 2.9233e-01, time/batch = 16.3945s	
10279/11350 (epoch 45.282), train_loss = 0.49853863, grad/param norm = 3.1408e-01, time/batch = 16.4716s	
10280/11350 (epoch 45.286), train_loss = 0.60754621, grad/param norm = 3.3172e-01, time/batch = 16.6897s	
10281/11350 (epoch 45.291), train_loss = 0.50310811, grad/param norm = 3.3610e-01, time/batch = 16.2986s	
10282/11350 (epoch 45.295), train_loss = 0.48906062, grad/param norm = 3.2709e-01, time/batch = 16.1351s	
10283/11350 (epoch 45.300), train_loss = 0.58961954, grad/param norm = 3.4639e-01, time/batch = 16.2207s	
10284/11350 (epoch 45.304), train_loss = 0.48292421, grad/param norm = 3.6029e-01, time/batch = 16.3850s	
10285/11350 (epoch 45.308), train_loss = 0.46930702, grad/param norm = 3.2161e-01, time/batch = 16.2233s	
10286/11350 (epoch 45.313), train_loss = 0.52534573, grad/param norm = 3.0823e-01, time/batch = 17.2507s	
10287/11350 (epoch 45.317), train_loss = 0.52973615, grad/param norm = 2.8386e-01, time/batch = 16.9505s	
10288/11350 (epoch 45.322), train_loss = 0.50143680, grad/param norm = 3.2505e-01, time/batch = 16.3044s	
10289/11350 (epoch 45.326), train_loss = 0.52705149, grad/param norm = 2.8877e-01, time/batch = 16.6363s	
10290/11350 (epoch 45.330), train_loss = 0.44261235, grad/param norm = 2.5743e-01, time/batch = 16.7615s	
10291/11350 (epoch 45.335), train_loss = 0.35472375, grad/param norm = 2.5929e-01, time/batch = 16.3695s	
10292/11350 (epoch 45.339), train_loss = 0.38240524, grad/param norm = 3.1332e-01, time/batch = 16.3753s	
10293/11350 (epoch 45.344), train_loss = 0.46042798, grad/param norm = 2.7275e-01, time/batch = 16.2223s	
10294/11350 (epoch 45.348), train_loss = 0.49256514, grad/param norm = 2.9479e-01, time/batch = 17.1809s	
10295/11350 (epoch 45.352), train_loss = 0.39172910, grad/param norm = 2.9015e-01, time/batch = 16.5274s	
10296/11350 (epoch 45.357), train_loss = 0.48503778, grad/param norm = 2.7144e-01, time/batch = 16.5358s	
10297/11350 (epoch 45.361), train_loss = 0.40568330, grad/param norm = 2.4435e-01, time/batch = 16.4684s	
10298/11350 (epoch 45.366), train_loss = 0.47578142, grad/param norm = 3.2109e-01, time/batch = 17.0192s	
10299/11350 (epoch 45.370), train_loss = 0.40932903, grad/param norm = 3.0333e-01, time/batch = 16.3818s	
10300/11350 (epoch 45.374), train_loss = 0.46188086, grad/param norm = 2.6364e-01, time/batch = 15.9730s	
10301/11350 (epoch 45.379), train_loss = 0.45954878, grad/param norm = 3.2914e-01, time/batch = 16.4636s	
10302/11350 (epoch 45.383), train_loss = 0.39920570, grad/param norm = 2.6539e-01, time/batch = 16.3835s	
10303/11350 (epoch 45.388), train_loss = 0.46706076, grad/param norm = 3.0387e-01, time/batch = 16.4728s	
10304/11350 (epoch 45.392), train_loss = 0.54329203, grad/param norm = 3.1068e-01, time/batch = 16.3032s	
10305/11350 (epoch 45.396), train_loss = 0.44594577, grad/param norm = 3.2063e-01, time/batch = 16.7064s	
10306/11350 (epoch 45.401), train_loss = 0.46534118, grad/param norm = 3.7143e-01, time/batch = 16.2972s	
10307/11350 (epoch 45.405), train_loss = 0.61924780, grad/param norm = 3.4236e-01, time/batch = 17.1789s	
10308/11350 (epoch 45.410), train_loss = 0.63456794, grad/param norm = 3.7130e-01, time/batch = 16.3002s	
10309/11350 (epoch 45.414), train_loss = 0.43783755, grad/param norm = 3.3997e-01, time/batch = 16.9406s	
10310/11350 (epoch 45.419), train_loss = 0.44322736, grad/param norm = 3.3597e-01, time/batch = 16.5549s	
10311/11350 (epoch 45.423), train_loss = 0.46617628, grad/param norm = 4.0472e-01, time/batch = 16.6213s	
10312/11350 (epoch 45.427), train_loss = 0.51199906, grad/param norm = 3.2981e-01, time/batch = 17.3446s	
10313/11350 (epoch 45.432), train_loss = 0.51233337, grad/param norm = 3.2380e-01, time/batch = 16.6991s	
10314/11350 (epoch 45.436), train_loss = 0.42447240, grad/param norm = 3.1252e-01, time/batch = 16.3184s	
10315/11350 (epoch 45.441), train_loss = 0.56414819, grad/param norm = 4.0604e-01, time/batch = 16.5561s	
10316/11350 (epoch 45.445), train_loss = 0.45077441, grad/param norm = 2.7784e-01, time/batch = 16.5398s	
10317/11350 (epoch 45.449), train_loss = 0.53068463, grad/param norm = 2.6605e-01, time/batch = 16.0569s	
10318/11350 (epoch 45.454), train_loss = 0.62790739, grad/param norm = 4.2675e-01, time/batch = 16.8640s	
10319/11350 (epoch 45.458), train_loss = 0.44057090, grad/param norm = 3.0808e-01, time/batch = 16.6303s	
10320/11350 (epoch 45.463), train_loss = 0.44857398, grad/param norm = 3.2571e-01, time/batch = 16.5535s	
10321/11350 (epoch 45.467), train_loss = 0.64412901, grad/param norm = 3.5627e-01, time/batch = 16.4572s	
10322/11350 (epoch 45.471), train_loss = 0.62977438, grad/param norm = 3.6986e-01, time/batch = 16.4727s	
10323/11350 (epoch 45.476), train_loss = 0.52515850, grad/param norm = 2.9917e-01, time/batch = 17.0164s	
10324/11350 (epoch 45.480), train_loss = 0.57817082, grad/param norm = 3.2942e-01, time/batch = 16.5330s	
10325/11350 (epoch 45.485), train_loss = 0.54510995, grad/param norm = 3.5103e-01, time/batch = 16.7092s	
10326/11350 (epoch 45.489), train_loss = 0.59560459, grad/param norm = 4.0210e-01, time/batch = 16.0671s	
10327/11350 (epoch 45.493), train_loss = 0.62203550, grad/param norm = 3.2578e-01, time/batch = 17.0944s	
10328/11350 (epoch 45.498), train_loss = 0.40115839, grad/param norm = 2.9480e-01, time/batch = 16.9390s	
10329/11350 (epoch 45.502), train_loss = 0.63804309, grad/param norm = 3.3542e-01, time/batch = 16.1474s	
10330/11350 (epoch 45.507), train_loss = 0.44995253, grad/param norm = 2.7572e-01, time/batch = 17.3940s	
10331/11350 (epoch 45.511), train_loss = 0.57983450, grad/param norm = 3.3758e-01, time/batch = 16.4706s	
10332/11350 (epoch 45.515), train_loss = 0.53312990, grad/param norm = 3.2153e-01, time/batch = 16.6296s	
10333/11350 (epoch 45.520), train_loss = 0.67318646, grad/param norm = 3.8639e-01, time/batch = 16.5633s	
10334/11350 (epoch 45.524), train_loss = 0.58738385, grad/param norm = 4.0880e-01, time/batch = 16.7046s	
10335/11350 (epoch 45.529), train_loss = 0.49438237, grad/param norm = 3.2768e-01, time/batch = 16.7050s	
10336/11350 (epoch 45.533), train_loss = 0.68159189, grad/param norm = 4.4579e-01, time/batch = 16.5512s	
10337/11350 (epoch 45.537), train_loss = 0.61778415, grad/param norm = 3.2509e-01, time/batch = 16.5432s	
10338/11350 (epoch 45.542), train_loss = 0.53000938, grad/param norm = 3.1687e-01, time/batch = 16.6983s	
10339/11350 (epoch 45.546), train_loss = 0.66942499, grad/param norm = 3.8559e-01, time/batch = 16.3811s	
10340/11350 (epoch 45.551), train_loss = 0.59178274, grad/param norm = 4.0212e-01, time/batch = 16.5511s	
10341/11350 (epoch 45.555), train_loss = 0.47599708, grad/param norm = 2.9108e-01, time/batch = 16.7916s	
10342/11350 (epoch 45.559), train_loss = 0.55664160, grad/param norm = 3.0159e-01, time/batch = 16.7064s	
10343/11350 (epoch 45.564), train_loss = 0.58949844, grad/param norm = 3.8427e-01, time/batch = 16.5525s	
10344/11350 (epoch 45.568), train_loss = 0.57226192, grad/param norm = 3.1176e-01, time/batch = 16.6028s	
10345/11350 (epoch 45.573), train_loss = 0.68121036, grad/param norm = 5.3252e-01, time/batch = 16.5322s	
10346/11350 (epoch 45.577), train_loss = 0.61892202, grad/param norm = 4.8439e-01, time/batch = 16.1544s	
10347/11350 (epoch 45.581), train_loss = 0.70686527, grad/param norm = 3.8330e-01, time/batch = 16.4693s	
10348/11350 (epoch 45.586), train_loss = 0.63525971, grad/param norm = 4.7618e-01, time/batch = 17.0985s	
10349/11350 (epoch 45.590), train_loss = 0.68649488, grad/param norm = 4.7299e-01, time/batch = 17.1623s	
10350/11350 (epoch 45.595), train_loss = 0.76585774, grad/param norm = 4.1728e-01, time/batch = 16.7158s	
10351/11350 (epoch 45.599), train_loss = 0.56772231, grad/param norm = 4.0626e-01, time/batch = 16.2287s	
10352/11350 (epoch 45.604), train_loss = 0.57476084, grad/param norm = 3.8234e-01, time/batch = 16.7046s	
10353/11350 (epoch 45.608), train_loss = 0.55248097, grad/param norm = 3.6411e-01, time/batch = 16.4766s	
10354/11350 (epoch 45.612), train_loss = 0.58696655, grad/param norm = 3.4350e-01, time/batch = 16.3782s	
10355/11350 (epoch 45.617), train_loss = 0.65403740, grad/param norm = 3.5514e-01, time/batch = 16.5425s	
10356/11350 (epoch 45.621), train_loss = 0.66356882, grad/param norm = 3.5626e-01, time/batch = 16.2174s	
10357/11350 (epoch 45.626), train_loss = 0.59218773, grad/param norm = 3.1802e-01, time/batch = 16.0652s	
10358/11350 (epoch 45.630), train_loss = 0.57880317, grad/param norm = 3.2756e-01, time/batch = 16.3863s	
10359/11350 (epoch 45.634), train_loss = 0.57055102, grad/param norm = 6.5966e-01, time/batch = 16.8768s	
10360/11350 (epoch 45.639), train_loss = 0.56387798, grad/param norm = 3.5556e-01, time/batch = 16.0610s	
10361/11350 (epoch 45.643), train_loss = 0.47846706, grad/param norm = 3.3555e-01, time/batch = 16.5554s	
10362/11350 (epoch 45.648), train_loss = 0.56307488, grad/param norm = 3.1471e-01, time/batch = 16.2274s	
10363/11350 (epoch 45.652), train_loss = 0.49246212, grad/param norm = 3.0840e-01, time/batch = 17.3756s	
10364/11350 (epoch 45.656), train_loss = 0.60426806, grad/param norm = 3.2319e-01, time/batch = 16.3136s	
10365/11350 (epoch 45.661), train_loss = 0.59938381, grad/param norm = 3.7983e-01, time/batch = 16.2244s	
10366/11350 (epoch 45.665), train_loss = 0.59574972, grad/param norm = 3.6665e-01, time/batch = 17.5747s	
10367/11350 (epoch 45.670), train_loss = 0.60014917, grad/param norm = 3.2772e-01, time/batch = 16.4548s	
10368/11350 (epoch 45.674), train_loss = 0.55803279, grad/param norm = 3.2683e-01, time/batch = 16.6732s	
10369/11350 (epoch 45.678), train_loss = 0.61181140, grad/param norm = 3.1321e-01, time/batch = 16.3902s	
10370/11350 (epoch 45.683), train_loss = 0.55791774, grad/param norm = 3.8120e-01, time/batch = 16.5498s	
10371/11350 (epoch 45.687), train_loss = 0.49810174, grad/param norm = 3.6469e-01, time/batch = 16.2217s	
10372/11350 (epoch 45.692), train_loss = 0.74307290, grad/param norm = 3.9073e-01, time/batch = 16.7117s	
10373/11350 (epoch 45.696), train_loss = 0.75881978, grad/param norm = 4.3366e-01, time/batch = 16.5446s	
10374/11350 (epoch 45.700), train_loss = 0.65871056, grad/param norm = 3.8575e-01, time/batch = 16.3038s	
10375/11350 (epoch 45.705), train_loss = 0.66258494, grad/param norm = 3.7822e-01, time/batch = 16.1419s	
10376/11350 (epoch 45.709), train_loss = 0.67078264, grad/param norm = 3.7672e-01, time/batch = 16.4827s	
10377/11350 (epoch 45.714), train_loss = 0.59781068, grad/param norm = 3.5850e-01, time/batch = 17.1819s	
10378/11350 (epoch 45.718), train_loss = 0.51115432, grad/param norm = 2.9686e-01, time/batch = 16.2167s	
10379/11350 (epoch 45.722), train_loss = 0.57155308, grad/param norm = 3.5189e-01, time/batch = 16.4834s	
10380/11350 (epoch 45.727), train_loss = 0.60824112, grad/param norm = 3.6118e-01, time/batch = 16.5610s	
10381/11350 (epoch 45.731), train_loss = 0.55579786, grad/param norm = 3.0125e-01, time/batch = 16.5361s	
10382/11350 (epoch 45.736), train_loss = 0.51930900, grad/param norm = 4.0222e-01, time/batch = 16.3090s	
10383/11350 (epoch 45.740), train_loss = 0.56281659, grad/param norm = 3.3184e-01, time/batch = 16.5572s	
10384/11350 (epoch 45.744), train_loss = 0.55990026, grad/param norm = 3.8848e-01, time/batch = 22.3626s	
10385/11350 (epoch 45.749), train_loss = 0.58116776, grad/param norm = 3.9082e-01, time/batch = 25.8417s	
10386/11350 (epoch 45.753), train_loss = 0.61852646, grad/param norm = 3.8119e-01, time/batch = 16.2667s	
10387/11350 (epoch 45.758), train_loss = 0.57222775, grad/param norm = 3.7619e-01, time/batch = 17.0965s	
10388/11350 (epoch 45.762), train_loss = 0.67936660, grad/param norm = 3.1645e-01, time/batch = 16.8741s	
10389/11350 (epoch 45.767), train_loss = 0.69522412, grad/param norm = 3.0923e-01, time/batch = 16.4727s	
10390/11350 (epoch 45.771), train_loss = 0.77973678, grad/param norm = 4.0486e-01, time/batch = 16.5419s	
10391/11350 (epoch 45.775), train_loss = 0.62649979, grad/param norm = 3.6655e-01, time/batch = 17.0341s	
10392/11350 (epoch 45.780), train_loss = 0.66655441, grad/param norm = 3.3796e-01, time/batch = 16.5499s	
10393/11350 (epoch 45.784), train_loss = 0.58089316, grad/param norm = 3.0638e-01, time/batch = 16.3078s	
10394/11350 (epoch 45.789), train_loss = 0.63104825, grad/param norm = 4.2309e-01, time/batch = 16.6201s	
10395/11350 (epoch 45.793), train_loss = 0.65290635, grad/param norm = 3.2119e-01, time/batch = 16.4006s	
10396/11350 (epoch 45.797), train_loss = 0.61186209, grad/param norm = 2.9279e-01, time/batch = 16.7743s	
10397/11350 (epoch 45.802), train_loss = 0.60351714, grad/param norm = 3.3842e-01, time/batch = 16.4655s	
10398/11350 (epoch 45.806), train_loss = 0.62074280, grad/param norm = 2.7918e-01, time/batch = 16.9482s	
10399/11350 (epoch 45.811), train_loss = 0.60269118, grad/param norm = 2.8165e-01, time/batch = 16.5472s	
10400/11350 (epoch 45.815), train_loss = 0.60046974, grad/param norm = 3.5095e-01, time/batch = 16.5505s	
10401/11350 (epoch 45.819), train_loss = 0.52475483, grad/param norm = 2.9129e-01, time/batch = 17.1720s	
10402/11350 (epoch 45.824), train_loss = 0.52717232, grad/param norm = 3.3120e-01, time/batch = 16.3906s	
10403/11350 (epoch 45.828), train_loss = 0.53475424, grad/param norm = 3.1099e-01, time/batch = 17.0113s	
10404/11350 (epoch 45.833), train_loss = 0.56781526, grad/param norm = 3.1052e-01, time/batch = 16.4716s	
10405/11350 (epoch 45.837), train_loss = 0.58907314, grad/param norm = 3.7635e-01, time/batch = 17.0256s	
10406/11350 (epoch 45.841), train_loss = 0.79312027, grad/param norm = 4.1426e-01, time/batch = 16.3962s	
10407/11350 (epoch 45.846), train_loss = 0.66652137, grad/param norm = 3.3112e-01, time/batch = 16.7193s	
10408/11350 (epoch 45.850), train_loss = 0.66689032, grad/param norm = 3.6798e-01, time/batch = 16.3811s	
10409/11350 (epoch 45.855), train_loss = 0.50374933, grad/param norm = 3.2671e-01, time/batch = 16.5494s	
10410/11350 (epoch 45.859), train_loss = 0.55235925, grad/param norm = 4.3956e-01, time/batch = 16.7723s	
10411/11350 (epoch 45.863), train_loss = 0.52616592, grad/param norm = 4.0197e-01, time/batch = 16.6112s	
10412/11350 (epoch 45.868), train_loss = 0.53231575, grad/param norm = 3.0464e-01, time/batch = 16.6938s	
10413/11350 (epoch 45.872), train_loss = 0.53605651, grad/param norm = 3.2323e-01, time/batch = 16.5321s	
10414/11350 (epoch 45.877), train_loss = 0.53234469, grad/param norm = 3.5264e-01, time/batch = 16.4684s	
10415/11350 (epoch 45.881), train_loss = 0.71099601, grad/param norm = 3.5833e-01, time/batch = 16.1456s	
10416/11350 (epoch 45.885), train_loss = 0.64220983, grad/param norm = 3.1540e-01, time/batch = 16.8732s	
10417/11350 (epoch 45.890), train_loss = 0.61811422, grad/param norm = 3.9632e-01, time/batch = 16.7119s	
10418/11350 (epoch 45.894), train_loss = 0.52900974, grad/param norm = 3.3950e-01, time/batch = 16.5490s	
10419/11350 (epoch 45.899), train_loss = 0.63915026, grad/param norm = 3.2249e-01, time/batch = 17.0012s	
10420/11350 (epoch 45.903), train_loss = 0.60342895, grad/param norm = 3.3020e-01, time/batch = 4.0587s	
10421/11350 (epoch 45.907), train_loss = 0.53061955, grad/param norm = 3.4239e-01, time/batch = 0.7382s	
10422/11350 (epoch 45.912), train_loss = 0.53990362, grad/param norm = 3.4083e-01, time/batch = 0.7398s	
10423/11350 (epoch 45.916), train_loss = 0.59166535, grad/param norm = 3.3899e-01, time/batch = 0.7366s	
10424/11350 (epoch 45.921), train_loss = 0.60010833, grad/param norm = 3.4744e-01, time/batch = 0.7338s	
10425/11350 (epoch 45.925), train_loss = 0.51356347, grad/param norm = 3.0088e-01, time/batch = 0.7351s	
10426/11350 (epoch 45.930), train_loss = 0.58799051, grad/param norm = 3.6751e-01, time/batch = 0.7486s	
10427/11350 (epoch 45.934), train_loss = 0.68049148, grad/param norm = 4.7159e-01, time/batch = 1.0679s	
10428/11350 (epoch 45.938), train_loss = 0.60103325, grad/param norm = 4.2094e-01, time/batch = 1.0789s	
10429/11350 (epoch 45.943), train_loss = 0.64416480, grad/param norm = 3.6804e-01, time/batch = 1.0826s	
10430/11350 (epoch 45.947), train_loss = 0.61057737, grad/param norm = 3.6569e-01, time/batch = 1.0744s	
10431/11350 (epoch 45.952), train_loss = 0.60429152, grad/param norm = 3.1364e-01, time/batch = 1.4827s	
10432/11350 (epoch 45.956), train_loss = 0.51080482, grad/param norm = 2.6442e-01, time/batch = 2.0015s	
10433/11350 (epoch 45.960), train_loss = 0.56452622, grad/param norm = 3.0902e-01, time/batch = 1.9901s	
10434/11350 (epoch 45.965), train_loss = 0.48543433, grad/param norm = 3.1343e-01, time/batch = 15.7060s	
10435/11350 (epoch 45.969), train_loss = 0.48680544, grad/param norm = 3.2106e-01, time/batch = 16.6305s	
10436/11350 (epoch 45.974), train_loss = 0.49455482, grad/param norm = 3.0116e-01, time/batch = 16.8595s	
10437/11350 (epoch 45.978), train_loss = 0.56784339, grad/param norm = 3.4523e-01, time/batch = 17.0920s	
10438/11350 (epoch 45.982), train_loss = 0.39260776, grad/param norm = 2.7390e-01, time/batch = 16.4619s	
10439/11350 (epoch 45.987), train_loss = 0.56932669, grad/param norm = 3.4706e-01, time/batch = 16.4575s	
10440/11350 (epoch 45.991), train_loss = 0.51161658, grad/param norm = 3.6010e-01, time/batch = 16.6354s	
10441/11350 (epoch 45.996), train_loss = 0.53347189, grad/param norm = 3.3321e-01, time/batch = 16.4633s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
10442/11350 (epoch 46.000), train_loss = 0.43290106, grad/param norm = 2.8184e-01, time/batch = 16.4471s	
10443/11350 (epoch 46.004), train_loss = 0.64624399, grad/param norm = 3.6920e-01, time/batch = 16.8558s	
10444/11350 (epoch 46.009), train_loss = 0.58378973, grad/param norm = 3.3362e-01, time/batch = 16.4409s	
10445/11350 (epoch 46.013), train_loss = 0.40445270, grad/param norm = 2.7232e-01, time/batch = 17.1185s	
10446/11350 (epoch 46.018), train_loss = 0.46035708, grad/param norm = 3.2859e-01, time/batch = 16.5395s	
10447/11350 (epoch 46.022), train_loss = 0.49180076, grad/param norm = 3.3875e-01, time/batch = 17.0375s	
10448/11350 (epoch 46.026), train_loss = 0.43806226, grad/param norm = 2.7422e-01, time/batch = 16.6154s	
10449/11350 (epoch 46.031), train_loss = 0.47050264, grad/param norm = 3.2386e-01, time/batch = 16.5500s	
10450/11350 (epoch 46.035), train_loss = 0.50058116, grad/param norm = 2.8390e-01, time/batch = 17.6326s	
10451/11350 (epoch 46.040), train_loss = 0.51175044, grad/param norm = 3.1319e-01, time/batch = 16.4737s	
10452/11350 (epoch 46.044), train_loss = 0.46331028, grad/param norm = 2.4813e-01, time/batch = 16.4743s	
10453/11350 (epoch 46.048), train_loss = 0.46681919, grad/param norm = 3.1585e-01, time/batch = 16.1415s	
10454/11350 (epoch 46.053), train_loss = 0.50697536, grad/param norm = 4.7969e-01, time/batch = 16.5399s	
10455/11350 (epoch 46.057), train_loss = 0.50719710, grad/param norm = 3.8790e-01, time/batch = 16.1442s	
10456/11350 (epoch 46.062), train_loss = 0.43278708, grad/param norm = 3.1636e-01, time/batch = 16.5446s	
10457/11350 (epoch 46.066), train_loss = 0.44931154, grad/param norm = 3.5239e-01, time/batch = 16.4663s	
10458/11350 (epoch 46.070), train_loss = 0.50384404, grad/param norm = 3.7441e-01, time/batch = 16.6283s	
10459/11350 (epoch 46.075), train_loss = 0.45181442, grad/param norm = 3.1797e-01, time/batch = 17.4864s	
10460/11350 (epoch 46.079), train_loss = 0.54829341, grad/param norm = 3.4873e-01, time/batch = 16.4655s	
10461/11350 (epoch 46.084), train_loss = 0.62059372, grad/param norm = 3.8251e-01, time/batch = 16.8637s	
10462/11350 (epoch 46.088), train_loss = 0.57506396, grad/param norm = 3.8153e-01, time/batch = 16.3975s	
10463/11350 (epoch 46.093), train_loss = 0.56797521, grad/param norm = 3.3385e-01, time/batch = 16.6302s	
10464/11350 (epoch 46.097), train_loss = 0.49324857, grad/param norm = 3.4489e-01, time/batch = 16.3722s	
10465/11350 (epoch 46.101), train_loss = 0.49059280, grad/param norm = 3.7140e-01, time/batch = 16.8680s	
10466/11350 (epoch 46.106), train_loss = 0.56063927, grad/param norm = 4.0499e-01, time/batch = 16.3923s	
10467/11350 (epoch 46.110), train_loss = 0.50179076, grad/param norm = 4.3615e-01, time/batch = 16.4606s	
10468/11350 (epoch 46.115), train_loss = 0.50493850, grad/param norm = 3.3822e-01, time/batch = 17.1815s	
10469/11350 (epoch 46.119), train_loss = 0.58782761, grad/param norm = 3.5104e-01, time/batch = 15.9747s	
10470/11350 (epoch 46.123), train_loss = 0.46849628, grad/param norm = 3.3891e-01, time/batch = 16.5546s	
10471/11350 (epoch 46.128), train_loss = 0.42895287, grad/param norm = 3.2773e-01, time/batch = 16.3121s	
10472/11350 (epoch 46.132), train_loss = 0.46562284, grad/param norm = 2.7488e-01, time/batch = 16.8714s	
10473/11350 (epoch 46.137), train_loss = 0.45109755, grad/param norm = 3.5310e-01, time/batch = 16.5419s	
10474/11350 (epoch 46.141), train_loss = 0.60017816, grad/param norm = 3.9892e-01, time/batch = 17.0827s	
10475/11350 (epoch 46.145), train_loss = 0.50894998, grad/param norm = 3.2036e-01, time/batch = 16.6241s	
10476/11350 (epoch 46.150), train_loss = 0.56170081, grad/param norm = 6.9291e-01, time/batch = 16.3831s	
10477/11350 (epoch 46.154), train_loss = 0.62885356, grad/param norm = 4.4933e-01, time/batch = 16.2271s	
10478/11350 (epoch 46.159), train_loss = 0.45593445, grad/param norm = 3.4219e-01, time/batch = 16.3761s	
10479/11350 (epoch 46.163), train_loss = 0.58213059, grad/param norm = 3.6262e-01, time/batch = 17.0339s	
10480/11350 (epoch 46.167), train_loss = 0.59146023, grad/param norm = 3.3896e-01, time/batch = 16.6774s	
10481/11350 (epoch 46.172), train_loss = 0.68850657, grad/param norm = 3.5571e-01, time/batch = 16.3025s	
10482/11350 (epoch 46.176), train_loss = 0.53830976, grad/param norm = 3.3494e-01, time/batch = 16.3089s	
10483/11350 (epoch 46.181), train_loss = 0.51888981, grad/param norm = 5.2123e-01, time/batch = 16.5460s	
10484/11350 (epoch 46.185), train_loss = 0.50335929, grad/param norm = 3.3685e-01, time/batch = 16.7783s	
10485/11350 (epoch 46.189), train_loss = 0.46857207, grad/param norm = 3.1499e-01, time/batch = 16.4799s	
10486/11350 (epoch 46.194), train_loss = 0.43558928, grad/param norm = 4.0059e-01, time/batch = 17.3349s	
10487/11350 (epoch 46.198), train_loss = 0.40144313, grad/param norm = 4.3196e-01, time/batch = 16.2257s	
10488/11350 (epoch 46.203), train_loss = 0.49713831, grad/param norm = 3.5324e-01, time/batch = 16.4695s	
10489/11350 (epoch 46.207), train_loss = 0.44063764, grad/param norm = 4.2355e-01, time/batch = 16.5302s	
10490/11350 (epoch 46.211), train_loss = 0.57541368, grad/param norm = 3.5644e-01, time/batch = 16.9996s	
10491/11350 (epoch 46.216), train_loss = 0.55094174, grad/param norm = 3.2663e-01, time/batch = 16.6371s	
10492/11350 (epoch 46.220), train_loss = 0.55693115, grad/param norm = 3.3031e-01, time/batch = 16.7231s	
10493/11350 (epoch 46.225), train_loss = 0.50543093, grad/param norm = 3.2956e-01, time/batch = 16.6291s	
10494/11350 (epoch 46.229), train_loss = 0.53858177, grad/param norm = 3.3938e-01, time/batch = 16.8010s	
10495/11350 (epoch 46.233), train_loss = 0.51005542, grad/param norm = 3.7121e-01, time/batch = 16.2238s	
10496/11350 (epoch 46.238), train_loss = 0.59365017, grad/param norm = 3.9563e-01, time/batch = 16.1476s	
10497/11350 (epoch 46.242), train_loss = 0.59594666, grad/param norm = 3.7400e-01, time/batch = 16.7832s	
10498/11350 (epoch 46.247), train_loss = 0.44121787, grad/param norm = 2.8626e-01, time/batch = 16.4822s	
10499/11350 (epoch 46.251), train_loss = 0.50291696, grad/param norm = 3.6004e-01, time/batch = 16.7225s	
10500/11350 (epoch 46.256), train_loss = 0.56187077, grad/param norm = 4.0996e-01, time/batch = 17.3961s	
10501/11350 (epoch 46.260), train_loss = 0.51211083, grad/param norm = 3.4501e-01, time/batch = 16.8012s	
10502/11350 (epoch 46.264), train_loss = 0.46779167, grad/param norm = 3.4345e-01, time/batch = 16.5442s	
10503/11350 (epoch 46.269), train_loss = 0.50903503, grad/param norm = 2.7067e-01, time/batch = 16.4763s	
10504/11350 (epoch 46.273), train_loss = 0.58635884, grad/param norm = 3.2574e-01, time/batch = 17.1706s	
10505/11350 (epoch 46.278), train_loss = 0.49810897, grad/param norm = 3.2053e-01, time/batch = 16.1417s	
10506/11350 (epoch 46.282), train_loss = 0.49348402, grad/param norm = 3.6027e-01, time/batch = 16.4712s	
10507/11350 (epoch 46.286), train_loss = 0.58860886, grad/param norm = 3.1842e-01, time/batch = 16.5468s	
10508/11350 (epoch 46.291), train_loss = 0.48314157, grad/param norm = 3.9978e-01, time/batch = 16.3070s	
10509/11350 (epoch 46.295), train_loss = 0.47302328, grad/param norm = 3.3198e-01, time/batch = 16.2134s	
10510/11350 (epoch 46.300), train_loss = 0.55931509, grad/param norm = 3.7484e-01, time/batch = 16.2146s	
10511/11350 (epoch 46.304), train_loss = 0.46615812, grad/param norm = 3.3973e-01, time/batch = 16.5971s	
10512/11350 (epoch 46.308), train_loss = 0.47766364, grad/param norm = 4.5599e-01, time/batch = 16.0723s	
10513/11350 (epoch 46.313), train_loss = 0.52991698, grad/param norm = 3.2089e-01, time/batch = 16.0643s	
10514/11350 (epoch 46.317), train_loss = 0.53052036, grad/param norm = 3.1036e-01, time/batch = 16.1461s	
10515/11350 (epoch 46.322), train_loss = 0.50525910, grad/param norm = 3.4236e-01, time/batch = 16.7903s	
10516/11350 (epoch 46.326), train_loss = 0.52734015, grad/param norm = 3.4977e-01, time/batch = 16.2367s	
10517/11350 (epoch 46.330), train_loss = 0.43626598, grad/param norm = 2.6547e-01, time/batch = 16.1511s	
10518/11350 (epoch 46.335), train_loss = 0.35650400, grad/param norm = 2.6522e-01, time/batch = 16.3103s	
10519/11350 (epoch 46.339), train_loss = 0.37432907, grad/param norm = 2.9096e-01, time/batch = 16.8544s	
10520/11350 (epoch 46.344), train_loss = 0.45373894, grad/param norm = 2.9792e-01, time/batch = 16.6355s	
10521/11350 (epoch 46.348), train_loss = 0.49447300, grad/param norm = 3.4491e-01, time/batch = 16.4707s	
10522/11350 (epoch 46.352), train_loss = 0.39231735, grad/param norm = 3.1378e-01, time/batch = 17.5906s	
10523/11350 (epoch 46.357), train_loss = 0.46977832, grad/param norm = 2.5383e-01, time/batch = 16.9940s	
10524/11350 (epoch 46.361), train_loss = 0.40075423, grad/param norm = 2.6673e-01, time/batch = 16.2216s	
10525/11350 (epoch 46.366), train_loss = 0.46306554, grad/param norm = 3.6151e-01, time/batch = 16.5577s	
10526/11350 (epoch 46.370), train_loss = 0.40139580, grad/param norm = 2.7975e-01, time/batch = 16.9336s	
10527/11350 (epoch 46.374), train_loss = 0.45194626, grad/param norm = 3.7482e-01, time/batch = 16.3894s	
10528/11350 (epoch 46.379), train_loss = 0.46398064, grad/param norm = 3.2123e-01, time/batch = 16.3171s	
10529/11350 (epoch 46.383), train_loss = 0.40144901, grad/param norm = 3.3734e-01, time/batch = 16.6234s	
10530/11350 (epoch 46.388), train_loss = 0.46633783, grad/param norm = 4.1190e-01, time/batch = 16.5435s	
10531/11350 (epoch 46.392), train_loss = 0.54281487, grad/param norm = 3.4835e-01, time/batch = 16.7854s	
10532/11350 (epoch 46.396), train_loss = 0.44634918, grad/param norm = 3.5491e-01, time/batch = 16.8248s	
10533/11350 (epoch 46.401), train_loss = 0.45442131, grad/param norm = 3.5836e-01, time/batch = 17.0167s	
10534/11350 (epoch 46.405), train_loss = 0.60018749, grad/param norm = 3.4656e-01, time/batch = 16.1351s	
10535/11350 (epoch 46.410), train_loss = 0.63706539, grad/param norm = 3.8042e-01, time/batch = 16.2278s	
10536/11350 (epoch 46.414), train_loss = 0.43768325, grad/param norm = 3.4173e-01, time/batch = 16.2992s	
10537/11350 (epoch 46.419), train_loss = 0.42843453, grad/param norm = 3.4919e-01, time/batch = 17.1312s	
10538/11350 (epoch 46.423), train_loss = 0.44227199, grad/param norm = 3.9641e-01, time/batch = 16.2992s	
10539/11350 (epoch 46.427), train_loss = 0.53039227, grad/param norm = 4.2828e-01, time/batch = 16.7061s	
10540/11350 (epoch 46.432), train_loss = 0.50257540, grad/param norm = 3.2872e-01, time/batch = 17.1693s	
10541/11350 (epoch 46.436), train_loss = 0.40935358, grad/param norm = 3.3293e-01, time/batch = 16.2110s	
10542/11350 (epoch 46.441), train_loss = 0.56379956, grad/param norm = 4.1367e-01, time/batch = 16.1500s	
10543/11350 (epoch 46.445), train_loss = 0.45201214, grad/param norm = 2.8410e-01, time/batch = 16.2144s	
10544/11350 (epoch 46.449), train_loss = 0.52175637, grad/param norm = 3.0229e-01, time/batch = 16.6900s	
10545/11350 (epoch 46.454), train_loss = 0.61913204, grad/param norm = 4.2950e-01, time/batch = 16.4621s	
10546/11350 (epoch 46.458), train_loss = 0.43241709, grad/param norm = 3.0279e-01, time/batch = 16.9102s	
10547/11350 (epoch 46.463), train_loss = 0.45187050, grad/param norm = 3.7853e-01, time/batch = 16.2923s	
10548/11350 (epoch 46.467), train_loss = 0.64229784, grad/param norm = 3.6697e-01, time/batch = 16.2190s	
10549/11350 (epoch 46.471), train_loss = 0.62986335, grad/param norm = 4.6080e-01, time/batch = 16.2980s	
10550/11350 (epoch 46.476), train_loss = 0.52249692, grad/param norm = 3.3063e-01, time/batch = 17.0072s	
10551/11350 (epoch 46.480), train_loss = 0.57636604, grad/param norm = 3.1829e-01, time/batch = 16.9543s	
10552/11350 (epoch 46.485), train_loss = 0.53698129, grad/param norm = 3.6571e-01, time/batch = 16.0614s	
10553/11350 (epoch 46.489), train_loss = 0.56703754, grad/param norm = 3.7954e-01, time/batch = 16.4563s	
10554/11350 (epoch 46.493), train_loss = 0.61026425, grad/param norm = 4.1340e-01, time/batch = 16.1425s	
10555/11350 (epoch 46.498), train_loss = 0.38781463, grad/param norm = 2.8199e-01, time/batch = 16.6992s	
10556/11350 (epoch 46.502), train_loss = 0.63489250, grad/param norm = 3.7638e-01, time/batch = 16.3029s	
10557/11350 (epoch 46.507), train_loss = 0.44949380, grad/param norm = 2.7686e-01, time/batch = 16.1436s	
10558/11350 (epoch 46.511), train_loss = 0.56198566, grad/param norm = 3.5731e-01, time/batch = 17.5762s	
10559/11350 (epoch 46.515), train_loss = 0.52639653, grad/param norm = 3.5243e-01, time/batch = 16.3948s	
10560/11350 (epoch 46.520), train_loss = 0.65145689, grad/param norm = 3.4890e-01, time/batch = 16.7863s	
10561/11350 (epoch 46.524), train_loss = 0.57861702, grad/param norm = 2.9376e-01, time/batch = 16.4656s	
10562/11350 (epoch 46.529), train_loss = 0.48632040, grad/param norm = 2.9266e-01, time/batch = 16.8632s	
10563/11350 (epoch 46.533), train_loss = 0.66896629, grad/param norm = 3.7045e-01, time/batch = 16.1402s	
10564/11350 (epoch 46.537), train_loss = 0.62456513, grad/param norm = 3.9938e-01, time/batch = 16.5608s	
10565/11350 (epoch 46.542), train_loss = 0.50418473, grad/param norm = 2.9875e-01, time/batch = 16.8431s	
10566/11350 (epoch 46.546), train_loss = 0.64792141, grad/param norm = 3.7847e-01, time/batch = 16.5464s	
10567/11350 (epoch 46.551), train_loss = 0.58968541, grad/param norm = 4.1679e-01, time/batch = 16.4622s	
10568/11350 (epoch 46.555), train_loss = 0.45822084, grad/param norm = 2.9985e-01, time/batch = 16.4757s	
10569/11350 (epoch 46.559), train_loss = 0.54523709, grad/param norm = 3.4780e-01, time/batch = 17.0390s	
10570/11350 (epoch 46.564), train_loss = 0.56475052, grad/param norm = 3.6664e-01, time/batch = 17.3370s	
10571/11350 (epoch 46.568), train_loss = 0.55909107, grad/param norm = 3.1969e-01, time/batch = 16.5425s	
10572/11350 (epoch 46.573), train_loss = 0.67296241, grad/param norm = 4.2309e-01, time/batch = 16.8630s	
10573/11350 (epoch 46.577), train_loss = 0.58660683, grad/param norm = 3.8976e-01, time/batch = 16.8024s	
10574/11350 (epoch 46.581), train_loss = 0.66871946, grad/param norm = 3.4484e-01, time/batch = 16.9504s	
10575/11350 (epoch 46.586), train_loss = 0.60921343, grad/param norm = 3.7955e-01, time/batch = 16.3856s	
10576/11350 (epoch 46.590), train_loss = 0.64817012, grad/param norm = 4.2411e-01, time/batch = 17.3404s	
10577/11350 (epoch 46.595), train_loss = 0.75719818, grad/param norm = 3.6251e-01, time/batch = 16.5552s	
10578/11350 (epoch 46.599), train_loss = 0.54929555, grad/param norm = 3.5467e-01, time/batch = 16.7166s	
10579/11350 (epoch 46.604), train_loss = 0.56727199, grad/param norm = 3.5405e-01, time/batch = 16.4674s	
10580/11350 (epoch 46.608), train_loss = 0.53955172, grad/param norm = 4.3066e-01, time/batch = 17.0966s	
10581/11350 (epoch 46.612), train_loss = 0.58493344, grad/param norm = 3.7773e-01, time/batch = 16.7129s	
10582/11350 (epoch 46.617), train_loss = 0.67141690, grad/param norm = 4.0901e-01, time/batch = 16.9260s	
10583/11350 (epoch 46.621), train_loss = 0.64641696, grad/param norm = 3.4142e-01, time/batch = 17.4135s	
10584/11350 (epoch 46.626), train_loss = 0.57729271, grad/param norm = 4.5690e-01, time/batch = 16.8632s	
10585/11350 (epoch 46.630), train_loss = 0.58027486, grad/param norm = 4.2367e-01, time/batch = 16.5473s	
10586/11350 (epoch 46.634), train_loss = 0.57615560, grad/param norm = 4.6204e-01, time/batch = 16.5447s	
10587/11350 (epoch 46.639), train_loss = 0.54229366, grad/param norm = 3.3515e-01, time/batch = 16.6985s	
10588/11350 (epoch 46.643), train_loss = 0.48979160, grad/param norm = 3.4546e-01, time/batch = 16.6903s	
10589/11350 (epoch 46.648), train_loss = 0.56292649, grad/param norm = 3.5358e-01, time/batch = 16.4678s	
10590/11350 (epoch 46.652), train_loss = 0.49383470, grad/param norm = 3.5031e-01, time/batch = 16.8557s	
10591/11350 (epoch 46.656), train_loss = 0.58578820, grad/param norm = 3.1339e-01, time/batch = 16.7075s	
10592/11350 (epoch 46.661), train_loss = 0.58716863, grad/param norm = 4.1313e-01, time/batch = 16.5428s	
10593/11350 (epoch 46.665), train_loss = 0.58901674, grad/param norm = 3.9982e-01, time/batch = 16.3060s	
10594/11350 (epoch 46.670), train_loss = 0.58743834, grad/param norm = 3.3337e-01, time/batch = 17.1042s	
10595/11350 (epoch 46.674), train_loss = 0.56139707, grad/param norm = 3.2178e-01, time/batch = 16.8756s	
10596/11350 (epoch 46.678), train_loss = 0.60622369, grad/param norm = 3.9390e-01, time/batch = 16.7731s	
10597/11350 (epoch 46.683), train_loss = 0.55621494, grad/param norm = 4.1546e-01, time/batch = 16.7873s	
10598/11350 (epoch 46.687), train_loss = 0.48674981, grad/param norm = 3.1323e-01, time/batch = 16.7939s	
10599/11350 (epoch 46.692), train_loss = 0.73794731, grad/param norm = 4.4151e-01, time/batch = 16.7190s	
10600/11350 (epoch 46.696), train_loss = 0.73557491, grad/param norm = 3.6570e-01, time/batch = 16.4768s	
10601/11350 (epoch 46.700), train_loss = 0.65084796, grad/param norm = 3.7895e-01, time/batch = 16.7094s	
10602/11350 (epoch 46.705), train_loss = 0.65481845, grad/param norm = 3.4530e-01, time/batch = 16.6008s	
10603/11350 (epoch 46.709), train_loss = 0.65936755, grad/param norm = 3.9340e-01, time/batch = 16.7868s	
10604/11350 (epoch 46.714), train_loss = 0.58087350, grad/param norm = 3.4778e-01, time/batch = 16.5507s	
10605/11350 (epoch 46.718), train_loss = 0.51468114, grad/param norm = 3.0511e-01, time/batch = 16.7111s	
10606/11350 (epoch 46.722), train_loss = 0.55946678, grad/param norm = 3.9366e-01, time/batch = 16.6436s	
10607/11350 (epoch 46.727), train_loss = 0.59758365, grad/param norm = 3.4154e-01, time/batch = 16.3816s	
10608/11350 (epoch 46.731), train_loss = 0.55055414, grad/param norm = 3.2888e-01, time/batch = 17.0121s	
10609/11350 (epoch 46.736), train_loss = 0.50101170, grad/param norm = 3.2110e-01, time/batch = 16.8558s	
10610/11350 (epoch 46.740), train_loss = 0.55464119, grad/param norm = 3.3786e-01, time/batch = 16.7057s	
10611/11350 (epoch 46.744), train_loss = 0.54527477, grad/param norm = 3.8136e-01, time/batch = 16.8690s	
10612/11350 (epoch 46.749), train_loss = 0.55990183, grad/param norm = 3.8813e-01, time/batch = 37.8526s	
10613/11350 (epoch 46.753), train_loss = 0.61494137, grad/param norm = 4.2992e-01, time/batch = 16.6310s	
10614/11350 (epoch 46.758), train_loss = 0.56351659, grad/param norm = 3.9490e-01, time/batch = 17.0136s	
10615/11350 (epoch 46.762), train_loss = 0.66464638, grad/param norm = 3.5376e-01, time/batch = 16.9268s	
10616/11350 (epoch 46.767), train_loss = 0.68601103, grad/param norm = 3.4495e-01, time/batch = 16.6421s	
10617/11350 (epoch 46.771), train_loss = 0.75204373, grad/param norm = 3.8725e-01, time/batch = 16.8018s	
10618/11350 (epoch 46.775), train_loss = 0.61417410, grad/param norm = 3.5548e-01, time/batch = 17.0976s	
10619/11350 (epoch 46.780), train_loss = 0.62833638, grad/param norm = 3.5427e-01, time/batch = 16.6351s	
10620/11350 (epoch 46.784), train_loss = 0.58928052, grad/param norm = 3.8881e-01, time/batch = 16.8860s	
10621/11350 (epoch 46.789), train_loss = 0.60483225, grad/param norm = 3.7618e-01, time/batch = 16.9596s	
10622/11350 (epoch 46.793), train_loss = 0.64837597, grad/param norm = 3.3001e-01, time/batch = 16.5598s	
10623/11350 (epoch 46.797), train_loss = 0.61172468, grad/param norm = 2.8107e-01, time/batch = 16.8805s	
10624/11350 (epoch 46.802), train_loss = 0.59735522, grad/param norm = 3.3868e-01, time/batch = 16.3981s	
10625/11350 (epoch 46.806), train_loss = 0.61446846, grad/param norm = 2.9627e-01, time/batch = 17.4140s	
10626/11350 (epoch 46.811), train_loss = 0.59908895, grad/param norm = 2.7123e-01, time/batch = 16.8694s	
10627/11350 (epoch 46.815), train_loss = 0.57904207, grad/param norm = 3.1732e-01, time/batch = 16.7265s	
10628/11350 (epoch 46.819), train_loss = 0.51991003, grad/param norm = 3.4037e-01, time/batch = 17.5006s	
10629/11350 (epoch 46.824), train_loss = 0.51187892, grad/param norm = 3.2657e-01, time/batch = 17.0339s	
10630/11350 (epoch 46.828), train_loss = 0.54542646, grad/param norm = 3.3333e-01, time/batch = 16.8759s	
10631/11350 (epoch 46.833), train_loss = 0.56030820, grad/param norm = 3.0449e-01, time/batch = 16.8094s	
10632/11350 (epoch 46.837), train_loss = 0.59168287, grad/param norm = 3.8276e-01, time/batch = 16.9361s	
10633/11350 (epoch 46.841), train_loss = 0.79272655, grad/param norm = 4.6149e-01, time/batch = 16.6425s	
10634/11350 (epoch 46.846), train_loss = 0.64580508, grad/param norm = 3.2221e-01, time/batch = 16.8013s	
10635/11350 (epoch 46.850), train_loss = 0.64638129, grad/param norm = 3.6549e-01, time/batch = 16.7856s	
10636/11350 (epoch 46.855), train_loss = 0.48560982, grad/param norm = 3.1691e-01, time/batch = 16.4737s	
10637/11350 (epoch 46.859), train_loss = 0.52332038, grad/param norm = 3.9150e-01, time/batch = 17.0413s	
10638/11350 (epoch 46.863), train_loss = 0.51365585, grad/param norm = 3.4952e-01, time/batch = 16.5596s	
10639/11350 (epoch 46.868), train_loss = 0.51677035, grad/param norm = 3.1057e-01, time/batch = 16.9886s	
10640/11350 (epoch 46.872), train_loss = 0.51807641, grad/param norm = 3.2260e-01, time/batch = 16.0629s	
10641/11350 (epoch 46.877), train_loss = 0.53050649, grad/param norm = 4.0146e-01, time/batch = 16.3821s	
10642/11350 (epoch 46.881), train_loss = 0.72107862, grad/param norm = 4.9322e-01, time/batch = 16.4636s	
10643/11350 (epoch 46.885), train_loss = 0.63963666, grad/param norm = 3.4985e-01, time/batch = 16.8734s	
10644/11350 (epoch 46.890), train_loss = 0.61716321, grad/param norm = 3.9721e-01, time/batch = 17.0142s	
10645/11350 (epoch 46.894), train_loss = 0.51803806, grad/param norm = 3.1914e-01, time/batch = 16.4418s	
10646/11350 (epoch 46.899), train_loss = 0.61849893, grad/param norm = 3.2105e-01, time/batch = 17.1668s	
10647/11350 (epoch 46.903), train_loss = 0.58771000, grad/param norm = 3.5538e-01, time/batch = 16.3855s	
10648/11350 (epoch 46.907), train_loss = 0.52570326, grad/param norm = 3.4772e-01, time/batch = 16.8671s	
10649/11350 (epoch 46.912), train_loss = 0.52480756, grad/param norm = 3.1101e-01, time/batch = 16.6785s	
10650/11350 (epoch 46.916), train_loss = 0.57513153, grad/param norm = 3.3968e-01, time/batch = 16.9437s	
10651/11350 (epoch 46.921), train_loss = 0.58556922, grad/param norm = 3.4430e-01, time/batch = 16.7098s	
10652/11350 (epoch 46.925), train_loss = 0.51254883, grad/param norm = 2.9295e-01, time/batch = 16.3959s	
10653/11350 (epoch 46.930), train_loss = 0.58088246, grad/param norm = 4.8470e-01, time/batch = 17.0349s	
10654/11350 (epoch 46.934), train_loss = 0.67476614, grad/param norm = 4.3011e-01, time/batch = 16.7918s	
10655/11350 (epoch 46.938), train_loss = 0.61659844, grad/param norm = 4.3149e-01, time/batch = 16.3966s	
10656/11350 (epoch 46.943), train_loss = 0.63910001, grad/param norm = 4.3620e-01, time/batch = 16.4741s	
10657/11350 (epoch 46.947), train_loss = 0.60652660, grad/param norm = 3.7927e-01, time/batch = 16.8656s	
10658/11350 (epoch 46.952), train_loss = 0.62751250, grad/param norm = 3.8379e-01, time/batch = 17.0481s	
10659/11350 (epoch 46.956), train_loss = 0.50309001, grad/param norm = 2.8693e-01, time/batch = 16.4572s	
10660/11350 (epoch 46.960), train_loss = 0.56488008, grad/param norm = 3.9868e-01, time/batch = 16.5467s	
10661/11350 (epoch 46.965), train_loss = 0.48059826, grad/param norm = 3.3487e-01, time/batch = 16.9732s	
10662/11350 (epoch 46.969), train_loss = 0.47159389, grad/param norm = 3.2744e-01, time/batch = 17.1853s	
10663/11350 (epoch 46.974), train_loss = 0.47435838, grad/param norm = 3.0649e-01, time/batch = 16.7777s	
10664/11350 (epoch 46.978), train_loss = 0.54575590, grad/param norm = 2.7819e-01, time/batch = 17.2478s	
10665/11350 (epoch 46.982), train_loss = 0.37942196, grad/param norm = 2.7431e-01, time/batch = 16.6999s	
10666/11350 (epoch 46.987), train_loss = 0.56947953, grad/param norm = 3.4448e-01, time/batch = 16.7105s	
10667/11350 (epoch 46.991), train_loss = 0.48898067, grad/param norm = 3.5193e-01, time/batch = 16.6202s	
10668/11350 (epoch 46.996), train_loss = 0.53071648, grad/param norm = 3.5950e-01, time/batch = 16.8386s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
10669/11350 (epoch 47.000), train_loss = 0.43266369, grad/param norm = 3.2206e-01, time/batch = 16.5480s	
10670/11350 (epoch 47.004), train_loss = 0.62662977, grad/param norm = 3.4915e-01, time/batch = 16.4638s	
10671/11350 (epoch 47.009), train_loss = 0.57670422, grad/param norm = 3.3151e-01, time/batch = 16.9532s	
10672/11350 (epoch 47.013), train_loss = 0.39821051, grad/param norm = 2.8665e-01, time/batch = 16.5603s	
10673/11350 (epoch 47.018), train_loss = 0.44817816, grad/param norm = 3.0636e-01, time/batch = 17.1124s	
10674/11350 (epoch 47.022), train_loss = 0.47916258, grad/param norm = 4.7860e-01, time/batch = 17.0224s	
10675/11350 (epoch 47.026), train_loss = 0.43276726, grad/param norm = 3.4660e-01, time/batch = 16.7949s	
10676/11350 (epoch 47.031), train_loss = 0.45187558, grad/param norm = 2.8230e-01, time/batch = 16.2155s	
10677/11350 (epoch 47.035), train_loss = 0.49674593, grad/param norm = 3.2897e-01, time/batch = 16.5625s	
10678/11350 (epoch 47.040), train_loss = 0.49901899, grad/param norm = 2.6150e-01, time/batch = 16.9502s	
10679/11350 (epoch 47.044), train_loss = 0.45960087, grad/param norm = 2.9139e-01, time/batch = 16.2302s	
10680/11350 (epoch 47.048), train_loss = 0.44451255, grad/param norm = 2.5572e-01, time/batch = 16.3864s	
10681/11350 (epoch 47.053), train_loss = 0.49746249, grad/param norm = 2.9377e-01, time/batch = 16.8584s	
10682/11350 (epoch 47.057), train_loss = 0.50322428, grad/param norm = 4.2204e-01, time/batch = 16.7659s	
10683/11350 (epoch 47.062), train_loss = 0.42181943, grad/param norm = 2.8902e-01, time/batch = 16.6261s	
10684/11350 (epoch 47.066), train_loss = 0.43909517, grad/param norm = 3.2783e-01, time/batch = 16.4682s	
10685/11350 (epoch 47.070), train_loss = 0.49912353, grad/param norm = 3.3717e-01, time/batch = 17.0354s	
10686/11350 (epoch 47.075), train_loss = 0.43257490, grad/param norm = 2.5996e-01, time/batch = 16.6301s	
10687/11350 (epoch 47.079), train_loss = 0.53595812, grad/param norm = 3.8549e-01, time/batch = 16.8761s	
10688/11350 (epoch 47.084), train_loss = 0.61558254, grad/param norm = 4.1131e-01, time/batch = 16.5559s	
10689/11350 (epoch 47.088), train_loss = 0.56949675, grad/param norm = 3.7917e-01, time/batch = 16.7744s	
10690/11350 (epoch 47.093), train_loss = 0.56356343, grad/param norm = 3.5500e-01, time/batch = 16.3142s	
10691/11350 (epoch 47.097), train_loss = 0.49676878, grad/param norm = 4.0224e-01, time/batch = 16.3845s	
10692/11350 (epoch 47.101), train_loss = 0.48500663, grad/param norm = 3.6534e-01, time/batch = 16.5306s	
10693/11350 (epoch 47.106), train_loss = 0.54648018, grad/param norm = 3.3196e-01, time/batch = 17.2307s	
10694/11350 (epoch 47.110), train_loss = 0.49096221, grad/param norm = 3.7865e-01, time/batch = 16.3945s	
10695/11350 (epoch 47.115), train_loss = 0.49211663, grad/param norm = 3.3950e-01, time/batch = 16.3136s	
10696/11350 (epoch 47.119), train_loss = 0.58639104, grad/param norm = 3.5682e-01, time/batch = 16.5301s	
10697/11350 (epoch 47.123), train_loss = 0.46853847, grad/param norm = 3.8862e-01, time/batch = 16.1462s	
10698/11350 (epoch 47.128), train_loss = 0.42456205, grad/param norm = 3.2817e-01, time/batch = 16.4526s	
10699/11350 (epoch 47.132), train_loss = 0.46096718, grad/param norm = 2.9883e-01, time/batch = 16.7058s	
10700/11350 (epoch 47.137), train_loss = 0.43508480, grad/param norm = 2.7096e-01, time/batch = 17.8860s	
10701/11350 (epoch 47.141), train_loss = 0.57554963, grad/param norm = 3.9611e-01, time/batch = 16.7094s	
10702/11350 (epoch 47.145), train_loss = 0.49275308, grad/param norm = 3.3267e-01, time/batch = 16.3103s	
10703/11350 (epoch 47.150), train_loss = 0.55125011, grad/param norm = 5.9651e-01, time/batch = 16.9591s	
10704/11350 (epoch 47.154), train_loss = 0.62291678, grad/param norm = 3.7802e-01, time/batch = 16.3861s	
10705/11350 (epoch 47.159), train_loss = 0.46834864, grad/param norm = 3.8291e-01, time/batch = 16.4902s	
10706/11350 (epoch 47.163), train_loss = 0.55444896, grad/param norm = 3.4175e-01, time/batch = 16.3952s	
10707/11350 (epoch 47.167), train_loss = 0.59250389, grad/param norm = 3.8916e-01, time/batch = 16.7831s	
10708/11350 (epoch 47.172), train_loss = 0.70312056, grad/param norm = 3.6166e-01, time/batch = 16.6332s	
10709/11350 (epoch 47.176), train_loss = 0.52894093, grad/param norm = 3.4135e-01, time/batch = 16.4605s	
10710/11350 (epoch 47.181), train_loss = 0.50423027, grad/param norm = 4.1782e-01, time/batch = 16.6343s	
10711/11350 (epoch 47.185), train_loss = 0.47868100, grad/param norm = 3.0565e-01, time/batch = 17.0726s	
10712/11350 (epoch 47.189), train_loss = 0.45594087, grad/param norm = 2.9282e-01, time/batch = 16.7915s	
10713/11350 (epoch 47.194), train_loss = 0.41846766, grad/param norm = 3.6734e-01, time/batch = 16.0523s	
10714/11350 (epoch 47.198), train_loss = 0.39178706, grad/param norm = 3.7189e-01, time/batch = 16.9459s	
10715/11350 (epoch 47.203), train_loss = 0.47366982, grad/param norm = 3.1221e-01, time/batch = 16.1401s	
10716/11350 (epoch 47.207), train_loss = 0.43270768, grad/param norm = 3.4506e-01, time/batch = 16.3747s	
10717/11350 (epoch 47.211), train_loss = 0.57582792, grad/param norm = 4.1857e-01, time/batch = 16.7930s	
10718/11350 (epoch 47.216), train_loss = 0.54993018, grad/param norm = 3.8990e-01, time/batch = 16.9426s	
10719/11350 (epoch 47.220), train_loss = 0.55600015, grad/param norm = 3.7884e-01, time/batch = 16.7042s	
10720/11350 (epoch 47.225), train_loss = 0.49714933, grad/param norm = 3.2367e-01, time/batch = 16.3776s	
10721/11350 (epoch 47.229), train_loss = 0.52466494, grad/param norm = 3.5795e-01, time/batch = 16.9385s	
10722/11350 (epoch 47.233), train_loss = 0.51025857, grad/param norm = 3.7541e-01, time/batch = 16.2908s	
10723/11350 (epoch 47.238), train_loss = 0.56221344, grad/param norm = 3.4121e-01, time/batch = 16.6252s	
10724/11350 (epoch 47.242), train_loss = 0.59124224, grad/param norm = 3.8272e-01, time/batch = 16.4496s	
10725/11350 (epoch 47.247), train_loss = 0.43423525, grad/param norm = 2.5986e-01, time/batch = 17.7269s	
10726/11350 (epoch 47.251), train_loss = 0.50232901, grad/param norm = 3.5639e-01, time/batch = 16.7228s	
10727/11350 (epoch 47.256), train_loss = 0.55170558, grad/param norm = 3.4346e-01, time/batch = 16.7856s	
10728/11350 (epoch 47.260), train_loss = 0.47567537, grad/param norm = 3.0501e-01, time/batch = 16.3773s	
10729/11350 (epoch 47.264), train_loss = 0.45493824, grad/param norm = 3.4277e-01, time/batch = 16.8051s	
10730/11350 (epoch 47.269), train_loss = 0.51102004, grad/param norm = 3.1924e-01, time/batch = 16.8756s	
10731/11350 (epoch 47.273), train_loss = 0.57802078, grad/param norm = 3.0655e-01, time/batch = 16.6147s	
10732/11350 (epoch 47.278), train_loss = 0.48607997, grad/param norm = 2.7867e-01, time/batch = 17.1033s	
10733/11350 (epoch 47.282), train_loss = 0.47584316, grad/param norm = 3.4593e-01, time/batch = 16.4810s	
10734/11350 (epoch 47.286), train_loss = 0.57951847, grad/param norm = 3.4737e-01, time/batch = 16.7897s	
10735/11350 (epoch 47.291), train_loss = 0.47841275, grad/param norm = 3.3318e-01, time/batch = 16.9391s	
10736/11350 (epoch 47.295), train_loss = 0.49278554, grad/param norm = 4.0759e-01, time/batch = 16.7076s	
10737/11350 (epoch 47.300), train_loss = 0.57720982, grad/param norm = 4.2686e-01, time/batch = 16.5332s	
10738/11350 (epoch 47.304), train_loss = 0.46023497, grad/param norm = 3.5440e-01, time/batch = 16.5327s	
10739/11350 (epoch 47.308), train_loss = 0.47147178, grad/param norm = 4.1444e-01, time/batch = 16.9542s	
10740/11350 (epoch 47.313), train_loss = 0.52163059, grad/param norm = 3.3345e-01, time/batch = 16.3784s	
10741/11350 (epoch 47.317), train_loss = 0.51259562, grad/param norm = 3.2283e-01, time/batch = 16.5530s	
10742/11350 (epoch 47.322), train_loss = 0.49569049, grad/param norm = 4.6494e-01, time/batch = 16.6279s	
10743/11350 (epoch 47.326), train_loss = 0.51529566, grad/param norm = 3.0408e-01, time/batch = 16.8773s	
10744/11350 (epoch 47.330), train_loss = 0.43724422, grad/param norm = 2.7831e-01, time/batch = 16.4734s	
10745/11350 (epoch 47.335), train_loss = 0.34043771, grad/param norm = 3.0038e-01, time/batch = 16.6298s	
10746/11350 (epoch 47.339), train_loss = 0.37006853, grad/param norm = 3.0672e-01, time/batch = 16.8718s	
10747/11350 (epoch 47.344), train_loss = 0.43518550, grad/param norm = 2.6287e-01, time/batch = 16.4749s	
10748/11350 (epoch 47.348), train_loss = 0.47032776, grad/param norm = 2.8027e-01, time/batch = 17.0920s	
10749/11350 (epoch 47.352), train_loss = 0.37432226, grad/param norm = 2.7373e-01, time/batch = 16.4599s	
10750/11350 (epoch 47.357), train_loss = 0.46048449, grad/param norm = 2.7337e-01, time/batch = 16.6081s	
10751/11350 (epoch 47.361), train_loss = 0.39453945, grad/param norm = 2.6283e-01, time/batch = 16.4618s	
10752/11350 (epoch 47.366), train_loss = 0.44723607, grad/param norm = 3.0338e-01, time/batch = 16.8520s	
10753/11350 (epoch 47.370), train_loss = 0.39856915, grad/param norm = 2.9089e-01, time/batch = 17.1631s	
10754/11350 (epoch 47.374), train_loss = 0.44834040, grad/param norm = 3.3941e-01, time/batch = 16.7881s	
10755/11350 (epoch 47.379), train_loss = 0.45061821, grad/param norm = 3.4442e-01, time/batch = 16.5575s	
10756/11350 (epoch 47.383), train_loss = 0.39225238, grad/param norm = 3.0031e-01, time/batch = 16.3054s	
10757/11350 (epoch 47.388), train_loss = 0.44628460, grad/param norm = 3.3060e-01, time/batch = 17.1804s	
10758/11350 (epoch 47.392), train_loss = 0.53427767, grad/param norm = 3.3512e-01, time/batch = 17.0059s	
10759/11350 (epoch 47.396), train_loss = 0.41879893, grad/param norm = 3.1371e-01, time/batch = 16.7085s	
10760/11350 (epoch 47.401), train_loss = 0.44851892, grad/param norm = 3.6672e-01, time/batch = 16.7432s	
10761/11350 (epoch 47.405), train_loss = 0.59690647, grad/param norm = 3.3283e-01, time/batch = 16.3901s	
10762/11350 (epoch 47.410), train_loss = 0.61254899, grad/param norm = 3.6210e-01, time/batch = 16.1390s	
10763/11350 (epoch 47.414), train_loss = 0.41603554, grad/param norm = 3.3939e-01, time/batch = 16.3859s	
10764/11350 (epoch 47.419), train_loss = 0.42519197, grad/param norm = 3.1518e-01, time/batch = 16.8632s	
10765/11350 (epoch 47.423), train_loss = 0.43366737, grad/param norm = 3.2068e-01, time/batch = 16.4758s	
10766/11350 (epoch 47.427), train_loss = 0.50562729, grad/param norm = 3.7754e-01, time/batch = 16.3923s	
10767/11350 (epoch 47.432), train_loss = 0.48808003, grad/param norm = 3.3072e-01, time/batch = 16.0739s	
10768/11350 (epoch 47.436), train_loss = 0.40707671, grad/param norm = 4.3551e-01, time/batch = 16.6199s	
10769/11350 (epoch 47.441), train_loss = 0.54966014, grad/param norm = 3.7334e-01, time/batch = 16.4772s	
10770/11350 (epoch 47.445), train_loss = 0.44503997, grad/param norm = 3.1838e-01, time/batch = 17.1107s	
10771/11350 (epoch 47.449), train_loss = 0.52881884, grad/param norm = 3.1354e-01, time/batch = 17.3116s	
10772/11350 (epoch 47.454), train_loss = 0.61572194, grad/param norm = 3.8994e-01, time/batch = 16.4613s	
10773/11350 (epoch 47.458), train_loss = 0.43782931, grad/param norm = 3.5735e-01, time/batch = 16.6191s	
10774/11350 (epoch 47.463), train_loss = 0.45915229, grad/param norm = 5.2581e-01, time/batch = 16.3894s	
10775/11350 (epoch 47.467), train_loss = 0.64451518, grad/param norm = 4.0258e-01, time/batch = 17.0366s	
10776/11350 (epoch 47.471), train_loss = 0.61738211, grad/param norm = 4.7600e-01, time/batch = 16.6179s	
10777/11350 (epoch 47.476), train_loss = 0.51028532, grad/param norm = 3.2980e-01, time/batch = 17.4735s	
10778/11350 (epoch 47.480), train_loss = 0.56946379, grad/param norm = 3.8016e-01, time/batch = 16.4327s	
10779/11350 (epoch 47.485), train_loss = 0.52437347, grad/param norm = 3.1340e-01, time/batch = 16.5493s	
10780/11350 (epoch 47.489), train_loss = 0.57210629, grad/param norm = 3.8811e-01, time/batch = 16.7213s	
10781/11350 (epoch 47.493), train_loss = 0.62004349, grad/param norm = 3.4569e-01, time/batch = 16.8025s	
10782/11350 (epoch 47.498), train_loss = 0.38672081, grad/param norm = 3.1223e-01, time/batch = 16.8675s	
10783/11350 (epoch 47.502), train_loss = 0.62149998, grad/param norm = 3.9153e-01, time/batch = 16.6083s	
10784/11350 (epoch 47.507), train_loss = 0.43921430, grad/param norm = 2.8927e-01, time/batch = 16.6316s	
10785/11350 (epoch 47.511), train_loss = 0.55061501, grad/param norm = 3.6018e-01, time/batch = 16.3095s	
10786/11350 (epoch 47.515), train_loss = 0.52726609, grad/param norm = 3.5619e-01, time/batch = 17.0268s	
10787/11350 (epoch 47.520), train_loss = 0.65134274, grad/param norm = 4.2803e-01, time/batch = 16.4741s	
10788/11350 (epoch 47.524), train_loss = 0.58082922, grad/param norm = 3.3701e-01, time/batch = 16.5508s	
10789/11350 (epoch 47.529), train_loss = 0.47542821, grad/param norm = 3.2453e-01, time/batch = 17.0198s	
10790/11350 (epoch 47.533), train_loss = 0.65896321, grad/param norm = 3.5343e-01, time/batch = 16.4598s	
10791/11350 (epoch 47.537), train_loss = 0.60403368, grad/param norm = 3.6871e-01, time/batch = 16.6341s	
10792/11350 (epoch 47.542), train_loss = 0.50707617, grad/param norm = 3.0974e-01, time/batch = 16.3932s	
10793/11350 (epoch 47.546), train_loss = 0.64286066, grad/param norm = 3.8845e-01, time/batch = 17.3176s	
10794/11350 (epoch 47.551), train_loss = 0.57960233, grad/param norm = 4.6315e-01, time/batch = 16.2933s	
10795/11350 (epoch 47.555), train_loss = 0.46081420, grad/param norm = 3.3153e-01, time/batch = 16.6297s	
10796/11350 (epoch 47.559), train_loss = 0.53235512, grad/param norm = 3.0996e-01, time/batch = 16.7054s	
10797/11350 (epoch 47.564), train_loss = 0.57574379, grad/param norm = 4.8679e-01, time/batch = 16.7990s	
10798/11350 (epoch 47.568), train_loss = 0.54453056, grad/param norm = 3.1336e-01, time/batch = 16.8486s	
10799/11350 (epoch 47.573), train_loss = 0.66219883, grad/param norm = 4.0585e-01, time/batch = 16.2884s	
10800/11350 (epoch 47.577), train_loss = 0.58859063, grad/param norm = 3.7326e-01, time/batch = 16.7902s	
10801/11350 (epoch 47.581), train_loss = 0.64638783, grad/param norm = 3.4525e-01, time/batch = 16.3853s	
10802/11350 (epoch 47.586), train_loss = 0.60332946, grad/param norm = 3.6027e-01, time/batch = 16.4656s	
10803/11350 (epoch 47.590), train_loss = 0.63574505, grad/param norm = 4.2643e-01, time/batch = 16.1382s	
10804/11350 (epoch 47.595), train_loss = 0.71672045, grad/param norm = 3.3264e-01, time/batch = 16.6230s	
10805/11350 (epoch 47.599), train_loss = 0.53717635, grad/param norm = 3.3880e-01, time/batch = 16.3880s	
10806/11350 (epoch 47.604), train_loss = 0.56541983, grad/param norm = 4.3710e-01, time/batch = 16.3826s	
10807/11350 (epoch 47.608), train_loss = 0.51642462, grad/param norm = 3.7535e-01, time/batch = 17.1692s	
10808/11350 (epoch 47.612), train_loss = 0.58338917, grad/param norm = 3.7373e-01, time/batch = 16.2969s	
10809/11350 (epoch 47.617), train_loss = 0.66159830, grad/param norm = 3.8295e-01, time/batch = 16.4687s	
10810/11350 (epoch 47.621), train_loss = 0.63492500, grad/param norm = 3.3444e-01, time/batch = 16.4708s	
10811/11350 (epoch 47.626), train_loss = 0.57942712, grad/param norm = 3.8302e-01, time/batch = 16.9121s	
10812/11350 (epoch 47.630), train_loss = 0.56579453, grad/param norm = 3.5697e-01, time/batch = 16.4733s	
10813/11350 (epoch 47.634), train_loss = 0.54865056, grad/param norm = 4.1200e-01, time/batch = 16.1396s	
10814/11350 (epoch 47.639), train_loss = 0.53192839, grad/param norm = 3.2900e-01, time/batch = 16.2135s	
10815/11350 (epoch 47.643), train_loss = 0.45993832, grad/param norm = 3.4776e-01, time/batch = 16.3806s	
10816/11350 (epoch 47.648), train_loss = 0.54211454, grad/param norm = 4.1447e-01, time/batch = 16.0705s	
10817/11350 (epoch 47.652), train_loss = 0.48652077, grad/param norm = 3.7014e-01, time/batch = 16.3127s	
10818/11350 (epoch 47.656), train_loss = 0.58711022, grad/param norm = 3.7317e-01, time/batch = 16.7644s	
10819/11350 (epoch 47.661), train_loss = 0.56336477, grad/param norm = 3.7291e-01, time/batch = 16.2285s	
10820/11350 (epoch 47.665), train_loss = 0.58169193, grad/param norm = 3.4765e-01, time/batch = 16.6378s	
10821/11350 (epoch 47.670), train_loss = 0.57904983, grad/param norm = 3.0832e-01, time/batch = 17.1796s	
10822/11350 (epoch 47.674), train_loss = 0.53928857, grad/param norm = 3.0562e-01, time/batch = 16.7826s	
10823/11350 (epoch 47.678), train_loss = 0.60649197, grad/param norm = 3.4712e-01, time/batch = 16.2222s	
10824/11350 (epoch 47.683), train_loss = 0.53219173, grad/param norm = 3.6898e-01, time/batch = 16.3157s	
10825/11350 (epoch 47.687), train_loss = 0.47673663, grad/param norm = 3.5352e-01, time/batch = 23.0156s	
10826/11350 (epoch 47.692), train_loss = 0.71891167, grad/param norm = 4.1998e-01, time/batch = 26.0158s	
10827/11350 (epoch 47.696), train_loss = 0.72428455, grad/param norm = 3.6209e-01, time/batch = 16.3090s	
10828/11350 (epoch 47.700), train_loss = 0.63544481, grad/param norm = 3.6296e-01, time/batch = 16.7082s	
10829/11350 (epoch 47.705), train_loss = 0.65561861, grad/param norm = 3.8579e-01, time/batch = 16.3158s	
10830/11350 (epoch 47.709), train_loss = 0.63574311, grad/param norm = 3.9555e-01, time/batch = 16.7047s	
10831/11350 (epoch 47.714), train_loss = 0.57312766, grad/param norm = 3.4231e-01, time/batch = 16.6238s	
10832/11350 (epoch 47.718), train_loss = 0.49230373, grad/param norm = 2.8891e-01, time/batch = 17.4902s	
10833/11350 (epoch 47.722), train_loss = 0.55885509, grad/param norm = 4.0842e-01, time/batch = 16.7779s	
10834/11350 (epoch 47.727), train_loss = 0.58253361, grad/param norm = 3.2396e-01, time/batch = 16.3930s	
10835/11350 (epoch 47.731), train_loss = 0.54132789, grad/param norm = 4.0568e-01, time/batch = 16.5290s	
10836/11350 (epoch 47.736), train_loss = 0.51773777, grad/param norm = 4.2578e-01, time/batch = 16.9908s	
10837/11350 (epoch 47.740), train_loss = 0.53856546, grad/param norm = 3.5436e-01, time/batch = 16.4724s	
10838/11350 (epoch 47.744), train_loss = 0.54937611, grad/param norm = 4.0470e-01, time/batch = 16.5506s	
10839/11350 (epoch 47.749), train_loss = 0.55059779, grad/param norm = 3.7013e-01, time/batch = 16.9329s	
10840/11350 (epoch 47.753), train_loss = 0.58948832, grad/param norm = 3.7130e-01, time/batch = 16.8094s	
10841/11350 (epoch 47.758), train_loss = 0.55323207, grad/param norm = 4.3909e-01, time/batch = 16.6235s	
10842/11350 (epoch 47.762), train_loss = 0.68727222, grad/param norm = 4.3848e-01, time/batch = 17.6533s	
10843/11350 (epoch 47.767), train_loss = 0.66963449, grad/param norm = 3.1461e-01, time/batch = 16.2081s	
10844/11350 (epoch 47.771), train_loss = 0.75877770, grad/param norm = 3.6580e-01, time/batch = 16.7117s	
10845/11350 (epoch 47.775), train_loss = 0.60231797, grad/param norm = 3.3509e-01, time/batch = 16.5551s	
10846/11350 (epoch 47.780), train_loss = 0.63480921, grad/param norm = 3.3336e-01, time/batch = 16.7870s	
10847/11350 (epoch 47.784), train_loss = 0.57474460, grad/param norm = 3.9798e-01, time/batch = 16.5354s	
10848/11350 (epoch 47.789), train_loss = 0.61003470, grad/param norm = 3.9145e-01, time/batch = 16.1230s	
10849/11350 (epoch 47.793), train_loss = 0.63595029, grad/param norm = 3.3706e-01, time/batch = 16.2932s	
10850/11350 (epoch 47.797), train_loss = 0.60281925, grad/param norm = 3.3744e-01, time/batch = 16.2965s	
10851/11350 (epoch 47.802), train_loss = 0.58328645, grad/param norm = 3.1051e-01, time/batch = 16.6065s	
10852/11350 (epoch 47.806), train_loss = 0.60933340, grad/param norm = 2.9923e-01, time/batch = 16.1364s	
10853/11350 (epoch 47.811), train_loss = 0.59377925, grad/param norm = 3.0705e-01, time/batch = 16.6145s	
10854/11350 (epoch 47.815), train_loss = 0.57373110, grad/param norm = 3.2191e-01, time/batch = 16.3854s	
10855/11350 (epoch 47.819), train_loss = 0.51779769, grad/param norm = 3.2608e-01, time/batch = 16.8048s	
10856/11350 (epoch 47.824), train_loss = 0.51440436, grad/param norm = 3.6562e-01, time/batch = 16.5515s	
10857/11350 (epoch 47.828), train_loss = 0.52856711, grad/param norm = 3.3901e-01, time/batch = 17.1084s	
10858/11350 (epoch 47.833), train_loss = 0.53683211, grad/param norm = 3.0643e-01, time/batch = 16.4703s	
10859/11350 (epoch 47.837), train_loss = 0.59354648, grad/param norm = 4.3623e-01, time/batch = 16.7080s	
10860/11350 (epoch 47.841), train_loss = 0.77075564, grad/param norm = 3.8371e-01, time/batch = 17.5425s	
10861/11350 (epoch 47.846), train_loss = 0.64276234, grad/param norm = 3.2792e-01, time/batch = 16.8561s	
10862/11350 (epoch 47.850), train_loss = 0.64716331, grad/param norm = 3.5599e-01, time/batch = 16.5568s	
10863/11350 (epoch 47.855), train_loss = 0.46525920, grad/param norm = 2.8494e-01, time/batch = 16.3870s	
10864/11350 (epoch 47.859), train_loss = 0.51592403, grad/param norm = 4.2073e-01, time/batch = 16.7969s	
10865/11350 (epoch 47.863), train_loss = 0.50087599, grad/param norm = 3.2931e-01, time/batch = 16.4553s	
10866/11350 (epoch 47.868), train_loss = 0.50608469, grad/param norm = 3.0086e-01, time/batch = 16.2212s	
10867/11350 (epoch 47.872), train_loss = 0.51226654, grad/param norm = 3.3299e-01, time/batch = 16.5429s	
10868/11350 (epoch 47.877), train_loss = 0.50927756, grad/param norm = 4.3851e-01, time/batch = 16.4567s	
10869/11350 (epoch 47.881), train_loss = 0.71765555, grad/param norm = 4.7807e-01, time/batch = 16.2810s	
10870/11350 (epoch 47.885), train_loss = 0.63013635, grad/param norm = 3.4478e-01, time/batch = 16.1570s	
10871/11350 (epoch 47.890), train_loss = 0.60094059, grad/param norm = 3.9717e-01, time/batch = 16.8678s	
10872/11350 (epoch 47.894), train_loss = 0.53270401, grad/param norm = 3.4746e-01, time/batch = 17.3965s	
10873/11350 (epoch 47.899), train_loss = 0.62048483, grad/param norm = 3.2538e-01, time/batch = 17.3595s	
10874/11350 (epoch 47.903), train_loss = 0.59239763, grad/param norm = 4.2340e-01, time/batch = 16.5462s	
10875/11350 (epoch 47.907), train_loss = 0.53392979, grad/param norm = 4.2873e-01, time/batch = 16.9637s	
10876/11350 (epoch 47.912), train_loss = 0.53534822, grad/param norm = 3.7731e-01, time/batch = 15.9745s	
10877/11350 (epoch 47.916), train_loss = 0.57774470, grad/param norm = 3.6067e-01, time/batch = 16.4648s	
10878/11350 (epoch 47.921), train_loss = 0.56949584, grad/param norm = 3.3357e-01, time/batch = 17.0046s	
10879/11350 (epoch 47.925), train_loss = 0.52213807, grad/param norm = 3.0966e-01, time/batch = 16.3829s	
10880/11350 (epoch 47.930), train_loss = 0.57600697, grad/param norm = 4.0315e-01, time/batch = 16.3772s	
10881/11350 (epoch 47.934), train_loss = 0.64144843, grad/param norm = 3.7453e-01, time/batch = 16.7063s	
10882/11350 (epoch 47.938), train_loss = 0.57647817, grad/param norm = 3.8869e-01, time/batch = 17.2572s	
10883/11350 (epoch 47.943), train_loss = 0.61322434, grad/param norm = 3.8873e-01, time/batch = 16.3137s	
10884/11350 (epoch 47.947), train_loss = 0.60821553, grad/param norm = 4.1025e-01, time/batch = 16.4769s	
10885/11350 (epoch 47.952), train_loss = 0.60991389, grad/param norm = 3.6013e-01, time/batch = 16.9496s	
10886/11350 (epoch 47.956), train_loss = 0.49236705, grad/param norm = 2.8342e-01, time/batch = 17.0912s	
10887/11350 (epoch 47.960), train_loss = 0.55955634, grad/param norm = 4.1037e-01, time/batch = 16.7064s	
10888/11350 (epoch 47.965), train_loss = 0.47806569, grad/param norm = 2.7756e-01, time/batch = 16.1483s	
10889/11350 (epoch 47.969), train_loss = 0.46677573, grad/param norm = 3.3200e-01, time/batch = 17.1053s	
10890/11350 (epoch 47.974), train_loss = 0.48743763, grad/param norm = 3.1704e-01, time/batch = 16.4662s	
10891/11350 (epoch 47.978), train_loss = 0.54920452, grad/param norm = 3.1296e-01, time/batch = 16.8653s	
10892/11350 (epoch 47.982), train_loss = 0.37810667, grad/param norm = 3.3805e-01, time/batch = 16.6146s	
10893/11350 (epoch 47.987), train_loss = 0.56088141, grad/param norm = 3.3081e-01, time/batch = 16.5383s	
10894/11350 (epoch 47.991), train_loss = 0.48691779, grad/param norm = 3.5823e-01, time/batch = 16.5549s	
10895/11350 (epoch 47.996), train_loss = 0.52941785, grad/param norm = 3.4802e-01, time/batch = 16.1351s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
10896/11350 (epoch 48.000), train_loss = 0.41861187, grad/param norm = 2.9273e-01, time/batch = 17.1034s	
10897/11350 (epoch 48.004), train_loss = 0.62451206, grad/param norm = 3.7437e-01, time/batch = 16.7823s	
10898/11350 (epoch 48.009), train_loss = 0.57028601, grad/param norm = 2.9165e-01, time/batch = 16.5278s	
10899/11350 (epoch 48.013), train_loss = 0.39224636, grad/param norm = 3.0441e-01, time/batch = 16.4437s	
10900/11350 (epoch 48.018), train_loss = 0.44226707, grad/param norm = 3.3476e-01, time/batch = 17.0104s	
10901/11350 (epoch 48.022), train_loss = 0.48149761, grad/param norm = 4.6770e-01, time/batch = 16.4429s	
10902/11350 (epoch 48.026), train_loss = 0.45694301, grad/param norm = 3.7804e-01, time/batch = 16.9674s	
10903/11350 (epoch 48.031), train_loss = 0.44513208, grad/param norm = 2.8916e-01, time/batch = 16.6128s	
10904/11350 (epoch 48.035), train_loss = 0.48886141, grad/param norm = 2.8115e-01, time/batch = 16.4631s	
10905/11350 (epoch 48.040), train_loss = 0.48800161, grad/param norm = 2.9625e-01, time/batch = 16.7864s	
10906/11350 (epoch 48.044), train_loss = 0.45236870, grad/param norm = 2.7865e-01, time/batch = 16.4689s	
10907/11350 (epoch 48.048), train_loss = 0.44576118, grad/param norm = 3.0212e-01, time/batch = 16.9355s	
10908/11350 (epoch 48.053), train_loss = 0.48779012, grad/param norm = 2.7028e-01, time/batch = 16.3098s	
10909/11350 (epoch 48.057), train_loss = 0.46770949, grad/param norm = 3.3525e-01, time/batch = 16.3047s	
10910/11350 (epoch 48.062), train_loss = 0.40180490, grad/param norm = 3.0522e-01, time/batch = 16.3837s	
10911/11350 (epoch 48.066), train_loss = 0.42887153, grad/param norm = 3.2880e-01, time/batch = 16.3857s	
10912/11350 (epoch 48.070), train_loss = 0.47631748, grad/param norm = 3.1947e-01, time/batch = 16.9399s	
10913/11350 (epoch 48.075), train_loss = 0.42672965, grad/param norm = 2.5902e-01, time/batch = 16.9467s	
10914/11350 (epoch 48.079), train_loss = 0.51711548, grad/param norm = 3.4725e-01, time/batch = 17.2537s	
10915/11350 (epoch 48.084), train_loss = 0.60983095, grad/param norm = 3.4541e-01, time/batch = 16.7870s	
10916/11350 (epoch 48.088), train_loss = 0.55070248, grad/param norm = 3.9491e-01, time/batch = 16.6107s	
10917/11350 (epoch 48.093), train_loss = 0.55175115, grad/param norm = 3.0640e-01, time/batch = 16.7084s	
10918/11350 (epoch 48.097), train_loss = 0.47532094, grad/param norm = 2.8772e-01, time/batch = 17.3121s	
10919/11350 (epoch 48.101), train_loss = 0.44924800, grad/param norm = 2.9706e-01, time/batch = 16.0627s	
10920/11350 (epoch 48.106), train_loss = 0.54382768, grad/param norm = 4.2099e-01, time/batch = 16.5582s	
10921/11350 (epoch 48.110), train_loss = 0.45379982, grad/param norm = 3.3094e-01, time/batch = 16.8717s	
10922/11350 (epoch 48.115), train_loss = 0.48509340, grad/param norm = 3.4360e-01, time/batch = 16.2239s	
10923/11350 (epoch 48.119), train_loss = 0.56332082, grad/param norm = 3.3247e-01, time/batch = 16.3836s	
10924/11350 (epoch 48.123), train_loss = 0.47517788, grad/param norm = 3.9647e-01, time/batch = 16.3765s	
10925/11350 (epoch 48.128), train_loss = 0.42136723, grad/param norm = 3.1419e-01, time/batch = 16.2977s	
10926/11350 (epoch 48.132), train_loss = 0.44801586, grad/param norm = 2.8417e-01, time/batch = 16.5495s	
10927/11350 (epoch 48.137), train_loss = 0.43183720, grad/param norm = 3.7893e-01, time/batch = 16.5449s	
10928/11350 (epoch 48.141), train_loss = 0.56921383, grad/param norm = 4.5702e-01, time/batch = 16.4524s	
10929/11350 (epoch 48.145), train_loss = 0.50383019, grad/param norm = 5.6891e-01, time/batch = 16.6978s	
10930/11350 (epoch 48.150), train_loss = 0.54296960, grad/param norm = 5.3724e-01, time/batch = 16.5408s	
10931/11350 (epoch 48.154), train_loss = 0.60418304, grad/param norm = 3.8885e-01, time/batch = 16.3944s	
10932/11350 (epoch 48.159), train_loss = 0.46107161, grad/param norm = 4.0539e-01, time/batch = 17.2662s	
10933/11350 (epoch 48.163), train_loss = 0.56270136, grad/param norm = 3.5691e-01, time/batch = 16.6303s	
10934/11350 (epoch 48.167), train_loss = 0.59361798, grad/param norm = 3.4569e-01, time/batch = 16.8717s	
10935/11350 (epoch 48.172), train_loss = 0.69157628, grad/param norm = 4.0366e-01, time/batch = 16.6244s	
10936/11350 (epoch 48.176), train_loss = 0.53039069, grad/param norm = 3.3683e-01, time/batch = 17.4275s	
10937/11350 (epoch 48.181), train_loss = 0.50796781, grad/param norm = 4.4137e-01, time/batch = 16.4529s	
10938/11350 (epoch 48.185), train_loss = 0.51506240, grad/param norm = 3.8395e-01, time/batch = 16.3025s	
10939/11350 (epoch 48.189), train_loss = 0.45918691, grad/param norm = 3.4282e-01, time/batch = 17.0023s	
10940/11350 (epoch 48.194), train_loss = 0.41602522, grad/param norm = 3.5593e-01, time/batch = 16.0576s	
10941/11350 (epoch 48.198), train_loss = 0.39265944, grad/param norm = 4.0122e-01, time/batch = 16.4732s	
10942/11350 (epoch 48.203), train_loss = 0.46548472, grad/param norm = 3.6880e-01, time/batch = 16.3940s	
10943/11350 (epoch 48.207), train_loss = 0.42995041, grad/param norm = 3.8098e-01, time/batch = 16.9402s	
10944/11350 (epoch 48.211), train_loss = 0.55634032, grad/param norm = 3.4968e-01, time/batch = 16.0689s	
10945/11350 (epoch 48.216), train_loss = 0.52868171, grad/param norm = 3.6912e-01, time/batch = 16.5460s	
10946/11350 (epoch 48.220), train_loss = 0.54850775, grad/param norm = 3.6359e-01, time/batch = 17.0256s	
10947/11350 (epoch 48.225), train_loss = 0.47893798, grad/param norm = 2.7879e-01, time/batch = 17.1059s	
10948/11350 (epoch 48.229), train_loss = 0.51299965, grad/param norm = 3.2428e-01, time/batch = 16.8386s	
10949/11350 (epoch 48.233), train_loss = 0.48888236, grad/param norm = 3.3201e-01, time/batch = 16.2253s	
10950/11350 (epoch 48.238), train_loss = 0.57548108, grad/param norm = 4.1546e-01, time/batch = 16.9964s	
10951/11350 (epoch 48.242), train_loss = 0.57145429, grad/param norm = 3.8632e-01, time/batch = 16.0669s	
10952/11350 (epoch 48.247), train_loss = 0.42264049, grad/param norm = 2.6524e-01, time/batch = 15.9803s	
10953/11350 (epoch 48.251), train_loss = 0.47541644, grad/param norm = 3.2212e-01, time/batch = 16.1415s	
10954/11350 (epoch 48.256), train_loss = 0.55049794, grad/param norm = 3.5250e-01, time/batch = 17.0417s	
10955/11350 (epoch 48.260), train_loss = 0.47737689, grad/param norm = 2.6483e-01, time/batch = 16.3883s	
10956/11350 (epoch 48.264), train_loss = 0.43577537, grad/param norm = 3.6216e-01, time/batch = 16.3145s	
10957/11350 (epoch 48.269), train_loss = 0.49983235, grad/param norm = 2.7791e-01, time/batch = 16.7893s	
10958/11350 (epoch 48.273), train_loss = 0.56637565, grad/param norm = 3.1884e-01, time/batch = 16.5556s	
10959/11350 (epoch 48.278), train_loss = 0.48610523, grad/param norm = 2.8545e-01, time/batch = 16.8511s	
10960/11350 (epoch 48.282), train_loss = 0.48516032, grad/param norm = 3.5482e-01, time/batch = 16.0586s	
10961/11350 (epoch 48.286), train_loss = 0.58110252, grad/param norm = 3.8421e-01, time/batch = 16.8601s	
10962/11350 (epoch 48.291), train_loss = 0.47606076, grad/param norm = 3.5827e-01, time/batch = 16.2307s	
10963/11350 (epoch 48.295), train_loss = 0.46177458, grad/param norm = 3.4756e-01, time/batch = 16.2166s	
10964/11350 (epoch 48.300), train_loss = 0.54735000, grad/param norm = 3.6346e-01, time/batch = 17.1574s	
10965/11350 (epoch 48.304), train_loss = 0.45840382, grad/param norm = 3.7798e-01, time/batch = 16.7121s	
10966/11350 (epoch 48.308), train_loss = 0.44242445, grad/param norm = 3.3859e-01, time/batch = 16.6267s	
10967/11350 (epoch 48.313), train_loss = 0.51671724, grad/param norm = 3.2015e-01, time/batch = 16.3154s	
10968/11350 (epoch 48.317), train_loss = 0.50784115, grad/param norm = 3.0011e-01, time/batch = 17.3101s	
10969/11350 (epoch 48.322), train_loss = 0.47839081, grad/param norm = 3.3661e-01, time/batch = 16.8845s	
10970/11350 (epoch 48.326), train_loss = 0.51462576, grad/param norm = 3.3625e-01, time/batch = 16.6294s	
10971/11350 (epoch 48.330), train_loss = 0.42017695, grad/param norm = 2.5351e-01, time/batch = 16.7080s	
10972/11350 (epoch 48.335), train_loss = 0.34512655, grad/param norm = 3.0712e-01, time/batch = 16.7197s	
10973/11350 (epoch 48.339), train_loss = 0.35914151, grad/param norm = 3.8757e-01, time/batch = 16.7011s	
10974/11350 (epoch 48.344), train_loss = 0.43338607, grad/param norm = 3.0802e-01, time/batch = 16.5546s	
10975/11350 (epoch 48.348), train_loss = 0.45808208, grad/param norm = 2.4907e-01, time/batch = 17.0203s	
10976/11350 (epoch 48.352), train_loss = 0.36319778, grad/param norm = 2.8135e-01, time/batch = 17.0819s	
10977/11350 (epoch 48.357), train_loss = 0.45207069, grad/param norm = 2.5683e-01, time/batch = 16.4644s	
10978/11350 (epoch 48.361), train_loss = 0.39286831, grad/param norm = 2.6918e-01, time/batch = 16.2320s	
10979/11350 (epoch 48.366), train_loss = 0.45531889, grad/param norm = 3.8462e-01, time/batch = 16.5397s	
10980/11350 (epoch 48.370), train_loss = 0.40141159, grad/param norm = 3.5232e-01, time/batch = 16.3944s	
10981/11350 (epoch 48.374), train_loss = 0.43820370, grad/param norm = 3.4338e-01, time/batch = 16.4620s	
10982/11350 (epoch 48.379), train_loss = 0.46138067, grad/param norm = 3.6036e-01, time/batch = 16.7966s	
10983/11350 (epoch 48.383), train_loss = 0.37122860, grad/param norm = 2.8879e-01, time/batch = 16.6184s	
10984/11350 (epoch 48.388), train_loss = 0.45180226, grad/param norm = 4.2048e-01, time/batch = 16.3870s	
10985/11350 (epoch 48.392), train_loss = 0.52214730, grad/param norm = 3.4924e-01, time/batch = 16.0585s	
10986/11350 (epoch 48.396), train_loss = 0.41550871, grad/param norm = 4.9073e-01, time/batch = 17.1638s	
10987/11350 (epoch 48.401), train_loss = 0.44114348, grad/param norm = 3.9411e-01, time/batch = 16.6301s	
10988/11350 (epoch 48.405), train_loss = 0.58562874, grad/param norm = 3.6199e-01, time/batch = 16.4740s	
10989/11350 (epoch 48.410), train_loss = 0.61123624, grad/param norm = 3.7429e-01, time/batch = 16.4662s	
10990/11350 (epoch 48.414), train_loss = 0.41751900, grad/param norm = 3.8496e-01, time/batch = 16.7051s	
10991/11350 (epoch 48.419), train_loss = 0.41932019, grad/param norm = 3.2996e-01, time/batch = 16.4747s	
10992/11350 (epoch 48.423), train_loss = 0.42637142, grad/param norm = 4.0372e-01, time/batch = 17.0243s	
10993/11350 (epoch 48.427), train_loss = 0.49036404, grad/param norm = 3.3307e-01, time/batch = 17.4140s	
10994/11350 (epoch 48.432), train_loss = 0.49127960, grad/param norm = 3.0899e-01, time/batch = 17.1407s	
10995/11350 (epoch 48.436), train_loss = 0.39393285, grad/param norm = 3.1804e-01, time/batch = 16.9679s	
10996/11350 (epoch 48.441), train_loss = 0.53425399, grad/param norm = 3.8572e-01, time/batch = 16.7064s	
10997/11350 (epoch 48.445), train_loss = 0.43544653, grad/param norm = 2.4862e-01, time/batch = 16.4690s	
10998/11350 (epoch 48.449), train_loss = 0.51270654, grad/param norm = 2.8375e-01, time/batch = 16.6308s	
10999/11350 (epoch 48.454), train_loss = 0.61427950, grad/param norm = 4.6459e-01, time/batch = 16.1489s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch48.46_2.2787.t7	
11000/11350 (epoch 48.458), train_loss = 0.41882601, grad/param norm = 3.1348e-01, time/batch = 16.6929s	
11001/11350 (epoch 48.463), train_loss = 1.48970738, grad/param norm = 6.7578e-01, time/batch = 16.8605s	
11002/11350 (epoch 48.467), train_loss = 0.66542751, grad/param norm = 4.4327e-01, time/batch = 16.5497s	
11003/11350 (epoch 48.471), train_loss = 0.60914122, grad/param norm = 5.2081e-01, time/batch = 16.7882s	
11004/11350 (epoch 48.476), train_loss = 0.51417833, grad/param norm = 3.5344e-01, time/batch = 16.8697s	
11005/11350 (epoch 48.480), train_loss = 0.56586009, grad/param norm = 3.7205e-01, time/batch = 16.4800s	
11006/11350 (epoch 48.485), train_loss = 0.52353811, grad/param norm = 4.0579e-01, time/batch = 16.4667s	
11007/11350 (epoch 48.489), train_loss = 0.55538069, grad/param norm = 3.8659e-01, time/batch = 16.4054s	
11008/11350 (epoch 48.493), train_loss = 0.60089223, grad/param norm = 3.3786e-01, time/batch = 16.7805s	
11009/11350 (epoch 48.498), train_loss = 0.38995953, grad/param norm = 3.2569e-01, time/batch = 16.6910s	
11010/11350 (epoch 48.502), train_loss = 0.61004872, grad/param norm = 3.5982e-01, time/batch = 16.6845s	
11011/11350 (epoch 48.507), train_loss = 0.44357220, grad/param norm = 3.1775e-01, time/batch = 16.8689s	
11012/11350 (epoch 48.511), train_loss = 0.54168814, grad/param norm = 3.6059e-01, time/batch = 16.3956s	
11013/11350 (epoch 48.515), train_loss = 0.52520772, grad/param norm = 3.5388e-01, time/batch = 16.9504s	
11014/11350 (epoch 48.520), train_loss = 0.64055242, grad/param norm = 3.9374e-01, time/batch = 17.0087s	
11015/11350 (epoch 48.524), train_loss = 0.56052279, grad/param norm = 3.2570e-01, time/batch = 16.7806s	
11016/11350 (epoch 48.529), train_loss = 0.46656045, grad/param norm = 2.8401e-01, time/batch = 16.4676s	
11017/11350 (epoch 48.533), train_loss = 0.64770660, grad/param norm = 3.8858e-01, time/batch = 16.7159s	
11018/11350 (epoch 48.537), train_loss = 0.60756262, grad/param norm = 3.5788e-01, time/batch = 16.9317s	
11019/11350 (epoch 48.542), train_loss = 0.50091310, grad/param norm = 3.4209e-01, time/batch = 16.6874s	
11020/11350 (epoch 48.546), train_loss = 0.61778281, grad/param norm = 4.0001e-01, time/batch = 16.8621s	
11021/11350 (epoch 48.551), train_loss = 0.55691144, grad/param norm = 3.7884e-01, time/batch = 16.3788s	
11022/11350 (epoch 48.555), train_loss = 0.45447826, grad/param norm = 3.2926e-01, time/batch = 16.6293s	
11023/11350 (epoch 48.559), train_loss = 0.52941208, grad/param norm = 3.0904e-01, time/batch = 16.6414s	
11024/11350 (epoch 48.564), train_loss = 0.53480735, grad/param norm = 3.6921e-01, time/batch = 16.7824s	
11025/11350 (epoch 48.568), train_loss = 0.53913822, grad/param norm = 3.3919e-01, time/batch = 16.3118s	
11026/11350 (epoch 48.573), train_loss = 0.64426322, grad/param norm = 5.2871e-01, time/batch = 17.0318s	
11027/11350 (epoch 48.577), train_loss = 0.58143326, grad/param norm = 4.5012e-01, time/batch = 16.5985s	
11028/11350 (epoch 48.581), train_loss = 0.66544037, grad/param norm = 4.3032e-01, time/batch = 16.4697s	
11029/11350 (epoch 48.586), train_loss = 0.59264862, grad/param norm = 3.9240e-01, time/batch = 16.7056s	
11030/11350 (epoch 48.590), train_loss = 0.64597929, grad/param norm = 4.4667e-01, time/batch = 16.3800s	
11031/11350 (epoch 48.595), train_loss = 0.72614149, grad/param norm = 3.7908e-01, time/batch = 16.7057s	
11032/11350 (epoch 48.599), train_loss = 0.52547457, grad/param norm = 3.4437e-01, time/batch = 16.2269s	
11033/11350 (epoch 48.604), train_loss = 0.54698155, grad/param norm = 3.8062e-01, time/batch = 16.6206s	
11034/11350 (epoch 48.608), train_loss = 0.50679367, grad/param norm = 3.5925e-01, time/batch = 16.2285s	
11035/11350 (epoch 48.612), train_loss = 0.55285835, grad/param norm = 3.0023e-01, time/batch = 16.1223s	
11036/11350 (epoch 48.617), train_loss = 0.63754976, grad/param norm = 3.7448e-01, time/batch = 18.5628s	
11037/11350 (epoch 48.621), train_loss = 0.62188132, grad/param norm = 3.4961e-01, time/batch = 29.2825s	
11038/11350 (epoch 48.626), train_loss = 0.56203805, grad/param norm = 3.6264e-01, time/batch = 16.7663s	
11039/11350 (epoch 48.630), train_loss = 0.55750672, grad/param norm = 3.5471e-01, time/batch = 16.9961s	
11040/11350 (epoch 48.634), train_loss = 0.53551504, grad/param norm = 4.1367e-01, time/batch = 16.6261s	
11041/11350 (epoch 48.639), train_loss = 0.53881038, grad/param norm = 3.9551e-01, time/batch = 16.6328s	
11042/11350 (epoch 48.643), train_loss = 0.46048102, grad/param norm = 3.5102e-01, time/batch = 16.4006s	
11043/11350 (epoch 48.648), train_loss = 0.52420445, grad/param norm = 3.1811e-01, time/batch = 16.7054s	
11044/11350 (epoch 48.652), train_loss = 0.47558414, grad/param norm = 3.5939e-01, time/batch = 16.2217s	
11045/11350 (epoch 48.656), train_loss = 0.58428555, grad/param norm = 3.0914e-01, time/batch = 16.2969s	
11046/11350 (epoch 48.661), train_loss = 0.55132947, grad/param norm = 3.5873e-01, time/batch = 16.3712s	
11047/11350 (epoch 48.665), train_loss = 0.56798872, grad/param norm = 3.4707e-01, time/batch = 16.7696s	
11048/11350 (epoch 48.670), train_loss = 0.56238977, grad/param norm = 3.0767e-01, time/batch = 16.8862s	
11049/11350 (epoch 48.674), train_loss = 0.52968916, grad/param norm = 3.0324e-01, time/batch = 16.9473s	
11050/11350 (epoch 48.678), train_loss = 0.60200212, grad/param norm = 3.8538e-01, time/batch = 17.0343s	
11051/11350 (epoch 48.683), train_loss = 0.53087780, grad/param norm = 3.5296e-01, time/batch = 16.3009s	
11052/11350 (epoch 48.687), train_loss = 0.47524115, grad/param norm = 3.3321e-01, time/batch = 16.3621s	
11053/11350 (epoch 48.692), train_loss = 0.70758737, grad/param norm = 4.3546e-01, time/batch = 16.6163s	
11054/11350 (epoch 48.696), train_loss = 0.71281745, grad/param norm = 3.9534e-01, time/batch = 16.6171s	
11055/11350 (epoch 48.700), train_loss = 0.62239362, grad/param norm = 3.9009e-01, time/batch = 16.5372s	
11056/11350 (epoch 48.705), train_loss = 0.62405782, grad/param norm = 4.1090e-01, time/batch = 16.4052s	
11057/11350 (epoch 48.709), train_loss = 0.63516748, grad/param norm = 4.2188e-01, time/batch = 16.8668s	
11058/11350 (epoch 48.714), train_loss = 0.56646253, grad/param norm = 3.4034e-01, time/batch = 16.3842s	
11059/11350 (epoch 48.718), train_loss = 0.48649884, grad/param norm = 3.2289e-01, time/batch = 16.5934s	
11060/11350 (epoch 48.722), train_loss = 0.54148067, grad/param norm = 4.0797e-01, time/batch = 16.3874s	
11061/11350 (epoch 48.727), train_loss = 0.57938176, grad/param norm = 3.5584e-01, time/batch = 16.7868s	
11062/11350 (epoch 48.731), train_loss = 0.52869751, grad/param norm = 3.4043e-01, time/batch = 16.3865s	
11063/11350 (epoch 48.736), train_loss = 0.47482155, grad/param norm = 3.1279e-01, time/batch = 17.5021s	
11064/11350 (epoch 48.740), train_loss = 0.53028600, grad/param norm = 3.3807e-01, time/batch = 16.9443s	
11065/11350 (epoch 48.744), train_loss = 0.52249434, grad/param norm = 3.8792e-01, time/batch = 16.4710s	
11066/11350 (epoch 48.749), train_loss = 0.53598545, grad/param norm = 3.3871e-01, time/batch = 16.6359s	
11067/11350 (epoch 48.753), train_loss = 0.58896214, grad/param norm = 4.0363e-01, time/batch = 16.5588s	
11068/11350 (epoch 48.758), train_loss = 0.52923492, grad/param norm = 3.6979e-01, time/batch = 16.8647s	
11069/11350 (epoch 48.762), train_loss = 0.65639581, grad/param norm = 3.6119e-01, time/batch = 16.3181s	
11070/11350 (epoch 48.767), train_loss = 0.65849958, grad/param norm = 3.7057e-01, time/batch = 16.4682s	
11071/11350 (epoch 48.771), train_loss = 0.74493777, grad/param norm = 3.8027e-01, time/batch = 17.0274s	
11072/11350 (epoch 48.775), train_loss = 0.59093092, grad/param norm = 3.7860e-01, time/batch = 16.5187s	
11073/11350 (epoch 48.780), train_loss = 0.62170067, grad/param norm = 3.3702e-01, time/batch = 16.4511s	
11074/11350 (epoch 48.784), train_loss = 0.56944189, grad/param norm = 3.6670e-01, time/batch = 16.1417s	
11075/11350 (epoch 48.789), train_loss = 0.58708739, grad/param norm = 3.9944e-01, time/batch = 17.2425s	
11076/11350 (epoch 48.793), train_loss = 0.62119708, grad/param norm = 3.2986e-01, time/batch = 16.3746s	
11077/11350 (epoch 48.797), train_loss = 0.58786934, grad/param norm = 3.0013e-01, time/batch = 16.8875s	
11078/11350 (epoch 48.802), train_loss = 0.56965116, grad/param norm = 3.4177e-01, time/batch = 17.4247s	
11079/11350 (epoch 48.806), train_loss = 0.59790803, grad/param norm = 3.0870e-01, time/batch = 16.6367s	
11080/11350 (epoch 48.811), train_loss = 0.58688552, grad/param norm = 2.6658e-01, time/batch = 16.3134s	
11081/11350 (epoch 48.815), train_loss = 0.55645782, grad/param norm = 3.3098e-01, time/batch = 16.6883s	
11082/11350 (epoch 48.819), train_loss = 0.50652131, grad/param norm = 3.5544e-01, time/batch = 16.7659s	
11083/11350 (epoch 48.824), train_loss = 0.50928658, grad/param norm = 3.2855e-01, time/batch = 16.7147s	
11084/11350 (epoch 48.828), train_loss = 0.52231679, grad/param norm = 3.0991e-01, time/batch = 17.1719s	
11085/11350 (epoch 48.833), train_loss = 0.54231588, grad/param norm = 3.5103e-01, time/batch = 16.2338s	
11086/11350 (epoch 48.837), train_loss = 0.56264294, grad/param norm = 3.9113e-01, time/batch = 16.9351s	
11087/11350 (epoch 48.841), train_loss = 0.74977708, grad/param norm = 3.7948e-01, time/batch = 16.3941s	
11088/11350 (epoch 48.846), train_loss = 0.63387970, grad/param norm = 3.1619e-01, time/batch = 16.7194s	
11089/11350 (epoch 48.850), train_loss = 0.64145676, grad/param norm = 3.6110e-01, time/batch = 17.4200s	
11090/11350 (epoch 48.855), train_loss = 0.47681491, grad/param norm = 3.4467e-01, time/batch = 16.7828s	
11091/11350 (epoch 48.859), train_loss = 0.50803426, grad/param norm = 4.3274e-01, time/batch = 16.6386s	
11092/11350 (epoch 48.863), train_loss = 0.49116193, grad/param norm = 3.3549e-01, time/batch = 16.5506s	
11093/11350 (epoch 48.868), train_loss = 0.50605381, grad/param norm = 3.2519e-01, time/batch = 17.0278s	
11094/11350 (epoch 48.872), train_loss = 0.49601820, grad/param norm = 3.2007e-01, time/batch = 16.4731s	
11095/11350 (epoch 48.877), train_loss = 0.50919302, grad/param norm = 3.3489e-01, time/batch = 16.3947s	
11096/11350 (epoch 48.881), train_loss = 0.69341937, grad/param norm = 5.0431e-01, time/batch = 16.3018s	
11097/11350 (epoch 48.885), train_loss = 0.59693849, grad/param norm = 3.1424e-01, time/batch = 17.2676s	
11098/11350 (epoch 48.890), train_loss = 0.58848825, grad/param norm = 4.2222e-01, time/batch = 16.7663s	
11099/11350 (epoch 48.894), train_loss = 0.50499890, grad/param norm = 3.4815e-01, time/batch = 16.6987s	
11100/11350 (epoch 48.899), train_loss = 0.60470858, grad/param norm = 3.2939e-01, time/batch = 16.7780s	
11101/11350 (epoch 48.903), train_loss = 0.58102161, grad/param norm = 3.7459e-01, time/batch = 16.4788s	
11102/11350 (epoch 48.907), train_loss = 0.51122431, grad/param norm = 3.5731e-01, time/batch = 16.8732s	
11103/11350 (epoch 48.912), train_loss = 0.51970891, grad/param norm = 3.4002e-01, time/batch = 16.3845s	
11104/11350 (epoch 48.916), train_loss = 0.55375651, grad/param norm = 3.2627e-01, time/batch = 16.7845s	
11105/11350 (epoch 48.921), train_loss = 0.56844757, grad/param norm = 3.3240e-01, time/batch = 16.6371s	
11106/11350 (epoch 48.925), train_loss = 0.49823763, grad/param norm = 3.0586e-01, time/batch = 16.4546s	
11107/11350 (epoch 48.930), train_loss = 0.56074044, grad/param norm = 3.9347e-01, time/batch = 17.4804s	
11108/11350 (epoch 48.934), train_loss = 0.63820804, grad/param norm = 3.6111e-01, time/batch = 16.7173s	
11109/11350 (epoch 48.938), train_loss = 0.56973669, grad/param norm = 4.0225e-01, time/batch = 16.1308s	
11110/11350 (epoch 48.943), train_loss = 0.62159161, grad/param norm = 3.8765e-01, time/batch = 16.5548s	
11111/11350 (epoch 48.947), train_loss = 0.58953733, grad/param norm = 3.6136e-01, time/batch = 17.2609s	
11112/11350 (epoch 48.952), train_loss = 0.59680495, grad/param norm = 3.5785e-01, time/batch = 16.6993s	
11113/11350 (epoch 48.956), train_loss = 0.50070618, grad/param norm = 2.9533e-01, time/batch = 16.6417s	
11114/11350 (epoch 48.960), train_loss = 0.55026909, grad/param norm = 3.4364e-01, time/batch = 16.4666s	
11115/11350 (epoch 48.965), train_loss = 0.46562394, grad/param norm = 3.1507e-01, time/batch = 16.5366s	
11116/11350 (epoch 48.969), train_loss = 0.45607380, grad/param norm = 3.0647e-01, time/batch = 16.8764s	
11117/11350 (epoch 48.974), train_loss = 0.46523924, grad/param norm = 4.1526e-01, time/batch = 16.3104s	
11118/11350 (epoch 48.978), train_loss = 0.52542524, grad/param norm = 2.9123e-01, time/batch = 17.0838s	
11119/11350 (epoch 48.982), train_loss = 0.39904324, grad/param norm = 5.1745e-01, time/batch = 16.4639s	
11120/11350 (epoch 48.987), train_loss = 0.56114203, grad/param norm = 3.3436e-01, time/batch = 16.5518s	
11121/11350 (epoch 48.991), train_loss = 0.46937229, grad/param norm = 3.1187e-01, time/batch = 16.6315s	
11122/11350 (epoch 48.996), train_loss = 0.51983510, grad/param norm = 3.5145e-01, time/batch = 16.8745s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
11123/11350 (epoch 49.000), train_loss = 0.42207020, grad/param norm = 3.8796e-01, time/batch = 16.4707s	
11124/11350 (epoch 49.004), train_loss = 0.61963612, grad/param norm = 3.4538e-01, time/batch = 16.3077s	
11125/11350 (epoch 49.009), train_loss = 0.56160444, grad/param norm = 3.0016e-01, time/batch = 12.6535s	
11126/11350 (epoch 49.013), train_loss = 0.39534740, grad/param norm = 3.1703e-01, time/batch = 0.7411s	
11127/11350 (epoch 49.018), train_loss = 0.42686907, grad/param norm = 3.1060e-01, time/batch = 0.7407s	
11128/11350 (epoch 49.022), train_loss = 0.45298051, grad/param norm = 3.6193e-01, time/batch = 0.7411s	
11129/11350 (epoch 49.026), train_loss = 0.43325250, grad/param norm = 3.2632e-01, time/batch = 0.7416s	
11130/11350 (epoch 49.031), train_loss = 0.43700301, grad/param norm = 3.0843e-01, time/batch = 0.7409s	
11131/11350 (epoch 49.035), train_loss = 0.47240352, grad/param norm = 2.9435e-01, time/batch = 0.7353s	
11132/11350 (epoch 49.040), train_loss = 0.47284087, grad/param norm = 2.6435e-01, time/batch = 0.9310s	
11133/11350 (epoch 49.044), train_loss = 0.44163803, grad/param norm = 2.7398e-01, time/batch = 1.0810s	
11134/11350 (epoch 49.048), train_loss = 0.43526858, grad/param norm = 2.9053e-01, time/batch = 1.0870s	
11135/11350 (epoch 49.053), train_loss = 0.47580207, grad/param norm = 2.7662e-01, time/batch = 1.0800s	
11136/11350 (epoch 49.057), train_loss = 0.47993595, grad/param norm = 4.5385e-01, time/batch = 1.0789s	
11137/11350 (epoch 49.062), train_loss = 0.39707085, grad/param norm = 3.0104e-01, time/batch = 1.9566s	
11138/11350 (epoch 49.066), train_loss = 0.42223650, grad/param norm = 3.2808e-01, time/batch = 2.0093s	
11139/11350 (epoch 49.070), train_loss = 0.47726601, grad/param norm = 3.4136e-01, time/batch = 8.7228s	
11140/11350 (epoch 49.075), train_loss = 0.41298835, grad/param norm = 2.9148e-01, time/batch = 17.0063s	
11141/11350 (epoch 49.079), train_loss = 0.50629184, grad/param norm = 4.1887e-01, time/batch = 16.6256s	
11142/11350 (epoch 49.084), train_loss = 0.59646321, grad/param norm = 4.1707e-01, time/batch = 16.5327s	
11143/11350 (epoch 49.088), train_loss = 0.54187792, grad/param norm = 3.5222e-01, time/batch = 16.0690s	
11144/11350 (epoch 49.093), train_loss = 0.53383144, grad/param norm = 3.1810e-01, time/batch = 17.0941s	
11145/11350 (epoch 49.097), train_loss = 0.46609879, grad/param norm = 3.4892e-01, time/batch = 16.5511s	
11146/11350 (epoch 49.101), train_loss = 0.45841591, grad/param norm = 3.3145e-01, time/batch = 16.6372s	
11147/11350 (epoch 49.106), train_loss = 0.52860050, grad/param norm = 3.3373e-01, time/batch = 16.2067s	
11148/11350 (epoch 49.110), train_loss = 0.45119451, grad/param norm = 3.2787e-01, time/batch = 16.3157s	
11149/11350 (epoch 49.115), train_loss = 0.47187857, grad/param norm = 3.4548e-01, time/batch = 16.9939s	
11150/11350 (epoch 49.119), train_loss = 0.55542023, grad/param norm = 3.4497e-01, time/batch = 16.8605s	
11151/11350 (epoch 49.123), train_loss = 0.45284255, grad/param norm = 4.3125e-01, time/batch = 16.1475s	
11152/11350 (epoch 49.128), train_loss = 0.41459554, grad/param norm = 3.2320e-01, time/batch = 16.5435s	
11153/11350 (epoch 49.132), train_loss = 0.43201475, grad/param norm = 2.5957e-01, time/batch = 16.6157s	
11154/11350 (epoch 49.137), train_loss = 0.42649099, grad/param norm = 3.5760e-01, time/batch = 16.3004s	
11155/11350 (epoch 49.141), train_loss = 0.54670870, grad/param norm = 4.4510e-01, time/batch = 16.3825s	
11156/11350 (epoch 49.145), train_loss = 0.48830936, grad/param norm = 3.4182e-01, time/batch = 17.4064s	
11157/11350 (epoch 49.150), train_loss = 0.50562478, grad/param norm = 4.6924e-01, time/batch = 16.5351s	
11158/11350 (epoch 49.154), train_loss = 0.58595065, grad/param norm = 3.9530e-01, time/batch = 16.4745s	
11159/11350 (epoch 49.159), train_loss = 0.43252016, grad/param norm = 3.2953e-01, time/batch = 16.1400s	
11160/11350 (epoch 49.163), train_loss = 0.55458324, grad/param norm = 3.7359e-01, time/batch = 17.0951s	
11161/11350 (epoch 49.167), train_loss = 0.57098903, grad/param norm = 3.7720e-01, time/batch = 16.7131s	
11162/11350 (epoch 49.172), train_loss = 0.66580660, grad/param norm = 3.2432e-01, time/batch = 16.5441s	
11163/11350 (epoch 49.176), train_loss = 0.50880987, grad/param norm = 3.3296e-01, time/batch = 17.0297s	
11164/11350 (epoch 49.181), train_loss = 0.48660284, grad/param norm = 4.2818e-01, time/batch = 16.5523s	
11165/11350 (epoch 49.185), train_loss = 0.47577484, grad/param norm = 3.2706e-01, time/batch = 16.4641s	
11166/11350 (epoch 49.189), train_loss = 0.42928230, grad/param norm = 2.9170e-01, time/batch = 16.3010s	
11167/11350 (epoch 49.194), train_loss = 0.40537437, grad/param norm = 3.5541e-01, time/batch = 16.3933s	
11168/11350 (epoch 49.198), train_loss = 0.37395417, grad/param norm = 3.9899e-01, time/batch = 16.4876s	
11169/11350 (epoch 49.203), train_loss = 0.48376382, grad/param norm = 4.8930e-01, time/batch = 16.8701s	
11170/11350 (epoch 49.207), train_loss = 0.42348528, grad/param norm = 3.8601e-01, time/batch = 16.6994s	
11171/11350 (epoch 49.211), train_loss = 0.53874558, grad/param norm = 3.7229e-01, time/batch = 16.7781s	
11172/11350 (epoch 49.216), train_loss = 0.51526194, grad/param norm = 3.4282e-01, time/batch = 16.6344s	
11173/11350 (epoch 49.220), train_loss = 0.52694245, grad/param norm = 3.7814e-01, time/batch = 16.5607s	
11174/11350 (epoch 49.225), train_loss = 0.47218714, grad/param norm = 2.6787e-01, time/batch = 17.4782s	
11175/11350 (epoch 49.229), train_loss = 0.49330607, grad/param norm = 3.0074e-01, time/batch = 16.6234s	
11176/11350 (epoch 49.233), train_loss = 0.47904176, grad/param norm = 5.6544e-01, time/batch = 16.6323s	
11177/11350 (epoch 49.238), train_loss = 0.56735751, grad/param norm = 4.4101e-01, time/batch = 16.5420s	
11178/11350 (epoch 49.242), train_loss = 0.56116428, grad/param norm = 3.8540e-01, time/batch = 17.0168s	
11179/11350 (epoch 49.247), train_loss = 0.41541614, grad/param norm = 2.9525e-01, time/batch = 16.4649s	
11180/11350 (epoch 49.251), train_loss = 0.48409015, grad/param norm = 4.0157e-01, time/batch = 16.3901s	
11181/11350 (epoch 49.256), train_loss = 0.53202172, grad/param norm = 3.4382e-01, time/batch = 17.0977s	
11182/11350 (epoch 49.260), train_loss = 0.48348379, grad/param norm = 2.8658e-01, time/batch = 16.3069s	
11183/11350 (epoch 49.264), train_loss = 0.43068330, grad/param norm = 3.3937e-01, time/batch = 16.7720s	
11184/11350 (epoch 49.269), train_loss = 0.49957442, grad/param norm = 2.7479e-01, time/batch = 16.3090s	
11185/11350 (epoch 49.273), train_loss = 0.55810824, grad/param norm = 3.1227e-01, time/batch = 16.5380s	
11186/11350 (epoch 49.278), train_loss = 0.48113425, grad/param norm = 2.9894e-01, time/batch = 16.3836s	
11187/11350 (epoch 49.282), train_loss = 0.46167796, grad/param norm = 3.5302e-01, time/batch = 16.3826s	
11188/11350 (epoch 49.286), train_loss = 0.56754155, grad/param norm = 3.9088e-01, time/batch = 16.3843s	
11189/11350 (epoch 49.291), train_loss = 0.45506437, grad/param norm = 3.2212e-01, time/batch = 16.8670s	
11190/11350 (epoch 49.295), train_loss = 0.44443690, grad/param norm = 2.9100e-01, time/batch = 16.2248s	
11191/11350 (epoch 49.300), train_loss = 0.54176331, grad/param norm = 4.6392e-01, time/batch = 16.5543s	
11192/11350 (epoch 49.304), train_loss = 0.43407200, grad/param norm = 3.8419e-01, time/batch = 17.0127s	
11193/11350 (epoch 49.308), train_loss = 0.42763496, grad/param norm = 3.0312e-01, time/batch = 16.8016s	
11194/11350 (epoch 49.313), train_loss = 0.50441588, grad/param norm = 3.2918e-01, time/batch = 16.6405s	
11195/11350 (epoch 49.317), train_loss = 0.49300108, grad/param norm = 2.8341e-01, time/batch = 16.6122s	
11196/11350 (epoch 49.322), train_loss = 0.47600929, grad/param norm = 3.6578e-01, time/batch = 17.3234s	
11197/11350 (epoch 49.326), train_loss = 0.49962748, grad/param norm = 2.9424e-01, time/batch = 16.2981s	
11198/11350 (epoch 49.330), train_loss = 0.41257373, grad/param norm = 2.5376e-01, time/batch = 16.0628s	
11199/11350 (epoch 49.335), train_loss = 0.33861312, grad/param norm = 2.8643e-01, time/batch = 16.5297s	
11200/11350 (epoch 49.339), train_loss = 0.37214442, grad/param norm = 4.0708e-01, time/batch = 16.4698s	
11201/11350 (epoch 49.344), train_loss = 0.42003517, grad/param norm = 2.9565e-01, time/batch = 16.8707s	
11202/11350 (epoch 49.348), train_loss = 0.46133005, grad/param norm = 2.7990e-01, time/batch = 16.4551s	
11203/11350 (epoch 49.352), train_loss = 0.37374028, grad/param norm = 2.9132e-01, time/batch = 17.0070s	
11204/11350 (epoch 49.357), train_loss = 0.43284230, grad/param norm = 2.4111e-01, time/batch = 16.4679s	
11205/11350 (epoch 49.361), train_loss = 0.38246468, grad/param norm = 2.6392e-01, time/batch = 16.6499s	
11206/11350 (epoch 49.366), train_loss = 0.42943805, grad/param norm = 3.4757e-01, time/batch = 16.6220s	
11207/11350 (epoch 49.370), train_loss = 0.39501852, grad/param norm = 3.7064e-01, time/batch = 16.3708s	
11208/11350 (epoch 49.374), train_loss = 0.42386844, grad/param norm = 3.0455e-01, time/batch = 16.3901s	
11209/11350 (epoch 49.379), train_loss = 0.43239030, grad/param norm = 3.1592e-01, time/batch = 16.6360s	
11210/11350 (epoch 49.383), train_loss = 0.37431938, grad/param norm = 3.1646e-01, time/batch = 17.0842s	
11211/11350 (epoch 49.388), train_loss = 0.43364122, grad/param norm = 3.2145e-01, time/batch = 16.4645s	
11212/11350 (epoch 49.392), train_loss = 0.49263236, grad/param norm = 2.8961e-01, time/batch = 17.3985s	
11213/11350 (epoch 49.396), train_loss = 0.40539768, grad/param norm = 3.3554e-01, time/batch = 16.6908s	
11214/11350 (epoch 49.401), train_loss = 0.43926768, grad/param norm = 4.1097e-01, time/batch = 16.7054s	
11215/11350 (epoch 49.405), train_loss = 0.57451567, grad/param norm = 5.4304e-01, time/batch = 16.4531s	
11216/11350 (epoch 49.410), train_loss = 0.61479073, grad/param norm = 3.7579e-01, time/batch = 16.7841s	
11217/11350 (epoch 49.414), train_loss = 0.40844225, grad/param norm = 3.6935e-01, time/batch = 16.9498s	
11218/11350 (epoch 49.419), train_loss = 0.41046734, grad/param norm = 2.8880e-01, time/batch = 16.4557s	
11219/11350 (epoch 49.423), train_loss = 0.41987232, grad/param norm = 4.2413e-01, time/batch = 16.7050s	
11220/11350 (epoch 49.427), train_loss = 0.50095420, grad/param norm = 4.0744e-01, time/batch = 16.6413s	
11221/11350 (epoch 49.432), train_loss = 0.47265346, grad/param norm = 3.2649e-01, time/batch = 16.7141s	
11222/11350 (epoch 49.436), train_loss = 0.38818985, grad/param norm = 2.9646e-01, time/batch = 16.4785s	
11223/11350 (epoch 49.441), train_loss = 0.52233548, grad/param norm = 3.9261e-01, time/batch = 16.5603s	
11224/11350 (epoch 49.445), train_loss = 0.41894144, grad/param norm = 2.7564e-01, time/batch = 16.7838s	
11225/11350 (epoch 49.449), train_loss = 0.49889072, grad/param norm = 3.2453e-01, time/batch = 16.1252s	
11226/11350 (epoch 49.454), train_loss = 0.59914561, grad/param norm = 4.0879e-01, time/batch = 16.7058s	
11227/11350 (epoch 49.458), train_loss = 0.41012867, grad/param norm = 3.0965e-01, time/batch = 16.3114s	
11228/11350 (epoch 49.463), train_loss = 0.43913010, grad/param norm = 3.2233e-01, time/batch = 17.3192s	
11229/11350 (epoch 49.467), train_loss = 0.59793069, grad/param norm = 3.8432e-01, time/batch = 16.2279s	
11230/11350 (epoch 49.471), train_loss = 0.58494543, grad/param norm = 3.9765e-01, time/batch = 16.4713s	
11231/11350 (epoch 49.476), train_loss = 0.49073921, grad/param norm = 3.1439e-01, time/batch = 17.2049s	
11232/11350 (epoch 49.480), train_loss = 0.55555464, grad/param norm = 3.8211e-01, time/batch = 16.7904s	
11233/11350 (epoch 49.485), train_loss = 0.50378445, grad/param norm = 3.1290e-01, time/batch = 16.4337s	
11234/11350 (epoch 49.489), train_loss = 0.55290741, grad/param norm = 4.0596e-01, time/batch = 16.6279s	
11235/11350 (epoch 49.493), train_loss = 0.58748997, grad/param norm = 3.3910e-01, time/batch = 16.3768s	
11236/11350 (epoch 49.498), train_loss = 0.37625841, grad/param norm = 2.8530e-01, time/batch = 16.5445s	
11237/11350 (epoch 49.502), train_loss = 0.59266854, grad/param norm = 3.2643e-01, time/batch = 16.7687s	
11238/11350 (epoch 49.507), train_loss = 0.41950434, grad/param norm = 3.0099e-01, time/batch = 16.5364s	
11239/11350 (epoch 49.511), train_loss = 0.52699805, grad/param norm = 3.0020e-01, time/batch = 16.7095s	
11240/11350 (epoch 49.515), train_loss = 0.50770705, grad/param norm = 3.3776e-01, time/batch = 16.1321s	
11241/11350 (epoch 49.520), train_loss = 0.60693910, grad/param norm = 3.7219e-01, time/batch = 16.5531s	
11242/11350 (epoch 49.524), train_loss = 0.55368268, grad/param norm = 3.8648e-01, time/batch = 16.7748s	
11243/11350 (epoch 49.529), train_loss = 0.46412365, grad/param norm = 2.9020e-01, time/batch = 16.8723s	
11244/11350 (epoch 49.533), train_loss = 0.62347205, grad/param norm = 3.5431e-01, time/batch = 16.9707s	
11245/11350 (epoch 49.537), train_loss = 0.58674135, grad/param norm = 3.6892e-01, time/batch = 16.5377s	
11246/11350 (epoch 49.542), train_loss = 0.48422186, grad/param norm = 3.1218e-01, time/batch = 17.0280s	
11247/11350 (epoch 49.546), train_loss = 0.61596848, grad/param norm = 4.3527e-01, time/batch = 16.3882s	
11248/11350 (epoch 49.551), train_loss = 0.55664081, grad/param norm = 4.0080e-01, time/batch = 16.3687s	
11249/11350 (epoch 49.555), train_loss = 0.43546028, grad/param norm = 3.2435e-01, time/batch = 16.9394s	
11250/11350 (epoch 49.559), train_loss = 0.52355584, grad/param norm = 2.9297e-01, time/batch = 16.1172s	
11251/11350 (epoch 49.564), train_loss = 0.52663291, grad/param norm = 4.2750e-01, time/batch = 16.4556s	
11252/11350 (epoch 49.568), train_loss = 0.51935352, grad/param norm = 3.1902e-01, time/batch = 16.1470s	
11253/11350 (epoch 49.573), train_loss = 0.63535847, grad/param norm = 4.9256e-01, time/batch = 16.6948s	
11254/11350 (epoch 49.577), train_loss = 0.57989475, grad/param norm = 3.9522e-01, time/batch = 16.0217s	
11255/11350 (epoch 49.581), train_loss = 0.64912586, grad/param norm = 3.8997e-01, time/batch = 16.4630s	
11256/11350 (epoch 49.586), train_loss = 0.58504580, grad/param norm = 3.5118e-01, time/batch = 16.6252s	
11257/11350 (epoch 49.590), train_loss = 0.63147106, grad/param norm = 4.5132e-01, time/batch = 16.6260s	
11258/11350 (epoch 49.595), train_loss = 0.70978952, grad/param norm = 4.3527e-01, time/batch = 16.4767s	
11259/11350 (epoch 49.599), train_loss = 0.53623426, grad/param norm = 3.5702e-01, time/batch = 16.4670s	
11260/11350 (epoch 49.604), train_loss = 0.53792146, grad/param norm = 3.4932e-01, time/batch = 17.1173s	
11261/11350 (epoch 49.608), train_loss = 0.51290699, grad/param norm = 3.7233e-01, time/batch = 16.6354s	
11262/11350 (epoch 49.612), train_loss = 0.54038159, grad/param norm = 3.4096e-01, time/batch = 16.6366s	
11263/11350 (epoch 49.617), train_loss = 0.63360294, grad/param norm = 3.5781e-01, time/batch = 17.4067s	
11264/11350 (epoch 49.621), train_loss = 0.61935755, grad/param norm = 3.7369e-01, time/batch = 32.2522s	
11265/11350 (epoch 49.626), train_loss = 0.54427248, grad/param norm = 3.1056e-01, time/batch = 16.7166s	
11266/11350 (epoch 49.630), train_loss = 0.54844767, grad/param norm = 3.5710e-01, time/batch = 17.0111s	
11267/11350 (epoch 49.634), train_loss = 0.51633756, grad/param norm = 3.6591e-01, time/batch = 16.6343s	
11268/11350 (epoch 49.639), train_loss = 0.51395948, grad/param norm = 3.9311e-01, time/batch = 17.1690s	
11269/11350 (epoch 49.643), train_loss = 0.44326718, grad/param norm = 3.2464e-01, time/batch = 16.2191s	
11270/11350 (epoch 49.648), train_loss = 0.51498803, grad/param norm = 3.0210e-01, time/batch = 17.1210s	
11271/11350 (epoch 49.652), train_loss = 0.46019899, grad/param norm = 3.1510e-01, time/batch = 16.5428s	
11272/11350 (epoch 49.656), train_loss = 0.55944444, grad/param norm = 3.3000e-01, time/batch = 16.6159s	
11273/11350 (epoch 49.661), train_loss = 0.55298917, grad/param norm = 4.5277e-01, time/batch = 16.6294s	
11274/11350 (epoch 49.665), train_loss = 0.57321969, grad/param norm = 4.0136e-01, time/batch = 16.8759s	
11275/11350 (epoch 49.670), train_loss = 0.56503270, grad/param norm = 3.3543e-01, time/batch = 16.8841s	
11276/11350 (epoch 49.674), train_loss = 0.51128823, grad/param norm = 3.4509e-01, time/batch = 16.3913s	
11277/11350 (epoch 49.678), train_loss = 0.58572249, grad/param norm = 3.4505e-01, time/batch = 17.1014s	
11278/11350 (epoch 49.683), train_loss = 0.51657918, grad/param norm = 3.3512e-01, time/batch = 16.7164s	
11279/11350 (epoch 49.687), train_loss = 0.46126172, grad/param norm = 3.3765e-01, time/batch = 17.1071s	
11280/11350 (epoch 49.692), train_loss = 0.69418417, grad/param norm = 4.7267e-01, time/batch = 16.7747s	
11281/11350 (epoch 49.696), train_loss = 0.70363317, grad/param norm = 3.9311e-01, time/batch = 16.8600s	
11282/11350 (epoch 49.700), train_loss = 0.60793443, grad/param norm = 3.4225e-01, time/batch = 16.3102s	
11283/11350 (epoch 49.705), train_loss = 0.63558952, grad/param norm = 4.4054e-01, time/batch = 16.7926s	
11284/11350 (epoch 49.709), train_loss = 0.61947955, grad/param norm = 3.4988e-01, time/batch = 17.0297s	
11285/11350 (epoch 49.714), train_loss = 0.55478235, grad/param norm = 3.3993e-01, time/batch = 16.8800s	
11286/11350 (epoch 49.718), train_loss = 0.47501129, grad/param norm = 2.8224e-01, time/batch = 16.7215s	
11287/11350 (epoch 49.722), train_loss = 0.54461804, grad/param norm = 4.2118e-01, time/batch = 17.3102s	
11288/11350 (epoch 49.727), train_loss = 0.57267260, grad/param norm = 3.3582e-01, time/batch = 16.9265s	
11289/11350 (epoch 49.731), train_loss = 0.51786971, grad/param norm = 3.3129e-01, time/batch = 16.7867s	
11290/11350 (epoch 49.736), train_loss = 0.49917399, grad/param norm = 4.5831e-01, time/batch = 16.5445s	
11291/11350 (epoch 49.740), train_loss = 0.51700299, grad/param norm = 3.1348e-01, time/batch = 17.0300s	
11292/11350 (epoch 49.744), train_loss = 0.52300931, grad/param norm = 3.3518e-01, time/batch = 16.9478s	
11293/11350 (epoch 49.749), train_loss = 0.53132312, grad/param norm = 3.8650e-01, time/batch = 16.4711s	
11294/11350 (epoch 49.753), train_loss = 0.56664632, grad/param norm = 3.6482e-01, time/batch = 16.5481s	
11295/11350 (epoch 49.758), train_loss = 0.53650600, grad/param norm = 3.9056e-01, time/batch = 16.7078s	
11296/11350 (epoch 49.762), train_loss = 0.62960970, grad/param norm = 3.5443e-01, time/batch = 16.4756s	
11297/11350 (epoch 49.767), train_loss = 0.64201558, grad/param norm = 3.0445e-01, time/batch = 16.6277s	
11298/11350 (epoch 49.771), train_loss = 0.74119401, grad/param norm = 4.1500e-01, time/batch = 17.0895s	
11299/11350 (epoch 49.775), train_loss = 0.59288885, grad/param norm = 3.6397e-01, time/batch = 16.4578s	
11300/11350 (epoch 49.780), train_loss = 0.61929588, grad/param norm = 3.4797e-01, time/batch = 16.2329s	
11301/11350 (epoch 49.784), train_loss = 0.54901850, grad/param norm = 3.7890e-01, time/batch = 17.1675s	
11302/11350 (epoch 49.789), train_loss = 0.57563616, grad/param norm = 3.5884e-01, time/batch = 17.1023s	
11303/11350 (epoch 49.793), train_loss = 0.60963838, grad/param norm = 3.5226e-01, time/batch = 16.6405s	
11304/11350 (epoch 49.797), train_loss = 0.59656813, grad/param norm = 4.2415e-01, time/batch = 16.7155s	
11305/11350 (epoch 49.802), train_loss = 0.55084708, grad/param norm = 3.2390e-01, time/batch = 16.7091s	
11306/11350 (epoch 49.806), train_loss = 0.59125990, grad/param norm = 3.2937e-01, time/batch = 16.7126s	
11307/11350 (epoch 49.811), train_loss = 0.57648046, grad/param norm = 2.9743e-01, time/batch = 17.1558s	
11308/11350 (epoch 49.815), train_loss = 0.54744493, grad/param norm = 3.1112e-01, time/batch = 16.4780s	
11309/11350 (epoch 49.819), train_loss = 0.49529866, grad/param norm = 3.3959e-01, time/batch = 16.4542s	
11310/11350 (epoch 49.824), train_loss = 0.49349241, grad/param norm = 3.5821e-01, time/batch = 16.5557s	
11311/11350 (epoch 49.828), train_loss = 0.51421101, grad/param norm = 3.4003e-01, time/batch = 17.1948s	
11312/11350 (epoch 49.833), train_loss = 0.52720337, grad/param norm = 3.2805e-01, time/batch = 16.5473s	
11313/11350 (epoch 49.837), train_loss = 0.57165143, grad/param norm = 4.4283e-01, time/batch = 16.7056s	
11314/11350 (epoch 49.841), train_loss = 0.74774666, grad/param norm = 3.7200e-01, time/batch = 16.3027s	
11315/11350 (epoch 49.846), train_loss = 0.62389107, grad/param norm = 3.1539e-01, time/batch = 16.3114s	
11316/11350 (epoch 49.850), train_loss = 0.62614820, grad/param norm = 4.1686e-01, time/batch = 17.2595s	
11317/11350 (epoch 49.855), train_loss = 0.46455482, grad/param norm = 3.0602e-01, time/batch = 17.0888s	
11318/11350 (epoch 49.859), train_loss = 0.49162431, grad/param norm = 3.7535e-01, time/batch = 16.3827s	
11319/11350 (epoch 49.863), train_loss = 0.48641343, grad/param norm = 3.3805e-01, time/batch = 16.4686s	
11320/11350 (epoch 49.868), train_loss = 0.49924181, grad/param norm = 3.3680e-01, time/batch = 16.6963s	
11321/11350 (epoch 49.872), train_loss = 0.48712078, grad/param norm = 3.1885e-01, time/batch = 16.8551s	
11322/11350 (epoch 49.877), train_loss = 0.49779386, grad/param norm = 4.0464e-01, time/batch = 16.2297s	
11323/11350 (epoch 49.881), train_loss = 0.66519153, grad/param norm = 3.7941e-01, time/batch = 17.0346s	
11324/11350 (epoch 49.885), train_loss = 0.59851723, grad/param norm = 3.2477e-01, time/batch = 16.6371s	
11325/11350 (epoch 49.890), train_loss = 0.58016262, grad/param norm = 3.8254e-01, time/batch = 16.4743s	
11326/11350 (epoch 49.894), train_loss = 0.50764484, grad/param norm = 3.2216e-01, time/batch = 16.6964s	
11327/11350 (epoch 49.899), train_loss = 0.59566854, grad/param norm = 3.2645e-01, time/batch = 16.9378s	
11328/11350 (epoch 49.903), train_loss = 0.56777943, grad/param norm = 3.7033e-01, time/batch = 16.1392s	
11329/11350 (epoch 49.907), train_loss = 0.49364247, grad/param norm = 3.1080e-01, time/batch = 16.7190s	
11330/11350 (epoch 49.912), train_loss = 0.51095856, grad/param norm = 3.2385e-01, time/batch = 16.5464s	
11331/11350 (epoch 49.916), train_loss = 0.55204838, grad/param norm = 3.3401e-01, time/batch = 16.3125s	
11332/11350 (epoch 49.921), train_loss = 0.56187333, grad/param norm = 3.6562e-01, time/batch = 16.1365s	
11333/11350 (epoch 49.925), train_loss = 0.49700868, grad/param norm = 2.9424e-01, time/batch = 16.4682s	
11334/11350 (epoch 49.930), train_loss = 0.54162052, grad/param norm = 3.9678e-01, time/batch = 17.0802s	
11335/11350 (epoch 49.934), train_loss = 0.63684549, grad/param norm = 4.1059e-01, time/batch = 16.1505s	
11336/11350 (epoch 49.938), train_loss = 0.57737275, grad/param norm = 4.3511e-01, time/batch = 16.1381s	
11337/11350 (epoch 49.943), train_loss = 0.60756973, grad/param norm = 4.3955e-01, time/batch = 16.4716s	
11338/11350 (epoch 49.947), train_loss = 0.58179393, grad/param norm = 3.8613e-01, time/batch = 17.0298s	
11339/11350 (epoch 49.952), train_loss = 0.57954439, grad/param norm = 3.8762e-01, time/batch = 16.2411s	
11340/11350 (epoch 49.956), train_loss = 0.47946841, grad/param norm = 2.9539e-01, time/batch = 16.9169s	
11341/11350 (epoch 49.960), train_loss = 0.53198676, grad/param norm = 3.7705e-01, time/batch = 16.4709s	
11342/11350 (epoch 49.965), train_loss = 0.45035449, grad/param norm = 2.7501e-01, time/batch = 16.6245s	
11343/11350 (epoch 49.969), train_loss = 0.45029649, grad/param norm = 3.2198e-01, time/batch = 16.3874s	
11344/11350 (epoch 49.974), train_loss = 0.44471236, grad/param norm = 3.0706e-01, time/batch = 16.6975s	
11345/11350 (epoch 49.978), train_loss = 0.51870064, grad/param norm = 2.7448e-01, time/batch = 16.6078s	
11346/11350 (epoch 49.982), train_loss = 0.35859590, grad/param norm = 3.4640e-01, time/batch = 16.3083s	
11347/11350 (epoch 49.987), train_loss = 0.55885725, grad/param norm = 4.6017e-01, time/batch = 16.7022s	
11348/11350 (epoch 49.991), train_loss = 0.46126449, grad/param norm = 3.6323e-01, time/batch = 16.0585s	
11349/11350 (epoch 49.996), train_loss = 0.50719644, grad/param norm = 3.4464e-01, time/batch = 16.9372s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_julialanguage_epoch50.00_2.2584.t7	
11350/11350 (epoch 50.000), train_loss = 0.42787515, grad/param norm = 3.5925e-01, time/batch = 16.5551s	

real	3115m24.567s
user	3094m5.252s
sys	2m50.264s
